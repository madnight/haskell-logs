02:54:57 <shapr> yow
03:16:15 * shapr finds an amusing Simon PJ quote
03:16:19 <shapr> I'm not sure what Hugs is doing.  Maybe it just generates the above
03:16:20 <shapr> instance declaration and hopes for the best.
03:16:33 * shapr is entertained by athropomorphised software
03:16:52 * opet gives shapr an n
03:17:00 <shapr> whoops, thanks
03:17:24 <shapr> maybe less code and more sleep last night...
03:21:57 <Marvin--> shapr: I think there's way too much of that in free software
03:22:04 <Marvin--> "Do you want me to overwrite foo with bar?"
03:23:31 <Marvin--> In Haskell, what's a Char? A wide unicode character?
03:24:29 <shapr> Marvin--: too much code and not enough sleep in free software?
03:24:55 <shapr> Marvin--: according to the standard, unicode, dunno if that means wide or not (don't even know what that means)
03:24:56 <Marvin--> shapr: no, too much anthropomorphization
03:24:58 <shapr> oh
03:25:09 <shapr> I think there's not enough :-)
03:25:18 <shapr> my emacs loves me.
03:25:19 * shapr laughs
03:25:30 <shapr> ok, maybe you're right
03:25:41 <Marvin--> I'm just curious how a) I can create a unicode string, b) what happens to a unicode string when I convert it to a CString
03:26:24 <shapr> I thought neither GHC nor Hugs had any clue about unicode?
03:26:36 <shapr> er..
03:26:46 <shapr> oh, I'm thinking about source code
03:26:46 <shapr> nm
03:27:01 <Marvin--> I don't care about source code
03:27:09 <Marvin--> very very very few programs need hardcoded strings in the source code
03:27:25 <Marvin--> and very very very few of them *should* have it
03:27:42 <shapr> that's true
03:28:18 <Marvin--> I'm thinking of counterparts to python's  str.decode  and unicode.encode  methods
03:28:58 <Marvin--> if I read a string from the user, is haskell the least bit aware of whether the environment is Latin1 or UTF-8 or something else?
03:30:06 <Marvin--> oh, have you talked to John about the quickCheck script btw?
03:30:14 <shapr> no, I got distracted :-(
03:30:17 <shapr> I'll send him an email right now
03:30:37 <Marvin--> http://www.cs.chalmers.se/~rjmh/QuickCheck/quickCheck <- looks like he's fixed it anyway
03:30:56 <Marvin--> looks like he fixed it by reverting your patch entirely
03:31:01 <shapr> oh, he has
03:31:18 <shapr> by putting the old one up I think
03:31:27 <Marvin--> that's what I said ;)
03:31:32 <shapr> oh, yes
03:31:42 <shapr> bah, I hate submitting crappy code
03:34:05 <shapr> dammit.
03:34:25 * Marvin-- brings forth vimdiff
03:34:44 <shapr> I doubt I'll have time to try to fix the quickcheck script till the weekend
03:34:51 <shapr> I have way too much crap to do this week
03:34:58 <shapr> I may have to go away from irc entirely
03:35:02 * shapr gasps in horror
03:35:21 <shapr> btw, there's a very cool thread about embedded Haskell on the main haskell list
03:35:25 <buggs> you have your finals or sth?
03:35:42 <shapr> buggs: not really, I have to get this xslt done by friday.
03:35:55 <shapr> I converting a custom xml format into openoffice xml for editing and printing
03:36:02 <shapr> s/I/I'm/
03:36:04 <Marvin--> shapr: I was about to mail him my unlit function
03:36:21 <shapr> Marvin--: going to mail him a unified diff?
03:36:23 <shapr> that's probably best.
03:36:50 <shapr> I must remember to ask others to test my code before sending it off :-(
03:37:17 <shapr> buggs: my clients want this done by friday
03:37:31 <Marvin--> shapr: I was thinking of attaching the entire script and put the unified diff inlined in the mail
03:37:36 <shapr> oh, good idea.
03:37:41 <Marvin--> or perhaps attaching it if it's too big
03:38:34 <buggs> ah ok then i don't think you'll drop irc ;)
03:39:44 <shapr> irc distracts me sometimes, and helps me others
03:39:46 <shapr> it's hard to choose
03:39:52 <Marvin--> shapr: no wait, there's both quickCheck and quickcheck scripts there, the quickcheck one is your b0rken version
03:40:05 <Marvin--> unfortunately it's also the one linked from the main page
03:41:07 <shapr> oho
03:41:29 <Marvin--> so you might still want to mail him
03:42:56 <shapr> ok
03:46:00 <shapr> hi usander 
03:46:00 <usander> Hi
03:48:00 * Marvin-- peers at shapr
04:33:05 <Janni> g'day!
05:18:23 <andersca> hey Marvin--
05:38:31 <Marvin--> hello
06:38:24 <mgoetze> so, i've got some code which looks like this:
06:38:56 <mgoetze> squares = (1,1):[(a+1,b+1+a+a)|(a,b)<-squares]
06:39:18 <mgoetze> intsqrt x = head [a|(a,b)<-squares,b>x]
06:39:57 <mgoetze> it's really fast when squares has already been evaluated sufficiently far, otherwise it's bloody slow. so my question is, is there any way to get ghc to load a cached evaluation from a file or something?
06:45:30 <Marvin--> heh
06:45:38 <Marvin--> you'd probably have to do that manually
06:45:43 <Marvin--> cute code though
06:46:48 <mgoetze> it's part of my quest to find prime factors really quickly :)
06:46:56 <Marvin--> good luck ;)
06:47:09 <mgoetze> i think i'm doing ok... want a copy of the code?
06:47:42 <Marvin--> not really, I'm leaving about now
06:47:55 <mgoetze> ok
06:47:58 <mgoetze> see you :)
07:17:48 <mgoetze> Prime> primefactors 2718281828459045
07:17:48 <mgoetze> [5,47,181,63906943187]
07:17:48 <mgoetze> (26.66 secs, 251041260 bytes)
07:18:03 <mgoetze> hm, i think that's pretty decent...
07:18:17 <mgoetze> anyone want to look at my code and see if they can find improvements?
07:20:46 <Igloo> I think Richard Brent would have a few algorithmic suggestions, but I'm not going to go ask him  :-)
07:22:02 <mgoetze> well, i have no idea who that is :)
07:22:29 * mgoetze googles
07:24:09 <mgoetze> yeah, he does look like the kind of person who would have suggestions on that :)
07:27:23 <Igloo> A numerical analyst name-dropped by Knuth sums it up, I think  :-)
07:30:43 <mgoetze> so, anyone more down-to-earth who wants to have a look at my code? :)
07:47:05 <Janni> yay, me! (but I don't think I can find some). gimme the URL
07:47:30 <mgoetze> url? you'd like it to be online? :)
07:47:37 * mgoetze was thinking more of a /QUERY
07:48:43 <mgoetze> anyway, let me get it online
07:48:50 <Janni> mgoetze: I don't care
07:51:29 <mgoetze> www.mgoetze.net/~mgoetze/prime.hs
08:04:01 <Janni> mgoetze: are you using True instead of otherwise on purpose? I think otherwise is nicer...
08:04:33 <mgoetze> Janni: actually, i was thinking that myself earlier :)
08:04:50 <mgoetze> i'll probably change it
08:06:01 <Janni> mgoetze: and you don't have to use divMod here.
08:06:16 <Janni> divides x y = r == 0 where (q,r) = divMod x y   can be changed to
08:06:32 <Janni> divides x y = r == 0 where r = x `mod` y
08:06:57 <Janni> but I don't think this will improve the performance
08:07:27 <mgoetze> yes, i assume that will be the same, performancewise, but i'm not sure
08:08:55 <Janni> But it's sury more logic code...
08:09:58 <Igloo> It'll depend how much optimisation happens and what the strictness analyser makes of it
08:10:16 <Igloo> It's also just divides x y = x `mod` y == 0 of course
08:20:11 <Janni> mgoetze: I think I know a thing that could be optimized. you aren't utilizing the fact, that the first argument of "without" is always a list of the form [x,2x,4x,...]
08:20:33 <Janni> err wait... have to think about that...
08:21:57 <mgoetze> well, it may be more of the form [16x, 17x, 19x, 20x, 23x, ...]
08:22:48 <mgoetze> actually, no, it's not even that :)
08:23:39 <mgoetze> the second argument is, of course, of the form [x,2x,3x,4x,5x...], but i have no idea how i would go about utilizing that :)
08:24:38 <Janni> mgoetze: multiples cur add max = [cur, cur + add .. max]
08:24:58 <mgoetze> oh, that works?
08:25:47 <mgoetze> (in that case, i could even change it to Integer->Integer->[Integer])
08:28:19 <mgoetze> yes, that works
08:28:29 * mgoetze checks for noticable speed increase.... doubts it though :)
08:33:23 <Igloo> If you swap the 2 lines in sieve' does it go faster?
08:33:50 <Igloo> clauses rather, as the second is 2 lines  :-)
08:35:15 <mgoetze> i was actually wondering whether i need the first clause at all :)
08:35:33 <mgoetze> i'm pretty sure i don't, so i intend to take it out
08:36:18 <Igloo> That might make a diffeence as it will then be strict in max
08:37:06 <mgoetze> say again?
08:37:22 <mgoetze> ah, wait, i get it
08:38:58 <Igloo> Same for without, actually
08:39:07 <Igloo> Try moving the last clause to be the first
08:39:53 <mgoetze> do you mean the x>y case or do you mean the terminations? :)
08:40:25 <Igloo> The latter, if you mean what I think you mean  :-)
09:42:59 <mgoetze> Heffalump: www.mgoetze.net/~mgoetze/prime.hs - any suggestions for optimizations?
09:43:31 * Heffalump --> look
09:44:35 <Heffalump> any word on IOHCC results, btw?
09:44:37 <Heffalump> could you do better by making intsqrt a CAF lookup table like squares?
09:45:13 <Heffalump> also, multiplication isn't really expensive given that hardware does it natively, so is the squares optimisation really useful?
09:46:31 <Igloo> It only does it natively for ~32 bits
09:46:31 <Heffalump> what's the sieve 100 ++ for?
09:46:31 <Heffalump> true.
09:46:31 <Heffalump> oh yes, Integer
09:46:31 <Igloo> No word, I don't think
09:46:31 <Heffalump> sorry?
09:46:31 <Igloo> < Heffalump> any word on IOHCC results, btw?
09:46:32 <Heffalump> ah, right
09:46:32 <mgoetze> Heffalump: the squares optimisation really takes off once squares has already been evaluated and you go factor another number with the same lookup table...
09:46:42 <Heffalump> aren't you two judges? :-)
09:46:48 <Igloo> Yes
09:47:01 <Heffalump> mgoetze: sure, hence thinking that you could do the same with intsqrt
09:47:35 <Heffalump> though it's still a linear search
09:47:35 <mgoetze> Heffalump: the 'sieve 100 ++' is for numbers like 1000000000000000000 where intsqrt, let alone sieve would be very expensive, when i can just grab the first factor (2) easily
09:47:46 <Heffalump> right
09:48:02 <Heffalump> can't you make sieve intsqrt start from 100, then?
09:48:09 <mgoetze> i'll admit that 100 is rather arbitrary, of course ;)
09:48:38 <mgoetze> Heffalump: uhm... not really. at least, not in any way that would be more efficient than what is done now
09:48:52 <Igloo> Why are you doing this OOI?
09:49:02 <mgoetze> i suppose i could do (drop 25 (sieve (intsqrt x))
09:49:05 <mgoetze> Igloo: excuse me?
09:49:10 <Heffalump> is sieve x supposed to just be a sieve of Eratosthenes to find the primes up to x ?
09:49:15 <mgoetze> Heffalump: that's right
09:49:24 <Heffalump> why not just define primes as another CAF and use takeWhile ?
09:50:10 <mgoetze> because takeWhile and dropWhile are pretty slow according to my subjective empirical impression :)
09:50:13 <Igloo> I can see the need for a simple implementation, an FFI calling optimised algorithm in C implementation and a reasonably fast Haskell implementation, but it's not clear why heavily optimised Haskell (of a sub-optimal algorithm) is useful?
09:50:18 <mgoetze> (probably because they throw lists around alot)
09:50:26 <Heffalump> and recalculating sieve each time won't be?
09:50:36 <Heffalump> takeWhile on a single list should be a linked list walk
09:50:56 <Heffalump> oh no, sorry
09:51:01 <Heffalump> dropWhile would be, takeWhile will copy
09:51:34 <mgoetze> Heffalump: well, i did an implementation with dropWhile, tried it on a test case for which it should be good, and found that the version with find is a lot faster (in ghci, at any rate)
09:51:36 <Heffalump> I'm inclined to think you should first make lots of CAF lists and then move to making them all balanced trees
09:52:21 <mgoetze> Igloo: oh, well, i'll happily implement a better algorithm once i get around to understanding those :)
09:54:49 <mgoetze> Heffalump: i'm not entirely sure how i would go about that... could you show me for the intsqrt bit at least, so i get the idea?
09:55:21 <Heffalump> the balanced trees?
09:55:24 <Heffalump> I have no idea :-)
09:55:37 <Heffalump> it was just an idea I had just now, I'm not actually sure how to implement it
09:56:10 <mgoetze> well, or even making a CAF of the intsqrt... unless it's what i think you mean, using exobytes of memory :)
09:56:42 <Heffalump> oh, hmm, it would
09:56:47 * Heffalump withdraws that idea :-)
09:57:12 <Heffalump> as would keeping a CAF of primes, I guess
10:00:51 <mgoetze> probably... sieve 100 is very fast anyhow, and that gets a lot of them
10:08:14 <mgoetze> btw, #go :)
11:10:10 <Rainer> Hi, I'm comverting to gVIM from xemacs and am still reading the manual. Could a vim user give me a hint how to interact with ghci?
11:11:28 <Rainer> I've read that the emacs way of "embedding" isn't possible..
11:15:16 <mgoetze> hmmm
11:15:50 <mgoetze> Rainer: well, i love vim and ghci, but i've never had any urge to let them "interact" specially :)
11:16:17 <Rainer> mgoetze: ok, what's your way of doing things then?
11:16:59 <Rainer> edit,compile,run?
11:17:34 <mgoetze> using vim, screen, ghci - :w^A^P:r<arrowup><enter>
11:18:43 <Rainer> ah, I'm just converting to freeBSD, I'll take a note of that
11:19:13 <Rainer> that means I'm still a win user
11:19:17 <mgoetze> oh :)
11:19:45 <mgoetze> on the linux console, you could of course do - :w<alt-arrowleft>:r<arrowup><enter>
11:19:48 <Rainer> ya, that's the other questions I have, what OS do you use, linux?
11:20:08 <Rainer> nm
11:20:11 <mgoetze> debian, irix, hpux mainly
11:20:29 <mgoetze> including my plans to get a debian/netbsd machine up "sometime"
11:21:13 <Rainer> and you main editor is vim, right?
11:21:59 <engstad> How can I generalize: foo = (func a) . (func b) . (func c) . (func d) . (func e) .... and so on.
11:22:14 <mgoetze> Rainer: s/main/only/ :)
11:22:28 <mgoetze> engstad: uhm, map?
11:22:37 <engstad> foo = map func [a,b,c,d,e] obviously doesn't work.
11:22:45 <mgoetze> why not?
11:22:47 <Rainer> fold?
11:23:05 <engstad> Using 'id' as unit?
11:23:56 <hdaume> i think you want 'foldr ($) func [a,b,c,d,e]' or something similar
11:24:36 <hdaume> oops, that's way wrong, nm
11:25:27 <hdaume> foldr (.) id $ map func [a,b,c,d,e] should work
11:25:39 <hdaume> you could obviously join the fold/map, but i don't really see why you should need to
11:26:00 <Rainer> foldr (.) (+3) [(+1),(+2)]$4
11:26:11 <Rainer> gives 10
11:27:02 <Rainer> foldr (.) x [func a,func b,...]
12:05:39 <engstad> Actually, I think I found it.
12:05:59 <engstad> foo x = foldr func x [a,b,c,d,e]
13:45:23 <shapr> whee
13:46:03 <dark> ?eehw
13:46:18 <shapr> hi hi hi dark!!
13:46:23 <shapr> work is over for the day
13:46:25 <shapr> yay!
13:46:30 <shapr> I get to work on my parser more
13:46:34 * shapr bounces happily
13:46:39 <shapr> oh dark, I have a question
13:46:45 <mgoetze> shapr: www.mgoetze.net/~mgoetze/prime.hs
13:46:48 <mgoetze> shapr: suggest optimizations! :)
13:47:26 * shapr looks
13:48:52 <shapr> neat
13:49:47 <mgoetze> it's reasonably fast, too
13:49:57 <mgoetze> (considering that it's a primitive algorithm)
13:50:02 <shapr> I've never tried to optimize Haskell code
13:50:26 <shapr> I wonder if profiling it would show places to optimize
13:50:52 * mgoetze enjoys banging random numbers into the keyboard and seeing what the prime factors are :)
13:51:28 <shapr> that is fun
13:51:45 <mgoetze> especially in haskell! lol
13:53:05 <shapr> I fixed my immediate type problem last night
13:53:20 <shapr> but I don't know how make nested algebraic types
13:53:43 <shapr> mgoetze: have you tried to profile it?
13:55:09 <mgoetze> nah, mostly just in ghci, :set +s and compared
13:55:32 <mgoetze> i have a pretty good idea of what takes the most time
13:55:38 <shapr> what is it?
13:56:00 <mgoetze> well, if there are big factors, a heckuva lot of time is spent in squares for the first evaluation
13:56:12 <mgoetze> after that, it seems to cache squares and go a lot faster
13:56:37 <shapr> *Prime> primefactors 68999911831
13:56:37 <shapr> [17,11471,353833]
13:56:37 <shapr> (0.55 secs, 23276592 bytes)
13:56:54 <shapr> it's faster than I expected
13:57:27 <mgoetze> do it a second time
13:57:35 <shapr> (0.26 secs, 8318868 bytes)
13:57:38 <shapr> ??
13:57:57 <mgoetze> yup, see, once squares has been evaluated that far, it doesn't get done again
13:58:01 <shapr> I see
13:58:01 <mgoetze> so it goes much faster
13:58:02 <shapr> nifty
13:58:29 <mgoetze> so, i was asking earlier whether there was any way to get ghc to load a cached evaluation
13:59:13 <mgoetze> i've already put some effort into making it go faster :)
14:01:02 * shapr profiles the code
14:02:37 <mgoetze> whatsit say?
14:02:53 <shapr> I got distracted, I decided to try ghc -O2 first
14:05:36 <shapr> whuff
14:05:42 <shapr> it can really eat memory
14:05:44 <shapr> I had to kill it
14:06:08 <mgoetze> what, the profiling? or did you throw a number with a really big factor at it? :)
14:06:16 <shapr> primefactors 689999118312533
14:06:30 <shapr> ate all my ram and got halfway through my swapfile before I could kill it
14:06:55 <mgoetze> yeah, i know that effect :)
14:07:06 <shapr> what's the largest number you've factored?
14:07:21 <mgoetze> i, uhm, don't remember
14:07:31 <mgoetze> but you can easily factor things like 1000000000000000000000000000000000000000000000000000000000 etc.
14:10:56 * shapr reads the profile
14:11:26 <shapr> http://kungens.kemi.fi/~shae/src/haskell/Main.prof
14:12:51 <mgoetze> yeah, that's about what i thought :)
14:13:09 <kawfee> hi
14:13:28 <shapr> hi kawfee 
14:13:33 <mgoetze> shapr: what was the test case?
14:13:36 * shapr tries to make a pretty postscript heap profile
14:13:41 <shapr> main = putStrLn $ show $ primefactors 6899991183111
14:15:26 <mgoetze> i wonder if i couldn't just use the standard sqrt function and round it up to an integer, that would probably be faster, wouldn't it?
14:15:27 * shapr chooses a larger number
14:15:37 <shapr> I don't know
14:15:39 <shapr> try it
14:20:23 <dark> shapr: question?
14:21:12 <shapr> memory consumption seems to grow very slowly, it's staying around 500mb of ram
14:21:32 <shapr> but it seems to want to look at all that ram regularly, it keeps swapping it in and out
14:21:45 <mgoetze> that's not good :(
14:22:05 <shapr> dark: I was going to ask you about using algebraic types as a pretend object tree, for more or less general types
14:22:15 <shapr> but I'm not sure if it's a silly question or not
14:22:19 <shapr> I think it is a silly question
14:23:12 <shapr> I don't think I can define 'subtypes' and later lump them together in another type declaration
14:23:42 <shapr> otoh, it works with data Foos = Int | String
14:26:01 * shapr gives up and kills the process
14:28:01 <mgoetze> hm, i just lost against myself, 13x13 with 4 handicap
14:28:12 <mgoetze> white had to resign before i even got to the other half of the board :)
14:28:16 <mgoetze> incidentally, #go
14:31:58 <dark> shapr: I can't figure out what you mean :)
14:32:23 * mgoetze prods shapr and dark into #go
14:32:28 <shapr> dark: data Trucks = Ford String | Chevy String
14:32:39 <shapr> data Cars = Mustang String | Taurus String
14:32:56 <shapr> then, can I declare a data Vehicles = Trucks | Cars
14:33:00 <shapr> basically, a superclass?
14:33:16 <shapr> I think I should be using a typeclass....
14:33:50 <dark> I don't think you can, at least not with that syntax.
14:34:19 <shapr> I'm trying to build a 'type tree' for RFC822 fields
14:34:29 <shapr> how would you do that?
14:37:50 <dark> I'd probably get a headache trying to do that :)  You might have to go all the way and make something as complex as the Num tree.
14:38:29 <shapr> hm, ok..
14:38:30 <shapr> thanks
14:39:31 <dark> I grappled with a similar problem for HTTP headers (that was in object-oriented C :).  I ended up making just two types of headers, string ones and comma-separated ones.  (That's pretty much the categories HTTP itself distinguishes)
14:39:52 <dark> Modeling all the header types completely was too messy, and just made the code more difficult to use, too.
14:40:03 <shapr> that's a good point
14:40:12 <shapr> I was wondering how to make the headers afterwards
14:40:41 <dark> An advantage of modeling them completely is that you get validity checks for free.  However, you can do that fairly easily with a separate function.
14:41:02 <dark> Also, I realized later that my usage required being able to deal with _invalid_ headers gracefully :)
14:41:07 <shapr> hm!
14:41:27 <shapr> I hadn't thought about that.
14:43:30 <jlouis> heh, now we have both haskel and SML as functional languages on OpenBSD 
14:44:07 <mgoetze> congratulations
14:44:09 <opet> obraun maintains loads of haskell stuff on freebsd
14:44:24 <dark> Hmm, in Haskell I might try it with just one typeclass for a header type, and implement a "generic string" one in addition to more specialized ones.  If I didn't want to go with just strings.
14:44:25 * mgoetze goes back to thinking of his plans for a debian/netbsd system for his collection
14:44:44 <dark> On the other hand... hm, no.  You'd want to be able to have a list of headers and that doesn't work with typeclasses.
14:52:09 <shapr> hi Pseudonym 
14:53:23 <mgoetze> ooh, lotsa judges here!
14:53:29 <Pseudonym> G'day.
14:53:40 * dark blushes and hides.
16:50:45 <engstad> Is there a good place to see how one can translate lazy evaluation into strict evaluation somewhere?
16:51:10 <engstad> I.e., I have a lazy algorithm. I want to transfer this to a strict language.
16:52:08 <Heffalump> well, you could use explicit laziness combinators
16:52:21 <whee> and some strict languages provide facilities for suspending evaulations
16:52:27 <whee> like streams
16:52:47 <engstad> Assume that the strict language is something like C++ or assembly... ;-)
16:53:07 <engstad> What is "explicit laziness combinators"?
16:53:12 <Heffalump> in SML:
16:53:31 <Heffalump> data 'a thunk = value of 'a | delay of (() -> 'a)
16:53:55 <Heffalump> force (value v) = v
16:54:12 <Pseudonym> In C++ you'd use an iterator or something for that.
16:54:17 <Heffalump> oh, sorry, I need a reference somewhere too
16:54:28 <Heffalump> get rid of that force line
16:54:33 <engstad> Ok.
16:54:36 <Heffalump> data 'a lazy = 'a thunk ref
16:55:18 <Heffalump> force l = case (!l) of value v => v | delay c => let v = c () in l := value v ; v
16:55:29 <Heffalump> basically you explicitly implement laziness using references
16:55:52 <engstad> I see.
16:55:55 <Pseudonym> Can I ask what algorithm it is?
16:56:03 <Pseudonym> Is it a well-known one that requires laziness?
16:56:32 <engstad> Hmm, yes and no.
16:56:54 <engstad> It's an old algorithm that I'm trying to prove is nothing but a lazy evaluation.
16:56:58 <Pseudonym> OK.
16:57:03 <Pseudonym> There's a lot of techniques you can use.
16:57:28 <Pseudonym> Dynamic programming is often lazy evaluation in disguise, for example.
16:57:40 <engstad> Yes. 
16:58:31 <engstad> How does the force get propagated in a structure like list or tree?
16:58:49 <Heffalump> manually
16:58:52 <Heffalump> it's not pleasant
16:58:58 <engstad> I suppose you must make a different kind of list?
16:59:10 <Heffalump> yeah
16:59:20 <Heffalump> datatype 'a stream = empty | cons of 'a * 'a stream susp
16:59:32 <Heffalump> where susp is the lazy type I mentioned above
16:59:44 <engstad> susp = lazy?
16:59:53 <Heffalump> yep
16:59:56 <engstad> ok.
16:59:57 <Pseudonym> In Haskell, decorating your data structures with ! sometimes helps.
17:00:44 <engstad> btw, what's the easiest way to trace evaluation in ghci and hugs?
17:01:00 <Pseudonym> That depends.
17:01:05 <Pseudonym> Manually, there's Debug.Trace.
17:01:59 <Pseudonym> There's a compile option you can set in hugs.
17:02:05 <Pseudonym> But the output isn't very helpful.
17:02:10 <Pseudonym> You might be better off using buddha.
17:06:08 <engstad> buddha?
17:06:52 <Pseudonym> I don't know if buddha supports this mode.  Many declarative debuggers work by tracing.
17:07:11 <Pseudonym> http://www.cs.mu.oz.au/~bjpop/buddha/
17:16:49 <engstad> Btw, I wonder if there's a more consise way of writing: 
17:16:55 <engstad> segs (a:b:pts) = func a b ++ segs (b:pts)
17:16:55 <engstad> segs _         = []
17:17:24 <hdaume> map uncurry func (zip l (tail l)) or something?
17:17:30 <hdaume> put parens around (uncurry func)
17:17:39 <engstad> Hmm, very good.
17:17:46 <hdaume> but the zip version will be hella slow :)
17:17:53 <engstad> Heh. :-)
17:18:13 <engstad> I wonder if perhaps my version is more instructive.
17:18:27 <Pseudonym> It will be the same order of complexity, surely?
17:18:36 <hdaume> Pseudonym: surely, but zip doesn't deforest
17:18:40 <hdaume> (on the second param
17:18:40 <hdaume> )
17:18:46 <engstad> I'm only interested in clearity, not efficiency.
17:18:59 <hdaume> engstad: you could also write [func a b | a <- l | b <- tail l], which is also fairly instructive
17:19:33 <engstad> hdaume: I like that one.
17:19:40 <hdaume> or even 'zipWith func l (tail l)'
17:21:13 <engstad> Wow, my code is very compact now.
17:26:33 * hdaume is going home
18:17:51 <shapr> Pseudonym: you understand Arrows?
18:18:13 <shapr> I was just wondering....
18:18:19 <shapr> if monads can be lifted to arrows
18:18:28 <shapr> and arrows are automatically arrow transformers
18:18:49 <shapr> can you get a monad back out of an arrow like you can with getting a value out of a monad?
18:18:58 <shapr> does that mean you could create monads transformers from any monad?
18:19:10 <shapr> or should I go get some sleep and stop hallucinating? :-)
18:19:55 <Heffalump> arrows are automatically arrow transformers?
18:20:08 <shapr> I'm 99% sure they are
18:20:30 * shapr grabs his copy of Hughes' paper
18:20:53 <engstad> How can arrows be automatic arrow transformers?
18:23:20 <shapr> I could be wrong
18:23:34 <shapr> I think Hughes said that they are in the Arrows paper
18:23:38 <shapr> I'm looking right now
18:27:24 <shapr> In many of these cases, we can generalize from -> to any arrow (possibly constrained), yielding arrow transformers.
18:27:27 <shapr> that's from:
18:27:31 <shapr> http://www.haskell.org/arrows/what.html
18:28:02 <shapr> sounds like you don't always get arrow transformers automatically, just sometimes
18:36:10 <andersca> hey shapr
18:36:36 <shapr> hi andersca 
18:37:13 <shapr> what's up?
18:40:20 <shapr> must be time to sleep
18:41:22 <andersca> yeah
18:41:25 <andersca> I got my ipod today!!
18:41:51 <shapr> cool!
19:11:11 <Pseudonym> I vaguely understand arrows.
19:11:20 * Pseudonym just got back from a visit to the health insurer
19:12:06 <Pseudonym> I don't believe that arroes are automatically arrow transformers.
19:12:13 <Pseudonym> Here's my reasoning:
19:12:25 <Pseudonym> Every monad is an arrow.
19:12:33 <Pseudonym> Not every monad is a monad transformer.  (e.g. IO)
19:12:46 <Pseudonym> Therefore not every arrow is a _monad_ transformer.
19:12:58 <Pseudonym> It follows that it's unlikely that not every arrow is an arrow transformer.
19:17:30 <Pseudonym> Has anyone here used the Haskell ports library?
19:17:35 <Pseudonym> (Apart from Chilli.)
19:17:57 <Pseudonym> No offence to Chilli, but I'd like a less biassed review. :-)
20:17:29 <engstad> Heh, anyone know what "compose" is in Ocaml/SML?
20:18:49 <Smerdyakov> o in SML
20:19:14 <engstad> In Ocaml?
20:29:48 <palomer> omg
20:29:54 <palomer> they're teaching haskell at my school!
20:32:57 * palomer dances
