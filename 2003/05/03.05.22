01:02:24 * _ozone_ dances
01:02:40 <_ozone_> take that, C++
01:03:09 <Marvin--> heh, what now?
01:03:39 <_ozone_> Marvin--: got oo-style overloading going in haskell.  i'm soooo happy
01:04:17 <Marvin--> ah
01:04:34 <Marvin--> with subtyping and everything?
01:04:59 <_ozone_> yeah, 100% typechecked
01:05:07 <Marvin--> cute
01:05:13 <_ozone_> not strictly subtyping per se, but with the same effect, and not much less inconvenient
02:26:43 <thornber> how can a pattern like:
02:26:56 <thornber> foo (d + 1) = bar d
02:27:12 <thornber> work ?
02:27:29 <thornber> is this just hardcoded into the language ?
02:38:21 <Darius> I believe +1 patterns are deprecated, I don't believe they are in the Haskell98 standard.
02:45:45 <Chilli> *pff*
02:45:52 <Chilli> FFI Addendum RC 10 is out
02:59:02 * thornber wonders what $ means
02:59:09 <thornber> eg,  show bd = unlines . map showRank $ reverse [1..8]
03:00:19 <Darius> f $ x = f x; infixr 9 $
03:01:13 <thornber> so it's there to avoid putting brackets round everything (which I have been having to do) ?
03:02:49 <Darius> that and sometimes you want application reified
03:02:52 <Darius> e.g. zipWith ($)
03:03:03 <thornber> cool, thanks
04:17:31 * shapr boings
04:18:40 <shapr> goood morning #haskell!
04:44:42 <Kokko> good morning shapr
04:45:59 <shapr> hi, what's up?
04:56:43 * o3 waddles in
04:56:51 <o3> hallo
04:57:12 <shapr> hiya o3 
05:16:33 <ChilliX> re
05:24:15 * thornber flicks clausens ear
05:24:46 <clausen> gday thornber
05:25:08 <thornber> hi
05:25:19 <clausen> binary search is such a PITA to implement
05:25:50 <thornber> ?
05:26:32 <clausen> go and do it if you don
05:26:37 <clausen> 't believe me
05:26:41 <clausen> (the hard version...
05:27:08 <clausen> where searching for 3 in [0,1,4,4,5] gives you 2, and in [0,1,2,3,3,3,4] gives you 3
05:27:11 <clausen> )
05:29:27 <thornber> clausen: did you see that we've hired the tux2 guy ?
05:29:34 <clausen> really?!
05:29:35 <clausen> who?
05:29:38 <clausen> (who hired?)
05:29:44 <clausen> (you mean dave phillips, right?)
05:29:51 <thornber> LVM team, daniel phillips
05:30:00 <clausen> oops
05:30:03 <clausen> daniel phillips
05:30:05 <clausen> thanks :)
05:30:10 <clausen> ah, cool
05:30:17 * clausen has such a bad memory
05:35:09 * clausen has been reading up on transactions
05:35:21 <clausen> (did I tell you I read "Transaction Processing" by Gray and Reuter?)
05:35:39 * clausen wonders how all this functional stuff compares to Aries / WAL
05:39:23 <shapr> oy
05:40:06 <shapr> hi ChilliX
05:40:13 <ChilliX> Hi sahpr
05:40:19 <shapr> what's up?
05:40:20 <ChilliX> shapr
05:40:56 <ChilliX> Put the hopefully final version of the FFI Addendum out today
05:41:06 <shapr> spiffy
05:41:24 <ChilliX> How about you?
05:41:47 <shapr> Nothing much today.
05:42:13 <shapr> trying to get started on something
05:43:31 <thornber> clausen: you mentioned it, a very expensive book otherwise I'd get it
05:45:18 <clausen> at least read the aries paper
05:45:29 <clausen> or google, say, "write ahead logging"
05:45:40 <clausen> and "wormhole theorem"
05:46:07 <clausen> (naturally, look for academic style material...
05:46:19 <clausen> anything coming from the commercial DB community is likely to be BS)
05:47:55 <thornber> clausen: is the book worth the money ?
05:49:13 <clausen> thornber: perhaps
05:49:20 <clausen> thornber: hard q to answer
05:49:54 <clausen> for example, do you have a handy reference on how to implement semaphores?
05:50:44 <clausen> I suspect all the information is fairly easy to access on the internet, but it's nice having it in one book
05:50:45 <Darius> ChilliX: that would explain why GHC had trouble building
05:50:46 <clausen> it covers a lot of material
05:51:02 <Smerdyakov> What does, clausen?
05:51:12 <ChilliX> Darius: what does?
05:51:21 <clausen> Smerdyakov: "transaction processing" by reuter and gray
05:51:59 <Darius> Just something in hslibs/win32 is importing Foreign.ForeignPtr but expecting the old newForeignPtr
05:52:34 <ChilliX> with old, do you mean the one using Haskell finalizers?
05:52:51 <ChilliX> (that changed quite a while ago)
05:52:52 <Darius> Yes, if you mean IO ()
05:53:10 <ChilliX> ok, that makes sense
05:53:20 <ChilliX> I compiled the thing today, but on Linux
05:53:50 <Darius> hslibs/win32 seems to be the last thing updated when changes happen
05:54:22 <ChilliX> virtually all developers use Linux
05:54:36 <Marvin--> Darius: you're volunteering, I hear :)
05:54:47 <ChilliX> and you just can't regression test win32 on a Linux box
05:55:13 <Marvin--> ah, the sweet sound of volunteering
05:55:20 <ChilliX> also, hslibs stuff has faily low priority, as everything is moved to libraries/ now
05:55:47 <Marvin--> everything? so in the next release of ghc I can expect to not have to use -package at all?
05:55:59 <ChilliX> is libraries/Win32/ not good for you?
05:56:08 <ChilliX> (hslibs is going to die eventually)
05:56:45 <Darius> I haven't noticed any problems (or even it's existence), so I'd say yes.
05:57:00 <ChilliX> Marvin--: don't think libraries has settled yet, but it is getting there
05:57:35 <Darius> ChilliX: I didn't know they finished moving
05:57:37 <Marvin--> there's still no Debug.Observe :-(
05:57:53 <Marvin--> it's still in hslibs/util
05:57:58 <ChilliX> Marvin--: well, you know how this is with the volunteering ;-)
05:58:26 <Marvin--> ChilliX: oh, believe me, I know :)
05:58:32 <ChilliX> hehehe
05:58:37 * Marvin-- is a Debian developer
05:58:57 <Marvin--> the only way to get things done in Debian is to do them
05:58:58 <ChilliX> Which packages are you maintaining?
05:59:24 <Marvin--> in main, just python-pyopenssl
05:59:40 <Marvin--> most of my time is spent on debian-installer
05:59:50 <Marvin--> I guess you could say I'm maintaining a bunch of the d-i packages
06:00:03 <ChilliX> ic
06:00:05 <Marvin--> but "developing" is more it
06:06:51 <Marvin--> hrrrm, I must be making a mistake in my reasoning
06:13:43 <shapr> hoi kosmikus :-)
06:13:46 <shapr> hoe gaat? ;-)
06:14:21 <kosmikus> one moment ...
06:20:35 <kosmikus> weer terug.
06:20:43 <kosmikus> hoi shapr
06:21:12 <kosmikus> I have just decided not to submit the Haskell Workshop paper
06:21:18 <kosmikus> so I am a bit frustrated
06:21:35 <shapr> I can be quite so you can focus :-)
06:21:38 <shapr> er "quiet"
06:22:12 <kosmikus> no need to focus anymore ...
06:22:26 <shapr> oh "not"
06:22:28 * shapr misread
06:23:07 <shapr> kosmikus: do you have a draft of the paper on your site?
06:26:25 <kosmikus> no, not yet
06:26:52 <kosmikus> If I had a draft that I would want to show around, I probably would have managed to submit as well :)
06:27:14 <kosmikus> but I will continue to work on it, sooner or later there will be a paper
06:27:31 <kosmikus> it's joint work with Ralf Hinze, BTW
06:27:47 <shapr> oh, nifty
06:27:53 <Marvin--> kosmikus: :) Koen Claessen and I were about to writ a paper for HW, but we dropped the idea since we'd made some mistakes
06:28:05 <shapr> I feel the peer pressure...
06:28:08 <shapr> I must write a paper!
06:28:14 <ChilliX> hehehe
06:28:15 <shapr> dunno where I'll submit it.. but hey
06:29:47 <Marvin--> shapr: slow down, I haven't written one yet ;)
06:29:54 <shapr> heh
06:29:57 * Marvin-- will try to do that during fall though
06:30:04 <shapr> I wonder what I would write a paper about....
06:30:08 <shapr> um
06:30:22 <shapr> interactive e-learning as applied to teaching functional programming
06:30:28 <shapr> aka "we sit around and chat on IRC"
06:30:56 <Marvin--> use that for sub title :P
06:31:03 * shapr grins
06:31:45 <Marvin--> I wonder if I could cram somethinb publishable out of hws-wp
06:31:50 <Marvin--> something even
06:32:07 <shapr> I think you could
06:33:31 <Marvin--> o3: you wanna write a paper with me? ;)
06:36:46 <shapr> g'day Lilith 
06:37:08 <Lilith> hullo shapr
06:37:41 * shapr mumbles something about "stone the crows"
06:38:03 <shapr> ok, I've been wondering for years... just what does that mean?
06:47:04 * andersca bounces
06:47:12 * shapr blinks
06:47:24 * shapr grumbles
06:48:54 * shapr is confused
07:01:38 <Lilith> geez
07:01:40 <Lilith> that sucks
07:02:06 <shapr> what?
07:02:58 <Lilith> shapr: having thesis fun
07:03:02 <shapr> oh, ok
07:03:06 <shapr> how was your presentation?
07:03:44 * Lilith hides
07:03:49 <shapr> ?
07:03:53 <Lilith> i'm rewriting it now
07:04:01 <shapr> that's good
07:04:38 <Lilith> i can't believe people dont do backups
07:04:45 <shapr> who didn't?
07:04:46 <Lilith> Alessandro Vernet wrote an article and a backend, but he mailed me
07:04:46 <Lilith> he lost the backend due to a computer crash.
07:04:46 <Lilith> http://www.scdi.org/~avernet/projects/jaskell/
07:04:49 <Lilith> ^
07:04:50 <shapr> oh
07:05:02 <shapr> that sucks :-(
07:05:14 <shapr> the moral of that story is... always make backups
07:05:29 <shapr> or at least keep all your sources in a cvs repo on a different drive
07:24:13 <shapr> hi Darius 
07:27:03 <Darius> heya
07:28:27 * Lilith decides looking at ghc internals is as fun to read as linux internals
07:29:07 <Lilith> some of the comments are *so* funny
07:30:24 <Darius> isn't that what open source is all about?  Programmers sharing programmer humor, plus code as commentary.
07:30:46 <shapr> heh
07:30:47 <shapr> maybe so
07:34:34 * shapr switches back to ghc5.04.2 debs
07:39:04 <Darius> Warum?
07:40:02 * Darius is almost done making a bleeding edge GHC
07:43:42 <shapr> I'm gearing up for another lambdabot release
07:43:54 <shapr> I still have 5.05 installed
07:44:56 <ChilliX> shapr: Maybe that's you opportunity for a paper?  Maybe lambdabot contains stuff of interest?
07:45:18 <shapr> hm
07:45:48 <Darius> I would try to get the packet length issues handled first; that will require non-trivial design decisions and potential changes if I'm not mistaken.
07:45:50 <shapr> What would I write about lambdabot?
07:45:58 <shapr> Darius: huh?
07:46:20 <Darius> If you send a long message to lambdabot then only part o
07:46:37 <Darius> If you send a long message to lambdabot then only part of it will be routed to the modules
07:46:45 <shapr> hm
07:46:48 <Darius> and recieving has a similar problem
07:47:09 <shapr> lambdabot needs unit tests.
07:47:24 <shapr> Maybe this would be a good chance to lean QuickCheckM
07:47:37 <Darius> The design decision is whether to raise the abstraction and merge messages, or keep a bit more power (for modules) and handle it some other way, or both.
07:48:09 <shapr> I'd say raise abstraction
07:48:22 <wli> I wouldn't mind an IRC module that parses, say, something resembling more than 0.01% of the protocol.
07:48:28 <ChilliX> shapr: depends what you think were interesting problems in its development
07:48:38 <ChilliX> shapr: interesting programming patterns etc
07:48:43 <wli> and actually notifies the receive side of errors handed back by the server.
07:52:14 <shapr> imho, The most interesting solved problems in lambdabot so far have been calling modules, and per-module state.
07:52:35 <kunphuzil> Oooh.. Qsort in 4 lines.. :)
07:53:00 <shapr> as for unsolved problems, I'd say writing plugins that act as input/output filters
07:53:01 <kunphuzil> haskell is so elegant :)
07:53:40 <shapr> The development process was pretty unusual, many different people involved.
07:55:14 <o3> re
07:55:14 <ChilliX> shapr: The Haskell community lacks good reports about application development
07:55:48 <o3> doh, marvin's gone
07:56:00 <shapr> I've noticed that Haskell lends itself to writing plugin APIs much more than other languages.
07:56:03 <ChilliX> shapr: not so easy to write, as it shouldn't be just a doc fr a program, but generalise experiences such that they are of general interest
07:56:24 <wli> How does one write plugins in Haskell different from in other languages?
07:56:31 <shapr> Though maintaining per-plugin state is harder.
07:57:01 <shapr> wli: referential transparency is wonderful when dealing with plugins
07:58:14 <esap> The ease of writing plugin API depends on what kind of architecture you want for it.
07:58:19 <wli> well I'd need something more specific
07:58:39 <wli> Suppose I wanted something like STREAMS modules, but in userspace.
07:59:06 <shapr> wli: I've written J2EE servlets, mod_python code, and Zope plugins of various flavors.
07:59:22 <wli> shapr: how would that be differentin Haskell than, say, C?
07:59:31 <shapr> What does STREAMS do?
07:59:46 <wli> shapr: stackable message queueing with built-in flow control.
08:00:08 <wli> (and numerous design mistakes floating around the periphery)
08:00:10 <shapr> One thing I like about reftrans is that control flow and execution flow are the same.
08:00:14 <ChilliX> shapr: STREAMS is an old Unix API that nobody uses anymore
08:00:32 <wli> ChilliX: No, it's still in SVR4 derivates
08:01:01 <wli> well +most
08:01:09 * o3 notices wli dodges the question stealthily
08:01:16 <ChilliX> wli: I didn't say that it doesn't exist anymore...
08:01:17 <wli> which question?
08:01:22 <wli> o3: ??
08:01:55 <o3> wli: well, SCO Linux exists, for example ...
08:01:58 <ChilliX> shapr: plugin APIs seem to be a good topic - instant interest
08:02:25 <shapr> if I were writing stackable messaging queueing with built-in flow control in Haskell, I'd use arrows, and something very close to the rpSwitch combinator in Yampa Continued
08:02:27 <o3> ChilliX: if i had more time, i'd really like to integrate the runtime loader stuff into 6.0.  semems like a nice thing to add to a major version release ...
08:02:35 <shapr> o3: YES PLEASE.
08:02:54 <shapr> :-)
08:03:05 <ChilliX> o3: 6.0 has already been forked yesterday
08:03:07 <o3> shapr: in time ... my schedule for the next few months is ... uhh ... "tight", shall we say
08:03:15 <o3> ChilliX: nod, i saw the cvs logs
08:03:24 <shapr> yow, when can we check it out?
08:04:00 <o3> ChilliX: oh well, i guess we'll see in the next few days just how robust TH is ;)
08:04:08 <shapr> maybe the summary of Haskell and plugins is "combinator programming is way powerful"
08:04:13 <ChilliX> o3: :-))
08:04:40 <shapr> point-free programming seems unique to functional languages
08:04:43 <o3> "hi, it seems i can't use more than 1024meg of heap space when in the quotation monad"
08:04:58 <shapr> is there any difference between point-free programming and combinator based programming?
08:05:03 <Darius> o3: hopefully it's MUCH better than a few months ago.
08:05:37 <o3> Darius: i never thought it was bad to begin with (although i only started playing it intensively a few weeks ago)
08:05:54 <o3> but they've certainly made some impressive advances even in the last few weeks
08:05:55 <shapr> I'd like to contribute QuickCheck tests to GHC :-)
08:06:01 <shapr> y0 syntax-laptop
08:06:12 <esap> I think if the plugin-API would like to use an OO layered design, it might be somewhat hard to implement in Haskell [you need to wrap it in some messaging stuff]
08:06:31 <shapr> esap: can you describe a layered design?
08:06:39 <shapr> I'm still not clear on that.
08:07:02 <ChilliX> shapr: I guess you could say point-free and combinator-based is the same
08:07:11 <syntax-laptop> howdy shapr
08:07:17 <Darius> o3: it mostly worked before, people just kept falling into holes, hopefully most of those have been handled.
08:07:23 <esap> shapr: yes. It's one where interface provider does not know anything about the interface user [and usually you pass _changes_ to some data in the other side of the interface].
08:07:57 <shapr> esap: how is that different from monadic calls?
08:09:07 <esap> shapr: basically it's very similar. The only thing is, monads fix one of the layers [the upper one] to 'values'.
08:09:40 <o3> Darius: nod, i'm going to be pushing it hard over the weekend
08:09:51 <esap> shapr: but otherwise, monads are it.
08:10:00 <shapr> hm, how do I dial the US from .se?
08:10:10 * shapr has forgotten the secret international code
08:10:27 <opet> it's 1 I think
08:10:39 <shapr> opet: what's before that?
08:10:41 <opet> oh.. from .se
08:10:49 <opet> no idea, then. sorry
08:11:08 <shapr> fooey
08:11:08 * opet should read and understand instead of just reading
08:11:58 <Darius> opet you could just understand without the reading, all you need is the understanding
08:13:11 <opet> Darius: then start wearing an orange robe and go live on the top of a mountain? :)
08:13:45 <esap> shapr: basically, when you use layered design, you will get concepts such as "object references" and "callback notifications" and "commands". If you use functional design, you get concepts such as "sending/receiving data" and "functions" and "combining functions".
08:15:46 <esap> shapr: it's basically OO vs functional when you consider the resulting system architecture.
08:17:42 <esap> shapr: the hard part is that in reality, both of them are actually different views to the "same" system.
08:19:46 <shapr> esap: I'll think about that, it's not immediately obvious to me
08:20:06 <esap> shapr: which part is not obvious?
08:20:17 <shapr> that they're the same system
08:20:54 <esap> shapr: ok. I'll explain.
08:21:02 * shapr listens attentively
08:21:05 <Darius> Hmm, my impression of most things called layered design is that they are effectively (approximations of) (E)DSLs.
08:22:22 <esap> shapr: Consider a component in the system, say 'x'. You can have that x has some inputs and outputs. Then its interface would be x : input -> output.
08:22:28 <shapr> yah
08:23:42 <esap> shapr: now consider the same component from another point of view. You want 'x', as part of processing its input, would like to cause some effects to its environment. So it sends some commands to the environment. You could model this as "x : input -> IO output". Now x can also perform I/O actions.
08:24:09 <shapr> ok
08:25:19 <esap> shapr: However, if 'x' is a component, then it should also provide some means of providing 'service' to its users, which would allow its users to control _how_ the component transforms its input to output.
08:25:34 <shapr> ok
08:26:53 <esap> shapr: To do this, you can extend the interface to something like: x : Request input -> IO output. This allows you to give the input wrapped in "commands from upper layer" that also describe _what_ to do with the input.
08:28:09 <esap> shapr: of course, you might want to separate the "commands" and the input. For example, the input might be in the database, and the output goes back to the database, you get an interface such as x : Request () -> IO ().
08:28:57 <shapr> I see
08:29:53 <esap> shapr: or you can mix all of this. Different choices for what to include in the interface [e.g. requests, input, commands, output] will produce different designs.
08:31:06 <esap> shapr: For example, I would expect that a "stateful variable" has type "StateReq () -> StateEffect ()".
08:32:16 <shapr> ok
08:32:18 <Darius> The EDSL way is simply to provide different functions for each request
08:32:59 <esap> shapr: Actually, correction: StateReq a -> StateEffect a, where a is the type of data stored.
08:33:04 <shapr> and combinators let you change the 'how' of transforming
08:33:34 <shapr> FP sounds a lot simpler and easier... more straightforward.
08:33:48 <esap> shapr: combinators can be used to build larger components from smaller components (irrespectively of which interfaces are exposed)
08:33:59 <shapr> OOP sounds like a quick hack from this viewpoint :-)
08:35:02 <esap> shapr: well OOP is just the viewpoint that you should expose requests and commands, but not the data manipulated.
08:35:26 <shapr> doesn't AFRP follow some of that as well?
08:35:38 <shapr> admittedly, they do it to escape the curse of space leaks..
08:36:08 <shapr> specifically, the Yampa stuff gets rid of first-class signals
08:36:10 <hdaume> morning folks
08:36:16 <shapr> only allows first-class signal functions
08:36:18 <shapr> hi hal
08:36:18 <o3> hi hal
08:36:23 <hdaume> shapr: haha, i beat you!
08:36:27 <shapr> dang :-)
08:36:31 * shapr grins
08:37:17 <esap> shapr: well I guess it has many of the same principles. I'm not entirely sure the distinction between "requests", "commands" and "data sent between components" has been properly made though.
08:37:31 <shapr> made in what sense?
08:37:45 <shapr> in the OOP or combinator paradigms?
08:37:48 <shapr> in my head? :-)
08:38:47 <esap> shapr: in combinator paradigms. I think combinator paradigms sometimes only consider only passing data between components, but do not consider changes to data.
08:39:20 <esap> shapr: but of course, some combinator things choose the other point of view and only consider changes, also avoiding the problem.
08:39:36 <shapr> yah, darcs does that.
08:41:08 <esap> shapr: I think the good approach is to consider both, and deal with the complexity.
08:42:00 <esap> shapr: only then can you do "balanced" design and choose the point of view most appropriate for each situation.
08:42:50 <shapr> sounds like you're suggesting two flavors of combinators, those that modify data, and those that modify other combinators
08:43:07 <Marvin--> "modify"?
08:43:21 <o3> ahoy marvin
08:43:30 <o3> you were saying something about a paper? :)
08:43:33 <esap> I think the idea is to distinguish between "changes" and "data". Of course, you might also consider "changes to changes" etc.
08:43:40 <shapr> yah, transform the data, or transform the way another combinator transforms the data
08:44:01 <Marvin--> o3: yeah, about the dynamic loading stuff
08:44:24 <shapr> I want another hws-wp release!
08:44:37 <Marvin--> bleh
08:44:43 <o3> Marvin--: i'd love to, but no hope in the next few months.  too busy with thesis right now
08:45:02 <Marvin--> o3: heck, I'm too busy too, with my own degree project
08:45:03 <esap> shapr: actually, it's more like each combinator has two kinds of interfaces, one that allows you to modify the way it changes data, and one that allows you to put in data.
08:45:21 <o3> Marvin--: hey, maybe shapr would like to write one ... ;)
08:45:31 <esap> shapr: and of course, similar distinction with output vs. commands.
08:45:44 <shapr> o3: I'm busy with my antithesis.
08:45:46 <shapr> :-P
08:46:44 <shapr> actually the common theme of plugin APIs is interesting
08:46:54 <shapr> I think I could write a series of paper about the runtime loader
08:47:03 <shapr> especially exploring hot loading of code.
08:48:32 <esap> shapr: but actually, if I interpret types with kind * -> * as "changes" and types with kind "*" as 'data', I guess you can quite simply interpret these things in Haskell.
08:49:11 <esap> shapr: of course, you can map this intepretation to other kinds as well.
08:49:22 <shapr> so commands are (* -> *) -> (* -> *) ?
08:49:32 <esap> shapr: no, that would be "changes to commands".
08:49:36 <shapr> oh
08:49:54 <shapr> is there any difference between the kind of requests and the kind of commands?
08:50:30 <esap> shapr: no, it's just whether they're "input" or "output" in relation to the component being considered.
08:50:59 <esap> shapr: so both commands and requests have kind * -> *.
08:51:06 <shapr> a request is input, and a command is output?
08:51:11 <esap> shapr: right.
08:51:21 <shapr> ah
08:51:22 <shapr> I see
08:53:30 <esap> shapr: So in a sense, monads capture "commands made by the component" [at least the way it's normally used, i.e. f : a -> IO b], but not requests.
08:54:23 <shapr> a request that specifies "how" instead of giving input is a higher order request
08:54:38 <shapr> right! aha!
08:54:44 <shapr> and arrows capture *both* of those!
08:54:54 * shapr bounces with realization
08:55:11 <esap> shapr: Arrows capture _hiding_ both requests and commands, and showing only input and output in the interface.
08:55:59 <esap> shapr: you need something like   Arrow a => a (Request input) (Command output)  to capture all of it.
08:56:00 <shapr> monads just do that for commands
08:57:32 <esap> shapr: or actually, to abstract it, something like (Arrow a, Request req, Command cmd, Input inp, Output out) => a (req inp) (cmd out).
08:58:16 <shapr> still, how do you model the state associated with an instance?
08:58:24 <shapr> where does it fit in there?
08:59:36 <esap> shapr: well the "state" can be modelled as "hidden input and hidden output". [similarly like arrows capture "hidden requests and commands".
08:59:47 <shapr> ah
09:00:18 <shapr> sounds like you already have the prototype based programming there
09:02:22 <elmex> shapr: i still don't really was able to grab the concept of StateT and Monads :(((
09:02:23 <esap> shapr: yes, I guess it captures quite many things, it is essentially the combination of OO and functional programning. [It doesn't strictly capture logic programming, but I already know how to do that as well :-) ]
09:03:00 <wli> logic programming can be nice at times
09:03:20 <esap> Logic programming can be seen as a type system for this thing.
09:04:05 <esap> ... where you never need to give the program itself.
09:04:07 <Smerdyakov> elmex, monads are just algebraic structures. Are you familiar with abstract algebra?
09:04:15 <Marvin--> well, I'm off to eat some sushi
09:04:18 <shapr> elmex: what parts do you understand so far?
09:04:34 <elmex> Smerdyakov: i'm just a simple young unexperienced hobby programmer, who doesn't really know that much math
09:05:13 <shapr> me too!
09:05:19 <shapr> I'm just a hobby programmer
09:05:20 <elmex> shapr: hmm, good question. i guess, i were able to grab some kind of clue .. but i'm not sure to express it
09:05:46 <Smerdyakov> elmex, well, the things that matter with monads are this: 1) They are thought of us "carrying" some types. 2) They have some atomic values and operators for combining them. 3) The combination operators are order-sensitive.
09:05:51 <shapr> elmex: I've discovered I often learn more by trying to express what I know to others.
09:06:01 <shapr> elmex: it helps me organize and integrate what I've learned.
09:06:15 <Smerdyakov> I think that's really it. There is nothing in them that allows you to "do IO" or "have state." That is all implemented by libraries written in non-Haskell languages and interfaced with Haskell.
09:06:17 <elmex> shapr: indeed
09:07:06 <elmex> hmm
09:07:20 <Smerdyakov> elmex, shapr, you might like http://www.hprog.org/ and #hprog :-)
09:07:37 <elmex> Smerdyakov: what about that?
09:08:28 <Smerdyakov> It's a new group for hobbyist programmers, and you said you are one.
09:08:44 <elmex> Smerdyakov: nah... more or less. well, i earn already some money
09:09:03 <Smerdyakov> That doesn't disqualify you. :-)
09:09:22 <elmex> Smerdyakov: i don't feel myself 'belonging' to some group or anything
09:10:03 <elmex> shapr: i guess i will readMonads for the Working Haskell Programmer another time
09:10:09 <shapr> ok
09:10:24 <shapr> elmex: if I had more time I'd ask you to explain to me what you do understand about monads
09:10:26 <elmex> and try to stick something together myself
09:10:40 <shapr> my attempts to explain monads to my fiancee were enlightening to both of us...
09:10:58 <shapr> though she realized she *really* didn't care =)
09:11:08 <elmex> shapr: yes, thanks. thats kind, but i don't want to steal your time ;) it's better i figure out all that stuff myself... hey.. i could try to explain it to my plant
09:11:22 <shapr> heh
09:11:38 <elmex> but i somehow feel dump talking to flowers
09:11:42 <shapr> I still don't completely understand monads myself, so it wouldn't steal my time.
09:11:50 <shapr> just that I have an appointment with a friend...
09:11:58 <Smerdyakov> elmex, what do you mean by "i don't feel myself 'belonging' to some group or anything"?
09:11:59 <elmex> shapr: no problem ;)
09:12:14 <elmex> Smerdyakov: hmm... was that english so broken?
09:12:28 <elmex> Smerdyakov: i mean, that i don't belong to some group
09:13:06 <Lilith> Smerdyakov: v. cute
09:13:46 <Smerdyakov> Lilith, eh?
09:13:52 <Smerdyakov> elmex, OK, but you can....
09:13:59 <Lilith> Smerdyakov: hprog
09:14:15 <Smerdyakov> Lilith, well, "cute" isn't the intended effect, but I guess it's better than "abominable."
12:04:51 <KoKkO> hullo
12:24:27 <pesco> hey ho
12:25:32 <Smerdyakov> I'm no ho, you ho.
12:25:48 <Riastradh> Ho yo!
12:25:54 <Riastradh> Yo ho ho!
12:26:12 <pesco> moo. moo? moomoo!
12:29:35 <pesco> shapr, you there?
12:31:59 <Smerdyakov> pesco, do you have a shapr-specific question, or do you just think he's the only one who wants to help you? =)
12:32:21 <pesco> Smerdyakov: Hey, are you trying to tease me?
12:32:30 <pesco> ;-)
12:32:45 <pesco> I wanted to ask him for his email-address. :)
12:33:27 <Smerdyakov> Oh
12:33:30 <Smerdyakov> Never mind, then
14:58:45 <Igloo> Eeek, 6.0 forked
14:59:58 <Igloo> Bah, and without the renaming changes, although there is apparently come controversy there anyway
15:00:40 <Igloo> Ah, it got merged in
15:46:18 <larsl> Can't you use '=' in ghci? When I type 'square x = x * x' I get the error message '<interactive>:1: parse error on input `=''.
15:46:59 <Igloo> let f = ...
15:47:29 <Igloo> But you get more flexibility if you load a .hs in ghci
15:47:35 <larsl> OK.
15:49:24 <larsl> What about 'data' statements?
15:51:19 <Igloo> Use a .hs
15:52:18 <Igloo> Line by line interpretation of a statically typed declarative language is not an easy model to work with
17:12:47 <Dark-Star> I was just wondering: Can I program _every_ possible list operation by only using foldr with a 'suitable' operator?
17:13:23 <Smerdyakov> That question is not phrased precisely enough.
17:13:41 <Smerdyakov> You can code every primitive recursive list operation, which is really just fold anyway :-)
17:13:52 <Dark-Star> hmmm...
17:14:14 <Pseudonym> Which means you can trivially write every primitive recursive function.
17:14:29 <Pseudonym> Using some combination of top-level functions each of which uses "foldr".
17:14:56 <Pseudonym> Since you asked, though, no you can't.
17:15:30 <Pseudonym> zipWith, for example.
17:15:52 <Pseudonym> You could, I suppose shoehorn foldr into there somewhere.
17:16:03 <Pseudonym> I think scanl might have trouble too.
17:16:11 <Dark-Star> well, I would actually try it if it wasn't that late here already ;-)
17:16:24 <Dark-Star> what does scanl do?
17:16:50 <Dark-Star> it's not in the prelude, is it? or at least it's not in the reference I use
17:17:50 <Pseudonym> I think it's in the List module.
17:18:18 <Dark-Star> argh it's far too late for me, when I wake up tomorrow I'm sure all these questions aill clarify themselves, I just feared I can't sleep until I got them answered ;-)
17:18:26 <Dark-Star> s/aill/will
17:18:28 <Pseudonym> Let me put it this way:
17:18:29 <Pseudonym> scanl (*) 1 [1..10]
17:18:41 <Pseudonym> That produces [0!, 1! .. 10!]
17:18:47 <Pseudonym> ! is factorial
17:19:00 <Pseudonym> Anyway, go sleep.
17:19:18 <Smerdyakov> Is that an order?
17:19:21 <Dark-Star> hmm I bet I could do that with foldl ... I'll think about it tomorrow :)
17:19:36 <Dark-Star> g'night
17:19:47 <Pseudonym> Nah, it's a friendly suggestion.
17:19:52 <Pseudonym> He'd dropped enough hints.
17:20:08 <Smerdyakov> It's only polite to pick them up for him.
17:20:09 <Pseudonym> Or, perhaps more accurately, it's an invitation to end the conversation.
17:20:20 <Pseudonym> Since I was just talking away.
19:57:51 <steveh> Hello!
20:39:29 <Pseudonym> @yow
20:39:29 <lambdabot> There's a SALE on STRETCH SOCKS down at the "7-11"!!
20:41:30 <alanl> hello
20:41:40 * alanl bored
20:42:15 <Pseudonym> G'day.
20:42:19 <Pseudonym> Want something to do?
20:42:24 <alanl>  yes
20:42:34 <Pseudonym> What sort of something?
20:42:46 <Pseudonym> Haskell, I assume, otherwise you wouldn't be here.
20:43:09 <alanl> well I'm in a haskell consult and no one wants to see me :-(
20:43:15 <Pseudonym> Ah.
20:43:37 <Pseudonym> Want me to ask an undergraduate questin, then?
20:43:43 <alanl> LOL
20:43:49 <Pseudonym> How do I do an assignment in Haskell?
20:44:08 <Pseudonym> :-)
20:44:11 <alanl> well I'll probably get those questions next week (task is due on saturday
20:44:21 <lament> Pseudonym: haha
20:44:45 <alanl> <alanl> well I'll probably get those questions next week (task is due on saturday
20:44:46 <alanl> <lament> Pseudonym: haha
20:44:46 <alanl>  [01:44pm][alanl(+iw) (zZzZ 0)][Mail: 1253] [#haskell(+n)]                                   
20:44:46 <alanl>  [Lag  0] [O/0 N/50 I/0 V/0 F/0]                                                  [U:a:S:b:h]
20:44:46 <alanl> [#haskell] 
20:45:07 <alanl> www.cse.unsw.edu.au/~cs1711/project/spec.html
20:45:12 <Pseudonym> If you want something to do, we need an implementation of this:
20:45:13 <Pseudonym> www.cs.uu.nl/~johanj/publications/TheWeb.ps
20:45:20 <Pseudonym> It's an interesting paper, too.
20:45:38 <Pseudonym> Oh, I remember flicking through this.
20:45:58 <alanl> well i'm going to have to automark some of this...
20:49:19 <alanl> what do you intend to use the zipper thinge for?
20:50:35 <Pseudonym> Nothing specific.  It looks pretty useful for the hierarchical libraries, though.
20:51:11 <Pseudonym> Besides, it'll give you a paper to read while nobody shows up.
20:51:30 <alanl> hehehee...well its almost over :-)
20:53:31 <alanl> so what do you do for a living....are you employed by a uni?
20:53:39 <Pseudonym> Sort of.
20:53:44 <Pseudonym> Technically I am.
20:54:38 <alanl> so are you a researcher?
20:54:52 <Pseudonym> No, developer.
20:55:13 <Pseudonym> I actually work on something that used to be a research project but is now a commercial product.
20:55:32 <alanl> can you name this product?
20:55:45 <Pseudonym> It's TeraText, which you probaly won't have heard of.
20:55:54 <Pseudonym> http://www.teratext.com.au/
20:57:21 <alanl> so essentially its a bad ass indexing system?
20:57:26 <Pseudonym> Kind of.
20:57:32 <Pseudonym> It's a database system.
20:57:43 <Pseudonym> But it's optimised for text.
20:58:48 <Pseudonym> And there's no Haskell in it.
20:59:10 <alanl> I'm sorta interested in searching but I have no idea where to start...got any good books/urls?
20:59:23 <Pseudonym> Text searching?
20:59:34 <alanl> uh huh...
20:59:39 <Pseudonym> You want to read "Managing Gigabytes" by Alistair Moffat, Tim Bell and... uhm...
20:59:44 <Pseudonym> Who's the third?
20:59:50 <Pseudonym> Oh, Ian Cleary.
21:00:20 <Pseudonym> Or...
21:00:29 <Pseudonym> No, Ian Witten.
21:00:30 <alanl> I assume linear algebra is used a lot in the new funky seacrhing algorithms?
21:00:45 <Pseudonym> Only in ranking, I think.
21:01:05 <Pseudonym> Note that the title, "Managing Gigabytes", is WAY out of date.
21:01:10 <Pseudonym> Gigabytes are easy.
21:01:43 <alanl> I know....I have 1/4 terabyte at home....plus way too many cds
21:02:06 <Pseudonym> Well we're talking about lots of text that you want to index and search.
21:02:17 <Pseudonym> I don't think you have 1/4 Tb of plain text.
21:03:02 <alanl> no :-)...but I am interested in some sort of file management system
21:03:43 <Pseudonym> Well what we do is specifically about indexing text, rather than just files.
21:04:43 <alanl> ah. but I'll come across gigs and gigs of text soon....my major is in bioinformatics
21:04:44 <Pseudonym> More like Google, only slower and more flexible.
21:05:00 <Pseudonym> Ah, there you go.
21:05:13 <Pseudonym> Buy our product. :-)
21:05:43 <alanl> er....have a cripped version so i can learn it and sell it to my future employers
21:06:09 <Pseudonym> Well you can always ask for an evaluation licence.
21:06:42 <Pseudonym> What will your gigs of text look like?
21:06:54 <Pseudonym> Just genetic data, or documents (e.g. SGML/XML)?
21:07:18 <alanl> both....but probably papers more
21:08:14 <alanl> anyway...I'm off for an hour....
21:08:23 <Pseudonym> OK, bye.
22:01:50 <ozone> hi
22:07:55 <Pseudonym> G'day.
22:13:18 <alanl> i'm back
22:17:23 <Pseudonym> Lucky you.
22:17:31 * Pseudonym is glad it's Friday
22:18:48 <alanl> are you more into perl or python?
22:18:54 <Pseudonym> Perl.
22:19:10 <Pseudonym> I start learning Python every few months then forget about it by accident.
22:22:21 <alanl____> i assume teratext is coded in something faster like C right+?
22:22:31 <Pseudonym> C++
22:22:41 <Pseudonym> It would be pretty unmanagable if it were written in C.
22:22:54 <Pseudonym> Oh, plus there's a proprietary scripting engine, called Ace.
22:23:23 <Pseudonym> Because all sufficiently large programs have some kind of scripting system.
22:23:34 <alanl____> what sorta hardware do i need to run it?
22:24:44 <Pseudonym> It'll run in IA32 under Win2k.
22:24:54 <Pseudonym> Or sparc under Solaris 9.
22:25:08 <Pseudonym> Or Itanium under Linux, though we haven't officially shipped that yet.
22:25:18 <Pseudonym> Because we found a bug in the kernel.
22:25:51 <Pseudonym> You need fast disk and a lot of RAM.
22:26:54 <Pseudonym> At least you need this for demanding applications.
22:27:58 <Pseudonym> Generally, if you have $30k to spend on a software licence, you buy a very grunty machine to run it on.
22:31:25 <Pseudonym> Oh, and we've just discovered some unfortunate things about hyperthreading.
22:31:43 <Pseudonym> Some operations are sped up by a factor of 2.  Others are slowed down by a factor of 20.
22:31:47 <Pseudonym> We're not quite sure why.
22:31:52 <alanl____> you mean its not what it knocked up to be?
22:32:00 <Pseudonym> Not for our application.
22:32:21 <Pseudonym> We think it might have something to do with the two virtual CPUs sharing an L1 cache.
22:32:29 <Pseudonym> Or something to do with TLB contention, perhaps.
22:33:30 <Pseudonym> You know, the TLB was probably the biggest mistake in the IA32 line.
22:34:01 <Pseudonym> A whole generation of people are growing up thinking that context switches are slow.
22:34:58 <wli> There are so many mistkes in the ia32 line the TLB castration is a drop in the bucket.
22:35:18 <Pseudonym> Well true.
22:35:28 <Pseudonym> Not redesigning the FPU is probably the worst sin.
22:35:56 <wli> It's death by a thousand cuts. No matter which design mistake you pick it's not going to make an overwhelming difference.
22:36:23 <Pseudonym> I think that the TLB thing is what makes the Intel chip completely unsuitable for modern OS designs.
22:36:47 <Pseudonym> Requiring a TLB flush on every address space change effectively kills IPC performance.
22:36:56 <Pseudonym> If you have good IPC performance, you gain a lot.
22:37:14 <Pseudonym> Personal opinion.
22:37:23 <Pseudonym> I can live with a lot of the IA32 peculiarities.
22:37:39 <Pseudonym> Yeah, there aren't enough registers, but that's not a huge thing IMO.
22:37:57 <Pseudonym> Fast L1 cache mitigates that.
22:38:01 <wli> actually it is a huge thing
22:38:06 <wli> (literally)
22:38:34 <wli> register spill/restore bloats the instruction stream, which heavily pressures its already grossly overweight instruction decoder.
22:39:09 <wli> it's something like 15%-30% of all instructions being register spill and restore.
22:39:26 <Pseudonym> Really?  Even with the complex addressing modes?
22:39:37 <Pseudonym> Surely you don't need to "restore" as such when you have them.
22:39:38 <wli> yes, even with the complex addressing modes.
22:40:10 <wli> you can only do single indirections, so every pointer must be loaded to be dereferenced
22:40:17 <Pseudonym> True.
22:40:38 <Pseudonym> I suspect that it might depend on your code.
22:40:47 <wli> you also can't use memory as indices, so you have to load those, too.
22:40:50 <Pseudonym> Heavy integer stuff will fare worse than, say, structure manipulation.
22:41:15 <Pseudonym> Since structure manipulation is mostly pointer chasing.
22:42:10 <alanl____> are the new 800FSB p4s worth the extra molah?
22:42:47 <Pseudonym> No idea.
22:42:55 <Pseudonym> Probably depends what you're trying to do.
22:44:25 <Pseudonym> I reckon Compaq is waiting for IA64 to die and will then bring out shiny new Alphas.
22:44:30 <Pseudonym> That's my prediction for th eweek.
22:48:59 <ozone> llo lil
22:49:15 <Lilith> lo o3
22:49:39 <Pseudonym> G'day.
22:51:57 <Lilith> hullo Pseudonym
22:53:46 <Pseudonym> I wonder if I slept for a while anyone in neighbouring cubicles would notice.
22:54:23 <Lilith> depends on how you sleep
22:54:36 <Lilith> if you do it the thinker's style, it might be somewhat harder to stop
22:54:42 <Lilith> s/stop/spot
22:55:09 <Pseudonym> That's an idea.
22:56:47 <Pseudonym> Nope, can't sleep that way.
22:57:34 * Lilith hands Pseudonym a jug of coffee
22:57:46 <Pseudonym> Please!  I'd love some decent coffee.
22:58:01 <Pseudonym> I can't believe I work two blocks from Lygon St but all we have here is Nescafe.
22:58:32 <Lilith> do yourself a favour and buy some decent coffee :-)
22:59:25 <ozone> now that's a damn good idea
22:59:40 <Pseudonym> I think someone around here has some Moccona, which isn't _that_ bad, but it's decaf.
22:59:48 <Pseudonym> So what's the point?
22:59:54 * Pseudonym sighs
22:59:56 <ozone> hmm
23:00:14 <ozone> generic question: is having hundreds of instances of a typeclass going to slow things down dramatically?
23:00:23 <Pseudonym> It shouldn't.
23:00:56 <Pseudonym> There's the normal kinds of effect you get from code bloat (e.g. increased time starting the executable), but apart from that, it should be fine.
23:01:19 <Pseudonym> Someone actually has some decaf cheap instant.  Now there's REALLY no point.
23:01:27 <ozone> Pseudonym: hmm, okay, thanks
23:01:42 <Pseudonym> It can't be for the taste and can't be for the caffeine.
23:01:59 <ozone> skim decaf latte?
23:02:24 <Pseudonym> At least a well-made skim decaf latte would taste nice.
23:03:14 * ozone gives up on typeclass problem until Chilli gets back and looks at the FFI marshalling library instead
23:03:59 * Lilith wonders if i can ask stupid questions here
23:04:00 <Lilith> hmm
23:04:09 <Lilith> what do objects look like on the heap?
23:04:50 <ozone> i used to know this
23:05:12 <Lilith> so they've got a few fields
23:05:28 <Lilith> but beyond that i don't know
23:05:47 <Pseudonym> In GHC?
23:05:55 <Lilith> Pseudonym: yes
23:06:06 <Pseudonym> Have you read the STG machine paper?
23:06:08 <ozone> Lilith: have you read the simonpj paper "Implementing functional langauges?"
23:06:13 <ozone> and the STG paper, as Pseudonym said
23:06:26 <Lilith> i'm re-reading them now
23:06:32 <Pseudonym> There you go. :-)
23:06:54 <Pseudonym> An object is pretty much a word which points to the object's meta-data followed by all of the arguments.
23:07:10 <Pseudonym> Boxed arguments are kept together as are unboxed arguments.
23:07:27 <Pseudonym> Can't remember which order they appear in.
23:08:45 <Pseudonym> The metadata is the type (i.e. constructor, closure, thunk etc).
23:08:52 <Pseudonym> Plus layout information for the GC.
23:08:57 <Pseudonym> Plus the code entry point.
23:09:00 <Pseudonym> I think that's all.
23:09:02 * Lilith nods
23:09:12 <Lilith> i'm just drawing pictures now for my slides
23:09:15 * Pseudonym nods
23:09:20 <Pseudonym> There's a good one in the eval/apply paper.
23:09:32 <Lilith> Pseudonym: ok. thanks
23:12:05 <wli> The microscopic register file is a huge problem. The addressing modes are really mostly crap. They don't mitigate the register pressure significantly.
23:13:29 <wli> $ wc -l disasm.new
23:13:30 <wli>      80 disasm.new
23:13:30 <wli> $ grep mov disasm.new| wc -l
23:13:30 <wli>      37
23:13:50 <wli> 46.25% spill/restore
23:14:03 <Pseudonym> What does that program do?
23:14:19 <wli> initializes PCI config space for Adaptec SCSI controllers.
23:14:46 <Pseudonym> I would think that's mostly moving data around to satisfy the BIOS or I/O registers.
23:15:10 <wli> those data movements are all done with procedure calls
23:15:14 <Pseudonym> In which case, many of those "mov" instructions may not be due to spill/restore.
23:15:18 <Pseudonym> Oh, OK.
23:15:29 <Pseudonym> So it's actually marshalling procedure call arguments, mostly?
23:15:33 <wli> they're actually 2 or 3 levels down the stack
23:15:38 <Pseudonym> Or is it saving registers across calls?
23:16:00 <wli> most of it is calculating values that go into a data structure
23:16:15 <wli> and some complex if () statements
23:16:31 <Pseudonym> And what compiler compiled it?
23:16:31 <wli> actually mostly one hugely complex if () condition
23:16:36 <wli> gcc
23:16:41 * Pseudonym nods
23:16:48 <Pseudonym> GCC actually performs poorly on small basic blocks.
23:16:58 <Pseudonym> The register allocator is mostly crap.
23:17:18 <Pseudonym> (Coalescing?  What coalescing?)
23:17:40 <wli> the register allocator can't be fixed. The good algorithms are all patented.
23:17:57 <Pseudonym> I think Chaitin's patent has expired, hasn't it?
23:18:03 <Pseudonym> The paper was published in 1983.
23:18:18 <Pseudonym> And I don't think Appel patented his algorithm.
23:18:35 <wli> neither of those are useful for ia32 (though there is another by Appel that _could_ be)
23:19:01 <Pseudonym> I thought the conservative coalescing algorithm might do well.
23:19:12 <Pseudonym> You generate moves to/from special registers and let the allocator do the rest.
23:19:41 <Pseudonym> Admittedly, having to deal with index registers as a special class would be a royal pain.
23:20:16 <wli> it doesn't do that well, no
23:20:30 <wli> He has another algorithm based on integer linear programming that does much better.
23:20:35 <Pseudonym> OK.  Someone is implementing a colouring allocator for GCC.
23:20:38 <Pseudonym> Oh, interesting.
23:20:47 <Pseudonym> Do you have a reference?
23:21:28 <wli> Incoming DCC
23:21:53 <Pseudonym> Did I do that correctly?
23:22:00 <Pseudonym> DCC is advanced IRC.
23:22:22 <wli> yes it's en route to you
23:22:36 <Pseudonym> OK, cool.
23:22:42 <Pseudonym> Thanks.
23:25:22 <Pseudonym> It's kind of interesting how register allocation has changed.
23:25:34 <Pseudonym> First it was treated as a stack problem, then someone noticed that it's actually NP-hard.
23:25:43 <Pseudonym> So then it became a napsack problem.
23:25:51 <Pseudonym> Then it was a graph colouring problem.
23:25:54 <Pseudonym> Now it's an ILP problem.
23:26:34 <wli> that only addresses a subset of the issues
23:26:51 <wli> the interactions with instruction scheduling aren't taken care of there
23:27:08 <Pseudonym> True.
23:27:14 <wli> there are integrated register allocation and instruction scheduling algorithms
23:27:31 <wli> but they're not capable of handling all the metrics
23:27:35 * Pseudonym nods
23:27:52 <Pseudonym> This is a corollary of the full employment theorem for compiler writers, I think.
23:29:10 <wli> There's a difference between full optimality being unattainable and the performance metric not even being quantifiable.
23:29:16 <Pseudonym> Yes.
23:29:32 <Pseudonym> You know, there's a problem I needed to solve recently which I discovered hasn't really been looked at.
23:29:48 <Pseudonym> Which is register allocation on a machine with an unlimited number of registers.
23:30:19 <Pseudonym> This turns up, for example, when you deal with spilled data.  OK, you've spilled your registers, now how do you map the spill locations to memory?
23:30:37 <Pseudonym> Ideally you want to minimise the amount of memory you use.
23:30:44 <Pseudonym> But you also want to minimise the amount of movement.
23:30:59 <Pseudonym> It also turns up in generating code for abstract VMs.
23:31:47 <Pseudonym> The problem was for a SIMD virtual machine.
23:32:10 <Pseudonym> Because you have multiple data, you want to make each processing element's data as small as possible.
23:32:37 <Pseudonym> One extra word may result in a lot of extra memory use/cache missing if you are running "massively" parallel.
23:33:36 <Pseudonym> Anyway, it turns out that nobody has looked at k-colouring if k is not limited.
23:34:17 <Pseudonym> If someone wants a good postgrad project, there's one there.
23:35:30 <wli> well there's the obvious minimization algorithm
23:35:57 <wli> try to k-color for each k starting from 1
23:36:01 * Pseudonym nods
23:36:03 <wli> hand back the first one you ifnd
23:36:05 <wli> find
23:36:05 <Pseudonym> Or you could binary-search.
23:36:36 <Pseudonym> Start with 1, double, then when you find a colouring, binary search the interval that you haven't looked at.
23:36:42 <wli> well you'd need to start by doubling
23:36:45 <Pseudonym> Right.
23:36:46 <wli> yeah
23:36:54 <Pseudonym> Or start with a reasonable value of k, like 32.
23:37:08 <Pseudonym> That's not very efficient, though.
23:37:22 <wli> well
23:37:24 <Pseudonym> You end up solving the same subproblems over and over again.
23:37:52 <wli> I wonder if it could be translated to a 0-1 integer linear programming problem
23:37:58 <Pseudonym> Maybe.
23:38:41 <wli> well the objective function would be obvious
23:39:45 <Pseudonym> I think it's also kind of like a bin packing problem.
23:39:49 <Pseudonym> Minimise the number of bins.
23:40:13 <Pseudonym> Coalescing really wins for the application I was thinking of.
23:40:28 <Pseudonym> Because a move operation means a lot of cycles get burned.
23:41:03 <Pseudonym> So I think you have to use something that does a lot of coalescing.
23:41:12 <Pseudonym> Actually, the language this implements doesn't have recursion, either.
23:41:16 <Pseudonym> All calls are inlined.
23:41:29 <Pseudonym> So there are a lot of moves around the site of a function/procedure call.
23:42:53 <wli> well it is bin-packing and knapsack and so on
23:43:11 <wli> translating it to something analyzable helps
23:44:51 * Pseudonym nods
23:45:03 <Pseudonym> That's what NP-hard means!
