03:13:32 <jak> whee: I like to think of the Monad types as "Monad actions" or "Monad computations". That way it makes sense to build up a complex Writer action from a sequence of smaller writer actions.
05:13:51 <Lunar^> @prelude tails
05:13:53 <lambdabot> *** "tails" prelude "Haskell Standard Prelude Dictionary": text follows
05:13:53 <lambdabot> tails
05:13:53 <lambdabot>   tails ::  [a] -> [[a]]
05:13:53 <lambdabot>   tails []                 = [[]]
05:13:54 <lambdabot>   tails xxs@(_:xs)         = xxs : tails xs
05:16:07 <whee> ahh, nuts. the server with that monad tutorial just went down
05:16:15 <whee> and I was almost finished reading :(
05:18:21 <Lunar^> whee: This is a real good tutorial :)
05:18:28 <Lunar^> whee: google cache ?
05:18:58 <whee> I checked, not all the pages are in the cache :\
05:19:13 <Lunar^> :(
05:27:34 <whee> meh, anyone know where to get that "The Fun of Programming" book in the US?
05:27:48 <whee> amazingly it's not available on amazon.com, but is on amazon.co.uk
05:28:18 <Verbed> You might try amazon.ca
05:34:22 <prologic> alrighty :) lol me is back for more dishing out
05:34:23 <prologic> haha
05:35:06 <prologic> I'm in search of some good tutorials, but not about learning haskell as such as I'm already doing it this semester, but rather one that compares imperitive languages to Haskell and helps me break my imperitive background :)
05:35:07 <prologic> anyone ?
05:35:23 <prologic> I'd google, but I don't even know what I'm searching for :P
05:36:10 <whee> prologic: http://haskell.org/learning.html might be helpful
05:36:30 <Lunar^> prologic: Use MiB memory cleaner ;)
05:36:39 <prologic> k ta, any specific ones anyone know of ?
05:36:51 <prologic> our professor just wrote a short pdf, 2 page on what I want
05:36:54 <prologic> I want more :)
05:37:06 <prologic> Lunar^, MiB ?
05:37:16 <Lunar^> Men in Black..
05:37:29 <Lunar^> the movie
05:37:32 <prologic> I'm lost
05:37:38 <prologic> how's that going to help me ?
05:37:43 <Lunar^> It was a joke
05:37:45 <prologic> oooh
05:37:46 <prologic> lol
05:37:50 <Lunar^> sorry
05:37:50 <prologic> I remember that part of the movie now
05:37:52 <prologic> very good ;)
05:37:56 <prologic> sorry took me a while
05:38:12 <prologic> I can't forget my imperitive background, just have to learn the difference
05:38:58 <Lunar^> You could try to rewrite all prelude functions
05:39:05 <Lunar^> Just take the name and types
05:40:00 <Lunar^> Try rewriting map, filter, foldl, foldr, tails, inits, isPrefixOf, isSuffixOf, reverse
05:40:33 <Lunar^> (++), concat, all, any, and, or, (&&), (||)
05:40:46 <Lunar^> This could be a good exercice IMHO
05:40:54 <prologic> lol
05:40:59 <prologic> not a bad idea actually
05:41:09 <prologic> write your own basic prelude
05:41:14 <prologic> lol
05:41:25 <Lunar^> All list functions actually force you to think in a more fp way
05:41:34 <Lunar^> You have to use recursion, function composition and pattern matching
05:42:52 <prologic> see it's weird I just posted a question in our forum and the professor said we aren't to use Lists or Maps as we haven't gotten that far yet
05:43:20 <prologic> so it beats me as to how I'm suppose to convert http://daisy.ods.org/~prologic/INT.FOR a fortran program to calculate integrals to Haskell
05:43:40 <Lunar^> Urh
05:43:51 <Lunar^> Converting IP to FP is really hard
05:44:14 <Lunar^> Because if you have the whole source, you easily stick to imperative algorithms
05:44:20 <Lunar^> This is bad. (tm)
05:44:33 <prologic> yeah
05:44:40 <prologic> but we are asked to stick to the same algorithm
05:44:46 <prologic> so help me out here :) I'm lost
05:44:55 <prologic> IP and FP are very different
05:45:05 <Lunar^> never read anything in fortran
05:45:18 <prologic> it's a disgusting language
05:45:20 <Lunar^> urgh.. this is unglier than C
05:45:29 <prologic> yeh
05:45:41 <prologic> fair enough I can write the function x^2 in haskell, easy
05:45:49 <Lunar^> Ok
05:45:52 <prologic> probably do the main procedure too easy enough
05:45:59 <Lunar^> So, start thinking with _types_
05:45:59 <prologic> the qtrap and trapzd functions argg ;)
05:46:19 <Lunar^> What does qtrap needs and produce ?
05:46:54 <prologic> right, ask myself these ? and write a similar algorithm that accepts and produces the same inputs and outputs ?
05:47:11 <Lunar^> I think that it's the right way to do it
05:47:19 <prologic> k
05:47:22 <prologic> that helps
05:47:41 <prologic> see with Haskell you cannot modify variables as you can in that fortran example
05:47:44 <Lunar^> When you have a good typesystem, thinking in terms of type leads you to powerfull code
05:47:48 <prologic> so a lot of the code is redunant right ?
05:47:57 <prologic> err useless rather
05:48:17 <Lunar^> If you take away the loops, what are vars are modified in the FORTRAN code ?
05:49:01 <prologic> ask myself this for each function too ? strip away the loops and work out how to get from the input to the output ?
05:49:07 <prologic> using the same algorithm
05:49:41 <Lunar^> It's easy to transform a imperative loop into recursion with practice
05:50:01 <prologic> yeh I haven't had the practise yet
05:50:06 <Lunar^> prologic: trapzd loop seems a good candidate for using "foldl" or "foldr"
05:50:16 <Lunar^> @type foldl
05:50:16 <lambdabot> foldl :: (a -> b -> a) -> a -> [b] -> a
05:50:24 <prologic> hrmm see we haven't even learnt that yet
05:50:28 <prologic> bloody professor :)
05:50:41 <prologic> I outta do it the easy way and use lists like it's been said here before
05:50:42 <Lunar^> foldl takes a function, a start value, and a list
05:50:55 <prologic> k
05:50:56 <Lunar^> uhhh sorry
05:51:05 <Lunar^> forget about foldl if you have no list
05:51:31 <Cale> well, if you were going to have a loop...
05:51:41 <Lunar^> When using recursion, the question is always "where to stop"
05:51:48 <prologic> yeh that's right :)
05:51:57 <Lunar^> Let's do trapzd together if you want
05:51:59 <prologic> spot on, I gotta learn how to write them so they stop
05:52:02 <prologic> sure ;)
05:52:04 <prologic> be lovely
05:52:11 <prologic> I got a hard copy of it here as we speak
05:52:12 <Lunar^> (just the loop)
05:52:25 <prologic> yup
05:52:36 <Lunar^> When do you stop then ?
05:53:41 <prologic> ooh geez, heck I don't even know! lol
05:53:46 <prologic> fortran is confusing
05:54:09 <Lunar^> hehe
05:54:22 <Lunar^> seems it's when J == IT
05:54:23 <prologic> hmm sorry
05:54:28 <prologic> ahh
05:54:32 <prologic> that what J=1,IT mean
05:54:35 <prologic> yeeesh :(
05:54:55 <whee> I think understanding the fortran code is harder than writing the haskell :)
05:54:59 <prologic> it is
05:55:15 <whee> have a calculus book handy?
05:55:21 <prologic> yeah
05:55:22 <Lunar^> Ok.. but inside the loop we do not need to use J
05:55:31 <whee> this is just a trapezoidal approximation of an integral
05:55:55 <prologic> hrmm but J isn't even modified in the loop is it ?
05:56:11 <Lunar^> I think it goes upward because of the way FORTRAN forks
05:56:43 <prologic> oh gawd
05:56:55 <prologic> so from "DO 11 J=1,IT" where does it go ?
05:56:58 <whee> I think you'd have more luck ignoring the fortran code and coming up with the haskell blind :)
05:57:04 <prologic> up to the beginning of the subroutine ?
05:57:16 <prologic> I'm thinking the same thing whee
05:57:24 <Lunar^> Sorry I need to go...
05:57:28 <Lunar^> think that whee is right
05:57:34 <prologic> but I may loose marks if it doesn't look similar to the fortran code
05:57:36 <Lunar^> Try to find web pages on the original algorithm
05:57:49 <Lunar^> prologic: forget about marks, what's important is what you learn
05:57:53 <Lunar^> Bye everyone
05:57:56 <prologic> true :)
05:58:00 <Cale> Haskell code is not going to look similar to fortran code.
05:58:01 <prologic> thanks Lunar
06:01:02 <whee> prologic: this does look like something you could do really easily with a list comprehension
06:01:54 <Cale> whee: I agree.
06:02:16 <prologic> could anyone explain how looping works in fortran if possible ?
06:02:17 <prologic> I can see I'm going to be stuck understanding the fortran code
06:02:17 <prologic> although you're right whee, I could just pick up my calculus textbook
06:02:31 <whee> it'll be a lot shorter and closure to the definition of the approximation when written in haskell
06:02:37 <whee> s/closure/closer/
06:02:44 <prologic> yeh but as I explained above, the profressor obviously doesn't want us to use lists as we haven't learnt them yet
06:02:53 <prologic> what other way is there ?
06:03:08 <whee> you could just recurse
06:03:08 <Cale> Using functions as lists?
06:04:05 <prologic> yeh well I'm going to have to recurse
06:04:26 <whee> err, does the [n..n2] range notation have something for a step size?
06:05:30 <prologic> well thank you guys once again, you're a great bunch of people that really do help :)
06:05:32 <Cale> [n1,n2..nn]
06:05:38 <Cale> iirc.
06:05:58 <Cale> yeah
06:06:02 <whee> ahh, yes that works
09:22:36 <hdaume> is icfp this week?
09:23:36 <Marvin--> yeah
09:23:49 <Marvin--> that's why it's so quiet :)
09:24:26 <hdaume> that's what i thought
09:24:41 * Marvin-- will meet lots of #haskell people tomorrow, hooray
09:43:40 <whee> anyone know of any tutorials on arrows?
09:44:31 <whee> or just anything that's easy to follow :|
09:45:00 <hdaume> i think the hughes paper is the best
09:45:08 <hdaume> (though i was just in here asking the same question recently)
11:27:06 <Vincenz> Hi
11:29:17 <hdaume> howdy
11:30:58 <Vincenz> been a while
11:31:14 <hdaume> it's slow in here this week (due to icfp)
11:35:30 <reffie> hehe
11:36:34 <Vincenz> oh yeah, are the results out?
11:36:51 <hdaume> dunno
11:36:53 <hdaume> don't thin kso
11:37:54 <Vincenz> should be today
11:53:17 <Marvin--> the icfp ends tomorrow
11:54:52 <Vincenz> hmm, it said the 26th
14:31:10 <kaol> what's the rationale for disallowing taking values out of an IO monad?
14:32:41 <Cale> Because they're involved in side effects. It keeps side effecting actions away from the rest of the computation.
14:34:01 <kaol> ok, just as I thought.
14:37:13 <Cale> This ensures, say, that functions will always return the same value given the same inputs.
14:42:41 <kaol> State is an argument for IO actions. Being inside a monad, you can use certain state only once. That'll ensure IO actions are referentially transparent, too.
14:43:06 <kaol> or something like that?
14:43:40 <Cale> yeah
14:44:22 <kaol> being able to input same state to different IO actions multiple times would be too expensive
14:45:29 <Cale> Yes. I tend to think of (IO a) values as being computational actions that are just being stuck together like lego by the bind operator to produce bigger actions.
14:45:57 <whee> got the urge to look at lambdabot, and sourceforge cvs is acting up. hooray
14:45:57 <kaol> That seems sensible.
14:48:38 <kaol> I think I'm beginning to understand monads. I'd just need to code a substantial amount of haskell to make myself comfortable with them. Before I forget about them.
14:49:45 <stepcut> :p
14:50:42 <stepcut> automatically rewriting sub-selects out of SQL statements is not easy :(
15:03:20 <whee> wow am I confused :|
15:03:24 <whee> lambdabos is complicated
15:03:33 <Riastradh> That's why I wanted to completely rewrite it.
15:04:00 <whee> I don't know what it is I don't like, it just seems complicated in general
15:04:07 <Riastradh> Then I decided, 'eh, I'd have more fun writing it in Erlang,' which I'm vaguely working on now and which isn't nearly complete.
15:04:26 <whee> yeah, I wrote an erlang irc bot to learn that language too :)
15:04:40 <Riastradh> Now I'm writing an IRCd in Erlang.
15:04:45 <whee> never really finished it up, but learned what I wanted to
15:05:02 <whee> if you want help with that, that's something I'd work on :P
15:05:07 <Riastradh> (At least with bots there are lots to hack around with.  With IRCds, they're _all_ in C, and they're _all_ based on the same original crappy IRCd)
15:05:57 <Riastradh> OK, but on one condition: you must become a frequenter of a certain channel on a certain network.
15:06:04 <Smerdy> I think it would be more interesting to create software for a more robust version of the IRC protocol.
15:06:20 <whee> Smerdy: I've thought about that, but the problem is client support
15:06:38 <Smerdy> Not if you're doing it to improve the state-of-the-art
15:06:52 <whee> Riastradh: fine by me, heh
15:07:25 <whee> back when slashnet was first starting I was one of the people working on their ircd, I wouldn't mind getting back into that line of coding
15:07:37 <Riastradh> whee, oh, do you have a place to put a CVS repository?
15:07:48 <whee> nope :\
15:10:46 * Riastradh would have put it on the hub of that network, but the admin got confused (he's not familiar with CVS...go figure) and didn't let anyone install a it there.
15:45:16 <Smerdy> Riastradh, Sourceforge. Sourceforge. Sourceforge. They are working on new CVS servers now.
17:48:47 <whee> hrm, arrows look a lot more fun than monads
17:56:47 <Cale> They're unfortunately named for those who happen to know some category theory though, as they're related to, but not the same as those arrows :)
17:58:06 <Cale> I should learn more about them, but I haven't run into many arrow based libraries that I've wanted to use yet.
17:58:14 <Cale> They do look powerful.
18:01:20 <whee> I'm reading the paper Hughes wrote, it's pretty good
18:01:34 <whee> says a lot when I can follow a paper :)
18:04:17 <Pseudonym> Personally, I think "arrow" is no less well-named than, say, "class".
18:04:36 <whee> I just need to find a practical example where a monad just doesn't work and an arrow does
18:05:18 <Pseudonym> whee: The first motivating example was parsers.
18:05:27 <Pseudonym> If you look at the monad bind operation:
18:05:35 <Pseudonym> (>>=) :: m a -> (a -> m b) -> m b
18:05:47 <Pseudonym> It can't get any information out of its second argument.
18:06:07 <Pseudonym> Not without actually giving it an argument, anyway.
18:06:14 <Pseudonym> Arrows don't have that problem.
18:06:29 <Pseudonym> So, for example, precomputing lookahead in parsers is better with arrows.
18:06:41 * Pseudonym probably didn't explain that well
18:06:50 <whee> mmf, I'll have to reread the section on parsers because I've never really written one
18:06:56 <Pseudonym> Ah, OK.
18:06:57 <whee> at least not in haskell
18:07:18 <Cale> Is there a parsec-equivalent done using arrows?
18:07:21 <whee> all I know how to do in haskell is use parsec :)
18:07:25 <Pseudonym> Personally, I've never had the need for arrows either.
18:07:34 <Pseudonym> I'm sure it's only a matter of time.
18:07:43 <Pseudonym> But monads have been sufficient for me so far.
18:11:25 <whee> I haven't written anything major in haskell yet, so I'm trying to at least be aware of all the current options
18:12:16 * Pseudonym nods
18:12:34 <Pseudonym> I've been programming in pure functional languages for over ten years, and I've never needed arrows yet. :-)
18:17:28 <whee> I just got entirely lost in this paper now, oh well
18:20:40 <Cale> I'd like to see a nice physical analogy for arrows in the style of http://www.nomaware.com/monads/html/analogy.html
18:21:03 <Pseudonym> Oh, that's easy.
18:21:21 <Cale> Intuition building stuff like that is good for giving your brain a foothold to work with.
18:21:26 <Pseudonym> The physical analogy for arrows is that they're like monads, only it's not a linear conveyer belt.
18:21:39 <Cale> ah
18:21:40 <Pseudonym> Instead of a line, arrows support arbitrary graphs.
18:22:05 <Pseudonym> So if you imagine a conveyor belt with points where the belt splits, maybe goes around in a circle etc.
18:22:32 <whee> I don't get that analogy at all :)
18:22:40 <Cale> which one?
18:22:52 <whee> the arrow one
18:23:05 <Cale> I think that it would work - I should keep that in mind and read the paper again.
18:23:19 <Pseudonym> Did you understand the monad one?
18:23:30 <Cale> I got the monad one.
18:23:32 <Pseudonym> OK.
18:23:40 <Pseudonym> Sorry, not you, I meant whee.
18:23:44 <Cale> ah
18:23:49 <whee> heh, yes I understood that one
18:23:58 <Pseudonym> OK.  Well a production line is linear.
18:24:02 <Pseudonym> Do this, then do this, then do this.
18:24:30 <Pseudonym> Arrows are more like circuits, in that the production line doesn't have to be linear.
18:24:36 <Pseudonym> It could have a cycle in it, for example.
18:24:54 <Pseudonym> e.g. a product has to go back into a machine several times until it's "right".
18:25:21 <Pseudonym> Maybe that's not a good analogy.
18:25:31 <Pseudonym> The "circuit" idea I think is the best.
18:25:59 <Pseudonym> Real electrical circuits have electricity flow going in all directions, not just in a forward line.
18:26:41 <Cale> well, perhaps it's okay with appropriate specification of what the arrow combinators are in the assembly line
18:26:47 <whee> the circuits analogy makes sense, but now I'm unsure how that actually applies in the code :\
18:26:56 <Pseudonym> Ah, now therein lies the problem.
18:27:09 <Pseudonym> The monad combinators and their axioms, I think, are easy to understand.
18:27:20 <Pseudonym> Whereas the arrow combinators and their axioms are, IMO, poorly motivated.
18:27:53 <Cale> Arrows appear to have a much more complicated category theoretic structure.
18:28:27 <Cale> and yeah, I don't really understand why it is that they do.
18:30:34 <Cale> does lambdabot have an arrow definition?
18:30:48 <Pseudonym> What do you mwan?
18:31:15 <Cale> like the @prelude stuff - a code listing of the appropriate typeclass
18:31:25 <Pseudonym> I don't think so, no.
18:31:58 <Cale> the Hughes paper has: arr :: (a -> b) -> a b c
18:32:09 <Cale> as one of the members
18:32:20 <Pseudonym> Yes, I think that's kind of the equivalent of "return".
18:32:21 <Cale> under the typeclass Arrow a
18:32:27 <Pseudonym> Sort of.
18:32:36 <Pseudonym> Or maybe it's "map".
18:32:37 <whee> the ghc source has arr :: (b -> c) -> a b c
18:32:43 <whee> which makes more sense to me
18:32:46 <Pseudonym> Oh.  Yes.
18:32:46 <Cale> that makes more sense
18:32:58 <Pseudonym> The GHC one is correct.
18:33:11 <Pseudonym> @prelude arr
18:33:13 <lambdabot> No match for "arr".
18:33:16 <Pseudonym> There you go.
18:33:21 <Cale> heh
18:33:35 <whee> @type Control.Arrow.arr
18:33:42 <whee> or not :)
18:33:46 <Cale> it would be nice to have all the ghc libraries in there
18:33:51 <Pseudonym> Yes, it would.
18:34:00 <Pseudonym> At least those which have been haddock-ised.
18:34:43 <Pseudonym> My general feeling is to steer clear of arrows until we understand them better, unless you really really need them.
18:34:48 <Pseudonym> But that could just be bias on my part.
18:35:06 <Pseudonym> Monad programming was similarly painful before do-notation.
18:36:40 <whee> your circuits analogy is exploding my brain :P
18:36:45 <Pseudonym> :-)
18:37:16 <whee> because I keep thinking of having some sort of feedback loop or any other typical circuits structure like a counter or adder
18:37:28 <Pseudonym> Yes, you've got it.
18:37:39 <whee> but then I don't know to express that with arrows :)
18:37:46 <Pseudonym> For now, don't.
18:37:51 <Pseudonym> Just think about it abstractly.
18:38:07 <Pseudonym> Consider, for example, a GUI library like fudgets.
18:38:37 <Pseudonym> A "button" control has three "things", abstractly.
18:38:46 <Pseudonym> Actually, forget a button.  Consider a checkbox.
18:39:24 <Pseudonym> It has three things: input (i.e. actions from the user), output (i.e. interested parties who want to know what's happening to the checkbox) and state (i.e. whether it's checked or not).
18:39:35 <Pseudonym> The "state" can be modelled as a feedback loop.
18:40:33 <whee> it'd be possible to implement some sort of constraint system with arrows, wouldn't it?
18:41:07 <Pseudonym> Probably.
18:41:19 <Pseudonym> It depends, I think, whether or not you need backtracking, for example.
18:43:19 <Darius> The paper, "A New Notation for Arrows" has little schematic examples of what each arrow combinator represents.
18:44:41 <Darius> oh, and arr's type is a typo in Hughes' paperr
18:50:01 <flippo> Anyone with new arrows must first fight Rumbaugh and Booch to the death
18:50:18 <Cale_> I love the power company!
18:51:23 <Pseudonym> whee: YOu might like to start reading the "stream processors" part of the fudgets thesis.
18:51:25 <Pseudonym> http://www.cs.chalmers.se/~hallgren/Thesis/streamprocessors.html
18:51:27 <Pseudonym> Start from there.
18:51:41 <Pseudonym> That might help you understand arrows a bit better.
18:53:15 <whee> I think I understand the concept, I just need to see if I can write code with them
18:56:21 <Cale> We've only had 3 power outages today! I feel special! :D This is doing wonders for my uptime!
18:56:41 <Pseudonym>  11:56:35 up 194 days, 15:44,  1 user,  load average: 0.01, 0.13, 0.19
18:56:57 <Pseudonym> My record is three years.
18:57:25 <Pseudonym> It was a firewall box running FreeBSD.
18:58:11 <Pseudonym> If you think about it, that's a pretty good amount of time between power outages long enough to make the UPS run out of battery.
18:59:08 <Cale> I should really, really get a small UPS.
19:01:05 <Pseudonym> Hmmm.
19:01:22 <Pseudonym> The more I look at fudgets, the more I feel my productivity may drop dramatically soon.
19:01:46 <Cale> heh
19:01:56 <Pseudonym> There's some stuff in here that I am trying to implement in C++ elsewhere.
19:01:59 <whee> wow I feel like an idiot
19:03:55 <Pseudonym> Yeah, I get that too.
19:10:16 <Pseudonym> I'm bored.
19:10:31 * Pseudonym is doing the least interesting job that's in his job description
19:10:37 <Pseudonym> Building beta CDs.
19:11:28 <flippo> Pseudonym: it's a rule of corporate life, designed to destroy your soul
19:11:35 <Pseudonym> Yes.
19:13:08 <Pseudonym> The trouble is, we contract to certain parties who need work done by a certain date.
19:13:42 <Pseudonym> I'm not working on that, so I pulled off what I'm doing to do grunt work every so often.
19:14:01 <Smerdyakov> Man, you don't gotta take that!!
19:14:34 <Pseudonym> Well, it could be worse.
19:15:13 <Pseudonym> The guy with the cubicle enxt to me is removing deadlocks from modifications he made to old code.
19:15:28 <Pseudonym> I believe the phrase "code rage" applies here.
19:17:03 <whee> heh, I know what's confusing me. how do you get the output values on these arrows :|
19:17:42 <Darius> the same way you get output values from monads.  There will be a run function.
