00:00:41 <norpan> you do that in an IO context
00:00:45 <norpan> for instance
00:00:47 <norpan> main =
00:00:54 <norpan>   do args <- getArgs
00:01:03 <norpan>      call function on args
00:02:08 <crass> hm, I was wondering if ther's a way to assign it toa  var without using do?
00:02:25 <ski> not if you are using getArgs
00:02:53 <ski> (well, you *can* use raw >>=, of course. but it is really the same, type-wise) 
00:03:12 <crass> yeah that's what I was thinking, but I think I have the syntax wrong
00:03:31 <norpan> but why not use do
00:03:33 <norpan> do is nice
00:04:20 <ski> (crass : you could also use IOExtensions.argv (in hugs), as mentioned earlier, it just have type [String])
00:04:29 <crass> yeah, I guess, just trying to do it a different way
00:04:41 <norpan> you could also use unsafePerformIO of course, but then you're on your own :)
00:04:42 <crass> yeah, using ghc though
00:05:02 <ski> norpan : implementing argv on his own, eh ?
00:05:07 <norpan> yes
00:05:10 <norpan> something like that
00:05:17 <crass> hehe, no thanks =P
00:05:23 <norpan> it's not hard to use do though
00:05:40 <norpan> _not_ to use i mean
00:05:49 <norpan> main = getArgs >>= \args -> print args
00:06:03 <norpan> or main = getArgs >>= print
00:06:19 <crass> hmm, ok, I'll try that thanks
00:06:55 <ski> just indent every command in the do-block the same number of spaces, *or* use like "do {x <- blah; blahh; y <- gah; ... }"
00:07:14 <ski> with the later version you can indent how you like
00:07:44 <crass> yeah, I vaguely remeber that, its been a year since I've programmed any haskell
00:07:50 <ski> crass : also see http://www.haskell.org/hawiki/ThatAnnoyingIoType
00:08:20 <crass> hehe, thanks
00:19:45 <norpan> Lars Lundgren indeed
00:19:52 <norpan> he is my workmate
00:21:56 <ski> somewhere here at math/comp.sci. institution ?
00:23:26 <norpan> nope
00:23:28 <norpan> safelogic.se
00:23:41 <ski> ok
00:23:53 <norpan> guess if the products contain haskell code? :)
00:24:44 <ski> could well be ..
00:26:25 <norpan> gotta go, take care now
00:26:33 <ski> sure, bye
03:48:56 * shapr yawns
03:49:01 <shapr> goood morning #haskell!
03:53:55 <opet> morning!
03:54:27 <shapr> hi opet, what's happening?
03:54:31 <opet> not much
03:54:35 <opet> scotland lost :(
03:54:40 <shapr> aww
03:54:44 <shapr> what were they competing for?
03:54:56 <opet> rugby world cup quarter final
03:55:15 * Marvin-- grumbles and growls
03:57:53 <shapr> hi Arnia, have you seen my antispam server idea?
03:59:36 <shapr> wow, there's a message on haskell-libs-developers !
03:59:38 <shapr> shocking!
04:34:14 <ham[home]> hiho
04:34:23 <shapr> hi ham
04:34:29 <shapr> what's up?
04:34:43 <ham[home]> nothing much :)
04:34:55 <ham[home]> i try to figure out how to draw a recursion
04:35:13 <shapr> klein bottle?
04:35:15 <ham[home]> i read a book on category theory and computation
04:35:23 <shapr> cantor dust?
04:35:38 <ham[home]> but i wonder how you can draw a recursion such that you see what the initial elements are
04:35:43 <ham[home]> and what the "flow" is
04:37:03 <shapr> fib = 1 : 1 : zipWith (+) fib (tail fib)
04:37:07 <ham[home]> a recursion in haskell is something which roughly looks like this fn x = if x init then endelem | fn2 head x fn tail x
04:37:35 <shapr> the fib lazy list above is alternating red and blue stripes that expand linearly
04:37:41 <shapr> that's my mental picture of it
04:38:03 <ham[home]> yeah but there are millions of different structures
04:38:10 <ham[home]> depending on the recusive functions
04:38:30 <ham[home]> but what is the general structure you can draw in a way like an automaton?
04:38:56 <shapr> oh, I don't know.
04:40:15 <ham[home]> i mean there is stuff on that out there but its just not "connected"
04:40:26 <ham[home]> in haskell its like pattern matching isnt it?
04:40:42 <ham[home]> that is when you have two functions it tries to match to the right one
04:40:52 <ham[home]> quite like in prolog
04:40:56 <ham[home]> or is that wrong?
04:41:21 <shapr> I don't think I understand the question
04:41:38 <ham[home]> fn ( nil ) := 0
04:42:06 <ham[home]> fn (h :: t) := +(fx (h),fn(t)) 
04:42:11 <ham[home]> something like that
04:42:22 <shapr> length [] = 0
04:42:26 <ham[home]> im not to familiar with haskell yet bought a book
04:42:32 <shapr> length (x:xs) = 1 + length xs
04:42:37 <ham[home]> yep
04:42:46 <shapr> http://purl.org/net/shapr/src/haskell/Demo.hs
04:43:44 <ham[home]> what was the name of that programm again that translated haskel programs to dotty graphs?
04:44:03 <shapr> er, I don't know?
04:44:23 <shapr> oh, do you mean the program from hIDE that showed the structure of a module?
04:44:30 <ham[home]> ah yes
04:44:37 <ham[home]> i think that was the thing i mean
04:44:42 <ham[home]> sec
04:44:47 <shapr> this one? --> http://www.scannedinavian.org/~shae/hIDE.png 
04:45:07 <ham[home]> thanks yes
04:45:12 <shapr> that's code from hIDE
04:45:24 <ham[home]> how would that represent a recursion
04:45:38 <ham[home]> as i see there are nodes that have more then one arrow exiting that node
04:45:48 <shapr> yah
04:46:08 <shapr> but that dotty picture is just a call tree, it shows who calls what
04:46:10 <ham[home]> so that shows you what happens in an if
04:46:20 <ham[home]> ah ok
04:46:29 <shapr> if you want to see the number of calls per invocation, then you'd get a different tree
04:46:42 <shapr> my first thought is to use different colored arrows
04:46:54 <ham[home]> so this programm doesnt show me the structure of the program?
04:47:14 <shapr> so for the recursive lazy list I pasted above, have a red and blue arrow, one for each separate call to yourself, and have those arrows point back to yourself
04:47:24 <ham[home]> the prob is if the arrows are different branches from an if how do you see what the corresponding elements are?
04:47:34 <ham[home]> yep
04:47:44 <ham[home]> and i thought that the set should be divided
04:47:46 <ham[home]> that is the node
04:47:55 <ham[home]> so that you see what the initial element is
04:48:15 <ham[home]> i think i will try that out and keep it im mind
04:48:25 <ham[home]> shapr: do you know of anyone in here dealing with ai?
04:48:41 <shapr> not professionally, but several who are interested.
04:48:56 <ham[home]> ah
04:49:15 <ham[home]> have you ever heared of neural nets?
04:49:57 <shapr> sure
04:50:15 <shapr> kohonen at helsinki.fi was the first person to get three layer backpropagation to succeed
04:50:35 <shapr> I've read a lot about them, but not much in the last few years
04:51:14 <ham[home]> so
04:51:20 <ham[home]> if you do that in haskell
04:51:36 <ham[home]> and you have different inputs lets say from sockets
04:52:01 <ham[home]> how would you construct something like a cartesian product on the fly form them with a function?
04:52:34 <shapr> if you do what in haskell? build a neural network?
04:55:30 <ham[home]> no i mean if you want to construct a type while the program is running
04:58:12 <ham[home]> i mean you have a \in |R and b \in |R and you want something like (a,b)
04:59:36 <shapr> reboot, my cdburner won't reset, I'll bbl
05:00:04 <ham[home]> k
05:01:46 <skew> Has anyone built GHC from CVS recently?
07:41:56 <ham[home1> what does this lambda bot do?
07:42:06 <ham[home1> lambdabot: tell me what you do
07:42:06 <lambdabot> Sorry, I'm not a very smart bot yet, try "lambdabot: @listcommands"
07:42:20 <ham[home1> lambdabot: @listcommands
07:42:21 <lambdabot> I react to the following commands: ["all-dicts","arr","cmafihe","define","definitions","del-definition","devils","dict","dict-help","dummy","dump","dynamic-load","dynamic-reload","dynamic-unload","easton","echo","elements","eval","foldoc","foo","fortune","gazetteer","get-definition","goodbye","hello","hitchcock","jargon","join","karma","karma+","karma-","leave","listchans","listcommands","listmodules","lojban","more","msg","part","prelude
07:42:42 <ham[home1> lambdabot: @jargon
07:42:42 <forge> lambdabot: fortune 
07:42:43 <lambdabot> Sorry, I'm not a very smart bot yet, try "lambdabot: @listcommands"
07:42:49 <forge> :)
07:42:58 <ham[home1> who has written that bot?
07:43:28 <ham[home1> lambdabot: @listmodules
07:43:29 <lambdabot> I have the following modules installed: ["base","cmafihe","dict","dummy","dynamic","eval","hello","karma","more","quote","seen","state","system","topic","type"]
07:43:37 <ham[home1> lambdabot: @karma
07:43:37 <lambdabot> I can't find the karma of nobody.
07:43:42 <ham[home1> lambdabot: @karma ham[home1 
07:43:43 <lambdabot> You have a karma of 0
07:43:53 <ham[home1> lambdabot: @karma+ ham[home1 
07:43:53 <lambdabot> You can't change your own karma, silly.
07:43:57 <ham[home1> :)
07:44:29 <ham[home1> lambdabot: @hello
07:44:29 <lambdabot> Hello world. 
07:45:06 <ham[home1> lambdabot: @all-ditcs
07:45:07 <lambdabot> Sorry, I don't know the command "all-ditcs", try "lambdabot: @listcommands"
07:45:15 <ham[home1> lambdabot: @all-dicts
07:45:55 <ham[home1> is there some module that enable to write dynamic haskell code?
08:41:32 <esap> Hmm.. is there some reason why Haskell lists can be both cyclic and non-cyclic? E.g. both let x = [1,2,3] ++ x in x  and [1,2,3] have the same type?
08:43:28 <earthy> esap: it is not cyclic. it is infinite.
08:43:44 <earthy> (which is perfectly allowable in lazy languages)
08:44:13 <esap> sure but they behave so differently that I would like them to be distinguished.
08:45:04 <earthy> err.... why?
08:45:33 <esap> like try foldr for them.
08:45:35 <earthy> (there's not that much difference between them, honestly)
08:46:02 <earthy> ah, you're asking for a guarantee that a list is finite.
08:46:30 <esap> Well more like a guarantee that I can use foldr for it.
08:46:35 * earthy doesn't really know how to enforce something like that within the typesystem.
08:46:46 <earthy> esap: but you *can* use foldr on it
08:46:56 <earthy> it just won't terminate ;)
08:47:03 <esap> right, so I can't use it.
08:47:19 <esap> But not all such questions are undecidable :-)
08:47:49 <earthy> subtle difference. you could foldr a constructor for a different data type over it and then cut off that datatype at a certain depth.
08:47:53 <esap> I could write my own list things, of course, that would represent finite lists. But maybe there was some reason why that wasn't done already.
08:48:27 <earthy> in most cases where finiteness matters you also want other properties as well
08:50:43 <Darius> esap: You can't make your own finite lists at least not in any straightforward way.
08:51:08 <Darius> (finite list type)
08:51:34 <esap> darius: hmm.. why not? Just you'd never offer operations to close the loop.
08:51:56 <Darius> List the operations you'd provide.
08:52:26 <earthy> esap: you could always write a function that did infinite cons'es...
08:52:46 <earthy> (as soon as you allow cons, you're screwed ;))
08:53:20 <Darius> You could make cons strict in it's second argument, but that just moves the problem.
08:54:09 <esap> yes, actually, that would have to be strict, I guess.
08:54:57 <phubuh> Hello!
08:56:00 <esap> darius: how would that move the problem?
08:56:54 <Darius> It would simply cause an infinite loop at construction rather than at use, it wouldn't keep it from happening (especially statically) nor would it raise an exception.
08:57:36 <esap> darius: ok, but actually, that would be infinitely better than having it when you use the infinite part. Then you'd know where the problem is.
08:58:10 <esap> darius: And I could not allow that construction.
08:58:29 <esap> darius: except with very low level primitive operations (and then it's up to whoever writes that)
08:59:10 <Darius> Not allow which construction?
08:59:52 <esap> let x = Cons 1 x in x  would be the primitive one, I wouldn't provied anything that did anything close to that.
09:00:15 <esap> And anyone that wrote that would surely get an infinite loop.
09:00:48 <Darius> Assuming you are talking about Haskell how would you disallow someone from writing let x = Cons 1 x in x?
09:00:52 <Darius> (or cons)
09:01:28 <esap> well you can't actually. But you can make it behave so badly that it's very hard to miss.
09:02:18 <Darius> And if you didn't want to just piss off Haskellers, you would document that, at which point it seems easiest to simply document that you're functions require finite lists.
09:02:48 <esap> The point is, I don't want to do it for all functions that require finite lists, I only want to document it once.
09:03:55 <esap> ANd then those functions would just refer to a data type that used those finite lists.
09:04:23 <esap> But anyway, I would just solve the finite vs. infinite list problem once, not for every use.
09:05:46 <Darius> This looks like it costs more than it gains.
09:06:18 <esap> I think the most important gain is that you'd be able to distinguish which functions require finite lists and which don't.
09:06:53 <Darius> I think most Haskellers assume functions will only work on finite lists unless they have a good reason to believe otherwise.
09:06:58 <esap> If the function worked for both kinds of lists, I would still use ordinary lists for it.
09:08:03 <esap> darius; hmm.. interesting. But that means that haskell lists could be changed to prevent looping?
09:08:23 <esap> darius: and there would be no effect.
09:09:03 <esap> darius: ... on users that have the same assumption, I mean.
09:09:58 <Darius> There are still functions that do work on infinite lists as well as reasons to use infinite lists in and of themselves, disallowing infinite lists would still break that code.
09:13:32 <Darius> All I'm saying is that most Haskellers wouldn't find much value in an explicit (but homegrown) FiniteList type and would likely find it more of a burden.
09:13:36 <esap> I'm just wondering whether the concept of a lazy list is actually not that good, if most users still use them as finite, that is, most users don't require the laziness there.
09:14:15 <esap> At least not in an essential sense.
09:14:39 <Darius> No, what I said is that most users don't pass them to functions whose strictness properties they don't understand.
09:15:05 <Darius> How often infinite data structures are used is a different question.
09:16:03 <ibid> i'd say many uses don't understand the strictness properties of functions :)
09:16:58 <esap> The reason I'm wondering about this is that I think this might be one reason why writing well-behaving (from performance point of view) Haskell programs is so hard.
09:17:29 <Darius> Laziness might, infinite structures isn't.
09:17:40 <Darius> (actually, it's hardly a "might")
09:17:57 <esap> No I mean, that laziness is used in structures that are not essentially infinite.
09:18:19 <Darius> Then what does any of this have to do with finite lists?
09:18:43 <Darius> (v. infinite lists)
09:19:36 <esap> Because I think finite vs. infinite question is the same thing as strict vs. non-strict. That is, for finite structures, strict evaluation is very good approach, whereas for infinite ones, lazy evaluation is the working approach.
09:21:02 <Darius> No, for infinite structures (some degree of) laziness is required no question.  For finite structures laziness may or may not be a win.  And at any rate, I'd think the problem with laziness and containers is more with the elements being lazy than the container.
09:22:04 <esap> darius: basically, what I'm saying is that for finite structures, laziness is more often than not a performance problem.
09:23:23 <esap> but you might be right about the element part. I'm not sure how that should be handled.
09:23:58 <esap> Because containers usually leave the elements as abstract. So maybe the choice between strict vs. lazy elements should be with the user of the data type.
09:24:09 <Darius> I'd say it's more often than not a slowdown, but I doubt it's a problem.  My point is that these are optimization issues which are separate from semantics and also separate from strict/non-strict and that this is a totally different issue than what you apparent began on.
09:26:01 <esap> Ok, my point of view is that there is something semantically wrong, if you get performance problems when you try to implement programs with the system.
09:26:43 <Darius> Then I guess both eager and lazy languages are semantically wrong.
09:26:58 <esap> Yes, of course.
09:27:38 <esap> You need one language which distinguishes between eager and lazy semantics in all language primitives.
09:28:28 <ibid> how would you do that?
09:28:55 <Darius> What would that accomplish? I could still write programns that would have performance problems and by your measure that language too would be semantically wrong.
09:28:59 <esap> I'm not sure it's possible actually.
09:30:08 <esap> ibid: but what I would try to do is to have two separate sublanguages that could not be easily mixed, one eager and one lazy. But that you could switch between those sublanguages in restricted ways.
09:31:23 <ibid> ugh
09:31:27 <esap> ibid: the point is, I need to know which primitives fall into which sublanguage. My hypothesis currently is that building coalgebras is clearly in the lazy part. And algebraic data types are in the strict part.
09:32:12 <ibid> esap: you could have that by having delayed evaluation as a choice and then providing strict and nonstrict versions of all library functions
09:32:33 <ibid> (delayed evaluation as a choice at the language level, that is)
09:32:51 <esap> ibid: but I'm not sure all functions can be implemented as lazy.
09:33:10 <ibid> esap: don't provide lazy versions of them then :)
09:33:36 <esap> another thing is, I guess the lazy and strict parts should be dual, so they should be symmetric :-)
09:33:39 <Darius> A lazy function can still be strict.
09:34:27 <Darius> In other words how could you -not- be able to implement a function as "lazy", it would be the other way around, you couldn't implement some lazy functions eagerly.
09:34:30 <ibid> lazy and strict on the same parameter? example please
09:35:11 <Darius> ibid: In that case it would be identical to the eager version.  My point is that you don't have to have a "lazy" (+).
09:35:49 <esap> I would expect that no single thing would have both lazy and strict versions of the _same_ thing. Those are different things :-)
09:35:50 <ibid> Darius: what would a lazy + do?
09:36:21 <ibid> lazy and eager, strict and nonstrict are pairs. please don't mix them :)
09:36:39 <esap> oh sorry, yes, you're right.
09:37:03 <ibid> (unless you *really* mean that)
09:37:05 <ibid> :)
09:37:34 <esap> I really mean lazy vs. eager I think.
09:38:29 <Darius> Okay, my point another way, you can rewrite any strict function in a (pure) lazy language and it will still work on the same inputs it would have in a strict language the other way won't in general.
09:39:18 <ibid> true
09:40:09 <esap> are you saying that what I should really have is a lazy language with a strict sublanguage?
09:40:38 <esap> and not try to do both ways?
09:42:04 <Darius> I don't know what you are going for so I'm not saying anything about that.  I was just responding to "I'm not sure all functions can be implemented as lazy"; either that's a kind of pointless phrase or it's wrong in practice in a pure language.
09:44:20 <esap> Well that might have been not exactly what I meant; I mean the fact that (+) and 'length' really have to demand their argument.
09:44:44 * esap might be confusing still lazy vs. nonstrict.
09:44:51 <Darius> You are.
09:45:11 <Darius> But it doesn't really matter here.
09:45:50 <Darius> However, if you don't have any functions force anything in the "lazy subset" what's the point of it, it won't be able to do much.
09:46:50 <esap> oh but it doesn't need. that part of the language just makes promises. _when_ you demand this, then you get this behaviour. But you couldn't do the demand itself at that side.
09:48:15 <Darius> In that case, either the transition will be so sugared as to be non-existent or it will be rather painful to use the lazy subset.
09:49:03 <esap> I think the transition would be operation performing a c
09:49:07 <esap> cut
09:49:29 <esap> or function application, I guess.
09:51:43 <Darius> Think about say if implemented as a function.  It's strict in it's first argument and lazy in it's next two.  Consider something like: if b calc1 calc2 + 10.  What would the transitions look for that? or what would be the difference from a lazy by default language?
09:52:54 <esap> I think the difference would be that the type system would enforce that the sublanguages would not be mixed arbitrarily.
09:53:23 <Darius> Okay, but I would like to be able to write something like the above; how would I do it?
09:53:47 <esap> I don't really know what effects it really has [I would have to know the design of those sublanguages already for that]
09:54:27 <esap> I think conditionals can be implemented in such system using the control operation.
09:55:19 <esap> which would be "strict" side operation only.
09:55:28 <Darius> Well, if the language isn't pure than this is a different issue.
09:56:18 <esap> well I think the two sublanguages don't need to provide the same things. One might be pure, another might not. I'm not really sure which facilities fall into which sublanguage.
09:56:59 <esap> But I would expect that very few operations are applicable for both.
09:58:58 <esap> And I would also expect that those sublanguages should take different stand on all such important questions like pure vs. impure.
09:59:11 <Darius> If I can't force anything in the lazy sublanguage, it's useless.  If you have a 'force' function or something equivalent that transitions to the strict language then how would that be any better than simply providing the strict operation in the lazy sublanguage?
10:00:25 <esap> consider the function application. What if the function part was written in one language and the argument part in another. That's not exactly a "force" function, but I think it can do this transition.
10:01:39 <ibid> no, it can't work that way
10:01:42 <Darius> Then how do I tell if b t e + 10 from a function that's completely in a lazy-by-default language?
10:01:58 <ibid> the function has to be strict and the argument nonstrict for it to be a force operation
10:02:47 <ibid> (hmm, eager and lazy would be more appropriate here)
10:05:38 <esap> darius: I would expect the typing would indicate it somehow. Strictness annotation like thing.
10:06:16 <esap> darius: but enforced in a type system.
10:07:35 <esap> I think this somehow is related to mono vs. epi distinction in category theory, but I don't really undestand the connection well enough.
10:08:29 <ibid> something i am planning is a strict language with a type modifier (sort of like C's storage class specifiers) "delayed"
10:08:37 <ibid> eager language that is
10:08:38 <Darius> esap: To what end? (re: type system)
10:09:45 <esap> darius: well my point is that if you can express this kind of powerful concepts in the type system, then the compiler would (if it's still decidable) be able to enforce much better that programs behave as they should [like for example for performance].
10:11:17 <Darius> What do you intend to -enforce-?
10:12:06 <esap> darius: Distinctions between different concepts. That programmer's wouldn't be able to confuse such concepts from each other. I do it all the time, and I hate it :-)
10:12:53 <esap> I want the programming language to enforce that I don't make conceptual mistakes when I design the system.
10:12:57 <Darius> That's nice, but doesn't answer my question.  What would it disallow?
10:14:56 <esap> Well like it would disallow using 'length' on a coalgebraic data type.
10:15:21 <esap> like that infinite list.
10:16:04 <Darius> And if it is a finite list?
10:16:12 <esap> Then it would work as always.
10:17:09 <esap> it would go through the data structure and count the elements.
10:18:02 <ibid> esap: how would it know that it is infinite?
10:18:15 <Darius> Either the coalgebraic "infinite list" is like data InfList a = Cons a (InfList a) in which case it's quite obvious that length won't terminate or it's has a Nil summand in which case it isn't obvious until runtime that it won't terminate (namely when it doesn't terminate).
10:18:30 <esap> ibid: I have to know this when you construct the structure, and distinguish coalgebraic things from algebraic things in types.
10:18:41 <ibid> Darius: it won't be obvious at runtime :)
10:20:00 <esap> I think the 'data InfList a = Cons a (InfList a)' would be a coalgebraic version of the ordinary list.
10:20:32 <ibid> esap: (i have no idea what algebraic and coalgebraic are in this context) that either allows a finite list in an infinite-list type or an infinite list in a finite-list type, unless you really intend to allow only primitive recursion in the finite-list type
10:20:52 <Darius> So is data List a = Nil | Cons a (List a) in Haskell (the type of finite and infinite lists)
10:22:23 <esap> actually, Haskell lists would probably be represented as "Either (InfList a) (FiniteList a)' or something.
10:23:01 <ibid> Darius: i mean, unless the list is a knot, you can't tell it's infinite even at runtime :)
10:23:07 <ibid> in general
10:23:58 <Darius> ibid: I agree, I was just emphasizing that it would be undecidable.
10:24:03 <ibid> true
10:24:12 <ibid> semidecidable:)
10:25:41 <esap> I think I'm ready to accept that some things are restricted to be less powerful than universal (I don't really buy the argument that it's sufficient to just have everything as powerful as possible).
10:26:37 <esap> The point is, if you get more power, you lose properties that you can prove. I want both :-)
10:27:58 <esap> And then I want to ensure that you can't use properties that the system can't provide.
10:28:46 <Darius> What properties do you lose by have a non-strict language?
10:29:39 <esap> Well non-strict is a property already, so you lose power due to that.
10:29:58 <Darius> What?
10:33:14 <esap> Hmm.. I'm not sure what kind of power would be lost by that. But I think it's fundamental thing that different properties that you can prove from programs do always come with the cost of expressivity [if you want correctness].
10:33:58 <esap> Like recursion and non-termination are a good example.
10:34:40 * esap doesn't really have the full picture.
10:38:20 <esap> This is one rationale why I began to read about duality. I suspect one side is about those properties and another is about the power.
10:39:19 <ibid> primitive recursion always terminates :)
10:39:49 * esap means general recursion by recursion usually.
10:40:47 <ibid> most of the time, you only need primitive recursion :)
10:42:35 <esap> true, which is why I believe this scheme might work. I think there are some people who think that every system should be at least as powerful to include general recursion to be useful. Needless to say, I disagree with that kind of thing.
10:43:07 <ibid> i believe there are some useful algorithms that are not expressible in primitive recursion
10:44:15 <esap> And also, I think there are more to the recursion thing than just primitive recursion vs. general recursion.
10:44:33 <ibid> yes
10:44:56 <ibid> there are some stages between, i've seen them mentioned but know almost nothing about them
10:45:04 <ibid> ah, the things they don't teach me here...
10:45:14 <ibid> didn't, rather
10:45:43 <esap> Well I've also found very little about it.
10:47:24 <esap> But I'd expect those would provide some insight on what should be done with the type systems. I'd really like to see a type system that would provide _either_ properties about programs _or_ power, but ensure that programmer never tried to do both.
10:47:54 <Smerdyakov> ERROR: 56.7-58.24: illegal use of power.
10:47:59 <ibid> hehe
10:48:02 <ibid> what's that?
10:48:09 <esap> heh, exactly!
10:48:32 * esap is considering an operation with the name 'power' :-)
10:48:41 <ibid> debian/rules
10:48:42 <ibid> :)
10:48:44 <ozone> esap: i think it's the other way around
10:48:59 <Smerdyakov> OH YEAH? Well, I admit elimination of quantifiers in the wider sense!
10:49:01 <ozone> esap: you can express more with laziness than you can with strictness
10:50:49 * esap goes to get something to eat. bbl.
10:51:27 <Smerdyakov> ozone, I don't believe that.
10:52:38 <ozone> Smerdyakov: sure.  why not?
10:53:29 <Smerdyakov> ozone, well, what's an example of this?
10:53:40 <ham[home1> is there some nice ide for haskell?
10:54:02 <ozone> Smerdyakov: things you can do with type classes and passing around undefineds
10:54:13 <ozone> so that you can get the type checker to accept some things
10:55:22 <Darius> ham[home]: There's hIDE, but I think most people use emacs/vim/their favorite editor.
10:55:34 <Smerdyakov> That's a type system issue, and you can obviously get around it in any language by coding a Haskell interpreter in it.
10:55:45 <ham[home]> Darius: is there a site for hide i wanst able to find it really
10:55:59 <ozone> Smerdyakov: but it's still a valid example, i think
10:56:35 <ozone> i mean, you have this semantic difference between lazy/non-lazy languages, in that you have this new value _|_ which can be of any type, right
10:56:36 <Smerdyakov> ozone, I don't know. You're not using any sort of formalizable meaning of "expressive," as far as I can tell, which makes this a little difficult to argue one way or the other!
10:56:39 <ibid> i think he's not talking about the algorithmic sense of expressibility
10:56:44 <ozone> Smerdyakov: very true
10:57:26 <Darius> ham[home]: Perhaps you should look at haskell.org. hIDE isn't exactly hidden away.
10:57:46 <ozone> so i would think that because of this difference, it should follow that you can express at least different things
10:57:57 <ozone> and probably that laziness allows you to express more
10:58:04 <ham[home]> Darius: k sry i used google ...
10:58:15 <ozone> ibid: i think i mean "express" in the sense of "you can express more with dynamic types than you can with static types"
11:00:36 <Darius> If I remember correctly, in Felleisen's paper strict and non-strict were incomparable.
12:45:44 <Jad>  /nickserv identify jad@saklawi.info
12:45:46 <Jad> oops
12:56:14 <Smerdyakov> OK, that's a weird password.
12:58:25 <Jad> lol
12:58:27 <Jad> it is my email
12:59:03 <Smerdyakov> That's not how you use identify!
12:59:37 <Jad> ?
12:59:38 <Jad> that is my password
12:59:53 <Jad> i was identifying, but by accident i typed a space before /
12:59:58 <Jad>  /
13:00:37 <dark> Ah, and you even list the email address in nickserv info, for the convenience of people who want to take over your nick.
13:01:05 <ibid> hmm
13:01:52 <Jad> dark this is a friendly network
13:02:06 <Jad> who the hell cares to take my nick
13:02:14 <Jad> any way just changed the passwd
13:02:21 <dark> Well... I did when someone took mine.  Took me a while to get it back.
13:02:26 <Jad> now it is two letters :P
13:02:48 <Jad> how did you get it back /
13:02:49 <Jad> ?
13:03:25 <dark> I waited for it to be unused for long enough.  It was a student so he went on summer vacation.
13:04:14 <Jad> ah okay
13:04:27 <Jad> so their is no way for password recovery if passwd was changed ?
13:06:04 <dark> What kind of recovery do you mean?  The network admins can see the password.
13:07:30 <Jad> no like if some one out here in the channel had killed me, and changed my passwd
13:07:49 <Jad> would it have been ppssobe for me to recover the nick ?
13:08:30 <ibid> how would anybody verify it's you and not the other person who really owns the nick?
13:08:36 <ibid> if not by using the password
13:09:03 <Smerdyakov> Wow. "ppssobe."
13:09:07 <Jad> well i remember on dalnet
13:09:15 <Jad> you can send the passwd to the email
13:09:52 <ibid> Jad: the attacker surely will change the email
13:10:31 <Jad> k..
13:11:50 <dark> Hmm.  Changing a tuple type to a named datatype is a surprisingly good way to get unstuck.
14:33:32 <stepcut> anyone gotten HOpenGL to compile under FreeBSD/ghc6
14:34:50 <steveh> good evening
14:36:11 <stepcut> evening
14:37:40 <steveh> does anyone happen to know of a good reading on continuation-passing style?
14:41:22 <stepcut> hrm
14:43:54 <stepcut> i read one once, but I can't find it
14:44:11 <steveh> heh
14:44:13 <steveh> well
14:44:16 <steveh> if you see it again, let me know :)
14:44:24 <stepcut> but thanks for mentoning it, I think I know how to solve a problem I have been working on :)
14:45:08 <steveh> excellent!
14:45:25 * Riastradh returns from LL3.
15:26:08 * esap goes see an eclipse.
16:17:06 <skew> good morning
16:17:43 <skew> is anyone on?
16:17:48 <clausen> yep
16:18:06 <skew> I'm trying to build GHC 6.3 from CVS
16:18:22 <skew> but it's getting the dependencies wrong or something
16:19:47 <clausen> I've never used ghc (!)
16:20:24 <skew> what do you use?
16:20:42 <clausen> I used to use hugs
16:20:48 <clausen> I haven't written much haskell code lately
16:20:52 <skew> Oh.
16:20:54 <skew> Sorry
16:21:27 <skew> Did you find something more interesting, or just more profitable?
16:21:54 <clausen> I haven't been writing much code lately
16:22:00 <clausen> just a bit in python for uni
16:22:05 <clausen> I've mostly been doing maths :)
16:22:30 <skew> I'm just arranging a double major. But I do more computers than math.
16:22:57 <skew> I haven't been coding much either, but I had some time this weekend
16:23:33 <skew> I've been playing around with odd typeclasses, an 6.3 helps
16:24:40 <skew> It build once, but none of the new versions I've pulled from CVS worked.
16:24:55 <skew> Ah well. Better go grade. Thanks
16:46:10 <dark> Greetings
19:17:31 <mariano> a bit OT: anyone know of a `real' (as in not `toy') imperative language with polymorphic types?
19:24:15 <clausen> ocaml?
19:24:21 <clausen> (it's kind of functional, but not really)
19:28:47 <ayrnieu> You can certain write imperative code in ocaml.
19:29:08 <ayrnieu> ly.  It has a very good book online, too.
19:37:20 <SyntaxLaptop> anyone care to critique a parsec parser of mine?
19:39:52 <Smerdyakov> Maybe you should find a parser critiquing focus group
19:40:40 <SyntaxLaptop> anyone care to help me find a parser critiquing focus group?
19:40:44 <SyntaxLaptop> It's a SMALL parser, btw
19:40:52 <SyntaxLaptop> I'm just thinking that it looks suboptimal
19:41:16 * SyntaxLaptop has to write parsers all the damn time
19:41:27 <SyntaxLaptop> it seems like anything worth doing requires a parser
19:41:35 <SyntaxLaptop> but this is my first time using parsec
19:46:35 <stepcut> mariano: nice.sf.net
20:16:21 <phubuh> mariano: I use OCaml all the time. :-) *hides*
21:22:51 <isomer> SyntaxLaptop: care to post it somewhere?
21:32:37 <SyntaxLaptop> isomer: sure :)
21:33:23 <SyntaxLaptop> http://www.syntaxpolice.org/tmp/Package.hs
21:33:28 <SyntaxLaptop> There's a lot of unrelated stuff there
21:33:39 <SyntaxLaptop>  look at the unit tests toward the bottom (which all pass)
21:33:53 <SyntaxLaptop> all I'm doing w/ parsec right now is parsing version numbers
21:34:09 <SyntaxLaptop> of either form major.minor-patch (1.2-3) or some date forms
21:34:34 <SyntaxLaptop> one part I really don't like is the parser that goes from short month strings to months
21:38:40 <isomer> yeah, date parsing is pretty hard
21:39:17 <SyntaxLaptop> fortunitely, I don't need to support everything under the sun.
21:39:38 <isomer> especially the mess that is mm/dd/yy or dd/mm/yy :)
21:40:29 <SyntaxLaptop> yeah. the One True Way is yyyy/mm/dd since that sorts nicely
21:40:46 <isomer> agreed
21:41:20 <isomer> doubly nice because if you go yyyymmdd it not only sorts nicely, but it can be stored as a long integer :)
21:41:42 * isomer has played knifey spoony before
21:41:54 <SyntaxLaptop> knifey spoony?
21:42:02 <isomer> the date game
21:42:26 <isomer> (it's from the simpsons -- amazing that i know it, considering i haven't owned a tv in years)
21:42:43 <SyntaxLaptop> hehe.
21:42:50 * SyntaxLaptop doesn't have a t.v. either, but likes the simpsons :)
21:43:42 <isomer> meh...looks OK to me. i unfortunately don't know enough haskell yet to give you any meaningful advice...
21:44:45 <isomer> if it was me, and in a language i knew better, i'd keep two parallel arrays, one with Jan Feb Mar .. and the other with January February March ... and just use the index into the short array to point to the word in the long array
21:44:48 <SyntaxLaptop> OK. Thanks.
21:44:58 <isomer> but i don't really know if that's a haskell-ish way to do things
21:45:25 <SyntaxLaptop> isomer: yeah, that makes sense, then that function would be a mapM of <|> or something
21:45:37 <isomer> *nod*
21:45:48 <isomer> and you could presumably squish it into one statement instead of 12
21:46:26 <SyntaxLaptop> I'll do that once I decide that the function is correct in the first place.  I know it seems to work, but not convinced that this is how one is supposed to structure such a thing in parsec.
21:47:05 <isomer> parsec is basically recursive descent?
21:47:35 <SyntaxLaptop> no, not quite. it can backtrack
21:48:05 <isomer> oh, right. that's how all those trys work...
21:49:11 <SyntaxLaptop> yup
21:49:40 <isomer> what's the general class of backtracking parsers called? do you remember?
21:50:47 <Smerdyakov> GLR?
21:51:02 <isomer> hmm
21:51:58 <isomer> is it indeed producing a right-most derivation?
21:52:06 <isomer> (not that it really matters)
23:15:13 <Brandon_> I'm not sure if I understand Monads enough, but so far I'm not sure if there is a way to retrieve a value of type a from a value of type IO a
23:16:45 <_rubix> No, you cannot do that.
23:16:50 <Brandon_> If not it would seemingly make modular functions that rely on I/O impossible to implement
23:16:57 <Brandon_> but maybe that is the point?
23:18:19 <_rubix> the point is to make the presence of side effects explicit directly at the type level
23:18:56 <_rubix> but I don't see why you think modular fonctions that rely on IO would be impossible
23:20:16 <Brandon_> i'm new to haskell and monads in general, so i'm sorry if I'm missing something obvious, but say I want a function that gets an Integer from the "world", does something complicated to it, and then the resulting Integer needs to be used in another function
23:20:18 <dennisb> Brandon_: you can get the value of type a, but you can only use it to create another IO thingy.
23:21:26 <dennisb> the operatior >>= has type (for IO): IO a -> (a -> IO b) -> IO b
23:22:17 <dennisb> that is, the left argument is the IO a operation and the right is a function that takes the a and create some other IO operation, the right function can do what it wants with the a
23:22:25 <_rubix> you can do that using (>>=) (or the do construct), but "another function" needs to keep the "IO" in its type signature
23:22:36 <Brandon_> i see
23:22:46 <Brandon_> thanks for the explanation guys
23:23:00 <shrimpx> once you're in IO land you stay there :)
23:23:17 <Brandon_> yeah haha, that was the impression i was getting
23:23:36 <dennisb> yes, if you have a function f then inside it somewhere do some IO, then the type of f must also include some IO in the type
23:26:23 <Brandon_> i guess that's not so bad ... it seemed that way until I realized most of my programming was being done for the interactive environment up until now
23:26:57 <Brandon_> actually i'm using Curry but the functional parts of it are basically taken straight from haskell
23:30:11 <Brandon_> the downside for a user like me is the lack of other users and libraries at this point, although once the language is finalized I imagine people will probably worry more about porting Haskell libraries to curry
23:31:15 <dennisb> haskell might have more libraries then curry, but I think libraries is the problem of haskell as well
23:32:01 <Brandon_> how do you mean?
23:33:36 <dennisb> I mean haskell needs more libraries (or rather bindings to libraries)
23:35:02 <Brandon_> oh yeah i agree ... which ones are you in want of in particular?
23:39:24 <shrimpx> whichever ones would help in solving the problem you're working on :)
23:41:57 <Brandon_> bbl
