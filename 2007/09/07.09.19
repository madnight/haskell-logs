00:00:03 <Olathe> glguy: I suppose The Who could help.
00:00:07 <glguy> > let who_polices x = x ++ " police police " ++ x in who_polices "police police police"
00:00:08 <lambdabot>  "police police police police police police police police"
00:03:16 <ttfh> there are
00:03:31 <wli> So basically there's (k, w, [A,B,C,...]) attributed to [A,B,C,...] !! k
00:03:42 <ttfh> part-of-speech analysers that could pick out the adjectives
00:19:54 <Korollary> welcome to comcast, dons.
00:22:22 <Syzygy-> Cale: How is that? (that any element of Buffalo* is a grammatically correct sentence?)
00:22:26 <scodil> does anyone know what the performance advantage would be like, if any, for representing statically-sized vectors with a type (C !a !b) with UNPACK pragmas, for instance a 3 vector would be (C a (C a (C a ()))). If you do type-level maps and folds and such with those vectors, will it all compile out to flat code? Or will it still end up consing those things, and end up copying more because of the unpacking?
00:22:34 <kolmodin> > let p x = "polis polis potatis" ++ x in p "mos"
00:22:35 <lambdabot>  "polis polis potatismos"
00:22:52 <Cale> Syzygy-: see http://en.wikipedia.org/wiki/Buffalo_buffalo_Buffalo_buffalo_buffalo_buffalo_Buffalo_buffalo
00:22:55 <lambdabot> Title: Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo - Wikipedia, the ..., http://tinyurl.com/zsxl4
00:23:27 <glguy> looks like ghc isn't ready for compiling my current work project
00:23:36 <glguy> ghc-6.8.0.20070918: panic! (the 'impossible' happened)
00:24:20 <Syzygy-> Ah.
00:24:27 <Syzygy-> I was unfamiliar with the verb buffalo.
00:24:43 <pjd> is that what the "Haskell makes hard things easy, and the impossible just happened" quote refers to? :)
00:25:09 <Cale> pjd: yesz
00:25:13 <Syzygy-> Cale: But can it work for any length? Don't you get some sort of non-1-length quantisation in it?
00:25:14 <Cale> -z
00:25:57 <glguy> hmm, I went back and rebuilt some of the libraries it used for that file
00:26:00 <glguy> and now things are ok
00:26:04 <glguy> I guess I screw up some how
00:26:22 <glguy> *ed
00:28:04 <Cale> Syzygy-: non-1-length quantisation? Essentially you get longer and longer chains of buffalo buffaloing other groups of buffalo
00:29:06 --- mode: ChanServ set +o Cale
00:29:14 --- mode: Cale set +b backco!*@*
00:29:22 <Syzygy-> Cale: But how do you get increases of size 1?
00:29:55 <Syzygy-> Hang on .... you can probably just move more and more buffalos into Buffalo and in the end tack on a new VP, right?
00:30:41 <FMota> nighty night
00:32:29 <ketil> Hah!  ssh tunnelling r0X, Y0z f1r3w411 1z p0wnd.  L33t is me.
00:33:22 <ketil> Ahem, topic, yes.  I think I have a good use case for DPH, but my arrays (currently lists) are sequential - i.e. the n+1th element depends in part on the nth.  Possible?
00:33:30 <Cale> hmm, perhaps you can't straightforwardly increase the length by 1, but you can certainly increase it by 3 with a relative clause "Buffalo buffalo buffalo" modifying some buffalo that are already mentioned. Then all you need is a good way to increase it by 2 (or something small and coprime with 3)
00:33:40 <ketil> I thought I thaw ..sorry, saw a fold in there.
00:37:56 <Cale> oh of course, "buffalo buffalo" works as an RC too.
00:38:57 <lament> malkovich malkovich?
00:42:05 --- mode: Cale set -o Cale
00:42:29 <Cale> hmm
00:42:32 --- mode: ChanServ set +o Cale
00:42:39 --- mode: Cale set -b backco!*@*
00:42:57 --- mode: Cale set -o Cale
00:45:55 <Cale> http://specgram.com/CLI.2/03.bakery.disorder.html
00:45:56 <lambdabot> Title: SpecGram&mdash;New speech disorder linguists contracted discovered!&mdash;Yreka  ...
00:47:31 <Olathe> Do spambots fill in password fields ?
00:48:15 <Cale> Olathe: I think in many cases, the first run is human guided, and thereafter automated.
00:48:27 <Olathe> Ahh.
00:53:57 <Olathe> Could you put a http://hpaste.org/randomthingy link in the topic ?
00:55:06 <glguy> Olathe: that seems like a reasonable implementation of putting a password in the topic
00:55:23 <glguy> Olathe: and instead of maintaining the topic
00:55:26 <glguy> hpaste, url
00:55:26 <hpaste> Haskell paste bin: http://hpaste.org/
00:55:29 <glguy> still could work
01:13:56 <arnuld> Hi all
01:14:02 <arnuld> this is my 1st day with Haskell
01:14:14 <arnuld> I came from C++ background
01:14:24 <arnuld> wandered through Common Lisp
01:14:41 <arnuld> just wanted to say "HI"  :-)
01:14:54 <dolio> Well, you have our condolences.
01:15:13 <arnuld> condolences ?
01:15:18 <arnuld> for what ?
01:15:36 <tuxplorer> What NLP libraries are available in Haskell?
01:15:51 <dolio> For being subjected to such languages until now, of course. :)
01:16:06 <arnuld> C++ is really bad , that's true
01:16:11 <arnuld> but not Commono Lisp
01:16:23 <arnuld> Common Lisp is great
01:16:53 <arnuld> ot to mention VB a.k.a. nonsense
01:16:56 <arnuld> :P
01:17:18 <arnuld> brb
01:18:25 <tuxplorer> Any idea when visual Haskell is coming with M$'s .NET platform?
01:18:35 <dolio> Heh.
01:18:58 <dolio> You mean shipped by MS?
01:19:11 <dolio> I don't think it's even a MS project.
01:19:51 <araujo> arnuld, welcome
01:20:06 <dolio> MS' big functional language is F#, but even it's stuck in the research areas.
01:20:15 <araujo> arnuld, pretty much what a new user to Haskell need to start is at www.haskell.org
01:20:17 <quicksilver> dolio: it was produced (partly) by people who are employed by MSR. Not the same thing, of course.
01:20:23 <matthew-_> so MS pay certain haskell developers/researchers at MSR Cambridge. Yet they wrote F#. Clearly they have great commitment to Haskell
01:20:45 <araujo> arnuld, i recommend you to take a look , check the tutorial/book section and keep around the channel in case of any doubt :-)
01:22:09 <tuxplorer> any NLP libraries available in Haskell? Something like a library that uses some database of words to detect the types of words(like noun, verb,etc) or something similar
01:23:31 <mcnster> anyone awake?
01:23:58 <arnuld_> ya
01:23:59 <arnuld_> me
01:24:00 <arnuld_> :P
01:24:08 <mcnster> cool.  know anything about fgl?
01:24:22 <arnuld_> fgl ? .... NO
01:24:33 <arnuld_> i am a pretty newbie
01:24:40 <mcnster> that sounds definitive ;)
01:25:15 <arnuld_> I read about Haskell at its Wiki, I was compelled to try to it :)
01:25:18 <mux> thte functional graph library?
01:25:22 <quicksilver> tuxplorer: http://www.haskell.org/haskellwiki/Applications_and_libraries/Linguistics
01:25:24 <lambdabot> Title: Applications and libraries/Linguistics - HaskellWiki, http://tinyurl.com/2aaeeg
01:25:37 <mcnster> hi mux :) yes
01:26:08 <mux> I've played with it in ghci one time, I don't have more experience with it than that :)
01:26:09 <mcnster> either i'm going crazy or i'm missing some fundamental clue....
01:26:38 <arnuld_> youa re missing Haskell Coding ;-)
01:26:42 <arnuld_> like me
01:27:06 <mcnster> i need Cale me sort this out
01:27:16 <mcnster> to help me
01:27:39 <Cale> mcnster: what's up?
01:27:47 <mcnster> Cale! :))))
01:28:50 <mcnster> i'm trying to figure out what is essentially wrong with making g' = gmap f g where f (ins, n, l, outs) = (ins, n, l', outs)
01:29:00 * tuxplorer kisses Haskell for its wealthy libraries and ease of programming complex stuff 
01:29:03 <tuxplorer> Thanks quicksilver
01:29:36 <mcnster> i recall you saying that there could be a problem if identity was involved
01:30:33 <Cale> No, that'll work fine. It'll construct a new graph where the labels have changed.
01:32:19 <mcnster> then i think my problem has to do with lazyness because when i "print g'" i get a result that can't possibily derive from g.
01:32:39 <quicksilver> that doesn't sound related to lazyness
01:33:32 <mcnster> specifically in the above l' = case length ins == 0 of True -> [Foo] False -> []
01:33:53 <Cale> yeah, that doesn't seem likely -- when a result is returned, lazy and strict evaluation give the same answer
01:34:28 <Cale> It's only in the cases where strict evaluation would go into an infinite loop or die that lazy evaluation gives a different result.
01:35:10 <mcnster> i print the graph g and it appears as i expect.  i print g' and its as if many 'ins' evaluated to [].  But i KNOW this is not the case!
01:35:46 <Cale> You know that graphs can be decomposed into contexts in a variety of ways, right?
01:35:47 <quicksilver> for those of us following along at home, where can I find the fgl docs?
01:35:55 <mcnster> Cale, yes
01:35:57 <quicksilver> @where fgl
01:35:57 <lambdabot> http://www.cs.orst.edu/~erwig/fgl/
01:37:51 <mcnster> could the usage of DynGraph as different from Graph be an issue?
01:39:37 <mcnster> i'm baffled.  i know my code may be decidedly unhaskellish, but i expect it to survive my funkyness :)
01:40:13 <Cale> mcnster: I might be able to help more if you can give me something that I can actually run :)
01:40:41 <mcnster> ok, you asked for it.  its one file from hell ;)
01:40:55 <Cale> Could you construct a small test case?
01:42:05 <Cale> DynGraph is required for gmap btw
01:42:34 <mcnster> Cale, when you say DynGraph is required, should that change my code at all?
01:42:39 <Cale> no
01:42:46 <Cale> unless you can't compile your code at all
01:42:48 <mcnster> i didn't think so
01:42:57 <Cale> The DynGraph class captures the sort of graph types that can be broken up into contexts
01:43:39 <mcnster> it compiles fine.  it runs as expected, EXCEPT when i take the result of a nasty nasty recursive function that constructions g and map it to g'.
01:43:57 <mcnster> s/ions/s/
01:44:09 <boudewijn> hi
01:44:18 <Cale> hello
01:44:40 <boudewijn> I've got a question concerning checking two lists of Ints against each other
01:44:48 <Cale> sure
01:44:55 <boudewijn> length of both is 4
01:44:55 <Cale> What's the question?
01:45:31 <boudewijn> It's for a mastermind game, I need to compute how many times an element of the first list exists in the second
01:45:32 <mcnster> Cale, is there anywhere i can send a zip file of the file and the dataset?  i'm pretty sure you're going to look at it and say "you can't do that"--i just need to know where and why....
01:46:02 <Cale> boudewijn: you probably want to use filter and elem, along with length
01:46:15 <boudewijn> so if I put in [1,2,3,4] [1,2,3,5] I need to get 3 as result , due to having 3 coincidences
01:46:21 <boudewijn> aha
01:46:26 <boudewijn> I'll have a look
01:46:41 <boudewijn> also [4,3,1,2] [1,2,5,3] has to result in a 3
01:47:06 <quicksilver> so order doesn't matter?
01:47:13 <boudewijn> indeed
01:47:18 <quicksilver> have you looked at the function 'intersect' ?
01:47:22 <quicksilver> :t intersect
01:47:24 <lambdabot> forall a. (Eq a) => [a] -> [a] -> [a]
01:47:28 <tuxplorer> let getTokens x = splitRegex (mkRegex "#$") x
01:47:29 <tuxplorer> let x="Foo#$Bar#$"
01:47:29 <tuxplorer> Now calling getTokens x gives ["Foo#$Bar#$"].. Why doesn't it split properly? any problem with the regex expression? $ implies at last or some special meaning? I even tried using escape character \ but it throws error
01:47:37 <Olathe> > intersect [1, 2, 3, 3] [1, 2, 3, 3]
01:47:38 <lambdabot>  [1,2,3,3]
01:47:44 <boudewijn> well also the first list needs to contain solely unique values
01:47:44 <quicksilver> > intersect [1,2] [2,3]
01:47:45 <lambdabot>  [2]
01:48:14 <tuxplorer> > let getTokens x = splitRegex (mkRegex "#$") x
01:48:14 <lambdabot>  Parse error
01:48:14 <boudewijn> but I'm able to do so after intersect
01:48:14 <boudewijn> thanks for the hint!
01:48:14 <tuxplorer> > getTokens x = splitRegex (mkRegex "#$") x
01:48:14 <lambdabot>  Parse error
01:48:23 <quicksilver> tuxplorer: yes, '$' means end of string
01:48:29 <Olathe> > intersect [1, 2, 3, 3] [1, 2, 3]
01:48:31 <lambdabot>  [1,2,3,3]
01:48:42 <Olathe> @src intersect
01:48:42 <lambdabot> intersect = intersectBy (==)
01:48:45 <Olathe> @src intersectBy
01:48:45 <lambdabot> intersectBy eq xs ys = [x | x <- xs, any (eq x) ys]
01:48:45 <boudewijn> nice thanks
01:48:48 <boudewijn> is it in Prelude?
01:48:52 <quicksilver> yup
01:48:57 <quicksilver> or Data.List
01:48:59 <quicksilver> can't remember :)
01:49:04 <tuxplorer> quicksilver: how to mean the literal $? what is the escape character here? using \ lexical error in string/character literal at character '\\'
01:49:09 <quicksilver> Data.List, it seems like
01:49:14 <Cale> let getTokens x = splitRegex (mkRegex "#\\$") x
01:49:16 <quicksilver> tuxplorer: you use \, but...
01:49:30 <quicksilver> tuxplorer: first you have to get the \ past the haskell string escape mechanism
01:49:40 <Sizur> > intersectBy (<) [1,2,3,4] [1,3]
01:49:41 <lambdabot>  [1,2]
01:49:46 <Cale> boudewijn: Data.List
01:49:51 <boudewijn> thanks!
01:50:02 <quicksilver> tuxplorer: "\$" is a haskell syntax error
01:50:13 <quicksilver> tuxplorer: "\\$" is the string consisting of one \ followed by one $
01:50:28 <tuxplorer> quicksilver: Cale: ok. I get it now. Thanks :)
01:50:34 <quicksilver> layers of escaping are horrible :(
01:50:48 <Sizur> yeah perl really shines there
01:51:17 <kfish> http://www.joelonsoftware.com/items/2007/09/18.html vs. http://haskell.org/haskellwiki/Yhc/Javascript :-/
01:51:17 <lambdabot> Title: Strategy Letter VI - Joel on Software
01:53:03 <Sizur> q,qq,qr
01:53:03 <quicksilver> Sizur: true, it helps a bit
01:53:03 <quicksilver> >  splitRegex (mkRegex "#\\$") "Foo#$Bar#$"
01:53:03 <lambdabot>   Not in scope: `mkRegex'
01:53:03 <quicksilver> must get dons to pull Text.Regex into scope
01:53:03 <quicksilver> @tell dons Would be nice to have Text.Regex in scope for lambdabot
01:53:03 <lambdabot> Consider it noted.
01:53:35 <Olathe> > let matches [] _ = 0; matches _ [] = 0; matches xxs@(x:xs) yys@(y:ys) = if (x < y) then (matches xs yys) else if (x > y) then (matches xxs ys) else (1 + (matches xs ys)) in (matches [1, 2, 3, 3] [1, 2, 3, 4])
01:53:37 <lambdabot>  3
01:55:22 <KatieHuber> > sum $ zipWith (\a b -> fromEnum (a == b)) [1, 2, 3, 4] [1, 2, 3, 5]
01:55:22 <lambdabot>  3
01:55:22 <quicksilver> > length . filter (==True) $ zipWith (==) [1,2,3,3] [1,2,3,4]
01:55:22 <lambdabot>  3
01:55:22 <KatieHuber> a million different answers^_^
01:55:22 <quicksilver> KatieHuber: I think fromEnum is probably evil
01:55:22 <tuxplorer> couldn't find dons as frequently as before nowadays! he used to be there all time on this channel sometime back..
01:55:22 <Olathe> It has to work with [1, 2, 2, 3] [1, 2, 3, 4]
01:55:36 <Olathe> And give 3.
01:55:49 <osfameron> Sizur: yay!  verily, Perl's string quoting and interpolation is a thing of joy, most of the time.
01:55:51 <quicksilver> KatieHuber: the mapping it gives should be considered arbitrary; it feels wrong to rely on fromEnum True being 1
01:56:04 <quicksilver> tuxplorer: he moved timezone and got a job :P
01:56:18 <quicksilver> Olathe: that's just length $ intersect IMO
01:56:43 <tuxplorer> quicksilver: oh! ok :)
01:56:53 <Olathe> That doesn't work with [1, 2, 3, 3] [1, 2, 3, 4]
01:57:06 <Olathe> > length $ intersect [1, 2, 3, 3] [1, 2, 3, 4]
01:57:08 <lambdabot>  4
01:57:20 <quicksilver> ah, I see what you mean
01:58:57 <quicksilver> > (\l m -> length l - length (l \\ m)) [1,2,3,3] [1,2,3,4]
01:58:58 <lambdabot>  3
01:59:11 <Olathe> @src (\\)
01:59:11 <lambdabot> (\\) = foldl (flip delete)
01:59:24 <quicksilver> '\\' has a multiset interpretation of difference which is what you want here, although it's inconsistent with intersect, interestingly
01:59:46 <quicksilver> > [3,3,3] \\ [3,3]
01:59:48 <lambdabot>  [3]
01:59:59 <Olathe> > [3, 3, 3, 3] \\ [3]
02:00:00 <lambdabot>  [3,3,3]
02:00:03 <Olathe> Neat :)
02:00:59 <Olathe> @src flip
02:01:00 <lambdabot> flip f x y = f y x
02:01:26 <Olathe> @src foldl
02:01:26 <lambdabot> foldl f z xs = lgo z xs
02:01:26 <lambdabot>     where lgo z []     =  z
02:01:26 <lambdabot>           lgo z (x:xs) = lgo (f z x) xs
02:03:34 <hpaste>  mcnster pasted "mayday mayday" at http://hpaste.org/2813
02:03:40 <Olathe> Neat :)
02:04:27 <mcnster> Cale, in my example, could slurpData be at fault?
02:06:26 <Cale> mcnster: to answer your first "WHY?" it's because the context containing the vertex 1576 had no inarcs in it.
02:07:22 <mcnster> but it does, from vertex 1574
02:08:34 <Cale> That doesn't mean that there are no inarcs to the vertex at all
02:08:52 <Cale> It just means there were none in the context which contained that vertex.
02:09:51 <Cale> That inarc to 1576 might be represented by an outarc from 1574.
02:09:59 <Cale> (in 1574's context)
02:10:13 <mcnster> ohferchristsake
02:11:18 <Cale> does that make sense?
02:12:09 <Cale> the labelling the particular function you're using gives to the result depends on how the graph is broken up into contexts
02:12:15 <mcnster> it makes sense as an explanation of why, but then i don't understand how i can hope to iterate g to find nodes with no inarcs
02:14:07 <Cale> Use the function pre
02:14:31 <mcnster> so you're saying the set of contexts on a graph do not overlap.  i grok that now
02:15:38 <Cale> initials g = filter (null . pre) (nodes g)
02:16:07 <mcnster> thank you SO MUCH, Cale.  such a simple idea eluded me.
02:16:47 <quicksilver> it is counterintuitive that gmap doesn't work over any 'canonical' interpretation of context, IMO
02:16:47 <mcnster> yes i see that.  there are several ways for me to get what i need
02:16:55 <quicksilver> it makes it easy to write non-deterministic functions
02:17:20 <quicksilver> (in the sense that they depend on decomposition, which in turn depends on non-exposed details of the Graph representation, so essentially non-deterministic to the user)
02:17:34 <mcnster> quicksilver, agreed
02:19:31 <mcnster> ok, back to it.  many thanks and goodnight.
02:20:00 <Cale> Well, if you really wanted to make everything deterministic, you could change contexts so that they only ever mention outarcs
02:20:09 <quicksilver> yes, for example
02:20:14 <Cale> But I think you'd ruin the complexity of certain algorithms
02:20:16 <quicksilver> that's the kind of thing I meant by 'canonical'
02:20:32 <quicksilver> yes, I'm sure that's the reason behind the decision
02:20:47 <quicksilver> but it deserves a <blink> <marquee> notice to that effect :)
02:21:11 <quicksilver> "you function Context a b -> Context c d should be well-defined over differnet decompositions, in the following sense:"
02:21:22 <quicksilver> it's a proof obligation for the caller, after all
02:22:37 <Cale> Of course, maybe there are some applications where you really want that nondeterminism, because you only want some weaker equivalence of results.
02:23:25 <quicksilver> possibly
02:23:33 <quicksilver> I find that a bit hard to imagine, but possibly :)
02:25:36 <Cale> heh, type GDecomp g a b = (Context a b, g a b) -- The same as Decomp, only more sure of itself.
02:26:17 <Cale> I really dislike a lot of the naming choices in FGL.
02:28:09 <quicksilver> yes, I saw that :)
02:28:19 <quicksilver> naming is hard, though
02:28:54 <Cale> They try to be overly succinct.
02:30:43 <quicksilver> does Graphics.Vty work cross-platform?
02:36:20 <iguana_> is there some kind of concurrent queue in haskell?
02:37:07 <quicksilver> iguana_: yes. Define "concurrent queue"
02:37:21 <quicksilver> iguana_: (probably what you're after is Control.Concurrent.Chan)
02:37:32 <iguana_> quicksilver: well, a threadsafe queue where one thread puts things and another thread gets things
02:37:49 <iguana_> ah yes
02:37:57 <iguana_> Chan looks that way
02:37:58 <quicksilver> yup
02:38:03 <quicksilver> supports multiple writers, too
02:38:06 <quicksilver> without doing any more work :)
02:38:10 <iguana_> great
02:38:12 <quicksilver> and, indeed, multiple readers
02:38:43 <quicksilver> (in both possible senses of "multiple readers")
02:54:20 <tuxplorer> What function would chomp off the whitespaces to both ends of a string?
02:55:08 <oerjan> the beginning is simply dropWhile isSpace
02:55:23 <oerjan> for the end it is easiest to reverse
02:56:32 <oerjan> > join (.) (reverse . dropWhile isSpace) $ "  testing \t "
02:56:44 <lambdabot>  "testing"
02:57:19 <Cale> If you don't mind compressing internal whitespace, you can use  unwords . words
02:58:13 <oerjan> @let on (=) f x y = f x = f y
02:58:13 <lambdabot>  Parse error
02:58:22 <oerjan> @let on (==) f x y = f x == f y
02:58:25 <lambdabot> Defined.
02:58:57 <oerjan> > groupBy ((==) `on` isSpace) "  testing   more  \t "
02:58:58 <lambdabot>  ["  ","testing","   ","more","  \t "]
03:00:52 <oerjan> > groupBy ((==) `on` isSpace) . (' ':) . (++" ") $ "  testing   more  \t "
03:00:55 <lambdabot>  ["   ","testing","   ","more","  \t  "]
03:01:11 <oerjan> > concat . tail . init . groupBy ((==) `on` isSpace) . (' ':) . (++" ") $ "  testing   more  \t "
03:01:12 <lambdabot>  "testing   more"
03:01:18 <oerjan> > concat . tail . init . groupBy ((==) `on` isSpace) . (' ':) . (++" ") $ "testing   more  \t "
03:01:20 <lambdabot>  "testing   more"
03:01:29 <oerjan> > concat . tail . init . groupBy ((==) `on` isSpace) . (' ':) . (++" ") $ "testing   more"
03:01:30 <lambdabot>  "testing   more"
03:03:33 <doserj> > concat . tail . init . groupBy ((==) `on` isSpace) . (' ':) . (++" ") $ ""
03:03:34 <lambdabot>  Exception: Prelude.tail: empty list
03:03:43 <oerjan> whoops
03:04:06 <oerjan> > concat . drop 1 . init . groupBy ((==) `on` isSpace) . (' ':) . (++" ") $ "testing   more"
03:04:08 <lambdabot>  "testing   more"
03:04:11 <doserj> > concat . tail . init . groupBy ((==) `on` isSpace) . (' ':) . (++" ") $ " "
03:04:12 <lambdabot>  Exception: Prelude.tail: empty list
03:04:17 <oerjan> > concat . drop 1 . init . groupBy ((==) `on` isSpace) . (' ':) . (++" ") $ "  "
03:04:18 <lambdabot>  ""
03:04:40 <doserj> :)
03:05:53 <Baughn> > concat $ intersperse " " $ words "testing  again"
03:05:55 <lambdabot>  "testing again"
03:06:30 <oerjan> @check \l -> intersperse " " l == unwords l
03:06:31 <lambdabot>  Couldn't match expected type `[Char]' against inferred type `Char'
03:06:54 <oerjan> @check \l -> concat $ intersperse " " l == unwords l
03:06:55 <lambdabot>  Couldn't match expected type `[Char]' against inferred type `Char'
03:07:23 <allbery_b> @check \l -> concat (intersperse " " l) == unwords l
03:07:23 <Baughn> oerjan: It's not. Not even remotely.
03:07:24 <oerjan> @check \l -> (concat . intersperse " ") l == unwords l
03:07:27 <lambdabot>  OK, passed 500 tests.
03:07:30 <lambdabot>  OK, passed 500 tests.
03:07:37 <oerjan> huh? :)
03:07:44 <Baughn> oerjan: Even if quickcheck claims it is...
03:07:50 <Baughn> > words "testing  again"
03:07:52 <lambdabot>  ["testing","again"]
03:07:54 <oerjan> @src unwords
03:07:54 <lambdabot> unwords [] = ""
03:07:55 <lambdabot> unwords ws = foldr1 (\w s -> w ++ ' ':s) ws
03:07:56 <Baughn> Oh, wait
03:07:59 <Baughn> It is.
03:08:06 <Baughn> Soo...
03:08:16 <infrared> > instance Show (t -> t) where { show x = "function" }
03:08:16 <lambdabot>  Parse error
03:08:30 <Baughn> > (unwords . words) "here  we are, then"
03:08:31 <infrared> how can i define a function as an instance of show?
03:08:31 <lambdabot>  "here we are, then"
03:08:32 <quicksilver> infrared: you can't put declarations into LB
03:09:03 <quicksilver> infrared: but that looks correct for a .hs file
03:09:09 <infrared> either way, this declaration is invalid
03:09:23 <oerjan> in haskell 98 yes
03:09:31 <infrared> ghc says: "The instance type must be of form (T a b c) where T is not a synonym, and a,b,c are distinct type variables"
03:09:37 <oerjan> t -> u would be valid
03:09:40 <Baughn> oerjan: For some reason I thought 'words "foo bar"' would evaluate to ["foo","","bar"]
03:09:55 <oerjan> or possibly (->) t u, if it is picky
03:10:06 <infrared> (t -> u) worked
03:10:06 <hpaste>  allbery_b pasted "Show for functions" at http://hpaste.org/2814
03:10:10 <SamB_XP> Baughn: do you by some chance mean 'words "foo  bar"'?
03:10:15 <infrared> cool, thanks! :)
03:10:26 <Baughn> SamB_XP: No, I figured that should have /two/ empty strings in it
03:10:32 <SamB_XP> which doesn't either, but at least that would be plausible...
03:10:33 <Baughn> SamB_XP: Never mind. It makes no sense, in retrospect.
03:10:40 <oerjan> infrared: with -fglasgow-exts you can do t -> t as well
03:10:58 <infrared> I learn new ghc flags every day :)
03:11:13 <oerjan> that's the main flag
03:11:20 <infrared> yesterday i learned about -fextended-default-rules
03:11:22 <oerjan> there's probably a more specific one
03:11:23 <SamB_XP> oerjan: the old flag
03:12:00 <oerjan> SamB_XP: there's a new replacement for "enable lots of things" ?
03:12:26 <SamB_XP> oerjan: the new way is to say which things to enable ;-P
03:12:47 <SamB_XP> -X, on the commandline
03:12:58 <oerjan> i know
03:13:16 * mrd wonders what ghc -XXX gets you.
03:13:20 <SamB_XP> (followed by something of type Language.Haskell.Extension.Extension)
03:13:25 <olsner> is there a good parallell programming in haskell tutorial?
03:13:56 <SamB_XP> mrd: a Read error, probably ;-)
03:15:06 <matthew_-> mrd: g++
03:15:26 <olsner> mrd: peano-coded ascii porn. as type errors.
03:16:36 <allbery_b> @remember olsner * mrd wonders what ghc -XXX gets you. <olsner> mrd: peano-coded ascii porn. as type errors.
03:16:36 <lambdabot> Done.
03:16:49 <SamB_XP> olsner: the easiest way to do it is to use ndp ;-)
03:18:04 <quicksilver> olsner: or if you just mean 'using threads and stuff' it's really surprising easy.
03:18:19 <quicksilver> olsner: forkIO to make threads. Share state with MVars. It all just works (TM).
03:18:29 <SamB_XP> unless you deadlock
03:18:36 <quicksilver> indeed
03:18:42 <SamB_XP> in which case hopefully the garbage collector will tell you
03:18:50 <olsner> ndp, nested data parallelism... it's on my increasingly long list of things to learn one day
03:18:51 <quicksilver> although the haskell runtime is pretty unusual in that it can sometimes detect deadlock
03:19:30 * Baughn wonders if there is a parallel-map primitive somewhere
03:19:41 <olsner> threads with shared state I can do in C any time ;-)
03:20:04 <SamB_XP> Baughn: you could, um, abuse PArray
03:20:11 <SamB_XP> or something
03:20:21 <quicksilver> olsner: yes, you can. And you'll be amazed how much easier it is in haskell.
03:20:39 <quicksilver> olsner: communicating through lock-safe, type-safe channels instead of tearing your hair out ;)
03:20:56 <SamB_XP> Baughn: using a wrapper that prevents PArray from doing anything to your actual data, if desired
03:21:10 <Baughn> olsner: And afterwards, you'll be amazed at how the laziness causes all the computation to be done in the thread that prints the results, instead of the ones that supposedly compute it.
03:21:18 <SamB_XP> Baughn: ask ChilliX about it
03:21:46 <Baughn> olsner: Plenty of solutions, of course. rnf and seq, for two.
03:21:58 <SamB_XP> Baughn: oh, yes ;-)
03:22:04 <SamB_XP> that's a classic ;-)
03:22:10 <oerjan> :t parMap
03:22:12 <olsner> so haskell provides much more than forkIO and MVars, even in the threads-with-shared-state model?
03:22:12 <lambdabot> forall b a. Strategy b -> (a -> b) -> [a] -> [b]
03:22:28 <SamB_XP> olsner: we also have STM
03:22:31 <SamB_XP> watch SPJ'
03:22:35 <Baughn> olsner: There's the entire Control.Concurrent hierarchy, plus plus
03:22:40 <SamB_XP> s lighting talk on the subject ;-)
03:22:47 <Baughn> Plus Control.Parallel, mostly
03:22:59 <olsner> SamB_XP: oh, did he do one on STM too?
03:23:11 <SamB_XP> olsner: yeah, he did it at OSCON
03:23:30 <SamB_XP> and he really did manage to squeeze the important stuff in 15-20 minutes
03:24:03 <quicksilver> olsner: well there is Chan which is often more useful than MVars
03:24:13 <quicksilver> olsner: and then there is the really clever STM stuff
03:24:16 <SamB_XP> and I don't even think he talked especially fast (for him)
03:24:22 <olsner> Chan, is that more or less a type-safe pipe?
03:24:27 <quicksilver> yes
03:24:33 <SamB_XP> it's made of MVars ;-)
03:24:35 <quicksilver> it's something like an MVar [a]
03:24:38 <quicksilver> or MVar (Seq a)
03:24:43 <Baughn> olsner: Control.Parallel might actually be all you need
03:24:47 <quicksilver> but it does the right thing w.r.t. blocking and stuff
03:25:17 <SamB_XP> it's queue, implemented as a singly-linked list linked by MVars
03:25:27 <oerjan> :t parMap rwhnf
03:25:29 <lambdabot> forall b a. (a -> b) -> [a] -> [b]
03:25:29 <SamB_XP> er. insert "a" at an appropriate spot
03:26:05 <oerjan> ^^ this one would evaluate in parallel and force all the results, right?
03:26:37 <quicksilver> SamB_XP: well, two lists
03:26:56 <quicksilver> SamB_XP: like the classic Queue [a] [a], but with MVar-ness scattered at every node
03:27:15 <SamB_XP> quicksilver: two lists?
03:27:40 <quicksilver> SamB_XP: you said it was implemented as "a singly linked list"
03:27:48 <quicksilver> SamB_XP: it's two, one for the reader end and one for the writer end
03:27:52 <Baughn> oerjan: Assuming that's what rwhnf does, yes. I wonder if there's documentations somewhere...
03:27:58 <SamB_XP> quicksilver: it's one list!
03:28:11 <Baughn> http://www.haskell.org/ghc/docs/latest/html/libraries/base/Control-Parallel-Strategies.html#v%3Arwhnf is impressively uninformative
03:28:13 <lambdabot> http://tinyurl.com/yj5j75
03:28:19 <oerjan> Baughn: i assume it meant reduce to weak head normal form, which is what seq does...
03:28:26 <SamB_XP> quicksilver: but the MVar to the end is cached
03:28:43 <SamB_XP> or something
03:29:05 <quicksilver> SamB_XP: hmm
03:29:11 <Baughn> oerjan: You might want rnf instead
03:29:34 <oerjan> Baughn: that's not a Strategy i think
03:29:36 <oerjan> :t rnf
03:29:39 <lambdabot> forall a. (NFData a) => a -> Done
03:30:25 <oerjan> oh wait it is
03:30:28 <olsner> hmm, so in (a `par` b), I'd want a bunch of seq's within a to get something that actually runs in another thread rather than at the time of forcing a?
03:30:36 <SamB_XP> hmm, the source says "see the Concurrent Haskell paper for a diagram explaining how the different channel operations proceed"
03:30:54 <quicksilver> SamB_XP: yes, I'm just reading the source
03:30:57 <Baughn> olsner: No, you'd want a to be, essentially, the exact same code you'll later be passing to an I/O operation
03:31:10 <quicksilver> SamB_XP: I'm interestin, cos I implemented a Chan as two MVars, (Seq a) and ()
03:31:24 <quicksilver> SamB_XP: and I'm trying to see if their implementation is better than mine, or if mine was actually wrong.
03:31:44 <Baughn> olsner: If that's hard, rnf might be helpful - that'll evaluate *everything*, though. Even infinities, which is to say it'll try.
03:32:03 <quicksilver> SamB_XP: of course the cute thing about a list with "MVars all the way down" is that you can change its tail
03:32:09 <olsner> Baughn: that is, I'd write a in a parallel program exactly as I'd write it in a single-threaded program?
03:32:19 <SamB_XP> quicksilver: well yeah, that's rather the point ;-)
03:32:23 <quicksilver> SamB_XP: whereas I was using a pure functional strucgture with efficient append
03:32:26 <quicksilver> SamB_XP: instead
03:32:47 <SamB_XP> I'm not at all sure how efficient it is
03:32:53 * quicksilver nods
03:32:53 <Baughn> olsner: You'll want to write a such that evaluating its weak head normal form requires the evaluation of everything you want to be computed in parallel
03:33:02 <quicksilver> SamB_XP: my version or their version?
03:33:04 <SamB_XP> theirs
03:33:08 * quicksilver nods
03:33:14 <quicksilver> I had much less MVar work going on
03:33:15 <SamB_XP> I've heard MVar has performance issues
03:33:17 <quicksilver> which means less locking
03:33:24 <quicksilver> just a top-level MVar
03:33:33 <Baughn> olsner: For example, if you want to make a nice int-tree in parallel, making a the sum of all the leaves in the tree will require the entire tree to be computed
03:33:34 <quicksilver> and <| and |> on Seq a, which are very fast
03:33:39 <SamB_XP> well, I think you must do about as much locking...
03:34:19 <SamB_XP> but you have a lot less total MVars
03:34:24 <SamB_XP> which is probably not a bad thing
03:34:43 <Baughn> olsner: Proably, looking into Strategies /would/ be useful. parmap rwhnf does the same thing as par, but for an entire list instead of just one value, for example.
03:35:01 <Baughn> ..and why does this sound like some obscure assembly op?
03:35:09 <quicksilver> SamB_XP: don't think so. They do a newM, a modifyM and putM inside that, per write
03:35:15 <olsner> Baughn: yeah, am looking now, but all I see is type signatures :P
03:35:21 <quicksilver> SamB_XP: for a write all I needed was a single modify
03:35:37 <quicksilver> SamB_XP: oh, I lie. a modify and a conditional put
03:35:50 <Baughn> olsner: An occupational hazard. Type signatures suffice to explain how to /use/ them, if you already know what they /do/.
03:35:53 <quicksilver> SamB_XP: I'd love to know if my implementation was actually watertight. I wonder if the separation guys can prove it.
03:36:15 <ChilliX> Baughn: What's this about PArrays and threads and laziness?
03:36:17 <olsner> yeah, and (parMap rwhnf) already told me that :P
03:36:25 <TuringTest> quicksilver: The reason to use the many MVar scheme in Chan (and TVar / TChan) is the dupChan (dupTChan) operation
03:36:41 <olsner> i.e. how to use it but not what it does
03:36:46 <Baughn> ChilliX: Well, I was looking for parMap rwhnf. I found it.
03:37:08 <olsner> rwhnf = R(ecursive?) weak head normal form?
03:37:09 <Baughn> ChilliX: You might profitably help olsner, though - I'll be disappearing in a poof of logic now. ;)
03:37:17 * Baughn disappears in a poof of logic
03:37:24 <oerjan> heh. rwhnf x = x `seq` ()
03:38:03 <ChilliX> Baughn: with PArrays there is no issue with having to use rwhnf or something
03:38:14 <quicksilver> TuringTest: Ah. Yes, I couldn't support that. I was just making many channels, instead
03:38:26 <Baughn> ChilliX: Mm. What module is that defined in?
03:39:17 <oerjan> hm.  there's a lot of haddock in that module that's not in the webpage
03:39:48 <ChilliX> Well, it is pretty experimental in an extra library, see http://haskell.org/haskellwiki/GHC/Data_Parallel_Haskell (the speed without convenience part)
03:39:48 <quicksilver> oerjan: I think haddock by defaul only shows oyu the exported symbols
03:39:49 <lambdabot> Title: GHC/Data Parallel Haskell - HaskellWiki
03:39:59 <quicksilver> oerjan: I think there is an option to make it doc everything
03:40:39 <oerjan> quicksilver: they really should use that for the webpage
03:41:43 <quicksilver> TuringTest: since we're tlaking about the MVars, something bothers me about the MVar API
03:41:53 <quicksilver> TuringTest: I miss a 'pure' version of modifyMVar
03:41:59 <TuringTest> quicksilver: Hmm?
03:42:11 <TuringTest> quicksilver: ???  That cannot work
03:42:21 <quicksilver> I want something of type (a->a) -> MVar a -> IO ()
03:42:28 <quicksilver> :t modifyMVar
03:42:30 <lambdabot> Not in scope: `modifyMVar'
03:42:37 <quicksilver> :t Control.Concurrent.MVar.modifyMVar
03:42:39 <lambdabot> forall a b. GHC.IOBase.MVar a -> (a -> IO (a, b)) -> IO b
03:42:52 <quicksilver> TuringTest: pure modification function
03:42:56 <TuringTest> quicksilver: What type signature do you want?
03:42:57 <quicksilver> TuringTest: not pure overall :)
03:43:02 <TuringTest> Ah
03:43:12 <quicksilver> MVar a -> (a -> a) -> IO ()
03:43:18 <quicksilver> for me, that's the most common case
03:43:30 <TuringTest> :t (return .)
03:43:31 <quicksilver> I keep writing modifyMVar_ (return $ .... )
03:43:32 <lambdabot> forall b (m :: * -> *) a. (Monad m) => (a -> b) -> a -> m b
03:43:34 * quicksilver nods
03:43:39 <quicksilver> yeah, I know
03:43:43 <quicksilver> I just think it's an odd API
03:44:09 <TuringTest> quicksilver: One can lift from pure to IO but not the other way around. So it is the right primitive.
03:44:27 <oerjan> @pl mmv f v = modifyMVar v (\x -> return (f x,()))
03:44:27 <lambdabot> mmv = flip modifyMVar . ((return . (,)) .)
03:44:39 <TuringTest> quicksilver: You could propose adding the already lifted version to the API, and if you hurry it may make it into 6.8.1
03:45:12 <quicksilver> TuringTest: to libraries@ ?
03:46:01 <TuringTest> quicksilver: There is a proposal process...I forget the details...try the wiki and libraries@ and the ghc trac website http://hackage.haskell.org/trac/ghc/query?status=new&status=assigned&status=reopened&type=feature+request&order=priority
03:46:05 <lambdabot> Title: Custom Query - GHC - Trac, http://tinyurl.com/2ykste
03:46:38 <quicksilver> TuringTest: as a precedent, by the way, consider modifyIORef
03:47:11 <oerjan> heh, Control.Parallel.Strategies is _old_ - "This version can be used with Haskell 1.4"
03:47:18 <TuringTest> quicksilver: Also worry about the strictness....
03:48:29 <quicksilver> TuringTest: you mean the fact that you end up stuffing the MVar with a thunk not a value?
03:48:37 <TuringTest> Right.
03:48:40 <aleator> Is there any way of getting smaller binaries with ghc. I have ridiculous 3mb text processing app.. :/
03:49:36 <CaptainJaffaCake> aleator: wait for shared libraries :)
03:49:43 <allbery_b> not currently.  I think a shared ghc lib is work in progress, rightnow ghc and packages are linked statically
03:50:25 <allbery_b> the flip side of that is that you can shlep a binary between systems without having to install ghc libs
03:50:50 <aleator> Oh.. Well. Have to bear the peer laughter for my 3.4mb cgi then. :)
03:51:17 <fasta> Why is this False? "2-2-3" =~ "[2-5]-[:digit:]+-[:digit:]+"::Bool
03:51:48 <puusorsa> :t (=~)
03:51:57 <lambdabot> Not in scope: `=~'
03:51:58 <puusorsa> @type (=~)
03:52:00 <lambdabot> Not in scope: `=~'
03:52:01 <puusorsa> oh
03:53:30 <oerjan> fasta: does "2-2+-3+" work?
03:53:39 <quicksilver> the problem is [:digit:]
03:53:51 <nornagon> @instances Functor
03:53:52 <lambdabot> ((,) a), ((->) r), Cont r, ContT r m, Either a, ErrorT e m, IO, Maybe, RWS r w s, RWST r w s m, Reader r, ReaderT r m, ST s, State s, StateT s m, Writer w, WriterT w m, []
03:54:21 <fasta> oerjan:  "2" =~ "[:digit:]" :: Bool even this doesn't work
03:54:31 <fasta> quicksilver: right :)
03:54:40 <fasta> quicksilver: why is it a problem?
03:55:04 <Baughn> fasta: Tried [[:digit:]]?
03:55:04 <quicksilver> TuringTest: where is it documented which dialect of regex the Text.Regex packages support?
03:55:06 <allbery_b> haskell stuff is, in general, not locale-aware
03:55:08 <TuringTest> fasta: Hmmm....
03:55:16 <allbery_b> and ==Baughn anyway
03:55:24 <quicksilver> Baughn is righ
03:55:28 <quicksilver> [[:digit:]] works
03:55:30 <TuringTest> quicksilver: Depends on the backend.  The Text.Regex backend is the system plateform's regex.h
03:55:54 <quicksilver>  "2-2-3" =~ "[2-5]-[[:digit:]]+-[[:digit:]]+"::Bool
03:55:55 <quicksilver> True
03:56:06 <Baughn> quicksilver: The Text.Regex package uses POSIX regexes
03:56:07 <fasta> The wikipedia article on Regexps shows [:digit:]
03:56:14 <fasta> Not [[
03:56:17 <allbery_b> (the standard POSIX regex documentation is annoying that way)
03:56:20 <fasta> Why is it different?
03:56:26 <allbery_b> yep, see annoying
03:56:32 <quicksilver> fasta: I think it's [:digit:], but it's only valid inside [] ?
03:56:37 <Baughn> fasta: Think of [:digit:] as expanding to 0-9
03:56:43 <allbery_b> the documentation states somwhere around there that such classes are valid only inside character classes
03:56:55 <allbery_b> meaning the real usage is [[:...:]]
03:56:58 <fasta> Baughn: is that how it works in Perl too?
03:57:03 <allbery_b> yes
03:57:07 <fasta> Ok, thanks
03:57:08 <quicksilver> but you can write [[:digit:][:letter:]]
03:57:15 <TuringTest> fasta: "man re_format" on OSX specifies [[:digit:]]
03:57:22 <Baughn> fasta: It's how it appears to work. I'm sure if I tried, I could prove that it isn't actually text expansion.
03:57:43 <Baughn> quicksilver: You can also write [0-9a-fA-F], if you like
03:58:07 <quicksilver> Baughn: indeed, I know :)
03:58:29 <TuringTest> fasta: I made the most recent regex-* packages.  Do you have any other comments or questions?
03:59:43 <Baughn> TuringTest: I haven't actually checked if there /is/ one yet, but it would be nice to have a combinatorial regex constructor in addition to the string-based one
04:00:47 <TuringTest> Baughn: There is one backend which uses combinators internally.  "regex-dfa"
04:00:52 <fasta> TuringTest: I used a blog post to use it, so it might be better if some usage blurb would be included.
04:01:27 <fasta> TuringTest: It is afterall, quite a non-obvious use of complex language features.
04:02:05 <fasta> TuringTest: http://www.serpentine.com/blog/2007/02/27/a-haskell-regular-expression-tutorial/
04:02:07 <lambdabot> Title: teideal glic deisbh√©alach ª Blog Archive ª A Haskell regular expression tutoria ..., http://tinyurl.com/2xtgpw
04:02:40 <quicksilver> Baughn: would a combinatorial regex-builder be better than a combinatorial parser-builder?
04:03:04 <Baughn> quicksilver: Not particularily, no. It might be faster.
04:03:23 <Baughn> quicksilver: Come to think of it, there is a regex-parsec backend
04:04:02 <TuringTest> fasta: regex-parsec is a bit slow.  But flexible.
04:04:16 <TuringTest> Baughn: I wrote regex-parsec as well.
04:04:17 <Baughn> quicksilver: The reason to have a combinatorial frontend would be for the ease of use, though
04:04:49 <Baughn> Parsec is nice, but a bit much if all I want is a regex
04:05:14 <allbery_b> hm, port snobol4/icon pattern matching to haskell?
04:05:26 <quicksilver> Baughn: then don't you just want a lighter-weight combinator library? :)
04:05:45 <Baughn> quicksilver: I guess so, yes.
04:06:02 <fasta> TuringTest: where can I find regex-parsec?
04:06:19 <Baughn> @where hackage
04:06:19 <lambdabot> http://hackage.haskell.org/trac/hackage
04:06:38 <Baughn> ..hmm, interesting choice of url
04:06:46 <quicksilver> Baughn: what I'm trying to say is that really regexes are ugly and not very powerful. They were created because it was convenient to have a DSL for matching
04:07:06 <quicksilver> Baughn: but now we have combinator parsing, we can get that convenience and still have something more attractive and more powerful
04:07:18 <quicksilver> Baughn: and it's not clear that backending on regexp is sensible
04:07:25 <quicksilver> it's almost anachronistic to do so :)
04:07:45 <Baughn> quicksilver: I figure, if I collect enough anachronisms, I can build a closed timelike loop
04:07:51 <quicksilver> ;)
04:09:57 <mux> Could anyone help me understand why some code of mine is leaking memory like mad?  http://hpaste.org/2800
04:10:08 <mux> this is a very stupid program for experimenting with things
04:10:38 <oerjan> Baughn: i thought you did so already?
04:11:11 <Baughn> oerjan: I did, but then I went back in time and stopped myself from doing so.
04:11:13 <mux> I changed the 'match' function to look for a sum of ascii codes == 66 rather than 666.  So the first match should be "B", and it's like the third element of the generated (inifinite) list
04:11:27 <mux> yet, the program is eating hundreads of megabytes of RAM before even printing this match
04:11:40 <Baughn> mux: Are you sure it's actually leaking memory? It doesn't mention max residency, or GCs
04:11:47 <Baughn> Inefficiency is a different matter
04:11:51 <mux> not leaking in the sense of a bug
04:12:06 <mux> leaking in the sense of the memory consumption being sub-optimal
04:13:51 <mux> the memory usage should be pretty much constant (not really, but before reaching the point where we have huge strings, it'll have run for hours already)
04:14:30 <Baughn> This is beyond me. I'd try to perturb it into behaving, but that's not really optimal.
04:14:45 <Baughn> You could try using foldl/foldr instead, I suppose
04:14:56 <quicksilver> mux: I would investigate the output of iterate first
04:15:00 <quicksilver> mux: I'm not sure it does what you think it does
04:15:05 <mux> I think the key to understanding is probably to run the generated GHC Core, but I can't do this
04:15:11 <mux> quicksilver: did that in GHCi
04:15:17 <mux> I get the list I'm expecting
04:15:31 <mux> and I can run stuff like "any (== "abc") $ mygenfunc"
04:15:33 <mux> which terminates
04:15:49 <mux> I can also take the first 10, 100, 1000 entries and get expected results
04:16:15 <mux> s/run the generated GHC Core/read .../
04:16:17 <oerjan> i thought i heard B.cons was rather inefficient?
04:16:53 <quicksilver> mux: oh, hang on
04:17:03 <quicksilver> mux: you're running mapM_ in the IO monad
04:17:07 <mux> Baughn: instead of using ByteString's fold?
04:17:09 <quicksilver> mux: you can't do that on an infinite list :P
04:17:12 <mux> ah.
04:17:14 <fasta> TuringTest: Can I also match groups? I.e. 2-3-4 => ("2","3","4")?
04:17:32 <mux> quicksilver: now you are picking my curiosity :-) could you expand on this?
04:17:32 <quicksilver> mux: the IO monad strictly sequences
04:17:53 <oerjan> quicksilver: what?
04:17:54 <quicksilver> mux: you can't run (sequence_ l) where l is an infinite list, and expect to get any results
04:18:14 <oerjan> quicksilver: but he is not running it to get a result, but for actions
04:18:19 <quicksilver> mux: (bearing in mind mapM_ is using sequence_)
04:18:23 <mux> ok, so you're saying sequence_ is waiting for filter to return?
04:18:48 <oerjan> i strongly doubt that is the problem.
04:18:57 * mux is puzzled
04:19:16 <quicksilver> oh, oerjan is right
04:19:20 <quicksilver> you're not waiting for the result
04:19:23 <quicksilver> hmm
04:19:26 * quicksilver continues poking
04:19:41 <oerjan> e.g. sequence_ . repeat $ getLine >>= putStrLn should work fine
04:19:55 * mux does more tests to see if his code isn't doing anything stupid
04:20:43 <mux> hm, I should first annotate this past with the latest code, where I changed to using strict bytestring (I don't need laziness for the strings, but only for the list of strings)
04:21:07 <quicksilver> mux your problem is just the time it take to get to 666, IMO
04:21:12 <quicksilver> mux: it runs very fast for 66, for me
04:21:53 <hpaste>  mux annotated "memory leak?" with "latest code" at http://hpaste.org/2800#a2
04:22:03 <mux> quicksilver: eh? I tried with 66 as I said
04:22:08 <mux> and never got any answer
04:22:13 <quicksilver> mux: when I try with 66, I get B instantly
04:22:14 <mux> what GHC version are you using?
04:22:18 <quicksilver> mux: more or less instantly anyhow
04:22:23 <mux> I'll re-test on my laptop
04:22:32 <quicksilver> 6.6.1
04:23:11 <mux> 1GB of RAM still no answer
04:23:13 <mux> 1.3GB
04:23:19 <mux> heh, I'd rather stop it now
04:23:42 <mux> and this is 6.6.1 too
04:23:44 <quicksilver> mux: with the strict BS version I still get the answer instantly, for 66
04:23:55 <mux> now, I'm really, really puzzled
04:25:00 <doserj> mux: are you compiling, or using ghci?
04:25:07 <mux> how did you build? I used --make -O2 -funbox-strict-fields
04:25:07 <quicksilver> I'm using ghci
04:25:13 <mux> ah.
04:25:14 <doserj> if compiling, it could be a simple buffering
04:25:17 <doserj> problem
04:25:21 <mux> quicksilver: can you try by building?
04:25:28 <quicksilver> sure
04:25:57 <fasta> Can I match groups with regex posix?
04:26:00 * mux waits for firefox to get back to his huge cache that has been nastily paged out by the haskell program ;-)
04:26:32 <mux> heh, it works for me too in GHCi
04:26:32 <quicksilver> mux: works fin
04:26:39 <quicksilver> mux: I get rapid results for 366
04:26:41 <mux> but definitely not when I build it
04:26:50 <mux> quicksilver: what about RAM usage?
04:26:57 <quicksilver> 466 seems to be taking a while
04:27:00 <quicksilver> ah, there it goes
04:27:14 <mux> I'm jealous! you are the one taking advantage of this awesome code ;-)
04:27:32 <mux> quicksilver: did you use --make -O2 -funbox-strict-fields?
04:27:39 <quicksilver> yeah, memory usage was pretty unpleasant for 466
04:27:41 <quicksilver> yes
04:28:01 <mux> does your box have 32GB of RAM or something? :-)
04:28:14 <quicksilver> 2G
04:28:22 <mux> same here. *grunts*
04:28:36 <quicksilver> well two problems
04:28:43 <quicksilver> (a) why does it not work on your machine, compiled
04:28:46 <quicksilver> (b) why does it suck memory?
04:29:12 <mux> right
04:29:13 <quicksilver> ah
04:29:25 <quicksilver> iterate keeps the last version around
04:29:29 <quicksilver> that makes it 'fast'
04:29:35 <mux> (c) why does everything I try to write in haskell ends up exercising FreeBSD's swapping code? :-) :-)
04:29:51 <quicksilver> but that means to calculate the (52x52x52) results in the 3rd iter, it holds on to the (52x52) from the second
04:29:57 <quicksilver> that's not a big problem
04:30:02 <mux> right
04:30:07 <mux> I expected this, more or less
04:30:20 <quicksilver> but when trying to calculate the fourth iter, it's keeping around the (52x52x52) from the second
04:30:27 <quicksilver> that's starting to sound like a pretty long list
04:30:31 <quicksilver> > 52^3
04:30:36 <lambdabot>  140608
04:30:56 <mux> it should be able to run while only keeping two strings in memory
04:30:58 <quicksilver> when my machine starting really pegging out, it had finished building the 4th iter
04:31:04 <quicksilver> mux: you're not listening to me :P
04:31:11 <quicksilver> mux: think about the call to iterate!
04:31:11 <mux> err, sorry!
04:31:23 <quicksilver> mux: it's building 52x52x52x52 strings based on the last iteration
04:31:30 <quicksilver> that last iteration was 52x52x52
04:31:34 <quicksilver> so it has to keep that list around
04:31:42 <quicksilver> it won't get gc'ed until it's finished building iter 4
04:31:43 <mux> oh right
04:32:07 <mux> so it's not only keeping two strings in memory at once, but two results of the concatMap stuff
04:32:07 <quicksilver> not nice...
04:32:13 <quicksilver> yeah
04:32:24 <quicksilver> it's building "all four letter words" from "all three letter words"
04:32:29 <mux> I knew I didn't like it when I had to add a concat call on the result of iterate
04:32:38 <quicksilver> and "all three letter words" is a 140,000 long list
04:32:42 <mux> yep, that is sub-optimal, I should rethink my algorithm
04:32:49 <quicksilver> my computer had just finished generating "al four letter words"
04:32:53 <quicksilver> > 52 ^ 4
04:32:55 <lambdabot>  7311616
04:32:58 <mux> pardon me, but $real_work is kicking in, I'll be back in a few
04:33:03 <quicksilver> so it had a 7 million long list in memory :)
04:33:08 <quicksilver> no wonder it was suffering
04:33:51 <Saizan> it sounds like the CSE-ed powerset
04:34:03 * ketil always limits heap to 80% of physical.
04:34:35 <quicksilver> sounds liek a sensible plan to me
04:35:13 * quicksilver 's computer is now strangely sluggish, as if everything had just been paged out :)
04:37:50 <Baughn> On the plus side, GHC behaves surprisingly well after it gets into swap. GCs usually suck at that.
04:39:26 <KatieHuber> my machine becomes completely unresponsive while it collects...
04:39:39 <KatieHuber> (once it's swapping)
04:40:00 <allbery_b> depends on how good the OS's VM management is
04:40:24 <allbery_b> IME freebsd and solaris are pretty good, most versions of linux suck at it
04:41:37 <mux> quicksilver: so, a good plan would be to rething the generation algorithm so that it needs less state, right?
04:41:44 <mux> rethink, even
04:41:52 <quicksilver> mux: well you're being bitten by the way iterate works, that's all
04:41:57 <quicksilver> @src iterate
04:41:57 <lambdabot> iterate f x =  x : iterate f (f x)
04:42:05 <quicksilver> mux: erm, that's not even true :)
04:42:29 <quicksilver> mux: ah, yes that's right
04:42:43 <mux> I still don't quite get how you get a result on your computer, and why it works when I run it in GHCi
04:42:56 <quicksilver> no, I can't understand that at all
04:43:03 <quicksilver> try deleting your .o and executable files
04:43:08 <quicksilver> and compiling 'fresh'
04:43:30 <quicksilver> mux: point is that iterate manages to share 'x' between head of list and recursive call to f
04:43:38 <quicksilver> mux: that's normally a good thing
04:43:52 <quicksilver> mux: in your case, 'x' is "all n-letter words" and becomes more painful to share
04:46:04 <mux> hmm, how can I check if my GHC is configured so that it builds natively versus building via C? I'm a bit suspicious now since I noticed gcc being run when recompiling this code
04:46:24 <quicksilver> > concatMap (\n -> replicateM n (['a'..'z']++['A'..'Z'])) [1..]
04:46:26 <lambdabot>  ["a","b","c","d","e","f","g","h","i","j","k","l","m","n","o","p","q","r","s"...
04:46:44 <quicksilver> mux: I believe that ^^ doesn't leak
04:46:54 <mikael> Saizan: what is the CSE'd powerset?
04:46:54 <quicksilver> > (!! 1000000) $ concatMap (\n -> replicateM n (['a'..'z']++['A'..'Z'])) [1..]
04:46:56 <lambdabot>  "gePO"
04:47:09 <quicksilver> certainly it find the millionth element 'fast enough' so I assume it's ok
04:47:17 <olsner> @quote fluxbox
04:47:17 <lambdabot> jcreigh says: I've found learning Haskell makes me feel vastly inferior to Haskell coders. ("Oh,", they say, "That's just a fold over the hyper-monad fluxbox list. Here's the one-line replacement
04:47:18 <lambdabot> for your entire program.")
04:48:34 <olsner> btw, isn't that [1..] >>= (flip replicateM) alphabet?
04:48:47 <olsner> @pl  concatMap (\n -> replicateM n (['a'..'z']++['A'..'Z'])) [1..]
04:48:47 <lambdabot> flip replicateM (['a'..'z'] ++ ['A'..'Z']) =<< [1..]
04:48:47 <Saizan> mikael: powerset (x:xs) = let xs' = powerset xs in xs ++ map (:x) xs
04:48:54 <quicksilver> olsner: yes
04:49:00 <quicksilver> olsner: but I find my way easier to read :)
04:49:11 <mux> quicksilver: trying that
04:49:17 <quicksilver> mux: now running it on 666
04:49:25 <quicksilver> mux: it's taking a long time, but memory use is stable
04:49:26 <mikael> Saizan: ah, yeah.  what does `CSE' mean?
04:49:31 <doserj> mux: i think for -O2 default is -fvia-C. for -O0, default is -fasm
04:49:34 <mux> but now I have String != ByteString mismatches
04:49:45 <quicksilver> mux: stick a map (B.pack) into the pipeline
04:49:49 <quicksilver> mux: I will paste my version
04:49:49 <mux> mikael: common subexpression elimination
04:49:56 <mux> doserj: ah, thanks
04:50:12 <hpaste>  quicksilver annotated "memory leak?" with "replciateM version" at http://hpaste.org/2800#a3
04:51:09 <quicksilver> mux: I wonder what the first answer is :) sure takes a while
04:51:28 <mux> I've found a 5 or 6 letters version by hand
04:51:30 * quicksilver runs the interpreted version on one core and the compiled version on the other core
04:52:00 <quicksilver> > sum . map ord $ 'ZZZZZ'
04:52:00 <lambdabot>  Improperly terminated character constant
04:52:05 <quicksilver> > sum . map ord $ "ZZZZZ"
04:52:07 <lambdabot>  450
04:52:14 <mux> ord 'z' > ord 'Z'
04:52:17 <quicksilver> doh
04:52:22 <quicksilver> > sum . map ord $ "zzzzz"
04:52:23 <lambdabot>  610
04:52:28 <quicksilver> ok, it's going to be 6 then
04:52:34 <quicksilver> > 52^5
04:52:36 <lambdabot>  380204032
04:52:41 <mux> > (sum . map ord) "zzzzgA"
04:52:42 <lambdabot>  656
04:52:46 <mux> nearly
04:52:47 <mux> :)
04:52:53 <quicksilver> so 380 million 5-letter ones to ignore first
04:52:59 <mux> heh heh
04:53:28 <mux> this could be improved with some heuristic, because we know the upper and lower bounds of this sum depending on the length of the strings
04:53:34 <quicksilver> wow, fans running
04:53:39 <quicksilver> don't often kick in the fans on this machine
04:53:41 <doserj> > sum . map ord $ "matrix" -- would have been too funny...
04:53:42 <lambdabot>  661
04:53:51 <mux> what the hell
04:54:05 <quicksilver> > sum . map ord $ "algore"
04:54:05 <mux> I'm still not getting even an answer for 66 (= "B")
04:54:06 <lambdabot>  634
04:54:12 <mux> and it's still eating RAM
04:54:16 <mux> with the replicateM version
04:54:27 <mux> though apparently less
04:54:34 <quicksilver> well my version is using ram, but in quite an orderly way
04:54:38 <quicksilver> about half a gig
04:54:50 <mux> quicksilver: what version of GCC do you have? 4.2.1 here
04:56:08 <hpaste>  mux annotated "memory leak?" with "cleaned up replicateM version" at http://hpaste.org/2800#a4
04:56:17 <quicksilver> mux: 6.6.1
04:56:23 <hpaste>  wli pasted "there must be a better way" at http://hpaste.org/2815
04:56:33 <mux> quicksilver: gcc, not ghc
04:56:48 <quicksilver> ooh, I got an answer
04:56:50 <oerjan> > map (sum . map ord) $ take 6 . tails $ "AAAAAAzzzzzz"
04:56:52 <lambdabot>  [1122,1057,992,927,862,797]
04:57:05 <quicksilver> and the winner is aajzzz
04:57:17 <oerjan> huh?
04:57:24 <oerjan> oh wait
04:57:24 <quicksilver> mux: i686-apple-darwin8-gcc-4.0.1 (GCC) 4.0.1 (Apple Computer, Inc. build 5367)
04:57:37 <oerjan> > map (sum . map ord) $ map (take 6) . tails $ "AAAAAAzzzzzz"
04:57:39 <lambdabot>  [390,447,504,561,618,675,732,610,488,366,244,122,0]
04:57:40 * mux grumbles
04:58:07 <quicksilver> mux: is this a stock market prediction algorithm? Shall I buy shares in aajzzz ?
04:58:14 <mux> hah
04:59:12 <mux> this is beyond me
04:59:33 <mux> no way to even get the "B" answer when I compile this code, whether I use -O0, -O1 or -O2
05:00:00 <oerjan> > sum . map ord $ "AAzzzz"
05:00:02 <lambdabot>  618
05:00:07 <doserj> mux: try a "hSetBuffering stdout NoBuffering"
05:00:29 <oerjan> > sum . map ord $ "AZzzzz"
05:00:30 <lambdabot>  643
05:00:38 <oerjan> > sum . map ord $ "Aazzzz"
05:00:40 <lambdabot>  650
05:00:47 <oerjan> > sum . map ord $ "Aqzzzz"
05:00:49 <lambdabot>  666
05:01:42 <mux> doserj: I highly doubt this would change anything
05:01:43 <fasta> I read about 1000 files in a directory and process them one by one: resource exhausted (Too many open files)
05:01:52 <mux> stdout is line-buffered by default, and I know FreeBSD respects this
05:01:55 <mux> I'll try though.
05:01:57 <fasta> I.e. shouldn't GHC close the files?
05:02:30 <oerjan> fasta: do you read them to the end?
05:02:41 <mux> doserj: what the... it worked!
05:02:58 <mux> so it sounds like nasty GHC is playing with buffering in a bad way
05:03:03 <fasta> oerjan: I basically do length.lines
05:03:07 <oerjan> if you just read part, they will not be closed until GC
05:03:19 <oerjan> oh
05:03:26 <mux> line buffering isn't working properly for some reason
05:05:59 <mux> quicksilver: did you get several matches for 666 yet? :)
05:06:18 <quicksilver> mux: well after the first one they pour in, of course
05:06:20 <oerjan> fasta: strange. but i think it is safe to close them explicitly after you are sure they are completely read.
05:06:23 <quicksilver> fasta: http://www.haskell.org/pipermail/haskell-cafe/2007-March/023498.html
05:06:24 <lambdabot> Title: [Haskell-cafe] Lazy IO and closing of file handles, http://tinyurl.com/2apf7f
05:06:45 <quicksilver> fasta: read that thread. weep. curse. swear never to use lazy IO again.
05:06:54 <b_jonas> mux: on unix, stdout is line-buffered only if it's a terminal, it's block buffered if it's a regular file or a pipe
05:07:08 <mux> b_jonas: sure, I know this. and it was a tty
05:07:09 <b_jonas> (that's what libcs do)
05:07:14 <b_jonas> ok
05:07:22 <b_jonas> because I sometimes find that highly annoying
05:07:44 <mux> what I find annoying is C code not handling this properly, not handling short reads/writes etc
05:07:49 <b_jonas> when I try to pipe some program I didn't write to a tee and the libc decides that it will do block-buffering the output
05:07:53 <mux> but at the moment I'm even more annoyed by GHC :-)
05:08:17 <quicksilver> fasta: executive summary is : automatic hClose will happen only if the handle gets GC'ed; if you're not doing much memory work, and your code is fast, a GC may not happen fast enough to close the file.
05:10:50 * mux notes it would be quite logical if main was in ReaderT + IO rather than just IO, and if things like std{in,out,err} and program command-line parameters were in the read-only state
05:11:11 <oerjan> > let alph = reverse (['A'..'Z']++['a'..'z']); seek n s n' | n == n' = [s] | otherwise = concatMap [seek n (c:s) n'' | c <- alph, let n'' = n' + ord c, n'' <= n] in seek 666 "" 0
05:11:19 <lambdabot>  Couldn't match expected type `a -> [b]'
05:11:39 <doserj> command-line parameters are writable on unix systems
05:11:41 <oerjan> > let alph = reverse (['A'..'Z']++['a'..'z']); seek n s n' | n == n' = [s] | otherwise = concat [seek n (c:s) n'' | c <- alph, let n'' = n' + ord c, n'' <= n] in seek 666 "" 0
05:11:46 <lambdabot>  ["Aqzzzz","Bpzzzz","Cozzzz","Dnzzzz","Emzzzz","Flzzzz","Gkzzzz","Hjzzzz","Ii...
05:13:38 <quicksilver> doserj: but we don't need to do that
05:13:46 <quicksilver> doserj: we have 'withArgs' which is cleaner
05:15:06 <mux> doserj: it makes no sense to leave them writable though, only setproctitle() is needed
05:15:23 <fasta> quicksilver: wouldn't a withReadFile <function arg working on string>  function work?
05:15:35 <fasta> quicksilver: I am reading the thread, still.
05:15:39 <quicksilver> fasta: yes, that would be really much nicer
05:15:56 <quicksilver> fasta: that would be safely lazy or not and it wouldn't matter to the caller
05:16:03 <quicksilver> s/would/could/
05:16:23 <mux> quicksilver: I've often wondered what was the point about linear substructural type systems when we can have with* functions
05:16:53 <mux> of course, with* functions can be implemented in an incorrect way, but well, there's not a lot of room for mistakes there :)
05:16:57 <DavidLeon> hi all
05:17:04 <mux> I can fully see the point of ordered type systems though
05:17:05 <DavidLeon> is there a way of marking a scope with a name?
05:17:13 <quicksilver> no
05:17:14 <DavidLeon> then i can refer to that scope
05:17:23 <DavidLeon> quicksilver: no?
05:17:33 <quicksilver> well, depends what kind of scope you mean
05:17:38 <quicksilver> there's only one kind of scope you can name
05:17:41 <quicksilver> that's "file scope"
05:17:47 <quicksilver> and you name it by making it a module
05:17:53 <DavidLeon> quicksilver: heh, func scope , ;)
05:17:54 <quicksilver> you can't name local scopes
05:18:06 <quicksilver> just try not to mask variables and you won't need to :)
05:29:05 <ndm> does anyone else get annoyed that we are being asked to correct a pirated edition of Hutton's book?
05:29:53 <fasta> quicksilver: I see hPutStrLn, but not something to read.
05:30:08 <Igloo> ndm: It's the blind guy, isn't it?
05:30:22 <ndm> Igloo: is he blind? in that case i'll let him off, i thought he was just stealing
05:30:23 <fasta> hGetLine
05:30:33 <fasta> Never mind
05:31:07 * Igloo assumes that if it was stolen it would either have been proofread or been accompanied with the pictures of the pages
05:31:23 <fasta> ndm: that's not stealing, it's copyright infringement in some countries.
05:31:23 <quicksilver> he is blind
05:31:37 <quicksilver> he may, of course, also have stolen it. But I don't think so :)
05:31:56 <quicksilver> fasta: hGetLine and hGetBuf are strict, I think
05:32:36 <fasta> quicksilver: ok, let me put it differently: what is the best way to do practically do it?
05:32:38 <drigz> quicksilver: oh, that kind of explains why his text is so large
05:32:45 <drigz> should i feel bad about complaining about that?
05:33:25 <quicksilver> fasta: I tend to use ByteString, which contains a strict getContents
05:33:36 <quicksilver> fasta: I agree that's a funny way around it
05:34:00 <oerjan> what about do s <- readFile f ; evaluate (length s); hClose f; return s
05:34:03 <quicksilver> fasta: otherwise, build a strict getContents out of hGetLine. Which is annoying.
05:34:06 <oerjan> wouldn't that work?
05:34:22 <quicksilver> oerjan: it's forbidden to hClose something which you have handed to readFile
05:34:29 <quicksilver> oerjan: the punishment is death
05:34:43 <oerjan> not according to the report
05:35:04 <oerjan> even if you _know_ it has been forced?
05:35:51 <fasta> @type hClose
05:35:54 <lambdabot> Not in scope: `hClose'
05:36:03 <fasta> @hoogle hClose
05:36:04 <oerjan> "Once a semi-closed handle becomes closed, the contents of the associated list becomes fixed. The contents of this final list is only partially specified: it will contain at least all the items of the stream that were evaluated prior to the handle becoming closed."
05:36:04 <lambdabot> IO.hClose :: Handle -> IO ()
05:36:26 <fasta> oerjan: your types don't match
05:36:33 <quicksilver> oerjan: hmm. I was wrong.
05:36:44 <wli> Close your handles. The GC is not very easy to work with.
05:37:06 <oerjan> oh wait
05:37:15 <oerjan> readFile doesn't give a handle
05:37:22 <quicksilver> oerjan: ah yes, that's the problem
05:37:27 <quicksilver> I forgot the details
05:37:43 <quicksilver> I knew there was something you couldn't do.
05:37:44 <quicksilver> ;)
05:37:44 <oerjan> however, there is another part of the report:
05:38:10 <oerjan> A semi-closed handle becomes closed: ... or once the entire contents of the handle has been read.
05:38:15 <quicksilver> right
05:38:30 <oerjan> so evaluating length _should_ close it.
05:38:59 <quicksilver> odd
05:39:05 <quicksilver> maybe fasta's problem is something else
05:39:19 <quicksilver> the fact remains this mess wouldn't be here if this lazy mess wasn't the default
05:39:43 * quicksilver campaigns for it all to be moved to UnsafeAndIrritatingToTypePleaseDontUse.IO
05:39:46 <quicksilver> :P
05:40:21 <EvilTerran> System.IO.ReallyLongNamesSoYouWontUseThem
05:41:16 <Cale> Lazy IO isn't so bad.
05:42:05 * EvilTerran has no idea what we're talking about, beyond that it probably already starts with unsafe
05:42:32 <drigz> you need it for when you're evangelising haskell on programming.reddit.com
05:43:18 <fasta> Cale: then tell us how to make sure I don't run out of open files?
05:43:22 <quicksilver> EvilTerran: getContents / readFile
05:43:27 <olsner> obligatoryUnsafeFunctionPrefix_with_ugliness_unsafePerformIO
05:43:36 <quicksilver> EvilTerran: no unsafe in sight
05:43:48 <EvilTerran> quicksilver, it's stealth unsafe \o/
05:43:51 <wli> I don't see the lazy IO as the real issue. AFAICT the two issues are handle lifetimes and error reporting.
05:44:02 <quicksilver> yes
05:44:14 <quicksilver> but those issues only arise because of lazy IO
05:44:20 <Cale> fasta: Don't open so many files ;)
05:44:24 <quicksilver> otherwise they are solved by brackets + catch
05:44:25 <oerjan> where is hGetContents defined?
05:44:28 <quicksilver> or 'with'
05:44:33 <EvilTerran> @index hGetContents
05:44:34 <lambdabot> System.IO
05:44:47 <oerjan> the source wasn't there
05:44:53 <oerjan> (for that function)
05:44:54 <Cale> or use the results of opening one file before you open the next
05:45:05 <EvilTerran> it must import it from somewhere, then
05:45:19 <quicksilver> Cale: that's not sufficient
05:45:20 <EvilTerran> @source System.IO
05:45:20 <lambdabot> http://darcs.haskell.org/packages/base/System/IO.hs
05:45:25 <Saizan> fasta: http://www.haskell.org/pipermail/haskell-cafe/2007-March/023527.html
05:45:27 <lambdabot> Title: [Haskell-cafe] Lazy IO and closing of file handles, http://tinyurl.com/2bol7t
05:45:28 <Cale> Control.Exception.evaluate is handy if you want to force evaluation to go in sequence with IO
05:45:30 <quicksilver> Cale: since you can't guarantee when the GC wll happen
05:45:31 <oerjan> Cale: fasta's problem is the file doesn't get closed even though he has used all of it
05:45:33 <wli> quicksilver: Not really. The lazy IO would be fine if the error reporting disaster were resolved. Handle lifetimes are less obvious how to resolve, and exist even without hGetContents etc.
05:45:43 <Saizan> fasta: you've to make readFile even lazier :)
05:46:03 <fasta> Saizan: ?
05:46:03 <Cale> quicksilver: tried a performGC?
05:46:26 <fasta> Cale: that would be an awfull hack.
05:46:33 <EvilTerran> @source IO
05:46:34 <lambdabot> IO not available
05:46:43 <quicksilver> Cale: any serious language which suggests you close your handles by calling 'performGC' deserves to be publically humiliated :P
05:46:44 <oerjan> @docs System.IO
05:46:44 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/System-IO.html
05:46:48 <fasta> awful*
05:46:50 <EvilTerran> @source GHC.IO
05:46:50 <lambdabot> GHC.IO not available
05:46:53 <oerjan> source link in upper right corner
05:47:05 <quicksilver> however, I don't know why fasta's version isn't working
05:47:17 <oerjan> but hGetContents is imported from somewhere else
05:47:18 <quicksilver> since I think he is completely reading the files
05:47:22 <quicksilver> so they should get closed
05:47:26 <Saizan> fasta: i haven't seen the structure of your code, but if you do something like mapM readFile files >>= \x -> e, all files are open before e
05:47:34 <Cale> Well, is there a reason to use lazy IO here?
05:47:42 <EvilTerran> oerjan, i know... it's importing it from GHC.IO/Hugs.IO/IO/NHC.IOExtras etc, though
05:47:47 <wli> quicksilver: Something like ErrorT e IO would help here.
05:47:53 <oerjan> EvilTerran: got a URL?
05:47:57 <fasta> Saizan: filterM is_foo =<< getDirectoryContents
05:48:00 <EvilTerran> http://darcs.haskell.org/packages/base/System/IO.hs
05:48:01 <quicksilver> Cale: none at all. Unfortunately the stanard libraries don't have a strict readFile
05:48:04 <Cale> If you're really having trouble with it, of course you can manage the handles manually.
05:48:06 <fasta> Saizan: That's the structure.
05:48:13 <EvilTerran> or do you mean for one of those? 'cos I can't see one of those
05:48:14 <oerjan> EvilTerran: for the _real_ source
05:48:25 <oerjan> i already found System.IO
05:48:31 <EvilTerran> ~\(-.-)/~
05:48:43 <Cale> They do have openFile, and things which operate on the handle that gives you.
05:48:58 <wli> I think the problem ends up being related to monad transformers vs. Haskell 98.
05:49:11 <fasta> Maybe, I should just call wc -l
05:49:32 <EvilTerran> got it - http://darcs.haskell.org/packages/base/GHC/IO.hs
05:49:32 <wli> You can't get reasonable error handling without monad transformers, but you can't get monad transformers in Haskell 98.
05:49:59 <hpaste>  EvilTerran pasted "hGetContents" at http://hpaste.org/2816
05:51:21 <quicksilver> wli: I don't think you're right, at all
05:51:34 <quicksilver> wli: lazy IO moves the exception out of the IO monad completely
05:51:42 <wli> quicksilver: Well, that's only one of the two problems.
05:51:45 <quicksilver> wli: you could have an exception triggered in a piece of pure code
05:52:13 <wli> quicksilver: That's actually what I'm on about.
05:52:33 <Cale> quicksilver: you can wrap up something which forces the reading to occur using evaluate and wrap that in a catch
05:53:44 <quicksilver> Cale: but if 99% of my code is pure, and the only bit of IO is some file boilerplate plus "let s = pureMain"
05:54:03 <wli> quicksilver: IMHO it shouldn't escape to pure code; there should be some viral error handling monad.
05:54:04 <Cale> quicksilver: Then there's no hope either way :)
05:54:12 <quicksilver> Cale: then wrapping that at the top level and having exception occur somewhere deep and impenetrable inside s is not very satisfactory
05:54:21 <EvilTerran> we need some intermediate level of stricture
05:54:44 <quicksilver> Cale: yes, there is plenty of hope. Strict IO (in the sense) and iteratee appraochs for partial reads
05:54:49 <quicksilver> Cale: otherwise known as callbacks
05:54:53 <quicksilver> there are ways of solving them
05:55:11 <quicksilver> the way that haskell chooses by default just provokes problems on #haskell and the cafe :)
05:55:13 <EvilTerran> something that can do the same sort of implicit lazy IO as getContents etc, but the magic can't escape from
05:55:16 <Cale> Yeah, but that doesn't look the same as what you wrote.
05:55:21 <quicksilver> Cale: true
05:55:41 <quicksilver> Cale: but then I acknowledge that I have to change my program structure if I want to process a huge file efficiently
05:55:47 <Cale> You already can open a file handle and read it even a character at a time if you want. I don't se what the problem is.
05:55:48 <quicksilver> Cale: making that admission is just being honest
05:55:50 <EvilTerran> i was talking about MonadSource yesterday - how about that?
05:56:01 <oerjan> :t foldM
05:56:06 <quicksilver> Cale: the problem is I disagree with the defaults in the library :)
05:56:06 <lambdabot> forall a b (m :: * -> *). (Monad m) => (a -> b -> m a) -> a -> [b] -> m a
05:56:18 <quicksilver> Cale: and the implicit recommendation that people use them
05:56:31 <quicksilver> provide an action call 'readFile' and people will assume it's a good thing to use it
05:56:47 <EvilTerran> quicksilver, yes, quite. the same goes, IMO, for Char IO being default
05:56:51 <Cale> If you're at the point where you're opening so many files that you have to worry about running out of file handles, then I think maybe you should be careful about managing each of them.
05:56:53 <EvilTerran> (and slightly broken Char IO at that)
05:57:17 <Cale> But for a very large class of programs, you're really only interested in one or two files, and lazy IO works rather well.
05:57:48 <quicksilver> EvilTerran: you mean Byte IO which pretends it has something to do with Chars ?
05:57:50 <fasta> Cale: I think the implementatation should call garbage collection on a specific part of the heap when one runs out of file handles.
05:57:52 <wli> There are a lot of issues with library design that can be resolved entirely with existing language features.
05:57:59 <EvilTerran> quicksilver, exactly
05:58:05 <Cale> fasta: that's true.
05:58:09 <fasta> Cale: Hugs does that in a simple way.
05:58:11 <quicksilver> wli: I'm certainly not suggesting language changes :)
05:58:26 <fasta> If you want a usable programming language, the implementation should abstract things it can.
05:58:28 <EvilTerran> if it really only does bytes, it should be producing [Word8]s
05:58:38 <fasta> I.e. every computable efficient function.
05:58:59 <Cale> quicksilver: I certainly wouldn't want getContents to be strict by default.
05:59:03 <EvilTerran> and then you could strap character encoding support on top of that
05:59:10 <wli> BTW I've narrowed down where to do monad comprehensions and do notation desugaring within the ghc intrinsics desugaring code.
05:59:26 <quicksilver> @go perils of getcontents
05:59:27 <lambdabot> http://www.haskell.org/pipermail/haskell-cafe/2007-March/023073.html
05:59:28 <lambdabot> Title: [Haskell-cafe] Takusen and strictness, and perils of getContents
05:59:39 <fasta> Opening and closing handles makes me think of C.
05:59:57 <wli> I'm just too dumb or otherwise too bogged down in other things to actually do much of anything with it.
06:00:02 <quicksilver> wli: ^^ in that article Oleg expresses my concerns more convingly and accurately than I normally do :)
06:00:14 <EvilTerran> System.IO.UTF8, System.IO.ISO8859, etc
06:00:32 <quicksilver> Cale: there should at least be a strict getContents sat right next to it
06:00:35 <olsner> I though monad comprehensions had already been in Haskell, but subsequently removed?
06:00:43 <quicksilver> Cale: along with a discussion of the properties of the two
06:00:54 <Cale> quicksilver: sure, call it getContents'
06:01:17 <wli> olsner: Yes. They should come back because the removal was due to some problems in/around error reporting vs. polymorphism in the Haskell 98 standardization process.
06:01:49 <wli> olsner: Which AIUI have since been either resolved or deemed irrelevant.
06:02:26 <quicksilver> It would be nice to have a standard way of swapping in/out libraries
06:02:36 <Cale> Well, the problem was that beginners using list comprehensions would get error messages about monads, and some people didn't like that.
06:02:38 <quicksilver> so that we could have (e.g.) a polymorphic version of Data.List
06:02:40 <EvilTerran> getContents' = length s `seq` s where s = getContents?
06:03:07 <quicksilver> which uses Foldable and Traversable to give more general types
06:03:15 <Cale> EvilTerran: you can do better
06:03:17 <quicksilver> but have "new programmers" use the concrete types
06:03:43 <EvilTerran> Cale, true. you could aviod lazy IO completely
06:03:53 <drigz> quicksilver: someone announce a Listable library didn't they
06:04:04 <drigz> sorry, ListLike
06:04:22 <Cale> EvilTerran: You can also read the whole file into a buffer in memory and only lazily convert that into a string.
06:04:37 <EvilTerran> a buffer? something packed?
06:04:51 <Cale> EvilTerran: yeah, the raw bytes
06:04:58 <EvilTerran> a BS.Char or something would work
06:05:04 <fasta> Is there a function that I give two lists that returns the set-difference that runs in O(n log n)? I can write it in two lines, but those things should be in the libs.
06:05:37 <quicksilver> drigz: yes, they did, but it's not quite polymorphic in the sense I meant
06:05:39 <olsner> Cale: but beginners get insane error messages about monads anyway ;-)
06:05:48 <EvilTerran> fasta, (\\)?
06:06:00 <EvilTerran> or do you mean the symmetric difference?
06:06:11 <quicksilver> Cale: getContents' = unpack . ByteString.getContents
06:06:20 <fasta> EvilTerran: that doesn't run in that time bound
06:06:24 <quicksilver> Cale: (where ByteString is the strict version)
06:06:38 <EvilTerran> fasta, how peculiar. and such an algorithm exists/
06:06:38 <EvilTerran> ?
06:06:51 <fasta> EvilTerran: of course there is an Ord constraint.
06:06:56 <oerjan> :t (Data.Map.\\)
06:07:02 <oerjan> :t (Data.Set.\\)
06:07:04 <EvilTerran> ah. it would've helped if you'd mentioned that.
06:07:05 <lambdabot> forall k a b. (Ord k) => Data.Map.Map k a -> Data.Map.Map k b -> Data.Map.Map k a
06:07:06 <lambdabot> forall a. (Ord a) => Data.Set.Set a -> Data.Set.Set a -> Data.Set.Set a
06:07:11 <fasta> EvilTerran: it seemed obvious
06:07:19 <EvilTerran> i guess, on reflection.
06:07:22 <fasta> oerjan: that's what I said about two lines
06:07:37 <EvilTerran> the SL seems to be a bit sparse on functions on sorted lists
06:07:40 <wli> Cale: What was the issue that resulted in the fail method for Monad?
06:08:05 <oerjan> fasta: well it seems difficult without sorting somehow
06:08:14 <Cale> wli: Well, after they removed monad comprehensions, someone noticed that MonadZero and MonadPlus no longer had to be separate
06:08:26 <oerjan> and Data.Set has all necessary functions
06:08:38 <Cale> wli: But pattern match failures would still cause problems.
06:08:43 <fasta> oerjan: I will just put it in my own "Util" module then.,
06:09:04 <fasta> oerjan: but I think that this is a very common operation.
06:09:25 <Cale> Since the translation of do-notation for failable patterns included mzero
06:09:31 * EvilTerran has never needed such a thing
06:09:37 <wli> Cale: So basically it was to nuke MonadZero from pattern match failures so newbies didn't see monads there, either.
06:09:39 <Cale> So they decided to add a fail to Monad to handle that.
06:09:56 <Cale> No, this is pattern match failures in do-blocks already
06:10:13 <Cale> Specifically, where you have  do { pat <- expr ; <stmts> }
06:10:48 <oerjan> fasta: it occurs to me that you could do this while preserving list order
06:11:01 <quicksilver> it's weird that pattern match failure are happy to use 'fail'
06:11:08 <quicksilver> but the function 'guard' uses mzero
06:11:28 <quicksilver> (and so, ironically, the better typed function produces less information, since it doesn't have an error message)
06:11:32 <Cale> In Haskell 1.4, if pat was a failable pattern, that was translated something along the lines of  let { f pat = do { <stmts> }; f _ = mzero } in expr >>= f
06:11:37 <oerjan> by only converting the subtracted list to a Set, and filtering over the other
06:11:43 <wli> Cale: But it was basically some sort of simplification though.
06:12:17 <Cale> and if it wasn't a failable pattern, it would get translated as expr >>= \pat -> do { <stmts> }
06:12:22 <wli> Presumably for "newbie friendliness" or some such.
06:12:38 <Cale> So using a failable pattern would cause a MonadZero constraint.
06:12:47 <Cale> That's a good thing, in my opinion.
06:13:06 <Cale> However, a MonadPlus constraint was considered too much.
06:13:23 <quicksilver> also, people don't like the idea that monad comprehensions might have different constraints
06:13:33 <quicksilver> depending on if they contain refutable patterns
06:13:41 * EvilTerran doesn't see the problem with that
06:13:46 <quicksilver> possibly partly because 'refutable' isn't a very elementary property
06:13:53 <quicksilver> but I don't find that convincing personally
06:14:04 <Cale> In my opinion, that's silly, since their type already depends on their contents pretty severely.
06:14:44 <EvilTerran> but then, i wouldn't mind if there were a load of restricted IO monad classes, and you got things of the type (MonadIOHandles m, MonadIOThreads m => m a) or whatever
06:14:57 <EvilTerran> more specificity is *good*!
06:15:03 <quicksilver> EvilTerran: yes, that would be really nice
06:15:23 * EvilTerran has thought about writing that. it'd be kinda clunky, i think.
06:15:38 <Cale> It's actually not *quite* the same as refutable.
06:15:44 * EvilTerran notes that he put that ) in the wrong place
06:16:04 <quicksilver> EvilTerran: it gets more interesting if you can imagine ways to generalise further
06:16:06 <Cale> (a,b) is a refutable pattern, but it's not a failable pattern
06:16:26 <quicksilver> EvilTerran: can we change MonadIOThreads to MonadForkable?
06:16:40 <quicksilver> EvilTerran: can I imagine forking in a non-IO context?
06:17:17 <EvilTerran> o/` spam spam spam spam spam LOVELY SPAM WONDERFUL SPAM o/`
06:17:22 --- mode: ChanServ set +o Cale
06:17:24 <EvilTerran> incompetent spam, at that
06:17:36 --- mode: Cale set +b backco!*@*
06:17:56 --- mode: Cale set -o Cale
06:18:34 * EvilTerran is reminded of the guestbook spam he's seen where the href's of the <a>s are empty, owing to (i presume) incompetence on the part of the spammer
06:20:04 <EvilTerran> quicksilver, i'm not sure what you mean...
06:20:39 <quicksilver> EvilTerran: can you write forkST, for example?
06:20:54 <quicksilver> EvilTerran: and then can you write 'fork-using' code which could be run in either IO or ST?
06:21:01 <EvilTerran> hm...
06:21:07 <EvilTerran> i don't know how ST works.
06:21:29 <EvilTerran> the impression i have is that it's the IORefs bit of IO and no other parts
06:22:04 <quicksilver> and the mutable array parts
06:22:13 <EvilTerran> in which case i think it'd be rendered redundant with my idea, replaced with the lower bound of (MonadIORefs m => m)
06:22:27 <quicksilver> but one could imagine it could be perfectly safe to 'fork' non-IO code
06:22:42 <quicksilver> which used an appropriately polymorphic version of MVars
06:22:56 <EvilTerran> again, i don't quite follow
06:24:12 <EvilTerran> i get the feeling that, anywhere where forking is appropriate, there's probably going to be IO or a newtype thereof lurking somewhere
06:24:19 <quicksilver> Igloo++ # http://urchin.earth.li/pipermail/debian-haskell/2007-June/000322.html
06:24:20 <lambdabot> Title: [Debian-haskell] Packaging a Cabal package in 10 easy steps, http://tinyurl.com/yspgf9
06:24:21 <fasta> Shouldn't filterM return everything for which the predicate returns True?
06:24:27 <oerjan> @src STM
06:24:27 <lambdabot> Source not found. It can only be attributed to human error.
06:24:40 <EvilTerran> in order for the threads to interact meaningfully
06:24:42 <EvilTerran> @type filteRM
06:24:44 <EvilTerran> @type filterM
06:24:44 <lambdabot> Not in scope: `filteRM'
06:24:46 <lambdabot> forall a (m :: * -> *). (Monad m) => (a -> m Bool) -> [a] -> m [a]
06:25:10 <fasta> I print the return value in the predicate. It says "True". When I see how many results there were(length results), it says 0.
06:25:19 <EvilTerran> > filterM (Just . odd) [1..10]
06:25:19 <fasta> This is completely inconsistent
06:25:22 <lambdabot>  Just [1,3,5,7,9]
06:25:35 <oerjan> fasta: paste?
06:26:47 <quicksilver> fasta: it doesn't necessarily return all the values, since it depends on the monad
06:27:03 <quicksilver> fasta: for example, if the monad was Maybe, then a single Nothing woudl short-circuit it all
06:27:35 <oerjan> but then there would be no list whose length could be 0.
06:27:37 <EvilTerran> > filterM (\x -> guard (odd x) >> Just x) [1..10]
06:27:38 <lambdabot>   add an instance declaration for (Integral Bool)
06:27:59 <EvilTerran> ?
06:28:01 <ricky_clarkson> :t (>>)
06:28:03 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> m b -> m b
06:28:11 <EvilTerran> ah
06:28:15 <EvilTerran> > filterM (\x -> guard (odd x) >> Just True) [1..10]
06:28:16 <lambdabot>  Nothing
06:28:41 <quicksilver> oerjan: that's a very good point :)
06:29:05 * EvilTerran would appreciate a function to the effect of "\p x -> guard p >> return x"
06:29:48 <fasta> oerjan, quicksilver: http://paste.debian.net/37527
06:30:24 <EvilTerran> @. docs index getDirectoryContents
06:30:24 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/index.html
06:30:36 <EvilTerran> ...
06:30:42 <EvilTerran> @index getDirectoryContents
06:30:42 <lambdabot> System.Directory, Distribution.Compat.Directory
06:30:50 <fasta> It seems it appears to depend on laziness.
06:32:21 <oerjan> bizarre.
06:33:44 <oerjan> :t withFile
06:33:47 <lambdabot> Not in scope: `withFile'
06:34:12 <fasta> oerjan: That function is not documented, but it is exposed.
06:34:21 <oerjan> source?
06:34:37 <fasta> oerjan: see some GHC tree.
06:34:43 <fasta> oerjan: System.IO
06:36:17 <fasta> This is also terribly slow.
06:36:19 * EvilTerran agrees that that's the most likely suspect
06:36:41 <oerjan> impossible.
06:36:58 <fasta> The total file size is about 2GB.
06:37:07 <oerjan> withFile is not mentioned in the source of System.IO.
06:37:17 <fasta> oerjan: ok, let me recheck.
06:37:42 <quicksilver> fasta: to do fast line counting on large files, you should definitely use ByteString
06:37:42 <fasta> oerjan: yes, it is.
06:37:49 <fasta> oerjan: ghc/libraries/base/System/IO.hs
06:37:52 <quicksilver> fasta: not that I think it will solve your other problem
06:38:05 <fasta> quicksilver: the file handles are not a problem anymore
06:38:14 <oerjan> http://darcs.haskell.org/ghc-6.6/packages/base/System/IO.hs -- nothing there
06:38:18 <quicksilver> fasta: you said it was slow
06:38:27 <wli> fiddleWithFile :: FilePath -> (String -> t) -> ErrorT IOError IO?
06:38:31 <quicksilver> fasta: bytestring length . lines is faster than system wc -l
06:38:36 <wli> er
06:38:41 <fasta> oerjan: how about you take the HEAD?
06:38:52 <EvilTerran> fasta, try http://paste.debian.net/37528 ?
06:39:44 <fasta> EvilTerran: I don't see the difference.
06:39:54 <wli> ErrorT IOError IO t
06:40:06 <EvilTerran> meh. sanity checking.
06:40:58 <EvilTerran> it should be the same, but it just might not be, if things're being weird.
06:41:45 <fasta> Where are all those AsFastAsC "wc" implementations when you need them...
06:42:26 <ndm> www.cs.york.ac.uk/~ndm/supero
06:42:32 <ndm> fasta: ^^^
06:43:52 <quicksilver> fasta: just B.length . B.lines will be much faster
06:44:04 <quicksilver> (B.hGetContents too)
06:44:12 <quicksilver> in case you don't feel like installing supero :)
06:44:16 <quicksilver> although supero is certainly cool
06:45:10 <fasta> ndm: I meant something that works _now_ and on GHC without hassle.
06:45:33 <ndm> fasta: you should be more specific :)
06:46:01 <ndm> quicksilver: if you manage to install and build supero i would be impressed, i borrowed a laptop and couldn't get it working myself
06:46:35 <quicksilver> ndm: ;) I have never tried
06:46:36 <fasta> E.g. I want gold, people shouldn't tell me "hey on this asteroid, there is plenty".
06:46:55 <fasta> if I*
06:48:31 <wli> Maybe something like:
06:48:32 <wli> withFile :: (String -> t) -> FilePath -> ErrorT IOError IO t ; f `withFile` path = liftIO $ (readFile path >>= return . f) `catch` throwError
06:49:19 <quicksilver> wli: I'm not sure why you think that's better than just IO?
06:49:33 <quicksilver> wli: you can catch IOErrors just as well in vanilla IO as in ErrorT IOError IO
06:50:02 <fasta> Oh, great. It is a problem with laziness/withFile/whatever.
06:50:21 <oerjan> @instances-importing Control.Monad.Error MonadError
06:50:22 <lambdabot> IOError IO, e (Either e), e (ErrorT e m), e (RWST r w s m), e (ReaderT r m), e (StateT s m), e (WriterT w m)
06:50:28 <fasta> I let the computation complete (took about 10 minutes) and indeed it returned the intended answer now.
06:50:34 <oerjan> (look at #1)
06:50:35 <wli> quicksilver: There were AIUI objections to the exceptions getting raised from the pure code handling the read file data.
06:51:12 <quicksilver> wli: right, but by the time you get back out to IO...
06:51:17 <quicksilver> wli: it doesn't matter any more
06:51:39 <quicksilver> wli: if you changed 'f' from 'String -> t' to 'String -> Either IOError t'
06:51:45 <quicksilver> wli: then that might make sense
06:51:54 <quicksilver> although ti wouldn't actually refelct the way haskell evaluates
06:52:01 <wli> quicksilver: Okay, sure.
06:52:41 <wli> quicksilver: It seems your suggestion is just flip withFile as I defined withFile
06:54:14 <fasta> quicksilver: B.length?
06:54:19 <fasta> quicksilver: you meant length?
06:54:35 <quicksilver> fasta: I meant import qualified ByteString.Char8 as B
06:54:47 <fasta> quicksilver: I got that, never mind.
06:54:48 <quicksilver> fasta: then B.length . B.lines
06:54:54 <quicksilver> (oops, Lazy.Char8)
06:56:06 <fasta> quicksilver: lines returns a list of byte strings
06:56:22 <fasta> quicksilver: B.length works on bytestrings, not lists.
06:57:13 <quicksilver> fasta: oh, sorry. Thinko then.
06:57:34 <fasta> quicksilver: that gets back the resource exhaustion problem
06:57:51 <fasta> Cool, to be in an infinite chain of horror.
06:59:43 <quicksilver> yay!
06:59:53 <oerjan> :t System.IO.hIsEOF
06:59:58 <lambdabot> GHC.IOBase.Handle -> IO Bool
07:02:06 <fasta> Ok, this is better.
07:02:22 <oerjan> hLength h = hl 0 where hl n = hIsEOF h >>= \b -> if b then n else do hGetLine h; n `seq` hl (n+1)
07:02:23 <fasta> Using h<foo> from ByteString
07:02:42 <fasta> Now, CPU usage has gone from 90% to 2%.
07:03:02 <fasta> Which is what one would expect.
07:04:03 <fasta> Now all I need is faster I/O :)
07:04:20 <fasta> hGetBufNonBlocking: illegal operation (handle is closed)
07:04:20 <Tac-Work> why does GHC default to line-buffered IO o__O
07:04:31 <fasta> ...
07:04:38 <fasta> As, I said, an infinite chain of horror.
07:05:07 <oerjan> fasta: you might try my function above, although it doesn't use ByteStrings...
07:05:49 <wli> I think once I unravel the Senatorial rules to where each distinct vote is broken down to a non-transferrable instance the fixed point can be found with flow algorithms or linear programming or some such. I'm just at a loss to set up the equations.
07:07:14 <fasta> oerjan: your function is ill-typed. I will repair it.
07:07:25 <oerjan> no it isn't
07:07:37 <oerjan> oh wait
07:07:43 <oerjan> yes it is
07:07:53 <oerjan> forgot a return
07:08:02 <quicksilver> Tac-Work: I don't think it does?
07:08:17 <fasta> oerjan: you mean two returns?
07:08:24 <oerjan> no, just one
07:08:39 <oerjan> hLength h = hl 0 where hl n = hIsEOF h >>= \b -> if b then return n else do hGetLine h; n `seq` hl (n+1)
07:09:14 <fasta> oerjan: oops
07:09:17 <fasta> oerjan: right, 1
07:09:25 <quicksilver> Tac-Work: the haskell standard doesn't specify but in practice I think ghc compiled apps line-buffer terminals and block-buffer other files
07:09:40 <quicksilver> Tac-Work: which is in alignment with what libc does on most unixy OSes
07:10:14 <fasta> CPU usage up a factor 30
07:11:00 <fasta> Why is there no hGetLine for ByteStrings?
07:11:09 <oerjan> there isn't? :(
07:11:10 <Tac-Work> is it now?
07:11:32 <Tac-Work> it's just kind of annoying that I have to flush my socket handles every time I send
07:11:33 <fasta> For lazy bytestrings*
07:11:48 <oerjan> fasta: you don't need to use lazy
07:12:06 <oerjan> you're only reading single lines, after all
07:12:35 <Cale> oerjan: single line files?
07:12:37 <oerjan> i think.
07:12:45 <oerjan> Cale: single lines from files
07:12:53 <oerjan> if using my function.
07:13:05 <quicksilver> Cale: he's only counting the lines. It would be fine to read + discard strictly, one line at a time.
07:13:10 <Cale> For lazy bytestrings you can just apply lines and then head
07:13:14 <quicksilver> Tac-Work: turn buffering off then?
07:13:18 <Cale> ah
07:13:36 <Tac-Work> I know I can change the buffering type
07:13:38 <fasta> Still, CPU at 30%
07:13:41 <oerjan> Cale: once again, the problem is his handles do not get closed when he reads them lazily
07:13:48 <oerjan> unless he fixed that
07:13:51 <Tac-Work> it just feels like a weird default
07:13:59 <quicksilver> Tac-Work: I think you could probably argue it's a weird default for sockets, yes
07:14:06 <quicksilver> Tac-Work: it's a sane default for files, though
07:14:14 <fasta> oerjan: that problem has already been "solved" by explicit closing.
07:14:16 <quicksilver> Tac-Work: and it has the weight of history behind it :)
07:14:24 <Tac-Work> I guess line buffering is the more Haskellesque way to do it though.
07:14:27 <oerjan> ok
07:14:36 <Tac-Work> Since it's so lazy, it doesn't even send until you flush it
07:14:49 <quicksilver> Tac-Work: that's got nothing to do with haskell IMO
07:14:56 <quicksilver> Tac-Work: that's how IO works on unix-like systems
07:15:15 <Tac-Work> It was a joke, but yeah =-P
07:15:15 <oerjan> and only for terminals
07:15:20 <oerjan> iiuc
07:15:22 <quicksilver> Tac-Work: It (Im' pretty sure) is block buffered not line
07:15:29 <Tac-Work> ah
07:15:31 <quicksilver> oerjan: he's doing sockets, not terminals
07:15:47 <Tac-Work> block buffered would be sent after 255 (or some other number n) bytes have been sent?
07:15:51 <oerjan> files, i thought?
07:16:06 <quicksilver> Tac-Work: normally 8k or some multiple of 8k
07:16:19 <quicksilver> oerjan: 15:10 < Tac-Work> it's just kind of annoying that I have to flush my socket"
07:16:21 <Tac-Work> I see I see
07:16:34 <quicksilver> Tac-Work: this is what you *definitely* want if you're uploading or downloading files
07:16:40 <quicksilver> Tac-Work: etc :)
07:17:06 <quicksilver> Tac-Work: your ethernet card has DMA support; that is only useful if buffers are being used.
07:17:07 <Tac-Work> I was just trying to get some simple HTTP transaction going, and it was freezing on me
07:17:08 <oerjan> quicksilver: whoops, i thought he was also discussing fasta's problem
07:17:19 <oerjan> didn't pay attention
07:17:27 <Tac-Work> but I've played with sockets in other languages enough to know it wasn't flushing
07:17:44 <quicksilver> Tac-Work: yup. Agreed. You'll read about this in any basic text on sockets or unix network programming
07:17:59 <quicksilver> Tac-Work: you have to 'flush' after every command on a command-stream-type connection
07:18:09 <quicksilver> like GET / HTTP/1.1\r\n\r\n
07:18:26 <Tac-Work> yeah
07:18:49 <wootles> I am getting (f 50, g 50) == (12,12), but (f 50) - (g 50) == 4 .... how is that possible O_o
07:19:19 <oerjan> wootles: shouldn't be?
07:19:39 <wootles> that;s what i thought, side effects can't occur right
07:20:07 <oerjan> in theory there could be some weird overloading...
07:20:26 <Saizan> wootles: types of each?
07:20:59 <kpreid> a weird Show instance?
07:21:11 <oerjan> !paste
07:21:12 <wootles> i dont understand types well yet , i havent done anything fancy, everything uses integers
07:21:12 <hpaste> Haskell paste bin: http://hpaste.org/
07:21:14 <Saizan> i can only think of some strange overflow happening somewhere depending on the concrete type
07:21:41 <oerjan> even that seems impossible
07:21:49 <oerjan> wootles: paste code? ^^^
07:21:55 <wootles> ok
07:22:01 <wootles> spoilers if you are doing project euler lol
07:22:20 <hpaste>  wootle pasted "wtf" at http://hpaste.org/2817
07:22:53 <wootles> in GHCi i get:
07:23:00 <wootles> gettrails 50 = 12
07:23:19 <wootles> specmult (fac 50) 1 = 12
07:23:40 <wootles> ((specmult (fac 50) 1)) - (gettrails 50) = 4
07:24:02 <quicksilver> your paste doesn't include fac?
07:24:05 <Tac-Work> forkIO __isn't__ just POSIX fork, is it?
07:24:16 <quicksilver> Tac-Work: hell no
07:24:17 <kpreid> Tac-Work: Not at all.
07:24:23 <Tac-Work> ok good
07:24:25 <kpreid> Tac-Work: that's forkOS
07:24:33 <quicksilver> kpreid: no, even that isn't posix fork
07:24:43 <infrared> is it possible to define a function which takes variable number of arguments?
07:24:50 <quicksilver> forkOS is still threads
07:24:56 <quicksilver> infrared: Yes, but you probably don't want to
07:25:00 <kpreid> infrared: wackily: see Text.Printf
07:25:03 <kpreid> but don't do that.
07:25:08 <fasta> Calling wc -l <foo> /bin/sh: setNonBlockingFD: invalid argument (Bad file descriptor)
07:25:08 <wootles> it's just vanilla factorial :  fac n  | (n > 0)   = n * fac(n-1) | otherwise = 1
07:25:31 <fasta> This is insane.
07:25:32 <ricky_clarkson> Is there some language where you can designate a function's params as strict, or lazy (whatever the opposite to the default is for that language)?
07:25:47 <fasta> ricky_clarkson: GHC Haskell
07:25:49 <infrared> quicksilver: why not? i know i want to :)
07:25:49 <fasta> ricky_clarkson: use !
07:26:01 <ricky_clarkson> Ok, and the other way around?
07:26:05 <fasta> ricky_clarkson: a !b = "b is strict"
07:26:06 <oerjan> wootles: is this error repeatable?
07:26:16 <fasta> ricky_clarkson: simply no annotation
07:26:17 <ricky_clarkson> fasta: Does it work like memoisation?
07:26:33 <oerjan> and btw are you using hugs or ghc?
07:26:40 <ricky_clarkson> ..no, I mean, some language that is strict by default but can use laziness via some annotation.
07:26:44 <fasta> ricky_clarkson: imho, you shouldn't depend on the memory management of your implementation.
07:26:48 <wootles> oerjan: im using GHCi, i tried reloading it, turning off optimisations etc
07:27:01 <Saizan> wootles: gettrails :: Int -> Int, but specmult :: Integral a => a -> a -> a, so when you ask for specmult (fac 50) 1 you get an Integer (because of defaulting) but when you compare it with gettrails you get an Int which leads to overflow, i think
07:27:15 <oerjan> aha
07:27:41 <kpreid> Int is evil!
07:27:41 <quicksilver> how does gettrails end up being Int -> Int, though?
07:28:26 <kpreid> @type repeat
07:28:28 <lambdabot> forall a. a -> [a]
07:28:32 <kpreid> hm, no, not relevant
07:28:35 <kpreid> aha
07:28:37 <kpreid> quot n 100
07:28:39 <kpreid> @type quot
07:28:41 <lambdabot> forall a. (Integral a) => a -> a -> a
07:28:43 <quicksilver> no
07:28:46 <quicksilver> it's 'take' and 'drop'
07:28:54 <quicksilver> ah well, there isn't a drop
07:28:57 <kpreid> in dothemult, quot n 100 is given to take
07:28:57 <quicksilver> but it's 'take' anyhow
07:29:00 <fasta> What does wc <defunct> mean in top?
07:29:08 <doserj> :t take
07:29:10 <lambdabot> forall a. Int -> [a] -> [a]
07:29:14 <doserj> that is the problem
07:29:24 <quicksilver> fasta: finished but never reaped
07:29:36 <kpreid> wootles: use genericTake, and add some type sigs to your functions to make it explicit you want Integer
07:29:37 <quicksilver> fasta: you have to waitpid() , or, in haskell, waitForProcess
07:29:42 <infrared> ricky_clarkson: you can make lisp lazy if you want
07:29:50 <fasta> quicksilver: oh, right, another thing I always forget
07:30:01 <wootles> ok
07:30:02 <fasta> quicksilver: computing is so easy in Haskell, IO is always a pain.
07:30:09 <quicksilver> infrared: "why not?" because it's better to give your functions a type which makes sense
07:30:34 <quicksilver> infrared: instead of variable args, you take either a list of args, or some more complex structure which correct reflects the type you want to accept
07:30:44 <ricky_clarkson> infrared: How?
07:30:52 <ricky_clarkson> (other than a defun-wrapping macro)
07:31:19 <infrared> quicksilver: well, i actually want the list of args, but with extra syntactic sugar (i.e. not having to write "fun [1,2,3]" but simply "fun 1 2 3")
07:31:25 <wootles> what is the difference between Int, Integral and Integer then?
07:31:37 <quicksilver> wootles: range
07:31:42 <quicksilver> wootles: Ints are 32 or 64 bit
07:31:46 <quicksilver> wootles: so 50! overflows
07:31:50 <quicksilver> wootles: Integer is unbounded
07:32:10 <quicksilver> infrared: your syntactic sugar would be at the cost of having a sane type
07:32:18 <oerjan> Integral is a common type class they are both in
07:32:19 <quicksilver> infrared: :)
07:32:19 <wootles> Int is for interoperability ?
07:32:29 <quicksilver> wootles: it's quite a lot faster
07:32:30 <infrared> ricky_clarkson: it depends what exactly you want to achieve. lazy lists (and other data structures) are easy to implement. if you want more, macros are way to go
07:32:38 <ricky_clarkson> infrared: Of course.
07:32:58 <fasta> quicksilver: I still get: Main: /bin/sh: setNonBlockingFD: invalid argument (Bad file descriptor)
07:33:07 <fasta> quicksilver: any idea what that might be?
07:34:06 <infrared> ricky_clarkson: but then again, you'd have to reimplement part of haskell interpreter using lisp macros ;)
07:34:09 <quicksilver> fasta: no. That's an odd one.
07:34:52 <infrared> quicksilver: ok then, i guess template haskell could do exactly what i want, yes?
07:35:06 <fasta> quicksilver: http://tunes.org/~nef/logs/haskell/05.11.29
07:35:11 <fasta> quicksilver: I am not the only one
07:36:14 <Saizan> infrared: f :: [a] -> b for some a and b, $(apply f a1 a2 a3 ..) ?
07:36:35 <wootles> quicksilver: so I need to make it explicit that my functions are Integer->Integer ? in order to stop it casting/truncating behind my back
07:37:08 <quicksilver> wootles: that would, at least, give you error message in the right places
07:39:20 <wootles> quicksilver: i dont understand the haskell error messages, i just move brackets around until they go away... they make c++ template errors look like monosyllabic grunts :(
07:39:41 <oerjan> ouch
07:39:51 <fasta> quicksilver: it seems to be bug in wc
07:39:58 <fasta> a bug*
07:40:02 <Saizan> wootles: you should read more on types and typeclasses, i think
07:40:03 <oerjan> @remember wootles quicksilver: i dont understand the haskell error messages, i just move brackets around until they go away... they make c++ template errors look like monosyllabic grunts :(
07:40:04 <lambdabot> Done.
07:40:37 <puusorsa> <3
07:41:56 <oerjan> @quote add.type
07:41:56 <lambdabot> No quotes match. Just what do you think you're doing Dave?
07:42:49 <oerjan> wootles: when you get type errors you don't understand, a good idea is to add type declarations for what you think the types should be
07:43:38 <oerjan> then the compiler can usually tell you more precisely what makes it wrong
07:44:01 <olsner> heh, that's how you see the difference in sophistication between the languages :P
07:44:44 <infrared> btw, any chance of Haskell Weekly News coming back?
07:45:05 <oerjan> i thought there was one not that long ago
07:45:15 <ndm> infrared: what it needs is a volunteer
07:45:19 <quicksilver> there was one not *that* long ago
07:45:26 <quicksilver> but the last one was, IIRC, before dons' new job
07:45:36 <quicksilver> time will tell if he has time whilst doing the new job, but likely he won't
07:45:47 <infrared> the last one was ~6 weeks ago
07:49:38 <fasta> quicksilver: I fixed it
07:49:48 <quicksilver> fasta: what was the problem?
07:49:52 <fasta> quicksilver: It's a completely ridiculous reason
07:50:04 <fasta> quicksilver: I write to stdout to see what file I am reading in Haskell
07:50:23 <fasta> quicksilver: I read the stdout from the wc program
07:50:39 <fasta> quicksilver: when I remove the print, it works.
07:51:06 * quicksilver doesn't think he understands
07:51:37 <fasta> quicksilver: actually, that isn't true
07:51:50 <fasta> quicksilver: I also need one call to putStrLn to force something, I guess.
07:52:01 <fasta> quicksilver: I don't understand it too.
07:52:09 <fasta> quicksilver: it's a mess and crap, imho.
07:54:03 <wli> No tips on improving the code I hpasted?
07:54:32 <wli> It's at http://hpaste.org/2815
07:57:42 <quicksilver> wli: you could significantly shorten that code
07:57:51 <quicksilver> wli: by putting more nto each line :)
07:57:51 <puusorsa> http://people.csail.mit.edu/rahimi/helmet/
07:58:07 <wli> quicksilver: Well, I was hoping for something more semantic or algorithmic.
07:58:22 <quicksilver> wli: it's a bit big to quickly grok and give comments on
07:58:23 <dino-> fasta: Forgive me for coming to this late, but are you waitForProcess on that thing executing wc?
07:58:52 <fasta> dino-: yes
07:59:04 <wli> quicksilver: Some of the verbosity helps document it.
07:59:39 <fasta> quicksilver, dino-: http://paste.debian.net/37531
07:59:40 <wli> quicksilver: Like the long descriptive variable names and monomorphic type decls for everything.
07:59:44 <quicksilver> wli: looks fairly nice to me. I like the use of unionWith
08:00:15 <wli> quicksilver: Hmm. It may be that this is as far as it goes.
08:01:10 <sjanssen> wli: I'd probably replace your typedefs with newtypes, and use Monoid instead of unionWith all over the place
08:01:16 <sjanssen> but that's just personal preference
08:01:29 <wli> sjanssen: Good ideas on both fronts.
08:01:34 <fasta> sjanssen: do you have any idea why http://paste.debian.net/37531 gives /usr/bin/wc: setNonBlockingFD: invalid argument (Bad file descriptor)?
08:01:41 <quicksilver> sjanssen: how can you replace a unionWith with a Monoid?
08:02:14 <wli> quicksilver: Map.unionWith (+) would be mappend in such a scheme.
08:02:23 <sjanssen> quicksilver: well, with mappend actually :).  You'd need to write the necessary Monoid instance
08:02:48 <quicksilver> sjanssen: but he also has uses of fromListWith (+)
08:02:49 <sjanssen> fasta: perhaps wc has problems with handles in non-blocking mode?
08:03:01 <sjanssen> quicksilver: yes, slightly problematic
08:03:12 <quicksilver> sjanssen: you'd risk losing uniformity
08:03:41 <quicksilver> would be cute if 'Map.unionWith' took a Monoid instance as a parameter, and fromListWith similarly
08:03:56 <sjanssen> fromListWith (+) could become: mconcat $ map (Map.singleton)
08:03:56 <quicksilver> if only we could send instances (dictionaries) as first-class things
08:03:59 <wli> That's one of the uglier parts of the code. I don't see a good way around it.
08:04:17 <wli> The Map.fromListWith (+) call that is.
08:04:38 <fasta> sjanssen: when I put a putStrLn to the output of the parsed result, the program works.
08:04:55 <quicksilver> fasta: does it help to hClose that stdout (wc's stdout)? And is that B. lazy or strict bytestrings?
08:05:36 <fasta> quicksilver: hClose helps
08:05:45 <olsner> :t Data.Map.fold (Data.Map.unionWith (Data.Map.unionWith (+)))
08:05:47 <lambdabot> forall a k k1 k2. (Num a, Ord k, Ord k1) => Data.Map.Map k1 (Data.Map.Map k a) -> Data.Map.Map k2 (Data.Map.Map k1 (Data.Map.Map k a)) -> Data.Map.Map k1 (Data.Map.Map k a)
08:06:32 <fasta> CPU usage doesn't even come up in top, because every wc returns so quickly.
08:07:48 <sjanssen> fasta: btw, why don't you use hpaste?
08:08:22 <sjanssen> this pastebin annoyingly copies the line numbers when you select the code
08:08:26 <fasta> sjanssen: It makes sure my code isn't eternalized.
08:09:39 <fasta> quicksilver: fd:6: hGetBufNonBlocking: illegal operation (handle is closed)
08:09:56 <quicksilver> yay
08:10:01 <quicksilver> switch back to strict bytestrings?
08:10:01 <dino-> sjanssen: Maybe clipping out of the edit control lower down is better.
08:10:05 <sjanssen> fasta: which ByteString are you using?
08:10:14 <sjanssen> dino-: yeah, that's what I did at the end
08:10:23 <fasta> sjanssen:  Data.ByteString.Lazy.Char8
08:10:29 <dino-> I didn't see it at first either, until I scrolled down.
08:10:52 <quicksilver> I fail to understand how people can continue to defend lazy IO when we get messes like this so often
08:10:57 <sjanssen> @hoogle getFile
08:10:58 <lambdabot> System.Console.Readline.getFilenameCompletionDesired :: IO Bool
08:10:58 <lambdabot> System.Console.Readline.getFilenameQuoteCharacters :: IO String
08:10:58 <lambdabot> System.Console.Readline.getFilenameQuotingDesired :: IO Bool
08:11:00 <mux> btw, does anyone know why ByteString only offers a constrained map interface?
08:11:07 <quicksilver> (in this channel at least)
08:11:10 <sjanssen> fasta: what are getFile and somedir
08:11:10 <mux> :t Data.ByteString.Char8.map
08:11:12 <lambdabot> (Char -> Char) -> Data.ByteString.Base.ByteString -> Data.ByteString.Base.ByteString
08:11:28 <mux> but it's offering generic folds
08:11:28 <quicksilver> mux: were you hoping for (Char -> a) ?
08:11:32 <mux> :t Data.ByteString.Char8.foldl
08:11:34 <lambdabot> forall a. (a -> Char -> a) -> a -> Data.ByteString.Base.ByteString -> a
08:11:34 <mux> quicksilver: yes
08:11:40 <quicksilver> mux: what would the reulst type be?
08:11:47 <quicksilver> mux: there is no Data.AString ;)
08:11:48 <fasta> sjanssen: somedir is <some directory path>, getFile is a function that attaches "foo" before the file to make a path
08:11:57 <sjanssen> mux: because you can get the other behavior with "map f . unpack", and "pack . map f . unpack" is hopelessly slow
08:12:07 <mux> quicksilver: hmm? I was hoping for (Char -> a) -> ByteString -> [a]
08:12:12 <quicksilver> mux: map f . unpack
08:12:19 <mux> sure sure :-)
08:12:24 <mux> I know how to work around it
08:12:31 <quicksilver> that's not a workaround
08:12:31 <mux> I'm just wondering what the rationale for this is
08:12:34 <quicksilver> it's the answer :)
08:12:40 <sjanssen> mux: because pack . unpack is really really slow
08:12:41 <mux> I mean, there could be two map functions exported
08:12:49 <quicksilver> sjanssen: pack . map f . unpack will stream-fuse, surely ?
08:12:51 <sjanssen> mux: so they'd need to have the constrained version *somewhere*
08:13:10 <sjanssen> quicksilver: the released version doesn't have stream fusion, it doesn't work without -O, doesn't work in Hugs, etc.
08:13:17 <mux> sjanssen: yup, not denying this; but I don't get why there is not another map function exported, a more generic one
08:13:20 <sjanssen> not to mention that it's a bit annoying to write out
08:13:38 <quicksilver> "it's a bit annoying to write out" is the argument for mux's (Char -> a) version though
08:13:38 <sjanssen> mux: because map f . unpack is really easy to write :)
08:13:41 <quicksilver> ;)
08:13:45 <mux> sjanssen: okay :-)
08:14:05 <sjanssen> > length "pack . map f . unpack" > length "map f . unpack" -- :)
08:14:06 <lambdabot>  Unbalanced parenthesis
08:14:11 <sjanssen> damnit
08:14:14 <sjanssen> > length "pack . map f . unpack" > length "map f . unpack"
08:14:16 <lambdabot>  True
08:14:46 <fasta> sjanssen: when I use strict byte strings, it works
08:15:06 <fasta> sjanssen: now, can you explain to be why the lazy byte strings interact so horribly?
08:15:17 <fasta> me*
08:15:25 <quicksilver> fasta: this is where we came in
08:15:37 <quicksilver> fasta: although I was actually wrong, when I thought this was your problem, at the start
08:15:43 <quicksilver> but it's what I *thought* was your problem
08:15:59 <quicksilver> the handles don't get closed
08:16:05 <quicksilver> on the lazy IO model
08:16:27 <fasta> quicksilver: but now I close them once manually (hClose) and once via the laziness?
08:16:46 <sjanssen> fasta: the pipe between wc and your program is filling up
08:17:04 <sjanssen> and it becomes blocked indefinitely when you waitForProcess
08:17:58 <sjanssen> wait, that isn't it
08:18:11 * quicksilver > waitForProcess sjanssen
08:18:21 <fasta> brb, but I am every interested in a complete answer.
08:18:44 <sjanssen> quicksilver: waitForProcess won't perform the lazy IO.  It's moot anyway, I was confused
08:21:04 <quicksilver> fasta: I *think* you only read up as far as the number of lines
08:21:08 <quicksilver> fasta: which is not quite the end of the file
08:21:13 <quicksilver> and thus it doesn't get lazy-closed
08:21:18 <quicksilver> hmm
08:21:30 <quicksilver> files which are actually pipes are never lazy-closed, perhaps?
08:21:41 <quicksilver> they just stop producing data
08:21:44 <quicksilver> I don't know!
08:21:47 <quicksilver> hClose it to be sure.
08:22:01 <sjanssen> ah, that's probably it
08:22:10 <quicksilver> which of my ramblings is probably it?
08:22:23 <quicksilver> I'm just throwing shit out at random, as far as I can see.
08:22:34 <sjanssen> fasta isn't reading the entire output of wc
08:22:47 <sjanssen> fasta: btw, this runs fine on my system
08:22:58 <quicksilver> so he should explicitly hClose
08:23:32 <Philippa> fasta: you're not demanding the input
08:23:49 <Philippa> no prize for working out what that means on a lazy string
08:24:15 <quicksilver> I maintain that this is a minefield and this lazy stuff really shouldn't be the default
08:26:11 <dino-> hi dons
08:28:12 <malcolmw> dons: the time of day suggests you are now in Oregon
08:29:54 <dons> that's right :)
08:29:54 <lambdabot> dons: You have 3 new messages. '/msg lambdabot @messages' to read them.
08:30:50 <malcolmw> dons: how long is it since you moved continents?
08:31:15 <dons> just over 2 weeks now
08:31:42 <malcolmw> ah, I'm behind on the news
08:32:24 * wli is all of 2 blocks from OGI but has never been there.
08:36:19 <fasta> Philippa: I _am_ demanding the output, maybe not all of it.
08:36:40 <phobes> Stream fusion, like proper tail recursion, turns incorrect (pragmatically) algorithms into correct algorithms ... it seems that programmers should get some guarantees about when this will happen.  Is this reasonable or is this hard?
08:36:44 <fasta> sjanssen: just run it on a directory with more than 1000 files.
08:37:12 <fasta> sjanssen: anyway, it doesn't work _here_, which is of course what I care about.
08:37:42 <fasta> sjanssen: well, actually, it does work here now, but "it" was the previous version I pasted.
08:38:36 <ndm> phobes: i don't think stream fusion changes the difference between possible and impossible by that much, if you ignore the _|_ issue
08:38:46 <fasta> Philippa: if it all is so obvious to you, maybe you could write a real answer instead?
08:39:03 <phobes> ndm:  Doesn't it eliminate stack overflow in a large number of cases?
08:39:04 <ndm> tail recursion does, full laziness does, CAF'ing does - but stream fusion is mainly a constant factor thing
08:39:14 <phobes> hmm
08:39:17 <ndm> phobes: i don't think so
08:39:28 <ndm> although i could be wrong
08:40:55 <Philippa> fasta: if you don't demand all the input, the handle never gets closed
08:41:05 <Philippa> it certainly never gets flushed beyond the last point you demand
08:41:49 <quicksilver> it should be OK to close the handle and then waitForProcess
08:41:55 <quicksilver> although you might need to ignore SIGCHLD
08:42:14 <fasta> I currently do waitForProcess and then hClose
08:42:21 <fasta> This appears to work
08:42:41 <sjw> dons: re
08:49:59 <quicksilver> is anyone aware of any cross-platform font libraries for haskell? hackage doesn't seem
08:50:10 <quicksilver> a freetype binding would be the most obvious, but perhaps not the only
08:50:25 <quicksilver> a binding ot the local OS font infrastructure might work too
08:50:42 <phobes> Is there a builtin that returns a list of partial foldl results?
08:50:49 <quicksilver> phobes: scanl
08:50:52 <phobes> thanks
08:50:52 <earthy> scanl
08:50:58 <quicksilver> earthy: i win!
08:51:05 <earthy> but, euhm, that's not really a list of partial results...
08:51:16 <quicksilver> depends what he meant. it might be :)
08:51:25 <quicksilver> > scanl (+) 0 [1..]
08:51:27 <lambdabot>  [0,1,3,6,10,15,21,28,36,45,55,66,78,91,105,120,136,153,171,190,210,231,253,2...
08:51:27 <earthy> it is a list of results of applying the foldl to prefixes of the list
08:53:23 <Saizan> and what would you call "list of partial foldl results" instea?
08:55:31 <dons> hey sjw
08:58:53 <dons> ?users
08:58:53 <lambdabot> Maximum users seen in #haskell: 407, currently: 364 (89.4%), active: 13 (3.6%)
09:00:07 <quicksilver> dons: people were asking about HWN. Are you likely to find time to continue the project? If not, perhaps you should solicit for a volunteer on the cafe...
09:00:09 <earthy> saizan: it could be a list of results of applying the foldl to *suffixes* of the list...
09:00:36 <quicksilver> earthy: but that makes less sense with the 'shape' of foldl
09:00:51 <earthy> umm... not rilly
09:00:54 <quicksilver> earthy: I'd expect to want to evaluate 'subexpressions' of the full foldl expression
09:01:03 <quicksilver> and that's what scanl does, if I'm not mistaken
09:01:25 <Saizan> earthy: the list returned from scanl are snapshots of the accumulator of the corresponding foldl
09:01:31 <dons> quicksilver: right. i've an issue mostly prepared, i'll just need to set aside time now to continue it. should be possible
09:01:40 <dons> if not, i'll ask for help
09:01:56 <wli> dons: An issue of what?
09:02:05 <dons> hwn
09:02:13 <sjanssen> s/w/?
09:02:14 <lambdabot> sjanssen: You have 1 new message. '/msg lambdabot @messages' to read it.
09:02:14 * dons off to work!
09:02:14 <sjanssen> :)
09:02:26 <wli> Okay.
09:02:27 <dons> :P
09:02:35 <mcnster> @where fgl
09:02:36 <lambdabot> http://www.cs.orst.edu/~erwig/fgl/
09:12:34 <quicksilver> donexcellent :)
09:12:38 <quicksilver> dons: excellent :)
09:50:32 * ddarius has the same problem as Eugenia Cheng only using F and U rather that F and G.
09:51:16 <ricky_clarkson> psykotic: Solved the numbers-as-text yet?
09:51:55 <psykotic> ricky_clarkson, i misread a part of the problem description and didn't bother spending more time on it after that.
09:52:21 <ricky_clarkson> So I see upon refresh.
09:52:52 <psykotic> my misconstrued version is almost more fun, though :)
09:53:33 <ricky_clarkson> I got a student to solve one of their puzzles, the long palindrome one.
10:15:03 <JohnnyL> anyone here actually using haskell for web stuff?
10:15:19 <JohnnyL> or just palindromes and recursive list processing?
10:15:56 <wli> Yes.
10:16:07 <kscaldef> JohnnyL: you mean web serving?
10:16:14 <mux> @where happs
10:16:15 <lambdabot> http://happs.org
10:16:44 <kscaldef> I'm writing a web spider at the moment
10:16:46 <wli> CGI apps are also easy to write by hand without even calling into libraries (which is what I do).
10:17:10 <sjanssen> apparently we can partition all programs into 'web stuff' and 'recursive list processing'
10:17:25 <iguana_> I one saw a paper that mentioned a web server in 1500 lines
10:17:29 <kscaldef> what else is there?
10:17:32 <JohnnyL> ok mux
10:17:35 <iguana_> is that code available anywhere?
10:17:41 <wli> I just bang out CGI apps by hand.
10:17:50 <puusorsa> in binary
10:18:00 <JohnnyL> isn't opening a socket and printing to it ..like two lines?
10:18:12 <JohnnyL> wli, what language.
10:18:16 <pejo> iguana, if it's the stuff by Marlow I think there's an updated darcs repository available from Bjˆrn Bringert's homepage.
10:18:21 <sjanssen> JohnnyL: yeah, something like that
10:18:22 <ndm> i do CGI apps by hand in Haskell
10:18:25 <JohnnyL> wli, ltns. are you still into chess theories?
10:18:26 <wli> JohnnyL: Haskell.
10:18:27 <iguana_> @where bringert
10:18:28 <lambdabot> I know nothing about bringert.
10:18:34 <exDM69> iguana_: a 1500 line web server is no problem if you use a good language
10:18:36 <JohnnyL> cool
10:18:42 <JohnnyL> i'd like to do that.
10:18:49 <wli> JohnnyL: Chess theories I've never been very expert on or into.
10:18:57 <pejo> @go Bjˆrn Bringert webserver site:chalmers.se
10:18:58 <JohnnyL> For some reason haskell is hard for me.
10:18:59 <lambdabot> http://www.cs.chalmers.se/~bringert/projects.html
10:18:59 <lambdabot> Title: Bj&ouml;rn Bringert - Projects & Publications
10:19:05 <JohnnyL> wli, oh, ok musta been someone else.
10:19:46 <wli> JohnnyL: It's probably me actually. I just wouldn't say that I'm any sortof chess expert or theorist.
10:19:51 <iguana_> yeah, there it is
10:20:00 <JohnnyL> h
10:20:01 <JohnnyL> oh
10:20:38 <JohnnyL> gotta go
10:20:40 <JohnnyL> take car
10:20:42 <iguana_> that's the great thing about small communities: everyone knows everything :D
10:20:45 <JohnnyL> tak care
10:21:49 <dons> though we're not that small, we're medium, but well connected, i'd say
10:22:02 <psykotic> dons: hey. acclimated to portland yet?
10:22:06 <iguana_> and growing, I gather
10:22:20 <dons> psykotic: its getting cold, but  yep, getting into the swing of things
10:22:32 <pejo> dons, heh, how cold is 'cold'?
10:22:47 <puusorsa> 0K ?
10:23:12 <kscaldef> portland isn't cold currently
10:23:18 <wootles> if i implement a function recursively using an 'accumulator' argument, is there a way i can set the 'default' value for that argument? the accumulator argument is more of an implementation detail of the function, and its always going to start at zero, then i'd like to hide it from the 'interface' if you see what i mean
10:23:46 <kscaldef> actually, portland never gets really cold
10:23:50 <psykotic> wootles, people typically just do foo x = foo' x default where foo' x y = ...
10:23:55 <iguana_> wootles: you can use a function in the function
10:24:07 <psykotic> err, actually more like foo = foo' default where foo' accum x = ...
10:26:01 <wootles> thanks
10:27:08 <iguana_> actually it is quite interesting that haskell allows ' in names...
10:27:34 <dons> > let this'is'pretty'coo'isn't'it = 1 in 2
10:27:36 <lambdabot>  2
10:27:57 <ndm> dons: no'this'is'a'really'bad'idea
10:28:06 <dons> no'this'is'good'malcolm'does'it!
10:28:13 <mux> hahaha
10:28:14 <iguana_> must be because of the strong mathematical background...
10:28:17 <sjanssen> ndm: what'is'wrong'with'it
10:28:28 <ndm> foo' is fine
10:28:36 <ndm> can't is not a good identifier!
10:28:43 <kscaldef> it's good for unit testing libraries.  You can have both is and isn't
10:28:49 <ndm> yes, and i know malcolm does it, and it annoys me when he does it
10:29:00 <iguana_> malcolm?
10:29:16 <ndm> it was going through hscolour that i saw it, and didn't think anyone would have thought to do that
10:29:19 <ndm> malcolm wallace
10:29:29 <ndm> of hat, cpphs, hscolour, nhc ...
10:29:41 <wootles> let's say I am writing a function for binary exponentiation
10:30:29 <sjanssen> I am writing a function for binary exponentiation
10:30:34 <wootles> and I have this case : | y == 0 mod 2 = f (bexp x (quot 2)) (bexp x (quot 2))
10:31:09 <wootles> f is any associative operator
10:31:14 <sjanssen> wootles: you've got to write "y `mod` 2 == 0"
10:31:29 <wootles> my bad, was typin it off the top of my head
10:31:52 <wootles> my question is, will haskell evaluate (bexp x (y quot 2)) twice ?
10:32:06 <iguana_> nobody knows :)
10:32:09 <sjanssen> wootles: it may or may not
10:32:18 <sjanssen> in practice, GHC will evaluate that twice
10:32:46 <wootles> so i should explicitly say let r = (bexp x (quot y 2)) in (f r r) ?
10:32:58 <sjanssen> yes
10:34:00 <twanvl> > let ord'a' = 97 in chr ord'a'
10:34:02 <lambdabot>  'a'
10:34:10 * twanvl ducks
10:35:35 <olsner> > let ord[] = 97 in chr ord[]
10:35:35 <lambdabot>  Couldn't match expected type `Int'
10:35:38 <wootles> in a similar vein, if i define fac n | n > 0 = n*fac(n-1) | otherwise = 0
10:36:41 <wootles> and then calculate fac 100 , then fac 101 ... will haskell 'remember' the value of fac 100 when evaluating fac 101 ?
10:36:55 <sjanssen> wootles: in practice, no
10:37:15 <exDM69> wootles: that's called memoization
10:37:34 <exDM69> but I guess good haskell compilers can optimize a lot
10:37:53 <wootles> mm
10:38:00 <sjanssen> none of the existing compilers do that
10:38:14 <sjanssen> of course Haskell's semantics allow it
10:38:42 <exDM69> sjanssen: but they do optimize the recursion a lot
10:38:51 <mux> I thought GHC memoized top-level functions
10:38:51 <mux> ?
10:38:51 <exDM69> sjanssen: by other means, not necessarily recursion
10:39:04 <exDM69> sjanssen: s/recursion/memoization/
10:39:08 <sjanssen> mux: top level CAFs
10:39:53 <mux> sjanssen: constant applicative forms?
10:39:56 <sjanssen> yes
10:41:56 <sjanssen> things like constant lists and other data types
10:41:56 <wootles> what if i define an infinite list of the factorials, recursively... so if i ask for fac 100, it will eval the first 100 items in the list. now if I were to then ask for fac 99, would it have thrown away the list by that time, or is the already evaluated portion of my list stored ?
10:41:56 <sjanssen> for example: facs = scanl (*) 1 [1..] -- will be shared
10:42:13 <sjanssen> wootles: if it is bound at the top-level of a module it will be kept
10:49:11 <phobes> > scanl (+) 0 (scanl (+) 0 [1..])
10:49:19 <phobes> > scanl (+) 0 (scanl (+) 0 [1..100])
10:49:21 <lambdabot>  [0,0,1,4,10,20,35,56,84,120,165,220,286,364,455,560,680,816,969,1140,1330,15...
10:49:22 <lambdabot>  [0,0,1,4,10,20,35,56,84,120,165,220,286,364,455,560,680,816,969,1140,1330,15...
10:49:30 <phobes> hmm
10:51:06 <xerox> http://golem.ph.utexas.edu/category/2007/09/the_catsters_on_youtube.html#c012072 haha this is funny.
10:51:08 <lambdabot> Title: The Catsters on YouTube | The n-Category Caf&#xE9;, http://tinyurl.com/2an7kx
10:51:40 <byorgey> tetrahedral numbers! =)
10:52:09 <balodja> How to quickly define types in @djinn?
10:52:25 <xerox> djinn-add (no recursive types supported)
10:52:43 <phobes> byorgey: heh :)
10:52:50 <mrd> @djinn (a->a)->a
10:52:51 <lambdabot> -- f cannot be realized.
10:53:16 <balodja> @djinn (a -> b -> c) -> (a -> b) -> (a -> c)
10:53:19 <phobes> Isn't this an example of code that will be sped up by super-constant amount through stream fusion?
10:53:34 <balodja> Where is my s-combinator? :)
10:53:51 <lambdabot> f a b c = a c (b c)
10:54:01 <balodja> Oh, here it is.
10:54:50 <dons> dcoutts: is it talk like a pirate day!! ?
10:54:50 <shapr> arr
10:54:50 * balodja has just view http://video.google.com/videoplay?docid=-4851250372422374791
10:54:50 <lambdabot> Title: Advanced Topics in Programming Languages Series: Parametric Polymorphism
10:54:50 <dons> ?yarr!
10:54:50 <lambdabot> Drink up, me 'earties
10:54:50 <shapr> @arr
10:54:50 <lambdabot> Yeh scurvy dog...
10:54:51 <dons> its our channel's national day!!
10:54:53 <shapr> @arr
10:54:53 <lambdabot> Yeh scurvy dog...
10:54:57 <shapr> @arr
10:54:57 <lambdabot> Aye Aye Cap'n
10:55:00 <shapr> @arr
10:55:00 <lambdabot> Aye Aye Cap'n
10:55:02 <shapr> dang it
10:55:10 <dons> Cap'n Shapr at the helm. Avast!
10:55:54 <phobes> > scanl (+) 0 (scanl (+) 0 [1..])
10:55:56 <lambdabot>  [0,0,1,4,10,20,35,56,84,120,165,220,286,364,455,560,680,816,969,1140,1330,15...
10:56:04 <shapr> @YARR!
10:56:05 <lambdabot> Unknown command, try @list
10:56:08 <shapr> @arr
10:56:09 <lambdabot> Aye
10:56:29 <balodja> Arr-flood :)
10:56:33 <shapr> I'm definitely in the mood to do all that pirate stuff, what is it, grapes and pillage?
10:56:48 <shapr> Wine, women, and enthusiastic but unskilled song.
10:57:11 <phobes> Rum, I thought
10:57:20 <dylan> Avast yee sea-drinking bilge rats!
10:57:22 <shapr> I bet that's where rumination came from.
10:57:36 <shapr> I'd like to walk her plank!
10:58:01 <dylan> shapr: you still going on about the catsters woman? :)
10:58:12 <shapr> dylan: I was talking to one of my friends about her last night :-)
10:58:32 <dylan> LOL.
10:58:37 <shapr> Friend of mine teaches IT at a community college, I was like, "check out the fine monad teaching woman on youtube!"
10:59:04 <phobes> Does anyone else pronounce it "moh-nad"?
10:59:30 <shapr> I always says, "I gots mo' nads than you!"
10:59:42 <dylan> well, when I do say it with sound it is "mon-ad"
11:00:01 <dylan> "mon" like a jamaican "man"
11:00:05 <EvilTerran> moe-nad
11:00:07 <phobes> dylan:  how do you say it without sound?
11:00:17 <dylan> phobes: I don't always associate words with sounds.
11:00:39 <phobes> dylan:  I don't either, but I associate saying with sound :P
11:01:05 <dylan> phobes: "talking" and "saying" have no relation to sound, otherwise half the time I'd never say anything
11:01:30 <dylan> mostly for convenience...
11:01:35 <phobes> I'm confused :)
11:01:45 <dylan> "I said 'such and such' to him"
11:01:46 <dylan> vs.
11:01:53 <dylan> "I typed 'such and such' to him"
11:02:16 <phobes> Ah, it is your contention that we are both saying things right now?
11:02:30 <olsner> of course you are, I can see you talking!
11:02:30 <dylan> yes.
11:03:07 <dylan> and if my step son signs "thank you", he would have "said" thank you.
11:03:14 <phobes> And so you reserve the special "say with words" for when you open your mouth and vocalize :)
11:03:31 <dylan> phobes: well, "say with sound"
11:03:35 <phobes> ah yes
11:03:37 <dylan> I also use the phrase "talk in text"
11:03:42 <phobes> "Excuse me speaker, could you say that with sound again?"
11:04:15 <dylan> phobes: "please repeat that sound". <g>
11:04:21 <phobes> or perhaps 'say' has a different connotation when in person :)
11:04:25 <wootles> I have :  let tri n | n > 0 = tri(n-1)+1 | otherwise = 1     ... how do i make haskell to do the addition at each step rather than building a towering stack of doom ?
11:05:10 <dylan> yeah. Well, my better half often requests that I "talk with text" so she can catch up on her web comics and such.
11:05:15 * Lycurgus chuckles at hassel the towering stack of doom
11:06:04 <dylan> it takes a lot more effort to process sounds into language. :)
11:06:09 <beelsebob> @arr
11:06:09 <lambdabot> I'll keel haul ya fer that!
11:06:26 <phobes> @define: say
11:06:26 <lambdabot> Unknown command, try @list
11:06:27 <beelsebob> excellent, lambdabot be enjoying the tidings of the day
11:06:34 <twanvl> let tri = tri' 1 ; tri' acc n | n > 0 = tri' (acc+1) (n-1) | otherwise = acc  -- option 1: use an accumulating parameter
11:06:47 <Lycurgus> but ya gotta love it cause them towers is hella elegant
11:07:31 <twanvl> let tri n = sum (map (\i -> 1) [1..n]) -- option 2: use built in list functions (which use accumulating parameters)
11:08:21 <olsner> hmm... but isn't that function just n + 1?
11:08:21 <wli> tri n | n > 0 = tri (n-1) + n | otherwise = 1 ?
11:08:21 <twanvl> let tri n = n -- option 3: think before you code
11:08:21 <twanvl> I mean n+1
11:08:21 <twanvl> No, actually, it is n
11:08:51 <olsner> @quickcheck (\n -> let tri n | n > 0 = tri(n-1)+1 | otherwise = 1 in tri n == (n + 1))
11:08:51 <lambdabot> Unknown command, try @list
11:09:30 <twanvl> ?check (\n -> let tri n | n > 0 = tri(n-1)+1 | otherwise = 1 in tri n == (n + 1))
11:09:30 <lambdabot>  Add a type signature
11:09:30 <twanvl> ?check (\n -> let tri n | n > 0 = tri(n-1)+1 | otherwise = 1 in tri n == (n + 1)) :: Int -> Int
11:09:30 <lambdabot>  Couldn't match expected type `Int' against inferred type `Bool'
11:09:30 <twanvl> ?check (\n -> let tri n | n > 0 = tri(n-1)+1 | otherwise = 1 in tri n == (n + 1)) :: Int -> Bool
11:09:30 <lambdabot>  Falsifiable, after 1 tests: -1
11:09:41 <twanvl> ?check (\n -> n >= 0 ==> let tri n | n > 0 = tri(n-1)+1 | otherwise = 1 in tri n == (n + 1)) :: Int -> Bool
11:09:42 <lambdabot>  Couldn't match expected type `Bool'
11:09:51 <twanvl> ?check (\n -> n >= 0 ==> let tri n | n > 0 = tri(n-1)+1 | otherwise = 1 in tri n == (n + 1)) :: Int -> Property
11:09:52 <lambdabot>  OK, passed 500 tests.
11:13:31 <shapr> I really like pandoc.
11:14:15 <hpaste>  wootles pasted "tail recursive?" at http://hpaste.org/2818
11:14:34 <wootles> i went for option 1
11:15:01 <wootles> but i probably did something wrong :(
11:16:40 <byorgey> wootles: what's the problem?  Does it give wrong answers, take a long time, blow the stack...?
11:16:52 <wootles> for sufficiently large n, ffacs n overflows
11:17:05 <byorgey> wootles: did you compile with -O2?
11:17:14 <wootles> same thing happens if i replace my `specmult` with + fwiw
11:17:31 <twanvl> If you don't compile with optimizations (and depending on what specmult does) you may still get pretty much the same problem. You need to make the function strict in the accumulator, ghc -O should do that automatically.
11:18:28 <wootles> i have {-# OPTIONS_GHC -O  ... } in my .hs file , that should work if i :l mysouce.hs in GHCi then test it interactively ?
11:18:49 <byorgey> wootles: hmm, is this for Project Euler #160?
11:18:55 <wootles> yeah
11:18:57 <byorgey> =)
11:19:15 <wootles> haskell is awesome, i have a solution in 10 lines :D but i want it shorter
11:19:33 <kReepicheep_> haskell golf?
11:19:49 <olsner> you need the fluxbox monad ;-)
11:20:17 <wootles> i dont want to make it obfu, but right now i think some of my code could be more elegant
11:22:00 <mikefoo> Quick Q:  So I took a development contract signed but "verbal agreed" it would take two weeks, turned into 8 weeks, and I dont have time to complete now.  So I can't finish project.  They are claiming I ruined their clients relationship. Any advice.. psudeo advice, I know no one is a lawyer.  - I wasn't paid anything btw
11:23:37 <wootles> anyone have any ideas on that tail recursion thing ? im desperate, im starting to hanker for a 'for' loop :o
11:24:04 <twanvl> You could try "ffacs' n !acc k"
11:24:19 <byorgey> wootles: when you say it blows up for "sufficiently large" n, how big are you talking about?
11:24:43 <wootles> replacing `specmult` with just +, it blows up for n >5e5
11:25:03 <wootles> twanvl: what does that do ?
11:25:15 <byorgey> wootles: twanvl's suggestion is also good, the ! in front of acc means that acc is a strict parameter
11:25:36 <bos> wootles: your code is not strict enough
11:25:43 <dino-> Eh, I fucked up my windowing and have to quit irssi. I don't remember how to do the confusing windowing shit.
11:25:53 <byorgey> wootles: and when you say "blows up", what exactly happens? does it say something about stack size exceeded?
11:25:53 <bos> both acc and k are likely to explode on you
11:25:58 <dino-> heh, wrong window
11:26:22 <wootles> byorgey: i get a stack overflow
11:26:49 <bos> wootles: the problem is that you build huge unevaluated expressions with both acc and k
11:27:18 <bos> so when their values are finally needed, the stack (which is deliberately set to a small, fixed size) explodes on you
11:27:57 <bos> the problem has nothing to do with tail recursion
11:29:53 <bos> use {-# LANGUAGE BangPatterns #-} and stick a ! in front of both acc and k
11:29:57 <wli> You're supposed to derive a faster formula than what you're using.
11:30:26 <wootles> wli: for PE 160 ?
11:30:50 <wli> wootles: Yeah. scanl1 (*) [1..] isn't going to cut it.
11:31:05 <wootles> wli: I only ever call ffacs n with n < 1e5
11:31:32 <wli> wootles: That's not going to help.
11:31:43 <wootles> wli: my algorithm calculates F(n) in O(log n) time, and i get the right answer
11:32:22 <wli> wootles: Hmm. Okay, maybe there's something I missed in your algorithm.
11:32:52 <wootles> wli: that ffacs function is part of my solution
11:33:48 <wootles> wli: i have a recursive function which reduces the problem of finding F(n) to several of finding F(x) where x has no factors of 5
11:35:52 <ricky_clarkson> I know it's stupid, but how can I get QC to accept this?
11:35:59 <ricky_clarkson> @check \x -> 4+4==8
11:36:00 <lambdabot>  Add a type signature
11:37:13 <Olathe> @check \x -> 4 + 4 = 8 :: Int
11:37:14 <lambdabot>  Parse error
11:37:21 <Olathe> @check \x -> 4 + 4 = (8 :: Int)
11:37:21 <lambdabot>  Parse error
11:37:49 <Olathe> @check (4::Int) + 4 == 8
11:37:50 <lambdabot>  OK, passed 500 tests.
11:38:09 <wootles> bos: thanks, the ! worked a treat
11:38:39 <ricky_clarkson> I wonder what tests it can possibly generate 500 of for that.
11:38:56 <Olathe> I was wondering the same thing :)
11:40:55 <mornfall> @check  () == ()
11:40:57 <lambdabot>  OK, passed 500 tests.
11:40:59 <mornfall> :-)
11:41:06 <mornfall> @check True
11:41:07 <lambdabot>  OK, passed 500 tests.
11:41:08 <Olathe> @check False
11:41:09 <lambdabot>  Falsifiable, after 0 tests:
11:41:16 <Olathe> Zero ?
11:41:27 <mornfall> it's confused.
11:41:43 <omniscientIdiot> Olathe: number of previous tests tried.
11:42:24 <axm> maybe there is some optimisation before the first test?
11:42:33 <axm> ok.
11:44:53 <Olathe> @check f 1 = True; f _ = False; f something
11:44:54 <lambdabot>  Parse error
11:44:55 <ricky_clarkson> @check \x -> (x :: Int)+4-4==x
11:44:56 <lambdabot>  OK, passed 500 tests.
11:45:01 <Olathe> Oh.
11:45:15 <ricky_clarkson> Why doesn't that catch the overflow bug (or perhaps there is none actually, oops).
11:46:27 <Olathe> How do you reduce the number of tests ?
11:46:44 <dons> @scheck \x -> (x :: Int)+4-4==x
11:46:45 <lambdabot>   Completed 13 test(s) without failure.
11:46:53 <wootles> is there a standard library function for binary exponentiation ?
11:47:06 <dons> :t (^)
11:47:08 <lambdabot> forall a b. (Integral b, Num a) => a -> b -> a
11:47:08 <dons> :t (^^)
11:47:08 <omniscientIdiot> @check let m = minBound :: Int in m - 2 + 2 == m
11:47:08 <arcatan> what's scheck?
11:47:10 <lambdabot>  OK, passed 500 tests.
11:47:12 <dons> :t (**)
11:47:12 <lambdabot> forall a b. (Integral b, Fractional a) => a -> b -> a
11:47:14 <lambdabot> forall a. (Floating a) => a -> a -> a
11:47:24 <nominolo> to have a threaded program, do i need anything more than: ghc -threaded -O2 --make bla  ?
11:47:27 <arcatan> > minBound :: Int
11:47:29 <dons> arcatan: that's SmallCheck, the bread-first test generator
11:47:30 <lambdabot>  -2147483648
11:47:32 <ricky_clarkson> Why can it generate duplicate tests?
11:47:33 <dons> nominolo: nope.
11:47:39 <arcatan> oh
11:47:43 <nominolo> dons, doesn't work ;)
11:47:48 <dons> hmm?
11:48:00 <nominolo> er, no ";)"
11:48:00 <dons> you're linking agains the threaded runtime
11:48:07 <dons> did you want to also use multiple cores?
11:48:12 <dons> if so, you need +RTS -N16
11:48:16 <nominolo> i run it with +RTS -N2 -RTS
11:48:18 <dons> or something like that, as a runtime flag
11:48:31 <dons> yes, compile with -threaded, run with +RTS -N2 -RTS
11:48:37 <Olathe> scheck just says Done
11:48:44 <nominolo> hm, maybe it's hyperthreading..
11:48:46 <dons> and use threads in the program too..
11:49:01 <dons> oh, if its just a hyperthreaded pentium, that's not a real core
11:49:45 <nominolo> dons, no it's a core due
11:49:49 <nominolo> *duo
11:50:07 <wootles> dons: i think i should have said 'exponentiation by squaring'
11:52:01 <nominolo> hm
11:52:35 <dons> you running a multithreaded kernel?
11:53:15 <nominolo> pretty sure
11:55:57 <nominolo> kernel is (ubuntu) 2.6.20-16-generic #2 SMP
11:56:51 <sioraiocht> LOL @ topic
11:57:00 <byorgey> wootles: I'm pretty sure ^ uses exponentiation by squaring
11:57:05 <byorgey> @src (^)
11:57:05 <lambdabot> Source not found. I feel much better now.
11:57:30 <nominolo> byorgey, ^ uses libgmp
11:57:42 <byorgey> oh, right =)
11:57:49 <wootles> byorgey: i am using a different multiplication operator to (*)
11:57:50 <sioraiocht> byorgey: libgmp uses FFT's for multiplication, probably for exponentiation too
11:58:19 <byorgey> wootles: right.  well, then, you'll have to implement the exponentiation yourself.  shouldn't be too hard.
11:58:40 <sioraiocht> @src (**)
11:58:41 <lambdabot> Source not found. Listen, broccoli brains, I don't have time to listen to this trash.
11:58:47 <sioraiocht> ** doesn't use libgmp, though, right?
11:59:56 <wootles> is there a list of operators somewhere? characters like +, *, /  seem to defeat most search engines
12:00:49 <omniscientIdiot> you might hoogle Num a => a -> a -> a
12:01:47 <ricky_clarkson> Does QuickCheck do source parsing or does it use reflection of some kind to find out the types it should supply functions with?
12:02:20 <dylan> well, neither.
12:02:31 <DRMacIver> It's just a consequence of how type classes work isn't it?
12:02:56 <omniscientIdiot> ricky_clarkson: the parameter types must belong to the Arbitrary class, which quickCheck uses to generate data.
12:02:59 <DRMacIver> You provide instances of Arbitrary, and quickcheck works on the methods defined by that.
12:03:25 <omniscientIdiot> @instances-importing Test.QuickCheck Arbitrary
12:03:26 <lambdabot> (), (a -> b), (a, b), Bool, Double, Float, Int, Integer, [a]
12:03:33 <omniscientIdiot> @src Arbitrary
12:03:34 <lambdabot> Source not found. Take a stress pill and think things over.
12:03:42 <omniscientIdiot> @src Test.QuickCheck.Arbitrary
12:03:42 <lambdabot> Source not found. My mind is going. I can feel it.
12:04:12 <nominolo> dons, a simple example using pthreads works
12:05:25 <ricky_clarkson> Hmm, I think I get that.
12:06:11 <DRMacIver> Presumably one or more of the usual metaprogramming suspects will derive Arbitrary instances for you?
12:07:13 <omniscientIdiot> Arbitrary has arbitrary :: Gen a and coarbitrary :: a -> Gen b -> Gen b, Test.QuickCheck has a bunch of functions to make Gens.
12:08:19 <DRMacIver> Hm. What is coarbitrary for?
12:09:01 <DRMacIver> Never mind. I'll look it up.
12:09:03 <omniscientIdiot> not sure, I think it has to do with basing values on other already created ones.
12:09:20 <wootles> is there a convenient way to time execution in ghci ?
12:09:49 <omniscientIdiot> http://www.math.chalmers.se/~rjmh/QuickCheck/
12:09:50 <lambdabot> Title: QuickCheck: An Automatic Testing Tool for Haskell
12:10:11 <Olathe> wootles: :? says +s
12:10:30 <Olathe> :s +s
12:10:53 <Olathe> 3 takes longer than 3 + 4 :)
12:11:14 <wootles> thanks :)
12:11:27 <Olathe> You're welcome.
12:14:08 <travisbrady> does anyone know of an easy example/tutorial/etc of using Haskell to generate xml?
12:19:27 <tuxplorer> Prelude Database.HSQL.MySQL> do dbconn<-connect "localhost" "Dbname" "dbuser" "dbpass"; closeStatement(query dbconn "select * from questions)
12:19:28 <tuxplorer> <interactive>:1:107: lexical error in string/character literal at end of input
12:19:28 <tuxplorer> Why is that error?
12:19:50 <RyanT5000> has anyone built an efficient suffix trie (or tree) in haskell?
12:20:17 <EvilTerran> tuxplorer, you're missing a closing quote
12:20:38 <EvilTerran> > "
12:20:38 <lambdabot>  Improperly terminated string
12:20:56 <omniscientIdiot> tuxplorer: in the ghc toplevel, do is implied.  Try omitting it.
12:21:23 <EvilTerran> omniscientIdiot, that only works for one command at a time
12:21:26 <omniscientIdiot> oh wait, nvm
12:21:34 <omniscientIdiot> you have a non-terminated string
12:21:35 <EvilTerran> Prelude> return 1; return 2
12:21:35 <EvilTerran> <interactive>:1:8: parse error on input `;'
12:21:48 <EvilTerran> anyway, do{}s nest without difficulty
12:22:00 <omniscientIdiot> EvilTerran: yeah, silly mistake
12:22:15 <EvilTerran> > do do do do do [1]
12:22:16 <lambdabot>  [1]
12:22:17 <sjanssen> > do do do do do do do do putStrLn "do"
12:22:19 <lambdabot>  <IO ()>
12:22:31 <omniscientIdiot> tuxplorer: put a " before the last )
12:23:02 <axm> in the hs-plugins manual, is the polymorphic eval example still up to date? AltData.Typeable does not seem to exist anymore in plugins-1.0 anymore, just changing it to Data is no obvious improvement to me, am I missing sth?
12:27:01 <tomppa> I have recently been googling around for information about implementing games/simulations in pure functional languages but I haven't found much anything. Anybody know any good papers on the subject?
12:27:14 <EvilTerran> @wiki Frag
12:27:15 <lambdabot> http://www.haskell.org/haskellwiki/Frag
12:28:17 <omniscientIdiot> haskell.org links to an "Applications and Libraries" page, which lists a "Games" page
12:28:23 <tomppa> ISTR that Frag uses Yampa. Most solutions seem to point towards FRP. Are there any other reasonable approaches?
12:28:51 <tomppa> Not that there is anything wrong with FRP...
12:29:03 <omniscientIdiot> </jerry-seinfeld>
12:29:31 <EvilTerran> @where frp
12:29:31 <lambdabot> I know nothing about frp.
12:29:55 <psnively> I don't know if it's entirely responsive, but: Google "
12:30:07 <psnively> Er, "Tim Sweeney Next Mainstream Programming Languages"
12:30:24 <tomppa> Yes, I have read that.
12:30:27 <psnively> Tim Sweeney == Head Honcho, Epic Games
12:30:30 <psnively> Ah, good.
12:30:55 <tomppa> My problems are mostly to do with handling the game state
12:31:07 <psnively> So are Tim's. :-)
12:31:10 <tomppa> lack of object identity and things like that
12:31:32 <psnively> Lack of object identity?
12:32:18 <tomppa> say, I have a simple simulation of physical bodies
12:32:18 <sjanssen> tomppa: you can simulate identity by allocating unique Int ids for objects
12:32:56 <tomppa> yep, but it doesn't just feel right.
12:33:31 <sjanssen> tomppa: is your program pure, or do you use references in IO or ST?
12:33:36 <tomppa> these physical objects in the simulation would have relations like "follow that object" or "stay away from that object" etc
12:33:37 <EvilTerran> newtype away the id into an abstract type, perhaps
12:33:51 <sjanssen> IORefs and STRefs do have identity
12:34:05 <EvilTerran> i believe that's related to how IORefs et al work
12:34:12 <tomppa> How would I handle updating the game state
12:34:23 <EvilTerran> modifyIORef?
12:34:44 <tomppa> so I would basically simulate traditional imperative structures with IORefs?
12:34:53 <sjanssen> perhaps
12:35:10 <sjanssen> you might check out frag, perhaps it solves some of these problems?
12:35:14 <EvilTerran> that, or use FRP, or build some other pleasing abstraction on top of IORefs etc
12:35:36 <psnively> I tend to think that Oleg's generic zipper would be useful for such tasks.
12:35:53 <tomppa> psnively: something like might work
12:35:57 <tomppa> *that
12:36:32 <sjanssen> ooh, SPJ seems receptive to type level numbers
12:36:37 <psnively> Basically, it seems to me that you need some kind of collection of concretizations of abstract data types, with maximal sharing.
12:36:44 <tomppa> ideally I'd like to have a pure datastructure that I could just map over to get the next state, with all relations intact
12:37:02 <psnively> Yes. I mean, a scene graph would be the PERFECT thing to build a zipper for, obviously.
12:37:08 <psnively> (I think about this a lot.)
12:37:38 <phobes> psnively:  You approached Sweeney about cooperating with them on the language implementation, right?
12:37:42 <phobes> What fell through?
12:37:46 <balodja> @type \g -> g (:) []
12:37:55 <lambdabot> forall a a1 t. ((a -> [a] -> [a]) -> [a1] -> t) -> t
12:37:59 <balodja> that type even doesn't exist!
12:38:26 <psnively> phobes: nothing fell through--there was never more than an agreement in principle that I could help beta test the compiler, write some sample code, docs, etc.
12:38:29 <balodja> could you construct a function, that (forall t) gives t as a result?
12:38:38 <sjanssen> balodja: hmm, looks like you're working with foldr/build fusion?
12:38:43 <phobes> psnively: ah ok
12:39:01 <psnively> I stopped bugging Tim about it periodically because this was shortly pre-GoW launch, and since then they have had UT3 and a lawsuit to deal with.
12:39:02 <pejo> psnively, is Sweeney writing a compiler?
12:39:05 <EvilTerran> balodja, by calling another function that returns that t
12:39:07 <tomppa> It is quite funny, before I tried Haskell it(functional simulations) seemed like quite an easy to task to accomplish. But now that I have actually tried it...
12:39:15 <EvilTerran> or taking that t as a parameter
12:39:17 <psnively> pejo: Of course. Again. He's written several before.
12:39:18 <phobes> heh ya, the lawsuit
12:39:21 <tomppa> there are all kinds of little differences all over
12:39:45 <EvilTerran> balodja, ::forall a b. a -> b can't be realised, 'cos you have no way of generating a b given only an a
12:39:48 <phobes> psnively:  If you count the unreal script compiler :)
12:39:52 <pejo> psnively, and that is for a language like he sketched on in the speech at POPL'06?
12:39:59 <psnively> Keep in mind that his new language is obviously for the Unreal 4 tech, sooooo... years away.
12:40:03 <balodja> sjanssen: yeah :) just read http://www.cs.chalmers.se/~josefs/publications/fusion.pdf
12:40:14 <wootles> if I have :  mylist = map (f) [1..1000]  , will this cause memorisation? ie if I evaluate mylist!!99, will any future evaluations of mylist!!99 be O(1) ?
12:40:25 <psnively> phobes: Which, obviously, I do... both shipped versions of it.
12:40:28 <sjanssen> wootles: yes
12:40:38 <balodja> EvilTerran: I've understand meaning of 'build', I'm talking about @type
12:40:39 <sjanssen> wootles: actually, they'll be O(n)
12:40:45 <EvilTerran> balodja, but ::forall a b. (a -> b) -> a -> b, say, can, because it can create a b given an a, and it has an a...
12:40:47 <sjanssen> wootles: because (!! n) is O(n)
12:40:48 <psnively> pejo: That's kind of the question. From e-mails and stuff he's said on LtU, I would have to guess "kind of."
12:40:49 <phobes> psnively: I know that's what you meant... I was snidely belittling unreal script :)
12:41:12 <balodja> it doesn't recognize 2order polymorphism
12:41:19 <balodja> (may be) :)
12:41:22 <psnively> phobes: Heh. I understand. But Tim himself has indicated that he knows more about PLT than he did when he wrote that, soooo.
12:41:27 <wootles> sjanssen: is there a way to get O(1) time ?
12:41:45 <psnively> And hey: UnrealScript has been VERY successful.
12:41:52 <phobes> psnively:  I've read most of his postings to LtU, and I can promise he knows much much more now :)
12:41:57 <sjanssen> wootles: you can use arrays if your domain is small enough
12:42:05 <wootles> 1e5 ?
12:42:08 <psnively> phobes: No kidding. A major reason for wanting to play with his work is to learn from it!
12:42:19 <phobes> I have alot of respect for Sweeney -- I think this language will probably be pretty good
12:42:23 <sjanssen> wootles: eg. mylist = listArray (1, 1000) $ map f [1..1000]
12:42:42 <psnively> tomppa: I think FRP + zippers will get you where you wanna go, personally.
12:43:01 <EvilTerran> balodja, ah, i see what you mean. indeed, lambabot runs with most extensions disabled
12:43:10 <phobes> I'm not sure you want FRP for a game loop...
12:43:24 <phobes> maybe you do ... I don't have much FRP experience
12:43:26 <sjanssen> balodja: @type knows rank-2, but it won't introduce rank-2 types by itself
12:43:40 <phobes> I'd think you'd want alot of control over the order in which reactions occur
12:43:42 <tomppa> psnively: I'll have to check the Frag sources
12:43:50 <psnively> phobes: I agree wholeheartedly. I think his presentation and his comments on LtU indicate that he's taking what a new language should do very seriously.
12:44:32 <EvilTerran> balodja, however, that's a perfectly valid type; you can't create a non-bottom function that fits the fully generalised type of its parameter ((a -> [a] -> [a]) -> [a1] -> t), but you can create a function that fits a less-polymorphic version of same
12:44:36 <sjanssen> @type (\g -> g (:) []) :: (forall b. (a -> b -> b) -> b -> b) -> [a]
12:44:38 <lambdabot> (forall b. (a -> b -> b) -> b -> b) -> [a] :: forall a. (forall b. (a -> b -> b) -> b -> b) -> [a]
12:44:42 <sjanssen> balodja: ^^^
12:44:51 <sjanssen> @type GHC.Exts.build
12:44:53 <lambdabot> forall a. (forall b. (a -> b -> b) -> b -> b) -> [a]
12:45:13 <psnively> tomppa: I think a bunch of what we run into is just that there isn't the depth of experience on alternatives to mutation and OO in game-like code that we'd like.
12:45:46 <tomppa> that is what I have been thinking too
12:46:24 <tomppa> it is interesting that besides FRP there doesn't seem to be any obvious solutions to the problem
12:46:36 <sjanssen> wootles: you can also handle an unbounded domain by using an infinite lazy trie
12:46:52 <Azmodan> Is there a way to match a value from a range? I'd like for instance that a definition of my function takes any x from 20 to 29 and the next one takes any x from 30 to 39 and do something with that x?
12:47:03 <phobes> Tomppa:  Would could just have an object ID manager in a Monad, right?
12:47:24 <sjanssen> > inRange (20, 29) 21
12:47:27 <lambdabot>  True
12:47:34 <sjanssen> Azmodan: ^^^
12:47:38 <tomppa> phobes: probably, maybe I'm just unnecessarily dismissing the simulating-imperative-in-functional approaches
12:47:46 <tomppa> being a haskell noob and all
12:47:54 <EvilTerran> f x | inRange (20,29) x = ... | inRange (30,39) x = ... | ...
12:48:02 <phobes> tomppa:  Well, you definitely don't want to try a verbatim translation of imperative approaches
12:48:07 <Azmodan> sjanssen: I can put that in the pattern matching part of my function?
12:48:30 <phobes> But modelling the world as a bunch of objects with IDs seems pretty reasonable
12:48:32 <psnively> I have to confess that I do always find the "it doesn't look like what I'd expect" argument against functional approaches to traditionally imperative problems... um... odd. :-)
12:48:42 <sjanssen> Azmodan: you'd do something like "f x | inRange (20, 29) x = ... | inRange (30, 39) x = ..."
12:49:02 <Azmodan> sjanssen: thanks
12:49:05 <phobes> tomppa: I think you want to try to minimize the number of things that have object IDs
12:49:07 <sjanssen> Azmodan: those things after "|" are called guards, the match succeeds when the Bool expression evaluates to True
12:49:12 <EvilTerran> http://hpaste.org/2654 ;]
12:49:31 * sjanssen prefers the Right Way :)
12:49:34 <Azmodan> sjanssen: Right, I forgot about guards, thanks.
12:50:45 <phobes> tomppa:  The thing is, with a functional approach, you're basically building the imperative semantics that you want, so you can do clever things
12:51:32 <tomppa> I guess I would like to have some dynamically selected objects to have identity
12:52:08 <phobes> tomppa:  Embed in a monad
12:52:33 <phobes> You can have a monad in which objects have identity
12:53:11 <wootles> when i :set +s in GHCi, and it says : (48.71 secs, 5191811456 bytes)  , what does the memory figure mean?
12:53:21 <psnively> I think the whole notion of "objects with identity" derives from the mutation mindset, and is extremely problematic, even in languages with mutation and objects with identity.
12:53:49 <phobes> psnively: I think  "objects with identity" + "everything is an object" is where you get into trouble
12:54:00 <psnively> What you said.
12:54:11 <phobes> psnively: Modeling actual "objects" in the world and giving them identities that other objects can remember makes alot of sense to me
12:54:33 <tomppa> it seems like a natural way to solve some problems
12:54:38 <EvilTerran> wootles, i think it's the amount of memory used overall, including stuff that was long ago garbage collected
12:54:45 <psnively> phobes: To the extent that "identity" == "pointer" or something, I think I agree.
12:54:53 <EvilTerran> unless you've got 5GB of memory over there ;]
12:55:02 <ricky_clarkson> psnively: Objects with an identity implies that you can create objects.
12:55:26 <psnively> tomppa: It's just surprisingly fraught with danger; see http://okmij.org/ftp/Computation/Subtyping/
12:55:27 <lambdabot> Title: Subtyping, Subclassing, and Trouble with OOP
12:55:39 <ricky_clarkson> psnively: You should only be able to use them, if they are immutable, and not have to worry about creating them.
12:55:51 <ricky_clarkson> Like I don't have to say 2=succ succ 0
12:56:01 <psnively> Right.
12:56:08 <ricky_clarkson> (that's not quite the same, duh)
13:00:21 <oklopol> > 1
13:00:22 <lambdabot>  1
13:00:46 <pejo> psnively, got a short punchline for the Oleg stuff on Subtyping?
13:01:35 <ricky_clarkson> > [1..]==[1..]
13:01:38 <phobes> pejo:  looks like "inheritance breaks encapsulation"
13:01:39 <lambdabot> Terminated
13:02:03 <bos> @hoogle &
13:02:04 <lambdabot> Data.Graph.Inductive.Graph.(&) :: DynGraph gr => Context a b -> gr a b -> gr a b
13:02:04 <lambdabot> Prelude.(&&) :: Bool -> Bool -> Bool
13:02:04 <lambdabot> Control.Arrow.(&&&) :: Arrow a => a b c -> a b c' -> a b (c, c')
13:02:19 <psnively> 1) "Subclassing and Subtyping are not the same thing."
13:02:29 <EvilTerran> i think it's more "overloading methods breaks encapsulation"
13:02:36 <psnively> 2) "Subclassing doesn't help enforce important algebraic properties of types."
13:02:53 <psnively> 3) "Most object-oriented software works by accident."
13:02:55 <EvilTerran> yes, that (2)'s the punchline, i guess
13:03:20 <psnively> 3) is really due to Graydon Hoare.
13:03:36 <EvilTerran> overloading methods of the superclasswould work fine if there were rigidly defined algebraic properties for the methods and you were careful to follow them
13:03:54 <pejo> Well, to be honest - I think that you can remove the word 'object-oriented' from 3 and it still holds.
13:04:12 <phobes> EvilTerran:  Ah you mean (what is to me) overriding
13:04:17 <psnively> pejo: Sure. The point is that object-orientation was supposed to help (more than it does).
13:04:19 <phobes> overloading (to me) is something else
13:04:20 <Saul_> Yeah but isn't that the case with haskell as well, nobody is forcing you to obey the monad laws, or that the (+) is associative for Num
13:04:28 <EvilTerran> pejo, that implies that non-OO imperative software ever actually works ;]
13:04:38 <ricky_clarkson> Subclassing retards.  (retard as in the verb here, I'm not sinsulting anyone!)
13:04:53 <EvilTerran> Saul_, it would be the case, but haskell tends to have said algebraic properties written down somewhere
13:05:03 <phobes> EvilTerran: And in that case, I agree with you... "the ability to override any method breaks encapsulation"
13:05:05 <psnively> Saul_: Sure. No one is claiming perfection. It's just that whole classes (heh) of OO software are Just Wrong‚Ñ¢.
13:05:17 <EvilTerran> Saul_, so it is *possible* to write
13:05:28 <EvilTerran> ...a subclass that doesn't break the superclass
13:05:31 <psnively> (And if you want the monad laws enforced, there's always Coq.)
13:05:36 <EvilTerran> and then modify the superclass without breaking the subclass
13:05:38 <Saul_> psnively: Yeah that's true
13:05:38 <phobes> Saul_:  With OO there's not a clear law that you're supposed to follow to get correct code
13:05:39 <EvilTerran> and so on
13:05:54 <EvilTerran> the prevailing wind in OO seems to not require such a thing, though
13:06:04 <Saul_> psnively: But I think it might have more to do with the users of haskell, than with haskell itself
13:06:06 <phobes> Look at all the OO languages trying to solve the "covariance problem"
13:06:21 <EvilTerran> what's that, then?
13:06:37 <phobes> Which is AFAICT a manifestation of using subtyping when you meant subclassing (in the Haskell sense)
13:06:38 <psnively> Yeah. In interviews, when I bring up the Liskov Substitutability Principle, people give me blank stares. When I explain it to them, they seem to think that's so horribly overly restrictive as to be utterly worthless.
13:06:54 <ricky_clarkson> Haha.
13:06:57 <psnively> phobes: Exactly.
13:07:15 * EvilTerran looks it up
13:07:16 <psnively> Saul_: So you're saying there's a cultural benefit to being a Haskeller? I quite agree.
13:07:21 <EvilTerran> wait, that's bleeding obvious!
13:07:21 <ricky_clarkson> psnively: Do better CV/resume screening.
13:07:27 <Saul_> psnively: I was
13:07:34 <psnively> ricky_clarkson: No kidding.
13:07:44 * EvilTerran would only need told what it was 'cos he'd never heard the name
13:07:47 <psnively> Saul_: Very good. :-)
13:08:02 <psnively> Yeah. CS people sometimes do refer to covariance and contravariance.
13:08:12 <Saul_> psnively: On the one hand it's a pity that not more people are using such a blissful language, but I think that on the other hand, they would just rape it
13:08:17 * EvilTerran doesn't even think something that intuitively obvious needs a name
13:08:26 <psnively> EvilTerran: And yet...
13:08:42 * EvilTerran points saul to the "I'm an imperative programmer!!! hpaste again
13:08:52 <psnively> Saul_: Haskell makes that, thankfully, bloody hard. But point taken; you can just write everything with unsafe_________ and be evil, yes.
13:09:21 <ricky_clarkson> And then develop an IDE that hides unsafe_______.
13:09:23 <EvilTerran> @remember http://hpaste.org/2654 "I'm an imperative programmer!!!"
13:09:23 <lambdabot> Done.
13:10:00 <Saul_> There are a lot of people in my classes (I study Computer Science) that actually run away screaming when I start talking about haskell
13:10:09 <pejo> phobes, what is the problem with covariance that they are trying to solve?
13:10:25 <xerox> EvilTerran: I doubt hpaste is persistent, better make a wikipage for persistence :)
13:10:40 <Olathe> Saul_: Cool :)
13:11:13 <dons> hpaste is persistent...
13:11:13 <EvilTerran> http://hpaste.org/0 -- looks fairly persistent to me
13:11:13 <omniscientIdiot> http://hpaste.org/1
13:11:16 <phobes> pejo:  When you override a method during inheritance (as subtyping), you can change the types on the parameters and return values, but only covariantly and contravariantly, respectively
13:11:29 <phobes> pejo:  But that's a real PITA
13:11:38 <psnively> Saul_: Unfortunately, people get addicted to mutation almost immediately upon exposure to it.
13:11:45 <Heffalump> it died once, not that long ago
13:11:45 <EvilTerran> Saul_, you can use that to get the upper hand at interviews -- talk about haskell 'til all the other candidates've run away
13:11:52 <psnively> LOL
13:11:54 <ricky_clarkson> phobes: Why is that bad?
13:12:02 <pejo> phobes, doh! covariance is the wrong thing.
13:12:03 <Saul_> Olathe: Less cool is that I know need to use C++ for my Visualisation assignment, since I couldn't convince anyone to use haskell
13:12:06 <dons> its also rather hard to build hpaste atm, as its linked against an old version of happs
13:12:18 <shapr> psnively: I dunno, I got addicted to lack of mutation when I was exposed to it.
13:12:19 <phobes> Probably the simplest example is object cloning.  Suppose class Object has a clone method that returns Object.
13:12:28 <psnively> Saul_: Um... there are about a dozen worthwhile languages other than Haskell or C++. :-)
13:12:35 <phobes> Then you have class Foo that derives Object, but you want its clone method to return a Foo
13:12:42 <psnively> shapr: You're not from around here, are you? ;-)
13:12:50 <ricky_clarkson> phobes: That's fine.
13:12:51 <shapr> psnively: Depends on what you mean by that.
13:13:04 <EvilTerran> phobes, sounds like you want ad hoc polymorphism
13:13:05 <phobes> Ya, actually, that is fine
13:13:12 <shapr> psnively: Born in Alabama, started #haskell years ago, decades of Python, Java, VB before that.
13:13:13 <phobes> That's the correct variance
13:13:20 <dons> I think people are missing the industry trends if they're not looking at FP languages now
13:13:22 <psnively> shapr: I know. I'm teasing. I think a very few people are drawn to a mathematical/logical point of view of programming, that's all.
13:13:34 <Saul_> psnively: Like what?
13:13:38 <phobes> but now consider the case of comparing for equality
13:13:43 <dons> C# picking up data parallel list comprehensions ... where'd they get  that idea eh? :)
13:13:46 <psnively> dons: Thanks in no small part to your efforts. :-)
13:13:46 <shapr> psnively: pjd said it best when he described overwriting a variable as an explicit garbage collection decision.
13:14:01 <phobes> Object might have a compareTo(Object) method... and you might want to override that method in Foo with compareTo(Foo)
13:14:17 <phobes> which is obviously not type safe, but is very convenient
13:14:21 <ricky_clarkson> phobes: That's where you want generics.
13:14:23 <psnively> Saul_: For visualization work, I would have to suggest... almost anything other than C/C++.
13:14:27 <phobes> ricky_clarkson:  Yes
13:14:32 <EvilTerran> since learning Haskell, i find myself getting antsy when things don't have documented algebraic properties
13:14:33 <psnively> shapr: A very good point.
13:15:03 <Saul_> psnively: Too late :(
13:15:26 <psnively> EvilTerran: Me too! But I can't even get people excited about http://alloy.mit.edu or trying to work through http://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-Software/dp/0321125215/ref=pd_bbs_sr_1/104-2276105-6959915?ie=UTF8&s=books&qid=1190232866&sr=8-1
13:15:28 <lambdabot> Title: Alloy Homepage
13:15:38 <EvilTerran> psnively, i agree wholeheartedly. i just recently persuaded one of my mathmo friends to do the number-crunching project set by his uni in haskell instead of C
13:15:41 <psnively> Saul_: Yeah, I sympathize.
13:16:28 <dolio> C? He wasn't usin Fortran?
13:16:28 <EvilTerran> (you may have seen him on here by the name of QuietPurple)
13:16:38 <Saul_> psnively: I really wanted to do that in haskell, since I wanted to learn how to use opengl in it
13:16:50 <Saul_> psnively: I want to make a game at some point
13:16:53 <EvilTerran> dolio, no, cam.ac.uk've outgrown *that*, at least ;)
13:16:59 <dolio> :)
13:17:16 <phobes> ricky_clarkson:  The thing is that you had to foresee that you wanted to use generics when you wrote the base class
13:17:16 <psnively> I hear good things about HOpenGL.
13:17:22 <EvilTerran> (well, maths.cam.ac.uk. those fossils in the natural sciences're probably still using fortran, cobol, assembly language, and APL)
13:18:00 <phobes> ricky_clarkson:  Which is why Eiffel went ahead and made up a complicated rule to be lenient on variance
13:18:08 <Saul_> psnively: I've tried to find some info on it though, and it's pretty badly documented (especially if you're new to opengl)
13:18:21 <phobes> (the rule basically being you can use the wrong variance as long as you don't use subtyping too powerfully with it)
13:18:24 <shapr> hiya samreid
13:18:35 <ricky_clarkson> phobes: Ok, so in other words, references to yourself in a non-final class are a bit silly.
13:18:50 <Saul_> psnively: Basically all documentation is very old (when the hopengl stuff was still a direct port from the C bindings)
13:18:52 <ricky_clarkson> phobes: ..other than in declarations of type parameters.
13:19:07 <pejo> phobes, to check that I understood - language designers are using covariant subtyping rules in their type system, when it's well known they shouldn't, basically?
13:19:22 <Saul_> psnively: They've cleaned it up since then, but don't seem to have updated the documentation very well
13:19:37 <phobes> pejo:  No, most language designers use sound type rules I think... Eiffel being a notable exception
13:20:07 <phobes> ricky_clarkson:  I think the problem is that often you want subclassing an not subtyping
13:20:21 <ricky_clarkson> For code reuse?
13:20:25 * EvilTerran found http://blog.mikael.johanssons.org/archive/2006/09/opengl-programming-in-haskell-a-tutorial-part-1/ was enough to get him started with HOpenGL, never having used OpenGL before
13:20:26 <phobes> ricky_clarkson:  Maybe you can fake subclassing by going crazy with generic parameters, ...
13:20:29 <lambdabot> Title: Michi&#8217;s blog ª Blog Archive ª OpenGL programming in Haskell - a tutorial ( ..., http://tinyurl.com/ea6tc
13:21:17 <tomppa> Saul_: You could always use some higher level foreign library and write your own bindings to it. It seems to be fairly easy in haskell
13:21:22 <psnively> I have to say that OCaml might have an edge for game development, with LablGL and bindings to ODE.
13:21:24 <EvilTerran> although the first example doesn't work with the version of GLUT i've got
13:21:44 <tomppa> writing bindings to shouldn't take more than a day or two...
13:21:50 <tomppa> to ODE, I mean
13:22:07 <psnively> Not if you keep 'em thin (as the OCaml bindings are).
13:22:19 <Saul_> EvilTerran: Yeah I did that one already, but that seemed a little limited
13:22:42 <EvilTerran> i've used other graphics libraries in other languages, mind, which may've helped
13:23:01 <Saul_> EvilTerran: I think it might
13:23:02 * EvilTerran still intends to write an allegro (alleg.sf.net) binding at some point
13:23:13 <dons> go for it EvilTerran !
13:23:16 <dons> just do it now :)
13:23:25 <EvilTerran> i can't get c2hs working on windows =(
13:23:30 <Saul_> EvilTerran: I did actually take a bunch of courses on computer graphics, but that was mostly theoretical
13:23:38 <dons> EvilTerran: oh? using the new c2hs?
13:23:43 <dons> have you talked to dcoutts about it?
13:23:43 <EvilTerran> not without installing cygwin, anyway, and that did terrible things to my system's performance the last time i did it
13:23:49 <EvilTerran> i may have done something stupid
13:23:58 <dons> it shouldn't need cygwin, afaik
13:24:02 <dons> maybe it does though
13:24:05 <Saul_> Basically I know how my graphics card works, but I can't get it to
13:24:05 <EvilTerran> but my last attempt seemed to boil down to "you need autoreconf"
13:24:06 <ricky_clarkson> EvilTerran: I've never noticed cygwin slow stuff down.
13:24:33 <EvilTerran> ricky_clarkson, well, the cygwin prompt itself got slower and slower 'til it refused to load at all
13:25:35 <wootles> what's the neatest way to define an infinite list [1, f(1), f.f(1), f.f.f(1) , ... ] ?
13:25:42 <EvilTerran> > iterate (1+) 1
13:25:43 <xerox> iterate f 1
13:25:44 <lambdabot>  [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,...
13:25:52 <EvilTerran> @src iterate
13:25:53 <lambdabot> iterate f x =  x : iterate f (f x)
13:26:03 <wootles> thanks :)
13:26:11 <xerox> ?hoogle (a -> a) -> a -> [a]
13:26:12 <lambdabot> Prelude.iterate :: (a -> a) -> a -> [a]
13:26:12 <lambdabot> List.deleteBy :: (a -> a -> Bool) -> a -> [a] -> [a]
13:26:12 <lambdabot> List.insertBy :: (a -> a -> Ordering) -> a -> [a] -> [a]
13:26:25 <EvilTerran> @docs Prelude -- i almost always have this open when i'm coding in Haskell
13:26:25 <lambdabot> Prelude -- i almost always have this open when i'm coding in Haskell not available
13:26:31 <EvilTerran> wha...
13:26:35 <EvilTerran> @docs Prelude
13:26:35 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html
13:27:20 <EvilTerran> @where c2hs
13:27:21 <lambdabot> http://www.cse.unsw.edu.au/~chak/haskell/c2hs/
13:27:26 * EvilTerran will have another go...
13:27:58 <jbauman> > sum $ take 10 $ iterate (/0.5) 1
13:28:00 <lambdabot>  1023.0
13:28:21 <jbauman> > sum $ take 10 $ iterate (/2.0) 1
13:28:22 <lambdabot>  1.998046875
13:28:51 <EvilTerran> > length . takeWhile (/=2) . iterate (/2) $ 1
13:28:55 <lambdabot> Terminated
13:28:57 <EvilTerran> wait...
13:29:01 <koeien> that's infinity
13:29:13 <EvilTerran> > length . takeWhile (/=2) . scanl (+) 0 . iterate (/2) $ 1
13:29:15 <lambdabot>  54
13:29:23 <EvilTerran> that's the one i was after ;]
13:30:12 <EvilTerran> > (length . takeWhile (/=0) . iterate (/2) $ 1, length . takeWhile (/=1) . map (+1) . iterate (/2) $ 1) -- an interesting comparison, imo
13:30:13 <lambdabot>  (1075,53)
13:30:47 * EvilTerran has used code very much like that to aptly demonstrate the limitations of floating point math
13:31:43 <Mr_Awesome> that is interesting
13:32:11 <Mr_Awesome> i wouldnt have expected such a discrepancy
13:32:28 <EvilTerran> in the first case, the exponent can move. in the second, it can't
13:32:28 <omniscientIdiot> adding 1 seems to decrease the accuracy?
13:32:29 <pjd> shapr: did i say that?
13:32:48 <EvilTerran> so the second can only go as many steps as there are bits in the mantissa
13:33:02 <EvilTerran> while the first can go all the way down 'til you can't make the exponent any smaller
13:33:55 <EvilTerran> [2^0, 2^-1, 2^-2, 2^-3 ...] vs [1, 1.1, 1.01, 1.001, 1.0001 ...]
13:34:16 <omniscientIdiot> right.
13:35:24 <phobes> 1075 is strange though
13:36:06 <EvilTerran> 1024 for the exponent, than another 51 until it runs out of denormalised ones, i guess
13:36:21 <EvilTerran> *1023 and 52, more likely, actually
13:36:21 <psnively> Aha! Here is the person to ask your OpenGL questions of. :-)
13:37:17 <phobes> EvilTerran: Ah yes, the denormalized ones :)
13:37:22 <shapr> pjd: Wasn't it you?
13:37:32 <shapr> pjd: Oh sorry paj
13:37:40 <pjd> ah, ok
13:37:50 <pjd> so i'm not going senile yet :)
13:38:00 <EvilTerran> (normally, the mantissa has an implicit 1 on the beginning. however, if the exponent is as small as it can be, that implicit 1 can disappear. otherwise, you could have 2^-1024, 2^-1024 + 1, + 2, ..., and you could have -2^-1024, -2^-1024 + 1, but you couldn't have anything in the middle
13:38:38 <shapr> pjd: Sorry for the confusion.
13:38:47 <EvilTerran> so a minimal exponent will indicate 0.<mantissa> * 2^-1023 instead of 1.<mantissa> * 2^<exponent> like it usually does
13:39:01 <phobes> EvilTerran: really?
13:39:12 <EvilTerran> (a minimal exponent being -1024)
13:39:38 <EvilTerran> phobes, if we're dealing with IEEE floating point, yup
13:39:52 <phobes> EvilTerran:  Hmm, never new that
13:39:55 <EvilTerran> as i said, it's to stop there being a (relatively) big gap around zero
13:39:56 <phobes> knew**
13:40:19 <dolio> The wonders of IEEE.
13:40:25 <dolio> So simple and elegant.
13:40:55 <EvilTerran> so, once you run out of making the exponent smaller at 1.0000...*2^-1023, you can then have 0.1000...*2^-123, 0.0100...*2^-1023, 0.0010...*2^-1023, etcetc
13:41:19 <psnively> I worked at Apple while the designer of IEEE was there. Very smart guy (obviously).
13:41:23 <psnively> Jeremy...?
13:41:31 <EvilTerran> > last . takeWhile (/=0) . iterate (/2) $ 1
13:41:33 <lambdabot>  5.0e-324
13:41:42 <EvilTerran> hm.
13:41:47 <phobes> EvilTerran:  Ok but then don't you have the same situation but replace 1024 with 1075?
13:41:58 <EvilTerran> phobes, not really, no
13:42:14 <EvilTerran> calls for a diagram, this
13:42:54 <phobes> I mean I see how it's different as you go away from 0
13:43:03 <EvilTerran> |                |        |    |  | |0| |  |    |        |                | <- 2^n, around zero
13:43:14 <EvilTerran> +/- 2^n, rather
13:43:49 <EvilTerran> if you didn't have denormalised numbers, the smallest number you could represent would be 2^-1024
13:44:08 <phobes> Yea... and if you do have them the smallest is 2^-1057
13:44:08 <EvilTerran> but you could also represent 2^-1024 + 2^-1076 or whatever
13:44:12 <phobes> err ya that
13:44:26 <idnar> or just 0?
13:44:34 <EvilTerran> and anything else between 2^-1024 and 2^-1023 in steps of 2^-1076
13:44:54 <EvilTerran> *but* you couldn't represent anything of lower magnatude than 2^-1024
13:45:33 <dolio> > decodeFloat . last . takeWhile (/=0) . iterate (/2) $ 1
13:45:34 <lambdabot>  (4503599627370496,-1126)
13:45:36 <EvilTerran> so you suddenly have a gap that's 2^52* the size of all the gaps near it
13:46:20 <phobes> oh I see your point
13:46:22 <phobes> ok thanks
13:46:27 <EvilTerran> instead, they fill the gap between -2^-1023 and +2^-1023 with equally-spaced points, so you don't have such a whopping gap
13:46:51 <EvilTerran> as idnar says, you couldn't even represent 0 without denormalised numbers, if you took the rest of IEEE
13:47:03 <EvilTerran> because of the implicit 1 at the start of the mantissa
13:47:09 <phobes> right
13:47:50 <phobes> which is good enough reason to declare exp MIN a special case I suppose
13:47:50 <EvilTerran> and, without that implicit 1, most numbers wouldn't have a single, unambiguous representation. and that would be even messier than the current arrangement
13:47:57 <axm> @hoogle pdynload
13:47:58 <lambdabot> No matches found
13:48:05 <wootles> is there a way to do this without the danger of stack overflow ? fastlist = listArray (0, 100000) $ (map (\(i,n,k)->(n `specmult` (2^k)))) (take 100001 (iterate fff (0,1,0)))
13:48:10 <EvilTerran> exp MAX is also reserved, for error codes etc
13:48:20 <phobes> ah
13:48:44 <wootles> do i need to use a strict iterate ?
13:48:45 <EvilTerran> NaN, +/-Inf, under/overflows, etcetc
13:49:07 <EvilTerran> > decodeFloat . last . takeWhile (/=1) . map (+1) . iterate (/2) $ 1
13:49:09 <lambdabot>  (4503599627370497,-52)
13:49:32 <EvilTerran> > first (printf "%X" :: Integer -> String) . decodeFloat . last . takeWhile (/=1) . map (+1) . iterate (/2) $ 1
13:49:33 <lambdabot>  Exception: Printf.printf: bad formatting char X
13:49:39 <EvilTerran> > first (printf "%x" :: Integer -> String) . decodeFloat . last . takeWhile (/=1) . map (+1) . iterate (/2) $ 1
13:49:41 <lambdabot>  ("10000000000001",-52)
13:49:54 <EvilTerran> > first (printf "%x" :: Integer -> String) . decodeFloat . last . takeWhile (/=0) . iterate (/2) $ 1
13:49:56 <lambdabot>  ("10000000000000",-1126)
13:50:09 <EvilTerran> crikey. that first one's wrong!
13:50:21 <EvilTerran> it's left the implicit 1 on the beginning! \o/
13:50:38 <EvilTerran> wait. never mind, i'm talking rubbish.
13:50:44 <EvilTerran> the second one?
13:50:45 <EvilTerran> er.
13:51:00 * EvilTerran stops flooding and goes to look up the definition of decodeFloat
13:51:02 <dolio> Yeah, decodeFloat's a little iffy.
13:51:19 <EvilTerran> @index decodeFloat
13:51:19 <lambdabot> Prelude
13:51:25 <dolio> It decodes NaN and infinities as if they followed the normal convention, too.
13:52:06 <phobes> can one not doing unsafeSomethingOrOther to get the actual bits out?
13:52:09 <EvilTerran> actually, i think it's right... but it's not accurately representing how the second one's stored in memory
13:52:19 <phobes> do**
13:52:39 <EvilTerran> unsafeCoerce#, between unboxed types, perhaps.
13:52:45 <dolio> You can unsafeCoerce to a Word64 or something.
13:53:06 <EvilTerran> i'd be tempted to switch to C and use a union{}
13:53:37 <EvilTerran> union { char cs [sizeof(float}]; float f } foo
13:58:38 <wootles> iterate' is in the prelude right ?
13:59:03 <Olathe> @hoogle iterate'
13:59:07 <lambdabot> No matches found
13:59:43 <wootles> does that mean its not in any of the standard libraries ?
14:00:15 <Olathe> I'm somewhat new, so I'm not sure.
14:00:47 <wootles> @hoogle nub
14:00:47 <lambdabot> List.nub :: Eq a => [a] -> [a]
14:00:47 <lambdabot> List.nubBy :: (a -> a -> Bool) -> [a] -> [a]
14:01:03 <wootles> damn
14:01:43 <Sgeo> @undo do foo; bar
14:01:43 <lambdabot> (foo >> bar)
14:02:01 <Sgeo> @undo fo
14:02:01 <lambdabot> (fo)
14:03:22 <EvilTerran> there is no iterate'
14:03:32 <EvilTerran> there's no need for it, as i understand it
14:03:43 <EvilTerran> or less, anyway.
14:03:51 <EvilTerran> like there's no scanl', iirc
14:04:10 <EvilTerran> the problem with foldl is that there's no way of stopping the buildup of a big unevaluated thunk
14:04:33 <EvilTerran> with scanl or iterate, if you force each element before calculating the next, no such buildup occurs
14:04:53 <EvilTerran> also, those ones are expected to use O(n) memory, while you'd hope foldl would be O(1)
14:05:14 <EvilTerran> (assuming it's building a value that doesn't take up more memory as you go along the list)
14:06:33 <wootles> fastlist = listArray (0, 100000) $ map (\(i,n,k)->(n `specmult` (2^k))) (take 100001 (iterate' fff (0,1,0)))
14:07:48 <wootles> it overflows when i replace iterate' with iterate
14:08:11 <EvilTerran> hm
14:08:40 <wootles> i have done it this way, because fastlist can *almost* be calculated iteratively
14:08:40 <EvilTerran> try moving the take to before the map
14:08:54 <Tac-Work> @unlambda `r```````````.H.e.l.l.o. .w.o.r.l.di
14:08:54 <lambdabot>  fd:23: hClose: resource vanished (Broken pipe)
14:09:02 <EvilTerran> fastlist = listArray (0, 100000) $ take 100001 $ map (\(i,n,k)->(n `specmult` (2^k))) $ iterate fff (0,1,0)
14:09:10 <Tac-Work> Does unlambda work?
14:09:16 <Tac-Work> or is it broken?
14:09:21 <EvilTerran> it looks broken to me
14:09:38 <Tac-Work> poor bot
14:09:51 <dolio>  @bf is also broken.
14:09:59 <dons> unlambda and bf probably aren't built
14:10:00 <EvilTerran> > listArray (0,10) ['a'..]
14:10:02 <lambdabot>  array (0,10) [(0,'a'),(1,'b'),(2,'c'),(3,'d'),(4,'e'),(5,'f'),(6,'g'),(7,'h'...
14:10:08 <EvilTerran> > listArray (0,3) ['a'..]
14:10:10 <lambdabot>  array (0,3) [(0,'a'),(1,'b'),(2,'c'),(3,'d')]
14:10:19 <EvilTerran> wootles, actually, you don't need the take at all
14:11:19 <wootles> you're right, it's much neater now
14:11:46 <wootles> surely i must need to make it 'strict' at some stage though
14:12:25 <wootles> should I do it by making an iterate' , or by making fff strict ?
14:12:30 <EvilTerran> alternatively, you could express the computation in terms of array accesses, instead of building a list and then array-ifying it
14:13:11 <EvilTerran> fastlist = listArray (0, 100000) $ map (\(i,n,k)->(n `specmult` (2^k))) $ (0,1,0) : map (fff.(fastlist!)) [0..]
14:14:08 <EvilTerran> > let a = listArray (0,100) $ 1 : map ((+2) . (a!)) [0..] in a
14:14:11 <lambdabot>  array (0,100) [(0,1),(1,3),(2,5),(3,7),(4,9),(5,11),(6,13),(7,15),(8,17),(9,...
14:14:25 <EvilTerran> i don't know if that would help, but it might
14:14:27 <wootles> its problematic because fastlist itself can't easily be calculated iteratively
14:16:30 <wootles> to give an analogy, it's like fastlist!n = factorial(n) + mod n 5 ... it's messy to calculate fastlist recursively, but its easy to calculate it from a separate recursive sequence (factorials)
14:18:13 <wootles> i think maybe the problem is that  (iterate fff (0,1,0)) is working backwards, building up a stack and then evaluating it once it hits (0,1,0)
14:18:28 <axm> so, I was trying to get the hs-plugins polymorphic "hello world" to run, but there is no AltData module in plugins-1.0 anymore. the 0.9.10 seems not to be buildable in ghc-6.6. anyone here got that working?
14:18:49 <kyevan> Hi... does anyone know of a version of YAHT formatted to be usable when printed on a B+W printer?
14:19:15 <kyevan> (EG, not using the blue and green borders, etc)
14:19:27 <wootles> so if I wander too far from (0,1,0), the stack overflows before it ends ... but since there is no iterate' in the prelude, i am guessing I shouldnt be using iterate for this in the first place
14:19:47 <EvilTerran> wootles, i'm not sure what you're trying to do here anymore
14:20:08 <bos> kyevan: http://darcs.haskell.org/yaht/yaht.pdf
14:21:26 <wootles> EvilTerran: fastlist!n is to be equal to factorial (n) but with any factor 10 removed (ie keep dividing by 10 until no longer possible)
14:21:44 <EvilTerran> hm
14:22:28 <EvilTerran> i would suggest a scanl over [1..] for such a process
14:22:30 <kyevan> Note to self: Do NOT accidently instruct Acrobat Reader to read YAHT out loud >_>
14:22:36 <EvilTerran> > scanl (*) 1 [1..]
14:22:48 <lambdabot>  [1,1,2,6,24,120,720,5040,40320,362880,3628800,39916800,479001600,6227020800,...
14:23:06 <axm> so divide by 2 for each factor 5 the next n contains?
14:23:19 <ricky_clarkson> kyevan: Does it crash?
14:23:40 <EvilTerran> > scanl (\e x -> let y = e*x in if y `mod` 10 == 0 then y `div` 10 else y) 1 [1..]
14:23:41 <lambdabot>  [1,1,2,6,24,12,72,504,4032,36288,36288,399168,4790016,62270208,871782912,130...
14:24:05 <kyevan> ricky_clarkson: No, it just sits around eating your entire CPU and insane amounts of memory.
14:24:08 <wootles> axm: almost ... I only want the last 5 non-zero digits of the factorial. as long as multiplication by 5 never occurs, its sufficient to just work mod 100000
14:24:13 <EvilTerran> (could be phrased more efficiently with divMod rather than div and mod seperately)
14:24:20 <kyevan> I managed to kill it shortly before it got to 200 megabytes of ram used >_>
14:24:58 <kyevan> Reloaded with just the PDF, it's at roughly 40.
14:25:01 <Olathe> The 2s will screw you up, though.
14:25:27 <wootles> what i do, is 'cream off' some factors of 2
14:25:29 <EvilTerran> every time you hit a 5, you can divide by 10, 'cos you will always've seen more 2s than 5s
14:25:33 <Olathe> The zeroes come from a combination of a 2 and a 5. So, for every 5 you skip, you have to skip a 2.
14:25:34 <kyevan> bos: It still uses the color borders :(
14:25:58 <wootles> then whenever a 5 comes, i cancel it with one of those 2s, and reduce my count of 2s
14:26:27 <kyevan> oh well.
14:26:54 <wootles> now that can be done iteratively by working on (i, n, k), where n is the product so far, and k is my 'buffer' of 2s which i have creamed off
14:26:58 <kyevan> Figuring out which is which is usually easy from context or content, I guess
14:27:56 <wootles> to actually get the value at a given position, i, i use f = n * 2^k   (putting the 2s back)
14:27:57 <oklopol> > let times 0 _ v = v; times n f v = f $ times (n-1) f v in times 3 (*2) 4
14:27:59 <lambdabot>  32
14:28:26 <glguy> *prod*
14:28:40 * oklopol falls down
14:28:45 * kyevan wastes paper and ink
14:29:46 <EvilTerran> tree murderer!
14:29:51 <wootles> the sequence of tuples (i,n,k) can be calculated iteratively, so then the sequence of (f) is just a map from the tuples of (i,n,k)
14:30:06 <wootles> hence   map (\(i,n,k)->(n `specmult` (2^k))) $ iterate fff (0,1,0)
14:30:52 <wootles> thing is, i cant just calculate the sequence of (f) iteratively, because once you put the 2s back in by doing 2^k, that destroys information that you would need in order to proceed iteratively
14:31:11 <wootles> because dividing by 2 is a no-no
14:31:13 <kyevan> EvilTerran: We let the ones in our yard live, even though they're a pain, That makes up for it, right?
14:31:36 <EvilTerran> oh, all right then
14:31:44 <Olathe> You can do f' that returns a tuple and f that converts the tuple to a number at the very end.
14:31:51 <EvilTerran> wootles, what exactly is the problem you're trying to solve?
14:32:13 <wootles> http://projecteuler.net/index.php?section=view&id=160
14:32:15 <Olathe> Then, just keep the total 2s without multiplying them in with f'.
14:32:18 <lambdabot> Title: Project Euler
14:33:55 <wootles> thats a good point olathe.. instead of  f n = fastlist!n , I could have f itself be the mapping
14:33:58 <monochrom> I'm just going to whine: Why do newbies troll Haskell? Why is pattern matching strict by default? Why does the computer keep giving me surprises? Why doesn't it just read my mind?
14:34:19 <EvilTerran> hm
14:34:23 <monochrom> s/Haskell/haskell-cafe/
14:34:56 <kyevan> Hmmm
14:34:56 * EvilTerran notes that that seems to be the problem that the fewest people've solved of Project Euler
14:35:09 <wootles> EvilTerran: i have an O(log n) solution , i am just putting memorisation in to make it faster
14:35:23 <kyevan> monochrom: I can answer the last one: It does.
14:35:32 <kyevan> It reads your mind, and does the thing most likely to annoy you.
14:35:38 <kyevan> It's part of the robot uprising!
14:35:44 <monochrom> heh
14:35:45 <EvilTerran> instance Read Mind...
14:36:06 <EvilTerran> when we get instance Write Mind, *that*'s when you need to be getting nervous
14:36:55 <monochrom> Debug your mind, not your code.
14:37:37 <EvilTerran> wootles, that's impressive. i'd've expected any algorithm to find f(N) to be O(N)
14:38:07 <EvilTerran> i'm gonna want to solve this myself now ;]
14:38:17 * EvilTerran has to wander off for a bit, tho
14:39:01 <wootles> it finds F(10^1000) in about 10 seconds ( <3 haskell )
14:40:16 <kyevan> the mindreading tech was origionally developed by google, by the way:http://www.google.com/intl/en/mentalplex/
14:40:17 <lambdabot> Title: Google
14:40:52 <kyevan> :P
14:46:26 <hpaste>  Olathe pasted "Fast power of two mod 100000" at http://hpaste.org/2819
14:47:08 <FMota> isnt it easier to just shift?
14:47:24 <FMota> then again, might not be integers... right
14:47:52 <Olathe> It might be.
14:48:20 <wootles> mm
14:48:26 <sorear> shift isn't too fast for huge integers
14:48:39 <wootles> i think I can just adjust the algorithm to cream off less 2s
14:48:40 <FMota> hmm?
14:49:00 <FMota> how huge are we talking here? :)
14:49:13 <wootles> at the moment, it just takes off a 2 from every even number, which is excessive to just cancel off the 5s
14:50:41 <Olathe> It died with: mod (Data.Bits.shiftL (1::Integer) 250000005) 100000
14:51:35 <wootles> ive derived that if  g(n) is the number of times that 5 divides n, then as n->+inf, g(n!)/n -> 1/4  ( from below )
14:54:41 <Olathe> It takes 0.04 secs to do the twoPower thing. It takes almost a second to do the shifting and modding.
14:55:23 <wootles> 5 goes into 10000! 2499 times
14:55:48 <Olathe> > (div 10000 5)
14:55:53 <lambdabot>  2000
14:56:28 <wootles> i should say, that 5^2499 divides 10000!, but 5^2500 does not
14:57:26 <Olathe> > let f n 0 = 0; f n k = let d = div k n in d + f n d in f 100000 5
14:57:28 <lambdabot>  0
14:57:30 <Olathe> Bah.
14:58:15 <Olathe> > let f n 0 = 0; f n k = let d = div k n in d + f n d in f 5 100000
14:58:16 <lambdabot>  24999
14:58:27 <Olathe> > let f n 0 = 0; f n k = let d = div k n in d + f n d in f 5 10000
14:58:29 <lambdabot>  2499
14:59:31 <shapr> cabal-setup is broken :-(
14:59:57 <wootles> do you know if ** uses exponentiation by squaring ?
15:01:10 <Lemmih> shapr: How so?
15:01:41 <shapr> Lemmih: ./CabalSetup.hs:14:7: \n Could not find module `Distribution.SetupWrapper':
15:02:25 <Lemmih> shapr: Are you trying to compile cabal-setup?
15:02:25 <Olathe> wootles: Since it can do Float powers, it's probably done with log and exp.
15:02:29 <shapr> Lemmih: yes
15:03:09 <Lemmih> shapr: And you have the latest Cabal?
15:03:15 <shapr> yup, 1.2
15:03:35 <wootles> Olathe: hmm, what about ^  ?
15:03:47 <Lemmih> shapr: Not the darcs version?
15:03:55 <shapr> It is the darcs version.
15:03:58 <Olathe> wootles: Not sure.
15:04:10 <Olathe> How do I force an Integer into an Int ?
15:06:51 <shapr> Lemmih: Does cabal-setup not work with the darcs version?
15:13:21 <scsibug> Olathe: fromInteger
15:14:30 <kyevan> D'arvet!
15:14:36 <kyevan> I printed out YAHT, started to punch it... and realised that my stepdad adjusted the hole puncher for his organizer pages >_>
15:19:06 <hpaste>  Olathe annotated "Fast power of two mod 100000" with "much faster" at http://hpaste.org/2819#a1
15:19:28 * ddarius had a totally different visual when reading the first part of that sentence.
15:21:03 <hpaste>  Olathe annotated "Fast power of two mod 100000" with "small error corrected" at http://hpaste.org/2819#a2
15:21:12 <Olathe> There.
15:21:34 <Olathe> FMota was right.
15:21:46 <FMota> :o
15:22:18 * dylan punches kyevan 
15:22:50 <kyevan> Ow :( Wazzat for, dylan?
15:23:15 <FMota> Olathe: well, I meant just doing
15:23:41 <FMota> oh
15:23:42 <FMota> nvm
15:23:45 <FMota> XD :)
15:24:20 <dylan> kyevan: for punching yaht. :)
15:24:47 <oklopol> > (,) 1 2
15:24:49 <lambdabot>  (1,2)
15:24:51 <oklopol> > (+) 1 2
15:24:52 <lambdabot>  3
15:24:58 <oklopol> > (+ 2) 2
15:24:59 <lambdabot>  4
15:25:02 <oklopol> > (, 2) 2
15:25:02 <lambdabot>  Parse error
15:25:06 <oklopol> why?
15:25:14 <ddarius> , is not an operator
15:25:14 <ricky_clarkson> , is syntax
15:25:21 <oklopol> ah
15:25:32 <ddarius> flip (,) 3 4
15:25:39 <ddarius> > flip (,) 3 4
15:25:41 <lambdabot>  (4,3)
15:25:43 <oklopol> > let (,,) = (,) in (,, 4) 2
15:25:44 <lambdabot>  Parse error
15:26:02 <oklopol> but... (,) is a function still, right?
15:26:07 <dylan> > let x =
15:26:07 <lambdabot>  Parse error
15:26:08 <dylan> err
15:26:13 <ddarius> > let (,) = (+) in (2,4)
15:26:14 <lambdabot>      Constructor `(,)' should have 2 arguments, but has been given 0
15:26:15 <lambdabot>     In t...
15:26:21 <ddarius> oklopol: It's a constructor.
15:26:26 <ddarius> So, yes.
15:26:35 <dylan> > let x = (,) in (`x` 2) 4
15:26:36 <lambdabot>  (4,2)
15:26:47 <kscaldef> I was reading this article from dons's blog: http://cgi.cse.unsw.edu.au/~dons/blog/2007/07/31#rle and was a little confused by this line: "encode = map (length &&& head) . group"
15:26:50 <lambdabot> Title: Haskell hacking
15:27:01 <dylan> kscaldef:
15:27:02 <kscaldef> is there a use of &&& other than for arrows?
15:27:03 <ddarius> kscaldef: What confused you?
15:27:05 <oklopol> you can't do (oper value) function creation with an operator of your own?
15:27:16 <kscaldef> hoogle didn't come up with anything
15:27:18 <ddarius> kscaldef: It is using the Arrows one with the (->) instance.
15:27:21 <dylan> > (head &&& tail) "foo"
15:27:22 <lambdabot>  ('f',"oo")
15:27:40 <oklopol> > let (!!!!!!!) a b = a * (- b) in (!!!!!!! 3) 2
15:27:41 <lambdabot>  -6
15:27:45 <ddarius> @src (->) first
15:27:46 <lambdabot> first f = f *** id
15:27:48 <kscaldef> so, is the arr function totally redundant?
15:27:53 <sorear> no
15:28:02 <ricky_clarkson> Not on talk like a pirate day.
15:28:10 <ddarius> kscaldef: For the (->) instance, arr is just id.
15:28:11 <sorear> it's necessary to go from (->) a b to (~>) a b
15:28:12 <kscaldef> :-)
15:28:44 <oklopol> > (,,)
15:28:45 <lambdabot>  Add a type signature
15:28:53 <phobes> wootles:  When you say your algorithm is O(log n), is that assuming constant time operations on numbers with O(log n) digits?
15:28:57 <oklopol> (,,) is syntax too, is why my code failed?
15:29:07 <ddarius> > let (=^.-=) = (++) in "foo" =^.-= "bar"
15:29:09 <lambdabot>  "foobar"
15:29:13 <oklopol> > let (,,) = (,) in (,, 4) 2 -- mean this one
15:29:13 <lambdabot>  Parse error
15:29:20 <ddarius> oklopol: Yes.
15:29:24 <ddarius> :t (,,)
15:29:26 <lambdabot> forall a b c. a -> b -> c -> (a, b, c)
15:29:27 <JBGood25> phobes, possibly, but not necessarily
15:29:57 <ddarius> @src (->) (&&&)
15:29:57 <lambdabot> Source not found. Do you think like you type?
15:30:09 <kscaldef> sorear: what is (~>)?
15:31:02 <phobes> JBGood25:  what do you mean by that?   (and are you wootles btw?)
15:36:26 <phobes> JBGood25:  FYI - I was really asking if you were wootles, not telling you to keep out :)
15:38:08 <sorear> kscaldef: A free variable
15:38:56 <kscaldef> I'm not sure I understand exactly
15:39:46 <EvilTerran> ksandstr, the same as "a" and "b" in
15:39:48 <EvilTerran> @type map
15:39:57 <lambdabot> forall a b. (a -> b) -> [a] -> [b]
15:40:38 <LoganCapaldo> @type (join .) . liftM
15:40:40 <lambdabot> forall a a1 (m :: * -> *). (Monad m) => (a1 -> m a) -> m a1 -> m a
15:40:56 <LoganCapaldo> @type flip $ (join .) . liftM
15:40:58 <lambdabot> forall a a1 (m :: * -> *). (Monad m) => m a1 -> (a1 -> m a) -> m a
15:41:16 <EvilTerran> ksandstr, you could write map :: ((~>) -> (<~)) -> [(~>)] -> [(<~)], if you wanted, for instance
15:41:44 <LoganCapaldo> So I see how you can get >>= out of join and liftM, but is there a way to get return out of join + liftM ?
15:41:49 <EvilTerran> but that would be odd - it's normal to use (~>) as the type variable representing any arrow
15:41:55 <EvilTerran> ?type pure
15:41:56 <ddarius> LoganCapaldo: No.
15:41:57 <lambdabot>     Ambiguous occurrence `pure'
15:41:57 <lambdabot>     It could refer to either `pure', imported from Control.Applicative
15:42:01 <EvilTerran> ?type arr
15:42:03 <lambdabot> forall b c (a :: * -> * -> *). (Arrow a) => (b -> c) -> a b c
15:42:14 <LoganCapaldo> So you always need return no matter what, right?
15:42:24 <EvilTerran> arr :: Arrow (~>) => (b -> c) -> (~>) b c
15:42:27 <EvilTerran> or, alternatively,
15:42:31 <EvilTerran> arr :: Arrow (~>) => (b -> c) -> b ~> c
15:42:31 <wootles> phobes: with a couple of modifications, it could work with fixed precision only
15:42:33 <kscaldef> oh... so sorear's original statement was to say that  for other instances of Arrow, arr is important
15:42:47 <EvilTerran> or even
15:42:57 <EvilTerran> arr :: Arrow (~>) => (->) b c -> (~>) b c
15:43:01 <kscaldef> where I was only intending to ask if arr was redundant for the -> instance
15:43:01 <ddarius> LoganCapaldo: You could use some other functions, but using return is probably the simplest thing.
15:43:01 <sorear> yes
15:43:06 <xwx> @seen Lemmih
15:43:07 <lambdabot> Lemmih is in #haskell. I last heard Lemmih speak 39m 19s ago.
15:43:08 <sorear> kscaldef: you're right
15:43:09 <sorear> kscaldef: BUT
15:43:27 <kyevan> dylan: I was punching HOLES in the bottom of the paper, so I could keep it all together
15:43:28 <sorear> kscaldef: a polymorphic function needs arr even if it's going to be used at (->)
15:43:31 <SamB_XP> I will state that having arr in the Arrow class is actually extremely annoying -- at least with Arrow also being the base class
15:43:50 <EvilTerran> kscaldef, well, yes, it is. but, if you use it, your function may work for any Arrow
15:43:57 <kyevan> Now I have a stuffed-full binder with a copy of Squeak by Example (4 pages/sheet) and a copy of YAHT (2 pages/sheet)
15:44:16 <xwx> @where yampa
15:44:17 <lambdabot> http://www.haskell.org/yampa/
15:44:20 <kscaldef> yeah, I was really only asking in the specific context of that bit of code: encode = map (length &&& head) . group
15:44:41 <kscaldef> which I would previously expected had to be written encode = map (arr length &&& arr head) . group
15:45:05 <xwx> anyone know if the yampa darcs repository at http://darcs.haskell.org/yampa will ever be filled? and what about the branch located at http://wagerlabs.com/yampa/ ?
15:45:07 <lambdabot> Title: Index of /yampa
15:45:13 <wootles> phobes: but you have a point, since my exponentation function takes O(log n), perhaps the order should be O( (log n)^2 )
15:45:45 <ddarius> kyevan: Bottom?
15:46:12 <ddarius> At 4 pages per sheet, I'd rather read it off the computer.
15:46:58 <wli> Duplex printing is nice for such cases. I even get things bound.
15:47:16 <kyevan> I'm too lazy to do duplex printing >_>
15:47:29 <ddarius> kyevan: Buy a printer that does it for you.
15:47:59 <kyevan> ddarius: The fancy ones that print two sides at once? Those are EXPENSIVE.
15:48:29 <wli> I've never done duplex printing without a duplex printer.
15:48:38 <wli> kyevan: They used to be. Not anymore.
15:49:17 <kyevan> wli: Well, How do you define 'expensive'?
15:49:37 <kyevan> I define it as 'more than 250 dollars' for most things
15:50:57 <wootles> phobes: in fact, it is almost perfectly O((log n)^2)  : F(10^250) takes 0.64s, F(10^500) takes 2.5s, F(10^1000) takes 10s
15:51:00 <phobes> wootles:  Do you compute remainders mod 2^5 and mod 5^5 and then combine?
15:51:01 <wli> They're down to under 1K USD as add-on modules vs. 5K USD options on high-end printers which were already several thousand USD AIUI.
15:51:28 <phobes> wootles: (obviously there's more to it than that... but do you take that approach?)
15:51:35 <kyevan> Yeh, if I was running a buisness, that might be worth it, wli.
15:51:38 <kyevan> I'm not :P
15:51:40 <wootles> everything is done mod 100000
15:52:50 <phobes> (ya I meant 2^6 and 5^6)
15:52:56 <phobes> err no I didn't :)
15:53:20 <wootles> phobes: multiplication by (y=100000+x) has the same effect as multiplication by  x  iff x is not a multiple of 5
15:53:50 <wli> I would say they're within my budgetary constraints.
15:53:53 <wootles> eg *100020 doesnt have the same effect as *20 because *100020 is actually *10002 so we can't discard the leading 1
15:54:40 <sieni> a puzzle for you:
15:55:09 <phobes> wootles: hmm, I would think 2s and 5s are both special.... you need to pair up N 5s and 2s and discount them.... where N is the number of 5s in the product
15:56:11 <phobes> ie you can discount multiples of 5s, but you also need to discount some of the multiples of 2
15:56:28 <wootles> phobes: what i do, is skip multiples of 5 completely, and cancel a 2 elsewhere for every multiple of 5 i have ignored .. for example, 10! becomes 1*2*3*(2)*1*6*7*(4)*9*1
15:56:29 <wli> Units mod 10^5
15:56:39 <wootles> phobes: the brackets indicate where i have cancelled a 2
15:56:44 <phobes> wootles: ya, that works
15:56:48 <sieni> given an integer, not divisible by 5 or 2: prove that there is an integer whose decimal representation consists of only 1:s (e.g. 1, 1111, 111111111111, ...) which is divisible by that number
15:57:51 <wootles> phobes: what I have done differently to most of the other algorithms i see, is that I actually ignore the multiples of 5 completely .. instead of multiplying by 10, i multiply by 1
15:58:34 <phobes> wootles: so do you just loop over the numbers 1...10^6 and compute something?
15:59:46 <wootles> yes, for each 1 <= k < 10^5, i compute the product of all 1 < a <= k with a mod 5 > 0, then divide by 2^floor(k/5)
15:59:47 <ddarius> YES! More Eugenia Cheng videos!
16:00:30 <wootles> what makes my approach so fast, is that rather than factoring out a 5 from 10,15,20...., i just ignore those completely
16:00:33 * LoganCapaldo still has only watched the 1st monad one
16:01:00 <wootles> which enables me to assume that multiplication by y=x+10^5 has the same effect as multiplcation by x
16:01:12 <wli> wootles: Why is that correct?
16:01:39 <ddarius> LoganCapaldo: Watch Adjunctions 3, even if you don't understand anything at all it's entertaining.
16:01:54 <LoganCapaldo> heh, really?
16:02:00 <wootles> wli: when multiplying by such a number, we know that we wont get another zero on the end (there is no 5 to make one)
16:02:07 <ddarius> LoganCapaldo: Watch it and find out, it's only 10 minutes.
16:02:16 <LoganCapaldo> I will
16:02:43 <wootles> wli: therefore it is equivalent to taking the last 5 digits, and multiplying by (x+10^5) , then taking the last 5 digits of that ... but multiplication by (x+10^5) mod 10^5 is just multiplication by x
16:03:17 <kscaldef> ddarius: link?
16:03:30 <ddarius> kscaldef: http://www.youtube.com/user/TheCatsters
16:03:31 <lambdabot> Title: YouTube - Broadcast Yourself.
16:03:39 <wootles> wli: however it doesnt work when x is a multiple of 5, because then we could get an extra 0, in which case we would have to know the last 6 digits (because now we need an new digit to get 5 nonzero ones)
16:03:57 <wli> wootles: You sure you don't need to multiply by x/5 or x/10?
16:04:15 <wootles> wli: thats the nice part
16:04:51 <wootles> wli: say i wanted F(n), first i would do the product i described
16:04:55 <phobes> siene:  The powers of 10 form a subgroup of integers mod 9N under multiplication ... therefore 10^k = 1 for some k
16:05:08 <phobes> sieni rather
16:05:23 <wootles> wli: now, as you mention, i have to take account of the factors 10/5, 15/5, 20/5, etc
16:05:43 <phobes> wootles:  You mean you don't know the right answer to this?
16:05:53 <wootles> phobes: i do
16:06:01 <wootles> what happens, is that I repeat my procedure recursively
16:06:14 <phobes> ok, so you do know that your program works, right?
16:06:14 <phobes>  :)
16:06:18 <wootles> first I do my funky product for [1..x]
16:06:34 <sieni> phobes: that's an interesting way to put that argument, but it works
16:06:54 <wootles> now i missed the multiples of 5 ... so i do the same product for [1..floor(x/5)], now that has compensated for the multiples of 5
16:07:10 <wootles> except i am still missing the multiples of 25... so i do my product for [1..floor(x/25)] too
16:07:14 <sieni> phobes: I proved it with fermat's little theorem, but the original proof is such that a schoolkid can find it:
16:07:58 <LoganCapaldo> @source Control.Monad.Writer
16:07:59 <lambdabot> http://darcs.haskell.org/packages/mtl/Control/Monad/Writer.hs
16:08:02 <wootles> and so on recursively, until [1..floor(x/(5^k)] is empty so there are no more multiples i missed
16:08:17 <sieni> given n: pick a set of n+1 distinct integers consisting of just ones in the decimal representation
16:08:32 <sieni> calculate the remainder of each one of them against n.
16:08:51 <sieni> by pigeonhole principle there must be two with the same remainder
16:09:01 <wootles> what makes it efficient, is that you'll notice that at every stage, i have ignored multiples of 5, therefore i can use the *(100000+x) == *(x)  optimisation i discussed earlier
16:09:32 <sieni> take the difference between the larger and the smaller. it will consist of only one:s and two:s
16:09:45 <phobes> ones and zeroes?
16:09:47 <wootles> therefore for the first pass on 10^12, i need not calculate (10^12)!, but instead i just do P[1..10^5] ^ 7
16:10:04 <sieni> phobes: like 1111111 - 111 = 1111000
16:10:11 <wootles> P[1..10^5] ^ (10^7) that is
16:10:14 <phobes> (you said ones and twos, nm go on)
16:10:23 <sieni> phobes: sorry, my bad
16:10:47 <phobes> right, then you factor out the common power of 10
16:10:56 <sieni> yes
16:11:14 <ddarius> Is it just me, or is the pigeonhole principle wikipedia page have an excessively complicated example as its first example?
16:11:39 <phobes> Have you read djikstra's rant on the pigeonhole principle?
16:12:10 <ddarius> phobes: I doubt it.
16:12:40 <EvilTerran> @go djikstra's rant on the pigeonhole principle
16:12:44 <lambdabot> http://www.cs.uni.edu/~wallingf/blog/archives/monthly/2004-10.html
16:12:44 <lambdabot> Title: Knowing and Doing: October 2004 Archives
16:12:57 <phobes> It was interesting - I thought it was good
16:12:59 <ddarius> dijk
16:13:10 <EvilTerran> so much for ^C^V
16:13:17 <sieni> has dijkstra ranted about the pigeonhole principle?
16:13:22 <EvilTerran> @go dijkstra pigeonhole principle
16:13:24 <lambdabot> http://www.cs.utexas.edu/users/EWD/transcriptions/EWD09xx/EWD980.html
16:13:24 <lambdabot> Title: E.W. Dijkstra Archive: The strange case of The Pigeon-hole Principle (EWD 980)
16:13:58 * EvilTerran puts it in the set of "things which don't really need a name, given that they're so bleedin' obvious"
16:14:17 <sieni> the book is actually great (that he's referring to)
16:14:18 <phobes> Ya, that one's it ... he argues that you should just remember that "For a non-empty, finite bag of numbers, the maximum value is at least the average value."
16:15:26 * ddarius agrees with EvilTerran 
16:15:53 * EvilTerran scrolls up to remind himself what he last assigned to that set
16:16:01 <ricky_clarkson> covariance
16:16:35 <EvilTerran> ah, yes, it was the  Liskov Substitutability Principle, ~3hr ago
16:17:39 <phobes> I agree that the pigeon hole principle is obvious... Dijkstra's rant is about how so many proofs seem to invoke the pigeon hole principle in an almost mystical way
16:17:56 <phobes> voila!  now we apply the pigeon hole principle!  ooooh aahhh
16:18:22 * EvilTerran prefers "from this, it clearly follows that" as a magic proof step
16:18:38 <Pseudonym> That's called "proof by intimidation".
16:18:42 <wootles> whenever i write 'clearly' , i know i have made a mistake
16:18:42 <Pseudonym> It helps if you use the word "trivial".
16:19:05 <Pseudonym> Basically, if your audience can't see how it works, they're too dumb.
16:19:16 <phobes> I used to end proofs that I couldn't finish with QED ... used to get nasty comments from the TAs who wasted time trying to figure out the last step
16:19:31 <olsner> ;-)
16:19:32 <sjanssen> haha
16:19:43 <wootles> don't forget proof by excessive gesticulation
16:19:46 <mrd> proof by decree
16:19:53 <Olathe> Proof by proving.
16:20:03 <wootles> Olathe: stack overflow
16:20:06 <mrd> QED thus it is demonstrated.
16:20:31 <Pseudonym> Feynman did that in lectures, apparently.
16:20:41 <Pseudonym> He'd move bits of matrix around in mid-air.
16:20:44 <mrd> I like proof by absurd quantity of details, like in machine proofs.
16:20:53 <Pseudonym> That's "proof by exhaustion".
16:21:13 <Pseudonym> Weil's proof of the Taniyama-Shimura conjecture (semistable case) is the classic example.
16:21:24 <Pseudonym> Though the four colour theorem proof is also a good example.
16:21:50 <mrd> except on dead trees it cannot be checked mechanically, only cowered before
16:22:01 <Pseudonym> That was true of Weil's proof.
16:22:15 <olsner> isn't that proof (four colours theorem) still somewhat disputed because it is so hard to verify?
16:22:35 <Pseudonym> Not really.  It's been simplified (still machine-proven, though) and re-checked enough times.
16:22:38 <sieni> EvilTerran: yes, the same "abuse" of the pigeon hole principle :-)
16:22:45 <Pseudonym> Using different theorem provers on different hardware.
16:23:06 <Pseudonym> There's still something a little but wrong about it, but nobody doubts that the theorem has been proven.
16:24:02 <phobes> Pseudonym:  The statement has been proven using a theorem prover from axioms?
16:24:19 <olsner> argh, Adjuctions 1 is broken
16:24:23 <mrd> i'm much happier with machine proofs than human proofs.  i don't trust myself as a proof checker.
16:24:37 <Pseudonym> phobes: Not in the Russell and Whitehead sense, obviously.
16:24:39 <LoganCapaldo> I cheated and looked at the source of Writer
16:24:39 <phobes> Originally the exhaustive search was accompanied by a large paper proof that the search would determine the answer, I think
16:24:45 <LoganCapaldo> I'm glad I did
16:24:52 <LoganCapaldo> I was this close to doing it wrong
16:25:00 <phobes> Pseudonym:  But in ZFC or something?
16:25:03 * LoganCapaldo holds fingers together slightly seperated
16:25:37 <Pseudonym> phobes: No, some standard theorems of graph theory were accepted as given.
16:26:16 <ddarius> LoganCapaldo: Are they together or separated?! Make up your mind!
16:26:28 <LoganCapaldo> lol
16:26:31 <ddarius> LoganCapaldo: How are you sure that what you did would've been wrong?
16:26:40 <phobes> According to wikipedia, efficient 4-coloring algorithms exist ... makes it seem pretty plausible :)
16:26:46 <LoganCapaldo> It woulda been too strict I believe
16:26:55 <LoganCapaldo> I was about to write it pretty much just like State
16:27:04 <Pseudonym> phobes: There are plenty of algorithms where their proof of correctness is long and hard.
16:27:07 <LoganCapaldo> \w -> (a, w)
16:27:15 <phobes> Pseudonym:  I know
16:27:15 <olsner> if you didn't even know you were wrong then, how do you know you're right now?
16:27:32 <ddarius> LoganCapaldo: Okay, I agree with you.  That would've been wrong.
16:28:00 <Pseudonym> phobes: Just about any nontrivial linear algebra algorithm, for example.
16:28:28 <phobes> Pseudonym:  In floating point?
16:28:30 <dons> http://programming.reddit.com/info/2rf0r/comments
16:28:31 <lambdabot> Title: Solving the "word numbers" problem in Haskell: part 3 (reddit.com)
16:28:43 <phobes> Proving anything about floating point accuracy is a nightmare
16:28:44 <Pseudonym> Actually, that's a good point, phbes.
16:28:46 <Pseudonym> Right.
16:28:56 <Pseudonym> Proving stability in IEEE-754 is hard.
16:29:02 <Pseudonym> Even if the algorithm is simple.
16:29:04 <dons> the best thing about working at galois: espresso machine and giradelli hot chocolate on tap
16:29:11 <ddarius> dons: Yeah, I saw part 2 and 3 on planet.haskell.org.  They're cute.
16:29:14 <Pseudonym> dons: Mmmm... Ghiardelli...
16:29:16 <dons> using haskell also is a nice aspect
16:29:27 <Pseudonym> Is it a decent espresso machine?
16:29:39 * Pseudonym has had bad luck with most of them
16:29:40 <dons> Pseudonym: though we've Schaffen-Berger hot chocolate at home, which I consider superior
16:29:55 <Pseudonym> Vicnet bought a reconditioned ex-cafe model.
16:29:56 <dons> it does a pretty good job, but its getting some heavy use. we'll need a bigger one i think..
16:30:10 <Pseudonym> It cost $3000 or so, but it was worth it.
16:30:16 <dons> heh
16:30:20 <sorear> phobes: Gonthier wrote a search, and then proved that the search would succeed.  the Calculus of Constructions has sufficient expressive power to combine them itself
16:30:21 <dons> you only live once
16:30:37 <dons> so hack haskell and drink espresso
16:31:01 * Pseudonym is actually doing real Galois theory in Haskell at the moment
16:31:03 <phobes> sorear:  I don't doubt it.... has it been proven though?
16:31:15 <wootles> haskell is so nice for maths
16:31:21 <dons> sjanssen: you should do an internship here... :)
16:32:13 <sorear> phobes: if by proven you mean that the CIC type (forall x : map, fourcolorable (graphof x)) is inhabited, than yes
16:32:16 <sorear> uh
16:32:18 <sorear> then
16:32:23 <sorear> @slap sorear
16:32:23 <lambdabot> why on earth would I slap sorear
16:32:28 <nominolo> dons, i found the problem
16:32:31 <dons> oh?
16:32:33 <pchiusano> hello
16:32:42 <nominolo> dons, i had to use a loop
16:32:57 <phobes> sorear:  cool
16:33:09 <LoganCapaldo> I haven't had espresso in a while...
16:33:29 <nominolo> dons, i had two threads with sum $ map doSth [1..bigNumber]
16:33:39 <dons> ok?
16:33:41 <nominolo> dons, that didn't scale
16:33:44 <dons> ah
16:33:48 <nominolo> transforming it to a loop worked
16:34:49 <nominolo> an _equivalent_ loop, that is
16:34:49 <nominolo> i assume it was some GC problem
16:34:49 <nominolo> ie, only one GC thread, means only single-threaded allocation
16:34:49 <pchiusano> if I have something like: map readFile filenames, that gives a list [IO String]
16:34:49 <pchiusano> if I want to get an IO [String] from that...
16:34:49 <pchiusano> how do I do it
16:34:49 <pchiusano> > 1 + 1
16:34:49 <lambdabot>  2
16:35:20 <xerox> pchiusano: sequence
16:35:26 <pchiusano> sorry, got cut off..
16:35:29 <xerox> pchiusano: or use mapM in first place
16:35:29 <pchiusano> did somebody
16:35:49 <pchiusano> is mapM = sequence . map
16:35:55 <nominolo> dons, do you think this is worth a bug report ?
16:36:20 <LoganCapaldo> @src mapM
16:36:20 <lambdabot> mapM f as = sequence (map f as)
16:36:20 <xerox> pchiusano: yeah, (sequence .) . map
16:36:39 <sorear> nominolo: there is no allocation lock...
16:36:52 <Pseudonym> Personal opinion, this is more clear:
16:36:56 <Pseudonym> mapM f = sequence . map f
16:36:57 <sorear> nominolo: and sum/map/[..] should have fused
16:37:04 <Pseudonym> :t mapM
16:37:06 <lambdabot> forall a (m :: * -> *) b. (Monad m) => (a -> m b) -> [a] -> m [b]
16:37:09 <nominolo> sorear, i know, but it didn't
16:37:17 <Pseudonym> ?free mapM :: (a -> M b) -> [a] -> M [b]
16:37:18 <lambdabot> $map_M g . h = k . f => $map_M ($map g) . mapM h = mapM k . $map f
16:37:58 <Pseudonym> For $map_M, read fmap
16:38:04 * Pseudonym should probably fix that
16:38:05 <dolio> @type fmap sequence . map
16:38:07 <lambdabot> forall (m :: * -> *) a a1. (Monad m) => (a1 -> m a) -> [a1] -> m [a]
16:39:25 <balodja> dons: Hi. I want lambdabot to support recoding features for irc messages, nicks and channels. By now I have some patches to Plugin/IRC.hs(and some adjoining plugins), that gives general functionality. But they are based on the use of gnu iconv library(through cabal package iconv-0.3). Are you interested in them? Or should I use for this purpose something like recently announced encoding-0.1?
16:39:26 <xerox> (.) = fmap :)
16:40:10 <dolio> @type fmap sequence `fmap` fmap -- :)
16:40:11 <pchiusano> okay, thx
16:40:12 <lambdabot> forall (m :: * -> *) a a1. (Monad m) => (a1 -> m a) -> [a1] -> m [a]
16:40:26 <wootles> I've been coding c/c++ for 9 years, discovered haskell yesterday and I'm already amazed
16:40:40 <LoganCapaldo> dolio: I hate you :)
16:40:52 <hpaste>  nominolo pasted "non-scaling code" at http://hpaste.org/2820
16:40:59 <nominolo> sorear, ^^
16:41:00 <Pseudonym> wootles: Woo!
16:41:06 <dibblego> wootles, welcome :)
16:41:07 <LoganCapaldo> (that was a joke)
16:41:08 <wootles> but how useful is haskell for hacky IO regex stuff  ?
16:41:19 <LoganCapaldo> (in case the smiley wasn't strong enough)
16:41:36 <Japsu> i√§ i√§, regex fhtagn
16:41:45 <Pseudonym> wootles: Arguably, more useful than C++.
16:41:54 <ddarius> Pseudonym: Argubly?
16:41:55 <wootles> yes, c++ was horrible for that
16:42:06 <Pseudonym> ddarius: Boost makes many things nicer.
16:42:14 <sorear> nominolo: how do you know that one scales and the other doesn't
16:42:15 <sorear> ?
16:42:24 <Pseudonym> But it's still not pretty.
16:42:28 <nominolo> sorear, i look at my cpu monitor
16:42:32 <sorear> @remember Japsu i√§ i√§, regex fhtagn
16:42:33 <lambdabot> Done.
16:42:36 <Japsu> <3
16:42:37 <wootles> for instance, say i have a matrix in the form {{1,2},{3,4}} , and i want to make it into latex
16:42:45 <sorear> nominolo: and what does it tell you?
16:42:46 <nominolo> sorear, for one it goes up fully, for the other it stays at 50%
16:42:58 <Pseudonym> wootles: Have you used Spirit?
16:42:58 <LoganCapaldo> wootles: parsec!
16:42:59 <nominolo> on a dual-core machine
16:43:02 <olsner> Japsu: what was that?
16:43:02 <wootles> but i actually have ten 10x10 ones in a file, and want to script the process... what would you use ?
16:43:05 <Pseudonym> If so, you'll LOVE Parsec.
16:43:11 <Japsu> what was which?
16:43:11 <Pseudonym> And you'll get it really quickly.
16:43:20 <Pseudonym> Parsec is MUCH easier to use than Spirit.
16:43:21 <ddarius> If not, you'll -still- LOVE Parsec.
16:43:21 <wootles> i have used: QBasic, c, c++ , lol
16:43:22 <sorear> nominolo: you're looking at something completely different
16:43:25 <geezusfreeek> <3 parsec
16:43:27 <olsner> Japsu: "i‰ i‰, regex fhtagn"
16:43:31 <sorear> nominolo: that has nothing to do with GC
16:43:32 <Pseudonym> wootles: Spirit is a Boost library.
16:43:33 <Japsu> ;D
16:43:40 <nominolo> sorear, why not?
16:43:43 <sorear> nominolo: that's full laziness at work
16:43:44 <Japsu> olsner: have you read about the cthulhu mythos?
16:44:01 <Japsu> the original goes "i√§ i√§, cthulhu fhtagn"... I just s/cthulhu/regex/
16:44:14 <olsner> about it, yeah... is it some kind of cthulhu chant?
16:44:18 <wootles> what is parsec then ?
16:44:19 <nominolo> sorear, you mean the thread doesn't run?
16:44:22 <Japsu> something like that
16:44:24 <sorear> nominolo: sum [1..big] is lifted out as qdm3293 = sum [1..whatever]; worker' = print qdm3293
16:44:25 <ddarius> @where parsec
16:44:25 <lambdabot> http://www.cs.ruu.nl/~daan/parsec.html
16:44:29 <LoganCapaldo> parsec is magic :)
16:44:36 <Pseudonym> No, it's not magic.
16:44:39 <sorear> nominolo: so you have two threads which evaluate the same CAF
16:44:42 <Pseudonym> There's no magic in Parsec.
16:44:51 <LoganCapaldo> it makes me want to try and rewrite all computer programs as parsers
16:44:52 <olsner> just sufficiently advanced technology
16:44:55 <sorear> nominolo: and to avoid wasting joules, the runtime puts one to sleep
16:44:58 <Pseudonym> olsner: Precisely.
16:45:03 <ddarius> With the new Parsec you can parameterize it with magic!
16:45:15 <nominolo> sorear, d'oh.  so i should have used a parameter
16:45:18 <LoganCapaldo> would "parsec is magical" offend your sensibilities less?
16:45:19 <Pseudonym> unsafePerformMagic@
16:45:20 <Pseudonym> unsafePerformMagic#
16:45:28 <nominolo> damn simplified test cases!!
16:45:30 <LoganCapaldo> Or am I just not allowed to use that adjective and friends
16:46:03 <Pseudonym> Parsec probably isn't magical for me because I understand it.
16:46:17 <Pseudonym> Stuff that I don't understand are magic.
16:46:23 <wootles> what's IO in haskell like ? doesn't IO clash with the functional programming thing in general ?
16:46:23 <LoganCapaldo> I'm pretty sure I understand it too
16:46:25 <Pseudonym> s/are/is/
16:46:31 <nominolo> sorear, thanks a lot for clarifying this
16:46:32 <Pseudonym> wootles: No!
16:46:40 <Pseudonym> wootles: IO in Haskell is pure functional.
16:46:49 <nominolo> sorear++
16:46:51 <dolio> Parsec is just a more efficient variation on 'StateT [a] [] b' (or something about like that). :)
16:46:52 <Pseudonym> Now that IS magic.
16:47:21 <ddarius> Pseudonym: You don't understand IO in Haskell or StateT [a] [] b?
16:47:25 <Pseudonym> wootles: There are these things that are spelled "monad" but pronounced "warm fuzzy thing".
16:47:52 <Philippa_> dolio: where the whole deal with try is a big thing
16:47:53 <wootles> you mean gonads?
16:47:55 <Pseudonym> ddarius: Not understanding it is a sufficient but not necessary condition.
16:48:03 <Pseudonym> wootles: No, warm fuzzy things>
16:48:07 <wootles> :)
16:48:21 <LoganCapaldo> @quote gonad
16:48:22 <lambdabot> No quotes match. Where did you learn to type?
16:48:29 <LoganCapaldo> I thought there was at least one
16:48:30 <Pseudonym> Monads are what make Haskell useful.
16:48:37 * ddarius is -not- going to make the comment that came into his head.
16:48:40 <Pseudonym> As opposed to merely elegant.
16:51:35 <nominolo> calling a monad "warm fuzzy thing" is like calling a flower "colourful  fragrant thing"
16:51:52 <nominolo> pretty oximoronic
16:52:08 <olsner> wow... those word numbers and sigfpe's antidiagonal tricks really got me thirsty for abstract algebra
16:52:08 <nominolo> *oxymoronic
16:52:25 <Pseudonym> olsner: Drink away.
16:52:50 <ddarius> @google Robert Ash Abstract Algebra
16:52:50 <Pseudonym> nominolo: Have you read the "hair shirt" paper?
16:52:52 <lambdabot> http://www.math.uiuc.edu/~r-ash/
16:52:52 <lambdabot> Title: Home Page of Robert B. Ash
16:53:06 <ddarius> @wn oxymoron
16:53:09 <lambdabot> *** "oxymoron" wn "WordNet (r) 2.0"
16:53:09 <lambdabot> oxymoron
16:53:09 <lambdabot>      n : conjoining contradictory terms (as in `deafening silence')
16:53:09 <lambdabot>      [also: {oxymora} (pl)]
16:53:22 <Pseudonym> Yes, it's not an oxymoron.
16:53:28 * ddarius 's point.
16:54:04 <ddarius> "oxymora"  I want to see that used seriously.
16:54:27 <Pseudonym> It does raise the question as to whether or not an oxymoron can contain only one term.
16:54:39 <Pseudonym> The legal term "brief" has been posited as an example.
16:54:42 <nominolo> Pseudonym, no
16:54:46 <nominolo> Pseudonym, should I ?
16:54:52 <ddarius> Yes!
16:55:03 <nominolo> hm, what's the opposite of oxymoron?
16:55:08 <ddarius> @where hair shirt would be cute
16:55:08 <Pseudonym> deoxymoron!
16:55:08 <lambdabot> I know nothing about hair.
16:55:23 <ddarius> @where hairshirt
16:55:24 <lambdabot> I know nothing about hairshirt.
16:55:29 * Pseudonym has hung around with chemists too much
16:55:34 <Pseudonym> nominolo: Yes, definitely.
16:55:40 <ddarius> @where+ hairshirt http://research.microsoft.com/~simonpj/papers/haskell-retrospective/
16:55:40 <lambdabot> Done.
16:56:13 <nominolo> ah, the haskell-history
16:56:17 <nominolo> Pseudonym, yes, i read that
16:56:26 <nominolo> just didn't know it by that name
16:57:00 <Saizan> uh, haskell is 1 year younger than me
16:57:14 <sorear> haskell is 3 years older than me!
16:57:15 <nominolo> Pseudonym, but even though Simon Says It (tm) doesn't mean i agree
16:57:28 <nominolo> :)
16:58:13 <nominolo> haskell can't drink alcohol, yet.  well, maybe beer in most of Europe...
16:58:37 <Pseudonym> It can in Australia.
16:58:59 <ddarius> And now we understand the relatively low presence of Haskell in America.
16:59:24 <dons> lambdabot has 19 hackage deps now :)
16:59:29 <wootles> won't functional programming become a lot more popular as all PCs become multi-core ?
16:59:37 <dons> wootles: that's the theory.
16:59:49 <ddarius> wootles: In practice it's becoming more popular regardless.
16:59:57 <nominolo> heh
17:00:32 <wootles> multi-processor in C++ was horrible ...
17:01:25 <nominolo> is seminearring a real word?
17:01:34 <nominolo> i know "semiring"
17:01:40 <nominolo> but semi-near-ring?
17:02:04 <sorear> wootles: it's easier, sure, but it's far from a panacea
17:03:03 * sorear gets really peeved by the fully automatic parallelism ranters and wishes we'd stick to facts for advocacy
17:03:32 <nominolo> sorear, who are you referring to?
17:03:33 <wootles> if there are no side-effects, the compiler can slice the program into as many threads as it wants ?
17:03:46 <nominolo> wootles, no, data dependencies matter
17:03:51 <dons> sorear: is anyone doing the automatic parallel advocacy?
17:03:56 <dons> i don't think any haskeller is.
17:04:06 <dons> but people seem to _infer_ it from stuff about DPH and so on
17:04:09 <sorear> dons: no names, but there are common threads in people's misconceptions
17:04:11 <dons> or its some kind of folklore
17:04:12 <nominolo> wootles, and threads are too heavyweight
17:04:26 <Pseudonym> OK, the antonym of "oxymoron" is "authemoron".
17:04:28 <dons> definitely, this misconceptoin that say, foldl is magically parallel, keeps coming up
17:04:35 <dons> i'm not sure where that comes from though
17:04:40 <dons> its just a interwebs meme
17:04:41 <Pseudonym> oxy = sharp, moron = foolish
17:04:43 <Pseudonym> authe = blunt
17:04:51 <Pseudonym> So there you go.
17:05:04 <sorear> wootles: no, because it's not possible for a compiler to tell the difference between 2 + 2 and largestPrimeSmallerThan 1000000000
17:05:04 <nominolo> dons, C# and Erlang have parallel maps and folds
17:05:23 <nominolo> dons, same for google's map/reduce
17:05:31 <dons> yeah, so does haskell, but its not the default that all combinators are parallel by default and magic
17:05:35 <sorear> wootles: you'd want the second to be forked, but not the first - so you still need annotations if you want a halfway decent job
17:05:44 <wootles> couldnt you use profiling ?
17:05:59 <Pseudonym> "oxymoron" literally means "pointedly foolish".
17:06:05 <Pseudonym> And it's a rhetorical term.
17:06:07 <dons> :t Control.Parallel.Strategies.parMap
17:06:09 <lambdabot> forall b a. Strategy b -> (a -> b) -> [a] -> [b]
17:06:26 <Pseudonym> "authemoron" means saying something contradictory, but in a dumb way, rather than in a smart way.
17:06:34 * Pseudonym will use that word in conversation from now on
17:06:52 <dons> nominolo: the misconception is that every single line of code you write in these languages is somehow magically parallel
17:07:22 <dons> of course, [:x * y | x <- xs | y <- ys:] is rather nice syntax...
17:07:36 <Pseudonym> Oh, now THIS is interesting.
17:07:40 <dons> suck that up C# PLINQ.. :)
17:07:44 <Pseudonym> The word "moron" is literally a black mulberry.
17:07:58 <Pseudonym> Apparently black mulberries grow in clusters, as do idiots.
17:08:04 <idnar> bwahahahah
17:08:06 <idnar> that's awesome
17:08:55 <nominolo> Pseudonym, i guess what i meant was "synonymous". but that just sounds half as elaborately chosen as "oxymoronic"
17:09:13 <nominolo> Pseudonym, too bad it meant the opposite ;)
17:10:33 <nominolo> dons, C# also has "delegate" instead of "lambda" or "\"
17:11:07 <dons> how bizarre
17:11:11 <wootles> has anyone written chess-like AI engines in haskell? how well does that work out ?
17:11:21 <Pseudonym> wootles: Surprisingly well.
17:11:22 <dons> though at least java 7 has this {int x} => x + 1 syntax
17:11:24 <LoganCapaldo> delegate makes it sound OO :)
17:11:30 <Pseudonym> A neat thing about Haskell is lazy evaluation.
17:11:31 <dons> or something like that
17:11:39 <Pseudonym> It means you can explicitly construct a game tree.
17:11:41 <wootles> i dont like C#, they took my const ...
17:11:45 <Pseudonym> And just evaluate the bits of it that you need.
17:11:56 <nominolo> "Thus the word oxymoron is itself an oxymoron." <- nice
17:11:58 <LoganCapaldo> then you should love haskell, everything is const :)
17:12:15 <Pseudonym> wootles: Having said that, you might like this paper.
17:12:17 <Pseudonym> http://okmij.org/ftp/Computation/monads.html#LogicT
17:12:17 <lambdabot> Title: Monads
17:12:28 <Pseudonym> You may not understand it, but there's code there for game playing.
17:13:28 <wootles> why would you want backtracking?
17:13:39 <dolio> There's a library based on that paper, too, so you don't have to type it all in yourself.
17:13:56 <LoganCapaldo> because acktracking is cool
17:14:14 <dibblego> wootles, I use backtracking a lot; for my specific work
17:14:18 <ddarius> C# 3.0 which -does- exist uses something like int x => x + 1
17:14:26 <dibblego> wootles, have you ever studied dynamic programming algorithms?
17:14:45 <dibblego> Scala is: (x: int) => x + 1
17:14:50 <dibblego> or just  _ + 1
17:14:56 <dibblego> i.e. point-free
17:14:57 * ddarius likes readonly variables
17:15:14 <wootles> i think the closest i have come to dynamic programming was a tranposition table in an othello AI
17:15:17 <wootles> it wasnt pretty ...
17:16:42 <nominolo> othello = reversi, right?
17:16:46 <ddarius> Yes.
17:17:09 * ddarius however was, for some reason, thinking backgammon before.
17:18:06 <nominolo> i think there's a chapter in norvigs "Paradigms of AI Programming" on a Reversi/Othello AI
17:19:22 <wootles> the problem is that while the minimax algorithms typically evaluate a position and return a value, it's desirable for analysis to extract the principal variation too... but there is no good way to do that
17:19:27 <kyevan> Is there one on Go?
17:19:41 * ddarius starts watching 40 minutes of bliss.
17:19:53 <nominolo> kyevan, go is too hard, i guess
17:20:08 <kyevan> Go's easy, if you don't want to play well :P
17:20:39 <nominolo> with that one-chapter program you can beat most humans
17:21:15 <wootles> if you try to keep track of the principal variation as you go, you'd have to store it in every transposition table entry (waste of memory) ... but it isn't possible to reconstruct it from the node values, because there are too many nodes to keep them all in memory (typically use a lazy hash table)
17:21:46 <dibblego> we call 'lazy hash tables', "memoization" around here
17:21:55 <dibblego> @where memo
17:21:56 <lambdabot> I know nothing about memo.
17:21:57 <nominolo> @go "principal variation"
17:21:59 <lambdabot> http://www.seanet.com/~brucemo/topics/pvs.htm
17:21:59 <lambdabot> Title: Principal Variation Search
17:22:00 <dibblego> @where memoization
17:22:01 <lambdabot> I know nothing about memoization.
17:22:08 <wootles> by lazy, i mean that if there is a collision, it just gives up and doesnt bother with the new record
17:22:27 <wootles> because it's more effort to start resolving collisions than the extra record will typically save
17:23:02 <kyevan> nominolo: Playing just better than random is better than most humans, at go :P)
17:23:05 <dibblego> memoization :)
17:23:40 <wootles> not to mention, the hash table is almost instantly swamped, and collision resolution at 95% load isnt feasible
17:23:42 <dibblego> @where+ memoization https://research.microsoft.com/users/simonpj/Papers/weak.htm
17:23:43 <lambdabot> Done.
17:23:48 <nominolo> wootless, with lazy programming you can specify the search space and the code to filter out some stuff separately
17:23:50 <dibblego> @where+ memoisation https://research.microsoft.com/users/simonpj/Papers/weak.htm
17:23:51 <lambdabot> Done.
17:23:56 <dibblego> @where+ memo https://research.microsoft.com/users/simonpj/Papers/weak.htm
17:23:57 <lambdabot> Done.
17:24:26 <nominolo> @where momo
17:24:26 <lambdabot> I know nothing about momo.
17:25:12 <Pseudonym> ?where pomo
17:25:12 <lambdabot> I know nothing about pomo.
17:26:02 <wootles> this font is bad.. there is just one pixel between you asking about pomo and porno
17:26:24 <LoganCapaldo> mmm pomo
17:26:30 <nominolo> that's written pr0n, anyways
17:26:31 <LoganCapaldo> what's pomo?
17:26:39 <nominolo> pomodori?
17:26:43 <JohnnyL> searching...
17:26:50 <wootles> postmodernism i thought
17:27:54 <wootles> http://www.arn.org/docs/johnson/sokal.htm
17:27:57 <lambdabot> Title: Pomo Science: Johnson, Phillip
17:28:21 <kyevan> @where porno
17:28:21 <lambdabot> I know nothing about porno.
17:28:30 <nominolo> @where pl0n
17:28:30 <lambdabot> I know nothing about pl0n.
17:28:32 <nominolo> @where pr0n
17:28:33 <lambdabot> I know nothing about pr0n.
17:28:34 <kyevan> ... Lambdabot leads a sheltered life, eh?
17:28:52 <nominolo> well, lambdabot is a girl after all ...
17:29:07 <lambdabot> I know lots about romance novels.
17:29:20 <nominolo> @hug lambdabot
17:29:20 <lambdabot> http://hackage.haskell.org/trac/ghc/newticket?type=bug
17:29:30 <nominolo> lol
17:29:40 <nominolo> ?hug lambdabot
17:29:40 <lambdabot> http://hackage.haskell.org/trac/ghc/newticket?type=bug
17:29:51 <nominolo> stupido!
17:30:06 <wootles> rejected by lamdabot
17:30:08 <michael> @bug lambdabot
17:30:09 <lambdabot> http://hackage.haskell.org/trac/ghc/newticket?type=bug
17:30:50 <lambdabot> No getting fresh OK?
17:30:52 <nominolo> @seen syntaxninja
17:30:52 <lambdabot> I saw syntaxninja leaving #haskell 2d 4h 46m 1s ago, and .
17:31:00 <Pseudonym> ?vixen Do you like hugs?
17:31:00 <lambdabot> i'd say i like
17:31:05 <Pseudonym> ?vixen How about bugs?
17:31:05 <lambdabot> no
17:31:13 <Pseudonym> ?vixen Fair enough.
17:31:13 <lambdabot> I'm stroking my hard cock as we speak...
17:31:19 <Pseudonym> Er...
17:31:21 <nominolo> O_o
17:31:22 <kyevan> o.O
17:31:46 <nominolo> ?vixen wtf?
17:31:47 <lambdabot> no
17:31:56 <nominolo> ?vixen wtf?!
17:31:56 <lambdabot> whoa whoa whoa, one question at a time!
17:32:00 <kyevan> Does... she normaly do that?
17:32:19 <lambdabot> Vixen isn't actually me, just a plugin.
17:32:40 <lambdabot> I'm a little worried about vixen to be honest.
17:32:47 <kyevan> Oh, so you're insane.
17:33:11 <lambdabot> Not so much insane as occasionally posessed.
17:33:14 <kyevan> Multiple-personality disorder, or something.
17:33:30 <nominolo> @girl
17:33:30 <lambdabot> LOL
17:33:35 <nominolo> @girl
17:33:35 <lambdabot> nobody can catch me
17:33:38 <dons> ?uptime
17:33:39 <lambdabot> uptime: 1d 6h 26m 24s, longest uptime: 1m 10d 23h 44m 29s
17:33:56 <dons> i have 4 projects in 4 different rcs' currently active :/
17:34:00 <lambdabot> Vixen is no more me than keal is.
17:34:07 <dons> cvs, svn, git and lots of darcs. what a world.
17:34:48 <nominolo> dons, say, is syntaxninja in the same building you are?
17:35:03 <sjanssen> dons: does Galois use all of those?
17:35:22 <dons> sjanssen: not cvs, afaik (though probably some cvs lurks around here ...)
17:36:13 <dons> nominolo: yeah, he's next to me, as is glguy, and iavor diatchki and andy gill
17:36:29 <olsner> sounds like that environment is ripe for a glue script that autodetects the version control metadata in the current directory and does the right thing
17:36:34 <dons> and elliottt now too!
17:37:52 <dons> sjanssen: and a slowly growing xmonad user base here
17:37:53 <balodja> dons: So what do you think about recoding?
17:37:55 <nominolo> dons, ok.  then, could you kindly ask him for me if he has any comments on that mail i sent him?  not right now, but maybe in a spare minute or sth
17:38:06 <dons> ok. he's just headed home, i think.
17:38:18 <dons> so you mightn't catch him till tomorrow
17:38:24 <dons> balodja: recoding what?
17:38:28 <dons> a revision control system? :)
17:38:29 <nominolo> dons, thanks a lot, no problem
17:38:32 <balodja> Oh.
17:38:35 <balodja> dons: 1 sec
17:39:00 <balodja> < balodja> dons: Hi. I want lambdabot to support recoding features for irc messages, nicks and channels. By now I have some patches to Plugin/IRC.hs(and some adjoining plugins), that gives general functionality. But they are based on the use of gnu iconv library(through cabal package iconv-0.3). Are you interested in them? Or should I use for this purpose something like recently announced encoding-0.1?
17:39:09 <dons> oh, i didn't see that.
17:39:28 <dons> `recoding features' ?
17:39:34 <dons> translating them to jabber or something?
17:39:43 <dons> or just encoding in different ways?
17:40:03 <dons> you can submit patches if they don't break lambdabot, and add features you need :)
17:40:04 <balodja> No-no, that's impossible for me :) I'm talking about charsets
17:40:10 <dons> yeah, i see.
17:40:12 <dons> seems reasonable
17:40:28 <Saizan> i want to test a binding with ghci, how can i get it to link the .o with compiled C code when loading the module?
17:40:47 <dons> ghci Foo.o iirc
17:40:59 <balodja> But this patches will add dependencies on gnu iconv anyway
17:41:06 <dons> oh i see. hmm
17:41:17 <dons> but its cabalised and on hackage?
17:41:20 <dons> the iconv lib?
17:41:36 <balodja> yep. iconv lib
17:41:38 <dons> adding new hackage dependencies are ok, and we can probably assume iconv.h is on most systems
17:41:47 <Saizan> dons: thanks, didn't expect to be this simple
17:44:52 <ddarius> iconv.h is on most systems?
17:45:17 <dons> kolmodin: this is what aja said about the .NET bridge:
17:45:18 <dons> > At this stage I don't have a tool to generate the bindings and type
17:45:18 <dons> > mapping on the Haskell side, so it's not yet ready for any users.
17:45:18 <dons> > Once I have the generator going I expect it could be used in some
17:45:18 <lambdabot>  Parse error
17:45:19 <lambdabot>  Parse error
17:45:19 <lambdabot>  Parse error
17:45:19 <dons> > projects
17:45:20 <lambdabot>   Not in scope: `projects'
17:45:24 <dons> and that's what lambdabot said
17:46:00 <nominolo> > what error?
17:46:01 <lambdabot>   parse error on input `}'
17:46:28 <kyevan> I want a haskell -> CLR compiler.
17:46:40 <kyevan> (Because then you could use haskell to program client-side web apps :P)
17:46:59 * ddarius wonders what was wrong with dons' third line.
17:48:04 <ddarius> Ah, 'in'
17:48:36 <ddarius> Back to videos.
17:50:46 <dibblego> kyevan, Yhc is such a compiler last I looked
17:50:55 <dibblego> er, or was it nhc?
17:52:01 <nominolo> probably yhc
17:55:09 <wootles> is there a tool to visualise the structure of a program as a tree ? like debugging
17:55:32 <dons> the module dependencies, you mean?
17:55:39 <wootles> the function calls
17:55:40 <dons> or the execution paths through the code?
17:55:54 <dons> HPC, in ghc head, let's you visual the execution
17:56:03 <dons> you need ghc head, and then compile your program with -fhpc
17:56:13 <dons> and you get pretty graphs, and statistics about what the program does
17:56:54 <dons> you can also run the program with profiling, to get a textfile about it
17:57:03 <dons> others have used 'dotty' to do graphs of module dependencies
17:57:11 <dons> but i'm not sure that's terribly useful
17:57:44 <dons> here's an example HPC coverage trace for xmonad,
17:57:45 <dons>   http://coverage.unsafeperformio.com/xmonad
17:58:04 <Nafai> What's HPC?
17:58:13 <dons> program coverage tracing
17:58:30 <dons> so you can see what paths were actually executed
17:58:35 <dons> and gather statistics about it
17:58:41 <Nafai> Oh nice
17:58:53 <dons> ah, this is a better link,
17:58:55 <dons>   http://coverage.unsafeperformio.com/xmonad/bootshut/hpc_index.html
17:58:56 <lambdabot> http://tinyurl.com/3bud7u
17:59:00 <dons> that's a full xmonad run
17:59:14 <Nafai> Hey shapr!
17:59:24 <dons> so you can see in the config file code that was executed, and which branches weren't
17:59:31 <shapr> hiya Nafai!
17:59:57 <ddarius> dons: What about executing the test suite?
18:00:11 <ddarius> And where is a pretty graph?
18:00:28 <dons> ddarius: no graphs, that's some other tool. (well, there's the graphs of coverage %)
18:00:36 <dons> i've got one somewhere for the testsuite too
18:00:42 <dons> 93% covered, hpc said
18:01:12 <dons> you can even trace execution, http://movies.unsafeperformio.com/hpctpreview2.mov
18:01:25 <dons> this is all andy gill's brilliant work, now in ghc
18:01:44 <dons> it'll revolutionise how we analyse haskell programs completely, i think
18:02:22 <Nafai> dons: So what's the yellow vs green when you look at the source?
18:03:02 <sorear> yellow code is evil, green code is good
18:03:07 <dons> green is always executed, i think. yellow is hmm, never executed. red is bad something.
18:03:14 <dons> always false iirc. but check the hpc homepage
18:03:25 <sorear> @seen andyjgill
18:03:25 <lambdabot> I saw andyjgill leaving #xmonad 2h 46m 21s ago, and .
18:03:27 <sorear> @seen andygill
18:03:28 <lambdabot> I haven't seen andygill.
18:03:28 <Nafai> Cool
18:03:35 <dons> he's home now
18:03:37 <Nafai> For some reason I can't play that movie :(
18:03:53 <dons> and this is in ghc now, so you'll get it with 6.8
18:04:00 <dons> and then any haskell program you can compile and run with -fhpc
18:04:02 <dons> to get this data
18:04:14 <dons> so immediate coverage results for QuickCheck runs, and so forth
18:04:26 <dons> and you can common up statistics from mulitiple runs
18:04:36 <Nafai> That is awesome
18:04:36 <dons> so you can test with QC, the pure bits, then combine that with data from an HUnit run
18:04:45 <dons> to get a complete coverage story for   your program
18:05:00 <dons> you can see from the Config.hs page it even tells you about which parts of static tables were evaluated
18:05:11 <dons> which i hear isn't possible in your average coverage tools from legacy languages
18:05:31 <dons> (i.e. you can see the bindign to exitWith was executed to quit xmonad, by looking at Config.hs)
18:05:57 <dons> and which arguments to functions were never evaluated -- so laziness data
18:06:11 <dons> its a whole new world of information about our programs
18:06:50 <dons> making haskell just that bit more enterprisey :)
18:06:57 <shapr> What's this?
18:07:00 * shapr looks at the link
18:07:04 <dons> hpc
18:07:11 <shapr> oh that's cool!
18:08:11 <shapr> Wow, this movie is awesome! Is that all available now?
18:08:30 <Nafai> I wonder why that movie won't play for me :(
18:08:31 <dons> see, shapr and i are coporate slaves now to haskell, building big enterprise systems, so this kind of thing matters :)
18:08:44 <dons> shapr: the movie is a branhc of hpct, not sure if that's distributed.
18:08:53 <Nafai> dons: Much better than the "enterpise" stuff I do at work :)
18:08:54 <shapr> I'd love to use this.
18:08:54 <dons> ask andy tomorrow
18:09:04 <dons> the hpc stuff otherwise is fully in ghc and just works
18:09:19 <dons> so you get the html visualisation of code paths, and coverage statistics and more
18:09:32 <shapr> impressive
18:10:18 <dons> it's bloody awesome, yeah. add it to the pile of tools we've got: QC, profiling, Catch, type system, and now HPC.
18:10:52 <kyevan> We need to get Haskell on Youtube somehow.
18:10:55 <kyevan> </random>
18:11:02 <byorgey> Don't forget SmallCheck and SparseCheck =)
18:11:11 <dons> yeah, and StrictCheck
18:11:25 <dons> they should all be combined
18:11:40 <byorgey> StrictCheck?
18:12:20 <byorgey> @where strictcheck
18:12:21 <lambdabot> I know nothing about strictcheck.
18:12:33 * byorgey googles
18:13:54 <Pseudonym> There's just no excuse for bugs in your Haskell programs any more.
18:14:07 <kyevan> Pseudonym: Sure there is
18:14:24 <byorgey> like what, "My dog ate QuickCheck?"
18:14:33 <kyevan> What if you're coding an ecosystem simulator?
18:14:42 <monochrom> hahahahaha
18:14:44 * byorgey groans
18:14:50 <Pseudonym> Oh dear.
18:15:13 <monochrom> Oh deer!
18:15:28 <Pseudonym> Someone write the ant screensaver in Haskell.
18:15:31 <monochrom> Do, a deer, a female deer. Ray, a droplet from the sun.
18:15:57 <ricky_clarkson> Doe
18:16:18 <kyevan> Dough, the stuffm that buys the beer! Ray, the guy, who sells the beer!
18:16:18 <ricky_clarkson> Doing a deer, a female deer, is quite illegal.
18:16:34 <Nafai> Cool, that video is cool
18:16:37 <monochrom> Doe = Department of Ecosystem? :)
18:16:52 <monochrom> Hahahahaa
18:17:08 <kyevan> monochrom: No, you're thinking of Minieco.
18:17:23 <kyevan> Minico, I mean
18:17:31 <stepcut> ricky_clarkson: not in all states
18:18:18 <wli> No Haskell books at all at Powell's Cedar Crossing store in PDX. :(
18:18:49 <kyevan> wli: Of course not
18:18:54 <kyevan> It's not Java, now is it?
18:19:22 <kyevan> er, wait
18:19:35 <kyevan> Ruby's the big popular language now. Or was it c#?
18:20:10 <Excedrin> PHP and C# and still a ton of Java
18:20:23 <kyevan> PHP is for losers :P
18:20:25 <ddarius> The "next" mainstream language is going to be (relatively) interesting.
18:20:31 <wli> Apparently not. I've been wandering around seeing which bookstores, if any, carry Haskell books.
18:20:58 <wli> ddarius: How so?
18:20:58 <kyevan> wli: "We can special order one for you" is a common response here >_>
18:21:08 <vagif> Hello. Is there a haskell smtp library ? How do you send emails from haskell ?
18:21:09 <Saizan> one thing i've never understood in CT diagrams: what the notation etaT stands for, and how is that different from Teta? (the eta is subscripted)
18:21:19 <dons> vagif: yes, i believe so. check on hackage
18:21:25 <dons> vagif: pretty sure stepcut wrote one
18:21:29 <vagif> i did, not found
18:21:41 <dons> check on the haskell wiki then under 'Applications and libraries'
18:21:42 <vagif> do you have a link to it ?
18:21:44 <dons> there's definitely one written
18:21:48 <dons> though i'd have to search for it
18:21:49 <Cale> Saizan: http://en.wikipedia.org/wiki/Natural_transformation#Operations_with_natural_transformations
18:21:51 <lambdabot> http://tinyurl.com/umyzp
18:21:55 <dons> stepcut: do you know of an smtp binding?
18:22:09 <notsmack> there's HAppS.Protocols.SMTP, isn't there?
18:22:14 <Cale> Saizan: particularly, that last paragraph
18:22:24 <ddarius> Saizan: Natural transformations are related to polymorhic functions.  So eta :: a -> T a, and eta_A is eta instantiated at A.
18:22:27 <stepcut> dons: there is postmaster
18:22:35 <stepcut> dons: do you want incoming or outgoing mail ?
18:23:02 <ddarius> So Teta is fmap eta and etaT is eta restricted to the type T a -> T (T a)
18:23:03 <dons> stepcut: meet vagif. vagif, stepcut knows.
18:23:04 <wli> kyevan: I've already got such books. The question is whether Haskell's taken off enough to get books on shelves.
18:23:12 * kyevan doesn't get monads >_>
18:23:18 <kyevan> wli: The answer is no.
18:23:27 <Cale> eta T is a natural transformation whose component at X is the component of eta at TX
18:23:29 <dons> kyevan: you can't 'get' monads in general. that only works on MonadState
18:23:53 <kyevan> dons: Huh?
18:23:53 <Cale> If eta: F -> G, then eta T: FT -> GT
18:23:59 <wli> kyevan: Some stores do have Haskell books.
18:24:21 <vagif> stepcut: I need outgoing emails through smtp server
18:24:27 <kyevan> Some stores have books on z80 asm.
18:24:28 <ddarius> *whoosh* The sound of dons' lame joke going over kyevan's head.  Don't worry, it was pretty bad.
18:24:39 <dons> sorry, yeah, it was a shocker
18:24:42 <dons> :t get
18:24:50 <lambdabot> forall (m :: * -> *) s. (MonadState s m) => m s
18:24:57 <Cale> Somewhat dually, T eta is the natural transformation whose component at X is T applied to eta's component at X.
18:24:59 <kyevan> Oh. Heheh.
18:25:03 <dons> :)
18:25:12 <kyevan> I only understand half that though >_>
18:25:14 <wli> ddarius: How is the next mainstream language going to be interesting?
18:25:14 <dons> not so lame afterall, ddarius
18:25:15 <Cale> Saizan: does that make sense?
18:25:29 <ddarius> wli: I was working on an answer, I just keep getting distracted.
18:26:33 <wli> ddarius: Sorry, I thought you didn't see the question.
18:26:46 <ddarius> wli: First off, I said "relatively".  But essentially, it is going to quickly be a lot closer to a "decent" language at the get-go and is going to incorporate many (well, some) things that you'd never thought you'd see in a mainstream language a few years ago.
18:27:01 <ddarius> Compared to "advanced" languages, it's going to be pretty boring still.
18:27:14 <kyevan> ddarius: Ooh, is it going to have lambda?
18:27:19 <ddarius> kyevan: Yes.
18:27:27 <wli> I'm on a Treo so I'm slow.
18:27:36 <kyevan> How do you know what the next mainstream language will be?
18:27:45 * kyevan 's putting money on LOLCODE
18:27:54 <ddarius> kyevan: When did I say I did?
18:27:56 * Cale doesn't care about the "next mainstream language".
18:28:08 <Pseudonym> I do.
18:28:09 <kyevan> ddarius: Will be like, then
18:28:17 <vagif> found haskellnet library. Looks like it has smtp
18:28:18 <Pseudonym> If it's a good one, then I'll be happy to be mainstream.
18:28:32 <ddarius> kyevan: Much the same way I know the sun is going to rise tomorrow.
18:28:50 <ddarius> Pseudonym: Indeed.  C# is actually not too too bad.
18:29:10 <Pseudonym> It's an improvement on Java, I'll grant you that.
18:29:22 <Pseudonym> Though Java was designed so that it could be implemented in microcode.  You can't say that of C#.
18:29:36 * ddarius -always- thought it was an improvement on Java and then it moved quickly (and quickly moved) to being a -big- improvement on Java.
18:30:00 <kyevan> ddarius: That's not saying much, though
18:30:11 <Pseudonym> And, of course, it was designed to run on 1993-era microcode.
18:30:16 <stepcut> vagif: hrm, no idea
18:30:19 <Pseudonym> Which you DEFINITELY can't say of C#.
18:30:26 <kyevan> Reminds me of the sayng "You know, horse shit really does smell sweeter than cow shit."
18:30:30 <ddarius> Pseudonym: Fine by me, it's not 1993 anymore.
18:30:37 <Pseudonym> ddarius: Sure, I'm just saying.
18:30:41 <stepcut> vagif: I just call sendmail -t ;) (which is harder than it sounds)
18:30:48 <Pseudonym> Because everyone knows that if you're just saying, it's okay.
18:31:12 <ricky_clarkson> Other than lambdas, how is C# better as a language than Java?
18:31:26 <vagif> stepcut: i'm on windows
18:31:48 <Cale> ricky_clarkson: Well, there's LINQ :)
18:32:16 <ddarius> properties/readonly variables/autoboxing/operator overloading/...
18:32:28 * kyevan goes through the OO.o setup wizard.
18:32:31 <kyevan> AGAIN
18:32:36 <notsmack> ugh, operator overloading...
18:32:43 <kyevan> Oh, hey, new step.
18:32:46 <sioraiocht> operator overloading is the DEVIL
18:32:58 <ricky_clarkson> I embrace that devil.
18:32:58 <notsmack> and java's done autoboxing for a while, at least in the useful cases
18:33:03 <ricky_clarkson> > let 2+2=5 in 2+2
18:33:09 <kyevan> "I " + "dis" + "agree."
18:33:12 <lambdabot>  5
18:33:13 <sioraiocht> especially when yo can overload += to be the OVERLOADING operator
18:33:32 <ricky_clarkson> Java's had readonly variables all the time.
18:33:42 <notsmack> what's a property in that context?
18:33:45 <ddarius> ricky_clarkson: Like C#'s readonly?
18:33:54 <wootles> is there any way to get automatic memorisation in haskell ?
18:33:54 <ricky_clarkson> ddarius: How does that differ from final?
18:33:55 <kyevan> I want write-only memory.
18:34:04 <dibblego> C# sealed ~= Java final
18:34:12 <dibblego> er, C# readonly ~= Java final
18:34:16 <ddarius> ricky_clarkson: readonly means "single assignment variable"
18:34:22 <ricky_clarkson> Properties I probably agree, I remember liking Delphi's properties.
18:34:31 <dibblego> Java 8 has properties
18:34:32 <kyevan> > let 0^0="nullity" in 0^0
18:34:33 <lambdabot>  "nullity"
18:34:36 <dibblego> it's just called Scala
18:34:38 <ricky_clarkson> ..you can certainly improve on javabeans garbage in Java.
18:34:40 <dibblego> instead of Java 8
18:35:00 <kyevan> What happened to 7?
18:35:01 <kyevan> >_>
18:35:10 <ricky_clarkson> > let 0^0="nullity" in 1^1
18:35:11 <lambdabot>   Non-exhaustive patterns in function ^
18:35:43 <dibblego> kyevan, they're stilling writing poor man's closures there :)
18:36:20 * sjanssen uses diamond-encrusted closuers
18:36:26 <Saizan> Cale: so it's a kind of composition? ( T eta looks like fmap eta to me)
18:36:30 <ricky_clarkson> dibblego: In Java 7?  Are you referring to currying again?
18:36:32 <kyevan> Anyway, there isn't anything Java can do that C# (or any other CLR-targeting language) can't
18:36:36 <kyevan> At least, not soon
18:36:40 <dibblego> ricky_clarkson, no, closures
18:36:41 <Cale> Saizan: yeah
18:36:44 <ricky_clarkson> kyevan: Turing completion?
18:36:47 <byorgey> wootles: didn't you ask that question earlier?
18:36:52 * kyevan pokes MS over silverlight 1.1
18:36:55 <Cale> Saizan: a sort of funny kind of composition though
18:37:21 <ricky_clarkson> dibblego: What's poor about BGGA closures?
18:37:21 <Cale> since you're composing a functor with a natural transformation
18:37:32 <kyevan> ricky_clarkson: There's a BF 'terp in C#. It's turing complete.
18:37:35 <ricky_clarkson> I'm struggling to really spot the difference between them and Haskell's.
18:37:44 <dibblego> ricky_clarkson, many things; including the inability to use point-free style
18:37:46 <Saizan> and they haven't the same domain
18:37:50 <Cale> The important thing to remember is just that if eta: F -> G, then eta T: FT -> GT, and T eta: TF -> TG
18:37:57 <ricky_clarkson> dibblego: That's not part of closures.
18:38:07 <ricky_clarkson> That's sections and/or partial evaluation.
18:38:24 <dibblego> ricky_clarkson, it's part of the proposal
18:38:29 <dibblego> scala> List.range(0, 10).map(_ + 1) // point-free style in Java 42
18:38:29 <dibblego> unnamed1: List[Int] = List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
18:39:23 <ddarius> But a functor can be identified with the identity natural transformation on it and then it is just horizontal composition.
18:39:27 <ricky_clarkson> It's an "open issue" in the proposal as to whether to include it.  Gafter says he has done no work on that.
18:39:53 <dibblego> I think it's a pointless issue, when you can already do that in a language with far better features than Java
18:40:12 <dibblego> i.e. no disadvantages and significant advantages
18:40:32 <kyevan> Does anything other than java have 'applets'?
18:40:33 <ricky_clarkson> So you say that Java 7 will have poor man's closures, then don't say why, name other features and then say the discussion's pointless.
18:40:36 * ddarius needs to figure what key combination that is.
18:40:40 <dibblego> I wonder if I'll be alive the day that Java gets higher-ranked kinds
18:40:44 <ddarius> So T eta is id_T * eta
18:40:55 <ddarius> or maybe the other way around.
18:41:07 <ricky_clarkson> dibblego: This isn't your usual quality of discourse. ;)
18:41:10 <dibblego> ricky_clarkson, the discussion is not pointless; the fact that Java continues to exist is pointless
18:41:32 <dibblego> ricky_clarkson, I didn't know that it was an open issue
18:41:39 <ddarius> kyevan: Does anything other than Java have a system whereby you can download code and execute it?
18:41:51 <ricky_clarkson> dibblego: http://www.javac.info/issues-v05.html
18:41:54 <lambdabot> Title: Closures: Open Issues (v0.5)
18:41:56 * ddarius never really got applets.
18:42:01 <sjanssen> ddarius: flash, javascript?
18:42:06 <ricky_clarkson> ddarius: Neither did users.
18:42:49 <ddarius> sjanssen: My question is rhetorical.  -All- languages allow that.
18:42:56 <dibblego> if Sun are going to make language compatibility changes, then there is no rational technical reason to simply not adopt Scala (or some minor variation of)
18:43:16 <dibblego> continually creeping in fundamental language features just keeps the ridiculous language alive
18:43:20 <ricky_clarkson> dibblego: The current proposal does not break old code.
18:43:21 <sjanssen> s/Scala/Haskell
18:43:22 <ddarius> But yes, Actionscript and Javascript immediately spring to mind and then there are plugins for all kinds of other things.
18:43:45 <dibblego> sjanssen, there are reasons there
18:43:56 <dibblego> ricky_clarkson, they said that last time and the time before
18:44:30 <kyevan> Actionscript is utter horror to run on !windows.
18:44:34 <ricky_clarkson> dibblego: I had one issue moving from 1.4 to 5, I had an accidental dependency on some implementation library that got removed.
18:44:41 * sioraiocht always finds it odd how some variants of English pluralise corporations, etc
18:44:45 <kyevan> (Well, within its environment, anyway)
18:44:47 <ricky_clarkson> dibblego: That's different to having to run a source translator.
18:46:23 <kyevan> Javascript is horror if you want to keep IE happy, and you usually do
18:47:07 <dibblego> the non-existence of language feature X, followed by the existence of X, is a language compatibility change
18:47:50 <sjanssen> dibblego: the changes can certainly be backwards compatible
18:58:08 <sioraiocht> kyevan: want to? or HAVE to =p
19:26:53 --- mode: irc.freenode.net set +o ChanServ
19:27:31 <FMota> geez, crash my IRC client why don't you?
19:27:32 <FMota> is there a Haskell IRC client?
19:27:34 <jammaj> Is there a way to specify a data type that contains a list of 5 things (and exactly 5 things)?
19:27:34 <ddarius> FMota: Yes.
19:27:38 <ddarius> jmob: A five tuple.
19:27:40 <ddarius> ..
19:27:48 <FMota> ddarius: hm?
19:27:57 <jmob> ddarius: you can't really map over a tuple though
19:28:12 <ddarius> FMota: There was at least Hircules.
19:28:22 <FMota> ok, ty
19:29:02 <sjanssen> jmob: there are a few things you can do
19:29:29 <kpreid> jmob: it's not hard to write fmap for it, etc.
19:29:45 <nburlett> can anyone recommend a good way to represent $ ?
19:29:47 <sorear> Is it as good as irssi?
19:29:50 <nburlett> float/double not so great
19:29:53 <sjanssen> there are neat type programming tricks that can guarantee the length of a vector
19:29:55 <sorear> nburlett: 42
19:30:08 <Saizan> ?docs Data.Fixed
19:30:08 <lambdabot> Data.Fixed not available
19:30:21 <ddarius> You could probably use some crazy generic thing to avoid having to do much work.
19:30:22 <nburlett> sorear: yes, I should just have all my bills be $42
19:30:37 <sorear> nburlett: uh, I mean 36
19:30:38 <sjanssen> nburlett: Rational?
19:30:42 <kpreid> jmob: http://homepage.mac.com/kpreid/2007/graph-life/GraphLife.hs uses a fixed 8-element type, Moore
19:31:30 <sorear> pfft, brute force CA is a bad idea when hashlife is so easy :)
19:31:31 <kpreid> sure, it's a bit repetitive, but pick the right typeclasses to instance and you only have to repeat it a few times :)
19:31:32 <nburlett> sjanssen: Rational seems reasonable
19:31:44 <Saizan> nburlett: http://haskell.org/ghc/docs/latest/html/libraries/base/Data-Fixed.html , using a type with resolution 2 probably
19:31:46 <lambdabot> http://tinyurl.com/yqdcrb
19:32:39 <sorear> kpreid: I have three implementations of statically sized tuples floating around as part of my (failed) attempt to make a compulational geometry library
19:32:43 <kpreid> sorear: I ought to look into hashlife ...
19:33:16 <kpreid> that said, this was an exercise in that particular implementation strategy, not a sensible CA system :)
19:34:22 <nburlett> so, what, I do a data E2 and type Money = Fixed E2?
19:34:46 <sorear> kpreid: it's pure, functional, and algebraic.  a perfect fit for Haskell
19:34:50 <Saizan> yes, with the right HasResolution instance
19:35:04 <nburlett> instance HasResolution Money where resolution _ = 2
19:35:20 <jmob> hmm, cool
19:35:45 * nburlett goes to try it
19:40:31 <scsibug> eek...is there some workaround for using Arrow syntax along with Haddock docs?
19:40:45 <sorear> scsibug: uh...
19:40:51 <sorear> scsibug: Arrow is H98
19:40:59 <ddarius> Arrow syntax isn't.
19:41:00 <sorear> scsibug: oh
19:41:03 <ddarius> CPP...
19:41:05 <sorear> scsibug: right, Arrow syntax
19:41:26 <sorear> scsibug: CPP, or upgrade haddock
19:41:37 <scsibug> ah, so it works in the latest haddock?
19:41:51 <ddarius> haddock.ghc uses GHC's parser
19:43:40 <nburlett> hm... now how to construct one of these
19:43:52 <timthelion> I'm trying to write a function which takes a list of lists, and trims out all the null lists. I write it like {trim ([]:xs) = trim xs ; trim (x:xs) = x : trim xs ; trim [] = [] } but what happens if trim got passed []? wouldn't head in the patern ([]:xs) be []?
19:43:53 <FMota> Xd, hi jessie
19:43:58 <FMota> *XD
19:44:00 <jessie_> hello
19:44:24 <ddarius> timthelion: No.
19:44:32 <sjanssen> timthelion: no, []:xs doesn't match []
19:44:45 <ddarius> Also, that function should be just filter (not . null)
19:44:46 <sorear> timthelion: don't you want filter (not.null) ?
19:45:07 <timthelion> that would work too!
19:45:16 <timthelion> my function works though
19:45:34 <ddarius> Your function does indeed work.
19:46:09 <timthelion> yay for obfuscation
19:46:32 <ddarius> timthelion: Now express trim as a fold.
19:46:41 <timthelion> hey!
19:46:59 <timthelion> that's just plain academic
19:48:33 * sorear dons a cape clearly labelled SOREAR, ENEMY OF THE ACADEMIA BASHERS
19:48:51 <sorear> :)
19:48:59 <dibblego> @pl \a b -> if null a then b else a : b
19:49:00 <lambdabot> ap (ap . if' . null) (:)
19:49:32 <mgsloan> I'm trying to instance Num a => Num (a, a), but ghc says "Illegal instance declaration"
19:49:45 <sorear> mgsloan: right, it's illegal
19:49:49 <dolio> @pl \e -> if null e then id else (e:)
19:49:49 <lambdabot> ap (flip if' id . null) (:)
19:49:49 <mgsloan> As an aside, is this a good idea, or should I newtype the tuple?
19:49:53 <mgsloan> why?
19:49:54 * ddarius rephrases a classic question in mathematical form
19:49:54 <timthelion> sorear: right now I'm writting an aplication in bash + tinny haskell string parsing apps and finding this to be by far the easies application dev I've done so far
19:50:06 <sjanssen> mgsloan: turn on flexible instances
19:50:09 <ddarius> Is "enemy of the" involutory?
19:50:18 <sorear> mgsloan: instance heads must be of the form T a b c ..., where T is a type constructor and a,b,c.. are *distinct* type variables
19:50:31 <araujo> hello
19:50:34 <sorear> mgsloan: termination checks and all that fun stuff
19:50:39 <mgsloan> ah..
19:50:45 * sorear throws a delimited continuation at araujo
19:50:49 <ddarius> And yes, you should newtype this.
19:50:57 <mgsloan> think so?
19:51:02 <ddarius> sorear: Using SML's syntax, eh?
19:51:12 <mgsloan> It's pretty cool to treat vectors just as numeric tuples
19:51:33 <mgsloan> (1, 3) + (2, 4) <- that kind of thing
19:51:41 <sorear> mgsloan: Incidentally, if you're using pairs of numbers for the reason I think you are, note that Data.Complex exists
19:51:45 <sorear> ddarius: huh?
19:51:51 <P_D> Eww, a basis.
19:51:52 <ddarius> A new data type would be acceptable (and better probably) as well.
19:52:29 <araujo> haha sorear
19:52:30 <sorear> mgsloan: uh...  what will you do with (a,a,a)? there are no real k-vector spaces with field structure, for k >= 3
19:52:30 <araujo> :-)
19:52:41 <mgsloan> heh, well, I don't need 3D vectors :)
19:52:44 <ddarius> http://www.smlnj.org/doc/SMLofNJ/pages/cont.html
19:52:45 <lambdabot> Title: The CONT signature
19:52:46 <sorear> not entirely sure about rings though
19:53:35 <mgsloan> D2 (1, 3) + D2 (2, 4) is plain uglier
19:53:48 <ddarius> mgs D2 1 3 + D2 2 4
19:53:51 <nburlett> hm.. how do I write a Read instance for one of these Data.Fixed deals?
19:54:02 <P_D> vector spaces are rings and more
19:54:26 <mgsloan> yeah, Num should be definable for all dimension vectors
19:54:36 * nburlett has never written a Read instnace
19:54:39 <ddarius> P_D: What multiplication are you using.
19:54:47 <nburlett> crud.. need to pick up dinner
19:54:56 * mgsloan is using scaling multiplication
19:55:03 <P_D> anything you want
19:55:06 <mgsloan> I suppose if you interpret multiplication as dot product..
19:55:15 <P_D> no, it has to be V X V -> V
19:55:28 <mgsloan> yeah
19:55:31 <mgsloan> so cross product
19:55:36 <P_D> that's only 3 and 7 dimension
19:55:37 <ddarius> P_D: If you do it component-wise then you're good.
19:55:44 <ddarius> wedge/outer product
19:55:46 <P_D> components are for engineers
19:56:09 <P_D> I'm a little confused though
19:56:13 <ddarius> I think so.
19:56:19 <P_D> I thought you had a ring without any additional structure
19:56:23 <coffeemug> man
19:56:25 <sorear> ddarius: oh, you were just taking offense to 'throw'.  haha
19:56:31 <coffeemug> Columbia Uni charges 1500 per credit
19:56:37 <coffeemug> that's rediculous!
19:56:44 <sorear> 1500 USD?
19:56:49 <coffeemug> yes
19:57:00 <coffeemug> oh, sorry, 1200 per credit
19:57:04 <ddarius> P_D: If you extend a vector space to a geometric algebra then you (obviously) have a ring structure (you have an algebra structure!)
19:57:04 <coffeemug> that's still pretty bad
19:57:54 <mgsloan> I guess I'll go to a specific data type..  I also think it'll be cool to be able to do things like D2 (Double -> Double)
19:58:01 <P_D> my mathematical physics book's chart goes only as far as associative algebras -> lie algebras -> vector spaces -> abelian groups -> groups -> sets
19:58:02 <mgsloan> (this would be a parametric path)
19:58:25 <ddarius> But, I don't see any "natural" multiplication (let alone distributive) on two vectors besides component-wise.
19:58:28 <P_D> so rings are off to the side somewhere, but presumably a req for one or both of the algebras
19:58:32 <P_D> yes, I agree
19:58:54 <Syzygy-> P_D: What does -> mean in that list thingie?
19:59:15 <P_D> Like a haskell function, f :: (vector,vector) -> vector
19:59:45 <Syzygy-> Ooooookay. There are MANY more arrows involved in that picture then.
19:59:50 <P_D> Oh
19:59:50 <P_D> sorry
19:59:57 <P_D> THOSE arrows
19:59:59 <P_D> they mean functors
20:00:02 <P_D> forgetful
20:00:16 <Syzygy-> Do you have a forgetful functor from Ass to Lie?
20:00:23 <Syzygy-> And can it really be said to be forgetful?
20:00:41 * sorear does not get lie-foo (yet)
20:00:42 <P_D> yes
20:00:51 <Syzygy-> P_D: How so?
20:01:02 <Syzygy-> sorear: It's not THAT big a deal. :)
20:01:35 <P_D> Um.. you'll have to wait until I read the chapter on associative algebras.  But he definitely says ass are a free construction on lie
20:01:51 <P_D> or directly from the vector space
20:02:00 <Syzygy-> P_D: Ass doesn't have the [,] as an inherent operation. I agree that Ass embeds to Lie, but not that it forgets to it.
20:02:21 <Syzygy-> Going Ass to vectorspace, I would agree with.
20:02:56 * ddarius likes his algebras over modules gosh darn it!
20:03:16 <Syzygy-> ddarius: Sure, you can go R-Mod instead of k-Vect if you care for it.
20:03:40 <Syzygy-> But don't come whining when you discover that computation ends up being difficult.
20:04:06 <P_D> "The covariant functor F 'forgets the symmetric part of the (associative) product of V."
20:04:12 * Syzygy- works on kG-Mod instead of RG-Mod since having a field there makes the ugly and evil Integral Homotopy Theory go away.
20:04:35 * ddarius hugs Smith Normal Form
20:05:03 <Syzygy-> P_D: I still don't really agree with the classification.
20:05:15 <P_D> it sounds like he's a little wishy washy about it too
20:05:19 <Syzygy-> Hang on.... SYMMETRIC?
20:05:21 <P_D> "We shall regard the above functor as forgetful"
20:05:24 <Syzygy-> Is he confusing Ass with Com?
20:06:07 <P_D> no, it's something to do with the identity vv' = (1/2)(vv'+v'v) +(1/2)(vv' - v'v)
20:07:37 <Syzygy-> Yech. This sounds like balancing on your head just because you can.
20:07:45 <Syzygy-> Physics! *shudder*
20:07:54 <P_D> haha
20:07:56 <P_D> it's not what I call physics
20:08:10 <Syzygy-> You said you grabbed it from a math.phys. book.
20:08:17 <P_D> keyword mathematical
20:08:18 <Syzygy-> And it's not algebra the way I'm used to doing it.
20:08:48 <P_D> The book's "example" for physics is the spectral theorem
20:10:10 * ddarius decides to explore the new branch of math called String theory.
20:10:27 <P_D> indeed.
20:10:37 <mgsloan> yeyfor negative probabilities (that's all that I know about it, btw)
20:11:04 <P_D> if somebody has negative probabilities I guarantee you it's just something they're embarassed about
20:11:11 <timthelion> ddarius: I sugest you start by reading "god code" on how string theory explaines the message that god left in our dna for us
20:11:12 <ddarius> Indeed.
20:11:32 <ddarius> (That was re P_D there)
20:13:03 * ddarius views string theory as mathematics being called physics.
20:13:41 <P_D> they argue that they argue with physically inspired methods
20:14:11 <P_D> of course, since it's unobserved, there's nothing physical to inspire them
20:15:12 <mgsloan> actually, I think the negative probabilities were for quantum mechanics
20:15:21 <mgsloan> also allows for probabilities > 1
20:15:32 <P_D> definitely not.  QM is very careful about that
20:15:37 <mgsloan> really, hmm
20:15:47 <P_D> all probabilities are the absolute value of some quantity, and normalized so that 1 is maximum.
20:16:13 <Pseudonym> Erm... not quite.
20:16:19 <P_D> people do get negative probabilities when they try to simulate quantum mechanics, but that's from approximations
20:16:27 <Pseudonym> Quantum probabilities use the 2-norm.
20:16:41 <Pseudonym> You sum the absolute squares of probabilities.
20:16:53 <Pseudonym> So probabilities can be negative.
20:17:15 <P_D> ok, describe to me the experiment?
20:17:23 <sorear> Pseudonym: And imaginary!
20:17:24 <ddarius> amplitude is the thing they then use
20:17:28 <Pseudonym> Yes, and imaginary.
20:17:58 <Pseudonym> P_D: Circularly polarised photon gets split into up-down and left-right polarisation.
20:17:59 <P_D> does Abs not mean Sqrt[zz*]?
20:18:25 <Pseudonym> The probabilities of u-d vs l-r are 1/sqrt 2 and 1/sqrt 2 respectively.
20:18:28 * sorear thinks that the weirdest thing in QM is not, as so many people insist, the uncertainty relations, but rather the fact that complex numbers are more real than real numbers.
20:18:39 <Pseudonym> sorear: Yes, I think that's true.
20:18:48 <ddarius> sorear: Read the work of Hestenes.
20:18:53 <Pseudonym> Right.
20:18:55 <P_D> .. those don't sum to one.
20:19:00 <ddarius> @google Imaginary numbers are not real
20:19:02 <lambdabot> http://www.mrao.cam.ac.uk/~clifford/introduction/intro/intro.html
20:19:03 <lambdabot> Title: Imaginary Numbers are not Real - the Geometric Algebra of Spacetime
20:19:12 <Pseudonym> Every occurrence of a complex number is arguably somethign geometric hiding.
20:19:13 * ddarius finds that title cute.
20:19:27 <Pseudonym> P_D: That's because you take the 2-norm.
20:19:33 <Pseudonym> a.k.a the Euclidean distance.
20:19:38 <Pseudonym> p_1^2 + p_2^2
20:19:41 <Pseudonym> Well.
20:19:46 <Pseudonym> Square of the Euclidean distance, I guess.
20:19:56 <P_D> so you meant amplitudes
20:19:59 <mgsloan> yeah, I intend to have all the L-norms for my Num a => (a, a)
20:20:02 <Pseudonym> I mean the 2-norm.
20:20:18 <Pseudonym> The "amplitude" of a wave is peak-to-peak.
20:20:22 <Pseudonym> Or RMS.
20:20:24 <Pseudonym> Not squared.
20:20:36 <P_D> I mean p1 is an amplitude, not a probability
20:20:41 <Pseudonym> Sure it is.
20:20:46 <P_D> You said probability.
20:20:47 <Pseudonym> It's a quantum probability.
20:20:49 <Pseudonym> Which can be negative.
20:20:52 <Pseudonym> Or complex.
20:21:02 <P_D> Ah
20:21:08 * ddarius says throw out all this "probability" nonsense
20:21:15 <P_D> We civilized physicists call that an AMPLITUDE
20:21:23 <P_D> and probability is reserved for what you're calling the 2-norm of that
20:21:25 <Pseudonym> We information theorists call it a probability.
20:21:59 <P_D> it's not a probability.  it has nothing to do with the frequentist limit.
20:22:08 <Pseudonym> It's not a CLASSICAL probability.
20:22:29 <P_D> moving on now, we understand each other
20:23:07 <Pseudonym> But it's a probability in the sense that it works just like a probability if you start from a slightly different axiom.
20:23:08 <P_D> OK the reason that is really dumb is because the angle is arbitrary
20:23:18 <P_D> You have a symmetry under rotation
20:23:53 <P_D> A negative amplitude is ap ositive amplitude if you rotate your head
20:24:14 <ddarius> "It's just like a probability!!! if you change the definition of probability!!"
20:24:19 <P_D> Hehe
20:25:04 <P_D> What he means though is that it follows an algebra just like regular probabilities
20:25:13 * ddarius knows what he means.
20:26:31 <Pseudonym> The interesting thing about quantum probabilities, though, is that they can have opposite sign.
20:26:40 * ddarius remembers, after a minute of thinking, sigma-algebras.
20:26:45 <P_D> ok be specific
20:26:49 <Pseudonym> If two outcomes have probabilities with opposite sign and equal magnitude, they cancel each other out.
20:26:51 <P_D> are you talking about R or C?
20:26:55 <Pseudonym> Double slit experiment, for example.
20:27:00 <P_D> so you're talking about C
20:27:07 <Pseudonym> Yeah.
20:27:13 <P_D> calling something negative is dishonest IMO
20:27:17 <P_D> in C
20:27:23 <Pseudonym> Probably.
20:27:44 <ddarius> The important thing is the cancellation which can't happen in "classical" probability theory.
20:27:51 <Pseudonym> C is more "real" than R in this sense because every transformation is continuous.
20:28:00 <Pseudonym> Unitary matrices have square roots.
20:28:00 <sorear> ddarius: This looks very promising.
20:28:08 <Pseudonym> So there's always a half-way point between two possibilities.
20:28:20 <ddarius> sorear: Geometric algebra is beautifully pragmatic.
20:28:25 <sorear> ddarius: Geometric algebra smells like tensor calculus without all the icky indices?
20:28:31 <ddarius> sorear: Indeed.
20:28:36 <P_D> you can have sqrts on orthogonal matrices just fine
20:28:40 <ddarius> Not quite, but it can do such things.
20:28:47 <Pseudonym> In much the same way that there being two possible ways for a pancake to lie implies the existence of the third dimension, even though a pancake is 2D (to a first approximation).
20:28:49 <P_D> SO anyway
20:28:51 * mgsloan finds indices relatively impure
20:29:05 <ddarius> sorear: Read about it.  It will make you bitter the way Haskell has (or will).
20:29:06 <Pseudonym> To flip the pancake, you need 3-space at least.
20:29:06 <mgsloan> obscuring, even
20:29:43 <sorear> Pseudonym: You can have non-superimposible pancakes on any orientable 2-manifold ?
20:30:04 <mgsloan> to reverse something you need a 4-space at least
20:30:10 <Pseudonym> Oh, that's an idea.
20:30:27 * Pseudonym should sell Klein bottle-shaped pans
20:30:40 <Pseudonym> That way, you no longer need to flip your pancakes.
20:31:13 * Pseudonym smells a business opportunity
20:31:17 <Pseudonym> Or maybe I just smell food.
20:31:41 <ddarius> Food is a business opportunity.
20:32:56 * ddarius needs some needlenose pliers.
20:44:32 <sorear> > length = foldr (√é¬ª_ n √¢\206\222 1 + n) 0
20:44:33 <lambdabot>  Parse error
20:45:01 <dibblego> why are people writing length with foldr and not foldl?
20:46:33 <ddarius> They shouldn't write it with foldl either.
20:46:54 <dibblego> foldl'
20:47:00 <Olathe> > length [1..]
20:47:04 <lambdabot> Terminated
20:47:13 <ddarius> > genericLength [1..] :: Nat
20:47:14 <lambdabot>   Not in scope: type constructor or class `Nat'
20:47:31 <Pseudonym> Though in theory, the foldr version works better with old-school deforestation.
20:48:15 <Syzygy-> IRC quote that reads quite differently for a #haskell regular: (05:47) ( _llll_) you think |x| doesnt have "shapr corners"?
20:49:38 <ddarius> What does a shapr corner look like?
20:49:49 <Olathe> Ask shapr.
20:50:01 <shapr> Probably full of cushions and has a bunch of monitors in front of it.
20:50:02 <dibblego> one where you can hire a shapr for the night
20:50:10 <shapr> I'm cheap. I'm even easy.
20:51:29 <shapr> But my only real skill is being entertaining at parties.
20:54:55 <shapr> What would a corner decorated in your style look like?
20:54:57 <chessguy> @pl foldr (\_ n -> n + 1) 0
20:54:57 <lambdabot> foldr (const (1 +)) 0
20:55:04 <tuxplorer> do dbconn<-connect "localhost" "Ybot" "ybot" "ypass"; closeStatement(query dbconn "select * from questions")
20:55:05 <tuxplorer> says  Couldn't match expected type `Statement'            against inferred type `IO Statement' What is the mistake?
20:55:19 <chessguy> @type foldr (\_ n -> n + 1) 0
20:55:27 <lambdabot> forall a b. (Num b) => [a] -> b
20:55:59 <sorear> tuxplorer: change ( to =<< and delete ) ?
20:56:08 <dibblego> > let f = foldr (const (1 +)) 0 in f [1..10]
20:56:13 <lambdabot>  10
20:56:32 <chessguy> that's reqlly cute
20:56:39 <chessguy> @src foldr
20:56:39 <lambdabot> foldr k z xs = go xs
20:56:39 <lambdabot>     where go []     = z
20:56:39 <lambdabot>           go (y:ys) = y `k` go ys
20:56:41 <tuxplorer> sorear: ok. now it works. But how to print the statement?
20:57:10 <tuxplorer> > :t closeStatement
20:57:11 <lambdabot>   parse error on input `:'
20:57:17 <tuxplorer> > t closeStatement
20:57:18 <lambdabot>   Not in scope: `closeStatement'
20:57:29 <sorear> ... WHY do people keep trying > :t ?
20:57:31 <chessguy> @type closeStatement
20:57:33 <lambdabot> Not in scope: `closeStatement'
20:57:43 <sorear> it doesn't even look like a Hugs/GHCi prompt!
20:57:48 <chessguy> @hoogle closeStatement
20:57:49 <lambdabot> No matches found
20:58:10 <tuxplorer> closeStatement is of type IO()
20:58:18 <tuxplorer> but why doesn't it print the statement?
20:58:24 <tuxplorer> closeStatement :: Statement -> IO ()
20:59:09 <nburlett> sorear: 'cause it looks like bird script?
20:59:28 <sorear> nburlett: > :t foo   doesn't work in bird script
20:59:40 <nburlett> sorear: yeah, but that doesn't mean that people think that way
21:02:44 <ddarius> sorear: Incidentally, http://modelingnts.la.asu.edu/pdf/NEW_GRAVITY.pdf is a pretty comprehensive and motivating paper for the use of geometric algebra in physics.
21:03:25 <P_D> gauge theory x)
21:04:47 <P_D> "I woke up at the crack of noon and spent eight and even twelve hours a day not learning field theory and soon I had not learnt more field theory than anyone else in Geoff's group and was quickly moving to the top"
21:08:04 <ddarius> Despite it's name, http://citeseer.ist.psu.edu/602558.html is probably the best paper for a complete and rigorous account of the algebra of geometric algebra.
21:08:05 <lambdabot> Title: The Inner Products of Geometric Algebra - Dorst (ResearchIndex)
21:19:44 <goalieca> inner products.. as in everything to do with hilbert spaces?
21:21:29 <ddarius> No.  There are plenty of other inner product spaces besides hilbert spaces.
21:21:56 <goalieca> hilbert spaces are complete..
21:21:58 <goalieca> right?
21:22:08 <goalieca> but the rest are not..
21:22:17 <goalieca> pre-hilbert is one
21:22:19 <goalieca> i think
21:23:48 <reffie> fuck math
21:24:20 <sjanssen> would if I could
21:26:41 <shapr> Math doesn't ever reject you.
21:28:07 <ddarius> goalieca: "complete" in what sense?
21:31:19 <goalieca> ddarius: lol. I guess closed under addition and scalar mult
21:31:25 <goalieca> no "holes"
21:31:44 * goalieca is an engineering student.. doesn't really care about all teeny details like a purist would :P
21:32:30 <Cale> goalieca: that would mean that, say Q is complete, since it's closed under addition and scalar multiplication
21:34:03 <goalieca> okay from my notes: every cauchy sequence is convergent
21:34:05 <goalieca> so there.
21:34:13 <Cale> yeah
21:34:19 <Cale> That's the usual sense of the term :)
21:34:30 <goalieca> abstract algebra can get too abstract
21:35:59 <Cale> A Hilbert space is any inner product vector space which is complete under the induced norm.
21:37:10 <omniscientIdiot> hyper fluxbox monadic fold?
21:37:22 <ddarius> omniscientIdiot: What about it?
21:37:35 <Cale> There are also Banach spaces, which are complete normed vector spaces, but which are not typically equipped with an inner product.
21:37:53 <omniscientIdiot> ddarius: makes as much sense to me as what Cale said ;)
21:38:22 <Cale> omniscientIdiot: Would you like an explanation?
21:38:23 <ddarius> omniscientIdiot: The difference being Cale is talking sense while that was nonsense.
21:38:28 <goalieca> my supervisor is basically an applied mathematician.. but not enough of that has rubbed off on me
21:38:31 <ddarius> (as in the quote was)
21:38:39 <goalieca> i know the basics.. but the details are always forgotten
21:38:52 <ddarius> Just remember the axioms and definitions
21:38:56 <omniscientIdiot> ddarius: precisely :)
21:39:33 <goalieca> heh.. tonight i was trying to follow some lecture on dual space projection theorems.. got pretty far but lost some of the finer points
21:39:37 <kolmodin> ?tell dons ok, thanks. might be interesting to follow that project then
21:39:38 <lambdabot> Consider it noted.
21:39:54 <Cale> omniscientIdiot: Do you know what a vector space is?
21:40:11 <goalieca> dual spaces are fucked up :S
21:40:24 <sorear> dual spaces are really cool!
21:40:30 <omniscientIdiot> nope
21:40:32 <ddarius> They're pretty straightforward.
21:40:39 <ddarius> omniscientIdiot: Know what a vector is?
21:40:51 <goalieca> sure they are.. but its weird how simple it all gets even if its hard to follow sometimes
21:40:59 <omniscientIdiot> direction + magnitude?
21:41:04 <tuxplorer> do dbconn<-connect "localhost" "Ybot" "ybot" "ypass";  query dbconn "select * from questions">>getFieldsTypes
21:41:04 <tuxplorer> What's wrong here?  Couldn't match expected type `IO'    against inferred type `(->) Statement'.          getFieldsTypes :: Statement -> [(String, SqlType, Bool)]
21:41:13 <Cale> I don't think you can *really* know what a vector is without knowing what a vector space is.
21:41:30 <goalieca> hehe
21:41:37 <mgsloan> well..
21:41:44 <Cale> omniscientIdiot: That's basically the case for a particular few vector spaces.
21:41:55 * mgsloan always hated the direction/magnitude definition
21:42:00 <sorear> omniscientIdiot: what about L2?
21:42:03 <ddarius> I don't think you can *really* know what a vector is without knowing set theory.
21:42:10 <mgsloan> I prefer matrix with either a single column or single row
21:42:19 <omniscientIdiot> sorear: never heard of it
21:42:21 <goalieca> oh boy.. lets go from the axioms of choice!
21:42:21 <ddarius> mgsloan: Oh blech!
21:42:21 <Cale> sorear: He doesn't know what a vector space is, and you're asking about L^2?
21:42:26 <mgsloan> I don't think you can *really* know anything
21:42:44 <Cale> omniscientIdiot: Okay, so how about a set and a function? :)
21:42:49 <goalieca> lets type it all up on latex as we go
21:42:49 <sorear> mgsloan: ugh..  matrices with infinite rank just reek of physicist math
21:43:21 <sjanssen> tuxplorer: getFieldsTypes doesn't have the right type to be used in that context
21:43:26 <omniscientIdiot> Cale: probably :)
21:43:29 <mgsloan> infinite rank?
21:43:33 <Cale> omniscientIdiot: Okay, a field?
21:43:48 <ddarius> Cale: "field" is ambiguous
21:43:49 <omniscientIdiot> no
21:43:52 <goalieca> lol
21:43:59 <mgsloan> the definition of direction + magnitude confuses people in my physics class to no end
21:44:02 <tuxplorer> sjanssen: it takes Statement type as input right?
21:44:03 <Cale> A field is essentially a set of things which behave somewhat like we expect numbers to behave.
21:44:14 <sjanssen> tuxplorer: yeah, where should that Statement come from?
21:44:23 <sjanssen> @type (>>)
21:44:25 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> m b -> m b
21:44:29 <mgsloan> do quaternions count as numbers?
21:44:35 * ddarius prefers the axiomatic definition of vectors as elements of a vector space.
21:44:40 <Cale> You can add them, multiply them, subtract them, and divide them (when the thing you're dividing by is nonzero), and most of the usual properties we like are true.
21:44:43 <goalieca> ya why not
21:44:51 <ddarius> mgsloan: They can.  What Cale meant was "real" numbers.
21:44:51 <sjanssen> tuxplorer: not how the type says that the right argument doesn't get anything from the left argument
21:44:55 <sjanssen> s/not/note
21:44:56 <sorear> mgsloan: they are a perfectly good division ring, iirc
21:45:00 <omniscientIdiot> Cale: like rings, semirings, groups and that stuff?  I know very little.
21:45:01 <Cale> http://en.wikipedia.org/wiki/Field_%28mathematics%29 -- this has a list of the properties which a field has to satisfy
21:45:02 <lambdabot> Title: Field (mathematics) - Wikipedia, the free encyclopedia
21:45:14 <Cale> omniscientIdiot: yeah, fields are just particularly nice rings
21:45:19 <mgsloan> sorear - yeah, I think maybe non-commutative multiplication, though... maybe I'm wrong
21:45:23 <goalieca> Cale: be complete or inconsistent..
21:45:29 <goalieca> err incomplete*
21:45:44 <mgsloan> I was mostly referencing the most obscure thing I could think of that sorta qualifies as a number
21:45:50 <Cale> In particular, they're commutative rings where you have multiplicative inverses for every nonzero element.
21:46:13 <tuxplorer> sjanssen: ya. ok.
21:46:15 <ddarius> mgsloan: Not even as far as octonions?
21:46:17 <Cale> (and 1 is not equal to 0)
21:46:19 <tuxplorer> @type (=<<)
21:46:21 <lambdabot> forall a (m :: * -> *) b. (Monad m) => (a -> m b) -> m a -> m b
21:46:22 <goalieca> group theory.. yay
21:46:27 <mgsloan> oh, I suppose octonions are more fun
21:46:30 <mgsloan> though less useful
21:47:03 <Cale> omniscientIdiot: If you'd like, I can go over the properties of a field. You sort of need to know what a field is to get what a vector space is.
21:47:13 <goalieca> no you don't
21:47:22 * ddarius agrees with goalieca 
21:47:28 <goalieca> all you really need is a good definition for set
21:47:29 <sorear> sedenions are better
21:47:30 <tuxplorer> sjanssen: how should I have got across a statement from query dbconn "select * from questions" to getFieldsTypes
21:47:43 <sjanssen> tuxplorer: what's the type of query?
21:47:51 * sorear loves abstract algebra
21:47:56 <tuxplorer> query :: Connection -> String -> IO Statement
21:48:11 <ddarius> You could just do vector spaces over the reals; you don't lose much.
21:48:15 <Cale> Well, your scalars are elements of some field, so it doesn't make much sense to go on without some small amount of understanding of what fields are about.
21:48:31 <dons> mm, this is very nice. http://programming.reddit.com/info/2rh69/comments
21:48:31 <lambdabot> dons: You have 4 new messages. '/msg lambdabot @messages' to read them.
21:48:32 <lambdabot> Title: The Actors Model and Haskell (reddit.com)
21:48:38 <dons> @seen lstephen
21:48:39 <lambdabot> I haven't seen lstephen.
21:49:02 <sjanssen> tuxplorer: do dbconn<-connect "localhost" "Ybot" "ybot" "ypass";  stmt <- query dbconn "select * from questions"; return (getFieldsTypes stmt)
21:49:21 <Cale> omniscientIdiot: anyway, examples of fields include Q (the rationals), R (the real numbers), C (the complex numbers), and Z/p (the integers modulo some prime)
21:49:26 <ddarius> Cale: You can just speak of real vector spaces and assume they know what reals are about at the useable level.
21:49:41 <tuxplorer> sjanssen: Thanks.
21:49:42 <goalieca> or get abstract into the functionals
21:50:10 <goalieca> but a vector space is more useful if you consider vectors-valued or matrix-valued
21:50:37 <goalieca> cuz.. in reals.. well that's easy normal math
21:51:18 <Cale> omniscientIdiot: so now, if you have some basic idea of what a field is (If you'd like, you can just think of some familiar field like the real numbers or the complex numbers like ddarius suggested)
21:51:43 <sorear> bah
21:51:48 <sorear> reals are *hard*
21:51:54 <Cale> omniscientIdiot: If F is a field, a vector space over the field F is a set V together with two binary operations:
21:51:56 <sorear> I avoid them if at all possible
21:51:56 <mgsloan> Mentalguy has been playing around with state machines & actor DSLs in haskell for interaction with widgets and things
21:52:13 <sorear> sure, I get geometric intuition, but it's hardly worth it
21:52:23 <Cale> vector addition: V x V -> V, denoted v + w, where v and w are in V
21:52:46 <Cale> and scalar multiplication: F x V -> V, denoted a v, where a is in F and v is in V.
21:53:03 <FMota> nighty night folks
21:53:08 <Cale> Further, it's subject to the following axioms:
21:53:12 <Inside> I hurd u guys r talking about vectosr and spaces?
21:53:16 * Inside ducks.
21:53:19 <Cale> 1) Vector addition is associative
21:53:33 <Cale> u + (v + w) = (u + v) + v for all u,v,w in V
21:53:42 <kilimanjaro> Haskell is the new math.
21:53:53 <Cale> 2) Vector addition is commutative: v + w = w + v for all v and w in V
21:54:00 <goalieca> kilimanjaro: i just sent a msg in #math about that too :P
21:54:28 <Cale> 3) Vector addition has an identity element: there is some 0 in V such that v + 0 = v for all v in V.
21:54:45 <ddarius> goalieca: Considering kilimanjaro is in #math...
21:54:47 <goalieca> not 0.. call it the null element
21:54:58 <goalieca> norm of 0.
21:55:00 <Cale> It's typically called 0.
21:55:07 <ddarius> That said Haskell doesn't get bogged down by questions about calculators and solving simple algebraic equations.
21:55:15 <Cale> I could call it e or something, but that would be strange.
21:55:18 <goalieca> lo ddarius
21:55:49 <kilimanjaro> 0 is fine, I don't see anything wrong with it as long as it is clear from context whether you mean zero vector or zero scalar
21:55:51 * ddarius likes punning on "understood" mathematical notations as much as possible.
21:55:55 <Cale> 4. There are inverses with respect to vector addition: for any v in V, there is some w in V for which v + w = 0
21:56:11 <Cale> (where that 0 is the same 0 as in property 3)
21:56:30 <ddarius> kilimanjaro: How can it not be clear from context for anything that matters (unless, I guess, if you were teaching someone who knew -nothing-)
21:56:51 <Cale> So those are all the things which just involve addition. Incidentally, you can summarise those four by saying that V is a commutative group under vector addition.
21:57:02 <tuxplorer> is there a tutorial that illustrates the use of each function in DataBase.HSQL ?
21:57:12 <Cale> Now we have some that are about scalar multiplication:
21:57:20 <goalieca> what constitutes a scalar..
21:57:22 <goalieca> oooh
21:57:28 <kilimanjaro> ddarius, well, we define our product to be F x V -> V, but on the other hand it might be natural to also have a VxF->V that behaves similarly, etc
21:57:29 <ddarius> @slop goalieca
21:57:29 * lambdabot slaps goalieca
21:57:52 <tuxplorer> forEachRow' :: (Statement -> IO ()) -> Statement -> IO ()
21:57:52 <tuxplorer> do dbconn<-connect "localhost" "Ybot" "ybot" "ypass";  stmt <- query dbconn "select * from questions"; forEachRow' (\stm -> getFieldValue stm "statement") stmt
21:57:52 <tuxplorer> throws error     No instance for (SqlBind ())       arising from use of `getFieldValue' at <interactive>:1:124-152     Possible fix: add an instance declaration for (SqlBind ())
21:57:52 <Cale> 5) Scalar associativity: for all a,b in F and v in V, we have a (b v) = (a b) v
21:58:05 <ddarius> kilimanjaro: And it doesn't matter if you switch them up, you get the same answer.
21:58:22 <kilimanjaro> ddarius, right, but that knowledge isn't part of the axioms, it is deduced from them...
21:58:40 <Cale> 6) Identity for scalar multiplication: For all v in V, we have 1 v = v, where 1 is the identity element in the field F.
21:59:07 <kilimanjaro> ddarius, this lecture is for beginners, who don't know what a field is, don't know what a vector space is, but instead they spend all their time thinking about type signatures. I think what I said is reasonable for the audience
21:59:24 <Cale> Finally, we have two axioms which tie scalar multiplication and vector addition together:
21:59:41 <ddarius> kilimanjaro: I didn't say it wasn't, though I don't think it particularly matters at this point or would be particularly helpful in this case.
22:00:03 <ddarius> Anyway, 0 is overloaded in Haskell, so it should be no problem
22:00:10 <Cale> 7) Scalar multiplication distributes over vector addition: for all a in F, and v, w in V we have a (v + w) = a v + a w
22:00:46 <Cale> 8) Scalar multiplication distributes over field addition: for all a,b in F, and v in V we have (a + b) v = a v + b v
22:00:58 <ddarius> Cale is thinking, "I wish these people would shut up and stop splitting my line of talk."
22:01:06 <Cale> heh
22:01:08 <ddarius> Since it is midnight, I think I will.
22:01:29 <Cale> omniscientIdiot: are you still following this?
22:01:46 <omniscientIdiot> I think
22:02:07 <Cale> okay. It might help to have some examples.
22:02:27 <goalieca> cale: you should go into basis vectors
22:02:31 <Paczesiowa> excuse me, is this "pam fs x = map (flip id x) fs" smart or stupid?
22:02:35 <Cale> goalieca: that's for a bit later :)
22:02:44 <kilimanjaro> omniscientIdiot, you also might find http://en.wikipedia.org/wiki/Vector_space useful, just as an overview of some of the stuff
22:02:45 <lambdabot> Title: Vector space - Wikipedia, the free encyclopedia
22:02:51 <Cale> goalieca: You need to know quite a bit about linear independence to do that :)
22:03:02 <goalieca> yup. but its a good end goal
22:03:05 <Cale> First, the most boring possible example. If F is any field, we can form a vector space which just has one vector, the zero vector.
22:03:17 <Cale> The operations are defined in the only possible way they could be
22:03:28 <Cale> Checking the axioms is easy but boring :)
22:03:56 <kilimanjaro> I've seen basis vectors introduced before linear independence actually, but I'm not really sure why. It was just a set such that any vector could be written uniquely as a sum of scalar multiples of the elements
22:04:06 <Cale> Slightly less, but still kind of boring example is that if F is any field, we can take V = F, and make F a vector space over itself.
22:04:22 <Cale> Then vector addition can be addition in F
22:04:27 <omniscientIdiot> Wait, slowing down, a vector space is a field F, a set V, the two operations and the axioms?
22:04:30 <Cale> and scalar multiplication is multiplication in F
22:04:47 <Cale> omniscientIdiot: a field F, a set V, and two operations, such that all the axioms are true
22:05:27 <Cale> So you can pick any set and any operations you like, so long as they fulfill the axioms
22:05:34 <Paczesiowa> what are you trying to do with that algebra stuff?
22:05:44 <mgsloan> so fmap (+) would be vector addition?
22:05:55 <omniscientIdiot> teach me cuz I stoopid
22:05:59 <Cale> mgsloan: if you'd like it to be
22:06:14 <bos> hi andyjgill
22:06:15 <mgsloan> (basically what I'm saying is that the underlying type of the collection (functor, I guess) is the field)
22:06:37 <mgsloan> s/collection/vector
22:06:37 <kilimanjaro> err
22:06:41 <andyjgill> hi bos
22:06:50 <Cale> It's not *quite* fair yet to say that a vector is a collection of scalars.
22:07:06 <goalieca> it is a tuple
22:07:12 <Cale> (note, we call elements of the field F scalars)
22:07:16 <Cale> goalieca: not necessarily
22:07:16 <kilimanjaro> mgsloan, that would be *a* vector addition, but it's certainly not the only one
22:07:22 <goalieca> ordered set then?
22:07:29 <Cale> goalieca: only if there's a basis
22:07:34 <kilimanjaro> goalieca, consider the reals as a vector space over the rationals
22:07:36 <mgsloan> oh, right, I guess there are other ones that would satisfy the axioms
22:07:49 <Cale> Yeah, that's a good example, let's do that one
22:07:57 <Cale> If Q is the field of rational numbers
22:08:05 <Cale> and R is the set of real numbers
22:08:11 <Cale> then R is a vector space over Q
22:08:11 * omniscientIdiot perks up
22:08:19 <goalieca> hmm. a vector is defined as an element of a vector space
22:08:24 <Cale> goalieca: right
22:08:25 <goalieca> so i see mathwolrd gives a tensor type approach
22:08:39 <Cale> The operations are the "obvious" ones
22:08:51 <Cale> vector addition is just addition of real numbers
22:09:20 <Cale> scalar multiplication of (p/q) r is just defined by multiplication of the real number (p/q) by r.
22:09:24 <goalieca> so technically a functional is a vector
22:09:30 <Cale> goalieca: absolutely
22:09:40 <kilimanjaro> goalieca, search for "dual space"
22:09:40 <Cale> goalieca: so is a matrix, tensor, what have you
22:09:55 <goalieca> ya.. i suppose i already treated it as such anyways
22:09:59 <goalieca> in calc of var
22:10:18 <Cale> omniscientIdiot: does that definition of the vector space operations for R over Q make sense?
22:10:34 <Cale> Then we just have to check the axioms
22:10:41 <Cale> and they're all pretty obvious things
22:10:50 <omniscientIdiot> I'm fuzzy on scalar multiplication.
22:11:00 <Cale> okay, so if we have a rational number p/q
22:11:03 <Cale> it's also a real number
22:11:06 <kilimanjaro> Cale, were you the one explaining how the construction of the dual space is not natural by using a typeclass argument?
22:11:09 <Cale> in a natural way
22:11:10 <kilimanjaro> sorry to deviate
22:11:17 <Cale> kilimanjaro: no
22:11:32 <Cale> kilimanjaro: sounds like something ddarius might do :)
22:11:41 <kilimanjaro> Cale, it was you, him, cjeris, or psykotic, I'm sure
22:11:45 <kilimanjaro> I think it was psykotic actually
22:12:20 <Cale> omniscientIdiot: since any fraction of integers is also a real number, not just a rational number
22:12:52 <tuxplorer> do dbconn<-connect "localhost" "Ybot" "ybot" "ypass";  stmt <- query dbconn "select * from questions"; return (collectRows (\smt -> closeStatement smt) stmt)
22:12:52 <tuxplorer> The return type is IO (IO [()])    But I would like to have the type as IO [String]. I can make the internal function as (\smt -> do a <- closeStatement smt; somefunc a). What would be the ideal function to be in place of somefunc?
22:13:00 <goalieca> i heard a definition for "irrational numbers are converged upon by rational numbers but aren't numbers on their own"
22:13:10 <goalieca> something like that...
22:13:11 <Cale> So we define the scalar multiplication of (p/q) by r as simply being the usual (p/q) r
22:13:16 <kilimanjaro> goalieca, that's silly, what's a number?
22:13:31 * goalieca doesn't know if he should be incomplete or inconsistent
22:13:55 <tuxplorer> is there some function that would convert String to IO String?
22:13:57 <Cale> goalieca: the set of irrational numbers doesn't satisfy any nice arithmetic properties is perhaps what you mean
22:14:05 <Paczesiowa> tuxplorer: return
22:14:08 <Cale> goalieca: but the set of real numbers as a whole does
22:14:16 <omniscientIdiot> tuxplorer: return?
22:14:46 <Paczesiowa> tuxplorer: and I think you need join at the top level to get rid of two levels of IO
22:14:47 <Cale> omniscientIdiot: clearer on the scalar multiplication?
22:14:56 <goalieca> Cale: i think the idea was to build the real numbers from the rational ones
22:15:07 <Cale> omniscientIdiot: It's a little confusing because I didn't give scalar multiplication a distinct symbol
22:15:13 <omniscientIdiot> I think
22:15:27 <Cale> omniscientIdiot: If I'd called it * then I could write something like (p/q)*r = (p/q)r
22:15:46 <Cale> So scalar multiplication just means ordinary multiplication
22:15:48 <kilimanjaro> goalieca, here's a counterintuitive challenge: show that the positive real numbers are a vector space over all real numbers (i.e. give me a vector addition and scalar product that make this a vector space)
22:16:11 <Cale> The axioms all check out due to the real numbers being a field.
22:16:25 <Cale> u + (v + w) = (u + v) + w, check
22:16:30 <tuxplorer> omniscientIdiot: Paczesiowa: The problem is collectRows executes the function in the brackets for each row in the table. So, if i use a return statement there, wouldn't it return intermittently?
22:16:35 <Cale> (that's a familiar property of real numbers)
22:16:40 <Cale> v + w = w + v, check
22:16:50 <kilimanjaro> I actually guess anyone who is interested could try for it, positive reals are a vector space over all reals
22:16:57 <Cale> there is some 0 such that v + 0 = v for any v, check, it's just the usual 0
22:17:01 <goalieca> kilimanjaro: scalars can be negative.
22:17:06 <kilimanjaro> goalieca, yep
22:17:15 <goalieca> so it can span
22:17:20 <omniscientIdiot> right
22:17:24 <Cale> Additive inverses exist: for all v in V there is some w in V for which v + w = 0
22:17:31 <Cale> check, take w = -v
22:17:43 <Paczesiowa> > :t collectRows
22:17:47 <lambdabot>   parse error on input `:'
22:17:52 <Paczesiowa> :t collectRows
22:17:54 <lambdabot> Not in scope: `collectRows'
22:17:57 <kilimanjaro> goalieca, I'll give you a hint. There is such a vector space, so any counterargument is wrong
22:17:58 <tuxplorer> @type collectRows
22:17:59 <lambdabot> Not in scope: `collectRows'
22:18:13 <tuxplorer> Paczesiowa: collectRows :: (Statement -> IO a) -> Statement -> IO [a]
22:18:14 <Cale> Scalar multiplication: for a,b in Q, v in R, we have a (b v) = (a b) v, check
22:18:24 <Cale> by usual associativity of multiplication in R
22:18:56 <Cale> For all v in V, we have 1*v = v, check
22:18:58 <earnest> why a, b in Q? what are you doing exactly?
22:19:11 <tuxplorer> Paczesiowa: My aim here is to get a list of all the records and process it.
22:19:18 <Cale> earnest: we're checking the axioms for R as a vector space over Q.
22:19:24 <earnest> oh, alright
22:19:42 <Paczesiowa> tuxplorer: what libs do I need to compile that?
22:19:53 <Cale> Last two... for all a in Q, and v,w in R, we have a(v + w) = av + aw, yep
22:19:56 <tuxplorer> Database.HSQL
22:20:15 <Cale> and for all a,b in Q and v in R, we have (a + b) v = av + bv, check
22:20:40 <Cale> All of this just follows from R being a field, and Q being a subfield of it.
22:20:42 <Paczesiowa> tuxplorer: wait, need to compile it
22:20:54 <tuxplorer> Paczesiowa: you can just load Database.HSQL.MySQL module on your ghci and paste this statement
22:21:21 <goalieca> kilimanjaro, i'm not sure what you're getting at. you mean you want me to define addition and scalar mult
22:21:27 <Cale> So we can just treat elements of Q as being elements of R and apply the field axioms, which tell us that these things are true :)
22:21:39 <Cale> omniscientIdiot: fairly clear?
22:21:54 <omniscientIdiot> Maybe a vector space where the vector addition and scalar multiplication aren't just the "natural" ones could be illustrative.
22:22:12 <kilimanjaro> goalieca, yea
22:22:28 <Cale> Well yes, but perhaps let's quickly look at F^2 first
22:22:41 <omniscientIdiot> okay
22:22:57 <kilimanjaro> goalieca, a vector space is sort of an abstract concept, addition in the vector space doesn't have to be the natural addition of the underlying set, even though the symbols used to denote addition might be identical
22:22:58 <omniscientIdiot> where V = F?
22:22:58 <Cale> If F is any field, then the set F^2 of ordered pairs of elements of F, is a vector space under the operations:
22:23:06 <Cale> (a,b) + (c,d) = (a+c, b+d)
22:23:22 <Cale> u (a,b) = (ua, ub)
22:23:41 <goalieca> kilimanjaro, i got that.. but now i'm trying to think addition to make it span all reals but still satisfy the axioms
22:24:16 <Cale> There's nothing special about pairs either, we could also use triples, 4-tuples, etc. with analogous rules.
22:24:41 <Paczesiowa> tuxplorer: why do you need that return in last line?
22:24:51 <Cale> So, in particular, R^2, the set of ordered pairs of real numbers, which is also known as the Cartesian plane, is a vector space.
22:25:00 <omniscientIdiot> right
22:25:02 <Cale> as well as R^3
22:25:29 <Cale> Another example would be polynomials
22:25:37 <Cale> with coefficients in R, say
22:25:42 <Paczesiowa> and suprisingly R^n for non-negative n
22:25:46 <tuxplorer> Paczesiowa: I can have anything of type IO a there. a function of type String -> IO String would be preferrable instead of return, so that I can get a list of Strings finally
22:25:47 <Cale> You know how to add polynomials
22:26:01 <Cale> and also how to multiply a polynomial with real coefficients by a real number
22:26:25 <Cale> and that leads to a vector addition and scalar multiplication which turns polynomials over R into a vector space
22:26:30 <goalieca> kilimanjaro, i give up
22:26:34 <goalieca> i'm not that creative right now
22:26:38 <goalieca> no outside the box thinking for me
22:26:39 <Paczesiowa> tuxplorer: I can't compile that (I dont have mysql), but try to remove that return
22:26:40 <Cale> Another example: continuous functions R -> R
22:26:48 <Cale> adding two continuous functions gives another
22:27:28 <Cale> and you can multiply a function f by a scalar a simply by defining (fa)(x) = a f(x)
22:27:32 <Cale> er
22:27:34 <tuxplorer> Paczesiowa: If I remove that return  Couldn't match expected type `IO a' against inferred type `()'
22:27:36 <Cale> (af)(x) = a f(x)
22:27:39 <kilimanjaro> goalieca, ok, so you have the set of positive real numbers with vector addition as multiplication in the reals, i.e. x,y are vectors, then x [+] y = x*y where [+] denotes vector addition
22:28:05 <kilimanjaro> goalieca, this preserves the 4 properties of vector addition that are necessary
22:28:19 <Cale> kilimanjaro: nice example :)
22:28:24 <kilimanjaro> goalieca, then scalar multiplication is s*v = v^s
22:28:36 <kilimanjaro> err, s[*]v = v^s to keep notation consistent
22:28:37 <goalieca> aah.. so that's how you preseve x + (-x) = 0
22:29:00 <Cale> yeah, the "0" in that vector space is 1
22:29:12 <Paczesiowa> it's easier to create isomorphism from polynomials of degree n to R^n
22:29:16 <kilimanjaro> Cale, thanks, I think its nice to get weirded out from the get go, that way you always think twice about making assumptions
22:29:34 <tuxplorer> Paczesiowa: you  meant remove the return of collectRows? If I remove that it compiles. but the type is foo :: IO [( )]
22:29:47 <Paczesiowa> thats better type
22:29:59 <Cale> omniscientIdiot: starting to get the idea?
22:30:03 <tuxplorer> Paczesiowa: Now, how do I get each element out of it?
22:30:12 <Paczesiowa> now just turn that () to String and you get what you want
22:30:32 <omniscientIdiot> I'll have to work through the example to see that they satisfy the axioms to my satisfaction :)
22:30:47 <omniscientIdiot> *examples
22:30:49 <Cale> omniscientIdiot: There's basically a lot of examples of this same kind of structure throughout mathematics. Vector spaces capture this idea and let us say things about all of them.
22:30:56 <Paczesiowa> tuxplorer: your problem is that funciton (\smt -> closeStatement smt) has type IO ()
22:31:27 <kilimanjaro> goalieca, yea, it seems like a bit of a trick, but with a bit of study in algebra that sort of thing would actually seem pretty natural, the reason why is because there's actually a name for the axioms vector addition alone must satisfy, it makes the vector space an "abelian group" under addition, and for positive reals multiplication is pretty much the classic abelian group
22:31:45 <Cale> Some really simple things you can prove are that if 0 and 0' are both zero vectors: that is, we have 0 + v = v and 0' + v = v for all v in V, then 0 = 0'
22:32:05 <Cale> Scalar multiplication with the zero vector gives the zero vector again
22:32:11 <Paczesiowa> tuxplorer: and I havent ever use a database, but I dont think that you really want to do that
22:32:14 <goalieca> kilimanjaro, i'm from engineering background.. i know a tad bit of group theory, but mostly i'm learning algebra for optimization problems.
22:32:23 <Cale> Scalar multiplication of any vector by the scalar 0 gives the zero vector
22:32:27 <tuxplorer> Paczesiowa: can I somehow make it into type IO <something else> say IO String?
22:32:29 <goalieca> mostly everything is formulated as a transform or an optimization
22:32:43 <Cale> In fact, a v = 0 if and only if a = 0 or v = 0
22:33:10 <earnest> (for an integral domain)
22:33:24 <Paczesiowa> tuxplorer: collectRows will close that connection for you
22:33:35 <Cale> Additive inverses are unique: if v is a vector and w and w' are vectors such that v + w = 0 and v + w' = 0, then w = w'
22:33:55 <Paczesiowa> tuxplorer: but it needs function Statemend-> IO a, so just write that function Statement -> IO String
22:34:02 <kilimanjaro> goalieca, yea, group theory is probably the most pervasive bit of algebra behind the standard linear algebra stuff. and it's mainly just a bunch of vocabulary, the ideas themselves come from a lot of other places
22:34:19 <Paczesiowa> tuxplorer: can't help you more I don't know anything but databases
22:34:20 <Cale> This uniqueness means that we can actually give a special name to the inverse of v, it's typically written -v.
22:34:40 <Cale> These are all *fairly* easy to prove, and you should try them :)
22:34:48 <Cale> If you get stuck with one of them, ask me about it :)
22:34:55 <tuxplorer> Paczesiowa: ok. But what function is of type Statement -> IO String?
22:35:04 <goalieca> kilimanjaro: i love abstraction though.. because then you can big-picture your way to a solution
22:35:16 <goalieca> no hacks or anything
22:35:51 <tuxplorer> ?hoogle () -> String
22:35:51 <lambdabot> Did you mean: () -> String
22:35:51 <lambdabot> Prelude.show :: Show a => a -> String
22:35:51 <lambdabot> Text.Html.prettyHtml :: HTML html => html -> String
22:35:57 <kilimanjaro> yea, that's the power of the algebraic approach, but then you also get accused of just being a jargon monger (well, I don't, but that's because I don't really know a whole lot of algebra)
22:36:07 <tuxplorer> (11:05:04  IST) lambdabot: Did you mean: () -> String     How does this help?
22:36:45 <tuxplorer> Its asking me if I meant what I typed there?
22:36:57 <goalieca> jargon monger? well in an academic setting there is never too much jargon.. out in the "real-world" people just want it to work
22:36:59 <Paczesiowa> tuxplorer: you cant turn () to String ( it's like turning void to String, not useful)
22:37:06 <Cale> omniscientIdiot: anyway, the quick big picture of the rest of what I was talking about: if V is a vector space over R or C, we can sometimes define what's called an inner product on vectors in V. This product takes two vectors and produces a scalar. It's connected up in a nice way with defining angles between vectors in the vector space.
22:37:10 <tuxplorer> Paczesiowa: ok.
22:37:35 <Cale> omniscientIdiot: A vector space together with a specified inner product is called an inner product space.
22:38:28 <Paczesiowa> tuxplorer: you need some function returning IO String (maybe getFieldValue?)
22:38:45 <Cale> omniscientIdiot: Once you have an inner product space, it's possible to talk about the "lengths" of vectors, by defining the length of v to be the square root of the inner product of v with itself.
22:38:50 <kilimanjaro> goalieca, well, there have been pretty famous arguments on both sides, http://pauli.uni-muenster.de/~munsteg/arnold.html is an interesting read if you have a few minutes
22:38:51 <lambdabot> Title: V.I. Arnold, On teaching mathematics
22:39:00 <tuxplorer> Paczesiowa: Control.Exception.evaluate might help I guess. Let me try.
22:39:23 <omniscientIdiot> Cale: I'm reminded of the absolute value of complex numbers.
22:39:27 <Cale> omniscientIdiot: That definition of length gives you a way to measure the distance between two vectors, as the length of v + (-w)
22:39:35 <Cale> omniscientIdiot: absolutely
22:39:52 <Cale> omniscientIdiot: C is a vector space over R
22:39:55 <kilimanjaro> goalieca, Arnold is one of those russian mathematical demi-gods, and if you take his word on it there is a stark contrast between the russian school (physics, geometric, whatever) vs the french school (axiomatic, bourbaki, etc)
22:39:58 <goalieca> kilimanjaro, i read that once before. i must admit the way they teach math is completely disjoint from what it means
22:40:10 <Cale> and this length actually coincides with the usual absolute value
22:40:27 <Cale> (for a particular inner product)
22:40:38 <Paczesiowa> tuxplorer: that won't work, is fomething return type IO () it means that it performed some side effect, but there is no result returned, there is no way to turn that not-existing result into anything usefuol
22:40:40 <goalieca> and tie that into normed spaces
22:40:49 <kilimanjaro> goalieca, yea, I think it's easy to succumb to that sort of approach as a student. you sort of figure if you just work on learning the axiomatics then the rest will come for free, but it's a mix of both that is really needed for a lucid understanding
22:40:50 <goalieca> lets go everywhere all at once
22:41:22 * goalieca was always impatient learning math as undergrad because i could never really see the point till later
22:41:22 <kilimanjaro> do all vector spaces have a norm? something akin to the discrete metric?
22:41:42 * sorear ponders
22:41:48 <kilimanjaro> i've not really studied much linear algebra, that's the price you pay for taking it at a community college
22:41:55 <goalieca> mathworld says: "A vector space possessing a norm."
22:41:57 <Cale> Then once you can talk about distances, you can talk about Cauchy sequences -- which are sequences of vectors so that for any tiny positive distance e, there's some point far enough out in the sequence beyond which any two elements are within distance e of one another
22:41:58 <goalieca> so i assume no
22:42:05 <sorear> If you norm a vector space, you get a metric spae
22:42:26 <sorear> Are there any non-metric spaces with vector structure?
22:42:30 <Cale> So such sequences "look like they're converging"
22:43:04 <Cale> One can ask whether any such sequence in the space is getting close to some particular vector.
22:43:09 <kilimanjaro> sorear, there's not really such thing as a non-metric space
22:43:14 <goalieca> kilimanjaro, i always admired feynman
22:43:15 <Cale> (called the limit of the sequence, if it exists)
22:43:24 <Cale> and if that's true, then the space is called complete
22:43:32 <kilimanjaro> your metric might just be something stupid like the discrete metric, but the existence of SOME metric is certain
22:43:43 <kilimanjaro> I was just wondering if the same held for norms
22:43:50 <Cale> Anyway, that's a lot to take in all at once, I'd just worry about the basics of vector spaces for now :)
22:44:08 <goalieca> ha. math has no beginning or end though
22:44:09 <sorear> kilimanjaro: define |x| = 0 if x = 0, 1 otherwise
22:44:16 <sorear> kilimanjaro: this satisfies all the norm lays
22:44:26 <omniscientIdiot> not just direction + magnitude :)
22:44:28 <kilimanjaro> ahh, I didn't even bother to recall the laws
22:44:31 <sorear> kilimanjaro: and induces the discrete topology on the underlying space
22:44:52 <Cale> goalieca: MathWorld can be a little funky, I recommend exercising caution with their definitions of things :)
22:45:08 <kilimanjaro> some of the mathworld proofs are horrible too
22:45:15 <goalieca> cale: i know. the guy who owns the joint isn't too popular but he's a real prick
22:45:24 <kilimanjaro> horrible as in, written by a guy who just learned what quantifiers meant and wants to use the symbols wherever he can
22:45:25 <Cale> PlanetMath will typically give you 3 or 4 definitions, and usually at least one of them will be the one everyone uses :)
22:45:28 <sorear> kilimanjaro: and yes there ARE non-metric spaces, like the space with two points and {}, {a}, {a,b} as open sets
22:45:34 <omniscientIdiot> direction/magnitude is just one way to visualize R^2, which is just one possible vector space over R, right?
22:45:43 <Cale> omniscientIdiot: right
22:45:44 <kilimanjaro> sorear, no, I didn't mean metrizable
22:45:52 <sorear> kilimanjaro: ...but we were talking about vector spaces, not topological spaces.  my confusion
22:46:09 <goalieca> planet math eh? bookmarked!
22:46:35 <Cale> omniscientIdiot: and that way of looking at things as "direction + magnitude" is actually only possible because it's really an inner product space
22:46:52 <Cale> (or at least a normed space -- one where the vectors have lengths)
22:47:01 <kilimanjaro> sorear, yea I was being a bit vague anyways
22:47:40 <Cale> goalieca: Wikipedia is also typically not so bad, but I'm guessing you've already heard of it ;)
22:48:00 <goalieca> cale: wikipedia.fr is a backup
22:48:02 <goalieca> ;)
22:48:08 <goalieca> sometimes french has more details
22:48:12 <goalieca> sometimes english
22:48:16 <goalieca> its nice being bilingual
22:48:21 <Cale> :)
22:48:26 <earnest> :)
22:48:44 <omniscientIdiot> (:[])
22:48:48 <kilimanjaro> sorear, it was sort of a stupid question anyways actually, I was wondering what sort of set would not be able to become a X space (for X is metric, normed vector, whatever), but if I am just thinking about sets with nothing else then size is the only thing that is interesting. so stupid question
22:49:10 <sorear> kilimanjaro: it depends on how much structure you want ;)
22:49:11 <Cale> I need to get better at French. I can just barely read it.
22:49:40 <Cale> I have a set of notes on the combinatorics of symmetric functions in French that I'm going to read though.
22:49:42 <tuxplorer> Thanks Paczesiowa for helping me. No tuts are found about using Database.HSQL :(
22:49:53 <omniscientIdiot> I can just barely almost read it :)
22:49:58 <goalieca> there are still a lot of math papers done up in french
22:50:16 <Cale> They're nice enough that it would almost be worth translating them properly.
22:50:53 <Paczesiowa> tuxplorer: just come by later, I'm sure there'll be some hsql-aware geek here
22:51:14 <tuxplorer> hoping :)
22:51:22 <goalieca> well to translate it properly enough i'd actually have to understand it.
22:53:05 <omniscientIdiot> @yow!
22:53:05 <lambdabot> 	Talking Pinhead Blues:
22:53:05 <lambdabot> Oh, I LOST my ``HELLO KITTY'' DOLL and I get BAD reception on channel
22:53:05 <lambdabot>     TWENTY-SIX!!
22:53:05 <lambdabot>  
22:53:05 <lambdabot> Th'HOSTESS FACTORY is closin' down and I just heard ZASU PITTS has been
22:53:07 <lambdabot> [7 @more lines]
22:53:46 <omniscientIdiot> @more?
22:53:47 <lambdabot>     DEAD for YEARS..  (sniff)
22:53:47 <lambdabot>  
22:53:47 <lambdabot> My PLATFORM SHOE collection was CHEWED up by th' dog, ALEXANDER HAIG
22:53:47 <lambdabot>     won't let me take a SHOWER 'til Easter ... (snurf)
22:53:47 <lambdabot>  
22:53:48 <Cale> http://cale.yi.org/autoshare/notes.pdf -- if you're curious :)
22:53:49 <lambdabot> So I went to the kitchen, but WALNUT PANELING whup me upside mah HAID!!
22:53:51 <lambdabot>     (on no, no, no..  Heh, heh)
22:55:42 <goalieca> cale: that reads quite well.. but is a little definition heavy
22:56:06 <Cale> yeah, for the initial portion :)
22:56:23 <goalieca> i wouldn't know what to translate partages as for example
22:56:25 <goalieca> a share?
22:56:27 <goalieca> joint
22:56:29 <goalieca> joint set?
22:56:45 <Cale> partitions
22:57:56 <Cale> At least, that's the standard translation :)
22:58:57 <goalieca> wow. that's a long document
22:59:00 <goalieca> would take time
22:59:07 <Cale> yeah
22:59:22 <Cale> It's essentially a book :)
22:59:24 <Paczesiowa> Cale you wrote that?
22:59:28 <Cale> Paczesiowa: no
22:59:41 <goalieca> i'm keeping that though because i can read it easily enough.. especially some of the other parts
22:59:47 <Cale> My French is not nearly that good :)
22:59:50 <Paczesiowa> images looks like tetris
23:00:10 <Paczesiowa> Cale: I don't know french at all so I just watch the pictures:>
23:00:11 * goalieca did math only in french until high school
23:00:12 <Cale> Yeah, the Ferrers' diagrams for the partitions :)
23:01:01 <goalieca> well i offer to help translate a passage if you cross your eyes too hard
23:02:57 <tuxplorer> All data in Haskell is immutable right? Then how is there an update method in Data.Hashtable?
23:03:14 <Cale> tuxplorer: because the IO monad isn't bound by that restriction :)
23:03:20 <dibblego> what is its type?
23:03:25 <P_D> haskell has an action language and a function language
23:03:38 <P_D> the action language allows for mutability.
23:03:47 <tuxplorer> oh! so, internally HashTable is stored as a file or something than as a datastructure in memory?
23:03:50 <dibblego> *controlled* mutability
23:03:54 <Cale> tuxplorer: We have mutable data structures but you can only work with them from the IO monad.
23:04:05 <Cale> tuxplorer: No, it's in memory
23:04:21 <dibblego> IORef probably
23:04:24 <Cale> tuxplorer: There are mutable arrays which you can use from the IO monad too.
23:04:53 <oerjan> @docs Data.IORef
23:04:54 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Data-IORef.html
23:04:58 <P_D> They put it under "IO" because it behaves exactly like the way you have to behave to talk to something over the network
23:05:06 <Cale> as well as IORefs which are rather like mutable cells containing typically immutable values
23:05:09 <goalieca> in haskell either it is a monad edit or a copy on write
23:05:09 <tuxplorer> Cale: where are those mutable arrays? I'm actually looking for a mutable list of HashTables. ie., I should be able to create add more HashTables to the list
23:05:26 <Cale> tuxplorer: By the way, don't use Data.Hashtable
23:05:28 <Cale> ever
23:05:35 <dibblego> @docs Data.Array
23:05:36 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Data-Array.html
23:05:45 <tuxplorer> Cale: oh! what's the issue with it?
23:05:52 <tuxplorer> what is the alternative?
23:05:52 <dolio> It's slower than Data.Map.
23:05:55 <Cale> It should be removed from the libraries, because it's actually less efficient than Data.Map
23:05:57 <oerjan> Data.Array is immutable
23:06:02 <tuxplorer> oh! ok
23:06:22 <Cale> http://www.haskell.org/ghc/docs/latest/html/libraries/base/Data-Array-MArray.html
23:06:24 <lambdabot> http://tinyurl.com/y2qz4l
23:06:30 <oerjan> @docs Data.Array.IO
23:06:30 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Data-Array-IO.html
23:06:38 <dibblego> thanks
23:06:40 <Paczesiowa> :t flip id
23:06:42 <lambdabot> forall b c. b -> (b -> c) -> c
23:06:44 <Cale> That's the general mutable array interface, and Data.Array.IO is a specific instance of it
23:07:20 <Cale> There's also Data.Array.ST, when you're doing what amounts to a pure computation, but you want to do it using mutable structures internally.
23:07:36 <dolio> If you want to be a hard-liner, you should use STArrays, but people seem to dislike them for some reason.
23:07:44 <dolio> Rather than IOArrays, that is.
23:07:50 <Cale> The s type parameter gets annoying sometimes.
23:07:56 <oerjan> however, someone recently wrote another hashtable implementation that supposedly was better some times
23:08:10 <oerjan> it uses Data.Map internally
23:08:15 <tuxplorer> Cale: Pure computation in the sense I wouldn't have to do any IO over it right?
23:08:23 <Cale> Right
23:08:37 <oerjan> (but not entirely)
23:08:45 <Cale> It's a pure function overall in the sense that it'll always produce the same results for the same inputs
23:08:57 <Cale> But internally, it's using mutable structures to do its work.
23:09:04 <Cale> That's what the ST monad is for.
23:09:28 <omniscientIdiot> "single-threaded" I think it was.
23:09:33 <Paczesiowa> does function application (that space in "f x") have name in haskell?
23:09:39 <Cale> Or "State Thread"
23:09:44 <tuxplorer> Cale: Thanks. I think Data.Array.ST should do for me
23:09:54 <Cale> tuxplorer: What are you working on?
23:09:56 <oerjan> Paczesiowa: "function application"? :D
23:10:11 <omniscientIdiot> @src ($)
23:10:11 <lambdabot> f $ x = f x
23:10:19 <sorear> Paczesiowa: Apposition
23:10:26 <Paczesiowa> omniscientIdiot: tx
23:10:40 <tuxplorer> cale I'm writing an IRC bot that does NLP on IRC chats.
23:10:52 <Cale> tuxplorer: Hmm, okay
23:11:01 <sorear> heard of megamonad?
23:11:20 <Cale> tuxplorer: I highly recommend trying to use the immutable data structures first.
23:11:33 <Cale> tuxplorer: If you need a hashtable-like thing, Data.Map is excellent.
23:12:14 <tuxplorer> Cale: I would need to have a part of the DB in memory. So, am planning to have the records as an Array-ST of Map
23:12:37 <dolio> Most people use the term "hashtable" when they mean "maps in general" anyway. :)
23:12:42 <oerjan> tuxplorer: i think that may be difficult.
23:12:46 <tuxplorer> Cale: any better suggestions to do that?
23:12:56 <tuxplorer> oerjan: oh!
23:13:02 <Cale> tuxplorer: What would the indices of the array be?
23:13:13 <oerjan> because you cannot do IO simultaneously with the ST array, i think.
23:13:22 <oerjan> i might be wrong though
23:13:40 <Cale> STArrays are kind of transient things.
23:13:45 <dolio> You could use unsafeIOToST! :)
23:14:04 <Cale> You can only keep them around for the life of your ST computations (modulo doing stupid hacks)
23:14:07 <oerjan> i _think_ dolio was being funny there.
23:14:08 <tuxplorer> Cale: the primary key of the DB?
23:14:41 <Cale> tuxplorer: changing the size of an array isn't a trivial operation
23:14:56 <tuxplorer> Cale: oh!
23:14:58 <Cale> So you might prefer just to use a Data.Map
23:15:17 <Cale> Don't worry so much that it's really a binary balanced tree :)
23:15:31 <oerjan> (IO arrays don't have that restriction, of course)
23:16:26 <Cale> oerjan: well, even the mutable array interface doesn't have a simple operation for modifying the bounds of an array dynamically, so you have to manually copy to a larger array.
23:16:39 <oerjan> yeah.
23:17:12 <Cale> Using a Map will be simpler -- how many entries is your DB expected to have?
23:17:39 <oerjan> despite this, finding the size of a mutable array is an IO operation, someone was bitten by it the other day.
23:17:54 <dibblego> why is it?
23:18:37 <Cale> Well, if you're willing to work hard, you could implement your own instance of MArray which had a resize operation.
23:18:39 <tuxplorer> Cale: it's a DB of all responses in a particular channel over time. But the inmemory thing needs to be just the responses for a particular IRC session.
23:19:28 <tuxplorer> so, you can expect the DB to be several thousand records long and the inmemory thing to be a thousand or so
23:20:10 <Cale> tuxplorer: oh, then Data.Map will be fine
23:20:28 <Cale> You can easily work with Maps on the order of 1 million elements with no troubles.
23:20:48 <tuxplorer> Cale: So, I can better have a Map of Maps instead of an Array of Maps right?
23:20:54 <Cale> yeah
23:21:00 <Cale> what's the inner structure?
23:21:22 <Cale> a map from queries to responses?
23:21:25 <goalieca> map of maps is really just one big tree
23:21:59 <Cale> sort of, yeah -- with a change of index halfway down :)
23:22:10 <P_D> just use (k1,k2) as k
23:22:36 <tuxplorer> Cale: yeah, That should be fine. But in a map, I can have only key -> value pairs.. but there can be several responses to a query.
23:22:59 <omniscientIdiot> key -> [value]
23:23:17 <tuxplorer> omniscientIdiot: :P didn't strike my mind
23:23:18 <Cale> or even Set Value
23:24:17 <Paczesiowa> map of maps is a forest
23:24:39 <Paczesiowa> or at least a garden
23:24:45 <Cale> On my machine allocating a map with a million elements takes about 10 seconds, and then lookups into it are essentially instantaneous
23:25:29 <Cale> (0.00 secs)
23:25:35 <tuxplorer> Paczesiowa: I won't have to have a map of maps if I use it like some_key_id -> [(queries,responses)]
23:25:45 <tuxplorer> sorry.
23:25:49 <Paczesiowa> that's only 13.8 comparisions
23:26:05 <goalieca> log 10^6 = 6 :)
23:26:06 <tuxplorer> some_key_id -> (query, [responses])
23:26:34 <Paczesiowa> > log (10 ** 6)
23:26:36 <lambdabot>  13.815510557964274
23:26:49 <omniscientIdiot> Map id (Map query (Set response))
23:26:51 <glguy> > log (10 ** 6) / log 10
23:26:52 <lambdabot>  5.999999999999999
23:26:53 <Cale> log 10^6 / log 10 = 6 :)
23:27:10 <goalieca> gotta love ieee float
23:27:11 <Paczesiowa> why /log10?
23:27:15 <goalieca> log = ln
23:27:22 <Cale> Paczesiowa: because log is the natural one :)
23:27:22 <goalieca> > ln 2.7
23:27:23 <lambdabot>   Not in scope: `ln'
23:27:27 <goalieca> > log 2.7
23:27:29 <lambdabot>  0.9932517730102834
23:27:35 <Cale> > log (exp 1)
23:27:37 <lambdabot>  1.0
23:27:40 <Cale> > exp 1
23:27:41 <lambdabot>  2.718281828459045
23:27:55 <Cale> Who needs any other, really?
23:28:19 <Paczesiowa> well I like logarythmic sugar:>
23:28:26 <goalieca> > log -1
23:28:27 <Cale> If I made calculators, they wouldn't have separate log and ln buttons. They'd have one button called log, and it would give you the natural log.
23:28:27 <lambdabot>   add an instance declaration for (Num (a -> a))
23:28:27 <lambdabot>     In the expression: log -...
23:28:31 <goalieca> woohoo
23:28:37 <Olathe> Paczesiowa: Maple syrup.
23:28:44 <coffeemug> I have a question about GHC garbage collector
23:28:45 <tuxplorer> omniscientIdiot: is using  Map some_key_id  (query, [responses]) better or Map id (Map query (Set response)) ?
23:28:50 <Olathe> > (chop tree) (exp 1)
23:28:50 <lambdabot>   Not in scope: `tree'
23:28:51 <coffeemug> I read somewhere that it's a mark and sweep
23:28:55 <glguy> goalieca: you tried to subtract 1 from log
23:29:09 <Cale> coffeemug: generational mark and sweep, I think
23:29:09 <goalieca> oh lol
23:29:14 <coffeemug> right
23:29:16 <goalieca> > log (-1)
23:29:17 <lambdabot>  NaN
23:29:22 <tuxplorer> which of the two is efficient?
23:29:24 <goalieca> yeh.. i didn't read the type sig
23:29:26 <dolio> "Why Common Lisp so is fast, Python is much slower, and Python's slowness is perhaps a good thing"
23:29:27 <coffeemug> but isn't it theoretically possible to do much better than that?
23:29:40 <coffeemug> because Haskell has value semantics
23:29:43 <Cale> coffeemug: oh, it's actually mixed with a copy collector
23:29:51 <omniscientIdiot> tuxplorer: I guess I misread, there's only one query for each id?
23:29:58 <Cale> http://hackage.haskell.org/trac/ghc/wiki/GarbageCollectorNotes
23:29:59 <lambdabot> Title: GarbageCollectorNotes - GHC - Trac
23:30:00 <P_D> JHC has has some region inference technology
23:30:22 <tuxplorer> omniscientIdiot: yes
23:30:23 <coffeemug> so even if you use pointers under the hood you could analyze the type info to infer a lot of useful stuff
23:30:34 <coffeemug> Cale: what's a copy collector?
23:30:50 <dolio> Ooo.
23:30:54 <P_D> look up cheney algorithm
23:31:03 * dolio thinks that region memory management is cool.
23:31:08 <omniscientIdiot> tuxplorer: your version is correct, you might use Set responses instead of list, it doesn't matter much.
23:31:18 <ari> :t log
23:31:18 <tuxplorer> omniscientIdiot: ok
23:31:20 <lambdabot> forall a. (Floating a) => a -> a
23:31:23 <coffeemug> ah, it's the same thing
23:31:50 <P_D> same thing?
23:31:50 <omniscientIdiot> > logBase 10 (10^6)
23:31:51 <lambdabot>  5.999999999999999
23:31:55 <ari> :D
23:32:06 <coffeemug> I mean copy collection and cheney's algorithm
23:32:29 <P_D> it's one style of copy collector
23:32:58 <coffeemug> but theoretically haskell doesn't need such GC schemes at all
23:33:10 <P_D> it probably does due to halting problem
23:33:34 <coffeemug> because it has value semantics and any underlying pointer optimizations can be analyzed at compile time
23:33:39 <coffeemug> hmm
23:34:10 <Cale> coffeemug: value semantics?
23:34:43 <P_D> serious haskell programs are ugly imperatiev programs anyway.
23:35:11 <P_D> at the outermost level, at least
23:35:26 <sjanssen> I don't think they're all ugly
23:35:42 <P_D> as far as deterministic memory management is concerned though
23:35:45 <sjanssen> but of course you've got IO at the outermost layer, every useful program has to do *some* IO
23:35:57 <goalieca> why not make the inside all beautiful while the messy imperative stuff in python ;)
23:36:11 <goalieca> and the messy imperative numerics in fortran ;)
23:36:26 <P_D> because it's still probably the best imperative language since you have control
23:36:30 <coffeemug> Cale: I mean that because of referential transparency you can copy data around or use pointers and the program won't know the difference (aside from speed)
23:44:21 <dolio> You might not be able to do that unless the types are unboxed.
23:44:26 <tuxplorer> I have this bot, and can I run HAppS on another thread in the same program and be able to access this data structure from the thread?
23:45:20 <tuxplorer> I mean when a webclient  sends a request to the HAppS webservice, would it be able to access this Map?
23:46:02 <coffeemug> arggh, mouse froze again, rbr
