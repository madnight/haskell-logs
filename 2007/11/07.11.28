00:00:08 <skew> or at least sub-optimal. Hmm, can't seem to reproduce that thing where definitions were not exported one build using --make
00:00:24 <skew> well, time to try scaling
00:01:15 <skew> I also managed to get C++ to optimize out the abstraction with templates
00:04:36 <skew> nice to see it optimized without the explicit staging
00:05:14 <skew> hmm, this is interesting - a --make run where another one of the modules was built for the first time seemed to inline its code
00:10:31 <skew> that's not it after all, strange
00:10:50 <skew> and the data structures don't completely go away when I get to nesting pairs :(
00:13:19 <skew> anyway, the issue with inlining seems just to be that GHC was lifting something out of a function as a CAF, which was not interesting to inline, and with it lifted there's no place you can stick the INLINE to make it inline
00:15:20 <andyjgill> Is it really the case that fixity can be declared inside a local binding? Or I am misreading the BNF?
00:16:23 <skew> > let f +|- q = f + 12* q; infixr 3 +|- in 1 +|- 2
00:16:25 <lambdabot>  25
00:17:03 <andyjgill> oh boy.
00:17:08 <dmwit> Okay, what do you call a single-character square in a terminal?  I want to say "pixel" but that's too small.
00:17:28 <goltrpoat> andyjgill:  are you talking about the class bit in topdecl?
00:17:29 <dmwit> > let infixr 3 *; infixr 5 + in 3 + 5 * 7
00:17:30 <lambdabot>   Not in scope: `+'
00:17:47 <int-e> dmwit: a cell perhaps
00:17:51 <rue> dmwit: Column, typically (although it is not strictly accurate)
00:17:56 <goltrpoat> fixity only appears in decl and cdecl, and the latter only appears in class definitions
00:17:59 <skew> I hope you can't override fixities
00:18:05 <dmwit> Okay, thanks.
00:18:40 <skew> but if you should happen to need 24 infix operators in your local definition they probably need fixities as well
00:19:49 <Olathe> Fixodent and forget it.
00:19:51 <andyjgill> I'm reading the online version of the report.
00:20:30 <andyjgill> Never, ever used infix inside a nested decl.
00:21:17 <skew> yeah, probably one of those things where it was just easier to describe "decls" rather than exclude it
00:22:09 <andyjgill> Hi JaffaCake
00:34:55 <needhelp> Hi! I need your help. Iam collecting points in page listed below. If you be so kind, please click url below. http://www.3dwhite.lt/?click=56a3cdcf22ccc7ab5f0a7f4d2bc900ff
00:34:58 <lambdabot> Title: 3D White
00:43:38 <luqui> the type signature for Data.IntMap.intersectionWith looks wrong
00:43:58 <luqui> it's (a -> b -> a) -> IntMap a -> IntMap b -> IntMap a
00:44:04 --- mode: irc.freenode.net set +o ChanServ
00:44:15 <luqui> seems like it should be (a -> b -> c) -> IntMap a -> IntMap b -> IntMap c
00:44:44 <luqui> the type signature for Data.IntMap.intersectionWith looks wrong
00:44:47 <luqui> it's (a -> b -> a) -> IntMap a -> IntMap b -> IntMap a
00:44:50 <luqui> seems like it should be (a -> b -> c) -> IntMap a -> IntMap b -> IntMap c
00:48:06 <luqui> hey, that was easy
00:48:06 <dmwit> luqui: 1. You should be able to write such a function using IntMap's interface.  2. Why are you using IntMap?  It's old, and its age shows.
00:48:29 <luqui> dmwit, 1. how? 2. what should I use instead?
00:48:39 <dmwit> Data.Map is fine
00:48:58 * osfamero1 kicks osfameron 
00:49:03 <osfamero1> nnunley!
00:49:28 <luqui> dmwit, well Data.Map's intersectionWith has the right type signature... so, fine, I will, so there! :-)
00:49:29 <dmwit> As for 1., I assume IntMap has some kind of map :: (a -> b) -> (IntMap a -> IntMap b), which should compose with intersectionWith nicely.
00:49:47 <dmwit> heh =)
00:52:43 <needhelp> Hi! I need your help. Iam collecting points in page listed below. If you be so kind, please click url below.(sorry for the spam, thank you) http://www.3dwhite.lt/?click=56a3cdcf22ccc7ab5f0a7f4d2bc900ff
00:52:43 <lambdabot> Title: 3D White
00:53:23 --- mode: ChanServ set +o glguy
00:53:58 --- mode: glguy set +b *!*@81-7-78-206.ip.zebra.*
00:55:16 <dmwit> Can we get a banhammer on him?
00:55:25 <glguy> banhammer?
00:55:26 <dmwit> Thanks, glguy.
00:55:30 <dmwit> Slam!
00:55:34 <Korollary> hammer time?
00:56:03 --- mode: glguy set -b *!*@81-7-78-206.ip.zebra.*
00:56:03 --- mode: glguy set +b *!*@81-7-78-206.ip.zebra.lt
00:57:08 <osfameron> rarr!
00:57:08 <lambdabot> osfameron: You have 1 new message. '/msg lambdabot @messages' to read it.
00:57:27 --- mode: glguy set -o glguy
00:59:49 <b_jonas> Hi,
01:00:07 <b_jonas> If I want an IO-mutable queue (LIFO), what should I use?
01:00:35 <b_jonas> A linked list with IORef links; an IORef Seq; Control.Concurrent.Chan; or somethig else?
01:00:48 <glguy> Chan is FIFO
01:00:59 <glguy> IORef [a] works well enough
01:01:19 <b_jonas> um, I meant FIFO
01:01:21 <b_jonas> sorry
01:01:26 <b_jonas> a FIFO queue, not a stack
01:02:02 <glguy> Chan is good if you plan to have multiple producers or consumers
01:02:05 <b_jonas> there's a fourth possibility: you could use an IORef IOArray deque-wise (marking empty elements at both ends and resizing on both ends if needed
01:14:10 * sjanssen agrees with glguy, use Chan
01:14:44 <sjanssen> it's automatically thread safe, and you might find the broadcast features useful
01:17:21 <b_jonas> sjanssen: one problem with Chan is that it doesn't have a non-blocking read function
01:17:39 <b_jonas> at least I can't find one in the docs
01:17:48 <sjanssen> b_jonas: use isEmptyChan
01:18:03 <b_jonas> sjanssen: wouldn't isEmptyChan have a race condition with multiple listeners?
01:18:18 <mauke> use TChan
01:18:26 <sjanssen> any non-blocking read function will have a race condition
01:18:27 <b_jonas> TChan?
01:18:47 <b_jonas> sjanssen: no, let me give an example
01:18:54 <mauke> http://haskell.org/ghc/docs/6.6.1/html/libraries/stm/Control-Concurrent-STM-TChan.html
01:19:25 <b_jonas> a nice way to implement a semaphore (QSem is implemented this way) is to have a wakeup queue
01:19:47 <b_jonas> QSem does this with a list in an MBox
01:19:50 <sjanssen> mauke: yes, there is even a good chance that TChan will perform better in this case
01:19:54 <b_jonas> and appends to it with ++
01:20:28 <osfameron> @tell chessguy thanks.  re repo, http://osfameron.vox.com/library/post/monad-wars---code-online.html
01:20:28 <lambdabot> Consider it noted.
01:20:34 <b_jonas> now you could use a channel here
01:20:37 <sjanssen> b_jonas: oh, I see what you mean
01:20:44 <b_jonas> (because ++ for appending would seem slow to me)
01:20:55 <sjanssen> the chan can become empty between isEmpty and readChan
01:21:12 <b_jonas> now for QSem, you don't need non-blocking read, but you can implement a condition variable with a wakeup list the same way
01:21:19 <b_jonas> and there you need a non-blocking read
01:21:21 <b_jonas> sjanssen: exactly
01:21:26 <sjanssen> so use TChan, which guarantees atomicity :)
01:21:50 <b_jonas> hey, that's an STM thing
01:22:02 <b_jonas> I've no idea what transactional memory is and don't want to know
01:22:09 <mauke> you don't need to
01:22:13 <quicksilver> another way to
01:22:17 <mauke> it's a monad, just use it :-)
01:22:27 <quicksilver> another way to do a non-blocking read on a chan is to pair a chan with an MVar ()
01:22:44 <quicksilver> not that I mean to say that's better than using TChan
01:22:56 <sjanssen> b_jonas: STM is fun!
01:23:07 <b_jonas> quicksilver: yes, but then I don't really need a Chan
01:23:25 <b_jonas> that is, the Chan seems unneccessary because I don't need its builtin locking
01:23:49 <b_jonas> that's why I'm asking the queue thing in first place
01:23:58 <quicksilver> if you're not using threads
01:24:01 <quicksilver> why do you need mutable at all?
01:24:05 <quicksilver> why not just use a Seq ?
01:24:07 <quicksilver> or a list?
01:24:17 <quicksilver> FIFO you said, so Seq.
01:24:25 <glguy> the isEmptyChan is blocking
01:24:32 <glguy> (could be important to consider)
01:24:42 <mauke> so it always returns False?
01:24:47 <quicksilver> glguy: eh? isEmptyChan blocks when?
01:24:56 <glguy> when someone is trying to read from an empty chan
01:25:05 <glguy> and then someone else asks "is it empty"
01:25:07 <glguy> it will block
01:25:14 <glguy> until the first reader gets an element
01:25:17 <mauke> wtf
01:25:19 <quicksilver> well yes
01:25:29 <quicksilver> but that's probably faster than haskell's thread scheduling anyway
01:25:33 <quicksilver> getting a point off of a chan
01:25:35 <mauke> where is that documented?
01:25:40 <b_jonas> quicksilver: I want to implement a Chan that supports non-blocking read, and I think the best way to do that is an IO-mutable queue inside an MVar
01:25:41 <quicksilver> is probably faster than a haskell context switch
01:25:52 <quicksilver> b_jonas: are you using threads?
01:25:52 <b_jonas> however, even without threads, people use IORefs and IOArrays
01:25:57 <sjanssen> glguy: no, there's an extra layer of indirection there
01:26:02 <quicksilver> mostly misguided people
01:26:14 <b_jonas> so an IO-mutable queue could make sense without threads too I think
01:26:16 <quicksilver> there are two reasons to use IORefs/MVars in haskell
01:26:21 <quicksilver> (1) threads
01:26:23 <quicksilver> (2) IO () callbacks
01:26:26 <quicksilver> (FFI callbacks)
01:26:27 <glguy> sjanssen: i've seen it block
01:26:33 <glguy> at least in the 6.6.1 impmlementation
01:26:35 <quicksilver> otherwise you don't need them.
01:26:36 <glguy> could have changed in 6.8.1
01:26:40 <b_jonas> quicksilver: I think there's a third
01:26:48 <b_jonas> (for IORefs)
01:26:51 <quicksilver> and that is?
01:27:01 <sjanssen> glguy: I don't think it has, I'm probably mistaken.  Chan is kinda crufty :(
01:27:34 <quicksilver> b_jonas: you code sounds to me like it's screaming out for Seq
01:27:38 <quicksilver> and can be written purely functionally
01:28:47 <b_jonas> quicksilver: that reason is to create and gc state variables dynamically in such a way that they can be accessed or modified in constant-time
01:29:24 <b_jonas> that is, where you could use a MonadState with a very large state
01:29:51 <quicksilver> constant time is a lie
01:29:56 <b_jonas> sure it is
01:30:18 <b_jonas> still, it's I think faster than looking up or modifying an element in a large state
01:30:31 <b_jonas> this is sort of the same situation
01:30:36 <quicksilver> nah
01:30:40 <quicksilver> I totally disagree
01:30:51 <quicksilver> this is a real case of premature optimisation and overcomplication
01:30:56 <quicksilver> drink the kool-aid man!
01:31:00 <quicksilver> use the functional style
01:31:11 <b_jonas> which is why I said Seq or an IORef-linked list at the beginning
01:31:27 <quicksilver> it's *so* much nicer to program with Seq
01:31:28 <opqdonut> IORef-linked list?
01:31:30 <opqdonut> yuck
01:31:32 <quicksilver> than mess with IORefs
01:31:37 <atp> iorefs are evil
01:31:38 <atp> avoid
01:31:39 <atp> avoid
01:31:53 <b_jonas> quicksilver: I think, even if this one isn't, there are also situations where large state is easier to code iwth IORefs than with a single state
01:32:01 <quicksilver> actually there aren't
01:32:06 <b_jonas> or where you need IORefs so the state is gc-ed properly
01:32:12 <quicksilver> !
01:32:18 <quicksilver> that's a really strange claim
01:32:20 <sjanssen> b_jonas: I'm not following this GC argument
01:32:20 <quicksilver> can you back that up?
01:32:27 <opqdonut> everything gets gc'd properly
01:32:36 <b_jonas> quicksilver: I'll try
01:32:37 <opqdonut> as long asyou care about being strict enough and not too strict
01:32:59 <b_jonas> suppose you want to implement an imperative programming language (like lisp) in haskell
01:33:12 <b_jonas> then you need to have mutable cons cells
01:33:27 <b_jonas> and garbage-collect those conses even if they form a cycle
01:33:38 <b_jonas> you can easily do that with IORefs
01:33:51 <b_jonas> (or equivalently IOArrays, STRefs, MVars)
01:34:09 <b_jonas> but I can't see how you could do that easily with a state var
01:34:18 <quicksilver> You might find it convenient to use STRefs for implementing a lisp
01:34:26 <quicksilver> but you might equally choose your own ref implementation
01:34:29 <mauke> yeah, you'd have to write your own GC
01:34:57 <quicksilver> but yes, if you implement a GC'ed language with different semantics from haskell
01:35:00 <quicksilver> you have to implement a GC
01:35:03 <quicksilver> that's not very surprising :)
01:35:19 <sjanssen> b_jonas: one might argue that writing a lisp interpreter is another one of those corner cases -- have you run into this issue in real code?
01:35:46 <b_jonas> quicksilver: even if you don't care about the GC, would you look up the cons cells in a large Map?
01:36:09 <b_jonas> sjanssen: this queue thing exactly
01:36:13 <b_jonas> I know a Seq could work
01:36:14 <mauke> I would!
01:36:19 <b_jonas> but that just seems wrong to me
01:36:24 <b_jonas> because it's stronger than what I need
01:36:35 <b_jonas> because I know I'd just need a list in an imperative language
01:36:41 <sjanssen> b_jonas: I was curious about the GC issue specifically
01:36:46 <mauke> a mutable list is also stronger than what you need
01:37:01 <sjanssen> Seq is similar to what many languages call a "list"
01:37:15 <b_jonas> sjanssen: for the GC, you'd have a similar problem if you wanted to have something like weak refs
01:37:24 <b_jonas> at least so I think
01:37:34 <b_jonas> mauke: then what would I need?
01:37:56 <mauke> no idea, what are you even trying to do?
01:38:03 <b_jonas> sjanssen: well, by list, I mean singly linked list with a pointer to both the head and tail
01:38:09 <b_jonas> mauke: nothing now, just thinking
01:38:16 <b_jonas> perhaps implementing condition variables later
01:38:22 <quicksilver> Seq is the way we model what imperative languages call list
01:38:25 <b_jonas> because I find condition variables convenient
01:38:29 <quicksilver> don't think too hard about how it's implemented
01:38:40 <quicksilver> just believe that it happens to be a clever pure functional way to implement a list
01:38:46 <quicksilver> which gives various kinds of operations efficiently
01:38:49 <quicksilver> (like splice and so on)
01:38:50 <mauke> what's a condition variable?
01:38:59 <b_jonas> mauke: it's a thread thingy
01:38:59 <quicksilver> in some cases more efficient than your imperative code, asymptotically
01:39:07 <mauke> what does it do?
01:39:13 <sjanssen> think of Seq like C++'s deque, which is a reasonable base for a queue
01:39:49 <b_jonas> sjanssen: I can't, because seq is a tree in which you can insert to the middle, or extract a subsequence, or concatenate two, each efficently
01:39:58 <b_jonas> mauke: it's an object that has two operations:
01:40:02 <glguy> @paste
01:40:02 <lambdabot> Haskell pastebin: http://hpaste.org/new
01:40:06 <sjanssen> b_jonas: you don't have to use those features :)
01:40:25 <glguy> the system is down, yo :(
01:40:47 <b_jonas> wait, which has a cond var and a mutex as its argument, it unlocks the mutex, then waits for the condvar to be signalled, then locks the mutex
01:41:22 <b_jonas> and signal which only needs a condvar and signals the condvar so if anyone is waiting on it, one of those are woken up
01:41:46 <mauke> complicated
01:41:55 <b_jonas> and there's a guarantee that if the mutex is unlocked and another thread locks it and then signals the condvar, then it surely gets woken up
01:42:08 <b_jonas> because if no-one is waiting on the cond var, then signal is a no-op
01:42:14 <b_jonas> mauke: it is, yes, but it's useful
01:42:21 <b_jonas> I've used it in ruby for threads things
01:42:23 <mauke> I don't see how
01:43:00 <b_jonas> for lightweight concurrencly (like haskells)
01:43:01 <skew> Chan is probably the best match
01:43:14 <skew> unless for some reason it is critical that events fall through the cracks if nobody is watching
01:43:26 <b_jonas> skew: as I've said, I'd need a non-blocking read for Chan to implement a condvar
01:43:32 <mauke> how would I do this with STM?
01:43:43 <b_jonas> mauke: I've no idea, dunno what STM is
01:43:51 <skew> why do you need the non-blocking read?
01:43:56 <b_jonas> I can try to explain why condvars are useful
01:44:03 <skew> you read from the Chan to block
01:44:12 <skew> if you get an item you are woken up
01:44:36 <mauke> please do
01:45:01 <skew> how are the different from semaphores again?
01:46:54 <quicksilver> hmm
01:47:04 <quicksilver> I'm reading about condition variables on various web pages
01:47:08 <quicksilver> it's looking like MVar () to me ?
01:47:21 <skew> mauke: all these things are quite easy to implement with STM
01:47:40 <sjanssen> the fair wake-up property seems difficult with STM
01:47:43 <skew> mauke: for semaphores just have a variable and increment/decrement inside your block, etc
01:48:13 <skew> your STM needs to be fair to get fair abstractions
01:48:36 <b_jonas> the point of condition variables is to implement more complicated objects that have blocking operations
01:48:51 <b_jonas> the blocking operations block until some condition is satisfied
01:48:58 <b_jonas> you implement them this way:
01:49:08 <b_jonas> you have a mutex and a cond var in the object
01:49:22 <b_jonas> (or a mutex and multiple cond vars in more complicated cases)
01:49:24 <mauke> atomically $ do { when (condition_false) retry; ... }
01:49:44 <b_jonas> mauke: that's a busy-loop
01:49:48 <mauke> b_jonas: no
01:49:53 <sjanssen> b_jonas: not exactly
01:50:02 <b_jonas> what does retry mean then?
01:50:05 <skew> MVar () seems to be equivlent
01:50:12 <b_jonas> skew: no, it isn't
01:50:21 <skew> why not?
01:50:28 <quicksilver> according to one of the web pages I read, a condition variable is like an MVar () except you use tryPut not put
01:50:32 <quicksilver> but web pages are not reliable...
01:50:39 <mauke> Retry execution of the current memory transaction because it has seen values in TVars which mean that it should not continue (e.g. the TVars represent a shared buffer that is now empty). The implementation may block the thread until one of the TVars that it has read from has been udpated.
01:50:50 <b_jonas> let me give a more concrete example of such an object:
01:51:14 <skew> b_jonas: in that case retry means "block until the value of condition_false changes"
01:51:34 <b_jonas> skew: yes, and to do that, you need cond vars
01:51:45 <b_jonas> for "block until the value of condition_false changes"
01:51:47 <skew> b_jonas: or something like a transactional memory implementation
01:51:56 <mauke> b_jonas: no, I just need retry
01:52:01 <b_jonas> I don't know anything about transactional memory
01:52:04 <b_jonas> maybe that's the problem
01:52:13 <mauke> what's there to know?
01:52:39 <b_jonas> I don't know what it means
01:52:45 <b_jonas> other than that it's a new buzzword
01:52:52 <skew> condition variables are just one sort of concurrency primitive, and not all that primitive a one at that
01:52:55 <quicksilver> it means that nothing really changes until you commit
01:52:57 <mauke> STM is a monad with mutable variables (TVar)
01:53:03 <skew> well, pretty primitive I guess
01:53:08 <quicksilver> like a database transaction
01:53:24 <quicksilver> so you can have a set of mutations which are either all successful or none
01:53:32 <b_jonas> quicksilver: I see
01:53:34 <zeeeee> is hpaste.org down?
01:53:35 <quicksilver> although with retry semantics which most database actually don't have
01:53:36 <skew> but the stuff about signals getting ignored seems kind of weird
01:53:39 <quicksilver> which is a nice win :)
01:53:51 <skew> as in, makes edge cases :(
01:53:56 <b_jonas> so what's this retry semantics?
01:53:57 <sjanssen> zeeeee: yeah
01:54:15 <quicksilver> b_jonas: you can abort the transaction (all current changes roll back) but request that it's run again
01:54:24 <quicksilver> b_jonas: potentially it keeps tryign until it gets through
01:54:24 <skew> b_jonas: retry just says "give up on this transaction"
01:54:35 <quicksilver> so if two conflicting transactions occur...
01:54:48 <quicksilver> one gets through first time and then the second gets through when the first has finished, perhaps.
01:55:01 <b_jonas> and does that allow me to wait until a condition becomes true?
01:55:18 <sjanssen> b_jonas: yes, trivially
01:55:22 <b_jonas> liek skew said in "block until the value of condition_false changes"
01:55:27 <mauke> yes, you just retry if the condition is false
01:55:28 <sjanssen> guard condition
01:55:38 <sjanssen> (because mzero = retry)
01:55:41 <skew> yeah, just set up the trasaction to "retry" if it is false, then it can't complete unless/until the condition is true
01:55:59 <quicksilver> is the STM docs broken?
01:56:00 <b_jonas> so retry will block
01:56:01 <b_jonas> ?
01:56:08 <quicksilver> I can't find the page which documents retry...
01:56:22 <b_jonas> that is, it will block until another transaction occurrs to retry after it?
01:56:26 <skew> I think "Composeable Memory Trasnactions" is the one to look for
01:56:33 <mauke> http://haskell.org/ghc/docs/6.6.1/html/libraries/base/GHC-Conc.html#v%3Aretry
01:56:41 <skew> b_jonas: until another transaction has changed the variables that it read to decide to fail, in fact
01:56:46 <sjanssen> quicksilver: GHC.Conc IIRC
01:56:47 <quicksilver> mauke: thanks
01:57:00 <skew> so a bunch of transactions can touch unrelated variables and your thread is still blocked
01:57:01 <sjanssen> quicksilver: it's the stupid cross-package documentation bug again
01:57:10 <b_jonas> skew: I see
01:57:24 <skew> so condition variables don't track how many times they've been notified?
01:57:28 <b_jonas> well then yes, that replaces condition variables
01:57:39 <b_jonas> condition variables are for the same purpose:
01:57:55 <b_jonas> you have a single mutex for an object that you lock in every method so that every change or read is atomic
01:58:02 <quicksilver> sjanssen: yeah, I understand now
01:58:08 <b_jonas> and you have a condition variable for every property you may want to wait for
01:58:27 <b_jonas> which you signal when you change that property to true
01:58:49 <skew> do they at least track whether there is an outstanding notification?
01:58:51 <b_jonas> so those methods that block do, like,
01:59:20 <b_jonas> until (property) { condvar.wait(mutex) }
01:59:33 <b_jonas> which unlocks the mutex so that other changes can happen
01:59:57 <b_jonas> if there's no-one waiting, then signal wakes up no-one
02:00:13 <b_jonas> but it can't happen that the mutex is already unlocked by a waiter but it's not listening to the signals
02:00:18 <skew> that translates to STM, except you don't need to bother allocating mutexes or conedition variables, or associating them with objects, or updating them
02:00:32 <quicksilver> ok, I understand condition variables
02:00:34 * quicksilver ponders
02:00:35 <skew> if you have a bunch of stuff you want to do atomically, do it in a trasnaction in "atomically"
02:00:53 <b_jonas> quicksilver: also, condvars have a broadcast method that wakes up every waiter, not just one
02:01:07 <b_jonas> it's often more useful than signal which wakes up just one
02:01:14 <quicksilver> hmm
02:01:14 <skew> if you want to wait for some contion to be true, then in you transaction test if the condition is true and retry otherwise
02:01:21 <quicksilver> but presumably they wake up one at a time
02:01:24 <quicksilver> skew: I don't think so, no
02:01:29 <b_jonas> which one you use depends on whether the methods "consume" the property
02:01:30 <skew> quicksilver: so if you understand them, does the variable have any state?
02:01:31 <quicksilver> skew: that would rollback the changes you've made so far
02:01:37 <b_jonas> quicksilver: yes, because they re-lock the mutex
02:01:48 <quicksilver> b_jonas: right, yes, I think I understand
02:02:10 <b_jonas> skew: I see
02:02:59 <skew> b_jonas: the interesting thing with STM is that you can sequence together the operations making up a trasnaction before you run it atomically
02:03:42 <b_jonas> skew: doesn't convince me
02:03:50 <skew> so you can take the "get item from queue K" and "put that item on queue M" operations together into one big transaction, and don't have to worry about other threads seeing a state where the object is nowhere
02:03:52 <b_jonas> I can hold a mutex for many operations
02:04:41 <sjanssen> b_jonas: http://paste.lisp.org/display/51504
02:04:41 <skew> again, all of this without inventing some new mutex to guard that particular combination of queue, or putting a global order on the mutexes or antyhing else
02:04:59 <skew> also, you can convert freely between blocking and non-blocking operations
02:05:12 <sjanssen> b_jonas: there's an IO queue based on STM, notice the definition of dequeue
02:05:46 <sjanssen> this is an example of skew's point about recovering non-blocking operations from blocking ones
02:06:27 <mauke> @index Data
02:06:27 <lambdabot> Data.Generics.Basics, Data.Generics
02:06:48 <skew> (and we've already mentioned you can go the other way with retry)
02:07:38 <quicksilver> I don't see a really straightforward mapping of condvars to MVars with the global-wakeup property
02:07:51 <quicksilver> the single-wakeup would be easier
02:07:51 <skew> which global-wakeup?
02:08:02 <skew> oh, if you want to wake them all up
02:08:05 <quicksilver> the notion that you can wake all threads blocking on a particular condition
02:08:18 <quicksilver> I think I"d want to see some real use cases
02:08:20 <skew> yeah, that is trickier
02:08:27 <b_jonas> sjanssen: in my head, the hierarchy for implementing stuff is like this: mutex -> atomic (wakeup) queue with only non-blocking read -> condition variable -> queue with blocking read
02:08:31 <quicksilver> because I haven't grasped why condvar + object mutex is a good programming style yet
02:08:37 <b_jonas> where x -> y means you implement y using x
02:08:41 <quicksilver> to me it sounds a bit weird
02:08:48 <quicksilver> but maybe it's just different
02:09:03 <skew> I think you'd have to keep inventing new shared variables, and not have them remove the variable
02:09:14 <skew> like MVar (MVar ())
02:09:18 <quicksilver> hmm
02:09:20 <b_jonas> you can implement condvars in other ways, but they are mostly either bad or need to be done in the os/threadlibrary-level
02:09:27 <quicksilver> actually
02:09:43 <quicksilver> maybe an MVar (Bool,Bool,Bool,Bool,....)
02:09:46 <quicksilver> that's all your conditions
02:09:48 <quicksilver> plus a Chan ()
02:09:49 <skew> and wake would be like wake k = do v <- get k; put v (); v' <- newEmptyMVar; put k v'
02:09:51 <quicksilver> to wake people up
02:10:00 <sjanssen> b_jonas: STM turns this hierarchy upside down
02:10:08 <skew> quicksilver: but then you want to signal again?
02:10:24 <b_jonas> quicksilver: as for waking up everyone, consider this:
02:10:25 <skew> quicksilver: and what if some thread that blocked a long time ago hasn't even been scheduled yet
02:10:40 <b_jonas> you have a money counter which is a non-negative real,
02:10:42 <skew> quicksilver: I think that's why you'd need to keep allocating and installing a new empty mvar each time
02:10:45 <b_jonas> and you have two operations:
02:10:57 <b_jonas> one is to have earned a given amount of money
02:11:23 <b_jonas> (which just increases the amount and signals the condvar, all under locking)
02:11:34 <b_jonas> and the other is to spend an amount of money
02:11:48 <quicksilver> what is the condition supposed to represent in this case? Just "something has changed"?
02:12:02 <skew> "you've got some more money"
02:12:03 <b_jonas> the condition means that you have more money than you used to
02:12:07 <quicksilver> ah, ok
02:12:22 <skew> as in "you might possibly have enough money now" as in "actually re-execute the trasnaction"
02:12:26 <b_jonas> the spender waits on the condvar until the amount is at least the amount you wait for,
02:12:29 * quicksilver nods
02:12:31 <b_jonas> then subtract it
02:12:49 <b_jonas> there can be more threads waiting to spend, and you want to wake up all of them
02:12:56 <quicksilver> I would use a Chan () for that
02:12:59 <b_jonas> though some of them might not actually succeed
02:13:04 <b_jonas> Chan?
02:13:08 <quicksilver> you send a () down the Chan when you've increase the amount
02:13:11 <skew> queue with blocking read
02:13:15 <quicksilver> and that wakes up all the threads blocking on it
02:13:30 <skew> what do you mean "non-blocking read" anyway, like unsynchronized?
02:13:39 <b_jonas> skew: no
02:13:49 <quicksilver> skew: non-blocking read means you can read from an empty queue and you get 'empty'
02:13:53 <b_jonas> it's synchronized, but if the queue is empty, it returns rightaway
02:13:54 <quicksilver> instead of failing to read at all
02:14:08 <quicksilver> at least, that's what I understood b_jonas to mean
02:14:22 <mauke> atomically $ do { x <- readTVar money; guard $ x >= 42; writeTVar money (x - 42) }
02:14:23 <skew> oh, and it doesn't provide the blocking operation as an option
02:14:27 <b_jonas> so it's just a fifo queue with push and shift, protected with a mutex
02:14:38 <b_jonas> skew: yes
02:14:45 <quicksilver> you could model it with MVar [a]
02:15:18 <skew> funny, Chan doesn't quite give you that read, just isEmpty and the blocking read
02:15:25 <b_jonas> quicksilver: my problem with that is that you need to use ++ then
02:15:38 <skew> you could of course make one from TChan...
02:15:44 <dmwit> :t (<$)
02:15:45 <lambdabot> forall a (f :: * -> *) b. (Functor f) => a -> f b -> f a
02:15:46 <b_jonas> which seems it may be quadratic
02:15:52 <quicksilver> read = do { a <- readMVar mv; case s of [] -> do { putMVar mv []; return Nothing} ; (x:xs) -> do {putMvar mv xs; return x} }
02:15:59 <dmwit> :t ($>)
02:15:59 <quicksilver> b_jonas: bit long for a one liner, but no ++ there
02:15:59 <lambdabot> Not in scope: `$>'
02:16:12 <quicksilver> b_jonas: return x should be return (Just x), sorry
02:16:36 <b_jonas> quicksilver: how would you write in that case?
02:16:46 <sjanssen> http://paste.lisp.org/display/51504#1 bank accounts are easy with STM
02:16:49 <skew> b_jonas: that's why Data.Sequence has constant time operations from either end
02:16:52 <quicksilver> write = modifyMVarPure (x:)
02:17:02 <quicksilver> sorry, this is LIFO
02:17:03 <quicksilver> not FIFO
02:17:05 <skew> or okasaki can suggest various other implementations
02:17:09 <quicksilver> with FIFO replace it with Seq
02:17:09 <b_jonas> sjanssen: it's not actually a real bank account, just something else I wanted to limit
02:17:23 <b_jonas> quicksilver: exactly
02:17:25 <b_jonas> and I'd like fifo
02:17:30 <quicksilver> use Seq then :)
02:17:43 <b_jonas> yes, that's what I'll probably do
02:17:49 <b_jonas> it's just logarithmic after all
02:17:52 <quicksilver> modifyMVarPure isn't in the standard lib
02:17:57 <quicksilver> much to my annoyance
02:18:03 <quicksilver> modifyMVar is mis-named.
02:18:05 <b_jonas> ok
02:18:07 <skew> b_jonas: constant time operations, actually
02:18:15 <quicksilver> modifyMVar should be called withMVar
02:18:27 <quicksilver> modifyMVar_ should be called withMVar_
02:18:33 <quicksilver> and modifyMVar should be pure
02:18:39 <quicksilver> but, libraries@ didn't agree :)
02:18:49 <mauke> @doc Language.Haskell.Extension
02:18:49 <lambdabot> Language.Haskell.Extension not available
02:19:10 <skew> b_jonas: read this http://research.microsoft.com/%7Esimonpj/papers/stm/index.htm#composeble
02:19:21 <skew> b_jonas: and you will see why we are not so excited about condition variables
02:19:40 <quicksilver> b_jonas: I think this mutex/condvar is interesting, but I can't see a real example where I couldn't do something simpler (IMO simpler) with Chans and MVars
02:19:40 <skew> they even explain how it's built from mutexes
02:19:51 <quicksilver> b_jonas: however, that may mean I haven't seen the right example yet.
02:19:59 <quicksilver> and 'simpler' is definitely subjective here.
02:20:18 <skew> quicksilver: notification with a Chan doesn't seem much different from a condition variable
02:20:36 <skew> except you can carry data and keep around old events and so on.
02:20:36 <b_jonas> though if I'm in IO anyway, then is a Seq-based deque better than an IOArray-based dequeue?
02:20:48 <quicksilver> yes
02:20:50 <mauke> probably
02:20:55 <quicksilver> IOArrays are horrible to use
02:21:00 <quicksilver> Seq is beautiful
02:21:03 <quicksilver> drink the Kool-Aid :)
02:21:21 <skew> an IOArray is fixed-size anyway
02:21:32 <b_jonas> skew: sure, but you can reallocate it
02:21:37 <quicksilver> skew: well presumably he's thinkinf of managing empty elements manually
02:21:46 <b_jonas> yes, that's just two ints
02:21:48 <atp> internally, what is seq? 2-3 finger trees or something?  (/me just read the paper on those)
02:21:49 <quicksilver> but who wants to write all that code for managing empty elements which might contain bugs...
02:21:55 <quicksilver> atp: yes.
02:21:56 <mauke> b_jonas: you mean allocate another array?
02:22:02 <b_jonas> mauke: yes
02:22:05 <atp> 2-3 finger trees are pretty cool
02:22:10 <quicksilver> you do start point and end pointer
02:22:12 <b_jonas> like how the c++ dequeue works
02:22:14 <quicksilver> and only reallocate if you overflow
02:22:15 <b_jonas> or how perl arrays work
02:22:17 <quicksilver> just like you would in C++
02:22:19 <quicksilver> but why bother
02:22:22 <mauke> b_jonas: so you have something like an IORef (IOArray ...) and a few IORef Ints?
02:22:23 <quicksilver> that's a lot of pointless hard work :)
02:22:34 <b_jonas> quicksilver: seq does more pointless hard work imo
02:22:35 <quicksilver> mauke: IORef(Int,Int,IOArray...) rather
02:22:41 <quicksilver> b_jonas: not work you for you.
02:22:49 <quicksilver> it's already written, it's pure
02:22:49 <b_jonas> mauke: no just an MVar (Int, IOArray, IOArray)
02:22:55 <skew> b_jonas: it's in the libs, the asymptotic complexity is right
02:23:02 <mauke> MVar is like an IORef, only worse
02:23:13 <b_jonas> quicksilver: an array-based dequeueueue is much easier to code than a seq-based one
02:23:23 <mauke> what?
02:23:29 <atp> b_jonas: you're not writing it, it's already been written
02:23:30 <mauke> I'd like to see that
02:23:32 <skew> Seq is a deque already
02:23:32 <b_jonas> so even if I don't write seq, it will seem extra complexity to me
02:24:06 <b_jonas> skew: yep. Seq is what's difficult to write
02:24:12 <goalieca> @src seq
02:24:12 <lambdabot> Source not found.
02:24:22 <sjanssen> if you want to waste time writing this code, feel free
02:24:42 <b_jonas> even the simplest tree thingy (either treap or 2-3 tree or red-black tree) is more complicated than an array with bounds-check
02:24:44 * sjanssen would take the easy way out :)
02:24:49 <atp> sjanssen: that's not nice.  he'll come around eventually, or he'll go back to writing C++ or similar.
02:24:57 <b_jonas> I only have to write it once
02:25:04 <dmwit> > let test[ x = x in test[ 3
02:25:04 <lambdabot>  Parse error at "=" (column 13)
02:25:08 <mauke> I only have to write it never
02:25:10 <sjanssen> b_jonas: you have to write Seq 0 times :)
02:25:12 <skew> isn't the worst time on any operation in Seq logarithmic in the total size?
02:25:20 <b_jonas> skew: yes it is
02:25:20 <atp> skew: it's amortized O(1)
02:25:29 <b_jonas> oh wait, fingered
02:25:35 <skew> I mean any single append at the head, which is amortized of course
02:25:35 <b_jonas> then maybe it's amortized O(1)
02:25:43 <atp> it's definitely amortized O(1)
02:25:47 <atp> easy to prove...
02:25:50 <b_jonas> I don't know those fingered or self-organized trees
02:25:51 <skew> how much laziness can pile up, is the question
02:25:58 <goalieca> O(log(n)) < 10 for all n :D
02:26:10 <atp> skew: if you're smart about forcing strictness (which i'm sure the library is) not much
02:26:30 <quicksilver> I doubt <| and |> force
02:26:35 <b_jonas> goalieca: yep, it's constant, but an array doesn't have too large a constant factor either
02:26:47 <skew> and, what kind of incremental array-copying scheme givies you deques with no copying pauses longer than a few elements?
02:26:51 <b_jonas> (it's amortized O(1) too)
02:27:00 <sjanssen> quicksilver: Seq are effectively spine strict
02:27:09 <b_jonas> skew: amortized
02:27:10 <atp> but arrays are ephemeral... you're writing haskell here, we like persistent data structures
02:27:15 <quicksilver> sjanssen: yes, but are <| and |> strict?
02:27:23 <skew> atp: yeah, I was getting to that
02:27:38 <skew> b_jonas: but also the worst case bound on any operation in the sequence is interesting
02:27:47 <b_jonas> skew: yes, that's true
02:27:51 <sjanssen> quicksilver: yes, I believe they are
02:27:57 <skew> b_jonas: oh, and then figure out how to make those deques catenable
02:28:02 <quicksilver> Seq supports  bunch of interesting tricks like efficient istory and undo
02:28:05 <b_jonas> skew: I don't need that
02:28:08 <skew> and confluently persistent...
02:28:17 <b_jonas> if I want them catenable, then yes, I'll use Seq
02:28:25 <b_jonas> Seq has a place
02:29:23 <b_jonas> as for worst case bound, let's see
02:29:34 <b_jonas> does haskell have an incremental gc with O(1) allocation now?
02:30:00 <atp> b_jonas: i have to wonder why you care
02:30:08 <b_jonas> atp: I don't
02:30:08 <sjanssen> b_jonas: array allocations are O(n) because they must be initialized
02:30:12 <skew> the allocation is quite cheap
02:30:30 <b_jonas> skew: you brought up worst case bounds
02:30:34 <b_jonas> I don't care about those
02:30:39 <b_jonas> so that's not a problem with arrays
02:30:39 <skew> GC is generational
02:30:54 <b_jonas> with arrays it's still amortized O(1)
02:31:00 <atp> b_jonas: if you want speed, you could write C or assembly.  you're writing haskell.  why try to be close to the metal in a language that is designed to abstract it from you?
02:31:17 <quicksilver> I thought an unbounded array was O(log n) at best?
02:31:23 <quicksilver> because of the copying when it grows?
02:31:38 <b_jonas> quicksilver: I think it's amortized O(1)
02:31:44 <atp> he's right i think...
02:31:48 <b_jonas> because you're copying it only at every two-power
02:31:48 <skew> if you grow exponentially the copying costs converge
02:32:05 <atp> ok guys i have to hit the sack
02:32:07 <atp> goodnight all
02:32:12 <b_jonas> night, atp
02:32:17 <goalieca> moi too
02:32:24 <b_jonas> (is atp named from the molecule?)
02:32:52 <b_jonas> but atp has a point about me prematurely optimizing
02:32:56 <b_jonas> I am prone to that
02:32:57 <skew> to some multiple of the inverse of your average allocated but unsued memory, I think
02:33:10 <desegnis> Out of curiosity, since it came up on the mailing list: What could Data.Collections.Map buy me over Data.Map?
02:33:23 <b_jonas> skew: so it's incremental. good.
02:33:32 <b_jonas> thanks
02:33:47 <skew> b_jonas: generations, not some kind of hard-realtime incremental
02:34:15 <b_jonas> skew: dunno, I still don't completely understand all this gc business
02:34:18 <skew> IOArrays will probably suck on the performance anyway
02:34:23 <b_jonas> I've read some papers but not too much
02:34:38 <b_jonas> would they?
02:34:45 <b_jonas> aren't IOArrays just plain mutable arrays?
02:34:50 <skew> to hold any kind of object it's an array of pointers
02:34:52 <taruti> incremental has better worst case time bounds, but it is slower in the common case.
02:35:07 <swiert> @seen mattam
02:35:07 <lambdabot> mattam is in ##logic and #haskell. I don't know when mattam last spoke.
02:35:12 <skew> to keep the basic sanity of the language intact bounds are always checked
02:35:41 <b_jonas> taruti: does that have to do with that an incremental can process an array in pieces?
02:36:16 <b_jonas> skew: hmm
02:36:22 <taruti> b_jonas: depends on the incremental collector.
02:36:31 <b_jonas> ok
02:36:56 <quicksilver> depends how arrays are implemented under te hood too
02:37:16 <quicksilver> haskell makes no promise that arrays are allocated in contiguous memory
02:37:22 <quicksilver> although I imagine that's what GHC does
02:37:28 <quicksilver> (just the pointers, though, as skew points out)
02:37:34 <skew> arrays have to be funky in an incremental copying collector
02:37:36 <quicksilver> the actual data could be everywhere or nowhere.
02:38:06 <quicksilver> skew: is an array significantly different from a huge tuple?
02:38:18 <skew> um
02:38:57 <skew> yes, it's not as similar as you might thing
02:39:10 <quicksilver> why's that?
02:39:16 <b_jonas> quicksilver: you can think of even a huge tuple as O(1) size
02:39:30 <quicksilver> eh?
02:39:30 <skew> they are completely homogeneous and a lot bigger so they get represeneted differently in the runtime
02:39:39 <b_jonas> so if an incremental collector does work linear in the size of the tuple, you can still say it's O(1)
02:39:44 <skew> you can type an indexed lookup without trouble
02:39:57 <b_jonas> but if it does work linear in a size of an array, you don't say that
02:40:08 <b_jonas> so you can't call it incremental if it does that in one step
02:40:14 <quicksilver> oh, I see
02:40:29 <quicksilver> yes
02:41:45 <b_jonas> and really, I've seen large tuples (records) in real programs, but not so huge ones as the largest arrays I've ever allocated in code I wrote
02:42:32 <skew> b_jonas: part of the point of using Haskell at all is to be able to design code so it's easy to get right
02:43:14 <b_jonas> yes, that's the advantage of pureness and the type system
02:43:28 <b_jonas> the type of a function specifies what side effects it can have
02:45:31 <skew> b_jonas: trees where you just have to think about what happens around one node vs. index arithmetic and various arrays, using immutable values to remove the time dimension, controlling concurrency with atomicity to limit interleaving rather than manually manipulating (any maybe forgetting) mutexes and conditional variables and so on
02:45:41 <skew> did I mention STM can't deadlock?
02:46:45 <scook0> skew: you can still get protocol deadlock
02:46:49 <skew> yep
02:46:55 <scook0> e.g. if you use STM to reimplement traditional locks
02:47:02 <quicksilver> skew: how about using zippers to get local modification in constant time whilst permitting efficient undo and good sharing between past + future?
02:47:07 <sjanssen> STM can livelock (though it is improbable)
02:47:11 <b_jonas> as for "STM can't deadlock",
02:47:31 <sjanssen> starvation is also an issue
02:47:35 <b_jonas> I can use a single mutex in the whole program and than mutex-condvars can't deadlock either
02:47:37 <skew> but for plain old mutal exclusion, some transaction will complete
02:47:50 <quicksilver> MVars are also remarkably good at detecting deadlocks which is rather neat, too.
02:48:00 <b_jonas> I don't know how much STM is better than that
02:48:06 <skew> quicksilver: it actually comes from garbage collection!
02:48:09 <scook0> sjanssen: what exactly do you mean by livelock?
02:48:18 <b_jonas> though maybe it's better on multiple processors
02:48:21 <sjanssen> b_jonas: doesn't that kill concurrency?
02:48:23 <scook0> I was under the impression that an STM system enjoys global progress
02:48:24 <skew> sjanssen: isn't that also protocol livelock?
02:48:30 <scook0> (but not necessary local progress)
02:48:34 <b_jonas> sjanssen: it kills being parallel
02:48:51 <b_jonas> but I'm also interested about just concurrency
02:48:51 <roconnor> @yow
02:48:52 <lambdabot> What a COINCIDENCE!  I'm an authorized "SNOOTS OF THE STARS" dealer!!
02:49:06 <b_jonas> for io
02:49:13 <skew> b_jonas: under STM, two atomic sections can only interfere if they use the same variable
02:49:21 <b_jonas> for example, my irc server uses concurrency heavily, but doesn't really use parallels
02:49:36 <scook0> i.e. if one transaction stalls (without using retry), it's because another transaction succeeded
02:50:00 <roconnor> @bab nl en Eucharistieviering
02:51:07 <skew> b_jonas: which is quite a lot better than one thread at a time
02:51:14 <sjanssen> oh, I think I'm incorrect about livelock, sorry
02:51:30 <b_jonas> skew: yes, that's true
02:51:47 <skew> really, that's about as good as it can get
02:52:18 <skew> heck, even if your code doesn't synchronize the memory location your CPUs will fight over the cache line
02:53:39 <wli> Kernel work inures you to obscure serialization protocols.
02:54:45 <skew> but it's not really about the performance - it's about having a model that makes it easy to make a program that works, and to make a bigger program out of smaller programs, and lets you design your program to at least have certain asymptotic performance
02:55:17 <b_jonas> skew: yes, I'll have to look at STM one time probably
02:55:24 <b_jonas> it might be a good paradigm
02:56:11 <b_jonas> the performance isn't important at all in the irc bot
02:56:14 <skew> it's not *entirely* coincidental that this stuff can all be implemented so it all gives fairly decent absolute performance, and even when you haven't been too careful with your source program
02:57:44 <wli> High-performance serialization protocols can get very tricky. Tombstones, retries, etc. STM probably manages to hide things like that on account of referential transparency.
02:58:03 <skew> sjanssen: starvation is hard to avoid anyway
02:58:31 <b_jonas> skew: yes, it is
02:58:34 <wli> Starvation is trivial to avoid barring performance considerations.
02:58:38 <skew> what do you do if one of your threads is while (true) { find a proof of Riemann hypothesis; print "hi"}
02:58:42 <b_jonas> my irc bot has serious bugs in that respect
02:59:01 <b_jonas> in fact, my bot even has basic locking problems and wrong design wrt concurrency
02:59:13 <skew> running the proof search in a transaction
02:59:44 <skew> that's really more complicated than it needs to be - just think of anything where something that takes a long time conflicts with short jobs
03:00:18 <skew> either the short jobs sometimes have to wait a long time (forever? halting-problem), or the long job keeps getting edged out by the short jobs
03:00:51 <skew> wli: I think it's the referential transparency that keeps STM simple
03:01:04 <b_jonas> lots of bugs
03:01:07 <skew> wli: don't like this run? don't promote your new value, nobody else cares
03:01:57 <quicksilver> b_jonas: I believe that the haskell primitives (MVar and Chan, even ignoring STM) are well-chosen
03:02:06 <quicksilver> b_jonas: because they appear to make it easy for me to write correct code
03:02:11 <quicksilver> of course I could be wrong :)
03:02:15 <b_jonas> quicksilver: Chan definitely is
03:02:20 <quicksilver> (there might be subtle bugs I don't understand)
03:02:24 <quicksilver> but it seems to work so far.
03:02:27 <b_jonas> I'm using chanels at lots of places
03:02:56 <b_jonas> (though it's actually not a primitive)
03:03:12 <skew> b_jonas: it's probably the locks, or data shared other than by passing it over a channel
03:03:34 <skew> b_jonas: big point - in Haskell you can share the pure data with no problems between lots of threads
03:04:07 <skew> (actually laziness means theres some trickiness between the scenes about which threads evaluate what)
03:04:14 <b_jonas> skew: can't you do that in other languages too?
03:04:16 <xpika> Are there any tutorials on writing a haskell pre-processor without using Template Haskell.  I want to translate invalid haskell to valid haskell to add a feature.
03:04:45 <skew> b_jonas: the problem is that in most languagess it is hard to see if you accidentally change the data somewhere
03:04:59 <mauke> I don't understand the coverage condition
03:05:13 <yaxu> any suggestions for how to make a graph of my program, showing which functions call which other functions?
03:05:29 <skew> xpika: I haven't heard of any tutorials
03:05:47 <yaxu> i mean turn some haskell modules into a dot file for feeding into graphviz
03:05:52 <takamura> hello
03:06:06 <b_jonas> skew: true, though some impure languages have both mutable and immutable languages, so if you use the right programming style you can see it
03:06:44 <skew> b_jonas: the problem is seeing when you've failed to use the right programming style, or when you thought that library function was pure...
03:07:30 <b_jonas> skew: yep.
03:07:45 <skew> b_jonas: and laziness makes it a bit more interesting anways, because you can describe the computation but it doesn't actually unfold until needed, and all that works even when the value is shared between thread
03:07:58 <b_jonas> I don't think I share much immutable data between threads in my bot though
03:08:03 <wli> Try shared library updates.
03:08:06 <skew> xpika: there are some examples of preprocessors
03:08:17 <wli> Imperative problems are worse than you suppose.
03:08:46 <b_jonas> um,
03:08:56 <b_jonas> shared library updates?
03:09:03 <b_jonas> wli: yes, I know
03:09:33 <b_jonas> I have several locking bugs in my bot
03:09:46 <b_jonas> and one part of it has a particularly bad design I'm ashamed of
03:09:56 <b_jonas> (it involves raising signals in threads)
03:10:00 <b_jonas> (it was a bad idea)
03:10:42 <skew> xpika: maybe the arrow preprocessor? maybe DrIFT? Maybe Liskell?
03:11:03 <xpika> skew: I'll chcek the arrows one
03:11:24 <wli> The program author(s) have no idea the shared library updates is coming. The shared library authors have no idea of the dependencies. Neither sees any sort of issue directly; only some unwitting user updating shared libraries sees it.
03:11:48 <skew> wli: oh, you are just talking about upgrades in general
03:11:49 <koredn> Hi, I got a error in my Haskell code, I don't quite get, what it means, and google does not really help me. The source extract: http://phpfi.com/279437; The error: "ERROR "scanner.hs":18 - "myscan" multiply defined" (line 18 is line 2 in my case). Can you point me to the error, or to some documentation on this type of errors?
03:12:01 <skew> wli: I thought you meant upgrading them while a program is running!
03:12:37 <wli> skew: Without a type system expressing purity/etc. it's all a horrible mess.
03:12:45 <skew> wli: the solution is simple, dependently-typed linkers
03:12:59 <pejo> skew, yeah right.
03:12:59 <mauke> koredn: irc.hs:2:9: Not in scope: `isNumber'
03:13:39 <scook0> koredn: the compiler seems to think you're trying to give multiple definitions of myscan
03:13:54 <quicksilver> koredn: you haven't showed us all the code :)
03:14:04 <quicksilver> koredn: but you must have separated your myscan clauses with another function
03:14:11 <quicksilver> you have to keep all the equations for one definition, together
03:14:37 <b_jonas> quicksilver: do you have to keep the type sig together with the equations as well?
03:14:41 <sjanssen> @remember skew the solution is simple, dependently-typed linkers
03:14:41 <lambdabot> I will never forget.
03:14:46 <quicksilver> b_jonas: I don't recall :)
03:14:51 <b_jonas> let's try
03:14:56 <skew> no, this library doesn't export "max", some random symbol, or even "int max(int,int)", it's "max:(x:int)->(y:int)->(n:int|(n=x\/n=y)/\n>=x/\n>=y}"
03:15:06 <b_jonas> > let { x :: Int; y = 1; x = 2;} in x
03:15:09 <lambdabot>  2
03:15:16 <quicksilver> interesting
03:15:22 <quicksilver> I wonder why they permit that
03:15:26 <koredn> quicksilver, This is the complete code, up to that line: http://phpfi.com/279439
03:15:38 <sjanssen> quicksilver: one handy reason is x, y :: Int
03:15:40 <yaxu> @paste
03:15:40 <lambdabot> Haskell pastebin: http://hpaste.org/new
03:15:41 <b_jonas> > let { x :: Int; y = 1; x :: Int; x = 2;} in x
03:15:41 <lambdabot>   x :: Int
03:15:58 <mauke> koredn: your pastebin sucks
03:16:09 <koredn> It is not mine ;)
03:16:09 <b_jonas> wtf
03:16:12 <quicksilver> sjanssen: ah, ok
03:16:19 <yaxu> hpaste is down by the looks
03:16:28 <quicksilver> b_jonas: LB has a broken parser in a couple of cases :)
03:16:36 <quicksilver> koredn: odd. that code looks fine.
03:16:48 <sjanssen> b_jonas: I think that was an error message that was cut poorly
03:16:51 <quicksilver> koredn: ah, no id doesn't
03:17:00 <quicksilver> hmm
03:17:00 <b_jonas> quicksilver: yes, it gives Duplicate type sig error in ghci
03:17:01 <quicksilver> my mistake
03:17:05 <quicksilver> it does look fine
03:17:14 <scook0> koredn: I think all those " in the patterns probably should be changed to '
03:17:21 <quicksilver> ah yes
03:17:24 <scook0> but I'm not sure if that's related to your current problem
03:17:24 <koredn> I thought, too that it looks fine. I am using hugs98
03:17:27 <yaxu> http://paste.husk.org/10331 # What does 'hidden' mean in the context of packages?
03:17:33 <quicksilver> scook0 is right
03:17:34 <koredn> I am trying this, thanks.
03:17:36 <quicksilver> I didn't check the type sig
03:17:40 <quicksilver> koredn: also you may like to know
03:17:47 <quicksilver> "all isNumber [a,b,c,d]"
03:17:50 <yaxu> that's when I'm installing control.monad.random under ghc 6.8.1
03:17:59 <quicksilver> koredn: is quite a lot shorter than that long && expression
03:18:06 <sjanssen> yaxu: it means that the random package isn't listed in build-depends
03:18:23 <sjanssen> yaxu: ie. the .cabal file hasn't been updated for GHC 6.8
03:18:58 <yaxu> sjanssen: ok thanks
03:20:04 <yaxu> ooh, more errors now
03:20:10 * yaxu fiddles
03:20:15 <koredn> I still get the same (for me weired error) with this: http://phpfi.com/279442
03:20:42 <koredn> (Sorry for the german names in there - they are dictated)
03:21:06 <mauke> koredn: give me something I can load into ghci
03:21:29 <yaxu> the errors told me how to fix the problems, that's the kind of error i like
03:22:48 <koredn> mauke, thanks for the effort, it is really my fault - and I am sorry for that - the actual error is not in the pasted code ... we got another function def seperated from that in the later code.
03:23:07 <koredn> So, the only weired thing is the reported error line.
03:23:34 <koredn> I should really have pasted the complete code and made no assumptions on the errnous case. Sorry for that, and thanks guys. :)
03:23:56 <koredn> Shame on me
03:24:26 <scook0> koredn: oh well, at least you found the String/Char problem :)
03:24:38 <scook0> and all isNumber
03:27:41 <koredn> yeah, taht's defenitely nice to know :)
03:35:18 <yaxu> what are 'profiling libraries'?  i'm trying to compile my program with -prof but ghc is complaining that I don't have profiling libraries for 'Safe'
03:35:47 <SamB_XP_> yaxu: they are libraries that are built to support profiling
03:36:05 <SamB_XP_> they may or may not be usefully instrumented
03:36:26 <sjanssen> yaxu: when you configure Safe, use --enable-library-profiling
03:36:39 <SamB_XP_> basically, libraries that were built with -prof, too
03:36:41 <yaxu> gotcha
03:37:03 <SamB_XP_> unlike with gcc/gprof, all code MUST be built for profiling
03:39:09 <SamB_XP_> so that it will at least keep the cost center stack going
03:40:35 <scook0> is that something that could conceivably change without major GHC-surgery?
03:41:02 <SamB_XP_> changing it would involve overhead...
03:41:16 <SamB_XP_> afaik
03:42:13 <SamB_XP_> anyway... sjanssen's suggestion sounds good to me ;-)
03:44:09 <yaxu> yes it works now, thanks
03:51:37 <quicksilver> might be nice to have a global cabal config
03:51:42 <quicksilver> 'always build libraries in profiling'
03:51:46 <quicksilver> or maybe there already is
03:52:21 <SamB> yeah, THAT could certainly be done ;-)
03:52:36 <SamB> well, if cabal has global config, anyway ;-)
03:54:50 <sjanssen> I can't find any docs on it
03:58:18 <koredn> Back with another error, I am unable to understand, and again google does not really help me with that: http://phpfi.com/279448 ... the error is "ERROR "scanner.hs":7 - Instance of Num Char required for definition of jktScan" - this is not given by the definition of the function - so I don't understand what the compiler complains about.
03:58:26 <koredn> (And this time the complete code ;)
03:59:24 <mauke> isNumber is broken
03:59:32 <sjanssen> koredn: you're trying to do arithmetic on a Char
03:59:45 <mauke> sjanssen: curiously, no
03:59:56 <sjanssen> numeric literal?
04:00:03 <mauke> isNumber    x = elem x [0..9]
04:00:06 <sjanssen> heh, now I have to look
04:00:27 <mauke> > elem '2' [0 .. 9]
04:00:32 <lambdabot>   add an instance declaration for (Num Char)
04:00:32 <lambdabot>     In the expression: 9
04:00:44 <mauke> > elem '2' ['0' .. '9']
04:00:45 <lambdabot>  True
04:00:50 <koredn> The isNumber really caused this error
04:01:00 <koredn> mauke, fixed that, and the error has gonne
04:01:15 <mauke> btw, you might want to use Char.isDigit
04:01:17 <koredn> .oO( hugs98 has a strange error reporting )
04:01:25 <koredn> Thanks for the hint.
04:01:40 <mauke> > isAlphaNum 'Z'
04:01:41 <lambdabot>  True
04:02:25 <koredn> OK, even the reported error makes sense somehow.
04:02:28 <koredn> Thanks again guys.
04:02:36 <koredn> (and gals? ;)
04:04:25 <mdmkolbe> I'm doing a quick survey of how different programs/languages handle library search paths.  How does GHCi handle this?  (Other implementations feel free to chime in) E.g. first the current working directory, then the directory the script is in, then LIB_PYTHON, then the $pkglibdir directory (i.e. /usr/local/lib/python); also how any of those parts can be dissabled.
04:04:40 <koredn> Yay, taht scanner finally works :)
04:04:51 <ricky_clarkson> > map (("loit" ++) . foldr (++) [] . flip take (repeat "er")) [0..10]
04:04:52 <lambdabot>  ["loit","loiter","loiterer","loitererer","loiterererer","loitererererer","lo...
04:05:05 <ricky_clarkson> Is there a nicer way of writing the foldr (++) [] bit?
04:05:20 <dmwit> ?hoogle [a] -> [a] -> Int
04:05:22 <lambdabot> No matches, try a more general search
04:05:30 <dmwit> ?hoogle index
04:05:30 <lambdabot> Ix.index :: Ix a => (a, a) -> a -> Int
04:05:30 <lambdabot> Data.PackedString.indexPS :: PackedString -> Int -> Char
04:05:30 <lambdabot> Data.Generics.Basics.indexConstr :: DataType -> ConIndex -> Constr
04:05:37 <mauke> ?. hoogle type foldr (++) []
04:05:38 <lambdabot> Did you mean: Forall A. [[a]] -> [a]
04:05:43 <mauke> bah
04:05:47 <mauke> ?hoogle [[a]] -> [a]
04:05:47 <lambdabot> Prelude.concat :: [[a]] -> [a]
04:06:07 <b_jonas> ricky_clarkson: try concat
04:06:31 <mdmkolbe> > foldr (++) [] ["a", "b"]
04:06:33 <lambdabot>  "ab"
04:06:47 <dmwit> > map ("loit"++) . iterate ("er"++) $ []
04:06:47 <lambdabot>  ["loit","loiter","loiterer","loitererer","loiterererer","loitererererer","lo...
04:06:48 <ricky_clarkson> > concat (take (repeat "er") 10)
04:06:49 <lambdabot>  Couldn't match expected type `Int' against inferred type `[[Char]]'
04:06:57 <ricky_clarkson> > concat (take 10 (repeat "er"))
04:06:58 <lambdabot>  "erererererererererer"
04:07:16 <b_jonas> also foldr1 (++)
04:07:24 <b_jonas> no wait, that's no good
04:07:30 <ricky_clarkson> @src concat
04:07:30 <b_jonas> just leave it concat
04:07:30 <lambdabot> concat = foldr (++) []
04:07:59 <ricky_clarkson> Thanks.
04:08:23 <dmwit> ?hoogle substr
04:08:24 <lambdabot> Data.PackedString.substrPS :: PackedString -> Int -> Int -> PackedString
04:10:17 <quicksilver> ricky_clarkson: or, more generally, mconcat!
04:10:20 <quicksilver> works for any monoid
04:10:29 <ricky_clarkson> @src mconcat
04:10:29 <lambdabot> Source not found. Take a stress pill and think things over.
04:10:33 <ricky_clarkson> Will do.
04:10:43 <quicksilver> so your code would then work with sequences, say
04:10:51 <quicksilver> which may not matter at all :)
04:10:59 <quicksilver> it wouldn't, of course, because you're using "er"
04:11:05 * quicksilver shrugs
04:11:11 <quicksilver> a pointless point, I think
04:11:53 * ricky_clarkson idly wonders what a pointless point actually is.
04:12:10 <mauke> a function argument
04:12:45 <b_jonas> @pl point
04:12:45 <lambdabot> point
04:14:58 <SamB> a pointless point is a point that has no point... maybe in a silly argument?
04:16:02 <jedbrown> Is it a feature that cabal install --global registers as user when ghc is in a nonstandard place (/home/haskell)?
04:17:20 * integral thought it was from topology...
04:17:33 <dcoutts_> jedbrown: nope
04:17:56 <jedbrown> dcoutts_: It seems like a bug to me.
04:17:59 <dcoutts_> jedbrown: that's because the command line handling is borked. Currently it requires cabal --global install
04:18:14 <dcoutts_> jedbrown: I'm rewriting the cabal-install command line handling atm
04:18:21 <jedbrown> dcoutts_: Oh, cool.
04:28:09 <zipMe> hi bringert
04:28:24 <bringert> hi zipMe
04:28:40 <vincenz> bringert: hey
04:28:47 <zipMe> I'm having trouble compiling haskellDB-hdbc
04:29:25 <zipMe> bringert:  I get thiserror, Database/HaskellDB/HDBC.hs:37:18:
04:29:25 <zipMe>     Not in scope: type constructor or class `Connection'
04:29:51 <bringert> zipMe: I think that's got to do with hdbc version you are using
04:30:02 <bringert> zipMe: the hdbc api has changed a few times
04:31:09 <zipMe> bringert : yes I'm using HDBC-1.1.3
04:31:19 <zipMe> bringert : maybe it's too recent ?
04:32:04 <bringert> zipMe: probably. a patch for haskelldb to work with hdbc 1.1.3 would be welcome
04:32:07 <vincenz> osfameron: ping
04:32:34 <zipMe> bringert: I fear that's beyond my capabilities
04:43:22 <jimstutt> zipMe: HDBC: build on ghc-6.8.1gives the ubiquitous "Illegal polymorphic or qualified type" error Types.hs l207
04:44:01 <zipMe> jimstutt : yes ?
04:44:16 <jimstutt> Elsewhere OPTIONS_GHC -XExistentialTypes has fixed it but not here
04:44:46 <zipMe> jimstutt : yeah but I have managed to build HDBC
04:44:59 <zipMe> jimstutt: my pb is with haskellDB-hdbc
04:45:17 <jimstutt> zipMe: sorry it worked for this msg on other pkgs
04:45:45 <Lycurgus> pb = problem?
04:46:00 <zipMe> Lycurgus : yes
04:46:49 <quicksilver> jimstutt: try -XRankNTypes
04:48:02 <zipMe> quicksilver : yes that's the one, not easy to infer from the error message that one !
04:49:33 <osfameron> vincenz: pong
04:51:18 <quicksilver> zipMe: well rankNTypes are a kind of polymorphic type
04:51:25 <quicksilver> zipMe: I do agree, though
04:52:23 <Beelsebob> hmm... I've been playing at project euler today... just because
04:52:35 <zipMe> quicksilver: sure if I knew more I might make the connection, but other missing extensions lead to messages that explicitly indicate the proper extension to add, which I found more useful
04:52:44 <Beelsebob> I've done problem 4 really navely... but it seems to generate the wrong answer
04:52:51 <chessguy> hey osfameron? thanks for putting your code up. the link seems to be broken though: http://greenokapi.svn/code/monadwars/
04:52:51 <lambdabot> chessguy: You have 1 new message. '/msg lambdabot @messages' to read it.
04:52:59 <chessguy> @messages
04:52:59 <lambdabot> osfameron said 3h 32m 31s ago: thanks. re repo, http://osfameron.vox.com/library/post/monad-wars---code-online.html
04:53:00 <Beelsebob> I have no idea what's up here... anyone see an obvious mistake? http://pastebin.ca/800415
04:54:22 <chessguy> Beelsebob, 1.) use hpaste, 2.) what happens when you run the code?
04:54:24 <vincenz> osfameron: ok, regarding your latest blog
04:54:27 <vincenz> osfameron: there is an easy solution
04:54:43 <roconnor> @go 1 oz in g
04:54:48 <Beelsebob> chessguy: 1) hpaste is returning server not found 2) I get 698896 which is apparently the wrong answer
04:55:03 <roconnor> @vixen how much is 1 oz in grams?
04:55:11 <lambdabot> however you want
04:55:20 <vincenz> osfameron: what I do is I write code in .lhs files, that way it is executable.  The parts that are not code, I just use html code.  Then I use hscolour, the tool by malcolm wallace, and with the new patch I submitted, there's a flag so it will nicely generate properly colored <pre> blocks around your code
04:55:25 <vincenz> and leave the html alone in your comments
04:55:43 <Saizan> Beelsebob: maybe you need cartesian product rater than zipWith? gretestFirst = flip compare btw
04:55:45 <vincenz> osfameron: a nice bonus is that you can experiment with what you're blogging about to make sure there's no bugs
04:55:56 <quicksilver> Beelsebob: is the question only about perfect squares?
04:55:59 <osfameron> chessguy: gah!  yes, that is cos I am thick
04:56:12 <Beelsebob> Saizan: yep, thanks
04:56:14 <Beelsebob> I'm a moron
04:56:17 <quicksilver> Beelsebob: because you're only checking perfect squares from 100*100 to 999*999
04:56:26 <Beelsebob> was thinking about list comprehension as I wrote it
04:56:29 <Beelsebob> just did it rong
04:56:35 <jimstutt> quicksilver: -XRankNTypes => Illegal poly....Had tried -XRank2Polymorphism.  Will try Rank2Types?
04:56:37 <osfameron> vincenz: so the example code is hscoloured, while the executable code isn't ?
04:56:58 <zipMe> jimstutt : yes it is Rank2Types sorry...
04:57:05 <vincenz> osfameron: no, the executable code is hscoloured, while the stuff that has no > in front of it (the comments)) which you can put html in, like <a>'s or <h2s>, is colored
04:57:37 <vincenz> osfameron: check http://notvincenz.blogspot.com/2007/07/higher-order-zippers.html
04:57:44 <zipMe> jimstutt: Extensions: ExistentialQuantification, TypeSynonymInstances, Rank2Types
04:58:04 <jimstutt> zipMe: Rank2Types nogo either
04:58:07 <Beelsebob> much better :) 906609
04:58:22 <osfameron> vincenz: ah, ok
04:58:25 <zipMe> jimstutt : what error message do you get ?
04:58:25 <vincenz> osfameron: that's what it looks like, but you can customize colors
04:59:02 <osfameron> vincenz: that should be fairly easy to do then, I just have to tell my preprocessor script which bits are non-executable code
04:59:07 <vincenz> osfameron: that's easy
04:59:10 <vincenz> osfameron: use .lhs files ::)
04:59:15 <osfameron> vincenz: which I already do... (for examples etc.)
04:59:22 <vincenz> osfameron: I mean for the -entire- article
04:59:23 <osfameron> vincenz: yeah, I meant for the markup to blog
04:59:31 <vincenz> osfameron: I have my entire article in one .lhs
04:59:34 <jimstutt> zipMe: have -XTypeOperators -XExistentialQuantification -XRank2Types. Adding TypeSynonymInstances
04:59:38 <vincenz> osfameron: with the text stuff in there as well as non > blocks
04:59:43 <vincenz> osfameron: lhs, the new version, leaves those alone
05:00:19 <osfameron> chessguy: fixed the link.  I was stupid and just wrote it out by hand and didn't test it...
05:00:26 <chessguy> gracias!
05:00:47 <osfameron> vincenz: what about links back to previous articles ?
05:00:52 <vincenz> osfameron: that's in my text
05:00:55 <vincenz> osfameron: as </a>
05:01:01 <jimstutt> zipMe: sorry if this is boring but still nogo with added TypeSyonymInstances
05:01:10 <vincenz> osfameron: even I have links, no
05:01:20 <zipMe> jimstutt :post the error msg
05:01:21 <vincenz> osfameron: hscolour will -not- touch blocks of text that are not code in your .lhs file
05:01:33 <vincenz> osfameron: and as you know, in lhs, the only parts that are code are preceeded by >
05:01:42 <vincenz> osfameron: so those text blocks can contain html
05:01:43 <chessguy> osfameron, got it. i'll play with it tonight
05:02:56 <osfameron> vincenz: ok.  I get it for the formatting, that simplifies my markup, which is great.
05:03:09 <osfameron> vincenz: but can I refer to code in a previous .lhs file, to avoid typing it again?
05:03:29 <vincenz> osfameron: you cacn always jus hscolour a .lhs file and copy paste the block in
05:04:08 <osfameron> vincenz: which means that the blog post is no longer executable (until the reader also copy/pastes the block) ?
05:04:16 <vincenz> osfameron: why wouldn't it be?
05:04:22 <vincenz> osfameron: your text is not preceeeded by >
05:04:44 <vincenz> osfameron: so that's comments as far as lhs is concerned
05:04:59 <osfameron> vincenz: I'm either not understanding or not explaining, sorry.. here's my use case
05:05:04 <vincenz> osfameron: but I used to have separate code and text, but really, having it all in one lhs file is easier
05:05:07 <osfameron> vincenz: in post 1 I refer to a sub "tokenise"
05:05:09 <vincenz> osfameron: but even if it's not ini one file
05:05:15 <vincenz> osfameron: oh, like that
05:05:18 <osfameron> vincenz: in post 2, one of the subroutines calls "tokenise"
05:05:26 <vincenz> osfameron: That will never be solvable
05:05:30 <vincenz> osfameron: but people do not like that anyways
05:05:45 <vincenz> osfameron: you want your blogposts to stand on ther own
05:06:28 <vincenz> osfameron: and otherwise, well you can always name the blogposts wiht module names and import em
05:06:31 <osfameron> vincenz: ok - that will obviously get harder later as the codebase being discussed grows in size though
05:06:46 <osfameron> ah!  yes, that's an idea.
05:06:49 <vincenz> osfameron: so e.g. your  .lhs file is named "ModuleFoo"
05:06:57 <vincenz> osfameron: then say in that blogpost "please save as ModuleFoo.lhs"
05:07:35 <vincenz> osfameron: but this is orthogonal to the issue of hving your code and text in oen file or not
05:08:00 <osfameron> vincenz: ok, lots to think about.  I'll see if I can do the next post as a proper .lhs
05:08:09 <osfameron> thanks :-)
05:08:21 <vincenz> np
05:10:36 <MyCatVerbs> @pl \c p -> \a b -> c (p a) (p b)
05:10:36 <lambdabot> join . ((flip . ((.) .)) .) . (.)
05:10:57 <MyCatVerbs> Huh. Probably not a good function to put into pointless form.
05:11:16 <MyCatVerbs> @pl \p -> \a b -> (p a)==(p b)
05:11:17 <lambdabot> flip =<< (((.) . (==)) .)
05:11:40 * MyCatVerbs stares at lambdabot.
05:11:48 <MyCatVerbs> What the Hell was that?
05:12:01 <MyCatVerbs> :t \c p -> \a b -> c (p a) (p b)
05:12:04 <lambdabot> forall t t1 t2. (t1 -> t1 -> t2) -> (t -> t1) -> t -> t -> t2
05:12:11 <idnar> hooray for pointless code
05:12:29 <opqdonut> :)
05:12:50 <vincenz> @type \a -> flip =<< a
05:12:50 <lambdabot> forall a b c. (b -> a -> b -> c) -> b -> a -> c
05:12:55 <MyCatVerbs> :t ((join . ((flip . ((.) .)) .) . (.)) (==) isUpper)
05:12:56 <vincenz> reader monad
05:13:01 <lambdabot> Char -> Char -> Bool
05:13:11 <MyCatVerbs> > ((join . ((flip . ((.) .)) .) . (.)) (==) isUpper) 'a' 'A'
05:13:12 <lambdabot>  False
05:13:15 <quicksilver> MyCatVerbs: lambdabot doesn't know about 'on'
05:13:16 <MyCatVerbs> > ((join . ((flip . ((.) .)) .) . (.)) (==) isUpper) 'C' 'A'
05:13:16 <lambdabot>  True
05:13:20 <MyCatVerbs> Heh.
05:13:21 <vincenz> MyCatVerbs: btw \c p a b ->  === \c p -> \a b
05:13:33 <quicksilver> MyCatVerbs: your function is c `on` p, isn't it?
05:13:45 <MyCatVerbs> vincenz: jah, I know about schonfinkelization, I'm just not sure how to spell it.
05:13:54 <quicksilver> you missed the silent q
05:13:55 <vincenz> and yes
05:13:59 <vincenz> your function is c `on` p
05:14:04 <MyCatVerbs> quicksilver: yes, but I can't find where on is defined, so I'm poking \bot about it. :)
05:14:10 <idnar> @src on
05:14:10 <lambdabot> (*) `on` f = \x y -> f x * f y
05:14:12 <vincenz> @hoogle on
05:14:13 <lambdabot> Test.QuickCheck.oneof :: [Gen a] -> Gen a
05:14:13 <lambdabot> System.Console.Readline.onNewLine :: IO ()
05:14:13 <lambdabot> Text.ParserCombinators.Parsec.Char.oneOf :: [Char] -> CharParser st Char
05:14:22 <MyCatVerbs> :i on
05:14:32 <idnar> @info on
05:14:32 <lambdabot> on
05:14:35 <idnar> heh
05:14:38 <vincenz> quicksilver: off = flip on   ?
05:14:50 <MyCatVerbs> vincenz: ohnoes!
05:14:50 <scook0> on is in Data.Function in 6.8, I believe
05:15:01 <scook0> I don't think it ships with 6.6
05:15:02 <MyCatVerbs> Ah. /me has 6.6.0
05:15:39 * MyCatVerbs ponders bugging his prof to get 6.8.1 installed here.
05:15:43 <masterflex> I just installed GHC 6.6.1. Anyone know a good tutorial for a complete noob?
05:16:10 <matthew-_> @where yaht
05:16:10 <lambdabot> PDF: http://darcs.haskell.org/yaht/yaht.pdf Wikibook: http://en.wikibooks.org/wiki/Haskell/YAHT
05:16:14 <matthew-_> masterflex: there
05:17:08 <b_jonas> so if I use a Seq as a dequeue, what's the function to split it to head and tail?
05:17:30 <b_jonas> ah, viewl
05:17:30 <quicksilver> viewl ?
05:17:33 <MyCatVerbs> matthew-_: seconded, YAHT is awesome.
05:17:40 <b_jonas> tricky
05:18:09 <MyCatVerbs> Er, masterflex, I mean.
05:18:12 <b_jonas> these smilies (:<) are wierd
05:18:22 <idnar> hahaha @ off
05:18:23 <quicksilver> I wonder if anyone ever made a proposal for constructors in typeclasses
05:19:04 <b_jonas> quicksilver: strange idea
05:19:05 <scook0> quicksilver: please elaborate :)
05:19:11 <quicksilver> :t 0
05:19:17 <b_jonas> we don't even have constructor aliases outside of classes
05:19:19 <lambdabot> forall t. (Num t) => t
05:19:21 <quicksilver> like that
05:19:23 <b_jonas> we can type Foo = Bar
05:19:26 <quicksilver> only not a dirty hack :)
05:19:32 <b_jonas> but not assign a constructor an alias
05:19:41 <b_jonas> like Cons = (:)
05:19:49 <quicksilver> :t \x -> case x of 0 -> True | _ -> False
05:19:54 <masterflex> Are there any types of programs that can't be written in Haskell?
05:20:02 <matthew-_> masterflex: wrong ones
05:20:03 <lambdabot> parse error on input `|'
05:20:07 <MyCatVerbs> masterflex: Church-Turing thesis says no. :)
05:20:08 <quicksilver> :t \x -> case x of 0 -> True ; _ -> False
05:20:12 <vincenz> b_jonas: why not use a banker's queue?
05:20:13 <lambdabot> forall t. (Num t) => t -> Bool
05:20:17 <quicksilver> there you go
05:20:21 <scook0> matthew-_: I disagree, writing wrong programs in Haskell is great fun!
05:20:24 <b_jonas> vincenz: what's that?
05:20:25 <quicksilver> '0' is a genuine constructor, in a typeclass
05:20:32 <quicksilver> but, it's implemented as a dirty hack
05:20:33 <vincenz> b_jonas: data DeQueue a = DQ [a] [a]
05:20:37 <quicksilver> that might be nice in general
05:20:44 <vincenz> b_jonas: it's a pair of stacks, you push off one, pop off the other for fifo
05:20:50 <vincenz> b_jonas: if one is empty, you reverse the other into place
05:20:58 <vincenz> b_jonas: it's amortized O(1)
05:20:58 <masterflex> MyCatVerbs, true. Thought, it also says my watch could compute anything. Which is also true, but unlikely.
05:21:04 <quicksilver> vincenz: because why bother? someone already wrote Seq
05:21:14 <quicksilver> vincenz: which is much clever and also amortized O(1) :)
05:21:23 <vincenz> quicksilver: it feels too heavy weight :)
05:21:27 <matthew-_> quicksilver: there'll be constant time differences between them
05:21:33 <quicksilver> of course
05:21:43 <vincenz> Seq has a high footprint
05:21:45 <quicksilver> but it's premature optimisation to care about constant factors
05:21:45 <matthew-_> quicksilver: I would bet money on bankers queue being faster for short queues
05:21:52 <matthew-_> absolutely
05:21:54 <quicksilver> I woudl bet money that I don't care
05:21:56 <quicksilver> ;)
05:22:00 <scook0> matthew-_: for example, the constant time it takes you to write and debug DeQueue? :P
05:22:03 <b_jonas> vincenz: wow, I've never heared of that
05:22:06 <b_jonas> thanks for mentioning
05:22:14 <vincenz> quicksilver: well you should not force your cost function onto others
05:22:18 <vincenz> quicksilver: they're both pareto optimal
05:22:29 * quicksilver shrugs
05:22:36 <vincenz> b_jonas: if it interests you, look for okasaki's purely functional data structure
05:22:39 <quicksilver> why write something new when the library provides something with works well?
05:22:45 <vincenz> quicksilver: that is your cost metric
05:22:47 <quicksilver> do you have a Foldable instance for your dequeue?
05:22:53 <quicksilver> a Traversable instance?
05:22:53 <vincenz> quicksilver: other's cost metric might be "I want something with low footprint"
05:22:57 <quicksilver> where is fromList?
05:23:00 <quicksilver> where is toList?
05:23:02 <quicksilver> where is foldM?
05:23:05 <quicksilver> where is concat?
05:23:11 <vincenz> quicksilver: read the above
05:23:12 <quicksilver> all these things that Seq gives me, already written
05:23:15 <b_jonas> I've used double stacks once, but not for queues, but for a purely functional replacement of mutable arrays that you mostly access locally
05:23:21 <quicksilver> what's a footprint?
05:23:25 <vincenz> memory footprint
05:23:32 <scook0> b_jonas: a list zipper?
05:23:32 <quicksilver> couldn't care less
05:23:34 <vincenz> quicksilver: anyways, ou're being a troll :)
05:23:38 <quicksilver> premature optimisation
05:23:52 <quicksilver> no, I'm applying Occam's razor
05:24:02 <quicksilver> why search for a more complex solution which involves writing code
05:24:04 <vincenz> quicksilver: no, you're applying your cost-function and expecting everyone to have the same
05:24:11 <quicksilver> when there is an existing solution which works
05:24:27 <vincenz> quicksilver: so why are we coding in haskell? We should've stuck to C
05:24:28 <b_jonas> scook0: something like that, but not exactly
05:24:42 <quicksilver> vincenz: because haskell gives me simpler solutions
05:24:42 <scook0> vincenz: I'd say that he's trying to convince others to adopt his cost metric
05:24:49 <vincenz> scook0: I agree
05:24:50 <quicksilver> yes
05:24:54 <vincenz> scook0: and I think that is not correct of him
05:24:57 <quicksilver> I'm trying to explain my cost metric
05:24:59 <vincenz> scook0: people can agree on the pareto optimal surface
05:25:04 <vincenz> scook0: but everyone should pick their own ideal point
05:25:10 <quicksilver> because I believe I'm helping people by suggesting they don't waste time
05:25:18 <quicksilver> of course, they may find that time well spent
05:25:24 <quicksilver> but I'm guessing, that it would be a waste
05:25:32 <vincenz> quicksilver: stop the crusade
05:25:33 <b_jonas> vincenz: fyi, me and quicksilver has already had a discussion like this a couple of hours ago
05:25:40 <vincenz> quicksilver: it's like you're afraid that someone might do it
05:25:52 <quicksilver> vincenz: stop telling me what to say?
05:26:00 <vincenz> fair enough
05:26:06 <quicksilver> I have my opinions, I'll share them. I don't believe I've offended anyone by doing so.
05:26:42 <quicksilver> if I had, I would apologise. Which distinguishes me from a troll, in my opinion :)
05:26:46 <b_jonas> scook0: it's the "tape" type in this code: http://www.math.bme.hu/~ambrus/pu/olvashato/
05:26:57 * matthew-_ is mortified by quicksilver's opinions
05:26:58 <matthew-_> ;)
05:27:08 <vincenz> quicksilver: it sounded like someone going on a crusade "emacs rules, stop using vim"
05:27:18 <matthew-_> emacs does rule. Without question.
05:27:42 <mauke> NO IT DOESN'T
05:27:46 <matthew-_> :p
05:27:56 <matthew-_> and it annoys the c*** out of me that stupid xmonad by default grabs alt/meta, thus breaking much of emacs.
05:27:59 <b_jonas> vincenz: no, he wasn't like that
05:28:01 <vincenz> @doc Data.Seq
05:28:01 <lambdabot> Data.Seq not available
05:28:06 <vincenz> @doc Data.Sequence
05:28:06 <lambdabot> Data.Sequence not available
05:28:10 <b_jonas> he's definitely not trolling
05:28:11 <vincenz> @index Data.Sequence
05:28:11 <lambdabot> bzzt
05:28:11 <quicksilver> matthew-_: you need another key, really
05:28:27 <quicksilver> matthew-_: it's quite sensible that window managers take a modifier of their own
05:28:29 * vincenz ponders
05:28:37 <vincenz> b_jonas: no, not trolling, but it was nuissant
05:28:38 <matthew-_> quicksilver: no, I just need ratpoison/xorg to stop crashing and then I'd be fine
05:28:38 <scook0> b_jonas: I can't really see how that differs from (my understanding of) a zipper
05:28:40 <vincenz> at least, to me
05:28:43 <quicksilver> matthew-_: on PC keyboards I tend to use the Windows key for the window manager, and Alt for Meta
05:28:53 <scook0> (except perhaps conceptually)
05:29:00 <matthew-_> quicksilver: windows key here switches to greek alphabet.
05:29:06 <quicksilver> ah
05:29:10 <quicksilver> that's a need I don't have
05:29:10 <b_jonas> scook0: I don't completely understand zippers either, but I think a zipper moves only in one direction
05:29:10 <vincenz> scook0: banker's queue and a zipper?
05:29:12 * quicksilver nods
05:29:13 <vincenz> scook0: it's the orientation
05:29:17 <mauke> matthew-_: well, you have two of them
05:29:31 <quicksilver> or the 'menu' key?
05:29:32 <matthew-_> mauke: I know. And xmonad seems to like both of them
05:29:41 <quicksilver> you can change that with xmodmap, I believe
05:29:43 <scook0> I'm pretty sure the whole point of a zipper is that you can go in both directions
05:29:47 <mauke> yeah, that's a matter of your keyboard config
05:29:50 <quicksilver> you have to map them to different modifiers
05:29:51 <matthew-_> quicksilver: yes, good point
05:30:04 <scook0> vincenz: list zipper vs. jonas' "tape"
05:30:05 <matthew-_> hmm. I only have a right menu key. I tend to use left hand for modifiers (yes, I know this is bad)
05:30:12 <vincenz> scook0: zipper is: (a_l: a_l-1...:a_0) * (a_l+1:a_l+2:...:a_n)  while BQ is (a_0:a_1:a_l) * (a_n:a_n_1...)
05:30:15 <vincenz> scook0: oh
05:30:27 <quicksilver> matthew-_: use right menu key for xmonad, if you use that less frequently than emacs meta?
05:30:29 <vincenz> erm, the second ends at a_l+! obb
05:30:31 <vincenz> obv
05:30:56 <b_jonas> does a zipper move both forward and backwards?
05:30:59 <vincenz> yes
05:31:14 <vincenz> b_jonas: http://notvincenz.blogspot.com/2007/07/higher-order-zippers.html
05:32:01 * vincenz wonders why the hell he made those monadic
05:32:04 <b_jonas> vincenz: ah, so that's a book
05:32:38 <b_jonas> Purely Functional Data Structures by Chris Okasaki that is
05:32:44 <vincenz> yes
05:32:50 <vincenz> there's also a pdf of a journal paper
05:32:52 <vincenz> it covers most of it
05:32:54 <vincenz> afaik
05:32:56 <vincenz> and iirc
05:33:03 * b_jonas searches the library catalogues
05:34:04 <vincenz> b_jonas: http://www.google.be/url?sa=t&ct=res&cd=1&url=http%3A%2F%2Fwww.cs.cmu.edu%2F~rwh%2Ftheses%2Fokasaki.pdf&ei=LG5NR83RGYmYwQHV8d3iDg&usg=AFQjCNGXKQqKJho73FE372EjGzUoeSJm1w&sig2=Y7U8HI9nY3hbxiOjAMRMyw
05:34:11 <quicksilver> of course, zippers for lists aren't that exciting
05:34:15 <quicksilver> they're just the simple example
05:34:20 <quicksilver> zippers for ADTs are more interesting
05:34:25 <vincenz> quicksilver: well scroll down
05:34:29 <quicksilver> ;)
05:34:33 * vincenz tsks
05:34:37 <quicksilver> I haven't read the reference
05:34:40 <quicksilver> I was just commenting
05:35:35 <vincenz> b_jonas: that's his phd thesis
05:35:57 <b_jonas> result: only in a departmental library where I probably can't get it easily (http://tinyurl.com/ypzsys)
05:36:09 <b_jonas> phd thesis? nice
05:36:10 <vincenz> b_jonas: www.cs.cmu.edu/~rwh/theses/okasaki.pdf
05:36:14 <scook0> can ADT zippers be derived mechanically? (e.g. by TH)
05:36:23 <vincenz> scook0: maybe, but there are issues with that
05:36:28 <vincenz> scook0: if you look at the example in my blog article
05:36:30 <b_jonas> thanks for the link
05:36:35 <vincenz> I was really struggling to name some of those components
05:36:45 <vincenz> scook0: you need to know what each part in the equation represents, and you need to massage it into a correct form
05:36:54 <vincenz> since some equations will give you things that make less sense to a human
05:37:05 <vincenz> but if you refactor it mathematically, it might make sense
05:37:09 <scook0> ah
05:37:16 <vincenz> the tree example, e.g., in my blog took me a while to make sense of
05:37:20 <vincenz> especially the second derivative
05:37:45 <scook0> because it seems as though zippers are (a) quite useful, and (b) a bit of a pain to define by hand
05:38:11 <vincenz> scook0: yes, but you want meaningful data-constructors
05:38:13 <scook0> (and I have TH on the brain currently)
05:38:13 <vincenz> e.g.
05:38:17 <vincenz> zipper of a list is
05:38:20 <vincenz> erm
05:38:34 <vincenz> 2nd order zipper of a list is: 2*[a]^3
05:38:59 <vincenz> so you need two data-constructor names
05:39:25 <vincenz> if, otoh, you care not about data structure names
05:39:44 <vincenz> what you -could- do is reformulate all data structures to ones without meaningful names, and then you could 'easily' do this
05:39:52 <quicksilver> scook0: it is a mechanical process in some sense
05:40:02 <quicksilver> scook0: but in real use cases, sensible naming helps a lot
05:40:08 <vincenz> right
05:40:25 <scook0> so I guess my answer is "technically yes, but an automatic derivation is likely to be useless to a human"
05:40:34 <vincenz> in short :)
05:41:24 <scook0> anyway, it's too late for me to be thinking such complicated thoughts :)
05:46:17 <puusorsa> @pl  (\x y-> x+((read [y])))
05:46:17 <lambdabot> (. (read . return)) . (+)
05:46:17 <b_jonas> yes, then I think my tape datastructure is like a zipper of a list
05:46:32 <b_jonas> so scook0 is right
05:46:36 <vincenz> b_jonas: the zipper of a list is two stacks
05:46:55 <b_jonas> vincenz: exactly
05:47:03 <chessguy> @pl \f -> f s
05:47:03 <lambdabot> ($ s)
05:47:20 <b_jonas> the second order zipper of a list is done in detail in the http://notvincenz.blogspot.com/2007/07/higher-order-zippers.html though
05:47:20 <lambdabot> Title: lambda.oasis: Higher Order Zippers
05:47:50 <vincenz> yep
05:47:51 <chessguy> @undo do { f <- m; f x }
05:47:51 <lambdabot> m >>= \ f -> f x
05:47:54 <zipMe> jimsutt : did u manage with HDBC ?
05:48:07 <chessguy> @pl \x ->  m >>= \ f -> f x
05:48:07 <lambdabot> (m >>=) . flip id
05:48:37 <puusorsa> @pl  (\y x-> x+((read [y])))
05:48:37 <lambdabot> (+) . read . return
05:49:37 <chessguy> puusorsa, you know you don't need all those parens
05:49:52 <chessguy> @pl \y x -> x + (read [y])
05:49:52 <lambdabot> (+) . read . return
05:50:05 <mauke> @pl \y x -> x + read [y]
05:50:05 <lambdabot> (+) . read . return
05:50:09 <chessguy> err, yeah
05:50:19 <chessguy> i'm still shedding parens myself :)
05:51:42 <chessguy> hmm. why is the list monad assumed by that return?
05:51:59 <mauke> :t read
05:52:01 <chessguy> @type (+) . read . return
05:52:14 <lambdabot> thread killed
05:52:16 <lambdabot> thread killed
05:52:21 <chessguy> ...
05:52:26 <mauke> :t read
05:52:27 <lambdabot> forall a. (Read a) => String -> a
05:52:27 <chessguy> @bot
05:52:27 <lambdabot> :)
05:52:31 <chessguy> @type (+) . read . return
05:52:33 <lambdabot> forall a. (Num a, Read a) => Char -> a -> a
05:53:20 <chessguy> oh! string
05:53:21 <chessguy> right
05:54:18 <jimstutt> zipMe: Fraid not: posted error on Haskell-Cafe@...
05:56:24 <oerjan> chessguy: although @pl probably does not check for type ambiguity when translating (:[]) to return (given that @pl knows nothing about types afaiu)
05:56:56 <chessguy> right, thats why i was suspicious
06:00:40 <quicksilver> well translating (:[]) to return is safe
06:00:47 <quicksilver> in that it obviously can't break working code
06:00:55 <quicksilver> of course, it can make code unexpectedly general
06:01:40 <chessguy> @pl \me -> lift me work
06:01:40 <lambdabot> flip lift work
06:03:00 <mauke> > mconcat [(:[]) 42]
06:03:03 <lambdabot>  [42]
06:03:05 <mauke> > mconcat [return 42]
06:03:05 <lambdabot>   add an instance declaration for (Show (m t))
06:03:52 <idnar> > mconcat [return 42] :: (Num t) => [t]
06:03:53 <lambdabot>  [42]
06:04:46 <oerjan> quicksilver: i am not so sure.  there might be something like show . read possible with return.
06:05:30 <oerjan> um, mauke just demonstrated i guess
06:05:50 <oerjan> or wait... no
06:06:08 <oerjan> mconcat does not eliminate the type
06:06:19 <mauke> it's hard to find a function that eliminates monads :-)
06:06:31 <oerjan> maybe Foldable?
06:07:11 <oerjan> > Data.Foldable.toList (Just 1)
06:07:12 <lambdabot>  [1]
06:07:18 <zipMe> bringert: I've managed to compile haskellDB-hdbc with the latest version of HDBC
06:07:18 <oerjan> > Data.Foldable.toList [1]
06:07:19 <lambdabot>  [1]
06:07:24 <oerjan> there you are
06:08:13 <oerjan> :t Data.Foldable.toList . return
06:08:15 <lambdabot>     Ambiguous type variable `t' in the constraints:
06:08:16 <lambdabot>       `Monad t' arising from use of `return' at <interactive>:1:23-28
06:08:16 <lambdabot>       `Data.Foldable.Foldable t'
06:10:55 <quicksilver> oerjan: ah, you can make it ambigous, I see what you mean.
06:11:03 <quicksilver> oerjan: you still don't "break it"
06:11:16 <quicksilver> the code is equivalent assuming you can feed the info to the type inferrer
06:12:03 <oerjan> except you cannot add a type without breaking up the expression
06:12:48 <oerjan> because the ambiguous type only exists inside the (.) pipeline
06:13:06 <quicksilver> (return :: Int -> [Int]) might work
06:13:13 <wolverian> (foo :: bar) . baz works
06:13:14 <quicksilver> or you might need scoped type vars to write the type correctly
06:13:27 <oerjan> that's what i meant by breaking up the expression
06:13:30 * quicksilver nods
06:13:35 <quicksilver> I wouldn't call it that
06:13:40 <quicksilver> I'd call it 'adding annotations' :)
06:13:44 <quicksilver> but yes, agreed
06:13:46 <quicksilver> you have to do it
06:14:15 <oerjan> i still think a (:: Type) section might be useful for such cases...
06:15:20 <quicksilver> well there is (`asTypeOf` ...) sections
06:17:11 <ski> @type asTypeOf
06:17:11 <lambdabot> forall a. a -> a -> a
06:17:15 <oerjan> in point-free code you might end up having to do (`asTypeOf` (undefined :: Type))
06:17:33 <ski> > (`asTypeOf` (undefined :: Int)) 17
06:17:36 <lambdabot>  17
06:19:30 <twanvl> type Id a = a -> a;   (id :: Id Type)
06:19:50 <b_jonas> oerjan: lol
06:20:22 <oerjan> twanvl: hm that's an improvement
06:23:58 <b_jonas> just one shorter than ud = undefined; ca = flip asTypeOf;   (ca (ud :: Type))
06:26:42 <oerjan> or (\x->x :: Type) which i think i saw Philippa mention on the mailing list
06:28:16 <ToRA> quick q, if i have a load of (ghc 6.8.1) code compiled with -fhpc, is there a flag or switch i can give to ghci to let me load it interactively to stop getting "unknown symbol `hs_hpc_module'" errors?
06:28:49 <ToRA> ah nm
06:28:56 <ToRA> ghci -fhpc
06:29:14 * ToRA puts his hand down
06:29:53 <MyCatVerbs> ToRA: I don't even know what that's *for*, but I'm reasonably sure I'm going to end up thanking you for mentioning that one day.
06:30:15 <ToRA> actually, ghci -fhpc doesn't work
06:30:31 <oerjan> it's the new coverage profiling isn't it
06:30:37 <ToRA> it loads the file, but when i try and execute stuff it still complains about the symbol not found in a dependand .o file
06:30:44 <ToRA> it's for code coverage, yeah
06:31:12 <ToRA> the hpc stuff is very very nice imho, but it'd be nice to be able to use ghci without needing to clean-compile
06:32:18 <b_jonas> oerjan: nice
06:33:54 <oerjan> b_jonas: and (:: Type) would be the logical section for that, just like other (`op` e) sections are defined to expand to (\v -> v `op` e)
06:34:33 <b_jonas> oerjan: hmm, if you say it like that...
06:34:57 <ToRA> ah pants, http://hackage.haskell.org/trac/ghc/ticket/1779
06:34:59 <lambdabot> Title: #1779 (unknown symbol `hs_hpc_module') - GHC - Trac
07:10:52 <dozer> hoogle: Map a b -> (b -> c) -> Map a c
07:12:34 <oerjan> @hoogle Map a b -> (b -> c) -> Map a c
07:12:35 <lambdabot> Data.Map.map :: (a -> b) -> Map k a -> Map k b
07:12:51 <dozer> ah, thanks
07:29:29 <EvilTerran> my bad =/
07:31:56 <osfameron> @src map
07:31:56 <lambdabot> map _ []     = []
07:31:56 <lambdabot> map f (x:xs) = f x : map f xs
07:32:32 * osfameron notes that scheme's map is less of a "thing of beauty" than the haskell one (see http://blog.plt-scheme.org/ )
07:35:04 <arsirc> one click can help me: http://www.cyberlord.at/?partner=16580
07:35:05 <lambdabot> Title: ASP Forum Script - Message Discussion Board Scripts - Download Free Hosting
07:35:37 <faxathisia> hi
07:35:51 <b_jonas> osfameron: scheme's map has zipWith and zipWith3 and zipWith4 etc in it
07:35:51 * oerjan cannot resist saying: from a pistol
07:35:52 <b_jonas> I like it
07:36:34 <osfameron> how so?
07:37:13 <vincenz> osfameron: their map is poly map
07:37:26 <vincenz> (map foo lis1 list2 list3..)
07:37:34 <vincenz> foo needs to take same number of args as the number of lists
07:37:45 <vincenz> you -could- do that in haskell
07:37:48 <faxathisia> (This is good http://en.wikibooks.org/wiki/Haskell )
07:37:48 <lambdabot> Title: Haskell - Wikibooks, collection of open-content textbooks
07:38:02 <vincenz> map :: ([a] -> b) -> [[a]] -> [b]
07:38:08 <vincenz> but it'd be harder to get that polytyped
07:38:26 * osfameron doesn't see how that takes multiple lists
07:38:31 <osfameron> unless car and cdr do...
07:38:44 <faxathisia> osfameron: map car inside the procedure :p
07:38:50 <faxathisia> (causes an infinite loop)
07:38:50 <EvilTerran> zipWithN or repeat/zapp would be the closest approximation, i'd've thunk
07:39:46 <oerjan> :t \f -> map f . transpose
07:39:48 <lambdabot> forall b a. ([a] -> b) -> [[a]] -> [b]
07:44:58 <osfameron> ah well.  I will learn scheme *next* :-)
07:48:12 <ricky_clarkson> Scheme's fun to learn, and sicp is a fantastic book, regardless of Scheme.
08:14:36 <roconnor> @type on
08:14:37 <lambdabot> Not in scope: `on'
08:14:44 <roconnor> @type sortBy
08:14:45 <lambdabot> forall a. (a -> a -> Ordering) -> [a] -> [a]
08:17:06 <oerjan> @let on (==) f x y = f x == f y
08:17:07 <lambdabot> <local>:10:0:     Multiple declarations of `L.on'     Declared at: <local>:6:...
08:17:35 <faxathisia> @src on
08:17:35 <lambdabot> (*) `on` f = \x y -> f x * f y
08:18:39 <roconnor> @type compoare
08:18:40 <lambdabot> Not in scope: `compoare'
08:18:41 <roconnor> @type compare
08:18:42 <lambdabot> forall a. (Ord a) => a -> a -> Ordering
08:19:47 <roconnor> @hoogle on
08:19:53 <lambdabot> Test.QuickCheck.oneof :: [Gen a] -> Gen a
08:19:53 <lambdabot> System.Console.Readline.onNewLine :: IO ()
08:19:53 <lambdabot> Text.ParserCombinators.Parsec.Char.oneOf :: [Char] -> CharParser st Char
08:20:59 <oerjan> Data.Function
08:23:00 <oerjan> @hoogle on\>
08:23:00 <lambdabot> Hoogle Error: Parse Error: Unexpected character '\>'
08:23:06 <oerjan> bah
08:23:43 <roconnor> oerjan++
08:34:33 * osfameron prepares to fall off the internet for a week or so
08:37:52 <hpaste>  Odissey pasted "data type" at http://hpaste.org/4128
08:45:18 <byorgey> osfameron: why?
08:46:09 <Nafai> byorgey: I got GHC 6.8.1 compiled last night!
08:46:24 <byorgey> Nafai: nice!
08:46:36 <byorgey> Nafai: was it difficult?
08:47:32 <Nafai> Not really
08:47:39 <osfameron> byorgey: last day at job today, no internet at Italian flat.  I'll be back in UK next tuesday, so unless I go cold turkey and need to run into an internet cafe, I'll be off for a bit :-)
08:47:48 <vincenz> osfameron: sei italiano?
08:48:01 <osfameron> vincenz: no, inglese, but I've been working here for the last couple of years
08:49:05 <byorgey> osfameron: I see.  well, good luck with the move! (?)
08:50:53 <osfameron> heh, thanks :)
08:51:52 <phlpp> :t takeUntil
08:51:59 <phlpp> :t dropWhile
08:52:01 <lambdabot> forall a. (a -> Bool) -> [a] -> [a]
08:52:01 <lambdabot> Not in scope: `takeUntil'
08:52:28 <mux> takeUntil p = takeWhile (not . p)
08:52:30 <mux> I guess
08:53:40 <phlpp> hehe
08:55:49 <phlpp> > "foobar"!!0
08:55:53 <lambdabot>  'f'
08:56:12 <osfameron> > "me too"!!1
08:56:19 <lambdabot>  'e'
08:59:19 <ricky_clarkson> hehe
09:00:00 <vincenz> > "lolcode!!1!!"!!11
09:00:15 <lambdabot>  thread killed
09:00:25 <vincenz> wtf
09:02:17 <Japsu> lol
09:02:30 <Beelsebob_> o.O
09:02:32 <phlpp> @pl \s -> (show $ length $ takeWhile (==s!!0) s) ++ [s!!0]
09:02:32 <lambdabot> ap ((++) . show . length . (takeWhile =<< (==) . (!! 0))) (return . (!! 0))
09:02:38 <Beelsebob_> > "lolcode!!1!!"!!11
09:02:38 <phlpp> :F
09:02:40 <lambdabot>  '!'
09:02:44 <Beelsebob_> better
09:03:12 <faxathisia> @src concatMap
09:03:12 <lambdabot> concatMap f = foldr ((++) . f) []
09:03:28 <faxathisia> :t flip.concatMap
09:03:29 <lambdabot>     Couldn't match expected type `b -> c' against inferred type `[b1]'
09:03:29 <lambdabot>     In the second argument of `(.)', namely `concatMap'
09:05:40 <faxathisia> @pointless (\a -> case a of (x,y) -> (x,f y))
09:05:40 <lambdabot> (line 1, column 24):
09:05:40 <lambdabot> unexpected ">"
09:05:40 <lambdabot> expecting variable, "(", operator or ")"
09:05:50 <lambdabot> Error: GHC type_check1 exploded at TypeCheck.hs:41-23
09:05:56 <dons> nice
09:06:01 <faxathisia> oops :[
09:06:03 <faxathisia> I made it explode
09:06:23 <faxathisia> I really think lambdabot is wanting a holiday
09:06:27 <dons> ?bot
09:06:27 <lambdabot> :)
09:06:59 <chessguy> @remember ghc Error: GHC type_check1 exploded at TypeCheck.hs:41-23
09:06:59 <lambdabot> It is forever etched in my memory.
09:07:09 * vincenz laughs
09:07:11 <vincenz> ./msg lambdabot @msg #haskell   Error: GHC type_check1 exploded at TypeCheck.hs:41-23
09:07:33 <chessguy> @quote ghc
09:07:33 <lambdabot> ghc says: magic number mismatch: old/corrupt interface file?
09:07:59 <mauke> @ghc
09:07:59 <lambdabot> ghc says: Cycle in class declarations (via superclasses)
09:09:25 <faxathisia> What should I do with (\(x,y)->(x,f y))?
09:09:54 <vincenz> second f
09:09:57 <vincenz> @type second f
09:09:58 <lambdabot> Not in scope: `f'
09:10:02 <vincenz> @type \f -> second f
09:10:02 <lambdabot> forall (a :: * -> * -> *) b c d. (Arrow a) => a b c -> a (d, b) (d, c)
09:10:17 <vincenz> > second (+1) ('a',4)
09:10:18 <lambdabot>  ('a',5)
09:10:26 <mauke> @type second ?f
09:10:27 <lambdabot> forall (a :: * -> * -> *) b c d. (?f::a b c, Arrow a) => a (d, b) (d, c)
09:10:35 <mauke> whee
09:10:39 <vincenz> mauke: nice
09:10:48 <faxathisia> how do you know all these things mauke..
09:11:18 <mauke> what, the ? thing? I saw someone else use it
09:11:44 <mauke> I think that's the main use for implicit arguments, typechecking in lambdabot :-)
09:12:00 <mauke> (that was probably said first by dons)
09:12:09 <vincenz> (as most things)
09:12:41 <Beelsebob_> > scanl (+) 0 [1..]
09:12:42 <lambdabot>  [0,1,3,6,10,15,21,28,36,45,55,66,78,91,105,120,136,153,171,190,210,231,253,2...
09:13:01 <hpaste>  (anonymous) pasted "takeWhile ++ (the element where we stopped if any)" at http://hpaste.org/4129
09:13:51 <faxathisia> vincenz: It is usual to use Arrows like that?
09:13:55 <mauke> @src takeWhile
09:13:55 <lambdabot> takeWhile _ []                 =  []
09:13:55 <lambdabot> takeWhile p (x:xs) | p x       =  x : takeWhile p xs
09:13:55 <lambdabot>                    | otherwise =  []
09:14:00 <mauke> oh great
09:14:08 <faxathisia> (it seems like not the purpose of them?)
09:14:52 <vincenz> ok
09:14:55 <vincenz> whoever pasted ht code...
09:14:59 <vincenz> > take 1 []
09:15:00 <lambdabot>  []
09:15:27 <hpaste>  vincenz annotated "takeWhile ++ (the element where we stopped if any)" with "yes " at http://hpaste.org/4129#a1
09:16:38 <hpaste>  (anonymous) pasted "(no title)" at http://hpaste.org/4130
09:16:56 <hpaste>  mauke annotated "takeWhile ++ (the element where we stopped if any)" with "(no title)" at http://hpaste.org/4129#a2
09:17:39 <hpaste>  vincenz annotated "takeWhile ++ (the element where we stopped if any)" with "other option" at http://hpaste.org/4129#a3
09:20:24 <ZsoL> anyone got a clue why I'm getting these '\SOH' characters in my fresh new irc client? :-)
09:20:31 <ricky_clarkson> It seems that sometimes a reversed idea of an immutable list would be useful, so that appending is cheap and accessing the start might be expensive.  Have I gone mad?
09:20:33 <ZsoL> what are these in the first place?
09:20:36 <ricky_clarkson> Any such types around?
09:20:40 <mauke> > ord '\SOH'
09:20:43 <lambdabot>  1
09:20:46 <vincenz> ricky_clarkson: yes, it's called a reversed list
09:20:52 <mauke> ZsoL: CTCP commands
09:21:04 <mauke> commonly seen in CTCP ACTIONs
09:21:07 <vincenz> ricky_clarkson: here is the type
09:21:10 <vincenz> type RevLis a = [a]
09:21:19 * shapr is awake!
09:21:21 <ricky_clarkson> vincenz: Then head, etc., are wrong.
09:21:26 <vincenz> ricky_clarkson: rename em
09:21:31 <Jaak> It lives!
09:21:32 <ZsoL> mauke, I get this in PRIVMSGs like this:
09:21:35 <vincenz> ricky_clarkson: serously, it's just a syntactical difference
09:21:40 <ricky_clarkson> vincenz: Sure.
09:21:44 <ZsoL> PRIVMSG HaskBot :\SOHPING
09:21:58 <mauke> looks like a CTCP PING
09:22:07 <mauke> but you should get another \SOH at the end
09:22:12 <ZsoL> yup
09:22:25 * mauke performs a CTCP ACTION
09:22:31 <ZsoL> so it's not haskell specific?
09:22:35 <mauke> no
09:22:46 <ZsoL> 'mmkay :-)
09:22:46 <mauke> that was a ping, btw :-)
09:23:13 <ZsoL> gotit, thx :-)
09:23:40 <phlpp> hmm
09:23:54 <shapr> hiya Jaak
09:24:17 <phlpp> @pl s -> dropWhile (==s!!0) s
09:24:17 <lambdabot> (line 1, column 3):
09:24:18 <lambdabot> unexpected ">" or "-"
09:24:18 <lambdabot> expecting variable, "(", operator or end of input
09:24:32 <phlpp> @pl \s -> dropWhile (==s!!0) s
09:24:32 <lambdabot> dropWhile =<< (==) . (!! 0)
09:24:38 <phlpp> wtf
09:24:49 <dons> ?users
09:24:49 <lambdabot> Maximum users seen in #haskell: 408, currently: 394 (96.6%), active: 21 (5.3%)
09:25:30 <mrd> phlpp: reader monad
09:25:58 <phlpp> @index group
09:25:58 <lambdabot> Data.List
09:26:15 <ricky_clarkson> I've kinda asked this before, but maybe I can phrase it better this time.
09:26:27 <mrd> @faq
09:26:27 <lambdabot> The answer is: Yes! Haskell can do that.
09:26:38 <ricky_clarkson> Ah, thanks.
09:26:42 <dons> heh
09:27:30 <ricky_clarkson> sicp covers streams, in which delay and force are used so that you don't end up recalculating parts of a stream.
09:27:49 <mrd> delay and force are explicit lazy evaluation operators
09:27:55 <ricky_clarkson> Do Haskell's lists do something similar, or recalculate?
09:28:04 <mrd> haskell's lists are implicitly lazy
09:28:13 <mrd> much like myself in the morning
09:28:34 <faxathisia> lol
09:28:41 <phlpp> @pl (\s -> map (\x -> (show $ length x) ++ [head x]) (Data.List.group s))
09:28:42 <lambdabot> map (ap ((++) . show . length) (return . head)) . ((Data . List) .) . group
09:29:13 <ricky_clarkson> Ok, but given a list where each element takes 1 second to compute, if you ask for the first two elements, twice, does that take 4 seconds?
09:29:22 <mrd> no
09:29:44 <conal> shapr: i had a follow-on thought to a recent conversation.  maybe we're programming "functionally" when we use Data.* and "imperatively" when we use Control.*.  i don't think (pure) functional programming has a notion of control, just values/data.
09:29:47 <ricky_clarkson> How does it decide when to throw away the 'forced' elements?
09:30:00 <mrd> when the garbage collector picks them up
09:30:01 <faxathisia> garbage collection
09:30:10 <pitecus> Does anyone know of an implentation of a typeclass for String-like things like [Char] or ByteString?
09:30:11 <conal> gc & laziness are sort of dual
09:30:23 <ricky_clarkson> Ok, brilliant.
09:30:24 <faxathisia> gc and type safety also
09:30:31 <conal> faxathisia: ?
09:30:32 <mrd> indefinite extent bindings basically require GC
09:30:39 <mrd> yea and type safety
09:30:40 <ricky_clarkson> Does the type system tell the GC anything?
09:30:46 <dcoutts_> pitecus: usually the answer is just to pick one and then use pack/unpack to convert.
09:30:59 <mrd> though you can devise some ridiculously complicated system which changes variables types after free() I suppose
09:31:12 <vincenz> dcoutts_: I think it's more of an interface and less of a pragmatic solution queustion
09:31:17 <faxathisia> conal: I think it's hard to have manual deallocation and type safety since you can clear away an object there is a reference to
09:31:17 <conal> i meant that laziness handles birth and gc death
09:31:34 <conal> faxathisia: is that a type safety issue?
09:31:39 <faxathisia> yeah
09:31:40 <dcoutts_> pitecus: there's a type class of traversable things
09:31:42 <pitecus> dcoutts, i want a few functions which work on both types
09:31:43 <vincenz> faxathisia: no it's not
09:31:46 <cjay> ricky_clarkson: regarding reversed lists: http://www.haskell.org/pipermail/haskell-cafe/2007-July/029485.html
09:31:48 <lambdabot> Title: [Haskell-cafe] snoc vs cons, http://tinyurl.com/37kbsx
09:31:54 <mrd> it means: free(x); *x; is not type safe but *x; free(x); might be
09:31:55 <shapr> conal: So what's the relationship between logic programming (as in Prolog) and functional programming?
09:31:57 <pitecus> dcoutts, is ByteString a Traversable?
09:31:59 <conal> faxathisia: i get the connection with safety but not type safety.
09:32:10 <mrd> it's not decidable statically
09:32:12 <vincenz> mrd: that's an issue of scoping rules, not type safey
09:32:20 <dons> pitecus: oh, hmm. no. i'm not sure it can be made so, either, due to monomorphism
09:32:23 <mrd> it's very much an issue of type safety
09:32:24 <faxathisia> yeah, what mrd said
09:32:25 <mrd> x is in scope
09:32:35 <vincenz> right, scoping rules :)
09:32:36 <faxathisia> I think not decidable statically is the key
09:32:38 <pitecus> duh
09:32:45 <mrd> but the first example will cause the program to crash and the second shouldn't assuming the rest of the program does the right thing
09:32:46 <dons> its not a Monad either, for example
09:32:53 <conal> shapr: pure logic programming is sort of like functional programming but more so.  i.e., more what and less how.
09:33:08 <conal> shapr: and both are about being, while imperative is about doing
09:33:27 <shapr> Sounds mystical.
09:33:41 <ricky_clarkson> Verbs are doing words, and be is a verb. ;)
09:33:58 <dcoutts_> pitecus: no, because ByteString is not in Functor
09:34:06 <phlpp> :t group
09:34:07 <lambdabot> forall a. (Eq a) => [a] -> [[a]]
09:34:09 <phlpp> @src group
09:34:09 <lambdabot> group = groupBy (==)
09:34:10 <ricky_clarkson> Being implies identity, which seems less important in FP than imperative.
09:34:13 <conal> ricky_clarkson: :)
09:34:54 <pitecus> so how do people go about defining interfaces that work for both type of strings??
09:35:20 <dcoutts_> pitecus: you can make a type class for conversions, you don't generally need a typeclass of their operations
09:36:03 <dcoutts_> conal: I've been thinking more about a combinator lib for a make-like rules system. We talked about it before at the hackathon.
09:36:06 <dcoutts_> conal: So currently our idea was to separately specify the targets an action reads and writes and the action itself.
09:36:10 * mrd wants module functors in Haskell'
09:36:18 <dcoutts_> conal: like Rule [Targets] [Targets] Action
09:36:24 <conal> dcoutts_: i remember
09:36:32 <dcoutts_> conal: but that's a bit annoying, we'd like to have just an Action
09:36:40 <pitecus> dcoutts_, wouldn't it be more efficient for an instance to use the ByteString operations directly rather than unpack, use list operations and pack back?
09:36:49 <dcoutts_> conal: and get from the construction of the Action what targets it reads and writes.
09:37:01 <conal> dcoutts_: somehow
09:37:11 <dcoutts_> conal: which means it can't be a monad of course, but perhaps an applicative functor or something
09:37:21 <dcoutts_> or an arrow, who knows exactly
09:37:22 <conal> dcoutts_: oh!
09:37:44 <conal> because you want some static analysis.  monad can't.  applicative & arrow can.
09:37:55 <dons> mm. the joy of working at galois: i get to write haskell libraries all day long, exclusively
09:37:56 <dcoutts_> conal: yes
09:37:58 <ricky_clarkson> cjay: Thanks for that about snoc.
09:38:02 <dcoutts_> conal: a make-like system is basically an incremental pure functional programming system
09:38:08 <conal> dons: such is happiness
09:38:19 <cjay> :)
09:38:31 <dcoutts_> conal: where the incremental bit is done by caching intermediate values, often storing things in files
09:38:44 <conal> dcoutts_: that's what i've been saying.
09:38:48 <dons> its good being able to concentrate on producing infrastructure code
09:38:59 <dcoutts_> conal: yes, well I've come round to the idea :-)
09:39:04 <conal> dcoutts_: :)
09:39:13 <Nafai> Any Yi hackers around?  I'm trying to install the latest source and I'm getting this: "Setup.hs: /home/nafai/share/yi-0.3/Yi: copyFile: does not exist (No such file or directory)"
09:39:24 <Nafai> Running GHC 6.8.1 and the Cabal that comes with it
09:39:25 <conal> dcoutts_: that means, no visible action.  just use DataDriven.
09:39:45 <dcoutts_> conal: obviously we need hacks/wrappers to lift calls of external processes into such a framework, but that's ok
09:40:09 <dcoutts_> conal: we have to do the checks dynamically there rather that by construction, but that's ok too
09:40:19 <conal> dcoutts_: yes.  as with FFI.  if those processes are pure, then unsafePerformIO them
09:40:28 <conal> dcoutts_: checks?
09:40:44 <dcoutts_> conal: checks that they're only reading and writing the files they say they will
09:41:01 <dcoutts_> that they have the correct dependencies & targets
09:41:09 <conal> dcoutts_: oh.  i'd take it further and simpler and eliminate files altogether from the programming model.
09:41:22 <dcoutts_> conal: ah but in a make system we need them
09:41:44 <dcoutts_> conal: our intermediate cached values are very often files
09:41:58 <dcoutts_> they're not all files, but many of them are
09:42:56 <conal> dcoutts_: yes. in what i'm thinking of, the files would be there but not in the programming model.  their entire life-cycle would be managed, as with memory in pure functional programs.
09:43:31 <dcoutts_> conal: ok, so I was imagining they're not in the model too as much as possible, but they are there in the implementation because ghc really reads and writes files.
09:43:50 <dcoutts_> conal: for a make system the abstraction we can make is that we're calculating a pure value, but caching lots of stuff to make incremental computation better, and thats done mutatively.
09:44:16 <dcoutts_> conal: if it were all in memory it'd be nicer, we could have series of changing values
09:44:23 <dcoutts_> but it's not
09:44:39 <conal> dcoutts_: yes.  that situation is no different from pure functional programming in general.  lots of mutation happens under the covers.
09:44:41 <dcoutts_> hia grahamhutton
09:44:48 <grahamhutton> hi duncan!
09:45:14 <dcoutts_> conal: right, graph reduction with caching for incremental (re)-evaluation
09:45:21 <conal> dcoutts_: exactly!
09:45:39 <conal> dcoutts_: but it all stays out of the semantics
09:45:45 <dcoutts_> conal: and in a make system, some of those caches will be in memory and some will be real files with changing content
09:46:12 <conal> dcoutts_: yep.  two different representations of the same simple semantics.
09:46:18 <dcoutts_> right
09:47:04 <dcoutts_> conal: so much of cabal is concerned with configuration etc, which is again a time changing value. And some bits deal with running programs. It's only the latter that need to be lifted into the model.
09:47:53 <conal> dcoutts_: i don't follow.  what's in which model and what's out?
09:48:41 <puusorsa> @src foldl'
09:48:41 <lambdabot> foldl' f a []     = a
09:48:41 <lambdabot> foldl' f a (x:xs) = let a' = f a x in a' `seq` foldl' f a' xs
09:49:05 <dcoutts_> conal: I'm not sure 100%, let me give an example. I'd like to be able to write an action, and then do three things with it. 1 get the set of targets the action reads, 2 get the set of targets the action writes, 3 'run' the action.
09:49:23 <EvilTerran> evenin' all
09:50:06 <Nafai> Evening EvilTerran
09:50:16 <dcoutts_> conal: the targets are the named intermediate values that get cached and actions get re-run when targets content changes.
09:50:38 <conal> dcoutts_: i don't know why you'd want to do get that explicit instead of letting the DataDriven lib do it for you.
09:50:43 <dcoutts_> conal: so overall we get a computation by scheduling the actions in the right order, respecting their deps.
09:51:08 <dcoutts_> conal: hmm, well perhaps I can be less explicit, but we still do have real files that will be read and written.
09:51:11 <conal> dcoutts_: sure, if you think in terms of actions.
09:51:37 <conal> dcoutts_: just as memory cells to be read and written.  let the RTS do it.
09:51:53 <conal> and do it transparently & well
09:52:17 <faxathisia> @hoogle [a] -> [a] -> [a]
09:52:17 <lambdabot> Prelude.(++) :: [a] -> [a] -> [a]
09:52:17 <lambdabot> List.intersectBy :: (a -> a -> Bool) -> [a] -> [a] -> [a]
09:52:17 <lambdabot> List.unionBy :: (a -> a -> Bool) -> [a] -> [a] -> [a]
09:52:36 <conal> dcoutts_: i don't think we need any notion of "action", just pure functions with an applicative functor of time-varying values.
09:52:48 <conal> dcoutts_: hiding things like IORef and File
09:53:07 <conal> dcoutts_: under a pure interface with simple semantics
09:53:20 <conal> no IO
09:53:36 <dcoutts_> conal: yes, I'd like to write my rules on that level, let (foo.o, foo.hi) = ghc foo.hs
09:54:08 <conal> dcoutts_: exactly.  that's how i program.  though it'd be "ghc <$> foohs"
09:54:11 <dcoutts_> conal: and I have to write the interpreter that goes and 'does' those things in the right order to calculate the result
09:54:29 <conal> dcoutts_: it's already written
09:54:34 <conal> @wiki DataDriven
09:54:34 <lambdabot> http://www.haskell.org/haskellwiki/DataDriven
09:54:59 <dcoutts_> conal: ok, well I have to write the bit that lifts files and running external programs into such a framework
09:55:32 <conal> dcoutts_: yes.  or i do, or we do it together.  and everyone benefits.  not just cabal.
09:55:42 <dcoutts_> conal: sounds nice :-)
09:55:42 <conal> leverage!  that's what FP is good at.
09:55:53 <conal> dcoutts_: so let's do it.  :)
09:55:53 <faxathisia> @hoogle intersection
09:55:54 <lambdabot> Data.IntMap.intersection :: IntMap a -> IntMap b -> IntMap a
09:55:54 <lambdabot> Data.IntSet.intersection :: IntSet -> IntSet -> IntSet
09:55:54 <lambdabot> Data.Map.intersection :: Ord k => Map k a -> Map k b -> Map k a
09:56:15 * dcoutts_ reads DataDriven again
09:57:40 <dcoutts_> conal: one thing I don't see yet is how I can name some of the variables, eg with filenames
09:57:51 <conal> there's so much imperative legacy in our thinking.  i'd like to use FP thinking in working with functional programs, which means an FP rethinking of all of our tools (make, ghc, ld, ...).
09:58:08 <dcoutts_> conal: like in the ghc <$> foohs example, I need to be able to specify the file location of those time varying values
09:58:17 <conal> dcoutts_: don't.  name the values, not the storage.
09:58:29 <conal> dcoutts_: ok
09:58:33 <dcoutts_> conal: I do need to specify file names, it is vital
09:58:49 <dcoutts_> conal: I know it's not nice and it's not needed for IORefs etc
09:59:05 <dcoutts_> but it is needed for files in a make system
09:59:06 <conal> it all depends how far we want to take this idea.  ultimately, i want to do *everything* functionally.  so files are never visible concepts.  but for now...
09:59:32 <conal> for now, just wrap up a file in the Source interface.
09:59:43 <dcoutts_> conal: how does one declare a time varying value?
10:00:41 <conal> dcoutts_: there are different ways.  pure & <*>, and various wrappers.  for instance, take a file, make a change-notifier event, and you have value of type Source String.
10:01:42 <conal> foo_o = ghc <$> readFile "foo.hs"
10:01:45 <conal> or something like that
10:01:58 <conal> where readFile :: FileName -> Source String
10:02:20 <conal> foo_exe = ld <$> foo_o
10:02:28 <dcoutts_> conal: ok. We also need it on the other end, the output file name.
10:02:48 <conal> run_out = foo_exe <*> readFile "input-data"
10:03:28 <conal> dcoutts_: yep.  something like writeFile :: FileName -> Source String -> IO ()
10:03:41 <conal> dcoutts_: which essentially spins off a thread
10:03:55 <dcoutts_> conal: other bits are nice and fit nicely into the model and don't need named cached values, stuff like configuration settings.
10:04:35 <conal> dcoutts_: yep.  and GUIs and internet-sourced info.
10:04:56 <conal> dcoutts_: (but i guess you meant other bits of cabal)
10:05:08 <conal> dcoutts_: installation also!
10:05:29 <conal> repos and releases are time-varying also.
10:05:49 <conal> they get grabbed automatically from over the internet, compiled & installed
10:05:54 <conal> testing also
10:06:33 <conal> probably all aspects of making, tweaking, building, delivering, installing, & running code.
10:07:00 <conal> in a simple, genuinely functional (no IO) framework.
10:08:25 <conal> and note the foo_exe case above, which is nicely higher-order.
10:08:40 <conal> oops: i meant the run_out case
10:09:12 <conal> run_out uses <*> instead of <$> .
10:09:29 <conal> because foo_exe is a time-varying function!
10:10:26 <conal> this kind of thing is why i love FP and want to see us to more functional programming and less imperative programming in a functional language.
10:10:42 <ricky_clarkson> Can you call something a function if it has a different value on each run of your program, but within a running program always gives the same thing?
10:12:13 <conal> ricky_clarkson: same input & different output?  then no.  others may disagree.
10:12:42 <vincenz> they're two different functoins
10:12:45 <dcoutts_> conal: yes, basically everything cabal does can be cast in a dependency system
10:12:46 <vincenz> they might just have the same name
10:12:59 <ricky_clarkson> They can't possibly have the same input and give different outputs.
10:13:16 <ricky_clarkson> Part of the input is the actual running program (or something about it, such as start time).
10:13:20 <conal> vincenz: i like that answer
10:13:56 <vincenz> conal: thanks :)
10:14:05 <araujo> ricky_clarkson, then it should be inside a monad, like IO
10:14:16 <conal> ricky_clarkson: agreed.  so to be more precise about my question: same argument value & different result?
10:14:38 <dcoutts_> conal: and cabal could uses both pull and push style. Often we want to do something like "build this lib now" but we'd also like "keep this lib up to date while I edit these source files"
10:14:42 <vincenz> araujo: he said input
10:15:02 <araujo> yes vincenz
10:15:04 <wolverian> has haskelldb bitrotted? is there an alternative? coddfish doesn't seem to give actual db connectivity..
10:15:17 <vincenz> araujo: input being monadic does not mean thefunction needs to be monadic
10:15:19 <conal> dcoutts_: yes.  that's a new dimension i'm excited to explore.  a rich algebra of evaluation strategies.
10:15:52 <araujo> vincenz, The input needs to be monadized
10:15:59 <araujo> it's what i meant
10:16:06 <conal> dcoutts_: DataDriven now has just one such policy, and it's certainly not adequate for all situations.
10:16:27 * araujo wonders if this term exists :-P
10:16:37 <dcoutts_> conal: and we need to do parallel evaluation for Cabal too
10:16:39 <vincenz> araujo: sounds painful :)
10:16:47 <vincenz> "You've been monadized"
10:16:50 <araujo> :-D
10:16:55 <conal> dcoutts_: that aspect is perhaps the most interesting research content.  then there's the great sex appeal of applying the functional paradigm to software management.
10:17:05 <conal> dcoutts_: parallel -- cool!
10:17:11 <araujo> "I am monadized"
10:17:13 <araujo> :-P
10:17:15 <dcoutts_> conal: everyone wants parallel builds
10:17:15 * mrd wonders if someday we may hear a pointy haired middle manager ask "But is that Monadized?"
10:17:26 <araujo> haha
10:17:34 <vincenz> dcoutts_: parallelism would easily work
10:17:42 <araujo> mrd, someday .. in the distant future
10:17:43 <conal> dcoutts_: i hadn't thought about that angle.  it really grabs me.
10:17:50 <dcoutts_> vincenz: it does in our prototype, yes.
10:17:50 <vincenz> In a sense, it's similar to what Kiselyov posted on CChan's blog.
10:18:03 <ricky_clarkson> I was thinking that if you have a time-varying 'function' you could represent its outputs as a list.  Perhaps I'm just reinventing monads from a streams angle.
10:18:05 <vincenz> They also had data-dependencies, in the forms of continuations that required evaluation
10:18:15 <vincenz> Then the under the hood manager would ask those in 'parallel'
10:18:15 <mrd> The Monadator will be sent back through time to stop the madness
10:19:07 <dcoutts_> conal: that's what make is, if you wear funny glasses, a parallel incremental graph reduction machine
10:19:07 <conal> ricky_clarkson: see FRP, which deals with time-varying values that can change continuously, as well as composable events for discrete changes.
10:19:22 <conal> dcoutts_: nicely put :)
10:19:38 <vincenz> dcoutts_: I would think that's valid for any dependency DAG
10:20:01 <dcoutts_> vincenz: right, and that's the sort of style we should make cabal use
10:20:07 * vincenz nods
10:20:10 <conal> vincenz: me too.  that's why it's such a general powerful idea.
10:20:45 <conal> and dependency DAGs are turing complete
10:20:56 <conal> (i think)
10:21:17 <conal> in that it's another name for the lambda calculus
10:21:19 <vincenz> dependency DAGs are also what are used to map operations to execution units
10:21:59 <vincenz> (in compilers)
10:22:04 <vincenz> same idea, parallelise as much as possible
10:22:19 <vincenz> There's a lot more work in tha area, because those people deal with heterogeneous units
10:22:55 <ricky_clarkson> conal: Does FRP relate to Actors at all?
10:23:16 <dozer> sure, and you tend to emply heuristics quite heavly as brute-force optimizetion of the mapping from the DAG to the hardware can very quicly become as expensive as running the program in the first place
10:23:31 <vincenz> dozer: indeed
10:23:47 <conal> ricky_clarkson: a bit, i guess.  the main differences are (a) continuous time, and (b) purely functional (simple semantics).
10:23:48 <vincenz> but the concept of push vs pull (ALAP vs ASAP) is not novel there
10:24:02 <vincenz> erm pull would be ALAP of course
10:24:04 <vincenz> so flip those two
10:25:23 <conal> vincenz: and ALAP and ASAP are just two points in a big space of possible policies.  i bet there's a nice compositional algebra from which people can roll lots of useful strategies.
10:25:36 <vincenz> conal: That would be an interesting algebra :)
10:26:50 <conal> one example of a policy is that UI toolkits throw out most mouse motion events, so as not to overwhelm the handlers.
10:27:26 <conal> another example i heard about is a syntax-aware editor rerunning analysis after a two-second idle interval.
10:27:48 <conal> neither ALAP or ASAP
10:27:56 <vincenz> right
10:28:01 <vincenz> but there, throwing out events is allowed
10:28:02 <conal> some kind of load management, i guess
10:28:05 <vincenz> in the models I was thinking of, this is not
10:28:15 <conal> vincenz: why "allowed"?
10:28:33 <vincenz> conal: you can process mouse events in a lossy fashion
10:28:42 <vincenz> you can not process operations in a cpu in a lossy fashion
10:28:55 <conal> vincenz: that's the assumption, but when is that assumption valid?
10:28:59 * dcoutts_ is performing on stage in an hour so must depart
10:29:07 <conal> dcoutts_: what??
10:29:10 <vincenz> "throws out most mouse motion events"
10:29:23 <dcoutts_> conal: I'm in a Pantomime :-)
10:29:33 <ricky_clarkson> dcoutts_: Are you the front or the back?
10:29:34 <conal> dcoutts_: cool!  i had no idea.  :)
10:30:00 <dcoutts_> ricky_clarkson: actually I'm not the pantomime camel, but we do have one of those in the show :-)
10:30:07 <conal> vincenz: yes, that's the policy.  the interesting question to me is under what assumptions does that policy work.
10:30:34 <vincenz> conal: right, when is lossy allowed and when not
10:31:01 <conal> vincenz: right.  my question is a thought experiment, in order to tease out a reusable tool.
10:31:13 <conal> from a common hack
10:31:29 <vincenz> well
10:31:36 <vincenz> I would presume "whenever there's enough redundancy"
10:32:05 <conal> vincenz: what's "redundancy" here?  identical event values?
10:32:14 <vincenz> or otherwise said, the gradient of the eventstream is soft
10:32:28 <vincenz> unlike operations, where you jump all over the map
10:33:22 <conal> vincenz: okay.  and there's another assumption being made, about a gradual eventstream leading to only gradual results.
10:33:24 <conal> i.e., continuity.
10:33:29 <vincenz> right
10:33:31 <vincenz> linearity?
10:33:35 <vincenz> erm
10:33:38 <vincenz> continuity, like you said
10:34:29 <conal> vincenz: and that assumption is *not* fundamentally valid.
10:34:42 <conal> it's only often the case.
10:34:45 <vincenz> right
10:34:54 <vincenz> and actually, even for mouse-events it's not valid
10:35:05 <conal> because?
10:35:06 <vincenz> imagine having a square be active when your mouse is in it
10:35:19 <vincenz> altough I guess the inaccuracy in the model is of little relevance to the user
10:35:21 <davidL> is linear search or binary search faster on an unsorted array?
10:35:37 <mauke> who cares?
10:35:42 <mauke> only of them works
10:35:48 <conal> vincenz: mouse events can be used for anything.  how about counting them?
10:36:00 <ricky_clarkson> binary search will fail, but do it faster!
10:36:02 <vincenz> conal: I'm reminded of a phrase here
10:36:37 <vincenz> conal: You have to examine all problems from the human context
10:36:45 <vincenz> conal: what's the relevance of the number of mouse events
10:38:44 <davidL> what if the algorithm sorts the data first, so O(n*log n) + O(log n)?
10:38:59 <vincenz> davidL: not all data is sortable in n log n
10:39:01 <conal> vincenz: that example is a concrete demonstration of the existence of expressible clients of mouse motion for which the discard-motion policy give very large errors.
10:39:07 <davidL> nvm, that's worse than O(n)
10:39:09 <ricky_clarkson> O(n*log n) is O(n*log n)
10:39:14 <ricky_clarkson> Er..
10:39:18 <vincenz> conal: agreed
10:39:23 <ricky_clarkson> O(n*log n)+O(log n) is O(n*log n)
10:39:37 <conal> vincenz: if i design a software system to only work for the cases i can think of then, i'm doomed to incorrectly predict the future, and my future users will suffer.
10:40:06 <conal> that's why software is complex and specialized rather than simple and general.
10:40:22 <davidL> so my teacher was wrong in asking which one would be faster on an unsorted array?
10:40:23 <ricky_clarkson> conal: If you design for cases you can't think of, well, you can't know whether you've solved them.
10:41:13 <conal> ricky_clarkson: i don't design for cases.  i design for simplicy & generality, and then i reality-check against cases i and others can think of.
10:41:17 <hpaste>  faxathisia pasted "large/bad function" at http://hpaste.org/4131
10:41:41 <conal> if a simple design works for all cases currently imaginable, then it's much more likely to work for cases we don't yet think of, as compared to a complex design.
10:41:42 <faxathisia> this seems kind of over-complex and hard to read ;|
10:41:48 <ricky_clarkson> conal: I do the same thing but in the other order.
10:41:51 <faxathisia> Is it? and any idea how to improve
10:42:12 <conal> ricky_clarkson: ?
10:43:05 <ricky_clarkson> conal: I have things to solve and then design for simplicity and generality.
10:43:25 <ricky_clarkson> Otherwise I tend to overgeneralise, I've found.
10:44:10 <conal> faxathisia: could use some factoring out of the repetition.
10:44:25 <faxathisia> oh yeah..
10:44:33 <faxathisia> thanks, I meant to do that
10:44:47 <davidL> vincenz: what kind of data can't be sorted in n log n?
10:44:48 <conal> ricky_clarkson: sure.  i meant the goal of design more than the order.
10:45:42 <vincenz> davidL: data that is not comparable
10:45:45 <conal> faxathisia: besides simplifying your code, the factoring will make it easy to look at the remaining complexity.
10:45:59 <vincenz> s/comparable/ordered
10:46:06 <olsner> two obvious refactorings: you can move || to inside the any condition and factor out liveNeighbours (length $ filter etc)
10:46:17 <faxathisia> ooh
10:46:19 <faxathisia> ok :D
10:46:34 <davidL> vincenz: what about merge sort, its worst case is n log n
10:46:42 <olsner> grid ! cell == Alive && liveNeighbours `elem` [2,3] ;-)
10:46:49 <vincenz> davidL: read again what I said
10:46:55 <vincenz> lu u sp no   :luo
10:47:47 <shapr> wow
10:47:48 <jimstutt> dons: where should I post my 6.8.1 build error with plugins-1.0? Direct to you?
10:47:54 <shapr> vincenz: How'd you do that?
10:47:59 <olsner> also, use of concatMap suggests that it's all replacable by some magic list monad magic :P
10:48:12 <vincenz> nq  s ul   u  'ou ,uop  :ds
10:48:27 <dons> jimstutt: grab the darcs version of hs-plugins
10:48:30 <olsner> vincenz: no, the bug is in you!
10:48:31 <shapr> That can't be a bug :-)
10:48:42 <jimstutt> dons: ta
10:48:54 <dons> jimstutt: oh, but it won't build with 6.8.1
10:49:00 <dons> that's not supoprted yet.
10:49:07 <dons> what project are you using that needs hs-plugins, btw?
10:49:18 <vincenz> onb  pun l  o s s  q 
10:49:19 <conal> (concatMap ==> monad) or a list comprehension
10:49:30 <davidL> vincenz: you said data that is not ordered, is that not the worst case (beside data that's reversed)?
10:50:04 <vincenz> davidL: Yes, what I meant is, the elements are not ordered
10:50:09 <vincenz> davidL: there is no < or >
10:50:27 <jimstutt> dons: lambdabot
10:50:33 <davidL> oh, what's that have to do with complexity?
10:50:37 <phlpp> @src concat
10:50:37 <lambdabot> concat = foldr (++) []
10:50:41 <phlpp> !
10:50:54 <phlpp> @src concatMap
10:50:54 <lambdabot> concatMap f = foldr ((++) . f) []
10:50:58 <vincenz> davidL: it means you can't sort
10:51:16 <vincenz> davidL: btw, if you're only doing one lookup O(n), if it's not presorted, sorting it first is going to get you worse performance
10:51:20 <phlpp> > (\s -> foldr (++) "" $ concatMap (\x -> (show $ length x) ++ [head x]) (Data.List.group s)) "WWWAAA"
10:51:21 <lambdabot>  Couldn't match expected type `[Char]' against inferred type `Char'
10:51:28 <phlpp> > (\s -> concatMap (\x -> (show $ length x) ++ [head x]) (Data.List.group s)) "WWWAAA"
10:51:28 <lambdabot>  "3W3A"
10:51:44 <dons> jimstutt: ah ok. not supported with 6.8 yet
10:51:46 <davidL> vincenz: that just means it can't be sorted period, not that it will be worse than n log n (which is what I thought you meant)
10:52:23 <vincenz> davidL: it means that you can never get log n look up
10:53:00 <phlpp> > (\s -> (map (length &&& head) . group) "WWWAAA"
10:53:00 <lambdabot> Unbalanced parentheses
10:53:26 <kpreid> > (map (length &&& head) . group) "WWWAAA"
10:53:27 <lambdabot>  [(3,'W'),(3,'A')]
10:53:30 <vincenz> shapr: ldl/op//:d
10:53:32 <phlpp> :D
10:53:42 <phlpp> vincenz: lol wtf
10:54:12 <faxathisia>  s s
10:54:50 <pejo> Whatever characters you guys are using - they're very nasty to my terminal I must say.
10:54:56 <davidL> @docs pcap
10:54:56 <lambdabot> pcap not available
10:55:38 <mauke>    
10:55:56 <vincenz> mauke: what's tha?
10:56:01 <davidL> I wonder if the pcap  works with winpcap
10:56:03 <jimstutt> dons: is there any way of being notified of cabal updates. I've edited lots in 2 weeks trying to get some web app server and db working.
11:02:04 <dons> jimstutt: updates to cabal itself?
11:05:57 <jimstutt> dons: oops getting tired. No, there are too many needed to keep checking. Will app devs announce app package upgrades somwhere? Obv. 1 == v. newb. Last Q, tnx.
11:06:29 <dons> oh, package upgrades are available via rss
11:06:31 <Dybber> Can anyone explain the definition of the Monad.guard-function to me? I don't understand how the "return ()"-part makes it work
11:06:38 <Dybber> http://members.chello.nl/hjgtuyl/tourdemonad.html#guard
11:06:39 <lambdabot> Title: A tour of the Haskell monad functions
11:06:39 <dons> http://hackage.haskell.org/packages/archive/recent.html
11:06:43 <mauke> @src guard
11:06:43 <lambdabot> guard True  =  return ()
11:06:43 <lambdabot> guard False =  mzero
11:06:45 <dons> keep an eye on that, or subscribe
11:06:46 <jimstutt> dons: ta
11:07:06 <dons> dcoutts_, kolmodin, i moved the binary homepage, http://code.haskell.org/binary/
11:07:06 <lambdabot> Title: Data.Binary - efficient, pure binary serialisation for Haskell
11:07:08 <mauke> Dybber: I don't understand what you don't understand :-)
11:09:55 <kolmodin> dons: nice
11:10:20 <kolmodin> and it's updated, very nice :)
11:15:42 <kaol> @users
11:15:42 <lambdabot> Maximum users seen in #haskell: 412, currently: 411 (99.8%), active: 16 (3.9%)
11:19:03 <Dybber> mauke, ok, could the () in "return ()" be replaced by something else? I can't see what the unit-value has to do with it.
11:19:49 <ricky_clarkson> :t return ()
11:19:53 <lambdabot> forall (m :: * -> *). (Monad m) => m ()
11:20:49 <ricky_clarkson> return () within IO returns a value of type IO ().  A bit like having to return null in Void (not void) methods in Java, or nil in lisps.
11:21:04 <ricky_clarkson> s/returns/is/
11:21:32 <Dybber> hmm it looks like it works in the same way when replacing "return ()" with "return undefined"
11:22:35 <dozer> ricky_clarkson: I tend to think of return () as like poping a function stack with zero return values on it
11:23:10 * ricky_clarkson popes off.
11:23:22 <Zao> Notable is that return doesn't exit the function.
11:23:25 <mauke> Dybber: it indicates that there's no useful return value
11:24:49 <dozer> hence 'like', not is :)
11:25:01 <dozer> perhaps it is a rubish analogy
11:25:07 <slava> hey rickard1
11:25:09 <slava> um
11:25:12 <slava> ricky_clarkson*
11:25:59 <ricky_clarkson> Hi, slava.
11:26:04 * jedbrown thinks the binary Builder is beautiful.
11:26:23 <slava> ricky_clarkson: i'm porting the jedit syntax highlighting package to factor
11:26:39 <slava> revisiting some of my horrid java code from 2000
11:26:51 <ricky_clarkson> slava: You're right, it's horrid.
11:27:00 <ricky_clarkson> Some comments were amusing, from recollection.
11:27:11 * ricky_clarkson -> work
11:29:04 <fasta> Suppose I read a tree from a file and then do getCPUTime, it there any possibility in which getCPUTime gets executed before the complete tree is built in memory(i.e. is available in rnf)?
11:30:50 <monochrom> There exists code that does that. There exists code that doesn't do that.
11:31:01 <byorgey> fasta: it depends what mechanism you use to read the file.
11:31:25 <Heffalump> it seems very likely that it would be executed before the tree was built
11:31:48 <Heffalump> since the tree would just be a suspension of read + string from file
11:33:01 <fasta> Heffalump: so in, tree <- build =<< readFile "treeFile" tree only gets evaluated to WHNF?
11:33:45 <monochrom> That action doesn't even start reading.
11:33:49 <Heffalump> there's no guarantee it'll even get to WHNF
11:33:59 <Heffalump> and readFile is lazy, so as monochrom says it won't even read
11:34:08 <Saizan> > do x <- return undefined; return "foo" :: Maybe String
11:34:16 <lambdabot>  Just "foo"
11:34:50 <fasta> Ok, so it's as lazy as a let binding?
11:35:19 <monochrom> I haven't seen the relevant code of "build".
11:36:29 <Heffalump> it can be
11:36:42 <fasta> Ok, suppose build is the deriving Read implementation.
11:37:07 <fasta> (and the tree is just a purely functional tree, no references)
11:37:24 <monochrom> build = read?
11:37:29 <fasta> yes
11:38:09 <monochrom> build =<< readFile doesn't type-check. I am not being anal. The actual detailed code is important.
11:38:09 <fasta> read::Tree (Maybe Int) for example
11:38:50 <fasta> liftM build (readFile "treeFile"), sorry.
11:38:52 <monochrom> There are one-character changes that completely flip behaviours.
11:39:11 <Saizan> in that case i think it won't even start reading from the file
11:39:19 <fasta> Yes, I know you are not being anal, I was simply imprecise.
11:40:14 <monochrom> Surprisingly, readIO =<< readFile "blah" type-checks and will be pretty eager.
11:40:36 <fasta> readIO?
11:40:40 <monochrom> (That is why I had to press it. read and readIO have opposite behaviours.)
11:40:41 <fasta> @where readIO
11:40:41 <lambdabot> I know nothing about readio.
11:40:46 <fasta> @hoogle readIO
11:40:53 <lambdabot> Prelude.readIO :: Read a => String -> IO a
11:40:53 <lambdabot> Data.IORef.readIORef :: IORef a -> IO a
11:41:08 <monochrom> @source readIO
11:41:08 <lambdabot> readIO not available
11:42:18 <monochrom> readIO blah is approximately: case read blah of [(x,"")] -> return x; _ -> throw IO exception saying "parse error"
11:42:40 <monochrom> So you see it reads and parses right away.
11:42:54 <fasta> If build would read the file char by char by itself construct the tree in that fashion, what then?
11:42:56 <monochrom> Err, it forces reading and it parses right away.
11:43:51 <monochrom> There exists code that reads eagerly but builds a thunk that will build the tree, not the tree itself.
11:44:53 <monochrom> Any granularity and any extent of eagerness and laziness is possible.
11:45:45 <monochrom> Therefore all hypothetical, speculative questions are trivial to answer.
11:53:26 <effie_jayx> hello all
11:53:41 <effie_jayx> how would you describe runghc
11:54:42 <Saizan> non-interactive interpreter?
11:54:45 <mrd> a program
11:55:21 <mrd> i might describe it using words, perhaps typed into an IRC client
11:55:37 <effie_jayx> mrd,  heh
11:56:02 <fasta> I would stimulate various neural pathways.
11:56:23 <dmwit> It's just a compiler that automatically runs its results at the end.  No need to be mysterious about it.
11:57:00 <effie_jayx> thank you all
11:57:13 <dmwit> Well... maybe "just" and "compiler" don't really go together. =)
11:57:33 <thetallguy> Just compiler?
11:57:34 <monochrom> Don't make things complicated.
11:57:47 <EvilTerran> $ make complicated
11:58:05 <monochrom> $ make strip
11:58:13 <Botje> $ make sense
11:58:27 <monochrom> $ make believe
11:58:28 <fasta> $ make all
11:58:45 <Botje> $ make it so
11:58:51 <EvilTerran> :D
11:59:06 <olsner> $ rm -f Makefile
11:59:11 <ibid> oh no, community left #haskell. how shall we cope?
11:59:26 <kaol> *** No targets specified and no makefile found.  Stop.
11:59:40 <monochrom> That is great news. No community, no special interest groups.
11:59:49 <Botje> no hidden agendas!
11:59:59 <mrd> ibid: i suggest extreme sarcasm
12:00:00 * olsner hides his agenda
12:01:23 <mrd> we already have the Haskell cabal, though
12:01:29 <effie_jayx> thanks .. I think I got it
12:01:36 <dylan> mrd: there is no cabal
12:01:49 <mrd> naturally
12:01:51 <monochrom> there is no cabal. there is only Setup.hs
12:04:44 <nominolo> which is the illiterate cousin of Setup.lhs
12:06:04 <Saizan> there's cabal-setup.
12:06:25 <dons> this ruby/python fibonacci is funny
12:07:06 <dons> http://cgi.cse.unsw.edu.au/~dons/blog/2007/11/29#smoking
12:07:06 <lambdabot> Title: Haskell hacking
12:07:08 <dons> :)
12:08:20 <fasta> dons: you meant pathetic?
12:08:21 <mrd> like shooting fish in a barrel, except its a python
12:08:27 <dons> :)
12:08:30 <faxathisia> how do you check if some code is slower than i should be?
12:08:39 <dons> i dropped some Control.Parallel in there for fun
12:08:48 <mrd> why pseq over par?
12:09:18 <Jaak> dons: range(36) == [0..35]
12:09:38 <dons> ah ok. thanks Jaak
12:09:53 <dons> ah yep
12:10:00 <Jaak> made the same mistake myself :P
12:10:09 <fasta> dons: pseq is only required because detecting payoff is too difficult for the compiler?
12:11:17 <dons> Jaak: right, and makes no difference to the runtime, of course
12:11:20 <faxathisia> isn't it possible to have everything in parallel ?
12:11:25 <dons> fasta: what, to discover the parallelism?
12:11:27 <monochrom> dons: I want to tell you that similar coding in C results in similar speed with GHC, even back when 6.6.1.
12:11:28 <faxathisia> and not write `par` or `pseq`?
12:11:31 <fasta> dons: yes
12:12:22 <dons> there's no implicit paralellism analysis in ghc stable
12:12:31 <dons> only in one of the research branches
12:12:38 <dons> faxathisia: i want to ensure it gets forced too
12:12:52 <dons> http://programming.reddit.com/info/61no8/comments/
12:12:55 <dons> vote up :)
12:12:58 <faxathisia> is it possible to get the research branches
12:13:15 <fasta> dons: I don't understand why you call that implicit parallellism.
12:13:23 <fasta> dons: you are annotating it.
12:13:47 <dons> there's no thread forking involved
12:13:58 <fasta> dons: i.e. you example shows an annotation, but at the same time, you claim that GHC can do implicit parallellism.
12:14:03 <dons> unlike, say, if we wrote it in erlang, and had to spawn all over
12:14:14 <monochrom> Oh, right, it is not as implicit as full automation. But it is more implicit than hand-coding threads.
12:14:15 <faxathisia> It's not implicit imo
12:14:18 <fasta> dons: well, that's not implicit parallellism, imho.
12:14:27 <faxathisia> (Still.. it's good)
12:14:28 <dons> this is accepted use
12:14:30 <faxathisia> I want to try pH
12:14:37 <faxathisia> but it doesn't seem to exist
12:14:43 <mrd> import Control.Parallel
12:14:45 <fasta> dons: heh, I don't accept it and I am sure there are others who don't.
12:14:46 <monochrom> Isn't English a great language.
12:14:47 <dons> `par` and `pseq` are just hints, there's no thread control involved
12:14:59 <fasta> monochrom: you majored in it?
12:15:02 <dons> fasta, well, got the the HW and read the implicit parallelism papers
12:15:16 <dons> there's a big difference between scheduling threads yourself, and hinting to the compiledr
12:15:39 <faxathisia> is there any reason you can't just have the compiler put `par` inbetween everything?
12:15:42 <fasta> dons: a bunch of people claiming something is implicit parallelism doesn't imply that they get to redefine a concept that existed before.
12:15:46 <monochrom> No one needs a major to observe the peril of this bickering over what is "implicit".
12:16:03 <fasta> monochrom: no, I understand that.
12:16:09 <mrd> implicit perilism
12:16:09 <pejo> faxathisia, it's not always a win to do things in parallel.
12:16:24 <vincenz> There's a definite cost-tradeoff
12:16:37 <vincenz> And finding an optimal solution is NP-hard
12:16:53 <mrd> @faq can haskell solve NP-hard problems in polynomial time?
12:16:53 <lambdabot> The answer is: Yes! Haskell can do that.
12:17:02 <faxathisia> in the type system?
12:17:03 <faxathisia> :p
12:19:04 <monochrom> I propose "implicit threading".
12:19:22 <dons> fasta: i modified the text. better?
12:20:43 <fasta> dons: In "And you can parallelise it for free" s/free/cheaply
12:20:50 <fasta> dons: then it seems pretty much acceptable.
12:20:54 <dons> ok. :)
12:21:02 <dons> but that's in the title, so i'm leaving that.
12:22:16 <fasta> dons: also, a complete picture would show compile time, but since this is such a silly exercise...
12:22:48 <monochrom> ghc didn't take 30 seconds to compile this one with -O2
12:23:54 <fasta> No, but it could take 3, which is still long.
12:26:38 <fasta> dons: can do parallelism => can use par...
12:26:52 <dons> hmm?
12:27:39 <fasta> dons: you claim in that sentence that the compiler does the annotations; it merely interprets them.
12:28:04 <dons> oh, ambiguous use of 'do'
12:29:20 <fasta> dons: oh, right.
12:31:25 <dons> i love shooting fish in barrels. am i a bad person? :)
12:32:03 <Igloo> I don't know, but I bet all your barrels leak
12:32:55 <monochrom> he shoots if his water pistol. I think the barrels are safe.
12:32:59 <monochrom> s/if/with/
12:33:03 <dons> good idea
12:34:20 <bos> dons: nice post, but acangiano was wrong about tail calls having anything to do with the ruby speedup. that fib benchmark doesn't do tailcalls.
12:34:58 * Saizan was going to say that..
12:35:30 <faxathisia> how is it faster then?
12:35:39 <bos> who cares? it's ruby.
12:35:44 <dons> bos, oh, yes, that's true! i didn't even think to look at tath
12:35:45 <faxathisia> I wonder
12:36:09 <faxathisia> the haskell one is memoizing right?
12:36:12 <bos> no.
12:36:20 <dons> no memoising
12:36:24 <faxathisia> so if you use fibs = 1:... would it be even faster?
12:36:27 <dons> yeah
12:36:28 <bos> it's the exact same implementation as the python and ruby implementations.
12:36:34 <dons> about a gazillion times faster
12:36:42 <faxathisia> :D
12:37:19 <bos> it would actually rip a hole in the fabric of time, and finish before it started.
12:37:20 <jedbrown> Although it isn't tons faster in ghci (or ghc -e).
12:38:00 <bos> yes, ghci isn't fast.
12:39:15 <dons> i amended the text about tail calls taken from antonio's page.
12:39:53 <faxathisia> does anyone know why the ruby code is running faster?
12:40:01 <dons> this little demos are incredibly popular for some reason -- little bite sized lessons -- the programming equivalent of funny short films?
12:40:24 <dons> with a sense of drama as you watch the fights break out
12:43:21 <shapr> I wish tags were case sensitive.
12:43:23 * shapr grumbles
12:43:49 <Nafai> tags?
12:46:24 <rey_> dons: you kind of cheated though
12:46:37 <rey_> the ruby and python versions use bignums
12:46:40 <olsner> nothing's cheating if haskell wins
12:47:51 <shapr> Nafai: Yeah, have you used ctags/etags/hasktags?
12:48:01 <shapr> Nafai: It's quite handy to use along with M-. in emacs.
12:48:15 <Nafai> etags, way back when
12:48:22 <Nafai> Code navigation is a must for me now
12:48:37 <Nafai> If I did any serious haskell coding, I'd want that
12:48:42 <Nafai> Eclipse has spoiled me in that regard
12:52:43 <olsner> is there a good name for liftM2 for the (->) monad, other than just using the monad instance?
12:53:03 <jwp> hrm, python with psyco handles that a lot better than plain ol' cpython. still gets spanked by haskell, tho
12:53:14 <idnar> @src (-> r) liftM2
12:53:14 <lambdabot> Source not found. Have you considered trying to match wits with a rutabaga?
12:53:27 <mauke> @src liftM2
12:53:27 <lambdabot> liftM2 f m1 m2 = do { x1 <- m1; x2 <- m2; return (f x1 x2) }
12:53:31 <olsner> I mean, liftM2 is great for @pl and obfuscation, but not very clear when using it to combine functions
12:53:46 <mrd> the same places you might use liftM or fmap, but with two parameters
12:54:13 <jwp> 5.6s(psyco.full()) vs 22.7s(cpython) on my laptop here
12:55:10 <jsnx> is there a module for doing permutations (e.g. `choose 2 list`
12:55:13 <jsnx> )
12:55:38 <mrd> > sequence (repeat 2 [1 .. 10])
12:55:39 <lambdabot>  Couldn't match expected type `[t] -> [m a]'
12:55:46 <mrd> > sequence (replicate 2 [1 .. 10])
12:55:47 <lambdabot>  [[1,1],[1,2],[1,3],[1,4],[1,5],[1,6],[1,7],[1,8],[1,9],[1,10],[2,1],[2,2],[2...
12:56:19 <monochrom> It seems to me liftM2 f m1 m2 = f m1 m2 for (->)
12:56:44 <olsner> monochrom: liftM2 f g h x = f (g x) (h x)
12:57:05 <monochrom> oopsie
12:57:58 <resiak> dons: are you still based in .au?
12:58:20 <resiak> or is it only your blog system? :)
12:58:20 <faxathisia> @pl (\f g x -> w f g g x)
12:58:20 <lambdabot> join . w
12:58:36 <faxathisia> :t `join . liftM2`
12:58:37 <lambdabot> parse error on input ``'
12:59:01 <faxathisia> > let on = join . liftM2 in ((==) `on` (`mod` 2)) 5 7
12:59:01 <lambdabot>  Couldn't match expected type `t1 -> t' against inferred type `Bool'
12:59:19 <olsner> :t join . liftM2
12:59:21 <lambdabot> forall a2 r (m :: * -> *). (Monad m) => (a2 -> a2 -> r) -> m a2 -> m r
12:59:26 <byorgey> resiak: dons is in Portland, OR now
13:00:16 <jsnx> mrd: that's not right
13:00:34 <mrd> no, it's probably not
13:00:43 <jsnx> it chooses [0, 0]
13:00:59 <byorgey> jsnx: there's no 'official' such module, but you could try something like http://www.polyomino.f2s.com/david/haskell/main.html
13:00:59 <lambdabot> Title: Haskell for Maths
13:01:31 <mrd> > [ (x, y) | x <- [1..10], y <- [1..10] `delete` x ]
13:01:32 <lambdabot>   add an instance declaration for (Num [[t]])
13:01:32 <lambdabot>     In the expression: 10
13:01:32 <lambdabot>     I...
13:01:57 <byorgey> > [ (x,y) | x <- [1..9], y <- [x+1..10] ]
13:01:59 <lambdabot>  [(1,2),(1,3),(1,4),(1,5),(1,6),(1,7),(1,8),(1,9),(1,10),(2,3),(2,4),(2,5),(2...
13:02:36 <jsnx> right now, i've got a recursive function to do it
13:02:45 <jsnx> i don't think there's a valid one liner
13:03:15 <Olathe> > filter (\(a, b) -> a /= b) $ replicateM 2 [1..10]
13:03:16 <lambdabot>  Couldn't match expected type `(t, t)' against inferred type `[t1]'
13:03:22 <byorgey> > let choose n [] = []; choose 0 _ = [[]]; choose n (x:xs) = map (x:) (choose (n-1) xs) ++ choose n xs in choose 2 [1..5]
13:03:23 <Olathe> > filter (\[a, b] -> a /= b) $ replicateM 2 [1..10]
13:03:23 <lambdabot>  [[1,2],[1,3],[1,4],[2,3],[2,4],[3,4]]
13:03:23 <lambdabot>  [[1,2],[1,3],[1,4],[1,5],[1,6],[1,7],[1,8],[1,9],[1,10],[2,1],[2,3],[2,4],[2...
13:03:28 <dons> resiak: nope.
13:03:36 <byorgey> > let choose n [] = []; choose 0 _ = [[]]; choose n (x:xs) = map (x:) (choose (n-1) xs) ++ choose n xs in choose 3 [1..6]
13:03:36 <lambdabot>  [[1,2,3],[1,2,4],[1,2,5],[1,3,4],[1,3,5],[1,4,5],[2,3,4],[2,3,5],[2,4,5],[3,...
13:04:04 <Olathe> > filter (\(a, b) -> a /= b) $ map (\[a, b] -> (a, b)) $ replicateM 2 [1..10]
13:04:04 <lambdabot>  [(1,2),(1,3),(1,4),(1,5),(1,6),(1,7),(1,8),(1,9),(1,10),(2,1),(2,3),(2,4),(2...
13:04:26 <resiak> dons: okay.  i just noticed that the date on your blog is a day ahead
13:05:00 <byorgey> Olathe: I think you probably want (\(a,b) -> a < b), assuming jsnx is asking about the 'choose' function in the combinatorial sense
13:05:17 <Olathe> Oh, I thought it was just nonequal tuples.
13:05:46 <jsnx> > let nums = [0..9] ; choose2 [] res = res ; choose2 (x:ys) res = choose2 ys (result ++ [ (x,y) | y <- ys ]) in choose2 nums
13:05:47 <lambdabot>   Not in scope: `result'
13:05:48 <faxathisia> > takeWhile (not.null) $ iterate $ drop 1 $ [1..10]
13:05:48 <lambdabot>  Couldn't match expected type `a -> a' against inferred type `[a1]'
13:05:54 <jsnx> > let nums = [0..9] ; choose2 [] res = res ; choose2 (x:ys) res = choose2 ys (res ++ [ (x,y) | y <- ys ]) in choose2 nums
13:05:55 <lambdabot>  <[(Integer,Integer)] -> [(Integer,Integer)]>
13:06:01 <faxathisia> > takeWhile (not.nil) $ iterate $ drop 1 $ [1..10]
13:06:01 <lambdabot>   Not in scope: `nil'
13:06:04 <jsnx> > let nums = [0..9] ; choose2 [] res = res ; choose2 (x:ys) res = choose2 ys (res ++ [ (x,y) | y <- ys ]) in choose2 nums []
13:06:04 <lambdabot>  [(0,1),(0,2),(0,3),(0,4),(0,5),(0,6),(0,7),(0,8),(0,9),(1,2),(1,3),(1,4),(1,...
13:06:07 <jsnx> aha
13:06:11 <faxathisia> > takeWhile (not.null) $ iterate (drop 1) $ [1..10]
13:06:11 <lambdabot>  [[1,2,3,4,5,6,7,8,9,10],[2,3,4,5,6,7,8,9,10],[3,4,5,6,7,8,9,10],[4,5,6,7,8,9...
13:06:27 <jsnx> see, that's what i'm using
13:06:42 <jsnx> it gets them in order, too
13:07:06 <faxathisia> > [(x,y) | x <- [0..10] , y <- [x..10]]
13:07:06 <lambdabot>  [(0,0),(0,1),(0,2),(0,3),(0,4),(0,5),(0,6),(0,7),(0,8),(0,9),(0,10),(1,1),(1...
13:07:22 <faxathisia> > [(x,y) | x <- [0..9] , y <- [(x+1)..9]]
13:07:23 <lambdabot>  [(0,1),(0,2),(0,3),(0,4),(0,5),(0,6),(0,7),(0,8),(0,9),(1,2),(1,3),(1,4),(1,...
13:07:28 <Olathe> > let f [] = []; f (x:xs) = (map (\a -> (x, a)) xs) ++ (f xs) in f [1..10]
13:07:28 <lambdabot>  [(1,2),(1,3),(1,4),(1,5),(1,6),(1,7),(1,8),(1,9),(1,10),(2,3),(2,4),(2,5),(2...
13:07:29 <byorgey> jsnx: did you see the version I typed above?  it also handles choosing more than 2 elements
13:07:46 <jsnx> byorgey: yes, but it's a lot more expensive...
13:07:54 <faxathisia> > [(x,y,z) | x <- [0..9] , y <- [(x+1)..9] , z <- [(y+1)..9]]
13:07:54 <lambdabot>  [(0,1,2),(0,1,3),(0,1,4),(0,1,5),(0,1,6),(0,1,7),(0,1,8),(0,1,9),(0,2,3),(0,...
13:08:03 <byorgey> jsnx: really?  you tried it?
13:08:19 <Olathe> > let f [] = []; f (x:xs) = (map (\a -> (x, a)) xs) ++ (f xs) in f "Hello !"
13:08:19 <lambdabot>  [('H','e'),('H','l'),('H','l'),('H','o'),('H',' '),('H','!'),('e','l'),('e',...
13:08:26 <jsnx> byorgey: no, but it's got more calls in it
13:08:38 <byorgey> jsnx: well, that doesn't necessarily mean it's more expensive.
13:08:57 <jsnx> byorgey: just a sec
13:10:10 <Olathe> @pl \n xs -> nub $ replicateM n xs
13:10:10 <lambdabot> (nub .) . replicateM
13:10:27 <Olathe> > let thingy = (nub .) . replicateM in thingy 5 [1..10]
13:10:33 <lambdabot>  [[1,1,1,1,1],[1,1,1,1,2],[1,1,1,1,3],[1,1,1,1,4],[1,1,1,1,5],[1,1,1,1,6],[1,...
13:10:45 <Olathe> Hmm, not quite.
13:11:23 <faxathisia> permute [] = return []
13:11:24 <faxathisia> permute (h:t) = do { t' <- permute t; member h t' }
13:11:38 <Olathe> member ?
13:11:41 <Olathe> @src member
13:11:41 <lambdabot> Source not found.
13:11:43 <faxathisia> member e [] = return [e]
13:11:43 <faxathisia> member e l@(h:t) = return (e:l) `mplus` do { t' <- member e t; return (h:t') }
13:12:06 <faxathisia> using LogicT
13:12:28 <vincenz> > member 1 []
13:12:34 <vincenz> > member 1 [2,3]
13:12:34 <lambdabot>   Not in scope: `member'
13:12:34 <lambdabot>   Not in scope: `member'
13:13:03 <Olathe> @let member e [] = return [e]; member e l@(h:t) = return (e:l) `mplus` do { t' <- member e t; return (h:t') }
13:13:04 <vincenz> member s a poor name
13:13:06 <lambdabot> Defined.
13:13:09 <Olathe> > member 1 []
13:13:09 <lambdabot>   add an instance declaration for (Show (m [t]))
13:13:13 <Olathe> No, you add one !
13:13:15 <faxathisia> you need LogicT
13:13:28 <vincenz> faxathisia: why is that a list inside a monad
13:13:35 <Olathe> @let permute [] = return []; permute (h:t) = do { t' <- permute t; member h t' }
13:13:40 <lambdabot> Defined.
13:13:41 <Olathe> > permute [1..5]
13:13:42 <faxathisia> It's logic programming
13:13:45 <lambdabot>   add an instance declaration for (Show (m [t]))
13:13:47 * Olathe sobs.
13:13:52 <faxathisia> Olathe: :p
13:13:52 <faxathisia> http://okmij.org/ftp/Computation/monads.html
13:13:52 <lambdabot> Title: Monads
13:14:06 <vincenz> > permute [1..5] :: [[Int]]
13:14:07 <lambdabot>  [[1,2,3,4,5],[2,1,3,4,5],[2,3,1,4,5],[2,3,4,1,5],[2,3,4,5,1],[1,3,2,4,5],[3,...
13:14:25 <Olathe> lambdabot couldn't have figured that out ?
13:14:30 <faxathisia> o_o
13:14:31 <vincenz> there is no default monad
13:14:40 <Olathe> @undefine
13:14:55 <lambdabot> thread killed
13:15:00 <vincenz> haha
13:15:02 <Olathe> @let permute [] = [[]]; permute (h:t) = do { t' <- permute t; member h t' }
13:15:02 <lambdabot> <local>:1:57: Not in scope: `member'
13:15:12 <bos> Olathe: elem
13:15:24 <vincenz> bos: no
13:15:30 <Olathe> Bah.
13:16:21 <bos> oh, nemmind. didn't read scrollback.
13:16:59 <byorgey> jsnx: it looks like your version is slower.  I think it's because you pass along the accumulated results as a parameter res, and then compute additional results with (res ++ *stuff*).
13:17:14 <Olathe> > takeWhile' (< 5) [1..10]
13:17:15 <lambdabot>  [1,2,3,4,5]
13:17:22 <byorgey> jsnx: ++ has to traverse its entire left argument before adding the right argument, so this will end up traversing the list of partial results many times
13:18:00 <byorgey> jsnx: just switching the order, to [*stuff*] ++ res, will probably give a big speedup.
13:18:29 <Taejo> what's the easiest way to install xmonad in ubuntu?
13:18:44 <jsnx> byorgey: yes, but it spits things out in the wrong order...
13:18:56 <jsnx> and reversing at the end doesn't fix it
13:18:59 <byorgey> jsnx: oh, good point.
13:19:04 <jsnx> since the sublists are in the correct order
13:20:00 <byorgey> jsnx: well, in that case my version is much faster.  although I realized what I typed above is not quite correct.
13:20:09 <byorgey> the order of the two base cases needs to be swapped.
13:20:45 <byorgey> > let choose 0 _ = [[]]; choose n [] = []; choose n (x:xs) = map (x:) (choose (n-1) xs) ++ choose n xs in choose 2 [1..10]
13:20:53 <lambdabot>  [[1,2],[1,3],[1,4],[1,5],[1,6],[1,7],[1,8],[1,9],[1,10],[2,3],[2,4],[2,5],[2...
13:23:11 <jsnx> byorgey: cool, i'm using it now
13:24:01 <jsnx> byorgey: does using tuples offer any advantage in memory usage?
13:24:22 <jsnx> if i use tuples, the type of the master choose is a little weird...
13:24:54 <byorgey> jsnx: I doubt it.
13:25:13 <jsnx> ok, well, that was instructive, to say the least
13:25:17 <jsnx> thanks
13:25:21 <byorgey> sure
13:26:57 <jsnx> byorgey: how did you do the timing?
13:27:15 <byorgey> Taejo: download the tarball, unpack it, and follow the instructions.  it's pretty easy.
13:27:23 <jsnx> unix time, or via something within ghci?
13:27:24 <byorgey> Taejo: ask in #xmonad if you have problems.
13:27:35 <Taejo> thanks byorgey
13:27:38 <byorgey> jsnx: I did it within ghci, by typing :set +s
13:28:09 <byorgey> jsnx: to do real benchmarking, you'd want to compile using -O2 but running some expressions within ghci is probably good enough to get a sense of relative timings.
13:28:53 <byorgey> Taejo: sure.  I'm running xmonad on ubuntu so I speak from experience. =)
13:29:11 * Beelsebob ponders a better solution to project euler 12
13:29:34 <olsner> what's the max size for hpaste?
13:29:49 <DukeDave> Hey gang, where / what is the 'lang' package for ghc..?
13:30:29 <byorgey> olsner: 5K, IIRC
13:30:37 <DukeDave> I'm on Ubuntu and I can't see a matching 'libghc6-..' in the universe repository :~
13:35:49 <byorgey> Beelsebob: do you know the formula for the nth triangular number?
13:36:09 <Beelsebob> byorgey: I was merely using scanl (+) 0 [1..] to produce them all
13:36:17 <Beelsebob> but the formula would be easy to figure
13:36:20 <Beelsebob> it's only a quadratic
13:36:23 <byorgey> yup
13:36:33 <Beelsebob> surely the scanl would be faster
13:37:04 <Beelsebob> on the other hand... something clever with the formula to figure the number of factors
13:37:09 <byorgey> well, once you have the formula, think about how you could find the factorization for the (n+1)st triangular number, given that you already know the factorization for the nth.
13:37:15 <Beelsebob> yep
13:37:18 <Beelsebob> fair enough
13:37:20 <scodil> what's the easiest way to get values out of a pointer to a C struct, from Haskell? I tried c2hs but it's choking on some file included by stdlib.h. Is there an easy way to do it using just the FFI?
13:37:25 * Beelsebob runs away and tries that
13:37:47 * Beelsebob had been thinking too much in terms of computing problem and not enough in terms of maths problem
13:38:24 <byorgey> Beelsebob: heh, yeah, it's usually good to start Project Euler problems by sitting somewhere with only a pencil and a piece of paper. =)
13:38:57 <olsner> ehrm, did I just buffer-overflow my xterm by pasting a 3.5k long line?  :S
13:39:03 <Beelsebob> byorgey: yeh, my approach so far was "try the nave approach, then do something clever" and so far navete had worked nicely
13:39:31 <byorgey> Beelsebob: that's certainly not a bad approach, but yeah, it only gets you so far.
13:39:44 <Beelsebob> indeed
13:40:48 <Beelsebob> in the mean time... while thinking about the clever version, the nave version appears to have finished
13:40:49 <Beelsebob> :P
13:40:53 <TSC> Beelsebob: I always do the naive approach first, because it's easy to be sure it's correct
13:41:03 <Beelsebob> TSC: exactly
13:41:05 <TSC> Then you have something to compare against for your faster, cleverer versions
13:41:24 <Beelsebob> hehe
13:41:43 <Beelsebob> so far I was mostly doing these to get something slightly more complex that I understood to test hat on
13:41:45 <TSC> Or the results you get from the simple version reveal some pattern in the answers that you can exploit
13:41:54 <Beelsebob> but I need to get onto some rather more complex computational ones in a bit
13:42:56 <byorgey> TSC: right, even if the naive version is too slow to give the ultimate answer, it's useful for "bootstrapping" =)
13:45:56 <olsner> http://paste.lisp.org/display/51533 <-- try this in ghci vs compiling with ghc --make
13:46:01 <olsner> what I get is ghci doing the lazy good thing and printing primes one at a time and ghc --make doing the bad thing trying to evaluate all primes before printing anything
13:46:33 <olsner> and yes, it's kind of a roundabout way to enumerate primes ;-)
13:46:46 <byorgey> olsner: you probably need to disable output buffering.
13:47:31 <olsner> oh, is that all? sounds way too easy!
13:47:41 <byorgey> main = do {hSetBuffering stdout NoBuffering ; etc... }
13:47:56 <TSC> Yeah, that's probably it
13:49:00 * shapr boings
13:49:10 <dons> ?users
13:49:10 <lambdabot> Maximum users seen in #haskell: 413, currently: 407 (98.5%), active: 12 (2.9%)
13:49:34 <olsner> yes! it works!
13:49:43 <bos> dons: you've ignited quite the firestorm
13:49:47 <byorgey> =D
13:50:29 <Beelsebob> some of these problems are surprisingly easy -- it's like they don't expect you to have a language with bignums support
13:51:01 <TSC> Yeah, and for a couple, abritrary-precision rationals
13:51:08 <olsner> they probably expect you to code in C, where every problem is hard
13:51:12 <Beelsebob> haven't found any of them yet
13:51:15 <BMeph> Beelsebob: Folks are funny that way with programming languages.
13:51:28 <Beelsebob> 90% of them so far are one liners
13:51:32 <goalieca> lol. dons @ your reddit "holy shmoly"
13:51:34 <dons> bos, i think we really should just step up for things like this. there's no reason for python and ruby web dev people to dominate programming discussions :)
13:51:42 <dons> represent, people!
13:52:03 <dons> also, using weapons from the future, like haskell, is a lot of fun
13:52:08 * faxathisia wants more interesting code than fibs..
13:52:09 <bos> dons: totally agree. i'd throw down if i wasn't working on the book :-)
13:52:14 <BMeph> I remember a review someone did of Lua, and he was freaking out because Lua doesn't have a special "integer" category of numbers.
13:52:32 <shapr> Haskell doesn't have variables, and that freaks out many people.
13:52:41 <bos> @smack shapr
13:52:41 <lambdabot> Unknown command, try @list
13:52:44 <goalieca> python vs ruby is a cripple fight.
13:52:46 <bos> @botsmack shapr
13:52:46 <lambdabot> :)
13:52:47 <faxathisia> How does haskell not have variablse?
13:52:48 <dons> bos, yeah, i'm building up a good set of things to cover in the concurrency chapter
13:52:50 <faxathisia> :|
13:53:18 <Stinger_> haskell has the unfortunate property that it breaks my brain
13:53:22 <bos> faxathisia: people have been conditioned to think that variables are things you can mutate.
13:53:24 <shapr> @quote variables
13:53:24 <lambdabot> cjs says: I have to explain this shit to people. I mean, I start out right, "Hey, you know how you always have these bugs because what you thought was in the variable is not there?" And I get all of
13:53:24 <lambdabot> these nods of agreement. "Well, I've found a new language that solves that problem." Audience: "Ooooh! How?" Me: "There's no variables!" And then they all start moving away from me slowly....
13:53:29 <faxathisia> bos: I haven't
13:53:44 <shapr> faxathisia: You have less to unlearn then :-)
13:53:58 <glguy> things that vary?
13:54:07 <bos> haskell has variables, they're just similar to the mathematical kind, not the programming kind.
13:54:31 <faxathisia> programming kind of variables should be renamed references or something
13:54:32 <vinse> [13:51] bos: faxathisia: people have been conditioned to think that variables are things you can mutate.
13:54:42 <Heffalump> they're not that similar to the mathematical kind either
13:54:51 <vinse> i think that comes from the definition of "vary"
13:54:52 <Heffalump> they don't really vary
13:55:04 <vinse> hence, tehy're kind of not variables
13:55:16 <vinse> unless you think it depends on what teh definition of "is" is
13:55:17 <olsner> we could call them impurities
13:57:38 <BMeph> olsner: Or "postulates." But then, we'd have a feud with the logic programmers... ;p
13:58:02 <dons> ?users
13:58:02 <lambdabot> Maximum users seen in #haskell: 413, currently: 408 (98.8%), active: 21 (5.1%)
14:01:35 <olsner> are postulates mutable?
14:02:05 <salierix> Interesting... Haskell actually beats Erlang in the thread-ring benchmark.
14:02:31 <BMeph> olsner: They are if you say they are... ;)
14:02:41 <dons> salierix: :)
14:03:58 <salierix> Still no ghc 6.8.1 though :(
14:06:14 <olsner> @ty (1:[2],3:[4])
14:06:18 <lambdabot> forall t t1. (Num t, Num t1) => ([t], [t1])
14:07:08 <olsner> > (\(1:_,2:_) -> True) ([1],[2])
14:07:17 <lambdabot>  True
14:08:18 <byorgey> @hoogle base
14:08:21 <lambdabot> Text.Html.base :: String -> HtmlAttr
14:08:21 <lambdabot> Test.HUnit.Base :: module
14:08:21 <lambdabot> Text.Html.basefont :: Html
14:16:32 * Beelsebob ponders, do the standard APIs have an AVL tree implementation anywhere in them?
14:17:56 <Cale> Beelsebob: no, but there's an AVL tree on Hackage, or somewhere at least, written by Adrian Hey
14:18:07 <Beelsebob> :) thanks Cale
14:18:07 <bos> @where collections
14:18:07 <lambdabot> I know nothing about collections.
14:18:10 <bos> hmph
14:18:21 <Cale> http://hackage.haskell.org/cgi-bin/hackage-scripts/package/collections-0.3
14:18:23 <lambdabot> http://tinyurl.com/yt7z4y
14:18:35 <bos> @where+ collections http://code.haskell.org/collections/collections-ghc6.8
14:18:35 <lambdabot> Okay.
14:21:14 <nominolo> dons: ruby doesn't optimize tail-calls.  and that fib thing isn't even a tail-call...
14:21:42 <nominolo> (so i wouldn't start an article with this :) )
14:21:57 <Cale> http://homepages.nildram.co.uk/~ahey/HLibs/Data.Tree.AVL/ -- appears to be some Hackage documentation. I'm not sure if it's the same version.
14:22:00 <sjanssen> dons: also, your fib program does not run in parallel
14:22:17 <sjanssen> dons: you need r `par` (l `pseq` l+r)
14:22:23 <sjanssen> pseq does no parallel computation
14:23:45 <nominolo> :t pseq
14:23:46 <lambdabot> Not in scope: `pseq'
14:24:28 <sjanssen> pseq is like seq, but somehow different (weird GHC magic that I don't understand is involved)
14:25:45 <dikini> dons: you made me start rewriting what I nearly finished :)
14:26:13 <Heffalump> sjanssen: how come it's faster, then?
14:26:37 <sjanssen> Heffalump: it's only very slightly different, 0.48 vs. 0.42
14:26:48 <dons> sjanssen: yeah, we were playing around with that internally. you're right.
14:26:58 <dons> it just sets up a better evaluation order as is
14:26:59 <sjanssen> that can be chalked up to any number of factors (load, cached executable, etc.)
14:27:12 <sjanssen> dons: you shouldn't call it parallel if it isn't
14:27:58 <hpaste>  jleedev pasted "Speed question (-O strangeness)" at http://hpaste.org/4133
14:28:28 <dons> yeah, i'm planning another post with a more useful example that will explore the strategies library
14:28:53 <dons> for best results in this test, glguy establish that a chunky parList was better, for forking the overall fib jobs
14:32:15 <Cale> jleedev: Uh, it got faster because you compiled with optimisations?
14:32:50 <jleedev> Cale: it goes slower.
14:33:10 <Cale> er, hmm
14:33:23 <Cale> ah
14:33:48 <Cale> I wonder what the core looks like
14:34:03 <jleedev> it also uses more memory
14:34:47 <hpaste>  Cale annotated "Speed question (-O strangeness)" with "core without optimisations" at http://hpaste.org/4133#a1
14:35:27 <hpaste>  Cale annotated "Speed question (-O strangeness)" with "core with optimisations" at http://hpaste.org/4133#a2
14:36:41 <monochrom> probably unimportant, but is it ghc-6.8.1?
14:36:48 <jleedev> 6.6
14:36:55 <Cale> 6.8.1 here
14:37:04 <Cale> (and yeah, I see that slowdown as well)
14:39:04 <sjanssen> dons: http://programming.reddit.com/info/61no8/comments/c02jw7i I achieve 1.8x speedup here, is parList version better than that?
14:39:51 <sjanssen> dons: oh, you're using parList to fork the individual jobs.  That's boring :P
14:41:22 <monochrom> Two pieces of evidence pointing towards the code memoizing and reusing f 10000000: more memory occupied, and the second print is very soon after the first.
14:42:31 <Cale> yeah, and profiling appears to show that the calls to f have become part of the CAF evaluation
14:42:52 <jleedev> what's CAF?
14:43:16 <Cale> Constant applicative form. These are the things which the compiler evaluates once and then stores.
14:43:33 <jleedev> are they often called thunks?
14:43:38 <Cale> no
14:43:50 <Cale> Thunks are values which have not yet been evaluated.
14:44:11 <jleedev> ookay
14:44:14 <vincenz> they should be futures!
14:44:15 <Cale> (and hence are represented by pointers to code along with possibly additional data)
14:44:20 <vincenz> futures subsume thunks
14:45:07 <dons> sjanssen: :)
14:45:26 <dons> its nice to see this stuff working so well
14:46:06 <Cale> jleedev: Somehow an optimisation is going wrong and storing the 10 million element list generated in the course of evaluating f.
14:46:35 <Cale> jleedev: I'd say that's a bug worthy of a trac ticket :)
14:47:24 <jleedev> Cale: ideally, it would only store the return value from f?
14:48:02 <Cale> It shouldn't really store anything, but I suppose if it was intended to do clever memoisation, yeah.
14:48:27 <Cale> (I don't think it really shouldn't memoise that at all)
14:49:00 <sjanssen> jleedev: I agree with Cale, file a bug report
14:49:15 * jleedev will so file, after dinner
14:49:36 <sjanssen> if GHC is smart enough to share [0 .. x :: Int], it should be smart enough to share length [0 .. x :: Int]
14:50:57 <Cale> Main.lvl :: [GHC.Base.Int]; Main.lvl = GHC.Enum.eftInt 0 10000000 -- if I'm not mistaken, that's where it's turned that list into a CAF.
14:51:50 <Cale> Then it has Main.lvl1 and Main.lvl2 which are separate CAFs for the two evaluations of length.
14:52:02 <Cale> yeah, that's really bad.
14:52:11 <mtp> hey guys
14:52:12 <DRMacIver> Sigh. The "Haskell memoizes everything!!" meme really makes me want to... I don't know. Glare sternly at people and force them to implement cobol compilers in brainfuck or something.
14:52:21 <byorgey> hi mtp
14:52:29 <mtp> I'm trying to build wsp, but it says Setup.lhs: cannot satisfy dependency text-any
14:52:33 <Cale> DRMacIver: Unfortunately, in this case it appears to be true in a horrible way.
14:52:43 <Cale> DRMacIver: (of course, that's a compiler bug)
14:53:08 <monochrom> Who says Haskell memoizes everything?
14:53:10 <dons> DRMacIver: yeah, that's a weird one. where do these memes come from?
14:53:38 <monochrom> We've just seen a GHC example of memoizing the wrong thing and not memoizing the right answer :)
14:54:02 <mtp> The only result on google for that was a log here, and it said there was a package "text" on hackage, which doesn't seem to exist today
14:54:28 <byorgey> mtp: there's a text package on hackage.  I just looked.
14:54:38 <DRMacIver> Cale: This case?
14:54:41 <byorgey> woops, never mind, that's a category =)
14:54:43 <Cale> dons: People assume that it would, without giving it too much thought, simply because it could.
14:54:49 <mtp> there's a text cat.. yeah.
14:55:00 <Cale> DRMacIver: http://hpaste.org/4133
14:55:00 <DRMacIver> dons: My theory is that it comes from people who don't know what they're talking about trying to justify why referential transparency is a good thing.
14:55:06 <dons> Cale, same as the magic parallelism meme
14:55:40 <DRMacIver> Cale: Ah. I wasn't actually talking about that - referring to the recent reddit nonsense. :)
14:55:41 <Cale> DRMacIver: GHC lifts things into CAFs in a bad way with -O turned on for this program.
14:55:58 <Cale> (as you can see by reading that core)
14:55:59 <DRMacIver> Ah. :-/
14:56:08 <vincenz> Any bikers (without engines) around?
14:56:25 <monochrom> I'm a walker (without engines).
14:56:35 <DRMacIver> vincenz: Intermittently, yes.
14:56:39 <monochrom> leg > wheel :)
14:56:42 <vincenz> I'm trying to decide what bike to buy
14:56:47 <vincenz> monochrom: leg -> wheel
14:56:53 <mtp> I wonder what happens if I remove the build-dependency :)
14:57:24 <monochrom> You will see which modules are wanted. Then we will know the modern day package.
14:57:41 <mtp> that works
14:57:57 <mtp> first it wants Network, which does exist on hackage and in debian.
15:01:36 <monochrom> Learned people will never understand the memes of unlearned people.
15:07:27 <dons> we've come a long way when random people say "I've never seen anyone claim that Haskell was slow or verbose or unproductive"
15:07:39 <Mitar> in a programming language theory - what is the difference between "function context" and "function environment" - is this a synonym?
15:08:09 <nominolo> Mitar: depends on the book
15:08:26 <thoughtpolice> dons: reddit?
15:09:51 <dons> yeah
15:10:51 <ddarius> dons: Link?
15:11:38 <dnox> that person must have been totally uninformed
15:12:54 <Eidolos> http://programming.reddit.com/info/61no8/comments/c02jv43
15:13:38 <ddarius> Are you rabble-rousing dons?
15:13:52 <Nafai> dons would never do that!
15:14:03 <Nafai> :)
15:14:50 <thoughtpolice> 150 comments in 3 hours must be 'rousing something. :)
15:15:25 <thoughtpolice> i think it had nearly ~30 when it was nearly just ~35 minutes old. :)
15:17:21 <dozer> evening
15:21:12 <esteban2> lambdabot
15:22:51 <olsner> @bot
15:22:51 <lambdabot> :)
15:24:17 <dons> ddarius: i get personally offended when ruby and python guys fight without us.
15:24:30 <dons> and get this weird urge to go in and bang heads together
15:24:48 <dons> i'm sure its a personality flaw
15:25:51 <ddarius> dons: You get offended when ruby and python bicker amongst themselves?
15:30:30 * dufflebunk watches the reddit flame war on haskell with amusement
15:30:42 <dons> ddarius: yeah, i like to charge in with a flame thrower.
15:31:08 <dons> its interesting watching the random reactions
15:31:10 <puusorsa> dufflebunk, url or it didnt happen
15:31:19 <dons> puusorsa: front page of reddit.com
15:31:43 <puusorsa> thanks
15:31:55 <dufflebunk> http://programming.reddit.com/info/61no8/comments/
15:32:11 <dons> what's the point of all our cool technology if we don't get to mop the floor with the competition?
15:32:40 <dons> and for a lot of things, python (and maybe ruby) are the competition
15:32:52 <vincenz> can't we all just get along?
15:33:03 <dibblego> no
15:33:09 <olsner> @pl (\(x:y:xs) -> f x y : xs)
15:33:09 <lambdabot> ap ((`ap` tail) . (. head) . ((:) .) . f . head) tail
15:33:09 <dnox> the competition? more like jumping into the pile of the other slow languages
15:33:12 <ddarius> dons: You have a question to answer: http://programming.reddit.com/info/61no8/comments/c02jwid
15:34:13 <Shimei> I like this counter argument to "Haskell syntax is funny": http://programming.reddit.com/info/61no8/comments/c02jwii
15:34:57 <dylan> 18:30 <@bz2> I really don't want to know what that's supposed to imply.
15:34:57 <dylan> 18:30 <@bz2> "Aftran's been summoned, you better have your pants on"?
15:34:57 <dylan> 18:31 <@Dylan> of course, I mean outerpants.
15:34:57 <dylan> 18:32 <@Dylan> see, outerpants are used in the summoning ceremony.
15:35:00 <dylan> aah
15:35:02 <dylan> ignore that
15:35:04 <Shimei> What is it with programmers assuming that if they can't do something, then it must not be their fault? :p
15:35:26 <puusorsa> well, haskell syntax IS funny
15:35:31 <Shimei> I would've thought all that debugging would eventually lead one to assume you're always wrong.
15:36:11 <dylan> haskell syntax is wonderful, especially if you've dealt with ML
15:36:40 <Shimei> puusorsa: It's funny, but I have had an easier time with it because all the operators are actually functions.
15:36:45 <vincenz> dylan: exactly :)
15:36:51 <vincenz> dylan: ; and ;; :)
15:36:55 <puusorsa> i'm not saying it's bad. just different
15:36:57 <vincenz> dylan: not to mention lists with ::
15:37:13 <Cale> Oh, great. All the documentation links in the highlighted Haskell code on haskell.org are broken.
15:37:24 <nominolo> @users
15:37:24 <lambdabot> Maximum users seen in #haskell: 413, currently: 400 (96.9%), active: 22 (5.5%)
15:37:43 <Shimei> puusorsa: I agree. It's just that lots of people equate different to bad, which is a boring stance to take...
15:37:57 <Cale> (because of the stupid version numbers on modules in the new documentation URLs)
15:38:05 <Cale> er, packages, rather
15:39:31 <dons> Cale, ah bug report to Igloo
15:39:37 <dons> it should symlink the old links to the new ones
15:39:42 <dons> at the very least
15:39:44 <Cale> dons: You missed some imports on the Haskell code for that fib program on your blog, btw. You need Control.Monad and Text.Printf of course.
15:39:55 <Igloo> It's already fixed
15:40:33 <Cale> It is?
15:40:39 <nominolo> Igloo: could we put the stuff from darcs.h.o/bin onto code.h.o ?
15:40:40 <Igloo> In darcs, yes
15:40:45 <ivanm> dons: out of curiosity... if you're working at Galois, why aren't you listed on the "people" page there? :p
15:40:54 <Igloo> nominolo: Which stuff?
15:41:03 <Cale> Igloo: Some symlinks on the server would be really nice in the meantime.
15:41:10 <Botje> ivanm: dons is an AI written by SPJ.
15:41:15 <nominolo> Igloo: the stuff to run post-hooks after darcs commits
15:41:15 <ivanm> heh
15:41:33 <nominolo> Igloo: http://darcs.haskell.org/bin/
15:41:34 <lambdabot> Title: Index of /bin
15:41:39 <ivanm> Botje: an AI who just happens to have studied at UNSW and had a blog and website there?
15:41:52 <nominolo> Igloo: needs some small path corrections
15:41:54 <Botje> ivanm: .. and a damn good microsoft(r) body.
15:42:13 <ivanm> Botje: so a Microsoft body that uses BSD ?
15:42:20 <Botje> of course.
15:42:28 <Igloo> nominolo: Aha, can you e-mail support [AT] community.haskell.org please?
15:42:34 <ivanm> hmmm.... has Balmer thrown chairs about that yet? :p
15:42:38 <nominolo> ok
15:43:05 <Botje> ivanm: it's all a clever scheme to hide the true maker.
15:43:11 <dons> ivanm, our web site is about to be updated to the 21st century :)
15:43:15 <monochrom> dons is unlisted because he is the skeleton in the closet of Galois. :)
15:43:29 <dons> which should include the other 2/3rds of the company also not listed on the old website
15:43:33 <ivanm> *nod* very clever... so clever no-one except you managed to uncover it?
15:43:36 <dons> and photos, bios, etc.
15:43:42 <monochrom> oooohhh, you have more skeletons
15:43:43 <ivanm> dons: heh... so is your blog going to remain at UNSW?
15:43:59 <dons> i'm actually thinking about moving it
15:44:10 <dons> darcs push to sydney can be tedious
15:44:19 <ivanm> heh
15:44:42 <Nafai> dons: You use darcs to manage your blog entries?
15:44:53 <dons> i do.
15:45:03 <nominolo> Igloo: ok i'll send concrete instructions tomorrow
15:45:17 <nominolo> s/instructions/requests/
15:46:19 <Nafai> Interesting
15:46:51 <conal> dons: fun read.  thanks much for stirring the pot.  i added 2cents.
15:47:19 <dons> :)
15:48:33 <ivanm> conal: 2 c ? that's all you could afford to contribute to dons' "I need a new blog host" fund? ;-)
15:48:55 <conal> ivanm: gimme a break -- i'm on a budget!
15:49:10 <conal> i could pledge 1 c per month for a year.
15:49:13 <ivanm> lol
15:49:19 <monochrom> 2 cents can probably buy you 2 megabytes of disk space already. not shabby at all.
15:50:14 <ivanm> *sigh* back to butchering java code
15:50:42 <monochrom> Be a nice butcher.
15:51:02 <monochrom> Do cut me some lamb chops at the end of the day.
15:51:06 <ivanm> might be more correct to say that its butchering me :p
15:51:18 * ivanm wants his HOFs!
15:51:27 * kyevan blinks
15:51:37 <kyevan> OK, I know types made sense before....
15:51:41 <kyevan> I hate it when this happense >_>
15:51:59 <monochrom> You need to be a resolution proof engine to understand types.
15:52:10 <Nafai> Hey byorgey
15:52:22 <byorgey> hey Nafai
15:53:07 <ddarius> Where does this "Haskell memoizes all function calls" craziness come from? (Actually, I know but even a second of critical thought would dispel it.)
15:53:36 <ddarius> monochrom: Luckily that's easy to be.
15:54:00 <monochrom> Learned people will never understand unlearned people.
15:54:10 <kyevan> ddarius: Probably misunderstanding some statement on them being true functions
15:54:39 <vincenz> ddarius: guess it's got to do with the thunking
15:54:57 <ddarius> kyevan: I'm pretty sure it comes from some aspect(s) of laziness, but if you think about it even for a second it's clear that that would be an staggering pessimization.
15:55:14 <ivanm> "pessimization" ... is that even a word?
15:55:21 <ddarius> @spell pessimization
15:55:33 <vincenz> degradation
15:55:34 <ddarius> ivanm: But, yes.
15:55:37 <ddarius> @wn pessimization
15:55:38 <lambdabot> No match for "pessimization".
15:55:43 <monochrom> The misunderstanding comes from an oversimplification.
15:56:42 <dons> ?users
15:56:42 <lambdabot> Maximum users seen in #haskell: 413, currently: 395 (95.6%), active: 24 (6.1%)
15:57:06 <monochrom> The same oversimplication as: "some Christians are fundamentalists" -> "Christians are fundamentalists" -> "all Christians are fundamentalists" -> "all Christians are against democracy"
15:57:09 <Shimei> ddarius: I assumed they concluded it from referential transparency. "If it's the same answer every time, they *must* memoize it!"
15:57:57 <vincenz> I think they just misunderstand the laziness -> thunking
15:58:26 <ddarius> Shimei: That would be concluding exactly the opposite of what referential transparency implies.  If it's the same every time then there is -no difference- between memoization and not.
15:59:01 <ivanm> Shimei: *gasp* you mean that it isn't true? :o
15:59:17 <ivanm> (note that I'm a Christian, not a fundamentalist, and support democracy(
15:59:52 <monochrom> I think it is more useful to investigate "why humans come in two genders" then "why people make mistakes".
15:59:59 <monochrom> s/then/than/
16:00:09 <kyevan> I haven't met any fndimentalist Christians
16:00:11 <Nafai> vincenz: What do you mean?
16:00:19 <kyevan> a few fundimentalist 'christians', but no Christians
16:00:39 <Zao> monochrom: To answer that question, I recommend that you read The Selfish Gene by Dawkins :)
16:00:48 <vincenz> laziness in haskell: values are thunked -> function is evaluated once then the value is stored -> memoization in a sense
16:01:21 <vincenz> but this is only for values that need to be stored anyways
16:01:30 <jonathanturner> hey everyone - I'm kinda new to Haskell so this may be a simple mistake
16:01:37 <Zao> jonathanturner: Welcome.
16:01:42 <sili> is there a favorite web server/library for making web apps with haskell?
16:01:52 <Zao> sili: happs?
16:01:57 <jonathanturner> I was playing around with the parallel-hinted fib, and when I compile I get this message
16:01:58 <monochrom> Precisely, Zao. Humans evolved to come in two genders. Humans evolved to have funny thoughts. They just happened. OK? A sequence of unfortunate events. No explanation.
16:02:25 <jonathanturner> Undefined symbols:___stginit_parallelzm1zi0zi0zi0_ControlziParallel_
16:02:36 <mauke> jonathanturner: try ghc --make
16:02:48 <sili> Zao: its web site has plenty of buzzwords. it must be good!
16:03:07 <jonathanturner> mauke: thanks that worked.
16:04:01 <jonathanturner> hmmm, not sure where dons got his numbers, but my run is definitely not 0.42s
16:04:19 <jonathanturner> it's more like 5.4s on a core 2 duo (in OS X)
16:04:46 <ddarius> monochrom: That was Darwin's original title for "The Origin of Species": "Charles Darwin's Series of Unfortunate Events"
16:04:54 <monochrom> haha
16:04:55 <mauke> jonathanturner: with -O2?
16:05:08 <jonathanturner> mauke: doing that now
16:05:33 <mauke> you might need to rm the .o file to force recompilation
16:06:12 <lament> people come in two genders for approximately the same reason that they make mistakes
16:06:40 <lament> so instead of investigating either question, it could be more useful to investigate both simultaneously, and their connection
16:06:41 <vincenz> ex?
16:07:42 <lament> (also, isn't Dawkins a tool? I haven't read the book but i heard negative things about it)
16:07:42 <vincenz> bleh, stupid lag
16:07:52 <vincenz> lament: how so?
16:07:58 <ddarius> lament: A tool of who?
16:08:14 <monochrom> A tool of God?  (hehehehe)
16:08:27 <vincenz> only Dawkins' God
16:08:53 <lament> ddarius: just a tool
16:09:16 <lament> as in, "he's such a tool"
16:09:19 <ddarius> lament: Nah.  A Philip's head screwdriver is much more useful than Richard Dawkin's.
16:09:21 <vincenz> lament: if you haven't read his books and only heard stuff from hearsay
16:09:24 <ddarius> -'
16:09:25 <jonathanturner> mauke: thanks for the help, that did the trick.  Funny, I get the reverse of his numbers, on mine parallel is slower.
16:09:26 <vincenz> lament: isn't a bit shortsighted to clal him a tool?
16:09:34 <lament> vincenz: that's why i'm phrasing it as a question
16:09:46 <vincenz> lament: what have you heard of him that makes you question this in the first place?
16:10:19 <monochrom> I have read a few of Dawkin's words. I am unable to refute them.
16:10:31 <ddarius> I heard that he was a Godless heathen, that's why -I- question him.
16:10:54 <vincenz> ddarius: for being an atheist?
16:10:55 <lament> vincenz: somehow i've formed this impression that his ideas are trivial pop-sci stuff.
16:11:00 <conal> I heard God is a Godless heathen.
16:11:16 <vincenz> lament: People who disagree with him typically will say such things to invalidate his ideas
16:11:35 <ddarius> vincenz is unable to read my tone through IRC
16:11:36 <Zao> Isn't there some kind of -blah channel for that kind of stuff?
16:11:39 <Plareplane> #math has a #not-math channel
16:11:44 <vincenz> ddarius: :)
16:11:46 <ddarius> @seen lambdabot
16:11:47 <lambdabot> Yes, I'm here. I'm in #friendly-coders, #scannedinavian, #gentoo-haskell, ##logic, #xmonad, #unicycling, #perl6, #parrot, #jtiger, #haskell-soc, #haskell-overflow, #haskell-blah, #scala, #haskell, #
16:11:47 <lambdabot> ghc and #darcs
16:11:56 <Plareplane> i'm not sure if there's a #not-haskell though
16:12:00 <vincenz> haskell-blah
16:12:50 <lament> vincenz: trivial, not invalid
16:13:08 <vincenz> lament: I think you should read "hindsight bias"
16:13:16 <ddarius> lament: Oh.  God doesn't exist is trivial.
16:13:38 <byorgey> jonathanturner: you compiled the parallel version with -threaded and ran it with +RTS -N2?
16:13:50 * ddarius purposely twists what lament says.
16:14:00 * lament purposely twists ddarius 
16:14:01 <tennin> but he writes pop-sci books.  isn't turning ideas into "trivial pop-sci stuff" the purpose of pop-sci books?
16:14:25 <goedel> hi! which is the highest level Turing-complete functional language (should be well documented)?
16:14:32 * monochrom writes pop-haskell books. monads are trivial.
16:14:39 <vincenz> http://www.overcomingbias.com/2007/08/hindsight-bias.html
16:14:39 <lambdabot> Title: Overcoming Bias: Hindsight bias
16:14:49 <benny> it's Richard Dawkins
16:14:49 <tennin> so if his ideas are now trivial pop-sci stuff then it sounds like he's been a success
16:14:55 <benny> there is no apostrophe in his name ;-)
16:14:55 <lament> The Selfish Monad
16:15:12 <monochrom> The Selfish Recursion.
16:15:27 <monochrom> Heh. MonadFix is the Selfish Monad. :)
16:15:40 <vincenz> I think the concept of selfish meme is quite nice
16:15:40 <byorgey> goedel: that depends on your point of view.  why do you ask? and what do you mean by "highest level"?
16:16:07 <lament> goedel: what should be well documented, the language, or which language is the highest level?
16:16:09 <jaj> goedel, I guess reading Principia Mathematica a long time ago has left its marks on your brain
16:16:32 <monochrom> hahahaha
16:16:57 <monochrom> What is the highest-level Goedel-incomplete language? :)
16:16:57 <jonathanturner> byorgey: still learning... thanks, that did the trick.  dons should mention how he compiles for newbies like me
16:17:04 <goedel> byorgey: I want to experiment with theorem provers. I need a well documented functional programming language which is very high level
16:17:24 <ddarius> goedel: Like most theorem provers are...
16:17:26 <monochrom> epigram is pretty high level. there are others.
16:17:44 <byorgey> jonathanturner: yeah, I think dons mentioned that he's planning a follow-up post...
16:17:53 <monochrom> however, both sml and haskell have been used in theorem provers successfully
16:18:02 <tennin> I'm going through the $80 Coq book.  It's good
16:18:05 <monochrom> oh, there's also lisp.
16:18:06 <lament> vincenz: i understand about hindsight bias, but weren't the ideas he expresses known for decades before his books?
16:18:20 <vincenz> lament: Aren't most things?
16:18:26 <vincenz> That's what the lispers have been saying since 1950
16:18:44 <monochrom> ???
16:18:56 <lament> vincenz: sure, which is why referring to dawkins as some sort of authority is as strange as saying Javascript invented closures.
16:18:57 <vincenz> "it's all been done before"
16:19:01 <monochrom> I mean ACL2 is in lisp. ACL2 is a very practical theorem prover.
16:19:04 <vincenz> lament: that was sarcasm
16:19:10 <monochrom> OK I see. :)
16:19:46 <lament> "C# introduces this amazing new technology known as ANONYMOUS FUNCTIONS!"
16:19:51 <goedel> monochrom: which dialect of lisp would you recommend?
16:19:57 <ddarius> Agda is a FP language, FP is a theorem prover as well.
16:20:09 <vincenz> lament: Ideas are more than their core, they're the implementation as well as the details
16:20:11 <ddarius> lament: Anonymous -delegates-.  Get it right.
16:20:16 <lament> hee
16:20:21 <vincenz> lament: dawkins has been doing valuable research and he's also brought it to the masses
16:20:27 <lament> okay
16:20:31 <lament> so he's not a complete tool :)
16:22:10 <lament> although anybody seriously arguing that the existence of god is "improbable" has a rather ...interesting understanding of probability theory
16:22:23 * ddarius has the desire to listen to "Dearly Beloved"
16:22:26 <Nafai> vincenz: Dawkin's field isn't religion or sociology but Biology, right?  I can't remember...
16:22:42 <dozer> Nafai: I'm not so sure he can by now, either
16:22:43 <vincenz> Nafai: I believe so, but I think he applies those ideas to sociology, I'm not an expert
16:22:44 <ddarius> Dawkins'
16:23:01 <TSC> Dawkins's
16:23:08 <ddarius> TSC: Also acceptable.
16:23:12 <TSC> Thanks (:
16:23:15 <benny> where is that acceptable?
16:23:22 <TSC> In English
16:23:31 <benny> I thought it has to be omitted if it ends on s
16:23:32 <Nafai> Thanks for the correction
16:23:44 <TSC> benny: That's usually for plurals
16:23:48 <ddarius> benny: Both are acceptable in (American) English.  (Or so I was taught.)
16:23:56 <benny> but without god, anything goes... right? :-P
16:24:09 <lament> let's murder and rape and program in Java!
16:24:10 <TSC> Yes, godless heretics can punctuate as they please
16:24:12 <ddarius> benny: That would explain religious peopl....
16:24:14 <dozer> on that note - I'm off
16:24:28 <benny> "If there is no God, everything is permissible."
16:24:42 <benny> the wicked one
16:25:06 <Japsu> I've always thought "Dawkins's" can only mean "Dawkins is", not "Dawkins' (his)"... tho I'm not a native speaker
16:25:15 <byorgey> http://www.bartleby.com/141/strunk.html
16:25:16 <lambdabot> Title: Rules of Usage. Strunk, William, Jr. 1918. Elements of Style
16:25:38 <byorgey> Dawkins's is correct, according to that.
16:25:57 <mtp> okay
16:26:11 <mtp> wants Text.Html
16:26:29 <noobie> guys i want to create a functio that checks a list for a incorrect data type| data Col = Bk | Bl | Cy | Mg   =  [Ck,Cy,Bk,Mg] sees "Ck" as an error
16:26:40 <goedel> thanks to all who replied to my questions! bye!
16:26:46 <byorgey> mtp: that's in the html package.
16:26:48 <mtp> ok
16:27:01 <jaj> whether there is a god or not is beyond our scope. we live in our virtual world which we call reality and we will never know what's beyond that, if there is something beyond that. That's why I'm an agnostic. I don't know if there is a god or not and I don't care.
16:27:08 <mtp> zygen: herro
16:27:26 <jaj> just my .2 euro cent
16:27:35 <byorgey> noobie: is this an assignment for class?
16:27:40 <ddarius> jaj: What do you mean by "virtual world" because if it's one meaning that means that "God" does exist.
16:27:44 <lament> jaj: sweet, that's a lot of money :)
16:27:44 <noobie> nope
16:27:58 <noobie> just wanted to
16:28:02 <byorgey> noobie: ok =)
16:28:29 <byorgey> noobie: well, [Ck, Cy, Bk, Mg] will just be a compile error, since Ck will be unrecognized.
16:28:41 <noobie> i get a Prelude  parse error i want to change that with my own err detector
16:28:43 <jaj> ddarius, well, we don't know if our world is real or not. perhaps it is, perhaps we live in an emulation. we will never know and it won't change anything.
16:28:45 <SamB> if we ever hear people complain about their accounts being reset, we can be pretty sure we are in some kind of elaborate MMORPG
16:28:54 <byorgey> noobie: are you reading this in from a string?
16:29:06 <noobie> nope
16:29:16 <noobie> type
16:29:19 <mtp> oookay
16:29:30 <mtp> Could not find module `Text.Html': it is a member of package html-1.0.1, which is hidden
16:29:50 <lament> jaj: you realize that the world "real" doesn't actually mean anything
16:29:57 <noobie> i used the reads function, but it seems the the parse err still displays
16:29:58 <SamB> lament: word
16:30:03 <SamB> it is a word, not a world
16:30:25 <SamB> lament: also, it does mean something
16:30:30 <jaj> lament, yeah, I guess you have to define 'real'
16:30:37 <byorgey> noobie: it shouldn't.  maybe you can paste the code you have so far? you haven't given us much to go on...
16:30:59 <ddarius> jaj: If we live in an emulation, God exists.
16:31:00 <byorgey> mtp: what do you get if you type ghc-pkg list at a prompt?
16:31:09 <SamB> unfortunately, apparantly there aren't any dictionaries of mathematics in dict.org's default dictionary list...
16:31:24 <mtp> Oh, I figured it out
16:31:25 <noobie> if i read it in as a strin, how could i trap the error?
16:31:29 <mtp> the cabal file is borked
16:31:33 <SamB> jaj: also, how is that different from being real
16:31:35 <dibblego> SamB, appar*e*ntly
16:31:44 <SamB> dibblego: !
16:31:46 <noobie> to say that it is not a member of the data tpe col
16:31:49 <byorgey> noobie: you would use reads.
16:31:53 <dibblego> SamB, ;)
16:32:03 <noobie> ok
16:32:11 <SamB> why do people keep bothering me about those words
16:32:29 <jaj> SamB, how is what different from being real?
16:32:38 <byorgey> SamB: because we're all a bunch of perfectionist freaks?
16:32:43 <ddarius> splng isn reaee neded
16:32:43 <SamB> jaj: an emulation
16:32:44 <mtp> noobie: You probably want a parser
16:32:52 <SamB> how do you know there is such a thing as a real world?
16:33:24 <ddarius> The "people" (gods) emulating us are themselves emulations.
16:33:29 <lament> I know there's a real world. I go there every night when I go to sleep.
16:33:53 <SamB> lament: hahahaha
16:34:11 <SamB> so, ddarius thinks it is turtles all the way down?
16:34:36 <ddarius> SamB: Actually I'm partial to porpoises.
16:34:40 <jaj> ddarius, yeah, when I write a computer program I'm sort of a god actually
16:34:42 <SamB> hah
16:34:59 <lament> ddarius: because they use rape for establishing the social hierarchy?
16:35:09 <SamB> jaj: wow, you must have a ginormous amount of RAM
16:35:22 <ddarius> lament: No, but that sounds like an effective system.
16:35:34 <davidL> @type bit
16:35:35 <lambdabot> forall a. (Bits a) => Int -> a
16:35:45 <ddarius> > bit 3 :: Int
16:35:46 <lambdabot>  8
16:35:51 <mtp> forall types scare me. :I
16:36:10 <ddarius> mtp: All (polymorphic) types are "forall types"
16:36:13 <davidL> > bit 32
16:36:13 <lambdabot>  Add a type signature
16:36:16 <LoganCapaldo> what if it was just (Bits a) => Int -> a
16:36:17 <davidL> > bit 32 :: Int
16:36:17 <lambdabot>  0
16:36:25 * dufflebunk ignores the forall parts of types
16:36:26 <LoganCapaldo> would that  make you feel better
16:36:28 <nornagon> > bit 32 :: Word64
16:36:28 <lambdabot>  4294967296
16:36:28 <mtp> the notation confuses me
16:36:45 <dibblego> mtp, you use the concept of "forall" all the time in your every day talk (aka universal quantification)
16:36:51 <mtp> dibblego: i know, i know
16:37:04 <jaj> SamB, actually I didn't want to say that I have god-like programming skills (which I don't have at all) but even a helloworld program has its own reality which the programmer designed
16:37:05 <mtp> i have taken a course in discrete math :P
16:37:05 <lament> for all i know, that's not at all how mtp uses it!
16:37:32 <dufflebunk> dibblego: what confuses is me is there's no existential type stuff...
16:37:46 <SamB> jaj: I meant, in order to simulate sentient beings, you must have a lot of RAM
16:37:50 <nornagon> it's not the size of the type, it's how you use it
16:38:00 <mauke> oh, there is
16:38:02 <lament> SamB: what does being a god have to do with creating sentient beings?
16:38:13 <ddarius> > let double :: (forall a.(a -> a) -> a -> a) -> (a -> a) -> a -> a; double n s z = n (s . s) z in double (\s -> s . s . s) (+1) 0
16:38:13 <lambdabot>  Parse error at ".(a" (column 24)
16:38:21 <ddarius> > let double :: (forall a. (a -> a) -> a -> a) -> (a -> a) -> a -> a; double n s z = n (s . s) z in double (\s -> s . s . s) (+1) 0
16:38:21 <lambdabot>  Parse error at "." (column 24)
16:38:30 <ddarius> Gah.  Stupid parser.
16:38:38 <SamB> lament: what kind of god doesn't create sentient beings?
16:38:42 <jaj> SamB, yeah and a lot of CPU power, too
16:38:48 <ddarius> SamB: A smart one.
16:39:00 <jonathanturner> SamB: Life simulates sentient beings if you look close enough
16:39:09 <lament> SamB: sentient beings evolve on their own, see Darwin. God just creates the laws of physics and some matter.
16:39:18 <SamB> A lame-ass god who is scared to try
16:39:31 <lament> SamB: sentient beings are not "special" in any way, despite what they like to think
16:39:31 <noobie> where can i find a parser?
16:39:45 <noobie>  > map reads (words "1 2 3 4")::[([Colors],String)]
16:40:02 <jonathanturner> lament: we're not special?  oh no!
16:40:05 <mtp> noobie: the Parsec library
16:40:10 <dufflebunk> lament: umm... perhaps the fact that other beings can't like to think anything makes the ones who can special?
16:40:43 <lament> dufflebunk: and non-flying creatures can't fly, so i guess the ones that can are special, but in that sense most things are special
16:40:45 <jaj> that picture: http://upload.wikimedia.org/wikipedia/en/a/a3/Escher%27s_Relativity.jpg is somewhat of a "sentient being"
16:40:45 <lambdabot> http://tinyurl.com/2kfu2x
16:40:47 <noobie> this not working map reads (words "1 2 3 4")::[([Colors],String)]
16:40:57 <jaj> for those of you who read GEB
16:41:31 <dufflebunk> lament: Yep, everybody is special ;)
16:41:37 <davidL> > rotate 3 1 :: Int
16:41:40 <lambdabot>  6
16:43:19 <nornagon> > 3 `shiftL` 1 :: Int
16:43:21 <lambdabot>  6
16:43:52 <ddarius> > rotate 3 (-1)
16:43:53 <lambdabot>  Add a type signature
16:43:57 <ddarius> > rotate 3 (-1) :: Int
16:43:57 <lambdabot>  -2147483647
16:44:35 <davidL> > minBound :: Int
16:44:35 <lambdabot>  -2147483648
16:44:43 <SyntaxNinja> @seen shapr
16:44:43 <lambdabot> shapr is in #ghc, #scannedinavian, #haskell-blah and #haskell. I last heard shapr speak 2h 50m 59s ago.
16:45:12 <ddarius> Hey SyntaxNinja
16:45:38 <davidL> > rotate 'a' 1 :: Char
16:45:39 <lambdabot>   add an instance declaration for (Bits Char)
16:45:39 <lambdabot>     In the expression: rotate '...
16:45:52 <mauke> > 0x80000001
16:45:53 <lambdabot>  2147483649
16:46:01 <mauke> > 0x80000001 :: Int
16:46:01 <lambdabot>  -2147483647
16:46:24 <davidL> :t 0x80000001
16:46:25 <lambdabot> forall t. (Num t) => t
16:47:04 <SyntaxNinja> hi ddarius
16:47:20 <dibblego> if I do not export a data constructor, can clients still use it for pattern matching (but not construction)?
16:47:41 <mauke> I don't think so
16:47:42 <nominolo> > scanl (*) [1..36]
16:47:43 <lambdabot>   add an instance declaration for (Num [t])
16:47:48 <nominolo> :t scanl
16:47:49 <lambdabot> forall a b. (a -> b -> a) -> a -> [b] -> [a]
16:47:53 <mauke> base case
16:48:05 <nominolo> > foldl1' (*) [1..36]
16:48:06 <lambdabot>  371993326789901217467999448150835200000000
16:48:41 <davidL> > 'a' :: CChar
16:48:42 <lambdabot>   Not in scope: type constructor or class `CChar'
16:49:42 <davidL> > 'a' :: Foreign.C.Types.CChar
16:49:42 <lambdabot>      Not in scope: type constructor or class `Foreign.C.Types.CChar'
16:51:33 <vincenz> davidL: 'a' is not polymorhic
16:52:50 <davidL> > castCharToCChar 'a'
16:52:50 <lambdabot>   Not in scope: `castCharToCChar'
16:53:41 <LoganCapaldo> > head "a" :: CChar -- could work
16:53:41 <lambdabot>   Not in scope: type constructor or class `CChar'
16:53:54 <LoganCapaldo> with the magic of IsString
16:55:55 <glen_quagmire> :i forM_
16:56:07 <glen_quagmire> @index forM_
16:56:07 <lambdabot> bzzt
16:56:14 <glen_quagmire> @index printf
16:56:14 <lambdabot> Text.Printf
16:56:21 <glen_quagmire> is bzzt module?
16:57:00 <glen_quagmire> @hoogle forM_
16:57:00 <lambdabot> No matches found
16:57:14 <jonathanturner> glen_quagmire: I think forM_ is in Control.Monad -- I had to look that up a few minutes ago
16:57:50 <glen_quagmire> http://cgi.cse.unsw.edu.au/~dons/blog/2007/11/29#smoking this is what i'm trying to compile
16:57:51 <lambdabot> Title: Haskell hacking
16:58:05 <dons> import Control.Monad; import Text.Printf
16:58:21 <dons> i can't remember if we put forM in with 6.6 or 6.8
16:58:27 <dons> ?src forM_
16:58:27 <lambdabot> forM_ = flip mapM_
16:58:35 <TSC> forM was in 6.6
16:58:47 <dons> how time flies.
16:58:54 <dons> like a catamorphism
16:59:10 <byorgey> I thought it was like an Arrow?
16:59:33 <monochrom> @remember dons how time flies. like a catamorphism
16:59:33 <lambdabot> Done.
16:59:51 <ddarius> Bananas don't fly very far.
17:00:01 <vincenz> time flies like an arrow, fruit flies like a banana
17:00:26 <vincenz> though it should be
17:00:29 <vincenz> fruit-flies like a banana
17:00:56 <Olathe> Lies.
17:01:14 <byorgey> Olathe: you forgot an 'F'.
17:01:25 <Olathe> :(
17:01:26 <bos> ddarius: you have to skim them less than a bananaspan from the ground, then the ground effect generates additional lift.
17:01:28 <conal> Lifes?
17:01:35 <Olathe> Lies. You get an F.
17:01:48 <byorgey> that's better.
17:03:11 * byorgey wanders off to request transcripts
17:03:38 * ddarius needs to go play soccer.
17:06:24 <LoganCapaldo> dons: can you get rid of the "proper tail comment" in yer blog? It doesn't, and even it it did the fib used there isn't tail recursive anyway
17:06:52 <davidL> > let f x = map (\y -> if testBit (x::Int) y then '1' else '0') [0..7] in f 32
17:06:52 <lambdabot>  "00000100"
17:07:06 <Olathe> Ow !
17:07:31 <dons> LoganCapaldo: oh, i noted that, but was just reflecting antonio's blog remark.
17:08:10 <dons> LoganCapaldo: are you saying there is no proper tail call  in ruby still, and that the speedup on Antonio's stuff is something else entirely?
17:08:25 <cdsmithus> Hi everyone.  Sorry for ceasing to exist for three months.
17:08:43 <davidL> cdsmithus: did you ever write a wrapper for libpng?
17:08:51 <mtp> hmm
17:08:52 <dons> hey cdsmithus
17:08:55 <cdsmithus> Uh no; I found haskell-gd, which was good enogh
17:08:58 <mtp> i'm using HWS+WASH
17:09:09 <mtp> and I can't seem to deploy HelloWorld
17:09:18 <davidL> cdsmithus: odd, I started writing a wrapper until I found gd myself
17:09:24 <LoganCapaldo> dons: yes
17:09:31 <dons> ok. thanks.
17:09:37 <LoganCapaldo> + finally isn't going thru method dispatch
17:09:42 <dons> ah!
17:09:42 <mtp> servlet died: Ix{Int}.index: Index (3145728) out of range ((0,19))
17:09:42 <dmwit> mtp: What's wrong?
17:09:49 <mtp> gives me that
17:10:06 <cdsmithus> I'm fiddling, and ran into a tough type problem, if anyone's interested.
17:10:18 <mauke> @quote oleg
17:10:18 <lambdabot> audreyt says: assembly would require metaolegs (or megaolegs)
17:10:38 <dons> thanks LoganCapaldo
17:10:38 <Botje> I'd like mega-legs.
17:11:03 <Shimei> Oh whoa. That "explaining algebraic theory with FP" paper posted on proggit is really neat.
17:11:05 <hpaste>  cdsmithus pasted "what is a better type for diff?" at http://hpaste.org/4134
17:11:17 <cdsmithus> That's basically it.
17:11:56 <mtp> dmwit: i can wash2hs HelloWorld, ghci it, and "run mainCGI", though
17:12:29 <dmwit> mtp: To check that things are what you expect, try using "HOME= ghci" instead of vanilla ghci.
17:12:48 <monochrom> cdsmithus: I'm wondering why it is not simply Num a => (a->a) -> a->a
17:13:04 <dmwit> WASH inspects $HOME and behaves differently if $HOME is non-empty than if it is empty.
17:13:10 <cdsmithus> Because it doesn't compile?  Let me check again to be sure...
17:13:34 <cdsmithus>     Occurs check: cannot construct the infinite type: a = AD a
17:13:34 <cdsmithus>     When generalising the type(s) for `diff'
17:13:36 <mtp> well, i'm running hwswash as the same user (it's a test setup)
17:13:56 <mtp> and I can also ghci with an empty $HOME
17:15:58 <dmwit> mtp: Sorry, I don't know much about HWS.  Does the Hello World program use WASH's persistence module or cookie module?
17:16:06 <mtp> no
17:16:09 <cdsmithus> Okay, so inference gives Num a => (AD a -> AD t) -> a -> t.  But that's messy, because AD isn't supposed to be exposed outside this module.
17:16:30 <dmwit> Okay.  I don't know what the problem is, sorry.
17:16:33 <monochrom> However, not all Num instances are AD's either.
17:17:00 <mtp> helloworld is two imports and mainCGI = standardQuery "Hello World" empty
17:17:02 <byorgey> cdsmithus: the type itself is not supposed to be exposed?  or just the type constructor?
17:17:23 <monochrom> OK, I see the intention for the 2nd-rank Num. It is to hide AD. Let me re-think.
17:17:25 <cdsmithus> The type itself isn't supposed to be exposed; but maybe that's unrealistic
17:17:42 <dmwit> mtp: Can you get HWS to serve up any static pages?
17:17:46 <mtp> yeah
17:17:55 <dmwit> hm
17:17:55 <mtp> it serves files out of my docroot just fine
17:19:32 <cdsmithus> byorgey, monochrom: so clearly I could write a bunch of functions like diffNum, diffFloating, diffFractional, etc; it just seems like something to avoid.
17:19:57 <mtp> dmwit: this is a hacked version of HWS made by the WASH guy
17:20:28 <mtp> and, lemme see if it's just HelloWorld complaining and a more-complicated script will work. :P
17:20:37 <dmwit> mtp: Are you just starting out?  I might recommend not using WASH. =P
17:21:05 <mtp> well, i'm doing a project comparing different webservers
17:21:07 <dmwit> I am using WASH for my own project, and there's a lot of downsides they don't tell you about.
17:21:08 <mtp> and languages
17:21:21 <dmwit> ah
17:21:47 <mlh> what's a better alternative to WAS?
17:21:49 <mlh> WASH
17:21:54 <dmwit> Well, happs is getting a lot of buzz, so I guess you're looking at both?
17:22:13 <dmwit> I can't say for sure, though, because I have only used WASH so far.
17:22:15 <mtp> i'm sort of looking for something like Ruby's webrick, common lisp's hunchentoot, or erlang's yaws
17:22:47 <mtp> with webrick and hunchentoot you mount servlets, and yaws parses files for <erl> tags.
17:23:06 <dmwit> Yeah, happs is its own web server, database, email server...
17:23:23 <StaZ|home> wow! an haskell channel, excelllllent
17:23:25 <monochrom> cdsmithus: Do you need diffFloating? Is it different from diffNum?
17:23:36 <bos> mtp: happs would be the closest to what you want, but it's fearsomely complicated and underdocumented
17:23:39 <dmwit> Hiya StaZ|home!
17:23:40 <mtp> yeah
17:23:41 <mtp> I looked at it
17:24:01 <byorgey> welcome, StaZ|home =)
17:24:14 <StaZ|home> thank you :)
17:24:15 <cdsmithus> monochrom: from a type standpoint, yes; the code would be identical.  But it could be used on functions of type forall a. Floating a => a -> a
17:25:19 <mtp> my 3 test cases are using the built-in static file service module to serve 4 files, using a servlet to read the same files and print them back, and the ackermann function.
17:25:36 <mtp> I suppose I could use WASH and CGI, but that'd incur an exec() overhead
17:27:11 <bos> mtp: you're comparing performance? or what?
17:27:20 <mtp> bos: yeah
17:27:48 <mtp> it's not exactly an awesome project, but it works
17:27:58 <bos> mtp: for school?
17:28:02 <mtp> yeah
17:28:32 <bos> mtp: there's a fastcgi module too, you could try that
17:28:33 <monochrom> cdsmithus: Will you ever differentiate a function that can be Num a => a->a but not Floating a => a->a? (I mean, for example, (\x -> x+1) can be made Floating a => a->a if you want...)
17:28:42 <StaZ|home> hey guys, i'm a noob and i'm not sure how to find my answer, it's a syntax question mainly : this is an example of an intersection of list but it's a syntax question ..   myfunc :: [a] -> [a] -> [a]      myfunc l1 l2 = filter (elem l2) l1      <- so this returns all elements of l1 that is inside l2
17:28:43 <hpaste>  cdsmithus annotated "what is a better type for diff?" with "works, but not ideal" at http://hpaste.org/4134#a1
17:29:09 <bos> mtp: also http://okmij.org/ftp/Haskell/#NewerCGI
17:29:09 <lambdabot> Title: Haskell Programming: Miscellanea
17:29:19 <vincenz> StaZ|home: and?
17:29:31 <StaZ|home> as you might have guessed, this doesn't work caus the elem function is  a -> [a] -> bool    so how can i "revert" this... to have an elem function that is [a] -> a -> bool
17:29:32 <vincenz> @type elem
17:29:33 <lambdabot> forall a. (Eq a) => a -> [a] -> Bool
17:29:34 <dmwit> StaZ|home: myfunc l1 l2 = filter (`elem` l2) l1 is more correct
17:29:35 <mtp> bos: well, i'm trying to stick to pure-$LANGUAGE implementations
17:29:37 <vincenz> StaZ|home: two ways
17:29:41 <vincenz> (flip elem l2)
17:29:41 <vincenz> or
17:29:44 <vincenz> (`elem` l2)
17:29:55 <cdsmithus> monochrom: if that's done, then all functions become Floating when differentiated; i.e., you can't calculate derivatives on Rational
17:30:00 <StaZ|home> ah great, i like the flip one, thank you very much
17:30:01 <vincenz> (`elem` l2) uses the infix notation and then binds the second argument
17:30:03 <dmwit> For more scalability, you can also use
17:30:03 <vincenz> it's like (+ 3)
17:30:06 <dmwit> (\x -> elem x l2)
17:30:15 <vincenz> dmwit: how is that more scalable
17:30:25 <StaZ|home> dmwit i thought of that but it's barely readable imho
17:30:29 <dmwit> Scalable to more arguments, I mean.
17:30:32 <monochrom> derivatives over Rational is rare IMO.
17:30:45 <dmwit> (\x -> elem a b c x d e f) -- hard to write point-free
17:31:01 <mauke> @pl (\x -> elem a b c x d e f)
17:31:01 <lambdabot> flip (flip (flip (elem a b c) d) e) f
17:31:03 <SamB> monochrom: why would it be rare?
17:31:07 <Olathe> That was pointless.
17:31:17 <mtp> Olathe: no, it was point-free. :)
17:31:20 <SamB> because most functions people deal with are over the reals?
17:31:21 <dmwit> ?users
17:31:21 <lambdabot> Maximum users seen in #haskell: 413, currently: 396 (95.9%), active: 26 (6.6%)
17:31:48 <Olathe> @help pl
17:31:49 <lambdabot> pointless <expr>. Play with pointfree code.
17:32:08 <Olathe> Ahh, I think I see better.
17:32:19 <Olathe> The original expression is pointless.
17:32:25 <Olathe> The output is pointfree.
17:32:32 <monochrom> One definition of derivatives uses limits. Such a definition is useless on an incomplete metric space.
17:32:59 <SamB> Olathe: eh?
17:33:02 <SamB> it's a JOKE
17:33:16 <mtp> @pl a n = 6*a (n-1) + 8*a (n-2)
17:33:16 <lambdabot> a = fix (ap (ap . (((+) . (6 *)) .) . (. subtract 1)) (((8 *) .) . (. subtract 2)))
17:33:27 <SamB> pointfree means "doesn't bind variables"
17:33:29 <mtp> awesome. 8D
17:33:52 <dmwit> mtp: ?pl has S, K, and I... it can do anything. =)
17:33:53 <SamB> pointless is a joking way to say pointfree
17:34:04 <mauke> @pl s f g = \x -> f x (g x)
17:34:04 <lambdabot> s = ap
17:34:16 <mtp> does it have y?
17:34:22 <mtp> @pl y f = f (y f)
17:34:22 <lambdabot> y = fix (ap id)
17:34:26 <dmwit> :t fix
17:34:26 <lambdabot> forall a. (a -> a) -> a
17:34:31 <conal> s = (<*>)
17:35:12 <dmwit> ?src fix
17:35:12 <lambdabot> fix f = let x = f x in x
17:35:17 <mauke> :t fix (ap id)
17:35:17 <lambdabot> forall b. (b -> b) -> b
17:35:28 <dmwit> huh
17:35:45 <dmwit> Oh, fix (ap id) = fix
17:35:51 <dmwit> interesting
17:36:14 <monochrom> cdsmithus: To conclude, I don't know a way to unify them, except maybe rewrite AD, and I don't know how.
17:38:30 <cdsmithus> monochrom: Hmm.  I was hoping for some kind of extension that does something like "forall A a. (instance A x => A (AD x)), A a => (forall b. A b => b -> b) -> a -> a
17:38:50 <cdsmithus> But that's a little over the top
17:39:54 * conal wishes again for Lambda-Prolog in haskell's type system.
17:40:01 <noobie> > reads$ show$ words "1 2 3 4" :: [([Int],String)]
17:40:03 <lambdabot>  []
17:40:21 <noobie> > reads$ show$  "1 2 3 4" :: [([Int],String)]
17:40:21 <lambdabot>  []
17:40:30 <noobie> > reads$  "1 2 3 4" :: [([Int],String)]
17:40:30 <lambdabot>  []
17:40:47 <monochrom> It has to be [1,2,3,4].
17:41:02 <dmwit> > map reads . words $ "1 2 3 4"
17:41:02 <lambdabot>  [[(1,"")],[(2,"")],[(3,"")],[(4,"")]]
17:41:15 <dmwit> > map read . words $ "1 2 3 4"
17:41:15 <lambdabot>  [1,2,3,4]
17:41:29 <dmwit> > read "[1,2,3,4]"
17:41:30 <lambdabot>  Exception: Prelude.read: no parse
17:41:36 <noobie> map read . words $ "1 2 3 4"
17:41:38 <dmwit> uh
17:41:44 <noobie> > map read . words $ "1 2 3 4"
17:41:44 <lambdabot>  [1,2,3,4]
17:41:47 <dmwit> > read "[1,2,3,4]" :: [Int]
17:41:47 <lambdabot>  [1,2,3,4]
17:41:55 <noobie> nice
17:42:08 <monochrom> Another thing you may like to know is that you can use lambdabot inside /msg, you don't have to use this or other channels.
17:48:19 <noobie> > map  reads$ show$ words "1 2 3 4" :: [([Int],String)]
17:48:19 <lambdabot>  Couldn't match expected type `String' against inferred type `Char'
17:48:50 <noobie> > map  reads$  words "1 2 3 4" :: [([Int],String)]
17:48:51 <lambdabot>  Couldn't match expected type `([Int], String)'
17:49:24 <noobie> > map  reads ( words "1 2 3 4") :: [([Int],String)]
17:49:24 <lambdabot>  Couldn't match expected type `([Int], String)'
17:52:21 <mtp> ok, i think I might actually have happs working for me.
17:52:34 <Brian`> @hoogle a -> [a] -> a
17:52:41 <lambdabot> Prelude.foldl :: (a -> b -> a) -> a -> [b] -> a
17:52:41 <lambdabot> Prelude.foldr :: (a -> b -> b) -> b -> [a] -> b
17:52:41 <lambdabot> Data.List.foldl' :: (a -> b -> a) -> a -> [b] -> a
17:53:12 <Brian`> is there a function that returns the index of an element if it exists in the list?
17:54:04 <EvilTerran> ?hoogle index
17:54:04 <lambdabot> Ix.index :: Ix a => (a, a) -> a -> Int
17:54:04 <lambdabot> Data.PackedString.indexPS :: PackedString -> Int -> Char
17:54:04 <lambdabot> Data.Generics.Basics.indexConstr :: DataType -> ConIndex -> Constr
17:54:12 <EvilTerran> ?hoogle+
17:54:12 <lambdabot> Control.Exception.IndexOutOfBounds :: String -> ArrayException
17:54:12 <lambdabot> List.elemIndex :: Eq => a -> [a] -> Maybe Int
17:54:12 <lambdabot> List.findIndex :: (a -> Bool) -> [a] -> Maybe Int
17:54:31 <EvilTerran> > 'c' `elemIndex` "abracadabra"
17:54:33 <lambdabot>  Just 4
17:54:39 <EvilTerran> > 'q' `elemIndex` "abracadabra"
17:54:39 <lambdabot>  Nothing
17:54:52 <EvilTerran> ?index elemIndex
17:54:53 <lambdabot> Data.List
17:55:45 <Brian`> cool :)
17:55:46 <Brian`> thank you
17:56:26 <Cale> A cabalistic word, formerly used as a charm, and believed to have the power, when written in a triangular arrangement, and worn round the neck, to cure agues, etc. Now often used in the general sense of a spell, or pretended conjuring word; a meaningless word of mysterious sound; jargon, gibberish.
17:57:37 <cdsmithus> After more thought, I think what I want is a type like: forall A a. (A <: Floating, A a) => (forall b. A b => b -> b) -> a -> a.  Here, <: means "is a superclass of", and quantification over capital letters denotes type classes.  And I think a type system extension like this would be safe, though I haven't fully thought it through.
17:58:31 <cdsmithus> Has anyone heard of anything like that?
17:58:50 <monochrom> bounded polymorphism is involved
17:59:24 <Cale> Shouldn't that be :> ?
17:59:34 <cdsmithus> Sure, change the notation as you like
18:00:08 <Cale> hmm
18:00:43 <Cale> I'm not sure I completely understand yet what that buys you here...
18:01:29 <cdsmithus> It lets me write one function, instead of the several in the annotation at the bottom of http://hpaste.org/4134.  I don't like writing multiple functions with identical implementations.
18:02:15 <monochrom> A function "diff" is proposed. It should do this: if f :: forall a. Num a => a->a, then diff f :: forall a.  Num a => a->a. If f :: forall a. Floating a => a->a, then diff f :: forall a. Floating a => a->a.  What is the type of diff?
18:03:44 <Cale> That is interesting.
18:03:46 <cdsmithus> To add to monochrom: but if f has some other arbitrary type, then diff f is an error and can't be written.
18:04:34 <monochrom> Yeah, diff uses the number 1 somewhere, so there are bounds on the type classes allowed.
18:05:56 <SamB> ... I'm pretty sure there is a good reason why you can't already do that
18:05:57 <Cale> Ask SPJ about it maybe. ;)
18:06:09 <Cale> Or Oleg.
18:06:28 <Cale> Oleg will probably find some way to embed it in Haskell 98 or something.
18:06:35 <SamB> Oleg would be the one to answer that type of question ;-)
18:06:56 <Botje> @quote SPJ
18:06:56 <lambdabot> shapr says: [on Oleg:]  And ccshan and he would argue furiously for a minute or two and then SPJ would say "Why don't you send an email to the Haskell list about that so we can have time to understand
18:06:56 <lambdabot>  what you just said?"
18:07:22 <Botje> ah. that's the one.
18:07:25 <Botje> I can sleep now :)
18:08:31 <cdsmithus> So I should write to haskell-cafe?
18:08:42 <Cale> yeah
18:10:14 <Cale> I'm not sure there is a satisfactory answer in contemporary Haskell. I don't really know how much the combination of higher rank types with typeclass polymorphism has been explored.
18:12:55 <monochrom> Create class Diffable a where { one :: a }. diff :: Diffable b => (forall a. Diffable a => a->a) -> b->b. In diff's code, replace 1 by one. instance Num a => Diffable a where one = (exercise for the reader). Similarly for Fractional, Floating. Turn on undecidable overlapping incoherent magic. Pray.
18:14:16 <monochrom> (I haven't tested it.)
18:14:19 <byorgey> @remember monochrom Turn on undecidable overlapping incoherent magic. Pray.
18:14:19 <lambdabot> I will never forget.
18:15:00 <monochrom> Evidently, I forgot flexible.
18:15:17 <EvilTerran> Ph'nglui mglw'nafh Cthulhu R'lyeh wgah'nagl fhtagn!
18:15:34 <EvilTerran> (incoherent magic)
18:18:28 <LoganCapaldo> {-# LANGUAGE Lovecraftian #-}
18:19:52 <LoganCapaldo> -fnoneuclidian-geometry
18:20:02 <LoganCapaldo> this is too much fun
18:21:11 <monochrom> -fquantum-computing
18:23:39 <cdsmithus> Cale: Thanks (sorry for the delay; my phone rang)
18:24:32 <cdsmithus> monochrom: That's an interesting idea with Diffable.  I will look at it, though incoherent instances are scary. :)
18:30:08 <faxathisia> :|
18:30:17 <faxathisia> Has anyone written a minesweeper solver in haskell?
18:30:26 <faxathisia> (I'd like to compare its speed with mine)
18:30:31 <TSC> I've always wanted to do that
18:30:53 <faxathisia> TSC :D
18:30:59 <TSC> Do you start out with some squares revealed, so that you don't have to guess?
18:31:01 <faxathisia> if you do it we can race them :p
18:31:13 <mtp> okay
18:31:29 <jfredett> noneuclidean geometry? Where!
18:31:30 <faxathisia> I mean things like this http://rafb.net/p/cBmeAT28.txt
18:31:37 <mtp> so with HAppS, is there a trivial way of using GET variables
18:31:46 <mtp> ie, http://url/foo?m=1
18:31:46 <lambdabot> Title: url
18:31:47 <faxathisia> [#] are known bombs, (?) are unknowns (you fill those in)
18:31:55 <jfredett> Hyperbolic Geometry == teh kickass. :)
18:31:57 <TSC> Right
18:32:20 <TSC> faxathisia: Are there more sample problems?
18:32:27 <faxathisia> I don't have any more
18:32:40 <faxathisia> here's one more http://syndicate.yoogi.com/logic-minesweeper/
18:32:40 <lambdabot> Title: Logic MineSweeper / Coin Collect Puzzle : Yoogi Puzzle Syndicate (Puzzles for ne ...
18:32:52 <faxathisia> anyway test4 is taking ages :[
18:33:12 <faxathisia> I'm really curious as to whether my code is fast or slow
18:34:50 <TSC> Let me try to solve it...
18:35:30 <hpaste>  faxathisia pasted "Cells.hs" at http://hpaste.org/4135
18:35:46 <hpaste>  faxathisia annotated "Cells.hs" with "minesweeperGrid" at http://hpaste.org/4135#a1
18:35:52 <faxathisia> if you like, there's that
18:36:00 <Nafai> Wow.
18:36:11 <Nafai> I just defended Haskell as being as readable as Python on reddit
18:36:59 <hpaste>  faxathisia annotated "Cells.hs" with "(aux)" at http://hpaste.org/4135#a2
18:37:33 <TSC> faxathisia: How long does your program take for test4?
18:37:41 <faxathisia> >:|
18:37:44 <faxathisia> I just got, *** Exception: stack overflow
18:38:00 <faxathisia> 3.3 seconds for test3
18:38:17 <faxathisia> I can't solve test4 at this point then
18:38:26 <mtp> Nafai: haskell is infinitely more readable than python
18:38:39 <monochrom> everything is readable.
18:39:02 <cjay> haskell is still easier to obfuscate than python :)
18:39:15 <Nafai> Well, considering Haskell is taking me a bit longer to pick up than Python did...
18:39:26 <Nafai> But I do think it is readable and elegant now that I understand it
18:39:31 <mtp> the readability of a language has little to do with how easy it is to pick up
18:39:40 <mgsloan> well, you probably knew a procedural language before picking up python
18:39:42 <mtp> PHP is easy for all manner of dipshits to pick up on
18:40:00 <mgsloan> lol
18:40:20 <mtp> and it's pretty unreadable :P
18:40:25 <monochrom> readability has nothing to do with the language
18:40:40 <mtp> exactly
18:40:48 <faxathisia> not exactly nothing..
18:40:56 <faxathisia> It's quite irrelevant though, I do agree
18:43:36 <mgsloan> well, brainfuck and befunge aren't exactly readable
18:45:41 <Brian`> @hoogle String -> IO ()
18:45:41 <lambdabot> Prelude.putStr :: String -> IO ()
18:45:41 <lambdabot> Prelude.putStrLn :: String -> IO ()
18:45:41 <lambdabot> Debug.Trace.putTraceMsg :: String -> IO ()
18:54:34 <TSC> faxathisia: I fed test4 into a constraint solver, and it solved it pretty quickly
18:54:50 <faxathisia> how?
18:55:11 <faxathisia> I turn test4 into these equations http://rafb.net/p/IlAicB15.txt
18:55:31 <faxathisia> is constraint solving the same method?
18:56:01 <dons> ?yow
18:56:01 <lambdabot> While my BRAINPAN is being refused service in BURGER KING, Jesuit
18:56:01 <lambdabot> priests are DATING CAREER DIPLOMATS!!
18:56:23 <hpaste>  TSC pasted "minesweeper" at http://hpaste.org/4136
18:56:50 <TSC> The solver I used does propagation on the constraints to prune the search space
18:57:13 <faxathisia> what can you run this in? not swi prolog?
18:57:16 <TSC> Eclipse
18:57:29 <faxathisia> cool I'll try it out
18:57:35 <faxathisia> Initially I just printed out prolog code
18:57:44 <TSC> http://eclipse.crosscoreop.com/
18:57:45 <lambdabot> Title: ECLiPSe Home
18:57:46 <faxathisia> but it seems like prolog solves it a lot slower than eclipse
18:57:52 <TSC> It depends
18:58:13 <TSC> If prolog is not using propagation, it will be slow
18:58:40 <faxathisia> amazing you solved it so fast :)
18:58:58 <TSC> I just fed it in, the solver solved it (:
18:59:48 <TSC> All I did was write a program to convert the input you gave into the eclipse program
19:02:34 <Brian`> > show "a\nb"
19:02:35 <lambdabot>  "\"a\\nb\""
19:02:59 <Brian`> how do I make show "something" that gives me a string containing a new line?
19:03:22 <Brian`> > putStrLn (show "a\nb")
19:03:23 <lambdabot>  <IO ()>
19:03:38 <faxathisia> :t onLines
19:03:38 <lambdabot> Not in scope: `onLines'
19:05:13 <cjay> Brian`: show is there to generate haskell-constants, I think literal newlines can't be part of constants
19:05:38 <cjay> Brian`: what you want is a prettyprinting Class, or something similar
19:05:40 <byorgey> Brian`: 'show' is just for converting things to String, it doesn't do any actual output.  putStr (or putStrLn) will display a string to the screen, including translating newline characters into new lines.
19:05:49 <hpaste>  TSC annotated "minesweeper" with "(no title)" at http://hpaste.org/4136#a1
19:06:01 <byorgey> Brian`: perhaps I don't understand what you're trying to do.
19:06:10 <oerjan> cjay: that's a bit simplified i think.  not all show instances always create legal haskell
19:06:16 <oerjan> > show (1/0)
19:06:16 <lambdabot>  "Infinity"
19:06:19 <cjay> oh
19:06:27 <cjay> I didn't know that
19:06:35 <oerjan> > Infinity
19:06:36 <lambdabot>   Not in scope: data constructor `Infinity'
19:06:39 <cjay> > 1/0
19:06:40 <lambdabot>  Infinity
19:06:43 <byorgey> oerjan: Double is a particularly poor example of anything.
19:06:54 <Brian`> I'm making a type Board as an instance of Show
19:06:55 <TSC> But for the most part, show is readable
19:06:59 <oerjan> although when it makes sense, they try to
19:07:13 <Brian`> and after one row, I want to put a new line
19:07:20 <Brian`> :t show
19:07:20 <lambdabot> forall a. (Show a) => a -> String
19:07:21 <oerjan> and show should always be read'able, in the read . show sense
19:07:30 <Brian`> i c..
19:07:41 <Brian`> would pretyPrint solve my problem?
19:08:18 <byorgey> Brian`: that's a separate issue.  putting "\n" in the output will do exactly what you want.
19:09:05 <byorgey> > "a\nb"   -- Brian`, is this what's confusing you?
19:09:20 <lambdabot>  thread killed
19:09:30 <byorgey> > "a\nb"
19:09:30 <lambdabot>  "a\nb"
19:10:00 <oerjan> ?
19:10:13 <byorgey> If you display a String value like that, it will just show the \n.
19:10:16 <oerjan> > "a\nb"   -- Brian`, is this what's confusing you?
19:10:29 <lambdabot>  "a\nb"
19:10:32 <Brian`> hm.. not really ;?
19:10:34 <byorgey> but if you putStr or putStrLn it, the \n will be displayed as an actual new line.
19:10:39 <Brian`> what's so confusing about "a\nb"?
19:10:49 <Brian`> yeah
19:10:50 <faxathisia> TSC: that's amazing!
19:10:51 <oerjan> (that was just me checking if the thread killed was a bug btw)
19:10:56 <Brian`> what I was trying to do is
19:10:58 <byorgey> Brian`: nothing really.  I guess I'm still not sure what your question is then.
19:11:15 <byorgey> oerjan: I guessed as much =)
19:11:17 <Brian`> I have a function that solves a sudoku puzzle and return the board
19:11:19 <TSC> faxathisia: Constraint programming is powerful on this kind of problem
19:11:22 <Brian`> and in my main do block
19:11:31 <Brian`> it looks like
19:11:36 <oerjan> i guess it's a heisenbug :/
19:12:04 <Brian`> do { putStrLn ( show (solveSudoku) ) }
19:12:05 <faxathisia> TSC: I'm gonna learn ECLiPSe now :D
19:12:12 <Brian`> something like that..
19:12:13 <faxathisia> maybe I will try and code it in haskell later too
19:12:19 <oerjan> @src print
19:12:19 <lambdabot> print x = putStrLn (show x)
19:12:20 <faxathisia> (the specific method)
19:12:29 <TSC> faxathisia: The thing that makes it fast is the ic solver, a library for eclipse
19:12:29 <byorgey> could be a mandelbug.
19:12:55 <oerjan> byorgey: hm i guess an infinite recursion is fractal in a sense...
19:13:02 <byorgey> Brian`: ok, that looks fine.  note that in that case you don't actually need the do { }.
19:13:25 <Brian`> yeah ; I just simplified my do block, that's why :) thanks for pointing out though
19:13:38 <byorgey> @src print
19:13:38 <lambdabot> print x = putStrLn (show x)
19:13:49 <Brian`> kk cool
19:15:46 <cjay> Brian`: you could 'show' the lines individually and output them on separate lines
19:16:09 <cjay> or write your own function to print the wohle thing in a human-friendly way
19:16:40 <Brian`> cjay, yeah I guess that approach looks like what I should do.
19:16:51 <enderbean> Is there a place I can search for functions by type?
19:16:59 <Brian`> hoogle?
19:17:03 <Brian`> @hoogle a -> [a]
19:17:04 <lambdabot> Prelude.repeat :: a -> [a]
19:17:04 <lambdabot> List.intersperse :: a -> [a] -> [a]
19:17:04 <lambdabot> Prelude.(:) :: a -> [a] -> [a]
19:17:15 <oerjan> @where hoogle
19:17:15 <lambdabot> http://haskell.org/hoogle
19:17:37 <oerjan> it has some bugs though
19:17:38 <enderbean> hoogle. Thats a great name.
19:17:48 <sorear> @tell dons the code on your blog is wrong - it isn't parallel
19:17:48 <lambdabot> Consider it noted.
19:18:15 <monochrom> @src readIO
19:18:15 <lambdabot> Source not found. It can only be attributed to human error.
19:19:38 <Brian`> hey, in pattern matching, can I not do func' a:b:c:d:e:f:g:h:i:xs
19:19:38 <Brian`> ?
19:20:02 <Olathe> > let f a:b:c:d:e:f:g:h:i:xs = "Insane" in f [1..25]
19:20:02 <lambdabot>  Parse error in pattern at "in" (column 39)
19:20:09 <Olathe> > let f (a:b:c:d:e:f:g:h:i:xs) = "Insane" in f [1..25]
19:20:13 <lambdabot>  "Insane"
19:20:24 <Olathe> Yes.
19:20:34 <Brian`> hm.. weird lol
19:20:43 <Brian`> thanks Olathe
19:20:48 <Olathe> No problem.
19:20:58 <Olathe> Bill Nye was almost right.
19:27:54 <unk_red> Is there any way to ease the tedium of writing all these accessor functions? http://hpaste.org/4137
19:28:19 <ddarius> unk_red: Use records
19:28:27 <unk_red> I was really happy till i reached the part where the instances were necessary
19:28:54 <unk_red> ddarius: is that possible with the differences between Car and Bike?
19:29:39 <ddarius> It would make writing the instances a bit nicer and more robust, but I don't really think you want to do what it looks like you're trying to do (but I could be wrong)
19:29:53 <Olathe> beep (Car _ _ _) = "Beep !"; beep (Bicycle _ _) = "Ding ding !"
19:30:18 <davidL> @src splitAt
19:30:18 <lambdabot> splitAt n xs           =  (take n xs, drop n xs)
19:32:14 <glguy> byorgey, you ther?
19:32:21 <glguy> ?seen byorgey
19:32:21 <lambdabot> byorgey is in #haskell and #xmonad. I last heard byorgey speak 18m 43s ago.
19:32:28 <byorgey> glguy: what's up?
19:32:44 <glguy> We were just doing the last PE problem
19:32:52 <glguy> and after solving it went though the solutions
19:32:56 <mm_freak> besides doing haskell stuff, is lambdabot competitive with eggdrop or energemech?
19:33:10 <byorgey> glguy: oh, yes, I saw you commented too
19:33:14 <glguy> Did you immediately think to use Endo to do the compose?
19:33:27 <glguy> or was that an after the fact endulgence?
19:33:31 <byorgey> glguy: yes, I did
19:33:50 <unk_red> ddarius: i want them to share some accessors but have a different number of parameters. i'm not sure what you think i'm trying to do? :) am i being stupid here?
19:34:07 <byorgey> glguy: do you think it's overkill? =)
19:34:13 <glguy> heh
19:34:40 <hpaste>  oerjan annotated "tedium" with "single datatype approach" at http://hpaste.org/4137#a1
19:34:41 <glguy> That is the same logic you used without the madness ;)
19:35:35 <oerjan> unk_red: unless you _really_ need to use classes a single datatype would be much simpler
19:35:44 <byorgey> glguy: yeah, that seems clearer.
19:36:03 <glguy> byorgey, I updated my forum post with my final answer before I saw yours :)
19:36:56 <oerjan> (see my paste annotation)
19:37:39 <unk_red> oerjan: ah. thanks. that is a lot simpler.
19:37:46 <byorgey> glguy: =)
19:37:51 <unk_red> oerjan: that would take away a lot of the compiler checks though right?
19:38:15 <oerjan> it would not distinguish Bicycle and Car by type, that is true.
19:38:35 <byorgey> glguy: OOC, who is "we"?
19:38:38 <unk_red> that was what was so appealing about classes
19:38:48 <glguy> byorgey, iavor and me
19:39:07 <byorgey> cool
19:39:07 <glguy> byorgey, I did my memoization solution and then pestered him until we made more progress
19:39:15 <byorgey> hehe =)
19:39:26 <glguy> anyway, I'm late to dinner!
19:39:28 <oerjan> otoh if you want to have lists of several mixed vehicles classes cause you to end up with existential types
19:39:29 <glguy> ttyl
19:39:36 <byorgey> glguy, enjoy =)
19:40:16 <oerjan> *vehicles, classes
19:44:12 <oerjan> unk_red: i'm not familiar with any of them, but one of the generics libraries probably can generate the instances automatically somehow
19:46:16 <ddarius> Certainly one of the Derivey things could easily.
19:47:00 <dufflebunk> Is (,) a real operator?
19:47:34 <TSC2> @type (,)
19:47:35 <lambdabot> forall a b. a -> b -> (a, b)
19:47:49 <LoganCapaldo> is <$> a real operator?
19:48:14 <oerjan> it's a real function but you cannot use it infix
19:48:26 <oerjan> > 2 `(,)` 3 -- nope
19:48:26 <lambdabot>  Parse error at "(,)`" (column 4)
19:48:35 <LoganCapaldo> > ("isn't this", "infix?")
19:48:36 <lambdabot>  ("isn't this","infix?")
19:48:47 <oerjan> circumfix? :)
19:48:48 <LoganCapaldo> > 2`(+)` 3 -- doesn't work anyway
19:48:48 <lambdabot>  Parse error at "(+)`" (column 3)
19:48:53 <mgsloan> mixfix?
19:48:53 <gwern> > (,) 2 3
19:48:54 <lambdabot>  (2,3)
19:49:27 <mgsloan> I just started on TAPL, and it calls trinary and up operators "mixfix"
19:49:50 <dufflebunk> What I meant was, if I redefine (,) will that change how (a,b,b) acts?
19:50:15 <ddarius> > let (,) = (+) in (3,4)
19:50:16 <lambdabot>      Constructor `(,)' should have 2 arguments, but has been given 0
19:50:16 <lambdabot>     In t...
19:50:16 <mgsloan> I don't see why (,) (,,) (,,,) etc aren't functions, though
19:50:23 <ddarius> (,) are constructors
19:50:25 <LoganCapaldo> > let (,) = (+) in (2,3)
19:50:27 <lambdabot>      Constructor `(,)' should have 2 arguments, but has been given 0
19:50:29 <lambdabot>     In t...
19:50:37 <mgsloan> constructors are functions, no?
19:50:40 <ddarius> dufflebunk's question is like asking "if I redefined Just will ..."
19:50:48 <LoganCapaldo> > let Just = id in Just "Can't do this in general no?"
19:50:49 <lambdabot>      Constructor `Just' should have 1 argument, but has been given 0
19:50:49 <lambdabot>     In t...
19:50:54 <LoganCapaldo> lol
19:50:55 <ddarius> mgsloan: They are functions but they aren't -just- functions.
19:51:01 <davidL> > let (,) x y = x + y in (3,4)
19:51:01 <lambdabot>      Occurs check: cannot construct the infinite type: t = (t, t)
19:51:01 <lambdabot>       Expec...
19:51:08 <LoganCapaldo> I like how I came up with the same example as ddarius
19:51:18 <mgsloan> well, yeah, not just functions, sure
19:51:25 <mgsloan> you can pattern match and such
19:52:02 <dufflebunk> ddarius: I might be, I don't know. Most languages have exceptions for various punctuation. Is , an operator in HAskell which can be redefined, or is it punctuation which cannot be redefined.
19:52:39 <dons> > let (,) = (+) in 1 , 2
19:52:39 <lambdabot>   parse error on input `,'
19:52:39 <lambdabot> dons: You have 3 new messages. '/msg lambdabot @messages' to read them.
19:52:48 <mgsloan> looks to me like un-redefinable punctuation
19:53:07 <dons> data (,,) a b c = (,,) a b c deriving (Eq, Ord)
19:53:13 <LoganCapaldo> or it could be an unredefinable constructor that just so happens to coincendentally be punctuation
19:53:18 <dons> > let (,.,) = (+) in 1 .,, 2
19:53:18 <lambdabot>  Parse error at ".,)" (column 7)
19:53:19 <LoganCapaldo> (I don't know which)
19:54:21 <oerjan> put a different way, , is not an operator character
19:54:35 <oerjan> nor are ()
19:55:17 <oerjan> the lexical analysis chapter in the report has a list i think
19:55:21 <oerjan> @where report
19:55:21 <lambdabot> http://www.haskell.org/onlinereport/
19:55:54 <oerjan> of course some combinations are keywords in any case such as --
19:56:47 <ddarius> dufflebunk: You can't redefine it, but you can't "redefine" any function in Haskell.  You can a) shadow old ones, but you can't shadow constructors or b) hide the old ones and make a new independent one, which you can do for constructors but not for (,)
19:57:10 <dufflebunk> I'm seeing weird stuff in the Binary code, which I can read but doesn't make sense from what I thought was just punctuation. Like: get = liftM5 (,,,,) get get get get get
19:57:35 <LoganCapaldo> they really take it all the way to 5?
19:57:42 <LoganCapaldo> geez
19:57:54 <dufflebunk> It goes further than that, to 7 or 8 I think
19:58:02 <oerjan> dufflebunk: all the tuple constructors have function versions like that
19:58:15 <LoganCapaldo> @hoogle liftM8
19:58:16 <lambdabot> No matches found
19:58:20 <LoganCapaldo> @hoogle liftM7
19:58:20 <lambdabot> No matches found
19:58:23 <LoganCapaldo> @hoogle liftM6
19:58:23 <lambdabot> No matches found
19:58:26 <LoganCapaldo> @hoogle liftM5
19:58:26 <lambdabot> Monad.liftM5 :: Monad a => (b -> c -> d -> e -> f -> g) -> a b -> a c -> a d -> a e -> a f -> a g
19:58:27 <lambdabot> Control.Monad.liftM5 :: Monad m => (a1 -> a2 -> a3 -> a4 -> a5 -> r) -> m a1 -> m a2 -> m a3 -> m a4 -> m a5 -> m r
19:59:19 <dufflebunk> oerjan: So the tuple constructors aren't plain constructors, or is there some limit to the size of tuple you can copnstruct?
19:59:21 <ddarius> LoganCapaldo: The Report defines how big tuples can be and be "supported" in various ways.
19:59:24 <gwern> I am kind of curious: I've been musing about how to turn a haskell prompt into a usable shell (or write a good shell in haskell; same thing in my view), and I think the biggest obstacles are the syntax and the whole IO monad thing. the best way around the latter seems to me to be some way of automatically applying unsafePerformIO to all IO operators, but I've been wondering - is it maybe better to instead think about pulling everything ...
19:59:25 <oerjan> > let (,) x y = (1,2) in x+y -- can even do this i think
19:59:26 <lambdabot>  3
19:59:29 <faxathisia> :t (,,,,,,,,,,,,,,,,,)
19:59:29 <lambdabot> forall a b c d e f g h i j k l m n o p q r. -> b -> c -> d -> e -> f -> g -> h -> i -> j -> k -> l -> m -> n -> o -> p -> q -> r -> (a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r)
19:59:30 <gwern> ... into IO instead of just obliterating it?
19:59:36 <LoganCapaldo> ddarius: I was talking about liftM
19:59:51 <ddarius> dufflebunk: They are plain except that you can't define them yourself for mere syntactical reasons.
20:00:14 <dufflebunk> ddarius: Ok, thanks.
20:01:25 <ddarius> LoganCapaldo: I don't think liftM is covered, but zipWithN and various instances are discussed in the Report.
20:01:31 <oerjan> dufflebunk: i don't see a limit to the tuples themselves. http://www.haskell.org/onlinereport/exps.html#sect3.8
20:01:32 <lambdabot> Title: The Haskell 98 Report: Expressions
20:01:57 <oerjan> although the other functions on tuples such as zip2 etc. are limited.
20:02:02 <LoganCapaldo> 5 just seems excessive in the presence of ap
20:02:16 <dons> ?users
20:02:16 <lambdabot> Maximum users seen in #haskell: 413, currently: 388 (93.9%), active: 18 (4.6%)
20:02:31 <ddarius> LoganCapaldo: What?!  I need liftM27
20:02:40 <LoganCapaldo> heh
20:03:50 <oerjan> dufflebunk: oh wait, section 6.1.4 puts a lower limit of 15
20:05:46 * dufflebunk looks at sectio n6.1.4
20:08:59 <dufflebunk> Thanks oerjan
20:09:21 <shapr> @yow !
20:09:22 <lambdabot> ... I see TOILET SEATS ...
20:09:23 <shapr> Excitement!
20:09:27 <shapr> g'day brushbox
20:09:55 <blackdog> shapr: are you despoiling my lingo?
20:09:58 <brushbox> shapr: hi!
20:10:00 <shapr> blackdog: um, no?
20:10:09 <blackdog> ersatz aussie :P
20:10:09 <shapr> blackdog: I think aussies are really cool, and so is their lingo!
20:10:13 <shapr> hah
20:10:19 <TSC2> Crikey!
20:10:33 <brushbox> we don't speak no lingo!
20:10:45 <shapr> Don't come the raw prawn on me!
20:10:54 * blackdog renames shapr Bruce, to avoid confusion
20:10:57 <TSC2> What the flaming hell's going on in here?
20:11:04 <blackdog> shapr: *with* me
20:11:14 <blackdog> coming a raw prawn on someone is extremely crass
20:11:15 <shapr> blackdog: I know, I just had to make that sound sexually perverted.
20:11:18 * shapr laughs
20:11:40 <shapr> Stone the crows, ya know.
20:11:43 <shapr> Whatever that means.
20:11:46 <TSC> You galah
20:12:21 <shapr> Ah, google turns up the meaning of stone the crows.
20:12:39 <shapr> the term "Stone The Crows" is from a Scottish curse meaning "the hell with it"
20:12:41 <shapr> Interesting
20:13:02 <Plareplane> is there a way to find the type of a "concretely defined, point-ful" function in ghci? (e.g, something like :t reverse xs == xs). it rightly complains about things not being in scope
20:13:32 <allbery_b> :set -fglasgow-exts and use implicit vars?
20:13:40 <cdsmithus> @ty \xs -> reverse xs == xs
20:13:41 <allbery_b> :t reverse ?xs == ?xs
20:13:42 <lambdabot> forall a. (Eq [a]) => [a] -> Bool
20:13:42 <lambdabot> (?xs::[Integer]) => Bool
20:13:59 <allbery_b> ...which defaulted.  feh
20:14:02 <Plareplane> oh thanks
20:14:22 <byorgey> Plareplane: you could also do something like:
20:14:26 <allbery_b> either one :)
20:14:32 <byorgey> @type let f xs = reverse xs == xs  in f
20:14:32 <lambdabot> forall a. (Eq [a]) => [a] -> Bool
20:15:42 <goalieca> hehe: c++ template compile-time fibonacci http://programming.reddit.com/info/61oiu/comments/c02jy45
20:15:55 <shapr> @seen SyntaxNinja
20:15:55 <lambdabot> I saw SyntaxNinja leaving #haskell and #haskell-blah 2h 12m 47s ago, and .
20:15:57 <shapr> aww
20:16:19 <thoughtpolice> i was going to give a stab at writing an intercal version but i haven't done intercal in a long time. :(
20:17:35 <ddarius> goalieca: Now write a Haskell compile-time version.
20:18:29 <faxathisia> Is there some constraint satisfaction solvers in haskell?
20:18:53 <TSC> faxathisia: Not that I know of
20:19:17 <TSC> You could try to use, say, gecode, which is written in C++
20:19:25 <TSC> It has bindings for Java and Ruby, I think
20:19:46 <faxathisia> I think I will try and rewrite my program in ECLiPSe then
20:19:49 <TSC> I've written a really simple, slow, stupid one for solving nonogram puzzles
20:19:56 <TSC> (in Haskell)
20:20:06 <faxathisia> what do you mean stupid?
20:20:17 <TSC> As in, not very clever
20:20:36 <TSC> And it doesn't support many constraints
20:21:02 <faxathisia> mmm I wrote one which is taking sets of linear equations and a finite integer domain for variables
20:21:45 <mwc> hey dons, amusing article on the Ruby 1.9 OMFG ITS SO FASTXOR!!!111!!one! hype
20:21:52 <faxathisia> actually can I see yours please? I'm interested
20:21:59 <ddarius> faxathisia: I don't think there are any nicely packaged, remotely "serious" ones.
20:22:13 <Olathe> Ruby 2.0 is the fastxor one.
20:22:21 <Olathe> With all its VMishness.
20:22:53 <Olathe> Unfortunately, it has a HURDish timeline, it seems.
20:23:13 <TSC> faxathisia: It's not nicely packaged or remotely serious, but you can see it
20:25:07 <mwc> Olathe, is it supposed to run on Parrot?
20:25:33 <mwc> Somebody should produce a parrot backend for GHC just to spite the Perl/Ruby crowd
20:26:24 <Olathe> No, its own.
20:26:31 <Olathe> Parrot seems a bit bloated.
20:27:03 <mwc> I was sort of amused by the whole register VM concept
20:27:13 <mwc> why not have a bazillion registers?
20:27:21 <mwc> why stop at N?
20:27:43 <mwc> why not then do away with registers at the VM level, and view memory as an array of cells
20:27:55 <Pseudonym> Because you can map virtual registers to real ones.
20:27:59 <ddarius> Memory is an array of cells.
20:28:22 <goalieca> but then you have to exchange between classes of cells
20:28:44 <Korollary> registers are just named L0 cache cells
20:28:56 <Pseudonym> No!
20:29:02 <Pseudonym> ISA registers are named L0 cache cells.
20:29:02 <mwc> Korollary, sure, that makes sense that the CPU level
20:29:13 <Pseudonym> Register renaming means that not all L0 cache cells are named.
20:29:17 <mwc> but at the VM/application level?
20:29:29 <Pseudonym> Actually, Korollary, I just realised that what I said doesn't contradict what you said.
20:29:33 <Pseudonym> Never mind.
20:29:40 <Korollary> Regina has the awesomest name for a place. Bravo Canadians.
20:30:20 <mwc> Korollary, thanks. In fact, the home town team (Saskatchewan Roughriders, of Regina) just brought home the grey cup!
20:30:56 <mwc> Korollary, though does the name lose its awesomeness if I tell you its latin for queen?
20:31:02 <goalieca> there once was a lady from regina
20:31:19 <Korollary> mwc: I sorta guessed its meaning, but it's still fun.
20:31:39 <goalieca> while regina is fine.. i like dog river better
20:32:01 <Korollary> That's like Liverpool
20:32:37 <lament> goalieca: something something china?
20:32:44 <allbery_b> re registers: then there's the K[AIL]10 / TMS9900 model...
20:32:51 <lament> there once was a lady from regina
20:32:56 <lament> who really liked chicken fajita
20:33:04 * lament runs away
20:33:47 * oerjan wants to kick lament but realizes he is not op while lament is on the other channel he's on
20:34:00 <allbery_b> heh
20:34:13 <goalieca> lamet: her neck looked like a <blank>
20:34:40 <goalieca> she once met the man from nantucket
20:36:07 <darrint> I've been fooling around with a toy function which uses lift to do IO in StateT. I tried to do the same with ListT but could never get it to work. Is ListT + IO even possible?
20:36:52 <oerjan> :t liftIO
20:36:53 <lambdabot> forall a (m :: * -> *). (MonadIO m) => IO a -> m a
20:37:39 <gwern> oh. no wonder that shell wasn't working, it was written for haskell 1.2 :)
20:39:05 <goalieca> @seen sigpfe
20:39:05 <lambdabot> I haven't seen sigpfe.
20:39:12 <goalieca> @seen sigfpe
20:39:12 <lambdabot> I haven't seen sigfpe.
20:39:36 <conal> i'm sure confused about cabal and .setup-config vs dist/setup-config.  afaict, cabal sometimes uses one and sometimes the other.  anybody know what's going on?
20:39:49 <sorear> goalieca: 'dpiponi'
20:40:01 <allbery_b> yeh, he's dpiponi around here
20:40:51 <thoughtpolice> conal: from general observations 1.1 used .setup-config while 1.2 moved it into dist instead
20:40:58 <chessguy> gotta love a blog post where one of the concluding remarks is "One last thing. Much of what I've said above is false."
20:41:05 <chessguy> @seen dpiponi
20:41:05 <lambdabot> I saw dpiponi leaving #haskell 1d 10h 34m 31s ago, and .
20:41:12 <chessguy> goalieca, ^^
20:41:20 <chessguy> oh, someone said that
20:41:59 <ddarius> chessguy: Link?
20:42:21 <chessguy> ddarius, http://sigfpe.blogspot.com/2007/11/io-monad-for-people-who-simply-dont.html
20:42:22 <lambdabot> Title: A Neighborhood of Infinity: The IO Monad for People who Simply Don't Care, http://tinyurl.com/yplmwx
20:42:28 <conal> thoughtpolice: oh!  i had to recompile my Setup.lhs.  thanks!  :)
20:42:38 <goalieca> chessguy, thanks for saving me time. i was going to complain
20:42:44 <goalieca> didn't read all the way to bottom
20:42:55 <chessguy> not the most impressive thing he's ever written. it is amusing though :)
20:43:55 <conal> why do people refer to the IO type as "the IO monad"?  we don't call [] "the list monad".
20:44:04 <mrd> we do
20:44:08 <goalieca> In the first paragraph he makes his first bad statement. x = if (a==1) { 2; } else { 3; } ==> int x = (a==1)?2:3;
20:44:32 <faxathisia> goalieca: Does he claim it's C?
20:44:38 <goalieca> ya
20:44:46 <goalieca> "nd in C you can't say x = if (a==1) { 2; } else { 3; }."
20:45:02 <mrd> alright, to be strictly correct, lets call it the IO type-constructor from now on
20:45:04 <faxathisia> x = if .. is an error :/
20:45:05 <conal> i get the impression that newbies think monads are about imperative computation.  maybe the term "the IO monad" contributes.
20:45:09 <faxathisia> what he said there is correct
20:45:20 <goalieca> int x = (a==1)?2:3;
20:45:28 <faxathisia> goalieca: That's a different peice of code
20:45:30 <Korollary> conal: I guess it's because IO is blatantly a monad while list isn't unless you want to think it is.
20:45:42 <goalieca> well.. lol.
20:45:47 <mrd> also lets stop talking about being "in the monad"
20:46:00 <goalieca> delete all mentions of the word monad
20:46:02 <mrd> unless you're singing about being "...in the monad..."
20:46:04 * jleedev spent a solid week inside the list monad. it was glorious
20:46:08 <conal> Korollary: maybe that's part of my objection.  the most interesting thing about IO is not that it's a monad.
20:46:29 <conal> it's that it's a type of values that represent imperative computation.
20:46:43 <allbery_b> o/` I'm siiiing-ing in the monad...  ... neh, doesn't scan
20:46:49 <conal> bringing in monads from the start muddles the issues.
20:48:11 <Korollary> But, you can't avoid it. All you have is the monad methods.
20:48:34 <ddarius> conal: Actually even categorists tend to refer to the functor part of a monad as "the monad"
20:48:40 <thoughtpolice> agreed. it suprised me to find the IO <expletive> wasn't really anything it all.
20:49:03 <thoughtpolice> the expletive is there so i don't offend anyone. :)
20:49:14 <mrd> it wasn't monad enough for you?
20:49:16 <Olathe> thoughtpolice: I can't believe you said that !
20:49:35 <thoughtpolice> i'm the police. i can do that.
20:49:48 <thoughtpolice> (end justification)
20:50:07 * chessguy chessguy_IA
20:50:13 * chessguy looks at thoughtpolice 
20:50:26 <dons> sjanssen: on 4 cores, 281% :)
20:50:39 <Korollary> dons: You're my #1 fanboy, dude.
20:50:41 <Olathe> thoughtpolice: Who polices the thought police ?
20:50:44 <dons> though i had to move to linux to get that to fly. openbsd doesn't seem up to the job -- the scheduler is just wacky
20:50:52 <chessguy> Olathe, the thought IA
20:50:55 <mrd> Olathe: who types the kinds?
20:50:59 <dons> this `par` stuff is super fun
20:51:12 <faxathisia> :(
20:51:21 <thoughtpolice> Olathe: the party!
20:51:24 <faxathisia> Maybe I am wrong about implicit parallelism
20:51:36 <mrd> we still talking about implicit perilism?
20:51:46 <conal> over & over i read that you need a monad to do anything useful in Haskell, particularly IO.  but the fact that the IO type (constructor) is a monad has is no more central to IO than to lists.
20:51:47 <dons> faxathisia: ?
20:52:14 <faxathisia> dons: I though it's defeating the purpose having things like `par` but you make me think I'm wrong
20:52:21 <atp> conal: the IO type constructor?  which would that be?
20:52:30 <conal> atp: IO
20:52:35 <dons> oh, we need things like `par` for code to keep getting faster
20:52:48 <atp> conal: that's not the constructor (necessarily)
20:52:56 <dons> right it the same naive way, drop in the parallel hints, and bammo, it runs across 4 cores unmodified
20:53:01 <conal> atp: ?
20:53:10 <faxathisia> Is it not reasonable to just attempt to parallelize everything?
20:53:11 <dons> but now i really want to switch to linux
20:53:21 <atp> conal: data Foo a = Bar a  <- Bar is the constructor
20:53:25 <dons> faxathisia: i think you have to ensure you don't swamp the spark pool with jobs
20:53:34 <mrd> i dropped some parMaps in and got parallelized matrix multiplication
20:53:34 <thoughtpolice> dons: to keep getting improvement? :)
20:53:36 <dons> so you only want to hint to parallelise tasks that are big enough
20:53:42 <faxathisia> mm yeah
20:53:47 <mrd> then i tried it with NDP and parMaps but GHC started crashing
20:53:51 <conal> atp: haskell has confusing terminology.  Bar is the data constructor and Foo is the type constructor.
20:53:56 <faxathisia> I thought it's maybe possible an implementation to decide
20:54:04 <dons> thoughtpolice: the openbsd shcheduler only wants to run big jobs on core 1, as far as i can see. its not spreading work around properly
20:54:07 <faxathisia> but I don't know any details on this sort of thing
20:54:14 <chessguy> @quote terminology
20:54:14 <lambdabot> dylan says: I avoid buzz-buzz whenever possible. I prefer math-based or completely insane terminology
20:54:20 <dons> inferring the expensive expressions is hard
20:54:33 <dons> mrd, make some bug reports?
20:54:38 <dons> mrd, without bug reports, we can't fix things
20:54:39 <conal> atp: the two uses of constructor are not consistent
20:54:47 <conal> atp: of "constructor"
20:54:55 <thoughtpolice> dons: yeah, i have my obsd box and i've heard of things like that (the scheduler is finnicky and whatnot, mainly benchmarks I saw complained)
20:55:03 <atp> conal: ah, i didn't know that.  but either way, if IO weren't a monad, you'd need to know much more about the internal representation of the IO type to compose functions that have side effects.
20:55:05 <faxathisia> :t par
20:55:06 <lambdabot> forall a b. a -> b -> b
20:55:10 <faxathisia> :t const
20:55:10 <lambdabot> forall a b. a -> b -> a
20:55:19 <mrd> dons: yea its filed
20:55:47 <conal> atp: i don't see why we'd need to know anything at all about the internal representation.
20:55:48 <atp> conal: and the whole point of putting IO in a monad is to hide that representation from you, in order to properly encapsulate the side effects.
20:56:14 <atp> conal: how else would you compose functions that feature IO types?
20:56:39 <ddarius> Haskell existed before monadic IO.
20:56:52 <atp> ddarius: yes, i remember something about it.  some sort of stack type thing with main or some such...
20:56:54 <conal> atp: for one, i could use functions that have the same signature as return and >>=, but without declaring the Monad instance.
20:57:15 <atp> conal: sure.   it'd still be a monad.
20:57:20 <conal> atp: type classes are nice for structuring & reuse, but they have nothing especially to do with IO.
20:57:38 <ddarius> Not declaring it a monad doesn't make it not a monad.
20:57:40 <conal> atp: certainly.  a monad whether declared to be or not.
20:57:45 <conal> :)
20:57:56 <atp> conal: right, so i don't exactly see what you're saying...
20:58:04 <thoughtpolice> speaking of haskell on cores i should probably get my dual xeon server running with ghc.
20:58:07 <conal> my point is that monadness is convenient, not essential to the notion of IO
20:58:26 <atp> conal: but regardless of what you call >>= and return, it's still a monad
20:58:30 <conal> any more than it's essential to the notion of lists or many other type (constructor)s that happen to be monads
20:58:45 <Olathe> It's also a computation.
20:58:47 <conal> atp: of course it's a monad
20:58:59 <atp> conal: the difference is that you can do useful things with lists without the monadic interface.  with IO, you're sort of stuck
20:59:04 <Olathe> So, we must emphasize theoretical computer science to all newcomers.
20:59:11 <davidL> is there an easy way to combine two Word8 to create a Word16?
20:59:22 <conal> atp: i can do lots: primitives, fmap, applicative,
20:59:40 <conal> atp: mapM, sequence, ...
20:59:46 <atp> conal: mapM is monadic, as is sequence
20:59:48 <Korollary> how is that not monadic?
20:59:56 <atp> conal: i believe fmap is defined in terms of bind and return for IO
21:00:27 <conal> atp: again, out of convenience, we exploit the elegant structuring that type classes allow.  but it's just factoring.  nothing essential to the nature of IO.
21:00:57 <atp> conal: i really don't understand the point you're trying to make...
21:01:23 <atp> conal: in a language that doesn't strictly enforce sequencing,
21:01:27 * conal thinks how to make it clearer
21:01:57 <atp> conal: if f and g both have side effects, when you do f + g, which side effect happens first?
21:02:07 <conal> atp: static type error
21:02:45 <ddarius> Indeed, there is nothing Monad or monads are doing for us that is essential.
21:03:13 <salierix> Is there a lot of overhead in calling a C function from Haskell?
21:03:16 <atp> ddarius: without monads, how would you do IO?
21:03:29 <P_D> salierix:  Not if you specify "unsafe"
21:03:30 <atp> salierix: mostly in taking the data across the border, as it were, or so i've heard
21:03:35 <ddarius> atp: As I said, Haskell existed before monadic IO.
21:04:02 <ddarius> atp: That said, I have to agree with you.  Arbitrarily not making IO an instance of Monad accomplishes nothing.
21:04:05 <atp> ddarius: right, but it was a clunky wacky interface, wasn't it?  something about a stack being passed to main (thus simulating state)
21:04:07 <jcreigh> ddarius: But from what I've heard, it was rather awkward.
21:04:07 <conal> my point pedagogical.  when people learn Haskell IO, they're getting taught two challenging and separable ideas, and so they muddle those ideas.  i'd like them to learn each idea independently so they can understand them more clearly and see how the ideas are used elsewhere.
21:04:25 <thoughtpolice> the two being?
21:04:38 <ddarius> atp: The stream based version had issues, but the CPS version was more or less the same as monadic IO.
21:04:50 <atp> ddarius: but that's because CPS is a monad at its core
21:04:53 <conal> one idea is that imperative computation can be captured in a type of pure values.  the other is the type classes and one in particular.
21:05:15 <atp> ddarius: we could do IO with ArrowApply too, but it's still just isomorphic to a monad...
21:05:17 <ddarius> atp: CPS can be expressed via a monad.  So could the stream based version.
21:05:35 <ddarius> atp: There is a difference between "is a" and "is an instance"
21:06:11 <ddarius> conal: In reality they are often separated.  You can pretend do notation is basic and for IO only when learning.
21:06:53 <atp> i really don't understand what all the fuss is about monads anyway
21:07:04 <Olathe> OMG MONADS !!!!1
21:07:05 <atp> i think people are afraid of the term
21:07:05 <mrd> much a 'do' about Nothing
21:07:09 <atp> hehe
21:07:12 <conal> mrd: :)
21:07:44 <atp> it probably doesn't help when someone asks "what is a monad" and some wiseguy says "why, it's a morphism from a category onto itself, together with two natural transformations!"
21:07:56 <atp> or functor
21:07:58 <atp> rather
21:08:21 <conal> i see so much confusion even among haskell folks.  for instance, in the second paragraph of sigfpe's latest blog entry (on IO).  he sets up "expressions" vs "commands".
21:08:28 <conal> but expression is syntax and command semantics.
21:08:52 <ddarius> atp: But, but, it is!
21:09:01 <atp> ddarius: i know :)
21:09:34 <salierix> By "command" does he mean "action"?
21:09:47 <conal> salierix: probably.  again, semantics.
21:09:52 <atp> i sort of doubt that sigfpe doesn't know what a monad is
21:10:20 <conal> IO values are denoted by expressions, just as any other values are.
21:10:30 <atp> he tries hard to make category theory approachable in his blog, and sometimes he sacrifices strict correctness for what he perceives as greater clarity
21:10:37 <atp> that said, i have not read the blog post in question
21:10:51 <conal> http://sigfpe.blogspot.com/2007/11/io-monad-for-people-who-simply-dont.html
21:10:53 <lambdabot> Title: A Neighborhood of Infinity: The IO Monad for People who Simply Don't Care, http://tinyurl.com/yplmwx
21:11:12 <chessguy> i would hardly consider most of sigfpe's blogs "approachable" for anyone without a math degree
21:11:26 * atp has a math degree, so ymmv
21:11:32 * mrd does not
21:11:38 <glguy> byorgey, heh, Factor runs problem 169 faster than haskell
21:11:45 <mrd> atp: what degree of math were you charged with?
21:11:57 <byorgey> glguy, what's Factor?
21:12:13 <atp> a bs, pure math, wrote my honor's thesis on de rham cohomology...
21:12:17 * ddarius doesn't have a math degree and wishes sigfpe would turn it up some.
21:12:27 <thoughtpolice> byorgey: see http://factorcode.org and #concatenative
21:12:27 <lambdabot> Title: Factor programming language
21:12:28 <thoughtpolice> :)
21:12:34 <atp> mrd, so topology?
21:12:38 <conal> math guys are notorious for confusing syntax and smcs
21:12:41 <conal> semantics
21:12:42 <mrd> atp: oh, hard time
21:13:07 <atp> i was good at math... thought i'd do the phd... then i broke up with fiancee of six years and decided moving to china would be a better use of my time
21:13:13 <conal> for instance the notion of "differentiate a function w.r.t x" makes no sense.  function is semantics and "x" is syntax.
21:13:23 <mrd> what do you do in china?
21:13:33 <atp> learned chinese
21:13:36 <atp> hid
21:13:41 <Korollary> atp: From the CIA?
21:13:58 <mrd> from the PhD committee
21:14:10 <atp> from my ex, but she works for the state dept now, so close
21:14:27 <sili> sounds extreme
21:14:28 <Korollary> She must have been some kinda threat to make a man move overseas.
21:14:36 <atp> it was extreme
21:14:39 <atp> i was depressed
21:14:42 <atp> it was many years ago...
21:14:53 <atp> but i speak chinese!
21:14:57 <Korollary> Nobody told you that you were out of your mind?
21:15:02 <atp> (fat load of good that does me, so do a billion other people)
21:15:06 <ddarius> conal: Indeed: D : (R -> R) -o (R -> R)
21:15:34 <thoughtpolice> atp: if it makes you feel any better i'm sort of envious because i've always wanted to be fluent in a foreign language.
21:15:45 <ddarius> thoughtpolice: Then become so.
21:15:52 <atp> thoughtpolice: it's not hard.  move some place.  isolate yourself.  in three months, you speak.
21:15:55 <conal> ddarius: "-o"?
21:16:05 <ddarius> conal: Linear function
21:16:06 <atp> thoughtpolice: if you want to speak very well it takes longer, depending on how different the language is from your mother tongue
21:16:16 <thoughtpolice> ddarius: little time. have to worry about college, although i investigated russian a bit a year or so ago.
21:16:33 <conal> ddarius: then don't you mean D : (R->R) -> (R -> (R -o R)) ?
21:16:34 <ddarius> thoughtpolice: Excuses or quit whining.  You make your choices.
21:16:38 <thoughtpolice> :(
21:16:42 <chessguy> atp, sounds like a tough 3 months to me
21:16:43 <atp> thoughtpolice: i moved after college
21:16:46 <thoughtpolice> good point i guess.
21:16:51 <atp> chessguy: in my case it was more than 4 years...
21:16:58 <thoughtpolice> atp: i haven't even gotten accepted anywhere yet.
21:17:10 <atp> thoughtpolice: then you have time.  don't sweat it.
21:18:19 <ddarius> conal: R -o R is isomorphic to R, and D(f + g) = Df + Dg and D(af) = aDf so clearly D should be a linear function of functions.
21:18:31 <thoughtpolice> no, i meant it in a more immediate sense. what comes after can be whatever; going somewhere isolated and doing martial arts has gone through my mine plenty. :)
21:18:41 <ddarius> conal: But yes, for higher dimensions that would be significant.
21:18:43 <thoughtpolice> s/mine/mind/
21:18:51 <conal> ddarius: gotcha.  i thought you'd misplaced the -o
21:19:26 <atp> you probably want to use a typeclass instead of R
21:19:43 <P_D> function really means vector at that point too
21:19:54 <thoughtpolice> in any case, i think me => sleep.
21:20:02 <atp> you can do calculus on lots of things other than R
21:20:04 <P_D> but yeah, the traditional notation for derivatives is screwed uP!
21:20:29 <Olathe> What is a good notation ?
21:20:39 <ddarius> Olathe: Differential operators is one.
21:20:48 <P_D> Mathematica uses a tuple of numbers to indicate derivatives with respect to argument number
21:20:48 <ddarius> It's better in many ways at least.
21:20:52 <atp> i don't know, i like it
21:20:55 <P_D> it works, but it isn't pretty.
21:21:12 <atp> d/dx reminds you of differential forms...
21:21:20 <atp> with d the exterior derivative
21:21:36 <Olathe> Is there a good article on differential operators ?
21:21:44 <atp> sure, lots
21:21:50 <ddarius> atp: Down with the exterior derivative, up with the vector derivative.
21:21:51 <atp> depends on how you want to attack it
21:22:00 <goalieca> down with algebra
21:22:06 <atp> algebra is the win
21:22:14 * atp hugs finite fields.
21:22:16 <P_D> as a physicist, tensor notation is very practical
21:22:27 * ddarius poos on tensor notation.
21:22:28 <goalieca> as an engineer i care if it works :-)
21:22:33 <ddarius> Use geometric calculus.
21:22:33 <atp> physicists are notorious for abuse of notation
21:22:38 <Olathe> Something that meshes with abstract algebra.
21:22:43 <goalieca> braket!
21:22:56 <atp> yeah, bra ket is a good example of evil
21:22:57 * ddarius hugs geometric algebra.
21:23:00 <P_D> I think that abuse is overdramaticized
21:23:06 <P_D> what's wrong with bra ket
21:23:10 <atp> see
21:23:12 * mrd starts the notational abuse hotline
21:23:13 <Olathe> It's missing the c.
21:23:15 <P_D> you have a space and a dual space.
21:23:18 <goalieca> math people are damn purists
21:23:22 <atp> yes we are
21:23:40 <Olathe> No we aren't !
21:23:43 <ddarius> goalieca: Look at the geometric calculus.  It's physics people, not math people.
21:23:48 <Olathe> Oh, wait, that's against the axioms.
21:23:48 <ddarius> (Well, both.)
21:23:52 <Olathe> Yes, we are !
21:24:02 <goalieca> Olathe, but that's why you have "choice"
21:24:05 <P_D> vector and covector
21:24:14 <Olathe> I suppose.
21:24:24 <Olathe> The axiom of choice: people have free will.
21:24:30 <atp> what?
21:24:31 <ddarius> @google "geometric calculus"
21:24:32 <lambdabot> http://modelingnts.la.asu.edu/
21:24:32 <lambdabot> Title: Geometric Calculus R & D Home Page
21:24:50 <Olathe> Einstein's theory: morality is relative.
21:25:06 <Olathe> Godel's theorem: We don't know anything, maaaannnnnn.
21:25:19 <atp> you need the axiom of choice to choose one sock from an infinite number of pairs, but you don't need it to choose one shoe
21:25:43 * atp paraphrases bertrand russell badly...
21:25:51 <mrd> what if you choose one red sock and one black sock?
21:26:00 <Olathe> mrd: People point and laugh.
21:26:10 <atp> if all the pairs are one red and one black then obviously you don't need AoC
21:26:25 <mrd> ah, proof by intimidation
21:26:40 <Olathe> Yep.
21:26:43 <goalieca> while math people are staring at their socks.. the engineer has already put them on and gotten laid
21:26:44 <Randroid> Finally got GHC on Leopard. What a pain in the ass. Didn't work at all through MacPorts.
21:26:53 <atp> goalieca: engineers get laid?
21:26:53 <mrd> goalieca: false! engineers don't get laid
21:27:03 * atp high fives mrd.
21:27:24 <ddarius> Apparently at one Australian women's college, computer science majors do well for themselves in the getting laid department.
21:27:33 <atp> because they're women?
21:27:36 <ddarius> Mathematician students, not so much.
21:27:48 <oerjan> goalieca: um, shouldn't that require taking the socks off?  i may be confused there.
21:27:48 <ddarius> atp: It was comparative between different majors.
21:28:11 <goalieca> once again you math people have missed the point
21:28:16 <oerjan> well, not strictly required i guess
21:28:37 <atp> if you're a girl, not taking them off is sexy.  if you're a guy... it's a pretty engineer thing to do
21:28:41 * ddarius avoids socks when possible.
21:28:45 <sorear> I sidestep the AoC by rejecting the axiom of infinity.
21:29:01 * atp hugs ZFC.
21:29:04 <Olathe> I sidestep the AoC by not dealing with unrealistic sets.
21:29:11 <ddarius> sorear: That's the way to be.
21:29:32 * atp loves the AoC.
21:29:58 <atp> i like well ordering the reals
21:30:02 * goalieca just assumes everything works because it does.
21:30:09 <Olathe> Naive set theory allows for you to have the set of all sets that don't contain themselves ! Ehh, so ?
21:30:17 * conal loves the Banach-Tarski paradox, so he loves AoC
21:30:24 <atp> i'm with you on that
21:30:41 <mrd> do you well-order your socks every morning?
21:30:58 <atp> of course a cursory read of the proof (specifically the use of the free group in two generators) makes it seem much less paradoxical
21:31:05 <Olathe> I apply the floor function to my socks.
21:31:57 <conal> Olathe: not ceiling?
21:32:05 <conal> watch out for truncate!
21:32:05 <Olathe> Nope.
21:32:10 <Olathe> They don't stick up there.
21:32:17 <conal> the trunk ate my socks
21:32:20 <Olathe> The ceiling function is the floor function.
21:32:26 <Olathe> So, I guess my socks are all integers.
21:32:34 <Olathe> That's actually a nice proof.
21:32:41 <atp> which
21:32:47 <atp> the b-t paradox?
21:32:52 <Olathe> All my socks are integers.
21:32:54 <mrd> at least you have only countably many socks
21:32:56 <atp> ha
21:33:21 <atp> you know, moving back to haskell here, i have to say that fingered 2-3 trees are pretty damn sexy
21:34:50 <sclv> i hear in eastern europe they've got black-market stuff that goes up to fingered 5-6. kinky!
21:34:56 * sclv ducks
21:35:26 * mrd duck hunts
21:36:58 <RayNbow> woah... the Haskell vs Ruby flamewar got more comments :p
21:37:12 <atp> where?
21:37:14 <Olathe> There's a flamewar ?
21:37:20 <atp> everyone knows haskell whoops all over ruby
21:37:24 <Olathe> Lies.
21:37:31 <atp> no, YOU LIE
21:37:34 <RayNbow> http://programming.reddit.com/info/61no8/comments/
21:39:03 <atp> hm, this isn't much of a flamewar.  i was expecting something more slashdotty.
21:39:13 <atp> or usenet in september-y
21:39:39 <sclv> its depressing enough to read comments like "In the real world, real world apps are all IO bound and performance doesn't matter."
21:39:45 <rue> It was more or less civil except the somewhat disingenious "surprise" at the compiled language being faster :P
21:40:07 <rue> The concurrency article vs. Erlang a couple days earlier was really good though
21:40:16 <atp> which was that?
21:40:17 <dons> the real gem is the use of `par`. i'm going to elaborate on that some more.
21:40:30 <dons> i.e. here's the same fib code on a 4 core box,
21:40:31 <dons>     cores   time    cpu %
21:40:31 <dons>   -N 1      111s     99%
21:40:31 <dons>   -N 2       71s    189%
21:40:31 <dons>   -N 3       58s    248%
21:40:33 <dons>   -N 4       54s    300%
21:40:35 <sclv> yeah this is more just a funny tweak about ppl arguing about performance of various hideously slow languages.
21:40:38 <dons> at which point do you think it beats C? :)
21:41:01 <rue> http://cgi.cse.unsw.edu.au/~dons/blog/2007/11/26#no-headaches
21:41:02 <lambdabot> Title: Haskell hacking
21:41:15 <rue> Also courtesy of dons
21:41:34 <atp> you should write more about par dons
21:41:38 <dons> yes!
21:41:52 <dons> i agree. this is really stunning stuff, if you think about it
21:41:57 <atp> functional programming will one day rule the parallel space
21:42:05 <dons> and all space will be parallel :)
21:42:06 <sclv> I want to buy a multiprocessor box just so I can play with par actually.
21:42:18 <sorear> dons: get my @tell?
21:42:20 <newsham> just wait
21:42:26 <newsham> your computers will turn multicore
21:42:29 <atp> you can do it just with multi-cores, can't you?  you don't need smp
21:42:35 <P_D> the graining of pseq isn't quite right.  naive fib can obviously paralleize much better so that you aren't doing whatever it does down at the bottom like fib 3
21:42:47 <dons> sorear: yes, that's right. its been sorted out.
21:43:03 <sorear> I just refreshed your blog page, it's still wrong
21:43:07 <dons> fib n = r `par` (l `pseq` l+r)
21:43:26 <sjanssen> P_D: yeah, I think it needs to switch to straight-line for a certain size of n
21:43:30 <sorear> dons: not what I see here
21:44:06 <dons> yeah, needs a better strategy
21:45:09 <P_D> Does someone here maintain Hoogle?
21:45:18 <sclv> the fancier strategies stuff still feels a bit obscure to me -- seperating the execution order annotations from the functions themselves has an upside in that it lets you play with tweaking settings all in one place, but it seems like it would introduce irritating couplings. I think what would be better are more things like parMap where you have specialized combinators embodying different strategies and you build up your programs from them.
21:45:23 <P_D> Control.Parallel.par is giving me a 404
21:45:42 <sclv> http://haskell.org/ghc/docs/latest/html/libraries/
21:45:49 <P_D> Yeah, I know.
21:46:09 <P_D> I'm just a hoogle whore.
21:46:25 <Olathe> @hoogle whore
21:46:27 <lambdabot> No matches found
21:46:32 <atp> that's not good
21:47:00 <sclv> @where+ libraries http://haskell.org/ghc/docs/latest/html/libraries/
21:47:00 <lambdabot> It is forever etched in my memory.
21:48:16 <hpaste>  sjanssen pasted "parallel fib with a cutoff" at http://hpaste.org/4138
21:51:03 <hpaste>  sjanssen annotated "parallel fib with a cutoff" with "don't repeatedly test the "small" property" at http://hpaste.org/4138#a1
21:52:48 <Olathe> We have printf ?
21:53:30 <Olathe> > printf "omg"
21:53:41 <lambdabot>  Add a type signature
21:53:47 <Olathe> > printf "omg" :: IO ()
21:53:50 <lambdabot>  <IO ()>
21:54:05 <Olathe> > printf "omg" :: IO Int
21:54:08 <lambdabot>  <IO Int>
21:54:16 <Olathe> > printf "omg" :: IO [[[[Char]]]]
21:54:17 <lambdabot>  <IO [[[[Char]]]]>
21:54:20 <Olathe> O-e
21:54:22 <rue> Thwarted
21:55:22 <Olathe> > printf "omg" :: [Char]
21:55:22 <lambdabot>  "omg"
21:55:24 <conal> what's the meaning of printf "omg" :: IO Int  ?
21:55:25 <Olathe> Neat.
21:55:30 <conal> what Int comes out?
21:55:33 <Olathe> conal: No idea.
21:55:50 <conal> i get: omg*** Exception: Prelude.undefined
21:55:57 <Olathe> > printf "omg" :: IO (Maybe [[[[(Char, [[[Int]]])]]]])
21:55:58 <lambdabot>  <IO (Maybe [[[[(Char,[[[Int]]])]]]])>
21:56:40 <Olathe> > printf "amg %d" 5 :: [Char]
21:56:40 <lambdabot>  "amg 5"
21:57:04 <conal> omg*** Exception: Missing "f"
22:00:53 <StaZ|home> hey guys, is there a builtin function that test if a list is an element of another?   ex.  [3, 5] is element of [1..10]  and   [2, 12] is not element of [1..10]
22:01:13 <P_D> what do you mean by element of?
22:01:33 <StaZ|home> well my problem is i don't know what it's called
22:01:41 <P_D> when you say element it evokes notions of sets, but you need to say what the set of a list is
22:01:42 <StaZ|home> my example isn't clear enough ?
22:01:56 <Zao> > elemIndex 3 [42, 3, 5]
22:01:59 <lambdabot>  Just 1
22:02:04 <P_D> well what are all the sets of [1,2,3] in your mind?
22:02:18 <Zao> Nvm. Misread the question.
22:02:28 <StaZ|home> well i want to know if all elements on a list is in another
22:02:31 <P_D> [], [1], [2], [3], [1,2], [2,3], [1,2,3]?  what about [2,1] etc?
22:02:43 <P_D> Ok, that's easy
22:02:51 <StaZ|home> yeah it is
22:02:57 <StaZ|home> just wanna know if a builtin function exist
22:03:09 <P_D> write down the type signature and type it into Hoogle
22:03:27 <StaZ|home> hoogle ? lol
22:03:28 <StaZ|home> ok
22:04:48 <ddarius> @seen dons
22:04:48 <lambdabot> dons is in #ghc, #xmonad and #haskell. I last heard dons speak 20m 42s ago.
22:04:49 <StaZ|home> doesn't look like... i guess that would do  :  all (`elem` list2) list1
22:05:08 <P_D> works for me.
22:05:19 <StaZ|home> i'll bookmark that hoogle, pretty fun stuff
22:05:21 <StaZ|home> thanks :F
22:05:23 <StaZ|home> :D
22:05:29 <P_D> it's the only link I have on my toolbar
22:05:39 <dons> ddarius: ?
22:05:46 <dons> sjanssen: so is the low-n cutoff better?
22:05:55 <sjanssen> dons: yes
22:05:56 <dons> i'm playing on a 4 core box atm, with different things
22:05:58 <ddarius> dons: Since when did you -lurk- reddit?
22:06:03 <dons> ok, i'll add that to the mix, sjanssen
22:06:15 <sjanssen> dons: though a cut off isn't exactly what we want
22:06:45 <P_D> seems like you might be getting into decidability issues to do any better
22:07:09 <P_D> well I guess you are even to go that far.
22:07:31 <sjanssen> dons: what we really want is to only `par` when there are available CPUs
22:07:34 <P_D> But it's still nice to know that you can hand compile code for go faster stripes with out leaving haskell
22:14:04 <dons> > 1 + 2 `par` 3
22:14:06 <lambdabot>  4
22:14:10 <dons> mmm
22:14:30 <blackdog> dons: was curious about your fib code - does ghc actually memoise it so it's equivalent to the linear algorithm?
22:14:34 <dons> nope.
22:14:42 <blackdog> ah. so the responses are full of crap, then :)
22:14:45 <dons> yep
22:15:04 <dons> sjanssen: yeah, the cutoff `par` is the winner
22:15:20 <blackdog> was very funny to see everyone jump on the I CAN WRITE FASTER FIBONACCI MUMMY  bandwagon
22:15:22 <dons> i need more cores though
22:15:26 <sjanssen> dons: I have one more, just a moment
22:15:29 <P_D> MORECORE!
22:15:32 <dons> blackdog: yeah, very few people cared about the `par` magic
22:15:36 <dons> 352%
22:15:43 <dons> for 0..44
22:15:44 <dons> n=44 => 701408733
22:15:45 <dons> ./par +RTS -N4  59.60s user 0.49s system 352% cpu 17.061 total
22:15:49 <dons> rockin.
22:15:58 <blackdog> on a four core cpu?
22:15:58 <dons> C has to have fallen over by then.
22:16:03 <dons> blackdog: yep
22:16:04 <P_D> those are some easy to swallow lies.
22:16:24 <Pseudonym> Yeah, I thought that was odd, too.
22:16:50 <Pseudonym> "There's clearly only one language of choice if you want to implement an unnecessarily inefficient, brain-dead algorithm!"
22:16:52 <dons> so the problem with C is that it lacks an Integer type
22:16:55 <dons> so I can't test it :(
22:17:04 <P_D> doesn't ghc use GMP?
22:17:06 <dons> since i suspect we've beaten C after -N3
22:17:11 <dons> P_D: yeah
22:17:27 <atp> you could use the GMP for C
22:17:43 <atp> i think that's probably as fast as C can make a generic integer type anyway
22:17:49 <dons> yep
22:17:56 <P_D> maybe not for small N
22:17:57 <atp> (i think it's pretty fast)
22:18:11 <hpaste>  sjanssen annotated "parallel fib with a cutoff" with "attempt to saturate all CPUs, without sparking excess jobs" at http://hpaste.org/4138#a2
22:18:15 <P_D> but this is generic anyway.  certainly GMP is the morally right choice for comparison.
22:18:30 <glguy> and my factor solution is still faster than the haskell
22:18:40 <glguy> err
22:18:50 <glguy> wrong window :)
22:18:50 <sjanssen> dons: I think this is faster in general, be sure to change cpus
22:19:02 <dons> change cpus?
22:19:05 <dons> -qw?
22:19:18 <sjanssen> the cpus variable
22:19:18 <P_D> it's a constant in the code.
22:19:19 <dons> ah i see.
22:19:35 <dons> there's the ffi binding for this now in base
22:20:32 <jbalint> hi, i have an error i cant decipher, shown here at the bottom (line #'s are correct) http://rafb.net/p/pPpeTp37.html
22:20:32 <lambdabot> Title: Nopaste - No description
22:20:47 <dons> $ time ./par2 +RTS -N4
22:20:47 <dons> Stack space overflow: current size 8388608 bytes.
22:20:47 <dons> Use `+RTS -Ksize' to increase it.
22:21:09 <sjanssen> jbalint: double check the case of your variable
22:21:34 <jbalint> sjanssen: ah, so simple! thanks alot
22:21:35 <jbalint> :)
22:25:59 <P_D> so, how many people have actually used the fibonacci numbers for non math research?
22:26:03 <P_D> in code.
22:26:34 <thetallguy> P_D: I've used it in graphics
22:26:43 <thetallguy> to draw things like spirals.
22:26:45 <ddarius> P_D: Boehm uses them in ropes.
22:26:52 * P_D nods
22:26:56 <dobblego> ?src liftM2
22:26:56 <lambdabot> liftM2 f m1 m2 = do { x1 <- m1; x2 <- m2; return (f x1 x2) }
22:27:03 <P_D> Is the boehm the guy who wrote the C GC?
22:27:15 <P_D> The boehm.  Boehm.
22:27:16 <notsmack> http://code.haskell.org/XMonadContrib/XMonad/Layout/Spiral.hs  --  fibs in a window manager
22:27:27 <P_D> I used them for a dynamic memory allocator
22:27:30 <dons> P_D: they're used in xmonad :)
22:28:14 <P_D> Splitting a block on fibonacci numbers instead of binary numbers, so that you get only golden ratio proportional wasted space instead of sqrt(2)
22:28:28 <dons> oh, they're used when growing buffers in Data.Binary, iirc
22:28:31 <dons> for similar
22:28:34 <P_D> binary numbers? I mean powers of two
22:30:33 <conal> P_D & dons: is there a particular benefit from phi ratio?
22:30:43 <P_D> it's smaller than two.
22:30:55 <conal> would 1.5 or sqrt 3 do as well?
22:31:18 <conal> lots of numbers are smaller than two
22:31:33 <P_D> Yes, and you can do that, but the fibonacci split is in to two blocks.
22:31:40 <P_D> You can do lagged fibonacci splits
22:31:45 <dons> you get to write fibonacci
22:31:50 <dons> that's the main benefit
22:31:54 <conal> :)
22:32:05 <conal> P_D: oh, splitting.  i can see that.
22:33:32 <sclv> haha firefox is choking to death on the reddit thread even as i'm reading this idiot tell me that no "real world app" has anything beyond io bound performance.
22:33:53 <sorear> define real world app
22:34:00 <P_D> microsoft word
22:34:16 <sorear> so nuclear fusion simulators don't actually exist?
22:34:21 <Olathe> sclv: Heheh
22:34:28 <P_D> correct.
22:34:35 <sorear> I've seen huge amounts of money spent on them
22:34:35 <sclv> apparently "They mostly deal with making money or saving money for some stupid company or another." and "People care about features and how long it will take to deliver those features."
22:34:36 <P_D> and-they are strongly IO bound.
22:34:37 <Olathe> sorear: Quit spreading the rumor !
22:35:14 <P_D> Scientific codes where you have large N anything-cells, particles, whatever-IO bound by memory hierarchy.
22:35:19 <sclv> programmers like him are the reason i'm getting paid to wade through 100s of ks of underperforming absurd code in php just to figure out what its supposed to do.
22:35:32 <dobblego> sclv, like who specifically?
22:35:51 <sclv> this malcontent troll.
22:36:17 <dobblego> I assigned him to the " indefinitely clueless" basket a while ago
22:36:18 <P_D> That's what FFTW's magic is.  Ordering to optimize IO.
22:37:38 <sclv> dobblego: yeah, i'm done being bated.
22:38:07 <dobblego> I'm not sure that his intention; some people are just stupid, I have to accept that with even humanist bone in my body :)
22:40:40 <sclv> patient to doctor: "you gotta help me doc, all my programs are written so they're bound by io." doc to patient: "well, don't do that then."
22:41:14 <Olathe> Heheh
22:42:15 <dobblego> frankly, I'm tired of his abuse of the apostrophe, but I'm a pedant like that
22:42:51 <conal> better call in apostrophe protection services
22:42:57 <conal> (my peeve also)
22:43:05 <dobblego> especiallt the it's/its thing
22:43:08 <dobblego> *especially
22:43:30 <conal> me too
22:49:56 <dobblego> is there any way of generalising liftMX functions?
22:51:28 <Shimei> dobblego: Dependent types maybe?
22:51:39 <byorgey> dobblego: one way is with Applicative Functors.
22:51:52 <dobblego> I thought something like that might do it
22:51:55 <byorgey> I'm surprised conal hasn't said that already. =)
22:52:28 <byorgey> liftMn f x y z ...  is sort of like f <$> x <*> y <*> z <*> ...
22:53:22 <byorgey> modulo the fact that liftMx functions are for monads, and AFs are more general.
22:53:44 <byorgey> but usually when you're using liftMx you're only using the monad as an AF, not as a monad per se.
22:53:47 <olsner> > ((,) <$> (+ 3) <$> chr) 65
22:53:52 <lambdabot>   add an instance declaration for (Num Char)
22:53:57 <Shimei> BTW: Has anyone been frustrated by doing lazy data structures in scheme? I'm having pains because my recursive function calls aren't lazy. Feh.
22:54:02 <olsner> > ((,) <$> (+ 3) <$> (+ 7)) 0
22:54:03 <lambdabot>  Add a type signature
22:54:27 <byorgey> olsner: the second should be <*>
22:55:03 <olsner> > ((,) <$> (+ 3) <*> (+ 7)) 0
22:55:06 <lambdabot>  (3,7)
22:56:09 <olsner> @hoogle (a -> (a,b)) -> a -> [b]
22:56:10 <lambdabot> No matches, try a more general search
22:56:20 <dobblego> ?hoogle (MonadPlus m) => a -> m a -> m a
22:56:21 <lambdabot> Prelude.asTypeOf :: a -> a -> a
22:56:21 <lambdabot> Prelude.const :: a -> b -> a
22:56:21 <lambdabot> Prelude.seq :: a -> b -> b
22:56:30 <dobblego> ?type mplus / return
22:56:32 <lambdabot> forall (m :: * -> *) a. (MonadPlus m, Fractional (m a -> m a -> m a)) => m a -> m a -> m a
22:56:33 <dobblego> ?type mplus . return
22:56:33 <lambdabot> forall (m :: * -> *) a. (MonadPlus m) => a -> m a -> m a
22:58:00 <felzix> Does using parallelism in Haskell require compiler hints or are the compilers just not smart enough yet?
22:58:54 <ddarius> felzix: I don't get that "or", but anyway, "automatic" parallelism is hard (it's not hard to make it parallel, but it hard to do so efficiently)
22:59:23 <conal> byorgey: thanks for filling in for me. :)
22:59:42 <byorgey> conal: no problem =)
22:59:47 <byorgey> conal: how'd I do?
22:59:59 <rue> Threading etc. is easy enough to do, but generally parallelisation means having the *same* task split between several CPUs which is nontrivial
23:00:09 <ddarius> rue: ?
23:00:13 <conal> byorgey: wunnerful
23:00:19 <byorgey> =D
23:00:49 <ddarius> rue: The problem is that threads cost something so most threads need to recoup their costs which requires getting a good granularity.
23:01:20 <conal> here's a piece of code from yesterday's hacking:
23:01:20 <conal>      renderPrimitive Quads $ sequence_ $
23:01:20 <conal>        liftA2 (dim r) [imin .. imax] [jmin .. jmax]
23:01:23 <Beelsebob> @src takeWhile
23:01:23 <lambdabot> takeWhile _ []                 =  []
23:01:23 <lambdabot> takeWhile p (x:xs) | p x       =  x : takeWhile p xs
23:01:23 <lambdabot>                    | otherwise =  []
23:01:50 <conal> the function dim takes three arguments.  I want to iterate over a 2D region of values for the second & third.
23:02:27 <felzix> ddarius: ok, thank you
23:02:48 <conal> and here's another from today, also Applicative:
23:02:50 <conal> redisplay <$> (display <$> ims) <*> pzms <*> (convWG <$> sizes)
23:03:09 <conal> which uses the Applicative instance for DataDriven (time-changing values)
23:03:30 <davidL> @src (<*>)
23:03:30 <lambdabot> Source not found. My pet ferret can type better than you!
23:04:21 <conal> Applicative makes for beautiful, applicative-style programs.
23:05:14 <dobblego> ?hoogle (Monad m) => (a -> b -> c) -> m a -> m b -> m c
23:05:15 <lambdabot> Prelude.flip :: (a -> b -> c) -> b -> a -> c
23:05:27 <conal> that last one is about adaptive computation.  whenever any of the time-varying values ims, pzms, sizes changes, just the dependent computations get updated.
23:05:44 <byorgey> conal: neat
23:06:09 <conal> byorgey: thanks.  i'm stunned sometimes at how beautifully things come out.
23:06:49 <conal> in this example, ims is an image, pzms is pan/zoom for viewing, and sizes is the window size.  all time-varying.
23:06:54 <byorgey> conal: yeah, that's a good feeling, when things come out more beautifully than you expected. =)
23:08:16 <hpaste>  bos pasted "EAN-13 barcode generator" at http://hpaste.org/4139
23:08:18 <conal> byorgey: DataDriven was certainly that way.  it started as some semi-complex machinery.  kept simplifying by re-expressing via Applicative and discovering that existing Applicative instances looked like pieces of my code.  in the end, my code almost vanished.
23:08:29 <conal> as well as being extremely general.
23:09:48 <byorgey> conal: I like how it corresponds so directly to redisplay (display ims) pzms (convWG sizes), which is what you would have if ims, pzms, and sizes were just plain constant values.  (right?)
23:10:06 <conal> byorgey: exactly!
23:10:13 <hpaste>  Sewwardsass pasted "pool table pad" at http://hpaste.org/4140
23:10:50 <conal> byorgey: transparent and efficient.
23:11:36 <conal> i want to use this mechanism for compiling and running code as well.
23:12:07 <byorgey> conal: thanks for sharing the code.  I've understood AFs from a theoretical point of view for a while, but I think I just got a much better idea of the sorts of places I might actually use them.
23:12:20 <conal> :) :)
23:12:22 <byorgey> for things other than just being "cute". =)
23:12:40 <conal> check out this use: let exe = ld <$> (ghc <$> source_code) in exe <*> source_data.
23:13:06 <byorgey> heh, nice
23:13:19 <conal> also, Fran & Pan (animation & imagery) are Applicative.
23:13:25 <byorgey> hm, doesn't that involve IO?
23:13:34 <conal> byorgey: why would they?
23:13:54 <byorgey> I mean ld and ghc
23:14:13 <conal> byorgey: they're pure functions, aren't they?
23:14:36 <byorgey> conal: oh, I guess so, I think I was misinterpreting the purpose of the code.
23:15:28 <conal> byorgey: i'm sort of teasing.  ld & ghc are designed to assume files.  they'd have to be redesigned or adapted.
23:15:54 <dobblego> can liftM3 be written in terms of liftM2?
23:15:58 <conal> i think they can be wrapped to make the whole file thing transparent.
23:16:01 <byorgey> conal: ok, right.  now it makes more sense. =)
23:16:02 <conal> dobblego: yes
23:16:42 <conal> liftM2 f a b `ap` c
23:17:01 <conal> more generally: liftA2 f a b <*> c
23:18:31 <conal> byorgey: the same kind of optimization as in the graphics example would apply to compilation etc.  it's easy to minimize the work done.  much more accurate information than in makefiles, and without the redundant specification that lets makefiles be incorrect.
23:18:58 <byorgey> conal: yeah, I could see that.
23:19:35 <conal> another good Applicative example is UIs, where "UI a" means a UI (widget or composite) that generates a flow of values of type a.
23:19:54 <conal> which i don't think can be done as a monad.
23:20:41 <dobblego> ?type liftM2 f a b `ap` c
23:20:43 <lambdabot> Not in scope: `f'
23:20:43 <lambdabot> Not in scope: `a'
23:20:43 <lambdabot> Not in scope: `b'
23:20:48 <dobblego> ?type \f a b c -> liftM2 f a b `ap` c
23:20:49 <lambdabot> forall a1 a2 a b (m :: * -> *). (Monad m) => (a1 -> a2 -> a -> b) -> m a1 -> m a2 -> m a -> m b
23:21:16 <byorgey> conal: yes, I tried reading your draft paper "Applicative data-driven programming" a while back, but I'm not sure I really got it at the time.  Perhaps I'll go dig it out and give it another read.
23:21:17 <conal> dobblego: if you write out liftM2 in terms of return & ap, you'll see why
23:22:00 <conal> byorgey: do.  it's sort of oddly written.  bottom-up.  i'll get back to it.
23:22:52 <conal> the style of liftMn def i gave works for for n>3 as well.
23:23:48 <Beelsebob> @src ($!)
23:23:48 <lambdabot> Source not found. BOB says:  You seem to have forgotten your passwd, enter another!
23:27:10 <conal> i'm off to bed.  thanks all, for the fun & stimulating chats.
23:27:37 <byorgey> night conal, same to you =)
23:27:49 <conal> :)
23:29:33 <ddarius> Night.
23:35:42 <dons> sjanssen, et al, `par` and 4 cores:
23:35:43 <dons>   http://cgi.cse.unsw.edu.au/~dons/blog/2007/11/29#smoking-4core
23:35:44 <lambdabot> Title: Haskell hacking
23:35:53 <dons> or, how to beat gcc -O3 with enough cores
23:37:49 <dons> there we go, http://programming.reddit.com/info/61p6f/comments/
23:39:21 <olsner> oh, I think I'm gonna get me a quad-core after christmas
23:39:56 <olsner> so I can crunch out those fibonaccis at 350% cpu!
23:40:07 <dons> :)
23:41:45 <olsner> but I don't really need more cpu power at home, cool as it would be :( I barely use this computer for anything except irc and tv series anyway
23:43:50 <wolverian> dons, I'm kind of miffed that ghc doesn't figure out the parallelism automatically.. :)
23:44:14 <ddarius> wolverian: I'm kind of miffed that GHC doesn't write my programs for me.
23:45:08 <dons> wolverian: its an open research topic.
23:45:09 <wolverian> that, too.
23:45:18 <dons> you've got to guess how expensive something is to compute
23:45:22 <wolverian> dons, would parZipWith make sense with fib?
23:45:23 <dons> which is a bit hard
23:45:31 <olsner> Expected behaviour: List of fibonacci numbers printed to console. Actual behaviour: GHC says "File not found"
23:45:34 <dons> wolverian: oh yes, there's probably all sorts of better strategies
23:45:44 <dons> olsner: ?
23:45:52 <olsner> GHC not writing the code itself ;-)
23:46:07 <Olathe> ghc is so lazy in that regard.
23:47:42 <P_D> A whole fib benchmark suite would be cute
23:48:09 <P_D> e.g. closed form floating point version parallelized over a vector
23:48:10 <ddarius> dons: It's been an open research topic (in general) for 50+ years.
23:48:29 <dons> :)
23:48:40 <dons> well, this particular thing, finding `par` annotations, is very active atm.
23:49:18 <P_D> gee
23:49:21 <P_D> Didn't eniac just turn 50?
23:49:42 <P_D> 60.
23:50:00 <Olathe> Those things are still running ?
23:50:04 <olsner> anyhow, off to work I am.. and I think I finally may have found the way to reduce my 6-line function into a foldl
23:50:36 <P_D> Yes, los alamos keeps several around for backwards compatibility.
23:50:45 <Olathe> Heheh
23:50:48 <P_D> nobody can figure out how Neumann's code works...
23:50:49 <olsner> @type until
23:50:52 <lambdabot> forall a. (a -> Bool) -> (a -> a) -> a -> a
23:51:09 <Olathe> They can't write an emulator ?
23:51:27 <P_D> actually ENIAC was reimplemented in silicon.
23:51:48 <wolverian> dons, does your version memoize?
23:51:51 <P_D> For I don't know.  professor with extra money on the grant?
23:52:22 <P_D> Or someone poured too much beer into the cardboard box the grad student was living in
23:52:23 <dons> wolverian: no!
23:52:31 <byorgey> olsner: the easiest way to do that is to post it in #haskell and say, "bet you can't turn this into a foldl".
23:52:40 <wolverian> dons, hmm. :)
23:52:59 <dons> memoisation is no fun. it makes it too fast
23:53:06 <dons> so you can't get those cpus smoking
23:53:17 <olsner> byorgey: yeah, was about to do that, but then it was suddenly 6 hours before alarm clock time and I had to run off to bed
23:53:19 <wolverian> how would it look with memoisation though? or is this in the manual?
23:53:39 <ddarius> byorgey: At which point we'd say, "Why would we want it to be a foldl? Use foldl'/foldr."
23:53:40 <P_D> once you memoize you'll only exercise GMP
23:53:50 <byorgey> olsner: yeah, I was mostly joking =)
23:53:59 <dons> wolverian, oh, just use the list-based zipWith loop
23:54:18 <wolverian> dons, hm, yeah.
23:54:31 <dons> > let fibs = 0 : 1 : zipWith (+) fibs (tail fibs) in fibs !! 45
23:54:45 <lambdabot>  1134903170
23:54:45 <dons> ?bot
23:54:45 <lambdabot> :)
23:54:49 <dons> > let fibs = 0 : 1 : zipWith (+) fibs (tail fibs) in fibs !! 450
23:54:55 <byorgey> I dunno dons, that was pretty slow... ;-)
23:54:56 <lambdabot>  4953967011875066473162524925231604047727791871346061001150551747313593851366...
23:54:57 <P_D> Won't that go N^2?
23:55:04 <dons> > let fibs = 0 : 1 : zipWith (+) fibs (tail fibs) in fibs !! 10000
23:55:11 <lambdabot>  3364476487643178326662161200510754331030214846068006390656476997468008144216...
23:55:14 <byorgey> P_D: nope!
23:55:17 <Olathe> wli had a nice one.
23:55:24 <olsner> byorgey: heh, #haskell is probably the best refactoring tool available for haskell :P
23:55:45 <Olathe> http://haskell.org/haskellwiki/The_Fibonacci_sequence#Fastest_Fib_in_the_West
23:55:45 <lambdabot> http://tinyurl.com/3ynj9f
23:55:53 <byorgey> olsner: yup.  #haskell is haskell's killer app!
23:56:18 <byorgey> why else would I be chatting here at 3am? =P
23:56:29 <dons> i should have posted the redux tomorrow morning, ah well.
23:56:39 <dons> we'll have to let the european guys up mod the `par` stuff :)
23:56:40 <dons>   http://programming.reddit.com/info/61p6f/details
23:56:41 <dons> ;)
23:57:33 <wli> Olathe: I've since devised a faster one.
23:57:45 <Olathe> Oh, cool.
23:58:10 * wolverian has no idea what wli's implementation does 
23:59:18 <olsner> http://www.ese.upenn.edu/~jan/eniac_chip.html <-- the eniac chip includes a Master Programmer!
