00:00:11 <opqdonut> :/
00:00:36 <wli> I just saw a compile taking 25 minutes involving generated C files that gcc required 3GB RAM to process.
00:00:42 <nornagon> "if a diff array is used in a single-threaded style, i.e. after // application the old version is no longer used, a'!'i takes O(1) time"
00:01:07 <nornagon> so I guess I must be saving references to the old array somewhere
00:01:10 <scook0> it still takes *greater* constant time, though
00:01:20 <nornagon> or that :/
00:01:41 <nornagon> i'm getting lookups that take 30% alloc, though
00:02:04 <scook0> lookups taking alloc ... too much laziness?
00:02:21 <scook0> (i.e. storing thunks in the array, instead of values)
00:02:36 <nornagon> hmm
00:02:46 <taruti> UArray perhaps?
00:03:11 <nornagon> my type is DiffArray (Int,Int) Float
00:03:19 <nornagon> will those types work unboxed?
00:04:18 <scook0> yeah, DiffUArray should work for float
00:04:26 <nornagon> okay, cool
00:04:27 <scook0> (index type doesn't matter for unboxing)
00:04:29 <nornagon> that helped a lot
00:04:41 <nornagon> alloc on lookups down from 30% to 3.5%
00:04:49 <nornagon> time from 30-40% to 0%
00:04:59 <scook0> the other option would have been to seq before writing
00:05:05 <scook0> but unboxed arrays give you that for free
00:05:17 <nornagon> now all my alloc and %time is coming from my random number generation functions O_o
00:05:32 <scook0> nornagon: which is where it was probably coming from anyway
00:05:44 <nornagon> quite possibly
00:06:07 <opqdonut> nornagon: what rng are you using?
00:06:21 <nornagon> whatever comes with getStdGen :: IO StdGen
00:06:34 <nornagon> i have a few wrappers around it, though
00:06:47 <opqdonut> you might want to implement your own rng
00:06:51 <nornagon> mm
00:06:54 <opqdonut> linear feedback should be pretty fast for example
00:06:58 <nornagon> mersenne twisters are tasty :)
00:07:09 <opqdonut> and knuth gives some good constants for that
00:07:14 <opqdonut> yeah mt is supposed to be fast too
00:07:17 <opqdonut> dunno how fast
00:07:21 <nornagon> it's very fast
00:07:27 <opqdonut> ok :)
00:07:33 <nornagon> i have experience with it from my work on the NDS
00:07:37 <opqdonut> ah, feedback shift register -based
00:07:55 <nornagon> and it is possible to get it down to almost negligible time with a few sacrifices in randomness
00:08:14 <hpaste>  nornagon pasted "my random range function in the State monad" at http://hpaste.org/2362
00:08:36 <nornagon> is that likely to be the cause of the alloc?
00:09:18 <scook0> as an aside, if you're doing lots of random stuff, it might be worth investigating a proper MonadRandom typeclass
00:09:27 <scook0> (I think there's some stuff on the wiki)
00:09:44 <nornagon> I sort of hacked my own up... it's really just a wrapper around State, though.
00:09:52 <nornagon> type GenState a = State StdGen a
00:11:00 <wli> Hmm, what's a good recurrence for (10^(10^(n+1))-1) `div` (10^(10^n)-1)
00:13:32 <DRMacIver>  Morning
00:18:04 <nornagon> Is there an easy way to convert a DiffUArray to a straight Array? After generation, the lookup operation is far more common than the modify operation
00:19:45 <paolino> I have a function p2 ::(ArrowXml a) => Parser [a XmlTree XmlTree], how do I get out the arrow ?
00:21:07 <scook0> nornagon: you should just be able to do (fromList . toList) or similar
00:21:24 <scook0> it'll be O(n), of course, but that can't be helped
00:21:28 <nornagon> *nod*
00:21:33 <nornagon> it's okay, only need to do it once
00:22:05 <scook0> the other option is to do construction with a mutable array, and then use freeze (which is what I ended up doing)
00:22:24 <scook0> it depends on how you want to write your generation code
00:22:38 <paolino> I tried runX $ constL (either (const []) id . parse p2 "" $ "a") <<< xread <<<constA "<a></a>"
00:23:11 <dons> sorear: thanks for pointing out the evilness on these dodgy array ideas on the mailing list
00:23:11 <lambdabot> dons: You have 1 new message. '/msg lambdabot @messages' to read it.
00:23:38 <sorear> dons: Yeah, I was worried five-nines might be good enough for Bulat :)
00:24:03 <dons> sorear: :(
00:24:06 <paolino> but I get     Ambiguous type variable `a' in the constraint:
00:27:44 <paolino> shouldn't runX take off the ambiguity ?
00:29:28 <hpaste>  steven_ashley pasted "System.Posix.IO troubles " at http://hpaste.org/2363
00:36:38 <scodil> is there a version of hoogle that indexes everything ghc ships with?
00:39:33 <tuomov> Is there a nice way to have type-dependent data?
00:40:02 <tuomov> Some examples in the standard libraries simply seem to define 'the parameter is not used', but that's ugly.
00:40:17 <DRMacIver> int-e++
00:40:34 <tuomov> (as in: class Storable a where sizeOf :: a -> Int)
00:40:35 <DRMacIver> (I really like his solution to my regexp problem)
00:41:27 <scodil> tuomov, you mean you don't like "sizeOf _ = 8" ?
00:41:30 <sorear> tuomov: agreed, but nobody's come up with a better approach.  We've had lots of worse ones though.
00:41:45 <tuomov> scodil: no, it can't be checked to terminate at compile time
00:41:46 <sorear> scodil: no, that's instance syntax
00:42:48 <scodil> ah. and btw... what was that dodgy array fine-nines thing? do you have a link to that thread?
00:44:27 <dons> http://cufp.galois.com/2007Schedule.html
00:44:28 <sorear> scodil: going on right now in -cafe, if you have a mailreader
00:44:28 <lambdabot> Title: Commercial Users of Functional Programming 2007 Program
00:44:39 <dons> hey tuomov!
00:45:12 <dons> tuomov: yeah, there's some new things like GADTs that make the type dependencies a bit easier
00:45:18 <sorear> scodil: http://haskell.org/pipermail/haskell-cafe/2007-August/index.html
00:45:19 <lambdabot> Title: The Haskell-Cafe August 2007 Archive by thread
00:45:28 <sorear> er, http://haskell.org/pipermail/haskell-cafe/2007-August/030799.html
00:45:29 <lambdabot> Title: [Haskell-cafe] How can I pass IOUArrays to FFI functions?
00:45:45 <phr_> it's in germany?  booh.
00:46:08 <sorear> where else would we put it?  France?
00:46:25 <phr_> berkeley
00:46:41 <dons> phr_: it alternates between the US and Europe.
00:46:52 <dons> between untyped and typed :)
00:46:55 <phr_> hee
00:46:59 <tuomov> dons: I was just wondering if GADTs would help, but it's been ages since I looked into that stuff
00:47:11 <phr_> ic i guess i wasn't into this stuff a year ago
00:47:15 <phr_> where's the next one?
00:47:26 <tuomov> class Foo a where bar :: (Int, a) seems a bit cleaner than bar :: a -> Int, and it seems to work, though
00:47:26 <dons> next Sept. not sure where though.
00:47:36 <phr_> i'm missing crypto 2007 right now
00:47:59 <dons> tuomov: yeah, you might be able to play some tricks with GADTs or type families
00:48:05 <dons> to index the type for bar based on the type
00:48:28 <dons> class Foo a where bar :: b ; instance Foo Int where bar :: Int
00:48:33 <dons> -- type family stuff in ghc head
00:48:38 <phr_> holy crap this is expensive
00:48:41 <dons> type bar :: Int , I mean
00:48:59 <sorear> type Bar = Int
00:49:19 <dons> that's it.
00:49:38 * sorear doesn't think GADTs are the answer to what tuomov was trying to ask
00:49:58 <dons> no, so you want to get a particular value of 'bar' based on the type?
00:50:04 <tuomov> yep
00:50:32 <tuomov> just like e.g. sizeOf of Storable, but without the uglyness of dummy variables
00:50:36 <dons> yeah, bar will need the type parameter to be able to resolve which value you need. right.
00:50:49 <phr_> type family = dependent types almost ... ?
00:50:53 <dons> phr_: yeah
00:51:06 <scodil> what's up with hoogle? I got no results for notMember
00:51:09 <dons> GADTs + type families =~ hard stuff
00:51:13 <dons> ?index notMember
00:51:13 <lambdabot> bzzt
00:51:18 <dons> scodil: from what type?
00:51:25 <dons> ?userrs
00:51:26 <lambdabot> Maximum users seen in #haskell: 411, currently: 372 (90.5%), active: 15 (4.0%)
00:51:50 <scodil> what do you mean what type?
00:52:07 <sorear> phr_: Type families are an essential part of dependant goodness, but they don't solve the whole problem
00:52:09 <nornagon> :t seq
00:52:12 <lambdabot> forall a t. a -> t -> t
00:52:13 <dons> scodil: notMember :: Set ?
00:52:14 <tuomov> at least with   bar :: (Int, a)  intead of   bar :: a -> Int  one should be able to make termination guarantees, although it's still ugly..
00:52:27 <scodil> yeah but why does that matter?
00:52:30 <scodil> ?index member
00:52:30 <lambdabot> Data.IntMap, Data.IntSet, Data.Map, Data.Set
00:52:34 <scodil> ?index notMember
00:52:35 <lambdabot> bzzt
00:52:44 <dons> :t maxBound
00:52:46 <lambdabot> forall a. (Bounded a) => a
00:52:51 <sorear> phr_: You still can't create a type  RecursiveFunction :: (Int -> Int) -> *, like you can in (eg) coq
00:52:51 <dons> :t fromEnum . maxBound
00:52:53 <lambdabot> forall b a. (Enum b, Bounded (a -> b)) => a -> Int
00:52:55 <tuomov> compile-time verification matters..
00:53:14 <dons> Id' probably be happy with  :: a -> Int
00:53:50 <sorear> tuomov: oleg et al use a type 'data Proxy a = Proxy' with functions 'proxy (_::a) :: Proxy a = Proxy' and 'sizeOf :: Storable a => Proxy a -> Int'
00:53:52 <tuomov> hmm... or would these whatwerethey function-whatever types help?
00:54:04 <tuomov> So you'd have a special type for the size, which would be convertible to integer?
00:54:08 <sorear> tuomov: that way, you never pass undefined except to known functuions
00:54:13 <phr_> is there some reason GADT's can't be printed?  i keep asking that and no one lets onto anything
00:54:20 <dons> Pseudonym: you really need to get your little modules onto hackage
00:54:27 <sorear> tuomov: and known functions can be proven lazy easier
00:54:28 <dons> Pseudonym: shall I send you a copy of mkcabal ? :)
00:54:29 <sorear> phr_: No.
00:54:37 <sorear> phr_: It is documented, really!
00:55:49 <nornagon> fromIntegral is taking up nearly 8% alloc :-(
00:55:52 <phr_> i saw something in the docs saying you can't use Show unless it's also a haskell 98 type
00:55:57 <Pseudonym> Sorry, which ones?
00:56:10 <sorear> phr_: You cannot use a deriving clause for a GADT; only for an ordianary data type.
00:56:11 <Pseudonym> You can if you want, but it seems a lot of work for one module.
00:56:21 <phr_> yeah i'm wondering what the reason for that is, if there is one
00:56:22 <Pseudonym> When I can just point people to darcs instead. :-)
00:56:32 <phr_> i don't understand why showability isn't the default
00:57:05 <sorear> phr_: Because you can write the instance yourself.
00:57:06 <tuomov> sorear: yeah, that might work too. I was wondering if functional dependencies could be useful also?
00:57:17 <sorear> tuomov: I doubt it.
00:57:21 <phr_> well i can always do that, but why make it hard?
00:57:38 <sorear> phr_: Because making it easy would be harder.
00:57:45 <sorear> phr_: There are only two Simons.
00:57:46 <tuomov> but better not use fancy features when not necessary..
00:58:10 <Pseudonym> Anyway, must away.
00:58:11 <Pseudonym> Nytol!
00:58:26 * sorear should probably just have said 'Lack of human resources' and left it at that.
00:59:13 <phr_> ok, so it's just an implementation limitation that may get fixed someday
00:59:17 <phr_> that's a reasonable answer
01:00:25 <phr_> good gadt paper http://64.233.167.104/search?q=cache:BoevndusDpoJ:www.informatik.uni-bonn.de/~ralf/publications/SYB1.pdf+gadt+%22deriving+show%22&hl=en&ct=clnk&cd=46&gl=us&client=firefox-a
01:00:26 <lambdabot> http://tinyurl.com/39ltxo
01:00:31 <phr_> googleized pdf ;)
01:08:54 <hpaste>  paolino pasted "hxt / parsec problem" at http://hpaste.org/2364
01:10:13 <DRMacIver> Hm. Presumably int-e's Trie implementations (in http://hpaste.org/2341#a3 ) could be generated by some sort of SYB/Uniplate/Drift/etc. approach from any datatype?
01:10:46 <DRMacIver> (Perhaps with special cases for the integral types and enums)
01:11:06 <paolino> someone can help me make that code compile and run , please ?
01:13:14 <DRMacIver> I have a hard enough time getting my own code to compile and run. :) What I always find useful when trying to debug confusing type errors is to add type signatures to things until the errors get less confusing.
01:13:54 <DRMacIver> Eventually either the compiler tells you "Nuh uh! That type signature is wrong!" or the more specific information reduces the level of bizarre inferencing to the point where you can actually understand what it means.
01:14:41 <DRMacIver> For example, what type do you expect childNameP to have?
01:15:53 <kilimanjaro> String -> Bool ?
01:16:13 <paolino> it's a parser lile p2
01:16:16 <paolino> like
01:16:37 <paolino> Parser (a XmlTree XmlTree)
01:17:07 <DRMacIver> Now, what happens to the evil confusing type error when you add that type signature like I suggested? :)
01:18:14 <DRMacIver> Oh, not much.
01:18:17 <DRMacIver> I just mistyped the first time.
01:18:19 * DRMacIver kicks self.
01:18:27 <DRMacIver> Sorry. :)
01:18:55 <steven_ashley> lol
01:19:03 <DRMacIver> Anyway, I don't understand the specific error you're getting, so I'll shut up now.
01:19:16 <paolino> nodeNameP,childNameP ::(ArrowXml a) => Parser (a XmlTree XmlTree)
01:19:25 <paolino> is the right one I think
01:22:35 <fasta> Is showing one line of lenght l slower than two of l/2 for sufficiently large l on the terminal?
01:22:56 <sorear> "the terminal" = ?
01:23:00 <hpaste>  paolino annotated "hxt / parsec problem" with "with typesig" at http://hpaste.org/2364#a1
01:23:07 <fasta> sorear: gnome-terminal
01:23:25 <sorear> gnome-terminal shows lines?  I thought it just showed letters...
01:23:28 <sorear> probably not
01:23:35 <fasta> sorear: Emacs at least seems to have problems with it.
01:24:28 <olsner> gnome-terminal is pretty slow at rendering text, in my experience...
01:24:41 <paolino> now it compiles, but runtest expose a ambiguity which I suppose comes from an extra layer of arrows or something ...
01:24:44 <fasta> olsner: it's about 4 times slower than xterm from my experience
01:25:01 <fasta> olsner: but they don't do the same.
01:25:08 <fasta> olsner: so, it's rather pointless to compare.
01:25:49 <olsner> (I haven't found any useful features in gnome-terminal over xterm, though)
01:26:00 <tuomov> yeah, xterm does what's needed; gnome-terminal spends cycles for useless bells and whistles
01:26:05 <scodil> are there any haskell libraries that read id3 tags?
01:26:26 * shachaf uses urxvt.
01:26:36 <fasta> olsner: gnome-terminal has a scroll bar
01:26:38 <tuomov> now that's full of bells and whistles too..
01:26:42 <earthy> scodil: I'd imagine hmp3 comes with an id3 tag reader
01:26:43 <shachaf> fasta: So does xterm.
01:26:46 <fasta> olsner: it has readable fonts
01:26:56 <tuomov> rotflmao
01:27:03 <tuomov> blurry shit
01:27:06 <fasta> olsner: I think xft fonts
01:27:10 <paolino> scodil : catenova.org:~phas has one, don't know if it works
01:27:10 <scodil> earthy: I looked at it appears to just read the output from mpg123. right? dons?
01:27:12 <tuomov> exactly, xft shit
01:27:23 <tuomov> won't touch anything infected with it, if I don't have to
01:27:37 <fasta> tuomov: post your xterm configuration to hpaste, and I might switch.
01:27:58 <evir> Xft really hurts my eyes.
01:28:00 <fasta> vanilla xterm is not for me, in any case.
01:28:14 <evir> Subpixel rendering as well as normal antialiasing.
01:28:28 <nornagon> I use xterm all the time :)
01:28:32 <dons> scodil: pretty sure there are bindings to libid3 somewhere. -- though its also not too hide to do that yourself.
01:28:36 <olsner> anyways, if terminal output slows you down, output to file instead ;-)
01:28:38 <tuomov> Xft configuration hurts my eyes just as much as the default settings
01:28:40 <shachaf> Is there any advantage to xterm over urxvt?
01:28:45 <dons> i use urxvt
01:28:49 <dons> it resizes way better
01:28:50 <tuomov> well, fontconfig, but same thing really
01:28:57 <dons> no flicky refresh when retiling
01:29:06 <jql> xterm has advantages?
01:29:14 <evir> urxvt has a better visual bell. :-)
01:29:26 <tuomov> I don't like the perl shit in urxvt these days, and have always preferred the "feel" of xterm
01:29:26 <evir> The visual bell of xterm flickers so fast that I do not notice it.
01:29:36 <tuomov> somehow *rxvt feel more clunkier
01:29:52 <evir> I am still looking for something like a global visual bell. That just blinks the whole X screen instead of belling.
01:29:56 <nornagon> urxvt has the advantage of glyph scavenging
01:29:56 <tuomov> a bit like the differences in page loading of browsers, with others showing the page immediately and adjusting it, and others waiting a bit
01:30:02 <tuomov> xterm being more like the latter
01:30:07 <dons> tuomov: don't you find it a pain to resize a xterm and lose text?
01:30:11 <nornagon> I like to use neep alt, but it doesn't have japanese characters
01:30:20 <tuomov> dons: I don't resize..
01:30:41 <dons> fair enough
01:31:01 * paolino starts desparationing
01:31:11 <shachaf> evir: Try visualBellDelay, maybe?
01:31:39 <evir> shachaf: Uh. :-) But I am quite happy with urxvt now since years.
01:31:46 <shachaf> "Number of milliseconds to delay when displaying a visual bell.  Default is 100.  If set to zero, no visual bell is displayed.  This is useful for very slow displays, e.g., an LCD display on a laptop."
01:31:52 <paolino> dons, can you solve my code ambiguity, please
01:34:36 <jacquesmerde> how long until ghc 6.6.1 plays better with the current gcc?
01:34:54 <fasta> jacquesmerde: probably never
01:35:31 <fasta> jacquesmerde: if you meant ghc, however, than it will probably be head or 6.8 when it is released.
01:36:00 <jacquesmerde> fasta: huh?
01:36:16 <fasta> jacquesmerde: you asked for ghc 6.6.1 specifically
01:36:29 <jacquesmerde> fasta: oh, sorry. yeah, ghc in general
01:36:58 <hpaste>  steven_ashley annotated "System.Posix.IO troubles " with "Posix troubles" at http://hpaste.org/2363#a1
01:37:00 <fasta> jacquesmerde: if you have any problem just download a nightly build
01:37:52 <DRMacIver> Then you can have an entirely *different* set of problems. ;)
01:37:57 <jacquesmerde> fasta: about how long until 6.8 is released? we're trying to work out what to do with the archlinux package for ghc. we're currently still at 6.6, wondering whether to move to 6.6.1 with larger binaries or wait for 6.
01:38:00 <jacquesmerde> 6.8
01:38:15 <steven_ashley> could someone have a look at that last paste for me? I
01:38:49 <fasta> jacquesmerde: I don't think any serious user is still using 6.6.
01:39:06 <wli> Wow, this is not going well. Something's probably wrong with my DSL modem.
01:39:08 <fasta> jacquesmerde: you should release packages on the day of a release.
01:39:28 <wli> Well, those who insist on Debian -packaged affairs are still on 6.6.1
01:39:34 <paolino> ... I think I got it .....
01:39:35 <fasta> jacquesmerde: otherwise, your users will need to work around it by downloading a nightly build for themselves.
01:39:38 * evir is using 6.6 from Debian Etch.
01:39:55 <evir> Is there any killer-reason why I shouldn't?
01:39:59 <fasta> wli: yes, by 6.6, I meant 6.6, not 6.6.1
01:40:23 <fasta> evir: apparently not
01:40:28 <steven_ashley> should ghc -v show the .1 ?
01:40:41 <fasta> evir: for me there are tons of reasons that I cannot even use 6.6.1
01:41:00 <fasta> 6.8 will be a much better release, imho.
01:41:00 <steven_ashley> $ ghc -v "Glasgow Haskell Compiler, Version 6.6, for Haskell 98, compiled by GHC version 6.6"
01:41:01 <wli> Ugh, it's apparently 10 being a 10^n-th root of unity mod p not merely a 10^n-th power residue.
01:41:25 <evir> fasta: Well, I will certainly try out 6.8.
01:41:29 <wli> I wonder what happened to ghc-cvs.
01:42:06 <fasta> jacquesmerde: september has been mentioned, but you shouldn't ask me. You should talk to Igloo if you want to know.
01:42:16 <wli> It's not obvious how to determine 10^n-th roots.
01:42:22 <fasta> evir: it hasn't been released yet.
01:42:28 <evir> fasta: I know.
01:42:52 <jacquesmerde> fasta: guess we'll stick with 6.6 until 6.8 then
01:43:30 <jacquesmerde> (6.6.0 that is)
01:44:03 <jacquesmerde> or 6.6.1 with split=no
01:44:46 <fasta> jacquesmerde: do you know of Arch users on 6.6?
01:44:52 <fasta> jacquesmerde: do you have statistics?
01:45:03 <jacquesmerde> fasta: i'm not the right person to ask...
01:45:08 <jacquesmerde> gour?
01:45:23 <gour> jacquesmerde: hi
01:45:29 <fasta> I am surprised Arch still exists.
01:45:46 <gour> fasta: i'm surprised gentoo still exists :-)
02:16:33 <wli> Hmm.
02:16:50 <roconnor> mmm
02:17:15 <steven_ashley> aaa
02:17:36 <dons> ?userrs
02:17:37 <lambdabot> Maximum users seen in #haskell: 411, currently: 378 (92.0%), active: 8 (2.1%)
02:18:17 <roconnor> dons: is there any harm in registering for the hackathon, even if it turns out I cannot make it?
02:18:47 <paolino> mmhh, folding (>>>) is dangerous with infixl operators around
02:18:51 <dons> roconnor: no, that's fine. perhaps on the website note your tentative nature.
02:18:57 <dons> roconnor: but this time we have a lot of room, so its fine
02:19:15 <dons> roconnor: you think you'll be able to make it?
02:19:23 <roconnor> I will have to stop randomizing my MAC address.
02:19:35 <roconnor> dons: I think I would like too, but I don't know when I'm teaching yet.
02:19:40 <roconnor> well TAing
02:19:44 <dons> ah ok. its over the weekend mostly
02:19:51 <roconnor> oh
02:20:00 <roconnor> I thought it was thrusday friday saturday.
02:20:06 <dons> ah yes, you're right.
02:20:18 <dons> don't mind me, i'm just helping organising it :)
02:20:24 <roconnor> :P
02:20:29 <dons> Fri/Sat/Sun actually
02:20:36 <roconnor> oh is it?
02:20:38 <dons> http://www.haskell.org/haskellwiki/Hac_2007_II#Dates
02:20:39 <roconnor> that's helpful
02:20:40 <lambdabot> Title: Hac 2007 II - HaskellWiki
02:21:14 <roconnor> ah, good.
02:21:37 <dons> you just need a laptop, and beer money :)
02:21:55 <roconnor> and a static MAC address :)
02:22:04 <dons> and that  :)
02:22:09 <roconnor> I suppose I can use the one written on the bottom of my laptop
02:22:34 <dons> depending on the room, you might just be able to connect -- we're not sure there's a fixed access list
02:22:45 <dons> but its useful to have a list of addresses just in case we do need them
02:23:33 <roconnor> iface eth1 inet dhcp
02:23:33 <roconnor>   pre-up ifconfig eth1 hw ether `head -c 5 /dev/urandom | xxd -g 1 -u | cut -d '
02:23:33 <roconnor>  ' -f 2-6 | sed "s/ /:/g;s/^/00:/"`
02:23:33 <roconnor>   pre-up iwconfig eth1 nick `/usr/games/fortune  | head -1 | sed "s/[^a-zA-Z]/ /
02:23:33 <roconnor> g;s/^ *//g;s/I //g" | cut -d " " -f 1`
02:24:34 <roconnor> whoa, I don't even remember randomizing my nick
02:25:14 <sorear> what's the point of a random mac?
02:26:09 <roconnor> sorear: one could use it to help disguise oneself when you are hijacking people's networks.
02:26:24 <dons> who else knew that ABN AMRO used Haskell?
02:26:31 <roconnor> sorear: or maybe one just doesn't want cafe's correlating your network traffic.
02:26:45 <sorear> ah.
02:26:47 <roconnor> dons: sweet, can I work for them?
02:27:05 <dons> and did anyone else see the email from barclays bank on ghc-users@?
02:27:23 <dons> they're obviously up to something, anyway
02:29:19 <roconnor> they should hire me.  I can optimize portfolios in 66 lines :)
02:30:01 <dons> :)
02:30:15 <dons> monte carlo simulations too eh. hmm, i wonder if they've read the paper on monte carlo in haskell
02:30:24 <dons> it even talks about trading simulations
02:32:29 * osfameron used a List Monad yesterday!
02:32:46 <dons> woot! osfameron enters level 4 lambda hacker!
02:32:47 <osfameron> is there already a function for:  guard True = [1]; guard Flase = []  ?
02:33:18 <osfameron> dons: nah, level 1.5 cargo cult lambda wannabe :-)  but it made sense at the time at least
02:33:20 <dons> hmm. don't think so. it looks weird.
02:33:25 <dons> cool :)
02:33:52 * wli doesn't know the Malliavin calculus. :(
02:33:55 <paolino> is it possible to change fixity for an operator in the importing module ?
02:34:34 <paolino> from infixl to infixr ?
02:35:43 <steven_ashley> paolino: create a new operator?
02:36:22 <paolino> <</ = </
02:36:24 <wli> I'm curious as to why banks would be so interested in Haskell programmers.
02:36:29 <shachaf> paolino: import Module hiding ((+)); import qualified Module; infixr n +; (+) :: ...; (+) = ...
02:36:56 <shachaf> paolino: That's the best way, as far as I know.
02:36:58 <tuomov> isn't it obvious? That's one place they really care about bug-free code
02:37:02 <paolino> ok
02:37:36 <wli> tuomov: There are lots of places where bug-free code matters and few of them have the remotest interest in VHLL's/FPL's/etc.
02:37:39 <tuomov> I wouldn't use a shoddy perl hack if I were a bank..
02:38:22 <wli> So, of all the places where bug-free code matters, why are banks taking such an interest?
02:38:43 <osfameron> although apparently a lot of banks use Perl too (probly mainly for glue)
02:38:46 <tuomov> the right people have infiltrated them?-)
02:38:58 <doserj> because they typically emply "mathy" people :)
02:38:59 <eivuokko> Banks don't take interest in it;  The stress bugs cause to software developers who make programs that are used to handle big sums of money - they care.
02:39:19 <wli> I find doserj's explanation most plausible.
02:39:40 <steven_ashley> dons: is hGetContents / hPutStr known to behave strangely with Posix.createPipe? I am creating a pipe and using fdToHandle on the returned handles. Using 6.6.1
02:40:52 <roconnor> pfft, ABN should be using Coq :)
02:42:27 <eivuokko> Hrm;  I find it confusing that all ran on empty list is True and not error.
02:42:56 <roconnor> eivuokko: that is called vaculously true
02:42:58 <wli> all _ [] is vacuously true.
02:43:05 <roconnor> vacuously
02:43:11 <roconnor> thanks for the spelling wli
02:43:16 <dons> steven_ashley: well, its lazy. you might have issues with closing handles before reading
02:43:30 <paolino> shachaf: how do I refer to the qualified old operator ?
02:43:37 <dons> steven_ashley: there's some strict io stuff with createPipe in hmp3, iriirc
02:43:39 <dons> ?where hmp3
02:43:40 <lambdabot> http://www.cse.unsw.edu.au/~dons/hmp3.html
02:44:03 <eivuokko> roconnor, wli, Thanks; That's a new word for me.  It still confuses me :)  I expected my quickCheck property to fail.
02:44:20 <wli> Hmm, there's a mapAccumL in here.
02:44:49 <steven_ashley> thanks :)
02:45:05 <paolino> shachaf: (</) = Text.XML.HXT.Arrow.(</) is interpreted as a Data constructor
02:45:08 <doserj> eivuokko: you want all (xs++ys) == all xs && all ys
02:45:11 <roconnor> eivuokko: forall is a fold of &&, and True is the identity element for &&.
02:45:13 <wli> No, scanl
02:46:11 <wli> Set.toList I think returns the set members in ascending order.
02:46:48 <DRMacIver> It does, but you should probably use Set.toAscList if you want to guarantee that behaviour. :)
02:46:56 <wli> Sounds good to me.
02:50:38 <DRMacIver> int-e: Thanks for the regexp solution.
02:50:39 <wli> I basically have a nonempty list of exponents to raise things to and want to scanl to get things raised to all the different exponents.
02:50:55 <int-e> DRMacIver: glad you like it :)
02:51:24 <wli> (differencing them first, of course)
02:51:33 <eivuokko> roconnor, I am not sure I understand the thought in that.  To me (&&) and (:) are not similary typed/assosiated, and I don't see how folding could say anything about mapping identities;   But maybe I misunderstood your point or just don't know some (basic) stuff.
02:51:51 <DRMacIver> int-e: I was wondering if one could generate the trie structures using some sort of SYB/Uniplate/whatever approach.
02:52:15 <roconnor> eivuokko: fold often (but not always) take an operation plus it's identity element.
02:52:19 <roconnor> @src all
02:52:19 <lambdabot> all p =  and . map p
02:52:25 <roconnor> @src and
02:52:26 <lambdabot> and   =  foldr (&&) True
02:52:29 <roconnor> @src or
02:52:29 <lambdabot> or    =  foldr (||) False
02:52:33 <roconnor> @src sum
02:52:34 <lambdabot> sum = foldl (+) 0
02:52:39 <roconnor> @src product
02:52:39 <lambdabot> product = foldl (*) 1
02:53:02 <roconnor> all these folds are on binary operations and their corresponding identity elements.
02:54:16 <wli> I wonder why the stock ones don't use divide-and-conquer strategies.
02:54:48 <eivuokko> roconnor, Hmm.  And vacously means that specification adds corner case mapping?
02:55:05 <wli> (basically, pair successive elements and operate until the list is reduced to length 1)
02:55:32 <doserj> wli: what would be the gain?
02:55:42 <paolino> how do I write qualified operators ?
02:55:44 <wli> doserj: It seems to run faster.
02:55:45 <roconnor> eivuokko: vacuous sastifaction is the term mathematicians use for when something is true forall x by virtute of there not being any x's.
02:55:47 <int-e> DRMacIver: Possibly. I haven't given it much thought. I'm planning to read the generalizing generalized tries paper first.
02:55:55 <eivuokko> roconnor, Ah!
02:55:55 <DRMacIver> ok. :)
02:56:01 <eivuokko> roconnor, Thanks!
02:57:22 <roconnor> After filing bug reports, does anyone else get that, ``what now'' feeling?
02:57:39 <int-e> DRMacIver: it should be possible to make 'Lookup trie key | trie -> key' and 'Populate trie key | trie -> key' type classes with some automatic deriving at the very least.
02:57:51 <int-e> DRMacIver: but I'm hoping for something simpler.
02:58:09 <DRMacIver> int-e: Yeah. Let me know if you think of anything. :)
02:58:24 * DRMacIver will add it to his "things to think about" list, but wants to finish off the regexp stuff before he looks further afield.
02:58:48 <sorear> wli: The reason is that it is impossible to add an argument like forall a b c, (a `op` b) `op` c = a `op` (b `op` c)   to a Haskell function :)
02:59:18 <osfameron> @pl let guard x = filter id [x]
02:59:18 <lambdabot> (line 1, column 28):
02:59:19 <lambdabot> unexpected end of input
02:59:19 <lambdabot> expecting variable, "(", operator, ";" or "in"
02:59:25 <osfameron> @pl guard x = filter id [x]
02:59:25 <lambdabot> guard = filter id . return
02:59:35 <osfameron> oooo!
02:59:44 <Igloo> dons: You know #haskell predates 2001, right?
02:59:49 <roconnor> @src guard
02:59:49 <lambdabot> guard True  =  return ()
02:59:49 <lambdabot> guard False =  mzero
02:59:59 <osfameron> @where guard
02:59:59 <lambdabot> I know nothing about guard.
03:00:02 <osfameron> meh
03:00:31 <roconnor> > guard =<< [Ture,False,False,True,False]
03:00:32 <lambdabot>   Not in scope: data constructor `Ture'
03:00:37 <roconnor> > guard =<< [True,False,False,True,False]
03:00:39 <lambdabot>  [(),()]
03:00:48 <osfameron> @index guard
03:00:49 <lambdabot> Control.Monad, Control.Monad.Reader, Control.Monad.Writer, Control.Monad.State, Control.Monad.RWS, Control.Monad.Identity, Control.Monad.Cont, Control.Monad.Error, Control.Monad.List
03:01:54 <osfameron> does that work the same way as [whatever] vs [] in a List Monad do ?
03:02:14 <roconnor> osfameron: I don't know what you mean.
03:02:35 <osfameron> roconnor: I defined guard True = [1]; guard False = []
03:02:57 <osfameron> roconnor: and can then use:   guard <<expression>> in a do-block to use it like a comprehension guard
03:03:16 <roconnor> > guard True
03:03:17 <lambdabot>   add an instance declaration for (Show (m ()))
03:03:17 <osfameron> (which was a trick from the "Monads in 15 minutes" blog article)
03:03:25 <roconnor> > guard True :: [()]
03:03:26 <lambdabot>  [()]
03:03:31 <roconnor> > guard False :: [()]
03:03:33 <lambdabot>  []
03:03:46 <roconnor> guard True = [()] and guard False = []
03:03:49 <dons> Igloo: yeah, but not a shapr-run #haskell with logs
03:03:50 <osfameron> how did you know to add :: [()] to it?
03:03:57 <roconnor> @type guard
03:03:59 <lambdabot> forall (m :: * -> *). (MonadPlus m) => Bool -> m ()
03:04:01 <dons> Igloo: iirc, 99 was the first haskell irc channel?
03:04:25 <roconnor> osfameron: I need an m (), for the list monad that is [()]
03:04:33 <dons> Igloo: but we have no logs from that era?
03:05:00 <osfameron> roconnor: what's a "m ()" ?
03:05:14 <roconnor> osfameron: yes, guard is used like comprehension guards.
03:05:32 <roconnor> osfameron: guard works for any MonadPlus
03:05:34 <osfameron> roconnor: ta - I just substituted import Control.Monad for the definition I'd made, and it works
03:05:46 <osfameron> and the () just means it doesn't take a parameter?
03:06:03 <doserj> () is a datatype
03:06:03 <roconnor> osfameron: () is the unit type in haskell.
03:06:31 <roconnor> @src ()
03:06:31 <lambdabot> data () = ()
03:06:33 <taruti> > return () :: [()]
03:06:34 <lambdabot>  [()]
03:06:35 <Cale> The only values of type () are () and undefined
03:06:55 <Cale> So it just means that it returns something uninteresting.
03:06:55 <osfameron> but it's a Monad?
03:07:06 <roconnor> () isn't a monad, but lists are.
03:07:08 <Cale> () isn't a monad, but m () is a monadic action.
03:07:27 <Cale> (which when run, produces a value of type ())
03:07:29 <taruti> m - the monad. m () - a monadic action
03:07:32 <osfameron> but it implements "return" like a Monad?
03:07:50 <Cale> return :: a -> m a
03:07:53 <Cale> () :: ()
03:07:53 <roconnor> osfameron: () is usually used when we don't care about the ``result type'' of a monad.
03:07:56 <Cale> return () :: m ()
03:07:58 <taruti> instance Monad [] where return x = [x] ...
03:08:00 <roconnor> @type print
03:08:02 <lambdabot> forall a. (Show a) => a -> IO ()
03:08:08 <Cale> roconnor: monadic action :)
03:08:09 <roconnor> osfameron: print returns an IO ()
03:08:32 <osfameron> roconnor: oh, yes, I'd seen that - I interpreted it as a "void" function
03:08:58 <doserj> osfameron: in your definition of "guard", you only used the value "1". The nicer way to do it is to use (), which only has one "real" value
03:09:35 <osfameron> doserj: I quite like the definition "filter id . return" which uses [True] instead :-)
03:09:52 <Cale> heh
03:10:07 <Cale> sneaky :)
03:10:31 <roconnor> @djinn Bool -> [()]
03:10:32 <lambdabot> -- f cannot be realized.
03:10:39 <roconnor> oh right, doesn't do lists.
03:11:15 <roconnor> @djinn Bool -> ((),())
03:11:16 <lambdabot> f _ = ((), ())
03:11:24 <roconnor> @djinn Bool -> Either () ()
03:11:24 <lambdabot> f a =
03:11:24 <lambdabot>     case a of
03:11:24 <lambdabot>     False -> Left ()
03:11:24 <lambdabot>     True -> Right ()
03:11:26 <doserj> @djinn Bool -> Maybe ()
03:11:26 <lambdabot> f a =
03:11:26 <lambdabot>     case a of
03:11:28 <lambdabot>     False -> Nothing
03:11:30 <lambdabot>     True -> Just ()
03:11:37 <doserj> same idea :)
03:12:33 <roconnor> osfameron: returning () is better than Bool.
03:12:56 <roconnor> because if you do y <- filter id . return $ blah
03:13:21 <roconnor> then y is a Bool, and it could be either False or True from it's type, but you know it is always True.
03:13:33 <roconnor> if you do () <- guard $ blah
03:13:36 <roconnor> er
03:13:38 <roconnor> if you do y <- guard $ blah
03:13:48 <doserj> basically, [()] is nice because it is isomorphic to the Peano Naturals
03:13:54 <roconnor> then y is a () and it must be a ().
03:14:06 <roconnor> which is good because you know it must be a ()
03:14:18 <roconnor> your data type corresponds exactly to your knowledge.
03:14:24 <osfameron> roconnor: but you don't use the value anyway: it's just used for the combinatorial thing
03:14:29 <osfameron> doserj: er, that's nice ;-)
03:14:50 <osfameron> roconnor: but yeah, I'll use the definition in Control.Monad, as it saves me having to define it anyway.  So thanks :-)
03:15:34 <roconnor> if it weren't for bottom screwing everything up, the compilier could optimize away code that uses ().
03:15:58 <snearch> join #perl6
03:17:41 <wli> This is aggravating.
03:17:48 <dons> ?users
03:17:48 <lambdabot> Maximum users seen in #haskell: 411, currently: 383 (93.2%), active: 16 (4.2%)
03:18:48 <wli> All I did was figure out the distinct values of (10^n) `mod` (p-1) then only raise 10 to those powers to check to see if 1 is among them.
03:20:05 <wli> To see if 10^(10^n)=1 mod p
03:20:27 <wli> For some reason this isn't working.
03:21:45 <wli> (that is, for any natural number n >= 1)
03:30:58 <ari> @src and
03:30:58 <lambdabot> and   =  foldr (&&) True
03:36:52 <osfameron> is there a partial binary-fold function?  like   foo (+) [1,2,3] => [3,5]
03:37:25 <Vq^> wouldn't that be scan?
03:37:39 <Cale> > ap (zipWith (+)) tail [1,2,3]
03:37:41 <lambdabot>  [3,5]
03:37:47 <Vq^> > scanl1 (+) [1,2,3]
03:37:48 <lambdabot>  [1,3,6]
03:38:27 <osfameron> oh, I thought scan accumulated values too
03:38:47 <Cale> uh, it does, in a sense
03:39:01 <osfameron> > scanl1 (+) [1,2,3,4,5]
03:39:03 <lambdabot>  [1,3,6,10,15]
03:39:22 <osfameron> yeah, I'd have wanted [3,5,7,9]
03:39:40 <osfameron> ah, zipWith is what I want then
03:39:43 <osfameron> why "ap" ?
03:40:06 <osfameron> @src ap
03:40:06 <lambdabot> ap = liftM2 id
03:40:38 <Cale> ap f g x = f x (g x)
03:40:43 <Cale> in the monad ((->) e)
03:40:50 <Cale> It's just a #haskell-ism
03:40:56 <osfameron> but I don't see a monad...
03:41:10 <Cale> Functions from a fixed type form a monad
03:41:25 <Cale> @t ap
03:41:26 <lambdabot> Maybe you meant: tell temp thank you thanks thx time tiny-url todo todo-add todo-delete topic-cons topic-init topic-null topic-snoc topic-tail topic-tell type . ft v
03:41:28 <Cale> :t ap
03:41:30 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m (a -> b) -> m a -> m b
03:41:36 <Cale>  m (a -> b) -> m a -> m b
03:41:45 <Cale> In this case m = (e ->)
03:41:46 <Cale> so:
03:42:04 <Cale> ap :: (e -> (a -> b)) -> (e -> a) -> e -> b
03:42:21 <Cale> and there's only one sane thing that could do
03:42:32 <Cale> but if you'd like...
03:42:44 <osfameron> gah, I still find types hard to read
03:43:02 <osfameron> but I like that it seems to apply something to itself, saving you from typing [1,2,3] twice
03:43:04 <Cale> collapse f xs = zipWith f xs (tail xs)
03:43:04 <opqdonut> i'd group that like ap :: (e -> a -> b) -> (e -> a) -> e -> b
03:43:11 <osfameron> > ap zip id [1,2,3]
03:43:12 <lambdabot>  [(1,1),(2,2),(3,3)]
03:43:38 <xerox> join = ap zip id
03:43:39 <Cale> > ap zip (^2) [1,2,3]
03:43:40 <lambdabot>   add an instance declaration for (Num [a])
03:43:50 <Cale> heh, right
03:43:57 <Cale> > ap zip reverse [1,2,3]
03:43:58 <lambdabot>  [(1,3),(2,2),(3,1)]
03:44:05 <osfameron> > join [1,2,3]
03:44:06 <lambdabot>   add an instance declaration for (Num [a])
03:44:06 <lambdabot>     In the expression: 3
03:44:23 <Cale> xerox: not true, is it?
03:44:43 <Cale> > ap (,) (^2) 5
03:44:45 <lambdabot>  (5,25)
03:44:55 <Cale> > map (ap (,) (^2)) [0..5]
03:44:56 <lambdabot>  [(0,0),(1,1),(2,4),(3,9),(4,16),(5,25)]
03:45:31 <Cale> > scanl1 (\x y -> concat ["(f ",x," ",y,")"]) ["1","2","3","4","5"]
03:45:31 <xerox> Cale: I meant join zip = ap zip id
03:45:33 <lambdabot>  ["1","(f 1 2)","(f (f 1 2) 3)","(f (f (f 1 2) 3) 4)","(f (f (f (f 1 2) 3) 4)...
03:45:42 <xerox> ...in general join f = ap f id.
03:45:50 <Cale> ah, right
03:45:55 <Cale> > join zip [1,2,3]
03:45:57 <lambdabot>  [(1,1),(2,2),(3,3)]
03:46:08 <evir> What module is the Monad instance declaration for ((->) a) in?
03:46:09 <Cale> In this monad, join f x = f x x
03:46:16 <Cale> evir: Control.Monad.Instances
03:46:21 <Cale> or Control.Monad.Reader
03:46:24 <evir> Thanks.
03:46:33 <Cale> (because it's really the same thing as the Reader monad)
03:46:57 <xerox> ?unmtl Reader r a
03:46:58 <lambdabot> r -> a
03:47:10 <Cale> So in this monad, actions are functions from the type e -- to "run" such an action, we apply it to the value which the action as a whole has been applied to
03:47:33 <xerox> Err, that's how you name cont variables. Sorry. Reader e a = e -> a :)
03:47:35 <Cale> > (do x <- id; y <- reverse; z <- map toUpper; return (x,y,z)) "hello"
03:47:38 <lambdabot>  ("hello","olleh","HELLO")
03:47:50 <Cale> osfameron: see how that works?
03:48:06 * xerox needs tea.
03:48:12 <osfameron> Cale: no, but I'm very scared.
03:48:30 <Cale> Well, first we see  x <- id
03:48:41 <osfameron> which means we're in a functiony monad
03:48:45 <Cale> right
03:48:50 <Cale> and to "run" the function id
03:49:01 <Cale> we just apply it to the thing which the whole do-block got applied to
03:49:07 <Cale> in this case, "hello"
03:49:10 <Cale> > id "hello"
03:49:11 <lambdabot>  "hello"
03:49:20 <Cale> So x = "hello" for the rest of the block
03:49:30 <Cale> Next, y <- reverse
03:49:33 <evir> One gets to see strange things here every day. :-)
03:49:36 <Cale> > reverse "hello"
03:49:38 <lambdabot>  "olleh"
03:49:46 <Cale> So y = "olleh" for the rest of the block
03:50:02 <Cale> and finally, z <- map toUpper, so z = "HELLO"
03:50:13 <Cale> and we return the triple of those results
03:50:15 <osfameron> Cale: but the do block hasn't been applied to anything at that point
03:50:31 <osfameron> it returns a function  [Char] -> ([Char], [Char], [Char])
03:50:34 <Cale> > (do x <- id; y <- reverse; z <- map toUpper; return (x,y,z)) "hello" -- the "hello" at the end
03:50:35 <lambdabot>  ("hello","olleh","HELLO")
03:50:47 <Cale> osfameron: oh, right, yes
03:50:57 <Cale> On its own, that's what it does
03:51:03 <Cale> :t (do x <- id; y <- reverse; z <- map toUpper; return (x,y,z))
03:51:05 <lambdabot> [Char] -> ([Char], [Char], [Char])
03:51:42 <osfameron> ah, ok.  That sort of makes sense.  a function monad allows various functions to be called on the same argument
03:51:56 <Cale> right
03:52:25 <Cale> > sequence [id, (+2), (*2), (^2), (2^)] 5
03:52:27 <lambdabot>  [5,7,10,25,32]
03:52:45 <Cale> There are lots of handy consequences :)
03:52:58 <osfameron> oh, because sequence isn't just for functions?
03:53:02 <osfameron> :t sequence
03:53:04 <lambdabot> forall (m :: * -> *) a. (Monad m) => [m a] -> m [a]
03:53:10 <xerox> > ap [id, (+2), (*2), (^2), (2^)] [5]
03:53:11 <lambdabot>  [5,7,10,25,32]
03:53:20 <Cale> Sequence takes a list of actions and gives an action returning a list.
03:53:22 <opqdonut> :t [id, (+2), (*2), (^2), (2^)]
03:53:24 <lambdabot> forall a. (Integral a) => [a -> a]
03:53:27 <opqdonut> :t sequence [id, (+2), (*2), (^2), (2^)]
03:53:29 <lambdabot> forall a. (Integral a) => a -> [a]
03:53:30 <opqdonut> exactly
03:53:34 <xerox> hence sequence = (. return) . flip ap
03:53:42 <Cale> xerox: heh
03:53:58 <opqdonut> xerox: nice, except that ap is in a different monad :)
03:54:12 <opqdonut> which might make it even more nicer in fact :)
03:54:14 <opqdonut> -more
03:54:22 <xerox> opqdonut: no, they are the same monad.
03:54:42 <Cale> Well, he's saying you're using the list monad
03:54:48 <opqdonut> yeah :)
03:54:51 <xerox> Am I?
03:54:55 <Cale> yes
03:54:56 <opqdonut> yeah
03:55:07 <opqdonut> > ap [id, (+2), (*2), (^2), (2^)] [5,5,7]
03:55:08 <opqdonut> observe
03:55:09 <xerox> Just in return.
03:55:10 <lambdabot>  [5,5,7,7,7,9,10,10,14,25,25,49,32,32,128]
03:55:23 <xerox> Ah, so in ap as well.
03:55:27 <opqdonut> yep
03:55:27 <Cale> right :)
03:55:28 <xerox> Didn't catch that. Cool.
03:55:53 <Cale> osfameron: So, you can take from this that we're all insane :)
03:55:55 <opqdonut> having both the list monad and monadic list operations leads to some interesting stuff
03:56:06 * xerox snickers
03:56:38 <Cale> osfameron: But yeah, the function monad and the list monad have lots of nice handy consequences.
03:56:43 <osfameron> Cale: heh.  I'm just zoning out for now until the conversation comes around to something I understand again :-)
03:57:05 <Cale> sequence :: (Monad m) => [m a] -> m [a]
03:57:11 <Cale> So when m = (e ->)
03:57:13 <osfameron> yeah, I'm beginning to get the occasional glimpse of that
03:57:20 <Cale> sequence :: [e -> a] -> e -> [a]
03:57:51 <Cale> (and there's only one reasonable thing that could do :)
03:58:21 <xerox> sequence _ = repeat undefined -- obviously
03:58:28 <Cale> heh
04:01:44 <waern> nominolo: we're in the computer room on floor 5 now btw
04:02:04 <doserj> @type flip (map . flip id)
04:02:06 <lambdabot> forall a c. [a -> c] -> a -> [c]
04:02:40 <dons> what did we talk about in here before lambdabot could eval and type things?
04:03:17 <dons> i don't think we talked about the reader monad before we could play around with it in here, and let @pl come up with examples
04:03:19 <nominolo> waern: cool, thanks
04:03:31 <xerox> dons: I suppose mainly about building lambdabot :-)
04:03:36 <dons> heh
04:03:39 * Vq^ didn't talk in here until lambdabot showed up :)
04:03:42 <wli> Aha, dumb typo.
04:03:59 <doserj> isn't there an idiomatic version of "flip id"?
04:04:24 <xerox> flip ($)
04:05:29 <dons> <$<  -- looks fishy
04:05:33 <doserj> i was more thinking of something like |>, or $>
04:05:50 <dons> ah yes, wrong direction, >$>
04:05:53 <wli> The orbit of 10 `mod` (p-1) still seems too slow.
04:06:13 <taruti> how about (>>>) ?
04:06:28 <doserj> in the (->) arrow, yes
04:06:41 <xerox> That's a different thing. (>>>) = flip (.)
04:07:15 <opqdonut> hows ><> for fishy?
04:07:20 <opqdonut> :P
04:07:34 <Vq^> :)
04:07:40 <opqdonut> wli: i love your dissociated number theory comments
04:08:13 <xerox> ?type let (><>) = flip id in 2 ><> (^2)
04:08:15 <lambdabot> forall t. (Num t) => t
04:08:17 <xerox> hah.
04:08:43 <wli> opqdonut: projecteuler ;)
04:08:51 <opqdonut> wli: yeah i know :)
04:15:09 <roconnor> ><>  fish?
04:15:30 <dons> so what's a good use for ><> it seems quite a fun little combinator
04:15:41 <dons> <>< ><>< >< all good
04:15:51 <dons> >o< -- if only!
04:16:15 <Japsu> the Goatse combinator? :E
04:16:21 <dons> hah
04:17:03 <Japsu> along with the Cthulhu operator, :â‚¬
04:17:07 <Japsu> (euro)
04:17:20 <wli> heh, Cthulhu operator
04:18:53 <wli> I can get answers out of repunit stuff but not in a terribly timely fashion. I'm closer to 10 minutes than 60s.
04:22:08 <osfameron> the fishy operators remind me of the esoteric language with salmon in it
04:22:14 <osfameron> and "downstream killing machine"
04:22:26 <puusorsa> .. #haskell gets better every day
04:22:36 <puusorsa> cthulhu operator, languages with salmon .. <3
04:23:25 <sorear> osfameron: Do you want to be reminded of its name?
04:23:31 <dons> puusorsa: :)
04:24:01 <osfameron> found it... http://spuzz.net/projects/homespring/tutorial.php
04:24:02 <lambdabot> Title: tutorial
04:24:04 <osfameron> good old delicious
04:24:44 <osfameron> "The basic idea here is that of salmon. Yes, salmon. The program is a tree or rivers that flow out into the ocean. In our example program, the 'bear' is at the point where the river flows out into the ocean. The ocean represents the input and output streams."
04:24:53 <puusorsa> btw dons is it possible that hsplugins has problems on big endian?
04:27:42 <puusorsa> a.out: Ix{Int}.index: Index (131072) out of range ((0,13))
04:27:48 <puusorsa> testsuites/dynload/simple
04:28:52 <wli> Hmm, if ord_p(x) = t then ord_p(x^k) = t/(k, t)
04:29:03 <puusorsa> 1.0rc0
04:29:41 <wli> ord_p(x^k) = t `div` (k `gcd` t)
04:29:47 <dons> puusorsa: hmm. what arch?
04:29:56 <puusorsa> ppc, osx
04:30:04 <dons> ghc 6.6.1 and darcs version of hs-plugins?
04:30:23 <dons> i think it works on the mac, the darcs version, with ghc 6.6.x
04:30:42 <wli> So basically the only prime divisors of ord_p(10) allowable are 2 and 5.
04:31:25 <puusorsa> 6.6.1, i
04:31:31 <puusorsa> 'll try again with latest darcs version
04:34:05 <puusorsa> just thought that 131072 = 2^17, mayeb the bytes are in wrong order or something. or i'm jsut using it wrong :)
04:37:20 <EvilTerran> anyone up for a little golf? i'm thinking about terse ways of getting "Exception: <<loop>>" or infinite computation...
04:37:33 <EvilTerran> (currently down to "fix id ()")
04:38:12 <opqdonut> > fix id
04:38:13 <lambdabot>  Exception: <<loop>>
04:38:15 <opqdonut> :)
04:38:22 <roconnor> > fix
04:38:23 <lambdabot>  Add a type signature
04:38:30 <roconnor> > id
04:38:31 <lambdabot>  Add a type signature
04:39:34 <puusorsa> now it seems i'm missing AltData.Typeable
04:40:12 <roconnor> > fail
04:40:13 <lambdabot>  Add a type signature
04:40:20 <roconnor> > mzero
04:40:21 <lambdabot>   add an instance declaration for (Show (m a))
04:45:24 <puusorsa> found that but no Setup.lhs ;(
04:46:32 <EvilTerran> @src repeat
04:46:32 <lambdabot> repeat x = xs where xs = x : xs
04:59:33 <wvd> hello
05:00:21 <opqdonut> hi
05:00:46 <Cale> hi
05:03:07 <dons> welcome wvd.
05:03:44 <puusorsa> how should i install AltData?
05:04:26 <dons> puusorsa: hmm? the old module from hs-plugins?
05:04:37 <dons> are you using the darcs version of hs-plugins? AltData isn't needed
05:04:55 <dons> and you just build hs-plugins with the usual cabal steps
05:04:58 <puusorsa> just did darcs pull, testcases/dynload/simple complains
05:05:29 <dons> oh, hmm. its possibly out of date
05:05:36 <dons> what are you using hs-plugins for, may I ask?
05:05:44 <dons> Cale: heh, cool url, http://monad.me.uk/
05:05:45 <lambdabot> Title: Paul Taylor - Foundations of Mathematics and Computation
05:05:52 <Cale> dons: yeah :)
05:05:54 <puusorsa> nothing yet ;)
05:06:53 <puusorsa> didn't lambdabot need it?
05:08:09 <dons> it does. yeah.
05:08:13 <dons> > 1+2 -- for this
05:08:14 <lambdabot>  3
05:08:42 <puusorsa> any testcases you know arent out of date?
05:08:53 <dons> most of them should run.
05:09:37 <dons> i'm wondering what you're planning on doing with it though? perhaps you should look at ghc-api for a more flexible system?
05:09:56 <puusorsa> lambdabot + GOA.hs
05:10:40 <dons> ah ok. yeah, should work for lambdabot. hs-plugins doesn't get stressed very much
05:10:54 <puusorsa> thanks
05:29:23 <fasta> What's better explicit lifting or not? For the code it doesn't matter whether I use it or not, but using explicit lifting turns GHC needing an instance Foo FooT(ContT (WhateverT ..)) into a simple Foo m, which makes that type easier to understand and it doesn't contaminate the rest of the code.
05:30:57 <dons> whatever is cleanest?
05:31:55 <fasta> dons: the code is easier to read without the lifts, but when a problem does come up, the one with a simpler type is easier to read.
05:32:24 <fasta> Ideally, the compiler would do this type simplification.
05:32:26 <wli> Hmm, I'd have to get the discrete log of 10 to pass to mod phi(p-1)
05:40:06 <Ben`> how can I fix this? "Could not find module `Data.ByteString.Char8':  it was found in multiple packages: fps-0.8 base"
05:41:11 <profmakx> which version of ghc are you using?
05:41:23 <profmakx> deinstall fps-0.8 its included in ghc 6.6
05:42:29 <wli> I could alread consider it a discrete log problem actually. log_(10,p-1)((10^n)*log_(10,p)(1))= n*log_(10,p-1)(10) + log_(10,p-1)(log_(10,p)(1)) = log_(10,p-1)(0) (clearly 10 must be a 0 divisor mod p - 1).
05:43:07 <Ben`> profmakx: ok, thanks
05:43:56 <Ben`> profmakx: now I get, "Setup.hs: cannot satisfy dependency fps>=0.7"
05:44:30 <profmakx> so, what are you trying to build?
05:44:46 <Ben`> profmakx: lambdabot
05:45:04 <profmakx> with ghc6.6?
05:45:18 <Ben`> 6.6.1
05:45:35 <Igloo> Delete the dependency
05:46:01 <profmakx> remove the dependency from the cabal file
05:46:05 <profmakx> that should work fine
05:46:43 <profmakx> i just wonder why this problem shows up. i didnt have it
05:47:02 <Ben`> hmm, but now I get: "Could not find module `Data.Binary'"
05:47:34 <profmakx> ?where  binary
05:47:34 <lambdabot> http://www.cse.unsw.edu.au/~dons/binary.html
05:47:43 <Ben`> oh
05:47:46 <Ben`> ok, thanks
05:48:32 <profmakx> which reminds me... i wanted to patch out binary serialisation for some files
05:49:14 <Ben`> I still get the same error, but it says "it is a member of package binary-0.3, which is hidden"
05:52:14 <matthew_-> use --make
05:52:22 <matthew_-> ghc -o raa --make foo.hs
05:56:54 <araujo> morning
06:00:43 <sorear> profmakx: it sounds like you're trying to compile the hopelessly outdated lambdabot 4.0
06:01:06 <profmakx> i am not compiling anything
06:01:09 <profmakx> Ben` is
06:01:33 <profmakx> my lambdabot with patches compilies just fine :)
06:01:39 <Ben`> I'm trying to compile it from darcs
06:03:23 <matthew_-> I thought lambdabot is about the hardest thing to compile known to #haskell
06:03:47 <wli> 10^(10^n) == 1 (mod p) --> (10^n)*log_(10, p)(10) == log_(10,p)(1) mod (p-1) --> 10^n == log_(10,p)(1), then n*log_(10,p-1)(10) == n == log_(10,p-1)(log_(10,p)(1)) mod phi(p-1) except this does not appear to be working for any prime p.
06:07:07 <bleep> ist possible to build lambdabot from darcs with ghc 6.6 ?
06:07:09 <profmakx> matthew_-  is it?
06:07:19 <ohub> bleep: yes
06:07:32 * zmike wishes he could get lambdabot to compile :(
06:07:44 <bleep> ohub: thanks
06:08:25 <zmike> What's the problem with hs-plugins and ghc 6.6.x, or is that just a gentoo problem?
06:14:27 <wli> The discrete log seems to be getting right answers though I need to do a better check.
06:16:21 <dons> zmike: you gotta use the darcs version of hs-plugins
06:16:23 <dons> ?versoin
06:16:23 <lambdabot> lambdabot 4p548, GHC 6.6 (Linux i686 2.66GHz)
06:16:23 <lambdabot> darcs get http://www.cse.unsw.edu.au/~dons/lambdabot
06:16:28 <wli> Not to mention a vastly faster discrete log implementation.
06:16:35 <dons> which should then be fine with linux/ghc6.6.x
06:16:49 <dons> bleep: yeah. see above.
06:16:59 <dons> darcs hs-plugins, darcs lambdabot + ghc 6.6.x
06:17:11 <dnox> still noone that has taken up the job to fix hs-plugins for win?
06:17:51 <bleep> dons: ok, let's go
06:17:59 <zmike> ok
06:18:30 <dons> dnox: no one seem to have strong enough inclination.
06:19:13 <dnox> ye
06:26:35 <falseep> /film
06:26:37 <bringert> kosmikus: pong
06:32:41 <wli> This largely seems to depend on how many advanced number theory algorithms one's got in his arsenal at the higher problem numbers.
06:33:15 <osfameron> wli: euler still?  I'm getting to the point where I don't understand all the problem descriptions :-)
06:33:26 <wli> osfameron: yeah
06:33:41 <wli> osfameron: I was going over an already-solved problem trying to optimize it so it runs within 60s.
06:33:51 <hpaste>  int-e pasted "type checking problem" at http://hpaste.org/2366
06:33:57 <osfameron> wli: nice!
06:34:45 <osfameron> I solved #67 at 4 in the morning after walking gf to the airport coach (I'd had it sloshing in my head for a few days as it's the optimization of #18)
06:34:58 <wli> osfameron: problem #133
06:35:06 <osfameron> wli: eeeek!  big number!
06:35:29 <wli> osfameron: #137 I blew away completely ... the solution runs in like 0.01s
06:36:14 <wli> osfameron: Ugh, maximal sum in a triangle.
06:36:43 <wli> osfameron: I totally ignored the ones involving table dumps etc.
06:37:12 <int-e> I've triggered an unfortunate interaction between given type signatures, functional dependencies and adding new instance (see paste) :/ I can put the instance in a different module as a work-around but I'm unhappy about it.
06:37:21 <osfameron> wli: yeah triangle one.  I'm finding it all a good workout
06:37:37 <nominolo_uni> any ideas how to match darcs patches by patch date or author?
06:38:10 <wli> osfameron: I put up my solution to #137 on hpaste
06:38:51 <wli> osfameron: http://hpaste.org/2316#a2
06:39:06 <osfameron> wli: thanks - are you blogging this too somewhere?  I don't think I have free cycles to look at it yet (as I said, I don't even understand the problem)
06:39:12 <int-e> hmm. hugs doesn't have that particular problem. interesting.
06:39:26 <wli> osfameron: No, I'm just messing around.
06:40:24 <fasta> Does (a, b::Int) <- foobar work in GHC?
06:40:43 <fasta> I don't think it's H98.
06:40:44 <SamB> fasta: depends!
06:40:47 <wli> osfameron: I'm actually kind of proud of the solution to #137; it took some serious thought about how to translate it to a Diophantine equation, how to deal with the difference between it and the stock Pell equation, etc.
06:41:02 <fasta> SamB: on what!!!!
06:41:04 <wli> fasta: -fglasgow-exts to allow type annotations all over the place.
06:41:07 <int-e> fasta: it supports that as an extension. yes.
06:41:10 <SamB> fasta: on what flags you pass!
06:41:28 <fasta> SamB: Do I also need to have the machine powered on!!!
06:41:29 <int-e> -XPatternSigs
06:41:51 <fasta> thanks
06:41:56 <SamB> I guess I don't need to use @doc now that int-e has revealed the extension name!
06:42:02 <wli> osfameron: How's it look?
06:43:20 <fasta> A pattern type signature cannot bind scoped type variables `foo'
06:43:49 <SamB_XP> wierd!
06:43:55 <fasta> Hmm, it needs scoped-type variables.
06:44:20 <SamB_XP> I think you should ask about that one
06:45:02 <mm_freak> i'd like to use implicit parameters for type-class instancesâ€¦  is there a way to do it?
06:45:21 <hpaste>  (anonymous) annotated "Farewell Letter" with "(no title)" at http://hpaste.org/2359#a1
06:45:55 <hpaste>  (anonymous) annotated "Farewell Letter" with "(no title)" at http://hpaste.org/2359#a2
06:47:12 <wli> osfameron: It enumerates the first 113 solutions (never mind 15) in clock time too small to register to /usr/bin/time as nonzero.
06:47:51 <mm_freak> for example:  M x + M y = M $ mod (x+y) ?modulus
06:48:04 <mm_freak> but it won't allow me to add a type signature for (+)
06:48:19 <wli> osfameron: It's clearly dominated by IO on large integers for the most part.
06:50:32 <wli> osfameron: The basic way it works is that it breaks down to the generating function of the Fibonacci numbers taking on a certain value, which leads to the vanishing of its discriminant, which yields a quadratic Diophantine equation. One then transforms it to something similar to Pell's equation, but not identical, and uses an analogous technique to the number field solution of Pell to solve it.
06:52:01 <wli> osfameron: When the smoke clears, you basically just get a constant factor times powers of a unit in your number field.
06:52:40 <wli> osfameron: And, of course, invert the transformation done to convert it all into a Pell-like equation.
06:53:52 <wli> osfameron: The transformation was basically x' = (5*x+1)/2, y' = y/2 (in rational numbers)
06:55:04 <wli> osfameron: This derives from the conic y^2=5*x^2+2*x+1 which is basically the condition on the discriminant being a perfect square (y^2 is the perfect square involved; 5*x^2+2*x+1 is the discriminant).
06:56:15 <wli> osfameron: And what it's the discriminant of is the quadratic equation you get from z/(1-z-z^2) = n, where z/(1-z-z^2) is the generating function of the Fibonacci numbers, i.e. the power series whose coefficients are Fibonacci numbers.
06:59:38 <ricky_clarkson> In the (probably broken) case that you wanted to add tracing to a simple data type, not necessarily a built-in one, how would you go about it?
06:59:45 <ricky_clarkson> I only mean tracing the read accesses.
07:01:21 <osfameron> wli: sorry, afk for work (busy today, the August slack is starting to dissolve)
07:01:37 <osfameron> wli: I understand your excitement but not your maths :-)
07:03:30 <wli> osfameron: Okay.
07:05:17 <Lycurgus> what is 'afk'?
07:05:24 <johnnowak> away from keyboard
07:05:32 <Lycurgus> ah, thanks.
07:05:53 <sieni> Lycurgus: nice one to put in one's tombstone
07:06:03 <Lycurgus> :)
07:07:34 <doserj> depending on your belief system, *brb* also works...
07:09:24 <Lycurgus> actually per mine it would be 'gto'
07:09:33 <Lycurgus> Glad That's Over
07:10:37 <wli> Okay, I understand baby step giant step.
07:11:42 <eivuokko> Is Mathieu Boespflug here?  Or anyone know if his SoC contribution can be seen somewhere.
07:15:10 <wli> I don't entirely understand the index calculus algorithm but it seems slightly easier than Pollig-Hellman.
07:17:47 <Nucleo2> Is there any way I can get Floats or Doubles to show() with more precision?
07:18:49 <mrd> investigate Numeric.show* functions
07:18:52 <bleep> dons : trying ./Setup.hs configure I get : Setup.hs: cannot satisfy dependency arrows-any
07:19:00 <Nucleo2> mrd: thank you
07:19:10 <ari> Would that extra "precision" actually be, well, meaningful?
07:19:13 <bleep> dons : building lambdabot
07:19:23 <mrd> yea I'm confused too. the default show method gives you everything, I think.
07:19:35 <wli> Ah, I think I understand Pohlig-Hellman.
07:20:15 <ari> > decodeFloat 5.43536543
07:20:17 <lambdabot>  (6119677431292619,-50)
07:20:34 <wli> wikipedia's description is worse than useless but CRT conquers all.
07:20:51 <Nucleo2> ari: thanks' that's perfect
07:21:36 <Nucleo2> > sqrt(2)::Float
07:21:38 <lambdabot>  1.4142135
07:21:44 <ari> Nucleo2: Good. There's other useful stuff for working with IEEE754 in RealFloat (do :info RealFloat in ghci)
07:21:44 <Nucleo2> > sqrt(2)::Double
07:21:45 <lambdabot>  1.4142135623730951
07:22:06 <Nucleo2> oooh, handy. Thanks for the tip!
07:22:43 <Lycurgus> CRT = chinese remainder?
07:23:09 <Saizan> bleep: you don't build lambdabot as a standard cabal package, check README, however the arrows package can be found on hackage.haskell.org
07:23:32 <wli> Lycurgus: Yeah.
07:27:59 <ohub> Some of my HUnit tests seems to take infinite amount of time and memory. Is there any easy way to get those tests to fail after some amount of time?
07:31:31 <roconnor> ohub: ulimit on a unix system?
07:33:16 <bleep> saizan : well I did, but I'm confused... what am I meant to do ?
07:36:44 <bleep> Saizan: when i do ./build, I get the same dependency error... ???
07:36:49 <matthew_-> does it not involve the sacrifice of goats?
07:38:04 <Saizan> bleep: yeah, you still have to install the package
07:38:08 <Saizan> ?where arrows
07:38:08 <lambdabot> http://www.haskell.org/arrows/
07:38:16 <Saizan> ?hackage arrows
07:38:17 <lambdabot> http://hackage.haskell.org/cgi-bin/hackage-scripts/package/arrows
07:38:55 <bleep> Saizan: ok, thanks !
07:50:55 <ndm> @tell enolan not yet, i start writing it tomorrow, and it will be submitted in 10 days time - so not long to wait
07:50:55 <lambdabot> Consider it noted.
07:51:56 <fasta> ohub: on GHC, yes.
07:52:06 <fasta> ohub: in H98, no.
07:52:40 <fasta> ohub: unless you assume OS features
07:53:04 <ohub> well, something
08:06:36 <sjanssen> @keal
08:06:36 <lambdabot> tomorrow i share next mathematical secrety
08:09:28 <enolan> ndm: Cool.
08:09:28 <lambdabot> enolan: You have 1 new message. '/msg lambdabot @messages' to read it.
08:10:14 <ndm> enolan: yesterday i was 20% faster than GHC in nqueens and 10% faster in primes, but I want much higher numbers
08:10:34 <ndm> i am aiming for ~50% faster
08:12:19 <fasta> ndm: you wrote some optimizer out of tree?
08:14:51 <ndm> fasta: very out of tree, in Yhc
08:18:48 <matthew_-> so far out of tree it's a bush of its own right
08:20:26 <ndm> indeed :)
08:20:50 <matthew_-> ndm: sorry I didn't make it to the anglo haskell. I would have liked to have been there. Did your talk go well?
08:21:22 <ndm> matthew_-: yep, was fine - inadvertantly deleted a critical slide somewhere between my machine and the projector, but was fine
08:21:41 <ndm> the moment when you skip to the next slide, and realise its missing, is not a good one!
08:22:03 <matthew_-> yeah
08:22:15 <osfameron> ooo, are there slides and writeups of anglohaskell?
08:22:45 <ndm> my slides are up
08:23:06 <ndm> http://www-users.cs.york.ac.uk/~ndm/downloads/
08:23:06 <lambdabot> Title: Neil Mitchell - Downloads
08:23:10 <osfameron> cool
08:23:31 <matthew_-> ndm: you might like to update the anglohaskell/2007 wiki page with that url
08:24:48 <ndm> matthew_-: we were going to collect all the slides, and post them up - i was also going to do a little blog summary and reflection thing
08:24:54 <ndm> @seen Philippa_
08:24:54 <lambdabot> Philippa_ is in #scannedinavian, #haskell-soc, #haskell-overflow, #haskell-blah and #haskell. I don't know when Philippa_ last spoke.
08:25:55 <matthew_-> ahh, super
08:26:57 <osfameron> ndm: shiny!  You say there is more to do for Supero on arbitrary programs:  is that just that it fails to speed up sufficiently, or does it play badly with some code ?
08:27:39 <ndm> osfameron: when i wrote that, it played badly, now it fails to give me the speedup i want (~10/20% over GHC in a small range of benchmarks)
08:29:50 <osfameron> ndm: so the "almost as good as or better than C" results are encouraging but anomalous so far?
08:30:16 <ndm> osfameron: hmm, there are only 3 programs which i have in both C and Haskell
08:30:27 <ndm> hence its hard to say, any inter-language comparison is just a teaser really
08:30:54 <osfameron> yeah, guess so
08:43:34 <matthew_-> ndm: underclock your CPU when running GHC
08:44:13 <matthew_-> just because it says it's a 2.2 GHz Core 2 Duo doesn't mean it has to be run at 2.2 GHz...
08:44:34 <ndm> matthew_-: everything is unpredicatable enough already, all my timings are inclusive of gmail checking my email, pandora playing some music, msn, gtalk etc
08:48:08 <matthew_-> yeah, especially with Window's well known multitasking abilities
08:49:58 <ndm> well i've found that pandora sucks some CPU when songs change, so i try and run the benchmarks during a song
08:51:05 <matthew_-> lol
08:51:17 <matthew_-> that's not quite the solution I'd have come up with
08:51:32 <matthew_-> enqueue some mahler symphonys
08:51:47 <sjanssen> can't you measure CPU time elapsed?
08:52:18 <ndm> sjanssen: you want to measure time, so that things like memory access etc. get accounted properly
08:52:54 <matthew_-> ndm: cache misses stall the CPU - does that not get included in CPU time?
08:53:03 <matthew_-> or are you talking about loading files etc?
08:53:38 <ndm> matthew_-: more paging time, i think cache misses get included
08:53:48 <ndm> but paging doesn't, since the CPU switches to something else
08:54:10 <eivuokko> pgavin, Yo.
08:54:15 <matthew_-> ja
08:54:21 <sorear> ndm: dons has a machine set up to be used exclusively for clean benchmarks (dunno how utilized/open it is though)
08:54:36 <matthew_-> ndm: you could always shutdown other applications so that you don't use swap
08:54:39 <sorear> if you need quality figures
08:54:40 <SamB> doesn't NT measure kernel time too?
08:54:43 <ndm> sorear: once i have all of nobench going through, i'm going to be abusing that one
08:54:59 <ndm> matthew_-: i like my music and my email, and the benchmarks aren't important enough to be clean
08:55:12 <ndm> once they are going in a thesis or paper, i'll try a bit harder to make them more robust
08:56:06 <matthew_-> ah ha
08:56:21 <matthew_-> well fortunately, the cricket's going pretty well
08:57:10 <pgavin> eivuokko, hi
08:57:33 <eivuokko> pgavin, re: Distrbution.Extended;  You extend Distrbution.Simple, right?
08:58:08 <pgavin> well, I tried putting my code straight into Distribution.Simple
08:58:11 <matthewgialich> hey guys
08:58:16 <pgavin> which isn't working as well as I'd like
08:58:27 <pgavin> hi
08:58:27 <eivuokko> pgavin, And that'd be by far best solution on long term.
08:58:45 <eivuokko> pgavin, If you don't, I assume we will start moving it there anyway...
08:58:46 <pgavin> eivuokko, which do you mean?
08:59:15 <pgavin> eivuokko, ah, ok, you mean creating Distribution.Extended is the right way :)
08:59:32 <eivuokko> pgavin, Intention is that most users use Distribution.Simple;  And if we get dependency analysis, we want it to be default.
09:00:06 <eivuokko> pgavin, No -.-  I mean it's wrong in two ways:  It seems wrong to separate it (ie not being default) *and* the name seems wrong to me as well.
09:00:06 <pgavin> eivuokko, right, but I'm going to have to wipe out big chunks of code if it goes straight into Simple
09:00:06 <HG`> holy shit, how busy is this place
09:00:16 <pgavin> eivuokko, ok
09:00:18 <sjanssen> HG`: fairly busy
09:00:27 <eivuokko> pgavin, If the code is no good, it ought to go away!
09:00:30 <sjanssen> HG`: we broke the 400 users watermark yesterday
09:00:31 <sjanssen> @users
09:00:31 <lambdabot> Maximum users seen in #haskell: 416, currently: 415 (99.8%), active: 14 (3.4%)
09:00:34 <HG`> wow
09:00:39 <pgavin> eivuokko, ok :) I'll do that then :)
09:00:48 <HG`> too much reddit stories, heh
09:00:50 <HG`> many*
09:01:05 <pgavin> eivuokko, I don't want to step on others' feet, that's all
09:01:11 <eivuokko> pgavin, I'd say: Don't be afraid to change things.
09:01:21 * Cale finds bugs in the reddit beta
09:01:25 <pgavin> eivuokko, ok
09:01:27 <Cale> 5 bugs in 5 minutes
09:01:42 <Cale> Or 7, depending on how you count :)
09:01:59 <pgavin> eivuokko, I'm afraid to make the packages out there break, though
09:02:00 <eivuokko> pgavin, If you remove features, just document them so they can be added back later on.
09:02:11 <pgavin> eivuokko, gotcha
09:02:31 <eivuokko> pgavin, Ah;  Yes.  That's annoying, but I don't think anyone thought you could add dep analysis without breaking something.
09:02:40 <pgavin> eivuokko, lol, good point
09:03:16 <pgavin> eivuokko, so supporting legacy code isn't really a big concern at this point
09:03:25 <eivuokko> pgavin, Please bring up the interface change decisiong on mailing list, though.  Maybe others have ideas.
09:03:42 <pgavin> eivuokko, ok :)
09:03:50 <eivuokko> pgavin, Well.  Supporting legacy code is important;  But not important enough to cripple devel yet.
09:03:56 <pgavin> eivuokko, right
09:04:23 <eivuokko> pgavin, At least that's what I've gathered from comments before.  And hooks need changes anyway...
09:04:51 <eivuokko> I think biggest question if changes go in for ghc 6.8 or not...
09:05:08 <pgavin> maybe later than that :)
09:05:28 <eivuokko> Yeah.  I have no idea if hooks are broken this time.
09:05:47 <eivuokko> If they are, and will be for next Cabal release as well...that'd be third time in a row or something.
09:06:11 <pgavin> the hook system would definitely need to be redone to make it work cleanly with dependencies
09:07:13 <pgavin> afk for a sec
09:07:22 <eivuokko> Yeah;  Just about every sensible refactoring breaks API at the moment.  It's all very shallow.
09:08:00 <matthew_-> imagine what would happen if all 415 #haskellers were involved in the same conversation!
09:08:10 <eivuokko> Confusion.
09:08:39 * ndm just beat GHC by 100% on primes! yay!
09:08:44 <eivuokko> o.O
09:08:54 <ndm> i.e. half the time GHC takes
09:08:59 <Maddas> ndm: wow, with mental arithmetic? ;-)
09:09:10 <ndm> maybe thats 50%, can't really remember percentages...
09:09:48 <SamB> just say you did it in half the time
09:09:51 <SamB> or twice as fast
09:10:09 <ndm> anyway, GHC = 7.5, Supero = 3.8, on prime number generation, finding the 8000th prime number
09:10:16 <pgavin> eivuokko, ok, well, I'll think about what needs to be done a bit more and post an email to the list
09:10:21 <pgavin> gtg, bbl
09:10:24 <eivuokko> pgavin, Thanks.
09:10:28 <ndm> @seen dcoutts_
09:10:28 <lambdabot> dcoutts_ is in #haskell, #gentoo-haskell, #haskell-overflow and #ghc. I don't know when dcoutts_ last spoke.
09:11:21 <hpaste>  (anonymous) pasted "foo" at http://hpaste.org/2370
09:11:54 <matthew_-> ndm: did you get the same answer as GHC
09:12:04 <matthew_-> or did you get 0.?or 1 ?
09:12:22 <ndm> matthew_-: exact same answer
09:13:20 <Igloo> ndm: Is that in seconds?
09:13:33 <ndm> Igloo: yes
09:13:46 <matthew_-> are these optimisations that are really new but could be applied to GHC, or optimisations that for some reason can't easily be worked into GHC?
09:13:51 <Igloo> Neat; is that due to one thing in particular?
09:14:07 <ndm> matthew_-: very new, but could be put into GHC
09:14:24 <ndm> Igloo: not really sure, probably a good bit of list deforestation, and some argument specialisation
09:14:32 <ndm> thats GHC 6.6.1, so no specconstr
09:14:42 <matthew_-> -O2 etc on GHC?
09:15:04 <ndm> of course
09:15:27 <matthew_-> cool. shows how much scope there is for getting haskell to go really fast.
09:16:46 <matthew_-> "We shall fight C on the beaches, we shall fight C++ on the landing grounds, we shall fight Clean in the fields and in the streets, and we shall fight OCaml in the Great Language Shootout."
09:17:02 <osfameron> how fast is the optimization process?
09:18:34 <ndm> a few seconds, running it through GHCi
09:19:49 <ndm> of which ~70% of the time is writting debug file
09:20:38 <ndm> wow, now i need percentages help
09:20:58 <ndm> GHC = 3.78 vs Supero = 1.06 for exp3_8
09:21:03 <ndm> (with 8 = 10, i think)
09:21:11 <ndm> that makes me 75% faster?
09:22:08 <osfameron> @index (\\)
09:22:09 <lambdabot> bzzt
09:23:43 <Igloo> If you can't understand it, then your readers won't be able to either
09:23:53 <ndm> i just can't understand percentages
09:24:18 <Igloo> "The SuperO version runs in approx 25% of the time of the GHC one" or something
09:24:29 <ndm> yeah, i guess
09:24:38 <ndm> yay! now i have some real results
09:24:44 <ndm> i wish i had had these for AngloHaskell
09:25:04 <Igloo> It would be nicer to say "less than 30%" IMO, incidentally
09:25:07 <ndm> and the great thing about exp3_8 is that list fusion etc won't get anything on it, since there are no lists
09:25:14 <Igloo> And it's a similar level of impressiveness
09:25:35 <ndm> i prefer over 3 times faster
09:27:02 <matthew_-> i prefer "instantaneous!!"
09:27:53 <matthew_-> or "infinitely faster"
09:29:53 <Saizan> "your other running programs will go faster, too!"
09:30:35 <glguy> wow...
09:30:36 <glguy> @users
09:30:36 <lambdabot> Maximum users seen in #haskell: 418, currently: 416 (99.5%), active: 17 (4.1%)
09:33:24 <matthew_-> "plus, with the --stripes option, your programs will run cooler too"
09:37:24 <byorgey> @users
09:37:24 <lambdabot> Maximum users seen in #haskell: 419, currently: 419 (100.0%), active: 14 (3.3%)
09:37:32 <ohub> \o/
09:37:37 <ddarius> What the heck?
09:37:41 <byorgey> congrats ddarius, you just pushed it up another notch =)
09:38:16 <ddarius> Where are these people coming from?
09:38:34 <byorgey> Mongolia?
09:38:47 <olsner> is haskell reaching critical mass?
09:39:01 <igel> \o/ ^^
09:39:07 <ddarius> @users
09:39:07 <lambdabot> Maximum users seen in #haskell: 419, currently: 418 (99.8%), active: 17 (4.1%)
09:39:13 <ddarius> @users
09:39:13 <lambdabot> Maximum users seen in #haskell: 419, currently: 417 (99.5%), active: 17 (4.1%)
09:39:41 <byorgey> olsner: it's reaching some sort of mass.  depends on what you mean by "critical". =)
09:40:08 <oerjan> i guess it has to do with schools etc. starting up?
09:40:27 <matthew_-> @users should report what fraction are university staff, what fraction are PhD students, undergrads etc and what fraction are commercial, and what fraction are lost
09:40:28 <lambdabot> Maximum users seen in should report what fraction are university staff, what fraction are phd students, undergrads etc and what fraction are commercial, and what fraction are lost: 1, currently: 0 (
09:40:28 <lambdabot> 0.0%), active: 0 (NaN%)
09:40:30 <olsner> could be.. my school doesn't have a haskell course afaik though
09:40:49 <byorgey> haha
09:41:06 <olsner> agh, gotta run
09:41:20 <byorgey> bye olsner
09:41:28 <olsner> (although ML did pop up in the semantics course I read this spring)
09:42:52 <olsner> the worst part with suddenly realizing you're late is simultaneously realizing you don't have any clothes on and then you have to find clean clothes and get dressed while already late
09:43:32 <byorgey> olsner: ...and typing in #haskell? =)
09:44:46 <augustss> ndm: good work on exp3_8!
09:44:52 <olsner> heh, yeah =)
09:45:49 <dmead> hello pa.,s
09:45:53 <dmead> *pals
09:46:26 <glen_quagmire> !next
09:46:45 <augustss> @quote
09:46:45 <lambdabot> <basti_> says: Snow doeth lay upon the lands. Even with cunning newtype; deriving the newtype is recursive. Great leaders brings less pain.
09:46:58 <byorgey> hi dmead
09:47:08 <glen_quagmire> @trivia
09:47:08 <lambdabot> Unknown command, try @list
09:47:17 <glen_quagmire> we need haskell trivia
09:47:29 <dmead> programming langauge trivia?
09:47:32 * glen_quagmire tries to turn #haskell into anime trivia chanell
09:47:44 <oerjan> @list faq
09:47:44 <lambdabot> dummy provides: eval choose id read show dummy bug get-shapr faq paste learn map shootout botsnack thanks thx thank you wiki oldwiki docs source fptools hackage
09:48:01 <oerjan> @help shootout
09:48:02 <lambdabot> shootout. The debian language shootout
09:48:08 <byorgey> @help thx
09:48:09 <lambdabot> Plugin `help' failed with: IRCRaised Plugin/Dummy.hs:(23,19)-(46,62): Non-exhaustive patterns in case
09:48:09 <sjanssen> trivia question: what does "filterM (const [True, False])" do?  (please don't spoil if you've seen it before)
09:48:17 <oerjan> @shootout
09:48:17 <lambdabot> http://shootout.alioth.debian.org/gp4/benchmark.php?test=all&lang=all
09:48:23 <Eelis> glen_quagmire: we need something like ##c++'s !trivia !
09:48:41 <dmead>   > map (1+) [x | x <- [1..10]]
09:48:45 <glen_quagmire> yes. let's write haskell00 standard in C++ style
09:48:47 <dmead>  > map (1+) [x | x <- [1..10]]
09:48:55 <dmead> > map (1+) [x | x <- [1..10]]
09:48:57 <lambdabot>  [2,3,4,5,6,7,8,9,10,11]
09:49:04 <dmead> wtf spaces
09:49:10 <dmead> c++ o rly
09:49:15 <Eelis> glen_quagmire: you're not making much sense to me
09:49:18 <dmead> c++ is getting type inferences
09:49:24 <dmead> i wonder what the really means
09:49:24 <dmead> like
09:49:28 <dmead> you won't have to delcare a type
09:49:28 <dmead> or
09:49:36 <dmead> something else
09:49:36 <Eelis> dmead: it already has type inference in template argument deduction
09:49:48 <dmead> well, thats overloading
09:49:48 <glen_quagmire> i thought !trivia in ##C++ was quotes from standard documentation
09:50:01 <Eelis> dmead: certainly not in the C++ sense of overloading
09:50:02 <dmead> overloading + templates = type inference i suppose
09:50:04 <dmead> but not really
09:50:12 <oerjan> @list quote
09:50:13 <lambdabot> quote provides: quote remember forget ghc fortune yow arr yarr keal b52s brain palomer girl19 v yhjulwwiefzojcbxybbruweejw protontorpedo
09:50:24 <Eelis> glen_quagmire: it is, which is why you weren't making sense to me :)
09:50:35 <oerjan> it should fit in the quote package
09:51:21 <damg> C doesn't require you to define any types anyways ;)
09:51:28 <damg> and C++ therefore either
09:51:33 <glen_quagmire> maybe !trivia should be : given a type guess what the function does
09:53:11 <ddarius> @djinn a -> b -> b
09:53:11 <lambdabot> f _ a = a
09:54:01 <oerjan> @free f :: a -> b -> b
09:54:01 <lambdabot> h . f x = f (g x) . h
09:55:10 <oerjan> the latter can sometimes be used to find _all_ the functions (well, there might be some issues with bottom?)
09:58:21 <oerjan> h (f x y) = f (g x) (h y), set h = const b and g = const a then b = f a b
09:59:32 <augustss> @free f :: a
09:59:32 <lambdabot> g f = f
10:00:16 <augustss> @free f :: a -> b
10:00:16 <lambdabot> h . f = f . g
10:00:40 <oerjan> those are impossible types
10:01:13 <augustss> I know
10:02:29 <augustss> @free f :: (a,b) -> (b,a)
10:02:29 <lambdabot> $map_Pair h g . f = f . $map_Pair g h
10:03:00 <Saizan> which are the assumptions? if f (g x) == _|_ for every g,x i think but h (f x) could be more defined
10:03:44 <augustss> Simplest assumption: no bottoma
10:03:49 <augustss> bottoms
10:04:15 <augustss> You can make statements with bottom too, but they get more complicated
10:07:14 <ihope> @help free
10:07:14 <lambdabot> free <ident>. Generate theorems for free
10:08:05 <ihope> @free f :: a -> b -> a
10:08:05 <lambdabot> g . f x = f (g x) . h
10:08:19 <ihope> Hmm...
10:08:26 <int-e> @free unsafeCoerce :: a -> b
10:08:27 <lambdabot> g . unsafeCoerce = unsafeCoerce . f
10:08:38 <ihope> @free unsafeCoerce# :: a -> b
10:08:38 <lambdabot> Extra stuff at end of line
10:08:45 <ihope> Woo.
10:08:54 <sorear> @free seq :: a -> b -> b
10:08:54 <lambdabot> g . seq x = seq (f x) . g
10:09:03 <ihope> @free f :: a -> m a
10:09:03 <lambdabot> Extra stuff at end of line
10:09:11 <ihope> Meh.
10:09:46 <sorear> > let { f _ = undefined ; x = 2 ; g = id } in (g . seq x) 5
10:09:48 <lambdabot>  5
10:09:57 <sorear> > let { f _ = undefined ; x = 2 ; g = id } in (seq (f x) . g) 5
10:09:58 <lambdabot>  Undefined
10:10:04 <ihope> @free s :: (a -> b -> c) -> (a -> b) -> a -> c
10:10:05 <lambdabot> (forall x. h . k x = p (f x) . g) => g . q = f1 . f => h . s k q = s p f1 . f
10:10:13 <ihope> Did I do that?
10:10:20 * monochrom tosses around some lambdas
10:10:56 <ihope> So, um, what's the point of @free?
10:10:58 * int-e wishes people would throw omicrons instead, they're safer.
10:11:17 <ihope> Indeed.
10:11:26 * ihope tosses around some omegas
10:11:47 <ihope> Some of them are mostly round with some pointy bits at the bottom.
10:11:56 <monochrom> What are omicrons and why are they safer?
10:12:05 <int-e> they aren't pointy.
10:12:23 <ihope> ÎŸÎ¿
10:12:26 <ihope> Two omicrons.
10:12:29 * monochrom recalls his lambdas and tosses around some omicrons
10:12:46 <monochrom> My lambdas were tainted with lead. :)
10:13:14 <pjd> monochrom: littering is bd
10:13:17 <pjd> bad, even
10:13:35 <Botje> you can pick them up with a lambda
10:13:38 <Botje> since they're nice and pointy
10:13:51 <ihope> But wait! Omicrons are also a safety hazard because you can strangle yourself with one!
10:16:59 * LeCamarade should be building Xmonad in a while ... standby for the usual wauling and wailing. And hopeless moaning about OMG we need hugs-get ... :o)
10:17:52 <augustss> Omicrons cause cancer in rats
10:27:37 <shapr> Good afternoon #haskell!
10:27:49 <ihope> Ello.
10:31:38 <LeCamarade> shapr: Good evening ... :o)
10:32:07 <daniel_larsson> shapr: God afton
10:33:39 <Maddas> shapr: Yow!
10:34:58 <Vq^> hej formarn
10:37:45 <gkr> What does "deriving Monad" do?
10:37:56 <augustss>  Hejsan shapr
10:38:04 <bos> hello san francisco: http://programming.reddit.com/goto?id=2hb96
10:38:06 <lambdabot> Title: Real World Haskell » Blog Archive » Announcing the Bay Area Functional Programme ...
10:38:09 <oerjan> gkr: this is on a newtype i take?
10:38:33 <bos> holy moly, where did all the extra campers in #haskell come from?
10:38:43 <oerjan> it uses the monad instance on the content field to create a monad instance for the newtype
10:38:46 <oerjan> iiuc
10:38:48 <bos> the number has gone up by almost 20% in a single week!
10:39:51 <_roconnor> @losers
10:39:51 <lambdabot> Maximum users seen in #haskell: 419, currently: 409 (97.6%), active: 16 (3.9%)
10:39:54 <gkr> Ah. Like newtype Baba = [Int] deriving Monad, then Baba works a monad like []?
10:40:13 <oerjan> well, the kinds on that example are wrong
10:40:28 <oerjan> and the syntax
10:41:03 <oerjan> newtype Baba a = BB [a] deriving Monad, i guess
10:41:21 <gkr> Yeah, thanks.
10:41:42 <pjd> a real "deriving Monad" would be so nifty
10:42:51 <augustss> pjd: use djinn :)
10:43:19 <oerjan> @djinn [a] -> (a -> [b]) -> [b]
10:43:20 <lambdabot> -- f cannot be realized.
10:43:36 <oerjan> hmph
10:43:37 <pjd> heh, oops
10:43:50 <pjd> @djinn [[a]] -> [a]
10:43:50 <lambdabot> -- f cannot be realized.
10:43:57 <pjd> @djinn a -> [a]
10:43:58 <lambdabot> -- f cannot be realized.
10:44:01 <oerjan> @djinn Maybe a -> (a -> Maybe b) -> Maybe b
10:44:01 <lambdabot> f a b =
10:44:01 <lambdabot>     case a of
10:44:01 <lambdabot>     Nothing -> Nothing
10:44:01 <lambdabot>     Just c -> b c
10:44:09 <oerjan> i don't think @djinn knows lists
10:44:17 <augustss> that's right
10:44:25 <pjd> @djinn Maybe (Maybe a) -> Maybe a
10:44:25 <augustss> nor any other recursive type
10:44:26 <lambdabot> f a =
10:44:26 <lambdabot>     case a of
10:44:26 <lambdabot>     Nothing -> Nothing
10:44:26 <lambdabot>     Just b -> b
10:44:34 <pjd> @djinn a -> Maybe a
10:44:35 <lambdabot> f = Just
10:44:39 <pjd> damn, nifty
10:45:03 <augustss> @djinn-env
10:45:03 <lambdabot> data () = ()
10:45:04 <lambdabot> data Either a b = Left a | Right b
10:45:04 <lambdabot> data Maybe a = Nothing | Just a
10:45:04 <lambdabot> data Bool = False | True
10:45:04 <lambdabot> data Void
10:45:05 <lambdabot> type Not x = x -> Void
10:45:07 <lambdabot> class Eq a where (==) :: a -> a -> Bool
10:45:09 <lambdabot> type Cont o a = (a -> o) -> o
10:45:20 <pjd> augustss: is there a specific reason for that?
10:45:35 <oerjan> @list djinn
10:45:36 <lambdabot> djinn provides: djinn djinn-add djinn-del djinn-env djinn-names djinn-clr djinn-ver
10:45:41 <augustss> pjd: for omitting recursion?  Yes, to make it decidable
10:45:52 <pjd> oh, okay
10:45:56 <ihope> The type system prevents bottom from happening, as long as there are no recursive types.
10:46:04 <kaol> @djinn Maybe a -> (Bool, Bool, Bool)
10:46:04 <lambdabot> f a =
10:46:04 <lambdabot>     case a of
10:46:04 <lambdabot>     Nothing -> (False, False, False)
10:46:04 <lambdabot>     Just _ -> (False, False, True)
10:46:21 <augustss> @djinn-add data S a = S (s -> (s, a))
10:46:55 <pjd> would a more limited kind of recursion help, in this context?
10:46:56 <augustss> @djinn S a -> (a -> S b) -> S b
10:46:57 <lambdabot> Cannot parse command
10:46:57 <lambdabot> -- f cannot be realized.
10:47:15 <ihope> @djinn (
10:47:15 <lambdabot> Cannot parse command
10:47:15 <lambdabot> Cannot parse command
10:47:27 <ihope> Cool, a double error message.
10:47:30 <augustss> @djinn-env
10:47:31 <lambdabot> data () = ()
10:47:31 <lambdabot> data Either a b = Left a | Right b
10:47:31 <lambdabot> data Maybe a = Nothing | Just a
10:47:31 <lambdabot> data Bool = False | True
10:47:31 <lambdabot> data Void
10:47:33 <lambdabot> type Not x = x -> Void
10:47:35 <lambdabot> class Eq a where (==) :: a -> a -> Bool
10:47:37 <lambdabot> Error: type variable not bound s
10:47:39 <lambdabot> type Cont o a = (a -> o) -> o
10:47:51 <augustss> @djinn-del S
10:47:51 <lambdabot> Cannot parse command
10:48:04 <augustss> @djinn-clr
10:48:11 <ihope> data Self a = Self (Self a -> a); self (Self x) = x (Self x)
10:48:21 <ihope> What is self (Self self)?
10:48:49 <augustss> @djinn-add data S a = S (State -> (State, a))
10:49:01 <augustss> @djinn S a -> (a -> S b) -> S b
10:49:10 <lambdabot> f a b =
10:49:12 <lambdabot>     case a of
10:49:14 <lambdabot>     S c -> S (\ d ->
10:49:16 <lambdabot>               case c d of
10:49:18 <lambdabot>               (e, f) -> case b f of
10:49:20 <lambdabot>                         S g -> g e)
10:49:25 <ihope> Autospam.
10:49:49 <ihope> @djinn (a -> b -> c -> d -> e) -> (a -> b -> c -> d) -> (a -> b -> c) -> (a -> b) -> a -> e
10:49:49 <lambdabot> f a b c d e = a e (d e) (c e (d e)) (b e (d e) (c e (d e)))
10:50:16 <ihope> @djinn (a -> b -> c -> d -> e -> f -> g) -> (a -> b -> c -> d -> e -> f) -> (a -> b -> c -> d -> e) -> (a -> b -> c -> d) -> (a -> b -> c) -> (a -> b) -> a -> g
10:50:16 <lambdabot> f a b c d e f g =
10:50:16 <lambdabot>     a g (f g) (e g (f g)) (d g (f g) (e g (f g))) (c g (f g) (e g (f g)) (d g (f g) (e g (f g)))) (b g (f g) (e g (f g)) (d g (f g) (e g (f g))) (c g (f g) (e g (f g)) (d g (f g) (e g (f g)))))
10:50:36 <ihope> Add h, i and j and it'll be eight times as long.
10:50:43 <augustss> pjd: I'm sure there are things that could be done for certain classes of recursive functions.  But I've not investigated
10:50:56 <littledan> @djinn a -> b
10:50:57 <lambdabot> -- f cannot be realized.
10:51:56 <ihope> @free f :: Int -> Int -> Int
10:51:57 <lambdabot> f = f
10:52:10 <ihope> Wow, what an entirely unobvious theorem.
10:52:19 <ihope> I bet the proof must be really clever.
10:52:22 <pjd> heh
10:53:00 <ihope> @free f :: ()
10:53:01 <lambdabot> f = f
10:53:08 <ihope> @free f :: a -> ()
10:53:08 <lambdabot> f = f . g
10:53:09 <oerjan> i don't think you get unobvious theorems without polymorphism
10:53:18 <ihope> Whew, finally.
10:56:07 <ihope> @djinn (a -> b -> c -> d -> e -> f -> g -> h -> i) -> (a -> b -> c -> d -> e -> f -> g -> h) -> (a -> b -> c -> d -> e -> f -> g) -> (a -> b -> c -> d -> e -> f) -> (a -> b -> c -> d -> e) -> (a -> b -> c -> d) -> (a -> b -> c) -> (a -> b) -> a -> i
10:56:07 <lambdabot> f a b c d e f g h i =
10:56:07 <lambdabot>     a i (h i) (g i (h i)) (f i (h i) (g i (h i))) (e i (h i) (g i (h i)) (f i (h i) (g i (h i)))) (d i (h i) (g i (h i)) (f i (h i) (g i (h i))) (e i (h i) (g i (h i)) (f i (h i) (g i (h i))))) (c i
10:56:07 <lambdabot> (h i) (g i (h i)) (f i (h i) (g i (h i))) (e i (h i) (g i (h i)) (f i (h i) (g i (h i)))) (d i (h i) (g i (h i)) (f i (h i) (g i (h i))) (e i (h i) (g i (h i)) (f i (h i) (g i (h i)))))) (b i (h i) (
10:56:07 <lambdabot> g i (h i)) (f i (h i) (g i (h i))) (e i (h i) (g i (h i)) (f i (h i) (g i (h i)))) (d i (h i) (g i (h i)) (f i (h i) (g i (h i))) (e i (h i) (g i (h i)) (f i (h i) (g i (h i))))) (c i (h i) (g i (h
10:56:09 <lambdabot> i)) (f i (h i) (g i (h i))) (e i (h i) (g i (h i)) (f i (h i) (g i (h i)))) (d i (h i) (g i (h i)) (f i (h i) (g i (h i))) (e i (h i) (g i (h i)) (f i (h i) (g i (h i)))))))
10:56:18 <ihope> Now we're getting something.
10:56:21 <phobes> Can anyone recommend a good book on category theory?
10:56:41 <dpiponi> phobes: a basic book for computer scientists is the one by pierce
10:56:52 <opqdonut> how would you represent actions of an rpn calculator? atm it's operation :: Stack -> (Stack,IO ())
10:57:15 <dpiponi> phobes: In fact, it's called "Basic Category for COmputer Scientists"
10:57:26 <phobes> He's the TAPL guy, right?
10:57:31 <dpiponi> yes
10:57:32 <augustss> opqdonut: does the calculator need to do arbitrary IO?  Or just output something
10:57:39 <opqdonut> output
10:57:42 <opqdonut> and quit :)
10:57:47 <dpiponi> It goes as far as adjunctions but doesn't mention monads.
10:57:57 <phobes> dpiponi: thanks - do you have a suggestion for something more advanced?
10:58:01 <opqdonut> augustss: variables will probably be implemented too
10:58:23 <augustss> opqdonut: I'd avoid IO in the type
10:58:31 <opqdonut> me too
10:58:31 <takamura> hi
10:58:42 <littledan> hey, takamura!
10:58:51 <opqdonut> should i special-case quitting and printing in the command handler then?
10:58:53 <ihope> Hmm.
10:58:58 <takamura> hello littledan
10:59:01 <dpiponi> phobes: I'm (very slowly) reading McLarty's "Elementary Categories, Elementary Toposes". I like it. Again, little or nothing on monads.
10:59:06 <augustss> opqdonut: you can make the second component be a list of things to print
10:59:16 <phobes> dpiponi: thanks
10:59:20 <augustss> opqdonut: and special case quitting
10:59:36 <pjd> phobes: what does your interest stem from?
10:59:37 <opqdonut> yep, i think that'd be a good solution
10:59:59 <phobes> pjd:  programming language semantics
11:00:04 <augustss> opqdonut: you could also try a writer monad
11:00:16 <opqdonut> StateT Writer?-)
11:00:28 <pjd> phobes: awesome
11:00:29 <opqdonut> no, not that
11:00:56 <augustss> opqdonut: sounds reasonable if you need state for the variables
11:01:04 <opqdonut> yep okay :)
11:01:11 <Japsu> Hmm
11:01:14 <Japsu> hpaste fails to announce
11:01:27 <Japsu> This is the code opqdonut is statefying: http://hpaste.org/2371
11:01:33 <oerjan> opqdonut: you can do each part with monad transformers.  ErrorT would give you quit, the rest can be StateT and/or WriterT
11:01:33 <augustss> opqdonut: you can start with Writer, and then add state later
11:02:05 <opqdonut> well, this is Japsu's code, i was trying to give constructive criticism on another channel
11:02:12 <littledan> there's no need for StateT; just make the Stack type more complicated, holding the variables as well as the stack
11:02:15 <swiert> phobes: I quite like Steve Awodey's "Category Theory".
11:02:16 <opqdonut> Japsu: so what do you think about writerising it?
11:02:24 <Japsu> Erf, more scary monads :<
11:02:34 <pjd> phobes: http://www.case.edu/artsci/math/wells/pub/ctcs.html
11:02:36 <lambdabot> Title: Category Theory for Computing Science
11:02:40 <opqdonut> Japsu: writer is just a string state that gets appended to :)
11:02:47 <Japsu> I haven't even grokked State nor StateT yet
11:02:55 <augustss> Japsu: do it without monads first
11:03:00 <swiert> phobes: It covers quite a lot of stuff, but the examples are much more down to earth than Mac Lane.
11:03:01 <phobes> swiert: thanks, I'll look at it
11:03:01 <pjd> i haven't read it, so i don't know how good it is
11:03:01 <jbjohns> Did Haskell win ICFP again this year?
11:03:16 <phobes> afk sec
11:03:32 <swiert> jbjohns: The winner will be announced at ICFP.
11:04:05 <jbjohns> right, but they have the scoreboard up, it's not possible to determine it from there?  I obviously couldn't, but I thought people "in the know" might. :)
11:04:46 <pjd> phobes: http://www.cs.le.ac.uk/people/akurz/books.html has a bunch of online category theory books and material
11:04:47 <lambdabot> Title: Electronically Available Books and Other Sources (mainly Category Theory)
11:04:58 <swiert> jbjohns: No. It's a closely guarded secret.
11:05:05 <oerjan> jbjohns: the scoreboard doesn't give the ordering of the top 20, iirc
11:05:15 <jbjohns> ah ok
11:06:04 <oerjan> i don't even know if anyone actually solved the problem completely, does anyone else?
11:06:18 <shapr> swiert: Hey, have you tried that STM sudoku on a multicore? I got 116% with -N2 !
11:06:44 <swiert> shapr: Nope. I'm stuck with a single core laptop...
11:07:01 <takamura> There is some haskell compiler that runs on PDAs? (or can be ported more or less easily)
11:07:04 <swiert> But that's a pretty cool speadup!
11:07:11 <shapr> Yeah, I was impressed.
11:07:58 <CosmicRay> takamura: I ran hugs on my Zaurus
11:08:07 <CosmicRay> don't think it's grunty enough for ghci though
11:08:08 <takamura> great :)
11:08:18 <takamura> and ghc?
11:08:28 <CosmicRay> that's what I meant
11:08:31 <takamura> ah
11:08:35 <swiert> I think most of the speedup isn't due to STM though...
11:08:45 <takamura> I wan't a compiler, not an interpreter
11:08:46 <elliottt> ah, finally something to do with my zaurus :)
11:08:54 <takamura> I want to produce executables
11:09:04 <CosmicRay> why does it matter?
11:09:10 <jbjohns_> ugh, stupid train network
11:09:23 <swiert> It's probably due to the forking off of new threads when you start building up the search tree.
11:10:57 <takamura> CosmicRay, did you try yhc on Zaurus?
11:11:16 <CosmicRay> no, I didn't
11:12:04 <takamura> mmm, maybe is better to ask in the compilers' mailing lists
11:12:18 <sjanssen> takamura: hugs is probably more useful than yhc, anyway
11:12:32 <sjanssen> it supports more language features, probably has fewer bugs, etc.
11:12:50 <sjanssen> I suppose yhc might be faster, though
11:13:24 <takamura> but i want to produce executable programs, for my clients
11:13:27 <conal> shapr: do you IRC on your nokia 770?  have a client you like?
11:14:00 <takamura> probably i will have to wait some years more
11:14:09 <takamura> to have a compiler in PDAs
11:14:27 <pierre-> i recently saw something about porting ghc to arm
11:14:45 <takamura> where? in the mailing list?
11:15:14 <pierre-> in ghc trac, as i remember
11:15:25 <takamura> i found it
11:15:42 <takamura> http://hackage.haskell.org/trac/ghc/wiki/ArmLinuxGhc
11:15:44 <lambdabot> Title: ArmLinuxGhc - GHC - Trac
11:15:51 <phobes> pjd: thanks
11:15:58 <pierre-> but i wonder if there's something usable about it
11:16:49 <pierre-> i'm also interested to have ghc on my Z :-)
11:17:29 <takamura> i will look further into it, it seems promising
11:17:41 <shapr> conal: xchat is the only irc client I've seen for Maemo (the nokia internet tablet platform) and it's okay. It would be much better if the fullscreen button worked. I suspect it's just fine if you have a bluetooth keyboard. It's hard to chat with any speed on a touchscreen keyboard.
11:18:07 <sjanssen> wouldn't space be a problem with ghc on a zaurus?
11:18:39 <shapr> takamura: From what I've heard, hugs runs fine on the Nokia 770, and I know stepcut built ghc 6.5 for the Nokia 770.
11:18:52 <phobes> swiert:  So you've used both Mac Lane and Awodey and prefer the latter?  Do you think they cover roughly the same material at the same depth?
11:18:54 <sjanssen> ghc takes 167MB on my system, and you've got to install gcc too
11:18:54 <pierre-> sjanssen: there even were successful projects to run kde on Z, i think space is not a big issue :-)
11:18:55 <conal> shapr: thanks.  no full-screen for xchat? :P
11:19:11 <shapr> conal: Not fullscreen in the maemo sense of the word.
11:19:23 <sjanssen> I suppose you can just buy a 2GB SD card
11:19:30 <shapr> Or 4GB
11:19:33 <conal> shapr: sure.  do you still use your 770?
11:19:38 <swiert> phobes: Yes. I've studied Awodey quite closely and read parts of Mac Lane.
11:19:53 <shapr> conal: I gave it to my girlfriend while her laptop is down for repairs, so it's in Stockholm now.
11:20:05 <swiert> phobes: depending on your background (I assume you're not a hard-core mathematician), I would recommend Awodey over Mac Lane.
11:20:22 <swiert> to understand category theory, you need good examples that you are already familiar with.
11:20:41 <conal> shapr: oh.  i haven't used mine in quite a while.  coincidentally, it lives in my girlfriend's purse.
11:20:47 <phobes> swiert:  I actually am a mathematician :)
11:20:55 <shapr> sjanssen: I'm pretty sure the Nokia 800 would support at least 8gb SD cards, and it's quite likely that 16 or 32 gb SD cards would work (don't know if they exist) with some kernel hacking..
11:21:02 <swiert> when Mac Lane says something is the tensor product over the modulus of a ring (or something along those lines) that doesn't mean much to me.
11:21:16 <swiert> The Awodey book has much more "down-to-earth" examples.
11:21:21 <phobes> swiert:  but I might still prefer Awodey
11:21:24 <swiert> It's still not an easy book to read.
11:21:39 <phobes> ok thanks
11:21:41 <shapr> conal: I used mine very much when I had it, but I'm unhappy that the bluetooth and wifi firmware is binary blobs, and I'm unhappy that Nokia dropped support for the 770.
11:21:47 <swiert> Mac Lane does cover a few advanced topics (notably ends, coends, and Kan extensions) that aren't in Awodey.
11:22:08 <swiert> As a first textbook on Category Theory, I'd definitely recommend Awodey.
11:22:23 <swiert> If you get hooked, you can always have a look at Mac Lane later on.
11:22:30 <phobes> swiert: Yep - exactly what I was thinking.  Thanks
11:22:56 <phobes> much eaiser to do the abstract math once you've built an intuition for the more concrete cases
11:22:57 <swiert> phobes: np. Good luck!
11:23:24 <phobes> swiert: thanks
11:24:53 <pjd> phobes: is this general interest, or are you planning some interesting work?
11:25:29 <phobes> pjd:  I'd love to do interesting work ... but right now this is a side project :)
11:55:10 <shapr> sjanssen: Ah, I think I know how to make something like ohloh that would be very much more useful to everyone.
11:56:02 <Nafai> Hi shapr!
11:56:14 <shapr> hiya Nafai!
12:02:03 <Japsu> @users
12:02:04 <lambdabot> Maximum users seen in #haskell: 419, currently: 412 (98.3%), active: 8 (1.9%)
12:04:26 <shapr> yay!
12:04:30 <shapr> Lotsa #haskell people!
12:16:39 <tuomov> Is it possible to GC Ptrs (or something like them)?
12:17:00 <sjanssen> tuomov: try Foreign.ForeignPtr
12:20:30 <tuomov> yes, that stuff seems to do it
12:21:44 <alexj> @seen glguy
12:21:44 <lambdabot> glguy is in #haskell. I last heard glguy speak 2h 51m 7s ago.
12:27:17 <ndm> @karma+ augustss -- writing exp3_8, which Supero optimises 4 times faster than GHC
12:27:18 <lambdabot> augustss's karma raised to 4.
12:28:06 * roconnor hopes Supero will optimise his alien DNA interpreter
12:28:07 <xerox> What package does contain ctrl.o?  Debian package.
12:28:14 <Lemmih> What's Supero?
12:28:59 <augustss> ndm: does exp3_8 depend on inputs?  otherwise you could make it infinitely faster
12:29:19 <augustss> I can't remember, it was a long time since I wrote it
12:29:26 <ndm> augustss: it depends on the 8 (which is actually 10)
12:29:33 <ndm> Lemmih: my optimiser
12:29:45 <augustss> ndm: ok
12:29:51 <ndm> augustss: you wrote it as a pure 3 ^ 8, since then someone parameterised the 8 as a command line arg
12:29:59 <augustss> good
12:30:09 <ndm> of course you could optimise it to a couple of integer instructions, even not knowing hte param
12:30:21 <xerox> ...or ctr1.o ?
12:30:28 <augustss> ndm: yeah, but that would take major trickery
12:30:42 <ndm> augustss: indeed, i do the same basic operations, just faster
12:30:48 <sorear> xerox: Architecture?
12:31:01 <xerox> sorear: x86, a newly installed ubuntu
12:31:19 <sorear> xerox: so this file is installed?
12:31:30 <augustss> ndm: I hope supero scales.  it feels right, somehow
12:31:52 <xerox> sorear: seems not, ghc configure fails with "gcc can't produce binaries", and config.log shows that gcc can't find crt1.o
12:31:59 <Lemmih> @where supero
12:32:00 <lambdabot> I know nothing about supero.
12:32:09 <sorear> xerox: oh, crt1!
12:32:34 <ndm> augustss: i hope it does, the current version won't, but i know what needs doing to make it scale
12:32:37 <sorear> xerox: that's probably in the gcc/binutils somewhere
12:32:42 <conal> @where+ supero http://www-users.cs.york.ac.uk/~ndm/supero
12:32:43 <lambdabot> Done.
12:32:53 <ndm> @karma+ conal -- beat me to it
12:32:53 <lambdabot> conal's karma raised to 2.
12:33:01 <sorear> xerox: you want the whole "build-essential" virtual package, at least on Debian
12:33:13 <conal> ndm: :)
12:33:20 <ndm> what i like is that Supero is one pass, none of these staged optimisations
12:33:47 <xerox> sorear: binutils is installed, no -essential present in the package database. -static is also installed.
12:33:47 <ndm> Lemmih: the paper on Supero will be out in 10 days time, so if you want to know more, best wait for then
12:34:13 <sorear> xerox: You apparently need libc6-dev.
12:34:40 <xerox> ah good, that one wasn't installed.
12:34:55 * sorear recommends to use the virtual packages
12:35:06 * johnnowak seconds that
12:35:41 <sorear> augustss: Last time I read the Supero papers, it was a simple catamorphic-ish traversal over the static reference graph, so it should be possible to add it as just another Simplifier phase
12:36:12 <pejo> Are there papers on (old?) incarnations of Supero?
12:36:38 <augustss> sorear: if you have enough infrastructure.  you need "source" for everything
12:37:00 <sorear> augustss: main complication being that ndm's termination conditions work by capping code duplication, but stuff like that has been extensively studied in the context of cross-module inlining, so shouldn't be a big deal
12:37:34 <phobes> If I write out my own ST implementation, will that likely be considerably slower than the standard library version?
12:37:36 <sorear> augustss: we have the infrastructure.  .hi files already store the bodies of all inlinable functions
12:37:41 <ndm> sorear: its changed quite a bit since you last read it, unless you have read something i wrote since 4:30pm
12:37:52 <augustss> sorear: all functions must be available
12:38:14 <augustss> at least for maximum effectiveness
12:38:23 <ndm> augustss: if they move to my suggestion of -ddump-core just means shoving everything into .hi, then they get it virtually for free
12:39:55 <augustss> ndm: but first you have to make scale :)
12:40:21 <ndm> augustss: exp3_8 takes 3 seconds, running in GHCi
12:40:25 <ndm> to compile
12:40:39 <ndm> at least 90% of that time is spent in the pretty printer for the output code!
12:41:03 <pejo> augustss, I think a lot of users are prepared to wait for a super optimized binary 'in the end'.
12:41:11 <ndm> i know that doesn't mean scale, of course, but it is dead quick on small examples
12:41:23 <augustss> well, tiny benchmarks is one thing, thousands of lines is another
12:42:06 <ndm> in Haskell, the second you add two numbers you pull in 1000's of lines, esp with Show being a parent of Num
12:42:23 <ndm> and if you pull in the rational class, you pull in loads of complex number stuff, its really annoying
12:42:29 <augustss> well, not that many parts of that code is used
12:42:49 <ndm> true, but the scale up isn't as big as you might expect
12:42:49 <olsner> Show is a parent of Num? sounds like a kludge
12:42:57 <ndm> olsner: it is
12:43:00 <ndm> @info Num
12:43:00 <lambdabot> (Num)
12:43:02 <augustss> you should pic something medium sized next
12:43:14 <ndm> nobench, starting small and working large is my plan
12:43:23 <ndm> plus i'm still fighting with CAF's :-)
12:43:25 <tuomov> Num is a kludge
12:43:32 <Heffalump> what's wrong with CAFs?
12:43:41 <tuomov> you should have AdditiveGroup first, and then Ring, ...
12:43:53 <tuomov> or something like that
12:43:53 <ndm> Heffalump: you have to treat them very differently, since you can't inline a CAF, but can inline anything else
12:44:06 <ndm> Heffalump: but if you don't inline a dictionary CAF, you loose big
12:44:26 <PaulAJ> tuomov: I'd say Num is an engineering compromise between the full Ring/SemiRing/NearRing bit and just listing all the operations in one class.
12:44:48 <ndm> realistically, I think I just need a "expensiveCaf" function, and only stop inlining those which are expensive
12:45:10 <tuomov> yeah, it should be easier to refer to the "inheritance" hierarchy
12:45:13 <PaulAJ> I've never looked at the full workup, but I kind of suspect you would wind up with a class for every possible combination of operations.
12:45:28 <xerox> no libreadline4 in ubuntu as well, ghc 6.6.1 is compiled for that, oh well.  Easy to solve anyway.
12:45:38 <tuomov> it should be necessary to type all of it in function type sigs etc.
12:45:47 <tuomov> the compiler should be able to infer things from the requirements of a class
12:46:14 <PaulAJ> I recall the Eiffel people having essentially the same debate.
12:48:11 <tuomov> +not
12:51:06 <Heffalump> ndm: presumably you mean CAFs at any level, not just top-level ones?
12:52:06 <SamB> I thought all CAFs were at the top level
12:52:43 <SamB> well. after being floated out, anyway.
12:53:17 <SamB> possibly GHC has warped my brain
12:54:52 <Heffalump> I can never remember the terminology either. But the y in 'f x = let y = x*x in ...' is presumably just as much of an issue.
12:56:32 <dolio> tuomov: The problem is that many people like to write top-level type signatures, so even though the compiler could infer all the constraints, in practice, people would have to type a lot.
12:57:02 <sjanssen> there are also cases where type signatures are required
13:01:37 <Heffalump> roll on partial type signatures
13:02:11 <sjanssen> Heffalump: partial type signatures don't help with really bloated contexts
13:03:54 <xerox> Are partial type signatures anywhere nearly implemented? I sometims would have liked to specify just part of the typesig and have the rest inferred by ghc. I guess I usually do that by applying (undefined::type) anyway.
13:03:56 <dolio> Class aliases could help, I suppose (and you can mimic that aspect today), but there's theoretically an explosion of those.
13:04:19 <dolio> I suppose there might just be a few typicially used class aliases.
13:05:45 <sorear> xerox: Hugs and OCaml support flexible type variables, so  _ -> _  is a good type for id or const but not False
13:06:36 <sorear> in Hugs, you can't name the wildcards, in OCaml (iirc) all type varibles are flexible
13:06:53 <Heffalump> sjanssen: they do if you can just leave in ... in the context, surely?
13:07:34 <Heffalump> sorear: is that a suitable type for (+2) ?
13:07:42 <sorear> Heffalump: Yes.
13:07:49 <sjanssen> Heffalump: true
13:08:11 <sjanssen> Heffalump: perhaps we'll all just write "foo :: ... => ..." to skirt the MR :)
13:08:13 <sorear> Heffalump: Flexible try variables are checked using unification, not subsumption as rigid ones are.
13:08:37 * sorear puts in a vote for Hughes' = / :=  proposal
13:09:10 <sjanssen> sorear: and which binder has the MR attached to it?
13:09:42 <sorear> sjanssen: Neither.  := binds values monomorphically.  = binds functions polymorphically.
13:10:22 <sorear> sjanssen: it's like the ML value restriction, but expressed in the syntax rather than special-case typing rules
13:10:57 <sjanssen> ah, that's an interesting perspective
13:12:43 <Heffalump> or you could just remove the restriction and not bother with :=
13:12:58 * doserj nods
13:13:46 <sorear> I think a purely call-by-name language would be extremely elegant, but it would not warrant the name Haskell'.
13:14:10 <sorear> Laziness is too entrenched to discard now.
13:14:23 <opqdonut> "purely call-by-name" would imply what?
13:14:29 <Heffalump> is that connected to the monomorphism restriction?
13:14:30 <mrd> no memoization?
13:14:30 <DRMacIver> ML's value restriction is exprssed in the syntax rather than special case typing rules isn't it?
13:14:39 <sorear> opqdonut: let x = 2 * 2 in x + x   multiplies twice
13:14:56 <opqdonut> sorear: ah, no sharing
13:15:09 <oerjan> DRMacIver: yeah, it replaced an older system which was based on types though
13:15:14 <DRMacIver> Ah
13:15:17 <sorear> DRMacIver: I thought there was some funny stuff in the typing rules like IF the rhs is one of these forms, skip generalization
13:15:31 <sorear> DRMacIver: whereas Hughes gives us two binding constructs
13:15:52 <DRMacIver> sorear: Mm. As far as I know, the value restriction is that top level val declarations can't be polymorphic. Am I thinking of the wrong thing?
13:16:34 <DRMacIver> (but top level fun declarations can be. Hence why I say it's expressed in the syntax)
13:16:44 <sorear> DRMacIver: Right thing, but I was under the impression it tried to be a bit cleverer and allow generalization of Î²-normal forms
13:17:59 <DRMacIver> sorear: I think, as oerjan suggests, that was proposed at one point and then people realised it was a pain to implement and didn't seem to make much practical difference in almost all existing code, so they standardised on being less clever.
13:18:08 <DRMacIver> (That's roughly how I recall the story anyway)
13:18:23 <sorear> DRMacIver: Now you're thinking of imperative type variables, I think
13:18:39 <xerox> This isn't the right evening. Gtk2hs fails building: ghc-6.6.1: unknown package: glib-0.9.12.2
13:18:39 <DRMacIver> Possibly.
13:18:44 <oerjan> sorear: that's what i was referring to, anyhow
13:18:56 <DRMacIver> But those are strongly related to the value restriction aren't they?
13:19:04 <DRMacIver> In that the value restriction basically comes about because reference types exist.
13:20:01 <DRMacIver> Or am I totally confused? :)
13:21:06 <oerjan> DRMacIver: it's like how unsafePerformIO is type unsafe in Haskell
13:22:38 <xerox> Anybody knows the solution?
13:22:47 <sorear> xerox: install glib?
13:23:10 <xerox> sorear: it's one of the gtk2hs packages it is compiling
13:23:19 <sorear> (since ghc complained, it's a haskell package)
13:23:32 <sorear> xerox: right; does gtk2hs have an unmet dependency?
13:23:33 <Heffalump> but values that happened to be monomorphic would still be shared. You just don't force them to be.
13:24:01 <xerox> sorear: gtk2hs does not build with cabal, but it has got this huge automake build
13:24:09 <HWSOD> hey what does the "ambigous type variable 'a' in the constraint: 'Random a' ..." mean?
13:24:22 <xerox> sorear: I don't exactly know where to try to fix this issue.
13:24:39 <sorear> HWSOD: You're trying to generate random numbers and use them in a comparison.
13:25:10 <sorear> HWSOD: If this is the case, add more types, like (0::Int)
13:25:11 <Heffalump> or something similar where the result isn't of the same type as the inputs
13:27:21 <oerjan> > random $ newStdGen 1
13:27:25 <lambdabot>  Couldn't match expected type `t -> a'
13:27:53 <oerjan> :t newStdGen
13:27:55 <lambdabot> IO StdGen
13:28:28 <oerjan> > random $ mkStdGen 1
13:28:30 <lambdabot>  (-604496784,1054756829 1655838864)
13:28:38 <xerox> > random (mkStdGen 1)
13:28:40 <lambdabot>  (-604496784,1054756829 1655838864)
13:29:06 <oerjan> lambdabot's defaulting is too nice
13:29:11 <HWSOD> Thanks!
13:34:09 <tsdh> Hi.
13:34:25 <phobes> Why can the MR problem not be solved by just binding dictionaries earlier?
13:34:51 <phobes> Like in the example:  f xs = (len,len) where len = genericLength xs
13:35:13 <phobes> couldn't that be implemented as:  f dict xs = (len, len) where len = genericLength dict xs ?
13:35:45 <tsdh> Would changing a function type from "(NamedWindow -> X ()) -> X ()" to "(NamedWindow -> X a) -> X a" break existing usages, or does "X ()" match "X a", too?
13:35:57 <b_jonas> hi. is understanding lazy semantics essential for learning haskell?
13:36:16 <Heffalump> that's not a very typical example
13:36:26 <oerjan> b_jonas: probably
13:36:27 <Heffalump> v = genericLength [1,2,3]
13:36:29 <Heffalump> is a better one
13:36:29 <Cale> b_jonas: yep, at some point you'll want to understand how things are evaluated
13:36:36 <phobes> b_jonas:  the lazy approach would be to just start programming and learn laziness when needed :)
13:36:39 <byorgey> tsdh: should be ok, X () matches X a.
13:36:44 <Igloo> phobes: Because that would actually be    f d1 d2 xs = (l1, l2) where l1 = genericLength d1 xs; l2 = genericLength d2 xs
13:36:48 <tsdh> byorgey: Thanks.
13:36:53 <Igloo> (without the MR)
13:37:02 <Cale> tsdh: () is a type just like any other -- it only has a single defined value, which is ()
13:37:23 <b_jonas> I'm asking because I've heared the tail recursion things work differently in lazy languages in practice
13:37:29 <b_jonas> so you have to write loops in a different way
13:37:38 <b_jonas> but I'm not sure how true that is
13:37:48 <Cale> b_jonas: Right, I can explain that
13:37:56 <tsdh> Cale: Thanks, I'm new to haskell and sometimes monads make me frightened. ;-)
13:38:09 <phobes> Igloo: "would actually be..."?   Why do we need two dictionaries if there's only one Num type involved?
13:38:10 <b_jonas> Cale: good, thanks
13:38:23 <glguy> we really need to find the person that keeps saying that monads are scary and sack him
13:38:36 <lament> Monads are scary!!
13:38:44 --- mode: ChanServ set +o glguy
13:38:44 <byorgey> b_jonas: pay attention, Cale is one of the best teachers in here =)
13:38:47 <b_jonas> yeah, monads are the other thing I have to learn, especially, how they can do interactive io
13:38:48 --- kick: lament was kicked by glguy (sacked)
13:38:55 <byorgey> hehe
13:38:56 --- mode: glguy set -o glguy
13:39:03 <oerjan> O_O
13:39:04 <Cale> b_jonas: The basic thing is that function parameters don't get evaluated. Lazy evaluation is a combination of two things: outermost-first evaluation, and sharing of computation results which came from duplication of a function parameter in the body of the function
13:39:20 <lament> sorry, i mean monads are.. cute and cuddly!
13:39:35 <Cale> (function parameters don't get evaluated before the end of the tail-recursive loop, I should say)
13:39:50 <Cale> Let's have a look at how foldl gets evaluated on a simple example...
13:39:54 <Cale> foldl (+) 0 [1,2,3]
13:39:55 <byorgey> lament: I think you mean warm and fuzzy
13:40:02 <Cale> = foldl (+) (0+1) [2,3]
13:40:08 <Cale> = foldl (+) ((0+1)+2) [3]
13:40:13 <lament> byorgey: something can be worm and fuzzy, and scary too
13:40:14 <Cale> = foldl (+) (((0+1)+2)+3) []
13:40:20 <Cale> = ((0+1)+2)+3
13:40:21 <lament> byorgey: but cute, cuddly and scary?
13:40:21 <oerjan> lament: the technical term is warm and fuzzy
13:40:25 <Cale> = (1+2)+3
13:40:28 <Cale> = 3+3
13:40:29 <Cale> = 6
13:40:30 <lament> *warm
13:41:01 <oerjan> fuzzy worms _are_ pretty scary.
13:41:02 <Igloo> phobes: That has type (Num b, Num c) => [a] -> (b, c) without the MR
13:41:08 <Cale> While the first part of that is still going to be a tight loop, it's a tight loop which builds up a large expression -- whose size is on the order of the size of the original list.
13:41:11 <byorgey> lament: sure, like a cute, cuddly, warm, fuzzy, RABID BUNNY
13:41:20 <ndm> Heffalump: no, only top level CAF's, i have a convincing story for let bindings
13:41:39 <Heffalump> oh?
13:41:44 <b_jonas> right, but you can't evaluate a foldl without building up something anyway
13:41:55 <glguy> http://www.googlism.com/index.htm?ism=monad&type=2
13:41:56 <lambdabot> Title: Googlism
13:42:00 <b_jonas> even though it can be a list or a call stack instead of a lazy expression
13:42:18 <glguy> "monad is capable of creating twelve souls
13:42:21 <ndm> Heffalump: yes, let bindings are preserves unless they reduce to a lambda, a small constant, or are used only once in the program
13:42:24 <Cale> In a strict (innermost-first) language, the parameter gets evaluated on each step
13:42:27 <phobes> Igloo: I see the point.  Thanks
13:42:57 <Heffalump> doesn't that cause your supercompiler to leave a lot of stuff unhandled?
13:43:02 <b_jonas> yep
13:43:12 <b_jonas> but does that actually make any difference?
13:43:19 <Cale> foldl (+) 0 [1,2,3] = foldl (+) (0+1) [2,3] = foldl (+) 1 [2,3] = foldl (+) (1+2) [3] = foldl (+) 3 [3] = foldl (+) (3+3) [] = foldl (+) 6 [] = 6
13:43:35 <Cale> It can, yeah.
13:43:48 <b_jonas> with foldl I mean
13:43:57 <ndm> Heffalump: not really, it only leaves stuff which is genuinely shared unhandled, which is the right behaviour
13:44:13 <ndm> i keep the let binding around for a while, while optimising inside it
13:44:22 <Cale> Absolutely, with lazy evaluation, foldl is going to use O(n) extra space while evaluating than in the strict case.
13:44:24 <ndm> so it has quite a lot of chance to get removed
13:44:33 <Heffalump> fair enough
13:44:59 <Heffalump> are you publishing this somewhere, btw?
13:45:09 <b_jonas> oh, so I'm confusing foldl and foldr
13:45:16 <ndm> yep, IFL
13:45:21 <Cale> What's more, if the expression it builds is very large, there's some danger that the subsequent evaluation once the end of the list is reached will overflow the stack.
13:45:21 <ndm> submission deadline of 10 days
13:45:39 <Cale> foldl f z [] = z
13:45:41 <ndm> expect a draft paper to appear on my website after the deadline, and once i've slept
13:45:48 <Cale> foldl f z (x:xs) = foldl f (f z x) xs
13:46:15 <ndm> although i may well blog a few benchmarks tomorrow
13:46:24 <b_jonas> ok
13:46:32 <Cale> foldl is the tail recursive one
13:46:37 <Cale> foldr f z [] = z
13:46:45 <Heffalump> it should be good POPL material once it's polished
13:46:49 <Cale> foldr f z (x:xs) = f x (foldr f z xs)
13:46:50 <b_jonas> so what do you do in a lazy language like haskell if you'd like to avoid this?
13:47:00 <ndm> yeah, its quite a bit of polish away
13:47:05 <ndm> needs scaling to be sorted first
13:47:15 <Cale> Well, you either use a strictified variant of foldl, or in many cases, foldr is actually better.
13:47:25 <ndm> i only got as large as primes yesterday, and exp3_8 only happened at 6pm
13:48:03 <xerox> sorear: the rpoblem was that gtk2hs buildsystem doesn't interact well with make -j3
13:48:07 <Cale> foldr has the advantage that if f can produce part of its result by only looking at its first parameter (meaning that the second parameter might not be needed), then the foldr might just stop short of the end of the list.
13:48:18 <b_jonas> hmm
13:48:23 <Cale> It works with infinite lists, even.
13:48:27 <Heffalump> what problems do you run into scaling it?
13:48:39 <olsner> thread-unsafe makefiles ;-)
13:48:42 <ndm> termination, immature code, a few special cases
13:48:48 <Cale> > foldr (\x y -> x : x : y) [] [1..]
13:48:50 <lambdabot>  [1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,13,14,14,15,15,16,...
13:48:56 <ndm> nothing fundamental, just things which take a bit of bedding down and experimentation
13:49:06 <b_jonas> so the normal direction is the reverse from strict languages in _both_ processing and creating lists
13:49:07 <ndm> i can actually give a termination proof for my optimiser, which GHC can't
13:49:14 <ndm> because GHC doesn't terminate
13:50:01 <Cale> It makes some sense that things would be flipped, because the evaluation order is inside out from what it is in a strict language.
13:50:03 <b_jonas> because you fold them from head to tail and build them from head to tail
13:50:14 <b_jonas> in haskell that is
13:50:15 <Cale> right
13:50:44 <b_jonas> but shouldn't lazyness also make it easier to do them in the other direction?
13:51:19 <Cale> Well, foldl doesn't work at all on infinite lists, certainly.
13:51:25 <b_jonas> because you can use a "strict foldl", whatever that means, if you want to process from tail to head
13:51:41 <Cale> It will never finish, always calling itself over and over looking for the end of the list.
13:51:47 <b_jonas> but I don't know how a strict anything works in a completely lazy language
13:51:51 <Cale> Oh, sure, you can do that :)
13:51:58 <Cale> Okay, so there's a primitive:
13:52:02 <Cale> seq x y
13:52:30 <Cale> when evaluated, will ensure that x is evaluated (to determining the top level constructor) before resulting in y
13:52:42 <b_jonas> because I know how you can bulid lists in both direction in a partially lazy language like prolog
13:53:13 <b_jonas> I see
13:53:28 <Cale> seq x y, in most cases, is like using case to pattern match against x, but then return y regardless
13:53:40 <b_jonas> yep
13:53:52 <Cale> (so it mostly doesn't have to be primitive, but it turns out that's convenient)
13:53:57 <b_jonas> and it works for primitive types like numbers too, right?
13:53:58 <lament> so with seq you don't really need monads?
13:53:59 <Cale> So we can write
13:54:06 <Cale> lament: huh?
13:54:09 <lament> i mean for IO
13:54:16 <Cale> lament: It just controls the evaluation order
13:54:27 <Cale> It has nothing to do with execution of effects
13:54:44 <lament> doesn't the io monad just control the evaluation order?
13:54:45 <Cale> b_jonas: right
13:55:05 <b_jonas> ok, go on
13:55:07 <oerjan> lament: actually in theory it could evaluate y first, then x, then return y
13:55:17 <Cale> lament: no, values of type (IO a) should be thought of as descriptions of what to do.
13:55:36 <Cale> and yeah, it doesn't *completely* specify the order
13:55:45 <phobes> oerjan:  in theory it could evaluate y then x, so long as it only does it finitely many times :)
13:56:07 <Cale> So let's write a strict version of foldl
13:56:12 <Cale> foldl' f z [] = z
13:56:15 <Cale> that's the same
13:56:36 <Cale> foldl' f z (x:xs) = let y = f z x in y `seq` foldl' f y xs
13:57:45 <Cale> This is still tail recursive, but it will evaluate f z x (by one step) before returning foldl' f y xs. Theoretically, it could recurse first, but any nonidiotic compiler will evaluate y first :)
13:58:22 <b_jonas> hmm
13:58:52 <Cale> (technically, it's just specified such that  undefined `seq` y = undefined, and x `seq` y = y otherwise.)
13:58:52 <Heffalump> seq doesn't technically provide guarantees about which exception will be thrown, does it?
13:59:42 <Cale> Heffalump: that's right, it doesn't, but for all intents and purposes, you might as well think of it as evaluating the left thing first
13:59:42 <sjanssen> H '98 doesn't distinguish between different _|_'s
14:00:00 <sjanssen> GHC does give some guarantees
14:00:52 <Cale> b_jonas: so, with foldl', we recover constant space usage
14:01:11 <Cale> foldl' (+) 0 [1..3]
14:01:36 <Cale> let y = 0 + 1 in y `seq` foldl' (+) y [2..3]
14:01:51 <Cale> let y = 1 in y `seq` foldl' (+) y [2..3]
14:01:58 <Cale> foldl' (+) 1 [2..3]
14:02:13 <Cale> let y = 1 + 2 in y `seq` foldl' (+) y [2..3]
14:02:22 <Cale> let y = 3 in y `seq` foldl' (+) y [2..3]
14:02:32 <Cale> er, oops :)
14:02:44 <Cale> forgot to change the list there
14:02:49 <Cale> but you get the idea
14:03:19 <Cale> It will do that bit of evaluation as it goes -- as well as do it tail recursively.
14:03:38 <Cale> (so really, this ought to compile down to a nice loop)
14:03:49 <b_jonas> good
14:04:09 <b_jonas> but how does it happen in buliding lists?
14:04:17 <b_jonas> let me think...
14:04:54 <Cale> Well, there it doesn't matter quite so much
14:05:25 <Cale> In fact, if you need to use foldl to build a list, it's likely that the lazy one is better.
14:05:36 <Cale> > foldl (flip (:)) [] [1..10]
14:05:41 <lambdabot>  [10,9,8,7,6,5,4,3,2,1]
14:06:25 <b_jonas> so that's a list that will be built lazily from the head to tail
14:06:26 <Cale> It doesn't really matter too much if the flip (:)'s are evaluated right away or not.
14:06:44 <Cale> yeah
14:07:41 <b_jonas> does that mean you can bulid a list from either end without seq
14:08:01 <b_jonas> let's see
14:08:18 <Cale> When the foldl finishes, you'll have something which looks like  flip (:) (...) 10
14:08:49 <Cale> and when you go to evaluate just the head of that, it will be possible to do without touching the (...)
14:08:57 <shapr> Is there an easy way to get cabal (as a library) to spit out the exact pathnames of the source files in a package?
14:09:02 <b_jonas> a lazy list from the tail like above it's let f 0 = [] | f x = () : f (x - 1)
14:09:12 <b_jonas> from the head I mean
14:10:26 <b_jonas> if you bulid from the tail, the list cannot be lazy, obviously
14:10:30 <Cale> right
14:11:11 <Cale> f 0 = []; f n = let xs = f (n-1) in xs `seq` () : xs
14:11:30 <Cale> That will recurse down to the base case, then build the list up from the tail.
14:11:45 <Cale> But there's little reason to do that, usually.
14:12:08 <Cale> You typically want lists to remain as lazy as possible.
14:12:28 <Cale> Since typically lists are much larger than the expressions which compute them.
14:13:45 <b_jonas> hmm. I'll have to think about the buliding part
14:14:26 <Cale> Well, it says to determine the top level constructor in xs before giving () : xs
14:14:41 <Cale> That is, either (:) or []
14:15:04 <Cale> To determine that, you have to evaluate f (n-1)
14:15:20 <Cale> until you get down to f 0 = []
14:15:39 <Cale> and then the f 1 case can finish, producing () : []
14:15:53 <Cale> and then the f 2 case can finish, producing () : () : []
14:15:56 <Cale> and so on
14:16:19 <b_jonas> but if you pass information other than the list tail from the inner instance of f to the outer one, then it would make sense to use seq to force the (:) anyway, wouldnt' it?
14:17:04 <b_jonas> because that's when you really want to build the list from the tail
14:17:33 <b_jonas> if you don't force the (:), the inner function gets called anyway but you get a promise of the pair
14:18:02 <eivuokko> shapr, No.  You can read package with Distribution.PackageDescription.readPackageDescription (and then probably use flattenPackageDescription to result);  Then you can access fields fairly conviently.  But some of those aren't file names, of course...like module list
14:18:38 <eivuokko> shapr, By far easiest way to find out list of files (I think) is to run setup sdist ...
14:19:04 <Cale> b_jonas: hmm... I suppose it depends.
14:19:22 <b_jonas> like, let f 0 = (1, []) | f x = let (u, t) = f (x - 1) in ((2 * u), u : t) -- to generate [64, 32, 16, 8, 4, 2, 1]
14:20:38 <b_jonas> so, in haskell, do you ever need to use one of the tricks from strict languages like reversing a list before processing or using an accumulator?
14:21:00 <Cale> the elements of the list will all be evaluated by the time that finishes, but the spine will get constructed lazily.
14:21:27 <Cale> sometimes
14:21:41 <shapr> eivuokko: I'm trying to pass a list of files to hinotify from the cabal file, sdist would mean I'd have to parse the tgz, right?
14:21:42 <Cale> there's another trick we tend to use as well
14:21:45 <b_jonas> yep, so would it make sense to force the spine too with seq or is that infeasable anyway in practice because you get so many promises inside anyway?
14:22:15 <Cale> It's reasonable to do it, but you tend to avoid that kind of recursion
14:22:19 <b_jonas> I mean, you don't ever force anything deeply if I understand right
14:22:20 <eivuokko> shapr, Yes.
14:22:37 <eivuokko> shapr, What is hinotify?
14:23:08 <b_jonas> it's not related, but does haskell has a standard library with lots of useful list functions like standard ml does?
14:23:08 <shapr> eivuokko: Haskell binding to inotify, the linux kernel file change notification thingy.
14:23:14 <Cale> yes
14:23:20 <Cale> Data.List
14:23:29 <Cale> and lots of that is available from the preluse
14:23:32 <Cale> prelude*
14:23:36 <shapr> eivuokko: I want to be able to push changes to a repo on a server and have the binary automatically rebuilt and restarted.
14:23:54 <Cale> (trying to type with a popsicle in my hand :)
14:23:55 <shapr> Does inotify work on MacOS X?
14:24:09 <Cale> > scanl (+) 0 [1..10]
14:24:11 <lambdabot>  [0,1,3,6,10,15,21,28,36,45,55]
14:24:17 <b_jonas> does it have a map2 that zips two lists to one with a custom function to unify the elements?
14:24:25 <tuomov> zipWith
14:24:26 <glguy> zipWith
14:24:29 <b_jonas> good
14:24:31 <shapr> > zipWith (+) [1..9] [1..9]
14:24:32 <Cale> > zipWith subtract [1..10] [2..10]
14:24:32 <lambdabot>  [2,4,6,8,10,12,14,16,18]
14:24:33 <lambdabot>  [1,1,1,1,1,1,1,1,1]
14:24:34 <eivuokko> shapr, What you need source file list for?
14:24:53 <glguy> > (+) <$> [1..9] <*> [1..9]
14:24:54 <lambdabot>  [2,3,4,5,6,7,8,9,10,3,4,5,6,7,8,9,10,11,4,5,6,7,8,9,10,11,12,5,6,7,8,9,10,11...
14:24:59 <b_jonas> and there's a one-level flattener too, right (that one gets forgotten about in most standard libraries for some reason)
14:25:07 <Cale> concat
14:25:09 <olliej_> ?src <$>
14:25:09 <eivuokko> shapr, Ah, well, ok;  If you want to depend only to sources, and not docs..
14:25:09 <lambdabot> f <$> a = fmap f a
14:25:10 <glguy> > (+) <$> ZipList [1..9] <*> ZipList [1..9]
14:25:10 <lambdabot>   add an instance declaration for (Show (ZipList a))
14:25:20 <glguy> > getZipList $ (+) <$> ZipList [1..9] <*> ZipList [1..9]
14:25:21 <olliej_> ?src <*>
14:25:21 <lambdabot>  [2,4,6,8,10,12,14,16,18]
14:25:21 <lambdabot> Source not found. Just what do you think you're doing Dave?
14:25:35 <olliej_> ?src $
14:25:35 <lambdabot> f $ x = f x
14:25:42 <laz0r> @wki TailRecursive
14:25:42 <lambdabot> http://www.haskell.org/haskellwiki/TailRecursive
14:25:43 <b_jonas> I've no idea why they do that, because concat is such a useful function that's impossible to write efficently
14:25:50 <Cale> huh?
14:25:53 <Cale> it's trivial
14:25:55 <eivuokko> shapr, Too bad Cabal rebuilds final libs anyway;  Or you could depend on those for checking if you need to build deps again.
14:26:04 <shapr> glguy: Are <$> and <*> from Applicative?
14:26:06 <glguy> shapr: yes
14:26:07 <laz0r> mmh
14:26:12 <b_jonas> I mean impossible to write efficently in the language if you don't have it in the library
14:26:17 <shapr> eivuokko: Huh?
14:26:17 <glguy> b_jonas: you must be thinking of a strict language
14:26:31 <b_jonas> glguy: well, yes
14:26:35 <laz0r> where is the TailRecursive Page that http://www.haskell.org/haskellwiki/Stack_overflow <- this page links to?
14:26:37 <lambdabot> Title: Stack overflow - HaskellWiki
14:26:54 <shapr> The old HaWiki is gone.. maybe I should put it up on ScannedInAvian.com
14:26:55 <Cale> b_jonas: no, that's not the case at all
14:26:57 <Cale> concat :: [[a]] -> [a]
14:26:57 <Cale> concat = foldr (++) []
14:27:07 <Cale> that's the honest to goodness library definition
14:27:15 <Cale> It's efficient too.
14:27:20 <eivuokko> shapr, (This doesn't work, because Cabal is silly): You could depend on _darcs/inventory to run a setup build;  And after that check if dist/bla/some.a changed to depend on setup register + continue building deps.
14:27:27 <b_jonas> so what's <*> ? the bot couldn't tell
14:27:40 <Cale> <*> is from Control.Applicative
14:27:40 <glguy> b_jonas: <*> is from Control.Applicative
14:27:45 <shachaf> <*> is ap.
14:27:46 <glguy> :t (<*>)
14:27:48 <lambdabot> forall (f :: * -> *) a b. (Applicative f) => f (a -> b) -> f a -> f b
14:27:55 <b_jonas> Cale: yeah, actually my problem is that I was thinking of arrays not lists
14:27:55 <shachaf> (For Applicatives.)
14:28:00 <b_jonas> with concat
14:28:15 <b_jonas> for different values of arrays
14:28:34 <shapr> eivuokko: Notifying on _darcs/inventory sounds like it would work, but I don't get the second part.
14:28:51 <b_jonas> ?src (<*>)
14:28:52 <lambdabot> Source not found. It can only be attributed to human error.
14:29:00 <laz0r> shapr: it must be somewhere, i've read it in the past, but now i have encountered a stack overflow problem, and wanted to check again what tail recursive exactly means
14:29:07 <Cale> b_jonas: it's a class method
14:29:14 <Cale> ?src Applicative
14:29:14 <lambdabot> class Functor f => Applicative f where
14:29:14 <lambdabot>     pure  :: a -> f a
14:29:14 <lambdabot>     (<*>) :: f (a -> b) -> f a -> f b
14:29:26 <shapr> b_jonas: http://www.haskell.org/ghc/docs/latest/html/libraries/base/Control-Applicative.html
14:29:28 <lambdabot> http://tinyurl.com/yyo64c
14:29:35 <b_jonas> ah, so Applicative is the class of functions or something like that?
14:29:40 <Cale> Kinda like monads, but fewer assumptions
14:30:13 <eivuokko> shapr, _darcs's inventory changes even when non-sources are changed, so it's not optimal.  So, if cbaal wasn't silly, you could run setup build and check afterwards if resulting lib changed.  If it changed, you'd need to do setup register/whatever and continue building deps.
14:30:26 <shapr> eivuokko: ohhh
14:30:49 <Cale> > (,) 5 6
14:30:51 <lambdabot>  (5,6)
14:30:55 <shapr> Still, notifying on _darcs/inventory would be the shortest route from nothing to something that works.
14:30:58 <b_jonas> ok, still trying to understand this: getZipList $ (+) <$> ZipList [1..9] <*> ZipList [1..9]
14:31:06 <b_jonas> how does it parenthisize, can the bot tell that?
14:31:18 <eivuokko> shapr, Yes.  And the only route at the moment, I think.
14:31:39 <olliej_> ?src pure
14:31:40 <lambdabot> Source not found. My mind is going. I can feel it.
14:32:02 <mauke> getZipList (((+) <$> (ZipList [1..9])) <*> (ZipList [1..9]))
14:32:07 <b_jonas> yep, (,) makes the infix operator comma to normal prefix syntax
14:32:26 <shapr> eivuokko: On the downside, if I want to notify on multiple cabal packages, I don't think there's an easy way to tell cabal to build all the packages that depend on the one that changed.
14:32:41 <Cale> > ((,) <*> tail) [1..10]
14:32:43 <lambdabot>  ([1,2,3,4,5,6,7,8,9,10],[2,3,4,5,6,7,8,9,10])
14:32:52 <mauke> oh, <*> is ap
14:32:58 <eivuokko> shapr, Indeed.
14:33:05 <shapr> hey yaxu, that livecoding is really cool.
14:33:26 <yaxu> hey shapr, thanks :)
14:33:31 <shapr> I wonder if I could rip code out of cabal-install to do that rebuilding?
14:33:32 <eivuokko> shapr, And also note;  You need to clean, because ghc *does not* check timestamps of installed packages.
14:33:42 <shapr> eivuokko: Yeah, I figured that out pretty quickly :-(
14:33:45 <shapr> That's a big problem, imho
14:33:54 <yaxu> shapr: you mean the recent screencast?
14:33:55 <eivuokko> shapr, I agree.  It has bitten me many times.
14:33:59 <shapr> yaxu: Yes, that.
14:34:05 <b_jonas> so (w <*> v) y = w y (v y)
14:34:11 <shapr> yaxu: Using the spiffy kol-something algorithm.
14:34:12 <Cale> b_jonas: Basically, the ZipList type is just a wrapper for lists such that: f <$> ZipList xs1 <*> ... <*> ZipList xsn = ZipList (zipWithn f xs1 ... xsn)
14:34:29 <Cale> b_jonas: that's for the function instance
14:34:35 <b_jonas> hmm
14:34:42 <Cale> <*> is polymorphic and does different things on different data types
14:34:47 <b_jonas> because I couldn't figure out from the words like "ap"
14:34:59 <mauke> someone needs to teach @pl about Applicative :-)
14:35:00 <b_jonas> I call that a "monadic hook"
14:35:05 <Cale> b_jonas: Right, you don't know about monads yet :)
14:35:09 <yaxu> shapr: karplus-strong, yep it's fun, looking forward to using it in anger
14:35:22 <Cale> I suppose you could learn about Applicative functors first, but it's unusual to do that :)
14:35:22 <b_jonas> no, it doesn't mean monad in the haskell sense
14:35:57 <b_jonas> J uses the word "monadic" and "dyadic" instead of "unary" and "binary" which is quite confusing
14:36:00 <Cale> b_jonas: Interestingly enough, I was actually replying to your line regarding 'ap' which is a monad function.
14:36:11 <Cale> :t ap
14:36:13 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m (a -> b) -> m a -> m b
14:36:16 <Cale> :t <*>
14:36:18 <lambdabot> parse error on input `<*>'
14:36:21 <Cale> :t (<*>)
14:36:23 <lambdabot> forall (f :: * -> *) a b. (Applicative f) => f (a -> b) -> f a -> f b
14:36:35 <Cale> Same thing, different level of generality.
14:36:44 <b_jonas> so does the bot not have a deparse plugin that puts in parenthesis and cleans up other syntactic sugar?
14:36:47 <Cale> (Applicative is slightly more general)
14:37:04 <Cale> It has a few things sort of like that, but not for parens.
14:37:05 <b_jonas> ?src ap
14:37:05 <lambdabot> ap = liftM2 id
14:37:33 <Cale> Should I give an intro to monads? What have you read already?
14:37:50 <b_jonas> buubot has a deparse plugin for perl but I've no idea if you can make it pass the -p parameter to do the parenthesis
14:38:16 <b_jonas> I've not read much _yet_, just one article
14:38:28 <b_jonas> but I'd rather not try to do monads now
14:38:35 <Cale> ah, all right
14:38:42 <b_jonas> (I'm in Europe so it's late)
14:38:59 <b_jonas> ?src liftM2
14:38:59 <lambdabot> liftM2 f m1 m2 = do { x1 <- m1; x2 <- m2; return (f x1 x2) }
14:39:36 <b_jonas> oh, so more general is because of the monads
14:39:52 <Cale> Yeah, and applicative functors are more general than monads again
14:40:19 <Cale> (every monad is an applicative functor, but not vice-versa)
14:40:53 <b_jonas> so if I understand this right, for functions, ap x y = x y
14:41:20 <xerox> ap f g x = f x (g x)
14:41:21 <Cale> Well, for the identity functor
14:41:40 <b_jonas> hmm
14:41:50 <xerox> There's an hidden parameter there, an environment.
14:41:53 <b_jonas> ap f g x = f x (g x)
14:42:03 <Cale> You're talking about two different instances!
14:42:04 <b_jonas> that does sound like the "monadic hook" from J then
14:42:07 <b_jonas> and <*> is the same
14:42:24 <Cale> The latter is the instance for functions from a fixed type
14:42:45 <Cale> ap x y = x y is the instance for the identity functor
14:42:56 <Cale> (but to get that, you have to do some wrapping)
14:43:42 <Cale> @index Id
14:43:42 <lambdabot> bzzt
14:43:44 <Cale> hmm
14:44:08 <b_jonas> ?src fmap
14:44:09 <lambdabot> Source not found. I can't hear you -- I'm using the scrambler.
14:44:15 <Cale> That's odd. The docs list an instance for Id, but strangely it's not exported
14:44:25 <xerox> > runIdentity (ap (return chr) (return 69))
14:44:26 <lambdabot>  'E'
14:44:29 <Cale> fmap is a generalisation of map to other data structures
14:44:40 <Cale> :t fmap
14:44:42 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
14:45:03 <Cale> (Functor f) => (a -> b) -> f a -> f b
14:45:07 <Cale> that's the important part :)
14:45:39 <b_jonas> uh huh
14:45:46 <Cale> > fmap (+5) (Just 10)
14:45:47 <lambdabot>  Just 15
14:45:52 <Cale> > fmap (+5) [1,2,3,4,5]
14:45:54 <lambdabot>  [6,7,8,9,10]
14:46:10 <Cale> > fmap (+5) (^2) 10
14:46:11 <lambdabot>  105
14:46:45 <Cale> That last one might be confusing :)
14:47:00 <Cale> But it's also the "functions from a fixed type" functor
14:47:19 <Cale> Or, ((->) e) (partially applied)
14:47:35 <Cale> So when f = ((->) e)
14:47:40 <Cale> (a -> b) -> f a -> f b
14:47:50 <Cale> = (a -> b) -> (e -> a) -> (e -> b)
14:48:05 <xerox> :t (.)
14:48:07 <lambdabot> forall b c a. (b -> c) -> (a -> b) -> a -> c
14:48:07 <Cale> and there's only really one thing that could be :)
14:48:33 <b_jonas> what on earth does (->) mean?
14:48:40 <Cale> That's the type constructor for functions
14:48:42 <xerox> It is the function type constructor
14:49:00 <b_jonas> hmm
14:49:05 <Cale> A -> B is the type of functions taking a parameter of type A and giving a value of type B
14:49:08 <xerox> It takes two types and returns a type, the type of functions from the first type to the second
14:49:23 <Cale> and you can write that prefix as well
14:49:26 <Cale> (->) A B
14:49:34 <Cale> For example...
14:49:37 <Cale> :t ord
14:49:39 <lambdabot> Char -> Int
14:49:48 <b_jonas> so it's a type constructor, not a real constructor
14:49:57 <Cale> right, not a data constructor
14:50:02 <xerox> You've got type constrcturs and data constructors.
14:50:18 <xerox> ?src Maybe
14:50:18 <lambdabot> data Maybe a = Nothing | Just a
14:50:23 <b_jonas> yeap
14:50:40 <Cale> Maybe is a type constructor, Nothing and Just are data constructors
14:50:42 <xerox> There Maybe is a type constructor, it construct a type Maybe a from a type a, Nothing and Just are a nullary and an unary data constructors
14:50:49 <b_jonas> I've got that
14:51:19 <b_jonas> at least it's not in all uppercase
14:51:24 <Cale> A functor is a type constructor f which takes a single type parameter, together with a definition of fmap :: (a -> b) -> f a -> f b
14:51:51 <Cale> @src Functor
14:51:51 <lambdabot> class  Functor f  where
14:51:51 <lambdabot>     fmap        :: (a -> b) -> f a -> f b
14:52:12 <b_jonas> "SOME" and "NONE" in sml are so ugly
14:52:58 <Cale> Oh, there are some laws as well, you should have  fmap id = id
14:53:05 <Cale> and fmap (f . g) = fmap f . fmap g
14:54:26 <b_jonas> right. now I know what <$> and <*> do, let me re-read the sentence about zipList
14:54:43 <b_jonas> "Basically, the ZipList type is just a wrapper for lists such that: f <$> ZipList xs1 <*> ... <*> ZipList xsn = ZipList (zipWithn f xs1 ... xsn)"
14:55:05 <Cale> Ah, and you have to know what zipWithn means -- there are some functions:
14:55:09 <Cale> :t zipWith
14:55:11 <lambdabot> forall a b c. (a -> b -> c) -> [a] -> [b] -> [c]
14:55:14 <Cale> :t zipWith3
14:55:16 <lambdabot> forall a b c d. (a -> b -> c -> d) -> [a] -> [b] -> [c] -> [d]
14:55:18 <Cale> :t zipWith4
14:55:20 <lambdabot> forall a b c d e. (a -> b -> c -> d -> e) -> [a] -> [b] -> [c] -> [d] -> [e]
14:55:31 <b_jonas> good
14:56:08 <b_jonas> but how does zipWithn know n?
14:56:28 <Cale> It doesn't, that was not proper Haskell code
14:56:34 <b_jonas> ah ok
14:57:20 <glguy> Anyone happen to know how to download a server's self signed certificate so that you can tell curl to trust it for https downloads?
14:57:21 <Cale> The idea of the ZipList thing is to get that effect through some combinators without having to muck about with macros and such.
14:57:46 <Cale> (though it's kind of verbose, and I haven't really seen a great application of it)
14:58:32 <ddarius> Cale: It has clear applications and it's only verbose because it is the "off" choice.
14:58:34 <Saizan> (parallel list comprehensions are surely nicer)
14:59:00 <b_jonas> wouldn't it be easier to have a function z so that z f [l1 .. ln] = zipWithn f l1 .. ln
14:59:11 <twanvl> I don't like parallel list comprehension, because it is way to easy to pick the wrong one
14:59:40 <ddarius> b_jonas: Without type class trickery what would the type of f be?
15:00:11 <b_jonas> ah right
15:00:12 <b_jonas> that's true
15:00:25 <ddarius> However, if you have f take a list then z f = f . transpose
15:01:08 <ddarius> map f . transpose that is.
15:01:18 <twanvl> A separate combinator sould be possible:  f `zip` l1 `zip` l2 `zip` l3
15:01:28 <twanvl> (where zip is a new combinator)
15:01:37 <b_jonas> I don't think that works
15:01:41 <b_jonas> map f . transpose that is
15:01:44 <b_jonas> let's see
15:01:51 <ddarius> twanvl: That's exactly what applicative does only you need to special case the first.
15:01:56 <ddarius> :t map ?f . transpose
15:01:59 <lambdabot> forall b a. (?f::[a] -> b) => [[a]] -> [b]
15:02:28 <b_jonas> (map f . transpose) [[a1, a2], [b1, b2]] = map f [[a1, b1], [a2, b2]] =
15:02:36 <twanvl> ddarius: Yes, but the ZipList wrapper is so verbose it is not really usable
15:02:41 <b_jonas> [f [a1, b1], f [a2, b2]] yep it works
15:02:44 <b_jonas> indeed
15:03:16 <b_jonas> on the other hand, I'm much more interested in zipWith then zipWith2 or zipWithn
15:03:24 <ddarius> twanvl: Agreed.  So simply define zapply and zsomething as <$> and <*>
15:04:13 <ddarius> I'd be using it if it weren't so verbose.
15:05:24 <twanvl> <$> for ziplist is simply map, isn't it?
15:05:50 <ddarius> twanvl: Yep, that is zipWith1
15:06:29 <twanvl> So, just define <%> = zipWith id, and you are done,  f <$> l1 <%> ... <%> ln = zipWithn l1 ... ln
15:06:40 <b_jonas> so (getZipList $ (+) <$> ZipList [1..9] <*> ZipList [1..9]) must mean (zipWith (+) [1..9] [1..9]) and indeed that's whose result it produced above
15:07:45 <b_jonas> now that was an evil example
15:08:00 <ddarius> Actually I was considering instance Num a => Num [a] where (+) = zipWith (+); etc.
15:09:12 <mauke> you can define instance Num a => Num (Applicative a), but that leaves you with ZipLists all over the place
15:12:01 <b_jonas> or you can use an array programming language like J or octave if you want arithmetic ops to map/zipWith over lists
15:12:21 <b_jonas> I don't think it would work nice in any normal language
15:16:17 <b_jonas> also, it's not only the syntax but the performance
15:17:11 <b_jonas> it's better to do arithmetic on numeric arrays then lists and better to have array arithmetic optimized in code then hoping a generic optimizer will pick it up
15:17:24 <b_jonas> (do I get kicked for things like this?)
15:17:42 <mauke> you can write your own optimizer rules :-)
15:17:51 <Eelis> is GHC trac the place to report Parsec bugs?
15:18:19 <b_jonas> mauke: that sounds like the generous claims the perl6 guys make
15:18:53 <wli> Compilers already do transformations/optimizations for array arithmetic (traversal, really) that are nigh impossible to do by hand.
15:19:02 <b_jonas> they say you can write any syntax as a macro, and any semantics as a builtin class
15:19:29 <mauke> I'm thinking of http://www.cse.unsw.edu.au/~dons/papers/CLS07.html
15:19:30 <lambdabot> Title: Stream Fusion: From Lists to Streams to Nothing at All
15:20:16 <b_jonas> wli: yeah. I've no idea how the J interpreter can do all the array operations fast
15:20:28 <byorgey> Eelis: no, Parsec is unrelated to GHC
15:20:34 <twanvl> Eelis: Are you sure you have found a bug?
15:20:40 <Eelis> twanvl: i'd say 70% sure
15:20:42 <b_jonas> though I haven't done benchmarks that they're really fast but I just hope they are if they're so much in the core
15:20:45 <Eelis> byorgey: ok, any suggestions where to report then?
15:20:47 <Cale> b_jonas: GHC has RULES pragmas which let you express algebraic transformation rules for the optimiser to use, and they're actually reasonably usable for domain-specific optimisation.
15:20:52 <twanvl> If so, try libraries@haskell.org or daan@cs.uu.nl
15:21:09 <ndm> @seen xerox
15:21:09 <lambdabot> xerox is in #haskell, #haskell-overflow, #haskell-soc, #ghc, ##logic and #haskell-blah. I last heard xerox speak 30m 27s ago.
15:21:12 <mauke> if it's about notFollowedBy, that's broken by design
15:21:18 <Eelis> i tried daan@cs.uu.nl, but that address is dead
15:21:18 <ndm> Eelis: xerox is the parsec maintainer now
15:21:42 <twanvl> Then the doc header should be updated
15:21:43 <Eelis> xerox: poke
15:22:25 <ndm> twanvl: xerox hasn't accepted the position, and daan hasn't relinquished it, but as far as i am concerned, xerox is the parsec maintainer
15:22:35 <ndm> i'm trying to persuade xerox to submit that patch
15:22:49 <SamB> ooooh
15:22:56 <SamB> I'll second that motion
15:23:27 <ndm> Eelis: if you can't find xerox tonight, send an email to haskell-cafe cc'ing xerox
15:23:28 <SamB> daan doesn't seem to have time to be the Parsec maintainer
15:23:40 <ndm> daan also started and dropped wxHaskell
15:23:55 <xerox> 'lo
15:23:56 <Eelis> ndm: alright, thanks
15:23:57 <SamB> I mean, just based on how hard he is to get in touch with...
15:24:08 <Eelis> http://hpaste.org/2376 <- parsec - strange error messages after using setInput
15:24:43 <ndm> xerox: please submit a patch changing the maintainer in the cabal file of parsec
15:24:51 <SamB> yes please
15:25:02 <SamB> it's nice to have a maintainer who answers email!
15:25:14 <xerox> ndm: after your suggestion, I changed all of them to my name :)
15:25:46 <SamB> what about your email address?
15:25:56 <xerox> Eelis: what's wrong with that message?
15:26:01 <mauke> and change the type of notFollowedBy to :: Show tok => (tok -> Bool) -> GenParser tok st ()
15:26:07 <Eelis> xerox: did you read the comment? it describes what's wrong
15:26:16 <pjd> glguy: openssl s_client server:443
15:26:57 <xerox> Eelis: spaces is optional?
15:26:58 <ndm> @karma+ xerox  -- taking over maintainership
15:26:59 <lambdabot> xerox's karma raised to 27.
15:27:12 <Eelis> xerox: yes, it's zero or more spaces
15:27:20 <xerox> Eelis: alright
15:27:28 <Eelis> xerox: note how the parse succeeds if you change 4 to 'y'
15:28:12 <xerox> Eelis: I see.
15:28:30 <b_jonas> Cale: so what's the other trick (to build lists, apart from accumulators and reversing) you were about to tell me before I interrupted with the library
15:29:33 <Eelis> xerox: in light of this, do you agree the messages are incorrect?
15:29:35 <Cale> b_jonas: oh, right -- if you're building up a list via a sequence of small appends on the right, due to the fact that (++) takes time which is on the order of the length of the left parameter, you can end up with quadratic performance
15:29:47 <b_jonas> oh yeah
15:29:48 <Cale> [] ++ ys = ys
15:29:52 <b_jonas> that's why concat is important
15:29:57 <Cale> (x:xs) ++ ys = x : (xs ++ ys)
15:30:35 <Cale> So the trick to avoiding (++) is to use functions from lists to lists instead -- functions which prepend content to the head of a list.
15:30:37 <xerox> Eelis: that's due to the very definition of setInput.
15:30:53 <b_jonas> that's what accumulators mean, don't they?
15:30:54 <Cale> (and then in the end, apply the function to the empty list)
15:31:06 <b_jonas> ok, not exactly
15:31:12 <b_jonas> but accumulators also cover that
15:31:21 <Eelis> xerox: you mean to say that the use of setInput is /supposed/ to lead to misleading error messages? that can't be the case :)
15:31:22 <b_jonas> because you can use accumulators without lists too
15:31:26 <Cale> Then you can use (.) for (++)
15:31:46 <Cale> I don't think it's the same, but perhaps you can show me :)
15:31:49 <xerox> Eelis: at least by the current design :-/
15:31:59 <b_jonas> ok, wait
15:32:07 <Cale> For example, suppose you have the following tree type:
15:32:12 <Eelis> xerox: so it's a design flaw?
15:32:24 <Cale> data Tree a = Tip | Branch a (Tree a) (Tree a)
15:32:34 <Eelis> xerox: can't setInput simply "purge" pending error messages?
15:32:44 <Cale> So the naive way is:
15:32:47 <Cale> preorder Tip = []
15:33:16 <Cale> preorder (Branch x r l) = x : (preorder r ++ preorder l)
15:33:16 <xerox> Eelis: I'm not sure that's a sensible strategy.
15:33:26 <b_jonas> so you really mean small increments, not increments of one, right?
15:33:48 <Cale> yeah, or even possibly large, possibly small increments -- like in the case of these trees
15:33:52 <b_jonas> ah wait, that's not small increments
15:33:54 <b_jonas> that's recursive
15:34:02 <Eelis> xerox: me neither :) i just ran into this problem in a bigger parser, could make no sense of the error messages, and eventually reduced it to this
15:34:09 <Cale> er
15:34:14 <b_jonas> when you said small increments, I thought of the case when you can use concat
15:34:17 <xerox> Eelis: I agree it should be fixed.
15:34:19 <b_jonas> but this is recursive so you can't
15:34:22 <Cale> I named my parameters stupidly there :)
15:34:31 <Cale> But it's still corrent
15:34:32 <Cale> ct*
15:34:32 <b_jonas> now in this case you can do two things:
15:34:38 <Eelis> xerox: alright, thanks
15:34:44 <Cale> I'm a little tired, cat woke me up at 5am :)
15:34:46 <b_jonas> accumulators or continuation passing
15:34:52 <ddarius_> b_jonas: Lifting (+) to arrays is not compatible with what I want.
15:34:55 <b_jonas> but the second one is probably never useful in a lazy language
15:35:08 <Cale> preorder' Tip = id
15:35:09 <xerox> Eelis: but it doesn't look easy. You've got three types of errors in Parsec, Expected something, UnExpected something, and Message something.  'something' is a String in each case.
15:35:23 <b_jonas> accumulators is this:
15:35:24 <Eelis> and SysUnexpected
15:35:24 <Cale> preorder' (Branch x l r) = (x:) . preorder' l . preorder' r
15:35:37 <Cale> preorder t = preorder' t []
15:35:38 <chessguy> xerox, what's Message?
15:35:40 <Eelis> xerox: i'm afraid i lack the Parsec expertise to make any suggestions :(
15:35:59 <xerox> Eelis: Okay, I'll look into it tomorrow.
15:36:01 <augustss> @seen sorear
15:36:01 <lambdabot> sorear is in #happs, #ghc, #xmonad, #haskell-overflow, #haskell-blah and #haskell. I last heard sorear speak 2h 10m 51s ago.
15:36:05 <xerox> ?localtime xerox
15:36:08 <lambdabot> Local time for xerox is Tue Aug 21 23:35:12 2007
15:36:13 <xerox> eheh, lies, it's 00:35.
15:36:19 <sorear> augustss: ?
15:36:33 <chessguy> @go haskell parsec message
15:36:34 <lambdabot> http://groups.google.com/group/fa.haskell/browse_thread/thread/b8468b4eeb2522e9/9989cdf631a45509
15:36:34 <lambdabot> Title: Parsec: Parenthesized expressions and more! - fa.haskell | Google Groups
15:36:43 <augustss> sorear: I was just thinking that maybe you're too old for computing
15:36:45 <xerox> chessguy: it is used in 'fail'
15:37:08 <xerox> chessguy: fail msg = (stuff... (Message msg) ... stuff)
15:37:27 <chessguy> ok..
15:37:28 <augustss> sorear: http://programming.reddit.com/info/2hdv2/comments ;)
15:37:29 <lambdabot> Title: International Olympiad in Informatics just finished. Guess which country best fe ...
15:37:47 <b_jonas> preorder'' t Tip = [] | preorder'' t (Branch x l r) = x : preorder'' (preorder'' t r) l -- that's accumulators
15:38:23 <desp> augustss: woop
15:38:33 <b_jonas> that's the same as your preorder' I think, except that yours is pointfree
15:39:38 <Cale> b_jonas: yeah, with the parameters flipped
15:39:49 <Cale> b_jonas: actually took me a moment to sort that out :)
15:39:57 * xerox >>= bed
15:40:09 <Saizan> preorder'' t Tip = t, no?
15:40:16 <b_jonas> yep
15:40:17 <Cale> right
15:40:33 <b_jonas> now there's continuation-passing which is probably not very wise here:
15:42:15 <b_jonas> preorder' Tip = id | preorder' (Branch x l r) = x $ (preorder' l) $ (preorder' r) []
15:42:32 <b_jonas> but because of currying, that might come out the same as the accumulator one, I don't know
15:43:01 <b_jonas> no wait, that defn is wrong
15:43:23 <b_jonas> preorder' Tip = id | preorder' (Branch x l r) = \t (x $ (preorder' l) $ (preorder' r) t)
15:43:25 <ndm> @seen Philippa_
15:43:26 <lambdabot> Philippa_ is in #scannedinavian, #haskell-soc, #haskell-overflow, #haskell-blah and #haskell. I don't know when Philippa_ last spoke.
15:43:49 <b_jonas> hmm
15:43:53 <Cale> that's identical to mine, but written using $ rather than .
15:43:56 <b_jonas> I'm not sure if I'm right here
15:44:35 <b_jonas> I'd have to look this continuation-passing stuff up because this might not be that
15:44:55 <b_jonas> wait, I think I know
15:45:14 <b_jonas> this is definitely not continuation-passing
15:45:37 <b_jonas> continuation-passing has to accept a function argument
15:46:12 <Cale> yeah
15:47:45 <ddarius> preorderCPS Tip k = k []; preorderCPS (Branch x l r) k = preorderCPS l (\ls -> preorderCPS r (\rs -> k (x:ls++rs)))
15:48:28 <mauke> fold f g Tip = f; fold f g (Branch x l r) = g x (fold f g l) (fold f g r)
15:49:02 <ddarius> fold tip branch Tip = tip; fold tip branch (Branch x l r) = branch x (fold tip branch l) (fold tip branch r)
15:50:24 <b_jonas> HOP (Mark Jason Dominus' book Higher-order Perl) doesn't have CPS if I can belive the index. I'll have to look it up in the functional programming notes then.
15:51:34 <midfield> anyone up to answering an STM question?
15:51:52 <mauke> the answer is "butter"
15:51:53 <Lemmih> midfield: Yes.
15:52:29 <midfield> great!  so i'd like to implement a concurrent Map
15:52:58 <midfield> the usual Map is given as a datatype like data Map k a = Tip | Bin Size k a (Map k a) (Map k a)
15:53:24 <midfield> the null function is just null t = case t of Tip -> True Bin _ _ _ _ _ -> False
15:53:30 <midfield> now i want to translate this into STM
15:53:43 <mauke> so, a mutable map?
15:53:55 <midfield> yes, and transaction protected
15:54:17 <midfield> so i have data TMap k a = Tip | Bin (TVar Size) (TVar k) .....
15:54:26 <midfield> et cetera
15:54:34 <midfield> but now i'm confused about "null"
15:54:44 <midfield> null :: TMap k a -> STM Bool
15:54:46 <Lemmih> midfield: Should it be difference from 'Map k (TVar a)' or 'TVar (Map k a)'?
15:55:08 <mauke> midfield: why doesn't it return plain Bool?
15:55:25 <midfield> the map itself should be updateable, so i imagine TVar (TMap k a)
15:55:57 <midfield> mauke: because you might want to work with a map that is empty inside a transaction -- you don't want someone else clobbering it while you're working on it
15:56:12 <mauke> your TMap isn't fully mutable
15:56:39 <mauke> null Tip = True; null _ = False
15:57:05 <midfield> so i am correct in thinking that this is not a transaction protected TMap
15:57:13 <midfield> or null is not transaction protected
15:57:42 <midfield> thus i have to do something like TMap k a = TMap (TVar (TMap_ k a))
15:57:49 <Lemmih> midfield: That's a very hard problem. The database guys have been trying to solve it for years without luck.
15:57:50 <midfield> and TMap_ is the old TMap ?
15:58:16 <midfield> Lemmih: what's a hard problem?  empty trees?
15:58:27 <mauke> I'd just prototype it in C
15:59:09 <mauke> then replace all pointers by TVars, et voila, threadsafe map
15:59:13 <FMota> I have a (sort of) haskell that's not directly related to programming. More of a philosophical question, really. The question is:
15:59:24 <midfield> or should the signature of null be null :: TVar (TMap k a) -> STM Bool ?
15:59:59 <FMota> why do Monads' bind have to have type (M a -> (a -> M b) -> M b) rather than (Ma -> (a -> b) -> M b)
16:00:16 <ddarius> :t flip fmap
16:00:21 <lambdabot> forall a b (f :: * -> *). (Functor f) => f a -> (a -> b) -> f b
16:00:23 <FMota> I'm sure there's a perfectly logical reason, I just haven't found it.
16:00:26 <ndm> who went to AngloHaskell?
16:00:26 <Lemmih> midfield: Indexes that perform well concurrently.
16:00:28 <mauke> FMota: because that's not general enough. you also need join then
16:00:59 <FMota> right, assuming you have join
16:01:00 <Cale> FMota: if they only had the latter, they'd just be Functors
16:01:01 <LoganCapaldo> FMota, because that's the type of flip liftM
16:01:10 <LoganCapaldo> @type flip liftM
16:01:12 <lambdabot> forall a1 r (m :: * -> *). (Monad m) => m a1 -> (a1 -> r) -> m r
16:01:18 <FMota> h, ok
16:01:20 <Cale> FMota: You can have fmap, join, and return, or return and bind
16:01:23 <FMota> *oh
16:01:36 <midfield> hmm... well i guess i have some more thinking to do.  thanks
16:01:53 <FMota> Cale: and they're equivalent
16:01:57 <FMota> I see
16:02:00 <astrolabe> ndm: I went to anglo haskell!
16:02:14 <FMota> well then, that was easy
16:02:20 <ndm> astrolabe: who did the talk on v iew patterns? i was just doing a post-mortem blog post
16:02:40 <astrolabe> Was it that ben guy?  Hang on a mo.
16:02:42 <ddarius> FMota: Just to clarify what is "they" in your statement?
16:02:52 <mauke> m >>= f = join (fmap f m)
16:02:57 <mauke> join m = m >>= id
16:03:01 <ddarius> ndm: There's a program for AngloHaskell on the wiki.
16:03:10 <mauke> fmap f m = m >>= return . f
16:03:45 <ndm> ddarius: ah, found it, he's on the list of talks but not he programme
16:03:50 <astrolabe> ndm: It was 'Dan Licata'
16:03:57 <astrolabe> ah.  You beat me.
16:04:00 <ndm> astrolabe: cheers :)
16:04:02 <FMota> "they" was (bind, return), and (fmap, join, return) being equivalent
16:04:09 <pjd> (=<<) = join . fmap
16:04:17 <FMota> yep, I get it now
16:04:20 <mauke> unlikely
16:04:24 <mauke> :t join . fmap
16:04:26 <lambdabot>     Occurs check: cannot construct the infinite type: f = (->) (f a)
16:04:26 <lambdabot>     Probable cause: `fmap' is applied to too many arguments
16:04:31 <EvilTerran> that was that young guy, wasn't it?
16:04:32 <astrolabe> Does anyone know who the guy was at anglo-haskell who used to have a poker website, and was interested in opponent modelling for poker?
16:04:48 <pjd> mauke: oops, join `dot` fmap
16:04:51 <EvilTerran> :t (join .) . fmap
16:04:53 <lambdabot> forall a a1 (f :: * -> *). (Monad f, Functor f) => (a1 -> f a) -> f a1 -> f a
16:04:54 <pjd> the other dot
16:04:59 <EvilTerran> :t (=<<)
16:05:01 <lambdabot> forall a (m :: * -> *) b. (Monad m) => (a -> m b) -> m a -> m b
16:05:15 <mauke> :t (join .) . liftM
16:05:17 <lambdabot> forall a a1 (m :: * -> *). (Monad m) => (a1 -> m a) -> m a1 -> m a
16:05:32 <FMota> *confused*
16:06:07 <glguy> @yow
16:06:08 <lambdabot> I'm pretending I'm pulling in a TROUT!  Am I doing it correctly??
16:08:40 <EvilTerran> @ghc
16:08:40 <lambdabot> ghc says: WARNING: SE CAFs unsupported, forcing UPD instead
16:12:03 <EvilTerran> > 2^128 :: Integer
16:12:05 <lambdabot>  340282366920938463463374607431768211456
16:13:43 <ndm> astrolabe: oh, i remember him, but by face only
16:14:01 <astrolabe> ndm: thanks
16:14:06 <FMota> > 2^64 :: Integer
16:14:07 <lambdabot>  18446744073709551616
16:14:10 <FMota> nifty.
16:14:53 <EvilTerran> haskell's Integer type is arbitrary-sized
16:15:03 <EvilTerran> > 2^128 :: Int
16:15:04 <lambdabot>  0
16:15:10 <EvilTerran> Int isn't. ;]
16:15:16 <mauke> > 2^128 :: Double
16:15:17 <lambdabot>  3.402823669209385e38
16:15:18 <FMota> I see
16:15:40 <FMota> > 10^20 :: Integer
16:15:41 <lambdabot>  100000000000000000000
16:16:11 <mauke> > sum (replicate 10 0.1)
16:16:12 <lambdabot>  0.9999999999999999
16:16:16 <mauke> > sum (replicate 10 0.1) :: Rational
16:16:17 <lambdabot>  1%1
16:16:51 <FMota> Oof, ugly syntax for the rationals
16:17:54 <byorgey> FMota: well, / was already taken.
16:17:54 <mauke> that's just for output
16:18:01 <mauke> > 1/3 + 1/3 + 1/3 :: Rational
16:18:03 <lambdabot>  1%1
16:18:17 <pjd> FMota: philosophical answer to your earlier philosophical question:
16:18:18 <pjd> the middle M b in (M a -> (a -> M b) -> M b) is there so that later monadic values can "depend" on earlier ones
16:18:33 <glguy> :t (%)
16:18:35 <lambdabot> forall a. (Integral a) => a -> a -> Ratio a
16:18:54 <FMota> ok :)
16:19:19 <FMota> ty
16:19:42 <ndm> ok, AngloHaskell blog post written and published, finally
16:19:49 <pjd> without it, you're only lifting pure functions into the monad;  you can't do things like conditionally produce Just foo or Nothing, depending on the value already in a Maybe
16:20:37 <pjd> or do one of several IO operations, depending on the result of an earlier IO operation
16:20:50 <pjd> s/do/choose between/
16:20:55 <EvilTerran> ndm, linky linky?
16:21:17 <ndm> EvilTerran: http://neilmitchell.blogspot.com/
16:21:19 <lambdabot> Title: Neil Mitchell's Haskell Blog
16:21:20 <byorgey> EvilTerran: I believe the proper term is "linky winky"
16:21:23 <FMota> ah
16:21:26 <FMota> that makes sense
16:21:30 <EvilTerran> thankyou :)
16:21:31 <desp> hm
16:21:50 <desp> is there any reason why calling performGC wouldn't cause a ForeignPtr's finalizer to fire?
16:22:32 <ndm> desp: yes, GC is not necessarily 100% perfect, you may have thunks floating around
16:22:50 <ndm> desp: particularly on the stack
16:23:16 <desp> ndm: I call an IO action that makes the fptr, and after the IO action finishes, I call performGC
16:23:57 <ndm> desp: do you store the result? is the IO action 100% forced?
16:23:57 <desp> the fptr isn't returned from the IO action
16:24:08 <eivuokko> desp, if you continue longer, or call finalizeForeignPtr, does it seem to work?
16:24:10 <desp> what do you mean by 100% forced?
16:24:12 <ndm> have you deepSeq'd the result of the IO action
16:24:24 <ndm> if you return a string, you will find its probably forced _ : _
16:24:29 <desp> I'll try that, but I observe the side effects
16:24:33 <ndm> so that the data still holds on
16:24:37 <eivuokko> There is no guarantee that finalizers get run in timely manner, anyway.
16:24:47 <desp> eivuokko: I'm going to try that next, yes
16:24:51 <desp> mhm
16:24:59 <ndm> eivuokko: no, but it should run straight after GC, in the current implemtnation?
16:25:01 <desp> just trying to verify that my finalizing code works
16:25:28 <astrolabe> ndm: I didn't say at the time, but I really liked the sound of Supero.  I want it for GHC, and now.
16:25:37 <eivuokko> ndm, I am not sure what performGc actually does :)  Maybe it only does some minor...
16:27:03 <desp> @index deepseq
16:27:04 <lambdabot> bzzt
16:27:16 <chessguy> @hoogle deepSeq
16:27:17 <lambdabot> No matches found
16:27:19 <ndm> astrolabe: i have much better benchmarks today, 4 times faster than GHC in one benchmark
16:27:23 <ndm> @hoogle rnf
16:27:23 <lambdabot> Control.Parallel.Strategies.rnf :: NFData a => Strategy a
16:27:58 <astrolabe> ndm: Wow.
16:28:10 <desp> ndm: I don't see deepSeq in Strategies...where is it?
16:28:12 <ndm> astrolabe: i know, i started dancing in my desk area :)
16:28:28 <ndm> desp: i think rnf was it, but not entirely sure now - i remember its somewhere obscure and with a silly name...
16:29:02 <desp> hm.
16:29:09 <ndm> desp: rnf x `seq` ...
16:29:49 <ndm> desp: although as eivuokko says, no garunatees
16:29:54 <desp> ok
16:30:00 <ddarius> rnf == deepSeq
16:33:55 <EvilTerran> what does "rnf" stand for?
16:34:16 <ndm> reduce to normal form
16:34:20 <sorear> ndm++ for the first summary
16:34:58 <ndm> sorear: i suspect 10 days after it might be the only one...
16:35:13 <sorear> oh?
16:35:52 <ndm> yeah, no one else seems to want to blog it
16:36:03 * EvilTerran would, but I don't have a blog
16:36:22 <EvilTerran> and I don't produce enough content to warrant one. it'd just be ego-stroking.
16:36:32 <ndm> EvilTerran: you can always guest blog, if you ever send me a post i'm happy to post it with your name
16:37:13 <desp> ok, forcing the finalization helped
16:38:11 <EvilTerran> ndm, oh right, thanks! i might see if i can rustle up something worth posting sometime
16:38:41 <ndm> EvilTerran: ok, if you ever do, just email it over
16:38:47 <EvilTerran> cool.
16:39:06 <ndm> EvilTerran: although creating a blogger account is really easy, and you can get it added to planet haskell if you ever do feel like posting something
16:39:40 <EvilTerran> meh. i've got a livejournal account somewhere (for posting on others' blogs), i suppose i could just use that.
16:39:54 <ndm> you can, lj has rss feeds
16:41:30 <ndm> i have an lj for personal stuff, and a blogger for haskell stuff
16:42:27 * ndm is reading the hbc bugs and limitations page, notes that most of them are still present in Haskell, or Haskell isn't quite as advanced as hbc
16:42:41 <ndm> (where Haskell = modern implementations of Haskell)
16:45:00 <ddarius> @index zipWith5
16:45:00 <lambdabot> Data.List
16:45:30 <ihope> ndm: hbc?
16:45:45 <ndm> http://www.cs.chalmers.se/~augustss/hbc/
16:45:47 <lambdabot> Title: Index of /~augustss/hbc
16:45:54 <ndm> ihope: lennart's compiler, from a LONG time ago
16:45:54 <bparkis> so in lisp, macros process implicit syntactic forms, but in haskell syntactic (quoted) forms can be done using data constructors
16:46:32 <ndm> bparkis: generally, lazy evaluation means you can define new control structures as functions, so you don't need the macro's that lisp offers
16:46:56 <ihope> And where is this bugs and limitations page?
16:47:11 <bparkis> the other feature of macros is implicit quoting so that you can choose not to evaluate certain expressions but instead take them as keywords
16:47:40 <bparkis> so with lazy evaluation and implicit quoting simulated by data constructors, haskell gets most of the functionality of macros
16:50:10 <LoganCapaldo> I'd argue the aziness is what is getting the "implicit quoting" sort of functionality
16:51:10 <bparkis> well, if you were to blow your fuse and write the "loop" macro in Haskell, you would probably use data constructors for the loop keywords
16:52:14 <LoganCapaldo> doesn't seem to have anything to do with quoting though. you are just using constructors in lieu of symbols
16:53:23 <ddarius> > (\x | True -> 0) 3
16:53:23 <lambdabot>  Parse error
16:53:23 <bparkis> loop keywords aren't evaluated, hence they are implicitly quoted
16:54:02 <LoganCapaldo> bparkis, but I thought _all_ the arguments to any macro were implicity quoted
16:54:08 <EvilTerran> ddarius, yeah, i want guards in lambdas too
16:55:18 <bparkis> it's the macro's choice, but some of the arguments to a macro are evaluated--loop keywords are expressions that don't _need_ to be implicitly quoted
16:55:29 <bparkis> er, other way around
16:55:53 <LoganCapaldo> macros just go from explicit quoting to explicit dequoting
16:55:54 <bparkis> loop keywords are expressions that _do_ need to be implicitly quoted whereas some other forms do not need to be explicitly quoted and could be evaluated as written
16:56:31 <bparkis> documentation for a macro will frequently state of a form in the macro, "evaluated" to indicate that it will be de-quoted
16:56:56 <bparkis> or converselly "not evaluated"
16:57:49 <LoganCapaldo> i'm just saying that laziness is what gives functionality that is very loosely equivalent to a macro's 'every argument is quoted (and therefore unevaluated) by default'.
16:58:07 <LoganCapaldo> constructors don't give you any more or less quoting ability
16:58:14 <LoganCapaldo> their just values
16:58:18 <LoganCapaldo> *they're
16:59:14 <bparkis> I'm basically saying, constructors are the Haskell semi-equivalent of symbols
16:59:27 <LoganCapaldo> I semi-agree with that
16:59:42 <LoganCapaldo> but early you said that they gave you implicit quoting
16:59:49 <LoganCapaldo> (semi-gave you)
17:00:00 <LoganCapaldo> which I semi-disagree with :)
17:00:09 <bparkis> well, nothing explicitly quotes them, but they are similar in behavior to symbols, which are quoted
17:00:31 <bparkis> so by analogy constructors are implicitly quoted
17:00:58 <LoganCapaldo> they aren't really similar in behavior to symbols, at least no more similar in behavior to symbols as numeric literals are
17:01:25 <pjd> this also depends what kind of macro system you're using
17:02:01 <pjd> you can't lump "lisp macros" together
17:02:03 <bparkis> well, it's not a big point but in Lisp, numeric literals can be quoted without changing their meaning
17:02:14 <bparkis> (eql '5 5)
17:02:21 <LoganCapaldo> exactly ;)
17:03:10 <LoganCapaldo> (i've always found the HOF + laziness <-analogy-> Lisp macros disingenious to be honest)
17:03:36 <SamB_XP> it's not so much an analogy as a cause for disinterest
17:04:09 <pjd> LoganCapaldo: well, lazy HOFs do correspond to a certain class of macros
17:04:09 <SamB_XP> bparkis: wierd
17:05:03 <LoganCapaldo> pjd: To a point, it's just that when you start talking about "details" it breaks down
17:05:03 <SamB_XP> so is (eql ''(5 6) '('5 '6)) too?
17:05:04 <pjd> macros can do more general things too, though
17:05:13 <SamB_XP> pjd: true
17:05:46 <SamB_XP> but the macros we'd care the most about would be those that do things that HOFs + laziness do for us now
17:06:20 <SamB_XP> only worse
17:06:21 <pjd> SamB_XP: nah; in that case, eql will receive '(5 6) and ('5 '6)
17:06:34 <SamB_XP> how about...
17:06:46 <SamB_XP> (eql '(5 6) '('5 '6))
17:06:48 <pjd> that is, (quote (5 6)) and ((quote 5) (quote 6))
17:06:59 <pjd> as plain lists
17:07:09 <mauke> still no
17:07:36 <LoganCapaldo> I think (eql '(5 6) (list '5 '6)) works
17:07:40 <LoganCapaldo> not sure
17:07:43 <mauke> quote works from the outside in, like laziness :-)
17:07:45 <SamB_XP> aha! so it's not so much that quoting numeric literals doesn't do anything as that numeric literals evaluate to themselves
17:07:48 <pjd> all that happens during application is that evaluation strips an (outer) layer of '
17:07:57 <mauke> SamB_XP: you win!
17:08:09 <pjd> SamB_XP: yes, exactly ;)
17:08:13 <LoganCapaldo> SamB_XP, numeric literals evaluating to themselves was my original point in bringing it up actually
17:08:35 <SamB_XP> so bparkis was either confused or lying
17:08:36 <pjd> strings and a few other values also evaluate to themselves
17:11:36 <bparkis> sorry, what?  I was AFK
17:11:52 <bparkis> what are you calling me on?
17:12:34 <SamB_XP> bparkis: you said that quoting numeric literals didn't change their meaning
17:12:42 <bparkis> it doesn't
17:12:48 <SamB_XP> it does
17:13:40 <pjd> that all depends on what you mean by "meaning"
17:13:42 <bparkis> quoting them twice will change their meaning
17:13:45 * pjd ducks
17:13:57 <bparkis> ''5 is not equal to 5
17:14:13 <SamB_XP> hmm.
17:14:25 <SamB_XP> ah right.
17:14:42 <SamB_XP> '5 has a value of five
17:14:43 <bparkis> but you can't substitute the '5 for a 5 in there because that would be evaluating within a quoted form
17:14:49 <SamB_XP> because 5 evaluates to 5
17:14:53 <SamB_XP> er.
17:14:53 <pjd> strictly speaking, it never changes the meaning of the literal, but does change the meaning of the expression
17:14:56 <SamB_XP> Well, no.
17:15:13 <SamB_XP> 5 has a value of 5 because numeric literals evaluate to themselves, yes, that's it...
17:15:29 <pjd> (in cases with more than the single outer layer of quoting)
17:15:32 <SamB_XP> so it's just that (eval 5) =
17:15:35 <SamB_XP> erg.
17:15:43 <LoganCapaldo> ' is not idempotent for numeric literals :)
17:15:48 <SamB_XP> (eval '5) = (eval ''5)
17:16:01 <LoganCapaldo> I've wanted to use the word "idempotent" all week :)
17:16:17 <bparkis> ' is not idempotent for anything
17:16:36 <SamB_XP> isn't it?
17:16:39 <mauke> eval (Quote x) = x
17:16:51 <mauke> eval (Num x) = Num x
17:16:58 <bparkis> but eval (quote (quote x)) is not equal to (quote x)
17:16:59 <dolio> What about an infinitely quoted value? :)
17:17:07 <bparkis> er wait
17:17:13 <LoganCapaldo> @karma+ dolio
17:17:13 <lambdabot> dolio's karma raised to 9.
17:17:14 <pjd> anyway, speaking of all this quoting!  what is the deal with Geoffrey Mainland's Haskell Workshop session?
17:17:15 <bparkis> (quote (quote x)) is not equal to (quote x)
17:17:17 <bparkis> evalling it is
17:17:24 <pjd> "Why It's Nice to be Quoted: Quasiquoting for Haskell"
17:17:29 <SamB_XP> #1='1# or whatever
17:17:42 <SamB_XP> I was trying to write that when dolio said that
17:17:53 <SamB_XP> I don't remember the syntax though
17:18:03 <SamB_XP> I bet ' is idemptotent for that
17:18:43 <dolio> I don't know how easy it is to construct such a thing, though.
17:19:11 <mauke> [1]> #1='#1#
17:19:11 <mauke> Segmentation fault
17:20:03 <mm_freak> is there any way to use implicit parameters inside of an instance declaration?
17:20:05 <byorgey> oh, I didn't know mauke came with a built-in lisp evaluator. =)
17:20:11 <SamB_XP> mauke: puny
17:20:23 <ndm> mm_freak: you probably don't want to use implicit params anywhere!
17:20:30 <SamB> * #1='#1#
17:20:30 <SamB> #1='#1#
17:20:38 <SamB> says
17:20:40 <SamB> CMU Common Lisp CVS 19c 19c-release-patch-1 + minimal debian patches (19C), running on hydrogen
17:20:59 <mauke> cmucl wins
17:21:03 <mm_freak> ndm: i've read that implicit configurations are the better alternative, but i don't comprehend them yet
17:21:39 <byorgey> mm_freak: what do you mean by "implicit parameters"?
17:22:06 <mm_freak> byorgey:  addm :: (?modulus :: Integer) => Integer -> Integer -> Integer
17:22:07 <dolio> @type f = ?x
17:22:09 <lambdabot> parse error on input `='
17:22:20 <dolio> @type let f = ?x in f
17:22:22 <lambdabot> forall t. (?x::t) => t
17:22:34 <ndm> mm_freak: they aren't, they suck and will be removed on day, and they are't in Yhc, so aren't Haskell
17:23:15 <mm_freak> ndm: implicit configurations are not a language featureâ€¦  you're confusing `parameters' with `configurations'
17:23:20 <ddarius> ndm: They aren't Haskell anyway.
17:23:33 <dolio> Implicit configurations are Oleg hackery.
17:23:43 <byorgey> ? I've never seen that syntax.
17:23:47 <mm_freak> what's the `right' way to do it?
17:23:56 <mm_freak> specifically for modular arithmetic
17:24:30 * byorgey goes off to read up on this...
17:24:31 <mm_freak> i don't comprehend implicit configurations anyway, so i'd be pretty happy about an easier alternative
17:24:52 <bparkis> though strictly speaking idempotent only applies to functions
17:25:11 <mauke> fix quote
17:25:26 <ndm> mm_freak: i'm just confused in general :)
17:25:45 <MarcWebe1> Is runhaskell called runghc now?
17:25:59 <mm_freak> wellâ€¦  implicit parameters (the language extension) are easy to understand and use, but not extremely elegant
17:26:02 <mauke> mm_freak: you could just copy the code from the configurations paper
17:26:29 <mm_freak> mauke: i don't like to use things i don't understand
17:26:40 <LoganCapaldo> I thought runhaskell was supposed to be a symlink to one of {runghc, runhugs, run<some other haskell impl>, ...}
17:26:51 <SamB_XP> bparkis: I can write a function that quotes a lisp AST
17:27:00 <conal> anyone here use wxHaskell with ghc-6.7?
17:27:10 <MarcWebe1> Hi conal!
17:27:21 <SamB_XP> however I'll write it in scheme because I can't remember CL's function syntax
17:27:34 <conal> MarcWebe1: hi!
17:28:10 <mm_freak> however, if you had neither implicit parameters, nor implicit configurationsâ€¦  what would be the way to go for modular arithmetic?
17:28:31 <mauke> (defun f () 42) (let ((g #'f)) (funcall g))
17:28:34 <SamB_XP> (define (q ast) `(quote ,ast))
17:28:55 <mm_freak> (non-monadic, of course)
17:29:31 <SamB_XP> mm_freak: encode the modulus in the type!
17:29:33 <MarcWebe1> conal: I'll start compiling it within the next 2minutes.. Will take some time though
17:29:40 <MarcWebe1> conal: Which trouble do you have?
17:30:06 <byorgey> mm_freak: http://okmij.org/ftp/Haskell/number-parameterized-types.html
17:30:07 <lambdabot> Title: Haskell Programming: Types that depend on numbers
17:30:12 <conal> MarcWebe1: Can't locate vars.pm in @INC (@INC contains: .) at c:\ghc\ghc-6.7.20070802\ghc-asm line 1290.
17:30:23 <bparkis> AST being an acronym for what??  abstract source tree?
17:30:30 <pjd> syntax
17:30:30 <byorgey> Abstract Syntax Tree
17:30:31 <mauke> conal: your perl is broken :-)
17:30:45 <mm_freak> byorgey: thanks
17:31:10 <conal> mauke: i guess so.  i'm not sure which perl is being used.  i have a /perl/bin/perl and one with ghc.
17:31:15 <byorgey> mm_freak: you're welcome =)
17:32:05 <bparkis> that wouldn't work SamB_XP
17:32:09 <SamB_XP> conal: you could try -fasm
17:32:12 <bparkis> ast would be evaluated first
17:32:25 <conal> SamB_XP: that might help?
17:32:31 <SamB_XP> bparkis: ast is an ast
17:32:38 <pjd> so, does anyone know something about Geoffrey Mainland's Quasiquoting for Haskell thing?
17:32:38 <mauke> (defmacro lolwut (ast) ast)
17:32:39 <SamB_XP> i.e. it was already quoted ;-)
17:32:52 <bparkis> ok, you can do that, but then q is not quote
17:33:04 <SamB_XP> never said it was quote
17:33:17 <bparkis> then what was the point?
17:33:44 <conal> anyone know how I can point ghc's perl's INC to my /Perl/lib ?
17:33:48 <SamB_XP> basically I restated the macro as a function between ASTs
17:34:21 <SamB_XP> so that the word idempotent could be used about it
17:35:00 <pjd> quote is the explicit identity function between ASTs, though
17:35:22 <pjd> (as opposed to the implicit evaluation function)
17:36:26 <bparkis> ok, then q is not idempotent
17:36:58 <conal> SamB_XP: removing -fvia-C did fix the problem.  thanks.
17:37:18 <bparkis> and you get around the problem of '5 being equal to 5
17:37:59 <bparkis> so it doesn't "seem" idempotent there either unlike quote
17:41:22 <kpreid> mauke, SamB: re #1='#1#, that's an option: cl:*print-circle*
17:42:43 <mauke> kpreid: still. a segfault? in a dynamic interpreter?
17:42:48 <mauke> that's pretty weak
17:42:56 <kpreid> an interpreter, you say?
17:42:58 <dons> crazy stuff, http://importantshock.wordpress.com/2007/08/21/haskell-curry-yes-i-dated-his-daughter/
17:43:01 <lambdabot> Title: &#8220;Haskell Curry? Yes, I dated his daughter.&#8221; « Important Shock, http://tinyurl.com/yo35nu
17:43:05 <dons> ?users
17:43:05 <lambdabot> Maximum users seen in #haskell: 419, currently: 372 (88.8%), active: 22 (5.9%)
17:43:07 <dons> huh
17:43:13 <mauke> yes, clisp
17:43:36 <kpreid> I will be surprised if clisp's printer isn't compiled. Or possibly even written in C.
17:44:26 <kpreid> but I only wished to point out that handling circular structure is an option, not an implementation variance
17:44:50 <mauke> I don't care if it's an option; it should never segfault ever
17:45:18 <chessguy> dons, that page a s/new-ish/not-so-new/ :)
17:45:25 <kpreid> well, I don't disagree
17:45:27 <LoganCapaldo> dons: Imagine if they had had children together. It would have been some kind of super-being
17:45:51 <dons> chessguy: oh, its from somewhere else?
17:45:52 <dons> `August 21, 2007
17:46:01 <wli> Hmm. 10^(k*5^(n+1))+1 = (10^(k*5^n)+1)*(10^(4*k*5^n)-10^(3*k*5^n)+10^(2*k*5^n)-10^(k*5^n)+1 which recursively breaks down.
17:46:07 <chessguy> dons, hm?
17:46:17 <wli> LoganCapaldo: The Muad'Dib of functional programming?
17:46:23 <chessguy> dons, he says haskell is a new-ish language, which it really isn't
17:46:33 <dons> that's true.
17:47:30 <LoganCapaldo> wli: One can only speculate...
17:48:02 <conal> success building & running wxhaskell with ghc-6.7 on WinXP !
17:48:06 <chessguy> @go muad'dib
17:48:08 <lambdabot> http://en.wikipedia.org/wiki/Muad'Dib
17:48:08 <lambdabot> Title: Muad'Dib - Wikipedia, the free encyclopedia
17:48:21 * byorgey high-fives conal!
17:48:42 <conal> :)
17:48:51 <dons> cool
17:48:56 <samreid> ^^ what byorgey said
17:49:44 <conal> there were stumbling blocks.  i kept notes, so if anyone tries & has trouble, let me know.
17:49:58 <chessguy> @ghc
17:49:58 <lambdabot> ghc says: accepting non-standard pattern guards (-fglasgow-exts to suppress this message)
17:51:24 <bos> gah, i've forgotten my hackage password.
17:51:33 <dons> bos, you need a new one?
17:51:40 <dons> or do you have the original email?
17:51:46 <bos> yes, seems like i need human assistance. oh!
17:51:57 <dons> ok. i'll send a new one
17:52:06 <bos> i must have changed it.
17:52:08 <bos> thanks!
17:52:13 <bparkis> there's a pretty direct mapping between pattern matching Haskell functions, and Turing machines
17:52:14 * dons likes it when bos uploads things to hackage
17:52:24 <mauke> @ghc
17:52:24 <lambdabot> ghc says: Too many parameters for class
17:52:31 <LoganCapaldo> dons: You're an enabler.
17:52:46 <dons> heh
17:52:50 <LoganCapaldo> You're not helping bos, your just feeding his hackage addiction
17:53:15 <bparkis> let f be a function of n arguments that does not call any other functions besides itself
17:53:57 <bos> http://darcs.serpentine.com/suffixtree/dist/doc/html/Data-SuffixTree.html
17:54:00 <lambdabot> http://tinyurl.com/2dttxd
17:54:08 <dons> bos, see privmsg. sent you new details
17:54:10 <bparkis> so every line of the definition of f is f <pattern matches> = f <values> or is f <pattern matches> = <literal value>
17:55:05 <dons> bos, did you see ABN AMRO is giving a haskell talk at CUFP?
17:55:13 <dons> notch up yet another bank using haskell.
17:55:23 <dons> and there's a guy from Barclay's posting ghc bug queries to the ghc list
17:55:37 <bparkis> except that f may call data constructors, but no other functions
17:55:43 <bos> dons: yeah, nifty
17:55:51 <TuringTest> dons: very nifty
17:55:52 <wli> dons: I should really work on learning Malliavin calculus.
17:56:17 <TuringTest> bos: I just logged in -- is the suffix try ast pst or cst from the paper?
17:56:41 <bos> TuringTest: cst
17:56:41 <dons> hey TuringTest . glad to you see you back!
17:57:07 <bos> ast is just a trie, and pst is unbearably slow
17:57:10 <TuringTest> dons: Did you see the Boyer Moore search module for Bytestring?
17:57:15 <dons> yes!
17:57:31 <bparkis> a Turing machine is representable by functions of the form f <state-match> <tape-match> <input> = f <new-state> <new-tape> <popped-input>
17:57:37 <dons> TuringTest: i'm a bit busy to hack it in atm, moving to the US in a few days.
17:57:47 <dons> TuringTest: but i'll look at it after that, unless dcoutts gets to it first
17:57:53 <TuringTest> dons: Nice -- good luck with the move.
17:58:07 <dons> cheers
17:59:06 <TuringTest> bos: Have you looked at suffix arrays? They seem to be as useful as a suffix tree and might take less space: http://portal.acm.org/citation.cfm?id=1242471.1242472
17:59:08 <lambdabot> Title: A taxonomy of suffix array construction algorithms
17:59:18 <byorgey> dons: where are you moving to?
17:59:56 <dons> byorgey: portland, to work for galois.
18:00:02 <byorgey> dons: nifty.
18:00:27 <dons> bos, i added the bay area fp meeting to the haskell.org frontpage.
18:00:44 <dons> http://kfahlgren.com/blog/2007/08/21/san-francisco-bay-area-fp-group/
18:00:46 <lambdabot> Title: Keith&#8217;s Blog -- The ramblings/life in San Francisco/code, http://tinyurl.com/2f8o23
18:00:47 <dons> for those who didn't see it.
18:06:40 <pjd> > fromListWith (+) . flip zip [1,1..] $ "abracadabra"
18:06:41 <lambdabot>   Not in scope: `fromListWith'
18:06:45 <pjd> > M.fromListWith (+) . flip zip [1,1..] $ "abracadabra"
18:06:47 <lambdabot>  fromList [('a',5),('b',2),('c',1),('d',1),('r',2)]
18:08:18 <mauke> fromRussiaWith love
18:08:39 * pjd endeavors to use "flip zip" wherever it is possible
18:09:21 <LoganCapaldo> > zip `flip` [1,1..] $ "abracadabra"
18:09:23 <lambdabot>  [('a',1),('b',1),('r',1),('a',1),('c',1),('a',1),('d',1),('a',1),('b',1),('r...
18:09:37 <LoganCapaldo> zip `flip` !!
18:43:37 <shapr> Hey, can I propogate the _darcs/prefs/defaults when put'ing a repo?
18:44:37 <dons> you can scp it.
18:44:43 <dons> not sure if it does it by default
18:44:49 <dons> ?users
18:44:49 <lambdabot> Maximum users seen in #haskell: 419, currently: 371 (88.5%), active: 2 (0.5%)
18:44:54 <dons> more high scores
18:45:02 <phobes> Can anyone recommend a program for organizing papers?   Anything better than JIRA?
18:45:27 <Nafai> phobes: You're using JIRA to organize papers?  JIRA the bug tracker?
18:45:29 <shapr> phobes: Organize how?
18:45:49 <phobes> err, woops.  JabREF ... mental lapse sorry
18:46:04 <phobes> Anything better than JabRef
18:46:12 <dons> hmm. maybe a good paper organising system is something we could produce
18:46:17 <dons> we know the domain rather well in here
18:46:25 * dons always looks for niches to take over
18:46:30 <shapr> Um, Fermat's Last Margin? :-)
18:46:38 <shapr> Which isn't working yet :-(
18:46:53 <shapr> No clue how BibTeX works, so not sure if it'd be useful to add to FLM.
18:47:13 <phobes> dons:  what kind of features would you want in that system?
18:49:52 <shapr> FLM is really just for making notes associated with one page of a paper, I don't know anything about organizing papers.
18:50:00 <dons> phobes: something that organised my papers and made them earchable?
18:50:15 <sorear> isn't that called google?
18:50:16 <dons> ways of extracting bibtex from papers
18:50:26 <dons> sorear: hmm, not so good.
18:50:33 <dons> you have a big pile of .ps.gz and .pdf papers locally on a topic
18:50:35 <sorear> "Don Steward"  more key words
18:50:42 <shapr> pstoedit turns pdf/ps into SVG, ImageMagick turns pdf/ps into png/jpg/etc
18:50:47 <Igloo> A distributed system for getting complete bibtex entries for papers would be nice
18:50:49 <dons> and you want to get bibtexs for them, search text, that kind of thing
18:50:52 <sorear> that does have the spelling problem
18:50:55 <dons> Igloo: yeah
18:51:00 <Igloo> Except you might get religious wars about how things should be bibtexed
18:51:03 <shapr> heh
18:51:27 <shapr> If you run strings on a pdf/ps, do you get the actual text?
18:51:35 <shapr> If so, should be easy to index.
18:51:41 <dons> Igloo: or you provide multiple bibtex, like for abcde/cd database
18:51:42 <Igloo> Although 99% of papers in our field you could probably cover by dictating the Right Thing from on high
18:52:21 * ddarius doesn't read papers soley from "our" field.
18:52:21 <Igloo> pdftotext exists, although it obviously won't do any good for older papers etc that are just scans
18:52:41 <Igloo> Right, but as it grows you can dictate more widely
18:52:42 <shapr> Igloo: But Google's Tesseract OCR could help there..
18:53:10 <Igloo> multiple bibtexs for the same publication would be a sign of failure, I think
18:53:13 <shapr> I wonder if a centralized word index for papers counts as "for personal use only"
18:53:45 <Igloo> You might have the main bibtex for foo (in ICFP, maybe) and the bibtex for foo (as earlier published in tech report blah), though
18:53:57 <phobes> shapr:  If not, you could always set that part up peer-to-peer?
18:55:15 <phobes> (and by that I really just mean swapping collections with your friends)
18:56:08 <ddarius> Technically with a next-word index you can rebuild the entire text of a paper.
18:56:55 <Pseudonym> Well theoretically, you can do that with a suffix array index, too.
18:57:03 <Pseudonym> Since you can just invert the BWT.
18:58:13 <Igloo> Although being able to rebuild "The type inference rules are shown in Figure 8" isn't an awful lot of use  :-)
18:58:55 <phobes> It would be pretty nice to have a facility that finds all the papers you have locally in a big database and then gives you the bibtex information and working links to the references, etc. (maybe just a working link to citeseer)
18:59:15 <shapr> phobes: Yeah, that's how FLM works. You annotate page images, and only the annotations are saved in the darcs repo. Then you pull from people you know.
18:59:26 <Pseudonym> You can access Citeseer and the ACM Digital Library from most places.
18:59:33 <Pseudonym> Those places are full of metadata.
18:59:57 <Igloo> citeseers bibtex entries generally aren't very useful, though
19:00:09 <shapr> Yay, my 500gb drive just arrived.
19:00:11 <Pseudonym> The citation entries are, though.
19:01:18 <shapr> phobes: Links to references wouldn't be hard to add to FLM annotations, but it'd have to be done by someone, and then others could pull those annotations.
19:01:41 <bparkis> I wonder what attempts have been made to introduce types into neural networks
19:02:13 <phobes> shapr: I haven't looked at FLM yet and google doesn't turn it up - do you have a link? (is anything up?)
19:02:14 <Pseudonym> For that matter, how about neural networks into types.
19:02:18 <shapr> FLM is nearly working... it can pull ps/pdf, generate page images and matching wikipages, I'm just having some inexplicable problems with the new HAppS code :-(
19:02:30 <Pseudonym> "Sorry, I can't prove that your program is type correct.  Please supply more type-correct programs for me to analyse."
19:02:36 <ddarius> bparkis: For the aspects that I consider interesting that would be counter productive.
19:02:42 <shapr> phobes: Nah, nothing is up yet, but I think it should be up by this weekend.
19:03:11 <bparkis> well I have something in mind, consider the nodes as functions and let them connect up randomly so long as types match
19:03:12 <ddarius> Pseudonym: How do you provide type correct tests if your type checker doesn't know they are type correct?
19:03:37 <Pseudonym> Obviously you need an oracle.
19:03:57 <bparkis> but it wouldn't do to have a built in fixed set of types, the types would somehow have to change as the network learns
19:04:37 <Pseudonym> BTW, I _hope_ nobody is taking my suggestion seriously.
19:04:47 <wli> > let n = (11*41*271*9091) * (101 * 3541 * 27961 * 60101 * 7019801 * 14103673319201 * 1680588011350901 * 251 * 5051 * 21401 * 25601 * 182521213001 * 78875943472201) in nub $ show n
19:04:56 <lambdabot>  "1"
19:06:45 <phobes> > (11*41*271*9091) * (101 * 3541 * 27961 * 60101 * 7019801 * 14103673319201 * 1680588011350901 * 251 * 5051 * 21401 * 25601 * 182521213001 * 78875943472201)
19:06:47 <lambdabot>  1111111111111111111111111111111111111111111111111111111111111111111111111111...
19:07:13 <ddarius> Pseudonym: How about training a neural net on code that doesn't type check and have it provide description of what it thinks the actual error is.
19:07:34 <phobes> let n = (11*41*271*9091) * (101 * 3541 * 27961 * 60101 * 7019801 * 14103673319201 * 1680588011350901 * 251 * 5051 * 21401 * 25601 * 182521213001 * 78875943472201) in length $ show n
19:07:40 <phobes> > let n = (11*41*271*9091) * (101 * 3541 * 27961 * 60101 * 7019801 * 14103673319201 * 1680588011350901 * 251 * 5051 * 21401 * 25601 * 182521213001 * 78875943472201) in length $ show n
19:07:42 <lambdabot>  100
19:08:12 <wli> 10^(1*10^0)+1 = 11, 10^(4*10^0)-10^(3*10^0)+10^(2*10^0)-10^(10^0)+1 = 9091, 10^(4*10^0)+10^(3*10^0)+10^(2*10^0)+10^(10^0)+1 = 41 * 271, 10^(2*10^0)+1 = 101, 10^(8*10^0)-10^(6*10^0)+10^(4*10^0)-10^(10^0)+1 = 3541 * 27961, 10^(4*10^1)-10^(3*10^1)+10^(2*10^1)-10^(10^1)+1 = 60101 * 7019801 * 14103673319201 * 1680588011350901, 10^(4*10^1)+10^(3*10^1)+10^(2*10^1)+10^(10^1)+1 = 251 * 5051 * 21401 * 25601 * 182521213001 * 78875943472201
19:08:57 <wli> phobes: Enlightening at all?
19:09:18 <dibblego> what are you doing with those big numbers!?
19:09:35 <dibblego> 4294967296 is a big enough number for anyone
19:09:47 <int-e> > 4294967296 :: Int
19:09:49 <lambdabot>  0
19:09:50 <wli> dibblego: Factoring (10^(10^n)-1)/9 to check for certain properties.
19:11:57 <bparkis> thats only 4 billion
19:12:36 <wli> Try factoring 2^(2^(2^5))+1 or some such.
19:14:45 <wli> Well 2^(2^7)+1 is already hard enough.
19:23:01 <wli> What I should really do with all this is implement Pohlig-Hellman so I can fiddle with discrete logarithms.
19:25:33 <wli> phobes/dibblego: http://hpaste.org/2377
19:25:57 <desp> what C type does Bool correspond to, through the FFI?
19:26:19 <desp> I mean...ugh.
19:26:31 <mauke> none, I hope
19:27:12 <desp> mauke: what do you mean?
19:27:39 <mauke> why should Bool map to a C type?
19:28:00 <bparkis> is this one kind of whole-program optimization currently used: transforming functions into a large FSM for a program together with a set of recursive data, then performing state-minimization on the FSM?
19:28:12 <desp> ah. right.
19:28:20 * desp shakes head at himself
19:28:48 <pgavin> okay, I have a design question I could use some insight on, if anyone's up for it :)
19:29:16 <pgavin> so, I have a whole crapload of state that needs to be kept track of
19:29:38 <pgavin> but not all of it is mutable
19:29:46 <pgavin> in fact, most of it isn't
19:29:48 <pgavin> or shouldn't be
19:30:10 <pgavin> but it would be convenient to tuck it into a monad
19:30:26 <pgavin> is this considered bad "style"?
19:31:07 <int-e> pgavin: hmm. use a ReaderT for the immutable 'state' and a StateT for the rest?
19:31:20 <pgavin> monad transformers aren't an option
19:31:26 <int-e> oh
19:31:31 <pgavin> but I'll check out ReaderT, for guidance :)
19:31:53 <Pseudonym> pgavin: Check out IRC.hs in the lambdabot sources.
19:32:03 <pgavin> hmm, ok :)
19:32:47 <pgavin> IRCBase.hs?
19:33:08 <Pseudonym> Yeah, that's it.
19:33:13 <Pseudonym> It's changed name since I looked at it last.
19:33:31 <Pseudonym> Erm.
19:33:32 <Pseudonym> Maybe.
19:33:52 <pgavin> heh :)
19:34:01 <Pseudonym> Ah, that's it.
19:34:03 <Pseudonym> Lambdabot.hs
19:34:10 <Pseudonym> There's IRCRState and IRCRWState
19:34:43 <dons> the use of ReaderT and StateT in xmonad might be useful as an example
19:34:44 <Pseudonym> Lambdabot currently implements the RWState as an IORef.
19:34:53 <Pseudonym> But it was originally StateT.
19:35:11 <wli> Pseudonym: Why did it change?
19:35:19 <Pseudonym> wli: Don't look at me.
19:35:28 <dons> wli, that's ost in the mist of time
19:35:31 <dons> lost
19:35:37 <Pseudonym> I didn't even know which module it was in.
19:35:39 <wli> dons: No worries.
19:35:58 <dons> pgavin: look at http://darcs.haskell.org/~sjanssen/xmonad/XMonad.hs
19:36:00 <dons> grep for newtype
19:36:02 <int-e> dons: maybe somebody wanted to change state asynchronously?
19:36:10 <dons> int-e: seems likely
19:36:37 <dons> lambdabot could stand to be rewritten in a post-STM, TVar style.
19:36:43 <pgavin> thanks for the pointers
19:36:48 <ddarius> TChan style!
19:36:59 <pgavin> sorry, I was afk reading code for a minute there :)
19:37:00 <dons> yeah. more threads, more bytestrings, less weird monad stacks
19:37:02 <sjanssen> lambdabot could maybe an HAppS application
19:37:03 <wli> I'm clueless about STM and TVars.
19:37:10 <sjanssen> s/maybe/maybe be
19:37:18 <RyanT5000> dons: did you ever get a chance to look at that code?
19:37:19 <sorear> wli: I suspect the switch to ioref is related to threading
19:37:25 <ddarius> sjanssen: And an IRC bot?
19:37:26 <dons> RyanT5000: ah you're back!
19:37:34 <RyanT5000> dons: yeah; i've been camping and in canada and such
19:37:35 <dons> RyanT5000: no, i'm busy atm. I think you should upload it to the shootout
19:37:40 <RyanT5000> dons: alright
19:37:40 <sorear> dons: do we still know why threads were added to lambdabot?
19:37:57 <ddarius> sorear: Where?
19:38:00 <dons> sorear: seemed like a good idea?
19:38:03 <sjanssen> ddarius: HAppS is multi-protocol -- imagine adding support for the IRC protocol
19:38:07 <dons> RyanT5000: https://alioth.debian.org/tracker/?func=browse&group_id=30402&atid=411646
19:38:08 <lambdabot> http://tinyurl.com/2ecshd
19:38:18 <dons> RyanT5000: be sure to mention its haskell / GHC
19:38:28 <wli> I'm at something of a loss to see why threads are needed.
19:38:30 <dons> sorear: i'd use more threads now , if anything :)
19:38:32 <sjanssen> ddarius: it already tries to solve a bunch of the problems an IRC bot has, accepting events, serialization, etc.
19:38:45 <RyanT5000> dons: alright
19:38:55 <dons> RyanT5000: and also upload to the wii page
19:39:00 <dons> ?wiki Shootout
19:39:00 <lambdabot> http://www.haskell.org/haskellwiki/Shootout
19:39:44 <dons> i think we could do a much simpler, stripped down, buildable lambdabot now
19:39:54 <dons> but maybe we don't care enough to do that
19:40:13 * ddarius wants plugins to be independent concurrent "processes".
19:40:26 <dons> they're separate threads with private state currently
19:40:46 <sorear> dons: As I see it, losing determinism is a far higher price than we are able to afford.
19:40:46 <dons> so that seems right. i'd keep that model
19:40:48 <wli> Where do I book up on STM and TVars?
19:40:49 <reltuk`> ddarius: erlang message-passing style?
19:40:58 <sorear> dons: that's why I question the utility of threads here
19:40:58 <ddarius> reltuk`: Something like that.
19:41:09 <ddarius> @google Simon Peyton Jones
19:41:11 <lambdabot> http://research.microsoft.com/~simonpj/
19:41:11 <lambdabot> Title: Simon Peyton Jones
19:41:13 <ddarius> wli: There
19:41:22 <dons> sorear: what's the problem though?
19:41:24 <wli> Okay. ;)
19:41:36 <dons> sorear: we needed threads due to long running computations in privmsg
19:41:41 <sjanssen> sorear: some things need to be asynchronous though, like the tinyurl and title stuff
19:41:45 <dons> people would compute something that took a while, and the bot would look up
19:41:52 <dons> lock. or do net searches, yeah
19:41:55 <dons> it has to be async
19:42:21 <ddarius> lambdabot's a server.  Clearly it needs some support for asynchrony.
19:42:23 <sjanssen> oh yeah, @run has to be async.  @type too, probably
19:42:39 <sorear> was all that worth the Netsplit Bug?
19:42:41 <dons> and forking a thread per request scales nicely to the smp runtime
19:42:56 * ddarius would like lambdabot to be a server to it's plugins as well.
19:43:19 <shapr> REST?
19:43:21 <dons> sorear: there's always been bugs. and yes, a usable bot is worth it.
19:44:00 <dons> you weren't around before the thread stuff. we'd complain about the bot not responding, and then people would apologies for running things in privmsg. that went away with the per-request threading.
19:44:02 <shapr> sjanssen: IRC for HAppS would be quite nifty.
19:44:53 <dons> sorear: what happened with lambdabot 7? did you get any code together?
19:44:56 * glguy has been hoping to see that happen for a while :)
19:45:55 <shapr> glguy: IRC for HAppS?
19:46:04 <shapr> That would simplify hpaste...
19:46:17 <glguy> shapr: yup
19:46:41 <shapr> I was reading about Data.Binary, and it seems fine for pulling apart things of a given size, but would it be good for reading jpeg files too?
19:46:44 <glguy> we tossed it around in channel a while ago... but I never understood how agents worked well enough to add it
19:46:51 <shapr> Or would that require ParsecT?
19:47:06 <shapr> glguy: Would be pretty easy, have you seen Server.UDP and Server.HTTP ?
19:47:15 <sorear> dons: No, every design I can think of is horrible
19:47:24 <shapr> Er, it would require Agents now that you mention it.
19:48:40 <dons> shapr: yeah, i reckon i'd use Data.Binary for that job
19:48:50 <dons> it'd be as fast as you could get it, i suspect.
19:49:13 <phobes> How many LoC is HAppS?  (ballpark)
19:49:19 <dons> sorear: something erlangy. lots of threads, very little state.
19:49:28 <sorear> phobes: 1k
19:49:59 <shapr> Hm, I thought it was 7k lines.
19:50:11 <sjanssen> 6921
19:50:13 <phobes> that's pretty impressive either way .... 1k is amazing
19:50:15 <sjanssen> according to sloccount
19:50:20 <dons> hpaste is < 1k
19:50:24 <sorear> dons: what happens to something with little explicit state when the power dies at UNSW?
19:50:40 <ddarius> hpaste should be less than 1kloc.
19:50:49 <sorear> sjanssen: that's probably including the non-Haskell parts
19:51:00 <shapr> ddarius: It'd be much smaller with an IRC agent.
19:51:06 <dons> sorear: i think you misunderstand. less state in the main thread.
19:51:14 <sjanssen> sorear: sloccount reports that they're Haskell source files
19:51:42 <shapr> I suspect there's some dead code in HAppS that could be trimmed out.
19:51:53 <shapr> Quite a bit since the recent core changes.
19:52:00 * ddarius doubts there is 5921 lines of it.
19:52:15 <sorear> oh
19:52:18 <sorear> hah
19:52:32 <sorear> I still thought you were talking about hpaste, sorry. :)
19:55:22 <mauke> :t let a=b.b;b=c.c;c=d.d;d=z.z; z x=(x,x) in a
19:55:38 <lambdabot> thread killed
19:55:49 <mauke> @bot snack
19:55:50 <lambdabot> :)
19:57:20 * shapr boings
19:57:31 <mauke> :t let a=b.b;b=c.c;c=z.z; z x=(x,x) in a
19:57:33 <lambdabot> forall a. -> ((((((((a, a), (a, a)), ((a, a), (a, a))), (((a, a), (a, a)), ((a, a), (a, a)))), ((((a, a), (a, a)), ((a, a), (a, a))), (((a, a), (a, a)), ((a, a), (a, a))))), (((((a, a), (a, a)), ((a,
19:57:33 <lambdabot>  a), (a, a))), (((a, a), (a, a)), ((a, a), (a, a)))), ((((a, a), (a, a)), ((a, a), (a, a))), (((a, a), (a, a)), ((a, a), (a, a)))))), ((((((a, a), (a, a)), ((a, a), (a, a))), (((a, a), (a, a)), ((a,
19:57:33 <lambdabot> a), (a, a)))), ((((a, a), (a, a)), ((a, a), (a, a))), (((a, a), (a, a)), ((a, a), (a, a))))), (((((a, a), (a, a)), ((a, a), (a, a))), (((a, a), (a, a)), ((a, a), (a, a)))), ((((a, a), (a, a)), ((a,
19:57:33 <lambdabot> a), (a, a))), (((a, a), (a, a)), ((a, a), (a, a))))))), (((((((a, a), (a, a)), ((a, a), (a, a))), (((a, a), (a, a)), ((a, a), (a, a)))), ((((a, a), (a, a)), ((a, a), (a, a))), (((a, a), (a, a)), ((a,
19:57:36 <lambdabot>  a), (a, a))))), (((((a, a), (a, a)), ((a, a), (a, a))), (((a, a), (a, a)), ((a, a), (a, a)))), ((((a, a), (a, a)), ((a, a), (a, a))), (((a, a), (a, a)), ((a, a), (a, a)))))), ((((((a, a), (a, a)), (
19:57:39 <lambdabot> (a, a), (a, a))), (((a, a), (a, a)), ((a, a), (a, a)))), ((((a, a), (a, a)), ((a, a), (a, a))), (((a, a), (a, a)), ((a, a), (a, a))))), (((((a, a), (a, a)), ((a, a), (a, a))), (((a, a), (a, a)), ((a,
19:57:42 <lambdabot>  a), (a, a)))), ((((a, a), (a, a)), ((a, a), (a, a))), (((a, a), (a, a)), ((a, a), (a, a))))))))
19:57:43 <Olathe> O-o
19:57:48 <mauke> ok, so that still works
19:58:22 <ddarius> Olathe: H-M type inference is exponential worst case.
19:59:05 <mauke>  :t needs a line limit
19:59:38 <Olathe> Is there something like nest f 3 which returns f.f.f ?
20:00:00 <ddarius> :t (foldr (.) id .) . replicate
20:00:02 <lambdabot> forall a. Int -> (a -> a) -> a -> a
20:00:26 <ddarius> :t flip $ (foldr (.) id .) . replicate
20:00:27 <lambdabot> forall a. (a -> a) -> Int -> a -> a
20:02:24 <ddarius> :t \f n -> (!! n) . iterate f
20:02:26 <lambdabot> forall a. (a -> a) -> Int -> a -> a
20:03:01 <Olathe> My brain !
20:03:52 <Olathe> OK, the iterate makes sense.
20:03:56 <dolio> Better use genericIndex in case you need to compose a function with itself more than 2147483647 times.
20:04:08 <mauke> yay, the type of  let a=b.b;b=c.c;c=z.z; z x=(x,(x,x)) in a  is 166 lines long
20:04:29 <Olathe> The flip is starting to make sense.
20:07:10 <reltuk`> what's a good way of thinking about a "hanging compose"
20:07:26 <reltuk`> (foldr (.) id _._) . replicate
20:07:30 <reltuk`> the underlined one :-p
20:07:45 <ddarius> @unpl (f .) . g
20:07:45 <lambdabot> (\ d i -> f (g d i))
20:08:21 <mauke> imagine what happens when you apply it to an argument x
20:08:47 <mauke> ((foldr (.) id _._) . replicate) x --> (foldr (.) id . replicate x)
20:10:23 <Olathe> In (foldr (.) id .), what does the last dot do ?
20:10:48 <ddarius> Olathe: It's a section.
20:10:48 <mauke> it composes functions
20:10:59 <ddarius> Like (3 +)
20:11:15 <glguy> (f .)  === (.) f
20:11:38 <Olathe> So, is it composing id with something or foldr with something ?
20:11:51 <ddarius> ((foldr (.) id) .)
20:11:56 <Olathe> Oh.
20:12:37 <mauke> > (sqrt 2 +) 1
20:12:39 <lambdabot>  2.414213562373095
20:12:59 <Olathe> Well, that's something unique.
20:13:27 <mauke> also, (f .) . g  ==  \x y -> f (g x y)
20:13:42 * ddarius could -almost- have (3 +) == (foldr (.) id .)
20:15:15 <shapr> hyvÃ¤Ã¤ huomenta Zzompp
20:15:35 <bos> pÃ¤ivÃ¤Ã¡
20:16:04 <shapr> bos: What? No Gaelic?
20:16:08 <bos> :-)
20:16:25 <shapr> I used to live with a guy from Dublin, he spoke Gaelic well.
20:16:31 <Olathe> mauke: How does that work ?
20:17:02 <mauke> what
20:17:40 <shapr> bos: Written any cool code lately?
20:17:46 <Olathe> mauke: (f .) . g == \x y -> f (g x y)
20:18:00 <Olathe> > let f x = x + 1 in let g x y = x * y in ((f .) . g) 2 10
20:18:01 <lambdabot>  21
20:18:13 <ddarius> @src (.)
20:18:13 <lambdabot> (.) f g x = f (g x)
20:18:17 <Olathe> > let f x = x + 1 in (f .) 20
20:18:18 <lambdabot>   add an instance declaration for (Num (a -> b))
20:18:36 <mauke> 20 is not a function (yet)
20:19:30 <Olathe> Oh, currying.
20:20:30 <shapr> Zzompp: Learning Haskell?
20:20:47 <glguy> @uses
20:20:47 <lambdabot> Maximum users seen in #haskell: 419, currently: 374 (89.3%), active: 13 (3.5%)
20:20:57 <Olathe> > let f x = x + 1 in let g x y = x * y in (.) ((.) f) g 2 10
20:20:59 <lambdabot>  21
20:22:06 <Zzompp> shapr: yes, or atleast looking into it
20:22:16 <ddarius> > let f = (+ 1); g = (*) in ((.) . (.)) f g 2 10
20:22:17 <lambdabot>  21
20:22:35 <bos> shapr: just writing up a release announcement for a small library
20:23:01 <Olathe> So, it gets (g 2) and composes that with f ?
20:23:12 <Nafai> bos: How's the writing going?
20:25:14 <shapr> Zzompp: Got any questions? Want any info?
20:25:16 <shapr> bos: Cool!
20:26:06 <bos> Nafai: good, took a break to write some code for a few days
20:26:07 <Zzompp> thanks, but not yet :) i joined the channel to see how things are here
20:26:16 <shapr> Zzompp: Ok, if you have any questions, feel free to ask.
20:26:20 <Zzompp> thanks
20:26:23 <Nafai> bos: Both good!
20:27:38 <bos> @where+ suffixtree http://www.serpentine.com/software/suffixtree/
20:27:39 <lambdabot> Done.
20:27:42 <shapr> Zzompp: And in case you're wondering... I lived in Tornio for 3.5 years.
20:27:46 <shapr> bos: ooh cool!
20:28:49 * ddarius downloaded that paper, but hasn't looked at it yet.
20:28:52 <Zzompp> ok :) i'm from helsinki
20:29:27 <bos> ddarius: the giegerich/stolz one?
20:29:32 <shapr> Zzompp: That's a much nicer place than Tornio.
20:29:40 <ddarius> bos: Yes.
20:29:58 <bos> it's possible to build suffix trees more efficiently, but the algorithm requires destructive updates.
20:30:31 <Zzompp> well, i've never been to tornio so can't comment on that, but helsinki is really nice
20:30:53 <shapr> I visited friends in Oulu, I liked that town.
20:31:51 <Zzompp> that's quite far up north, at least from my perspective :)
20:32:07 <shapr> Yeah, I agree. I later moved to Boden, Sweden and then to Stockholm.
20:32:15 <shapr> But now I'm back in Alabama!
20:32:24 <Zzompp> :)
20:32:38 <shapr> Zzompp: What got you interested in Haskell? (If I'm distracting you from real work or something, I'll leave you alone :-)
20:33:15 * shapr is hacking on HAppS while he chats
20:33:27 <Zzompp> well, I started to dabble with different languates.. guess I got bored with the ones I have used (python, php, perl and their ilk)
20:33:51 <Zzompp> so now I'm looking into haskell, ocaml, common lisp, scheme as a hobby
20:33:58 <shapr> That makes sense, Python was my language of choice before I started with Haskell.
20:34:28 <shapr> Those are good choices! Have you also looked at concatenative languages like Joy, Forth, and Factor?
20:34:34 <shapr> And postscript, of course.
20:34:50 <Zzompp> actually no.. I've heard about Joy, I think
20:34:53 * bos went 6502 -> scheme -> c -> perl -> haskell -> java -> c++ -> python -> haskell
20:35:40 <shapr> I like Joy a lot, it's pretty.
20:36:04 * mauke BASIC -> pascal -> c -> bash -> perl -> o'caml -> java -> c++ -> haskell
20:36:10 <Zzompp> now I actually do some work using python, but I noticed that using common lisp (if only a little) gave me new perspective into coding it.. so I thought learning a few more languages might change my coding style even more, and probably for the better
20:36:21 <shapr> Zzompp: Oh, I do that too!
20:37:02 <Nafai> bos: Interesting you wentn from Haskell to Java, C++, and Python then *back* to Haskell
20:37:05 <Nafai> bos: Why the diversion?
20:37:09 <shapr> Haskell is quite world changing, my Python never looked the same after that.
20:37:23 <shapr> On the downside, Pythonistas couldn't read my Python either :-(
20:37:24 <bos> Nafai: restlessness
20:37:34 <thedatabase> :t liftM
20:37:38 <lambdabot> forall a1 r (m :: * -> *). (Monad m) => (a1 -> r) -> m a1 -> m r
20:37:43 <bos> Nafai: i decided not to do a PhD on Haskell topics, and went and did commercial stuff for a long time
20:37:51 <magnus_> I can never decide on a favorite language... there is stuff to hate about every language :)
20:37:56 <Nafai> bos: Makes sense
20:38:01 <Tac-Tics> heh
20:38:01 <shapr> magnus_: And stuff to love about every language!
20:38:08 <Tac-Tics> magnus_: that's great
20:38:22 <Nafai> That's why I'm stuck on Java at the moment :(
20:38:32 <thedatabase> oops, evening all -- accidentally queried the lambdabot instead of GOA (normally i'm too shy...)
20:38:43 <shapr> hiya thedatabase
20:38:48 <shapr> Don't be shy, we're all nice here!
20:38:49 <thedatabase> .... but now that I'm here, I've a quickcheck question :)
20:39:11 <thedatabase> I'm trying to generate some random floats using one of ekidds distributions
20:39:14 <Zzompp> shame I wasted all those years coding PHP.. didn't make me any better as a programmer :P
20:39:24 <shapr> Zzompp: Probably paid the bills though.
20:39:24 <Tac-Tics> PHP is so ugly
20:39:24 <coffeemug> magnus_: can you decide between a hammer and a screw driver?
20:39:32 <thedatabase> -- how to coearce the Rand [Double] to a Gen [Double]?
20:39:38 <Tac-Tics> I'm doing PHP right now, and at no point do I not wish it was anything else
20:39:41 <Tac-Tics> even Java is better than PHP
20:39:53 <monochrom> haha, interesting
20:39:53 <Zzompp> yeah, paid bills and obviously I learned a lot of other stuff coding that
20:40:11 <Tac-Tics> PHP has the loosest type checking in all of language history
20:40:46 <Tac-Tics> critical errors like trying to find the length of a null or unset variable goes by just fine, and it just shows up as an empty string in your database
20:41:00 <reltuk> Tac-Tics: looser than perl?
20:41:05 <shapr> Looser than forth?
20:41:10 <Tac-Tics> I've never done the perl thing
20:41:19 <Tac-Tics> I don't image perl is much better though
20:41:25 <mauke> reltuk: yes, php has insane coercion semantics
20:41:30 <Tac-Tics> and I've not really hard anything aboutforth
20:42:07 <Tac-Tics> and PHP has this identity crisis where it doesn't know if it has arrays or hashes
20:42:21 <mauke> http://www.php.net/manual/en/language.operators.comparison.php
20:42:22 <lambdabot> Title: PHP: Comparison Operators - Manual
20:42:40 <shapr> Forth doesn't have any typechecking.
20:42:50 <mauke> PHP has something it calls "arrays"; however they're really hashes with a doubly-linked list through the values
20:43:46 <Tac-Tics> oh yeah, and at work I use PHP 4, and EVERY assignment is a copy operation by default
20:44:08 <Tac-Tics> $arr1 = $arr2 makes a deep copy of the entire contents of $arr2
20:44:29 <mauke> haha
20:44:34 <mauke> sounds like C/C++
20:44:52 <monochrom> At least C offers you * and C++ offers you &
20:45:00 <mauke> no, I mean "C/C++"
20:45:08 <mauke> it's a semi-real language
20:45:34 <monochrom> I'll go sit in a corner.
20:50:12 <Tac-Tics> I wish Haskell was easier to use as a web development language
20:50:21 <Tac-Tics> I think a haskell web site would be fun to try out
20:50:40 <shapr> HAppS!
20:50:42 <reltuk> Network.CGI?
20:51:01 <shapr> HAppS is very cool, and will have CGI support soon
20:51:18 <dons> Tac-Tics: well, hmm, hpaste.org runs on happs, and braintreehemp.com.au runs on WASH.
20:51:21 <Tac-Tics> I looked at HAppS once and it confused me and I ran away
20:51:24 <dons> so its a matter of the web libs
20:51:28 <shapr> Tac-Tics: It's getting better!
20:51:33 <dons> rather than haskell itself.
20:51:37 <Tac-Tics> and Network.CGI, is that a custom module?
20:51:39 <sorear> I wish Haskell would find its niche and stop trying to become uselessly general.
20:51:42 <shapr> The new repos should be out in a few days, maybe even tomorrow.
20:51:49 <Tac-Tics> sorear: heh, yeah
20:52:06 <Tac-Tics> Master of all trades, master of none
20:52:08 <Tac-Tics> err
20:52:10 <shapr> sorear: I think that is Haskell's niche, being more general than anything else.
20:52:14 <Tac-Tics> Jack of all trades* I guess
20:52:45 <dons> sorear: isn't high assurance software the niche? or banking? or compiler construction? or teaching? or transformation and parsing?
20:52:48 <Tac-Tics> Haskell's niche, from what I've seen, is to give the shortest programs to the kinds of algorithms they teach in school
20:52:49 <shapr> I think a big part of that comes from not having control flow decided ahead of time.
20:52:54 <dons> or concurrent code? or math?
20:53:00 <shapr> or webapps?
20:53:37 <shapr> Cool, I have an account on community.haskell.org ! What can I do with it?
20:53:59 <Tac-Tics> @let fact = prod . (enumFromTo 1)
20:54:00 <lambdabot> <local>:10:7: Not in scope: `prod'
20:54:10 <Tac-Tics> @let fact = product . (enumFromTo 1)
20:54:16 <lambdabot> Defined.
20:54:17 <Tac-Tics> fact 5
20:54:19 <Tac-Tics> > fact 5
20:54:20 <lambdabot>  120
20:54:22 <Tac-Tics> I suck as lambdabot
20:54:30 <Tac-Tics> as* .... and typing
20:54:35 <TSC> at?
20:54:38 <Tac-Tics> thank you
20:54:42 <Tac-Tics> It's been a long day
20:54:50 <shapr> Huh, I thought I was in the sudoers file, whoops.
20:56:11 <glguy> shapr: do we even have passwords on community. ?
20:56:20 <glguy> I think I can only get in with my ssh key
20:56:39 <shapr> I think I have a password...
20:57:27 <shapr> Yes, in fact I do! and it works!
20:59:12 <reltuk> shapr: does HTTP a relatively similar ServerPart for HTTP?
20:59:24 <reltuk> shapr s/s HTTP/s HAppS 0.9/
21:00:19 <shapr> reltuk: Er, yeah..
21:00:40 <lambdabot> Tac-Tics: If it's any consolation, I suck as you too.
21:00:52 <Tac-Tics> lols
21:01:01 <monochrom> hahaha
21:01:09 <Tac-Tics> I got served by LambdaBot
21:01:41 <shapr> reltuk: Does this help any? http://hpaste.org/2378
21:03:08 <dibblego> @pl \n -> map (\x -> x * x) [1..n]
21:03:09 <lambdabot> map (join (*)) . enumFromTo 1
21:03:09 <shapr> hiya sprang, learning Haskell?
21:03:35 <dibblego> @pl \x -> x * x
21:03:36 <lambdabot> join (*)
21:03:46 <dibblego> :t join
21:03:48 <lambdabot> forall (m :: * -> *) a. (Monad m) => m (m a) -> m a
21:03:53 <sprang> uh oh, I've been detected :)
21:04:31 <shapr> sprang: Welcome and spiffiness!
21:04:43 <sprang> I've been learning for a while now
21:05:21 <shapr> How's it going? Got any questions?
21:06:27 <ddarius> @index scanl'
21:06:27 <lambdabot> bzzt
21:06:28 <sprang> it's going well - haven't written anything significant yet
21:06:45 <shapr> Anything insignificant?
21:06:51 <sprang> just seeing if any interesting traffic goes by
21:06:55 <Pseudonym> I have LOTS of insignificant code.
21:07:03 <shapr> I have lots of interesting traffic!
21:07:26 <sprang> lots of 50 line experiments :)
21:07:48 <shapr> Cool!
21:08:29 <ddarius> My plucked string synthesizer is 131 (wc -l) lines.
21:10:21 <shapr> Pseudonym: What's up with the STM b-trees?
21:11:04 <shapr> How would Data.{Map,Set}.Concurrent be structured?
21:11:16 <dibblego> I reinvented STM b-trees myself a while ago; I wish I could work on something like that
21:12:21 <shapr> That whole thread sounds interesting.
21:12:28 <shapr> STM friendly data structures! w00!
21:12:48 <ihope> I thought I knew Haskell. Then I tried to implement a delimited continuation monad transformer.
21:12:51 <ihope> :-)
21:13:04 <ihope> I'm still working on that darn >>= function.
21:13:40 <ihope> DLiftT val >>= rem = DShiftT (\rem' -> oh, something)
21:14:04 * shapr is scared of delimited continuation monad transformers.
21:14:28 <ihope> shapr: have you ever actually seen one?
21:14:44 <ihope> I know what they do; I just can't yet actually write them.
21:14:49 <ddarius> You don't actually need a delimited continuation monad transformer...
21:14:55 <ihope> I don't?
21:15:31 <ddarius> You should be able to get the same effect with just a delimited continuation monad.
21:15:32 <dolio> shift and reset for ContT are pretty easy to define.
21:15:45 <ihope> Oh? How?
21:15:56 <ihope> (To both of you, I guess :-P)
21:16:07 <ddarius> @google Representing Layered Monads
21:16:13 <ddarius> @google Representing Monads
21:16:14 <dolio> @wiki MonadCont done right
21:16:16 <lambdabot> http://portal.acm.org/citation.cfm?id=292540.292557
21:16:16 <lambdabot> Title: Representing layered monads
21:16:19 <lambdabot> http://lambda-the-ultimate.org/classic/message6300.html
21:16:19 <lambdabot> Title: LtU Classic Archives
21:16:19 <lambdabot> http://www.haskell.org/haskellwiki/MonadCont_done_right
21:16:37 <dolio> See the bottom of that wiki page.
21:17:00 <shapr> Who's the maintainer of BitSyntax?
21:17:12 <Pseudonym> shapr: Erm...
21:17:15 <reltuk> is BitSyntax like erlang bit patterns?
21:17:20 <shapr> Sort of ...
21:17:22 <joed> Question.... Would the IMAP libs be something wildly stupid to look at for a first type project?
21:17:24 <shapr> The cabal file needs fixing.
21:17:35 <Pseudonym> Yeah, well, that's a side project of Tom Conway, with my input.
21:17:45 <Pseudonym> STM-friendly persistent data structures.
21:17:50 <shapr> Pseudonym: That's cool!
21:17:57 <shapr> Does Adam Langely hang out here?
21:17:59 <Pseudonym> Efficient, persistent, scalable: pick any three.
21:18:14 <shapr> heh
21:18:27 <shapr> HAppS could *really* benefit from those.
21:18:32 <Pseudonym> We haven't got transaction safety, though.
21:18:43 <Pseudonym> So we've got a B-tree and an extensible hash table.
21:19:27 <littledan> a persistent hash table?
21:19:42 <Pseudonym> Yeah.
21:19:45 <littledan> how?
21:19:59 <Pseudonym> Same as your favourite database server.
21:20:34 <ihope> Shift and reset for the Cont monad? That's something likable.
21:21:02 <Pseudonym> Your favourite database server uses, for its indexing, some kind of B-tree and/or some kind of on-disk hash table.
21:21:07 <Pseudonym> Most likely.
21:21:18 <Pseudonym> Or it uses ISAM, of course.
21:21:22 <ihope> Those aren't the types I'm familiar with, but I think I came up with the types I'm familiar with myself.
21:21:55 <Pseudonym> But even in ISAM, the indexes are hash tables or B-trees.
21:22:42 <dolio> ihope: The problem is, you can't make them polymorphic in the monad type.
21:23:05 <ihope> Which monad type?
21:23:08 <dolio> ihope: So you can't layer things over them.
21:23:17 <littledan> Pseudonym: is the code for this persistent hashtable available anywhere? (I'd rather read a Haskell implementation than a C one)
21:23:30 <dolio> Well, for one, notice you need separate functions for Cont and ContT.
21:23:54 <ihope> Can't you make ContT into Cont with an identity monad?
21:24:07 <dibblego> Pseudonym, have you written some kind of abstraction to btrees, so that clients can select the complexity of certain operations over that btree?
21:24:34 <littledan> Pseudonym: or does it just use a persistent tree in place of a flat array?
21:24:41 <dolio> ihope: Well, you also won't be using shift in 'StateT s (Cont r) a'
21:25:03 <Pseudonym> littledan: No, it's not, sadly.
21:25:05 <dolio> Unless maybe you do some lifting, and even then...
21:25:07 <Pseudonym> Even I haven't seen all the code.
21:25:15 <ihope> Yeah, I think I see.
21:25:15 <Pseudonym> Since it was written for a company that I don't work for.
21:25:40 <Pseudonym> dibblego: Not really.  B-trees don't have that many operations.
21:25:48 <ihope> That'd be quite a lot of lifting.
21:26:04 <Pseudonym> But it's a full-on B-tree.
21:26:09 <dibblego> Pseudonym, they don't; but there are different types of b-trees, with different complexity on their operations
21:26:15 <shapr> I wish more companies would open source stuff...
21:26:28 <dibblego> Pseudonym, I was thinking something like insert :: a -> c a -> c a
21:26:40 <Pseudonym> dibblego: Sure, but generally speaking, they all have the same disk-seek-complexity behaviour.
21:26:43 <dibblego> where c is one variation of B-tree
21:26:56 <Pseudonym> Which is the operation that you generally want to minimise.
21:27:08 <ihope> shapr: they'll be more eager to do it when everything is already open source.
21:27:09 <Pseudonym> Really, for STM, there's only one variant of B-trees that makes sense.
21:27:15 <Pseudonym> And that's relaxed balance B-trees.
21:27:20 <dibblego> well, what type is each node made of? is it a list?
21:27:33 <Pseudonym> dibblego: It's a disk page.
21:27:45 <dibblego> ah ok
21:28:07 <Pseudonym> Not a physical disk page, of course.
21:28:22 <dibblego> but effectively, another b-tree?
21:28:23 <Pseudonym> But yeah, it's a page-structured file.
21:28:29 <Pseudonym> Beloved of database implementors everywhere.
21:29:19 <ddarius> That always annoyed me.
21:29:28 <Pseudonym> It makes a lot of sense.
21:29:39 <Pseudonym> Hell, filesystems are page-structured files.
21:29:56 <ddarius> To use page structured files instead of pages of disk?
21:30:07 <Pseudonym> Ah, well.
21:30:17 <Pseudonym> Good database engines, and some bad ones, can use either files or disk.
21:30:27 <Pseudonym> All it needs is something with pages./
21:30:40 <Pseudonym> You can give Oracle a partition, for example.
21:30:43 <Pseudonym> And it will manage it.
21:31:35 <dibblego> Pseudonym, are you writing this in a commercial environment?
21:31:48 <Pseudonym> Tom is.
21:31:55 <dibblego> Tom?
21:31:58 <Pseudonym> Conway
21:32:07 <dibblego> oh right; how are you related to the project?
21:32:07 <ddarius> Pseudonym: Why does everyone think you're writing it?
21:32:25 <Pseudonym> Because I'm the only one connected to the project who's on IRC.
21:32:43 * Pseudonym is more of a consultant/code reviewer
21:32:44 <dibblego> because Pseudonym is talking about it
21:32:49 <Pseudonym> And paper co-author, when it's finished.
21:33:51 <dibblego> sounds fun
21:34:30 <Pseudonym> Oh, it is.
21:35:10 <ddarius> Time to sleep.
21:35:28 * shapr has a hissy fit at this weird error
21:50:22 <thoughtpolice> hm i'm still shakey on all of the unsafe functions. i realize that their use may be somewhat unadvised, but I'm having trouble finding just about any concrete info on their usage/etc. I was looking through some of the yi kernel sources to see how things went but for example, unsafeCoerce# eludes me.
21:51:15 <dons> unsafeCoerce# coerces, forcably, one type to another. the type check just believes you.
21:51:29 <dons> it should only be used when you have a separate proof that the representations match up
21:53:18 <thoughtpolice> dons: so when you specify the type signature for unsafeCoerce# you just say "I know what I'm doing; I'm human, after all"
21:53:27 <thoughtpolice> basically a typecast (which is saying the same thing I always thought)
21:54:28 <dons> yeah, but you also need to know that somehow that the coerce is safe. which is fairly non-trivial
21:54:49 <dons> its a type cast, yep. and the most unsafe operation provided
21:55:34 <sieni> what kind of unsafe coercions can you do safely?
21:56:23 <dons> if you have some unknown type you can sometimes cast it to a specific type, if you know the type by some other means
21:56:27 <dons> dynamics do this, for example
21:56:30 <dons> ?src fromDyn
21:56:30 <lambdabot> fromDyn (Dynamic t v) def
21:56:30 <lambdabot>   | typeOf def == t = unsafeCoerce v
21:56:30 <lambdabot>   | otherwise       = def
21:57:31 <dons> FFI stuff can often be cast (though castPtr is provided for the common cases)
21:59:02 <sjanssen> you rarely rarely see unsafeCoerce#, especially when compared to unsafePerformIO
21:59:24 <thoughtpolice> dons: how can you be sure the coerce is safe? for example in the yi 0.2 sources, Boot.startYi I noticed the use of unsafeCoerce# before running Yi.main,
22:00:31 <dons> thoughtpolice: yeah, that's an unknown dynamiccall.
22:00:41 <sjanssen> thoughtpolice: you have to know how the two types are represented in memory to be really sure
22:00:47 <thoughtpolice> unsafeCoerce is used after a compileExpr run on the type signature of Yi.main (compileExpr "Yi.main :: Yi.Kernel -> Prelude.IO ()",) the expression just being (x' :: Kernel -> IO ()) = unsafeCoerce#
22:00:48 <dons> we know that its safe because the caller and callee use the same type -- its just not checked since they're compiled separately
22:00:48 <reltuk> if I wanted to write a streaming proxy, would be easy to tie a lazy io read to a lazy io write and have the runtime handle buffering and the likes?
22:01:03 <dons> reltuk: yeah. lazy bytestrings are used for that kind of thing
22:01:06 <thoughtpolice> sjanssen: ah, hence 'non trivial'
22:01:18 <dons> let laziness do the buffering, and bytestrings do the data stream efficiently
22:02:14 <thoughtpolice> sjanssen: so you really have to know so you can make sure when you go from type A to B that you can render B over the same piece of memory properly without the world exploding, basically?
22:03:19 <sjanssen> thoughtpolice: yeah.  Try running "(unsafeCoerce# :: Integer -> Int) 0"
22:03:34 <dons> heh
22:05:07 <thoughtpolice> hm, well unsafe* stuff does indeed seem a bit nasty. :)
22:05:14 <thoughtpolice> (pun intended?)
22:05:27 <dons> that's the most unsafe
22:05:33 <sjanssen> btw, you can write unsafeCoerce with unsafePerformIO
22:11:01 <thoughtpolice> "Segmentation Fault"
22:11:04 <thoughtpolice> ouch.
22:12:17 <littledan> funny, the same thing with Int -> Integer works just fine
22:13:41 <thoughtpolice> Integer is just like Int only it's done-by-memory (and thus can have numbers of infinately long digits,) right?
22:13:52 <dolio> Well, I# Int# -> S# Int# maps pretty well.
22:15:29 <dons> thoughtpolice: yeah, under 32 bits, its just an Int, otherwise its a gmp byte array
22:15:51 <dolio> J# Int# -> ??? is more of a problem.
22:16:23 <dolio> Er, J# Int# ByteArray#
22:16:28 <thoughtpolice> dons: ah, hence why going Integer -> Int via coercing wouldn't work
22:17:15 <dolio> It works for small enough Integers.
22:17:35 <thoughtpolice> except 0, apparently.
22:17:41 <sjanssen> 0 isn't small enough?
22:18:05 <dolio> Works for 0 here.
22:18:25 <thoughtpolice> http://hpaste.org/2379
22:19:26 <sjanssen> grr, why does Data.ByteString.Lazy.zipWith have the type it does?
22:20:21 <sjanssen> zipWith :: (Word8 -> Word8 -> a) -> ByteString -> ByteString -> [a] -- quite annoying
22:20:51 <dons> sjanssen: there's a specialised version
22:21:00 <dons> if you want to zip into 2 bytestrings
22:21:13 <dons> ah, maybe not for the lazy version
22:21:28 <dons> the tension is between a monomorphic, fast, but not so useful version, and a more generic zip
22:22:35 <sjanssen> it's a bit of an annoying inconsistency -- look at map's type
22:24:06 * sjanssen was trying to write the world's fastest/shortest one time pad program
22:24:26 <blackdog> hey, anyone got any recommendations for haskell-friendly web hosting?
22:24:49 <blackdog> getting ghc going on an unfriendly host is not so much fun.
22:24:50 <thoughtpolice> sjanssen: there's probably a game of perl golf going on right now for that :p
22:25:17 <dons> blackdog: hmm, compile on your machine, and upload statically linked binaries?
22:25:43 * blackdog pulls face
22:25:47 <blackdog> yeah, it's a possibility
22:26:18 <blackdog> i'm vaguely hoping to do some introspection tricks - generate code from the database with TH, that sort of thing
22:26:27 <blackdog> which i think makes the static binary approach unattractive
22:26:36 <stepcut> blackdog: Amazon EC2/S3 ?
22:26:48 <stepcut> :p
22:26:48 <blackdog> basically i want rails' ActiveRecord stuff with some static guarantees :)
22:26:55 <sprang> blackdog: I've heard good things about these guys: https://www.nearlyfreespeech.net/
22:26:55 <blackdog> stepcut: ... you can do that?
22:27:28 <stepcut> blackdog: the HAppS people are supposed to have a new release that supports EC2/S3 any day now
22:28:04 <stepcut> blackdog: what do you want from a Haskell friendly website? I do as dons suggests, and just upload statically linked binaries
22:28:27 <stepcut> blackdog: a VPS that supports debian sid might be a good choice
22:29:06 <stepcut> blackdog: since Debian sid tends to have a reasonably up-to-date version of GHC, and a number of 3rd party libraries
22:29:08 <blackdog> stepcut: yeah, a VPS was my next thought. just wondering if i can avoid it for the moment - i have enough boxes to maintain without worrying about virtual ones.
22:30:01 <sjanssen> thoughtpolice: I doubt perl can do much better than "zipWith xor pad text"
22:30:02 <stepcut> blackdog: My friend has a (shared system?) dreamhost account, and I think he convinced them to install ghc6 on it
22:30:29 <thoughtpolice> nearlyfreespeech.net supports haskell as a CGI but I don't know if it allows happs-style stuff (since happs contains its own web server)
22:30:36 <stepcut> blackdog: opinions on dreamhost vary wildly
22:30:37 <blackdog> but nearlyfreespeech looks interesting, although i vaguely remember they don't like long-lived processes
22:30:46 <blackdog> thoughtpolice: yeah, that's what i was worried about.
22:30:53 <thoughtpolice> probably be easier to buy like a xen VPS (heard good things about slicehost) and deal with that.
22:31:09 <mauke> sjanssen: $pad^$text
22:31:35 <sjanssen> mauke: will that work with some stream-like thing?
22:32:00 <mauke> no
22:32:11 <mauke> unless you use objects and overload ^
22:32:37 <blackdog> stepcut: cheers. i'm on textdrive atm, and they're pretty decent for rails, but installing new stuff is needlessly difficult.
22:32:38 <stepcut> I think for HAppS based sites, Amazon EC2/S3 is going to be hard to beat
22:35:37 <mudge> I was watching the videos simon peyton jones did
22:35:45 <mudge> he says some interesting stuff
22:35:55 * stepcut should really finish those videos sometime
22:36:03 <mudge> like, "We are showing xmonads on Linux because the X windows system runs better on linux than windows."
22:36:28 <mudge> and hey,  he said xmonads was written by Don Stewart,   I know him, that's dons,   he hangs out here
22:36:56 <mudge> simon works for microsoft
22:36:57 <stepcut> mudge: s/xmonads/xmonad/, s/X windows system/X window system/
22:36:58 <stepcut> ;)
22:37:02 <thoughtpolice> the videos are quite good. :) i like spj's speaking (and his writing is very good too, I'm reading implementation of functional programming languages right now)
22:37:32 <mudge> thoughpolice:  oh yea, i've seen that book online,  is it pretty good?
22:38:21 <mudge> thanks stepcut
22:38:24 <stepcut> mudge: I have read (most) of it, it is very good
22:38:30 <thoughtpolice> mudge: the book online isn't the 'whole' thing
22:38:40 <mudge> do you have the print version?
22:38:46 <mudge> is the print version available?
22:39:02 <thoughtpolice> dunno if you can still get it from amazon
22:39:58 <thoughtpolice> the online version is only from intermediate representation<->backend stuff; the print version covers haskell->core->end, so basically the whole 9 yards.
22:40:48 <zmike> You know what videos are really good
22:40:56 <thoughtpolice> mudge: I'm not far into it but so far I really like it a lot
22:40:56 <zmike> The german university lectures
22:41:01 <zmike> Those are amazing
22:41:26 <mudge> thoughtpolice,   wow,  I want it,  how easy is it to read?
22:42:37 <thoughtpolice> mudge: i'm only on the chapter covering the lambda calculus (2nd chapter,) but so far yeah, it's pretty easy to read. note i've read a little about compilers (the dragon book and whatnot) but I've never really had experiance with the lambda calculus, although it seems to ease in really really nicely.
22:43:28 <stepcut> thoughtpolice: are you sure the online version is missing stuff? It says on the page, 'My 1987 book is now out of print, but it is now available online in its entirety.'
22:43:28 <mudge> cool,  i found it on Amazon,  i can buy it for $85
22:43:40 <mudge> it's pretty old, 1987
22:44:01 <stepcut> thoughtpolice: the online version is 469 pages
22:44:17 <thoughtpolice> mudge: i had a copy of the online one before I got the print, I might just be hallucinating or something
22:44:21 <stepcut> s/469/439/
22:45:07 <thoughtpolice> stepcut: ah this http://research.microsoft.com/~simonpj/papers/slpj-book-1987/start.htm
22:45:09 <lambdabot> Title: The Implementation of Functional Programming Languages, http://tinyurl.com/2nyr8p
22:45:12 <thoughtpolice> yeah that's the book.
22:45:14 <thoughtpolice> i had a pdf
22:45:26 <thoughtpolice> although I remember it being different
22:45:41 <thoughtpolice> hm. either way it's a really good book. :)
22:46:16 <mudge> amazon says its hardcover is 500 pages
22:46:39 <mudge> but maybe it was just rounded up
22:46:49 <stepcut> mudge: yeah, it is dated, but things like it's lambda calculus introduction are very well done, and just as relevent today
22:47:19 <stepcut> mudge: well, there might be close to 500 pages total if you include all the pages like the table of contents, etc
22:47:51 <thoughtpolice> not exactly cutting edge these days but so far it's a really good introduction to it, it seems.
22:48:23 <mudge> oh okay
22:49:08 <stepcut> thoughtpolice: right, I think the best way to go is to read that first, and then move on to something like "Implementing lazy functional languages on stock hardware: the Spineless Tagless G-machine"
22:49:41 <thoughtpolice> yeah. it'd be a good idea to read some of the research done between then and now before you go off writing a haskell compiler after reading it. :)
22:50:00 <thoughtpolice> or something similarly daring.
22:50:04 <mudge> I guess I'll hold off my haskell compiler then
22:50:14 <mudge> for a little
22:50:34 <mudge> just kidding,  I barely know haskell
22:51:44 <thoughtpolice> no reason not to have big ideas, though. :)
22:52:12 <stepcut> mudge: read the section titled, 'the story of jhc', http://repetae.net/john/computer/jhc/jhc.html
22:52:13 <lambdabot> Title: Jhc
22:53:10 <mudge> thoughtpolice: I'm proficient in that
22:53:40 <thoughtpolice> the idea of a haskell compiler for embedded devices has been floating around my head, probably ever since I got my PSP.
22:54:08 <thoughtpolice> because from the moment I got it I had already decided homebrew was good. :)
22:54:24 <stepcut> thoughtpolice: one that targets embedded devices? Or a compiler that runs on an embedded device ?
22:55:27 <thoughtpolice> stepcut: targeted for embedded devices.
22:56:08 <mudge> stepcut: cool story on jhc,  who wrote jhc?
22:56:12 <Bourbaki> due to the lazyness of haskell is there any kind of optimization if you build up functions out of basic operations like + and *? that is for example if you have a function like f(x,y) = g(x) + h(y) in order to be able to write a derivation system, where the functions expand until an actual number is reached or a simple expression within that system.
22:56:26 <thoughtpolice> stepcut: implements haskell98 fully, but you can target for lots of different architectures that're common in embedded devices (mips, arm, etc.)
22:56:50 <stepcut> mudge: john meachem
22:57:04 <thoughtpolice> rather than compile directly to native code though the main thought for something initially was just go to ANSI C and let gcc take care of all the tough work. :)
22:57:08 <mudge> ah, what's his nic name on IRC?
22:57:15 <thoughtpolice> JohnMeachem :p
22:57:25 <mudge> ah, thanks!
22:58:02 <thoughtpolice> i'm hardly a compiler expert, though. so it might have to wait until college, maybe something to write a paper over one day.
22:58:10 <stepcut> thoughtpolice: I heard rumors that the GHC will (soon ?) have a real ANSI C backend (plain ANSI-C, no funny evil mangler stuff)
22:59:08 <stepcut> thoughtpolice: A YHC core->ANSI-C backend should be feasibly as well
22:59:34 <thoughtpolice> hah, you want to see something evil, run ghc over a file using -keep-hc-file and look at the horror. i was somewhat startled but intrigued at the same time.
22:59:57 <stepcut> thoughtpolice: :p
23:00:19 <thoughtpolice> needless to say compilers generally make some damn ugly code when going from a -> C. :p
23:01:01 <thoughtpolice> in terms of looks, at least. some of the javascript code generated by that scheme->js compiler that I saw on reddit a couple of days ago just made me say "damn"
23:01:13 <stepcut> thoughtpolice: yeah, I think yhc is supposed to generate somewhat readable C
23:01:18 <thoughtpolice> and that was all that needed be said.
23:01:38 <Mr_Awesome> well, as long as it runs :P
23:01:53 <thoughtpolice> hah. yeah, can't complain a whole bunch.
23:02:00 <Pseudonym> It's not enough that t runs.
23:02:27 <Pseudonym> Compilers that compile to C also have a habit of generating code that reveals bad behaviour in C compilers.
23:02:33 <Pseudonym> Though GCC is probably pretty good at that by now.
23:03:03 <Pseudonym> Even parser generators have been known to trigger highly superlinear behaviour in older C compilers.
23:03:09 * stepcut wonders if C-- will ever take of
23:03:09 <thoughtpolice> conclusion: compilers are just evil.
23:03:10 <stepcut> f
23:03:30 <coffeemug> I don't really understand the purpose of C--
23:03:31 <Mr_Awesome> intriguing though. ive always wanted to get into compiler writing for fun
23:03:46 <coffeemug> if I want to go that way I'd much rather pick C
23:03:53 <coffeemug> if I don't, I'll write a backend for JVM/CLR
23:04:10 <coffeemug> or perhaps LLVM
23:04:16 <coffeemug> but C--, eh...
23:04:17 <coffeemug> I don't know
23:04:35 <Pseudonym> C-- has some advantages.
23:04:36 <stepcut> coffeemug: Well, doing efficient tail calls in C is difficult
23:04:43 <thoughtpolice> i've thought a lot about compilers from time to time ever since I picked up the dragon book for the first time.
23:04:44 <Pseudonym> You can't even compile C++ to C easily these days.
23:04:59 <coffeemug> stepcut: you don't do it in C, you transform your code to do it and then transform that to C
23:06:06 <thoughtpolice> aside from a haskell compiler, a compiler for a subset of perl 6 -> parrot has been buzzing in my head for a while. in my head for some reason I feel a project like that would be easier to cut teeth on than something for a language like haskell perhaps
23:06:16 <thoughtpolice> but i've never written a compiler so I have no idea what I'm talking about. :)
23:06:19 <stepcut> coffeemug: you mean turn transform the code into CPS-style, and then output that to C ?
23:06:36 <Pseudonym> The easiest thing to write first is an interpreter which just interprets abstract parse trees.
23:06:37 <stepcut> thoughtpolice: pugs ?
23:07:12 <thoughtpolice> stepcut: somewhat, but pretty much just a one-shot compiler from p6->parrot and that's all. nothing really fancy or probably as impressive as pugs.
23:07:15 <Pseudonym> Or, alternatively, start with a compiler that compiles single integers to programs.
23:07:17 <Pseudonym> Then add stuff.
23:07:29 <coffeemug> stepcut: you could do it via CPS to avoid stack business
23:07:39 <coffeemug> stepcut: or just generate a for loop in C :)
23:08:10 <stepcut> coffeemug: well, if you have mutually recursive tail cails, that is not so simple
23:08:22 <stepcut> (... generating a loop)
23:09:47 <stepcut> coffeemug: on the other hand, a intermediate C-like language that supported tail cails, and returning multiple arguments would keep the high-level compiler a lot simpiler, yes ?
23:10:27 <coffeemug> that is true
23:10:35 <coffeemug> but I'd still rather go with C
23:10:35 <stepcut> coffeemug: then you could focus on the interesting parts of your language/compiler, instead of reimplementing old hacks for working around C limitations?
23:10:52 <coffeemug> it also depends on your purpose
23:11:01 <coffeemug> if you're doing it for fun/learning, C is fine
23:11:04 <johnnowak> there's really something to be said for generating portable C
23:11:16 <coffeemug> http://llvm.org/demo/index.cgi
23:11:18 <lambdabot> Title: Try out LLVM in your browser!
23:11:19 <coffeemug> take a look at this
23:11:22 <coffeemug> this is pretty cool
23:11:33 <stepcut> coffeemug: yeah, I am aware of it
23:14:58 <Pseudonym> http://andrew.bromage.org/darcs/simpleCompiler/
23:14:59 <lambdabot> Title: Index of /darcs/simpleCompiler
23:15:13 <Pseudonym> That's a single-number compiler, for reference.
23:17:17 <stepcut> coffeemug: there has been some discussion as to whether or not LLVM would be an efficient backend for GHC, there are some concerns that it might be a bad match, but I don't think anyone has really investigated it
23:17:50 <coffeemug> this whole issue is tricky
23:17:57 <coffeemug> they wrote a lot of optimization passes
23:18:00 <coffeemug> and keep adding them
23:18:07 <stepcut> coffeemug: obviously, if you have to make a lot of hacks to get GHC to work efficiently on LLVM, then you have not really gained much ;)
23:18:27 <coffeemug> so if you code to their platform your compiler will theoretically get faster and faster without you doing any work
23:18:34 <coffeemug> due to them adding more optimization passes
23:18:37 <stepcut> coffeemug: that said, LLVM is pretty nifty, and definitely right for some projects ;)
23:18:40 <Pseudonym> OTOH, it might be better to submit bug reports to the LLVM guys.
23:18:57 <coffeemug> why did people think it might be a bad match for GHC?
23:19:09 <stepcut> http://lists.cs.uiuc.edu/pipermail/llvmdev/2006-December/007664.html
23:19:12 <lambdabot> Title: [LLVMdev] LLVM capability question., http://tinyurl.com/2v2r5j
23:20:03 <stepcut> http://www.haskell.org/pipermail/glasgow-haskell-users/2007-January/011838.html
23:20:05 <lambdabot> Title: LLVM back end, http://tinyurl.com/3yo6yj
23:24:23 <stepcut> coffeemug: since C-- is one of SPJ's babies, I don't think they are especially keen on using LLVM, even if it is a good idea ;)
23:24:48 <Pseudonym> SPJ has a history of abandoning babies.
23:25:00 <Pseudonym> If necessary.
23:25:18 <Pseudonym> All good researchers do.
23:25:41 <stepcut> good to hear
23:27:31 <flux> couldn't they have an LLVM-backend to a c-- -compiler?
23:30:58 <Pseudonym> Or compile LLVM to LLVM, and then just take the least fixpoint.
23:31:27 <Pseudonym> compile :: Turtle -> Turtle
23:32:00 <slava> is there a darcs binary for solaris x86?
23:36:52 <dons> slava: yeah, i think so.
23:36:57 <dons> check darcs.net or the darcs list
23:37:09 <stepcut> anyone know what the difference is between the compiler and compiler98 directories in yhc ? It looks like compiler98 might be obsolete ?
23:44:29 <dons> stepcut: one is from nhc, one from yhc, iirc
23:45:35 <stepcut> dons: ah, makes sense
23:46:10 <stepcut> compiler is the only one listed in src/SConstruct, so I am going to assume that is the yhc one
23:46:33 <stepcut> I think I need to extend the FFI to support some additional calling conventions besides ccall
23:46:34 <dons> that sounds right
23:46:42 <dons> oh, interesting.
23:47:42 <stepcut> my flash compiler is far enough, that I need to figure out how to import flash functions for real
23:48:30 <stepcut> and there are three different types of things I need to import: primitive opcodes (such as ActionSubtract), function calls, and method calls. They each require the stack to be set up slightly differently
