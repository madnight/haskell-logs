00:00:07 <lokimaf> olsner: hey thanks for the shorter version
00:00:43 <olsner> here's a pointless one-liner: drop 2 (uncurry ((. return) . (:)) =<< iterate (uncurry (ap (ap . ((,) .) . ap (+) . ((16 *) .) . (.&.)) (ap ((.) . (+) . (16 *)) (.|.)))))
00:01:18 <newsham> ?. unpl olsner
00:01:18 <lambdabot> Plugin `compose' failed with: IRCRaised Parse error: "olsner"
00:01:41 <olsner> newsham: no, I am not a part of lambdabot
00:01:57 <newsham> but i would like lb to unpl you
00:04:43 <olsner> however, I don't unpl easily, as you will notice
00:08:24 <wli> Okay, I can interpolate a cubic from (a, b), (f a, f b), (f' a, f' b)
00:25:30 <dmwit> :t drop 2 (uncurry ((. return) . (:)) =<< iterate (uncurry (ap (ap . ((,) .) . ap (+) . ((16 *) .) . (.&.)) (ap ((.) . (+) . (16 *)) (.|.)))))
00:25:32 <lambdabot>     Couldn't match expected type `[(a, a)]'
00:25:32 <lambdabot>            against inferred type `(a1, a1) -> [(a1, a1)]'
00:26:09 <dmwit> olsner: Not just pointless, but also wrong?
00:29:51 <oerjan> @seen olsner
00:29:51 <lambdabot> I saw olsner leaving #haskell 10m 29s ago, and .
00:30:06 <hpaste>  loki annotated "infinite random stream generator in 18 lines of haskell code" with "with getArgs and no list item doubling" at http://hpaste.org/3343#a2
00:31:18 <lokimaf> 18 was an overestimate really
00:32:34 <lokimaf> guess it's late
00:45:09 <shapr> @yow !
00:45:10 <lambdabot> Now I'm concentrating on a specific tank battle toward the end of World War II!
00:46:36 <etnt> I've been thinking of buying Hudak's Haskell book, anyone read it (of course you have :-), is it good?
00:46:43 <newsham> > iterate (\x -> 279470273*x `mod` 4294967291) 1 :: [Integer]
00:46:45 <lambdabot>  [1,279470273,1196210100,1795977874,3523022591,1091671578,3704055081,19293150...
00:46:50 <newsham> infinite random stream in 1 line
00:47:31 <newsham> (not quite infinite)
00:47:37 <glguy> > [4,4..] -- infinite random number stream, number choosen by roll of fair dice
00:47:38 <lambdabot>  [4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4...
00:48:08 <newsham> thats a lot of random
00:49:16 <huamn_> glguy, I bet you cheated and did not roll a dice
00:49:35 <newsham> maybe he remembered a previous die roll
00:49:39 <newsham> (hopefully without bias)
00:49:59 <huamn_> yeh
00:50:27 <oerjan> clearly 4 is the most random die roll.  everybody knows that.
00:51:14 <vincenz> if it's the most random roll, then it's not random
00:51:23 <vincenz> if it were random, they'd all equally be random
00:51:34 <newsham> but if its not the most random roll, then it is again
00:52:13 <vincenz> Clearly this indicates a rift in the time-space chaos-line
00:52:25 <vincenz> Hence 4 is so much more than a random die roll
00:52:46 <newsham> i think it was fine when it was rolled once
00:52:58 <newsham> but the infinite sequence was asking for trouble
01:04:12 <hpaste>  wli pasted "cubic Newton-like method" at http://hpaste.org/3344
01:04:35 <wli> There you go.
01:06:25 <wli> A more intelligent implementation would go through the trouble of remembering computed function values and derivatives.
01:15:21 <quicksilver> ooh, nice
01:15:36 <wli> You like my little solver?
01:15:36 <quicksilver> if you hPutStrLn from two different threads you can get char-by-char interleaving...
01:15:44 <quicksilver> sorry, I do like your solver too :)
01:15:56 <wli> -C0 required most of the time
01:15:59 <quicksilver> I mean hPut from two different threads is obviously stupid
01:16:08 <quicksilver> but I'm still surprised to see that level of interleaving
01:16:31 <quicksilver> still it's a good incentive to do it the right way with channels
01:18:20 <wli> For the most part the higher-degree bits don't help.
01:18:42 <wli> It'd probably be better to do the endpoints zeroth order and the midpoint first-order.
01:20:08 <wli> That needs a different Lagrange-Hermite basis, though.
01:24:34 <wli> Since you always have to have the midpoint there to fall back to anyway...
01:25:44 <wli> Plus you get the normal Newton at the midpoint largely for free.
01:26:05 <quicksilver> "Salary: enough to live comfortably in Manhattan"
01:26:11 <quicksilver> that is pretty vague :P
01:26:28 <profmakx> for appropriate values of comfortable
01:26:44 <wli> Numerical Ito and Stratonovich integrals would probably be more interesting.
01:26:44 <quicksilver> quite
01:27:46 <wli> I'm still quite fuzzy on SDE solvers and what those integrals mean, though.
01:42:02 <quicksilver> why isn't the Data.Binary haddock browsable from hackage?
01:44:02 <quicksilver> well maybe someone here knows the answer, then :)
01:44:12 <quicksilver> does data.binary have any capability to cope with errors?
01:50:14 <quicksilver> dcoutts__: ah! morning! you know about binary...
01:57:06 <scook0_> quicksilver: (the hackage main page leads me to believe that haddock doesn't actually get run on a regular basis)
01:57:40 <scook0_> older versions of the lib do have haddock docs present
02:03:37 <etnt> regarding the binary stuff, does it have anything similar to the bitsyntax of Erlang ?
02:10:23 <quicksilver> scook0_: I interpreted that to mean it had a build error trying to run haddock, or soething, on 0.4
02:10:35 <quicksilver> etnt: in terms of functionality it does, but not in terms of syntax
02:12:14 <scook0_> quicksilver: though there's no build log on the 0.4 page (admittedly I'm guessing at this point)
02:12:32 <reffie> anyone use postmaster?
02:13:23 <etnt> quicksilver: ok, nice, are there any examples e.g how to parse a IP header or something similar ?
02:17:53 <quicksilver> etnt: not that I can find, no, although it's fairly straightforward
02:17:58 <quicksilver> (if slightly boring to write)
02:18:12 <quicksilver> for another approach, not Data.Binary, see http://hackage.haskell.org/cgi-bin/hackage-scripts/package/BitSyntax-0.3
02:18:15 <lambdabot> http://tinyurl.com/2m67ne
02:18:34 <quicksilver> that includes the IP header stuff as an example in the docs
02:19:07 <etnt> quicksilver: ok, thx!
02:47:44 <dcoutts_> quicksilver: binary eh?
02:48:12 <quicksilver> dcoutts_: yes. Meta-question: why aren't haddocs for 0.4 showing up on hackage? 0.3 does...
02:48:48 <dcoutts_> quicksilver: it's not been built yet I guess
02:49:10 <dcoutts_> there's no build lot either
02:49:37 * quicksilver nods
02:49:53 <quicksilver> dcoutts_: ok, well real question: how can binary be used robustly?
02:50:12 <quicksilver> dcoutts_: if it was to be used for a network thingy, it would need to behave 'sensibly' in the face of deliberate malicious data
02:50:26 <dcoutts_> quicksilver: right
02:50:49 <quicksilver> even something as simple as sending ridiculous huge messages to try to cause memory exhaustion
02:51:04 <dcoutts_> quicksilver: main issue there is not allocating memory just because the attacker asks you to
02:51:09 * quicksilver nods
02:51:22 <dcoutts_> quicksilver: it was a consideration in the implementation, but you'd probably want to audit to be sure
02:51:29 <quicksilver> of course you can choose to write binary instances which are 'obviously' bounded
02:51:43 <quicksilver> but certainly natural instances aren't bounded (or not very)
02:51:47 <quicksilver> like the instance for [a]
02:51:59 <dcoutts_> I'm not sure that's right
02:52:28 <dcoutts_> the point is, if the attacker wants us to allocate 4GB memory, he actually has to send us ~4Gb data
02:52:40 <quicksilver> yes, that's true
02:52:42 <dcoutts_> so we can design a [a] instance that works that way
02:52:51 <quicksilver> I see your point
02:52:52 <dcoutts_> though perhaps the current one does not
02:53:11 <quicksilver> but if the attacker has several machines
02:53:16 <quicksilver> (botnet)
02:53:22 <quicksilver> he may be quite happy to allocate Gb of data...
02:53:46 <dcoutts_> quicksilver: you have to solve that at a different layer
02:54:16 <dcoutts_> quicksilver: the only thing the protocol parsing layer has to do is not do lots of work when the attacker only does a little
02:54:26 <dcoutts_> you have to make them do as much work
02:54:53 <quicksilver> that is part of my question
02:54:58 <quicksilver> can I solve this in a different layer?
02:55:13 <quicksilver> It struck me I could have a high-level 'chunk interface'
02:55:18 <quicksilver> with limited size chunks
02:55:22 <quicksilver> and protection there
02:55:24 <dcoutts_> if you want to limit the total incoming data, that's easy
02:55:32 <quicksilver> and the chunks being concatenated and passed on to binary
02:55:39 <dcoutts_> take 1bazillion input
02:56:15 <dcoutts_> quicksilver: there's this high-level chunk interface that we call Data.ByteString.Lazy ;-)
02:56:23 <quicksilver> yeah, but that doesn't have control
02:56:41 <quicksilver> but yes, I could package my chunks into a lazy bytestring after I'd vetted them
02:57:03 <quicksilver> I think this issue is quite a long way from 'easy'
02:57:14 <quicksilver> not that I would necessarily expect Binary to magically make it easy
02:57:23 <quicksilver> but if there was a clever way to make it safe-by-default...
02:57:35 <dcoutts_> quicksilver: you don't really care about the chunk size, it's the total data sent you want to limit
02:57:46 <dcoutts_> quicksilver: the chunk size is never more than 64k anyway
02:57:51 <quicksilver> yes, not quite what I meant
02:58:00 <quicksilver> I meant put a meta-protocol on top of the lower level protocol
02:58:22 <dcoutts_> quicksilver: so how do you decide if the client is sending too much data ?
02:58:22 <quicksilver> and say "although the real protocol permits data of any length, the meta-protocol bundles it into chunks of at most nK"
02:58:35 <dcoutts_> quicksilver: I don't see how chunks are relevant
02:58:44 <quicksilver> so the meta-protocol restricts valid messages to ones at most that size
02:58:58 <dcoutts_> ah, so it's a message oriented protocol
02:59:07 <dcoutts_> with limits on message size
02:59:22 <dcoutts_> that's not the same as the chunks I was thinking of
03:00:23 <quicksilver> right, well, the picture I'm trying to paint is that "nominally" messages are of unlimited size
03:00:38 <quicksilver> but for sanity a higher-level discipline discards any messages bigger than X
03:00:42 <dcoutts_> so yes, if messages boundaries are easy to find without parsing then you could have a layer that breaks the input stream into messages
03:00:49 <quicksilver> mind you I'm not really sure if that's a good solution
03:00:58 <dcoutts_> and cuts the connection if any message is too big
03:01:13 <dcoutts_> but the attacker could send lots of small messages
03:01:20 <dcoutts_> in a short period of time
03:01:32 <quicksilver> yes, I'm not sure what I"m saying is making sense
03:01:41 <quicksilver> the other concern I have is this lazy parsing thing
03:01:52 <quicksilver> whilst lazy parsing is very neat I'm not sure it's secure
03:02:07 <quicksilver> it feels like it will be a mess if I pick up a parse exception in the middle of some pure code
03:02:22 <dcoutts_> you don't pick it up in the pure code
03:02:32 <dcoutts_> you catch it outside in some IO handler
03:02:39 <quicksilver> yes, I understand that
03:02:46 <quicksilver> let msg = decode raw
03:02:51 <quicksilver> otherIOaction msg
03:03:00 <dcoutts_> and since you wrap your entire conversation with the client in a handler, that should be fine
03:03:02 <quicksilver> 'otherIOaction' thinks it has a properly formatted message there
03:03:10 <quicksilver> so it starts to draw to the screen, or whatever
03:03:19 <quicksilver> and then halfway through, it finds a parse failure
03:03:39 <quicksilver> it's a pain to have to wrap every such action in something which knows how to 'unroll' the IO-side-effects it just did
03:03:47 <dcoutts_> if there is any info that is comes out of the conversation with the client, then yes that has to be vetted
03:04:16 <dcoutts_> so I don't see any problem with doing lazy parsing
03:04:17 <quicksilver> I have considered suggesting you add 'validate' to the Binary API
03:04:28 <quicksilver> validate would 'strictly' go through the parsing process
03:04:31 <quicksilver> but discard the result
03:04:36 <quicksilver> so it would just check that parsing works :)
03:04:45 <dcoutts_> Get is already strict
03:04:51 <quicksilver> then after that it's safe to lazy parse cos you know it's going to work
03:06:00 <quicksilver> "< dcoutts_> so I don't see any problem with doing lazy parsing"
03:06:07 <quicksilver> I think I must have failed to communicate my worry then :)
03:06:16 <quicksilver> because I'm sure it *is* a valid concern.
03:06:27 <dcoutts_> I don't, but you'll have to use something more cunning to do lazy parsing using Get
03:06:35 <dcoutts_> it's only the boundary between the bit of code that talks to the client and any shared app state that you have to look at closely
03:06:51 <quicksilver> are you saying Binary instances aren't lazy?
03:06:58 <quicksilver> I though they were? I thought decode was lazy?
03:07:29 <dcoutts_> if you demand the value, it reads as much of the input as is necessary to construct the value
03:07:34 <quicksilver> right
03:07:37 <quicksilver> yes, that's what I thought
03:07:44 <dcoutts_> so sub-components of that value cannot be _|_
03:07:54 <quicksilver> really?
03:08:03 <quicksilver> even if the value is a nested ADT?
03:08:09 <dcoutts_> yes
03:08:18 <quicksilver> ah, that's OK then
03:08:37 <quicksilver> it's enough to 'seq' once at the top level in that case, I think?
03:08:41 <quicksilver> and that's not too much of a pain
03:08:44 <phlpp> hm, when given a number (integer), how could i split this integer into all his digits and save this to a list?
03:09:01 <quicksilver> phlpp: 'show' turns a number into a string...
03:09:02 <dcoutts_> quicksilver: there's some special lazy functions in Get, but they're fairly clearly marked
03:09:12 <quicksilver> phlpp: and a string is a list of digits, in a sense
03:09:28 <phlpp> hm okay, i thought there is another way
03:09:31 <quicksilver> dcoutts_: ok, that reassures me considerably
03:09:36 <quicksilver> phlpp: yes, there are lots of other ways
03:09:44 <quicksilver> phlpp: you didn't ask for *every* possible way :)
03:10:01 <quicksilver> dcoutts_: I had misunderstood what people meant when they said that 'Data.Binary is lazy'
03:10:11 <phlpp> quicksilver: next time i'll do so :D
03:10:13 <quicksilver> dcoutts_: I think we have a problem that we overuse the word lazy quite so much
03:10:13 <dcoutts_> quicksilver: it's lazy on the writing side
03:10:32 <quicksilver> and there are lots of different levels of laziness you can imagine :)
03:10:38 <dcoutts_> quicksilver: lazy parsing is much harder to implement
03:10:51 <dcoutts_> quicksilver: eg, how could you write a lazy parser using parsec?
03:11:01 <dcoutts_> you really can't
03:11:11 <quicksilver> you can have a kind of weak laziness
03:11:14 <dcoutts_> you need a more cunning parser to be able to do that
03:11:17 <phlpp> quicksilver: does read also work on Chars?
03:11:33 <quicksilver> but arbitrary access tends to force "everything to the left"
03:11:35 <phlpp> because every single digit is now a Char, and i want to convert them into a number
03:11:39 <dcoutts_> > read "'a'" :: Char
03:11:41 <lambdabot>  'a'
03:11:50 <dcoutts_> > ord 'a'
03:11:51 <lambdabot>  97
03:12:02 <quicksilver> so a naive lazy parser would force the left-branch of a tree when you access the right
03:12:05 <quicksilver> IYSWIM
03:12:13 <quicksilver> phlpp: it's not hard to turn a Char back into a small String
03:12:19 <phlpp> ah ok
03:12:20 <phlpp> :D
03:12:21 <quicksilver> > read ['9'] :: Int
03:12:22 <lambdabot>  9
03:12:23 <phlpp> i got it
03:12:24 <phlpp> ;-)
03:12:29 <phlpp> thanks
03:12:49 <dcoutts_> quicksilver: no, more than that. consider: do { a <- get; b <- get; c <- get; return Foo a b c }
03:13:02 <dcoutts_> quicksilver: that could be code in a parser, or a binary instance
03:13:15 <phlpp> works brilliant ;-)
03:13:16 <quicksilver> dcoutts_: yes. You can imagine accessing a without forcing b and c to be parsed
03:13:26 <dcoutts_> quicksilver: right, but it doesn't :-)
03:13:28 <quicksilver> dcoutts_: but if you accessed c, a and b would have to be parsed first
03:13:42 <quicksilver> dcoutts_: because it needs to know how many bytes long they are :)
03:13:53 <phlpp> squareDigits x = foldr (+) 0 $ map (\x -> (read [x])^2)	(show x)
03:13:57 <quicksilver> unless you have a different kind of instance with fixed lengths
03:13:58 <phlpp> can you teach me some better style? ;)
03:14:04 <dcoutts_> quicksilver: so it's not nearly that sophisticated, it has to read a, b and c to construct the Foo
03:14:23 <phlpp> i think there's at least one version that tends to be more sexy than mine ;_
03:14:25 <quicksilver> dcoutts_: ok, understood
03:14:33 <dcoutts_> quicksilver: because we don't know if we'll run out of input, or get a parse error or whatever
03:14:47 <quicksilver> phlpp: foldr (+) 0 is more commonly known as 'sum', assuming (+) is associative
03:14:56 <quicksilver> dcoutts_: yes, I definitely prefer that
03:14:57 <Botje> phlpp: sum $ map ((^2).read.return $ show x
03:14:58 <dcoutts_> quicksilver: lazy parsers are cool, but much harder to implement. Really useful for protocol messages though.
03:15:04 <phlpp> ah ok, didn't know that sum
03:15:06 <Botje> phlpp: sum $ map ((^2).read.return) $ show x
03:15:07 <Botje> even
03:15:19 <quicksilver> dcoutts_: I'm not sure lazy parsers are that cool, for the reasons I have been trying to outline :)
03:15:35 <quicksilver> dcoutts_: I mean, they are "cool technology" but I'm not sure they're "cool for untrusted data"
03:15:52 <quicksilver> dcoutts_: for pre-validated or otherwise trusted data, though
03:15:55 <dcoutts_> quicksilver: for example our tar file parser uses Get but returns a lazy list of tar entries. It had to extend the Get api to do that though.
03:16:04 <dmwit> Botje: Since it's a function, you might even leave of the last x: sum . map ((^2) . read . (:[])) . show
03:16:30 <dmwit> I prefer the crazy psycho monkey operator (:[]) to return; it's one less character. =P
03:16:36 <quicksilver> I always prefer (\x->[x]) or (:[]) to return
03:16:41 <quicksilver> not because of characters
03:16:50 <dcoutts_> quicksilver: they're cool for infinite data, like a stream of messages. You'd not be very pleased if you could not respond to the first message until you'd parsed the last message :-)
03:16:52 <quicksilver> but because they're not gratuitously polymorphic
03:16:53 <Botje> yeah, but it'll stab you with a banana when you're not looking.
03:17:07 <quicksilver> dcoutts_: true, true
03:17:21 <dcoutts_> quicksilver: but certainly, within a single message you want to parse it in one go to see if there could be any format errors.
03:17:33 <quicksilver> dcoutts_: did you consider a version of decode which returns a Maybe?
03:18:03 <quicksilver> dcoutts_: speaking for myself I'd rather something explicit I can force in pure code than an IO exception
03:18:15 <phlpp> hm, the pointfree version pasted by dwmit doesn't work for me
03:20:11 <quicksilver> > sum . map((^2).read.(:[])) . show $ 123
03:20:22 <lambdabot>  14
03:20:24 <dmwit> > let bozo = sum . map ((^2) . read . (:[])) . show in bozo 123
03:20:26 <lambdabot>  14
03:20:33 <SamB_XP_> quicksilver: Maybe isn't too informative
03:20:36 <dcoutts_> quicksilver: yes, we've not made Get into an error monad as we feared it'd make it too slow.
03:20:56 <quicksilver> SamB_XP_: true, but IO exceptions are a pain
03:21:15 <quicksilver> SamB_XP_: if we have a way of being informative then sure, make it an Either :)
03:21:22 <quicksilver> dcoutts_: fair enough. Would be interesting to test.
03:21:27 <dcoutts_> quicksilver: yes
03:21:53 <dmwit> > ord '0'
03:21:55 <lambdabot>  48
03:22:22 <dmwit> > let bozo = sum . map ((^2) . (subtract 48) . ord) . show in bozo 123
03:22:24 <lambdabot>  14
03:22:37 <quicksilver> dcoutts_: decodeM m = unsafePerformIO ((evaluate (decode m) >>= return . Just) `catch` return Nothing)
03:22:42 <quicksilver> dcoutts_: or, something like that
03:23:01 <quicksilver> :t try
03:23:03 <lambdabot> Not in scope: `try'
03:23:22 <quicksilver> :t Control.Exception.try
03:23:24 <lambdabot> forall a. IO a -> IO (Either GHC.IOBase.Exception a)
03:23:48 <quicksilver> decodeEither m = unsafePerformIO (try . evaluate . decode $ m)
03:23:50 <quicksilver> perhaps :)
03:24:29 <SamB_XP_> I really wish there was a way to do it lazily
03:24:49 <quicksilver> SamB_XP_: do which lazily?
03:25:02 <SamB_XP_> well, that sort of thing
03:25:17 <quicksilver> my whole point is that I don't want it to be lazy :)
03:25:28 <quicksilver> I need a place in my code where I can say "Is this message valid"
03:25:41 <quicksilver> I don't want a message thunk with hidden lazy invalidity in it, as it were
03:25:48 <SamB_XP_> yeah
03:25:57 <quicksilver> but I agree there are other applications where laziness would be cute
03:26:39 <SamB_XP_> it would be nice to have BOTH the lack of delayed _|_ AND laziness
03:27:06 <SamB_XP_> say, what does HXT do? I think I heard it could parse lazily now?
03:27:16 <SamB_XP_> or was that haxml?
03:27:58 <malcolmw> It is HaXml that can parse lazily
03:28:06 <SamB_XP_> ah.
03:28:26 <malcolmw> but you do get hidden bottoms inside values, if the input document is not well-formed
03:29:09 <malcolmw> the Utrecht parser combinators give "online" parsing, which returns results lazily, but only if there are no errors
03:29:54 <malcolmw> they do a complicated analysis to determine  whether there are any other parse possibilities, and if not, then they can return the prefix of the value
03:30:04 <SamB_XP_> I suppose hidden bottoms are not a problem with MAME gamelists
03:30:51 <SamB_XP_> ... since, you know, they are autogenerated and should always be valid
03:31:15 <SamB_XP_> or, more to the point, well-formed
03:32:54 <quicksilver> right
03:33:04 <quicksilver> hidden bottoms aren't a problem with guaranteed well-formed data
03:33:30 <quicksilver> although depending how much you trust that 'guarantee' you may be building a less robust system if you assume...
03:33:48 <quicksilver> the canonical answer to avoiding hidden bottoms but doing the actual parsing lazily is two-parse
03:33:53 <quicksilver> two-pass parse :)
03:34:03 <quicksilver> you do one full parse first but discard all the data instantly
03:34:13 <quicksilver> hopefully a good compiler/GC makes that fairly painless
03:34:18 <quicksilver> just to validate
03:36:20 <quicksilver> ..unless there is a clever approach I haven't thought of :)
03:41:00 <phlpp> okay, again i got some problems working on lists in lists. i have a list, sqDigList which workes like: iterate squareDigits ,though the list is going to be infinite (squareDigits 1 == 1......1.....1....1)
03:41:28 <phlpp> i want to create several sqDigLists for a certain "space" of numbers, e.g. [1..10]
03:42:11 <Cale> um, I don't understand what it is that you're trying to define...
03:42:24 <phlpp> wait, i'm not the fastest english typer ;)
03:42:28 <quicksilver> map squareDigits [1..10] ?
03:42:31 <phlpp> i'm trying to formalize it more precise
03:42:34 <phlpp> yeah
03:42:34 <quicksilver> that would give you a list-of-lists
03:42:36 <phlpp> that's it
03:42:39 <quicksilver> each list is infinite
03:42:44 <quicksilver> although the top-level list is not (10 items)
03:42:46 <phlpp> and now i want to check each of this 10 lists
03:43:00 <phlpp> if in a list is an element == 89
03:43:15 <quicksilver> you can't check an infinite list for an element, in finite time :)
03:43:25 <profmakx> *cough*
03:43:27 <quicksilver> well you can write code which returns if it is preset
03:43:31 <profmakx> in general
03:43:39 <quicksilver> but if it is absent, it will run forever looking...
03:44:07 <phlpp> it's true, i can't check sqDigList 1 for this
03:44:14 <phlpp> because it ends up in cycle 1, 1, 1
03:44:43 <bas`> Hello, quick question: Can you write "let (x, y) = e in (f x, y)" shorter using Arrows?
03:44:44 <phlpp> but i can check every list which ends up 89..some numbers..89, can't i?
03:44:45 <roconnor> filter (==89) $ concat $ transpose  $ map squareDigits [1..10]
03:44:56 <roconnor> any (==89) $ concat $ transpose  $ map squareDigits [1..10]
03:45:11 <Cale> If you can ensure that it's in one of them, it's possible to search through them in "parallel" to find which one contains the element you're looking for.
03:45:37 <phlpp> @src transpose
03:45:37 <lambdabot> transpose []             = []
03:45:38 <lambdabot> transpose ([]   : xss)   = transpose xss
03:45:38 <lambdabot> transpose ((x:xs) : xss) = (x : [h | (h:t) <- xss]) : transpose (xs : [ t | (h:t) <- xss])
03:45:39 <Cale> Yeah, transpose is quite handy for that
03:45:41 <scook0> bas`: looks like first f $ e
03:45:51 <scook0> (well, the $ is redundant)
03:45:53 <Cale> > transpose [[1,2,3],[4,5,6],[7,8,9]]
03:45:54 <lambdabot>  [[1,4,7],[2,5,8],[3,6,9]]
03:46:10 <phlpp> ah okay, what do i have to import to get transpose? =)
03:46:22 <scook0> @hoogle transpose
03:46:22 <lambdabot> List.transpose :: [[a]] -> [[a]]
03:46:22 <lambdabot> Data.Graph.transposeG :: Graph -> Graph
03:46:22 <roconnor> import Data.List
03:46:25 <phlpp> ah ok
03:46:30 <bas`> scook0: ok thanks!
03:46:56 <scook0> bas`: another way is (f *** id)
03:47:00 <roconnor> any (any (==89)) $ transpose  $ map squareDigits [1..10]
03:47:55 <roconnor> filter (any (==89)) $ transpose  $ map squareDigits [1..10]
03:48:12 * roconnor likes that last one
03:51:18 <trez> can someone explain how and why 'flip id 3 (+1)' works? because can't get how the types matches
03:51:40 <dobblego> ?type flip id 3 (+1)
03:51:42 <SamB_XP_> @type flip id
03:51:42 <lambdabot> forall b. (Num b) => b
03:51:44 <lambdabot> forall b c. b -> (b -> c) -> c
03:52:39 <SamB_XP_> @pl flip id 3 (+1)
03:52:39 <lambdabot> 4
03:52:42 <SamB_XP_> heh
03:52:45 <scook0> ($) is a type-restricted id
03:52:55 <scook0> so flip id is flip ($)
03:53:05 <SamB_XP_> @pl flip id x (+y)
03:53:05 <lambdabot> x + y
03:53:08 <scook0> which supplies an argument to a function
03:53:13 <trez> hmm :)
03:53:35 <phlpp> roconnor: seems like i end up in infinte lists because of that nums that end in a "1...1...1" cycle? (pls excuse my slooow understanding)
03:54:28 <roconnor> phlpp: do you want to truncate the list when the 1 appears again?
03:55:02 <roconnor> > takeWhile (/=1) (iterate (
03:55:02 <lambdabot>  Unbalanced parenthesis
03:55:15 <phlpp> finally, i want to "count" all numbers that end by iterating over the square of digits 89
03:55:28 <roconnor> > takeWhile (/=1) (iterate (\n -> if odd n then 3*n+1 else n`div`2) 22)
03:55:33 <lambdabot>  [22,11,34,17,52,26,13,40,20,10,5,16,8,4,2]
03:56:15 <phlpp> hehe
03:56:17 <phlpp> that are
03:56:30 <phlpp> hm, unfourtnatly forgot the names of this numbers ;)
03:56:32 <phlpp> ah, collatzNums
03:56:39 <phlpp> yeah, a problem that i solved  before
03:57:58 <roconnor> phlpp: I don't understand :(  You are generating infinite lists, and you want to avoid doing that somehow?
03:58:17 <phlpp> hm, ok, that's probably my fault because of my poor english
03:58:31 <roconnor> phlpp: it's okay, everyone here speaks haskell
03:58:37 <roconnor> phlpp: you can use paste
03:58:38 <phlpp> at first we have a function that squares the digits of the num, so squareDigits 44 is 32
03:58:39 <roconnor> @past
03:58:39 <lambdabot> Haskell pastebin: http://hpaste.org/new
03:58:50 <phlpp> now i got a list thats like sqDigList = iterate squareDigits
03:58:59 <roconnor> phlpp: ah sume of squares of the digits
03:59:02 <roconnor> wer
03:59:07 <roconnor> sum of squares of digits
03:59:15 <phlpp> yeah
03:59:17 <phlpp> sorry ;)
03:59:22 <roconnor> no problem
03:59:25 <quicksilver> trez: want a more detailed explanation?
03:59:28 <roconnor> so you iterate this process.
03:59:34 <phlpp> so this sqDigList is infinite, no matter on the number
03:59:41 <roconnor> right
04:00:00 <phlpp> and the amazing thing now is, that every number prolly ends in one of two cycles
04:00:09 <roconnor> oh?
04:00:23 <phlpp> first cycle looks like 44 -> 32 -> 13 -> 10 -> _1_ -> _1_
04:00:35 <roconnor> right
04:00:47 <phlpp> and second cycle is like 85 -> _89_ -> 145 -> 32 -> 20 -> 4 -> 16 -> 37 -> 58 -> _89_
04:01:11 <roconnor> so when you get to 89 or 1, you can stop, because you know what the rest will look like.
04:01:21 <phlpp> yeah
04:01:44 <phlpp> and the task is to count all the numbers between a certain space of numbers, which end up in this 89 cycle
04:01:53 <trez> quicksilver: yeah
04:02:08 <scook0> is it *known* that all sequences degenerate into one of those two?
04:02:15 <roconnor> so apply (takeWhile (\x -> x/=89 /\ x/=1)) to your infinite list
04:02:20 <quicksilver> trez: look at the type of flip, first
04:02:23 <quicksilver> :t flip
04:02:24 <roconnor> that will make the list finite
04:02:25 <lambdabot> forall a b c. (a -> b -> c) -> b -> a -> c
04:02:30 <phlpp> so i think the problem to me, despite the other problems i had, is to drop all this cycles which end up in 1, and get a list with nums that end up in a 89 cycle, so i just can do like "length l" and get the result
04:02:35 <trez> mm
04:02:47 <quicksilver> trez: flip's argument must be of the form (a -> b -> c)
04:02:49 <quicksilver> (for some a,b,c)
04:03:00 <quicksilver> now id has type "d -> d" for *any* d
04:03:12 <roconnor> so apply (takeWhile (\x -> x/=89 && x/=1)) to your infinite list
04:03:17 <phlpp> ?type (/\)
04:03:17 <quicksilver> so we have to unify (a -> b -> c) with (d -> d)
04:03:18 <lambdabot> Not in scope: `/\'
04:03:22 <quicksilver> if we're going to apply flip to id
04:03:33 <roconnor> phlpp: sorry /\ is the wrong language.  I meant &&
04:03:36 <quicksilver> trez: make sense so far?
04:03:42 <trez> quicksilver: I think so
04:03:53 <phlpp> roconnor: ah, /\ is the && for working on sets in mathematics
04:03:55 <phlpp> i think
04:03:56 <phlpp> ;)
04:03:58 <quicksilver> trez: that looks impossible at first glance
04:04:05 <trez> thats for sure :)
04:04:08 <quicksilver> trez: but a -> b -> c is actually (a -> (b -> c))
04:04:08 <roconnor> phlpp: something like that. :)
04:04:20 <trez> as i suspected
04:04:21 <quicksilver> trez: so the unification is "d = a" and "d = b -> c"
04:04:33 <quicksilver> ...which means a = b->c too
04:04:56 <trez> as simple as that then ;)
04:04:56 <quicksilver> so we have id at type "(b -> c) -> (b -> c)"
04:05:11 <quicksilver> which can be written "(b -> c) -> b -> c"
04:05:17 <quicksilver> that's just "identify on functions"
04:05:25 <quicksilver> "identity" sorry
04:05:35 <quicksilver> now *finally* we can flip it
04:05:40 <quicksilver> so we flip the two parameters
04:05:48 <quicksilver> and we get flip id :: b -> (b -> c) -> c
04:06:00 <quicksilver> which is just a way of applying a function to a value
04:06:06 <roconnor> phlpp: actually apply (dropWhile (\x -> x/=89 && x/=1)) is better
04:06:09 <quicksilver> but it takes the 'value' b before the 'function' b -> c
04:06:14 <quicksilver> > flip id 3 (+1)
04:06:19 <lambdabot>  4
04:06:23 <roconnor> phlpp: then the head of the list will either be an 89 or a 1.
04:06:25 <quicksilver> here b == c == Int
04:06:34 <trez> quicksilver: think I understand now :)
04:07:10 * quicksilver nods
04:07:14 <quicksilver> it's a bit odd I agree :)
04:07:14 <trez> thanks! :)
04:07:23 <quicksilver> clever old unification algorithm
04:07:28 <trez> hehe
04:07:55 <scook0> and, as I mentioned, id at type "(b -> c) -> (b -> c)" is the ($) operator
04:08:51 <scook0> so if you wanted, you could write f `id` x instead of f $ x ;)
04:09:37 <phlpp> roconnor: ok, now i get finite lists when mapping sqDigList to e.g. [1..10]. and now i have to check every list (in the "main" list)) for a "pattern number" like 42, or 16, or 58?
04:09:54 <roconnor> phlpp: actually apply (dropWhile (\x -> x/=89 && x/=1)) is better
04:10:02 <roconnor> then you can look at the head of the list
04:10:13 <phlpp> ah, i just have to look of the last element
04:10:15 <phlpp> of each list
04:10:31 <phlpp> and if its like 10, then drop this
04:10:39 <phlpp> (so all 1..cycles are dropped)
04:10:54 <roconnor> phlpp: that works, but using dropWhile is better
04:11:31 <roconnor> and now that I think about it, find is even better still
04:12:00 <phlpp> hm, but now i get infinite lists again?
04:12:05 <roconnor> > find (\x -> x==89 /\ x == 1)
04:12:06 <lambdabot>   Not in scope: `/\'
04:12:13 <phlpp> :D
04:12:17 <scook0> roconnor: depends if you just want the signature number, or if you also want the list before it
04:12:18 <roconnor> phlpp: look at the head of the infinite list
04:12:36 <phlpp> cool
04:12:38 <phlpp> ;-)
04:12:39 <scook0> > let (/\) = (&&) in find (\x -> x==89 /\ x == 1)
04:12:40 <lambdabot>      precedence parsing error
04:12:40 <lambdabot>         cannot mix `(==)' [infix 4] and `(==)' ...
04:12:44 <roconnor> > find (\x -> x==89 && x == 1) [32, 45, 89, 6,5]
04:12:45 <lambdabot>  Nothing
04:12:51 <roconnor> > find (\x -> x==89 || x == 1) [32, 45, 89, 6,5]
04:12:53 <lambdabot>  Just 89
04:12:57 <roconnor> > find (\x -> x==89 || x == 1) [32, 45, 1, 6,5]
04:12:58 <lambdabot>  Just 1
04:13:22 <scook0> phlpp: what exactly do you want to do with the list, once you've identified that it contains 89 or 1?
04:13:40 <scook0> e.g. do you care about the list elements before that point?
04:13:43 <roconnor> map (find  (\x -> x==89 || x == 1)) $ map squareDigits [1..10]
04:14:00 <roconnor> filter (==Just 89) $ map (find  (\x -> x==89 || x == 1)) $ map squareDigits [1..10]
04:14:05 <roconnor> length $ filter (==Just 89) $ map (find  (\x -> x==89 || x == 1)) $ map squareDigits [1..10]
04:15:02 <roconnor> of course, what would be more fun is to write a function that finds the first repeated element in a list,
04:15:10 <phlpp> yeah
04:17:24 <roconnor> > find (\l -> (last l) `elem` (init l)) $ inits [32, 45, 1, 6,5 ,1]
04:17:25 <lambdabot>  Exception: Prelude.init: empty list
04:17:37 <roconnor> > find (\l -> (last l) `elem` (init l)) $ tail $ inits [32, 45, 1, 6,5 ,1]
04:17:38 <lambdabot>  Just [32,45,1,6,5,1]
04:17:59 <roconnor> > fmap last $ find (\l -> (last l) `elem` (init l)) $ tail $ inits [32, 45, 1, 6,5 ,1]
04:18:01 <lambdabot>  Just 1
04:18:07 <roconnor> > fmap last $ find (\l -> (last l) `elem` (init l)) $ tail $ inits [32, 45, 1, 6,5 ,45]
04:18:08 <lambdabot>  Just 45
04:18:13 <roconnor> > fmap last $ find (\l -> (last l) `elem` (init l)) $ tail $ inits [32, 45, 1, 6,5 ,45,55,66]
04:18:14 <lambdabot>  Just 45
04:20:14 <scook0> ideally you'd be using some kind of Set type for that
04:20:42 <dcoutts_> @seen bringert
04:20:42 <lambdabot> bringert is in #ghc and #haskell. I don't know when bringert last spoke.
04:20:47 <bringert> hi dobblego
04:20:53 <bringert> hi dcoutts_
04:20:56 <bringert> is what I meant
04:21:06 <bringert> stupid tab completion doesn't know what I mean
04:21:35 <dcoutts_> bringert: hia. cabal -w ghc-6.4.2 install does not do what I expect. It uses ghc-6.4.2 when considering package deps, but builds the package using ghc from the path
04:21:48 <dcoutts_> bringert: presumably we should pass on the compiler to setupWrapper
04:21:55 <phlpp> ok
04:22:04 <phlpp> this solution seems to be PoC ;)
04:22:18 <phlpp> i broke this "one-minute-rule" now like 10 times :D
04:22:27 <phlpp> (space is 1..10^7)
04:24:45 <bringert> dcoutts_: ah yes, it doesn't do that
04:25:03 <roconnor> PoC?
04:25:18 <dcoutts_> bringert: I'm trying to use cabal-install to test that a dozen package all build with 6.4.2, 6.6.1 & 6.8.0.x
04:25:21 <roconnor> > 10^7
04:25:32 <lambdabot>  10000000
04:25:44 <roconnor> kinda bigish
04:26:13 <quicksilver> one minute rule is euler, I think
04:26:26 <quicksilver> every problem should be solvable on a moderate computer in under a minute
04:26:33 <quicksilver> if it takes longer, your algorithm isn't celver enough
04:26:41 <dcoutts_> bringert: so my use case is to cd to the unpacked dir, and: $ for ghc in ghc-6.4.2 ghc-6.6.1 ghc; do cabal -w $ghc install; done
04:26:51 <dcoutts_> bringert: to get it installed for all the compilers
04:27:16 <bringert> dcoutts_: sounds good
04:27:36 <dcoutts_> bringert: then I'll send you tar & unix-compat patches :-)
04:27:58 <dcoutts_> though cabal needs another fix before we can build unix-compat with 6.8.x
04:28:03 <bringert> dcoutts_: I'm putting them on code.haskell.org. Just waiting for my project requests to be approved
04:28:18 <dcoutts_> bringert: oh yes, I should go approve them...
04:28:39 <bringert> dcoutts_: I'll take off soon though, so I won't have time to do that until tonight or tomorrow
04:28:53 <dcoutts_> bringert: np
04:30:40 <roconnor> @bab en nl lose
04:30:42 <lambdabot>   verlies
04:34:06 <phlpp> roconnor: Proof of Concept
04:34:39 <phlpp> quicksilver: yeah, thats it, but for me the rule isn't important. im trying to 'increase' my skills of 'thinking functional' in haskell by solving euler problems
04:34:53 * quicksilver nods
04:40:42 <yitz> quicksilver: by Moore's law, the limit on Euler should be under 15 secs. now.
04:41:00 <quicksilver> yitz: ;)
04:41:13 <quicksilver> yitz: I think the notion is that you might have an old-ish computer
04:41:32 <yitz> Well, that was also the notion four years ago. :)
04:41:56 <scook0> yitz: nah, you just have to be able to solve the problem four times, in under a minute
04:42:46 <yitz> scook0: :) Fortunately for me, there is no limit on brain time, only CPU.
04:54:08 <phlpp> ok
04:54:11 <phlpp> see ya later guys
04:54:13 <phlpp> thanks for help :))
04:54:38 <roconnor> anytime
04:59:36 <profmakx> man, template haskell seems to be quite evil to compile o.O
05:01:08 <Igloo> to compile? It comes with GHC
05:02:03 <Igloo> malcolmw++ dcoutts_++ # doing community admin stuff
05:02:09 <dcoutts_> @arr!
05:02:10 <lambdabot> Aye
05:02:26 <dcoutts_> no more pending project requests
05:02:34 <dcoutts_> Igloo: I made a little script
05:02:42 <profmakx> Igloo, if there is a compiler binary ready for your OS.
05:02:43 <dcoutts_> we should probably use that centrally
05:03:00 <profmakx> might be, that i should leave this one out for bootstrapping 6.8 o.o
05:03:19 <Igloo> profmakx: Do you mean "uses lots of memory/time" by evil?
05:03:38 <profmakx> Igloo: yes
05:03:47 <Igloo> dcoutts_: Cool, please add it to the repo
05:04:04 <Igloo> profmakx: Ah, OK, yes
05:04:04 <profmakx> but i wont need it for bootstrapping right?
05:04:21 <dcoutts_> Igloo: remind me where that is
05:04:26 <Igloo> I don't think so, no, as you'll only be building a stage1 GHC
05:04:55 <dcoutts_> ah /home/admin/web/admin
05:05:14 <Igloo> dcoutts_: Hmm, I can't see the repo that contains malcolmw's script
05:06:10 <Igloo> Oh, no, you're right, it's just not executable in my checkout so I missed it
05:14:49 <dcoutts_> Igloo: done
05:15:22 <Igloo> Cool, thanks
05:16:03 <dcoutts_> Igloo: btw, do all users umaks default to making group writable?
05:16:12 <Igloo> Yup
05:16:17 <dcoutts_> ok good good
05:16:39 <dcoutts_> so combined with the group sticky bit that should be ok
05:17:05 <dcoutts_> we'll not need _darcs  chmod g+w -R hacks
05:17:38 <Igloo> No, except darcs push over SSH seemed to break perms for some people at the Hackathon. I haven't got around to investigating yet
05:19:00 <dcoutts_> hmm
05:19:26 <dcoutts_> I'm always confused about what base files are sourced for interactive vs non-interactive ssh logins
05:19:33 <dcoutts_> base/bash
05:20:19 <Igloo> I'm mostly confused because I'm pretty sure I tested it a while ago and it worked for me
05:20:44 <dcoutts_> Igloo: ssh community.haskell.org touch foo
05:20:46 <dcoutts_> then
05:20:51 <dcoutts_> ls -l foo
05:20:51 <dcoutts_> -rw-r--r-- 1 duncan duncan 0 Oct 17 08:20 foo
05:20:56 <dcoutts_> not group writable
05:21:42 <dcoutts_> but when I log in interatively and touch bar it is group writable
05:22:41 <malcolmw> @karma
05:22:42 <lambdabot> You have a karma of 2
05:23:25 <kosmikus> malcolmw++
05:23:36 <mux> you know that using the sgid bit on directories to force the group of files within it is not portable?
05:23:41 <malcolmw> aw, shucks :-)
05:24:06 <dcoutts_> mux: we don't need it to be portable, it only has to work on code.haskell.org
05:24:16 <mux> ah, okay :-)
05:24:32 <mux> I was about to suggest ACLs
05:26:25 <dylan> well, I dunno about bash, but zsh always  executes a ~/.zshenv, you could use that to set umask.
05:26:57 <dylan> ~/.bashrc and ~/.bash_profile are only executed for interactive and login shells, respectively.
05:29:30 <quicksilver> mux: not portable to what? CP/M?
05:29:56 <quicksilver> mux: it's supported by every OS I've used wchich has a chmod command at all..
05:30:40 <roconnor> good ol' CP/M
05:30:55 <mux> quicksilver: can't answer that off the top of my head
05:31:06 <mux> but there are some, that are more used than CP/M =)
05:31:18 <quicksilver> well it works on linux, OSX and Solaris. That's Good Enough for Me (TM) :)
05:31:25 <quicksilver> oh, and *BSD
05:32:26 <roconnor> OS/2?
05:34:06 <EvilRanter> is it a POSIX requirement?
05:34:37 <ndm> @seen malcolmw
05:34:37 <lambdabot> malcolmw is in #haskell-soc, #ghc, #haskell-overflow, #haskell-blah and #haskell. I last heard malcolmw speak 10m 56s ago.
05:34:56 <malcolmw> ndm: whatsup?
05:34:59 <ndm> malcolmw: you broke Yhc with your CPPHS change!
05:35:07 <ndm> defaultCpphsOptions {defines = macros,
05:35:09 <ndm>                   boolopts = defaultBoolOptions{ansi=True, strip=False}}
05:35:13 <ndm> strip has now disappeared
05:35:31 <malcolmw> oops
05:35:33 <ndm> any suggestions what should go in its place?
05:35:43 <malcolmw> it was a fix for a reported bug
05:35:52 * EvilRanter notes that malcolmw and ndm are both @*.cs.york.ac.uk
05:36:18 <ivanm> EvilRanter: what, you're saying that they should actually talk to each other _face-to-face_ ?
05:36:26 <EvilRanter> heh. in the past, i've talked to someone literally one room away over IRC
05:36:26 <ivanm> isn't that unhygenic? :p
05:36:44 <malcolmw> ndm: stripC89=False, stripEol=False
05:36:52 <ndm> EvilRanter: yes, malcolm is about 25m from me at the moment
05:36:53 <earthy> heh. in the past, I've talked to someone literally in the same roon over IRC. :P
05:36:53 <EvilRanter> it's handy when you both want to be able to look stuff up online
05:37:22 <EvilRanter> i've also talked to someone whose laptop was sitting on the same table over IRC, because i wanted to send him a link
05:37:28 <ndm> i have a friend who plays facebook scrable with his wife who is in the next room
05:37:34 <EvilRanter> just thought it was vaguely amusing
05:38:12 <malcolmw> I think ndm just wanted to shame me in front of the world, so he'd get a faster bugfix :-)
05:38:26 <earthy> heh, I've had my gf poke me on MSN to get my attention... while we were both on the couch.
05:38:41 <EvilRanter> ivanm, you should be able to alpha-reduce 'til it's hygenic, regardless
05:38:44 <yitz> Here's something you can't do face to face:
05:38:48 <yitz> @botsnack
05:38:49 <lambdabot> :)
05:39:03 <earthy> @botsnack
05:39:03 <lambdabot> :)
05:39:08 <ndm> hehe, its not that bad
05:39:28 <ndm> if i had you on google talk would have probably tried that first...
05:39:47 <malcolmw> earthy: know anything about the Utrecht parser combinators?
05:44:03 <malcolmw> I need a primitive combinator like (satisfy :: (token->Bool) -> Parser token token), and was wondering if it would be difficult to write?
05:46:10 <madnificent> I'd like to represent a matrix in haskell. Only for some very simple things (I just need to be able to substract a number on a certain position in it), but I can't really think of an efficient structure for it...
05:46:41 <EvilRanter> array ((0,0),(w-1,h-1)) ?
05:46:46 <EvilRanter> ?docs Data.Array
05:46:47 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Data-Array.html
05:47:20 <EvilRanter> if you know how big it is in advance, a tuple-of-tuples might be better
05:47:30 <EvilRanter> but then again, it might not, because they're a pain to manipulate
05:47:57 <EvilRanter> ... yeah, i'd use Arrays. tuples're only really better for hereogeneous stuff
05:48:12 <madnificent> EvilRanter: lemme see
05:49:13 <EvilRanter> they're O(1) lookup time, and rather more space efficient than a list of (key,value) pairs or whatever too
05:50:49 <madnificent> EvilRanter: but they'll need to be recreated after every change... any idea how long that would take?
05:51:02 <madnificent> O(n) ?
05:51:22 <EvilRanter> do you actually need to change the contents of your array one-cell-at-a-time?
05:51:39 <madnificent> EvilRanter: yup
05:51:48 <EvilRanter> @docs Data.DiffArray
05:51:48 <lambdabot> Data.DiffArray not available
05:51:51 <madnificent> EvilRanter: 2 cells at a time to be correct...
05:51:59 <EvilRanter> @docs Data.Array.Diff
05:51:59 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Data-Array-Diff.html
05:52:30 <EvilRanter> that one's more efficient for changing things, but performance suffers if you need to play with an old version of the array after you've changed it
05:53:04 <quicksilver> I'd be inclined to start with a list of lists or a plain array
05:53:21 <madnificent> EvilRanter: so it is rather hard to go back to a previous 'state' of the array?
05:53:22 <quicksilver> and only try something more ifddly if you've proved that doesn't work well enough
05:53:35 <EvilRanter> Array would be O(n) for each modification, DiffArray would be O(1) as long as you don't look at old versions
05:53:39 <EvilRanter> but O(n) otherwise
05:53:55 <EvilRanter> i agree with quicksilver. i'd try Array first and see if that's fast enough.
05:54:12 <EvilRanter> alternatively, you could use
05:54:16 <EvilRanter> @docs Data.Array.IArray
05:54:16 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Data-Array-IArray.html
05:54:28 <quicksilver> IArray is only an interface
05:54:30 <EvilRanter> and then you could try both array implementations and see what works best for you
05:54:33 <quicksilver> (to which Array conforms)
05:54:56 <madnificent> it's for an assignment... so I'll need all the speed I can get... but I could go for a non-ideal first-solution...
05:55:12 <EvilRanter> quicksilver, i know. i meant he could write general code that would work over Arrays *and* DiffArrays, and then profile or something
05:55:44 <quicksilver> right
05:55:50 <quicksilver> well the code isn't very different anywa, actually
05:55:54 <quicksilver> most of the names the same
05:55:59 <quicksilver> just depends what you import
05:56:11 <madnificent> thanks!
05:56:23 <EvilRanter> indeed
05:56:24 <madnificent> still learning haskell, so it will take a while
06:02:56 <fasta> I have two classes that have the same text(but different implementations). How can I write a constant CPP(processed by cpphs) macro that has newlines in it? I.e. <spaces> foo = fooImplementation<newline>*
06:03:22 <fasta> s/classes/instances
06:05:06 <fasta> I already tried using \
06:10:47 <EvilRanter> i don't think you can. CPP wasn't really designed for whitespace-dependent languages.
06:12:45 <fasta> EvilRanter: cpphs should be
06:13:07 <EvilRanter> ah, well, i'm not familiar with that in particular. i don't know how much they've changed it.
06:13:28 <fasta> EvilRanter: never mind, I found it
06:13:36 <EvilRanter> o tell?
06:13:39 <EvilRanter> *do tell?
06:15:43 <fasta> EvilRanter: \\n line continuations within all # directives
06:16:00 <EvilRanter> aha
06:16:32 <fasta> EvilRanter: but now I just include the whole file
06:17:51 <yitz> you could use m4 instead of cpp
06:17:54 * yitz ducks
06:19:21 <krishnbh1kt> I was wondering how the compiler of haskell is compiled in haskell?
06:20:05 <krishnbh1kt> what was used to compile the first haskell compiler?
06:20:18 <matthew_-> C
06:20:21 <EvilRanter> a haskell interpreter? :P
06:20:31 <matthew_-> ghc 6.4 didn't require ghc IIRC
06:20:38 <krishnbh1kt> ok
06:21:04 <yitz> There is a "bootstrap" version of ghc in c. it is very slow and simple. You then recompile several iterations until you get something good.
06:21:15 <krishnbh1kt> now we compile the latest ghc using previous version or ghc, or we use gcc?
06:21:22 <yitz> ghc
06:21:47 <fasta> I thought you could also use other Haskell compilers to compile GHC.
06:21:49 <osfameron> but when porting to a system that has never had a ghc you start with the bootstrap version?
06:21:54 <fasta> But maybe that has changed.
06:21:56 <yitz> right
06:22:02 <matthew_-> which, I assume, causes all kinds of hell for gentoo and nix os ?
06:22:14 <yitz> No, why?
06:22:26 <krishnbh1kt> ok
06:22:32 <matthew_-> if you try to install ghc 6.6 or better, would it not first have to download and compile 6.4 via C ?
06:22:32 <fasta> matthew_-: what do you mean by nix? *nix?
06:22:39 <matthew_-> fasta: no, nix os
06:22:40 <madnificent> matthew_-: ghc runs fine here... (gentoo)
06:22:43 <krishnbh1kt> what is c compiler compiled with?
06:22:49 <allbery_b> <matthew_-> ghc 6.4 didn't require ghc IIRC
06:22:49 <matthew_-> goats
06:22:57 <matthew_-> precisely
06:23:10 <idnar> gcc is compiled with gcc
06:23:11 <EvilRanter> krishnbh1kt, the original C compiler was probably written in assembly
06:23:20 <cjay> gentoo uses a ghc binary to compile ghc by default
06:23:22 <EvilRanter> most modern ones are written in C, though
06:23:24 <krishnbh1kt> ok
06:23:31 <matthew_-> cjay: ahh, I wondered if they'd done that
06:23:50 <EvilRanter> and the first assembler must've been written, at least in part, in raw machine code
06:23:52 <krishnbh1kt> and assembly compiler written in binary?
06:23:53 * osfameron imagines that Visual Basic isn't written in VB...
06:24:04 <cjay> matthew_-: they also have a ghcbootstrap useflag, but I don't know what that does exactly
06:24:07 <allbery_b> my understanding is that compiling ghc has, except for the very first version, always required ghc.  but you could and still can split it up by using a working ghc to generate "exportable" unregisterised ANSI C, which you can then carry over to a new machine and build with any ANSI C compiler to get a slow but working ghc
06:24:16 <EvilRanter> of course not, osfameron. everyone knows all of MS's software's written in qbasic!
06:24:32 <vincenz> Anyone from NY here?
06:24:41 <allbery_b> then yiou can use that to iteratively build and test a native registerised ghc port
06:25:03 <matthew_-> fasta: http://nix.cs.uu.nl/nixos/index.html
06:25:04 <dcoutts_> osfameron, EvilRanter: surely VB is written in pure binary COM
06:25:05 <lambdabot> Title: NixOS
06:25:11 <fasta> matthew_-: yes, I know it.
06:25:15 <osfameron> eeeek!
06:25:41 <yitz> @go porting ghc
06:25:41 <EvilRanter> dcoutts_, i'm joking already ;)
06:25:44 <lambdabot> http://hackage.haskell.org/trac/ghc/wiki/Building/Porting
06:25:44 <lambdabot> Title: Building/Porting - GHC - Trac
06:25:46 <dcoutts_> well, back in the days when VB was VB rather than C#
06:26:02 <matthew_-> allbery_b: ahh ok, that's interesting
06:26:23 <EvilRanter> allbery_b, so it's kinda like cross-compilation, only you don't need to know so much about the target platform because there's another compilation step to come?
06:26:41 <osfameron> back in those days, I wrote a source filter to add support for anonymous closures to vbscript, in vbscript itself.
06:27:02 <allbery_b> the unregisterised version requires very little about the target platform.  the price paid is that it's very slow.
06:27:10 <yitz> To get registerisation to work right, you'll have to customize based on your platform specific knowledge.
06:27:37 <krishnbh1kt> and how is the os compiled?
06:27:59 <Olathe> It's not.
06:28:00 <quicksilver> EvilRanter: are you sure the first assembler wasn't written as punched cards? :)
06:28:07 <Olathe> It runs on VBScript.
06:28:10 <allbery_b> you could just use that, but if you want something with decent performance you need to go in and customize the unregisterised C code to use native registers efficiently and generate efficient tail and thunk calls, etc.
06:28:12 <quicksilver> krishnbh1kt: most OSes are written mostly in C
06:28:34 <allbery_b> it's really not something to attempt unless you're handy with writing optimizing compilers for the target platform
06:28:37 <EvilRanter> quicksilver, well, it'd be machine code on the punched cards
06:28:40 <krishnbh1kt> so we compile with c-compiler
06:28:52 <EvilRanter> and that could be used to assemble, er, assembly on punched cards, i guess
06:29:01 <allbery_b> (meaning, deep understanding of the target machine/assembly language)
06:29:03 <quicksilver> EvilRanter: yeah, I was joking :P
06:29:35 <EvilRanter> okay then
06:29:37 <allbery_b> in the old days it also required customizing an ugly and fragile chunk of perl appropriately named the Evil Mangler.  with modern ghc'
06:29:57 <allbery_b> s ability to compile directly, the Evil Mangler is no longer necessary IIRC
06:30:11 <yitz> quicksilver: maybe it was written in plugged-in patch cords
06:30:25 <fasta> What does Unregistred mean? Is it just that the compiled code cannot use registers?
06:30:28 <profmakx> bootstrapping is a pita nonetheless
06:30:33 <Zao> fasta: registerised.
06:30:56 <yitz> fasta: right, well, not all of them.
06:31:02 <Zao> A registerised build it handcrafted to fit the platform. An unregisterised build is just plain old C, which will be rather unefficient.
06:31:19 <allbery_b> fasta: originally "yes" (more specifically,, does not customize its register usage for the platform) but it actually goes well beyond that
06:32:06 <quicksilver> allbery_b: I always did (still do) find the irony of the evil mangler being written in Perl quite delicious :)
06:32:07 <allbery_b> ghc generated code uses all sorts of tricks to get fast performance these days.  (very early versions, not so much.)
06:32:27 <quicksilver> allbery_b: puts me very much in mind of http://xkcd.com/224/
06:32:28 <lambdabot> Title: xkcd - A webcomic of romance, sarcasm, math, and language - By Randall Munroe
06:32:40 <allbery_b> yeh
06:34:16 <matthew_-> quicksilver: yeah, that's probably my favourite xkcd
06:36:14 <EvilRanter> there'd be something deliciously circular if it were written in perl6 running on pugs :D
06:37:33 <fasta> Is there a length function that works for million element lists?
06:37:56 <EvilRanter> length doesn't?
06:38:16 <phlpp> hi :)
06:38:20 <matthew_-> if, tonight, every single C compiler, both binary and source code, magically was erased, I imagine we'd be in big trouble...
06:38:42 <fasta> EvilRanter: oh, it seems it does now.
06:38:47 <EvilRanter> :D
06:38:59 <fasta> > length [1..100000000]
06:39:04 <lambdabot> Terminated
06:39:05 <matthew_-> but if you know it's a million element list...
06:39:18 <fasta> matthew_-: ...
06:39:20 <Zao> Heh, it ran out of memory.
06:39:23 <Itkovian> Can one argue that a compiled Haskell application somehow runs on a virtual machine, albeit one that is compiled into the binary?
06:39:29 <matthew_-> fasta: then the answer will be 1,000,000
06:39:30 <EvilRanter> fst . last . zipWith [1..]? ;)
06:39:35 <EvilRanter> Zao, no, it ran out of time
06:39:42 <quicksilver> Itkovian: one can certainly argue that, yes
06:39:42 <fasta> matthew_-: yes, I know that wanted to say that
06:39:49 <EvilRanter> @help run
06:39:50 <lambdabot> run <expr>. You have Haskell, 3 seconds and no IO. Go nuts!
06:39:50 <quicksilver> Itkovian: it depends on what you mean by 'virtual machine'
06:39:53 <Zao> EvilRanter: On my box, for  length $ take 100000000 [0..]
06:40:02 <quicksilver> Itkovian: however, it certainly doesn't run as any kind of bytecode
06:40:03 <Zao> :P
06:40:05 <EvilRanter> ohh, i thought you meant lambdabot :P
06:40:08 <allbery_b> Itkovian: look up "spineless tagless G-machine".  (although these days it is neither)
06:40:12 <quicksilver> Itkovian: which is often taken to be characteristic of virtual machines
06:40:22 <Itkovian> quicksilver: true enough. something that takes care of all the nastiness like garbage collection etc
06:40:31 <quicksilver> normally we just call those 'run-time systems'
06:40:34 <Itkovian> allbery_b: yeah, but if the G-machine is not really used
06:40:37 <quicksilver> but yes, you can make a case
06:40:40 <matthew_-> > length [1..10000000]
06:40:44 <lambdabot> Terminated
06:40:47 <fasta> I thought length had "issues" for large lists, but apparently it wowrks just fine.
06:40:51 <fasta> works*
06:40:52 <Itkovian> allbery_b: when I was taught Haskell, the G-machine was mentioned
06:40:53 <matthew_-> wow, the box b's running on is slow
06:41:00 <Itkovian> quicksilver: managed runtime systems
06:41:02 <quicksilver> fasta: length doesn't work for lists longer than MAXINT
06:41:03 <pejo> Itkovian, if the GC makes it run in a virtual machine, then C+Boehms collector is a vm too.
06:41:18 <Itkovian> pejo: of course, more than just GC is required
06:41:19 <fasta> quicksilver: that's good enough for me ;)
06:41:23 <quicksilver> fasta: so, around 1 billion or 2 billion
06:41:28 <quicksilver> (on a 32bit machine)
06:41:41 * quicksilver can't remember how many bits haskell Ints are
06:41:45 <matthew_-> 29
06:41:46 <quicksilver> > (maxBound :: Int)
06:41:47 <lambdabot>  2147483647
06:41:53 <fasta> Oh, right I am confused with maximum
06:41:54 <quicksilver> apparently not?
06:41:56 <matthew_-> > 2^28
06:41:57 <lambdabot>  268435456
06:42:01 <matthew_-> oh
06:42:13 <fasta> > maximum [1..1000000]
06:42:13 <quicksilver> I think it's permitted to reserve some bits for flagging and stuff
06:42:14 <lambdabot>  1000000
06:42:17 <vegai> dddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddiddddddddddddd
06:42:17 <yitz> > 2^31
06:42:19 <lambdabot>  2147483648
06:42:22 <desegnis> > maxBound - minBound :: Int
06:42:23 <lambdabot>  -1
06:42:24 <quicksilver> but ghc in fact does not choose to do so
06:42:28 <fasta> Odd, on my system that gives a stack overflow
06:42:38 <fasta> lambdabot must run with a larger stack
06:42:38 <quicksilver> fasta: compiled vs interpreted, I imagine
06:42:50 <quicksilver> fasta: lambdabot runs compiled with -O2, so it does strictness analysis
06:42:53 <fasta> quicksilver: you are right probably.
06:43:10 <desegnis> > fromIntegral (maxBound::Int) - minBound :: Integer -- bah
06:43:11 <lambdabot>   add an instance declaration for (Bounded Integer)
06:43:23 <desegnis> I hate me
06:43:34 <yitz> > fromIntegral (maxBound - minBound :: Int) == 2^32
06:43:35 <lambdabot>  False
06:43:37 <desegnis> > fromIntegral (maxBound::Int) - fromIntegral minBound :: Integer
06:43:38 <lambdabot>  Add a type signature
06:43:44 <yitz> > fromIntegral (maxBound - minBound :: Int)
06:43:45 <lambdabot>  -1
06:43:48 * vegai apologizes on the behalf of whoever did that.
06:43:52 <yitz> > fromIntegral (maxBound - minBound :: Int)  ::Integer
06:43:54 <lambdabot>  -1
06:44:02 <Itkovian> desegnis: well, we could join you in that
06:44:05 <Itkovian> :-)
06:44:18 <Itkovian> vegai: kid sitting on your lap?
06:44:26 <desegnis> what, in hating me?
06:44:37 <vincenz> Itkovian: alles goed??
06:44:44 <Itkovian> desegnis: we would not want to to feel all alone in such an undertaking
06:44:45 <yitz> > fromIntegral (maxBound::Int) - fromIntegral(minBound :: Int)  ::Integer
06:44:47 <lambdabot>  4294967295
06:44:48 <Itkovian> vincenz: yeps
06:45:01 <Itkovian> vincenz: well, I need to finish a presentation in 16 minutes :-)
06:45:02 <yitz> > (fromIntegral (maxBound::Int) - fromIntegral(minBound :: Int)  ::Integer)==2^32
06:45:04 <lambdabot>  False
06:45:05 <Itkovian> so I'm procrastinating
06:45:10 <yitz> > 2^32
06:45:12 <lambdabot>  4294967296
06:45:17 <yitz> > (fromIntegral (maxBound::Int) - fromIntegral(minBound :: Int)  ::Integer)==2^32-1
06:45:17 <desegnis> d'oh, of course
06:45:19 <lambdabot>  True
06:45:24 <vincenz> Itkovian: enjoy
06:46:26 <fasta> In Python you cannot even compute recursive length of a 1001 length list, so ghci doesn't do bad, anyway.
06:52:49 <vegai> Itkovian: ya...
06:59:28 <Saizan> ?hoogle Monad m => Bool -> (a -> m a) -> m a -> m a
06:59:32 <lambdabot> No matches, try a more general search
07:01:20 <quicksilver> Has anyone else ever wanted a 'total' variant of Data.Map?
07:01:28 <quicksilver> i.e. finite type of key
07:01:31 <quicksilver> and every key present
07:01:44 <quicksilver> clearly I could use an array, but hmm that just feels ugly
07:05:32 <matthew_-> quicksilver: it sounds like you want to use a record
07:05:36 <desegnis> I sometimes wished for an array the bounds of which are implicit in its type. That would probably be it
07:05:52 <EvilRanter> sounds like an array would be ideal, quicksilver.
07:06:39 <EvilRanter> maybe with wrapping it in something with a (Bounded i, Ix i) constraint and using the (minBound,maxBound) as bounds implicitly
07:08:46 <jedbrown> Is there a clean way to make an IntPairMap from Data.IntMap where Key = (Int, Int)?
07:08:51 <quicksilver> matthew_-: nah
07:09:01 <quicksilver> matthew_-: if I use a record, I can't lookup cleanly by type
07:09:08 <quicksilver> matthew_-: each field has a silly name I have to choose
07:09:39 <quicksilver> maybe a newtyped array is right
07:10:12 <quicksilver> I think you could even generate the Ix instance
07:10:19 <quicksilver> from the Enum + Bounded ones
07:10:25 <quicksilver> mind you, why bother, since Ix is derivable
07:11:33 <EvilRanter> jedbrown, no, not really
07:11:57 <EvilRanter> if you know your ints are going to be short enough, you could pack 'em into one Int with bitwise operations
07:12:17 <EvilRanter> you could do an IntMap of IntMaps, actually. that'd be simpler.
07:12:33 <EvilRanter> but I'd just use a normal Map
07:14:34 <jedbrown> As long as I'm on a 64-bit machine, they'll be short enough.  Thus I can pack with (\(i,j) -> i * N + j), but I don't know how to do that translation cleanly.
07:16:05 <malcolmw> fasta: if you are still wondering about cpp directives with newlines in, then the cpphs option to preserve whitespace is --layout
07:16:07 <jedbrown> The performance on IntMap is much better than general Map.  Also, I can do cheap ordered traversal with IntMap, but not with general Map.
07:18:03 <jedbrown> Is there a Judy Array implementation for Haskell?
07:19:21 <EvilRanter> i guess you could write a Data.Map.IMap instance to do that transparently
07:20:22 <fasta> malcolmw: The \\n option also works, right?
07:20:45 <fasta> malcolmw: I don't have the problem anymore, but would like to know anyway.
07:21:40 <glen_quagmire> :t Maybe
07:21:42 <lambdabot> Not in scope: data constructor `Maybe'
07:21:51 <fasta> :t Just
07:21:53 <lambdabot> forall a. a -> Maybe a
07:21:57 <fasta> :t Nothing
07:21:59 <lambdabot> forall a. Maybe a
07:22:29 <jedbrown> EvilRanter: How do I make it use the IntMap structure with `key preprocessing' to generate the packed Int?  I don't know how to do it without making wrappers for every function.
07:22:48 <EvilRanter> i think you'd have to make those wrappers, i'm afraid
07:23:19 <jedbrown> Talk about boilerplate.  There must be a better way.
07:23:23 <EvilRanter> it'd be theoretically possible to automate the process, i imagine, but would probably take longer than doing it manually, in practice
07:23:37 <malcolmw> fasta: \\n is what goes in the cpp directive, yes, but then you also need the --layout cmdline option to make sure the \n (unescaped) actualyl appears in teh output
07:23:52 <jedbrown> Sure, Emacs can do most of the work, but its still ugly.
07:24:11 <EvilRanter> wait, there isn't even an IMap... i must've been thinking of IArray.
07:24:15 <EvilRanter> that's even less helpful.
07:26:21 <fasta> jedbrown: what do you want to do?
07:26:24 <jedbrown> Whatever I do, I'd like it to work for triples and quads of Ints as well.  I guess the generic code would have Key = [Int].
07:26:51 <jedbrown> (multilevel) sparse arrays
07:27:41 <fasta> jedbrown: type families solve that problem, but nobody is an expert on those, since they don't work yet ;)
07:28:03 <jedbrown> aha
07:28:58 <fasta> jedbrown: but you should just use Data.Map or if you care for performance use Adrian Hey's Data.AVLTree.
07:29:06 <jedbrown> Maintaining the structure of the tuple would be nice since it would be useful for parallelizing the data structure.  Of course NDP is another thing that only sort of works now.
07:29:26 <jedbrown> What's AVLTree?
07:29:31 <quicksilver> jedbrown: what makes you think that you can't do cheap ordered traversal of Data.Map?
07:30:19 <fasta> And as always: only use a Map when you need Maplike features, otherwise just use STArray :)
07:30:39 <fasta> (for code that needs to run somewhat fast)
07:30:46 <jedbrown> quicksilver: not reading the documentation carefully.
07:30:56 <quicksilver> jedbrown: I would definitely use Data.Map to start with, until you identify specific performance characteristics it fails. It's decently fast in my experience.
07:31:11 <bens> I wrote up a .cabal file for it today and it works nicely. Just pass "-f split_base" to Setup.lhs configure for the new base and nothing for the old one.
07:31:25 <bens> oops, wrong channel... sorry
07:31:48 <fasta> bens: what channel is that?
07:32:31 <bens> a private one for a library I'm working on, #libmpd-haskell
07:32:39 <jedbrown> Another question: what's the best way to have multiple quantities in the same sparse array defined by a Map?
07:32:53 <quicksilver> jedbrown: I don't know what you mean?
07:33:05 <quicksilver> jedbrown: make the value type of the map a tuple or a disjunction, perhaps?
07:34:18 <jedbrown> The map defines a sparse grid of collocation points.  There may be several functions that are relevant on that grid.  They need to be multiplied pointwise or differentiated (which is achieved by  a wavelet transform which can also use the same data structure).
07:36:00 <quicksilver> jedbrown: the simplest approach is probably just a bunch of maps
07:36:15 <quicksilver> jedbrown: but you could have a single map which contained something more complex 'at each point'
07:36:29 <quicksilver> the "bunch of maps" approach allows the degree of sparseness to be different in each case...
07:38:15 <jedbrown> Yeah, I'm familiar with the tradeoff.  Multiplication is only cheap when they are on the same sparse grids.  Otherwise wavelet interpolation needs to be done first (which is still O(N), but not so fast).  And usually all the quantities need high resolution in the same physical space.
07:39:25 <jedbrown> Having a bunch of maps makes wavelet transforms of just one quantity simple, but pollutes the grid management code (iteratively adapting the grid to the solution).
07:39:38 * quicksilver nods
07:39:52 <quicksilver> well I think what I'm saying is "the Data.Map API exposes that tradeoff to you" :)
07:41:40 <jedbrown> Yeah, I'm just trying to find a way to shave the log(N) factor because all other aspects are O(N) where N is the total number of points on the mesh.
07:41:59 <jedbrown> And N may be 10^9.
07:42:04 <yitz> . 
07:42:21 <yitz> oops, sorry
07:43:24 <quicksilver> > log (10^9)
07:43:25 <lambdabot>  20.72326583694641
07:43:35 <quicksilver> jedbrown: 20 isn't a very big number :)
07:44:35 <jedbrown> True, but 20 is the reason for doing an adaptive algorithm in the first place.
07:45:56 <jedbrown> It doesn't matter at this point though, because I can use Data.Map now and switch to any other data structure with a similar API at a later time.
07:46:40 <EvilRanter> it's a shame there isn't an IMap class or anything
07:46:56 <EvilRanter> but i've played with such a concept, and it really doesn't work very well
07:47:14 <fasta> EvilRanter: you can say that for about every function.
07:47:27 <fasta> EvilRanter: no Reversable class etc.
07:47:41 <EvilRanter> well, yes, but we've already got two datatypes with very similar interfaces
07:48:24 <EvilRanter> it's on the edge of one-two-many already, so if anyone comes up with something else that fits the Map-esque interface well, it'd do to generalise, imo
07:51:25 <quicksilver> EvilRanter: I'd quite like a typeclass simply to overload (!) actually
07:51:37 <quicksilver> EvilRanter: after all, overloading was the reason typeclasses were invented...
07:51:39 <EvilRanter> yes, that'd be good
07:51:44 <quicksilver> "Map.lookup" is annoying to type
07:51:55 <EvilRanter> and Map.! makes my eyes bleed
07:52:14 <quicksilver> but this goes back to my earlier comment about total maps
07:52:19 <quicksilver> (!) is only total on total maps
07:52:33 <quicksilver> and (!) with a Maybe type is ugly :)
07:52:39 <EvilRanter> class Lookup m k v where (!) :: m -> k -> v; (?) :: m -> k -> Maybe v --?
07:52:56 <quicksilver> yes, somethign like that
07:53:04 <quicksilver> m -> k, m -> v probably
07:53:16 <EvilRanter> what?
07:53:20 <quicksilver> fundeps
07:53:29 <EvilRanter> ah, yes, quite. thought that was a type there.
07:53:32 <quicksilver> ;)
07:53:44 <quicksilver> if you want to be really celver and minimal you could do m,k -> v
07:53:50 <quicksilver> but I think that's probably too clever
07:54:05 <quicksilver> (allows different (!) to be used based on key type)
07:54:27 <EvilRanter> well, m encodes the key type already
07:54:35 <quicksilver> it might not
07:54:54 <quicksilver> how about type MegaMap = (Map Int String, Map String Bool)
07:55:07 <EvilRanter> yeah, that's too clever.
07:55:10 <EvilRanter> ;)
07:55:10 <quicksilver> I can instance that so that you can ! with an Int to get a string, but ! with a string to get a bool
07:55:14 <quicksilver> but, I don't recommend it :)
07:55:34 <quicksilver> interestingly you could make functions instances of Lookup
07:55:51 <quicksilver> and you could probably make any lookup an instance of Arrow
07:56:38 <EvilRanter> it's starting to sound like Arrow without arr
07:56:53 <EvilRanter> well, not really
07:57:08 <EvilRanter> anyway. i have to go for a lecture.
07:57:10 <quicksilver> sort-of, except it's a class not a type
07:57:11 <quicksilver> but yes
07:57:27 <quicksilver> have a nice lecture :)
08:11:52 <Plouj> hi
08:12:13 <Plouj> is this universally true about all haskell programs: http://www.haskell.org/haskellwiki/Introduction#No_core_dumps ? They really don't cause segmentation faults?
08:12:14 <lambdabot> Title: Introduction - HaskellWiki
08:13:04 <Igloo> FSVO "Haskell programs", yes
08:14:00 <Igloo> If you start poking raw memory yourself with the Foreign.* stuff, for example, then you can still cause segfaults
08:18:10 <Plouj> is haskell a language that I should be studying if I want to be able to write programs that will scale to multiple processors?
08:18:28 <Philippa> yes. Even if you don't use the language, you'll learn things that help - most importantly stateless programming
08:19:23 <Plouj> humm, I've been hearing "stateless" a lot, although I don't see how it can be good or why it helps with parallelalizm
08:19:30 <Plouj> s/good/better/
08:20:21 <thepointer_> if you dont have state, i'd imagine you couldnt have syncronization issues
08:20:22 <fasta> Plouj: it makes program analysis easier, but I haven't seen proof of that.
08:20:22 <pejo> Shared state causes trouble with synchronization.
08:20:35 <integral> writing to the same memory location at the same time is a big problem
08:20:47 <thepointer_> i actually had a lecture today about parallel programming with haskell
08:21:17 <Plouj> humm
08:21:37 <Plouj> help me understand stateless programming (and it's opposite) given that I know how turing machines work
08:21:54 <Plouj> I mean how finite state automatons work
08:22:24 <Olathe> Addition is stateless.
08:22:32 <fasta> Plouj: Basically your program becomes a function from a tuple to a tuple
08:22:56 <Saizan> you can't rewrite on the same cells of the tape :)
08:23:00 <Plouj> fasta: without "static" variables? :)
08:23:00 <fasta> Plouj: if you have read Knuth, that's how he starts with defining an algorithm.
08:23:11 <fasta> Plouj: static as in C?
08:23:14 <Plouj> fasta: yes
08:23:26 <fasta> Plouj: certainly without those, yes.
08:23:39 <fasta> Plouj: but you can fake those
08:23:51 <Plouj> wouldn't that break the statelessness?
08:24:14 <fasta> Plouj: it depends on how you define "state".
08:24:29 <fasta> Plouj: referential transparancy is used
08:24:46 <fasta> Plouj: so, you can fake it while still having referential transparancy.
08:25:36 * fasta notices that this isn't a smart way to explain something
08:25:45 <Olathe> Stateless isn't about how machines work, since they always use state. It's a way of thinking about programming where the results are already computed and there is no intermediateness.
08:26:21 <fasta> Plouj: Have you read Vol 1 of TAOCP?
08:26:31 <Olathe> For instance, you can think about how a circuit adds two numbers over time, or you can think that 1 + 2 is 3 without thinking it needs to be computed.
08:26:40 <Philippa> fasta: there's an awful lot of side-conditions you can skip in an analysis if you don't have to worry about state. Believe me, this makes life easier when you sit down to do it
08:27:23 <Philippa> if you've not seen evidence, it's because you've not seen someone sit down and bash out the necessary reasoning
08:27:38 <fasta> Philippa: right, I haven't.
08:28:16 <fasta> Philippa: the only convincing way would be to see the algorithms for both approaches.
08:28:17 <ricky_clarkson> I suppose it's not as rigorous as you might like, but when sicp introduces set! that explains it quite well imo.
08:29:16 <pejo> fasta, compare http://www.blassen.dk/soren/papers/2005lics.pdf with http://www.blassen.dk/soren/papers/2007popl.pdf. I'd say the first is much simpler.
08:29:22 <Olathe> With state, you have to pay attention to *when* something is happening in your analysis. Without it, time is irrelevant, which simplifies things.
08:31:07 <phlpp> hm, is there a formular, when given a positive integer n, that produces n times the number 1? e.g. f 5 = 11111?
08:31:14 <fasta> Naively, it would seem that you could compile C to a Haskell DSL. I.e. the same problems would still need to be solved.
08:31:17 <Philippa> fasta: with the stateful approach you have to do all the reasoning for the stateless one and a bunch of side-checks as well - and in the limit, the side-checks require hard proofs
08:31:27 <roconnor> > replicate 5 '1'
08:31:29 <lambdabot>  "11111"
08:31:31 <fasta> And it seems those problems are not in the DSL.
08:31:38 <phlpp> roconnor, cool, thanks :)
08:31:45 <Philippa> they're not in the DSL: they're in the compilation
08:31:58 <Olathe> phlpp: f 0 = 0; f a = 10^a + (f (a - 1))
08:32:04 <Olathe> > let f 0 = 0; f a = 10^a + (f (a - 1)) in f 5
08:32:05 <lambdabot>  111110
08:32:08 <fasta> Philippa: yes, I meant the compilation to the dsl
08:32:10 <Olathe> Not quite :(
08:32:16 <Olathe> > let f 0 = 0; f 1 = 1; f a = 10^a + (f (a - 1)) in f 5
08:32:18 <lambdabot>  111101
08:32:19 <roconnor> > replicate 5 True
08:32:20 <lambdabot>  [True,True,True,True,True]
08:32:20 <Olathe> Bah.
08:32:49 <roconnor> > let f 0 = 0; f a = 10^(a-1) + (f (a - 1)) in f 5
08:32:50 <lambdabot>  11111
08:32:56 <Olathe> Yay !
08:33:21 <Philippa> by which I mean: the compilation has to do much of the hard work involved. And cutting unnecessary dependencies introduced in the C code is no easier in the haskell, because they're that entangled - it's just easier to spot that they're unnecessary in pure code because it's easier to write stuff that's not so entangled in the first place
08:33:26 <Philippa> to put it another way, the C overspecifies
08:33:49 <roconnor> @hoogle reset
08:33:49 <lambdabot> Text.Html.reset :: String -> String -> Html
08:33:49 <lambdabot> Text.ParserCombinators.ReadPrec.reset :: ReadPrec a -> ReadPrec a
08:33:49 <lambdabot> Foreign.C.Error.resetErrno :: IO ()
08:33:58 <roconnor> @hoogle shift
08:33:58 <lambdabot> Data.Bits.shift :: Bits a => a -> Int -> a
08:33:58 <lambdabot> Data.Bits.shiftL :: Bits a => a -> Int -> a
08:33:58 <lambdabot> Data.Bits.shiftR :: Bits a => a -> Int -> a
08:34:17 <Choko_> is there a method like trace in scheme for haskell ?
08:34:41 <ndm> @hoogle trace
08:34:41 <lambdabot> Debug.Trace.trace :: String -> a -> a
08:34:41 <lambdabot> Debug.Trace :: module
08:34:41 <lambdabot> Debug.Trace.putTraceMsg :: String -> IO ()
08:34:44 <ndm> Choko_: yes
08:34:45 <Olathe> > let f 0 = 0; f n = 10*(f (n - 1)) + 1 in f 5
08:34:47 <lambdabot>  11111
08:34:48 <Choko_> thanks
08:34:59 <fasta> Choko_: not something that does the exact same thing, unless you use e.g. Hat
08:35:01 <Olathe> More efficient, I'd bet.
08:35:17 <fberthold> Greetings all.
08:35:58 <Plouj> fasta: I have not read TAOCP
08:36:00 <roconnor> @hoogle trace
08:36:00 <lambdabot> Debug.Trace.trace :: String -> a -> a
08:36:00 <lambdabot> Debug.Trace :: module
08:36:00 <lambdabot> Debug.Trace.putTraceMsg :: String -> IO ()
08:36:11 <roconnor> I'm slow
08:36:57 <fasta> Plouj: ok, well, Knuth basically defines algorithms as applying rules that go from list of tuples to another list of tuples.
08:37:20 <fasta> Plouj: the rules are functions in Haskell
08:38:08 <fasta> s/list of tuples/tuple
08:38:30 <geocalc> > replicate 4 [0..3]
08:38:31 <lambdabot>  [[0,1,2,3],[0,1,2,3],[0,1,2,3],[0,1,2,3]]
08:39:25 <Olathe> > let ones = 1 : [ 10*a + 1 | a <- ones] in ones
08:39:26 <lambdabot>  [1,11,111,1111,11111,111111,1111111,11111111,111111111,1111111111,1111111111...
08:40:06 <MyCatVerbs> > tails ones
08:40:07 <lambdabot>   Not in scope: `ones'
08:40:13 <MyCatVerbs> Oh, oops.
08:40:25 * roconnor 's head explodes
08:40:35 <roconnor> ahhh delimited continuations.
08:40:49 <Olathe> > let ones = 1:map ((1+).(10*)) ones in ones
08:40:50 <lambdabot>  [1,11,111,1111,11111,111111,1111111,11111111,111111111,1111111111,1111111111...
08:40:57 <Olathe> @let ones = 1:map ((1+).(10*)) ones in ones
08:40:57 <lambdabot>  Parse error
08:41:01 <Olathe> @let ones 1:map ((1+).(10*)) ones in ones
08:41:01 <lambdabot>  Parse error
08:41:04 <Olathe> Bah
08:41:19 <Olathe> @let ones = 1:map ((1+).(10*)) ones
08:41:22 <lambdabot> Defined.
08:41:23 <Olathe> > tails ones
08:41:25 <lambdabot>  [[1,11,111,1111,11111,111111,1111111,11111111,111111111,1111111111,111111111...
08:41:44 <fasta> Can I test for undefinedness (yes, I know this is a bad idea, but still I want to do it)?
08:42:05 <yrlnry> You can't test for undefinedness.
08:42:10 <Philippa> no, you can't match against _|_
08:42:13 <yrlnry> That's called the "halting problem".
08:42:24 <yrlnry> it's a famous example of a problem for which there is no solution.
08:42:31 <MyCatVerbs> fasta: nearest I know of is that you can catch the exception thrown when something is declared as undefined.
08:42:43 <fasta> MyCatVerbs: that's of course what I mean.
08:42:45 <Philippa> conceptually, seq x is case x of {_|_ -> _|_; foo -> foo;} though
08:42:46 <ricky_clarkson> > [1..]==[1..]
08:42:49 <lambdabot> Terminated
08:42:53 <yrlnry> Oh, sorry.  I wasn't being deliberately obtuse.
08:42:54 <MyCatVerbs> fasta: but no, finding "foo = foo" isn't going to be possible. :)
08:43:14 <Philippa> er, seq x y is case x of {_|_ -> _|_; _ -> y} even
08:43:30 <pejo> Philippa, it doesn't test though, it just evaluates the thing.
08:43:44 <Philippa> pejo: sure. I say 'conceptually' for a reason :-)
08:43:48 <MyCatVerbs> pejo: yes, that's why she prefixed it with "conceptually" :P
08:43:55 <fasta> In the IO monad I can catch the exception, but I am in ST>
08:44:04 <ricky_clarkson> Can you actually explicitly write _|_ in Haskell somehow?
08:44:04 <Philippa> OTOH, if evaluation throws an exception then you can catch that. Good as you'll get.
08:44:09 <phlpp> is tehre some big num (integer) data type?
08:44:11 <phlpp> *there*
08:44:17 <Olathe> phlpp: Yes, Integer.
08:44:22 <phlpp> hm.
08:44:26 <fasta> > 111111111111111111111111111111*11111111111111111111111
08:44:27 <lambdabot>  1234567901234567901234555555554320987654320987654321
08:44:30 <Philippa> ricky_clarkson: depends what you mean by _|_. You can use undefined, but there's no constructor
08:44:31 <yrlnry> Yay.
08:44:45 <ricky_clarkson> > length $ show $ foldl (*) 2 [3..1000]
08:44:47 <lambdabot>  2568
08:44:56 <ricky_clarkson> 2568 digits in that number.
08:45:08 <Olathe> > 2^129 + 3
08:45:10 <lambdabot>  680564733841876926926749214863536422915
08:45:11 <Spark> > foldl (*) 2 [3..1000]
08:45:12 <lambdabot>  4023872600770937735437024339230039857193748642107146325437999104299385123986...
08:45:29 <Philippa> pejo: the evaluation thing means that in the presence of exceptions it's closer to seq x y = case x of {e@_|_ -> e; _ -> y} even
08:46:50 <phlpp> hm
08:46:56 <phlpp> Repunit> r (10^6)
08:46:57 <phlpp> ERROR - C stack overflow
08:47:03 <phlpp> r :: Int -> Integer
08:47:04 <phlpp> r k = read $ replicate k '1'
08:47:24 <geocalc> > 1 / (((256^3)^100)^10)
08:47:26 <lambdabot>  0.0
08:47:27 <phlpp> why stack overflow? replicate (10^6) 1 works fine
08:47:49 <Olathe> What's Repunit ?
08:48:01 <phlpp> my module
08:48:34 <phlpp> R(6) is a repunit of length 6 = 111111
08:48:48 <geocalc> > ((256^3)^100)^10
08:48:49 <lambdabot>  5246817223921887906185668778333620824017561523482713174518959107440494451845...
08:49:10 <chessguy> > (10^6) :: Int
08:49:11 <lambdabot>  1000000
08:49:13 <pa-ching> Hmm, how can I do the equivalent of "(a, b, c) = take 3 someList" neatly?
08:49:13 <Olathe> phlpp: Make it easier for the compiler to tell it's tail recursive.
08:49:22 <Olathe> phlpp: What is the definition of r ?
08:49:31 <Lemmih> pa-ching: let [a, b, c] = take 3 someList
08:49:33 <phlpp> r k = read $ replicate k '1'
08:49:43 <pa-ching> Lemmih: Ah, thanks :)
08:49:55 <pa-ching> so it *does* work like that
08:50:09 <Olathe> > read $ replicate 5 '1'
08:50:10 <lambdabot>  11111
08:50:11 <phlpp> > 256^113
08:50:13 <lambdabot>  1352433999707303030661989849386282512688249154652471096647579415108285190545...
08:50:14 <Lemmih> pa-ching: Note that it will fail if 'someList' has less than three members.
08:50:19 <Olathe> @src replicate
08:50:20 <lambdabot> replicate n x = take n (repeat x)
08:50:21 <phlpp> > 256^3000
08:50:23 <lambdabot>  5246817223921887906185668778333620824017561523482713174518959107440494451845...
08:50:31 <Olathe> @src take
08:50:32 <lambdabot> take n _      | n <= 0 =  []
08:50:32 <lambdabot> take _ []              =  []
08:50:32 <lambdabot> take n (x:xs)          =  x : take (n-1) xs
08:50:59 <phlpp> hm
08:51:05 <Lemmih> phlpp: It's most likely the 'read' that fails.
08:51:09 <phlpp> yeah
08:51:12 <phlpp> think so, too
08:51:14 <pa-ching> Lemmih: yeah, I should hope so hehe.
08:51:22 <Olathe> @src read
08:51:22 <lambdabot> read s = either error id (readEither s)
08:51:30 <pa-ching> Lemmih: I guess I was just worried that the types would complain in the list case or something
08:51:32 <Olathe> @src readEither
08:51:32 <lambdabot> Source not found. I am sorry.
08:51:36 <chessguy> > let [a, b, c] = take 3 [] in [a,b,c]
08:51:37 <lambdabot>   Irrefutable pattern failed for pattern [a, b, c]
08:52:06 <Olathe> @pl \(a:b:c:xs) -> (a, b, c)
08:52:07 <lambdabot> ap ((`ap` tail) . (. head) . flip flip tail . (ap .) . flip flip head . (((.) . (const .)) .) . (,,) . head) tail
08:52:29 <dylan> that's beautiful. XD
08:52:53 <phlpp> the question is, no matter how we fix this read issue now: is it possible to work with this number by doing some modulo stuff?
08:52:57 <Olathe> > let f (a:b:xs) = (a, b, head xs) in f [1, 2, 3, 4, 5, 6]
08:52:59 <lambdabot>  (1,2,3)
08:53:01 <phlpp> in a acceptable amount of time
08:53:14 <Olathe> > let f (a:b:c:xs) = (a, b, c) in f [1, 2, 3, 4, 5, 6]
08:53:15 <lambdabot>  (1,2,3)
08:53:17 <phlpp> i mean, a number with 10^6 digits where all digits are 1
08:53:20 <Olathe> Quite readable.
08:54:13 <ricky_clarkson> phlpp: What would you like to do with this number?
08:55:19 <phlpp> ricky_clarkson, some modulo divisions by a number n. the problem is, i have to find that number 'n' ;)
08:55:34 <fberthold> Does anyone have any suggestions for how to use parsec to parse the following, "1aabhd2aad3ab" into [("1", "aabhd"), ("2", "aad"), ("3", "ab")]
08:55:36 <phlpp> so: r 10^6 mod n = 0
08:55:37 <geocalc> > replicate (10^6) 1
08:55:39 <lambdabot>  [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1...
08:55:54 <Olathe> > let r = r' 0; r' x 0 = x; r' x n = r' (10*x+1) (n-1) in r (10^6)
08:55:58 <lambdabot> Terminated
08:56:01 <Olathe> :(
08:56:06 <phlpp> and i'm looking for the least value n
08:56:15 <fberthold> My main problem is telling it to consume undifferentiated text until the start of a new section.
08:56:38 <fberthold> (The example given is a grossly simplified version of parsing a spec document)
08:56:43 <Olathe> > let r = r' 0; r' x 0 = x; r' !x !n = r' (10*x+1) (n-1) in r (10^6)
08:56:43 <lambdabot>  Parse error in pattern
08:56:45 <Olathe> Bah.
08:56:56 <jonafan> over the last few days, i've seen a few people refer to ruby as a functional language, or a language that nods to functional programming... why?  there's nothing functional about ruby
08:57:02 <geocalc> > replicate (10^6) '1'
08:57:04 <lambdabot>  "111111111111111111111111111111111111111111111111111111111111111111111111111...
08:57:16 <Olathe> jonafan: They have lambdas and things like map.
08:57:26 <Olathe> Though they are a bit messy.
08:57:30 <jonafan> that's no big deal
08:57:44 <yrlnry> jonafan: It depends a lot on what you mean by "functional", I suppose,  These terms tend to have different meanings for different people.
08:57:57 <dylan> ruby also has callcc
08:58:01 <Olathe> So, you can program in functional style if you'd like.
08:58:02 <chessguy> do they have functions as first-class objects?
08:58:03 <ricky_clarkson> It's a language that you can pass functions around as values in.
08:58:06 <yrlnry> jonafan: Like "strongly-typed".  There's widespread disagreement about whether or not C is "strongly-typed"< for example.
08:58:12 <yrlnry> chessguy: they do.
08:58:18 <jonafan> c is weakly typed
08:58:20 <dylan> chessguy: it has three types of functions, 2 of which are first-class...
08:58:20 <phlpp> Olathe, maybe i have to find sth. out about 10^6 times '1', so that i can use some 'division rules' on that number
08:58:26 <jonafan> weak static typing
08:58:30 <chessguy> to me, that's a functional language then
08:58:31 <yrlnry> jonafan: so you say, but my point is that a lot of people assert the opposite.
08:58:31 <phlpp> so i don't have to calc with 10^6 times 1
08:58:37 <ricky_clarkson> Static typing.  Weak or strong are bull.
08:58:46 <jonafan> to me, functional means an emphasis on immutable data and there's a semantical difference in how if statements are used
08:58:48 <yrlnry> jonafan: that doesn'[t mean that you're wrong, or that they're wrong; it just means that there is disagreement about the meaning of the term.
08:58:58 <ricky_clarkson> See http://cdsmith.twu.net/types.html
08:58:59 <lambdabot> Title: What To Know Before Debating Type Systems
08:59:02 <Olathe> > ones !! (10^6)
08:59:05 <lambdabot>  Exception: stack overflow
08:59:10 <jonafan> in functional languages, if statements are like functions that return values
08:59:20 <Olathe> Don't use !! with large arguments, I guess.
08:59:20 <dylan> jonafan: ruby if statements are expressions
08:59:23 <dons> C's clearly not strongly typed :)
08:59:33 <ricky_clarkson> jonafan: C has an expression if. ? :
08:59:36 <dons> you can crash a well typed program due to a type error
08:59:38 <phlpp> Olathe, ok, i have to go now. maybe we'll discuse later on this? ;)
08:59:59 <dons> i've a theory that its only a functional language if it supports &&& and |||
09:00:01 <Olathe> phlpp: OK.
09:00:03 <jonafan> can you use an if statement in the middle of another statement?
09:00:05 <dons> and the (-> a) monad
09:00:13 <Igloo> dons: So what makes head [] not a type error?
09:00:13 <Olathe> @src (&&&)
09:00:14 <lambdabot> f &&& g = arr (\b -> (b,b)) >>> f *** g
09:00:14 <jonafan> like
09:00:20 <yrlnry> I've heard Perl experts seriously claim that Perl was "strongly-typed".  They did in fact mean something by it, although it wasn't anything like what I might have meant.
09:00:35 <Olathe> What do &&& and ||| do ?
09:00:40 <dons> Igloo: the semantics of head is well defined.
09:00:41 <jonafan> functioncall(if (x==y) then y else x);
09:00:42 <dons> like / 0
09:00:48 <jonafan> sorry, i don't know ruby or haskell!!!
09:00:58 <dons> Igloo: its not total, typed programming, just well typed.
09:01:03 <Olathe> jonafan: Yes, you can.
09:01:11 <jonafan> no way!
09:01:12 <dons> well typed programs should not go wrong. while C programs can happily go wrong despite being well typed
09:01:15 <chessguy>  I give the following general definitions for strong and weak typing, at least when used as absolutes:
09:01:15 <chessguy>     * Strong typing: A type system that I like and feel comfortable with
09:01:15 <chessguy>     * Weak typing: A type system that worries me, or makes me feel uncomfortable
09:01:17 <chessguy> heh
09:01:18 <dons> and end up in unpredictable states
09:01:18 <dylan> jonafan: that is almost valid ruby.
09:01:22 <chessguy> that's cute
09:01:27 * dylan personally hates ruby, but anyway...
09:01:38 <dons> until ruby wins the icfp contest, we can't take it seriously
09:01:42 <jonafan> i looked at a tutorial, and if statements looked like c if statements
09:01:46 <Olathe> dons: Heheh
09:01:48 <dons> or any dynamic language actually ..
09:01:51 <yrlnry> show 23
09:01:56 <chessguy> who won icfp this year, anyway?
09:02:00 <Igloo> dons: You could define semantics for dereferencing NULL etc
09:02:02 <chessguy> err, what language
09:02:04 <dons> google
09:02:31 <chessguy> what language did they use?
09:02:46 <dons> Igloo: so there's no progress theorem for C's type system, right? valid expressions have undefined semantics, and a cast can subvert safety at any point
09:02:49 <fberthold> Is anyone aware of a combinator in parsec that is equivalent to the character parser "noneOf"
09:02:51 <dons> so that's clearly weakly typed
09:03:19 <Olathe> > (length &&& head) [1, 2, 3]
09:03:20 <lambdabot>  (3,1)
09:03:30 <dons> true support for functions, eh Olathe ? :)
09:03:51 * Igloo isn't sure about progress theorems for C's type system
09:03:54 <Philippa> fberthold: no, and there can't be one - think about it, how much should it consume?
09:04:05 <Igloo> maxBound + 1 :: Int has undefined semantics in Haskell, though
09:04:05 <Philippa> oh, wait, yeah, there should be one for general tokens
09:04:11 <Olathe> tand = proc { |a, b| proc { |x| [a[x], b[x]] } }
09:04:16 <chessguy> > (length &&& head &&& (+1)) [1, 2, 3]
09:04:16 <lambdabot>   add an instance declaration for (Num [a])
09:04:25 <chessguy> err, whoops
09:04:27 <Olathe> That would do it on Ruby.
09:04:39 <chessguy> > (length &&& head &&& ((+1).head)) [1, 2, 3]
09:04:40 <ricky_clarkson> dons: Doesn't unsafePerformIO cause an equivalent complaint to yours about casting?
09:04:40 <lambdabot>  (3,(1,2))
09:04:45 <dons> so my rule for functional languages is: composition must be the shortest operator, and there must be support for splitting and building pipes of composed functions
09:04:54 <osfameron> splitting!
09:04:58 <dons> ricky_clarkson: right, (that's an FFI extension to interface with C)
09:05:25 <Olathe> length = proc { |a| a.size }; head = proc { |a| a.first }; tand = proc { |a, b| proc { |x| [a[x], b[x]] } }; tand[length, head][[1, 2, 3]] #=> [3, 1]
09:05:30 <dons> unsafePerformIO is fairly hamrless though
09:05:38 <dons> unsafeCoerce# is the real C devil
09:05:45 <fberthold> Phillipa: I think I see what you mean for the general problem.... I think the problem I'm dealing with can be solved by writing a scanner, but I haven't been able to find any clear instructions for how to do so.
09:06:03 <dons> so many ugly lambdas :)
09:06:05 <quicksilver> yeah, n-ary &&& would be nice
09:06:08 <Olathe> dons: Yeah :)
09:06:21 <quicksilver> I'm not sure our type-system is strong enough for n-ary &&&
09:06:26 <Olathe> It can do it, but it's not idiomatic or anything.
09:06:28 <quicksilver> maybe it is with the right MPTC
09:06:35 <dons> quicksilver: i think that sounds like an oleg challenge :)
09:06:44 <chessguy> oh no!
09:06:45 <dons> s/strong/rich/
09:06:45 <chessguy> C++ is the programming language of choice for
09:06:45 <chessguy> discriminating hackers.
09:06:58 <dylan> NOO!!
09:07:01 <quicksilver> unsafePerformIO is equivalent to unsafeCoerce
09:07:13 <quicksilver> but only because of IORefs and similar features
09:07:14 <chessguy> :(
09:07:20 <dylan> C++ won!?
09:07:40 <chessguy> apparently so
09:07:53 <quicksilver> I don't think unsafePerformIO is equivalent to unsafePtrEquality though
09:08:02 <quicksilver> well, C++ didn't win. Google did.
09:08:08 <quicksilver> They just happened to use C++...
09:08:11 <dons> interesting, http://lucille.atso-net.jp/blog/?p=354
09:08:12 <Mr_Awesome> its not like the language entered the contest
09:08:13 <lambdabot> Title: lucille development blog  Blog Archive  Work in progress: Initial Haskell vers ...
09:08:16 <fberthold> Phillipa: For the example above, something that will first go through and creat tokens [Title "1", Text "abaad", Title "2", Text "acca"]
09:09:10 <desp> @pl getNChars n = liftM (replicate n) getChar
09:09:10 <lambdabot> getNChars = flip fmap getChar . replicate
09:09:12 <chessguy> Mr_Awesome, yet we had no problem saying that haskell was the language of choice for several years :)
09:09:28 <desp> @hoogle fmap
09:09:29 <lambdabot> Prelude.fmap :: Functor f => (a -> b) -> f a -> f b
09:09:29 <lambdabot> Data.FunctorM.fmapM :: (FunctorM f, Monad m) => (a -> m b) -> f a -> m (f b)
09:09:29 <lambdabot> Data.FunctorM.fmapM_ :: (FunctorM f, Monad m) => (a -> m b) -> f a -> m ()
09:09:30 <dons> its ok, if the C++ guys didn't win it occasionally, it'd look rigged
09:09:38 <Olathe> Heheh
09:10:07 <dons> however, why python, perl, ruby and erlang don't do well is very curious to me
09:10:17 <osfameron> Perl team came 2nd, no?
09:10:26 <quicksilver> dons: well this year the contest was very CPU-centric
09:10:34 <quicksilver> dons: not a good year for slow interpreted languages
09:10:35 <dons> yes, that's the best result ever for that class of languages
09:10:39 <chessguy> As far as functional programming is concerned, we must
09:10:39 <chessguy> conclude that functional languages didnt fare too well this
09:10:39 <chessguy> year (although in the Top 15 there were five users of OCaml
09:10:39 <chessguy> and three of Haskell).
09:10:41 <dons> quicksilver: but in general, they never do well
09:10:44 <chessguy> that makes no sense to me
09:10:50 <dons> chessguy: indeed
09:10:56 <chessguy> half of the top 15 were functional languages, but FP didn't do well?
09:11:00 <dons> we must conclude that dynamic interpreted languages did very poorly
09:11:03 <dons> again
09:11:12 <quicksilver> chessguy: well it is the IC *F* P contents :)
09:11:15 <quicksilver> chessguy: contest
09:11:16 <dons> chessguy: i'm inclined to rebut this fud about fp doing badly again.
09:11:39 <chessguy> dons, i'd say it deserves a blog entry :)
09:11:42 <dons> two losses in 7 years :)
09:12:02 <dons> so if we're only 75% more likely to win thn C++, I can live with that
09:12:26 <dylan> hrm, I am having problems finding (pseudo-code?) for the actor model.
09:12:29 <chessguy> and our language is still improving. c++ can hardly even say that
09:12:38 <dylan> I understand semantics well enough, I think, but I'd like some syntax.
09:12:42 <Mr_Awesome> just think how well the winners could have done if they had used haskell instead of C++
09:12:47 <dons> heh
09:12:57 <dons> well, i think those guys might win it even in ruby
09:13:06 <dons> ok, maybe ot
09:13:15 <geocalc> hehe
09:13:21 <Olathe> Ruby is very slow for this sort of thing.
09:13:34 <Olathe> I tried using it for the 2006 contest and it was insanely slow.
09:13:42 <Philippa_> Mr_Awesome: there were technical reasons Haskell didn't generally do too well this year
09:13:45 <dylan> anyone happen to have some examples of the actor model laying around? XD
09:13:49 <quicksilver> dons: but, I agree it's suprising the dynamic languages didn't do better in, e.g., that parcel-delivering one a few years ago
09:13:55 <Mr_Awesome> Philippa_: i know. im only kidding
09:14:01 <dons> Philippa_: oh? 3/15 and hmm, 8/30 seems pretty good?
09:14:18 <quicksilver> dons: that wasn't CPU intensive and message passing and stuff made a sensible implementation
09:14:19 <kscaldef> dons: I'm not sure how much interest there is in the contest in those communities
09:14:20 <dons> quicksilver: or the maze searcher/refactoring one. oh hang on, refactoring...
09:14:22 <quicksilver> or the ants one, perhaps
09:14:32 <quicksilver> refactoring not so much, perhaps :)
09:14:37 <dons> kscaldef: there's typically more perl and python entries than haskell (at least in past years)
09:14:47 <dons> maybe not the good perl programmers though
09:15:03 <Philippa_> dons: general vs specific :-) You had to think a bit not to pick the wrong structure by default
09:15:04 <kscaldef> dons: interesting... I never hear anyone I know in the perl community talking about the contest
09:15:48 <osfameron> kscaldef: acme was trying to get a group together on #london.pm, but I think noone had time (I certainly didn't)
09:16:26 <Philippa_> I suspect the good perl programmers use another language most of the time on grounds of efficiency - fast tools really do matter
09:16:28 <kscaldef> maybe next year I'll see if pdx.pm wants to give it a shot
09:16:42 <quicksilver> dons: I strongly suspect that 'recreational programmers' are not a representative subset of programmers as a whole
09:16:49 <yrlnry> Philippa_: My guess is that you are mistaken.
09:17:12 <quicksilver> dons: and the ICFP is clearly recreational; so this biases the language choices
09:17:12 <yrlnry> Philippa_: Based only on my experience with a large number of very good Perl programmers.
09:17:20 <Philippa_> yrlnry: I'm talking specifically about ICFP here
09:17:22 <quicksilver> Philippa_: Perl is pretty fast if you know how to use it
09:17:24 <kscaldef> Philippa_: when they do, that other language tends to be XS extensions to Perl, written in C
09:17:31 <yrlnry> Philippa_: Could be.
09:17:40 <quicksilver> Philippa_: that is, if you know which bits are fast and which bits aren't
09:18:07 <Philippa_> quicksilver: *nod*. If you want really damn fast you're still at risk of the problem just not fitting the limitations though
09:18:26 <quicksilver> true
09:18:40 <quicksilver> but, e.g., perl hashes are faster than C++ map<>
09:18:51 <quicksilver> and certainly faster than anything a C coder is likely to write...
09:18:58 <hellblade> hello peeps. is it possible to increase the value of a variable inside a function? I mean e.g. take ("text",3) and make it ("text",4) without having to use it like myTuple = increase myTuple
09:19:11 <Philippa_> yeah. But then not all problems want a hash
09:19:11 <quicksilver> hellblade: the short answer is "no"
09:19:16 <quicksilver> Philippa_: shame :(
09:19:18 <hellblade> oh ok
09:19:27 <quicksilver> hellblade: the longer answer is, you don't really need to do that :)
09:19:27 <Philippa_> obvious dumb question: how easy is it to yank the perl hash code to use in another language?
09:19:40 <kscaldef> Philippa_: probably hard.
09:19:58 <kscaldef> perl generally wasn't written with that type of reuse in mind
09:20:04 <quicksilver> hellblade: one of the nice things about haskell is that values (note I avoid the word 'variable') don't vary
09:20:08 <kscaldef> maybe in Perl 6 it'll be easier
09:20:18 <quicksilver> hellblade: this has nice consequences for robust programming and in some cases memory sharing
09:20:20 <mrd> > (second (+1)) ("txt",3)
09:20:25 <lambdabot>  ("txt",4)
09:20:38 <quicksilver> hellblade: on the other hand, it takes a little getting used to if you've always used languages with assignment before
09:21:34 <jonafan> hey i just started reading this "What To Know Before Debating Type Systems" thing
09:21:56 <kscaldef> jonafan: link?
09:22:01 <jonafan> http://cdsmith.twu.net/types.html
09:22:02 <lambdabot> Title: What To Know Before Debating Type Systems
09:22:17 <hellblade> I am not sure what this definition of an exercise means "Define a function win which given a team records that they have won a game. Think carefully about what this entails." where a Team is (String,Int,Int,Int) and the wins is the second Int
09:22:26 <jonafan> i thought (and still think) weak typing meant if you tell the language you're dealing with a certain type, it will believe you
09:22:30 <jonafan> damn the consequences
09:22:42 <jonafan> where a strong typing language knows if you're wrong
09:23:04 <alexj> is there a substantial commuity of Windows devs here?  thinking about happs functionality that won't work well on windows because it doesn't have System. stuff
09:23:21 <jonafan> if you try to cast an int as a LinkedList in java, it will throw an exception because it knows you're wrong
09:23:31 <jonafan> therefore java is strongly typed
09:23:43 <jonafan> if you do the same sort of thing in c or c++, it will believe you, and then crazy things will occur
09:24:06 <quicksilver> c++ has multiple kinds of casts
09:24:15 <quicksilver> some are checked at compile time, some at runtime, and some not at all
09:24:18 <pejo> jonafan, what weak and strong typing "means" is ambigious, and context dependent. People in #haskell might have the same view, but it will probably differ from the people in #C.
09:24:31 <quicksilver> so c++ can be as "cast-safe as Java" if you choose the right cast
09:24:42 <jonafan> therefore the people in #C are wrong!
09:24:43 <quicksilver> but it lets you take off the training wheels and shoot yourself in the foot if you want
09:24:48 <kscaldef> hellblade: presumably you are to return the new Team structure with the win recorded
09:25:11 <quicksilver> (I note that GHC does the same even if haskell98 doesn't)
09:25:37 <jonafan> out of curiousity, how would people in C define strong/weak?
09:25:53 <geocalc> alexj=<< change to linux
09:26:34 <quicksilver> some people use 'weak' typing to denote type systems with relatively few types
09:26:47 <quicksilver> like perl which has SCALAR ARRAY LIST HASH and a couple more
09:26:57 <quicksilver> and implicit coercions between most of them when it makes sense
09:27:07 <quicksilver> other people don't think it means that :)
09:27:25 <kscaldef> I think lots of C programmers don't understand the difference between strong and static typing, so think that C is strongly typed
09:27:30 <quicksilver> I associate 'strong' typing with a language which makes it easy to define new custom types and enforce that cvertain values are in that type.
09:27:33 <jonafan> so to them, weak means ... not very powerful
09:27:39 <Philippa_> jonafan: note how if a type system just believes you, it's unsound
09:28:03 <Philippa_> quicksilver: the implicit coercions would be a significant part of why people consider perl weakly typed, no?
09:28:25 <quicksilver> Philippa_: yes, I think so
09:29:01 <jonafan> to me, implicit coercion is still strong typing, because the language still knows, it's just trying to cover for you instead of throwing an exception
09:29:48 <alexj> geocalc: I am a mac user and the libs work on this platform.  just wondering how much to care about windows users for happs.
09:30:06 <Philippa_> jonafan: so a language with implicit coercions between all types would be strongly typed?
09:30:18 <jonafan> i think so
09:30:35 <Philippa_> despite the fact that it may as well have one type or no types at all at that point?
09:31:41 <jonafan> if it doesn't result in unpredictable errors because it's stupidly reinterpretting data incorrectly, i think it's still strong
09:31:56 <jonafan> however, i would definitely say that type system is silly
09:32:50 <Philippa_> such a type system is pretty much guaranteed to interpret data stupidly at some point
09:33:15 <geocalc> alexj=<< don't care of this dead os !
09:33:19 <Philippa_> whether the coercions do any conversion work or not
09:33:35 <jonafan> yeah, but i mean like misinterpretting bytes of memory internally
09:33:40 <quicksilver> Philippa_: I think you could add implicit conversions between all the Num instances in the prelude and haskell would still be strongly typed
09:33:46 <quicksilver> Philippa_: type inference would be odd, though
09:34:03 <jonafan> i'm not really down with type coercion either
09:34:07 <quicksilver> a value would still only have one type
09:34:20 <quicksilver> it's just you'd be "allowed" to pass it to a funciton of a different type and it would get converted first
09:34:26 <DRMacIver> When we say 'coercion' do we really mean 'conversion'?
09:34:31 <quicksilver> yes
09:34:31 <DRMacIver> s/we/you/
09:34:33 <DRMacIver> ok
09:34:37 <quicksilver> we,, I did :)
09:34:38 <Philippa_> quicksilver: it wouldn't be safe - you couldn't preserve properties regarding wraparound
09:34:41 <Philippa_> DRMacIver: I don't
09:34:49 <Philippa_> it may or may not involve a conversion
09:34:53 <quicksilver> Philippa_: there's lots of ways it would be odd
09:35:36 <DRMacIver> Philippa_: Ok.
09:36:49 <DRMacIver> (For what it's worth, Scala's is an example of a reasonable good static type system with a wide range of implicit conversions)
09:37:15 <Philippa_> yeah. I deliberately picked a totally degenerate case - there're arguments for some implicit coercions
09:37:28 <DRMacIver> In Scala's case they're user definable.
09:38:05 <DRMacIver> I think your degenerate case doesn't really hold, because there aren't valid implicit conversions between all types unless you count something like "Throw an exception"
09:38:49 <DRMacIver> How would you feel about the status of a (neccessarily very restricted) language in which the types of all expressions are known at compile time but all types are implicitly converted between?
09:39:01 <DRMacIver> And that all of thse conversions are valid total functions.
09:39:36 <DRMacIver> Hm. Actually I suspect such a case can't be sufficiently expressive to be interesting.
09:41:09 <geocalc> isn't everythung converted i, bits anyway
09:41:19 <geocalc> in*
09:41:49 <Philippa_> DRMacIver: that's exactly /why/ my degenerate case holds. There're languages that perform implicit but in some sense invalid conversions
09:41:51 <dankna> okay, so.  I want to implement my own moderately complicated data structure (an r-tree, not that it matters).
09:42:27 <dankna> I don't really have enough Haskell experience to know what I should know about how to make sure I get all the benefits of lazy evaluation, blah blah blah
09:42:47 <dankna> and whether the naive approach to doing incremental updating will be hideously space-wasting or whether I can count on the compiler to optimize it out
09:42:51 <dankna> where can I find background reading about this?
09:43:21 <quicksilver> I don't have a simple answer to that :(
09:43:38 <quicksilver> I would say 'be naive to start with, and learn from the experience'
09:43:39 <dankna> bleh :( I was afraid of that
09:43:42 <quicksilver> cos that's what I do...
09:43:45 * dankna nods
09:43:53 <dankna> I mean, that's fair of course, but disappointing
09:44:14 <quicksilver> I've not read a good document which explains sharing, laziness and space leaks in a unified coherent wayw
09:44:20 <quicksilver> (that doesn't mean such don't exist
09:44:22 * dankna nods
09:44:34 <geocalc> for incrementation you waste time andf memory dankna
09:44:44 <dankna> so far I haven't even figured out how I can tell whether laziness is happening or not in any particular case
09:44:55 <quicksilver> laziness happens at constructores
09:45:02 <quicksilver> you force things to be strict by doing case
09:45:07 <dankna> hmmmmm
09:45:09 <quicksilver> that's the basic rule :)
09:45:25 <quicksilver> let f x = Just (g x)
09:45:26 <dankna> in other words, things are evaluated at the time that you pattern-match against them
09:45:30 <quicksilver> yes
09:45:36 <quicksilver> but only as much as the pattern-match forces
09:45:39 <dankna> right, okay
09:45:43 <dankna> that helps a lot, actually
09:45:45 <quicksilver> case (f x) of Just h ->
09:45:51 * dankna nods
09:45:51 <quicksilver> ^^ I still haven't evaluated 'g'
09:45:57 <quicksilver> I've just bound 'h' to 'g x'
09:45:57 <dankna> right, gotcha
09:47:06 <dankna> is there anything that explains how the standard-library data structures are implemented, besides the source?  (though I'll probably wind up at least glancing at the source eventually anyhow...)
09:47:20 <quicksilver> well list and maybe are trivial
09:47:30 <quicksilver> Data.Map is far from trivial and the only docs are the source
09:47:34 * dankna nods
09:47:42 <quicksilver> Data.Sequence is described in a paper, which is referenced in the haddock
09:48:42 <dankna> okay, I can track that down
09:48:47 <quicksilver> I actually have not the faintest idea how Arrays are implemented. I've never looked :)
09:48:50 <dankna> haha :)
09:48:58 <dankna> yeah, they seem difficult, don't they? :)
09:49:39 <dankna> well, thanks
10:03:56 <hpaste>  Olathe pasted "How do I get this to print each element of the list immediately after it's computed ?" at http://hpaste.org/3345
10:05:21 <Lemmih> Olathe: Disable buffering on stdout?
10:05:38 <Olathe> How do I do that ?
10:06:06 <Lemmih> hSetBuffering stdout NoBuffering
10:07:41 <Olathe> Do I put that in the source somehow ?
10:08:22 <Olathe> I tried "main = hSetBuffering stdout NoBuffering >> print ...", "hSetBuffering stdout NoBuffering" on its own line, "hSetBuffering stdout NoBuffering" in a comment.
10:09:03 <Vulpyne> Probably want to use a "do" block.
10:10:42 <Olathe> Ahh, I didn't have import System.IO
10:10:51 <Olathe> Lemmih: Thanks :)
10:27:56 <fasta> Wasn't there an arrow function f that did f g (x,y) => (g x, g y)?
10:28:14 <Olathe> @pl \f g (x, y) -> (g x, g y)
10:28:15 <lambdabot> const ((`ap` snd) . (. fst) . (flip =<< (((.) . (,)) .)))
10:28:18 <Olathe> Eww.
10:28:26 <Olathe> @pl \g (x, y) -> (g x, g y)
10:28:26 <lambdabot> (`ap` snd) . (. fst) . (flip =<< (((.) . (,)) .))
10:29:08 <Saizan> ?type (***) -- fasta
10:29:10 <lambdabot> forall (a :: * -> * -> *) b c b' c'. (Arrow a) => a b c -> a b' c' -> a (b, b') (c, c')
10:29:54 <fasta> Saizan: doesn't that take two functions?
10:30:34 <Saizan> oh, yes, sorry misparsed
10:30:39 <Saizan> ?type join (***)
10:30:41 <lambdabot> forall (a :: * -> * -> *) b c. (Arrow a) => a b c -> a (b, b) (c, c)
10:32:12 <Olathe> @hoogle (a -> b) -> (a, a) -> (b, b)
10:32:12 <lambdabot> Data.Graph.Inductive.Query.Monad.(><) :: (a -> b) -> (c -> d) -> (a, c) -> (b, d)
10:32:21 <fasta> Saizan: somehow uses of (->) instances are harder to understand
10:33:17 <fasta> :t on
10:33:18 <lambdabot> Not in scope: `on'
10:33:48 <Saizan> yeah, we should have a name for this in Data.Tuple or such
10:35:22 <kscaldef> hey, does anyone understand why the ResponseCode type in Network.HTTP isn't exported?
10:36:06 <fasta> E.g.  join (flip const)  == join const
10:36:07 <kscaldef> how is one supposed to actually construct a Response?
10:37:25 <Olathe> @t mapT
10:37:25 <lambdabot> Maybe you meant: tell temp thank you thanks thx time tiny-url todo todo-add todo-delete topic-cons topic-init topic-null topic-snoc topic-tail topic-tell type . ? @ ft v
10:37:33 <Olathe> > mapT
10:37:34 <lambdabot>   Not in scope: `mapT'
10:37:53 <kscaldef> @type mapT
10:37:55 <lambdabot> Not in scope: `mapT'
10:38:17 <Olathe> > let mapT f (a, b) = (f a, f b) in mapT (+1) (2, 3)
10:38:19 <lambdabot>  (3,4)
10:39:59 <doserj> type join . (***)
10:40:11 <fasta> :t join . (***)
10:40:13 <lambdabot>     Couldn't match expected type `(->)' against inferred type `(,)'
10:40:13 <lambdabot>       Expected type: (b -> c) -> (b' -> c') -> (b' -> c') -> a
10:42:50 <Lemmih> kscaldef: It's a bug.
10:43:21 <Lemmih> kscaldef: It's a triple. You can treat it as such.
10:44:01 <kscaldef> Lemmih: yeah, I looked at the source code and determined that.  I was just wondering if it was some strange design decision I couldn't figure out
10:45:00 <kscaldef> the triple is kinda bizarre, as well.   Seems like it should be an enumerated type
10:47:52 <Arnar> hi folks..
10:48:20 <Arnar> so, anyone here up to looking at some involved problems with me?
10:49:26 <dons> you can probably just ask, and see if it captures some interest :)
10:49:33 <Arnar> dons: right, will do
10:50:16 <Arnar> first I must tell you this is "homework" - or more of a term-project. However, I've already met (and exceeded) what's required for a full mark and my prof. didn't know how to take this further
10:50:54 <Arnar> I'm implementing (or rather animating) structural operational semantic rules in haskell..
10:50:57 <dons> ok, brain storming on hard problems is reasonable, in here.
10:50:59 <Arnar> for a small CSP like language
10:51:23 <Arnar> the core problem is that this language (called Spinoza) is highly non-determnistic
10:51:44 <Arnar> so I am having problems fully simulating that in Haskell
10:52:36 <dmwit> Even with the non-determism monad?
10:52:45 <dmwit> s/mism/minism/
10:52:59 <Arnar> dmwit: no.. I didn't fully get that, or rather I couldn't find any useful examples
10:53:01 <Olathe> determaxism
10:53:06 <Arnar> I'm just using IO and some random generator
10:53:11 <byorgey> dmwit: ...you mean []?
10:53:16 <dmwit> byorgey: yes
10:53:46 <dmwit> Arnar: Aha; by non-determinism do you mean un-predictable, or does the program actually need to trace all possible execution paths?
10:53:47 <Arnar> may I show you an example construct that I fail to simulate correctly?
10:53:55 <Arnar> dmwit: non-predictable..
10:54:05 <Arnar> not the FSM kind of non-determinism
10:54:10 <glguy> Olathe: did you figure out your hpasted question?
10:54:14 <dmwit> ah
10:54:41 <Arnar> consider this small statement "local c in (c!1 par c!3 par c?x par c?y)"
10:54:48 <byorgey> Arnar: here CSP = Communicating Sequential Processes?
10:54:52 <Arnar> here, c is a channel, and x and y are integer viarables
10:54:53 <Arnar> byorgey: yes..
10:54:57 <Arnar> extended with channels
10:54:59 <Olathe> glguy: Yep Lemmih had the answer :)
10:55:04 <byorgey> ok
10:55:15 <Arnar> c!v sends an integer on channel c
10:55:24 <Arnar> c?x reads from chanel c into variable x
10:55:45 <Arnar> Statement "par" Statement executes one step from either statement (non-deterministically)
10:56:07 <byorgey> so... that code means that x and y will end up with the values 1 and 3, but it's non-deterministic which is which?
10:56:12 <dons> hey byorgey
10:56:12 <Arnar> local c in (...) ensures that no unmatched reads or writes escape out of the (...) on channel c
10:56:15 <Arnar> byorgey: exactly
10:56:16 <byorgey> hey dons
10:56:31 <Arnar> I have SOS rules for this that work on paper..
10:57:13 <Arnar> however, when I simulate the "par" construct above, the Haskell implementation only succeeds if the statements are evaluated in a suitable order..
10:57:42 <Arnar> in the SOS, the "no escape of unmatched reads/writes" for the local c in ... construct ensures the correct order is chosen..
10:57:49 <Olathe> > let perfSqs = 0:map (\(a, b) -> a + b) (zip perfSqs [1,3..]) in perfSqs
10:57:51 <lambdabot>  [0,1,4,9,16,25,36,49,64,81,100,121,144,169,196,225,256,289,324,361,400,441,4...
10:58:05 <Arnar> but in the haskell version - I can't check that part without doing the "par" stuff first..
10:58:08 <Arnar> a catch 22
10:58:13 <dons> Cale: around?
10:58:26 <byorgey> Olathe: neat =)
10:59:24 <glen_quagmire> you like haskell because it's complicated like C++ right?
10:59:26 <byorgey> Arnar: hmm, interesting
10:59:30 <glen_quagmire> oh crap it's not -blah
10:59:36 <Arnar> byorgey: the code for this is online.. let me paste the url
11:00:23 <Arnar> https://trac.hvergi.net/arnarmisc/browser/ru-projects/T-724_Semantics/spinoza_haskell/trunk/sos.hs
11:00:24 <lambdabot> http://tinyurl.com/249ltg
11:00:45 <Arnar> in particular the definitions on lines 73 and 112
11:02:37 <byorgey> Arnar: what's SOS stand for?
11:02:40 <fasta> allocBoxed elems init = mLift ( \s -> case newArray# (fromI# elems) init s of { (# s, arr #) -> (# s, MVec arr #) } )
11:02:45 <fasta> What's wrong with this?
11:02:45 <Arnar> perhaps instead of "picking" an alternative when I have non-deterministic construts, I shold pursue all paths until I either hit an exception (win which case that path is rejected) or find a "Final" configuration
11:02:52 <Arnar> byorgey: Structural Operational Semantics
11:02:57 <byorgey> ok, thanks
11:03:04 <fasta> It panics GHC with "Cannot unify"
11:03:24 <fasta> This is Bulat's code which was designed to work on 6.4
11:03:50 <byorgey> Arnar: that seems like the only way to go, since some of the "pickable" alternatives might not actually be viable.  e.g. a read from a channel that nothing has written to yet.
11:04:11 <Arnar> byorgey: yeah..
11:04:39 <Arnar> is there some pattern in Haskell of doing that (try-all-paths)
11:04:47 <byorgey> Arnar: ideally, if you're worried about the efficiency of trying every path, you could do some sort of dependency analysis/graph reduction sort of thing, and choose between all the viable reductions at each step... but that could get complicated
11:04:53 <byorgey> Arnar: yes, it's called the list monad =)
11:05:01 <Arnar> :)
11:05:37 <byorgey> > [ (x,y,z) | x <- [1..100], y <- [x+1..100], z <- [y+1..100], x^2 + y^2 == z^2]
11:05:39 <lambdabot>  [(3,4,5),(5,12,13),(6,8,10),(7,24,25),(8,15,17),(9,12,15),(9,40,41),(10,24,2...
11:06:07 <Arnar> ok..
11:06:44 <byorgey> @type (>>=)
11:06:47 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> (a -> m b) -> m b
11:07:01 <dmwit> :t (>>=) `asTypeOf` concatMap
11:07:02 <lambdabot>     Couldn't match expected type `[b1] -> a -> b'
11:07:03 <lambdabot>            against inferred type `[a]'
11:07:08 <dmwit> :t (>>=) `asTypeOf` flip concatMap
11:07:09 <lambdabot> forall a b. [a] -> (a -> [b]) -> [b]
11:07:17 <byorgey> ah, thanks dmwit =)
11:07:27 <Arnar> wait.. I didn't get that one
11:08:05 <dmwit> Arnar: Do you grok concat and map (separately)?
11:08:05 <byorgey> that says, 'take a list of possibilities :: [a], then given a function :: (a -> [b]) which gives the possible continuations of each possibility :: a, create a new list of possibilities :: [b]'
11:08:23 <Arnar> dmwit: I think so yes..
11:08:36 <Arnar> byorgey: oh.. cool
11:08:54 <dmwit> Arnar: Okay, so imagine some function f :: a -> [b]; the idea is that f is a function that has *several* outputs.
11:09:13 <dmwit> Arnar: (>>=) then says, if I have several *inputs*, try f on each one, and then return all the possible results.
11:09:16 <dmwit> So:
11:09:44 <dmwit> > let f x = replicate 3 x in map f ['a', 'b', 'c']
11:09:46 <lambdabot>  ["aaa","bbb","ccc"]
11:09:52 <dmwit> > let f x = replicate 3 x in concat $ map f ['a', 'b', 'c']
11:09:54 <lambdabot>  "aaabbbccc"
11:10:04 <dmwit> > let f x = replicate 3 x in ['a', 'b', 'c'] >>= f
11:10:05 <lambdabot>  "aaabbbccc"
11:10:58 <dmwit> So you should now have two ways of thinking of the list monad: in one, you simply replace (>>=) with the equivalent concat and map; in the other, you imagine a non-deterministic function (i.e. one with several possible outputs) that is run on several possible inputs.
11:11:17 <Arnar> ok
11:11:37 <Olathe> Is there a way of making >>= produce outputs in random order ?
11:11:42 <dmwit> It might help to have a better example of a non-deterministic function, hold on a second.
11:11:45 <Olathe> > ['a', 'b', 'c'] >>= replicate 3
11:11:46 <lambdabot>  "aaabbbccc"
11:11:56 <Arnar> > let adj x = [x-1,x+1] in [1,2,3,10] >>= adj
11:11:57 <Olathe> Have it give "bbbaaaccc" one time, maybe ?
11:11:58 <lambdabot>  [0,2,1,3,2,4,9,11]
11:12:01 <dmwit> > let f x = [x + 1, x + 2, 2 * x] in [5, 7, 32] >>= f
11:12:02 <lambdabot>  [6,7,10,8,9,14,33,34,64]
11:12:22 <byorgey> Olathe: you could make your own function like that, but the type would be different.
11:12:33 <dmwit> Olathe: Probably the simplest thing is to just shuffle the resulting list.
11:12:45 <Olathe> It would be nice for randomized algorithms.
11:13:14 <Olathe> I suppose making a monad wouldn't be so hard.
11:13:25 <MyCatVerbs> > foldl' max [1..10]
11:13:27 <lambdabot>  <[[Integer]] -> [Integer]>
11:13:30 <Arnar> impl. NDFAs would be a snap with this..
11:13:32 <byorgey> Olathe: you could easily define something like (x >>~ f) = shuffle . (x >>= f)
11:13:35 <dmwit> Olathe: I did something similar, but it had to be in the StateT StdGen [] monad instead of just a plain-old [] monad.
11:13:42 <MyCatVerbs> > foldl' max 0 [1..10]
11:13:43 <lambdabot>  10
11:13:49 <Olathe> byorgey: Hmm, yeah you're right.
11:13:57 <dmwit> Arnar: Yes!
11:14:38 <dmwit> Hence the name non-determinism monad. =P
11:14:57 <dmwit> > [1,2,3] < [3,4,5]
11:14:58 <Arnar> so list monad = non-determinsim monad :)
11:14:59 <lambdabot>  True
11:15:05 <dmwit> huh
11:15:06 <dmwit> oh
11:15:07 <dmwit> right
11:15:11 <dmwit> Arnar: yes =)
11:15:14 <Olathe> > O-O <
11:15:14 <lambdabot>   parse error on input `}'
11:16:08 <Arnar> haskellers have three names for everything..
11:16:09 <Arnar> :)
11:16:34 <byorgey> that's because everything has three names! =)
11:17:18 <Arnar> hmm..
11:17:27 <Arnar> although, maybe this wouldn't make sense for my impl.
11:17:39 <Arnar> I have a construct "star(C)" in the language
11:18:06 <Arnar> the semantics being that either star(C) = nop , or star(C) = C; star(C)
11:18:23 <Arnar> nop is no operations and ; is regular sequential composition
11:18:31 <Arnar> C is any statement
11:19:02 <Arnar> so a program star(x:=x+1) would result in x having some value greater or equal to it's initial value
11:19:23 <Arnar> now.. obviously the tree is infinite..
11:19:26 <MyCatVerbs> Uh. Is there a standard NOP in System.IO? return ()?
11:19:41 <Arnar> MyCatVerbs: this is a different language that I'm simulating
11:20:06 <Arnar> so pursuing all possible paths will never terminate..
11:20:08 <MyCatVerbs> Arnar: right, sorry, you just reminded me of that. I'm pretty certain I've wanted to use one before, y'see.
11:20:09 <dmwit> > let star c = [[], return c >>= star c] in star 1 -- hmmm...
11:20:10 <lambdabot>  Couldn't match expected type `a -> m b'
11:21:06 <Olathe> > let f c = [c, c + 1] in [5] >>= f >>= f
11:21:07 <lambdabot>  [5,6,6,7]
11:21:46 <Olathe> > let (>>~) = nub . (>>=); f c = [c, c + 1] in [5] >>= f >>= f
11:21:47 <lambdabot>  Couldn't match expected type `[a]'
11:22:10 <Olathe> > let (>>~) = nub . (>>=); f c = [c, c + 1] in [5] >>~ f >>~ f
11:22:11 <lambdabot>  Couldn't match expected type `[a]'
11:22:16 <dmwit> > let star m = [[], m >> m] in star [1]
11:22:18 <lambdabot>  [[],[1]]
11:22:27 <Arnar> so could I (at the end of simulation) pick a random element from an infinite list?
11:22:32 <dmwit> > let star m = [[], m >> star m] in star [1]
11:22:38 <lambdabot>      Occurs check: cannot construct the infinite type: a = [a]
11:22:40 <lambdabot>       Expected...
11:22:50 <Olathe> Arnar: Yes, just not uniformly.
11:22:52 <fasta> WTH!
11:23:05 <fasta> I cannot send executables via gmail...
11:23:09 <Arnar> Olathe: of course, a uniform selection would give every element a probability 0
11:23:38 <fasta> There are no executables even.
11:24:50 <Olathe> > ((+1), id) &&& 5
11:24:51 <lambdabot>   add an instance declaration for (Num (a -> a, c'))
11:25:06 <dmwit> > (+1) &&& id $ 5
11:25:07 <lambdabot>  (6,5)
11:25:34 <Olathe> Ahh.
11:26:07 <Olathe> @pl \f x -> [x, f x]
11:26:07 <lambdabot> ap (:) . flip flip [] . ((:) .)
11:26:59 <Olathe> > let possibly f x = [x, f x] in [5] >>= possibly (+1) >>= possibly (+1)
11:27:01 <lambdabot>  [5,6,6,7]
11:29:06 <Olathe> > let >>~ = (nub .) . (>>=); possibly f x = [x, f x] in [5] >>~ possibly (+1) >>~ possibly (+1)
11:29:06 <lambdabot>  Parse error
11:29:12 <Olathe> > let (>>~) = (nub .) . (>>=); possibly f x = [x, f x] in [5] >>~ possibly (+1) >>~ possibly (+1)
11:29:14 <lambdabot>  [5,6,7]
11:29:36 <Arnar> (whooosh)
11:29:56 <Olathe> Did you understand > let possibly f x = [x, f x] in [5] >>= possibly (+1) >>= possibly (+1) ?
11:30:14 <Arnar> yes.. think so
11:30:22 <kscaldef> you can select with uniform probability from a list of any length (even infinite).  But, it will take infinite time to do it.
11:30:28 <Olathe> The last was the same thing with >>~ instead of >>=
11:30:35 <Olathe> >>~ just removes duplicates.
11:30:39 <Arnar> kscaldef: which is another way of saying you can't really do it :)
11:30:45 <Arnar> Olathe: oh, ok
11:30:53 <Olathe> ksandstr: How ?
11:30:57 <Olathe> Bah.
11:31:00 <Olathe> kscaldef: How ?
11:31:17 <kscaldef> Arnar: right, but you can do it for a list of arbitrary length, even if you don't know the length in advance
11:31:34 <Arnar> Olathe: but you're applying a fixed number of times though..
11:31:34 <Olathe> Oh yeah.
11:31:42 <Olathe> Arnar: Yep.
11:32:08 <Olathe> Replace the current selection with the nth item with 1/n possibility.
11:32:16 <kscaldef> Olathe: right
11:32:21 <Arnar> kscaldef: ah, yes.
11:33:05 <dmwit> I don't think you can prove that that is uniform for an infinite list.
11:33:27 <kscaldef> I guess it depends on what you mean by "infinite"
11:33:30 <dmwit> If it were uniform, you should have P(I choose an even-numbered element) = 1/2.
11:33:37 <Arnar> well.. I have to go, thanks for your input
11:33:44 <Arnar> dmwit++ byorgey++
11:33:45 <kscaldef> but, you can prove it by induction for all pos. integers
11:33:54 <Olathe> > let (>>~) = (nub .) . (>>=); possibly f x = [x, f x]; f x = x >>~ possibly (+1) in iterate f [5]
11:33:55 <lambdabot>  [[5],[5,6],[5,6,7],[5,6,7,8],[5,6,7,8,9],[5,6,7,8,9,10],[5,6,7,8,9,10,11],[5...
11:34:04 <dmwit> But I think you get something like P(I choose an even numbered element) = P(I choose an element) /= 1/2
11:34:05 <Arnar> kscaldef: that provies it for a list of "arbitrary" length..
11:34:07 <kscaldef> so, if the infinite list is defined inductively, the proof seems like it holds
11:34:12 <kscaldef> more, or less
11:34:20 <Olathe> Actually.
11:34:31 <dmwit> Induction fails on the first non-finite ordinal. =P
11:34:48 <dmwit> In this case, an infinite list just so happens to have that same ordinality. =(
11:34:55 <Olathe> > let results = 5:map (+1) results
11:34:55 <lambdabot>  Parse error
11:34:58 <Olathe> > let results = 5:map (+1) results in results
11:35:00 <lambdabot>  [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31...
11:35:08 <Olathe> That's a nicer way to do something or nothing.
11:35:23 <Arnar> Olathe: cool.. thanks
11:35:28 <Arnar> Olathe++
11:35:38 <newsham> > iterate (+1) 5
11:35:39 <lambdabot>  [5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31...
11:35:49 <ricky_clarkson> Woah, I really don't get Olathe's code there.
11:35:50 <Arnar> thanks again..
11:35:56 <Arnar> bye
11:36:03 <Olathe> > let doOrNotForever f start = results where results = start:map f results in results; doOrNotForever (+2)
11:36:03 <lambdabot>  Parse error
11:36:15 <Olathe> > let doOrNotForever f start = results where results = start:map f results in doOrNotForever (+2) 5
11:36:16 <lambdabot>  [5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,...
11:36:35 <dmwit> > let doOrNotForever = iterate in doOrNotForever (+2) 5
11:36:35 <Arnar> Olathe: that looks pretty much like what I need..
11:36:37 <lambdabot>  [5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,...
11:36:42 <dmwit> ;-)
11:36:46 <Olathe> dmwit: heh
11:36:58 <Olathe> iterate is what you need, I guess.
11:37:02 <Olathe> > iterate (+2) 5
11:37:03 <Arnar> yeah..
11:37:04 <lambdabot>  [5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,...
11:37:05 <newsham> ricky: results[0] = 5; results[1..] = map (+1) (results[0..])
11:37:06 <Arnar> :src iterate
11:37:08 <dmwit> ricky_clarkson: Don't worry, just work through the code slowly.
11:37:12 <Arnar> ?src iterate
11:37:12 <lambdabot> iterate f x =  x : iterate f (f x)
11:37:20 <newsham> > [5,5+2..]
11:37:21 <lambdabot>  [5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,...
11:37:27 <Arnar> is there a reference sheet for lambdabot commands?
11:37:33 <dmwit> ?where Prelude
11:37:34 <lambdabot> http://www.haskell.org/onlinereport/standard-prelude.html
11:37:37 <dmwit> ?list
11:37:37 <lambdabot> http://www.cse.unsw.edu.au/~dons/lambdabot/COMMANDS
11:37:46 <fasta> Can the patch command give a patch between two directories?
11:38:00 <Arnar> dmwit: yeah.. but when to use >, :, ? etc..
11:38:01 <dmwit> fasta: Yes.
11:38:10 <dmwit> Arnar: Always use ? with the commands listed there.
11:38:17 <newsham> > enumFromThen 5 (5+2)
11:38:18 <lambdabot>  [5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,...
11:38:18 <Arnar> ok..
11:38:26 <Arnar> > : etc are just shorthands for other stuff?
11:38:26 <lambdabot>  Parse error
11:38:29 <Arnar> heh
11:38:37 <dmwit> fasta: Are you trying to generate the patch?  That's usually done with diff.
11:38:48 <fasta> dmwit: right
11:38:58 <newsham> arnar: (:) is the constructor for a list with a head element and a tail list
11:39:24 <Arnar> newsham: I'm talking about lambdabot syntax :)
11:39:42 <Arnar> anyways.. I'm late now
11:39:47 <newsham> ">" is for evaluating.  "?" and "@" are to start lambdabot commands
11:40:00 <newsham> ":" is sometimes used to mimic some ghci commands (like :type)
11:40:20 <newsham> ?elite lambdabot command elite mangles text
11:40:20 <lambdabot> LaM8daBOT COM/\/\4Nd 3LI7e mAng1E$ 73XT
11:40:35 <newsham> > "lambdabot eval"
11:40:37 <lambdabot>  "lambdabot eval"
11:41:20 <dmwit> ?eval "this is the long-hand for >"
11:41:32 <dmwit> or maybe not
11:41:35 <newsham> ?help eval
11:41:35 <lambdabot> eval. Do nothing (perversely)
11:42:16 <byorgey> ?help run
11:42:16 <lambdabot> run <expr>. You have Haskell, 3 seconds and no IO. Go nuts!
11:42:22 <dmwit> that one
11:42:23 <dmwit> =)
11:42:42 <Olathe> @. elite . run yow
11:42:42 <lambdabot> parzE erR0R On InPu+ `}'
11:42:54 <dmwit> ?. elite yow
11:42:54 <lambdabot> hey, W4It 4 /\/\InU73!! i WANt a Div0rcE!! ... YoU'r3 N0+ (1iNt 3azt\/\/Ood!!
11:43:14 <newsham> ?. elite run map (+1) [2..5]
11:43:15 <dmwit> ?. elite run "yow!"
11:43:16 <lambdabot> [3,4,5,6]
11:43:16 <lambdabot> "yoW!"
11:43:26 <dmwit> ?arr!
11:43:26 <lambdabot> Aye Aye Cap'n
11:43:34 <newsham> ?. vixen keal
11:43:35 <lambdabot> who doesn't want that?
11:43:35 <olsner> @. elite arr!
11:43:35 <lambdabot> Plugin `compose' failed with: IRCRaised Parse error: "arr!"
11:43:38 <Olathe> @. elite . run arr!
11:43:38 <lambdabot> Plugin `compose' failed with: IRCRaised Parse error: "arr!"
11:43:45 <newsham> let vixen talk to keal
11:43:58 <Olathe> @. keal vixen
11:43:58 <lambdabot> 99% of my book has been erased by faulty hdd's
11:44:05 <newsham> dont think keal takes an arg
11:44:06 <Olathe> @. vixen keal
11:44:06 <lambdabot> what's worth more a flush or a full house?
11:44:30 <newsham> (strangely keal is never invoked without an argument)
11:44:36 <Olathe> Heheh
11:44:43 <kscaldef> @keal
11:44:43 <lambdabot> when i put what i dat recoved from that tile into a ti92. the damn thing blew up
11:44:57 <fasta> dmwit: diff -r dira dirb > thepatch seemed to work
11:45:03 <Olathe> That just reminded me. I have pumpkin pie.
11:45:10 <kscaldef> @yhjulwwiefzojcbxybbruweejw
11:45:11 <lambdabot> "\""
11:45:28 <kscaldef> @yhjulwwiefzojcbxybbruweejw
11:45:28 <lambdabot> Exception: <<loop>>
11:45:48 <olsner> @help yhjulwwiefzojcbxybbruweejw
11:45:48 <lambdabot> V RETURNS!
11:45:51 <kscaldef> okay then
11:46:21 <kscaldef> hmm... that's not especially helpful
11:46:59 <Olathe> It's quite a name.
11:47:28 <byorgey> pumpkin pie!
11:47:52 <dmwit> fasta: Yep.  FWIW, I usually figure that diff -Naur is a pretty sane default.
11:48:22 <byorgey> > let pumpkin x = exp x - x in pumpkin pi
11:48:24 <lambdabot>  19.999099979189474
11:49:24 <fasta> dmwit: diff a b == diff b a, right?
11:49:53 <dmwit> fasta: NO
11:50:19 <dmwit> fasta: But don't worry, patch can usually detect reversed diffs. =)
11:50:29 <fasta> dmwit: I did diff old new
11:50:36 <dmwit> That is the preferred way.
11:50:50 * dmwit -> shower
11:53:31 <newsham> ?type diff
11:53:33 <lambdabot> Not in scope: `diff'
11:53:52 <phlpp> re
11:53:53 <phlpp> :0
11:54:46 <Olathe> byorgey: Heheh
11:55:45 <phlpp> byorgey: i bet this evening i'll annoy you guys again ;)
12:02:48 <hpaste>  hellblade pasted "Type error in explicitly typed binding" at http://hpaste.org/3347
12:03:48 <mauke> hellblade: null :: [a] -> Bool
12:03:59 <mauke> null is not a Strand
12:04:07 <hellblade> sry wrong paste
12:04:12 <hpaste>  hellblade pasted "Instance of Eq Unit required for definition of compS" at http://hpaste.org/3348
12:04:29 <mauke> yeah, your Unit doesn't support ==
12:04:56 <mauke> comp x = case x of A -> T; T -> A; C -> G; G -> C
12:05:12 <mauke> (replace ';' by '\n' where desired)
12:05:42 <doserj> comp A = T ; comp T = A; etc.
12:05:49 <hellblade> oh ty guys
12:05:56 <mauke> I'd use case here
12:10:42 <fasta> It stack overflows when used in ghci, and it used 99% CPU when used in ghc and it runs longer than expected. What is it?
12:11:17 <Beelsebob> does anyone off the top of their head know what the best reference for the Hindley Milner type inference system is?
12:11:48 <Igloo> Just something to reference, rather than something to read?
12:11:56 <Beelsebob> just something to reference
12:12:28 <hpaste>  Igloo pasted "Beelsebob" at http://hpaste.org/3349
12:12:35 <kscaldef> fasta: is that a riddle?
12:12:37 <Beelsebob> excellent
12:12:39 <Beelsebob> thanks a lot Igloo
12:12:44 <roconnor> continuations make my head hurt
12:12:48 <fasta> kscaldef: yes, without a solution
12:13:10 <fasta> kscaldef: I think it's just some infinite loop, but I have no idea where it comes from as AFAIK, I don't use anything that can cause infinite loops.
12:13:19 <fox86> does anyone know if this tutorial is any good? http://www.lisperati.com/haskell/
12:13:20 <fasta> (e.g. mapM and foldM should terminate)
12:13:46 <kscaldef> fasta: exponential complexity blowups do a good job of simulating infinite loops
12:14:06 <Beelsebob> Igloo: don't suppose you have an equivalent one for ML itself do you?
12:14:19 <fasta> kscaldef: well, I think I just have something like z = z somewhere
12:14:26 <Beelsebob> nvm actually
12:14:27 <kscaldef> fox86: it's amusing, at least
12:14:28 <Beelsebob> found the definition
12:14:31 <fasta> kscaldef: but then in some longer cycle by forgetting something
12:14:50 <Igloo> Beelsebob: I have one for SML, but not ML
12:14:50 <fasta> Probably -Wall finds it
12:15:07 <Beelsebob> yeh, SML works :) I'm using Milner's definitional book
12:15:13 <Beelsebob> google didn't instantly find it though
12:16:02 <yrlnry> The original Milner paper appeared in Elsevier "Journal of Theoretical Computer Science".  I used to have that issue, but I gave it away.
12:16:28 <yrlnry> But someone, I think Peter Buneman, pointed out that the algorithm has exponential worst-case running time.
12:16:58 <fasta> What is an orphan instance?
12:18:08 <byorgey> fox86: it's pretty new, I don't know how many people have read it.  The same guy also wrote a lisp tutorial which seems highly regarded.
12:18:24 <byorgey> fox86: you should give it a try and see what you think =)
12:18:29 <paczesiowa> fasta: An instance declartion is an orphan if it appears in a module in which neither the class nor the type being instanced are declared in the same module. A rule is an orphan if it is a rule for a function declared in another module. A module containing any orphans is called an orphan module.
12:19:28 <paczesiowa> how do I catch exceptions from 'read "" :: Int' ?
12:19:30 <fasta> paczesiowa: I define a relation between two types in different modules
12:19:49 <paczesiowa> fasta: don't ask me, I just googled that
12:19:49 <mauke> paczesiowa: can't you use reads instead?
12:20:06 <fasta> paczesiowa: ok
12:20:16 <fox86> byorgey: okay, i will!
12:20:39 <paczesiowa> mauke: thx!
12:20:56 <mauke> > reads "" :: [(Int,String)]
12:20:58 <lambdabot>  []
12:20:59 <fasta> Why is there no -fnowarn-missing-signatures?
12:21:53 <fasta> I thought of combining -Wall and then subtracting the warnings I don't want.
12:22:37 <paczesiowa> why do you omit signatures?
12:22:52 <fasta> Never mind
12:22:58 <fasta> It is there, I just read over it
12:23:10 <fasta> paczesiowa: because the types are a page long?
12:23:39 <paczesiowa> if you write quick-throw-away code don't use -Wall, if it's so important then you really want signatures:>
12:24:08 <fasta> paczesiowa: I haven't seen anyone putting a type signature of a page on something.
12:24:41 <fasta> paczesiowa: you can write something more complicated than fib in Haskell
12:24:58 <fasta> paczesiowa: if I wanted to put type signatures on everything, I would use C++.
12:25:04 <fasta> Or Omega ;)
12:25:53 <paczesiowa> still if it's simple function, put it in where clause, or use lambda expression, they don't need signatures in -Wall mode
12:26:47 <fasta> I put more stuff on the top-level since otherwise my functions become too wide.
12:26:54 <paczesiowa> if it's important enough to be defined at top level, you will be grateful tomorrow when you have to fix a bug:>
12:27:15 <kscaldef> type sig a page long??? What are you doing?
12:27:37 <paczesiowa> maybe he has comments inside types?
12:28:04 <paczesiowa> type ThisNumberRepresentsSomething...= Int
12:28:48 <fasta> kscaldef: try using monad transformers and generic data structures and you will know
12:29:16 <Botje> LOL
12:29:42 <Botje> leCamarade++ # for his hilarious analog of monads to food
12:29:43 <kscaldef> hmmm... okay.  Never used monad transformers, so I guess i'll take your word for it
12:30:21 <Saizan> well it's still unusual to get page-long types..
12:30:27 <fasta> kscaldef: a type for a fully generic function, is O(the number of different generic types used)
12:30:52 <fasta> kscaldef: and you also need to add different instantiations sometimes
12:31:15 <Saizan> fasta: most of the type are typeclass constraints?
12:31:18 <kscaldef> couldn't some additional type defs shorten things?  I am familiar with how verbose C++ generic types can get, but you usually use typedefs to help with that
12:31:23 <fasta> Saizan: yes
12:31:48 <kscaldef> oh... I see
12:32:22 <fasta> Most of the times when your types are 4 pages long, you made a mistake.
12:32:26 <fasta> Just like C++ ;)
12:32:53 <Saizan> you've pushed ad-hoc polymorphism very far :)
12:33:05 <Botje> that or you're implementing assembly in the type system.
12:33:13 <fasta> Saizan: yes, but it seems to work quite well now.
12:33:18 <fasta> (when there are no compiler bugs)
12:33:20 <dmwit> > map chr [72, 105, 33]
12:33:22 <lambdabot>  "Hi!"
12:33:58 <Saizan> fasta: no more struggling with fundeps?
12:34:06 <fasta> Saizan: no, they all just work.
12:38:35 <hpaste>  hellblade pasted "Instance of Eq Base required for definition of occurs" at http://hpaste.org/3350
12:39:12 <hellblade> can I somehow make my own type be comparable?
12:39:30 <olsner> hellblade: add deriving Eq to the end of the type definition
12:39:31 <mauke> occurs b = length . filter (b ==)
12:39:31 <mauke> yes
12:39:38 <mauke> just say data Unit = ... deriving (Eq)
12:39:48 <hellblade> oh ty
12:40:12 <mauke> make that deriving (Eq, Ord, Show, Enum, Bounded)
12:41:38 <doserj> occurs b = length . filter (==b) ?
12:43:05 <doserj> ups, didn't see your comment, mauke :)
12:43:48 <mauke> TMTOWTDIBTAE
12:44:45 * roconnor finds it hard to imagine situations where it is useful to use continuations.
12:44:49 <EvilRanter> TMTOWTDI, but this aint, er...
12:45:19 <mauke> but they're all equal
12:45:26 <EvilRanter> ah, okay
12:45:46 * EvilRanter was aiming for "but this aint one of 'em", but it didn't fit
12:45:49 <EvilRanter> ...
12:45:56 <Irrelevant> wait
12:46:04 <EvilTerran> that's the one
12:46:34 * EvilTerran was very confused for a minute there
12:49:31 <phlpp> > read $ replicate (10^6) '1'
12:49:35 <lambdabot> Terminated
12:49:43 <phlpp> eh?
12:49:55 <EvilTerran> @help run
12:49:55 <lambdabot> run <expr>. You have Haskell, 3 seconds and no IO. Go nuts!
12:50:20 <EvilTerran> apparently that takes longer than 3 seconds
12:50:32 <phlpp> ah, i see
12:50:36 <phlpp> it has to terminate
12:50:48 <phlpp> but working with this value gets me an overflow :C
12:51:08 <byorgey> phlpp: what sort of overflow?
12:51:10 <EvilTerran> > typeOf $ read $ replicate (10^6) '1'
12:51:11 <lambdabot>  Add a type signature
12:51:22 <byorgey> phlpp: be sure to use Integer, not Int
12:51:31 <EvilTerran> hm. try explicitly typing it as Integer rather than Int, phlpp
12:52:28 <phlpp> to my surprise, at home (before i tested sth like this at work) he doesn't put me an overflow
12:52:35 <phlpp> ghci is just hanging ;)
12:53:21 <byorgey> phlpp: maybe it's using too much memory?
12:53:25 <phlpp> r :: Int -> Integer
12:53:33 <phlpp> r k = read $ replicate k '1'
12:53:33 <phlpp> you mean like this?
12:53:47 <phlpp> byorgey: probably. i think that's one of the problems i'll get to solve this task
12:54:17 <Lemmih> Why do you want such a big number?
12:54:28 <phlpp> it's not given that the num, consisting only of 1s, thats why we call it a 'repunit', has to be 10^6. it has at least to be a number with 10^6 digits, whereas all digits are '1'
12:55:01 <phlpp> Lemmih: i really don't WANT, but unless i found a solution to use a smaller one i have to
12:55:02 <byorgey> phlpp: yeah, when I run that code on my machine, it uses almost 130MB.  I let it run for like twenty seconds before killing it.
12:55:10 <byorgey> phlpp: there are much better ways to deal with repunits =)
12:55:13 <phlpp> oh dear
12:55:43 <phlpp> oh really? i thought so, i tried to think about some 'division' rules, you know
12:56:01 <byorgey> phlpp: is this for project euler?
12:56:04 <phlpp> maybe i look up at google for repunits ;)
12:56:15 <phlpp> yeah, it is ;)
12:56:25 <byorgey> which one?
12:56:31 <phlpp> erm
12:56:35 <phlpp> wait a sec
12:56:38 <byorgey> don't worry, I won't give away the answer =)
12:56:59 <phlpp> :>
12:57:02 <phlpp> problem 129
12:58:02 <phlpp> my notes according this: R (A (n)) mod n = 0 -> we're looking for the least n, where (A(n)) exceeds 10^6
12:58:50 <phlpp> and yeah, gcd (n, 10) has to be 1, so i don't have to test all numbers from 1 to ... ;)
12:59:13 <byorgey> phlpp: ok, I see.  yes, you'll have to be a bit more clever to solve that one.  you want to be able to compute A(n) without explicitly constructing the repunits involved.
12:59:24 <byorgey> ...since they will be very big.
12:59:46 <phlpp> yeah
13:00:01 <phlpp> i think every naive implementation would violate one minute rule ;)
13:00:13 <phlpp> i'll try do so some research on repunits
13:01:03 <phlpp> btw. the first thing i had to do on a naive implementation would be to test if: rep 10^6 is prime ;)
13:03:29 <byorgey> hah, good luck with that =)
13:04:03 <phlpp> :D
13:04:54 <phlpp> even an optimized lucas lehmer test wouldn't terminate in an acceptable amount of time, i think :p
13:06:39 <byorgey> well, it would probably take a month or so.
13:06:44 <byorgey> not too bad.
13:07:17 <phlpp> hehe
13:07:18 <byorgey> actually, wait, I'm thinking of Mersenne primality testing.  for repunits, yeah, never mind =)
13:07:45 <phlpp> hm, lucas lehmer is used for mersenne primality testing
13:07:47 <phlpp> isn't it?
13:07:54 <byorgey> yes
13:08:44 <phlpp> ok, this is a really hard task
13:08:45 <phlpp> :D
13:08:58 <adaptable> I was amazed at how quickly doing Project Euler turned from a "learning Haskell" hobby to "learning number theory".
13:09:11 <phlpp> hehe
13:09:29 <byorgey> phlpp: yeah, it isn't trivial.  I think that one (and many of them, as adaptable points out) is more about figuring out the math behind it, rather than programming tricks.
13:09:37 <phlpp> byorgey: jup
13:09:45 <byorgey> but the math is pretty interesting =)
13:10:05 <oerjan> @free (a -> b) -> f a -> f b
13:10:05 <lambdabot> Pattern match failure in do expression at Plugin/Free/FreeTheorem.hs:54:20-34
13:10:21 <phlpp> my attempt: R(A(n)) mod n = 0 won't do i think
13:10:24 <shachaf> When do we get @projecteuler?
13:10:27 <oerjan> @free m :: (a -> b) -> f a -> f b
13:10:27 <lambdabot> Extra stuff at end of line
13:10:39 <phlpp> because for this i have to figure out about such big repunits
13:10:51 <shachaf> @free map
13:10:53 <lambdabot> g . h = k . f => $map g . map h = map k . $map f
13:11:09 <oerjan> @free (b -> c) -> (a -> b) -> f a -> f c
13:11:09 <lambdabot> Pattern match failure in do expression at Plugin/Free/FreeTheorem.hs:54:20-34
13:11:19 <oerjan> bah, it cannot handle it
13:11:59 <phlpp> ok, maybe this is a bit to hard for advancing in 'learning haskell' ;)
13:12:13 <shachaf> @free a -> a
13:12:14 <lambdabot> Extra stuff at end of line
13:12:18 <shachaf> @free id :: a -> a
13:12:18 <lambdabot> f . id = id . f
13:12:27 * oerjan suspects a similar equality as for map holds for fmap, just from the type
13:12:40 <fasta> Can one use profiling to find stack overflows?
13:12:46 <shachaf> oerjan: Yes, @djinn doesn't know about lists, as far as I know.
13:12:57 <shachaf> So you can use [a] for f a.
13:13:06 <oerjan> shachaf: i'm talking about free
13:13:10 <shachaf> (I may be wrong.)
13:13:16 <shachaf> And I meant @free too. :-)
13:13:46 <oerjan> except it would then assume it can use $map
13:14:28 <shachaf> Oh. Never mind.
13:15:34 <oerjan> i have a sort of intuition that anything with type m :: (b -> c) -> (a -> b) -> f a -> f c will automatically satisfy m f g = m id (f.g) = m (f.g) id
13:15:47 <oerjan> by looking just at the b
13:16:49 <oerjan> and by plugging in \f g -> fmap f . fmap g you get that fmap is determined by its type + fmap id = id
13:17:19 <oerjan> hm... can free take type constructors?
13:17:42 <oerjan> @free m :: (b -> T2) -> (T1 -> b) -> R
13:17:43 <lambdabot> m . (.) f = (.) (m f) . (.)
13:18:32 <oerjan> @unpl m . (.) f
13:18:32 <lambdabot> (\ g -> m (\ c -> f (g c)))
13:19:07 <oerjan> @unpl (.) (m f) . (.)
13:19:07 <lambdabot> (\ j c -> m f (\ g -> j (c g)))
13:19:18 <CosmicRay> heh, simonmar keeps threatening to remove my favorite features from the haskell library... forkProcess this time
13:19:21 <hellblade> "Program error: {encode_v1334 [] Base_T}" do you know what could this mean? my program executes ok
13:19:48 <fasta> CosmicRay: context?
13:20:25 <byorgey> hellblade: it's hard to know without seeing the code.  Can you paste it on hpaste?
13:20:25 <CosmicRay> fasta: http://news.gmane.org/find-root.php?group=gmane.comp.lang.haskell.cafe&article=30242
13:20:29 <lambdabot> Title: Gmane Loom, http://tinyurl.com/ynsmta
13:20:35 <dons> hlhmm, using Data.Binary ?
13:20:45 <dons> hellblade: ^^
13:20:53 <allbery_b> He's right, though, since fork() and multithreading can mix oddly given strict POSIX constraints
13:21:05 <phlpp> byorgey: ok, i found a more easier task. my problem: get the proper divisors of a num. proper divisors of 10 are 1, 2, 5. so in an imperative language, i would test all numbs starting with 1 to n/2, if num mod i == 0
13:21:18 <CosmicRay> allbery_b: sure they *can* mix oddly.  but fork() still exists in libc and could still exist in Haskell with the current warning
13:21:28 <phlpp> maybe you just give me a tip
13:21:29 <allbery_b> (that said, IIRC it's something like POSIX allowing fork() to be implemented as vfork(), which no unixlike supported by ghc does)
13:21:34 <phlpp> what do i have to 'use'
13:21:40 <fasta> CosmicRay: I assume something suitable will replace it.
13:21:42 <phlpp> not the whole 'solution' ;)
13:21:42 <CosmicRay> I doubt that most people that use forkProcess are going to want to be using threading anyway
13:21:53 <CosmicRay> fasta: his message indicates he just wants out out entirely.
13:22:03 <byorgey> phlpp: well, to start, you only have to go up to sqrt n, not n/2
13:22:10 <allbery_b> also keep in mind that FFI uses threading behind your back
13:22:31 <phlpp> byorgey: but, then, i'm missing the 5
13:22:45 <phlpp> when e.g. i want to get proper divisors of 10
13:22:51 <byorgey> phlpp: no you aren't.  you find the 5 when you find the 2. =)
13:23:02 <phlpp> ah, yeah :D
13:23:42 <byorgey> phlpp: if you want to get more sophisticated, you can figure out a way to generate all the proper divisors, given a list of prime divisors.  that's faster for large numbers.
13:23:47 <phlpp> it's really hard work for me when thinking in ways of for and while loops, but have to use recursion (which is indeed much more elegant, but the transformation is harder)
13:24:07 <byorgey> phlpp: you'll get used to it. =)
13:24:21 <hellblade> dons: no idea what Data.Binary is but i make no use of binary data in my code: http://hpaste.org/3352
13:24:26 <shachaf> phlpp: Also, you don't have to use recursion yourself.
13:24:35 <byorgey> phlpp: also, you really shouldn't have to explicitly use recursion all that much.  there are plenty of functions in the Prelude that do it for you in certain common ways.
13:24:36 <shachaf> > (\n -> filter (\i -> n `mod` i == 0) [1..n `div` 2]) 10 -- For example.
13:24:38 <lambdabot>  [1,2,5]
13:25:10 <byorgey> phlpp: like iterate, takeWhile, foldl/foldr, map, filter...
13:25:30 <phlpp> alright, yeah, i got to know this yesterday ;)
13:25:59 <shachaf> > (\n -> [i | x <- [1..n `div` 2], n `mod` i == 0]) 10 -- With a list comprehension
13:26:00 <lambdabot>   Not in scope: `i'
13:26:31 <shachaf> > (\n -> [i | i <- [1..n `div` 2], n `mod` i == 0]) 10 -- With a list comprehension
13:26:32 <lambdabot>  [1,2,5]
13:27:33 <quicksilver> allbery_b: 99% of the time people use fork(), including (if I understand right) the examples CosmicRay was talking about, it's immediately before an exec()
13:28:00 <quicksilver> allbery_b: that's a common idiom since it was (is?) the ony way you get to spawn subprocesses in a unix-style system
13:28:06 <CosmicRay> quicksilver: yes.  often there is some dup2() or close() activity, but very little else
13:28:16 <quicksilver> right, that's part of the game
13:28:22 <quicksilver> fork, fix up the FDs, exec
13:28:33 <quicksilver> maybe fork again for good measure
13:28:35 <allbery_b> right, I'm not sure if ghc runtime caches os threads for FFI calls tough
13:28:37 <quicksilver> to break from a process group
13:29:05 <CosmicRay> so if runInteractiveProcess, which uses these very calls, is allowed to work, why not let us do the work ourselves?
13:29:19 <allbery_b> (and this  use case is exactly why POSIX worries about fork() secretly being vfork(), which is specifically optimized for this common case)
13:29:20 <CosmicRay> I am not satisfied with the completeness of System.Process relative to System.Posix.Process
13:29:39 <quicksilver> I'm in total agreement :)
13:29:50 <dons> i'm not satisified with its level of abstraction
13:30:02 <CosmicRay> dons: you want it more or less abstraced?
13:30:11 <dons> more. a la newpopen
13:30:27 <byorgey> hellblade: the 'rest' function defined within the scope of 'split' is missing some patterns.
13:30:32 <dons> readProcess :: FilePath                     -- ^ command to run -> [String]                     -- ^ any arguments -> String                       -- ^ standard input -> IO (Either ExitCode String)  -- ^ either the stdout, or an exitcode
13:30:36 <dons> hmm
13:30:41 <byorgey> hellblade: in particular it fails if the list is empty.
13:30:43 <dons> firefox sucks at pasting
13:30:48 <dons> http://www.cse.unsw.edu.au/~dons/code/newpopen/System/Process/Run.hs
13:30:49 <lambdabot> http://tinyurl.com/2f7j8l
13:31:13 <dons> we should have a standard, obvious popen, competitive with perl's
13:31:22 <CosmicRay> dons: but there are cases where performance would dictate piping between two external processes without having a Haskell process copying (and converting back and forth between Strings) between them
13:31:32 <quicksilver> I think forcing stdin to be a string is quite restrictive
13:31:41 <quicksilver> I think it's useful, of course, in certain cases
13:31:57 <alexj> dons: Does System.Process.Run work on windows?
13:31:58 <quicksilver> but in general you want the ability to make a patchwork of fds between proceses
13:32:06 <dons> alexj: i've not tested it, but I don't see why not.
13:32:12 <dons> it just uses System.Process, which does
13:32:29 <quicksilver> alexj: I"m quite sure it's supposed to...
13:32:55 <fasta> How can I force GHC to write out the profile report before it's done?
13:33:05 <dons> +RTS -S -RTS iirc
13:33:14 <dons> there's some other stuff for incremental profiling
13:33:26 <quicksilver> dons: on a tangent, I wonder why cse.unsw.edu.au shows haskell files in my firefox, while haskell.org makes my firefox download them...
13:33:29 <hellblade> byorgey: the problem is not in split. it only appears when i run "encode myStr"
13:33:38 <quicksilver> dons: this never used to happen to me..
13:33:41 <dons> quicksilver: no idea. its cool
13:33:54 <dons> cse does something weird with its apache, other files behave differntly too
13:33:55 <alexj> quicksilver: different mime types?
13:34:04 <quicksilver> until about 3 weeks ago I could browse library source on haskell.org
13:34:10 <quicksilver> since then it insists on downloading them
13:34:16 <quicksilver> I don't know if the change is my end or their end
13:34:19 <CosmicRay> quicksilver: look at the content-type they're sending
13:35:06 <fasta> dons: the file Main.stat gets created, however it's empty.
13:35:43 <dons> fasta, check the docs for getting incremental GC info
13:36:24 <fasta> dons: it seems it doesn't collect a lot of garbage.
13:36:45 <fasta> I.e. runs in constant space
13:37:04 <quicksilver> ah yes
13:37:20 <quicksilver> cse is serving it as text/plain
13:37:20 <dons> haskell's cute like that, fasta :)
13:37:29 <quicksilver> haskell.org as text/x-haskell
13:37:39 <quicksilver> sadly the less correct type is the more useful :P
13:38:29 <olsner> more browsers should have the "open in browser" option
13:38:52 <takamura> hi
13:40:12 <byorgey> hellblade: sorry, wrong 'rest', it's the one in 'encode'.
13:40:24 <quicksilver> U vageuly recall
13:40:24 <quicksilver>   
13:40:31 <byorgey> hellblade: I ran 'encode myStr' and got the following error: *** Exception: U.hs:(58,2)-(60,21): Non-exhaustive patterns in function rest
13:40:35 <quicksilver> excuse that :)
13:40:45 <quicksilver> I vaguely recll there is a 10 year old firefox bug on this
13:41:16 <fasta> quicksilver: firefox isn't even that old
13:42:57 <phlpp> nah
13:43:03 <phlpp> wrong result :C
13:44:35 <puusorsa> about the divisors .. got me thinking, no odd number is divisible by even number, right?
13:45:53 <kscaldef>  puusorsa: right
13:46:03 <EvilTerran> divisibility is transitive
13:46:16 <bringert> @seen dcoutts
13:46:16 <lambdabot> dcoutts is in #gentoo-haskell, #haskell-overflow, #haskell and #ghc. I don't know when dcoutts last spoke.
13:46:26 <bringert> @seen dcoutts_
13:46:27 <lambdabot> I saw dcoutts_ leaving #gentoo-haskell, #haskell, #ghc and #haskell-overflow 56m 57s ago, and .
13:46:41 <EvilTerran> a `divides` b && b `divides` c ==> a `divides` c
13:46:55 <hellblade> byorgey: your solution worked for me. i think we have an extended Prelude in our university hugs installation cause some code doesnt work in my ubuntu OS as well
13:46:57 <hpaste>  (anonymous) pasted "(no title)" at http://hpaste.org/3353
13:47:40 <phlpp> puusorsa: every even number is divisible by 2
13:47:47 <phlpp> and no odd number is diviisible by 2
13:47:49 <phlpp> q.e.d.
13:47:52 <puusorsa> hooray!
13:47:55 <phlpp> \o/
13:47:56 <phlpp> :P
13:48:04 <phlpp> i'm a  bit late, i know
13:48:24 <EvilTerran> er... deleted? more spam?
13:48:42 <phlpp> byorgey: yay, finished problem 21 :P
13:48:43 <puusorsa> :(
13:49:03 <phlpp> isAmicableNumber n = (n == ((sum . divisors . sum . divisors) n)) && (n	/= (sum	$ divisors n))
13:49:09 <glguy> anonymous unlabeled pastes are considered temporary
13:49:19 <byorgey> phlpp: =D
13:49:20 <puusorsa> it was supposed to be
13:49:21 <phlpp> is it possibile to write this a bit more.. not messy?
13:49:22 <phlpp> ;)
13:49:24 <puusorsa> but not THAT temporary
13:50:09 <EvilTerran> isAmicableNumber n = n == (sum . divisors . sum . divisors $ n) && n /= sum (divisors n) -- enough better?
13:50:18 <hpaste>  (anonymous) pasted "unneccessarily long divisors" at http://hpaste.org/3354
13:50:52 <alexj> @seen lemmih
13:50:52 <lambdabot> lemmih is in #haskell. I last heard lemmih speak 56m 35s ago.
13:51:23 <EvilTerran> phlpp, i wouldn't consider the odd/even distinction particularly necessary
13:51:47 <EvilTerran> also, why're you going to n/2 in particular?
13:51:49 <pastorn-rr> phlpp: let f = sum . divisors in n == ( f . f $ n ) && n /= f n
13:53:24 <phlpp> EvilTerran: i know, n/2 are few steps to far
13:53:53 <EvilTerran> > takeWhile (\i -> i*i <= 16) [1..]
13:53:55 <lambdabot>  [1,2,3,4]
13:54:36 <EvilTerran> > takeWhile ((20>=).(^2)) [1..]
13:54:38 <lambdabot>  [1,2,3,4]
13:54:51 <EvilTerran> (if you prefer things pointsfree)
13:56:31 <bos> slides from my Ignite SF talk last night: http://www.red-bean.com/~bos/IgniteSF.pdf (4.3MB)
13:56:36 <dons> sweet.
13:56:49 <bos> warning: the slides are almost devoid of actual words, and are mostly graphics
13:56:55 <fasta> I thought GHC warned when you wrote down a =a ... ARG
13:57:02 <dons> why would it?
13:57:14 <dons> solving the halting problem isn't its job :)
13:57:18 <fasta> Or at least do <<loop detected>>
13:57:20 <dons> > let a = a in a
13:57:22 <lambdabot>  Exception: <<loop>>
13:57:36 <dons> the runtime might spot the blackhole
13:57:38 <dons> for some cases
13:57:55 <EvilTerran> > let f x = f x in f 1
13:57:59 <lambdabot> Terminated
13:58:02 <fasta> Well, the case a = a is quite easy. Then again, I shouldn't be writing that...
13:58:03 <alexj> bos: how do I get on those lists.  what is ignitesf?  I would have come to this talk!
13:58:04 <EvilTerran> but not all cases!
13:58:20 <fasta> It's a 4 char difference.
13:58:43 <allbery_b> @go Ignite! SF
13:58:45 <lambdabot> http://upcoming.yahoo.com/event/263028/
13:58:45 <lambdabot> Title: Ignite SF at DNA Lounge (Tuesday, October 16, 2007) - Upcoming
13:58:46 <phlpp> lol
13:58:51 <bos> alexj: there wasn't a list, it's an occasional night of lightning talks that O'Reill runs
13:59:01 <fasta> One if you don't count permuted letters.
13:59:04 <bos> i'm very proud of my slide deck.
13:59:04 <phlpp> J is some messy stuff
13:59:06 <phlpp> :F
13:59:14 <EvilTerran> DNA? that's JWZ's place, isn't it?
13:59:17 <bos> yep
13:59:29 <EvilTerran> that's awesome, right there
13:59:38 <fasta> They are going to bomb sourceforge?
13:59:50 <EvilTerran> geek running a nightclub :D
14:00:08 <bos> the dna lounge isn't anything special. just another small poky dark nightclub.
14:00:41 <TomMD> In the 'Of Phantom types and Type Extensions' thread I started on haskell-cafe, I don't understand why the provided solution works while a solution that defines 'getAddressType' as a top level function does not work.  Any pointers?
14:00:54 <dons> yay, andrew resubscribed!
14:01:24 <byorgey> phlpp: J the programming language?
14:01:30 <byorgey> bos: awesome slides =)
14:01:33 <phlpp> yep
14:01:42 <phlpp> got some solution in J for this problem
14:01:44 <phlpp> ._.
14:01:44 <byorgey> phlpp: hehe, J has a special place in my heart =)
14:01:49 <phlpp> hehe
14:01:58 * bos is glad. andrew started out very annoying, but once he throttled the offtopic noise, was fine to have around.
14:02:11 <bos> byorgey: thanks!
14:02:14 <byorgey> phlpp: I actually did a lot of the project euler problems in J
14:02:27 <alexj> bos: missed you at bayfp.  did you get a chacnce to see the talk?
14:02:38 <bos> alexj: no, sorry, i was speaking at another conference
14:03:39 <bparkis> abstraction (function definition) somehow makes programs shorter
14:03:43 <alexj> bos: happs talk recorded online with slides at: http://www.bayfp.org/blog/2007/10/16/alex-jacobson-on-happs-videos-slides/
14:03:51 <bos> alexj: nice
14:03:52 <phlpp> byorgey: you like messy source? ;)
14:04:07 <alexj> video very fuzzy at the beginning but then cleans up later
14:04:10 <bparkis> but at some level, if two languages have the same alphabet and one only allows basic instructions whereas the other has some kind of abstraction mechanism, both languages can express the same number of programs at a given length
14:04:35 <bparkis> i.e. the number of programs in one language that are 500 symbols long is approximately the same as the number of programs in the other language that are 500 symbols long
14:04:53 <bparkis> so why, theoretically, does abstraction seem to make programs shorter?
14:05:05 <byorgey> phlpp: it only looks messy.  it's actually quite elegant.
14:05:11 <kscaldef> it makes interesting programs shorter?
14:05:21 <bparkis> define interesting
14:05:29 <shapr> bparkis: Abstraction is about communication with humans. Separation of concers makes it easier for us to think about the problem.
14:05:31 <kscaldef> define "seems"
14:05:33 <phlpp> byorgey: oh ok
14:05:39 <shapr> concerns*
14:05:56 <bparkis> well by "seems" i mean that for most any program that a _human_ wants to write, abstraction makes it more concise
14:06:09 <kscaldef> then that's what interesting means :-)
14:06:11 <shapr> bparkis: I got a cool book on mental arithmetic a coupla years ago, and it's all about abstraction.
14:06:30 <byorgey> phlpp: the hardest part is remembering what all the operators do =)
14:06:31 <bparkis> an interesting program means that a human wants to write it? but that's just a tautology and doesn't offer any explanation
14:07:07 <hpaste>  (anonymous) annotated "unneccessarily long divisors" with "less slow divisors" at http://hpaste.org/3354#a1
14:07:08 <kscaldef> why would we create a particular abstraction if not to make the things we want to do easier?
14:07:19 * gene9 thinks IMHO  theoretically,abstraction makes programs not shorter, but it gives them a chance, I mean support and extencibility
14:07:42 <byorgey> bparkis: wouldn't you think that a language with the abstraction mechanism would have more *valid* programs that are 500 symbols long than the other language?
14:08:53 <bparkis> no not necessarily byorgey
14:08:58 <bparkis> in fact the opposite would be true, most likely
14:09:07 <bparkis> for example let's say i have a "sum" language
14:09:35 <bparkis> programs in this language consist of a string of 0's and 1's and the output is the sum of all the 1's in the program, to the power of the sum of all of the 0's in the program
14:09:43 <byorgey> phlpp: are you the one posting the 'divisors' stuff?
14:09:51 <bparkis> the number of programs at length n is the maximum possible, namely 2^n valid programs
14:09:54 <bparkis> but there is no abstraction
14:10:17 <bparkis> and if you added abstraction you would probably decrease the number of valid programs at length n
14:10:27 <bparkis> because you would add more syntax with rules that can be broken
14:11:47 <bparkis> here's what i think it the benefit of abstraction is, after considering it for the past 5 minutes:  i'll bet it has something to do with concise program _specification_
14:12:03 <byorgey> bparkis: but that's not a good example since that language isn't anywhere close to being turing-complete.
14:12:33 <bparkis> that for some reason abstraction allows you to more concisely write programs that can be concisely _specified_ in some specification language (spec language consists of invariants about the program)
14:12:44 <puusorsa> byorgey, i am
14:12:51 <byorgey> ah, ok
14:13:11 <byorgey> puusorsa: that second paste makes sense, and should indeed be faster than the first -- asymptotically so
14:13:18 <puusorsa> it is
14:13:59 <puusorsa> tried divisors 555555555 for example,. the latter one is instantenous in ghci, other takes a minute or so
14:14:14 <phobes> bparkis:  There is a standard big-O like definition that can explain the power of abstraction
14:14:23 <bparkis> byorgey: well then how about we have a computer with a small instruction set and every word corresponds to an instruction
14:14:37 <phobes> bparkis:  An abstract language can do everything a non-abstract language can with a bounded amount of extra syntax
14:14:38 <bparkis> no abstraction, just machine language, but any random program of length n words is valid
14:15:00 <bparkis> whereas a more complicated language would have more invalid programs due to more syntax
14:15:59 <phobes> bparkis:  and then you need to talk about global program transformations for that definition to not just mean turing complete
14:16:40 <phlpp> byorgey: no
14:16:46 <bparkis> well to some extent it is all about a constant overhead
14:17:07 <bparkis> because given a language with no abstractions that's turing complete you can probably write another language in it that has abstractions, then write your program in that
14:17:22 <bparkis> so it's just a constant overhead to write the new program
14:17:30 <byorgey> phlpp: ok, sorry, it was puusorsa =)
14:17:48 <pgavin> @seen dcoutts
14:17:48 <lambdabot> dcoutts is in #gentoo-haskell, #haskell-overflow, #haskell and #ghc. I don't know when dcoutts last spoke.
14:18:15 <bparkis> so let's say that constant overheads matter
14:18:20 <ndm> @seen dons
14:18:20 <lambdabot> dons is in #xmonad and #haskell. I last heard dons speak 16m 4s ago.
14:18:36 <bparkis> suppose it's not about asymptotic size it's about absolute size
14:18:55 <phobes> bparkis:  Have you seen this?  www.ccs.neu.edu/scheme/pubs/scp91-felleisen.ps.gz
14:19:07 <bparkis> no
14:19:17 <phobes> It's a formal definition of expressiveness
14:19:24 <phlpp> http://projecteuler.net/index.php?section=problems&id=30
14:19:25 <lambdabot> Title: Project Euler
14:19:29 <phlpp> thats really surprising
14:19:44 <bparkis> i don't know if this is really about expressiveness, i'm just talking about program length
14:19:55 <phlpp> why aren't there only 3 numbers, which can be written as the the sum of the fourth power of their digits?
14:19:58 <bparkis> is that the same as expressiveness?
14:21:07 <phlpp> i mean is there a restriction that fourth power means -> only 4 digits?
14:21:09 <phobes> You're interested in number of keystrokes to solve a problem?
14:21:27 <Excedrin> does project euler require registration in order to view the problems? (the url goes to some about page)
14:21:33 <phlpp> otherwise i can't imagine how anyone could proof this, and my suggested restriction isn't describe in the task, is it?
14:21:49 <phlpp> Excedrin: you have to, if you want to check in your solution
14:21:51 <phlpp> i think
14:21:57 <phobes> (oops, must leave, good luck)
14:22:14 <Excedrin> oh, interesting
14:22:19 <phlpp> ah yeah
14:22:21 <Excedrin> http://projecteuler.net/index.php?section=view&id=30 <- this link works
14:22:22 <phlpp> actually you have to register
14:22:22 <lambdabot> Title: Project Euler
14:22:24 <phlpp> oh
14:22:34 <phlpp> http://projecteuler.net/index.php?section=view
14:22:35 <lambdabot> Title: Project Euler
14:22:38 <phlpp> ;)
14:22:40 <phlpp> this should work for you
14:22:41 <bparkis> yes phobes just because it's simpler
14:23:02 <phlpp> byorgey: still there?
14:23:04 <bparkis> it's not incredibly meaningful to practical problems but it's a simpler question to ask
14:23:17 <bparkis> about program length instead of trying to get a meaningful definition of expressiveness
14:23:25 <byorgey> phlpp: I'm still here, I'm trying to figure out what you are asking
14:23:37 <phlpp> oh
14:23:56 <phlpp> see the problem page i posted few minutes ago
14:24:08 <phlpp> "Surprisingly there are only three numbers that can be written as the sum of fourth powers of their digits:"
14:24:23 <byorgey> yes
14:24:26 <bparkis> and in fact let's only ask about program length for languages where every program is valid
14:24:28 <phlpp> i mean, i can't imagine a proof on this.
14:24:36 <byorgey> oh, ok, I see what you are asking
14:24:44 <bparkis> so as to avoid the whole mess about syntactically invalid programs
14:24:52 <byorgey> because you don't see how you could place a limit on the number of digits in the numbers?
14:24:59 <byorgey> that's not hard, actually
14:24:59 <phlpp> my 'real' problem is, i don't know till what number (10^4, 10^5,...l) i have to test
14:25:02 <bparkis> so at length n, there are c^n valid programs over an alphabet of length c
14:25:27 <bparkis> and compare those c^n programs for a language with no built-in abstractions, to c^n programs for a language that does have built-in abtractions
14:25:38 <bparkis> and let's not even require that either of those languages be turing-complete
14:25:40 <phlpp> hm, yes, and somehow this is related to my misunderstanding for the existence of any proof on the ^4 stuff
14:26:08 <byorgey> phlpp: if you add up the 4th powers of the digits of an n-digit number, you get at most n*9^4
14:26:54 <byorgey> phlpp: and for all n > m (for some m) that gives you a number with less than n digits.
14:27:12 <byorgey> so it can't give you the original number back.
14:27:17 <bparkis> so what is the "best" programming language, measured by the conciseness of its programs?  in one sense, the only way to distinguish two programming languages is in the number of redundant programs
14:27:26 <byorgey> > 5 * 9^4
14:27:28 <lambdabot>  32805
14:27:33 <bparkis> that is, the number of programs that compute the same value as some other program in the language
14:27:35 <phlpp> hm
14:27:49 <byorgey> > length . show $ 5*9^4
14:27:50 <lambdabot>  5
14:27:57 <bparkis> a language with no redundancy would have the "shortest" programs on average
14:28:13 <phlpp> so all numbers i actually have to figure out in the task are between 10^4 and 10^5, right?
14:28:18 <bparkis> meaning that for a length n, it can express the greatest number of programs with <= n symbols
14:28:21 <byorgey> > map (\n -> (n,length . show $ n*9^4)) [1..30]
14:28:23 <lambdabot>  [(1,4),(2,5),(3,5),(4,5),(5,5),(6,5),(7,5),(8,5),(9,5),(10,5),(11,5),(12,5),...
14:28:31 <bparkis> number of distinct programs that compute different things
14:28:48 * FMota thinks lazyness can and should be restricted to when it's strictly necessary (e.g. codata), or when it's explicit. Then again, I'm in #haskell, so I'l probably get jumped on.
14:29:15 <phobes> bparkis:  (back for sec)  But that's not a particularly good metric for anything, since the language that just prints its source has a perfect 2^n rating by that measurement, but isn't useful to anyone
14:29:20 <byorgey> phlpp: no, I think they could be bigger than that
14:29:24 <byorgey> phlpp: I'm not sure
14:29:25 <bparkis> yes that's right phobes
14:29:27 <phlpp> hmpf
14:29:37 <byorgey> phlpp: but there must exist an upper bound =)
14:29:41 <phlpp> yeah
14:29:42 <bparkis> so the question is, how do you distinguish a language that just prints its source from a language that does something useful?
14:29:56 <bparkis> because they both can express an equal number of concepts at a given length
14:29:58 <phlpp> ah ok i think i did some
14:30:12 <bparkis> and i think that the answer has to be in the program specification
14:30:31 <phlpp> wrong assumption
14:30:41 <bparkis> that a language with abstraction somehow has shorter programs _for a specification of a given length_
14:30:42 <phobes> bparkis:  I think this is more about 'huffman coding' ... keeping the programs people actually want to write short
14:30:44 <phlpp> i aussme(d), that the upperbound for ^4 is 10^3
14:31:08 <bparkis> so let's say i give the specification 'a program that outputs n^2 for 0 <= n <= 40'
14:31:18 <phlpp> seems to be that's not proven nor said ;)
14:31:35 <bparkis> a language with abstraction can follow that specification in not many more characters than it took to say it just then
14:31:54 <bparkis> a language without abstraction--or, say, a non-turing complete language--might require much more characters
14:32:08 <phobes> I'm not sure that definition will capture what abstraction is about though
14:32:16 <bparkis> so what's meaningful is how short are the programs you write, _relative to your specification of them_
14:32:31 <bparkis> if you can write a short program for a short specification, you have a good language
14:32:59 <MyCatVerbs> bparkis: I know at least one language with wonderful abstraction that can't express that in a non-insane quantity of characters: unlambda.
14:33:25 <opqdonut> :D
14:33:36 <byorgey> phlpp: right.
14:33:45 <bparkis> unlambda has no abstraction MyCatVerbs
14:33:51 <bparkis> it's lambda calculus with abstraction taken out
14:33:58 <MyCatVerbs> bparkis: how is lambda calculus not abstract?
14:34:53 <opqdonut> has there been work on "compiling" lambda calculus into SKI?
14:35:09 <phobes> Isn't that what @pl does?
14:35:10 <bparkis> lambda calculus is abstract, unlambda is not lambda calculus
14:35:18 <bparkis> it lacks named variables
14:35:27 <byorgey>  @pl is a bit more sophisticated than that =)
14:35:48 <FMota> unlambda is combinatory logic, no?
14:36:13 <bparkis> yeah which is not abstract
14:36:39 <FMota>  indeed
14:36:44 <MyCatVerbs> opqdonut: SKI?
14:36:59 <MyCatVerbs> opqdonut: is that where you slide down a hillside to pass the time while waiting for your code to compile?
14:37:06 <FMota> opqdonut: that's ... mostly trivial
14:37:33 <opqdonut> FMota: do you have a pointer for the algorithm?
14:37:41 <byorgey> Olathe: funny coincidence, my wife just called and said she randomly made pumpkin pie today! =D
14:37:46 <FMota> http://www.wikipedia.org/wiki/combinatory_logic has examples of how to do so.
14:37:58 <bparkis> but anyway, if you measure programming language quality by the length of the program relative to the specification length, it also depends on what specification language you use
14:38:04 <opqdonut> ah, i've only been reading the ski combinator calculus page
14:38:06 <FMota> although I couldn't really tell you the best way to go about it
14:38:24 <FMota> (algorithmically speaking)
14:38:27 <bparkis> because if you use the specification language that just consists of asking whether the program outputs a given number, with the number given in binary, then there is no benefit to abstraction
14:38:40 <FMota> ... is lambdabot down?
14:39:03 <FMota> > 2 + 2
14:39:07 <lambdabot>  4
14:39:14 <FMota> that's weird...
14:39:41 <bparkis> so really, a good programming language is one that has a concise mapping from the specification language to the programming language
14:39:58 <FMota> bparkis: tha'ts only part of it, though
14:40:02 <FMota> *that's
14:40:02 <bparkis> a good programming language is a "good fit" for the specification language being used
14:40:12 <bparkis> and a bad programming language is a "bad fit" for the specification language being used
14:40:20 <FMota> right...
14:40:24 <byorgey> MyCatVerbs: http://en.wikipedia.org/wiki/SKI_combinator_calculus.  In Haskell, S = ap, K = const, I = id.
14:40:26 <lambdabot> Title: SKI combinator calculus - Wikipedia, the free encyclopedia
14:40:35 <FMota> but you can have multiple, extremely different languages, be good fits
14:40:41 <FMota> depending on what you think is best.
14:40:46 <bparkis> true and then they are probably both good languages
14:41:05 <bparkis> assuming (maybe a big assumption) that it is not difficult to write programs in them
14:41:15 <MyCatVerbs> :t ap
14:41:17 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m (a -> b) -> m a -> m b
14:41:18 <FMota> I.e., you could use Python or Ada for the same things, and It's a matter of personal preference -- if you get to choose.
14:41:30 <MyCatVerbs> :t liftM2
14:41:30 <bparkis> i.e. let's say that the programing language is the list of scheme programs that have been encrypted using a key that you don't know
14:41:32 <lambdabot> forall a1 a2 r (m :: * -> *). (Monad m) => (a1 -> a2 -> r) -> m a1 -> m a2 -> m r
14:41:43 <bparkis> then it's very hard to write in that language, even though it's "as good as" scheme
14:41:54 <bparkis> meaning its program lengths are about the same as scheme's
14:42:04 <FMota> program length is unimportant
14:42:10 <FMota> to some extent
14:42:26 <bparkis> program length in the number of primitives you use is important imo
14:42:30 <MyCatVerbs> bparkis: yes, but that's a deliberately obfusticated language.
14:42:42 <bparkis> i.e. it doesn't matter whether you say 'x' or 'xcoordinateofthesquare' as a variable name
14:42:56 <bparkis> but it does matter how many variable names you use
14:43:04 <byorgey> MyCatVerbs: I should mention that when I say S = ap, I mean particularly in the ((->) e) monad.  So ap :: (e -> a -> b) -> (e -> a) -> e -> b
14:43:07 <FMota> More important than program length is being able to grasp what all of the individual blocks (modules) does, and for each of them now what each function does, and then for each function know how it does it
14:43:29 <FMota> and it should be possible to keep one of these levels of abstraction entirely in your head
14:43:33 <bparkis> which is, FMota, the same as finding out what the code invariants are
14:43:36 <byorgey> MyCatVerbs: in particular, ap f g x = f x (g x)
14:43:42 <MyCatVerbs> byorgey: ((->) e)? How the Hell is that read?
14:43:50 <bparkis> so in a good language it should be simple for a human to determine code invariants
14:44:12 <FMota> well.
14:44:13 <FMota> yes
14:44:14 <bparkis> i.e. properties relating to a given block of code that must always be true
14:44:27 * MyCatVerbs occasionally comes up against (->) in types and has no clue what that means.
14:44:47 <byorgey> MyCatVerbs: (->) is a type constructor, just like, e.g. Maybe.
14:44:50 <FMota> the important thing, for me anyways, is being able to grok what is going on, without having to dig into too much detail
14:45:06 <bparkis> i think understanding a program, and determining the invariants of the program, are much the same process
14:45:14 <byorgey> MyCatVerbs: Maybe a is the type of things which might yield an 'a' or might not.  (->) a b is the type of functions from a to b.
14:45:21 <bparkis> the only difference being, the former is less formal than the latter
14:45:22 <MyCatVerbs> byorgey: ahhhhh! But that's fscking evil! Specifically, there's the confusion between (->) and ->. :/
14:45:29 <byorgey> MyCatVerbs: although that's usually written infix, (a -> b).
14:45:33 <MyCatVerbs> byorgey: wait, wha
14:45:44 <byorgey> MyCatVerbs: well, -> is infix, and (->) is prefix.  just like + is infix and (+) is prefix. =)
14:45:52 <FMota> btw
14:45:53 <MyCatVerbs> byorgey: oh I see. So what the Hell does ((->) e) refer to, then?
14:46:03 <FMota> (a ->)   and ((->) a)   mean the same thing, right?
14:46:11 <byorgey> FMota: yes.
14:46:22 <FMota> :/ IMO people should use the former.
14:46:26 <omnId> FMota: except type sections aren't supported
14:46:30 <MyCatVerbs> k, but what the smeg does (a ->) mean? That makes no sense whatsoever.
14:46:35 <FMota> tyhpe sections?
14:46:39 <omnId> MyCatVerbs: not quite a function yet
14:46:49 <FMota> *omnId: type sections?
14:46:51 <MyCatVerbs> omnId: so how do you go about making it a function?
14:46:51 <omnId> FMota: (Type `TypeOp`)
14:47:01 <omnId> MyCatVerbs: give it a type parameter!
14:47:08 <omnId> ((->) Int) Char
14:47:13 <omnId> = Int -> Char
14:47:15 <byorgey> MyCatVerbs: it's a partially applied type.  it represents functions which take something of type e.
14:47:31 <FMota> oh, you mean type constructors that happen to be operators have to be either infix or prefix, then?
14:47:41 <omnId> FMota: yeah
14:47:45 <FMota> that's weird.
14:47:53 <omnId> just not implemented
14:48:07 <bparkis> and invariants of the program are statements in the specification language of the program
14:48:13 <MyCatVerbs> omnId: gah. Example please, and how to actually use it? Also, what's the name for that kind of type, so that I can google for it, please?
14:48:19 <omnId> there doesn't seem to be any reason in principle why it can't be added.
14:48:37 <bparkis> i might specify "the program on input n returns the value of n^2" and that's a program specification
14:48:49 <omnId> MyCatVerbs: usually it's called reader, like the newtype that encapsulates it.
14:48:52 <bparkis> or i might realize "oh, this function returns the value of n^2" and that's a code invariant
14:49:17 <omnId> ((->) Int) "Int reader"
14:49:41 <MyCatVerbs> omnId: could you throw an example into lambdabot that I can play with, please?
14:50:03 <omnId> chr :: IntReader Char, given the alias type IntReader = (->) Int
14:50:18 <Saizan> > ap (*) (+1) $ 6
14:50:26 <lambdabot>  42
14:51:40 <omnId> > (do { c <- chr ; return (toUpper c) }) 97 -- here I use do notation to extract the result Char from the chr action (Which is an action in the (->) Int monad)
14:51:41 <lambdabot>  'A'
14:52:26 <omnId> @type chr
14:52:28 <lambdabot> Int -> Char
14:52:58 <phlpp> byorgey: oh, 99999 isn't a good upper bound
14:53:19 <phlpp> found a num that fulfilles the condition > 99999: 194979
14:53:51 <MyCatVerbs> omnId: no do-notation, that's harmful. ;)
14:53:56 <byorgey> > 5*9^5
14:53:57 <lambdabot>  295245
14:54:03 <omnId> > (chr >>= \c -> return (toUpper c)) 97 -- without, then :)
14:54:03 <lambdabot>  Unbalanced parenthesis
14:54:10 <phlpp> yeah, thats a good upper bound
14:54:12 <omnId> > (chr >>= \c -> return (toUpper c)) 97 -- without, then (:  :)
14:54:13 <lambdabot>  'A'
14:54:14 <phlpp> 10^6 is to high
14:54:23 <phlpp> [1,4150,4151,54748,92727,93084,194979]
14:54:24 <phlpp> \o/
14:54:26 <byorgey> phlpp: yup, 5*9^5 is six-digits long, so 99999 isn't a high enough upper bound.
14:54:35 <MyCatVerbs> > (chr >>= return . toUpper) 97
14:54:36 <lambdabot>  'A'
14:54:59 <Cale> It really is useful to look at the do-notation for that monad though
14:55:02 <MyCatVerbs> k. Where's the I-presume-previously-unbound variable 'chr' coming from, though?
14:55:11 <MyCatVerbs> :t chr
14:55:13 <lambdabot> Int -> Char
14:55:15 <byorgey> @index chr
14:55:15 <lambdabot> Data.Char
14:55:23 <Cale> > (do { x <- id; y <- reverse; z <- map toUpper; return (x,y,z) }) "hello"
14:55:24 <phlpp> byorgey: could you again explain how to get to this "formular"
14:55:25 <lambdabot>  ("hello","olleh","HELLO")
14:55:25 <omnId> (>>=) in the (->) e monad basically composes the functions together but each function in the chain gets the same argument passed to the whole action.
14:55:29 <phlpp> i mean 5*9^5
14:55:33 <omnId> @src (->) (>>=)
14:55:34 <lambdabot> f >>= k = \ r -> k (f r) r
14:55:43 <byorgey> phlpp: well, let's say we have some 5-digit number.
14:55:46 <omnId> f >>= k is a function of some argument, r
14:55:55 <omnId> r is passed to f to get a result
14:55:57 <byorgey> phlpp: we know we want to raise each of its digits to the 5th power and add them.
14:56:07 <byorgey> phlpp: the question is, how big could this sum be?
14:56:11 <omnId> that result is passed to k to make a new function expecting an r
14:56:27 <omnId> r is passed to this new function
14:56:31 <byorgey> phlpp: well, the biggest it could be is if all the digits are equal to 9, in which case we get 5 * 9^5 as the sum
14:56:34 <byorgey> phlpp: right?
14:56:46 <phlpp> yeah
14:56:53 <byorgey> > 5 * 9^5
14:56:54 <lambdabot>  295245
14:56:59 <omnId> @src (->) return
14:57:00 <lambdabot> return = const
14:57:06 <phlpp> ah ok
14:57:09 <omnId> return ignores the r passed to the final action
14:57:11 <byorgey> but the result is bigger than 99999, so some 5-digit numbers could yield themselves.
14:57:16 <omnId> and just returns the result
14:57:22 <byorgey> > 6 * 9^6
14:57:23 <lambdabot>  3188646
14:57:34 <omnId> return result shared_r = result
14:57:36 <byorgey> phlpp: that's too big also, since that gives 7 digits.
14:57:42 <phlpp> yeah
14:57:53 <phlpp> yeah
14:57:56 <phlpp> my result is correct \o/
14:58:03 <phlpp> sum $ drop 1 $ filter (\x -> (sum . map((^5).read.(:[])) . show $ x) == x) [1..5*9^5]
14:58:13 <omnId> (chr >>= \c -> return (toUpper c)) = (\r -> (\c -> return (toUpper c)) (chr r) r)
14:58:18 <byorgey> phlpp: hooray!
14:58:30 <omnId> = (\r -> (\c -> const (toUpper c)) (chr r) r)
14:58:32 <phlpp> @src return
14:58:32 <lambdabot> Source not found.
14:58:39 <phlpp> @src (:[])
14:58:39 <lambdabot> Source not found. You untyped fool!
14:58:42 <phlpp> :>
14:58:46 <omnId> = (\r -> const (toUpper (chr r))) r)
14:58:48 <hpaste>  (anonymous) pasted "generating tabular data with quickcheck instances, would like something like sequence but for tables" at http://hpaste.org/3355
14:58:52 <phlpp> forgot the other way to do the same..
14:59:03 <omnId> = (\r -> toUpper (chr r))
14:59:17 <tphyahoo> that last hpaste was me.
15:00:02 <MyCatVerbs> @src (->) return
15:00:03 <lambdabot> return = const
15:00:27 <MyCatVerbs> Makes about as much sense as anything else on this planet.
15:00:31 <MyCatVerbs> :t (->) return
15:00:33 <lambdabot> parse error on input `->'
15:00:39 <byorgey> phlpp: for lists, return is the same as (:[]).
15:00:41 <omnId> > return "action results in this" "regardless of the overall argument"
15:00:42 <lambdabot>  "action results in this"
15:00:51 <phlpp> byorgey: yeah
15:01:02 <omnId> the utility is when it's at the end of a (>>=) chain
15:01:16 <omnId> (>>=) has already passed the argument to each action
15:01:38 <hpaste>  nbarterd annotated "generating tabular data with quickcheck instances, would like something like sequence but for tables" with "genBndList is ok. I want genBndTable" at http://hpaste.org/3355#a1
15:01:39 <omnId> return gives the result, ignoring the r that (>>=) passes to it.
15:01:40 <phlpp> byorgey: it's like i just took this pointfree stuff from the squareDigits task, so i had to figure out what it means ;)
15:02:29 <MyCatVerbs> > 4 >>= (2*) >>= (3*)
15:02:29 <lambdabot>   add an instance declaration for (Num (m b))
15:02:39 <MyCatVerbs> > :t (4 >>= (2*) >>= (3*))
15:02:39 <lambdabot>   parse error on input `:'
15:02:42 <MyCatVerbs> :t (4 >>= (2*) >>= (3*))
15:02:44 <lambdabot> forall (m :: * -> *) b. (Num (m (m (m b))), Num (m (m b)), Num (m b), Monad m) => m b
15:02:52 <MyCatVerbs> (4 >>= (2*) >>= (3*)) 5
15:02:54 <omnId> > (*4) >>= (+) >>= div)
15:02:54 <lambdabot>  Unbalanced parenthesis
15:03:05 <omnId> > ((*4) >>= (+) >>= div) 5
15:03:07 <lambdabot>  5
15:03:19 <omnId> @type (>>=)
15:03:20 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> (a -> m b) -> m b
15:03:26 <phlpp> ah
15:03:28 <phlpp> got it ;)
15:03:32 <MyCatVerbs> Where the Hell did \bot get unbalenced parens from there? *couns 'em*
15:03:47 <omnId> (>>=)'s left argument is m a, where m = (->) e, so its a function of one argument to one result.
15:03:50 <MyCatVerbs> > (4 >>= (2*) >>= (3*)) 5
15:03:51 <lambdabot>   add an instance declaration for (Num (t -> b))
15:03:59 <MyCatVerbs> > (4 >>= (2*) >>= (3*)) 5 4
15:04:00 <lambdabot>   add an instance declaration for (Num (t -> t1 -> a))
15:04:13 <omnId> (>>=)'s right argument is a kleisli, it gets the left result and make an m a action
15:04:16 <Saizan> > (return 4 >>= (2*) >>= (3*)) 5
15:04:17 <lambdabot>   add an instance declaration for (Num (t -> b))
15:04:18 <mauke> > (return 4 >>= (2*) >>= (3*)) 5
15:04:19 <lambdabot>   add an instance declaration for (Num (t -> b))
15:04:22 <mauke> haha
15:04:24 <FMota> > 4 >>= (2 *)
15:04:24 <lambdabot>   add an instance declaration for (Num (m b))
15:04:34 <MyCatVerbs> > ((4-) >>= (2*) >>= (3*)) 5 4
15:04:34 <lambdabot>      Occurs check: cannot construct the infinite type: t = t -> a
15:04:35 <lambdabot>     Probabl...
15:04:39 <MyCatVerbs> > ((4-) >>= (2*) >>= (3*)) 5
15:04:40 <lambdabot>      Occurs check: cannot construct the infinite type: t = t -> a
15:04:40 <lambdabot>     Probabl...
15:04:44 <mauke> > (return 4 >>= (2*)) 5
15:04:44 <lambdabot>   add an instance declaration for (Num (t -> b))
15:04:48 <FMota> return 4 >>= return . (2 *)
15:04:51 <omnId> MyCatVerbs: the subsequent actions in (>>=) take two arguments
15:04:58 <FMota> > return 4 >>= return . (2 *)
15:04:59 <lambdabot>   add an instance declaration for (Show (m b))
15:05:07 <MyCatVerbs> > ((4-) >>= (*) >>= (*)) 5
15:05:08 <lambdabot>  -25
15:05:10 <omnId> one the result of the left action, two the shared argument among all the actions
15:05:13 <FMota> :/
15:05:30 <wli> A little odd. There only ever seems to be one superlinear narrowing of the interval. The rest are all bisections.
15:05:46 <omnId> (4-5)*5*5
15:05:50 <omnId> > (4-5)*5*5
15:05:51 <lambdabot>  -25
15:05:57 <MyCatVerbs> omnId: suddenly that makes sense, sort of.
15:06:04 <MyCatVerbs> omnId: now how's it useful? :)
15:06:24 <MyCatVerbs> > ((4-) >>= reti) 5
15:06:25 <lambdabot>   Not in scope: `reti'
15:06:35 <MyCatVerbs> > ((4-) >>= return (2*)) 5
15:06:36 <omnId> MyCatVerbs: raw (->) e is mostly for showing off :)  The encapsulation of the Reader newtype can be useful though.
15:06:37 <lambdabot>  10
15:06:44 <wli> I'd expect the linear and cubic Newtons to get different signs more often.
15:06:52 <omnId> @google reader interpreter dons
15:06:53 <lambdabot> http://cgi.cse.unsw.edu.au/~dons/blog/2006/12/11
15:06:54 <lambdabot> Title: Haskell hacking
15:07:14 <omnId> newtype Reader r a = Reader (r -> a)
15:07:31 <omnId> (modulo the weird record selector for extraction)
15:08:10 <omnId> MyCatVerbs: it's useful when you have a bunch of actions that each require a shared state that they aren't allowed to alter.
15:08:25 <MyCatVerbs> omnId: ah, handy.
15:08:28 <omnId> MyCatVerbs: search that page for "Quick interpreters in the Reader monad"
15:09:17 <omnId> @type local
15:09:19 <lambdabot> forall r (m :: * -> *) a. (MonadReader r m) => (r -> r) -> m a -> m a
15:09:54 <wli> I don't get sqrt2.hs
15:09:57 <omnId> ^ a function function indeed, local modifier action runs action with a state locally modified by modifier
15:10:21 <omnId> "a function function"?
15:10:22 <mauke> wli: why not?
15:10:29 <omnId> a *handy* function!
15:10:36 <phlpp> @src digitToInt
15:10:37 <lambdabot> Source not found. Listen, broccoli brains, I don't have time to listen to this trash.
15:11:01 <wli> loop and longsqrt mystify me
15:11:22 <phlpp> hm, digitToInt seems to be quite fast
15:11:26 <mauke> loop should be easy
15:12:00 <wli> iterate f until you get a Left
15:12:12 <wli> okay
15:12:25 <wli> What's going on with longsqrt?
15:12:50 <mauke> it computes the decimal expansion of a suqare root
15:13:11 <wli> Sure, but how?
15:13:42 <mauke> http://en.wikipedia.org/wiki/Methods_of_computing_square_roots#Decimal_.28base_10.29
15:13:44 <omnId> local f m = m . f -- the r passed to a (local f m) action first goes through f before going into m, this doesn't change r for the subsequent actions in the higher bind chain, though.
15:13:45 <lambdabot> http://tinyurl.com/yk6zgb
15:15:03 <wli> Okay, this is not how I do it.
15:16:42 <wli> Or otherwise not how I learned to do it.
15:17:22 <mauke> I never learned how to do it so I used the algorithm from wikipedia :-)
15:18:27 <dibblego> ?hoogle (Eq a) => a -> [a] -> Maybe Int
15:18:31 <lambdabot> Data.List.elemIndex :: Eq a => a -> [a] -> Maybe Int
15:18:31 <lambdabot> List.elemIndex :: Eq => a -> [a] -> Maybe Int
15:18:47 <nornagon> wli: you could use newton's method to find a root for x^2 - 2 = 0
15:18:58 <wli> In my grandmother's day they had to memorize multiplication tables up to 30x30 and do n-th roots with pencil and paper (not even slide rules).
15:19:15 <nornagon> ouch
15:19:16 <wli> Somewhere along the way things were dumbed down.
15:19:28 <nornagon> i wouldn't say dumbed down
15:19:31 <mauke> multiplication to 10x10, squares up to 20 here
15:19:34 <nornagon> just moved to a higher level
15:19:36 <mauke> no roots
15:20:11 <nornagon> i don't even have to remember multiplication (though we learned up to 12x12 in primary school), all my exams are calculator-friendly
15:20:27 <Philippa_> yeah, there's no particular reason for me to learn roots. 1-10 are all the tables you really /need/
15:20:33 <wli> There were powers up to something above 3.
15:20:38 <Philippa_> and that only if you're working in decimal
15:21:19 <dibblego> @pl \x -> Just (x + 1)
15:21:19 <lambdabot> Just . (1 +)
15:21:24 <mauke> do you do all your multiplications in binary? :-)
15:21:34 <mauke> dibblego: Just . succ
15:21:38 <wli> The antique analytic geometry things were what dated her.
15:21:40 <dibblego> of course, thanks
15:22:20 <wli> Working directly with calc substitutions like x + (x^2+1)^(1/2) etc.
15:24:11 <wli> Plus geometry on conic sections. Nobody does that anymore.
15:24:30 <wli> Euclid-type geometry that is.
15:24:31 <phlpp> wtf
15:24:34 <phlpp> load 3.09
15:24:56 <phlpp> obey teh fibonacci sequence!
15:24:58 <phlpp> ;)
15:26:19 <wli> You still see plenty of mucking around with conics but it's all Cartesian coordinate vector stuff, not Euclid-style constructions.
15:27:22 <wli> The Euclid-style constructions are holdovers from the 1800's.
15:28:17 <dibblego> ?type pred
15:28:23 <lambdabot> forall a. (Enum a) => a -> a
15:32:52 <Taejo> @src pred
15:32:52 <lambdabot> Source not found. Sorry about this, I know it's a bit silly.
15:34:33 <dons> interesting statement on reddit: `The author forgets one very important point: haskell is the language that has the highest proportion of female members in its community of enthusiasts.'
15:34:40 <dons> is that even remotely true?
15:37:08 <pgavin> dons: i wouldn't know :)
15:37:08 <lambdabot> pgavin: You have 1 new message. '/msg lambdabot @messages' to read it.
15:37:33 <wli> It might help reel people in if it were.
15:38:22 <Lemmih> It would be sad if it were true.
15:39:16 <Igloo> I'd estimate we've got around 3%
15:39:32 <dons> Igloo: yes, about 5 females in 150 at the HW :(
15:39:37 <wli> That's very high.
15:39:42 <dons> so that's really bad
15:39:48 <phlpp> > sum $ map digitToInt $ show $ 2^1000
15:39:50 <lambdabot>  1366
15:40:31 <Igloo> Yeah, I wouldn't be that surprised if we were highest
15:42:00 <dons> that's terrible
15:42:08 <Igloo> I don't think we're doing much to chase them away, though. Certainly nowhere near as bad as some other similar IRC channels I've been in
15:42:21 <dons> hmm
15:42:33 <Igloo> Are there IT industry stats anywhere?
15:43:39 <omnId> @vixen lol, parody
15:43:39 <lambdabot> are you really laughing?
15:47:17 <dons> huh 76.0KXMonadContrib-0.4.tar.gz
15:47:18 <dons> getting big
15:47:59 <Botje> darcs likes to ship the whole history around :(
15:48:50 <dons> the .tar.gz isn't a darcs repo, iirc
15:49:03 <dons> that's just src
15:49:20 <dons> good code/comment ratio in the extensions lib
15:49:22 <dons> TOTAL:                 3746   3266
15:49:26 <dons> code/comments
15:49:45 <thoughtpolice> whoohoo. :) now my bot can fully reload its code and it works.
15:49:55 <thoughtpolice> i guess it must have been breaking because my initial thread synchronization stuff was bad...
15:57:26 <dons> thoughtpolice: cool!
16:00:43 <magnusth> just to make sure I've understood something here... "explicit type signatures are necessary when using Phantom Types"... true or false?
16:02:08 <LoganCapaldo> true sometimes?
16:02:16 <Philippa_> not true in and of itself
16:02:16 <monochrom> false sometimes
16:02:29 <dons> `are necessary ' is false
16:02:29 <monochrom> "sometimes" means "some contexts"
16:03:04 <magnusth> so, when can the compiler infer the correct phantom types?
16:03:05 <dons> "explicit type signatures are sometimes required when using phantom types"
16:03:19 <dons> when there's enough type information about the phantom type in the surrounding context
16:03:25 <dons> e.g. if its used twice, you might annotate it once
16:03:33 <magnusth> any exmples posted anywhere?
16:03:41 <dons> should be easy enough to construct one
16:04:19 <magnusth> anyone feeling like constructing an example to help me see the light?
16:04:21 <dons> the point is that full inference can be ambiguous, as there's no concrete value attached to the phantom
16:04:29 <dons> its usually (undefined :: X)
16:04:31 <dons> or some such
16:04:43 <Philippa_> or it might be specified by a constructor
16:05:19 <Saizan> Philippa_: with GADTs you mean?
16:05:34 <dons> Philippa_: do you think this is true, `http://programming.reddit.com/info/5yigz/comments/c029q50'
16:05:52 <Philippa_> Saizan: yeah
16:06:40 <Philippa_> dons: I've no idea if it's true or not. I do know there's a comparatively high proportion of us who're reasonably visible though
16:07:14 <dons> hmm. ok, that's good to know, i think.
16:07:30 <monochrom> eww, I can't just click on that link, due to the ` and '
16:07:37 <dons> sorry
16:07:46 <LoganCapaldo> works for me :)
16:07:48 <dons> its a console habit
16:07:58 <dons> clicking?
16:08:07 <glguy> urxvt properly detects the url
16:08:10 <glguy> and excludes the '
16:08:23 <Philippa_> a lot of GUI clients let you double-click URLs and the like to open them
16:08:25 <magnusth> dons, yes, it's done with the window-chosing-device sometimes called "mouse"
16:08:25 <benny> and even it didn't, it's configurable ;-)
16:08:26 <LoganCapaldo> your irc link detection has failed. So has lambdabot's aparently
16:08:29 <dons> i love this thread, http://programming.reddit.com/info/5yigz/comments/c029put
16:08:30 <lambdabot> Title: programming: Haskell Myths
16:08:35 <dons> about how great ghc 12.5 is
16:08:37 <monochrom> yeah, clicking, it's an xmonad habit :)
16:08:45 <glguy> urxvt has a mode for clicking on URLs, good for irc
16:08:47 <dons> i've had 3 people message me privately asking about ghc 12.5 and why they can't find it
16:09:01 <LoganCapaldo> dons: No!
16:09:13 <LoganCapaldo> Really?
16:09:18 <sieni> dons: haskell seems to be such a language that it makes many of the male community participants to become female
16:09:30 <dons> well, there is that, yes.
16:09:56 <dibblego> wtf is ghc 12.5?
16:10:08 <magnusth> dibblego, clearly it's the shit ;)
16:10:09 <dons> ghc 12.5 is super cool
16:10:10 <glguy> a joke?
16:10:18 <sieni> dibblego: that's the one used on u.s.s. defiant
16:10:18 <gravity> The best release yet!
16:10:21 <dons> the IO monad is implicit, dudes!
16:10:23 <dons> it roxors
16:10:29 <LoganCapaldo> a poor way of constructing an argument
16:10:34 <dons> non terminating programs are detected by the type checker!
16:10:39 <Botje> dibblego: a software package SPJ's grandchild brought back from the future. we're still trying to figure out how to unpack it.
16:10:43 <magnusth> only for true HaX0R5 then?
16:10:45 <dons> chuck norris uses ghc 12.5
16:11:33 <magnusth> dons, I see a new Haskell t-shirt in the making :)
16:11:37 <dons> heh :)
16:12:03 <dons> all C programs run slower than any Haskell compiled with ghc 12.5
16:12:12 <dons> naive fibonacci is not naive with ghc 12.5
16:12:28 <dons> they use ghc 12.5 in soviet russia
16:12:38 <dons> it ran the kgb
16:12:43 * Botje would like a MEMOIZE directive.
16:12:44 <monochrom> there will be soviet russia again?!
16:12:48 <gravity> monads transform you
16:13:08 <dons> monochrom: no, ghc 12.5 uses a time travelling continuation monad to disrupt empires
16:13:19 <monochrom> ...
16:13:21 <dons> lazily, of course
16:13:29 <sieni> dons: have you had too many fosters tonight? ,-)
16:13:59 * monochrom wonders what is dons smoking, you know, it's America... :)
16:14:26 <wli> dons: Are you back in pdx?
16:14:35 <LoganCapaldo> @vera pdx
16:14:37 <lambdabot> No match for "pdx".
16:14:40 <sieni> monochrom: I think he's just been drinking ,-)
16:14:53 <dgriffi3> @where pdx
16:14:53 <lambdabot> I know nothing about pdx.
16:15:05 <dons> wli, yup
16:15:08 <wli> Airport code.
16:15:13 <LoganCapaldo> I've become too reliant on lambdabot
16:15:14 <dons> sieni: fosters! /me slaps sieni
16:15:35 <LoganCapaldo> if she doesn't know about it I don't bother tabbing to a browser
16:15:48 <LoganCapaldo> @go pdx
16:15:50 * magnusth is off, it's late in the UK
16:15:51 <lambdabot> http://www.flypdx.com/
16:15:51 <lambdabot> Title: Port of Portland - Portland International Airport
16:15:57 <LoganCapaldo> score
16:15:58 <wli> dons: we'll have to do lunch sometime
16:16:02 <magnusth> good night good people!
16:16:05 <monochrom> "clicking" and "tabbing" are two great GUI habits :)
16:16:09 <dons> wli, sounds like a plan
16:16:27 <dons> wli, moving into my new apartment this weekend, so in the coming weeks sometime
16:16:41 <sieni> dons: sorry, I forgot you are a purist and only drink finlandia boaka
16:16:43 <dons> know any good vege places?
16:16:57 <dons> sieni: hah, no, fosters is some strange beer you never see in austrlia
16:17:07 <monochrom> Mom: "You lazy bum! Get up and do the chore! What do you think your hands are for?"  Son: "left hand is for tabbing, right hand is for clicking"
16:17:10 <dons> but apparently that's the one everyone else thinks we drink
16:17:37 <wli> dons: I can't name a single one. I'm sort of not in tune with that.
16:17:41 <sieni> dons: well I haven't seen in finland either, in the states they used to have these funny commercials
16:17:45 <dons> ah!
16:17:48 <dons> :)
16:18:04 <wli> Foster's: Australian for dingo p@#$
16:18:19 <dons> i have seen ads for yellowglen wine here in the US that is actually popular in .au
16:18:26 <sieni> dons: "fosas - astralian fo bia"
16:18:33 <dons> yeah, that one :(
16:18:54 <dons> you got the accent wrong though: 'strayan fo bia'
16:19:05 <waern> I drank fosters last saturday :)
16:19:21 <dons> any good?
16:19:24 <Mr_Awesome> they spell beer incorrectly too, iirc
16:19:26 <byorgey> I think they actually showed that one during the Sydney Olympics!
16:19:29 <waern> dons: ok
16:19:31 <dibblego> Australians don't drink Foster's
16:19:33 <wli> I never liked that stuff while I could drink.
16:19:46 <Mr_Awesome> like "bier" or something
16:19:47 <Mr_Awesome> right?
16:19:47 <wli> I was all about Lagavulin.
16:19:50 <dons> dibblego: have you seen these huge blue fosters cans they sell overseas?
16:19:53 <dons> i never saw those in .au
16:20:06 <dons> they're a long neck volume in a can.
16:20:07 <sieni> dons: gotta correct that one: "fostas - straijan fo bia"
16:20:07 <dibblego> dons, yeah, I've seen them; clever marketing :)
16:20:20 <dons> i've not seen long necks here, i must admit
16:21:12 <sieni> but the commercial where the guy threw the boomerang to the head of the guy who was next to the tv
16:21:22 <sieni> and the guy changed the channel
16:21:44 <sieni> and then the voice said "rimyut kontrol"
16:21:58 <sieni> and next "fostas - ostrlin fo bi"
16:23:14 <sieni> hmph
16:23:24 <sieni> perhaps -> #haskell-blah
16:24:03 <dons> heh
16:24:56 <wli> I wonder if there will be a pdxhug.
16:25:10 <sieni> finnish males have a big heart and a large head mostly made of wood and a small specimen of nerve tissue inside
16:25:41 <Beelsebob> @src (==) :: Int -> Int -> Bool
16:25:42 <lambdabot> Source not found. Take a stress pill and think things over.
16:25:42 <sieni> you have to excuse us for the most brutal cultural diversions
16:25:48 <Beelsebob> hmm
16:26:01 <Beelsebob> @src (==) :: String -> String -> Bool
16:26:02 <lambdabot> Source not found. Wrong!  You cheating scum!
16:26:06 <geocalc> this was an interlude of annonimous alcoolic league
16:26:19 <Beelsebob> I guess that that's truely built in and down to the compiler to define then?
16:26:36 <dibblego> that essay is awesome
16:27:20 <LoganCapaldo> (==) is likely (Eq a) => [a] -> [a] -> Bool for Strings
16:27:49 <Saizan> also, the @src database is manually and not consistently populated
16:28:07 <Saizan> @src [a] (==)
16:28:07 <lambdabot> Source not found. I can't hear you -- I'm using the scrambler.
16:28:09 <LoganCapaldo> also, I don't think @src takes the type into account like that
16:28:23 <LoganCapaldo> (you'd have to use syntax like what Saizan is doing)
16:28:35 <LoganCapaldo> @src Maybe (>>=)
16:28:35 <lambdabot> (Just x) >>= k      = k x
16:28:35 <lambdabot> Nothing  >>= _      = Nothing
16:28:58 <LoganCapaldo> @src (>>=) :: Maybe a -> (a -> Maybe b) -> Maybe b
16:28:58 <lambdabot> Source not found. That's something I cannot allow to happen.
16:29:13 <LoganCapaldo> @src (>>=)
16:29:13 <lambdabot> Source not found. My pet ferret can type better than you!
16:29:20 <dons> you need to specify the instance
16:29:24 <dons> ?src [] (>>=)
16:29:24 <lambdabot> m >>= k     = foldr ((++) . k) [] m
16:29:49 <LoganCapaldo> @src [] (==)
16:29:49 <lambdabot> []     == []     = True
16:29:49 <lambdabot> (x:xs) == (y:ys) = x == y && xs == ys
16:29:49 <lambdabot> _xs    == _ys    = False
16:30:01 <LoganCapaldo> So that's == for Strings
16:30:23 <LoganCapaldo> (Eq a) => [a] s in general
16:31:18 <LoganCapaldo> @type (and .) . zipWith (==)
16:31:21 <lambdabot> forall a. (Eq a) => [a] -> [a] -> Bool
16:32:48 <moonlite> :t fmap
16:32:50 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
16:33:20 <moonlite> hm wrong window but lambdabot got it anyway :)
16:34:19 <moonlite> $src Maybe fmap
16:34:24 <moonlite> @src Maybe fmap
16:34:24 <lambdabot> fmap _ Nothing       = Nothing
16:34:24 <lambdabot> fmap f (Just a)      = Just (f a)
16:34:29 <dons> http://www.haskell.org/pipermail/xmonad/2007-October/002906.html
16:34:30 <lambdabot> Title: [Xmonad] ANNOUNCE: xmonad 0.4
16:34:33 <dons> get your xmonad woots here.
16:34:50 <dons> woots and ftws for everyone!
16:36:08 <moonlite> :)
16:40:34 <Pseudonym> ftws, or wtfs?
16:40:57 <glguy> for the wins
16:43:09 <byorgey> hopefully no one will get a wtf from xmonad.
16:47:18 <monochrom> wtf = window tiling fault? :)
16:47:24 <dons> :)
16:47:37 <dons> full,tall,wide
16:47:40 <dons> hmm
16:47:55 <byorgey> wtf = workspace too fat
16:48:12 <Pseudonym> Write The Fine manual
17:05:47 <paczesiowa> > isSeparator ' '
17:05:49 <lambdabot>  True
17:06:28 <ferron> how do I integrate Hpaste.el in emacs on kubuntu
17:07:03 <paczesiowa> what's wrong with my ghc? I don't have isSeparator in Char:/
17:07:12 <paczesiowa> > isSeparator '\t'
17:07:13 <lambdabot>  False
17:07:17 <paczesiowa> > isSeparator '\n'
17:07:18 <byorgey> paczesiowa: did you import Data.Char?
17:07:18 <lambdabot>  False
17:07:59 <paczesiowa> there's Char and Data.Char, apparently I was trying to use Char
17:08:17 <byorgey> paczesiowa: yeah, modules like 'Char' and 'Maybe' etc. are deprecated
17:08:31 <byorgey> they're only there for backwards compatibility, you should use Data.Char, Data.Maybe, etc. instead
17:08:42 <paczesiowa> kthx:>
17:08:50 <byorgey> also 'System.IO' instead of 'IO', and so on =)
17:09:54 <paczesiowa> anyway, it seems I don't need it. I wanted to test if character is ' ' or '\t'. looks like I have to write it myself
17:10:35 <twanvl> > isSpace' '
17:10:35 <lambdabot>  Improperly terminated character constant
17:10:39 <twanvl> > isSpace ' '
17:10:41 <lambdabot>  True
17:10:47 <paczesiowa> > isSpace '\n'
17:10:49 <lambdabot>  True
17:10:57 <paczesiowa> that's not what I need:>
17:11:15 <byorgey> > ' ' `elem` " \t"
17:11:16 <lambdabot>  True
17:11:16 <LoganCapaldo> > oneOf " \t"
17:11:17 <lambdabot>   Not in scope: `oneOf'
17:11:23 <byorgey> > '\t' `elem` " \t"
17:11:24 <lambdabot>  True
17:11:28 <byorgey> > '6' `elem` " \t"
17:11:29 <lambdabot>  False
17:11:32 <LoganCapaldo> I demand more parsec in lambdabot :)
17:11:37 <byorgey> and so on
17:12:41 <paczesiowa> when I wrote that I need to write it myself, I meant that's so easy I'll finish it before I finish writing that sentence:>
17:13:27 <paczesiowa> but, thx anyway. different ideas always help
17:13:45 <phlpp> how can i create a list that has elements between [1..sqrt n]?
17:14:07 <byorgey> > [1 .. floor (sqrt 90)]
17:14:09 <lambdabot>  [1,2,3,4,5,6,7,8,9]
17:14:11 <paczesiowa> > [1..floor (sqrt 10)]
17:14:12 <lambdabot>  [1,2,3]
17:14:14 <LoganCapaldo> that's not the same thing
17:14:21 <Pseudonym> takeWhile (\x -> x*x < n) [1..]
17:14:33 <Pseudonym> Or (<=), I guess.
17:14:39 <paczesiowa> > [1..floor (sqrt 100)]
17:14:40 <lambdabot>  [1,2,3,4,5,6,7,8,9,10]
17:14:41 <dons> Pseudonym: can you create a lambdacat that also includes ghc 12.5, and chuck norris, in a single image?
17:14:42 <byorgey> LoganCapaldo: ?
17:14:51 <Pseudonym> dons: Erm.
17:15:06 <Pseudonym> What caption do you want?  /msg it if you want a surprise
17:15:24 <LoganCapaldo> > (sqrt 10) `elem` [1..floor (sqrt 10)] -- :)
17:15:24 <lambdabot>  Unbalanced parenthesis
17:15:33 <LoganCapaldo> arg
17:15:43 <Pseudonym> Ha ha.
17:15:44 <LoganCapaldo> > (sqrt 10) `elem` [1..floor (sqrt 10)] -- smiley face. stop being silly lb
17:15:45 <lambdabot>  Add a type signature
17:15:45 <paczesiowa> > --:)
17:15:45 <lambdabot>  Unbalanced parenthesis
17:16:02 <dons> > "( hmm"
17:16:03 <lambdabot>  Unbalanced parenthesis
17:16:06 <dons> i thought we fixed that.
17:16:14 <LoganCapaldo> clearly not :)
17:16:15 <byorgey> LoganCapaldo: oh, being picky, I see. =)  Well, it seemed clear that's what phlpp wanted.
17:16:16 <dons> ah no, i have an unapplied patch for it
17:16:31 <LoganCapaldo> lambdabot's nopt the only one being silly :)
17:16:39 <twanvl> My patch only fixes the one in a string, I hadn't thought of comments
17:17:02 <paczesiowa> how about, instance Enum Double where...?
17:17:35 <byorgey> paczesiowa: there already is such an abomina^H^H^H thing.
17:17:53 <byorgey> > [1.3 .. 2.7]
17:17:55 <lambdabot>  [1.3,2.3]
17:18:36 <LoganCapaldo> oh wows
17:18:42 <LoganCapaldo> that's a surprise
17:18:44 <byorgey> > [1.0 .. 4.9] -- for a really good time, go dig through the Report until you figure this one out
17:18:45 <lambdabot>  [1.0,2.0,3.0,4.0,5.0]
17:18:50 <paczesiowa> > [(1::Double)..(2::Double)]
17:18:52 <lambdabot>  [1.0,2.0]
17:18:52 <Pseudonym> Or this:
17:18:54 <Pseudonym> > [1,1..1]
17:18:56 <lambdabot>  [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1...
17:19:10 <byorgey> Pseudonym: nice. =)
17:19:41 <LoganCapaldo> > ['a','a'..'a']
17:19:42 <lambdabot>  "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa...
17:19:55 <LoganCapaldo> > ['a'..'a']
17:19:57 <lambdabot>  "a"
17:20:07 <LoganCapaldo> I don't think I want to fgure that out
17:20:14 <LoganCapaldo> I think I'll be happier not knowing
17:20:26 <Tac-Tics> > ['z' .. 'a']
17:20:27 <lambdabot>  ""
17:20:50 <LoganCapaldo> > ['z','y'..'a']
17:20:51 <lambdabot>  "zyxwvutsrqponmlkjihgfedcba"
17:21:27 <paczesiowa> I meant smth even more stupid:> computer doubles aren't densed ordered so there is another possiblity to enum them:>
17:21:49 <Pseudonym> > [1,1..4]
17:21:50 <lambdabot>  [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1...
17:21:54 <Pseudonym> > [1,1..0]
17:21:55 <lambdabot>  []
17:22:07 <LoganCapaldo> Geez
17:22:13 <paczesiowa> > [1,2..0]
17:22:14 <lambdabot>  []
17:22:32 <paczesiowa> @src enumFromTo
17:22:32 <lambdabot> Source not found. You untyped fool!
17:23:12 <byorgey> paczesiowa: heh, yes, I see.  that would be... crazy.
17:23:47 <LoganCapaldo> untyped fool
17:23:56 <LoganCapaldo> I feel like that's a new'un
17:24:09 <dons> ah, new insults!
17:24:40 <newsham> ?where djinn
17:24:40 <lambdabot> darcs get http://darcs.augustsson.net/Darcs/Djinn
17:25:31 <paczesiowa> lambdabot pities the untyped fool
17:26:05 <newsham> what did (+1) say to the Int?  You're my type!
17:26:53 <paczesiowa> (+1) [] --let's just be friends?
17:27:12 <phlpp> good night everyone
17:27:20 <paczesiowa> bye
17:28:25 <LoganCapaldo> Shouldn't that be what did (+1) say to (*3) ?
17:29:15 <paczesiowa> yeah, type-friends:D
17:40:54 <bct> i've got a program that looks like this: (f (g (h x)))
17:41:07 <bct> x is determined by f, but is only needed by h
17:41:26 <bct> right now i'm passing x as a parameter to all the functions along the chain
17:41:32 <bct> is this a job for the state monad?
17:41:42 <LoganCapaldo> or maybe reader
17:41:56 <Cale> um
17:42:17 <Cale> x is determined by f?
17:42:35 <LoganCapaldo> I think he means f calls h which calls g which calls h
17:42:44 <LoganCapaldo> he just chose a poor notation for his call stack :)
17:42:57 <LoganCapaldo> at least that's my theory
17:43:12 <bct> f calls g which calls h
17:43:23 <LoganCapaldo> yeah I done screwed myself up
17:43:24 <bct> x is a function of some parameter that's passed to f, but not to g or h
17:43:58 <bct> yeah, i didn't use great notation. sorry.
17:44:06 <paczesiowa> f . g . h $ x looks better
17:44:08 <Cale> Ah, okay
17:44:23 <Cale> paczesiowa: yeah, except that's not at all what he means
17:44:51 <TSC> Do g and h "belong" to f?  If so, you could put them inside f and remove the argument passing.
17:44:58 <sieni> bct: in all haskell f (g (h x)) is the same as always
17:45:38 <bct> TSC, sort of, but the actual chain is so deep that that would be impractical
17:45:54 <sieni> bct: x gets sucked into h which gets sucked into g which gets sucked into f and then when you need the whole expression, then everything is evaluated
17:46:05 <paczesiowa> I don't know what he means, but f . g . h $ x works like (f (g (h x))). and I just hate parentheses
17:46:17 <Cale> He really meant what he said a few lines after
17:46:22 <Cale> <bct> f calls g which calls h
17:46:31 * LoganCapaldo bets bct will never write it like that ever again :)
17:46:35 <Cale> Which is something quite different
17:47:02 <Cale> bct: I'd usually just pass the parameter along.
17:47:23 <Cale> bct: After all, if the inner functions actually need it, then their result must depend upon it.
17:47:36 <Cale> So you probably really do want to make it a parameter.
17:47:50 <bct> it seems messy, though.
17:47:56 <bct> and only the innermost function really depends on it
17:48:21 <sieni> bct: this "calling" thing is a bit imperative anyway
17:48:22 <Cale> Well, does the result of the outer functions depend on the result of the innermost function?
17:48:32 <paczesiowa> could you show us at least type signatures for f,g,h,x
17:48:51 <LoganCapaldo> calling is bit imperative?
17:49:16 <Cale> bct: Unless you're throwing away that result, the result of the outer functions really does depend on the value.
17:49:38 <bct> Cale, it does, yes.
17:49:41 <Cale> So it really does make sense for them to take it as a parameter.
17:50:04 <bct> does it help to say that this is rather imperative code anyhow? (Cairo stuff)
17:50:14 <Cale> If you want, there are things like the reader monad for passing an environment value down to functions throughout a computation
17:50:16 <bct> all in 'do' blocks
17:50:36 <Cale> Isn't the Cairo monad in MonadIO?
17:50:44 <monochrom> I have only seen "f calls g" to mean "the body of f uses g", not "f (g x)".
17:51:04 <LoganCapaldo> oh man
17:51:06 <Cale> monochrom: right, which is why what he originally wrote confused everyone
17:51:20 <LoganCapaldo> hey now! I figured it out! :)
17:51:26 <bct> yeah, it really was rather bad notation. sorry :)
17:51:30 <LoganCapaldo> I speak imperative programmer ;)
17:51:51 * sorear has 222 messages in less than a day... :(
17:52:00 <Cale> sorear: mailing lists?
17:52:18 <bct> Cale, yes, I think it's within a MonadIO. does that make a difference?
17:52:27 <sorear> haskell@, haskell-cafe@, libraries@, cvs-ghc@, happs@, and a slew of less active ones
17:53:08 <Cale> well, possibly. The IO monad supports lots of effects. However, you'll likely have to pass at least something down :)
17:53:58 <Cale> I have over 2500 unread messages in my gmail account.
17:54:00 <sieni> LoganCapaldo: well, maybe not imperative, but at least strict
17:55:04 <bct> ok. passing parameters works and is easy, i guess i'll leave it alone for now.
17:55:05 <sieni> LoganCapaldo: saying that a function is called makes more sense in a strict language like ML or Scheme
17:55:05 <bct> thanks all
17:55:28 <LoganCapaldo> and what would you call it in haskell?
17:56:05 <Cale> Well, under lazy evaluation, functions are still called, they're just called outermost firs.t
17:56:09 <Cale> first.*
17:57:54 <LoganCapaldo> Cale's gt my back :)
17:57:57 <LoganCapaldo> *got
17:59:30 <sieni> whatever
18:00:19 <monochrom> I say "evaluated"
18:00:31 <sieni> yes, expressions are evaluated
18:00:41 <seliopou> functions are applied
18:01:05 <sieni> and procedures are called
18:01:17 <sieni> yes I have heard of this somewhere
18:01:56 <monochrom> Haskell: Don't call us, we'll evaluate you.
18:03:51 <bct> while we're on terminology, what do you call those things that functions get passed? parameters, arguments, ... ?
18:04:55 <Cale> If we have, say, f x = x + x, then x is a parameter of f, and in the expression (f 5), 5 is an argument to f.
18:05:30 <bct> aah, ok. makes sense.
18:06:19 <sieni> bct: the classical fibonacci number computation might be enlightening:
18:06:21 <LoganCapaldo>  mmm
18:06:31 <sieni> > let fibs = 1 : 1 : zipWith (+) fibs (tail fibs) in take 10 fibs
18:06:33 <lambdabot>  [1,1,2,3,5,8,13,21,34,55]
18:06:42 <LoganCapaldo> it's not point free it's parameter free :)
18:07:02 <sieni> ok
18:07:18 <LoganCapaldo> > let noparameters = join (+) in f 5
18:07:19 <sieni> @pl let fibs = 1 : 1 : zipWith (+) fibs (tail fibs)
18:07:19 <lambdabot> (line 1, column 48):
18:07:19 <lambdabot> unexpected end of input
18:07:19 <lambdabot> expecting variable, "(", operator, ":", "++", ";" or "in"
18:07:19 <lambdabot>   Not in scope: `f'
18:07:30 <sieni> o blaarggag
18:07:30 <lekro> @pl fibs = 1 : 1 : zipWith (+) fibs (tail fibs)
18:07:31 <lambdabot> fibs = fix ((1 :) . (1 :) . ap (zipWith (+)) tail)
18:07:44 <sieni> stupid me
18:07:49 <LoganCapaldo> > let noparameters = join (+) in noparameters 5
18:07:50 <lambdabot>  10
18:08:06 <LoganCapaldo> it has an argument but no parameters ;)
18:08:45 <Cale> Well, it's a function of an unnamed parameter :)
18:09:06 <bct> sieni, what am i meant to be enlightened by?
18:10:51 <sieni> well, even in the first step, `take` is a function that takes a number and a list as an argument and returns a list of the same type as the seconda argument
18:11:19 <sieni> but fibs is not something that is completely evaluated at the point that "take" is calles
18:11:22 <sieni> called
18:11:30 <sieni> "called" rather
18:12:08 <bct> ahh, gotcha
18:12:16 <LoganCapaldo> I don't think that makes it any less called
18:12:29 <sieni> so what haskell does is "call-by-name" instead of "call-by-value"
18:12:53 <sieni> LoganCapaldo: whatever, everything anyway depends on definitions
18:13:23 <jbalint> do the ghc 6.8 snapshots support something like the "make in-place" that was there before?
18:13:56 <paczesiowa> haskell doesn't call-by-need?
18:14:09 <LoganCapaldo> well everything depends on definitions :)
18:15:14 <sieni> paczesiowa: I guess that's more to implementation, since haskell is a purely functional language, so the compiler can automatically memoize the function calls
18:16:12 <sieni> paczesiowa: but of course there is difference between call-by-name and call-by-need if you can have side-effects
18:16:15 <Cale> Well, lazy evaluation doesn't do that, but nothing says Haskell is lazily evaluated :)
18:16:30 <paczesiowa> not only it "can" it "has" to memoize I think? you can't use Jensen's device in haskell, right?
18:16:50 <Cale> hm?
18:17:12 <Cale> If you write f 5 + f 5, f will be evaluated twice.
18:17:42 <paczesiowa> but f 5 equals f 5
18:17:50 <Cale> GHC doesn't do anything but the very simplest CSE, and in particular it won't common those up.
18:18:01 <Cale> Right, they'll end up equal.
18:18:14 <paczesiowa> in algol, x doesn't have to be equal to x
18:18:30 <sieni> paczesiowa: well, jensen's device does what it does in algol 60 because it's not a purely functional language
18:18:33 <Cale> However, in general it's difficult to determine whether it's worth holding on to the results of function applications.
18:18:46 <Cale> Because although you'll certainly save time, it costs memory to do so.
18:19:19 <Cale> There is something in lazy evaluation which is sort of like memoisation, though isn't quite the same thing, called sharing.
18:19:23 <lekro> > let x = 0/0 in x == x
18:19:24 <lambdabot>  False
18:19:42 <lament> huh what
18:19:56 <lament> > 0/0
18:19:58 <lambdabot>  NaN
18:20:00 <lament> oh.
18:20:04 <Cale> Whenever a parameter to a function occurs more than once in the body, the result of evaluating that argument is shared between the copies.
18:20:08 <paczesiowa> I just mean, that in call-by-need you can memoize. in call-by-name memoizing would break the whole idea of call-by-name
18:20:29 <lekro> lament: just a quirk of the IEEE numbers
18:20:34 <Cale> I always forget which is which with those names for evaluation strateies.
18:20:52 <Cale> Call by need is lazy evaluation? Outermost first?
18:21:06 <lament> i think so
18:21:17 <lekro> lament: obviously they wanted to annoy mathematicians.
18:21:39 <paczesiowa> I think so. I'm only sure about call-by-need, because I failed programming exam because of that stupid '60 thing:-)
18:22:53 <Cale> ah, call by name is apparently normal order evaluation but doesn't evaluate inside the bodies of unapplied functions
18:23:40 <Cale> So I'd normally call that outermost first evaluation, yeah.
18:23:52 <mrd> left to right outermost first, not inside lambdas
18:24:10 <Cale> Call by need is lazy evaluation.
18:24:42 <Cale> Personally, I don't really understand the logic behind the call-by-x names for evaluation strategies.
18:24:54 <lament> me neither, it's confusing
18:25:25 <lament> and there's call-by and then there's pass-by, and sometimes people even confuse the two
18:25:28 <Tac-Tics> My job makes me cry when I run my code an PHP tells me Call By Reference is deprecated =-(
18:25:35 <LoganCapaldo> i'm sure it's jsut an artifact of people coming about with evaluation strategies and then needing to name them
18:25:42 <omnId> to parellel imperative-think call-by-value?
18:25:50 <sieni> Cale: I don't quite understand the difference between call-by-need and call-by-name in the context of something haskellish
18:26:03 <Cale> sieni: The difference is sharing
18:26:32 <Cale> In outermost first evaluation (call by name), if you have double x = x + x, and you evaluate double 5, this is what happens:
18:26:34 <Cale> double 5
18:26:42 <Cale> er, no
18:26:46 <Cale> double (double 5)
18:26:54 <Cale> is the example I want :)
18:26:56 <Cale> double (double 5)
18:27:02 <Cale> = double 5 + double 5
18:27:09 <Cale> = (5 + 5) + double 5
18:27:12 <Cale> = 10 + double 5
18:27:16 <Cale> = 10 + (5 + 5)
18:27:17 <Cale> = 10 + 10
18:27:19 <Cale> = 20
18:27:39 <Cale> Notice that the work to compute double 5 is duplicated.
18:27:50 <Cale> So lazy evaluation (call by need) avoids this.
18:27:56 <Cale> double (double 5)
18:27:57 <sieni> I'm thinking about semantics, not what the evaluator does
18:28:06 <Cale> = let x = double 5 in x + x
18:28:10 <Cale> = let x = 5 + 5 in x + x
18:28:12 <sieni> Cale: if you look at http://en.wikipedia.org/wiki/Jensen%27s_Device
18:28:13 <Cale> = let x = 10 in x + x
18:28:15 <Cale> = 20
18:28:25 <Cale> Of course the semantics are the same
18:28:55 <sieni> if you can do imperative stuff, then apparently the semantics isn't the same
18:29:03 <Cale> huh?
18:29:06 <Pseudonym> sieni: Actually, no.
18:29:11 <Cale> It's just that lazy evaluation does a bit less work.
18:29:16 <sieni> although I don't quite understand what happens in the jensen's device
18:29:27 <SamB_XP_> sieni: you are supposed to prove that the semantics are the same before using unsafePerformIO, actually
18:29:49 <Pseudonym> A shell script, if unmodified, means the same thing.
18:29:57 <sieni> Pseudonym: well, if each evaluation can have side-effects, then it of course matters how many times you evaluate something
18:29:59 <Pseudonym> Even though it may do different things when run in different contexts.
18:30:14 <Cale> sieni: Well, yes, but Haskell doesn't have side effects on evaluation.
18:30:26 <SamB_XP_> Pseudonym: how do I tell which shell it is intended for?
18:30:36 <Pseudonym> Assuming a standard shell.
18:30:37 <sieni> Yes, but I was thinking about imperative context, not Haskell
18:30:40 <Cale> (unsafePerformIO is part of the compiler, not part of the language :)
18:30:47 <Pseudonym> No, it's in the FFI.
18:30:56 <Pseudonym> So it's part of H98 + appendices.
18:31:03 <SamB_XP_> at least, you have to prove that the difference does not matter to you
18:31:33 <Cale> Pseudonym: Yeah, but like the rest of the FFI stuff, I think it's it's better to think of it as a hook into the RTS or compiler
18:31:55 <Cale> Pseudonym: Effectively it lets you extend the language in ways that would otherwise involve changing the compiler.
18:32:12 <Pseudonym> A good way to think about it is that unsafePerformIO is itself foreign to Haskell.
18:32:57 <LoganCapaldo> is unsafePerformIO necessary? Can you have the FFI without it?
18:33:09 <Cale> Yeah, you could.
18:33:17 <paczesiowa> but only inside IO?
18:33:18 <lament> in the same way that using pointers is foreign to C, which is otherwise a very safe language </troll> :D
18:33:46 <Cale> Yeah, C should have proper references, proper arrays, and no pointer arithmetic.
18:34:00 <Pseudonym> So... C++, then.
18:34:21 <Pseudonym> OK, C++ with Boost.
18:34:25 <lament> c++ has proper arrays?
18:34:25 <sieni> paczesiowa: I think the conclusion is that in Haskell, call-by-need and call-by-name give the same result, but that's not true if you can have side effects, like in jensen's device.
18:34:30 <Cale> C++ still has pointer arithmetic
18:34:33 <Pseudonym> lament: In the library, yeah/
18:34:38 <Tac-Tics> hey now, pointer arithmetic is very educational!
18:34:44 <Tac-Tics> (it teaches you not to use pointer arithmetic)
18:34:45 <lament> Tac-Tics: uhhh...... yeah.
18:34:50 <Pseudonym> Cale: Ah, but you can't do pointer arithmetic on "proper references" and "proper arrays".
18:34:54 <Pseudonym> In C++.
18:35:00 <Cale> Tac-Tics: Educational in that it teaches you not to do pointer arithmetic?
18:35:09 <Tac-Tics> yeah =-P
18:35:21 <Pseudonym> Pointer arithmetic is kinda handy if you're writing run-time systems, I must admit.
18:35:25 <Tac-Tics> bounds checking? wassat?
18:35:27 <Pseudonym> Or using C as a high-level assembler.
18:35:32 <Cale> Yeah
18:35:44 <Pseudonym> Or writing a low-level device driver or small embedded system.
18:36:19 <Cale> I suppose that making C a lower-level language would make more sense than making it a higher level language.
18:36:34 <Pseudonym> Stroustrup points out that with most languages, you can't write all of the standard library in the language itself.
18:36:44 <Pseudonym> C and C++ are really the only two that you can do it with.
18:37:06 <lament> really? write malloc
18:37:09 <Cale> Depends on what you consider to be the standard library and what you consider to be part of the language.
18:37:10 <sjanssen> you can't really define the IO libraries in C
18:37:57 <Pseudonym> sjanssen: Yeah, you can.
18:38:10 <sjanssen> Pseudonym: portably?
18:38:13 <LoganCapaldo> lament: You could write malloc if you get syscall for free?
18:38:16 <Pseudonym> lament: Sure, I will.  Assuming that I have a decent set of system calls, like mmap() and sbrk().
18:39:00 <lament> with a decent set of system calls, you shouldn't have trouble in any language :)
18:39:07 <Beelsebob>  am I right in thinking that ghc has been dabling in using other evaluation orders than lazy?
18:39:22 <Pseudonym> The cheat here is that Unix (or, in general, POSIX) _is_ a C virtual machine.
18:39:34 <Beelsebob> hehe
18:39:38 <Beelsebob> so true
18:39:52 <Pseudonym> So apart from some bootstrapping stuff, writing a compliant standard library in C isn't hard.
18:40:03 <Pseudonym> Just a lot of work.
18:40:21 <Pseudonym> (You'd probably write some in assembler for efficiency, of course.)
18:40:37 <paczesiowa> sieni: I agree
18:40:46 <Pseudonym> sjanssen: POSIX is portable.
18:41:09 <Pseudonym> But hey, those #ifdefs don't write themselves...
18:41:29 <xuhao> ^^
18:41:40 <sjanssen> Pseudonym: it seems like you're moving the goal posts, from a language definition problem to an OS definition
18:41:54 <sjanssen> Pseudonym: can't we play similar goals with any other programming language?
18:41:58 <sjanssen> s/goals/games
18:42:00 <Pseudonym> Maybe.
18:42:11 <Pseudonym> Look, let's assume that we have the RTS and FFI for free in Haskell.
18:42:11 <lament> yes we can.
18:42:21 <Pseudonym> So we could, in principle bind to the Unix system calls using FFI.
18:42:41 <Pseudonym> We still couldn't write ByteString or Data.Array in pure Haskell.
18:42:55 <sjanssen> the FFI extension is enough to write ByteString
18:42:58 <sjanssen> Array is tricky
18:44:16 <sjanssen> can you define int and int* in C?
18:45:47 <Pseudonym> Personally, I think the problem with C++ is not that it has pointer arithmetic, but that it's too easy to get to.
18:46:03 <Pseudonym> If it was called std::ptr<int> instead of int*, people would use it less.
18:46:22 <Pseudonym> And the star operator could be repurposed for something useful.
18:46:31 <sorear> not std::raw_memory_address?
18:46:47 <Pseudonym> Or even better.
18:46:50 <Pseudonym> std::memory_block
18:46:56 <Pseudonym> And use iterators into that.
18:47:31 <lament> awesome.
18:47:36 <SamB_XP_> sorear: std::raw_memory_address doesn't actually describe pointers as the C standard defines them...
18:47:37 <Pseudonym> std::memory_block<int>::iterator
18:48:04 <SamB_XP_> the C standard nowhere tries to state that they are in any way raw
18:48:26 <SamB_XP_> presumably because that wouldn't really mean anything
18:48:44 <SamB_XP_> and if it did would limit implementation strategies unnecessarily
18:49:31 <LoganCapaldo> you know's what's fun?
18:49:34 <Pseudonym> Yeah, it's not obvious what you mean by "raw pointer" on a true Harvard architecture.
18:49:41 <LoganCapaldo> #define MEMORY 0
18:50:22 <LoganCapaldo> int* f = malloc(sizeof(int)); MEMORY[f] = 2; if( MEMORY[f] == 2 ) printf("Hi!\n");
18:51:02 * Pseudonym clearly has a different sense of fun
18:51:04 <LoganCapaldo> points are just indexes into the giant array of your memory ;)
18:52:15 <Beelsebob> LoganCapaldo: except that causes EXC_BAD_ACCESS on any sane system
18:52:28 <Beelsebob> or usually does
18:52:31 <SamB_XP_> Beelsebob: what the heck?
18:52:33 <LoganCapaldo> um?
18:52:36 <LoganCapaldo> what?
18:52:47 <Beelsebob> you wirte a random location in memory
18:52:52 <SamB_XP_> Beelsebob: MEMORY[f] is the same as *(MEMORY+f)
18:52:55 <LoganCapaldo> except I'm not
18:53:03 <Beelsebob> oh, so you're not
18:53:04 <Beelsebob> bah
18:53:10 <SamB_XP_> which is the same as *(f+MEMORY), and f[MEMORY]
18:53:11 <Beelsebob> that's nasty
18:53:20 <Beelsebob> nasty beyond belief
18:53:33 <Excedrin> this is more fun: char* null="(null)"; mmap(0,strlen(null)+1, PROT_READ|PROT_WRITE, MAP_SHARED|MAP_FIXED|MAP_ANON, -1, 0); printf("%s\n", 0);
18:53:54 <Excedrin> oh, forgot a strcpy in there
18:53:55 <LoganCapaldo> hehehe
18:54:01 <SamB_XP_> you don't like 1[array] ?
18:54:05 <Excedrin> strcpy(0, null); before printf
18:54:11 <Beelsebob> SamB_XP_: no
18:55:23 <LoganCapaldo> Excedrin is clearly more fun than me
18:55:28 <LoganCapaldo> I
18:55:36 <LoganCapaldo> I'm impressed that works.
18:55:40 <LoganCapaldo> where does that work?
18:56:22 <Excedrin> everywhere mmap works?
18:57:11 <SamB_XP_> and lets you map that page
18:57:21 <monochrom> 1[array] is standard C. :)
18:57:28 <SamB_XP_> which apparantly Linux often is not
18:57:38 <SamB_XP_> or won't be
18:57:39 <Excedrin> SamB_XP_: it works on linux
18:57:40 <Beelsebob> monochrom: it may be, that doesn't make it a good coding practice
18:57:47 <monochrom> No.
18:57:47 <SamB_XP_> said our resident kernel hacker
18:59:14 <Excedrin> works on Solaris too
18:59:27 * SamB_XP_ wishes he could remember who was the resident linux kernel hacker
18:59:27 <Excedrin> I'd be surprised if it didn't work somewhere that mmap is supported
19:00:28 <SamB_XP_> Excedrin: prepare for surpise
19:00:29 <allbery_b> it'll lose on a machinethat supports mmap if the executable is linked into one of the old formats (assuming they are supported)
19:00:33 <SamB_XP_> er. spelled better.
19:01:23 <SamB_XP_> I was given to understand that what passes for HEAD doesn't allow mapping anything at NULL
19:01:29 <allbery_b> Beelsebob: that's one of the classic examples of how loe level C is.  a[b] is defined as being identical to *(a+b), so it is in fact commutative
19:02:02 <SamB_XP_> is that an example of how low-level it is?
19:02:03 <Beelsebob> works fine on OS X too
19:02:29 <Beelsebob> allbery_b: it may be... doesn't make it good coding practice
19:02:42 <allbery_b> SamB_XP_: yes.  another example is Duff's Device, which demonstrates how low level switch() is.
19:02:47 <Beelsebob> something being commutative doesn't mean you should commute them
19:02:49 <SamB_XP_> I think it isn't an example
19:02:56 <allbery_b> oh, it's not, it's also a classic example of obfuscated C code :)
19:03:21 <Excedrin> I only code self-modifying C, because otherwise it's too easy to understand, who's with me on this?
19:03:22 <SamB_XP_> because notice that what code is generated depends on what types a and b are
19:03:38 <LoganCapaldo> Just to be totally clear, whe I #define'd MEMORY to be 0 I wasn't going for good coding practice
19:03:38 <Beelsebob> okay, duffs device is wrong
19:03:39 <SamB_XP_> (since the array index is an index, not a byte offset, you know?)
19:03:40 <Beelsebob> wtf
19:06:54 <Beelsebob> I'm surprised that the case is evaluated each time through the loop
19:07:30 <SamB_XP_> Beelsebob: huh?
19:07:48 <SamB_XP_> the case labels are inside the loop
19:07:52 <Beelsebob> oh no
19:07:53 <Beelsebob> I'm a noob
19:07:58 <Beelsebob> it does it at the stant
19:08:01 <Beelsebob> start*
19:08:03 <Beelsebob> not the end
19:08:12 <SamB_XP_> yeah
19:08:13 <Beelsebob> that's really clever... but also horrible
19:08:16 <SamB_XP_> 'tis the point
19:08:25 <allbery_b> yes, yes it is
19:08:26 <SamB_XP_> but I'm not sure if it's at all useful anymore
19:08:46 <Beelsebob> no, I expect any compiler worth its salt does the loop unrolling automagically
19:09:06 <SamB_XP_> I'm not sure GCC has any salt
19:09:21 <LoganCapaldo> hehe
19:09:25 <Beelsebob> hehe
19:09:48 <Beelsebob> I thought that gcc 4 was meant to have an architecture change to allow such optimisations
19:09:52 <Beelsebob> along with auto-vectorisation etc
19:10:18 <SamB_XP_> you say they have added an NaCl engine for GCC 4?
19:10:25 <Beelsebob> hehe
19:11:25 <allbery_b> knowing gcc it's not so much an NaCl engine as a KCl engine
19:11:33 <Beelsebob> heh
19:12:10 <SamB_XP_> what? fake salt for the salt-challanged?
19:12:25 <ricky_clarkson> How is KCl fake?
19:12:40 <allbery_b> it sorta tastes like salt, but isn't
19:13:01 <SamB_XP_> it's only fake in the sense that NaCl is what is usually meant by "salt" in ordinary conversation...
19:13:03 <allbery_b> it's also got its own health problems associated with it
19:13:05 <ricky_clarkson> It is a salt.  Table salt is "a salt".
19:13:25 <allbery_b> it is a chemist "salt" but not a very good substitute for *food* salt
19:13:34 <ricky_clarkson> Yeah, but if you're bringing chemical formulae into things you're not in normal conversation.
19:14:19 <SamB_XP_> anyway, if you just say "salt" you usually mean NaCl. if you meant any salt at all, you'd say "a salt", wouldn't you?
19:15:26 <lament> the only chemical formula i remember is a joke (in russian) about flat-chested women.
19:15:59 <Excedrin> please share
19:16:08 <lament> do you speak russian?
19:16:21 <Cale> According to wikipedia, KCl can be used as a salt substitute for food, but due to its weak, bitter, unsalty flavour, it is usually mixed with regular salt, NaCl for this purpose to improve the taste.
19:18:49 <ricky_clarkson> Willy was a chemist. Willy is no more.  For what he thought was H2O was H2SO4.
19:19:21 <Beelsebob> :)
19:19:26 <Beelsebob> the old ones are the best ones
19:19:34 <Pseudonym> Everyone agrees the old ones are... old.
19:19:39 <Beelsebob> hehe
19:20:03 <Beelsebob> speaking of which... there were two fish in a tank, one said to the other "so how do you drive this thing?"
19:20:06 <ricky_clarkson> Bah, I need to tell jokes to a younger age group.
19:20:44 <Pseudonym> Said the tiny ant to the elephant, "Mind you you step in this clearing!"  But alas!  Poor fate!  He was struck by the weight of an elephant, hard of hearing.
19:21:37 <ricky_clarkson> Beelsebob:     add an instance declaration for (Fish Driver)
19:22:20 <ricky_clarkson> Pseudonym: Your typo ruined that.
19:22:22 <Beelsebob> ricky_clarkson: you deserve a slap for that
19:22:33 <Beelsebob> plus... shouldn't it be (Driver Fish)
19:26:24 <allbery_b> .oO { you reach a point where there's not a lie in the world that you could use to make the boys believe you're still in your twenties }
19:26:45 <Beelsebob> haha
19:26:52 <Beelsebob> what point is that?
19:26:55 <Beelsebob> 23?
19:27:28 <allbery_b> (one reference not spotted...)
19:27:41 <Beelsebob> apparently so
19:27:59 <allbery_b> (Against Me!, "Thrash Unreal")
19:30:01 <Pseudonym> Oh well.
19:30:20 <ricky_clarkson> A girl was trying to speak Spanish to me and told me she was 36 instead of 26.  Lucky me that I looked shocked, even if it was feigned somewhat.
19:32:59 <lament> more girls should try to speak spanish to me.
19:33:52 <Tac-Tics> that's weird, I don't remember /join #haskell-blah'ing
19:33:54 <Tac-Tics> =-P
19:34:24 <allbery_b> :)
19:34:35 <ricky_clarkson> I was just continuing the theme of whatever allbery_b was actually talking about.
19:34:38 <monochrom> 36 is a nice square
19:34:45 * allbery_b was reacting to ricky_clarkson's comment about talling jokes to younger age groups
19:47:07 <Olathe> Stack space overflow: current size 8388608 bytes :(
19:58:53 <sclv> the reddit thread on "haskell myths" is comedy gold.
20:01:22 <lekro> sclv: where can I find this thread?
20:01:48 <seliopou> http://programming.reddit.com/info/5yigz/comments/
20:01:49 <lambdabot> Title: programming: Haskell Myths
20:01:56 <lekro> thanks
20:02:00 <todizz> how would i compare snd (String,String) and another string
20:02:01 <seliopou> My comment, I think has been misunderstood
20:02:15 <seliopou> todizz: ==
20:02:23 <todizz> i get a type error
20:02:50 <seliopou> (snd ("a", "b")) == "c"
20:02:50 <todizz>  Couldn't match expected type `Char' against inferred type `(a, b)'
20:02:50 <todizz>     In the pattern: (a, b)
20:02:50 <todizz>     In a lambda abstraction: \ (a, b) -> b == sym
20:02:51 <seliopou> ?
20:03:20 <todizz> toName sym = filter (\(a,b) -> b == sym) namensym
20:03:50 <todizz> where namensym is [(String,String)]
20:04:10 <todizz> has type*
20:05:14 <omnId> it would seem to be inferring namensym :: String
20:05:17 <lekro> > let toName sym = filter (\(a,b) -> b == sym) [("hello", "a")] in toName "a"
20:05:20 <lambdabot>  [("hello","a")]
20:05:33 <seliopou> Yeah, works for me
20:05:48 <seliopou> Did you give it a type anotation?
20:05:53 <seliopou> annotation*
20:05:58 <omnId> > filter (\(a,b) -> b == "blah") "foo"
20:05:59 <lambdabot>  Couldn't match expected type `(t, [Char])'
20:06:03 <todizz> toName :: String -> String
20:06:26 <lekro> todizz: look what toName gives
20:06:26 <todizz> should it be to [(String,String)]
20:06:28 <seliopou> Remove the annotation and it should work
20:06:38 <omnId> todizz: yes
20:07:09 <todizz> yea thanks
20:07:20 <omnId> @src lookup
20:07:21 <lambdabot> lookup _key []          =  Nothing
20:07:21 <lambdabot> lookup  key ((x,y):xys) | key == x  = Just y
20:07:21 <lambdabot>                         | otherwise = lookup key xys
20:07:42 <omnId> given [(a,b)], that'll give a (Maybe b)
20:08:34 <monochrom> @quote 12.5
20:08:35 <lambdabot> No quotes match. My mind is going. I can feel it.
20:08:46 <monochrom> @remember dons ghc 12.5 can implement the device drivers in the type system!
20:08:47 <lambdabot> Done.
20:11:55 <seliopou> Does lambdabot not respond to private messages?
20:12:07 <monochrom> It does.
20:14:16 <seliopou> It's been a while; how do I solicit its services
20:15:22 <monochrom> /msg lambdabot > 1+1
20:15:31 <lokimaf_> how do i match to any letter in parsec?
20:15:35 <monochrom> Or, in the channel...
20:15:37 <monochrom> > 1+1
20:15:48 <lambdabot>  2
20:16:12 <lokimaf_> lambdabot lagging?
20:16:26 <lekro> @quote
20:16:26 <lambdabot> Plugin `quote' failed with: IRCRaised getRandItem: empty list
20:17:00 <monochrom> "letter" gets you the next letter.
20:17:12 <lokimaf_> just by itself?
20:17:28 <monochrom> Yes.
20:17:29 <lokimaf_> as in letter :: Parser Char ?
20:17:30 <lokimaf_> kk
20:18:22 <lokimaf_> I'm amazed how i've never used it before
20:21:24 <omnId> lokimaf: maybe anyToken
20:21:42 <omnId> @hoogle anyToken
20:21:43 <lambdabot> Text.ParserCombinators.Parsec.Combinator.anyToken :: Show tok => GenParser tok st tok
20:22:02 <omnId> that'll parse one of whatever tokens are being parsed.
20:22:37 <lokimaf> cool thanks :)
20:23:16 <omnId> @hoogle letter
20:23:17 <lambdabot> Text.ParserCombinators.Parsec.Char.letter :: CharParser st Char
20:23:17 <lambdabot> Text.ParserCombinators.Parsec.Language.identLetter :: LanguageDef st -> CharParser st Char
20:23:17 <lambdabot> Text.ParserCombinators.Parsec.Language.opLetter :: LanguageDef st -> CharParser st Char
20:26:02 <dataangel> is there a form of tail that works with empty lists? (just giving [])
20:26:05 <xpika> @src fix
20:26:06 <lambdabot> fix f = let x = f x in x
20:26:10 <sorear> dataangel: drop 1
20:26:30 * lambdabot yawns
20:27:11 <omnId> lambdabot: hard day?
20:27:27 <lambdabot> a bit
20:29:10 <sclv> @botsnack
20:29:10 <lambdabot> :)
20:29:57 * omnId wonders what variety of snack that conjures
20:30:26 <Korollary> forall a. (Snack a)
20:30:47 <xpika> > take 10$ fix ('w':)
20:30:48 <lambdabot>  "wwwwwwwwww"
20:31:05 <xpika> can fix be implemented in pure lamba calculus?
20:31:16 <omnId> yes
20:31:18 <Korollary> yes in untyped pure lc
20:31:21 <Tac-Tics> fix IS pure lambda calculus
20:31:22 <sclv> forall a. a --its a _|_ snack!
20:31:33 <Korollary> no in some typed lc's
20:31:41 <dataangel> How do I match a list that contains all empty lists? e.g. matches [[]. []. []. []]
20:31:50 <Tac-Tics> http://us.st11.yimg.com/us.st.yimg.com/I/paulgraham_1969_36533
20:31:56 <omnId> func xs | all null xs
20:31:59 <Tac-Tics> ^^^ the fix point combinator in LC
20:32:19 <Tac-Tics> tattooed on (I believe) paul graham's arm
20:32:45 <omnId> s/the fix point combinator/a fix point combinator/ :)
20:32:52 <Korollary> I don't think it's LG's arm
20:33:08 <Adamant> he's a pretty big dude, IIRC
20:33:59 <Korollary> dataangel: you can't match an arbitrarily long list of empty lists
20:34:21 <omnId> but a guard will allow you to test using the all function.
20:34:23 <sorear> you can in GHC HEAD
20:34:29 <sorear> (all null =>)
20:34:53 <dataangel> omnId: thanks :)
20:35:31 <omnId> sorear: => is the implicit Maybe/Bool syntax?
20:36:47 <sorear> omnId: iirc
20:44:12 <newsham> ?seen sorear
20:44:12 <lambdabot> sorear is in ##logic, #ghc, #xmonad, #haskell-overflow, #haskell-blah and #haskell. I last heard sorear speak 7m 24s ago.
20:44:54 <sorear> IE, 5 lines ago in #Haskell :P
20:44:57 <newsham> sorear: so I'm not getting everything you're saying.  the gist is that "functions need to be total" yes?
20:45:10 <sorear> that's the main part, yes
20:45:35 <newsham> so the text I added to that effect should be ok?  (I dont wanna get into lots of details I dont understand myself, but I dont want to mislead either)
20:46:18 <sorear> probably.
20:46:22 <newsham> "(Note: to be correct, the function must be total: it must terminate for all defined arguments. It's easy to cheat by using "undefined" in your proofs. In fact, this is a useful tool when debugging incomplete proofs)."
20:46:37 <sorear> That's not *quite* enough.
20:47:04 <sorear> ((a -> a) -> a) -> a is a theorem:
20:47:17 <sorear> @scheck \a -> ((a <= a) <= a) <= a
20:47:19 <lambdabot>   Completed 2 test(s) without failure.
20:47:39 <sorear> but any proof of it must fail when passed 'fix'
20:48:17 <sorear> (there are methods to enumerate all essentially distinct proofs of a proposition, they tell us that proofs of this are of the form \x -> x id)
20:48:20 <hpaste>  dataangel pasted "why is foldr written that way instead of this way?" at http://hpaste.org/3357
20:48:23 <newsham> what more do I need to say?
20:48:58 <dataangel> whoops, that should consistently refer to "myFoldR" not "joeFoldR". I tried to anonymize it and failed ;p
20:49:01 <sorear> dataangel: your function isn't even correct
20:49:09 <sorear> it's just foldl . flip
20:49:44 <dmwit> joe: I think you wrote a left-associative fold
20:49:44 <newsham> btw, I had to load haskell-cafe archives in firefox to see your weird unicode characters :)
20:49:45 <dataangel> sorear: I get the same result for foldr (/) 64 [4, 2, 4]
20:49:50 <sorear> newsham: not sure what the best approach is, I introduced Tait's SN construction, but it has a definite smell of sledgehammer nutcracking
20:49:51 <dmwit> Oh, sorear beat me to it.
20:50:25 <sorear> dataangel: Try it on a non-palindromic list.
20:50:48 <sorear> dataangel: joeFoldR f z l == foldr f z (reverse l)
20:50:59 <dataangel> oh :P
20:51:12 <Olathe> @scheck \x -> (id id) x == (id . id) (x::[String])
20:51:13 <omnId> @let myFoldR f accum [] = accum; myFoldR f accum (x:xs) = myFoldR f (x `f` accum) xs
20:51:18 <lambdabot> Done.
20:51:23 <lambdabot> Defined.
20:51:44 <Olathe> See, scheck doesn't need to check any [String]s ! It has a proof !
20:52:07 <Olathe> @scheck \x -> (id id) x == (id . id) (x::String)
20:52:09 <lambdabot>   Completed 1957 test(s) without failure.
20:52:23 <Olathe> Unfortunately, we're stuck with empirical tests for Strings.
20:53:52 <omnId> erm, so (id id) x == id (id x)?  That follows if you substitute the definiton of id and the (==) law right?
20:54:54 <sorear> no
20:55:04 <sorear> > let x = 0/0 in (id id) x == id (id x)
20:55:06 <lambdabot>  False
20:55:16 <omnId> ignoring the evil NaN of course :)
20:55:49 <omnId> Double doesn't follow the Eq laws!  Er, Eq has the law x == x, right?
20:55:52 <sclv> > let x = undefined in (id id) x == id (id x)
20:55:53 <lambdabot>  Undefined
20:55:58 <sorear> (id id) x _ id x _ x
20:56:04 <sorear> id (id x) _ id x _ x
20:59:34 <Beelsebob> > id (id (0/0)
20:59:34 <lambdabot>  Unbalanced parenthesis
20:59:37 <Beelsebob> > id (id (0/0))
20:59:38 <lambdabot>  NaN
20:59:43 <Beelsebob> > (id id) (0/0)
20:59:45 <lambdabot>  NaN
20:59:51 <Beelsebob> ah... but different NaNs
20:59:55 <omnId> > let nan = 0/0 in nan == nan
20:59:56 <lambdabot>  False
21:00:04 <Beelsebob> makes sense
21:00:22 <newsham> sorear: do you know if the martin-Lof book covers this?
21:00:50 <chessguy> Beelsebob, more like...not provably the same
21:01:11 <Beelsebob> chessguy: well, yes
21:01:23 <chessguy> @src (==)
21:01:23 <lambdabot> x == y = not (x /= y)
21:01:27 <Beelsebob> in the same way as infinity - infinity = anything you chose between -infinity and infinity
21:01:42 <chessguy> err
21:01:43 <chessguy> no
21:01:44 <omnId> Double (==) is more than likely primitive.
21:01:52 <Beelsebob> chessguy: it does in a term rewriting system at least
21:02:05 <chessguy> infinity - infinity is not defined. infinity is not a number to be subracted
21:02:16 <Beelsebob> chessguy: depends on the model you're using
21:02:18 <newsham> omni: not equal is probably also primitive
21:02:26 <Beelsebob> in traditional maths, yes
21:02:31 <chessguy> i choose mathematics :)
21:02:42 <Beelsebob> in some bizare term rewriting systems with infinatary rewrites, no
21:02:49 <chessguy> next you'll start talking about nullity
21:02:52 <Beelsebob> hehe
21:03:29 * Beelsebob goes to bed
21:07:13 <newsham> nmap fyodor?
21:10:36 <fyodor> newsham: I'm sorry, no.
21:10:50 <newsham> no need to be sorry :)
21:12:44 <fyodor> newsham: :)
21:15:42 <Sgeo> Bye all
21:23:03 <newsham> ?type \x y z -> x z (y z)
21:23:05 <lambdabot> forall t t1 t2. (t -> t1 -> t2) -> (t -> t1) -> t -> t2
21:23:33 <chessguy> @pl \x y z -> x z (y z)
21:23:33 <lambdabot> ap
21:23:48 <chessguy> @type ap
21:23:49 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m (a -> b) -> m a -> m b
21:23:57 <chessguy> hmm
21:24:06 <mauke> where m = (t ->)
21:24:14 <chessguy> right
21:24:23 <chessguy> why do the types not match up though?
21:24:39 <omnId> (t -> a -> b) -> (t -> a) -> (t -> b)
21:24:41 <mauke> huh?
21:24:46 <Pseudonym> ap is more general
21:25:31 <newsham> (t -> a -> b) -> (t -> a) -> t -> b
21:25:56 <newsham> the last "m b" sneaks in an extra argument :)
21:26:21 <chessguy> filthy, sneaky little monadws
21:26:44 <omnId> sneaky yes, filthy no
21:27:24 <shachaf> @ty (<*>) -- Even more general. :-)
21:27:26 <lambdabot> forall (f :: * -> *) a b. (Applicative f) => f (a -> b) -> f a -> f b
21:27:54 <newsham> filthy == impure?
21:30:54 <chessguy> i wondered who was going to make that joke
21:31:06 <omnId> bah.  The "impure" sticker on monads is misplaced.
21:32:52 <user317> how come there is no Random Word
21:33:36 <omnId> @instances-importing Data.Word System.Random Random
21:33:38 <lambdabot> Bool, Char, Double, Float, Int, Integer
21:33:56 <ricky_clarkson> x++ is only impure if it changes x.  If, instead, it describes an action that has x as an input and x+1 as an output, where x+1 is used instead of x thereafter, it is pure.
21:34:17 <ricky_clarkson> That's one way I think of monads.. reasonable?
21:34:18 <omnId> > bitSize (0 :: Word)
21:34:20 <lambdabot>  32
21:34:59 <omnId> > (minBound, maxBound) :: (Word, Word)
21:35:00 <lambdabot>  (0,4294967295)
21:35:25 <user317> i guess i could add one using float
21:35:39 <omnId> @type first fromIntegral . randomR (0, 2^32)
21:35:40 <lambdabot> forall b a. (Num b, RandomGen a) => a -> (b, a)
21:35:52 <omnId> is Word in Num?
21:35:59 <swix> I want to split a list of length 3n in to 3 lists of size n, where the first, fourth,seventh... are in one list, the second,fifth,eight are in another, and the third, sixth,ninth... are in a final list....
21:36:52 <lokimaf> how do i change case of a letter into uppercase?
21:36:56 <omnId> swix: split into lists of length 3 then transpose?
21:36:57 <mauke> > unzip3 "123456789"
21:36:58 <lambdabot>  Couldn't match expected type `(a, b, c)'
21:37:05 <mauke> oh right :(
21:37:07 <user317> omnId, yea its in num
21:37:27 <ricky_clarkson> @hoogle Char -> Char
21:37:28 <lambdabot> Char.toLower :: Char -> Char
21:37:28 <lambdabot> Char.toUpper :: Char -> Char
21:37:29 <omnId> lokimaf: toUpper
21:37:45 <ricky_clarkson> > map toUpper "hello"
21:37:47 <lambdabot>  "HELLO"
21:37:48 <lokimaf> > toUpper "a"
21:37:49 <lambdabot>  Couldn't match expected type `Char' against inferred type `[Char]'
21:37:59 <lokimaf> > toUpper 'a'
21:38:00 <lambdabot>  'A'
21:38:03 <vegai> "After Chuck Norris helped Simon Peyton Jones fix the bugs in the GHC type checker, GHC 12.5 can statically guarantee you get laid."
21:38:04 <lokimaf> kk thanks :)
21:38:05 <omnId> user317: I don't know why there's no Random Word, but you could fromIntegral :: Integer -> Word in the meantime.
21:38:06 <vegai> dons++
21:38:42 <omnId> @quote dons 12\.5
21:38:42 <lambdabot> Plugin `quote' failed with: IRCRaised getRandItem: empty list
21:38:54 <Nafai> vegai: Yeah, I thought dons was hilarious in that reditt thread
21:39:26 <mauke> url?
21:39:32 <ricky_clarkson> The bit about predictable space not being a problem in practice, oh that cracked me up.
21:39:47 <ricky_clarkson> mauke: http://programming.reddit.com/info/5yfe6/comments
21:39:49 <lambdabot> Title: programming: The problem with Haskell is ... that even seasoned experts have gre ...
21:40:22 <swix> omnId, how do I add transpose to my scope?
21:40:30 <mauke> @index transpose
21:40:30 <lambdabot> Data.List
21:40:34 <mauke> import Data.List
21:40:34 <shachaf> swix: import Data.List
21:40:35 <Nafai> mauke: http://programming.reddit.com/info/5yigz/comments/
21:40:37 <lambdabot> Title: programming: Haskell Myths
21:40:37 <omnId> import it :)
21:40:42 <shachaf> swix: Or :m + Data.List
21:40:48 <swix> alright
21:43:50 * bos manages to type "nodule" instead of "module"
21:45:16 <swix> how about, counting unique elements of a list...?
21:45:44 <mauke> length . group . sort
21:45:55 <wli> length . nub
21:50:59 <vegai> is Linspire still using Haskell?
21:51:09 <wli> No idea.
21:51:15 <wli> I've barely heard of them.
21:51:54 <swix> @index chr
21:51:54 <lambdabot> Data.Char
21:56:32 <swix> alright, now, how do you convert an Integer to an Int?
21:56:42 <shachaf> swix: fromIntegral
21:56:52 <shachaf> swix: Why do you need to?
21:56:56 <mauke> fromInteger :-)
21:57:08 <shachaf> swix: You should look at the generic* functions too.
21:57:18 <shachaf> mauke: Well, OK.
21:57:42 <swix> I was just using chr and it wants an Int
21:58:21 <omnId> > fromEnum (96 :: Integer)
21:58:23 <lambdabot>  96
21:58:26 <omnId> > fromEnum (96 :: Integer) :: Char
21:58:27 <lambdabot>  Couldn't match expected type `Char' against inferred type `Int'
21:58:57 <omnId> bah, and toEnum takes an Int
21:59:27 <shachaf> > toEnum 96 :: Char
21:59:28 <lambdabot>  '`'
21:59:33 <shachaf> @ty toEnum
21:59:35 <lambdabot> forall a. (Enum a) => Int -> a
22:01:28 <swix> does haskell have bitwise operators (specifically xor)?
22:02:19 <omnId> @docs Data.Bits
22:02:19 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Data-Bits.html
22:05:37 <swix> omnId, I'm confused... how do I convert my Num to a Bits type?
22:05:56 <omnId> swix: what type do you have?
22:06:05 <swix> Int or Integer
22:06:11 <omnId> @instances-importing Data.Bits Bits
22:06:12 <lambdabot> Int, Integer
22:06:22 <omnId> it's already in the Bits class
22:06:28 <omnId> > xor 5 3
22:06:29 <lambdabot>  Add a type signature
22:06:34 <omnId> > xor 5 3 :: Int
22:06:39 <lambdabot>  6
22:06:41 <swix> ahh
22:06:50 <swix> I was going xor 3::Int 2:Int
22:07:06 <omnId> that's a syntax error
22:07:14 <omnId> xor (3::Int) (2::Int)
22:07:26 <omnId> a type annotation extends all the way to the right
22:07:56 <omnId> so you'd get ((xor 3) :: (Int 2 :: Int)), and (Int 2 :: Int) isn't a valid type
22:08:22 <omnId> though xor (2::Int) (3::Int) should do fine, since xor has type:
22:08:24 <omnId> @type xor
22:08:26 <lambdabot> forall a. (Bits a) => a -> a -> a
22:08:41 <omnId> both params and the result are the same, so you need only annotate one.
22:20:22 <dibblego> what's another name for as-patterns?
22:21:02 <sorear> @-patterns
22:21:02 <lambdabot> Unknown command, try @list
22:21:16 <dibblego> something I can google for, to find out how to achieve same in Scala?
22:22:35 <sorear> newsham: Probably does, Tait's work is pretty foundational.  But I don't really know about this "Martin-Lf's book" of which you speak, besides that Martin-Lf himself is a big-N Name in the field of type theory and mechanised logic
22:23:33 <swix> how would you sort a list of tuples by the 2nd element?
22:23:47 <wli> sortBy (comparing snd)
22:23:53 <swix> woo
22:24:22 <dibblego> ?type comparing
22:24:24 <lambdabot> forall b a. (Ord a) => (b -> a) -> b -> b -> Ordering
22:24:27 <omnId> sortBy (\x y -> compare (snd x) (snd y)) if you didn't know of comparing
22:25:04 <dibblego> ?info comparing
22:25:04 <lambdabot> (comparing)
22:25:10 <dibblego> what module is comparing?
22:25:21 <wli> Data.Ord
22:25:23 <omnId>  ?info --spellcheck--> ?undo, and comparing is Data.Ord
22:25:30 <omnId> ?undo comparing
22:25:31 <lambdabot> (comparing)
22:26:09 <hpaste>  thetallguy pasted "Time the evaluation of two expressions" at http://hpaste.org/3358
22:26:23 <newsham> http://www.cs.chalmers.se/Cs/Research/Logic/book/
22:26:25 <lambdabot> Title: Programming in Martin-Lof's Type Theory
22:26:32 <newsham> referenced by the agda site, amoung other things
22:26:38 <sorear> thetallguy: x `seq` return () doesn't do what you want
22:26:45 <thetallguy> Is there an existing library function that does something like the above at hpaste?
22:26:53 <bos> thetallguy: your code doesn't work
22:26:55 <thetallguy> sorear: that was my second question
22:26:59 <omnId> thetallguy: that just evaluates to WHNF
22:27:01 <thetallguy> Actually, it does
22:27:08 <bos> no, it *looks* like it works.
22:27:10 <thetallguy> Which puzzled me.
22:27:12 <bos> but it's not working.
22:27:33 <bos> it gives you a number, but it doesn't completely evaluate x or y.
22:27:41 <thetallguy> Ah, right, I see.
22:27:44 <kscaldef> hoogle is failing me and it's late and my brain is not working at full power.  Can anyone point me to this function:   Arrow a => a (b,c) d -> a (b,c) (d,c)   ?
22:27:57 <thetallguy> I was passing in foldr' for each of the expressions
22:27:59 <omnId> there's a r(educeto)n(ormal)f(orm) somewhere
22:28:03 <bos> it just tells you how long it takes for x to evaluate to the point of giving back a constructor, and likewise for y.
22:28:06 <omnId> @hoogle rnf
22:28:07 <lambdabot> Control.Parallel.Strategies.rnf :: NFData a => Strategy a
22:28:14 <sorear> thetallguy: even with bos' suggestion, it's not good enough
22:28:19 <sorear> thetallguy: x `seq` return ()  means 'evaluate x to whnf at some undetermined time, then return ()'
22:28:32 <thetallguy> No wonder it was keeping in sync
22:28:37 <sorear> in particular, it's legal for x and y to be evaluated at program startup
22:28:48 <bos> true nuff.
22:28:54 <sorear> seq forces evaluation, but (despite its name) it doesn't force *when*
22:28:57 <thetallguy> But one would expectit to work in ghci?
22:28:58 <sjanssen> in theory, x and y don't have to be evaluated at all
22:29:12 <sjanssen> if the compiler could prove that they aren't _|_ at compile time
22:29:23 <sjanssen> (no Haskell compiler works this way)
22:29:26 <sorear> if you want to specify order, use evaluate from control.exception
22:30:24 <thetallguy> evaluate is compiler magic, then?
22:30:56 <sjanssen> @src evaluate
22:30:56 <lambdabot> evaluate a = IO $ \s -> case a `seq` () of () -> (# s, a #)
22:31:23 <omnId> ooooooo
22:31:33 <thetallguy> Ah, cool, thanks.
22:31:39 <thetallguy> So, the first question stands
22:31:41 <sorear> the #'s are a good hint that the behavior you want can't be easily done in user code
22:31:52 <sorear> alas, no.
22:31:55 <thetallguy> sorear: yeah.
22:32:09 <sorear> dons has written it for nobench, though, so there IS precendent
22:32:15 <thetallguy> bummer, I find stuff like that useful
22:32:23 <thetallguy> and I want it in a standard library
22:32:33 <sorear> write it up, slap on a .cabal file, post it on hackage
22:32:36 <sorear> then it's standard
22:32:47 <thetallguy> Yup.
22:33:03 <thetallguy> But that means I have yet another project.
22:33:13 <thetallguy> Ah well, no rest for the wicked.
22:37:34 <kscaldef> @pl \(x,y) -> ((x,y),y)
22:37:34 <lambdabot> uncurry (join . ((,) .) . (,))
22:38:57 <omnId> @type id &&& snd
22:39:06 <lambdabot> forall a b. (a, b) -> ((a, b), b)
22:39:27 <ski> ricky_clarkson : yes
22:41:01 <kscaldef> omnId: that seems much more readable
22:41:03 <mauke> :t ap (,) snd
22:41:05 <lambdabot> forall a b. (a, b) -> ((a, b), b)
22:42:07 <bos> alexj: lunch tomorrow?
22:46:22 <Pseudonym> > 0/0 == 0/0
22:46:24 <lambdabot>  False
22:46:25 <Pseudonym> > 0/0 /= 0/0
22:46:27 <lambdabot>  True
22:46:31 <Pseudonym> Hmm.
22:46:36 <Pseudonym> Is that latter one correct?
22:46:48 <bos> yes
22:46:52 <omnId> it follows from the former
22:47:02 <Pseudonym> Does it?
22:47:07 <omnId> @src (/=)
22:47:08 <lambdabot> x /= y = not (x == y)
22:47:10 <omnId> yep
22:47:46 <omnId> oh, specifically in the case of NaNs, and how the interact with /=?
22:47:59 <Pseudonym> But you can define an instance of Eq such that x /= y is not always not (x==y), and more importantly, the H98 report doesn't mention that this is an invariant.
22:48:01 <Pseudonym> Right.
22:48:18 <Pseudonym> And NaNs strike me as one of those corner cases.
22:48:35 <omnId> I do believe NaN /= Nan -> True is a property of NaNs
22:48:36 <Pseudonym> Because NaN is a member of Float/Double which isn't actually a member.
22:48:57 <Pseudonym> NaN statically types as a Float/Double, but isn't really one.
22:49:07 <omnId> right
22:51:12 <Pseudonym> Yeah, it seems right to me that NaN /= NaN is true, but I'm not 100% certain.
22:51:35 <omnId> you could check the relevant IEEE spec.
22:51:39 <bos> it's standard behaviour for machines using IEEE754 floats.
22:52:03 <bos> all languages i'm aware of treat NaN /= NaN
22:52:17 <wli> Java sinned here at one point.
22:52:17 <bos> now where languages differ is in treatment of -0 and +0
22:52:21 <Pseudonym> Ah, but let's be clear here.
22:52:29 <bos> no, that was 0, not NaN.
22:52:30 <Pseudonym> not (Nan == NaN), definitely.
22:52:42 <Pseudonym> The question is: What about NaN /= NaN.
22:52:54 <wli> "Why Java floating point hurts everyone, everywhere, all the time."
22:53:10 <Pseudonym> I'm guessing that IEEE-754 doesn't make a distinction.
22:53:18 <Pseudonym> It just says "is equal" vs "is not equal".
22:53:28 * Pseudonym doesn't have a copy of the spec around at the moment
22:53:46 <omnId> wli: wasn't that about the forced fixed precision that brought about the odd 'strictfp' method annotation?
22:54:00 <wli> Kahan will write a paper flaming you if you break it.
22:54:22 <wli> omnId: It addressed several issues.
22:54:39 <wli> omnId: +/-0 was one
22:55:40 <Pseudonym> Right.  isNaN(x) is equivalent, in the spec, to x /= x.
22:55:47 <Pseudonym> I think that answers that one.
22:56:08 <Pseudonym> But the spec also defines x <> y, which is different than not (x == y).
22:56:13 <quicksilver> Pseudonym: most languages don't distinguish between not (a == b) and (a /= b); so they're unlikely to face this precise question.
22:56:21 <Pseudonym> Right.
22:56:43 <quicksilver> you can argue if the intended denotation of /= is <> or not . ==
22:56:48 <quicksilver> I don't have the faintest idea :)
22:57:03 <Pseudonym> The difference is entirely in exception behaviour.
22:59:38 <bos> of course, there are many NaN values.
23:01:30 <bos> 9007199254740988 or so of them, iirc.
23:01:37 <alexj> anyone know what the difference is between ByteString and Lazy.ByteString and why one would pick one over the other?
23:01:51 <bos> alexj: strict vs chunked.
23:02:15 <bos> all one big array, or a list of cache-sized 64KB blocks.
23:02:51 <bos> which to use depends on your data and application.
23:03:08 <alexj> ah ok.  HAppS has both in various places.
23:03:16 <bos> for small strings, ByteString has less overhead.
23:03:23 <alexj> not sure whether that makes sense.
23:03:30 <bos> that makes sense, at least in principle.
23:03:38 <quicksilver> <flamebait>For example, if you want to use unsafe lazy IO, lazy bytestrings have support for that dangerous paradigm</flamebait>
23:04:14 <quicksilver> my rule of thumb is "if I can imagine always being happy about this data being strictly in-memory, use a strict bytestring
23:04:32 <quicksilver> so anything upto a few megabytes, strict is fine IMO
23:05:02 <bos> it depends. sometimes you can get better performance by using lazy bytestrings even when strict will easily fit in memory.
23:05:15 <quicksilver> agreed
23:05:34 <wli> I'm getting sort of unexpected convergence behavior.
23:05:37 <quicksilver> alexj: the other nice thing about lazy bytestrings is efficient append
23:05:45 <quicksilver> alexj: and sharing
23:06:15 <quicksilver> although we lack a 'self-defragmenting' lazy BS for truly good asymptotic append
23:06:21 <wli> Basically these things make drastic reductions in the bounding interval size only once or twice early on and then basically bisect from then on.
23:07:02 <wli> So essentially the superlinear methods only seem to get used to make one large bounding interval reduction.
23:07:34 <wli> This is not quite the expected behavior where "once superlinear convergence sets in" it continues superlinearly.
23:08:01 <bos> for good append, combining Data.Sequence with explicit munging the bowels of lazy bytestrings is needed.
23:09:25 <quicksilver> bos: a native LBS based zipper would be a nice thing, to
23:09:36 <bos> yep
23:09:50 <quicksilver> although somethign about zippers seems to mean you end up writing your own for a particular application rather than just distributing a library
23:09:59 <quicksilver> there seem to be too many choices to get it right in a library
23:12:52 <seliopou> Ok
23:13:01 <seliopou> Has somebody read the haskell myths comments?
23:13:05 <sjanssen> a zipper isn't *a* data type, it's a class of data types
23:13:12 <iank> zipzipzip
23:13:14 <sjanssen> (namely the derivative of a data type)
23:13:20 <seliopou> because the people responding to my comment are driving me bonkers. Have I not been clear at all?
23:13:46 <dblhelix> sjanssen: a generic  or polytypic data type, if you like ;-)
23:14:46 <sjanssen> seliopou: I think the argument is over a split hair
23:15:18 <seliopou> I disagree
23:15:23 <sjanssen> seliopou: it is fair to say that ?: operator in C has semantics similar to laziness
23:15:35 <sjanssen> that doesn't mean C is a lazy language, of course
23:15:39 <seliopou> These people seem to be saying, "Something isn't evaluated. It's laziness!"
23:15:51 <seliopou> No, it is not lazy
23:16:01 <seliopou> That is a control structure, it is not a function
23:16:18 <seliopou> just because something is not evaluated does not make it lazy
23:16:24 <seliopou> and that is the point I am trying to get across
23:16:50 <seliopou> If that's the case, laziness means nothing
23:17:01 <ski> `lazy' being defined as ?
23:17:30 <sjanssen> seliopou: I think this comment by augustss makes a good case http://programming.reddit.com/info/5yigz/comments/c029qv6
23:17:32 <lambdabot> Title: programming: Haskell Myths
23:17:47 <seliopou> arguments to functions are not evaluated at application, but rather when it is necessary that they be evaluated for the evaluation of the application to proceed
23:18:01 <seliopou> he is talking about short circuiting
23:18:22 <seliopou> obviously they are going to be implemented similarly in language irrespective of laziness/strictness/etc
23:18:24 <sjanssen> seliopou: they aren't saying that C is lazy, they're saying it has some constructs that taste lazy
23:18:37 <seliopou> It was my mistake to call it short-curcuiting in the first place
23:18:51 <sjanssen> seliopou: I think you have an unfairly narrow definition of lazy
23:19:00 <seliopou> I am not saying that C is not lazy
23:19:24 <seliopou> The original article said, there are things in C/Java/every other language ever that are lazy
23:19:37 <seliopou> To which I said, false
23:19:44 <seliopou> that is not laziness
23:19:57 <wli> Anyway, the poor results of polynomial interpolation can be contrasted with rational interpolation once that's in a comparable state.
23:20:23 <omnId> perhaps the original article is too fast and loose.  But you can say that those operators are indistinguishable from functions with lazy evaluation.
23:20:40 <mauke> ?: behaves exactly like a lazy operator in an otherwise strict language
23:20:40 <lambdabot> Maybe you meant: . ? @ v
23:21:09 <seliopou> makue: In the end result, yes. In how it gets to the end result, no.
23:21:22 <seliopou> er.. mauke
23:21:39 <seliopou> That is exactly what I said in my comment
23:21:44 <mauke> seliopou: huh?
23:22:01 <seliopou> http://programming.reddit.com/info/5yigz/comments/c029qui
23:22:01 <sjanssen> seliopou: explain to me why ?: isn't lazy
23:22:02 <lambdabot> Title: programming: Haskell Myths
23:22:09 <seliopou> see the above link
23:22:13 <omnId> in the absence of side-effects, "how it gets there" is irrelevant.
23:22:24 <seliopou> so says you
23:22:34 <mauke> seliopou: that doesn't make sense to me
23:22:41 <omnId> in terms of semantics
23:23:02 <mauke>  ?: takes three thunks. it evaluates the first one, then returns either the second or the third thunk.
23:23:11 <seliopou> mauke: No.
23:23:13 <mauke> yes.
23:23:15 <seliopou> No.
23:23:18 <seliopou> It simply doesn't
23:23:18 <mauke> why not?
23:23:25 <seliopou> Because it is not a lazy language
23:23:36 <seliopou> it checks the condition to see if it is true or false
23:23:37 <mauke>  ?: is not a language
23:23:41 <lokimaf_> whats the type of a function
23:23:42 <lokimaf_> ?
23:23:48 <seliopou> if it is true, it evalutes the true branc, otherwise it evaluates the false branch
23:23:49 <lokimaf_> nm
23:23:59 <mauke> seliopou: what's the difference?
23:24:00 <seliopou> mauke: obviously
23:24:08 <sjanssen> hmm, conditional evaluation smells like laziness to me
23:24:11 <mauke> and by difference I mean observable difference
23:24:23 <seliopou> in the case of a lazy function, there are three thunks produced
23:24:40 <mauke> OBSERVABLE
23:24:42 <seliopou> in the case of ?: one might be produced
23:25:10 <sjanssen> seliopou: now you're talking implementation strategy
23:25:14 <omnId> no, ?: doesn't make thunks.  It still behaves like a lazy function might.
23:25:17 <sjanssen> this is different from semantics
23:25:20 <seliopou> who cares about observable? Laziness is implemented one way, conditional branching is implemented another
23:25:28 <mauke> seliopou: no, it isn't
23:25:30 <sjanssen> seliopou: false
23:25:34 <seliopou> that is what laziness is!
23:25:39 <mauke> I can implement C on top of lazy evaluation
23:25:50 <sjanssen> seliopou: I can write a Haskell compiler that compiles to conditionals, and a C compiler that compiles to thunks on the heap
23:26:07 <quicksilver> seliopou: laziness is a semantic concept, not an implementation one
23:26:09 <sjanssen> implementation isn't the important thing here
23:26:45 <quicksilver> although actually I think we're talking about non-strictness here :) but perhaps not worth adding more pedantry :P
23:26:56 <sjanssen> :)
23:27:00 <seliopou> So that they have the same flavor is indisputable, but to call conditional lazy is just wrong
23:27:09 <sjanssen> seliopou: why?
23:27:27 <seliopou> because laziness is a term applied to evaluation strategies and function application
23:27:29 <sjanssen> seliopou: I think you need to justify your claim with a definition
23:27:34 <seliopou> ?: or if then else is not a function
23:27:34 <lambdabot> Maybe you meant: . ? @ v
23:27:47 <seliopou> see above
23:27:53 <mauke> seliopou: C functions aren't functional anyway
23:27:56 <seliopou> and by and I meant at
23:28:16 <oerjan> actually, isn't non-strict rather than lazy the term used for haskell, precisely to avoid implementation issues?
23:28:17 <seliopou> the discussion has nothing to do with being functional
23:28:41 <seliopou> by function I mean, function, procedure, method, subroutine, etc.
23:28:47 <mauke> lame
23:29:19 <mauke> I apply "laziness" to operators, not just functions
23:29:20 <omnId> seliopou: if the wording were that "those operators in the other languages have non-strict semantics" would you be satisfied?
23:29:26 <quicksilver> seliopou: laziness or non-strictness is about expression evaluation (not 'function evaluation')
23:29:28 <seliopou> mauke: that's your mistake
23:29:30 <omnId> rather than "are lazy"
23:29:35 <mauke> seliopou: NO U
23:29:43 <quicksilver> seliopou: ? : is an expression builder in C, just like + and &&
23:29:46 <seliopou> mauke: NO U
23:29:55 <quicksilver> seliopou: ?: and && both have non-strict semantics, while + has strict
23:30:01 <omnId> @slap seliopou and mauke
23:30:01 <lambdabot> Plugin `slap' failed with: IRCRaised getRandItem: empty list
23:30:06 <mauke> haha
23:30:12 * seliopou <3 mauke
23:30:23 <omnId> @slap omnId
23:30:23 <lambdabot> Plugin `slap' failed with: IRCRaised getRandItem: empty list
23:30:26 <omnId> hmm
23:30:52 <oerjan> @vixen are you being buggy again, eh?
23:30:52 <lambdabot> Plugin `vixen' failed with: IRCRaised getRandItem: empty list
23:30:54 <seliopou> quicksilver: you might have a point there, but what about if then else (in C)
23:31:03 <seliopou> ?
23:31:16 <oerjan> @list slap
23:31:17 <lambdabot> slap provides: slap
23:32:03 <omnId> seliopou: would you prefer that the original article say the operators were non-strict instead of lazy?
23:32:04 <iank> @slap lambdabot
23:32:04 <lambdabot> Plugin `slap' failed with: IRCRaised getRandItem: empty list
23:32:13 <quicksilver> in C, if then else isn't an expression builder, it's a statement builder, if you use the standard C definition of the word 'expression' and 'statement'
23:32:32 <quicksilver> but you could give a denotation for C in which statements were a kind of expression
23:32:41 <quicksilver> that's just a 'local convention' of naming really
23:32:55 <seliopou> omnid: the original article went as far as saying, "a jump is basically the most primitive mode of lazy evaluation"
23:32:58 <seliopou> So, I guess not.
23:33:29 <omnId> okay so it was just a *touch* fast and loose with correctness on terms and details :)
23:33:47 <olsner> hmm... the original article was not entirely successful in debunking the myths
23:33:55 <quicksilver> in isolation that is a weird comment, yes
23:34:09 <quicksilver> but of course jumps are certainly a tool for implementing it...
23:34:19 <quicksilver> and I could imagine a train of argument which might lead you to say that
23:34:28 <seliopou> quicksilver: I more meaningless statement, I have never seen
23:34:35 <seliopou> :P
23:35:17 <quicksilver> seliopou: Colourless green ideas sleep furiously.
23:35:26 <seliopou> Where is that from
23:35:37 <quicksilver> I used to share a room with a linguisticist
23:35:46 <quicksilver> that's the canonical example of a meaningless statement :)
23:35:53 <seliopou> grammatical yet meaningless
23:36:02 <quicksilver> right
23:36:06 <omnId> passes my syntactic analyzer
23:37:15 * oerjan recalls there have been writing contests based on making it mean something
23:37:39 <omnId> Babies blue a loop loop FUCK unwittingly the as purple RUN!
23:39:02 <seliopou> Anyways, anybody seen Legend?
23:39:12 <seliopou> :P
23:39:59 <Nafai> What's Legend?
23:40:16 <seliopou> http://en.wikipedia.org/wiki/Legend_%28film%29
23:40:17 <lambdabot> Title: Legend (film) - Wikipedia, the free encyclopedia
23:40:18 * omnId would presume it's a movie
23:40:21 <seliopou> It has Tom Cruise and unicorns
23:40:26 <seliopou> or rather, unicorn
23:40:32 <ski> invisible pink unicorns ?
23:40:44 <seliopou> No, but this was back when tom cruise still had bad teeth
23:40:53 <seliopou> go figure
23:43:29 <Pseudonym> This is before he jumped the couch?
23:43:34 <seliopou> 1985
23:44:33 * omnId 's birth year
23:45:06 * Pseudonym remembers 1985
23:45:18 * Pseudonym remembers where he was when he heard that John Lennon was shot
23:45:48 * omnId was probably figuring out what his fingers were at the time.
23:46:05 <Pseudonym> That was in 1980.
23:46:54 <Pseudonym> I think that's my earliest pop-culture-related memory.
23:47:35 <Pseudonym> I have plenty of memories from the 7 years before that, like Farrah hair and flares, but none related to pop culture events.
23:49:41 <Pseudonym> My wife beats me on that, though.  She's older than I am, and she vaguely remembers hippies.
23:49:48 <raxas> in 1985, raxas wrote an Ackermann function implementation in Pascal using arrays only, without recursion
23:51:19 <Korollary> I remember the Sledgehammer video
23:51:19 <raxas> and it could not be done without goto. take that, anti gotoists!
23:51:34 <Korollary> was that in 1986?
23:52:24 <olsner> goto can be emulated without goto, using e.g. a loop and a switch
23:53:17 <Korollary> yes, it was in 1986
23:53:39 <raxas> olsner: try it on ackermann
23:55:19 <olsner> put every basic block in its own part of the switch, then just set the doNext variable to the label you would goto
23:55:48 <mauke> I think I've seen that on thedailywtf.com
23:56:10 <olsner> yep, I've finally found a use for it ;-)
23:56:48 <olsner> http://worsethanfailure.com/Articles/The_FOR-CASE_paradigm.aspx
23:56:49 <lambdabot> Title: The FOR-CASE paradigm - Worse Than Failure
