00:30:34 <edwardk> @seen ski
00:30:34 <lambdabot> ski is in #haskell-overflow, ##logic and #haskell. I last heard ski speak 1d 9h 22m 25s ago.
00:32:15 * wli has trouble building HSSL
00:32:51 <wli> (Haskell GSL bindings)
00:33:31 <wli> unrecognized option `--numeric-version'
01:26:19 <sannysanoff> adept: hi there
01:26:32 <Sizur> good morning #haskell
01:27:05 <ADEpt> sannysanoff: hi :)
01:27:11 <masak> Sizur: morning
01:29:35 * wli gets desperate for linear algebra packages.
01:30:21 <sannysanoff> adept: I tried to explain to my friend that he will definitely love haskell (like any beginner), and he said "i don't need haskell". I tried various approaches. Finally he said, "I don't need Haskell, because I have Clean". Then he started to praise the speed of Clean. Why it's so? He says that in real world tasks clean is 10x faster. (I hope it is not flame topic here)
01:30:33 * wli wonders how people survive without them, or otherwise if someone has a stash of such floating around.
01:31:50 <wli> sannysanoff: Not sure there's a defense against that apart from waiting for the residual performance issues to get cleaned up [sic].
01:32:03 <goalieca> haskell compiler is still relatively young
01:32:15 <ADEpt> sannysanoff: why, you can tell him: "no, haskell is 10x faster!", and it'll be 1:1 :)
01:32:34 <goalieca> i should say ghc is relatively young instead
01:32:49 <wli> goalieca: I don't think so. I think Haskell's got a broader set of design goals than Clean.
01:32:50 <sannysanoff> we agreed to solve same task (suitable for beginnger like me) in Clean (he) and Haskell (me). Then we will know for sure.
01:33:09 <ADEpt> sannysanoff: besides, speed is not the end in itself. Next time with Clean, look for things like STM, GADT, ...
01:33:16 <sannysanoff> i hope it is not 10x times difference.
01:33:29 <sannysanoff> i know that feature set in haskell is 100x times larger
01:33:44 <ADEpt> sannysanoff: you might just look at "great computer language shootout" and meditate over results stored there
01:33:51 <wli> sannysanoff: I'd expect Haskell to lose and 10x is not out of the question by any means.
01:33:52 <goalieca> haskell has STM, experimental data parallelism
01:33:53 <goalieca> etc.
01:34:18 <sannysanoff> yeah, he agrees with "haskell has more features, nevertheless". It's only about speed.
01:34:43 <wli> sannysanoff: Performance requires some sophistication. Beginners will not get the speed for such contests.
01:34:47 <goalieca> if it is about speed then code in c and make use of cache instructions and intrinsics :P
01:34:57 <roconnor> ASM!
01:35:08 <goalieca> c is faster than asm :P
01:35:17 <roconnor> c--?
01:35:40 <roconnor> half way between asm and C
01:35:49 <roconnor> wait
01:35:52 <goalieca> in fact.. write the entire program in c, then ffi a single call in haskell
01:35:54 <roconnor> c-- is really slow isn't it?
01:35:54 <wli> sannysanoff: Realistically Haskell is making steady progress in terms of performance but it is not the sole focus of the programming language research.
01:36:00 <sannysanoff> so, for haskell (GHC in particular) is it possible to get the same speed some day? or there is something that says: "it's so sophisticated that it's virtually impossible to get the same speed as simpler language like Clean" ?
01:36:20 <roconnor> @hoogle par
01:36:20 <lambdabot> Control.Parallel.par :: a -> b -> b
01:36:20 <lambdabot> List.partition :: (a -> Bool) -> [a] -> ([a], [a])
01:36:20 <lambdabot> Data.IntMap.partition :: (a -> Bool) -> IntMap a -> (IntMap a, IntMap a)
01:36:49 <roconnor> is the semantics of par a b the same as b?
01:36:56 <roconnor> denotational semantics
01:37:02 <goalieca> sannysanoff, haskell is more declarative than imperative. It says what to do not how to do it. So technically with a sufficiently smart compiler...
01:37:17 <wli> goalieca: Please let's be concrete about it.
01:37:37 <wli> sannysanoff: There are issues with boxing and unboxing that could be easily resolved for vast speedups.
01:37:44 <ski> roconnor : i would assume so
01:37:44 <goalieca> well then i'm way out of my league because i don't write compilers for a living
01:38:15 <wli> sannysanoff: In like fashion there are transformations like CPS that could be done internally for more similarly vast speedups.
01:38:27 <roconnor> ski: I was thinking the other day that we need a version of seq that doesn't normalize a before be, but starts a parallel thread to normalize a.
01:38:37 <roconnor> ski: but that is obviously what par is
01:38:50 <roconnor> s/before be/before b/
01:38:58 <sannysanoff> goaleica, in this terms, Haskell and Clean are similar
01:39:20 <wli> sannysanoff: There are different things the compiler team is focusing on, most likely related to novelty as opposed to the raw amount of speedup it's possible to reap.
01:40:05 <sannysanoff> wli, yes, that's what I was thinking of.
01:40:32 <goalieca> we should get a bunch of grad students to come up with some reduction algorithms
01:40:35 <goalieca> hehe
01:40:54 <osfameron> ibid: hehe, fair enough. One of the problems with Vox...
01:41:08 <sannysanoff> goaleica, how many people do actually work on core of GHC?
01:41:21 <goalieca> sannysanoff, i haven't a bloody clue
01:41:28 <Zao> Most of them are probably named Simon.
01:41:31 <wli> No, we need far more people to be brought up to speed on ghc internals.
01:41:33 <sannysanoff> zao: hehe
01:41:58 <goalieca> seriously though.. lets just advertise some grad projects for it
01:42:01 <wli> There need to be more than 3 people named Simon who can implement speedup program transformations.
01:43:13 <goalieca> from what i understand though ghc started out producing c code as output
01:43:20 <goalieca> only recently able to generate asm
01:43:34 <goalieca> so it is quite young in that regard
01:44:38 <wli> I, in particular, don't have much of a vested interest in the Haskell language. I'm not an advocate. I'm not a "fan boi." I use it because it suits me to use it for farting around with the sorts of things I fart around with (which are really not all that much more elevated than, say, calculating pi to zillions of places, generating long lists of primes, or similarly pointless affairs).
01:45:22 <wli> So when I say these things I think I have the objectivity and detachment for accurate judgment.
01:45:59 <wli> (This is not to say I couldn't be wrong out of ignorance or fallacious reasoning.)
01:47:47 <wli> Haskell's primary promise over Clean is that its IO encapsulation construct is actually useful for software engineering purposes where the uniqueness types don't do much of anything of that sort.
01:48:50 <wli> Most of the other, more experimental features of Haskell besides the monadic affairs don't really make that big of a difference either way.
01:50:11 <goalieca> I haven't found a use for haskell in my research.. but learning haskell has made me a better c++ programmer
01:50:45 <wli> sannysanoff: There's my 100,000 ft. pointy-haired PowerPoint slide summary of why I'd go for Haskell over Clean despite the current codegen efficiency situation.
01:50:56 <ibid> osfameron: would have submitted my version of the function, after seeing the spec but not having read further :)
01:51:01 <goalieca> does clean have lazyness?
01:51:17 <wli> goalieca: Yes. Also typeclasses, though they're restricted to one method each.
01:51:27 <sannysanoff> wli, where?
01:51:38 <osfameron> ibid: ooo!  hpaste?
01:51:45 <wli> goalieca: Its method of dealing with IO and mutable state is uniqueness types.
01:51:45 <sannysanoff> goaleica, yes
01:52:43 <wli> sannysanoff: The "PowerPoint slide summary" characterization was only likening my blather to the sorts of things that would appear in PowerPoint slide presentations. There are no actual PowerPoint slides.
01:52:46 <goalieca> i've always thought about learning ocaml
01:53:09 <sannysanoff> wli, I suspected
01:53:09 <wli> I learned SML and Ocaml before Haskell.
01:53:16 <sannysanoff> wli, ;-)
01:53:36 <wli> I miss ML modules very, very badly, and not as a replacement for typeclasses in any sense.
01:54:32 <wli> (or alternative, or whatever)
01:55:20 <sannysanoff> wli, what are you working on?
01:55:32 <sannysanoff> wli: (on daily basis)
01:56:02 <wli> There is a lot of talk about ML modules and typeclasses overlapping in some respect or other and IMHO it's hogwash. Scope control is another beast entirely on a software engineering level even if you can encode programs "equivalently" with both constructs.
01:56:10 <wli> sannysanoff: The Linux kernel.
01:56:17 <ibid> osfameron: it's a oneliner, as i just did it in ghci and didn't bother with files
01:56:22 <ibid> osfameron: for init test next body | test init = do { body init ; for (next init) test next body } | otherwise = return ()
01:56:41 <ibid> osfameron: reformatting for layout left as an exercise for the reader :)
01:56:51 <sannysanoff> wli: and haskell/sml/ocaml helps you? or it just made you better C programmer too?
01:56:53 <osfameron> ibid: ah, that's cute
01:57:13 <ibid> osfameron: similar to your first attempt
01:58:23 <osfameron> ibid: yeah, only a) functional, and b) nice with the guards
01:58:50 <ibid> dunno about that functional part
01:58:59 <ibid> unless you mean function*ing* :
01:58:59 <ibid> )
01:59:17 <osfameron> yeah, in that sense of the word :-)
01:59:57 <wli> sannysanoff: There are subsidiary tasks which do not consist of code to be directly incorporated in the kernel for which I use Haskell. Others most typically use perl for them. Log processing, kernel statistics collection, numerical experiments with hash functions, statistical computations on profile data, email processing(!), and so on are things I do with Haskell that are pertinent to work.
02:00:36 * ibid is reminded of the poster in comp.lang.c when responding to a post crossposted from comp.lang.functional: "What do you mean C isn't a functional language? I use it every day at work!"
02:01:03 <sannysanoff> wli, thanks, I got the idea. So, for you haskell code is in small tools you write for yourself.
02:01:31 <sannysanoff> wli, ... for personal use
02:02:50 <wli> sannysanoff: I would not say that Haskell has made me a better C programmer. I would say that it's had little or no effect on my abilities as a programmer. I'd already futzed with a broad variety of languages prior to settling on Haskell as my favorite scripting language and so exhausted what boosts were possible to reap from knowing multiple languages (which did improve my C programming).
02:03:07 <sioraiocht> are we having the "real world uses of haskell" discussion?
02:03:41 <wli> sannysanoff: Those are my uses in professional practice. My personal uses are more akin to recreational mathematics.
02:03:57 <wli> sioraiocht: Sort of, yes.
02:04:06 <sioraiocht> I love this discussion :)
02:04:12 <wli> sannysanoff: There are other, better examples of real-world users of Haskell than myself.
02:04:36 <sannysanoff> sioraiocht: with each new learner you will have it.
02:04:45 <osfameron> project euler questions exist in the real world, right? ;-)
02:04:50 <sioraiocht> hahaha
02:04:57 <sioraiocht> sannysanoff: yes, I was a new learner once, myself
02:05:37 <sannysanoff> wli: "other, better examples of real-world users of Haskell than myself." -- everyone says so.
02:05:52 <sioraiocht> I like haskell because I like using it. Except for software dev, you can usually use whatever programming languges you want to accomplish your tasks in the workplace
02:06:16 <sioraiocht> my b/f used to use Lua all the time at work for system scripts, because he became obsessed after using it for world of warcraft mods
02:07:34 <wli> I basically use Haskell as a scripting language where many others would use perl, python, or ruby. Just as neither perl, python, nor ruby code gets submitted for incorporation in the kernel, neither does my Haskell code.
02:07:35 <quicksilver> sioraiocht: however what may be enlightening is to think about why you like using it :)
02:07:44 <sannysanoff> wli, got it.
02:08:02 <quicksilver> I like using haskell because I find that programs I write in haskell are more likely to work correctly first time.
02:08:16 <sioraiocht> quicksilver: because it's so EASY, and PRETTY
02:08:26 <sioraiocht> and yes, the type system makes your programs usually work if they compile
02:08:28 <wli> The reason why I like using Haskell is essentially that it's very close to ASCII-transcribed mathematical notation. I use ghci heavily as a calculator with data structures.
02:08:31 <quicksilver> And I find that the process of encoding my program in haskell data types is likely to bring design errors to my attention earlier rather than later.
02:08:51 <quicksilver> so I'm less likely to have wasted a day on a fundamentally flawed design.
02:08:53 <osfameron> I find that my haskell programs either work immediately and surprisingly, or don't work at all and give error messages I don't understand :-)
02:09:08 <sioraiocht> the type system will spit errors out, and in the process of just tyring to get it to compile I figure out..."wow...it actually WORKS, now"
02:09:28 <sannysanoff> i work in software house, and we all use java for our projects. This is boring, because you type in too much to express your ideas (since 1996). I'm interested in cooperative work (as opposed to dirty immediate scripting of helpers), and whether it's done in haskell. Unfortunately, there are more java programmers than people who want to do something better. With better results, too.
02:10:41 <sannysanoff> ... but so far I see mostly perl replacements for log analyzing (forgive me).
02:11:06 <sioraiocht> sannysanoff: that's not unusual.  I do a lot of work in perl for dirty parsing like that
02:11:23 <sioraiocht> I find myself less of a fan of haskell when it comes to regular expressions
02:11:45 <wli> > let step (cur, prev) a = (a * cur + prev, cur) ; evalCF ((hST, kST), ~(a:as)) = ((step hST a, step kST a), as) ; cvgts = tail $ (map (uncurry ((/) `on` fromIntegral) . (fst *** fst) . fst) $ iterate evalCF (((1, 0), (0, 1)), 2 : 1 : concat [[2*n, 1, 1] | n <- ([1..] :: [Integer])] ) :: [Rational]) in takeWhile ((<50) . length . show) $ drop 3 [(min a b, max a b, fromRational (abs $ b - a) :: Double) | (a, b) <- zip cvgts (tail cvgts)]
02:11:47 <lambdabot>  [(19%7,11%4,3.571428571428571e-2),(19%7,87%32,4.464285714285714e-3),(106%39,...
02:12:01 <wli> One instance of recreational mathematics.
02:12:43 <sioraiocht> wtf?!
02:13:07 <sannysanoff> wli: what was that? I'm so far from academic applications (unfortunately)
02:13:15 <wli> sioraiocht: BS with rational approximations to e.
02:13:44 <sioraiocht> sannysanoff: you will also find that learning about haskell will force you to learn more about programming language theory, just because of its design, and that in turn will make you a FAR better programmer
02:13:50 <wli> sannysanoff: Silly garbage about transcendental numbers.
02:14:22 <sannysanoff> sioraiocht, this makes me thrill!
02:14:36 <sioraiocht> sannysanoff: also, you will find that haskell programs will often be more succinct, like as much as 75% smaller, imo
02:14:53 <sannysanoff> sioraiocht, already
02:15:02 <oklopol> K pwns haskell at that though
02:15:36 <ski> measures in characters, or ast nodes ?
02:16:20 <oklopol> i don't know what ast nodes are, but you are probably right, K probably loses in ast nodes.
02:16:52 <oklopol> in characters, it's verrrry short
02:17:19 <oklopol> unfortunately i've never managed to find a K compiler/interp, so don't know that much about it
02:17:33 <sannysanoff> ok, thanks for answers, I'm off back to "lathe".
02:17:46 <sioraiocht> anyone know what causes random muscle spasms
02:18:21 <jeffz> sioraiocht: stress or sign of developing alzheimers.
02:18:32 <quicksilver> overexercise or underexercise
02:18:41 <sioraiocht> quicksilver: it's probably the former
02:18:48 <quicksilver> high levels of lactic acid in the tissues
02:18:58 <sioraiocht> hrm..I don't do any aerobic sports, lol
02:19:00 <ski> `AST' being "Abstract Syntax Tree'
02:20:48 <wli> quicksilver: I'm having enough problem finding a sufficiently expressive type system that's not taking me off into the weeds of research problems with type inference etc. that I'm thinking the entire project is too big or too advanced to take on.
02:22:58 <quicksilver> wli: I don't know the answer. But that is what I suspected. I think the type system required to get the mtl working is necessarily quite hefty.
02:25:12 <wli> quicksilver: Determining the simplest type system required to get it working would probably be something of a research topic in and of itself.
02:25:20 <quicksilver> ;)
02:26:47 <oklopol> ski: you mean a lisp-style representation of the code :P
02:26:56 <oklopol> *presentation
02:26:58 <oklopol> asdsd
02:28:16 <ski> oklopol : i just mean an abstract representation tree of the syntax .. nearer to counting concepts used, than characters (or lines, or tokens) used
02:34:06 <wli> I was truly shocked that MPTC's were such an unresolved subject.
02:35:36 <osfameron> MPTC?
02:35:53 <wli> Multi Parameter Type Classes
02:38:32 <quicksilver> MPTCs on their own are pretty straightforward
02:39:06 <quicksilver> the problem is that in practical usages of them the compiler would be unable to choose the right instance unless you pollute your interface with lots of dummy parameters
02:39:27 <quicksilver> hence, fundeps and ATs and ATSes and so on.
02:40:58 <quicksilver> (if you add explicit instances choice to your language they are totally un problematic. Just ugly).
02:41:56 <wli> Well, an ordinary typeclass is just a 1-place predicate on types, so you get qualified types like (Q_1 t_1, Q_2 t_2, ..., Q_n t_n) => T(t_1, ..., t_n) where T is some unqualified type expression involving t_1, ..., t_n and the Q_k are type qualifiers.
02:43:22 <wli> Entailment lets you nuke a bunch of these by basically noticing that Q_k t_i implies Q_l t_j so you can drop Q_l t_j; similarly if you need to know that Q_l t_j holds you can smoke it out of the reduced context.
02:43:31 <quicksilver> right
02:43:40 <quicksilver> mptcs are no harder though
02:43:52 <wli> All this generalizes directly to multiple predicates.
02:43:53 <quicksilver> makes your notation a bit heavier :)
02:44:03 <wli> Rather, multiple-place predicates.
02:44:52 <wli> But in all honesty I've not the vaguest idea of what a fundep represents and AT's and type families and so on make even less sense.
02:45:55 <wli> I can't even really figure out what the latter end up meaning when you start fiddling with types.
02:46:42 <quicksilver> wli: ok, well that's not too hard to explain
02:46:51 <wli> (That is how to alter inference and checking algorithms to take them into account etc.)
02:46:51 <quicksilver> wli: a fundep is only about instance selection, that's all
02:47:07 <wli> Okay. I could use a dumbed-down explanation if you've got the time.
02:47:09 <quicksilver> suppose 'foo' is a method of the class C a b c
02:47:14 <wli> Okay.
02:47:19 <quicksilver> and foo has type foo :: a -> b
02:47:32 <quicksilver> really, foo is a family of functions, foo_a,b,c
02:47:43 <quicksilver> we've got to decide which a, b and c to choose
02:47:45 <quicksilver> to get the right one
02:47:46 <wli> Indexed by type, sure.
02:47:47 <quicksilver> (the right instance)
02:48:04 <quicksilver> now, "a" should be clear enough by type inference on the argument
02:48:13 <wli> (Indexed by the type parameters of the MPTC that is.)
02:48:22 <quicksilver> with a little luck, "b" is clear by type inference on the context foo is appearing in
02:48:32 <quicksilver> if it isn't, an explicit type annotation can solve that
02:48:44 <quicksilver> however "c" is totally up in the air
02:48:54 <quicksilver> the type checker has aboslutely no way to determine which "C" to use
02:49:02 <quicksilver> and there isn't even a way you could add a type annotation to make it clear
02:49:31 <ski> `class Foo a b | a -> b' means `forall a. unique b. Foo a b', or `forall a b0 b1. (Foo a b0,Foo a b1) => b0 = b1' or `forall b0 b1. (exists a. (Foo a b0,Foo a b1)) => b0 = b1' .. or in words : "for any specific type `a', you may have at most one `b' associated with it such that `Foo a b' holds" .. so in some sense `b' should be "reconstructible/determinable" from `a'
02:50:12 <quicksilver> wli: so, the point is, we need some way to decide "C"
02:50:26 <quicksilver> wli: fundeps let you say "Ah, well, in fact there is only one possible C for any particular choice of A"
02:50:36 <quicksilver> wli: or, one possible C for any particular A, B, etc
02:50:51 <quicksilver> wli: so then the type-checker knows which C to use, and can pick the right foo.
02:50:55 <quicksilver> even that much is fairly simple
02:51:11 <quicksilver> the REALLY HARD bit is deciding when instance declarations actually satisfy the fundeps you have declared
02:51:17 <wli> quicksilver: This sounds weird because it doesn't really specify c in any way.
02:51:17 <quicksilver> that's where it all gets into a mess
02:51:25 <quicksilver> right. it doesn't.
02:51:33 <ski> this allows the type inference/checking to know that in a local context, for specific `a',`b0',`b1', if `Foo a b0' and `Foo a b1' holds, then `b0 = b1' must be true .. so this reduces ambiguity, thus not requiring as much context or explicit type ascription to knwo which instance to use
02:51:43 <quicksilver> so you just have to give the type-checker a great big hint.
02:51:50 <wli> quicksviler: You're merely promising that the instances do so?
02:51:53 <quicksilver> like saying "actually c is uniquely determined by a"
02:51:59 <quicksilver> wli: that's right. it's merely a promise.
02:52:10 <quicksilver> wli: and the bloody hard bit, is writing a compile which "checks" that promise is true.
02:52:18 <quicksilver> wli: for a given set of instance declarations.
02:52:38 <wli> quicksilver: Okay, what is an AT and how does it attack this problem?
02:52:55 <wli> ski: Sorry I'm needing a far more dumbed-down presentation than that.
02:53:11 <quicksilver> so the AT appraoch is different
02:53:22 <quicksilver> the fundep "a -> c"  is a hint to the type checked
02:53:29 <quicksilver> it says "For every a there is only one c"
02:53:42 <quicksilver> in mathematics, we have another word for that
02:53:48 <quicksilver> we could say "c is a function of a"
02:53:53 <quicksilver> so let's make that explicit
02:53:59 <quicksilver> let's make c a type-level function
02:54:07 <ski> for Associated Types, instead of having `class Foo a b | a -> b where {..a..b..}', one has `class Foo a where {type B a; ..a..B a..}' iiuc
02:54:13 <quicksilver> ATs are one way of shoe-horning a kind of type-level function into haskell.
02:54:28 <quicksilver> or, ATFs and ATSes are.
02:54:40 <quicksilver> I'm not familiar enough with the notation to give examples, I always get it wrong :P
02:55:07 <wli> quicksilver: I'm in enough need of concepts I'll take any notation I can get.
02:55:25 <ski> so for each instance of `Foo a', (i.e. for specific `a's) you get to pick what type `B a' is for *this* `a'
02:55:32 <Sizur> the key is to always use arrows ;) cannot go wrong with arrows in maths lol
02:57:16 <wli> What's the difference between ATF and ATS?
02:57:32 <geocalc> f s
02:58:38 <ski> wli : saying `a -> b' is *declaring* that we require that `a' determine `b' .. it doesn't in any way give a way of computing `b' for any `a' (there doesn't have to exist any `b', btw, just at most one `b')
02:59:08 <quicksilver> ski's last point is a good way of explaining it
02:59:10 <wli> ski: Okay.
02:59:16 <quicksilver> ATs let you actually explicitly choose the b
02:59:20 <quicksilver> when you write the instance
02:59:25 <ski> wli : when using multiple instances in the same context, the language processor is required to check these declarations, by checking that there is no two instances for the same `a'
02:59:32 <wli> You also write b as a function of a.
02:59:39 <quicksilver> you write the instance for "a", and as part of the instance, you say "the corresponding b is"
02:59:52 <quicksilver> yes, although to be fair it doesn't have to be a natural function of a
02:59:53 <ski> quicksilver : can't you choose with FDs, too ?
03:00:00 <quicksilver> it can be arbitrarily chosen pointwise
03:00:13 <quicksilver> ski: yes, you can...
03:00:23 <ski> quicksilver : although possiblt ATs allow making the choice for `b' abstract at the module bounadry (not sure)
03:00:29 <wli> In the FD's, b as a function of a only comes about from instances.
03:00:33 <Sizur> too much writing, can somebody explain using pictures and music please
03:01:01 <wli> In the AT's b as a function of a comes about in the class decl?
03:01:14 <Sizur> and lego pieces if available
03:01:15 <ski> wli : no .. same with both i think
03:01:42 <ski> (wli : also the function is partial, since you don't need to have an instance for any `a' .. just uniqueness, not necessarily existence)
03:02:07 <ski> in both cases, the type function is partially determined by all the instances together
03:02:15 <wli> ski: semidet when phrased in terms of det, semidet, multidet, and nondet.
03:02:19 <ski> s/function is partially/partial function is/
03:02:27 <ski> wli : exactly
03:02:56 <wli> ski: So what people want is a terminating typed fragment of Prolog at the type level?
03:03:10 <ski> wli : that's a good way of thinking of this (i.e. FDs) .. as a mode declaration of the MPTC
03:03:43 <wli> ski: One could, in principle, apply mode inference and puke on failure to infer semidet.
03:03:48 <ski> wli : well, there's some more complications, because we have instance members, and issues with ambiguity
03:03:52 <doserj> wli: some people want full prolog :)
03:04:08 <wli> ski: Okay what are the issues with instance members and ambiguity?
03:04:19 <wli> doserj: Well, that's a bit extreme.
03:05:50 <ski> wli : well, as quicksilver said, if you have an instance member whose type doesn't mention one of the MPTC parameters, then we don't know which instances to choose from those that differ only in that parameter
03:06:19 <ski> wli : and since those instance members could have different semantics, we must disambiguate in some way
03:06:57 <ski> one way if lifting out some members to a superclass with some of the full functionality, but only mentioning some of the params
03:07:09 <scook0> relational normalization!
03:07:13 <ski> (:
03:07:38 <wli> ski: If you do the Prolog -like solving you barf if you get a result that isn't unique or fail to get a result.
03:08:05 <ski> another way is requiring that the nonmentioned parameter is determined by the mentioned ones, for each member, so that there can be at most one instance to choose from, in each case, so no ambiguity
03:08:43 <ski> (which is what quicksilver said)
03:09:07 <wli> ski: So it seems that there's no need to do anything about it if your Prolog bits do enough work.
03:09:37 <wli> ski: This can't be true given how much fuss there is about it. Where did I go wrong?
03:09:50 <ski> also, as mentioned, it can be used to simplify (and possibly disambiguate that way) `Foo a b0',`Foo a b1' into `Foo a b' where `b' is the unification of `b0' and `b1' (iiuc)
03:10:09 <ski> wli : i'm not sure what you're asking
03:10:16 <doserj> wli: it is hard to define a terminating subset of prolog, that is at the same time general enough
03:11:01 <geocalc> knapsck it
03:11:11 <wli> ski: I don't see why you have to deal with FD's at all if the subset of Prolog at the type level is full enough.
03:11:42 <doserj> FD's *are* the subset of Prolog
03:12:18 <ski> wli : FDs (and ATs) help reduce ambiguity .. in the case of member functions, it is necessary to get predictable result
03:12:25 <wli> ski: Either you find a type that works and it's unique, or you find no type, or you find multiple types. The promise that a type is unique seems irrelevant.
03:12:32 <ski> wli: : what do you mean by `subset of Prolog' ?
03:12:40 <ski> wli : do you include a mode system ?
03:12:49 <wli> ski: Yeah.
03:13:16 <wli> ski: But only in the sense that everything essentially has to be semidet.
03:13:34 <ski> wli :what if you find a type that works, but, because instances are open, don't know whether anyone later will add a conflicting instance (one making things definitely not unique) ?
03:13:57 <wli> ski: I don't know how that could happen.
03:14:17 <Philippa> trivially
03:14:26 <Philippa> that's what MPTCs without fundeps have to assume can happen
03:14:29 <ski> just compile your library, then later someone else links that to his/her code with conflicting instances
03:14:47 <Philippa> two different modules with two conflicting instances, that's all
03:15:21 <wli> ski: Presumably compiling their modules would barf because they import the library and get a conflicting instance.
03:16:12 <wli> Philippa: It sounds like importing them simultaneously would cause an error.
03:17:19 <wli> I'm missing something if these examples are meaningful.
03:19:53 <Philippa> the requirement that there be a single answer is critical, semantically speaking - you can't decide which piece of evidence to pass without a unique answer, you'd have to make Haskell non-det at the term level
03:20:46 <wli> A single answer regardless of which modules are in scope?
03:21:24 <quicksilver> the problems here are no worse than for single-parameter type classes
03:21:32 <Philippa> yes, because otherwise you can get conflicting evidence
03:21:40 <quicksilver> you always have to report an error if modules contain conflicting instances
03:21:43 <ski> you don't want to commit to one instance, only to later have someone add another instance that could just as well have been chosen
03:22:44 <wli> Okay, the cross-module thing is a killer. I don't understand why it's needed but I see why it screws up a lot of thins.
03:24:25 <ski> for uniqueness we want an absolute guarantee, while the fails we get for not finding an instance just tells us that : that an instance was not found (now), it still might exist (i.e. being known/added later)
03:25:13 <wli> I don't see why different modules have to see the same instance.
03:26:14 <wli> Though I can see why requiring all modules to see the same instance if one exists throws a monkey wrench in straightforward approaches to the type system.
03:27:20 <quicksilver> if we could allow partially applied type synomyms in instance declarations
03:27:30 <quicksilver> then we could use type-level functions and be fone with it
03:27:38 <quicksilver> that's not easy though, either, as I understand it.
03:30:13 <ski> quicksilver : but `ATs' (and FDs, though worse syntax) also gives separatedly defined (partial) type functions .. like caseing on the argument types
03:30:53 <wli> I'm still stuck on why different modules have to see the same instance.
03:31:40 <ski> wli : i'm not sure, but i think it can be related to requiring that every instance defined or imported into a module is also exported from it (and you can't choose not to import an instance from an imported module) .. and i assume that has to do with coherence in some way (not saying one couldn't in some way lift this restriction)
03:32:31 <wli> ski: So by the time you get to Main.lhs the conflicting instances will all eventually be in scope or the modules unused?
03:32:40 <ski> if you want to combine two modules in the same program, then the instances of both modules will be imported into some main module, where the functional dependency wouldn't hold any longer
03:32:47 <ski> yes
03:33:21 <quicksilver> wli: in principle there is not a problem with multiple instances and some way to select
03:33:33 <quicksilver> wli: an extension was written to allow this
03:33:39 <ski> (however, i think there should be some wayo to have "implementation-private" classes and instances, that shouldn't be exported, simply because the class isn't known outside)
03:34:16 <wli> ski: My #1 beef with the current module system for general software engineering reasons.
03:34:29 <quicksilver> all the fiddlyness of the current typeclass system is to do with automatic instance selection
03:34:40 <quicksilver> at the Fc level (which selects instances explicitly) everything is quite clear
03:34:55 <Philippa> that's because at the Fc level there ain't no typeclasses
03:34:58 <quicksilver> right
03:35:05 <quicksilver> but there are uniquely typed dictionaries
03:35:16 <quicksilver> which is equivalent to 'explicitly selected instances'
03:35:35 <quicksilver> it seems remarkably hard to find the sweet-spot in automatic instance selection, though
03:35:42 <Philippa> IIRC that uniqueness isn't enforced though?
03:36:02 <quicksilver> not quite what I meant
03:36:12 <quicksilver> I just meant that if Show is a class, then ShowDict is an Fc type
03:36:25 <quicksilver> ShowDict is isomorphic to (a -> String)
03:36:32 <wli> quicksilver: Scoped instances and a beefier module system to actually manipulate namespaces and the instances they carry around sound like an instant solution.
03:36:34 <Philippa> sure. Point being that all you've got there is the scars of a process that happened elsewhere - there simply isn't any typeclass-related machinery in System Fc
03:36:45 <quicksilver> yes, absolutely
03:36:58 <quicksilver> the point I was making is that "this is semantically straightforward at the backend"
03:37:00 <wli> quicksilver: Was that wrt. my scoped instance comment?
03:37:07 <quicksilver> it is making a sufficiently pretty front-end that's hard
03:37:16 <quicksilver> wli: no
03:37:28 <quicksilver> wli: however, it is somethinig I'd like
03:37:41 <Philippa> at times like this I tend to think that the front/back end distinction gets a little artificial - by Fc, you've compiled it all out at the type level
03:38:02 <Philippa> whereas most other typing constructs are still in a fundamental sense there
03:40:57 <mcp_> Hi, new types i create by using data are not comparable. I have to add deriving(Eq) to type declaration to make them comparable. Is this what i have to expect from my types, or is my declaration faulty?
03:41:33 <Philippa> that's what you have to expect
03:42:10 <Philippa> for example, if your type includes another one that isn't in Eq then there can't be an Eq instance. Or your type may have non-comparable semantics
03:42:49 <Philippa> (or require a context to be compared - you can't usefully compare two keys for equality without knowing they're supposed to come from the same map, for example)
03:43:02 <quicksilver> mcp_: or in some cases you may choose to implement a special instance of Eq
03:43:10 <quicksilver> mcp_: because there are some things you don't care about
03:43:18 <ski> (Philippa : to nitpick, there can be an instance if you write it explicitly (e.g. ignoring or explicitly providing way to compare the subpart without `Eq'))
03:43:23 <quicksilver> but deriving (Eq) does the 'obviously right' thing for 'obvious, simple, data'
03:44:23 <hpaste>  katana pasted "emerge --update --deep world" at http://hpaste.org/3557
03:45:54 <geocalc> ^ is hpaste not only for haskell things ?
03:45:58 <jedbrown> Is there an easy way to see the total time spent evaluating a particular library function, such as Data.Map.partition, regardless of context?
03:46:05 <hpaste>  katana annotated "emerge --update --deep world" with "emerge --update --deep world" at http://hpaste.org/3557#a1
03:46:06 <ivanm> geocalc: it's a ghc problem :p
03:46:13 <ivanm> though he shouldn't be announcing it
03:46:28 <quicksilver> jedbrown: yes. profiling.
03:46:48 <quicksilver> jedbrown: http://www.haskell.org/ghc/docs/latest/html/users_guide/profiling.html
03:46:50 <lambdabot> Title: Chapter 5. Profiling, http://tinyurl.com/kwh6c
03:46:53 <jedbrown> Should that be the default if the profiling library is installed?
03:46:57 <quicksilver> jedbrown: GHC has quite sophisticated profiling stuff
03:47:09 <quicksilver> jedbrown: although sometimes lazy evaluationw ill surprise you
03:47:19 <quicksilver> (things may not happen attributed to the subroutine you expect)
03:47:28 <jedbrown> Yes, I'm reading that, building with -prof -auto-all, and running with +RTS -p
03:47:38 <hpaste>  katana annotated "emerge --update --deep world" with "emerge --update --deep world" at http://hpaste.org/3557#a2
03:48:00 <jedbrown> But the .prof file only has my top-level definitions.
03:48:21 <quicksilver> jedbrown: simplest thing might be to wrap Data.Map.partition into a top-level of your own
03:48:29 <quicksilver> jedbrown: and give it a SCC (or use -auto-all)
03:49:07 <jedbrown> Oh, that's simple, but not very flexible.
03:50:25 <opqdonut> if i want an immutable structure with fast indexing i guess i should use IArray?
03:50:55 <opqdonut> i mean, IntArray
03:51:27 <wli> quicksilver: So basically all this stuff about FD's, AT's, et al is about instance selection?
03:51:53 <scook0> opqdonut: UArray Int?
03:52:07 <ac> has anybody here had any experience with curry?
03:52:15 <quicksilver> wli: Yes. Absolutely.
03:52:18 <opqdonut> yeah UArray thanks
03:52:27 <quicksilver> ac: hmm. Jalfrezi is a favourite.
03:52:46 <scook0> opqdonut: depending on circumstances, it might be worth making your code polymorphic in IArray
03:53:11 <scook0> (which just means more general type sigs)
03:53:22 <quicksilver> scook0: and slower code :)
03:53:47 <scook0> quicksilver: true
03:53:57 <wli> quicksilver: So if there were ways to explicitly select instances, it would all vanish in a puff of logic programming?
03:54:13 <opqdonut> i'm modelling state machines in haskell, i was thinking whether it's wise to use "data FSM a = Array Int (Array a Int)"
03:54:26 <quicksilver> wli: yes. Although automatic instance selection is rather the point of typeclasses, from one perspective.
03:54:39 <opqdonut> maps might be nicer in a sense
03:54:52 <fox86> those of you who are proficient in haskell, do you often use other languages as well?
03:54:55 <ac> quicksilver: hm maybe I'll try that someday. I was actually talking about the extension to Haskell though
03:55:14 <ac> I suppose I should have capitalized it
03:55:36 <quicksilver> fox86: yes. Mostly perl at the moment, in prior lives, C, C++, Java etc.
03:55:53 <Philippa> quicksilver: xerox didn't much like his jalfezi at AngloHaskell :-)
03:56:04 <quicksilver> :(
03:56:26 <Philippa> yeah. Good thing I didn't have him try a little of my phall really, the jalfrezi was too hot for him
03:56:26 <ac> It sounds pretty good to me now... especially because I'm hungry
03:57:18 <Philippa> ac: you mean Curry the functional logic language?
03:57:39 <ac> Philippa: yeah. I tried to experiment it before I started with Haskell, but I gave up because I couldn't get any basic libraries to work
03:58:10 <fox86> quicksilver: because you prefer to, or is it work-related?
03:58:25 <wli> quicksilver: Not sure what to say to that. I guess it depends on how explicit you have to get and how large a subset is mostly automatic.
03:58:49 <quicksilver> wli: agreed
03:59:02 <quicksilver> wli: and, that's why it seems to be surprisingly hard to hit the sweet spot
03:59:10 <quicksilver> wli: in my own code, I often don't use typeclasses
03:59:17 <quicksilver> wli: I just bundle up a dictionary instead
03:59:38 <quicksilver> fox86: surprisingly hard to give a short answer to that
04:00:32 <wli> quicksilver: I find that most of the time the typeclasses and instances I need are already there (e.g. in the MTL).
04:00:50 <quicksilver> fox86: combination of historical reasons, staffing issues, library availability
04:00:55 <ac> fox86: since I started writing Haskell, I have not written a single line of code in any other language ;)
04:01:19 <wli> I've written mostly C for the Linux kernel.
04:01:36 <fox86> ah, okay
04:01:54 <wli> Most of the scripting tasks I've run into are either already done or far too large to take on.
04:02:16 <hpaste>  quicksilver pasted "dictionary by hand" at http://hpaste.org/3558
04:02:17 <fox86> i suppose that once i've learned haskell, i will be unemployed for the rest of my life because i refuse to use other languages
04:02:23 <wli> Those that remained I used Haskell for.
04:02:40 <quicksilver> wli: see that paste for an example
04:03:00 <quicksilver> wli: 'Behaviour' is essentially a dictionary
04:03:11 <quicksilver> I could use the type class selection mechanisms to choose a behaviour automatically
04:03:19 <quicksilver> (based on the type of 's' or something else, perhaps)
04:03:40 <quicksilver> but actually, that's not really convenient
04:03:50 <quicksilver> I'd rather be able to give subtly different behaviours to particle particles
04:03:57 <quicksilver> and not try to do anything clever and magic with types
04:04:01 * wli fails to get http://alberrto.googlepages.com/gslhaskell to compile.
04:04:02 <lambdabot> Title: Alberrto - A simple scientific library for Haskell
04:04:21 <wli> quicksilver: Do you use numerical linear algebra libs, and if so, which?
04:09:30 <quicksilver> wli: no. I write stuff by hand :)
04:10:18 <jedbrown> wli: try http://perception.inf.um.es/~aruiz/darcs/HSSL
04:10:34 <wli> jedbrown: That's the same lib.
04:11:44 <MyCatSchemes> Yarrrr.
04:11:47 <jedbrown> wli: I just rebuilt it 10 minutes ago.
04:12:33 <geocalc> quicksilver=<< when will you give the link to dl your project (again this question ;) )
04:12:54 <wli> jedbrown: I get build errors. Any chance you could look at that I'm doing wrong?
04:14:08 <jedbrown> wli: What sort of errors?  I assume you have GSL headers installed.
04:14:36 <wli> Setup.lhs: executing external program failed (exit 127) : /usr/local/bin/alex --version
04:14:36 <wli> unrecognized option `--numeric-version'
04:15:01 <wli> jedbrown: /usr/local/bin/alex isn't even executable.
04:15:14 <wli> -rw-r--r-- 1 wli src 503132 Apr 17  2003 /usr/local/bin/alex
04:15:59 <geocalc> chmod +x it
04:16:02 <jedbrown> Hmm, I have -rwxr-xr-x 1 root root 629744 2006-11-24 07:19 /usr/bin/alex
04:16:12 <jedbrown> (Installed from Debian)
04:16:20 <wli> jedbrown: I have a normal /usr/bin/alex it doesn't seem to find.
04:16:46 <wli> Setup.lhs: executing external program failed (exit 1) : /usr/bin/c2hs --numeric-version
04:16:54 <MyCatSchemes> > "Ya" ++ (repeat 'r')
04:16:59 <lambdabot>  "Yarrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr...
04:16:59 <wli> jedbrown: Now I get that and c2hs is completely normal.
04:17:06 <MyCatSchemes> Yay, lambdapirate.
04:17:28 <ski> @yarr
04:17:28 <lambdabot> Eat maggoty hardtack, ye unkempt, jenny frequentin', son of a gun.
04:18:27 <jedbrown> wli: I don't even have c2hs installed (although I do have hsc2hs)
04:19:01 <MyCatSchemes> ski: that raises the question of how on Earth guns breed?
04:19:12 <wli> jedbrown: I also have hsc2hs
04:19:22 <wli> jedbrown: I don't know why c2hs is being used.
04:19:36 <jedbrown> wli: Do you have a recent Cabal?
04:19:50 <wli> jedbrown: I don't have the foggiest idea how to use cabal.
04:20:30 <jedbrown> wli: I think it was for something else, but I have Cabal-1.2.1 installed.  I had to do it locally since there isn't a package for it.  That may be fix your problems.
04:21:12 <wli> jedbrown: What package is cabal in?
04:21:23 <geocalc> ghc
04:21:57 <jedbrown> wli: http://darcs.haskell.org/cabal-branches/cabal-1.2/
04:21:58 <lambdabot> Title: Index of /cabal-branches/cabal-1.2
04:22:10 <wli> jedbrown: No debs? Okay.
04:23:15 <ski> MyCatSchemes : guns can't procreate, they're sterile .. however, there's gun factories ..
04:23:29 <wli> jedbrown: What do I do once I finish darcs getting it?
04:24:04 <dcoutts> wli: I'd get the package off of hackage rather than going to the darcs version
04:24:07 <wli> (sorry if this is a bit much wrt. handholding; I'm a bit out of it due to recent surgery)
04:24:13 <wli> dcoutts: Okay.
04:24:16 <jedbrown> wli: runhaskell Setup.lhs configure --prefix=$HOME/usr, etc.
04:24:41 * dcoutts also recommends cabal-setup and cabal-install
04:25:23 <wli> dcoutts: Are they separate packages?
04:25:29 <dcoutts> wli: yes
04:25:32 <geocalc> dcoutts=<< what about cabal-make ?
04:25:45 <dcoutts> geocalc: na
04:25:55 <geocalc> ok
04:26:05 <quicksilver> geocalc: sent you PM, don't think you got it.
04:26:20 <geocalc> no
04:26:43 <osfameron> can you do haskell 1-liners?  As in: $ runhaskell -e 'your code goes here'    ?
04:27:17 <dcoutts> osfameron: ghc -e 'print "hello world"'
04:27:35 <osfameron> dcoutts: ah, cool, thanks
04:29:23 <wli> Okay, I'm mildly stumped.
04:29:34 <wli>     Could not find module `Text.PrettyPrint':
04:31:01 <geocalc> wli=<< ghc version ?
04:31:26 <wli> The Glorious Glasgow Haskell Compilation System, version 6.7.20070830
04:32:32 <LeCamarade> ^]:r !ghc -V
04:32:59 <geocalc> with 6.6.1 i didn't have this error wli
04:33:15 <jedbrown> wli: I've got 6.6.1 as well.
04:33:19 <quicksilver> recent ghcs have the rearranged base packages
04:33:22 <wli> No idea what to do about that.
04:33:27 <quicksilver> which means that cabal dependencies won't work
04:33:50 <quicksilver> don't use unreleased ghc's unless you know how to fight a morass of library renamings :)
04:33:58 <geocalc> that's bad ^
04:33:58 <LeCamarade> Is there a place to find the new order?
04:34:31 <osfameron> bash$ function hi { x="interact $ $1"; ghc -e "$x"; }
04:34:34 <wli> The most I can do is uninstall the new ghc's or possibly point the autoconf crud at the old ghc.
04:35:50 <wli> Would the darcs versions of cabal do better with the newer ghc's?
04:36:01 <quicksilver> it's not a problem with the cabal version
04:36:03 <quicksilver> AIUI
04:36:10 <quicksilver> the problem is the fact that the libraries now have different names
04:36:25 <quicksilver> so the dependencies on the .cabal file for the thing you are trying to compile, are wrong
04:36:35 <quicksilver> dcoutts would be the one who actually knows, though :)
04:37:22 * LeCamarade will confess to having generated doc by echo :b Network.HTTP | ghci -v0 > /tmp/network.http.txt :o)
04:37:30 <dcoutts> wli: sounds like you're using a rather old ghc-6.7, cabal-1.2 has only been tested with ghc-6.4, 6.6 and 6.8.0.x
04:37:44 <wli> Okay, how do I point cabal at the stock Debian 6.6.1 (which is also there; the new ghc's are in /usr/local/)
04:38:09 <dcoutts> wli: build it with ghc-6.6.1
04:38:12 <wli> I'm trying to build a fresh ghc from darcs as we speak.
04:38:30 <dcoutts> wli: I'd use a ghc nightly snapshot tarball
04:38:40 <wli> dcoutts: Easy enough. Fetching.
04:39:40 <dcoutts> wli: to build cabal for ghc-6.6.1 rather than ghc on the path, do make setup; ./setup configure -w ghc-6.6.1; ./setup build; sudo ./setup install
04:39:57 <wli> nativeGen/MachCodeGen.hs:118:27: Not in scope: `assignReg_I64Code'
04:40:02 <wli> I forget how I solved this.
04:40:29 <dcoutts> wli: is that in the nightly 6.8.0.x snapshot?
04:40:53 <wli> dcoutts: darcs; the nightly I'd not started trying to deal with.
04:41:01 <dcoutts> oh ok
04:41:27 <wli> dcoutts: I'd be very interested in a nightly snapshot.
04:41:45 <dcoutts> there are also binaries
04:42:12 <wli> dcoutts: Can I choose installation dirs for binaries so they land in /usr/local/?
04:42:36 <dcoutts> wli: that's the default, you can override with --prefix
04:42:55 <wli> If /usr/local/ is the default I don't even have to override.
04:45:21 <profmakx> yay 6.9 ghci segfaults :(
04:46:01 <jedbrown> From my emacs buffer, while waiting at the interactive prompt: Process ghci segmentation fault (core dumped)
04:46:09 <jedbrown> (just now)
04:46:29 <profmakx> i hava broke yout ghci!
04:46:40 <fox86> what is ghc written in? C?
04:46:46 <Sizur> haskell
04:46:49 <therp> fox86: mostly haskell
04:46:53 <wli> jedbrown: What did you do to trigger it?
04:47:02 <therp> fox86: parts are written in cmm, some C support files.
04:47:19 <jedbrown> Nothing.  It was just sitting at the prompt.  I was in another buffer and when I came back, that was sitting there.
04:47:25 <jedbrown> No worries though.
04:48:00 <fox86> therp: ah, okay. what is cmm?
04:48:03 <wli> Okay, latest ghc nightly snapshot installed.
04:48:58 * profmakx did it with latest snapshot on FreeBSD7/amd64
04:50:07 <therp> fox86: cmm, is C-minus-minus, or C--. http://www.cminusminus.org/ - it's a target language for compilers that resembles C semantics but occasionally modified
04:50:09 <lambdabot> Title: C-- Home
04:50:47 <fox86> therp: aah, i read about it on SPJ's webpage
04:51:15 <therp> fox86: but the thing on cmm.org isn't the code used in GHC. GHC needs a few extensions to work on top of cmm well
04:51:46 <wli> Setup.lhs: At least the following dependencies are missing:
04:51:46 <wli>     zlib >=0.3, HTTP >=3000.0&&<3001.1
04:51:53 <wli> Okay, what to do there?
04:52:45 <fox86> therp: i see
04:53:25 <dcoutts> wli: grab them from hackage
04:53:33 <Japsu> grr
04:53:44 <dcoutts> wli: once you've got cabal-install built, then it does that task automagically
04:54:02 <dcoutts> ie the dep chasing, downloading & installing dependent packages
04:54:22 <profmakx> i suppose the segfault is related to the new linking code?
04:55:02 <wli> I'm totally unclear on how to use cabal for anything at the moment.
04:55:02 <profmakx> i will prepare a few patches etc. for FreeBSD7/amd64 during the weekend, just if someone is interested testing this ;)
04:58:23 <dcoutts> wli: the standard operating procedure is: http://haskell.org/haskellwiki/Cabal/How_to_install_a_Cabal_package
04:58:25 <lambdabot> Title: Cabal/How to install a Cabal package - HaskellWiki, http://tinyurl.com/39kra4
04:59:10 <dcoutts> wli: that is unless you're using cabal-install in which case you'd just say  $ cabal install xmonad
04:59:22 <wli> Okay I did that but there's something wrong with one of the versions.
05:00:50 <dcoutts> wli: and if you get messages when building packages like "blah uses Foo.Bar which is part of package baz-1.0 which is hidden" then it really means "this package has not been updated for ghc-6.8"
05:02:34 <wli> dcoutts: Well, I got a different error.
05:02:40 <wli> Setup.lhs: At least the following dependencies are missing:
05:02:40 <wli>     zlib >=0.3, HTTP >=3000.0&&<3001.1
05:02:59 <dcoutts> wli: and this was after you'd installed those two?
05:03:01 <wli> I got that again, despite doing the runhaskell Setup.lhs bits.
05:03:08 <dcoutts> where did you install them?
05:03:15 <dcoutts> globally or per-user
05:03:19 <wli> dcoutts: Yeah. I'm not entirely sure.
05:03:35 <dcoutts> wli: ghc-pkg list zlib
05:03:43 <dcoutts> that tells you if it's registered
05:03:51 <wli> dcoutts: Looks per-user.
05:04:04 <dcoutts> wli: ok, then when you configure use --user
05:04:17 <wli> I want global
05:04:18 <dcoutts> wli: ontherwise it only looks at the packages you installed globally
05:05:04 <dcoutts> wli: a library to be installed globally cannot depend on libs that are only installed locally
05:05:09 <wli> Things told me to do --user
05:05:22 <wli> That was not what I wanted. Fixed.
05:05:31 <dcoutts> wli: but cabal-install isn't a library, so it'd be ok to use --user and --prefix=/usr/local
05:05:40 <dcoutts> but only because it's a binary and gets statically linked
05:06:01 <wli> cabal-install is installed.
05:06:20 <dcoutts> cabal-install defaults to per-user installs of everything under ~/.cabal/
05:06:37 <wli> That will have to be overidden.
05:06:45 <dcoutts> wli: so you can $ cabal update
05:06:56 <dcoutts> wli: and you can edit the settings in ~/.cabal/config
05:07:44 <dcoutts> you can set the prefix and if it should do per-user installs or not
05:08:00 <wli> Okay.
05:08:16 <dcoutts> but if you want global installs you'll have to su/sudo
05:08:29 <dcoutts> we've not worked so much on that side yet
05:08:29 <wli> gid permissions are set up properly.
05:09:10 <dcoutts> so if you encounter problems please report them at: http://hackage.haskell.org/trac/hackage/
05:09:13 <lambdabot> Title: Hackage - Trac
05:11:20 <wli> HSSL / GSLHaskell isn't on hackage.
05:11:46 <dcoutts> someone needs to bug the author
05:11:53 <dcoutts> if it's not on hackage it doesn't exist
05:13:36 <dcoutts> wli: cabal-install also works for locally unpacked packages, untar, cd, $ cabal install
05:13:51 <wli> I'm just building the thing with 6.6.1
05:14:43 <dcoutts> cabal install -w ghc-6.6.1
05:14:49 <wli> I'll try with 6.9.20071030 once I resolve the debian package deps.
05:15:29 <dcoutts> (hmm actually I'm not sure the -w flag works yet)
05:16:01 <wli> Heh, they don't honor --prefix somehow.
05:16:34 <dcoutts> wli: what doesn't? cabal-install?
05:17:04 <wli> Whatever build system they're using they did not set up to honor --prefix
05:17:11 <nominolo> dcoutts: we could topologically sort the graph and remove all back-edges
05:17:20 <dcoutts> nominolo: ok, fine
05:17:32 <dcoutts> nominolo: that keeps it as a DAG right?
05:17:39 <nominolo> pretty sure
05:17:45 <dcoutts> ok
05:18:03 <nominolo> i still don't understand the suggestion from sorear
05:18:08 <dcoutts> nominolo: I pushed the patches from yesterday
05:18:24 <dcoutts> nominolo: so darcs pull and work with that, rather than the current gobby version
05:18:39 <wli> The updates for more recent ghc are pretty easy. Just stick the package in the Build-Depends: list.
05:18:54 <dcoutts> wli: yes
05:18:57 <wli> HSSL built for ghc-6.9.20071030
05:19:15 <dcoutts> wli: though it's slightly more tricky to make it work with both 6.6 and 6.8 at once
05:19:19 <nominolo> dcoutts:  btw, what license is your dotty-code?  i modified it to enable different edge-styles and use it for my MSc thesis (internally)
05:19:38 <dcoutts> nominolo: lets say public domain shall we
05:19:51 <nominolo> dcoutts: ok
05:20:12 <wli> dcoutts: I'm not concerned about that at all. I'll just be using the latest snapshot I've bothered to install.
05:20:22 <dcoutts> wli: right
05:20:53 <dcoutts> wli: if you find the time, pester the hssl author to get his stuff on hackage
05:21:12 <dcoutts> almost everything else is distributed from there now
05:23:14 <wli> Okay, I now have numerical linear algebra libs. I'm getting very, very dangerous.
05:24:53 <wli> ghc-6.9.20071030: panic! (the 'impossible' happened)
05:24:53 <wli>   (GHC version 6.9.20071030 for i386-unknown-linux):
05:24:53 <wli>         linkBCO: >= 64k insns in BCO
05:41:57 * wli is a very happy camper.
05:42:44 <quicksilver> excellent
05:43:47 * wli is already cranking out eigenvalues of matrices.
05:48:56 <exDM69> @pf \x -> foldl (+) 0 $ (flip take) [1..] x
05:48:56 <lambdabot> Maybe you meant: bf pl
05:49:15 <exDM69> how did this work=?
05:49:22 <ricky_clarkson>   @PL
05:49:59 <exDM69> @PL \x -> foldl (+) 0 $ (flip take) [1..] x
05:50:00 <lambdabot> Maybe you meant: . ? @ bf ft id pl rc v wn
05:50:02 <ricky_clarkson> @pl \x -> foldl (+) 0 $ (flip take) [1..] x
05:50:02 <lambdabot> foldl (+) 0 . flip take [1..]
05:50:14 <ricky_clarkson> PL was because of my stupid caps lock key..
05:50:37 <exDM69> ah, function composition, of course
05:50:53 <exDM69> not function application
05:51:43 <jberg> what does @pl do?
05:51:49 <exDM69> makes code point free
05:52:00 <jberg> cool
05:52:17 <ricky_clarkson> @pl \x -> 10*x+2
05:52:17 <lambdabot> (2 +) . (10 *)
05:52:19 <jberg> pointless code :)
05:53:40 * wli has instantly become very very dangerous. ;)
05:55:08 <profmakx> hm. have you solved some NP-complete problem in P-time?
05:55:30 <quicksilver> it was speculated that installing cabal might be NP-complete
05:55:35 <quicksilver> it was never proven, though
06:03:08 * wli attempts to come up with a plan of action.
06:04:21 <nominolo> @hoogle mapMaybe
06:04:22 <lambdabot> Maybe.mapMaybe :: (a -> Maybe b) -> [a] -> [b]
06:04:38 <nominolo> @hoogle Set.mapMaybe
06:04:39 <lambdabot> No matches, try a more general search
06:09:43 <wli> Hmm. The matrix formation primitives don't give you easy ways to do some of the things I want (of course).
06:13:01 <wli> "Here are bands sitting in blocks of these shapes to land in these positions in an otherwise zero matrix."
06:15:19 <nominolo> @instances Monoid
06:15:24 <lambdabot> (), (a -> b), (a, b), (a, b, c), All, Any, Dual a, Endo a, Ordering, Product a, Sum a, [a]
06:15:46 <nominolo> > Maybe 2 `mappend` Nothing
06:15:47 <lambdabot>   Not in scope: data constructor `Maybe'
06:15:54 <nominolo> > Just 2 `mappend` Nothing
06:15:55 <lambdabot>   add an instance declaration for (Monoid (Maybe t))
06:15:55 <lambdabot>     In the expression: (...
06:16:02 <EvilTerran> mplus?
06:16:15 <EvilTerran> @instances MonadPlus
06:16:16 <lambdabot> Either e, ErrorT e m, IO, Maybe, RWST r w s m, ReaderT r m, StateT s m, WriterT w m, []
06:16:18 <nominolo> No, i want to use foldMap
06:16:26 <quicksilver> :t foldMap
06:16:28 <lambdabot> Not in scope: `foldMap'
06:16:40 <quicksilver> there should be a way to make a monoid out of a monadplus, but there isn't
06:16:41 <nominolo> :t Data.Traversable.foldMap
06:16:42 <lambdabot> Not in scope: `Data.Traversable.foldMap'
06:17:01 <nominolo> quicksilver: it would lead to undecidable instances
06:17:07 <quicksilver> nominolo: I meant via a newtype
06:17:16 <quicksilver> like Product and Endo
06:17:43 <nominolo> right. one could do that
06:21:29 <nominolo> :t Data.Foldable.foldMap
06:21:31 <lambdabot> forall a m (t :: * -> *). (Data.Foldable.Foldable t, Monoid m) => (a -> m) -> t a -> m
06:25:17 <quicksilver> nominolo: still, I think there is no harm defining the monoid instance for Maybe
06:25:43 <quicksilver> nominolo: I think it's maybe a bit unusual to want to use foldMap on a maybe like that though
06:25:55 <quicksilver> nominolo: isn't it a bit like 'sequence' ?
06:26:13 <nominolo> I really want mapMaybe for sets
06:26:23 <nominolo> just written a libraries proposal
06:26:29 <quicksilver> go via fromList / toList, I would have thought
06:26:41 <nominolo> that's O(n * log n)
06:26:50 <nominolo> the direct implementation is O(n)
06:26:56 <quicksilver> I don't believe it is
06:27:03 <quicksilver> the direct implementation is n log n also
06:27:08 <quicksilver> you are going through the set and changing stuff
06:27:13 <quicksilver> therefore it needs to be rebalanced
06:27:15 <quicksilver> so you pay
06:27:37 <quicksilver> the only way you could get O(n) is if you could promis the map was monotonic
06:27:40 <quicksilver> (order-preserving)
06:27:51 <nominolo> true.
06:27:53 <nominolo> hm
06:28:08 <nominolo> still, it's a fairly standard function
06:28:24 <quicksilver> I think maybe the correct thing to want is a generic version of catMaybes
06:28:35 <quicksilver> which you would then compose with fmap
06:28:54 <nominolo> but i don't think that fuses well
06:29:00 <quicksilver> I don't see your library proposal yet?
06:29:07 <nominolo> one sec :)
06:30:38 <nominolo> ok, sent
06:32:02 <nominolo> damn, now i forgot where i wanted to use it ...
06:32:49 <mdmkolbe|ubunt1> Does TH do type checking all at once before the fragments are spliced together or does it have to type check the meta-programm and then later type check the resulting program afterwards?
06:32:52 <ac> After reading a little about GPGPU (General Programming on GPUs), it looks like it's generally done using off screen rendering with OpenGL, so no compiler modification would really be necessary, like I was talking about earlier.
06:35:46 <flux> not having read about it, I'd imagine the (yet unimplemented, perhaps slightly unrealistic) idea would be to somehow automatically gpuize existing haskell code?
06:36:15 <quicksilver> that is clearly the holy grail, yes
06:36:32 <flux> if we try to be a bit more realistic, perhaps the approach of data parallel haskell would be an option
06:36:39 <quicksilver> it requires compiler modifications if you want to use "normal operations" like (+) and (*)
06:36:44 <quicksilver> actually
06:36:46 <quicksilver> maybe it doesn't
06:36:47 <ac> flux: the hardware is specific enough that that is never been realistically considered
06:36:50 <quicksilver> maybe overloading Num is enough
06:37:11 <ac> *that has
06:37:20 <quicksilver> hmm
06:37:24 <quicksilver> I'm not sure what you mean, ac?
06:37:37 <ac> But the existing techniques of using textures as data structures could certainly be improved with a decent library
06:37:38 <quicksilver> commodity hardware now ships with GPUs capable of non-trivial calculation
06:39:10 <quicksilver> it would apear that recognising when a 'general calculation' could be GPU-ised is definitely a compiler issue and very hard
06:39:26 <quicksilver> but, yes, making textures-as-data-structures convenient could be much easier
06:39:27 <matthew_-> > 3
06:39:27 <lambdabot>  Illegal character ''\173''
06:39:27 <lambdabot>  at "3" (column 2)
06:40:04 <quicksilver> I wonder if I could use it for a fast particle engine, for example
06:40:05 <ac> although I should say "common practice" not "existing techniques" as there are already at least two languages for that purpose
06:40:20 <ac> quicksilver: I bet you could. I think nvidia has a demo of that
06:40:38 <ac> quicksilver: nvidia also has a fluid dynamics demo
06:41:29 <ac> As far as I can tell, they both just use OpenGL and GLEW
06:44:48 <ac> Kind of funny how you do maps using pixel shaders, and reduce operations by rendering a large texture on to a smaller texture
06:44:51 <ac> (or something like that)
06:45:52 * quicksilver nods
06:46:07 <quicksilver> well you don't need pixel shaders for the simple maps, of course
06:46:15 <quicksilver> addition and a couple of other operations are just a blending mode
06:46:25 <quicksilver> (I don't know if that's actually faster than a pixel shader or not)
06:46:44 <ac> too bad I don't have a video card to play with
06:47:06 <quicksilver> I keep meaning to write a surface-tension particle model, too
06:47:14 <quicksilver> I believe you can do quite cool stuff with that
06:47:23 <quicksilver> some much code, so little time!
06:53:08 <Sizur> who has used Network.FastCGI?
06:53:51 <matthew_-> me
06:54:11 <abell> Sizur, I tried to, but I had problems working with transformed monads
06:55:02 <abell> running a CGIT ( StateT MyState ) IO, if I remember correctly
06:55:43 <Sizur> abell: in the docs i dont see any fastcgi specifics, like getting the url path. do you have to parse that yourself?
06:56:39 <abell> You can get it within the CGI monad
07:00:33 <abell> While building the CGI action to run, you can do path <- CGI.pathInfo
07:00:56 <abell> Network.CGI.pathInfo, I mean
07:05:30 <Sizur> abell: thank you.
07:15:50 <swiert> @yow
07:15:50 <lambdabot> Hmmm ... a CRIPPLED ACCOUNTANT with a FALAFEL sandwich is HIT by a
07:15:50 <lambdabot> TROLLEY-CAR ...
07:16:01 <volk> How do I get value of an element inside a group? like: ("el1", "el2", 0.001)
07:16:19 <swiert> volk: which value do you want?
07:17:08 <swiert> You can pattern match, or call library functions like fst and snd.
07:18:29 <quicksilver> > let foo (a,b,c) = a++b in foo ("el1","el2",0.001)
07:18:31 <lambdabot>  "el1el2"
07:18:55 <quicksilver> volk: pattern matching is the key. Doing pattern matching directly in function definitons (be they local or global) is often an attractive approach.
07:19:26 <volk> ok sound reasonable..
07:19:34 <kowey> hey all... can anybody recommend a good introduction to (typed) lambda calculus for linguists and other non programmers?
07:19:55 <quicksilver> good introductions to lambda calculus tend to be untyped. IME.
07:20:28 <quicksilver> I read banrendregt
07:20:34 <quicksilver> I think that requires some maths background though.
07:21:04 <kowey> yeah, the person who is asking said that this might go over the target audience's heads
07:21:19 <kowey> nothing against linguists, of course
07:21:23 <Philippa> kowey: I can't, but I find translating "\x:y.e" as "given a y, called x, e" helps if you're after the logical interpretation
07:21:35 <Philippa> and then application is just giving it the y
07:21:57 <Philippa> the logical interpretation's probably easier to get people to think about than the computational one at first
07:23:03 <kowey> Philippa: that indeed sounds like a friendly way to say out typed formulas, thanks! (will pass on the idea)
07:25:31 <kowey> anyway, back to your regularly scheduled haskell-related programming... please shout if you have any ideas, books, tutorials, etc
07:34:31 <quicksilver> I wonder when dons will leap into action. There is a -cafe thread with his name on it.
07:36:10 <hpaste>  mdmkolbe pasted "GADT problems" at http://hpaste.org/3559
07:37:02 <mdmkolbe|ubunt1> Is this a bug/misfeature in the GADT design? http://hpaste.org/3559
07:38:39 <wli> polylambda.ps was good, or so I thought.
07:38:56 <ToRA> mdmkolbe|ubunt1 which version of ghc are you using?
07:39:50 <mdmkolbe|ubunt1> ToRA: 6.6.1
07:40:32 <hpaste>  ToRA annotated "GADT problems" with "under 6.8" at http://hpaste.org/3559#a1
07:40:57 <ToRA> i don't think 6.6.1 propogates all the class constraints round correctly
07:41:27 <mdmkolbe|ubunt1> ToRA: 6.8 is still in pre-release right?
07:42:39 <ToRA> think so
07:42:44 <ToRA> it's very close to a release tho
07:44:18 <hpaste>  ToRA annotated "GADT problems" with "Closest I can get working with 6.6.1" at http://hpaste.org/3559#a2
07:44:41 <ToRA> does that help? i assume you don't want the a to be existential tho :(
07:44:58 <mdmkolbe|ubunt1> ToRA: that doesn't fit with my needs, oh well
07:47:41 <quicksilver> mdmkolbe|ubunt1: why isn't ToRA's version what you want?
07:48:49 <quicksilver> mdmkolbe|ubunt1: I'm not sure "data Foo a = forall a. (Show a) => Foo a" means what you think it means?
07:50:52 <mdmkolbe|ubunt1> quicksilver: I have other constructors like Baz :: Bar a -> Bar b -> Bar (a, b)
07:51:20 <quicksilver> well, one thing at a time
07:51:36 <quicksilver> you do realise there are two different 'as' in your data declaration?
07:52:25 <quicksilver> I mean, obviously "a" occurs four times. But syntactically there are two different ones.
07:52:36 <quicksilver> you are binding a type variable and then shadowing it with another.
07:52:48 <mdmkolbe|ubunt1> quicksilver: oh, I guess I really wanted "data Foo a = (Show a) => Foo a"
07:53:05 <oklopol> http://www.vjn.fi/pb/p133216242.txt <<< i fail @ haskell's type system
07:53:09 <oklopol> wanna help?
07:53:16 <quicksilver> In your code you have the type 'Foo :: (Show a) => a -> Foo a1'
07:53:29 <quicksilver> in particular, 'Foo "bar" :: Foo a'
07:53:32 <quicksilver> (not Foo String)
07:53:34 <mdmkolbe|ubunt1> quicksilver: yes, I understand you know. and you are right
07:53:35 <oklopol> it says IORef ProgramState expected, but getting just ProgramState
07:53:48 <quicksilver> mdmkolbe|ubunt1: what did you intend?
07:54:16 <quicksilver> oklopol: you want display :: IORef ProgramState -> IO ()
07:54:26 <quicksilver> oklopol: you have one two many 'IO' in your signature for display
07:55:50 <oklopol> well, as you can prolly see from that, i'm not exactly sure what IORef is, trying to understand it by using it :P
07:56:04 <oklopol> well, i *may* know what it is, just not sure.
07:56:08 <oklopol> hmm
07:56:23 <oerjan> an IORef is a reference to a mutable cell
07:56:30 <oklopol> yeah, i assumed it is
07:56:34 <oerjan> usable from the IO monad
07:56:43 <titusg> @pl \xs -> elem 1 xs || elem 2 xs
07:56:43 <lambdabot> ap ((||) . elem 1) (elem 2)
07:56:48 <mdmkolbe|ubunt1> quicksilver: just like where observing a constructor of a GADT allows you to use more info about the types (e.g. if "Baz :: Int -> Baz Int" then you can write "baz :: Baz a -> a; baz (Baz x) = x"), I want to be able to "discover" class constraints so I can write "gum :: Baz a -> String; glum (Bar a) = show a"
07:56:51 <oklopol> i guess i understand that
07:56:57 <quicksilver> oklopol: typically display doesn't need an IORef at all
07:56:59 <fasta> oklopol: there is documentation, you don't need to reverse-engineer anything.
07:57:15 <titusg> how do I do that with using Ap? There's a way of doing it just with (.), not?
07:57:23 <titusg> with/without
07:57:29 <quicksilver> oklopol: because it is typically an invariant of the display function that it doesn't change the state
07:57:41 <quicksilver> oklopol: so I would normally expect simply display :: ProgramState -> IO ()
07:57:43 <oklopol> fasta: true, i just didn't grasp the documentation tbh...
07:58:21 <fasta> oklopol: in that case you should file a bug explaining how it would better be explained.
07:58:23 <oklopol> quicksilver: it doesn't change the state, but some of my other functions do, so even if i change that for display, others would have the same problrem
07:58:27 <oklopol> *problem
07:58:28 <quicksilver> oklopol: "IORef a -> IO ()" says I can both read and write the 'a' value.
07:58:36 <quicksilver> oklopol: "a -> IO ()" says I can only read it
07:58:38 <quicksilver> much nicer
07:58:52 <quicksilver> personally I prefer "a -> IO a" to "IORef a -> IO ()" anyway
07:58:55 <quicksilver> avoid passing references
07:58:58 <oklopol> yeah, i'll change that, but i need to get that working first, since, as i said, the other functions need it.
07:59:00 <quicksilver> they are gnarly.
07:59:13 <oklopol> just changing the function signature doesn't help
07:59:28 <quicksilver> it should at least change the error
07:59:31 <quicksilver> what did it says now?
07:59:32 <oklopol> it says now it's expecting IORef ProgramState
07:59:46 <oklopol> and getting IO (IORef ProgramState)
07:59:54 <quicksilver> we need details + line numbers
08:00:01 <quicksilver> ah
08:00:04 <quicksilver> no, I see it
08:00:08 <quicksilver> "let programState ="
08:00:15 <quicksilver> programState <-
08:00:19 <quicksilver> in the first line of main
08:00:25 <quicksilver> you need to 'execute' newIORef
08:00:28 <oklopol> fasta: i don't know how it could be better explained, i just fail
08:00:34 <oerjan> oklopol: btw the fields of data declarations usually don't need parentheses around them
08:00:45 <titusg> how do I make a pointsfree function that uses it's input twice, but without using Ap...?
08:00:55 <quicksilver> titusg: join in the -> monad
08:01:01 <quicksilver> titusg: which amounts to the same thing
08:01:04 <oklopol> oerjan: you mean like in data MousePos = MP (GLdouble, GLdouble)
08:01:10 <oklopol> or..?
08:01:15 <quicksilver> (ap and join are two different ways of getting at the structure of the -> monad
08:01:28 <quicksilver> oklopol: yes, it's more idiomatic to simply write MP GLdouble GLdouble
08:01:33 <oerjan> right, could have been data MousePos = MP GLDouble GLDouble
08:01:35 <quicksilver> oklopol: however, what you're doing is not wrong.
08:01:43 <fasta> The documentation does seem a bit short, though.
08:01:44 <quicksilver> (it has more bottoms, but that's not very important)
08:01:57 <oerjan> using parentheses gives you an extra redirection.
08:02:08 <oklopol> ahh now i get it
08:02:15 <titusg> quicksilver, oh dear, -> is a monad? Eek!
08:02:15 <quicksilver> oklopol: anyway, did you see my answer to your actual problem?
08:02:27 <ac> stupid question: how do I specify the type of a function in a let? "let foo x = round $ x ** 2 :: Double -> Int" doesn't seem to work for me
08:02:31 <quicksilver> titusg: yes, it's the "apply a bunch of functions to the same value" monad
08:02:36 <oerjan> otoh if you do use parentheses you may get rid of that by using newtype instead of data (since there is then only one real field)
08:02:47 <oklopol> yep, fixed it, thanks, except i now have another bug... but might be just the fact i cut the program into a test case pretty randomly
08:02:49 <quicksilver> > sequence [(+1),(*3),const 0] $ 5
08:02:53 <oklopol> "test case", hmm
08:02:54 <lambdabot>  [6,15,0]
08:02:59 <quicksilver> titusg: ^^
08:03:08 <fasta> ac: the same as you would do for a top-level function
08:03:30 <quicksilver> ac: let foo :: Double -> Int (new line) foo x = round....
08:03:30 <fasta> ac: let a::Int;a=3 ...
08:03:51 <ac> fasta: ah. that looks odd
08:04:00 <titusg> quicksilver, what's the neat way of doing it using just (.) that I saw an example of somewhere? like (elem 1) . (. elem 3) or something?
08:04:12 <fasta> ac: the ; is only there because I am not using an Emacs IRC client now.
08:04:27 <fasta> ac: it is valid Haskell, but newlines are what I normally use.
08:04:37 <ac> right
08:04:38 <fasta> ac: like quicksilver said
08:04:45 <oklopol> ah, i put 0.0 into the GLint var
08:04:51 <oklopol> fixed, i'll get back to work
08:05:15 <ac> fasta: I assume I can put the type decleration before or after the declaration
08:06:21 <oerjan> titusg: you cannot do it with just . because . is linear, it only uses each argument once
08:06:27 <quicksilver> mdmkolbe|ubunt1: I'm afraid I didn't understand that well enough. I'm not sure it's possible.
08:06:57 <oerjan>  @pl uses join and ap for this
08:07:20 <waern> how do I check if a darcs repository is partial?
08:07:34 <koeien> does anybody know if there is a multiset implementation available for haskell?
08:07:38 <koeien> tried to hoogle, but didn't find any
08:07:45 <quicksilver> koeien: [] ?
08:07:49 <quicksilver> koeien: Data.Sequence ?
08:07:54 <quicksilver> are two
08:08:03 <quicksilver> what kind of thing are you hoping for, from your multiset?
08:08:22 <quicksilver> Map Value Int --- a model of a multiset, by counting multiplicities
08:08:28 <quicksilver> is a third
08:08:37 <koeien> quicksilver: that's a pretty good idea
08:08:47 <quicksilver> keep it simple :)
08:08:50 <mdmkolbe|ubunt1> quicksilver: I've got a hack that does what I want, but I've got to run now
08:08:53 <quicksilver> I'd use [] or Data.Sequence most of the time
08:08:54 <koeien> quicksilver: thanks
08:09:07 <koeien> yes, it's not too big, so lists can be used
08:09:09 <quicksilver> but if your focus is about counting multiplicities and doing stuff with them
08:09:19 <quicksilver> then the Map version might be right
08:09:20 <oerjan> titusg: although one interesting thing is if your original function is also linear (everything used exactly once) then you _can_ make do with just id, . and flip
08:09:48 <volk> I want to read a few strings using getLine recursively into a list of strings. How do I avoid the IO.hGetChar end of file error?
08:10:59 <quicksilver> oklopol: a good principle is 'minimise IORefs, minimise passing around of IORefs'
08:10:59 <oerjan> :t hIsEOF
08:11:07 <lambdabot> Not in scope: `hIsEOF'
08:11:17 <dcoutts_> volk: if you want to read the while file it's easy: ls <- return . lines =<< getContents
08:11:19 <oerjan> :t System.IO.hIsEOF
08:11:20 <lambdabot> GHC.IOBase.Handle -> IO Bool
08:11:45 <oerjan> volk: use hIsEOF to check before each getLine
08:11:48 * wli has never used an IORef and has no idea what others use them for.
08:12:02 <volk> ok thanks
08:12:06 <dcoutts_> wli: avoid them if you can
08:12:10 <oklopol> i'm passing program state around :P
08:12:11 <oerjan> :t isEOF -- might be for stdin
08:12:12 <lambdabot> Not in scope: `isEOF'
08:12:19 <oerjan> :t System.IO.isEOF -- might be for stdin
08:12:20 <lambdabot> IO Bool
08:12:23 * oklopol has done a lot of c++
08:12:25 * wli seems to be having an easy time avoiding them.
08:12:26 <oerjan> volk: or that one
08:12:51 <quicksilver> oklopol: passing state around is fine
08:12:59 <quicksilver> oklopol: it's more-or-less necessary in that kind of program
08:13:07 <quicksilver> oklopol: I'm saying, don't pass around the IORef. Just pass the state iteslf
08:13:27 <dcoutts_> oklopol: the standard way of doing that is passing parameters and getting return values, using hidden side channels like IORefs is best avoided
08:13:27 <oklopol> i'll just pass the ioref for the keyevent function
08:13:44 <quicksilver> I would make your keyevent function havea  type like this:
08:13:49 <oklopol> or.. should i not do that either?
08:13:50 <oklopol> hmm
08:13:52 <quicksilver> keyevent :: ProgramState -> IO ProgramState
08:14:10 <quicksilver> that clearly declares that it takes a state, and returns a new state (after some IO side-effects)
08:14:21 <quicksilver> often, your keyevent may not even have IO side-effects!
08:14:29 <quicksilver> in which case, you get an even cleaner type without IO at all
08:14:34 <quicksilver> keyevent :: ProgramState -> ProgramState
08:14:34 <oklopol> but... opengl is the one doing the calling... so... hmm
08:14:42 <quicksilver> make a thin wrapper
08:14:47 <quicksilver> to bind to openGL
08:14:57 <dcoutts_> or if possible: keyevent :: IO Something; and a pure update function :: Something -> ProgramState -> ProgramState
08:15:02 <quicksilver> the thin wrapper unpacks the IORef
08:15:11 <quicksilver> calls the real function
08:15:14 <quicksilver> and repacks the IORef
08:15:39 <oklopol> i'll try getting this to work first, then make it prettier, kay ;) getting a lot of errors already, since i kinda suck at even the basics.
08:15:59 <quicksilver> fair enough
08:16:00 <oerjan> quicksilver: um, i think oklopol is using the already existing haskell openGL binding?  don't know if that uses IORefs
08:16:03 <quicksilver> that's a good plan :)
08:16:20 <quicksilver> oerjan: you need to use IORefs to hide state inside arbitrary IO callbacks
08:16:24 <quicksilver> oerjan: that's OK
08:16:37 <quicksilver> oerjan: but I minimise it by unpacking the IORef in the callback and calling out to ref-free code
08:16:44 <oklopol> i originally thought i'd make this project using C++ for the result, then decided to do it in haskell for the exercise :P
08:17:11 <quicksilver> oklopol: I'm doing quite a bit of haskell openGL programming in my spare time at the moment
08:17:13 <wli> Hmm, converting a Map to an Array with a default value for missing Array elements would be handy.
08:17:22 <quicksilver> oklopol: so I'm quite familiar with these issues
08:17:51 <oklopol> well, i'm just using a minor subset of opengl currently, i'm actually just using 2d line drawing.
08:18:03 <oerjan> wli: probably need to go by toList in any case?
08:18:33 <quicksilver> oklopol: yeah, but the issue is really about the glut event stuff
08:18:38 <quicksilver> oklopol: and how to store program state
08:18:39 <wli> Probably yes.
08:18:45 <oklopol> true
08:19:13 <oklopol> hmph, i wish i'd learn to decrypt the error messages soon :P
08:19:34 <conal> quicksilver: what's your opengl project?  (i'm barely getting started.)
08:20:00 <quicksilver> conal: a multiplayer turn-based game almost but not entirely unlike chess.
08:20:23 <conal> quicksilver: neat.  multiplayer over the internet?
08:20:40 <oerjan> wli: or perhaps it's better to start with the array range and map ist over the Map (since Map does have functions with convenient defaults)
08:20:47 <quicksilver> conal: yup
08:20:58 <wli> oerjan: Good point.
08:21:21 <oklopol> err...
08:21:22 <oklopol> programState <- newIORef (PS (MP (0.0, 0.0), Idle, GD 10.0, SS (0.0, 0.0)))
08:21:22 <oklopol> programStateReadOnly <- get programState
08:21:22 <oklopol> displayCallback $= display programStateReadOnly
08:21:27 <oklopol> does this look right..? :|
08:21:32 <oklopol> kinda verbose :P
08:22:19 <conal> oklopol: what's "get"?
08:22:38 <oklopol> it takes the value from inside an IORef... i think :)
08:22:51 <conal> oklopol: maybe you mean getIORef
08:22:58 <conal> i mean readIORef
08:23:04 <excitingjelly> what's $= ?
08:23:05 <oklopol> that *works*, though.
08:23:07 <wli> oerjan: [maybe defaultValue id $ Map.lookup key m | key <- keyRange]
08:23:29 <conal> oklopol: wouldn't you want to access the ioref value *inside* the callback?
08:23:45 <oklopol> not inside the *display* callback
08:23:48 <oklopol> i mean
08:23:53 <conal> otherwise, i don't know how the callback would see changing values.
08:23:53 <oklopol> i want it to be readonly there
08:24:07 <oklopol> oh
08:24:08 <oklopol> hmm
08:24:18 <conal> oklopol: i see. hence the name.
08:24:22 <conal> what's the type of "get"?
08:24:57 <oerjan> wli: [Map.findWithDefault defaultValue key m | key <- keyRange]
08:24:59 <oklopol> i actually don't know what happens if i'm just giving the function the variable without the IORef enclosing it, and the IORef's value changes, will display always get the correct, newest programState?
08:25:11 <wli> oerjan: Better still.
08:25:26 <oklopol> conal: i don't actually know :)
08:25:39 <conal> oklopol: can you do ":i get" in ghci?
08:26:09 <oklopol> hmm... not really
08:26:15 <conal> ok
08:26:18 <oklopol> my code won't compile, don't know how to do that
08:26:28 <conal> oh yeah.
08:26:43 <shapr[> mmm, code
08:27:18 <arcatan> MyCatSchemes is an excellent nick
08:27:56 <wli> oerjan: Possibly array (minimum keyRange, maximum keyRange) [(key, findWithDefault defaultValue key m) | key <- keyRange]
08:28:30 <MyCatSchemes> arcatan: thank you? ^_^
08:28:36 <wli> oerjan: Or array (keyMin, keyMax) [(key, findWithDefault defaultValue key m) | key <- [keyMin .. keyMax]]
08:28:44 <quicksilver> conal: no, he means 'get'
08:28:49 <quicksilver> conal: get is a magic StateVar method
08:29:00 <quicksilver> oklopol: but, no that isn't right
08:29:05 <conal> quicksilver: i see.
08:29:08 <MyCatSchemes> arcatan: I usually use MyCatVerbs, but MCS and MCV were both picked specifically for their relative uniqueness in Google.
08:29:23 <quicksilver> conal: it basically gives a uniform interface to openGL properties and IORefs
08:29:29 <oklopol> quicksilver: what's wrong with it?
08:29:33 <quicksilver> oklopol: one second and I'll paste a fragment of code
08:29:34 <oklopol> i just meant it looks verbose :P
08:29:39 <oerjan> wli: i am not sure if Ix order is required to be the same as the ordinary one
08:29:43 <quicksilver> oklopol: (that makes your dislpay always use the initial state)
08:29:49 <oklopol> ah.
08:30:05 <oerjan> but Ix has a method for getting the whole range from the endpoints
08:30:17 <oerjan> @src Ix
08:30:17 <lambdabot> class (Ord a) => Ix a where
08:30:17 <lambdabot>     range           :: (a,a) -> [a]
08:30:17 <lambdabot>     index           :: (a,a) -> a -> Int
08:30:17 <lambdabot>     inRange         :: (a,a) -> a -> Bool
08:30:17 <lambdabot>     rangeSize       :: (a,a) -> Int
08:30:17 <oklopol> wow, i would've gotten my first non-syntax error :P
08:31:17 <ToRA> > range ((0,0),(2,2))
08:31:18 <lambdabot>  [(0,0),(0,1),(0,2),(1,0),(1,1),(1,2),(2,0),(2,1),(2,2)]
08:31:47 <MyCatSchemes> Hrmn. Are arrays (I realise that there are several types in Haskell) packed, anyway? I mean, if you have non-contiguous indexes, how efficient is the space usage? What about if the indexes *are* contiguous?
08:31:53 <oerjan> So it may be better to do array bounds [(key, findWithDefault defaultValue key m) | key <- range bounds]
08:33:34 <hpaste>  quicksilver pasted "fragments for display callbacks" at http://hpaste.org/3560
08:33:36 <oerjan> MyCatSchemes: the packing of indices is determined by the Ix instance
08:33:43 <quicksilver> oklopol: that's the kind of thing I do
08:33:57 <quicksilver> oklopol: I'm using MVars because I'm being thread safe, but you can assume an MVar is the same as an IORef
08:34:00 <quicksilver> for this purpose
08:34:19 <oklopol> MVar is kinda like IORef?
08:34:30 <oerjan> you give it a rectangular region as argument, and it assigns a continuous sequence of Ints to it
08:34:36 <oklopol> oh
08:34:37 <oklopol> you
08:34:38 <oklopol> said that
08:34:55 <MyCatSchemes> oerjan: handy, but not quite what I'm after.
08:35:20 <MyCatSchemes> oerjan: wait, belay that, that *is* what I'm after. Nevermind.
08:35:38 <oklopol> quicksilver: that's what i had!
08:36:01 <oklopol> you are giving the variable to the function inside the MVar
08:36:17 <oklopol> i mean
08:36:22 <oklopol> that's what i had earlier
08:36:41 <quicksilver> oklopol: OK, well it looks a bit of a mess, to separate 'displayDispath' from 'display'
08:36:50 <quicksilver> oklopol: but it does enable you to give display the 'Right' type
08:36:56 <quicksilver> oklopol: so I prefer to do it that way
08:38:05 <oklopol> readMVar is kinda lik eget?
08:38:08 <oklopol> *like get
08:38:26 <oklopol> yay, fixed 1 error out of 3!
08:38:52 * oklopol fixes errors at a dazzling 1-error-per-hour speed
08:39:07 <oklopol> and i'm even faster at making them.
08:40:13 <ac> I just wrote a little program to generate Mandelbrot sets, and it's running a lot slower than I expected. Any obvious reasons?
08:40:15 <hpaste>  ac pasted "experimental mandelbrot set generator" at http://hpaste.org/3561
08:40:48 <oklopol> wow it compiled!
08:41:04 <oklopol> doesn't work, though :<
08:41:08 <oklopol> and gotta leave, see ya ->
08:41:17 <MyCatSchemes> oklopol: awesome trick: replace a let foo = bar with a foo <- bar (or vice versa) in the middle of a huge 'do' block and watch ghc SCREAM its tiny little silicon lungs out. XD
08:41:23 <quicksilver> oklopol: yes, readMVar is 'like get' for mvars
08:41:35 <quicksilver> oklopol: in fact, you could make MVar an instance of StateVar and then use get
08:42:29 <ac> I'm guessing I'm doing something in an obviously inefficient way
08:42:42 <oerjan> ac: for one thing your check is pretty inefficient
08:43:03 <oerjan> and lacks some abs
08:43:14 <quicksilver> ac: don't malloc and poke
08:43:18 <quicksilver> ac: use withArray
08:43:28 <ac> quicksilver: yeah you said that a while back. I haven't figured out how to do that yet
08:43:50 <quicksilver> I don't know if there is a speed hit, but I speculate there is.
08:43:54 <ac> oerjan: ah, so even if it grows rather large on the negative side, it still has to iterate 255 times
08:44:13 <oerjan> if re^2+im^2 <= 4 is the test i've heard
08:44:21 <oerjan> and used, once upon a time
08:45:51 <ac> oerjan: well, that test doesn't improve anything
08:46:09 <ac> oerjan: though it does get rid of some funny artefacts
08:46:14 <oerjan> i guess the problem is not in the calculations then
08:46:19 <quicksilver> ac: could you paste the entire code? I'd like to play with it this evening.
08:46:50 <ac> quicksilver: sure, but the rest of it is rather boring OpenGL stuff
08:46:54 <quicksilver> ac: did you compile with -O2 -funbox-strict-fields
08:47:04 <ac> oh, I forgot about -O2
08:47:13 <ac> never heard of -funbox-strict-fields, let me try it
08:48:37 <hpaste>  ac annotated "experimental mandelbrot set generator" with "The rest of it" at http://hpaste.org/3561#a1
08:48:59 <ac> quicksilver: nah, didn't seem to effect the performance
08:49:55 <oerjan> ac: not **2, that would use logarithms! use ^ or even multiplication
08:50:47 <oerjan> actually, realPart . abs should be equivalent
08:51:05 <oerjan> realPart (abs x) <= 2
08:56:18 <quicksilver> ac: yes, that does seem pretty slow, odesn't it? I'll have a look at it later.
08:57:18 <ac> quicksilver: I like how concise it is, but not how slow it is ;). Also, if you want to make it so it's not sideways, swap x and y in the points declaration
08:57:44 <ac> (obviously I guess)
08:58:16 <dons> ?users
08:58:16 <lambdabot> Maximum users seen in #haskell: 424, currently: 391 (92.2%), active: 12 (3.1%)
08:58:31 <exDM69> @src foldl
08:58:31 <lambdabot> foldl f z xs = lgo z xs
08:58:31 <lambdabot>     where lgo z []     =  z
08:58:31 <lambdabot>           lgo z (x:xs) = lgo (f z x) xs
09:05:15 <yrlnry> Why "lgo"?
09:05:55 <chessguy> @src foldr
09:05:55 <lambdabot> foldr k z xs = go xs
09:05:55 <lambdabot>     where go []     = z
09:05:55 <lambdabot>           go (y:ys) = y `k` go ys
09:06:04 <exDM69> yrlnry: that function would be rather hard to write otherwise
09:06:17 <yrlnry> No, I mean what does the name "lgo" mean?
09:06:21 <yrlnry> "go left"?
09:06:27 <dons> yep
09:06:29 <therp> left variant of go?
09:06:30 <chessguy> it's the "left" version of the go function in foldr
09:06:44 <yrlnry> Thanks.
09:07:05 <yrlnry> See, I really was asking 'Why "lgo"?', not 'Why lgo?'.
09:07:07 <therp> I'm not sure if "go" is appropriate for any pure function
09:07:35 <chessguy> it's not likely a good name for any function
09:08:05 * wli cranks the Principle of Evil Made Flesh for the occasion.
09:08:50 <therp> (except when the function plays the game known as Go :))
09:09:18 <chessguy> even then...
09:09:38 * chessguy is picky about function names, and usually doesn't even like his own
09:09:45 <chessguy> hiya glguy
09:09:59 <glguy> hi
09:12:15 <chessguy> @losers
09:12:15 <lambdabot> Maximum users seen in #haskell: 424, currently: 392 (92.5%), active: 16 (4.1%)
09:12:40 <mrd> @boozers
09:12:40 <lambdabot> Unknown command, try @list
09:12:41 <chessguy> > 16/392
09:12:46 <lambdabot>  4.081632653061224e-2
09:12:48 <oerjan> @abusers
09:12:48 <lambdabot> Maximum users seen in #haskell: 424, currently: 392 (92.5%), active: 17 (4.3%)
09:12:59 <chessguy> > 16/424
09:13:01 <lambdabot>  3.773584905660377e-2
09:13:13 <ac> why is "(-2)" of type "Num" instead of "Num -> Num"
09:13:19 <oerjan> @udders
09:13:19 <lambdabot> Maximum users seen in #haskell: 424, currently: 392 (92.5%), active: 17 (4.3%)
09:13:45 <chessguy> @type (subtract 2)
09:13:47 <ac> seems like it's inconsistent with all other binary operators
09:13:47 <lambdabot> forall t. (Num t) => t -> t
09:13:54 <oerjan> ac: it's considered a wart
09:14:11 <oerjan> but, because it means negation
09:14:16 <chessguy> and by the way, there is no such thing as Num -> Num
09:14:31 <wli> Num t => t -> t
09:14:38 <ac> I guess I meant "(Num t) => t -> t" though I don't understan dthe difference
09:14:48 <chessguy> ac, Num is a type class
09:15:08 <chessguy> it's a set of types. a type is a set of vaues
09:15:09 <ac> oh ok. I guess you can't return something of a type type class
09:15:23 <chessguy> right
09:15:24 <chessguy> @type 2
09:15:26 <lambdabot> forall t. (Num t) => t
09:15:43 <chessguy> so 2 can be of any type that belongs to the Num typeclass
09:15:54 <ac> oh, so that's what forall means
09:16:32 <ac> But that's not true, because Complex is a Num, right?
09:16:38 <ac> and "2" can't be Complex
09:16:41 <quicksilver> sure it can
09:16:46 <oerjan> > 2 :: Complex Double
09:16:47 <quicksilver> > 2 :: Complex Double
09:16:48 <lambdabot>  2.0 :+ 0.0
09:16:49 <lambdabot>  2.0 :+ 0.0
09:16:57 <chessguy> @stereo
09:16:58 <lambdabot> Unknown command, try @list
09:17:03 <chessguy> @quote stereo
09:17:03 <lambdabot> Cale says: Welcome to #haskell where your questions are answered in majestic stereo!
09:17:09 <oerjan> o_O
09:17:10 <ac> lol
09:17:13 <chessguy> hey, it's back!
09:17:26 <oerjan> @quote stereo
09:17:26 <lambdabot> LoganCapaldo says: * LoganCapaldo must resist urge to mention stereo
09:17:48 <wli> The additive group substructures of rings are all Z-modules, so integers inject quite easily, which is one of the few things that's right about the numeric hierarchy as it now stands.
09:17:48 <oerjan> but not alone
09:19:13 <chessguy> @instances-importing Num
09:19:14 <lambdabot> Double, Float, Int, Integer
09:19:28 <fasta> @quote stereo
09:19:28 <lambdabot> Cale says: Welcome to #haskell where your questions are answered in majestic stereo!
09:19:50 <oerjan> @instances-importing Data.Complex Data.Ratio Num
09:19:51 <lambdabot> Complex a, Double, Float, Int, Integer, Ratio a
09:19:51 <chessguy> @instances Num
09:19:52 <lambdabot> Double, Float, Int, Integer
09:20:00 <ac> I guess numeric hierarchies are hard to get right, because I've heard complaints (from mathematicians) about all the ones I've ever used
09:20:22 <ac> (I've been perfectly happy with all of them)
09:20:48 <chessguy> well, none of them are as flexible as haskell's anyway
09:21:04 <chessguy> @src Num
09:21:04 <lambdabot> class  (Eq a, Show a) => Num a  where
09:21:04 <lambdabot>     (+), (-), (*)           :: a -> a -> a
09:21:04 <lambdabot>     negate, abs, signum     :: a -> a
09:21:04 <lambdabot>     fromInteger             :: Integer -> a
09:21:05 <ac> well, wli seems to be complaining about Haskell's too
09:21:22 <chessguy> oh, there's no question that it needs work
09:23:08 <ac> apparently Haskell does not have the concept of counting numbers
09:23:29 <ac> or whatever you call the set of positive integers
09:24:18 <roconnor> ac: not by default :(
09:24:25 <roconnor> ac: [()] comes close
09:24:41 <geocalc> it is a subset ac
09:25:01 <ac> geocalc: a lot of languages have types for unsigned integers
09:25:25 <wli> It'd be nice if we did, too.
09:25:30 <oerjan> ac: haskell has too, just not unbounded ones
09:26:07 <oerjan> > [minBound,maxBound :: Word]
09:26:13 <lambdabot>  [0,4294967295]
09:26:26 <Syzygy-> > [minBound, maxBound :: Word64]
09:26:27 <lambdabot>  [0,18446744073709551615]
09:26:30 <dylan> > maxBound :: Integer
09:26:31 <lambdabot>   add an instance declaration for (Bounded Integer)
09:26:31 <lambdabot>     In the expression: ma...
09:26:37 <dylan> Heheh
09:26:53 <roconnor> > length $ sequence_ [(replicate 3 ()) (replicate 4 ())]
09:26:54 <lambdabot>  Couldn't match expected type `t -> m a'
09:27:04 <roconnor> > length $ sequence_ [(replicate 3 ()),(replicate 4 ())]
09:27:05 <lambdabot>  12
09:27:23 <roconnor> > length $ (replicate 2 ())++(sequence_ [(replicate 3 ()),(replicate 4 ())])
09:27:24 <lambdabot>  14
09:27:28 <roconnor> 2+3*4
09:27:30 <roconnor> > 2+3*4
09:27:31 <lambdabot>  14
09:27:33 <ac> oerjan: but Word* types aren't part of the number hierarchy are they?
09:27:48 <Saizan> yes, they are
09:27:56 <Saizan> > 1 :: Word
09:27:58 <lambdabot>  1
09:27:58 <ac> :t (-2)
09:28:00 <lambdabot> forall a. (Num a) => a
09:28:00 <ac> :t 2
09:28:01 <lambdabot> forall t. (Num t) => t
09:28:16 <Saizan> > (-2) :: Word
09:28:17 <lambdabot>  4294967294
09:28:22 <ac> I see
09:30:01 <ac> so the only thing missing is unbounded unsigned numbers :P
09:30:11 <lewis> i need to write a function reps :: String -> String -> Int that will find the number of repetitions of the first string in the second string,
09:30:12 <lewis> i.e. reps "the" "to the winner the spoils" will output 2
09:30:14 <lewis> can anyone help with this as i dont have a clue where to start on that
09:30:35 <wli> ac: Negation on an unsigned type should be a type error.
09:30:54 <quicksilver> haskell has very relaxed bounded integrals
09:31:00 <quicksilver> all kinds of overflow is silently accepted
09:31:08 <quicksilver> when that's what you want, it's great, but when it's not, it's annoying
09:31:18 <quicksilver> I presume it's because it's expensive (CPU time) to add bounds checking
09:31:30 <quicksilver> > 255 :: Word8
09:31:32 <lambdabot>  255
09:31:34 <Saizan> > length . filter ("the" `idPrefixOf) . tails $ "to the winner the spoils"
09:31:35 <lambdabot>  Parse error at ")" (column 35)
09:31:42 * raxas regrets that hexadecimal numbers are not first class citizens in haskell
09:31:42 <Saizan> > length . filter ("the" `idPrefixOf`) . tails $ "to the winner the spoils"
09:31:42 <quicksilver> > 255 + 1 :: Word8
09:31:43 <lambdabot>   Not in scope: `idPrefixOf'
09:31:44 <lambdabot>  0
09:31:51 <Saizan> > length . filter ("the" `isPrefixOf`) . tails $ "to the winner the spoils"
09:31:52 <lambdabot>  2
09:31:56 <roconnor> > 0x24
09:31:57 <lambdabot>  36
09:31:58 <quicksilver> Saizan: doing other peoples homework for them? :P
09:32:17 <roconnor> > 0o24
09:32:18 <lambdabot>  20
09:32:24 <Saizan> quicksilver: with bonus syntax errors :)
09:32:44 <roconnor> > 0xff :: Word8
09:32:45 <lambdabot>  255
09:32:49 <ac> @hoogle tails
09:32:50 <lambdabot> List.tails :: [a] -> [[a]]
09:32:50 <lambdabot> Text.PrettyPrint.HughesPJ.TextDetails :: data TextDetails
09:33:08 <ac> nice. I always used "iterate (drop 1)"
09:33:48 * wli recalls a certain email exchange between one Ben Pfaff and someone who repeatedly made one-off errors.
09:34:04 <wli> "Are you sure you don't mean ``Ben Pfb00?''"
09:34:22 <geocalc> > 0xffffff :: Word8
09:34:24 <lambdabot>  255
09:34:36 <osfameron> why not   length . filter ("the" `isPrefixOf`) $ tails "to the winner the spoils"  ?
09:34:56 <Syzygy-> > 0xffefdfcfbfaf9f8f7f6f5f4f3f2f1f :: Word8
09:34:57 <lambdabot>  31
09:35:04 <osfameron> ah, because then it's a whole pipeline from the starting ionput
09:35:05 <Syzygy-> > 0x1f :: Word8
09:35:06 <lambdabot>  31
09:35:27 <wli> Even C emits warnings for literals that overflow.
09:35:40 <geocalc> > 0xffffff :: Word24
09:35:41 <lambdabot>   Not in scope: type constructor or class `Word24'
09:35:51 <geocalc> lol
09:35:53 <oerjan> but how many times does "abab" occur in "ababab"? >:)
09:36:58 <quicksilver> wli: but C calculates literals at compile time while haskell, in principle, does so at runtime.
09:37:01 <quicksilver> wli:  :(
09:37:53 <geocalc> > 0xffffff :: Int
09:37:55 <lambdabot>  16777215
09:39:08 <fasta> what does MUT stand for again?
09:40:23 <ski> Memorative Untestamentary Tauromorphic
09:40:45 <raxas> I mean, logical && and || and xor works for booleans, not hex numbers in haskell, which makes it less usefull for electronics
09:41:07 <fasta> ski: in a GHC profile, of course
09:41:27 <wli> The equivalents are .&., .|., and xor in Data.Bits
09:41:40 <wli> There isn't a named xor for Bool
09:41:51 <ski> fasta : then i don't know
09:42:09 <raxas> so Data.Bits works on all Num types?
09:42:44 <ski> > (/=) `fmap` [False .. True] `ap` [False .. True]
09:42:45 <lambdabot>  [False,True,True,False]
09:42:54 <wli> It's orthogonal to Num. The predefined integral types all have Bits instances.
09:45:22 <quicksilver> raxas: it's not definied to work on Nums, but it works on all the instances you want
09:45:26 <quicksilver> @instances Bits
09:45:27 <lambdabot> Couldn't find class `Bits'. Try @instances-importing
09:45:33 <quicksilver> bah
09:46:02 <oerjan> @instances-importing Data.Bits Data.Word Data.Int Bits
09:46:03 <lambdabot> Int, Int16, Int32, Int64, Int8, Integer, Word, Word16, Word32, Word64, Word8
09:46:27 <quicksilver> ;)
09:46:45 <quicksilver> also, FWIW, all the C types and so on
09:47:13 * oerjan suddenly realizes quicksilver is just using a trick so he doesn't have to write all the modules himself
09:47:32 <quicksilver> ;)
09:48:12 <quicksilver> I am reminded of the well-known usenet rule
09:48:18 <quicksilver> that if you really want an answer, post something wrong
09:48:29 <quicksilver> if you say "How do I do this?" no one will bother to answer
09:48:36 <quicksilver> but if you say "You have to do this!"
09:48:43 <ski> @instances-importing Data.Bits Data.Word Data.Int Foreign Foreign.C Bits
09:48:44 <lambdabot> CChar, CInt, CIntMax, CIntPtr, CLLong, CLong, CPtrdiff, CSChar, CShort, CSigAtomic, CSize, CUChar, CUInt, CUIntMax, CUIntPtr, CULLong, CULong, CUShort, CWchar, Int, Int16, Int32, Int64, Int8, IntPtr,
09:48:44 <lambdabot>  Integer, Word, Word16, Word32, Word64, Word8, WordPtr
09:48:44 <quicksilver> then people will jump down your throat to prove you're wrong..
09:48:55 <Sizur> can somebody point out code for a minimal http server in haskell?
09:50:12 * oerjan is sure he saw someone making a minimal http server on this channel a while ago
09:50:52 <basvd> Sizur: Check out http://haskell.org/haskellwiki/Applications_and_libraries/Web_programming
09:50:54 <lambdabot> Title: Applications and libraries/Web programming - HaskellWiki, http://tinyurl.com/253xhy
09:50:59 <oerjan> i think it was quicksilver
09:51:55 <raxas> well, seems using Data.Bits cures my disability well :)
09:52:11 <quicksilver> no
09:52:15 <quicksilver> I never talk
09:52:20 <quicksilver> you must be mistaken
09:52:41 <oerjan> quicksilver: darn, your theory doesn't seem to be working
09:53:15 <quicksilver> @go haskell web server
09:53:18 <lambdabot> http://darcs.haskell.org/hws/
09:53:18 <lambdabot> Title: Index of /hws
09:53:21 <quicksilver> I imagine that's the one
09:53:29 <roconnor> > 0xaf .&. 0xfa
09:53:29 <lambdabot>  Add a type signature
09:53:34 <roconnor> > 0xaf .&. 0xfa :: Word8
09:53:36 <quicksilver> I think it may have been dons
09:53:39 <lambdabot>  170
09:53:40 <oerjan> i recall something rather more minimal
09:53:48 <roconnor> > showHex (0xaf .&. 0xfa :: Word8) []
09:53:49 <quicksilver> ah. Maybe. I don't recall that.
09:53:50 <lambdabot>  "aa"
09:54:05 <Sizur> hws sounds good
09:55:10 <Sizur> donn paste this: http://hpaste.org/3534 but i need something real
09:56:00 <oerjan> not quite _that_ minimal, it was several months ago
09:56:01 <Sizur> hws sounds good, will take a look into it. why reinvent another weel when somebody smarter already did it
09:56:12 <quicksilver> right
09:56:16 <quicksilver> and by that logic, use apache :P)
09:56:34 <Sizur> you mean that grandpa elephant?
09:57:27 <conal> how do people test quickcheck generators?  is there a way (in QC1) to show a bunch of generated values?
09:58:03 <dcoutts_> conal: generate
09:58:17 <dcoutts_> @type Test.QuickCheck.generate
09:58:19 <lambdabot> forall a. Int -> StdGen -> Test.QuickCheck.Gen a -> a
09:58:59 <dcoutts_> you give it a size, a rnd and a Gen
09:59:12 <quicksilver> map (\i -> generate i (mkStdGen 17) g) [0..10]
09:59:14 <quicksilver> I think?
09:59:28 <dcoutts_> that gives you different sizes
09:59:44 <basvd> conal: I use: printGen n gen = print =<< testGen n gen   where testGen n gen = do {stdGen <- newStdGen; return $ generate n stdGen gen}
09:59:44 <quicksilver> ah, not really what I meant :)
09:59:45 <dcoutts_> or map over a sequence of StdGen for different examples
10:00:08 <conal> @type mkStdGen
10:00:09 <quicksilver> map (\i -> generate 1 (mkStdGen 17*i) g) [0..10]
10:00:09 <lambdabot> Int -> StdGen
10:00:15 <quicksilver> looks more like it :)
10:00:31 <quicksilver> successive mkStdGens aren't "very" independent
10:00:53 <conal> cool.  thanks, all.
10:02:07 <oerjan> conal: you can also use vector to avoid doing your own looping, iirc
10:02:13 <wli> Are we going to get some Mersenne twisters to deal with this?
10:02:38 <quicksilver> it has been discussed
10:02:43 <conal> oerjan: i like that trick.  thanks.
10:02:45 <quicksilver> no one has done it, as far as I know :)
10:03:07 <wli> quicksilver: augustss has written a Mersenne twister module.
10:03:52 <oerjan> conal: or replicateM if you are starting with Gen i guess
10:03:53 <quicksilver> excellent!
10:03:56 <quicksilver> augustss++
10:04:21 <wli> quicksilver: It's not plugged into the Data.Random interface but that can't be so hard.
10:05:10 <dcoutts_> @type List.unfoldr (Just . (\(_,x)->(x,x)) . Random.random) (Random.mkStdGen 0)
10:05:12 <lambdabot>     Ambiguous type variable `t' in the constraint:
10:05:12 <lambdabot>       `Random t' arising from use of `random' at <interactive>:1:39-51
10:05:12 <lambdabot>     Probable fix: add a type signature that fixes these type variable(s)
10:05:23 <dcoutts_> @type List.unfoldr (Just . (\(_,x)->(x,x)) . Random.next) (Random.mkStdGen 0)
10:05:24 <lambdabot> [StdGen]
10:05:29 <dcoutts_> there we go
10:05:34 <ski> conal : i have used this, sometime `sample :: Show a => Int -> Gen a -> IO (); sample n gen = forM_ [1..n] $ \i -> do rnd <- newStdGen; print (generate n rnd gen)'
10:05:52 <quicksilver> dcoutts_: if that is safe, it should be a standard function
10:06:10 <quicksilver> dcoutts_: well not starting from mkStdGen 0, but starting from any particular gen
10:06:15 <dcoutts_> right
10:06:20 <quicksilver> dcoutts_: but I don't understand the splitting properties of rngs
10:06:21 <dcoutts_> but for generate 0 is ok
10:06:28 <dcoutts_> quicksilver: it's not splitting
10:06:35 <dcoutts_> quicksilver: it's using next
10:06:37 <kimmell> can anyone offer advice on integrating a preprocessor with Cabal-1.2.1?
10:06:54 <quicksilver> dcoutts_: I know
10:06:58 <kimmell> The PreProcessor type (in Distribution.Simple.PreProcess) is opaque
10:06:59 <quicksilver> dcoutts_: but it is a kind of splitting
10:07:26 <dcoutts_> kimmell: you want to implement it in your Setup.hs file I suppose?
10:07:33 <kimmell> and mkSimplePreProcessor (which the haddock documentation suggests using) isn't exported
10:07:37 <kimmell> yeah
10:07:39 <kimmell> sorry
10:08:42 <dcoutts_> kimmell: so you'd be trying to add something to the list of hookedPreProcessors in the UserHooks
10:08:49 <kimmell> exactly
10:09:47 <dcoutts_> kimmell: mm, yes, I see. It's not exported.
10:10:48 <dcoutts_> kimmell: I guess I should export it for you :-)
10:11:16 <kimmell> dcoutts: ah. okay. I thought maybe I was going at this the wrong way.
10:11:18 <dcoutts_> kimmell: you can see we've not had many Setup scripts add additional pre-processors before
10:11:28 <dcoutts_> what kind of pre-processor are you adding?
10:12:55 <dons> ?yow
10:12:55 <lambdabot> Youth of today!  Join me in a mass rally for traditional mental
10:12:55 <lambdabot> attitudes!
10:13:06 <kimmell> dcoutts: it just generates a bunch of haskell boilerplate from a small data description file
10:13:52 <dcoutts_> kimmell: you might find it easier at the moment to just hard code that generation as a build step, rather than using the pre-processor stuff
10:14:33 <dcoutts_> kimmell: eg, see the happy package's Setup.hs file which does something like that as a post-build step
10:15:15 <kimmell> dcoutts: I'll do that. Thanks a lot for your help.
10:15:52 <dcoutts_> kimmell: np, sorry it's not all completely thought out. All that internal api is in flux.
10:17:06 <kimmell> dcoutts: yeah, I saw the disclaimers about that. I suppose I shouldn't have ignored them.
10:25:14 <oerjan> @users
10:25:15 <lambdabot> Maximum users seen in #haskell: 424, currently: 391 (92.2%), active: 13 (3.3%)
10:28:09 <waern> what to do when happy instead of giving you a proper error message, just says "parE"?
10:49:01 <hpaste>  dozer pasted "makes me feel dirty" at http://hpaste.org/3562
10:49:01 <hpaste>  dozer pasted "makes me feel dirty" at http://hpaste.org/3563
10:49:09 <dozer> hi
10:49:46 <Cale> hello
10:49:56 <dozer> Is there a clean way to do this - that is, run the arrow (runX) for a list of inputs (in input) 'propperly' rather than by this hacky external concatMapM?
10:51:17 <Cale> hmm... I suppose it may be cleaner to bind the runX (...) somewhere to a name
10:51:40 <dozer> is there no way to inject the list of values directly into the runX though?
10:52:00 <Cale> oh, yeah, there likely is
10:52:16 <Cale> You want the arrow to act on the concatenation of the XML documents?
10:52:32 <dozer> not really, I want it to run on each in turn
10:53:02 <dozer> produce a list of results, one for each input file
10:53:29 <Cale> okay
10:53:47 <Cale> aha
10:54:00 <Cale> You'll want readFromDocument, rather than readDocument
10:54:13 <Cale> which gets the filename from the arrow, rather than as a function parameter
10:54:30 <dozer> ah, ok - that's a good start
10:54:31 <Cale> and  constL input
10:54:37 <Storm> hello all
10:55:09 <Cale> which if input is the list of filenames will give the arrow which nondeterministically produces those names
10:55:39 <Cale> er, that's an awkward way to say it... anyhow  constL :: [c] -> a b c
10:55:50 <Cale> Storm: hello
10:55:59 <MyCatSchemes> @hoogle [a] -> (a,[a])
10:56:00 <lambdabot> List.mapAccumL :: (a -> b -> (a, c)) -> a -> [b] -> (a, [c])
10:56:00 <lambdabot> List.mapAccumR :: (a -> b -> (a, c)) -> a -> [b] -> (a, [c])
10:56:00 <lambdabot> Data.List.mapAccumL :: (acc -> x -> (acc, y)) -> acc -> [x] -> (acc, [y])
10:56:17 <MyCatSchemes> @hoogle \a -> (head a,tail a)
10:56:17 <lambdabot> Hoogle Error: Parse Error: Unexpected character '\a -> (hea'
10:56:25 <Storm> iam kind of new to this stuf just will sit here and watch if thats ok i kind of want to learn scripts and stuff
10:56:26 <Arnar> hey folks..
10:56:34 <MyCatSchemes> Arrr, nevermind.
10:56:43 <Saizan> :t head &&& tail
10:56:44 <lambdabot> forall a. [a] -> (a, [a])
10:56:54 <Cale> Storm: that's cool, but feel free to ask questions. We're very beginner friendly :)
10:57:00 <Storm> ok ty
10:59:41 <opqdonut> i want to keep track of what elements in my (linked) datastructure have been already visited in the current iteration
10:59:57 <dozer> cheers Cale - that seems to have done it, modulo a bit of tweaking above and below that block
10:59:59 <opqdonut> in c i would add a mutable generation counter to the elements, but that seems ugly in haskell
11:00:38 <opqdonut> then again a per-generation Set or Map of visited elements would be log n for checking whether an element has been visited
11:00:48 <dozer> opqdonut_: like folding an int counter through the visiting function?
11:00:48 <opqdonut> whereas the mutable counter would be O(1)
11:00:50 <Cale> opqdonut: Are the elements identifiable uniquely?
11:00:51 <opqdonut> ideas?
11:00:54 <quicksilver> opqdonut: use a zipper?
11:01:02 <quicksilver> opqdonut: everything "to the left" is obvioulsy already visited
11:01:13 <quicksilver> (as long as your traversal is L-to-R)
11:01:13 <Cale> I'd usually just carry around a Data.Set consisting of the elements I'd visited already.
11:01:24 <quicksilver> you could even structure the zipper with an efficient left-side
11:01:27 <opqdonut> quicksilver: graph traversal essentially
11:01:31 <quicksilver> which amounts to the same thing that Cale said :)
11:01:31 <Cale> (given that this is something like a graph)
11:01:37 <dozer> I'd usually push the Data.Set into a StateT to be honest
11:01:38 <quicksilver> but it sounds more buzzword-compliant
11:01:53 <quicksilver> Data.Set state threading, now via Zipper 2.0 technology!
11:01:56 <opqdonut> yeah i've been thinking of keeping a set state
11:02:05 <opqdonut> but is there really no elegant O(1) solution?
11:02:15 <Cale> Don't trouble yourself too much over the logarithmic time
11:02:18 <quicksilver> opqdonut: there are no elegant O(1) solutions
11:02:19 * MyCatSchemes wonders how many people would all go insane tomorrow morning if, just before leaving the lab tonight, he switched off all the LCDs on unused computers.
11:02:20 <quicksilver> opqdonut: to anything.
11:02:22 <quicksilver> opqdonut: ever.
11:02:26 <quicksilver> O(1) is not elegant :)
11:02:33 <MyCatSchemes> Well, it's a computer science department, so, uh, tomorrow afternoon. But yeah.
11:02:35 <opqdonut> :D
11:02:37 <Cale> The only reason that the mutable solution is O(1) is that memory can be accessed uniformly.
11:02:47 <dozer> opqdonut_: to find an O(1) solution, we'd need to know loads of stuff about the linked data structure like guaranteed ordering in traversal etc.
11:02:50 <Cale> Which is aymptotically unrealistic anyway.
11:02:57 <opqdonut> hrmmnn okay
11:03:11 <opqdonut> it's just that this is a project that gets graded in terms of asymptotical performance
11:03:15 <Cale> asymptotically*
11:03:16 <MyCatSchemes> Yeah, and actually it's O(n^(1/3)), because that's how many DIMMs you can (asymptotically) fit within a given distance of your CPU in three dimensions.
11:03:17 <opqdonut> but i guess i can justify log n
11:03:22 <quicksilver> MyCatSchemes: ;)
11:03:28 <Cale> log n is essentially constant ;)
11:03:30 <MyCatSchemes> People living in higher dimensioned universes may achieve lower bounds than this.
11:03:34 <opqdonut> esp. because n tends to be small
11:03:35 <dozer> for suitable values of n :)
11:03:40 <MyCatSchemes> quicksilver: I'm not even bullshitting. XD
11:05:12 <Cale> MyCatSchemes: right, but it's actually worse. Assuming that certain conjectures in quantum information theory are correct, the amount of information you can store in a given volume is actually equivalent to the amount of information you can store on the boundary of that volume
11:05:44 <Cale> (though you have to get to impractical information densities before you see that effect)
11:05:56 * matthew_- checks this is #haskell and not #weird-scary-maths-land
11:06:15 <Cale> matthew-_: those aren't the same thing?
11:06:16 <wli> It's worse than math, it's physics, Jim.
11:06:53 <matthew_-> wli: quite. It's pretending that mathematical models of stuff are equivalent to stuff
11:07:08 <MyCatSchemes> Cale: whoaaaaa.
11:07:10 <dozer> Cale - yeah, but before we have computing requirements that legitimately exceed this limit, we will probably be doing "string computing" in 9 dimensions
11:07:16 * dozer harks back to culture novels
11:07:55 <Cale> So it's actually O(n^(1/2))
11:07:57 <wli> Um, we're actually rapidly approaching practical limits for which there are no plausible answers within CPU vendors' current roadmaps.
11:08:01 <MyCatSchemes> Cale: and I can't get around that by using a honeycomb or any such nonsense? Storing my data on a device shaped like a sea urchin?
11:08:17 <matthew_-> only a male sea urchin that has been castrated
11:08:27 <Cale> MyCatSchemes: I'm not sure, I don't really know enough about it.
11:08:43 <Cale> http://en.wikipedia.org/wiki/Holographic_principle
11:08:44 <lambdabot> Title: Holographic principle - Wikipedia, the free encyclopedia
11:08:47 <Arnar> some of you (byo
11:08:51 <Arnar> bla
11:08:57 <Arnar> many
11:09:04 <Arnar> craaap, backspace no worky
11:09:10 <MyCatSchemes> matthew-_: that'd be impractical for hardware vendors, on account of it'd destroy the ability of their biggest customers to boast about the sizes of their e-penises, so to speak.
11:09:50 <matthew_-> indeed.
11:09:54 <Arnar> some of you guys helped me alot a few days ago.. if anyones interested, my project (SOS implemented in Haskell) is online http://seta07.blogspot.com/2007/10/spinoza-sos-in-haskell.html
11:09:57 <lambdabot> Title: Semantics 2007 (RU): Spinoza SOS in Haskell
11:09:58 <wli> It's not 22nm which is where the problems happen but somewhat below it. I don't remember what they are anymore, though.
11:09:59 <MyCatSchemes> After all, what kind of spotty dweeb is going to boast about their "castrated higher-dimensional seafood DIMMs"? I can't see that selling, TBH.
11:10:03 <Cale> If the entropy of ordinary mass (not just black holes) is also proportional to area, then this implies that volume itself is somehow illusory: that mass occupies area, not volume, and so the universe is really a hologram which is isomorphic to the information "inscribed" on its boundaries.
11:10:11 <wli> 22nm is "close to it" somehow.
11:10:55 <matthew_-> MyCatSchemes: it's all about branding
11:11:01 <matthew_-> after all, they sold the pentium 4
11:11:11 <hpaste>  conal pasted "quickcheck puzzle -- why does sample hang?" at http://hpaste.org/3564
11:11:54 <conal> i'm stumped on this one.  maybe someone with more QC experience can spot the problem.
11:11:58 <wli> Also, single-threaded performance is not keeping up anymore in some sense, which is part of what's behind the multicore push.
11:12:26 <matthew_-> wli: indeed. Which, I think, should play nicely into functional programmers' hands
11:13:48 <wli> matthew-: My great hope is that architectures will rediversify and that the fabrication process playing field will level. Sadly it looks like none of that will happen for other reasons.
11:14:26 <fasta> Does GHC ever change something inplace that is programmed as pure immutable code?
11:14:45 <nominolo> conal: are you sure the right instance for fmap is chosen?
11:14:54 <matthew_-> fasta: yes, I certainly believe so
11:15:07 <matthew_-> fasta: especially with unboxing.
11:15:30 <Cale> conal: It hangs?
11:15:42 <Cale> oh, I see
11:15:44 <conal> Cale: yeah
11:16:17 <raxas> Cale: so it should be perfectly possible to construct higher material dimensions just by organizing information on the surface
11:16:18 <matthew_-> wli: it seems to me that vast amounts of silicon and expense are thrown at trying to maintain the illusion of a model of computing which is just not sustainable. I hope they throw all that crap out the window and properly let programmers deal with it.
11:16:50 <matthew_-> wli: for example the "transparent" caches and cache coherancy and so on.
11:17:14 <dcoutts_> matthew_-: have you been reading the LWN series on memory?
11:17:19 <wli> TLB's too.
11:17:29 <matthew_-> dcoutts_: yes and no
11:17:54 <matthew_-> dcoutts_: I want to spend a couple of days properly working through that stuff because some of it is very close to my PhD
11:17:55 <fasta> Is there anyone here who has written long running (at least 1 hour) non-trivial combinatorics code in Haskell?
11:17:57 <conal> oh -- my "arbitrary" is using Gen's fmap, not mine.
11:18:12 <dcoutts_> matthew_-: oh interesting, what's your PhD topic?
11:18:14 <wli> fasta: What about it?
11:18:16 <matthew_-> dcoutts_: I've skimmed some of the articles
11:18:17 <dpiponi> Anyone have a suggestion for the easiest way to get a native Intel version of ghc running under Leopard? I'm ghc-less at the moment and suffering from withdrawal...
11:18:22 <matthew_-> dcoutts_: session types
11:18:56 <sebell> dpiponi: Oh, the Tiger binaries don't work?
11:18:57 <fasta> wli: it seems to stress the garbage collector in that it spends more time in GC than on actual computation.
11:19:03 <matthew_-> make cache into a distributed core-local memory address range and let programmers deal with it. Imperative languase seem to be built around this assumption about the way computers perform work which is flawed and badly broken. Why are hardware vendors trying to patch up the gaps?
11:19:21 * MyCatSchemes hrmns.
11:19:37 <dcoutts_> matthew_-: perhaps it's faster to handle in hardware, even if software were fully aware of it
11:19:40 <wli> fasta: Eventually the numbers get too big and bigger, badder hardware is the only solution.
11:19:43 <Cale> conal: It's re-entering coarbitrary repeatedly.
11:20:08 <MyCatSchemes> I have an exception from Prelude.head, and I'm not sure exactly where. Anyone know offhand how to get the line number or anything else, please?
11:20:29 <fasta> wli: are you saying that garbage collection and limited memory don't play nicely together?
11:20:29 <dpiponi> sebell: I tried the 6.6.1 from http://www.haskell.org/ghc/download_ghc_661.html and it failed with some cryptic error messages. I'll try again and report the message.
11:20:30 <lambdabot> Title: GHC: Download version 6.6.1
11:20:31 <matthew_-> dcoutts: it's just that I'm making an argument about the value of message passing. And so dealing with the issues of shared memory is important - hence why the lwn memory stuff is relevant
11:20:43 <hpaste>  conal annotated "quickcheck puzzle -- why does sample hang?" with "fix" at http://hpaste.org/3564#a1
11:20:48 <dons> MyCatSchemes: you can compile with profilig on, and then look at the top of the call stack
11:20:53 <matthew_-> dcoutts: I think I'm going to wait for the LaTeX version of all that stuff so that I can print it nicely...
11:21:03 <fasta> wli: (with infinite memory you would of course don't need a garbage collector)
11:21:14 <dons> MyCatSchemes: you can also replace calls to head with calls to assert head
11:21:24 <dons> MyCatSchemes: which will give you a line number
11:21:25 <conal> Cale: thanks.
11:21:30 <MyCatSchemes> @where assert
11:21:30 <lambdabot> I know nothing about assert.
11:21:31 <fasta> dons: Can I use that optimized List library today?
11:21:36 <MyCatSchemes> @where head
11:21:36 <lambdabot> I know nothing about head.
11:21:47 <fasta> dons: streams, IIRC?
11:21:47 <MyCatSchemes> :i assert
11:21:50 <dons> fasta: the stream fusion one?
11:21:51 <dons> sure!
11:21:57 <MyCatSchemes> dons: thanks.
11:22:03 <MyCatSchemes> @i assert
11:22:03 <lambdabot> Maybe you meant: id ignore index instances instances-importing irc-connect . ? @ v
11:22:07 <narain> how do i fork off a thread that sits in an infinite loop waiting for messages from other threads?
11:22:08 <dons> darcs get http://www.cse.unsw.edu.au/~dons/code/streams/list
11:22:08 <lambdabot> Title: Index of /~dons/code/streams/list
11:22:15 <fasta> dons: how much changes does it require to existing code?
11:22:28 <dcoutts_> matthew_-: I tend to agree that it should be made more explicit and the hardware simpler, I just wonder if even if it were controlled by software, would it be faster?
11:22:52 <dcoutts_> would we really use different faster ways of managing the local memory
11:22:58 <sebell> dpiponi: I haven't tried running my GHC installation on Leopard... upgraded last night.
11:22:58 <mae> Hi, how can I make a cabal setup script use the older version of cabal (pre 1.2) to install.. some packages still are not compatibile with 1.2
11:23:02 <dons> enumerations, and Control.Monad stuff you want to fuse need to be replaced with enumFromTo and local definitions of the monadic stuff. Prelude and List need to have their list functions hidden. everything else is unchanged
11:23:10 <wli> dcoutts: COMA?
11:23:13 <dons> fasta: so if you stick to only list functions, juts imports change
11:23:13 <MyCatSchemes> Gah. Where's assert defined please, sorry?
11:23:26 <dcoutts_> wli: I don't know what that stands for
11:23:28 <dons> MyCatSchemes: Control.Exception
11:23:38 <wli> dcoutts: Cache Only Memory Architecture
11:23:39 <Cale> @hoogle assert
11:23:40 <lambdabot> Control.Exception.assert :: Bool -> a -> a
11:23:40 <lambdabot> Test.HUnit.Base.assert :: Assertable t => t -> Assertion
11:23:40 <lambdabot> Control.Exception.assertions :: Exception -> Maybe String
11:23:53 <dons> MyCatSchemes: i use this sometimes, http://hackage.haskell.org/cgi-bin/hackage-scripts/package/loch-0.2
11:23:55 <lambdabot> http://tinyurl.com/yqfuld
11:23:58 <fasta> dons: do you have online API docs?
11:24:01 <matthew_-> dcoutts: sure - if you were doing message passing between different cores but they shared an L3 (ok, memory, not cache), you could just plonk it in there - no need for "main" memory at all
11:24:03 <dcoutts_> mae: does the Setup.hs not compile at all with cabal-1.2? or is it that the package fails to configure?
11:24:17 <dons> fasta: the docs are identical to the Data.List library dovs
11:24:21 <mae> package fails to configure i believe.. this is for some logger program
11:24:24 <dons> docs, as all functions are the same
11:24:29 <matthew_-> dcoutts: there's loads of stuff which is horrible and slow because of the obsession with "main" memory being the only store, and these caches being only for speed
11:24:54 <dcoutts_> matthew_-: right, so you'd not need to shadow the L3 message passing window in main memory
11:24:59 <fasta> dons: then I don't understand how Control.Monad is related.
11:25:15 <MyCatSchemes> dons: thanks. (Oh and damn, looks like I forgot to build profiling versions of the libs. Argh.)
11:25:18 <mae> http://rafb.net/p/rd5HEb66.html
11:25:19 <lambdabot> Title: Nopaste - No description
11:25:27 <dcoutts_> matthew_-: so the only copy would be in the L3 area
11:25:40 <dpiponi> sebell: It looked remarkably like the installer was installing the PowerPC version of GMP and the Intel binary of GHC failed when it tried to link to it. I'm doing a fresh download and trying again.
11:25:42 <matthew_-> dcoutts_: RIGHT
11:25:51 <matthew_-> sorry - accidental use of caps
11:25:54 <dcoutts_> :-)
11:26:08 <dons> fasta: you want things like sequence and mapM to fuse sometimes, which means they should be defined in terms of Data.List.Stream functions, not Data.List
11:26:12 * narain gets no response and tries again
11:26:16 <mae> dcousee pastebin
11:26:19 <matthew_-> dcoutts_: I'm saying no caches. The cells that were part of the cache remain, but they have their own addresses. No more global unified address space
11:26:20 <dcoutts_> mae: so use ghc -package Cabal-1.1.6.2 Setup.hs -o setup; ./setup configure
11:26:20 <dons> see the thread on the list about fusion from earlier this week
11:26:28 <narain> what's the right way to write a thread which sits idle waiting for messages from other threads?
11:26:41 <dons> narain: wait on a Chan?
11:26:53 <dons> or takeMVar/takeTVar
11:27:00 <narain> i need something that's interruptible... i was thinking throwTo
11:27:08 <fasta> dons: ok, but if I look at those figures in your paper, it seems it doesn't always do better.
11:27:28 <matthew_-> dcoutts: and then, what happens to all these languages that rely on passing around pointers, when pointers refer only to a core's own address space? It becomes much much harder to deal with shared memory. Thus Haskell wins! The End. ;-)
11:27:30 <dcoutts_> matthew_-: and if you want to use some part of the L3 local memory as a data cache in a traditional way, you have to manage it manually? That's slower presumably.
11:27:30 <fasta> dons: but I suppose you explain that in your article ;)
11:27:40 <dons> fasta: it should always be better, but ghc sometimes can't compile nested list comprehensions
11:27:43 <narain> dons: is throwTo the right way to do interrupting messages?
11:27:49 <dons> fasta: but do yous a recent ghc snapshot
11:27:57 <dons> since a number of those issues are fixed now
11:28:02 <fasta> dons: yes, ghc from yesterday
11:28:04 <dons> narain: that's one way.
11:28:09 <dons> great,fasta , that should be ideal
11:28:10 <matthew_-> dcoutts_: yep, it's slower, because you've got to turn on your cache coherency and all the rest of the magic that goes on these days
11:29:08 <dcoutts_> matthew_-: so perhaps the best we can hope for is more control over the use of the local memory, if we think we can manage it better than using it with the normal cache coherency protocol implemented in hardware, then we get to do that.
11:29:28 <narain> so i guess i need an infinite loop inside  catch (???) (\message -> foo message) ?
11:29:38 <narain> how do i write an infinite loop as an io action?
11:29:52 <dcoutts_> matthew_-: my point is, since there is so much legacy software, I don't see cpu makers just turning off the caches and making us manage it. But perhaps they'll let us manage it if we want to.
11:30:03 <matthew_-> but we are seing cpus which have such a distributed heirarchy - the CELL cpu and some other DSPs have such a distributed memory model. With more cores, the bandwidth you need to keep the cores' cache's happy becomes enourmous.
11:30:10 <fasta> narain: loop = putStrLn "hello" >> loop
11:30:12 <matthew_-> dcoutts_: your point is very valid ;)
11:30:31 <mae> dcoutts_:  matt@OMG-Its-a-mac ~/haskell/hslogger-1.0.2 $ghc -package Cabal-1.1.6.2 Setup.hs -o setup
11:30:32 <mae> ghc-6.6.1: unknown package: Cabal-1.1.6.2
11:30:33 <fasta> narain: or forever (putStrLn "hello")
11:30:36 <narain> fasta: thanks. is there a built-in combinator?
11:30:38 <narain> oh, ok
11:30:45 <waern> is forever in the std libs?
11:30:46 <fasta> narain: but forever only works in newer versions
11:30:52 <waern> that's nice
11:30:59 <augustss> matthew-_: get a GPU and you can have handle the memories yourself
11:31:03 <narain> thanks fasta
11:31:44 <matthew_-> augustss: yeah. Isn't that going away though - aren't tlbs and stuff coming in on gpus now?
11:31:54 <MyCatSchemes> Dammit. Still can't find where this null list is. :/
11:31:54 <dcoutts_> matthew_-: eg, within a single process where we're mixing legacy and new code (eg glibc + ghc rts) we could ask to use half the local memory for an automatically managed cache and address the remainder of it directly. And perhaps we can set the GC heap to be virtual address space not managed via that cache.
11:31:56 <fasta> dons: can you explain why it isn't faster in the figures in your article then?
11:32:18 <mrd> MyCatSchemes: used -xc?
11:32:39 <augustss> matthew_-: maybe, but people are willing to put up with a lot of pain for that last bit of graphics performance
11:32:42 <dcoutts_> matthew_-: so an opt-out scheme on a per VMA basis
11:32:43 <MyCatSchemes> mrd: what's that do, please?
11:32:46 <matthew_-> dcoutts_: yep, quite. The Xenon in the 360 has some interesting ways to divide up cache between the threads - they've done bits of this, they've just not yet reached the next step...
11:32:53 <fasta> MyCatSchemes: stack trace on exception
11:32:59 <wli> dcoutts: What do you want on a per-vma basis?
11:33:18 <MyCatSchemes> fasta, mrd: where do I give it, the RTS or ghc or...?
11:33:23 <fasta> In 6.9 it even works when you do C-c on an infinite loop.
11:33:25 <dcoutts_> wli: opt out of using L1,2,3 caches
11:33:39 <wli> dcoutts: That's not quite what you're hoping for.
11:33:45 <fasta> MyCatSchemes: RTS, but you need to compile with profiling
11:33:57 <mrd> ah fasta has beaten me to the punch
11:33:59 <wli> dcoutts: Cray got away with this because he used what was essentially cache memory as main memory.
11:34:03 <matthew_-> dcoutts, wli: well no, you want to treat caches as if they have their own address spaces. address them directly
11:34:18 <MyCatSchemes> fasta: then I'm stuck. No profiling libs. :(
11:34:28 <fasta> MyCatSchemes: ?
11:34:30 <dcoutts_> wli: so code working with data in those areas would use dma instructions to copy things into local memory, like the cell SPUs.
11:34:50 <wli> dcoutts: It's all set up wrong.
11:35:06 <wli> dcoutts: Those operations are super dogslow.
11:35:10 <fasta> MyCatSchemes: AFAIK, if you have a program, you can compile it for profiling.
11:35:17 <fasta> MyCatSchemes: see manual for details
11:35:20 <dcoutts_> wli: what right now you mean? or it's not a sensible design for some future chip.
11:35:31 <matthew_-> right now
11:35:37 <dcoutts_> sure
11:35:49 <fasta> We need a Reduceron 500XT
11:35:53 <matthew_-> the cell has very poor performance getting data into the SPU's local memory
11:35:56 <wli> dcoutts: IO operations for memory manipulation would only be worth it if you were doing it for vast amounts of data. 64KB and more worth of bitblitting is faster than using various sorts of IO to do it in the background.
11:36:32 <dcoutts_> wli: I'd imagine we'd add instructions for loading/storing multiples of 'cache lines' between local memory and main memory, then addressing local memory directly.
11:36:35 <narain> does  a `seq` b  evaluate  a  entirely? from the documentation it seems possible that it only verifies that  a  is non-bottom
11:36:47 <dcoutts_> wli: which is just like how it works on a SPU as I understand it
11:36:50 <matthew_-> because of temporal locality, prefecting and prediction, yes, cache hit rates are high and make a big difference
11:36:59 <fasta> dons: one issue I don't understand is how you can replace Data.List if you cannot redefine [].
11:37:01 <mrd> narain: "entirely" can mean different things, so basically  yea
11:37:42 <wli> dcoutts: Similarly, main memory is a *LOT* slower than cache memory. A fair amount of what a cache does is amortize it and do accesses in the "background" while OOOE keeps forward progress going.
11:37:45 <narain> mrd: ok
11:37:47 <mrd> > (1:undefined)`seq`1
11:37:48 <lambdabot>  1
11:38:05 <dcoutts_> wli: but I'm suggesting some mixed model, where we default to using the caches in the traditional way for most of the address space, and then we can specially ask to opt out of the cache coherency for some virtual memory areas and manage local memory explicitly.
11:38:18 <MyCatSchemes> fasta: I'm using filepath, amongst others, and I didn't ask for profiling versions of the library to be built when I compiled it (no damn disk space here ^_^)
11:38:24 <narain> > repeat 1 `seq` 42
11:38:25 <mrd> narain: the NFData class intends to give a method by which you can "reduce to normal form"
11:38:26 <lambdabot>  42
11:38:32 <fasta> MyCatSchemes: you think the error is in filepath?
11:38:43 <MyCatSchemes> Still, found the problem. Mental note that I need to make better use of --chatty options. And, Hell, always put them in.
11:38:44 <fasta> MyCatSchemes: oh, never mind, GHC needs everything profiled.
11:38:47 <wli> dcoutts: You're going to run into huge issues with the hardware not supporting that sort of performance model.
11:38:57 <fasta> MyCatSchemes: I always install profiling libraries automatically
11:39:00 <wli> dcoutts: Unless somehow you convince CPU vendors to play along with you.
11:39:07 <dcoutts_> wli: right.
11:39:10 <mrd> narain: it's a very simple method which is actually derivable by Data.Derive and Drift.  basically it just reduces the subterms to normal form, and seqs those calls.
11:39:23 <narain> mrd: i just want to ensure i've got the whole value before i start doing io
11:39:25 <MyCatSchemes> fasta: the compilation error was in filepath. The real error is that my program silently dies on invalid input instead of properly screaming about the PEBCAK.
11:39:47 <narain> i basically want to avoid long-running computation interleaved in my io
11:39:51 <MyCatSchemes> Worked around that rather than actually fixed it, because I'm busy and that's going to get fixed properly later anyway.
11:39:52 <dcoutts_> wli: I was fantasising with matthew_-. It was more realistic than a pure local memory model as it'd allow a transition.
11:39:53 <mrd> narain: this is used by Control.Parallel to ensure that work is done by the spawned thread not lazily delayed
11:39:55 <fasta> MyCatSchemes: ok
11:40:11 <MyCatSchemes> (I mean I'm rewriting the input sections later, so it's no biggie anyway)
11:40:12 <mrd> @hoogle NFData
11:40:12 <lambdabot> Control.Parallel.Strategies.NFData :: class NFData a
11:40:12 <lambdabot> Control.Parallel.Strategies.NFDataInt :: class (NFData a, Integral a) => NFDataInt
11:40:25 <fasta> dons: Data/List/Stream.hs:226:22: parse error on input `#'
11:40:31 <wli> dcoutts: Have you read about elder Cray systems' memory architectures?
11:40:49 <fasta> dons: it doesn't compile out of the box, checking...
11:40:52 <narain> that seems sort of heavyweight, mrd
11:40:56 <dcoutts_> wli: the one where the whole memory is fast SRAM?
11:41:08 <wli> dcoutts: That would be the one.
11:41:18 <dcoutts_> wli: and no virtual memory (apparently Mr Cray though it was terribly slow)
11:41:31 <dcoutts_> wli: I was an intern at Cray a few summers ago, good fun.
11:41:50 <wli> dcoutts: Have you read about how address translation worked on Cray's systems that *did* have any form of it, prior to the commodity CPU's, anyway?
11:42:13 <fasta> import GHC.Exts (Int(I#), Int#, (+#))
11:42:20 <dcoutts_> wli: only for their more recent NUMA style machines, not the old SMP ones.
11:42:23 <fasta> What is Int(I#) supposed to do?
11:42:25 <wli> dcoutts: And do you know about TLB overhead in modern CPU's?
11:42:41 <fasta> Import constructor I# for type Int?
11:43:09 <dcoutts_> wli: yes, the newer numa machines have this memory mode where they ignore TLBs almost completely and map virtual memory to per-node physical memory in a very straightforward way
11:43:14 <fasta> It's not being accepted anyway.
11:43:35 <harlekin> !source
11:43:52 <harlekin> Where do I get the source from lambdabot? I remember seeing it somewhere.
11:43:55 <wli> dcoutts: There is a concept called "batch address translation," (it vaguely inspired 32-bit PPC BAT's but is something different) which basically uses (virtual_start, physical_start, length) triples etc.
11:43:59 <shapr> @version
11:43:59 <lambdabot> lambdabot 4p571, GHC 6.6 (Linux i686 2.66GHz)
11:43:59 <lambdabot> darcs get http://code.haskell.org/lambdabot
11:44:06 <harlekin> Thank you. (:
11:44:15 <dcoutts_> wli: so for running a big mpi process, you have to set up the threads on each node, get their memory mappings right and flip into this alternative addressing mode
11:44:23 <wli> dcoutts: UNICOS' VM subsystem is bizarre because it was basically written for that sort of thing.
11:44:38 <wli> dcoutts: That's a sort of instance of it, but far less general.
11:44:42 <dons> fasta: are you using the cabal build system?
11:44:47 <fasta> dons: yes
11:44:54 <dons> since that sounds like a cpp error..
11:45:16 <desegnis> fasta: I didn't follow the discussion and the context of the import not being accepted, but -fglasgow-exts permits the # functions and types
11:45:24 <wli> dcoutts: Basically hardwired ranges in a TLB, or otherwise programmed by firmware and not modifiable by the privileged executive.
11:45:27 <dons> fasta: checking...
11:45:42 <fasta> dons: runghc Setup.*s configure --enable-library-profiling <some extra options>
11:45:50 <fasta> dons: runghc Setup.*s build
11:45:59 <fasta> dons: that's what I do
11:46:06 <wli> dcoutts: Anyhow, you know how ordinary TLB's work?
11:46:09 <dcoutts_> wli: I don't recall all the details, I think it used the TLB on each node, so a memory request to a foreign node used the first few address bits as a node index, then it did the lookup in the local node's TLB. So that means each thread has to have the same view of the memory for it to be consistent.
11:46:23 <dons> fasta: i have some unrecorded patches here. let me push
11:46:27 <dons> they're for 6.8
11:46:32 <fasta> dons: what does {-# SOURCE #-} do?
11:46:41 <fasta> dons: 6.9 says they are pointless
11:46:51 <dons> hmm, do you have the right repo?
11:47:00 <fasta> dons: I used your command
11:47:06 <dons> the 'list' repo?
11:47:10 <fasta> dons: yes
11:47:13 <profmakx> any hints on how to build darcs with 6.8 or 6.9?
11:47:14 <opqdonut> ?pl \c x -> let a = f (g a) c in a
11:47:14 <lambdabot> const . fix . flip (f . g)
11:47:16 <dcoutts_> wli: yes, ordinary TLBs cache mappings of virtual to physical addresses in page sized chunks.
11:47:22 <dons> fasta: ah yes.
11:47:25 <fasta> profmakx: impossible, I think
11:47:29 <profmakx> hm
11:47:32 <dons> but that's to do with your build failing.
11:47:35 <wli> dcoutts: Okay, do you know how TLB's that support multiple pagesizes work?
11:47:39 <dons> fasta: just hang on 5 mins while i push some patches
11:47:40 <profmakx> okay then i have to put quickcheck into my 6.6.1
11:47:40 <opqdonut> ?pl \c x -> let a = f (g a) x in a
11:47:41 <lambdabot> const (fix . flip (f . g))
11:47:45 <fasta> profmakx: they wait until the actual release, IIRC.
11:47:54 <opqdonut> ?pl \c x -> let a = f (c a) x in a
11:47:54 <lambdabot> (fix .) . flip . (f .)
11:47:59 <opqdonut> urgh
11:48:08 <profmakx> yeah but trying to do something useful without darcs seems pointless ;)
11:48:15 <profmakx> at least for haskell development
11:48:36 <dcoutts_> wli: I'm not sure how they support the multiple page sizes, just that they do so.
11:49:51 <wli> dcoutts: It's only really necessary to know the interface seen by the kernel. So you have that much covered? Do you know how and why things are able to get fewer TLB misses and so big speedups with TLB's supporting multiple pagesizes?
11:50:21 <dcoutts_> wli: sure, bigger page sizes means the same number of cached TLB entries covers more virtual address space
11:50:39 <fasta> dons: I get that the interface file /home/me/lib/ghc-6.9.20071030/base-3.0/GHC/Num.hi-boot does not exist when I load it in ghci.
11:50:49 <dpiponi> At http://www.haskell.org/ghc/download_ghc_661.html, in the Tiger Intel binary section, it says "You will also need a GMP framework  and a readline framework." but I see no instructions about where to install these. What is the recommended place?
11:50:50 <lambdabot> Title: GHC: Download version 6.6.1
11:50:56 <dons> fasta: hang on! your build is failing for some reason, meaning the wrong code is being compiled.
11:51:02 <dons> wait 5 minutes :)
11:51:08 <wli> dcoutts: And taking exceptions to handle TLB misses, even when you've got a hardware pagetable walker like x86-64, is slow and so on.
11:51:16 <fasta> dons: I was just providing extra information.
11:52:11 <dcoutts_> wli: I was talking to a kernel hacker from SGI the other day, and they have a customer who wants to be able to cover the entire memory in a few large pages that fit into the TLB. This customer is using it for massive in-memory databases, like a few TB.
11:52:36 <dcoutts_> so they can do random lookups without horribly TLB thrashing
11:52:43 <narain> ?i forever
11:52:43 <lambdabot> Maybe you meant: id ignore index instances instances-importing irc-connect . ? @ v
11:52:51 <narain> ?index forever
11:52:51 <lambdabot> bzzt
11:53:06 <wli> dcoutts: Okay, there are a couple of issues with the multiple pagesize bits, namely (1) alignment restrictions and (2) size restrictions, like only having pages of limited sizes. I'm going to assume it's moderately obvious how having (virtual_start, physical_start, length) triples in the TLB would do in these situations.
11:54:02 <dons> fasta: darcs get http://www.cse.unsw.edu.au/~dons/code/streams/list
11:54:02 <lambdabot> Title: Index of /~dons/code/streams/list
11:54:06 <wli> dcoutts: Now it gets really interesting. It turns out IBM's virtualization silliness has actually produced a method of sharing TLB entries between processes.
11:54:17 <fasta> dons: I will just pull, ok?
11:54:21 <dons> ok.
11:54:35 <MyCatSchemes> dpiponi: GMP and readline are both GNU libraries that can be installed on pretty much any unix-alike.
11:54:40 <dcoutts_> wli: tagged TLB entries?
11:54:40 <dons> be sure to clean first before building
11:54:54 <MyCatSchemes> dpiponi: which includes Macs, yay, but I've no idea how to install libgmp and libreadline on a Mac.
11:55:20 <dcoutts_> wli: and so by two processes using the same tag they could share TLB entries?
11:55:20 <nominolo> MyCatSchemes: they're called "frameworks"
11:55:26 <fasta> dons: Data/Stream.hs:753:0: Warning: Defined but not used: `concatMap''
11:55:29 <MyCatSchemes> nominolo: what?
11:55:32 <dons> that's fine.
11:55:38 <MyCatSchemes> nominolo: they're libraries. When did "framework" come into it?
11:55:39 <wli> dcoutts: But not tagged by address space. They're tagged by "segment." Ranges of a process address space map to segment ID's, and TLB entries are tagged with segment ID's.
11:55:41 <fasta> dons: oh, missed the extra '
11:55:42 <dons> there should be a couple of warnings
11:55:49 <MyCatSchemes> nominolo: or does Apple package them up and publish them in some weird format?
11:55:54 <fasta> dons: yes, otherwise I know warnings are fine.
11:56:02 <fasta> dons: ok, it worked
11:56:05 <wli> dcoutts: Of course, process address spaces have their own tags as well.
11:56:33 <dons> fasta: so be sure to compile with -O2 , and -ddump-simpl-stats to check fusion is occuring.
11:56:39 <wli> dcoutts: This basically makes each file (or other mmap()'able object) the "owner" of the TLB entry.
11:56:39 <nominolo> MyCatSchemes: see bottom if this page: http://www.haskell.org/ghc/download_ghc_66.html
11:56:40 <lambdabot> Title: GHC: Download version 6.6
11:56:43 <dpiponi> I just downloaded those zip files and shoved them in System/Library/Frameworks and now ghc works. I know next to nothing about C++ development on Macs and it wasn't completely obvious, so someone ought to update those instructions.
11:56:52 <dons> fasta: and you'll just need to ensure that you use definitions from this package, rather than base
11:57:03 <wli> dcoutts: Linux does its best to ignore the feature, but AIX uses it to good effect.
11:57:07 <dcoutts_> wli: so if two processes map the some virtual address space to the same physical addresses then the kernel could arrange to share the TLB entry?
11:57:14 <fasta> dons: I am just applying this to my ton of code and see whether it goes any faster.
11:57:19 <wli> dcoutts: Exactly.
11:57:31 <fasta> dons: but I will make sure I am actually using it, don't worry
11:57:42 <dcoutts_> wli: so useful for threads and for shared memory like SysV IPC
11:57:44 <dons> fasta: yep.
11:57:48 <dons> -O2
11:58:03 <dons> you have some good benchmarks, so you can actually tell if its faster?
11:58:13 <MyCatSchemes> nominolo: ahhh, okkie. Tell dpiponi though, I'm not the one using the OS X box.
11:58:21 <dons> also, i'd compile with -ddump-simpl-stats and check there's some stream fusion happening
11:58:36 <dpiponi> nominolo: I was using the 6.6.1 page not the 6.6 page. They have different instructions. I couldn't get the 6.6 version to work but I just got the 6.6.1 version to work by manually installing GMP and readline.
11:58:39 <dons> you'll get nice messages logged when ghc spots a fusion chance
11:58:47 <wli> dcoutts: Well, threads would have the same ASN and so would map to the same segments no matter what. SysV IPC, shared libraries, and so on are what get boosted by it.
11:59:02 <fasta> dons: Yes, I can see that. I will let one particular problem run for a few minutes.
11:59:13 <dcoutts_> wli: Right. So would that be done on a per-VMA basis in the kernel.
11:59:24 <nominolo> dpiponi: ok
11:59:35 <fasta> dons: it's not a perfect benchmark, but since the run-time is about the same everytime it's not a problem.
11:59:49 <fasta> dons: if it's more than 5% faster it's no coincidence.
12:00:01 <wli> dcoutts: Well, it's the way AIX does it. Linux totally ignores it all, and I've no idea what the BSD's that run on 64-bit POWER do there.
12:00:44 <wli> dcoutts: The segment mapping involved has alignment and size limitations that effectively cripple it.
12:01:31 <dons> fasta: for lists, 5-25 would be good
12:01:33 <wli> dcoutts: The same range bits as for the TLB would make it highly useful.
12:01:47 <fasta> dons: minutes?
12:02:00 <fasta> dons: never mind
12:02:02 <dons> fasta: % speedup
12:02:03 <fasta> dons: %
12:02:05 <wli> dcoutts: (It's called the SLB or "Segment Lookaside Buffer" and so on.)
12:02:18 <dcoutts_> wli: oh so things like shared libs couldn't just be mapped at any old 4k address and then share TLB entries
12:02:41 <dcoutts_> so how does AIX manage with the alignment restrictions?
12:03:25 <wli> dcoutts: The implementation creates that problem. The concept can obviously be implemented so as not to have that problem. AIX just uses virtual placement strategies that use the address space the right way in 64-bit processes.
12:03:48 <dcoutts_> ah
12:03:58 <wli> dcoutts: The potential placement optimizations are largely ignored for 32-bit processes due to virtualspace pressure.
12:06:04 <wli> dcoutts: There are other system-level issues beyond this.
12:06:17 <wli> dcoutts: Manipulating the TLB is done with a poor set of primitives.
12:06:29 <L29Ah> Hi all! Could you recommend me any function to 'show' integral in binary?
12:06:37 <dcoutts_> wli: which often involve too much flushing as I understand it
12:06:47 <Olathe> L29Ah: Convert to a string and show that.
12:07:21 <L29Ah> How to convert to a string in a binary way? =)
12:07:32 <L29Ah> printf can't do that...
12:07:33 <wli> dcoutts: For instance, it's common to mmap() and munmap() things. When you munmap() you want to flush a specific range. There is no primitive for that in most CPU architectures, implementations, etc. You are forced to choose between flushing everything or flushing one entry at a time.
12:07:45 <hpaste>  (anonymous) pasted "(no title)" at http://hpaste.org/3565
12:08:32 <wli> dcoutts: For CPU models with hardware pagetable walkers there are no "prefill" operations which would essentially be the diametric opposites of such range flushing instructions.
12:09:00 <dcoutts_> wli: right
12:09:20 <wli> dcoutts: There's a lot more...
12:10:16 <dcoutts_> wli: do you have a feature request list that you send intel ? :-)
12:12:19 <Olathe> > let numToBin = numToBase 2; numToBase = numToBase' ""; numToBase' "" _ 0 = "0"; numToBase' ds _ 0 = ds; numToBase' ds base x = numToBase' ((if even x then '0' else '1'):ds) base (div x 2) in numToBin 47
12:12:20 <lambdabot>  "101111"
12:12:31 <Olathe> Doesn't work so well with negative numbers, though.
12:12:50 <Olathe> That wouldn't be too hard to correct, though.
12:13:03 <fasta> The Haskell module system is not expressive enough :(
12:13:13 <L29Ah> =))
12:13:18 <Olathe> > let numToBin = numToBase 2; numToBase = numToBase' ""; numToBase' "" _ 0 = "0"; numToBase' ds _ 0 = ds; numToBase' ds base x = numToBase' ((if even x then '0' else '1'):ds) base (div x 2) in numToBase 10 47
12:13:19 <lambdabot>  "101111"
12:13:22 <hpaste>  (anonymous) pasted "(no title)" at http://hpaste.org/3566
12:13:23 <wli> dcoutts: I've discussed these things with people at Intel. They pretty much tell me they're never happening.
12:13:24 <Olathe> O-o
12:13:32 <Olathe> > let numToBin = numToBase 2; numToBase = numToBase' ""; numToBase' "" _ 0 = "0"; numToBase' ds _ 0 = ds; numToBase' ds base x = numToBase' ((if even x then '0' else '1'):ds) base (div x base) in numToBase 10 47
12:13:34 <lambdabot>  "01"
12:13:37 <wli> dcoutts: I did the same with IBM while I worked there. Same answer.
12:13:37 <Olathe> Hmm.
12:13:39 <fasta> One should be able to say: if A and B export C, then use the one from A.
12:13:42 <Olathe> Not working so well ;)
12:13:54 <dcoutts_> wli: because they don't think there's enough performance benefit?
12:13:58 <wli> dcoutts: It's been a couple of years. No idea if the answer's changed.
12:14:23 <L29Ah> thx
12:14:25 <twanvl> > showIntAtBase 2 (chr . (+ord '0')) 123 ""
12:14:27 <lambdabot>  "1111011"
12:14:46 <Olathe> > let numToBin = numToBase 2; numToBase = numToBase' ""; numToBase' "" _ 0 = "0"; numToBase' ds _ 0 = ds; numToBase' ds base x = numToBase' ("0123456789abcdefghijklmnopqrstuvwxyz" !! (mod x base)):ds) base (div x base) in numToBase 10 47
12:14:46 <lambdabot> Unbalanced parentheses
12:14:49 <Olathe> Bah.
12:14:49 <wli> dcoutts: They have other ideas and set their goals years in advance. I'm also not very influential.
12:14:54 <Olathe> twanvl's works ;)
12:15:03 <Olathe> > let numToBin = numToBase 2; numToBase = numToBase' ""; numToBase' "" _ 0 = "0"; numToBase' ds _ 0 = ds; numToBase' ds base x = numToBase' (("0123456789abcdefghijklmnopqrstuvwxyz" !! (mod x base)):ds) base (div x base) in numToBase 10 47
12:15:05 <lambdabot>  "47"
12:15:09 <Olathe> Take that !
12:15:09 <wli> dcoutts: Anyway, another big, big, big deal is cache directories.
12:15:31 <dcoutts_> wli: is that different from the multiple levels of page tables?
12:16:08 <wli> dcoutts: It's unrelated to address translation (it would sit below the translation layer in VIVT/VIPT caches, even).
12:17:15 <Olathe> > showIntAtBase 5000 (chr . (+ord '0')) 123456789 ""
12:17:17 <lambdabot>  "4\4739\1837"
12:17:19 <Olathe> O-o
12:17:36 <wli> dcoutts: Basically some idiotic ownership negotiation protocol like dining philosophers or worse has to go on unless you have some sort of vaguely centralized tracking system for who owns what cachelines.
12:18:13 <dcoutts_> wli: the cache coherency protocols
12:18:19 <wli> dcoutts: Yes.
12:18:44 <wli> dcoutts: The ones now used on x86(-64) are complete disasters from this POV.
12:19:12 <dcoutts_> the read/shared/exclusive tags etc
12:19:42 <wli> dcoutts: It's all to avoid having some "expensive" component on system boards (when you get to NUMA, there may not be a unique one to call the "mother" or "main" board).
12:20:07 <wli> dcoutts: Yeah, those would be in the cache directory, too.
12:21:24 <wli> dcoutts: Anyhow you get some sort of quadratic messaging explosion as the number of CPU's goes up unless you have those things.
12:22:01 <quicksilver> @seen ac
12:22:02 <lambdabot> ac is in #haskell. I last heard ac speak 2h 48m 53s ago.
12:22:09 <dcoutts_> wli: because they all have to broadcast that they're taking ownership of some cache line
12:22:36 <wli> dcoutts: Or worse yet (in some protocols) poll every other possible owner.
12:22:36 <quicksilver> ac: have managed to get 10x speed improvement on your code
12:23:34 <quicksilver> ac: key art turns out to be  takeWhile (\(xr :+ xi) -> xr*xr+xi*xi <= 4)
12:23:56 <wli> dcoutts: What I'm driving at is that there is a lot of very old, well-trodden ground that doesn't need magic materials science advances or wild, crazy kernel/user interface changes that would vastly improve performance.
12:24:43 <dcoutts_> wli: which comes back to the point I was making to matthew_- about opting out of caching for some mappings, so no coherency for them.
12:26:06 <wli> dcoutts: Well, you'd have to redo a fair amount of architecture for that in much more disruptive ways than the various things I covered.
12:26:16 <dcoutts_> right
12:26:47 <Philippa> it's probably cheaper to have a cacheless MOV instruction or something similar
12:27:05 <wli> Oh, there are things like that AIUI.
12:27:10 <dcoutts_> Philippa: x86 has that already, for some SSE instructions
12:27:27 <Philippa> mmm. SSE was around when I stopped paying much attention
12:28:03 <wli> What's more desperately needed are cacheless memory-to-memory copies and cacheless zeroings operating on whole cachelines at a time.
12:28:21 <dcoutts_> mini dma operations
12:28:24 <wli> (like 64-bit POWER)
12:29:36 <CosmicRay> has anyone seen my post to haskell@haskell.org?  it seems to have disappeared into the ether
12:29:44 <CosmicRay> it was announcing the latest HDBC
12:30:11 <int-e> CosmicRay: I got that one
12:30:21 <CosmicRay> oh hmm, something must be weird with my end then
12:31:31 <int-e> gmane has it too
12:31:53 <CosmicRay> weird.  i am set up to receive acks for posts to the list and didn't get one
12:31:57 <wli> Anyway, things have already gone off into the weeds. For instance, more 4K-at-a-time garbage has gone in with the nested pagetable extensions for virtualization.
12:32:15 <fasta> dons: I should also use Control.Monad.Stream, right? I.e., it's intended for end-users?
12:32:18 <MyCatSchemes> Nice. Switching to a IOArray solution from (a rather kludgy) list solution seems to have sped this code up three times.
12:32:54 <dcoutts_> wli: you mean rather than moving to more sane management of bigger pages?
12:33:29 <wli> dcoutts: Yes, and also virtualization solutions that operate on large pages.
12:33:55 <MyCatSchemes> Hehehhe, nope. Actually that slowed it down massively.
12:34:09 <dcoutts_> CosmicRay: are those releases on hackage too?
12:34:09 * MyCatSchemes suspects this is probably O(n^2) or worse. Keekeekee.
12:34:44 <wli> dcoutts: Which even independently of optimizing guest/hypervisor interactions far more closely matches how hypervisors work: in bigger chunks of memory than guest kernels do.
12:35:26 <dcoutts_> wli: right, the guest os is responsible for swapping not the hypervisor
12:37:28 <wli> What's really painful about all this is that we can't do much of anything about it and the agenda was set the better part of a decade in advance.
12:39:22 <volk> how do I delete all occurences of an element in a list?
12:39:42 <asmanur> filter (== val)  ?
12:39:53 <asmanur> er, i mean /=
12:40:00 <mauke> > delete 'o' "foo"
12:40:02 <lambdabot>  "fo"
12:40:07 <mauke> hmm, yeah
12:40:27 <asmanur> > filter (/= 'o') "foo"
12:40:29 <lambdabot>  "f"
12:40:48 <volk> ah ok..
12:40:53 <mauke> (>'o')>
12:40:59 <mauke> kirby!
12:41:11 <shapr> KIRBY!
12:41:21 <shapr> hej volk
12:41:24 <arcatan> KIRBY!
12:41:31 <shapr> @go kirby
12:41:33 <lambdabot> http://www.kirby.com/
12:41:33 <lambdabot> Title: Welcome to the Kirby Company and Kirby vacuums
12:41:38 <shapr> hmm, maybe not
12:42:47 <shapr> Where's all the CODE??
12:46:29 <ski> @quote code
12:46:29 <lambdabot> Lemmih says: "I don't understand why my code acts weird when I use unsafePerformIO" is not a bug.
12:49:03 <fasta> I imported Control.Monad.Stream, I did import Prelude hiding(fmap), doing :i fmap still shows the one in base.
12:49:06 <fasta> Why?
12:49:27 <shapr> I think you have to hide the prelude on the command line as well.
12:49:36 <shapr> -fno-implicit-prelude or something
12:49:58 <fasta> shapr: I am pretty sure that's not the case.
12:50:39 <ski> Prelude> :m -Prelude
12:50:39 <ski> > :i fmap
12:50:39 <ski> Top level: Not in scope: `fmap'
12:50:46 <lambdabot>   parse error on input `:'
12:51:33 <fasta> It just reexports it, that's why.
12:51:51 <ski> fasta : that doesn't help ?
12:52:19 <fasta> ski: I already did that and it's irrelevant when you already do import Prelude <something>
12:52:34 <ski> ok
12:53:51 <dons> fasta: yep.
12:54:04 <dons> if you want monadic stuff to fuse with list stuff
12:54:40 <fasta> Having mapM implementations for a lot of generalizations also isn't great for refactorability.
12:55:04 <fasta> (the problem being that the generalizations are slower)
12:55:16 <jeremiah> hi friends, i woul like to learn haskell, and i would like to start a litle program with GUI, windows and linux compatible
12:55:48 <shapr> jeremiah: This is a good place to do that!
12:55:56 <jeremiah> thx shapr
12:56:33 <dmwit> jeremiah: Are you asking for library suggestions?  Gtk2Hs is pretty good.
12:56:39 <dmwit> ?where gtk2hs
12:56:39 <lambdabot> http://haskell.org/gtk2hs/
12:56:58 <dmwit> I think there's also wxHaskell, if you're familiar with wxwidgets.
12:57:04 <jeremiah> yes dmwit, thx, i will read it
12:57:39 <jeremiah> thx lambdabot, i will read the Gtk2Hs documentation
12:57:53 <dcoutts_> jeremiah: I'd suggest that GUIs are not the best place to start learning Haskell
12:58:21 * fasta is with dcoutts_ 
12:58:39 <dcoutts_> it'll give you the impression that Haskell is just an excellent imperative language
12:58:41 <fasta> The APIs are so big, it's hard to see where to begin.
12:58:52 <jeremiah> dcoutts:i know, but i like GUI's, and this motivate me to learn (sorry i dont speak english well)
12:59:24 <dcoutts_> jeremiah: ok, well bear in mind that Haskell GUIs are quite a different programming style to almost all other Haskell code
12:59:42 <dcoutts_> jeremiah: the real strength of the language is in the other core stuff
13:00:11 <jeremiah> ok, thx dcoutts
13:00:57 <hpaste>  (anonymous) pasted "(no title)" at http://hpaste.org/3567
13:03:24 <mauke> @babel de en kuerbis
13:03:26 <lambdabot>   kuerbis
13:03:32 <mauke> @babel de en krbis
13:03:33 <lambdabot>   krbis
13:03:37 <mauke> argh
13:04:18 <mauke> @babel en de pumpkin
13:04:18 <lambdabot>   Krbis
13:04:20 <shapr> @babel sv en sorg
13:04:20 <lambdabot> Plugin `babel' failed with: Error: Language sv not supported
13:04:23 <shapr> aww
13:05:06 <olsner> @babel se en sorg
13:05:06 <lambdabot> Plugin `babel' failed with: Error: Language se not supported
13:05:07 <dons> i think its 'se'?
13:05:10 <dons> ?help babel
13:05:11 <lambdabot> babel <lang1> <lang2> <phrase>.
13:05:11 <lambdabot> Translate a phrase in lang1 to lang2.
13:05:11 <lambdabot> Language is an element of"german","de" "greek","el" "english","en" "spanish","es" "french","fr" "italian","it" "dutch","nl" "portuguese","pt"
13:05:14 <dons> ah
13:05:20 <olsner> the language is sv, the country is se ;-)
13:05:25 <dons> :)
13:06:09 <shapr> Why is that anyway?
13:06:23 <olsner> some weird fluke of history I guess...
13:06:26 <shapr> El Salvador has .sv and why??
13:10:07 <phlpp> hi
13:11:01 <phlpp> babel en de what the fuck
13:11:07 <phlpp> @babel en de what the fuck
13:11:08 <lambdabot>   was das Bumsen
13:11:16 <phlpp> lol.
13:11:21 <arcatan> @babel de en was das Bumsen
13:11:21 <lambdabot>   which the Bumsen
13:11:40 <Japsu> ...
13:12:04 <dmwit> Nobody quickcheck'd that @babel de en . @babel en de === id.
13:12:15 <Japsu> hahaha
13:12:17 <shapr> hah
13:12:31 <Japsu> @remember dmwit Nobody quickcheck'd that @babel de en . @babel en de === id.
13:12:31 <lambdabot> Done.
13:12:31 <shapr> @help compose
13:12:32 <lambdabot> . <cmd1> <cmd2> [args].
13:12:32 <lambdabot> . [or compose] is the composition of two plugins
13:12:32 <lambdabot>  The following semantics are used: . f g xs == g xs >>= f
13:12:45 <glguy> phrik has a nice piping system for that: glguy: !en2de what the fuck | de2en
13:12:46 <glguy> [1:12pm] phrik: which the Bumsen
13:14:04 <phlpp> hehe
13:14:23 <phlpp> veeeery literally translation
13:14:30 <phlpp> word-by-word :P
13:14:39 <dons> fasta: got some fusion going on yet?
13:15:55 <fasta> dons: not yet, there's quite a bit of refactoring I need to do.
13:16:18 <fasta> dons: e.g. at some places I used the mapM_ from Traversable which complicates things, etc.
13:16:38 <dons> you can certainly compile ignoring those for now
13:16:44 <pgavin> dcoutts_: ping
13:16:47 <fasta> er mapM
13:16:48 <dons> though the more of those, the better the result
13:16:57 <fasta> dons: well, I already broke a lot.
13:17:05 <fasta> dons: I will just make it work completely
13:17:10 <dons> cool
13:17:14 <fasta> dons: trusting that indeed it does work
13:17:42 <fasta> I am also renaming some stuff in the process, s.t. changing to another lib in the future should be one line change.
13:17:53 <dons> there's some unknowns wrt. the latest simplifer/inliner/rules changes in ghc, but i'd be fairly confident.
13:18:01 <dons> all the examples i keep trying on the mailing list just wor
13:18:02 <dons> k
13:18:10 <dons> the unknown is large/cross module stuff
13:19:57 <fasta> dons: the thing you demonstrated on the mailing list sure looked cool.
13:20:03 <astrolabe> how do I make ghci see Data.List?
13:20:10 <fasta> dons: or maybe things, I only saw one thing.
13:20:12 <dons> yeah, that was a perfect result.
13:20:20 <dons> astrolabe: :m + Data.List
13:20:20 <fasta> astrolabe: :m + Data.List
13:20:31 <astrolabe> thank you :)
13:20:58 <fasta> dons: now, only GHC should use it itself ;)
13:21:04 <dons> yep.
13:21:10 <fasta> dons: are there plans for replacing it?
13:21:13 <dons> we need to solve the issue of list comprehensions first
13:21:21 <dons> but yes, it does need to happen , i think
13:21:27 <dons> so much code is suboptimal
13:21:29 <fasta> I only use single level list comprehensions.
13:21:30 <dons> due to left folds
13:21:34 <dons> right, most people do.
13:22:12 <fasta> dons: well, it depends on the definition of level
13:22:43 <fasta> dons: if you use a result that's computed by a list comprehension, but hidden in a function, does that add an extra level?
13:23:52 <dons> probably not
13:24:20 <dons> its the list comprehension desugaring that yields nested concatMaps with complex states that previously was difficult
13:25:10 <fasta> dons: can one extend this approach to different data structures?
13:25:20 <dons> yep
13:25:26 <dons> anything that looks like a sequence
13:25:31 <dons> see the end of the main fusion paper
13:25:33 <dons> for e.g. trees
13:25:36 <fasta> dons: I was thinking of graphs :)
13:25:48 <fasta> dons: mutable ones for example
13:25:58 <dons> mutable ones. hmm. unknown.
13:26:11 <dons> fusion generally relies on purity
13:26:20 <dons> to reorder things radically
13:26:26 <fasta> dons: pure functional goodness is nice, but if mutable code runs 20 times faster...
13:26:53 <dons> sure, but you sacrificie the ability to fuse loops automatically
13:27:01 <dons> since first you have to do an effect analysis
13:27:09 <sjanssen> fasta: that doesn't seem possible
13:27:09 <lambdabot> sjanssen: You have 3 new messages. '/msg lambdabot @messages' to read them.
13:27:31 <fasta> sjanssen: IntMap vs mutable arrays
13:27:32 <sjanssen> the 'stream' function can't have the graph changing underneath it
13:27:35 <idnar> Press 1 to hear new messages, press * to hang up.
13:27:40 <dons> well, IntMap is fine.
13:27:45 <fasta> sjanssen: oh, you meant something else.
13:27:52 <dons> O(log n) == O(1) for all machines
13:27:55 <dons> :)
13:27:59 <sjanssen> (unless you want to pay an O(n) copy cost at the beginning)
13:28:13 <fasta> dons: abusing notation? :)
13:28:28 <dons> well, in practice.
13:28:29 <EvilTerran> dons, and, of course, when the imperative programmers say they have O(1) lookups, they really mean O(log n), too
13:28:35 <EvilTerran> ;)
13:28:37 <dmwit> log n < 30 for all n ;-)
13:28:38 <dons> EvilTerran: right.
13:29:05 <EvilTerran> so we're O(1) and they're O(log n). who'd've thunk it? :P
13:29:08 <dons> so those log n costs for purity, thread safety and persistence don't matter. :)
13:29:17 <quicksilver> the constant factors do, though :(
13:29:20 <dons> its whether there are known good structures that matters more
13:29:22 <dons> e.g. for graphs
13:29:27 <fasta> dons: I might change back to IntMap when I have a 1000 core machine
13:29:55 <wli> dons: multidimensional range search
13:30:02 <dons> sure, i'd use mutable arrays too if i was going for performance for indexing
13:30:15 <dons> but you don't get automagic loop fusion then
13:30:23 <dons> since i can't reorder your writes
13:31:10 <wli> in parallel it may not even happen in a consistent order
13:31:18 <fasta> My import lists are too long...
13:31:39 <roconnor> fasta: make a module that exports all your imports?
13:31:42 <dons> yeah.
13:31:47 <conal> if i understood john o'donnell at ifl 07, RAM access takes log time, not constant.
13:31:49 <dons> i do that in lambdabot
13:32:02 <conal> i.e., address decoding
13:32:05 <fasta> roconnor: yes, I already have a MyPrelude, but it doesn't contain everything.
13:32:22 <dons> sjanssen: thanks. note new screenshots on the frontpage, and no more X11-extras
13:32:45 <dons> also, i think i fixed the X lib path cabal issue, where the .cabal file had to have paths edited
13:32:57 <sjanssen> dons: what about users that are installing 0.4?
13:32:59 <dons> so hopefully xmonad got just a bit easier
13:33:12 <dons> sjanssen: right. i'm not sure. did we specify precisely X11 1.2.3?
13:33:16 <sjanssen> no
13:33:16 <dons> or >= 1.2.3?
13:33:18 <dons> hmm
13:33:26 <sjanssen> >= 1.2.2, or some such
13:33:27 <shapr> I have a vaguely Haskell-oriented question... I'm trying to figure out what undergraduate degree I could acquire soonest from the university next door. FGL is probably a good tool to try there, but I haven't been able to find a single collection of the degree requirements in a parseable form. Is that sort of information usually available from a college?
13:33:34 <dons> i'm going to add == to the .cabal now actually
13:34:30 <dmwit> shapr: No. =/
13:34:34 <shapr> :-(
13:34:37 <sjanssen> dons: my point is that users building 0.4 will still need a link to X11-extras on hackage
13:34:54 <dons> sure. i only removed the dev branch darcs links
13:34:59 <dmwit> shapr: In fact, here at Stanford, I offered to undertake a project to put the information into a parseable form, and they absolutely shut me down.
13:35:08 <shapr> whatever for?
13:35:15 <dmwit> They want to control that information, I guess.
13:35:40 <shapr> I do not have a positive opinion of Stanford's decision in that matter.
13:35:48 <dmwit> yeah
13:36:41 <sjanssen> Stanford probably has a private copy of the requirements in computer-readable form
13:37:10 <sjanssen> do they have an automated "degree audit"?
13:37:19 <dons> some nice new screenshots for xmonad fans, http://xmonad.org/
13:37:21 <lambdabot> Title: xmonad : a tiling window manager
13:37:25 <fasta> dons: I miss an instance for MonadPlus now
13:37:36 <fasta> dons: can that be related to your code?
13:37:39 <dons> fasta: oh? for what type?
13:37:40 <dmwit> sjanssen: I think the answer is "yes" to both of those statements.
13:37:43 <quicksilver> sjanssen: 99% chance, 'computer-readable form' means an excel spreadsheet with hideous formulae :)
13:38:04 <fasta> dons: MonadPlus (MaybeT <something horrible>
13:38:35 <dons> fasta: oh, maybe no MonadPlus list instance visible?
13:38:36 <fasta> dons: I am currently only using Control.Monad.Stream and I am only importing Control.Monad()
13:38:51 <dons> that's the only  thing i can think of
13:39:06 <fasta> dons: I am not sure how it's related to []
13:39:20 <fasta> dons: AFAIK, the monadplus instance for MaybeT is not in scope.
13:39:21 <sjanssen> UNL has a website that can show pretty exactly the progress on your degree.  If UNL can do it, I'd hope Stanford can too :)
13:39:29 <dons> could you have hidden a required instance from Data.List?
13:39:29 <fasta> I think I just removed one bit too much.
13:39:34 <dons> yeah, maybe
13:39:51 <quicksilver> woo
13:40:01 <quicksilver> CosmicRay++ # adding a bit more strictness to hdbc
13:40:01 <shapr> Anyway, if I do get the degree information, is FGL the best/a good choice to solve that sort of thing?
13:40:17 <fasta> dons: the problem is that MaybeT uses the base monad, not your monad.
13:40:30 <fasta> dons: does that sound plausible?
13:40:58 <fasta> shapr: what do you mean by FGL? The graph library?
13:41:17 <shapr> yup
13:41:29 <fasta> shapr: FGL does not scale for big problems.
13:41:42 <shapr> How so?
13:41:45 <fasta> shapr: you should be fine until a dew thousand
13:41:48 <fasta> shapr: few*
13:41:55 <shapr> As far as I know FGL is lazy, why wouldn't it scale?
13:42:07 <dons> fasta: oh, yes.
13:42:19 <dons> fasta: so the wrong instances in use.
13:42:20 <shapr> fasta: Do you have some code that demonstrates how/why FGL does not scale?
13:42:45 <dons> fasta: i've not looked through the issues with changing to Control.Monad.Stream very thoroughly
13:43:03 <dons> copying code to rebind the MaybeT defn seems easy enough
13:43:35 <fasta> shapr: Asymptotically it is not efficient. I also did some benchmarks which said the same.
13:43:46 <shapr> Do you have code that demonstrates that?
13:44:15 <dons> fgl
13:44:15 <fasta> shapr: I have some code, but I am not sure how easy it is to get it working.
13:44:27 <dons> could do with a good working over for performance
13:44:35 <fasta> shapr: the data structures used are simply not suitable for the problem.
13:44:38 <dons> since its not deeply optimised
13:44:38 <shapr> fasta: Could I get a copy of your code?
13:44:45 <shapr> fasta: What would be better?
13:45:10 <fasta> shapr: if you want to scale to 100,000 size graphs with a few million edges, use STArrays.
13:45:48 <fasta> shapr: between that, use IntMap
13:45:50 <shapr> I'd like to get a copy of your code and try it out myself, but I don't doubt your conclusion.
13:46:02 <wli> You won't be running eigenvector centrality bits on that one.
13:46:03 <shapr> fasta: Sounds like it's worth writing a blog post about.
13:46:09 <fasta> shapr: that code was written years ago, and probably doesn't work.
13:46:23 <shapr> I might be able to clean it up.
13:46:48 <fasta> shapr: Under some conditions I might be willing to share, let me see...
13:49:00 <fasta> dons: I also use Control.Monad.Cont, so it's probably never going to work this way?
13:49:16 <fasta> dons: or did you cover that case?
13:49:46 <dons> you can just not hope for fusion for code not compiled against Data.List.Stream
13:49:52 <dons> but things should work otherwise.
13:50:08 <fasta> dons: ok, I understand that, but I meant for the missing instances problem.
13:50:19 <dons> there might be issues there too, i supppppose
13:51:04 <pitecus> @hoogle concatMapM
13:51:04 <lambdabot> No matches found
13:52:55 <fasta> I don't like API changes without deprecation though....
13:53:02 * fasta mumbles (>>>)
13:54:35 <oklopol> what's the callback for mouse motion in opengl? coding in haskell, so this must be the right place to ask :P
13:54:46 <oklopol> google refused to help me
13:55:51 <dons> grep the opengl docs?
13:55:55 <dons> or hopengl
13:56:01 <omnId> http://haskell.org/ghc/docs/latest/html/libraries/GLUT/Graphics-UI-GLUT-Callbacks-Window.html#6
13:56:03 <lambdabot> http://tinyurl.com/yvf5f6
13:56:21 * Japsu mumbles about (>>>) and (>>=) being on the same precedence level
13:56:32 * omnId just mumbles
13:56:48 * arcatan just
13:56:59 * shachaf
13:57:13 * Japsu would like to do getContents >>= (sort >>> group >>> map (length &&& head)) without the outer parenthesis
13:57:13 * fasta mumbles that there are only 9 levels of precedence
13:57:15 <CosmicRay> quicksilver: thanks, yes I am.
13:57:17 <wli> 100 precedence levels would've been just as easy as 9.
13:57:24 <CosmicRay> quicksilver: so far without introducing incompatibility
13:57:29 <fasta> wli: an infinite is possible too
13:57:48 <soncek> which parser should I use if I would like to parse indentation aware language (like Python, Haskel ...), is it possible to do with parsec?
13:57:50 <wli> fasta: Sure, floating point numbers.
13:58:17 <fasta> wli: I mean that the parser can be adapted to work without any reference to numbers
13:58:39 <Japsu> Why not just use "put operator X right after operator Y" and let the compiler compiler deduce the full order? ;)
13:58:40 <wli> Sure, you can do it by defining a preorder.
13:59:00 <EvilTerran> @hackage IndentParser -- soncek, how about this?
13:59:00 <lambdabot> http://hackage.haskell.org/cgi-bin/hackage-scripts/package/IndentParser -- soncek, how about this?
14:00:02 <soncek> will look
14:00:24 <EvilTerran> it's built on top of parsec, AFAICT
14:00:58 <fasta> shapr: I did find the code, but it implements rather specialised things (and doesn't work and requires access some books to understand). The best thing you can do if you want to compare some things, is to call some functions from FGL for increasingly larger graphs. By the time you hit 1million you wish you had never started it.
14:01:13 <fasta> to some*
14:01:21 <shapr> ok
14:01:47 <fasta> shapr: I might put in a comparison in my thesis.
14:01:57 <fasta> shapr: but that hasn't been planned yet.
14:02:18 <fasta> shapr: I am also not sure what the point of stating the obvious is, though.
14:02:49 <fasta> I estimate that my implementation is about 1000 times faster for my algorithms.
14:03:20 <shapr> I think it's not obvious to the average programmer how to do graph algorithms efficiently in Haskell.
14:03:23 <fasta> I could port FGL to my library to check that number, but I stopped using it _because_ it was too slow.
14:04:34 <fasta> shapr: yes, well, neither did I at the start, otherwise I would do what I am doing now :)
14:04:44 <fasta> would have done*
14:05:04 <shapr> I'm just saying that posting a wiki page or blog post about that would not be stating the obvious.
14:05:45 <opqdonut> http://haskell.pb.paivola.fi/341 -- i made a simple regex engine :))
14:05:47 <lambdabot> Title: haskell private pastebin - collaborative debugging tool
14:05:58 <opqdonut> (sorry, not in hpaste so no syntax hl)
14:06:23 <opqdonut> *Parse> run "aaabbabababbabababbccccccccaaabcbcbc" (compile "(a|b)*c+(a|bc)*")
14:06:27 <opqdonut> True
14:06:31 <opqdonut> works like that
14:07:34 <fasta> shapr: anyone is free to read the code for FGL and read the paper on it and see that the complexity is just a nightmare to begin with.
14:08:15 <fasta> shapr: the only thing the Haskell community should do is not say:"Oh, you have a graph problem, use FGL".
14:08:44 <dons> i don't think we say that, usually
14:08:48 <dons> except for small problems
14:09:10 <dons> for large ones we usually say: you'll need a different structure/bind to a C lib or boost
14:10:57 <fasta> dons: a binding to boost would be interesting too, indeed. I have no idea how to do that, though.
14:11:34 <fasta> dons: AFAIK, keeping the C++ parametricity is impossible currently.
14:11:40 <dons> has to go via C first, and flatten any type system tricks on the C++ side
14:12:13 <fasta> dons: flattening amounts to what I said, I guess?
14:12:21 <Zao> Most boost libraries are template based anyway, so it'll get even more bothersome.
14:12:36 <dons> yep
14:12:39 <dons> yep
14:12:42 <fasta> What you want is a mapping from Concepts to TypeClasses
14:12:49 <dons> its a big open question
14:12:50 <fasta> and you want that it compiles to Haskell.
14:13:00 <fasta> Well, it's "just a compiler".
14:13:08 <fasta> Just "a lot of work", I guess.
14:13:16 <nominolo> it's "only C++"
14:13:18 <fasta> It's not an open question, I think.
14:13:33 <dons> a new graph library all in haskell, even in say, ST, would make someone famous ...
14:13:38 <dons> if they churned it for performance
14:13:48 <nominolo> dons: i could use one
14:13:50 <dons> how hard can graphs be?
14:14:14 <bartw> port dot/graphviz
14:14:27 <nominolo> dons: i'm need to keep track of dependencies between different instructions
14:14:35 <dons> mm
14:14:37 <nominolo> bartw: that's for drawing graphs only
14:14:48 <fasta> I didn't "churn for performance", but it does scale.
14:15:12 <dons> fasta: released the code on hackage?
14:15:30 <profmakx> are graphs just hard to capture efficiently functionally?
14:15:51 <dons> i think its more that current haskell libs are few, and researchy
14:15:56 <nominolo> profmakx: most algorithms are very imperatively specified, yup
14:15:57 <fasta> profmakx: no
14:16:09 <fasta> profmakx: I will write something about it in my thesis.
14:16:11 <dons> graphs have historically been harder, but that's in the past.
14:16:26 <fasta> The only problem about graphs are practical in Haskell.
14:16:31 <fasta> That's a task for compiler writers.
14:16:32 <nominolo> fasta: have a quick summary?
14:16:45 <fasta> nominolo: basically you can use Data.DiffArray
14:17:08 <fasta> nominolo: on top of that you can implement linked lists
14:17:16 <nominolo> fasta: that works for 2d-arrays?
14:17:18 <fasta> nominolo: then you have an adjacency list graph
14:17:30 <fasta> nominolo: oh, it must be doubly linked
14:17:34 <nominolo> i see
14:17:41 <fasta> nominolo: I implemented that too.
14:17:45 <nominolo> i currently use a Map of Maps
14:18:02 <fasta> The problem is that it's ultra-slow.
14:18:03 <dons> fasta: where's your code?
14:18:08 <nominolo> it's nice for backtracking (more sharing)
14:18:09 <fasta> dons: here :)
14:18:21 <dons> then it doesn't exist :)
14:18:24 <fasta> dons: your code is running here too.
14:18:26 <profmakx> as linus says: Talk is cheap. show me code!
14:18:43 <fasta> dons: if it completes in 4 minutes, you have won.
14:18:44 <dons> code.haskell.org is available for repo hosting
14:18:56 <nominolo> profmakx: he also calls people 'ugly' and 'stupid', a lot :)
14:18:58 <dons> oh, you're running benchmarks now?
14:19:01 <dons> got it to build?
14:19:14 <fasta> dons: I am runnning that one test problem of about 5 minutes, yes.
14:19:17 <dmwit> nominolo: Lots of people are ugly and stupid...
14:19:17 <dons> did you use -ddump-simpl-stats to check fusion was occuring?
14:19:23 <profmakx> nominolo. yeah right. but he admits that he is an asshole ;)
14:19:42 <dons> fasta: if it doesn't get faster, i'd like to see the test code, so we can work out why
14:19:45 <nominolo> profmakx: doesn't make him more likable, though ...
14:20:07 <fasta> dons: no, I didn't use -ddump- yet
14:20:32 <dons> -O2 though? (you can see other useful flags in the list.cabal file)
14:21:00 <dmwit> nominolo: Well, at the very least, a lot of people are ugly and ignorant. =)
14:21:28 <fasta> dons: yes, via-c
14:21:57 <fox86> hmm, i am trying to compile a gtk2hs example using "ghc --make ActionMenu.hs -o actionmenu.exe" on windows, and it says "gcc: installation problem, cannot exec `as': No such file or directory" ... any idea why?
14:22:00 <nominolo> dmwit: sure.  but that doesn't mean you have to be the same ...  It doesn't help anyone
14:22:09 <profmakx> gna. need patch for darcs
14:22:22 <fasta> fox86: that's a FAQ, don't know the answer by heart.
14:22:26 <nominolo> dmwit: well, except if your goal is to piss people off
14:22:31 <nominolo> anyways...
14:23:19 <fox86> fasta: ah, okay
14:23:35 <fasta> dons: it appears there's no notable difference
14:23:49 <fasta> dons: raw seconds wise, it's even slower.
14:23:56 <fasta> dons: I will check the stats now
14:24:15 <dons> yep, or maybe you don't use much list stuff of value to fuse
14:24:26 <dons> or its already so lazy, removing intermediate lazy nodes doesn't matter
14:25:11 <fasta> dons: I get a _long_ list of output.
14:26:07 <fox86> fasta: i had to add ghc/ghc-libs to the path. now it works
14:26:10 <dons> Igloo: Linker.c in head is broken on openbsd,
14:26:11 <dons> #ifdef USE_MMAP
14:26:11 <dons>     #ifndef linux_HOST_OS /* mremap is a linux extension */
14:26:11 <dons>         #error ocAllocateSymbolExtras doesnt want USE_MMAP to be defined
14:26:11 <dons>     #endif
14:26:16 <dons> urgh!
14:26:27 <dons> fasta: -ddump-simpl-stats?
14:26:30 <dons> about rules firing?
14:26:33 <fasta> dons: yes
14:26:37 <dons> cool
14:26:46 <fasta> dons: but that's not just your rules, I guess
14:26:51 <profmakx> sme for freebsd ;)
14:26:55 <dons> no, you're looking for fusion
14:27:21 <dons> profmakx: yes, this is bad, since the mmap linker has been the only working one for years now
14:27:27 <dons> and its broken in the last 2 weeks or so
14:28:39 <fasta> dons: you can accept the dcc request, if you want to see the output.
14:29:56 <dons> can you just post it on the web somewhere?
14:30:05 <dons> ideally, with src, so i can reproduce
14:32:06 <fasta> dons: why not just accept the request?
14:33:03 <fasta> The output of the simplifier is also rather pointless, since it doesn't contain line number of what didn't fuse.
14:35:17 <oklopol> > Just Nothing
14:35:19 <lambdabot>  Just Nothing
14:35:30 <oklopol> > Maybe Just Nothing
14:35:31 <lambdabot>   Not in scope: data constructor `Maybe'
14:35:34 <oklopol> heh
14:35:42 <oklopol> > Just Nothing :: Maybe
14:35:42 <lambdabot>      `Maybe' is not applied to enough type arguments
14:35:42 <lambdabot>     Expected kind `?', b...
14:35:49 <oklopol> > Just Nothing :: Maybe Maybe
14:35:50 <lambdabot>      `Maybe' is not applied to enough type arguments
14:35:50 <lambdabot>     Expected kind `*', b...
14:35:54 <oklopol> hmm :)
14:35:56 <fasta> oklopol: you can also do /msg lambdabot
14:35:58 <omnId> Just Nothing :: Maybe (Maybe a)
14:36:16 <oklopol> fasta: sorry, i was just trying to brighten up your day!
14:36:29 <oklopol> > Just Nothing :: Maybe (Maybe a)
14:36:29 <fasta> oklopol: you didn't.
14:36:29 <dons> fasta: i prefer mail/urls. i can help if there's a src bundle, and instructions for reproducing the test
14:36:31 <lambdabot>  Just Nothing
14:37:00 <oklopol> fasta: well, i tried my best
14:37:23 <fasta> dons: you are saying that when it says that there were X calls to length and Y of them weren't fusible, you can magically decide which ones it were?
14:38:28 <dons> yes. i have magic powers. but no, not all will fuse -- that's not the interesting info anyway. its what fused, what it fused to, and how much fusion there was in comparison to build/foldr
14:39:07 <omnId> @remember dons i have magic powers.
14:39:07 <lambdabot> Done.
14:42:50 <oerjan> @quote magic
14:42:50 <lambdabot> shapr says: Programming is the Magic Executable Fridge Poetry, it is machines made of thought, fueled by ideas.
14:42:55 <fasta> dons: it is quite nice that it computes the same answer, though. (I.e. in a pretty complicated use of lists, it works)
14:43:30 <salierix> What does Haskell over a language like Clean? The syntax looks very similar.
14:43:43 <Cale> salierix: Clean and Haskell are very similar
14:43:44 <dons> fasta: oh, that's good to know
14:43:53 <sjanssen> salierix: Haskell has an active community
14:43:55 <dons> it would be bad if fusion broke programs
14:44:05 <fasta> dons: and I was wrong.
14:44:10 <fasta> dons: it is about 6 seconds faster.
14:44:27 <dons> salierix: yeah, the core languages are similar in definition, the difference is in libraries, community, extensions and other things
14:44:48 <salierix> I heard Haskell is very hard to learn..
14:44:49 <fasta> real    5m35.061s
14:44:49 <fasta> user    5m11.911s
14:44:49 <fasta> sys     0m2.972s
14:44:56 <Cale>   >>> Missing "in" marshaller!
14:44:56 <Cale>   There is no default marshaller for this combination of Haskell and C type:
14:44:56 <Cale>   Haskell type: ImlibColorModifier
14:44:56 <Cale>   C type      : (ImlibColorModifier)
14:44:58 <fasta> real    5m17.466s
14:44:58 <fasta> user    5m5.547s
14:44:59 <fasta> sys     0m2.612s
14:45:00 <Cale> grumble :)
14:45:07 <oerjan> isn't clean one of the old languages haskell was based on, which has somehow kept an independent existence because of its unique properties (pun intended)?
14:45:08 <dons> salierix: can't be that hard, we teach it to beginner programmers and a few universities
14:45:13 <dons> oerjan: yep.
14:45:16 <fasta> dons: the first is without your library.
14:45:22 <fasta> dons: the second it with.
14:45:24 <dibblego> salierix, it's easy to learn for people who have never programmed before
14:45:28 <dons> fasta: ok, that looks significant
14:45:35 <monochrom> Chinese is easy to learn. :)
14:45:39 * Cale begrudgingly specifies the identity function for marshalling :)
14:45:47 <salierix> dibblego, and for C/C++ people?
14:45:50 <dons> monochrom: esp. if you know cantonese already
14:45:54 <dibblego> salierix, semmingly difficult
14:46:00 <omnId> salierix: the hardest part is unlearning some fundamental assumptions about computation that imperative programming sits on.
14:46:02 <monochrom> hahaha
14:46:03 <dibblego> *seemingly
14:46:15 <dibblego> salierix, what omnId said matches my observations precisely
14:46:20 <monochrom> Learning is Unlearning.
14:46:30 <omnId> War is Peace!
14:46:31 <dons> ?quote unlearn
14:46:31 <lambdabot> DukeDave says: Haskell has the greatest unlearning curve
14:46:39 <dons> ?users
14:46:39 <lambdabot> Maximum users seen in #haskell: 424, currently: 402 (94.8%), active: 16 (4.0%)
14:46:52 <dons> 424 irc users have managed to learn it ;)
14:47:06 <fox86> does gtk2hs come with cairo?
14:47:12 <omnId> oh, so the long-standing 420 has finally broken :)
14:47:13 <dibblego> 424 tried; 23 failed :)
14:47:25 <dons> salierix: start with one of the nice tutorials on haskell.org
14:47:30 <salierix> Somehow Clean is now faster than C++ on the computer language shootout.
14:47:36 <monochrom> If you know nothing, it's easy to learn something. If you know a bit of something, it's hard to learn more. If you know almost everything, it's easy again to learn the rest.
14:47:57 <dons> salierix: yeah, its good for small benchmarks
14:48:11 <dons> but falls down in the usual things: libraries, portability, community, documentation
14:48:31 <dons> its essentially a haskell fork with a harder type system
14:48:41 <dons> you looking to replace C/C++ with somethiong?
14:48:45 <omnId> how much Clean have you written, dons?
14:48:52 <salierix> I like the Haskell syntax but it seems very abstract.
14:49:01 <salierix> dons, Yes, I hate C++
14:49:03 <mauke> hah, try lisp
14:49:16 <monochrom> Yes, Haskell is a bit more abstract than average.
14:49:19 <mauke> I hear it has no concrete syntax
14:49:34 <dons> omnId: a little, but that's reporting the tyep system remark was from ben lippmeijer, who's done a fair bit in each.
14:49:35 * Cale works some more on his better Imlib2 binding :)
14:49:44 <ddarius> salierix: I heard programming is hard to learn.
14:49:58 <Heffalump> dons: I didn't realise it was a fork
14:50:18 <dons> a fork that didn't merge
14:50:21 <Heffalump> "harder" type system sounds a bit unlikely given what GHC does these days :-)
14:50:25 <salierix> ddarius, most languages don't have monads as a core mechanic.
14:50:45 <Heffalump> wow, it's top hit for "Clean" on google. I didn't realise until after I successfully found it how unlikely that would be..
14:50:48 <mauke> salierix: yeah, most languages use something complicated
14:50:55 <dons> Heffalump: oh, the uniqueness stuff gets really tricky, quickly
14:51:05 <Cale> Well, it has uniqueness types, which let you specify that a parameter to a function must occur only once in its body.
14:51:11 <goalieca> salierix, i find monads overcomplicate things
14:51:17 <goalieca> at least syntax wise
14:51:17 <omnId> haskell syntax is mostly declarations, patterns, types, and expressions.  The declarations is a lot to get familiar with, patterns and expressions are similar, and *beautifully* lean and consistent, types are weird-looking at first, but not too different from term-level expressions.
14:51:28 <dons> they don't have the 10 years/user base to make uniqueness types easy with all the support monads have
14:52:03 <Cale> I think if I was to program in Clean, I'd still want monads for carrying around my unique-typed things :)
14:52:09 <ddarius> dons: They have more than 10 years.
14:52:17 <ddarius> Cale: You can have them.
14:52:21 <Cale> Right
14:52:30 <dons> ddarius: yes, but not the community pushing for simplification
14:52:47 <Cale> It's just the base library doesn't define an IO monad. Of course you could construct the monad library, because Clean has constructor classes.
14:52:53 <dons> which did happen with haskell stuff -- we have tutorials, for example
14:52:55 <Heffalump> can you partition the IO token?
14:53:16 <Cale> Not if I recall correctly, though that would be a neat idea.
14:53:49 <salierix> I just don't understand how you can have a program state if nothing is mutable.
14:53:51 <pitecus> When I modify some installed GHC package, then  in another project that depends on it I have to delete the dist directory, or the build fails with missing bindings etc. Isn't this a bug?
14:54:08 <Cale> salierix: by passing it around as a parameter
14:54:25 <Cale> salierix: (essentially)
14:54:27 <dons> pitecus: right, ou can also clean
14:54:34 <salierix> Isn't that expensive? Everything gets copied.
14:54:34 <Cale> You can always simulate state.
14:54:37 <Cale> No
14:54:44 <Cale> You're just passing a pointer to something.
14:54:49 <omnId> salierix: very little is copied, actually.
14:54:50 <dons> pitecus: there's an open ticket for this
14:54:55 <Cale> At least, if your compiler's not dumb.
14:54:55 <Heffalump> salierix: semantically, you pass it around. Operationally, it gets erased and the compiler just guarantees things happen in the right order.
14:55:09 <pitecus> ok thanks, dons
14:55:13 <Heffalump> The compiler knows that it can implement the token using the arrow of time :-)
14:55:19 <omnId> salierix: since things can't change, there's no need to copy things, just reuse pointers to existing things.
14:55:50 <salierix> But what if you want to make a change to something?
14:56:09 <dibblego> you don't, change is an illusion
14:56:16 <dons> Heffalump: cute
14:56:34 <Cale> salierix: Then you need to copy the spine of the structure from the top down to the bit which has changed, but everything else doesn't need to be touched.
14:56:48 <omnId> salierix: it's not as difficult as it first appears to be, it's actually pretty easy when you get used to how it works.
14:56:55 <EvilTerran> salierix, you know the idea of converting an iterative loop into a tail-recursive function where each variable that changes in the loop is represented by a parameter to the function?
14:56:58 <atom> hi everyone.
14:56:58 <dons> ?remember Heffalump (re the RealWorld# token) The compiler knows that it can implement the token using the  arrow of time
14:56:58 <lambdabot> It is forever etched in my memory.
14:57:15 <salierix> EvilTerran, Yeah...
14:57:20 <ddarius> instance Arrow Time
14:57:43 <Heffalump> instance Banana Fruit
14:57:43 <omnId> data Time a b = ???
14:57:47 <atom> How can I define a Range datatype that looks like (Integer, Integer)? I've tried data Range = (Integer, Integer) but it fails.
14:57:48 <EvilTerran> salierix, the State monad is a thin veneer over that concept
14:57:58 <dons> time flies like a monad
14:58:00 <omnId> Heffalump: Fruit Banana, more likely
14:58:01 <Cale> For example, if you want to write a function which "mutates" the nth element of a list, it will have to copy the first n-1 cons cells except the last one will have a new tail, consisting of the cons-cell with the new element followed by the original tail.
14:58:12 <mauke> atom: 'data' requires a constructor in each alternative
14:58:18 <Heffalump> no, time flies like an arrow, fruit flies like a banana
14:58:18 <Cale> So the last N-n elements of the list aren't copied.
14:58:34 <atom> mauke: um... in english?
14:58:52 <Cale> atom: data Range = R Integer Integer
14:58:58 <omnId> atom: data Range = Range (Integer, Integer) -- not the constructor on the rhs
14:59:02 <omnId> note*
14:59:05 <mauke> type Range = (Integer, Integer)
14:59:15 <omnId> ^ that's a type alias
14:59:22 <monochrom> @quote flies
14:59:22 <lambdabot> monochrom says:  Time flies like an arrow.  Fruit flies like a banana.  Syntax rules like a macro.
14:59:29 <Cale> mauke's option there using type doesn't really create a new type, just gives another name to an existing type
14:59:31 <omnId> Range and (Integer, Integer) would be interchangeable in that case.
14:59:43 <salierix> I'm also learning about ocaml...
14:59:43 <dons> time flies like a monad, fruit flies like uniqueness types
14:59:59 <omnId> dons: *rimshot*
15:00:18 <atom> ok... thanks. Maybe, in time, i'll actually understand all of this.
15:01:00 <ddarius> atom: That's not something you can put off.
15:01:01 <omnId> atom: the value (1, 2) has type (Integer, Integer).  You need to pass it into a constructor for your Range type to make it into a Range value.
15:01:38 <ddarius> atom: That said, any tutorial should have a decent explanation of what each of type, newtype, and data is?
15:01:42 <omnId> so with 'data Range = R (Integer, Integer)', the value 'R (1, 2)' has type 'Range'
15:02:23 <salierix> What's Haskell's performance like? Is ghc getting better over time or is the performance generally static?
15:02:40 <dons> it tends to get better by 10% or so each major release
15:02:50 <salierix> I remember hearing a few years ago that Haskell's performance was really bad.
15:02:54 <dons> with usually good jumps in library and parallelism support
15:02:58 <atom> ddarius: ok... I'll look it up. I should have already, I understand that. It's just so much easier to just ask.
15:03:00 <salierix> I see.
15:03:15 <dons> salierix: its typically 6 to 600x faster than python
15:03:21 <dons> and 1-4x slower than C
15:03:34 <dons> so pick which language you care about
15:03:59 <salierix> I do like the syntax though. Its purty.
15:04:09 <omnId> @where examples
15:04:09 <dons> sometimes it beats C, particularly for concurrent and parallel programs
15:04:09 <lambdabot> ghc, pugs, darcs, xmonad, lambdabot, yi, frag, house, hpaste (use @where+ to add more)
15:04:12 <dons> heh
15:04:13 <fasta> dons: does importing System.IO.Unsafe have any effect for the optimiser(even if you don't use any functions from it)?
15:04:14 <dons> cool
15:04:18 <omnId> ^ major stuff written in Haskell
15:04:36 <dons> fasta: not that i know of. sometimes imports can do strange things to really huge programs though
15:04:51 <Cale> salierix: It used to have kinda crappy performance, but that's changed dramatically over the past 10 years or so.
15:04:58 <Cale> Especially over the last few.
15:05:43 <salierix> So when are the draft chapters of that Haskell book coming out?
15:05:49 <ddarius> "It used to have kinda crappy performance 10 years ago."
15:05:52 <bos> salierix: in maybe a month
15:06:11 <ddarius> That said, I think the Pseudoknot benchmark was in '95 and GHC faired fairly well.
15:06:20 <ddarius> bos: Yay
15:06:20 <bos> salierix: we're working on a nov 15 deadline for half the book to be written, after that we'll revise a few early chapters and publish them
15:07:09 <salierix> Is it for people who already know Haskell?
15:07:19 <omnId> bos: do you have a ballpark for the whole book?  another 6 months?  You're of course free to say "no comment" :)
15:07:22 <bos> no, definitely not.
15:07:56 <bos> omnId: probably in the four to six month range for first drafts
15:08:24 <salierix> "Real World Haskell" sort of gave me that impression.
15:08:38 <salierix> The title I mean.
15:08:41 <bos> so far, we've been firing on two cylinders, but dons is starting to ramp up, which should improve our completion rate.
15:08:57 <bos> salierix: it's haskell for people who know how to program, but not necessarily in haskell.
15:09:03 <dibblego> nothing wrong with two cylinders!! (VTR1000F owner)
15:09:45 <bos> there are plenty of excellent intro to programming books already written with haskell as the language. bird, hutton, etc.
15:09:46 <salierix> I hope you have some interesting example programs.
15:10:10 <Pseudonym> Two cylinder vehicles are very economical.
15:10:18 <dibblego> mine isn't
15:10:21 <ddarius> Zero cylinders even more so.
15:10:24 <monochrom> Reduces CO2 emission :)
15:10:26 <Pseudonym> Indeed!
15:10:26 <dibblego> 2x48mm CV carburettors
15:10:40 <salierix> I hate programming books that just teach you the language and not how to actually do anything with it.
15:11:10 <monochrom> There is no such book.
15:11:38 <EvilTerran> the standards documents tend to be like that
15:11:56 <Pseudonym> Will RWH have a cookbook section?
15:11:59 <Pseudonym> Or is that volume 2?
15:12:05 <omnId> EvilTerran: which is good, that's not the place for it :)
15:12:14 <salierix> Most C++ books are like that actually.
15:12:26 <salierix> I think so at least.
15:12:37 <bos> Pseudonym: no cookbook section, though there will be bits of cookbookishness scattered throughout.
15:12:51 * Pseudonym nods
15:13:00 <monochrom> I am not sure standard documents teach anything. But let's say they teach you the language. Then they also teach you the criteria for a compliant implementation.
15:13:03 <Pseudonym> That's one thing that I found the most useful about "Programming Perl".
15:13:10 <ddarius> Next will be Complex World Haskell, followed by Quaternion World Haskell and finally Octonion World Haskell.
15:13:15 <bos> e.g. how to emulate multiway "if" using "case" is one useful tiplet i wrote just the other night.
15:13:24 <Pseudonym> (First edition, anyway; no idea what the latest revision is like.)
15:13:25 <bos> ddarius: category world haskell.
15:13:39 <Japsu> Is there a way to QuickCheck predicates of type a -> IO Bool?
15:13:42 <Pseudonym> There's no Rational World Haskell, unfortunately.
15:13:45 <fasta> bos: will it also contain something new?
15:13:53 <bos> fasta: something new?
15:13:55 <ddarius> Pseudonym: There is no Rational World silly.
15:14:03 <Pseudonym> But there is a RealWorld, true.
15:14:06 <fasta> bos: something that hasn't been blogged about?
15:14:26 <fasta> bos: or discussed on mailing lists or in articles or ...
15:14:30 <Pseudonym> So clearly Real World Haskell is the initial book.
15:14:40 <ddarius> fasta: Why would/should it?
15:14:42 <bos> fasta: we're not aiming to cover entirely new ground.
15:14:56 <fasta> ddarius: It was just a question.
15:15:05 <Pseudonym> (Unique up to isomorphism, anyway.)
15:15:59 <bos> fasta: it'll just be the first popular book that gathers together a few hundred of the things an effective haskell hacker already has stuffed into their head.
15:16:14 <omnId> salierix: I know of a blog post that doesn't really teach you much Haskell but gives a rough idea of some interesting, useful bits.  It seems to be down, I'll look for a cache.
15:16:15 <Pseudonym> Yes and no.
15:16:25 <Pseudonym> It's not going to have any of the theoretical things.
15:16:41 <dibblego> ?hoogle concatM
15:16:42 <lambdabot> Prelude.concatMap :: (a -> [b]) -> [a] -> [b]
15:16:45 <salierix> How what you write a machine emulator in Haskell? I could do so straightforwardly in an imperative language but I can't even imagine how to do something like that in a pure functional language like Haskell.
15:16:47 <fasta> bos: Non-trivial use of FFI?
15:16:49 <Pseudonym> It's not going to mention words like "algebra" and"free theorem".
15:16:56 <Pseudonym> salierix: Formally.
15:17:13 <Pseudonym> If you can come up with a formal model for it, you can execute the model directly in Haskell.
15:17:23 <mauke> salierix: http://mauke.ath.cx/stuff/haskell/hell.hs
15:17:23 <bos> Pseudonym: a few of the most directly usable theoretical nuggets, but no more
15:17:31 <mauke> salierix: that executes raw machine code in haskell
15:17:31 <omnId> salierix: someone wrote a Game Boy emulator.
15:17:41 <mauke> ACCEPT NO SUBSTITUTES
15:17:45 * Pseudonym wrote an SECD machine emulator after using Haskell for two months
15:17:48 <bos> fasta: depends on what you mean by non-trivial. if you're talking about foreign wrapper calls, c2hs, and that sort of thing, sure.
15:17:51 <Pseudonym> Well, Orwell.
15:18:00 <Pseudonym> But still, lazy functional.
15:18:03 <Cale> mauke: haha
15:18:13 <bos> but not e.g. interfacing to C++ or whatever.
15:18:28 <Cale> salierix: Haskell has low-level stuff too.
15:18:41 <Cale> salierix: You can do anything in IO which you could have done in C.
15:19:07 <Cale> It's just that usually you don't *want* to do it that way, since having a pure interface is so much easier to work with.
15:19:12 <Pseudonym> From what I can see, Real World Haskell is really going to concentrate on the awkward squad.
15:19:17 <omnId> salierix: that blog post I mentioned, Haskell IO for Imperative Programmers: http://web.archive.org/web/20070501220907/http://blogs.nubgames.com/code/?p=22
15:19:18 <dibblego> what's the typical way of taking a m [[a]] to a m [a] using concat? foldM?
15:19:19 <Cale> (With C, you have no option)
15:19:21 <lambdabot> Title: Nub Games  Haskell IO for Imperative Programmers, http://tinyurl.com/2w34ck
15:19:22 <salierix> omnId, and he says it runs at 10% real speed.
15:19:26 <Pseudonym> Which is what most imperative programmers are interested in.
15:19:34 <fasta> Pseudonym: oh, you have seen a preview probably?
15:19:39 <omnId> dibblego: liftM concat.
15:19:39 <Pseudonym> Yeah.
15:19:49 <dibblego> omnId, righto cheers
15:19:55 <Pseudonym> Over 150 people have, at last count.
15:19:57 <Pseudonym> :-)
15:20:03 <fasta> Yes, I guess it was better if I'd subscribed too.
15:20:18 <bos> fasta: it's never too late.
15:20:22 * Pseudonym is guessing that not everyone will get a complimentary copy
15:20:51 <fasta> dons: I ran about the same code and it shows about the same result.
15:21:05 <bos> i'll try to make sure we can send a free copy to everyone who's submitted substantial comments.
15:21:14 <omnId> salierix: I believe he wrote it to learn Haskell.  I'm not familiar enough with the domain to say how much, but I'm sure it could be faster.
15:22:13 <quicksilver> @seen ac
15:22:13 <lambdabot> ac is in #haskell. I last heard ac speak 5h 49m 5s ago.
15:22:33 <fasta> quicksilver: it runs now a 1000 times faster? ;)
15:22:49 <salierix> So what do functional languages have over imperative?
15:22:50 <Pseudonym> bos: I think most would be happy with an acknowledgement.
15:23:04 <bos> Pseudonym: yeah, we'll definitely be doing that, too.
15:23:11 <Pseudonym> salierix: First off, false dichotomy.
15:23:13 <bos> salierix: they go up to eleven.
15:23:19 <dibblego> salierix, permits a more disciplined method of programming
15:23:23 <bos> imperative languages only go up to ten.
15:23:29 <monochrom> many imperative languages lack streamlined higher-order functions.
15:23:29 <Pseudonym> Some don't even go to ten.
15:23:36 <Pseudonym> Java gets stuck around seven.
15:23:42 <Olathe> Machine code only goes up to one :(
15:23:47 <dibblego> Pseudonym, don't be so nice to Java
15:23:48 <monochrom> oh, many imperative languages lack first-class continuations too. :)
15:23:49 <bos> but when you need the extra bit of volume, you turn the IO knob and hey, eleven.
15:24:10 <fasta> Where do you pull your numbers from?
15:24:25 <Pseudonym> dibblego: The fact that people _have_ written medium-sized applications in Java suggests that it's useful despite itself.
15:24:26 <salierix> Couldn't you just make a better imperative language and make that the new 10?
15:24:27 <atom> @Num
15:24:27 <lambdabot> Maybe you meant: bug run
15:24:32 <bos> fasta: http://www.imdb.com/title/tt0088258/
15:24:33 <lambdabot> Title: This Is Spinal Tap (1984)
15:24:36 <Olathe> fasta: The integers.
15:24:42 <dibblego> Pseudonym, right, so 1 and not 0
15:24:42 <Pseudonym> The fact that those applications are pretty much all of the same type is also telling, of course.
15:24:53 <omnId> @instances Num
15:24:55 <monochrom> Haskell is quickly becoming the best imperative language. :)
15:24:57 <Pseudonym> dibblego, now hang on.
15:24:57 <lambdabot> Double, Float, Int, Integer
15:25:14 <Pseudonym> Of all of the third-generation languages out there, Java is one of the easiest to statically analyse.
15:25:33 <atom> omnId: um... In fact, I need to see which operators are supposed to be defined for Num
15:25:33 <Pseudonym> As such, it's a great way to test out new imperative compilation techniques.
15:25:46 <omnId> @src Num
15:25:46 <lambdabot> class  (Eq a, Show a) => Num a  where
15:25:46 <lambdabot>     (+), (-), (*)           :: a -> a -> a
15:25:46 <lambdabot>     negate, abs, signum     :: a -> a
15:25:46 <lambdabot>     fromInteger             :: Integer -> a
15:26:02 <Pseudonym> In fact, it's caused something of a renaissance in compiler research.
15:26:30 <Pseudonym> When a new imperative thing comes along, Java is usually the first imperative language it's applied to.
15:26:40 <dibblego> I find Java unbearable, despite knowing it inside-ou
15:26:41 <dibblego> ty
15:26:42 <Pseudonym> Where "thing" is "compiler thing", not "user-visible thing".
15:26:59 <salierix> Hm, erlang would be pretty cool if I have a 64 core processor...
15:27:00 <Pseudonym> Oh, I wouldn't try to write anything serious in it.
15:27:34 <atom> um... how do I define an operator on a new datatype? For instance, how do I define + on my new Range type? I can't find this in a tut anywhere...
15:27:39 <fasta> bos: Is it an expression from that movie?
15:27:42 <Pseudonym> salierix: Or a farm.
15:27:58 <sjanssen> atom: you need to write an instance of the Num class
15:28:08 <sjanssen> atom: look for the section on type classes in your tutorial
15:28:19 <atom> sjanssen: I can't define all the functions Num wants on my Range type
15:28:28 <atom> for instance, abs and fromint don't make any sense
15:28:34 <sjanssen> atom: then you can't use the + symbol
15:28:37 <bos> fasta: yes, it's one of the canonical expressions.
15:28:46 <omnId> atom: then it's not a Num type.  But you can cheat and say 'instance Num Range where abs = undefined'
15:28:59 <bos> fasta: your insight into nerd culture will be greatly endeepified if you watch that movie.
15:29:00 <sjanssen> atom: however, Haskell let's you make up your own operators:
15:29:06 <omnId> or abs = error "No abs for Ranges"
15:29:31 <sjanssen> > let (x, y) +! (a, b) = (x+a, y+b) in (1, 2) +! (10, 20)
15:29:33 <lambdabot>  (11,22)
15:29:39 <fasta> bos: I already know what 42 means by actually reading the books _and_ seeing the movie. That's enough for now ;)
15:29:42 <ddarius> Pseudonym: When new imperative things come along, Haskell is usually the first language it's applied to.
15:30:14 <dons> and new types and data structures
15:30:21 <Pseudonym> ddarius: I've never seen classic imperative optimisations applied to Haskell.
15:30:31 <Pseudonym> Or even new variations.
15:30:44 <Pseudonym> The stuff that's applied to Haskell is _really_ different.
15:31:01 <atom> sjanssen: ok... so now I've got something else to experiment with
15:31:02 <atom> :)
15:31:07 <Heffalump> Pseudonym: register allocation, peepholing
15:31:17 <dons> Pseudonym: yeah, that's what nr et al are working on, the ssa layer
15:31:21 <Pseudonym> Yeah.
15:31:24 <Pseudonym> So it's happening.
15:31:30 <sjanssen> atom: user defined operators are easy, they're just like functions
15:31:35 <ddarius> Pseudonym: Actually, depending on what you mean by "classic", I'm sure many of GHC's optimization are them, but yeah, I responded before reading "Where 'thing' is 'compiler thing'."
15:31:51 <ddarius> That said, Java is also a major testbed for many user-visible things.
15:32:07 <salierix> So if I want to learn Haskell, where can I start?
15:32:14 <ddarius> @where learning
15:32:14 <lambdabot> I know nothing about learning.
15:32:17 <ddarius> @where learn
15:32:17 <lambdabot> I know nothing about learn.
15:32:22 <bos> ha.
15:32:31 <atom> salierix: with a project :)
15:32:32 <fasta> Nowhere, apparently.
15:32:32 <omnId> haskell.org
15:32:32 <ddarius> salierix: Start at haskell.org.  Where to go from there will be obvious.
15:32:34 <mauke> @where tutorial
15:32:34 <lambdabot> http://www.haskell.org/tutorial/
15:32:37 <Pseudonym> Oh, BTW.  A great paper for those who understand SSA form: http://www.pllab.riec.tohoku.ac.jp/~matsu/SCP.pdf
15:32:47 <Pseudonym> Brilliant piece of work.
15:32:54 * Pseudonym just finished reading it
15:32:56 <mauke> salierix: you'll need a haskell implementation
15:33:09 <Pseudonym> It represents SSA form as type annotations without any code rewriting.
15:33:09 <omnId> salierix: getting started from the beginning: http://haskell.org/haskellwiki/Haskell_in_5_steps
15:33:10 <lambdabot> Title: Haskell in 5 steps - HaskellWiki
15:33:27 <Pseudonym> Which means that undoing the SSA transformation is trivial: delete the annotations.
15:33:29 <bos> Pseudonym: thanks for the pointer
15:33:36 <ddarius> Pseudonym: The name sounds familiar.  I probably read it when I first came across Atsushi Ohori's site.
15:33:39 <Pseudonym> Yeah.
15:33:56 <Pseudonym> I think there's a lot of cool research that could be done with that.
15:34:22 <dibblego> > intersperse ' ' []
15:34:23 <lambdabot>  ""
15:34:32 <Pseudonym> Many of the interesting old-school optimisations are simpler in SSA form.
15:34:47 <Cale> > intersperse ' ' "hello"
15:34:48 <lambdabot>  "h e l l o"
15:35:10 <Pseudonym> This paper strongly implies that most of them may have versions which are "type-preserving" in the SSA-form-is-a-type sense.
15:35:12 <omnId> > intersperse ", " (words "quick brown fox")
15:35:13 <lambdabot>  ["quick",", ","brown",", ","fox"]
15:35:19 <omnId> > concat $ intersperse ", " (words "quick brown fox")
15:35:20 <lambdabot>  "quick, brown, fox"
15:35:25 <Pseudonym> Which makes them a) easier to specify, and b) provably correct.
15:35:49 <Pseudonym> Nice stuff.
15:35:55 <mauke> there's a subtle difference between "provably correct" and "probably correct"
15:36:09 <Pseudonym> Yeah.
15:36:12 <Pseudonym> This is "probably correct".
15:36:25 <omnId> mauke: what a difference a voiced consonant makes!
15:36:37 <monochrom> SSA is provably correct. RSA is probably correct. That's one of the subtle differences. :)
15:36:38 <Pseudonym> Because if you represent liveness in types, then any type-correct transformation preserves the "meaning" of variable liveness.
15:36:54 <salierix> Is Haskell Prime going to introduce major changes?
15:36:58 <Pseudonym> Dead code elimination, for example, if it's type-correct, never eliminates live code.
15:37:14 <ddarius> salierix: Not if it never gets finished.
15:37:54 <monochrom> Oh! October 31 is today!
15:38:01 <Pseudonym> monochrom: No it's not.
15:38:05 <Pseudonym> It's November 1.
15:38:10 <Pseudonym> ?local-time Pseudonym
15:38:11 <lambdabot> Local time for Pseudonym is Thu Nov  1 09:38:10 2007
15:38:14 <Pseudonym> See?
15:38:18 <omnId> it's Dec 25.
15:38:28 <mauke> living in the future must be nice
15:38:42 <ddarius> Do they have flying cars there?
15:38:45 <fasta> mauke: he could also be living in the past.
15:38:50 <idnar> decimal 25
15:38:55 <dons> ?time dons
15:38:59 <lambdabot> Local time for dons is Wed Oct 31 15:38:56 2007
15:39:05 <LoganCapaldo> In teh distant future, in a world after Halloween, Pseudonym walks the earth
15:39:06 <dons> argh, i'm trapped in the past now!
15:39:13 <EvilTerran> @yow
15:39:13 <lambdabot> BI-BI-BI-BI-BI-BI-BI-BI-BI-BI-BI-BI-BI-BI-BI-BI-BI-BI-BI-BI-BI-BI-BI-BI-
15:39:21 <dons> what month is it? Nov? and they lock me away
15:39:31 <Pseudonym> BTW, in Australia, Halloween isn't a big deal.
15:39:39 <dons> its quite scary here
15:39:43 <Pseudonym> It's Spring, and it's daylight savings time.
15:39:47 <Pseudonym> There's no bloody point.
15:39:54 <dons> SyntaxNinja is dressed as an evil crow today
15:39:59 <Pseudonym> Oh.
15:40:04 * fasta is glad GHC doesn't come with "easter eggs" like drscheme
15:40:04 <dons> its quite distressing for the engineers
15:40:08 <Pseudonym> That is a bit disturbing.
15:40:51 <bos> everybody loves SSA. gcc finally acquired it relatively recently, though they don't seem to know what to do with it. it's one of the main IRs used by LLVM and open64, too.
15:40:59 <Pseudonym> Yeah.
15:41:00 <monorobot> <-- That's my Halloween costume tonight! :)
15:41:11 <Pseudonym> GCC still doesn't have colouring register allocation, though, does it?
15:41:13 <Igloo> dons: JPG!
15:41:57 <ddarius> It's the main language of the GHC frontend too.
15:42:13 <fasta> Pseudonym: it doesn't? Wow.
15:42:20 <bos> Pseudonym: the chaitin patent only expired a little over a year ago
15:42:41 <bos> Pseudonym: and gcc typically takes 10 or 15 years to catch up with the latest technology.
15:42:42 <monorobot> patents are evil
15:42:56 <fasta> There is a patent on using graph colouring for register allocation!?!?!
15:43:03 <Pseudonym> There _was_.
15:43:09 <fasta> Insanity
15:43:13 <bos> fasta: it's a very famous patent. pissed a *lot* of people off.
15:43:15 <atom> ok, so I'm trying to create a +! operator on my Range datatype that is defined as such: data Range = Range (Integer, Integer).
15:43:32 <Pseudonym> It wouldn't have happened has Chaitin not worked for IBM at the time, I suspect.
15:43:52 <dibblego> IBM is evil
15:43:56 <fasta> It seems that when something has a practical applications, it suddently gets patented.
15:44:17 <fasta> Which is quite an odd thing, since the algorithm worked all the time for other cases too.
15:44:18 <atom> (Range a b) +! (Range c d) = Range (a+c, b+d) doesn't work, as doesn't (Range (a, b)) +! (Range (c, d)) = Range (a+c, b+d)
15:44:20 <ddarius> Why patent things with no application?
15:44:23 <Pseudonym> The idea of using NP-hard problems dates back to the 70s.
15:44:31 <Pseudonym> ddarius: You've never worked for a start up.
15:44:39 <omnId> atom: the datatypes on the lhs are malformed
15:44:40 <sjanssen> atom: how does the second one fail?
15:44:40 <mauke> atom: how does it not work?
15:44:41 <Pseudonym> You patent things so that the business has assets.
15:44:49 <monorobot> Actually, everything gets patented. Then some of them turns out to be useful, and then you find out it is patented.
15:45:06 <bos> startups don't patent much because they don't have time. it's mostly big companies that file patents.
15:45:07 <fasta> If OTOH, they invented graph colouring as a solution for that problem, then it might be considered for patenting, imho.
15:45:08 <atom> ok, now it worked.
15:45:23 <atom> and that's weird.
15:45:25 <fasta> But that's not how it worked.
15:45:30 <sjanssen> atom: the first is incorrect because you've got "Range (Integer, Integer)", so (x,y) is required in the pattern match
15:45:31 <Pseudonym> bos: IME, it's both.
15:45:31 <atom> because it didn't the last time
15:45:42 <Pseudonym> But it's the startup patents that get bought by trolls.
15:45:55 <Pseudonym> And the big business patents that stay with big businesses.
15:46:01 <atom> sjanssen: I thought so, so I tried teh 2nd form, and it failed to load... I must have had a typo somewhere else at the time probably.
15:46:21 <atom> otherwise it would have worked, and I'm sure that's what I've written before as well.
15:46:25 <omnId> atom: did you check which line and error message it said at the time :)
15:46:29 <sjanssen> atom: also, it's generally considered better to write "data Range = Range Integer Integer"
15:46:37 <fasta> There are so many patents that nobody can be aware of them.
15:46:56 <fasta> I also don't know anyone that actively reads patents to learn from them.
15:47:01 <atom> sjanssen: ok. Still interested to know why though
15:47:05 <Pseudonym> Anyway, I think it was Bill Wulf who pointed out in his PhD thesis that register allocation can be understood as a knapsack problem.
15:47:19 <EvilTerran> atom, the first version you had there would work if Range were specified as "data Range = Range Integer Integer"
15:47:20 <Pseudonym> It seems to me that graph colouring is a trivial extension of that.
15:47:39 <sjanssen> atom: it's just common style.  The tuples force you to add extra parens and commas all over the place
15:47:49 <EvilTerran> atom, ...which is more idiomatic approach, depending on style
15:47:50 <omnId> atom: sjanssen's makes a new datatype with two fields;  yours, a datatype with one field, itself a datatype with two fields.
15:47:56 * raxas just wanders, how many haskell researchers working at microsoft payroll do patent their stuff
15:48:02 <EvilTerran> nach, beaten to the punch by sjanssen. never mind.
15:48:09 <salierix> Should I download version 6.6.1 of ghc or a more recent snapshot?
15:48:09 <fasta> Another problem is that universal intelligence has already been discovered, which subsumes any specific invention.
15:48:17 <atom> ok. thanks.
15:48:51 * ddarius would write data Range = Range !Integer !Integer
15:49:14 <fasta> The only things that might be worth patenting then are things that are not computable.
15:49:21 * omnId doesn't worry about strictness when learning.
15:49:56 <ddarius> EvilTerran: Actually his first version wouldn't have worked with that type either.
15:50:10 <fasta> Or not recognizable as such, for example a design of a nice bridge ;)
15:50:20 <omnId> Range a b +! Range c d = Range (a+c) (b+d) -- this would
15:50:23 <EvilTerran> ah, because of the tuple on the RHS, yes
15:50:30 <monorobot> salierix: since you're just beginning, there is no need to get the most recent. There is only need to get the most supported. That is 6.6.1 for now.
15:51:04 <ddarius> Is 6.8 ever going to be released?
15:51:21 <fasta> ddarius: Yes, together with Duke Nukem Forever
15:51:23 <monorobot> OTOH if you bet on 6.8.1 coming out very soon, a recent snapshot is preferrable since it's closer to the eventual 6.8.1.
15:51:31 <bos> ddarius: have you sacrificed your goat yet?
15:51:53 * ddarius doesn't have a goat.  SOL, I guess.
15:52:37 <monorobot> Duke Nukem is a cool name. :)
15:53:06 <LoganCapaldo> Nuke Dukedom
15:53:57 <monorobot> Duke Nukem would not be very pleased if you nuked his Dukedom. :)
15:54:34 * omnId nukes Duke Nukem's Dukedom.
15:55:11 <LoganCapaldo> hey
15:55:15 <LoganCapaldo> here's a thought
15:55:17 <EvilTerran> but it's not ready yet!
15:55:34 <Olathe> LoganCapaldo: That was a nicely recursive thought.
15:55:36 <augustss> raxas: none
15:55:53 <LoganCapaldo> why do you need the let keyword in do block definitions
15:56:18 <ddarius> Why do you need the let keyword at all?
15:56:24 <LoganCapaldo> would there be any insurmountable problems if the syntax allowed for do { x = 1; } ?
15:56:26 <augustss> LoganCapaldo: to make it look like BASIC
15:56:35 <monorobot> hahahaha BASIC
15:56:54 <Olathe> x <- 1 is a nice way to do that, but it doesn't work with functions.
15:57:09 <EvilTerran> LoganCapaldo, mutually recursive bindings?
15:57:29 <augustss> LoganCapaldo: people thought do { x = 1 } didn't have enough syntactic clues.  I think it's fine.
15:57:44 <LoganCapaldo> augustss: ah thanks.
15:57:49 <augustss> It was considered
15:58:02 <fasta> let is just noise
15:58:22 <omnId> do { let { evens = 0 : map (+1) odds; odds = map (+1) evens } ; return evens }
15:58:26 <EvilTerran> > let y = 1 in do { let { x = y }; let { y = x }; [x,y] }
15:58:27 <lambdabot>  [1,1]
15:58:34 <EvilTerran> > let y = 1 in do { let { x = y; y = x }; [x,y] }
15:58:35 <lambdabot>  Exception: <<loop>>
15:59:14 <LoganCapaldo> Assuming ti was legal syntax I don't see how that's a problem do { x = y ; y = x ; [x, y] }
15:59:31 <Olathe> > do { x <- 1; x }
15:59:31 <EvilTerran> LoganCapaldo, which would it mean, though?
15:59:32 <omnId> LoganCapaldo: where do you delimit the binding groups?
15:59:32 <lambdabot>   add an instance declaration for (Show (t t1))
15:59:36 <Olathe> :(
15:59:40 <fasta> augustss: who can we blame for the existence of let?
16:00:00 <LoganCapaldo> you could always use let ... in ... if you needed to make it smaller
16:00:05 <omnId> fasta: in general?
16:00:10 <IAW1939>  > let check xs ys = length (filter (id) (zipWith (==) xs ys)) in check [12,2,2][2,3,3,4]
16:00:12 <oerjan> let wasn't in the original haskell iirc
16:00:13 <ddarius> Peter Landin?
16:00:22 <fasta> omnId: no in H98
16:00:27 <atom> @src Num
16:00:27 <lambdabot> class  (Eq a, Show a) => Num a  where
16:00:27 <lambdabot>     (+), (-), (*)           :: a -> a -> a
16:00:27 <lambdabot>     negate, abs, signum     :: a -> a
16:00:27 <lambdabot>     fromInteger             :: Integer -> a
16:00:41 <IAW1939> > let check xs ys = length (filter (id) (zipWith (==) xs ys)) in check [12,2,2][2,3,3,4]
16:00:43 <lambdabot>  0
16:00:48 <monorobot> Hahaha, Peter Landin to be blamed for let. :)
16:00:49 <augustss> fasta: for 'let' in a 'do' block I can't remember, but trawl the old mail archieves
16:00:53 <IAW1939> > let check xs ys = length (filter (id) (zipWith (==) xs ys)) in check [12,3,2][2,3,3,4]
16:00:55 <lambdabot>  1
16:01:16 <fasta> augustss: and let in general outside do blocks?
16:01:22 <IAW1939> hey guys i worte this checking function above, but what does id do?
16:01:31 <ddarius> @src id
16:01:32 <lambdabot> id x = x
16:01:34 <augustss> fasta: it's quite old.  Maybe Landin
16:01:39 <IAW1939> i know it is a identity function
16:01:42 <augustss> fasta: long before Haskell
16:01:49 <fasta> augustss: did anyone oppose it?
16:01:56 <Igloo> It would be a bit ugly if recursive binding groups were only delimited by p<-e statements
16:01:58 <ddarius> And the parens around id are completely superfluous.
16:02:00 <mauke> @unpl length (filter (id) (zipWith (==) xs ys))
16:02:00 <lambdabot> length (filter (\ a -> a) (zipWith (==) xs ys))
16:02:03 <IAW1939> but what does it do in my function
16:02:17 <ddarius> IAW1939: The same thing it does everywhere.
16:02:19 <augustss> fasta: hmmm, Arvind might have opposed it.  Id didn't have it
16:02:25 <IAW1939> ???
16:02:27 <ddarius> IAW1939: If you wrote the function, don't you know what it does?
16:02:36 <omnId> IAW1939: it filters to just the Trues.
16:02:59 <omnId> > filter id [True, False, True, True, False]
16:03:00 <lambdabot>  [True,True,True]
16:03:03 <IAW1939> i used the where function when i wirote it first but someone told me id could be used
16:03:18 <omnId> "the where function"?
16:03:20 <ddarius> There is no where function
16:03:27 <IAW1939> ok
16:03:33 <IAW1939> why only Trues
16:03:34 <IAW1939> ???
16:03:48 <omnId> uh, because that's what filter does?
16:03:49 <ddarius> IAW1939: What does filter do?
16:03:50 <oerjan> @src filter
16:03:50 <lambdabot> filter _ []     = []
16:03:50 <lambdabot> filter p (x:xs)
16:03:50 <lambdabot>     | p x       = x : filter p xs
16:03:50 <lambdabot>     | otherwise = filter p xs
16:03:57 <Olathe> Yay filter !
16:04:01 <kscaldef> IAW1939: how did you end up writing this function if you have no idea what it does or how?
16:04:11 <LoganCapaldo> trial and error
16:04:21 <LoganCapaldo> type system is good for that :)
16:04:24 <IAW1939> but can't filter, filter false ???
16:04:41 <oerjan> > filter not [True, False, True, True, False]
16:04:42 <lambdabot>  [False,False]
16:04:42 <LoganCapaldo> @type filter
16:04:44 <lambdabot> forall a. (a -> Bool) -> [a] -> [a]
16:04:50 <omnId> > filter (\b -> b == False) [True, False, True, True, False]
16:04:51 <lambdabot>  [False,False]
16:04:57 <Olathe> > map not [True, False, True, True, False]
16:04:58 <lambdabot>  [False,True,False,False,True]
16:04:59 <kscaldef> filter removes the elements for which the predicatae is false, and keeps those for which is it true
16:05:02 <Olathe> > map id [True, False, True, True, False]
16:05:03 <lambdabot>  [True,False,True,True,False]
16:05:07 <omnId> it happens that (\b -> b == False) is the same as (not)
16:05:26 <Olathe> It gets rid of the elements that map to False.
16:05:30 <IAW1939> filter id [False, True, True ]
16:05:36 <IAW1939> > filter id [False, True, True ]
16:05:37 <lambdabot>  [True,True]
16:05:38 <monorobot> kscaldef: Did you know that most programs come about by Natural Selection, not Intelligent Design? :)
16:05:41 <Olathe> > map id [False, True, True]
16:05:43 <lambdabot>  [False,True,True]
16:05:44 <oerjan> and (\b -> b == True) is the same as (id)
16:05:49 <IAW1939> > filter not [False, True, True ]
16:05:50 <Olathe> Note that the last two map to True.
16:05:51 <lambdabot>  [False]
16:05:53 <kscaldef> monorobot: only too well :-(
16:06:04 <Olathe> > map not [False, True, True]
16:06:05 <lambdabot>  [True,False,False]
16:06:08 <IAW1939> > length (filter not [False, True, True ])
16:06:10 <lambdabot>  1
16:06:13 <IAW1939> ok
16:06:16 <IAW1939> thanks
16:06:20 <Olathe> Note that the first maps to True, so it's the only thing left after filter.
16:06:28 <IAW1939> just understand
16:06:41 <IAW1939> n00b recommended me to this site
16:06:42 <omnId> if you have a list of xs, filter not gives you those xs where (not x) is True.
16:06:45 <IAW1939> it really helps
16:06:50 <Olathe> > map even [1..5]
16:06:51 <lambdabot>  [False,True,False,True,False]
16:06:57 <Olathe> > filter even [1..5]
16:06:59 <lambdabot>  [2,4]
16:07:29 <IAW1939> length (map even [1..5])
16:07:29 <omnId> in general, filter f xs gives you the xs where (f x) is True.
16:07:33 <IAW1939> > length (map even [1..5])
16:07:34 <lambdabot>  5
16:07:50 <Olathe> > length (filter even [1..5])
16:07:51 <lambdabot>  2
16:08:13 <omnId> > filter isUpper "A Man, a Plan, Panama!"
16:08:14 <lambdabot>  "AMPP"
16:08:14 <oerjan> @free length
16:08:15 <lambdabot> length = length . $map f
16:08:43 <IAW1939> >length (map id [1..5])
16:08:49 <IAW1939> > length (map id [1..5])
16:08:50 <lambdabot>  5
16:09:00 <Olathe> @check length (map _ xs) == length xs
16:09:00 <lambdabot>  Parse error in expression at end of input
16:09:03 <Olathe> Doesn't work :(
16:09:04 <omnId> map id x = id x = x
16:09:11 <omnId> > length [1..5]
16:09:12 <oerjan> IAW1939: that @free theorem tells that using map before taking length does nothing
16:09:13 <lambdabot>  5
16:09:13 <LoganCapaldo> You couldn't have  a class with a method churchEncode such that for Either a b it would be either, for Maybe a it would be maybe, etc. could you?
16:09:35 <IAW1939> length [1...5]
16:09:40 <Olathe> @help free
16:09:40 <lambdabot> free <ident>. Generate theorems for free
16:09:45 <omnId> LoganCapaldo: maybe an MPTC
16:09:47 <Olathe> @free map
16:09:48 <lambdabot> g . h = k . f => $map g . map h = map k . $map f
16:09:58 <IAW1939> >length (map even [1..5])
16:10:04 <IAW1939> > length (map even [1..5])
16:10:05 <lambdabot>  5
16:10:16 <ddarius> LoganCapaldo: With type families or a lot of cleverness possibly.
16:10:30 <IAW1939> > length (filtter even [1..5])
16:10:30 <lambdabot>   Not in scope: `filtter'
16:10:31 <omnId> class Church type encoding | type -> encoding where churchify :: type -> enconding
16:10:40 <IAW1939> > length (filterer even [1..5])
16:10:41 <lambdabot>   Not in scope: `filterer'
16:10:44 <IAW1939> > length (filter even [1..5])
16:10:46 <lambdabot>  2
16:10:53 <dibblego> > map even [1..5]
16:10:54 <lambdabot>  [False,True,False,True,False]
16:11:04 <monorobot> I suggest renaming churchify to baptise or baptize :)
16:11:19 <IAW1939> > map even [1..5]
16:11:20 <lambdabot>  [False,True,False,True,False]
16:11:28 <dibblego> ?check \xs f -> length xs == length(map f (xs :: [Int]))
16:11:28 <lambdabot>  Add a type signature
16:11:31 <omnId> instance Church Nothing (b -> (a -> b) -> a -> b)
16:11:35 <dibblego> ?check \xs f -> length xs == length(map (f :: Int -> Int) (xs :: [Int]))
16:11:37 <lambdabot>  OK, passed 500 tests.
16:11:37 <omnId> s/Nothing/Maybe/
16:11:45 <IAW1939> > filer id (map even [1..5])
16:11:46 <lambdabot>   Not in scope: `filer'
16:11:51 <IAW1939> > filter id (map even [1..5])
16:11:52 <lambdabot>  [True,True]
16:12:00 <omnId> hrm, Church is not kind-polymorphic...
16:12:06 <IAW1939> > length (filter id (map even [1..5]))
16:12:07 <lambdabot>  2
16:12:20 <sjanssen> omnId: should it be?
16:12:44 <omnId> sjanssen: I don't know how you could instance Maybe and Either, for example.
16:12:54 <IAW1939> >  filter (==) [1..5]
16:12:55 <lambdabot>  Couldn't match expected type `Bool'
16:13:00 <oerjan> omnId: Typeable has corresponding Typeable1 etc. iirc
16:13:03 <IAW1939> >  filter (==2) [1..5]
16:13:04 <lambdabot>  [2]
16:13:04 <sjanssen> omnId: instances should fully apply type variables, eg. "instance Church (Maybe a) ..." "instance Church (Either a b) ..."
16:13:25 <raxas> augustss: hmm, and what about us patent #7249333 "Quantified boolean formula (QBF) solver" it even contains haskell code in the patent document
16:13:54 <IAW1939> > [1..5]
16:13:55 <lambdabot>  [1,2,3,4,5]
16:14:12 <omnId> sjanssen: right.
16:14:17 <IAW1939> > filter ([1..5]) `mod` == 0
16:14:17 <lambdabot>  Parse error at "==" (column 23)
16:14:22 <Olathe> Does Haskell strictly separate Church from State ? ;)
16:14:24 <IAW1939> > ([1..5]) `mod` == 0
16:14:25 <lambdabot>  Parse error at "==" (column 16)
16:15:02 <ddarius> IAW1939: What are you expecting that to mean?
16:15:09 <omnId> not sure what such a class would win you.
16:15:20 <oerjan> IAW1939: list comprehensions may be easier for that, or a lambda
16:15:21 <IAW1939> nothing
16:15:24 <EvilTerran> IAW1939, your lexemes seem to be in the wrong order
16:15:43 <IAW1939> even numbers are equal 0 when moded
16:15:48 <oerjan> > [x | x <- [1..5], x `mod` 2 == 0]
16:15:49 <lambdabot>  [2,4]
16:15:55 <omnId> > filter even [1..5]
16:15:56 <lambdabot>  [2,4]
16:16:04 <omnId> > filter (\x -> x `mod` 2 == 0) [1..5]
16:16:05 <lambdabot>  [2,4]
16:16:20 <EvilTerran> IAW1939, when "(`mod`2)ed", not just "`mod`ed"
16:16:21 <omnId> filter takes a function and a list.
16:16:26 <IAW1939> i was trying to find another way of doing it except those
16:16:26 <oerjan> > filter ((==0).(`mod` 2)) [1..5]
16:16:28 <lambdabot>  [2,4]
16:16:36 <IAW1939> ok
16:16:48 <dcoutts> fox86: yes, gtk2hs comes with cairo
16:16:50 <augustss> raxas: who's on the patent application?  Simon or Simon?
16:16:51 <EvilTerran> > x <- [1..5]; guard (even x); return x
16:16:51 <lambdabot>  Parse error at "<-" (column 3)
16:16:54 <EvilTerran> > do x <- [1..5]; guard (even x); return x
16:16:56 <lambdabot>  [2,4]
16:16:58 <Olathe> @unpl even
16:16:58 <lambdabot> even
16:17:03 <Olathe> @unpl id
16:17:04 <lambdabot> (\ a -> a)
16:17:08 <Olathe> Okey dokey.
16:17:10 <omnId> @src even
16:17:10 <lambdabot> even n = n `rem` 2 == 0
16:17:12 <EvilTerran> even x = odd (x-1) :P
16:17:18 <EvilTerran> odd x = even (x-1)
16:17:22 <raxas> augustss: Yu; Yuan (Cupertino, CA), Zhang; Lintao (Sunnyvale, CA)
16:17:26 <Olathe> I know, but it's weird to expand id.
16:17:37 <ddarius> EvilTerran: With even 0 = True that would work.
16:17:57 <monorobot> That's sweet, some patent application contains Haskell code.
16:17:59 <ddarius> Olathe: id is one of the combinators pl uses.
16:18:00 <EvilTerran> ddarius, well, for positive numbers, i guess. it'd still be a rather silly definition
16:18:00 <Olathe> Until you did even (-1)
16:18:05 <LoganCapaldo> this is getting OT sort of but are there languages out there that let you play with  anonymous types? (type lambdas?).
16:18:20 <ddarius> LoganCapaldo: Yes.
16:18:28 <eventualbuddha> EvilTerran: even = not . odd, odd = not . even  ?
16:18:41 <EvilTerran> eventualbuddha, but that's not even approximating useful..
16:18:43 <monorobot> Newbie: "Is Haskell ever used in real world applications?"  #haskell: "Yes, in fact patent applications too! See #7249333 ..."
16:18:43 <EvilTerran> .
16:18:47 <IAW1939> >  filter (\x -> x `mod` 2 == 0) [1..5]
16:18:48 <lambdabot>  [2,4]
16:19:03 <EvilTerran> monorobot, patents clearly having nothing to do with the real world...
16:19:04 <IAW1939> why the slash at beginning of x
16:19:05 <omnId> eventualbuddha: you could have one or the other, but together they loop.
16:19:11 <IAW1939> lambda calc
16:19:14 <IAW1939> ??
16:19:16 <omnId> IAW1939: yes
16:19:16 <monorobot> It's just for the laugh :)
16:19:23 <eventualbuddha> omnId: yes, it was a joke :)
16:19:26 <IAW1939> ok
16:19:30 <augustss> raxas: they are not Haskell researcher employed by Microsoft
16:19:32 <EvilTerran> IAW1939, (\ x y z -> ...) = (let f x y z = ... in f)
16:19:51 <augustss> raxas: There are only two, maybe three of those
16:19:59 <ddarius> EvilTerran: For f not free in ...
16:20:08 <EvilTerran> (alpha-converting appropriately to make it a safe substitution)
16:20:38 <eventualbuddha> @src mod
16:20:38 <lambdabot> Source not found. Where did you learn to type?
16:20:42 <ddarius> > let f f = f in f 3
16:20:43 <lambdabot>  3
16:20:47 <oerjan> @src Integral
16:20:47 <lambdabot> class  (Real a, Enum a) => Integral a  where
16:20:47 <lambdabot>     quot, rem, div, mod :: a -> a -> a
16:20:47 <lambdabot>     quotRem, divMod     :: a -> a -> (a,a)
16:20:47 <lambdabot>     toInteger           :: a -> Integer
16:21:03 <omnId> Int and Integer mod is primitive
16:21:06 <Olathe> @src (+)
16:21:06 <IAW1939> what are overloaded functions ???
16:21:06 <lambdabot> Source not found. Have you considered trying to match wits with a rutabaga?
16:21:24 * EvilTerran noticed recently that a recursive function can be turned into a fix-able function by writing "foo foo x = ..." instead of "foo x = ..."
16:21:40 <monorobot> Yes, good observation.
16:21:41 <LoganCapaldo> http://www.cs.uu.nl/wiki/Ehc/LanguageFeatures <-- good choice for fiddling with type lambdas?
16:21:43 <lambdabot> Title: Ehc / Language Features
16:21:49 <EvilTerran> well, unless they're mutually-recursive
16:21:56 <omnId> IAW1939: please use one question mark.  An overloaded function is one name that' s used for different functions of different types.
16:22:03 <omnId> @type abs
16:22:04 <lambdabot> forall a. (Num a) => a -> a
16:22:12 <omnId> > abs (-3 :: Int)
16:22:13 <lambdabot>  3
16:22:17 <omnId> > abs (-3 :: Double)
16:22:18 <lambdabot>  3.0
16:22:27 <oerjan> > abs (-3 :: Rational)
16:22:28 <omnId> > abs (-3 :: Complex Float)
16:22:28 <lambdabot>  3%1
16:22:29 <lambdabot>  3.0 :+ 0.0
16:22:35 <Olathe> > abs (-3 :: Natural)
16:22:36 <lambdabot>   Not in scope: type constructor or class `Natural'
16:23:36 <EvilTerran> Olathe, you seem to be thinking of a different langauge
16:23:42 <omnId> the type 'forall a. (Num a) => a -> a' means the type 'a -> a', where 'a' is any type that has an instance of the Num class.
16:25:03 <omnId> "forall a."  Any type 'a', "(Num a) =>"  the 'a' type must be in the Num class, "a -> a" the type of the abs function.
16:26:08 <omnId> 'a -> a' means a functions that takes a thing, and returns something of the same type.
16:26:15 <omnId> @type abs (undefined :: Int)
16:26:17 <lambdabot> Int
16:26:22 <omnId> takes an Int, returns an Int
16:26:57 <raxas> augustss: I really don't care, for there are no validity of software patents in my country, but still it is scary somewhere out there Microsoft can get patents on trivial math logic
16:27:08 <Cale> EvilTerran: heh, that's a nice trick
16:27:29 <Cale> EvilTerran: (shadowing the name of the current function like that)
16:27:49 <EvilTerran> ty :)
16:28:00 * bos played a bit with takusen the other day. it's very cute, but the long shadow of oleg hangs heavy over it.
16:28:37 <IAW1939> > map id () [True,False,False]
16:28:38 <lambdabot>  Couldn't match expected type `[a]' against inferred type `()'
16:28:44 <IAW1939> > map id  [True,False,False]
16:28:45 <lambdabot>  [True,False,False]
16:29:00 <IAW1939> why am i getting back everything
16:29:03 <IAW1939> ???
16:29:23 <omnId> because map applies a function to each element, id doesn't change anything.
16:29:28 <omnId> @src id
16:29:28 <lambdabot> id x = x
16:29:34 <IAW1939> > filter id [True,False,True]
16:29:35 <lambdabot>  [True,True]
16:29:37 <Olathe> IAW1939: map and filter are different.
16:29:40 <omnId> map f [x, y, z] = [f x, f y, f z]
16:30:13 <IAW1939> > map 2 [2,2,2]
16:30:14 <lambdabot>   add an instance declaration for (Num (a -> b))
16:30:15 <Cale> > map id "Hello"
16:30:17 <lambdabot>  "Hello"
16:30:24 <Cale> > map toUpper "Hello"
16:30:25 <lambdabot>  "HELLO"
16:30:31 <ddarius> @pl map id
16:30:32 <lambdabot> id
16:30:33 <Cale> > map isUpper "Hello"
16:30:35 <lambdabot>  [True,False,False,False,False]
16:30:37 <Olathe> > map even "Hello"
16:30:37 <omnId> IAW1939: 2 is not a function.
16:30:38 <lambdabot>   add an instance declaration for (Integral Char)
16:30:38 <Cale> > filter isUpper "Hello"
16:30:40 <lambdabot>  "H"
16:30:46 <IAW1939> > filter toUpper "hello"
16:30:47 <lambdabot>  Couldn't match expected type `Bool' against inferred type `Char'
16:30:56 <IAW1939> > filter =isUpper "hello"
16:30:56 <lambdabot>  Parse error at "=isUp..." (column 8)
16:31:00 <LoganCapaldo> toUpper is not a function of the right type
16:31:00 <Cale> filter :: (a -> Bool) -> [a] -> [a]
16:31:06 <Cale> map :: (a -> b) -> [a] -> [b]
16:31:08 <IAW1939> > filter isUpper "hello"
16:31:10 <lambdabot>  ""
16:31:18 <Cale> IAW1939: do you understand those type signatures?
16:31:18 <sclv> :t toUpper
16:31:19 <lambdabot> Char -> Char
16:31:30 <sclv> > map toUpper "hello"
16:31:30 <Cale> IAW1939: I think they explain things fairly well.
16:31:31 <augustss> raxas: I think it's scary too.  But you asked how many Microsoft Haskell researchers there are patenting things.  And I don't think there are any.
16:31:31 <lambdabot>  "HELLO"
16:31:47 <omnId> > filter isUpper "and then she READ the PLEDGE of ALLEGIENCE!"
16:31:48 <lambdabot>  "READPLEDGEALLEGIENCE"
16:31:52 <augustss> raxas: Unless you count Erik Meijer.  He has a ton of trivial patents
16:31:54 <atom> @src Show
16:31:54 <lambdabot> class  Show a  where
16:31:54 <lambdabot>     showsPrec :: Int -> a -> ShowS
16:31:54 <lambdabot>     show      :: a   -> String
16:31:54 <lambdabot>     showList  :: [a] -> ShowS
16:31:59 <IAW1939> ok
16:32:23 <sclv> @src isUpper
16:32:24 <lambdabot> Source not found. The more you drive -- the dumber you get.
16:32:25 <omnId> @src ShowS
16:32:26 <lambdabot> type ShowS = String -> String
16:32:38 <omnId> atom: so showsPrec has type Int -> a -> String -> String
16:33:06 <Olathe> filter isUpper @yow
16:33:17 <IAW1939> map returns the result after applying the function while filter just simply check the condition with the input
16:33:35 <omnId> @@ @run filter isUpper @show @yow
16:33:36 <atom> omnId: cool. I just need to overload the show function for my own datatype :)
16:33:42 <oerjan> Olathe: unfortunately @@ is broken in public
16:33:45 <atom> omnId: I think I pretty much got how that's done
16:33:50 <oerjan> omnId too
16:33:58 <omnId> Olathe: the lb command I gave works in /msg :)
16:34:11 <IAW1939> can a function be written for putStr
16:34:16 <oerjan> @show test
16:34:16 <omnId> 19:38 <omnId> @@ @run filter isUpper @show @yow
16:34:16 <lambdabot> "test"
16:34:17 <omnId> 19:38 <!lambdabot>  "HPOLYVINYLCHLORIDE"
16:34:23 <IAW1939> :t putStr
16:34:23 <Cale> IAW1939: hm?
16:34:24 <lambdabot> String -> IO ()
16:34:28 <Olathe> omnId: Ahh :)
16:34:34 <IAW1939> @s putStr
16:34:34 <lambdabot> Maybe you meant: scheck seen shootout show slap source spell spell-all src . ? @ v
16:34:34 <Cale> IAW1939: You can write putStr given putChar
16:34:47 <Cale> IAW1939: at some point, it needs to be a primitive though :)
16:34:49 <Olathe> IONLYTDYINGOYSTERS
16:34:54 <IAW1939> ok
16:34:59 <IAW1939> what about the IO
16:35:33 <Cale> Well, values of type (IO t) are descriptions of actions which if carried out will produce a value of type t
16:36:05 <SamB_XP> assuming they don't throw exceptions instead
16:36:07 <omnId> you can hook these actions together with the funny-looking (>>=) function.
16:36:08 <IAW1939> ok
16:36:12 <Cale> They're either IO primitives, or they're built up using return and some operations called >>= and >>
16:36:14 <omnId> (called bind)
16:36:35 <IAW1939> can haskell be used as a email client ??/
16:36:35 <Cale> If x and y are actions, then x >> y is the action which does x, then does y
16:36:42 <Cale> (and returns the result of y)
16:36:45 <Cale> IAW1939: Sure
16:36:50 <IAW1939> how  ???
16:36:58 <ddarius> omnId:  concat . intersperse " " . filter (all isUpper) . words
16:36:59 <oerjan> @faq can haskell be used as a email client ??/
16:36:59 <lambdabot> The answer is: Yes! Haskell can do that.
16:37:04 <Cale> IAW1939: If you have an SMTP and POP library, I suppose.
16:37:06 <SamB_XP> IAW1939: well, you have to write an email library
16:37:09 <omnId> ddarius: =D
16:37:13 <Cale> IAW1939: I think someone's written one.
16:37:24 <IAW1939> where
16:37:32 <omnId> 19:41 <omnId> @@ @run concat . intersperse " " . filter (all isUpper) . words $ @show @yow
16:37:32 <omnId> 19:42 <!lambdabot>  "I NO HOPE OFFSET"
16:37:38 <omnId> bahahaha
16:37:41 <IAW1939> @google email client written in haskell
16:37:43 <Olathe> @pl \x -> (x == ' ') || (isUpper x)
16:37:43 <lambdabot> http://www.haskell.org/haskellwiki/Applications_and_libraries/Network
16:37:43 <lambdabot> Title: Applications and libraries/Network - HaskellWiki
16:37:43 <lambdabot> liftM2 (||) (' ' ==) isUpper
16:37:44 <SamB_XP> IAW1939: but why would you want to use a programming language as an email client anyway?
16:38:01 <IAW1939> project
16:38:21 <Cale> http://darcs.haskell.org/SoC/haskellnet/
16:38:22 <lambdabot> Title: Index of /SoC/haskellnet
16:38:28 <IAW1939> I have a write a frontend using either wxhaskell or gtk
16:38:42 <Cale> That library has SMTP and POP in it.
16:38:49 <pgavin> poll: given the choice of either C or C++ (but nothing else), which would you choose?
16:38:58 <Cale> (btw, why isn't it on hackage?)
16:39:04 <pgavin> (I know it's off topic :) )
16:39:10 <LoganCapaldo> lambdabot but for email!
16:39:11 <Cale> pgavin: C
16:39:17 <Olathe> This fails :( : @@ @run filter (liftM2 (||) (' ' ==) isUpper) @show @yow
16:39:18 <LoganCapaldo> evaluate code by sending an email
16:39:44 <Cale> pgavin: Because if those were my choices, I'd probably be using the language as a kind of high-level assembly, and so simpler is better.
16:39:47 <oerjan> Olathe: i think @@ may mix badly with parentheses you want to keep
16:39:51 <oerjan> @help @
16:39:51 <lambdabot>  @ [args].
16:39:51 <lambdabot>  @ executes plugin invocations in its arguments, parentheses can be used.
16:39:51 <lambdabot>  The commands are right associative.
16:39:51 <lambdabot>  For example:    @ @pl @undo code
16:39:51 <lambdabot>  is the same as: @ (@pl (@undo code))
16:39:53 <omnId> EVERYONE!  @@ @run let x = (@show @yow) in ...
16:39:54 <pgavin> Cale: I always choose C as well, I was wondering if any other haskellers would choose similarly
16:39:59 <EvilTerran> @protontorpedo
16:39:59 <lambdabot> is ghc bad for learning?
16:40:05 <LoganCapaldo> pgavin: so i don't get to choose the compiler, just the language?
16:40:06 <pgavin> Cale: right
16:40:44 <pgavin> LoganCapaldo: well, you get to use any ISO standard C or C++ compiler
16:40:55 <Olathe> Ahh hah !
16:40:57 <pgavin> LoganCapaldo: or Visual C++
16:41:00 <Olathe> Thanks, omnId.
16:41:15 * LoganCapaldo wonders if ISo standard C++ (or even C) compilers exists <g>
16:41:29 <dmwit> There's definitely no ISO C++ compilers.
16:41:30 <IAW1939> Ki have a week to write it
16:41:35 <pgavin> LoganCapaldo: that implement the standard and *only* the standard, no
16:41:42 <IAW1939> what would be faster gtk or wxhaskell
16:41:49 <pgavin> dmwit: isn't there an ISO C++ standard?
16:41:52 <pgavin> IAW1939: gtk
16:42:03 <IAW1939> becuase of glade ???
16:42:04 <Cale> also, I have bad associations with C++ from back when I was using a version of VC++ which had a severely broken implementation of the STL.
16:42:07 <dmwit> pgavin: Well, there's *some* C++ standard, and I know nobody implements it.
16:42:16 <LoganCapaldo> assuming magical ideal compiler then I'll go with C++
16:42:24 <pgavin> dmwit: I thought GNU was pretty close though
16:42:24 <Olathe> It would be nice if this worked: @@ @let yow = @show @yow
16:42:42 <dmwit> pgavin: There's a construct that allows you to put template-class definitions in a separate file from template-class declarations and include in the usual "include whatever.h" style.
16:42:47 <dmwit> Nobody does that.
16:42:59 <dmwit> Instead you have to put "include whatever.cpp" at the end of the header file.
16:43:01 <omnId> > yow
16:43:02 <lambdabot>  "... bleakness ... desolation ... plastic forks ...\n"
16:43:08 <omnId> seems to have worked.
16:43:24 <omnId> @undef
16:43:26 <sclv> @@ @run let x = (@show @yow) in filter (liftM2 (||) (' ' ==) isUpper) x -- whee!
16:43:26 <lambdabot> Undefined.
16:43:46 <omnId> lambdabot++
16:43:53 <pgavin> dmwit: that'd be fixed by using something like ghc's .hi files
16:44:00 <omnId> 19:48 <omnId> @@ @run let x = (@show @yow) in filter (liftM2 (||) (' ' ==) isUpper) x -- whee!
16:44:01 <omnId> 19:48 <!lambdabot>  "I GLAD I   XEROX   UNDERSHIRTS"
16:44:02 <LoganCapaldo> not really
16:44:17 <oerjan> sclv: @@ only works in private messages
16:44:18 <raxas> augustss: ok, then. ;)
16:44:31 <opqdonut> what does @@ do?
16:44:36 <pgavin> dmwit: but, other than that, what problems does g++ have?
16:44:38 <omnId> such fun!
16:44:52 <EvilTerran> opqdonut, someone @help'd it a minute ago
16:45:06 <omnId> opqdonut: kind of @., but with arbitrary subcommands :D
16:45:48 <opqdonut> ah
16:45:49 <opqdonut> nice
16:46:06 <IAW1939> where HaskellNet do I put them
16:46:30 <IAW1939> do i write the code using these lib ???
16:46:30 <oerjan> @todo-add fix @@ to work in channel
16:46:30 <lambdabot> Entry added to the todo list
16:46:54 <Cale> IAW1939: you "darcs get" the repository from that address and then  runghc Setup.hs configure; runghc Setup.hs build; runghc Setup.hs install
16:47:08 <Cale> and it'll install the library
16:47:38 <sclv> IAW1939: check with your prof. maybe he just wants you to write the gui? and have it drive an existing command line app?
16:48:26 <Cale> Yeah, that sounds more likely
16:49:23 <Olathe> omnId: it's constant.
16:49:24 <IAW1939> what if i am using windows ?
16:49:42 <omnId> Olathe: hm?
16:49:59 <omnId> Olathe: oh you want a dynamically-recomputed 'yow'?
16:50:09 <omnId> that wouldn't be very pure :)
16:50:17 <ac> How would you generate a list of all orderings of a given list?
16:50:36 <Olathe> omnId: I know :)
16:50:48 <SamB_XP> someone has HOMEWORK to write an email client in Haskell?
16:50:57 <Cale> ac: I'd first write a function pick which would return a list of pairs consisting of an element of the list, together with the remainder of the elements.
16:51:11 <omnId>  @let yow = runLBCommand "@yow" :: IO String -- :)
16:51:30 <ddarius> pgavin: I would use C++.
16:51:41 <ac> Cale: I was hoping the answer would be a composition of two or three existing functions ;)
16:51:59 <omnId> ac: pick should be :)
16:52:14 <Cale> Actually permutations should be in Data.List
16:52:15 <oerjan> ac: pick has been discussed before several times here
16:52:45 <Cale> I seem to recall someone's List library for Haskell a while back having permutations and combinations in it.
16:52:59 <oerjan> > let pick l = [(x,bef++aft) | (bef,x:aft) <- zip (inits l) (tails l)] in pick [1,2,3,4]
16:53:07 <Cale> I'm not sure if they were in the standard and subsequently removed, or if it was just in that implementation.
16:53:09 <omnId> > (\xs -> zip xs (zipWith (++) (init $ inits xs) (tail $ tails xs))) [1,2,3,4]
16:53:11 <lambdabot>  [(1,[2,3,4]),(2,[1,3,4]),(3,[1,2,4]),(4,[1,2,3])]
16:53:12 <lambdabot>  [(1,[2,3,4]),(2,[1,3,4]),(3,[1,2,4]),(4,[1,2,3])]
16:53:28 <sclv> @quote Cale stereo
16:53:28 <lambdabot> Cale says: Welcome to #haskell where your questions are answered in majestic stereo!
16:53:40 <SamB_XP> eeeeeeeeg
16:53:43 <omnId> :O
16:53:45 <omnId> it's a zombie!!!!
16:53:49 <SamB_XP> poor Cale
16:53:59 <omnId> @forget Cale Welcome to #haskell where your questions are answered in majestic stereo!
16:53:59 <lambdabot> Done.
16:54:02 * omnId fixes things.
16:54:17 <oerjan> @quote Cale stereo
16:54:18 <lambdabot> No quotes match. My pet ferret can type better than you!
16:54:26 <sclv> whew!
16:54:29 <ddarius> @quote
16:54:29 <lambdabot> sarahbot says: sarahbot: later tell lambdabot @quote sarahbot
16:54:29 <oerjan> @quote stereo
16:54:29 <lambdabot> LoganCapaldo says: * LoganCapaldo must resist urge to mention stereo
16:54:43 <Cale> > let pick [] = []; pick (x:xs) = (x,xs) : map (second (x:)) (pick xs) in pick [1,2,3,4]
16:54:44 <lambdabot>  [(1,[2,3,4]),(2,[1,3,4]),(3,[1,2,4]),(4,[1,2,3])]
16:54:56 <SamB_XP> @remember C-a-l-e Welcome to #haskell where your questions are answered in majestic stereo!
16:54:57 <lambdabot> Good to know.
16:55:09 <omnId> SamB_XP: ?
16:55:16 <Cale> SamB_XP: Thanks :)
16:55:21 <SamB_XP> the idea is to avoid triggering Cale's highlight
16:55:27 <omnId> I see.
16:56:06 <ddarius> I thought the idea was to get people to stop using that quote.
16:56:19 <SamB_XP> that's what the other quotes with stereo in them are for
16:56:27 <oerjan> right, we must not annoy Cale: that would be evil.
16:57:08 <SamB_XP> @quote stereo
16:57:09 <lambdabot> z0d says: What was the stereo quote?
16:57:15 <Cale> hehe
16:57:19 <shachaf> Of course, by now, there are several other quotes matching /stereo/.
16:57:30 <ddarius> @quote stereo!
16:57:30 <lambdabot> C-a-l-e says: Welcome to #haskell where your questions are answered in majestic stereo!
16:58:19 <shachaf> @quote omniscientIdiot stereo
16:58:20 <lambdabot> omniscientIdiot says: geez, how many metastereo quotes are going to be @remembered?  >_>
16:59:27 <SamB_XP> @quote @remember
16:59:27 <lambdabot> fasta says: I think the @remember command is way overused.
16:59:32 <oerjan> @let pick l = [(x,bef++aft) | (bef,x:aft) <- zip (inits l) (tails l)] in pick [1,2,3,4]
16:59:32 <lambdabot>  Parse error
16:59:38 <SamB_XP> @quote @remember
16:59:39 <lambdabot> fasta says: I think the @remember command is way overused.
16:59:39 <oerjan> @let pick l = [(x,bef++aft) | (bef,x:aft) <- zip (inits l) (tails l)]
16:59:41 <lambdabot> Defined.
16:59:41 <SamB_XP> hmm
17:01:38 <Olathe> What's x ?
17:01:51 <Olathe> Oh.
17:01:53 <omnId> the head of each tail
17:02:14 <oerjan> > let perms [] = [[]]; perms l = do (x,r) <- pick l; map (x:) (perms r) in perms [1,2,3,4]
17:02:16 <lambdabot>  [[1,2,3,4],[1,2,4,3],[1,3,2,4],[1,3,4,2],[1,4,2,3],[1,4,3,2],[2,1,3,4],[2,1,...
17:03:07 <oerjan> > let perms [] = [[]]; perms l = [x:r' | (x,r) <- pick l, r' <- perms r] in perms [1,2,3,4]
17:03:09 <lambdabot>  [[1,2,3,4],[1,2,4,3],[1,3,2,4],[1,3,4,2],[1,4,2,3],[1,4,3,2],[2,1,3,4],[2,1,...
17:03:12 <ddarius> @remember ddarius I think the @forget command i way underused.
17:03:12 <lambdabot> It is stored.
17:04:06 <Olathe> @help forget
17:04:06 <lambdabot> forget nick quote.  Delete a quote
17:04:10 <oerjan> there ought to be some way of doing that with unfoldr
17:04:18 <sclv> hey, lambdabot lets you @remember yourself!? that ain't right.
17:04:27 <oerjan> or do you need unfoldrM?
17:04:35 <monorobot> It also lets you forget yourself :)
17:05:01 <Olathe> That sarahbot quote looks bad.
17:05:04 <puusorsa> @forget me
17:05:04 <lambdabot> Incorrect arguments to quote
17:05:06 <sclv> I don't need a bot for that..
17:07:51 <Olathe> It's a lambdabot system ! I know this !
17:08:00 <dmwit> Olathe: Try ?where zap
17:08:01 <dmwit> =)
17:08:09 <Olathe> @where zap
17:08:09 <lambdabot> ?where zap
17:08:15 <Olathe> ?where zap
17:08:15 <lambdabot> ?where zap
17:08:19 <Olathe> Ehh
17:08:24 <dmwit> Dangerous only when there are two lambdabots.
17:08:29 <Olathe> Oh :)
17:09:02 <Pseudonym> ?where ?where ?where ?where
17:09:02 <lambdabot> ?where ?where
17:09:13 <dmwit> ?where ?where
17:09:14 <lambdabot> ?where ?where
17:09:18 <dmwit> ?where ?where blargle
17:09:19 <lambdabot> ?where ?where
17:09:22 <Olathe> @where omg
17:09:22 <lambdabot> I know nothing about omg.
17:09:22 <Pseudonym> Right.
17:09:29 <Olathe> @where @where
17:09:29 <lambdabot> I know nothing about @where.
17:09:47 <Cale> @where werewolf
17:09:47 <lambdabot> I know nothing about werewolf.
17:09:49 <Olathe> @where ?somethingorotherthatcouldntpossiblyhavebeentypedbeforebloofargle
17:09:49 <lambdabot> I know nothing about ?somethingorotherthatcouldntpossiblyhavebeentypedbeforebloofargle.
17:09:58 <Olathe> @where @run
17:09:58 <lambdabot> I know nothing about @run.
17:10:16 <Cale> @where zombies
17:10:17 <lambdabot> I know nothing about zombies.
17:10:30 <pgavin> @where lambdabot
17:10:30 <lambdabot> http://www.cse.unsw.edu.au/~dons/lambdabot.html
17:10:37 <omnId> @where+ anything I know nothing about anything.
17:10:37 <lambdabot> Done.
17:10:42 <omnId> @where anything
17:10:42 <lambdabot> I know nothing about anything.
17:10:49 <Cale> @where+ zombies Braaaaaaiiiiinnnnsss!
17:10:49 <lambdabot> I will remember.
17:10:51 <omnId> IS IT THERE OR NOT?????
17:10:52 <Cale> @where zombies
17:10:53 <lambdabot> Braaaaaaiiiiinnnnsss!
17:10:57 <pgavin> @where+ everything I know nothing about everything.
17:10:57 <lambdabot> Okay.
17:10:58 <sebell> Hmm. My Tiger ghc-6.6.1 seems to work just fine on Leopard. Was anyone else having any problems?
17:11:02 <pgavin> @where everything
17:11:03 <lambdabot> I know nothing about everything.
17:11:07 <pgavin> @where you
17:11:07 <lambdabot> I know nothing about you.
17:11:08 <Olathe> @where+ wolf ...
17:11:08 <lambdabot> It is stored.
17:11:12 <pgavin> @where me
17:11:12 <lambdabot> I know nothing about me.
17:11:12 <Olathe> @where wolf
17:11:13 <lambdabot> ...
17:11:15 <pgavin> lol
17:11:32 <sebell> This bot abuse is almost as bad as #scheme... :)
17:11:45 <Cale> @where wolf Aroooooo!
17:11:46 <lambdabot> ...
17:11:49 <Cale> @where+ wolf Aroooooo!
17:11:50 <lambdabot> It is forever etched in my memory.
17:11:55 <pgavin> nice
17:11:58 <ac> poor bot
17:12:00 <Olathe> I wonder if CTCPs are possible
17:12:00 <dmwit> ?were wolf
17:12:00 <Cale> @where wolf
17:12:00 <lambdabot> Aroooooo!
17:12:00 <lambdabot> Aroooooo!
17:12:19 <monorobot> hahahaha
17:12:41 <Olathe> @where+ botdeath ACTION dies
17:12:42 <lambdabot> It is stored.
17:12:46 <Olathe> @where botdeath
17:12:46 * lambdabot dies
17:12:51 <dmwit> ?botsnack
17:12:51 <lambdabot> :)
17:13:35 <omnId> @quote stereo
17:13:35 <lambdabot> stereo says: The stereo quote is bad and you should *feel* bad.  This has been a public service announcement.
17:13:47 <omnId> :O
17:14:03 <Olathe> Allowing CTCPs is not so good.
17:14:12 <dmwit> ?go CTCP
17:14:13 <lambdabot> http://en.wikipedia.org/wiki/CTCP
17:14:13 <lambdabot> Title: CTCP - Wikipedia, the free encyclopedia
17:14:23 <Olathe> > filter (/= '\001') "ACTION dies"
17:14:30 <lambdabot>      lexical error in string/character literal at character '\SOH'
17:14:43 <Olathe> > filter (/= '\001') "\001ACTION dies\001"
17:14:48 <lambdabot>  "ACTION dies"
17:14:56 <mwc> Wow, the cabalDebianPackage is absolutely fantastic!
17:15:03 <dmwit> Great!
17:15:32 <Cale> mwc: hm?
17:19:16 <mwc> Cale: a nice little skeleton to make a debian package from cabalized sources
17:19:26 <mwc> so Cale, how're things with you lately?
17:19:33 * mwc has started masters at UWaterloo ;)
17:19:42 <Cale> mwc: I'm fine. I'm working on a new version of my Imlib binding
17:19:54 <mwc> cool, I was just looking at that tonight
17:20:05 <mwc> went with gd instead
17:20:08 <Cale> This time with Haddock, and a complete interface to the X stuff.
17:20:28 <Cale> When I'm done with it, I might start on ecore.
17:20:41 <wli> What's ecore?
17:20:57 <Cale> It's a nice little library for getting a canvas on the screen in X.
17:21:16 <Olathe> @unpl \f xxs@(x:xs) -> if f x then xxs else xs
17:21:16 <lambdabot> \ f xxs@(x : xs) -> if f x then xxs else xs
17:21:22 <Olathe> O-o
17:21:43 <Olathe> That didn't work out so well.
17:21:46 <omnId>  @unpl, you crazy
17:21:51 <omnId>  you might want @pl
17:22:00 <Olathe> Oh :)
17:22:03 <Olathe> @pl \f xxs@(x:xs) -> if f x then xxs else xs
17:22:04 <lambdabot> (line 1, column 7):
17:22:04 <lambdabot> unexpected "@"
17:22:04 <lambdabot> expecting pattern or "->"
17:22:22 <Olathe> @pl \f (x:xs) -> if f x then (x:xs) else xs
17:22:22 <lambdabot> (`ap` tail) . (. head) . flip flip id . (ap .) . (`ap` (:)) . (((.) . if') .)
17:22:35 <Cale> It's basically a nice little abstraction over Xlib.
17:22:37 <Olathe> Stop ! You're making it worse !
17:22:38 <mwc> Cale: sounds like something from the Enlightenment folk
17:22:42 <Cale> yes, it is
17:22:52 <puusorsa> stop! you're making sense! STOP!
17:22:53 <omnId> Olathe: it did precisely what you told it to.
17:23:00 <Cale> There's also Evas, which would probably be nice to have.
17:23:30 <Olathe> I know :)
17:23:55 <dmwit> Olathe: maybe you'd be interested in dropWhile?
17:24:02 <dmwit> It's not exactly the same.
17:24:50 <dmwit> ?pl \f (x:xs) -> [x | f x] ++ xs
17:24:51 <lambdabot> (`ap` tail) . (. head) . ((++) .) . flip flip [] . ((:) .) . ap (|)
17:25:15 <omnId> dmwit: clever!
17:25:27 <dmwit> =)
17:25:33 <dmwit> I learned that trick here.
17:26:03 <omnId> guard f >> return x
17:26:09 <omnId> (f x), rather
17:26:20 <omnId> @pl \x -> guard (f x) >> return x
17:26:20 <lambdabot> ap ((>>) . guard . f) return
17:26:25 <dmwit> :t guard
17:26:27 <lambdabot> forall (m :: * -> *). (MonadPlus m) => Bool -> m ()
17:26:40 <dmwit> Looks like the argument to guard can't be just f.
17:27:00 <dmwit> Oh, I see it's not.
17:27:01 <dmwit> =P
17:27:10 <omnId> guard True = [()], guard False = [], [()] >> return x = [x]
17:28:10 <dmwit> Oh, ?pl must not understand list comprehensions!
17:28:20 <dmwit> Notice the "ap (|)" at the end of mine...
17:29:04 <omnId> @pl \f (x:xs) -> (guard (f x) >> return x) ++ xs
17:29:04 <lambdabot> (`ap` tail) . (. head) . ((++) .) . (`ap` return) . (((>>) . guard) .)
17:29:09 <eventualbuddha> dmwit: what does that do?
17:29:30 <dmwit> eventualbuddha: [x | f x] is a list that has either 0 or 1 elements.
17:29:31 <omnId> > ([1 | even 1], [2 | even 2])
17:29:32 <lambdabot>  ([],[2])
17:29:33 <EvilTerran> eventualbuddha, it causes an error. | is not an operator
17:30:01 <omnId> "the list of all x such that f x holds"
17:30:17 <dmwit> ...only we've bound x to a particular value first.
17:30:32 <eventualbuddha> okay, got it
17:30:42 <omnId> rather, it's not being generated from a comp bind.
17:30:49 <eventualbuddha> normally list comprehensions have a "<-" drawn from, right?
17:30:55 <omnId> yes
17:31:12 * EvilTerran has been thinking about monad comprehensions some more
17:32:03 <omnId> EvilTerran: translate into do notation with guard and return.  Bam.
17:32:19 <EvilTerran> specifically, I was thinking about trying to ratify my idea for list comprehensions and [x,y,z|...] = concat [[x,y,z]|...] with the monad comprehension idea
17:32:50 <omnId> concat [[x,y,z] | ...] = [w | ... , w <- [x,y,z]]
17:33:12 <EvilTerran> omnId, yes, but that's got a redundant variable, and those are icky.
17:33:23 <oerjan> @pl \f xss -> if head xss then xss else tail xss
17:33:24 <lambdabot> const (ap (if' =<< head) tail)
17:33:34 <jtxx000> why isn't RandomGen a monad?
17:33:43 <dmwit> EvilTerran: That form makes it obvious that what you want isn't easily representable.
17:33:50 <oerjan> @pl \f xss -> if f (head xss) then xss else tail xss
17:33:51 <lambdabot> (`ap` tail) . join . (if' .) . (. head)
17:33:53 <dmwit> EvilTerran: You would need a "return multiple" for any monad you wanted to use it with.
17:34:01 <omnId> jtxx000: it represents a number source, not an action that uses random numbers.
17:34:08 <omnId> @instances RandomGen
17:34:09 <lambdabot> Couldn't find class `RandomGen'. Try @instances-importing
17:34:17 <EvilTerran> dmwit, i was thinking something could be done with MonadPlus
17:34:20 <omnId> @instances-importing System.Random RandomGen
17:34:21 <lambdabot> StdGen
17:34:22 <dmwit> EvilTerran: Right.
17:34:47 <omnId> @type randomR (0,5 :: Integer)
17:34:48 <lambdabot> forall g. (RandomGen g) => g -> (Integer, g)
17:35:04 <omnId> > randomR (0,5 :: Integer) (mkStdGen 1)
17:35:05 <lambdabot>  (5,80028 40692)
17:35:30 <omnId> > read "80028 40692" :: StdGen
17:35:31 <lambdabot>  80028 40692
17:35:34 <dmwit> heh
17:35:58 <EvilTerran> [x0,x1,...,xN | ...] = msum [msum (map return [x0,x1,...,xN]) | ...] or something like that
17:36:16 <EvilTerran> not entirely clear on the details yet.
17:36:44 <EvilTerran> the main point of what i was saying was the thought of getting MonadPlus involved somehow, anyway.
17:37:08 <dmwit> [x0,x1,...,xN | ...] = [w | ..., w <- msum [x0,x1,...,xN]]
17:37:22 <dmwit> Well...
17:37:33 <dmwit> w <- msum [return x0, return x1,..., return xN]
17:37:34 <EvilTerran> (msum.map return) rather than msum?
17:37:38 <dmwit> yeah
17:37:39 <EvilTerran> snap
17:37:43 <jtxx000> @omnId but isn't the g -> (Int, g) pattern what monads are for?
17:37:44 <lambdabot> Unknown command, try @list
17:37:44 <EvilTerran> ;)
17:38:22 <oerjan> jtxx000: for some reason the Monad is not in the standard, but there is a Control.Monad.Random on hackage i think
17:38:24 <omnId> jtxx000: yes, it could be abstracted into a (State g) monad, but it hasn't.  The library predates it I think.
17:38:31 <dmwit> jtxx000: Sure, people often combine the State monad with their RandomGen usage.
17:38:36 <EvilTerran> i'm not entirely clear on how useful that'd actually be, but i figured it was interesting enough to warrant putting out to you guys for feedback
17:38:51 <wli> oerjan: Is there a RandomT monad transformer lib?
17:39:08 <oerjan> wli: no idea
17:39:18 <oerjan> i've just seen the module name
17:39:21 <dmwit> wli: Yes.
17:39:50 <omnId> > runState (do x <- State (randomR (0,10)); y <- State (random) ; return (x, y :: Bool)) (mkStdGen 42)
17:39:52 <lambdabot>  ((4,True),128694412 1655838864)
17:40:22 <jtxx000> Control.Monad.Random looks like what i'm after
17:42:36 <oerjan> too bad MonadState doesn't include a method with type (s -> (a,s)) -> m a.  although you could write one it seems like it would be more efficient to take it as basis.
17:44:02 <EvilTerran> State itself just calls it State, does it not?
17:44:12 <omnId> and StateT calls it StateT
17:44:27 <oerjan> not quite StateT
17:44:30 <oerjan> :t StateT
17:44:32 <lambdabot> forall s (m :: * -> *) a. (s -> m (a, s)) -> StateT s m a
17:44:34 <omnId> oh, right
17:44:49 <omnId> @type StateT . (return .)
17:44:49 <oerjan> :t StateT . return
17:44:51 <lambdabot> forall s (m :: * -> *) a. m (a, s) -> StateT s m a
17:44:51 <lambdabot> forall a (m :: * -> *) a1. (Monad m) => (a1 -> (a, a1)) -> StateT a1 m a
17:45:00 <oerjan> um, right
17:45:35 <oerjan> er, no i was
17:45:39 <wli> One could always write biconjugate gradient as a StateT thing.
17:45:45 <oerjan> :t StateT . return
17:45:47 <lambdabot> forall s (m :: * -> *) a. m (a, s) -> StateT s m a
17:45:55 <omnId> nerp
17:46:01 <oerjan> nah, the order was switched
17:46:09 <omnId> @slap lambdabot
17:46:09 <lambdabot> why on earth would I slap lambdabot?
17:47:17 <Olathe> lambdabot: Because you told me to.</terminator>
18:09:23 <TomMD> @tell ndm I still am unable to build YHC due to the configure not realizing that my GCC is a good build that CAN report the size of common data types.  I know your busy, no hurry and all, but if/when I get this working I'd be glad to make it a buildbot.
18:09:24 <lambdabot> Consider it noted.
18:11:51 <sorear> As a mere user, I find it difficult to beleive that autotools was actually worse than this.
18:12:14 <sieni> so don't use them!
18:12:25 <mwc> autotools is fantastic as long as the macros you need are already written
18:37:32 <ac> so why doesn't this work: perms l = concat $ map (\(h,r) -> map ([h] ++) (perms r)) $ pick l -- ?
18:38:13 <ddarius> Unrelated, but ([h] ++) is (h:)
18:38:37 <ac> ddarius: right
18:38:55 <ac> perms is supposed to return all orderings of l
18:38:57 <oerjan> > let perms l = concat $ map (\(h,r) -> map ([h] ++) (perms r)) $ pick l in perms [1,2,3,4]
18:39:02 <lambdabot>  []
18:39:11 <oerjan> oh right, no base case
18:39:27 <oerjan> > let perms [] = [[]]; perms l = concat $ map (\(h,r) -> map ([h] ++) (perms r)) $ pick l in perms [1,2,3,4]
18:39:28 <lambdabot>  [[1,2,3,4],[1,2,4,3],[1,3,2,4],[1,3,4,2],[1,4,2,3],[1,4,3,2],[2,1,3,4],[2,1,...
18:39:30 <ac> shouldn't need a base case, because pick [1] is (1,[])
18:39:35 <ac> and when you concat that, you get [1]
18:40:02 <oerjan> what is pick [] ?
18:40:07 <ac> []
18:40:14 <ac> > pick []
18:40:16 <lambdabot>  []
18:40:35 <oerjan> so perms l = []
18:40:41 <oerjan> er, perms []
18:40:53 <ac> I don't get it
18:41:17 <ddarius> ac: Go through it step by step with perms [1]
18:41:32 <oerjan> perms [] = concat $ map whatever $ pick [] = []
18:41:59 <ddarius> also concatMap
18:43:13 <ddarius> > let perms [] = [[]]; perms l = [h:perms r | (h,r) <- pick l] in perms [1,2,3]
18:43:14 <lambdabot>      Occurs check: cannot construct the infinite type: a = [a]
18:43:14 <lambdabot>       Expected...
18:43:35 <ac> ddarius: hah, I got that type error a few times too
18:43:40 <ddarius> > let perms [] = [[]]; perms l = [map (h:) $ perms r | (h,r) <- pick l] in perms [1,2,3]
18:43:41 <lambdabot>      Occurs check: cannot construct the infinite type: a = [a]
18:43:41 <lambdabot>       Expected...
18:43:58 <chessguy> 'evening, ya'all
18:44:18 <ac> ddarius: I think you need a concat somewhere in there
18:44:33 <oerjan> perms [1] = concat $ map (\(h,r) -> map ([h] ++) (perms r)) $ [(1,[])]
18:44:34 <chessguy> @type pick
18:44:35 <lambdabot> Not in scope: `pick'
18:44:53 <ac> pick was defined earlier
18:45:09 <ac> @let pick l = [(x,bef++aft) | (bef,x:aft) <- zip (inits l) (tails l)]
18:45:10 <lambdabot> <local>:3:0:     Multiple declarations of `L.pick'     Declared at: <local>:1...
18:46:26 <oerjan> = concat $ [map ([1] ++) (perms [])]
18:46:54 <oerjan> = concat $ [map ([1] ++) []] = concat [] = []
18:47:28 <oerjan> perms [] should be [[]], not [], to make it work, which needs a base case
18:47:50 <oerjan> er, slight error
18:48:00 <oerjan> = concat $ [map ([1] ++) []] = concat [[]] = []
18:49:01 <ddarius> > fix concat
18:49:02 <lambdabot>      Occurs check: cannot construct the infinite type: a = [a]
18:49:02 <lambdabot>       Expected...
18:49:59 <araujo> > let intercal x [] = [[x]] ; intercal x ls@(y:ys) = (x : ls) : map (y :) (intercal x ys) in let perms [] = [[]] ; perms (x : xs) = concatMap (intercal x) (perms xs) in perms [1,2,3,4]
18:50:01 <lambdabot>  [[1,2,3,4],[2,1,3,4],[2,3,1,4],[2,3,4,1],[1,3,2,4],[3,1,2,4],[3,2,1,4],[3,2,...
18:50:17 <omnId> @quote intercal
18:50:17 <lambdabot> No quotes match. :(
18:50:30 <araujo> omnId, defined there
18:50:51 <omnId> I was expected a quote on the INTERCAL language.
18:51:01 <araujo> hah
18:51:11 <chessguy> @quote
18:51:11 <lambdabot> gFunk says: [the main advantage of functional programs are that they're] incorrect the first 1000 times you try to compile it!
18:51:59 <ddarius> @pl \h -> map (h:) . perms
18:51:59 <lambdabot> (. perms) . map . (:)
18:52:13 <ac> ddarius: ah I get it
18:52:19 <ac> ddarius: took a little thinking
18:53:22 <oerjan> @quote unlambda
18:53:23 <lambdabot> No quotes match. Take a stress pill and think things over.
18:53:24 <ddarius> oerjan put out a lot more effort than I did.
18:53:31 <oerjan> @quote brainfuck
18:53:32 <lambdabot> No quotes match. Have you considered trying to match wits with a rutabaga?
18:53:42 <oerjan> @quote befunge
18:53:42 <lambdabot> xerox says: you know, befunge is probably the only language I've seen where you can run code pasted from IRC with the <nick> tags still in place ;-)
18:53:49 <jeffz> @quote PostScript
18:53:49 <lambdabot> No quotes match. BOB says:  You seem to have forgotten your passwd, enter another!
18:53:59 <chessguy> @quote bf
18:53:59 <lambdabot> sieni says: scheme adheres to the TIMTOBFTTWTDI principle instead of TIMTOWTDI
18:54:01 <ddarius> whitespace
18:55:44 <ac> ddarius: how do I avoid the "overlapping pattern match" problem?
18:55:54 <ac> I want to match a single element list, and everything else
18:56:36 <ddarius> ac: It shouldn't complain as long as you put the [] case first.
18:56:50 <ac> oh that's my problem
18:57:03 <ac> wow, that took me a lot longer than it should have
18:58:32 <ac> the space of possible one liners is actually quite large
18:58:54 <ac> the space of incorrectly typed and useless one liners is much larger
18:59:03 <ddarius> Indeed, it's countably infinite.
18:59:24 <oerjan> any haskell program _can_ be written on one line
18:59:27 <ac> I think the latter is a larger infinity :P
19:00:30 <ac> well I should have defined one liner as programs consisting of 15 primitive functions
19:00:38 <ac> or something like that
19:01:31 <monorobot> It's more useful to count tokens.
19:02:09 <conal> how about a type of well-typed haskell programs and a quickcheck Arbitrary instance.
19:02:36 <sclv> let pick (y,l) = map(\(a,b)-> (a:y,b)) [(x,bef++aft) | (bef,x:aft) <- zip (inits l) (tails l)] in (\x->map (fst) $ last $ takeWhile (not . null)  (iterate (concatMap pick) $ pick ([],x))) [1,2,3,4]
19:02:51 <ddarius> conal: You should be able to make a type of well-typed Haskell 98 programs in GHC Haskell.
19:03:02 <conal> ddarius: with gadts
19:03:43 <conal> polymorphism would probably be tricky
19:04:16 <ddarius> conal: The more mundane module system would probably be more tricky.
19:04:31 <sclv> > let pick (y,l) = map(\(a,b)-> (a:y,b)) [(x,bef++aft) | (bef,x:aft) <- zip (inits l) (tails l)] in (\x->map (fst) $ last $ takeWhile (not . null)  (iterate (concatMap pick) $ pick ([],x))) [1,2,3,4]
19:04:33 <lambdabot>  [[4,3,2,1],[3,4,2,1],[4,2,3,1],[2,4,3,1],[3,2,4,1],[2,3,4,1],[4,3,1,2],[3,4,...
19:04:43 <sclv> there we go.
19:05:00 <ddarius> What is with random parens around identifiers?
19:05:30 <sclv> ddarius: wrote the whole thing in ghci real sloppy, that's all
19:05:39 <ddarius> iterate (pick =<<)
19:05:45 <oerjan> ddarius: it's shy
19:06:31 <ddarius> Also, because no one has said it.  inits is not the most efficient thing in the world...
19:07:49 <oerjan> hm, true, and given that the ordering on the bef part is scrambled again later it may not be as useful
19:08:56 <sclv> here we are
19:09:03 <sclv> > let pick (y,l) = map(\(a,b)-> (a:y,b)) [(x,bef++aft) | (bef,x:aft) <- zip (inits l) (tails l)] in (map fst . last . takeWhile (not . null) . iterate (pick =<<) . pick . (,) []) [1,2,3,4]
19:09:05 <lambdabot>  [[4,3,2,1],[3,4,2,1],[4,2,3,1],[2,4,3,1],[3,2,4,1],[2,3,4,1],[4,3,1,2],[3,4,...
19:11:40 <sclv> > let pick (y,l) = map (first (: y)) [(x,bef++aft) | (bef,x:aft) <- zip (inits l) (tails l)] in (map fst . last . takeWhile (not . null) . iterate (pick =<<) . pick . (,) []) [1,2,3,4]
19:11:42 <lambdabot>  [[4,3,2,1],[3,4,2,1],[4,2,3,1],[2,4,3,1],[3,2,4,1],[2,3,4,1],[4,3,1,2],[3,4,...
19:13:21 <oerjan> > let pick (y,l) = map (first (: y)) [(x,bef++aft) | (bef,x:aft) <- zip (inits l) (tails l)] in map (take 5) $ (map fst . last . takeWhile (not . null) . iterate (pick =<<) . pick . (,) []) [1..]
19:13:25 <lambdabot> Terminated
19:13:31 <ddarius> Um, pick (y,l) = [(x:y, ...
19:15:23 <oerjan> > map (second (take 5)) (pick [1..])
19:15:24 <lambdabot>  [(1,[2,3,4,5,6]),(2,[1,3,4,5,6]),(3,[1,2,4,5,6]),(4,[1,2,3,5,6]),(5,[1,2,3,4...
19:16:10 <sw17ch> just curious, what are you trying to do?
19:16:32 <Olathe> @src pick
19:16:33 <lambdabot> Source not found. Just what do you think you're doing Dave?
19:16:39 <oerjan> make a list of all permutations of finite parts of a possibly infinite list
19:17:02 <Olathe> @let bojangles = 5
19:17:07 <lambdabot> Defined.
19:17:09 <Olathe> > bojangles
19:17:10 <lambdabot>  5
19:17:13 <Olathe> @src bojangles
19:17:13 <lambdabot> Source not found. Your mind just hasn't been the same since the electro-shock, has it?
19:17:32 <ddarius> Olathe: It's an exercise to you, the reader, to add such support to lambdabot.
19:17:53 <Olathe> I'm nowhere near that good in Haskell.
19:17:56 <ddarius> Olathe: It would also be easy to add a more selective @undefine while you're at it.
19:18:00 <ddarius> Olathe: It's not hard.
19:18:24 <Olathe> @unlet bojangles
19:18:25 <lambdabot>  Parse error
19:18:32 <Olathe> @unlet bojangles = 5
19:18:33 <lambdabot> <local>:4:0:     Multiple declarations of `L.bojangles'     Declared at: <loc...
19:18:37 <Olathe> O-o
19:18:44 <Olathe> @help unlet
19:18:45 <lambdabot> help <command>. Ask for help for <command>. Try 'list' for all commands
19:18:49 <Olathe> Bah.
19:18:49 <ddarius> Olathe: That's getting spell-corrected to @let
19:18:54 <Olathe> I know.
19:19:00 <Olathe> @help should do spell-correction, too.
19:19:01 <ddarius> Olathe: The command is @undefine but it undefines everything.
19:19:01 <lambdabot> help <command>. Ask for help for <command>. Try 'list' for all commands
19:19:16 <sclv> the idiom involving foo f cond = last . takeWhile cond . iterate ( concatMap f) seems to come up all the time. is there some shorthand form in the list monad for it?
19:20:14 * ddarius would be more inclined to use until on pairs rather than that.
19:21:41 <ddarius> :t \f -> fst . until ((f . fst)&&&snd)
19:21:43 <lambdabot>     Couldn't match expected type `Bool' against inferred type `(c, b)'
19:21:43 <lambdabot>     In the first argument of `until', namely `((f . fst) &&& snd)'
19:21:43 <lambdabot>     In the second argument of `(.)', namely `until ((f . fst) &&& snd)'
19:21:45 <oerjan> might want a lastWhile, perhaps?
19:22:01 <oerjan> :t until
19:22:02 <lambdabot> forall a. (a -> Bool) -> (a -> a) -> a -> a
19:22:15 <sclv> I define a firstWhere all the time.
19:22:24 <ddarius> :t \p f -> snd . until p ((f . fst)&&&snd)
19:22:25 <lambdabot> forall c b. ((c, b) -> Bool) -> (c -> c) -> (c, b) -> b
19:22:38 <ddarius> :t \p f -> snd . until (p . fst) ((f . fst)&&&snd)
19:22:40 <lambdabot> forall b c. (c -> Bool) -> (c -> c) -> (c, b) -> b
19:22:47 <oerjan> sclv: there is also find
19:22:54 <sw17ch> can some one explain the &&& syntax?
19:22:58 <ddarius> find would be good
19:23:02 <ddarius> sw17ch: There is no &&& syntax
19:23:03 <omnId> @src (->) (&&&)
19:23:04 <lambdabot> Source not found. The more you drive -- the dumber you get.
19:23:10 <ddarius> :t find
19:23:11 <lambdabot> forall a. (a -> Bool) -> [a] -> Maybe a
19:23:12 <sorear> @src (->) &&&
19:23:13 <lambdabot> Source not found. Just what do you think you're doing Dave?
19:23:18 <sorear> @src -> (&&&)
19:23:18 <omnId> (f &&& g) x = (f x, g x)
19:23:19 <lambdabot> Source not found. There are some things that I just don't know.
19:23:21 <glguy> :t until
19:23:23 <lambdabot> forall a. (a -> Bool) -> (a -> a) -> a -> a
19:23:33 <oerjan> what the
19:23:35 <sw17ch> ah, i see. thank you
19:23:51 <omnId> > ((+1) &&& even) 4
19:23:53 <lambdabot>  (5,True)
19:23:56 <glguy> @index until
19:23:57 <lambdabot> Prelude
19:24:01 <glguy> \o/
19:24:05 <oerjan> @src -> (***)
19:24:06 <lambdabot> Source not found. It can only be attributed to human error.
19:24:15 <omnId> (->)
19:24:30 <oerjan> oh wait
19:24:47 <oerjan> omnId: i mistook your response for lambdabot's
19:24:52 <glguy> (&&&) f g x = (f x, g x)
19:24:54 <omnId> :)
19:24:58 <oerjan> so i thought it actually had the source
19:25:02 <glguy> (***) f g (x,y) = (f x, g y)
19:25:11 <reilly> has anybody done ghc builds on mac os x leopard?
19:25:18 <omnId> though (***) is more lazy than that.
19:25:29 <ddarius> :t \p f -> snd . until (p . fst) ((f . fst)&&&fst)
19:25:30 <lambdabot> forall c. (c -> Bool) -> (c -> c) -> (c, c) -> c
19:25:57 <oerjan> omnId: (***) f g ~(x,y) = (f x, g y) ?
19:26:03 <omnId> oerjan: yes
19:26:12 <omnId> @src (->) (***)
19:26:12 <lambdabot> (f *** g) ~(x,y) = (f x, g y)
19:26:20 <oerjan> eek
19:27:01 <sw17ch> Has any one done any significant work with parallel programming in Haskell? I have a professor who is curious about it.
19:27:34 <oerjan> ah, &&& is using the default
19:27:42 <oerjan> @src (&&&)
19:27:42 <lambdabot> f &&& g = arr (\b -> (b,b)) >>> f *** g
19:27:43 <Zao> sw17ch: Look up STM. Great fun.
19:28:00 <reilly> sw17ch: lookup up STM and data parallel haskell
19:28:25 <ddarius> sw17ch: parallelism and Haskell go back to it's beginning
19:28:51 <sw17ch> I've looked at a few of those briefly, but I keep getting caught up in the lazy part of things.
19:29:36 <sw17ch> I'm quite new to Haskell (if you can't tell), and don't know if you can "force" evaluation or not... but that seems the only way you could actually make parallelism work.
19:29:38 <monorobot> http://www.haskell.org/haskellwiki/Research_papers/Parallelism_and_concurrency lists papers.
19:29:40 <lambdabot> Title: Research papers/Parallelism and concurrency - HaskellWiki, http://tinyurl.com/yybhes
19:29:46 <sw17ch> Merci
19:29:51 <omnId> > last [1..] `seq` ()
19:29:55 <lambdabot> Terminated
19:30:05 <omnId> > last [1..] `par` ()
19:30:07 <lambdabot>  ()
19:30:28 * omnId spawns a doomed thread :)
19:30:29 <monorobot> Yes, an operator to force evaluation is included.
19:31:53 <sw17ch> Is it required to run parallel code?
19:33:41 <monorobot> Yes.
19:34:01 <ddarius> For one particular approach and by design.
19:34:12 <sw17ch> So there's no way around it then?
19:34:49 <monorobot> I guess I am not actually sure.
19:35:35 <sclv> > let pick (y,l) = map(\(a,b)-> (a:y,b)) [(x,bef++aft) | (bef,x:aft) <- zip (inits l) (tails l)] in (map fst . until (null . snd . head)  (pick =<<) . (:[]) . (,) []) [1,2,3,4]
19:35:37 <lambdabot>  [[4,3,2,1],[3,4,2,1],[4,2,3,1],[2,4,3,1],[3,2,4,1],[2,3,4,1],[4,3,1,2],[3,4,...
19:36:07 <ddarius> sclv: The map (first (:y)) can be trivially folded into the list comprehension.
19:36:13 <ac> so something like [ (x,y) | x <- aList, y <- aList ] gets you a cartesian product. How would you avoid getting (x,x)? I suppose you could "filter (\(x,y) -> x /= y)"
19:36:34 <sclv> ddarius: i tried and somehow kept fouling it up, so gave up.
19:37:30 <sclv> ac: do you want (x,y) as well as (y,x) though?
19:37:32 <ddarius> > let pick (y,l) [(x:y,bef++aft) | (bef,x:aft) <- zip (inits l) (tails l)] in map fst . until (null . snd . head) (pick =<<) . (:[]) . (,) [] $ [1,2,3,4]
19:37:32 <lambdabot>  Parse error at "in" (column 74)
19:37:35 <sw17ch> omnId: If I were to implement some code using seq or par, would either of them actually use two threads in the operating system?
19:37:52 <ac> sclv: I now that you mention it, no
19:37:56 <ddarius> > let pick (y,l) = [(x:y,bef++aft) | (bef,x:aft) <- zip (inits l) (tails l)] in map fst . until (null . snd . head) (pick =<<) . (:[]) . (,) [] $ [1,2,3,4]
19:37:57 <omnId> not sure, I know next to nothing about it :)
19:37:58 <lambdabot>  [[4,3,2,1],[3,4,2,1],[4,2,3,1],[2,4,3,1],[3,2,4,1],[2,3,4,1],[4,3,1,2],[3,4,...
19:38:21 <sw17ch> hehe, alright. I had been playing around with both of those, and cannot get anything to crush both cores in my machine.
19:38:23 <omnId> I believe par spawn *something* to evaluate its first argument.
19:38:28 <Cale> let pick [] = []; pick (x:xs) = (x,xs) : map (second (x:)) (pick xs); perms xs = [y:zs | (y,ys) <- pick xs, zs <- perms ys] in perms [1,2,3,4]
19:38:30 <ddarius> sw17ch: seq doesn't spawn threads.  par spawn sparks.
19:38:35 <Cale> > let pick [] = []; pick (x:xs) = (x,xs) : map (second (x:)) (pick xs); perms xs = [y:zs | (y,ys) <- pick xs, zs <- perms ys] in perms [1,2,3,4]
19:38:37 <lambdabot>  []
19:38:40 <Cale> er
19:38:48 <wli> Explain M:N threading...
19:39:11 <ac> I guess I want all selections of two from aList, not the cartesion product
19:39:14 <Cale> > let pick [] = []; pick (x:xs) = (x,xs) : map (second (x:)) (pick xs); in pick [1,2,3,4]
19:39:16 <lambdabot>  [(1,[2,3,4]),(2,[1,3,4]),(3,[1,2,4]),(4,[1,2,3])]
19:39:26 <ddarius> sw17ch: As wli mentions vaguely,  Haskell uses lightweight threads and spreads them over OS threads.
19:39:55 <Saizan> sw17ch: compile with -threaded and run with +RTS -N2 if you want 2 OS threads
19:39:57 <sclv> >  [(x,y) | x<-[1..5],y<-[1..x]] --ac: if your list is ordered, you can do something like  this.
19:39:58 <lambdabot>  [(1,1),(2,1),(2,2),(3,1),(3,2),(3,3),(4,1),(4,2),(4,3),(4,4),(5,1),(5,2),(5,...
19:40:18 <sw17ch> Saizan: is there any way to get the behavior with GHCI?
19:40:36 <sclv> >  [(x,y) | x<-[1..5],y<-[1..(x-1)]] --or, er, this
19:40:38 <lambdabot>  [(2,1),(3,1),(3,2),(4,1),(4,2),(4,3),(5,1),(5,2),(5,3),(5,4)]
19:40:41 <omnId> @index par
19:40:41 <lambdabot> GHC.Conc, Control.Parallel, Graphics.HGL.Utils, Graphics.HGL
19:40:53 <omnId>  :m +Control.Parallel
19:40:57 <Cale> > let pick [] = []; pick (x:xs) = (x,xs) : map (second (x:)) (pick xs); perms [] = [[]]; perms xs = [y:zs | (y,ys) <- pick xs; zs <- perms ys] in perms [1,2,3,4]
19:40:58 <lambdabot>  Parse error at ";" (column 124)
19:40:59 <oerjan> > [(x,y) | (x:r) <- tails [1..5], y <- r]
19:41:00 <lambdabot>  [(1,2),(1,3),(1,4),(1,5),(2,3),(2,4),(2,5),(3,4),(3,5),(4,5)]
19:41:01 <Cale> > let pick [] = []; pick (x:xs) = (x,xs) : map (second (x:)) (pick xs); perms [] = [[]]; perms xs = [y:zs | (y,ys) <- pick xs, zs <- perms ys] in perms [1,2,3,4]
19:41:03 <lambdabot>  [[1,2,3,4],[1,2,4,3],[1,3,2,4],[1,3,4,2],[1,4,2,3],[1,4,3,2],[2,1,3,4],[2,1,...
19:41:05 <Cale> heh
19:41:14 <Cale> I'm stupid, forgot the base case :)
19:41:37 <oerjan> ac: ^^
19:41:55 <Saizan> sw17ch: never tried, but you should be able to run it with +RTS -N2 too
19:42:06 <omnId> Prelude Control.Parallel> product [1..10^1000] `par` ()
19:42:07 <omnId> ()
19:42:15 <omnId> my PC is now horribly laggy :)
19:42:18 <monorobot> Go co-inductive. Then you don't need a base case. You only need to be a terminal nutcase. :)
19:42:24 <Cale> It's beyond me why we don't have a permutations in Data.List
19:42:34 <ac> it never occurred to me that you could repeat variables in a comprehension after the |
19:42:40 <sw17ch> omnId: I did something similar, haven't actually used the swap file on this machine until just then =)
19:42:45 <Cale> and pick as well should be there
19:44:11 <oerjan> ac: hm?
19:44:32 <ac> orbitz: as in: [(x,y) | x<-[1..5],y<-[1..x]]
19:44:51 <ac> the "y <- ..." parts refers to the "x <- ..." part
19:44:57 <ddarius> ac: oerjan's exapmle translates as do (x:r) tails [1..5]; y <- r; retun (x,y)
19:45:15 <oerjan> modulo typos
19:45:26 <ac> right. I see they're the same, but I find sclv's more comprehensible
19:45:27 <ddarius> Yeah, I was not in a proper typing position for that.
19:45:40 <oerjan> sclv?
19:46:19 <oerjan> ac: sclv's solution works only for a list of consecutive Enum's
19:46:27 <sclv> ac: it's also less powerful -- the solution with tails works on anything.
19:46:28 <ddarius> ac: Assuming you're responding to me, the point is the translation to do-notation, not the actual algorithm.
19:46:58 <ac> ddarius: you just confused me with that translation ;P
19:47:02 <sw17ch> Saizan: I'm getting a "unknown RTS option: -N2"
19:47:16 <sw17ch> Saizan: am i missing something i should have compiled in with GHC?
19:47:31 <ac> ddarius: why translate something that's fairly comprehensible in to something that's completely uncomprehensible?
19:47:31 <ddarius> ac: The point to note here, is that with the do-notation version, it should be immediately obvious what the variables scope over.
19:47:34 <sclv> for a haskell newb, translating a comprehension into the list monad isn't exactly shining a light on the matter, I guess.
19:47:59 <ac> ddarius: I'll just think of it as a sort of let where the body is before the declarations
19:48:29 <Saizan> sw17ch: are you passing that when launcing ghci?
19:48:37 <ddarius> sclv, ac: Seeing as the translation is trivial it shouldn't be confusing.  I'm not asking that one understand -why- they are the same, just understand do-notation in a very shallow sense.
19:48:58 <sw17ch> Saizan: I'm trying the compiled route for now... ghci doesn't understand -N2 either... so i figured i'd try a source file next
19:49:22 <Saizan> sw17ch: you need to use -threaded when compiling
19:49:22 <sw17ch> Saizan: ghc t.hs -o t -threaded
19:49:42 <Saizan> sw17ch: and the ./t +RTS -N2 ?
19:49:51 <sclv> ddarius: I'm just saying that the list monad isn't something that easy to get in a shallow sense. ac: by the way, you can also generate useful results from infinite lists that way, if you're careful.
19:50:07 <sw17ch> Saizan: unknown RTS option: -N2
19:50:20 <ddarius> sclv: Again, I didn't say anything about understanding the list monad.
19:50:23 <sw17ch> Saizan: ~ > ./t +RTS -N2
19:51:17 <ddarius> sclv: That said, if you understand list comprehensions, this translation immediately tells you want list monadic code means.
19:51:26 <sw17ch> Saizan: hey, i found my problem
19:51:40 <sw17ch> Saizan: The Glorious Glasgow Haskell Compilation System, version 6.4.2
19:52:31 <Cale> sw17ch: that's sort of an old version
19:52:50 <ddarius> It's the previous version!
19:52:53 <sw17ch> Cale: amd64 stable in gentoo... i'll move to the unstable 6.6 and try again
19:53:16 <sw17ch> any word on how "unstable" 6.6 is? the gentoo guys usually overreact to changing numbers
19:53:29 <Cale> ddarius: yeah, when new versions only come out once every 6 months or so, the previous version is kind of old :)
19:53:36 <Cale> It's not
19:53:43 <Cale> 6.8 is almost out
19:53:49 <Cale> 6.6.1 is released.
19:54:29 <Cale> When the GHC team releases something, it's generally very stable.
19:54:34 <ddarius> 6.8.1 will be released... any day now... any day
19:55:08 <sw17ch> length anyDay
19:55:23 <Cale> ddarius: Happen to know why it's not 6.7.x with 6.8 being the release version?
19:55:38 <Cale> Is it because that's where they make the feature freeze?
19:55:42 <sorear> Cale: that's not quite how it works
19:55:54 <sorear> Cale: 6.8.0.x = pre-release snapshots
19:56:03 <Cale> ah, okay
19:56:15 <sorear> 1.x is snapshots for 2.0, etc.
19:58:12 <geocalc> so 6.8.0 is snapshot for 12.16.0
19:58:38 <sw17ch> too bad compiling everything takes so long. i like gentoo, but man... building GCC/GHC etc... takes... well... a long time
19:58:48 <Cale> sw17ch: I wouldn't compile it
19:59:03 <Cale> sw17ch: If I was using Gentoo, I'd probably just download the generic linux binary.
19:59:15 <ddarius> sw17ch: 6.6 or 6.8 is supposed to be much better in that regard (though still not wonderful)
19:59:18 <Cale> Of course, the compiling is why I don't use Gentoo.
20:00:12 <sw17ch> Cale: I use gentoo because of emerge... I'd switch quite fast (and may soon) to something different if their package management tools were nicer
20:00:30 <Cale> sw17ch: Have you ever tried Ubuntu or Debian?
20:00:54 <geocalc> try paldo sw17ch
20:01:05 <Olathe> Have you tried The Best Linux Ever (TBLE) ?
20:01:10 <Cale> Ubuntu has the annoying property of always being one version behind in GHC releases.
20:01:17 <sw17ch> Cale: wife has Ubuntu, I'm slowly coming to like it more
20:01:28 <Cale> But otherwise it has a rather nice packaging system, along with Debian.
20:01:33 <sw17ch> newest ghc-bin available for gentoo is 6.4.2 :(
20:01:44 <geocalc> ubuntu lol
20:01:50 <Cale> If you go with Debian, I highly recommend going with Debian Unstable. It's not really unstable.
20:02:39 <ddarius> It just had a tough childhood.
20:03:59 <Cale> I used it for about 5 years, and in that entire time, I only bumped into one or maybe two packaging bugs, which caused a package I wanted to be uninstallable. I just waited a day or two, and the problems were fixed.
20:04:33 <Cale> And if you care, testing is a bit more stable than that.
20:04:40 <Cale> Stable is way-too-stable. :)
20:04:47 <glguy> I gave unstable a shot and had two packages that would just segfault outright
20:04:49 <glguy> gpg was one
20:04:51 <glguy> so I moved on
20:04:58 <sw17ch> Cale: I use debian in an embedded environment. I'm afraid I like pretty things for the desktop... and would lean toward ubuntu...
20:05:06 <sw17ch> Cale: I know enough linux to make it do what i please
20:05:26 <Cale> Yeah, Ubuntu has the nice property of being set up mostly the way I want it set up right away.
20:05:43 <Saizan> unstable has become more so after the lenny release
20:05:50 * sorear does the command line advocacy cry!
20:05:54 <sw17ch> I like XFCE, so it would be Xubuntu
20:06:10 <sw17ch> bah, this is not #linux, i'll stop now
20:06:11 <Cale> Saizan: Ah, it was already a year or two ago which I last used Debian.
20:06:26 * omnId mentions the xmonad wm to sw17ch 
20:06:49 * sw17ch has heard of it. is afraid of tiling for some reason
20:06:50 <Cale> Heh, most Haskell users are also linux users anyway, it seems :)
20:07:00 <sw17ch> yet our kernel is C
20:07:03 <Cale> I can't stand tiling for some reason.
20:07:38 * ddarius doesn't use the tiling features of xmonad
20:07:44 <Saizan> sorear: do you read ps/pdf in the terminal?
20:07:55 <kilimanjaro> I just like having applications completely fullscreen
20:07:57 <glguy> after a lot of tiling wm use, you get spoiled. I find it annoys me when I switch to xfce that  I haveto move and resize windows myself
20:08:14 <sorear> Saizan: no, I use xpdf, generally pretending it's less
20:08:28 <ddarius> kilimanjaro: That's how I do it.  xmonad border width set to 0
20:08:30 * sorear really wants to see tuomov's superunix
20:08:38 <Cale> I actually like having my windows overlap.
20:08:48 <sorear> HERETIC!
20:08:55 <ddarius> Cale: Mine "overlap" completely
20:09:10 <Cale> ddarius: yes, but then you can't see changes in a covered window
20:09:23 * sw17ch hates wasted screen real estate, but also does not like really big dialog boxes
20:09:54 <sorear> sw17ch: xmonad displays dialog boxes at their natural size in the center of the screen
20:10:26 <sorear> actually it allows them to be moved/resized at will, but usually permanent windows are tiled and transients aren't touched
20:10:31 <kilimanjaro> I use xmonad straight out of the box (ok, so I lied, I also use dmenu). The only modifications I have considered making is setting up a custom status bar to show whether or not I have pending messages on IRC or IM
20:10:58 * sorear uses irssi for that.  mod-9 and look for purple digits
20:11:03 <ddarius> Other than vimier keybindings, the only thing I've changed is the border width.
20:11:31 * sw17ch realizes xmonad doesn't exist in the eyes of Gentoo, thus i must fear and abhor it
20:11:35 <Cale> Has anyone here used xmonad in conjunction with Gnome?
20:11:41 <glguy> size hint layouts are a must of the console/mplayer user :)
20:11:54 <sjanssen> sw17ch: I think we'll be able to get xmonad 0.5 in Gentoo
20:11:57 <mrd> would that be, xgnomad?
20:12:28 <omnId> xmognad
20:12:36 <sjanssen> Cale: yeah, we have a guide for it.  It's a bit rough around the edges however
20:12:42 <sw17ch> sjanssen: I'll give it a shot before it makes it in :)
20:17:11 <kilimanjaro> sorear, yea, but I'd like to be able to be notified of messages in a different virtual desktop, but in a non-intrusive way (i.e. no popups)
20:17:31 <sorear> kilimanjaro: is a beep too obtrusive?
20:17:48 <kilimanjaro> sorear, that might work out well, except I often listen to music / I might not notice it
20:17:55 <kilimanjaro> so I'd like a visual flag that is set
20:17:59 <kilimanjaro> it's not a huge deal
20:18:29 <kilimanjaro> I get all IM's via IRC too, using bitlbee
20:20:14 <sw17ch> Has any one done major work with Parsec?
20:20:17 <sorear> Daan?
20:20:33 <sorear> oh, major work *with*
20:20:46 <sw17ch> how about any work =)
20:20:48 <sorear> several of our XML processors are based on it
20:20:48 <sjanssen> sw17ch: I'm sure the necessary expertise is in the channel
20:20:54 <sjanssen> (don't ask to ask, etc. :)
20:21:09 <sorear> sjanssen: I think he's just trying to insult it's practicality
20:21:13 <sjanssen> ah
20:21:37 <sw17ch> haha, actually... my senior project is a combination of Parsec and HOpenGL
20:21:52 <sorear> a model renderer?
20:21:54 <sw17ch> ahem... will *hopefully* be a combination of
20:22:09 <sw17ch> Language analysis and manipulation
20:22:26 <sw17ch> wow, that said a lot of nothing
20:23:03 <sw17ch> I'm trying to display the AST of a program in OpenGL in a way that one can "navigate" through the program
20:25:01 <sorear> ah.
20:25:51 <ddarius> sw17ch: To answer your current, previous, and future questions: Haskell and its significant libraries have been, are, and will continue to be used in significant projects.
20:28:24 <sw17ch> preemptive answers are the best :P
20:28:36 <oerjan> if it's haskell you're analysing it might be better to use an already available parser, such as the one in Language.Haskell.  parsing haskell is quite subtle.
20:28:56 <sw17ch> I'm using a very small lisp for starters.
20:29:06 <sw17ch> actually , i should call it a scheme
20:29:21 <oerjan> that should be easy enough with Parsec
20:29:27 <sw17ch> oh yeah, no kidding
20:29:44 <sw17ch> so far, the most challenging part was parsing all the various integer constants one can represent in lisp
20:30:08 <sw17ch> #x43DE, #36rOERJAN, etc..
20:30:19 <sw17ch> okay, the most challenging part was the radix notation
20:30:39 <sw17ch> but perhaps it was only challenging because i was/am quite new to the language and the library
20:30:53 <oerjan> there are some handy functions in Numeric for arbitrary bases
20:31:11 <sw17ch> Do they allow me to retain the string representation?
20:31:24 <sw17ch> bah, dumb question
20:31:33 <oerjan> hm, i guess you may not have that much need for the actual value...
20:31:46 <sw17ch> actually at this point, i don't have any need for it
20:31:56 <sw17ch> i just need the string representation
20:32:48 <sw17ch> unfortunately, i also need to preserve whitespace
20:40:36 <omnId> > let ds = ['0'..'9'] ++ ['a'..'z']; toDigit c = d where Just d = findIndex (c ==) ds in readInt 36 (`elem` ds) (toDigit) "oerjan"
20:40:37 <lambdabot>  [(1475987567,"")]
20:42:12 <omnId> > map digitToInt $ ['0'..'9']++['a'..'z']
20:42:13 <lambdabot>  Exception: Char.digitToInt: not a digit 'g'
20:42:17 <omnId> only hex, eh?
20:44:59 <sw17ch> omnId: got you thinking about base 36?
20:45:30 <omnId> I wanted to know if oerjan was anything terribly interesting in base 10 :)
20:45:57 <sw17ch> 1475987567
20:46:29 <sw17ch> Base 36 and BigNum allow for some pretty neat things
20:47:19 <sw17ch> @src -> (readInt)
20:47:19 <lambdabot> Source not found. Your mind just hasn't been the same since the electro-shock, has it?
20:47:49 <omnId> sw17ch: the (->) before was looking for a class method for the (->) type constructor
20:47:53 <omnId> @src readInt
20:47:54 <lambdabot> Source not found. Have you considered trying to match wits with a rutabaga?
20:48:09 <omnId> didn't think it'd be available anyway, it's probably a little long.
20:48:26 <sw17ch> :t readInt
20:48:28 <lambdabot> forall a. (Num a) => a -> (Char -> Bool) -> (Char -> Int) -> String -> [(a, String)]
20:48:46 <omnId> base isDigit toDigit string
20:48:57 <sw17ch> oic
20:49:00 <sw17ch> :)
20:49:40 <sw17ch> it takes me 14 lines to parse the lisp radix numbers...
20:49:54 <sw17ch> i keep thinking i'm missing fun features of haskell that would make this much easier
20:49:57 <sw17ch> and shorter
20:50:39 <omnId> > let ds = ['0'..'9'] ++ ['a'..'z']; toDigit c = d where Just d = findIndex (c ==) ds; in sum $ zipWith (*) (iterate (*36) 1) (map toDigit "sw17ch")
20:50:41 <lambdabot>  1048409452
20:50:58 <omnId> probably should reverse that
20:51:04 <omnId> > let ds = ['0'..'9'] ++ ['a'..'z']; toDigit c = d where Just d = findIndex (c ==) ds; in sum $ zipWith (*) (iterate (*36) 1) (map toDigit $ reverse "sw17ch")
20:51:06 <lambdabot>  1746856817
20:51:28 <sw17ch> clisp agrees
20:51:40 <sw17ch> :t zipWith
20:51:42 <lambdabot> forall a b c. (a -> b -> c) -> [a] -> [b] -> [c]
20:51:42 <omnId> sum (zipWith (*) powersOfBase (map toDigitsAtBase (reverse yourString)))
20:51:48 <omnId> @src zipWith
20:51:49 <lambdabot> zipWith f (a:as) (b:bs) = f a b : zipWith f as bs
20:51:49 <lambdabot> zipWith _ _      _      = []
20:51:58 <omnId> zipWith (*) is elementwise multiply
20:52:09 <omnId> > iterate (*36) 1
20:52:10 <lambdabot>  [1,36,1296,46656,1679616,60466176,2176782336,78364164096,2821109907456,10155...
20:52:17 <omnId> powers of 36
20:52:33 <sw17ch> oh cool
20:52:54 <sw17ch> wait... how does iterate work?
20:52:56 <sw17ch> :t iterate
20:52:57 <lambdabot> forall a. (a -> a) -> a -> [a]
20:53:09 <Olathe> @src iterate
20:53:09 <lambdabot> iterate f x =  x : iterate f (f x)
20:53:10 <omnId> iterate f x = x : iterate f (f x)
20:53:21 <sw17ch> iterate (+1) 1
20:53:23 * omnId defeats LB once again!
20:53:40 <omnId> > iterate (+1) 1 -- forgot the >
20:53:42 <lambdabot>  [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,...
20:53:43 <Olathe> > iterate ('a':) ''
20:53:43 <lambdabot>  Improperly terminated character constant at "''" (column 16)
20:53:54 <Olathe> > iterate ('a':) ""
20:53:56 <lambdabot>  ["","a","aa","aaa","aaaa","aaaaa","aaaaaa","aaaaaaa","aaaaaaaa","aaaaaaaaa",...
20:54:18 <Olathe> > iterate ('A':) "A !"
20:54:19 <lambdabot>  ["A !","AA !","AAA !","AAAA !","AAAAA !","AAAAAA !","AAAAAAA !","AAAAAAAA !"...
20:54:38 <sw17ch> why am i having such a hard time seeing what it actually does :(*
20:54:44 <omnId> ('A':) looks like a 2ch face.
20:55:15 <omnId> sw17ch: do you get map toDigit (reverse string)?
20:55:25 <Olathe> sw17ch: It does [a, f(a), f(f(a)), f(f(f(a))), ...]
20:55:28 <oerjan> > iterate (\s -> "f("++s++")") "x"
20:55:28 <conal> any QC2 users here?
20:55:29 <lambdabot>  ["x","f(x)","f(f(x))","f(f(f(x)))","f(f(f(f(x))))","f(f(f(f(f(x)))))","f(f(f...
20:55:41 <sw17ch> omnId: yes
20:55:55 <conal> i.e., QuickCheck 2?
20:55:59 <omnId> sw17ch: oh, were you asking about the whole thing or just iterate?
20:56:11 <sw17ch> > take 5 $ iterate (*2) 1
20:56:12 <lambdabot>  [1,2,4,8,16]
20:56:15 <sw17ch> ah, i see now
20:56:16 <sw17ch> =)
20:56:23 <sw17ch> Olathe: thanks
20:56:27 <Olathe> Heh.
20:56:40 <Olathe> (to oerjan's example)
20:56:47 <Olathe> sw17ch: You're welcome.
20:56:49 <sw17ch> omnId: I think i get your implementation of base 36. as most things in haskell, i have to think about it for a bit
20:56:58 <omnId> =)
20:58:26 <sw17ch> > [x | x <- (iterate (*2) 1), x < 100]
20:58:30 <lambdabot> Terminated
20:58:48 <sw17ch> :(
20:59:00 <sclv> > concat $ iterate ( "help, i'm trapped in a fixpoint that starts '"++) []
20:59:02 <lambdabot>  "help, i'm trapped in a fixpoint that starts 'help, i'm trapped in a fixpoin...
20:59:26 <sw17ch> sclv: fantasitc
20:59:45 <oerjan> > takeWhile (< 100) $ iterate (*2) 1
20:59:45 <omnId> sw17ch: I think it stops once it hits 100 and keeps computing, only to discard all of them.
20:59:46 <lambdabot>  [1,2,4,8,16,32,64]
21:00:06 <omnId> filter + inf lists = eventual _|_
21:00:34 <omnId> takeWhile stops as soon as it gets a counterexample
21:00:46 <sw17ch> omnId: i've been looking for that. thank you
21:01:10 <omnId> sw17ch: if you do the list comp in ghci, it'll do up to 99 then hang.
21:01:25 <sw17ch> omnId: GHC just finished recompiling ... :(
21:01:28 <sw17ch> that took forever
21:01:54 <omnId> Prelude> [x | x <- (iterate (*2) 1), x < 100]
21:01:54 <omnId> [1,2,4,8,16,32,64 (it hangs here)
21:01:56 <sw17ch> oh, never mind, not done
21:02:32 <sw17ch> @src gcd
21:02:32 <lambdabot> gcd 0 0 = error "Prelude.gcd: gcd 0 0 is undefined"
21:02:32 <lambdabot> gcd x y = gcd' (abs x) (abs y)
21:02:32 <lambdabot>    where gcd' a 0  =  a
21:02:32 <lambdabot>          gcd' a b  =  gcd' b (a `rem` b)
21:03:27 <omnId> that's the first I've seen @src give error "..." instead of undefined
21:03:36 <sw17ch> > takeWhile (<100) $ [(x,y) | x <- [1..], y <- [1..(x-1)], gcd x y == 1]
21:03:37 <lambdabot>   add an instance declaration for (Num (t, t))
21:04:07 <oerjan> omnId: may be from ghc source rather than the report?
21:04:26 <sw17ch> oh, dumb
21:05:02 <sw17ch> > takeWhile (<100 $ fst) $ [(x,y) | x <- [1..], y <- [1..(x-1)], gcd x y == 1]
21:05:03 <lambdabot>      The operator `<' [infix 4] of a section
21:05:03 <lambdabot>         must have lower preceden...
21:05:15 <oerjan> > takeWhile ((<100).fst) $ [(x,y) | x <- [1..], y <- [1..(x-1)], gcd x y == 1]
21:05:15 <omnId> sw17ch: ((<100) . fst)
21:05:16 <lambdabot>  [(2,1),(3,1),(3,2),(4,1),(4,3),(5,1),(5,2),(5,3),(5,4),(6,1),(6,5),(7,1),(7,...
21:05:58 <sw17ch> omnId: I still don't quite understand function composition... is it just syntactic sugar?
21:06:09 <omnId> sw17ch: it's just a function
21:06:11 <Cale> sw17ch: It's just an ordinary function
21:06:13 <omnId> @src (.)
21:06:14 <lambdabot> (.) f g x = f (g x)
21:06:17 <Cale> (f . g) x = f (g x)
21:06:27 <omnId> that's the entire definition
21:06:35 <oerjan> > nubBy (((>1).).gcd) [2..] -- obligatory example
21:06:37 <lambdabot>  [2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71,73,79,83,89,97,101,...
21:06:46 <Cale> (I don't know why it's not defined my way in @src, since my definition is a valid Haskell definition)
21:07:24 <omnId> oerjan: I think @src gets built from GHC source with a USE_REPORT_PRELUDE macro #defined, it seems gcd doesn't have an alternative.
21:07:25 <Cale> It's usually a good idea to separate the . from the things it's combining with a space.
21:07:47 <Cale> This is because for some silly reason, . is also the module path separator.
21:07:58 * serishema appears
21:08:03 <Cale> Hello!
21:08:11 <sw17ch> so, the same effect of (a.b) x can be had by a(b(x))
21:08:18 <omnId> sw17ch: yes.
21:08:26 <omnId> sw17ch: that's the definition of (.)
21:08:37 <omnId> (a . b) x = a (b x)
21:08:38 <serishema> I want to define a function that takes two values and an operator and returns a stack
21:09:03 <serishema> and the values should be able to be eaither Integer or Double with it figuring it  out by itself
21:09:04 <sw17ch> > takeWhile ((<100).fst) $ [(x,y) | x <- [1..], y <- [1..(x-1)], gcd x y == 1]
21:09:06 <lambdabot>  [(2,1),(3,1),(3,2),(4,1),(4,3),(5,1),(5,2),(5,3),(5,4),(6,1),(6,5),(7,1),(7,...
21:09:11 <omnId> serishema: takes a stack too?
21:09:21 <sw17ch> i suppose in that case it would be a little tough to represent that without the (.)
21:09:29 <Cale> serishema: a stack represented using nested tuples or a list?
21:09:31 <monorobot> What is a stack?
21:09:35 <omnId> sw17ch: (\x -> fst x < 100)
21:09:43 <serishema> Cale: as a list because i understand how lists work
21:09:57 <Cale> serishema: If you want to put different kinds of things on your stack, you'll probably want to create a datatype for the different possible cases.
21:10:21 <serishema> I tried going type Number = (Double,Int) to start off with
21:10:28 <omnId> sw17ch: (((<100) . fst) x), by definition of (.) expands to: (<100) (fst x), then you apply the section and get: fst x < 100
21:10:36 <Cale> So, for exaple,  data Item = I Integer | D Double | S String
21:10:45 <Cale> (to start off with)
21:10:52 <monorobot> haha
21:10:57 <serishema> ah the | operator
21:11:00 <serishema> hmm
21:11:06 <serishema> I should go look at the docs again
21:11:09 <omnId> serishema: it's datatype declaration syntax
21:11:10 <Cale> | is not an operator, it's just part of the syntax of data
21:11:17 <serishema> ah
21:11:27 <Cale> The I, D, S are called data constructors
21:11:35 <Cale> an example of a value of type Item
21:11:38 <salierix> Damn, there is no ghc 6.8.1 snapshot for linux yet...
21:11:43 <Cale> is, say  S "hello", or I 56
21:11:57 <serishema> I'm back at haskell again because i'm hoping i'll be able to write an interpreter really quickly as compared to doing it in say java or php.
21:12:09 <serishema> unfortunately this may not pan out because i don't really know what i'm doing :/
21:12:14 <Cale> It simply marks the type involved so that you can tell between the cases.
21:12:18 <sw17ch> serishema: using parsec?
21:12:24 <serishema> parsec?
21:12:35 <Cale> parsec is a nice library for writing parsers
21:12:42 <monorobot> You will eventually parse. But it's easy. Even without library support.
21:12:57 <serishema> hmm sounds promising
21:13:03 <serishema> I don't want deployment issues
21:13:05 <sw17ch> it's quite nice
21:13:21 <sw17ch> :t parse
21:13:23 <lambdabot> Not in scope: `parse'
21:13:23 <serishema> and what i want to make isn't that complicated
21:13:26 <Cale> Parsec comes with GHC, it's in Text.ParserCombinators.Parsec
21:13:34 <oerjan> :t Text.ParserCombinators.Parsec.parse
21:13:36 <lambdabot> forall tok a. Text.ParserCombinators.Parsec.Prim.GenParser tok () a -> Text.ParserCombinators.Parsec.Pos.SourceName -> [tok] -> Either Text.ParserCombinators.Parsec.Error.ParseError a
21:13:44 <Cale> But yeah, you can probably just do the parsing by hand for a simple stack language.
21:13:46 <serishema> oh ok.
21:13:50 <monorobot> I have long used the ReadS way (and noting it can be monadized, and I monadized it) long before I switched to Parsec.
21:13:52 <sw17ch> ah, i forgot that the type signature is ... long
21:14:20 <serishema> it's a really simple spreadsheet like formula thing
21:14:23 <sorear> sw17ch: it's a bit nicer when you import the modules
21:14:39 <sw17ch> sorear: never used lambdabot before (to be honest)
21:14:40 <Cale> serishema: Haskell?
21:14:46 <omnId> GenParser tok () a -> SourceName -> [tok] -> Either ParseError a
21:14:50 <Cale> serishema: It is rather like that?
21:14:56 <Cale> er, no "?"
21:14:58 <Cale> serishema: It is rather like that.
21:15:16 <sw17ch> hmm... also, what does the () represent.. i see that all over, and haven't quite figured out what it means
21:15:17 <omnId> sw17ch: she listens to /msgs.  Use the @help and @list commands to fool around.
21:15:26 <Olathe> > ("Parentheses ?)
21:15:27 <lambdabot> Unbalanced parentheses
21:15:35 <Cale> sw17ch: () is a type which has only one defined value which is ()
21:15:38 <omnId> sw17ch: () (prounouced unit) is a simple type with one value: ()
21:15:59 <Olathe> Quite a bit of confusion with that error message. It should say unterminated string.
21:15:59 <Cale> It also has one undefined value, because you can't avoid having things like infinite loops.
21:16:16 <sw17ch> hmm... what is it good for
21:16:22 <wli> But does it really make sense for () to be pointed?
21:16:26 <omnId> it's basically useless as is, but you can put it into places where more complicated types might be used instead
21:16:28 <Olathe> "Unbalanced parentheses ?! But they are balanced !"
21:16:31 <Cale> sw17ch: For when you need a type which means "nothing interesting here"
21:16:46 <Cale> sw17ch: If you know C, it serves a similar purpose as void.
21:16:59 <monorobot> For example putStr :: String -> IO ()
21:17:04 <sw17ch> similar to the _ pattern matching?
21:17:11 <oerjan> Olathe: it's a precheck in @run before sending to the compiler
21:17:29 <Cale> monorobot's example is good
21:17:38 <oerjan> > (1+2
21:17:39 <lambdabot> Unbalanced parentheses
21:17:42 <Olathe> I know, but it's still confusing.
21:17:54 <Cale> putStr takes a String and returns an IO action which when run, produces an uninteresting value.
21:18:02 <Cale> It's the side effects you're interested in there.
21:18:07 <oerjan> it seems they fixed the bug that made it purely character based
21:18:28 <omnId> sw17ch: for parse, the GenParser type constructor *can* have an arbitrary state that gets used during parsing, but if you don't have any parser state, use () to fill the parser state parameter to say "no I don't want a stateful parser"
21:18:32 <sw17ch> i see... so if IO were to have an interesting value, it would have something like IO (Int)
21:18:32 <oerjan> > ("or ) what")
21:18:34 <lambdabot>  "or ) what"
21:18:38 <Cale> right
21:18:51 <Cale> IO Int, the parens aren't required
21:18:59 <sw17ch> ah, thanks
21:19:47 <sw17ch> I can't remember the last time any language had such a steep learning curve and such a fantastic payoff when you finally "get it"...
21:20:05 <Cale> Probably your first programming language :)
21:20:10 <monorobot> @unlearn
21:20:10 <lambdabot> http://www.haskell.org/learning.html
21:20:14 <Olathe> It should do the innermost nested opening character as the one it complains about.
21:20:15 <monorobot> @quote unlearn
21:20:15 <Cale> (whatever that was)
21:20:15 <lambdabot> DukeDave says: Haskell has the greatest unlearning curve
21:20:16 <omnId> unlearning is painfully delicious
21:20:29 <Olathe> ("bleh) would then complain about unbalanced quotes.
21:21:24 <ac> why does Data.Map.lookup return a monad, rather than just the value?
21:21:41 <oerjan> ac: if there is no value
21:21:50 <monorobot> so you can make it Maybe, or [], or IO, or ...
21:21:51 <Cale> ac: Because some wise guy thought it would be a good idea to use fail if it doesn't.
21:21:55 <omnId> > lookup 1 (M.fromList [(1,'a'), (2,'b')]) :: Maybe Char
21:21:56 <oerjan> :t Data.Map.Lookup
21:21:56 <lambdabot>  Couldn't match expected type `[(t, Char)]'
21:21:57 <lambdabot> Not in scope: data constructor `Data.Map.Lookup'
21:22:00 <oerjan> :t Data.Map.lookup
21:22:02 <lambdabot> forall k a (m :: * -> *). (Ord k, Monad m) => k -> Data.Map.Map k a -> m a
21:22:03 <jcreigh> ac: well, the value might not actually be there.
21:22:03 <omnId> > lookup (M.fromList [(1,'a'), (2,'b')]) 1 :: Maybe Char
21:22:04 <lambdabot>        add an instance declaration for (Num [(M.Map t Char, Char)])
21:22:10 <Cale> (and MonadZero is no longer with us, for another stupid reason)
21:22:13 <omnId> > M.lookup 1 (M.fromList [(1,'a'), (2,'b')]) :: Maybe Char
21:22:14 <lambdabot>  Just 'a'
21:22:18 <omnId> > M.lookup 3 (M.fromList [(1,'a'), (2,'b')]) :: Maybe Char
21:22:20 <lambdabot>  Nothing
21:22:24 <monorobot> Hehe, yeah, it should be MonadZero.
21:22:30 <omnId> > M.lookup 1 (M.fromList [(1,'a'), (2,'b')]) :: [Char]
21:22:32 <lambdabot>  "a"
21:22:35 <omnId> > M.lookup 3 (M.fromList [(1,'a'), (2,'b')]) :: [Char]
21:22:36 <lambdabot>  ""
21:22:57 <ac> hmm. sow how do I do something simple like an insert of a lookup?
21:23:07 <omnId> M.insert?
21:23:19 <omnId> @type Data.Map.insert
21:23:20 <lambdabot> forall k a. (Ord k) => k -> a -> Data.Map.Map k a -> Data.Map.Map k a
21:23:23 <Cale> ac: If you want, ignore the m, and think of it as Maybe, since that's what you usually want
21:23:40 <monorobot> "insert of a lookup" may fail since the lookup may fail.
21:23:52 <ac> but I'm already doing an "if member ..."
21:24:09 <monorobot> Use the Identity monad or something.
21:24:18 <Cale> ac: ah, you don't have to do that, do you?
21:24:26 <monorobot> Or the Maybe monad but pretend Nothing never happens.
21:24:33 <Cale> You can do the lookup, and decide what to do after
21:24:57 <omnId> do v <- lookup val map1; return (insert somekey v map2)
21:24:58 <oerjan> ac: if lookup is awkward you can use findWithDefault
21:25:02 <monorobot> But my suggestion sucks. Do what Cale says. You were over-complicating.
21:25:21 <ac> findWidthDefault makes sense to me :)
21:25:49 <Olathe> > iterate (\(x:xs) -> x:'u':xs) "Dude !"
21:25:51 <lambdabot>  ["Dude !","Duude !","Duuude !","Duuuude !","Duuuuude !","Duuuuuude !","Duuuu...
21:25:53 * serishema is starting to have some idea what she's doing now
21:25:54 * ac applies bull-headedness to learning Haskell
21:26:22 <serishema> data Token = Input String | Number Integer | Number Double | Operator Char | Output String | Variable String
21:26:34 <serishema> hmm and now i can write myself constructors for those that do something sensible
21:26:54 <serishema> and then build up a parser function that will actually break down an entire stack and pass it to the right constructor?
21:27:36 <omnId> you'll need different names for the Integer and Double constructors
21:28:15 <serishema> omnld: oh, so even if i want to store Integer and Double?
21:28:19 <monorobot> case lookup x m of { Nothing -> m; Just y -> insert x y m }
21:28:42 <monorobot> = m ?  :)
21:29:10 <omnId> monorobot: it doubles a value if found, iiuc
21:29:16 <ac> here we go: countDups l = foldr (\a b -> M.insert a (1 + M.findWithDefault 0 a b) b) M.empty l
21:29:21 <ac> now somebody will tell me that's already defined somewhere
21:29:22 <monorobot> case lookup x m of { Nothing -> m; Just y -> insert x (y*2) m }
21:29:25 <oerjan> omnId: no such thing as doubling
21:29:42 <oerjan> you need insertWith or similar if you want that
21:29:43 <omnId> oh, right
21:30:30 <omnId> liftM (\y -> insert x (y*2) m) (lookup x m)
21:30:42 <omnId> erm...
21:31:10 <omnId> @type liftM (\y -> M.insert x (y*2) m) (M.lookup x m) -- doublechecking the types :)
21:31:12 <lambdabot> Couldn't find qualified module.
21:31:26 <omnId> @type liftM (\y -> M.insert ?x (?y*2) ?m) (M.lookup ?x ?m)
21:31:28 <lambdabot> Couldn't find qualified module.
21:31:28 <oerjan> ac: insertWith could simplify that
21:32:28 <Cale> > map (id &&& length) . group . sort $ "mississippi"
21:32:30 <lambdabot>  [("iiii",4),("m",1),("pp",2),("ssss",4)]
21:32:36 <monorobot> What does insertLookupWithKey do? And updateLookupWithKey? ...  :)
21:32:58 <P_D> @src group
21:32:58 <lambdabot> group = groupBy (==)
21:33:12 <Cale> O(log n). The expression (insertLookupWithKey f k x map) is a pair where the first element is equal to (lookup k map) and the second element equal to (insertWithKey f k x map).
21:33:13 <oerjan> something horrendously complicated, obviously
21:33:23 <monorobot> Oh man, and there is alter, the mother of all map operations!
21:33:28 <Cale> updateLookupWithKey :: Ord k => (k -> a -> Maybe a) -> k -> Map k a -> (Maybe a, Map k a)
21:33:28 <Cale> O(log n). Lookup and update.
21:33:52 <P_D> > map (id . length) . group . sort $ "mississippi"
21:33:53 <lambdabot>  [4,1,2,4]
21:34:17 <P_D> &&& is a fork of sorts?
21:34:21 <monorobot> This Data.Map library has sweetened the pot considerably since last I checked! :)
21:34:23 <Olathe> > map (head &&& length) . group . sort $ "mississippi"
21:34:24 <ac> why does insertWith take a function that takes two arguments?
21:34:25 <lambdabot>  [('i',4),('m',1),('p',2),('s',4)]
21:34:28 <omnId> P_D: (id &&& length) = (\x -> (id x, length x))
21:34:41 <Olathe> @src insertWith
21:34:42 <lambdabot> Source not found. The more you drive -- the dumber you get.
21:34:47 <P_D> @src &&&
21:34:47 <lambdabot> f &&& g = arr (\b -> (b,b)) >>> f *** g
21:34:54 <omnId> ac: to combine two elements with clashing keys.
21:34:56 <P_D> @src ***
21:34:56 <lambdabot> f *** g = first f >>> second g
21:35:03 <P_D> @src >>>
21:35:03 <lambdabot> Source not found. You speak an infinite deal of nothing
21:35:13 <sw17ch> woo! ghc 6.6.1 emerged and i now have working threading. thanks all that helped
21:35:30 <omnId> > M.fromListWith (++) [(1,"alpha"), (2,"beta"), (1,"gamma")]
21:35:32 <lambdabot>  fromList [(1,"gammaalpha"),(2,"beta")]
21:35:32 <ac> so the "new_value" is what you pass in
21:35:34 <monorobot> insertWith wants such a function because it is useful.
21:36:17 <monorobot> (translation: why ask why?)
21:36:19 <oerjan> ac: insertWith (+) a 1 b would work for you, i think
21:36:43 <ac> oerjan: I was getting there
21:36:52 <sw17ch> does haskell automatically memoize functions?
21:36:52 <oerjan> sorry :)
21:36:58 <monorobot> No.
21:37:08 <sw17ch> monorobot: can it nicely be asked to?
21:37:29 <sw17ch> monorobot: since it seems like it's something that would make sense
21:37:47 <sw17ch> monorobot: assuming you have the memory available
21:39:26 <omnId> http://www.haskell.org/haskellwiki/Memoization
21:39:29 <lambdabot> Title: Memoization - HaskellWiki
21:39:38 <omnId> look at memoFix for some serious black magic :)
21:42:12 <monorobot> No black magic. Intelligent Design by Algebra and Science of Programming.
21:42:20 <monorobot> No Natural Selection either.
21:42:40 <omnId> still seems goat's-bloody
21:42:50 <omnId> @quote goat
21:42:50 <lambdabot> malig says: I have to admit I'm still stunned when "tying the knot" actually works. it's like I just performed the kind of magic that normally requires a lot more goat's blood
21:45:01 <sw17ch> How does one determine the source module of a function like memoize?
21:45:20 <monorobot> Oh, but of course, any sufficiently intelligent design looks like magic, and any algebra beyond the level of Bird's algebra is pretty close to algebra straight from The Book.
21:45:20 <omnId> LB has @index
21:47:06 <sw17ch> @index memoize
21:47:07 <lambdabot> bzzt
21:47:39 <omnId> that page seems to link to R Hinze's papers for memoize, but there's a reddit link that gives a copypaste solution.
21:48:06 <omnId> tabulate bounds f = array bounds [(i,f i) | i <- range bounds]
21:48:07 <omnId> dp bounds f = (memo!) where memo = tabulate bounds (f (memo!))
21:48:49 <sw17ch> the fibonacci example there... if done in a list comprehension, the list is preserved, correct?
21:48:58 <sw17ch> to the point of previous evaluation?
21:49:22 <omnId> data in a toplevel declaration stays resident, yes.
21:49:41 <omnId> in GHC's implementation, as far as I know
21:51:05 <Olathe> @let tower [] = repeat 0; tower (i:is) = tower' is (repeat i); tower' [] xs = xs; tower' (i:is) xs = tower' is result where result = i:zipWith (+) xs result
21:51:08 <lambdabot> Defined.
21:51:38 <Olathe> > tower [2, 1, 0]
21:51:39 <lambdabot>  [0,1,4,9,16,25,36,49,64,81,100,121,144,169,196,225,256,289,324,361,400,441,4...
21:51:51 <Olathe> > tower [6, 6, 1, 0]
21:51:52 <lambdabot>  [0,1,8,27,64,125,216,343,512,729,1000,1331,1728,2197,2744,3375,4096,4913,583...
21:54:35 <wli> How's the representation as a single number supposed to work?
21:56:11 <wli> Wrong tower. Never mind.
21:56:20 <sw17ch> perhaps I'm just missing it, but does the memoizable function actually exist somewhere?
21:56:25 <sw17ch> ah, memoize function
21:57:45 <Pseudonym> > tower [6,6,1,0]
21:57:47 <lambdabot>  [0,1,8,27,64,125,216,343,512,729,1000,1331,1728,2197,2744,3375,4096,4913,583...
21:59:33 <OceanSpray> > tower what?
21:59:40 <lambdabot>   parse error on input `}'
22:00:40 <Pseudonym> @let diffs xs = zipWith (-) (tail xs) xs
22:00:42 <Cale> btw, Math.OEIS is a fun module to add to lambdabot's import list.
22:00:42 <lambdabot> Defined.
22:00:57 <Pseudonym> > map head . iterate diffs $ [ i^4 | i <- [0..] ]
22:00:58 <lambdabot>  [0,1,14,36,24,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...
22:01:07 <Pseudonym> > tower [24,36,14,1,0]
22:01:08 <lambdabot>  [0,1,16,81,256,625,1296,2401,4096,6561,10000,14641,20736,28561,38416,50625,6...
22:02:08 <Olathe> Now, how do you make untower (map (^4) [1..25]) work ?
22:02:37 <Olathe> Ahh.
22:02:39 <Olathe> Nice.
22:02:59 <Cale> http://www.marriedtothesea.com/110107/no-study-hall.gif -- haha
22:04:14 <monorobot> I hope the student is not doing Haskell homework. :)
22:04:27 <Pseudonym> > map chr . tower $ [-41212,22028,-10851,4776,-1788,518,-90,-5,15,-22,29,72]
22:04:29 <lambdabot>  Exception: Prelude.chr: bad argument
22:04:43 <Pseudonym> > tower [-41212,22028,-10851,4776,-1788,518,-90,-5,15,-22,29,72]
22:04:44 <lambdabot>  [72,101,108,108,111,32,119,111,114,108,100,33,-72747,-821983,-5094625,-22865...
22:05:01 <Pseudonym> Aha.
22:05:14 <Pseudonym> > map chr . map (`mod`128) . tower [-41212,22028,-10851,4776,-1788,518,-90,-5,15,-22,29,72]
22:05:15 <lambdabot>  Couldn't match expected type `a -> [a1]'
22:06:01 <Pseudonym> > take 12 . map chr . map (`mod` 128) . tower $ [-41212,22028,-10851,4776,-1788,518,-90,-5,15,-22,29,72]
22:06:03 <lambdabot>  "Hello world!"
22:06:37 <Olathe> > (map head) . (takeWhile (\xs -> all (==0) (take 256 xs))) . (iterate diffs) $ map (^4) [0..]
22:06:41 <lambdabot>  []
22:06:44 <Olathe> :(
22:07:09 <wli> > > let { hanoi :: Integer -> [(Char, Char)] ; hanoi h = hanoi' h 'f' 't' 'r' ; hanoi' 0 _ _ _ = [] ; hanoi' h f t r = (hanoi' (h-1) f r t) ++ (f, t) : (hanoi' (h-1) r t f) } in hanoi 3
22:07:15 <lambdabot>   parse error on input `>'
22:07:32 <wli> > let { hanoi h = hanoi' h 'f' 't' 'r' ; hanoi' 0 _ _ _ = [] ; hanoi' h f t r = (hanoi' (h-1) f r t) ++ (f, t) : (hanoi' (h-1) r t f) } in hanoi 3
22:07:33 <lambdabot>  [('f','t'),('f','r'),('t','r'),('f','t'),('r','f'),('r','t'),('f','t')]
22:07:49 <Pseudonym> > map chr . take 27 . tower $ [-581183910,312689217,-164211594,83443910,-40707889,18914408,-8297001,3403846,-1296830,462801,-165531,71759,-44361,34058,-26646,19675,-13504,8589,-5022,2648,-1215,458,-136,48,-45,43,74]  -- Perl, eat your heart out
22:07:51 <lambdabot>  "Just another Haskell hacker"
22:08:13 <Olathe> > ((map head) . (takeWhile (\xs -> not $ all (==0) (take 256 xs))) . (iterate diffs)) (map (^4) [0..])
22:08:14 <lambdabot>  [0,1,14,36,24]
22:08:17 <oerjan> > foldl' (flip scanl (+)) (repeat 0) $ [6,6,1,0]
22:08:17 <lambdabot>  Couldn't match expected type `(a -> a -> a) -> b -> a -> a -> a'
22:08:23 <Olathe> > ((map head) . (takeWhile (\xs -> not $ all (==0) (take 256 xs))) . (iterate diffs)) (map (^5) [0..])
22:08:25 <lambdabot>  [0,1,30,150,240,120]
22:08:50 <Olathe> > let untower = reverse $ ((map head) . (takeWhile (\xs -> not $ all (==0) (take 256 xs))) . (iterate diffs)) in untower (map (^5) [0..])
22:08:51 <lambdabot>  Couldn't match expected type `[a]'
22:09:11 <Olathe> > let untower = reverse . (map head) . (takeWhile (\xs -> not $ all (==0) (take 256 xs))) . (iterate diffs) in untower (map (^5) [0..])
22:09:12 <lambdabot>  [120,240,150,30,1,0]
22:09:22 <omnId> what is this tower function that I can look it up?
22:09:25 <Olathe> > tower [120,240,150,30,1,0]
22:09:26 <lambdabot>  [0,1,32,243,1024,3125,7776,16807,32768,59049,100000,161051,248832,371293,537...
22:09:38 <Olathe> Here: @let tower [] = repeat 0; tower (i:is) = tower' is (repeat i); tower' [] xs = xs; tower' (i:is) xs = tower' is result where result = i:zipWith (+) xs result
22:09:53 <Olathe> @let untower = reverse . (map head) . (takeWhile (\xs -> not $ all (==0) (take 256 xs))) . (iterate diffs)
22:09:57 <omnId> I saw the definition, I wanted to know a name so I could google it.
22:09:58 <lambdabot> Defined.
22:10:20 <Olathe> Oh. Not sure.
22:10:27 <Olathe> Cale might know.
22:10:39 <Pseudonym> It's the solution to a certain class of IQ question.
22:10:48 <Pseudonym> "What's the next number in this series?"
22:10:52 <Pseudonym> Example:
22:11:01 <Pseudonym> 0  1  4  9  16  25
22:11:04 <Pseudonym> Take the differences:
22:11:14 <Olathe> > untower [0,1,4,9,16,25]
22:11:15 <lambdabot>  [2,1,0]
22:11:17 <Pseudonym>   1  3  5  7
22:11:19 <Pseudonym> Right.
22:11:22 <Olathe> > tower [2,1,0]
22:11:24 <lambdabot>  [0,1,4,9,16,25,36,49,64,81,100,121,144,169,196,225,256,289,324,361,400,441,4...
22:11:27 <Pseudonym>     2   2   2
22:11:36 <oerjan> > foldl' (scanl (+)) (repeat 0) $ [6,6,1,0]
22:11:37 <lambdabot>      Occurs check: cannot construct the infinite type: a = [a]
22:11:37 <lambdabot>       Expected...
22:11:39 <Pseudonym> Take the diagonal down the left, and reverse it.
22:11:54 <Olathe> @let extend = tower . untower
22:11:58 <lambdabot> Defined.
22:11:59 <P_D> Newton's something or other, or?
22:12:05 <Olathe> > extend [1,4,9,16]
22:12:06 <lambdabot>  [1,4,9,16,25,36,49,64,81,100,121,144,169,196,225,256,289,324,361,400,441,484...
22:12:07 <P_D> Neville maybe?
22:12:11 <Pseudonym> > extend [0,1,1,2,3,5,8,13]
22:12:12 <lambdabot>  [0,1,1,2,3,5,8,13,42,189,715,2200,5765,13377,28250,55355,102052,178857,30035...
22:12:19 <oerjan> > foldl' (flip $ scanl (+)) (repeat 0) $ [6,6,1,0]
22:12:21 <lambdabot>  [0,1,8,27,64,125,216,343,512,729,1000,1331,1728,2197,2744,3375,4096,4913,583...
22:12:26 <oerjan> that was it
22:12:28 <Olathe> It's polynomial, so fibs will fail :|
22:12:32 <Pseudonym> Yeah.
22:13:06 <Olathe> > extend $ map (\x -> x^3 + 2*x^2 - 3*x + 4) [1..10]
22:13:08 <lambdabot>  [4,14,40,88,164,274,424,620,868,1174,1544,1984,2500,3098,3784,4564,5444,6430...
22:13:16 <Olathe> > map (\x -> x^3 + 2*x^2 - 3*x + 4) [1..100]
22:13:17 <lambdabot>  [4,14,40,88,164,274,424,620,868,1174,1544,1984,2500,3098,3784,4564,5444,6430...
22:13:31 <oerjan> > foldl' (flip $ scanl (+)) (repeat 0) $ [2,1,0]
22:13:32 <lambdabot>  [0,1,4,9,16,25,36,49,64,81,100,121,144,169,196,225,256,289,324,361,400,441,4...
22:13:50 <Olathe> > foldl' (flip $ scanl (+)) (repeat 0) $ [2,1,1]
22:13:51 <lambdabot>  [1,2,5,10,17,26,37,50,65,82,101,122,145,170,197,226,257,290,325,362,401,442,...
22:13:55 <Olathe> Neat :)
22:14:09 <Pseudonym> > check \a b c -> take 100 (extend [ a*i*i + b*i + c | i <- [0..5] ]) == [ a*i*i + b*i + c | i <- [0..99] ]
22:14:09 <lambdabot>  Parse error at "\a" (column 7)
22:14:17 <Olathe> @let tower = foldl' (flip $ scanl (+)) (repeat 0)
22:14:18 <lambdabot> <local>:9:0:     Multiple declarations of `L.tower'     Declared at: <local>:...
22:14:18 <Pseudonym> ?check \a b c -> take 100 (extend [ a*i*i + b*i + c | i <- [0..5] ]) == [ a*i*i + b*i + c | i <- [0..99] ]
22:14:19 <lambdabot>  OK, passed 500 tests.
22:14:24 <Olathe> Bah :(
22:14:26 <Pseudonym> Woo!
22:14:53 <omnId> awesome :D
22:15:05 <wli> > let linrec start cs = let ans = start ++ [sum a | a <- transpose . zipWith (map . (*)) cs $ tails ans] in ans in take 10 $ linrec [0, 1] [1, 1]
22:15:06 <lambdabot>  [0,1,1,2,3,5,8,13,21,34]
22:15:08 <omnId> > extend [1,4,9,15]
22:15:10 <lambdabot>  [1,4,9,15,21,26,29,29,25,16,1,-21,-51,-90,-139,-199,-271,-356,-455,-569,-699...
22:15:21 <monorobot> Fun. What is the specification of tower?
22:15:45 <P_D> Fit a zeroth order polynomial, subtract, fit a first order polynomial, subtract, etc.
22:15:58 <omnId> it's in the scrollback, it'll take me some time and combination to understand it.
22:15:59 <P_D> but there's a formula for doing it in N steps.
22:16:23 <Olathe> @check \a b c -> (take 100 (extend (map (\i -> a*i^2 + b*i + c) [0..5])) == map (\i -> a*i^2 + b*i + c) [0..100]
22:16:24 <lambdabot> Unbalanced parentheses
22:16:33 <Olathe> @check \a b c -> (take 100 (extend (map (\i -> a*i^2 + b*i + c) [0..5]))) == map (\i -> a*i^2 + b*i + c) [0..100]
22:16:34 <lambdabot>  Falsifiable, after 0 tests: 0, -1, -1
22:16:40 * Olathe sobs.
22:16:59 <Pseudonym> Try [0..99]
22:17:03 <Pseudonym> take 100, remember.
22:17:19 <Olathe> @check \a b c -> (take 100 (extend (map (\i -> a*i^2 + b*i + c) [0..5]))) == (take 100 (map (\i -> a*i^2 + b*i + c) [0..]))
22:17:21 <lambdabot>  OK, passed 500 tests.
22:17:24 <Olathe> Yay !
22:17:56 <omnId> (==) `on` (take 100) :)
22:18:18 <wli> P_D: Stirling numbers?
22:18:41 <P_D> wli: I don't remember, I haven't done it since high school.
22:19:27 <oerjan> monorobot: i simplified it to tower = foldl' (flip $ scanl (+)) (repeat 0)
22:19:39 <monorobot> Newton differences?!
22:19:58 <Olathe> I wonder how to convert [6,6,1,0] into [1,0,0,0] (for 1x^3 + 0x^2 + 0x + 0).
22:20:29 <Olathe> monorobot: I think so.
22:20:30 <monorobot> [6,6,1,0] sounds like more GHC version! :)
22:20:32 <oerjan> Olathe: i recall binomial coefficients are involved
22:20:36 <Olathe> monorobot: Heheh.
22:20:43 <P_D> I have it in my notes somewhere
22:20:54 <wli> Converting Newton series to power series is Stirling numbers.
22:21:07 <monorobot> fun fun fun
22:21:39 <wli> Converting power series to Newton series is binomial coefficients.
22:21:55 <Pseudonym> First or second kind?
22:22:04 <wli> Second kind IIRC.
22:22:27 <wli> The first kind don't crop up all that often anyway.
22:22:46 <Pseudonym> One of the few cases where sequels are better.
22:23:08 <P_D> Here it is
22:23:30 <P_D> jth newton term * (x choose j)
22:23:31 <wli> In the sequel, "Stirling number" will refer to Stirling numbers of the second kind unless otherwise stated.
22:24:16 <P_D> Maybe stirling numbers gives you the power series with out mixed up terms?
22:24:18 <omnId> @check \a b c -> let poly = map (\i -> a*i^2 + b*i + c) in on (==) (take 100) (extend (poly [0..5])) (poly [0..])
22:24:19 <lambdabot>  OK, passed 500 tests.
22:24:21 <Cale> Yeah, those are the good kind anyway :)
22:24:54 <Pseudonym> @let binomial n k = product [k+1..n] `div` product [1..n-k]
22:24:57 <lambdabot> Defined.
22:25:12 <wli> That is so the wrong way.
22:25:12 <Cale> Half of the Stirling numbers of the first kind are negative, and who ever heard of a negative number anyway? ;)
22:25:32 <P_D> Seriously
22:25:39 <Pseudonym> @let stirling n k = sum [ (-1)^i * binomial k i * (k-i)^n | i <- [0..k] ] `div` product [1..k]
22:25:45 <lambdabot> Defined.
22:25:48 <Pseudonym> > stirling 3 1
22:25:49 <lambdabot>  1
22:25:49 <Pseudonym> > stirling 3 2
22:25:51 <lambdabot>  3
22:25:53 <Pseudonym> > stirling 3 3
22:25:54 <lambdabot>  1
22:25:58 <Pseudonym> Test cases check.
22:26:20 <Pseudonym> > [ stirling 5 k | k <- [0..5] ]
22:26:21 <lambdabot>  [0,1,15,25,10,1]
22:26:34 <Pseudonym> > [ stirling 6 k | k <- [1..6] ]
22:26:36 <lambdabot>  [1,31,90,65,15,1]
22:26:38 <Pseudonym> Yup.
22:26:56 <wli> n `choose` k | k < 0 || n < 0 = 0 | k == 1 || k == n = 1 | k == 1 || k == n - 1 = n | 2*k > n = n `choose` (n - k) | otherwise = (n * ((n - 1) `choose` (k - 1))) `div` k
22:27:21 <wli> Or something on that order.
22:27:29 <wli> Oh dear please not that for Stirling numbers.
22:27:38 * P_D coughs memoize
22:27:46 <Pseudonym> Hey, it's a one-liner.
22:27:48 <Pseudonym> So don't complain.
22:28:16 <wli> Thst was translated from memoized code with monadic memo table lookups and the whole nine yards.
22:29:08 <P_D> Huh
22:29:21 <Pseudonym> http://andrew.bromage.org/darcs/numbertheory/Math/Combinatorial.hs
22:29:23 <lambdabot> http://tinyurl.com/297scf
22:29:30 <P_D> Oh, I thought it was a sum formula.
22:29:57 <Pseudonym> @let legendre p 0 = 0
22:29:59 <wli> No it was the bloody defining recurrence (which is a damn sight faster than the sum formula).
22:30:02 <lambdabot> Defined.
22:30:12 <Pseudonym> @let legendre p n = let (q,r) = n `divMod` p in s p q + r
22:30:13 <lambdabot> <local>:13:43: Not in scope: `s'
22:30:21 <Pseudonym> @let legendre p n = let (q,r) = n `divMod` p in legendre p q + r
22:30:27 <lambdabot> Defined.
22:30:46 <P_D> Whatever it came from, it's doing a product now
22:31:01 <goalieca> say i wanted to indent every line.. would this be an efficient implementation?
22:31:19 <goalieca> indent input = unlines $ map ('\t' ++ )  $ lines input
22:31:38 <wli> Okay I followed Knuthfor Stirling.
22:31:41 <Pseudonym> @let primesUpTo n = let sieve (p:ps) = p : sieve (filter (\n -> n `mod` p == 0) ps) in takeWhile (<=n) (sieve [2..])
22:31:47 <lambdabot> Defined.
22:31:48 <Pseudonym> > primesUpTo 10
22:31:50 <lambdabot>  [2,4,8]
22:31:52 <wli> 0   `subset`    0   =   1
22:31:52 <wli> 0   `subset`    _   =   0
22:31:52 <wli> n   `subset`    0   =   0
22:31:52 <wli> n   `subset`    1   =   1
22:32:01 <Pseudonym> @let primesUpTo n = let sieve (p:ps) = p : sieve (filter (\n -> n `mod` p /= 0) ps) in takeWhile (<=n) (sieve [2..])
22:32:02 <lambdabot> <local>:14:0:     Warning: Pattern match(es) are overlapped              In t...
22:32:07 <Pseudonym> @let primes n = let sieve (p:ps) = p : sieve (filter (\n -> n `mod` p /= 0) ps) in takeWhile (<=n) (sieve [2..])
22:32:11 <wli> n   `subset`    2   =   2^(n-1) - 1
22:32:11 <wli> n   `subset`    k   |   n == k      =   1
22:32:11 <wli> n   `subset`    k   |   k == n - 1  =   n `choose` 2
22:32:12 <Pseudonym> > primes 10
22:32:13 <lambdabot>   Not in scope: `primes'
22:32:14 <lambdabot> Defined.
22:32:16 <Pseudonym> > primes 10
22:32:17 <lambdabot>  [2,3,5,7]
22:32:17 <wli> n   `subset`    k   |   otherwise   =
22:32:17 <wli>                                 k * (n' `subset` k) + (n' `subset` (k-1))
22:32:17 <wli>                                         where n' = n - 1
22:32:52 <P_D> You had a systematic way to drop that sum?
22:33:06 <wli> P_D: What sum?
22:33:15 <P_D> the last equation
22:33:36 <wli> P_D: Too many equations have flown past to disambiguate that.
22:33:57 <P_D> next term in pascal's triangle = add left and right parents
22:34:32 <goalieca> indent input = unlines $ map ('\t':)  $ lines "a line to be tabbed"
22:34:35 <wli> P_D: For binomial coefficients? Yes, it's obvious. Use factorial expansions.
22:34:38 <goalieca> > unlines $ map ('\t':)  $ lines "a line to be tabbed"
22:34:39 <lambdabot>  "\ta line to be tabbed\n"
22:34:56 <P_D> Right, the product formula.
22:36:13 <Pseudonym> @let factorial n = product . map (\p -> p^((n - legendre p n) `div` (p-1))) . primes $ n
22:36:20 <lambdabot> Defined.
22:36:21 <Pseudonym> > factorial 5
22:36:22 <lambdabot>  120
22:36:35 <P_D> ???
22:36:45 <P_D> Relationship between factorial, legendre polynomials, and primes?
22:36:54 <Pseudonym> No, not Legendre polynomials.
22:37:01 <Pseudonym> It's the Legendre method for computing n!
22:37:14 <P_D> Too many legendre's
22:37:27 <Pseudonym> Not as many as there are Eulers and Gausses.
22:37:48 <P_D> True that
22:38:04 <wli> I have no idea what Pseudonym was doing besides interspersing errors from lambdabot in the midst of the Stirling number paste I was trying to make.
22:38:16 <Pseudonym> Computing factorial.
22:38:34 <geocalc> > last $ primes 999999999
22:38:38 <lambdabot> Terminated
22:38:51 <wli> I havr no idea why you'd try to compute factorials that way.
22:39:02 <P_D> I see a Legendre method for gamma(x) as integral : 0 to 1 :  log (1/t)^(x-1) dt
22:39:03 <Pseudonym> wli: Let me put it this way.
22:39:22 <Pseudonym> @let let n = 100 in map (\p -> (p,(n - legendre p n) `div` (p-1))) . primes $ n
22:39:22 <lambdabot>  Parse error
22:39:34 <P_D> double let
22:39:35 <Pseudonym> @let let n = 100 in map (\p -> (p,(n - legendre p n) `div` (p-1)) . primes $ n
22:39:36 <lambdabot>  Parse error
22:39:37 <wli> Yes, I got that part.
22:39:40 <Pseudonym> Ah.
22:39:50 <Pseudonym> @let n = 100 in map (\p -> (p,(n - legendre p n) `div` (p-1))) . primes $ nA
22:39:51 <lambdabot>  Parse error
22:39:54 <Pseudonym> @let n = 100 in map (\p -> (p,(n - legendre p n) `div` (p-1))) . primes $ n
22:39:54 <lambdabot>  Parse error
22:39:58 <Pseudonym> Gah.
22:39:59 <omnId>  >
22:40:08 <Pseudonym> > n = 100 in map (\p -> (p,(n - legendre p n) `div` (p-1))) . primes $ n
22:40:09 <lambdabot>  Parse error at "=" (column 3)
22:40:09 <Pseudonym> Yes.
22:40:17 <Pseudonym> > let n = 100 in map (\p -> (p,(n - legendre p n) `div` (p-1))) . primes $ n
22:40:19 <lambdabot>  [(2,97),(3,48),(5,24),(7,16),(11,9),(13,7),(17,5),(19,5),(23,4),(29,3),(31,3...
22:40:19 <Pseudonym> OK.
22:40:30 <Pseudonym> Note that each number fits in an Int.
22:40:35 <Pseudonym> > let n = 1000 in map (\p -> (p,(n - legendre p n) `div` (p-1))) . primes $ n
22:40:37 <lambdabot>  [(2,994),(3,498),(5,249),(7,164),(11,98),(13,81),(17,61),(19,54),(23,44),(29...
22:40:39 <Pseudonym> Still fits.
22:40:56 <wli> sure
22:41:07 <Pseudonym> Now imagine that you wanted to compute binomial coefficients.
22:41:19 <Pseudonym> No large integer divisions.
22:42:16 <wli> You're stuck factoring the lower index somehow to make use of that.
22:42:44 <Pseudonym> Not really.
22:42:57 <wli> Fine. Explain how it's used.
22:43:00 <Pseudonym> @let facseries n = map (\p -> (p,(n - legendre p n) `div` (p-1))) . primes $ n
22:43:07 <lambdabot> Defined.
22:43:21 <Pseudonym> You compute facseries n, facseries k and facseries (n-k).
22:43:25 <Pseudonym> Do a bunch of list merges.
22:43:31 <Pseudonym> Lazy ones.
22:43:39 <Pseudonym> Then do the product, bottom-up.
22:44:53 <wli> Okay. That will do.
22:45:10 <Pseudonym> Right.  And, moreover, it works for arbitrary multinomials.
22:45:32 <wli> Multinomial coefficients of arbitrary arity, you mean?
22:45:36 <Pseudonym> Yes.
22:47:00 <wli> Sounds potentially useful.
22:47:12 <geocalc> > facseries 215.957
22:47:13 <lambdabot>  Add a type signature
22:48:01 <Pseudonym> > gamma 216.957
22:48:02 <lambdabot>   Not in scope: `gamma'
22:49:34 <P_D> @let loggamma z = (z - 0.5) * log z - z + ((log (2 * pi)) / 2)
22:49:41 <lambdabot> Defined.
22:49:54 <P_D> > exp (loggamma 5)
22:49:55 <lambdabot>  23.603833591517997
22:50:05 <geocalc> > facseries 215
22:50:07 <lambdabot>  [(2,209),(3,103),(5,52),(7,34),(11,20),(13,17),(17,12),(19,11),(23,9),(29,7)...
22:50:15 <P_D> > exp (loggamma 200)
22:50:15 <wli> > exp (loggamma (0 :+ 1))
22:50:16 <lambdabot>  Infinity
22:50:20 <lambdabot>  (-0.11096769457250333) :+ (-0.5091239800499059)
22:50:31 <Pseudonym> > exp (loggamma 0.5)
22:50:33 <lambdabot>  1.5203469010662807
22:50:37 <Pseudonym> > sqr $ exp (loggamma 0.5)
22:50:38 <lambdabot>   Not in scope: `sqr'
22:50:51 <Pseudonym> > (^2) $ exp (loggamma 0.5)
22:50:52 <lambdabot>  2.311454699581843
22:50:52 <wli> That's a wrong answer for Gamma(i).
22:51:03 <Pseudonym> And that's a wrong answer for gamma (0.5).
22:51:09 <Pseudonym> gamma 0.5 == sqrt pi
22:51:12 <wli> Yeah.
22:51:20 <P_D> well, yeah, it's only good for very large and very small z
22:51:43 <P_D> someone define the bernoulli numbers and you can add some more terms
22:53:13 <wli> Use the Lanczos approximation to the gamma function.
22:53:34 <P_D> lanczos is a bad ass
22:53:44 <P_D> grossly underappreciated
22:55:45 <wli> let bigGamma z = sqrt (2*pi) * (z + g - 1/2)**(z - 1/2) * exp (negate $ z + g - 1/2) * bigA g z where bigA g z = ...
22:57:05 <P_D> getting too hard to crunch these functions into @let =)
22:57:56 <wli> Well, it takes a bit more work for all this.
22:58:14 <wli> wikipedia seems to have enough material on it that you should be able to go on it.
22:59:33 <phlpp> hi
23:00:20 <wli> P_D: Wow, yet another victim of anticommunism. I had no idea.
23:00:40 <P_D> wli:  Lanczos?
23:01:18 <wli> P_D: Yeah.
23:01:52 <phlpp> anticommunism?
23:01:57 <wli> (Granted, he seems to have made it out largely intact, unlike many, but anyhow.)
23:02:03 <phlpp> some NeoCon badword? :>
23:02:09 <P_D> wli:  his thesis is almost readable.  He constructs electrodynamics through complex analysis where charges are singularities
23:02:40 <P_D> "biquaternionic field theory"
23:02:54 <phlpp> sounds difficult
23:03:16 <P_D> it's equivalent to the usual theory, so, yes, but ultimately no.
23:03:27 <wli> It just means a function whose values are pairs of quaternions.
23:04:13 <wli> (Presumably its domain is either quaternions, pairs thereof, or 3-vectors.)
23:04:44 <P_D> it would have to be minkowski space, 4-vectors
23:04:49 <P_D> since it's relativistic.
23:05:09 <wli> That may or may not count as a domain consisting of single quaternions.
23:05:26 <wli> phlpp: You just need to get used to the jargon.
23:05:31 <Pseudonym> @let mul1 (a:as) bs'@(b:bs) = a*b : zipWith (+) (mul1 as bs') (mul1 (a : repeat 0) bs)
23:05:38 <wli> phlpp: "biquaternionic" = two quaternions
23:05:39 <lambdabot> Defined.
23:06:04 <Pseudonym> @let mul2 (a:as) bs'@(b:bs) = mul1 a b : zipWith (+) (mul2 as bs') (mul2 (a : repeat (repeat 0)) bs)
23:06:12 <lambdabot> Defined.
23:06:25 <wli> phlpp: "field" is typically a vector field or analogue thereof. For quaternions it would be something like a quaternion-valued function of quaternions.
23:07:00 <Pseudonym> @let safediv 0 0 = 1
23:07:09 <Pseudonym> @let safediv n d = n%d
23:07:09 <lambdabot> Defined.
23:07:11 <wli> phlpp: "theory" is just tacked on to make it sound right. It's the theory of quaternion-valued functions of quaternion variables.
23:07:17 <lambdabot> Defined.
23:08:03 <Pseudonym> @let diff1 (_:as) = zipWith (*) as [1..]
23:08:05 <wli> phlpp: You could say "biquaternionic fields" to leave out "theory," but it'd sound unusual.
23:08:11 <lambdabot> Defined.
23:09:11 <wli> phlpp: Call it the etymological approach to reading paper titles.
23:10:33 <Pseudonym> @let diff2 as = map (\a -> zipWith (+) (diff1 a) (zipWith (*) [0..] a)) as
23:10:42 <lambdabot> Defined.
23:11:34 <Pseudonym> Ah, I see a problem with my theory.
23:12:05 <Pseudonym> > diff2 ([(-1),1] ++ repeqt 0)
23:12:05 <lambdabot>   Not in scope: `repeqt'
23:12:07 <Pseudonym> > diff2 ([(-1),1] ++ repeat 0)
23:12:07 <lambdabot>   add an instance declaration for (Num [a])
23:12:12 <Pseudonym> > diff2 ([(-1),1] ++ repeat [0])
23:12:12 <lambdabot>   add an instance declaration for (Num [a])
23:12:13 <lambdabot>     In the expression: 1
23:12:24 <Pseudonym> > diff2 ([(-1),1] ++ repeat 0 : repeat [0])
23:12:25 <lambdabot>   add an instance declaration for (Num [a])
23:12:25 <lambdabot>     In the expression: 1
23:12:40 <Pseudonym> > diff2 (([(-1),1] ++ repeat 0) : repeat [0])
23:12:42 <lambdabot>  [[1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...
23:12:51 <P_D> @let loggamma z = (z - 0.5) log z - z + (0.5* log (2 * pi)) + 1/(12*z) - 1/(360*z^3) + 1/(1260*z^5) - 1/(1680 *z^7)
23:12:52 <lambdabot> <local>:26:0:     Multiple declarations of `L.loggamma'     Declared at: <loc...
23:12:57 <P_D> @let loggamma2 z = (z - 0.5) log z - z + (0.5* log (2 * pi)) + 1/(12*z) - 1/(360*z^3) + 1/(1260*z^5) - 1/(1680 *z^7)
23:12:58 <lambdabot> <local>:26:28:     Occurs check: cannot construct the infinite type:       t ...
23:13:27 <Pseudonym> > diff2 [[(-1),1]]
23:13:29 <lambdabot>  [[1]]
23:13:35 <oerjan> missing *
23:13:52 <goalieca> @src lines
23:13:52 <lambdabot> Source not found. I am sorry.
23:13:52 <P_D> @let loggamma2 z = (z - 0.5)*log z - z + (0.5* log (2.0 * pi)) + 1/(12.0*z) - 1/(360.0*z^3) + 1/(1260.0*z^5) - 1/(1680 *z^7)
23:13:55 <P_D> thanks
23:13:59 <goalieca> @src unlines
23:14:02 <lambdabot> Defined.
23:14:02 <lambdabot> unlines = concatMap (++ "\n")
23:14:08 <Pseudonym> > eval0 = sum . map head
23:14:08 <lambdabot>  Parse error at "=" (column 7)
23:14:13 <Pseudonym> @let eval0 = sum . map head
23:14:17 <P_D> > exp $ loggamma2 (0.5)
23:14:21 <lambdabot>  1.6696087655475824
23:14:24 <lambdabot> Defined.
23:14:24 <P_D> > (exp $ loggamma2 (0.5))^2
23:14:26 <lambdabot>  2.787593429993322
23:15:45 <Pseudonym> @let rdiff (p,q) = (zipWith (-) (mul2 q (diff2 p)) (mul2 p (diff2 q)), mul2 q q)
23:15:54 <lambdabot> Defined.
23:16:19 <Pseudonym> @rdiff ([[0,1]], [-1,1])
23:16:19 <lambdabot> Unknown command, try @list
23:16:22 <Pseudonym> > rdiff ([[0,1]], [-1,1])
23:16:23 <lambdabot>   add an instance declaration for (Num [t])
23:16:23 <lambdabot>     In the expression: rdiff ([[0...
23:16:42 <Pseudonym> > rdiff ([[-1],[1]], [[-1,1]])
23:16:42 <lambdabot>   add an instance declaration for (Num [a])
23:16:42 <lambdabot>     In the expression: rdiff ([[-...
23:16:59 <Pseudonym> Damn.
23:17:12 <oerjan> > [rdiff,()]
23:17:12 <lambdabot>  Couldn't match expected type `([[a]], [[a]]) -> ([[a]], [[a]])'
23:17:18 <P_D> @let loggamma3 z = (z+0.5)*log(z+0.5) - (z+0.5)+0.5*log(2*pi)-(1/12.0)*(1/(2*z+1) + (7/360.0)*(1/(2*z+1))^3 - (31.0/1260)*(1/(2*z+1))^5
23:17:18 <lambdabot>  Parse error
23:17:34 <P_D> @let loggamma3 z = (z+0.5)*log(z+0.5) - (z+0.5)+0.5*log(2*pi)-(1/12.0)*(1/(2*z+1)) + (7/360.0)*(1/(2*z+1))^3 - (31.0/1260)*(1/(2*z+1))^5
23:17:44 <lambdabot> Defined.
23:18:01 <P_D> > exp $ loggamma3 $ sqrt $ succ $ 0.5
23:18:03 <lambdabot>  1.1169271555965434
23:18:08 <P_D> > exp $ loggamma3 $ sqrt $ pred $ 0.5
23:18:10 <lambdabot>  NaN
23:18:27 <P_D> > (^2) $ exp $ loggamma3 $ succ $ 0.5
23:18:28 <lambdabot>  1.7671334390862066
23:18:51 <P_D> > (^4) $ exp $ loggamma3 $ succ $ 0.5
23:18:53 <lambdabot>  3.1227605915366436
23:24:58 <Pseudonym> @let bernoulli 0 = 1%1
23:25:08 <lambdabot> Defined.
23:25:11 <Pseudonym> @let bernoulli n = 1%(n+1) * sum [ (-1)^j * (fromIntegral j)^n * (binomial (n+1) (k-j) % binomial n k) | k <- [1..n], j <- [1..k] ]
23:25:21 <lambdabot> Defined.
23:25:25 <Pseudonym> > [ bernoulli i | i <- [0..10] ]
23:25:26 <lambdabot>  [1%1,(-1)%2,1%6,0%1,(-1)%30,0%1,1%42,0%1,(-1)%30,0%1,5%66]
23:25:36 <wli> Where do you get these horribly inefficient series expansions?
23:25:46 <Pseudonym> Mathematica!
23:25:59 <Pseudonym> But my attempt at an efficient one didn't work.
23:26:20 <wli> http://holomorphy.com/~wli/Bernoulli.lhs
23:30:12 <Pseudonym> Symbolic differentiation of formal multinomial power series turns out to be hard if you're only allowed to use one-liners.
23:30:34 <wli> Who says you can only use one-liners?
23:30:44 <Pseudonym> The @let command.
23:30:51 <wli> Oh.
23:31:43 <P_D> do auto differentiation
23:36:33 <P_D> > 1.0*(product [2,4..10])*(product [4,6..12])/(product [3,5..11])
23:36:44 <lambdabot>  8511.16883116883
23:36:56 <P_D> > sqrt(1.0*(product [2,4..10])*(product [4,6..12]))/(product [3,5..11])
23:36:58 <lambdabot>  0.90486201176406
23:37:09 <P_D> > sqrt(4.0*(product [2,4..10])*(product [4,6..12]))/(product [3,5..11])
23:37:10 <lambdabot>  1.80972402352812
23:40:25 <geocalc> wli=<< can't you make an index of all your haskell files on your site  ?????????????????
23:42:46 <sjanssen> > nub "?????????????????" -- calm down, geocalc
23:42:48 <lambdabot>  "?"
23:43:42 <geocalc> bad fingers i'm calm
23:47:40 <sjanssen> :)
23:50:46 <quicksilver> @seen ac
23:50:47 <lambdabot> ac is in #haskell. I last heard ac speak 2h 14m 4s ago.
23:56:11 <quicksilver> @quote ten
23:56:11 <lambdabot> sorear says: "Boredom breeds existential pondering"
23:56:15 <quicksilver> @quote ten
23:56:15 <lambdabot> Dijkstra says: It is practically impossible to teach good programming style to students that have had prior exposure to BASIC: as potential programmers they are mentally mutilated beyond hope of
23:56:16 <lambdabot> regeneration.
23:56:21 <quicksilver> @quote imperative
23:56:21 <lambdabot> SamB says: Haskell is the only language I know with first-class support for imperative programming
23:56:25 <quicksilver> @quote imperative
23:56:25 <lambdabot> DavidAmos says: the real reason for using Haskell is that the code comes out shorter, and is quicker to write, than in imperative languages .. What that means is, I can get much more done when I use
23:56:25 <lambdabot> Haskell
23:56:28 <quicksilver> @quote imperative
23:56:29 <lambdabot> DavidAmos says: the real reason for using Haskell is that the code comes out shorter, and is quicker to write, than in imperative languages .. What that means is, I can get much more done when I use
23:56:29 <lambdabot> Haskell
23:56:30 <quicksilver> @quote imperative
23:56:30 <lambdabot> SamB says: Haskell is the only language I know with first-class support for imperative programming
23:56:37 <quicksilver> @remember bos imperative languages only go up to ten
23:56:37 <lambdabot> Done.
