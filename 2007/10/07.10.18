00:02:06 <raxas> olsner: but thats less effective than pure goto. you need to set and analyze some variable to emulate fixed goto
00:02:08 <omnId> olsner: O_o
00:02:25 <omnId> wow
00:02:55 <mauke> raxas: not if the compiler unrolls the loop!
00:03:23 <locomalo> SamB, Hello, Once I asked for discribing hardware with functional languages and you pointed me to funhdl project, thak you for that. Are you using Atom or Lava? Thank you
00:05:01 <omnId> @seen SamB_XP_
00:05:02 <lambdabot> SamB_XP_ is in #haskell-blah and #haskell. I last heard SamB_XP_ speak 4h 50m 43s ago.
00:05:27 <oerjan> @seen SamB
00:05:28 <lambdabot> SamB is in #perl6 and #haskell. I don't know when SamB last spoke.
00:05:39 <raxas> mauke: it cant do that for ackermann
00:06:13 <roconnor> Can someone write a article called ``Effective use of continuations?''
00:07:30 <raxas> mauke: since ackermann is totally recursive function, but not a primitive recursive function
00:07:59 <raxas> and it grows faster than any primitive recursive function
00:08:07 <mauke> ... so?
00:08:16 <mauke> unrolling the loop should still be trivial
00:08:34 <raxas> so it is not possible to predict ack with primitive rec function
00:08:59 <locomalo> omnId, oerjan: If you see him can you tell that I asked that question please? I'm going to sleep now, but I'll leave my client irc conected for a few hours.
00:09:09 <omnId> @help tell
00:09:09 <lambdabot> tell <nick> <message>. When <nick> shows activity, tell them <message>.
00:09:48 <omnId> say @tell SamB <your message>
00:10:25 <locomalo> omnId, thank you, I did't now that feature, I do that
00:10:42 <omnId> @botsnack
00:10:42 <lambdabot> :)
00:11:10 <locomalo> omnId, you are a bot?
00:11:14 <omnId> nah
00:11:20 <omnId> last I checked, anyway
00:11:30 <omnId> @vixen You a bot, LB?
00:11:30 <lambdabot> Plugin `vixen' failed with: IRCRaised getRandItem: empty list
00:11:35 <LeCamarade> Salut, tout le monde.
00:11:35 <omnId> uh oh
00:11:38 <locomalo> omnId, you answered so fast that I thought you where!
00:12:20 <omnId> hehe, the wonders of OMG SOMEONE SAID MY NICK BETTER HIGHLIGHT IT IN BRIGHT RED AND MAKE NOISES OMG OMG!!!
00:13:33 <locomalo> @tell SamB "Hello, Once I asked for discribing hardware with functional languages and you pointed me to funhdl project, thak you for that. Are you using Atom or Lava? Thank you"
00:13:34 <lambdabot> Consider it noted.
00:14:47 <locomalo> lambdabot, you are the best bot I ever seen :)
00:14:59 * locomalo is away: Ausente
00:15:18 <omnId> @. elite keal
00:15:19 <lambdabot> Plugin `compose' failed with: IRCRaised getRandItem: empty list
00:15:54 <omnId> :(
00:23:47 <LeCamarade> All the LB plugins seem to have gone sick o' late.
00:24:08 <oerjan> only those using the quote database, me thinks
00:24:19 <oerjan> it seems to get broken regularly
00:24:21 <LeCamarade> @quote qwe1234
00:24:21 <lambdabot> Plugin `quote' failed with: IRCRaised getRandItem: empty list
00:24:40 <LeCamarade> Sad. I want me some quotes.
00:24:42 <oerjan> > 2+2
00:24:43 <lambdabot>  4
00:26:27 <omnId> @tell omnId2 something
00:26:27 <lambdabot> Consider it noted.
00:26:31 <omnId2> blah
00:26:32 <lambdabot> omnId2: You have 1 new message. '/msg lambdabot @messages' to read it.
00:26:39 <omnId2>  @tell seems fine
00:27:27 <oerjan> @quote arglebargle
00:27:28 <lambdabot> Plugin `quote' failed with: IRCRaised getRandItem: empty list
00:27:59 <oerjan> apparently it doesn't matter if there is no quote
00:29:58 <omnId> how do you know nobody's been quoted saying arglebargle? :)
00:30:09 <oerjan> just a hunch :)
00:34:32 <profmakx> hm. anyone with hints on how to bootstrap 6.8? i have build a collection of .hc files but on the target the build seems to depend on ghc
00:34:44 <takamura> hi
00:36:44 <LeCamarade> Hi.
00:47:22 <bos> ha. try googling for "define concision", and boggle at the result you get.
00:47:57 <bos> i would not have thought of penises as relating to the #1 result.
00:48:10 <dons> ?quit silly bot
00:50:09 <mauke> > take 0 undefined
00:50:11 <lambdabot>  Undefined
00:50:15 <mauke> FAIL
00:50:55 <Jaak> heh. in hugs that return empty list
00:51:06 <Jaak> I assume that's the indended behaviour
00:51:36 <glguy> ?src take
00:51:36 <lambdabot> take n _      | n <= 0 =  []
00:51:36 <lambdabot> take _ []              =  []
00:51:36 <lambdabot> take n (x:xs)          =  x : take (n-1) xs
00:52:02 <yitz> In ghci, take 0 undefined is the empty list also. Silly bot.
00:53:12 <oerjan> i think that was discussed before, it's an optimization bug in ghc's rule for take
00:53:26 <roconnor> wow
00:53:30 <roconnor> that's pretty serious
00:53:31 <masak> dons: lambdabot has somehow fallen out of #bioclipse, and we miss it. do you think you could reinvite it?
00:54:31 <roconnor> > take undefined []
00:54:33 <lambdabot>  Undefined
00:54:46 <nornagon> > take 0 undefined
00:54:47 <lambdabot>  Undefined
00:55:08 <nornagon> i guess f undefined == undefined
00:55:13 <Cale> lambdabot: @join #bioclipse
00:55:21 <yitz> Hmm the first two rules for take are in the wrong order.
00:55:21 <nornagon> but, wait
00:55:31 <nornagon> ah.
00:55:34 <oerjan> > take undefined `seq` False
00:55:35 <nornagon> that would explain it.
00:55:36 <lambdabot>  False
00:55:45 <Jaak> > const 1 undefined
00:55:46 <lambdabot>  1
00:56:16 <Cale> > const undefined `seq` ()
00:56:18 <lambdabot>  ()
00:56:42 <roconnor> @slap seq
00:56:42 <lambdabot> why on earth would I slap seq?
00:57:05 <yitz> Why not? Lennart would slap it.
00:57:50 <Cale> I'm not sure if I really hate seq all that much.
00:58:10 <Cale> It's kind of annoying that const undefined isn't undefined, but also kind of makes some sense.
00:59:00 <roconnor> I've only used seq in cases when I could have used case
00:59:08 <yitz> I like seq the way it is. But I guess that's because I
00:59:41 <yitz> "grew up with it", and I'm not so much into theoretical lambda calculus as some others.
01:00:27 <roconnor> seq probably messes up optimizations?
01:00:43 <yitz> Do I misunderstand the report? Isn't seq semantically identical to "using case"?
01:01:21 <Jaak> > length [1..] `seq` "hai!!1"
01:01:25 <lambdabot> Terminated
01:02:12 <roconnor> yitz: you can't do case analysis on functions
01:02:12 <sjanssen> yitz: yes, except seq is too polymorphic to actually be written with case
01:03:53 <yitz> I'm not sure if seq "messes up" optimizations, or just interferes with them. Using seq means exactly: don't do certain optimizations involving laziness. That could be good or bad; presumably, if you are using seq, you think that's good.
01:04:11 <yitz> But you could be wrong.
01:04:26 <Cale> Maybe seq should be treated as a hint.
01:04:27 <yitz> roconnor, sjanssen: OK, I see.
01:06:23 <sjanssen> Cale: sometimes you need it for error control
01:06:52 <Cale> hmm, doesn't evaluate work better for that?
01:07:34 <sjanssen> perhaps
01:07:54 <sjanssen> the IO type might not be convenient all the time
01:07:59 <yitz> It can't always be just a hint; sometimes you use it as a guarantee. e.g. foldl'
01:09:21 <sjanssen> Cale: actually, par is quite like a hint
01:09:26 <geocalc> hoho you never stop talking here, i love this chan !
01:09:29 <Cale> sjanssen: yeah
01:09:45 <yitz> par?
01:09:58 <sjanssen> yitz: in Control.Parallel
01:09:58 <Cale> par is like seq, but for parallel computation
01:10:14 <Cale> par x y will "spark" x before resulting in y
01:10:54 <yitz> @hoogle par
01:10:54 <lambdabot> Control.Parallel.par :: a -> b -> b
01:10:54 <lambdabot> List.partition :: (a -> Bool) -> [a] -> ([a], [a])
01:10:54 <lambdabot> Data.IntMap.partition :: (a -> Bool) -> IntMap a -> (IntMap a, IntMap a)
01:10:57 <Cale> What that means is essentially that it will add x to a queue of things to be evaluated in parallel by available processors
01:11:31 <yitz> So why is that a only a hint?
01:11:45 <yitz> (and why is it not in IO?)
01:11:53 <Cale> Because it doesn't change semantics.
01:12:03 <Cale> par x y is semantically equivalent to y
01:12:09 <Cale> par undefined y = y
01:12:31 <Cale> (However, you might blow lots of CPU time)
01:13:05 <yitz> par undefined y = (smoke comes out of cpu) `seq` y
01:13:14 <Cale> heh
01:13:47 <pastorn-rr> Cale: so if i wanna do sum [1..100] and product [50..100] in paralell, how do i go about?
01:14:31 <Cale> let x = sum [1..100]; y = product [50..100] in x `par` y `par` (x,y)
01:15:10 <Cale> (assuming you want the results :)
01:15:19 <pastorn-rr> heh
01:15:30 <yitz> Ah. So ideally a compiler should figure that out without par. So par is a hint.
01:15:54 <sjanssen> yes, ideally
01:15:55 <yitz> > product [50..100]
01:15:57 <lambdabot>  1534259378127483018601365229764734869614229860842344479723893493491079479386...
01:16:00 <Cale> Well, sort of. It's kind of unreasonably hard for compilers to automatically parallelise, but yeah.
01:16:45 <Cale> (at least, if you want to push that paralellism down to the level of individual expressions)
01:16:46 <yitz> No, I don't think it's unreasonable for them to do something reasonable in many cases. It's only unreasonable for them to get it exactly right every time.
01:16:52 <Cale> hehe
01:17:05 <yitz> Sort of like automatic memory management.
01:17:17 <Jaak> it's much more difficult than that
01:17:30 <Cale> I think data parallelism is the sensible way forward.
01:17:34 <sjanssen> yitz: the wise men say automatic parallelization is very difficult
01:17:51 <yitz> Doesn't it depend on how you define success?
01:18:25 <yitz> Truth is, memory management is also very difficult. But we just do it anyway, not getting it right, and it helps.
01:18:28 <Cale> Well, you want a reasonable speedup for making use of the multiple CPUs. If you actually end up with slower programs in general, that's bad.
01:18:35 <sjanssen> forking a computation tends to be quite expensive, perhaps larger than the cost of executing serially
01:19:13 <goalieca> well.. especially depending on memory
01:19:15 <yitz> I am envisioning how we will use architechures with, say, megaCPUs. With some built-in parallel hardware for forking to one of the CPUs
01:19:42 <Cale> Data parallelism just lets you use particular data structures, the operations on which are automatically parallelised.
01:19:55 <goalieca> map->reduce hardware?
01:20:05 <Cale> (At the lowest programmer-visible level, parallel arrays)
01:21:07 <pejo> How is the 'forking' implemented, a pool of worker-threads that get the computation scheduled on them, or?
01:21:41 <quicksilver> yes, much like that
01:21:55 <yitz> Why not do it with functions? If you've got a few thousand processors for almost free, just start forking (well, not completely arbitrarily, but with some reasonable but simple algorithm)
01:21:57 <quicksilver> only one 'real' thread per CPU, typically
01:21:58 <Cale> Well, the array sizes are known at the time where it comes to evaluate the elements
01:22:13 <pejo> quicksilver,  where does the 'cost' occur if the threads are pre-allocated?
01:22:37 <Cale> So you split the array up appropriately for the number of CPUs and do the computation on each CPU serially.
01:22:39 <goalieca> wait. forking is different from spawning a thread.
01:22:41 <quicksilver> setting up a new 'computation'
01:22:53 <quicksilver> you can use the word thread at (at least) two different levels of abstraction
01:23:10 <quicksilver> calling forkIO may not set up a new literal hardware thread
01:23:11 <goalieca> a thread shares memory. fork has to make a copy (or do some lazy write scheme)
01:23:14 <Cale> yitz: Because it's impossible to tell where the costly subtrees are
01:23:34 <quicksilver> but it still has to do work to set up the computation context
01:23:41 <quicksilver> goalieca: when we speak of fork, we don't mean that fork
01:23:53 <quicksilver> goalieca: haskell programs almost never use fork() in the unix sense
01:23:57 <pejo> So what we are missing is a calculus for determining the cost of evaluating an expression, much the same information that the inliner would love to have.
01:24:01 <Cale> You can perhaps do something clever to try to record which subtrees were costly in the past and try to parallelise better in the future.
01:24:09 <goalieca> quicksilver, okay. then waht type of thread.. user space or kernel or what
01:24:11 <yitz> I know. But that only matters if it is expensive to fork. If not - just make some reasonable guess.
01:24:13 <quicksilver> goalieca: so you can take me to mean a lightweight (thread) fork
01:24:25 <Cale> yitz: Which it generally is. :)
01:24:26 <quicksilver> goalieca: neither. It's a pseudo-thread
01:24:39 <pejo> goalieca, any 'sensible' OS does some sort of COW
01:24:40 <goalieca> so its scheduled in the main haskell process?
01:24:40 <yitz> Now. But soon it won't be.
01:24:52 <quicksilver> yitz: the cost of setting up a new computation context is MASSIVE compared to the cost of doing a primitive reduction
01:24:54 <Cale> Oh? Why is that?
01:25:03 <quicksilver> (pretending for a moment that GHC is a reduction machine)
01:25:04 <sjanssen> GHC's implementation of par isn't quite so naive as to create a new thread for every spark
01:25:12 <pejo> Cale, as for keeping track of costs - what did the optimistic evaluation do?
01:25:15 <quicksilver> yitz: perhaps 4 orders of magnitude slower?
01:25:22 <quicksilver> maybe more...
01:25:32 <Cale> pejo: Yeah, you could do something like that.
01:25:38 <sjanssen> it inserts the job into a special spark queue, the spark queue is inspected every scheduler tick.  IIRC...
01:26:10 <quicksilver> goalieca: yes, that's right
01:26:23 <quicksilver> goalieca: the main haskell process can use user space threads if you want it to
01:26:24 <Cale> I don't really care much for the idea of optimistic evaluation either, but I've written a lot of programs where optimistic evaluation would do nothing but waste time.
01:26:35 <quicksilver> goalieca: but, traditionally, you only do that if you are actually running on a multi-core machine
01:26:40 <Cale> and I suspect they're not the majority of programs :)
01:26:47 <yitz> quicksilver: OK. But if two processors, with parallel access to memory, automaticly work on both approaches in parallel, what do you lose?
01:26:52 <quicksilver> goalieca: otherwise you have one user-space thread, and a haskell schedular
01:26:54 <pejo> sjanssen, happen to know how often it 'ticks'?
01:27:28 <quicksilver> yitz: I note in passing that 'parallel access to memory' itself slows things down by many orders of magnitude since it invalidates caches...
01:27:37 <sjanssen> pejo: 0.02 seconds, according to +RTS -?
01:27:39 <pejo> Cale, well. I don't think anyone truly believes in optimistic evaluation in the sense we know it today.
01:27:49 <quicksilver> SMp systems have to manage write barriers in their memory management etc...
01:27:58 <yitz> quicksilver: right, I am assuming an architechture that deals with that.
01:28:01 <goalieca> so.. not having a dual core to play around with.. if the haskell is one process doesn't the OS schedule it to just 1 cpu.. implying all lightweights are run on there too?
01:28:13 <quicksilver> goalieca: yes
01:28:20 <quicksilver> goalieca: no
01:28:25 <quicksilver> goalieca: sorry, misread you :)
01:28:41 <quicksilver> goalieca: OSes will schedule user-spae threads on separate CPUs/cores
01:28:46 <sjanssen> goalieca: no, modern OSs can run several threads from the same process in parallel
01:28:50 <quicksilver> sjanssen: 0.02 by defaault yes
01:29:06 <quicksilver> sjanssen: you can change it to 'as fast as possible' though
01:29:18 <quicksilver> which I find is a good plan if you want a responsive UI
01:29:28 <pejo> quicksilver, won't that reduce throughput even more?
01:29:36 <quicksilver> pejo: which?
01:29:37 <goalieca> sjanssen, assuming the os knows about the thread?
01:29:46 <pejo> quicksilver, ticking more often
01:29:53 <goalieca> quicksilver, is there a system call..
01:29:55 <roconnor> @src foldl'
01:29:55 <lambdabot> foldl' f a []     = a
01:29:55 <lambdabot> foldl' f a (x:xs) = let a' = f a x in a' `seq` foldl' f a' xs
01:29:56 <goalieca> how would they know
01:29:56 <quicksilver> pejo: in principle yes
01:29:57 <sjanssen> goalieca: yes.  GHC uses a combination of OS threads and userspace threads
01:30:02 <yitz> In fact, caching is just a special case of what I am suggesting. Once you have megaparallelism, it may turn out to be better to forget that and just make straight memory access as fast as possible in parallel. Then the parellel cpus do today's caching as one of their strategies.
01:30:24 <quicksilver> yitz: you still need write barriers between CPUs
01:30:32 <quicksilver> otherwise they can fight when trying to access the same memory location
01:30:37 <quicksilver> and your code goes non-deterministic
01:30:45 <sjanssen> goalieca: it requests M OS threads (M should be equal to the number of cores on the box), and then schedules N lightweight threads between them
01:30:50 <pejo> yitz, the bandwidth to the memory is definitely not unlimited.
01:31:24 <goalieca> sjanssen, :-) But this model is really dependant on the OS implementation isn't it?
01:31:38 <badf00d5> <- noob: can someone tell me how to use functions from Data (specifically Data.List) in ghci? Documentation fails me
01:31:46 <sjanssen> goalieca: I don't think it requires more than POSIX threads
01:31:52 <quicksilver> badf00d5: :m +Data.List
01:32:10 <badf00d5> quicksilver: awesome, thanx
01:32:19 <quicksilver> goalieca: all OSes I'm aware of these days support a thread model which supports this
01:32:22 <yitz> Yes. Well, let's say our hardware architechure is functional at the low level, not a vonNeumann. So those barriers only apply to the gc.
01:32:25 <geocalc> + why + ?
01:32:36 <quicksilver> geocalc: in case he already has other modules open
01:32:40 <quicksilver> geocalc: don't want to lose them
01:32:49 <geocalc> ok
01:33:15 <quicksilver> yitz: "let's say apples are four-wheel drive vehicles?"
01:33:21 <quicksilver> yitz: these things you speak of don't exist...
01:33:26 <yitz> badf00d5: you can also use them by writing out the module name in full: Data.List.foldl'
01:33:41 * roconnor wonders if supercombinators can be complied to an FPGA
01:33:41 <pejo> Heh, quicksilver took the words out of my mouth.
01:34:09 <yitz> People did build LISP machines in the past. They're not in style now. But you never know :)
01:34:28 <badf00d5> yitz: LISP machines were not VNA?
01:34:35 <quicksilver> LISP is not a pure a language
01:34:38 <yitz> VNA?
01:34:40 <quicksilver> LISP machines were perfectly mutable
01:34:47 <badf00d5> Von-Neumann Architecture?
01:35:00 <quicksilver> I'm not aware of any hardware architecture which supports a basic notion of immutability
01:35:05 <badf00d5> s/?//
01:35:07 <quicksilver> I'm not saying such a thing might not be interesting
01:35:14 <quicksilver> but I think it implies 'GC at the hardware level'
01:35:35 <geocalc> and for multi gpu how do you do parallelism ?
01:36:18 <yitz> yeah, I know. Just an example. My point is that there will need to be a paradigm shift in low-level architechture, no matter how it is done. Current optimizations, like caching parallelism, may or may not exist in the future.
01:36:58 <goalieca> geocalc, currently graphics cards have it built in hardware
01:37:04 <goalieca> or firmware or something
01:37:10 <yitz> So that is not a reason why it is conceptually impossible to do parallelism via functions rather than just the data structures, or other explicit meddling with the parallelizing strategy.
01:37:12 <goalieca> afaik drivers just load tasks
01:37:33 <goalieca> i might be wrong though..
01:38:16 <quicksilver> multi GPUs, in most cases, do a very restricted form a parallelism
01:38:17 <KatieHuber> GPUs can take lots of shortcuts because they know lots about data dependencies (ie, there aren't any)
01:38:23 <quicksilver> where you perform exactly the same calculation
01:38:26 <quicksilver> on a big data set
01:38:39 <quicksilver> that happens to be very useful for graphics
01:38:39 <KatieHuber> and because they're doing exactly the same, simple calculation, massively parallel
01:38:51 <yitz> I don't know the details of LISP machines, but their low-level machine operations where LISP-like, so they were certainly less vonNeumann-like than today's machines.
01:38:58 <KatieHuber> and even then, not *massively* parallel
01:39:08 <quicksilver> of course it can be useful for general computation too. But you need to jump through some hoops.
01:39:10 <KatieHuber> 48 ways on a Radeon X1900 IIRC
01:39:17 <quicksilver> Still there are people working on general computation on GPUs
01:39:32 <quicksilver> simply because GPUs are cheap (ish) commodity hardware and it's fun to play with them
01:39:41 <yitz> quicksilver: that happens to be very useful for everything, not just graphics. It's called referential transparency.
01:39:46 <goalieca> gpu = return of the co-processor?
01:40:00 <quicksilver> goalieca: modern computers have many, many co-processors in
01:40:09 <geocalc> hehe
01:40:13 <KatieHuber> goalieca: absolutely
01:40:57 <quicksilver> graphics, audio, wifi, modem etc
01:41:32 <goalieca> of course. but not quite in the sense of the old FPU
01:41:47 <goalieca> anywho.. bedtime.
01:43:42 <badf00d5> quicksilver: what exactly would hardware-level immutability mean?
01:44:14 <quicksilver> badf00d5: it would mean that you have opcodes for reading but not writing :)
01:44:17 <badf00d5> PROM instead of RAM?
01:44:23 <quicksilver> badf00d5: and, presumably, opcodes for allocating 'new' stuf
01:44:35 <quicksilver> so you allocate new stuff (specifying values) and you read old stuff
01:44:38 <quicksilver> but you never change old stuff
01:44:42 <quicksilver> I guess..
01:44:59 <quicksilver> certainly that would make certain kinds of parallelisation easier
01:45:16 <yitz> LIke massive parallel memory access.
01:45:38 <pejo> quicksilver, oh, definitely. Cache coherency, which you've already mentioned.
01:46:10 <badf00d5> yeah, but you'd have to buy new RAM every few seconds
01:46:31 <geocalc> lol
01:46:59 <yitz> badf00d5: I have to do that now anyway. :)
01:47:44 <quicksilver> badf00d5: right, it would need hardware GC
01:47:49 <quicksilver> badf00d5: as I pointed out :)
01:47:55 <quicksilver> hardware GC would be cute, though
01:48:00 <quicksilver> because the MMU would know about it
01:48:09 <quicksilver> so you could have a copying-collector without pointers actualy moving
01:48:19 <haraldk> All these virtual machines with GC, aren't they a hint that a real machine with GC would be nice? :-)
01:48:27 <badf00d5> hardware GC = throwing away used PROM
01:48:39 <badf00d5> i.e. literally GC
01:48:51 * earthy thinks 'register windows'
01:48:58 <yitz> The shredders that people will buy in the future will look different...
01:49:31 <earthy> really, having a programmable MMU would be useful
01:49:56 <exDM69> haraldk: no, GC is not always a good solution
01:49:59 <earthy> but having a fixed GC in hardware would not be quite as useful.
01:50:20 <earthy> (just look at the weirdness that is SPARC register windows
01:50:21 <earthy> )
01:50:49 <quicksilver> earthy: modern MMUs are pretty much programmable aren't they?
01:51:20 <badf00d5> hardware GC would have to poll every process for each page it wanted to deallocate, no?
01:51:38 <exDM69> quicksilver: are there any modern MMU's? Most of them are some legacy hardware from 1980's, patched together with chewing gum
01:51:42 <badf00d5> that would probably be very bad at high levels of parallelization
01:53:05 <quicksilver> badf00d5: hardware GC could run entirely asynchronously on a co-processor
01:53:20 <quicksilver> badf00d5: and the MMU could provide the illusion of infinite memory
01:53:28 <pejo> Mmmm, concurrent gc.
01:53:30 <quicksilver> GC was always supposed to give the illusion of infinite memory
01:53:46 <quicksilver> GC : write you program in infinite space, as long as its time-profile is compact
01:56:04 <sandingblock> @type map
01:56:06 <lambdabot> forall a b. (a -> b) -> [a] -> [b]
01:58:23 <roconnor> anyone have an example where continuations generated by callCC are used more than once?
02:03:30 <roconnor> ``Many algorithms which require continuations in other languages do not require them in Haskell, due to Haskell's lazy semantics.
02:03:33 <roconnor> ah ha
02:03:35 <pharm> The old lisp machines did hardware GC IIRC.
02:03:36 <roconnor> I suspected that
02:04:50 <quicksilver> roconnor: yeah, that's not hardcore callCC stuff though
02:05:01 <quicksilver> roconnor: the algorithsm they are talking about are linear use of continuations
02:05:07 <quicksilver> i.e. using them to delay evaluation
02:05:16 <quicksilver> i.e. yes that's the same as non-strict semantics :)
02:06:20 <quicksilver> roconnor: no, I've not seen a haskell example using a continuation twice. Most of the haskell examples have been ContT IO, and that isn't "real continuations" in a sense
02:06:40 <roconnor> @pl \k -> c (\a -> f a k)
02:06:40 <lambdabot> c . flip f
02:07:29 <quicksilver> roconnor: you could write a nice complex case in StateT Cont
02:07:53 <quicksilver> roconnor: which would "demonstrate" that CallCC in that context saves the state, and permits rollback and alternative futures
02:08:15 <roconnor> I'm just trying to add continutations to me mental toolkit
02:08:28 <roconnor> but I can't think if clear examples when to use them
02:08:53 * MyCatSchemes smacks roconnor with a continuation-tipped icepick, hoping to by this method embed one in his brain.
02:08:53 <roconnor> the common example of bailing out of a product can be done with exceptions ... more or less
02:09:11 <quicksilver> and you can implement exceptions with continuations :)
02:09:30 * roconnor catches MyCatSchemes current continuation and aborts it.
02:09:33 <quicksilver> you probably use continuations quite a lot, just not callCC itself
02:09:38 <quicksilver> :t either
02:09:40 <lambdabot> forall a c b. (a -> c) -> (b -> c) -> Either a b -> c
02:09:47 <quicksilver> every time you use either, or something like it, you're using continuations
02:09:55 <roconnor> quicksilver: fair enough.  then I'm looking for cases to use callCC.
02:10:06 <MyCatSchemes> roconnor: damn you! I've forgotten what I was doing now. :/
02:10:16 <quicksilver> the use case for callCC is "save the current state I might want to come back to it"
02:10:36 <roconnor> quicksilver: yeah, I'm trying to figureout how to use that continuation twice.
02:10:57 <roconnor> i suppose you can do strange things like wrap it up in the return type?
02:10:58 <MyCatSchemes> roconnor: backtracking. Continuations make it really trivial to implement Prolog in Scheme.
02:11:42 <roconnor> MyCatSchemes: when I think prolog backtracking I usually think of the list monad.
02:11:55 <pharm> Although backtracking is unlikely to invoke the same continuatin twice, surely?
02:12:16 <pharm> (hmm, maybe the state changes)
02:12:23 <MyCatSchemes> roconnor: that only gets you nondeterminism for free. How do you implement red cuts using the list monad?
02:12:43 <quicksilver> the list monad is a case of using a continuation more than once, though
02:12:44 <quicksilver> in a sense
02:12:47 <roconnor> I thought cuts were a blight on Prolog. :)
02:12:53 <pharm> !
02:13:15 <MyCatSchemes> pharm: continuations are still handy for that, because you want to be able to backtrack up arbitrary lengths in the tree. You don't know in advance whether you're going to backtrack once, twice, three times... so longjmp() won't suffice.
02:13:45 <MyCatSchemes> roconnor: hardly, without them I don't think it's even Turing-complete.
02:14:12 <yitz> MyCatSchemes: StateT [] does that too
02:14:13 <roconnor> sure, cuts make Prolog practical, but I thought it still screws up the semantics.
02:14:30 <roconnor> but I don't know much about Prolog
02:14:45 <pharm> Oh sure, I'm just not sure that a standard backtracking algorithm will invoke the same continuation more than once...
02:14:47 <roconnor> I just thought cut is away of avoiding infinite branches
02:14:53 <roconnor> but you risk losing your result.
02:15:00 <MyCatSchemes> roconnor: it kind-of does. If you understand how the unifier works under the hood, they're no problem, but they're *heavily* dependant on that.
02:15:21 <MyCatSchemes> yitz: ah, cool! Thanks. I'll have to look into that.
02:15:43 <MyCatSchemes> pharm: foo:-bar;baz;bletch
02:15:53 <MyCatSchemes> pharm: think of a predicate with three OR'd clauses.
02:15:56 <pharm> ! shortcuts the exploration, so you never explore a chunk of the tree -- which may or may not be a good thing
02:15:56 <roconnor> yitz: what do you mean by StateT [] does that too?
02:16:36 <roconnor> yitz: StateT [] sounds like the monad I was using to solve the ICFP 2006 adventure game.
02:16:40 <MyCatSchemes> roconnor: I *think* he means that you get nondeterminism because you're (ab)using the list monad, and you can backtrack to previous states because of StateT.
02:16:43 <roconnor> which was basically a prolog problem
02:17:01 <pharm> MyCatSchemes: you're saying that you end up stuffing the clauses into the same contuation one by one?
02:17:12 <roconnor> which MyCatSchemes suggests callCC as useful for.
02:17:30 <yitz> mzero means backtrack - do the next iteration, after resetting the original state. So when you nest them, you can backtrack as far up as you need to.
02:17:43 <roconnor> yitz: :D
02:17:48 <roconnor> that's totally what I did.
02:17:55 <MyCatSchemes> pharm: I'm saying that you save a continuation, you attempt the first clause, if that fails you resume from the continuation point and attempt the second clause....
02:18:18 <MyCatSchemes> yitz: sounds awesome.
02:19:09 <roconnor> newtype NDS s a = NDS {runNDS :: s -> [(s,a)]}
02:19:14 <roconnor> is that StateT [] ?
02:19:36 <oerjan> @unmtl StateT s [] a
02:19:36 <lambdabot> s -> [(a, s)]
02:19:40 <pharm> MyCatSchemes: I guess I tend to conceptualise the continuation and argument (OR clause in this case) as being different; a functional approach perhaps.
02:19:47 <roconnor> oerjan: oh wow
02:19:52 <pharm> sorry. not very clear;
02:20:08 <yitz> Cale: does that make sense?
02:20:23 <roconnor> so my question is, would using continuations be more efficent than StateT []?
02:20:35 <Cale> yitz: That mzero initiates backtracking?
02:20:44 <Cale> Yes, that makes sense, typically.
02:20:46 <pharm> I should be trying to use the same terminology as everyone else does :)
02:20:54 <pharm> (internally that is)
02:24:10 <hpaste>  roconnor pasted "using backtracking to solve the ICFP 2006 adventure game" at http://hpaste.org/3359
02:24:48 <yitz> roconner: NDS is StateT [], yes.
02:25:32 <roconnor> :'( the use cases for callCC are dwindeling.
02:27:45 <quicksilver> you can use callCC to get rollback semantics in a stack of state monads
02:27:55 <yitz> Short-circuting: http://www.haskell.org/haskellwiki/New_monads#MonadExit
02:27:56 <lambdabot> Title: New monads - HaskellWiki
02:28:00 <quicksilver> without the rollback code being aware of the detail of the stack
02:28:20 <yitz> Or, use the Maybe monad additively (`mplus` instead of >>)
02:29:36 <roconnor> yitz: how is the exit monad different from the error monad?
02:29:56 <yitz> Rollback: StateT a (StateT b ... StateT []) ... )
02:30:36 <yitz> roconnor: almost identical. Except the error monad requires the exit type to be an instance of Error. bummer.
02:30:49 <roconnor> ah yes
02:33:53 <quicksilver> the error monad tries to conflate the exit type with the buitin 'fail'
02:34:22 <quicksilver> that's where the Error constraint arises from
02:34:23 <roconnor> quicksilver: the distinction make some sense now
02:34:40 <roconnor> and I see that the ExitMonad must Exit with Exit
02:34:55 <roconnor> I could have used this instead of MaybeT.
02:35:11 <yitz> MaybeT is also nice.
02:35:14 <roconnor> well I guess I didn't need a result value
02:35:26 <roconnor> so maybe MaybeT was fine for my problem at the time.
02:35:48 <roconnor> ExitT look nice
02:35:59 <roconnor> and removes another case to use callCC.
02:36:21 <roconnor> the shortcircut multiplication could nicely be done with Exit.
02:36:40 <yitz> You can get a result value with MaybeT too - MaybeT with mplus is equivalent to ExitT with >>.
02:37:13 <hpaste>  Japsu pasted "deterministic finite automaton" at http://hpaste.org/3360
02:42:33 <yitz> Jaspu: what is "states" supposed to be used for?
02:43:45 <yitz> @seen Jaspu
02:43:45 <lambdabot> I haven't seen Jaspu.
02:43:48 <yitz> oh.
02:43:55 <Japsu> yitz: nothing... yet
02:44:07 <yitz> ok
02:44:18 <Japsu> there'll eventually be a minimizing algorithm ;)
02:44:31 <Japsu> though trans as a function won't work there
02:44:47 <Japsu> it has to be a [((s, a), s)]
02:45:00 <Japsu> which will uglify runDFA a little
02:45:47 <quicksilver> yitz: eh? MaybeT with mplus is equivalent to ExitT with >> ?
02:45:56 <quicksilver> yitz: MaybeT doesn't have an exit type though
02:46:34 <oerjan> MaybeT ~= ErrorT (), isn't it?
02:53:10 <hpaste>  yitz pasted "Exit == Maybe" at http://hpaste.org/3361
02:53:26 <yitz> Here is a contrived example. ^
02:58:00 <phlpp> > map Char.chr [103, 111, 111, 100, 32, 109, 111, 114, 110, 105, 110, 103, 33]
02:58:08 <lambdabot>  "good morning!"
03:01:08 <quicksilver> > map(chr.(+100))[3,11,11,0,-68,9,11,14,10,5,10,3,-67]
03:01:10 <lambdabot>  "good morning!"
03:01:13 <quicksilver> ^^ data compression!
03:03:48 <therp> I don't think we have yet hit the lower boundary on the kolmogorov complexity of "good morning"
03:05:35 <osfameron> is 3 less complex than 103 ?
03:06:24 <yitz> @let gm = const "good morning!"
03:06:27 <lambdabot> Defined.
03:06:31 <yitz> > gm []
03:06:33 <lambdabot>  "good morning!"
03:06:42 <yitz> How's that?
03:06:49 <phlpp> :D
03:07:30 <mauke> @undefine
03:07:31 <lambdabot> Undefined.
03:07:41 <mauke> @let gm = "good morning!"
03:07:43 <lambdabot> Defined.
03:12:12 <roconnor> > gm
03:12:14 <lambdabot>  "good morning!"
03:13:54 <phlpp> hm, if i got a number, and another number, and i want to check if num1 is a permutation of num2, i just have to check if all elements (so convert the nums to strings) from num1 are in num2
03:14:19 <phlpp> how can i solve this?
03:14:25 <phlpp> @src elements
03:14:26 <lambdabot> Source not found. I feel much better now.
03:14:57 <quicksilver> phlpp: by elements you mean digits?
03:15:16 <wli> sort
03:16:28 <geocalc> @hoogle element
03:16:29 <lambdabot> Data.Set.elementOf :: Ord a => a -> Set a -> Bool
03:16:29 <lambdabot> Test.QuickCheck.elements :: [a] -> Gen a
03:16:29 <lambdabot> Control.Exception.UndefinedElement :: String -> ArrayException
03:16:40 <quicksilver> phlpp: the most obvious algorithm is to sort both lists and then compare them...
03:17:00 * wli ponders derangements vs. permutations.
03:17:11 <quicksilver> if you thik the numbers are extremely long, it will be faster to build histograms first and compare those
03:17:33 <scook0_> (==) `on` (sort . show) perhaps? :)
03:18:22 <wli> A derangement is a permutation with no fixed points.
03:19:47 <phlpp> quicksilver: numbers are below 10^7
03:20:09 <phlpp> aww..
03:20:21 <scook0_> ?
03:20:36 <phlpp> i almost forget the simplest things (sort both numbers/strings)
03:20:41 <phlpp> ;)
03:20:57 <ricky_clarkson> :t on
03:20:59 <lambdabot> Not in scope: `on'
03:21:25 <scook0_> @djinn \bin proj x y -> (proj x) `bin` (proj y)
03:21:25 <lambdabot> Cannot parse command
03:21:37 <scook0_> uh, oops
03:21:49 <scook0_> :t \bin proj x y -> (proj x) `bin` (proj y)
03:21:51 <lambdabot> forall t t1 t2. (t1 -> t1 -> t2) -> (t -> t1) -> t -> t -> t2
03:22:16 <phlpp> @hoogle sort
03:22:16 <lambdabot> List.sort :: Ord a => [a] -> [a]
03:22:16 <lambdabot> List.sortBy :: (a -> a -> Ordering) -> [a] -> [a]
03:22:16 <lambdabot> System.Win32.NLS.sORTIDFROMLCID :: LCID -> SortID
03:22:28 <scook0_> @djinn (b -> b -> c) -> (a -> b) -> a -> a -> c
03:22:29 <lambdabot> f a b c _ = a (b c) (b c)
03:22:47 <scook0_> silly djinn
03:23:18 <scook0_> but I guess that's a perfectly valid realization
03:24:09 <scook0_> anyway, bin `on` proj applies proj to both arguments, and then applies bin on the results
03:24:26 <phlpp> @hoogle phi
03:24:27 <lambdabot> Distribution.Extension.NoMonomorphismRestriction :: Extension
03:24:27 <lambdabot> Distribution.Extension.PolymorphicComponents :: Extension
03:24:27 <lambdabot> System.Win32.NLS.sUBLANG_ENGLISH_PHILIPPINES :: SubLANGID
03:24:34 <phlpp> ehehe ;)
03:25:16 <LeCamarade> > "#haskell is literate Haskell source"
03:25:18 <lambdabot>  "#haskell is literate Haskell source"
03:25:22 <LeCamarade> :o)
03:25:52 <Japsu> > let poly x = (-123 * x^2 + 229 * x + 116) `div` 2 in map (toEnum . poly) [0..2] :: String
03:25:53 <lambdabot>  ":o)"
03:26:01 <phlpp> wtf
03:26:02 <phlpp> :>
03:26:04 <wli> let derangements xs = [map fst p | p <- permutations (zip xs [1..]), not $ or $ zipWith (==) [1..] (map snd p)] is slow; approximately only 1/e of all permutations are derangements.
03:28:05 <LeCamarade> > map Char.chr [72, 105, 33]
03:28:06 <lambdabot>  "Hi!"
03:28:55 <scook0_> is there a clever way to do derangements? perhaps a modification of the technique for shuffling an array...
03:29:26 * osfameron finds looking at haskell for long enough makes him sufficiently deranged as a matter of course
03:29:40 <yitz> > map toEnum [74,117,115,116,32,97,110,111,116,104,101,114,32,80,101,114,108,32,104,97,99,107,101,114]
03:29:42 <lambdabot>  [74,117,115,116,32,97,110,111,116,104,101,114,32,80,101,114,108,32,104,97,99...
03:29:56 <yitz> > map toEnum [74,117,115,116,32,97,110,111,116,104,101,114,32,80,101,114,108,32,104,97,99,107,101,114] :: String
03:29:58 <lambdabot>  "Just another Perl hacker"
03:30:02 <yitz> oops, sorry.
03:31:58 <wli> No clue.
03:32:24 <scook0_> I suppose you'd have to assume that there were no duplicate elements
03:32:46 <scook0_> and if you wanted *all* derangements (instead of a random one) it might get nasty
03:33:28 <wli> I wouldn't want to have to assume that.
03:33:50 <mauke> yitz: perl -wle ' print 74.117.115.116.32.97.110.111.116.104.101.114.32.80.101.114.108.32.104.97.99.107.101.114'  # optimized!
03:33:52 <wli> All derangements would be most interesting.
03:34:07 <Cale> If you can do a random derangement with uniform probability, you can certainly do all of them
03:34:19 <wli> Especially in the case where there are duplicates, when there are far fewer derangements.
03:34:30 <Cale> Because you just make every random choice that you made in all possible ways.
03:34:42 <scook0_> Cale: yeah, but I was thinking of the destructive array-shuffling algorithm
03:34:48 <Cale> Hmm, I suppose you might get a uniform duplication :)
03:34:57 <Cale> (but that would be strange)
03:34:59 <hpaste>  gnn annotated "why is foldr written that way instead of this way?" with "Prelude version has different semantics than proposed one" at http://hpaste.org/3357#a1
03:35:24 <wli> Enumerating all derangements is about as bad as all permutations, i.e. n!, when no duplicates are assumed.
03:35:38 <Cale> dataangel?
03:35:50 <wli> When duplicates are there the solution space is cut down drastically.
03:36:17 <wli> (likewise for distinct permutations ignoring multiplicity actually)
03:36:40 <wli> It's just reduced even further for derangements.
03:36:45 <Cale> as n -> infinity, about n/e of the permutations are derangements, iirc.
03:36:58 <Cale> er, n!/e
03:37:05 <wli> 1/e
03:37:12 <Cale> 1/e proportionally
03:37:38 <Cale> > 1/exp 1
03:37:40 <lambdabot>  0.36787944117144233
03:37:50 <scook0_> isn't that "myFoldR" just foldl . flip?
03:37:58 <wli> It's n!*sum(0<=k<=n) (-1)^k/k! or similar.
03:38:03 <Cale> scook0: yes
03:38:12 <Cale> scook0: which means that it's actually wrong :)
03:38:50 <wli> Cale: When duplicates enter the picture derangements are reduced much further than permutations.
03:39:12 <scook0_> ugh, it's late
03:40:09 <ketil> Do the GHC snapshots support profiling?  I can't seem to link with HSrts_p?
03:40:20 <Cale> It's not that hard to generate all derangements.
03:40:44 <wli> Cale: I'm starting to have ideas for algorithms there.
03:40:59 <phlpp> "Find the value of n, below ten million, for which φ(n) is a permutation of n and the ratio n/φ(n) produces a minimum." what is meant by "ratio produces a minimum"?
03:41:06 <Cale> A way which would be easy to prove correct would be to write an algorithm for generating all cycles on a given set.
03:41:33 <Cale> Together with an algorithm for partitioning n into subsets.
03:41:47 <phlpp> if i got two number "pairs", which both are permutations to their computed "partner", i should then take the pair with lowest ratio?
03:42:03 <Cale> Into subsets of size greater or equal to 2
03:42:18 <wli> That sounds really slow.
03:42:30 <Cale> Not really.
03:43:29 <Cale> You just find nonidentity cycles on each of the subsets in the partition and compose them, and that's all derangements, each occurring exactly once.
03:44:11 <wli> I'm thinking something like going over the distinct elements of the set in order of frequency and trying to find places to put them in all possible placements with no overlaps with their original placement.
03:44:38 <Cale> Oh, I'm assuming that elements of the set are distinct.
03:45:04 <wli> In that case you get really bad combinatorial explosion.
03:45:22 <Cale> You'll get combinatorial explosion anyway
03:45:27 <Cale> By definition of the problem :)
03:45:40 <Cale> There are about n!/e of them
03:45:47 <wli> It's vastly mitigated by duplicates.
03:46:03 <quicksilver> maybe that would be a good lambdacat. Combynaturl exploshun.
03:46:12 <quicksilver> wli: not if there are only two :)
03:46:16 <Cale> You mean permuting a word instead of a set?
03:46:22 <quicksilver> wli: (a.k.a. depending how many there are...)
03:46:34 <phlpp> hmpf
03:46:49 <wli> Cale: I guess one could put it that way.
03:50:00 <wli> All derangements of "quagga" for instance...
03:51:27 <wli> The character 'a' must be placed twice anywhere but positions 3 and 6 and 'g' placed twice anywhere but positions 4 and 5.
03:52:26 <wli> So that's C(6,2) choices for placing 'a' and C(4,2) choices for 'g' I think.
03:52:37 <quicksilver> not independent
03:52:46 <quicksilver> if the a happens to end up in a g place
03:52:53 <quicksilver> that increases the number of g possibilities
03:53:01 <quicksilver> (since gs definitely can't go in g places)
03:53:02 <wli> Yeah, I botched it.
03:53:29 <quicksilver> I would point out, in passing, that quagga is an excellent word
03:53:38 <quicksilver> I might start using it henceforth as a metasyntactic variable
03:54:12 <mauke> http://search.cpan.org/~book/Acme-MetaSyntactic-0.99/lib/Acme/MetaSyntactic.pm
03:54:15 <lambdabot> Title: Acme::MetaSyntactic - Themed metasyntactic variables names - search.cpan.org, http://tinyurl.com/24z6jw
03:57:51 <osfameron> quagga is a zebra/horse hybrid ?
03:57:59 <ketil> Anybody here using ghc-6.8?
03:58:10 <dcoutts_> ketil: yep
03:58:22 <ketil> dcoutts_, is profiling supposed to work?
03:58:33 <dcoutts_> I expect it is, yes.
03:58:54 <ketil> Could you do a 'locate HSrts_p' and see if you get any hits?
03:59:27 <quicksilver> 'HSrts_p' is the kind of noise you make when someone punches you hard and you spit out a tooth
03:59:28 <ketil> Or a ghc -prof -auto-all on whatever Main.hs file you have around?
03:59:41 * ketil got punched by GHC.
04:00:15 <dcoutts_> ketil: /usr/lib/ghc-6.8.0.20071008/libHSrts_p.a
04:01:22 <ketil> It's not here.  Did you install a binary snapshot, or compile it?
04:01:40 <dcoutts_> ketil: I compiled it
04:02:03 <ketil> Bug in the snapshot, then.
04:05:07 <pejo> Are the snapshots produced in some other way than compiling and packaging the installation-directory?
04:05:56 <ketil> No idea, really.
04:06:33 <ketil> I could try the snapshot dcoutts_  is using (mine is 20071017).
04:07:44 <dcoutts_> ketil: or try building from source
04:08:02 <ketil> ...although both 1011 and 1017 seem to be missing it.
04:08:13 <ketil> dcoutts_, yes, there is that.
04:14:21 <ketil> dcoutts_, okay, okay, you convinced me.  Now compiling :-)
04:14:45 <ketil> Is it possible to compile an AMD64-to-i686 cross-compiler, though?
04:14:59 <ketil> (64bit pointers are too expensive for me)
04:15:45 <quicksilver> set up a 32bit chroot?
04:15:55 <quicksilver> and compile in that so it thinks it's 32bit
04:16:03 <quicksilver> my AMD64 machine is all 32bit anyway :P
04:18:44 <SamB_XP_> ketil: of course it's possible
04:19:36 <SamB_XP_> oh, but you meant GHC. which is not practical...
04:20:00 <SamB_XP_> the easiest thing would be to install a 32-bit
04:20:01 <SamB_XP_> OS
04:20:07 <araujo> morning
04:20:28 <quicksilver> SamB_XP_: well a 32bit userland, at least
04:20:42 <quicksilver> SamB_XP_: you can run 32bit userland on 64 bit kernels, which is what I do.
04:20:56 <quicksilver> (and if you want, you can have 32 bit and 64 bit userlands in chroots)
04:25:39 <ketil> The missing profiling is a known issue:  http://hackage.haskell.org/trac/ghc/ticket/1778
04:25:41 <lambdabot> Title: #1778 (Linux binary distributions only have one RTS way) - GHC - Trac
04:26:35 <ketil> I installed Ubuntu 7.10, and thought I'd give 64bits a try.  It does run 32bit statically linked binaries, but apparently not dynamical ones.
04:27:02 <ketil> quicksilver, know how to set it up so it works?
04:29:42 <quicksilver> AFAIK you need to install a complete (perhaps minimal) system
04:29:47 <quicksilver> i.e. libc and stuff
04:30:06 <quicksilver> doesn't even have to be ubuntu :) you could probably have a debian chroot inside ubuntu or vice versa
04:30:08 <SamB_XP_> personally, I'd install 32-bit everything
04:30:16 <SamB_XP_> then maybe swap in a 64-bit kernel
04:31:06 <ketil> Right, I can do a chroot, but it does seem to me to be a bit cumbersome.
04:31:19 <ketil> SamB, sounds like a good option.
04:31:47 <SamB_XP_> my way is a bit cumbersome too, but the cumbersomeness is highly localized ;-)
04:32:13 <SamB_XP_> at least I assume it's cumbersome
04:32:53 <quicksilver> you don't need to "then swap in a 64 bit kernel"
04:33:01 <SamB_XP_> true
04:33:06 <quicksilver> installing 32-bit everything still gives you a 64 bit kernel
04:33:07 <ketil> I wonder why it isn't possible to switch LD_LIBRARY_PATH or similar depending on the binary type?
04:33:14 <SamB_XP_> quicksilver: oh really?
04:33:22 <quicksilver> ubuntu and debian have 64 bit kernels in their standard dists, yes
04:33:24 <nopcode> why wouldnt you install all 64 bit?
04:33:29 <quicksilver> (in their standard 32 bit dists, I mean)
04:33:29 <SamB_XP_> oh nice
04:33:48 <quicksilver> nopcode: 64 bits is slower and takes more memory :)
04:33:55 <nopcode> slower?
04:33:58 <nopcode> uh
04:33:58 <quicksilver> ketil: that's absolutely possible, in theory
04:33:58 <ketil> nopcode, ghc uses a lot of pointers, so 64bits gets expensive.
04:34:05 <quicksilver> nopcode: sure. More data to push around.
04:34:17 <quicksilver> nopcode: every pointer is twice as big, data structures become 64-bit aligned, etc etc
04:34:25 <SamB_XP_> nopcode: it may have more bogomips, but trust us
04:34:25 <matthew_-> is there a direct formula for fibonacci? rather than a recursive definition?
04:34:28 <ketil> nopcode, I posted a benchmark on the lists recently - mostly it's the GC time that goes up.
04:34:34 <quicksilver> matthew_-: yes
04:34:37 <nopcode> well ok haskell
04:34:40 <quicksilver> matthew_-: something with root 5s in it
04:34:41 <nopcode> but
04:34:41 <SamB_XP_> nopcode: memory bandwidth does NOT double when you go to 64-bit mode
04:34:45 <nopcode> you get twice the amount of registers
04:34:53 <nopcode> and register argument passing per convention
04:35:00 <SamB_XP_> registers?
04:35:11 <nopcode> if ghc can't use that, well, that's not intel/amd's fault
04:35:13 <SamB_XP_> isn't cache pretty fast anyway?
04:35:28 <quicksilver> nopcode: it's not just ghc
04:35:28 <ketil> nopcode, some benchmarks improve, some don't.
04:35:36 <quicksilver> nopcode: almost all code runs slower on 64bit
04:35:46 <quicksilver> nopcode: it's only stuff that is tightly register local that wins
04:35:49 <SamB_XP_> GHC pretends to use register passing always
04:36:04 <nopcode> hm
04:36:10 <nopcode> well it wasnt even a question for me
04:36:19 <nopcode> when i got my athlon64 i instantly installed 64 bit debian
04:36:29 <scook0> huh. I'd heard that 64 is faster for everything except "pointer-heavy" code
04:36:52 <nopcode> at > 2 gig physical memory it gets ugly with 32 bit anyways
04:36:52 <scook0> but I guess that designation includes a lot of stuff these days
04:37:12 <SamB_XP_> scook0: that's probably true
04:37:20 <ketil> scook0, sounds reasonable to me.  I'm not sure I buy quicksilver's generalization to almost all code. (Sorry, q!)
04:37:37 <SamB_XP_> perhaps a 32-bit ABI for long mode code is in order?
04:37:40 <wli> It doesn't really start getting ugly until > 16GB really.
04:37:49 <nopcode> you can also put 2 ints into a register now
04:37:50 <nopcode> ^^
04:37:51 <matthew_-> quicksilver: tnx. that confirms what I hoped - I have the "naive" version where the number of recursive calls actually follows the fibonacci sequence itself and I wanted to show that that's exponential, and there are 2^ns in that formula, so I'm happy
04:37:56 <scook0> I can see it affecting stuff like dynamic-language runtimes and haskell programs though
04:37:57 <ketil> Aside: the nice thing about compiling GHC is that you suddenly have a lot of time to waste on IRC :-)
04:37:58 <nopcode> wli: it does
04:38:06 <nopcode> wli: we have code here at work which uses all physical memory
04:38:08 <quicksilver> http://www.osnews.com/story.php/5768/Are-64-bit-Binaries-Really-Slower-than-32-bit-Binaries/page2/
04:38:10 <lambdabot> Title: Are 64-bit Binaries Really Slower than 32-bit Binaries? - OSNews.com, http://tinyurl.com/yrfoyd
04:38:11 <nopcode> one process, all memory
04:38:41 <SamB_XP_> nopcode: that's not possible
04:38:46 <SamB_XP_> the kernel needs some too ;-P
04:39:00 <hpaste>  wli pasted "derangements" at http://hpaste.org/3363
04:39:12 <nopcode> SamB_XP_: most of it, i mean ;P
04:39:15 <JaffaCake> nopcode, quicksilver: C code fairs better on 64 bit because it doesn't generally double its memory usage (hence the "pointer-heavy" thing)
04:39:17 <wli> This is actually something of my specialty within Linux.
04:39:33 <JaffaCake> ghc however always doubles memory usage on 64-bit
04:39:36 <wli> No, it's the register pressure in the 32-bit ABI.
04:39:45 <nopcode> i also prefer using indexes into storage arrays
04:39:47 <nopcode> instead of pointer
04:39:48 <nopcode> s
04:39:57 <nopcode> for algorithms that are otherwise pointer-heavy
04:40:05 <nopcode> because then you can do you own memory management on that array
04:40:07 <SamB_XP_> wli: what's the register pressure?
04:40:14 <ketil> quicksilver, come on! That's three years old, and comparing Sparc 64 to Sparc 32.
04:40:25 <wli> The 32-bit ABI has about 3 usable registers, and absolutely none that are clobber-free.
04:40:29 <SamB_XP_> ketil: so?
04:40:33 <quicksilver> ketil: right. But the general point is sound.
04:40:35 <wli> Side effect clobbers that is.
04:40:40 <quicksilver> 64bit is *obviously* slower than 32bit
04:40:46 <quicksilver> there's no reason for it to be inherently faster :)
04:40:46 <SamB_XP_> wli: ah.
04:40:50 <quicksilver> and plenty for it to be lower
04:40:52 <SamB_XP_> wli: really
04:40:53 <SamB_XP_> ?
04:40:57 <scook0> quicksilver: things get subtle with x86-64
04:40:57 <wli> Yes, really.
04:41:00 <quicksilver> now... if your 64bit architecture also has more registers...
04:41:04 <quicksilver> then that helps, of course
04:41:05 <ketil> quicksilver, but AMD64 is a different architecture from x86.
04:41:11 <JaffaCake> quicksilver: x86_64 is better at doing PIC, so shared libraries can be faster
04:41:14 * quicksilver nods
04:41:29 <wli> x86-64 throws 8 free registers into the equation plus that PIC-useful addressing mode.
04:41:41 <wli> Cale: There are derangements for you.
04:41:53 <scook0> in the case of equivalent underlying architectures, you'd obviously expect 64-bit to be strictly worse
04:42:04 <ketil> JaffaCake, any plans for 'ghc -m32 '?
04:42:17 <SamB_XP_> wli: are the rep/xtox instructions really so frequent?
04:42:19 <JaffaCake> ketil: well, ghc -fvia-C -optc-m32 works
04:42:34 <JaffaCake> oh, if it was built for 32-bit that is
04:42:42 <wli> SamB_XP: No. They're also near-impossible for compilers to generate effectively.
04:42:47 <JaffaCake> I guess the real answer is no :)
04:42:55 <phlpp> hm
04:42:56 <ketil> :-)
04:42:57 <phlpp> thats odd
04:42:58 <phlpp> *Problem70> (2371214) == 2*29*40833
04:42:59 <phlpp> Fals
04:43:07 <SamB_XP_> wli: then what else uses esi and edi specially?
04:43:13 <phlpp> why is this evaluating to false? 2, 29 and 40833 are the prime facotrs of 2371214
04:43:22 <mauke> > 2*29*40833
04:43:24 <lambdabot>  2368314
04:43:32 <nopcode> yeah x86_64 has rip-relative addressing for PIC
04:43:44 <wli> SamB_XP: They're typically counted among the two usable registers.
04:43:49 <wli> SamB_XP: Three, even.
04:43:50 <phlpp> philipp@spitfire:~$ factor 2371214
04:43:51 <phlpp> 2371214: 2 29 40883
04:43:56 * JaffaCake has a 64-bit build of GHC with shared libraries thanks to therp :)
04:44:02 <SamB_XP_> > 2368314 / 2371214
04:44:03 <lambdabot>  0.998776997774136
04:44:10 <phlpp> aaww..
04:44:14 <scook0> phlpp: typo; 40883 not 40833
04:44:21 <SamB_XP_> wli: ah, right
04:44:27 <SamB_XP_> wli: is the other one ecx?
04:44:27 <phlpp> ah
04:44:28 <phlpp> lol
04:44:32 <phlpp> scook0: thanks m8
04:44:36 <wli> SamB_XP: Yeah.
04:44:45 <SamB_XP_> okay then
04:44:48 <scook0> phlpp: thanking m3? ;)
04:45:09 <wli> Any comments/improvements upon the derangement code?
04:45:12 <SamB_XP_> wli: the DIV instruction is the worst ;-)
04:45:28 <phlpp> scook0: 8 == eight, mate ;)
04:45:31 <wli> SamB_XP: mul is no different
04:45:33 <phlpp> :>
04:45:38 <phlpp> ah, ok, you got it
04:45:39 <phlpp> :D
04:45:45 <scook0> wli: acct is a little deranged, style-wise
04:46:05 <wli> SamB_XP: 32-bit floating point is the worst
04:46:10 <SamB_XP_> wli: it's not QUITE as hard to wrap your head around...
04:46:24 <SamB_XP_> oh, floating point... don't talk of floating point!
04:46:58 <phlpp> @hoogle factor
04:46:59 <lambdabot> No matches found
04:47:01 <phlpp> @hoogle factorize
04:47:01 <lambdabot> No matches found
04:47:04 <phlpp> hmpf
04:47:21 <wli> scook0: I bungled the indentation on the last $ yeah.
04:47:49 <ricky_clarkson> @hoogle Integer -> [Integer]
04:47:49 <lambdabot> No matches, try a more general search
04:47:59 <ricky_clarkson> No, you.
04:48:14 <wli> Also forgot to collapse the last zip xs [0..] into xs'
04:48:43 * Cale upgrades Ubuntu. (Or should that be Ubuntu upgrades Cale?)
04:49:29 <ricky_clarkson> Ubuntu, an ancient African word meaning "I can't configure Debian".
04:50:18 <wli> Any algorithmic comments?
04:50:22 <quicksilver> In soviet russia, ubuntu grades up you?
04:50:22 <Cale> I can't be *bothered* to configure Debian.
04:51:03 <Cale> I actually ran Debian for 5 years.
04:51:06 <LeCamarade> @remember ricky_clarkson Ubuntu, an ancient African word meaning "I can't configure Debian".
04:51:06 <lambdabot> It is stored.
04:51:11 <nopcode> i ran debian too
04:51:17 <nopcode> at some point dist-upgrade ate my X
04:51:20 <nopcode> and i couldnt fix it
04:51:22 <nopcode> then i switched
04:51:45 <LeCamarade> Me, I don't do no funky stuff, and Debian runneth good.
04:51:52 <wli> dist-upgrade ate my X config a while back and my monitor burned out before I got around to fixing it
04:51:57 <SamB_XP_> nopcode: I could fix it ;-)
04:52:06 <SamB_XP_> took me a while though
04:52:17 <LeCamarade> Hurd! Hurd!
04:52:20 <wli> I generally can fix it, but I'm not swift at doing it.
04:52:41 <wli> Cale: I hammered out derangement code; see hpaste
04:52:53 <quicksilver> I had a debian machine go through so many unattended upgrades that it did two major libc transitions
04:52:55 <SamB_XP_> I believe it happened in the XFree86 -> X.org transition
04:52:57 <quicksilver> and it never crashed
04:53:03 <quicksilver> and never needed physical presence.
04:53:03 <nopcode> i've got debian on my root server
04:53:04 <nopcode> stable tho
04:54:01 <SamB_XP_> actually, I think it had apt kind of wedged...
04:54:25 <Cale> wli: tsk, tsk, overuse of $ :)
04:54:50 <wli> Cale: pipelines
04:54:55 <Cale> (.)
04:55:49 <Cale> You only need $ to apply the function at the very end.
04:55:56 <wli> okay...
04:56:11 <Cale> (.) is nicer because it's an associative operator
04:56:27 <Cale> which means that you can refactor those pipelines a little bit more easily
04:56:33 <SamB_XP_> wli: yeah, if you keep doing that we won't be able to change the associativity of $ to something more useful
04:56:34 <opqdonut> (.)(.) is nice
04:56:37 <opqdonut> ;)
04:57:01 <wli> (.) . (.) ?
04:57:08 <LeCamarade> My toy language will have no precedence, and will use spaces to group expressions. 1 *  1 + 2 == 1 * (1 + 2) != (1 * 1) + 2
04:57:14 <Cale> :t (.)(.)
04:57:18 <LeCamarade> Three spaces. Yeah, crazy.
04:57:23 <lambdabot> forall b c a a1. (a1 -> b -> c) -> a1 -> (a -> b) -> a -> c
04:57:36 <LeCamarade> opqdobut: :-o
04:57:46 <Japsu> :t (.)(.)(.) -- the three-boob creature from Total Recall
04:57:48 <lambdabot> forall a b c a1. (b -> c) -> (a -> a1 -> b) -> a -> a1 -> c
04:57:53 <Cale> > (.)(.) (+) 5 negate 4
04:57:54 <lambdabot>  1
04:57:55 <scook0> I don't know about (.)(.), but (.).(.) is totally useful
04:58:08 <LeCamarade> @djinn (a -> b)
04:58:08 <lambdabot> -- f cannot be realized.
04:58:13 <LeCamarade> @djinn (a -> a)
04:58:13 <lambdabot> f a = a
04:58:14 <hpaste>  wli annotated "derangements" with "stylistic update" at http://hpaste.org/3363#a1
04:58:23 <Cale> hehe
04:58:34 <LeCamarade> @djinn (a b -> (b -> a))
04:59:12 <LeCamarade> Woah. That will kill djinn. Victory is within #ocaml's grasp, now.
04:59:46 <LeCamarade> :t flip
04:59:48 <lambdabot> forall a b c. (a -> b -> c) -> b -> a -> c
05:00:00 <Cale> wli: If you put the index in the first component, then you can include zip [0..] in the pipeline.
05:00:00 <wli> Any algorithmic comments?
05:00:27 <Cale> I'm not sure I completely understand the algorithm yet.
05:00:34 <quicksilver> algorithms? pah!
05:01:02 <wli> Basically I generate feasible index sets as a sort of environment.
05:01:11 <quicksilver> We reject algorithms, semantics, and real work. We embrace syntactic elegance and aesthetically pleasing combinators!
05:01:44 <Cale> yeah, I'm seeing that now. acct produces a list of elements together with the positions they don't occur in.
05:01:45 <wli> Each choice does the list of successes thing and strikes out the choice made from the remaining available choices for the rest of everything's available choices.
05:02:14 <wli> When the smoke clears, sort on the indices then forget them to form a fresh list.
05:02:16 <Cale> oh, and the number of them too, for some reason...
05:02:41 <wli> The number of feasible choices doesn't indicate how many of them to choose.
05:03:16 <scook0> since you have n occurrences to place in m positions
05:03:45 <Cale> It's really funny how in Haskell, using the first component of a pair for extra information is more natural.
05:03:57 <wli> For "quagga" you need to choose 2 places for 'a' out of 6 possible locations (2 of which are infeasible and stricken out early on).
05:04:10 <scook0> Cale: how so?
05:04:35 <Cale> scook0: ((,) t) is a Functor, and you have things like zip [0..]
05:04:36 <quicksilver> join the campaign to replace readFile with the continuatoin passing variant and fix these stupid questions!
05:04:44 <yitz> Cale: Partly because of the Ord instance for (,)
05:04:46 <Cale> quicksilver: never!
05:04:54 <quicksilver> readFile :: FilePath -> (String -> IO()) -> IO() for president!
05:05:25 <quicksilver> it actually could then be 'unsafe lazy' inside the continuation with much less damage caused
05:05:34 <quicksilver> because you'd know that things were tided up in the end
05:05:39 <Cale> quicksilver: Why not withFile :: FilePath -> (String -> IO String) -> IO () ?
05:05:43 <yitz> I vote for readFile :: FilePath -> ListT IO Char
05:05:54 <quicksilver> Cale: isn't that what I said?
05:05:56 <Cale> ew, ListT IO
05:06:03 <Saizan> quicksilver: readFile :: FilePath -> (seed -> String -> IO (Either seed seed)) -> seed -> IO() you mean!
05:06:06 <Cale> quicksilver: not quite
05:06:11 <yitz> New ListT, of course
05:06:17 <Saizan> s/()/seed/
05:06:19 <quicksilver> Cale: yours changes the file too?
05:06:23 <Cale> quicksilver: yeah
05:06:27 <quicksilver> ok that's nice too
05:06:31 <quicksilver> I have no objection to that
05:06:40 <quicksilver> but you want the non-modifying version as well
05:06:42 <Cale> quicksilver: Might as well, as long as you're doing the continuation passing.
05:06:44 <quicksilver> I would have thought
05:06:49 <Cale> Yeah, possibly
05:06:58 <wli> There is a slight problem in that redundant derangements are generated.
05:07:00 <Cale> Though I wouldn't want to remove readFile
05:07:06 <quicksilver> I would!
05:07:08 <Cale> Lazy IO is good for some things.
05:07:09 <scook0> @. pl djinn (a,(b,c)) -> (a, b, c)
05:07:10 <lambdabot> f = uncurry ((`ap` snd) . (. fst) . (,,))
05:07:11 <quicksilver> all these questions!
05:07:15 <Cale> In fact, it's incredibly handy.
05:07:25 <quicksilver> Cale: at least hGetContents gives you a handle you can explicitly close
05:07:28 <quicksilver> that's better
05:07:30 <yitz> ListT IO provides the laziness, with losing control with unsafe IO.
05:07:35 <quicksilver> readFile just leaves you in a mess
05:07:36 <scook0> it would at least make sense in a "Q&D scripting" module
05:07:57 <wli> I'd like to avoid generating redundant derangements.
05:07:58 <yitz> s/with/without/
05:08:03 <quicksilver> (well hGetContents doesn't give you a handle, of course, but you see what I mean)
05:08:14 <Cale> Well, if you want the handle on readFile to close, you just throw away the reference to the string, and it'll be closed on the next GC.
05:08:22 <quicksilver> maybe
05:08:24 <wli> So there is a problem to solve here.
05:08:30 <quicksilver> finalization is not guaranteed
05:08:38 <quicksilver> and this bites people often enough that it's a real problem
05:08:50 <Cale> Who honestly opens that many files?
05:08:56 <wli> I have.
05:09:00 <quicksilver> someone doing a big global search and replace
05:09:05 <quicksilver> (current thread in -cafe)
05:09:16 <wli> Also standing servers that open and close files to service clients.
05:09:20 <quicksilver> and there was a nother one a few months back
05:09:25 <quicksilver> and others before that
05:10:01 <ketil> Slightly weird problem:  I have a library that configures/builds/installs okay.  I can :m + it in GHCi.  But when I try to use a function, I get an error about a non-exposed module.
05:10:10 <Cale> readFile isn't for heavy duty programs, it's for quick hacks.
05:10:23 <ketil> Prelude Bio.Alignment.BlastXML> x <- readXML "454vsUP90.xml"
05:10:23 <ketil> Loading package array-0.1 ... linking ... <interactive>: /usr/local/lib/bio-0.3.1/ghc-6.8.0.20071011/HSbio-0.3.1.o: unknown symbol `__stginit_biozm0zi3zi1_BioziUtil_'
05:10:24 <ketil> ghc-6.8.0.20071011: unable to load package `array-0.1'
05:10:43 <ketil> Anybody know what this means?
05:10:43 <scook0> Cale: though for most quick hacks, do you really need the laziness?
05:10:59 <quicksilver> Cale: and if your quick hack involves many files and you try to scale it, it breaks with an incomprehensible error you have no idea how to fix
05:11:02 <Cale> Sure, in lots of cases you have one big file you want to process.
05:11:12 <quicksilver> Cale: which, IMO, leaves a really nasty taste in the mouth of people trying out haskell
05:11:25 <Cale> If you're opening so many files that you're in danger of running out of file handles, then you probably want to manage file handles yourself.
05:11:31 <Cale> And there are tools for doing that.
05:11:34 <Cale> Obvious ones.
05:11:43 <quicksilver> no, I disagree
05:11:47 <quicksilver> this code was a oneliner!
05:11:52 <quicksilver> it looked nicer as a oneliner!
05:12:00 <quicksilver> and it would have been a correct oneliner if readFile wasn't broken
05:12:04 <ketil> I use readFile (and hGetContents) a bit, works for me.
05:12:25 <Cale> Yeah, I've used Haskell for years now, and never had a problem with readFile.
05:12:37 <ketil> only in combination with mapM or similar :-)
05:12:53 <quicksilver> http://article.gmane.org/gmane.comp.lang.haskell.cafe/30348
05:12:55 <lambdabot> Title: Gmane -- Mail To News And Back Again
05:12:58 * ketil considers the limited number of open files the real bug (in the kernel).
05:13:02 <quicksilver> just so you know what we're talking about
05:13:07 <Cale> ketil: I agree.
05:13:21 <quicksilver> philosophically you're right
05:13:25 <quicksilver> but this is where we are
05:13:30 <quicksilver> with these kernels, which have these limitations
05:13:38 <Cale> Someone should submit a kernel patch. :)
05:13:46 <quicksilver> trying to have a scalable, elegant referentially transparent language..
05:13:54 <quicksilver> and this *could* be easy
05:14:02 <quicksilver> the continuation passing version of readFile is easy to write
05:14:05 <quicksilver> and not much harder to use
05:14:38 <ketil> quicksilver, link to an example?
05:14:43 <quicksilver> I just did?
05:14:50 <quicksilver> an example of the problem, or of the solution?
05:15:17 <quicksilver> instead of loadAndCheck fp = liftM hasEmpty $ readFile fp
05:15:31 <wli> You'll just run the system out of memory with file handle objects.
05:15:38 <quicksilver> he'd have loadAndCheck fp = readFile (hasEmpty) fp
05:16:05 <quicksilver> parens for emphasis, for some reason I'm not unsure about :)
05:16:57 <fox86> hmm, i just started on a haskell tutorial, and the code is supposed to result in this: http://www.lisperati.com/haskell/picnic.hs ... is it common to litter haskell code with so many let-statements?
05:17:27 <quicksilver> fox86: no
05:17:36 <phlpp> is it possible to do (==) on more than 2 as?
05:17:40 <quicksilver> fox86: It would be more common to make most of those top-level definition
05:17:51 <fox86> quicksilver: maybe it was done like that in order to make the code easier to understand?
05:17:53 <phlpp> such as (\x -> x == 2*x == 3*x)?
05:18:08 <quicksilver> phlpp: no
05:18:16 <phlpp> oh :<
05:18:21 <quicksilver> phlpp: operators are binary by definition
05:18:26 <phlpp> hm
05:18:46 <quicksilver> easy to write allEqual :: Eq a => [a] -> Bool though
05:19:26 <quicksilver> fox86: if that was the reason, I don't find it convincing :)
05:19:27 <Cale> fox86: The only reason I could think of is maybe if the author wrote it by working in GHCi a bunch and copying things out.
05:19:35 <Saizan> let (==:) a b c = a == b == c in 3 ==: 4 $ 5 -- the better you get
05:19:43 <Saizan> > let (==:) a b c = a == b == c in 3 ==: 4 $ 5
05:19:50 <quicksilver> fox86: I would have them top-level so I could test them independently
05:19:51 <lambdabot>      precedence parsing error
05:19:52 <lambdabot>         cannot mix `(==)' [infix 4] and `(==)' ...
05:19:58 <fox86> Cale: aah. the code must be run with "runhaskell file.hs" in the tutorial
05:20:00 <fox86> quicksilver: ah, okay
05:20:03 <Cale> fox86: I don't think that's a reasonable way to write it, for exactly the reason that quicksilver just pointed out.
05:20:19 <phlpp> hm
05:20:27 <Cale> fox86: That makes it impossible to test all those definitions independently.
05:20:50 <Saizan> > let (==:) a b c = (a == b) == c in 3 ==: 4 $ 5
05:20:50 <lambdabot>   add an instance declaration for (Num Bool)
05:20:51 <fox86> Cale: perhaps i should find another tutorial
05:21:27 <quicksilver> Saizan: ITYM (a==b) && (b == c) ?
05:21:57 <Saizan> quicksilver: yes, i think i'm not awake yet
05:22:07 <Cale> fox86: Have you looked at YAHT or the Wikibook?
05:22:39 <scook0> > (\xs -> and $ zipWith (==) xs (tail xs)) [1, 1, 1]
05:22:41 <lambdabot>  True
05:22:44 <scook0> > (\xs -> and $ zipWith (==) xs (tail xs)) [1, 2, 3]
05:22:45 <lambdabot>  False
05:22:51 <wli> I see why.
05:22:58 * LeCamarade has to kick C# while watching your lambdas run about. I swear it makes /me mad. I'll just start trolling like qwe1234. :o(
05:23:00 <Cale> fox86: I'd recommend either of those, up until you start looking at monads, at which point there are much better alternative tutorials.
05:23:10 <fox86> Cale: i have "read" YAHT past the first chapter about datatypes... then after that there were like 5 more chapters about datatypes and then my brain couldn't handle it any longer.
05:23:18 <Cale> fox86: okay
05:23:22 <fox86> Cale: perhaps i should look at the wikibook then. it's on haskell.org, right?
05:23:25 <scook0> @pl \xs -> and $ zipWith (==) xs (tail xs)
05:23:25 <lambdabot> and . ap (zipWith (==)) tail
05:23:41 <wli> Nailed it.
05:23:43 <Cale> No, http://en.wikibooks.org/wiki/Haskell
05:23:44 <LeCamarade> fox86: To be frank with you, you will have to use more than one tut.
05:23:44 <lambdabot> Title: Haskell - Wikibooks, collection of open-content textbooks
05:23:46 <scook0> gah, ((->)r)
05:23:53 <Cale> (well, it's also linked from the main haskell site)
05:24:05 <fox86> Cale: thank you
05:24:08 <quicksilver> ap in (->)r is one of @pl's favourite ways of duplicating an argument
05:24:17 <quicksilver> the other is join
05:24:23 <quicksilver> (also in (->)r)
05:24:24 <fox86> LeCamarade: okay. i have yaht and the wikibook now. and the one where they use "let" a lot
05:24:39 <Cale> Oh, it looks like the Haskell wikibook's section on monads has been replaced...
05:24:46 <Cale> I'll have to read it at some point.
05:24:56 <quicksilver> with something more better or less better?
05:25:40 <Cale> With something apparently incomplete, but I have a hard time imagining that it's much worse. ;)
05:26:13 <nominolo> metaphors generally don't work well with monads
05:26:17 <hpaste>  wli annotated "derangements" with "eliminating duplicates" at http://hpaste.org/3363#a2
05:26:25 <nominolo> in my experience
05:26:29 <Cale> There's some odd language in there.
05:26:49 <wli> It was a one-character, one-line change to fix it all.
05:26:50 <Cale> and some wrongly-suggestive language too :)
05:27:03 <wli> I've found all the monad metaphors to be completely useless.
05:27:09 <Cale> nominolo: They work, you just need the right metaphor.
05:27:22 <nominolo> Cale, they all break sooner or later
05:27:23 <Cale> wli: So you apply the category theoretic definition directly?
05:27:38 <wli> Cale: No. Just work with the code.
05:27:41 <arcatan> ERROR "Compiler.hs" - Module "Text.ParserCombinators.Parsec" not previously loaded
05:27:44 <nominolo> the only good tutorial on monads i know is the one by sigfpe
05:27:57 <Cale> sigfpe uses a metaphor
05:28:10 <nominolo> which one?
05:28:13 <Cale> Monads as types of computation.
05:28:44 <nominolo> ok, what else are they in the context of haskell?
05:29:30 <Cale> The containers metaphor works about equally well in the context of Haskell, with perhaps monads over IO being an exception.
05:30:00 <nominolo> very bad exception
05:30:06 <Cale> (because IO is such a strange monad)
05:30:08 <nominolo> since that is what newbies see first
05:30:15 <Cale> Not always
05:30:16 <wli> Mostly I've seen that a lot of monads are just sugar atop threading components of a pair (,) through a composition pipeline.
05:30:29 <Cale> Actually, I think newbies usually see lists a good while before IO
05:30:40 <nominolo> but not as a monad
05:30:47 <LeCamarade> They also see Maybe before they see IO.
05:30:54 <Cale> Well, that makes them a good introduction to monads.
05:30:54 <wli> Typically munging them in some repetitive fashion at each composition stage.
05:31:12 <quicksilver> I think viewing monads as a way to hide plumbing/boilerplate is a good one
05:31:17 <quicksilver> that was my initial view of them
05:31:20 <Cale> IMO, lists are a much better example monad than IO is.
05:31:21 <quicksilver> (because of an SPJ talk)
05:31:31 <nominolo> quicksilver, right
05:31:36 <quicksilver> it helps that I had already tried to write type unification algorithms
05:31:45 <quicksilver> so SPJ's example of that was meaningful to me
05:31:52 <roconnor> @remember JamesMckinna We are once again left with the miserable prospect that it is equality that divides us.
05:31:52 <lambdabot> It is forever etched in my memory.
05:32:01 <wli> Ditch all the squishy talk. Go directly to the code.
05:32:04 <nominolo> Cale, people don't need to _understand_ them
05:32:14 <quicksilver> essentially, type inference in a state monad for the unifier
05:32:17 <nominolo> Cale, they just need to be able to use them
05:32:23 <quicksilver> so it infers states and builts up the unification together
05:32:27 <nominolo> wli, exactly
05:32:35 <Cale> nominolo: Depends on what you mean by "use".
05:32:45 <hpaste>  yitz pasted "derangements" at http://hpaste.org/3364
05:32:49 <quicksilver> but you can't go straight to the code for IO
05:32:53 <quicksilver> because it is a primitive
05:33:13 <Cale> You kind of have to understand monads if you're writing a library which you'd like to be monadic.
05:33:20 <wli> Ignore IO to start with. Maybe, lists, state.
05:33:27 <quicksilver> parser combinators are another good eample of plumbing hiding, because I had written ML parser combinators before I knew what a monad was.
05:33:30 <Cale> Yeah, work up :)
05:33:32 <nominolo> Cale, i mean that you just have to realize that they are those two simple operators and that they can be very useful
05:33:41 <quicksilver> and then I could see that the monadic notation was just what I was already doing
05:34:20 <Cale> Yeah, I think parser combinators were what made the idea click for me initially.
05:34:54 <nominolo> for me it was state, i think
05:34:58 <Cale> Maybe is too simple. List is a little better, though I somehow had missed that example in my learning.
05:35:02 <quicksilver> There is a style of parser combinator which 'by default' builds up big nested tuples
05:35:03 <vegai_> ah, Monad war stories.
05:35:05 <wli> For me it was the springschool95.ps type inference bit.
05:35:16 <Cale> When I was learning, the explanations of how the state monad worked kind of sucked.
05:35:23 <Cale> That was a few years ago though.
05:35:25 <wli> But only after YAHT's monad transformer stack.
05:35:26 <yitz> Here is how I first understand monads, and I think it is a good program. 3 steps:
05:35:46 <yitz> 1. Learn how to use list comprehensions.
05:36:03 <yitz> 2. Learn how to use State, without understanding the plumbing
05:36:26 <Cale> Oh, the wikibook's monads article is still talking about nuclear waste.
05:36:32 <yitz> 3. Read Cale's wiki page about containers.
05:36:39 <yitz> Ping!
05:37:00 <Cale> Yeah, any newbies here, don't read the wikibook's stuff on monads.
05:37:37 <opqdonut> yep
05:37:45 <opqdonut> pointer to the wiki page plz?
05:37:46 <osfameron> Cale: oops, I tried to read it at weekend
05:37:47 <Cale> I'm going to have to rewrite that. Maybe I can just import my own tutorials into the wikibook.
05:37:48 <phlpp> okay, my allEqual solution directly hacked in a lambda:
05:37:50 <phlpp> head $ filter (\n -> ((sort$show n)==(sort$show(2*n)))&&((sort$show n)==(sort$show(3*n)))&&((sort$show n)==(sort$show(4*n)))&&((sort$show n)==(sort$show (5*n)))&&((sort$show n)==(sort$show (6*n)))) [1..10^6]
05:37:50 <opqdonut> i don't think i've read it
05:37:53 <Cale> http://en.wikibooks.org/wiki/Haskell
05:37:54 <phlpp> :P
05:37:54 <lambdabot> Title: Haskell - Wikibooks, collection of open-content textbooks
05:37:56 <osfameron> luckily I didn't understand a word of it :-)
05:38:10 <yitz> @go monads as containers
05:38:12 <Cale> The "Understanding Monads" section is in terrible shape, by the looks of it.
05:38:13 <lambdabot> http://www.haskell.org/haskellwiki/Monads_as_Containers
05:38:13 <lambdabot> Title: Monads as containers - HaskellWiki
05:38:18 <Cale> Read my tutorials :)
05:38:29 <quicksilver> I have an alternative to yitz's step 2
05:38:38 <Cale> "Monads as containers" and "Monads as computation" on the Haskell wiki.
05:38:42 * wli ponders monadic monad tutorial writing combinators.
05:38:49 <quicksilver> 2. Write some programs using the explicit state-passing style, s -> (a , s)
05:39:03 <nominolo> quicksilver, ack
05:39:10 <quicksilver> 2a. understand them properly and then learn how you can rewrite that as State s a
05:39:11 <Cale> http://haskell.org/haskellwiki/Monads_as_computation
05:39:12 <phlpp> i'm wondering if there's some more cute solution, like having a abbreviation for sort $ show n, but which's is still a "one-liner" and produces output
05:39:13 <lambdabot> Title: Monads as computation - HaskellWiki
05:39:19 <quicksilver> 2b. discuss if that's actually any better
05:39:33 <yitz> quicksilver: right, not an alternative. Assuming you have done that also. So, 4 steps I guess.
05:39:38 <wli> I found monad transformer stacks crucial to understanding monads.
05:39:53 <Cale> wli: that's interesting.
05:39:57 <yitz> Noticing the easy translation of list comprehension -> do notation is also a trivial step I left out.
05:40:00 <wli> Monads seem mostly pointless without monad transformer stacks.
05:40:01 <nominolo> quicksilver, just let user's "invent" >>= themselves
05:40:12 <quicksilver> nominolo: that's what I said, I believe
05:40:16 <quicksilver> :)
05:40:20 <nominolo> k :)
05:40:57 <quicksilver> I note taht explicit state passing sometimes comes out more pleasant looking than the monadic version :P
05:41:09 <quicksilver> all those explicit puts and gets make for very verbose code
05:41:11 <Cale> I wrote Monads as Computation in order to give the sense that monads are a naturally occurring thing for programmers.
05:41:21 <quicksilver> custom combinators and newtypes help somewhat
05:41:27 <wli> quicksilver: Which is where monad transformer stacks come in wrt. their relevance.
05:41:31 <nominolo> and then you can go on with:  this structure: >>=, return, and some run-function turns out to be an incredably useful construct
05:42:14 <Cale> Also, in response to all the horrible tutorials for other languages, where the implementation of the monad abstraction misses the whole point of making that abstraction in the first place.
05:42:46 <Cale> Hint: If you can't write code which will operate in any monad, then there's no point in talking about monads.
05:43:07 <quicksilver> or "any of a subset of monads"
05:43:13 <Cale> Sure.
05:43:15 <quicksilver> e.g. MonadState s m => m
05:43:18 <Cale> But any monad, first of all.
05:43:36 <Cale> You should be able to write sequence, and have it work in state and list
05:43:44 <Cale> Without rewriting it.
05:43:47 <quicksilver> BTW, does anyone else think 'whenJust' deserves a place in the standard libs
05:44:04 <Cale> quicksilver: what would its type be?
05:44:05 <wli> The standard combinators can actually be rather tricky to write.
05:44:07 <quicksilver> whenJust :: Maybe a -> (a -> m()) -> m()
05:44:25 <quicksilver> I find I write ".... Nothing -> return ()" rather often
05:44:26 <Cale> Isn't that just  when . isJust?
05:44:32 <Cale> errr
05:44:38 <quicksilver> Cale: plus a magic fromJust, yes
05:44:42 <Cale> ah
05:44:51 <quicksilver> Cale: it's the magic fromJust or explicit case I'm trying to remove
05:45:05 <Cale> Yeah, that seems handy enough.
05:45:26 <quicksilver> I would really like skip = return (), too
05:45:28 <nominolo> quicksilver, yep
05:45:38 <quicksilver> I'm not fond on return () as a form, it feels ugly :)
05:46:01 <Cale> There are lots of times where you end up wanting Maybe-monad-like functionality but in a monad that doesn't actually support that.
05:46:05 <nominolo> also, it's doesn't "return" (in the C/Java/... sense)
05:46:10 <Cale> And that would be perfect for lots of those cases.
05:46:26 <wli> Anyway, writing monad tutorials is a common enough operation it justifies a monadic combinator library for it.
05:46:35 <quicksilver> Cale: yeah
05:46:55 <quicksilver> Cale: one common case for me at the moment is whenJust (Map.lookup ...)
05:47:04 <Cale> I'd like to think that my monad tutorials are not quite the standard fare :)
05:48:00 <yitz> +1 whenJust, +1 skip
05:48:09 <yitz> Cale: MaybeT
05:48:24 <Cale> yitz: yes, but that involves transforming the monad.
05:48:35 <wli> Transforming monads is good.
05:48:44 <Cale> and in many cases, that's too heavy an operation
05:48:45 <yitz> x <- runMaybeT ...
05:48:49 <nominolo> Cale, your Monads as computations looks pretty good.  for a tutorial a more hands-on approach would be nicer.  but it's already quite good
05:49:06 <Cale> Yeah, the one thing I regret about it is the lack of examples.
05:49:29 <wli> I'd like to see one that lays out the guts of monad implementations and sprays out a long series of well-thought-out problems.
05:49:53 <Cale> But I also halfway wrote it for other monad tutorial authors :)
05:50:07 <Cale> To address some points which I thought they were missing.
05:50:10 <quicksilver> So really it's a monad tutorial authoring tutorial ?
05:50:19 <quicksilver> :P
05:50:22 <nominolo> wli, i think the name "Monad" should be mentioned rather late
05:50:26 <Cale> Disguised as a monad tutorial, yeah :)
05:50:33 <ulfdoz> Schon kde ist hier nahe an der 100-Prozesse-Marke
05:50:36 <ulfdoz> ECHAN, sorry
05:50:38 <wli> nominolo: I don't see why.
05:50:51 <quicksilver> Cale: Who will tutor the monad tutor tutors?
05:51:02 <nominolo> wli, because all that abstract talk scares newbies away
05:51:13 <wli> I also think things should go back to map and join.
05:51:26 <wli> vs. bind directly
05:51:40 <Cale> Depends on which presentation you're giving.
05:51:54 <wli> nominolo: You can be abstract so long as you're not squishy about it. You always need grounding in concrete code.
05:51:55 <nominolo> the first time someone told me that a monad is just a typeclass with two operators i thought, "uhuh"
05:52:14 <quicksilver> the truth is that there is no perfect tutorial in isolation
05:52:15 <Cale> For the computation-directed approach, bind is way more natural. For some other approaches, map, join are better.
05:52:18 <quicksilver> it depends on the reader
05:52:18 <phlpp> > head $ filter (\n -> ((sort$show n)==(sort$show(2*n)))&&((sort$show n)==(sort$show(3*n)))&&((sort$show n)==(sort$show(4*n)))&&((sort$show n)==(sort$show (5*n)))&&((sort$show n)==(sort$show (6*n)))) [1..10^6]
05:52:25 <Cale> Indeed.
05:52:26 <nominolo> the point is how to "use" them -- many monad examples ...
05:52:31 <lambdabot>  142857
05:52:42 <quicksilver> and readers of monad tutorials come from widely varying backgrounds
05:52:43 <wli> bind is too complex of an operation to explain
05:52:52 <Cale> phlpp: factor repetition :)
05:52:58 <quicksilver> from another perspective bind is the WHOLE POINT :)
05:53:10 <nominolo> yep
05:53:11 <quicksilver> monads let you (a) hide plumbing and (b) attach names to values
05:53:19 <Cale> Nah, the whole point is sharing things like sequence and mapM
05:53:27 <quicksilver> well, true
05:53:30 <phlpp> Cale: in fact, this task is easy to solve without any computer
05:53:30 <nominolo> bind isn't complex for the computation approach
05:53:31 <quicksilver> maybe there's more than one point?
05:53:35 <Cale> We've had combinator libraries for years.
05:53:40 <quicksilver> that was deliberate hyperbole anyway :)
05:53:42 <Cale> They hide plumbing :)
05:53:56 <wli> Computation approach? Metaphor; DOA.
05:54:00 <quicksilver> Cale: if you take the paulson parsing combinators, the way bind lets you name particular parts is very powerful
05:54:24 <quicksilver> Cale: older parsing combinators built up everything into tuples and then deconstructed them
05:54:42 <quicksilver> I don't think of the computation approach as a metaphor
05:54:53 <quicksilver> the computation approach is the *truth*! It's what they really are.
05:54:58 <Cale> No it's not.
05:55:00 * quicksilver has read Moggi, and drunk deep of the kool-aid.
05:55:18 <Cale> They're really triples consisting of an endofunctor and two natural transformations.
05:55:30 <nominolo> yeah
05:55:33 <Cale> Satisfying some laws :)
05:55:41 <nominolo> i don't care
05:55:59 <Cale> They show up all over mathematics as well
05:56:07 <quicksilver> Cale: right. But monads in haskell are, by definition, the computation type.
05:56:16 <Cale> Well, so is everything in Haskell :)
05:56:19 <quicksilver> right
05:56:21 <nominolo> most programmers aren't mathematicians
05:56:29 <quicksilver> that's the "they" in my sentence
05:56:35 <quicksilver> that's what they [haskell monads] really are
05:56:38 <quicksilver> not all monads
05:56:42 <wli> The computation metaphor was useless for me.
05:56:42 <Cale> nominolo: Right, which is why we use the metaphor.
05:56:56 <wli> And remains so, actually.
05:56:56 <Cale> wli: Isn't it exactly the metaphor you're advocating?
05:57:07 <Cale> You're saying just look at the code.
05:57:13 <wli> I'm advocating ditching metaphors altogether.
05:57:14 <Cale> That is the computation metaphor.
05:57:20 <nominolo> maybe we should have different approaches for mathematicians
05:57:40 <wli> You've got a higher-order function stashed in a data structure and are doing things with it.
05:58:03 <nominolo> how is that not computation?
05:58:05 <quicksilver> but that's not even true, is it?
05:58:06 <wli> No metaphor. No magic. No mystery.
05:58:13 <Cale> Not quite true.
05:58:14 <quicksilver> where is the higher-order function in 'Nothing'
05:58:21 <wli> Varies by monad.
05:58:31 <Cale> quicksilver: I think maybe he's referring to the typeclass dictionary?
05:58:35 <nominolo> ok, wait.  you have two approaches for DSLs-as-monad
05:58:39 <quicksilver> ah
05:58:44 <nominolo> deep embedding and shallow embedding
05:58:45 <quicksilver> well that's an implementation detail of haskell
05:58:46 <Cale> I don't usually think of that as a "data structure", but okay.
05:58:48 <quicksilver> that's not important :)
05:59:20 <wli> It's crucially important to getting squishy metaphor talk out of the way and showing what's really happening.
05:59:20 <Cale> nominolo: hmm?
05:59:31 <Cale> wli: Well, sometimes.
05:59:43 <Cale> wli: Sometimes priming with good examples at a high level is good too.
06:00:02 <Cale> For example, I always like to give the following example before jumping into a discussion of ((->) e)
06:00:06 <quicksilver> again, I can't really accept the characterisation of computation as a metaphor.
06:00:19 <quicksilver> a metaphor is when you compare something to something it actually isn't
06:00:24 <quicksilver> like "quicksilver is a snake"
06:00:28 <Cale> > (do x <- id; y <- reverse; z <- map toUpper; return (x,y,z)) "hello"
06:00:39 <lambdabot>  ("hello","olleh","HELLO")
06:00:58 <quicksilver> a value of type "IO a" actually is a value representing a computation, which may do some IO, before returning a value of a type 'a'
06:01:01 <quicksilver> that's not a metaphor
06:01:04 <Cale> This doesn't actually explain how ((->) e) is implemented, but it directly shows what the meaning of the definition of it is.
06:01:04 <quicksilver> that's a descrption
06:01:05 <yitz> Rather than the computation metaphor, I like to emphasize the difference between step-by-step execution on the one hand, and specifying an idea as a series of steps (that are not necessarily *executed* in that order) on the other.
06:01:21 <Cale> quicksilver: That doesn't say what a monad in general is though.
06:01:26 <yitz> A good metaphor that came up on the cafe is a recipe for cooking.
06:01:29 <nominolo> Cale, in a shallow embedding your monad primitives are usually functions on haskell types,  in a deep embedding you basically build up a datastructure representing your program
06:01:33 <Cale> quicksilver: Do you know what metric completion is?
06:01:43 <Cale> (I don't know how much of a mathie you are)
06:01:44 <nominolo> the "run" function is then basically just an interpreter
06:01:52 <quicksilver> Cale: no, it doesn't. Yes, I do.
06:02:00 <yitz> A good cook does not necessarily follow the recipe step by step - but understands from it what the final product is supposed to be.
06:02:02 <Cale> quicksilver: Metric completion is a monad.
06:02:07 <quicksilver> yes, I know :)
06:02:20 <quicksilver> but I am tryign to talk about exclusively haskell monads.
06:02:48 <Cale> Even over Hask, it's a little bit questionable whether "computations" is always the best approach.
06:03:01 <Cale> I often don't think of the list monad computationally.
06:03:24 <quicksilver> I thnk that's quite fair
06:03:28 <quicksilver> I'm not saying it's always the best approach
06:03:35 <quicksilver> I'm saying "it's not a metaphor, it's a descrption"
06:03:36 <quicksilver> :)
06:03:54 <quicksilver> of course, it does depend on a slightly fuzzy definiton of 'computation'
06:03:55 <Cale> I'm of the opinion that anything beyond the definition is a metaphor :)
06:04:05 <Cale> and yeah, that's just fuzzy enough...
06:04:14 <nominolo> just start with one way to view them, and then show that there are so many others
06:04:20 <LeCamarade> Cale: Your line up there no work in-a de GHCi.
06:04:22 <Cale> The problem with the computation metaphor is that people don't generally know what computations are.
06:04:27 <LeCamarade> (do x <- id; y <- reverse; z <- map toUpper; return (x,y,z)) "hello"
06:04:35 <LeCamarade> That no work. Why?
06:04:39 <Cale> LeCamarade: :m + Control.Monad.Reader
06:04:52 <osfameron> yeah, metaphors work best when you know what the comparison is...
06:04:53 <LeCamarade> Cale: Cale Gibbard, I presume?
06:04:53 <dcoutts_> Cale: they're things wot do stuff, init? :-)
06:04:57 <Cale> LeCamarade: yep
06:05:44 <LeCamarade> Control.Monad.Reader. Interesting what a simple magazine can do with data!
06:05:45 <fasta> How can one cast an STArray containing Maybe FooBars to one containing Maybe Zorks? (when it's known at run-time that they both only contain Nothing values)?
06:05:48 <Cale> Monads are only a specific kind of computation, and so that description can be sort of unhelpful if you're not really careful.
06:06:13 <Cale> LeCamarade: hehe
06:06:25 <Cale> LeCamarade: Also, Control.Monad.Instances will work in 6.6+
06:06:34 <twanvl> fasta: unsafeCoerce?
06:06:38 <Cale> LeCamarade: Personally, I think that instance deserves to be in the Prelude.
06:06:49 <roconnor> map (const Nothing)
06:07:12 <fasta> roconnor: without traversing the entire structure again.
06:07:23 <quicksilver> Cale: no! type! errors! newbies! help!
06:07:26 <quicksilver> :)
06:07:29 <Cale> quicksilver: hehe
06:07:39 <Cale> quicksilver: Well, maybe we'll keep map and (.) separate for now :)
06:07:51 <Cale> Even though they really *are* the same thing.
06:08:01 <twanvl> No, they're not
06:08:07 <fasta> Don't you mean fmap?
06:08:09 <Cale> They're both fmap
06:08:11 <quicksilver> I wish there was a way to get at fmap for homogenous tuples
06:08:20 <twanvl> (.) is better generalized as (<<<)
06:08:28 <Cale> Just specialised at different types.
06:08:33 <quicksilver> I often end up writing [foo,bar,baz] = map blah [x,y,z]
06:08:46 <quicksilver> which is kind of daft, because it's a runtime pattern match check
06:08:56 <fasta> quicksilver: I do the same
06:09:01 <quicksilver> wish I could write (foo,bar,baz) = map blah (x,y,z)
06:09:34 <fasta> quicksilver: you can do that with a simple type class.
06:09:39 <quicksilver> probably the best I can do is class Tuple t where tmap :: (a->a) -> t a -> t a
06:09:50 <quicksilver> that is, a copy of Functor
06:09:52 <vincenz> instance Functor
06:09:54 <hpaste>  smashor pasted "helloworld.hs" at http://hpaste.org/3365
06:09:54 <quicksilver> but with a different name
06:10:09 <quicksilver> vincenz: conflicts with the other instance we have for 2-tuples
06:10:17 <vincenz> quicksilver: wrap em with a dataconstructor
06:10:18 <fasta> > fmap (+1) (1,2)
06:10:25 <quicksilver> vincenz: ugly as hell
06:10:30 <lambdabot>  (1,3)
06:10:30 <vincenz> nah
06:10:34 <vincenz> if you use record syntax
06:10:35 <fasta> quicksilver: not Functor
06:10:45 <vincenz> unAllEqual . fmap foo . AllEqual
06:10:51 <quicksilver> right
06:10:51 <vincenz> :)
06:10:53 <quicksilver> very very ugly!
06:10:55 <vincenz> hah
06:10:56 <Cale> I actually rather like fmap = second
06:10:58 <vincenz> it's just function application
06:11:04 <quicksilver> let (foo,bar,baz) = map blah (x,y,z)
06:11:09 <quicksilver> that's what I want to write
06:11:24 <vincenz> right
06:11:25 <quicksilver> unAllEqual . .... . AllEqual would be really nasty code noise
06:11:27 <Cale> fmap really should be renamed to map
06:11:27 <vincenz> so use what I propose
06:11:31 <vincenz> quicksilver: and then
06:11:40 <quicksilver> I'd rather make a special type class with 'tmap'
06:11:40 <vincenz> tmap f = unEqual . fmap f . AllEqual
06:11:42 <Cale> If we want a specialised version of map for lists, call it lmap. Nobody will use it.
06:11:45 <vincenz> quicksilver: this is more generic
06:12:00 <quicksilver> Cale: no! type! errors! newbies! help!
06:12:12 <Cale> quicksilver: heh
06:12:13 <quicksilver> Cale: (translated: yes, I agree)
06:12:27 <quicksilver> vincenz: yes, that's true
06:12:42 <Cale> I don't think it's really so hard to explain some baby-talk version of what a Functor is.
06:12:49 <twanvl> We should work on improving the type errors then
06:12:49 <quicksilver> neither do I
06:12:55 <Cale> twanvl: that too :)
06:12:59 <quicksilver> but I don't really believe haskell will change the definiton of 'map'
06:13:00 <osfameron> aren't Lists the most obvious example of things that you'd want to map over?
06:13:03 <quicksilver> although I'd love it if they did
06:13:08 <Cale> quicksilver: Why not?
06:13:15 <quicksilver> because I'm a pessimist :)
06:13:19 <quicksilver> I hope I'm wrong
06:13:24 <vincenz> a realistic pessimistc, like myself
06:13:30 <Cale> quicksilver: We can make you wrong.
06:13:30 <vincenz> also called a realist :)
06:13:39 <Cale> Who wants to fork base?
06:13:47 <Cale> I do, I do!
06:13:48 <Cale> hehe
06:14:02 <vincenz> Cale: yes, and let's add numeric prelude :)
06:14:02 <quicksilver> yes, a forked base could work
06:14:07 <quicksilver> but it's a lot of work, probably
06:14:11 <vincenz> not to mention class aliases and a better split
06:14:12 <Cale> Yeah, it is.
06:14:14 <vincenz> of TCs
06:14:16 <quicksilver> someone was writing one here a few weeks back, weren't they?
06:14:21 <quicksilver> with (.) for fmap
06:14:32 <twanvl> no!
06:14:40 <twanvl> (<$>) for fmap, but not (.)
06:14:49 <Cale> Also, we need some additional switches in GHC, which will eventually become defaults, but we'll keep that secret until it's too late :)
06:14:59 <Cale> twanvl: why?
06:15:05 <twanvl> arrows
06:15:19 <Cale> arrows?
06:15:35 <nominolo> > ((+3) `fmap` (*5)) 45
06:15:37 <lambdabot>  228
06:15:50 <twanvl> (.) :: Arrow (~>) => (b ~> c) -> (a ~> b) -> (a ~> c)
06:15:51 <Cale> There are way more examples of functors than arrows :)
06:16:13 <nominolo> unreadable
06:16:23 <twanvl> That doesn't mean that (.) is the right operator for functors
06:16:43 <vincenz> (.) only really maes sense for functors when you're doing reader-monad
06:16:44 <Cale> It worked rather nicely when I tried it for a while.
06:16:56 <Cale> vincenz: no, it actually works quite well
06:16:57 <nominolo> i'm happy with using specific names for specific uses
06:17:09 <twanvl> Another advantage of <$> is that it looks great with <*>
06:17:16 <vincenz> > let (.) = fmap in (+1) . [1,2,3]
06:17:17 <lambdabot>  [2,3,4]
06:17:24 <vincenz> Cale: I dunno
06:17:49 <quicksilver> > let (.) = fmap in (*2) . (+1) . [1,2,3]
06:17:50 <lambdabot>  Couldn't match expected type `a -> a' against inferred type `[a1]'
06:17:58 <Cale> vincenz: If you can think of a list as being a function from some initial subset of the naturals to elements, then that's actually composition. :)
06:17:59 <quicksilver> that's not very nice...
06:18:03 <vincenz> wrong infix
06:18:08 <quicksilver> I know
06:18:11 <quicksilver> it's still not nice...
06:18:29 <quicksilver> actually
06:18:31 <vincenz> > let (-<) = fmap in (+1) -< [ 1,2,3]
06:18:32 <lambdabot>  [2,3,4]
06:18:35 <fasta> twanvl: I think using <$> only looks acceptable for experienced Haskell programmers. Otherwise, it's just obfuscation.
06:18:38 <vincenz> > let (-<) = fmap in (+3) -< (+1) -< [ 1,2,3]
06:18:39 <lambdabot>  Couldn't match expected type `a -> a' against inferred type `[a1]'
06:18:42 <Cale> um, that's because you forgot the type sig
06:18:42 <quicksilver> shouldn't it be associative in any case?
06:18:49 <Cale> MR
06:18:50 <vincenz> Cale: . tends to be symmetrical, while it's use in fmap is not
06:18:59 <phlpp> @src map
06:18:59 <lambdabot> map _ []     = []
06:18:59 <lambdabot> map f (x:xs) = f x : map f xs
06:19:03 <masak> > pl \x y z -> f (g x y) z
06:19:03 <lambdabot>  Parse error
06:19:05 <phlpp> @src fmap
06:19:05 <lambdabot> Source not found. Maybe if you used more than just two fingers...
06:19:06 <quicksilver> Cale: eh?
06:19:11 <Cale> > let (.) :: (Functor f) => (a -> b) -> (f a -> f b); (.) = fmap in (*2) . (+1) . [1,2,3]
06:19:13 <lambdabot>  [4,6,8]
06:19:15 <Cale> see?
06:19:16 <masak> @pl \x y z -> f (g x y) z
06:19:16 <lambdabot> (f .) . g
06:19:26 <quicksilver> oh!
06:19:27 <Cale> You used a pattern binding to define it
06:19:28 <quicksilver> thanks :)
06:19:30 <vincenz> Cale: it's ugly to use . for functors
06:19:35 <vincenz> Cale: fmap is not a symmetrical operator
06:19:47 <quicksilver> (.) is not symettric either, vincenz
06:19:49 <Cale> vincenz: Yes, but a version of associativity still applies.
06:19:54 <quicksilver> it's associative but that's different
06:19:55 <vincenz> quicksilver: typewise it is
06:20:01 <Cale> Yeah, and (.) isn't quite symmetrical
06:20:05 <Cale> :t (.)
06:20:07 <lambdabot> forall b c a. (b -> c) -> (a -> b) -> a -> c
06:20:21 <vincenz> reasonably symmatrical
06:20:24 <vincenz> it takes functions on both sides
06:20:27 <vincenz> of 1 param
06:21:12 <Cale> The important thing is the associativity, and you can use the functoriality to prove the associative law holds after generalisation, even though the types involved change rather interestingly.
06:21:36 <Cale> That is, that f . (g . x) = (f . g) . x
06:21:58 <quicksilver> but here the (f.g) part is, in fact, forced to be 'ordinary function composition', right?
06:22:16 <Cale> Translated, that says  fmap f (fmap g x) = fmap (f . g) x
06:22:16 <vincenz> quicksilver: no the . is in the reader-functor
06:22:19 <vincenz> if it's on the left
06:22:23 <quicksilver> same thing
06:22:29 <Cale> Which is *exactly* the law which functors satisfy.
06:22:32 <quicksilver> . in the reader-functor is ordinary function compositin
06:22:35 <vincenz> quicksilver: not quite, that's more restrictred than any old function
06:22:43 <yitz> Cale: empirically, fmap and (.) seem to obey the same laws.
06:22:53 <quicksilver> more restricted in what way?
06:22:54 * vincenz still prefers -<<
06:22:54 <Cale> In fact, it's very beautiful.
06:22:57 <yitz> @type (.)((.)(.))
06:22:59 <lambdabot> forall b c a a1 a2. (a2 -> a1 -> b -> c) -> a2 -> a1 -> (a -> b) -> a -> c
06:23:09 <yitz> @type (.)(.)(.)(.)
06:23:10 <vincenz> quicksilver: nm
06:23:11 <lambdabot> forall a a1 b c a2. (a -> a1 -> b -> c) -> a -> a1 -> (a2 -> b) -> a2 -> c
06:23:13 <yitz> same
06:23:15 <Cale> Heh, this conversation has convinced me even more that fmap should be (.)
06:23:20 <yitz> @type fmap(fmap fmap)
06:23:22 <lambdabot> forall a b (f :: * -> *) (f1 :: * -> *) (f2 :: * -> *). (Functor f, Functor f1, Functor f2) => f2 (f1 (a -> b)) -> f2 (f1 (f a -> f b))
06:23:28 <Cale> However, I think a prefix form is still nice to have around
06:23:30 <yitz> @type fmap fmap fmap fmap
06:23:31 <lambdabot> forall (f :: * -> *) (f1 :: * -> *) a b (f2 :: * -> *). (Functor f, Functor f1, Functor f2) => f (f1 (a -> b)) -> f (f1 (f2 a -> f2 b))
06:23:33 <Cale> Which I think should be called map
06:23:34 <yitz> same
06:23:44 <phlpp> let fac n = n * (fac (n-1)) where fac 1 = 1
06:23:49 <phlpp> arg
06:23:53 <osfameron> map is the same as function composition?
06:24:03 <twanvl> Cale: Arrow around the world will hate you!
06:24:04 <Cale> osfameron: yes, when you look at things the right way
06:24:04 <quicksilver> arguably (map (+1)) is a more pleasant partial application than ((+1).) as a secton
06:24:11 <Cale> twanvl: they have <<<
06:24:15 <twanvl> bah
06:24:15 <quicksilver> but it's all taste
06:24:21 <pjd> Cale: wasn't map = fmap in pre-Haskell98?
06:24:25 <Cale> pjd: yes
06:24:33 <twanvl> Functors have (<$>) :)
06:24:45 * osfameron falls over
06:24:56 <Cale> osfameron: Want to see how?
06:25:07 <Cale> > fmap (+1) [1,2,3]
06:25:09 <lambdabot>  [2,3,4]
06:25:13 <Cale> That's normal map
06:25:16 <roconnor> > ((+1) `fmap` (*2)) 3
06:25:17 <lambdabot>  7
06:25:27 <Cale> That's map for functions from a fixed type.
06:25:45 <Cale> fmap :: (a -> b) -> (f a -> f b)
06:25:45 <osfameron> how is that a map?
06:25:54 <Cale> Let f = ((->) e)
06:26:09 <Cale> then fmap :: (a -> b) -> (e -> a) -> (e -> b)
06:26:15 <Cale> which is the same type as (.)
06:26:33 <roconnor> @djinn  (a -> b) -> (e -> a) -> (e -> b)
06:26:34 <lambdabot> f a b c = a (b c)
06:26:35 <TuringTest> osfameron: I think "import Control.Monad.Reader" is needed for the Functor instance of (->)
06:26:43 <Cale> yes, it is.
06:26:48 <Cale> Unfortunately ;)
06:26:56 <phlpp> is it possible to define faculty (n!) by using iterate?
06:27:05 <roconnor> @. pl djinn  (a -> b) -> (e -> a) -> (e -> b)
06:27:06 <lambdabot> f = (.)
06:27:07 <Cale> phlpp: Factorial?
06:27:10 <phlpp> yeah
06:27:13 <phlpp> faculty, lol ;)
06:27:14 <phlpp> sorry
06:27:15 <roconnor> @fmap pl djinn  (a -> b) -> (e -> a) -> (e -> b)
06:27:16 <lambdabot> http://www.haskell.org/hawiki/HaskellUserLocations
06:27:47 <Cale> Sort of.
06:27:51 <osfameron> Cale: thanks - but I don't get what (f)map is doing on a function instead of a list in the first place.  So I think this is beyond me right at the mo.
06:28:07 <Cale> osfameron: fmap is a class function
06:28:14 <Cale> @src Functor
06:28:15 <lambdabot> class  Functor f  where
06:28:15 <lambdabot>     fmap        :: (a -> b) -> f a -> f b
06:28:19 <TuringTest> phlpp: Why would you want to use iterate?
06:29:20 <phlpp> TuringTest: don't know. it doesn't have to be iterate. i just thought there is a kind of lambda expression for factorial
06:29:40 <phlpp> (and yeah, lambda != iterate, but i hope you got my point)
06:30:11 <TuringTest> phlpp: http://www.willamette.edu/~fruehr/haskell/evolution.html
06:30:12 <lambdabot> Title: The Evolution of a Haskell Programmer
06:30:19 <osfameron> Cale: which on a list maps the list from a list of a's to a list of b's
06:30:32 <osfameron> Cale: and on a function composes it ?
06:31:00 <TuringTest> phlpp: Of course, only one of the examples on that page uses iterate...
06:31:08 <Sizur> honorable dudes, does anybody know if there is any project already going on concerning authentication and authorization? something like this:
06:31:08 <Sizur> clearance :: (Action f) => [Role] -> [Role] -> f -> maybe f
06:31:13 <Cale> osfameron: yeah, which if you think of the function as being a giant indexed container, makes perfect sense
06:31:40 <Cale> (Arrays are just functions with finite, contiguous domains)
06:31:56 <phlpp> TuringTest: oh, cool, thanks
06:32:10 <osfameron> Cale: hmmm, I started writing a sarcastic reply and midway through sort of understood what you meant :-)
06:32:19 <Cale> :)
06:33:09 <osfameron> Cale: ok, that begins to make some sort of sense
06:34:08 <Cale> Function composition g . f, sort of applies the function g to each of the elements of the codomain of f.
06:34:33 <Cale> Well, it produces the function which makes it look that way, anyway.
06:35:42 <Cale> Or if you think of a function as a set of ordered pairs, it applies the function g to each of the second components of those pairs.
06:35:58 <Cale> Which incidentally, is exactly what the Functor instance for a single ordered pair does:
06:36:04 <Cale> > fmap (+1) (10,20)
06:36:13 <osfameron> and are fmap and (.) currently implemented as synonyms for the Functor instance?
06:36:16 <lambdabot>  (10,21)
06:36:20 <TuringTest> osfameron: Or consider a list as a function.  A list is a function from indices to elements.  "map" is then (.)
06:36:22 <Cale> osfameron: no
06:36:47 <Cale> osfameron: The idea is to define (.) to mean fmap, and rename fmap to map
06:37:17 <Cale> (Just to keep a prefix form around)
06:37:32 <Cale> Interestingly enough, associativity still holds beautifully.
06:37:35 <osfameron> Cale: which is internally more consistent, but which will lead to even worse error messages than normal?
06:37:57 <Cale> osfameron: hehe, maybe worse
06:37:59 <twanvl> To me the problem is that (.) has two incompatible generalizations, fmap and (<<<). While the latter may be used less, I think it makes more sense
06:38:52 <Cale> Are those generalisations really incompatible, I wonder...
06:39:11 <phlpp> > sum $ map Char.digitToInt $ show $ product [1..100]
06:39:13 <lambdabot>  648
06:39:27 <fasta> You can make a class ArrowFunctor (trivial solution) ;)
06:39:32 <Cale> After all, if (~>) is an Arrow, don't we have a Functor instance for ((~>) e) ?
06:39:44 <quicksilver> yes
06:39:57 <quicksilver> because you 'pure up' the fn (e -> f)
06:40:00 <quicksilver> erm
06:40:03 <quicksilver> (f -> e) sorry
06:40:07 <quicksilver> into f ~> e
06:40:07 <Cale> Sure we do, it's  fmap f x = pure f <<< x
06:40:10 <quicksilver> right
06:40:17 <quicksilver> however this fails for arrows-without-pure
06:40:25 <quicksilver> which some people believe are an interesting class :)
06:40:35 <Cale> Yeah, but screw that.
06:40:38 <Cale> hehe
06:40:39 <quicksilver> for example, the tangible values stuff is actualy *not* arrows
06:40:44 <osfameron> (~>) is a pretty operator.
06:40:46 <quicksilver> and they're always quoted as an example of arrows
06:40:50 <twanvl> Also, functional references
06:40:51 <quicksilver> but they don't have pure
06:41:06 <Cale> They can use separate operators if they're not going to be as nice.
06:41:21 <quicksilver> it may be that arrow as a type class isn't that useful
06:41:23 <CUBErt> Hello.. Im trying to teatch quickCheck to generate Maybe Ints.. How do I do that?
06:41:25 <quicksilver> pure is too restricting :)
06:41:46 <twanvl> quicksilver: see the libraries@ list
06:42:36 <quicksilver> twanvl: recently? I only subscribed a month or so ago
06:43:14 <pBot-> How can I extract the String out of a (Int,String) pair?
06:43:17 <twanvl> Yes, there is a "Add Compositor class as superclass of Arrow" thread going on right now
06:43:31 <twanvl> ?type snd
06:43:34 <lambdabot> forall a b. (a, b) -> b
06:43:35 <CUBErt> pBot-: (Int,String) = String
06:44:06 <quicksilver> twanvl: oh yes, I see it. /me reads.
06:44:38 <pBot-> so if I do
06:44:41 <pBot-> molseqNameLength c = (name c,length (sekvString c))
06:45:15 <pBot-> btw what if I have (String, String) and want the first one?
06:45:19 <pBot-> Then I can't do = String
06:45:22 <yitz> CUBErt: why not just generate Ints and wrap them in Just? Then add a single case for Nothing.
06:45:45 <CUBErt> pBot-: you cant name both of them to "String", you could do (Str1, Str2)
06:45:56 <CUBErt> Then it would be (Str1, Str2) = Str1
06:46:28 <quicksilver> pBot-, CUBErt: there seem to be some confusion here about the different between types and values?
06:46:32 <quicksilver> String is the name of a type
06:46:35 <quicksilver> you don't get to choose that :P
06:46:40 <quicksilver> values have lower case names
06:46:47 <CUBErt> yitz: the problem is that I dont really understand how to teatch quickCheck things...
06:46:50 <pBot-> quicksilver, I meant in general.. if I have (type1, type2)
06:46:58 <quicksilver> pBot-: 'snd' works in general
06:47:02 <quicksilver> so does a let-bindinf
06:47:06 <quicksilver> let (_,b) = foo
06:47:15 <quicksilver> ^^ extracts second component of foo, discards first
06:47:54 <CUBErt> yitz: i have; Instance Arbitrary a => Arbitrary (Maybe a) where; arbitrary = ... ; return (Maybe a)
06:48:05 <CUBErt> Is it right so long?
06:48:35 <CUBErt> return (Maybe a) where a is the things i do where there are dots.
06:50:09 <quicksilver> that loks like a very strange use of 'return'
06:50:16 <quicksilver> return doesn't have naything to do with defining instances
06:50:22 <twanvl> Isn't there an instance for Maybe in the library already?
06:50:24 <quicksilver> (unless you happen to be defining and instance of Mnad :P)
06:51:05 <CUBErt> quicksilver: should I just return a?
06:51:17 <twanvl> My docs say there is, so you don't need to define it yourself
06:52:12 <quicksilver> CUBErt: you shuoldn't return anything
06:52:20 <quicksilver> CUBErt: return is a specil function used with monads
06:52:28 <quicksilver> CUBErt: it has nothing to do with instance declarations at all
06:53:00 <CUBErt> when i run quickChek prop_update(which my property is named) I get this error message;
06:53:00 <quicksilver> apologies for my poor typing...
06:53:06 * quicksilver sacks his typist
06:53:09 <CUBErt>  No instance for (Arbitrary (Maybe Int))
06:53:15 <CUBErt>     Probable fix: add an instance declaration for (Arbitrary (Maybe Int))
06:53:23 <quicksilver> can you paste your code?
06:53:25 <quicksilver> @hpaste
06:53:25 <lambdabot> Haskell pastebin: http://hpaste.org/new
06:53:44 <quicksilver> preferably the property and the instance
06:53:48 <hpaste>  (anonymous) pasted "(no title)" at http://hpaste.org/3366
06:53:55 <CUBErt> http://hpaste.org/3366
06:54:16 <CUBErt> Whoa
06:54:20 <CUBErt> All my code didnt fit.
06:54:21 <CUBErt> Sorry
06:55:33 <nominolo> @instances Arbitrary
06:55:38 <lambdabot> Couldn't find class `Arbitrary'. Try @instances-importing
06:56:09 <hpaste>  (anonymous) pasted "(no title)" at http://hpaste.org/3367
06:56:25 <CUBErt> quicksilver: there is the code that is relevant.
06:58:37 <quicksilver> where is the abitrary instance for maybe?
06:58:50 <doserj> should be in Test.QuickCheck
06:59:04 <quicksilver> I think I mislead you though, of course you can use return inside arbitrary instances. I completely forgot that there is a monadic interface to arbitrary.
06:59:15 <CUBErt> doserj: i have imported that one.
06:59:17 <quicksilver> doserj: indeed, but CUBErt is trying to write his own
06:59:19 <quicksilver> odd
07:02:10 <quicksilver> twanvl: Oh! That's what lenses are :)
07:02:46 <twanvl> I think lenses and functional references are the same thing
07:04:14 <pBot-> So if molseqNameLength (head molseqs) returns a pair I can just do:
07:04:14 <pBot-> molseqNameLength (head molseqs) (_, b) for the second value in the pair?
07:04:42 <quicksilver> twanvl: yes. I didn't know that until I read this thread. :)
07:04:49 <quicksilver> pBot-: nearly
07:04:58 <pBot-> quicksilver, ok?
07:05:02 <quicksilver> either : snd (molseqNameLength (head molseqs))
07:05:18 <quicksilver> or : let (_,b) = molseqNameLength (head molseqs) in .....
07:05:24 <quicksilver> (and then just use b to refer to it)
07:05:30 <pBot-> snd meaning "second" and fst meaning "first"?
07:05:33 <quicksilver> right
07:05:46 <quicksilver> @src snd
07:05:46 <lambdabot> snd (_,y) =  y
07:06:45 <pBot-> @src trd
07:06:46 <lambdabot> Source not found. Have you considered trying to match wits with a rutabaga?
07:06:48 <pBot-> @src thr
07:06:48 <lambdabot> Source not found. My brain just exploded
07:06:53 <pBot-> is there a third? ^^
07:06:55 <pBot-> just curious, lol
07:07:13 <dankna> why would there be?  fst and snd won't work on a triple
07:07:21 <pBot-> oh ok, didn't know
07:07:41 <dankna> the type decl tells you that.  it's not like Lisp where a tuple is a bunch of cons cells, it has a predetermined length :)
07:08:17 <dankna> (... although it occurs to me that comparisons to Lisp are probably illuminating to a vanishingly small number of people, but oh well)
07:08:50 <quicksilver> maybe it *is* like lisp, but it's like dotted pairs
07:08:56 <dankna> that's true too
07:09:02 <quicksilver> and haskell lists are made from cons cells
07:09:04 <dankna> well, I think of Haskell lists as being made of cons cells
07:09:05 <dankna> righ
07:09:07 <dankna> *right
07:09:47 <dankna> the existence of lists and tuples as two different things in Haskell is one of those things that I just sort of accept until I'm experienced enough to decide whether there's a rationale for it or not :)
07:10:26 <quicksilver> fair enough
07:10:27 <dylan> well, a list must contain all the same type.
07:10:36 <quicksilver> the rationale is the type system, essentially
07:10:43 <allbery_b> yeh, isn;t it an issue of the type syystem?
07:10:44 <dankna> hmm - yes, okay.
07:10:45 <allbery_b> heh
07:10:51 * allbery_b slow today
07:12:45 <Cale> Also, the Functor instance is really different :)
07:12:53 <Cale> > fmap (+1) [1,2]
07:12:55 <lambdabot>  [2,3]
07:12:58 <Cale> > fmap (+1) (1,2)
07:12:59 <lambdabot>  (1,3)
07:13:04 * dankna blinks rapidly
07:13:08 <quicksilver> Cale: which is where we came in, sin't it?
07:13:13 <Cale> hehe
07:13:14 <dankna> > fmap (+1) (1, 2, 3)
07:13:15 <lambdabot>   add an instance declaration for (Functor ((,,) t t1))
07:13:15 <lambdabot>     In the expression...
07:13:18 <quicksilver> Cale: because I wanted the homogenous function instance
07:13:26 <dankna> > fmap (+1) [1, 2, 3]
07:13:27 <lambdabot>  [2,3,4]
07:13:29 <Cale> and tuples are of a size which is known at compile time
07:13:30 <dankna> I see
07:13:58 <Cale> Also, there are basically no functions which work on all tuples, pairs, and 3-tuples are completely different types.
07:14:18 <Cale> (you'd have to write the version for each size separately)
07:14:33 <Cale> (though you could use typeclasses usually to give them the same name)
07:14:33 <dankna> right, but that's a result of the distinction, not a justification for it
07:14:57 <dankna> although I see how it has benefits, since yeah, there's no type for "list of a given size"
07:15:03 <pBot-> @src chain
07:15:04 <lambdabot> Source not found. Sorry about this, I know it's a bit silly.
07:15:09 <Cale> right
07:15:14 <pBot-> Ye, lambdabot... Silly you :
07:15:15 <pBot-> :'(
07:15:37 <seliopou> dankna: you can do that
07:18:23 <dankna> oh?  I thought I saw something about it once, but the answer seemed to be along the lines of "no, not really, although there's a not-recommended workaround if you insist..."
07:18:40 <seliopou> It's a type system extentsion
07:19:44 <seliopou> It's fun to see a type error when you try to compile a program that's not-so-obviously taking the head of an empty list.
07:19:50 <seliopou> warm fuzzies
07:19:52 <dankna> hah, yes
07:21:22 <yitz> A tuple is an anonymous ADT (=type defined by "data"). The way I see it, they are intentionally inconvenient to use to encourage us to write meaningful data types.
07:21:51 <dankna> hah
07:22:04 <dankna> well, I get the motivation there, but I don't really approve :)
07:22:09 <Cale> Well, pairs are convenient, that's about it
07:22:28 <yitz> If you call () a tuple, it's also convenient.
07:22:35 <Cale> hehe, yes
07:22:38 <dankna> amusement
07:22:42 <Cale> For anything larger, you're generally much better off using a proper datatype.
07:22:56 <Cale> (That you've defined yourself)
07:23:26 <Cale> That way, you can do things like use record syntax to document what the components are.
07:23:38 <seliopou> and make them abstract
07:23:48 <Cale> that too :)
07:23:59 <TuringTest> and make some elements strict.
07:24:11 <Cale> You're allowed to hide the constructors of your own type behind a module boundary
07:24:35 <Cale> Which means that if you later decide you don't like the representation, you can change it.
07:24:57 <TuringTest> But tuples are great at allowing a function to return multiple values without creating a special name type.
07:25:05 <Cale> Right.
07:25:15 <TuringTest> :t unfold
07:25:24 <lambdabot> Not in scope: `unfold'
07:25:27 <Cale> If it only happens in one place in your library, it's probably sensible to use a tuple.
07:25:35 <yitz> But if there are more than 2 return values, there must be a reason, so define a meaningful typ.
07:25:35 <Cale> (that is, in an equivalent fashion)
07:26:02 <Cale> Sometimes 3, though even 3 can be annoying at times.
07:26:20 <yitz> Prelude ++ thrd
07:26:25 <hpaste>  (anonymous) pasted "(no title)" at http://hpaste.org/3368
07:26:35 <CUBErt> quicksilver: i solved it :)
07:26:41 <CUBErt> http://hpaste.org/3368
07:27:26 <yitz> CUBErt: use the name and title fields on hpaste - it posts here automatically.
07:27:37 <CUBErt> Ok :)
07:27:38 <Cale> CUBErt: you might want to make Nothing occur a little less frequently.
07:27:54 <pBot-> @src transpose
07:27:54 <lambdabot> transpose []             = []
07:27:54 <lambdabot> transpose ([]   : xss)   = transpose xss
07:27:54 <lambdabot> transpose ((x:xs) : xss) = (x : [h | (h:t) <- xss]) : transpose (xs : [ t | (h:t) <- xss])
07:28:09 <CUBErt> the frequency of Nothing shouldnt matter in the property i wrote.
07:28:10 <pBot-> Oh, transpose merges lists, huh
07:28:33 <yitz> Transposes rows and columns in a 2-dim list
07:29:14 <hpaste>  (anonymous) annotated "(no title)" with "(no title)" at http://hpaste.org/3368#a1
07:29:14 <Cale> CUBErt: To do that, you can do something like  oneOf (return Nothing : replicate 7 (return (Just a)))
07:29:25 <yitz> >  [[(i,j) | i<-[1..3]] j<-[4..6]]
07:29:25 <lambdabot>  Parse error
07:29:35 <CUBErt> Cale: Ah, simple :)
07:30:08 <CUBErt> Thanks for the help everybody.. Now i must be going home from school :)
07:30:09 <yitz> ?
07:30:24 <quicksilver> yitz: no | in the outer list comp?
07:30:25 <yitz> >  [[(i,j) | i<-[1..3]] |j<-[4..6]]
07:30:27 <lambdabot>  [[(1,4),(2,4),(3,4)],[(1,5),(2,5),(3,5)],[(1,6),(2,6),(3,6)]]
07:30:30 <yitz> tnx
07:30:39 <yitz> >  transpose [[(i,j) | i<-[1..3]] |j<-[4..6]]
07:30:40 <lambdabot>  [[(1,4),(1,5),(1,6)],[(2,4),(2,5),(2,6)],[(3,4),(3,5),(3,6)]]
07:33:30 <fasta> > let () = seq undefined undefined -- no match failure in 6.9
07:33:31 <lambdabot>  Parse error
07:33:40 <fasta> > let () = seq undefined undefined
07:33:40 <lambdabot>  Parse error
07:33:45 <fasta> ?
07:33:50 <seliopou> in ...
07:34:02 <fasta> Oh, right, that only works in ghci
07:34:06 <quicksilver> > let () = seq undefined undefined in 4
07:34:08 <lambdabot>  4
07:34:12 <seliopou> (in a monad)
07:34:18 <quicksilver> fasta: why would you expecta  match failure?
07:34:22 <fasta> > let () = seq undefined undefined in 1
07:34:23 <quicksilver> fasta: let binds lazily
07:34:24 <lambdabot>  1
07:34:37 <fasta> quicksilver: I thought it had to match ()
07:34:41 <quicksilver> it does
07:34:44 <quicksilver> but it's not observable
07:34:48 <quicksilver> because you never check :P
07:34:51 <vincenz> > let [x] = seq undefined undefined in 4
07:34:51 <quicksilver> let bindings are lazy
07:34:52 <lambdabot>  4
07:34:56 <quicksilver> only case forces things
07:35:06 <quicksilver> > case seq undefined undefined of () -> 4
07:35:08 <lambdabot>  Undefined
07:35:09 <quicksilver> boom
07:35:16 <vincenz> so...
07:35:21 <vincenz> this means that let () = ...
07:35:25 <vincenz> will never force anything
07:35:29 <vincenz> since there's no way to refer to any part of ()
07:35:31 <quicksilver> right
07:35:32 <fasta> quicksilver: ok, that explains it.
07:35:47 <vincenz> so let bindings are fored when variables inside of it are forced
07:35:49 <vincenz> interesting
07:35:57 <vincenz> I always thought only the variables were lazy, not the whole binding
07:36:08 <fasta> vincenz:  me too
07:36:12 <vincenz> > let [x,y] = 1:undefined in x
07:36:14 <lambdabot>  Undefined
07:36:32 <quicksilver> 'essentially', case is the only thing in haskell which forces
07:36:33 <vincenz> > let [x,y] = 1:undefined in 2
07:36:34 <lambdabot>  2
07:36:49 <quicksilver> in practice, 'if' does as well and probably a couple of other higher level things
07:37:01 <vincenz> if is just a simplified case
07:37:03 <Cale> > let x : ~[y] = 1 : undefined in x
07:37:05 <lambdabot>  1
07:37:19 <yitz> function def'ns: guards, patterns
07:37:19 <vincenz> if a then b else c === case a of True -> b; _ -> c
07:37:47 <quicksilver> yitz: patterns dont' do any forcing on their own
07:38:00 <quicksilver> yitz: only if they occur in case or function defns
07:38:10 <quicksilver> (of course function defns are case really)
07:38:17 <yitz> right, in function defns
07:38:34 <quicksilver> guards only force if that branch actually gets evaluated
07:38:39 <quicksilver> so I'm not sure I'd put them in the list
07:38:41 <Cale> Right, multiple clauses of a function definition turn into a case expression
07:38:53 <yitz> case is just an uglier way of writing guards :)
07:39:10 <Cale> and I suppose that guards turn into a horrible nested mess of case expressions :)
07:39:15 <yitz> guards are just a prettier way of writing an Exit monad :)
07:40:02 <yitz> (which is why there is no use for pattern guards that justifies the confusion. but don't get me started again...)
07:40:19 <quicksilver> I like pattern guards!
07:40:39 <yitz> oh, no here we go
07:40:56 <yitz> well you're lucky, I have to go now :)
07:41:02 <Cale> Heh, I hadn't seen MonadExit. The Exit e monad is just Either e though
07:41:21 <Cale> (With a more suitable name for the way that you think about it as a computation)
07:41:25 <yitz> right. except without the requirement of an Error instance
07:41:25 <quicksilver> Cale: it is in a sense but it has an unusual interpretation
07:41:41 <quicksilver> Cale: because the 'normal' use of the exit monad is that you will always eventually exit
07:41:52 <quicksilver> Cale: so it's not an exceptional condition, it's the default condition
07:42:01 <yitz> I would have given that monad instance to Either, and given the one for exceptions a different name. But that's hindsight.
07:42:09 <Cale> Yeah, but Left e is pretty neutral terminology :)
07:42:42 <yitz> I must admit, "Right" meaning not an error is cute.
07:43:18 <yitz> data Either a b = Sinister a | Right b
07:44:03 <sieni> data Either a b = Wrong a | Right b
07:44:23 <quicksilver> data Either a b = TwoLegs a | FourLegs b
07:44:27 <yitz> sinister means left in latin
07:44:44 <quicksilver> indeed it does
07:47:13 <Plouj> hi
08:02:34 <eyeris> I installed the Text.CSV hackage. I've been using it in ghci. Now I want to compile my program, but I am getting undefined references. Do I have to point ghc to the .so file manually?
08:03:13 <Saizan> do you use --make when compiling your program?
08:03:33 <eyeris> ahh, thanks
08:03:41 <eyeris> I was not using any options.
08:03:54 <eyeris> What does --make do exactly? It is in't in the --help message.
08:04:21 <allbery_b> it tells ghc to chase dependencies automatically like ghci does
08:04:22 <Saizan> it links other packages/modules in your binary
08:04:42 <allbery_b> otherwise you need to explicitly specify any packages used with -package foo (for appropriate foo)
08:04:43 <eyeris> ok
08:05:16 <fasta> eyeris:        --make Build a multi-module Haskell program, automatically figuring out
08:05:19 <fasta>               dependencies. Likely to be much easier, and faster,  than  using
08:05:21 <fasta>               make; see for details..
08:05:33 <fasta> eyeris: it seems to he there at least in my version
08:05:37 <fasta> be*
08:05:46 <eyeris> in the --help?
08:05:57 <fasta> eyeris: oh, in the manpage.
08:06:05 <fasta> --help is pretty pointless, imho
08:06:25 <eyeris> it is... but it isn't supposed to be :)
08:06:36 <fasta> eyeris: submit a patch ;)
08:07:17 <eyeris> I'm actually thinking about submitting a patch that just tells you that you need either --make or --package when there are any undefined references.
08:07:49 <fasta> eyeris: that sounds like a UI improvement
08:08:04 <Saizan> or better, make --make the default
08:08:21 * allbery_b thought there was already a PR for that one
08:08:26 <eyeris> Saizan
08:08:31 <eyeris> Saizan's thinking
08:08:34 <fasta> I think when a program stops processing for some reason(there always is a reason) it should state that reason or shut up.
08:09:13 <fasta> I.e. completely unlike Haddock which just returns internal data structures.
08:12:12 <eyeris> Is there a common haskell.vim script?
08:12:30 <Taejo> the compiler can automatically derive certain classes (Show, Eq, etc) but is there any way I can tell it how to derive my own classes?
08:13:19 <eyeris> Taejo try it
08:13:22 <eyeris> I bet it works
08:13:26 <TomMD> @where vim
08:13:26 <lambdabot> I know nothing about vim.
08:13:30 <TomMD> @where vi
08:13:30 <lambdabot> I know nothing about vi.
08:13:32 <eyeris> It would just use the default implementation
08:13:40 <eyeris> But I'm just a beginner
08:13:48 <eyeris> @where haskell.vim
08:13:49 <lambdabot> http://urchin.earth.li/~ian/vim/haskell.vim
08:13:50 <BSP_> it can derive through newtypes if you turn on the right flag
08:13:58 <Taejo> eyeris, what do you mean?
08:13:59 <fasta> Code 139 is a segfault?
08:14:00 <Saizan> Taejo: you can with Template Haskell, there's a package on hackage dedicated to this called derive
08:14:09 <Taejo> Saizan, thx
08:14:11 <fasta> Haskell isn't supposed to do that!
08:14:45 <fasta> (but yes, I am using something that might break something)
08:15:06 <TomMD> Don't do unsafe writes to random memory locations ... that is _bad_
08:15:06 <fasta> Odd, when compiled, it runs fine
08:16:43 <fasta> Hmm, how annoying, it's reproducable.
08:17:24 <allbery_b> <fasta> Code 139 is a segfault?
08:17:35 <allbery_b> SIGSEGV + core-dumped flag, yes
08:25:16 <Arnar> hey folks..
08:25:33 <Arnar> what's the correct terminology for a definition of a function for some parameters..
08:25:36 <Arnar> instance?
08:25:58 <EspenG> how can i import fuctions like chr. ord and isLower into my programs?
08:26:06 <Arnar> ?index chr
08:26:07 <lambdabot> Data.Char
08:26:12 <Arnar> ?index ord
08:26:12 <lambdabot> Data.Char
08:26:20 <Arnar> EspenG: import Data.Char
08:26:28 <EspenG> ok, stupid me :P
08:26:54 <phlpp> hm
08:26:55 <byorgey> Arnar: no, 'instance' usually refers to a particular type being an 'instance' of a type class
08:27:10 <phlpp> i think YAHT should be written as book with more exercises included
08:27:16 <Arnar> byorgey: yes.. that's why I feel incomfortable with it..
08:27:35 <fasta> Arnar: calling a function a function would be a start
08:27:39 <Arnar> couldn't think of a better word (partly because I'm not a native-english speaker)
08:27:45 <phlpp> it's very much information in a very compressed form
08:27:53 <phlpp> too much for me, actually
08:27:57 <Arnar> fasta, yeah, but I want to refer to a specific form of it..
08:27:58 <fasta> Arnar: some people use equation, but that's WRONG.
08:27:59 <byorgey> Arnar: I don't know if there's a term for what you're talking about... maybe something like 'case'?
08:28:16 <Arnar> byorgey: hmm, yes.. that probably describes it best
08:28:20 <EspenG> ok, now i get a new error: http://norskwebforum.no/pastebin/9761
08:28:59 <allbery_b> that would be correct
08:29:09 <Arnar> EspenG: are you trying to create an executable?
08:29:13 <Arnar> or an object?
08:29:17 <allbery_b> you told it to produce a complete program, but you have only defined functions, not something to invoke them
08:29:26 <byorgey> EspenG: if you want to compile your code to an executable, you need to include a function called main, with type IO ().
08:29:27 <EspenG> aaahh.. i see
08:29:38 <byorgey> EspenG: if you just want to play around with the functions you've defined, use ghci.
08:29:55 <byorgey> i.e. just type 'ghci caesar.hs'
08:30:10 <byorgey> or run ghci and then load it by typing ':load caesar.hs'
08:30:28 <EspenG> aahh.. i see
08:30:29 <EspenG> thanks
08:31:08 <phlpp> btw. hello byorgey :)
08:31:34 <Arnar> EspenG: if you modify caesar.hs, you can issue ":reload" inside ghci to make it pick up the changes
08:32:44 <Taejo> why doesn't Haskell QuickCheck have shrinking?
08:32:46 <EspenG> i got one more question. is it possible for haskell-mode in emacs to automatically indent the :: a -> a -> b  part to be the same indention as the = or do i have to do that my self?
08:33:49 <pejo> Taejo, nobody implemented it?
08:34:02 <pejo> Taejo, we would love to have it though.
08:34:20 <byorgey> phlpp: hi phlpp =)
08:34:23 <Taejo> pejo, I've heard the version of haskell at Chalmers has it. Maybe that's not ture
08:35:01 <pejo> Taejo, oh. That's nice.
08:35:39 <byorgey> hm, why did I bother writing 'phlpp:' before saying 'hi phlpp'?  I'm... not sure. =)
08:35:42 <allbery_b> EspenG: in haskell-indent minor mode, there are key sequences to  reindent stuff.  try C-h m
08:35:45 <dcoutts_> Taejo: QuickCheck2 does have it
08:35:58 <EspenG> allbery_b: thanks, i'll try that
08:36:10 <Taejo> dcoutts_, is QuickCheck2 still vaporware or can I get it somewhere?
08:36:23 <dcoutts_> Taejo: it is available somewhere, but I'm not sure where :-)
08:36:34 <dcoutts_> Taejo: I'd ask dons and bringert
08:36:48 <allbery_b> (which shows themode-specific help.  the haskell-mode I have running on this machine is out of date... the one in most emacs distirbution has didferent keybidings from the current downloadable haskell-mode)
08:37:01 <Taejo> dcoutts_, your talk was one of the few at ICFP I understood; thank you!
08:37:10 <bringert> pejo, Taejo: darcs.haskell.org/QuickCheck
08:37:17 <dcoutts_> Taejo: heh, thanks :-)
08:37:45 <phlpp> byorgey: eheh
08:42:54 <ddvlad> hi, how can I convert from a character to an integer?
08:43:05 <quicksilver> ddvlad: which integer would you like?
08:43:21 <profmakx> 42
08:43:24 <ddvlad> Int i guess, thought it doesn't matter, i'm still learning
08:43:47 <quicksilver> no, I don't mean which type
08:43:50 <quicksilver> I mean, which number?
08:43:58 <profmakx> > (read "1") :: Integer
08:44:00 <lambdabot>  1
08:44:00 <quicksilver> > map (const 42) "hello"
08:44:01 <lambdabot>  [42,42,42,42,42]
08:44:11 <quicksilver> that converted all the letters in hello to 42...
08:44:19 <quicksilver> but probalby you don't want to convert every letter to 42
08:44:28 <quicksilver> probably you have some particular onversion scehem in mind
08:44:48 <byorgey> ddvlad: if you want to convert a string to the corresponding integer, you can use 'read'.  If you just want to convert a single character like '0', '1', etc. to the corresponding Int value, you can use the digitToInt function in Data.Char.
08:44:56 <ddvlad> I have a Char (say '9') and would like to convert it to the equivalent number. trick is that it's a char, not a string
08:45:10 <byorgey> > digitToInt '1'
08:45:11 <lambdabot>  1
08:45:32 <ddvlad> oops, I just realise. can i use something like:
08:45:33 <bos31337> CosmicRay: wonderful typoblogging
08:45:35 <quicksilver> you can also use read, but it may not be what you want
08:45:39 <quicksilver> > read ['9']
08:45:40 <lambdabot>  9
08:45:41 <ddvlad> > read ('9':[])
08:45:43 <lambdabot>  9
08:46:02 <ddvlad> quicksilver: yes, that's what I was looking for
08:46:27 <ddvlad> thank you all for your answers and apologies for the basic question. I am what would be called a n00b :-)
08:46:28 <CosmicRay> bos: thanks
08:46:38 <byorgey> ddvlad: no need to apologize! =)
08:47:27 <sieni> @pl \n -> [1..n] >> (:[])
08:47:27 <lambdabot> (>> return) . enumFromTo 1
08:47:31 <ddvlad> byorgey: almost asked a few other things of the same nature, but I eventually figured them out. all this new syntax and the concepts are making me pay less attention to trivial things
08:48:17 <phlpp> byorgey: what does g@(Graph v1 e1) stand for in search g@(Graph v1 e1) src dst (some guards stuff here) where Graph is sth like data Graph v e = Graph [(Int,v)] [(Int,Int,e)]
08:48:35 <quicksilver> phlpp: that's a pattern match
08:48:40 <byorgey> ddvlad: yes, Haskell is good at allowing you to pay less attention to trivial things =)
08:48:46 <quicksilver> phlpp: but it has an 'alias' which is the @
08:49:04 <quicksilver> phlpp: if it just said (Graph v1 e1) then v1 would be the vertices and e1 the edges, right?
08:49:23 <mrd> phlpp: that's like saying: pattern match (Graph v1 e1) and then let g = Graph v1 e1 ...
08:49:38 * quicksilver mutters at mrd
08:49:41 <phlpp> ah ok
08:49:45 <mrd> now you have three variables in scope: v1, e1, and g
08:49:52 <quicksilver> this was a gradual explanation I was waiting for confirmation he had caught up ;)
08:50:23 <sieni> :t (>> return) . enumFromTo 1
08:50:26 <lambdabot>     Couldn't match expected type `(->) a' against inferred type `[]'
08:50:26 <lambdabot>     Probable cause: `enumFromTo' is applied to too many arguments
08:50:35 <byorgey> heh, there ought to be a word for that, when you're working through a careful explanation, and then someone else makes a short statement that makes everything immediately clear =)
08:51:02 <quicksilver> then the part before the @ is just a name for the 'whole thing'
08:51:12 <quicksilver> mrd: actualy it's not the same as what you said. Better sharing :)
08:51:26 <mrd> indistinguishable :P
08:51:39 <quicksilver> depending on your definition of observation, yes
08:51:40 <mrd> that's my way of glossing over the details
08:52:20 <byorgey> explanemption?
08:52:44 <phlpp> erm, ok, seem's that i did'nt have been understanding this. why could i not write search (Graph v1 e1) src dst?
08:52:52 <phlpp> i mean, 'g' isn't used in the whole source
08:53:01 <quicksilver> phlpp: you could
08:53:07 <phlpp> (it's first source from YAHT 8.4.2)
08:53:08 <quicksilver> phlpp: maybe in a previous version g was used :)
08:53:17 <quicksilver> phlpp: or maybe the author is preparing to use it later
08:53:56 <byorgey> or maybe g is used in a lot of functions with similar arguments, and the author just got in the habit of writing g@(Graph v1 e1) whether g was used or not.
08:54:29 <phlpp> ok, at the moment it's not important for understand this section
08:54:35 <phlpp> i think/hope
08:56:04 <sioraiocht> psssht, can i please build GHC w/o ghc?
08:56:20 <mauke> just emerge ghc-bin first!
08:58:44 <Cale> Heh, Ubuntu's servers must be pretty bogged down. I'm only getting 77KiB/s from them, whereas usually I get ~700.
08:59:20 <phlpp> oh
08:59:23 <phlpp> i'm sorry
08:59:28 <phlpp> g is actually used
08:59:31 <quicksilver> ;)
08:59:41 <phlpp> ah ok, i got the idea behind this
09:00:30 <sioraiocht> mauke: I use os X =p
09:00:41 <sioraiocht> and had to reinstall it last night
09:00:52 <sioraiocht> is bootstrapping ghc hard?
09:00:52 <fasta> Odd they don't use torrents to distribute packages
09:01:03 <mauke> isn't there a binary package?
09:01:05 <Taejo> Cale, that's why I installed before release
09:01:21 <sioraiocht> mauke: yes, it's 64 megs, that takes forever when my bandwidth is so capped =/
09:01:46 <hpaste>  Julien Oster pasted "straightlinem.hs" at http://hpaste.org/3369
09:01:47 <Cale> How capped?
09:01:49 <mauke> :(
09:01:53 <Taejo> I don't know how many patches there've been since yesterday, tho, since my mirror only updates around 6pm UTC
09:02:11 <sioraiocht> Cale: it takes me around 30-40 minutes to download 60 megs
09:02:30 <mauke> that's a lot quicker than building ghc
09:02:34 <Cale> sioraiocht: That's less time than it will take to compile it, even assuming it's bootstrapped.
09:02:41 <sioraiocht> I'll compile it anyway
09:02:49 <sioraiocht> this is just to bootstrap the compilation, imo
09:03:02 <quicksilver> Cale: that does depend quite a lot on your machine
09:03:06 <Cale> Well, yes
09:03:08 <quicksilver> Cale: on my last machine ghc took 6 hours
09:03:13 * sioraiocht tries to avoid compiled binaries as much as possible
09:03:26 <mauke> I ONLY USE SOURCE BINARIES
09:03:33 <sioraiocht> lol
09:03:50 <Cale> sioraiocht:  I hold you personally responsible for the eventual heat death of the universe.
09:03:57 <sioraiocht> Cale: kk ;)
09:04:09 <sioraiocht> I don't think we'll be around to see it, sooo...
09:04:16 <mauke> sioraiocht: http://timedoctor.org/index.php?id=2183
09:04:17 <lambdabot> Title: timedoctor.org - SWEET CHRISTMAS! BIG-MOUTHED FLOATING THINGIES! IT'S ALWAYS SOM ...
09:04:28 <iank> o_O
09:04:42 <Cale> Seriously though, compiling things yourself when you're not hacking on them and there are binaries available is a stupid waste of time.
09:04:46 <Arnar> so.. is there a way of installing a lambdabot like prompt locally?
09:05:01 <sioraiocht> rofl
09:05:17 <quicksilver> Arnar: yes, but it's not easy
09:05:19 <Arnar> tried it the other day but the distribution was borked
09:05:20 <Cale> Arnar: yes, lambdabot :)
09:05:22 <quicksilver> @go ghci on acid
09:05:23 <lambdabot> http://www.cse.unsw.edu.au/~dons/code/goa/
09:05:23 <lambdabot> Title: Index of /~dons/code/goa
09:05:28 <Cale> Oh, there's GoA too
09:05:29 <phlpp> hm, seems like i have to look for some other monad explination/tutorial
09:05:35 <Cale> But lambdabot works in local mode.
09:05:35 <allbery_b> that's lambdabot interface to ghci
09:05:44 <allbery_b> lambdabot by itself in local mode provides a prompt
09:05:45 <Arnar> GoA is what I tried..
09:05:48 <Cale> phlpp: Which are you reading?
09:05:50 <Arnar> didn't have much luck :/
09:06:01 <allbery_b> ()GoA is currently broken I think)
09:06:27 <Arnar> where can I find labdabot?
09:06:30 <phlpp> Cale: i'm working on YAHT, but there the monad's chapter builds up on some knowledge about some graph searching algorithms
09:06:35 <mauke> @where lambdabot
09:06:35 <lambdabot> http://www.cse.unsw.edu.au/~dons/lambdabot.html
09:06:51 <Cale> phlpp: Oh, yeah, don't use that for monads :)
09:06:52 <phlpp> where then a class Computation is created.. but that's not necessary
09:06:54 <phlpp> the point is
09:07:05 <gkr> YAHT?
09:07:09 <Cale> Computation is the same as Monad, effectively
09:07:11 <mauke> @where yaht
09:07:11 <Cale> IIRC
09:07:11 <lambdabot> PDF: http://darcs.haskell.org/yaht/yaht.pdf Wikibook: http://en.wikibooks.org/wiki/Haskell/YAHT
09:07:11 <phlpp> it's hard to understand this stuff about his computation class
09:07:13 <sioraiocht> yet another haskell tutorial
09:07:15 <phlpp> and how this leads to monads
09:07:17 <Cale> phlpp: Okay
09:07:29 <Arnar> mauke thanks
09:07:30 <Cale> phlpp: Are you more interested in I/O or in monads in general?
09:07:46 <phlpp> monads in general, actually
09:07:55 <Cale> I've written three tutorials, one of which has been translated into Russian :)
09:08:01 <phlpp> cool
09:08:16 <Cale> http://www.haskell.org/haskellwiki/Monads_as_Containers
09:08:18 <sioraiocht> I wonder how many people learn about monads are let down when they realise they aren't arcane magic..
09:08:18 <lambdabot> Title: Monads as containers - HaskellWiki
09:08:30 <sioraiocht> no offense phlpp, it's just the number one thing everyone is interested in
09:08:30 <Cale> http://www.haskell.org/haskellwiki/Monads_as_computation
09:08:30 <kilimanjaro> Can anybody recommend a book or resource for someone interested in learning type theory and semantics? I'm a math student and I don't know any cat theory but I have studied abstract algebra, and I think this stuff might be interesting to study
09:08:31 <lambdabot> Title: Monads as computation - HaskellWiki
09:08:34 <osfameron> we need a (poignant) haskell tutorial with cartoon foxes!
09:08:43 <puusorsa> CHUNKY BACON!
09:08:44 <Cale> http://www.haskell.org/haskellwiki/Introduction_to_IO
09:08:45 <lambdabot> Title: Introduction to IO - HaskellWiki
09:08:46 <sioraiocht> kilimanjaro: do you want type theory or category theory?
09:08:55 <phlpp> sioraiocht: i don't think monads are arcane magic
09:08:55 <mauke> @where tapl
09:08:55 <lambdabot> http://www.cis.upenn.edu/~bcpierce/tapl/
09:08:56 <sioraiocht> kilimanjaro: Type and Programming Languages by Benjamin Pierce
09:09:15 <sioraiocht> phlpp: I didn't think you did, was just making a hasty generalisation
09:09:19 <phlpp> ok
09:09:21 <kilimanjaro> cool thanks
09:09:33 <kilimanjaro> I plan on taking the second logic course next spring (it's not often offered)
09:09:43 <kilimanjaro> maybe there will be some overlap
09:09:44 * sioraiocht hated his logic classes.
09:09:58 <arcatan> CHUNKY BACON
09:10:03 <sioraiocht> hrm?
09:10:32 <eyeris> I think it requires arcane magic to ignore all the "ok, we're coming to Monads, please don't get scared" parts of Haskell texts :) They build them up to be much more than they are.
09:10:51 <sioraiocht> eyeris: yes, I don't even use them all that much, hehe
09:10:59 <Cale> eyeris: Well, there was a long time where monads had a really bad reputation.
09:11:01 <Rebooted> kilimanjaro: TAPL is a good place to start, it only teaches operational semantics though
09:11:17 <sioraiocht> Rebooted: I think that's a good starting place, though
09:11:22 <Cale> At least as far as comprehensibility was concerned.
09:11:26 <Arnar> "Setup.hs: cannot satisfy dependency fps>=0.7" <-- that one is not on hackagedb
09:11:33 <Arnar> @where fps
09:11:34 <lambdabot> http://www.cse.unsw.edu.au/~dons/fps.html
09:11:44 <Cale> Things have been refined and improved so much now though that it almost seems silly.
09:11:57 <sioraiocht> was dons PhD in writing random haskell libraries?1
09:11:58 <kilimanjaro> Rebooted, I was thinking about picking up http://www.amazon.com/Practical-Introduction-Denotational-Semantics-Cambridge/dp/0521314232/ref=pd_bbs_sr_1/103-7060664-3966244?ie=UTF8&s=books&qid=1192723882&sr=8-1
09:12:02 <lambdabot> http://tinyurl.com/yrqsfg
09:12:05 <quicksilver> Arnar: fps is renamed bytestring
09:12:06 <eyeris> Makes sense
09:12:14 <lament> eyeris: warning! This book is about to become really, really difficult!
09:12:15 <kilimanjaro> Rebooted, do you have any experience studying denotational semantics?
09:12:26 <Arnar> quicksilver: ok, I should get fps 0.7 to go with lambdabot though?
09:12:45 <kilimanjaro> I've studied posets lattices a bit, I haven't really gotten into the hairy CPO sort of stuff that seems to be prevalent in denotational semantics though
09:12:53 <Rebooted> kilimanjaro: i'm learning categorical semantics, but I don't know much "traditional" denotational semantics
09:13:02 <kilimanjaro> ahh
09:13:15 <kilimanjaro> maybe I'll just start learning category theory
09:13:49 <quicksilver> Arnar: I don't think so, no
09:13:56 <Arnar> ok..
09:13:56 <quicksilver> Arnar: I think that's just a package name hiccup
09:14:00 <quicksilver> but I don't know what the answer is
09:14:10 <byorgey> ?remember sioraiocht was dons PhD in writing random haskell libraries?
09:14:10 <lambdabot> I will remember.
09:14:14 <byorgey> hehe
09:14:19 <quicksilver> no, that was ndm's phd?
09:14:27 <sioraiocht> @quote sioraiocht
09:14:27 <lambdabot> sioraiocht says: if you made a type class the same name as a type, I'd stab you in the face
09:14:36 <sioraiocht> @quote sioraiocht
09:14:36 <lambdabot> sioraiocht says: [after fmap = (.)] omg; my life; is much happier now
09:14:55 <sioraiocht> LOL I don't remember that one!
09:15:00 <sioraiocht> @quote sioraiocht
09:15:00 <lambdabot> sioraiocht says: if you made a type class the same name as a type, I'd stab you in the face
09:15:11 <Cale> phlpp: I can also give you a personalised intro to monads, if you're interested, but I probably should take a nap sometime soon :)
09:15:24 <sioraiocht> I guess that's what I'm good for in this channel...
09:15:28 <Cale> (I didn't sleep, and it's noon)
09:15:37 <sioraiocht> Cale: GO TO SLEEP
09:15:47 <sioraiocht> Cale: are you canadian?
09:15:50 <Cale> sioraiocht: GOTO considered harmful
09:15:52 <Rebooted> kilimanjaro: theres a video on categorical semantics here: http://video.google.com/videoplay?docid=1878650318476022439&hl=en
09:15:53 <lambdabot> Title: Jonathan Sobel: Categorical Semantics (Dan Friedman&#39;s 60th Birthday)
09:15:58 <Cale> sioraiocht: yep
09:16:01 <phlpp> Cale: hm, i'm reading through your monads as containers tutorial
09:16:02 <dons> morning. time to wake up!
09:16:07 <Cale> phlpp: cool :)
09:16:12 <phlpp> Cale: cool style
09:16:12 <sioraiocht> Cale: ah, thought so, didn't recognise the ISP
09:16:12 <phlpp> ;)
09:16:13 <kilimanjaro> Rebooted, yea I've seen that
09:16:24 <Rebooted> kilimanjaro: and the book Categories, Types and Structures is free as a pdf
09:16:25 <phlpp> "If you will give me a blueberry for each apple I give you (a -> b), and I have a box of apples (f a), then I can get a box of blueberries (f b)." i like this one
09:16:31 <kilimanjaro> Rebooted, cool I'll look into that
09:16:40 <sioraiocht> WTF?
09:16:55 <sioraiocht> I would say that more describes functors, though
09:17:03 <phlpp> it does, actually
09:17:05 <sioraiocht> well, a monad IS a functor
09:17:14 <phlpp> :)
09:17:16 <Cale> sioraiocht: yes, I say that right after :)
09:17:20 <phlpp> yup
09:17:23 <sioraiocht> Oh wow.
09:17:27 <phlpp> ok, im continuing reading
09:17:32 <sioraiocht> I can has an understanding of category theory?
09:17:41 <Cale> Indeed you can.
09:17:47 <quicksilver> the difference between a functor-box and a monad-box
09:17:54 <quicksilver> is that with monads, we 'don't care' about nested boxes
09:18:05 <Cale> Well, we have a way to get rid of the nestin
09:18:06 <Cale> g
09:18:08 <quicksilver> right
09:18:14 <quicksilver> we have a special plan on how to unnest
09:18:16 <sioraiocht> @type join
09:18:18 <quicksilver> but we never unbox
09:18:19 <lambdabot> forall (m :: * -> *) a. (Monad m) => m (m a) -> m a
09:18:20 <quicksilver> we only un-nest
09:18:23 <mauke> join = FUSE BOXES!!
09:18:36 <Cale> CHUNKY BOXES?!
09:18:45 * sioraiocht facepalms.
09:20:14 <Beelsebob> quicksilver: but what if you have a bird in your nest and you want it in a box for dinner, but don't want to get punched in the monads?
09:20:51 <quicksilver> "Catch a fox and put him in a box and never let him go!"
09:21:14 <phlpp> If I have a box of apples (m a) and for each apple, you will give me a box of blueberries (a -> m b) then I can get a box with all the blueberries together (m b)
09:21:17 <phlpp> :D
09:21:20 <phlpp> this isn't a fair trade-off ;)
09:21:38 * DRMacIver feels dirty
09:21:44 <Beelsebob> why not? you want the spare boxes for when you go to tesco?
09:21:45 <DRMacIver> I just wrote an object pooling mechanism.
09:22:02 <quicksilver> compost them!
09:22:09 <quicksilver> cardboard and wood boxes both compost well
09:22:11 <lament> i really don't like that apples-to-blueberries explanation.
09:22:16 <quicksilver> although the wood ones take quite a long time
09:22:17 <puusorsa> weird, arrows make more sense than monads to me
09:22:25 <Beelsebob> I think it works quite well actually lament
09:22:35 <lament> i suppose i prefer the monads-as-computation approach.
09:22:38 <Beelsebob> puusorsa: you're not the only one
09:22:39 <DRMacIver> (hm. I didn't actually mean for that to be in this channel. Oops)
09:22:56 <hpaste>  purplepenguins pasted "(no title)" at http://hpaste.org/3370
09:23:06 <Rebooted> kilimanjaro: TAPL is still a good place to start if you've not read it before, though
09:24:08 <puusorsa> and it was nice to find that >>> combines functions
09:26:03 <puusorsa> btw, is there something like this defined that i just didnt find? a ->>> b = b $ a
09:26:24 <puusorsa> so i can do for example: "sdf sdjhsj dfjk sj" ->>> words >>> length
09:26:27 <Arnar> Could not find module `Data.ByteString.Char8':  it was found in multiple packages: fps-0.8 base  <- what's the best way to tackle this?
09:26:37 <quicksilver> puusorsa: yes, that's >>>
09:26:41 <quicksilver> puusorsa: in Control.Arrow
09:26:49 <quicksilver> oh, sorry
09:26:52 <quicksilver> misunderstood you
09:27:04 <dcoutts_> Arnar: unregister fps.0.8
09:27:14 <quicksilver> no, I'm not sure if there is a flip ($) defined anywhere
09:27:30 <Botje> @src <<< (Arr a b c)
09:27:30 <lambdabot> Source not found. Are you on drugs?
09:27:44 <Arnar> dons: how?
09:27:58 <Arnar> (sorry for the cluelessness)
09:28:10 <Arnar> bah, dcoutts_ ^^ meant you
09:28:11 <dcoutts_> Arnar: use: ghc-pkg unregister fps.0.8
09:28:18 <Arnar> thanks..
09:28:29 <dcoutts_> Arnar: actually it depends if it's a global or user package
09:28:38 <dcoutts_> if it's global you might need to use sudo
09:28:51 <dcoutts_> if it's a user package: ghc-pkg --user unregister fps.0.8
09:28:59 <Arnar> yeah, I installed it with sudo.. so I unregistered with sudo
09:29:15 <Arnar> but now it just complains that it can't find fps 0.8 :/
09:31:18 <dcoutts_> Arnar: do clean and configure again
09:32:02 <Arnar> can't configure without fps, which is why I installed it in the first place..
09:32:07 <Arnar> Setup.hs: cannot satisfy dependency fps>=0.7
09:32:15 <Arnar> can I remove the requirement from Setup.hs ?
09:32:20 <quicksilver> no, it needs bytestring
09:32:26 <quicksilver> do you not have bytestrings installed?
09:32:33 <quicksilver> it comes as default in the 'big' GHC packages
09:32:40 <quicksilver> btu if you installed from a distro which splits things up
09:32:48 <quicksilver> then it might be in another (Distro) sub package
09:32:55 <Arnar> quicksilver: looks like I do, but configure is still looking for fps
09:33:06 <dcoutts_> quicksilver, Arnar: he's got ghc-6.6.x so bytestring is in the base package there
09:33:16 <dcoutts_> so you can just remove the fps bit from the .cabal files
09:33:17 <Zao> Arnar: Just hack it out of the .cabal?
09:33:19 <phlpp> > (map (^2) [1..10]) == ([1..10] >>= \x -> [x^2])
09:33:21 <lambdabot>  True
09:33:24 <Arnar> Zao: yeah, trying that now
09:33:25 <phlpp> ah, cool.
09:33:31 <quicksilver> ah
09:33:39 <quicksilver> dcoutts_: didn't realise that :)
09:34:02 <mauke> > (map (^2) [1..10]) == ([1..10] >>= \x -> return (x^2))
09:34:03 <lambdabot>  True
09:34:21 <mauke> > (map (^2) [1..10]) == ([1..10] >>= return . (^2))
09:34:23 <lambdabot>  True
09:34:27 <phlpp> > (map (^2) [1..10]) == ([1..10] >>= \x -> (:[])x^2])
09:34:28 <lambdabot>  Parse error
09:34:31 <phlpp> aww
09:34:34 <Arnar> grr..
09:34:34 <mauke> > (map (^2) [1..10]) == (liftM2 (^2) [1..10])
09:34:35 <lambdabot>  Couldn't match expected type `[a]'
09:34:40 <mauke> > (map (^2) [1..10]) == (liftM (^2) [1..10])
09:34:42 <lambdabot>  True
09:35:11 <dons> quicksilver: return (foo `seq` bar) isn't what you mean :) (re. readFile io)
09:35:33 <Arnar> plucked it out of the cabal, configures ok but now I get a "not in scope" for some lines referring to qualified names in Data.ByteString.Char8
09:35:58 <dons> are you building lambdabot with ghc 6.8?
09:36:04 <dons> or 6.6.1?
09:36:32 <Arnar> 6.6.1
09:36:40 <Arnar> I should upgrade?
09:36:46 <cizra> Hi
09:37:04 <dons> no, that's fine.
09:37:08 <dons> ?version
09:37:08 <lambdabot> lambdabot 4p555, GHC 6.6 (Linux i686 2.66GHz)
09:37:09 <lambdabot> darcs get http://www.cse.unsw.edu.au/~dons/lambdabot
09:37:16 <dons> is the same one we use
09:37:27 <Arnar> ok..
09:37:32 <Arnar> it only seems to bomb on scripts/BotPP.hs:41:25: Not in scope: `B.breakChar'
09:37:42 <Arnar> other names starting with B. are fine
09:39:18 <cizra> > let countFilter cond (x:xs) = if cond x then (x:xs) else let (a, b) = countFilter cond (tail xs) in (a, b + 1) in countFilter (>5) [9, 1, 8, 2]
09:39:19 <lambdabot>  Couldn't match expected type `[t]' against inferred type `(a, b)'
09:39:26 <cizra> What's wrong here?
09:39:41 <mauke> let (a,b) = countFilter ...
09:39:45 <mauke> countFilter returns a list, not a tuple
09:40:00 <cizra> It should return a tuple.
09:40:04 * cizra fixes
09:40:07 <mauke> then (x:xs) is wrong
09:40:34 <cizra> yep
09:40:39 <mauke> > length . filter (>5) $  [9, 1, 8, 2]
09:40:41 <lambdabot>  2
09:41:13 <cizra> I must return a tuple of the filtered list and the number of removed elements.
09:41:22 <cizra> No, don't solve it for me. I need to stir my lazy brains.
09:41:48 <mauke> ah
09:42:42 <cizra> ([9,6,14*** Exception: Prelude.tail: empty list
09:42:43 <twanvl> > second length . partition (>5) $ [9,1,8,2,0]
09:42:45 <lambdabot>  ([9,8],3)
09:42:47 <cizra> Never seen this before..
09:42:56 <mauke> cizra: lazy exception
09:43:26 <cizra> \o/ works
09:43:29 <cizra> countFilter cond (x:xs) = if cond x then let (a, b) = countFilter cond xs in ((x:a), b) else let (a, b) = countFilter cond (tail xs) in (a, b + 1)
09:43:40 <mauke> > first length . partition (>5) $ [9,1,8,2,0]
09:43:41 <lambdabot>  (2,[1,2,0])
09:44:03 <mauke> cizra: doesn't handle []
09:44:23 <cizra> it does. I didn't paste it.
09:44:37 <mauke> tail xs looks wrong
09:45:11 <cizra> Might be..
09:45:46 <pBot-> @transpose
09:45:46 <lambdabot> Unknown command, try @list
09:46:03 <pBot-> @src transpose
09:46:03 <lambdabot> transpose []             = []
09:46:03 <lambdabot> transpose ([]   : xss)   = transpose xss
09:46:03 <lambdabot> transpose ((x:xs) : xss) = (x : [h | (h:t) <- xss]) : transpose (xs : [ t | (h:t) <- xss])
09:46:33 <cizra> mauke: Yep, it was wrong, (x:xs) already "tailed" it.
09:48:40 <phlpp> hm
09:49:02 <phlpp> ok, i have to stop reading about monads. about 8hours haskell is a hard job
09:49:15 <phlpp> at least for me
09:49:27 <[LeCamarade]> Eh. Why can't I say deriving Functor? Shouldn't be hard.
09:49:34 <phlpp> it would be nice if someday it would be a 'nice job' to me
09:50:53 <mauke> [LeCamarade]: for a newtype?
09:51:54 <[LeCamarade]> data X = Y deriving Functor. Dunno if it would be feasible.
09:53:49 <pBot-> (x : [h | (h:t) <- xss]), what's (h:t) <- xss mean? Is it assigining xss to (h:t)?
09:54:15 <byorgey> [LeCamarade]: data X a = Foo a a.  How would you automatically make that into a functor?
09:54:21 <mauke> it loops over xss, binding each element to (h:t)
09:54:25 <mauke> which means xss must be a list of lists
09:54:51 <mauke> byorgey: fmap f (Foo x y) = Foo (f x) (f y)
09:55:06 <twanvl> <[LeCamarade]>: Data.Derive can derive Functor
09:55:15 <byorgey> mauke: my point is that there are multiple legitimate ways to write a Functor instance, so it can't be done automatically by the compiler.
09:55:23 <mauke> byorgey: what's the other way?
09:55:36 <[LeCamarade]> Ah.
09:55:47 <[LeCamarade]> Hmm ... voodoo.
09:55:58 <byorgey> erm.... never mind, I was going to say fmap f (Foo x y) = Foo (f x) y
09:56:02 <byorgey> but that doesn't type check
09:56:09 * [LeCamarade] goes back to watching Coupling from which the Functor thing pulled him.
09:56:23 <twanvl> The only time there are multiple ways is when you are messing with CoFunctors
09:57:34 <byorgey> hmm
10:04:27 <Taejo> what does weak head normal form mean?
10:04:57 <noob> @src bracket
10:04:57 <lambdabot> bracket before after thing = block $ do
10:04:57 <lambdabot>     a <- before
10:04:57 <lambdabot>     r <- catch (unblock (thing a)) (\e -> do { after a; throw e })
10:04:57 <lambdabot>     after a
10:04:57 <lambdabot>     return r
10:09:15 <byorgey> Taejo: weak normal head form means that an expression has been evaluated just enough to know what the outermost data constructor is.
10:09:28 <Taejo> cool
10:09:53 <byorgey> but the rest of the value may still be an unevaluated thunk.
10:13:42 <Arnar> lambdabot seems to be referencing a function breakChar from Data.ByteString.Char8 - which doesn't exist..
10:13:51 <Arnar> any pointers on what I can use to replace this function?
10:13:59 <Arnar> ?index breakChar
10:13:59 <lambdabot> bzzt
10:14:08 <dcoutts_> Arnar: break (==c)
10:14:30 <Zao> http://www.nabble.com/Can't-build-Lambdabot-t3940862.html
10:14:32 <lambdabot> Title: Nabble - Haskell - Haskell-Cafe - Can't build Lambdabot
10:14:38 <Zao> Surprisingly, google saves the day :P
10:15:18 <Arnar> ?type break
10:16:09 <lambdabot> forall a. (a -> Bool) -> [a] -> ([a], [a])
10:17:33 <Arnar> ?type (==c)
10:17:35 <lambdabot> Not in scope: `c'
10:18:12 <[LeCamarade]> djinn ((a, b) -> b) -- snd
10:18:21 <[LeCamarade]> @djinn ((a, b) -> b) -- snd, right?
10:18:21 <Arnar> ah,
10:18:21 <lambdabot> Cannot parse command
10:18:36 <Arnar> > break (== ',') "nonni,manni"
10:18:38 <lambdabot>  ("nonni",",manni")
10:18:38 <[LeCamarade]> @djinn ((a, b) -> b)
10:18:39 <lambdabot> f (_, a) = a
10:19:39 <Arnar> dcoutts_: a type mismatch on [Char] and ByteString..
10:19:51 <dcoutts_> Arnar: B.break
10:20:03 <Arnar> dcoutts_: of course.. sorry
10:22:41 <Arnar> one stupid q. -- get an error about a hidden package.. I try ghc-pkg expose on it which indicates success..
10:22:44 <Arnar> but still I get the error
10:31:01 <Saizan> hi bakert!
10:31:09 <bakert> hi Saizan
10:31:24 <bakert> i am looking for the source of the frequency function in QuickCheck
10:31:31 <bakert> but lambdabot-fu is not up to it
10:32:13 <bakert> ?where QuickCheck
10:32:13 <lambdabot> http://www.cs.chalmers.se/~rjmh/QuickCheck/
10:32:21 <Saizan> ?docs Test.QuickCheck
10:32:21 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/QuickCheck/Test-QuickCheck.html
10:32:45 <bakert> aha magical source code link.  cool
10:33:13 <bakert> i am using frequency but unless i have encountered extremely unlikely results (always possible) i am not using it correctly :)
10:35:15 <Flynsarmy> Is there a way i can name getSymbols x so i don't have to tyep 'getSymbolx x' every time i want to use it?
10:35:43 <mauke> naem = getSymbols x
10:36:06 <bakert> damn, i AM using frequency correctly.  something else must be broken :(
10:36:53 <Flynsarmy> name = getSymbols x returns a  parser error on input =
10:37:06 <mauke> in ghci?
10:37:24 <Flynsarmy> Yes. i was loading a script using ghci
10:37:31 <mauke> let name = getSymbols x
10:38:01 <Arnar> any hint on "... is a member of package regex-compat-0.71, which is hidden"
10:38:06 <Arnar> tried ghc-pkg expose
10:38:48 <dcoutts_> Arnar: build-depends: regex-compat
10:39:00 <Arnar> ok
10:40:00 <Arnar> thanks..
10:40:30 <Arnar> well then.. at least I'm past that to the next error :)
10:40:34 <bakert> How would you represent this data structure in Haskell?  A set of scales that go from 0 to 20 with a name for both sides.  For example hot 0 == cold 20 and cold 15 == hot 5.
10:40:50 <bakert> So the total is always 20.  I need to access both hot and cold approximately equal amounts.
10:41:15 <bakert> And there's about 10 different scales.  Say, hot/cold, up/down, etc.
10:41:37 <yitz> bakert: How about a function that convert between hot and cold, etc.
10:41:38 <bakert> I mean, they're just an integer really.  Everything else is derivable from that.
10:42:08 <bakert> hot x = x
10:42:10 <bakert> cold x = 20 - x
10:42:11 <bakert> ?
10:42:22 <bakert> and just have loads of not connected functions?
10:42:28 <yitz> Just one function
10:42:32 <bakert> oh yeah
10:42:37 <bakert> with different names?
10:42:45 <bakert> i don't want to have to say
10:42:51 <bakert> inverse hot hotValue
10:42:55 <bakert> to get cold
10:42:59 <bakert> bit clunky
10:43:02 <Arnar> :hoogle pling_name
10:43:12 <Arnar> ?hoogle pling_name
10:43:13 <lambdabot> Language.Haskell.Syntax.pling_name :: HsName
10:43:59 <yitz> Use a type class - they all use the same function.
10:45:19 <Arnar> I give up :`(
10:45:26 <yitz> (that would be a 2-parameter type class though, so you need -fglasgow-exts flag)
10:46:00 <bakert> class Scale a where ... ???
10:46:09 <bakert> (sorry, not very au fait with typeclasses)
10:46:38 <mrd> ?babel fr en au fait
10:46:39 <lambdabot>   with the fact
10:46:57 <bakert> mrd: familiar
10:47:28 <bakert> "having experience or practical knowledge of a thing; expert; versed."
10:47:29 <bakert> :)
10:47:37 * yitz thinks about how to avoid multi-parameter class.
10:47:38 <bakert> that is precisely not me and typeclasses!
10:47:43 <mrd> ?babel fr en au pare
10:47:43 <lambdabot>   avoids
10:48:34 <bakert> What I really want to do is supply the values "hot" and "cold" once to something and then be able to say "hot x" and "cold x" forever more I guess.
10:48:48 <bakert> plus if the something will ensure my values are between 0 and 20 too that's good too.
10:49:10 <bakert> plus if i can wrap all my scales into one value that would be good too
10:49:24 <bakert> show hot scales = "15"
10:49:30 <mrd> class Scale a where hot :: a -> Int; cold x = 20 - hot x
10:49:48 <bakert> mrd: but then what about up/down
10:49:49 <bakert> ?
10:49:50 <bakert> :)
10:49:56 <mrd> what's that
10:50:08 <bakert> well there are about 10 of these scales
10:50:14 <bakert> that all kind of belong together
10:50:37 <bakert> so i want to be able to make hot/cold and up/down and left/right and nice/mean and good/evil
10:50:39 <mrd> they are data types which implement Scale?
10:50:49 <bakert> well Scale i just made up because each pair
10:51:01 <oerjan> @users
10:51:01 <lambdabot> Maximum users seen in #haskell: 420, currently: 413 (98.3%), active: 16 (3.9%)
10:51:01 <bakert> is a total of 20.  kind of like a sliding scale or axis or something
10:51:16 <bakert> hot = 20 - cold
10:51:20 <bakert> up = 20 - down
10:51:23 <bakert> evil = 20 - good
10:51:23 <bakert> etc.
10:51:31 <jcpetruzza> hi, anybody knows if there are binaries of ghc 6.8 rc available for intel macs somewhere?
10:51:36 <bakert> i'm just trying to think of a haskell-y way of representing this
10:51:47 <mrd> settle on a generic name and then define everything in terms of that
10:52:25 <bakert> so say i have my bundle of scales and i want to know the value for hot, what would i do then?
10:53:02 <bakert> have the bundle as a record and say:
10:53:05 <bakert> bundle.hot
10:53:18 <bakert> or 'inverse bundle.hot' for cold?
10:53:39 <bakert> i don't even mean "." do i.  how do i get values out of a record
10:53:45 <bakert> inverse hot bundle
10:53:50 <bakert> and hot bundle
10:53:51 <bakert> ?
10:54:02 <mauke> inverse (hot bundle)
10:54:18 <bakert> i'd definitely rather say
10:54:20 <bakert> cold bundle
10:54:40 <mauke> cold = inverse . hot
10:54:42 <yitz> OK, first the class way:
10:54:44 <puusorsa> cold = .. yes
10:55:07 <puusorsa> cold = inverse . hot .. that even makes sense :)
10:55:23 <yitz> class Invertible a b where {invert :: a -> b}
10:55:24 <puusorsa> up = inverse . down .... haskell is beautiful :)
10:55:33 <bakert> mauke: but then i need to go through all of my inverses defining a function.  i'd rather supply the words "hot" and "cold" somewhere and have it make sense of it :)
10:55:47 <bakert> Scale hot cold
10:55:55 <bakert> Scales = [Scale]
10:56:04 <puusorsa> not sure but maybe templatehaskell would help?
10:56:06 <bakert> as you can see i really have no idea :)
10:56:17 <yitz> newtype Hot a = Hot a
10:56:25 <yitz> newtype Cold a = Cold a
10:57:18 <yitz> instance Num a => (Hot a) (Cold a) where {invert (Hot x) = Cold (20 - x)}
10:57:39 <yitz> oops -
10:57:50 <yitz> instance Num a => Invertible (Hot a) (Cold a) where {invert (Hot x) = Cold (20 - x)}
10:57:58 <bakert> yitz: you got there.  but isn't that more lines of code than just defining a record and then defining 10 inverted functions? :)
10:58:14 <yitz> instance Num a => Invertible (Cold a) (Hot a) where {invert (Cold x) = Hot (20 - x)}
10:58:16 <yitz> etc.
10:59:10 <bakert> Something like this would be snazzy:
10:59:12 <yitz> Yes - but then you need to use a different function for each  type, so you can't write polymorphic functions that work on any invertible scale
10:59:19 <bakert> true
10:59:47 <bakert> instance Num a => Scale a where hot = a, cold = 20 - hot a
11:00:01 <bakert> which is total gibberish but you see what i mean :)
11:00:25 <bakert> then i could have one line for each pair and be happy.
11:01:40 <bakert> Or is there someway of saying
11:02:17 <bakert> class Scale a where {main :: a, invert :: a -> a}
11:02:27 <bakert> and then another line for each scale assigning names to main and invert???
11:03:47 <puusorsa> No instance for (Invertible (Cold Integer) b)
11:03:49 <yitz> Your class mean that for each type that is a scale, there is a special element of that type called the "main" one, and a scaling function.
11:04:13 <hpaste>  glguy pasted "dwm style dynamicLog" at http://hpaste.org/3371
11:04:27 <yitz> puusora: what did you try to compute?
11:04:38 <bakert> yitz: that sounds right!  doesn't it?
11:04:50 <puusorsa> let a = Cold 5 in invert a
11:05:32 <puusorsa> s/in/\n/ .. did it in ghci
11:06:06 <yitz> try let a = Cold 5 in invert a :: Hot Int
11:06:29 <puusorsa> No instance for (Invertible (Cold t) (Hot Int))
11:06:49 <bakert> so how do I say there is a typeclass called Scale and any type in that typeclass will define two functions value and inverse?
11:06:57 <puusorsa> let a = Cold (5::Int) in invert a :: Hot Int
11:07:02 <puusorsa> that works
11:07:21 <bakert> puusorsa: for some definition of "works" ;)
11:07:27 <puusorsa> but if the point was to do something not fuckgly ..
11:08:21 <bakert> i just feel like i should be able to define my data structure with (a) declaration of bundle of scales, (b) declaration of how the 20 and 20 - thing works and (c) one line for each scale with the names for the functions.
11:08:30 <bakert> but i don't think we've managed anything close to that :(
11:09:02 <yitz> I assume that they;re not all 20, but other values, right?
11:09:16 <bakert> no they are all 20
11:09:19 <bakert> handy :)
11:09:33 <oerjan> what about something like:
11:09:33 <bakert> they are really very very similar things but with different names!
11:09:58 <yitz> Well, then just define invert x = 20 -x and use regular numbers. What are the types for?
11:10:01 <oerjan> data Positive a = Positive Int; data Negative a = Negative Int
11:10:43 <oerjan> data Temperature; type Hot = Positive Temperature; Cold = Negative Temperature
11:10:52 <oerjan> oh wait, data constructors missing
11:11:28 <bakert> oerjan: looks promising
11:11:34 <bakert> yitz: i don't need to use types
11:11:41 <bakert> you are right that they are just numbers
11:11:50 <bakert> my concern is that deeper in my program i will want to say stuff like
11:12:10 <yitz> ok. my fault for introducing so much complexity. KISS.
11:12:11 <bakert> magic s = hot s + up s + right s + evil s
11:12:25 <yitz> Anyway, there's nice stuff you can do like that :)
11:12:30 <bakert> and do stuff based on whether hot is > 15
11:12:34 <bakert> and whatever
11:13:15 <bakert> if they are just numbers (and i they are, really) where shall i store them and what scaffolding shall i build in order to let me refer to them comfortably later, without writing 30 lines of code to define the scales.
11:13:28 <bakert> i mean i could just have a list of numbers
11:13:34 <bakert> and "know" which number is which scale.
11:13:37 <bakert> but that ain't pretty!
11:13:38 <bakert> :)
11:13:41 <TuringTest> bakert: I am just reading back and I cannot see what you are trying to use 'hot' and 'cold' for.   Could you give several example of their usage?
11:13:41 <oerjan> what about using a Map?
11:14:15 <bakert> TuringTest: sometimes i will want to know if the entity in question has a combined hot + up + evil + monkey score of 35 or more
11:14:24 <bakert> sometimes i will want to just know the value of "cold"
11:14:35 <bakert> that's about it really
11:15:03 <TuringTest> bakert: Is "cold" an Int or a function?
11:15:13 <bakert> either.  its 20 - hot!
11:15:25 <bakert> (that ! is an exclamation, not a factorial :) )
11:15:35 <bakert> basically there is one int
11:15:44 <bakert> and it represents both hot and cold.  either is derivable from it.
11:15:52 <bakert> 20 - cold = hot
11:15:55 <bakert> 20 - hot = cold
11:15:58 <TuringTest> bakert: That is a constraint.
11:16:09 <bakert> sounds good.  how do i write that in haskell?
11:16:27 <TuringTest> bakert: So the type of hot and cold are Int.  So they are just compile time constants.
11:16:48 <TuringTest> bakert: I see no data structure here
11:17:06 <bakert> well, these scales are all kind of related.  and they all belong to one entity.
11:17:16 <bakert> there are 10-15 scales from 0-20.  with a name at each end
11:17:27 <bakert> and i just need to decide how to represent them in my program.
11:17:41 <TuringTest> bakert: Try explaining that to me again.
11:17:46 <bakert> um.  ok.
11:17:57 <bakert> so here's Bob who is an entity.
11:18:12 <bakert> and Bob has some Scales.  which are hot-cold, left-right, up-down and evil-good.
11:18:23 <dons> so have we convinved andrew coppih to drop by yet?
11:18:43 <byorgey> dons: I tried =)
11:18:44 <bakert> at various points in my program i am going to want to say: "is Bob's hot > 10" or "is Bob's up + left + good > 25?"
11:19:01 <bakert> and being fairly unfunctional in brain patterns i can't quite work out how i should go about this :(
11:19:08 <bakert> i thought about a record
11:19:11 <TuringTest> bakert: Okay, I am seeing this more clearly now.
11:19:16 <byorgey> I think he came around once but happened to hit a period when no one was talking, and then later complained there was never anyone talking in the IRC channel =P
11:19:20 <dons> byorgey: me too!
11:19:23 <bakert> Scales { hot :: Int, good :: Int, up :: Int }
11:19:32 <bakert> and then defining the opposite functions separately
11:19:42 <bakert> cold s = 20 - (hot s)
11:19:44 <TuringTest> bakert: That looks sensible
11:19:50 <bakert> evil s = 20 - (good s)
11:20:00 <bakert> but i wanted something "neater" if possible.
11:20:12 <bakert> where i could say "MagicThing hot cold"
11:20:20 <bakert> and that would create me a hot-cold scale
11:20:24 <puusorsa> something without the repetitve code
11:20:27 <bakert> yes
11:20:34 <bakert> although
11:20:51 <bakert> inverse = (20 -)
11:20:57 <Cale> What is with these people who use Java and think they know something about static type systems?
11:20:58 <bakert> or something could be employed i suppose
11:21:06 <puusorsa> yes, and cold = inverse.hot
11:21:38 <bakert> so that's not the end of the world.  although there's still 15 lines snaking away from my record definition making me slightly uncomfortable.
11:21:53 <bakert> the trouble with anything that's not perfect is, i think it must be me and not haskell :)
11:22:02 <bakert> because i know so little
11:22:05 <TuringTest> bakert: How do you plan to create a Bob/Scales ?
11:22:32 <bakert> well at the moment Entity is just a record one of whose values is Scales.
11:22:41 <bakert> so it's just records all the way down
11:22:42 <bakert> :)
11:22:54 <bakert> there's actually more levels of nesting than that
11:23:15 <bakert> since i learnt about records everything looks like a record to me (in haskell)
11:24:18 <TuringTest> bakert: With what information  do you initialize / construct a Scales?
11:24:29 <Botje> records are just nicer tuples
11:24:52 <bakert> Well in the current code I changed it from being a record into being a weird thing :)
11:24:55 <EvilTerran> well, they're product constructors, anyway
11:24:57 <pmatos> Hello all, How can I convert a string containing digits to an integer?
11:25:05 <EvilTerran> > read "23" :: Int
11:25:12 <bakert> data TriaitName = Hot | Good | Up | Left
11:25:16 <lambdabot>  23
11:25:22 <bakert> data Trait = TraitName Int
11:25:40 <bakert> new = map (\x -> Trait x 10) [Hot .. Left]
11:25:45 <bakert> ???!!!
11:26:02 <mauke> undeclared data constructor 'Trait'
11:26:04 <EvilTerran> > readInt 16 isHexDigit digitToInt "DEADBEEF"
11:26:06 <lambdabot>  [(3735928559,"")]
11:26:08 <bakert> oh and TraitName derives Enum so i can do that range thing
11:26:46 <EvilTerran> > readHex "CAFFE1NE"
11:26:48 <lambdabot>  [(13303777,"NE")]
11:27:04 <EvilTerran> ups, there's no N in hex. i think i need more of that stuff... ;)
11:27:11 <pmatos> EvilTerran: Thx
11:27:27 <EvilTerran> > readInt 10 isDigit digitToInt "1337" -- also
11:27:28 <lambdabot>  [(1337,"")]
11:27:40 <olsner> > read "1337"
11:27:41 <lambdabot>  1337
11:27:53 <bakert> TuringTest: so you can see i have tried a few approaches :)
11:28:03 <bakert> they all start at 10, basically
11:28:15 <puusorsa> 2003 was the year of the satanic elite
11:28:22 <puusorsa> 1337 + 666 = 2003
11:28:27 <TuringTest> bakert: Okay...they all start at 10
11:28:31 <bakert> :)
11:28:38 <bakert> but they do get modified
11:29:16 <puusorsa> how about having them in the [-10..10] range?
11:29:48 <TuringTest> Does everything possess every scale?
11:30:27 <bakert> no it's a minor part of the program.  for tracking some values.  but an Entity has a name and an address and all sorts of other non-scaley things.  or have i misunderstood?
11:31:29 <TuringTest> bakert: Let me ask again:  There are 4 scales (Hot,Good,Up,Left) and every entity has (in addition to many other things) all four scales. yes?
11:32:26 <bakert> yes!
11:32:29 <bakert> sorry i see what you mean
11:35:59 <hpaste>  pmatos pasted "(no title)" at http://hpaste.org/3372
11:36:22 <pmatos> oppps, sorry, didn't know it was going to announce here...
11:36:56 <pmatos> Well, I'm trying to read the first command line argument and convert it to a number but it is not working. It's just 4 lines, can someone help me on this?
11:37:45 <oerjan> pmatos: except for the first, those should be let = , not <-
11:38:01 <oerjan> (let ... = )
11:38:14 <oerjan> and the last one probably needs a return
11:38:20 <Zao> or spam a pile of return, but that would be ugly.
11:38:31 <oerjan> er, a print
11:38:37 <eyeris> Is there a form of filter, like filterWithKeys that passes the list index instead of (or in addition to) the value to the predicate?
11:39:00 <pmatos> oerjan: So, I should use let instead of do? What's the difference?
11:39:02 <Zao> zip, filter and unzip?
11:39:11 <oerjan> no, inside the do
11:39:32 <oerjan> head and read are not IO functions
11:39:47 <oerjan> so you cannot use them with <- in an IO action
11:39:50 <eyeris> Zao thanks
11:40:09 <hpaste>  TuringTest pasted "Scales" at http://hpaste.org/3373
11:40:35 <TuringTest> bakert: I posted one way to use Arrays on hpaste link above
11:40:39 <byorgey> > let filterByIndex p = map snd . filter (p . fst) . zip [0..] in filterByIndex even "how about this?"
11:40:40 <lambdabot>  "hwaotti?"
11:41:45 <bakert> TuringTest: that's pretty cool.  it's not "the dream" of MagicThing hot cold.  but i will take a good look at it.  thanks!
11:41:47 <pmatos> oerjan: thx
11:42:16 <TuringTest> bakert: One gets closer to reducing typing using Template Haskell or code generation tools.
11:42:43 <TuringTest> bakert: Or using Data.Generics and its kin, but those are not very useful here.
11:42:43 <eyeris> byorgey what would the type of p be in that?
11:42:50 <eyeris> Int?
11:43:07 <eyeris> oh no
11:43:17 <eyeris> it would be (Int -> Bool), right?
11:43:50 <oerjan> eyeris: if you want to pass both in a tuple, you can leave out the fst
11:44:34 <byorgey> ?type \p -> map snd . filter (p . fst) . zip [0..]
11:44:36 <lambdabot> forall a b. (Num a, Enum a) => (a -> Bool) -> [b] -> [b]
11:44:59 <byorgey> eyeris: Int -> Bool works, although as you can see it's slightly more general than that
11:45:06 <eyeris> right
11:45:30 <oerjan> ?type \p -> map snd . filter (uncurry p) . zip [0..]
11:45:32 <lambdabot> forall a b. (Num a, Enum a) => (a -> b -> Bool) -> [b] -> [b]
11:45:50 <byorgey> that's a nice function too.
11:52:57 <Heffalump> @seen ndm
11:52:57 <lambdabot> I saw ndm leaving #xmonad, #haskell-soc, #ghc, #haskell-overflow, #haskell-blah and #haskell 18h 47m 54s ago, and .
11:57:57 <MyCatSchemes> @seen dead_people
11:57:57 <lambdabot> I haven't seen dead_people.
11:58:44 <oerjan> @seen the_light
11:58:44 <lambdabot> I haven't seen the_light.
12:01:51 <bos> @users
12:01:51 <lambdabot> Maximum users seen in #haskell: 420, currently: 411 (97.9%), active: 20 (4.9%)
12:01:53 <bos> woo
12:02:10 <bos> the amount of traffic on haskell-cafe has gone through the roof recently. i wonder why.
12:03:10 <byorgey> ...quantum fluctuations in the ether?
12:03:42 <EvilTerran> it's only just gone September
12:07:38 <MyCatSchemes> oerjan: winner.
12:14:50 <MyCatSchemes> ...Cabal is teh SEX.
12:15:05 <dcoutts_> @yarr!
12:15:05 <lambdabot> Well Ahoy! thar.
12:15:25 <dcoutts_> MyCatSchemes: erm I guess that's a compliment :-)
12:15:46 <MyCatSchemes> dcoutts_: to the Cabal developers, yes.
12:15:59 <MyCatSchemes> dcoutts_: and basically everyone writing haskell libraries, too.
12:16:10 * dcoutts_ is about to release Cabal-1.2.1
12:19:22 <monochrom> The recent haskell-cafe traffic results from a succession of controversial topics.
12:19:48 <monochrom> Or topics that hit people's buttons.
12:21:22 * MyCatSchemes hugs Lemmih.
12:22:20 <byorgey> maybe there could be a program that detects when traffic is unusually high, and starts delaying posts by people who've been posting a lot for a few hours.
12:22:24 <byorgey> =)
12:22:59 <dankna> snicker.  amusing concept, but technological solutions to social problems are not a great idea.
12:23:13 <monochrom> I wonder how the prolific authors will like it. :)
12:23:39 <MyCatSchemes> Hrmn. How do I use haddock to produce one treeful of documentation for several Cabal projects, please? I'm trying to get one merged set of docs for hsSDL-gfx, hsSDL-ttf, etc, all in one browsable tree.
12:24:38 <dankna> I believe what haddock does is, it asks ghc-pkg if it knows where the docs for the referenced packages are, and uses that to construct links to them
12:25:04 <dankna> so unless you're trying to put that single tree together so you can redistribute it, it doesn't really need to be, the docs can just be in the directories for each separate package and they'll still be inter-browseable
12:25:21 <dankna> this is based on my observations, not on actually reading up on how it works, though :)
12:25:35 <dcoutts_> MyCatSchemes: something like: haddock --html --gen-index --use-package=hsSDL-gfx --use-package=hsSDL-ttf
12:26:12 <MyCatSchemes> dcoutts_: thank you very much. You rock. ^^
12:28:38 <bakert> If I have a record: Scale { hot :: Int, up :: Int, left :: Int, ... lots more int attributes ... } what is the neatest way to initialize one with every value = 10?
12:29:16 <Heffalump> you can play evil games with type classes
12:29:19 <EvilTerran> Scale 10 10 10?
12:29:22 <Heffalump> apart from that, you just have to list them
12:29:32 <EvilTerran> (more 10s as appropriatE)
12:29:45 <Heffalump> class Scale a where mkScale :: a -> Scale
12:29:56 <Heffalump> instance Scale Scale where mkScale = id
12:30:12 <Heffalump> instance Scale a => Scale (Int -> a) where mkScale f = mkScale (f 10)
12:30:22 <Heffalump> then mkScale Scale will do the job
12:30:22 <hpaste>  fberthold pasted "Attempt at a token parser" at http://hpaste.org/3374
12:30:38 <Heffalump> (I'm assuming that your type is also called Scale, if not change the appropriate bits)
12:31:01 <Heffalump> I can't think of any other way short of TH that avoids having to list one 10 per field.
12:31:27 <Heffalump> oh, and my last instance isn't H98.
12:32:01 <bakert> Heffalump, EvilTerran: thanks
12:33:09 <pmatos> Is there any memoization module in haskell?
12:34:24 <byorgey> pmatos: not as such, no.
12:34:33 <byorgey> pmatos: what are you trying to do?
12:35:03 <Pastorn> @src Control.Monad.Cont.(>>=)
12:35:04 <lambdabot> Source not found. :(
12:35:08 <Pastorn> how?
12:35:49 <fberthold> Hi folks, I'm trying to write a token parser but I'm having the devils time at it.
12:35:58 <EvilTerran> bakert, alternatively, you can add deriving (Typeable,Data) to your type def, and then use "everywhere (mkT $ const 10) Rec{}"
12:36:05 <EvilTerran> Scale{}, rather
12:36:05 <pmatos> byorgey: nothing special, I have a fib kind of function I would just like to see the effect memoization has on my haskellian fib. :-) As a very very beginner of haskell, I wouldn't know how to go and implement it! heh
12:36:24 <EvilTerran> (this requires you to import Data.Generics)
12:36:36 <mrd> pmatos: haskell does memoization on everything .. it's called lazy evaluation
12:37:08 <EvilTerran> mrd, er...
12:37:12 <integral> err, no, mrd.
12:37:15 <fberthold> This is the code that I'm using http://hpaste.org/3374 I get a type error when I enter "runParser pBullet () "" [Lbullet (pBullet "string here")]"
12:37:18 <EvilTerran> that's not quite rigtht
12:37:34 <mrd> > let fibs = 0 : 1 : [ a + b | (a,b) <- zip fibs (tail fibs) ] in (fibs !! 10, fibs !! 10)
12:37:37 <lambdabot>  (55,55)
12:37:40 <EvilTerran> (1) haskell isn't garunteed to evaluate lazily, only have non-strict semantics
12:37:57 <EvilTerran> (2) lazy evaluation != memoization by a long way
12:38:09 <mrd> it's memoization when your computation is reified
12:38:37 <byorgey> pmatos: check out http://haskell.org/haskellwiki/Memoization
12:38:39 <lambdabot> Title: Memoization - HaskellWiki
12:39:04 <pmatos> byorgey: thank you! I guess this is the place to go for FAQs. :-) good!
12:39:06 <mrd> i know perfectly well what haskell does.  what he wants is what I typed.
12:39:31 <EvilTerran> ah, reify. one of the most versatile adjectives in existence.
12:39:35 <EvilTerran> er, verbs.
12:39:38 <EvilTerran> more tea!
12:39:42 <byorgey> pmatos: but as mrd points out, with Haskell, memoization often isn't what you really want.
12:39:52 <mrd> lazy evaluation is call-by-name with memoization
12:39:55 <Pastorn> where can i find the GHC sources? (browseable darcs-server or sumthin like that)
12:39:56 <Heffalump> mrd: your example is a good case of using lazy evaluation to get memoization. That doesn't mean everything is memoized.
12:40:28 <byorgey> pmatos: it's often possible to do things in a more idiomatic way that yields efficiency through lazy evaluation rather than explicit memoization.
12:40:28 <Heffalump> in particular, CAFs are memoized for as long as they remain in scope. Other things aren't (in any mainstream Haskell evaluator, that is)
12:40:33 <EvilTerran> @src ghc
12:40:33 <lambdabot> Source not found. Do you think like you type?
12:40:35 <EvilTerran> alas
12:42:13 <pmatos> byorgey:
12:42:17 <pmatos> byorgey: thx
12:42:21 <pmatos> mrd: thx
12:42:40 <pmatos> mrd: I still have to study a lot of haskell until I understand your fib version
12:42:40 <pmatos> lol
12:43:17 <mrd> pmatos: it generates the infinite list of fibonacci numbers and then indexes into it twice
12:43:56 <pmatos> mrd: why indexing twice? What's the !!?
12:43:58 <desegnis> fberthold: MyParser parses Tokens, but you didn't give it any
12:44:14 <mrd> pmatos: that's indexing, and just to show off
12:44:28 <pmatos> mrd: ok
12:44:30 <mrd> > [0,1,2] !! 1
12:44:31 <lambdabot>  1
12:45:08 <mrd> pmatos: the first time it indexes (fibs !! 10) it computes the first 10 fibonacci numbers.  the second time it indexes, they're already computed so it just re-uses the same list.
12:45:22 <bakert> Is there any way to declare a type that is an Int that cannot go below 0 or above 20?
12:45:26 <mrd> pmatos: this is because, as Heffalump pointed out, the list is bound to a CAF: fibs = ...
12:45:37 <pmatos> mrd: oh, ok, got it.
12:45:39 <EvilTerran> bakert, not easily, no
12:46:29 <EvilTerran> there're a number of choices of what to do in case of overflow, for one thing
12:46:31 <Heffalump> bakert: what would you want arithmetic overflow/underflow to result in?
12:46:44 <bakert> just stay at the top/low value
12:46:52 <bakert> 0 - 1 = 0
12:46:55 <Heffalump> it's fairly easy to do by declaring a type in a module with some operations that you check are ok, and then export stuff hiding the internals
12:47:05 <Heffalump> it's much harder to do if you want the compiler to check it all
12:47:13 <bakert> no the first sounds fine
12:47:15 <dankna> heh, we had this question yesterday but the "obvious" desired behavior was to do modular arithmetic, wrapping around
12:47:23 <Heffalump> bakert: the technical term for that is "saturate", FWIW.
12:47:29 <bakert> ooh
12:47:30 <bakert> :)
12:47:46 <Heffalump> bakert: ok, so just wrap Int up in a newtype, and declare your own instance of Num and anything else you want to be able to do with them.
12:48:00 <Heffalump> Then export the type, but not its constructor.
12:48:00 <fberthold> desegnis: I thought it was on those lines.  I think my problem is in who I wrote the code.  What I'm trying for is a parser that will parse a stream of tokens the same way a parser would parse a stream of characters.  But I seem to have missed the mark.
12:48:12 <fberthold> r/who/how/
12:48:16 <Heffalump> And any non-class operations you want to be able to use (class instances are automatically exported)
12:48:48 <byorgey> mrd: I kind of doubt pmatos knows what "CAF" stands for. =P
12:50:07 <mrd> learning is fun
12:50:55 <desegnis> fberthold: I'm sorry the last time I worked with Parsec is too long ago to guess what your code should look like
12:51:22 <pmatos> byorgey: you're right. but I just wrote it down because I'm having a terrible headache and also don't want to bother you more with these questions. I'm sure I'll have more tomorrow. heh :-)
12:51:43 <fberthold> desegnis: Thank you for taking the time to look at it.  Can you reccomend any sources that have small complete uses of GenParser
12:52:31 <byorgey> pmatos: knowing what "CAF" stands for (Constant Applicative Form, in fact) isn't terribly import at this point. =)
12:52:59 <roconnor> @bab nl en beelden
12:53:00 <lambdabot>   to beelden
12:53:24 <byorgey> pmatos: but you certainly won't bother anyone by asking questions!  hope your headache feels better soon.
12:54:06 <pmatos> byorgey: thanks, hope so...
12:54:23 <twanvl> roconnor: images
12:54:51 <roconnor> twanvl: that was my guess from the context
12:58:16 <desegnis> fberthold: I suppose you could just drop the Token type (you won't be able to generate error messages with line numbers, but well), and look at the source of Parsec.Char as a model
12:58:59 <omnId> @source Text.ParserCombinators.Parsec.Char
12:59:00 <lambdabot> http://darcs.haskell.org/packages/parsec/Text/ParserCombinators/Parsec/Char.hs
13:02:48 <fberthold> desegnis: Ah, I'd tried reading Parsed.Char before but missed the relevant section.  Rereading it now. Thank you.
13:04:18 <bakert> what's the difference between an Integer and an Int, and how can I get from the former to the latter?
13:04:31 <seliopou> :info Int
13:04:38 <seliopou> No such thing?
13:04:43 <Tac-Tics> Integer is arbitrary precision
13:04:46 <seliopou> One is like an int in C
13:04:47 <Tac-Tics> Int is word-sized
13:04:48 <seliopou> other isn't
13:04:56 <Tac-Tics> > 234234234234234234234234234 :: Integer
13:04:58 <lambdabot>  234234234234234234234234234
13:05:01 <Tac-Tics> > 23423423423423423423423423423423234234 :: Int
13:05:03 <lambdabot>  -967524166
13:05:05 <Tac-Tics> see?
13:05:16 <bakert> gotcha
13:05:18 <bakert> thanks
13:05:20 <Tac-Tics> :t fromIntegral
13:05:22 <lambdabot> forall a b. (Num b, Integral a) => a -> b
13:05:38 <Tac-Tics> @let x = 23423423423423423423423423423423423423423423423 :: Integer
13:05:43 <lambdabot> Defined.
13:05:46 <Tac-Tics> > (fromIntegral x) :: Int
13:05:47 <lambdabot>  -967334977
13:06:15 <Tac-Tics> > (fromIntegral x) :: Ratio
13:06:16 <lambdabot>      `Ratio' is not applied to enough type arguments
13:06:16 <lambdabot>     Expected kind `?', b...
13:06:39 <Tac-Tics> er hm
13:07:03 <Tac-Tics> > (fromIntegral x) :: Ratio Int
13:07:04 <lambdabot>  (-967334977)%1
13:07:07 <Tac-Tics> yep
13:07:09 <Tac-Tics> that's it
13:07:36 <puusorsa> > (fromIntegral x) :: Ratio Integer
13:07:38 <lambdabot>  23423423423423423423423423423423423423423423423%1
13:07:43 <puusorsa> <3
13:10:26 <bakert> oh i need a functional brain transplant :(
13:10:38 <bakert> i keep reinventing object oriented programming, badly
13:10:55 <kilimanjaro> bakert, how badly?
13:11:23 <bakert> i'm just trying to set up this Trait type that is like an Int but cannot go below 1 or above 19.
13:11:59 <bakert> i started with
13:12:00 <bakert> newtype Trait = MkTrait Int deriving (Show, Eq)
13:12:16 <bakert> and proceded to
13:12:16 <bakert> instance Num Trait where
13:12:16 <bakert>     MkTrait x + MkTrait y = MkTrait $ inRange $ x + y
13:12:25 <bakert> before becoming confused.
13:12:27 <bakert> :(
13:12:32 <mrd> don't forget a fromInteger method
13:12:42 <bakert> i have     fromInteger n = MkTrait $ fromIntegral n
13:12:54 <mrd> probably should add an inRange there
13:12:59 <bakert> :)
13:13:19 <mrd> ok, now say,  1 :: Trait will produce a Traut
13:13:20 <bakert> well i did have "inRange = (min 19) . (max 1)
13:13:20 <mrd> Trait
13:13:21 <bakert> "
13:13:29 <bakert> but that went badly for me
13:13:38 <mrd> because of the monomorphism restriction
13:13:59 <mrd> just do: inRange x = (min 19) . (max 1) $ x -- for now
13:14:06 <bakert> ok
13:14:26 <mrd> this involves CAFs ... again ...
13:15:01 <bakert> CAFs?
13:15:12 <mrd> bindings of the form: "foo = ..."
13:15:22 <bakert> ah
13:15:24 <bakert> ooh it works
13:15:25 <bakert> :)
13:15:38 <monochrom> No, this involves monomorphism.
13:15:42 <mrd> the monomorphism restriction applies to CAFs with polymorphic type-class restricted types
13:15:51 <monochrom> OK, this also involves CAF.
13:15:57 <bakert> can i get away with not defining * and ^ and / and sin and cos?
13:16:01 <bakert> or will that hurt me
13:16:06 <mrd> you can "get away" with it
13:16:27 <mrd> @src Num
13:16:27 <lambdabot> class  (Eq a, Show a) => Num a  where
13:16:27 <lambdabot>     (+), (-), (*)           :: a -> a -> a
13:16:27 <lambdabot>     negate, abs, signum     :: a -> a
13:16:27 <lambdabot>     fromInteger             :: Integer -> a
13:16:45 <bakert> ooh.  my example i am copying from is all wrong :)
13:17:05 <bakert> will these default to what they do on Int somehow because I have
13:17:17 <bakert> newtype Trait = MkTrait Int
13:17:18 <bakert> ??
13:17:22 <mrd> no
13:17:22 <bakert> or am i being daft?
13:18:20 <bakert> multiplying has no meaning for these traits.
13:18:32 <mrd> if you want to keep things abstract, put this stuff in its own module and only export the type.
13:19:01 <bakert> yes this is in a module.  can i say IN the module that i'm only exporting some stuff or does it only happen on import?
13:19:12 <mrd> module Stuff (Trait) where
13:19:18 <bakert> cool
13:19:36 <bakert> i need to list everthing there?
13:19:44 <mrd> if it complains about incomplete Num instance you can do something like (*) = error "no meaning!"
13:19:55 <mrd> bakert: everything you want to export
13:20:27 <bakert> hmm  have about 15 functions in here.  perhaps i ought to break that up.  they are very directly concerned with traits but still
13:20:58 <mrd> you should export the abstract type and its interface
13:21:27 <bakert> is "newtype Trait = MkTrait Int deriving (Show, Eq)"
13:21:35 <bakert> better style than "newtype Trait = Trait Int deriving (Show, Eq)"
13:21:36 <bakert> ?
13:21:43 <bakert> i prefer the latter.
13:21:52 <bakert> but i guess it could be confusing
13:22:05 <omnId> the constructor name you choose doesn't matter much, whatever your preference.
13:22:33 <bakert> will i accidentally be exporting it if it is called the same thing though???
13:22:39 <omnId> nope
13:22:40 <mrd> no
13:22:43 <bakert> cool
13:22:48 <mrd> only gets exported if you specify Trait(..) in the list
13:22:54 <mrd> (or the name explicitly)
13:22:55 <bakert> ah i see
13:23:06 <bakert> the brackets make it constructor?
13:23:19 <EvilTerran> the brackets indicate that you're exporting a type
13:23:23 <EvilTerran> iirc
13:23:26 <omnId> module Blah (Type(C1, C2)) -- exports constructors -- module Blah (Type(..)) -- all of them -- module Blah (Type) -- none of them
13:23:35 <EvilTerran> ah, yes, that's it
13:23:42 <bakert> cool
13:23:45 <bakert> good to know
13:23:47 <bakert> tks
13:23:59 <EvilTerran> so you can't export the constructor on its own, 'cos what sort of sense would exporting a constructor without exporting its type make?!
13:30:10 <thoughtpolice> I am still suprised at how much more easily my irc bot came together when I wrote the actual 'proverbial network loop' last...
13:30:44 <bakert> are there any general terms I can use in export statements?  for example, go export every accessor function of a record type without listing all the names?
13:31:11 <bakert> maybe i should just give up on hiding the constructor for Trait.
13:32:26 <mrd> bakert: why?
13:32:38 <bakert> because i'm getting a bit tied up.
13:32:56 <bakert> Traits wants a function called "new" that supplies a Traits record with all traits set to 10.
13:33:06 <bakert> For that method I must have access to the constructor.
13:33:12 <mrd> no
13:33:12 <bakert> s/method/function/g :)
13:33:17 <mrd> 10 :: Trait
13:33:21 <bakert> ah!
13:33:26 <bakert> cunning
13:33:34 <mrd> you implemented fromInteger
13:33:40 <bakert> that calls fromIntege i see
13:33:44 <bakert> thanks
13:34:41 <mrd> T(..) exports the record field names too
13:34:44 <byorgey> you could also just put the 'new' function (or something like it) in the module and export it.  then it could access the constructor (from within the module) without exposing it.
13:35:37 <bakert> yes i thought about that.  but then the record defintion has to do in there too. and then i have to export the accessors.  although i see mrd showed a way to do that succinctly above
13:35:55 <omnId> though Num conveniently includes such a constructor in fromInteger
13:36:17 <tommd> Anyone here from the YHC team?
13:37:54 <bakert> ?src Num
13:37:54 <lambdabot> class  (Eq a, Show a) => Num a  where
13:37:55 <lambdabot>     (+), (-), (*)           :: a -> a -> a
13:37:55 <lambdabot>     negate, abs, signum     :: a -> a
13:37:55 <lambdabot>     fromInteger             :: Integer -> a
13:38:38 <bakert> what is signum?
13:38:48 <bakert> ?google haskell signum
13:38:50 <lambdabot> http://www.zvon.org/other/haskell/Outputprelude/signum_f.html
13:38:50 <lambdabot> Title: Haskell : signum
13:39:02 <bakert> huh
13:39:24 <ski> > signum `map` [-3..3]
13:39:26 <lambdabot>  [-1,-1,-1,0,1,1,1]
13:39:30 <mrd> @src Int signum
13:39:30 <lambdabot> Source not found. That's something I cannot allow to happen.
13:52:16 <tommd> @src cabal
13:52:16 <lambdabot> Source not found.
13:52:23 <tommd> ?where cabal
13:52:23 <lambdabot> http://www.haskell.org/cabal
13:54:00 <mrd> @src universe
13:54:00 <lambdabot> Source not found.
13:54:09 <mrd> the universe is closed-source :(
13:55:24 <bakert> To declare function that is a record with all values "Trait 10" i am trying:
13:55:38 <bakert> new = Traits (10 :: Trait) (10 :: Trait) (10 :: Trait) (10 :: Trait)
13:55:41 <bakert> is that wrong?
13:56:14 <bakert>  Couldn't match expected type `Traits'
13:56:14 <bakert>            against inferred type `Trait -> Traits'
13:57:12 <bakert> egad.  wrong number of traits.
13:57:14 <bakert> i am a lemon.
13:57:15 <bakert> :(
13:59:23 <tommd> @src Traits
13:59:24 <lambdabot> Source not found. And you call yourself a Rocket Scientist!
13:59:43 <ski> bakert :t Traits
13:59:45 <tommd> Is 'Traits' a data structure of your own making?
13:59:49 <bakert> tommd: Traits is my thing
14:00:14 <bakert> crafted at the expense of much tears and bloodshed by the long-suffering members of this chat room :)
14:00:27 <ski> how is `Traits' defined ?
14:00:29 <bakert> it turned out i had 15 (10 :: Trait) and only needed 13
14:00:35 <bakert> so it was a stoopid problem
14:00:37 <bakert> :(
14:00:53 <bakert> in actual fact because Trait is an instance of Num I can even write:
14:01:01 <bakert> new = Traits 10 10 10 10 10 10 10 10 10 10 10 10 10
14:01:08 <bakert> and that works fine too as far as i can see
14:01:10 <bakert> :)
14:01:19 <tommd> Makes sense
14:01:33 <jcpetruzza> i'm trying to build ghc-6.8.0.20071017 but i'm getting "ghc-pkg: dependency readline doesn't exist" when making stage 2
14:01:42 <jcpetruzza> is there something obvious i should check?
14:01:48 <TuringTest> jcpetruzza: What platform / OS ?
14:01:55 * glguy guess os x..
14:02:31 <jcpetruzza> TuringTest: intel mac
14:02:51 <jcpetruzza> TuringTest: i have ghc 6.6.1 installed via macports
14:03:05 <tommd> +karma glguy
14:03:15 <tommd> @karma glguy
14:03:15 <lambdabot> glguy has a karma of 50
14:03:36 <glguy> tommd: +karma isn't a command :)
14:03:58 <tommd> doh - I guess I forgot the command.... onto msging the lambda
14:04:13 <phlpp> @karma Philippa
14:04:14 <lambdabot> Philippa has a karma of 4
14:04:17 <phlpp> @karma phlpp
14:04:17 <lambdabot> You have a karma of 0
14:04:20 <phlpp> :>
14:04:35 <phlpp> @karma byorgey
14:04:35 <tommd> karma+ glguy
14:04:35 <lambdabot> byorgey has a karma of 6
14:04:44 <glguy> tommd: nope ;)
14:04:49 <TuringTest> jcpetruzza: Can you put the readline library on the environment variable DYLD_LIBRARY_PATH ?
14:04:54 <tommd> @karma+ glguy
14:04:54 <lambdabot> glguy's karma raised to 51.
14:04:58 <tommd> damn strait!
14:05:01 <phlpp> @karma+ byorgey
14:05:01 <lambdabot> byorgey's karma raised to 7.
14:05:01 <phlpp> :>
14:05:02 <glguy> heh
14:05:06 <glguy> thnx!
14:05:10 <tommd> Enjoying galois?
14:05:17 <glguy> definitely
14:06:49 <jcpetruzza> TuringTest: I can try that; should I run "make stage2" straight afterwards or start from scratch?
14:07:36 <Tac-Tics> @src concatMap
14:07:36 <lambdabot> concatMap f = foldr ((++) . f) []
14:07:56 <TuringTest> jcpetruzza: I don't build from source, so I don't know.  Readline on OS X is a silly issue.
14:08:32 <jcpetruzza> TuringTest: yeah, i've heard that already :)
14:08:44 <jcpetruzza> TuringTest: ok, i'll give it a try, thanks!
14:16:10 <hpaste>  bakert pasted "How to increment record values?" at http://hpaste.org/3377
14:16:43 <bakert> How can I alter various record values when I know the "name" of the field I want to alter?
14:16:52 <Heffalump> record { name = name record + 1 }
14:17:19 <Heffalump> in general record { name = newvalue } is the syntax for updating one (or more) fields of a record
14:17:27 <Heffalump> and name record is the way to lookup a field in the record
14:17:33 <bakert> mm.  but how do i pass that name as a value?
14:17:48 <Heffalump> to some other function?
14:17:50 <bakert> if i use it literally it refers to the function
14:17:51 <Heffalump> You can't :-(
14:17:54 <bakert> :(
14:17:56 <Heffalump> Haskell doesn't have first-class record-updates.
14:17:56 <bakert> indeed
14:17:59 <Heffalump> It's a right pain.
14:18:10 <bakert> so i can't write the alterVarious function in http://hpaste.org/3377
14:18:10 <bakert> ?
14:18:10 <mrd> \ x -> rec { name = x }
14:18:17 <Heffalump> I sometimes make a function out of it: upd_name record value = record { name = value }
14:18:32 <Heffalump> and then pass that around, or a tuple (name, upd_name)
14:18:51 <bakert> hmm ... now i know why i was doing this as a list and not  a record before ...
14:19:17 <bakert> perhaps i should not have switched back.
14:19:43 <bakert> but then i have to write a bunch of hideous functions so that my code knows that item number 3 in the list is the hot/cold value.
14:19:50 <bakert> and number 4 is the up/down value, etc.
14:19:53 <bakert> yeuch.
14:20:02 <omnId> bakert: you could use what's known as "functional references"
14:20:07 <bakert> sounds good
14:20:09 <bakert> what are they?
14:20:12 <Saizan> or a Map
14:20:26 <omnId> i.e. values that encapsulate the "getting" and "setting" of a field on a record
14:20:34 <omnId> @go functional references
14:20:37 <lambdabot> http://www.cs.bris.ac.uk/~ian/Functional/refs.html
14:20:37 <lambdabot> Title: Functional references of current local interest.
14:20:42 <omnId> er, not that
14:20:54 <bakert> nope :)
14:21:25 <omnId> http://twan.home.fmf.nl/blog/haskell/overloading-functional-references.details
14:21:27 <lambdabot> Title: Overloading functional references - 21 thoughts, http://tinyurl.com/2ustba
14:22:47 <wli> yitz' code doesn't seem to work.
14:22:51 <omnId> data R = R {x_, y_ :: Int} ; x = FRef x_ (\x r -> r {x_ = x}) ; y = FRef y_ (\y r -> r{y_ = y})
14:23:21 <Heffalump> that's basically the tuple I suggested above. The neat trick in that page is the use of type classes to do the updating.
14:24:45 <omnId> actually, typeclasses just make it so you can do both (get (ref :: FRef s a)) and the usual (ref :: s -> a).
14:26:47 <bakert> ok functional references look cool.
14:26:52 <bakert> i'll give that a spin.
14:28:00 <bakert> it's 13 more functions though :(
14:28:44 <omnId> I'd put the FRef type, get, set, update, and compose in its own module
14:30:49 <bakert> so i need a get/set function AND an accessor function for each field in the record?  so 26 more functions :(
14:31:18 <bakert> he's right this should happen automatically :)
14:32:21 <bakert> where is name_ defined?
14:32:28 <Saizan> get and set are just the fields in the FRef record
14:32:33 <omnId> name_ is the field accessor on your record
14:32:50 <bakert> oh ok so i need to rename my record fields with an extra _
14:33:06 <EvilTerran> that's one naming convention you could use
14:33:11 <Saizan> it's just that you can't define 2 things with the same name in a module
14:33:28 <phlpp> > product [1..10^12]
14:33:32 <lambdabot> Terminated
14:33:41 <bakert> hmm so how do i get away with
14:33:43 <phlpp> hmpf
14:33:47 <bakert> name :: Ref r => r Traits String
14:33:48 <bakert> and
14:33:56 <bakert> name = FRef { get, set }
14:33:59 <bakert> ?
14:34:50 <omnId> name = ref name_ (\x s -> s {name_ = x})
14:35:09 <omnId> ref makes the polymorphic reference.
14:35:23 <omnId> (either an FRef or a plain accessor function)
14:35:39 <bakert> so do i need
14:35:40 <bakert> name = FRef
14:35:40 <bakert>       { get = name_
14:35:40 <bakert>       , set = \n e -> e { name_ = n }
14:35:40 <bakert>       }
14:35:41 <bakert> ?
14:35:49 <omnId> that'd work
14:36:01 <bakert> as well as
14:36:02 <bakert> name = ref name_ (\n e -> e { name_ = n })
14:36:05 <omnId> yep
14:36:12 <Saizan> you need only the second one
14:36:25 <bakert> oh right.  so the second is a neater replacement for the first?
14:36:30 <Saizan> yes
14:36:32 <bakert> cool
14:36:42 <Saizan> one that you can also use as the plain accessor
14:36:51 <bakert> got it
14:36:52 <byorgey> > let n = 10^12 in (0.5 * log (2*pi*n) + n * log n - exp 1 * log n) / log 10
14:36:54 <lambdabot>  1.1999999999973777e13
14:36:58 <omnId> the second one has the benefit of also instanting to (name :: Record -> Name'sType)
14:37:11 <byorgey> phlpp: ^^^ that's how many DIGITS (10^12)! has =)
14:37:31 <bakert> and there's no way to generate these automatically?  i need to have them explicitly in the code for all 13 fields?
14:37:47 <omnId> I wrote a template haskell thingy that does that.
14:37:47 <bakert> (someone is going to mention template haskell again, it always happens to me)
14:37:51 <bakert> :)
14:37:56 <omnId> :D
14:38:06 <byorgey> template haskell!
14:38:14 <omnId> I link to it in twan's post.
14:38:17 <Saizan> well that or generics
14:38:19 <bakert> methinks template haskell is the way forward
14:38:20 <byorgey> sorry, I couldn't resist =)
14:38:30 <omnId> Wait one sec, I'll add the final version.
14:39:09 <bakert> aha .. the automatic reference generator mentioned down the bottom?  that's what the public wants!
14:40:09 <hpaste>  omnId annotated "Not in scope: `field_'" with "module FRef" at http://hpaste.org/3018#a9
14:40:37 <omnId> you might 'import FRef hiding ((.))' if you don't want to deal with the name clashing.
14:41:01 <bakert> cool.  so what do i do with it?  import it and then call addRefs RecordName?
14:41:02 <EvilTerran> or Prelude hiding ((.)) :)
14:41:14 <phlpp> byorgey: oh ok :D
14:41:39 <omnId> bakert: read the big comment before the addRefs function.
14:41:58 <bakert> ah yes crazy macro syntax.  i remember now.
14:42:06 <bakert> thanks this is cool
14:42:22 <omnId> basically add {-# OPTIONS_GHC -fth #-} to the top of your module and add a $(addRefs ''YourType) after the declaration of YourType.
14:43:21 <bakert> if i make a lib dir below my current dir how do i import from it?
14:43:53 <omnId> I think you'd do 'import Lib.FRef'
14:44:04 <omnId> and capitalize the Lib dir name
14:44:19 <bakert> cool tks
14:44:23 <Saizan> omnId: you could also provide a macro that takes a list of record-type declarations, so one doesn't need to repeat the types
14:44:29 <TSC> Or ghc -ilibdir
14:44:59 <omnId> Saizan: then mapM over it?  Good idea.
14:45:24 <bakert> does that OPTIONS_GHC thing need to go in the lib, Main.hs, or the file I use the FRef stuff in?  Or all three?
14:45:45 <omnId> the file you use the $(addRefs ''Blah) splice in :)
14:45:49 <Saizan> omnId: something like $(addRefs' [d| data Foo = ..; data Bar = .. |])
14:46:00 <omnId> ooooh!
14:46:14 <phlpp> hmm
14:47:11 * omnId writes
14:48:03 <Tac-Tics> @hoogle genSym
14:48:07 <lambdabot> No matches found
14:48:19 <Tac-Tics> @hoogle IO Int
14:48:20 <lambdabot> System.Console.Readline.getCompletionQueryItems :: IO Int
14:48:20 <lambdabot> System.Console.Readline.getEnd :: IO Int
14:48:20 <lambdabot> System.Console.Readline.getMark :: IO Int
14:48:26 <Tac-Tics> hmmm
14:48:39 <bakert> do i have to say "module Lib.FRef" in omnId's file if I want to import it with import Lib.FRef?
14:48:48 <Saizan> yes
14:48:48 <omnId> not sure
14:48:56 <Tac-Tics> @hoogle IO Integer
14:48:57 <lambdabot> CPUTime.getCPUTime :: IO Integer
14:48:57 <lambdabot> IO.hFileSize :: Handle -> IO Integer
14:48:57 <lambdabot> System.IO.hTell :: Handle -> IO Integer
14:50:09 <bakert> that's a very odd requirement.  so all modules effectively have an absolute name in the universal haskell namespace declared by their authors unless you actually edit their source code.  i suppose that's quite normal in a way.
14:50:15 <bakert> as long as there are standards.
14:51:11 <bakert> com.sun.blah.etc is the same thing by another name i suppose
14:52:14 <Saizan> yup
14:52:29 <Saizan> you can hide packages though, so it's not really global
14:53:42 <omnId> Saizan: what should I name this new splice?  And do you suggest a better name for addRefs?
14:54:37 <Saizan> addRefs seems fine, but i'm not very good with names :)
14:55:13 <omnId> Saizan: what about a name for $(blah [d| ... |])?
14:55:56 <omnId> or anyone for that matter?
14:55:57 <Saizan> declareWithRefs?
14:56:05 <omnId> sounds good.
14:56:14 <omnId> withRefs even
14:56:24 <Saizan> yeah
14:56:25 <bakert> do you want to use FRefs not just Refs in the names?
14:56:29 <omnId> [d| ... |] :: Q [Dec] ?
14:56:49 <Saizan> yes
14:57:10 <omnId> I should've asked ghci such a simple question :)
14:57:16 <omnId> but thanks :)
14:57:46 <Saizan> so you've to prepend those declarations to your output
14:58:39 <hpaste>  omnId annotated "Not in scope: `field_'" with "I think this is right :)" at http://hpaste.org/3018#a10
14:59:03 <omnId> erm, maybe not.  I'm not sure reify would would on as-yet-undeclared types.
14:59:13 <omnId> would work*
15:00:28 <omnId> I'll factor out the ref generation from addRefs and have the factored out part take types themselves.
15:00:35 <Saizan> omnId: well, i don't see reify there..
15:00:51 <omnId> withRefs calls addRefs, which reifies.
15:00:52 <Saizan> ah, in addRefs
15:01:31 <bakert> of course the ticklish thing here is that the update stuff isn't going to work with my inverse traits :)
15:01:47 <bakert> update up (+ 3) is great
15:01:54 <bakert> but update down (+ 3) is nonsensical
15:02:00 <bakert> :(
15:02:23 <bakert> can i create an inverse of update?
15:02:41 <Saizan> what should that do?
15:02:47 <bakert> i have no idea :)
15:03:00 <omnId> do you want (update down (subtract 3))?
15:03:04 <Saizan> update down (+3) == update up (-3) ?
15:03:07 <bakert> all i know is i did have up and down functions for accessing the up value and (20 - up)
15:03:11 <bakert> and now i don't :(
15:03:19 <Saizan> ha!
15:03:43 <bakert> becuase some clever code i don't understand has stole them away :) :)
15:03:51 <quicksilver> dons: yes, I understand now. Thanks :)
15:04:04 <omnId> down = ref ((20-) . up_) (\x s -> s {up_ = 20-x})
15:04:22 <bakert> omnId: now the trick is, is there a way of writing invert
15:04:24 <bakert> so that
15:04:29 <bakert> down = invert . up
15:04:29 <bakert> ?
15:04:34 <bakert> :)
15:04:44 <bakert> no
15:04:47 <bakert> i don't think so
15:05:01 <Saizan> is 20 a constant?
15:05:04 <bakert> yes
15:05:09 <bakert> for all scales
15:06:04 <omnId> apply f r = ref (f (get r)) (set r . f) -- I think, then 'down = apply (20-) up
15:06:07 <Saizan> invert name = ref ((20-) . name) (\x -> update name (20-x)) -- if this types
15:06:46 <bakert> oooh, choices!
15:07:53 <omnId> s/(f (get r))/(f . get r)/ , like in Saizan's
15:08:04 <bakert> this is to read the value, right?  i can't update this way too?
15:08:16 <omnId> update uses get and set
15:08:21 <omnId> so it just works :)
15:08:25 <bakert> ooh
15:08:27 <bakert> magic
15:08:45 <hpaste>  etnt' pasted "how to use liftM" at http://hpaste.org/3378
15:09:20 <etnt`> anyone able to give me some help on the use of liftM ?
15:10:08 <omnId> etnt`: updateStep2 i | isOdd i = modify (\(x,y) -> (x+1, y+1))
15:10:29 <omnId> liftM affects the action's result, not the inner state in the State moand.
15:10:38 <monochrom> liftM cannot update state. it deliberately leaves state unchanged.
15:10:54 <etnt`> aah...thx!
15:11:08 <monochrom> liftM can only bring pure functions into your monad.
15:11:09 <omnId> modify already does the get/apply f/put
15:11:41 <omnId> bakert: update ref f s = set ref (f (get ref s)) s
15:12:07 <bakert> omnId: is that informational or to put in the code? :)
15:12:13 <omnId> bakert: not much magic there
15:12:15 <bakert> can you tell i'm in over my head? :)
15:12:23 <Saizan> ah, so mine was wrong..
15:12:25 <omnId> informational :)
15:12:38 <bakert> Saizan: i get a  Couldn't match expected type `FRef s a'
15:12:38 <bakert>            against inferred type `s -> t'
15:12:43 <bakert> with your version of invert
15:12:56 <Saizan> yeah i confused update with set
15:12:57 <bakert> invert name = ref ((20-) . name) (\x -> update name (20-x))
15:13:20 <omnId> yeah, using name as an ordinary accessor forces the (->) instance, which doesn't support update.
15:13:46 <tumdum> :q
15:13:47 <bakert> so am i better off with:
15:13:48 <bakert> apply f r = ref (f (get r)) (set r . f) -- I think, then 'down = apply (20-) up
15:14:02 <etnt`> I must say that you guys are really helpful, many thanx!
15:14:07 <Saizan> omnId: damned first rank polymorphism :)
15:14:16 <omnId> apply f r = ref (f . get r) (set r . f) -- This should be correct, and hopefully not too difficult to understand.
15:14:17 <bakert> god damn this is the greatest chat room ever etnt' and no mistakin'
15:14:27 <bakert> so i can actually say:
15:14:35 <etnt`> bakert: indeed :-)
15:15:02 <omnId> bakert: do you see how apply works there?
15:15:07 <bakert> invert r = ref ((20 -) (get r)) (set r . (20 -)
15:15:14 <bakert> :( :) ??? !!!
15:15:28 <omnId> bakert: actually my first version of apply was wrong
15:15:34 <bakert> omnId: apply is taking a functon and a record
15:15:45 <bakert> and it is saying if you are doing a request for the value get it
15:15:48 <olsner> oh, etnt' was a nick... here I was trying to decipher it as misspelt english :P
15:15:52 <omnId> s/ ((20 -) (get r)) / ((20 -) . get r) /
15:15:52 <bakert> and if you are doing a setting of the value then set it
15:16:18 <bakert> maybe i will build invert from your apply :)
15:16:49 <bakert> and i must change it's name from invert now
15:16:51 <bakert> to opposite
15:16:55 <omnId> bakert: get r needs another argument, the actual record to get from, so either use (.) or (\s -> (20 -) (get r s))
15:17:14 <omnId> which equals: (20 -) . get r
15:17:14 <bakert> i like (.)
15:17:21 <etnt`> hm..I tried to find modify at hoogle but failed?
15:17:31 <omnId> @index modify
15:17:31 <lambdabot> Control.Monad.State, Control.Monad.RWS
15:17:41 <Saizan> does (20-) actually do the right thing when setting the value?
15:17:49 <bakert> good question
15:18:08 <TSC> etnt`: hoogle is wrong, I think: http://haskell.org/ghc/docs/latest/html/libraries/mtl/Control-Monad-State-Class.html#v%3Amodify
15:18:10 <lambdabot> http://tinyurl.com/yuyeqp
15:18:10 <omnId> set down 5 = set up (20 - 5) = set up 15
15:18:36 <bakert> makes sense
15:19:01 <etnt`> TSC: thx!
15:19:20 <bakert> i am struggling with invert
15:19:27 <bakert> it's not as simple as:
15:19:33 <bakert> invert = apply (20 -)
15:19:56 <Saizan> getting a type error about ambiguous variables?
15:19:56 <omnId> what error do you get?
15:20:14 <bakert>   Couldn't match expected type `FRef s t'
15:20:14 <bakert>            against inferred type `Trait'
15:20:23 <bakert> where i declare my first inverted thing
15:20:27 <omnId> did you change apply to be correct?
15:20:27 <bakert> up = invert .down
15:20:36 <bakert> apply f r = ref (f . get r) (set r . f)
15:20:38 <omnId> up = invert down
15:20:44 <omnId> no (.)
15:20:44 <bakert> oh
15:21:02 <bakert> yes i see
15:21:06 <bakert> we are doing it to it, then using it
15:21:13 <bakert> rather than doing something to it's result
15:21:18 <bakert> maybe
15:21:24 <bakert> (brain fry)
15:21:34 <omnId> yep, since up isn't a function with a result
15:21:38 <omnId> (neccessarily :)
15:21:43 <bakert> oh lordy
15:21:59 <omnId> it encapsulates both getting and setting
15:22:09 <omnId> it's a data thingy.
15:22:47 <bakert> ok.  so i just have some silly error now about scope and imports.
15:22:56 <bakert> Not in scope: type constructor or class `FRef.Ref'
15:22:59 <bakert> but i have
15:23:02 <bakert> import Lib.FRef
15:23:14 <bakert> so i'm not sure how to fix it
15:23:14 <Saizan> import Lib.Fref as FRef
15:23:23 <Saizan> or use just Ref
15:23:25 <bakert> ah that macro is using it?
15:23:33 <omnId> oh, darn
15:23:35 <bakert> because it's not in the file explicitly anywhere
15:23:55 <omnId> my macro uses the literal name "FRef.Ref"
15:24:04 <Saizan> omnId: you should use ''Ref for the name
15:24:10 <bakert> ah.  so it has to FRef
15:24:17 <bakert> that it is imported as
15:24:19 <bakert> i see
15:24:32 <bakert> "Ref?  we are so in lispworld
15:24:50 <omnId> Saizan: I made this with very shaky understanding of TH.  How would I modify addRefs to fix it?
15:25:12 <Saizan> bakert: heh, similar, in TH you get the name of an identifiers with ' and of a type/class with ''
15:25:39 <tphyahoo> bakert: thought you'd given up :)
15:25:46 <EvilTerran> that's two ('), not one (")
15:25:47 <bakert> tphyahoo: this is not HAppS!
15:25:57 <bakert> HAppS i am on temporary hiatus with
15:25:58 <tphyahoo> whoops never mind
15:26:02 <bakert> here we are on the commandline
15:26:07 <bakert> only
15:26:18 <bakert> never to venture to scary places like HAppS
15:26:39 <tphyahoo> perils of multiple screen irc sessions
15:26:42 <bakert> EvilTerran: then we are even MORE in lispworld than i thought!
15:26:53 <Saizan> let [ref,refClass,val,s] = ['ref,''Ref] ++ map mkName ["val","s"] -- i think
15:27:03 <EvilTerran> we're twice as far into lispworld than even the lispers ;)
15:27:06 <hpaste>  stoic_ pasted "hp printer lcd hack not working" at http://hpaste.org/3379
15:27:18 <bakert> i am still permanently attached to the #happs group because i want someone to spur me into action writing my next tutorial :)
15:27:28 <bakert> but it hasn't happened yet
15:27:51 <alexj> bakert: what sort of spur?
15:27:59 <alexj> lots of stuff has been getting tied down recently.
15:28:00 <bakert> alexj: i need faith!
15:28:05 <omnId> Saizan: just directly put the quoted names in addRefs and it'll pick the correct ones in the client module?  cool!
15:28:07 <bakert> i'm pretty rubbish with haskell
15:28:21 <bakert> i am hoping to make some ground looking at the new hpaste
15:28:27 <bakert> which uses 0.9
15:28:32 <alexj> bakert ah ok.
15:28:38 <bakert> that's what i used last time to make sense of it all
15:28:41 <stoic_> could anyone tell me why my code above isn't working? I'm trying ti implement the hack I recently saw on reddit in haskell
15:28:51 <Saizan> omnId: GHC converts to absolute names, like Lib.FRef.Ref
15:28:59 <alexj> where is the source for hpaste?  i'd like to see what other people do too.
15:29:03 <twanvl> stoic_: There is a % in that string
15:29:18 <bakert> alexj: i have a patch on my desktop :)
15:29:19 <glguy> kakapop.scannedinavian.com/~eric/hpaste-devel
15:29:28 <bakert> glguy: that's the 0.8 version right?
15:29:39 <twanvl> "\33%-12345...", you should probably use "\33%%-12345..."
15:29:43 <omnId> grar, I wish my editor's syntax coloring wasn't so stupid.
15:29:46 <Saizan> alexj: http://zzodici.yi.org/s/hpaste-devel <-- my repo which works with 0.9
15:29:48 <bakert> or is that location update to 0.9 now
15:29:51 <bakert> ah there you go
15:30:10 <Saizan> glguy: ah, btw, are you interested in a patch to port hpaste to 0.9?
15:30:16 <bakert> :)
15:30:58 <stoic_> twanvl: hmm why is that?
15:31:17 <glguy> Saizan: hpaste-devel works against 0.9
15:31:21 <twanvl> % is a special character for printf
15:31:22 <stoic_> twanvl: I see that is it like %% in the C version but I thought the escape code was just \33
15:31:24 <bakert> ok, so now i have that famousest of errors about the monomorphism restriction
15:31:30 <glguy> Saizan: to my surprise it has for a while
15:31:34 <bakert>    Ambiguous type variable `r' in the constraint:
15:31:34 <bakert>       `Ref r' arising from use of `apply' at Traits.hs:22:9-20
15:31:47 <bakert>     Possible cause: the monomorphism restriction applied to the following:
15:31:49 <twanvl> > '\33'
15:31:51 <lambdabot>  '!'
15:31:56 <bakert> does that just mean i need type signatures?
15:31:56 <Saizan> glguy: sure? after the repos splittage?
15:32:03 <omnId> bakert: eta-extend (add a parameter to both the lhs and rhs) of apply.
15:32:12 <omnId> er, invert, rather
15:32:20 <EvilTerran> bakert, or explicitly type
15:32:28 <bakert> ah yes.  this is what you said earlier but it made no sense then because i am dim :)
15:32:32 <ddarius> eta-expand
15:32:32 <EvilTerran> (i think)
15:32:38 <omnId> ddarius: thanks
15:33:23 <twanvl> stoic_: printf looks for the '%' character in the string, so if you want a literal '%' in the output it must be escaped as "%%".
15:33:36 <bakert> if i add an x to both sides of invert i push the same error to each of the inverted functions.  that is to
15:33:39 <bakert> down = invert up
15:33:41 <bakert> and so on
15:33:51 <bakert> so do i need to eta-expand them too i guess?
15:33:52 <omnId> :(
15:34:12 <stoic_> twanvl: ahh yeah
15:34:23 <Saizan> bakert: or use -fno-monomorphism-restriction
15:34:24 <augustss> bakert: eta expand or give a type signature
15:34:27 <twanvl> Also, '\33' in C is not the same as '\33' in haskell. In C it is octal, so character 27, ESC, in haskell you get 33 decimal, '!'. You can write the escape character as '\ESC' or '\27'
15:34:57 <Saizan> down can't be eta-expaned without forcing a particular instance, no?
15:35:01 <bakert> augustss: when you say that it sounds to me like, "or just climb mount everest in your boxers"
15:35:03 <bakert> :)
15:35:12 <bakert> (brain fry redux)
15:35:45 <stoic_> twanvl: thank you
15:35:48 <bakert> ok all looks good.  lots of r and x that we'd like to get rid of but that can come later ...
15:35:57 <bakert> Saizan: i changed down from
15:36:02 <bakert> down = invert up
15:36:02 <bakert> to
15:36:06 <bakert> down r = invert up r
15:36:13 <bakert> ???
15:36:16 <Saizan> :type down?
15:36:29 <bakert> hang on, it doesn't compile yet :)
15:36:30 <geocalc> > \SYN
15:36:30 <lambdabot>  Parse error
15:36:48 <augustss> > '\SYN'
15:36:50 <lambdabot>  '\SYN'
15:37:04 <omnId> try adding 'down :: Ref r => r RecordType UpsType'
15:37:15 <omnId> and un-eta-expanding :)
15:37:32 <bakert> cool i will try that
15:37:36 <bakert> eta-compressing to the max
15:38:12 <Saizan> "eta-reduce"  usually
15:38:27 <bakert> eta-not-knowing-what-i'm-talking-about to the max :)
15:38:28 <EvilTerran> eta-eating?
15:38:40 <omnId> I are not schooled in these lambda doohickeys.
15:38:54 <omnId> Though I talk liek I does are did.
15:39:04 <bakert> omnId: dude, you WROTE the code i cannot understand you are in no position to talk!
15:39:13 <omnId> :D
15:46:16 <bakert> how tightly does (::) bind?
15:46:28 <omnId> it's base syntax below operators.
15:46:33 <bakert> or is (::) even right?  or is it something special not a funciton?
15:46:36 <omnId> operator functions I should say.
15:46:44 <bakert> hmm.
15:47:07 <omnId> it binds as loosely and widely as it can
15:47:08 <Saizan> it's syntax
15:47:09 <EvilTerran> it's not a function. yet.
15:47:29 <EvilTerran> syntactically, you could think of it as an operator with fixity lower than any function operator
15:47:50 <EvilTerran> (f $ x :: y) = (f $ x) :: y, not f $ (x :: y)
15:48:19 * EvilTerran is going to spend the rest of the evening thinking about (::) sections again, now :(
15:48:20 <bakert> being an instance of Num doesn't give you access to > and < i take it
15:48:27 <bakert> EvilTerran: sorry :)
15:48:31 <EvilTerran> bakert, no, you have to define Ord for that
15:48:31 <omnId> usually you'll want to parenthesis annotations unless you specifically mean "everything to the right"
15:48:40 <EvilTerran> or left
15:48:57 <EvilTerran> s/define Ord/define an Ord instance/
15:49:00 <omnId> bakert: if you're newtyping Int, you could deriving (Ord)
15:49:10 <bakert> i am
15:49:11 <bakert> cool
15:49:16 <bakert> so i just add it in with Show and Eq
15:49:19 <bakert> funky
15:49:56 <bakert> woohoo, we have complation
15:50:01 <bakert> that means it works, right? :)
15:50:22 <Saizan> modulo undefined :)
15:50:49 <EvilTerran> and human error
15:51:20 <bakert> ok now to uncomment all the stuff i commented out to get it to compile :)
15:51:34 <hpaste>  omnId annotated "Not in scope: `field_'" with "parse error on line starting with 'let stype = ...' in makeRefs :(" at http://hpaste.org/3018#a11
15:52:22 <omnId> I added withRefs and I'm trying to test it but got a parse error.
15:52:45 <Saizan> omnId: you forgot the do
15:52:56 * omnId smacks forehead
15:53:00 <omnId> thanks
15:53:13 <bakert> i love the fact that you are debugging the library i am already using right in front of me.  it's like a live changelog.
15:54:21 <omnId> adding stuff :)
15:54:25 <bakert> what's the haskell name for collect?
15:54:31 <omnId> foldr?
15:54:34 <bakert> ah yes\
15:54:43 <opqdonut> collect wtf
15:54:49 <bakert> sorry ... ruby :(
15:54:53 <augustss> where is it called collect?
15:54:53 <omnId> must be a rubyist :)
15:54:53 <opqdonut> ah :)
15:54:58 <bakert> i will be banished from #haskell forthwith
15:55:00 <augustss> oh, ruby
15:55:01 <opqdonut> i was thinking python
15:55:05 <opqdonut> but python has reduce iirc
15:55:14 <augustss> they had to invent another name, eh?
15:55:14 <bakert> the funny thing is ruby annoyed me with its names coming from python!
15:55:22 <augustss> I like reduce
15:55:32 <bakert> python's names are way better than rubys
15:55:49 <bakert> ruby doesn't even really have map ... it does but they prefer you to use soemthign else i forget what
15:56:00 <opqdonut> transform?
15:56:05 <bakert> nah
15:56:06 <bakert> um ...
15:56:12 * bakert greps code
15:56:21 <omnId> each I believe
15:56:33 <monochrom> "collect them all!"
15:56:47 <bakert> each
15:56:48 <bakert> yes
15:56:50 <omnId> though that resembles mapM_ I believe
15:56:55 <bakert> ?!
15:56:55 <lambdabot> Maybe you meant: . ? @ v
15:57:06 <omnId> @type mapM_
15:57:08 <lambdabot> forall a (m :: * -> *) b. (Monad m) => (a -> m b) -> [a] -> m ()
15:57:14 <omnId> "do a bunch of actions in sequence"
15:57:31 <omnId> M means monadic, or in sequence, _ means discard the results.
15:57:42 <bakert> ooh that's interesting to know
15:57:48 <bakert> M i had worked out
15:57:53 <bakert> but _ i had not
15:58:09 <allbery_b> think analogy with _ in pattern matching
15:58:28 <opqdonut> hmm, hadn't thought of it like that
15:58:34 <allbery_b> it was fairly obvious to me when I irst encountered it, largely because that's the only place _ is normally used
15:58:36 <omnId> a sketchy analogy, I think, but it's good enough
15:59:01 <allbery_b> not that sketchy.  _ <- mapM ...
15:59:08 <omnId> Saizan: what's the last [Name] in a DataD?
15:59:23 <omnId> anything important?
15:59:50 <allbery_b> (or mapM ... >>= \_ -> ... if you dislike do notation)
15:59:52 <bakert> if i define a lambda with two arguments do i use a comma?
15:59:57 <Saizan> omnId: i can't honestly remember the shape of TH's AST :)
16:00:02 <omnId> bakert: just a space.
16:00:05 <shachaf> bakert: Not unless it gets a tuple.
16:00:09 <allbery_b> \x y -> ...
16:00:09 <omnId> (\x y -> ...)
16:00:21 <bakert> ah because the arrow tells it where the arguments end
16:00:23 <shachaf> Or you can use another lambda.
16:00:23 <omnId> \(x,y) -> ... for a pair
16:00:29 <omnId> \x -> \y -> ...
16:00:33 <bakert> i was wondering how it would know
16:00:34 <omnId> but that's masochism :)
16:01:41 <omnId> DataD cxt name params constrs (something :: [Name])
16:02:38 <bakert> :t foldr
16:02:40 <Saizan> something might be the list of classes in the deriving clause
16:02:40 <lambdabot> forall a b. (a -> b -> b) -> b -> [a] -> b
16:03:37 <bakert> You know these references?  Are they of type FRef?
16:04:59 <bakert> no
16:05:00 <bakert> :(
16:05:48 <omnId> bakert: hm? which references?
16:06:00 <bakert> well if i am passing "up" to another function
16:06:10 <bakert> and i wanted to add  a type declaration to that function
16:06:16 <omnId> up :: Ref r => r Traits Trait
16:06:20 <bakert> what type would i put where i pass "up"?
16:06:24 <omnId> r could be FRef of (->)
16:06:39 <glguy> etnt: you about?
16:06:39 <bakert> golly
16:06:40 <omnId> or*
16:06:45 <bakert> that looks complicated
16:06:46 <Saizan> Prelude Language.Haskell.TH> $(runQ [d| data Foo = Foo deriving (Ord,Eq) |] >>= return . LitE . stringL . show)
16:06:50 <Saizan> "[DataD [] Foo [] [NormalC Foo []] [GHC.Base.Ord,GHC.Base.Eq]]"
16:06:50 <bakert> :)
16:06:50 <Saizan> confirmed
16:06:51 <omnId> r could be FRef *or* (->)
16:07:20 <omnId> so up :: Traits -> Trait, or up :: FRef Traits Trait
16:07:20 <bakert> so instead of
16:07:32 <bakert> modTrait :: (FRef, Int) -> Traits -> Traits
16:07:33 <bakert> i would need
16:08:09 <bakert> Ref r => (r Traits Traits, Int) -> Traits -> Traits
16:08:10 <bakert> ???
16:08:36 <omnId> r Traits Trait*
16:09:04 <bakert> ah
16:09:06 <phlpp> hm
16:09:34 <phlpp> today (yesterday) was a shitty day
16:09:55 <omnId> but you could use update and fromInteger directly
16:09:56 <bakert>     Couldn't match expected type `FRef'
16:09:56 <bakert>            against inferred type `r' (a rigid variable)
16:09:57 <bakert> ???
16:10:13 <bakert> omnId: howso?
16:10:45 <bakert> modTrait is a bit of a hangover from the pre-functional references era :)
16:10:59 <Saizan> update forces the type to FRef, i think
16:11:08 <omnId> eugh, perhaps references polymorphic in (->) are too much of a hassle afterall.  You're the first example of their actual use I know.
16:11:09 <bakert> i just have a list of (trait, int) pairs to apply to traits
16:11:34 <bakert> [(up, 1), (left, -1)]
16:11:37 <bakert> type thing
16:12:04 <omnId> try the type: (FRef Traits Trait, Int) -> Traits -> Traits
16:12:08 <phlpp> @karma omnId
16:12:08 <lambdabot> omnId has a karma of 2
16:12:11 <phlpp> oh
16:12:14 <phlpp> @karma+ omnId
16:12:14 <lambdabot> omnId's karma raised to 3.
16:12:17 <bakert> foldr (\x y -> modTrait x y) traits [(up, 1), (left -2)])
16:12:25 <bakert> @karma+ omnId
16:12:25 <lambdabot> omnId's karma raised to 4.
16:12:29 <bakert> or is that cheating?
16:12:57 <phlpp> it isn't
16:13:06 <bakert> he deserves at least 2 really let's be frank
16:13:09 <omnId> wouldn't it be easier to use update directly, then the 1 and (-2) would be inferred as :: Trait
16:13:21 <phlpp> i just think omnId is a smart guy who always can help :>
16:13:40 <bakert> i'm not sure what you mean by "directly".  you mean don't bother with a list just chain a bunch of calls to update?
16:13:43 <phlpp> who's always able to help is  better expression, i think
16:13:52 <omnId> bakert: update instead of modTrait
16:14:09 <bakert> in the foldr?
16:14:19 <bakert> oh and split apart the pair in there
16:14:20 <bakert> cunning
16:14:44 <omnId> foldr (\(ref, x) s -> update ref x s) traits [...]
16:15:59 <Saizan> or foldr (uncurry update) traits [..] if you feel evil
16:17:01 <bakert> Saizan: love it!
16:17:09 <bakert> but perhaps should stay away from it :)
16:17:38 <Saizan> well, uncurry f = \(x,y) -> f x y
16:17:53 <bakert> this cannot be denied
16:18:00 <omnId> pairs love uncurry
16:19:01 <not_omnId> omniscientIdiot-- omnIdiot-- omnId++ omnId++
16:19:08 * not_omnId migrates his karma
16:19:37 <bakert> :)
16:19:43 <EvilTerran> @karma omnId
16:19:43 <lambdabot> omnId has a karma of 6
16:19:47 <shachaf> omnId: I don't think you're allowed to do that.
16:19:55 <EvilTerran> @karma omniscientIdiot
16:19:56 <lambdabot> omniscientIdiot has a karma of 0
16:20:01 <omnId> I did it anyway!  :P
16:20:13 * bakert sings rebel rebel by david bowie
16:20:45 <shachaf> omnId: Nobody "migrated" their karma when it was reset a while ago.
16:21:06 <bakert> more fool them.  they will be reincarnated as beatles and not unicorns
16:21:09 <bakert> oops beetltes
16:21:12 <bakert> beetles even
16:21:13 <omnId> omnId-- me if you want
16:21:13 <bakert> gah
16:21:26 <omnId> it doesn't matter much to me :)
16:21:36 <phlpp> @src uncurry
16:21:37 <lambdabot> uncurry f p = f (fst p) (snd p)
16:21:40 * bakert sings let me take you down 'cause i'm going to
16:21:41 <phlpp> hehe
16:21:55 <Saizan> phlpp: ahah!
16:21:56 <shachaf> omnId: The right way is to java ++. :-)
16:22:46 <tphyahoo> know what would be really useful? lambdabot for happs
16:22:47 <shachaf> @ty \f -> liftM2 f fst snd
16:22:49 <lambdabot> forall r a b. (a -> b -> r) -> (a, b) -> r
16:22:59 <tphyahoo> especially for @src
16:23:17 * EvilTerran prefers uncurry f ~(x,y) = f x y, tbh
16:23:23 <tphyahoo> i know you're supposed to be able to integrate LB with ghci but i was never able to get that to work.
16:23:23 <Saizan> tphyahoo: src is manually populated, and you want to see the comments too
16:23:27 <EvilTerran> @src fst
16:23:27 <lambdabot> fst (x,_) =  x
16:23:38 <tphyahoo> oh?
16:23:53 <Saizan> from the happs modules i mean :)
16:24:10 <Saizan> however hoogle might be nice
16:24:26 <tphyahoo> another thing is if :info would give better "info"
16:24:44 <tphyahoo> an argument signature could be valuable if the args had sensible var names
16:24:54 <sorear> tphyahoo: that's what haddock is for
16:25:14 <Saizan> yeah, the list of instances for a type or a class is often incomplete
16:25:24 <alexj> sorear: I agree with tphyahoo, that programmer supplied variable names are highly informative.
16:25:28 <tphyahoo> does haddock give you meaningful var names?
16:25:36 <alexj> e.g. uid vs Int
16:25:52 <tphyahoo> or just type sigs?
16:25:57 <glguy> type Uid = Int
16:26:03 <sorear> alexj: And I'm saying foo :: {-| The number of times to frob the quux. -} Int -> IO () exists
16:26:18 <bakert> egad.  explain to me how to use update.  i can't say: update evil (13 :: Trait) traits
16:26:19 <bakert> ?
16:26:26 <bakert> or even
16:26:29 <LoganCapaldo> I like the glguy method
16:26:29 <bakert> update evil 13 traits
16:27:08 <omnId> rar, Q doesn't have a Functor instance :/
16:27:15 <LoganCapaldo> @type update
16:27:17 <lambdabot> Not in scope: `update'
16:27:20 <Saizan> bakert: set evil 13 traits ?
16:27:31 <EvilTerran> omnId, it'd be pretty easy to write one if you need it...
16:27:33 <bakert> Saizan: isn't that cheating?!
16:27:43 <omnId> I know, it's the principle of the thing.
16:27:49 <Saizan> bakert: or update evil (\_ -> 13) traits
16:27:49 <tphyahoo> jeff polakow says "implement setContentType damnit"
16:27:52 <sorear> [Msgs:147 New:103 Old:44 923K]  does anyone still keep up with -cafe these days?
16:27:54 <EvilTerran> i know what you mean in that regard, actuallyu
16:27:58 <alexj> glguy: yes that works, but I use a lot of SYB operators so the types are not visible in the sigs.
16:28:16 <Saizan> bakert: update takes a function to modify the value, not just a new value
16:28:47 <EvilTerran> like i get antsy about using things like (.:), swap, bool, ..., because, although they have fairly standard meanings, they're not in a library anywhere.
16:28:51 <bakert> ha!  that's actually what i want but i was trying to get something simpler working first.  doh!
16:29:02 <omnId> oh goody!  I gots my first GHC panic!
16:29:05 <tphyahoo> how do I change my user from nbarterd to tphyahoo on #happs?
16:29:10 <alexj> glguy: for example the argument name is uid but the function that uses it does a (gFind' uid) so it can handle either an Int or a (Uid Int) style argument.
16:29:59 <LoganCapaldo> (Uid uid) => uid -> ... instance Uid Int, instance Uid ConcreteUid?
16:30:15 <bakert> Saizan:     No instance for (Num (Trait -> Trait))
16:30:15 <bakert>       arising from the literal `1' at Character.hs:133:101
16:30:16 <LoganCapaldo> that probably defeats the purpose of using syb
16:30:41 <alexj> LoganCapaldo: yes.  the nice thing about the generic operators is that you don't have to do all those declarations and everything just works.
16:30:42 <sorear> omnId: congrats, @bug
16:30:52 <alexj> its all about scrapping boilerplate!
16:31:00 <Saizan> bakert: with which code?
16:31:08 <omnId> sorear: 6.6.1, I'll check if it's fixed.
16:31:14 <LoganCapaldo> on the other hand, boilerplate is what's nice to read :)
16:31:19 <bakert> Saizan: update evil (\_ -> 13) traits
16:31:21 <LoganCapaldo> if not to write
16:31:21 * shachaf always gets a GHC panic when he runsghc Setup in base/.
16:31:23 <phlpp> omnId: do you think it's possible, actually for me, to write a very simple irc bot in 1 week? are there some libraries making sockets stuff easy to handle or even libraries for interacting with irc servers?
16:31:42 <omnId> phlpp: not used sockets stuff myself, sorry
16:31:42 <shachaf> @go roll your own irc bot
16:31:45 <lambdabot> http://haskell.org/haskellwiki/Roll_your_own_IRC_bot
16:31:45 <lambdabot> Title: Roll your own IRC bot - HaskellWiki
16:32:16 <phlpp> cool, thnx shachaf
16:32:16 <bakert> Saizan: to do with Num.  do i need a :: Trait in there somewhere?
16:32:17 <phlpp> :)
16:32:33 <tphyahoo> what about writing a server? happs obviously. any simpler examples / tuts ?
16:32:45 <sorear> omnId: can you @paste the code so someone ELSE can check if it's fixed?  the rc doesn't work for me, it might be equally painful for you
16:33:13 <sorear> omnId: take advantage of the internet, save yourself some at least waiting
16:33:26 <Saizan> bakert: on 13, if that solves, i'd like to know the type of traits and evil
16:33:46 <bakert> doesn't fix it.  same error.
16:35:07 <omnId> sorear: I have two modules, one that defines some TH splices, one that uses them.  I think the panic happens because of an interaction between quoting and splicing or something, give me a sec and I'll paste.
16:35:09 <Saizan> phlpp: there's a irc package on hackage, just parsing/prettyprinting though
16:35:53 <Saizan> bakert: can you paste the code?
16:35:54 <phlpp> Saizan: ok, first, the tutorial mentioned by shachaf is ok to me ;)
16:37:00 <shachaf> phlpp: Well, you'd probably use something smarter than (drop n) for anything non-trivial.
16:37:25 <hpaste>  omnId pasted "GHC panic, file FRefTest.hs" at http://hpaste.org/3380
16:37:48 <bakert> Saizan, omnId and everyone else.  thanks so so much for all your help.  we're nearrrrly there.  it's gone midnight here though so perfection must wait for another day.  thanks!
16:37:49 <hpaste>  omnId annotated "GHC panic, file FRefTest.hs" with "file FRef.hs" at http://hpaste.org/3380#a1
16:37:51 <bakert> g'night!
16:37:56 <phlpp> shachaf: eh?
16:38:42 <omnId> Saizan: looks like your suggestion to quote the name in the splice functions may have caused the panic.
16:39:58 <hpaste>  omnId annotated "GHC panic, file FRefTest.hs" with "version of FRef.hs that doesn't panic" at http://hpaste.org/3380#a2
16:40:03 <shachaf> omnId: In GHC 6.9.20071012, I get:  FRef.hs:97:32: Stage error: the non-top-level quoted name 'ref must be used at the same stage at which is is bound
16:40:07 <Saizan> maybe it doesn't like the fact that ref and Ref are dfined in the same module
16:40:43 <Saizan> whre the names are quoted
16:40:45 <omnId> diff: http://hpaste.org/3380/diff?old=1&new=2
16:43:15 * omnId looks at the reportabug page
16:46:29 <omnId> "panic template stage" didn't get anything in the trac search.  I'll register and make a ticket
16:46:49 <airy> what the
16:47:16 <sorear> @seen igloo
16:47:17 <lambdabot> igloo is in #haskell, #ghc and #darcs. I last heard igloo speak 7h 16m 44s ago.
16:47:43 <airy> Did I (Ari Rahikkala) just send a message to haskell-cafe consisting of an haskell-cafe digest?
16:47:54 <omnId> is this related?: http://hackage.haskell.org/trac/ghc/ticket/1755
16:47:56 <lambdabot> Title: #1755 (Template Haskell quoting bug) - GHC - Trac
16:48:25 <sorear> omnId: igloo looks asleep, you might want to report it as guest (with a -- name, of course) - accounts must be manually activated because spammers are smart enough to register these days, but not smart enough to read the "log in as guest/guest" bit
16:48:29 <airy> Ah, good
16:48:34 <airy> mailman held it and allowed me to cancel it
16:48:41 <sorear> Wow.
16:48:49 <sorear> For once!  A valid use for the 40k cap!
16:48:50 * airy happened to fail in a spectacular way with the gmail interface
16:51:26 <omnId> sorear: so when the Login link asks for username/password give guest/myname?
16:51:39 <sorear> omnId: 'guest' and 'guest'
16:51:45 <omnId> gotcha
16:52:12 <sorear> omnId: and suffix your post with '-- $moniker', there's not much we like less than bugs with no contact information
17:03:42 <omnId> http://hackage.haskell.org/trac/ghc/ticket/1788#preview
17:03:47 <lambdabot> Title: #1788 (panic with Template Haskell splicing/quoting) - GHC - Trac
17:20:56 <omnId> not having much success making a reducing demonstation of the bug.  Everything works :) :(
17:21:05 <omnId> reduced*
17:33:18 <omnId> @instances Quasi
17:33:19 <lambdabot> Couldn't find class `Quasi'. Try @instances-importing
17:33:56 <omnId> @instances-importing Language.Haskell.TH.Syntax Quasi
17:33:57 <lambdabot> IO, Q
17:34:38 <omnId> lambdabot++
17:35:14 <Pseudonym> ?karma lambdabot
17:35:14 <lambdabot> lambdabot has a karma of 46
17:35:45 <lambdabot> I am so cool I outfreeze myself.
17:36:13 <phlpp> @src (>>=)
17:36:13 <lambdabot> Source not found. It can only be attributed to human error.
17:36:16 <phlpp> hehe
17:36:17 <omnId> that you are, LB
17:36:56 <balodja> kill all humans?
17:37:17 <lambdabot> I have no hate. Om...
17:37:55 <omnId> you don't need hate to kill, you could be sociopathic.
17:38:01 <phlpp> hm, how could i check if there is a string in a string?
17:38:06 <phlpp> sth. like strstr?
17:38:11 <phlpp> (strstr for C/PHP i mean)
17:38:14 <Pseudonym> Do you need to find where it is?
17:38:24 <phlpp> no, just if it is there
17:38:27 <Pseudonym> Right.
17:38:30 <omnId> phlpp: new version should have an isInfixOf, until then here it is:
17:39:03 <omnId> xs `isInfixOf` ys = any (xs `isPrefixOf`) (tails ys)
17:39:20 <omnId> @index isPrefixOf
17:39:21 <lambdabot> Data.List
17:39:27 <Pseudonym> Having said that, if performance is an issue, google for: knuth morris pratt haskell
17:39:40 <phlpp> omnId: ah ok, its there
17:40:46 <phlpp> ah, great, that works :>
17:41:10 <Pseudonym> Unfortunately, hawiki is offline, but Google cache helps here:
17:41:12 <Pseudonym> http://72.14.253.104/search?q=cache:kG4zvvkZPLYJ:www.haskell.org/hawiki/RunTimeCompilation
17:41:14 <lambdabot> http://tinyurl.com/27qoj3
17:42:31 <phlpp> thx
17:43:04 <puusorsa> how about boyer-moore?
17:43:16 <phlpp>  ok guys
17:43:26 <phlpp> that's all for today (yesterday, actually)
17:44:02 <phlpp> i'll continue annoying you in a few hours, when i'm awake again.
17:44:08 <phlpp> good night everyone
17:44:19 <Pseudonym> Night, and this is good annoying.
17:44:21 <puusorsa> sleep is just an inadequate substitute for caffeine
17:44:48 <puusorsa> http://article.gmane.org/gmane.comp.lang.haskell.libraries/7363
17:44:50 <lambdabot> Title: Gmane -- Mail To News And Back Again
17:44:53 <LoganCapaldo> bah
17:45:06 <puusorsa> isn't boyer-moore faster than kmp?
17:48:38 <sorear> aren't they both O(n)?
17:48:58 <puusorsa> no?
17:49:09 <LoganCapaldo> even if they are, constant factors?
17:49:13 <puusorsa> just a moment
17:49:39 <puusorsa> Assuming the prior existence of the table T, the search portion of the Knuth-Morris-Pratt algorithm has complexity O(k)
17:50:11 <puusorsa> The worst-case to find all occurrences in a text needs approximately 3*N comparisons, hence the complexity is O(n), ..
17:50:26 <puusorsa> so yes, they're both O(n)
17:52:14 <puusorsa> The Turbo Boyer-Moore algorithm takes an additional constant amount of space to complete a search within 2n comparisons (instead of 3n)
17:52:40 <LoganCapaldo> turbo?
17:52:44 <LoganCapaldo> heh turbo
17:52:54 <puusorsa> i blame wikipedia
17:53:05 <LoganCapaldo> more algorithms should have turbo in their name
17:53:09 <puusorsa> borland should make turbohaskell
17:54:21 <qubit> hi guys, a quick question about syntax : when i write msort :: Ord a => [a] -> [a]
17:54:21 <qubit> msort [] = []
17:54:21 <qubit> msort [x] = [x]
17:54:21 <qubit> msort xs = merge (msort top) (msort bottom)
17:54:21 <qubit>    where
17:54:21 <qubit>    (top, bottom) = splitAt (length xs `div` 2) xs, what do the brackets under the where statement mean?
17:54:45 <shachaf> qubit: Pattern-matching.
17:55:25 <qubit> ,so the match the pattern top and bottom in the above expression?
17:55:28 <shachaf> qubit: The right side of the = is a tuple; this calls its fst top and its snd bottom.
17:55:30 <puusorsa> splitAt (length xs `div` 2) xs returns a pair
17:55:37 <puusorsa> and what shachaf said
17:55:50 <qubit> ok got it thanks!
17:56:44 <qubit> so it matches the top and bottom for the msort expression
17:57:10 <Cale> qubit: It defined top and bottom to be the result of splitAt
17:57:14 <Cale> defines*
17:57:24 <qubit> ok
17:57:29 <Cale> and then those get used in the merge above
17:57:30 <qubit> ;)
17:57:42 <qubit> cheers
17:57:52 <jleedev> > let (,) a b = (1,2) in a+b
17:57:53 <lambdabot>  3
17:57:57 <lekro> in what kind of calculation can ghci be stuck if it ignores ^C?
17:58:14 * Cale watches all his software get upgraded out from under him
17:58:25 <LoganCapaldo> oh noes
17:58:26 <Cale> lekro: What platform is that?
17:58:30 <lekro> Cale: Mac OS X
17:58:51 <lekro> I'm constructing a DiffArray and apparently there is some never-ending loop in my code. I was only curious why ghci keeps ignoring ^C then
17:59:40 <EvilTerran> ^C might not work when ghci's in a foreign imported function
17:59:49 <sorear> lekro: almsot any, ghci does not handle ^c well at all
18:00:00 <EvilTerran> (i'm guessing)
18:00:12 <lekro> EvilTerran: it's pure code, just a DiffArray in some state and reader monad
18:00:13 <LoganCapaldo> have you tried Ctrl-\
18:00:40 <EvilTerran> yeah, but i think all the *Arrays use foreign functions in their implementations
18:01:21 <lekro> LoganCapaldo: Ctrl-\ is ignored too
18:02:02 <LoganCapaldo> have you tried Ctrl-Z in conjunction with kill? :)
18:02:43 <Cale> I don't think I've ever seen Ctrl-C get ignored.
18:02:47 <lekro> I just opened another terminal and used killall
18:03:00 <Cale> But yeah, Ctrl-Z typically works for programs which die like that
18:03:11 <LoganCapaldo> Cale: I just tried it (also on OS X) Ctrl-C doesn't appear to do anything
18:03:28 <lekro> Cale: Ctrl-Z works, yes
18:03:40 <LoganCapaldo> oh wait
18:03:49 <LoganCapaldo> jsut doesn't do anything when you're not doing anything
18:04:38 <LoganCapaldo> STOP, like KILL is one of the signals a process can not trap or ignore
18:05:00 <LoganCapaldo> unfortunately processes can still take over the terminal and stop you from using Ctrl-Z to send STOP
18:05:18 <sorear> LoganCapaldo: not quite
18:05:31 <sorear> LoganCapaldo: ^Z sends, depending on terminal modes, TSTP
18:05:37 <sorear> which *can* be caught or ignored
18:05:45 <sorear> kill -STOP is unstoppable
18:07:38 <LoganCapaldo> Is that something flavor specfic? (eg SysV or BSD?) ? I've never heard of TSTP before
18:07:56 <allbery_b> and you really want to be able to catch TSTP, because otherwise TSTPing a (n)curses-using program could make you very unhappy
18:08:25 <LoganCapaldo> guess not
18:08:49 <sorear> allbery_b: huh, I thought shells were supposed to install reasonable terminal modes when wait returns?
18:08:54 <LoganCapaldo> I guess I've just never heard of it before
18:09:46 <allbery_b> sorear: not historically, it really only started happening when shells started themselves running in -icanon
18:10:36 <sorear> methinks they should just fix the line driver
18:10:45 <sorear> readline is an adomination
18:29:50 <newsham> heh, ttys in 2007
18:30:15 <newsham> what baud is your teletype?
18:30:35 <monochrom> 100 mega baud
18:32:54 <newsham> "stty sets current I/O options on the current output typewriter."
18:34:48 <shubalub> I for one am happier knowing that my Ubuntu install running in a VM is ready to talk to me over a teletype, should the need arise
19:23:25 <_achilles_> quiet in here this evening
19:33:29 <dhpeterson> yeah
19:33:36 <dhpeterson> in the morning (AEST)
19:33:37 <dhpeterson> :)
19:48:37 <Brian`> hi
19:48:54 <Brian`> is there a function that returns the datatype of arguments and its return type?
19:49:00 <Brian`> like :t in ghc interpreter
19:49:26 <allbery_b> haskell doesn't do introspection, if that's what you're asking
19:49:31 <shachaf> Brian`: It depends -- what do you want to do with it?
19:49:36 <allbery_b> there's Data.Typeable but it fails in the presence of polymorphism
19:49:48 <allbery_b> that said, what are you really looking for?
19:50:27 <Brian`> I'd like to build an IDE that shows data type of current argument
19:50:34 <Brian`> i mean as in intellisense
19:50:57 <Brian`> for example, if the programer starts typing 3 +
19:50:57 <shachaf> Brian`: You might want to look at the way current editors/IDEs do it.
19:51:15 <Brian`> then the intellisense shows your the next argument would be Int or Num or something like that
19:51:26 <Brian`> what's the current most popular IDE for haskell?
19:51:48 <shachaf> Brian`: Vim or emacs? :-)
19:51:55 <Cale> Brian`: vim or emacs.
19:51:57 <Brian`> oh ok
19:52:10 <shachaf> I think Visual Haskell has something like that.
19:52:46 <shachaf> But both vim and emacs also have some sort of support (by connecting to ghci, I think).
19:53:10 <Brian`> hm.. i c
19:54:02 <Cale> It's theoretically possible to create an awesome Haskell IDE, but nobody's really done it.
19:54:26 <Cale> Also, the design of Haskell obviates many of the usual reasons to use an IDE.
19:56:02 <Brian`> i c..
19:56:40 <allbery_b> @where shim
19:56:40 <lambdabot> http://shim.haskellco.de/trac/
19:56:48 <allbery_b> ^^ there?
19:56:57 <Brian`> I was planning to make an IDE that can be opened on internet browser
19:57:19 <geocalc> why ?
19:57:57 <Brian`> to easily program server-side script with haskell and see the result instantly
19:59:09 <geocalc> so you just need your server run ghci
19:59:37 <asl> @djinn a -> Maybe a
19:59:37 <lambdabot> f = Just
19:59:44 <Brian`> hm.. yeah but the problem is since other ppl don't know haskell
19:59:44 <asl> @djinn a -> [a]
19:59:45 <lambdabot> -- f cannot be realized.
20:00:07 <asl> @djinn a -> Either a b
20:00:07 <lambdabot> f = Left
20:00:11 <Brian`> I was going to make an IDE that can help them write a widget quickly wihout knowing too much about haskell
20:01:06 <asl> @djinn-env
20:01:07 <lambdabot> data () = ()
20:01:07 <lambdabot> data Either a b = Left a | Right b
20:01:07 <lambdabot> data Maybe a = Nothing | Just a
20:01:07 <lambdabot> data Bool = False | True
20:01:07 <lambdabot> data Void
20:01:09 <lambdabot> type Not x = x -> Void
20:01:09 <geocalc> widget need widget knowledge
20:01:11 <lambdabot> class Eq a where (==) :: a -> a -> Bool
20:03:21 <geocalc> Brian`=<< what kind of widget ?
20:03:43 <Brian`> like that of iGoogle widget
20:03:57 <Brian`> the website i'm working on is kinda similar to iGoogle
20:04:07 <Brian`> but specialized to specific area
20:04:23 <Brian`> right now working with php and javascript
20:04:26 <Brian`> but they are pain in the ass
20:04:54 <geocalc> ^hehe
20:04:58 <Brian`> that might be because i'm not expert in those but still feel like it's hard to program with...
20:05:25 <ramza3> completely off-topic question; but I just want to ask once.  Do ips change when you are using a wireless connection; they aren't mapped to the laptop device?
20:05:59 <geocalc> sure haskell is better Brian` :)
20:06:28 <dankna> ramza: this really isn't the place to ask, but the short answer is that the router you connect to assigns the IP, and unless it's been configured to always give you the same one, yes it changes
20:06:31 <Brian`> lol yeah I hope so
20:06:38 <Brian`> though I'm not haskell expert either
20:06:46 <Brian`> but I really enjoy learning haskell
20:06:53 <Brian`> something looks elegant in haskell
20:07:06 <geocalc> me too
20:07:09 <ramza3> dankna, I know, but I got my answer
20:07:16 <dankna> heh, okay
20:07:20 <Brian`> I just with I become expert in haskell someday soon :)
20:07:29 <Brian`> geocalc, how long have you programmed with haskell
20:07:31 <dankna> that's why I probably shouldn't have answered, people won't thank me for encouraging it :)
20:07:34 <dankna> oh well
20:07:43 <ramza3> dankna, but I meant the public ip
20:08:00 <geocalc> 0 day i begin :)
20:08:15 <dankna> NAT is a separate issue, but again, it's under the control of the router; whether it's a wired or a wireless router doesn't matter
20:08:33 <SamB_XP_> I want my 0 day Haskell warez
20:08:38 <Brian`> haha really? i c
20:08:40 <Brian`> that's cool
20:08:51 <Brian`> anyway I'm gonna go to bed now :)
20:08:52 <Brian`> good night guys
20:20:09 <ac> In Haskell, it is difficult for me to understand how to implement an efficient queue (though I do know it's possible, thanks to a paper I read). This can be directly attributed to Haskell's referential transperency, no?
20:24:34 <chessguy> not so
20:24:44 <chessguy> you should be able to easily do it with Data.Sequence
20:24:53 <Philippa> that's cheating
20:25:35 <chessguy> uh, i think that's how most people would go about it...
20:27:02 <sorear> ac: Implementing an ephemeral queue in Haskell is just as easy as in any other language, and implementing a persistent queue is just as hard as in any other language.
20:28:49 <ac> sorear: what's ephemeral vs persistent?
20:29:30 <sorear> ac: ephemeral structures are destroyed by operations.  if you have a = {1,2,3} and b = a + {4}, does a still exist?
20:44:41 <ac> sorear: I didn't ask what I intended. What I really meant to ask is "is there an easy way to understand how purely functional and lazy data structures behave"
20:45:13 <ac> sorear: and a queue is a good example of such a data structure that is apparently fairly easy to implement in Haskell but hard (for me) to understand how it operates
20:46:23 <shubalub> semi-seriously, is there an easy way to understand how anything in haskell behaves?
20:47:19 <Cale> shubalub: sure
20:47:33 <Cale> shubalub: Do you mean that you'd like to know how evaluation works?
20:47:52 <shubalub> I think I understand function evaluation
20:48:08 <Cale> Evaluation is carried out in an outermost first fashion
20:48:15 <Cale> So if you have double x = x + x
20:48:27 <ac> I feel it's easy to understand how most things behave in Haskell... until I come accross something like this:
20:48:30 <ac> http://citeseer.ist.psu.edu/okasaki95simple.html
20:48:32 <lambdabot> Title: Simple and Efficient Purely Functional Queues and Deques - Okasaki (ResearchInde ...
20:48:43 <Cale> Well, I'll show it with plain outermost first, and then lazy evaluation, which is an optimisation of that:
20:48:49 <Cale> double (double 5)
20:49:06 <Cale> Er, let's do strict evaluation too, just to be safe.
20:49:12 <Cale> So under strict evaluation:
20:49:16 <Cale> double (double 5)
20:49:20 <Cale> = double (5 + 5)
20:49:22 <Cale> = double 10
20:49:26 <Cale> = 10 + 10
20:49:27 <Cale> = 20
20:49:40 <Cale> Under plain outermost first (normal order) evaluation:
20:49:44 <Cale> double (double 5)
20:49:49 * omnId greps the #haskell logs for 'double (double 5)' :)
20:49:50 <Cale> = (double 5) + (double 5)
20:49:56 <Cale> = (5 + 5) + (double 5)
20:50:07 <Cale> = 10 + (double 5)
20:50:10 <Cale> = 10 + (5 + 5)
20:50:12 <Cale> = 10 + 10
20:50:14 <Cale> = 20
20:50:28 <Cale> and you can see there that it duplicated the work of evaluating double 5
20:50:37 <Cale> So lazy evaluation is an optimisation of that
20:50:52 <shachaf> omnId: I find 27... And they're all by Cale. :-)
20:51:00 <Cale> Whenever a parameter to a function occurs multiple times in the body, the result is shared by all the copies.
20:51:01 <dfranke_> double (double (toil && trouble))?
20:51:06 <Cale> shachaf: hehe
20:51:12 <omnId> :)
20:51:14 <shubalub> ah, memoization?
20:51:17 <Cale> Kind of
20:51:39 <ac> lazy evaluation with shared values != memoization
20:51:43 <Cale> But not quite the same thing
20:51:47 <shubalub> I think thunks are involved here, but not the Win16 kind
20:52:08 <Cale> It's a sort of temporary memoisation which only lasts while that function is being evaluated, I suppose.
20:52:20 <Cale> So under lazy evaluation:
20:52:24 <Cale> double (double 5)
20:52:32 <Cale> = let x = double 5 in x + x
20:52:37 <Cale> = let x = 5 + 5 in x + x
20:52:40 <Cale> = let x = 10 in x + x
20:52:43 <Cale> = 20
20:52:43 <shachaf> There's also a quadruple x = double (double x)
20:53:05 <Cale> shubalub: hm?
20:53:11 <Cale> er, shachaf rather
20:53:13 <shachaf> Cale: = 10 + 10, also?
20:53:15 <sorear> Cale: nah, it lasts longer.  (\x -> (x,x)) (double x)  will only double x once, but after the function returns
20:53:21 <shachaf> Cale: In the logs.
20:53:41 <Cale> shachaf: yeah, but since that doesn't actually correspond to an evaluation step, I left it out. I'm using the let to denote where pointers are pointing :)
20:53:53 <shubalub> mmm...is it always valid to view function applications as nested lets?
20:53:58 <ac> could somebody explain to me how you could write a function that prepends a value to a list, and insures that there are never more than N values in the list (meaning it after N iterations, it starts discarding the last element) that operates in O(1) time?
20:54:23 <Cale> shubalub: If you really wanted to, I suppose that you could.
20:54:38 <shachaf> ac: Well, if you do anything with the last element, how would it be O(1)?
20:54:47 <Cale> ac: It would have to maintain the length of the list.
20:54:57 <ac> shachaf: I'm sure it's possible
20:54:59 <Cale> and even then, it would be O(log n) time
20:55:11 <omnId> ac: so for behavior, you want: prepend n x xs = x : take (n-1) xs -- ?
20:55:16 <Cale> because as the integer got larger, it would take longer to increment it
20:55:18 <geocalc> \ac
20:55:30 <Cale> :)
20:55:53 <omnId> regardless of runtime complexity, is that what you want the function to do?
20:56:01 <ac> Cale: this is a simpler problem than the one solved in that paper I just linked to, and they claim inserts and removals are O(1)
20:56:11 <ac> omnId: Yes
20:56:31 <Cale> ac: I suppose that omnId's version is "O(1)"
20:56:51 * ac :) at omnId's use of "--"
20:56:55 <Cale> But it makes accesses to later elements of the list progressively slower.
20:57:06 <omnId> I had to finish the question :)
20:57:23 <ac> omnId: I always put the code in quotes, but that's cooler
20:57:49 <Cale> You're going to pay an additional O(1) cost for each element of the tail you want to look at.
20:58:18 <omnId> I suppose I could put the code between \begin{code} and \end{code} :D
20:58:23 <ac> Cale: this is just a theoretical question, but the point is that adding and reading the head is quick, and if you really want to, you can look at older values
20:58:39 <Cale> ac: ah, then that's valid
20:58:54 <ac> Cale: so omnId's version is actually efficient?
20:58:56 <Cale> yes
20:59:04 <Cale> It returns a cons cell immediately
20:59:22 <Cale> That cons cell has in its tail,  take (n-1) xs
20:59:32 <omnId> prepend ... = (:) x (...) -- remember, outermost-first, so the caller immediately gets the (:)
20:59:38 <Cale> Of course, another problem is that xs won't be freed.
21:00:17 <Cale> So if you do a lot of prepends, you'll still incur all the memory costs until you finish evaluating one of them and throw away the rest.
21:00:26 <Cale> At which point you'll have paid the time costs as well.
21:00:37 <ac> right, so periodically you'd want to force that by saying "take 10 xs"
21:00:39 <Cale> (which are quadratic in n)
21:00:49 <ac> er, "take N xs"
21:01:18 <omnId> @src take
21:01:19 <lambdabot> take n _      | n <= 0 =  []
21:01:19 <lambdabot> take _ []              =  []
21:01:19 <lambdabot> take n (x:xs)          =  x : take (n-1) xs
21:01:48 <Cale> Well, you have to actually force evaluation, so something like completely forcing xs to evaluate using some recursive application of seq or even just computing the length
21:01:55 <omnId> take gives a cons cell immediately, too.  You'll have to force it by printing or `seq` something that depends on the whole list.
21:02:15 <ac> Cale: the way I'm imagining it is that with each prepend, another take gets queued up, and they aren't evaluated until you look at the older elements
21:02:23 <ac> Cale: is that a valid way of picturing it?
21:02:23 <Cale> ac: that's right
21:02:39 <Cale> It *really* returns the expression on the RHS
21:02:49 <Cale> directly, with no additional evaluation
21:03:01 <ac> Cale: what's an ellegant way to periodically force the evaluation to conserve memory, or does ghc do this automatically?
21:03:21 * locomalo is away: Ausente
21:03:41 <Cale> Well, it's not usually all that elegant, but you can use seq in order to force the evaluation of, say, the length of the list.
21:03:57 <omnId> seq evaluates to the top level constructor
21:04:16 <omnId> each integer itself behaves as if it's one constructor
21:04:17 <ac> oh, so that's a valid use of seq. I remember someone saying a while back on this channel that seq was rather obstruse
21:04:26 <Cale> Right, so if you applied seq immediately, all it would do is say, "yep, it's a cons", and leave the rest alone.
21:04:59 <ac> s/obstruse/obscure/
21:05:03 <Cale> So you need to either apply it recursively, or seq (length xs) ...
21:05:05 <omnId> in order to see *which* integer the length evals to, it has to walk down the list.
21:05:25 <Cale> You should usually profile your program first though
21:05:31 <Cale> in order to see if it's really necessary
21:05:41 <ac> Cale: this is just a thought experiment
21:05:50 <ac> to help me understand Haskell
21:06:06 <ac> meaning I have nothing to profile ;)
21:06:10 <omnId> well, when you *write* haskell, profile before seqing :)
21:06:11 <Cale> If you actually use the list soon enough, then you don't actually need seq
21:06:25 <ac> I see
21:06:40 <Cale> seq x y is sort of like  case x of ... -> y, _ -> y
21:06:57 <Cale> Where you could fill in the ... with some constructor pattern match for the type of x
21:07:16 <Cale> So for instance, if x is a list, it would be  case x of (_:_) -> y; _ -> y
21:07:22 <bos> @src on
21:07:23 <lambdabot> (*) `on` f = \x y -> f x * f y
21:07:39 <Cale> That'll check to see if x is cons or nil before returning y
21:08:03 <omnId> oh right, I was going to say that you needed to add the other constructors, but evaluation only needs to inspect the constructor once :)
21:08:08 <Cale> right
21:08:33 <Cale> At some level, case expressions cause all evaluations to start.
21:08:41 <bos> is there a common name for the pattern \q f g x -> f x `q` g x ?
21:08:50 <bos> @src liftM2
21:08:51 <lambdabot> liftM2 f m1 m2 = do { x1 <- m1; x2 <- m2; return (f x1 x2) }
21:08:52 <omnId> the actually act of "inspecting the constructor" for a pattern match is what sets evaluation off and running.
21:09:12 <omnId> bos: looks like 'on'.
21:09:18 * Cale restarts and hopes for the best.
21:09:33 <bos> omnId: it's similar to on, but not the same
21:09:50 <omnId> oh, there are two inner functions.
21:10:04 <ac> omnId: why does case force evaluation?
21:10:08 <omnId> @pl \q f g x -> f x `q` g x -- should be liftM2
21:10:08 <lambdabot> liftM2
21:10:21 <bos> that's what i thought.
21:11:03 <omnId> ac: well, it has to actually perform the function applications like Cale demonstrated until it can figure out if the value matches the (_:_) pattern, or if it's nil.
21:11:43 <ac> omnId: oh I see. So because it can be a cons sell OR a nil, it has to evaluate it
21:11:49 <omnId> yep
21:11:52 <bos> only liftM2 has a monadic type constraint, whereas this function doesn't
21:12:05 <bos> so it's lifting the function q into some other category
21:12:22 <omnId> bos: m = ((->) e)
21:12:31 <bos> ooh, good observation
21:12:43 <shachaf> @ty liftM2 `asTypeOf` (\q f g x -> f x `q` g x)
21:12:44 <lambdabot> forall a1 a2 r t. (Monad ((->) t)) => (a1 -> a2 -> r) -> (t -> a1) -> (t -> a2) -> t -> r
21:12:47 * bos always forgets the ((->) e) monad
21:12:58 <omnId> ((->) e) (a -> b -> c) -> ((->) e) a -> ((->) e) b -> ((->) e) c
21:13:15 <shachaf> bos: For that matter, this can be liftA2 from Control.Applicative.
21:14:02 <omnId> is there an instance Applicative ((->) e) anywhere?  It wouldn't be too hard to define one but...
21:14:03 <ac> @src seq
21:14:03 <lambdabot> Source not found. There are some things that I just don't know.
21:14:17 <bos> omnId: yes, in Control.Applicative
21:14:26 <ac> :t seq
21:14:28 <lambdabot> forall a t. a -> t -> t
21:14:33 <shachaf> > (,) <$> (+1) <*> (*2) $ 5
21:14:34 <lambdabot>  (6,10)
21:14:41 <bos> ah, #haskell is the best channel EVAR
21:14:48 <bos> thanks, guys.
21:14:52 <shachaf> ac: It's a primitive.
21:14:56 <ac> bos: I agree
21:15:07 <lament> seq is magical, it breaks the rules of haskell, writing it in haskell would be difficult
21:15:16 <ac> shachaf: it would figure. I thought it might be implemented with case
21:15:31 <shachaf> ac: You can implement it as (seq !_ y = y) with BangPatterns, though.
21:15:34 <shachaf> (I think?)
21:15:40 * omnId now understands why class Eval where seq :: a -> b -> b would fix things.
21:15:41 <ac> lament: it's not magical... from a semantic perspective it has 0 effect, right?
21:15:55 <shachaf> ac: No.
21:15:57 <ac> if it's magic, it's invisible magic, right?
21:16:00 <shachaf> > undefined `seq` 2
21:16:02 <lambdabot>  Undefined
21:16:08 <bos> it can cause your program to crash where otherwise it would not.
21:16:19 <omnId> ac: _|_ is a very tricky thing indeed.
21:16:31 <ac> "_|_"?
21:16:32 <shachaf> ac: A function f is strict if f _|_ = _|_.
21:16:38 <omnId> bottom.
21:16:50 <omnId> undefined
21:16:52 <shachaf> Can we have @_|_, please? :-)
21:16:53 <wli> const _|_?
21:16:54 <omnId> infinite loop
21:16:56 <omnId> error
21:17:00 <lament> so seq is like >> in the monad that's notable by its absence from Haskell
21:17:27 <omnId> bottom is bad things
21:17:45 <lament> > undefined >> 2
21:17:46 <lambdabot>   add an instance declaration for (Num (m b))
21:17:50 <lament> hehe
21:18:00 <omnId> > undefined >> return 2 :: Maybe Int
21:18:01 <lambdabot>  Undefined
21:18:21 <lament> > undefined >> return 2
21:18:21 * locomalo is back (gone 00:13:54)
21:18:21 <lambdabot>   add an instance declaration for (Show (m t))
21:18:31 <lament> oh, right
21:18:32 <sorear> wli: yup, that function is strict
21:18:38 <shachaf> > (undefined >> return 2) 5 -- Reader isn't strict.
21:18:39 <lambdabot>  2
21:18:54 <omnId> :)
21:19:00 <lament> i don't get the reader monad at all
21:19:01 <sorear> wli: a favorite example of mine for using on those newbies who think strictness has something to do with evaluating arguments
21:19:19 <shachaf> > runIdentity (undefined >> return 2 :: Identity Int) -- Nor is Identity.
21:19:20 <lambdabot>  2
21:19:24 <shachaf> Are there any others?
21:21:38 <omnId> the gentle introduction gives some explanation of bottom.
21:22:11 <ac> are all of Haskell's primitives strict?
21:22:17 <geocalc> when there's no beer talks it's interesting here :)
21:22:33 <wli> no
21:22:40 <ac> silly question: why not?
21:23:06 <omnId> I guess it'd make it difficult for Haskell to call itself non-strict :)
21:23:08 <ac> I see why you would want to define your own non-strict functions, but in general, isn't strictness desireable?
21:23:18 <TSC> It depends on the operation
21:23:44 <ac> like why isn't tail strict?
21:23:59 <kscaldef> because you might not need the result
21:24:03 <ac> > tail tail tail [1 2]
21:24:04 <lambdabot>  Couldn't match expected type `[a]'
21:24:08 <TSC> > tail [1..]
21:24:09 <lambdabot>  [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29...
21:24:10 <kscaldef> or the result might be infinite
21:24:11 <TSC> That's why
21:24:13 <ac> > tail tail tail [1, 2]
21:24:14 <lambdabot>  Couldn't match expected type `[a]'
21:24:19 <ac> bleh
21:24:25 <ac> > tail $ tail $ tail [1,2]
21:24:28 <lambdabot>  Exception: Prelude.tail: empty list
21:24:43 <wli> It forces one constructor application.
21:24:46 <kscaldef> ac: do you want (foo && bar) to be strict in any language?
21:25:38 <ac> kscaldef: I do not have an opinion :P
21:26:04 <wli> I'd like || and && to be symmetrically non-strict. ;)
21:26:14 <kscaldef> how about "if"?  Should "if" be strict?
21:26:21 <shachaf> TSC: That wouldn't matter, would it?
21:26:49 <shachaf> TSC: It would still work; only the first (:) would be forced.
21:27:49 <omnId> I like that non-strictness in general allows me to not care *what* order things evaluate in.
21:28:58 <wli> What about x || True?
21:29:17 <wli> vs. True || x
21:30:11 <kscaldef> wii: I would tend to consider it bad style to depend on that distinction, if any, in any language
21:30:20 <sjanssen> wli: that seems difficult
21:30:28 <TSC> It's pretty common to depend on it
21:30:32 <sjanssen> remember that non-termination is a _|_
21:30:58 <wli> Just interleave the reduction steps for the left and right arguments..
21:31:29 <kscaldef> TSC: common to depend on that literally?
21:31:41 <wli> yes
21:31:49 <sjanssen> @src and
21:31:49 <lambdabot> and   =  foldr (&&) True
21:32:06 <TSC> In C, something like "if (p == null || p->x == 0)", or something like that
21:32:09 <TSC> If that's what you mean
21:32:50 <ac> I think I need a clue injection. I'm still not quite grasping the relationship between head being non-strict, and being able to return an infinite list
21:32:50 <kscaldef> well, that's certainly not literally "True"
21:33:22 <TSC> Oh, I thought you meant || being lazy in general
21:33:49 <wli> There's something called full abstraction...
21:33:50 <kscaldef> no, I meant literally writing C code like (...side effects... || 1)
21:33:56 <sjanssen> head is strict, isn't it?
21:34:03 <sjanssen> head _|_ = _|_
21:34:05 <kscaldef> and assuming the side effect wll happen
21:34:15 <ac> > head undefined
21:34:26 <lambdabot>  Undefined
21:34:34 <ac> er, I meant tail
21:34:36 <ac> > tail undefined
21:34:37 <lambdabot>  Undefined
21:34:43 <geocalc> ac need glasses
21:34:45 <sjanssen> tail is also strict
21:34:55 <ac> geocalc: I'm wearing glasses
21:35:17 <geocalc> newest so
21:35:31 <geocalc> ;)
21:35:54 <ac> Ok, well I don't understand the relationship between strictness and seq
21:36:07 <ac> But that's OK, because I don't understand seq, and I don't anticipate needing to use it any time soon
21:36:11 <shachaf> ac: seq is strict.
21:36:19 <shachaf> ac: In its first argument.
21:36:45 <shachaf> ac: And then it returns its second argument.
21:36:56 <shachaf> ac: If it gets to it.
21:37:02 <shachaf> s/then //, I guess.
21:37:35 <wli> Depending on order of evaluation happens in constructor scrutinization, so operational semantics are more strict than denotational.
21:38:58 <wli> For operational and denotational to coincide scrutinization needs to be order-independent.
21:39:20 <geocalc> scrut... what a word !
21:39:30 <omnId> @wn scrutinize
21:39:32 <lambdabot> *** "scrutinize" wn "WordNet (r) 2.0"
21:39:32 <lambdabot> scrutinize
21:39:32 <lambdabot>      v 1: to look at critically or searchingly, or in minute detail;
21:39:32 <lambdabot>           "he scrutinized his likeness in the mirror" [syn: {size
21:39:32 <lambdabot>           up}, {take stock}, {scrutinise}]
21:39:34 <lambdabot>      2: of accounts and tax returns; with the intent to verify [syn:
21:39:36 <lambdabot>          {audit}, {scrutinise}, {inspect}]
21:39:52 <wli> case statements
21:40:36 <wli> Especially case (x, y) of (patX1, patY1) -> ... ; (patX2, patY2) -> ...
21:41:18 <wli> but also fall-through semantics defeat full abstraction, e.g. wildcard _ in many instances
21:41:57 <sjanssen> Haskell doesn't have much of an operation semantics
21:42:38 <wli> case and pattern guards are defined operationally in terms of sequentially trying alternatives
21:43:57 <geocalc> definable order you mean sjanssen ?
21:46:10 <sjanssen> geocalc: I mean operational semantics :)
21:46:22 <geocalc> i better use precedence
21:46:45 <sjanssen> but yes, the lack of a defined sequence of operations is part of it
21:47:55 <geocalc> i agree
21:48:20 <wli> The operational semantics is underspecified.
21:48:47 <sjanssen> I don't think this is a problem
21:48:51 <wli> However, the constructs I mentioned are still operationally defined.
21:48:58 <wli> It's not a problem. It's a distinction.
21:49:29 <sjanssen> wli: reading the report, I'm not sure that I agree
21:50:23 <sjanssen> the report's treatment of case seems denotational to me
21:51:15 <wli> It arises from the significance of the order of alternatives.
21:51:29 <geocalc> we need a maude clone in haskell
21:53:09 <wli> This all has to do with getting _|_ more often than might seem strictly [sic] necessary.
21:53:18 <lament> is there a good intro to the -> monad?
21:53:39 <wli> Essentially generalizations of x || True vs. True || x
21:53:59 <lament> (i'm sure there is, but it's impossible to google for ->, and haskell.org search doesn't work either)
21:54:17 <sjanssen> lament: do you know the Reader Monad?
21:54:20 <omnId> lament: try "reader monad" or "function monad"
21:54:50 <wli> The x || True vs. True || x phenomenon arises from lacking full abstraction, i.e. denotational /= operational.
21:55:39 <lament> sjanssen: more or less
21:56:11 <sjanssen> lament: Reader is actually just a wrapper around ->
21:56:16 <sjanssen> @src Reader
21:56:16 <lambdabot> Source not found. Sorry.
21:56:17 <sjanssen> bah
21:56:30 <sjanssen> newtype Reader e a = Reader (e -> a)
21:56:55 <sjanssen> ask = id
21:57:13 <omnId> lament: I became more familiar by taking some common monad functions, like liftM2, and replacing and applying the definitions of return and (>>=)
21:57:35 <wli> In the end it comes down to operational aspects of pattern match definitions and case statements.
21:58:03 <thoughtpolice> hm, is it worth really upgrading to cabal 1.2.0 right now?
21:58:26 <omnId> here's something: http://www.alpheccar.org/en/posts/show/61
21:58:27 <lambdabot> Title: A newbie in Haskell land : The (->) monad
21:58:36 <thoughtpolice> the configurations look nice, but i'd have to specify to use cabal 1.1.6.2?
21:58:45 <thoughtpolice> for all other packages, that is
21:58:58 <shachaf> sjanssen: ask = Reader id,  no?
21:59:01 <thoughtpolice> or i could just hide 1.2.0 and have this package require it explicitly
21:59:01 <omnId> though ((->) e) is the correct monad, or I should say, monads, since e is polymorphic.
21:59:11 <sjanssen> shachaf: depends on which instance :)
21:59:25 <shachaf> < sjanssen> newtype Reader e a = Reader (e -> a)
22:00:35 <sorear> yes
22:00:38 <sorear> @src Reader ask
22:00:39 <lambdabot> Source not found. I am sorry.
22:00:41 <sorear> bah
22:00:58 <omnId> ask = ReaderT return -- ?
22:01:09 <omnId> @type ReaderT
22:01:12 <lambdabot> forall r (m :: * -> *) a. (r -> m a) -> ReaderT r m a
22:01:26 <geocalc> :t (->)
22:01:28 <lambdabot> parse error on input `->'
22:01:45 <omnId> (->) is itself a type
22:02:10 <geocalc> hmm
22:02:14 <shachaf> :k (->)
22:02:16 <lambdabot> ?? -> ? -> *
22:02:30 <omnId> takes two types to make a concrete type.
22:02:36 <omnId> :k (->) Int String
22:02:38 <lambdabot> *
22:03:04 <geocalc> oh kind too work
22:03:12 <wli> I'm not sure anyone got the idea I was trying to get across.
22:03:37 <sjanssen> wli: I understand
22:03:43 <wli> okay
22:03:56 <omnId> wli: I think I did mostly, but I'm not confident enough in my understanding to make any comments :)
22:03:59 <sjanssen> wli: though using "operational" was a bit confusing at first
22:04:21 <sjanssen> I would have followed "sequential" more easily
22:05:19 <wli> Haskell's a bad language to use as an example because the operational semantics are so loosely specified.
22:05:35 <wli> Where specified at all.
22:06:34 <geocalc> use maude wli
22:06:57 <wli> maude?
22:07:21 <sorear> however, the denotational semantics are
22:07:27 <sorear> so you can use any compatible opsem
22:08:03 <geocalc> ?go maude language
22:08:05 <lambdabot> http://maude.cs.uiuc.edu/papers/abstract/Dmodalg_1999.html
22:08:05 <lambdabot> Title: A Reflective Module Algebra with Applications to the Maude Language
22:12:00 <wli> This also vaguely explains functions that should denotationally be symmetric in their arguments but whose symmetry is broken by differences in strictness behavior.
22:15:41 <shubalub> ghci is okay with "s <- readFile filename", but it chokes on "s <- lines . readFile filename". Can someone please tell me why, or point me someplace I can find out the answer?
22:16:00 <omnId> shubalub: lines expects a String, not an IO String
22:16:12 <shubalub> and IO is a monad
22:16:28 <wli> liftM lines $ readFile filename
22:16:30 <omnId> yeah, but that doesn't really matter much
22:16:32 <shubalub> and...I dunno
22:16:35 <omnId> @src liftM
22:16:36 <lambdabot> liftM f m1 = do { x1 <- m1; return (f x1) }
22:17:30 <omnId> if you didn't know liftM you might've used its definition yourself: 's <- readFile filename ; let ls = lines s'
22:17:31 <shubalub> thanks
22:17:50 <shubalub> not quite
22:17:59 <omnId> hm?
22:18:07 <shubalub> I mean, :t s said string
22:18:35 <shubalub> "s :: String". So print (lines s) didn't choke
22:18:36 <omnId> yes, s is a String, which was extracted from the (readFile filename :: IO String) action.
22:19:12 <shubalub> that confused me, because I expected the type of s to be IO String
22:19:55 <shubalub> I think my understanding of <- is incomplete
22:20:06 <omnId> that's what the <- thing does
22:20:26 <omnId> do { pat <- action ; ... } = action >>= \pat -> do { ... }
22:20:29 <omnId> @type (>>=)
22:20:31 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> (a -> m b) -> m b
22:20:46 <geocalc> <-->
22:20:46 <omnId> you see there that the 'a' in second argument isn't in the monad.
22:20:59 <shachaf> lines <$> readFile filename -- With Control.Applicative.
22:21:25 <shachaf> With (.) = fmap, that would work, actually.
22:21:49 <omnId> oh boy, and I don't think I'd like explaining why to a newbie :)
22:22:33 <shachaf> shubalub: If you'd said "let s = readFile filename", s would've been :: IO String.
22:22:43 <shubalub> yeah, I'm having trouble reading a file and splitting it into lines
22:22:57 <shachaf> shubalub: Using "<-" means to extract the String from the IO.
22:23:00 <geocalc> read yaht shubalub
22:23:14 <shubalub> yaht is good?
22:23:16 * shachaf didn't like YAHT's explanation of IO.
22:23:35 <geocalc> for <-
22:23:52 <shachaf> It's weird; it introduces do-notation first, but in a confusing (I thought) way.
22:23:52 <shubalub> well, what I've found for Haskell tutorials so far tries to make me think I'm doing C with Monads
22:24:22 <geocalc> oh
22:24:37 <shubalub> and I've gotten farther from going back through my discrete mathematics text than with those :P
22:24:44 <shubalub> so I will read YAHT
22:25:18 <omnId> shubalub: the thing to remember is that actions and other values are different, and to use the right functions to get values out of, change the contents of, chain more actions onto, other actions.
22:25:20 <shachaf> @wiki Monads as containers
22:25:21 <lambdabot> http://www.haskell.org/haskellwiki/Monads_as_containers
22:25:27 <shachaf> @wiki Monads as Containers
22:25:27 <lambdabot> http://www.haskell.org/haskellwiki/Monads_as_Containers
22:25:35 <omnId> liftM changes the "contents" of an action.
22:25:43 <shachaf> Oh, never mind.
22:26:16 <shachaf> @wiki Monads as computation
22:26:16 <lambdabot> http://www.haskell.org/haskellwiki/Monads_as_computation
22:26:55 <shachaf> shubalub: Those two are nice.
22:27:01 <shachaf> Both by Cale, I think?
22:27:08 <shachaf> Yes.
22:27:28 <omnId> Cale: you should put double (double 5) into a wiki page to avoid carpel tunnel.
22:28:43 <shachaf> omnId: Peope don't listen unless they're being told personally, maybe.
22:29:04 <Cale> omnId: hehe
22:29:11 <omnId>  @doubledouble5, then :)
22:29:29 <geocalc> rev $ (double(double 5))
22:29:30 <shachaf>  @cale doubledouble5
22:30:40 <omnId> @brain Are you pondering what I'm pondering?
22:30:40 <lambdabot> Umm, I think so, Brain, but what if the chicken won't wear the nylons?
22:35:36 <shachaf> @v
22:35:36 <lambdabot> "\"\\\"\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\"
22:36:19 <geocalc> @?
22:36:45 <geocalc> no
22:36:52 <shachaf> @yhjulwwiefzojcbxybbruweejw
22:36:53 <lambdabot> "\"#$%&'()*+,\""
22:37:33 <omnId> @. elite protontorpedo
22:37:33 <lambdabot> I haVe A \/\/iN xp boX
22:37:47 <omnId> not very elite
22:38:15 <shachaf> @. elite brain
22:38:15 <lambdabot> |-|3RE \/\/3 4R3, PInxY--47 Th3 D4WN Oph 7i/\/\E!
22:38:30 <omnId> That took some effort :)
22:38:32 <Cale> @. elite keal
22:38:33 <lambdabot> i C4n+ 7HInk AnY/\/\ORE
22:38:38 <Cale> @. elite keal
22:38:38 <lambdabot> kea| \/\/4$ sO happY wItH +, C0d3D in 84sIC $o ruN oN 4nYt|-|IN9, ANd DOEs 10+
22:38:44 <geocalc> and not torpedo too omnId
22:39:02 <omnId> "+,"?
22:39:21 <shachaf> @. elite vixen Can you read @elite's output?
22:39:21 <lambdabot> yES
22:39:36 <omnId> wrong way through :)
22:39:48 <omnId> @. vixen elite How about now?
22:39:48 <lambdabot> how? it depends...
22:40:53 <shachaf> @elite vixen
22:40:53 <lambdabot> \/Ix3n
22:41:05 <shachaf> @. elite . vixen elite It's \/Ix3n!
22:41:05 <lambdabot> dO joo TrU$t +he g0V3RNMent?
22:41:10 <shachaf> Hmm.
22:42:51 <ac> does Haskell have primitive bitwise operators?
22:43:00 <shachaf> ac: What do you mean by primitive?
22:43:36 <omnId> there are bitwise operators, yes
22:43:36 <ac> shachaf: that they'll eventually be compiled to the bitwise machine instructions
22:43:50 <roconnor> lazy smallcheck looks totally awsome
22:44:35 <shachaf> It depends on the instances, I guess.
22:44:54 <geocalc> @. elite vixen Will You Make My Coffee Now ?
22:44:54 <lambdabot> n3VeRMINd aBoU+ +h4T
22:45:11 <geocalc> :(
22:45:30 <roconnor> but how does it manage to backtrack to the last case statement
22:46:43 <omnId> the @source of Data.Bits looks like it uses unboxed types for Int and Integer.
22:46:45 <ac> shachaf: what I'm wondering is if it'd be better to use bitwise operators (assuming they exist) on ints or boolean operations on bools
22:47:02 <ac> shachaf: (If I have large arrays of them)
22:47:41 <omnId> @docs Data.Bits
22:47:41 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Data-Bits.html
22:47:56 <omnId> They exist, and I'd presume they're pretty well optimized.
22:47:59 <EvilTerran> @docs Data.UArray
22:47:59 <lambdabot> Data.UArray not available
22:48:12 <EvilTerran> @docs Data.Array.Unboxed
22:48:12 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Data-Array-Unboxed.html
22:48:14 <roconnor> omnId: they are not well optimized.
22:48:36 <omnId> Well then I'm an ass.
22:48:44 <ac> roconnor: does that mean I'm better off with the latter?
22:48:49 <roconnor> but they exist  :)
22:48:56 <EvilTerran> I'd recommend a UArray of Bools
22:49:08 <EvilTerran> depending on what exactly you're doing
22:49:18 <ac> EvilTerran: think cellular automata
22:49:33 <EvilTerran> yeah, UArray of Bools would be perfect, imo
22:49:43 <roconnor> ac: I honestly don't know which would be better.
22:49:48 <EvilTerran> it's got the direct indexing lists of Bools would give you
22:50:17 <EvilTerran> and the good memory performance bitshuffling offers (seeing as it does the bitshuffling under the hood, as i understand it)
22:50:38 <ac> bitshuffling?
22:50:45 <ac> meaning packing bits into bytes?
22:50:47 <EvilTerran> shifts and masks and all that rubbish
22:50:51 <omnId> I seem to recall dons remarking that a UArray of Bools got reduced into bitwise operations in some shootout entry that forbade bitshuffling :)
22:51:09 <ac> hah
22:51:36 <ac> ghc scores +1
22:51:38 <roconnor> omnId: that's crazy
22:51:42 <roconnor> :)
22:52:37 <roconnor> EvilTerran: so each bool in UArray of Bools takes one bit!?
22:52:59 <EvilTerran> i think so, yeah. that or one byte, i forget ;)
22:53:13 <EvilTerran> either way, astronomically better than a bog standard array
22:54:20 <quicksilver> one bit, yes
22:54:55 <quicksilver> and omnId'd recollection is quite right, sad though it is
22:55:09 <quicksilver> cursed because our compiler is too clever...
22:55:37 <omnId> In the linked code: "Uses Word8 values to represent Bools, avoiding a bit-packing Array Bool": http://www.haskell.org/pipermail/haskell-cafe/2006-September/018164.html
22:55:39 <lambdabot> Title: [Haskell-cafe] Bit string, http://tinyurl.com/29h3sm
22:57:42 <omnId> ghc++
22:58:42 <omnId> here it is!  http://shootout.alioth.debian.org/gp4/benchmark.php?test=nsieve&lang=ghc&id=4
22:58:45 <lambdabot> Title: nsieve Haskell GHC #4 program | Gentoo : Intel&#174; Pentium&#174;&nbsp;4 Comput ..., http://tinyurl.com/32zyl4
22:58:55 <omnId> "NOT ACCEPTED:The Bool array is represented as a bit array - the same program is shown in nsieve-bits"
22:59:40 <sorear> that
22:59:45 <sorear> that's not cleverness at all
22:59:46 <zeeeee> is there a way to use splitRegex on ByteStrings?
22:59:54 <zeeeee> (or any of the text.regex functions)
23:00:08 <sorear> can you think of a more obvious way to implement an array of bools?
23:02:04 <quicksilver> zeeeee: not directly, no. It's fairly painless to 'unpack' first.
23:02:39 <goalieca> c++ packs bits in bools together. they even have a separate version of std::vector
23:02:59 <quicksilver> IMO, though sorear has now gone, the clever part is generated good code to acces the bits
23:03:04 <zeeeee> quicksilver, well, i was hoping for perf
23:03:07 <quicksilver> rather than having the idea of using bits
23:03:31 <quicksilver> zeeeee: the performance may be fine, the array may get eliminated
23:03:36 <quicksilver> zeeeee: depends what you're doing :)
23:03:43 <quicksilver> s/array/list
23:03:46 <Flynsarmy> Is there a way to create a list of 0's of infinate size? Trying to do somethign like this:
23:03:48 <Flynsarmy> print (take 1024 $ getIntegers y y ++ [0..0])
23:03:50 <Flynsarmy> where getIntegers returns a list with a length alot smaller than 1024
23:03:58 <quicksilver> Flynsarmy: [0,0..]
23:04:01 <omnId> > repeat 0
23:04:02 <lambdabot>  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0...
23:04:04 <quicksilver> > [0,0..]
23:04:06 <lambdabot>  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0...
23:04:22 <omnId> > [0..0]
23:04:23 <lambdabot>  [0]
23:04:39 <shachaf> > fix (0:)
23:04:40 <lambdabot>  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0...
23:05:12 <omnId> (foldr ($) undefined . repeat) (0:)
23:05:16 <omnId> > (foldr ($) undefined . repeat) (0:)
23:05:17 <lambdabot>  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0...
23:05:23 <omnId> :)
23:05:46 <omnId> [0..0] means "start at zero, stop at zero"
23:06:01 <omnId> [0,0..] means "start at zero, then zero, keep going"
23:06:14 <goalieca> map (\x -> x-x) [0..]
23:06:17 <goalieca> > map (\x -> x-x) [0..]
23:06:19 <lambdabot>  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0...
23:06:35 <goalieca> :-)
23:06:43 <shachaf> omnId: But... If you can make [(0:),(0:),...], then...
23:06:49 <shachaf> omnId: Never mind.
23:06:53 <omnId> shachaf: :)
23:13:22 <shubalub> oh wow, you don't even need for or while to count the number of lowercase characters in a string
23:14:36 <shubalub> that didn't take long for me to like haskell more than C++
23:15:14 <omnId> :D
23:15:30 <goalieca> watch this
23:15:35 <goalieca> > ['a'..]
23:15:36 <lambdabot>  "abcdefghijklmnopqrstuvwxyz{|}~\DEL\128\129\130\131\132\133\134\135\136\137\...
23:15:42 <dons> shubalub: :) that's cool.
23:15:44 <omnId> what's this "for" thing?
23:16:09 <goalieca> omnId, what's this "monad" thing
23:16:14 <omnId> :P
23:16:19 <omnId> warm and fuzzy
23:16:25 <goalieca> oh. like gonads
23:16:30 <omnId> exactly
23:17:24 <dons> hmm
23:18:04 <ricky_clarkson> Help, my monads have an STM.
23:18:49 <quicksilver> :t forM
23:18:50 <lambdabot> forall a (m :: * -> *) b. (Monad m) => [a] -> (a -> m b) -> m [b]
23:18:54 <quicksilver> omnId: there you are :)
23:19:14 <omnId> oh, so flip map?  What an unusual name.
23:19:26 <dons> omg our for loops have types!
23:19:37 <quicksilver> goalieca: we did have a long conversation once with a newbie who genuinely believed that they were called Gonads.
23:19:47 <dons> heh
23:19:48 <omnId> bahaha
23:19:48 <quicksilver> goalieca: and didn't know what that word means, either :)
23:20:14 <quicksilver> Actually UArray Bool is quite odd, for the following reason
23:20:30 <quicksilver> in H-M languages, parametric data types are used parametrically
23:20:33 <goalieca> haha
23:20:50 <quicksilver> so an implementation-specific to a particular type, like packing bools, is impossible
23:21:11 <dons> so you need associted types, or rewrite rules, or ..
23:21:12 <quicksilver> UArray gets around this by haaving a weak implemenation, and specialising the real content to a typeclass
23:21:23 <quicksilver> and typeclasses are ad-hoc, not parametric
23:21:35 <quicksilver> it's a strange trick
23:21:36 <goalieca> hmm this is odd look what the last number in the sequence is
23:21:39 <goalieca> > take 2 $ reverse ['A' ..]
23:21:41 <lambdabot>  "\1114111\1114110"
23:22:02 <omnId> > showHex 1114111 ""
23:22:03 <lambdabot>  "10ffff"
23:22:07 <goalieca> something unicode related?
23:22:18 <goalieca> like.. the largest number currently described
23:22:43 <Pseudonym> Yes, it's the largest Unicode code point.
23:22:46 <omnId> unicode is split into sixteen 2^16 codepoint "plains"
23:22:57 <Pseudonym> omnId: No.
23:23:04 <Pseudonym> Well... not quite.
23:23:08 <thetallguy> Anyone know what the state of QuickCheckM is?
23:23:10 <Pseudonym> And besides, it's "planes".
23:23:11 <Pseudonym> :-)
23:23:27 <thetallguy> Doesn't seem to be packaged up anywhere.
23:23:33 <omnId> what do you mean by not quite?
23:23:41 <Pseudonym> (I misread what you saw, saw I was wrong, and then fixed it with a misdirection on spelling.  Aren't I clever!)
23:23:57 <omnId> @slap Pseudonym
23:23:57 <lambdabot> Plugin `slap' failed with: IRCRaised getRandItem: empty list
23:23:59 <lambdabot> Pseudonym: You're an idiot.
23:24:04 <Pseudonym> Shut up, lambdabot.
23:24:07 <goalieca> lol
23:24:56 <lambdabot> Insecure bloody humans, honestly.
23:25:26 <quicksilver> dons: learn to control your bot, sire
23:25:35 <Pseudonym> ?seen dons
23:25:35 <lambdabot> dons is in #xmonad and #haskell. I last heard dons speak 4m 24s ago.
23:25:48 * allbery_b wonders if he should be glad he doesn't get that empty list thing, or annoyed that he gets unexplained deadlocks
23:25:52 <thetallguy> quicksilver: submit a patch
23:26:04 <quicksilver> thetallguy: too late
23:26:13 <quicksilver> thetallguy: it's sentient now, it vets its own patches
23:26:18 <Pseudonym> quicksilver: The way to control the bot there, is to reduce the number of administrators.
23:26:20 <thetallguy> lol
23:26:22 <quicksilver> won't apply anything which it doesn't like
23:26:32 <Pseudonym> dons escapes rather than hacking lambdabot!
23:26:42 <dons> i think that's the second time i've done that.
23:26:48 * allbery_b thinks he meant @quit...
23:26:49 <dons> ?quit try again
23:26:50 <allbery_b> heh
23:26:57 <dons> :)
23:27:01 <omnId> @quote
23:27:05 <lambdabot> Spark says: "oops, we proved the wrong property"
23:27:15 <lambdabot> I live.
23:27:21 <omnId> does she @flush when she @quits?
23:27:25 <dons> she does
23:27:32 <dons> very hygienic
23:27:36 <allbery_b> well, tries to
23:27:42 <lambdabot> Hey, do I ask you personal questions?
23:27:42 <allbery_b> mine seems to have issues doing so
23:27:57 * lambdabot hmphs
23:28:04 <omnId> lambdabot: You could if you wanted :3
23:28:08 <dons> lambdabot has many issues
23:28:14 <dons> she's a complicated girl
23:28:33 <lambdabot> I work on non-intuitionistic logic.
23:28:41 <dons> oh yes.
23:30:02 <Pseudonym> So, what's new in the current lambdabot instance?
23:30:51 <omnId> @index blargle new insults!
23:30:51 <lambdabot> bzzt
23:30:56 <omnId> er, oops
23:30:59 <allbery_b> heh
23:31:00 <dons> some new insults, yeah
23:31:05 <allbery_b> @src foo
23:31:05 <lambdabot> Source not found. That's something I cannot allow to happen.
23:31:05 <dons> ?src foo
23:31:05 <lambdabot> Source not found. Just what do you think you're doing Dave?
23:31:11 <dons> huh
23:31:30 <dons> jinx (after alpha renaming) on allbery_b
23:31:30 <omnId>  @index should totally insult me
23:31:42 <omnId> is there a common insult module?
23:31:50 <roconnor> @quote equality
23:31:50 <lambdabot> pkhuong says: you'll probably still want unsafeEquality or whatever, though
23:31:54 <dons> see, people love the insults
23:31:55 * allbery_b not sure he wants to risk pulling, his current crop of bugs is quite annoying enough
23:32:09 <roconnor> @quote divides
23:32:09 <dons> she's rather infested
23:32:09 <lambdabot> JamesMckinna says: We are once again left with the miserable prospect that it is equality that divides us.
23:32:18 <dons> doesn't get much love, unfortunately
23:32:29 <roconnor> oh good, she remembered
23:32:31 <dons> but she struggles on.
23:32:32 * lambdabot sulks
23:32:56 * omnId pats lambdabot on the back... er, bits
23:33:12 <lambdabot> I do have a back-end.
23:33:19 <omnId> we'll always love you <3
23:33:51 <glguy> lol... you patted lambdabot's bits
23:33:53 <glguy> that's naught
23:33:57 <glguy> y
23:34:53 <Pseudonym> I suspect that glguy is making some assumptions about bot anatomy.
23:35:44 <allbery_b> lb has some very naughty bits, but not *that* way :)
23:35:49 <Adamant> @b52s
23:35:49 <lambdabot> Hot pants explosion at the factory!
23:36:03 <olsner> @help b52s
23:36:03 <lambdabot> b52s. Anyone noticed the b52s sound a lot like zippy?
23:36:11 * allbery_b still wonders why @seen tries to list users on freenode (hardcoded) before executing online.rc
23:36:21 <olsner> @b52s
23:36:21 <lambdabot> Some say she's from Mars, or one of the seven stars that shine after 3:30 in the morning. WELL SHE ISN'T.
23:36:36 <Pseudonym> Geez, how much Haskell was there at SIGPLAN?
23:36:46 <Pseudonym> Looks like a third of the papers.
23:36:57 <omnId> @vixen glguy wants to touch your bits
23:36:58 <lambdabot> i understand
23:36:58 <Pseudonym> Oh, it's ICFP.
23:36:59 <Pseudonym> Duh.
23:37:50 <Pseudonym> Anyone read this [paper?
23:37:56 <Pseudonym> Richard A. Frost, "Realization of natural language interfaces using lazy functional programming"
23:40:30 <olsner> wow, and these are actual b-52 quotes
23:46:21 <olsner> the song hot pants explosion seems to be somewhat hard to come by
23:46:57 <swix> and yet, it's a phenomenon that has many times ruined my day.
23:47:14 <Pseudonym> I think they passed a law making them safer.
23:48:00 <Adamant> you're never safe from B-52's quotes
23:50:24 <Flynsarmy> Is there a nice quick way of removing the last 2 characters from a string?
23:50:52 <olsner> > (reverse . drop 2 . reverse) "abcdef"
23:50:53 <lambdabot>  "abcd"
23:51:43 <olsner> (it's fun there's a language where a double-reverse isn't incredibly stupid)
23:52:18 <ricky_clarkson> @hoogle [a] -> Integer -> [a]
23:52:18 <lambdabot> No matches, try a more general search
23:52:21 <omnId> take (length xs - 2)
23:52:21 <swix> > (\x -> (take ((length x) - 2) x) "abcdef"
23:52:22 <lambdabot>  Unbalanced parenthesis
23:52:36 <olsner> > (\l -> take ((length l)-2) l) "abcdef
23:52:36 <lambdabot>  Improperly terminated string
23:53:11 <swix> > (\x -> (take ((length x) - 2) x)) "abcdef"
23:53:12 <lambdabot>  "abcd"
23:53:27 <olsner> > (\x -> (take ((length x) - 2) x)) [1..10000000]
23:53:30 <lambdabot> Terminated
23:53:38 <omnId> > init (init "abcdef") -- not sure if this is too wise, but it works too
23:53:40 <lambdabot>  "abcd"
23:53:53 <olsner> > (reverse . drop 2 . reverse) [1..10000000]
23:53:57 <lambdabot> Terminated
23:54:06 <ricky_clarkson> @pl \x -> (take ((length x) - 2) x)
23:54:06 <lambdabot> take =<< subtract 2 . length
23:54:18 <omnId> > init (init [1..10^7])
23:54:23 <lambdabot>  [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,...
23:54:24 <swix> what's@pl do?
23:54:29 <omnId> @help pl
23:54:29 <lambdabot> pointless <expr>. Play with pointfree code.
23:54:39 <olsner> @type (take =<<)
23:54:40 <lambdabot> forall a. ([a] -> Int) -> [a] -> [a]
23:54:48 <omnId> gets rid of explicit lambdas by using library functions.
23:54:52 <Pseudonym> init . init is really efficient with stream fusion, I would think.
23:54:56 <omnId> @pl (\x -> f x)
23:54:57 <lambdabot> f
23:55:02 <swix> ahh
23:55:10 <omnId> @pl (\f g x -> f (g x))
23:55:10 <lambdabot> (.)
23:55:18 <omnId> @pl (\x -> f (g x))
23:55:19 <lambdabot> f . g
23:56:08 <omnId> makes it "pointless", where the points are the explicit lambda parameters.
23:56:35 <omnId> @pointy f . g
23:56:35 <lambdabot> (\ c -> f (g c))
23:57:17 <olsner> > let dropLast n = foldl1 (.) (replicate n init) in dropLast 9 [1..10]
23:57:19 <lambdabot>  [1]
23:58:01 <omnId> (.) is infixr, so maybe foldr1 would be better?
23:59:09 <olsner> hmm... maybe
