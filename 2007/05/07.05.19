00:00:07 <Weremanatee> hmm
00:00:14 <Weremanatee> yea, that's wrong I see it now.
00:00:20 <int-e> UUStudent: yes I got lucky and guessed correctly.
00:00:33 <Weremanatee> I want  map signum ...
00:00:36 <int-e> Weremanatee: that's where it gets the a -> a from:
00:00:39 <int-e> @type signum
00:00:44 <Weremanatee> gotcha.
00:00:45 <lambdabot> forall a. (Num a) => a -> a
00:01:07 <Weremanatee> alright, now I have a list of all the signums
00:01:20 <Weremanatee> now to find out if they're all equal
00:01:52 <UUStudent> thanks a lot, anyway..i've been guessing for hours, and i have all the code to look at and test :)
00:02:57 <Weremanatee> foldl1?
00:03:05 <Weremanatee> what an odd name
00:03:58 <int-e> I read the '1' as 'first' - foldl but starting with the first element of the list as the initial value
00:04:09 <Weremanatee> ah
00:04:22 <Weremanatee> not like Oracle's VARCHAR2
00:04:25 <Weremanatee> :-)
00:04:34 <int-e> no, we use ' for that ;)
00:04:37 <int-e> @index foldl'
00:04:37 <lambdabot> Data.List
00:04:42 <Weremanatee> nice
00:05:07 <int-e> (foldl' is foldl with a strict accumulator - very similar but not quite the same.)
00:06:55 <int-e> @index foldl1'
00:06:55 <lambdabot> Data.List
00:07:03 <int-e> and to top it off, this one exists as well :)
00:07:04 <dons> though not a fully strict accumulator, in the current impl.
00:07:08 <dons> > foldl' (const $ const 0) undefined [1]
00:07:10 <lambdabot>  0
00:07:24 <int-e> interesting.
00:07:26 <dons> (i.e. could be stricter, since its strict in the result of f x, not the initial accumulator)
00:07:31 <dons> ?src foldl'
00:07:32 <lambdabot> foldl' f a []     = a
00:07:32 <lambdabot> foldl' f a (x:xs) = let a' = f a x in a' `seq` foldl' f a' xs
00:07:39 <dons> rather than, f !a [] = a
00:07:40 <int-e> I never thought about that :)
00:07:49 <dons> strictness is subtle, and unspecified!
00:08:16 <int-e> but then I'm not writing a new list fusion framework
00:08:22 <dons> hehe
00:08:48 <dons> you get a proper worker from the fully strict version
00:09:07 <dons> since the lazier foldl' stlil needs to think about bottom, unfortunately
00:10:18 <UUStudent> after i've found something in a search using readSM in a do, is it possible to modify the returned result and add it as a new data record?
00:10:31 <Weremanatee> hmm
00:10:39 <Weremanatee> foldl (==) doesn't work for this
00:11:21 <duey> @do assignment, tiny parser
00:11:22 <lambdabot> assignment, tiny parser not available
00:11:29 <duey> crap
00:12:27 <dons> heh
00:13:19 <Weremanatee> @type uncurry
00:13:21 <lambdabot> forall a b c. (a -> b -> c) -> (a, b) -> c
00:15:30 <int-e> UUStudent: yes. you can do stuff like   do foo <- bar; if foo == 23 then do xyzzy else do blubb ...
00:16:06 <int-e> @undo do foo <- bar; if foo == 23 then do xyzzy else do blubb
00:16:06 <lambdabot> bar >>= \ foo -> if foo == 23 then xyzzy else blubb
00:17:22 * int-e wonders if there's a wiki page about desugaring do
00:17:54 <davidL> int-e: this is what I tried http://hpaste.org/1895#a2
00:18:52 <Weremanatee> is there a good way to find out if all elements in a list are equal?
00:18:57 <int-e> davidL: looks reasonable at first sight. does it cause problems?
00:19:03 <davidL> yeah
00:19:09 <davidL> do you want me to paste error code?
00:20:00 <int-e> davidL: yes.
00:20:02 <int-e> davidL: of course you now have adjMatrix in IO. you can change adjMatrix to take a nums argument, too and lift the IO one level higher.
00:20:25 <davidL> > f xs = all (==(head xs)) xs in f [1,1,1,1]
00:20:26 <lambdabot>  Parse error
00:20:40 <int-e> > let f xs = all (==(head xs)) xs in f [1,1,1,1]
00:20:41 <lambdabot>  True
00:20:50 <davidL> oh wow
00:21:08 <davidL> that's what happens at 02:20
00:21:13 <Weremanatee> > all (uncurry (==)) (zip [1,1,1] [1,1])
00:21:14 <lambdabot>  True
00:21:18 <Weremanatee> > all (uncurry (==)) (zip [1,1,1] [1,3])
00:21:19 <lambdabot>  False
00:21:23 <Weremanatee> sweet!
00:21:36 <int-e> > and (zipWith (==) [1,1,1] [1,3])
00:21:37 <lambdabot>  False
00:21:50 <Weremanatee> AND!
00:21:54 <Weremanatee> that's what was missing
00:22:00 <int-e> or exists, too
00:22:07 <int-e> @src and
00:22:07 <lambdabot> and   =  foldr (&&) True
00:22:11 <Weremanatee> oh, very nice
00:22:36 <davidL> ...where is hpaste
00:22:37 <UUStudent> int-e: are you saying..nested do expressions?
00:22:39 <int-e> (the counterpart for 'all' is 'any')
00:22:45 <davidL> @seen hpaste
00:22:45 <lambdabot> I saw hpaste leaving #haskell 3h 59m 15s ago, and .
00:22:59 <davidL> I annotated the paste with the error int-e
00:23:06 <Weremanatee> is there a zipWithTail function or similar in the prelude?
00:23:07 <int-e> davidL: ah. array is pure, so you need a return
00:23:38 <Weremanatee> seems like a common thing to do, zip x (tail x)
00:23:45 <Weremanatee> zipwith rather
00:23:51 <int-e> davidL: because if you want to use nums', adjMatrix must be in IO - hence adjMatrix :: IO (Array ...)
00:24:11 <sorear> davidL: He disappeared in a netsplit.
00:24:17 <sorear> glguy: ping
00:24:39 <davidL> so I should put a return statement in the lambda?
00:24:49 <int-e> davidL: adjMatrix :: [[Int]] -> Array ... is an option though, lifting the IO one level up as I already mentioned.
00:24:58 <int-e> davidL: yes. return $ array ...  instead of array ...
00:25:16 <int-e> davidL: or return (array ...)  if you dislike $.
00:25:23 <davidL> there's multiple levels of IO?
00:25:28 <int-e> UUStudent: yes, you can nest dos
00:25:52 <int-e> > do do do do do []
00:25:54 <lambdabot>  []
00:25:57 <dons> hehe
00:26:00 <dons> cute.
00:26:31 <int-e> @type do undefined
00:26:33 <lambdabot> forall (t :: * -> *) t1. t t1
00:26:40 <int-e> ouch.
00:27:06 <sorear> @type do ?_
00:27:08 <lambdabot> forall (t :: * -> *) t1. (?_::t t1) => t t1
00:27:10 <int-e> I expected Monad t => t a
00:27:45 <davidL> wtf... Expected kind `?', but `Array' has kind `* -> * -> *'
00:28:11 <sorear> davidL: You can't put Array on the left of a function arrow.
00:28:19 <sorear> Array (Int,Int) Int  yes
00:28:47 <sorear> Probable cause: you didn't give Array enough arguments
00:28:55 * sorear can't figure out what
00:29:06 <sorear> is so obscure about that error
00:29:35 <davidL> forgot the last int, but of course, the infamous [[Int]] does not match IO [[Int]] comes back to haunt me
00:29:40 <int-e> davidL: I gave incomplete type signatures.
00:29:49 <davidL> 0.o
00:30:09 <sorear> it seems like every three days some newbie comes in with a type signature like Array -> a  and refuses to believe ghc's diagnostic
00:30:22 <davidL> adjMatrix :: [[Int]] -> Array (Int, Int) Int
00:30:43 <sorear> davidL: if you ever figure out what made you say "wtf..." be sure and let the Simons know - it will help a lot of newbies
00:31:01 <int-e> sorear: kinds.
00:31:41 <sorear> int-e: I still don't get why people won't beleive the (invariably correct in this case) probable cause
00:31:57 <fuzan> i've done a lot of haskell to date, and i've still never used an array.
00:32:36 <davidL> sorear: sorry, I hadn't read the first line of the diagnostic output
00:33:01 <int-e> davidL: if you want to implement [[Int]] -> Array (Int, Int) Int, the return  will have to go away again.
00:33:06 <sorear> davidL: So you think the output needs to be permuted?
00:34:59 <davidL> sorear: no
00:37:40 <sorear> davidL: what would have helped you?
00:38:16 <davidL> sorear: surely you have made a mistake before, no?
00:38:53 <sorear> davidL: Yes, but your mistake is amazingly common
00:39:36 <davidL> sorear: is there anything I can do about that?
00:40:09 <ivanm> hi everyone
00:40:56 <int-e> sorear: hrm. maybe be redundant and add a "likely fix: add missing arguments to Array type constructor." to the message.
00:41:17 <ivanm> if I have a list of values vs, and a list of indices ins (with ins being sorted in increasing order, no dups), is there a better way of getting the components from vs with indices in ins without using map (vs !!) ins ?
00:42:09 <int-e> sorear: swapping might help - often the really useful output in the error comes after the 'big and scary line with lots of arrows in it'.
00:42:11 <davidL> it already says that plain and clear: "`Array (Int, Int)' is not applied to enough type arguments" -- my eyes immediatley jumped to the stars and it is 3 in the morning :(
00:44:58 <Mephisto> is there a function that does type checking? like .. return False on   'a' :: Bool  instead of error
00:46:23 <wilx> How would that be possible in static typing system like Haskell's?
00:46:52 <davidL> int-e: nums' >>= (\nums -> array ...) -- this stays in place when I use what is called higher level IO?
00:47:04 <int-e> Mephisto: what do you want to use it for?
00:47:28 <wilx> I mean, you are not supposed to have that kind of problems since your programmes have to typecheck to be compiled.
00:47:46 <dons> Mephisto: very unusual code, Mephisto, since types are erased statically, and aren't available at runtime for you to write code for.
00:48:11 <dons> the only way would be to reflect a type into data, and keep that data around at runtime.
00:48:12 <Mephisto> it's not for use in a program
00:48:24 <Mephisto> i just wonder if there is one
00:48:24 <dons> :t fromDynamic
00:48:33 <lambdabot> forall a. (Typeable a) => Dynamic -> Maybe a
00:48:52 <dons> > fromDynamic (toDyn 'a') :: Just Bool
00:48:53 <lambdabot>   Not in scope: type constructor or class `Just'
00:48:55 <ivanm> @pl map (vs !!) ins
00:48:56 <lambdabot> map (vs !!) ins
00:48:59 <dons> > fromDynamic (toDyn 'a') :: Maybe Bool
00:49:00 <lambdabot>  Nothing
00:49:04 <dons> there :-)
00:49:08 <dons> > fromDynamic (toDyn 'a') :: Maybe Char
00:49:09 <lambdabot>  Just 'a'
00:49:10 <int-e> davidL: I added an annotation
00:49:37 <int-e> davidL: hum, and I reused the foo identifier, that's a different foo from yours :)
00:49:46 <dons> > let isBool x = case fromDynamic (toDyn x)  of Nothing -> False ; _ -> True  in   isBool 'x'
00:49:47 <lambdabot>  Add a type signature
00:49:58 <dons> > let isBool x = case fromDynamic (toDyn x)  of Nothing -> False ; Just (_ :: Bool) -> True  in   isBool 'x'
00:49:59 <lambdabot>  Parse error in pattern
00:50:15 <dons> > let isBool x = case fromDynamic (toDyn x) :: Maybe Bool of Nothing -> False ; Just _ -> True  in   isBool 'x'
00:50:17 <lambdabot>  False
00:50:21 <dons> > let isBool x = case fromDynamic (toDyn x) :: Maybe Bool of Nothing -> False ; Just _ -> True  in   isBool False
00:50:23 <lambdabot>  True
00:50:37 <dons> toDyn reflects a type into data, so its kept around till runtime.
00:50:53 <sorear> maybe ghc should check modtimes and Probable cause: program was written after midnight
00:50:54 <dons> fromDynamic inspects this type-as-value, against its expected type, using a bit of magic.
00:51:10 <Mephisto> hm .. alright
00:51:17 <dons> > toDyn 'x'
00:51:19 <lambdabot>  <<Char>>
00:51:28 <dons> ?docs Data.Dynamic
00:51:28 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Data-Dynamic.html
00:51:30 <davidL> thanks int-e
00:51:42 <dons> standard way to do dynamic typing, delay type checking to runtime, check tags on the fly, at runtime.
00:51:51 <dons> easy to add to a polymorphic, statically typed lang.
00:52:05 <dons> with all the runtime type errors you could ever want :-)
00:53:06 <dons> > dynApp (toDyn (+ 1))  (toDyn 'x')
00:53:07 <lambdabot>  Exception: Type error in dynamic application.
00:53:07 <lambdabot> Can't apply function <<Integer...
00:53:18 <dons> yay for runtime type errors!
00:53:33 <dons> :t fromDynamic ( dynApp (toDyn (+ 1))  (toDyn 'x') ) :: Maybe Int
00:53:35 <lambdabot> Maybe Int :: Maybe Int
00:53:39 <dons> so it type checks.
00:53:50 <dons> but we did the agile, dynamic thing, and didn't actuall ytype check the code.
00:53:56 <dons> better write some unit tests to check that code path
00:54:13 <dons> > fromDynamic ( dynApp (toDyn (+ 1))  (toDyn 'x') ) :: Maybe Int
00:54:15 <lambdabot>  Exception: Type error in dynamic application.
00:54:15 <lambdabot> Can't apply function <<Integer...
00:54:46 <int-e> > fromDynamic ( dynApp (toDyn (+ 1))  (toDyn 1) ) :: Maybe Int -- polymorphism hurts?
00:54:47 <lambdabot>  Nothing
00:54:50 <dons> and thus we see that dynamic typing is just a special case of static typing , where you wrap all values in a universal representation, and insert 'case' statements at each evaluatoin step at runtime, to check types .
00:55:09 <dons> int-e: here, yes. I think you need Int tags
00:55:12 <int-e> > fromDynamic ( dynApp (toDyn (+ (1 :: Int)))  (toDyn (1 :: Int)) ) :: Maybe Int
00:55:13 <lambdabot>  Just 2
00:55:38 <dons> to unify polymorphic values dynamically needs more sophisticated dynamics.
00:55:47 <davidL> is there a limit on the size of an array?
00:55:52 <dons> memory.
00:56:06 <int-e> > fromDynamic ( dynApp (toDyn (+ 1))  (toDyn 1) ) :: Maybe Integer -- err, Integer is the default.
00:56:08 <lambdabot>  Just 2
00:56:10 <davidL> would that explain: Exception: Prelude.(!!): index too large
00:56:31 <Heffalump> an index that was too large, perhaps? :-)
00:56:33 <dons> int-e: ah yes, we use extended defaulting in lambdabot too. i wonder what happened there.
00:56:34 <Heffalump> @type (!!)
00:56:35 <int-e> davidL: !! works on lists
00:56:36 <lambdabot> forall a. [a] -> Int -> a
00:56:44 <dons> davidL: yeah, [a] is a list, not an array
00:56:48 <Heffalump> so either your [a] was too short, or your Int was too large
00:57:02 <Heffalump> oh, "would that explain", not "what would explain", sorry.
00:57:03 <int-e> davidL: so it says you're trying to access an element past the end of a list
00:57:31 <int-e> davidL: note that list indices are zero based
00:57:34 <davidL> ah I see my mistake
00:57:41 <davidL> thanks
00:58:30 <dons> all this dynamic typing stuff just enforces the point that interpreters are too easy to write. hence we have ruby.
00:59:18 <dons> its so much easier to write an AST evaluator that checks types at each reduction, than to write a type checker.
01:01:04 <sorear> I think writing type checkers is easier.
01:01:25 <sorear> With type checkers, you get to check all the types ONCE, with a simple  (+) :: Int -> Int -> Int
01:01:26 <jyp> dons: So you explain the "dynamic typing is better" point of view as a failure (or lack of motivation) to understand the subtleties of type inferencers.
01:01:43 <sorear> the runtime tagging code needed for dynamics gets *very* tedious to write
01:02:24 <dons> people playing around with designing their own language hack up interpreters, interpreters that check types dynamically are the easiest to write, hence perl, python, ruby , um, erlang, all start out like that.
01:02:39 <dons> i.e. languages that start as a private hack, tend to be dynamic checking interpreters
01:02:41 <johnnowak> dons: smalltalk too?
01:02:49 <johnnowak> and self?
01:02:51 <fuzan> what's the difference between writeTChan and ungetTChan?
01:02:52 <dons> smalltalk is a different case, from what I understand.
01:03:01 <fuzan> :t unGetTChan
01:03:03 <lambdabot> Not in scope: `unGetTChan'
01:03:06 <fuzan> :t writeTChan
01:03:08 <lambdabot> Not in scope: `writeTChan'
01:03:11 <fuzan> ;(
01:03:13 <johnnowak> dons: how much have you used smalltalk?
01:03:20 <dons> very little. only read articles.
01:03:20 <skew> sorear: you could try to infer some of the tagging code with type classes
01:03:53 <johnnowak> dons: would explain some things then. :)
01:04:04 <dons> but i do think the fact that "interpreters that check as they reduce are easy" explains why scripting langs are dyn typed.
01:04:27 <dons> scripting languages, i should constrain my remarks to.
01:04:49 <dons> not to say, fully dynamic systems designed to be made of dynamically bound replacable components.
01:04:50 <johnnowak> seems like an artificial distinction
01:05:58 <dons> languages that start as small dsls for doing say, text munging, that get scaled up to full languages.
01:07:00 <int-e> dons: then add reflection capabilities to the picture and the inevitable hacks that follow "oh this method doesn't exist. ask the object if it wants to do anything before we actually throw an error."
01:07:02 <johnnowak> what about dsls for list and string processing?
01:07:27 <dons> yeah, if you've only got 1 or 2 types in mind, when you start, you don't bother checking at all.
01:07:33 <int-e> dons: and suddenly dynamic typing becomes a necessity.
01:07:43 <dons> yeah.
01:08:48 <fuzan> does writeTChan append to the end of the list, while unGet pushes onto the head?
01:09:39 <dons> and also, very few free lance people can write type sytems. while, eval (Plus e1 e2) | Int v1 <- eval e1, Int v2 <- eval e2 -> Int (v1 + v2) | otherwise = Int (-1) -- is just too easy to write...
01:09:41 <sorear> yeah
01:10:09 <skew> or design type systems in the first place
01:10:19 <dons> and then you say, oh, why don't we allow strings, then Int v1 + String v2 could be, oh, Int v1 + (read v2)
01:10:22 <dons> and you've got perl.
01:10:46 <int-e> or php
01:10:47 <fuzan> dons: but that's a feature! haha
01:10:50 <dons> an ad hoc set of coercions develop over time, as you find new things you want to write. and so it goes.
01:11:25 <int-e> (php seems to be quite notorious for hiding errors)
01:11:30 <skew> and if you don't do much design, why not just embed a DSL
01:11:36 <dons> yeah, php is sort of the degenerate case.
01:11:49 <dons> let a non-language person try to write the 'eval' functoin, and you get php.
01:12:32 <dons> now, if we taught type systems in uni, maybe it would be different.
01:12:46 <johnnowak> perhaps dynamic languages have a bad reputation in some circles due to the lower barrier of entry for implementations
01:13:43 <Korollary> Dynamic languages don't really have a bad rep, except for performance in general.
01:13:48 <dons> but hindley-milner isn't even widely taught. so , oh well.
01:13:48 <dons> i think the lower barrier explains the large number of them, and why they sometimes  become ad hoc feature balls.
01:13:48 <dons> that's basicaly my thesis on this matter :-)
01:13:50 <dons> there's a separate category for language designed to be dynamic though.
01:14:15 <int-e> . o O ( And C++ is commonly regarded as strongly typed. )
01:14:17 <johnnowak> Korollary: high-level languages in general have that reputation
01:14:33 <dons> javascript is another example. commerical pressure to get a scripting system done in 2 weeks leads to the simplest things you could write.
01:14:39 <skew> johnnowak: there's Java, and then there's Ruby
01:14:41 <fuzan> hmm; tchan's don't seem to be very elegant when you need to search through them.
01:15:16 <dons> its lucky we have the open source type systems we do :-)
01:15:23 * dons takes off hat to the Haskell committee.
01:15:24 <johnnowak> skew: and then there's Self, a dynamic language who's implementation paved the way for Java
01:16:33 <dons> int-e: yeah, once you've got your types as values at runtime, in an interpreter, reflectoin becomes terribly tempting, and then eval functoins, and then arbitrary self-modifying code :-)
01:17:02 <johnnowak> there's a lot of value in arbitrary self-modifying code :)
01:17:05 <integral> hmm, type-safe self modifying code
01:17:09 <dons> very powerful.
01:17:36 <dons> hey, did people see the asm generator lib for haskell that came out this week?
01:17:44 <Korollary> yes
01:17:54 <dons> writes opcodes into memory using a nice dsl, executes them. holy crap ensues.
01:18:06 <dons> i mean, cool runtime specialisation games :-)
01:18:17 <sorear> but it's not typesafe!
01:18:23 <Korollary> it's holy crap
01:18:27 <dons> makes hs-plugins look angelic ;-)
01:18:35 <skew> better name it "unsafeRunBytes"
01:18:47 <dons> super-super-super unsafe.
01:19:03 <Korollary> game programmers love that stuff
01:19:05 <dons> > 1 + 2 -- at least this runtime codegen gets a type check on the splice point.
01:19:07 <lambdabot>  3
01:19:08 <Korollary> at least, they used to.
01:19:24 <dons> hsakell is such a fun dynamic system.
01:19:26 <dons> mwhaha
01:19:31 <Korollary> GHC is
01:19:44 <dons> yhc too, i suspect. bytecodes yaya.
01:19:50 <johnnowak> er.. what's fun about needing things like hs-plugins? :)
01:19:53 <int-e> dons: imagine Haskell would only provide GHCs primops and no libraries around them.
01:20:06 <skew> I extracted some code with Coq the other day, and for the first time felt completely justified that I'd discharged my proof obligation on unsafeCoerce#
01:20:24 <dons> johnnowak: well, retrofitting dyn eval onto native code compilers is always going to be a bit odd.
01:20:42 <dons> much more sensible to add dyn eval to a bytecode interpreter. oh, like yi/ghci/yhc :-)
01:21:04 <johnnowak> dons: i understand the need, i'm just saying it's more a substitute for not being able to easily evaluate arbitrary code at runtime than "fun" in my book
01:21:15 <sorear> there is something very deeply unsatisfying about ghc's use of names to identify types
01:21:17 <skew> does hs-plugins acutally take advantage of bytecode?
01:21:22 <johnnowak> maybe my book is cranky today
01:21:30 <sorear> it works (barely) for ghc
01:21:32 <dons> right, retrofitting eval onto native code batch compilers isn't fun.
01:21:42 <dons> skew: well, yi is now using ghc-api
01:21:49 <johnnowak> we don't need no stinking compilers
01:21:55 <sorear> but with hs-plugins... multiple modules can share a name
01:21:57 <skew> it sounds like there's a bit of work to get bytecode and native code playing nicely in e.g. ghci
01:21:59 <dons> it all just runs as a (mostly statically typed) dynamic app sitting on a bytecode interepreter
01:22:15 <dons> the key thing is that 99% of an application's code is known statically, and can be fully statically typed.
01:22:27 <int-e> johnnowak: no, you're wrong, we need better compiler to do number crunching faster ;)
01:22:37 <dons> your dyn components can be statically checked in isolatoin as well. its just the splice points that need true dynamic checks.
01:23:03 <fuzan> @src liftIO
01:23:03 <lambdabot> Source not found. I feel much better now.
01:23:04 <johnnowak> int-e: well i suppose you don't need dynamic behaviour for number crunching anyway :)
01:23:13 <int-e> [For number crunching, I keep prototyping in Haskell and rewriting stuff in C for speed.]
01:23:33 <int-e> johnnowak: yes.
01:23:49 <dons> int-e: or write a haskell program that generates C on the fly, links it back in, and runs that....
01:23:52 <skew> oh, compilers you need. batch compiling, maybe not
01:24:00 <dons> works really nicely for number crunching.
01:24:05 <int-e> dons: too scary.
01:24:10 <int-e> :)
01:24:21 <dons> hey, read the monte carlo spec paper?
01:24:29 <int-e> no.
01:24:30 <dons> at least generating C into buffers dynamically gets FFI checking on it.
01:24:34 <skew> int-e: beats generating C by smashing strings together
01:24:36 <dons> unlike generating asm on the fly.
01:24:41 <sorear> dons: how do you keep different types with the same name from mixing, in the presence of stale .hi files and similar nicities?
01:24:52 <dons> sorear: in hs-plugins?
01:24:56 <sorear> yeah
01:24:58 <dons> sorear: fully qualified names.
01:25:14 <sorear> dons: Are fully qualified names REALLY unique?
01:25:24 <dons> dynamically constructed module names, are, yes.
01:25:33 <sorear> dons: what if I compile two Foo modules in different directories?
01:25:34 <int-e> sorear: now that they contain the package name - pretty much
01:26:02 <int-e> sorear: if you try to break it you can break it, of course.
01:26:18 <dons> yes, you can just edit the .o files and ensure names will clash
01:26:24 <dons> its not PCC.
01:26:26 <Heffalump> why do they contain the package name, btw?
01:26:39 <Heffalump> I thought the point of the hierarchical libraries was to provide that separation
01:26:46 <sorear> take any real dynamic language and try to crash it without bugs or unsafe operations - you can't
01:26:52 <fuzan> how can I use a monad other than IO in my own Monad ?
01:26:58 <dons> so we can have module F in two separate packages, without developers having to agree.
01:27:01 <int-e> Heffalump: to allow one package to depend on foo-1.0 and another to depend on foo-1.5 and use them both
01:27:19 <johnnowak> sorear: i can seg fault perl fairly fast :)
01:27:19 <sorear> i don't want a haskell dynamism lib where I have to ensure my fully qualified names are unique
01:27:22 <Heffalump> dons: well, they just have to agree to avoid the same package names instead
01:27:39 <dons> sorear: hehe. the point is that allowing arbitrary access to memory will crash any system.
01:27:41 <sorear> johnnowak: take any real dynamic language and try to crash it *without bugs* or unsafe operations - you can't
01:27:53 <dons> so if you had access to the bytecodes of a perl program, you can break that too.
01:27:56 <sorear> dons: that requires unsafe operations, which I disallowed
01:28:03 <johnnowak> sorear: er. well yes.
01:28:46 <sorear> dons: can you crash perl just by loading two modules with different contents and the same fully qualified names?
01:28:48 <int-e> Heffalump: and requiring that a package author renames his modules for incompatible changes seems too much to me.
01:29:19 * sorear is too tired to actually try and crash anything right now.
01:29:35 <dons> sorear: i'm not sure what the point is, they're really the same model. symbols bound dynamically.
01:29:44 <dons> and dynamic binding is scary anyway ;-)
01:30:01 <dons> ?time sorear
01:30:02 <lambdabot> Local time for sorear is Sat May 19 01:28:56 2007
01:30:14 <sorear> dons: i'm afraid of putting responsibility on the programmer
01:30:27 <dons> you don't. its on the 'eval' function.
01:30:33 <sorear> with perl, a dynamic binding mixup at worst gives you a dynamic type error
01:30:44 <fuzan> is there any way of lifting into your monad other monads that aren't specified in the type?
01:30:46 <sorear> with haskell, what can I get with dynamic binding mixups?
01:30:52 <Heffalump> int-e: that sounds reasonable
01:31:05 <dons> a type error. (maybe the runtiem refusing to load a module twice, leading to a Nothing)
01:31:20 <dons> :t System.Eval.Haskell.eval
01:31:23 <Heffalump> the idea of including the version number is a more convincing justification than the idea of including the name, though you might as well do both
01:31:28 <lambdabot> forall a. (Typeable a) => String -> [System.Eval.Utils.Import] -> IO (Maybe a)
01:31:33 <sorear> dons: Oh, so the RTS enforces the uniqueness of loaded fully qualified module names?
01:31:37 <dons> yeah.
01:31:50 * sorear breathes a sigh of relief
01:31:53 <dons> it'll fail with a particular message, mapped to Nothing.
01:32:04 <ivanm> @hoogle random
01:32:05 <lambdabot> Random.random :: (Random a, RandomGen b) => b -> (a, b)
01:32:05 <lambdabot> System.Random.random :: (Random a, RandomGen g) => g -> (a, g)
01:32:05 <lambdabot> Random :: module
01:32:06 <dons> that IO (Maybe a) is kind of the point ;-)
01:32:21 <dons> Maybe a, the dynamic typing operation :-)
01:32:22 <ivanm> > random 5
01:32:23 <lambdabot>  Add a type signature
01:32:27 <ivanm> > random 5 :: Int
01:32:28 <lambdabot>  Couldn't match expected type `Int' against inferred type `(a, t)'
01:32:33 <ivanm> > random (5 :: Int)
01:32:35 <lambdabot>   add an instance declaration for (RandomGen Int)
01:32:35 <lambdabot>     In the expression: rand...
01:32:37 <sorear> dons: Inadequately documented.  I thought the Maybe was only for object file format errors
01:32:41 <dons> :t ($)
01:32:44 <lambdabot> forall a b. (a -> b) -> a -> b
01:32:52 <dons> sorear: the Typeable hints that it does a type check ,surely..
01:33:09 <ivanm> > random $ (5 :: Int)
01:33:10 <lambdabot>   add an instance declaration for (RandomGen Int)
01:33:10 <sorear> dons: ISTR a two level error type, one level for type errors and one for non-type errors.  I'm talking the latter
01:33:23 <ivanm> @doc Random
01:33:23 <lambdabot> Random not available
01:33:31 <dons> right, the latter become Nothings too. that's mentioned somehwere.
01:33:35 <ivanm> @doc System.Random
01:33:35 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/System-Random.html
01:33:46 <dons> > x y z   -- random non-typecheck failure
01:33:47 <lambdabot>   Not in scope: `z'
01:34:03 <dons> that' didn't fail due to Typeable.
01:36:09 <ivanm> How can I generate random numbers?
01:36:21 <sorear> System.Random
01:36:24 <ivanm> not quite sure what the input to random is meant to be :s
01:36:30 <sorear> a seed
01:36:40 <sorear> it gives you back a random value, and a new seed
01:36:59 <sorear> you remember how prngs work?
01:37:03 <ivanm> well, I tried above to use it, and it kept complaining about types
01:37:09 <ivanm> sorear: prngs? what's that?
01:37:23 <sorear> pseudo random number generator s
01:37:31 <sorear> > random (mkStdGen 42)
01:37:33 <lambdabot>  (-1673289139,128694412 1655838864)
01:37:38 <sorear> > randoms (mkStdGen 42)
01:37:40 <lambdabot>  [-1673289139,1483475230,-825569446,1208552612,104188140,84572631,-1284852847...
01:37:50 <sorear> > randoms (mkStdGen 42)
01:37:51 <lambdabot>  [-1673289139,1483475230,-825569446,1208552612,104188140,84572631,-1284852847...
01:37:52 <sorear> > randoms (mkStdGen 42)
01:37:53 <lambdabot>  [-1673289139,1483475230,-825569446,1208552612,104188140,84572631,-1284852847...
01:37:58 <sorear> same seed, same numbers.
01:38:00 <sorear> purity!
01:38:20 <ivanm> ahhh, you can't just pass in an int or something...
01:38:31 <norpan> 42 is an int
01:38:46 <sorear> no, we use stronger types :)
01:38:50 <ivanm> I meant as in the "mkStdGen" function applied to 42
01:38:58 <ivanm> thanks sorear++ !
01:39:11 <sorear> yw.
01:39:14 <ivanm> now, is there an easy way to use this to find a random permutation of a (finite) list?
01:39:16 <fuzan> type MBot a = ReaderT BotThread (ErrorT String (WriterT [String] IO)) a ;;; I have this monad, yet I can't seem how to also work with STM within it. i'm failing with fmap, lift, etc.
01:39:28 <ivanm> other than generating all permutations then randomly choosing one?
01:40:03 <sorear> sure.  the finite shuffling algorithm will work (O(n^2) though...)
01:40:24 <sorear> > S.fromList
01:40:25 <lambdabot>   Not in scope: `S.fromList'
01:40:31 <sorear> > Data.Sequence.fromList
01:40:32 <lambdabot>  Add a type signature
01:40:48 <ivanm> @google "finite shuffling algorithm"
01:40:49 <lambdabot> No Result Found.
01:40:56 <ivanm> @google finite shuffling algorithm
01:40:58 <lambdabot> http://www.perlmonks.org/?node_id=444397
01:40:58 <lambdabot> Title: Re^4: Functional shuffle
01:41:01 <johnnowak> a random permutation should be O(n), no?
01:41:17 <sorear> johnnowak: Easily, but the only algorithm I remember uses arrays!
01:41:51 <johnnowak> given 10 items, make a list 0 to 9, randomly pick and remove values from that list, and use them map the first 10 items onto a new array
01:41:52 <Heffalump> fuzan: how are you trying to use STM?
01:41:56 <ivanm> well, its only for small lists, and only called once (well, three times probably)
01:42:12 <sorear> johnnowak: remove is O(n)
01:42:42 <johnnowak> sorear: ?
01:42:47 <ivanm> and now for something completely different ;-)
01:42:53 <fuzan> Heffalump: using (<- readTChan) within a funtion of type :: foo -> MBot foo2
01:43:05 <ivanm> how about randomly choosing an element from a list, without knowing the size of the list or what elements are in there?
01:43:10 <johnnowak> sorear: remove is O(1), no?
01:43:20 <ivanm> i.e. f [1..] will randomly choose any integer > 0
01:43:20 <Heffalump> fuzan: but that's of STM type, not MBot type
01:43:50 <int-e> sorear: you can use a divide-and-merge approach: split a list into two, shuffle each; then combine them: if the lists have length a and b, then pick the first element of the first list with probability a/(a+b) and otherwise pick it from the second list.
01:44:08 <fuzan> Heffalump: yup. my question is how I use STM within MBot
01:44:10 <int-e> sorear: data.sequence is probably an easier way to get O(n log(n)) performance though.
01:44:18 <fuzan> Heffalump: for IO, i use liftIO, etc.
01:44:27 <fuzan> Heffalump: I can't seem to use lift, or fmap
01:44:42 <ivanm> int-e: but how do you choose which elements are in which list? a 0.5 prob of going to either list, randomly chosen?
01:44:42 <Heffalump> fuzan: why would they work? STM isn't in your monad stack
01:44:53 <Heffalump> you'll need to use the STM -> IO conversion functions explicitly
01:45:01 <fuzan> Heffalump: I also asked how would I add it to the monad stack
01:45:15 <Heffalump> oh, right. You can't, cos it's not a monad transformer.
01:45:18 <Heffalump> Hence my solution.
01:45:28 <mux> @type atomically
01:45:29 <int-e> ivanm: just do that deterministically
01:45:30 <lambdabot> Not in scope: `atomically'
01:45:31 <fuzan> Heffalump: but I can't find any stm->io either :(
01:45:38 <fuzan> only io->stm
01:45:40 <fuzan> :t unsafe
01:45:42 <lambdabot> Not in scope: `unsafe'
01:45:43 <mux> @hoogle atomically
01:45:44 <lambdabot> GHC.Conc.atomically :: STM a -> IO a
01:45:45 <Heffalump> IO -> STM sounds unsafe
01:45:46 <fuzan> @hoogle unsafe
01:45:47 <lambdabot> Language.Haskell.TH.unsafe :: Safety
01:45:47 <lambdabot> System.IO.Unsafe :: module
01:45:47 <lambdabot> Language.Haskell.TH.Unsafe :: Safety
01:45:49 <Heffalump> but yes, atomically
01:45:50 <fuzan> oh, wow
01:45:53 <ivanm> int-e: how? I'm trying to create a random permutation, so how do you split them deterministically?
01:46:08 <int-e> ivanm: the shuffling happens when the lists are combined again.
01:46:10 <fuzan> mux ftw
01:46:18 <ivanm> int-e: ahhh.....
01:46:21 <fuzan> @src atomically
01:46:21 <lambdabot> Source not found. And you call yourself a Rocket Scientist!
01:46:24 <mux> heh
01:46:27 <norpan> since you need to keep the list in memory anyway, why don't you use an intermediate array?
01:46:46 <ivanm> so you divide and conqueor, a bit like in merge-sort (I think that's the right one), with the conquer step randomly choosing how to interleave them?
01:46:56 <Heffalump> on a related note, there is no function of this type, is there? (MonadTrans t, Monad m1, Monad m2) => (m1 a -> m2 a) -> t m1 a -> t m2 a
01:47:13 <int-e> ivanm: yep
01:47:16 <norpan> the problem with divide and conquer for permutating is that you want each permutation to be equally likely
01:47:39 <ivanm> so to split them, break in two recursively or something?
01:47:47 <int-e> norpan: that's why I didn't use 50:50 chances
01:47:50 <norpan> which may be possible, but hard to check
01:49:07 <norpan> a/(a+b) might do it but you need to prove it :)
01:49:18 <ivanm> norpan: so you're saying to convert the list to an array, and then do what?
01:49:19 <johnnowak_> ivanm: http://pastie.caboo.se/62870
01:49:20 <lambdabot> Title: #62870 - Pastie
01:49:22 <int-e> > let split [] = ([],[]); split (x:xs) = let (as,bs) = split xs in (x:bs, as) in split [1,2,3]
01:49:23 <lambdabot>  ([1,3],[2])
01:50:04 <ivanm> johnnowak_: ahhh!!! C!!!!!
01:50:08 * ivanm gibbers in terror
01:50:10 <ivanm> :p
01:50:41 * ivanm is guessing that it's C, as he only did a little C a couple of years ago
01:50:45 <matthew-_> @seen DRMacIver
01:50:45 <lambdabot> DRMacIver is in #haskell-blah and #haskell. I last heard DRMacIver speak 13h 51m 50s ago.
01:50:49 <johnnowak_> it's not C, it's nothing
01:51:04 <norpan> ivanm: then permutate the array destructively :)
01:51:25 <ivanm> norpan: random swaps going through the array?
01:51:25 <johnnowak_> aye :)
01:51:46 <ivanm> johnnowak_: there's a reason I'm in #haskell and not #C (assuming the latter exists) :p
01:51:57 <norpan> ivanm: yeah, the standard imperative permutation algorithm :)
01:52:05 <norpan> but that's not a pure solution
01:54:56 <int-e> norpan: actually the algorithm is easier to understand in reverse: to pick a random subset of size n from m elements, pick the first element with probability n/m, then continue with the remaining elements (adjusting n and m as necessary).
01:56:08 <int-e> norpan: and then you can shuffle the two subsets, and then combine them in any deterministic way. this is exactly the opposite direction of what I did.
01:56:29 <int-e> norpan: now if you run a perfect shuffling algorithm in reverse you get a perfect shuffling algorithm.
01:56:33 <norpan> yeah, do you store the lengths or does calculating them each time not increase the complexity
01:56:57 <int-e> norpan: I was planning to store them.
01:57:26 <int-e> norpan: or at least only compute them once per merge - so mergining is O(n+m) with n and m being the list lengths.
01:59:34 <DRMacIver> Morning
01:59:37 <DRMacIver> matthew-_: ?
01:59:47 <matthew-_> DRMacIver: hang ok ;-)
01:59:51 <matthew-_> err, on
02:00:08 <matthew-_> int-e: you know the other day, when we were talking about that issue with fundeps? class F a b | a -> b and then data G :: * -> * where GC :: (F a b) => b -> F a ?
02:00:21 <DRMacIver> matthew-_: ok :)
02:00:30 <int-e> matthew-_: yes
02:00:30 * ivanm thinks he likes int-e's solution better atm
02:00:59 <johnnowak2> i think my irc client exploded for recommending mutation
02:01:01 <int-e> matthew-_: http://hpaste.org/1898 is an example of the scenario I thought of
02:01:11 <matthew-_> int-e: were you suggesting that my function foo :: (F a b) => G a -> b wouldn't work unless the class was closed?
02:01:37 <int-e> matthew-_: the topic came up again earlier today
02:02:30 <matthew-_> int-e: ahh. right, that finally makes sense in my head
02:02:45 <matthew-_> int-e: it's almost like dimond multiple inheritence problem in C++
02:03:00 <matthew-_> err, diamond. Sheesh my spelling's poor this morning
02:03:37 <matthew-_> int-e: I presume that ghc doesn't treat the class differently if it's exported or not?
02:03:56 <int-e> matthew-_: as far as I know it doesn't.
02:04:46 <int-e> matthew-_: it only checks consistency of fundeps when you try to use a class dictionary - defining d :: Bar Int; d = Bar 2  in Main would result in an error.
02:04:57 <skew> with Data.Generics, ext1T is supposed to use the second argument whenever the types match, right?
02:04:59 <int-e> matthew-_: (instances are always exported I think)
02:05:22 <mux> is Data.Foldable being considered for Haskell' ?
02:05:32 <matthew-_> right. Yeah, I really need closed classes then.
02:06:18 <skew> I've got swap a b = gmapT (swap a b) `extT` swapVar a b `ext1T` swapBind a b
02:06:25 <johnnowak> ...
02:06:28 <skew> where swapBind "x" "a" ("x" ://
02:06:33 <int-e> matthew-_: or associated types (which hopefully solve that problem, too)
02:06:37 <skew> where swapBind "x" "a" ("x" :// "x") --> "b" :// "b"
02:06:53 <skew> where swapVar "x" "a" "x" --> "a"
02:07:01 <duey> what does +++ do in do commands?
02:07:06 <skew> and swap "x" "a" ("x" ://
02:07:07 <xwl> Hi, anybody use ghc6 in debian? when i try to use `runhasell', it just complains "ghc-6.6: not built for interactive use". what's this? i've to recompile it myself?
02:07:10 <int-e> @type (+++)
02:07:14 <lambdabot> forall (a :: * -> * -> *) b c b' c'. (ArrowChoice a) => a b c -> a b' c' -> a (Either b b') (Either c c')
02:07:14 <skew> and swap "x" "a" ("x" :// "x") --> "a" :// "a"
02:07:34 <duey> confusing
02:07:45 <int-e> duey: it has nothing to do with do
02:10:46 <mux> @src applyM
02:10:46 <lambdabot> Source not found. Do you think like you type?
02:24:18 * araujo needs to write a small paper for univ
02:24:24 <araujo> any topic recommendation?
02:30:33 <duey> araujo: poor haskell teaching practices and how more interesting more relevent assignments would improve the popularity of the lanugage</rant>
02:30:43 <ivanm> araujo: a comment on the meaningless of discussions in online chat media? :p
02:31:59 * araujo takes notes
02:38:55 <dons> duey: you haven't had fun haskell assignments?
02:39:10 <duey> no
02:39:12 <dons> some unis do good ones, at unsw we write an interpreter. at oxford they do some cool gtk game.
02:39:13 <duey> depressing
02:39:24 <duey> im doing an interpreter
02:39:30 <duey> but not really interested in them
02:39:42 <dons> my first haskell assignment, many years ago, was an online maze bot, where all the students assignments fought each other for points.
02:39:45 <dons> that was fun.
02:40:09 <duey> i solved my first assignment using lambdabot
02:40:18 <ivanm> dons: was that subject your first exposure to haskell & FP?
02:40:26 <dons> but i'd imagine that boring assignments are boring in any language, and its just hard to find tutors who want to spend time coming up with a fancy assignment.
02:40:27 <ivanm> duey: lol
02:40:30 <dons> ivanm: yeah.
02:40:33 <duey> personally im not a fan of FP
02:40:48 <dons> duey says, hanging out in #haskell.
02:40:52 <ivanm> duey: and so you hang around this channel why???
02:40:59 <duey> i dont hangout here
02:41:02 <dons> ah well, there's always python.
02:41:06 <duey> use lambdabot
02:41:07 <duey> :D
02:41:28 <duey> plus I have to do haskell
02:41:30 <dons> you're not a fan of functional programming techniques?
02:41:31 <duey> for uni
02:41:41 <dons> what's the alternative, being a fan of encapsulated mutable state?
02:41:49 <ivanm> lol
02:41:53 <duey> yep!
02:42:08 <jmg_> hi
02:42:13 <dons> yeah, abstractions sucks. the kids always love raw untyped bytes
02:42:35 <duey> >> 1
02:42:45 <ski> bus errors, yay !
02:42:59 <dons> > 1 `shiftR` 8
02:43:00 <lambdabot>  Add a type signature
02:43:01 <dons> > 1 `shiftR` 8 :: Int
02:43:03 <lambdabot>  0
02:43:06 <ivanm> ski: what, the timetables are wrong, or there's a lot of traffic? :p
02:43:11 <duey> lol
02:43:53 <DRMacIver> @src shiftR
02:43:53 <lambdabot> Source not found. Wrong!  You cheating scum!
02:44:01 <dons> ?docs Data.Bits
02:44:01 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Data-Bits.html
02:44:15 <ski> ivanm : maybe passangers didn't align correctly in seats ?
02:44:28 <ivanm> heh
02:45:41 <duey> dons: are there regular expression libaries by default
02:46:04 <duey> ?docs Regex
02:46:04 <lambdabot> Regex not available
02:46:16 <dons> duey: yeah, Text.Regex
02:46:25 <duey> ?docs Text.Regex
02:46:25 <dons> have a look on hackage, there's about 8 of them.
02:46:26 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Text-Regex.html
02:46:40 <duey> I should do my assignment using regex
02:46:50 <dons> i wouldn't. very unhaskelly
02:46:57 <duey> indeed
02:46:57 <duey> :D
02:47:02 <duey> 404 on that link
02:47:04 <dons> usually a little lexer/parser is better form, and safer
02:47:27 <dons> look on hackage, under the regex-base and regex-* packages
02:47:33 <dons> ?hackage regex-base
02:47:34 <lambdabot> http://hackage.haskell.org/cgi-bin/hackage-scripts/package/regex-base
02:47:49 <qwr> regexes are comfortable to use ;)
02:48:01 <dons> they can be, sure.
02:48:16 <araujo> the problem with regexs is that they can be easily abused
02:48:20 <duey> now all i need are globals!
02:48:38 <dons> go duey, that's some great programming techniques you're trying out ;-)
02:48:43 <duey> :D
02:48:57 <dons> i suppose if you do use StateT for your globals, you'll get bonus points.
02:49:15 <DRMacIver> As they say, people will figure out how to write (Fortran|Perl|Blub) in any language. ;)
02:49:50 <int-e> hmm. targeted advertising ... Subject: To make it clear that the exception is actually thrown at run time, the revised specification lists UnsatisfiedLinkError as a Runtime Exception in the descriptions of all the method invocation instructions.
02:49:58 <int-e> weirdest spam subject ever.
02:50:02 <dons> heh
02:50:24 <duey> caught your attention though didn't it
02:50:49 <int-e> yes it did. sadly for them I'm not very interested in stock trading.
02:52:03 <roconnor> > fix (+1)
02:52:11 <lambdabot>  Exception: <<loop>>
02:53:46 <duey> > fix(\x -> 1)
02:53:47 <lambdabot>  1
02:59:13 <IvdSangen> @pl map (chr.(+6).ord)
02:59:13 <lambdabot> map (chr . (6 +) . ord)
03:30:52 <Igloo> cdsmith: darcs pull or darcs-all pull?
04:52:29 <timbod> Can anyone point me to documentation for the Network package?
04:52:59 <timbod> It's part of my debian ghc install, but no docs...
04:55:15 <pejo> timbod, isnt' there a -doc-package?
04:56:06 <timbod> pejo: not in my testing installation. I'm not sure about unstable
04:56:35 <timbod> (I was hoping it would be visible on the net somewhere)
04:57:13 <Saizan> ?docs Network
04:57:13 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/network/Network.html
04:57:26 <matthew-_> are gadts allowed in associated/indexed types yet in GHC HEAD?
04:58:02 <timbod> Do you think I could find that with google? Thanks Saizan
04:59:15 <timbod> Any sockets experts about? I'm a bit surprised that in my server, after a client has been killed, the server can still write to the client's socket, and doesn't get an exception until it reads.
04:59:38 <opqdonut> the socket hasn't been properly shut down, i'd guess
05:00:43 <timbod> No, it wasn't intentionally. I'm trying to get the server to handle abnormal client disconnects
05:01:16 <matthew-_> timbod: could well be kernel / OS specific
05:01:24 <Lemmih> dcoutts: ping.
05:02:12 <timbod> matthew-_: It probably is - it's just that
05:02:23 <pejo> timbod, isn't the default tcp timeout something like 15 minutes?
05:02:38 <timbod> I don't want the server to go on sending info to a client that's gone
05:03:28 <timbod> pejo: Unsure - a read from the killed client fails immediately, it's the write that appears to keep working.
05:03:30 <matthew-_> timbod: it may not actually go out of the nic - it might be buffered in the kernel for the connection to come back
05:05:55 <timbod> matthew-_: maybe, but it's gone from my stateful servers data structures, which is not good at all. I'm seeing if an hIsEOF call will detect problems before I write.
05:06:00 <LeCamarade> timbod: Maybe you are writing to a buffer.
05:06:23 <matthew-_> timbod: plus, it could well be haskell, and lazy IO.
05:07:07 <LeCamarade> matthew-_: Was about to say that, and suggest he hSetBuffering socket NoBuffering
05:07:22 <matthew-_> LeCamarade: yeah, or use hFlush
05:07:54 <timbod> LeCamarade: Well I know that I am writing to a buffer, but the hFlush succeeds at the end of it :-(
05:08:25 <LeCamarade> timbod: The hFlush succeeds even when the client isn't listening anymore?
05:09:20 <Lemmih> @seen dcoutts
05:09:20 <lambdabot> dcoutts is in #haskell-overflow, #haskell, #ghc and #gentoo-haskell. I don't know when dcoutts last spoke.
05:09:40 <timbod> I think so... the client process is killed, so it's not listening. hFlush doesn't seem to throw anything, however
05:14:32 <LeCamarade> timbod: hFlush doesn't seem specified to fail in case the stream is closed.
05:16:45 <Lemmih> Evil code of the day: deRefStablePtr (castPtrToStablePtr (Ptr (int2Addr# idsPtr)))
05:17:52 <timbod> LeCamarade: I've just looked a little close, and it definitely succeeds (I  manually threw an IOError after it to check my handling code)
05:18:16 <LeCamarade> Actually, it should throw an error to flush a closed stream. Hmm ....
05:19:29 <LeCamarade> Now we should move focus to the client side. It should be that the system (client) actually keeps the hope alive.
05:20:17 <LeCamarade> And when you try to read, the system queries the client for data, and discovers the folly, and  tells you about it.
05:20:38 <timbod> I'm not sure what you mean - I'm not really interested in fixing the client code, as I'm hoping to handle forced disconnects ok
05:21:07 <LeCamarade> You may have to keep a test going - trying to read as a test.
05:21:53 <LeCamarade> Short of that, you may not be able to know if the client is connected, or it is just the system buffering for the client and creating an illusion of connection.
05:22:29 <Baughn> Printed by parsec: 'unexpected end of input; expecting "<!-- TMPL_", "<!-- /TMPL_", end of input or ">"'
05:22:35 <Baughn> ..this'll be fun
05:24:15 <erider> good morning
05:27:01 <timbod> LeCamarade: I guess the extra latency of an ACK from the client back to the server may be worth it.
05:27:50 <Jedai> Hello
05:27:54 <LeCamarade> Well, maybe.
05:28:39 <Jedai> I'm writing a short program to count the number of lines in a file that contains a list of patterns
05:29:29 <LeCamarade> ndm: 47% faster. I'm yet to recover.
05:29:32 <Jedai> I'm having trouble to optimize it, does someone have another idea to make it faster :
05:29:40 <Baughn> Jedai: Use wc -l instead?
05:29:50 <LeCamarade> > repeat "Publish"
05:29:52 <lambdabot>  ["Publish","Publish","Publish","Publish","Publish","Publish","Publish","Publ...
05:30:38 <ndm> Baughn, if you're refering to my wc thing, the Haskell and C versions outperform wc -l on my machine - better buffering would help either, but the Haskell will remain C speed
05:31:07 <ndm> LeCamarade, i need a full set of benchmarks first, but yes - i am aiming to publish
05:31:25 <ndm> wc -w is giving my optimiser issues - its not terminating, and i've no idea why not
05:31:26 <Jedai> Baughn : it would be grep "list of pattern" | wc -l
05:31:41 <Jedai> But assume I'm not on Unix here
05:31:55 <ndm> Jedai, download grep for windows - easy enough
05:32:56 <dons> ndm, be a good idea to show the asm generated from each (C, optimised Haskell), imo, to get an idea of why they're so close
05:33:12 <dons> and what different code you get without the IO fusion (that's what's happening?)
05:33:32 <ndm> dons, i'm doing IO and list fusion
05:33:52 <dons> i hope you're careful with strictness :-)
05:34:02 <ndm> the generated Core isn't as nice as it should be..
05:34:09 <ndm> very, preserves strictness and sharing properties
05:34:16 <ndm> no human rewrite rules, so less of an issue
05:34:23 <mauke> perl -lne '++$n if /pattern/}{print 0+$n'
05:34:57 <integral> mauke: you've got extra spaces.
05:35:01 <Jedai> So is here something which I'm not doing right ?
05:35:11 <mauke> integral: perl -lne '$n++if/pattern/}{print$n+0'
05:35:30 <mauke> integral: make that perl '-lne$n++if/pattern/}{print$n+0'
05:35:47 <Jedai> By the way, my code is at http://hpaste.org/1901
05:36:04 <Jedai> Shouldn't have it been announced ?
05:36:22 <Saizan> only if the announce box was flagged
05:36:35 <int-e> @seen hpaste
05:36:35 <lambdabot> I saw hpaste leaving #haskell 9h 13m 5s ago, and .
05:36:49 <Saizan> oh
05:37:20 <Jedai> Oh well, I announced it myself so I guess that's ok
05:38:52 <Saizan> ?type toChunks
05:38:52 <lambdabot> Not in scope: `toChunks'
05:39:06 <Saizan> ?docs Data.ByteString.Lazy
05:39:06 <lambdabot> Data.ByteString.Lazy not available
05:39:28 <Japsu> > take 20 $ unwords $ repeat "test"
05:39:30 <lambdabot>  "test test test test "
05:39:36 <Japsu> yay
05:39:38 <Jedai> The thing is my program in haskell take 5 seconds where a program in OCaml (compiled with ocamlopt) take 1.3 s, when I think the Haskell version "should" be faster
05:39:40 <int-e> Jedai: I'd use foldl'
05:39:50 <Japsu> lazy strings ftw
05:40:47 <dons> are you using bytestrings?
05:41:33 <dons> -O2 with bytestrings should produce some particular good code, if you are careful.
05:42:04 <Jedai> My code is at http://hpaste.org/1901
05:42:20 <Jedai> int-e : thanks, I'll try foldl'
05:42:27 <dons> foldl', for a start.
05:42:31 <Saizan> mmh why are you splittings and concatenating each line?
05:42:44 <Saizan> to get a strict BS instead of a Lazy one?
05:42:45 <dons> looks a bit suspicious, btw.
05:42:59 <Jedai> Japsu: Lazy string ? You don't mean Data.String ? It was awfully slow
05:43:00 <dons> i've got some similar code on the shootout, let me see...
05:43:30 <Jedai> Saizan : I first tried with Strict ByteString.Char8 but it wasn't faster (neither slower)
05:43:34 <dons> Japsu: those concats will copy, also.
05:44:35 <dons> Japsu: here's an example super-fast lazy bytestring program, http://shootout.alioth.debian.org/gp4/benchmark.php?test=sumcol&lang=ghc&id=0
05:44:37 <lambdabot> Title: sum-file Haskell GHC program | Gentoo : Intel&#174; Pentium&#174;&nbsp;4 Compute ..., http://tinyurl.com/327qll
05:44:46 <dons> might have some hints.
05:45:08 <Japsu> hmm
05:45:09 <Saizan> oh, there's not isSubstringOf for lazy bytestrings..
05:45:36 <Jedai> Saizan : Yes, that's a bit of the problem
05:45:58 <Jedai> It's understandable though I guess
05:46:04 <Jedai> thanks dons
05:46:14 <Jedai> I'll look into that
05:47:01 <dons> Jedai: so can i just check, you're counting lines from a file that match a list of bytestring patterns?
05:48:06 <Jedai> Yes
05:48:20 <dons> and the [Bool] -> a  (looks suspicious..)
05:48:38 <Jedai> I can specify via a parameter if I want a "and" or "or" there
05:48:56 <dons> hmm. ok.
05:48:58 <DRMacIver> As an idle observation, your bracketing convention makes me sad. ;)
05:49:04 <dons> heh
05:49:11 <dons> a bit lispy ;-)
05:49:18 <Jedai> True
05:49:30 <dons> hmm, I wonder how I'd write it.
05:49:41 <dons> Jedai: do you use anything other than 'or' or 'and'?
05:49:50 <dons> (though, a good INLINE would specialise those I think)
05:49:56 <DRMacIver> dons: Not really. The positioning of the brackets would cause a lynch mob in lisp circles. :)
05:50:16 <Jedai> Not yet, would it really change anything to inline those ?
05:51:01 <dons> let me see.
05:52:59 <dons> how big are the files?
05:53:26 <Jedai> 40 Mo
05:53:42 <dons> do you need to process them in constant space? or will O(n) space do?
05:54:00 <Jedai> O(n) space will do
05:54:11 <dons> ok. strict bytestrings will do then.
05:54:18 <dons> that simplifies things a bit
05:54:25 <dons> (and helps the optimiser)
05:55:27 <matthew-_> mmm. deriving seems to be broken for indexed types in ghc HEAD. Certainly don't seem to work as per http://haskell.org/haskellwiki/GHC/Indexed_types
05:55:29 <lambdabot> Title: GHC/Indexed types - HaskellWiki
05:55:37 <Jedai> I tried strict bytestring, it didn't get any faster. But I may have overlooked something
05:57:03 <timbod> LeCamarade: I think your suggestion was a good one... My client now responds with an ACK, and the server doesn't remove the data from it's state until it's received. Much more reliable, without having to worry about socket low level details.
05:59:16 <cinimod> @help
05:59:17 <lambdabot> help <command>. Ask for help for <command>. Try 'list' for all commands
05:59:36 <cinimod> @help list
05:59:36 <lambdabot> list [module|command]
05:59:37 <lambdabot> show all commands or command for [module]. http://www.cse.unsw.edu.au/~dons/lambdabot/COMMANDS
05:59:45 <cinimod> @list
05:59:45 <lambdabot> http://www.cse.unsw.edu.au/~dons/lambdabot/COMMANDS
06:00:22 <Cheery> guys at space research right now seem like great people for creating unbearable complexity
06:00:39 <cinimod> @src
06:00:40 <lambdabot> src <id>. Display the implementation of a standard function
06:00:46 <cinimod> @src splitAt
06:00:47 <lambdabot> splitAt n xs           =  (take n xs, drop n xs)
06:00:58 <cinimod> @src take
06:00:58 <lambdabot> take n _      | n <= 0 =  []
06:00:59 <lambdabot> take _ []              =  []
06:00:59 <lambdabot> take n (x:xs)          =  x : take (n-1) xs
06:01:06 <the_undefined> quick haskell beginner question about ghc: Even the simplest programms turn out to be ~600kb in file size - any way to reduce this?
06:01:59 <Saizan> the_undefined: there's the weight of the runtime system
06:02:12 <Saizan> s/there/that/
06:02:41 <the_undefined> Saizan: So no way to ommit it, right?
06:03:19 <Saizan> no, at the moment
06:04:04 <the_undefined> ok thx. No big deal, just wondered if there might be some simple compiler option to get rid of redundant library stuff
06:04:08 <Lemmih> the_undefined: People are working on dynamic linking, iirc.
06:04:44 <the_undefined> Lemmih: k
06:05:31 <the_undefined> thx for the information, probably going to lurk around here every once in a while from now on - haskell seems very interesting ; )
06:05:33 <the_undefined> bye
06:06:57 <dons> Jedai: so i'm just hacking up an optimised version.
06:07:08 <dons> there's two things, one, make sure your lines walker is nice and strict.
06:10:34 <dons> the second, don't use isSubstringOf, we can use a faster manual loop.
06:11:59 <Jedai> Why would isSubstringOf be slow ?
06:12:15 <Jedai> Or do you mean we're searching for all the pattern in one pass ?
06:12:39 <greenrd> Is there an existing radix trie (aka PATRICIA tree) implementation in Haskell?
06:13:44 <dons> Jedai: oh, just that isSubstringOf isn't implemented as well as I'd like.
06:13:59 <tcr> How do you best test if all elements in a list are equal? I'm currently using `and (map (== head list) (tail list))'
06:14:02 <dons> it uses an Array internally, whereas I've found a manual loop with isPrefixOf can be faster.
06:14:11 <dons> :t all
06:14:14 <lambdabot> forall a. (a -> Bool) -> [a] -> Bool
06:14:18 <dons> > all (==) [1,1,1,1]
06:14:19 <lambdabot>  Couldn't match expected type `Bool'
06:14:34 <dons> oh, no, not like that :-)
06:14:42 <tcr> all (== head list) (tail list)
06:14:43 <tcr> probably
06:14:48 <dons> yeah.
06:15:40 <Jedai> dons: Oh, I just assumed it would use one of the very fast algorithm for string searching
06:16:07 <Saizan> greenrd: IntSet and IntMap are implemented using patricia trees, also there's Data.Trie here -> http://hackage.haskell.org/cgi-bin/hackage-scripts/package/collections-0.3
06:16:09 <lambdabot> http://tinyurl.com/yt7z4y
06:16:50 <dons> Jedai: its Knuth-Morris-Pratt, but I've had some poor results with it.
06:16:52 <greenrd> @hoogle IntMap
06:16:53 <lambdabot> Data.IntMap :: module
06:16:53 <lambdabot> Data.IntMap.IntMap :: data IntMap a
06:17:11 <greenrd> @whereis IntMap
06:17:11 <lambdabot> Maybe you meant: where where+
06:17:16 <greenrd> @where IntMap
06:17:16 <lambdabot> I know nothing about intmap.
06:17:43 <Saizan> @docs Data.IntMap
06:17:43 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Data-IntMap.html
06:17:43 <dons> Jedai: so I'd do something like this to start with, http://www.cse.unsw.edu.au/~dons/tmp/A.hs
06:18:17 <dons> Jedai: and also try the current B.isSubstringOf instead of the naive, but strict, versoin there.
06:18:32 <cinimod> @src drop
06:18:32 <lambdabot> drop n xs     | n <= 0 =  xs
06:18:32 <lambdabot> drop _ []              =  []
06:18:32 <lambdabot> drop n (_:xs)          =  drop (n-1) xs
06:18:37 <dons> Jedai: note 'go' is a non-copying loop over the strict bytestring.
06:18:44 <dons> so it won't make unnec. copies / concats
06:18:54 <dons> in fact, we never even break up the string with lines.
06:19:53 <dons> Jedai: the inner loop ends up as,
06:19:57 <dons>               $wgo_s3aO =
06:19:57 <dons>                 \ (ww9_s38t :: GHC.Prim.Addr#)
06:19:57 <dons>                   (ww10_s38x :: GHC.Prim.Int#)
06:20:05 <dons> which is exactly as we'd want.
06:20:22 <Jedai> Ok, thank you, I'll try that
06:20:33 <dons> Jedai: can you try it out now? :-)
06:21:02 <cdsmith> @tell Igloo You were right and I'm an idiot.  I was using darcs pull instead of darc-all pull.
06:21:03 <lambdabot> Consider it noted.
06:21:44 <dons> Jedai: in general, I'd say its a *bug* if bytestring processing with ghc 6.6 is ever slower than strings in ocaml.
06:22:16 <Jedai> dons: That was my reaction too :)
06:23:03 <Igloo> cdsmith: OK, glad you're sorted  :-)
06:23:14 <cdsmith> Igloo++
06:23:32 <cdsmith> Yep, it's building now, and already past the point where it failed.
06:23:37 <dons> yeah, the compiled code looks fine for the one I pasted. i hope it runs well.
06:23:42 <Igloo> dons: What's the plan for renaming fps to bytestring, BTW?
06:23:53 <dons> that's a 'go' , yes.
06:23:59 <dons> after the binary paper is done.
06:24:07 <Igloo> OK
06:24:09 <dons> move the stream fusion (faster!) branch to bytestring
06:24:19 <dons> and make that a hackage package , and move fps out of base.
06:24:21 <dons> how's that sound?
06:24:47 <dons> got to get the stream fusion branch into hackage before i finish my phd.
06:24:48 <Igloo> "move fps out of base" == "delete Data.ByteString from base", right?
06:24:51 <dons> yeah
06:25:03 <dons> it'll be available from bytestring, which i guess is a core package
06:25:18 <dons> is that the consensus we had?
06:26:11 <Igloo> We might be able to get away with it being an extralib for 6.8
06:26:38 <dons> people will cry if their default ghc doesn't come with bytestrings
06:26:50 <dons> but i guess they do with mtl already
06:27:10 <Igloo> That's just a detail, anyway
06:27:16 <dons> but either way, it will be a hackage package called 'bytestring'
06:27:17 <dons> and not in base.
06:27:42 <dons> and use stream fusion with all the secret dons-and-duncan tricks mwhahaha evil laugh
06:28:48 <dons> Jedai: so the lesson here is to try to get down to raw, strict bytestrings, in tight tail recursion
06:28:59 <dons> then its like programming assembler
06:29:41 <dons> and to also use zero-copying substring pieces (unsafeTail), rather than buliding up lazy lists with lines.
06:30:09 <dons> Jedai: any numbers? its late and i'm leaving, but want to know if the code is better ....
06:30:11 <Heffalump> so why bother using Haskell at all?
06:30:34 <dons> Heffalump: we still know its pure. and QC works on it.
06:30:41 <Heffalump> unsafeTail?
06:30:52 <dons> is just an unchecked substring slice.
06:30:52 <Jedai> dons: It didn't finish yet... There's something very wrong here since your code seems excellent
06:31:03 <dons> ok. it might have bugs :-)
06:31:03 <Heffalump> and if it was empty?
06:31:11 <dons> probably missed a base case.
06:31:41 <Jedai> I'm searching for it
06:32:00 <xic> why isn't this channel called ##haskell?
06:32:22 <dons> one # is enough for anyone.
06:33:02 * dons tests the code.
06:33:33 <xic> freenode policy indicates that a double # should be use
06:33:52 <dons> why?
06:33:55 <Pseudonym> Freenode has a policy on this?
06:34:00 <Pseudonym> WHy don't they enforce it in chanserv?
06:34:08 <Japsu> ## channels are "about" channels
06:34:09 <dons> heya Pseudonym. up late.
06:34:14 <Pseudonym> Not much of a policy if you ask me.  Code is law.
06:34:17 <Pseudonym> Yeah, you too!
06:34:17 <Japsu> # channels are "official" project channels
06:34:33 <Pseudonym> Haskell.org is an offician project.
06:34:43 <Pseudonym> We've got SoC students and everything.
06:34:43 <dons> hence #haskell.
06:34:48 <dons> and tshirts, don't forget the tshirts.
06:34:52 <xic> #haskell.org :)
06:35:02 <Japsu> if this channel is run by haskell.org, then as I see it there's nothing wrong with this channel being #haskell, not ##haskell
06:35:22 <dons> Jedai: hehe. I think I see it.
06:36:10 <dons> i always forget that.
06:36:18 <Japsu> http://freenode.net/policy.shtml#primarychannels
06:36:19 <lambdabot> Title: freenode: Policies
06:36:22 <Pseudonym> dons: I had a mild migrane today, so I slept a lot of the day.
06:36:24 <Pseudonym> Not tired now.
06:36:40 <dons> Jedai: hehe.
06:36:41 <Pseudonym> What's your excuse?
06:36:46 <dons>         go' !i !s
06:36:47 <dons>             | B.null s  = i
06:36:47 <dons>             | otherwise = go' (i + n) (B.unsafeTail ss)
06:37:04 <dons> Pseudonym: oh, late night last night, stayed up watching rage. so slept in late.
06:37:14 <dons> now hacking, while gf dances around the room listening to annie lennox.
06:37:15 <Pseudonym> Fair enough.
06:37:20 <dons> my house is weird sometimes.
06:37:24 <Pseudonym> I'm more of a Saturday night Rage kind of person.
06:37:30 <dons> yeah. me too.
06:37:32 <Jedai> Of course ! break don't del the char...
06:37:40 <dons> Jedai: hehe. always forget that!
06:38:01 <dons> Pseudonym: yeah, though there was the National, and bit by bats last night. and some good aussie indie chicks.
06:39:17 <Jedai> Ok, thank you, it's down to the OCaml performance now
06:39:20 <dons> Jedai: seems about twice as faster here as your code.
06:39:23 <dons> ah nice.
06:39:41 <dons> before, ./b  0.27s user 0.02s system 98% cpu 0.293 total. after  0.169
06:39:52 <Jedai> With the areSubstringOf optimized it should be faster
06:39:53 <dons> now I wonder if isSubstringOf helps.
06:40:03 <dons> yeah. that's probably the main thing to look at now.
06:41:20 <dons> yeah, Data.ByteString.isSubstringOf is slower.
06:41:30 <Jedai> remplacing isSubstring by B.isSubstringOf get the performance back where we were before...
06:41:33 <dons> that lazy Array it uses isn't ideal.
06:41:37 <dons> yeah, same here.
06:41:58 <dons> so we need a strict, fast KMP substring, not the lazy slow impl. fps currently uses.
06:42:00 <Jedai> Maybe that's something to look at for a future version of the library
06:42:05 <dons> definitely.
06:42:31 <Jedai> In this precise case, maybe a Boyer-Moore would be faster
06:42:53 <Jedai> to study once and only once the patterns
06:42:59 <dons> might be nice to hack that up. we should have a collection of fast string matchers on bytestrings.
06:43:55 <Jedai> Yeah, that would be useful
06:44:03 <dons> heya swiert. i meant to thank you for the zipper idea for xmonad. (if you've read the article)
06:44:32 <swiert> hi dons. Which article? On your blog?
06:44:36 <Jedai> I wonder if the regex library based on ByteString would have what I need... I'll check that
06:45:02 <dons> swiert: yeah, a couple of days ago.
06:45:06 <swiert> (and you're welcome, of course)
06:45:10 <dons> swiert: we're moving entirely to a zipper in xmonad.
06:45:14 <swiert> Ok. Let me check it out.
06:45:17 <dons> its really the perfect structure.
06:45:17 <swiert> Cool!
06:45:53 <dons> Jedai: oh, interesting. yes, that's rather well optimised too.
06:46:05 <dons> e.g. the tre-regex bytestring code might be pretty good
06:46:20 <dons> Jedai: btw, i guess you're optimising this just for fun?
06:46:43 <Igloo> "Haskell: Optimised for FUN!"
06:47:10 <Jedai> dons: You're right, frankly the performance is already sufficient for my need
06:47:40 <dons> good to know.
06:47:53 <Jedai> But the fact that Ocaml was faster with subpar code just wasn't to my taste...
06:48:37 <Jedai> Still the Ocaml code is much longer, even that your module
06:48:45 <swiert> dons: Any chance of a xmonad article for the next TMR?
06:49:01 <dons> it would be nice if naive bytestring folds optimimsed a bit better, the stream fusion branch should help a lot there
06:49:21 <dons> swiert: hmm. could i take my collection of blog posts, unify them, and combine them into a single article?
06:49:36 <dons> since i'll write 1 or 2 more in the next couple of weeks. they could then be polished into a single TMR.
06:49:50 <swiert> dons: sounds great.
06:50:23 <byorgey> dons: what's the URL of your blog?  just curious
06:52:05 <dons> www.cse.unsw.edu.au/~dons/blog
06:52:53 <byorgey> ok, thanks, I'll check it out =)
06:56:35 <igli> dons: that xmonad site is excellent ty
06:57:02 <igli> (er series)
06:57:11 <dons> cheers.
06:59:11 <igli> "We can now just write down in pseudocode (well, let's just use actual Haskell code)" heh altho i do find myself wondering what the pseudo-code would look like.
07:00:09 <dons> pseudocode is dead. ;-)
07:00:12 <SamB_XP> heh
07:00:32 <xic> is xmonad a good alternative to wmii?
07:00:33 <igli> hehe ok :)
07:01:16 <SamB_XP> pseudocode is just real code where some functions have to be added, perhaps in lets or wheres...
07:01:22 <dons> xic, yeah.
07:01:34 <SamB_XP> or, perhaps with a ... thrown in
07:01:54 <xic> dons: is mouse support planned for xmonad?
07:02:00 <dons> > let (...) = undefined in map (...) [1..10]
07:02:02 <dons> ;-)
07:02:02 <lambdabot>  Undefined
07:02:07 <dons> xic, it has mouse support.
07:02:18 <xic> dons: windows can be resized with the mouse?
07:02:37 <dons> nope. that's keyboard. though come to think of it, its about 4 lines if someone really wants to do that.
07:02:55 <dons> mod-h,l will resize though.
07:03:12 <dons> i wonder why no one has mentioned mouse resizing before.
07:03:28 <int-e> isn't the point of a tiling wm not having to do that?
07:03:33 <dons> yeah :-)
07:03:53 <Saizan> "put down the mouse"
07:03:56 <dons> i hardly resize anyway, once i set my tile fraction to 2%3, it seems to get it right.
07:04:14 <dons> i guess i don't have a mouse. so maybe that's why i don't notice it.
07:04:25 <xic> maybe i'll give xmonad a try. btw what do you think about the idea of a haskell gui toolkit?
07:04:54 <dons> sounds good. gtk2hs is one, but we could always have more :-)
07:05:16 <dons> xmonad is a serious contender to wmii, imo. its a perfectly acceptable replacement, and a lot smaller.
07:05:18 <Saizan> is there an extenstion to firefox to easily browse via keyboard?
07:05:19 <igli> i love my trackball tho
07:05:20 <mux> gtk2hs is nice as a backend for higher-level GUI toolkits
07:05:29 <mux> such as the one from neil mitchell
07:05:32 <dons> Saizan: yeah, sjanssen uses it. though can't recall the name.
07:05:50 * Saizan googles
07:06:06 <xic> dons: i meant a pure haskell gui toolkit
07:06:14 * mux takes a look at GuiHaskell
07:06:18 <dons> oh, like conal's stuff.
07:06:23 <xic> dons: to complement xmonad :)
07:06:27 <dons> xic, have a look on hackage.
07:07:07 <dcoutts__> if someone was going to look at doing a more Haskelly GUI toolkit I'd recommend starting with xcb, pango and cairo
07:07:41 * int-e wants to have an Applicative instance for Data.Binary.Get :/
07:07:48 <dons> oh, don't we have one now?
07:07:50 <dons> dcoutts__: ?
07:07:53 <dcoutts__> int-e: done already
07:08:03 <dons> ah, in the unstable branch.
07:08:32 <dcoutts__> int-e: in fact that's the only way to make it run really fast is to use the applicative combinators
07:08:55 <dons> >>= sucks for rewrite rule matching
07:09:02 <xic> dcoutts_: are there haskell bindings for xcb?
07:09:03 <dons> monads are so silly.
07:09:07 <int-e> oh so there's some hope we'll get them despite the compatibility issues with older base libs? :)
07:09:13 <dons> xic, nope. but sjanssen has it as his SoC project.
07:09:18 <SamB_XP> dcoutts: couldn't you use cheap immitations?
07:09:19 <dons> so by july (he starts on monday)
07:09:30 <dcoutts__> dons: if someone doesn't want to go via gtk, but wants to make a more custom gui thing, then using pango text layout and cairo vector graphics with xcb tying things together would be a reasonable route
07:09:41 <dons> yeah, sounds cute.
07:09:48 <dcoutts__> xic: sjanssen will be working on xcb bindings for SoC
07:09:55 <dons> i want flaming glass explosions in xmonad  when i close a client.
07:10:01 <int-e> hmm. how do xcb and opengl interact?
07:10:14 <tcr> there does not seem to be a concatM already defined, is there?
07:10:27 <SamB_XP> dons: are you adding a plugin system?
07:10:33 <int-e> tcr: what would that do?
07:10:38 <dcoutts__> int-e: similarly to xlib and opengl I expect, X11 has a separate path for gl vs core
07:10:42 <dons> SamB_XP: i was thinking we'd embed a ruby interpreter.
07:10:46 <int-e> @type foldM (++) []
07:10:48 <dons> maybe some javascript.
07:10:50 <SamB_XP> heh
07:10:51 <lambdabot>     Occurs check: cannot construct the infinite type: a = [a]
07:10:51 <lambdabot>       Expected type: [a] -> [a] -> [[a]]
07:10:55 <xic> dcoutts__: doesn't xcb have the problem that it's not portable to windows and mac?
07:10:55 <dons> :t foldM
07:10:56 <dcoutts__> SamB_XP: cheap imitations?
07:10:58 <lambdabot> forall a b (m :: * -> *). (Monad m) => (a -> b -> m a) -> a -> [b] -> m a
07:11:25 <dcoutts__> xic: yes (well mac has an X11 server)
07:11:27 <dons> :t foldM (return . (++)) []
07:11:29 <lambdabot> forall a b. [b] -> [a] -> [a]
07:11:34 <int-e> @type foldM (fmap . (++)) []
07:11:36 <lambdabot> forall (f :: * -> *) a. (Functor f, Monad f) => [f [a]] -> f [a]
07:11:40 <dons> better :-)
07:11:41 <SamB_XP> dcoutts: functions that do the same thing but don't use the Applicative typeclass?
07:11:54 <dcoutts__> SamB_XP: you could, but that'd be silly
07:12:12 <SamB_XP> quite!
07:13:42 <tcr> Actually, I just want something to turn m [[x]] -> m [x]
07:14:38 <int-e> @type liftM concat
07:14:40 <lambdabot> forall a (m :: * -> *). (Monad m) => m [[a]] -> m [a]
07:14:40 <dcoutts__> Lemmih: you were after me?
07:14:50 <Saizan> is there a binary repo that compiles with HEAD?
07:14:53 <tcr> ah right, int-e. Silly me. Thanks!
07:15:12 <int-e> Saizan: I just did that, hmm
07:15:24 <int-e> http://darcs.haskell.org/binary
07:15:26 <lambdabot> Title: Index of /binary
07:16:01 <Saizan> ok
07:16:21 <dcoutts__> dons: I'm still in two minds about the ForeignPtr in ByteStrings, I think we should consider either allowing ForeignPtr to point to a movable heap block, or not using ForeignPtr at all. Pinned heap blocks are too expensive for small strings. We waste heap space terribly, and people notice.
07:16:47 <dons> yeah. i'm with you on this.
07:16:48 <dcoutts__> and the engineering to allow ForeignPtr to point to a movable heap block is hard
07:16:56 <int-e> Saizan: if there are include file troubles (related to HsBase.h most likely) you might need the patch that I just sent to libraries@haskell.org
07:17:29 <int-e> Saizan: (the patch is for the base package - right now it doesn't install all include files that are needed. you can also copy them manually.)
07:17:36 <dons> its fine for big stuff (readFile), but creating lots of new strings .hmm.
07:17:52 <dcoutts__> dons: I've been pondering a lazy bytestring rep that distinguishes the foreign and native cases
07:18:34 <dcoutts__> dons: eg data LBS = Nil | Native ByteArray Int Int LBS | Foreign ForeignPtr Int Int LBS
07:18:44 <Lemmih> dcoutts__: Yeah, I thought I had found a bug in gtk2hs. Turns out it had been fixed already.
07:19:07 <dcoutts__> Lemmih: oh good, what bug was that? (and we should have a new release out some time soonish)
07:19:56 <Lemmih> dcoutts__: 'listStoreClear' entered an infinite loop if called on an empty listStore.
07:19:59 <dcoutts__> Lemmih: right
07:20:31 <dcoutts__> dons: and if we're pondering the LBS rep again, then thinking of something tree like would be interesting, can we allow both lazy and random access file IO?
07:20:42 <dcoutts__> in the same structure
07:20:43 <Lemmih> dcoutts__: Should I expect my application to segfault if I use 'forkIO', btw?
07:21:30 <milagro> hi all, I have a question concerning Data.Set data type. My current source looks like this:
07:21:35 <milagro> import Data.Set (Set)
07:21:35 <milagro> import qualified Data.Set as Set
07:21:35 <milagro>  
07:21:35 <milagro> my_set = Set.fromList [1,2,3]
07:21:35 <milagro> result = Set.map (1+) my_set
07:21:35 <milagro>  
07:21:37 <milagro> main = putStrLn(show(result))
07:21:55 <dcoutts__> Lemmih: if you use GUI calls from multiple Haskell threads and you're using the -threaded rts, then yes. You have to call unsafeInitGUIForThreadedRTS and use postGUI / asyncGUI to do actions safely from other threads.
07:21:55 <milagro> but I don't want to write "Set.map" everywhere
07:22:16 <norpan> milagro: what do you want to write then?
07:22:21 <milagro> is there a way to use just "map" instead?
07:22:27 <norpan> sure
07:22:29 <dcoutts__> milagro: import Prelude hiding map
07:22:32 <norpan> import Prelude hiding map
07:22:36 <norpan> bah
07:22:47 <dcoutts__> actually, import Prelude hiding (map)
07:23:00 <norpan> ut if you want another name, you can simply do m = Set.map
07:23:05 <Lemmih> dcoutts__: Should it work if I'm not using the threaded rts?
07:23:08 <int-e> @quote stereo
07:23:08 <lambdabot> Cale says: Welcome to #haskell where your questions are answered in majestic stereo!
07:23:10 <milagro> ok, will it overwrite the definition of original map, i.e. will I be able to use map on lists?
07:23:18 <norpan> no, that's the point
07:23:31 <norpan> there can only be one map
07:23:36 <dcoutts__> Lemmih: if you're using he single threaded rts then everything works fine, you just need to do the cooperative scheduling hack
07:23:57 <dcoutts__> milagro: you can use fmap
07:24:14 <milagro> oh, but I want Haskell to find out if I passed set or list
07:24:16 <Lemmih> dcoutts__: The cooperative scheduling hack? The timeout/yield thingy?
07:24:22 <dcoutts__> milagro: then use fmap
07:24:24 <norpan> milagro: it doesn't work like that
07:24:27 <dcoutts__> Lemmih: yep
07:24:41 <dcoutts__> @type fmap
07:24:43 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
07:24:59 <dcoutts__> milagro: Set and lists [a] are instances of Functor
07:25:07 <Saizan> is Set?
07:25:27 <milagro> dcoutts__: fmap doesn't seem to work
07:25:32 <Saizan> don't you need Ord a for Set? and so you can't have an instance for Functor?
07:25:35 <milagro> dcoutts__: I get "Unresolved top-level overloading"
07:25:48 <dcoutts__> milagro: you might need to specify a type
07:25:54 <norpan> set is surely not a Functor
07:26:13 <Lemmih> dcoutts__: I'm getting segfaults when using the new liststore api from a forked thread (without -threaded).
07:26:22 <milagro> dcoutts__: where?
07:26:54 <norpan> i don't know the exact Functor requirements, but I can imagine Set does not apply
07:27:00 <norpan> and that is not a pun
07:27:07 <Saizan> ?src Functor
07:27:07 <lambdabot> class  Functor f  where
07:27:07 <lambdabot>     fmap        :: (a -> b) -> f a -> f b
07:27:18 <dcoutts__> hmm, I thought it was in Functor, but it seems not
07:27:24 <milagro> so, from other point of view, is there a way to easily create a function which will work both on sets and lists; if yes, how?
07:27:37 <dcoutts__> Map is in Functor
07:27:40 <norpan> dcoutts__: sets need Ord, and they don't keep duplicate elements
07:28:01 <norpan> dcoutts__: a map is a functor in the value type yes
07:28:06 <dcoutts__> right, yes
07:28:18 <norpan> but not in the key type
07:28:21 <dcoutts__> milagro: ok, fmap does not help
07:28:30 <milagro> dcoutts__: ok..
07:28:35 <dcoutts__> Lemmih: with the darcs version of gtk2hs?
07:28:51 <norpan> milagro: but as i said, you can define any name you like, just do name = Set.map
07:28:52 <Lemmih> dcoutts__: Yes.
07:29:08 <dcoutts__> Lemmih: can you find repeatable test cases ?
07:29:15 <milagro> norpan: yes, but i want function map to map both lists *and* sets
07:29:20 <Saizan> norpan: not keeping duplicates doesn't mean it's not a functor, the only problem is that you can't express the costraint in the current Functor class
07:29:43 <norpan> Saizan: perhaps, i don't know the Functor requirements :)
07:29:45 <norpan> milagro: why?
07:29:55 <norpan> don't you know what data type you are using?
07:30:13 <norpan> there is a great difference between a list and a set, so you really should know
07:30:14 <milagro> norpan: I want to create a function which will work on any enumerable
07:30:26 <milagro> norpan: sometimes it will be a list, and sometimes a set
07:30:36 <norpan> enumerable?
07:30:38 <Saizan> ?docs Data.Traversable
07:30:38 <lambdabot> Data.Traversable not available
07:30:42 <norpan> sets are not enumerable?
07:30:54 <milagro> norpan: they are, that's the point
07:31:02 <mdmkolbe|home> milagro: I think you don't mean enumerable the way Haskell does
07:31:02 <lambdabot> mdmkolbe|home: You have 1 new message. '/msg lambdabot @messages' to read it.
07:31:18 <mdmkolbe|home> milagro: In haskell, things like Integers and characters are enumerable
07:31:18 <milagro> well, probably not, i'm new to haskell :)
07:31:21 <mdmkolbe|home> @src Enum
07:31:22 <lambdabot> class  Enum a   where
07:31:22 <lambdabot>     succ                     :: a -> a
07:31:22 <lambdabot>     pred                     :: a -> a
07:31:22 <lambdabot>     toEnum                   :: Int -> a
07:31:22 <lambdabot>     fromEnum                 :: a -> Int
07:31:24 <lambdabot> [3 @more lines]
07:31:48 <SamB_XP> @more
07:31:48 <lambdabot>     enumFrom                 :: a -> [a]
07:31:48 <lambdabot>     enumFromThen, enumFromTo :: a -> a -> [a]
07:31:48 <lambdabot>     enumFromThenTo           :: a -> a -> a -> [a]
07:31:49 <norpan> milagro: if you know what properties you want, you should perhaps try to make your own type class
07:32:03 * SamB_XP thought there were defaults for those three
07:32:03 <mdmkolbe|home> milagro: basically anything that you can take the next of. (e.g. (succ 1) == 2)
07:32:06 <milagro> what I mean is that mapping is an operation which should work on any iterable/enumerable "thing", which both lists and sets are
07:32:27 <norpan> but map only works on sets of orderable things
07:32:34 <milagro> question is, why I have to explicitly do this, using "map" or "Set.map"
07:32:34 <mdmkolbe|home> milagro: are you only wanting mapping?
07:32:39 <norpan> that's an additional constraint
07:32:47 <norpan> which has to do with the set implementation
07:32:50 <milagro> why can't haskell do this for me and allow me to use "map" only?
07:32:51 <mdmkolbe|home> @type fmap
07:32:53 <lambdabot> forall a b (f :: * -> *). (Functor f) => (a -> b) -> f a -> f b
07:33:20 <milagro> norpan: map works only on orderable things? i don't think so
07:33:31 <norpan> milagro: for sets
07:33:39 <norpan> because the elements are stored in a tree
07:33:40 <SamB_XP> > fmap show (S.fromList "Hello!")
07:33:40 <lambdabot>   Not in scope: `S.fromList'
07:33:47 <SamB_XP> > fmap show (Set.fromList "Hello!")
07:33:47 <lambdabot>   Not in scope: `Set.fromList'
07:33:51 <SamB_XP> argg.
07:34:03 <SamB_XP> > fmap show (Data.Set.fromList "Hello!")
07:34:04 <lambdabot>        add an instance declaration for (Functor Data.Set.Set)
07:34:04 <lambdabot>     In the expr...
07:34:10 <SamB_XP> aww.
07:34:20 <Lemmih> dcoutts__: Yep, I'll make a minimal repo case.
07:34:23 <mdmkolbe|home> milagro: fmap, will do map over anything that supports "mapping" by being part of functor.  I know that lists are functors.  Sets should also be functors.
07:34:43 <dcoutts__> Lemmih: cheers, could you send that to the gtk2hs-devel list
07:34:44 <Saizan> Sets are not functors because of the way the Functor class is defined.
07:34:45 <SamB_XP> mdmkolbe|home: I think you need a more complicated typesystem for that?
07:35:08 <mdmkolbe|home> milagro: but like SamB_XP just demonstraited, sets aren't implemented as fuctors, but you might be able to add an instance
07:35:11 <mdmkolbe|home> @src Functor
07:35:11 <lambdabot> class  Functor f  where
07:35:11 <lambdabot>     fmap        :: (a -> b) -> f a -> f b
07:35:16 <milagro> so in principle it should work, but current implementation is lacking, yes?
07:35:21 <mdmkolbe|home> SamB_XP: what do you mean
07:35:31 <mdmkolbe|home> milagro: yes, but it can be fixed in 2 lines
07:35:42 <milagro> mdmkolbe|home: please, show me those two lines :)
07:36:01 <mdmkolbe|home> milagro: what is the manual function for mapping over sets?  mapSet?
07:36:15 <Saizan> mdmkolbe|home: instance Functor Set where fmap f s = Set.map f s  won't work, because you don't know Ord b
07:36:15 <SamB_XP> I think that you would have trouble if not Ord b
07:36:20 <milagro> mdmkolbe|home: Set.map
07:36:37 <SamB_XP> @type Data.Set.map
07:36:39 <lambdabot> forall a b. (Ord b, Ord a) => (a -> b) -> Data.Set.Set a -> Data.Set.Set b
07:36:54 <SamB_XP> for some reason it also wants Ord a, but I don't think it is really needed
07:36:54 <mdmkolbe|home> milagro: ah, I was going to do what Saizan just listed, but like he said there is a problem
07:37:27 <milagro> soo, it can't be achieved easily?
07:37:39 <mdmkolbe|home> SamB_XP: it wants ord, probably b/c it implements the set as a binary tree on the inside which needs to be able to order it's elements
07:37:48 <mdmkolbe|home> milagro: unfortunately no
07:38:00 <mdmkolbe|home> milagro: the type system won't allow it
07:38:37 <milagro> mdmkolbe|home: is this a Haskell's type system limitation or limitation of current library/Data.Set implementation?
07:38:57 <milagro> mdmkolbe|home: or: can this be fixed sooner than later?
07:39:00 <mdmkolbe|home> milagro: both.  suppose you were to map with a function that produced un-orderable items (e.g. IOPtr), a Set couldn't hold them b/c they aren't orderable
07:39:21 <SamB_XP> I believe I know a way to define a "map" function without such constraints -- the trouble is I can't figure out how to make it map from Sets to Sets!
07:39:36 <SamB_XP> also it uses fundeps
07:40:18 <bens> hello, I'm having some trouble compiling hs-plugins. The error message is "src/System/Plugins/Load.hs:80:0:\n Failed to load interface for `GHC.Prim'".
07:40:18 <milagro> mdmkolbe|home: but set doesn't preserve an order, why "orderability" is important?
07:40:20 <mdmkolbe|home> milagro: but one could make the argument that the Haskell type system should allow one to specify a Functor instance that says "I can 'fmap' but only for functions that produce orderable things".  But if you look at the way Haskell classes have to be implemented such a thing is impossible.
07:40:34 <mdmkolbe|home> milagro: Set preserves order internally
07:40:35 <bens> does anybody know what I ought to do?
07:40:51 <SamB_XP> milagro: if you want sublinear time for element lookup, you need something more than simply equality testing
07:41:01 <milagro> mdmkolbe|home: internally... i see, so it's leaking abstraction
07:41:03 <mdmkolbe|home> milagro: Set might use something like a red-black tree or a heap data structure
07:41:11 <mdmkolbe|home> milagro: yes
07:41:38 <mdmkolbe|home> milagro: a non-leaky abstraction for set would be if it only required (Eq a), but that is impossible to implement quickly
07:41:58 <milagro> mdmkolbe|home: hash tables won't work?
07:41:59 <mdmkolbe|home> milagro: and even that would have the same problem b/c it would require Eq instead of Ord as it is now
07:42:16 <SamB_XP> milagro: that would require another abstraction leak
07:42:19 <mdmkolbe|home> milagro: ok, I guess hashtables would work
07:42:25 <SamB_XP> a worse one, at that
07:42:46 <SamB_XP> plus hashtables don't like "multi-threaded" access
07:43:02 <SamB_XP> er. probably access is the wrong word?
07:43:03 <milagro> SamB_XP: I'd have to provide a safe hashing function myself for each type
07:43:29 <SamB_XP> milagro: the safe part is easy. but it would also need to be efficient.
07:43:30 <Saizan> how can you keep uniqueness without (at least) Eq a ?
07:43:57 <milagro> Eq a is a must, of course
07:44:16 <milagro> hash tables would use both Eq and hashing function
07:44:38 <mdmkolbe|home> milagro: the reason the haskell type system won't allow this is b/c I might have a function f :: (Functor f) -> f a -> Bool {- or whatever -}, the body that function must be allowed to do fmap with *any* function it dreams up even ones that don't output something of class Ord or Eq
07:45:30 <mdmkolbe|home> milagro: it would be nice if we could fix that restriction, and people are looking at it, but it would require a lot of type system adjustment
07:45:33 <SamB_XP> also because you might pass it an (f a) where a isn't in Ord
07:45:42 <Saizan> ?paste
07:45:43 <lambdabot> Haskell pastebin: http://hpaste.org/new
07:46:00 <SamB_XP> well, actually, no.
07:46:21 <milagro> mdmkolbe|home: ok, i can understand that
07:46:56 <Saizan> http://hpaste.org/1902
07:46:57 <mdmkolbe|home> do we have a faq, this seems like a good question to put on it
07:47:00 <mdmkolbe|home> @faq
07:47:01 <lambdabot> The answer is: Yes! Haskell can do that.
07:47:11 <SamB_XP> hmm.
07:47:15 <Saizan> see my paste for a possible solution
07:47:17 <SamB_XP> not in this instance ;-)
07:47:44 * mdmkolbe|home thinks lambdabot's faq answer is a bit ironic
07:48:09 <SamB_XP> Saizan: hmm, interesting approach.
07:48:50 <milagro> Saizan: yeah, it works, very cool!
07:48:51 <mdmkolbe|home> Saizan: Yeah, I've seem people propose such things before.  I don't recall if there are any objections/problems
07:49:10 <norpan> it's multi-parameter, that's what's the main objection i suppose
07:49:53 <Saizan> mdmkolbe|home: it's not h98, also it doesn't enforce the naturality of fmap, and maybe other problems with type ifnerence
07:51:10 <mdmkolbe|home> of course if I want to up the ante.  I might have something that is a Fuctor' in one of 2 ways.  i.e. F is a functor if both input and output are Ord *or* F is a functor if both input and output are both ... eh I don't know ... Hashable?
07:51:22 <mdmkolbe|home> Saizan: what do you mean by that not preserving naturality?
07:52:02 <norpan> type inference gets tricky with mptc
07:52:34 <Saizan> well you could instance Functor [] Double b where fmap' f a = []  just to be evil, while treating all other types "normally"
07:52:55 <mdmkolbe|home> Saizan: I see
07:53:00 <mcspiff> Hello
07:53:05 * mdmkolbe|home starts dreaming about evil things to do
07:53:27 * mdmkolbe|home stops dreaming so he doesn't scare off mcspiff
07:53:41 <Saizan> hi mcspiff
07:53:47 <mdmkolbe|home> Hello, mcspiff
07:53:49 <mcspiff> if i have a type data (show a) => Simple a = Simple a deriving Show
07:54:02 <mcspiff> shouldnt these two type signatures be equal
07:54:25 <mcspiff> displaySimple (Show a) => Simple a -> String
07:54:36 <mcspiff> and displaySimple :: Simple a -> string
07:54:57 <mdmkolbe|home> mcspiff: no
07:55:10 <mdmkolbe|home> sorry, I take that back
07:55:14 <Saizan> mcspiff: that's a bit tricky, but currently the (Show a ) context is *required*, and not *provided*
07:55:37 <nominolo> hey dcoutts__
07:55:42 <Saizan> it just makes Simple :: Show a => a -> Simple a, nothing more
07:56:01 <mcspiff> So the (Show a) in the type provides type safety but doesnt imply a (Show a) in type signatures?
07:56:04 <SamB> mcspiff: the context on the "data" declaration is rather broken
07:56:10 <SamB> IMO
07:56:20 <Saizan> mcspiff: exactly
07:56:30 <nominolo> !paste
07:56:32 <mcspiff> SamB: In my usage or in general
07:56:39 <mdmkolbe|home> ?paste
07:56:40 <lambdabot> Haskell pastebin: http://hpaste.org/new
07:56:56 <SamB> mcspiff: well, more generally, any context in that position of a data declaration
07:57:06 <mcspiff> ah ok
07:57:28 <SamB> I think it shouldn't be allowed if it is going to be half-assed like that
07:57:43 <mcspiff> so ATM its like wearing suspenders and a belt ;-)
07:58:11 <SamB> rather
07:58:22 <nominolo> dcoutts__: http://hpaste.org/1903 this is what i'm trying to do
07:58:50 <mcspiff> well that clears that up.Thanks
08:00:38 <davidL> if an expression is satisfies the conditions for two guards, which guard takes precedence?
08:00:39 <milagro> thank you for your answers. bye!
08:01:04 <dmhouse> davidL: the first one.
08:01:10 <dmhouse> davidL: just like pattern matching.
08:01:12 <davidL> dmhouse: thanks
08:01:20 <nominolo> dcoutts__: the basic idea is to get some handle to the image data and use that as a opengl texture
08:01:48 <nominolo> dcoutts__: i don't know, though, how to do that with the current cairo bindings
08:01:57 <nominolo> dcoutts__: and how best to extend it
08:05:00 <SamB> nominolo: you don't need to do a texture upload?
08:05:25 <dcoutts__> nominolo: something like imageSurfaceGetPixelData
08:05:51 <dcoutts__> nominolo: and from that use some GL function to create a texture from the image data
08:06:25 <davidL> ?ty replicate 10 (1/0)
08:06:27 <lambdabot> forall t. (Fractional t) => [t]
08:06:49 <sorear> hello.
08:08:28 <davidL> is Infinity of the Fractional class?
08:08:53 <dmhouse> Infinity is something weird and special, I think.
08:08:54 <Saizan> ?instances Fractional
08:08:55 <lambdabot> Double, Float
08:08:57 <isaacd_> > (1/0) :: Double
08:09:05 <nominolo> dcoutts__: haven't found that GetPixelData function
08:09:12 <lambdabot>  thread killed
08:09:14 <isaacd_> > (1/0) :: Rational
08:09:17 <lambdabot>  Exception: Ratio.%: zero denominator
08:09:23 <dmhouse> It's like an extra and unexported constructor for certain numberical types.
08:09:24 <mdmkolbe|home> ?ty inf
08:09:27 <lambdabot> Not in scope: `inf'
08:09:33 <mdmkolbe|home> ?ty infinity
08:09:40 <dmhouse> > 1/0
08:09:48 <lambdabot> thread killed
08:09:54 <dmhouse> Okay, lambdabot's being weird.
08:09:56 <lambdabot>  thread killed
08:10:02 <dmhouse> Prelude> 1/0
08:10:02 <dmhouse> Infinity
08:10:06 <mdmkolbe|home> ?ty 1
08:10:23 <lambdabot> Plugin `type' failed with: IRCRaised thread killed
08:10:35 <Saizan> *Main> 1/0 :: Double
08:10:35 <Saizan> Infinity
08:10:52 <davidL> neat
08:11:05 <dmhouse> Prelude> (1/0 :: Double, 1/0 :: Float)
08:11:06 <dmhouse> (Infinity,Infinity)
08:11:24 <dmhouse> Prelude> - 1/0
08:11:24 <dmhouse> -Infinity
08:11:28 <dmhouse> It's not really neat, it's wrong.
08:11:33 <Saizan> Infinity is a value specified by IEEE 754 (the standard for floating point)
08:11:39 <sorear> I thought it was just show syntax
08:12:05 <dmhouse> Saizan: yes, but it's still wrong.
08:12:55 <nominolo> dcoutts__: i guess that one is not yet implemented, is it?
08:13:05 <davidL> Prelude> (1/0 :: Double) > 101
08:13:07 <davidL> True
08:13:19 <davidL> what's wrong with that?
08:13:26 <nominolo> SamB: what do you mean by "texture upload"?
08:13:30 <mcspiff> > 1/0
08:13:36 <lambdabot>  Infinity
08:13:38 <dmhouse> davidL: why should 1/0 be infinite?
08:13:46 <SamB> nominolo: usually cards want textures to be on the card?
08:14:12 <nominolo> oh, yes, probably
08:14:13 <davidL> dmhouse: oh, I don't think that is right, but I don't know of an other way to get Infinity
08:14:16 <mcspiff> > 1::float / 0::float
08:14:17 <lambdabot>  Parse error
08:14:17 <dmhouse> Picture the graph of y = 1/x. If you set x = a bit more than 0, and gradually decrease x, y goes off to positive infinity. But if you set x = a bit less than 0, and gradually increase x, then y goes off to negative infinity.
08:14:30 <mdmkolbe|home> > NaN
08:14:39 <lambdabot>   Not in scope: data constructor `NaN'
08:14:47 <Lemmih> dcoutts__: I might be doing something stupid. Does 'onClicked' act radically different from 'onFocus'?
08:14:47 <nominolo> SamB: that's why i render on a cairo surface and than import this as an opengl texture
08:14:56 <dmhouse> Therefore it's nonsensical to say that 1/0 is either Infinity or -Infinity. You either shouldn't distinguish between them or should say that 1/0 doesn't have a value; it's a meaningless symbol.
08:15:06 <nominolo> SamB: and i make no assumptions on whether it copies or not
08:15:21 <davidL> dmhouse: is there another way to return Infinity?
08:15:24 <mdmkolbe|home> dmhouse: I think IEEE handles that by NaN in that case.  Does Haskell not have that
08:15:27 <mdmkolbe|home> ?
08:15:28 <dmhouse> davidL: hrm, good question.
08:15:37 <dmhouse> mdmkolbe|home: it does, can't remember where I've seen it though.
08:15:46 <mcspiff> >:t 1/0
08:15:47 <SamB> nominolo: ah.
08:15:51 <davidL> ?ty isInfinite
08:15:54 <lambdabot> forall a. (RealFloat a) => a -> Bool
08:16:00 <Saizan> *Main> 0/0
08:16:00 <Saizan> NaN
08:16:25 <mdmkolbe|home> @src RealFloat
08:16:25 <lambdabot> Source not found. My mind is going. I can feel it.
08:17:03 <dmhouse> > let comp (_:_) [] = GT; comp [] (_:_) = LT; comp (_:xs) (_:ys) = comp xs ys; infty = () : infty in comp (replicate 101 ()) infty
08:17:05 <lambdabot>  LT
08:17:06 <mdmkolbe|home> Prelude> :info RealFloat
08:17:06 <mdmkolbe|home> class (RealFrac a, Floating a) => RealFloat a where
08:17:06 <mdmkolbe|home>   floatRadix :: a -> Integer
08:17:06 <mdmkolbe|home>   floatDigits :: a -> Int
08:17:06 <mdmkolbe|home>   floatRange :: a -> (Int, Int)
08:17:06 <mdmkolbe|home>   decodeFloat :: a -> (Integer, Int)
08:17:08 <mdmkolbe|home>   encodeFloat :: Integer -> Int -> a
08:17:10 <mdmkolbe|home>   exponent :: a -> Int
08:17:12 <mdmkolbe|home>   significand :: a -> a
08:17:14 <mdmkolbe|home>   scaleFloat :: Int -> a -> a
08:17:17 <mdmkolbe|home>   isNaN :: a -> Bool
08:17:18 <mdmkolbe|home>   isInfinite :: a -> Bool
08:17:20 <dmhouse> mdmkolbe|home: woah, pastebin.
08:17:20 <mdmkolbe|home>   isDenormalized :: a -> Bool
08:17:22 <mdmkolbe|home>   isNegativeZero :: a -> Bool
08:17:24 <mdmkolbe|home>   isIEEE :: a -> Bool
08:17:27 <mdmkolbe|home>   atan2 :: a -> a -> a
08:17:28 <mdmkolbe|home>         -- Defined in GHC.Float
08:17:30 <mdmkolbe|home> instance RealFloat Double -- Defined in GHC.Float
08:17:32 <mdmkolbe|home> instance RealFloat Float -- Defined in GHC.Float
08:17:35 <mdmkolbe|home> sorry, that was a bit longer than I thought
08:18:05 <dmhouse> You can do a sensible infinity with Peano encoding (or lists of (), as they're isomorphic):
08:18:08 <dmhouse> > let comp (_:_) [] = GT; comp [] (_:_) = LT; comp (_:xs) (_:ys) = comp xs ys; infty = () : infty in comp (replicate 101 ()) infty
08:18:12 <SamB> mdmkolbe|home: pay attention when selecting
08:18:24 <lambdabot>  thread killed
08:18:30 <dmhouse> Gah.
08:18:41 <dmhouse> It worked ^^ earlier.
08:18:59 <sorear> dmhouse: Right.  thread killed  is always lambdabot's fault, not yours
08:19:09 <dmhouse> sorear: yeah, what's up with it?
08:19:18 <sorear> dmhouse: nota clue!
08:19:18 <dmhouse> Prelude> let comp (_:_) [] = GT; comp [] (_:_) = LT; comp (_:xs) (_:ys) = comp xs ys; infty = () : infty in comp (replicate 101 ()) infty
08:19:18 <dmhouse> LT
08:19:25 <dmhouse> (Just to prove it :))
08:19:35 <mdmkolbe|home> @botsnack
08:19:36 <lambdabot> :)
08:19:38 <sorear> dmhouse: dons is really confused too
08:19:39 <mdmkolbe|home> @botsnack
08:19:39 <lambdabot> :)
08:19:45 <dmhouse> sorear: weird.
08:19:55 <sorear> mdmkolbe|home: it only affects commands that fork ghc
08:19:56 <davidL> thanks dmhouse
08:19:58 <dmhouse> sorear: does it happen anywhere other than on dons's box?
08:20:13 <sorear> dmhouse: Nope, -but-
08:20:30 <sorear> dmhouse: dons has physically replaced his box twice with no effect
08:21:03 <sorear> it happens on linux and openbsd - he tried that
08:21:21 <dmhouse> How odd. Does it happen when not connecting to IRC?
08:22:01 <sorear> don't know, you'd have to ask him
08:22:29 <dmhouse> Hrm, actually, that shouldn't really matter, if it only happens when forking GHC it's unlikely to be network-related.
08:22:52 <mdmkolbe|home> before I go off and re-invent the wheel, has anyone seen thing that generalizes the Zipper to cyclic data types?
08:23:02 <mcspiff> is there a nop for monads? im trying to fold over a list of actions (i believed they are called)
08:23:08 <dmhouse> mcspiff: return ()
08:23:44 <mcspiff> that just made my day :D
08:23:46 <mauke> whatever :: (Monad m) => m (); whatever = return ()
08:24:08 <dmhouse> Actually, return x for any x is guaranteed to be a nop by the monad laws. (Specifically that return x >>= f = f x.)
08:24:35 <Saizan> mdmkolbe|home: an example?
08:25:00 <sorear> > (return () >> (undefined :: IO ())) `seq` 0
08:25:02 <lambdabot>  0
08:25:33 <mdmkolbe|home> Saizan: suppose I have cyclic list, the standard Zipper wont work on it
08:25:53 <mdmkolbe|home> Saizan: this was motivated by the last Blog on XMonad
08:26:11 <dmhouse> > (undefined :: IO ()) `seq` 0
08:26:13 <lambdabot>  Undefined
08:26:27 <mcspiff> > foldr (>>) (return ()) $ map putChar "hello"
08:26:28 <lambdabot>  <IO ()>
08:26:36 <mcspiff> im rather proud of that :D
08:26:40 <mdmkolbe|home> the zipper used there is over a non-cyclic list, but most people prefer their desktops to wrap around
08:26:56 <dmhouse> > mapM_ putChar "hello"
08:26:58 <lambdabot>  <IO ()>
08:27:04 <mauke> mcspiff: that looks like sequence_
08:27:14 <Saizan> mdmkolbe|home: they "wrap" using reverse iirc
08:27:22 <mauke> @src sequence_
08:27:22 <lambdabot> sequence_ ms = foldr (>>) (return ()) ms
08:27:24 <dmhouse> mcspiff: foldr (>>) (return ()) = sequence_. mapM_ f xs = sequence_ (map f xs)
08:27:49 <mdmkolbe|home> Saizan: huh?
08:28:05 <Saizan> see focusRight
08:28:11 <nominolo> mdmkolbe|home: well, instead of top, you could make the path cyclic, maybe?
08:28:37 <mcspiff> @src mapM_
08:28:37 <lambdabot> mapM_ f as = sequence_ (map f as)
08:29:57 <mcspiff> Well, I may have reinvented the wheel, but I think that cleared up a few problems I had with monads
08:30:24 <nominolo> mcspiff: that's ok.
08:30:33 <SamB> reinventing the wheel is a time-honored activity among haskell users
08:30:53 <mdmkolbe|home> Saizan: I can't find the blog right now, but if I understand you, then yes, but it's acting as a sort of hack that would be nice to eliminate
08:31:10 <SamB> of course, we usually like to then just use the old wheel when we notice we've reinvented it
08:31:13 <Saizan> mdmkolbe|home: yes, i concur
08:31:39 <mcspiff> Seems fair enough
08:31:51 <SamB> saves code, you know
08:32:11 <mdmkolbe|home> nominolo: I have thoughts along simmilar lines (but then it starts to get compilicated).  I'm sure I can do it, but if it's already done I'll skip the work
08:32:52 <koeien> @src sequence_
08:32:52 <lambdabot> sequence_ ms = foldr (>>) (return ()) ms
08:33:31 <Saizan> the main problem would be to keep insertion to work right
08:33:35 <SamB> istr a datastructure with O(1) rotation?
08:33:44 <pitecus> Is there a simpler way of expressing \x -> case x of { Just x' ->  Just (x',x') ; Nothing -> Nothing }?
08:33:45 <mdmkolbe|home> Saizan: absolutely
08:33:56 <mcspiff> is there a version of ghci with things like @src built in?
08:34:06 <SamB> not @src, no
08:34:09 <mauke> @type fmap (join (,))
08:34:18 <lambdabot> forall a (f :: * -> *). (Functor f) => f a -> f (a, a)
08:34:20 <dmhouse> pitecus: fmap (\x -> (x, x))
08:34:23 <SamB> well. I guess you could try GHCi On Acid
08:34:27 <pitecus> cool dmhouse
08:34:32 <dmhouse> pitecus: or fmap (join (,)) if you want to be a bit obscure.
08:34:36 <mauke> > fmap (join (,)) (Just 42)
08:34:38 <lambdabot>  Just (42,42)
08:35:00 <SamB> (which lets you use lambdabot inside GHCi)
08:35:09 <mcspiff> sounds interesting
08:35:18 <SamB> don't know how up-to-date it is
08:35:28 <mcspiff> would it be on dons's site?
08:36:13 <SamB> @where goa
08:36:13 <lambdabot> http://www.cse.unsw.edu.au/~dons/code/goa/
08:36:18 <TomMD> shhhh, you'll wake him up, he is sleeping.
08:36:35 <dmhouse> mcspiff: also :info is surprisingly useful.
08:37:03 <mcspiff> :info
08:37:08 <mcspiff> opps wrong buffer
08:37:25 <SamB> TomMD: I'm relatively sure dons is used to having urls with dons in them mentioned while he is sleeping
08:37:41 <mdmkolbe|home> mcspiff: try ":info Monad" or ":info Integer"
08:38:01 <chrismbrown_> is there a function that I can use to check whether one string is a substring of another?
08:38:07 <mcspiff> ahh that is useful, thanks
08:38:23 <Saizan> ?type isSubstringOf
08:38:25 <lambdabot> Not in scope: `isSubstringOf'
08:38:27 <mauke> isInfixOf, 6.6
08:39:09 <chrismbrown_> "(ComplexExpr1 a b (ComplexExpr2 Null))" `contains` "ComplexExpr1 a b (ComplexExpr2 Null)" = True
08:39:10 <dmhouse> mdmkolbe|home: or even :info find etc.
08:39:12 <chrismbrown_> something like that
08:39:36 <dmhouse> chrismbrown_: not in the standard libs, but it's fairly easy to write.
08:39:51 <mauke> > "x" `isInfixOf` "(x)"
08:39:53 <lambdabot>  True
08:39:53 <chrismbrown_> dmhouse: yeah, but I was hoping there was a cheat! :)
08:40:00 <SamB> mdmkolbe|home: what would you say to real-time dequeues?
08:40:07 <chrismbrown_> mauke: ah! cool
08:40:21 <dmhouse> mauke: is that new?
08:40:51 <mdmkolbe|home> SamB: I plan to look at some
08:41:06 <chrismbrown_> ?type isInfixOf
08:41:08 <lambdabot> forall a. (Eq a) => [a] -> [a] -> Bool
08:41:20 <mdmkolbe|home> @src isInfixOf
08:41:20 <lambdabot> isInfixOf needle haystack = any (isPrefixOf needle) (tails haystack)
08:41:41 <chrismbrown_> thanks
08:41:41 <SamB> I found some on page 56 of okasaki's PhD thesis
08:41:57 <mdmkolbe|home> SamB: link?
08:42:16 <SamB> @go CMU-CS-96-177
08:42:20 <lambdabot> http://www.cs.cmu.edu/afs/cs.cmu.edu/project/fox/mosaic/papers/cokasaki-thesis.ps
08:43:13 <SamB> also http://www.cs.cmu.edu/~rwh/theses/okasaki.pdf
08:43:41 <SamB> and http://citeseer.ist.psu.edu/okasaki98purely.html
08:43:42 <lambdabot> Title: Purely Functional Data Structures (ResearchIndex)
08:44:10 <mdmkolbe|home> SamB: thx, I'll look at it this evening
08:44:17 <SamB> actually, page 57
08:44:34 <SamB> and my PDF reader thinks it is page 69
08:54:16 <araujo> morning
09:00:09 * SamB assumes that, in a window manager, you probably want actual O(1), not just amortized O(1)
09:00:48 <mdmkolbe|home> SamB: probably, though the size of n is small enough, it might not matter
09:01:24 <SamB> mdmkolbe|home: yeah. but it isn't like you need raw speed, anyway.
09:02:06 <SamB> @hoogle dequeue
09:02:06 <lambdabot> Data.Queue.deQueue :: Queue a -> Maybe (a, Queue a)
09:02:50 <mdmkolbe|home> SamB: I'm mostly just trying to figure out of there is a pricipaled way to approach these problems (like Zipper is pricipled way to do mutable trees)
09:03:14 <SamB> which are the problems?
09:03:44 <SamB> and personally I'd just see the dequeue as a way to implement a circular zipper
09:04:17 <mdmkolbe|home> SamB: mutable data types with Cycles (more than just circular lists)
09:04:24 <SamB> oh.
09:04:59 <SamB> so have you thought of a particular problem where this is true?
09:06:47 <mdmkolbe|home> SamB: hmm, well anyting where I want a graph that I can follow edges and change nodes (but without the standard edge-list structures)
09:07:24 <dcoutts__> Lemmih: re onClicked vs onFocus, what kind of thing did you mean?
09:07:56 <dcoutts__> nominolo: yeah, you'd need to extend the cairo bindings slightly
09:08:23 <dcoutts__> nominolo: and now would be a good time to do that, as we're going to do a new release soonish
09:08:27 <Lemmih> dcoutts__: Thing?
09:08:45 <dcoutts__> Lemmih: what kind of radical difference were you noticing?
09:09:38 <Lemmih> dcoutts__: My program works fine with 'onClicked' but it segfaults with 'onFocus'.
09:09:44 <dcoutts__> Lemmih: onFocus doesn't seem very useful, it's only for containers
09:10:29 <Lemmih> dcoutts__: Right, I was just using it for testing. I was too lazy to add a button.
09:11:31 <SamB> mdmkolbe|home: hmm. I doubt there is a general approach of the kind you seek...
09:12:07 <dcoutts__> Lemmih: hmm, seems our onFocus is in the wrong module
09:12:11 <mdmkolbe|home> SamB: such challanges, eager me does make
09:12:24 <mdmkolbe|home> (in my best yoda voice)
09:14:23 <dcoutts__> Lemmih: perhaps you want onFocusIn/Out
09:15:02 <Lemmih> dcoutts__: I don't really need. I was just surprised that it segfaulted.
09:15:10 <dcoutts__> Lemmih: what value are you returning from the handler?
09:15:31 <dcoutts__> Lemmih: looks to me like we've bound it with the wrong return type (as well as putting it in the wrong module)
09:15:52 <dcoutts__> Lemmih: it looks like it ought to be a bool return type rather than that enumuration
09:16:22 <Lemmih> dcoutts__: Oh. I just returned the input argument.
09:16:33 <dcoutts__> Lemmih: ok
09:17:09 <dcoutts__> Lemmih: could you send me a test case for that too, so I can try and reporduce and then confrim I've fixed it
09:19:23 <Lemmih> dcoutts__: Just returning the input argument works fine. It's only when threads are involved that it segfaults.
09:19:45 <dcoutts__> Lemmih: oh, weird
09:20:03 <dcoutts__> Lemmih: and we're definitely not using the threaded rts?
09:20:32 <dcoutts__> Lemmih: and not using ghci
09:20:40 <dcoutts__> (which uses the threaded rts)
09:20:46 <Lemmih> Pretty sure. Control.Concurrent.rtsSupportsBoundThreads is False and I'm not using GHCi.
09:20:53 <dcoutts__> ok
09:22:34 <dcoutts__> Lemmih: so I can do this fix, but I don't think it's the source of the problem.
09:29:41 <encryptio> > nubBy (>) [5,2,8,3]
09:29:45 <lambdabot>  [5,8]
09:30:14 <encryptio> > iterate (nubBy (>)) [5,2,8,3] !! 2
09:30:15 <lambdabot>  [5,8]
09:31:55 <lekro> is nubBy (>) well-defined? or could there be an implementation that assumes the given relation to be symmetric?
09:32:51 <mdmkolbe|home> > nubBy (==) [1,1,2,2,1,1]
09:32:53 <lambdabot>  [1,2]
09:34:32 <lekro> hm, the report states: "When the "By" function replaces an Eq context by a binary predicate, the predicate is assumed to define an equivalence."
09:34:58 <lekro> so the result of nubBy (>) is very implementation dependent, isn't it?
09:35:53 <norpan> lekro: what would you want it to mean?
09:36:05 <ndm> @seen dcoutts
09:36:05 <lambdabot> dcoutts is in #ghc, #haskell-overflow, #haskell and #gentoo-haskell. I last heard dcoutts speak 7m 24s ago.
09:36:14 <lekro> I don't know, I encryptio using it
09:36:19 <lekro> +saw
09:36:27 <ndm> dcoutts, you said you had "more lazy" versions of words/lines somewhere?
09:37:01 <SamB> lekro: I suppose so
09:40:23 <dcoutts> ndm: yep, lemme find it...
09:40:35 <mdmkolbe|home> @src words
09:40:35 <lambdabot> words s = case dropWhile isSpace s of
09:40:35 <lambdabot>     "" -> []
09:40:35 <lambdabot>     s' -> w : words s'' where (w, s'') = break isSpace s'
09:42:46 <ndm> i can deforest lines perfectly easily, but works is significantly harder
09:43:00 <ndm> i'm wondernig if its a laziness bug in the definition
09:43:46 <dcoutts> @src unwords
09:43:46 <lambdabot> unwords [] = ""
09:43:46 <lambdabot> unwords ws = foldr1 (\w s -> w ++ ' ':s) ws
09:44:04 <dcoutts> ndm: it's intersperse, intercalate and unwords that are too strict
09:44:30 <dcoutts> ndm: the impls are here:
09:44:33 <dcoutts> http://www.cse.unsw.edu.au/~dons/code/streams/list/Data/List/Stream.hs
09:44:34 <lambdabot> http://tinyurl.com/2eavnc
09:44:41 <ndm> none of those 3 are on the list of ones i'm using
09:44:50 <ndm> must be something else
09:44:55 <dcoutts> ndm: strictness tests here: http://www.cse.unsw.edu.au/~dons/code/streams/list/tests/Strictness/
09:44:56 <lambdabot> Title: Index of /~dons/code/streams/list/tests/Strictness, http://tinyurl.com/2hsm7g
09:45:54 <dcoutts> ndm: I think words and lines are specified correctly, only unwords (+ intersperse) is too strict
09:45:58 <ndm> ah, i've found why mine was screwing up, i think
09:46:14 <dcoutts> ndm: words and lines are both very lazy which does make fusion tricky
09:47:04 <ndm> yeah, i've spotted they are very lazy
09:47:10 <dcoutts> ndm: one has to start yielding the line before finding the end of the line
09:47:12 <ndm> but in my fusion system thats entirely irrelevant, thankfully
09:47:35 <matthew-_> does anyone know what the plans are (and ideally, eta) for supporting GADTs in indexed types?
09:48:10 <dcoutts> matthew-_: ask ChilliX
09:48:41 <matthew-_> @seen ChilliX
09:48:41 <lambdabot> I saw ChilliX leaving #ghc and #haskell 1d 4h 7m 41s ago, and .
09:48:59 <matthew-_> dcoutts: cheers, will do.
09:49:14 <dcoutts> @seen Chilli
09:49:15 <lambdabot> I haven't seen Chilli.
09:55:44 * nominolo starts reading the c2hs docs
09:57:08 <ndm> hmm, totally deforesting "length . words =<< getContents" still leaves me 40% slower than C
09:57:14 <ndm> (but twice the speed of GHC)
09:57:48 <pchiusano> hello
09:57:51 <nominolo> ndm: did you examine the assembly?
09:58:22 <dcoutts> ndm: you'd probably need to make words stricter, it's using a different eval order from the optimal for the strict case
09:58:30 <sorear> helllo ndm
09:58:35 <ndm> nominolo - i haven't examined the Core yet...
09:58:36 <ndm> hi sorear
09:58:54 <ndm> dcoutts - unacceptable, i want to go from standard stuff - i suspect mine should be able to reduce optimally...
09:59:10 <dcoutts> ndm: or rather, we want to specialise words on the strictness shape, when it's spine-strict
10:00:02 <pchiusano> is data Expr = Symbol String | [Expr] not valid syntax?
10:00:05 <dcoutts> ndm: so not changing the original definition, just specialising (taking advantage of) the strictness
10:00:21 <SamB> pchiusano: you forgot to give a name for the second constructor
10:00:27 <dcoutts> pchiusano: no, you need names for each constructor
10:00:36 <mdmkolbe|home> pchiusano: you want data Expr = Sybol String | Expers [Expr]
10:00:41 <ndm> dcoutts, my optimisation is strictness information free - i'd ideally like to keep it that way - although i think mine may now be strict
10:00:50 <pchiusano> oh, so, like
10:00:54 <pchiusano> okay
10:00:58 <dcoutts> ndm: what may be strict?
10:01:03 <ndm> well, it must be actually - it returns an Int and nothing else - no spine strict when no data
10:01:05 <pchiusano> cool
10:01:07 <pchiusano> thx
10:01:20 <ndm> dcoutts, the deforested result must be strict, since it returns Int
10:01:35 <dcoutts> ndm: right, but are we taking advantage of that to change the order of evaluation
10:02:11 <ndm> dcoutts, i hoped GHC would, but i don't think it is for "lines", which is simpler than words
10:02:22 <ndm> it is for "wc -c" though
10:02:43 <dcoutts> aye, but that doesn't do this tricky lazy splitting
10:03:23 <ndm> indeed
10:03:37 <ndm> i'll try and get lines down to a perfect Core, then i'll move on to words
10:04:05 <dcoutts> ndm: so currently it creates a (,) thunk with the result for the current word/line and the remaining input
10:04:49 <ndm> no, i deforested out the (,)
10:04:50 <dcoutts> ndm: so you should be able to fuse the consumer with the bit that gets the result for the current line, but we're still doing the thunk (or some equivalent)
10:05:28 <sorear> ndm: does supero use ghc or ghc -O2 ?
10:05:30 <ndm> the "length . words =<< getContents" creates no data, at all
10:05:36 <ndm> sorear, -O2
10:05:50 <dcoutts> ndm: that does not matter
10:06:09 <ndm> dcoutts, it creates no (,) thunk
10:06:20 <ndm> its also first order
10:06:31 <ndm> data/functinos have absolutely no where to hide!
10:06:46 <dcoutts> ndm: you should still see the reminants of the funny eval order in the final looping code
10:06:52 <pchiusano> what is the type of '[]' ?
10:07:04 <ddarius> :t []
10:07:06 <lambdabot> forall a. [a]
10:07:12 <dcoutts> pchiusano: it's a list with elements of any type you like
10:07:13 <ndm> dcoutts, nope, the eval order should have been flattened - although i can't guarantee that
10:07:54 <dcoutts> ndm: right, that's the crucial thing, we should have a single loop, the standard eval order for lines/words is a nested loop
10:07:59 <ndm> i'll have to check that in detail though, its possible a remnant got through
10:08:05 <pchiusano> is [] sort of a special case?
10:08:16 <dcoutts> pchiusano: special in what way?
10:08:19 <ndm> yeah, i'm not sure if I get down to one loop for lines yet
10:08:30 <mdmkolbe|home> pchiusano: what do you mean?
10:08:33 <pchiusano> well, could I create my own [] ?
10:08:40 <mdmkolbe|home> pchiusano: yes
10:08:41 <dcoutts> pchiusano: yes, except for the syntax
10:08:41 <sorear> pchiusano: yes
10:08:49 <ndm> data List a = Nil | Cons a (List a)
10:09:18 <mdmkolbe|home> :type Nil = forall a. List a
10:10:18 <pchiusano> hmm ok
10:10:23 <ski> Nil :: forall a. List a  -- more haskellish syntax :)
10:10:31 <ski> Cons :: forall a. a -> List a -> List a
10:10:56 <sorear> data List :: * -> *  where
10:11:11 <sorear>    Nil :: forall a. List a
10:11:18 <sorear>    Cons :: forall a. a -> List a -> List a
10:11:22 <pchiusano> okay, but if I have a function f Nil = 23
10:11:28 <ski> (oh, yes, temporarily forgot about GADT syntax)
10:11:30 <pchiusano> what is the type of f?
10:11:43 <sorear> f :: Num b => List a -> b
10:11:44 <mdmkolbe|home> sorear: does that syntax work? GADTS?
10:11:45 <pchiusano> or f [] = 23
10:11:49 <ski> is there any more equation defining 'f' ?
10:11:54 <sorear> mdmkolbe|home: Yes, that syntax works.
10:12:03 <sorear> f :: Num b => [a] -> b
10:12:05 <ski> :t let f [] = 23 in f
10:12:07 <lambdabot> forall t t1. (Num t1) => [t] -> t1
10:12:09 <pchiusano> no, suppose that is it
10:12:11 <sorear> f :: Num b => [] a -> b
10:12:23 <mdmkolbe|home> sorear: is that using GATDs or something else?
10:12:28 <ski> mdmkolbe|home : it is
10:12:51 <sorear> a GATD sounds like something bad.
10:13:35 <mdmkolbe|home> sorear: the only thing I can think of would be a GATeD community
10:15:11 <nominolo> dcoutts: what is the preferred way of dealing with raw-byte data on the haskell site?
10:15:32 <nominolo> i'd like to avoid implementing a bytestring style lib
10:16:25 <dcoutts> nominolo: a Ptr ?
10:16:44 <dcoutts> nominolo: or a bytestring directly
10:17:23 <nominolo> a unsigned char *
10:17:56 <ndm> @karma+ Igloo -- splitting up base
10:17:56 <lambdabot> Igloo's karma raised to 22.
10:18:22 <nominolo> dcoutts: ok, it's a bit trickier:
10:18:46 <dcoutts> nominolo: because of sizes, offsets, row strides, bit depths etc
10:18:54 <nominolo> dcoutts: PixelData PixelFormat DataType (Ptr a)
10:18:56 <waern_> niiiice... base has been splitted up?
10:19:08 <nominolo> yes, that's the input format, OpenGL expects
10:19:26 <nominolo> (PixelData is the constructor)
10:19:28 <dcoutts> nominolo: which gl function is that?
10:19:42 <nominolo> texImage2D
10:19:53 <dcoutts> nominolo: or rather which module, so I can find it in the haddoc docs
10:19:55 <ndm> waern_ - i've just seen the pretty library come out of base
10:20:12 <waern_> ndm: ah
10:20:29 <mdmkolbe|home> ndm: pretty library == pretty printing library?
10:20:30 <nominolo> http://haskell.org/ghc/docs/latest/html/libraries/OpenGL/Graphics-Rendering-OpenGL-GL-Texturing-Specification.html
10:20:32 <lambdabot> http://tinyurl.com/28pzsb
10:20:56 <ndm> mdmkolbe|home: yes
10:21:00 <nominolo> and this is the cairo spec: http://www.cairographics.org/manual/cairo-Image-Surfaces.html
10:21:01 <lambdabot> Title: Image Surfaces
10:22:26 <dcoutts> nominolo: lots of format variation allowed by gl I see
10:22:34 <nominolo> dcoutts: I guess I could wrap it up and tag it with the relevant data from the surface
10:22:44 <dcoutts> nominolo: so cairo image surfaces have a much more restricted pixel format
10:22:54 <nominolo> dcoutts: not sure how i would do that within c2hs, though
10:22:58 <dcoutts> nominolo: mostly RGB/ARGB but it's pre-multiplied
10:23:06 <nominolo> yep
10:23:40 <dcoutts> nominolo: we don't want to have the cairo bindings depend on the opengl package, we just want to have cairo provide all the info necessary to use it with gl
10:23:41 <nominolo> I guess I would have to write a marshaller for Ptr CUChar -> SurfaceData a, right?
10:24:05 <nominolo> dcoutts: yes, hence the wrapped data-type
10:24:35 <dcoutts> nominolo: so what is the info we need to make a gl surface, the format, the size and the pointer? anything else?
10:25:36 <nominolo> no, that should be it
10:25:39 <dcoutts> nominolo: so you can already get the format, and the width and height
10:25:44 <nominolo> right
10:25:46 <dcoutts> nominolo: so is it just the Ptr ?
10:25:54 <nominolo> yep
10:26:28 <nominolo> dcoutts: ok, well, we can't get the format yet
10:26:33 <nominolo> though, it's an enum
10:26:37 <nominolo> that should be trivial
10:26:43 <dcoutts> nominolo: ok, but you specify it when creating the surface
10:27:03 <nominolo> yes
10:27:30 <dcoutts> nominolo: and the docs would have to say that the Ptr is only valid while the surface exists
10:27:54 <nominolo> i'd have data SurfaceData a = SurfaceData Format (Int,Int) (Ptr a)
10:28:08 <nominolo> dcoutts: yes, i think so
10:28:11 <dcoutts> nominolo: why do we need a new data type?
10:28:20 <nominolo> dcoutts: to wrap it up?
10:28:21 <dcoutts> nominolo: we have functions to return each component already
10:28:23 <pchiusano> how do you convert a number to a string?
10:28:31 <dcoutts> pchiusano: show
10:28:32 <nominolo> pchiusano: show
10:28:49 <pchiusano> oh, duh.
10:28:52 <pchiusano> thx
10:28:57 <pchiusano> i knew that
10:28:58 <nominolo> dcoutts: ok, wrapping it up, could be done one level higher
10:29:09 <dcoutts> nominolo: yeah, fine
10:29:43 <dcoutts> nominolo: so the only thing I worry about is the lifetime of the image data
10:29:49 <nominolo> so, how do i get from C type: Ptr CUChar to Haskell type  Ptr a ?
10:29:53 <TomMD> Is there a tool that will point out (highlight in e-macs, for example) all instances of PFA?  I notice that accidential PFA (via too few arguments) cause confusing error messages in GHC.
10:30:07 <nominolo> dcoutts: yes, an alternative would be:
10:30:07 <dcoutts> nominolo: since there's no easy way to keep the Surface alive while using the raw data
10:30:31 <dcoutts> nominolo: withImageSurfacePixelData $ \ptr -> ...
10:30:52 <nominolo> dcoutts: cairo provides a function create_surface_for_data, which takes a data pointer and then renders to it
10:31:05 <nominolo> this way the user has to provide an object of the right size
10:31:17 <nominolo> but can control the lifetime
10:31:18 <dcoutts> nominolo: that'd be ok too, though again I think there is some issue with memory management
10:31:25 * dcoutts ponders
10:31:50 <nominolo> yes, it's tricky
10:32:42 <dcoutts> nominolo: so there we have the opposite issue, the caller must guarantee that the pixel data buffer exists as long as the Surface exists
10:33:43 <nominolo> yeah.  but it's probably better in practice, because you'd use it to do something with the data afterwards
10:33:52 <nominolo> preferably outside any withSurface..
10:36:28 <nominolo> how about some functions to allocate those pixel data thingies.  that way we could check if it's in use
10:37:46 <nominolo> though, i have no experience how ugly those kinds of reference counting schemes get in practice
10:37:53 <nominolo> it's probably not very compositional
10:38:46 <asus> helo ! i and magnitogorsk iz russia
10:38:58 <dcoutts> nominolo: we probably also need to bind cairo_image_surface_get_stride
10:40:16 <pchiusano> is there a way of doing sting interpolation in haskell?
10:40:29 <pchiusano> so I don't have to build up a giant expr using ++
10:40:45 <asus>          
10:40:47 <dcoutts> nominolo: ah hah! we can attach 'destructors' to cairo surfaces using cairo_surface_set_user_data
10:41:21 <asus>    
10:41:37 <mauke> pchiusano: what's wrong with ++?
10:42:19 <dcoutts> pchiusano: there's a printf function
10:42:19 <TomMD> I always have a line in my Haskell programs 'doublePlus = (++)'  just to be different, wordy, and inefficient.  Is it for any of those reasons you don't use ++?
10:42:25 <pchiusano> well, nothing, I guess it is just a little more verbose if you have a lot of variables you are inserting
10:42:51 <TomMD> dcoutts: Is the printf function unsafe?
10:42:54 <gkr> Is there any function like unwrap :: Maybe a -> a, unwrap (Just a) = a?
10:43:02 <mauke> @type fromJust
10:43:05 <lambdabot> forall a. Maybe a -> a
10:43:11 <jcreigh> TomMD: do you have any variables named "unGood"? :)
10:43:29 <dcoutts> TomMD: you can get runtime errors if the format string does not match the types of the supplied args, but no segfault unsafety like in C
10:43:30 <nominolo> dcoutts: oh, that looks good.  maybe i should take a look at other GC'd languages' bindings.  see how they did it
10:43:31 <gkr> mauke my prelud hasn't that function defined :-(
10:43:39 <mauke> @index fromJust
10:43:39 <lambdabot> Data.Maybe
10:43:56 <TomMD> Actually yes.  I wrote a program showing the goodness of haskell by defining functions and variables that when combined would read "doublePlus un good" and print 'ungood'.
10:44:11 <jcreigh> haha. excellent.
10:44:33 <pchiusano> :t printf
10:44:35 <lambdabot> forall r. (PrintfType r) => String -> r
10:44:51 <dcoutts> nominolo: so perhaps we could have a image surface constructor that takes a ForeignPtr
10:44:57 <monochrom> @remember TomMD I wrote a program showing the goodness of haskell by defining functions and variables that when combined would read "doublePlus un good" and print 'ungood'.
10:44:57 <lambdabot> Done.
10:45:27 <mauke> > printf "%s %s %s" "doublePlus" "un" "good" :: String
10:45:28 <lambdabot>  "doublePlus un good"
10:45:39 <nominolo> dcoutts: and how would we know when to free the data?
10:45:46 <dcoutts> nominolo: and then we'd save that ForeignPtr in a StablePtr and attach that to the surface, then when the surface goes away then we'd free the StablePtr which would allow the ForeignPtr to be GCd.
10:46:33 * ptolomy really hopes neil's Supero thing scales up well and easily integrates with GHC.
10:46:46 <ski> Supero ?
10:46:53 <dcoutts> nominolo: so we'd pass the StablePtr as the user_data and freeStablePtr as the destroy function (or rather a foreign exported function that calls freeStablePtr)
10:47:57 <sorear> ptolomy: you should have said something 13 minutes ago
10:48:05 <sorear> 10:33 -!- ndm [i=9020809b@gateway/web/cgi-irc/ircatwork.com/x-cc005a34fb91b394] has left #haskell []
10:49:28 <ptolomy> fudge.
10:49:41 <nominolo> dcoutts: hm, i have to read up on stable pointers.  btw, ocaml uses bigarrays and allows surfaces to be created based on bigarrays
10:50:00 <dcoutts> nominolo: do you know how bigarrays are managed?
10:51:36 <nominolo> not yet
10:54:27 <hstenstrom> Could someone help me understand, how to get SOEGraphics working on my Debian machine? (I have hugs installed, and there is a SOEGraphics.hs file in oldlib. SOEGraphics is used in The Haskell School of Expression by Paul Hudak.
10:56:44 <dcoutts> nominolo: actually the easier thing is to implement imageSurfaceGetPixelData by returning a ForeignPtr
10:57:16 <dcoutts> nominolo: at the same time we'd increment the surface's ref count and attach as a finaliser the function to decrement the surface ref count
10:57:57 <dcoutts> nominolo: that's much the easiest way
10:58:40 <nominolo> dcoutts: yes, sounds good
10:58:51 <dcoutts> much easier than binding the function to create an image surface from a user-supplied buffer (though that is useful anyway, but we don't need it yet)
10:58:58 <nominolo> dcoutts: i think ocaml bigarrays work like mutable unboxed arrays in haskell
10:59:14 <dcoutts> nominolo: right, pinned ByteArray#'s
11:00:19 <dcoutts> sorear: btw, was it you who was looking into some other leak in the cairo bindings a few months back?
11:00:58 <dcoutts> maybe not a leak, but some other memory management issue
11:01:34 <sorear> dcoutts: No.
11:01:43 <dcoutts> hmm, ok
11:01:56 * dcoutts doesn't remember who it was
11:02:14 * sorear has greppable local #haskell  logs
11:02:24 <monochrom> hstenstrom: I don't use hugs (personal reason). I install ghc6 and libghc6-hgl-dev from unstable. SOE is in the latter. "import Graphics.SOE".  Actually I lie, I don't use the debs or even debian, I build ghc and most libs myself.
11:02:45 <gkr> Can I not derive Num? If my thing is something like data A = A Int ?
11:03:01 <sorear> gkr: No, you can't derive Num.
11:03:06 <dcoutts> gkr: use newtype and -fglasgow-exts for generalised newtype deriving
11:03:25 <earthy> gkr: you can, but it won't be haskell'98 anymore
11:03:31 <ttt-> do you guys do every-day coding in haskell
11:03:33 <nominolo> dcoutts: oh, cairo surfeces already have a reference counter
11:03:36 <ttt-> or just research things
11:03:38 <dcoutts> nominolo: yep
11:03:43 <earthy> ttt: what do you consider 'every-day coding'?
11:03:50 <dcoutts> nominolo: which makes life much easier
11:03:51 <ttt-> i have no idea
11:03:55 <gkr> Thanks folks.
11:04:03 <monochrom> I write programs in haskell everyday.
11:04:18 <ttt-> big programs that connect to databases and GUIs
11:04:28 <dcoutts> ttt-: I code only in Haskell and C, and only in C because of binding to libs implemented in C
11:04:30 <ttt-> and run web services
11:05:01 <earthy> um, yeah, I don't do that
11:05:09 <earthy> :)
11:05:12 <pchiusano> you know how the naive way of concatenating a list of strings is quadratic
11:05:28 <pchiusano> concat strings = foldl (++) "" strings
11:06:15 <Saizan> > foldl (++) "" ["a","b","c"]
11:06:20 <lambdabot>  "abc"
11:06:22 <dcoutts> @src concat
11:06:22 <lambdabot> concat = foldr (++) []
11:06:32 <Saizan> > foldr (++) "" ["a","b","c"]
11:06:33 <lambdabot>  "abc"
11:06:48 <sorear> pchiusano: just use foldr
11:06:50 <pchiusano> is that more efficient?
11:06:56 <sorear> much
11:06:57 <monochrom> Yes.
11:07:02 <pchiusano> can you explain?
11:07:04 <dcoutts> pchiusano: O(n) vs O(n^2)
11:07:10 <Sgeo> > foldl' (++) "" ["a","b","c"]
11:07:11 <lambdabot>  "abc"
11:07:26 <Sgeo> > foldr' (++) "" ["a","b","c"]
11:07:27 <lambdabot>   Not in scope: `foldr''
11:07:38 <pchiusano> why is it O(n)
11:07:49 <Saizan> with foldr: ("a" ++("b" ++ "c")), with foldl (((""++"a")++"b")++"c"), can you see the difference?
11:08:12 <dcoutts> Sgeo: foldr' can't be defined sensibly for lists, since you naturally want to do foldr' from the back
11:08:38 <nominolo> dcoutts: ah, so we just we just call cairo_surface reference when we read a pointer to the data
11:08:40 <Saizan> well ("a"++("b"++("c"++""))) in teh first case, but it doesn't matter
11:08:54 <pchiusano> okay, so with foldr
11:09:12 <dcoutts> nominolo: yes and use newForeignPtr cairo_surface_destroy
11:09:13 <Sgeo> And with the ("a"++("b"++("c"++""))) then it knows that the first one is "a"?
11:09:13 <pchiusano> you build up this expression tree
11:09:31 <pchiusano> but eventually, you need to start evaluating the concatenations
11:09:50 <dcoutts> nominolo: c2hs does not help with importing a FinaliserPtr, you have to do that manually
11:10:03 <dcoutts> @hoogle newForeignPtr
11:10:04 <lambdabot> Foreign.Concurrent.newForeignPtr :: Ptr a -> IO () -> IO (ForeignPtr a)
11:10:04 <lambdabot> Foreign.ForeignPtr.newForeignPtr :: FinalizerPtr a -> Ptr a -> IO (ForeignPtr a)
11:10:04 <lambdabot> Foreign.ForeignPtr.newForeignPtr_ :: Ptr a -> IO (ForeignPtr a)
11:10:18 <Sgeo> From an imperative pov, it might look like foldl is more efficient?
11:10:19 <dcoutts> nominolo: you want Foreign.ForeignPtr.newForeignPtr
11:10:22 <Saizan> with foldl to get the first 'a' you need to go through 3 layers of (++)s, with foldr you just need one
11:10:26 <chessguy> hi all
11:10:27 <nominolo> dcoutts: ok, i' figure it out (or come back if i don't ;) )
11:10:31 <sorear> hi
11:10:55 <monochrom> From an imperative pov, the question does not exist.
11:10:58 <dcoutts> Sgeo: foldl is like a strict imperative loop, foldr is kind of like an on-demand iterator
11:11:29 <dcoutts> Sgeo: depending on the context, one may be more efficient than the other
11:12:28 <dcoutts> Sgeo: mostly it's to with the strictness of the function being used by the fold
11:12:39 <hkBst> is there a Haskell equivalent to SICP?
11:14:06 <chessguy> hkBst: not exactly equivalent, but you might check out YAHT and the haskell wikibook
11:14:09 <chessguy> ?where yaht
11:14:09 <lambdabot> http://darcs.haskell.org/yaht/yaht.pdf
11:14:11 <chessguy> ?where wikibook
11:14:14 <Sgeo> What's SCIP?
11:14:14 <lambdabot> http://en.wikibooks.org/wiki/Haskell
11:14:35 <MyCatVerbs> Sgeo: SICP
11:14:45 <chessguy> ?where tutorials
11:14:46 <lambdabot> I know nothing about tutorials.
11:14:47 <hkBst> Sgeo: http://en.wikipedia.org/wiki/Sicp
11:14:53 <MyCatVerbs> hkBst: and no, but that's irrelevant.
11:15:12 <monochrom> In a strict functional language like ML you still use foldr (++)
11:15:14 <chessguy> http://www.haskell.org/haskellwiki/Meta-tutorial is also good
11:15:16 <lambdabot> Title: Meta-tutorial - HaskellWiki
11:15:31 <hstenstrom> monochrom: Thank you, I will test ghc6. For some reason, I can't install libghc6-hgl-dev right now, because some dependency problem. I will wait until they are solved, rather than building myself.
11:15:33 <chessguy> ?where+ tutorials http://www.haskell.org/haskellwiki/Meta-tutorial
11:15:33 <lambdabot> Done.
11:15:35 <MyCatVerbs> hkBst: you can write Scheme-like code in Haskell if following SICP's your guide, and you don't want to use SICP as an introductory text for Scheme. 
11:15:38 <gkr> How can I find what functions I have to instance to be my type of an X class?
11:15:56 <mauke> read the docs for X
11:15:57 <MyCatVerbs> gkr: hit up lambdabot with @src class?
11:16:09 <chessguy> @src Num
11:16:09 <lambdabot> class  (Eq a, Show a) => Num a  where
11:16:10 <lambdabot>     (+), (-), (*)           :: a -> a -> a
11:16:10 <lambdabot>     negate, abs, signum     :: a -> a
11:16:10 <lambdabot>     fromInteger             :: Integer -> a
11:16:29 <mauke> that doesn't tell you which functions are optional
11:16:48 <MyCatVerbs> mauke: implement them all, you lazy swine! =D
11:16:53 <monochrom> @src Ord
11:16:53 <lambdabot> class  (Eq a) => Ord a  where
11:16:53 <lambdabot>     compare      :: a -> a -> Ordering
11:16:53 <lambdabot>     (<), (<=), (>), (>=) :: a -> a -> Bool
11:16:53 <lambdabot>     max, min         :: a -> a -> a
11:17:10 <monochrom> Right, in Ord, most of them are optional.
11:18:01 <MyCatVerbs> monochrom: it'll still be more efficient if you implement the lot =)
11:18:18 <monochrom> Yes.
11:19:00 <MyCatVerbs> Well, for some classes. I don't suppose there's much point implementing read by hand if you've already written readsPrec. 
11:19:01 <hkBst> MyCatVerbs: no, but you do want it as an introductory CS book
11:19:28 <MyCatVerbs> hkBst: so download PLT Scheme and use that instead. The lessons are totally transferrable.
11:21:26 <hkBst> MyCatVerbs: PLT Scheme instead of what?
11:21:46 <MyCatVerbs> hkBst: instead of attempting to replace the best damn textbook on the planet. :P
11:23:51 <hkBst> MyCatVerbs: no argument there :D What I really meant was "what is the best damn textbook using Haskell" :P
11:23:51 <MyCatVerbs> hkBst: besides, there are abuses of Haskell syntax that let you pretty much write Scheme code directly into ghci, provided you add enough brackets...
11:24:33 <MyCatVerbs> hkBst: only disadvantage of that is that several of the examples they show you which -ought- to freeze because of applicative-order evaluation don't. =D
11:25:32 <gkr> Thanks again.
11:25:37 <gkr> @src Integral
11:25:38 <lambdabot> class  (Real a, Enum a) => Integral a  where
11:25:38 <lambdabot>     quot, rem, div, mod :: a -> a -> a
11:25:38 <lambdabot>     quotRem, divMod     :: a -> a -> (a,a)
11:25:38 <lambdabot>     toInteger           :: a -> Integer
11:26:56 <monochrom> Bird "introduction to functional programming using haskell" is the damn best book using haskell. covers parser combinators, monad transformers, program derivation.
11:27:50 <hkBst> chessguy: thanks btw :)
11:28:12 <sieni> monochrom: sounds cool
11:28:19 <sieni> maybe I should get a copy
11:29:38 <hkBst> chessguy: what I'm really interested in is textbooks which teach not Haskell but CS and use Haskell throughout, SICP style
11:30:59 <MyCatVerbs> hkBst: you won't get one anywhere near as good as SICP. Learn the CS topics that SICP teaches from SICP and the topics that you can learn through Haskell practice from any good Haskell textbooks you find.
11:31:45 <monochrom> "CS" is broad. But I take it to mean: induction, equational reasoning, program derivation. So my suggestion has them all.
11:32:14 <mauke> and counterterrorists!
11:32:15 <monochrom> SICP misses out on equational reasoning and program derivation.
11:33:50 <hkBst> thanks monochrom, I somehow missed your suggestion the other time
11:34:41 <nominolo> hm, does c2hs have a built-in feature to construct FunPtr s from function names?  The #pointer directive doesn't like it
11:36:29 <nominolo> ie, like in: foreign import ccall "stdlib.h &free"  p_free :: FunPtr (Ptr a -> IO ())
11:42:10 <davidL> is there an Integral equivalent of Fractional's Infinity?
11:42:52 <Saizan> there's maxBound for Int, nothing for Integer
11:43:09 <davidL> ?t maxBound
11:43:09 <lambdabot> Maybe you meant: tell temp time tiny-url todo todo-add todo-delete topic-cons topic-init topic-null topic-snoc topic-tail topic-tell type . ft v
11:43:13 <roconnor> @hoogle infinity
11:43:13 <lambdabot> No matches found
11:43:17 <davidL> ?ty maxBound
11:43:19 <lambdabot> forall a. (Bounded a) => a
11:43:28 <davidL> > maxBound Int
11:43:29 <lambdabot>   Not in scope: data constructor `Int'
11:43:36 <davidL> > maxBound::Int
11:43:37 <lambdabot>  2147483647
11:43:57 <Saizan> > maxBound +1 :: Int
11:43:58 <lambdabot>  -2147483648
11:44:29 <davidL> I imagine throwing around those big numbers is slow
11:44:51 <sorear> huh?
11:44:56 <sorear> Int math is constant time
11:45:26 <pchiusano> where is foldl' ?
11:45:30 <sorear> Data.List
11:45:34 <mauke> @index foldl'
11:45:34 <lambdabot> Data.List
11:45:37 <pchiusano> do I need to import that?
11:45:40 <mauke> yes
11:45:52 <pchiusano> but not foldl
11:45:57 <mauke> @index foldl
11:45:57 <lambdabot> Data.List, Prelude
11:46:03 <mauke> foldl is in the Prelude
11:46:17 <pchiusano> ah, ok, thx
11:46:26 <davidL> how much faster are Ints than Doubles?
11:46:38 <mauke> they are?
11:46:54 <sjanssen> davidL: depends on your processor
11:47:07 <davidL> Oh ok.
12:11:38 <Baughn> Why is System.Environment.getArgs in IO? Would anything break if I unsafePerformIO it?
12:13:06 <Heffalump> Baughn: no
12:13:39 <Heffalump> in principle something not in IO can be evaluated at compile-time
12:13:49 <nominolo> "Inline C code can currently not contain any code blocks; i.e., only declarations as typically found in header files may be included." <-- *cry*
12:13:52 <Heffalump> but unsafePerformIO getArgs is pretty safe.
12:14:45 <twanvl> ?hoogle withargs
12:14:47 <lambdabot> System.Environment.withArgs :: [String] -> IO a -> IO a
12:15:26 <nominolo> dcoutts: where is the best place to add supporting C-wrappers?
12:15:28 <Heffalump> oh, I didn't know about that
12:15:34 <nominolo> s/add/put/
12:15:35 <Heffalump> well, don't do that and you'll be fine :-)
12:16:13 <Baughn> Indeed. I'm aiming to put an 'if debugMode' deep inside existing code, so..
12:28:04 <xic> Heffalump: i've seen code that does unsafePerformIO for reading environment variables
12:28:42 <Heffalump> I think it's been suggested as a way of getting true global variables, too
12:32:19 <chessguy> ?seen cale
12:32:19 <lambdabot> I saw cale leaving #oasis, #ghc, #haskell-overflow and #haskell 5d 48m 45s ago, and .
12:35:50 <xic> lambdabot bug?
12:36:49 <sorear> no, it's correct
12:36:55 <sorear> cale really hasn't been here
12:38:22 <xic> i meant the final "and". a sentance can never end with the word "and"
12:38:33 <xic> the exception being the sentance i just said :)
12:38:36 <chessguy> yours just did :)
12:38:37 <chessguy> haha
12:38:56 <xic> =]
12:38:59 <chessguy> ?remember xic a sentence can never end with the word "and"
12:39:00 <lambdabot> Done.
12:39:02 <dcoutts> nominolo: do we need a c-wrapper? what for?
12:39:10 <Korollary> @seen Cale
12:39:10 <lambdabot> I saw Cale leaving #oasis, #ghc, #haskell-overflow and #haskell 5d 55m 35s ago, and .
12:39:19 <jyp> @seen lambdabot
12:39:20 <lambdabot> Yes, I'm here. I'm in #friendly-coders, #dreamlinux-es, #xmonad, #unicycling, #perl6, #parrot, #oasis, #jtiger, #haskell-soc, #haskell-overflow, #haskell-blah, #haskell, #ghc, #gentoo-uy, #gentoo-
12:39:20 <lambdabot> haskell, #darcs and #scannedinavian
12:39:59 <jyp> @seen gabuzomeu
12:39:59 <lambdabot> I haven't seen gabuzomeu.
12:41:05 <chessguy> hmm. /whois lambdabot gives: [lambdabot] #dreamlinux-es #xmonad #darcs #ghc #unicycling #gentoo-uy #jtiger #haskell-overflow #gentoo-haskell #haskell #oasis #perl6 #parrot
12:42:21 <chessguy> almost the same, but it's not actually in #friendly-coders
12:43:25 <sorear> chessguy: It listens to PART and JOIN
12:43:34 <sorear> chessguy: did lambdabot get KICKed?
12:43:44 <chessguy> @bot
12:43:45 <lambdabot> :)
12:43:51 <Japsu> @b
12:43:51 <lambdabot> Maybe you meant: b52s babel bf botsnack brain bug . v
12:45:46 <mgabel> anyone alive?
12:46:02 <dcoutts> @arr!
12:46:02 <lambdabot> I'll crush ye barnacles!
12:46:16 <mgabel> talk like a pirate day is not yet :)
12:46:31 <dcoutts> mgabel: :-)  did you have a Haskell question?
12:46:34 <mgabel> yes
12:46:46 <dcoutts> ask away, don't bother asking if you can ask :-)
12:46:54 <mgabel> I only started playing with it yesterday, so assume ignorance
12:47:23 <mgabel> I have two lists of lists
12:47:48 <mgabel> and I want a function [[a]] -> [[a]] ->[[a]] that returns all combinations
12:48:11 <norpan> combinations in what way?
12:48:28 <mgabel> f [x1,x2,...] [y1,y2,...]  will give me [x1++y1, x1++y2, x2++y1, x2++y2,....]
12:48:42 <sorear> liftM2 (++)
12:48:44 <mgabel> xi and yi are lists, [Char]
12:49:12 <mgabel> yeah, like I said, it's new to me, hold on while I read the documentation
12:49:13 <norpan> mgabel: zipWith (++) I'd say
12:49:24 <thruspa> [(++) x y | x <- a , y <- b] ?
12:49:53 <norpan> > zipWith (++) [[1,2,3],[4,5,6]] [[7,8,9],[10,11,12]]
12:49:54 <mgabel> zipWith will not help, since it will give me [x1++y1, x2++y2,...] but not [x1++y2] for example
12:49:55 <lambdabot>  [[1,2,3,7,8,9],[4,5,6,10,11,12]]
12:50:01 <norpan> is that what you want
12:50:17 <norpan> oh, you want all combos
12:50:20 <mgabel> yes
12:50:48 <mgabel> now, I've written a recrusive function that does it
12:50:55 <mgabel> but there must be an elegant way for this
12:51:02 <thruspa> > [(++) x y | x <- [[1,2],[3,4]] , y <- [[5,6],[7,8]]]
12:51:03 <lambdabot>  [[1,2,5,6],[1,2,7,8],[3,4,5,6],[3,4,7,8]]
12:51:19 <dcoutts> mgabel: list comprehensions are the most simple and elegant way, like thruspa's solution
12:51:36 <mgabel> ok, I hvaen't got to that part yet in the book :)
12:51:52 <dcoutts> mgabel: read on! :-) list comprehensions are great
12:51:59 <mgabel> but it looks way better than my kludge
12:52:01 <DRMacIver> Isn't sorear's suggestion rather nicer than that?
12:55:07 <dcoutts> DRMacIver: it's shorter but not necessarily more comprehensible, especially to a beginner
12:55:25 <dcoutts> the list comp is immediately understandable
12:55:41 <mgabel> well, the liftM2 is over my head
12:56:38 <dcoutts> mgabel: come back to that solution after reading the chapter(s) on monads
12:57:05 <thruspa> Using liftM2 is elegant.
12:57:09 <mgabel> so I shall
12:57:27 <dcoutts> mgabel: ie you'd have a chance of understanding what liftM2 (++) means after groking monads, and in particular, the list monad
12:57:46 <mgabel> even without reading about list comprehension, though, I can sort of understand that solution
12:57:58 <thruspa> But I think it is equivalent to using list comprehensions, just interpreted in the List monad, isn't it?
12:58:06 <dcoutts> thruspa: yes
12:58:44 <dcoutts> thruspa: or equivalent to: (++) <$> a <*> b
12:59:01 <dcoutts> which is equivalent to liftM2 (++) a b
12:59:04 <Saizan> > let foo xs ys = concatMap (\x -> concatMap (x++) ys) xs in foo [[1,2],[3,4]] [[5,6],[7,8]]
12:59:04 <thruspa> eh? :-)
12:59:05 <lambdabot>  [1,2,5,6,1,2,7,8,3,4,5,6,3,4,7,8]
12:59:10 <Saizan> ops.
12:59:33 <dcoutts> though (++) <$> a <*> b has a somewhat more general type than liftM2 (++)
12:59:52 <sorear> lifA2 (++)
13:00:26 <dcoutts> @hoogle liftA2
13:00:28 <lambdabot> No matches found
13:00:37 <mgabel> ok, another simple thing
13:00:55 <dcoutts> sorear: does that live in Control.Applicative ? I've not seen it (though it's obvious what it does)
13:01:05 <mgabel> convert a string to a list of single-character strings: "abc" to ["a","b","c"]
13:01:25 <dcoutts> mgabel: try using another list comprehension
13:01:26 <mgabel> again it's easy to write a recursive function, and again it seems there should be an easier way
13:01:27 <ddarius> > map (:[]) "abc"
13:01:28 <lambdabot>  ["a","b","c"]
13:01:39 <dcoutts> mgabel: try and work it out yourself
13:01:50 <dcoutts> mgabel: as a list comp I mean
13:01:52 <mgabel> ok lets see
13:02:22 <mgabel> well that WAS easy
13:02:34 <mgabel> [[x] | x<-"abc"]
13:02:38 <dcoutts> right
13:02:45 <dcoutts> > [[x] | x<-"abc"]
13:02:46 <lambdabot>  ["a","b","c"]
13:03:53 <dcoutts> mgabel: and actually it corresponds directly to ddarius's solution
13:03:53 <fuzan> that's confusing if you dont' realize that [Char] == String
13:03:57 <cdsmith> Hmm.  Is it feasible to combine Data.Binary with Control.Concurrent.STM?
13:04:05 <sorear> dcoutts: yes
13:04:08 <fuzan> [['a'],['b'],['c']]
13:04:22 <Heffalump> cdsmith: to do what?
13:04:26 <dcoutts> mgabel: since list comprehensions are neat ways of writing combinations of map, filter and concatMap
13:04:38 <cdsmith> Heffalump: write a snapshot of a data structure with TVars in it?
13:04:51 <fuzan> cdsmith: that's how I'm writing a project of mine
13:04:54 <Heffalump> you'd need to extract the TVar data into IO first
13:05:04 <Heffalump> unless you want to do unsafe stuff
13:05:13 <dcoutts> sorear: I don't see why anyone would ever want to use liftAN, the <$>, <*> style is so much nicer
13:05:20 <Heffalump> it doesn't make sense to write out a TVar directly
13:05:32 <cdsmith> Heffalump: I don't want to do unsafe stuff.
13:05:36 <sorear> dcoutts: pointlessness.
13:05:58 <Heffalump> cdsmith: I wasn't suggesting you do, just noting that the only way you could write out anything direct from STM is to use it.
13:06:01 <dcoutts> Heffalump: cdsmith: Data.Binary does not involve IO
13:06:16 <Heffalump> dcoutts: sure, but writing out a file does.
13:06:25 <Heffalump> which was what I assumed was meant by "write a snapshot"
13:06:26 <cdsmith> Heffalump: So I'd need to define a different set of data types to hold the snapshot if the data first?
13:06:32 <Heffalump> cdsmith: yes.
13:06:47 <cdsmith> Heffalump: wow, that's a real pain actually.
13:06:50 <dcoutts> sorear: bah people take that too far
13:06:54 <Heffalump> can you parametrise your data structure over TVar?
13:07:03 <cdsmith> Heffalump: ?
13:07:11 <Heffalump> can you hpaste what you have?
13:07:36 <cdsmith> Umm sure, as soo as I figure out how to separate it from 500 lines if unrelated code.
13:07:37 <Heffalump> basically I'm suggesting adding a parameter to the datatype and replacing every TVar with the parameter
13:07:44 <Heffalump> then Foo TVar is your STM structure
13:07:55 <Heffalump> and Foo Id is your writeable structure
13:07:58 <cdsmith> Heffalump: Ah!  That sounds promising
13:08:11 <Heffalump> then you can write a fairly generic function to switch between them
13:08:37 <cdsmith> Heffalump: okay, I'll give that a try.
13:08:39 <Heffalump> don't worry about pasting it if you understand what I just suggested, I was just going to make my suggestion more concrete
13:10:04 <nominolo> dcoutts: i can only use create a finalizer on the _same_ type
13:10:16 <mgabel> thanks for the help, by the way
13:10:24 <nominolo> dcoutts: so instead I have to use ForeignEnvPtr (or so)
13:11:06 <nominolo> so, I somehow close over the surface and ignore the data pointer
13:11:38 <nominolo> i.e. the finalizer has type FunPtr (Ptr Surface -> Ptr UCChar -> IO ())
13:11:58 <Heffalump> am I right that there is no general function of type (MonadTrans t, Monad m1, Monad m2) => (m1 a -> m2 a) -> (t m1 a -> t m2 a) ? I'm trying to work out what it is about a monad transformer that makes that function implementable for a specific t.
13:12:09 <nominolo> though, to create sth. of type FunPtr I have to bind a c-function or allocate a wrapper
13:12:22 <nominolo> but i'd rather not allocate anything
13:14:34 <cdsmith> Heffalump: now I'm having problems with "deriving Eq" and I can't figure out how to contrain a to Eq-able things.
13:15:40 <Heffalump> are TVars Eq-able?
13:15:46 <cdsmith> Yes
13:15:59 <Heffalump> you shouldn't need to constrain it
13:16:07 <Heffalump> at least, the constraint should be picked up automatically when you try to use Eq
13:16:53 <cdsmith> Well, it clearly tells me I need an instance for Eq (a String)
13:17:32 <Heffalump> oh, I see.
13:17:38 <Heffalump> sorry, I'm wrong
13:17:48 <cdsmith> But adding to the data decl doesn't help
13:17:51 * Heffalump wonders how to add that to the type signature
13:18:04 <Heffalump> generally adding class constraints to the data decl is a waste of time
13:18:20 <Heffalump> I'm not sure if it's valid Haskell 98 to just add that constraint to the function definitions
13:18:37 <ddarius> ?
13:19:18 <cdsmith> ddarius: Trying to do something like 'data Wrapper a = W (a String) deriving Eq
13:20:50 <nominolo> !paste
13:21:06 <Heffalump> the grammar says you can just write that
13:21:18 <Heffalump> in the class context of any affected function
13:21:24 <Heffalump> bit annoying, but a one-time thing
13:21:44 <cdsmith> Heffalump: There are not affected function yet; ghc isn't even accepting the data statement.
13:21:49 <Heffalump> oh.
13:21:58 * Heffalump goes to read about deriving
13:22:34 <nominolo> dcoutts: http://hpaste.org/1908
13:23:10 <Heffalump> hmm, report doesn't say much
13:23:12 * Heffalump plays
13:25:50 <Heffalump> FWIW, it does work with -fglasgow-exts -fallow-undecidable-instances
13:25:51 <Heffalump> but..
13:26:52 <cdsmith> but?
13:27:02 <Heffalump> well, you might not be happy to switch those on
13:27:07 <Heffalump> if you are, go right ahead :-)
13:27:21 <Heffalump> it's hardly ideal, and it's annoying me, because I can't quite see what's non-H98 about it
13:27:32 <cdsmith> Well, if it's the only choice other than reimplementing all of the data structures, then yeah I will.
13:27:52 <Saizan> is there a paste?
13:28:15 <cdsmith> Saizan: For what Heffalump and I are discussing?
13:28:24 <Saizan> yes
13:28:32 <cdsmith> Saizan: data Wrapper a = W (a String) deriving Eq
13:29:30 <ddarius> What does happen if you put data (Eq (a String)) => Wrapper a = W (a String) deriving Eq with just -fglasgow-exts?
13:30:05 <cdsmith> ddarius: Still asks for undecidable instances
13:30:10 <Saizan> so you get instance Eq (a String) => Eq (W (a String)) where .. that's surely not h08
13:30:13 <Saizan> *98
13:30:33 <Heffalump> I can't intuitively see why that shouldn't be H98.
13:30:42 <ddarius> a = W?
13:30:47 <Heffalump> If you're in H98, there's only one way to reduce Eq (a String)
13:30:50 <Heffalump> no, a is a parameter to W
13:30:54 <ddarius> I know.
13:31:01 <Heffalump> oh, right
13:31:06 <Heffalump> that's not kind-correct
13:31:07 <Saizan> you can only have instance Class (T a b c) in h98
13:31:14 <ddarius> True.
13:31:15 <Heffalump> Saizan: that's when defining things
13:31:19 <Heffalump> I thought it could arise in context reduction
13:31:36 <ddarius> Saizan: Yes, but you can with just -fglasgow-exts
13:32:21 <Saizan> ddarius: we're agreeing
13:32:22 <Heffalump> my logic is that you can't reduce Eq (a String) until you know a, and once you do it will always be via the instance ... => Eq (Foo x)
13:32:48 <Heffalump> so there's none of the difficulties with context reduction that would normally make things non-H98
13:34:21 <Heffalump> foo a b = fmap strlength a == fmap strlength b
13:34:38 <cdsmith> Well, I guess I'm sticking with the "undecidable instances are my friends" viewpoint and forging on.
13:34:48 <Heffalump> gets inferred to have Eq (f b) as a constraint, where 'b' isn't mentioned anywhere in the type signature
13:34:57 <Heffalump> (strlength is just length specialised to String)
13:35:49 <cdsmith> Heffalump++
13:37:51 <matthew-_> so am I wrong with my scoping issue with associated types or is it just one of the issues of the partial implementation?
13:38:01 <dcoutts> nominolo: I don't understand why we need newForeignPtrEnv
13:38:45 <dcoutts> nominolo: note that you never use the extra environment parameter
13:38:53 <Saizan> (-fallow-undecidable-instances is not required only when your instance is problematic, but just when it doesn't follow the heuristic ghc uses to check if it's safe)
13:39:32 <nominolo> dcoutts: yes, but I want to return a foreign pointer to the data, not the surface
13:40:01 <nominolo> but the finalizer has to take a pointer of the same type
13:40:10 <dcoutts> hmm
13:40:26 <nominolo> newForeignPtr :: FinalizerPtr a -> Ptr a -> IO (ForeignPtr a)  -- a needs to be UCChar
13:41:54 <Heffalump> Saizan: yeah, it's not being able to do it in H98 that's annoying me. Once I've accepted -fglasgow-exts not much else bothers me :-)
13:42:05 <dcoutts> nominolo: yeah ok, fair enough
13:42:33 <nominolo> dcoutts: now i'm trying to figure out where to put that C-file and how to make that import declaration work
13:43:29 <Saizan> Heffalump: even h98 has its own "heuristic" :)
13:45:39 <dcoutts> nominolo: in a future c2hs release you'd be able to put the C code inline in the .chs file, but not yet
13:45:51 <nominolo> dcoutts: yes, unfortunately
13:46:07 <nominolo> dcoutts: seems like i have to magically add it to the makefile, for now
13:46:30 <Heffalump> Saizan: true :-)
13:46:37 <dcoutts> nominolo: see how we do it for gtk/Graphics/UI/Gtk/ModelView/Gtk2HsStore.c
13:47:31 <nominolo> dcoutts: in Makefile.in I guess?
13:47:44 <dcoutts> nominolo: Makefile.am in the gtk2hs root dir
13:48:14 <nominolo> ah, k
13:50:14 <Saizan> int-e: ping
13:50:16 <milagro> hi, I have a problem with typeOf which I don't understand
13:50:20 <milagro> when I use:
13:50:21 <milagro> result = Set.fromList([1])
13:50:21 <milagro> main = putStrLn(show(typeOf(result)))
13:50:30 <milagro> I get "Set Integer"
13:50:39 <milagro> but when I move typeOf to result definition:
13:50:45 <milagro> result = typeOf(Set.fromList([1]))
13:50:45 <milagro> main = putStrLn(show(result))
13:50:56 <milagro> I get an error
13:51:00 <milagro> runhugs: Error occurred
13:51:00 <milagro> ERROR "game-of-life.hs":10 - Unresolved top-level overloading
13:51:00 <milagro> *** Binding             : result
13:51:00 <milagro> *** Outstanding context : (Typeable b, Num b, Ord b)
13:51:24 <milagro> any idea what's going on?
13:51:26 <Heffalump> it just means it doesn't know what b should be
13:51:34 <Heffalump> without the Typeable constraint, the defaulting rules kick in
13:51:41 <Heffalump> but they don't work on Typeable, so they don't
13:51:51 <Heffalump> give a type signature for result and it'll be fine
13:51:56 <milagro> but how come the first source code works and the second doesn't?
13:52:04 <Saizan> ?type typeOf
13:52:07 <lambdabot> forall a. (Typeable a) => a -> TypeRep
13:52:07 <mauke> defaulting rules
13:52:07 <Heffalump> because of the defaulting rules
13:52:22 * milagro have to read about defaulting rules
13:52:59 <Saizan> also, in result the incognit b  was expressed in the type of result, instead in the second is hidden
13:53:20 <Saizan> s/result/first/
13:53:56 <int-e> Saizan: pong
13:54:33 <Saizan> int-e: have you tried compiling a program that imports Data.Binary with HEAD?
13:54:33 <milagro> what type should result have? TypeRep?
13:55:26 <Heffalump> sorry, it's not result that needs the signature
13:55:29 <Saizan> milagro: yes, but that won't help, you need result = typeOf (Set.fromList [1::Integer])
13:55:31 <Heffalump> it's the literal 1
13:55:38 <Heffalump> my mistake
13:55:54 <milagro> oh, I see
13:55:58 <Saizan> int-e: i get link errors
13:56:12 <milagro> it's because of "1" type
13:56:19 <int-e> Saizan: ah. yes, I get link errors as well
13:56:30 <milagro> if I use a string, it will work alright
13:56:35 <Saizan> int-e: ok, fine, known bug :)
13:56:35 <milagro> like:
13:56:36 <milagro> result = typeOf(Set.fromList(["a"]))
13:56:36 <milagro> main = putStrLn(show(result))
13:57:19 <milagro> Heffalump: you said that, it's because of literal 1, thanks!
13:57:41 <Saizan> ?type 1 -- because it's polymorphic
13:57:44 <lambdabot> forall t. (Num t) => t
13:57:52 <Heffalump> can someone explain why I can't write an instance of Eq for Wrapped a myself in H98?
14:00:38 <Heffalump> (in the grammar I can't write the necessary constraints, but I still don't quite see why I'm not allowed to)
14:02:04 <int-e> Saizan: apparently stg_* got renamed to hs_*
14:02:38 <matthew-_> int-e: (re this morning's conversation) it seems I can't make it work with an associate type either
14:07:36 <int-e> Saizan: try http://int-e.home.tlink.de/haskell/binary-ghc-6.7.2.patch
14:10:39 <int-e> matthew-_: oh, that's sad.
14:12:34 <matthew-_> int-e: it could be me. it could be features missing from the implementation. I've already found code in papers that you have to rewrite to make work in the current impl.
14:13:43 <davidL> can someone explain how DP can be done with out mutable types?
14:14:24 <ddarius> > let fibs = 0:1:zipWith (+) fibs (tail fibs) in fibs
14:14:26 <lambdabot>  [0,1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946,...
14:14:28 <mauke> davidL: just precompute the whole cache
14:14:51 <fasta> davidL: or use DiffArray
14:15:22 <ddarius> Lazy evaluation does what is needed in many (all?) cases.
14:15:27 <sorear> back.
14:15:46 <matthew-_> front.
14:16:01 <fasta> ddarius: AFAIK, lazy evaluation implementations use more than a constant factor more memory
14:16:07 <davidL> I want to convert a recursive function into DP
14:16:13 <int-e> > let foo = listArray (0,100) [f x | x <- [0..100]]; f 0 = 1; f 1 = 1; f x = foo ! (x-1) + foo ! (x-2) in foo ! 99
14:16:15 <lambdabot>  354224848179261915075
14:16:40 <fuzan> DP?
14:16:45 <int-e> just pretend that you already have all the results and put them into a suitable data structure - here it's an array.
14:17:05 <int-e> and let lazy evaluation take care of the rest.
14:17:07 <Lemmih> fuzan: Double penetration.
14:17:12 <fasta> Lemmih: :)
14:17:23 <fuzan> Lemmih: i beleived you for about 2 seconds.
14:17:27 <matthew-_> aka dynamic programming
14:17:28 <fasta> We talk about DP all day
14:18:00 <matthew-_> fasta: shame you only talk :-P
14:18:15 <ddarius> matthew-_: He said only all _day_.
14:18:31 <matthew-_> man, talk about fore play!
14:19:27 <sorear> @users
14:19:27 <lambdabot> Maximum users seen in #haskell: 340, currently: 308 (90.6%), active: 49 (15.9%)
14:21:28 <fasta> If that's DP, I wonder what WYSIWYG is :)
14:22:18 <ddarius> fasta: It's quite clear to me.
14:26:50 <monochrom> http://www.haskell.org/haskellwiki/Dynamic_programming_example
14:26:51 <lambdabot> Title: Dynamic programming example - HaskellWiki
14:28:02 <monochrom> Most of dynamic programming is write-once. You do not need full mutable.
14:28:35 <int-e> it's more akin to memoization really. in fact it can usually be formulated as a memoized, recursive function.
14:28:43 <davidL> can I be sure that lazy evaluation will do it correctly?
14:28:48 <monochrom> Yes.
14:29:10 <monochrom> In fact dynamic programming = recurrence + memoization. No more no less.
14:31:25 <monochrom> A problem with imperative programming is that you throw full mutability at all problems, and then you never reflect how much you really need.  Similarly OOP: you throw full existential, subtyping, inheritance, ... at all problems, then never think what is going on.
14:33:27 <beelsebob> roflcopters
14:33:40 <beelsebob> friend of mine decided that she has lots of CPU spare
14:33:44 <beelsebob> so she would set of on a grand scheme
14:33:47 <monochrom> Gimme some!
14:33:53 <beelsebob> to compute the finite state machine for chess
14:34:01 <fasta> Can you even have too much CPU?
14:34:02 <Heffalump> :-)
14:34:02 <monochrom> Noble cause.
14:34:06 <beelsebob> other friend and I informed her that the state space might be a bit large
14:34:09 <edward1> i hope she has some spare universes to run it in ;)
14:34:16 <beelsebob> which she went "nahh... can't be" to us
14:34:30 <beelsebob> we just computed the number of states to be... 497275065157795229721406525452498161822005325091061440
14:34:36 <fasta> Some universities are computing it now, AFAIK.
14:34:36 <monochrom> The process of investigation is valuable. Let her do it.
14:34:57 <Heffalump> fasta: where are they going to store it?
14:35:21 <edward1> checkers is closer to being storable as i recall
14:35:22 <monochrom> Blu-Ray.
14:35:35 <fasta> Heffalump: I don't remember the details, but google knows probably.
14:35:37 <Heffalump> and do they expect to answer whether chess is winnable?
14:35:40 <edward1> there are only a few moves in the middle of a checkers game before you get to 'known win' conditions
14:36:36 <int-e> @google chinook checkers
14:36:38 <lambdabot> http://www.cs.ualberta.ca/~chinook/
14:36:38 <lambdabot> Title: Chinook
14:36:42 <beelsebob> just to check I calculated it right... does this make sense to other people?
14:36:42 <beelsebob> > let {fac 0 = 1; fac x = x * fac (x - 1); positions = fac 64 `div` fac (64 - x)} in sum $ map [2..32]
14:36:46 <beelsebob> oops... fail
14:36:50 <lambdabot>   Not in scope: `x'
14:37:06 <beelsebob> > let {fac 0 = 1; fac x = x * fac (x - 1); positions x = fac 64 `div` fac (64 - x)} in sum $ map positions [2..32]
14:37:07 <lambdabot>  497275065157795229721406525452498161822005325091061440
14:37:24 <Heffalump> http://www.mathematik.uni-bielefeld.de/~sillke/SEQUENCES/series014 says 10^43
14:37:29 <lambdabot> http://tinyurl.com/ys5xz8
14:37:34 <edward1> well, not all of the states are reachable there beelse
14:37:42 <Heffalump> > length "497275065157795229721406525452498161822005325091061440"
14:37:43 <lambdabot>  54
14:37:44 <edward1> unless you allow for fischer style starting positions
14:37:57 <beelsebob> ah, that's legal positions
14:37:58 <Heffalump> even then you can't reach the ones with pawns on the first rank
14:38:07 <beelsebob> yeh
14:38:13 <edward1> yep
14:38:16 <Heffalump> or on the 8th, really
14:38:17 <beelsebob> so mine calculates all configurations of pieces on the beard
14:38:20 <beelsebob> board*
14:38:23 <beelsebob> lots aren't reachable
14:38:30 <Heffalump> did you consider pieces not being on the board?
14:38:34 <Heffalump> that's a 65th position
14:38:40 <Heffalump> (apart from for the king)
14:38:41 <edward1> no pawns on your back rank, on the 8th, certain pawn configurations can't be reached midboard even, etc.
14:38:57 <Heffalump> also, to be precise you have to consider 50 moves of history
14:39:03 <Heffalump> but that's probably abstractable away
14:39:04 <edward1> yeah
14:39:28 <Heffalump> actually, make that the entire history since the last piece capture or pawn move
14:39:44 <int-e> Heffalump: and 4 bits for the 4 castling moves.
14:39:51 <int-e> hmm.
14:40:05 <int-e> oh, make that an additional position for the rooks instead.
14:40:27 <edward1> though you can't get into all of those states, because you can't have castled with both of your rooks
14:40:34 <Heffalump> and of course the king doesn't need both of the bits
14:40:43 <Heffalump> s/both of the bits/the taken position/
14:40:50 <int-e> edward1: the bits would represent which castling moves are still allowed
14:40:52 <Heffalump> edward1: the idea is to represent whether the rook *could* castle
14:41:02 <Heffalump> once you castle both rooks can't castle
14:41:07 <edward1> fair enough
14:41:07 <Heffalump> or if the king moves
14:41:35 <int-e> but of course unless a rook is in a corner castling can't be allowed anymore. so it's a lot less than a bit
14:41:46 <Heffalump> right
14:41:59 <Heffalump> oh, and for pawns you need to track what they got promoted to
14:42:01 <edward1> then of course the bit is only needed if the rook is still in position, so we have a fractional number of bits, etc.
14:42:14 <Heffalump> edward1: hence int-e's suggestion of just having an extra position
14:42:17 <edward1> yeah
14:42:21 <Heffalump> there's "in the corner" and "castlable"
14:42:30 <int-e> edward1: an additional position for 'unmoved rook' is more appropriate (and you can do the same for the king)
14:42:31 <edward1> k
14:42:39 <Heffalump> you don't need to for the king
14:42:39 <edward1> i'll buy that
14:42:46 <Heffalump> just reset the rooks to uncastlable if it moves
14:42:54 <edward1> you just move both your rooks to the corners when you move the king
14:42:55 <edward1> that works
14:43:04 <edward1> er if they were 'castable'
14:43:11 <edward1> er castlable
14:43:17 <Heffalump> pawns also have the "can be taken en passant" state
14:43:21 <dmhouse> Heffalump, edward1: what's the problem you're discussing?
14:43:29 <Heffalump> enumerating chess positions
14:43:34 <edward1> enumerating the possible chess states
14:45:53 <fasta> Heffalump: I think they see it as a goal that might be achieved before 2100
14:45:59 <Heffalump> oh, right :-)
14:46:11 <Heffalump> I guess if Moore's law keeps going
14:46:30 * Heffalump goes to bed
14:46:37 <fasta> In theory one can compute infinitely fast, btw :)
14:47:07 <fasta> By infinite I mean: " as fast as you want"
14:47:43 <SamB> what theory is that? newtonian physics?
14:47:52 <fasta> SamB: no, warp theory :)
14:48:01 <fasta> SamB: a field started in 1994 :)
14:48:24 <SamB> how long do they say it will be before they have a warp core?
14:48:27 <sorear> I wish ghc wasn't so hard to build!
14:48:47 <matthew-_> I wish ghc was perfect
14:48:54 <SamB> GHC is hard to build?
14:48:56 <matthew-_> or at least had everything I wanted in it
14:49:02 <dmhouse> I wish the subjunctive were used correctly.
14:49:13 <fasta> SamB: they don't, since there's a practical problem: some particles needed for the trick only exist in theory.
14:49:28 <SamB> fasta: hmm?
14:49:47 <SamB> so you say the theory is bunk, or they just haven't figured out where to get the particles from?
14:50:24 <ddarius> SamB: The particles might not exist.
14:50:42 <SamB> ah. so the theory *might* be bunk
14:51:01 <fasta> SamB: Alcubierre, M. "The Warp Drive: Hyper-fast Travel within General Relativity," Classical and Quantum Gravity, 11(5), L73-77 (1994).
14:51:23 <ddarius> fasta: Anything online?
14:51:27 <fasta> SamB: I am saying I am not qualified to have an expert opinion on it.
14:51:30 * ddarius is too lazy to Google.
14:51:32 <fasta> ddarius: yes, lots of it.
14:51:49 <fasta> ddarius: the wikipedia article on it references it (archiv.org)
14:52:08 <ddarius> fasta: Any recommendations?
14:52:58 <fasta> ddarius: The first article is nice, but difficult to understand details.
14:53:06 <fasta> ddarius: I will get a link for you
14:53:54 <fasta> ddarius: http://members.shaw.ca/mike.anderton/WarpDrive.pdf
14:54:19 <fasta> http://arxiv.org/pdf/gr-qc/0107097
14:54:24 <SyntaxNinja> hi everybody
14:54:32 <ddarius> hi Dr. Jones!
14:54:39 <fasta> I was surprised that someone even thought of this stuff already.
14:55:00 <ddarius> fasta: People think of all kinds of crazy stuff
14:55:18 <fasta> ddarius: yes, so do I.
14:56:18 <ddarius> fasta: The surprising thing is that some people get paid to think of this crazy stuff
14:57:09 <fasta> ddarius: unfortunately this happens less and less
14:57:40 <fasta> ddarius: most of the articles on "warp theory" aren't funded
14:58:45 <fasta> ddarius: all articles relating the topic: http://omnis.if.ufrj.br/~mbr/warp/
14:58:47 <lambdabot> Title: Marcelo B. Ribeiro's Page on "Warp Drive Theory"
15:01:37 <wchogg> Heh.  My GR is a bit rusty, but I believe Alcubierre's paper doesn't really present a spacetime that obey's Einstein's field equations.
15:02:22 <wchogg> If I remember right it requires a negative energy density...and there was some other condition that I don't remember.
15:02:55 <fasta> wchogg: he admits that he does that.
15:03:13 <SamB> negative energy density?
15:03:29 <ddarius> SamB: Negative mass so to speak.
15:04:45 <wchogg> fasta:  I don't remember the paper very well.  It was probably 4-5 years ago when I last looked at it.
15:05:48 <SyntaxNinja> ddarius: 'sup? :)
15:06:15 <ddarius> SyntaxNinja: Nothing good, you?
15:06:34 <xtofs> hi
15:07:05 <sorear> hello xtofs
15:24:46 <SyntaxNinja> ddarius: just doing various little tasks.
15:30:41 <sorear> SyntaxNinja: How's the haskell community server project coming/
15:33:36 <int80h> http://hpaste.org/1910?lines=true#a0
15:33:53 <int80h> I guess I didn't select the announce feature
15:34:34 <int80h> any ideas?
15:34:38 <SyntaxNinja> sorear: well, we got it, and then they accidentally disabled it, and then reenabled it!
15:34:46 <SyntaxNinja> but we haven't done anything with it yet.  I'll try to kick start that actually.
15:35:17 <sorear> SyntaxNinja: What does it mean to disable a server?
15:36:15 <int80h> anyone want to help me out with my hugs server problem?
15:36:38 <SyntaxNinja> sorear: well, it's a virtual server, so they just stopped the virtual machine (the colo)
15:37:03 <SyntaxNinja> they're all like "You haven't paid!" and I was all like, "er, yeah I did" and they were all like "oops"
15:37:41 <sorear> ok, makes more sense
15:38:02 <sorear> I'm still stuck with a mental image of a computer sitting under a desk somewhere :)
15:44:48 <SyntaxNinja> sorear: that's so 2006 ;)
15:45:18 <monochrom> Now they hide under your bed.
15:46:13 <monochrom> "Mom, I think a computer is hiding under my bed!" "It's okay, it doesn't bite, it holds your blog." "So it's a friend?" "Yeah!"
15:46:38 <fasta> This seems to loop forever: http://pastebin.ca/497555 I am pretty sure that when the input is correct that it shouldn't loop, though.
15:47:16 <fasta> So, I guess the input isn't correct, but thanks to the great debugging tools of GHC, it's next to impossible to find the error.
15:48:04 <monochrom> You have to solve a puzzle on rec.puzzle to enable the debugger.
15:48:59 <monochrom> t <- val ref_tree   should this be ref_t ?
15:49:51 <monochrom> Indeed, I think that folds it.
15:50:03 <sorear> fasta: just fyi, there is a #haskell pastebin
15:50:30 <fasta> monochrom: yes, thanks.
15:50:52 <fasta> I guess I shouldn't program this late :)
15:51:21 <int80h> how do I use the #haskell pastebin?
15:51:24 <fasta> sorear: I know, but the Haskell pastebin holds information forever.
15:51:26 <ari> !paste
15:51:33 <int80h> !paste
15:51:44 <ari> Hmm, the bot isn't here
15:51:47 <ari> hpaste.org/new
15:51:51 <sorear> fasta: is this a problem?
15:51:53 <fasta> @paste
15:51:54 <lambdabot> Haskell pastebin: http://hpaste.org/new
15:52:01 <int80h> oh I have one already but it didn't announce
15:52:04 <int80h> but here it is
15:52:11 <sorear> fasta: what if I'm reading the logs in ten years time.
15:52:17 <int80h> http://hpaste.org/1910
15:52:25 <int80h> looks like I need to link to something
15:52:27 <sorear> fasta: do you want to deprive me the contextual information of your paste?
15:52:31 <int80h> and I don't know what
15:56:29 <int80h> can someone tell me what I should be linking to?
15:56:31 <davidL> int80h: the hpaste bot that is supposed to announce is sleeping
15:57:04 <davidL> what you linked above was fine
15:57:42 <davidL> more importantly, how do I make something a global variable from within main?
15:59:16 <int80h> no I mean, it seems I am not linking something, thus the compiler error
15:59:26 <int80h> so maybe I am missing something, like something else to link
15:59:34 <davidL> oh lol, I thought you meant url
16:01:04 <davidL> you could try asking in ##c
16:02:03 <int80h> well this is for a haskell server so I figured I am in the right place
16:07:05 <davidL> #haskell ?
16:27:57 <matthew-_> int-e: it's definitely a bug in the current implementation of type families. There's no reason not to allow the class head ty vars to extend over the rhs of a constructor. I think.
16:55:16 <pchiusano> hello!
16:56:23 <sorear> hello!!
16:56:29 <pchiusano> hi sorear
16:56:38 <pchiusano> is there a list flatten?
16:56:42 <ddarius> concat
16:56:56 <pchiusano> not quite what I want
16:57:10 <pchiusano> > concat [[[1]], [[2]]]
16:57:12 <lambdabot>  [[1],[2]]
16:57:21 <pchiusano> I want it to return [1, 2]
16:57:29 <pchiusano> concat just does 1 'level'
16:57:34 <sorear> > concat (concat [[[1]], [[2]]])
16:57:34 <lambdabot>  [1,2]
16:57:39 <pchiusano> hehe
16:57:41 <Korollary> join?
16:57:47 <ddarius> I think you could make a type class for it.
16:58:23 <pchiusano> ddarius, can you explain?
16:58:31 <ddarius> It would be very tricky, perhaps impossible, to deal with the overlapping though...
16:58:53 <sorear> ddarius: Very tricky, perhaps impossible, to deal with the ambiguity.  Remember 1 is overloaded
16:58:55 <IvdSangen> an iterating function would be nicer I think
16:59:12 <sorear> ddarius: and defaulting doesn't work when user classes are involved
16:59:14 <pchiusano> :i join
16:59:22 <pchiusano> > :i join
16:59:22 <lambdabot>  Parse error
16:59:28 <pchiusano> umm
16:59:35 <sorear> pchiusano: that's not valid haskell
16:59:44 <sorear> IvdSangen: alas, that can't be made to work well without dependent types
16:59:54 <ddarius> sorear: That's rather irrelevant to what I'm thinking of.
17:00:14 <IvdSangen> well, with using a Just | Maybe it's quite nice I
17:00:18 <IvdSangen> guess
17:00:18 <sorear> > let { iter 0 f = id ; iter k f = f . iter (k-1) f } in iter 2 concat [[[1]]]
17:00:19 <lambdabot>      Occurs check: cannot construct the infinite type: a = [a]
17:00:20 <lambdabot>       Expected...
17:01:16 <pchiusano> I guess lambdabot does not understand ghci commands... :)
17:01:17 <monochrom> join is in Control.Monad. join :: (Monad m) => m (m a) -> m a
17:01:45 <sorear> pchiusano: Lambdabot deliberately rejects ghci commands.
17:01:51 <monochrom> lambdabot only knows :t.  It doesn't even know :type, you have to say @type
17:01:55 <sorear> it's a security thing
17:01:59 <pchiusano> huh.
17:02:12 <monochrom> Try it!
17:02:19 <pchiusano> : 42
17:02:22 <sorear>  :t is not passed directly to ghci - it is parsed by lambdabot
17:02:32 <pchiusano> > :t 42
17:02:32 <lambdabot>  Parse error
17:02:36 <pchiusano> oop
17:02:38 <monochrom> :t 42
17:02:40 <lambdabot> forall t. (Num t) => t
17:02:40 <pchiusano> :t 42
17:02:42 <lambdabot> forall t. (Num t) => t
17:02:46 <monochrom> :type 42
17:02:50 <ddarius> You can do, class Concatable a where deepConcat :: [[a]] -> [a]; instance Concatable a => Concatable [a] where deepConcat = concatMap deepConcat; instance Concatable Int where deepConcat = concat, etc for all base types, or somesuch.
17:02:50 <monochrom> @type 42
17:02:53 <lambdabot> forall t. (Num t) => t
17:03:09 <ddarius> You could also make a "generic" concat.
17:03:44 <matthew-_> sorear, ddarius: you guys normally manage to educate me on why what I want can't be done. Do you know what the deal is with my associated types issue is? http://www.haskell.org/pipermail/haskell-cafe/2007-May/025630.html
17:03:46 <lambdabot> Title: [Haskell-cafe] Scope of type variables in associated types, http://tinyurl.com/2gufja
17:04:03 * ddarius hasn't looked at associated types at all.
17:04:17 <pchiusano> ddarius, explain "you could make a generic concat'?
17:05:04 <ddarius> With Typeable or some other scheme you should be able to make a concat that determines it's depth dynamically.
17:05:52 <pchiusano> determines it's depth dynamically?
17:06:29 <ddarius> Essentially it looks at the type (via Typeable) and goes "Hey this is a thrice nested list so we want concat . concat"
17:06:56 <pchiusano> oh, but that won't handle lists with different levels of nesting
17:07:07 <pchiusano> like [1, [2, [3]], [4, 5]]
17:07:16 <matthew-_> that's not a valid value
17:07:23 <matthew-_> > [1, [2, [3]], [4, 5]]
17:07:24 <lambdabot>   add an instance declaration for (Num [t])
17:07:24 <lambdabot>     In the expression: 5
17:07:24 <lambdabot>     In t...
17:07:34 <matthew-_> this isn't erlang ;)
17:07:37 <ddarius> pchiusano: Actually this approach would and the other approach wouldn't except that as matthew-_ pointed out you can't even have that.
17:07:42 <pchiusano> oh, damn, you are right
17:07:53 <ddarius> If you want Rose trees they are there.
17:08:06 <ddarius> @src Data.Tree.Tree -- rolls the dice
17:08:06 <lambdabot> Source not found. And you call yourself a Rocket Scientist!
17:08:09 <ddarius> Bah.
17:08:21 <matthew-_> @src Data.Tree.Forest
17:08:21 <lambdabot> Source not found. And you call yourself a Rocket Scientist!
17:08:24 <matthew-_> drat
17:08:32 <matthew-_> it's in Data.Tree anyway ;)
17:08:43 * matthew-_ calls it quits and heads to bed
17:09:15 <pchiusano> okay
17:09:32 <pchiusano> @src product
17:09:33 <lambdabot> product = foldl (*) 1
17:13:14 <monochrom> @src Either
17:13:14 <lambdabot> Source not found. This mission is too important for me to allow you to jeopardize it.
17:13:24 <monochrom> Looks like you can @src a data type.
17:13:31 <sorear> @src IO
17:13:31 <lambdabot> newtype IO a = IO (State# RealWorld -> (# State# RealWorld, a #))
17:14:31 <monochrom> Looks like I had a Freudian slip that corrected me.
17:15:37 <pchiusano> @src lookup
17:15:38 <lambdabot> lookup _key []          =  Nothing
17:15:38 <lambdabot> lookup  key ((x,y):xys) | key == x  = Just y
17:15:38 <lambdabot>                         | otherwise = lookup key xys
17:17:47 <atp> hey guys, i'm trying to write a function monadFlip :: Monad m => [m a] -> m [a] which does what's expected (makes a list of monadic elements into a monadic list of elements).
17:18:00 <sorear> sequence
17:18:05 <sorear> @type sequence
17:18:14 <lambdabot>     Ambiguous occurrence `sequence'
17:18:14 <lambdabot>     It could refer to either `sequence', imported from Control.Monad.Writer
17:18:15 <sorear> monadFlip = sequence
17:18:19 <sorear> @type Prelude.sequence
17:18:22 <lambdabot> forall (m :: * -> *) a. (Monad m) => [m a] -> m [a]
17:18:44 <atp> ah... that's cool, because i couldn't exactly figure out how to write a recursive definition for it
17:18:56 <pjd> @source Prelude.sequence
17:18:57 <lambdabot> Prelude.sequence not available
17:19:03 <pjd> @source sequence
17:19:03 <lambdabot> sequence not available
17:19:13 <atp> @src Prelude.sequence
17:19:13 <lambdabot> Source not found. Where did you learn to type?
17:19:34 <atp> well, hey, maybe one of you can help me understand it?  let me explain what i have so far
17:20:05 <atp> monadFlip [mx, my, mz] = mx >>= \x -> my >>= \y -> mz >>= \z -> return [x, y, z]
17:20:13 <atp> obviously, there's a pattern here
17:20:35 <monochrom> monadFlip [] = return []   you probably guessed so
17:20:41 <atp> yeah
17:20:42 <sorear> @src sequence
17:20:42 <lambdabot> sequence ms = foldr k (return []) ms
17:20:42 <lambdabot>     where
17:20:42 <lambdabot>       k m m' = do { x <- m; xs <- m'; return (x:xs) }
17:20:56 <monochrom> monadFlip (mx:ms) = can you complete this?
17:21:17 <monochrom> It's going to be like mx >>= \x -> ...
17:21:48 <atp> monochrom: that's what i was trying to figure out... mx >>= \x -> (liftM2 (++)) (return [x]) (monadFlip mxs) ?
17:21:58 <atp> hm
17:22:05 <atp> that works maybe, hey?
17:22:33 <atp> maybe better to use : ?
17:22:34 <monochrom> ... should be a recursion that replaces your my >>= ... return something
17:22:53 <atp> > liftM2 (:)
17:22:54 <lambdabot>  Add a type signature
17:23:30 <atp> monochrom: does my idea not work?
17:23:45 <monochrom> Yes.
17:23:54 <atp> but maybe there's a better way?
17:24:14 <atp> ++ is kind of expensive
17:24:32 <monochrom> liftM'ing a return is also kind of redundant.
17:24:45 <atp> yeah
17:24:57 <atp> good point
17:25:33 <atp> maybe mx >>= \x -> monadFlip mxs >= \xs -> return (x:xs) ?
17:25:42 <atp> >>= even
17:25:51 <monochrom> Yeah that's the classical solution
17:25:58 <atp> thanks monochrom :)
17:26:35 <monochrom> The foldr version summoned by sorear is obtained by recognizing this recursion pattern to be a foldr.
17:27:19 <monochrom> liftM (x :) (monadFlip mxs)   is in a style closer to yours, and no redundancy.
17:27:21 <atp> i guess it does look like  ( ... (... ( ... ( ... ))))
17:27:42 <atp> but foldr is implemented recursively anyway, right?
17:28:19 <monochrom> Oh, what am I thinking?  monadFlip (mx:mxs) = liftM2 (:) mx (monadFlip mxs)
17:28:43 <atp> hey! that's nice
17:29:17 <monochrom> monadFlip mxs = foldr (liftM2 (:)) (return []) mxs   :)
17:29:38 <ddarius> monadFlip = foldr (liftM2 (:)) (return [])
17:30:06 <atp> i guess the Prelude definition of sequence doesn't want to depend on Control.Monad so it doesn't use liftM2, huh?
17:30:13 <monochrom> The "k m m' = ..." above is simply liftM2 (:)
17:30:23 <monochrom> OH! Point.
17:30:44 <monochrom> But it's educational to see it's a foldr.
17:31:05 <atp> yeah.  i'm still not good at recognizing these things, but i guess it comes with practice.
17:32:02 <atp> anyway, thanks a lot for your help
17:32:06 <atp> and you too ddarius :)
17:34:02 <ddarius> Yeah, the time I don't actually help...
17:35:45 <newsham> I'm thinking about reasoning about haskell code to eliminate errors and I came across a hard one -- stack overflow runtime exceptions.
17:36:01 <newsham> Seems like it would be hard to reason about wether this type of exception can happen or not
17:36:50 <newsham> (for example,  lets say you define "fact" as Int -> Int in the normal recursive way.  in a termination proof you can say that it will always terminate because counting down to zero can always work in modulo arithmetic)
17:36:58 <newsham> (ignoring for the time being that the result would be wrong)
17:36:59 <SamB_XP> you'd have to be able to reason about how much stack a computation could take
17:37:06 <newsham> but, fact -1 gives a stack overflow
17:37:20 <newsham> samb: yah, over every single function in the program... :\
17:37:20 <ddarius> newsham: Not with enough stack
17:37:25 <MyCatVerbs> newsham: not if you implement it tail-recursively. =)
17:37:31 <monochrom> If you increase the stack beyond 4G it will not overflow.
17:37:48 <MyCatVerbs> monochrom: that would be... awkward.
17:37:53 <SamB_XP> monochrom: is that some kind of obscure joke?
17:37:58 <monochrom> It's hypothetical.
17:37:59 <matthew-_> yep. The JVM does some stack bounds checking at link time, but that's only for each method call.
17:38:01 <newsham> ddarius: i can prove that my stack size is always less than the number of integers my cpu handles ;-)
17:38:05 <SamB_XP> like, it would wrap around instead?
17:38:06 <MyCatVerbs> monochrom: more like 16G or 32G, considering the size of a stack frame.
17:38:18 <SamB_XP> I bet that joke is architecture dependant!
17:38:25 <ddarius> newsham: What you want to prove is the asymptotic behavior of the stack.
17:38:28 <atp> monochrom: that would require larger than 32-bit addressing, in which case -1 would probably be 64-bit 2's complement
17:38:28 <monochrom> For some suitable value of 4G.
17:38:31 <davidL> how do I make something a global variable from within main?
17:38:36 <MyCatVerbs> monochrom: and *then* you have to contend with the fact that a 64bit machine (which you'd need to get all that addressing space) has much larger integers. x_x
17:38:49 <newsham> so thats another thing.. I dont really have a good notion of how haskell recursive code maps onto the real machine in terms of real recursion that uses the stack
17:38:49 <ddarius> davidL: You don't.
17:38:51 <monochrom> Ah, sounds like an uphill battle.
17:38:52 <MyCatVerbs> "Suitable value of 4G" <-- I like that expression. =)
17:39:00 <monochrom> hee hee hee
17:39:21 <davidL> ddarius: I can't? or it's _better_ if I pass it as a parameter?
17:39:33 <monochrom> OK, it is possible to reason about time and space costs of Haskell programs. Seems hard but mitigated with a suitable calculus.
17:40:04 <ddarius> davidL: Depending on what you mean by "global" you can't and it doesn't really make sense.  So, what do you mean/what are you trying to do?
17:40:16 <newsham> ok, now lets assume i was sick and I really wanted to reason about stack space.
17:40:26 <MyCatVerbs> > let { f 0 = id; f n = (n*); fac = f 1 } in fac 500
17:40:28 <lambdabot>  500
17:40:31 <newsham> what am I going to need to know?  am I going to have to understand spineless-tagless g-machine well?
17:40:35 <MyCatVerbs> Wait, balls. Dammit.
17:40:48 <monochrom> Such as calculus is a generalization of termination proofs.  But the generalization consists of some leap.  You don't easily recognize it.
17:40:52 <ddarius> newsham: All you need is a model that has a stack in it.
17:41:05 <ddarius> newsham: You don't need it to be precise.
17:41:12 <newsham> for example, i dont really understand the space difference of rfold and lfold yet.
17:41:22 <newsham> foldr/foldl whatever
17:41:35 <pjd> newsham: they operate from oppose ends?
17:41:48 <monochrom> foldl (+) and foldr (+) have no space difference anyway.
17:41:49 <pjd> oh, nevermind
17:41:49 <newsham> yes i understand that, and I understand in normal strict evaluation how it works :)
17:41:57 <ddarius> newsham: Except that the stack isn't very explicit, you can understand them simply by unfolding the calculation.
17:41:58 <davidL> ddarius: did you say anything in reply that I might have missed?
17:42:03 <newsham> but in non-strict i get confused ("too many thunks" would make a nice tshirt)
17:42:16 <ddarius> Using an abstract machine with a stack, it will be more apparent.
17:42:39 <ddarius> [19:38] <ddarius> davidL: Depending on what you mean by "global" you can't and it doesn't really make sense.  So, what do you mean/what are you trying to do?
17:42:57 <newsham> has there been any work into making space guarantees on haskell code (ie. programmatica?)
17:43:33 <monochrom> foldl (+) 0 [1,2]  -> after several steps ->  (0+1)+2.  Only then the summing begins.  You can see how that consumes memory.
17:43:55 <davidL> ddarius: I will pass it as a parameter then, thanks
17:44:05 <monochrom> foldr (+) 0 [1,2] -> after several steps -> 0+(1+2).  You can also see its cost.
17:44:57 <ddarius> newsham: On reduced Haskell languages.  You'd need to help any analysis for Haskell.
17:45:20 <newsham> i would consider using a language subset
17:45:28 <newsham> got any references?
17:45:55 <newsham> I would like to spend some time writing a (small) program that cannot throw any runtime exceptions
17:46:00 <monochrom> Here we are using the fact that (+) is strict. When you ask the computer to evalute "blah + bleh", the computer can't help but dig into blah and bleh first.  This doesn't hold for some operators such as :
17:46:25 <pjd> newsham: sounds like total functional programming?
17:46:45 <newsham> mono: see, its things like that.. "... if you're using (+) which is strict...".  I dont have a good grasp of all of the if's
17:47:06 <newsham> pjd: yah, i'd probably want a total function so I can use HOL on some proofs
17:47:08 <monochrom> OK. You will need to.
17:47:23 <newsham> mono: any recommendations on where to start digging?
17:47:40 <ddarius> newsham: Googling real-time Haskell with quotes placed appropriately should wokr.
17:47:46 <newsham> thank you
17:47:59 <pjd> newsham: have you looked at David Turner's work?
17:48:03 <newsham> not at all.
17:48:08 <ddarius> pjd: No, total functional programming doesn't care about resource usage.
17:48:24 <ddarius> Albeit, in a strongly normalizing language such things should be much easier to analyze.
17:48:31 <newsham> pjd: anything in particular?
17:48:44 <ddarius> newsham: If you don't find anything, tell me and I'll find what I'm talking about.
17:48:55 <pjd> newsham: well, the total functional programming stuff :)
17:49:05 <pjd> like ddarius said, it's probably not directly relevant
17:49:17 <pjd> but it's very interesting nonetheless
17:49:37 <newsham> i'll look into it
17:49:50 <pjd> the basic idea is the elimination of bottom
17:49:58 <newsham> "total functional programming" as in "functions are total" as in "HOL" ?
17:50:03 <pjd> (as i understand it)
17:50:11 <pjd> HOL?
17:50:18 <monochrom> hol.sf.net
17:50:18 <newsham> higher order logic (of total functions)
17:50:46 <pjd> sounds like it
17:51:11 <newsham> isabelle (proof assistant) supports HOL (among others):  http://www.cl.cam.ac.uk/research/hvg/Isabelle/logics.html
17:51:13 <lambdabot> Title: Logics
17:51:21 <newsham> i may be using that for some things
17:51:54 <newsham> havent seen hol.sf.net before, thanks.
17:54:33 <monochrom> "A Natural Semantics for Lazy Evaluation", "A Space Semantics for Core Haskell", "Strictness analysis aids time analysis"
17:55:24 <newsham> i just found the 2nd of those.. looks interesting
17:55:24 <monochrom> Oh, isabelle is a cousin of hol.  also isabelle has type classes, which hol misses.
17:56:48 <newsham> programatica uses a different proof assistant (agda? alfa?  I forget) which seems more tightly integrated (automated translation)
17:56:54 <newsham> but i havent looked into it in much detail yet
17:57:00 <monochrom> Authors are John Launchbury for the first, Phil Wadler for the third.
17:58:19 <newsham> http://ogi.altocumulus.org/~hallgren/Programatica/HCSS04/
17:58:21 <lambdabot> Title: An Overview of the Programatica ToolSet
18:09:55 <TomMD> newsham: If you learn plover really well then perhaps you could make a wikibook entry.
18:32:42 <newsham> tommd: i'll keep that in mind :)
18:45:06 <Svrog> does ghc have to be compiled with some special switch somewhere in build.mk to support smp and the -N  RTS option?
18:45:50 <Svrog> the prebuilt binaries for windows dont seem to support it anymore
18:46:50 <sorear> Svrog: you should never pass -N to the compiler
18:46:58 <Svrog> no no
18:47:00 <sorear> Svrog: pass it to the compiled program
18:47:02 <Svrog> i mean to the final program
18:47:05 <Svrog> compile it with --threaded
18:47:16 <Svrog> then pass +RTS -N <number of threads> -RTS to the program
18:47:17 <Svrog> yes
18:47:21 <Svrog> doesnt work
18:47:32 <Svrog> it used to with 6.6 prebuilt binaries
18:47:34 <sorear> just -threaded, one -
18:50:02 <Svrog> just tried it again and its definitely not working
18:50:15 <Svrog> about to try the prebuilt os x binaries
18:57:38 <Svrog> so is there a switch in build.mk to enable support for the -N RTS option?
19:10:58 <MyCatVerbs> Ow, ow, my head.
19:11:19 <ddarius_> Drive nails with a hammer, not your head.
19:11:47 <MyCatVerbs> Referential transparency means you can replace any function f with any function g provided g always maps the same inputs to the same outputs as f, right?
19:12:14 <MyCatVerbs> Referential transparency also applies to the IO monad, though. Haskell is awesome like that.
19:13:15 <MyCatVerbs> But one problem. You are -never- going to be able to feed both f and g the same universe to see if they give the same results for the same inputs. Can't be done, because the universe will have changed in between testing one and the other.
19:13:23 <ddarius> Precisely: Referential transparency means you can replace a reference to a variable with it's definition.
19:14:14 <ddarius> MyCatVerbs: But we usually don't care about -all- the details of the universe.
19:14:22 <MyCatVerbs> So if we want to check monadic functions for referential transparency, we'll need a method of creating and annihilating -universes- in order to do so.
19:14:50 <skew> MyCatVerbs: IO, maybe. For other monads it's easier
19:15:08 <ddarius> MyCatVerbs: And regardless, we can't check any (partial) functions for equality extensionally in general.
19:15:13 <MyCatVerbs> ddarius: and yet I am still excited by the prospect of blasting every last atom, quark and leptop in all creation into fuzzy nonexistent shit, multiple times, just for the sake of unit testing. =D
19:15:26 <MyCatVerbs> *lepton, argh
19:15:32 <skew> like, with State you can just feed in different states
19:16:01 <skew> MyCatVerbs: that's why I would like to prove things instead - I like my atoms
19:16:05 <MyCatVerbs> skew: jah, but really what it's all about is I want an excuse to blow the universe up multiple times.
19:17:06 <skew> anyway, it's more something you assume the compiler provides, and then use it to abstract out repeated actions
19:17:32 <ddarius_> MyCatVerbs: One never needs an excuse to do that.
19:18:55 <skew> Referential transparency with IO doesn't really give you much more than making funtions of no arguments in imperative languages
19:19:20 <MyCatVerbs> ddarius_: I'm thinking that'd be a -much- cooler feature to add to ghc than automatic deforestation.
19:19:41 <Svrog> oops.. -N does work after all - just had to remove a space between -N and the number of threads hehe
19:19:52 <skew> but I like it a bit better, maybe just for lighter syntax on value definitions
19:20:08 <MyCatVerbs> ddarius_: good optimization strategy, too. Just keep blowing up universes until you find one which contains a globally optimal implementation of your program.
19:20:35 <ddarius_> MyCatVerbs: Well, get to it.
19:20:36 <skew> MyCatVerbs: that doesn't get you much more than NP
19:20:40 <skew> MyCatVerbs: PP tops
19:20:48 <ddarius_> skew: Sure it does, time is part of the universe.
19:21:24 <MyCatVerbs> ddarius_: believe it or not, this is only the second stupidest idea I've ever had related to computation. =D
19:21:35 <skew> well, those bounds are for computing, and then destroying the universe if you don't like the answer, then assuming you continue to exist
19:22:03 <MyCatVerbs> skew: depends on the rate of universe creation, though.
19:23:37 <MyCatVerbs> skew: if we can spin off universes at a constant, finite rate then, we can get exponential algorithms happily. You spawn one universe, you spawn a second universe and your first universe spawns its own extra universe...
19:24:05 <SamB> MyCatVerbs: I want to know how we land ourselves in a universe with the answer
19:24:35 <MyCatVerbs> skew: on the other hand, what if we made a machine to spin off or destroy universes with a cardinality of |N| per step? We could hit all of PSPACE in a single step for any problem on discrete numbers.
19:24:38 <ddarius_> SamB: It happens for free.
19:24:50 <SamB> hmm?
19:25:04 <SamB> is this like with the list monad?
19:25:13 <monochrom> Yes!
19:25:33 <SamB> so how do we destroy the universes we don't like?
19:25:34 <ddarius_> SamB: The universe relevant to us will be the one in which the right answer exists and we exist in it.
19:25:34 <MyCatVerbs> SamB: oh easy, you just blow up all the universes that don't contain the answer. The only one we -percieve- is the successful universe, because all the other versions of us have been atomized, our atoms quarked and our quarks reduced to a fine quantum mush.
19:25:39 <monochrom> You need a test to say "right answer" or "wrong answer". Then you kill off wrong answers.
19:25:58 <monochrom> Garbage collection.  (I'm just kidding!)
19:26:07 <MyCatVerbs> monochrom: I lol'd.
19:26:28 <MyCatVerbs> SamB: ah, that's the difficult part. Presumably if we have a mechanism to spin off universes with desirable characteristics, though, we could also reverse it?
19:27:10 <davidL> Speaking of universes, was the quadratic equation created at the big bang or did we invent it?
19:27:31 <MyCatVerbs> (Okay, step one, construct a universe factory. Eat your heart out, Magrathea.)
19:27:42 <monochrom> It created the Big Bang.  (duck)
19:27:51 <SamB> davidL: you don't want to deal with that one, I think...
19:28:12 <SamB> it probably ends up being a point-of-view question...
19:28:14 <MyCatVerbs> davidL: I think, technically, we created it, when we constructed a system of mathematics which mimics some of the features found in this universe.
19:28:16 <monochrom> "Is math discovered or inflicted?" :)
19:28:52 <davidL> Yes, that is the question.
19:28:57 <davidL> heh
19:29:12 <ddarius_> Math is generated from our (collective) impressions of the universe.
19:29:31 <MyCatVerbs> I say discovered. There are an infinite variety of possible mathematical systems (all the ones that aren't contradictory) and mathematics includes (but does not consist entirely of) picking ones that mimic properties of the universe, or at least give useful answers about chunks of universe.
19:29:35 * QtPlatypus would sat that maths is abstracted from, rather then generated.
19:29:55 <SamB> MyCatVerbs: why don't you want to count contradictory ones?
19:29:57 <QtPlatypus> MyCatVerbs: Or just happen to have interesting results.
19:30:22 <MyCatVerbs> QtPlatypus: I'd count abstracting from an infinite set as invention, usually.
19:30:26 <SamB> I thought physics was where they pick the ones that model stuff
19:30:28 <MyCatVerbs> SamB: because they're useless?
19:30:56 <SamB> MyCatVerbs: well, yes. but does mathematical now imply useful?
19:31:09 <MyCatVerbs> SamB: yes. We don't bother with the useless stuff.
19:31:32 <QtPlatypus> Usefull in this context means "Usefull to mathematisions"
19:31:34 <MyCatVerbs> At least, not intentionally. We hit on dead ends, sure, but we're not *aiming* to.
19:31:38 <ddarius_> Physics doesn't pick mathematics it's makes models within mathematics.
19:32:07 <SamB> ddarius: and they pick the kind of numbers to use...
19:32:17 <monochrom> Abstractions are invented. I think we agree on that.
19:32:21 <ddarius_> SamB: Not really.
19:32:24 <SamB> and a kind of number is rather a mathematical system if you ask me.
19:32:27 <monochrom> OK, maybe not. Nevermind.
19:32:32 <SamB> ddarius: how so?
19:32:34 <MyCatVerbs> SamB: I like to think of it as exploring a solution space. Sometimes the mathematicians just happen to hit on solutions before the physicists come up with the problems to attach to them. =)
19:32:41 <SamB> are you telling me the numbers pick them?
19:32:46 <QtPlatypus> However the use within physics drives the path mathimatics takes.
19:32:56 <monochrom> The numbers picked us.
19:33:25 <ddarius_> SamB: If physists discover that deep down the universe is discrete, we will still use real numbers (or more to the point, continuous geometric entities) because that corresponds with our everyday experience.
19:33:27 <QtPlatypus> Or anything realy, would there be as much interest and resurch into typed lambda calculis if we didn't have computers?
19:34:14 <MyCatVerbs> QtPlatypus: kinda. I mean, people go off on weird tangents that do eventually hit dead ends and turn out not to be useful. But then, physicists -will- if neccessary attempt to invent new branches of mathematics if they're absolutely neccessary to model some real thing.
19:34:16 <ddarius_> Reality isn't as relevant as our perception of it.
19:36:15 <MyCatVerbs> ddarius: if physicists actually proved that the universe modelled itself as a set of discrete processes, with no such thing as a real number anywhere under the hood (problematic, what about irrational numbers? There are irrational -ratios- that pop up in the real world, after all)...
19:36:25 <MyCatVerbs> ddarius: I would burn my FPU and start a cult.
19:36:33 <MyCatVerbs> Several cults.
19:36:35 <SamB> ddarius_: sure. I was talking about what sorts of numbers they use beyond the complex numbers, for instance...
19:36:44 <ddarius> MyCatVerbs: You're FPU has nothing to do with the real numbers.
19:37:04 <dons> morning.
19:37:10 <MyCatVerbs> ddarius: my FPU attempts to model an approximation to real numbers using discrete numbers, I know.
19:37:16 <SamB> your FPU is quite reasonable for approximating discrete numbers
19:37:29 <MyCatVerbs> SamB: down to 23 bits, maybe.
19:37:40 <SamB> MyCatVerbs: well, consider the alternative
19:37:45 <dons> hah http://ocamlnews.blogspot.com/2007/05/functional-programmer-stole-my-job.html
19:37:45 <monochrom> MyCatVerbs just wants to start several cults.
19:37:47 <MyCatVerbs> ddarius: burning it doesn't exactly go against the definition of a "cult" though, does it now? =)
19:37:48 <lambdabot> Title: OCaml News: Functional programmer stole my Job, http://tinyurl.com/2ygq4b
19:37:54 <monochrom> haha dons
19:37:55 <dons> "Gangs of ruthless functional programmers are overwhelming interviewers by listing programming
19:37:58 <dons> languages like OCaml, Haskell and even Lisp on their CVs.
19:38:01 <dons> "
19:38:03 <dons> :-)
19:38:10 <MyCatVerbs> monochrom: yes! Regular ritual orgies, every Wednesday.
19:38:18 <MyCatVerbs> monochrom: nobody from Florida is allowed to jion.
19:38:20 <MyCatVerbs> *join
19:38:48 <ddarius> "Sharon in accounts" That's what I need to do, get a girl in finance. -Always- a good idea (so long as you don't have a bad breakup...)
19:38:51 <nostrademons> hah, if only it were true
19:38:53 <monochrom> dons: what the bloody hell, incidentally, is meant by "third world countries like Europe"? :)
19:39:04 <dons> heh
19:39:08 <ddarius> Indeed.  Europe is not a country.
19:39:09 <nostrademons> when I listed Haskell on my resume, my employer asked me "How's it feel to know a language that will never ever become practical."
19:39:32 <dons> nostrademons: really?
19:39:41 <ddarius> nostrademons: Heck, if they even know what it is they're beginning to contradict themselves.
19:39:43 <dons> that seems a bit harsh...
19:39:48 <nostrademons> yes
19:40:17 <nostrademons> he knew what it is because he's a former MIT (math) professor, and one of his advisors is an MIT CS professor that's into advanced languages
19:40:22 <nostrademons> he doesn't know it himself though
19:41:17 <MyCatVerbs> nostrademons: "Ever so slightly more fun than learning Scheme."
19:41:23 <nostrademons> he's one of those "Java should be good enough for anyone" guys
19:41:34 <dons> ah well.
19:41:34 <nostrademons> oh, he teases me about Scheme too
19:41:42 <MyCatVerbs> nostrademons: especially if he's one of the MIT people who's been beaten about the ears with SICP. =)
19:42:04 <dons> did people see sigfpe's (first?) combined robots + haskell post?
19:42:07 <dons> --> http://sigfpe.blogspot.com/2007/05/haskell-incarnate.html
19:42:07 <MyCatVerbs> Wait, what the Hell-ass is this?
19:42:08 <lambdabot> Title: A Neighborhood of Infinity: Haskell Incarnate
19:42:11 <MyCatVerbs> "Sharon in accounts?"
19:42:22 <SamB> nostrademons: did he not hear that we failed at our objective to avoid success at all costs?
19:42:42 <nostrademons> hah
19:42:44 <MyCatVerbs> WTF is up with that? Everyone with functioning eyes _knows_ the cutest chicks are always in the DP pool. *Always*.
19:42:46 <dons> yeah, far too many of us now have jobs writing haskell. what's going on!?
19:42:48 <cdsmith> @pl \x -> x { foo = bar }
19:42:49 <lambdabot> (line 1, column 9):
19:42:49 <lambdabot> unexpected "{"
19:42:49 <lambdabot> expecting variable, "(", operator or end of input
19:43:00 <nostrademons> the robot's really cool, dons...
19:43:09 <nostrademons> I made one like that with another friend, but programmed in C
19:43:14 <MyCatVerbs> I agree with nostrademons except for one difference.
19:43:34 <SamB> nostrademons: you should have asked him how it felt to do math
19:43:34 <MyCatVerbs> I would like to add like thirty fucking underlines, gratituous bloody swearing and HUGE BOLD FONTS to that sentence.
19:43:42 <SamB> and said that programming Haskell was roughly the same
19:43:47 <nostrademons> hahahaha
19:43:48 <MyCatVerbs> Lambdabot rules. ^^
19:43:49 <nostrademons> I should've
19:43:52 <dons> yeah, i think there's a real market for haskell and robot dsls. the AI guys in my dept struggle around hacking up C++ and little custom languages. sometimes I think the language research group should go down and show them how to write a compiler. mwhaha
19:44:14 <MyCatVerbs> dons: I think you should install TCL on all their machines instead.
19:44:36 <dons> SamB: hah. nice analogy
19:44:38 <MyCatVerbs> dons: if they're working on really -fun- robots they're sure to misplace an uplevel and kill themselves sooner or later... =)
19:44:46 <dons> yikes
19:44:48 <ddarius> I don't know enough about Tcl to know if I dislike it more than Perl.
19:44:55 <SamB> dons: what analogy?
19:45:04 <dons> "you should have asked him how it felt to do math"
19:45:12 <SamB> but how is that an analogy
19:45:36 <dons> oh, sorry. maybe i misread you. I read that as "Imagine asking a math graduate how it felt to have a skill that would never be practical"
19:45:48 <MyCatVerbs> ddarius: I think Tcl is possibly the only language on Earth more powerful than Lisp. It scares the bejeezus out of me, for one.
19:45:48 <dons> and then imply that knowing haskell might have a similar effect.
19:45:57 <SamB> not really ;-)
19:46:20 <SamB> I meant, forget about the "never become practical" part
19:46:25 <dons> but people would suggest knowing math is good for engineering.
19:46:33 <dons> so why not foundations of programming, for um.. programming.
19:46:38 <ddarius> People think knowing math is good for everything.
19:46:39 <dons> bizarre. we have an immature industry.
19:46:42 <MyCatVerbs> ddarius: I bet a mathematician or a CS researcher with about a week of too much spare time on their hands could prove some really -frightening- mathematical properties of Tcl programs.
19:46:53 <SamB> dons: all I meant was that... haskell feels like math!
19:47:01 <dons> ok. but i think there's a stronger result there.
19:47:06 <ddarius> SamB: That's how I read you.
19:47:09 <SamB> could be!
19:47:20 <jcreigh> MyCatVerbs: hmm? What's so special about tcl? "Everything is a string" is kinda of interesting, but other than that it's stuck me as somewhat unremarkable.
19:47:21 <dons> for people not actually coding in haskell, knowing haskell is like an engineer having a good math background.
19:47:37 <dons> they're aware of what state is.
19:48:02 <SamB> and how to control it
19:48:50 <MyCatVerbs> jcreigh: code is a string too. On the fly code generation becomes trivial.
19:48:51 <ddarius> That thing is bloody loud.
19:49:25 <SamB> I thought the important things in TCL were *commands*
19:49:40 <jcreigh> MyCatVerbs: okay...other languages have "eval()"...does it work nicer in tcl than it does in other dynamic languages?
19:50:11 <mauke> depends on your definition of "nice"
19:50:17 <Saizan> wasn't the important thing in tcl that you could script eggdrops with it? </troll>
19:50:36 <MyCatVerbs> jcreigh: kinda. The simpler syntax helps and it has the ability to abuse the living shit out of the scoping rules because of uplevel.
19:51:17 <SamB> scoping rules?
19:51:20 <MyCatVerbs> jcreigh: the fact that you can arbitrarily do evil and nasty things to the scoping rules like that means you can write -procedures- which work exactly the same as macros do in other langages.
19:51:25 <Svrog> being aware of what state is and how to control is often frustratingly useless when working in a team of hardcore oo programmers
19:51:51 <SamB> we need another abstraction, then
19:52:02 <SamB> one that teaches you what programmers are and how to control *them*
19:52:05 <MyCatVerbs> Svrog: are you sure it's not just the OO programmers being intrinsically annoying?
19:52:23 <MyCatVerbs> SamB: cat herding. It's trivial, once you understand cats. =)
19:52:39 <SamB> MyCatVerbs: well, see, thats the part about what programmers are
19:53:20 <MyCatVerbs> SamB: scoping rules, erm, I'm not entirely sure how to best describe the implications of that. Things like, you can define a function "dotimes" taking a number and an arbitrary string.
19:53:58 <MyCatVerbs> SamB: have it eval() the string n times in the context of the calling function, rather than the dotimes function itself.
19:54:16 <SamB> MyCatVerbs: I like closures better
19:54:25 <MyCatVerbs> SamB: "what programmers are" <-- betcha cat<->dog nature varies with competence. =D
19:54:36 <SamB> really?
19:54:51 <SamB> I dunno.
19:54:59 <MyCatVerbs> No idea. I wouldn't wager much more than a beer on it.
19:55:05 <SamB> I think it might vary with pizza intake or something.
19:55:06 <MyCatVerbs> Just a totally uneducated hunch.
19:55:17 <MyCatVerbs> Well, I eat no pizza and I'm a fucking moron.
19:55:22 <MyCatVerbs> So you could be on to something there.
19:55:33 <SamB> I meant the cat <-> dog nature
19:55:36 <ddarius> The secret to Tcl is that it is so slow that repeatedly evaling strings is not a performance loss!
19:55:46 <Svrog> haha
19:55:47 <MyCatVerbs> SamB: closures are saner than uplevel, true, but I get the impression uplevel evaluation is more general.
19:55:52 <SamB> ddarius: isn't that how it already works anyway?
19:56:13 <MyCatVerbs> ddarius: _still_ faster than Ruby. =)
19:56:19 <SamB> MyCatVerbs: sometimes, it is not nice to be more general
19:56:39 <MyCatVerbs> SamB: jah, hence, "sanity."
19:56:42 <SamB> DTSTTCPW
19:56:46 <MyCatVerbs> ?
19:56:55 <SamB> do the simplest thing that could possibly work
19:56:59 <MyCatVerbs> Ahhhh.
19:58:03 <MyCatVerbs> I prefer Ken Thompson on that one. "A language that doesn't have everything is actually easier to program in than some that do." =)
19:58:29 <SamB> nice.
19:59:11 <mauke> heh
19:59:14 <mauke> St Monad
19:59:25 <SamB> it seems that a lot of the "XP principles" apply regardless of what language you use...
19:59:37 <dons> yeah, its called good developmenet practice.
19:59:42 <ddarius> SamB: Why wouldn't they?
19:59:47 <dons> starting with an X is just buzz. like xmonad ;-)
19:59:53 <MyCatVerbs> SamB: I still find YAGNI controversial. =)
19:59:56 <ddarius> Or X!
20:00:17 <dons> though it makes for cool logos.
20:00:29 <dons> so, ddarius, why do't you have a blog.
20:00:41 <ddarius> Yeah, a blank square would be a crappy logo for a windowing system.
20:00:45 <dons> i find myself with coffee on a sunday morning, looking for some good programming to read, and not seeing anything..
20:01:10 <ddarius> dons: I think I've said before on #haskell that I don't really intend to ever have a blog.
20:01:11 <dons> there's 300 people in here, and maybe 5 writing stuff for the public. boo hoo!
20:01:19 <TomMD> dons: Typically a good sign you need to write one.
20:01:22 <ddarius> And unfortunately I haven't been writing too much code lately.
20:01:35 <dons> ddarius: but no one will ever know your amusing ideas about programming and language design.
20:01:42 <jcreigh> dons: that's because writing is like work.
20:01:56 <dons> nah, its what you do *instead* of work ;-)
20:02:01 <ddarius> But that might change now that my pleasant distraction is missing, but I hope to get a new more distracting pleasant distracting soon.
20:02:06 <dons> heh, let's make a robot that uses comonads. cool. i'll blog that.
20:02:49 <MyCatVerbs> I have a better idea.
20:02:53 <dons> if people are looking for direction on what to write about, perhaps fill out the modules in the base library that haven't yet been written about..
20:03:03 <MyCatVerbs> Why don't the other 299 of us blog about everything that dons does?
20:03:05 <dons> such as Control.Parallel or Data.Sequence.
20:03:20 <dons> here's all the good blogs from the last 6 months, http://www.haskell.org/haskellwiki/Blog_articles
20:03:22 <lambdabot> Title: Blog articles - HaskellWiki
20:03:35 <MyCatVerbs> That way dons can just get along with hacking and the rest of us can spam reddit into a quivering pile of shit.
20:03:36 <dons> but there's some gaps, such as a lot of Data.* , a fair few techniques haven't been explored (no yampa).
20:03:42 <ddarius> What documentation that exists for Control.Monad.*, I mostly wrote, but it mostly gets overlooked and that was years ago.
20:03:52 <dons> the stuff in mtl, you mean?
20:03:58 <ddarius> Yeah.
20:04:01 <dons> primarily, MPJ's paper on overloading
20:04:05 <ddarius> I do like it when articles I've written get referenced.
20:04:16 <Modius> Q:  "What's it like knowing a language that'll never be practicel"   A:  "I wouldn't know"
20:04:20 <dons> we have a lot of talented people in here, who really should be writing..
20:04:24 <Modius> (forgive spelling on rush)
20:04:25 <MyCatVerbs> Modius: good answer.
20:04:26 <dons> Modius: hah.
20:04:28 <Svrog> i was trying to think of how to write something like yampa/frp using comonads yesterday but im having a hard time figuring out how to replace the arrows with comonads - im guessing it would probably help a bit if i knew a bit more about languages like lucid and lustre before reading all those frp research papers heh
20:05:05 <dons> so, I would like to encourage anyone here thinking about writing, to dive in and do so.
20:05:11 <ddarius> Q: "What's it like knowing a language that'l never be practical?" A: "I forgot to take Brainfuck off my resume, didn't I?"
20:05:21 <dons> its quite rewarding, you can really improve your own understanding of some code, by writing about it.
20:05:26 <dons> and its very cheap to get started.
20:06:07 <ddarius> I have some articles that I was supposed to finish months ago, but on category theory and analytic number theory...
20:06:07 <dons> and, like I say, for content, start in base, and write about some data structure you've never used. :-)
20:06:15 <dons> ddarius: perfect!
20:06:17 <MyCatVerbs> dons: one question. I have a hunch which way you'll answer on this one.
20:06:32 <MyCatVerbs> dons: what'd you say if I offered to buy you a beer for having written lambdabot?
20:06:48 <dons> beer is nice. though i didn't write all of it.
20:06:54 <dons> there's been around 80 contributors :-)
20:07:00 * dons checks..
20:07:21 <MyCatVerbs> Hrmn. Okay, just for statistical purposes, same question again with vodka?
20:07:47 <MyCatVerbs> (*Started* lambdabot, then, if you'd prefer that.)
20:08:01 <dons> i'm an aussie, so beer is preferred :-)
20:08:43 <MyCatVerbs> But if I hadn't thought of beer at all and just handed you a bottle of Russian jet-fuel straight out of the blue?
20:09:03 <dons> heh. i wouldn't turn it down.
20:09:28 <MyCatVerbs> Fascinating. Thank you.
20:09:34 <dons> hah
20:11:31 <stepcut> who started lambdabot ?
20:12:13 <stepcut> Andrew J. Bromage ?
20:12:37 <dons> yeah.
20:12:45 <TomMD> How do I catch a non-IO exception? (ex: head []) (ex2: foo "hi" where foo ('[':lst) = ...)
20:12:46 <dons> then shapr maintained it till 2004, then i took over maintainer.
20:12:54 <dons> more recently, sorear has done a lot of work on it.
20:13:16 <stepcut> what sort of work? Internal stuff ?
20:13:20 <stepcut> or new functionality ?
20:15:10 <dons> oh, an rc script system, concurrency stuff, and multiple server support.
20:15:17 <dons> so new low level functionality. quite nifty
20:15:45 <stepcut> cool
20:16:07 <dons> ok, apparently i've written 900 lambdabot patches, jlouis 100, TheHunter 68, sorear 60
20:16:24 <dons> SamB 30, sjanssen , lispy 20.
20:16:33 <dons> int-e 16.
20:16:38 <dons> ddarius 8
20:16:51 <dons> and another 60 wrote less.
20:17:01 <stepcut> speaking of sorear, is his deriving Binary stuff tools/derive/BinaryDerive.hs  ?
20:17:16 <dons> did sorear write that? I can't recall.
20:17:33 <stepcut> actually, let me ask a better question
20:17:39 <SamB> 30?
20:17:40 <SamB> really?
20:17:46 <SamB> I must use small patches
20:17:47 <stepcut> what is the best way to derive binary instances ?
20:17:58 <dons> ah. to use the binary deriver, yes. though drift works too
20:18:07 <dons> drift might even be the best bet, not sure.
20:18:31 <stepcut> BinaryDerive is a standalone program that generates code you copy and paste into your module ?
20:19:26 * stepcut was expecting TH for some reason
20:21:46 <dons> stepcut: right.
20:22:06 <dons> stepcut: it is an offline tool, that given a type, generates a string of code that gives you the instance.
20:22:09 <dons> using SYB techniques
20:22:53 <stepcut> hrm, I don't think the usage instructions work :(
20:23:14 <stepcut> when I do this:
20:23:24 <stepcut>     *Main> deriveM (undefined :: Drinks)
20:23:30 <stepcut> oops
20:23:34 <stepcut>     $ ghci -fglasgow-exts BinaryDerive.hs
20:23:37 <stepcut>     *BinaryDerive> :l Example.hs
20:23:39 <ddarius> dons: Do you read LtU?
20:23:42 <stepcut>     *Main> deriveM (undefined :: Drinks)
20:23:47 <stepcut> deriveM is no longer in context
20:23:55 <dons> ddarius: not regularly, only if keywords come up in my rss feed
20:23:59 <dons> ddarius: why?
20:24:10 <dons> stepcut: hmm, check the src (its very short)
20:24:28 <sorear> stepcut: BinaryDerive is obsolete
20:24:45 <stepcut> sorear: what is the replacement ?
20:24:58 <sorear> stepcut: Data.Derive (which I co-wrote) does Binary even better than BinaryDerive, and a whole lot more
20:25:08 <ddarius> dons: I'm just kind of surprised that I don't see you there.
20:25:10 <stepcut> sorear: does that use TH ?
20:25:57 <dons> ddarius: hmm,  i'm not sure why I don't contribute to it. it never really hooked me, for some reason.
20:26:14 <sorear> stepcut: Optional.
20:26:30 <stepcut> sorear: where is Data.Derive? It's not part of binary is it ?
20:26:41 * stepcut jfgi
20:27:19 <dons> sorear: is that really the best strategy for deriving Binary now? i've not seen any discussion about it.
20:28:14 <sorear> dons: huh?  it works well enough, and gets slower the more sopthisticated you make it
20:28:39 <dons> sorear: oh, just that i don't recall any discussion recently about what our preferred deriving mechanism is.
20:28:51 <dons> so i'm wondering if we're now in a position we should be saying: use Data.Derive.
20:33:59 <TomMD> Did any of Neil Mitchell's PhD work make it into GHC?  And on that note - Sorear: will you be blogging about how you fixed potential pattern match issues in xmonad?
20:34:00 <dons> afternoon bos31337
20:34:18 <bos31337> howdy do
20:34:23 <dons> TomMD: ha? ndm fixed the pattern issues, and Catch /ndm-fusion isn't in ghc yet.
20:34:33 <bos31337> @seen cosmicray
20:34:34 <lambdabot> I saw cosmicray leaving #haskell-blah, #darcs and #haskell 1d 3h 49m 23s ago, and .
20:34:38 <dons> ghc uses a different fusion strategy based on rewrite rules.
20:35:00 <dons> TomMD: it was ndm who ran is 'Catch' verifier over xmonad, to spot the pattern match issues.
20:35:05 <dons> found a bug in the zipper code, in fact.
20:35:09 <bos31337> nice.
20:36:00 <TomMD> dons: Yes, and I scanned his blog (look forward to a polished 'Catch'), but he mentioned that Sorear made the actual fixes, so I was just wondering if any lessons learned or strats came from that.
20:36:03 <dons> so now we have a proof of non-partiality of xmonad's core. yay for programming.
20:36:15 <dons> TomMD: oh, I think he means sjanssen (?)
20:36:21 <skew> what else ought to be proved about it?
20:36:26 <dons> the lesson was: think harder about partial functions.
20:36:47 <dons> in fact, Catch is changing how I code. by (further) constraining what code is accepted, we get better code.
20:36:58 <dons> so i'm a big fan of mechanical support.
20:37:11 <TomMD> Oh, so I remembered wrong.  I suppose sjanssen is too busy with college to blog right now.
20:37:15 <dons> skew, about xmonad. hmm.
20:37:28 <ddarius> What was the case that quickcheck properties were missing? or were you missing quickcheck properties?
20:37:35 <bos31337> i see there are two books about f# in the pipeline.
20:37:56 <dons> ddarius: yeah, it was a missing QC property, the bug that was caught. additionally, some other issues were very corner case stuff.
20:38:07 <bos31337> dons: is catch usable yet?
20:38:14 <dons> such as, being polymorphic in Integral, assuming that there was a 0, but that can be broken by a funny instance.
20:38:19 <bos31337> as in, by people not manually coached by ndm?
20:38:20 <dons> so nothing in the real world, but possible.
20:38:30 <dons> bos31337: close, but not there yet , i think.
20:38:36 <skew> hey, what about ESC/Haskel?
20:38:49 <skew> I haven't heard anything about that since ICFP
20:38:52 <SamB> how available is coaching?
20:39:21 <ddarius> SamB: How often do you see ndm?
20:39:33 <dons> skew: ndm reported that ESC/Haskell isn't usable yet.
20:39:40 <dons> there was a talk he attended on it last week.
20:39:43 <SamB> hmm.
20:39:59 <SamB> okay, so I guess I won't try it yet
20:40:43 <dons> skew: so proofs for some ofthe high level properties currently done with QC would be really cool
20:40:48 <dons> but I think that requires Isabelle.
20:41:04 <skew> I've never tried Isabelle
20:41:19 <dons> are there any other static analysers we could try. i'm keen to use xmonad as a test case for high assurance real world haskell.
20:41:42 <skew> ESC/Haskell is the big one I thought of
20:41:42 <dons> but not sure yet if I can justify coding up an Isabelle embedding. that's more work than I've got time for :}
20:42:21 <MyCatVerbs> I have a cheaper idea.
20:42:33 <sorear> Get a grad student to do it?
20:42:34 <skew> I just know a little bit about extracting code
20:42:40 <MyCatVerbs> sorear: even better. Step one, convert the whole thing to .lhs, with pretty TeX annotations.
20:43:04 <sorear> Ah.  Step 2 is the ICFP review board?
20:43:10 <MyCatVerbs> Step two, since it's now valid TeX source, track down Donald Knuth and wave it under his nose.
20:43:16 <skew> but reflecting code into a prover sounds interesting
20:43:34 <MyCatVerbs> Step three, leave the code and Knuth in a locked room together. ????? will occur.
20:43:38 <MyCatVerbs> Step four is profit.
20:43:56 <sorear> we just need a way to immutably access the past
20:44:21 <skew> sorear: isn't that the only kind of access you have to the past?
20:44:26 <dons> i'm not sure Knuth reads Haskell, or has even heard of it :}
20:44:30 <sorear> get a reference to edsger dijsktra c. while he was alive; force him to use X w/o providing a WM
20:44:30 <MyCatVerbs> skew: ahahahahahah.
20:44:47 <MyCatVerbs> dons: that's what the TeX is for. Bait and switch maneouvre, y'see.
20:44:48 <sorear> he'll write and prove one quickly enough
20:44:54 <monochrom> The second part is not immutable.
20:45:08 <sorear> x = y;
20:45:20 <sorear> uses y non-mutingly
20:45:23 <skew> I don
20:45:30 <sorear> skew: No, you're not.
20:45:31 <skew> I don't see a windows package of Isabelle
20:45:35 <ddarius> A high assurance wm, just what the world needs.
20:45:47 <sorear> > "Brandon" == "don"
20:45:52 <lambdabot>  False
20:45:52 <chessguy> xmonad ftw!
20:45:54 <skew> For some reason I'm running windows at the moment
20:46:03 <TomMD> Did that wp issue get resolved yet, or does that take some time?
20:46:24 <sorear> TomMD: No, the fate of the universe STILL hangs in the balance.
20:46:33 <TomMD> Damn universe
20:48:50 <sorear> does exetel use dynamic ips?
20:52:32 <ddarius> "Since most computer scientists do prefer classical reasoning, constructive type theories are not widely used."
20:53:01 <skew> yeah, usually masively inconsistent type theories are used
20:53:41 <monochrom> That is a misunderstanding.
20:53:48 <TomMD> Stupid question: is there a monad that will allow me to use a throw function (like 'error') that won't crash the running program.  I guess I can use maybe and call 'fail', but that just seems... wrong.
20:54:18 <skew> TomMD: there's a few - IO has exceptions, Maybe and Error are simple cases
20:54:37 <TomMD> Bleah, I avoid IO any time I can.
20:54:37 <monochrom> Control.Monad.Error
20:55:13 <monochrom> The Maybe monad is also ok, not wrong.
20:55:46 <monochrom> If you know how to use continuations to throw and catch exceptions, Control.Monad.Cont.
20:57:07 <skew> hmm, Text.PrettyPrint isn't so nice for Haskell
20:57:34 <skew> you can't get ; to turn into a linebreak
20:58:51 <dons> $$ or vsep ?
20:59:05 <skew> yeah, I'll do that
20:59:23 <skew> still doesn't let the pretty-printer switch
20:59:34 <skew> actually, I was starting with PPrint, but that doesn't have a strong linebreak
20:59:39 <dons> sorear: hmm? exetel? no.
21:00:14 <dons> skew, right, no isabelle for X, but the majority of xmonad logic is a pure data structure. that's certainly encodable in isabelle.
21:00:24 <dons> the X layer is just an event handler which calls the api of the data structure
21:00:39 <dons> and a 'refresh' ffunction which renders windows according to the current shape of the data structure.
21:00:43 <dons> MVC ;-)
21:01:11 <ddarius> "Mathematicians typically define objects by explicitly constructing them."
21:01:14 <skew> dons: actually,  I meant an Isabelle build for MS windows
21:01:59 <monochrom> For example, tuples are constructed, not axiomatized. Functions too.
21:02:05 <dons> ah right. no idea. needs an SML compiler.
21:02:31 <skew> but I know nothing about Isabelle
21:02:34 <ddarius> Then shortly, "Such definitions are often rejected in favor of more abstract ones."
21:02:54 <skew> sounds like they just used sed to turn Haskell into acceptable isabelle
21:03:24 <allbery_b> mrf?
21:03:29 <dons> skew, who?
21:03:43 <monochrom> The first time I read Isabelle definitions and proofs, I was like, "am I reading Haskell?" :)
21:03:45 <dons> the L4/Haskell guys use a small parser to turn haskell into isabelle.
21:03:47 <allbery_b> oh, wrong Brandon :p
21:03:53 <dons> but i'd like a general embedding. and converter.
21:04:02 <skew> yeah, those
21:04:17 <dons> if we had a library of isabelle/haskell, and a converted that takes h98 to isabelle, i'd use isabelle for things i currently use QuickCheck for, I suspect.
21:04:29 <dons> since that'd lower the barrier a lot to formal checking of things.
21:04:29 <skew> hmm, you'd probably have to model nontermination somehow
21:05:03 <monochrom> Nice. We will lure dons to the Dark Side. I mean formal verification.
21:05:37 <monochrom> "Fear leads to uncertainty. Uncertainty leads to doubt. Doubt leads to theorem proving."
21:05:42 <dons> heh
21:06:27 <dons> nice hwn quote.
21:06:33 <monochrom> hahahaha
21:07:18 <monochrom> perhaps change "theorem proving" to "formal verification" there. Or "formal methods".
21:07:39 <dons> we should collect the pratical formal and semi-formal tools available for haskells now on a wiki page
21:07:42 <dons> and make some recommendations
21:08:01 <dons> things like QC, Catch. then other things that are used, such as Isabelle or the Agda work.
21:08:10 <dons> what else is there? HPC.
21:08:29 <skew> extraction?
21:08:42 <sorear> faking it
21:09:27 <dons> there's also strict check and chasing bottoms, for checking laziness issues.
21:10:18 <skew> I wonder how hard it would be to get that xmonad core extracted from Coq - I don't know much about the interfacing
21:11:01 <dons> hmm. yeah, we need someone familiar with doing extraction of data structure code.
21:11:24 <dons> but it is a purely functional data structure, with a pretty small api, so 'doable'.
21:14:39 <edward1> its a pain in the butt to extract haskell from coq though, easy with ocaml, but haskell support there is definitely a second class citizen
21:15:03 <dons> there's haskell extraction in Isabelle too, iirc?
21:15:20 <edward1> there i am less familiar
21:15:20 <dons> (Isabelle seems to be used more by Haskell people,than Coq or Twelf, I've noticed)
21:17:17 <dons> hi edward1,btw. what you up to these days?
21:17:58 <edward1> been off working in the real world doing boring data mining work, but I just got to where I have enough free time to work on my toy compiler again
21:18:18 <skew> what are you compiling?
21:19:12 <TomMD> ?paste
21:19:12 <lambdabot> Haskell pastebin: http://hpaste.org/new
21:19:52 <edward1> a toy language with substructural types, predicate subtyping, and polymorphic records and variants, with known undecidable type checking, trying to see if the predicate subtypes can let me open up the domains of functions more and close them down with unrolling
21:21:10 <edward1> er that latter bit probably won't make much sense unless you've been talking to me for the last few months
21:21:33 <edward1> the unrolling is counter-example guided, ala Dana Xu's ESC Haskell
21:25:22 <edward1> actually I'm hoping the substructural type annotations can become a bunch of predicates now, so the same cheesy theorem proving/simplification process can carry them around.
21:27:39 <edward1> currently it lets you say things like   sort : forall a, [a] -> (x : [a] | sorted x)     or fib : (x : Int | x >= 0) -> (y : Int | y >= 0) and apply any total functions at either the type or term level, weird stuff like that, while i play around
21:27:49 <skew> I just grabbed a bunch of papers Thursday describing assorted features I'd like to have in a functional language
21:28:14 <skew> except I purposely stayed away from any assertion or dependent type kind of stuff
21:28:40 <skew> polymorphic records and variants are quite overdue
21:28:49 <edward1> in the above, you could also just say: nat = (x : Int | x >= 0);    fib : nat -> nat
21:29:03 <edward1> well, they nicely simplify a lot of the work for the theorem prover. =)
21:29:59 <edward1> only problem is that they, by default in my current implementation my polymorphic variants can only work with arity 1, so you have to tuple up arguments to them ala ML
21:30:02 <MyCatVerbs> skew: assertions?
21:30:14 <edward1> assertions?
21:30:33 <MyCatVerbs> skew: we don't need no language-level support for assertions. Just deliberately leave incomplete patters in and if anything impossible happens you'll damn well get notified.
21:30:38 <MyCatVerbs> XD
21:30:43 <edward1> mycat: at RUN time
21:30:50 <skew> predicate subtypes, dependent typing, what have you
21:30:59 <MyCatVerbs> edward1: lawls. =D
21:31:13 <edward1> the above are compile time errors if they can prove a counter example, compile time warnings if they are unsafe
21:32:01 <MyCatVerbs> edward1: well yeah, but the whole damn thing is Turing complete anyway. You can't neccessarily prove in the general case that a function that doesn't define an exhaustive pattern will never be called with arguments it wasn't defined for.
21:32:07 <edward1> sure
21:32:16 <edward1> i don't want to prove it for every case
21:32:31 <edward1> i want to prove it where i can, and if i can't show that the precondition is satisfied, thats a warning
21:32:39 <edward1> if i can prove that its called incorrectly, thats an error
21:32:45 <edward1> i want to push into that grey area a bit
21:33:12 <MyCatVerbs> So instead of doing the C-like thing and writing "if (assertion) then carryOnWorking else error \"Assertion on __LINE, __FILE, failed.\""...
21:33:15 <edward1> its just a form of abstract interpretation
21:33:44 <skew> also, you can have logical systems (where searching for proofs is undecidable) that let you prove whether or not a program will work out
21:33:47 <MyCatVerbs> Just call "(\True -> carryOnWorking) (assertion)" somewhere.
21:34:00 <edward1> in my case you would say something like f : (x : T |  precondition x) -> (y : T | postcondition x y)
21:35:00 <edward1> which play the rule of the assertions as you enter and exit the function
21:35:27 <edward1> mycat: your example is caught at runtime again =P
21:35:34 <edward1> the predicates are checked at compiletime
21:35:41 <MyCatVerbs> edward1: yyyyyes, I fail to see the problem.
21:35:45 <skew> but, before I get to general language stuff I've got this idea that principal typings might have something to do with supporting dynamic typing of polymorphic values
21:36:08 <MyCatVerbs> Or, more to the point, I fail to see how doing it at compile time is even remotely tractable.
21:36:13 <ddarius> skew: Look at Clean.
21:36:26 <edward1> mycatverbs: go read dana xu's ESC/Haskell paper
21:36:48 <edward1> i've reimplemented the same machinery in my type system, its quite clean and surprisingly robust
21:36:50 <MyCatVerbs> edward1: this'd explain how you avoid running head-first into the damn halting problem?
21:37:36 <MyCatVerbs> Oh and not to mention how you might somehow manage this all with an algorithm whose complexity class doesn't require longer than the universe to hit up a big project like, say, ghc?
21:37:43 <edward1> its partial, it TRIES, if it can prove it, it moves on quietly. it only unrolls a few function applications, if it can prove that evaluation will result in an error then it emits an error.
21:38:36 <edward1> mycat: it works and its real, its just a form of abstract interpretation, like Gamma-CFA
21:38:52 <MyCatVerbs> edward1: ohhhh.
21:39:10 <edward1> the trick is that if it can't prove it in a bounded amount of time it moves on and emits a warning that you might be doing something funny
21:39:19 <edward1> xu's version is for partial correctness
21:39:19 <MyCatVerbs> edward1: so it'll go through most practical algorithms because they tend to be short, but don't expect to be able to run it against parsers?
21:40:36 * MyCatVerbs casts about for a crow to munch on.
21:40:55 <edward1> well, you can use it against fairly complicated algorithms, because it can test pre and post conditions locally, by examining each function in turn. but its a proof of partial correctness if it succeeds, it doesn't detect infinite loops, only "error" calls, incomplete patterns, or pre/post- condition failures
21:41:31 <edward1> if applied to 'unpointed' types you get a proof of total correctness for free
21:41:42 <MyCatVerbs> Unpointed?
21:42:42 <edward1> so i'm currently applying it in a higher order fashion, with pointedness analysis, to allow me to apply any total function to arguments at any sort safely. its the other parts of my type system that cause it to blow up into undecidability ;)
21:42:50 <MyCatVerbs> Er, I'm not sure how to express this in English, but data RecursiveType = Foo | Bar | Baz RecursiveType is pointed and "data NonRecursiveType = Fuu | Bah | Bzzt" is unpointed?
21:43:03 <skew> I think that still just tells you that if it terminates it is correct
21:43:09 <edward1> an unpointed term doesn't contain bottom
21:43:17 <skew> not necessarily that it will terminate, even if it is working over an unpointed type
21:43:18 <MyCatVerbs> edward1: I've actually no idea what the term "unpointed" means here so I'm guessing. >>
21:43:44 <MyCatVerbs> Ahhh, okay.
21:44:00 <skew> edward1: so extracting a value of unpointed type from a data structure won't be a problem
21:44:06 <MyCatVerbs> Er...
21:44:07 <edward1> unpointed domains are useful for thinking about boxing and unboxing
21:44:27 <MyCatVerbs> edward1: how in the lemon-flavoured smeg do you guarantee that a given type will never come up _|_?
21:44:42 <skew> but you can still write something trivial like f :: () -> Int#; f () = f ()
21:44:48 <edward1> because it is permissible to compute unpointed values eagerly, but not "W-safe", its somewhere between strict and lazy.
21:44:54 <MyCatVerbs> edward1: I thought it was kinda an intrinsic problem with lazy evaluation.
21:45:07 <edward1> mycatverb, apply a bunch of functions involving non-recursive definitions
21:45:24 <MyCatVerbs> Ohkay...
21:46:41 <MyCatVerbs> edward1: so anything that never has to loop can be proven correct? And anything that will loop a fixed quantity of times can also be shown correct, except that the checker might decline to do so if it looks computationally intractable?
21:46:46 <edward1> you can also show general termination of some functions inductively and use those to build more complicated examples
21:47:08 <edward1> but basically then you step into theorem proving territory
21:47:12 <edward1> and i'm trying to steer clear
21:47:30 <edward1> i just want a language that can 'steal some of that theorem-proving mojo'
21:47:34 <skew> so is there any systematic way to help it along on correct examples that can't be totally verified?
21:47:47 <MyCatVerbs> edward1: I'm wondering how this deals with fold and map, for example - totally neccessary and guaranteed safe provided you pass a noninfinite list and a terminating function - but still recursive.
21:47:50 <edward1> right now? break it up into smaller pieces =)
21:48:29 <MyCatVerbs> I mean, I'd look like a right twerp trying to write large Haskell programs without ever calling map or fold. =)
21:48:34 <edward1> mycatverbs: i haven't tackled totality yet in its full glory.
21:48:38 <MyCatVerbs> Heehee.
21:48:47 <edward1> mycatverbs: yeah but the only restriction on them is you can't use them on TYPES ;)
21:49:10 <MyCatVerbs> edward1: is it permissable for these kinds of provers to have special ('illegal', even) knowledge about the conditions under which commonly used builtins can be guaranteed to terminate?
21:49:19 <edward1> sure
21:49:30 <edward1> i'm a pragmatist =)
21:49:50 <MyCatVerbs> Oh, awesome. That's gotta make somebody's phD a *lot* easier. =)
21:49:56 <edward1> go look at something like concoqtion, they do that, call out to coq for the heavy lifting =)
21:52:11 <ddarius> skew: But essentially all you need to do to support dynamically typed polymorphic values is delay parts of type checking to runtime.
21:52:16 <ddarius> And clearly that generalizes, all aspects of type checking can be supported by delaying type checking to run-time.
21:54:14 <dons> yep. you just need access to the type checker at runtime, and a representation of the type AST, as a value that persistts to runtime
21:54:23 <MyCatVerbs> edward1: but this is all meant to be proving properties of the types that your functions might return and largely independant of their behavoir?
21:55:02 <edward1> anyways the biggest issue is that the principal typings for terms in an impredicative type system with subtypings are not inferrable, however, there is a 'hack in the ESC/Haskell technique that i think can solve a lot of the 'practical' considerations
21:55:38 <skew> edward1: principal types or principal typings
21:55:54 <edward1> both should be not inferrable
21:56:28 <edward1> some local type inference hacks help out a bit though
21:56:31 <MyCatVerbs> edward1: to be entirely honest, I don't really see how writing a theorem prover for my source would help more than surrounding chunks of it with (conditionally compiled?) unit tests.
21:56:52 <edward1> mycat: well, you don't write it, its part of the compiler, and its written =)
21:57:16 <MyCatVerbs> edward1: but then, I can definately see the value in doing absolutely bloody masses of research on it. That way the problem can be more or less cracked entirely and get standardised into all the compilers. ^^
21:57:47 <monochrom> unit tests are finite approximations for properties to be proved.
21:57:56 <skew> ddarius: but how do you check the code around the use of the dynamic
21:58:08 <edward1> the parts that are neat are that you can expose rewrite rules this way, so you can say that Int is an integral domain, and you can talk about commutativity and associativity, so there is an incestuous relationship between type checking, and exposing rewrite rules and the predicate checks, etc.
21:58:22 <MyCatVerbs> monochrom: yuhuh. But they pay off surprisingly rapidly, up until you hit the (almost immediate) plateaus.
21:58:44 <monochrom> I am not dissing unit tests.
21:58:54 <MyCatVerbs> monochrom: fair enough.
21:59:15 <skew> with principal typings you have a guarantee that you can typecheck any open term, check whether it's possible for it to work out at all, and come up with minimal assumptions on the term you want to stick in
21:59:20 <monochrom> I am saying, if you understand unit tests, then take limit and you understand assertions, properties, etc., too.
21:59:26 * MyCatVerbs would still much rather fly in an airplane whose code has had a theorem prover run over it than an airplane held in the sky by diligent unit tests anyway. ^^
22:00:04 <edward1> btw- since i have the CEG unrolling thing, and i can prove some of them, and disprove others in a rigorous fashion, the ones in the middle make a good case for being analyzed automatically in terms of pre and post conditions with a quickcheck type tool. you can take and use the 'arbitrary' instance, generate test data, make sure all the preconditions are met and run it through looking for counter examples that way.
22:00:33 <skew> edward1: and of course, farm them out to a theorem prover
22:01:09 <edward1> skew: i can't tell you a minimum set of assumptions, i'm impredicative
22:01:27 <edward1> currently allowing f-bounded subtyping even =)
22:01:47 <edward1> i figured i'd throw the type system wide open and see how far i could go with the predicates
22:01:48 <MyCatVerbs> edward1: I've heard that you can apparently use a pessimistic (in?)version of the amb operator to exhaustively search for execution paths that make your program blow up. Was I misunderstanding that?
22:01:54 <monochrom> Everyone knows more about formal verification than they think.
22:02:37 <edward1> mycat: not sure how fast that would be ;)
22:02:41 <MyCatVerbs> monochrom: limit case: what about those smelly little EJB weenies who think they know -everything-? =D
22:03:38 <MyCatVerbs> edward1: it's something like backtracking search under the hood, I've heard O(n^2) mentioned. But I've no clue what the Hell that's in terms of, program length or recursion depth.
22:04:02 <edward1> skew: the hard part i have yet to do, because i need a good theorem prover i can pass a nice set of rewrite rules to, that can figure out a nice simplified form of expressions
22:04:07 <mwc> wtf
22:04:08 <mwc> ghci
22:04:09 <mwc> ghc-6.6: not built for interactive use
22:04:18 <mwc> stupid 'buntu packages ;(
22:04:18 <MyCatVerbs> mwc: oh, dude, boned.
22:04:21 <monochrom> My condolesence
22:04:29 <MyCatVerbs> mwc: my advice, comrade: build 6.6.1
22:04:47 <monochrom> I use the binary tar.bz2
22:05:21 <edward1> the biggest problem i have right now is that its kind of a pain in the butt to write monads and things in my current language because i lack haskell style typeclasses, i just have records and typecase, so you have to do the plumbing yourself
22:05:21 <mwc> I'm test driving 'buntu... So far it doesn't compare to Arch
22:06:05 <monochrom> ubuntu is fine if you discount the easily solved ghc issue.
22:06:29 <MyCatVerbs> monochrom: meh, it's fun to exercise the Hell out of the machine by compiling huge stuffs like ghc - I still have just a little bit of Gentoo user in me, somewhere, y'see. Probably left over from that last kernel ricer I murdered and ate... er, forget I said that?
22:07:07 <SamB> MyCatVerbs: see, this is why you should not eat them after you kill them
22:07:16 <mwc> monochrom: yeah, but this is just icing on the annoyance cake. i'm googling around for 6.6.1 debs
22:07:34 <skew> surprise, the debian debs seem to work
22:07:35 <monochrom> debian unstable has the debs.
22:08:13 <mwc> ah, but for ppc ;)
22:08:38 <monochrom> ghci does not exist for ppc, ubuntu or deb or arch or gentoo or fc or ...
22:08:49 <MyCatVerbs> SamB: oy vey, sod that.
22:09:15 <MyCatVerbs> SamB: I'm *hungry*. What the Hell else do you expect me to eat, alpacas?
22:09:29 <monochrom> cheese
22:09:32 <edward1> mycat: anyways, one way to work on finite lists safely would be to build a primitive catamorphism operator that can destruct a least fixed pointed type, that can be done safely, its the anamorphisms and general recursion that get you
22:10:03 <MyCatVerbs> edward1: you just referenced about three entire _fields_ of CS that I have no grounding in. :/
22:10:15 <edward1> hahahaa
22:10:29 <monochrom> WLOG, you can narrow it down to catamorphism and anamorphism, just two.
22:10:48 * MyCatVerbs dons a conical hat. It bears no stars or cresents. It is not a wizard hat, oh no. Instead, it bears a five letter word beginning with 'D'.
22:11:06 <monochrom> All programs can be rewritten as a composition of cata and ana, so you can't narrow it down further.
22:11:11 <edward1> and really those are both part of the same discipline =)
22:11:11 <mwc> monochrom: that's incorrect. I had ghci running on OS X, on Arch Linux/PPC, etc
22:11:23 <monochrom> OH! Darn.
22:11:38 <monochrom> ghci 6.6.1 ?
22:11:54 <mwc> yeah, 6.4 even
22:12:01 <mwc> and 6.6.1 just yesterday
22:12:07 <mwc> before the 'buntu experiment
22:12:44 <edward1> monochrom: well, not efficiently, you eventually need to add a few more tricks to the bag, a view of their concatenation as hylomorphisms for fusion rules, and you want generalized catamorphisms and generalized anamorphisms parameterized over an arbitrary comonad and monad eventually, etc.
22:12:53 <ddarius_> monochrom: If you separate the types that can be folded from those than can be unfolded you're still safe.
22:13:02 <mwc> Was there ever a 6.2.2? that seems familiar to me, but I can't remember if I actually used it
22:13:49 <mwc> Oh well, I'll futz with this later. night all
22:14:57 <edwardk> i'm really really tempted to add haskell style data types and type classes to minimize the amount of plumbing i have to carry around
22:15:11 <edwardk> but thats a whole other can of worms to open
22:15:27 <edwardk> and things are messy enough in there without trying to figure out if i have those right =/
22:15:54 <edwardk> the records/variants thing actually worked out nicely, because they let me get rid of 'case' in exchange for a fancier application rule
22:19:22 <MyCatVerbs> edwardk: I can't really see the point of making up minilanguages like that. Well, doing it at least once is -extremely- good for the soul, I think, but unless you're exploring uncommon features (and combinations thereof) with your own langauges, wouldn't the upshot from hacking on the same compiler that everyone else is putting work into be much greater?
22:20:27 <edwardk> mycat: no one has a base language that i can reasonably extend with the features i want
22:20:45 <ddarius> MyCatVerbs: You need to figure these things out and it's very difficult to modify a large codebase.
22:20:51 <MyCatVerbs> edwardk: so you're exploring different feature sets? Fair enough.
22:20:55 <edwardk> yeah
22:21:12 <MyCatVerbs> ddarius: that's the second exception I was careful to make. 
22:21:35 <MyCatVerbs> The first being the karma thing, "If you don't write your own compiler at least -once-, are you sure you're really a programmer?"
22:22:39 <ddarius> I'm not sure if I've written a compiler... certainly for some values of "compiler" I haven't.  I've written plenty of interpreters.
22:22:40 <atp> @src cycle
22:22:40 <lambdabot> cycle [] = undefined
22:22:40 <lambdabot> cycle xs = xs' where xs' = xs ++ xs'
22:22:52 <atp> ah
22:22:52 <ddarius> That's bizarre.
22:23:01 <atp> i had always wondered how that was defined :)
22:23:04 <atp> i guess that makes sense
22:24:03 <edwardk> polymorphic records and variants have been explored by academics, but they aren't really in widespread use, and no one is using the 'record as case' formulation i tripped over by accident, the extended static checking thing is just way too cool, and it generalizes to a very nice subset notation { x : T | P x } (or use ()'s if your record syntax conflicts, which is where i am now) which is sweet and easy to explain, substructural type inferen
22:25:04 <MyCatVerbs> ddarius: eh, I wouldn't worry about the distinction, really.
22:26:07 <edwardk> exposing the same syntax for type level functions as term level functions keeps people from getting turned off by having to learn a whole 'meta-language' like typeclasses in haskell and open up the syntax a lot, pure type systems have had that for a long time, but they generally have crappy syntaxes and no type-inference, ..., you get the idea ;)
22:26:08 <ddarius> It's pretty significant.  I'm also mildly amused by the fact that I probably have written a compiler, I just don't remember it.
22:26:20 <MyCatVerbs> ddarius: I'm totally ripping off Yegge here, but having actually written a compiler or a 'terp yourself gives you a *much* better conception of what the Hell programming really is, y'know? Kinda chases all the scary voodoo mythos out of it.
22:26:50 <ddarius> MyCatVerbs: It depends on the language(s) you implement.
22:26:55 <MyCatVerbs> It's like checking behind the curtain and seeing a mirror there. Oh hi, it was actually a bunch of mortals like yourself all along.
22:26:56 * SamB_XP invents a programming language based on voodoo dolls
22:27:31 <ddarius> I do remember when implementing a programming language seemed like an awe-inspiring feat.
22:27:36 <MyCatVerbs> ddarius: well, no prizes for the metacircular interpreter in Lisp, but I'm not so sure about that. =)
22:27:52 <edwardk> heh, i've been writing compilers and assemblers pretty much since i started programming. though, i wrote the assembler because i told another kid in 3rd grade that i'd already written it, and then had to make good on that when he caled my bluff.
22:28:05 <edwardk> they do blow a lot of cobwebs out of your thinking
22:28:10 <MyCatVerbs> ddarius: I think the lower limit for what has to be done that actually -matters- might be a lot lower than you'd normally think.
22:28:32 <ddarius> MyCatVerbs: Now I have no idea what you are talking about.
22:28:39 <edwardk> heh, i have a metacircular compiler in javascript, does that count? =)
22:28:41 <MyCatVerbs> ddarius: yeah, that sentence sucked.
22:29:19 <luqui> I have a function that looks like this:
22:29:28 <MyCatVerbs> ddarius: lemme try again. I think the lower limit of how clever a language you'd have to create for yourself in order to get (most of) the really important benefits might be lower than you'd expect.
22:29:35 <luqui> do decks <- mapM (...) [1..100000]
22:29:35 <edwardk> but its a real compiler, constant folding, common subexpression elimination, cps trampolined threads, etc.
22:29:44 <luqui>    return $ length $ filter (...) decks
22:29:50 <luqui> and it is using tons of memory
22:29:56 <luqui> but obviously it doesn't need all that memory
22:30:00 <ddarius> MyCatVerbs: I was talking about "chasing the scary voodoo mythos" out of programming.
22:30:10 <luqui> how do I reduce the memory usage of this naturally?
22:30:14 <monochrom> edwardk is a good example of programming by lazy evaluation.
22:30:49 <edwardk> mono: heh, i start working on things, get what i need out of them, then quit? =)
22:31:08 <MyCatVerbs> ddarius: ohkay, I specifically meant "chasing the scary voodoo mythos out" when I said "the really important benefits" there.
22:31:33 <ddarius> Implementing, say, Tiny C leaves a lot of magical stuff out there.
22:31:36 <monochrom> No. You boast that you have an assembler. Then someone calls you to it. Then the assembler is written. :)
22:31:42 <edwardk> =)
22:31:54 <ddarius> luqui: If I understand correctly you want a foldM
22:32:10 <luqui> I can't use length lazily like that?
22:32:22 * sorear just last week wrote an assembler and most of two compilers
22:32:35 <ddarius> luqui: Depending on the monad, the mapM will be completely evaluated before you reach the next line.
22:32:41 <luqui> it's in IO
22:32:45 <MyCatVerbs> ddarius: oh, right. Jah. But it'll sharply clear up most enough all your misconceptions about *procedural* programming, so...
22:32:50 <edwardk> luqui: you aren't lazy because of the mapM in IO, so it did all that work
22:32:55 <luqui> ok
22:33:10 <edwardk> the list was built up strictly as you went
22:33:22 <monochrom> Must you work in IO?
22:33:23 <luqui> hmm... is there a way to still use length?
22:33:25 <ddarius> I've written various chunks of compilers, but not yet a HLL->Machine Code compiler.
22:33:35 <edwardk> what are you using IO for?
22:33:40 <luqui> random
22:33:42 <luqui> I could pass a randgen
22:33:44 <ddarius> luqui: Not one that I want to recommend.
22:33:46 <luqui> but I was being lazy...
22:33:46 <monochrom> I knew it.
22:34:08 <ddarius> s/a HLL/a full HLL/
22:34:15 <edwardk> @type randoms
22:34:18 <lambdabot> forall g a. (Random a, RandomGen g) => g -> [a]
22:34:23 <sorear> ddarius: Is Forth a high level language in your book?
22:34:38 <MyCatVerbs> ddarius: and if you try adding a primitive object system to it then suddenly things like C++ and Objective C no longer seem scary, and if you then make the (rare, gargantuan) attempt to hack in some kind of GC then Java will feel pretty trivial to work in.
22:34:39 <monochrom> Someone please help luqui cook a pure version. Yeah based on the streams. I have forgotten enough details to do it myself.
22:35:04 <ddarius> sorear: One could argue that it's not, but I would say it was enough (at least as far as HL v. assembly goes).
22:35:09 <sorear> MyCatVerbs: Gc is very easy, I've done it several times
22:35:10 <MyCatVerbs> ddarius: eh, machine code's too much damn effort. I'd say a reasonable bytecode is probably usually enough.
22:35:16 <sorear> MyCatVerbs: Indeed, I've done generational
22:35:20 <edwardk> there is nothing wrong with forth that a good type system, er... and rewriting it, couldn't fix ;)
22:35:42 * luqui cooks a pure version...
22:35:48 <edwardk> hahaha
22:35:51 <luqui> I'm still not sure what's lazy about haskell and what's strict
22:35:52 <edwardk> pureForth
22:35:53 <sorear> @remember edwardk there is nothing wrong with forth that a good type system, er... and rewriting it, couldn't fix
22:35:54 <ddarius> I've made a virtual machine.
22:35:54 <lambdabot> Done.
22:35:54 <MyCatVerbs> sorear: but you're a freak of nature. You hang out in #haskell and when your brain cells finally do die, it won't be of loneliness.
22:36:02 <luqui> so I tend to do things however I want and cross my fingers :-)
22:36:04 <MyCatVerbs> sorear: I do not believe these are normal traits. =)
22:36:29 <edwardk> luqui: whenever you tell the IO monad to do something, it'll do those steps in order. mapM makes a bunch of little steps one for each item in the list
22:36:39 <edwardk> so mapM in IO over an infinite list never returns
22:36:43 <luqui> ok
22:37:04 <edwardk> so by the time you get to your filter and length you've already done all the steps and built up a massive list
22:37:16 <monochrom> Yeah!  Infinite lists and "undefined" are good ways to test for strictness if you need.
22:38:13 <monochrom> Example. "const x y" is that strict in the y part? const 1 undefined.
22:38:15 <ddarius> I remember making a crazy converter from Haskell to C that was... out there.
22:38:34 <MyCatVerbs> sorear: I think I need to read up on how generational GC actually works. As is, I only actually properly understand mark-and-sweep, (I think that's the term for the algorithm I'm thinking of). That blew my mind to see how little code it took to get a runnable implementation.
22:38:35 <edwardk> so anyways
22:38:38 <edwardk> you could so something like
22:38:38 <ddarius> (for the vm)
22:38:43 <monochrom> Example. "x * y" is that strict? 0 * undefined.
22:39:05 <ddarius> > 0 * undefined
22:39:06 <lambdabot>  Undefined
22:39:24 <MyCatVerbs> > take 3 $ "poo" ++ undefined
22:39:25 <lambdabot>  Undefined
22:39:34 <luqui> ok.  sooo...
22:39:34 <edwardk> do generator <- getStdGen; return $ length $ filter $ map (...) $ randoms generator
22:39:35 <MyCatVerbs> ...eh?
22:39:43 <MyCatVerbs> > take 3 $ "few moar characters" ++ undefined
22:39:44 <lambdabot>  "few"
22:39:50 <MyCatVerbs> > take 3 $! "few moar characters" ++ undefined
22:39:52 <lambdabot>  "few"
22:40:03 <MyCatVerbs> ...oh right.
22:40:06 <luqui> yeah, I grok most of that, (except the $! stuff, which I've never touched)
22:40:16 <MyCatVerbs> > take 3 $ (++) "few moar characters" $ undefined
22:40:17 <lambdabot>  "few"
22:40:20 <MyCatVerbs> > take 3 $ (++) "few moar characters" $! undefined
22:40:22 <lambdabot>  Undefined
22:40:31 <luqui> and now I understand $! :-)
22:40:41 <monochrom> @src take
22:40:41 <lambdabot> take n _      | n <= 0 =  []
22:40:41 <lambdabot> take _ []              =  []
22:40:41 <lambdabot> take n (x:xs)          =  x : take (n-1) xs
22:40:48 <edwardk> @src ($!)
22:40:48 <lambdabot> Source not found. Wrong!  You cheating scum!
22:41:15 <MyCatVerbs> luqui: $ is just function application, right? Its main use is enabling you to use less parentheses.
22:41:17 <monochrom> > take 0 undefined
22:41:18 <lambdabot>  Undefined
22:41:42 <ddarius> A paper on drawing hairs on plants...
22:41:44 <monochrom> That is either a bug or a feature.
22:41:44 <luqui> yeah, but $! is what I didn't grok
22:41:54 <luqui> which evaluates its right argument, then applies the function
22:41:57 <MyCatVerbs> luqui: $! is the same thing, but it forces the system to _completely_ evaluate the arguments before making the function call.
22:42:15 <monochrom> I think "completely" may be interpreted wrong.
22:42:19 <luqui> yeah
22:42:32 <monochrom> > take 1 $! ("ab" ++ undefined)
22:42:33 <lambdabot>  "a"
22:42:39 <sorear> MyCatVerbs: You should study copying collection, it's about as simple as m&s.  Once you have that, the leap to generational should be (relatively) simple.
22:42:39 <luqui> I get it.
22:42:41 <monochrom> Not very completely.
22:42:54 <MyCatVerbs> monochrom: oh, wow.
22:42:55 <sorear> MyCatVerbs: Just remember that object lifetimes are like earthquakes
22:43:04 <MyCatVerbs> sorear: bloody unpredictable?
22:43:05 <sorear> MyCatVerbs: The bigger they are, the rarer
22:43:12 <luqui> hmm, so how is $! implemented?
22:43:24 <MyCatVerbs> sorear: and everything gets shaken up and falls off the damn shelves when they come up?
22:43:24 <monochrom> Evaluation stops as soon as the first cons cell is exposed.
22:43:26 <ddarius> sorear: A heuristic.
22:43:41 <edwardk> ddarius: but a pretty useful one
22:43:46 <ddarius> @src ($!)
22:43:46 <lambdabot> Source not found. You type like i drive.
22:43:54 <MyCatVerbs> monochrom: oh, I see. That still works because $! is applied to the "take" call and not the ++ operator?
22:44:00 <ddarius> f $! x = x `seq` f x
22:44:02 <edwardk> which is why i like region-based memory management, poof O(1) as long as your program decomposes nicely
22:44:14 <MyCatVerbs> sorear: I like that explaination. =)
22:44:24 <monochrom> $! is applied to the ++ operator.  Still, only goes so far as getting the top cons cell.
22:44:49 <monochrom> > length (take 1 $! (undefined : undefined : undefined))
22:44:50 <lambdabot>  1
22:44:58 <luqui> I understand it... but I'm having trouble explaining it, so it's hard to verify that I understand it
22:45:07 <sorear> edwardk: ALL reasonable allocation systems are O(1) amortized allocation cost.  copying, m&s, generational, buddy, slab, etc
22:45:08 <monochrom> You don't even need the list elements!
22:45:17 <MyCatVerbs> > length [undefined,undefined]
22:45:19 <lambdabot>  2
22:45:29 <ddarius> luqui: Lookup and understand weak head normal form
22:45:31 <edwardk> sorear: O(1) freeing cost, regardless of the amount of the size of the heap though =)
22:45:36 <sorear> edwardk: constant factors are a big deal however, and stack/region wins by a *long* shot
22:45:36 <edwardk> sorear: no amortization ;)
22:45:41 <monochrom> > length $! [undefined,undefined]   -- also notable
22:45:42 <lambdabot>  2
22:45:45 <MyCatVerbs> monochrom: _ <-- my mind just blew up again.
22:45:51 <luqui> ddarius, I've implemented systems like this before, which is why i think I understand it
22:45:54 <monochrom> I like doing that to people :)
22:46:06 <dons> hey luqui.
22:46:09 <luqui> and "weak head normal form" seems to describe things I've implemented pretty well :-)
22:46:19 <MyCatVerbs> monochrom: evaluation strategies are helluvva subtle.
22:46:22 <luqui> dons, ?
22:46:29 <edwardk> only problem i am running into at the moment is that 'laziness' and 'regions' don't play nice
22:46:30 <dons> long time no see. :-)
22:46:35 <luqui> yeah, it's been a while
22:46:39 <monochrom> MyCatVerbs: "weak head normal form" is the keyword here.
22:46:40 <ddarius> Well then the explanation for $! is simply that it reduces it's (second) argument to whnf before applying.
22:47:06 <MyCatVerbs> monochrom: I thought that was just the mathematical term for "already evaluated"?
22:47:14 <dons>  :-)
22:47:14 <ddarius> MyCatVerb: It's pretty straightforward (in this regard), it just evaluates as much as is needed.
22:47:34 <ddarius> MyCatVerb: Normal form would be "completely" evaluated.
22:47:59 <luqui> woah... longer than I remembered
22:48:08 <dons> ?remember luqui "weak head normal form" seems to describe things I've implemented pretty well :-)
22:48:08 <lambdabot> Done.
22:48:17 <dons> that's a nice quote, i've not heard that one before.
22:48:25 <monochrom> There are too many shades of "already evaluated".  "WHNF" pins down exactly one of them.
22:48:39 <MyCatVerbs> ddarius: oooh.
22:48:53 <dons> weak head is really least evaluation possible.
22:49:01 <ddarius> It's a fairly natural one for "evaluating as much as is needed" for functional languages.
22:49:02 <dons> so only reduce to the outermost constructor.
22:49:16 <ddarius> dons: For LP languages it's more complicated.
22:49:42 <dons> > let x = Just undefined in x `seq` ()
22:49:44 <lambdabot>  ()
22:49:46 <dons> > let x = undefined in x `seq` ()
22:49:48 <lambdabot>  Undefined
22:50:29 * ddarius is reminded of subdivision surfaces.
22:50:33 <dons> anyone want a little example of why zippers are so much better for implementing window managers?
22:50:36 <MyCatVerbs> ddarius: er, looking at SICP, they show the difference between applicative-order evaluation and normal-order evaluation and show that applicative-order is by-value, eager evaluation.
22:50:51 <MyCatVerbs> ddarius: so, is normal-order evaluation equivalent to lazy evaluation...?
22:51:01 <ddarius> MyCatVerbs: Yes and no.
22:51:02 <Lemmih> dons: Yes!
22:51:05 <dons> using a lookup table, the 'swap' function, which swaps the focused window with the left most window on the screen, was: 11 lines long.
22:51:11 <dons> it is now 2 lines:
22:51:15 <MyCatVerbs> 'Cuz they show one or two example programs that terminate under applicative but not normal-order...
22:51:18 <monochrom> dons: Is it because zippers enable quick clean walking of list/tree all ways?
22:51:18 <dons> soryr, 3:
22:51:19 <dons> swap = modify Empty $ \c -> case c of
22:51:19 <dons>     Node _ [] _  -> c    -- already master.
22:51:19 <dons>     Node t ls rs -> Node t [] (ys ++ x : rs) where (x:ys) = reverse ls
22:51:31 <dons> monochrom: more that they naturally encode 'focus' and 'master' directly.
22:51:34 <luqui> okay, so back to my original question, purifying my example.  I want a "stream" of random numbers to follow me through a sequence of function calls, where I can extract a random number at will
22:51:41 <dons> whereas with a lookup table, you end up indexing and filtering a lot.
22:51:44 <luqui> some kinda monad will work here
22:51:44 <ddarius> MyCatVerbs: There is a difference between semantics and implementation.
22:51:49 <edwardk> luqui: i pasted one above more or less
22:51:53 <MyCatVerbs> ddarius: oh, okay. Is normal-order a subset of lazy evaluation or something along those lines?
22:51:54 <dons> previously, just the bit on the rhs of the final line above was:
22:51:55 <dons> swap a b xs = maybe xs id $ do
22:51:55 <dons>     ai <- L.elemIndex a xs
22:51:55 <dons>     bi <- L.elemIndex b xs
22:51:55 <dons>     return . insertAt bi a . insertAt ai b $ xs
22:51:56 <monochrom> Oh! Cursor.
22:51:57 <dons>   where insertAt n x ys = as ++ x : drop 1 bs
22:52:00 <dons>             where (as,bs) = splitAt n ys
22:52:03 <dons> scary, huh.
22:52:12 <dons> monochrom: exactly. we get a notion of cursor by construction
22:52:13 <edwardk> do generator <- getStdGen; return $ length $ filter $ map (...) $ randoms generator
22:52:17 <dons> so tracking focus becomes tracking the cursor
22:52:29 <ddarius> MyCatVerbs: normal order is usually call-by-name, lazy evaluation is call-by-need.
22:52:31 <MyCatVerbs> ddarius: or am I just trying to form a connection that doesn't exist at all because of the commonality of the will/won't terminate thing?
22:52:39 <luqui> edwardk, the ... uses the random numbers, and more than one, a few function calls away
22:52:46 <luqui> so now this is not about random numbers
22:52:55 <luqui> but more about how to make a stream reader
22:52:55 <edwardk> ok
22:53:01 <edwardk> then pass them a generator
22:53:04 <edwardk> look at System.Random
22:53:06 <luqui> uh... duh
22:53:07 <luqui> ok
22:53:09 <ddarius> MyCatVerbs: Sometimes normal order is used as equivalent to non-strict (often times lazy evaluation is too, but it definitely is different).
22:53:09 <dons> and I have a hard time working out of 'swap' above is correct, , but I can see directly that the zipper version is right.
22:53:11 <luqui> :-)
22:53:23 <dons> so yay, domain specific data structures! :-)
22:53:37 <edwardk> there is also a Gen monad in Quickcheck that has nice functions for this sort of thing
22:53:46 <luqui> hm, probably won't need them
22:53:51 <luqui> passing the generator will do just fine
22:54:08 <luqui> I seem to have an affinity for not choosing obviously simple and correct solutions
22:54:24 <edwardk> you have to remember to plumb the generator throughout and pass it back out, becuase its pure. or you have to 'split' it before passing it to your nested functions
22:54:47 <edwardk> otherwise if you do something like f (myFoo mygenerator) (myFoo mygenerator)  it'll generate the same number each time
22:55:03 <edwardk> @type random
22:55:06 <lambdabot> forall g a. (Random a, RandomGen g) => g -> (a, g)
22:55:57 <MyCatVerbs> ddarius: righto. About the speed differences between eager and nonstrict evaluation, is the reason lazy eval is slower is mostly because of the added bookkeeping that gets done and the reason for normal-order being somewhat slower down to often calculating the same result several times? Same issue with different reasons?
22:56:14 <ddarius> This is pretty cool: http://algorithmicbotany.org/papers/goodlines.eg2003.html
22:56:15 <lambdabot> Title: A Few Good Lines: Suggestive Drawing of 3D Models
22:56:51 <edwardk> mycatverbs: plus when working strictly you may do more work than strictly necessary when you concatenate small bits of programs from various places
22:56:59 <ddarius> MyCatVerbs: eager : strict :: lazy : non-strict
22:57:26 <ddarius> MyCatVerbs: Also, for pure languages, lazy is asymptotically faster than eager under some assumptions.
22:57:50 <ddarius> In some cases.
22:58:20 <MyCatVerbs> ddarius: I think that's kind of attached to the bookkeeping overhead. Specifically that you can get lower complexity classes, but at higher constants.
22:58:22 <ddarius> Or to rephrase, there are algorithms that are implementable asymptotically faster in a pure lazy language as compared to a pure eager language.
22:58:54 <MyCatVerbs> ddarius: "some cases" <- trivially demonstratable, just jam an infinite list into the middle of your program. =)
22:58:55 <ddarius> MyCatVerbs: You don't have to perform any bookkeeping except where you
22:58:58 <ddarius> -have- to.
22:59:43 <monochrom> "more haste, less speed" contains an example, doesn't it?
22:59:46 <ddarius> MyCatVerbs: I'm saying that there are algorithms you -couldn't- implement as fast in a pure eager language as you could in a pure lazy language.
22:59:59 <ddarius> monochrom: Yes.
23:00:05 <MyCatVerbs> A large part of haskell optimization boils down to working out where the bookkeeping is and isn't neccessary?
23:00:25 <monochrom> It is just three pages or something. MyCatVerbs may like to take a look.
23:00:27 <edwardk> mycat: yep, strictness analysis eliminates a lot of overhead, etc.
23:00:59 <MyCatVerbs> monochrom: cool, thanks.
23:01:24 <edwardk> though, that said ddarius, there are examples where a 'pure' language doesn't have a known algorithm with asymptotic behavior as good as the imperative one.
23:01:28 <ddarius> MyCatVerbs: In so far as the aspects that are peculiar to Haskell, yes.
23:01:31 <MyCatVerbs> (BTW, I know I'm asking lots and lots and -lots- of stupid n00blet questions here. Apologies if I'm starting to get on peoples' nerves.)
23:01:43 <ddarius> edwardk: Yes.
23:02:15 <monochrom> Not stupid questions. n00blet yes. We love to eat n00blets.  Err I mean we love n00blets.
23:02:51 <ddarius> MyCatVerbs: You are not going to get on people's nerves in a way that is a problem for you without having some explicit notification of it.
23:02:56 <MyCatVerbs> monochrom: yeah, don't eat me. For your own good. You'd all die of massive coronaries within a week.
23:03:57 <monochrom> We don't bite.
23:04:52 <MyCatVerbs> edwardk: things like tha lack of mutable state meaning you can't do hash tables with O(1) insertion except by passing them around as state variables in monads?
23:05:25 <ddarius> Overall this site is pretty interesting: http://algorithmicbotany.org/papers/#webdocs
23:05:25 <MyCatVerbs> s/tha/the/ (my subconcious loves haggis)
23:05:26 <lambdabot> Title: Algorithmic Botany: Publications
23:05:50 <edwardk> basically there is some sort of pain associated, either you can't do that, or you have to have something else stateful behind the scenes, like there are array instances that will sort of fake being pure
23:05:52 <ddarius> MyCatVerbs: Meaning you can't do hash tables with O(1) insertion period.
23:06:22 <ddarius> Of course, the difference between pure eager and pure lazy is statefulness behind the scenes.
23:06:48 <MyCatVerbs> ddarius: not even inside of a monad?
23:07:16 <edwardk> mycatverbs: the ST monad is basically a mini-IO without world-access, there you can do it, but its not 'pure'
23:07:21 <ddarius> MyCatVerbs: If the monad let's you use imperative stuff, e.g. IO and ST, then yes, but you can't implement those in a pure language.
23:08:07 <edwardk> that said, you can possibly implement that in a 'pure' language with uniqueness types because if you hold the only reference to something you are permitted to modify it in place, but then you have to plumb around capabilities
23:08:36 <edwardk> that particular example is more complex than anything i've run in a uniqueness type system though
23:09:11 <MyCatVerbs> ddarius: you can't implement ST in a pure langauge? Je ne comprends pas. I thought the whole idea of monads is that they're the one way of implementing IO and ST in a pure language. 
23:09:23 <edwardk> the logic is that if i have something that i have the only reference to, its permissible for me to modify it in place
23:09:41 <bos> ddarius: where did you come across that site?
23:09:50 <edwardk> because there is no one to see the changes, no one else has any reference to it
23:13:25 <MyCatVerbs> edwardk: I was thinking with a little less firepower than that. Since there's only ever one copy of the state variable at any one time in a monad, the compiler might safely emit code that works on it in-place, which means array update can be done without having to make a copy of the whole array, so that you can update the array in O(1) instead of O(n). Once you've got that in hand, all you need to do is cons another record onto the list (if any) re
23:13:27 <ddarius> bos: http://www-swiss.ai.mit.edu/projects/amorphous/related_sites.html
23:13:33 <lambdabot> Title: Amorphous Computing: Related Sites
23:13:54 <MyCatVerbs> Er, did that get clipped off by the ircd? I have a sinking sensation it might've been over 512 bytes.
23:14:16 <edwardk> 'all you need to do is cons another record onto the list (if any) re' is where you got cut off
23:14:20 <ddarius> MyCatVerbs: You can (modulo some issues) implement the semantics, but not the asymptotic complexities.
23:14:55 <ddarius> MyCatVerbs: However, since they are abstract, they can be used to encapsulate impurities as well.
23:15:05 <MyCatVerbs> -all you need to do is cons another record onto the list (if any) pointed to by that array cell and update the array to point to the list's new head.
23:15:13 <edwardk> mycatverbs: thats the same idea as the 'uniqueness' type, one copy, no one else gets to see it, modify it in place and thread it through strictly, its not really 'pure' though =)
23:16:20 <MyCatVerbs> edwardk: yeah, but I think it could be workable and it does get us back into the running on asymptotic complexity pissing matches.
23:17:55 <MyCatVerbs> (albeit with the protest, "Oi, you bastard, you just reimplemented imperative hashtables using monads. That's no more bloody valid than a C programmer shipping a 'terp for a lazily evaluated language and claiming the complexity bounds gained by that as an achievement of the C language.")
23:18:17 <edwardk> i just enrich the types, look that one is unique, now field updates can be performed in place, uniqueness typing ensures that no one snags a copy along the way
23:18:44 <edwardk> unless you hand it to them and they hand it back before you modify it again
23:19:06 <ddarius> MyCatVerbs: There are no complexity gains gained by that.
23:19:15 <ddarius> That's the point.
23:19:38 <edwardk> ddarius: no complexity gains by what?
23:19:44 <MyCatVerbs> edwardk: ohkay, but I don't see how a uniqueness type is really neccessary here. Monads were appiled to FP -specifically- for the purpose of making sure there is exactly one and only one version of the universe being passed around, so I don't see why they can't be used to ensure that only one version of some other data structure is being passed around.
23:19:47 <ddarius> By implementing lazy FP in C.
23:20:19 <ddarius> MyCatVerbs: No, that is not why they were applied to FP.
23:21:09 <edwardk> mycatverbs: there are tons of monads that have nothing to do with a universe. they are used that way by moggi's monadic lambda calculus which popularized them, but there are tons of monads
23:22:39 <MyCatVerbs> ddarius: eh? But you said yourself, lazy evaluation occasionally gives you lower bounds than eager, so why wouldn't implementing a lazy language in an eager one allow you to use hooks into the lazy code 'terp in programs written in the eager language to get the asymptotic speedups when neccessary?
23:22:43 <edwardk> we use them for IO because its a heck of a lot cleaner than the old 'response'/''request' infinite lazy list model
23:23:18 <edwardk> mycatverbs; you missed a fine point of distinction, 'pure lazy' can be faster than 'pure eager' asymptotically, you missed 'pure' in 'pure eager' ;)
23:23:23 <MyCatVerbs> edwardk: oh. Fun. I had thought the IO monad was the primary purpose, and the things like list comprehensions were, er, "w00t bonus?"
23:23:52 <edwardk> to a lot of programmers thats they way they view them, to someone with a more categorical bent, the IO monad is a bit of a freak ;)
23:24:09 <ddarius> MyCatVerbs: No implementation of any lazy language has used monads to enforce single-threading of mutable state such that the compiler would optimize it to in-place update.
23:24:36 <MyCatVerbs> edwardk: ah. So it's mandanatory to keep one hand behind your back by promising not to implement the other strategy even if it's faster on some problems to cheat? =)
23:24:42 <edwardk> ddarius: clean offers up uniqueness operations on arrays for that purpose
23:24:51 <ddarius> IO isn't particularly different from the other monads from a categorical perspective.
23:24:59 <ddarius> edwardk: Yes, uniqueness types, not monads.
23:25:00 <MyCatVerbs> ddarius: but surely you could.
23:25:17 <edwardk> sure, but i can bundle that uniqueness state in a monad, they just don't bother
23:25:48 <ddarius> MyCatVerbs: You could, but that doesn't change the fact that that clearly demonstrates that that is not why monads were introduced into FP.
23:25:48 <edwardk> my toy language has uniqueness types, but i don't use them the way clean does, they make you do to much plumbing because they see uniqueness and monads as 'either/or'
23:25:54 <MyCatVerbs> ddarius: if you have a guarantee that there's only one copy of a data structure and no one else is referring to it, I really don't see why a smart enough compiler couldn't reduce it to a mutable record.
23:26:12 <ddarius> edwardk: They do, but again, they aren't relying on the monad to mainatain uniqueness.
23:26:30 <ddarius> edwardk: You can easily use monads in Clean.
23:26:35 <edwardk> sure
23:26:41 <edwardk> just referring to the dominant paradigm
23:27:13 <ddarius> MyCatVerbs: It can.  I said so repeatedly.  That's irrelevant to what I said.  Also, GHC sometimes -does- do that effectively with the state monad.
23:27:29 <edwardk> funny what a shift in the basic type system will let you make into a monad, oh, look you don't have recursion built in, here is a general recursion monad... ;)
23:30:04 <MyCatVerbs> ddarius: I'm missing something here. What misconception is it that you're trying to beat out of me, please?
23:30:11 <edwardk> heh
23:30:21 <edwardk> i'm a little confused on that front as well now
23:30:45 <ddarius> [01:18] <ddarius> MyCatVerbs: No, that is not why they were applied to FP.
23:31:00 <ddarius> [01:23] <ddarius> MyCatVerbs: You could, but that doesn't change the fact that that clearly demonstrates that that is not why monads were introduced into FP.
23:31:06 <MyCatVerbs> ddarius: right. That one went flying out of the window about ten minutes back.
23:31:15 <edwardk> =)
23:31:40 <MyCatVerbs> ddarius: and I've no idea what the Hell you're talking about there. What demonstrates that why is not why monads were introduced?
23:31:56 <ddarius> [01:22] <ddarius> MyCatVerbs: No implementation of any lazy language has used monads to enforce single-threading of mutable state such that the compiler would optimize it to in-place update.
23:33:41 <MyCatVerbs> ddarius: hrmn. Okay, I'm not suggesting that the compiler should push your code into this pattern as an optimization, I'm suggesting that if you write your code in this pattern it would make it possible for a sufficiently clever compiler to optimize it down to a lower complexity bound.
23:33:52 <MyCatVerbs> Or is that not it?
23:34:02 <edwardk> to which i'll answer thats because uniqueness is a comonadic property in the type system, so a monad is the wrong tool ;)
23:34:15 <int-e> I'm playing with family instances a bit - am I right to assume that after  type instance Foo Int = Float,  x :: Foo Int; x = 0.1  should work?
23:35:05 <ddarius> MyCatVerbs: All I am saying is that history does not bear out monads being introduced to FP for this reason.  I've said several times now, that compilers can and do do this.
23:35:25 <MyCatVerbs> ddarius: ...okay, which I've admitted wasn't the point, about, um, four times in a row now?
23:35:28 <int-e> (the family declaration for Foo is  type family Foo a)
23:36:19 * edwardk quietly inters the dead horse, and holds a brief candlelit vigil.
23:36:25 <MyCatVerbs> ddarius: I'm not even contesting that point. It's really nothing whatsoever to do with anything to do with what the Hell I'm talking about.
23:37:11 <MyCatVerbs> ddarius: what I'm talking about is that I think you could (admittedly abuse) the monad system to get an O(1) insertion hash table.
23:37:39 <ddarius> MyCatVerbs: And I've said, since the first time you said that, that you could, so why do you keep repeating yourself?
23:37:45 <edwardk> mycatverbs: sure, its been done, use an STArray in a ST monad and go =)
23:37:48 <MyCatVerbs> ddarius: because you said I couldn't.
23:38:23 <MyCatVerbs> "07:13:16 < ddarius> MyCatVerbs: You can (modulo some issues) implement the semantics, but not the asymptotic complexities." "07:04:48 < ddarius> MyCatVerbs: Meaning you can't do hash tables with O(1)"
23:38:41 <ddarius> edwardk: Replied to that aspect,[01:13] <edwardk> mycatverbs: thats the same idea as the 'uniqueness' type, one copy, no one else gets to see it, modify it in place and thread it through strictly, its not really 'pure' though =)
23:39:32 <ddarius> MyCatVerbs: You can't simulate mutation with the same asymptotic complexities.  You certainly can implement mutation with mutation.
23:39:53 <edwardk> mycat: basically the response was that you can't do so in a 'pure' language for some definition of pure that precludes substructural type annotations or ambitious optimizations by the compiler. basically in a call-by-need lambda calculus setting you're screwed, but in the real world you're fine
23:41:27 <MyCatVerbs> edwardk: jah, but surely I have to be able to take into account optimizations what how the code is structured might or might not expose to the compiler. Otherwise how could one show that tail recursion lets you do work in O(1) space instead of O(n)?
23:41:41 <edwardk> good thing we're not working in a call-by-need lambda calculus then isn't it ;)
23:41:42 <MyCatVerbs> s/what/that/
23:42:11 <MyCatVerbs> edwardk: gah. But nobody bloody does that anyway because you wouldn't have tail recursion if you did. x_x
23:42:17 <edwardk> =)
23:43:20 <MyCatVerbs> edwardk: see, this is one of the advantages of Scheme. It says it right there in the RnRS report, you are not allowed to call your compiler or 'terp "Scheme" if you don't implement tail recursion, dammit.
23:43:34 <edwardk> heh
23:43:50 <edwardk> it took me all this time to figure out that you'd been saying 'terp for 'interpreter' ;)
23:44:06 <MyCatVerbs> edwardk: whoopsy, old habit.
23:45:21 <MyCatVerbs> edwardk: and I really don't get this insistence on discussing theoretical 'pure' languages that aren't allowed to do any optimizations at all and the real, actually pure functional language that we're actually using and implementing and moaning about the syntax of which -does-.
23:45:32 <edwardk> sure
23:45:39 <edwardk> i'm a pragmatist
23:45:44 <edwardk> it was just a fine point of distinction
23:46:01 <MyCatVerbs> edwardk: what the Heck is the point in discussing the former? Who would ever want to use it? It's not even a useful mathematical model, FFS, because it doesn't give the same results as the universe does.
23:46:13 <ddarius> Optimization isn't the point.  The point is that you -can- simulate mutation without using mutation -anywhere-, but -not- with the same asymptotic bounds.
23:47:02 <edwardk> because it offers nice equational reasoning properties. uniqueness types offer a subset of those reasoning properties because you can't always reverse them, etc.
23:47:49 <edwardk> er offer only a subset of
23:48:16 <MyCatVerbs> ddarius: so you have to write large chunks of your code inside of a fairly rickety and unstable monad. I'm not really sure if there's much of a problem in practice, though, because the situations in which you'd want an O(1) hash table usually occur in the middle of an IO monad anyway.
23:48:28 <edwardk> nah
23:48:31 <edwardk> they happen all over the place
23:48:42 <edwardk> i want them for memoizing hashconsed values
23:48:44 <edwardk> for instance
23:48:57 <edwardk> something that has a 'pure' interface but needs state on the back end
23:48:57 <MyCatVerbs> edwardk: oh, my bad. Hrmn.
23:49:00 <ddarius> MyCatVerbs: I'm just talking about theory.  In practice, we just use mutation.
23:49:27 <ddarius> It -would- be a significant result if we -could- simulate mutation with the same asymptotic bounds.
23:50:08 <MyCatVerbs> ddarius: but a theory which doesn't match -anyone-'s practice ought to be thrown out the window and replaced with one that does.
23:50:25 <ddarius> MyCatVerbs: Mathematics does not have mutable variables.
23:50:50 <ddarius> Denotational semantics is pretty much -exactly- such a language.
23:52:02 <MyCatVerbs> ddarius: (academic whining point, ignore this) only on the same basis as mathematics lacks square roots of negative numbers - right up until the moment where you contruct a larger mathematical system which *does* have a concept of mutable variables.
23:52:23 <int-e> hash tables aren't the only case where mutation is useful. union find data structures are another example.
23:52:28 <ddarius> MyCatVerbs: Based on?
23:52:53 <ddarius> MyCatVerbs: And there is no -reason- to.  I don't care about how fast a mathematical model runs.
23:53:01 <MyCatVerbs> ddarius: buggered if I know. Beat a mathematician with salmon jerky until he gets around to coming up with a theory that does.
23:53:23 <ddarius> Anyways, there are reasons mathematics doesn't have mutable variables.
23:54:58 <MyCatVerbs> edwardk: damnation. I was actually thinking of the task of parsing input files with keywords going into a hashtable for use later - in which case you could make multiple passes, filling the hashtable with tokens in one ST-monad operation and then using it as a constant for the rest of the input parsing.
23:55:26 <MyCatVerbs> edwardk: but that's totally useless for memoization, jah. :/
23:55:41 <edwardk> heh
23:56:04 <edwardk> you can fake it with unsafePerformIO and System.Mem.Weak references, etc
23:56:08 <int-e> you could try the diffarray trick.
23:56:27 <edwardk> int-e, that still requires changing the function's interface that you are memoizing
23:56:33 <int-e> (diffarrays are based on unsafePerformIO and an MVar)
23:57:02 <int-e> edwardk: hmm. yes, I guess it does. but is that truely necessary? I think not.
23:57:03 <scodil> does anyone have any good introductory material or examples for simple distributed programming in haskell? basic map-reduce type stuff, spread over multiple computers.  is this easy? doable?
23:57:31 <int-e> edwardk: note: I meant the implementation of DiffArrays, I didn't want to use them directly.
23:57:38 <edwardk> yeah
23:58:00 <edwardk> same basic idea then
23:58:18 <ddarius> scodil: Other than distributed Haskell and ports which both are dead, I believe, there isn't direct support for distributed computing.
23:58:24 <int-e> indeed
23:58:37 <ddarius> scodil: Of course, you can handle aspects of it on your own.
23:58:42 <scodil> ddarius: so it would involve writing my own client-server framework, right?
23:59:32 <edwardk> as it is, i just moved my hashcons functions into a monad, and made the monad more complicated, yay for standard solutions ;)
23:59:42 <ddarius> scodil: Not necessarily client-server, but yes, you'd have to do the work of moving things about yourself.
23:59:46 <MyCatVerbs> ddarius: what about SSA as a mathematical model of mutable state?
23:59:53 <scodil> has anyone used hMPI? does that work with 6.6?
