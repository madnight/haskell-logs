00:00:16 <erisco> but now I want to see everything as a Proxy
00:00:30 <erisco> it makes more sense now than Producer, Consumer, Pipe, Effect, yadda yadda
00:03:19 <erisco> I guess I can intuit them now
00:04:03 <erisco> Producer has to just sends out downstream, Consumer just takes in upstream, Pipe takes in upstream and sends out downstream
00:05:02 <gamegoblin> there is a foldM, is there a foldA?
00:06:15 <kadoban> Okay, so this is annoying … I'm using persistent-th to generate my persistent types. How do I explicitly export some of this, like I have a Client entity with a name field, but if I try to export ClientName from the module it gives me an error because that's not a type constructor or class. If I remove the module export list and fire up ghci, ClientName exists in that module though. Help?
00:09:16 <erisco> gamegoblin, there is 'fold' from Foldable
00:09:52 <gamegoblin> :t fold
00:09:54 <lambdabot> (Foldable t, Monoid m) => t m -> m
00:10:17 <liste> kadoban it's a data constructor, not type constructor
00:10:34 <nshepperd> foldA :: (Monoid m, Applicative f, Foldable t) -> (a -> f m) -> t a -> f m?
00:11:52 <gamegoblin> :t foldM
00:11:54 <lambdabot> (Monad m, Foldable t) => (b -> a -> m b) -> b -> t a -> m b
00:12:05 <kadoban> liste: A data constructor is a synonym for value constructor? I don't understand then. I'm already exporting Client(..), and it's still not visible outside.
00:12:30 <liste> kadoban it's of another type
00:12:37 <gamegoblin> erisco: how does `fold` help?
00:13:13 <kadoban> liste: How do I figure out what type?
00:13:13 <liste> Client is the record, ClientName is the tag(?) of the field, used in queries
00:13:26 <liste> I have no idea what type Persistent generates for it
00:13:35 <liste> maybe -ddump-splices helps?
00:13:55 <kadoban> -ddumpsplices is … terrible for this. I tried to look, it's unbearable.
00:13:57 <nshepperd> something directly identical to foldM wouldn't work, since foldM requires >>= to let you look inside the accumulator before returning the next `m b`
00:13:58 * hackagebot Earley 0.10.0 - Parsing all context-free grammars using Earley's algorithm.  https://hackage.haskell.org/package/Earley-0.10.0 (OlleFredriksson)
00:14:10 <erisco> gamegoblin, I guess you can define it
00:14:16 <gamegoblin> nshepperd: actually all I really need it foldA_ 
00:14:18 <gamegoblin> :t foldM_
00:14:20 <lambdabot> (Monad m, Foldable t) => (b -> a -> m b) -> b -> t a -> m ()
00:14:20 <erisco> gamegoblin, http://lpaste.net/139252
00:15:39 <erisco> well, it isn't quite the same
00:15:50 <erisco> because the accumulator doesn't return in the applicative
00:16:11 <erisco> you've got to make some sacrifices
00:17:36 <nshepperd> that sort of foldA_ wouldn't work either
00:17:54 <nshepperd> :t traverse_ -- but maybe you want this?
00:17:55 <lambdabot> (Applicative f, Foldable t) => (a -> f b) -> t a -> f ()
00:18:26 <liste> kadoban look at the "code generation" section of http://www.yesodweb.com/book/persistent
00:18:44 <liste> seems it's an associated type
00:19:58 <gamegoblin> Traverse doesn’t take a starting value, which I need..
00:20:24 <erisco> you don't get join/bind
00:20:29 <erisco> and you kinda need that
00:20:48 <liste> kadoban so you need to export EntityField(ClientName), I suppose
00:20:57 <kadoban> liste: Ohhh, thanks. That's … so weird. So I need to import Unique and Entity from persistent and then export Unique(..) and etc …
00:21:45 <kadoban> That … seems a bit mind-bending. Probably because I don't really understand the syntax going on there, heh.
00:21:53 <liste> familiar with type families?
00:21:53 <nshepperd> With Applicative, your output actions can't depend on the previous values of the accumulator
00:22:10 <kadoban> liste: nope :-/
00:22:38 <nshepperd> unless the accumulator would be calculated purely, entirely separate from the applicative stuff
00:22:41 <erisco> nshepperd, what do you mean? sure it can
00:22:42 <liste> snoyberg's stuff relies on them quite heavily, so you might want to look into them
00:23:13 <kadoban> Yeah I might have to learn at least the very basics. I kinda figured I could treat that stuff as black-boxish and run with it, but maybe not so much.
00:23:27 <erisco> > foldA (+) 0 [1..10]
00:23:29 <lambdabot>      No instance for (Show (f0 a0))
00:23:29 <lambdabot>        arising from a use of ‘show_M6022426749818941234823’
00:23:29 <lambdabot>      The type variables ‘f0’, ‘a0’ are ambiguous
00:23:37 <erisco> > foldA (+) 0 [1..10] :: [Int]
00:23:39 <lambdabot>  [55]
00:23:57 <kadoban> liste: Either way though, thanks again. At least past the immediate hurdle, huzzah.
00:24:09 <nshepperd> erisco: >_>
00:24:09 <liste> you're welcome (:
00:24:10 <erisco> it just isn't that interesting :P
00:24:37 * nshepperd sees what you did there
00:24:50 <erisco> all that is happening is I am lifting the accumulator and values into some arbitrary Applicative
00:24:53 <erisco> :t foldA
00:24:55 <lambdabot> Applicative f => (a -> b -> a) -> a -> [b] -> f a
00:25:15 <erisco> so it isn't the same spirit as foldM, but there isn't anything I can do that I know of
00:26:01 <erisco> > foldA (+) 0 [1..10] "hello world"
00:26:03 <lambdabot>  55
00:27:37 <nshepperd> (Foldable t, Applicative f) => (b -> a -> b) -> (b -> f c) -> b -> t a -> f ()
00:27:46 <Lokathor> so i'm parsing some HTML and trying to setup a parser with Parsec
00:28:06 <nshepperd> ^^ that would just be a traverse_ of a scanl
00:28:07 <Lokathor> is there a "parse anything until you find this" type of thing i should be using?
00:28:13 <Peaker> foldA seems completely silly?
00:28:20 <erisco> it is XD
00:28:45 <Lokathor> oh, between
00:28:47 <Lokathor> nevermind
00:31:11 <frerich> Lokathor: 'between' wouldn't be my first choice. If I wanted to parse e.g. all letters up to the first digit, I would use 'many letter <* digit'
00:31:36 <Lokathor> well, <* goes from the back too right?
00:31:45 <Lokathor> in this case it's a 60mb file, is that wise?
00:32:33 <Hijiri> if it's attoparsec you might want to use manyUntil
00:32:40 <frerich> Lokathor: I'm not sure exactly what you meant by 'goes from the back' -- the parsing always starts from the front.
00:32:45 <Hijiri> (and then use a predicate matching the beginning of your thing)
00:32:57 <Lokathor> Hijiri, it's Parsec
00:33:05 <Hijiri> oh
00:33:12 <Hijiri> ok, ignore that I guess then
00:33:13 <frerich> Lokathor: 'many letter' will consume zero or more letters, 'digit' will ocnsume a single digit and '<*' will return just the result of 'many letter' but not 'digit'.
00:33:30 <Hijiri> also apparently I meant takeTill and not manyUntil
00:33:35 <Lokathor> frerich, oh, the notes I saw said that <* combined two parsers by doing the first forward and the later backward until they meet somewhere
00:34:03 <Lokathor> but they weren't official notes so i'm not too put off by them being wrong
00:34:48 <Lokathor> well i want to capture all text within a <span> </span> pair of tags
00:34:49 <frerich> Lokathor: Triggered by Hijiri's comment Ijust found that parsec has a 'manyTill', too
00:34:58 <Hijiri> oh
00:35:03 <Lokathor> so, many letter <* (string "</span>")
00:35:05 <Lokathor> ?
00:35:16 <Hijiri> I guess I was confusing a bunch of things
00:35:29 <Hijiri> takeTill was the one I was thinking of though
00:35:58 <Lokathor> oh manyTill seems perfect
00:36:32 <Hijiri> oh
00:36:34 <Hijiri> and I just found a bug
00:36:48 <Lokathor> oh?
00:36:59 <frerich> Lokathor: It's longer though - I wonder whether there is some difference between <* and manyTill
00:37:07 <Hijiri> I used takeTill to find the first occurence of the character "I" as in "IP"
00:37:17 <Hijiri> but that doesn't take into account usernames starting with I
00:37:21 <Hijiri> and usernames appear earlier
00:37:23 <frerich> Lokathor: Oh, of course manyTill applies the first argument multiple times (zero or ore times)
00:37:31 <Hijiri> actually I don't know
00:37:45 <Hijiri> it could be usernames are sent in a different message and won't be parsed together
00:37:50 <Hijiri> this is for a chat bot for something
00:38:09 <Hijiri> to get someone's ip address you have to send a command and it sends it back as formatted html
00:38:09 <Lokathor> value <- manyTill anyChar (try (string "</span"))
00:38:12 <Hijiri> so I have to parse it out
00:38:18 <rlewis> Lokathor are you doing this as a learning experience? because if not there are already plenty of html/xml parsers on hackage
00:38:27 <frerich> Lokathor: 'many letter <*' is still shorter than 'manyTill letter' though :-)
00:38:53 <Lokathor> frerich, i'm not sure a new characters either way is necessarily a dealbreaker :3
00:39:05 <frerich> Lokathor: Maybe not. :o)
00:39:17 <Lokathor> rlewis, it's partly for Parsec practice, yes
00:39:30 <erisco> I have a Text, and I want to map every character and produce a vector
00:39:44 <erisco> a fold would be a disaster for producing a vector
00:39:45 <frerich> Lokathor: Do you remember this 'starts from the back' note you read? I'm trying to come up with a test case which demonstrates it...
00:39:56 <erisco> not sure what else is available though
00:40:58 <Lokathor> facebook lets you export your data, but your message logs get output as a single giant file. There's a python script that someone wrote that will parse it all out, but when my friend ran it the script took forever and burned 6gb of RAM while going
00:41:13 <Lokathor> so i figured i'd tinker with a better solution
00:41:41 <frerich> Lokathor: There is a difference between 'manyTill' and '<*' in case the two parsers overlap. E.g. 'parseTest (many letter <* char 'x') "foox" gives an 'unexpected end of input' error. With 'letter `manyTill` char'x'' you get 'foo'.
00:41:42 <Lokathor> 6gb to parse a 100mb file is surely an excessive amount of bloat on python's part
00:42:19 <Lokathor> frerich, well i think i want the latter situation
00:42:45 <Lokathor> also, i found the "reads from the end" thing I thought i'd read, but i'd read it wrong
00:42:51 <Lokathor> https://www.fpcomplete.com/school/starting-with-haskell/libraries-and-frameworks/text-manipulation/attoparsec
00:42:58 <Lokathor> > he <* combinator applies the parser from the left, then the parser from the right, and then returns the result of the first parser.
00:43:00 <lambdabot>  <hint>:1:50: parse error on input ‘,’
00:43:15 <Lokathor> oh sorry lambdabot :/
00:43:28 <frerich> Lokathor: Ah yeah - that explanation fits my observation -- since it first applies the parser from the left, that will 'win' in case the two parsers overlap.
00:44:02 <erisco> not even a monadic fold in Data.Text?
00:44:10 <erisco> I could have at least written to a mutable vector
00:46:56 <erisco> geez this is bad
00:47:10 <erisco> do I have to try and duct tape this together with seq and unsafe operations? yeesh
00:47:17 <frerich> erisco: You could use 'foldr' to transform your Text into a list and then use 'fromList' to generate a vector, but I suppose you don't want that?
00:47:36 <erisco> absolutely not
00:47:47 <erisco> I don't trust what it will do with the list
00:47:53 <erisco> it could spew allocations all over the place, I can't know
00:48:00 <johnw> it may also fuse it away
00:48:15 <johnw> you could use vector's stream support and hand-code a Text to stream function
00:48:20 <johnw> that shouldn't be too difficult
00:48:44 <erisco> stream support?
00:49:22 <johnw> https://hackage.haskell.org/package/vector-0.11.0.0/docs/Data-Vector-Fusion-Stream-Monadic.html
00:49:36 <johnw> also https://hackage.haskell.org/package/vector-0.11.0.0/docs/Data-Vector-Fusion-Bundle.html
00:50:08 <erisco> Text and Vector use different stream types
00:50:13 <erisco> I don't know how I'd mash them together
00:50:30 <johnw> i just paste links, it's mah job
00:52:34 <erisco> okay, so I can fold a Text Stream
00:52:42 <erisco> I should be able to fold it into a Vector Stream
00:52:58 <erisco> however, their toList probably just uses the fold
00:53:05 <erisco> okay, lets get real for a moment
00:53:11 <erisco> how can I be sure the list allocation will go away
00:53:42 <erisco> if I fromList . toList
00:54:12 <erisco> if I use the folds directly no list constructors become involved, so I certainly don't have to worry
00:54:44 <erisco> then again I wonder what this Stream data is like
00:55:05 <erisco> the picture is really simple but, ugh, trying to make sure it is working the way it should
00:55:15 <erisco> Text is all packed up nice and tight together, so is a vector
00:55:26 <erisco> I should be able to just forward traverse over the Text and write to my vector
00:55:31 <erisco> nice easy loop
00:55:44 <Lokathor> it works!
00:55:51 <erisco> what I don't want is random memory allocations going off and now I have to go hunting through random memory in the middle of my loop
00:56:21 <erisco> after spending so much effect to keep everything lined up in a row
00:56:26 <erisco> effort
00:56:45 <erisco> it makes me wonder what a Stream Char ends up as
00:57:22 <erisco> if everytime I uncons the Stream I have to go dereference a pointer to get the remaining stream
00:57:26 <erisco> there is zero point in doing this
00:58:22 <erisco> who can weigh in on this?
01:00:41 <frerich> erisco: I'm not sure anymore what the question is - if it's still "How can I be sure that intermediate data structures are eliminated" then I think that this is a matter of relying on compiler optimizations and library features (clever rewrite rules?). Or, of course, not using intermediate data structures in the first place.
01:01:02 <erisco> I can't help it though
01:01:19 <erisco> so what is going on is I have Text, and say I want to get to Vector Char
01:01:47 <opqdonut> erisco: list fusion should work even if you use toList, fromList
01:02:00 <opqdonut> erisco: but the only way to be sure is to profile allocations
01:02:07 <erisco> now, the only candidate approach seems to be using Text Stream and Vector Stream, which are two different stream types defined in their respective modules
01:02:17 <erisco> now focusing on Text Stream
01:02:30 <erisco> uncons :: Stream Char -> Maybe (Char, Stream Char)
01:02:46 <erisco> so, I've got some x :: Stream Char, okay
01:02:58 <erisco> that is somewhere in memory, we'll say it is close by
01:03:04 <opqdonut> erisco: (see https://downloads.haskell.org/~ghc/7.8.3/docs/html/users_guide/prof-heap.html for profiling)
01:03:11 <erisco> now I  uncons x :: Maybe (Char, Stream Char)
01:03:15 <erisco> two questions
01:03:25 <erisco> where is the Maybe allocated and where is the remaining Stream Char allocated?
01:03:41 <erisco> if I have to deference pointers to get to them I'm really unhappy
01:04:01 * hackagebot wai-middleware-throttle 0.2.0.2 - WAI Middleware for Request Throttling  https://hackage.haskell.org/package/wai-middleware-throttle-0.2.0.2 (ChristopherReichert)
01:04:22 <erisco> because I should be able to convert from Text, which afaik is a bytearray underneath, to an unboxed vector char
01:04:25 <gamegoblin> Wish there was a typeclass like "Deconstruct" with a function like "deconstruct :: d a -> (Maybe a, d a)" where it would split of 1 element of the structure at a time (if the structure was non-empty)
01:04:32 <opqdonut> without optimizations, they do get allocated, but of course lazily, so if you don't look at the second part of the pair, you don't get a Stream
01:04:45 <jasonx2> anyone knows where I can get a relatively large text file for testing purposes (at least 20 MB)? real text, not just a bunch of random characters
01:05:00 <opqdonut> erisco: right, if you want to do it without copies you'll have to reach for unsafe primitives. just a second...
01:05:01 <erisco> well of course I'm looking at the second part, it is how I get to the rest of the stream
01:05:03 <liste> jasonx2 what kind of text?
01:05:22 <liste> project gutenberg has a lot of text, but it's kinda formatted
01:05:28 <opqdonut> erisco: but you can definitely get a copying transformation without extra allocations by fusing away the Stream / list in between
01:05:30 <gamegoblin> wikipedia
01:05:36 <gamegoblin> you can easily download wikipedia
01:05:38 <jasonx2> plain english text
01:05:40 <opqdonut> erisco: but in the worst case you'll have to implement your own streaming to make sure fusion works
01:05:41 <erisco> but how do I know this magical fusion has happened?
01:05:50 <liste> jasonx2 here http://corpus.byu.edu/
01:05:51 <opqdonut> a) profile b) look at ghc core
01:05:54 <erisco> I run the profiler on it?
01:05:59 <erisco> that seems crazy
01:06:18 <erisco> there is no way I'm going to be able to reliably determine if it is working
01:06:18 <opqdonut> "ghc core" is one of the intermediate representations in the compiler, basically functional assembler
01:06:24 <erisco> even if I manage to verify it once
01:06:26 <opqdonut> you can see what has been optimized
01:06:32 <erisco> new compiler version, who knows
01:06:37 <erisco> tweak the source code, who knows
01:06:40 <erisco> change a compiler flag, who knows
01:06:42 <opqdonut> sure
01:06:43 <srhb> jasonx2: If not, you can combine a ton of Project Gutenberg files I guess. :)
01:06:52 <opqdonut> but that applies to all performance
01:07:00 <frerich> erisco: That's true for any code you write though.
01:07:03 <jasonx2> liste are those actually .txt files? plain ascii (or unicode)
01:07:13 <erisco> the difference if this was, say, C, is that I can be explicit about what memory operations I am doing
01:07:47 <erisco> maybe I can get the Text to C with FFI and do the conversion there
01:08:14 <opqdonut> erisco: you can mess around with ptrs and allocation in haskell too
01:08:24 <frerich> erisco: I think that if you want that level of control, then C might be a good choice. Of course, you're then giving up all the other goodies you get when focusing on describing what you want to do instead of how to do it. There's clearly a tradeoff.
01:08:25 <opqdonut> then you just need to write more code yourself
01:08:34 <erisco> but I can't know the code that is actually working with the pointers and so on isn't allocating stuff itself
01:09:02 <liste> jasonx2 they have dumps but they cost, I guess
01:09:04 <frerich> erisco: If you are already on the "I want to know exactly how many allocations happen, how many pointers are dereferenced etc." level and you do not want to depend on a particular Haskell compiler or optimization flags, then your best bet is to not use Haskell I think.
01:09:09 <liste> gutenberg is free
01:09:12 <opqdonut> erisco: you could also have a look at https://hackage.haskell.org/package/bytestring-0.10.2.0/docs/Data-ByteString-Unsafe.html#g:2
01:09:18 <frerich> erisco: Or any other 'high level' language (e.g. Python).
01:09:27 <frerich> erisco: You seem to want something closer to the metal.
01:09:30 <erisco> they call C high level
01:09:47 <frerich> erisco: I thought they call C syntactic sugar for assembler :-)
01:10:21 <ely-se> Rust
01:10:24 <jasonx2> checked 10 files ebooks on gutenberg.. 400 KB was the largest
01:10:32 <erisco> might be worth asking how you can get this level of control in a functional setting
01:10:39 <liste> http://linguistics.stackexchange.com/questions/4232/english-text-corpus-for-download <-- here's more on corpora
01:10:45 <ely-se> C gives you all the safety of assembly with all the readability of assembly.
01:11:18 <opqdonut> erisco: it's an interesting question, and there are many high-performance haskell libraries that do resort to mallocs & buffers
01:11:44 <opqdonut> trying to remember the last example of that I bumped into
01:11:50 <frerich> erisco: I think it's not even specific to functional languages. Any higher level imperative language (say: Python or Perl) has the same tradeoff -- you usually need a lot less code to get anything done, but you do give up 100% control over what pointers are dereferenced internally and how many bytes are allocated at what point exactly.
01:11:53 <ely-se> if you want to write maintainable code and avoid runtime indirection, you really need a language with templates such as C++ or monomorphised generics such as Rust
01:12:26 <jasonx2> screw it I'll just replicate 400KB text file 25 times
01:12:29 <frerich> erisco: If you are willing to rely on a specific implementation (e.g. a specific Python interpreter) then you can start taking advantage of the optimizations it performs. IF you don't want to rely on that - then I think the best bet is to just use C.
01:12:57 <ely-se> otherwise you need either duplicate code or void pointers
01:13:30 <nshepperd> erisco: you can write a foldM in terms of foldr, I guess, and then use that to write into a mutable Char Vector?
01:13:35 <erisco> could be wrong but it doesn't look like core is going to shed any light on the memory
01:13:52 <erisco> nshepperd, I thought of that but there is no monadic fold provided
01:14:08 <frerich> erisco: Even without a monadic fold, you still wouldn't know exactly what's going on.
01:14:15 <frerich> erisco: Err, even *with* a monadic fold.
01:14:25 <erisco> you're right
01:14:48 <opqdonut> erisco: you might be interested in this: http://neilmitchell.blogspot.fi/2014/01/optimising-haskell-for-tight-inner-loop.html
01:14:49 <erisco> but the significance this has shouldn't be understated
01:15:04 <erisco> there is a lot of effort going into using Text and Vector rather than just strings and lists
01:15:07 <opqdonut> erisco: core has explicit allocations
01:15:09 <frerich> erisco: As long as you stick to the 'I want to have 100% control, and I do not want to rely on some compiler', then you want assembler. Or maybe C (though even a C compiler does a lot of magic when it comes to reordering instructions and whatnot).
01:15:09 <erisco> and you're supposed to gain something from that
01:15:20 <erisco> but in certain cases, like this, everything you gain can go out the window
01:15:31 <erisco> so then back to square one, why not lists
01:15:31 <johnw> erisco: why do you need so much control?
01:15:42 <erisco> that isn't the entire point as I just explained johnw
01:15:46 <liste> even with x86 asm you don't get complete control
01:15:53 <johnw> why not use lists and strings until a particular performance issue arises
01:16:03 <erisco> still not the point
01:16:14 <ely-se> compilers are better at opsimising then you are, so don't write assembly code
01:17:25 <nshepperd> foldM f z xs = foldr (\a m b -> f b a >>= m) return xs z
01:18:27 <nshepperd> and then write your array copy using that
01:18:54 <opqdonut> nshepperd has good suggestions
01:19:05 <erisco> I don't know what that gives me
01:19:29 <nshepperd> a monadic fold
01:20:20 <nshepperd> then you can use the usual Vector.create to write into a mutable vector
01:20:43 <erisco> :t \f z xs -> foldr (\a m b -> f b a >>= m) return xs z
01:20:45 <lambdabot> (Monad m, Foldable t) => (b -> a -> m b) -> b -> t a -> m b
01:20:48 <nshepperd> I believe this should compile down into a nice loop once things get inlined
01:21:09 <nshepperd> you'll want Text.foldr of course
01:21:22 <frerich> I think all that won't help erisco based on his comment that he does not want to rely that a particular compiler happens to generate efficient code.
01:21:32 <frerich> I think he wants to (and should just) write that bare metal code himself.
01:21:49 <erisco> memory isn't bare metal
01:22:00 <opqdonut> the fold nshepperd is suggesting is much less susceptible to compiler quirks than fusion, though
01:22:11 <erisco> I think ever since you had paged memory and so on it became far from
01:22:31 <opqdonut> erisco: what are you trying to do in general btw?
01:22:35 <opqdonut> just wondering
01:22:45 <erisco> something stupid
01:22:47 <nshepperd> yes, this compilation does not require any complicated RULES or anything, just inlining
01:22:59 <frerich> erisco: You will surely agree that *any* Haskell code you end up writing will be suspectible to compiler-specific quirks. I.e. you either accept those, or you do not write Haskell code.
01:23:07 <erisco> I was just thinking, instead of processing Text, I also need line and column numbers
01:23:15 <opqdonut> frerich: it's not black and white
01:23:17 <erisco> what if I mapped every char to a new data type that included that information
01:23:31 <frerich> opqdonut: *I* agree :-)
01:23:38 <opqdonut> ok :)
01:24:02 * hackagebot neil 0.10 - General tools for Neil  https://hackage.haskell.org/package/neil-0.10 (NeilMitchell)
01:24:05 <opqdonut> erisco: you can do that and risk allocations, or keep track of the information during your fold
01:24:14 <frerich> opqdonut: It was erisco who wrote 'even if I manage to verify if once \n new compiler version, who knows \n tweak the source code, who knows \n change a compiler flag, who knows" :-]
01:24:19 <erisco> that is an interesting idea nshepperd, thanks
01:24:26 <erisco> but I'd also like to know about unconsing the stream
01:26:34 <erisco> I suppose what I really need, if there is any hope to get to the bottom of things
01:26:50 <erisco> with C you can read all about what it means in terms of memory
01:26:54 <erisco> I need the same for ghc
01:27:19 <erisco> so I can predictably know at least some behaviours
01:27:51 <erisco> it'd be nice to know how a function call works, how a thunk works, etc
01:27:57 <erisco> is there a heap and stack
01:28:10 <erisco> when might something be heap allocated and when not, so on
01:28:29 <erisco> control is less important than predictability
01:28:38 <frerich> erisco: The word 'stack' doesn't even appear in the C language standard I think. Especially such machine-specific things are intentionally left undefined to help portability.
01:28:39 <erisco> if I could just know it worked one way and not another that'd suffice
01:28:54 <frerich> erisco: I.e. what consitutes an 'address', how the memory works etc. is all undefined.
01:29:06 <erisco> frerich, well then you can just ask what a popular compiler does
01:29:36 <nshepperd> https://github.com/takenobu-hs/haskell-ghc-illustrated is pretty good
01:29:48 <nshepperd> though it doesn't cover everything
01:30:17 <erisco> is that really comic sans?
01:30:46 <nshepperd> I don't know what comic sans looks like
01:31:01 <nshepperd> I mean it could be
01:31:03 <nshepperd> heh
01:31:36 <erisco> eh that doesn't really fly
01:31:38 <frerich> erisco: For a specific compiler version and some specific target platform you can, yes. That's true for any language though, i.e. you can either go read up on what exactly, say, ghc 7.8 generates for you - or you just try it and rely on subsequent calls generating the same code. :-)
01:32:01 <erisco> I can't know what is really going on by pictures on the slides
01:32:07 <erisco> I presume there is supposed to be someone talking too
01:33:00 <nshepperd> reading the C language standard would probably be an awful way to learn the language for that reason
01:33:08 <nshepperd> everything is incredibly vague
01:33:36 <erisco> frerich, that is like playing a game of Mao, and I'd rather just read the rules
01:34:21 <erisco> like, the slides just through out HEC and TSO and so on
01:34:25 <erisco> like I am supposed to know what that means
01:34:50 <nshepperd> yeah ok
01:35:12 <nshepperd> I don't seem to be able to find the actual talk, I guess it wasn't ever recorded
01:36:59 <nshepperd> I think regarding the stream unconsing, that the Maybe object will be optimized out
01:37:22 <erisco> geez you have to dereference a pointer to jump for a sum type?
01:37:34 <erisco> have to deref the info ptr?
01:37:39 <erisco> to get the entry code?
01:38:15 <erisco> that is kind of bonkers
01:38:34 <frerich> erisco: I really think that if dereferencing a pointer is a problem, and you need precise control over that kind of thing, then Haskell might not be a good language for your problem. :-}
01:38:37 <erisco> how much time does a Haskell program spend dereferencing pointers? someone should bench this
01:39:05 <nshepperd> things like `case Just x of { Just y -> y }` can be optimized out because it realises you are just wrapping and unwrapping something
01:39:10 <erisco> frerich, it is one of the most expensive operations you can do
01:39:24 <flux> erisco, mabe some intel performance profiling tool would be able to tell. or qemu..
01:39:41 <flux> oops I mean cachegrind of a tool similar to it
01:40:03 <nshepperd> is it that expensive? if the target isn't in cache it would be
01:40:20 <frerich> erisco: If dereferencing a pointer is one of the most expensive (which is a relative term, fo course) operations in your particular piece of code, then you might enjoy Haskell's FFI facility to move that particular logic to a lower-level language.
01:40:29 * frerich thinks this discussion is not making any progress...
01:43:18 <erisco> nshepperd, what if you found out the program spends 25% of its time dereferencing memory?
01:43:28 <nshepperd> we have also pointer tagging to avoid dereferencing anything for types with two or three constructors like Maybe
01:44:15 <flux> nshepperd, but to choose to make such an optimization would would like to know if it's an issue or not, though?-)
01:44:27 <erisco> how do you get the entry code address from the tag though?
01:44:31 <erisco> isn't that still needed?
01:45:19 <Peaker> alex seems so kludgy
01:45:26 <nshepperd> if it's already evaluated the entry code would be a no-op, you just grab the payload
01:45:28 <erisco> the lexer?
01:45:32 <Peaker> yeah
01:45:35 <Peaker> My parsec parser has abysmal performance, so I'm thinking of switching to alex
01:45:38 <Peaker> (and happy)
01:45:45 <erisco> I don't know how they make them so confusing, it is impressive really
01:46:08 <Peaker> Yeah, it seems like such a simple problem, yet all the tools around them are so ugly
01:46:16 <Peaker> maybe I should try uu-parsinglib instead
01:46:26 <arkeet> aren't alex/happy designed after lex/yacc sort of
01:47:34 <Peaker> seems so, I hate those tools :(
01:48:03 <Peaker> makes some sense to generate a parser in C like that.. but in a language like Haskell why would we code-gen like that? 
01:48:52 <erisco> Peaker, how big are the source files you're parsing?
01:49:03 <erisco> how much is too much for parsec
01:50:00 <Peaker> erisco: I'm parsing a Makefile-dialect that uses include directives for textual include. Due to elaborate use of "include" as sort of a poor man's function-application, there are lots of lines to parse.. it takes ~10 sec to parse(!)
01:50:33 <erisco> 100,000 lines? 1,000,000 lines? Text? String?
01:51:56 <erisco> anyways, the point of this line of questioning ultimately comes down to why would you really be using Text or Vector
01:52:33 <erisco> is it to use less memory? maybe, seems you can rely on that. is it to make your program faster? maybe, but it doesn't seem you can rely on that
01:53:07 <erisco> and that is incredibly bothering
01:54:11 <erisco> and it puts perspective on what is worth spending time on
01:54:43 <jasonx2> @hoogle ByteString -> Int
01:54:44 <lambdabot> Data.ByteString length :: ByteString -> Int
01:54:44 <lambdabot> Data.ByteString.Char8 length :: ByteString -> Int
01:54:44 <lambdabot> Data.ByteString count :: Word8 -> ByteString -> Int
01:55:04 <jasonx2> is there no ByteString.words?
01:55:09 <Rc43> Hello
01:55:45 <jasonx2> and lines
01:56:21 <Rc43> Does Conor McBryde visit this channel?
01:56:37 <erisco> jasonx2, they are just bytes, what is a word and a line?
01:56:55 <jasonx2> erisco if you don't know you can't help me
01:57:22 <arkeet> he is correct.
01:57:26 <arkeet> a bytestring is just an array of bytes.
01:57:30 <arkeet> not characters.
01:57:53 <dramforever> there's one in the Char8 module
01:57:57 <jasonx2> yes. because array of bytes can't represent characters
01:57:59 <dramforever> jasonx2: ^
01:58:06 <erisco> jasonx2, http://hackage.haskell.org/package/bytestring-0.10.6.0/docs/Data-ByteString-Char8.html
01:58:14 <dramforever> Char8++
01:58:36 <arkeet> you *can* use that, if you are sure that your bytestring encodes text in latin-1 or some subset
01:58:46 <frerich> jasonx2: With a sufficiently simple definition of what consitutes a word separator (e.g. a plain ' ' character) you could use 'split'.
01:58:46 <erisco> he knows what he is doing
01:58:59 <erisco> don't you see
01:59:00 <erisco> I see
01:59:01 <arkeet> but generally use of Char8 is not recommended
01:59:30 <jasonx2> huh, that is a separate type? Data.ByteString.ByteString and Data.ByteString.Char8?
01:59:42 <erisco> just a module
01:59:44 <quchen2> No. It's a silently truncating bad module.
01:59:44 <jasonx2>  Data.ByteString.Char8.ByteString
01:59:45 <dramforever> not separate type
02:00:05 <jasonx2> Data.ByteString.Char8 defines ByteString
02:00:16 <quchen2> The only valid use case for Char8 is dirty hacking.
02:00:30 <erisco> I support dirty hacking
02:00:32 <jasonx2> Data.ByteString.Char8.ByteString is different from Data.ByteString.ByteString?
02:00:36 <arkeet> no
02:00:39 <arkeet> it is re-exported
02:00:44 <arkeet> for convenience
02:00:58 <quchen2> In all other cases, slap an "encodeAscii" in between. Hacking is bad.
02:01:08 <jasonx2> why is basic functionality not provided though.. words, lines, etc
02:01:23 <erisco> okay now you're worrying me
02:01:27 <arkeet> again.
02:01:28 <Peaker> erisco: 64KLOC apparently take parsec ~10sec to parse
02:01:30 <dramforever> jasonx2: because you are not supposed to be dealing with text with bytestrings
02:01:31 <arkeet> ByteString is an array of bytes, not characters.
02:01:52 <erisco> Peaker, geez that is a deal breaker isn't it
02:02:09 <Peaker> erisco: it's terrible
02:02:10 <erisco> and I presume you're not using the more expensive backtracking stuff?
02:02:19 <Peaker> erisco: I don't think I'm using much backtracking
02:02:23 <Peaker> but maybe I'm wrong
02:02:26 <jasonx2> an array of bytes is a perfectly resonable representation of english characters 
02:02:31 <quchen2> No.
02:02:46 * dramforever feels sad about that because he is Chinese
02:02:47 <quchen2> An array of characters is a good representation.
02:03:03 <Lokathor> an array of bytes means you're in ASCII only land
02:03:06 <quchen2> An array of bytes represents bytes, not characters. The meaning is given to it in the decoding.
02:03:07 <Lokathor> which is not the best land to be in
02:03:19 <quchen2> An array of bytes means nothing.
02:03:21 <erisco> Peaker, well, that includes "try" methinks, are you using that?
02:03:29 <erisco> it is possibly something substantial to watch out for
02:03:31 <quchen2> It means as much ASCII as it means JPG.
02:03:44 <jasonx2> quchen2, don't be silly
02:03:44 <erisco> maybe the parser is looking really far ahead and then failing
02:03:46 <Peaker> erisco: I'm using "try", but I'm not sure how heavily
02:03:48 <jasonx2> quchen2, have you ever used C?
02:03:58 <Peaker> erisco: Yeah, I can try to factor out my uses of "try" perhaps
02:04:00 <Lokathor> well alright, *assuming that you're reprisenting characters with 1 byte each*, it means you're in ascii only land
02:04:08 <quchen2> Yes. C is not a good langauge at abstraction, so lots of these facilities are not available there.
02:04:09 <erisco> and I think there is lookAhead as well
02:04:18 <dramforever> C says "char"
02:04:27 <jasonx2> I don't care about abstraction. I care about processing ascii files as fast as I can
02:04:36 <erisco> basically anything that could cause the parser to backtrack arbitrary distance
02:04:39 <ChristianS> jasonx2: you're naïve, even english commonly contains non-ascii chars such as “quotation marks” and – dashes —
02:04:41 <frerich> jasonx2: It's true that for plain ASCII text (e.g. English) treating bytes as characters in a 1:1 correspondence makes sense. That's just a specific case though, which doesn't really warrant defining functions like 'words' or 'lines' for ByteString by default. Especially because that may well make people misuse those functions if they don't know the decoding(s) they are dealing with exactly.
02:05:13 <jasonx2> ChristianS, not the english I am parsing. please don't comment when you don't know my requirements
02:05:19 <erisco> Peaker, I don't expect parsec to be lightning but just 64k lines sounds crazy for 10s
02:05:22 <dramforever> wait
02:05:24 <jasonx2> (and if could properly read you would know them already)
02:05:26 <dramforever> STOP everybody
02:05:37 <dramforever> jasonx2: just use words Data.ByteString.Char8
02:05:50 <dramforever> or Lazy, if you think you need and can cope with it
02:06:02 <erisco> 0.1ms per line? lol
02:06:07 <grayen> Is there a way to use a different instance for a type synomym? I want to have a Map with the keys being decided by the values, that also means I want to have a different IsList/Show/Read instance that use the list of values instead of a key-value tuple. Is there no other way than having to define a newtype and wrapping the ~90 functions of Map for my newtype? The only shortcut I found is converting the Map to the newtype when wanting
02:06:09 <erisco> that is so awful
02:06:22 <dramforever> that's perfectly fine if you really know what you are doing
02:06:25 * quchen2 thinks suggesting a wrong solution to silence someone isn't a good idea.
02:06:25 <arkeet> grayen: you must newtype.
02:06:29 <jasonx2> oh my bad, so Data.ByteString.Char8 does have words and lines
02:06:36 <dramforever> jasonx2: =)
02:06:39 <arkeet> grayen: a type synonym is just that, a synonym.
02:06:50 <jasonx2> that is funny, after so many people explained why they shouldn't exist :)
02:07:09 <dramforever> jasonx2: #haskell problem: we sometimes get carried away because we thought we solved the simpler form of the problem
02:07:09 <erisco> we also linked that to you
02:07:13 <Intolerable> lots of things exist that shouldn't
02:07:27 <dramforever> I like Char8 to some extent
02:07:29 <erisco> believe it or not we didn't link it to you with the belief that it didn't contain lines and words
02:07:33 <jasonx2> well take it with GHC developers then
02:08:00 <dramforever> jasonx2: just curious, what are you parsing?
02:08:35 <Peaker> erisco: btw, Binary.Get on the parse result takes 0.58 sec(!!)
02:08:51 <Lokathor> so in Parsec
02:09:34 <Lokathor> i have a parser that parses what i want, and the thing after that is either the same thing, or there's some junk between repeats that i want to avoid, or it's a different "end of file" sort of text
02:09:41 <jasonx2> dramforever just plain english text files, that are rather large, and for simplicity i want to keep them all in memory. with ByteString that is 1 byte per char as far as I can see. with Text that would be considerably larger (and even more so with String)
02:09:58 <dramforever> plain english text files hmm...
02:10:11 <jasonx2> yeah. plain ascii
02:11:25 <Lokathor> jasonx2, #haskell tends to be a little fanatical about textual encodings
02:11:38 <jasonx2> how much memory overhead does ByteString have compared to C string?
02:12:17 <erisco> probably an extra two words at least
02:12:28 <dramforever> erisco: what about those finalizers?
02:12:31 <Peaker> jasonx2: it has a ForeignPtr to a dynamic allocation, an unpacked offset, an unpacked length.  Not sure how much ForeignPtr costs and how much overhead the dynalloc adds
02:12:34 <dramforever> oh that's GC overhead
02:13:23 <Peaker> in C I can have a string like:   char foo[] = "MyString";  // doesn't even have dynalloc overhead
02:13:24 <erisco> so, irrelevant for large strings
02:13:29 <erisco> since the overhead is constant
02:13:35 <ChristianS> jasonx2: Text is generally 2 bytes per chars, while ByteString is 1, plus some constant overhead in both cases. so the different is not so big, and one is full unicode while the other is only ascii/latin1.
02:14:16 <dramforever> ForeignPtr contains a finalizer https://hackage.haskell.org/package/base-4.8.1.0/docs/src/GHC.ForeignPtr.html#ForeignPtrContents
02:14:32 <dramforever> jasonx2: if you really care you could also use ShortByteString
02:14:33 <erisco> Peaker, I keep getting the impression that maybe Haskell is alright for bootstrapping an idea
02:14:51 <dramforever> http://hackage.haskell.org/package/bytestring-0.10.6.0/docs/Data-ByteString-Short.html
02:15:02 <erisco> Peaker, but then you're better off going elsewhere to make it work on realistic data
02:15:21 <dramforever> jasonx2: just the array and a length
02:15:27 <Peaker> erisco: if you need really good performance, I also don't believe Haskell quite cuts it. The vast majority of the code in the world doesn't need great performance though
02:15:40 <erisco> Happy may produce a haskell program but if you've ever looked at the generated source... it is marginally a haskell program
02:15:40 <Peaker> I'm fighting performance issues in Haskell a looot recently :(
02:16:21 <jasonx2> dramforever I see
02:16:27 <dramforever> jasonx2: btw don't say with too much confidence that "this part of the code will be slow" before you profiled it
02:16:55 <dramforever> profiling will often suprise you
02:17:12 <jasonx2> i dont care as much about speed as memory overhead
02:17:39 <dramforever> it's the same, do a heap profiling first
02:17:50 <dramforever> althought it's a bit tricky in haskell, though
02:18:16 <erisco> Peaker, when just working with dummy data to get the idea working, though, simplicities like lists and GC and so on help, yes?
02:18:17 <grayen> arkeet: ok, I was hoping I missed some extension, I really dislike these kind of boilerplate cases.
02:18:35 <Peaker> erisco: of course
02:18:43 <erisco> Peaker, then port to another language and add on the complications of performance? maybe
02:18:50 <dramforever> grayen: wait I'm not quite getting your question
02:19:07 <dramforever> oh wait I know it
02:19:10 <dramforever> =P
02:19:14 <Peaker> erisco: A nice elegant Haskell composition looks so different from how a C++ program would look like, where you fuse all your pipelines/compositions manually
02:19:35 <jasonx2> dramforever that would work if I could easily switch between string types.. but I can't. so I will pick the correct representation from the beginning
02:19:40 <erisco> Peaker, it makes me wonder what role structures such as Text, Vector, IntMap, IntSet, etc have realistically
02:19:52 <dramforever> jasonx2: you could, but it's nonstandard
02:20:15 <dramforever> and IMHO rather difficult, https://hackage.haskell.org/package/monoid-subclasses-0.4.1/docs/Data-Monoid-Textual.html
02:20:25 <erisco> Peaker, you've got simple lists, then there is a grey area in the middle with these higher performance structures
02:20:38 <erisco> Peaker, then at the high end you're looking to FFI to another language or port entirely
02:20:55 <erisco> or use some tool to generate state machines like Happy
02:21:57 <erisco> Map does bring down the complexity of [(k,v)] and that matters regardless of your constant overheads for any appreciable data set, sure
02:22:27 <erisco> but IntMap? I dunno
02:22:32 <dramforever> jasonx2: after all you could also write your own typeclasses
02:24:06 * hackagebot packdeps 0.4.1 - Check your cabal packages for lagging dependencies.  https://hackage.haskell.org/package/packdeps-0.4.1 (MichaelSnoyman)
02:24:26 <Lokathor> i got my parser thing working
02:24:44 <Lokathor> but when parsing a 60mb file it hits 1.5gb of RAM used by the time it's done parsing
02:24:57 <Lokathor> which is better than the python version
02:24:58 <erisco> lol
02:25:05 <Lokathor> but it still needs work perhaps
02:25:11 <Lokathor> https://github.com/Lokathor/fbmessageparse/commit/e6864026ed1f1bc8471fce63c6ffd72d5734d74e
02:25:53 <erisco> this makes me very sad
02:26:02 <Fuuzetsu> @pl f x = g x $ h x
02:26:02 <lambdabot> f = ap g h
02:26:04 <Lokathor> my code?
02:26:29 <erisco> I doubt your code is so bad as to warrant 1.5GB of memory
02:26:36 <Lokathor> oh
02:26:54 <Lokathor> that's because it gets 100% parsed and kept in memory before it begins to print any of it
02:26:59 <Intolerable> are those not just xml?
02:27:02 <erisco> the original was 60MB
02:27:07 <erisco> how does it inflate 20x?
02:27:17 <Lokathor> yeah i dunno man, the python version of a similar script used 6gb
02:27:18 <pacak> erisco: Don't underestimate haskell in memory representation :)
02:27:27 <dabd> How do you reason about invariants in purely functional programming? 
02:28:07 <bennofs> is it possible to build only the tests of a cabal package, using an already-installed version of the library defined in the package?
02:28:18 <Lokathor> anyway
02:28:19 <Lokathor> bed
02:28:32 <erisco> what is it parsing into?
02:28:33 <dabd> Foe example if you look at the proof of correctness of insertion sort from CLRS they prove that a certain loop invariant is true, but in a purely functional implementation how do you prove the correctness of the algorithm?
02:28:41 <erisco> some XML tree thing?
02:28:44 <erisco> XML DOM thingie?
02:29:16 <dramforever> dabd: much simpler, just use induction
02:30:04 <jasonx2> is this a safe use of unsafeCoerce? bottom of the file: http://lpaste.net/139257
02:30:12 <dramforever> first prove that if xs is sorted, the insert a xs is sorted and is a permutation of (a : xs)
02:30:23 <dabd> so for example using Quickcheck how do you write an "inductive" property based test?
02:30:27 <dramforever> hmm...
02:30:51 <jasonx2> that should have been runGeneric ByteString act = act $ unsafeCoerce genericByteString
02:30:51 <dramforever> dabd: quickcheck is supposed to do random checks
02:31:01 <pacak> jasonx2: type families?
02:31:10 <dramforever> it just gives your program a large number of random inputs
02:31:18 <dramforever> and check that a certain condition is met
02:31:34 <jasonx2> pacak I don't understand
02:31:43 <dramforever> @check ((\xs -> reverse (reverse xs) == xs) :: [Int] -> Bool)
02:31:45 <lambdabot>  +++ OK, passed 100 tests.
02:32:00 <erisco> oh a toy
02:32:31 <pacak> jasonx2: You don't need that  unsafeCoerce
02:32:38 <erisco> @check all :: [Bool] -> Bool
02:32:40 <lambdabot>  Couldn't match type ‘t0 a0 -> Bool’ with ‘Bool’
02:32:40 <lambdabot>  Expected type: [Bool] -> Bool Actual type: (a0 -> Bool) -> t0 a0 -> Bool Pro...
02:32:50 <erisco> oh right, they changed it
02:32:57 <erisco> @check all id :: [Bool] -> Bool
02:32:59 <lambdabot>  *** Failed! Falsifiable (after 7 tests and 2 shrinks):
02:32:59 <lambdabot>  [True,False,True,False]
02:33:17 <jasonx2> pacak I should use type families instead? what would that gain me?
02:33:30 <jasonx2> still curious if this is a safe use of unsafeCoerce
02:33:35 <jasonx2> I never used it before
02:34:36 <erisco> it isn't meant to be used, I haven't seen a use case for it
02:35:32 <dramforever> @check (\xs -> length xs < 10000)
02:35:34 <lambdabot>  No instance for (Show (t0 a0)) arising from a use of ‘myquickcheck’
02:35:34 <lambdabot>  The type variables ‘t0’, ‘a0’ are ambiguous Note: there are several potentia...
02:35:54 <dabd> I guess to prove correctness we would need a more expressive type system: dependently typed
02:35:57 <jasonx2> is it safe or not? that is all I want to know :)
02:36:04 <erisco> @check (\xs -> length xs < 10000) :: [Int] -> Bool
02:36:06 <lambdabot>  +++ OK, passed 100 tests.
02:36:11 <erisco> it is fine guys
02:36:12 <jasonx2> it appears to work
02:36:15 <dramforever> dabd: or just use an external system
02:36:25 <dabd> googling a bit I found some information about using Idris or Agda to prove correctness of sorting algorithms using dependent types
02:36:31 <dramforever> =)
02:36:50 <dramforever> dabd: yes you could also use a proof assistant like Coq that supports extracting to haskell
02:37:02 <dramforever> although...I'm not exactly sure coq can handle haskell typeclasses
02:37:45 <dramforever> dabd: wait...isn't that imperative proof using an external system too?
02:38:19 <erisco> how did I let myself get convinced I was doing something worthwhile
02:38:25 <erisco> no no no this is all silly
02:39:06 * hackagebot wiring 0.4.0 - Wiring, promotion and demotion of types.  https://hackage.haskell.org/package/wiring-0.4.0 (seanparsons)
02:39:08 <erisco> you let something give little rewards to you now and then
02:39:12 <erisco> and suddenly it is the best thing ever
02:39:13 <erisco> for a while
02:40:08 * frerich imagines erisco standing on a podeum with 1486 people in the room, witnessing that monologue :-}
02:40:30 <jasonx2> ByteString is 5 times faster than Text for the simple test case I used (counting bytes, lines, words of a 100 MB file)
02:40:32 <Intolerable> im a bit confused tbh
02:40:41 <jasonx2> that was in ghci, I'll try ghc too
02:40:43 <tulcod> dabd: essentially, independent type systems cannot claim anything more interesting than "propositional" truths. so whenever you'd like a quantifier or state an equality between elements, you need dependent types. essentially.
02:40:48 <erisco> frerich, hm, that was supposed to be -blah
02:40:50 <erisco> but whatever
02:40:52 <jasonx2> (String failed with "out of memory" error)
02:40:57 <arahael> jasonx2: Why is that surprising?
02:41:10 <Intolerable> i still don't understand why you need to haul the entire thing into memory
02:41:17 <jasonx2> araheal it is not. it is exactly why I will use it, even though everyone told me i shouldn't
02:41:30 <Intolerable> do it with pipes or something and see what that gives you
02:41:36 <Hafydd> I don't think you can reliably count lines of a UTF-encoded file by just looking at individual bytes.
02:41:47 <Intolerable> he doesn't want it to work
02:41:50 <Intolerable> he just wants fast
02:42:11 <arahael> Hafydd: Why not?
02:42:27 <frerich> Hafydd: I think separating by lines, e.g. splitting on '\n', would work just fine in a UTF-8 encoded file.
02:42:31 <Hafydd> arahael: something might be encoded as two bytes, where the second bytes is \n.
02:42:45 <arahael> Hafydd: That will never happens, as per UTF-8 specification.
02:42:49 <frerich> Hafydd: That can never happen.
02:42:58 <Hafydd> Doesn't it? I see.
02:43:19 <arahael> Hafydd: The high bit is always set for non-ASCII characters.
02:44:15 <arahael> Hafydd: Infact, it's old text files where you'll have a biger issue.
02:44:51 <arahael> Hafydd: Is \n\r\r\r\r one line?  What about \r\r\r\r\n?  \n on it's own, in a file with \n\r? What about \r\n?
02:45:13 <arahael> Hafydd: Is the final \n a new line that happens to be empty? What if there is no \n at the end of the file?
02:45:37 <jasonx2> LOL String tries to use over 2GB of memory with a 100 MB file
02:45:57 <Intolerable> i dont think anyone tried to tell you that string would be the right option
02:46:00 <arahael> jasonx2: Why not call String lazilly?
02:46:56 <jasonx2> because I am testing how much it takes if kept in memory
02:47:01 <jasonx2> Text uses 464 MB
02:47:17 <liste> that's String for ya
02:47:45 <arahael> Yeah well, string is a list of 32-bit data.
02:47:59 <dramforever> pointer, pointers evertwhere
02:48:49 <jasonx2> so with Text I am getting 464 MB memory use and processing of 7.4 seconds. with ByteString 101MB of memory used, and just 1.2 seconds time
02:49:29 <dramforever> but I guess their point is you're not going to support anything beyond ascii that way
02:49:42 <jasonx2> i don't need to support anything else
02:50:08 <arahael> dramforever: That's a false premise. If you pass the non-ascii stuff straight through, as-is, then you're still supporting it.
02:50:10 <liste> jasonx2 you sure? there's a lot of non-Ascii characters in English too
02:50:27 <jasonx2> liste but not a lot of non-ascii characters in ascii text files :)
02:50:32 <dramforever> arahael: I didn't say it wasn't one =P
02:50:37 <arahael> dramforever: Ok. :)
02:50:46 <liste> oh.
02:50:59 <merijn> Try typing fiancé in ascii :p
02:51:07 <dabd> tulcod: i see. interesting discussion on this topic https://www.reddit.com/r/haskell/comments/3hlck0/planned_change_to_ghc_merging_types_and_kinds/
02:51:26 <Intolerable> merijn trying would be quite naïve
02:51:34 <merijn> I don't see a reason to not support non-ascii, considering Haskell's unicode story is pretty straightforward and simple :)
02:52:36 <jasonx2> merijn because ByteString uses 4 times less memory and 6 times faster than Text
02:53:07 <ChristianS> jasonx2: 4 times less memory? that doesn't sound plausible
02:53:58 <arahael> Unless Text is UTF-32, for some reason.
02:54:04 <arahael> But it's UTF-16, surely?
02:54:07 <ChristianS> yes
02:54:20 <jasonx2> ChristianS that is the numbers I got. I am reading 100 MB text file, counting characters, counting number of lines (length $ lines text) and counting number of words
02:54:24 <liste> lazy or strict Text/Unicode?
02:54:38 <merijn> jasonx2: Text is UTF-16
02:55:21 <merijn> jasonx2: The better solution for this would probably be to use pipes/conduits and do the processing streaming
02:55:27 <merijn> That scales up to arbitrary file sizes
02:56:07 <dramforever> merijn++
02:56:12 <jasonx2> I need to keep processed text in memory during duration of the pring
02:56:23 <jasonx2> of the program
02:57:14 <arahael> Weird requirement.
02:57:16 <Peaker> oh wow, I just learned SPECIALIZE can be used as sort of a REWRITE rule
02:57:32 <jasonx2> Text may be UTF-16, but that is the results I got. 100MB memory use with ByteString, 400MB with Text
02:57:42 <jasonx2> arahae weird? heh
02:58:49 <arahael> jasonx2: I can think of no reason why it must be kept in memory as a requirement.
02:59:07 * hackagebot moesocks 0.1.0.21 - A functional firewall killer  https://hackage.haskell.org/package/moesocks-0.1.0.21 (JinjingWang)
02:59:09 * hackagebot Chart 1.5.3 - A library for generating 2D Charts and Plots  https://hackage.haskell.org/package/Chart-1.5.3 (TimDocker)
03:00:04 <tulcod> dabd: that looks like a dangerously powerful patch
03:00:16 <dramforever> hmm...this moesocks thing is really actively updated
03:00:45 <tulcod> dabd: this is getting into dependent type terrain indeed, and then you should basically re-design haskell to be on the safe side. ergo the existence of Idris, Agda, Coq, and other proof assistants
03:00:59 <dramforever> doesn't make sense
03:01:13 <jasonx2> maybe GC works more efficiently with ByteString
03:01:23 <jasonx2> and cleans up crap sooner
03:01:29 <dramforever> tulcod: I don't think those stuff can be compared with proving an imperative insertion sort correct
03:01:41 <dramforever> because that one is using an external system
03:02:29 <tulcod> dramforever: i don't know what you mean by "external system" here
03:02:39 <merijn> jasonx2: Oh, I think I may know...
03:02:40 <tulcod> dramforever: are we talking about http://www.randomhacks.net/2015/07/19/proving-sorted-lists-correct-using-coq-proof-assistent/ ?
03:02:45 <merijn> jasonx2: How did you measure memory usage?
03:02:46 <dramforever> no
03:03:06 <dramforever> tulcod: just ... dabd's original question
03:03:16 <tulcod> dramforever: which i missed :)
03:03:28 <merijn> jasonx2: ByteString allocates everything pinned so it can be used across the FFI, Text just uses the heap. So I would expect Text to bloat the heap/GC space more
03:03:30 <jasonx2> merijn I used ps
03:03:39 <merijn> So if you're looking at ps I would expect more memory usage
03:03:45 <merijn> Due to GHC using a copy-over GC
03:03:47 <jasonx2> I see
03:04:02 <merijn> jasonx2: I expect if you use the profiling tools it's actually not using that much more memory
03:04:06 <Peaker> according to the GHC profiler, my Parsec horribly-slow parser is spending 85% of its time in my underlying monad's >>=  (which is just a  ReaderT (IORef ..) IO)
03:04:07 <merijn> ANyway, lunchtime
03:04:46 <dramforever> Peaker: consider unwrapping it then
03:05:07 <dramforever> @unmtl ReaderT (IORef Foo) IO
03:05:07 <lambdabot> Plugin `unmtl' failed with: `ReaderT (IORef Foo) IO' is not applied to enough arguments, giving `/\A. IORef Foo -> IO A'
03:05:10 <dramforever> duh
03:05:12 <dramforever> @unmtl ReaderT (IORef Foo) IO a
03:05:12 <lambdabot> IORef Foo -> IO a
03:05:40 <Peaker> Since it's just a single transformer layer over IO, I don't see how manually writing it there would help?
03:05:51 <ttt_fff> how do I check if first char of a Text is an uppercase
03:05:52 <dramforever> oh dunno then...
03:05:59 <dramforever> just randomly guessing
03:06:06 <dramforever> ttt_fff: Data.Text.head
03:06:08 <jasonx2> tried 1GB file, Text failed with out of memory error. ByteString using just 1GB of memory
03:06:15 <dramforever> or I wonder if there's a better one
03:06:17 <ttt_fff> :t Data.Text.head
03:06:18 <lambdabot> Data.Text.Internal.Text -> Char
03:06:18 <jasonx2> btw I need to install 64bit ghc
03:06:19 <dramforever> safer
03:06:25 <dramforever> ttt_fff: is there a safer one?
03:06:32 <ttt_fff> > Data.Text.head "Hello"
03:06:34 <lambdabot>      Not in scope: ‘Data.Text.head’
03:06:34 <lambdabot>      Perhaps you meant ‘Data.List.head’ (imported from Data.List)
03:06:49 <ttt_fff> Data.Text.head ("Hello" :: Text)
03:06:57 <ttt_fff> > Data.Text.head ("Hello" :: Text)
03:06:58 <dramforever> try in your own ghci, lambdabot doesn't really trust text
03:06:59 <lambdabot>      Not in scope: ‘Data.Text.head’
03:06:59 <lambdabot>      Perhaps you meant ‘Data.List.head’ (imported from Data.List)Not in scope...
03:06:59 <Intolerable> text isn't on lambdabot
03:07:32 <ttt_fff> oh, is it fear of stack overflow attacks?
03:07:32 <dramforever> ttt_fff: oh maybe use uncons if you need the rest of the text
03:07:41 <ttt_fff> > isUpperCase 'H'
03:07:43 <lambdabot>  Not in scope: ‘isUpperCase’
03:07:47 <ttt_fff> > isUpper 'H'
03:07:48 <lambdabot>  True
03:07:56 <dramforever> @let import qualified Data.Text as T -- this could show the problem
03:07:57 <lambdabot>  .L.hs:114:1:
03:07:57 <lambdabot>      Data.Text: Can't be safely imported!
03:07:57 <lambdabot>      The package (text-1.2.1.3) the module resides in isn't trusted.
03:08:11 <dramforever> uh oh
03:08:45 <Intolerable> > let f ((isUpper -> True):xs) = Just xs in f "Hello world"
03:08:46 <lambdabot>  Just "ello world"
03:09:43 <jasonx2> Intolerable huh? 
03:09:51 <jasonx2> is that some extension
03:10:12 <srhb> View Patterns.
03:11:03 <jle`> hi
03:11:17 <Intolerable> best extension tbh
03:11:31 <jle`> i have a GADT where i need to assume Show b => ... inside some existential
03:11:39 <frerich> Intolerable: My personal favorite is LambdaCase.
03:11:44 <Intolerable> > return False >>= \case False -> return "hello"
03:11:45 <lambdabot>  <hint>:1:18: parse error: naked lambda expression ''
03:11:48 <Intolerable> aww
03:11:50 <jle`> but the way the constructors are set up, there isn't any way to construct anything with that type that *isn't* a Show
03:11:51 <Intolerable> i was just about to put that
03:12:05 <jle`> can I have GHC be happy with me just using show?
03:12:22 <Intolerable> i would sooner drop OverloadedStrings than ViewPatterns and LambdaCase
03:12:23 <dramforever> jle`: data F a b = F (a -> b) lol
03:13:14 <jle`> data Foo a where Bar :: Int -> Foo Int; Baz :: Foo Int -> Foo Bool
03:13:26 <Peaker> I recently started using LambdaCase, and it's much nicer than I thought.. saving the name is a minor benefit.. saving 2 indent levels is huge
03:13:26 <jle`> oh i meant
03:13:30 <jle`> data Foo a where Bar :: Int -> Foo Int; Baz :: Foo a -> Foo Bool
03:13:59 <Peaker> >>= \x -> case x of       is way too ugly (also saves indent levels).   But foo >>= \case    is nice and saves the indents
03:14:02 <jle`> the only members of Foo will be (Bar i) for some Int i, and repeated applications of Baz
03:14:32 <Intolerable> saving an identifier isnt a huge gain
03:14:48 <Intolerable> but literally being unable to access whatever got bound is really nice
03:15:40 <jle`> oh nvm i think i figured it out
03:16:10 <Peaker> Intolerable: yeah, indeed. the indent level and that extra safety
03:16:33 <Intolerable> i use view patterns for the same thing mainly
03:16:40 <Intolerable> making sure something never makes it into scope
03:17:53 <dramforever> lambdacase is pretty much the same thing
03:18:02 <dramforever> you could even get an escape hatch
03:18:12 <dramforever> \case a@(Pat te rn) -> ...
03:18:31 <dramforever> well, same benefit
03:27:33 <jasonx2> how come HTX only supports parsing to String?
03:28:09 <Intolerable> hxt?
03:28:36 <jasonx2> @hoogle hxt
03:28:37 <lambdabot> package hxt
03:28:37 <lambdabot> package hxt-binary
03:28:37 <lambdabot> package hxt-cache
03:28:45 <jasonx2> https://hackage.haskell.org/package/hxt
03:29:09 * hackagebot api-builder 0.11.0.0 - Library for easily building REST API wrappers in Haskell  https://hackage.haskell.org/package/api-builder-0.11.0.0 (Intolerable)
03:29:16 <srhb> jasonx2: (You mistyped it htx, hence the confusion)
03:29:34 <srhb> And I think the answer is: Because no one made it compatible with Text and ByteString
03:29:40 <srhb> There's no fundamental limitation.
03:29:47 <Intolerable> i kinda wish hackagebot would wait until docs were built
03:30:32 <jasonx2> people say we shouldn't use String (and I agree), but it is hard when other string types aren't supported by major libraries
03:31:27 <srhb> That's very true.
03:31:42 <cocreature> jasonx2: the problem is that we don't have a good story for polymorphism over string types. either library authors go for one and support only that one or they have a bunch of modules like attoparsec, one for each popular string type
03:32:06 <srhb> It might not be a big issue for applications that can consume the String lazily, even if there is some cost of speed.
03:32:27 <srhb> (Or rather, produce the String lazily?)
03:32:41 <srhb> I suppose both need to be true.
03:34:16 <Intolerable> xml-conduit?
03:50:53 <jasonx2> this is odd, when I don't keep one 100MB string in memory, but that string split into lines and words, Text is actually using less memory than String (122 vs 144MB). how can that be?
03:51:43 <merijn> jasonx2: String takes about 24 bytes per character...
03:51:52 <merijn> jasonx2: String is a terrible datatype for text processing
03:51:59 <jasonx2> sorry, Text is using less memory than ByteString
03:52:02 <merijn> jasonx2: It's literally a linked list of unicode characters
03:52:24 <merijn> jasonx2: Strict Text/BS or lazy?
03:52:28 <Intolerable> are they both strict / both lazy?
03:52:31 <jasonx2> Text is using 122MB, ByteString 142
03:52:46 <jasonx2> I used Data.Text and Data.ByteString, so whatever is default
03:52:58 <merijn> Those are strict, I think
03:53:02 <Intolerable> yes
03:53:10 <merijn> I'd guess that Text can share more
03:53:48 <dave65> Can anyone help me a bit, I'm trying to create a pivot table(like a spreadsheet program would) from a [[String]]. But don't really know how to start
03:54:55 <Intolerable> build a record from each row ([String]) and then use sortBy?
03:55:37 <Intolerable> :t comparing length
03:55:38 <lambdabot> Foldable t => t a -> t a -> Ordering
03:55:42 <Intolerable> :t comparing length <> comparing head
03:55:44 <lambdabot> Ord a => [a] -> [a] -> Ordering
03:56:10 <Intolerable> :t sortBy (comparing length <> comparing head) [[1,2,3],[1,2],[3],[3,4,5]]
03:56:11 <lambdabot> (Num a, Ord a) => [[a]]
03:56:15 <Intolerable> > sortBy (comparing length <> comparing head) [[1,2,3],[1,2],[3],[3,4,5]]
03:56:17 <lambdabot>  [[3],[1,2],[1,2,3],[3,4,5]]
03:57:23 <dave65> The first row are headers, and I want to group by 1 or more of them
03:58:20 <tsahyt> Hello. I have a function of type Monad m => a -> m b, and I'd like to build make a function of type Monad m => m (a -> b) out of it. Is this even possible?
03:58:38 <Peaker> tsahyt: it's not possible, no
03:59:01 <Peaker> tsahyt: the shape of the "m" in "m b" depends on the "a", so you cannot build that shape/m withot looking at "a" first
03:59:01 <tsahyt> Peaker: Why is that?
03:59:26 <Peaker> tsahyt: the other direction is possible, though
03:59:53 <Peaker> :t \m x -> ($ x) <$> m
03:59:54 <Intolerable> counterpoint: if you turned putStrLn :: String -> IO () into IO (String -> ()), it makes no sense
03:59:54 <lambdabot> Functor f => f (a -> b) -> a -> f b
04:00:28 <notdan>  Also: take m = Maybe, b = (). Then Maybe b = Maybe () is basically a two-element set. So, |a -> m b| = 2^|a|. However, Maybe (a -> ()) contains only two elements
04:00:39 <notdan> modulo undefined
04:01:20 <tsahyt> Peaker: Okay that makes sense, thank you.
04:02:15 <dave65> what does <> do and what package does it come from?
04:02:32 <bennofs> dave65: it comes from Data.Monoid
04:02:33 <tsahyt> dave65: it's an alias for mappend
04:02:34 <notdan> dave65: it's mconcat and it is from Data.Monoid
04:02:37 <bennofs> dave65: it's an alias for mappend
04:02:40 <notdan> erm s/mconcat/mappend/
04:02:44 <dave65> ah thx
04:02:44 <Peaker> dave65: it's mappend from Data.Monoid, and also a Doc append operator in Text.PrettyPrint
04:03:30 <tsahyt> dave65: So, basically it's the operator of whatever monoid you happen to work in. <> is vaguely reminiscent of the little circle (\circ in TeX) that is often used to denote the monoid operation.
04:04:10 * hackagebot syntactic 1.15.1 - Generic abstract syntax, and utilities for embedded languages  https://hackage.haskell.org/package/syntactic-1.15.1 (EmilAxelsson)
04:04:15 <bennofs> tsahyt: doesn't <> stand for a "diamond"-like shape? 
04:04:56 <dramforever> somehow you have to make do with it
04:05:56 <bernalex> in maths you use '•' for the binary operator.
04:06:48 <bernalex> like in the laws, associativity (a • b) • c = a • (b • c), & identity element e • a = a • e = a.
04:13:04 <tsahyt> bennofs: I've seen a lot of the <...> operators typeset as ... circled in papers, so I've assumed that this is the way it should be read. Either way, it's a nice mnemonic for monoid in my opinion.
04:16:34 <phaazon> :t untilM
04:16:35 <lambdabot>     Not in scope: ‘untilM’
04:16:35 <lambdabot>     Perhaps you meant ‘until’ (imported from Prelude)
04:16:40 <phaazon> I thought we would have that
04:16:50 <quchen2> phaazon: monad-loops
04:17:52 <phaazon> @let untilM :: (Monad m) => m Bool -> m b -> m (); untilM pred a = pred >>= loopOver where { loopOver False = void a; loopOver True = void a >> pred >>= loopOver }
04:17:54 <lambdabot>  Defined.
04:17:59 <phaazon> quchen2: hm
04:18:39 <phaazon> whileM_ then
04:19:10 <phaazon> that should be in Control.Monad
04:19:14 <phaazon> like filterM
04:19:15 <phaazon> partitionM
04:19:16 <phaazon> and so on
04:19:18 <phaazon> :)
04:19:23 <jasonx2> if I got it right ByteString is just a plain chunk of memory pointed to by a pointer, while Text is a pair of beginning/end pointers?
04:20:00 <opqdonut> they're both just buffers in memory
04:20:04 <opqdonut> so they have a position and a length
04:20:05 <merijn> jasonx2: ByteString also has a size, iirc
04:20:15 <phaazon> yep
04:20:15 <merijn> opqdonut: There's some differences
04:20:18 <phaazon> BS has
04:20:20 <opqdonut> the difference is that semantically BS stores bytes and Text codepoints
04:20:20 <quchen2> phaazon: There are *so* many possible monadic loops it'd hardly be useful to have all of them in the main module
04:20:23 <merijn> opqdonut: ByteString is pinned, Text is not
04:20:25 <phadej> phaazon: http://hackage.haskell.org/package/extra-1.4.1/docs/Control-Monad-Extra.html
04:20:30 <opqdonut> merijn: oh, I didn't know
04:21:00 <phaazon> I wonder whether there’s an abstraction capturing monadic loops
04:21:00 <merijn> opqdonut: This is because you might wanna passa a ByteString as input to FFI functions as "Ptr Word8", so GC shouldn't move them
04:21:06 <merijn> opqdonut: Text is just on the regular heap
04:21:11 <phaazon> mfix, maybe
04:21:14 <opqdonut> merijn: makes sense
04:21:17 <merijn> So allocating Text is cheaper
04:21:25 <quchen2> merijn: The lazy versions of BS/Text don't need to have a size, no?
04:22:18 <merijn> quchen2: Right
04:23:10 <quchen2> merijn: But what's the difference between Text and BS apart from the type of thing they contain? I thougt both were contiguous blocks of memory.
04:23:44 <merijn> quchen2: Like I just said, BS is pinned, Text is not
04:24:05 <Intolerable> what's pinned
04:24:10 <srhb> can't be moved around by GC
04:24:16 <Intolerable> ok
04:24:18 <Intolerable> ty
04:24:29 <srhb> Which seems to me to make lazy ByteStrings especially dangerous.
04:24:29 <quchen2> What's the reason for that?
04:24:41 <srhb> But I suppose you should not use it if you build large ones in memory
04:25:39 <quchen2> So using large blocks of text is bad for performance during GC when it decides to move everything around?
04:27:25 <merijn> srhb: Not sure lazy BS is pinned
04:28:02 <quchen2> merijn: Could you talk a bit about how pinning is beneficial (or not beneficial)?
04:28:09 <phadej> lazy BS is a list of strict BS's, which are pointers to raw memory
04:28:47 <phadej> i.e. foreignptr's
04:28:51 <phadej> they aren't moved by gc
04:28:51 <merijn> quchen2: It's more expensive (because allocating pinned memory is more expensive than on the heap, it requires locking)
04:28:52 <phadej> http://hackage.haskell.org/package/bytestring-0.10.6.0/docs/src/Data.ByteString.Internal.html#ByteString
04:29:14 <merijn> quchen2: But since it cannot be moved it's safe to turn ByteString into "Ptr Word8" that you can pass to a C function using the FFI
04:29:36 <merijn> quchen2: Imagine passing a pointer to a C function and GC magically moving the buffer midway during the function call...
04:30:04 <phadej> merijn: AFAIK gc isn't run when there are (unsafe?) ffi calls?
04:30:13 <merijn> phadej: Why wouldn't it?
04:30:28 <merijn> phadej: Safe foreign calls run in separate threads so they don't block haskell code
04:30:46 <merijn> phadej: Unsafe foreign calls run the code directly in the haskell thread, blocking GC until the call returns
04:31:00 <merijn> phadej: But you shouldn't be using unsafe foreign calls unless you know what you're doing anyway
04:31:03 <srhb> merijn: No I meant, with Lazy ByteString consisting of strict chunks, you could really fragment memory in a bad manner.
04:31:09 <srhb> Assuming the strict chunks are still pinned.
04:31:31 <srhb> Though I suppose it's still better than contiguous pinned blocks
04:32:06 <phadej> srhb: if you really need to keep everything in memory, strict bs is probably better
04:32:12 <merijn> srhb: meh, memory fragmention is not that big a deal
04:32:17 <srhb> Okay. :)
04:32:18 <merijn> And what phadej said
04:32:28 <merijn> srhb: Just request more memory from the OS when you run out :p
04:33:03 <phadej> merijn: i'm not sure what happens in -threaded rts, it way beyond my understanding
04:33:38 <qwe_> @help
04:33:38 <lambdabot> help <command>. Ask for help for <command>. Try 'list' for all commands
04:33:49 <qwe_> @pl \xs n -> take n xs
04:33:49 <lambdabot> flip take
04:34:32 <phadej> merijn: just trying to remember how it working is explained in https://simonmar.github.io/posts/2015-07-28-optimising-garbage-collection-overhead-in-sigma.html
04:34:42 <qwe_> @pl f1 (f2 x) (f3 y)
04:34:42 <lambdabot> f1 (f2 x) (f3 y)
04:35:10 <phadej> merijn: there is "Saving 5ms per GC by not using ForeignPtr" subsection
04:35:32 <dramforever> qwe_: remember to use a lambda or something, otherwise pl cannot see how to abstract away your stuff
04:35:48 <quchen2> merijn: Hm. But then why isn't Text pinned as well?
04:35:52 <dramforever> @pl \x y -> f1 (f2 x) (f3 y) -- I'm going to guess it's liftA2 f1 f2 f3
04:35:52 <lambdabot> (. f3) . f1 . f2
04:35:55 <dramforever> fail
04:36:06 <qwe_> @pl \x y -> f1 (f2 x) (f3 y)
04:36:06 <lambdabot> (. f3) . f1 . f2
04:36:14 <dramforever> it's not, obviously
04:36:33 <qwe_> thanks
04:36:45 <dramforever> you're welcome
04:42:40 <merijn> quchen2: Because not many C/FFI functions take UTF-16 blobs? :)
04:43:19 <quchen2> Why not? I mean handling it is more complicated, but it still sounds very performant.
04:43:32 <quchen2> (The same way using nuclear power to propulse a car is performant, but still.)
04:43:54 <dramforever> performant/efficient
04:44:16 <dramforever> UTF-16 blobs need more memory, obviously
04:44:54 <dramforever> I wonder how hard it is to deal with UTF-8 encoded strings without converting first
04:44:56 <merijn> quchen2: I've never wanted to do this, whereas passing ByteString to C happens whenever I use any C library for networking, parsing, whatever :)
04:46:37 <quchen2> merijn: Alright, I'll file it under "subject to further research"
04:46:42 <quchen2> i.e. "later"
04:46:46 <quchen2> i.e. "never" :-þ
04:50:43 <frerich> Such negativity! It's called "ASAP"!
04:51:33 <liste> > asap == never
04:51:35 <lambdabot>  True
04:52:17 * frerich works at a place where task tickets can have a 'Scheduled' state with any of Unscheduled, Distant Future, ASAP. And then there's also a 'Status' called 'To Do'.
04:52:18 <frerich> Go figure.
04:54:23 <quchen2> I just found out we have a ticket status "Geneva".
05:03:37 <breadmonster> Hello everyone.
05:03:52 <Nashie> Hey everyone!
05:04:07 <liste> hello
05:04:14 <bernalex> hallo
05:04:16 <Nashie> What would be a good way to loop through two lists and compare all elements with a custom function?
05:04:28 <liste> Nashie all with all or pairwise?
05:04:47 <lf94> What are some good FRP packages in Haskell?
05:04:48 <Nashie> Pairwise, they have to be close to each other, within a limit
05:04:56 <bjornars> zipWith seems suitable
05:05:00 <Intolerable> zipWith x list1 list2?
05:05:10 <Nashie> I'll look into it, thanks! :)
05:05:21 <Nashie> Kinda new to Haskell but I'm liking it so far
05:05:29 <bernalex> lf94: https://wiki.haskell.org/FRP
05:05:40 <bernalex> lf94: see the Libraries section.
05:05:43 <lf94> I thought you guys would have had some opinions of your own
05:05:46 <lf94> But ok :)
05:05:59 <mpickering> lf94: You ask 10 different people and you will get 10 different answers
05:06:00 <bennofs> lf94: reactive-banana is quite easy to get started with
05:06:02 <bernalex> lf94: there are several libraries that do FRP differently.
05:06:06 <bennofs> lf94: but it'll depend on what you want to do
05:06:41 <bernalex> lf94: the most popular ones atm seem to be reactive banana, netwire, and frpnow.
05:07:06 <lf94> Excellent, thank you all.
05:07:17 <bennofs> lf94: reactive-banana: gui stuff (has gtk bindings),   reflex-dom: web stuff (compiles to JS with GHJJS),    netwire: things that need more behaviors than "events", like games
05:07:23 <lf94> I'll probably try out reactive banana. It's got a nice name X)
05:08:09 <Nashie> bjornars: Hmm, if I wanted to have just a one bool result, should I still just use zipWith and at the end fold the list into single bool?
05:08:47 <bernalex> Nashie: one result? are you trying to determine if one list is equal to the other?
05:09:10 <bjornars> :t all
05:09:10 <liste> Nashie that would make sense
05:09:11 <lambdabot> Foldable t => (a -> Bool) -> t a -> Bool
05:09:15 <liste> :t any
05:09:17 <lambdabot> Foldable t => (a -> Bool) -> t a -> Bool
05:09:30 <liste> look at all and any too
05:09:33 <Nashie> Yeah that all elements (pairwise) are within a set limit from each other
05:09:40 <bjornars> :t and
05:09:41 <lambdabot> Foldable t => t Bool -> Bool
05:10:00 <bjornars> 'and' reduces a foldable of bools down to a single bool
05:10:18 <bernalex> Nashie: I still don't even understand what you are trying to do. 'and' might be what you want.
05:10:27 <bjornars> (a list is Foldable)
05:12:10 <liste> > and (zipWith (\× y -> abs (x - y) < 10) [1, 2, 3, 4, 50] [2,3,4,5,51])
05:12:11 <lambdabot>  <hint>:1:20: parse error on input ‘->’
05:12:18 <liste> > and (zipWith (\x y -> abs (x - y) < 10) [1, 2, 3, 4, 50] [2,3,4,5,51])
05:12:19 <lambdabot>  True
05:13:32 <bjornars> > and (zipWith (\x y -> abs (x - y) < 10) [1, 2, 3, 4, 50] [2,3,4,5,51, 0, -1])
05:13:33 <lambdabot>  True
05:14:46 <dramforever> I think the optimizer should optimize it away
05:15:07 * dramforever checks about those "good producers/consumers" stuff
05:16:50 <dramforever> forget about it, can't find it anymore
05:19:09 <merijn> dramforever: It's in the GHC manual, but I forget where :p
05:19:21 <dramforever> exactly what's happening to me
05:19:32 <merijn> Pretty sure zipWith is a good producer and and a good consumer
05:20:00 <dramforever> merijn: in one of it's arguments, IIRC
05:20:05 <dramforever> I mean the comsumer part
05:24:41 <srhb> That seems a bit weird.
05:24:56 <dramforever> dunno
05:25:02 <dramforever> maybe I'm wrong
05:25:38 <srhb> Section 7.14.4 List Fusion -- and no, that is indeed what it says
05:26:04 <srhb> Gawd, we really need some SEO on these sites...
05:26:22 <srhb> That was an ancient version.
05:26:30 <dramforever> we need a better SE for code in general I think
05:26:39 <dramforever> or does google already do this well?
05:26:39 <srhb> 7.23.5 in latest: https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/rewrite-rules.html#idp26293440
05:27:13 * dramforever got it right =)
05:27:23 <srhb> Yep. :)
05:27:39 <srhb> A little explanation in that spot would have been nice... :P
05:28:06 <dramforever> "if both are good producers, zip will fuse with one but not the other"
05:28:09 <dramforever> how useful...
05:28:15 <bennofs> isn't foldl a good consumer in head?
05:28:26 <bennofs> s/head/7.10
05:29:20 <srhb> Supposedly yes, according to #7994
05:29:45 <breadmonster> srhb: Are there any easy tickets on ghc for n00bs like myself to start hacking on?
05:30:06 <srhb> breadmonster: You are asking the wrong person, I am a perpetual n00b. :)
05:30:09 <bennofs> there's a list of easy tickets somewhere
05:30:23 * dramforever thinks he opened one some time ago, but I'm totally n00b on ghc
05:30:40 <breadmonster> haha, doesn't mean you don't know about easy tickets
05:30:40 <breadmonster> bennofs: Yeah, they got rid of that sometime ago.
05:30:49 <dramforever> it's a parser problem
05:30:59 <dramforever> breadmonster++
05:31:02 <bennofs> https://ghc.haskell.org/trac/ghc/wiki/Newcomers "Finding a ticket" ?
05:31:36 <breadmonster> bennofs: Oh right, I meant the ticket difficulty ratings.
05:31:47 <merijn> breadmonster: Did I already link you my "Fisher Price: My First GHC Patch" tutorial? ;)
05:32:02 <breadmonster> merijn: No.
05:32:42 <merijn> breadmonster: I wanted to have a minimal start-to-finish workflow for landing a patch in GHC, so I summarised a lot of the (very useful!) wiki pages into: https://gist.github.com/merijn/c01405e6c5a78a1c4ccb
05:33:11 <dramforever> hmm...looks like someone added the newcomer tag and removed it a week later
05:33:17 <merijn> It doesn't deal with working on GHC itself, but exactly how to get sources, get code reviews in arc and the specific commands to use, etc.
05:33:36 <merijn> And how to add/run tests
05:34:04 <merijn> breadmonster: Lemme know if you run into anything missing :)
05:34:11 <breadmonster> Sure.
05:34:19 <breadmonster> How do I start working on ghc itself?
05:34:26 * dramforever is thinking of writing a post about reasoning about monads, but encountered this problem: https://en.wikipedia.org/wiki/Frame_problem
05:35:26 <dramforever> TL;DR: If you want to use axioms to describe your system, you might find yourself adding too many axioms just to make sure that things don't change randomly
05:35:59 <merijn> breadmonster: Once you checkout stuff as described in that guide you just start reading source, changing things and compiling? :p
05:36:12 <merijn> breadmonster: Depends on what exactly you wanna patch
05:36:12 <breadmonster> But okay.
05:36:12 <breadmonster> It's not that easy :P
05:36:27 <merijn> You can ask in #ghc for good starting places if you specify the ticket/problem you're looking at
05:36:28 <breadmonster> merijn: https://ghc.haskell.org/trac/ghc/ticket/10089
05:37:17 <breadmonster> Alright then.
05:37:17 <merijn> breadmonster: I would recommend by starting with "where is the unused datatype warning generated/produced"
05:37:25 <breadmonster> Okay.
05:37:40 <merijn> breadmonster: And then try to understand how it works/what it does and then looking into why deriving stops it from being reported
05:40:43 * dramforever also read about operational semantics and denotational semantics, but neither seems to describe monads well
05:40:49 <dramforever> or I'm misunderstanding something
05:42:37 <dramforever> hmm...wait, looks like we could write a stepper for monads
05:42:46 <dramforever> and use operational semantics
05:43:59 <merijn> dramforever: You're confusing things, I think?
05:44:06 <merijn> dramforever: What do semantics have to do with monads?
05:44:35 <dramforever> I'm not going to write about monads in general
05:44:41 <merijn> dramforever: Since Monad is implemented in Haskell why would you need semantics for Monad, that just follows from the semantics of haskell
05:44:55 <dramforever> I'm going to talk about some particular monad
05:45:01 <dramforever> but I haven't decided yet
05:45:12 <dramforever> guess that generality came from my experience of haskell =P
05:45:23 <exio4> maybe he's taling about stuff like IO, whose behavior is .. kinda? .. axiomatically
05:45:28 <dramforever> merijn: oh wait, what about this: MonadReader doesn't have any laws
05:45:43 <dramforever> exio4: yes you're right
05:45:55 <merijn> dramforever: It does, it should follow the Monad laws
05:46:10 <dramforever> but what are ask and local supposed to do?
05:46:24 <merijn> Then you don't wanna use the term operational semantics/denotational semantics, because that'll confuse things
05:46:34 <dramforever> um...
05:46:46 <dramforever> yep, looks like the confusion is in that part
05:47:07 <merijn> Semantics is the field of describing what a given program "means"
05:47:31 <merijn> denotational semantics does this by mapping programs to a specified mathematical object and then proving properties about the object
05:48:02 <dramforever> doesn't look right because monads are kinda already mathematical objects
05:48:03 <merijn> Operational semantics specifies the meaning by mapping programs to "executed behaviour", with the subfields of small-step and big-step semantics
05:48:28 <merijn> dramforever: It doesn't make sense because you cannot specify semantics for object in a language on their own
05:48:28 <dramforever> yes, and this is what I think might simplify things
05:48:34 <dramforever> hmm...
05:48:48 <dramforever> interesting
05:48:59 <merijn> Like I said, the semantics of Monad follow from the semantics of Haskell, since Monads *are* haskell programs
05:49:13 <dramforever> then I have to go for axioms
05:49:14 <merijn> So specifying "the semantics of Monad" is a bit of a silly notion
05:49:34 <merijn> You can talk about laws implementations should obey, but those are not semantics, they're more like invariants
05:49:53 <dramforever> merijn: ok thanks for clearing things up
05:49:59 <dramforever> then the frame problem arises https://en.wikipedia.org/wiki/Frame_problem
05:50:43 <dramforever> post again: TL;DR: If you want to use axioms to describe your system, you might find yourself adding too many axioms just to make sure that things don't change randomly
05:50:49 <merijn> dramforever: Well, there's a reason why semantics are metatheory :)
05:50:53 <dramforever> *arbitarily
05:51:06 <dramforever> merijn: what if I could make do with a metatheory?
05:51:25 <dramforever> the MonadReader language is really abstract isn't it
05:52:02 <merijn> dramforever: I dunno what you want to actually explain :)
05:52:09 <dramforever> oh
05:52:22 <dramforever> merijn: "How do I reason about this program that uses monads"
05:52:37 <dramforever> it's...kinda silly after going through all this, though
05:52:51 <merijn> But monads don't impact how you reason about programs...not much, anyway
05:52:58 <dramforever> wait no
05:53:15 <dramforever> merijn: MonadReader
05:53:53 <merijn> dramforever: Right, so what do you wanna reason about that? You get the monad laws and that's about it
05:54:13 <dramforever> merijn: what if ask can tell whether I called it?
05:54:24 <dramforever> what if local applies that function twice?
05:57:33 <merijn> dramforever: That's not dependent on MonadReader at all, just the implementation of ask and local
05:57:53 <dramforever> "the implementation" hmm...no
05:58:05 <dramforever> merijn: we have monoid laws, monad laws
05:58:10 <dramforever> but not MonadReader laws
05:58:29 <dramforever> and surely MonadReader instances have to obey something
05:58:52 <dramforever> I'm trying to formalize the intuitions of it
05:59:15 * hackagebot nvim-hs 0.0.5 - Haskell plugin backend for neovim  https://hackage.haskell.org/package/nvim-hs-0.0.5 (saep)
05:59:29 <merijn> dramforever: "The same as Reader"?
05:59:42 <dramforever> it can't be, saidly
05:59:43 <Intolerable> ask >> ask ≣ ask ?
05:59:56 <dramforever> Intolerable: good that's what I'm trying to do
06:00:09 <Intolerable> local f ask ≣ fmap f ask ?
06:00:45 <dramforever> yep
06:00:55 <merijn> dramforever: Why not?
06:01:15 <Intolerable> dunno if there's anything else you can get out of it
06:01:26 <dramforever> merijn: "the same" -> ReaderT A IO can't be the same as Reader
06:01:27 <Intolerable> and i've certainly written instances where ask >> ask isn't ask
06:01:29 <nshepperd> local f (m >>= n) = local f m >>= local f n
06:01:40 * dramforever likes this =)
06:01:51 <merijn> dramforever: Why not? ask/local should not have sideeffects in any monad but the underlying reader
06:02:12 <dramforever> merijn: ok sorry I understand it then, now formalize that
06:02:15 <merijn> dramforever: And any underlying monad trivially has a "no effect" option, because return does that
06:02:26 <Intolerable> actually it might've been an invalid MonadState instance
06:02:26 <dramforever> hmm...
06:02:49 <Intolerable> where "put x >> get" was not necessarily x
06:03:52 <dramforever> merijn: also there's another problem: why do you assume there's an underlying monad?
06:04:17 <liste> @src State
06:04:17 <lambdabot> Source not found. BOB says:  You seem to have forgotten your passwd, enter another!
06:04:38 <Intolerable> @src Control.Monad.State.State
06:04:38 <lambdabot> Source not found. You speak an infinite deal of nothing.
06:04:40 <Intolerable> aww
06:05:12 <dramforever> hmm...
06:05:25 <dramforever> maybe all this is an infinite deal of nothing, just like lambdabot said
06:10:38 <bennofs> dramforever: how about: ask >> x = x
06:10:54 <dramforever> wait
06:11:03 <dramforever> I'll post mine so far
06:12:06 <lpaste_> dramforever revised “No title”: “No title” at http://lpaste.net/139267
06:12:14 <dramforever> there you go
06:12:15 <merijn> dramforever: Because MonadReader has a Monad constraint?
06:12:25 <merijn> dramforever: Therefore there must be an underlying Monad
06:12:27 <deepfire> does Andrew Gibiansky come here?
06:12:33 <dramforever> merijn: maybe
06:12:40 <dramforever> this is interesting...
06:12:52 <merijn> dramforever: Time to download Software Foundations and start working on a proof/spec in Coq ;)
06:13:15 <dramforever> merijn: already worked on SF for a while
06:13:19 <dramforever> now on Equiv
06:13:33 <cocreature> I have finally "finished" sf a few days ago
06:13:47 <cocreature> I learned so much by reading that book and doing the exercises
06:13:50 <dramforever> got stuck on proving the x /= 0 infinite looper...
06:13:57 <dramforever> cocreature ++
06:14:10 <merijn> I should continue with SF, I didn't work on it since OPLSS
06:14:13 <bennofs> dramforever: heh, local is a functor: local id = id and local (f . g) = local f . local g
06:14:23 <dramforever> that's backwards isn't it
06:14:34 <bennofs> oh :|
06:14:37 <dramforever> local (f . g) = local g . local f
06:15:05 <bennofs> contravariant functor, right, this makes sense
06:15:17 <dramforever> except that it's not general
06:15:42 <dramforever> it's only from the category where the only object is r
06:15:56 <dramforever> where r is the type variable in the MonadReader class
06:16:33 <dramforever> merijn: I think verifying that those instances indeed satisfy the laws is not too hard
06:16:39 <bennofs> dramforever: perhaps you could formalize it as being isomorphic to some a Representable contravariant functor?
06:16:47 <dramforever> good idea!
06:17:15 <dramforever> wow how could I have...wait there's another problem I think
06:17:28 <bennofs> :t local
06:17:29 <lambdabot> MonadReader r m => (r -> r) -> m a -> m a
06:17:57 <dramforever> wow
06:18:24 <dramforever> wait it's getting interesting...
06:18:27 <bennofs> dramforever: or just say that local is a monoid homomorphism for endo
06:18:41 <bennofs> :)
06:18:47 <dramforever> s/monoid homomorphism/monad homomorphism/
06:20:10 <dramforever> hmm...wait it's two ways
06:20:15 <bennofs> :t appEndo . local . Endo
06:20:16 <lambdabot>     Couldn't match type ‘m0 a0 -> m0 a0’ with ‘Endo a’
06:20:17 <lambdabot>     Expected type: (r0 -> r0) -> Endo a
06:20:17 <lambdabot>       Actual type: (r0 -> r0) -> m0 a0 -> m0 a0
06:20:22 <bennofs> :t appEndo . Endo . local . Endo
06:20:23 <lambdabot>     Couldn't match type ‘Endo a1’ with ‘r0 -> r0’
06:20:23 <lambdabot>     Expected type: (a1 -> a1) -> r0 -> r0
06:20:23 <lambdabot>       Actual type: (a1 -> a1) -> Endo a1
06:20:24 <dramforever> a monoid homomorphism on the first argument
06:20:33 <dramforever> a monad homomorphism on the second
06:20:37 <dramforever> this is getting interesting
06:21:00 <bennofs> :t Endo . local . appEndo -- this is the monoid homomorphism form
06:21:02 <lambdabot> MonadReader r m => Endo r -> Endo (m a)
06:21:28 <dramforever> hmm...
06:22:04 * dramforever wonders if that "isomorphic to an representable functor" works
06:22:36 <dramforever> hmm...
06:22:54 <dramforever> "(m a) is isomorphic to (r -> m a)" that sounds interesting
06:23:28 <dramforever> uh...
06:23:48 * dramforever stops sending filler words to #haskell
06:24:55 <hodapp> :P
06:25:26 <bennofs> dramforever: or just make laws that allow to transform any monad reader action to an action where only a single ask is used
06:25:27 <dramforever> I wonder what the isomorphism should do
06:26:06 <dramforever> bennofs: ask-comm, ask-return and ask-idem will allow that
06:26:10 <dramforever> (see my lpaste)
06:26:21 <dramforever> but what about local?
06:26:29 <dramforever> oh those are covered by the local laws
06:26:46 <dramforever> I wonder if that's enough....
06:31:03 <bennofs> dramforever: hmm, ask >>= flip local m . const  === m
06:31:36 <dramforever> interesting...
06:32:27 <dramforever> ask >>= \e -> local (const e) m  =  m
06:32:32 <dramforever> I'm considering this
06:36:39 <aweinstock> @src local
06:36:39 <lambdabot> Source not found. Are you on drugs?
06:37:54 <bennofs> dramforever: let observe m e = local (const e) m, then reader . observe = id 
06:38:05 <dramforever> wow
06:38:05 <bennofs> > local (+3) ask $ 4
06:38:07 <lambdabot>  7
06:38:11 <dramforever> this is getting more and more interesting
06:38:43 <bennofs> dramforever: observe . ask = return
06:38:48 <bennofs> I think
06:38:58 <dramforever> I guess you're right
06:39:36 <bennofs> :t reader
06:39:37 <lambdabot> MonadReader r m => (r -> a) -> m a
06:39:58 <bennofs> oh, the first one doesn't typecheck I think
06:40:17 <dramforever> @let observe m e = local (const e) m
06:40:19 <lambdabot>  Defined.
06:40:21 <dramforever> :t observe
06:40:22 <exio4> reader f = fmap f ask ? 
06:40:22 <lambdabot> MonadReader b m => m a -> b -> m a
06:40:32 <dramforever> :t observe . reader
06:40:33 <bennofs> exio4: yeah
06:40:34 <lambdabot> MonadReader r m => (r -> a) -> r -> m a
06:40:50 <dramforever> typechecks prett...oh it doesn't
06:40:52 <dramforever> :t reader
06:40:54 <lambdabot> MonadReader r m => (r -> a) -> m a
06:41:03 <bennofs> :t reader . observe
06:41:05 <lambdabot> (MonadReader r m, MonadReader r m1) => m1 a -> m (m1 a)
06:41:11 <bennofs> should be join I think
06:41:27 <dramforever> :t flip (reader . observe) -- that should force it
06:41:28 <lambdabot> MonadReader r m => r -> m a -> m a
06:41:41 <dramforever> but what does it do?
06:41:43 <dramforever> oh I know...
06:41:54 <dramforever> :t flip (reader . observe) 4 ask $ 5
06:41:56 <lambdabot> Num a => a
06:41:59 <dramforever> > flip (reader . observe) 4 ask $ 5
06:42:00 <lambdabot>  4
06:42:06 <dramforever> expected =P
06:42:15 <bennofs> > observe ask 4 $ 5
06:42:17 <lambdabot>  4
06:42:48 <Sindriav_> How undesirable are RankNTypes? I mean, constraining fields to classes seems like it should be a regular feature
06:43:07 <Intolerable> noone will complain if you turn RankNTypes on
06:43:11 <dramforever> it's an extension because it's not in the report
06:43:23 <dramforever> Intolerable: a compiler that doesn't support it will complain =P
06:43:24 <Sindriav_> Sorry, what I meant was: "how likely is it that they're a good solution for what I want to do"
06:43:43 <Sindriav_> Which is making a field constrained to MonadIO instead of making it IO
06:43:43 <Intolerable> they are probably what you want
06:44:09 * Sindriav_ slaps himself on the hands because XY problem
06:44:42 <dramforever> =p
06:44:44 <Sindriav_> I want to make an IO action as a field of the structure, but I want to use MonadIO instead of IO, because it's cleaner
06:44:51 <Sindriav_> Should I use RankNTypes?
06:44:55 <Sindriav_> There, better.
06:45:02 <dramforever> but it's not what RankNTypes are for IIRC
06:45:31 <Sindriav_> dramforever: Well, when I try "field :: MonadIO m => m () ", GHC suggests Rank2Types or RankNTypes
06:45:37 <dramforever> oh
06:45:38 <dramforever> sorry
06:45:45 <bennofs> @let data DoesItEvenWork = DoesItEvenWork { x :: forall m. MonadReader Int m => m () }
06:45:47 <lambdabot>  Defined.
06:45:49 <mamaukeke> inb4 existential antipattern
06:46:01 <mamaukeke> @undefine
06:46:01 <lambdabot> Undefined.
06:46:11 <Sindriav_> Oh, so I don't need RankNTypes
06:46:20 <bennofs> mamaukeke: nothing to do with existential antipattern. this would rather be universal antipattern, if at all :)
06:46:20 <Sindriav_> Just an explicit `forall` ?
06:46:28 <bennofs> Sindriav_: lambdabot has RankNTypes by default I think
06:46:39 <exio4> Sindriav_: it may be better if you give us some high-level context 
06:46:40 <Sindriav_> I see. I'll try it out locally
06:46:45 <Sindriav_> oh, ok, gimme a sec
06:46:49 <mamaukeke> bennofs: that would surprise me
06:46:53 <exio4> Sindriav_: but RankNTypes is not discouraged, it's a really handy extension 
06:47:08 <bennofs> mamaukeke: the type I gave is not existential at all
06:47:24 <bennofs> or, is it?
06:47:26 <Sindriav_> exio4: I'm doing some GL stuff, and every drawable object has it's own draw function (drawArrays, drawElements, etc…) and I want to make that a field of the type Handle i'm generating for these objects
06:47:26 <mamaukeke> I'm talking about Sindriav_'s problem, not your code
06:49:02 <Sindriav_> exio4: And making the draw function part of a typeclass would lead to a lot of boilerplate (each draw instance would need to do 75% of the same stuff manually, like bind the VAO and use the shader)
06:49:17 * hackagebot ansi-terminal 0.6.2.2 - Simple ANSI terminal support, with Windows compatibility  https://hackage.haskell.org/package/ansi-terminal-0.6.2.2 (RomanCheplyaka)
06:49:48 <catofhask> Hello
06:49:54 <srhb> catofhask: Hello.
06:50:03 <catofhask> I have a very stupid question 
06:50:05 <Sindriav_> exio4: So I make a handle with a VAO identifier, Shader identifier and a render IO action, and I have `draw :: MonadIO m => Handle -> m ()`, which binds the stuff and then sequences in the render action handle has in it
06:50:10 <joco42> is
06:50:44 <liste> catofhask go ahead
06:50:55 <joco42> is someone here using ghc-mod with cabal projects? it does not seem to work for me
06:51:16 <Sindriav_> joco42: ghc-mod is very buggy for me on OSX with GHC 7.10 and Cabal 1.22
06:51:29 <joco42> ghc-mod works fine for single standalone files though..
06:51:30 <catofhask> If I want to have a constraint over fn that takes a data type containing a set of properties, how can I generalise that without Type class
06:52:06 <joco42> Sindriav_: I use it with ghc 7.8.4 on osx
06:52:40 <Sindriav_> joco42: Make sure you have a proper ghc-mod version, I guess. No idea on what to do next, except trying `hdevtools`
06:52:53 <joco42> ok
06:52:57 <joco42> maybe
06:53:25 <catofhask> example : A  a b c = A {x : a, y: b, z: c } , and I want to write a function that I will require to get out say `a` and `b`
06:54:56 <Sindriav_> catofhask: I suggest you first name it better, then you might see the solution clearer ^^
06:54:58 <catofhask> a type class with `class Extractor r where getA :: r -> a; getB;: r-> b` works
06:55:23 <Intolerable> lens?
06:55:35 <dramforever> classy?
06:55:40 <liste> catofhask sum type?
06:55:50 <quchen2> catofhask: You discovered the records problem, congratulations. It's an unsolved problem, but there are some promising attempts to fix it.
06:56:14 <quchen2> catofhask: In other words, there is no good way to do this right now.
06:56:38 <dramforever> quchen2 ++
06:57:02 <quchen2> You can write the classes yourself, but that's a lot of boilerplate. You can use lenses, but that might be an overkill. You can wait for Nikita to implement his solution, merge it into GHC, and then use it happily ever after. The latter might take a few years ;-(
06:57:22 <joco42> maybe this hdevtools is good too ... https://github.com/bitc/vim-hdevtools
07:00:28 <aweinstock> quchen2: could you provide a link with information on Nikita's solution to the record problem?
07:00:53 <quchen2> Well, there's the talk he gave about it
07:01:02 <quchen2> http://www.techcast.com/events/bigtechday8/maffei-1005/?q=maffei-1005
07:01:41 <quchen2> I'm not aware of an up-to-date writeup of the contents (but I also didn't look for one, so there might well be one)
07:08:07 <Intolerable> is this what you're talking about? http://nikita-volkov.github.io/record/
07:08:52 <quchen2> That was the original post, but he worked on it quite a bit.
07:09:03 <Intolerable> fair
07:10:23 <ew0> so, I'm adding an ew edge to a fgl graph
07:10:29 <ew0> am I doing this right?
07:10:30 <ew0> http://pastebin.com/yfLb0J8j
07:10:40 <ew0> erm, is there a better way to do it?
07:28:43 <Lokathor> Parsec doesn't quite do what i want
07:28:52 <grayen> I have a data structure using HashMap for which I want to support both a lazy and strict version. The only difference between the two versions will be whether I import the lazy or strict version of HashMap. How can I prevent code duplication in this situation?
07:28:53 <Lokathor> and looking at the types, i don't think i can force it to do what i want
07:30:14 <Sindriav_> Lokathor: What do you want?
07:31:38 <Lokathor> what i want is, instead of wrapping all the parsing up in an Either, to simply parse along consing up a list, and any error causes the current parse to be the empty list (which stops the parse)
07:32:00 <aweinstock> :t either (const []) id
07:32:01 <lambdabot> Either b [t] -> [t]
07:32:06 <Lokathor> i basically want incrimental parsing, instead of having to parse 100% of my input into memory before i can start dealing with my result
07:32:58 <aweinstock> (I think Left does early-abort in the way you're asking about)
07:34:13 <Sindriav_> Well, if Left is sequenced with anything, it just makes left again, so I don't think it executes any code
07:34:23 <Sindriav_> *any other code
07:34:52 <Lokathor> well the parsing is deterministic
07:35:11 <Lokathor> it's just that it's 1.5gb of ram to pull everything into memory at once
07:35:23 <geekosaur> Lokathor, I don't know if either will help, but you might also look at trifecta or possibly uuagc
07:35:47 <geekosaur> that said, I thought parsec had sufficient laziness to do stream parsing...
07:35:52 <Sindriav_> Lokathor: Did you try that? I'd be very surprised if Haskell pulled something into memory all at once unless asked to. Even readFile doesn't do that IMO
07:35:57 <geekosaur> (if the grammar is written correctly at least)
07:36:44 <Lokathor> geekosaur, my grammar might not be written sufficiently correctly to do what i want
07:36:45 <geekosaur> what's the underlying type?
07:37:01 <geekosaur> (String, ByteString (which?), Text (which?), ...)
07:37:06 <Lokathor> uhm
07:37:10 <Lokathor> String
07:37:16 <Sindriav_> :Yeah, don't do that
07:37:17 <geekosaur> hm.
07:37:23 <Lokathor> I guess i could switch it to Text or whatever
07:37:38 <tdammers> is that relevant in this context though?
07:37:39 <geekosaur> actually I'd think String would be lazy enough, if rather large
07:37:40 <Sindriav_> Lokathor: String has potential overhead of 32bytes per character IIRC
07:38:01 <geekosaur> lazy Text might be better, but if the parser is being strict with String I expect it'd be strict with a lazy Text too
07:38:03 <tdammers> oh, hmm
07:38:10 <Lokathor> i can't get too into it right now for i must leave for work in 10 or 15 minutes
07:38:13 <tdammers> strict Text will pull everything in at once
07:38:13 <Lokathor> https://github.com/Lokathor/fbmessageparse/blob/master/src/Main.hs
07:38:17 <Lokathor> that's what i was running
07:38:30 <chpatrick> Lokathor: attoparsec does incremental parsin
07:38:31 <chpatrick> g
07:38:36 <Lokathor> though, it's just cobbled together in 3 hours type code, probably missing stuff
07:38:40 <chpatrick> you can even turn it into a conduit for free
07:38:48 <Sindriav_> chpatrick: TIL
07:39:22 <chpatrick> also for parsing HTML I would recommend
07:39:26 <chpatrick> @hackage html-conduit
07:39:26 <geekosaur> um
07:39:26 <lambdabot> http://hackage.haskell.org/package/html-conduit
07:39:42 <geekosaur> so, just looking at this, I think it is capable of laziness but being forced all at once by the final putStrLn?
07:40:35 <geekosaur> not certain of that though. also make sure you're not holding stuff you don't need somehow
07:40:44 <geekosaur> building with profiling might help
07:41:54 <Lokathor> now that i think of it, i guess i do want to potentially re-arrange things before outputting them, since the messages are in the file all jumbled based on i don't even know what
07:42:21 <Lokathor> so maybe trying to get more lazyness out of things isn't even going to help
07:43:09 <floralshoppe> is haskell more than a gimmick
07:43:19 <Lokathor> floralshoppe, yes
07:43:23 <Sindriav_> floralshoppe: yes, it's a language
07:43:47 <floralshoppe> but is it a practical language?
07:44:06 <Lokathor> very
07:44:10 <Sindriav_> floralshoppe: Yes. Facebook uses it, Siemens uses it, some US telecommunications use it IIRC
07:44:34 <Sindriav_> floralshoppe: There's a list of real-world uses on the wiki.
07:44:40 <floralshoppe> what do they use it for? number crunching?
07:44:47 <floralshoppe> oh ok
07:44:49 <floralshoppe> ill check it out
07:45:10 <Sindriav_> floralshoppe: Since computing isn't much else than number crunching, then yes. Number crunching.
07:46:05 <aweinstock> don't several financial institutions use haskell too?
07:46:09 <Sindriav_> The main reason it's not more popular (IMO) is that it requires actual effort to learn, since it's not remixed C-like language, like Java, Rust, Python, Javscript…
07:46:25 <aweinstock> (and multiple prominent haskellers are employed by financial institutions?)
07:46:33 <Sindriav_> aweinstock: "financial institutions" brings COBOL to mind :D
07:47:08 <floralshoppe> but why should I learn a language that is marginally different
07:47:12 <floralshoppe> Is it that much better?
07:47:15 <Intolerable> "marginally"
07:47:21 <Intolerable> yes
07:47:21 <Sindriav_> floralshoppe: "Why should I learn"
07:47:24 <Lokathor> most of this html-conduit package is lacking in example :/
07:47:50 <floralshoppe> Intolerable, sorry, radically*
07:48:03 <Intolerable> that makes more sense :)
07:48:32 <Lokathor> floralshoppe, learning haskell will make even your non-haskell code easier to work with
07:48:33 <aweinstock> for learning, isn't the relevant question "why shouldn't I learn ...?"
07:48:46 <aweinstock> (modulo time constraints)
07:48:48 <Sindriav_> Lokathor: Arguable. It made C++ unbearable for me :D
07:48:56 <Sindriav_> aweinstock + 1
07:49:24 <jasonx2> Lokathor same for C# for me
07:49:26 <Lokathor> yes, it will also make you grumpy when you lack things you expect
07:49:33 <jasonx2> and python
07:49:43 <Lokathor> java's lack of Maybe has gotten on my nerves lately
07:49:43 <geekosaur> amazon and google (at least) also prefer Haskell programmers even though they don't use Haskell internally, because they've found programmers who know Haskell to be better programmers in general
07:50:02 <Sindriav_> Lokathor: No. It will make you grumpy with languages that are badly designed. I'm fine with C.
07:50:12 <Sindriav_> Lokathor: *it made me grumpy
07:50:54 <Sindriav_> floralshoppe: As with real life languages, learning a new programming language often comes with a significant increase in understanding of other langauges you know
07:51:33 <Sindriav_> floralshoppe: Languages (almost by definition) abstract things away from you. Each language that abstracts a different thing makes you understand it better
07:52:57 <Sindriav_> *makes you understand other things better
07:53:44 <Sindriav_> floralshoppe: German made me understand word composition better, Toki Pona made me understand context better.
07:54:33 <floralshoppe> Yeah you're right, but as a language is it actually good for using it to create various programs?
07:54:40 <Intolerable> yes
07:54:46 <floralshoppe> How's it compared to C in terms of speed?
07:54:56 <Sindriav_> floralshoppe: Comparable.
07:55:12 <Intolerable> depends what you're doing
07:55:19 <Intolerable> some stuff will be as-fast-as or faster
07:55:23 <Intolerable> some stuff might be slower
07:55:25 <Sindriav_> floralshoppe: good C code will be faster than Haskell in most cases, but good C code is hard to come by.
07:55:30 <Intolerable> there's always ffi
07:55:36 <Sindriav_> That being said, Haskell is compilable into hardware you can print ¯\_(ツ)_/¯
07:56:07 <aweinstock> average haskell code is a similar speed to average Java/C# code? (GC'd compiled languages)
07:56:25 <aweinstock> (ignoring things like Ivory that use haskell as a macro-assembler)
07:56:57 <Sindriav_> aweinstock: I'd say it's significantly faster, in my experience
07:57:33 <Sindriav_> floralshoppe: Speed is a hard metric to compare. All you need to know is that Haskell is in the "compiled language" category of speed.
07:58:11 <jasonx2> python is an order or two magnitudes slower and is still usable for many programs
07:58:48 <jasonx2> (more usable than C, I'd say. I would never use C other than for system and embedded programming)
07:58:53 <Sindriav_> jasonx2: Python can be faster than handwritten C for many computations, since it has better libraries than C
07:59:12 <jasonx2> Sindriav_ how can libraries written in C be faster than C?
07:59:26 <aweinstock> jasonx2: inline assembly ;)
07:59:26 <jasonx2> and yes, python's solution for speed is "don't write it in python"
07:59:34 <Lokathor> maybe instead of having my Parsec parser be (many parseThread) i just need to do (many (try parseThread))
07:59:35 <Sindriav_> jasonx2: I never said they're faster than C, they're faster than handwritten C.
07:59:41 <Lokathor> hmmmm
07:59:50 <Lokathor> things to consider while at work
07:59:53 <Sindriav_> jasonx2: Handwritten C meaning C that most people write themselves.
07:59:56 <jasonx2> Sindriav_ handwritten by whom?
08:00:15 <Sindriav_> jasonx2: e.g. C that's not hardcore optimised by hand
08:00:25 <Sindriav_> Which noone does anyways
08:00:29 <floralshoppe> http://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=ghc&lang2=gcc
08:00:46 <itsu> Sindriav why did you learn toki pona ?
08:01:08 <Sindriav_> itsu: It's fun, it's a great conversation starter and you can do it on a spare weekend
08:01:20 <jasonx2> Sindriav_, as soon as your python stops being a shallow wrapper around C libraries it will be about 100 times slower
08:01:22 <itsu> yeah it seems so, it looks really interesting
08:01:22 <Sindriav_> itsu: I haven't used it though, and now I don't remember shit
08:01:26 <jasonx2> than C
08:01:38 <Sindriav_> jasonx2: >>= #haskell-blah anyways
08:03:00 <Sindriav_> (because once your C code stops being a shallow wrapper around C libraries, it will be about 100 times slower than optimized code) and we can do this all day, which I don't want to,
08:03:36 <jasonx2> you're not making any sense. computation intensive code in python is written in C because the language is dog slow
08:03:39 <Sindriav_> floralshoppe: Bottom line is, Haskell will be fast enough for you. If you needed the speed you talk about, you most likely wouldn't be asking
08:04:07 <Sindriav_> jasonx2: I am making lots of sense. That sense being "take this somewhere else than #haskell, because it's getting offtopic real fast"
08:04:09 <chpatrick> Lokathor: look at the link at the top of the contents
08:04:14 <jasonx2> this is why sum, for example, isn' written in python but in C (and thus doesn't automatically expand integrals on overflow, as python does)
08:04:25 <jasonx2> Sindriav_, I stopped, and then you continued
08:04:46 <Intolerable> anyone know any neat ways of fudging a >>= operator in python?
08:05:00 <Intolerable> atm im just manually expanding Eithers
08:05:00 <jasonx2> lets make it topical: http://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=python3&lang2=gcc
08:05:04 <Sindriav_> Intolerable: How would you define a Monad in Python?
08:05:05 <jasonx2> err
08:05:07 <jasonx2> http://benchmarksgame.alioth.debian.org/u64q/compare.php?lang=python3&lang2=ghc
08:05:15 <Intolerable> i don't want a generic Monad
08:05:25 <Intolerable> i just want to have bind look not like ass
08:05:36 <Intolerable> at the moment i have a bind method on Left and Right classes
08:05:46 <Intolerable> but lambdas are awful in python
08:06:07 <Sindriav_> Intolerable: I believe Python allows writing syntax extensions, which would allow custom operators
08:06:15 <aweinstock> Intolerable: write a haskell-to-unreadable-python compiler?
08:06:24 <Intolerable> bleh, both too much work
08:06:34 <Sindriav_> Intolerable: Search for getting "++" in Python :D
08:06:39 <jasonx2> just make a bind function? why does it need to be an operator
08:06:39 <Intolerable> there's no nasty way of doing it with iterators?
08:06:41 <seagreen> Is there a way to create a list of all the data constructors for a given sum type? I could do it by making the type an instance of Bounded and Enum, but I was wondering if there was a way without adding instances.
08:06:54 <Sindriav_> Intolerable: Sure, overload ">=" :D
08:07:00 <Intolerable> because if you do Left(5).bind(lambda x: (whatever))
08:07:05 <Intolerable> the nesting gets awful and huge
08:07:10 <aweinstock> maybe try hacking do-notation with context managers? (python's "with" syntax)
08:07:19 <Intolerable> and you can only put expressions inside it
08:07:22 <Intolerable> oh, thats a good idea
08:07:25 <Sindriav_> Intolerable: Left(5) >= lambda x: (whatever)
08:07:34 <Intolerable> still the expression problems
08:07:38 <Intolerable> *problem
08:07:40 <Intolerable> singular
08:08:10 <Intolerable> with looks like the way to go
08:08:27 <aweinstock> Intolerable: what kind of situation is this where writing magical haskell-in-python is acceptable, but writing normal haskell isn't?
08:09:18 <aweinstock> seagreen: [minBound..maxBound]
08:09:20 <Intolerable> having co-workers that can't haskell
08:09:21 * hackagebot OpenGLRaw 2.5.2.1 - A raw binding for the OpenGL graphics system  https://hackage.haskell.org/package/OpenGLRaw-2.5.2.1 (SvenPanne)
08:10:22 <seagreen> aweinstock: Right, but I still have to make it an instance of Bounded. Not the end of the world though.
08:10:36 <Sindriav_> Intolerable: Write a Python wrapper around a C wrapper around Haskell
08:10:53 <Intolerable> mm, sounds performant
08:11:04 <Sindriav_> :D
08:12:10 <aweinstock> seagreen: "deriving" will write the instance for you automatically
08:13:35 <aweinstock> Intolerable: but they can understand python metaclass voodoo hackery?
08:14:24 <Intolerable> i mean its literally just binding Eithers
08:15:13 <aweinstock> it won't be once you have generalized monad machinery with do-notation provided by context managers :)
08:15:49 <Intolerable> Either is fine thanks
08:15:55 <Intolerable> dont need to add everything else 
08:15:59 <Intolerable> (i have sequence though)
08:16:21 <Intolerable> (admittedly with a weird applicative instance)
08:18:08 <seagreen> aweinstock: Good point.
08:23:19 <Arcaed0x> Hi there I was wondering if the new Haskell platform for windows allows dynamic linking ?
08:32:54 <ansible1> trying out the armv7 ghc binary on debian jesse.  I'm trying to build cabal-install 1.22.06, but no luck so foar.
08:33:42 <ansible1> when I run the bootstrap.sh, it downloads mtl-2.2.1 and builds a 'Setup' executable.  that fails with illegal instruction.
08:57:12 <ansible1> ok, tried replacing ld with gold like so: "ln -s `which gold` ~/bin/ld"  but Setup still produces an illegal instruction.  not sure if I'm doing it right.
09:00:06 <jasonx2> is efficient functional hash table possible?
09:02:17 <int_index> http://lpaste.net/139274 Is this defined anywhere?
09:02:18 <chpatrick> @hackage unordered-containers -- jasonx2?
09:02:18 <lambdabot> http://hackage.haskell.org/package/unordered-containers -- jasonx2?
09:02:38 <chpatrick> it's not literally a hashtable though
09:02:39 <Intolerable> int_index: what does it do
09:03:23 <int_index> Intolerable: it discards a type parameter (makes it existential). 
09:03:27 <jasonx2> what makes it different?
09:04:15 <scshunt> int_index: yes
09:04:18 <scshunt> @hoogle Const
09:04:19 <lambdabot> Control.Applicative Const :: a -> Const a b
09:04:19 <lambdabot> Control.Applicative newtype Const a b
09:04:19 <lambdabot> Data.Data data Constr
09:04:45 <int_index> scshunt: it's completely different. Pay closer attention.
09:04:56 <scshunt> oh
09:05:08 <chpatrick> jasonx2: it's actually a fancy tree
09:05:23 <jasonx2> hmm
09:05:31 <chpatrick> the only "hashy" thing about it is that it hashes the keys first to store them in the tree structure
09:05:40 <chpatrick> but it's definitely functional
09:05:56 <chpatrick> in the "purely functional data structures" sense
09:07:06 <jasonx2> what is the advantage of that over just storing values  (and gettings orting for free)?
09:09:14 <chpatrick> jasonx2: what do you mean just storing?
09:09:25 <chpatrick> by order like in Data.Map?
09:10:06 <jasonx2> yes
09:11:24 <chpatrick> I'm not an expert but I think it's because you can compare chunks of the hashed key
09:11:34 <chpatrick> as opposed to comparing the whole structure like with Ord
09:11:52 <chpatrick> also comparing ints is always going to be really fast
09:13:28 <jasonx2> still log n comparisons though
09:18:24 <nitrix> What's the difference between fail and error?
09:19:00 <nitrix> fail is a failure in a monadic context and error is the entire application?
09:19:11 <Intolerable> fail is in a monad and error is an exception
09:19:21 <nitrix> Intolerable: Thanks.
09:19:33 <Intolerable> you shouldn't use fail in a generic Monad m => context
09:19:40 <Peaker> "error" is not "entire application", it's an exception catchable in IO
09:19:45 <Intolerable> because a lot of Monad instances don't have fail or have bad fails
09:20:21 <nitrix> Peaker: Well, isn't that because the application as a whole is an IO ?
09:20:47 <nitrix> Anyway, I think I figured the SDL thing:
09:21:33 <Peaker> nitrix: I can catch it in some small IO computation
09:21:42 <Peaker> nitrix: it doesn't have to crash my entire application
09:21:50 <Peaker> also, I think it'd typically only crash the current thread anyway
09:22:35 <nitrix> https://github.com/nitrix/lasers/blob/master/src/Main.hs
09:23:00 <nitrix> How does that look? First time using the Foreign interface.
09:23:58 <nitrix> I probably need to initialize SDL and finalize it too.
09:26:24 <Intolerable> is there an easier way to build something for windows than "get a windows pc"
09:26:55 <ew0> I used my first Control.Arrow  function today =D
09:26:58 <ew0> hurray!
09:27:22 <bamboo> ew0, congrats, looking forward to my first time as well :)
09:27:55 <bennofs> Is there any work on getting a distinction between hard and soft bounds into cabal?
09:28:40 <oftl> Intolerable: get a VirtualBox ;-)
09:28:55 <Intolerable> yeah, i think that's what it's gonna have to be :(
09:30:20 <monochrom> nothing is easier than "get a windows pc". however, a virtual machine is cheaper and has benefits like "can take snapshot and roll back"
09:30:26 <oftl> at least that's not as bad as a whole pc of it
09:30:46 <Intolerable> how much space does a windows 7 install take
09:31:00 <Intolerable> 20gb
09:31:03 <Intolerable> uhhhhhh
09:31:15 <Intolerable> that might be a problem
09:31:38 <bennofs> Intolerable: I think it's less
09:32:00 <Intolerable> presumably with ghc and friends it will be a bit more than that
09:32:15 <bennofs> Intolerable: 9.2G is the qcow2 size for my win7 machine
09:32:33 <ungov-> Hello! I'm trying out xmonad. Any ideas on how I could fix this error? http://ibin.co/2Co8EZKeLxba
09:32:50 <ungov-> This is all I have in my xmonad.hs file: http://pastebin.com/KM8SQV9P
09:33:03 <ew0> f***, now I'm seeing arrows in everything
09:33:04 <nshepperd> windows 7 installs tend to take as much space as you give it
09:33:20 <nshepperd> mostly by making ungodly large page files
09:33:24 <ew0> and I don't want to rewrite all my code
09:33:30 <Intolerable> fair
09:33:32 <ew0> damn you haskell people
09:33:42 <Intolerable> someone wants a windows build of something i made
09:34:26 <monochrom> hire a windows builder
09:34:43 <Intolerable> how much will it be for double glazing
09:35:07 <nitrix> Guys, I don't understand what's going on with sdl2. The hackage package points to https://github.com/haskell-game/sdl2.git, but when I check the examples in the repository, they use functions (e.g. SDL.initialize or SDL.quit) that aren't even in the API. 
09:35:10 <o`connor> Intolerable: if it's a one off thing, spin up a VPS on Amazon or something, build it, shut it down in an hour or two
09:35:11 <nitrix> What's going on?
09:35:15 <o`connor> it will be like a dollar, maybe
09:35:30 <Intolerable> that's a thought
09:41:48 <bennofs> nitrix: seems the github page points to a branch called "new-api", which probably isn't on hackage yet
09:45:47 <bennofs> Is cabal install still not able to upload package candidates? :O
09:50:54 <ungov-> > Hello! I'm trying xmonad out. Any ideas on how to fix this error?
09:50:54 <ungov->     http://ibin.co/2Co8EZKeLxb
09:50:56 <lambdabot>  <hint>:1:66:
09:50:56 <lambdabot>      parse error (possibly incorrect indentation or mismatched brackets)
09:51:06 <ungov-> This is all I have in my xmonad.hs file: http://pastebin.com/KM8SQV9P
09:51:24 <Intolerable> does it still happen if you completely reload xmonad?
09:51:55 <Intolerable> i.e. restart it, rather than just loading the new config
09:52:21 <Intolerable> image is here btw
09:52:22 <Intolerable> http://ibin.co/2Co8EZKeLxba
09:52:25 <Intolerable> u dropped the 
09:52:30 <Intolerable> *the a
09:52:57 <glguy> Intolerable: It looks like you have more than one version of xmonad installed
09:53:06 <glguy> Intolerable: try: ghc-pkg list xmonad
09:53:09 <Intolerable> that's not my screenshot
09:53:15 <Intolerable> direct it @ ungov-
09:53:24 <glguy> ok, ungov- ^
09:54:03 <glguy> When you get errors where one of the types explicitly qualifies the package it means that it's trying to match types across different versions of the same package
09:55:18 <ungov-> got you
09:55:28 <ungov-> So just uninstall one of the versions?
09:55:40 <glguy> Uninstalling the old version is the easiest solution
09:55:52 <glguy> ghc-pkg unregister xmonad-<oldversionnumber>
09:56:18 <ungov-> kewl... so cabal uninstall xmonad-0.10.1?
09:56:37 <ungov-> sorry, not very haskell versed...
09:56:51 <glguy> Yes, assuming that 0.10.1 is the old version
09:58:01 <ungov-> ghc-pkg list came back with bad news: http://pastebin.com/A6qG8sJ2
09:58:38 <Sindriav_> @pl [a + x, a + x, a + x, a - x, a - x, a + x, a - x, a - x]
09:58:38 <lambdabot> [a + x, a + x, a + x, a - x, a - x, a + x, a - x, a - x]
09:58:52 <Sindriav_> @pl \a x -> [a + x, a + x, a + x, a - x, a - x, a + x, a - x, a - x]
09:58:52 <lambdabot> ap (ap . ((:) .) . (+)) (ap (ap . ((:) .) . (+)) (ap (ap . ((:) .) . (+)) (ap (ap . ((:) .) . (-)) (ap (ap . ((:) .) . (-)) (ap (ap . ((:) .) . (+)) (ap (ap . ((:) .) . (-)) (flip flip [] . ((:) .) . (-))))))))
09:58:56 <Sindriav_> whoa
09:59:06 * Intolerable screams
09:59:43 <glguy> Sindriava: You can play with lambdabot in private message
10:00:18 <Sindriav_> Fair enough, but this wasn't enough to start a query IMO
10:00:29 <Sindriav_> anyways, si there a way to make it shorter?
10:00:31 <Sindriav_> *is
10:01:25 <Sindriav_> e.g. I have a point (x, y), that is a center of a square with the size W, and I want all of the square's corner points
10:01:42 <monochrom> \a x -> let {i = a+x; l = a-x} in [i, i, i, l, l, i, l, l]
10:02:20 <ungov-> ghc-pkg check says http://pastebin.com/Qxw59x36
10:02:29 <ungov-> What should I do about this?
10:02:35 <Intolerable> :t \a x -> zipWith3 ($) (cycle [(+), (-)]) (repeat a) (repeat x)
10:02:37 <lambdabot> Num d => d -> d -> [d]
10:02:47 <Sindriav_> monochrom: That's not really an improvement, considering it's [a], there must be some magic trick
10:02:53 <nitrix> bennofs: Should I stay away from that new-api until it's stable?
10:02:59 <bennofs> nitrix: no idea
10:02:59 <Intolerable> oh wait that's wrong
10:03:14 <Sindriav_> > (\a x -> zipWith3 ($) (cycle [(+), (-)]) (repeat a) (repeat x)) 0 0 5
10:03:16 <lambdabot>      Couldn't match expected type ‘Integer -> t’
10:03:16 <lambdabot>                  with actual type ‘[Integer]’
10:03:16 <lambdabot>      The function ‘\ a x
10:03:50 <monochrom> I agree to disagree.
10:03:57 <aweinstock> :t \w (x,y) -> [(x # w, y @ w) | (#) <- [(+),(-)], (@) <- [(+),(-)]]
10:03:59 <lambdabot> parse error on input ‘)’
10:04:22 <Sindriav_> nah, mapM maybe? gimme a sec
10:04:26 * hackagebot irc-core 1.1.1 - An IRC client library and text client  https://hackage.haskell.org/package/irc-core-1.1.1 (EricMertens)
10:04:57 <ungov-> What to do in this situation? http://pastebin.com/Qxw59x36 ... Looks bad...
10:05:33 <aweinstock> :t \w (x,y) -> let ops = [(+),(-)] in [(x # w, y @ w) | (#) <- ops, (@) <- ops]
10:05:35 <lambdabot> parse error on input ‘)’
10:05:43 <Sindriav_> aweinstock: That's way too complicated
10:05:52 <Intolerable> cabal install xmonad?
10:06:02 <Intolerable> (@ungov-)
10:06:32 <aweinstock> :t \w (x,y) -> let ops = [(+),(-)] in [(x # w, y & w) | (#) <- ops, (&) <- ops]
10:06:33 <lambdabot> parse error on input ‘)’
10:07:12 <aweinstock> huh, that's weird (it works locally)
10:08:05 <aweinstock> > (\w (x,y) -> let ops = [(+),(-)] in [(x # w, y & w) | (#) <- ops, (&) <- ops]) 2 (5,5)
10:08:07 <lambdabot>  <hint>:1:57: parse error on input ‘)’
10:09:11 <Sindriav_> monochrom: In any case, `i` and `l` are not good variable names for this case, and your example was more unreadable than the original code, thus making it pointless
10:09:17 <dolio> aweinstock: @ isn't a valid operator name.
10:10:21 <Sindriav_> aweinstock: I basically want [a + x, b + x, a + x, b - x, a - x, b + x, a - x, b - x]. There's bound to be some monadic function that works like that on [a]
10:11:12 <ungov-> Intolerable: thanks! Error is gone now
10:11:20 <Intolerable> enjoy
10:12:29 <Sindriav_> aweinstock: Get all possible pairs, choosing from [(+x), (subtract x)], mconcat them and zip with cycle [a, b] should work
10:13:05 <aweinstock> dolio: i got an error message relating to @ in a local ghci, so i changed it to &, but that still doesn't work with lambdabot (even though it works in local ghci)
10:13:25 <L8D> > (\w (x,y) -> let ops = [(+),(-)] in [(x `l` w, y `r` w) | l <- ops, r <- ops]) 2 (5, 5)
10:13:26 <lambdabot>  [(7,7),(7,3),(3,7),(3,3)]
10:13:42 <L8D> aweinstock: '#' is a reserved character
10:14:00 <L8D> aweinstock: it's used for annotating boxed/unboxed variables I think
10:14:10 <dolio> L8D: It's not reserved.
10:14:29 <aweinstock> oh, so # can't be used as an operator when MagicHash extension is enabled?
10:14:32 <dolio> There's just an extension that lets you use # at the end of alphanumeric names.
10:15:48 <chpatrick> @let allPairs = \case { [] -> []; x : xs -> xs >>= \x' -> [ ( x, x' ), ( x', x ) ] : allPairs xs }
10:15:48 <lambdabot>  Parse failed: LambdaCase is not enabled
10:15:50 <pyon> Is there any way to get the link to the documentation of a function (either from Hackage or installed locally) in GHCi?
10:16:00 <L8D> > (\w (x,y) -> let ops = [(+),(-)] in [(x ? w, y & w) | (?) <- ops, (&) <- ops]) 2 (5, 5)
10:16:02 <lambdabot>  [(7,7),(7,3),(3,7),(3,3)]
10:16:02 <dolio> aweinstock: I think the error is a quirk of the > command. Your expression with & works in @type.
10:16:09 <chpatrick> @let allPairs as = case as of { [] -> []; x : xs -> xs >>= \x' -> [ ( x, x' ), ( x', x ) ] : allPairs xs }
10:16:10 <dolio> I think > and @eval does some of its own parsing.
10:16:11 <lambdabot>  Defined.
10:16:23 <aweinstock> > (\w (x,y) -> let ops = [(+),(-)] in [(x & w, y && w) | (&) <- ops, (&&) <- ops]) 2 (5,5)
10:16:24 <L8D> > let (@) = (+) in (@)
10:16:26 <lambdabot>  [(7,7),(7,3),(3,7),(3,3)]
10:16:26 <lambdabot>  <hint>:1:6: parse error on input ‘@’
10:16:31 <L8D> ^^^^
10:16:40 <chpatrick> > let foo xs = map uncurry [ (+) , (-) ] <*> allPairs xs
10:16:42 <lambdabot>  <no location info>:
10:16:42 <lambdabot>      not an expression: ‘let foo xs = map uncurry [ (+) , (-) ] <*> allPairs xs’
10:16:44 <L8D> you can't use '@' as a variable name
10:16:55 <chpatrick> let foo xs = map uncurry [ (+) , (-) ] <*> allPairs xs in foo [ 1, 10, 100 ]
10:17:05 <L8D> > let (#) = (+) in (#)
10:17:05 <chpatrick> > let foo xs = map uncurry [ (+) , (-) ] <*> allPairs xs in foo [ 1, 10, 100 ]
10:17:07 <lambdabot>  <hint>:1:7: parse error on input ‘)’
10:17:07 <lambdabot>      Couldn't match type ‘[(t, t)]’ with ‘(b1, b1)’
10:17:07 <lambdabot>      Expected type: [(b1, b1)]
10:17:07 <lambdabot>        Actual type: [[(t, t)]]
10:19:48 <chpatrick> @unlet allPairs
10:19:48 <lambdabot>  Parse failed: TemplateHaskell is not enabled
10:26:12 <pyon> In the `pipes-parse`, the documentation mentions «improper lenses». What's an «improper lens»?
10:27:23 <bennofs> pyon: one that doesn't satisfy the lens laws  (3 lens laws: set/get = setting and then getting gives the set value,  set/set = setting twice is the same as only doing the second set,   get/set = setting to the value you get is the same as doing nothing)
10:28:26 <pyon> Ah, okay! I understand the lens laws. I just have no idea why or when one would want to use a lens that doesn't satisfy them.
10:29:20 <bennofs> pyon: it's quite easy to end up with Traversals that don't satisfy the Traversal laws. for example, filtered is not a "valid" traversal if you set to a value that violates the condition
10:29:27 * hackagebot snaplet-postgresql-simple 0.6.0.3 - postgresql-simple snaplet for the Snap Framework  https://hackage.haskell.org/package/snaplet-postgresql-simple-0.6.0.3 (DougBeardsley)
10:29:59 <xplat> well, the 'show/read' prism is improper
10:30:33 <bennofs> xplat: yeah, it happens with Prisms / Traversals quite often. Is there a commonly used Lens that fails the laws though?
10:33:48 <FatBoyXPC> I'm hoping I can get some help with my xmonad config in here
10:37:58 <pyon> So, I get the general principles behind lenses (first-class single nested value) and traversals (first-class sequence of nested values). Nevertheless, the fact GHCi's `:t` command only gives fully expanded type signatures makes them *really* hard to read. Is there any technical reason why GHCi can't work with type synonyms?
10:38:27 <FatBoyXPC> I'm trying to configure my xmonad.hs config to move window to screen AND follow that window. Note: this is for screen, not workspace.
10:39:00 <xplat> bennofs: well, there are some improper isos that get used, like non/anon, and isos are also lenses or can be composed into lenses
10:39:31 <xplat> bennofs: and partsOf (iirc) turns a traversal into an improper lens
10:40:19 <bennofs> pyon: ghci can work with type synonyms in some cases, but they sometimes get expanded during typechecking afair.
10:50:43 <fjordrunner> hi folks, please can you help me with following? I'm trying to create a project with cabal. After I create it and run cabal install I get: haddock: internal error: /Library/Frameworks/GHC.framework/Versions/7.8.3-x86_64/usr/lib/ghc-7.8.3/settings: openFile: does not exist (No such file or directory)
10:51:11 <fjordrunner> (I'm in empty sandbox)
10:51:14 <Ankhers> fjordrunner: How did you install GHC?
10:51:23 <Ankhers> fjordrunner: Have you been able to build things before?
10:51:31 <fjordrunner> homebrew (mac)
10:51:49 <Ankhers> Pretty sure that is not maintained.
10:51:58 <fjordrunner> ghc and ghci works fine,.
10:52:22 <Ankhers> That is still a fairly old version of GHC.
10:52:37 <fjordrunner> ok, so should I try with fresh install from https://www.haskell.org/platform/?
10:52:44 <fjordrunner> will try,.. :-)
10:52:55 <Ankhers> I'm going to give you two suggestions. Either use stack, or https://ghcformacosx.github.io/
10:53:16 <Ankhers> Stack has the advantage of downloading GHC for you if you don't have it.
10:53:39 <Ankhers> https://github.com/commercialhaskell/stack
10:54:07 <fjordrunner> Ankhers: thanks,..will try
10:56:11 <Ankhers> fjordrunner: No problem. Good luck. Let us know if you have issues with anything.
10:57:38 <fjordrunner> I just know that with the last version there is some problem with ghc-mod on mac,...but I can live without that...
10:58:51 <Ankhers> fjordrunner: If I'm not mistaken, ghc-mod currently does build against 7.10.2. Just not the version on Hackage.
11:01:37 <Ankhers> fjordrunner: Actually, it may be fixed on Hackage now too.
11:02:56 <ski> pyon : you could also try asking in #haskell-lens
11:04:06 <SrPx> Hello, does anyone know how I can write the rewrite rules for that type I posted on Reddit? `fromFold . toFold == id` and vice-versa. Can I actually use "." there, will it still work for `fromFold (toFold x)`?
11:06:04 <nitrix> How do I find out if a pointer's null?
11:06:12 <nitrix> peek fooPtr == nullPtr ?
11:06:36 <fosterite> is there a tool that takes a type signature and tells you the free theorems for it?
11:06:43 <fosterite> I've only ever seen it done by hand
11:06:55 <nitrix> Oh wait, just fooPtr == nullPtr should do it, right?
11:07:26 <bennofs> fosterite: like
11:07:28 <bennofs> @free map
11:07:29 <lambdabot> g . h = k . f => $map g . map h = map k . $map f
11:08:01 <pyon> Where `$map` means?
11:08:15 <fosterite> @free (foo :: Num r => r -> r)
11:08:15 <lambdabot> Pattern match failure in do expression at src/Lambdabot/Plugin/Haskell/Free/FreeTheorem.hs:54:21-35
11:08:30 <clrnd> hello :)
11:08:46 <bennofs> fosterite: http://www-ps.iai.uni-bonn.de/cgi-bin/free-theorems-webui.cgi perhaps?
11:09:33 <fjordrunner> Ankhers: so the cabal project worked with the ghcformacos,..great
11:09:39 <bennofs> http://www-ps.iai.uni-bonn.de/cgi-bin/exfind.cgi# is also pretty cool
11:09:57 <fosterite> bennofs: yeah thanks
11:10:11 <ski> pyon : `fmap' on lists
11:11:42 <ski> @free f :: [[a]] -> [a]  -- fosterite
11:11:42 <lambdabot> $map g . f = f . $map ($map g)
11:12:05 <ski> @free f :: [Maybe a] -> [a]
11:12:05 <lambdabot> $map g . f = f . $map ($map_Maybe g)
11:12:33 <ski> @free f :: [[a] -> a] -> [a]
11:12:33 <lambdabot> (forall h. (forall k p. g . k = p . $map g                        =>                         h k = p)           =>            $map h xs = ys) => $map g (f xs) = f ys
11:14:20 <clrnd> hi, I have a small question regarding folds (maybe)
11:14:22 <clrnd> http://lpaste.net/139289
11:14:37 <Welkin> a small question?
11:14:44 <Welkin> what does a large question look like? :p
11:14:52 <clrnd> Welkin, I can show you (?)
11:15:04 <fosterite> ski: that helps. I had assumed that typeclass laws could be included
11:15:09 <int-e> Welkin: What?
11:15:21 <Welkin> lambdabot is having a bad day
11:15:24 <clrnd> anyway, the thing is, that works nice ^ and I've almost done parsing this stuff, but it just hit me: foldr isn't tail rec
11:15:28 <Welkin> what's with all the random whitespace?
11:16:02 <fosterite> what I would most like is "Ring r => r -> r are the polynomials in one variable" but all I'm getting is "they're ring homomorphisms"
11:16:18 <int-e> Welkin: looks like it removed newlines from pretty-printed output.
11:16:38 <clrnd> I'm using foldr just because `lensMagic .~ value` takes it's argument on the right
11:16:48 <clrnd> the question is whether a foldl' would be faster, maybe
11:17:49 <clrnd> or I could just `foldl' (flip parseExample)` ... lol I'm dumb
11:18:15 <fosterite> another question: if I have a free algebra and I want to generate specialized code for each occurrence of an operation, do I need to use template haskell
11:19:40 <clrnd> thanks guys
11:19:43 <fosterite> e.g. I make a free geometric algebra, use it to multiply some scalars, the generated code is specifically scalar multiplies rather than the general multiplication
11:28:27 <kqr> @pl \fn -> fmap (readPost fn) (readFile fn)
11:28:27 <lambdabot> liftM2 fmap readPost readFile
11:29:18 <ReinH> fosterite: Perhaps you are mixing up two different "free" concepts.
11:29:54 <fosterite> ReinH: In my second question I mean free in the sense that List is the free monoid
11:30:07 <fosterite> not the free theorem sense
11:30:39 <ReinH> fosterite: free theorems are theorems for the type. They do not know anything babout typeclass laws, which are out-of-band.
11:31:29 <kclancy> Is there a guide to understanding the pretty print output of ghc core syntax?
11:31:49 <mitchty> say i wanted to output a Fractional in ghci without exponent notation, is there an easy way to do that?
11:31:53 <kclancy> I know Fc(x), but I don't know what the @'s represent.
11:32:08 <ReinH> fosterite: I'm confused by your second question. Free objects don't have any specializations. That's sort of the point.
11:32:25 <ski> ReinH : possibly they could take typeclass constraints into account ..
11:33:04 <ReinH> ski: Perhaps, but only jn an ad hoc way
11:33:10 <ReinH> *in
11:33:16 <ski> ReinH : i'm not sure about that
11:33:22 <ski> fosterite : can you elaborate ?
11:33:25 <fosterite> ReinH: I want to use the free structure to build the computation, but when evaluating it take into account the extra things I know about it to use better functions
11:33:55 <ski> ReinH : well .. yes, if one would like to take the laws of the typeclass into account
11:33:58 <ReinH> fosterite: Evaluating it is usually done via homomorphisms, which would apply the specialized operations in the target structure
11:34:25 <ReinH> for example, foldMap
11:34:50 <ski> fosterite : do you have an example of what you want to be able to do ?
11:34:52 <fosterite> e.g. Inverse (UnitVector a :*: UnitVector b) can just be (UnitVector b :*: UnitVector a)
11:35:24 <ReinH> That doesn't look like a free structure, that looks ike an initial encoding.
11:35:28 <ski> fosterite : what is `:*:' ?
11:35:30 <fosterite> and (Scalar a :*: Scalar b) should be Scalar (a*b)
11:35:42 <kqr> :t mapM
11:35:43 <lambdabot> (Monad m, Traversable t) => (a -> m b) -> t a -> m (t b)
11:35:49 <kqr> :t fmap
11:35:50 <lambdabot> Functor f => (a -> b) -> f a -> f b
11:35:50 <fosterite> ski: infix data type constructor
11:35:53 <ReinH> which can be manipulated using, e.g.,  rewrite rules with uniplate
11:35:53 <kqr> ah
11:36:05 <ski> fosterite : i know, i mean what does it *mean* in your example ?
11:36:13 <fosterite> ski: the geometric product
11:36:25 <ReinH> ski: it's an initial encoding, where :*: encodes *
11:36:38 <ReinH> it isn't a free construction
11:36:39 * ski doesn't know much about geometric algebra
11:36:48 <fosterite> ReinH: I confused the two
11:36:59 <ReinH> ski: No different from 1 + 1 ~ Scalar 1 :+: Scalar 1
11:37:34 <fosterite> ski: if a is a unit vector a*a = 1, so the inverse of a*b where a,b are unit vectors is b*a and you save on the computation
11:37:43 <ski> is `:*:' representing some kind of inner product or what ?
11:37:44 <ReinH> You can use uniplate for that, things like rewriting Negate (Negate p) -> p
11:37:56 <fosterite> ski: geometric product is inner + exterior product
11:38:15 <ReinH> ski: it doesn't really matter what particular operation is being encoded
11:38:38 <ski> fosterite : and geometric product is in general not commutative ? how about upto isomorphism ?
11:38:44 <fosterite> ReinH: I'll take a look at it thank
11:38:46 <ReinH> just that it has some laws that you can use to rewrite optimize terms 
11:39:03 <ReinH> fosterite: you might look at Plated from lens
11:39:04 <fosterite> ski: not commutative. it's associative though
11:39:37 <ski> ReinH : well, one could have a free structure for that as well, i believe .. just not anarchic
11:40:42 <fosterite> also, what's the precise difference between an initial encoding and a free structure
11:41:11 <fosterite> I thought they were both the ability to define homomorphisms to any other instance of the structure
11:41:12 <ReinH> fosterite: in this case, knowing that inverse is sometimes a noop means you are no longer just using the free structure
11:41:16 <ReinH> you're using additional information
11:41:40 <ReinH> a free structure is one where *only* the laws hold
11:42:03 <fosterite> ReinH: I see, thanks again
11:45:59 <ReinH> fosterite: free objects are initial, yes
11:46:24 <kqr> okay I need some assistance with a short function. I can come up with a bunch of ways to write it but they all are uglier than the next and it feels like I'm missing something. please see http://lpaste.net/8059338876327559168
11:49:07 <ReinH> kqr: sequence . mapM (printLeft . parsePost . readFile) where printLeft (Left reason) = putStrLn reason; printLeft (Right post) = return post
11:49:19 <ReinH> er, that's just either putStrLn return
11:49:30 * hackagebot DSA 1.0 - Implementation of DSA, based on the description of FIPS 186-4  https://hackage.haskell.org/package/DSA-1.0 (AdamWick)
11:49:33 <ReinH> hmm, type error
11:49:48 <kqr> mapM can't filter out the Left results
11:49:54 <ReinH> it doesn't need to
11:50:29 <kqr> oh?
11:50:32 <Welkin> kqr: why is that function in IO? Why not use Writer to log your errors?
11:50:46 <kqr> Welkin, to be able to read the file
11:51:05 <Welkin> you can read the file and then apply another function to it
11:51:09 <Welkin> keep all the IO in main
11:51:34 <RageYL> hi
11:51:51 <kqr> I guess I could read [FilePath] into a [(FilePath, Text)] and the uncurry the function over that, but meh
11:51:55 <kqr> I was hoping that wasn't necessary
11:52:55 <ReinH> catMaybes . sequence . mapM ((either (\str -> putStrLn str >> return Nothing) (return . Just)) . parsePost . readFile)
11:53:30 <ReinH> I don't like mixing up logging with reading either though
11:54:23 <ReinH> I don't see any problem with taking [(FilePath, Text)]
11:54:39 <SrPx> There is a function that is defined like "f a b c = ...". I changed it to "f = \ a b c -> ..." and now it won't typecheck.
11:54:39 <ReinH> You don't even need Writer
11:54:53 <ReinH> Just collect your [Either String Post] into ([String], [Post])
11:55:28 <ReinH> SrPx: my guess is the DMR, but you should include your error messages when reporting errors
11:55:36 <RageYL> i would like to create something like a global variable, i read that we can achieve that with monad, but can you give me more information about ?
11:55:40 <SrPx> ReinH: I have the monomorphism flag on
11:55:56 <ReinH> SrPx: ok, show us your code and your error message
11:56:07 <ReinH> RageYL: Why do you want to do that?
11:56:08 <kqr> RageYL, not with monad, but with IO
11:56:17 <kqr> RageYL, an IORef is like a global mutable variable
11:56:28 <Welkin> RageYL: the Reader monad
11:56:39 <RageYL> ReinH: my first project is an irc bot and i have command. some command have a 'context' that must be kept
11:56:46 <Welkin> well, that is for a global constant, not a variable
11:56:49 <ReinH> RageYL: is that context mutable?
11:56:55 <RageYL> yep
11:57:01 <Welkin> global variables = bad idea
11:57:15 <ReinH> RageYL: a few options: pass it around, use StateT, or use an IORef
11:57:23 <ReinH> There are others, but none of them require "global variables"
11:57:52 <ReinH> It isn't unreasonable to look at Haskell as a language motivated by avoiding the use of global variables
11:57:56 <SrPx> This is the error http://lpaste.net/139290 , I didn't show it because I'm still isolating, but if you want the full code I included it too...
11:58:37 <SrPx> Specifically just line 49/50 are relevant I believe
11:58:39 <RageYL> i will see with IORef, i don't know StateT (but i know about State) and it seems not to be what i want
11:58:54 <RageYL> because i would like to have a context for the bot and small context for each command
11:58:57 <ReinH> SrPx: you always seem to find the weirdest things to do with haskell
11:59:11 <SrPx> ReinH: thanks
11:59:28 <Cale> RageYL: I would say just use function parameters to start
11:59:40 <ReinH> personally I would just pass things around
11:59:47 <ReinH> which is why I mentioned it first and IORefs last ;)
11:59:48 <RageYL> there would be too much arguments
11:59:49 <SrPx> One day somebody else will understand my weird stuff
11:59:58 <Cale> RageYL: Once it becomes clear how you're using those function parameters, maybe you can think more clearly about what sort of machinery would clean things up.
12:00:08 <ReinH> RageYL: put them in a record. You'll need to do that for the other solutions anyway
12:00:11 <Cale> RageYL: Remember that you can define data types
12:00:27 <Cale> So you can bundle all the configuration together into a single argument
12:00:38 <ReinH> SrPx: I'm not complaining :)
12:01:00 <RageYL> i can use a big structure and use state monad but thus things are all in the same structure
12:01:02 <ReinH> SrPx: I'd say try to find a smaller test case that we can look at
12:01:15 <SrPx> I'll do it soon
12:01:23 <ReinH> RageYL: you said you have a global state and a local state. That sounds like two parameters to me.
12:01:23 <RageYL> can i paste you my code (it's small) and tell me if i do something wrong ?
12:01:31 <ReinH> RageYL: sure, use lpaste.net
12:01:44 <RageYL> do you accept gist ?
12:01:47 <Cale> yes
12:01:51 <ReinH> NO WE DO NOT... ok sure
12:02:07 <RageYL> https://gist.github.com/anonymous/08d20fca8c27999a2bdf
12:02:32 <SrPx> do you think I'll eventually reach your enlightenment and stop hating types 
12:03:14 <Welkin> SrPx: I can tell
12:03:24 <Welkin> why are your type declarations so far away from the definitions?
12:03:33 <Welkin> it makes it very hard to read
12:03:35 <Cale> RageYL: This code looks fairly reasonable to me as a start...
12:03:50 <ReinH> RageYL: where particularly are you wanting to introduce the state?
12:03:55 <RageYL> for example now i would like to implement a !roulette command
12:04:00 <RageYL> i need to keep track of the counter
12:04:40 <SrPx> Welkin: it is easier to read to me. I'm sorry.
12:04:42 <ReinH> RageYL: clientLoop can take a state parameter
12:05:02 <Cale> So yeah, the fact that everything is in IO gives you a few options here.
12:05:17 <ReinH> clientLoop handle state ... newState <- dispatch handle message state ... clientLoop handle newState
12:06:13 <RageYL> ok i will try with a state then
12:06:25 <Cale> You can create an IORef just outside the forever loop to hold the state, and pass that around, or you can do what ReinH is suggesting, which is perhaps the more pure solution.
12:06:58 <ReinH> You can even do nice things like use lens to zoom in on the relevant state for a subcommand
12:07:11 * ski would first try what ReinH suggested, before going for `IORef'
12:07:48 <ReinH> I have good ideas sometimes :D
12:07:53 <RageYL> i will go with ReinH solution then
12:07:55 <fjordrunner> please, anybody experienced following while installing ghc-mod? <command line>: can't load .so/.DLL for: /Users/eDS/Library/Haskell/ghc-7.10.2-x86_64/lib/mtl-2.2.1/libHSmtl-2.2.1-KMpng31YRYc5JfMWFZ3FCU-ghc7.10.2.dylib (dlopen(/Users/eDS/Library/Haskell/ghc-7.10.2-x86_64/lib/mtl-2.2.1/libHSmtl-2.2.1-KMpng31YRYc5JfMWFZ3FCU-ghc7.10.2.dylib, 5): Library not loaded: /usr/local/lib/ghc-7.10.2/trans_3eG64VdP2vzGjP6wJiCp5X/libH
12:07:55 <fjordrunner> Stransformers-0.4.2.0-3eG64VdP2vzGjP6wJiCp5X-ghc7.10.2.dylib
12:08:07 <RageYL> but i will try what Cale said about IORef to learn about it
12:08:14 <RageYL> and see lens too ;)
12:08:15 <RageYL> thanks guys
12:08:23 <fjordrunner> am on mac
12:08:29 <ski> `IORef' if you need to be able to reify and pass around the state location itself
12:08:56 <ReinH> fjordrunner: can you pastie the full output?
12:09:03 <ski> if you don't need that, then just keeping the state as a local, nonlocated, value, is probably nicer
12:09:05 <ReinH> @where lpaste
12:09:05 <lambdabot> http://lpaste.net/
12:09:33 <Cale> Another thing you can do, which is sort of the OO solution, is to define a record data type whose fields are the relevant operations on the state. Creating such a record might be as simple as r <- newIORef initialValue and then putting readIORef r and writeIORef r into the record, but you might take that opportunity to more finely control how the state is accessed of course.
12:09:50 <jerbome> hi guys, is it tolerated here, to post SE code reviews here ?
12:10:11 <srhb> jerbome: Yes, but they have a poor track record in terms of responses.
12:10:13 <Cale> jerbome: I don't know what one of those is
12:10:13 <fjordrunner> here is the output: http://lpaste.net/139293
12:10:24 <ski> that "OO solution" is intermediate in power between the two earlier solutions mentioned
12:10:52 <jerbome> here it is then : http://codereview.stackexchange.com/questions/101502/hackerrank-candies
12:10:58 <ski> the more powerful solutions are (tyically) hard to reason about (e.g. refactor), so you shouldn't unnecessarily go for more power, unless you need it
12:11:06 <ski> s/hard/harder/
12:11:08 <fjordrunner> it looks like problem with installing fclabels
12:11:46 <ReinH> fjordrunner: cabal install fclabels-2.0.2.2 and report the output :)
12:11:56 <ReinH> it'll give you a better error msg
12:12:00 <RageYL> i will go with easy solution for now ^^
12:12:16 <RageYL> i must not run too fast :D
12:12:31 <ReinH> RageYL: :)
12:13:03 <RageYL> that's why i wanted to learn haskell, i wanted to see how to solve problem another way
12:13:06 <fjordrunner> ReinH: in a way the same: http://lpaste.net/139294
12:14:41 <srhb> I might be going blind, but I'd try reinstalling the broken libs (eg mtl) too. I have no idea why they might be broken though (and no experience with OS X)
12:14:50 <Cale> You can also sort of combine the two, by defining a type for your state which has operations that produce new values of that type, like:  data StateObject = SO { curFoo :: Integer, setFoo :: Integer -> StateObject } -- if this were all you were doing, it would be not really better than passing around an Integer, however, if you had more specialised and meaningful operations, it can be a nice approach.
12:17:45 <RageYL> Cale: with you solution that means i must return the state on each function ?
12:17:49 <Cale> yes
12:17:58 <ReinH> fjordrunner: well you've done screwed the pooch on that one I guess :(
12:18:01 <RageYL> ok...
12:18:03 <Cale> Well, with this last one
12:18:14 <fjordrunner> ReinH: what you mean?
12:18:23 <ReinH> fjordrunner: I mean that your mtl install seems to be broken, which is bad
12:18:32 <Cale> With the IORef, you just need to pass the record in, and the operations modify the value of the IORef.
12:18:40 <Alas-> Hello, I'm sorry if this gets asked a lot, but what is the minimal way of installing Haskell on OS X? Is it sufficient to just install ghc using brew?
12:18:47 <fjordrunner> ReinH: do you know that how could I fix that?
12:18:59 <fjordrunner> ReinH: uninstall?
12:19:03 <ReinH> fjordrunner: You could force reinstall mtl, but then you'd probably need to force reinstall everything else too
12:19:12 <srhb> That sounds likely.
12:19:26 <ReinH> Perhaps best to nuke everything and start over, but there goes your day...
12:19:41 <Cale> Alas-: Uh, minimal? I think just installing this package would be pretty close. https://www.haskell.org/ghc/download_ghc_7_10_2#macosx_x86_64
12:19:43 <ReinH> fjordrunner: could you perhaps have reinstalled or upgraded ghc recently?
12:19:55 <fjordrunner> ReinH: yes,..
12:19:58 <Cale> Alas-: However, you might have a better time with https://www.haskell.org/platform/#osx
12:20:12 <ReinH> fjordrunner: then you'll probably need to reinstall everything.
12:20:17 <srhb> ReinH, fjordrunner: The package is in /Users though, which suggests it's already a local package, not a global one.
12:20:24 <srhb> That might make it Less Disastrous? :-)
12:20:33 <ReinH> Alas-: homebrew is a good option, as is https://ghcformacosx.github.io
12:20:45 <RageYL> for me IORef seems like it goes against haskell philosophy
12:20:59 <voidzero> sounds religious
12:20:59 <RageYL> (from the documentation)
12:21:05 <ReinH> srhb: fjordrunner That location is the global db for that user
12:21:16 <ReinH> So probably not less disasterous :(
12:21:19 <srhb> RageYL: Not really. The contents can only be dealt with from within the IO Monad, so all's good.
12:21:20 <Alas-> Cale: I do not want to pull a lot of packages that I will not use right away. I assume it is possible to install things as I go.
12:21:22 <jle`> IORef actually makes a lot of sense from haskell philosophy/point of view/semantics
12:21:25 <srhb> ReinH: Ah, crap. Ok.
12:21:35 <ReinH> Alas-: You could also install stack and have stack install your ghcs for you.
12:21:37 <RageYL> srhb: but in multithread that's not safe no ?
12:21:44 <fjordrunner> ReinH: trying with completer fresh install
12:21:48 <jle`> it's like a part of an IO computation, describing actions
12:21:49 <srhb> RageYL: Then there's MVar which is similar.
12:21:58 <RageYL> function have side effect with IORef
12:21:59 <srhb> RageYL: It also depends what you mean by safe.
12:22:00 <jle`> so an action that changes a pointer's pointed value makes perfect sense
12:22:06 <Alas-> ReinH: I'm checking it out
12:22:06 <srhb> RageYL: No, they don;t.
12:22:20 <jle`> all IORef actions themselves are pure
12:22:25 <RageYL> that's not like a pointer ?
12:22:34 <jle`> it's no different than like, querying an external database using IO
12:22:37 <Cale> RageYL: Depends on what you mean by "not safe" -- updates to IORefs are atomic
12:22:48 <ReinH> RageYL: you can think of it as a pointer that is managed for you by the runtime
12:23:30 <Cale> RageYL: But if you were using multiple threads to update the value, you'd more likely prefer to use something like an MVar
12:23:38 <RageYL> for me i mean not safe as: the content can be modified, thus if it's use by two function simultaneously it can cause problem
12:23:45 <ReinH> Alas-: I've been enjoying stack because I can pretty easily use multiple ghc versions on different packages
12:23:55 <ReinH> RageYL: Not if atomic updates are used
12:24:07 <RageYL> there can be toctou
12:24:16 <ReinH> RageYL: not if the runtime manages the pointer for you
12:24:41 <Cale> RageYL: You'll never see a half-written IORef
12:24:41 <ReinH> the runtime manages what is basically locking access to the var
12:24:56 <RageYL> i mean if i have 2 condition
12:25:05 <RageYL> the condition pass
12:25:14 <Cale> But you might have two threads which read the IORef simultaneously, compute an update, and then both write to it separately, losing an update.
12:25:26 <RageYL> yep that's what i mean Cale ;)
12:25:28 <RageYL> :D
12:25:38 <Cale> That's what MVars and TVars solve.
12:25:48 <RageYL> ok perfect ;)
12:27:35 <Cale> An MVar may be empty (no value), or full (containing a value). You can take from a full MVar which obtains the current value while emptying the MVar. Taking from an empty MVar will cause the thread to block until it becomes full. You can also put to an empty MVar, which will fill it. Trying to put a value into a full MVar will block until it becomes empty.
12:28:38 <Cale> RageYL: So basically, if two threads want to update the same MVar, they will both try to take from it, one will succeed and the other will get blocked until the thread which succeeded in taking the MVar puts in a new value.
12:28:39 <RageYL> i will remember. i think in few weeks i will try to use multithreading in the bot
12:29:36 <Cale> I wonder if freenode is getting attacked.
12:29:53 <RageYL> ^^
12:30:55 <Cale> RageYL: So yeah, the advantage to abstracting over the operations that act on your state is that you can change out an IORef-based implementation for something which uses an MVar, or something which additionally logs changes to the state somewhere for instance.
12:31:03 <cjay> SrPx: I find your weird stuff interesting. Is CList a known concept, or did you just invent it?
12:31:30 <SrPx> cjay: it is short for church list. You just told me to name my types better. :(
12:31:31 <Cale> cjay: That style of list is older than electronic computers :)
12:31:42 <Cale> It's due to Curry.
12:31:47 <cjay> ah :)
12:31:52 <Cale> Er, Church maybe
12:32:59 <ReinH> Yes, they are called "Church lists" and named after Haskell Curry.
12:33:12 <Cale> heh
12:33:15 <cjay> ^^
12:33:17 <SrPx> I know it might not be a replacement for foldable but I find that typeclass insanely useful, I can have all list algorithms, vector math and much more stuff for list, vectors, unboxed vectors etc
12:34:05 <SrPx> So I'll just call it ListIsomorphic but that solves a huge issue I had before, I'm glad for it
12:34:16 <Cale> I always forget who is responsible for what exactly. There are a bunch of contemporary logicians who worked on lambda calculi and did things of that sort.
12:34:46 <ReinH> Similarly, Haskell was named after a logician named Moses Schönfinkel
12:34:59 <tomjaguarpaw> Does someone know how I get stack to put its stuff somewhere other than ~/.stack?
12:35:00 <cjay> lol
12:35:12 <Cale> SrPx: You ought to just be able to use [a] instead of CList a
12:35:27 <Tuplanolla> Is there something for collecting monadic actions? Something like (Monad m, Traversable t) => m (Maybe a) -> m (t a) or perhaps (Monad m, Traversable t) => (a -> Bool) -> m a -> m (t a).
12:36:01 <ReinH> Which is why we now call f g a b = g (a, b) Schönfinkeling
12:36:13 <ReinH> The More You Know
12:36:14 <SrPx> Cale: on haskell yes, maybe, but then I'd need scott lists on the λ-calculus view (I'm translating stuff from it) and I'm getting a lot of problems in making them work
12:36:22 <Cale> ReinH: Right, Schönfinkel was so named because he invented currying.
12:36:50 <SrPx> Scott lists are weird in that I can't write `foldr` for them without the Y-combinator or similar non-strong normalizing term
12:36:53 <voidzero> did he call it Schönfinkeling?
12:36:57 <sm> methinks I've tuned in to #haskell at a bad time :)
12:37:06 * sm very confused
12:37:17 <Cale> sm: We're being a bit silly
12:37:21 <orion> Hi. Why is it recommended to use throwIO instead of throw then in IO?
12:37:24 <sm> phew
12:37:33 <srhb> sm: Schönfinkel _probably_ invented currying before Haskell Curry. ;)
12:37:42 <Cale> orion: Because the *evaluation* of throw x will throw an exception.
12:37:50 <Rembane> Schönfinkling is an awesome verb.
12:37:53 <siwica> How can I find out that typeclasses a given type belongs to using ghci?
12:37:59 <srhb> :i type
12:38:06 <aweinstock> :t filterM
12:38:07 <lambdabot> Monad m => (a -> m Bool) -> [a] -> m [a]
12:38:13 <Cale> orion: Whereas what's usually important is the time at which the action is *executed*
12:38:59 <siwica> srhb: thanks!
12:39:25 <Cale> orion: If you throw exceptions from evaluation, it can be tricky to catch them reliably, because you have to ensure that the evaluation which produces the exception actually occurs during the execution of the relevant catch, which it may not, for various reasons.
12:39:57 <ski> SrPx : did you figure out `zipWith' by yourself ?
12:40:13 <SrPx> yes why
12:41:19 <ReinH> sm: what, you don't believe that Haskell was named after Moses Schönfinkel?
12:42:52 <ski> SrPx : it's nicer if you don't need `unsafeCoerce'. but i think it's nice that you managed to figure out intuitively how it ought to work
12:43:54 <SrPx> It was pretty simple in comparison, I have a lambda term that receives a λ-encoded first-class algebraic datatype and it returns to a zipWith definition for the respective scott-encoded ADT with that type. So you can write: "list_zip = derive_zip (List *)"
12:43:57 <SrPx> that was hard
12:44:08 <SrPx> I wish more people cared about the untyped λ-calculus so I could post that kind of stuff
12:44:33 <ski> SrPx : years ago, i figured out the same thing, if you're interested <http://lpaste.net/47814>
12:44:59 <ski> (that doesn't use `unsafeCoerce')
12:45:07 <SrPx> wow
12:45:27 <SrPx> Why didn't you tell me that when I was asking like crazy? That is awesome
12:45:38 <ski> when were you asking like crazy ?
12:45:42 <ski> i muse have missed that
12:45:48 <ski> s/muse/must/
12:45:57 <ReinH> ski: unacceptable
12:46:06 <ski> ReinH : which ?
12:46:33 <SrPx> ski: http://stackoverflow.com/questions/29879944/why-haskell-doesnt-accept-my-combinatoric-zip-definition
12:46:37 <ReinH> ski: not paying attention to #haskell 24/7/365
12:46:47 <ski> oh
12:46:52 * ski hangs head in shame
12:46:58 <SrPx> there is also a follow-up question, some people spent some time trying to figure it out
12:47:52 <ReinH> ski: oh, Oleg did it. Of course.
12:48:01 <SrPx> Oleg didn't do it
12:48:23 <SrPx> it was different
12:48:28 <SrPx> I believe
12:48:36 <SrPx> and quadratic
12:50:29 <SrPx> I envy you, in 2007 I was in middle school
12:50:44 <ski> SrPx : anyway, i seldom look at SO posts
12:50:51 <SrPx> trying to understand bhaskara's formula lol
12:54:52 <orion> Cale: Ah ok. That makes sense. Thanks!
12:55:45 <SrPx> What the heck
12:55:53 <ski> SrPx : anyway, the intuition of `zipWith' here is of two coroutines, passing their suspended state (the "baton", if you will) to the other when yielding to it, until one of the lists end (at which point the remaining state of the other coroutine is discarded)
12:55:58 <SrPx> Running some code with runhaskell works
12:56:06 <SrPx> Compiling it gives me an error
12:56:08 <SrPx> whyyyyy
12:56:43 <t7> coz haskell
12:56:46 <t7> no why
12:56:56 <Welkin> isn't runhaskell just like running in ghci?
12:57:26 <SrPx> ski: yep! :) The same like of thought can be used to easily define `min/max` for church numbers (which I couldn't find online at least), as well as a more efficient sub (the one you find around is `sub n x = n pred x` which is mad slow
12:57:51 <SrPx> and also a total O(N) sort function for church lists
12:58:25 <geekosaur> runhaskell isn't quite exactly like compiling, nor quite exactly like running in ghci
12:58:44 <shachaf> It's very close to running in ghci.
12:58:54 <SrPx> list of who asked: 
12:58:56 <SrPx> > filter even [1,3..300]
12:58:58 <lambdabot>  []
13:00:09 <SrPx> Compiling it without -O2 works too, wtf
13:00:43 <monochrom> we need more positive statements here! Examples: ...
13:01:24 <monochrom> Example 1: runhaskell is quite like ghci, in that it interprets
13:01:40 <monochrom> Example 2: runhaskell is quite like compiling, in that you don't issue ghci commands
13:01:45 <monochrom> (end of joke)
13:02:25 <monochrom> P.S. apple is quite like orange!
13:02:26 <zipper> When I set an environment variable with setEnv I can't get other programs called by that program to read the environment variable. What could be the issue?
13:02:51 <zipper> System.Environment.setEnv
13:03:28 <zipper> or could it be laziness causing the environment varianle to not be set?
13:03:36 <xplat> maybe they are being called by execve with an explicit environment?
13:03:41 <mauke> zipper: do you have a test case?
13:03:52 <monochrom> do you have a minimal self-contained demo so other people can reproduce the problem?
13:04:02 <xplat> laziness could only make it not be set if it is in unsafePerformIO or something
13:04:31 <Sindriav_> Why can't I deduce "Constraint c" in "Constraint c => [c]" for "[]" ?
13:04:37 <monochrom> and yeah, when it comes to IO, laziness is rarely relevant. IO actions are rarely lazy.
13:04:46 <SrPx> Is there any reason not to include a method on the "class" definition when it can be optimized for a specific type?
13:05:32 <xplat> SrPx: it bloats the dictionary and usually requires extra laws to relate it to the other methods
13:05:45 <SrPx> ah
13:05:57 <SrPx> that means a runtime penalty right?
13:06:01 <xplat> (will need extra tests etc)
13:06:02 <quchen> SrPx: It can dilute the class a lot, see Foldable, which is a kitchen sink of folding functions
13:06:05 <zipper> I have a very good situation in which it is failing. Let me show you. Too bad it's a whole project on github
13:06:43 <mauke> ghc -e 'System.Posix.Env.setEnv "blurb" "flabble" True >> System.Process.system "echo $blurb"'
13:06:46 <mauke> wfm
13:06:56 <xplat> the runtime penalty is usually small, but it can be large if you are using deeply nested structures or nested-recursive structures, or of course if you have ten billion methods
13:07:06 <monochrom> well yeah that's going to be 10000 moving parts therefore every hypothesis you think up has 0.01% probability of being true.
13:07:38 <Sindriav_> mauke: TIL there's -e for GHC
13:07:49 <xplat> it can be well worth it if the optimization potential is significant
13:08:06 <xplat> Sindriav_: oddly, runghc doesn't have -e
13:08:39 <xplat> i would have thought runghc would be the one that had it
13:08:49 <Sindriav_> xplat: That's not that surprising. I've always though of runghc as sort of a helper to ghc
13:08:56 <zipper> mauke: I am using setEnv from System.Envrironment not System.Posix.Env
13:09:05 <zipper> To make it more cross platform
13:09:27 <Sindriav_> xplat: I mean, I see where you're going, but it makes more sense in GHC, imo. That way it stays contained in one command
13:09:28 <xplat> Sindriav_: i made the mistake of thinking of it as 'haskell as a scripting language', which would be the obvious place to put -e
13:09:54 <monochrom> ghc -e 'System.Environment.setEnv "blurb" "flabble" >> System.Process.system "echo $blurb"'
13:09:59 <monochrom> that still works for me
13:10:02 <Sindriav_> xplat: Yeah. I've always thought of is as an alias for "ghc $1 && ./$1"
13:10:20 <Sindriav_> xplat: + rm all the files
13:10:58 <Sindriav_> Anyways, why can't I pass `[]` as `(Constraint c) => [(String, c)]` ?
13:12:17 <xplat> Sindriav_: you need to either have Constraint c in the environment or instance Constraint c {- a universal instance -} if it's just a bare c like that
13:12:20 <SrPx> (can someone confirm if typeclass dictionaries cause a runtime penalty or ir they are eliminated on compile time)
13:12:44 <Sindriav_> xplat: I do have it in the environment… I'll paste the code
13:12:49 <bennofs> SrPx: depends on use case. they're often eliminated though, iirc
13:13:09 <SrPx> is there any resource stating when it isn't
13:13:14 <Sindriav_> xplat: http://lpaste.net/2853744574050861056
13:13:39 <xplat> they tend to be eliminated when you use them at concrete arguments
13:14:03 <xplat> where the instance in use can be determined at compile time
13:14:05 <glguy> Sindriav_: You're probably getting an ambiguous type error, You can use [] in the position , but you hvae to tell it what the type is
13:14:29 <Sindriav_> glguy: Huh. Why doesn't the typechecker do this?
13:14:52 <Sindriav_> Oh, wait, I guess I see why
13:14:54 <glguy> Because it's ambiguous, it has no way to know what you meant for 'u' to be
13:15:01 <Sindriav_> Urg
13:15:22 <xplat> with extended defaulting it could become (), but that's probably not what you want
13:21:00 <SrPx> How do I inline a typeclass method? That is there are many methods with the same name. Do I just add the pragma below class, or below the instance?
13:22:51 <jle`> SrPx: you inline the method with the method name when you define it in the instance
13:23:02 <SrPx> thanks jle` 
13:23:22 <jle`> the indent level is anywhere where a type signature for that method would make sense
13:23:27 <jle`> syntactically
13:23:44 <Tuplanolla> I wrote this thing, but I don't know how to name it. Any suggestions? The type is (Monad m, Applicative f, Monoid (f a)) => (a -> Bool) -> m a -> m (f a) and it can be called with (/= '.') getChar to read a sentence for example.
13:24:32 <jle`> Tuplanolla: what's the source?  it looks like it might be a library function
13:25:01 <shachaf> You're using pure and (<>)?
13:25:16 <shachaf> Why not just (a -> Bool) -> m a -> m [a]?
13:25:23 <lpaste_> Tuplanolla pasted “somethingWhileM” at http://lpaste.net/139297
13:25:36 <hpc> . o O ( (<>) = getLine )
13:26:22 <shachaf> Oh, and mempty.
13:26:36 <davik> quick question, how do I find the bitwise xor of 5 and 6, I tried import Data.Bits and 5 xor 6 and that didn't work
13:26:36 <jle`> any reason why you're using fix instead of normal readable recursion, heh
13:26:46 <jle`> davik: what does "didn't work" mean?
13:26:50 <shachaf> Something which has mappend, mempty, and pure sounds like a free monoid, i.e. []
13:26:55 <glguy> davean: You have to use   `xor`  to use it infix like that
13:27:07 <davik> says type ambiguous
13:27:10 <davik> oh
13:27:12 <davik> duh
13:27:12 <Tuplanolla> I like doing that to avoid naming things, jle`.
13:27:20 <jle`> Tuplanolla: you name it already, though
13:27:27 <jle`> you actually introduce an extra name, heh
13:27:35 <jle`> without fix you wouldn't need `againWith`
13:27:36 <Tuplanolla> Perhaps, but it's always the same.
13:29:17 <jle`> mhm.  but in haskell "the same" can be surprisingly more complex and unreadble and verbose than the simpler clean readble version :)
13:33:16 <SrPx> where can I see the infix declarations for the +, *, / etc operators
13:33:59 <zoug> :t (+)
13:34:01 <lambdabot> Num a => a -> a -> a
13:34:13 <SrPx> ski: is it possible to use your zip definition to get foldr/build to work with zip? After all AFAIK GHC doesn't fuse zips for lists specifically
13:34:27 <SrPx> only vectors
13:35:32 <ReinH> SrPx: in the source on hackage
13:35:49 <ReinH> SrPx: and also with :info in ghci
13:38:48 <SrPx> ah ok
13:49:35 * hackagebot smsaero 0.1 - SMSAero API and HTTP client based on servant library.  https://hackage.haskell.org/package/smsaero-0.1 (NickolayKudasov)
13:50:14 <BlackCap> :t (+)
13:50:16 <lambdabot> Num a => a -> a -> a
13:50:27 <BlackCap> that's a pretty neat feature :3
13:50:53 <BlackCap> :t (map $ chr.pred.ord)
13:50:55 <lambdabot> [Char] -> [Char]
13:53:21 <BlackCap> > map (chr.pred.ord) "hello, world"
13:53:22 <lambdabot>  "gdkkn+\USvnqkc"
13:54:36 <monochrom> eh, "unit separator"? :)
13:55:44 <BlackCap> @djinn (a -> b) -> [a] -> [b]
13:55:44 <lambdabot> Error: Undefined type []
13:56:45 <hexagoxel> :exf "(a -> b) -> [a] -> [b]"
13:56:46 <exferenceBot> fmap
13:57:43 <BlackCap> @hoogle (a -> b) -> [a] -> [b]
13:57:44 <lambdabot> Prelude map :: (a -> b) -> [a] -> [b]
13:57:44 <lambdabot> Data.List map :: (a -> b) -> [a] -> [b]
13:57:44 <lambdabot> Control.Parallel.Strategies parMap :: Strategy b -> (a -> b) -> [a] -> [b]
14:09:36 * hackagebot hunch 0.1.0 - CSS-like syntax for file system manipulation.  https://hackage.haskell.org/package/hunch-0.1.0 (loganbraga)
14:12:36 <SrPx> So you leave a simulation running for weeks in order to determine what is the combination of cards that give you the fastest deck
14:13:03 <SrPx> Only so, when you start getting great results, one of the main cards your simulation picked is banned
14:13:03 <SrPx> fml
14:14:36 * hackagebot cabal-bounds 1.0.0 - A command line program for managing the bounds/versions of the dependencies in a cabal file.  https://hackage.haskell.org/package/cabal-bounds-1.0.0 (DanielTrstenjak)
14:14:36 <BlackCap> auch :/
14:17:50 <ril> is there anything like Show/Read for data that can be represented as an int, double or rational?
14:18:26 <Lokathor> it can be any of the three?
14:18:29 <ril> no no
14:18:35 <ril> one or the other
14:18:41 <ril> like say I have phantom rational types for dollars and euros
14:19:05 <Lokathor> well you can use (read "1" :: Int)
14:19:08 <Lokathor> and get 1 as an int
14:19:22 <ril> but I want a method to extract a unitless representation for serialization
14:19:55 <Lokathor> well i think they've all already got Read and Show instances
14:20:14 <Lokathor> typically Read should be able to read whatever Show decides to put out, if a type has both
14:20:40 <ril> but Read is String -> a and Show is always a -> String
14:20:57 <Lokathor> right, the a is picked depending on the type constraint of the rest of the expression
14:21:17 <ril> I guess I'm looking for a higher order read/show that could be parameterized
14:21:26 <ril> ReadFloat, ReadInt, ReadRational
14:21:53 <fvgvxmpv1> :t (read :: String -> Int)
14:21:55 <lambdabot> String -> Int
14:21:57 <quchen> Show comes with the law that stuff generated by it should be valid Haskell, it's not for prettyprinting. Integers are not valid Haskell, since source files contain characters, not numbers. So I don't think a direct analogon is useful.
14:21:59 <Lokathor> read can already do that is what i'm saying
14:22:21 <fvgvxmpv1> your readInt is just (read :: String -> Int)
14:22:40 <monochrom> use types to specify which "read" you want
14:22:43 <ril> mm, I see
14:22:44 <Tuplanolla> I have an idea.
14:22:51 <quchen> I think he means "class Readable input a where read' :: input -> a".
14:22:59 <quchen> And similarly for Showable.
14:23:39 <Tuplanolla> > data Like = Doublike Double | Intlike Int deriving Show
14:23:40 <lambdabot>  <hint>:1:1: parse error on input ‘data’
14:23:56 <Tuplanolla> How do you drive this thing?
14:24:03 <Lokathor> quchen, what do you mean "intergers are not valid haskell"?
14:24:29 <ril> my practical goal is to extend Persistent's derivePersistField to allow currency values to be serialized and deserialized to a database in a type-safe way
14:25:28 <ril> derivePersistField will use "read" and "show" to persist and rehydrate the stringified representation
14:25:29 <quchen> Lokathor: Well, you can't write integers in your Haskell source file. You can write characters that represent integers. So if you have "Show should produce pasteable Haskell that comes close to the thing shown" you can't do that with an integer representation, really. You'd have to print something like "fromMyShownInteger 123" which is not an integer.
14:25:30 <Lokathor> ril, does the database have info in it about what currency type a value is? or does it just have a double like 13.5 and you have to know some other way?
14:26:10 <Lokathor> > read (show (1 :: Int)) :: Int
14:26:12 <lambdabot>  1
14:26:40 <Tuplanolla> How do you define a data type for lambdabot?
14:26:43 <ril> I would use a second column for the unit
14:26:43 <fosterite> :t show . read
14:26:44 <lambdabot> String -> String
14:26:53 <quchen> ?let data Foo = Foo Int
14:26:56 <lambdabot>  Defined.
14:26:57 <quchen> :t Foo
14:26:59 <lambdabot> Int -> Foo
14:27:02 <quchen> Tuplanolla: ^
14:27:32 <quchen> Lokathor: What I'm trying to say is that the "roundtrip" with read/show for things other than strings is hard to accomplish.
14:27:56 <BlackCap> > Foo 2
14:27:57 <Lokathor> ril, my inclination would be to have your haskell data types match what your tables are storing, if possible. But I haven't used DBs in haskell so I dunno how well that holds up
14:27:58 <lambdabot>      No instance for (Show Foo)
14:27:58 <lambdabot>        arising from a use of ‘show_M619512603241353804013876’
14:27:58 <lambdabot>      In the expression:
14:28:03 <Tuplanolla> Does the same apply to values, quchen?
14:28:10 <Lokathor> i know that works well in java is all
14:28:23 <ril> I don't have a sophisticated plan either; I'm sort of trying to use Persist as an additional layer of type safety over SQL column types
14:28:36 <ril> but I would like to fall back on SQL's native types whenever possible rather than using strings
14:28:44 <quchen> Tuplanolla: Yes, both values and types are defined via "let" in Lambdabot.
14:28:50 <quchen> ?let foo = 1+1
14:28:52 <lambdabot>  Defined.
14:28:53 <quchen> > foo
14:28:54 <lambdabot>  2
14:28:57 <quchen> ?undef
14:28:57 <lambdabot> Undefined.
14:29:04 <Tuplanolla> ?let data Like = Doublike Double | Intlike Int deriving Show
14:29:05 <Tuplanolla> ?let f x = Intlike <$> readMaybe x <|> Doublike <$> readMaybe x
14:29:05 <Tuplanolla> [f "42.0", f "42"] -- This should do, Lokathor.
14:29:06 <lambdabot>  Defined.
14:29:07 <lambdabot>  .L.hs:152:19: Not in scope: ‘readMaybe’
14:29:07 <lambdabot>  
14:29:07 <lambdabot>  .L.hs:152:48: Not in scope: ‘readMaybe’
14:29:33 <zipper> Heh I'm having a small issue. When it comes to reverse proxying. One side is the destination and the other is the?
14:29:37 * hackagebot smsaero 0.1.1 - SMSAero API and HTTP client based on servant library.  https://hackage.haskell.org/package/smsaero-0.1.1 (NickolayKudasov)
14:29:38 <zipper> source?
14:29:44 <ril> Persistent will translate Haskell's numeric types intelligently ( https://github.com/yesodweb/persistent/wiki/Persistent-entity-syntax#conversion-table-migrations )
14:29:54 <zipper> Too sleepy to english right now :(
14:29:57 <ril> but if you want to use a custom type, it always gets stored as a String, even if it has interpretably numeric content
14:30:03 <Tuplanolla> Of course readMaybe from Text.Read wasn't imported there.
14:30:23 <arkeet> @let import Text.Read
14:30:24 <lambdabot>  Defined.
14:30:25 <arkeet> :t readMaybe
14:30:27 <lambdabot> Read a => String -> Maybe a
14:31:25 <ril> I suppose that's just as well in some ways - if the type information is safety-critical, it would be wrong to use SQL's mathematical operators in a type-blind way
14:31:41 <quchen> zipper: Client server source sink destination origin
14:31:52 <quchen> There, all the pipe-y words :-)
14:32:05 <ril> even if doing so would have desirable performance characteristics
14:32:19 <zipper> quchen: Thanks :)
14:32:19 <Tuplanolla> Also "peer" for when you don't know.
14:32:43 <Tuplanolla> There should be a dictionary of technical synonyms and antonyms somewhere. That'd save so much time.
14:33:06 <BlackCap> > putStr "Can lambdabot do IO actions?"
14:33:08 <lambdabot>  <IO ()>
14:33:38 <quchen> Tuplanolla: #haskell is that dictionary. It's also lazy: the dictionary only contains stuff you ask about.
14:33:53 <ril> thanks everyone
14:34:20 <cocreature> but you share the state with all other threads where one thread consists of the questions of one person
14:35:44 <consus> Hi guys
14:35:56 <BlackCap> Hi
14:35:57 <quchen> cocreature: The history is immutable so that's covered as well.
14:36:13 <consus> POSIX.IO contains pread call that allows caller to read with offset from an FD concurently. Is there something similar for Handle?
14:37:16 <Eduard_Munteanu> consus, you can get a Fd from a Handle
14:37:40 <Eduard_Munteanu> @hoogle handleToFd
14:37:40 <lambdabot> System.Posix.IO.ByteString handleToFd :: Handle -> IO Fd
14:37:40 <lambdabot> System.Posix.IO handleToFd :: Handle -> IO Fd
14:38:24 <consus> Hm... Well, that's an option. But do POSIX.IO works on non-POSIX like systems?
14:40:05 <saml> types are always after ::, right?  types aren't involved in actual expression
14:40:39 <Eduard_Munteanu> saml, yes
14:40:44 <saml> thanks
14:42:28 <Lokathor> saml, note that you can use ( ) around a typed expression to fit it inside a larger expression: (1 :: Int) + 2
14:42:44 <saml> ah right
14:49:42 <ski> saml : types also occur in other contexts. e.g. in `type MyType = ...', `...' is a type expression
14:50:01 <saml> ah true
14:50:32 <ski> in `(1 :: Int) + 2', the `1 :: Int' part is a(n expression) type ascription
14:51:08 <ski> in `not :: Bool -> Bool; not False = True; not True = False', `not :: Bool -> Bool' is a type signature
14:51:55 <ski> (there's also type ascriptions in patterns, like `foo (x :: Blah) ;; Bleh = ...' or `do x :: Blah <- ...; ...')
14:52:11 <ski> (er, s/;;/::/)
14:53:37 <GLM> Is there a way to have a default implementation for a function in a typeclass?
14:53:48 <arkeet> yes
14:53:51 <arkeet> just write it 
14:53:56 <arkeet> in the class
14:54:29 <arkeet> example https://hackage.haskell.org/package/base-4.8.1.0/docs/src/GHC.Base.html#Monad
14:54:39 <Welkin> the default implementation for (==) in Eq is (==) = (/=)
14:54:48 <Welkin> gues how (/=) is defined? :)
14:55:04 <Welkin> er
14:55:08 <arkeet> I wonder if anyone defines /= without defining ==
14:58:01 * ski hands Welkin a negation
14:58:45 <Welkin> yes
14:58:54 <Welkin> actually
14:58:59 <Welkin> I can't even find the source for Eq
14:59:01 <Welkin> O.o
14:59:03 <Welkin> wtf
14:59:28 <Welkin> no source links in the docs
14:59:36 <Welkin> and Data.Eq only imports GHC.Base
15:01:36 <bob_twinkles> Welkin: http://community.haskell.org/~simonmar/base/src/GHC-Classes.html
15:02:16 <bob_twinkles> GHC.Base rexports GHC.Classes, which has a bunch of the prelude classes in it
15:02:34 <Welkin> anyway: http://book.realworldhaskell.org/read/using-typeclasses.html#id603255
15:03:24 <Welkin> thanks bob_twinkles 
15:03:30 <ecognium> Hi everyone, hopefully an easy question.  I am using `persistent` to store some UTCTime data in Sqlite. It is stored as `2015-08-12T22:22:00.000Z`. I am writing some tests and want to be able to convert an UTCTime to that format. If I just do show, it gives me `2015-08-12 22:22:00 UTC`. Looking at the persistent code, I am not sure how this string representation is obtained.   
15:03:33 <Welkin> sometimes I run into issues like that with the haddocks
15:03:46 <Welkin> I wish it wasn't so difficult to find the source for these things
15:03:46 <bob_twinkles> heh, I had to use google-fu to find that =P
15:04:21 <bob_twinkles> finding implementations for Prelude stuff seems to be weird in general
15:04:24 <Lokathor> ecognium, you might need to write your own function for conversion to string
15:04:30 <Welkin> ecognium: you can convert to any format you want using the Calender module
15:04:32 <Tuplanolla> I just reinstalled everything with documentation, but I'm still missing GHC.Base.
15:05:06 <kadoban> ecognium: Is it just using the Show instance of UTCTime probably?
15:05:21 <Welkin> er
15:05:23 <Welkin> https://hackage.haskell.org/package/time-1.5.0.1/docs/Data-Time-Format.html
15:05:26 <Welkin> I meant Time
15:05:45 <fragamus> I have been writing some java code and I yearn for haskell
15:07:04 <ecognium> Welkin: Thanks. Let me try to figure out which format maps to the string I am getting back from persistent. kadoban: show seems to be giving me a different string representation. In the persistent source code it looks like it is using show but i cannot really tell with all the wrappers
15:11:07 <kadoban> Anyone know an example package I can look at for the correct CPP code for making a GHC 7.8/7.10 import list without errors/warnings?
15:12:17 <Chobbes> How do you get stack to use a local version of a package? I've added the directory to the package: section of stack.yaml, and stack build causes it to build, but the function I added isn't there?
15:12:57 <SrPx> How do I write an instance for a class? That is, I want to make every vector type (using Data.Vector.Generic) also an instance of ListIsomorphic
15:13:26 <Welkin> SrPx: template haskell?
15:14:16 <serendependy> Can't you just do instace Foo a => instance Bar a ?
15:14:32 <serendependy> * Can't you just do instace Foo a => Bar a ?
15:14:39 * hackagebot language-nix 1.0 - Haskell AST and Parsers for the Nix language  https://hackage.haskell.org/package/language-nix-1.0 (PeterSimons)
15:15:13 <SrPx> That is what I mean, but how? http://lpaste.net/139300
15:16:30 <Chobbes> SrPx: Vector has two parameters?
15:16:30 <serendependy> SrPx, It looks like you're missing a type argument to V.Vector
15:16:53 <SrPx> yes that is the point, if I add "V.Vector v a" then the other side doesn't match
15:20:13 <ecognium> Welkin: I cannot figure out which format maps to `2015-08-12T22:22:00.000Z`. I tried `formatTime defaultTimeLocale "%Y-%m-%dT%H:%M:%S" d` and it gives me "2015-08-12T22:22:00" (I cannot get .000Z) -- I can manually add it but worried things may break if I switch DBs. I searched the Persistent repo for formatTime but saw only one hit and that format does not give me the same value.
15:20:35 <serendependy> SrPx, GHC complains about the two sides not matching?
15:21:30 <SrPx> It says: "Variable ‘a’ occurs more often than in the instance head       in the constraint: V.Vector v a"
15:22:04 <ecognium> Welkin: `formatTime defaultTimeLocale "%Y-%m-%dT%H:%M:%S0Z" d` does it. Thanks! 
15:22:20 <SrPx> Changing "ListIso v" to "ListIso v a" or "ListIso (v a)" doesn't work too (and doesn't really make sense)
15:23:18 <kadoban> What base version corresponds to GHC 7.10 again? Is that 4.8.0.0 ?
15:23:30 <Chobbes> kadoban: yes.
15:23:34 <kadoban> Thanks
15:23:36 <Chobbes> SrPx: https://wiki.haskell.org/Multi-parameter_type_class ?
15:23:39 <SrPx> It is like GHC expects a complete constraint before the `=>`, but I can't give it
15:24:12 <mpickering> SrPx you realise that if that does compile then you are going to overlap with every other instance?
15:24:24 <athan> What's the more general version of `zipWith`? Something from BiFoldable, maybe?
15:24:31 <SrPx> mpickering: what do you mean?
15:25:10 <athan> hrm
15:25:20 <mpickering> As v is just a type variable then it matches every type right? 
15:25:28 <SrPx> athan: the one I posted on reddit :v
15:25:36 <athan> SrPx: :OOOOOO show meeeee
15:26:08 <SrPx> athan: ah it is around there... but I remember Lens had something
15:26:22 <jle`> athan: general in what way?
15:26:32 <mpickering> athan: generalize in what sense
15:26:51 <athan> jle`: Shouldn't it be possible with an Applicative and Foldable instance?
15:27:01 <jle`> you can have it work with functions of multiple arity by defining zipAp = zipWith ($)
15:27:10 <SrPx> I think he means he is writing a function that uses zipWith and he wants it to be generic
15:27:12 <athan> `zipWith :: (Foldable f, Applicative f) => (a -> b -> c) -> f a -> f b -> f c
15:27:13 <athan> `
15:27:17 <jle`> so you can merge together zipWith3, zipWith4, etc.
15:27:41 <jle`> oh i see
15:27:43 <athan> jle`: That's interesting! I haven't seen that before
15:27:50 <athan> I'm just trying to see how I could break it out of lists
15:28:22 <athan> wait
15:28:24 <athan> derp
15:28:25 <athan> thank you
15:28:55 <jle`> :t liftA2 -- might do what you wat
15:28:56 <athan> that signature just looks like liftM2. Is there a general version of ZipList, then?
15:28:56 <lambdabot> Applicative f => (a -> b -> c) -> f a -> f b -> f c
15:29:09 <athan> to get the parallel and not cartesian instance?
15:29:11 <jle`> zippy behavior depends on the Applicative instance
15:29:16 <jle`> well, it depends on the type
15:29:25 <athan> jle`: hm
15:29:37 <jle`> what type are you thinking of using it on??
15:29:40 <jle`> *?
15:29:55 <jle`> for the vector types in linear, for example, all of the instances are zippy
15:30:15 <athan> jle`: Lots - `Map k`, `Set`, etc
15:30:23 <athan> hmm!
15:30:37 <SrPx> This? http://comonad.com/reader/2008/zipping-and-unzipping-functors/
15:30:41 <jle`> Map k and Set probably won't work with most of the major palyers because they require constraints
15:30:41 <athan> okay! I think I just need to dive into zippyness for a while
15:31:01 <athan> hmm, okay. Thanks jle`.
15:31:08 <athan> Thank you SrPx :)
15:34:35 <broma0> Can anyone think of an elegant way to transform 'Map (Text, Text) Text' into 'Map Text (Map Text Text)'? 
15:35:00 <broma0> sort of unfolding the tuple into another map layer
15:36:28 <benzrf> interesting, broma0
15:36:49 <ski> hm, currying a finite map
15:36:57 <benzrf> ski: ha nice
15:36:57 <broma0> its a cool problem 
15:37:01 <benzrf> perhaps a fold
15:37:10 <benzrf> cant think of anything particularly pleasant off the top of my head tho
15:37:15 <glguy> demo m 07= Map.fromListWith Map.union [ (a, Map.singleton b c) 07| ((a,b),c) 07<- Map.toList m ]
15:37:49 <broma0> > let f m = Map.fromListWith Map.union [ (a, Map.singleton b c) | ((a,b),c) <- Map.toList m ]
15:37:49 <Welkin> COLORS?
15:37:50 <lambdabot>  <no location info>:
15:37:50 <lambdabot>      not an expression: ‘let f m = Map.fromListWith Map.union [ (a, Map.singl...
15:37:57 <broma0> how does that work anyway..
15:38:31 <ski> @let demo m = Map.fromListWith Map.union [ (a, Map.singleton b c) | ((a,b),c) <- Map.toList m ]
15:38:32 <lambdabot>  .L.hs:154:5:
15:38:32 <lambdabot>      Not in scope: ‘Map.fromListWith’
15:38:32 <lambdabot>      Perhaps you meant one of these:
15:38:43 <glguy> I think lambdabot has it as "M"
15:38:49 <ski> hm, yes
15:39:02 <broma0> > let f m = M.fromListWith M.union [ (a, M.singleton b c) | ((a,b),c) <- M.toList m ]
15:39:03 <lambdabot>  <no location info>:
15:39:04 <lambdabot>      not an expression: ‘let f m = M.fromListWith M.union [ (a, M.singleton b...
15:39:25 <ski> no `> ' for a (more) persistent binding, use `@let'
15:39:46 <ski> (also, don't name it `f')
15:40:23 <Welkin> lol
15:40:32 <Welkin> name it icanhazcheezburger
15:40:52 <broma0> @let icanhazcheezburger m = M.fromListWith M.union [ (a, M.singleton b c) | ((a,b),c) <- M.toList m ]
15:40:54 <lambdabot>  Defined.
15:40:55 <glguy> 07< demo (Map.fromList [ ((0410,0420), 0430), ((0410,045),046), ((047,048),049) ])
15:40:57 <glguy> fromList [(047,fromList [(048,049)]),(0410,fromList [(045,046),(0420,0430)])]
15:41:14 <Welkin> glguy: you are bleeding colors D:
15:42:40 <broma0> thank you!
15:47:10 <ski> @let broma0 = M.foldrWithKey (\(k0,k1) v -> M.insertWith M.union k0 (M.singleton k1 v)) M.empty
15:47:12 <lambdabot>  Defined.
15:47:33 <ski> > broma0 (M.fromList [((10,20),30),((10,5),6),((7,8),9)])
15:47:35 <lambdabot>  fromList [(7,fromList [(8,9)]),(10,fromList [(5,6),(20,30)])]
15:48:00 <jle`> class Curryable r where curry :: r (a, b) c -> r a (r b c)
15:48:43 <jle`> pretend we don't need the Ord constraint >_>
15:50:47 <ski> @type M.foldrWithKey (uncurry (.) . (M.insertWith M.union *** M.singleton)) M.empty
15:50:48 <lambdabot> (Ord b, Ord b') => M.Map (b, b') a -> M.Map b (M.Map b' a)
15:53:16 <broma0> ski: thats a cool one
15:57:53 <Sindriava> How should I handle default values for data types?
16:00:36 <mpickering> in what sense? 
16:00:50 <mpickering> Do you ask whether you should use the Default typeclass or not?
16:01:17 <mpickering> "best practice" seems to be to write defaultFoo = ...
16:01:30 <Welkin> Sindriava: make a function that constructs it with the default
16:01:41 <Sindriava> mpickering: I wasn't aware there's a `Default` typeclass. I have a structure AppConfig, that I'm using a ReaderT to read in my app
16:02:14 <Sindriava> mpickering: Right now, I construct the value manually in `main`, but it feels smelly that i'm defining it someplace else than App.hs
16:02:50 <mpickering> right just write a function which is called "defaultAppConfig :: _ -> AppConfig"
16:02:59 <mpickering> with whatever initialisation parameters you need
16:03:10 <glguy> Sindriava: You just define some: defaultAppConfig :: AppConfig. If you define it as a record you can then use it later like: defaultAppConfig { customizedField = customValue }
16:03:20 <Sindriava> mpickering: Great, thanks ^^
16:03:35 <Sindriava> What's the Default typeclass used for?
16:03:41 <glguy> making a mess
16:04:54 <lspitzner> the default Int is 42 i assume?
16:10:15 <Sindriava> lspitzner: Making it 0 would make it remotely useful. 42 is just an easter egg
16:10:39 <Sindriava> Well, that certainly cleared up some duplicit imports. Thanks, mpickering!
16:10:48 <ski> in Cryptol, there's `zero :: a'
16:15:55 <jle`> can i no-monomorphism-restriction a single binding
16:16:37 <Welkin> jle`: maybe put it in its own module?
16:24:42 * hackagebot diplomacy-server 0.1.0.0 - Play Diplomacy over HTTP  https://hackage.haskell.org/package/diplomacy-server-0.1.0.0 (alexvieth)
16:32:58 <broma0> Is there a sequence-like thing for sets? i have an 's :: Set Text' and id like to 'sequence $ fmap monadicAction s)'
16:33:27 <jle`> broma0: yeah, it's called sequence
16:33:41 <broma0> jle`: ha, really? it works for any functor?
16:33:57 <jle`> oh :(
16:34:02 <broma0> traversable.
16:34:14 <jle`> there's no Traversable instance
16:34:18 <jle`> i forgot, heh
16:34:20 <jle`> well, you can sequence_ :)
16:34:24 <mniip> set is not traversable?
16:34:45 <mniip> ah, makes sense
16:34:45 <shachaf> Not even Functor.
16:34:49 <mniip> too many invariants
16:36:06 <jle`> i guess the best way is just fromList . mapM f . toList :|
16:36:08 <broma0> sounds like i have to bite the bullet with Set.toList
16:36:12 <broma0> bleh
16:36:29 <jle`> um
16:36:45 <jle`> fmap fromList . mapM f . toList
16:37:31 <jle`> but yeah, if you don't care about th rsults, you can use sequence_
16:39:04 <jle`> and also mapM_
16:39:42 * hackagebot cabal-debian 4.31.2 - Create a Debianization for a Cabal package  https://hackage.haskell.org/package/cabal-debian-4.31.2 (DavidFox)
17:10:37 <dmiles_afk> https://www.livecoding.tv/kritzcreek/
17:10:42 <dmiles_afk> Haskell coding stream
17:11:21 <mniip> >coding stream
17:15:49 <Sindriava> dmiles_afk: Appreciate the idea, but you might want to introduce the stream a little more
17:16:08 <Sindriava> dmiles_afk: Imagine a sports channel titled "People kicking a ball"
17:21:31 <Welkin> Sindriava: "People Kicked in the Balls"
17:24:05 <Sindriava> Welkin: That's too realistic
17:24:14 * Sindriava glares at american tv
17:25:59 <dmiles_afk> Sindriava: hehe
17:26:01 <Welkin> Sindriava: that is the only TV that exists in the movie Idiocracy
17:26:22 <Welkin> TV show*
17:27:38 <Sindriava> *the documentary Idiocracy
17:28:03 <Sindriava> Anyways, I fucked up. I need to rewrite a part of my API
17:28:07 <Sindriava> *cries*
17:30:14 <Sindriava> The guy who wrote this code was a retard, I swear to god
17:31:51 <Welkin> Sindriava: would that be you?
17:31:57 <Sindriava> ...
17:32:30 <Welkin> Sindriava: it is a serious question
17:33:01 <Sindriava> I can neither confirm or deny any details about any operation without the permission of the secretary.
17:34:44 * hackagebot yesod-test 1.4.4 - integration testing for WAI/Yesod Applications  https://hackage.haskell.org/package/yesod-test-1.4.4 (GregWeber)
17:35:17 <Sindriava> Welkin: … yes :D
17:49:45 * hackagebot yesod-test 1.5 - integration testing for WAI/Yesod Applications  https://hackage.haskell.org/package/yesod-test-1.5 (GregWeber)
17:56:36 <arian0n> any emacs users here who use ghc-mod? when I start it up, emacs hangs and all it says is "ghc-mod: unknown command: map-file", and google hasn't been helpful at all :<
18:04:07 <wailord> it's probably a problem with ghc-mod not emacs, try reading the source of the plugin
18:09:45 <arian0n> i think i found the issue, my ghc.el and my ghc-mod don't match
18:13:37 <jacksnipe> how do I install slack?
18:13:48 <jacksnipe> stack*
18:13:49 <jacksnipe> fuck
18:14:24 <dreams> is there a function that takes eg. [4,4,4] and return [[4],[4],[4]]?
18:14:36 <dramforever> :t (:[])
18:14:37 <lambdabot> a -> [a]
18:14:45 <dramforever> should give you a hint
18:14:54 <Welkin> how do I install fuck?
18:15:06 <dreams> dramforever: I'm looking for saturated one.
18:15:15 <dramforever> um...huh?
18:15:24 <dreams> yeah thats partial.
18:15:28 <dramforever> ok how much haskell have you learnt?
18:15:38 <Welkin> > map (:[]) [4,4,4]  -- dreams 
18:15:40 <lambdabot>  [[4],[4],[4]]
18:15:44 <dreams> dramforever: to be honest I just want to borrow the name.
18:15:55 <dramforever> hmm...borrow the name
18:15:59 <dreams> Welkin: that's partial application again.
18:16:02 <dramforever> that's really weird
18:16:02 <dreams> dramforever: heh yeah.
18:16:26 <dramforever> dreams: if you haven't you should really get used to this partial application thingy
18:16:32 <dreams> dramforever: I'm open for suggestion.
18:16:41 <Welkin> dreams: every single haskell function is partially applied... until it is fully applied
18:16:41 <dreams> dramforever: its not going to be in Haskell.
18:16:44 <Welkin> that is how it works
18:16:46 <defanor> > map return [4,4,4] :: [[Int]]
18:16:48 <lambdabot>  [[4],[4],[4]]
18:16:48 <dramforever> hmm......
18:17:15 <nolrai66> I wish return was called wrap or unit.
18:17:21 <nolrai66> Return is a terible name.
18:17:23 <srhb> nolrai66: It's called pure, not good enough?
18:17:28 <nolrai66> True..
18:17:29 <dramforever> we need a not-so-newbie haskell F.A.Q. in which the first question is "Is there a function for ...?"
18:17:30 <Welkin> > map pure [4,4,4]
18:17:31 <lambdabot>      No instance for (Show (f0 a0))
18:17:31 <lambdabot>        arising from a use of ‘show_M758851105598989369317349’
18:17:31 <lambdabot>      The type variables ‘f0’, ‘a0’ are ambiguous
18:17:32 <nolrai66> its okay.
18:17:47 <dramforever> > map pure [4,4,4] :: [[Int]]
18:17:48 <nolrai66> Huh.
18:17:48 <lambdabot>  [[4],[4],[4]]
18:17:49 <dreams> Welkin: no its not. That would be very inefficient, at the RTS all the arguments are on the stack and applied at once.
18:18:07 <srhb> dreams: Huh?
18:18:07 <dramforever> dreams: that's an optimization
18:18:15 <dreams> dramforever: that's also reality.
18:18:19 <dramforever> yep
18:18:36 <dramforever> in reality we run optimized programs
18:18:40 <srhb> Arguments on the stack what now?
18:18:49 <dramforever> srhb ++
18:18:52 <dramforever> stack?
18:19:05 <Welkin> dreams: who cares how it is implemented? All programs are just differences in voltage
18:19:15 <dramforever> dreams: there isn't a regular stack in the haskell runtime
18:19:15 <nolrai66> Its a compiler detail really.
18:19:22 <dramforever> compiler detail ++
18:19:32 <srhb> dreams: Are you talking about a call stack?
18:19:54 <dreams> dramforever: depends what you define regular. 
18:19:57 <mniip> hmm
18:20:07 <mniip> mtl misses a certain kind of feature...
18:20:09 <dramforever> dreams: a call stack as in many other languages
18:20:14 <nolrai66> I am fairly sure GHC does actually put arguments on the hardware stack.
18:20:18 <dramforever> hmm...we have similar names
18:20:21 <mniip> natural transformations on a specific part of the monad stack
18:20:23 <nolrai66> But I would have to reread..
18:21:10 <mniip> like for example if you have a transformer that is known to contain a MaybeT somewhere
18:21:27 <mniip> and you want to naturally transform that MaybeT into a ListT
18:21:41 <dramforever> dreams: your question is really a bit weird, I have to say
18:21:43 <mniip> does what I'm saying make sense :o
18:21:48 <dreams> dramforever: why do you think its different? :)
18:22:01 <dramforever> dreams: lazy evaluation
18:22:11 <dreams> dramforever: I'm just trying to come up with a decent name for the function.
18:22:14 <dramforever> there isn't even a notion of "returning" and "calling"
18:22:23 <srhb> dreams: mapToList
18:22:28 <dramforever> dreams: "decent name" yeah I know
18:22:48 <dreams> dramforever: so I thought why not steal other people's hard work.
18:23:04 <srhb> dreams: Well, the problem is that we don't tend to name such simple compositions. :P
18:23:13 <srhb> Since we can just talk about map return...
18:23:53 <dreams> dramforever: well yeah but jump is return in principle, also is continuations. I think of it the same, the only thing thats different is the context of the stack (that interleaving behaviour).
18:24:06 <dramforever> oh sure it is
18:24:56 <mniip> dreams, an STG machine has no concept of a call stack
18:25:05 <mniip> it however has a demand stack
18:25:16 <mniip> which is similar but different
18:25:42 <dramforever> just different names, different implementations, different semantics
18:25:49 <dreams> mniip: sure it has. a call (eg in non-strict context causes a stack-frame to be allocated).
18:26:22 <dramforever> dreams: s/stack-frame/thunk/
18:26:27 <nshepperd> just a completely different thing
18:26:39 <mniip> dreams, what's a call
18:26:46 <dreams> dramforever: a thunk in a stack-frame.
18:26:53 <dramforever> hmm...
18:26:53 <Welkin> there are no calls
18:27:03 <Welkin> the entire program is evaluated to a single IO action
18:27:06 <mniip> dreams, what exactly do you think is a call within the STG machine
18:27:15 <mniip> Welkin, IO is out of scope here
18:27:19 <dramforever> anyway I wonder if you accept that this isn't really the same as in other languages
18:27:22 <nshepperd> when you apply a function in ghc a thunk gets created on the heap
18:27:37 <dreams> mniip: any call to a function.
18:28:01 <mniip> dreams, that's not an explanation
18:28:16 <dreams> dramforever: its not the same context-wise, but the idea of the stack remains, with similar operations..etc.
18:28:36 <dramforever> dreams: we don't call functions, the whole program is just a big expression
18:28:48 <levi> People sure do have a lot of conflicting ideas about how GHC evaluates things.
18:29:20 <Welkin> levi: :D
18:29:27 <dreams> dramforever: operationally you do. a function is called (its value is demanded).
18:29:36 <mniip> function's value?
18:29:39 <dramforever> hmm...
18:29:51 <Welkin> I think this is a question for #ghc
18:30:08 <dramforever> dreams: weird but interesting...
18:30:18 <dreams> Welkin: no need, just look at the operational semantics of STG.
18:31:00 <Cale> "Call" is weird terminology for anyone who thinks about evaluation as graph reduction.
18:31:00 <nshepperd> dreams: that doesn't put anything on the stack
18:31:18 <nshepperd> unless it happens to be strict in some argument
18:31:41 <dreams> nshepperd: it depends! if its tail recursive I agree.
18:31:43 <nshepperd> in which case you go evaluate that first and then come back
18:31:45 <Cale> The STG machine is a little bit different from straight graph rewriting, but nevertheless, just thinking about everything in terms of graph rewriting works really well.
18:31:51 <nshepperd> dreams: no
18:31:56 <nshepperd> no tail recursion
18:32:03 <nshepperd> it's solely about strictness
18:32:18 <Cale> But yeah, regardless, there is no call stack
18:32:24 <Cale> There's an evaluation stack which is used
18:32:42 <dramforever> I'm starting to wonder
18:32:48 <Cale> but it doesn't quite line up with what you'd normally think of as a call stack, it would be better to call it a pattern matching stack or something
18:32:50 <dramforever> could we be talking about two different things?
18:32:54 <mniip> dreams, tail recursive?
18:33:00 <mniip> are you sure you're talking about STG?
18:33:26 <dreams> mniip: tail-call in general.
18:33:26 <dramforever> mniip ++
18:34:03 <Cale> "Tail-call optimisation" is a weird thing to talk about when expressions are evaluated outermost-first and there's no call stack.
18:34:10 <dramforever> dreams: what about this
18:34:11 <mniip> dreams, GHC doesn't have a concept of tail calls
18:34:20 <dramforever> dreams: describe the stack in your mind
18:34:53 <dramforever> let's check if we are arguing because we think two identical things are different
18:34:56 <dreams> Cale: yeah but we still have a stack.
18:35:21 <dramforever> dreams: can you describe the stack you're talking about a bit?
18:35:25 <Cale> Yeah, it's just that the stack is full of case expressions that are waiting for their scrutinee to be sufficiently evaluated to match a pattern, essentially.
18:35:27 <dramforever> what does it contain?
18:35:49 <Cale> At least, that's how I think of it :)
18:35:54 <dramforever> Cale ++
18:35:59 <mniip> Cale, too haskelly
18:36:06 <mniip> think about a stack of entered closures
18:36:21 <Cale> mniip: Well, what are those closures, and why did you enter them?
18:36:28 <mniip> the most common reason for entering a closure is, yes, pattern matching
18:36:34 <mniip> but there are other cases
18:36:42 <dramforever> mniip: like seq?
18:36:42 <Cale> mniip: They're the closures for expressions which are being evaluated because some case expression wants to match :)
18:36:48 <mniip> dramforever, and stranal
18:36:51 <Cale> (for the most part)
18:36:54 <dreams> mniip: what do you mean by "no concept of tail-calls"?
18:37:26 <dramforever> dreams: what do you mean by stack?
18:37:26 <Cale> dreams: Well, you can talk about "tail calls" in some sense, but they don't coincide with anything special at the implementation level.
18:37:35 <dramforever> like, what does it contain?
18:37:36 <mniip> dreams, I mean that tail call optimization does not apply to STG
18:37:50 <dreams> Cale: you mean continuations.
18:38:02 <Cale> In particular, there's no special interaction between tail calls and GHC's stack which can be exploited.
18:38:18 <mniip> continuations are a high-level concept
18:38:31 <mniip> and there's nothing called "continuations" at closure level
18:38:35 <Cale> When you do a tail call, there's no entry which is necessarily going on the stack, but that's not because it's a tail call, it's because you didn't pattern match.
18:38:59 <dreams> mniip: they call the alternative of case expressions continuations.
18:38:59 <Cale> and even in many cases where it's not a tail call, you won't have a stack entry
18:39:13 <Cale> Consider, for instance  f n = n : f (n+1)
18:39:18 <Cale> This won't use the stack.
18:39:22 <mniip> dreams, the alternative of case expressions?
18:39:33 <dramforever> hmm...I'm still unanswered
18:39:36 <dreams> the branches.
18:39:44 <dreams> ugh, ok I'm a bit outdated.
18:39:46 <mniip> do they
18:39:50 <mniip> "they"
18:39:58 <dreams> mniip: the authors of the STG.
18:40:01 <dramforever> I wonder if you saw my question
18:40:21 <nolrai66> Cale: and the c stack is used to store things, yes? Or am I missremembering?
18:42:22 <Cale> nolrai66: Yeah iiuc, results of evaluation do go on the stack. It's the same stack, it's just really weird to think of it as a call stack from the level of Haskell.
18:42:40 <levi> If you force a deeply nested thunk that refers to itself without an intervening data constructor, you will in a lot of cases get activation records that build up in something that very much resembles the C stack.
18:42:52 <Cale> nolrai66: Because it doesn't really correspond to applications of Haskell functions.
18:42:56 <nshepperd> I think the c stack is sorta just used in ghc as a sort of dumping ground for things that won't fit in registers?
18:43:22 <mniip> nshepperd, C stack is orthogonal to closures
18:43:22 <nolrai66> Cale: right.
18:43:25 <dreams> levi: wouldn't that blackhole?
18:44:13 <dramforever> nshepperd: wait a sec
18:44:36 <dramforever> I thought I heard that someone told the ghc devs\
18:44:40 <johnw> nshepperd: as far as I understand, the 'stack' isn't special in any other way except that new allocations "grown down".  You sbrk() to extend the heap, while the maximum stack size is fixed when the executable is built, IIRC
18:44:54 <dramforever> "I have a new register allocation algorithm, do you want it?"\
18:45:09 <dramforever> the response was: "we don't need those registers"
18:45:17 <dramforever> weird...
18:45:38 <dramforever> ok those might be off a bit, but you get the idea
18:45:48 <dramforever> so...now ghc could make use of the stack?
18:45:52 <dramforever> *registers?
18:46:16 <nolrai66> I think in practice we don't end up using that many registers.
18:46:29 <nolrai66> (Not sure why I am apparently part of GHC?)
18:47:22 <dramforever> nolrai66: yep, because we just have to waste quite a bit of memory
18:47:36 <nolrai66> Hm?
18:47:53 <dramforever> pointers
18:48:00 <dramforever> thunks
18:48:21 <nolrai66> Ah, so our memory usage is so high more registers wont help much?
18:48:52 <dramforever> I think so...
18:49:00 <dramforever> but it's getting weird
18:49:08 <Cale> johnw: You can set the maximum stack size with an RTS option
18:49:27 <mniip> yeah a couple registers won't help
18:49:27 <Cale> johnw: The default is apparently 80% of the heap
18:49:32 <johnw> Cale: OK
18:49:35 <mniip> you want to compress closures instea
18:49:45 <johnw> I remember that the default size was extended greatly in 7.6 or 7.8
18:49:48 <mniip> there are millions of closures in memory at a time
18:50:02 <dramforever> that's also the only part I hate about haskell
18:50:05 <dramforever> lazy evaluation
18:50:15 <Cale> :(
18:50:16 <johnw> registers are pretty awesome whenever tight loops are involved
18:50:17 <mniip> it's not a failure of haskell
18:50:22 <dramforever> johnw ++
18:50:25 <johnw> saves loading/restoring to/from memory
18:50:32 <dmj> dramforever: that's like one of the best parts
18:50:32 <mniip> it's a failure of "stock hardware" as the STG paper calls it
18:50:43 <dramforever> johnw: yep, I think you're right
18:50:46 <thoughtpolice> I'm very confused by this whole conversation. A better register allocator for GHC would be great, and just like any compiler, a register allocator is a crucial component for performance. GHC's is pretty old at this point.
18:50:55 <thoughtpolice> And second, laziness is great. It's why I like Haskell :)
18:51:00 <dramforever> thoughtpolice: sorry
18:51:14 <dramforever> 1. I'm not even sure that one is real
18:51:28 <mniip> thoughtpolice, a better register allocator might squeeze some bytes out of the memory footprint, but it's not drastic
18:52:01 <dramforever> thoughtpolice: that story could be fake, really
18:52:03 <Stratege> isn't better register allocation about needing less time, not less memory? (I might be entirely wrong there of course)
18:52:05 <johnw> better register allocators will also decrease the number of move instructions
18:52:07 <thoughtpolice> I'm not convinced. Our current one is vintage 1995. We could do a lot better on tight loops for one, but also, GHC doesn't take into account any kind of modern microarchitecture information.
18:52:08 <Cale> The main thing about laziness is that you really have to be used to it in order to find it intuitive to write programs which perform well, but once you've been using it for a long time, the increased ability to decompose problems really grows on you.
18:52:20 <dramforever> thoughtpolice: sorry for the confusion
18:52:23 * johnw says me, who is working on a register allocator as we speak
18:52:27 <dramforever> that story could be fake
18:52:51 * nshepperd checks out 'haskell ghc illustrated' just to make sure he has things right
18:52:52 <thoughtpolice> e.g. GHC doesn't sit around and think much about whether one instruction is going to pipeline better than another for a particular machine. In practice, I imagine we could improve this a lot. But it's boring, very tedious amounts of work.
18:52:56 <mniip> Cale, you start seeing the picture through the symbols
18:53:09 <mniip> you comprehend the beauty of closures!
18:53:23 * dramforever learnt that one shouldn't say something too vague
18:53:25 <johnw> thoughtpolice: we need to get Intel interested in building a custom GHC backend just for their processors, they way they've done for C++
18:53:25 <Cale> mniip: I don't even think in terms of closures, that's too low-level
18:53:35 <mniip> Cale, sometimes I do
18:53:37 <Welkin> thoughtpolice: that's why you assign it as a research project for graduate students funded by grants
18:53:40 <dramforever> thunks are too hard to manage well to me
18:53:41 <Cale> mniip: I just think in terms of expression trees/graphs being rewritten
18:53:52 <dramforever> I wonder if it's a problem well-solved
18:54:00 <dreams> Cale: 'perform well' in terms of efficiency?
18:54:01 <dramforever> or really a new problem
18:54:06 <mniip> Cale, well thunks, but they're not thunks
18:54:10 <thoughtpolice> dramforever: I'm not slighted or anything, I'm just confused. :) A good register allocator would be excellent, and it's vital for any compiler! Even GHC where we're often in a really high level of abstraction.
18:54:13 <mniip> values that can be demanded
18:54:18 <Cale> Yeah, don't worry about thunks, you only need to think about the stuff that the thunks are being used to implement -- expressions at runtime
18:54:30 <dramforever> thoughtpolice: yes so I said I was sorry for the confusion
18:54:31 <thoughtpolice> johnw: I don't think we need Intel. :) But maybe we do need a grad student or two.
18:54:31 <fryguybob> johnw: They kind of did once
18:54:38 <Cale> dreams: Yeah, in terms of time and space efficiency 
18:54:47 <dramforever> forget about that register allocator story
18:54:53 <nshepperd> oh, looks like we don't use the c stack at all
18:54:53 <Cale> dreams: It's kind of like learning to program again -- your intuitions are all wrong at first
18:54:55 <thoughtpolice> Right now, the current x86 backend is something like ~13,000 lines of code.
18:55:07 <johnw> fryguybob: I thought I remembered something about that, but I dismissed the memory; what was that project called again?
18:55:08 <dramforever> Cale: there's an interesting problem
18:55:08 <mniip> thoughtpolice, let's make that 100000!
18:55:11 <thoughtpolice> Honestly I think that could be incrementally reduced and improved.
18:55:12 <Cale> dreams: But spend a few years doing it, and you start to get good at spotting what works and what doesn't.
18:55:16 <dreams> Cale: for large programs, it can be extremely hard.
18:55:20 <dramforever> oh wait lemme think about it more
18:55:36 <Cale> dreams: Well, that's true independently of evaluation model
18:55:41 <dramforever> Cale: it's hard to implement many algorithms efficiently in haskell
18:55:43 <thoughtpolice> There's a lot of scope for killing many of the redundancies in the backend e.g. by using something like LLVM's TableGen. That would make it a lot easier to extend and improve it, too.
18:55:55 <dramforever> I didn't say impossible, just hard
18:56:01 <thoughtpolice> (Well, not exactly their TableGen, it's pretty specific to them, but something similar)
18:56:15 <Welkin> dramforever: you need to use the right algorithms/data structures
18:56:18 <thoughtpolice> And as for a register allocator, literally anything more modern than 1995 would be a good start. :)
18:56:21 <dramforever> Welkin ++
18:56:22 <Welkin> not ones invented for an imperative model
18:56:32 <fryguybob> johnw: One of the papers: http://dl.acm.org/citation.cfm?id=2500605
18:56:39 <Cale> dreams: In my experience, the differences between strictness and laziness don't often affect things at the really large scale in large programs so much.
18:56:42 <thoughtpolice> johnw: Is your RA written in Coq working good yet? :)
18:56:46 <dramforever> that's one thing I hate about the "outside world"
18:56:56 <johnw> thoughtpolice: yeah, it's working very well
18:57:15 <Cale> dramforever: Uh, I don't know if I'd agree with that at all.
18:57:19 <fryguybob> Ah they called it the Intel Labs Haskell Research Compiler
18:57:21 <thoughtpolice> Oh, I was off by like 10,000 lines.
18:57:23 <johnw> thoughtpolice: recently I wrote a verifier for it, so it runs your program through a VM to further validate the allocations; it'll even catch uninitialized register references for you, if you enable strict mode
18:57:29 <thoughtpolice> The x86 backend we have is about 4,000 lines.
18:57:32 <dreams> Cale: I think for lazy ones its harder, specially space. how can you keep all these complex interleav-ish expressions in your head? Even with profiles you'd need to understand the operational behaviour.
18:57:43 <Cale> dramforever: At worst, you can program imperatively, and just do what you'd do in any imperative language.
18:57:44 <thoughtpolice> The entire native code generator is about 15,000 lines
18:57:45 <johnw> thoughtpolice: or references to a register that actually has the contents of another virtual variable
18:57:51 <thoughtpolice> So yes, huge amounts of room for improvement honestly.
18:57:54 <dramforever> Cale: ok then
18:58:01 <Cale> dramforever: But you might give up lots of nice properties you'd like to get from Haskell in doing that.
18:58:10 <dramforever> Cale: exactly
18:58:19 <thoughtpolice> johnw: That's pretty awesome. But is it fast? :)
18:58:32 <johnw> thoughtpolice: oh heck no, I haven't even done a single round of perf analysis yet
18:58:40 <dramforever> Cale: another problem is debugging
18:58:41 <johnw> I expect the asymptotics to be horrific
18:58:52 <thoughtpolice> :) Does it generate fast code though? Don't leave out the good parts ;)
18:59:09 <thoughtpolice> Seriously though, something like that even optionally would be kind of amazing if you could just get it kind-of-fast.
18:59:13 <johnw> I mean, I use QuickCheck to generate 10,000 sample programs, up to 100 basic blocks each, upon to 100 instructions per block, and it'll allocate and verify for those in less than a minute; but still, that should be a piece of cake
18:59:24 <Cale> dreams: I keep in my head some sort of picture of what the expression graphs look like, and imagine them being successively rewritten by evaluation as I pattern match. Yes, it's possible for this to be very complicated, but in *most* cases, it's reasonably simple and linear.
18:59:43 <dramforever> Cale: "intuition" -> fine
18:59:49 <johnw> thoughtpolice: now, the code it generates should be high quality though
19:00:07 <Cale> dreams: and I usually only start to do it once I've identified that a certain piece of code is, or is likely to be a problem in terms of performance.
19:00:10 <johnw> thoughtpolice: there are just two optimizations I have yet to implement: move split positions to block boundaries where possible, and moving them outside of loops when possible
19:00:31 <thoughtpolice> johnw: That would probably work tbh speed wise. At least as something like an optional backend for doing tests. Hooking it into GHC is also definitely a good selling point for any paper :)
19:00:41 <johnw> thoughtpolice: but I do do loop depth analysis, and generating pseudo use-positions to hold variables in registers until the end of the loop as much as possible
19:00:58 <johnw> thoughtpolice: I'd love to hook it into GHC; any interest in a collaboration at some point?
19:01:32 <thoughtpolice> Yeah, GHC doesn't do anything like this IIRC. I don't even know how good it is at rematerialization sometimes tbh, which should say something.
19:02:11 <johnw> also, it's a linearscan allocator, so once I have done some perf analysis, it should be hella fast.  It's the same algorithm being used for JIT allocation in the Java HotSpot JVM from Sun
19:02:28 <thoughtpolice> johnw: Sure. It would be quite a test drive! And for GHC you wouldn't need to hook into Hoopl, although I'm not sure what kind of interface you might need OTTOMH.
19:02:32 <Stratege> Cale is laziness really needed for better decomposing? Or just a performance optimization when having such decomposed code?
19:02:44 <thoughtpolice> Yeah, GHC's default allocator is linear scan already, and it almost certainly can't be older than our current version.
19:02:53 <johnw> thoughtpolice: I intentionally keep the interface abstract; my only input is a set of records-of-functions that characteristize your program graph
19:03:00 <thoughtpolice> There's a graph coloring allocator but uh, I think it's been broken for like
19:03:08 <Cale> dramforever: Well, if you manage to avoid just using Haskell as another imperative language, I find debugging is nicer in Haskell than most other languages. Because so many things are pure, you get nice guarantees all over the place that code which is run in isolation is going to work the same way in the real program. So you don't need any special debugging tool to reconstruct the state of the world and inspect it befo
19:03:08 <Cale> re and after running the bit of code you're interested in.
19:03:09 <thoughtpolice> 2 major releases and nobody has fixed it.
19:03:15 <dreams> Cale: you're the first Haskeller I met who puts the word "simple" when it comes to reasoning about behavior. Perhaps you look after 'reasonable efficiency'.
19:03:16 <thoughtpolice> Or there were some pretty severe unresolved bugs I think...
19:03:33 <johnw> thoughtpolice: every graph-coloring allocator that I'm personally aware of suffers from both of those problems
19:03:40 <dramforever> Cale: special debugging tool hmm...yes you are right somehow
19:03:41 <Cale> Stratege: It gives you additional ways to decompose problems which would otherwise take combinatorially more time.
19:03:51 <dramforever> somehow those stuff just magically fall into place
19:03:52 <Cale> Stratege: In some cases, infinitely more time.
19:03:57 <Welkin> Cale: isn't that called a "test harness"? A name that suits iw well, since it sounds like some sadomasochistic nightmare
19:04:13 <Stratege> Cale so yeah, just performance improvements. Minus those cases which deal with infinities.
19:04:14 <dramforever> Cale: lemme see...do you think it could be because of the conciseness of haskell code?
19:04:17 <johnw> thoughtpolice: so, every time my validator finds a bug in my allocator, I devise a theorem to make that class of bugs impossible, and then move on to the next bug.  In time, this thing should be provably correct for all allocatable cases
19:04:22 <Cale> dreams: Well, it does depend on what we're talking about.
19:04:26 <dramforever> oh and generality helps
19:04:40 <dramforever> yes, writing general code leads to less bugs
19:04:44 <Cale> dreams: I'm just talking about real world practical behaviour of realistic programs.
19:04:45 <thoughtpolice> johnw: I think for something like GHC it's definitely a worthy goal, Graph based allocators are very fancy in a lot of cases, but they're not just "heavy" in terms of runtime/performance - they're not particularly simple either.
19:04:56 <dramforever> the reusablity isn't really important compared to that
19:05:20 <Cale> dreams: If you want to talk about automated or semi-automated mechanisms for determining the time and space behaviour of programs, then sure, laziness is theoretically much harder to cope with.
19:05:21 <johnw> thoughtpolice: and wouldn't it be cool to find the "last allocator you'll ever need?"  If I could offer that, it would be a compelling point in Coq-for-Haskell's favor
19:05:41 <thoughtpolice> I think for GHC having something like a modern linear scan allocator with something like better instruction scheduling would be a lot better. We already have a pretty high complexity budget, and I'd rather have something simple, fast, and working for the most part.
19:05:41 <dreams> Cale: no I'm talking about squeezing out the best of things.
19:05:58 <Cale> dreams: But in practice, these theoretical details don't hit you nearly so often, and the benefits come up more and more.
19:06:12 <thoughtpolice> johnw: Yes, I think it's a pretty exciting project! CompCert is the only other thing I can think of in the same space
19:06:28 <Welkin> dreams: a good reference on this topic is "Purely Functional Data Structures" by Chris Okasaki
19:06:34 <thoughtpolice> And this is actually reusable which is the nice part.
19:06:41 <dramforever> Cale: I wonder if you agree that generality helps to avoid bugs
19:06:49 <johnw> thoughtpolice: and CompCert isn't using a verified implementation, just a data validator between pipeline stages, so they can't 'rule out' bugs as they fix them, only detect them
19:07:10 <thoughtpolice> Ah, that's a good point I hadn't considered.
19:07:17 <johnw> thoughtpolice: I'll resume this with you in #ghc, so as not to drown out discussion here
19:07:24 <Cale> dreams: and yeah, if you really want to get the best out of things, typically you want to be extremely cautious about *both* strictness and laziness, as both end up being important ingredients in a lot of good pure functional datastructures
19:08:21 * dramforever feels like being devil's advocate here
19:08:27 <dramforever> but I'm going to continue
19:08:41 <dreams> Cale: yup. and *this* is what is harder than say imperative languages. I mean its common knowledge (in the literature).
19:09:27 <dramforever> dreams ++
19:09:31 <Cale> dreams: Well, you're starting to compare quite different things though.
19:09:41 <dreams> Cale: I have also read some report from the industry complaining about space. (never dealt with industrial Haskell personally).
19:09:58 <Cale> There are reasons why you might want these pure data structures in a language where the usual modus operandi was mutation.
19:10:17 <Cale> and you'd end up thinking about all the same stuff if you tried to work with them then
19:11:04 <Cale> We just really like purity and all the benefits it gives to reasoning about the end results of programs, so we do this up front when writing our data structure libraries :)
19:11:32 <Cale> dreams: Yeah, space is the harder of the two to develop intuition about.
19:12:00 <Welkin> dreams: that can ahppen if you aren't careful with laziness
19:12:07 <dreams> Cale: and is harder to optimize than speed (compiler-wise).
19:12:12 <Cale> You can be caught out for not noticing that you're failing to evaluate some expression which you're building up, and end up having it eat up more and more space.
19:12:22 <Welkin> just use strictness when appropriate
19:12:27 <Welkin> for example
19:12:36 <dramforever> Welkin: easier said than done
19:12:37 <Cale> But these are things you do learn to spot, especially if you know you're looking for them
19:12:47 <nolrai66> Welkin or change how you are doing things.
19:12:47 <Welkin> > foldl max [1..10000000]
19:12:49 <lambdabot>      No instance for (Typeable t0)
19:12:49 <lambdabot>        (maybe you haven't applied enough arguments to a function?)
19:12:49 <lambdabot>        arising from a use of ‘show_M676033986651991099518161’
19:12:56 <Welkin> > foldl1 max [1..10000000]
19:13:02 <lambdabot>  mueval: ExitFailure 1
19:13:05 <Welkin> > foldl1' max [1..10000000]
19:13:09 <lambdabot>  10000000
19:13:24 <nolrai66> > foldl max [1..10^8] :: Integer
19:13:26 <lambdabot>      Couldn't match expected type ‘Integer’
19:13:26 <lambdabot>                  with actual type ‘t0 [Integer] -> [Integer]’
19:13:26 <lambdabot>      Probable cause: ‘foldl’ is applied to too few arguments
19:13:32 <dramforever> Welkin: still easier said than done
19:13:39 <Cale> There are similar things which come up in most any language or setting where a garbage collector is being used.
19:14:28 <Cale> Part of the problem is pedagogical. It's hard to figure out how to teach people to think about memory usage in Haskell programs -- especially if you want to stick to saying only things which are 100% true.
19:14:38 <Lokathor> speaking of which, Cale would you care to take a glance at my program here https://github.com/Lokathor/fbmessageparse/blob/master/src/Main.hs
19:14:48 <Lokathor> perhaps spot any obvious memory leaks
19:14:49 <Cale> But I think maybe there's like a 95% accurate model which wouldn't be horrible?
19:16:43 <Cale> Lokathor: Are you having any performance issues with it?
19:17:25 <johnw> Cale: I wonder how many other things are limited in their teachability if you stick to only 100% accuracy
19:17:29 <Cale> It looks like these parsers ought to be nicely predictive -- all your uses of try are quite limited in scope.
19:17:51 <Lokathor> well, it's to parse this 60mb HTML file, and it takes about 30 seconds but uses about 1.6gb of RAM
19:18:23 <Cale> Lokathor: all right, that's useful to know
19:18:35 <Lokathor> when it spits it all back out at the end it creates a 30mb csv file
19:18:36 <Cale> Lokathor: btw,  import Text.Parsec  is the new way
19:18:56 <Lokathor> ah. i was referencing the old "teach yourself scheme in 48 hours" guide
19:20:07 <Cale> Lokathor: It might be very convenient to run the HTML through TagSoup first.
19:20:31 <Lokathor> i don't really need to make it much better, i was just wondering if there were any obvious errors in the code.
19:20:49 <Lokathor> yeah the HTML that facebook generates is kinda a mess
19:21:18 <Lokathor> i have no idea why thread divs are inside an extra unclassified div from time to time, for example
19:22:20 <SrPx> Is it possible to write an instance for "class ListIso l where { toList :: l a -> [a], fromList :: [a] -> l a }" for Data.Vector.Unboxed?
19:22:31 <Cale> Lokathor: I suspect most of the inefficiency is just use of String
19:23:02 <Lokathor> yeah i was told it has quite the overhead
19:23:20 <Cale> Lokathor: String can be 4 machine words per character
19:23:32 <Cale> Lokathor: and on 64 bit machines, that's pretty hefty
19:23:50 <SrPx> On my attempts I get "No instance for (UV.Unbox a) arising from a use of ‘UV.toList’", but following GHC's suggestion and adding a type sig doesn't work. Is it the case that such a thing is impossible?
19:23:52 <Lokathor> ohhhhh
19:23:54 <dramforever> another interesting thing: I was once put off by "read ghc core to be sure that the code is fast"
19:24:15 <dramforever> that is, until I ended up reading assembly when tuning my C++
19:25:09 <SrPx> Also, is it just me or unboxed vectors are the fastest structure available by very, very far?
19:25:13 <Cale> dramforever: GHC core is at least still a functional programming language -- it's a weird and kind of awful to read one, but if you play around with the flags, you can reduce a lot of the noise.
19:25:28 <Cale> SrPx: That sounds reasonable.
19:25:36 <dramforever> Cale: not awful at all
19:26:25 <SrPx> the instance or they being fast? I expected unboxed vectors to be like 2, 3 times faster. It is sometimes even 100 times faster
19:26:28 <Cale> SrPx: Of course, it really depends on what operations you're performing.
19:27:23 <Cale> SrPx: But unboxed arrays are really fast at a lot of stuff already, and adding stream fusion to the operations on them is even better.
19:27:42 <SrPx> Why aren't they used more / suggested more?
19:27:48 <Cale> SrPx: 100 times faster compared to what?
19:28:47 <SrPx> A bunch of random micro benchmarks, and in actual code that was the case too. Pretty much anything you try. For example
19:28:50 <mniip> [04:22:12] <Cale> dramforever: GHC core is at least still a functional programming language -- it's a weird and kind of awful to read one, but if you play around with the flags, you can reduce a lot of the noise.
19:28:59 <mniip> it's just that you're mostly reading machine-generated core
19:29:05 <Cale> mniip: yes
19:29:05 <mniip> with machine-generated variable names
19:29:10 <Cale> mniip: indeed
19:29:22 <dramforever> mniip: much better than assembly
19:29:27 <Cale> If the compiler could be bothered to come up with more sensible names, it would be a lot more pleasant ;)
19:29:29 <mniip> same can be said about TH splices
19:29:32 <jmcarthur> i quite like the intermediate representations of ghc
19:29:32 <dramforever> where you just chase those values around the memory
19:29:37 <dramforever> and registers
19:29:41 <Welkin> assemby is fun :D
19:29:45 <Welkin> assembly*
19:29:48 <jmcarthur> core, stg, and cmm are all quite pleasant, compared to just reading the raw assembly
19:30:20 <SrPx> Ohh... no. Cale. Nevermind, I just realized I was using integers again /facepalms
19:30:24 <SrPx> Damn Integer is slow
19:30:25 <jmcarthur> and enlightening
19:30:40 <jmcarthur> Integer is pretty fast for what it does
19:31:47 <SrPx> But even with ints (except if some of those intermediate structures is using integer and I didn't realize), it is much faster 
19:31:51 <SrPx> In some cases:
19:31:54 <Cale> SrPx: but fast enough most of the time, and more correct!
19:31:58 <SrPx> > UV.sum $ UV.unsafeUpdate (UV.enumFromStepN 0 1 n) (UV.generate n (\x->(x,x*2)))
19:32:00 <lambdabot>      Not in scope: ‘UV.sum’
19:32:00 <lambdabot>      Perhaps you meant ‘F.sum’ (imported from Data.Foldable)Not in scope: ‘UV...
19:32:05 <jmcarthur> SrPx: you can't even use unboxed vectors with Integer
19:32:13 <Welkin> lol
19:32:14 <SrPx> Woops, of course. How do I import stuff on lambdabot?
19:32:16 <mniip> [04:26:27] <mniip> same can be said about TH splices
19:32:25 <mniip> class ClassAKK a_a34C where methodAKK :: forall c1_a34D. ClassK c1_a34D => a_a34C c1_a34D -> ()
19:32:28 <Cale> SrPx: You shouldn't be able to import stuff on lambdabot
19:32:43 <Cale> (if you find out a way, let int-e know about it)
19:32:56 <mniip> Cale, you can with letlpaste
19:33:06 <Cale> Oh really? :)
19:33:16 <dramforever> Cale: you can import something in lambdabot
19:33:21 <dramforever> @undefine -- clean things up
19:33:21 <lambdabot> There's currently no way to undefine just one thing.  Say @undefine (with no extra words) to undefine everything.
19:33:21 <SrPx> jmcarthur: no, I meant if for what I posted. The code above. Replacing unboxed vectors by vectors give a 46x slowdown here
19:33:28 <dramforever> @undefine
19:33:29 <lambdabot> Undefined.
19:33:35 <dramforever> @let import Data.List -- horray
19:33:36 <lambdabot>  Defined.
19:33:41 <dramforever> Cale: see?
19:33:42 <Cale> Oh, I suppose it might be using the Safe Haskell extension or something to help weed out the usual suspects
19:33:43 <dramforever> @undefine
19:33:43 <lambdabot> Undefined.
19:33:53 <dramforever> Cale: yes it will only imported trusted stuff
19:33:59 <mniip> quick
19:34:01 <dramforever> @let import qualified Data.Text
19:34:02 <lambdabot>  .L.hs:112:1:
19:34:02 <lambdabot>      Data.Text: Can't be safely imported!
19:34:02 <lambdabot>      The package (text-1.2.1.3) the module resides in isn't trusted.
19:34:04 <Cale> At least when I ran lambdabot it didn't have that :)
19:34:12 <mniip> someone find a deficiency in the type inference engine
19:34:33 <mniip> so that we can implement a safeCoerce
19:34:43 <SrPx> (but there is something weird, ints and integers give the same performance for (V.sum $ V.unsafeUpdate (V.enumFromStepN 0 1 n) (V.generate n (\x->(x,x*2))) :: Int))
19:34:54 <dramforever> mniip: it was done before
19:35:18 <mniip> I know
19:35:19 <SrPx> Oh nvm I guess the code in that case defaulted for Ints not Integers. Damn I always get that wrong.
19:36:08 <dolio> dramforever: By the way. The answer to your question in ##logic is that, yes, there is a decision procedure for theorems in intuitionistic propositional logic. It's what @djinn uses to find functions of a given type.
19:36:19 <dramforever> oh wow
19:36:25 <dramforever> dolio: fully decidable?
19:36:35 <SrPx> anyway anyone got an idea if it would be impossible to write an unboxed instance for ListIso? I feel like I'm wasting my time trying it
19:36:40 <dolio> Yes, if it's just propositional logic.
19:36:42 <dramforever> dolio: thank you very much for the information
19:36:48 <dramforever> </off-topic>
19:40:06 <mniip> dramforever, dolio more than that
19:40:12 <mniip> it's in P
19:40:12 <dramforever> oh?
19:40:17 <dramforever> hmm...
19:40:45 <dramforever> wow
19:41:20 <dolio> In what? Number of variables?
19:41:40 <mniip> size of input I assume
19:41:57 <dramforever> ...
19:42:24 <mniip> maybe about of -> signs
19:42:35 <dramforever> ...
19:42:57 <mazur> hi, does anyone know what nixos environment `cabal init` needs to guess dependencies? e.g. I get "Warning: no package found providing Control.Lens"
19:45:58 <dolio> mniip: Are you sure? There's a math overflow saying it's PSPACE complete. Which isn't P, right?
19:46:11 <dolio> I have trouble remembering all this.
19:47:29 <dolio> Conjectured to not be P, I guess.
19:52:02 <randomthoughts> hello haskellers
19:52:08 <pacak> o/
19:52:23 <randomthoughts> is it safe to make unsafe FFI calls from bound thread?
19:53:31 <johnw> randomthoughts: safe in what sense?  I don't think it's any less safe
19:53:41 <johnw> either way, the GHC runtime is blocked
19:54:42 <randomthoughts> johnw: in the same sense as safe vs unsafe FFI calls
19:55:10 <johnw> I don't think calling from a bound thread changes anything
19:55:28 <johnw> (I mean, in that regard)
19:55:57 <randomthoughts> I'm trying to use mmap'ed files from haskell, but reading mmaped memory may block
19:56:19 <randomthoughts> but I don't want to pay price for overhead of safe FFI call for each access
19:58:42 <bycn82> hi
19:58:57 <bycn82> help
20:00:29 <bycn82> can i have multiple line of expressions in a function?
20:00:34 <mjrosenb> oh man, I finally got around to looking at lenses
20:00:38 <benzrf> what do you mean by that, bycn82
20:00:44 <johnw> did they look back at you, mjrosenb?
20:00:46 <mjrosenb> they are as awesome as I'd hoped.
20:01:04 <johnw> hold them under the sun, and they can start fires
20:01:21 <mjrosenb> johnw: only when I try to use them on abyss = abyss ++ abyss
20:04:53 <itsu`> Anyone working in haskell as main language here ?
20:05:03 <johnw> itsu`: yes
20:05:26 <itsu`> johnw: are you working for a startup ? big company ?
20:05:31 <johnw> huge company
20:05:39 <johnw> and I know startups that use it
20:05:47 <johnw> Wagon is looking for a Haskell engineer just since a day or two ago
20:06:03 <itsu`> oh nice, I thought only little company would use haskell (aside from facebook)
20:06:15 <johnw> other very large financial companies use it too
20:06:21 <johnw> it's general purpose like any language
20:07:02 <itsu`> I'm just a beginner but two years ago I started learning scala and couldn't find any jobs so I was wondering if it was the same for haskell
20:07:12 <itsu`> although I was looking for a job in France
20:07:40 <rpfun> is there some example of use for the SomeNat typeclass? i am just confused since I can't see an application where i can't pull in the value from type-level with natVal and do my computations without invoking someNat?
20:07:42 <johnw> there are probably a lot more Scala jobs in the market
20:07:54 <itsu`> yeah, plenty in the US
20:08:11 <itsu`> but the more I code in Haskell, the less I want to go back to scala :-(
20:09:29 <johnw> rpfun: SomeNat lets you recover the type-level value as a runtime value
20:09:41 <johnw> SomeNat n => Proxy n -> Vector n Int
20:09:48 <johnw> now I can determine the length of the vector I'm to return at runtime
20:09:55 <johnw> as well as reason about it at compile-time
20:11:01 <rpfun> johnw: can you give an example of the function body? I'm just confused as to why I can't use natVal
20:11:21 <johnw> natVal would take that proxy argument
20:11:33 <johnw> oh, I see
20:11:50 <johnw> SomeNat is an existential
20:11:57 <johnw> i.e., you have some number, but you don't know what it is
20:13:21 <rpfun> so suppose i write something like "mkT :: (KnownNat n) => [a] -> Vector n a", with a check in the function body (length [a] == natVal (Proxy :: Proxy n)), which i have done and compiles/works
20:13:39 <rpfun> what power would I gain if i replaced "KnownNat" with SomeNat?
20:14:13 <SrPx> uhmm... guys?
20:14:27 <SrPx> Do you actually not know if it is possible?
20:14:34 <monochrom> my impression is that you gain runtime flexibility power and lose compile-time checking power
20:14:51 * hackagebot exact-pi 0.2.1.2 - Exact rational multiples of pi (and integer powers of pi)  https://hackage.haskell.org/package/exact-pi-0.2.1.2 (dmcclean)
20:15:12 <johnw> rpfun: you couldn't write that function
20:15:40 <johnw> it would be saying, "there exists an 'n', which I'm giving you, for which you must produce a vector of that length from any list"
20:16:30 <rpfun> johnw: ah, but i could write something like "generateN :: (SomeNat n) => Proxy n -> Vector n a" and have it generate a list of the length I pass in?
20:16:49 <johnw> SomeNat is a data type, it's not a constraint
20:16:55 <johnw> it packages up a number "you know not which"
20:17:14 <johnw> i.e., any number can go into it, but you can't tell which number it was
20:17:32 <johnw> which is great if you have the burden of making one, since you can pick any number that satisfies your typ
20:17:32 <johnw> e
20:17:43 <johnw> but as a consumer, it's simply proof that SOME number existed to satisfy the type
20:18:28 <rpfun> johnw: sorry, i was confused since you wrote "SomeNat n => ..." earlier. could you give a short snippet that demonstrates its use?
20:18:33 <feryll> Quick Q: Could I rewrite the following into a one-liner? http://lpaste.net/139317
20:19:26 <rpfun> feryll: Graph vs <$> mapM bar es
20:20:00 <feryll> Ah, thanks.
20:20:07 <exio4> feryll: side-note, the type is missing a constraint
20:20:13 <johnw> rpfun: http://stackoverflow.com/questions/30752653/can-i-have-an-unknown-knownnat
20:20:16 <feryll> Yeah, (Monad m) ?
20:20:33 <exio4> @type mapM
20:20:35 <lambdabot> (Monad m, Traversable t) => (a -> m b) -> t a -> m (t b)
20:20:37 <exio4> yup, Monad
20:21:22 <johnw> rpfun: in that example, SomeNat is being used to promote the value read at runtime into a type-level number that we can use to satisfy the call to bar
20:21:39 <johnw> since we don't know what number it is (it came from the user), but it's "some" Nat
20:22:02 <johnw> meanwhile, bar uses KnownNat, which means it works for *any* number
20:22:18 <johnw> thus, the two sides are compatible, and at compile-time we don't need to know exactly which number it is
20:22:47 <johnw> it's unfortunate how many hoops we have to jump through here
20:22:54 <johnw> in Agda this would be a trivial existential vs. universal distinction
20:23:17 <johnw> but then again, it's cool that we *can* do this, without needing fully dependent types
20:23:18 <rpfun> oh wow, so somehow GHC does some form of typechecking at runtime?
20:23:25 <johnw> no, it's not type-checking at runtime
20:23:42 <johnw> think through the example: the specific number (i.e., the type of the singleton the user will choose at runtime) is never necessary
20:23:58 <johnw> bar works for any integer, and only requires that we give proof of having *some* integer to thus be callable
20:24:28 <johnw> and SomeNat is constructible from any runtime integer, since being able to call someNatVal is sufficient proof that we have such a number
20:24:44 <johnw> so, at compile-time all the requirements are satisfied, and the types are erased
20:25:03 <johnw> at runtime, everything works because at compile-time we showed that every necessary detail was fulfilled
20:25:47 <rpfun> johnw: thank you, this clears a lot up! i just didn't even imagine the scope of what was possible.
20:25:51 <nshepperd> I normally write a little function 'withNat :: Integer -> (forall n. KnownNat n => Proxy n -> r) -> r' to save some of the faffing about
20:25:55 <johnw> even dependent types do not exist at runtime; they simply constrain what it's possible to write to those programs which fulfill the types
20:26:17 <rpfun> johnw: was this implemented directly in GHC using existing Haskell + extensions, or is it a direct extension to GHC itself?
20:26:22 <johnw> yeah, withNat is mentioned on the mailing list
20:26:29 <johnw> rpfun: it can all be implemented using singleton types
20:26:41 <johnw> and Rank-2 quantification, in this case
20:27:12 <johnw> GHC is automated the production of singletons "behind the scenes", which gives it the magical feel
20:27:38 <johnw> see http://hackage.haskell.org/package/singletons if you want to go a lot further with this type of programming
20:27:55 <nshepperd> the only part that really requires ghc support is I think making it so you can use literals like '5' as types of kind Nat
20:27:58 <johnw> and with the upcoming type/kind unification, things will get very nice
20:28:11 <johnw> nshepperd: right, that's the magical part
20:28:30 <johnw> otherwise, I could easily hand-craft a type called Five
20:29:08 <rpfun> is the singletons paper the good place to learn about these things?
20:29:14 <johnw> sure
20:29:23 <johnw> in the beginnings, programming with singletons was a massive PITA
20:29:26 <nshepperd> hey, do you know when the SMT typechecker plugin stuff is likely to land?
20:29:37 <johnw> the last 10 years have seen many iterations of progress in making them more transparent
20:30:07 <nshepperd> just because I really wish stuff like (KnownNat a, KnowNat b) ==> KnownNat (a*b) could be inferred
20:30:49 <rpfun> nshepperd: is your withNat short?
20:31:16 <johnw> nshepperd: I don't know when that's coming
20:31:24 <johnw> but having an arithmetic solver would be fantastic
20:31:36 <nshepperd> withNat n f = case someNatVal n of { Just (SomeNat proxy) -> f proxy } -- I think this is all you need
20:31:57 <Pamelloes> Is there a way to defer an IO call in a lazy fashion?
20:32:14 <rpfun> nshepperd: ok, that's what I thought, thanks!
20:32:34 <rpfun> is there any reason that most list/array operations shouldn't use this machinery extensively?
20:32:49 <erisco> "Improper lens from packed ByteStrings to unpacked Word8s"
20:32:53 <erisco> what is an improper lens?
20:32:57 <erisco> http://hackage.haskell.org/package/pipes-text-0.0.0.16/docs/Pipes-Text.html
20:35:27 <erisco> also how does the description match the types
20:35:27 <nshepperd> hmm, I built some unsafe machinery for constructing the KnownNat (a*b) dictionary explicitly earlier, where did I put it...
20:35:28 <erisco> unpack :: Monad m => Lens' (Producer Text m r) (Producer Char m r)
20:35:34 <erisco> Char is not a Word8 is it?
20:36:35 <pacak> > ord 'ы'
20:36:36 <lambdabot>  1099
20:36:40 <pacak> erisco: nope
20:37:02 <dolio> Pamelloes: unsafeInterleaveIO.
20:38:53 <erisco> Pamelloes, a little more context could help, for example [putStrLn "hello", putStrLn "world"] is [IO ()] and doesn't print anything, so perhaps that is like a referred IO call
20:38:56 <erisco> deferred
20:39:48 <Pamelloes> I'm debating whether making a type in the form of MyType (IO Type1) (IO Type2) (IO Type3) etc. or MyType Type1 Type2 Type3 where the values are calculated with a deferred IO call (apparently via unsafeInterleaveIO)
20:40:20 <erisco> you'd probably do  IO MyType
20:40:28 <erisco> rather than having each field be some IO type
20:41:14 <Pamelloes> Well, what's going on is MyType is a JSON object retrieved from a server. And each field is a URI referring to another object.
20:41:46 <erisco> sure, so IO MyType could work fine
20:42:08 <Pamelloes> Hm.....
20:42:58 <Pamelloes> I'd like to hide the underlying URI interactions--hence having MyType Type1 Type2 etc. instead of MyType URI URI URI
20:43:09 <dolio> Depends on your metric for "fine," probably.
20:43:59 <Pamelloes> Each conversion from URI to respective object is a separate IO call. I would rather avoid resolving parts of the API that aren't needed.
20:43:59 <erisco> I see, so you want to resolve the documents when they are needed
20:44:01 <dolio> Is the issue that you don't want to fetch the data if no one looks at it or something?
20:44:17 <Pamelloes> dolio: exactly.
20:45:04 <erisco> a problem with using something like unsafeInterleaveIO is that an IO exception can be thrown in pure code
20:45:10 <Pamelloes> The API is setup in such a way where the root node provides a JSON object with links to categories of functions. And then each category provides links to specific functions/sub categories etc.
20:45:34 <Pamelloes> erisco: Yeah, that's what I'm worried about.
20:46:08 <Pamelloes> I think making MyType (IO T1) (IO T2).... might be the safest solution, but it seems kind of ugly.
20:47:22 <Pamelloes> Also, it could wind up with repeated, unnecessary calls. Since each sub value will not change.
20:47:25 <Pamelloes> Probably.
20:47:29 <erisco> should you go that route I wouldn't bother with  IO T1 and so on
20:47:51 <erisco> I mean, you can just have a function URI -> IO Document or whatever and use that
20:48:27 <dolio> You could fix the multiple fetch issue (manually).
20:50:21 <erisco> memoising impure values seems to be a bother
20:50:34 <erisco> I am assuming you don't want to have to work with IO every time
20:50:55 <erisco> ie you use IO to get the sub-document once, and then after that you don't need IO
20:51:02 <Pamelloes> Right.
20:52:05 <Pamelloes> The URIs can, theoretically change, but they're unlikely to. So within a single run of the program the root node and each of the categories are pure values--executing the calls multiple times should yield the same results.
20:52:11 <erisco> you might use a sum type... data LazyDocument a = Loaded a | Unloaded (IO a)
20:52:15 <erisco> something like that
20:52:33 <erisco> so if you have  MyType (LazyDocument T1) (LazyDocument T2)  etc
20:52:39 <erisco> I dunno, it isn't super ideal
20:52:48 <Pamelloes> Hm.
20:52:55 <erisco> you'll end up with partiality if you want to assume later on something is loaded
20:53:05 <erisco> you could parameterize MyType but that could get verbose
20:53:27 <kadoban> So … with PartialTypeSignatures and/or NamedWildCards … is there a way to say "this is a wildcard, I don't care to see a warning about it when I compile" ? I just want to specify part of the type sig, not hear about it every time I compile …
20:53:35 <erisco> data LoadedDocument a = ...; data UnloadedDocument a = ...;  MyType a b = MyType a b
20:53:48 <erisco> so, like,  MyType (UnloadedDocument T1) (LoadedDocument T2)
20:53:59 <Pamelloes> eek
20:54:03 <erisco> yeah =\ hm
20:54:08 <Pamelloes> that would get verbose quite fast.
20:54:23 <Pamelloes> The root API has 25 nodes.
20:54:31 <Pamelloes> So that would mean 25 parameters.
20:54:32 <Pamelloes> D:
20:54:49 <erisco> but it would mean you could have any combination loaded or unloaded
20:54:56 <erisco> without any partiality down the line
20:55:48 <erisco> I don't think there is going to be a perfect solution for this
20:56:21 <erisco> you can also flatten it out to  MyTypeWithDocumentT1 = MyTypeWithDocumentT1 T1 (IO T2)
20:56:41 <Pamelloes> Yeah, this is tricky.
20:56:42 <erisco> so if you only have a few combinations likely to happen that could work
20:57:53 <dolio> I think there's pretty clearly a 'nicest to use' solution, out of the ones so far discussed. :)
20:58:20 <erisco> you can do something else actually
20:58:56 <erisco> I can't think of all the details up front, but you essentially create a DSL that is evaluated later
21:00:12 <Pamelloes> Alright, it turns out I mis-interpreted the API I'm wrapping (its lack of documentation is incredibly frustrating--programmers, document your code!)
21:00:14 <erisco> data Mytype = MyType T1 T2  withT1FromMyType :: (T1 -> a) -> MyDSL a
21:00:40 <erisco> you do something vaguely along those lines, so you're basically wrapping up all your operations on the document into some data type
21:00:48 <erisco> which you evaluate (interpret) later on
21:00:56 <erisco> this could possibly fit as an Arrow
21:01:13 <Pamelloes> I've never used Arrows....
21:01:35 <Pamelloes> Well, I've "used" them but I don't really understand them.
21:01:57 <erisco> okay, well it might be hard to suddenly start using them now then
21:02:45 <erisco> basically an Arrow is a generalisation of ->, it is something which sends one object to another
21:02:58 <erisco> or one type to another
21:03:14 <erisco> so, -> are magical special Haskell things which do this
21:03:18 <erisco> but you can make up your own
21:03:26 <Pamelloes> Interesting.
21:03:28 <erisco> and then you can interpret these later
21:03:54 <erisco> there are libs which use this... one that does xml or html or something like that iirc
21:04:02 <erisco> some FRP libs
21:04:47 <erisco> so it'd be more like  retrieveT1FromMyType :: MyDSL MyType T1
21:05:16 <erisco> so 'retrieveT1FromMyType' is the name of a function, a function of MyDSL which sends MyType to T1
21:05:22 <Pamelloes> Huh.
21:05:49 <erisco> and Arrows are categories, so you can compose them
21:06:19 <erisco> so you can write some f :: MyDSL T1 B  and do  f . retrieveT1FromMyType :: MyDSL MyType B
21:06:50 <erisco> and I imagine you can figure out when you interpret your DSL whether something needs to be fetched through IO or not, and cache it even
21:07:12 <Pamelloes> So you could use arrows to interact with the DSL as if you were in normal pure code.
21:07:38 <Pamelloes> That's an interesting concept.
21:08:08 <erisco> this does mean you have to use arrow notations
21:08:17 <Pamelloes> oh.
21:08:20 <erisco> so you can debate whether that is any gain over using do-notation and working in IO
21:08:28 <Pamelloes> I've looked at that and it's.... scary.
21:08:28 <erisco> or monad notations
21:08:57 <Pamelloes> So this library I'm trying to wrap is an absolute nightmare.
21:09:10 <erisco> well, you can go way overboard and use TH :P
21:09:26 <Pamelloes> s/library/API
21:09:36 <erisco> you can use the Arrow as an implementation for a DSL parsed from TH
21:09:55 <Pamelloes> this is becoming kind of crazy.
21:10:38 <Pamelloes> What's upsetting here is the reason all these problems exist is because the API's developers were trying to be /nice/.
21:11:01 <erisco> I have seen this before actually, but in a PHP lib for JSON-LD
21:11:16 <Pamelloes> The API is designed so that you never construct any URIs. Each JSON object retrieved has links to related objects.
21:11:18 <erisco> also ORMs are a fan of doing this
21:11:31 <erisco> i.e. surprise IO when you access some field
21:11:51 <erisco> Pamelloes, sounds like HATEOAS
21:12:38 <Pamelloes> yep, that's what it is.
21:12:53 <Pamelloes> And documentation is nonexistant.
21:14:17 <erisco> I'd go with one of the earlier ideas just to get it working
21:14:29 <erisco> don't worry about memoisation either
21:14:52 <Pamelloes> So about half of the functions are "pure" i.e. they cannot change until a server restart. The remaining functions are dynamic so those will always need an IO call to access.
21:15:00 <erisco> if the code is really bad for re-fetching documents then you can keep a memo table externally
21:15:14 <Pamelloes> erisco: How does that work?
21:15:15 <erisco> or if you really want to kludge you can use an unsafe mvar
21:16:04 <erisco> well you just keep a Map URI Document handy, if that suffices
21:16:09 <erisco> pass it around
21:16:16 <Pamelloes> Ah, I see.
21:16:35 <erisco> you can use StateT to tuck it away a bit
21:17:09 <Pamelloes> Yep, I've done that before.
21:17:47 <erisco> if you have  MyType (IO T1) (IO T2)  etc
21:17:56 <erisco> then you can use mvars safely in each of those IO actions
21:18:11 <erisco> and as you access them in your IO computation those mvars will stay alive
21:18:38 <Pamelloes> The issue here is less about querying the server multiple times and more about ease of use of the API.
21:18:53 <Pamelloes> The queries are light enough that a few extras shouldn't be an issue.
21:19:07 <erisco> *shrug* I guess make it convenient enough to use with do-notation
21:19:17 <Pamelloes> However, if you need to query something 5 layers deep, that winds up being 5 lines in do notation which is a pain.
21:19:43 <Pamelloes> If the layers were pure, it could be done in one line with lenses.
21:19:57 <erisco> if they are named it doesn't have to be 5 lines
21:20:08 <erisco> you can just compose with >=>
21:20:16 <Pamelloes> :t >=>
21:20:17 <lambdabot> parse error on input ‘>=>’
21:20:38 <erisco> :t (>=>)
21:20:39 <lambdabot> Monad m => (a -> m b) -> (b -> m c) -> a -> m c
21:20:51 <Pamelloes> huh
21:20:59 <Pamelloes> That's super useful.
21:21:01 <erisco> so you'd end up with   field1 >=> field2 >=> field3 >=> field4 >=> field5
21:21:21 <erisco> or you can use <=< if you like right-to-left
21:21:40 <Pamelloes> Whereas what I was picturing was field1 ^. field2 ^. field3 .... which is not too syntactically different.
21:21:57 <Pamelloes> I can't believe I've never stumbled upon (>=>) before.
21:22:01 <Pamelloes> That simplifies everything :D
21:22:19 <erisco> apparently they are called Kleisli arrows
21:22:43 <solrize> Pamelloes, tekmo has a really good article about >=>
21:23:38 <Pamelloes> solrize: Can you link to it?
21:23:42 <solrize> looking
21:24:17 <erisco> :t Kleisli
21:24:19 <lambdabot> (a -> m b) -> Kleisli m a b
21:24:35 <erisco> note that Kleisli m is an Arrow for Monad m
21:24:48 <erisco> just a fun fact :)
21:24:53 <Pamelloes> Kleisli is right about where I got completely confused in the Typecalssopedia.
21:25:12 <erisco> notice how the arrow in this case is "-> m"
21:26:39 <solrize> http://www.haskellforall.com/2012/08/the-category-design-pattern.html  hmm i remembered it a little differently
21:26:55 <Pamelloes> What makes >=> so special that it starts getting into Arrows and stuff? It looks to me like it's just (>=>) f g a = do t <- f a; g t
21:27:13 <solrize> and it uses <=<
21:29:25 <solrize> but yeah its a good article and it explains where the monad laws come from
21:30:23 <SrPx> Is it possible that GHC doesn't pick a specialized method for an instance? Because I created an Unbox instance for ListIso, yet the performance when I use certain functions is that of lists, not unboxed vectors. I know it can't be, because if I just manually use unboxed vectors functions directly the performance is dramatically superior.
21:30:53 <SrPx> This is my instance declaration: http://lpaste.net/139325 GHC is definitely not picking those functions and is picking the list ones instead
21:31:33 <pacak> SrPx: Look at generated core/stg
21:31:43 <SrPx> --ddump-simpl?
21:31:56 <pacak> yep
21:32:30 <pacak> -ddump-to-file and -dsuppress-all also help
21:32:30 <pacak> You'll see what exactly it's trying to do.
21:32:34 <SrPx> 4000 lines I don't understand any of it
21:33:38 <eskatonic> quit
21:33:56 <pacak> SrPx: stackoverflow.com/questions/6121146/reading-ghc-core
21:34:22 <erisco> Pamelloes, there is nothing special other than it is an Arrow
21:34:42 <erisco> Pamelloes, it is like asking why (a,b) is so special that it is a Functor
21:34:52 <pacak> SrPx: being able to read core and stg helps
21:35:25 <Pamelloes> erisco: Fair enough. Though Arrows are still special magic voodoo in my eyes (albeit less so than an hour ago :)
21:35:46 <GrapeSoda> Hey folks. So I'm working on a GID library that converts lat/lon pairs into human-friendly strings. Unfortunately, Doubles do not have sufficient numerical accuracy for my algorithm. BigFloat works, but it is very slow. Anyone have any suggestions for high-accuracy numbers with Floating instances?
21:35:51 <GrapeSoda> s/GID/GIS
21:36:44 <pacak> :t Pico
21:36:45 <lambdabot> Not in scope: data constructor ‘Pico’
21:36:45 <tomberek> @pl: f a b = b
21:36:45 <lambdabot> f = const id
21:36:49 <pacak> Hmmm...
21:37:06 <pacak> GrapeSoda: There's Data.Fixed
21:37:18 <GrapeSoda> pacak: It doesn't have a Floating instance
21:37:22 <GrapeSoda> I need to take sqrt
21:37:24 <erisco> note that Arrow contains 'arr' and I don't think it should be there
21:37:29 <erisco> maybe it should, but I don't get why
21:37:43 <GrapeSoda> erisco: Many agree with you
21:37:58 <GrapeSoda> It is a reasonable opinion that arr is "too powerful"
21:38:13 <erisco> I heard it from the many first, then when I started working with Arrows I too began to wonder
21:38:17 <tomberek> erisco: GrapeSoda: I'm working on an arrow improvement right now. I could use some feedback.
21:38:22 <tomberek> It's an optimizer.
21:38:56 <pacak> GrapeSoda: Depending on how often you need to use sqrt compared to other operations you can implement it your self
21:39:04 <tomberek> basically it takes proc-do syntax and tries to parse it without using `arr`. It also can apply the CCA optimization. [https://hackage.haskell.org/package/CCA]
21:39:10 <erisco> it'd be more reasonable to have  c a b -> c' a b  as a separate thing
21:39:11 <SrPx> pacak: ... thank you... this is the file: http://lpaste.net/139327 - I read that SO answer, yet I don't think I'll be able to read that file any soon. I'm not sure what to do.
21:39:15 <pacak> Or change your code to avoid using sqrt - it might be possible at all.
21:39:15 <erisco> I don't know what that thing would be
21:39:28 <erisco> but if you want to translate from one category to another, there you go
21:39:56 <rpfun> this is not valid haskell to my knowledge, but suppose i have "newtype A a = A :: a", and "type B l e = A (l e)", can i have (for example) an applicative instance for (B l) and for A? is there some way to emulate this?
21:40:15 <GrapeSoda> pacak: I might be able to do that, but it will be  a pain compared to using the Floating instance. I'm using Data.Dimensional, which has its own version of sqrt.
21:40:26 <rpfun> without adding newtypes
21:40:28 <tomberek> erisco: GrapeSoda: do you have any arrow code that I can look at? How often do you use proc-do syntax in a manner that requires arr, or is it mostly tupling, diag, shuffling, etc?
21:40:42 <pacak> GrapeSoda: I mean you can implement your own Floating instance
21:41:04 <GrapeSoda> pacak: People have tried for Data.Fixed. Apparently it is not pretty
21:41:11 <erisco> tomberek, I don't, it'd be lost somewhere in a backup it has been a long time
21:41:57 <tomberek> erisco: i'm just looking to real-world examples, perhaps a benchmark to test against
21:42:22 <Pamelloes> I can't believe I've been working in Haskell for almost half a year now, and only just encountered (<=<)......
21:42:38 <Pamelloes> Monads make so much more sense now :)
21:44:25 <pacak> SrPx: Try again with -duppress-all - it will make it less  verbose
21:45:38 <mjrosenb> do lenses and arrows play nicely together?
21:46:59 <tomberek> mjrosenb: https://www.reddit.com/r/haskell/comments/1nwetz/lenses_that_work_with_arrows/
21:49:44 <SrPx> pacak: I think I see the problem... interesting. Thanks
21:49:51 <mjrosenb> cool.
21:49:54 <SrPx> It is not that scary
21:50:13 <mjrosenb> next question, possibly related:
21:50:49 <mjrosenb> if I have data Poly a = Poly { _a :: a, _b :: a, _c :: Int }
21:51:20 <mjrosenb> can I write a function with type Poly Int -> Poly bool via (==4)?
21:52:22 <mjrosenb> s/bool/Bool/
21:52:50 <pacak> mjrosenb: Yes.
21:52:59 <tomberek> mjrosenb: sure   f g (Poly a1 a2 i) = Poly (g a1) (g a2) i   where g is (==4)
22:07:58 <tomberek> i'm not a fan of the records package switching to a preprocessor, what other nice record solutions are there?
22:10:27 <erisco> so what is an improper lens
22:10:41 <Romefeller> Hi all
22:10:45 <edwardk> it used the wrong fork for the salad course
22:10:56 <pacak> erisco: Lens must obey some laws.
22:11:13 <Romefeller> anyone knows Yesod?
22:11:19 <Romefeller> i have a quick question
22:11:45 <erisco> why would this lib involve the complications of lenses if it isn't even going to do them right
22:11:59 <edwardk> erisco: ?
22:12:21 <edwardk> erisco: the lens library includes a bunch of laws. it doesn't depend on those laws. the code still works if you break them
22:12:37 <edwardk> what breaks is a.) your ability to reason about things using those laws and b.) the universality of the constructions i use
22:13:04 <edwardk> e.g. you can't care if 'over' reads in one pass and then in another pass modifies the structure, so long as your lens is law-abiding.
22:13:22 <edwardk> if it isn't then you may have situations where doing things like over l f . over l g = over l (f . g) doesn't hold.
22:13:36 <edwardk> and that becomes something you have to reason through operationally on a case by case basis
22:13:45 <edwardk> but all the combinators we give you still work and are useful
22:13:56 <edwardk> they just aren't 'unique' necessarily any more
22:14:06 <erisco> unpack :: Monad m => Lens' (Producer Text m r) (Producer Char m r)
22:14:25 <erisco> this just had to be Pipe Text Char m r
22:14:30 <erisco> I don't know what is going on with it really
22:15:33 <johnw> erisco: it gives you a way of working with the Char producers "within" each Text segment
22:15:48 <edwardk> it is occasionally useful to lie in a lens a little bit. or to have a lens that isn't quite able to handle all the values of the viewed range and may do a bit of normalization. e.g. consider something that looks at a date and then lets you set the hour. unless you enumerated TwelveOClock etc, in a data type, it probably has some Int it views. reading and
22:15:48 <edwardk> writing that Int may fail the laws, but its still useful
22:16:04 <edwardk> for that unpack thing... well, thats between you and Tekmo =)
22:16:13 <tomberek> edwardk: quick update, i've got the arrow optimizer a bit further along. It needs polish, but can parse basic proc-do. It also uses a dataflow graph to use ***/&&& more than built-in proc-do uses. 
22:16:21 <edwardk> he seems to get a lot of mileage out of using lenses a little bit wrong in the pipes stuff
22:16:36 <johnw> i.e., a Producer of Text a structural superset of a producer of Char
22:16:49 <erisco> this is not tekmo unless tekmo is Michael Thompson
22:16:54 <johnw> if you try writing the lens yourself, it should become pretty clear
22:17:17 <edwardk> erisco: http://www.haskellforall.com/2014/02/pipes-parse-30-lens-based-parsing.html
22:17:39 <edwardk> ^- that notion of fiddling with producers and pipes and the like with lenses came from tekmo
22:18:16 <edwardk> that article also covers why he uses the combinators that way
22:22:20 <erisco> johnw, well I don't know lenses, so it is kind of a bummer
22:22:34 <erisco> is there an easy way to get the pipe?
22:22:44 <johnw> view on a producer
22:23:14 <johnw> likewise, you can "set" to modify the chars of a producer of text
22:27:41 <johnw> erisco: have you ever written a Traversable instance?
22:27:47 <erisco> yes
22:27:53 <johnw> so, writing a lense is almost the exact same thing
22:28:08 <johnw> :t traverse
22:28:09 <lambdabot> (Applicative f, Traversable t) => (a -> f b) -> t a -> f (t b)
22:28:16 <erisco> expanding the alias gives me http://lpaste.net/139332
22:28:20 <erisco> I don't know what the function is anymore
22:28:34 <johnw> whereas a lens is: (a -> f b) -> s -> f t.  So if you set s ~ t a and t ~ t b, you can see the resemblance
22:28:57 <johnw> as a result, the code for a lens is written in much the same "style" as an implementation of traverse
22:30:00 <erisco> I don't know what the unpack function is doing
22:30:20 <erisco> I want a producer of Char, so I don't know why it is giving me yet another producer of Text
22:30:26 <erisco> though the name suggests it is what I want
22:30:35 <johnw> so, let's say you have a producer of text named "p"
22:30:43 <johnw> p ^. unpack
22:30:47 <johnw> will be a producer of char
22:31:08 <johnw> the reason why lenses are kind of awesome for this
22:31:17 <johnw> is it gives us a way of manipulating the "chars within the text"
22:31:50 <erisco> well that is what going from a producer of text to a producer of char is supposed to do in the first place
22:31:57 <johnw> yep
22:31:58 <erisco> it is supposed to let me work on the text per character
22:32:01 <erisco> so why the lens
22:32:03 <johnw> in conduit, this is done with two sets of functions
22:32:10 <johnw> one for working on "chunks" and one for working on "elements"
22:32:17 <johnw> with the lens abstraction, we don't need to bifurcate like that
22:32:31 <johnw> because elements are conceptually within the structure of chunks
22:32:41 <johnw> and lens is all about focusing on elements within structures
22:33:11 <erisco> did you see my pastebin?
22:33:21 <johnw> yea
22:33:27 <erisco> what is going on with that type?
22:33:28 <johnw> that's the lens type I gave above
22:33:32 <johnw> (a -> f b) -> s -> f t
22:33:40 <johnw> to understand what's going on with that type, watch http://ftp.newartisans.com/pub/Lenses.mp4
22:33:40 <erisco> I especially don't get the  (Pipes.Producer Char m r -> f (Pipes.Producer Char m r))  oart
22:33:47 <erisco> part
22:33:52 <erisco> forget lens, what is this doing
22:33:56 <johnw> that IS lens
22:34:08 <edwardk> erisco: lets just look at forall f. Functor f =>  (a -> f b) -> s -> f t and see what it _must_ do
22:34:16 <erisco> no no
22:34:16 <johnw> I'll let the expert explain :)
22:34:18 <edwardk> it needs to build some 'f t' at the end, right?
22:34:20 <erisco> look, lens is cool, I get it
22:34:26 <erisco> but right now this is just text and chars
22:34:29 <johnw> but the video I linked to motivates this type very, very nicely
22:34:35 <erisco> and some pipes, I understand some pipes
22:34:44 <edwardk> erisco: you are demanding us to tell you what that means but you don't want to let us stop and tell you what it means
22:34:51 <edwardk> so please pick
22:35:10 <erisco> you're just explaining lens
22:35:14 <erisco> nevermind, I just don't want to right now
22:35:15 <edwardk> i'm explaining that type
22:35:22 <edwardk> i don't care if you use the lens library to talk about it
22:35:28 <johnw> understanding that type will make everything else clear
22:35:40 <edwardk> but forall f. (Pipes.Producer Char m r -> f (Pipes.Producer Char m r)) -> (Pipes.Producer Text m r -> f (Pipes.Producer Text m r))
22:35:46 <edwardk> is just a special case of a more general type
22:35:47 <edwardk> er
22:35:57 <edwardk> Functor f => (Pipes.Producer Char m r -> f (Pipes.Producer Char m r)) -> (Pipes.Producer Text m r -> f (Pipes.Producer Text m r))
22:36:07 <edwardk> and its easier to pick apart with less noise
22:36:17 <edwardk> so a = Pipes.Producer Char m r      lets us see what the hell is going on
22:36:21 <edwardk> (a -> f b) -> s -> f t
22:36:57 <edwardk> here we need to build some 'f t' which i don't care what it is right now, and i don't get to know 'f', so the only way i have to build it is with that function i'm given
22:37:15 <edwardk> so any combinator with this type has to _somehow_ get an 'a' out of the 's' it is given.
22:37:22 <edwardk> and call that function to get an 'f b'
22:37:35 <edwardk> it has no way to stick together 'f's using just a Functor, so it can only meaningfully do this once
22:38:22 <edwardk> then it has some 's' in the environment to use, and it has to get under the 'f' to convert b -> t, the only thing it has for that is fmap, so it can fmap some way to map from b -> t, which has access to 's' 
22:38:22 <pacak> Playing aroud with ghc from git. Warnings it produces when failing to specialise something are nice.
22:38:24 <edwardk> thats it
22:38:55 <edwardk> now, if you want to throw laws on top of it, great, and you can then call it a lens, but what this is is a 'getter: s -> a' and  'setter: s -> b -> t' in disguise as something manipulating functors
22:39:26 <edwardk> so he's giving you the ability to read a Producer Char m r   from a Producer Text m r
22:39:45 <edwardk> and a way to 'plug another Producer for Char's into a Producer for Text.
22:39:47 <edwardk> whatever that means
22:39:50 <edwardk> that is what he's doing
22:40:28 <edwardk> whether the crazy stuff he's doing with producers there passes the lens laws, i don't actually happen to know
22:40:32 <edwardk> i'm somewhat dubious
22:40:54 <edwardk> but it does work operationally with the lens combinators
22:49:58 * hackagebot coverage 0.1.0.0 - Exhaustivity Checking Library  https://hackage.haskell.org/package/coverage-0.1.0.0 (NicolasDelPiano)
22:54:58 * hackagebot coverage 0.1.0.1 - Exhaustivity Checking Library  https://hackage.haskell.org/package/coverage-0.1.0.1 (NicolasDelPiano)
23:14:42 <rhovland> getting an error about ExposePackage when I try to install ghc-mod
23:42:17 <SrPx> Is it possible to define two versions of a function, one will be used only if a type has an Unbox instance, the other otherwise?
23:57:36 <quchen2> SrPx: There is no "case for types".
