00:23:40 <jle`> dminuoso: not curried, but partially applied
00:24:09 <dminuoso> jle`: err yeah thats what I meant :)
00:24:37 <jle`> i figured :)
01:01:36 <tsahyt> say I've got an AST, and I want to obtain a list of all arithmetic expressions contained somewhere in that tree. is there some simple lensy way to do this?
01:02:56 <tsahyt> i.e. without having to specify each exact path to where those might be
01:45:02 <kuribas> is it possible to export submodules qualified?
01:45:22 <merijn> kuribas: What do you mean? When re-exporting, you mean?
01:45:25 <kuribas> yes
01:45:32 <merijn> kuribas: No, that'd be horrifically brittle
01:46:11 <kuribas> it's just, we have a big hierarchy of classes (in lisp), I though I could model it with a haskell modules
01:46:49 <merijn> kuribas: I mean, what if the "qualified re-export" clashes with a prefix someone is already using for another qualified import?
01:47:14 <kuribas> merijn: choose another prefix?
01:47:51 <merijn> kuribas: That just means you piss off users
01:48:04 <merijn> kuribas: Why do they have to be qualified?
01:48:16 <kuribas> it just to bring some order in it.
01:48:30 <kuribas> and to avoid having a long import list
01:48:50 <merijn> kuribas: But why not just re-export without a qualification then?
01:49:09 <kuribas> merijn: then it looses the structure?
01:50:36 <merijn> kuribas: Why is the structure relevant?
01:50:50 <kuribas> merijn: it's how our app is written
01:51:03 <merijn> kuribas: You have a lot of implicit assumptions on what you want that you are not articulating, which doesn't really help when asking questions like this :)
01:51:24 <kuribas> merijn: we have classes like this: "/im/Object/PVModules"
01:51:31 <kuribas> it's a big hierarchy
01:51:40 <kuribas> I am thinking of a way to preserve that
01:52:30 <kuribas> but maybe leaving the imports to the library user is ok...
01:52:37 <kuribas> if a bit verbose
01:53:23 <merijn> Most likely the answer is "you don't". I mean, is it likely for someone to need the entire hierarchy? If not, why have a way of importing the entire thing? And if they do, why is it a hierarchy?
01:56:47 <kuribas> merijn: I suppose you're right
02:32:53 <tsahyt> @hoogle (Maybe a, Maybe b) -> Maybe (a,b)
02:32:54 <lambdabot> Agda.Utils.Maybe unzipMaybe :: Maybe (a, b) -> (Maybe a, Maybe b)
02:32:54 <lambdabot> Agda.Utils.Maybe.Strict unzipMaybe :: Maybe (a, b) -> (Maybe a, Maybe b)
02:32:54 <lambdabot> Prelude unzip :: [(a, b)] -> ([a], [b])
02:44:11 <mniip> tsahyt, that's the (**) applicative operator
02:44:19 <mniip> not sure if it's available in a library somewhere though
02:44:40 <tsahyt> oh
02:45:05 <tsahyt> well, turns out that I need to treat them separately anyhow, the type I looked at wouldn't have the semantics I need
02:45:36 <mniip> :t liftA2 (,)
02:45:38 <lambdabot> Applicative f => f a -> f b -> f (a, b)
02:45:48 <mniip> the exact operator would be
02:45:55 <mniip> :t uncurry (liftA2 (,))
02:45:57 <lambdabot> Applicative f => (f a, f b) -> f (a, b)
02:46:07 <mniip> but likely you don't need the tuple
02:46:30 <tsahyt> ah I see
02:59:10 <duairc> So I'm trying to learn recursion-schemes, I think I get it, but I don't have an intuition yet for which recursion schemes to solve specific problems
02:59:39 <duairc> I've made a gist with a simplified version of a problem I'm currently working on if anyone wants to give me a hand:
02:59:42 <duairc> https://gist.github.com/duairc/3aa5c72399c9cdeea0f352d01ba6ff2d
03:06:35 <berndl> duairc: My intuition is folds for reducing and unfolds for building.
03:08:02 <duairc> berndl: Yes, but I think for my specific problem I need one of the more exotic ones, unless I'm missing something
03:08:25 <dminuoso> mniip: I wish we had a class Monoidal instead of Applicative.
03:08:36 <dminuoso> It finally completely clicked - Applicative feels rather strange now. ;)
03:08:40 <berndl> The more exotic ones are just variations or combinations of fold/unfold.
03:08:56 <mniip> dminuoso, no MPTCs and FunDeps in base
03:09:23 <berndl> dminuoso: Same here. But Monoidal would not be the correct name though.
03:09:48 <dminuoso> berndl: monoidal in the sense of monoidal functor.
03:10:01 <berndl> dminuoso: yes, but that's too vague.
03:10:27 <berndl> It should be monoid functor where the source and target tensors are the Cartesian product.
03:10:39 <duairc> berndl: Fair enough. But I guess I'm not sure how my problem breaks down into folds and unfolds.
03:10:40 <dminuoso> berndl: You can call it Smashy or StrongLaxMonoidal as far as I care :P
03:10:57 <berndl> dminuoso: Let's call it Applicative then ;)
03:11:20 <dminuoso> berndl: But the thing is, Applicative carries the notion that it's something about "function application"
03:11:28 <dminuoso> :t (<*>)
03:11:29 <lambdabot> Applicative f => f (a -> b) -> f a -> f b
03:11:52 <berndl> dminuoso: So?
03:18:11 <berndl> I guess the "function application" part of Applicative comes from the fact that Applicative is a monoid in the monoidal category of endofuctors where the tensor is Day convolution?
03:25:06 <jle`> duairc: for things that aren't simple cata's/ana's, sometimes i like to write the explicitly recursive version first, and then see if i can refactor it into a cata or ana
03:25:32 <jle`> dminuoso: the function application notion is a red herring, i think
03:26:13 <jle`> if you think of it in terms of being able to liftA2 f, then that's just liftA2 ($)
03:26:24 <jle`> just one possible function (out of many) that can be liftA2'd
03:27:09 <jle`> the fact that you can liftA2 a function can be considered an important thing
03:27:18 <jle`> *can be considered the important thing
03:27:32 <jle`> and so being able to liftA2 ($) is just incidental to that
03:27:49 <jle`> duairc: oh i just noticed in your gist, that's what you do
03:28:56 <duairc> jle`: Well, sort of! I actually use recursion schemes to make the function I have "more recursive", if that makes sense. Though yes, I used explicit recursion to write that one and I probably need to convert that too
03:29:03 <duairc> *I actually want to use
03:29:15 <jle`> or i mean, that's what you are in the process of doing, heh
03:29:46 <jle`> recursion schemes for reiting Expr -> Expr gives you two options
03:30:14 <jle`> you can either use ana/apo/etc., to build the Expr from the top-down by breaking up the first one from the top down
03:30:28 <jle`> or you can use cata/para/etc. to build the Expr from the bottom-up by breaking up the first one from the bottom-up
03:31:24 <jle`> duairc: i assume you've already had some practice writing things like 'eval' ?
03:31:37 <jle`> (which is a straighforward catamorphism)
03:32:21 <jle`> one thing that really helped for me is jumping into a ghci session or using typed holes and start just seeing the type of things that are expected
03:33:30 <jle`> i believe with this one you should be able to use either ana/apo/etc. or cata/para/etc., so try just jumping in and writing: rightAssociateAdd = ana _, cata _, etc. until things fit the shape you want
03:34:24 <jle`> this presentation was pretty helpful for me https://github.com/willtim/recursion-schemes
03:35:23 <duairc> jle`: I hadn't seen that presentation, cool, I'll check it out
03:35:49 <duairc> jle`: And yes, I can write eval, etc. I guess I can 
03:35:57 <duairc> I guess I can just poke the types until they fit
03:36:41 <duairc> I just haven't done this sort of thing maniuplating ASTs before, and I'm just wondering if I'm missing something
03:43:21 <pamir> is there any ORM in haskell?
03:45:25 <jle`> duairc: there is one thing to note that i see, from from working with these in the past
03:45:53 <jle`> duairc: the `go (Add a b) rest = go a ...` is a "left-fold" kind of pattern
03:46:27 <jle`> "tail-recursive", so to speak
03:47:19 <jle`> if you want to wrie that using a catamorphism, then often you want to build a continuation, and then run that continuation at the end
03:47:31 <jle`> see the 'foldl' example in the presentation i linked, for an example of this
03:48:39 <duairc> jle`: Like how difference lists work?
03:49:37 <mniip> 11/21/2018 [14:17:50] 18<berndl18> I guess the "function application" part of Applicative comes from the fact that Applicative is a monoid in the monoidal category of endofuctors where the tensor is Day convolution?
03:50:01 <mniip> I think dminuoso is trying to say the lax monoidal definition of applicative generalizes to non-CCC categories
03:50:03 <mniip> whereas <*> does not
03:56:17 <mniip> class (Monoidal p, Monoidal q, Functor f, Dom p ~ Dom f, Dom q ~ Cod f) => LaxMonoidal f p q where liftUnit :: Cod f (Id q) (f (Id p));  liftMonoid :: Cod f (q (f x) (f y)) (f (p x y))
03:57:29 <mniip> where Dom,Cod are associated types of Functor and Id is the associated type of Monoidal
03:59:14 <mniip> and Monoidal p has a superclass constraint (Functor p, NT (Dom p) (Dom p) ~ Cod p)
04:41:00 <marxS> im trying to run this: https://paste.ofcode.org/E2Fz6jpVq77hW2BNkbET8V , but I get an error that the compiler cant make a derived instance of the functor
04:41:54 <opqdonut> do Q.Seq and BidT have functor instances?
04:42:22 <opqdonut> even if they do I'm not sure even GeneralizedNewtypeDeriving can derive that Functor instance
04:42:40 <marxS> BidT is just a tagged type, so yes on that
04:43:15 <opqdonut> oh right and it's not even a newtype
04:43:52 <opqdonut> ah the extension is DeriveFunctor
04:44:22 <marxS> what do you mean the extension is DeriveFunctor?
04:45:04 <opqdonut> the language extension that lets you derive Functor
04:45:17 <marxS> oh lol
04:46:21 <marxS> so i just need a bunch of pragmas?
04:46:42 <marxS> and then it compiles lol
04:48:30 <c_wraith> Such is modern development with GHC.  So many helpful things in extensions that you rarely code without them.
04:48:32 --- mode: glguy set +v lost_
04:48:34 <Solonarv> you need a bunch of /language extensions/, yes; a {-# LANGUAGE Blah #-} pragma is one way of enabling extensions, but not the only on
04:49:28 <Ariakenom> % :set -XDeriveFunctor
04:49:29 <yahb> Ariakenom: 
04:49:55 <Solonarv> you can also, for example, enable them in your .cabal file: https://github.com/Solonarv/interfreter/blob/master/interfreter.cabal#L32-L35
04:50:05 <merijn> But you shouldn't...
04:50:41 <Solonarv> Eh, that's a rather lengthy discussion
04:50:54 * Ariakenom takes a seat
04:51:00 <Putonlalla> I was recently disappointed by not being able to say `{-# LANGUAGE Some #-}` and use `-XCPP -DSome=...` to define the set of extensions I want to put there.
04:52:15 <matheus21> Hi! I can't use ghc-8.6.2 in archlinux anymore, since it complains about a missing libHShaskeline-ghc-8.6.2.so
04:52:23 <matheus21> did anyone else have this error?
04:52:25 <merijn> Ariakenom: It's not that long tbh: "Putting it in the cabal file means you have to look at multiple files to see what's going when reading the source, having pragma's at the top is easy to spot"
04:52:46 <merijn> matheus21: Have you consulted the Arch wiki on Haskell (and how they like to fuck up their packages) yet?
04:52:47 <matheus21> I tried reinstalling ghc-static in archlinux
04:52:58 <Rembane> I put all the good stuff in my local ghc configuration.
04:54:03 <Solonarv> counterargument: I don't like having a screenful of language pragmas at the top of each file, and the cycle of 'use extension -> get error -> "oh, I need this extension" -> add it -> repeat for other extension' is irritating
04:54:33 * hackage oblivious-transfer 0.1.0 - An implementation of the Oblivious Transfer protocol in Haskell  http://hackage.haskell.org/package/oblivious-transfer-0.1.0 (sdiehl)
04:54:42 * Ariakenom tries to remember where he put the popcorn
04:55:17 <Solonarv> as long as they *only* enable new syntax/code (e.g. LambdaCase, MPTC) I don't see much harm in putting them in the cabal file.
05:00:49 <mniip> Solonarv, I mean honestly I get what you mean, but there's no way to realistically standardize RankNTypes
05:01:01 <mniip> or TypeFamilies
05:04:33 <Solonarv> "standardize"? wdym?
05:08:03 * hackage aern2-mp 0.1.3.1 - Multi-precision ball (interval) arithmetic  http://hackage.haskell.org/package/aern2-mp-0.1.3.1 (MichalKonecny)
05:08:13 <marxS> what does it mean if we have a data constructor with nothing after? so just:
05:08:17 <marxS> data Bid
05:08:35 <merijn> marxS: That's a type constructor, not data constructor
05:08:47 <merijn> marxS: It defines a type "Bid" that has no constructors
05:09:06 <marxS> then why not just use new type or type
05:09:37 <merijn> marxS: type is just an alias for an existing type and newtype's must have exactly 1 constructor, so neither of those do the same thing?
05:09:43 <marxS> oh
05:09:45 <marxS> tyvm
05:10:03 <Ariakenom> marxS: No constructors mean you can't construct values of that type. Except bottom, like an exception
05:10:40 <duairc> I've updated my gist where I'm trying to figure out recursion schemes. https://gist.github.com/duairc/3aa5c72399c9cdeea0f352d01ba6ff2d
05:11:26 <duairc> So now rightAssociateAdd can recurse through multiply, and it "uses" recursion schemes, barely... but my 'recurse' seems like a code smell. It looks sort of like hylo, but not really?
05:14:55 <duairc> Okay, let's take a simpler example
05:15:07 <duairc> Let's say I have a binary tree and I'm trying to turn it into a list
05:15:08 <duairc> https://gist.github.com/duairc/b1c00f1569b57babad322aa066632ff4
05:15:20 <duairc> This works, but it's kind of cheating, because it's just defined in terms of ++, which is itself recursive
05:15:34 <duairc> How do I define toList so that all the recursion is going through recursion-schemes?
05:15:50 <merijn> duairc: Honestly, I've never really found all the complexity of recursion-schemes to be worth it
05:19:34 <dmwit> duairc: Do you consider (.) recursive?
05:20:03 <duairc> merijn: Maybe... I'm working on a real project that has a huge ADT with loads of recursive constructors describing an AST. And I have a load of "optimizations" I want to apply to it. Using explicit recursion gets really messy really quickly. I feel that if I can "grok" recursion-schemes I could tidy it up a lot. Even if don't even end up using recursion-schemes itself, I think if I grokked it I'd have a 
05:20:09 <duairc> better intuition for this kind of thing
05:20:26 <dmwit> duairc: If not, perhaps the difference-list trick would suit you, as in `cata go [] where go (LeafF a) = (a:); go (BranchF a b) = a . b`
05:21:18 <merijn> duairc: I remember a blogpost by johnw about using recursion-schemes for that, maybe it'll help if you haven't seen it yet?
05:21:21 <merijn> duairc: http://newartisans.com/2018/04/win-for-recursion-schemes/
05:21:39 <merijn> duairc: That has a bunch of non-trivial examples with ASTs
05:22:02 <duairc> dmwit: Yes, I think that's the leap I was struggling to make, or some of it at least
05:22:46 <duairc> dmwit: Thanks
05:22:54 <duairc> merijn: Cool, I'll check out that post, I hadn't seen it
05:25:09 <dmwit> Odd, recursion-schemes doesn't appear to have anything for metamorphisms, which seems like what you would want here if you didn't want to use the difference-list trick.
05:31:25 --- mode: glguy set +v fen
05:31:50 <fen> is it possible to make one of a chain of composed functions jump to the front without storing them in a list?
05:34:41 <fen> the idea is to preserve lazyness, ie if an argument is not called, the chain of applications of functions to it isnt either
05:34:52 <Solonarv> so, you want to turn 'f . g . h . i . j . k' into 'j . f . g . h . i . k' ?
05:37:14 <fen> well, suppose only 2 types of function, f and g, such that g composed like; g . g . g . g = foldl (.) id (replicate n g), but then if (f . (g . g ...)) becomes (g . g ...) . f
05:37:52 <fen> if the functions were stored in a list, then updating this list might not be lazy?
05:39:20 <Solonarv> what, you want to automatically rewrite 'f . (g . g . ...)' into '(g . g . ...) . f' ?
05:39:52 <fen> yes
05:39:58 <fen> take e.g. (c a,b), and function :: (c a,b) -> Either (forall a. c a -> c a) (c a -> c b)
05:40:27 <fen> and then apply the function returned,stored by the Either, and apply it to the rhs
05:40:50 <fen> repeatedly applying this function, results in a chain of functions being applied to the lhs
05:41:15 <fen> (sorry, the function returned in the Either is applied to the *lhs*)
05:41:56 <Solonarv> functions are opaque, so you can't inspect them; this means you can't reorder arguments to (.)
05:41:57 <fen> but the idea is that the (c a -> c b) jumps to the front of the chain of applications
05:42:27 <Solonarv> you can, however, stick them in some kind of list, and *then* reorder them
05:42:53 <fen> because the functions dont fire until the first value of the pair is inspected, it is lazy to compose with (.)
05:43:00 <fen> but reordering the list isnt?
05:43:20 <Solonarv> depends on which list you use
05:43:38 <fen> which list?
05:44:16 <fen> actually, there is no need to reorder a list, as the functions that jump to the front can be applied directly by composing with (.)
05:44:58 <fen> the only important thing is that they happen before the chain of the other type of function
05:45:39 <Solonarv> You're wanting to reorder a chain of functions composed with (.). You can't do that; instead you have to stick the functions in some datastructure, reorder them, and only at the final step compose them with (.)
05:46:04 <fen> as long as doing that is lazy in the same way as composing with (.) would be, then its ok
05:47:40 <Solonarv> Sure, it can be lazy if you want. Depends on the data structure you're using.
05:47:41 <fen> for instance, rather than storing them in a list, as they are all the same, and this is known before (there is only one value of type `forall a. c a -> c a' that will ever be returned on the lhs of the Either) then an Int can be used instead of a list 
05:48:14 <fen> and then the fucntion can have the type :: (c a,b) -> Maybe (c a -> c b)
05:48:28 <fen> and if it returns Nothing, then the Int is incremented 
05:48:33 <Solonarv> if you know the 'forall a. c a -> c a' is always the same, your function should probably have a different type.
05:49:08 <fen> this allows the question of lazyness to be in terms of, is that incramenting the Int lazy?
05:49:58 <Solonarv> it is, but you can make it strict with judicious use of bang patterns and/or seq
05:50:34 <fen> ((Int,c a),b) -> Maybe (c a -> c b) can then be used to make ((Int,c a),b) -> ((Int,c a),b) 
05:51:03 <fen> hmm, no thats wrong
05:51:13 <fen> ((Int,c a),b) -> Maybe (c a -> c a) can then be used to make ((Int,c a),b) -> ((Int,c a),b)
05:52:04 <fen> but if the first value of this pair is never accessed, it should not incur computational cost to update the Int
05:53:12 <Solonarv> Sure. instead it might incur computational cost because you're building up an enormous thunk.
05:53:15 <fen> basically, this function is a navigation on an adjacent column of a pointer on a 2d grid. 
05:53:55 <WhatisRT> @free
05:53:55 <lambdabot> Try `free <ident>` or `free <ident> :: <type>`
05:54:08 <fen> Solonarv: more than if it functions were composed using (.) ?
05:54:33 * Solonarv hand wiggles
05:54:33 <fen> there are as many updates to the Int as functions composed with (.) so is this thunk just as big?
05:54:37 <Solonarv> about the same?
05:54:47 <Solonarv> *if* you're building thunks on both cases
05:54:59 <fen> yes, the lazyness is desired
05:55:19 <Solonarv> but adding ints together is fast, so you might want to do that strictly anyway.
05:55:33 <merijn> You *definitely* want to do that strictly
05:55:48 <fen> if the current column is navigated, the adjacent column should recieve the same navigation, but it should not fire until it is accessed, to allow a function to be applied to the column before it is navigated
05:56:00 * Solonarv head shakes
05:56:23 <Solonarv> you're thinking in imperative terms; unless you're doing really weird stuff laziness doesn't affect semantics, only performance
05:56:33 * hackage sized-grid 0.1.1.6 - Multidimensional grids with sized specified at compile time  http://hackage.haskell.org/package/sized-grid-0.1.1.6 (edwardwas)
05:56:50 <fen> otherwise it would have to be navigated in reverse to get the whole collumn visible to be mapped over
05:56:57 <fen> and then renavigated
05:57:12 <fen> which is going to be more expensive than storing the thunk
05:57:13 <__monty__> Solonarv: Laziness affects semantics even in very basic stuff though : >
05:57:19 <Solonarv> I'd ask for a code paste, but if the past is any guide that wouldn't help me at all
05:57:36 <Solonarv> __monty__: fair enough, it might affect whether your program terminates at all.
05:58:11 <Solonarv> It shouldn't cause you to get a *different* answer, though (in pure code where you can't catch exceptions)
05:58:45 <fen> here, lazness is being kind of emphasised more than normal, as not only should the navigations not fire until accessed, if there is an fmap opperation on the adjacent column, this needs to happen before the navigations
05:59:21 <fen> normally it would be enough just to have columns that are not accessed not have the navigations explicitly performed on them
05:59:30 <Solonarv> what do you think happens if you modify the int strictly? fmap mutates the wrong columns?
05:59:49 <fen> but for the comonad Pointer instance, every value is replaced with the structure navigated to point to this location
06:00:36 <fen> if the pointer is navigated to some location before duplicate, every value must be updated, and it would be no good to have to undo navigations left lazily unapplied to adjacent columns
06:01:46 <WhatisRT> @free f :: (a -> m Bool) -> [a] -> m (Maybe a)
06:01:46 <lambdabot> Plugin `free' failed with: src/Lambdabot/Plugin/Haskell/Free/Type.hs:(152,17)-(160,45): Non-exhaustive patterns in case
06:02:20 <Solonarv> Oh boy.
06:02:43 <Solonarv> fen: could you provide a (readable!) paste explaining what you're trying to do?
06:03:22 <fen> Solonarv: the problem with the strict update of the Int (which is capturing this deffered navigation, instead of lazyness) is that it would not be lazy. that is, while lazily navigating the adjacent column to keep it at the same location as the current column should incur no computations other than thunk storage, and so if that column is never accessed, no navigation occurs, strict update of the Int would happen to every column, and th
06:04:32 <Solonarv> okay, I definitely want a code sample now. I don't know what your data type looks like and I don't know what operation you're implementing.
06:04:34 <fen> perhaps the claim is that strict int updates could be actually less intensive than thunk storage!?
06:05:04 <fen> (Solonarv. its that 700 line long graph paste....)
06:05:42 <Solonarv> could you extract *just* the part you're actually asking about?
06:07:00 <fen> it might be easier just to recognise the datatype as data Zipper a = ([a],[a]), type SquareGrid a = Zipper (Zipper a)
06:07:03 <dmwit> If you have only two functions f and g, and you want all applications of f to jump to the front, perhaps you can just store how many times each of f and g are composed.
06:07:22 <dmwit> That is, instead of `f . f . f . g . g` or `[f,f,f,g,g]`, store `(3,2)`.
06:07:35 <dmwit> It is easy to increment or decrement one of the two numbers in a tuple.
06:07:39 <fen> dmwit, thats what the Int is for, and the to store the `f's 
06:07:49 <fen> the `g's can be composed directly
06:08:43 <fen> (g corresponds to the act of updating the column to replace values of type `a' with values of type SquareGrid a)
06:08:51 <fen> for the Comonad SquareGrid instance
06:09:13 <fen> and `f' corrsponds to navigating forwards
06:09:13 <Solonarv> so g = duplicate? or does it just have the same type, but do something different?
06:09:15 <dmwit> Apologies for rehashing. I hadn't seen that part of the conversation yet.
06:09:29 <fen> g /= duplicate
06:09:38 <fen> it acts just on one column
06:09:57 <fen> g :: [a] -> [SquareGrid a]
06:10:09 <fen> it acts on the fully rewound Zipper
06:10:20 <fen> ie just the rhs of ([a],[a])
06:10:27 <fen> when the lhs == []
06:11:04 <fen> the idea is that if the zipper were navigated to location, it would have to be rewound before this could be applied
06:11:31 <fen> so the navigation should not just be lazy, but explicitly deffered 
06:11:35 <Solonarv> ... how does 'replicate n g' even typecheck, then?
06:11:48 <fen> no its replicate n forwards
06:11:54 <Solonarv> oh I see
06:11:55 <merijn> fen: "not lazy, but explicitly deferred" <- what does this even mean?
06:12:57 <Solonarv> as I said earlier, you will never get a *different* answer because of lazy/strict differences.
06:13:08 <Solonarv> (yes, yes, as long as you're not catching exceptions)
06:13:09 <fen> rather than just composing (forwards . forwards ...) and applying that to the adjacent columns (actaully its fmaped over *all* the columns) it sould be stored seperatly, to allow somthing else (g in this case) to act on the columns it will be applied to
06:13:21 <fen> merijn^
06:14:41 <fen> this actually has a more simple use aswell. suppose the grid is navigated to some location, and then navigated forwards and backwards along some column over and over. this would cause the thunks of navigating the other columns to grow, where really these navigations should cancel
06:15:15 <fen> possibly this can be avoided using GroupAct, where the composed inverses cancel?
06:16:28 <fen> (\(x:xs,ys) -> (xs,x:ys)) is inverse to (\(xs,y:ys) -> (y:xs,ys))
06:16:42 <Solonarv> The group you're looking at is (Integer, +, 0); so just use that directly
06:17:18 <Solonarv> (or Int if you don't need to handle values > 2^63 - ish )
06:17:30 <fen> calling these forwards and backwards, the navigations could be such as (forwards . backwards . forwards . backwards)
06:17:51 <fen> equivalent to (+1) . (-1) . (+1) . (-1)
06:18:15 <fen> on (Int,Zipper a)
06:18:29 <fen> which is this way of explicitly storing the unnaplied navigations
06:18:48 <Solonarv> I'd suggest instead having a type like 'newtype Move = Move { moveOffset :: Int } deriving (Semigroup, Monoid) via (Sum Int)'
06:18:49 <fen> still, its hard to see how these compositions would cancel
06:19:05 <Solonarv> and then 'applyMove :: Move -> Zipper a -> Zipper a'
06:19:05 <fen> nice
06:19:20 <fen> well, how to get the inverse?
06:19:39 <Solonarv> add 'deriving Num' and use 'negate'
06:19:53 <fen> hmm
06:19:58 <fen> prefer Group to Num
06:20:01 <Solonarv> I don't think there's a Group typeclass in base, but there might be a package that has it
06:20:15 <fen> (*) isnt relevant here
06:20:34 <Solonarv> Oh I agree
06:20:40 <fen> its a simple subclass of Monoid 
06:20:59 <Solonarv> Sure, so there probably *is* a package somewhere that has it
06:21:05 <Solonarv> I'm searching hackage for it right now
06:21:06 <fen> class Monoid a => Group a where inverse :: a -> a
06:21:06 * hackage postgresql-simple-migration 0.1.13.0 - PostgreSQL Schema Migrations  http://hackage.haskell.org/package/postgresql-simple-migration-0.1.13.0 (ameingast)
06:21:34 <fen> but anyway, it still wont work
06:21:45 <fen> suppose its not Int, but something more expensive
06:21:48 <fen> like, reverse
06:22:04 <fen> rather than pred, succ, which are inverses
06:22:06 <Solonarv> @hackage groups
06:22:06 <lambdabot> http://hackage.haskell.org/package/groups
06:22:09 <fen> reverse is self inverse
06:22:27 <Solonarv> ^ there you go
06:22:56 <fen> so (reverse . reverse . reverse . reverse) should cancel just like (succ . pred . succ . succ)
06:22:58 <Solonarv> already has an instance for Sum Int, so you can simply write 'newtype Move = Move Int deriving (Semigroup, Monoid, Group) via (Sum Int)
06:23:07 <fen> awesome
06:23:35 <Solonarv> that's got to be one of the tiniest packages I've ever seen
06:23:43 <fen> anyway, this "more expensive" thing shows how they should cancel when they are just thunks
06:23:51 <fen> and not be actually applied 
06:24:00 <Solonarv> That has nothing to do with thunks
06:24:15 <Solonarv> thunks just say "here's what to do if you need my value"
06:24:25 <Solonarv> they don't magically make 'reverse . reverse' free
06:24:52 <fen> right, or there wouldnt be an issue
06:25:23 <fen> so, while doing things like using lists of functions instead of thunks, this seems like a natural extension
06:26:10 <Solonarv> the problem there is you can't inspect functions, so "lists of functions" doesn't really help with making 'reverse . reverse' free
06:26:50 <fen> this cancelation of opposite navigations will happen alot while navigating a sparse grid, such as updating the location of a ball bouncing around the inside of a box
06:27:25 <Solonarv> "Group actions" definitely sounds like the right way to go at it
06:27:53 <fen> well it would still either be a list or a list folded with (.), of these Group actions
06:28:18 <Solonarv> which means define a group ('Move'), and define its action ('applyMove :: Move -> Zipper a -> Zipper a')
06:28:18 <fen> ok, maybe not the composed version, that definatly cant cancel, can it?
06:28:28 <Solonarv> exactly, those can't cancel
06:28:47 <Solonarv> so instead you find a different representation of the group, one where canceling is easy
06:29:07 <Solonarv> e.g. a plain old Int (or an Integer, or a newtype over them)
06:30:12 <fen> all groups are isomorphic to the Integers?
06:30:39 <fen> well, probably can restrict this to countable Groups
06:30:56 <Solonarv> not as far as I know; but this one is
06:30:57 <lavalike> no
06:31:12 <Solonarv> e.g. moves on a 2D grid are iso to (Integer, Integer) instead
06:31:16 <fen> hmm, and reverse is self inverse so its both 1 and -1
06:31:50 <Solonarv> yes, that's the (Z/2Z, +, 0) group
06:32:04 <fen> not like a memory offset?
06:32:15 <Solonarv> fen: wdym?
06:32:16 <fen> making a square grid into a line
06:32:44 <Solonarv> there's an invertible morphism between Integer and (Integer, Integer); but there isn't one that preserves group operations
06:32:45 <lavalike> take infinite direct products of finite groups of chosen sizes, you can choose the sizes to make infinitely many non-isomorphic, countable groups
06:32:51 <fen> :t index
06:32:53 <lambdabot> Ix a => (a, a) -> a -> Int
06:33:13 <mniip> any group that has a nonzero morphism into integers must necessarily be infinite
06:33:16 <fen> > index ((0,0),(2,2)) (1,1)
06:33:18 <lambdabot>  4
06:33:27 <mniip> any group that has a nonzero morphism from integers must necessarily have an abelian subgroup
06:34:16 <Solonarv> fen: again, yes; but that function doesn't preserve group structure
06:34:21 <fen> ok
06:34:59 <fen> then can all groups be cast to [Int] ?
06:35:06 <fen> (to and from)
06:35:07 <Solonarv> if you want to preserve group structure you additionally need 'f x <> f y = f (x <> y)', 'f mempty = mempty', and 'f . invert = invert . f'
06:35:38 <fen> that would be the canonical representation like a matrix right?
06:36:18 <fen> and something about the size of that matrix and some factorisation like lagrange theorem...
06:36:37 <fen> partitioning into closed subgroups
06:37:04 <fen> which then must divide the order of the group
06:37:08 <fen> confused sry
06:37:53 <fen> the number of subgroups divides the number of elements of a finite group right?
06:38:03 * hackage shakespeare 2.0.20 - A toolkit for making compile-time interpolated templates  http://hackage.haskell.org/package/shakespeare-2.0.20 (MichaelSnoyman)
06:38:09 <fen> and that corresponds to the length of the [Int] that can encode it?
06:39:25 <Solonarv> mniip: help!
06:39:55 <Taneb> mniip: every group has an abelian subgroup, the trivial group
06:40:17 <mniip> other than that though
06:41:16 <Taneb> It is true that every morphism from Z to G gives us an abelian subgroup which is the image of the morphism
06:41:46 <mniip> and if the morphism is nonzero, the image is nontrivial
06:41:52 <mniip> 11/21/2018 [17:34:37] <fen> then can all groups be cast to [Int] ?
06:41:55 --- mode: glguy set +v lala_
06:41:55 <mniip> only finitely generated ones
06:42:06 <Solonarv> what does it mean for a morphism to be nonzero? I'm not familiar with that term.
06:42:17 <mniip> Solonarv, whether it factors through the zero object
06:42:20 <Taneb> Solonarv: the zero morphism maps everything to the identity
06:42:26 <Solonarv> oh, I see.
06:43:00 <fendor> how can I nicely fork off n threads, let them work for s seconds and then collect their results that they have written into a respective tvar?
06:43:11 <mniip> in a category where the initial and terminal objects are the same, morphisms that commute the triangle with the initial/terminal morphisms are called zero morphisms
06:43:54 <Solonarv> fendor: IIRC async has a 'timeout' operator which sounds like what you're looking for
06:44:10 <merijn> fendor: What if they're not done in those s seconds?
06:44:49 <Ariakenom> the async package has a bunch of juicy concurrency stuff. have a look
06:44:53 <c_wraith> tvar sounds wrong for that. it requires transactions to commit.
06:45:32 <fendor> merijn, they should write solutions to a tvar. If they didnt manage to write a single solution, the tvar should contain Nothing.
06:45:42 <c_wraith> I think you just want an IORef with atomicModifyIORef to store partial results.
06:46:01 <fendor> then it should commit Seppuku for dishonoring their family
06:47:00 <Solonarv> does each worker have its own *Var, or do they share one?
06:47:13 <fendor> c_wraith, ok, IORef sounds better, you are right
06:47:35 <fendor> Solonarv, their own, they solve problems individually
06:47:44 <fen> anyway, so zipwith (+) is then the canonical update?
06:48:25 <Ariakenom> The Ref choice seems unimportant, no?
06:48:36 <mniip> 11/21/2018 [17:37:31] <fen> the number of subgroups divides the number of elements of a finite group right?
06:48:36 <mniip> what
06:48:42 <Solonarv> is the var just for getting results out? because it looks like async might be a better approach than what you're doing.
06:48:45 <fen> it still seems like there should be a better way to cancel the inverse functions than integer arithmetic? 
06:48:50 <fendor> Ariakenom, it is. sorry, forgot async, i will look at its api 
06:49:12 <fen> mniip: https://en.wikipedia.org/wiki/Lagrange%27s_theorem_(group_theory)
06:49:13 <Solonarv> fen: what better way can you imagine for modeling one-dimensional movement?
06:49:19 <mniip> fen, that's not what that theorem says
06:49:35 <fen> its a corollary
06:49:38 <mniip> it's saying about the subgroup order and the subgroup index
06:49:43 <fen> its the other side of the division
06:49:51 <mniip> still no
06:50:21 <fendor> I see, so, I should just aysnc away everything, wait s seconds, then cancel it, right?
06:50:24 <fen> oh, because some subgroups order could be multiples of the order of the other subgroups? 
06:50:51 <fen> dont all subgroups have the same degree?
06:51:00 <merijn> fendor: Yes, no, maybe
06:51:10 <merijn> fendor: Async doesn't handle, e.g. rate limiting
06:51:20 <fendor> merijn, what is rate limiting?
06:51:25 <mniip> the symmetric group S_4 has 40 subgroups, which is actually more than it has elements
06:51:28 <mniip> (24)
06:51:29 <fen> how else could a matrix of some size encode a group?
06:51:38 <mniip> whoops
06:51:41 <mniip> correction: 30 subgroups
06:51:41 <merijn> fendor: i.e. if you have a collection of 1 million elements you might not wanna launch 1 million concurrent async's
06:52:25 <Ariakenom> fendor: something like, "mapConcurrently_" for the wrokers and a "waitEither" between those and a "threadDelay t"
06:52:47 <fendor> merijn, right, but the elements should be relatively low
06:52:52 <fen> hmm, that can be right for this theorem, it forms a partitioning, there must be more than one partitioning and those that are consistent with one particular partitioning are then compatible
06:53:00 <fen> if thats not confusing too many terms
06:53:18 <fendor> *amount of elements
06:53:23 <merijn> fendor: Well, you asked "is it ok", and like I said, the answer depends :p If it's relatively small, then probably it is
06:53:37 <fen> and pretty sure they all have to be the same size
06:54:01 <Ariakenom> oh not waitEither but race_
06:55:11 <fendor> merijn, And I thank you for your helpful hint that it might not be, I appreciate it! I know it is difficult to give examples when I am not explaining what acutally want to do
06:55:33 <fen> mniip?
06:55:37 <mniip> what
06:55:52 <fendor> s/examples/answers/
06:55:56 --- mode: glguy set +v safinaskar
06:56:20 <mniip> lagrange's theorem talks about the subgroup index, that is the number of distinct cosets
06:56:22 <safinaskar> hi
06:56:24 <mniip> cosets aren't subgroups though
06:56:42 <fen> the size of the partitioning is the degree of the group/the degree of the subgroups
06:57:23 <fen> cosets*
06:58:57 <fen> 2d grid <-> (Int,Int) arbitrary groups <-> [Int] where its length divides the number of values in the group
06:59:13 <fen> hmm, (3,3) has 9 which does not divide by 2
06:59:13 <mniip> what
06:59:16 <fen> damn
06:59:24 <fen> nvm, idk wtf
06:59:47 <safinaskar> does haskell have raw string literals which ACTUALLY work? look at this: you can use raw-strings-qq. but then you will not be able to use |] in your strings. yes, you can use [rQ| ... |], but then you still will not be able to use |] in your strings, you need to write |~] instead. all this is completely not satisfactory. compare this with C++ raw strings: R"foo(some-string)foo". you can write 
06:59:53 <safinaskar> everything instead of foo, foo will be end of string marker
07:00:02 <fen> oh no its ok, its still 2 subgroups
07:00:17 <fen> hmm
07:00:45 <haveo> fen: are your arbitrary groups finite? because the 2d grid isn't but talking about the number of values only makes sense if the group is finite
07:01:02 <fen> yeah, finite. 
07:01:12 <fen> so a 2d grid of given finite bounds
07:02:09 <fen> the theorem seems quite general though, allowing all finitly generated groups actions to be encoded as vectors of Ints. just cant quite figure the theorem about the length of this list
07:02:15 <haveo> that would only be a group if it's (Z/pZ, Z/qZ) but ok
07:02:23 <merijn> safinaskar: What do you need those raw string literals for?
07:02:45 <mniip> fen, it's not a faithful encoding
07:02:53 <mniip> rather
07:02:55 <mniip> it's not full
07:03:09 <mniip> actually no, forget what I said
07:03:14 <fen> the Ints correspond to the numbers of actions of the various orthoganal generating elements right?
07:03:18 <mniip> it's not an encoding at all - it only works for abelian groups
07:03:21 <fen> like, one from each partition
07:03:32 <makalu> I can use #include with ForeignFunctionInterface. But how can I tell cabal where to look for headers if they are in a non-standard location?
07:04:04 <fen> Abelian obviously! unless you want to do quantum functional programming with lie brackets or something!?
07:04:24 <fen> its a flat space...
07:04:24 <mniip> fen, it was vaguely bearable when you were talking about programming, but in group theory please use the commonplace vocabulary
07:04:38 <fen> sry
07:04:51 <safinaskar> merijn: well, my question is abstract, again
07:05:06 <safinaskar> merijn: i just want this feature to exist in language
07:05:13 <safinaskar> merijn: but i can describe my task
07:05:18 <merijn> safinaskar: I mean, for lots of usescases you can just include a string literal from a file at compile time
07:05:19 <mniip> a finitely generated abelian group is indeed just a list of powers of the generators
07:05:27 <fen> woot!
07:05:32 <safinaskar> merijn: i generate input for Flex lexer generator using Haskell
07:05:35 <fen> does this theorem have a name?
07:05:39 <mniip> but you still have no idea how to compare two such lists for equality
07:05:46 <mniip> so it's not a particularly useful "encoding"
07:05:49 <fen> hmm
07:05:50 <safinaskar> merijn: Flex will then process generated file to produce C++ source
07:05:58 <merijn> safinaskar: Also, in C++ you have the same issue, you can't write " directly in a raw string
07:06:02 <safinaskar> merijn: which in turn will be lexer for some language
07:06:03 <mniip> it's not a theorem, just how freely generated groups work
07:06:11 <fen> ill tell that
07:06:34 <fen> its nothing to do with lagrange theorem?
07:06:41 <mniip> no
07:06:46 <safinaskar> merijn: so, i will have flex portions embedded in my haskell source
07:06:59 <safinaskar> merijn: this flex portions contain regexes
07:07:05 <fen> but how come the number is the same as the number of partitions?
07:07:16 <mniip> "partitions"?
07:07:37 <safinaskar> merijn: they will not contain |] in most cases, but i am just curious is this possible to have raw strings without limitation about |]
07:07:45 <fen> partitions under lagrange theorem, where the distinct subgroups partition the group
07:07:53 <fen> cosets*
07:07:58 <fen> but they are not groups?
07:08:00 <fen> hmm
07:08:03 <merijn> safinaskar: Also, there's Alex which basically "Flex for haskell"
07:08:19 <mniip> cosets yeah
07:08:26 <fen> Lagrange's theorem, in the mathematics of group theory, states that for any finite group G, the order (number of elements) of every subgroup H of G divides the order of G
07:08:29 <fen> so, groups
07:08:37 <mniip> you have the theorem that if two cosets intersect they coincide
07:08:44 <fen> exactly
07:08:48 <mniip> which means that every element of G can only be in one coset
07:08:56 <fen> the generating element orbits round the whole subgroup
07:08:58 <safinaskar> merijn: "I mean, for lots of usescases you can just include a string literal from a file at compile time" - this is overkill. my fragment is too short for this. it contains two lines
07:09:01 <mniip> and it has to be in /some/ coset because you can always take that element and multiply by H
07:09:07 <mniip> what
07:10:24 <haveo> fen: the way the theorem works is you *pick* a subgroup H then the theorem gives you a bunch of cosets (which are indeed all of the same size as H) which partition G
07:10:30 <fen> if any element of another partition was included it would act on each element to take it into the other partition, they are the same size and this mapping is one to one, so then they overlap
07:10:44 <haveo> so it can't really say anything about the set of subgroups (at least not directly)
07:10:54 --- mode: glguy set +v govno
07:11:03 <fen> ah ok
07:11:05 <haveo> also, since only one of the cosets contains the identity it's pretty clear only one can be a subgroup
07:11:15 <fen> hmm
07:11:20 <fen> no they all contain the identity
07:11:23 <mniip> no
07:11:26 <fen> thats how they are all groups
07:11:29 <mniip> if they did they'd intersect
07:11:30 <safinaskar> merijn: "Also, in C++ you have the same issue, you can't write " directly in a raw string" - no. websearch for "C++ raw strings". they appeared in C++11. i showed you example: R"foo(string)foo". in this example the only thing which cannot appear in string is sequence of this 5 chars: )foo"    so, as you can see this solution is very flexible
07:11:39 <fen> the identity doesnt do this casting elements of one partition into the other
07:11:44 <haveo> they can't all contain the identity and form a partition...
07:11:50 <fen> so it can safely be included in all partitions
07:12:08 <fen> so they intersect exactly only at the identity
07:12:30 <mniip> safinaskar, I don't think what you want is possible and you'd be better off with a TH splice that just loaded an external file or something
07:12:40 <fen> the only reason they had to not share values was that otherwise under group action the partitions would then overlap
07:12:44 <safinaskar> merijn: "Also, there's Alex which basically "Flex for haskell"" - i am generating flex file for c++ program, not haskell's one
07:13:43 <fen> (0,0),(1,0),(2,0) and (0,0),(0,1),(0,2)
07:13:47 <fen> its fine
07:13:57 <haveo> fen: if the cosets intersect then you don't get the actual lagrange theorem, that |H| divides |G|
07:14:17 <mniip> fen, do you understand what cosets are
07:15:06 <fendor> if I use `mapM (async . return) [1..10]`, or something like that, will that start 10 threads as expected? I use async explicitly, because i dont see a way to otherwise cancel them
07:17:07 <fen> maybe that means the partitions recombine under cartesian product to give the full group
07:17:22 <mniip> no
07:17:36 <fen> 3 divides 9
07:17:43 <mniip> a group doesn't always factor into a product of groups
07:18:00 <fen> sure, at worst its the identity and the whole group
07:18:16 <mniip> C_4 has C_2 as subgroup
07:18:21 <mniip> but doesn't factor into C_2 x C_2
07:18:39 <fen> this would correspond to a group with a prime number of elements
07:18:55 <fen> where the only divisors are 1 and n
07:19:07 <haveo> 4 is not prime though
07:19:41 <fen> C_2 x something ?
07:20:00 <mniip> no
07:20:26 <fen> like a grid of size (2,3)
07:20:41 <fen> Z2 x Z3
07:21:04 <fen> mniip: must be!
07:21:31 <mniip> https://groupprops.subwiki.org/wiki/Groups_of_order_4
07:21:35 <mniip> see they're nonisomorphic
07:21:48 <Ariakenom> fendor: (race_ (print "1") (threadDelay 100 >> race (print"2") (threadDelay 100 >> print"3"))) will just print 1
07:23:07 <mniip> fen, the order of the group C_2 x something is  2 * order of something
07:23:13 <mniip> hence something must be of order 2
07:23:17 <mniip> but there's only one group of order 2
07:23:30 <mniip> so the only possibility is C_2 x C_2 and it's not that
07:23:56 <fen> C_4 = C_2 x (C_4 / C_2)
07:24:09 <Ariakenom> fendor: You can just use race to cancel them
07:24:45 <fendor> Ariakenom, I see, so, something like a fold can be used? 
07:24:45 <mniip> C_4 / C_2 = C_2
07:24:56 <mniip> it is not the case that  A = B x (A / B)
07:25:06 <Ariakenom> fendor: mapConcurrently_ should work for you
07:25:40 <Ariakenom> I described it in more detail earlier fi you can find the messahe
07:26:07 <mniip> fendor, for a in A, a^n = e, and for b in B, a^m = e
07:26:09 <fendor> Ariakenom, i remember, but I can not tell whether they are really cancelled
07:26:18 <mniip> then in A x B, (a, b)^lcm(m, n) = (e, e)
07:26:34 <mniip> hence C_2 x C_2 has no element of order four
07:26:40 <safinaskar> why this doesn't work: https://zerobin.net/?fc4d466b22887aad#OE3c7zgroI9AKuJyIoEM6G/Qla2jdmHb6CRk4+8p4bI= ?
07:26:40 <mniip> while C_4 does
07:26:46 <fen> why do you think that was claimed?
07:26:58 <Ariakenom> fendor: threadDelay t `race_` (mapConcurrently_ task inputs)
07:27:00 <safinaskar> this is temlate haskell
07:27:07 <mniip> safinaskar, post the error message too
07:27:11 <fendor> Ariakenom, ok now I got it
07:27:20 <fendor> thank you, sorry, now your explanation from aboce is clear
07:27:23 <fen> the subgroups are not all of the same size, right
07:27:47 <mniip> ok so?
07:27:54 <mniip> fen: ok so?
07:28:34 <fen> so the [Int] does not have the same bound for each value
07:29:04 <fen> e.g. (2,3) for the top right corner of a grid
07:29:12 <fen> [2,3]
07:29:32 <safinaskar> mniip: oops, i just missed {-# LANGUAGE QuasiQuotes #-}
07:29:44 --- mode: glguy set +v fen_
07:30:17 <Ariakenom> fendor: nice. whether or not is cancelled is a good question though. I'd advice playing around in ghci.
07:31:26 <Ariakenom> (eh not "good question" as in "I don't know the answer". damn idioms)
07:32:11 <fen_> lagrange theorem gives the length of the list as the number of partitions, which divides the degree of the group
07:32:35 <fen_> and the bounds of the ints corresponds to the degree of the corresponding subgroup partitions
07:34:08 <mniip> you're still trying to factor the group into a (semi)direct product
07:34:22 <mniip> that is not always possible
07:34:23 <fen_> after choosing a generating element, i.e. other than the identity, any element of a smallest possible subgroup partition will generate that subgroup, and then the bijection between any group and [Int] is faithful 
07:34:52 <mniip> the groups which that works for are called solvable
07:34:52 <fen_> mniip, it is certainly always possible
07:35:06 <fen_> is there a counterexample?
07:35:12 <mniip> they admit an cyclic (abelian) tower
07:35:21 <mniip> fen_, any simple group that is not cyclic
07:35:51 <fen_> as stated previously, in the worst case, for groups of prime degree, the only factors are the whole group and the identity
07:35:58 <mniip> A_5 for example
07:36:04 <mniip> of size 60
07:36:41 <mniip> it has 59 subgroups but none of them are normal, and thus you can't produce a quotient
07:37:23 <fen_> ok, nice
07:37:33 * hackage crypto-enigma 0.0.3.1 - An Enigma machine simulator with display.  http://hackage.haskell.org/package/crypto-enigma-0.0.3.1 (Orome)
07:37:33 <fen_> so solvable groups, which admit a quotient
07:38:26 <fendor> Ariakenom, it doesnt matter actually, the program reads from the ioRef and print the result and then terminates
07:38:39 <fendor> assuming they get cancelled when main exits
07:38:56 <fen_> and continuing to take quotients until smallest possible groups are found, forms a partition, and a faithfull mapping to [Int]
07:39:15 <fen_> where the length is the number of subgroups, and the bounds on the int are the corresponding subgroup size
07:39:17 <Ariakenom> fendor: correct
07:39:57 <fen_> after selection of a generating element
07:40:16 <fen_> which as the subgroups are as small as possible, resultingly generates the whole subgroup
07:40:53 <mniip> fen_, what you're looking for is called a cyclic tower
07:41:12 <mniip> it's a tower of subgroups where all intermediate quotients are cyclic
07:41:19 <fen_> if it does not, then a quotient can be taken, selecting only the values of the orbit of the candidate generator, which then *is* a generating element of the new subgroup, which is then as small as possible
07:41:34 <fen_> a cyclic tower corresponds to [Int]
07:41:59 <mniip> kinda
07:42:00 <fen_> all groups have a at least one choice of bijection with [Int[
07:42:03 * hackage nmis-parser 0.1.0.2 - NMIS file parser  http://hackage.haskell.org/package/nmis-parser-0.1.0.2 (v0d1ch)
07:42:09 <mniip> with the understanding that it's really (C_i, C_j, C_k, ...)
07:42:21 <mniip> again, not all, only the solvable ones
07:42:34 <fen_> in the worst case its just Int
07:42:50 <mniip> after all, [Int] is, what, merely countable?
07:42:57 <mniip> there exist sets that are far larger
07:44:07 <mniip> even within finite groups you've still got non-solvable ones
07:44:17 <davean> mniip: countable is about as small as infinity gets
07:44:36 <mniip> davean, nah infinity begins at like 2
07:44:56 <davean> Thats about the same
07:45:38 --- mode: glguy set +v koopa184
07:45:49 <hodapp> and uncountable is where it goes next.
07:45:51 <hodapp> OR IS IT
07:46:10 <fen_> so what about these inverses
07:46:35 <haveo> hodapp: I mean by definition it is
07:46:36 <fen_> oh right, groups are to be encoded as [Int] and then they can be composed cheaply 
07:46:41 <mniip> no they can't
07:46:56 <haveo> whether it's P(N) is another question
07:47:02 <mniip> it isn't an isomorphism between your group and (Int, Int, ...)
07:47:27 <mniip> haveo, what if there's uncountable sets smaller than N!
07:50:47 <Solonarv> [Int] is countable, because Int is finite. I don't think [Integer] is countable, though.
07:50:58 <hodapp> mniip: what if it's all just a lie produced by non-constructive math
07:51:33 * hackage protocol-buffers 2.4.12 - Parse Google Protocol Buffer specifications  http://hackage.haskell.org/package/protocol-buffers-2.4.12 (TvH)
07:51:46 <haveo> mniip: what if N is bigger than we've been told!
07:51:50 <haveo> it's all a conspiracy
07:52:11 <Solonarv> I mean, by definition N is countable
07:52:14 <haveo> also, has the governement found a field with one element and is hiding it in area 51?
07:52:17 <mniip> they're hiding elements of N from us
07:52:36 <Solonarv> this reminds me of that one SCP
07:52:41 <MarcelineVQ> Well, no one needs every single N.
07:52:42 <mniip> Solonarv, it is countable if restricted to finite lists
07:53:00 <MarcelineVQ> Surely we can do without a couple less popular ones.
07:53:01 <haveo> "countably inifinite ought to be enough for anyone"
07:53:03 * hackage hprotoc 2.4.12, protocol-buffers-descriptor 2.4.12 (TvH): https://qbin.io/import-rely-ikrl
07:53:23 <mniip> Solonarv, you can represent it as 1 + N + N*N + N*N*N + N*N*N*N + ...
07:53:29 <mniip> N*N*...N are all countable
07:53:36 <mniip> and a countable union of countables is countable
07:53:45 <mniip> (use the logarithmic ruler or something)
07:53:55 <Solonarv> o rly? eh, makes sense I guess
07:54:21 <hodapp> guys, quiet down a little or Gregory Chaitin will hear us and come join, and he'll very quickly get into the most awkward "mathematics is like sex, you see!" comparisons ever
07:55:15 <MarcelineVQ> Can't have that.
07:55:24 <Solonarv> ah, found it - http://www.scp-wiki.net/scp-1313, an equation whose solution is a bear.
07:55:49 <Solonarv> ah no, I was thinking of 33
07:56:08 <hodapp> MarcelineVQ: just be glad that the book "META MATH!" has very few pictures in it
07:59:16 <haveo> Solonarv: alternatively, you can write an injective function from [Integer] to [Bool] by writing the integers as binary and [Bool] is very clearly countable
08:00:05 <Solonarv> yeah, true
08:00:10 <haveo> (you might need some trickery to make it truely injective but it ends up working in the end)
08:00:46 <saml> is monad a turkey?
08:01:08 <mniip> a better question is
08:01:11 <mniip> is turkey a monad?
08:01:25 <MarcelineVQ> is a turducken a free monad?
08:01:29 <fen_> this was supposed to be a way to quickly allow inverse group elements to cancel before applying them to the target value
08:01:54 <saml> that's nice inverse
08:04:10 <saml> eric88, are you 30 yet?
08:12:23 <safinaskar> does haskell have js-style strings with embedded values? for example, in js we can write: console.log(`x = ${x}`). does haskell have something like this?
08:12:56 <Franciman> safinaskar, you may want to look at Text.Printf in base package
08:13:08 <Franciman> don't know of other alternatives though
08:13:33 <Ariakenom> mniip: hey, can yahb get async?
08:13:54 <mniip> if that creates background threads I'd rather not
08:14:15 <Ariakenom> safinaskar: Franciman there's a library called formatting
08:14:29 <safinaskar> i don't want to insert non-string entities to string
08:14:37 <safinaskar> all i need to insert is just strings
08:14:47 <safinaskar> i. e. i simply need to insert strings into strings
08:14:52 <safinaskar> i. e. concatenation
08:15:01 <safinaskar> i need pretty syntax for this
08:15:07 <Solonarv> probably doable with some sort of quasiquoter?
08:15:12 <marvin2> > "one" ++ "two" ++ "three"
08:15:14 <Franciman> very cool Ariakenom, thanks
08:15:14 <lambdabot>  "onetwothree"
08:15:16 <marvin2> > concat ["one", "two", "three]
08:15:17 <Ariakenom> mniip: oh, why?
08:15:18 <lambdabot>  <hint>:1:30: error:
08:15:18 <lambdabot>      lexical error in string/character literal at end of input
08:15:23 <marvin2> > concat ["one", "two", "three"]
08:15:24 <safinaskar> i. e. i want to type something like js-style `x = ${x}` instead of "x = " ++ x
08:15:28 <lambdabot>  "onetwothree"
08:15:33 <safinaskar> Solonarv: probably
08:15:50 <saml> isn't there template haskell?
08:15:51 <safinaskar> Solonarv: maybe such quasiquoter already exists and i don't need to create my own?
08:16:01 <Solonarv> [blah|x = #{x}|] for example
08:16:06 <Solonarv> yes, that's what I was alluding to
08:16:11 <saml> "x = " ++ show x
08:16:20 <confusedwanderer> that's called string interpolation if it helps your searches
08:16:24 <rotaerk> also: https://hackage.haskell.org/package/text-format
08:16:39 <MarcelineVQ> mniip: it uses ghc's green threads via forkIO and MVar's
08:17:12 <merijn> @hackage interpolate <- string interpolation
08:17:12 <lambdabot> http://hackage.haskell.org/package/interpolate <- string interpolation
08:17:13 <rotaerk> https://github.com/sol/interpolate
08:17:50 <marvin2> seems a bit of an overkill to use third party library just to concatenate a few strings
08:17:52 <Ariakenom> mniip: MarcelineVQ: yes they are subject to the usual yahb timeout
08:18:00 <merijn> marvin2: Depends on the complexity ;)
08:18:18 <codedmart> I am reading through a taffybar config. Where does `<|||>` come from?
08:18:23 <merijn> marvin2: If it's just a sequence of string i usually do "mconcat [ ... ]" with indidivual string parts in the ...
08:18:27 <mniip> Ariakenom, it can mess up output
08:18:29 <confusedwanderer> it's not as pretty, but you can also use the monoid <>
08:18:34 <merijn> @hoogle (<|||>)
08:18:34 <lambdabot> No results found
08:18:37 <mniip> % forkIO $ forever $ putStr "a"
08:18:38 <yahb> mniip: ThraeaadIad a71a; aaa
08:18:41 <mniip> % ()
08:18:41 <yahb> mniip: aaaaaaaaaa(a); aaaa
08:18:56 <Solonarv> kill it!
08:19:12 <Ariakenom> mniip: huh, I see
08:19:17 <mniip> % :q
08:19:18 <yahb> mniip: aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa
08:19:27 <rotaerk> ..
08:19:35 <MarcelineVQ> The sound a dying bot makes.
08:19:51 <mniip> well I could've used %kill and it would've been silent
08:23:36 <Ariakenom> I'll register interest though. Think I've been surprised it wasn't there 3 separate  times now :p
08:23:41 <safinaskar> you crashed the bot using fork bomb??
08:24:36 <ski> just one thread forked
08:24:48 <MarcelineVQ> it didn't crash, just got messy output
08:25:08 <Solonarv> not at all. Simply forked a thread that vomited 'a' onto stdout, and then manually killed the interpreter to stop it.
08:25:31 <matheus23> Did really nobody else experience this ghc issue with archlinux??? installing ghc-static simply doesn't install all shared libraries. They're missing! copying them from a stack-installed ghc install makes it work. I'm confused how It seems I'm the only one with this issue :D
08:29:10 <cocreature> matheus23: the problem on arch isn’t missing shared libraries, it’s missing static libs
08:29:38 <cocreature> matheus23: ghc-static does install static libs but only for the ones bundled with ghc. you should just avoid installing anything Haskell-related via pacman except for ghc
08:29:47 <matheus23> cocreature: I know of that issue. But it's another one. I installed "ghc-static" and manage my libraries via cabal-install
08:30:16 <cocreature> matheus23: what’s the output of ghc-pkg list?
08:30:24 <cocreature> and what’s the actual error you are seeing?
08:31:05 <matheus23> https://pastebin.com/jwjDsU97
08:32:01 <matheus23> cocreature: error: https://pastebin.com/wnPXbx7g
08:32:17 <matheus23> The ghc-pkg output is with my 'fixed' install of ghc-static
08:34:09 <fen_> class Group a => Generated a where generator :: a -> [Int]; generate :: [Int] -> a 
08:35:45 <fen_> data Gen a where Gen :: (Generated a,Act a b) => [Int] -> b -> Gen a
08:36:07 <cocreature> matheus23: https://www.archlinux.org/packages/community/x86_64/ghc-libs/ appears to have that lib. are you sure you’ve updated everything? (I could imagine running into a situation like this if you do a partial update)
08:36:46 <safinaskar> Franciman: Ariakenom: i found what i wanted. this is package "interpolate"
08:37:22 <fen_> instance Generated a => Act a (Gen a) where act a (Gen g b) = Gen (zipWith (+) (generator a) g) b
08:37:56 <MarcelineVQ> https://www.archlinux.org/packages/community/x86_64/ghc-static/ also lists haskeline, so there's some kind of setup or path error happening somewhere
08:39:02 <mniip> fen_, go and learn some actual algebra
08:39:24 <fen_> toGen :: (Generated a,Act a b) => a -> b -> Gen a; toGen a = Gen (generator a) b
08:39:28 <cocreature> I don’t think ghc-static matters here
08:39:48 <matheus23> cocreature: humm. I tried reinstalling ghc and ghc-static. I might have been stupid and forgot reinstalling ghc-libs!
08:40:14 <MarcelineVQ> Not sure, haven't had this exact issue, I have had base be unable to be found without static though :(
08:40:30 <fen_> fromGen :: Gen a b -> b; fromGen (Gen a b) = act (generate a) b
08:40:56 <fen_> oops, s/Gen a/Gen a b
08:41:19 <cocreature> MarcelineVQ: right but this error is about a shared lib not being found when running ghc. not about a static lib not being found when linking
08:41:19 <fen_> s/toGen a/toGen a b
08:41:30 <matheus23> cocreature: It doesn't fix that issue for me... but I'll try out something right now, I think I'm on to sth
08:41:31 <fen_> mniip: ?
08:41:49 <fen_> whats wrong with that?
08:42:00 <mniip> everything?
08:42:14 <fen_> specifically!
08:45:33 <matheus23> cocreature: Seems like this was a mistake of some other tool I've been using. I don't remember installing ghc into /usr/local/. However, thats where the corrupt ghc lives...
08:47:32 <fen_> https://bpaste.net/show/7f2adfd32b1d
08:51:20 <MarcelineVQ> matheus23: hmm yeah good catch, lib for system ghc here seems to be /usr/lib/ghc-*  with bin in /usr/bin
08:57:33 * hackage constraints-extras 0.2.1.0 - Utility package for constraints  http://hackage.haskell.org/package/constraints-extras-0.2.1.0 (abrar)
08:59:45 <safinaskar> what is recommended way to install ghc and cabal to my debian system?
09:02:45 <MarcelineVQ> if you're just starting out I'd probably install the haskell platform, https://www.haskell.org/platform/
09:03:24 <safinaskar> MarcelineVQ: but it seems for me that installing cabal from my debian repo is better
09:03:29 <safinaskar> MarcelineVQ: am i right?
09:05:04 <cocreature> the version from your repos is probably going to be outdated
09:05:06 <MarcelineVQ> That's up to you, distro packages are often older versions of things so it depends on whether that matters for you
09:05:18 <fen_> mniip: maybe it should use the cyclic Zn instead of Int?
09:05:38 <fen_> does that have as fast binary representation though?
09:05:48 <cocreature> also often you want to have multiple GHC installations side-by-side which can get a bit tricky with OS package managers
09:08:33 <safinaskar> cocreature: "the version from your repos is probably going to be outdated" - so what? it is ok for me as long as i will be able to install recent versions of packages (not recent versions of ghc and cabal themselves)
09:09:18 <safinaskar> is this possible to install fresh versions of packages if cabal and ghc are installed from debian repos (and thus old)?
09:10:02 <geekosaur> cabal mostly yes, ghc largely no
09:10:22 <cocreature> safinaskar: not every package keeps backwards compatibility to older versions of ghc and cabal
09:10:46 <cocreature> so depending on how old your GHC release is, you can’t use recent versions of certain packages
09:10:54 <MarcelineVQ> which kind of debian packages do you use? stretch, sid?
09:11:03 <safinaskar> MarcelineVQ: stretch
09:11:14 <safinaskar> is this possible to install ghc via cabal?
09:11:20 <cocreature> no
09:12:50 <MarcelineVQ> I would be inclined to install the platform myself then since stretch's minimum bounds look little old. I don't have debian to confirm what it ghc version actually chooses to install though
09:13:38 <amx> it seems like there is a debian repo here: https://downloads.haskell.org/debian/
09:14:58 <Lears> You can "install" ghc from bindist somewhere isolated and use cabal's --with-ghc /path/to/ghc option.
09:15:04 <MarcelineVQ> amx: neato
09:20:03 * hackage merkle-tree 0.1.1 - An implementation of a Merkle tree and merkle tree proofs of inclusion  http://hackage.haskell.org/package/merkle-tree-0.1.1 (sdiehl)
09:34:07 <ztf> If i map each string in a list to the difference between it's length and the length of the longest string like this: strToLengthDisparity l = map (\s -> (maximum (map length l)) - length s)) l then it evaluates the maximum length for each string, correct? 
09:34:24 <ztf> would using a where change anything about that? 
09:35:23 <lyxia> I don't think there are any guarantees about that actually
09:35:47 <Solonarv> there aren't any guarantees, but in practice that's correct
09:36:09 <lyxia> are you sure GHC won't float it out?
09:37:27 <Solonarv> I'm *not* sure. GHC might float it out, or it might not.
09:37:55 <Solonarv> If you want it floated out, a 'where' clause will most likely cause that to happen.
09:40:31 <ztf> my TA said "it depends" and wasn't quite sure, I didn't really believe him tbh
09:40:31 <ztf> thanks for the answer :) 
09:46:06 --- mode: glguy set +v fen
09:46:29 <fen> is there a normal way to make a new Int of different maxBound?
09:46:41 <fen> like, an n-bit int
09:47:25 <Solonarv> look in Data.Int (signed) and Data.Word (unsigned), they might already have whatever you need
09:47:34 <fen> such as could be used to index a binary partition tree over a list of length i^2
09:47:38 <Solonarv> IIRC they have 8, 16, 32, and 64 - bit
09:47:41 <fen> no
09:47:51 <fen> ioh, maybe
09:48:05 <fen> > map (2^) [1..]
09:48:08 <lambdabot>  [2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384,32768,65536,131072,262...
09:48:28 <Solonarv> (that defaulted to Integer, which is unbounded)
09:48:39 <fen> some of the simulations are like 1000*1000
09:48:53 <fen> so 1024 probably
09:48:59 <fen> wait is that right
09:49:00 <fen> no
09:49:02 <fen> hmm
09:49:10 <fen> its not the depth of the tree?
09:49:23 <Solonarv> it should be 2^(depth of the tree)
09:49:28 <Solonarv> IIUC
09:49:29 <fen> oh right, thats the order of the partitions
09:49:40 <Solonarv> i.e. (depth of the tree) bits
09:49:50 <fen> so each bit halfs the container
09:50:03 <Solonarv> *nod*
09:50:17 <fen> yeah, then it needs e.g. odd bits?
09:50:35 --- mode: glguy set +v reactormonk
09:50:40 --- mode: glguy set -v reactormonk
09:50:45 <fen> well, all the ints really
09:50:50 <Solonarv> if 64 bits is enough, use Word64 (possibly in a newtype wrapper); if not, use Natural (possibly with a wrapper)
09:51:01 <fen> its too many thats the point
09:51:07 <fen> its cyclic so
09:51:14 <Solonarv> ooh I see
09:51:43 <Solonarv> Word32, then (since it looks like you need about 20 bits)
09:51:44 <fen> 100 * 100 only uses 7 bits
09:52:03 <Solonarv> no? it's 14 bits
09:52:06 <fen> 2^7
09:52:11 <fen> > 2^7
09:52:14 <lambdabot>  128
09:52:19 <Solonarv> but you need two indexes ?
09:52:29 <fen> so 2 seven bit ints
09:52:41 <Solonarv> so, 14 bits total ;)
09:52:46 <fen> oh right
09:52:47 <fen> ok
09:52:59 <Solonarv> if you know a smaller type is enough, you can use e.g. Word16 or Word32 instead
09:53:09 <fen> Word7 ?
09:53:30 <Solonarv> doesn't exist afaik, but you can use a newtype wrapper over Word8
09:53:52 <Solonarv> and make the wrapper's operations "ignore" the highest bit
09:54:11 <fen> that way the "does it exceed the max bound" can be easily done in a fast way, only bothering to check if the largest significance bit is on
09:54:44 <fen> or even, maybe just doing bitswaps to do the cyclic computation
09:54:57 <Solonarv> or you just set the high bit to 0 in your 'unwrap' function
09:55:24 <Solonarv> if your math is modulo 128, all your numbers are smaller than 128! ;)
09:55:36 <fen> no, if its a 100 width row
09:55:56 <fen> then 100 = 1
09:56:00 <fen> hmm
09:56:03 <fen> 100 = 0
09:56:14 <fen> so its mod 100
09:56:21 <Solonarv> I'm pretty sure there's a package for modular algebra somewhere
09:56:22 <fen> > 100 `mod` 100
09:56:24 <lambdabot>  0
09:56:46 <fen> yeah that sounds like it could work
09:57:06 <Solonarv> % newtype Fin (n :: Nat) = Fin Word64
09:57:07 <yahb> Solonarv: ; <interactive>:1:19: error: Not in scope: type constructor or class `Nat'
09:57:14 <Solonarv> bah
09:57:22 <fen> nah
09:57:23 <fen> data Mod i (n :: Nat)
09:57:27 <fen> http://hackage.haskell.org/package/modular-arithmetic-1.2.1.3/docs/Data-Modular.html
09:57:29 <fen> its slow
09:57:53 <fen> oh right, that Nat is the mod
09:58:07 <fen> but its "integral" i
09:58:25 <fen> was expecting some specific bit level opperations 
09:58:58 <Solonarv> just 'unMod' and use bit-level operations on that
09:59:55 <fen> wouldnt it be easier to define it like Word7 ?
10:00:01 <fen> are they cyclic?
10:01:05 <Solonarv> yes, all the modular-integer groups are cyclic
10:01:51 <Solonarv> Word7 doesn't map cleanly to machine-level types, so you'll have to do quotienting (i.e. "ignore the high bit") at /some/ level
10:03:27 <fen> % toEnum 10 :: Word8
10:03:28 <yahb> fen: 10
10:03:33 <fen> % toEnum 130 :: Word8
10:03:33 <yahb> fen: 130
10:03:36 <fen> hmm
10:03:50 <fen> % toEnum 260 :: Word8
10:03:51 <yahb> fen: *** Exception: Enum.toEnum{Word8}: tag (260) is outside of bounds (0,255)
10:04:09 <fen> doesnt look very cyclic
10:04:15 <Solonarv> % fromInteger 260 :: Word8
10:04:15 <yahb> Solonarv: 4
10:04:31 <Solonarv> % 3 + 255 :: Word8
10:04:31 <yahb> Solonarv: 2
10:04:32 <fen> % toEnum 250 :: Word8 + 10
10:04:32 <yahb> fen: ; <interactive>:8:21: error: Not in scope: type constructor or class `+'
10:04:38 <fen> okok
10:04:40 <fen> thanks
10:05:02 <fen> not sure how to do this quotienting thing though
10:05:12 <fen> about "machine level types" !?
10:06:15 <Solonarv> there's no "compare two 7-bit words" CPU instruction, is what I meant
10:07:08 <Solonarv> so someone somewhere needs to implement a "discard the high bit" wrapper over that
10:07:33 <fen> hmmm
10:07:59 <fen> so they are fast not only because bit addition algo is fast, but also from cpu instructions?
10:08:38 <Solonarv> what is "they" ?
10:09:33 <fen> Words?
10:09:37 <fen> Ints?
10:09:46 <fen> bit things
10:10:06 <fen> binary integers 
10:10:58 <koz_> Solonarv: Can't you just mask all but 7 bits using pext, then compare?
10:11:11 <Solonarv> koz_: idk about pext, so maybe?
10:11:47 <koz_> Well, pext is probably excessive, just and with 0b1111111 would work I think.
10:11:52 <Solonarv> fen: yes, binary integers are fast because they're fast... this isn't really a great insight though
10:11:53 <koz_> s/and/AND/
10:12:05 * hackage co-log-sys 0.1.1.0 - Syslog implementation on top of 'co-log-core'  http://hackage.haskell.org/package/co-log-sys-0.1.1.0 (pasqu4le)
10:12:06 <Solonarv> koz_: that'd be the 'discard the high bit' wrapper I mentioned
10:12:58 <koz_> ... this is what I get for replying before coffee.
10:14:21 <fen> whats pext?
10:15:15 <fen> and the question about the fastness is if the avalability of machene instructions makes them faster than an equivalent implementation of a binary addition algorithm
10:15:56 <Solonarv> yes, generally speaking if there's a machine instruction to do X that's faster than implementing 'do X' yourself
10:16:09 <Solonarv> that's why we have more than one machine instruction!
10:16:42 <fen> but why? is that something to do with how words are encoded into the cpu?
10:16:45 <koz_> Doing something in hardware is faster than doing something in software.
10:16:50 <fen> like how its a 64 bit processor?
10:17:08 <koz_> (generally speaking)
10:17:24 <koz_> (I have been bitten by assuming that too broadly in the past)
10:17:57 <Solonarv> it's mostly a practical thing: developers need operations on 8-bit integers, so CPU instruction sets provide them. They very rarely need operations on 7-bit integers, so CPU instruction sets don't provide those.
10:19:08 <fen> but if there are machine level bool opperations, sure that eg making a 7 = 4 + 2 + 1 bit word cant be impossible?
10:19:24 <fen> it seems less clumsy than discarding the bit of an 8 bit word
10:20:06 <fen> it might not seem so bad with 7 vs 8, but for like 50 vs 64 its strating to become more significant
10:20:08 <Solonarv> this would take quite long to explain, and it's a subject I'm rather shaky in.
10:20:40 <koz_> Clarification on what Solonarv said - _some_ CPU instruction sets provide them.
10:20:43 <Solonarv> I'd recommend you look into other resources than #haskell if you want to learn about that
10:20:49 <koz_> x86 does, but ARM is 'word width or GTFO'.
10:21:06 <koz_> fen: Machine-level bool operations operate on whole words.
10:21:18 <koz_> Usually with the semantics 'all bits low false, anything else true'.
10:22:24 <oak> Also x86 only has those 8-bit 16-bit etc. operations just because of backwards compatibility, they are slower than using 32-bit or 64-bit instructions
10:22:53 <fen> ohno!
10:23:33 * hackage hoauth2 1.8.3 - Haskell OAuth2 authentication client  http://hackage.haskell.org/package/hoauth2-1.8.3 (HaishengWu)
10:23:35 <koz_> Yeah, the registers overlap.
10:23:47 <koz_> AX, EAX and RAX are all the same register.
10:24:03 <Solonarv> and usually you're not saving memory by using smaller types, because it's all aligned anyway
10:24:09 <koz_> Or should be.
10:24:24 <koz_> Some architectures bite you for unaligned accesses, or forbid them entirely.
10:24:28 <koz_> *cough*ARM*cough*
10:25:03 <koz_> 'Bit packing' can sometimes be useful (I'm using it to great effect in something I'm working on), but generally shouldn't be the first, second or _tenth_ thing you reach for.
10:25:08 <Gigabitten> I'm through LYAH, and I want to get started on some really basic non-basic stuff. Is there a solid, generally used library for graphics rendering that I can try playing with, or are there a bijillion different options depending on what I want to do?
10:25:08 <fen> so it seems like this ignoring the excess bits is the only way to go, any chance of a better description to try and implement that off, or an existing implementation
10:25:12 <geekosaur> x86 is generally configured to permit, at a penalty of extra clock cycles for unaligned access.there'sa PSR bit to throw exceptions instead
10:25:46 <koz_> fen: Are you asking 'how do I mask bits'?
10:25:51 <Gigabitten> oh geez I jumped in here and found everyone talking about more complicated stuff than I expected lol
10:25:53 <fen> maybe!
10:25:54 <__monty__> Gigabitten: Usually there's multiple options.
10:26:29 <koz_> fen: https://en.wikipedia.org/wiki/Bit_manipulation
10:26:33 * hackage git-annex 7.20181121 - manage files with git, without checking their contents into git  http://hackage.haskell.org/package/git-annex-7.20181121 (JoeyHess)
10:26:33 <fen> whatever Soolnarv was suggesting above
10:26:43 <koz_> fen: Also this: https://graphics.stanford.edu/~seander/bithacks.html
10:26:48 <Solonarv> TL;DR fen wants a Word7 type
10:26:53 <Solonarv> at least, I think so
10:26:59 <koz_> You can read one of Knuth's monographs on this if you want _loads_ of detail, but that's tricky.
10:27:19 <Solonarv> Gigabitten: what are you trying to render? that'll affect the choices somewhat
10:27:35 <koz_> fen: Although to be honest, based on both today _and_ the other day, I suspect what you need to do is learn some basics about computer architecture.
10:27:39 <fen> Solonarv: yah, thats right, basically just for any n, not just powers of 2
10:27:42 <koz_> Since you seem to be missing vast swaths of that.
10:28:11 <Solonarv> fen: use the package that does exactly that!
10:28:22 <Solonarv> @hackage modular-arithmetic - it was linked earlier, too
10:28:22 <lambdabot> http://hackage.haskell.org/package/modular-arithmetic - it was linked earlier, too
10:29:05 <fen> koz_ read his BinInts in fortran, cant find it now though. for monte carlo (random numbers)
10:29:31 <koz_> fen: See my prior comment.
10:29:41 <fen> hmm
10:29:42 <koz_> Solonarv: That's _really_ neat.
10:31:15 <fen> not sure its as fast as it could be wrt arbitrary length words
10:31:43 <Solonarv> it should be as fast as whatever you pick for 'i'
10:32:20 <fen> anyway, all that stuff about architectures is ok, like clash for fpgs or something
10:32:44 <fen> ok Solonarv, that settles it. thanks
10:33:04 <koz_> Solonarv: Out of sheer interest, what timezone are you in?
10:33:11 <koz_> I typically see you on here during my morning.
10:33:57 <Solonarv> Paris (GMT+1), I tend to stay up really late though
10:34:02 <koz_> Ah, I see.
10:34:12 <koz_> I'm GMT+12.
10:34:13 <koz_> I think.
10:34:17 <koz_> Timezones make my brain hurt.
10:34:37 <MarcelineVQ> koz_: make a function that does the thinking for you :>
10:34:39 <Tuplanolla> The documentation for `Applicative` says that "As a consequence of these laws, the `Functor` instance for `f` will satisfy `fmap f x = pure f <*> x`". How can this be, when the laws make no mention of `fmap`? Does the consequence actually arise from free theorems?
10:35:01 <Solonarv> Tuplanolla: without looking into the specifics, probably yes
10:35:31 <fen> :t liftA2
10:35:33 <lambdabot> Applicative f => (a -> b -> c) -> f a -> f b -> f c
10:35:43 <fen> :t (<*>)
10:35:45 <lambdabot> Applicative f => f (a -> b) -> f a -> f b
10:35:45 <koz_> Tuplanolla: It's kinda the reason why we have Functor f => Applicative f - it's what I call an 'honesty constraint'. If you can define law-abiding 'pure' and <*>, you can recover a law-abiding fmap.
10:35:54 <fen> :t (<$>)
10:35:56 <lambdabot> Functor f => (a -> b) -> f a -> f b
10:36:04 <koz_> So having that constraint there basically is us admitting this fact.
10:37:00 <Tuplanolla> I don't see it.
10:37:13 <fen> fmap id == id ...
10:37:17 <Solonarv> on top of that: there is at most one law-abiding fmap for any type
10:37:36 <Solonarv> so the ability to recover fmap + uniqueness of fmap means they must be the same
10:37:47 <Tuplanolla> Free theorems it is, then.
10:38:28 <fen> you should be able to write the proof...
10:38:39 <Solonarv> which proof?
10:39:09 <fen> either
10:39:23 <fen> that fmapDefault is lawful, or fmap f x = pure f <*> x
10:41:41 <Solonarv> we have 'pure id <*> x = x' as one of the applicative laws, so that's a law-abiding fmap.
10:41:41 <Solonarv> there is at most one law-abiding fmap, so this is in fact *the* law-abiding fmap.
10:43:07 <fen> so which is faster, using the Mod wrapper with Word64 or making a WordN by either masking WordM^2 or writing a new binary addition algo 
10:43:40 <glguy> I remember we had cases with more than one law-abiding fmap when you allowed strict fields in your datatypes, but now I can't remember the example
10:44:59 <Solonarv> probably Mask >= Mod >> new algo, in terms of speed
10:45:14 <Solonarv> there should be barely any difference between the first two, thouh
10:45:26 <Solonarv> and masking obviously only works for powers of two
10:45:32 <Tuplanolla> I wonder what sort of axiom schema for free theorems one would need to formalize these type class laws in Coq.
10:53:36 <fen> thanks Solonarv
11:13:03 * hackage stp 0.1.0.1 - Simple Theorem Prover  http://hackage.haskell.org/package/stp-0.1.0.1 (bor0)
11:15:35 <freeman42x]NixOS> is it ok to set build-depends for base package to an exact version?
11:16:07 <amx> that is in fact what `cabal init` gives you
11:16:29 <amx> well, sort of
11:17:05 <Solonarv> it's okay, but there's usually no need to 'base == 4.11.*' works just as well
11:18:11 <geekosaur> usually exact versions mean avoiding bugs in specific ghc versions via the base versions they bring along
11:24:45 <freeman42x]NixOS> I set it up to specific version and now I am getting a lot of "not in scope type constructor or class Integer" and similar errors, basically for types from prelude if I understand correctly
11:24:56 <freeman42x]NixOS> this is using Haskell IDE Engine
11:30:11 <amx> I doubt that's the reason but it's easy enough to set it to something like >= 4.11 && < 5 for testing?
11:33:03 * hackage escaped 1.0.0.0 - Produce Text with terminal escape sequences  http://hackage.haskell.org/package/escaped-1.0.0.0 (PatrickBrisbin)
11:53:33 * hackage simple-get-opt 0.2.0 - A simple library for processing command-line options.  http://hackage.haskell.org/package/simple-get-opt-0.2.0 (IavorDiatchki)
12:02:06 <Tuplanolla> @free fmap
12:02:07 <lambdabot> Extra stuff at end of line in retrieved type "Functor f => (a -> b) -> f a -> f b"
12:05:54 <int-e> @free fmap :: (a -> b) -> F a -> F b
12:05:55 <lambdabot> g . h = k . f => $map_F g . fmap h = fmap k . $map_F f
12:20:45 <Tuplanolla> @free apA :: F (a -> b) -> F a -> F b
12:20:45 <lambdabot> (forall h. (forall k p. g . k = p . f                        =>                         h k = p)           =>            $map_F h x = y) => $map_F g . apA x = apA y . $map_F f
12:20:58 <Tuplanolla> I don't know what I expected.
12:23:01 <Zemyla> Huh, I figured out a way to turn traversals into crosswalks. :O
12:23:13 <ski> crosswalks ?
12:23:29 <Tuplanolla> Is this about commuting?
12:24:01 <Zemyla> http://hackage.haskell.org/package/these-0.7.5/docs/Data-Align.html
12:28:25 --- mode: glguy set +v fen
12:29:01 <fen> is there a fast way to get a gausian from the gradient at 2 points?
12:29:30 <fen> hmm, maybe thats over-determined 
12:30:05 <fen> maybe, the value at 3 points
12:30:33 <fen> it might be faster to just linearly interpolate...
12:31:15 <Tuplanolla> Come on, that was a top tier joke.
12:31:36 <fen> but it might be more accurate if the underlying Gaussian can be inferred   
12:32:42 <fen> the good thing about gausians is they can be approximated by blurring 
12:32:56 <fen> and thats a local operation 
12:33:25 <fen> better than trying to find a NURB or spline or polynomial approximation 
12:33:35 <fen> better than trying to find a NURB or spline or polynomial approximation 
12:34:02 <fen> especially for 1/r^2 interaction laws
12:35:21 <fen> actually, maybe the gausians from several points would interact, yeah, linear interpolation is probably best
12:35:26 <fen> sorry, nvm!
12:48:03 * hackage qnap-decrypt 0.3.3 - Decrypt files encrypted by QNAP's Hybrid Backup Sync  http://hackage.haskell.org/package/qnap-decrypt-0.3.3 (alexkazik)
12:51:40 <Ariakenom> Tuplanolla: haha
12:51:51 <davean> go tolt
12:56:01 <alanz> It seems weird that Data.Set has map but not fmap
12:56:46 <Tuplanolla> That's because Haskell's `Functor` is polymorphic, but `Set` is constrained to `Ord`ered types, alanz.
12:57:01 <alanz> ah, that makes sense. Thanks.
12:57:21 <Tuplanolla> Morally, it's still a functor.
12:57:59 <alanz> yes, which is why I was surprised.  But it can't actually be one
12:58:09 <lavalike> why is Set constrained to Ord types?
12:58:49 <Tuplanolla> You get better asymptotic and practical performance, lavalike.
12:58:50 <alanz> lavalike, so you can tell if one element is the same as another
12:58:52 <amx>     The implementation of Set is based on size balanced binary trees (or trees of bounded balance)
12:59:13 <Solonarv> you actually only need Eq to enforce uniqueness
12:59:32 <alanz> well, you could do it with Ord or with Eq
12:59:41 <earthy> Solonarv: yeah, but ord allows faster implementations
12:59:43 <alanz> but I am sure Ord is generally a lot cheaper
12:59:48 <Solonarv> Eq is a superclass of Ord, yes
13:00:21 <Solonarv> and I was in the process of typing that! yes, Ord gets you vastly better performance and doesn't actually exclude a lot of types.
13:00:27 <geekosaur> but Ord mans you can build a tree and know which branch to folow by comparing the key in the current node with the  one you're searching for. there's also HashMap which requires a Hashable constraint instead of Ord
13:00:34 <alanz> I see in the docs you can do showTree or showTreeWith on a Data.Set
13:01:51 <geekosaur> but the Ord thing does reveal that we kinda abuse Ord; con sdier that there's no meaning Ord mathematically for a pair (isomorphic to a complex number), but it's entirely sensible to have one for the purposes of an ordered tree structure
13:02:36 <Solonarv> the phrase "arbitrary ordering" exists for a reason!
13:03:21 <Tuplanolla> There is such a thing as a lexicographic order topology.
13:04:39 <mniip> and we can't even encode the category of monotonous functions in haskell
13:05:17 <Solonarv> well, we *can*. But the typechecker doesn't help enforce monotonicity.
13:06:13 <Tuplanolla> It's not too late to overcome being metrizably challenged!
13:07:47 <mniip> hmmm
13:08:01 <Solonarv> Hold my ~~beer~~ coffee
13:08:09 <mniip> I'm getting ideas
13:08:17 <mniip> it involves singletons
13:15:29 <dmwit> alanz: I don't know if the docs say this, but I would treat showTree and showTreeWith as unsafe, in the sense that equal sets may not produce equal strings.
13:16:45 <alanz> dmwit, they are in the debug section, I would treat them as something interesting to gain an understanding of how they work under the hood
13:17:33 <dmwit> > S.showTree (S.fromList [1..5]) == S.showTree (S.fromList [2,1,4,3,5])
13:17:35 <lambdabot>  False
13:17:42 <dmwit> > S.fromList [1..5] == S.fromList [2,1,4,3,5]
13:17:45 <lambdabot>  True
13:21:15 <dmwit> (I have a similar complaint about some other abstract data types on Hackage. I wish they'd more clearly indicate -- e.g. by including "unsafe" in their name, but other ways would be fine, too -- which operations violate the abstraction boundary.)
13:23:50 <dmwit> (For Set in particular, I agree with alanz that the "Debugging" section header is pretty clear indication of this.)
13:26:41 <int-e> > fmap (S.size . S.fromList . fmap (S.showTree . S.fromList) . permutations . enumFromTo 1) [0..9]
13:26:47 <lambdabot>  [1,1,2,1,4,6,4,17,32,44]
13:27:08 --- mode: glguy set +v m-renaud
13:30:09 <dmwit> Oh, I didn't think to ask GHC to search for a counterexample for me. Smart!
13:30:52 <lavalike> > fmap (S.size . S.fromList . fmap (S.showTree . S.fromList) . permutations . enumFromTo 1) [0..]
13:30:58 <lambdabot>  mueval-core: Time limit exceeded
13:30:59 <dmwit> Ah, of course there's a size-2 counterexample. Should have known.
13:40:24 <duairc> I've been continuing my experiments with recursion-schemes, and I think I'm making progress
13:40:27 <duairc> This is what I have now: https://gist.github.com/duairc/3aa5c72399c9cdeea0f352d01ba6ff2d
13:41:16 <duairc> I'm wondering if there's some way to compose the Expr -> Expr functions so that they don't traverse the whole tree every time.
13:45:30 <duairc> I know that cata f . cata g = cata (f . project . g), but I can't use that for rightAssociate{Add,Multiply}, because their catamorphisms make an Expr -> Expr, not an Expr
13:50:14 --- mode: glguy set +v ijmustafa
13:50:24 <ijmustafa> Has anyone here used https://github.com/facebook/duckling before?
14:07:38 <lavalike> ijmustafa: nope, but neat
14:11:27 <ijmustafa> I'm trying get a SingleValue from a ResolvedVal in an Entity defined here: https://hackage.haskell.org/package/duckling-0.1.6.1/docs/Duckling-Types.html
14:11:43 <elgoosy> hi, in this video https://www.youtube.com/watch?v=fCoQb-zqYDI he tries to explain the IO in haskell. I made a snippet https://pastebin.com/z6GHKL8F. How the returned value from printStr (World) is the new state of the world. It is the same data constructor that was passed as an argument to the function. It's the same value, - World. And if meant that every time you write data constructor World you get a different Wo
14:11:43 <elgoosy> rld(in that instance of time let's say), then that value (World) in itself is not pure and is against what a value is. 5 = 5. World = World. 
14:12:44 <ijmustafa> Getting the ResolvedVal out of an Entity is pretty straight forward. But when it comes to anything deeper than that, I can't seem to figure out how to extract any info out of the ResolvedVal.
14:13:01 <glguy> elgoosy: You aren't meant to think of it that literally. It's not how IO actually works
14:13:48 <glguy> "pure" is a property of functions, so it doesn't really make sense to ask if "World" is pure
14:14:00 <ijmustafa> Here's an example of what a resolvedVal looks like: RVal AmountOfMoney (SimpleValue (SingleValue {vCurrency = Dollar, vValue = 21.95}))
14:14:28 <ijmustafa> How do I go about getting vCurrency and vValue?
14:15:47 <Solonarv> mniip: https://gist.github.com/Solonarv/9fd7f64059375c769f9d0715bc94f7b3 -- thoughts?
14:16:02 <elgoosy> glguy: so i should think of a World constructor as computation always giving me an actual state of world at a particular point in time?
14:16:58 <glguy> elgoosy: You'll have to think about it however the author of the video described it. I'm not sure how to salvage that explanation of what IO is
14:18:17 <mniip> Solonarv, you want another method in Cat: observe :: p x y -> Dict (Ob p x, Ob p y)
14:19:21 <Solonarv> ah, yes - I was going off of ed kmett's half-remembered gist
14:20:47 <mniip> Solonarv, I was thinking of something different
14:21:03 <Solonarv> oh, I figured; this is just the direction I ran off into
14:51:13 <monochrom> I am actually a bit disappointed that even Hutton's book uses IO a = World -> (World, a)
14:52:20 <Solonarv> to be fair, there's Additional Confusion because that's what it is in GHC, too
14:52:26 <monochrom> It would not be a crime if it came with bold enlarged font saying "this is a beginner model and World is completely fictional".
14:52:36 <koz_> monochrom: One big reason why it was so mind-blowing to me when I read the ST paper.
14:52:46 <monochrom> But both Hutton and SPJ merely use normal fonts.
14:52:49 <koz_> (since I had a sorta-similar mental model before then)
14:53:33 <amx> Details are hazy, but I think a long time ago this is more or less how it was implemented
14:54:24 <monochrom> How you know you have misrepresented it: When readers actually believe World has a data constructor.
14:55:24 <Solonarv> Bleh. Ed's Categories.hs paste breaks my brain.
14:55:33 <Solonarv> er, s/paste/gist/
14:56:28 <monochrom> To be clear, I am not entirely against World -> (World, a).  I am just against forgetting to warn readers, in bold enlarged fonts, three times, that it is total fiction.
14:57:02 <monochrom> (Notice that on average you have to tell people the same thing three times before they actually listen.)
14:57:10 <amx> oh it was merely discussed. https://www.microsoft.com/en-us/research/wp-content/uploads/2016/07/history.pdf   section 7.1
14:57:18 <monochrom> (1st time, they aren't even listening.  2nd time, they're still in denial.)
14:58:49 <monochrom> GHC uses a phantom world type.  Hugs, IIRC different versions did  different things, there was a phantom world type and there was a free monad.
15:02:04 <monochrom> The benefit of a phantom world type is the following.  Pure code is sequenced by lazy evaluation and data dependency, IO code by >>=.  If you want one single code generator that does both, the world type can introduce data dependency equivalent to >>= order.
15:03:03 <glguy> Trying to introduce a pretend World type seems to just swap one problem for another
15:03:33 <glguy> It's doesn't seem necessary or productive to drag functions into the picture when trying to understand IO
15:03:37 <monochrom> But clearly this is a code generation trick.  The generated code does not pass around "world" values that contain information about what I'm going to enter to getLine tomorrow.
15:05:18 <monochrom> glguy, I'm sympathetic to telling a world story because the other two options are: a free monad story (equally fictional) and "it is abstract, just don't ask".
15:05:38 <monochrom> My IO tutorial does the latter but we know how many people simply don't buy it.
15:05:58 <monochrom> Everyone wants a concrete model. Everyone wants to hear white lies.
15:06:14 * geekosaur describes it as a baton
15:06:41 <clever> monochrom: https://hackage.haskell.org/package/acme-realworld
15:07:12 <monochrom> Everyone wants to imagine "queue means mutable linked list" even though a lot of implementations are not and it shouldn't matter.
15:07:21 <Solonarv> you forgot one: [Request] -> [Response] ;)
15:07:31 <monochrom> No one wants to learn queues as a bunch of algebraic laws.
15:07:32 <geekosaur> backwards :)
15:07:33 <hpc> monochrom: imagine explaining how it's actually implemented
15:07:56 <hpc> "ghc defines this but has a pragma that makes it not exist at runtime, IO actions are the same as their unsafePerformIO'd thunks and nothing is sacred"
15:08:24 <koz_> Alternatively, getting into rank-2 types so that people can follow the ST paper.
15:08:32 <hpc> then watch them go "oh, so it's abstract then"
15:08:47 <koz_> (to be fair, isovector's book has a really good explanation which helped me)
15:10:09 <monochrom> geekosaur: Could you tell me more about the baton story?
15:10:41 <geekosaur> the wole point of the so-called world is ensuring sequencing. whch is more or less the same story as relay races
15:11:09 <monochrom> Oh, that baton.
15:11:30 <monochrom> I thought Herbert von Karajan or something.
15:11:41 <geekosaur> butit never does anyting, so ghc just makes it go away and records the result of the race
15:13:05 <dmwit> White lies are a proud pedagogical tradition.
15:13:46 <koz_> It actually makes me wonder how _I_ would go about teaching this to someone.
15:13:56 <koz_> (not had to do that yet, but it's inevitably coming)
15:14:21 <monochrom> Yes I'm sympathetic to white lies.
15:15:13 <monochrom> Actually the kind of white lies that actually give you some predictive power and good-enough predictions.  (I'm a scientist.)
15:15:52 <hpc> the best white lies are actual answers that just aren't as detailed
15:15:52 <Welkin> what about black lies?
15:16:07 <koz_> Welkin: For that, go into the tech industry. :P
15:16:52 <Welkin> oh my god, ocharles  has been infected by matrix too
15:17:06 <monochrom> "white paper" = black lies. There. :)
15:17:07 <koz_> Welkin: ??
15:17:20 <Welkin> notice ocharles[m]
15:17:24 <koz_> Ah.
15:17:35 <Welkin> there is a women's shop called White House, Black Market
15:17:42 <Welkin> I always wonder if they sell black market goods
15:17:44 <monochrom> ocharles read the matrix white paper. :)
15:17:48 <koz_> LOL
15:17:54 <Arahael> monochrom: The "white lies" you seem to like are usually called "assumptions".
15:17:58 <Welkin> and have some link to the white house?
15:17:59 <Arahael> :)
15:18:18 <koz_> Welkin: For extra irony, 'The White House' is a high-end strip club in my city.
15:18:19 <Welkin> or the porn site whitehouse.org
15:18:31 <Welkin> or was it .com
15:19:25 <clever> Welkin: nixos.com was also a porn site until just recently
15:19:26 <Welkin> where is our resident porn historian?
15:19:59 --- mode: glguy set +v kderme
15:21:41 * hackage DAV 1.3.3 - RFC 4918 WebDAV support  http://hackage.haskell.org/package/DAV-1.3.3 (ClintAdams)
15:21:50 <Welkin> Clint: is that you?
15:23:40 <monochrom> Bah why is functional programming so hard.
15:23:56 <Arahael> Getting stuff to work is hard. :)
15:24:05 <koz_> monochrom: Because all programming is hard, functional is just more honest.
15:25:31 <MarcelineVQ> monochrom: I can recommend someone you could ask about tutoring under
15:25:45 <monochrom> Backus might actually like the [FromUser] -> [ToUser] model.
15:26:39 <MarcelineVQ> his name is albert and he's really smart and knows all kinds of stuff about various things and subjects and is a sharp dresser with a no-nonsense attitude
15:26:52 <monochrom> :)
15:27:57 <Arahael> Being a sharp dresser is certainly a plus!
15:28:09 <koz_> My secondary supervisor is a sharp dresser.
15:28:19 <MarcelineVQ> It's nearly as good as being a shapr dresser
15:28:53 <monochrom> https://steamcommunity.com/market/listings/440/Genuine%20Sharp%20Dresser haha
15:29:57 <MarcelineVQ> I figured it would be a link to a dresser made from 16 triangles
15:30:12 <monochrom> haha
15:30:34 <koz_> MarcelineVQ: How about a dresser made of razor blades?
15:30:40 <koz_> _That_ would be a sharp dresser.
15:30:58 <Welkin> you mean a cabinet used for storing clothing?
15:30:59 <MarcelineVQ> back in my day 16 was a luxury dresser, practically a wardrobe, if it weren't for the fact that wardrobes are easier to model
15:31:21 <koz_> Welkin: Natural language has wonderful ambiguity properties.
15:32:14 <monochrom> Hey, Narnia-themed first-person hand combat game: The Lion, The Witch, and The Sharp Dresser.
15:32:38 <koz_> monochrom: That sounds like a C.S. Lewis/Clive Barker crossover.
15:32:46 <koz_> Like, Narnia + Hellraiser.
15:34:25 <Welkin> does it include all of the christian undertones of cs lewis?
15:34:40 <koz_> Welkin: I think 'undertones' is being a bit generous.
15:34:50 <monochrom> Yes and no. There is a slider in the settings for that. >:)
15:34:51 <Welkin> okay
15:34:52 <koz_> IIRC, C.S. Lewis wasn't terribly subtle.
15:34:53 <Welkin> overtones
15:35:57 <MarcelineVQ> Yeah, what is that in modern critic parlance?  The Plot Convenience, The Diversity Hire, and The Macguffin
15:36:14 <Welkin> macguffin
15:36:41 <MarcelineVQ> But throughout our magic journey we learn that the kids were the real macguffin all along
15:37:07 * hackage hspec-leancheck 0.0.3 - LeanCheck support for the Hspec test framework.  http://hackage.haskell.org/package/hspec-leancheck-0.0.3 (rudymatela)
16:31:57 <koz_> I'm trying to use genSingletons, but it gives me a pile of 'The exact Name 'd_...' is not in scope Probable cause: you used a unique Template Haskell name, perhaps via newName, but did not bind it'.
16:32:04 <koz_> What's going on with that?
16:32:57 <MarcelineVQ> dunno about that specifically but did you use it after defining your datatypes? TH is order-sensitive
16:33:07 <koz_> Never mind, should have read further, need ScopedTypeVariables.
16:33:09 <koz_> Or it blows up.
16:33:49 <koz_> (with that kind of error _first_)
16:35:45 --- mode: glguy set +v fen
16:39:36 <fen> so, the zipper comonad duplicate instance should be strict! otherwise navigating from the current location to another, where the duplicate has replaced a value with a version of the zipper navigated to that location, when accessed, using something of cokliesli type such as extract or a stencil, would call that zipper and trigger its evaluation
16:40:48 <fen> this is the result of lazyness, whereas if the comonad instance forced the navigation through being strict, the zipper stored as the value at each position of the duplicated zipper would already be navigated to the correct position
16:41:50 <fen> the reason that this is important is because the duplicate process visits each value in turn and replaces it with a carried copy of the zipper which is updated to the next position at each location along the path of the traversal
16:42:11 <fen> the way zippers work means that this "next" operation is very cheap
16:42:36 <fen> however, this sharing of computational expense is not achieved if the zipper is not strictly evaluated at each location
16:43:03 * hackage purescript 0.12.1 - PureScript Programming Language Compiler  http://hackage.haskell.org/package/purescript-0.12.1 (garyb)
16:43:44 <fen> if left lazily unevaluated, if calling two adjacent locations of the duplicated zipper, each of the navigations would happen independently of each other (?) and the shared computation would not be achieved
16:43:54 <fen> does that sound right/
16:43:55 <fen> ?
16:46:39 <fen> the only thing that might mean that even without strict evaluation, that the computation would be as cheap as it should be is if the lazy call references the other value, like, for two adjacent values, that one is exactly a "next" call on the other (forwards/left for a linear zipper) 
16:47:04 <fen> is there a chance that somehow lazy evaluation can still use these shared computations?
16:47:15 <fen> is there some term to refer to this process?
16:48:24 <fen> the strict call on the duplicated zipper removes these doubts, but is it then more memory intensive than allowing the lazy referencing, if that is actually how it works?
16:51:30 <koz_> When you read a fundep like r -> a, does this mean 'a uniquely determines r'?
16:51:44 <Solonarv> no, it means 'r determines a'
16:52:14 <geekosaur> you can read the arrow as 'implies'
16:52:31 <koz_> So, for example, for MonadState, we have 'class Monad m => MonadState s m | m -> s'.
16:52:42 <koz_> Does this mean that each m has its own, unique, associated s?
16:53:33 <geekosaur> yes
16:54:04 <koz_> And the 'm' parameter is 'rest of monadic stack', right?
16:54:14 <Solonarv> there's no requirement for uniqueness
16:54:45 <Solonarv> the fundep means "if you know what 'm' is, then you know what 's' is"
16:55:04 <koz_> Ah, OK.
16:55:15 <koz_> That makes more sense, thank you.
16:56:11 <Axman6> so in the case of State you would end up having State s -> s
17:04:21 <dmwit> koz_: not unique
17:04:42 <dmwit> Two different monads m may have the same state type s.
17:07:37 <Solonarv> however, 'm' must determine 's' - so it's not possible to have 'instance MonadState s1 m' and 'instance MonadState s2 m' at the same time
17:08:06 <Axman6> edwardk: pinging you as someone who might be able to help fen with his questions about zippers, comonads, lenses etc.
17:10:20 <fen> lenses?
17:10:48 <koz_> dmwit, Solonarv: Thank you for that - I definitely get it now.
17:10:54 <fen> here is what the "lazy" version looks like; https://bpaste.net/show/e795fa303d82
17:11:33 <koz_> Also, how does the TH-created singletons stuff determine what fromSing does?
17:14:02 <koz_> Or, better question: How does genSingletons define Demote?
17:15:38 <fen> actually, there is an even simpler version for linear zippers (the version above works for arbitrary shapes where directions `i' are provided to follow the traversal)
17:18:59 <fen> so simple! https://bpaste.net/
17:19:16 <fen> hmm.. https://bpaste.net/show/cb1dbdd6402a
17:24:03 * hackage loc 0.1.3.4 - Types representing line and column positions and ranges in text files.  http://hackage.haskell.org/package/loc-0.1.3.4 (chris_martin)
17:25:33 * hackage loc-test 0.1.3.4 - Test-related utilities related to the /loc/ package.  http://hackage.haskell.org/package/loc-test-0.1.3.4 (chris_martin)
17:31:04 <Axman6> fen: this looks relevant: https://stackoverflow.com/questions/25554062/zipper-comonads-generically
17:31:32 <fen> https://bpaste.net/show/02bd094e6394
17:31:40 <fen> Axman6
17:31:41 <fen> no
17:31:42 <fen> sorry
17:31:52 <fen> they did good work
17:32:01 <fen> but thats not the approach taken here
17:33:32 <fen> oh thought that was a link to scrap your zippers
17:33:41 <fen> got thrown by the generics thing
17:33:49 <fen> not using generics
17:34:11 <fen> anyway, this paste shows the comonad default used to navigate a linear zipper
17:34:41 <fen> the question above regarding strict evaluation and lazyness and sharing of the carried zipper stands
17:37:43 <fen> Axman: that is a hellish so post!
17:38:20 <fen> and yes, there is generics! 
17:38:42 <fen> it should be much easier to see how zippers form the comonad at the heart of the question from that paste
17:42:44 <fen> really its just a question about lazy evaluation
17:43:54 <fen> the result of the function "test" has values which when accessed, do they share partial computation, or is accessing eg the second and third values making a total of 5 calls to next
17:44:00 <fen> where it should only be 3
17:45:18 <fen> wait, it should be 2, and if it does it wrong it will be 3
17:45:31 <fen> i.e. is accessing the third value calling next on second value, or calling next 2 times on the original zipper, regardless of the call already performed to get to the second value
17:49:10 <koz_> % :info NFData
17:49:10 <yahb> koz_: ; <interactive>:1:1: error: Not in scope: `NFData'
17:49:35 <Solonarv> @hackage deepseq -- koz_
17:49:35 <lambdabot> http://hackage.haskell.org/package/deepseq -- koz_
17:49:45 <koz_> Solonarv: Thank you!
17:50:14 <fen> maybe there is a way to see how many times a function is called...
17:50:35 <fen> at wors could just do unsafecoerce and putStrLn
17:51:01 <fen> but it would be nice if there was some kind of justification based on reasoning around lazy evaluation
17:51:44 <fen> like, if the list zipper was really long, and it was accessed at 2 distant locations, would it be reasonable to expect this sharing to take place?
17:56:23 <fen> hmm, seems to only call twice as desired; https://bpaste.net/show/09218d0c2f82
17:57:18 <fen> so whats happening there under the hood? why does laziness manage to refer to the previous value?
17:57:47 <fen> might this cause a memory overflow?
17:58:02 <fen> or would strict evaluation be more or less memory intensive?
17:58:54 <fen> :r
17:59:56 --- mode: glguy set +v orzo
18:00:02 <orzo> I'm trying to use cabal v2-build on a new project generated with cabal init.  The v1- style build works fine, but v2- is causing it to fail and reports missing dependencies that it should not need.  I looked in this directory and in the parrent directory for .ghc* and *.project files, and there are none.  What could be the issue?
18:05:45 <koz_> Someone who knows constraints (the library): Is there a less Java-like way to write this? https://gist.github.com/kozross/efac5cf011124501f04b5bbd304935fd
18:07:11 <koz_> (yes, I am using both singletons and constraints)
18:10:34 <orzo> answer to my own question: v2-build is apparently looking at extra directories that happen to have cabal files in my current dirrectory and assuming i want to build those.  I don't know how to tell it to only build the cabal file in the cwd, so i ended up moving all my scrap out to another directory in order to make it work
18:11:36 <fen> koz: im so sorry
18:20:53 --- mode: glguy set +v bonjo
18:23:24 <koz_> How would I actually use :- from Data.Constraint?
18:24:51 <fen> % :t (:-)
18:24:51 <yahb> fen: ; <interactive>:1:1: error:; * Data constructor not in scope: :-; * Perhaps you meant one of these: `Seq.:<' (imported from Data.Sequence), `:<' (imported from Control.Lens), `Seq.:>' (imported from Data.Sequence)
18:26:06 <fen> newtype (:-) = Sub (a => Dict b)
18:27:56 <fen> so this basically turns one Dict into another that requires the first
18:28:45 <koz_> Specifically, I need to infer a superclass constraint.
18:28:55 <koz_> Or rather, a superclass _instance_.
18:29:15 <fen> right, so thats what all those cases are
18:29:27 <koz_> fen: This is unrelated to my previous paste.
18:29:31 <fen> oh
18:29:34 <fen> good
18:29:37 <mniip> % :t Sub
18:29:38 <yahb> mniip: (a => Dict b) -> a :- b
18:29:43 <mniip> you just have to ask for the right thing
18:29:46 <fen> ah
18:30:06 <koz_> mniip: Looks like I'm gonna have a withDict pyramid of doom.
18:30:20 <mniip> for?
18:30:23 <fen> % :t withDict
18:30:23 <yahb> fen: Dict a -> (a => r) -> r
18:31:01 <koz_> I have two withDicts nested inside each other to demonstrate class constraints, but now GHC is complaining that I need to demonstrate instances of the _superclass_ as well.
18:31:14 <koz_> Which means I'm gonna have to nest two more withDicts inside that AFAICT.
18:31:20 <rotaerk> hmm building a test suite with QuickCheck.  the thing I need to test now is a function that, provided a texture file name, reads its contents and fills a buffer.  however, I'm not sure I can really use Gen to produce any variation in test cases, since I basically want to test on all the texture files within a given folder
18:31:23 <fen> % :t flip withDict Sub
18:31:24 <yahb> fen: ; <interactive>:1:6: error:; * Couldn't match type `c' with `(a0 => Dict b0) -> a0 :- b0'; `c' is untouchable; inside the constraints: a; bound by a type expected by the context:; a => c; at <interactive>:1:6-13; `c' is a rigid type variable bound by; the inferred type of it :: Dict a -> c; at <interactive>:1:1; Possib
18:31:29 <fen> % :t flip withDict (:-)
18:31:29 <yahb> fen: ; <interactive>:1:6: error:; * Couldn't match type `b0' with `c'; `b0' is untouchable; inside the constraints: a; bound by a type expected by the context:; a => c; at <interactive>:1:6-13; `c' is a rigid type variable bound by; the inferred type of it :: Dict a -> c; at <interactive>:1:1; Possible fix: add a type signa
18:31:33 <fen> oh damn sorry
18:32:19 <rotaerk> should I just build a monadic quickcheck property that fetches all these files ... or should I hardcode the names of files into a list and use Gen to pick them
18:32:28 <rotaerk> or what
18:32:45 <fen> well, you could read the file names using getDirectorContents...
18:33:03 <rotaerk> right, but that'd have to be *inside* the monadicIO block of the property
18:33:07 <rotaerk> Gen doesn't do IO
18:33:09 <fen> but is QuickCheck really the best way to test *all* the cases?
18:33:27 <rotaerk> hmm, is there an alternative I should use here?
18:34:08 <fen> not sure, whats the test?
18:35:07 <rotaerk> I think one thing I'll test is that the function successfully is able to read everything from the file that it's trying to read (i.e. no early EOF), and that once it's read everything it should, there's not leftover data
18:36:34 <fen> so whats wrong with the IO approach?
18:36:44 <rotaerk> can't really think of more precise checks than that for "did I read this file correctly"
18:37:05 <fen> its an IO [] right? but QuickCheck just wants to build a [] ?
18:37:21 <rotaerk> I'll be using IO to run the test, but what's unusual is that I need to use IO to get the test cases
18:37:30 <rotaerk> and thus can't use Gen
18:38:02 <fen> yeah, its more for like, building structured binary data or something
18:38:14 <fen> not so much for reading stuff in
18:38:16 <rotaerk> oh wait ... I see a Gen.Unsafe
18:38:41 <rotaerk> hmm maybe I *can* use Gen, then
18:39:30 <fen> wierd thats the option they provide rather than an IO option... guess they want a pure environment and it just has to be up to the user not to screw up the IO stuff...
18:40:30 <fen> safe effects only plz!
18:41:03 <rotaerk> I mean, a pure way I could test it is to have a function to *generate* these KTX texture files
18:41:17 <fen> hence Gen
18:41:32 <rotaerk> but I want to test on real world files, just in case there's some kind of deviation from the spec
18:41:59 <fen> ah, not your ability to implement such examples
18:42:47 <fen> not really sure why eg reading a file into binary would ever fail though?
18:43:10 <fen> is that really something that you need to test?
18:43:43 <rotaerk> fen, https://www.khronos.org/opengles/sdk/tools/KTX/file_format_spec/  this is the format I'm reading
18:43:45 <fen> like, is what your testing the code, or the validity of the file format
18:44:05 <rotaerk> there's some metadata, and there are multiple blocks of image data, each preceded by an image size
18:44:20 <fen> ok sure
18:44:24 <fen> that makes sense
18:44:54 <koz_> Never mind, I was proving the wrong thing. :P
18:45:01 <fen> but again, is it a test for running over all the examples or for the implementation of the code? not sure if quickcheck is designed for for one of those
18:45:03 <rotaerk> so if I am off a little bit and I read a size from the wrong place, then I proceed to read that number of bytes thereafter, I'm likely to under/overshoot the EOF
18:45:25 <rotaerk> it's a test to make sure my implementation works for existing KTX files
18:45:48 <fen> ah, so your code is valid if all the texture files are read in successfully, that sounds more like it
18:46:02 <rotaerk> yes
18:46:24 <fen> and you dont want to have to make something that generates valid texture files incase its broken in the same way!
18:46:25 <rotaerk> and I might have to find a larger variety of such files to thoroughly test, so I'd want to just be able to drop them into the folder
18:46:35 <fen> yeah, the Unsafe approach sounds right then
18:46:50 <rotaerk> I'll eventually make a generator, and the match up between that and the reader will also be tested
18:47:03 <fen> quickcheck would like that more
19:06:31 <rotaerk> hmm is there an abstraction that includes file handles but could also be used to read in-memory data?  not just a stream, but also with the ability to seek to specific positions and to get the full size
19:07:18 <Welkin> you mean seek a bytestring
19:08:04 <rotaerk> well, you'd "seek" within a bytestring by having some kind of bytestring reader that keeps track of the current index, or something
19:08:12 <rotaerk> just wondering if there's an existing abstraction for that
19:13:03 * hackage dhall 1.19.0 - A configuration language guaranteed to terminate  http://hackage.haskell.org/package/dhall-1.19.0 (GabrielGonzalez)
19:14:33 * hackage dhall-json 1.2.5 - Compile Dhall to JSON or YAML  http://hackage.haskell.org/package/dhall-json-1.2.5 (GabrielGonzalez)
19:17:03 * hackage dhall-text 1.0.14 - Template text using Dhall  http://hackage.haskell.org/package/dhall-text-1.0.14 (GabrielGonzalez)
19:17:06 <supersaiyan> hello everyone, if i wanted to print the length of a word, that would just be  print.length(x) ? if x = word
19:17:33 <glguy> print (length x)
19:17:40 <supersaiyan> glguy: thank you
19:21:23 <MarcelineVQ> that was a nice way to ask that
19:31:33 * hackage dhall-bash 1.0.17 - Compile Dhall to Bash  http://hackage.haskell.org/package/dhall-bash-1.0.17 (GabrielGonzalez)
19:35:35 <rotaerk> yeah I think while I could get something rigged up for this in quickcheck, I don't think quickcheck is the right tool for this test
19:36:13 <rotaerk> like, I could "generate" a random file name from the folder of textures, but it's going to run that 100 times, and there aren't that many files
19:37:03 <rotaerk> really just want to test against each file, every time, rather than sampling inputs
19:41:54 <monochrom> rotaerk: Maybe the "mmap" package.
19:43:06 <rotaerk> monochrom, hmm, thanks
20:17:58 <koz_> Can someone answer this singletons-related question? https://gist.github.com/kozross/eb0dfc657cd805f879a026aa69a8ed23#file-sized-hs-L285
20:18:06 <koz_> (the linked part is the question, the rest is given for context)
20:18:11 <koz_> jle`: ^
20:31:37 * hackage partial-semigroup 0.5.0.0 - A partial binary associative operator  http://hackage.haskell.org/package/partial-semigroup-0.5.0.0 (chris_martin)
20:33:33 * hackage partial-semigroup-hedgehog 0.5.0.0 - Property testing for partial semigroups using Hedgehog  http://hackage.haskell.org/package/partial-semigroup-hedgehog-0.5.0.0 (chris_martin)
20:40:33 * hackage path-text-utf8 0.0.1.2 - Read and write UTF-8 text files  http://hackage.haskell.org/package/path-text-utf8-0.0.1.2 (chris_martin)
20:59:03 * hackage proto-lens-arbitrary 0.1.2.5 - Arbitrary instances for proto-lens.  http://hackage.haskell.org/package/proto-lens-arbitrary-0.1.2.5 (JudahJacobson)
21:23:11 --- mode: glguy set +v govno
22:24:20 <jle`> koz_: you can do something like a Knockable GADT
22:24:46 <koz_> jle`: Oh yeah, that'd work...
22:24:55 <koz_> Seriously, your Introduction to Singletons is deep.
22:25:29 <jle`> data NotLine :: Shape a -> Type where NRRect :: NotLine ('Rectagle a); NRCuboid ('Cuboid a)
22:26:16 <koz_> NR?
22:26:27 <jle`> oh heh, NL, however you want to spell it
22:26:43 <koz_> NotRine
22:26:51 <jle`> or you could pass in refutation of line-ness, (forall n. Sing ('Line n) -> Void)
22:27:15 <jle`> hm, you'd have to link that to the s though.
22:27:16 <koz_> I think NotLine is probably a better approach. I guess your decidable package can also do this?
22:27:44 <jle`> yeah, the thing about LIne is that it takes a parameter so you can't just pass in a straightforward (Refuted (s :~: 'Line n))
22:27:56 <jle`> since that only refutes a single n.  you'd want to refute all possible n's
22:28:01 <koz_> Yeah.
22:28:09 <jle`> so that'd be Rank-N, (forall n. (s :~: 'Line n) -> Void)
22:28:27 <koz_> I guess that makes sense, yeah.
22:28:41 <koz_> How do I actually give evidence for this refutation though?
22:28:56 <jle`> it's possible for specific s
22:29:08 <jle`> just do an empty pattern match
22:29:47 <jle`> for example, rectNotLine :: forall n. (Rectangle a :~: 'Line n) -> Void
22:29:53 <jle`> rectNotLine = \case {}
22:30:03 <jle`> that's a complete pattern match because there are no constructors for that type
22:30:26 <jle`> there is no construct of type 'Rectangle a :~: 'Line n, so ghc verifies that you've handled every valid case.
22:31:04 <koz_> So how would I write slice' then?
22:32:12 <jle`> i added a comment
22:33:00 <koz_> Thanks!
22:33:58 <koz_> Also, do you know if I can clean up this constraints hurr-durr? https://gist.github.com/kozross/eb0dfc657cd805f879a026aa69a8ed23#file-sized-hs-L165
22:34:40 <jle`> i don't know if there's a nice way to do so
22:35:08 <koz_> It's literally 'drag in constraints through pattern matching then reify into Dict'.
22:35:23 <koz_> Suits was pretty much designed with that in mind.
22:35:34 <jle`> yeah, remember that these constraints can be thought of as typeclass dictionaries with methods
22:35:41 <jle`> and each combination is a different dictionary with different functions
22:35:51 <koz_> Even though the value-level constructor is the same.
22:35:54 <jle`> so you're essentialy enumerating over all possible implementations
22:36:15 <koz_> I could TH it I guess?
22:36:16 <jle`> each of those Dict's is a unique Dict, with different functions and implementations
22:36:32 <jle`> so you're basically building a different set of implementations for every possible combination
22:36:42 <koz_> Yeah, which is why I have to 'spell' it like that.
22:36:52 <jle`> it also depends on the nature of the typeclass
22:37:07 <koz_> A.Source you mean?
22:37:10 <jle`> if the typeclass has dozens of instances, that's basically doznes of implementations
22:37:12 <jle`> yeah
22:37:12 <koz_> (in this case)
22:37:26 <jle`> this type of thing would show up in a situation where there are actually dozens of instances of that typeclass
22:37:48 <jle`> however, if there are only a few instances of that typeclass, then there might be a way to clean it up maybe.
22:38:09 <jle`> each Dict should correspond to a completely separate instance of that typeclass that someone (usually) hand-wrote
22:38:11 <koz_> http://hackage.haskell.org/package/massiv-0.2.3.0/docs/Data-Massiv-Array.html#t:Source
22:38:31 <jle`> oh, so it looks like there are only a few instances
22:38:31 <koz_> I more or less spell the entire damn typeclass instance list, paired with every possible Shape.
22:38:36 <jle`> so maybe there might be a way to clean it up
22:38:44 <jle`> you have polymorphic instances
22:39:26 <jle`> can you list the instances each line corresponds to?
22:39:55 <jle`> there might be a way to clean it up, by taking advantage of the fact that the instances are defined polymorphically, and not separately for each dozens of combinations
22:40:09 <jle`> but i'm not familiar enough with the instances to know what instance the first pair represents, etc.
22:40:30 <koz_> Essentially, it confirms two things:
22:40:37 <koz_> 1) Index ix exists (that is, we can index sensibly)
22:40:44 <koz_> This is _guaranteed_ by Shape via DemoteShape.
22:40:55 <koz_> 2) If there's some kind of special requirement for the data, that I've met it.
22:40:59 <jle`> which instance are you using?
22:41:01 <koz_> (Unbox, Storable etc)
22:41:02 <jle`> in the list of instances
22:41:07 <koz_> All of them.
22:41:11 <jle`> i mean, for the first line
22:41:13 <jle`> the second line, etc.
22:41:14 <koz_> Since it's basically spelled for each representation type.
22:41:28 <koz_> As in, which instance would SLine _, SBoxed correspond to?
22:41:31 <jle`> yeah
22:41:44 <koz_> Index ix => Source B ix e
22:41:52 <koz_> If I were to fully instantiate.
22:41:56 <koz_> Source B Ix1 e
22:42:00 <koz_> For every possible e.
22:42:42 <jle`> right, so you could write a separate combinator Sing s -> Dict (Index (A.Ix (Dims s)))
22:43:03 <jle`> and when you match on SBoxed, just use that separate combinator to summon the Index ix => .. constraint you need, to make Source B ix e
22:43:21 <koz_> Yeah, that's cut the spelling by a third.
22:43:23 <jle`> case y of SBoxed -> case mkIxDict x of Dict -> Dict
22:43:38 <jle`> the point is that we're matching the structure of our proofs to the structure of our instances
22:43:52 <jle`> and because there are seven instances of Source, you now have at most 7 lines
22:43:59 <jle`> one for each instance
22:44:05 <jle`> instead of combinatorical explosion
22:44:21 <koz_> Yeah, that makes sense. Especially if I later add Hypercuboid Nat Nat Nat Nat.
22:44:31 <koz_> (what _is_ the 4D analog to the cuboid?)
22:44:53 <jle`> tesseroid? :)
22:45:12 <koz_> I guess that's a nicer name than 'hypercuboid'.
22:45:34 <jle`> tessercuboid would be explicitly 4-d
22:45:42 <jle`> hypercuboid is any n
22:45:58 <koz_> So explicitly 5D would be?
22:47:18 <jle`> cube -> cuboid, tesseract -> tesseroid, so penteract -> penteroid?
22:47:34 <jle`> or decateron -> decateroid
22:47:58 <koz_> Makes sense.
22:48:04 <jle`> an n-d hypercube is called an n-cube too so you could call it a 5-cuboid
22:49:11 <koz_> Makes sense, but I can't start a data constructor name with a number.
22:51:47 <Lears> If only numerals still had case.
22:52:27 <koz_> jle`: Your solution doesn't make the compiler very happy.
22:53:03 <dminuoso> Mmm, `ReaderT (IORef Foo) IO` or some record variant holding multiple IORefs is becoming my standard monad transformer stack. It's quite interesting that deeply layered monad transformers feel inadequate for many uses.
22:53:06 <koz_> (the SLine match blows up complaining that Void isn't a 'entire rest of function')
22:53:44 <jle`> hm, what's the error?
22:54:39 <koz_> jle`: https://gist.github.com/kozross/eb0dfc657cd805f879a026aa69a8ed23#gistcomment-2766058
22:56:17 <jle`> oh yeah, that gives you Void
22:56:24 <jle`> so you can use absurd :: Void -> a, to get whatever else you need
22:56:29 <koz_> Ah.
22:56:40 <jle`> absurd (notLine Refl)
22:56:56 <koz_> OK, GHC is happy.
22:57:12 <koz_> So I guess I have to give proof evidence at the call site?
22:57:44 <koz_> I guess I can wrap it with SingI, summon the singleton and then construct the evidence?
22:57:49 <jle`> yeah, which should be just (\case {}) (literally), actually, for monomorphic values
22:58:19 <jle`> you can't always construct the eviedence (s could be Line ), but you could "decide" it
22:58:39 <koz_> Is there a way I can _force_ it to be impossible to pass Line-shaped things?
22:58:45 <jle`> it's either true or not true
22:58:47 <koz_> That was kinda my goal from the get-go.
22:58:49 <jle`> koz_: that's what that does
22:58:56 <jle`> it already forces it to be impossible to pass the line-shaped things
22:59:02 <koz_> Ah, OK.
22:59:12 <koz_> Since you can't provide evidence of that kind.
22:59:13 <jle`> it just expects also a proof that the s isn't Line-shaped
22:59:25 <koz_> OK, thanks.
22:59:42 <koz_> I absolutely adore this stuff. It tickles my logical side.
22:59:45 <jle`> if you make that NotLine GADT, then you could write a decision function
22:59:52 <jle`> decideNotLine:: Sing s -> Decision (NotLine s)
23:00:05 <jle`> that's for the situation when you get an 's' at *runtime*
23:00:14 <koz_> Which I will have.
23:00:19 <koz_> So I guess NotLine GADT it is.
23:00:53 <jle`> you can write a decision function for the other one too but it's tricky to express as Decision because of lack of impredicative polymorphism
23:00:57 <jle`> you'd need a newtype wrapper
23:01:15 <jle`> newtype NotLine s = NotLine (forall n. (s :~: 'Line n) -> Void)
23:01:38 <jle`> then you can write the same decideNotLine :: Sing s -> Decision (NotLine s)
23:02:04 <koz_> Ah, I see - NotLine is just a wrapper around the evidence.
23:02:15 <koz_> And decideNotLine builds some evidence.
23:02:32 <jle`> yeah.  actually you could actually phrase that as decideLine
23:02:48 <jle`> newtype IsLine s = forall n. IsLine (Sing ('Line n))
23:02:59 <jle`> and then decideLine :: Sing s -> Decision (IsLine s)
23:03:14 <koz_> Ah, I see.
23:03:17 <jle`> and you could have your function take a (Refuted (IsLine s)), or (IsLine s -> Void)
23:03:26 <jle`> (that actually should be a data, not newtype)
23:03:29 <koz_> (Refuted (IsLine s)) is a bit nicer.
23:03:34 <koz_> (even if it's the same)
23:03:41 <jle`> yeah, it's the same
23:04:19 <jle`> if you write IsLine as a predicate for decidable, then you can have `IsLine`, and `Not IsLine` as predicates, heh
23:04:36 <koz_> Not IsLine, lol.
23:04:43 <koz_> Maybe a better phrasing would be 'ALine'.
23:04:46 <koz_> And 'Not ALine'.
23:05:02 <koz_> (Or 'Liney' I guess)
23:05:08 <jle`> i wish there was a nice way to define IsLine/ALine though using anonymous combinators, instead of having to write to from scratch
23:05:10 <koz_> ('Linear'?)
23:06:19 <koz_> Apparently newtypes aren't allowed foralls.
23:06:29 <jle`> i could add such a predicate constructor to 'decidable' maybe.  but i am trying to think if there is already a way to make it
23:06:39 <jle`> (yeah, you need data instead of newtype.  and it's the existential type that is preventing newtype)
23:09:20 <koz_> OK, I might need help writing decideLinear'. Let me paste.
23:11:18 <koz_> jle`: https://gist.github.com/kozross/eb0dfc657cd805f879a026aa69a8ed23#file-sized-hs-L47
23:11:24 <koz_> I don't get what the kind error's about.
23:13:19 <jle`> oh sorry, i defined linear badly. the way i wrote it, s is phantom
23:13:31 <jle`> it should be data IsLine s = forall n. IsLine (s :~: 'Line n)
23:13:37 <koz_> Ah, I see.
23:13:50 <jle`> or well, not phantom, but completely ignored :)
23:14:17 <koz_> So that inner 'forall n' really says 'exists n'.
23:14:31 <koz_> As in, IsLine s is evidence that, for _some_ n, s is a Line whose length is n?
23:14:47 <jle`> yeah, it's an exists n on the inside. the syntax was always really confusing for me
23:14:54 <koz_> Skolemization amirite?
23:16:17 <jle`> there's something there that makes it theoretically 'nice', but it's still confusing i think heh
23:16:45 <koz_> Yeah, agreed.
23:16:52 <koz_> An 'exists' keyword would be much easier.
23:17:54 <jle`> that's why a lot of people prefer gadt syntax, data IsLine :: Shape a -> Type where IsLine :: (s :~: 'Line n) -> IsLine s
23:20:12 <koz_> The other entries should be something like 'SRectangle {} -> Disproved (\case {})' right?
23:20:55 <jle`> yeah
23:21:08 <jle`> or Disproved $ \case IsLine r -> case r of {}
23:21:13 <koz_> GHC complains of non-exhaustive patterns.
23:21:44 <jle`> the real thing that is 'forbidden' is the Refl, so you need to empty-case-match on the Refl
23:21:48 <jle`> it's a little syntactically noisy
23:22:15 <jle`> ok, i found a way to express IsLine in terms of anonymous 'decidable' combinators out-of-the-box, but it isn't pretty
23:22:27 <koz_> Lol, what's it look like?
23:23:06 <jle`> Found (FlipPP (PPMap (TyCon1 'Just) (TyPP (:~:))))
23:23:12 <koz_> Wat.
23:23:18 <jle`> gotta figure out a way to make this nicer, heh, because it sounds useful
23:23:50 <jle`> well, the point of 'decidable' is that if you state that as your predicate, your decision function will be automatically generated for you
23:24:18 <jle`> so if you have type IsLine = Found (FlipPP (PPMap (TyCon1 'Just) (TyPP (:~:))))
23:24:32 <jle`> then you have a function decide :: Sing s -> Decision (IsLine @@ s), without having to write it yourself
23:24:42 <koz_> Ah, I see.
23:25:27 <jle`> but right now that decision function isn't automatically generatable unfortunately. gotta look into this, it seems like a common enough use case
23:25:45 <koz_> Yeah, agreed.
23:26:15 <jle`> i'm supposed to be packing for a trip right now but i want to try this out v.v
23:26:28 <koz_> Best ideas happen at worst times. :P
23:26:34 <koz_> Where you going?
23:29:09 <jle`> on a cruise with family :)
23:29:14 <koz_> Ah, OK.
23:29:24 <koz_> I'm actually going to Vietnam with my family in February.
23:29:29 <koz_> Well, one member of my family anyway.
23:33:18 <jle`> oh nice :) VN is a great place to visit!
23:33:28 <koz_> I'm _really_ looking forward to it.
23:36:58 <jle`> you're going to have a blast! feel free to ask if you want any suggestions about where to go :)
23:37:18 <koz_> I'll definitely ask, closer to the time.
23:43:44 <koz_> % :t fromMaybe
23:43:44 <yahb> koz_: a -> Maybe a -> a
