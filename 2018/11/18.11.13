00:30:14 <dminuoso> cocreature: Do you know of a document that describes how async and async exceptions interact?
00:31:00 <dminuoso> Or anyone for that matter :)
00:31:45 <Ariakenom> I don't, more than the docs. But I could answer a question :)
00:34:22 <Ariakenom> Are you wondering how the library uses exceptions?
00:34:52 <Ariakenom> Or more how it handles them from other sources.
00:42:06 <dminuoso> Ariakenom: Let me try out some scenarios.
00:45:15 <MarcelineVQ> dminuoso: there's a book on it  :> https://www.oreilly.com/library/view/parallel-and-concurrent/9781449335939/ch09.html#sec_async-exceptions
00:45:35 <dminuoso> MarcelineVQ: Shoot I even have that! 
00:45:46 <MarcelineVQ> probably don't want to jump into the middle there though, it takes you through implementing async piece by piece
00:45:48 <dminuoso> I kind of stopped in the middle of it because I got busy.
00:46:21 <dminuoso> Ariakenom: Right now the main thing Im wondering about, is where async exceptions like `Ctrl-C` get propagated to?
00:46:34 <dminuoso> Is there a chance they get thrown to some `Async Void` thread Im running?
00:49:02 <Ariakenom> should be the main thread
00:49:16 <MasseR> Too bad ghc can't really handle parallel builds :<. I have a 'beefy' buildmachine which I'd like to take proper advantage of. 
00:49:57 <Ariakenom> dminuoso: relatedly, the main thread dying will kill the program
00:51:35 <Athas> MasseR: ironic that a compiler for a functional language is so bad at parallelism!
00:51:57 <Athas> Although I do recall doing parallel builds with GHC with some limited success.
00:52:23 <MasseR> Athas: something like max 5 parallel jobs and after that it starts getting slower and slower
00:52:42 <maerwald> But memory spikes better
00:52:50 <maerwald> So if you want to test your oom killer...
00:53:01 <MasseR> I have lots of memory to spare. ~250G
00:53:07 <maerwald> ram?
00:53:09 <MasseR> ram
00:53:21 <maerwald> That could be enough for haskell development xD
00:53:24 <Athas> MasseR: I wonder if that's because of the GC.  All those jobs will use the same heap.  I recall that the GC became a big problem last time I tried to do parallel Haskell.
00:53:32 <tdammers> Athas: it's more like, "completely expected that a 20-year-old codebase is do bad at parallelism"
00:53:44 <maerwald> Why?
00:53:51 <maerwald> Parallellism is older than 20 years
00:53:54 <tdammers> yes
00:54:13 <maerwald> It just wasn't a priority, imo
00:54:16 <tdammers> but mass-produced commodity hardware on which parallel builds are worth it is not
00:54:31 <MasseR> maerwald: some of our machines (not for building :<) have terabytes of ram :)
00:54:59 <tdammers> 20 years ago, unless you were building stuff for heavily funded research projects or a customer with truckloads of money, you would not normally go crazy on parallelizing things
00:55:15 <dminuoso> Ariakenom: Okay, if that is the case then wrapping any SomeException being thrown in my async workers group inside some `newtype WorkerError = WorkerError SomeException` seems like a safe thing to do.
00:55:15 <Athas> tdammers: is there something in the design of GHC that inhibits parallelism?
00:55:33 <Athas> I'd expect that modules (that do not depend on each other) could be compiled in parallel easily enough.
00:55:57 <dminuoso> Athas: What about things like open world assumption of typeclasses?
00:56:30 <Athas> dminuoso: that's not a problem.  Those are checked when modules are imported.
00:56:31 <tdammers> Athas: I don't know, really; in theory, this should be trivial, but I'm sure there are architectural choices in GHC that would make it somewhat inconvenient
00:56:45 <tdammers> I don't think there are fundamental show stoppers though
00:57:16 * hackage slave-thread 1.0.2.7 - A fundamental solution to ghost threads and silent exceptions  http://hackage.haskell.org/package/slave-thread-1.0.2.7 (NikitaVolkov)
00:57:20 <Athas> I vaguely recall GHC having some magical/unsafePerformIO-ish string interning.  But those could just be furnished with a lock.
00:57:41 <Athas> Also, GHC *is* able to correctly compile in parallel.  It's just nowhere near as profitable as passing -j32 to 'make' when compiling C.
00:59:27 <Ariakenom> dminuoso: Seems strange but might make sense. When do you convert it?
00:59:42 <MasseR> https://ghc.haskell.org/trac/ghc/ticket/9221
00:59:42 <maerwald> Does GHC do "lto"? I mean, C doesn't do much "cross-module" optimization, which is why you can just throw 32 cores at it
00:59:53 <MasseR> "linear slowdown of parallel builds"
01:07:09 <maerwald> Just had to reboot, because GHC killed my laptop
01:07:25 <maerwald> Or cabal, because default jobs are nproc 
01:12:50 <maerwald> and in that process, it destroyed my new-build cache
01:19:06 <mniip> interesting https://hackage.haskell.org/package/Chart-gtk-1.1/docs/
01:19:13 <mniip> the package doesn't have any of those modules...
01:23:54 <MarcelineVQ> likely a good thing to mention in #hackage  pretty mysterious
01:25:12 <MarcelineVQ> oh it's an old version ehe
01:25:41 <MarcelineVQ> 'Docs uploaded by user' maybe some sillyness due to this
01:27:11 <Athas> maerwald: yes, GHC does the moral equivalent of "LTO".
01:27:19 <Athas> It is quite crucial to many of its optimisations.
01:27:41 <Athas> The difference is that GHC doesn't do it just at linking-time, but (potentially) whenever a module is imported.
01:31:09 <maerwald> Athas: then it's also hard to complain about parallelism
01:31:25 <maerwald> While in C it's just dumb independent object compilation
01:31:47 <maerwald> which isn't even done by the compiler ;)
03:06:46 * hackage llvm-hs-pretty 0.6.0.0 - A pretty printer for LLVM IR.  http://hackage.haskell.org/package/llvm-hs-pretty-0.6.0.0 (sdiehl)
03:29:47 * hackage lsp-test 0.5.0.0 - Functional test framework for LSP servers.  http://hackage.haskell.org/package/lsp-test-0.5.0.0 (luke_)
03:52:39 <ski> @tell crestfallen "ok normal order is just what haskell calls lazy evaluation." -- no, not quite. first (considering lambda-calculus) "normal order" (and "applicative order") reduces under lambda (formal parameter binder), while "call-by-value" (as well as "call-by-name") doesn't
03:52:39 <lambdabot> Consider it noted.
03:53:16 <ski> @tell crestfallen then "by-name" may evaluate an argument expression (actual parameter) many times, while "call-by-need" (aka lazy evaluation) evaluates it at most once (by caching or graph rewriting or similar)
03:53:16 <lambdabot> Consider it noted.
04:04:20 * quicksilver is concerned that ski (may have (caught LISP))
04:06:19 * hackage funflow 1.4.0 - Workflows with arrows  http://hackage.haskell.org/package/funflow-1.4.0 (nclarke)
04:07:27 <nelsonhb> (silicone, saline, string) implants
04:11:47 <ski> quicksilver : a long time ago. i get flashbacks
04:14:04 <cocreature> you can only treat the effects of LISP but you can’t cure it
04:14:40 <nelsonhb> hello! everybody. (silicone, saline, string) implants!
04:15:08 <ski> hello nelsonhb ?
04:15:46 <nelsonhb> hello! everybody. (silicone, saline, string) implants!
04:24:50 <Solonarv> I'm very confused
04:25:24 <cocreature> Solonarv: are you not in need of a string implant?
04:25:42 <Solonarv> well I sure hope I'm not!
04:25:45 <lavalike> IsString implants
04:26:19 <cocreature> is there also a Text implant? we all know String is bad for you
04:27:46 * hackage tyfam-witnesses 0.1.1.2 - Provide proof witnesses for closed type family evaluation  http://hackage.haskell.org/package/tyfam-witnesses-0.1.1.2 (GaborGreif)
04:54:19 * hackage hw-simd 0.1.1.3 - SIMD library  http://hackage.haskell.org/package/hw-simd-0.1.1.3 (haskellworks)
05:07:23 <__monty__> cocreature: Yes, the old crumpled up bible pages. Those are unisex even.
05:31:46 * hackage extensible-effects-concurrent 0.12.0 - Message passing concurrency as extensible-effect  http://hackage.haskell.org/package/extensible-effects-concurrent-0.12.0 (SvenHeyll)
05:52:48 <WilliamHamilton[> is the #reflex-frp irc channel no more on freenode?
05:53:18 <WilliamHamilton[> I don't seem able to connect (matrix says that's an empty room)
05:53:55 <ski> it's there
05:54:00 <Solonarv> I checked too
05:55:04 <WilliamHamilton[> thanks, something must be wrong with my setup!
05:57:11 <MarcelineVQ> is it set to registered only? +r
05:57:20 * hackage termonad 1.0.0.0 - Terminal emulator configurable in Haskell  http://hackage.haskell.org/package/termonad-1.0.0.0 (cdepillabout)
06:02:21 * hackage extensible-effects-concurrent 0.12.1 - Message passing concurrency as extensible-effect  http://hackage.haskell.org/package/extensible-effects-concurrent-0.12.1 (SvenHeyll)
06:07:54 <WilliamHamilton[> MarcelineVQ: I'm registered, something must be wrong with my matrix setup
06:25:41 <fozworth> Today is the LAST DAY to fill out the 2018 state of #Haskell survey! Join the nearly 4,500 other respondents and fill it out today! https://airtable.com/shr8G4RBPD9T6tnDf
06:26:28 <Athas> Wooo, surveys
06:27:11 <cocreature> 4500 is a lot more than I expected
06:28:58 <fozworth> it's more than three times as many as last year 
06:29:04 * ski . o O ( "Republic of Haskell" <http://www.lisperati.com/landoflisp/panel57.html>,<http://www.lisperati.com/landoflisp/panel60.html>,<http://www.lisperati.com/landoflisp/panel63.html> )
06:30:09 <MarcelineVQ> wait, there's levels above beginner and intermediate? :>
06:32:44 <ski> (hm, the full contents i see at that page is "Alert\n\nLorem Ipsum\nOkay\n@\n\n  •\n    {userName}\n\n", with a text box after that)
06:44:47 * hackage vector-sized 1.1.1.0 - Size tagged vectors  http://hackage.haskell.org/package/vector-sized-1.1.1.0 (jophish)
06:49:23 * hackage llvm-hs-pretty 0.6.1.0 - A pretty printer for LLVM IR.  http://hackage.haskell.org/package/llvm-hs-pretty-0.6.1.0 (sdiehl)
06:50:19 * hackage http-api-data 0.4 - Converting to/from HTTP API data like URL pieces, headers and query parameters.  http://hackage.haskell.org/package/http-api-data-0.4 (phadej)
06:53:35 <c_wraith> MarcelineVQ, yes, I think "Simon" is the next level up.
06:54:29 <tauoverpi[m]> Which simon?
06:55:00 <c_wraith> all of them. it's a title awarded to those who go past "intermediate"
06:55:03 <jebes> our saviour who art in glasgow?
06:57:57 <ski> @quote long.and.hard
06:57:57 <lambdabot> pikhq says: <kmc> you use simonSaysPerformIO to make it so <pikhq> Yes, but you should think long and hard before using it if you're not named Simon.
06:58:37 <Ariakenom> If my name is Simon will I be granted extraordinary powers or do I just have to change my name?
07:03:08 <mniip> MarcelineVQ, http://i.imgur.com/2Scjd4W.jpg
07:03:37 <mniip> no wait that's the wrong oen
07:03:39 <mniip> MarcelineVQ, https://i.imgur.com/c111qqp.jpg
07:03:40 <MarcelineVQ> now how did you know what I'm writing in this survey..
07:04:03 <MarcelineVQ> er, and, I just read mpickering et al profunctor optics paper
07:04:05 <MarcelineVQ> you're fire mniip
07:06:46 * hackage extensible-effects-concurrent 0.13.0 - Message passing concurrency as extensible-effect  http://hackage.haskell.org/package/extensible-effects-concurrent-0.13.0 (SvenHeyll)
07:16:14 <dminuoso> Ariakenom: https://gist.github.com/dminuoso/fea9ff60469689480bf284c1bf1feac9
07:16:37 <Solonarv> I like how the first one has 'Author: Edward A. Kmett'
07:16:40 <dminuoso> Ariakenom: The idea being that someone who uses the library gets notified that a worker has errored out. It's a primitive to build a resource-pool abstraction around (so that I can catch a WorkerError and terminate the connection)
07:24:38 <mniip> Solonarv, yes, it's a ncie touch
07:27:54 <Ariakenom> dminuoso: hm, async exceptions other than Ctrl-C may be thrown in non-main thread. async uses it to cancel threads.
07:29:54 <dminuoso> Ariakenom: What kind of async exceptions would that be?
07:30:08 <dminuoso> A raw throwTo is not possible because I never expose the thread ID.
07:32:35 <tsahyt> @hoogle Pipe a b m () -> Proxy a' a b b' m ()
07:32:36 <lambdabot> Data.Conduit.Internal generalizeUpstream :: Monad m => Pipe l i o () m r -> Pipe l i o u m r
07:32:36 <lambdabot> Data.Conduit.Internal yieldOr :: Monad m => o -> m () -> Pipe l i o u m ()
07:32:36 <lambdabot> Pipes.Prelude generalize :: Monad m => Pipe a b m r -> x -> Proxy x a x b m r
07:32:44 <tsahyt> oh so it does exist
07:32:50 <Ariakenom> (Not saying there's any problem, just read through what I said and wanted to clarify)
07:33:22 <Ariakenom> dminuoso: Async.AsyncCancelled was the one I was talking about
07:34:31 <dminuoso> Ariakenom: Oh that's fine. That shouldn't be possible to receive, I never expose the Async that far outside.
07:34:33 <dminuoso> But even if, that's precisely where it should fall out.
07:34:53 <dminuoso> anything that signals that the workers group is dying should be re-thrown into WorkerError
07:36:25 <fr33domlover> GHC 8.2.2 is asking me to enable DeriveFunctor othewise it can't derive a Functor instance - is this something new? Why can't it derive without the extension? In which cases should I use it, and in which should I manually write the instance? (In my case, a trivial instance, writing a library)
07:37:20 <cocreature> fr33domlover: that was always the case
07:37:34 <cocreature> fr33domlover: there usually isn’t any reason to write the instance yourself if DeriveFunctor works
07:40:39 <Ariakenom> Is there a list of asynchronous exceptions anywhere?
07:43:16 <fr33domlover> cocreature, thanks
07:43:28 <Ariakenom> dminuoso: BlockedIndefinitelyOnMVar
07:44:20 <dminuoso> Ariakenom: Yeah that's fine too.
07:44:28 <dminuoso> Ariakenom: If my workers group is hung somehow, it needs to die.
07:46:15 <Boarders> does anyone know if there is a way to do a foldMap into a commutative monoid in parallel?
07:46:39 <Boarders> or rather if there is a combinator somewhere to do it?
07:47:32 <Ariakenom> dminuoso: so the wrapper is an escalation in the sense that no one gets to recover from it?
07:49:13 <quicksilver> it doesn't need to be commutative to be parallelisable
07:49:21 <quicksilver> just associative is enough (which all monoids are supposed to be)
07:50:09 <Boarders> ah yeah, fair enough
07:50:30 <Ariakenom> a<>(b<>(c<>d)) = (a<>b)<>(c<>d)
07:51:15 <Boarders> do you know of a good approach? In Simon Marlow's book he warns against writing explicit methods to divide and conquer
07:51:35 <Boarders> since that presumes all elements take roughly equal time to compute
07:51:57 <quicksilver> I don't know a good answer :(
07:52:51 <quicksilver> edwardk wrote some blog posts on parallelizing IIRC
07:55:34 <dminuoso> Ariakenom: Right.
07:55:35 <dminuoso> Ariakenom: It's just a way to communicate that the caller has to do cleanup
07:56:47 <lyxia> Boarders: it seems fairly easy to do with the parallel library
07:57:36 <Welkin> If I have a Map that I am storing in an MVar, and I have many threads that may want to read or write to it, but I don't want the threads to be blocked from reading at any time (because the the updated data will be published to a Chan), what should I do?
07:57:55 <Welkin> if I stored the data in an external datastore instead I would not have this problem
07:58:09 <Welkin> like a database, reads should never be blocked
07:58:24 <Welkin> and writing different parts of the data structure shouldn't block either
07:58:29 <Welkin> different keys*
07:58:50 <Ariakenom> Welkin: Sounds like stm then
07:59:06 <Welkin> I am reading about STM now, but it seems like STM doesn't solve this problem
07:59:13 <Welkin> unless I didn't read far enough
08:00:20 <Ariakenom> read-while-write should be fixed by just changing the XVar. there will be some retries instead of blocking tho
08:01:24 <Ariakenom> well it just reads the one TVar, that probably won't conflict a lot
08:01:48 <Ariakenom> for multiple writers you'd need something other than TVar (Map K V) though, yes
08:02:45 <Ariakenom> Welkin: maybe this is relevant https://hackage.haskell.org/package/stm-containers
08:03:51 <Welkin> concurrent read is more important than write
08:03:53 <Welkin> thanks, taking al ook
08:08:40 <dminuoso> Ariakenom: the thing is "recovery" depends on how you look at it.
08:09:04 <dminuoso> I want it recoverable in the sense that I can catch it, but there is no way to actually recover the thread that produced that exception.
08:09:09 --- mode: ChanServ set +o glguy
08:09:10 --- mode: glguy set +q $~a
08:11:46 * hackage servant 0.15 - A family of combinators for defining webservices APIs  http://hackage.haskell.org/package/servant-0.15 (phadej)
08:24:38 <fryguybob> Welkin: A transction in STM that only reads a single TVar can be done with readTVarIO.  This will only block (by spinning) while another thread is updating the TVar which should always happen quickly.
08:25:16 * fryguybob goes to lunch, but I will be back later.
08:29:21 <shapr> I heard fryguybob writes research papers about STM
08:30:11 <MarcelineVQ> I heard he's a fan of starch
08:30:16 * hackage servant-client-core 0.15 - Core functionality and class for client function generation for servant APIs  http://hackage.haskell.org/package/servant-client-core-0.15 (phadej)
08:31:16 * hackage servant-foreign 0.15, servant-docs 0.11.3 (phadej): https://qbin.io/they-wells-odte
08:32:16 * hackage servant-server 0.15 - A family of combinators for defining webservices APIs and serving them  http://hackage.haskell.org/package/servant-server-0.15 (phadej)
08:33:35 --- mode: glguy set +v ababaie
08:33:37 <ski>   readTVarIO = atomically . readTVar  -- ?
08:33:54 <phadej> semantically yes
08:36:22 * hackage servant-client 0.15 - Automatic derivation of querying functions for servant  http://hackage.haskell.org/package/servant-client-0.15 (phadej)
08:37:46 * hackage servant-pipes 0.15 - Servant Stream support for pipes  http://hackage.haskell.org/package/servant-pipes-0.15 (phadej)
08:38:52 * hackage servant-machines 0.15, servant-conduit 0.15 (phadej): https://qbin.io/lucia-christ-4wsn
08:51:26 <Ariakenom> Welkin: did you reach a conclusion?
08:51:48 <Welkin> I'm still reading
08:52:02 <Welkin> got distracted for a moment by http load testing tools too
08:58:57 --- mode: glguy set +v justaguy
08:59:15 <justaguy> Anyone here familiar with the db interface selda?
08:59:38 --- mode: glguy set +v Juanandres
09:05:54 <cocreature> justaguy: just ask your actual question instead
09:07:56 * hackage stratosphere 0.27.0 - EDSL for AWS CloudFormation  http://hackage.haskell.org/package/stratosphere-0.27.0 (jdreaver)
09:14:22 <justaguy> In a selda query I'm writing adding this restriction "restrict $ (note ! #process_version .== null_) .|| (note ! #process_version ./= null_)" is removing all rows from the response. Even though it seems like this should do nothing. Am I missing something about how selda handles null fields?
09:15:15 <phadej> I don't know selda, but have you tried to look on the generated SQL
09:16:38 <Welkin> Just use sql instead of trying to write sql through an intermediate hacked-together dsl. SQL is already a great language.
09:16:57 <Welkin> take your pick of postgresql-simple, sqlite-simple, mysql-simple, etc.
09:17:21 <cocreature> my guess would be that this generates "… = NULL" which will return false
09:18:16 <justaguy> I see, does (NULL = NULL) return false in sql or something?
09:18:19 <cocreature> yep
09:18:36 <justaguy> okay awesome, that's definitely it 
09:18:48 <justaguy> thanks!
09:19:06 <cocreature> hm or does it return NULL?
09:19:10 <cocreature> it definitely doesn’t return true :)
09:19:12 <byorgey> it's NULL
09:19:40 <byorgey> except apparently ORDER BY treats NULLs as equal
09:21:28 <Ariakenom> Every message after "SQL is already a great language." made me doubt that. Also sum of no rows is NULL -.-
09:25:15 <dminuoso> Stratosphere.ResourceProperties.ApplicationAutoScalingScalingPolicyTargetTrackingScalingPolicyConfiguration
09:25:18 <dminuoso> What the heck is this.
09:25:51 <dminuoso> http://hackage.haskell.org/package/stratosphere-0.27.0 :<
09:28:23 <Welkin> let me rephrase then: postgres is great, not sure about the others
09:31:46 * hackage pandoc-citeproc 0.15 - Supports using pandoc with citeproc  http://hackage.haskell.org/package/pandoc-citeproc-0.15 (JohnMacFarlane)
09:31:47 <Ariakenom> Welkin: :)
09:36:17 * hackage servant-pagination 2.1.2 - Type-safe pagination for Servant APIs  http://hackage.haskell.org/package/servant-pagination-2.1.2 (KtorZ)
09:44:12 --- mode: glguy set +v fen
09:44:28 <fen> why are the versions using build slower? https://bpaste.net/show/8cd338683e6a
09:50:16 <MarcelineVQ> Neat link fen thanks. You probably want to be inlining things you want to fuse, look at base's list functions for examples of how you might want to do that
09:52:44 <MarcelineVQ> There's some rather complex looking, to me, interactions in the various inlining phases and rules phases but I think they're explained in the source if one looks around
09:53:17 <fen> sure
10:02:16 * hackage criterion 1.5.3.0 - Robust, reliable performance measurement and analysis  http://hackage.haskell.org/package/criterion-1.5.3.0 (ryanglscott)
10:03:37 <kuribas> if you write "myfun x = someComputation x expensive_constant" it will never float out expensive constant, right?
10:04:40 <cocreature> kuribas: if you compile with -ffull-laziness (which is part of -O2) GHC is quite aggressive when it comes to floating out things
10:04:46 <cocreature> so pretty sure that this will be floated out
10:05:28 <fen> MarcelineVQ: there is this; https://hackage.haskell.org/package/base-4.8.0.0/docs/src/Data-OldList.html
10:05:57 <fen> that mentions INLINE and NOINLINE with square parenthesis which must do something...
10:05:58 * hackage toodles 0.1.4 - Manage the TODO entries in your code  http://hackage.haskell.org/package/toodles-0.1.4 (aviaviavi)
10:07:36 <fen> there is this also; https://downloads.haskell.org/~ghc/7.0.3/docs/html/users_guide/pragmas.html
10:08:03 <fen> it mentions SPECIALISE for recursive functions...
10:08:51 <fen> (section 7.13.9.)
10:10:44 <fen> "Unlike INLINE, it is OK to use an INLINABLE pragma on a recursive function. The principal reason do to so to allow later use of SPECIALISE"
10:11:06 <pacak1> Is there a difference from ghc runtime point of view whenever you have a buffer of size 1023 bytes or 1024 bytes?
10:12:09 <pacak1> I have some code that segfaults or dies with internal error when I use 1024+ bytes, but works fine for 1023.
10:12:11 <fen> "For example, for a self-recursive function, the loop breaker can only be the function itself, so an INLINE pragma is always ignored."
10:12:53 <fen> and then links this; https://www.microsoft.com/en-us/research/wp-content/uploads/2002/07/inline.pdf
10:13:19 <fen> this is like a rabbit hole
10:14:06 <mpickering> fen: http://mpickering.github.io/posts/2017-03-20-inlining-and-specialisation.html
10:14:29 * hackage ngram 0.1.0.1 - Ngram models for compressing and classifying text.  http://hackage.haskell.org/package/ngram-0.1.0.1 (TomLippincott)
10:16:07 <fen> would anyone be able to discuss whats happening with this example? https://bpaste.net/show/8cd338683e6a
10:16:19 <fen> thanks mpickering!
10:17:13 <mpickering> fen: What in particular?
10:17:51 <fen> which of INLINE, INLINABLE and SPECIALISE to use to make the build and foldr fuse
10:19:04 <fen> also, the goal is to add a rule that rewirites the "uncons" version (which is slower) to the equivalent "get" version (which is faster)
10:19:34 <mpickering> so you expect all four versions to be the same speed?
10:21:15 <mpickering> have you looked at the core already?
10:21:15 <fen> after that second step yes, but currently, its just surprising that the performance of; test1 /= test3 and test2 /= test4. where in both cases, translating into an implementation using build is resultingly slower 
10:21:40 <mpickering> there's too much code there to understand quicklyu
10:24:43 <fen> mpickering: this is a shorter example using the same idea; https://bpaste.net/show/31a15bbd9110
10:25:58 <fen> hyloList2  :: ListLike f => (f a -> (b, f a)) -> f a -> (b -> c -> c) -> c -> c
10:28:05 <fen> would -ddump-simpl be the flag to generate the core?
10:29:45 <cocreature> yes
10:30:58 <kuribas> cocreature: couln't that potentially create a space leak?
10:34:52 <fen> here is the core, but it does not seem to be helpful https://bpaste.net/show/61b79abce61d
10:35:00 <cocreature> kuribas: yes which is why some people really dislike -ffull-laziness
10:35:44 <cocreature> kuribas: https://www.reddit.com/r/haskell/comments/55xk4z/erratum_to_sharing_memory_leaks_and_conduit_and/ and the preceding post points at some of the problems
10:37:06 <fen> so basically there are 3 questions. 1. what pargma is used to ensure build fold fuses in these pastes, and also, how to convert between the two versions (that using Maybe, and that using Pattern matching using the ListLike class)
10:38:45 <mpickering> fen: Do you know what the static argument transformation is?
10:38:55 <fen> wah!?
10:39:01 <fen> no...
10:40:04 <fen> there is this; https://ghc.haskell.org/trac/ghc/wiki/StaticArgumentTransformation
10:45:33 <fen> and this is more helpful; https://ghc.haskell.org/trac/ghc/ticket/888
10:51:56 * hackage fswatcher 0.2.2 - Watch a file/directory and run a command when it's modified  http://hackage.haskell.org/package/fswatcher-0.2.2 (ErlendHamberg)
10:52:49 --- mode: glguy set +v govno
10:54:53 <buttons840> is there a way I can get the total memory usage for a haskell process from within haskell?
10:56:51 <boj> buttons840: maybe look into the ekg package
10:57:51 <fryguybob> buttons840: There is also GHC.Stats http://hackage.haskell.org/package/base-4.12.0.0/docs/GHC-Stats.html
11:00:56 <buttons840> fryguybob: looks like the hot ticket, ty
11:03:13 <buttons840> I'm binding to a graphics library and want to set up some memory leak tests, I'll run a loop and watch the amount of memory used for constant growth during the loop -- unless someone has a better suggestion?
11:04:05 <buttons840> "currentBytesUsed" in GHC.Stats looks like what i need
11:09:19 <eric8> Does anyone know if `fswatcher` (mentioned above) detects directory changes if the files in the directory are overwritten with exact copies?
11:09:45 <cocreature> buttons840: valgrind?
11:10:06 <cocreature> buttons840: GHC.Stats will probably only give you memory allocated via GHC, not memory allocated in your graphics lib
11:10:54 <mniip> using valgrind with the GHC RTS sounds... optimistic to say the least
11:11:41 <cocreature> mniip: it worked quite well for me to detect leaks in ffi bindings
11:16:18 <buttons840> cocreature: i'll check it out, i've used it before but will have to brush up on it
11:20:09 <geekosaur> eric8, it dosn't care abotu the file contents, it watches system calls affecting files in any way
11:21:18 <geekosaur> it monitors at the filesystem level, not the file level
11:23:47 <cocreature> buttons840: fairly simple usage gets you quite far actually, just prefix your command with "valgrind"
11:25:47 * hackage fmt 0.6.1.1 - A new formatting library  http://hackage.haskell.org/package/fmt-0.6.1.1 (Artyom)
11:25:52 --- mode: glguy set +v zachk
11:26:08 <zachk> cocreature, do you have to compile something extra to use valgrind?
11:26:21 --- mode: asimov.freenode.net set +v zachk
11:26:21 --- mode: glguy set -v zachk
11:26:37 <kuribas> cocreature: I was thinking if you could float up SQL strings, it would make selda more performant.
11:27:06 <kuribas> cocreature: you could have a more expensive optimization step, which only needs to be ran once for each query function.
11:27:08 <geekosaur> zachk, ot aside from possibly valgrind itself (but really it should already be packaged)
11:27:23 <geekosaur> its sort of an insrumented VM
11:27:47 <cocreature> zachk: you don’t have to but for the ffi usecase you might want to compile the C code with debug info and maybe also the Haskell code although I don’t recall if valgrind works properly with the latter
11:29:22 <kuribas> I haven't tested selda's performance, but I think generating the query string each time is pretty slow.
11:29:38 <kuribas> If you have many queries returning little data.
11:29:54 <kuribas> (for rew queries returning a lot of data it doesn't matter).
11:33:51 <p0lyph3m> does someone have experience with the Sound.JACK binding ? I have a strange timing issue , and after two days of hacking around i have no more ideas to resolve it.
11:39:02 <hyperisco> p0lyph3m, godspeed
11:43:11 <[exa]> p0lyph3m: please describe the issue closer
11:43:20 * hackage code-page 0.2 - Windows code page library for Haskell  http://hackage.haskell.org/package/code-page-0.2 (ryanglscott)
11:44:22 --- mode: glguy set +v bbooii
11:46:18 <bbooii> according to haskell wiki i can.
11:47:04 <bbooii> So, i started learning haskkell, and i'm completly stuck on polymorphic type variables,
11:47:10 <cocreature> bbooii: I think your first message may have gotten lost
11:47:23 <bbooii> eh, it's ok
11:47:25 <zachk> @type sort 
11:47:27 <lambdabot> Ord a => [a] -> [a]
11:47:38 <zachk> bbooii, does that make any sense to you bbooii ?
11:47:44 <zachk> > sort [3,2,1] 
11:47:46 <lambdabot>  [1,2,3]
11:48:13 <zachk> > sort ["red","cabbage","smells","good] 
11:48:15 <lambdabot>  <hint>:1:39: error:
11:48:15 <lambdabot>      lexical error in string/character literal at end of input
11:48:23 <zachk> > sort ["red","cabbage","smells","good"] 
11:48:25 <bbooii> yep
11:48:25 <lambdabot>  ["cabbage","good","red","smells"]
11:48:28 <p0lyph3m> ok, i am doing a drummachine that translates midi messages to "drumsample based audio". 
11:48:51 <zachk> bbooii, so how are you stuck on polymorphic type variables then? 
11:50:00 <p0lyph3m> however , the audio of the drumsample sequence differs if i record two or more times , i wonder if its gc that interfers even if jackd doesnt report XRUNS
11:50:07 <bbooii> to expand on my message: i don't get why i can't have x :: a (newline) x = 1, or f :: a -> a (newline) f x = 1
11:50:23 <bbooii> why do i need to constraint type of a to num?
11:51:14 <cocreature> bbooii: x :: a means that your code has to work for any "a" that the caller might use
11:51:24 <cocreature> so in particular it has to work for a = String
11:51:30 <cocreature> but 1 is not of type String
11:51:56 <kuribas> can you enable some optimization settings on a per-file settings?
11:52:00 <kuribas> with cabal/stack?
11:52:07 <cocreature> kuribas: OPTIONS_GHC pragmas
11:52:21 <kuribas> cocreature: can you make that optional for release builds?
11:52:27 <bbooii> but no way i can put string in there, is it not so?
11:52:46 <cocreature> bbooii: I’m not sure what you mean by “put in” and “here”
11:53:04 <bbooii> f x = 1 will always be 1
11:53:21 <bbooii> no way around it
11:53:29 <kuribas> cocreature: for example increasing inline function size.  But only for production builds to avoid large compile times.
11:53:58 <cocreature> bbooii: right but if you specify the type "f :: a -> a" you are promising to the caller that they can choose whatever type they want for "a" and your function will work
11:54:12 <cocreature> bbooii: so if I’m the caller, I must be able to use your function as f :: String -> String
11:56:29 <cocreature> bbooii: whenever you use a polymorphic type variable, your implementation has to work _for all choices of types_
11:56:40 <zachk> bbooii, how many functions are there that satisfy f :: a -> a ? 
11:56:48 <cocreature> bbooii: so you don’t get to make any assumptions about what the type variable is
11:57:17 <p0lyph3m> hyperisco, [exa] : here is a screenshot https://imagebin.ca/v/4MUzokpAAqTA
11:57:31 --- mode: glguy set +v midi[m]
11:58:38 <cocreature> kuribas: hm, I don’t think you can toggle pragmas via cpp so doing this on a per-file basis is probably going to be tricky
11:58:55 <bbooii> i think i'm starting to get it, but it's a bit counterintuitive.
12:00:02 <p0lyph3m> hyperisco, [exa] : here is a prog : https://thepasteb.in/p/nZhqcZDLJYO3mHq
12:01:20 <bbooii> nah, i think i'm dumb
12:01:45 <bbooii> if we have function f :: a -> b (newline) f x = 1
12:02:06 <rain1> thats not a -> b though
12:02:25 <bbooii> yeah, i don't get why
12:02:34 <rain1> well the result is a number
12:02:42 <cocreature> bbooii: "a -> b" means that your implementation has to work for _all choices of a and b_
12:02:42 <rain1> so it's going to be Number b => a -> b
12:03:23 <bbooii> as i see, it will work for all a
12:03:30 <cocreature> bbooii: right but not for all b
12:03:38 <cocreature> a -> Int would be fine
12:04:04 <bbooii> and b is constnat, no matter what a is
12:05:06 <bbooii> i mean, we can "put any number in a", when function is called.
12:05:10 <cocreature> "a -> b" still allows the caller to make whatever choice for "b" they want
12:05:13 <p0lyph3m> hyperisco, [exa] : in the screenshot track 2 and 3 should be the same, however they differ in Beat 6 of Bar 4 and in Beat 5 of Bar 5.
12:05:18 <cocreature> so they can choose b = String, b = (), …
12:05:43 <bbooii> but definition is f x = 1
12:06:00 <cocreature> right and 1 does not have type String
12:06:12 <cocreature> so your implementation doesn’t have the type you are claiming it has
12:06:15 <cocreature> so GHC yells at you :)
12:07:31 <bbooii> whoa, thank you.
12:08:00 <bbooii> somehow your "implementation doesn’t have the type you are claiming it has " makes sense to me 
12:08:33 --- mode: glguy set +v shiro[cloud]
12:28:46 --- mode: glguy set +v fen
12:28:47 * hackage math-functions 0.3.1.0 - Collection of tools for numeric computations  http://hackage.haskell.org/package/math-functions-0.3.1.0 (AlexeyKhudyakov)
12:38:19 * hackage lsp-test 0.5.0.1 - Functional test framework for LSP servers.  http://hackage.haskell.org/package/lsp-test-0.5.0.1 (luke_)
12:40:16 <fen> adding inline pragmas everywhere does not give better performance for this https://bpaste.net/show/8cd338683e6a
12:40:41 <fen> is there a more precise approach which might give better results?
12:41:38 <fen> here is the briefer version https://bpaste.net/show/31a15bbd9110
12:43:11 <fen> build and foldr @ 63,79 and 103 should cancel right?
12:43:24 <fen> so why is it slower?
12:44:48 <fen> its as if the build fold fusion isnt firing 
12:45:20 <lyxia> maybe you should look at the core
12:45:32 <fen> this? https://bpaste.net/show/61b79abce61d
12:45:38 <fen> what for?
12:45:47 <cocreature> to see if fusion happens
12:46:34 <cocreature> you probably want to throw some -dsuppress-* options at this to get something remotely readable
12:47:08 <fen> what would be the best way to do that?
12:47:47 <cocreature> to do what?
12:47:55 <fen> output readable core
12:48:04 <cocreature> -dsuppress-all is a start
12:48:14 <fen> ghc -O2  -o main -dsuppress-all ?
12:48:42 <cocreature> you still need -ddump-simpl
12:48:50 <cocreature> https://github.com/yav/dump-core is another option
12:51:18 <fen> https://bpaste.net/show/ae81070bcf88
12:51:43 <cieplak> I'm trying to create an alias for a certain combinator without having to copy the entire function signature
12:52:05 <cieplak> This is the alias: `(.&) = (SuperRecord.&)`
12:52:36 <fen> cocreature: its not enough to just use the benchmarks?
12:52:38 <cieplak> But this is the signature: `(.&) :: forall l t lts s sortedLts. ( RecSize lts ~ s , sortedLts ~ Sort (l := t ': lts) , KnownNat s , KnownNat (RecVecIdxPos l sortedLts) , KeyDoesNotExist l lts , RecCopy lts lts sortedLts) => l := t -> Rec lts -> Rec sortedLts`
12:53:19 <cieplak> Is there are way to tell ghc to use the original signature without having to copy-paste?
12:53:26 <cocreature> fen: apparently you are having trouble understanding your benchmark results. so looking at the core to see what optimizations got applied, can help you figure out why something is slower than something else
12:53:44 <fen> the code was written in an attempt to do the conversion automatically to be compared with a direct translation. there isnt much else that distinguishes the code other than if the fusion happens
12:54:09 <fen> which would indicate that the fusion did not happen
12:54:28 <fen> and its not easy to see even from this now <2000 lines of core, if this happened 
12:54:47 <fen> the question is why
12:54:52 <fen> and how to ensure it does happen
12:55:39 <geekosaur> cieplak, just provide parameters so it infers them. otherwise you could turn off the monomorphism restriction, but that's a rather blunt tool
12:57:11 <cieplak> geekosaur: That's great advice, I'm trying the parameters now instead of using the point-free style
12:57:29 <fen> directing users to reams of garbled jibberish is not a useful feature of the haskell development cycle 
12:59:20 <fen> if you are not convinced that the optimisations were not applied, then you can look at the core. otherwise the kind of advice that would be easier to appreciate is how to get the fustion to fire as it seems that it should automatically from all available reference material 
12:59:59 <Welkin> if I have a Chan that is written to before there are any consumers/readers, what happens to the messages written to it before the first dupChan is applied to it? Do they sit forever in memory, or are they garbage collected?
13:00:25 <Welkin> it seems that they would not be garbage collected (which makes sense since there is still a reference to them in the original Chan)
13:00:58 <fen> Welkin: did you ever get an answer to that?
13:00:59 <cieplak> geekosaur: Perfect! just needed to add flexiblecontexts and it completely solved the problem. Thanks so much
13:01:04 <Welkin> I could use a bounded channel, but I have no idea how large it would need to be.
13:01:15 <Welkin> fen: not that I remember
13:01:30 <Welkin> I am almost certain they will sit in the channel forever
13:01:46 <systemfault> Hi wonderful people of the Haskell world, was wondering if there was something like >>= + <*
13:01:58 <systemfault> Basically, I want to apply an effect but return the old value.
13:02:00 <Welkin> one solution I thought of it to create a consumer immediately after I created the channel and before anything can write to it
13:02:03 <rain1> systemfault: what would be the type of the thing you want?
13:02:06 <Welkin> and this consumer will just eat all the messages
13:02:47 <Welkin> systemfault: no
13:02:55 <cocreature> Welkin: yes they will pile up. there is newBroadcastTChan to avoid this and merijn also created a library specifically for this https://hackage.haskell.org/package/broadcast-chan
13:03:05 <Welkin> systemfault: flip (>>) flips te parameters, but has different semantics than <*
13:03:16 <systemfault> m a -> (a -> m b) -> m a ? :(
13:03:35 <Welkin> what?
13:03:40 <Welkin> :t (=<<)
13:03:42 <lambdabot> Monad m => (a -> m b) -> m a -> m b
13:03:50 <mpickering> fen: If you want to understand what the optimiser is doing you have to read the core. There's no getting around this.
13:04:27 <rain1> @hoogle m a -> (a -> m b) -> m a
13:04:28 <lambdabot> Data.GI.Base.ShortPrelude (>>=) :: m a -> (a -> m b) -> m b
13:04:28 <lambdabot> Data.Function.Between.Lazy withIn :: ((a -> b -> r) -> r) -> (a -> b -> r) -> r
13:04:28 <lambdabot> Data.Function.Between.Strict withIn :: ((a -> b -> r) -> r) -> (a -> b -> r) -> r
13:04:32 <fen> how could it possibly help anyone!?
13:04:39 <rain1> it seems that it doesn't exist
13:04:46 <rain1> but maybe you coudl define it
13:04:59 <Welkin> I read your question wrong systemfault 
13:05:11 <systemfault> Welkin: I might have not been clear..
13:05:59 <mpickering> fen: If you post the complete code for the simpler example then I will look at it and try to point you in the right direction 
13:06:10 <fen> if it is indeed legible to some humans, and those able to use that information can find it helpful, can glean anything from the core it has been provided in a paste
13:06:54 <fen> mpickering: what else should the simpler paste include?
13:07:20 <mpickering> language pragmas? a call to `unfoldr1` and `unfoldr2`?
13:07:56 <Welkin> cocreature: I see this in the docs "By using newBroadcastTChan to create the broadcast channel, items can be garbage collected after clients have seen them."
13:07:59 <fen> but thats what the more comlex paste consists of
13:08:17 <Welkin> what is meant by "after the clients have seen them"?
13:08:47 <Welkin> assuming dupTChan has the same semantics as dupChan, the client will never see the messages written before dupTChan has been used
13:09:56 <fen> traverse is implemented by refolding the unfolded things. it needs this extra fold for the build fold fusion to be demonstrated 
13:11:34 <Welkin> :t \ma f -> ma >>= \a -> (f a >> pure a)
13:11:36 <lambdabot> Monad m => m b -> (b -> m a) -> m b
13:11:42 <Welkin> systemfault: ^
13:11:57 <systemfault> ***mindblown***
13:12:13 <fen> thats the stage thats currently the barrier, the simpler paste was for the next stage, of how to make a rule to rewrite from one version to the other
13:12:39 <fen> but if the build fold fusion isnt working, thats not the current task
13:13:42 <mpickering> I am compiling the bigger program now
13:13:56 <fen> thanks
13:15:56 <zachk> is there anything I can pass to ghc/cabal install so ghc will take less RAM when compiling?
13:16:16 * hackage servant-swagger 1.1.7 - Generate Swagger specification for your servant API.  http://hackage.haskell.org/package/servant-swagger-1.1.7 (phadej)
13:16:34 <cocreature> Welkin: iirc all items are discarded while there is no client
13:16:37 <MarcelineVQ> -j1   if part of that ram use is from compiling dependencies
13:17:50 <shapr> zachk: https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/sooner.html ?
13:17:58 <Welkin> cocreature: what is the difference between broadcase-chan and newBroadcastTChan from stm?
13:18:19 <Welkin> broadcast-chan*
13:18:33 <zachk> should I even bother trying to use haskell-platform on a vps system with 512 megs of ram?
13:18:43 <Welkin> oh I see, one is STM the other isn't
13:18:54 <cocreature> the latter does not require stm and has more bells and whistles
13:19:18 <MarcelineVQ> Welkin: broadcase-chan's documentation tells you the difference
13:19:52 <cocreature> zachk: you’re almost certainly going to run into trouble. so compile locally and only deploy your executable
13:20:01 <MarcelineVQ> but if you're asking what single-wakeup and fair mean that's definitely a good question to ask on this sort subject
13:20:21 <shapr> I need to upgrade to a 128GB ram laptop
13:20:26 <shapr> </joke>
13:20:33 <zachk> how many slots do you have for ram though?
13:20:52 <Welkin> I just read the chapter on STM in the parconc book, so I have an idea what single-wakeup means: that only one thread is woken up instead of all of them that are blocked
13:21:10 <Welkin> because Chan maintains a FIFO queue of blocked readers
13:21:25 <shapr> zachk: my laptop right now has 64GB of ram, I tune GHC to use way more memory
13:21:36 <Welkin> shapr: laptop?
13:21:43 <Welkin> I am running 4 gb
13:21:51 <shapr> Welkin: ThinkPad P50, but I want the P52 that has the 128GB option
13:22:06 <Welkin> that is bigger than my storage drive (120 gb)
13:22:17 <shapr> I will say that the larger cache size on the Xeon helps with compilation
13:22:20 <cocreature> shapr: maybe you should learn to close some browser tabs instead :)
13:22:21 <zachk> im on 4gigs and thinking of going to 8gigs 
13:22:22 <kadoban> 128 is a bit hard to find even in desktops xD
13:22:46 <shapr> cocreature: My laptop also has a 4k screen, you would be *amazed* at how many browser tabs I can have open at the same time!
13:22:49 <zachk> I have no idea how stuff used to run 20 years ago with my 128 meg system
13:23:05 <kadoban> Poorly, mostly
13:23:18 <cocreature> shapr: one tab per pixel? :)
13:23:26 <zachk> ran quake3 just fine for competitive gaming :) 
13:23:28 <shapr> yeah, I wrote helper utilities for building GHC cause otherwise I would cry
13:23:57 <Welkin> why don't you have a threadripper laptop?
13:24:06 <shapr> Welkin: does that exist?
13:24:11 <Welkin> 16/32 cores
13:24:12 <Welkin> yes
13:24:16 <kadoban> It probably does soon if not already
13:24:21 <Welkin> the battery life is teribble though
13:24:31 <Welkin> it has been around for at least a year
13:25:04 <kadoban> Suppose that was inevitable, someone would make one once it came out for the bleeding edge people
13:25:06 <shapr> my P50 has a large battery, but Xeon can eat waay more than that
13:25:27 <shapr> if I do something like recompile amazonka from source, 1% battery per minute
13:25:44 <kadoban> I've been trying to plan a decent workstation. Was looking at threadripper briefly, but I don't think it'd make any sense even once the price drops a bit
13:26:22 --- mode: glguy set +v chessai
13:29:34 <Welkin> I'm wondering if I should use STM or not. I will have one thread per connection (on a web server) and each thread will read from a duplicate channel. I don't want the runtime to wake up 1,000 threads all at once
13:29:38 <mpickering> fen: So the question is precisely why is test4 slower than test2?
13:30:39 <shapr> I wrote a shell snippet to inform me when a long compile succeeds or fails: https://gist.github.com/shapr/fbe79e53f44e9b6d5a615bce349eb588
13:31:17 <Welkin> does it make sense to use Chan or TChan in this case, or is there no difference?
13:31:39 <Welkin> reading from a duplicate channel doesn't block unless it is empty
13:32:28 <Welkin> shapr: not `say "All your base are belong to us!"`?
13:33:23 <chessai> https://gist.github.com/chessai/0e85a0d6f783cee9535b2790a943fd50
13:33:32 <Welkin> I may need to re-read the STM chapter, but I recall that if threads are blocked on any operation in STM, all of them get woken up when the resource is unblocked
13:34:11 <Welkin> does this only apply to a single transaction?
13:34:11 <fen> mpickering: that, and why is test3 slower than test1
13:34:16 <Welkin> that would make sense
13:34:54 --- mode: glguy set +v reactormonk
13:34:55 <mpickering> If you look at the definition of test4 you can see it's implemented in terms of two recursive functions 
13:35:02 --- mode: glguy set -v reactormonk
13:35:42 <fen> the traversal and the list generation?
13:36:13 <MarcelineVQ> chessai: your first message didn't come through
13:36:29 <mpickering> fen: I mean the traversal
13:36:35 <mpickering> foldr and hyloList2 are both recursive
13:36:39 <chessai> MarcelineVQ what first messages
13:36:41 <mpickering> so it is harder for the optimiser to get rid of them
13:36:42 <fen> differenceTraverse4 g xs = (foldr (liftA2 (.)) (pure id)  (build (hyloList2 (differenceT2 g) xs))) <*> (pure Empty)
13:36:58 <mpickering> If you look at the core, you can see that hyloList2 is not eliminated
13:37:08 <fen> which should rewrite to;
13:37:11 <chessai> MarcelineVQ: oh, i think you're thinking i had a question. i do not have a question - i just thought the content of the gist was cool
13:37:24 <MarcelineVQ> ah ok
13:37:34 <fen> hyloList2 (differenceT2 g) xs (liftA2 (.)) (pure id) <*> (pure Empty)
13:37:50 <fen> right?
13:37:53 <mpickering> Where did the foldr go to?
13:37:58 <Welkin> chessai: fmap . fmap is available somewhere as <$$>
13:38:07 <chessai> Welkin: in base?
13:38:18 <Welkin> I dont recall
13:38:41 <chessai> hoogle with 'stackage' set provides package 'LambdaHack' as top result
13:38:45 <Welkin> I usually just define it myself, but when I use `fmap . fmap` it is usually a sign I am making my code too complicated
13:39:16 <chessai> it's a useful function when writing code with reflex
13:39:26 <Welkin> chessai: what is even cooler is (.).(.)
13:39:31 <chessai> oh boy
13:39:32 <Welkin> :t (.).(.)
13:39:34 <lambdabot> (b -> c) -> (a1 -> a2 -> b) -> a1 -> a2 -> c
13:39:34 <__monty__> chessai: fmap . fmap == fmap fmap fmap, it's related to the blackbird operator (...) = (.).(.)
13:39:34 <chessai> that is cool
13:39:36 <chessai> yeah
13:39:38 <Welkin> :t fmap . fmap
13:39:40 <lambdabot> (Functor f2, Functor f1) => (a -> b) -> f1 (f2 a) -> f1 (f2 b)
13:39:41 <Welkin> they are the same
13:40:01 <chessai> yeah
13:40:31 <fen> mpickering: thats build fold fusion!
13:40:39 <__monty__> Welkin: Imo, the fmap version's cooler, since it's more general.
13:40:49 <mpickering> What mechanism are you expecting it to happen by?
13:40:59 <fen> the build/fold rewrite rule
13:41:07 <mpickering> ok
13:41:22 <mpickering> Did you check that rule fired?
13:41:47 <fen> the benchmarks seem to indicate that it did not
13:41:58 <fen> neither for test4 or test3
13:42:00 <mpickering> You can check by looking at `-ddump-rule-rewrites`
13:42:32 <fen> runCommand "ghc -O2 traverseTest.hs -o main -ddump-simpl -ddump-rule-rewrites -dsuppress-all > main.core
13:42:32 <fen> ?
13:42:40 <mpickering> yes
13:42:55 <fen> nothing else? like maybe to get it below 1000 lines?
13:43:12 <mpickering> pipe it to a file
13:43:15 <mpickering> and then search for the rule
13:44:28 <mpickering> The rule is called "fold/build"
13:44:47 <mpickering> and it fires according to my log
13:45:41 <fen> so if thats not whats making it slow, what is?
13:46:13 <mpickering> https://usercontent.irccloud-cdn.com/file/C39EEU1a/Screen%20Shot%202018-11-13%20at%2021.37.03.png
13:46:20 <mpickering> That's the core for test4
13:46:28 <mpickering> So you can see that the call to hyloList2 is not eliminated
13:47:24 <fen> should it be? is it in test2? is that why test2 is faster?
13:48:36 <mpickering> test2 isn't implemented in terms of recursive functions so no it doesn't mention it
13:48:54 <mpickering> It's one possibility
13:50:18 <mpickering> just testing out another definition now
13:50:19 * hackage moo 1.2 - Genetic algorithm library  http://hackage.haskell.org/package/moo-1.2 (SergeyAstanin)
13:51:45 <mpickering> Try rewriting hyloList like this https://www.irccloud.com/pastebin/CPSMJtIU/
13:51:53 <mpickering> That makes it fast for me
13:55:52 <leifmetcalf> When parsing JSON: Is it better to first parse into an intermediate representation that closely matches the structure of the JSON and then translate that into the final representation type, or just to parse the JSON directly to the final representation type?
13:56:21 <Welkin> reading from a duplicate channel should always be a safe operation, right?
13:56:33 <mpickering> leifmetcalf: What's your opinion?
13:56:38 <Welkin> leifmetcalf: direct
13:57:19 <Welkin> why waste resources for no reason
13:57:33 <leifmetcalf> I tried doing it directly first, but having everything wrapped in `Parser` made the functions more complicated than I felt they needed to be.
13:57:41 <mpickering> https://twitter.com/shumovichy/status/1062309831288279041
13:57:45 <Welkin> leifmetcalf: why are you not using aeson?
13:57:51 <leifmetcalf> I am
13:58:37 <mpickering> I think parsing to intermediate representation is better
13:58:40 <Welkin> leifmetcalf: and you are definig FromJSON instances for your types?
13:58:40 <Solonarv> ah, so you're asking about having separate 'Foo' and 'FooRaw' types (or something like that)?
13:59:14 <leifmetcalf> mpickering: Is that bad? My new approach is to use the generic instances to parse too a FooRaw type, and then write my own functions to turn the FooRaw into a Foo
13:59:23 <leifmetcalf> Solonarv: yes
13:59:32 <mpickering> I think that's an excellent approach
13:59:56 <Solonarv> IMO if the generic instances don't do the right thing on my actual data types I'd often rather just write instances manuall
14:00:37 <mpickering> fen, did you try what I suggested?
14:02:25 <leifmetcalf> Solonarv: I tried that, but the translation from the raw data to the ideal representation is very complex, and having everything wrapped in `Parser` makes it more so.
14:02:58 <Welkin> leifmetcalf: simplifly your data then if you control it
14:03:19 <Solonarv> I'm assuming they're dealing with some messy JSON API
14:03:29 <leifmetcalf> Solonarv: that's correct
14:03:41 <leifmetcalf> Welkin: you mean simplify the final representation?
14:03:48 <Welkin> I meant the source
14:04:00 --- mode: glguy set +v fen
14:04:16 * hackage servant-multipart 0.11.3 - multipart/form-data (e.g file upload) support for servant  http://hackage.haskell.org/package/servant-multipart-0.11.3 (phadej)
14:04:17 <leifmetcalf> Ah, I do not control the source, it's a JSON API
14:04:43 <fen> mpickering: yes but it is not as fast
14:05:05 <mpickering> It is for me, ghc-8.6.1
14:08:34 <mpickering> https://usercontent.irccloud-cdn.com/file/W6eBqSsw/Screen%20Shot%202018-11-13%20at%2022.07.57.png
14:08:40 <mpickering> There's the core 
14:08:47 * hackage servant-mock 0.8.5 - Derive a mock server for free from your servant API types  http://hackage.haskell.org/package/servant-mock-0.8.5 (phadej)
14:10:32 <fen> so whats happening there with your new definition, the case handles the pattern matching and that allows some optimisation?
14:10:46 * hackage hmm-hmatrix 0.1.1 - Hidden Markov Models using HMatrix primitives  http://hackage.haskell.org/package/hmm-hmatrix-0.1.1 (HenningThielemann)
14:10:54 <fen> yes, its faster on this side too
14:11:13 <fen> will this also work for tests 1 and 3 ?
14:11:24 --- mode: glguy set -v chessai
14:11:30 <fen> hyloList1 is different
14:12:17 * hackage servant-js 0.9.4 - Automatically derive javascript functions to query servant webservices.  http://hackage.haskell.org/package/servant-js-0.9.4 (phadej)
14:12:48 <fen> obviously they wouldnt be as fast as 2 & 4 now are
14:12:56 <fen> but they should at least be as fast as each other
14:13:41 <chessai> https://gist.github.com/chessai/f6665d1abe01e92ddcd08150aa37845f
14:13:47 <chessai> as-patterns are unrestricted!
14:14:21 <fen> also, the way this example hyloList3 is so much faster seems to indicate that this kind of way of writing recursive pattern matching functions by placing the matching *within* the function rather at top level scope
14:15:12 <fen> honestly thats a very strange thing to find at the heart of the issue
14:15:57 <mpickering> It means that hyloLIst3 can get inlined
14:16:05 <mpickering> because it isn't recursive anymore
14:16:11 <fen> hmm
14:16:15 <fen> that kind of makes sense
14:16:19 <mniip> hmmmm
14:16:33 <mniip> liftingShowsPrec :: (Functor f, forall s. Reifies s (ReifiedShow a) => Show (f (ReflectedShow a s))) => (Int -> a -> ShowS) -> ([a] -> ShowS) -> Int -> f a -> ShowS
14:16:37 <mpickering> The static argument transformation does that transformation automatically
14:16:45 <mniip> could be useful for pretty-printers
14:16:58 <fen> so hyloList1 can be made to be not recursive using a similar "go" function in local scope? lets check, 1 sec
14:18:52 <mniip> % liftingShowsPrec (const showString) shows 11 (Just "hello") ""
14:18:52 <yahb> mniip: "(Just hello)"
14:20:58 <fen> wow, now all the versions using build (2,3,4) are as fast as each other
14:21:12 <fen> that seems to mean that there is no need to do the conversion to eliminate Maybe
14:21:39 <fen> (i.e. converting e.g. test 3 to test 4)
14:21:42 <c_wraith> does ghc eliminate the Maybes in the core?
14:22:28 <fen> maybe, ill link it incase anyone can read it
14:23:18 <mpickering> fen: You can try the dump-core package which is how I usually view core
14:23:40 <fen> its easier to read?
14:24:12 <mpickering> yes
14:24:58 <fen> more great documentation; http://hackage.haskell.org/package/dump-core-0.1.3.2/docs/DumpCore.html
14:25:34 <mpickering> https://github.com/yav/dump-core
14:29:28 <fen> so is there any point making the explicit rewrite rule between these 2 versions?
14:30:00 <mpickering> which two versions?
14:31:00 <mpickering> you seem to be saying now they all optimise to the same thing?
14:32:20 <mpickering> however, you have now discovered that the optimiser can be quite brittle and hard to understand
14:33:07 <fen> yes
14:33:12 <fen> thats exactly right 
14:35:17 <fen> ok, this paste is long and scary, but it shows where this approach would be used in practice
14:35:17 <fen> https://bpaste.net/show/a7132418dbf5
14:37:37 <fen> the function "progress" uses a looping function, to navigate over the "substructure" of a graph, from one value to the next
14:38:00 <fen> it has plenty of Maybes to control the various phases of this navigation
14:39:09 <fen> if a rewrite rule isnt necessary to ensure this is rewritten to the fastest version, then maybe just looping functions that are well designed wrt compiler optimisations is all that is nesacary
14:39:42 <mpickering> you'll have to look at the core again
14:40:03 <fen> it was hoped that by using build/fold fusion, that this process could be relied on to do this rewrite
14:40:48 <fen> and being unable to read core, benchmarking these loops would be a way to ensure they perform well
14:42:35 <fen> (installing DumpCore just broke the Criterion install, so that looks like all for now)
14:42:52 <fen> might try this new version of ghc...
14:43:05 <fen> mpickering: thanks for the help
14:52:41 <koz_> Does anyone know how to get one of those Hackage badges for a Github repo?
14:52:45 <koz_> (in the README)
14:53:48 <wchresta> koz_: Yeah, just copy paste the url from one of the ones you see. It's just an image link to a specific url
14:53:59 <koz_> wchresta: Oh, OK. Thanks!
15:08:39 <YellowOnion> what does flip do with a function that has more than two parameters?
15:08:46 * hackage hmatrix-vector-sized 0.1.1.1 - Conversions between hmatrix and vector-sized types  http://hackage.haskell.org/package/hmatrix-vector-sized-0.1.1.1 (jle)
15:08:51 <YellowOnion> :t flip
15:08:53 <lambdabot> (a -> b -> c) -> b -> a -> c
15:09:24 <mniip> suppose the function foo :: X -> Y -> Z -> W
15:09:49 <mniip> applying 'flip foo' yields a=X, b=Y, c=(Z -> W)
15:10:03 <mniip> and the result is  b -> a -> c  =  Y -> X -> Z -> W
15:10:13 <geekosaur> YellowOnion, any function has one paramete; if it appears to take multiple, it actually takes one and produces a function that takes another, etc.
15:10:53 <mniip> yes, X -> Y -> Z -> W is a more convenient notation for  X -> (Y -> (Z -> W))
15:12:07 <YellowOnion> so how do I transform a -> b -> c -> d to b -> c -> a -> d?
15:13:03 <c_wraith> YellowOnion, easiest to not use flip
15:13:30 <c_wraith> YellowOnion, just write it out.
15:13:58 <c_wraith> but if you really must torture yourself, there's always @pl
15:14:25 <YellowOnion> c_wraith, I wanted the last parameter to be a do block, which always looks nice
15:14:37 <c_wraith> @pl \f b c a -> f a b c
15:14:37 <lambdabot> (flip .) . flip
15:14:45 <koz_> Yay for @pl.
15:14:50 <YellowOnion> Ha.
15:14:55 <geekosaur> both dotty and flipping you off...
15:15:12 <koz_> inb4 someone feeds it something like \a b c d e f -> f d c b a e
15:16:38 <YellowOnion> `runHaskeyT (do blah) db def` to this: `runHaskeyT db def $ do blah`
15:17:43 <geekosaur> withHaskeyT db def f = runHaskeyT f db def -- really not worth flipping out over
15:18:44 <koz_> What's Haskey?
15:19:27 <jle`> YellowOnion: btw, fun fact, ghc 8.6 lets you do runHaskeyT db def do blah
15:19:45 <jle`> without the $
15:19:47 <YellowOnion> koz_, It's a kv store written in Haskell.
15:19:53 <koz_> Ah.
15:20:01 <jle`> apologies for unsolicited fun fact
15:20:11 <YellowOnion> jle`, you have my curiosity.
15:20:17 <koz_> jle`: Did they change fixities or something?
15:20:29 <jle`> -XBlockArguments
15:20:31 <koz_> Or something about precedence?
15:20:33 <jle`> do no longer requires $ before it
15:20:33 <koz_> Ah.
15:20:47 <koz_> Another reason why 8.6 is delicious.
15:20:49 <jle`> it's more readable if the 'blah' is on a new line afterwards
15:21:17 * hackage hmatrix-vector-sized 0.1.1.2 - Conversions between hmatrix and vector-sized types  http://hackage.haskell.org/package/hmatrix-vector-sized-0.1.1.2 (jle)
15:21:18 <YellowOnion> geekosaur, withHaskeyT I'm surprised it's not already implemented.
15:21:48 <fen> kv store?
15:21:53 <geekosaur> that's a question for whoever maintains the package you found it in
15:22:35 <YellowOnion> fen, key value store.
15:22:59 <fen> argh
15:23:22 <YellowOnion> I don't need performance, and it's giving me some insight on contructing haskell types, while also avoiding an external library.
15:24:15 <fen> :t seek
15:24:16 <lambdabot> error: Variable not in scope: seek
15:24:21 <fen> % :t seek
15:24:21 <yahb> fen: ComonadStore s w => s -> w a -> w a
15:25:20 <fen> similar to pointer navigation...
15:26:41 <fen> actually, it might just be totally equivalent 
15:26:53 <fen> maybe the Comonad instance is different...
15:28:16 <fen> oh wait confused... was thinking of data Store s a = Store (s -> a) s
15:28:31 <fen> duplicate (Store f s) = Store (Store f) s
15:29:55 <fen> = ((((s -> a),s) -> a),s)
15:32:46 * hackage servant-yaml 0.1.0.1 - Servant support for yaml  http://hackage.haskell.org/package/servant-yaml-0.1.0.1 (phadej)
15:33:11 <fen> is that different?
15:34:13 <fen> hmmm,   seeks f = peeks f . duplicate
15:34:20 <fen> that looks slow for pointers
15:34:57 <fen> they should be navigated from where they are to where they should be, rather than a global accessor to the traversal that gives duplicate
15:35:16 <fen> maybe these pointers are really fast versions of ComonadStore...
15:35:58 --- mode: glguy set +v nksegos_
15:36:46 <fen> or maybe thats a sign that the traversal is a slow pointer duplicate... like, it has to be rewound to the first entry to then go over each value, replacing this with a pointer to that value. 
15:36:55 <fen> and then navigated back to where it was
15:37:33 <fen> if that wasnt the case it might work really well with ComonadStore...
15:37:57 <fen> *slow implementation of duplicate for pointer
15:38:08 <fen> it should do better at retaining its position 
15:38:23 <fen> rather than rewinding and then getting back to where it was
15:38:53 <fen> how is traverse supposed to start from the middle!?
15:39:19 <fen> :t split
15:39:19 * hackage mattermost-api 50200.0.1 - Client API for Mattermost chat system  http://hackage.haskell.org/package/mattermost-api-50200.0.1 (KevinQuick)
15:39:20 <lambdabot> Splitter a -> [a] -> [[a]]
15:39:32 <fen> hmm, whats dual to mappend?
15:39:46 * hackage mattermost-api-qc 50200.0.1 - QuickCheck instances for the Mattermost client API library  http://hackage.haskell.org/package/mattermost-api-qc-50200.0.1 (KevinQuick)
15:41:57 <fen> damn, then there is that whole higher dimensional square grid thing, like where going up shouldnt mean going right over the whole rest of the current row, and then right some of the way allong the row above
15:42:25 --- mode: glguy set +v nksegos
15:42:40 <Solonarv> fen: 'split :: a -> (a, a)', or 'flip (<>)' -- depends on the precise meaning of "dual"
15:42:50 --- mode: glguy set -v nksegos
15:42:51 <fen> there is a faster version for Cartesian grids, but only for grids
15:43:22 <fen> Solonarv, yeah, thats the split... then the traverse can be done backwards over one half and forwards over the rest
15:44:08 <fen> but if that was going to be lazily navigated to some other value according to some direction (type s of ComonadStore is like a navigational index, like (Int,Int) for square grids)
15:44:43 <fen> its only faster if this can be done in orthogonal directions
15:44:57 <fen> especially for higher dimensions  
15:45:22 * hackage brick 0.41.3 - A declarative terminal user interface library  http://hackage.haskell.org/package/brick-0.41.3 (JonathanDaugherty)
15:46:07 <mniip> you could also pick a dual monoidal structure
15:46:30 <mniip> 0 -> a; a + a -> a
15:46:46 <fen> dustruct and split right?
15:47:03 <fen> a -> 0; a -> a + a
15:47:12 <fen> comonoid 
15:47:21 <mniip> no, a -> a * a
15:47:23 <mniip> in a comonoid
15:47:34 <mniip> also a -> 1
15:47:37 <mniip> is destruct
15:47:37 <fen> damn, the implementation is wrong in my paste...
15:47:39 <fen> right (FreeZipper (Zipper fs (Free z))) = fmap (\z' -> FreeZipper (Zipper fs (Free z'))) (forwardsS z)
15:47:47 <fen> that only goes forwards on the current row
15:47:58 <fen> it should map forwards over all rows 
15:49:15 <Solonarv> in haskell, that'd be 'class Comonoid a where split :: a -> (a, a); destruct :: a -> ()' - which has a trivial implementation for every 'a', making it not particularly useful
15:49:26 <fen> oh no comonoid is not the correct thing if it makes a sum type... thats `a -> Either a a'
15:49:48 <fen> Solonarv: no mniip is saying thatsnot dual
15:50:02 <fen> it needs to dual up the * and +
15:50:03 <Solonarv> as I said: depends on the precise meaning of "dual"
15:50:09 <fen> hmmm
15:50:17 <fen> i prefer your version
15:50:21 <fen> if there was a choice
15:50:25 <fen> not sure there is though
15:50:44 <Solonarv> well my version is rather useless! (in haskell, that is)
15:50:52 <fen> not at all!
15:51:12 <fen> const or destruct are really essential for doing stuff properly
15:51:43 <Solonarv> for one, it shouldn't be a class, since you can write 'instance Comonoid a'
15:51:59 <fen> just dont...
15:52:03 <fen> problem solved
15:52:13 <fen> its a valid Comonoid
15:52:28 <Solonarv> tell me, what are the laws for (this form of) Comonoid?
15:52:37 <fen> this idea of classes having one unique implementation is an artefact of the haskells undecidable overlapping bs
15:52:53 <fen> oh laws, now thats more serious
15:53:00 <fen> that might cause one valid instance
15:53:06 <fen> to be the only valid instance
15:53:20 <Solonarv> classes are pretty useless without (at least informal) laws
15:53:29 <fen> and while not all classes have laws, this seems like one that would
15:53:39 <fen> (as Monoid does)
15:54:02 <fen> the laws are probably that the duals yield identity
15:54:03 <fen> wait
15:54:25 <fen> that makes your version seem more correct that the one that mixes up (,) and Either
15:54:34 <fen> might be some kind of square thing going on 
15:54:55 <fen> dont ask me about this stuff! idk!
15:56:28 <fen> ( whats a -> Either a a !?)
15:57:09 <fen> reversing arrows and exchanging product and sum should really have unique names
15:57:17 <fen> they must be called something other than dual
15:57:30 <Solonarv> iiuc the laws should be something like 'first dup . dup ≅ second dup . dup', 'first destroy . dup ≅ id', 'second destroy . dup ≅ id'
15:57:35 <hpc> we could take whatever the thing is, and put "co" before it
15:57:42 <hpc> now we have infinite interesting names
15:57:43 <MarcelineVQ> reversing arrows is contra, ofen shortened to co
15:57:55 <fen> if reversing arrows is the dual we like, whats the reversing *,+ called? whats the combination of both called?
15:57:55 <mniip> fen, I said "you could also"
15:58:05 <lavalike> @freshname
15:58:05 <lambdabot> Hasq
15:58:09 <lavalike> infinite names
15:58:17 <hpc> @freshname
15:58:17 <lambdabot> Hasr
15:58:21 <mniip> in the (Hask, *, ()) monoidal structure
15:58:23 <hpc> heh
15:58:25 <mniip> there's monoids and comonoids
15:58:26 <fen> yeah but co is self inverse
15:58:40 <fen> and there are 4 things we are talking about
15:58:42 <mniip> and in (Hask, +, 0) monoidal structure
15:58:46 <fen> so there needs to be some more names
15:58:47 <mniip> there's also monoids and comonoids
15:59:06 <Solonarv> that's the direct analogy to the Monoid laws, and these laws are fulfilled by 'dup x = (x, x); destroy = const ()' - so not particularly interesting or useful!
15:59:33 <mniip> Solonarv, unless your underlying logic is linear!
15:59:34 <fen> aha sorrt MarcelineVQ
15:59:42 <fen> sorry* dindt see that
15:59:45 <Solonarv> yes, with linear arrows it gets more interesting
15:59:45 <fen> "contra"
15:59:51 <fen> ContraMonoids
15:59:54 <mniip> and dup/destroy have to be explicit
16:00:20 <Solonarv> with linear arrows, 'Comonoid' basically means "unrestricted"
16:01:04 <MarcelineVQ> fen: more specifically it's terminology lifted from https://en.wikipedia.org/wiki/Functor#Covariance_and_contravariance  which, just for fun, both start with co
16:01:15 <fen> you would have a difficult job dealing with networks representing computations without being able to delete nodes
16:01:20 <fen> destroy is essential
16:01:26 <fen> like flip and (.)
16:01:34 <fen> its like an axiom or something
16:01:43 <fen> or a fundamental combinator 
16:02:10 <fen> so is a Comonoid contra or co?
16:02:11 <Solonarv> sure; that just means "invert the arrows on base:Data.Monoid.Monoid" does not get you the right abstraction
16:02:15 <fen> Comonad*
16:02:36 <mniip> a comonad is a comonoid in the category of endofunctors
16:02:47 <fen> a contramonoid?
16:02:52 <mniip> the monoidal structure in use for monads doesn't have a dual akin to *
16:03:01 <dmwit> > fromEnum 's' - fromEnum 'a'
16:03:03 <lambdabot>  18
16:03:15 <dmwit> > 19*26+18
16:03:17 <fen> mniip: but the Monoids do
16:03:18 <lambdabot>  512
16:03:26 <mniip> fen, did you read what I said earlier
16:03:36 <fen> linear logic?
16:03:39 <mniip> no
16:03:49 <mniip> a monoidal structure produces both monoids and comonoids
16:03:55 <fen> in the (Hask, *, ()) monoidal structure
16:04:03 <fen> and in (Hask, +, 0) monoidal structure
16:04:09 <fen> there's also monoids and comonoids
16:04:12 <fen> that^ ?
16:04:24 <mniip> in a category C with monoidal structure (C, ⊗, 1)
16:04:38 <mniip> a monoid object is X in Ob(C) with morphisms X⊗X -> X  and 1 -> X
16:04:42 <fen> tensor!?
16:04:56 <mniip> a comonoid object is X in Ob(C) with morphisms X -> X⊗X  and X -> 1
16:05:03 <mniip> (such that such and such commute)
16:05:12 <fen> its a semiring if it has both right?
16:05:20 <fen> like, 2 monoids
16:05:25 <fen> one for +, one for *
16:05:30 <mniip> what
16:05:35 <fen> like Nat
16:05:59 <fen> but, with the product and sum being (,) and Either
16:06:16 <shachaf> (+) and (*) are both monoidal
16:06:17 <fen> haskell types must for a semiring then
16:06:48 <mniip> sigh
16:06:59 <fen> no?
16:07:15 <mniip> 11/14/2018 [03:04:49] <fen> its a semiring if it has both right?
16:07:16 <mniip> both what
16:07:26 <mniip> I described a monoid and a comonoid of an arbitrary monoidal category
16:07:27 <fen> 2 associative things
16:07:41 <fen> binary functions
16:07:42 <shachaf> comonoids are more coassociative than associative
16:07:52 <mniip> the two "associative things" I described are very different in natura
16:07:55 <fen> ⊗ = + or ⊗ = *
16:08:04 <mniip> is + a bifunctor?
16:08:13 <fen> its Either
16:08:15 <fen> so yes
16:08:28 <shachaf> Wait, this is #haskell. I thought it was a different channel.
16:09:02 <mniip> then + and * both create monoidal structure on hask
16:09:18 <mniip> the structure created by * is your familiar average monoids
16:09:18 <fen> ah, so Hask is a semiring?
16:09:35 <mniip> Ob(Hask) is a semiring yes
16:09:39 <fen> woot!
16:09:42 <mniip> under Ob(+) and Ob(*)
16:09:46 <fen> Ob
16:09:52 <fen> what kind of a mapping is that
16:09:57 <fen> seems to be written in c
16:10:15 <mniip> Ob(+) is a notation I just made up for the object mapping of a functor
16:10:33 <mniip> Ob(Hask) is the set of objects of Hask
16:10:37 <fen> protected void <⊗ :: C > Ob(⊗)
16:10:56 <mniip> Ob : Category -> Set
16:11:15 <fen> much better
16:11:27 <fen> good ol cons
16:11:35 <mniip> now lift Ob to a functor
16:11:38 <mniip> Ob : Cat -> Set
16:11:50 <mniip> and then Ob(F) where F is a functor is well defined
16:11:57 <fen> wait
16:12:22 <mniip> in particular if F : C -> D, then Ob(F) : Ob(C) -> Ob(D)
16:12:36 <fen> because it has Cat as its codomain and Set as its domain 
16:12:51 <fen> hmm
16:12:52 <fen> ok
16:13:27 <fen> so whats up with this, "object mapping"
16:13:36 <fen> like, why?
16:14:20 <mniip> why what
16:14:20 <fen> in haskell we say a -> b, and dont care that it means "a *value* of type `a' to a *value* of type `b'"
16:14:33 <mniip> what
16:14:36 <fen> why talk about the objects, when we can think about types
16:14:43 <shachaf> Objects are not values.
16:14:44 <mniip> in Hask objects are the types
16:14:50 <shachaf> Objects are types.
16:14:50 <fen> right
16:14:52 <Solonarv> the objects of Hask are types
16:14:59 <fen> values of Hask are types
16:15:05 <fen> same difference
16:15:10 <mniip> what
16:15:13 <Solonarv> no, "values of Hask" is a nonsense phrase
16:15:14 <shachaf> "values" of a category isn't a thing
16:15:16 <mniip> you know what Hask is?
16:15:20 <mniip> right?
16:15:44 <fen> reflecting considereations at type level down to value level is not intuitive, so why bother mapping from sets to objects?
16:15:48 <shachaf> Petition to rename "objects" to a less concrete-sounding word because people keep getting confused by this.
16:15:54 <Solonarv> "values of Hask" means the same thing as "a;dofjgner[ of Hask" - which is to say, it doesn't mean anything
16:16:14 <Solonarv> shachaf: seconded!
16:16:22 <fen> well whats a type anyway, its just a set of values
16:16:47 <fen> with some restrictions, like a subset of types that have no such restrictions
16:17:00 <fen> so this set of objects is then much like a type
16:17:03 <Solonarv> category theory doesn't concern itself with what an object "really is"
16:17:12 <fen> and the Ob mapping is confusing for this reason
16:17:23 <Solonarv> but yes, Hask is similar-ish to Set, and the analogy is useful
16:17:31 <mniip> you are confusing for the reason of refusing to learn proper terminology
16:17:41 <Solonarv> (in Set, the objects are sets)
16:17:54 <shachaf> One might ask the same thing about birds.
16:17:57 <shachaf> What are birds?
16:18:05 <fen> you are using proper terminology for no reason, and its confusing 
16:18:27 <Solonarv> think of how much more confusing it'd be if we weren't using proper terminology!
16:18:29 <fen> sure A -> B and Ob(A) -> Ob(B) makes sense
16:18:38 <fen> but why not just use the one that looks more like types
16:18:41 <Solonarv> we'd be using the same word for different things, or different words for the same thing
16:19:04 <mniip> when discussing advanced concepts, you use terminology to precisely convey your meaning
16:19:23 <fen> if there is an actual reason to talk about the objects of a set rather than mappings over all objects in a set, now would be the time to say
16:19:28 <mniip> you say "unital ring" instead of "mushy like thing that combines"
16:19:33 <fen> NO
16:19:41 <fen> this is a specific example
16:19:51 <fen> and in this instance its a reasonable question
16:20:14 <fen> obviously not arguing to reject all terminology. thats crazy!
16:20:46 <fen> why talk about objects in a set rather than the sets, when speaking to a haskell audience
16:20:56 <mniip> there are no "objects in a set"
16:20:58 <shachaf> "objects" are not the elements of a set
16:21:01 <fen> argh
16:21:17 <shachaf> "object" is a word that means something else. This is why people are being careful (?)
16:21:18 <fen> if only i understood this stupid terminolgy so i could better argue why not to use it
16:21:22 <mniip> "object" is a term
16:21:32 <shachaf> I agree with you, it's not great terminology
16:21:52 <mniip> a category is a set of objects (Ob) and for each pair of objects a set of morphisms (Hom)
16:22:12 <mniip> this is what we mean when we say "objects in Hask are types"
16:22:13 <fen> lets invent a better term for object so we can argue why not to use it without getting confused about terminolgy 
16:22:16 <mniip> as Hask is a category
16:22:37 <fen> but sets are a category
16:22:41 <fen> and its not a category
16:22:43 <fen> its a set
16:22:44 <mniip> Set is a category yes
16:22:51 <fen> so why say object
16:22:59 <mniip> Set is the category where objects are sets and morphisms are functions
16:23:03 <fen> Hask is a set, yes
16:23:08 <mniip> no
16:23:21 <fen> hmmm
16:23:29 <fen> so what are Categories that dont use sets called?
16:23:37 <fen> because its not one of those
16:23:42 <fen> my mistake, sry
16:23:50 <shachaf> The dangers of object-oriented thinking.
16:24:26 <fen> so, same argument as above, but with set -> category 
16:24:37 <mniip> a category, by definition, has a set of objects
16:24:39 <Solonarv> I typed out something rather long which I'm not sure is correct, someone shitcheck me:
16:24:40 <Solonarv> in the monoidal category (Hask, *, 1):
16:24:40 <Solonarv>    an object X in Hask is
16:24:40 <Solonarv>       a monoid if there are arrows (X * X) -> X and 1 -> X
16:24:40 <Solonarv>       a comonoid if there are arrows X -> (X * X) and X -> 1
16:24:40 <Solonarv> in the monoidal category (Hask, +, 0):
16:24:40 <Solonarv>   an object X in Hask is
16:24:41 <Solonarv>     a monoid if there are arrows (X + X) -> X and 0 -> X
16:24:41 <Solonarv>     a comonoid if there are arrows X -> (X + X) and X -> 0
16:24:43 <mniip> objects themselves can be whatever though
16:25:07 <mniip> Solonarv, yes
16:25:18 <shachaf> Solonarv: Plus some laws
16:25:29 <Solonarv> yes, forgot to mention those
16:25:35 <mniip> yes, you need to figure out how to encode associativity in terms of morphisms only
16:26:01 <fen> so, as Types are the Objects of Hask. you say Ob(Hask) -> Ob(Hask)
16:26:15 <fen> where we say (a -> b) ?
16:26:27 <mniip> not sure what you're trying to say here
16:26:38 <jle`> an (a -> b) is a member of Hom(Hask)_a,b
16:26:39 <fen> are you reflecting from a higher levity?
16:26:51 <mniip> "levity"
16:26:59 <fen> casting, whatever a levity changing transformation is called
16:27:05 <Solonarv> no, Ob(Hask) -> Ob(Hask) is more like a type constructor (specifically, something of kind 'Type -> Type')
16:27:21 <fen> a set of types is like "one level above" types, which are sets of values
16:27:33 <shachaf> fen: I think the best thing here is to take a step back, forget about Hask and whatever, and make sense of the definition of the category in some other context.
16:27:35 <fen> (ignoring morphisms so I can say set instead of Category)
16:27:44 <shachaf> It comes across as just typing symbols.
16:27:48 <fen> ?
16:28:01 <mniip> I'll try to explain without any notation
16:28:05 <fen> a category is a set with some arrows at leas id
16:28:13 <fen> simples
16:28:15 <mniip> you mention that Hask is "like a semiring"
16:28:39 <mniip> a semiring is first and foremost a set, with a couple binary operations. Hask is a category
16:28:49 <mniip> what I'm saying is that /the set of objects of Hask/ is indeed a semiring
16:29:00 <fen> yes, (+ : Hask -> Hask -> Hask) and (* : Hask -> Hask -> Hask)
16:29:01 <mniip> but saying that Hask is a semiring is a bit loose
16:29:14 <mniip> well except that, again, Hask is a category
16:29:23 <jle`> fen: not Hask -> Hask -> Hask, but Ob(Hask) -> Ob(Hask) -> Ob(Hask)
16:29:32 <fen> why though!?
16:29:42 <jle`> because Ob(Hask) is the semiring you are talking about
16:29:43 <jle`> not Hask
16:29:56 <jle`> Ob(Hask) is the set of haskell types
16:30:02 <jle`> Hask is not the set of haskell types.
16:30:09 <jle`> so one of these is the set of haskell types
16:30:11 <jle`> and it's not Hask
16:30:16 <fen> so the confusion is that im trying to use Hask like a type
16:30:24 <fen> but its a set of types
16:30:28 <jle`> you're trying to use Hask to refer to the set of haskell types
16:30:31 <fen> so its at higher levity...
16:30:33 <jle`> but it is not the set of haskell types
16:30:49 <fen> because it has morphisms also?
16:31:16 <jle`> primarily because it is a category, and not a set.
16:31:19 <jle`> they are different concepts
16:31:22 <fen> its a category over a set
16:31:29 <fen> and im ignoring the morphisms
16:31:56 <jle`> the important thing here is that it is a category, and not a set
16:32:00 <shachaf> Welcome to #haskell, where your questions are answered in a dissonant cacophony!
16:32:19 <shachaf> Not that I'm helping.
16:32:31 <fen> that is defiantly not whats the problem!
16:32:45 <fen> it *is* a set, despite also being a category
16:32:53 <fen> thats just extra morphisms, no need 
16:33:10 <jle`> Hask is not a set, it is a category
16:33:12 <jle`> Ob(Hask) is a set
16:33:17 <fen> aha!
16:33:30 <shachaf> I suggest listening to the people who are answering your questions about things they know that you're trying to figure out, rather than disagreeing with everything they say.
16:33:31 <Solonarv> fen: it *is* not a set. It *has* a set of objects
16:33:37 <fen> so Ob is the morphism ignoring transformation
16:33:54 <jle`> i'm not sure what you mean, but Ob(Hask) is defined as the set of Haskell types
16:34:03 <fen> why talk about Hask then
16:34:16 <jle`> we talk about Hask when we want to talk about a category
16:34:20 <fen> just talk about Ob(Hask) and drop the superfluous notation
16:34:24 <jle`> we talk about Ob(Hask) when we want to talk about a set
16:34:39 <fen> when could you possibly want to talk about Hask!?
16:34:40 <shachaf> Also I suggest you take this conversation to #haskell-overflow.
16:34:44 <Solonarv> because we're writing haskell, and Hask is the category that haskell's type system is based on
16:35:21 <fen> right, but Ob(Hask) is the set of haskell types. so why would you want to talk about the morphisms?
16:35:27 <jle`> fen: you want to talk about Hask when you want to talk about category-related concepts, like functors.  and yeah, probably to go deeper we'd go to #haskell-overflow
16:35:51 <fen> all I see is Ob(...) everywhere, which until now was totally confusing, so no doubt it is for everyone else in the universe!
16:35:53 <hpc> fen: because it's category theory and not set theory :P
16:35:59 <jle`> fen: it can be useful to talk about Hask as a category; that's the basis of the Functor, Monad etc. typeclasses
16:36:13 <jle`> but it's not useful when you just want to talk about the set of haskell types.
16:36:26 <shterrett> (I hate to interrupt,  but I have a question about TVars. I’m trying to use a bounded queue with a “I’m finished” value so the consumer knows to exit when the queue is empty and the producer is finished. It’s currently deadlocking/infinite looping. The relevant files are https://github.com/shterrett/escape-from-itunes/blob/infinite-loop/app/Main.hs line 32 and 
16:36:27 <shterrett> https://github.com/shterrett/escape-from-itunes/blob/infinite-loop/src/Channel.hs line 41, 50-52, and 61. I *think* it’s a laziness issue with the producer calling `finish`, but I’m not sure)
16:36:27 <fen> so whats a Functor?
16:36:38 <shachaf> shterrett: You're not interrupting
16:36:42 <fen> described referring to Hask
16:36:44 <shachaf> fen: Take this conversation to #haskell-overflow
16:37:09 <fen> your inviting me out!?
16:37:25 * shachaf sighs
16:37:27 <shterrett> ^ that was not my intention
16:37:48 <shachaf> Moving the conversation there had already been mentioned multiple times.
16:38:10 <jle`> that was nobody's intention
16:38:18 <hpc> i mean, the channel actually exists...
16:38:39 <hpc> that conversation was finally getting somewhere too
16:39:27 <phadej> I wonder if there are people who read all of #haskell
16:39:28 <hpc> shterrett: that's a pretty good name on your repo
16:39:53 <shachaf> Solonarv: So +-monoids must be boring, right?
16:39:57 <Solonarv> we're not saying "shut up", we're saying "lets go find a cozy place where we won't drown out other discussions"
16:40:03 <shachaf> Like *-comonoids. And +-comonoids don't exist at all.
16:40:06 <shterrett> hpc: Thanks :)
16:40:12 --- mode: glguy set +v fen
16:40:14 <fen> Hask is the set of haskell types. Cat(Hask) is the Category over the set of haskell types
16:40:40 <Solonarv> shachaf: certainly true in Hask, AIUI
16:40:50 <mniip> shachaf, empty set
16:40:57 <shachaf> ?
16:41:06 <Solonarv> 'data Void' <- that
16:41:09 <mniip> initial object is a +-comonoid
16:41:15 <shachaf> Oh, sure
16:41:52 <jle`> Solonarv: they had quit when you wrote your message, so your message was not seen at the time.
16:42:00 <Solonarv> yeah, I noticed afterwards
16:42:28 <Solonarv> phadej: I read all of it as long as I'm online, so I'm halfway there!
16:43:01 <phadej> nah, reading all of the backlog too
16:43:03 <phadej> is the thing
16:43:03 <Solonarv> I'd probably read backscroll too if I could be bothered to set up a bouncer
16:43:19 * lavalike bounces
16:44:03 <shachaf> monoidal categories moproblems
16:44:03 <hpc> shterrett: my gut says it's in readChan, because it does a lot of things
16:44:08 <hpc> like reverse, and both reads and writes
16:44:39 <Solonarv> comonoidal cocategory coproblems?
16:45:08 <shterrett> hpc: I lifted that almost verbatim from _Parallel and Concurrent Programming in Haskell_. 
16:45:22 <hpc> oh, nvm
16:45:33 <hpc> although perhaps i could interest you in http://hackage.haskell.org/package/stm-2.5.0.0/docs/Control-Concurrent-STM-TChan.html
16:46:08 <lavalike> the dual of Ntrol.Ncurrent.STM.TChan
16:46:14 <shterrett> Yeah - I want a bounded channel because I expect the generation of paths to be *much* faster than the copying, and I don’t want the channel to blow up in size
16:46:23 <hpc> oh, right
16:46:25 <hpc> hmm
16:46:48 <Solonarv> there's a TBChan somewhere, too
16:47:16 <Solonarv> lavalike: no, it's the dual of Ntrol.Ncurrent.CoSTM.CoTChan !
16:47:36 <hpc> this sort of feels like a place for blocking instead of transactions
16:48:06 <hpc> you have a producer and a consumer, and they're async but kept somewhat in sync by the bounds of the channel
16:48:20 <hpc> one can only ever get a fixed distance away from the other
16:48:31 <shterrett> yeah
16:48:33 <hpc> when producer fills the channel, it should stop
16:48:38 <hpc> when consumer empties the channel, it should stop
16:48:53 <shterrett> and eventually, when there’s nothing left to produce, everybody should exit
16:48:59 <hpc> and blocking is perfect for that, so maybe a regular bounded channel instead of transactional thingy?
16:49:46 <shterrett> Something like https://hackage.haskell.org/package/BoundedChan
16:50:09 <hpc> transactional concurrency works best with contention
16:50:18 <hpc> when you have multiple writers or readers interfering with each other
16:50:25 <hpc> (usually multiple writers)
16:52:51 <lavalike> Solonarv: duh!
16:54:25 <hpc> shterrett: yes, this is definitely a place for blocking - it took me a minute to get my brain into concurrency mode but now i am sure
16:54:40 <leifmetcalf> Uploaded file: https://uploads.kiwiirc.com/files/c25ede2efa25eb673cf54f778b2f3d31/pasted.txt
16:54:49 <leifmetcalf> What does that mean
16:55:15 <shterrett> hpc: ok - I’ll rework it with BoundedChan instead of STM. That makes sense
16:55:57 <leifmetcalf> Ignore me, I got it
16:56:34 <shterrett> To signal that it’s empty and nothing more is coming, should I make the channel a sum type, something like `data Element = Running Copy | Finished`?
16:57:05 <Solonarv> shterrett: that seems reasonable, though you could also just use Maybe instead of your own custom type
16:57:24 <shterrett> Solonarv: yeah - good point
16:58:37 <shterrett> Great - thanks. I’ll go refactor
17:02:52 * hackage hid-examples 0.3 - Examples to accompany the book "Haskell in Depth"  http://hackage.haskell.org/package/hid-examples-0.3 (bravit)
17:09:44 <Nolrai> @hoogle dimap
17:09:44 <lambdabot> Control.Lens.Iso dimap :: Profunctor p => (a -> b) -> (c -> d) -> p b c -> p a d
17:09:44 <lambdabot> Data.Profunctor dimap :: Profunctor p => (a -> b) -> (c -> d) -> p b c -> p a d
17:09:44 <lambdabot> Data.Profunctor.Types dimap :: Profunctor p => (a -> b) -> (c -> d) -> p b c -> p a d
17:55:16 * hackage extensible-effects-concurrent 0.13.2 - Message passing concurrency as extensible-effect  http://hackage.haskell.org/package/extensible-effects-concurrent-0.13.2 (SvenHeyll)
17:57:17 * hackage waargonaut 0.3.0.0 - JSON wrangling  http://hackage.haskell.org/package/waargonaut-0.3.0.0 (schalmers)
17:59:46 * hackage attoparsec-ip 0.0.5 - Parse IP data types with attoparsec  http://hackage.haskell.org/package/attoparsec-ip-0.0.5 (athanclark)
18:27:30 <shterrett> hpc: I refactored to use a BoundedChan and not STM, so it’s blocking now. But it’s still “thread blocked indefinitely in an MVar operation” New code: https://github.com/shterrett/escape-from-itunes/blob/infinite-loop/app/Main.hs
18:49:46 * hackage shift 0.2.1.1 - A tool to quickly switch between directories  http://hackage.haskell.org/package/shift-0.2.1.1 (vmchale)
18:57:26 <lyxia> shterrett: lines 28 and 29, each call to channel is creating a fresh chan
18:58:04 <shterrett> well that would explain it
18:58:16 <lyxia> you need to bind the channel higher.  let ... in channel >>= \c -> concurrently (readSources ... c) (doAction ... c)
18:58:24 <shterrett> Why is that? I thought `newBoundedChan` created a single reference
18:58:31 <lyxia> it does
18:58:34 <shterrett> ok - that makes sense
18:58:37 <lyxia> once for every time you run it
18:58:46 <lyxia> and you were running it twice
18:59:02 <shterrett> right - because it return an IO action that I’m running each time I call bind
19:00:25 <lyxia> indeed
19:01:02 <shterrett> brilliant — thanks so much
19:01:14 <shterrett> It’s working properly now
19:02:51 <lyxia> yw
19:14:56 <rotaerk> hmm why do I see people often use Spec.hs for the test suite's main file?
19:16:58 <rotaerk> just feel like I'm missing some background behind that convention
19:17:00 <lyxia> I think it's in a stack template
19:17:06 <rotaerk> ah
19:17:43 <lyxia> which might come from an older convention, idk
19:18:19 * geekosaur immediately thought "hspec" fwiw
19:19:26 <rotaerk> the tutorial I read about quickcheck didn't mention anything about converting Properties into cabal Tests, but that's what this guy did: https://github.com/achirkin/easytensor/blob/master/easytensor/test/Spec.hs
19:19:36 <rotaerk> wonder what that accomplishes
19:22:08 <rotaerk> eh, nm; I think he's just making it so each set of tests' results show separately, or something
19:23:02 <jkaye> Hi all, relatively new to Haskell - I'm looking for the best way to convert a data record to a Set
19:23:32 <rotaerk> jkaye, a set containing what
19:24:13 <jkaye> In this instance, tuples
19:24:14 <jkaye>  
19:24:43 <jkaye> I'm able to convert each field in the record to its corresponding tuple - I have a typeclass and instances for that
19:26:52 <rotaerk> can you link a paste of your record type, and give an example of such a set
19:27:07 <jkaye> Sure
19:27:51 <jkaye> I'm trying to turn this record: https://github.com/jkaye2012/hs-ipfs-api/blob/master/src/Network/Ipfs/File.hs#L17
19:28:16 <jkaye> Into this type: https://github.com/jkaye2012/hs-ipfs-api/blob/master/src/Network/Ipfs/Core.hs#L104
19:31:44 <rotaerk> jkaye, oh, you're wanting to turn your record type into what looks to be essential a map
19:32:09 <rotaerk> a mapping from a ByteString to a Maybe ByteString, where the key bytestring should correspond to the field name, and the Maybe ByteString should correspond to the value of the field ?
19:33:20 <rotaerk> (except where the map is represented as a set of key-value pairs, and thus technically could have multiple instances of the same key)
19:36:45 <jkaye> Yup - honestly, it might even make more sense for my intermediate representation to be a map instead of a set; I really just chose Set because it was most convenient for a first-pass implementation
19:37:03 <jkaye> But you have the gist of it
19:38:15 <jkaye> In my mind it's some kind of incremental building - almost like piping the operations together. Which I know I can do with do-notation and a Monad, but I just feel like there must be something already existing for this
19:38:22 <jkaye> So rolling my own Monad does not feel correct
19:38:50 <jkaye> And really part of the reason that I'm doing this project is to hopefully move from theoretical knowledge of functional programming into something more practically useful :)
19:40:10 <rotaerk> might be a way to do it more cleverly, but I'd just make a function that takes an AddFileOptions and returns a IpfsQuery, and build it explicitly
19:41:28 <freeman42x]NixOS> does anyone know of any Haskell minification thingie?
19:42:47 <buhman> isn't that just regular haskell ?
19:43:01 <rotaerk> jkaye, toSet (AddFileOptions { addFileRecursive, addFileQuiet, ... }) = Set.fromList $ IpfsQueryItem <$> [("addFileRecursive", if addFileRecursive then Just "" else Nothing), ("addFileQuiet", if addFileQuiet then Just "" else Nothing), ...]
19:43:41 <rotaerk> (can use a `Bool -> a -> Maybe a` function to eliminate the repetitive if-thens)
19:44:50 <Mrbuck> https://www.sas.upenn.edu/~jesusfv/comparison_languages.pdf   I am reading this and not nderstanding anything
19:45:06 <Mrbuck> so they say haskell good language for economics or not ?
19:46:23 <jkaye>  Yeah, something like that does seem easiest and not too much boilerplate or anything
19:46:31 <jkaye> I'll stick with that for now
19:46:35 <jkaye> Thank you for taking a look!
19:46:54 <rotaerk> Mrbuck, haskell is a great general purpose language.  if you want to know if it's "good for economics", that's really just a question about the quality of its libraries specific to that domain; so check if there are any libraries suiting your need
19:48:16 <rotaerk> jkaye, if you find yourself needing to convert lots of records into sets ... you'll need to use something more general
19:48:24 <maerwald> Mrbuck: that paper has the word Haskell exactly once and no proper comparison afais
19:48:25 <rotaerk> I've never really done that before, but Generics come to mind
19:48:33 <maerwald> so how did you come to the conclusion it might be good for economics?
19:48:33 <Mrbuck> rotaerk:  i think none ? I am not economics guy just found above paper and trying to understand what he said
19:49:51 <ion> jkaye: If you want to define a mapping function from each value type to ByteString and automate the conversion, GHC.Generics might be useful.
19:49:59 <Mrbuck> maerwald:  I feel none of the economists know programming or Haskell level programming
19:50:20 <maerwald> No idea, I just don't see any reasonable indication from the paper that haskell is particularly suited
19:50:23 <Mrbuck> even cs graduates dont now haskell or heard of it
19:50:28 <maerwald> C++ and Python (Cython) seem fine though
19:50:29 <rotaerk> they can program in Excel formulas - that counts !1
19:50:40 <maerwald> according to the paper
19:54:39 <rotaerk> cocreature, hmm, just noticed that with that .ghci approach to working with ghcid you suggested, it's ignoring the test-suite clause of my cabal file
19:54:50 <rotaerk> so I can't seem to add build-depends to it
19:59:45 --- mode: glguy set +v dd7
20:02:16 <dd7> Hi, is there a way to "undefine an instance"? I'm following along with tutorials and was trying to define Functor instances for things like [] and Maybe. It doesn't compile because those are already defined in Prelude Base. (New to haskell, it's quite possible what I'm doing doesn't make sense)
20:02:37 <jkaye> rotaerk: Ended up with this https://github.com/jkaye2012/hs-ipfs-api/blob/master/src/Network/Ipfs/File.hs#L71
20:02:51 <jkaye> Thanks again
20:03:02 <rotaerk> np
20:05:49 <ion> dd7: One option is to define your own List and Maybe types for this exercise. data MyMaybe a = MyNothing | MyJust a deriving Show; data MyList a = Nil | a ::: MyList a deriving Show
20:06:45 <ion> @tell dd7 One option is to define your own List and Maybe types for this exercise. data MyMaybe a = MyNothing | MyJust a deriving Show; data MyList a = Nil | a ::: MyList a deriving Show
20:06:45 <lambdabot> Consider it noted.
20:11:46 * hackage witherable 0.3 - filterable traversable  http://hackage.haskell.org/package/witherable-0.3 (FumiakiKinoshita)
20:18:38 <Shockk> :i (<$>)
20:18:50 <Shockk> @info (<$>)
20:18:50 <lambdabot> (<$>)
20:18:53 <Shockk> thanks a lot
20:19:16 <Shockk> is that just because I had brackets around it?
20:19:20 <Shockk> @info <$>
20:19:20 <lambdabot> <unknown>.hs:1:1:Parse error: <$>
20:23:51 <geekosaur> @info isn't a thing (it uses edit correction to find @undo)
20:23:51 <kadoban> Shockk: lambdabot doesn't actually have :i  and @info only works because of a corner case of its type handling. (it's actually doing  @undo, note that the n and the o match)
20:23:51 <lambdabot> <unknown>.hs:1:54:Parse error in expression: find@undo
20:24:08 <Shockk> ohhh okay
20:24:12 <Shockk> fair enough
20:24:20 <kadoban> typo* handling. I typoed the word typo ... *sigh*
20:24:39 <clever> i want to write some code like this, with a custom Monad, https://gist.github.com/cleverca22/86d6295319a9c13ff3db22483de8bf09 , what type should it have, how would i write the `when` and `getConfig` type functions, and is there a guide on how to do these kinds of things?, the main `Example` monad can be pure, its simply to generate an AST and some lists, which IO will later handle
20:25:20 <geekosaur> you can get :info output from yahb. you should use %% instead of % so it sends the output to a pastebin, since it can be fairly large
20:25:35 <geekosaur> %% :info (<$>)
20:25:35 <yahb> geekosaur: http://qp.mniip.com/y/39
20:26:39 <geekosaur> not so much here, btu if it starts listing typeclass instances it can go on a bit
20:29:45 <Shockk> I have a kind of obscure problem but basically I'm using attoparsec to build a parser for my programming language
20:30:48 <Shockk> my grammar basically defines an expr (which can be a branch or a compound), a compound (which can be an operation or a primary), a primary (which can be an identifier or a literal),
20:30:59 <Shockk> a branch which is: compound ? expr : expr
20:31:20 <Shockk> and finally an operation which is: primary <valid operator char> expr
20:32:09 <Shockk> so when I try and parse the following:   1 > 0 ? 10 : 5
20:32:47 <Shockk> it goes to parse a branch, which tries to parse a compound, which tries to parse an op, which first parses the 1 and the <
20:33:04 <Shockk> and then the rhs of the op actually parses the entire rest of the branch, as:  0 ? 10 : 5
20:33:51 <Shockk> and once the parser fails to parse the *outer* branch that it was originally trying to parse (as there's no input left obviously), it then ends up parsing it as an operation anyway
20:33:51 <geekosaur> you probably want to consider supporting operator precedence
20:34:12 <Shockk> ah, so I need to use precedence to handle this, as opposed to the grammar?
20:35:13 <geekosaur> you can do ti in the grammar but must factor it so ? isn't part of what it's parsing there.
20:35:27 <Shockk> hmm I see
20:36:01 <geekosaur> so expr is a branchexpr or a simplexpr, and parsing aftr > takes a simplexpr instead of expr
20:36:59 <geekosaur> precedence support is nicer though because it makes the parser framework do the work and you can write things more naturally instead of having to track precedence by which kind of expr you parse
20:37:16 * hackage multipool-persistent-postgresql 0.1.1.0 - Read and write appropriately from both master and replicated postgresql instances.  http://hackage.haskell.org/package/multipool-persistent-postgresql-0.1.1.0 (IanDuncan)
20:37:42 <Shockk> right, I mean I do want precedence support but I feel like I'm going to have a bigger headache if I try and redo the way I'm handling branch parsing to make them operators instead
20:37:57 <geekosaur> which becomes painfl if you also want it to handl;e 4 + 6 * 10 the way people expect it to
20:38:08 <geekosaur> because now you need a differet kind of expr for + vs. *
20:38:39 <Shockk> yep, I've hit that problem too but intend to do precedence for it
20:38:55 <geekosaur> yeh, if you want it to be custom yntax instead ofopertors, you want to distinguish that from expressions
20:39:18 <geekosaur> optionaly allowing it in a parenthesized expression
20:39:21 <Shockk> I suppose I could do it so that x ? y returns some intermediary thing that can then be used as a first operand to :
20:40:09 <Shockk> oh I just realized, so would all I have to do, be to change my operation parser to like
20:40:23 <Shockk> <primary> <operator> <simpleExpr> (where simpleExpr is as you described)?
20:40:47 <geekosaur> something like that, yes
20:40:50 <Shockk> because thinking about it, I think operators are the only situation in my grammar where this issue can come up right?
20:41:36 <Shockk> actually I could just use compound in that case, since expr is only branch | compound
20:41:40 <geekosaur> probably. ideally it should be the oly place, because that kind of thing s problematic in general; but peple like their math operators to behave the way they learned them (as with * vs. +)
20:41:56 <Shockk> right
20:42:27 <geekosaur> parser generators talk about shift/reduce and reduce/reduce conflicts; this is part of what they mean
20:42:33 <Shockk> I don't intend to implement additive or multiplicative parsers or whatever, I'm definitely going to just rebuild the parts of the tree after precedences are known
20:43:05 <geekosaur> (shift/reduce often isn't a problem; reduce/reduce should tell you that ou ave an ambiguous grammar and need to rethink it)
20:43:15 <Shockk> hmm what does reduce/reduce mean?
20:43:29 <geekosaur> it doesn't know which parse rule to use
20:43:45 <Shockk> ah right
20:44:26 <geekosaur> wheres shift/reduce means e.g. you allow a list of expressions and it has to decide on seeing the comma whether to keep going or stop; it will defalt to keeping going, which is what yougenerally want, and designing aaround that kind of "conflict" is fiddly and makes the grammar noisy
20:45:51 <Shockk> hmm I see
20:46:27 <Shockk> ooooh it worked
20:46:28 <Shockk> great
20:46:32 <Shockk> thanks a lot 
20:47:16 <Shockk> only had to change 3 words in my code base for it to change everywhere as well :D
20:56:22 <Shockk> geekosaur: in case you're curious about what I'm working on; this now works thanks to your help :D 
20:56:24 <Shockk> https://gist.github.com/shockkolate/d953c409eb9eb1e08d2daeeb7f6a39c6
21:08:38 <rotaerk> really not clear on why GHCID seems to be designed under the assumption that your tests are directly in the library being tested...
21:09:46 * hackage extensible-effects-concurrent 0.14.0 - Message passing concurrency as extensible-effect  http://hackage.haskell.org/package/extensible-effects-concurrent-0.14.0 (SvenHeyll)
21:14:40 <rotaerk> hexagoxel, that --run flag to ghcid doesn't exist anymore.  did that do what --setup does?
21:15:11 <rotaerk> or maybe it's new and I have an old ghcid
21:16:39 <rotaerk> ah yeah... it's really new... I'm one minor version behind
21:17:43 --- mode: glguy set +v eric88
21:18:11 <eric88> Is there any way to build multiple executables?
21:18:40 <eric88> I keep getting the "Warning: output was redirected with -o, but no output..." from `stack build`
21:39:09 <kadoban> eric88: Any other warnings? Does it actually perform incorrectly, or is there just the warning?
21:40:19 <eric88> There's just the warning.
21:40:33 <eric88> I don't think it compiles completely... let me doublecheck
21:41:50 <eric88> Yeah it just dies once the compiler complains.
21:42:51 <eric88> I'm fiddling around with the `executables` section of the `package.yaml` but I'm not sure which next sources to consult.
21:45:23 <eric88> And it looks like the `executable` sections of the .cabal are a-ok
21:46:25 <vlatkoB> Is it possible to make stack behave like "yesod devel", something like "stack run --file-watch"?
21:50:31 <kadoban> eric88: Maybe run it verbose, see what command it's actually executing or if there's extra warnings/errors ?
21:51:17 <kadoban> vlatkoB: I don't know yesod devel, what does it do differently compared to --file-watch
21:53:17 <vlatkoB> nothing, simply "stack run --file-watch" is invalid, but that is what I need. Rebuild and run on file change.
21:55:29 <kadoban> vlatkoB: There's the --exec "some-executable" flag to 'stack build --file-watch'
21:58:11 <vlatkoB> I did try that, but it is not rebuilding. Probably because "some-executable" is a web server and it never ends. 
21:58:11 <eric88> kadoban: I will run in verbose and return with more info
21:59:00 <kadoban> vlatkoB: Hm, possibly. You could write a little wrapper than starts the webserver in the background, and kills the existing one first
21:59:06 <eric88> Having started with a clean `stack new`, the error is narrowed down to changing the name of the `main` field under `executables` in `package.yaml`
21:59:20 <eric88> When it's not named `Main.hs`, the build-script complains.
21:59:26 <eric88> Is this standard behavior?
22:00:24 <vlatkoB> @kadoban Yes, I know. Just thought maybe there is some stack magic do that. I think I saw somewhere a combination with ghcid, but can't find it anymore. :-(
22:00:24 <lambdabot> Unknown command, try @list
22:01:04 <kadoban> eric88: Doesn't sound likely. Did you change everything to match, the filename and uhm ... what's the module statement in the file?
22:02:02 <eric88> `module MyModule where`
22:02:09 <eric88> in `MyModule.hs`
22:02:33 <kadoban> Hmmm. I wonder if it's still supposed to be Main
22:02:46 <eric88> This stackoverflow describes similar behavior: https://stackoverflow.com/questions/50818254/cant-define-multiple-executables
22:03:28 <eric88> Mm no it's not still supposed to be "Main", the compiler gives a "Found ... Expected" error that's comprehendable.
22:03:39 <eric88> Or, I mean, I can read that error at least :P
22:04:18 <kadoban> Unfortunate. That's the only guess I had, sorry.
22:07:17 <eric88> Dang. Well, I will update with progress should there be any.
22:11:54 <rotaerk> cocreature, hexagoxel, got it working how I'd like, with one ghcid instance.  here's my .ghcid file: -c "cabal new-repl" --test=":!cabal new-test" --warnings --reload=test --restart "ktx-rw.cabal"
22:12:40 <rotaerk> basically, don't need to load the test package, just need to run cabal new-test whenever my main library's build passes, or if the code in the test/ folder changes
22:13:52 <rotaerk> so not limited by cabal new-repl's "one package only" constraint
22:17:51 <eric88> kadoban: the solution was creating multiple subdirectories in the `app` dir
22:19:14 <eric88> then renaming both top level modules to `app/subd1/Main.hs` and `app/subd2/Main.hs`
22:19:16 * hackage text-ansi 0.1.0 - Text styling for ANSI terminals.  http://hackage.haskell.org/package/text-ansi-0.1.0 (mitchellwrosen)
22:35:17 * hackage Win32 2.8.1.0 - A binding to Windows Win32 API.  http://hackage.haskell.org/package/Win32-2.8.1.0 (TamarChristina)
22:37:04 <kadoban> eric88: Oh, weird. That didn't used to be necessary
23:07:49 <Shockk> quick question; what exactly are the differences between MonadModuleBuilder and MonadIRBuilder, in llvm-hs-pure?
23:08:26 <Shockk> I mean, I understand that I can only use each in different circumstances
23:08:48 <Shockk> what I'm wondering is what those circumstances are, and why the two are required, as opposed to a single monad
23:12:06 <opqdonut> Shockk: it looks like they're both State monads, but with different state types: ModuleBuilderState and IRBuilderState
23:12:31 <Shockk> I'm also wondering if, due to those differences, there's any way to add a new function to the current module from inside a function builder function, or if I have to either do another pass over my AST beforehand / return the information out of the function builder
23:12:38 <Shockk> opqdonut: ah right
23:13:07 <opqdonut> I'm not familiar with the library itself, I just glanced over the docs
23:15:38 <opqdonut> hmm so you're taking about this: http://hackage.haskell.org/package/llvm-hs-pure-7.0.0/docs/LLVM-IRBuilder-Module.html#v:function
23:15:52 <opqdonut> it doesn't look like you can escape from the Functio body builder. You need a second pass
23:16:21 <opqdonut> no, wait, the monad in the function builder is: MonadModuleBuilder m => IRBuilderT m ()
23:16:33 <opqdonut> so you should have both ModuleBuilder and IRBuilder functionality available
23:16:37 <opqdonut> as it's a stack of both monads
23:16:56 <Shockk> wait hmm 
23:17:27 <opqdonut> use liftModuleState
23:17:39 <Shockk> ohhh huh I see
23:17:44 <Shockk> not sure how I missed that
23:17:46 <Shockk> great thanks
23:18:03 <opqdonut> it's quite an oldschool monad transformer stack api, those are always a pain to navigate...
23:18:15 <MasseR> Is there a channel for ghcjs and/or miso related questions?
23:22:37 <cocreature> MasseR: there is #ghcjs but it’s pretty quiet. for miso there is a slack
23:22:51 <koz_> What's miso?
23:24:19 <MasseR> koz_: a web framework over ghcjs
23:24:26 <koz_> MasseR: Ah, OK.
23:38:26 --- mode: glguy set +v rckd
23:38:48 --- mode: glguy set -v rckd
23:54:46 * hackage servant-pagination 2.1.3 - Type-safe pagination for Servant APIs  http://hackage.haskell.org/package/servant-pagination-2.1.3 (KtorZ)
23:56:16 * hackage slave-thread 1.0.3 - A fundamental solution to ghost threads and silent exceptions  http://hackage.haskell.org/package/slave-thread-1.0.3 (NikitaVolkov)
