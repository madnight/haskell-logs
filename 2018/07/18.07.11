00:00:31 <pally> :t [1.3, 3]
00:00:33 <lambdabot> Fractional a => [a]
00:01:06 <pally> My question would be what makes ghc decide it to go with Fractional a => [a]
00:01:13 <pally> and not Integral a => [a]
00:01:35 <glguy> Because 1.3 had a decimal, it's a floating point literal
00:01:43 <romanix> Hi Guys! Anyone familiar with Accelerate (http://hackage.haskell.org/package/accelerate) and Cuda? I'm playing with the examples trying to run them on the GPU with --llvm-ptx but I get the following exception/crash: accelerate-tunnel: LookupTargetException ": error: unable to get target for 'nvptx64-nvidia-cuda', see --version and --triple.\n"
00:02:42 <glguy> :t fromRational
00:02:44 <lambdabot> Fractional a => Rational -> a
00:03:10 <glguy> Those kinds of literals turn into uses of fromRational
00:03:23 <Ariakenom> > [1.3, 3] :: [Rational]
00:03:26 <lambdabot>  [13 % 10,3 % 1]
00:03:46 <mniip> hmm, if I have an [(Int, Int)] digraph edge list, what would be a neat way to obtain a graph condensation
00:04:04 <Ariakenom> not just >floating point< literals
00:04:31 <quicksilver> yeah I was about to say, with a really pedantic hat on, it's probably better to call them decimal literals or rational literals :)
00:05:00 <Athas> romanix: does it work with --llvm-cpu?
00:05:23 <vaibhavsagar> mniip: tarjan's algorithm?
00:05:42 <vaibhavsagar> what format do you want the condensation in?
00:06:14 <mniip> not sure it's really the condensation I want
00:08:07 <ahri_> I had a function `applyEvent :: Tools a -> a -> Event -> Either Error a` and I was folding over multiple events via `applyEvents :: Tools a -> a -> [Event] -> Either Error a; applyEvents tools = foldM (applyEvent tools)`, but now I've altered `Tools` from `Tools a` to `Tools m a` (aside: maybe Tools should be called DatabaseTools). I've changes `applyEvent` to be `applyEvent :: Tools m a -> a -> Event -> m (Either Error a)` but I'm st
00:08:22 <pally> > 13 % 10
00:08:24 <lambdabot>  13 % 10
00:08:32 <[exa]> evil.
00:09:43 <cocreature> ahri_: I think your message might be cut off at the end but it looks like ExceptT is probably worth a look
00:11:55 <ahri_> cocreature: ah, ok, and that's because I'm wanting to stack up 2 monads, one of which is `Either`?
00:12:37 <ahri_> (shouldn't it be `EitherT` I look at?)
00:12:49 <cocreature> ahri_: ExceptT e m a wraps "m (Either e a)" and gives you a Monad instance that combines the shortcircuiting behavior of Either with the Monad instance of "m"
00:13:18 <cocreature> "ExceptT" is exactly what you would expect EitherT to be but it’s in the transformers lib which you almost certainly already depend on
00:13:32 <cocreature> the reasons for why we have EitherT and ExceptT are mostly historical
00:14:24 <ahri_> ah hah! slightly confusing, but very useful nonetheless :) I will read up - thank you very much for the pointer
00:18:57 <glguy> You can keep you pedant hat on and call them floating literals like the report does
00:20:36 * hackage speechmatics 0.7.1.0 - Speechmatics api client  http://hackage.haskell.org/package/speechmatics-0.7.1.0 (Jappie)
00:23:51 <ZeuPiark> hello
00:25:51 <quicksilver> glguy: I could. But especially with the hat on I like to disagree with the report. Maybe it's a hobby :) It's certainly not hugely productive.
00:31:26 <romanix> Athas, Sorry, I was afk. Yes, it does work with --llvm-cpu
00:40:36 * hackage language-puppet 1.3.19.1 - Tools to parse and evaluate the Puppet DSL.  http://hackage.haskell.org/package/language-puppet-1.3.19.1 (SimonMarechal)
01:14:46 <mniip> can I hyperlink an identifier from the cabal description field?
01:15:23 <gentauro> so I "upgraded" my Qubes 3.2 => Qubes 4.0 (which equals a re-install with format and stuff)
01:15:44 <gentauro> I have now a "clean" box (oh it feels great) and I'm trying to install "Elm"
01:16:02 <gentauro> since I just want to use "stack" (downloaded it with curl)
01:16:14 <gentauro> I noticed that "Elm" requires cabal to be installed
01:16:25 <gentauro> I did the "stack install cabal-install"
01:16:53 <gentauro> and now I have caban in my "~/.local/bin" folder, thx to stack
01:17:20 <sclv> mniip: you can use a normal
01:17:31 <gentauro> when I run the Elm build script (BuildFromSource.hs) I get some strange stuff
01:17:41 <sclv> hyperlink but there’s no special syntax
01:17:48 <gentauro> it builds actually, but doesn't create any bin folder :|
01:18:00 <gentauro> which makes the build process pretty useless :D
01:18:23 <gentauro> have anybody else had some issue with this combination? (cabal installed by stack with cabal-install)?
01:18:51 <sclv> gentauro: have you checked ~/.cabal/bin ?
01:21:19 <leptonyu> exit
01:23:13 <gentauro> sclv: yes, there is no bin folder neither :(
01:24:47 <cocreature> gentauro: according to the instructions and the source code, things should be installed in .cabal-sandbox/bin
01:24:48 <sclv> gentauro: ah it says it instals it in thr sandbox’s bin?
01:25:20 <gentauro> sclv: cat cabal.sandbox.config ->
01:25:26 <gentauro> install-dirs
01:25:36 <gentauro> prefix: /home/user/scripts/elm/Elm-Platform/0.18/.cabal-sandbox
01:25:46 <gentauro> bindir: $prefix/bin
01:25:50 <gentauro> but no such bin folder ...
01:25:55 <gentauro> kind of strange
01:27:02 <pie_> glguy, which hackage library actually supplies 'everywhere'? doesnt seem to be in Data.Data or Data.GMap
01:27:39 <pie_> Ah. I'm not used to thinking of reaching for hoogle yet. It's in Data.Generics.Schemes.
01:33:16 <Ariakenom> :t [minBound .. maxBound]
01:33:17 <lambdabot> (Enum a, Bounded a) => [a]
01:34:09 <mniip> hmm
01:34:28 <mniip> if I had    foo :: C a => (C a => A) -> B
01:34:38 <mniip> and then I made it   foo :: C a => A -> B
01:34:46 <mniip> does that look like a breaking API change worth a major revision
01:35:14 <mniip> in all cases I can think of the solver can solve around it
01:43:07 <pie_> Profpatsch, oh! yay! it looks like the javascript stuff already uses  {-# LANGUAGE DeriveDataTypeable #-}  , i dont know why their source code looked like it didnt use it (cant rememebr what i was looking at)
01:43:54 <Taneb> mniip: that's a weird type to have to start with
01:44:32 <mniip> Taneb, the actual type is a tad more complicated of course
01:45:07 <mniip> it doesn't fit on one line in haddock even
01:46:13 <Taneb> Those are the best types ;)
01:46:51 <mniip> I'll do a minor version bump
01:47:19 <mniip> literally any call  'foo f' that would have elaborated to 'foo @d f' would now just simply elaborate to 'foo @d (f @d)'
01:51:06 <dataN> is there a version of "foldable alternatives are monads" involving distributive and comonads?
01:55:02 <Profpatsch> pie_: Awesome.
01:56:01 <dataN> could need maybe something like split of comonoid but over types of kind * -> *
01:56:24 <dataN> coalternative?
02:00:12 <mupf> Saizan: wtf?
02:01:47 <lavalike> mupf: topic
02:03:07 <pie_> why do university cs pages always end up dead links. http://web.archive.org/web/20151121203336/http://web.archive.org:80/web/20080622204226/http://www.cs.vu.nl/boilerplate
02:03:25 <pie_> archive.org++
02:07:53 <pie_> Profpatsch, Whoa! That was easy! https://bpaste.net/show/c2e50c662745
02:08:48 <pie_> hm. missed a spot. "this.n".
02:10:06 * hackage interprocess 0.2.0.1 - Shared memory and control structures for IPC  http://hackage.haskell.org/package/interprocess-0.2.0.1 (achirkin)
02:14:08 <mniip> pie_, wow that's like double dead
02:14:28 <pie_> mniip, hm? :p
02:14:59 <pie_> mniip, oh the link
02:15:07 <mniip> it looked like the first web.archive link was dead so you added on a second one :p
02:15:13 <pie_> oh what lol
02:15:19 <pie_> lmao
02:15:45 <pie_> not sure what happened there
02:16:43 <haasn> dataN: "foldable alternatives are monads" -> wait, what does this mean?
02:17:43 <haasn> instance (Foldable f, Alternative f) => Monad (WrappedApplicative f) where ... ?
02:18:35 <mniip> join = foldr (<|>)
02:18:47 <mniip> join = foldr (<|>) empty
02:19:09 <mniip> [] is one such monad
02:20:10 <mniip> alongside with Maybe
02:20:25 <mniip> any of the three Alternatives that arise from Maybe works
02:20:36 * hackage deferred-folds 0.5.1 - Abstractions over deferred folds  http://hackage.haskell.org/package/deferred-folds-0.5.1 (NikitaVolkov)
02:20:45 <mniip> two*, I guess
02:20:48 <haasn> Can you prove the monad laws?
02:22:37 <haasn> I'm not sure if Foldable's laws are strong enough for that
02:23:03 <haasn> I think you can write a legal Foldable instance for [] which ignores some or all elements?
02:23:14 <haasn> e.g. folding over ever second term only
02:23:47 <mniip> true, some coherence between the Alternative and Foldable is required
02:24:06 * hackage speechmatics 0.7.2.0 - Speechmatics api client  http://hackage.haskell.org/package/speechmatics-0.7.2.0 (Jappie)
02:24:11 <mniip> namely  foldr f z (pure x) = f x z
02:24:12 <haasn> well they're both somehow connected to Functor
02:24:17 <mniip> foldr f z empty = z
02:24:18 <haasn> but yeah that law is required
02:24:38 <haasn> although folding over every second instance would still satisfy that law, but maybe not the other ones
02:24:38 <mniip> foldr f z (a <|> b) = foldr f (foldr f z b) a
02:24:49 <haasn> yes that one is required I think
02:24:58 <mniip> with these three I think the monad laws are ok
02:25:04 <haasn> seems sensible
02:26:08 <Taneb> Is that equivalent to foldMap f (a <|> b) = foldMap f a <> foldMap f b?
02:26:44 <shachaf> There are reasonable Foldable+Alternative instances that don't satisfy these laws, though.
02:26:51 <Taneb> Maybe doesn't
02:26:54 <Taneb> (for example)
02:27:21 <shachaf> I think saying these things is less a statement about Foldable (which doesn't really have laws, it can do whatever it wants) and more about the Monad instance you're trying to get.
02:27:39 <shachaf> Might as well write that instance directly.
02:27:52 <mniip> hmm
02:28:11 <mniip> Maybe doesn't satisfy the last law
02:28:15 <Taneb> Yeah, neither Alternative nor Foldable have any laws you can really rely on
02:28:17 <mniip> but it produces a valid Monoid
02:28:53 <mniip> er
02:28:54 <mniip> Monad
02:28:54 <haasn> pure a >>= f = f a  <->  foldr (<|>) empty (fmap f (pure a)) = f a  <->  foldr (<|>) empty (pure (f a)) = fa  <->  pure (f a) = f a  <-> f a <|> empty = f a  <->  f a = f a
02:28:58 <haasn> first monad law proven
02:29:24 <haasn> with the extra laws required by mniip
02:29:49 <shachaf> Taneb: Alternative is at least a monoid, which is pretty good.
02:30:33 <ccapndave> Hey everyone - I'm actually writing something in Elm, not Haskell, but I think the general principles might be the same so I wanted to ask here.  I am trying to make a Tree structure, with a specific number of levels such that each level of the tree has a different data type *or* is a leaf.
02:30:52 <shachaf> (It's a monoid in the category of endofunctors!)
02:30:57 <mniip> ccapndave, sounds like type-level lists
02:31:02 <shachaf> (Just like Applicative and Monad.)
02:31:11 <ccapndave> https://gist.github.com/ccapndave/a1041abaeeeff8db4c351af19574b054
02:31:15 <Taneb> (what isn't a monoid in the category of endofunctors these days)
02:31:30 <mniip> shachaf, over the curried monoidal structure in the underlying category?
02:31:32 <shachaf> A MonadPlus is a monoid in the category of endofunctors with three different tensor products.
02:31:42 <shachaf> Curried?
02:31:46 <ccapndave> This does it, but without fulfilling the requirement that there can be a leaf at any level
02:31:52 <mniip> (F (x) G)(A) = F(A) (x) G(A)
02:32:10 <shachaf> Yes, that one.
02:32:29 <mniip> does being a monoid over that really imply being a monoid over day convolution?
02:32:42 <shachaf> Where did Day convolution get involved?
02:32:47 <cocreature> ccapndave: I’m not sure the Haskell solution here is translatable to Elm tbh. I would use fairly advanced features of Haskell’s type system here and afaik Elm’s type system is a lot simpler
02:32:52 <mniip> applicative as a monoid?
02:33:01 <shafox> How do I write a parser for this grammar: https://gist.github.com/shadow-fox/677cc89445b65ef0cec6a3c8d87cc9cb
02:33:06 <ccapndave> cocreature: Yeah, it doesn't have anything fancy (I wish it did :( )
02:33:17 <shachaf> Oh, sure, Day convolution of that gives you Applicative.
02:33:27 <shachaf> But if you just use that directly you get Alternative.
02:33:28 <ccapndave> I'm searching for a way to do it with your basic ML features.  It doesn't matter if its boilerplatey
02:33:40 <dataN> if the laws for monad are to be satisfied by a foldable alternative, then it is traversable as the traversable laws imply length is preserved.
02:33:55 <ccapndave> i.e. it doesn't need to be a solution for any depth tree; I'm fine re-implementing it (or code generating it) for different depths.
02:34:24 <mniip> ccapndave, does elm have gadts
02:34:28 <cocreature> ccapndave: what would a leaf look like? is there a separate type for the data stored in leafs or no data at all?
02:34:44 <ccapndave> mniip: I'm not sure what that is, so I'm going to say no...
02:34:49 <dataN> sorry, traversable is sufficient but not necessary
02:34:52 <ccapndave> cocreature: Leafs have their own datatype as well
02:35:02 <mniip> data D a where C :: D Int
02:35:17 <mniip> as the declaration says, C :: D Int
02:35:23 <mniip> foo :: D a -> a;  foo C = 123
02:35:27 <Taneb> mniip: Elm doesn't have GADTs
02:35:33 <mniip> valid because pattern matching on C reveals that a ~ Int
02:35:36 <ccapndave> No, I've never seen anything like that in Elm
02:35:39 <mniip> GADTs in a nutshell
02:35:44 <dataN> and it is this use of traversable that motivates interest in distributive for the contrariwise version
02:36:18 <mniip> Taneb, typeclasses? type families? mptcs/fundeps?
02:36:42 <ccapndave> mniip: Nope
02:36:49 <mniip> :(
02:36:59 <ccapndave> Although to be fair I don't know what the last two are
02:37:15 <cocreature> ccapndave: you can probably do something like https://gist.github.com/cocreature/25029e15dd1669f43821db5cc2890896 but that’s kind of horrible
02:37:21 <Taneb> mniip: none of those
02:37:34 <Taneb> mniip: Elm is like Haskell without any of the fun bits
02:37:50 <mniip> haskell98 then
02:37:57 <cocreature> not even that
02:38:02 <cocreature> haskell98 has typeclasses
02:38:05 <Taneb> Elm is like Haskell98 without any of the fun bits
02:38:33 <ccapndave> cocreature: That looks reasonable, except as you say its kind of horrible that we need separate type constructors for each leaf
02:38:33 <ccapndave> But it will work
02:38:50 <ccapndave> Elm is great for learning why you need more advanced functional features :)
02:39:06 <shachaf> Are there any other good tensor products for the category of endofunctors?
02:39:08 <ccapndave> And to be fair its pretty great for building webapps up to a certain point of complexity
02:39:16 <ccapndave> Then it becomes less great
02:39:43 <ccapndave> cocreature: Do you reckon that is the only possible implementation for this
02:39:44 <ccapndave> ?
02:39:55 <ccapndave> I have tried many and that looks like the only one that will actually compile
02:40:03 <ccapndave> (Thanks very much, btw :) )
02:42:38 <cocreature> ccapndave: I don’t know any Elm so maybe it has some clever feature up its sleeve that would help here but in Haskell98 I don’t know another solution
02:43:02 <cocreature> in modern Haskell you could use a GADT and parametrize your Tree type by a list of types
02:43:03 <ccapndave> You can assume there are no clever features :)
02:43:10 <ccapndave> That sounds wonderful :(
02:43:13 <dataN> unfoldable gives comonad so maybe coalternative (kind * -> * monoid) gives unfoldable and distributive extends this to satisfy the laws...
02:43:51 <ccapndave> cocreature: And in my research I found that in Ocaml I could use a module functor to create a module based on other modules
02:44:07 <ccapndave> Well, nothing to do about it.  At least this a possible solution.  Thankyou very much indeed!
02:44:31 <cocreature> ccapndave: that said, this kind of heterogenous data structure often tends to be fairly unwieldly (even if defining it is not that hard in modern Haskell) so often finding a way to avoid it is a better solution
02:44:40 <ManDay[m]> I want to implement a heavy algorithmic mechanism which is also computationally heavy in either Scheme or Haskell and I'm worried that Scheme's eager-and-ordered evaluation prevents natural parallelism while Haskell would automatically parallelize everything as far as logically possible. Can anyone comment on that suspicion?
02:45:07 <cocreature> ManDay[m]: Haskell doesn’t do automatic parallelization
02:45:16 <dataN> extend = unfold = repeat..
02:45:28 <ccapndave> cocreature: There is a way to avoid it; use a normal recursive tree and have one union type for branches, and then a type for the leaves
02:45:32 <cocreature> (and before someone starts being pedantic, GHC doesn’t and nobody cares about other implementations)
02:45:48 <ccapndave> cocreature: But then I have no guarantee of what is at any level so I'm going to have case statements and Maybes littered through my codebase
02:45:48 <ManDay[m]> cocreature: Not at all? So f(g(x),h(y)) would not automatically parallel evaluate g() and h() ?
02:47:01 <Taneb> ManDay[m]: no Haskell implementation can determine whether evaluating g and h in parallel is worth spinning up a new thread
02:47:14 <dataN> cant find Curried anywhere...
02:47:39 <Taneb> Automatic parallelization is an open research problem that by-and-large stopped a long time ago due to infeasibility (although I am aware of some more recent research)
02:48:40 <dataN> Taneb: accelerate achieves this easily
02:49:00 <ccapndave> cocreature: I suppose another possibility is to make the data property a union type of BranchData and LeafData and then just have an empty array for children
02:49:14 <ManDay[m]> Taneb: Okay, fair point: The overhead of parallelization cannot be weighted against the load of the calculation. But that seems to be the "only" missing piece of the puzzle, so is there the next-best-thing as easy as telling Haskell that it *is* indeed worth it, like so f(g~thats_some_heavy_stuff(x),h~that_too(y)) ?
02:49:20 <cocreature> ccapndave: I was more thinking of larger changes, e.g., sometimes you can convert data to a common type when you put it into a data structure rather than when you extract it and thereby sidestep the need to store heterogenous data. but there is no general approach here, it heavily depends on the specifics of your application
02:49:21 <ccapndave> If everything is wrapped up in an opaque module then I can (try!) to enforce rules so that things don't get out of sync
02:49:47 <Taneb> dataN: accelerate is not a general solution by any means, it's really quite specialized
02:50:03 <hso> how to generate haskell stack project binaries in perticular folder?
02:50:10 <ccapndave> cocreature: Sure
02:50:24 <Taneb> ManDay[m]: have you read the parallel chapters of Simon Marlow's book Parallel and Concurrent Programming in Haskell? It's a good read and I think the ebook is free
02:51:27 <ManDay[m]> No I haven't. I haven't done anything practical in Haskell yet. I'm just wondering (because of those reasons) whether it would be much easier to obtain a certain amount of automatic-parallelization than no-parallalization-at-all in scheme.
02:51:52 <Taneb> There's fairly easy manual-parallelization
02:52:59 <ManDay[m]> Still better than Scheme, I guess ;-/
02:53:28 <ManDay[m]> Just not sure how much of functional beauty is left than - compared to an implementation in an another language
02:53:39 <ManDay[m]> s/than/then
02:54:19 <dataN> bindings can be used to foreign libraries such as CUDA
02:54:41 <dataN> do you need a pure interface?
02:54:47 <Taneb> ManDay[m]: the functional beauty is what makes the parallelization possible
02:55:09 <Taneb> dataN: I think ManDay[m] is after a different type of parallelization, the kind the library "parallel" exposes
02:56:10 <dataN> how is that different?
02:56:47 <Taneb> accelerate is great for doing the same operation on a huge amount of data
02:56:53 <ManDay[m]> dataN: I want as little explicit notion of parallelism in the code as possible.
02:57:18 <Profpatsch> pie_: Haha, very nice.
02:57:19 <Taneb> If you want to run two different, expensive functions in parallel, on a small amount of data (say, one value), accelerate is useless
02:57:58 <ManDay[m]> In essence, I know all my calculations are awfully heavy, and the dependency tree is mostly one-child only. So in practice, the parallel overhead wouldn't hurt.
02:58:09 <ManDay[m]> I understand that's not generally applicable, just saying in my case...
02:58:20 <dataN> because its for GPUs?
02:58:28 <Taneb> dataN: yeah
02:58:33 <ManDay[m]> (The dep-tree is one-child only for the non-heavy ops, that is ofc)
02:59:30 <dataN> how is OS threading not enough?
02:59:47 <Taneb> So for the example ManDay[m] wrote earlier, you can write "f ((g x, h x) `using` parTuple rpar rpar)"
02:59:49 <Athas> dataN: Accelerate is not auto-parallelisation.  The programmer specifies all parallelism.
03:01:14 <Athas> ManDay[m]: it is very easy to automatically execute Haskell in parallel, *but* hard to do it in order to obtain any kind of speedup.
03:01:56 <Athas> For example, as a naive approach, you can just have a bunch of background threads that wander the heap and evaluate any thunks they find.  Very parallel, but heavy on communication overhead, and are in practice just a bunch of background threads that mess up your cache.
03:02:17 <hso> how to generate binaries in perticular folder using haskell stack ?
03:02:28 <ggVGc> just had a lovely surprise when making a small simple embedded DSL. Apparently my "compiler" automatically goes dead code elimination because of laziness
03:02:37 <ManDay[m]> Athas: How is it done, set up Haskell to automatically execut in parallel? I'm confident that *if* Haskell does every possible parallelization, the speed-up would still be enourmous in my case, for the parts where the overhead outweighs the benefits are negligible.
03:02:41 <ggVGc> didn't even think about it when I started
03:03:05 <ggVGc> but I just put everything in a state monad, which turns out becomes dead code elimination when generating
03:03:13 <Athas> ManDay[m]: that thunk-thing was an experiment from long ago; it's not available anymore.  There is no automatic parallelisation in GHC, but there *is* very lightweight manual parallelisation via the 'par' combinator.
03:03:14 <romanix> ManDay[m], http://hackage.haskell.org/package/parallel
03:03:31 <ManDay[m]> Ok, thanks
03:03:37 <Athas> In practice, I think the Par monad is the best way of doing task parallelism in Haskell.  It's easy to use.
03:04:04 <Athas> The problem with the more powerful/flexible approaches (like that package) is that it's not always clear what to do in order to get good performance.  The Par monad is quite limited, but trivial.
03:04:30 <romanix> Athas, as always laziness gets in the way :)
03:04:47 <Athas> romanix: yeah, that too.  Par works around that by requiring NFData on the results of all parallel computations.
03:05:18 <Athas> Unfortunately, I think the early hope of functional programming enabling parallelism for free has been broken.
03:05:35 <JuanDaugherty> does distributed haskell use it (the Par monad)?
03:05:49 <Athas> JuanDaugherty: no, I don't think so.  Which distributed Haskell are you thinking of?
03:06:09 <romanix> Athas, what do you mean by the broken hope?
03:06:11 <JuanDaugherty> the one associated with the channel I'm about to join
03:06:26 <Athas> I once wrote a backend for Par that used Eden (a distributed Haskell dialect), which worked OK.  But the Par API does not expose the locality information you want to do efficient distributed programming.
03:07:08 <Athas> romanix: it clearly does not work as well as was hoped.  Parallel programming in a functional language is not that easier or different than parallel programming in other high-level languages.
03:07:11 <dataN> oh, i was confusing accelerate with improve, sorry
03:07:12 <JuanDaugherty> the one that squats a domain at github
03:07:42 <Athas> In the 80s and 90s, you could find lots of people hoping that pure functional programming is straightforward to execute in parallel, because order of evaluation does not matter.
03:07:53 <JuanDaugherty> "squat" may have been a poor choice of words
03:08:22 <Athas> Ah, Cloud Haskell?
03:08:25 <Athas> No, it does not use Par.
03:08:29 <JuanDaugherty> i believe so
03:08:39 <Athas> Par is only useful for multicore parallelism.
03:09:14 <JuanDaugherty> because it is limited to a single hs executable
03:09:20 <romanix> Athas, I'm not an expert but I think that it's still easier to make one's program parallel when using FP. Optimisation is another story of course.
03:09:51 <JuanDaugherty> (and runtime, i presume)
03:10:11 <mniip> why does the ambiguity check pass for type   (forall k. (KnownNat k) => q k) -> ()
03:10:15 <mniip> but not for   (forall k. (KnownNat k, k <= 0) => q k) -> ()
03:10:30 <JuanDaugherty> or a dynamically linked ipc family on the same machine
03:10:35 <dataN> is there a virtualisation for testing paralelisation strategies?
03:10:43 <Athas> romanix: yes, definitely, if you just want to keep a bunch of cores busy, FP works fine.  But if you want to achieve *speedup*, then it's not so easy.
03:10:44 <JuanDaugherty> (hopefully)
03:10:54 <mniip> does an equality constraint suddenly mess everything up
03:10:57 <Athas> FP makes *correct* parallelisation trivial, but *fast* parallelisation remains elusive.
03:11:23 <romanix> Athas, exactly
03:11:44 <Athas> On the other hand, FP is clearly a major success for *concurrency*.
03:12:51 <Athas> dataN: virtualisation?
03:13:06 * hackage bulletproofs 0.1.0 -   http://hackage.haskell.org/package/bulletproofs-0.1.0 (sdiehl)
03:13:17 <ManDay[m]> I think dependencies (and thus concurrency) are equally well detectable in any other language. I just thought the pure functional approach made leveraging it easier.
03:13:36 <dataN> some kind of virtual gpu or something that is hardware independent...
03:13:48 <Athas> ManDay[m]: dependencies are hard to detect when you have side effects.
03:13:49 <JuanDaugherty> i guess in as much as it is haskell-distributed.github.com rather than cloud-haskell.github.com, "squat" works
03:13:50 <ManDay[m]> (Or rather: Realizing such a detection more readily than with an monstrous effort)
03:14:03 <ManDay[m]> Athas: Ah yeah, and that
03:14:12 <dataN> llvm maybe?
03:15:07 <croben_> is it possible to display core dump in ghci? something equivalent to "ghc -c x.hs -ddump-simpl"
03:15:11 <Athas> Also, Haskell has some other qualities that make parallel execution difficult (mostly laziness, but also an emphasis on sequential algorithms in the programming style).
03:15:32 <dataN> like a kind of virtual cluster or something, for testing on one machine before deploying to a distributed network...
03:15:55 <Athas> dataN: I'm not aware of anything like that for strategies.
03:16:16 <ManDay[m]> Athas: Laziness shouldn't make parallelization any difficult
03:16:30 <JuanDaugherty> igess the distinction between squatter and pioneer, or founding settler is determined after the fact (of the success or no of the squat/settlement)
03:16:55 <cocreature> croben_: launching ghci with -ddump-simpl or running ":set -ddump-simpl" inside ghci should work
03:16:59 <Athas> ManDay[m]: no, but it makes efficient parallel execution more difficult.  Laziness is in practice a combination of (controlled) side effects and control flow.
03:17:09 <ManDay[m]> (at least not compared to eager evaluation - of course one wouldn't want superfluous calculations to be done)
03:17:12 <Athas> Every thunk is potentially a synchronisation point.
03:17:29 <dataN> so that the user could specify the architecture, e.g. number of cores, memory structure e.t.c.
03:17:33 <Athas> There is a reason (almost) all the Haskell libraries for parallelisation are strict.
03:18:09 <dataN> and model latency along communication channels between processors e.t.c.
03:18:22 <croben_> Athas: can you elaborate on this? currently working on a PLT class and having trouble arguing why we should switch to scala for parallel programming
03:18:40 <croben_> cocreature: thank you :)
03:19:49 <Athas> croben_: what do you want to know?  One example of the issue is that when you send a thunk to N processors, those processors will then contain references into the same heap.  When they start evaluating the thunk, they will be mutating the same heap.  This requires expensive synchronisation.
03:20:18 <Athas> The alternative would be to copy the thunk (*and everything to which it refers*) when it is send to the processors.  This might be a *lot* of data.  Usually it's better to just evaluate it fully before you send it.
03:20:51 <Athas> And of course, if you have a bunch of worker processors that just send back un-evaluated thunks to the master processor, then you haven't saved anything, since the master processor will end up having to evaluate all of them sequentially.
03:21:27 <haasn> Athas: I was under the impression that haskell's lack of side effects (referential transparency) meant you didn't need expensive synchronization on thunks since a double-write or double-evaluation is harmless?
03:21:28 <Athas> It's even worse if you want to exploit restricted high-performance chips like GPUs or the vector units on a CPU, since they cope really poorly with the kind of control flow required to handle thunks.
03:21:43 <Athas> haasn: yes, semantically, but not operationally.  It might cost you time.
03:22:26 <Athas> Also, multiple processors writing to the same location in memory will cause severe cache misbehaviour.
03:22:55 <croben_> thank you, that is incredibly helpful!
03:23:47 <Athas> It's not that you can't do lazy parallel programming.  There are probably some cool tricks possible (just like with sequential lazy programming).  But it's like digging for gold in a minefield...
03:24:31 <croben_> so lucky that you were addressing this today
03:26:09 <dataN> is it true that immutable datastructures are faster for this sort of thing?
03:26:13 <Athas> I'm always ranting about parallel programming!
03:26:33 <Athas> dataN: "faster", not sure.  But mutable data structures are definitely incredibly hard to get to work in a parallel setting.
03:27:02 <Athas> But I suppose since mutable sharing is slow in a multicore environment, that's an argument for immutable datastructures.
03:28:02 <dataN> well, just that the geometry of the data interaction can be explicitly stated rather than depending on what could be a less than optimal automatic weight balancing act.
03:28:36 <croben_> Athas: we will definitely be paying attention to you then!
03:31:30 <dataN> what about code fusion? can that enter the considerations?
03:31:40 <mniip> 1531301920 [12:38:40] <shachaf> Are there any other good tensor products for the category of endofunctors?
03:31:45 <mniip> coproduct!
03:33:03 <shachaf> That doesn't give you interesting monoids.
03:33:08 <dataN> of automatic rewrites for parallel programs...
03:34:15 <mniip> shachaf, that doesn't give you monoids at all
03:34:20 <mniip> Either (f a) (f a) -> f a
03:34:22 <mniip> Void -> f a
03:35:03 <mniip> Const Void perhaps
03:35:23 <dataN> mniip: was there a place to find info on adjunctions resulting from curried profunctors!?
03:35:54 <mniip> is the identity of the tensor product always a monoid?
03:35:55 <shachaf> mniip: Hmm?
03:36:27 <mniip> shachaf, if you define (F (x) G) = A mapsto FA + GA
03:36:49 <shachaf> Writing a function :: Void -> f a is the easy part (there's only one).
03:36:51 <mniip> the identity of that is A mapsto Void
03:36:56 <mniip> oh
03:36:57 <mniip> er
03:37:01 <shachaf> Oh, I see what you mean.
03:37:19 <shachaf> Or do I? Did you mean Const ()?
03:37:25 <mniip> yeah I guess everything is a monoid there
03:37:35 <shachaf> No, you need the monoid laws.
03:38:21 <mniip> aren't they automatically satisfied
03:38:47 <mniip> mappend = either id id; mempty = absurd
03:38:48 <shachaf> Oh, wait, I was thinking of comonoids.
03:39:16 <shachaf> Yes, monoids are just boring.
03:39:20 <mniip> mappend is assoc, and to observe the nonidentity of mempty you need an inhabitant of Void
03:40:23 <shachaf> Yep.
03:40:55 <shachaf> So it's the same situation as monoids in * with Either.
03:41:05 <dataN> if Reifies does something like (a->b) -> (s -> (a->b)), what does (a -> b) -> (a -> (s,b))? where (s -> (a->b)) is like ((s,a)->b)...
03:41:27 <mniip> dataN, what?
03:41:45 <dataN> that was what the Curried was for...
03:48:28 <dataN> i.e. if instead of extending a class definition e.g. 'class Set f where set :: (a,f a) -> f a' to 'class SetI i f where seti :: i -> ((a,f a)->f a)' the reification machinery allows the original class to be locally instantiated e.g. via provision of a value with the type of seti, then how is the converse done? i.e. something like reifies which could handle the abstraction (avoid writing the extended class);
03:49:01 <dataN> 'class Get f where get :: f a -> (a,f a)'  extended to 'class GetI i f where geti :: f a -> (i,(a,f a))
03:49:25 <dataN> see how the 'i' kind of jumps over the arrow...
03:51:16 <dataN> comparing 'seti :: (i,(a,f a))->f a' to 'geti :: f a -> (i,(a,f a))'
03:53:12 <dataN> the fact that the rest of the type is also backwards is kind of distracting, it need not be, the point is to return some kind of reifying inverse without mentioning 'i' in a modified version of the class, but to use the original class.
03:53:55 <dataN> it would be nice if it was; Reifies  (f a -> (a,f a)) i
03:54:59 <cocreature> what would be the point of that? Reifies allows you to add an additional input parameter which can be useful for customizing the behavior of something. what is the point of injecting an output parameter that you have supplied yourself?
03:56:14 <mniip> reify a continuation
03:57:08 <dataN> I don't understand this answer
03:57:45 <mniip> frankly I have a hard time understanding your question
03:58:11 <mniip> Reifies s (T -> r)
03:58:45 <mniip> then when you have ((T -> r) -> r)
03:58:54 <mniip> you can apply it
04:00:22 <pally> instance SomeTypeClass myTypeConstuctor where
04:00:35 <ocramz> hullo !
04:00:46 <pally> in ghci, what do I need to type after "where" to finish the body?
04:00:57 <pally> how do I escape the newline?
04:01:20 <ocramz> you can type everything on a single line
04:01:21 <cocreature> pally: you can use multiline input if you start it with :{ and end it with :}
04:01:22 <pally> I believe an indentation is also required
04:02:03 <Ariakenom> you can use braces instead of indentation f = x where {y=3; x=y}
04:02:07 <pally> ocramz, don't you need indentation in the body?
04:02:35 <pally> Ariakenom, okay.
04:02:57 <ocramz> it depends, for a single where clause you can just omit the braces and the semicolon
04:03:09 <ocramz> but yea Ariakenom 's is the general solution
04:04:28 <dataN> cocreature: the idea of extending get and set to geti and seti is to allow 'differenceT :: Applicative g => f a -> (g (f a -> f a),f a)' to be implemented by something other than 'Lens f = (Get f,Set f)'. the ability reify away this abstraction on the side of Set is promising, but the Get class supports no obvious similar abstraction
04:06:03 <cocreature> dataN: you really need to provide more context here if you want people to understand your question: what is differenceT supposed to do, what is Get, what is Set, …
04:07:27 <dataN> the classes were stated above, implementing differenceT is equivalent to implementing an instance for Traversable, i.e. it could be included in the Traversable class, or even replace it.
04:08:42 <revskill> Hi , i have one question
04:09:01 <revskill> my function is userFields = fmap (pack . showConstr) . dataTypeConstrs . dataTypeOf $ (undefined :: UserSerialized)
04:09:12 <revskill> this is used to get list of field names from a record
04:09:30 <revskill> now i want to get rid of userFields function name
04:09:34 <dataN> the idea is to use reification so that the differenceT instance afforded by Lens can be used as the only version, with any others simply providing a local implementation.
04:09:38 <revskill> instead i want to abstract over the type
04:10:01 <revskill> so that i can call like that: getFields @UserSerialized
04:10:43 <dataN> because all itterativly constructed containers are isomorphic to list in this way.
04:12:07 <dataN> differenceT xs = let (x,xs) = get xs in (fmap set (pure x),xs)
04:12:57 <dataN> differenceT ys = let (i,(x,xs)) = get ys in (fmap (seti i) (pure x),xs)
04:13:11 <dataN> geti*
04:13:13 <cocreature> I still don’t really understand your goal here but it sounds like you are first trying to replace lens’ approach of passing optics around as regular values by typeclass instances only to then try to turn those typeclass instances into values using Reifies
04:13:29 <dataN> yes
04:14:43 <dataN> the advantage being that the more simple version using get/set should be used as a local instance can be provided, rather than defining the classes geti/seti
04:15:35 <dataN> essentially, the traversal implementation for list is then the only one required.
04:15:47 <pie_> so...i guess the issue here is that the a type variable is generic, but what do I do if I dont actually want to inspect it? https://bpaste.net/show/a7c420ae47d9
04:16:47 <dataN> with the added side effect of providing a sane realisation of invertable functions. except the absence of this backwards reifies concept
04:17:01 <dataN> it would be interesting to see about if Curried can help here...
04:20:46 <dmwit> revskill: Sounds plausible. One way would be to use ScopedTypeVariables.
04:22:01 <revskill> dmwit: do you mean this: fields = fmap (pack . showConstr) . dataTypeConstrs . dataTypeOf $ (undefined :: @a)
04:22:29 <revskill> I have a bunch of records, and need to render to html table, so i have to get fields name first.
04:22:36 <dmwit> `(undefined @a)` would be fine, or `undefined :: a`. You will also need to include `forall a.` in the type signature for `fields`.
04:25:08 <dmwit> pie_: It's a bit hard to say without knowing what the type arguments to `Id` and `LValue` are supposed to signify. But what if you just write `(normId :: Id () -> Id ())` (and similarly for `normLVal` in the `let f = ...` line?
04:26:25 <pie_> dmwit, sorry, typically its SourcePos from Parsec i think
04:26:36 <pie_> if i do Id SourcePos its fine
04:26:38 <lyxia> pie_: you might want a top-down "everywhereBut" which is not defined
04:26:54 <dmwit> pie_: So... problem solved?
04:27:11 <pie_> dmwit, but i want to do it like in the module where they pass a generic type
04:27:13 <lyxia> pie_: and you'll have to specialize this type variable in some way
04:27:28 <pie_> s/pass/accept/
04:27:30 <revskill> dmwit: Thanks, compiler understood what i mean!
04:27:43 <dmwit> revskill: ^_^
04:28:24 <dmwit> pie_: Okay, sure, but to actually run the program, you have to pick a type somewhere. It's gonna use that class instance, and it has to know which dictionary to pass.
04:28:53 <pie_> dmwit, hm. does it not suffice that the constraints get solved when I call it?
04:29:03 <dmwit> You can push the decision later and later with judicious typeclass-polymorphic type signatures. But eventually you've got to decide.
04:29:12 <pie_> i get this for the type of f: f :: JavaScript SourcePos -> JavaScript SourcePos
04:30:14 <dmwit> Right. You can probably make that, e.g., `f :: (Data a, Typeable a) => JavaScript a -> JavaScript a`. But then the caller of `f` needs to choose `a`.
04:30:18 <__monty__> Haskell source code formatters yes/no? Which one, hindent, brittany?
04:30:29 <dataN> everything traversable is isomorphic to list, differenceT via geti/seti does this, and the get/set version could be recovered if geti to get could be achieved in a similar way to how seti was replaced by 'Reifies i ((a,f a)->f a)'
04:31:03 <dmwit> pie_: Ah, got it.
04:31:05 <mniip> "everything traversable is isomorphic to list" - what?
04:31:10 <dmwit> pie_: This is the monomorphism restriction.
04:31:37 <dataN> should be
04:31:41 <dmwit> mniip: That seems very unlikely.
04:31:52 <mniip> my thought as well
04:32:03 <dmwit> dataN: What about, say, `Tree`?
04:32:22 <dataN> Tree = Free []
04:32:25 <dmwit> dataN: Or, like, make it even simpler. What about `Const ()`?
04:32:41 <dataN> oh, maybe its product type like
04:33:14 <dmwit> Const Bool () -- has exactly two (total) inhabitants, unlike [X] for any X
04:33:56 <Putonlalla> Why doesn't `()` have a `Traversable` instance?
04:34:16 <dmwit> wrong kind
04:34:24 <dmwit> data Unit a = Unit -- can have a Traversable instance
04:34:28 <shachaf> Traversable f means that each "f a" is a product of a^n for some n and some other data
04:34:28 <Putonlalla> Oh, right, `Proxy`.
04:34:32 <pie_> dmwit, im looking at https://wiki.haskell.org/Monomorphism_restriction im not sure where that leaves me.
04:34:43 <dmwit> shachaf: That also sounds very unlikely.
04:35:02 <shachaf> dmwit: n can depend on the individual value
04:35:05 <dmwit> shachaf: fix (1:) is not (Int^n) for any n.
04:35:14 <tdammers> .oO( source code formatters make the most sense for languages that don't have syntax-relevant formatting )
04:35:16 <pie_> dmwit, compiled and baked are both of type JavaScript SourcePos
04:35:26 <dmwit> pie_: Just give `f` an explicit type signature is where that leaves you.
04:35:46 <shachaf> OK, fine, I was talking about free monoids and forgetting this was Haskell.
04:35:47 <dmwit> pie_: Or give `f` an extra argument, as in `f x = everywhere (...) x`.
04:36:02 <shachaf> But you know what I mean.
04:36:02 <Putonlalla> I was going to ask for a witness for the isomorphism between `Proxy a` and `[a]`.
04:36:13 <cocreature> __monty__: I tend to use hindent, it’s not great but the emacs integration is able to operate on a single declaration and therefore I can still use it for declarations where it works decently.
04:36:19 <dataN> ok, well just considering everything that *is* traversable via an isomorphic to list realised using differenceT via geti/seti
04:36:33 <dataN> isomorphism*
04:36:50 <pie_> dmwit, ok thanks, i'll give it a shot. What I don't understand is, given that it derived a completely defined signature, and i am passing a parameter of the appropriate type; why is it unhappy?
04:36:51 <cocreature> __monty__: I would switch to brittany if there was an emacs integration that would allow me to operate on a single declaration at the time
04:37:01 <shachaf> I mean that you can take each value apart into a product of a list component and "the rest of the type" component.
04:37:10 <dataN> hmm, ok maybe whats wrong is that this 'i' is adding extra "structure"
04:37:18 <shachaf> And then you can change the contents but not the shape of the list component, and put it back.
04:37:22 <dataN> which would be lost in an isomorphism
04:37:22 <shachaf> That's what traverse does.
04:37:32 <dataN> ok sorry
04:38:38 <shachaf> And by list I don't mean list but free monoid, which is more complicated in Haskell, if you want to be a stickler about it.
04:38:50 <pie_> dmwit, same error with: let f = (everywhere ((mkT normId) `extT` (mkT normLVal))) :: JavaScript SourcePos -> JavaScript SourcePos
04:38:58 <__monty__> cocreature: Hmm, ok thanks. Main reason I'm taking a look at it is the autoindentation of the plugin I use currently drives me crazy. It changes the indentation every time I add whitespace to a line >: (
04:39:54 <dmwit> pie_: Oh, really? Then it's not the MR. I apologize.
04:40:12 <pie_> dmwit, no problem, im happy for the effort :p
04:40:20 <pie_> would still be nice to solve..
04:40:22 <cocreature> __monty__: stylish haskell?
04:40:49 * jit10 asd
04:41:03 <dataN> anyway, the point is to replace the whole of Traversable by the implementation of differenceT :: Applicative g => f a -> (g (f a -> f a),f a) in terms of geti/set, namely; differenceT ys = let (i,(x,xs)) = geti ys in (fmap (seti i) (pure x),xs)
04:41:12 <__monty__> cocreature: No, haskell-vim. It does highlighting and indentation.
04:41:44 <Putonlalla> I'm fine with Vim's `copyindent`, __monty__.
04:41:46 <cocreature> ah, can’t commen on that :)
04:41:48 <pie_> dmwit, i think `Data a => a -> a` is the type of the everywhere expression
04:41:51 <cocreature> *comment
04:41:58 <Putonlalla> It doesn't do much magic, but doesn't get in the way either.
04:42:07 <__monty__> The indentation is generally OK but when it's not it's a PITA.
04:42:24 <dataN> seti*
04:42:24 <pie_> eh well it does say wher ethe error originates, nvm, but im still stumped.
04:43:06 * hackage wai-extra 3.0.23.0 - Provides some basic WAI handlers and middleware.  http://hackage.haskell.org/package/wai-extra-3.0.23.0 (MichaelSnoyman)
04:45:28 <hso> how to generate binaries in perticular folder using haskell stack ?
04:47:36 * hackage deriving-compat 0.5.1 - Backports of GHC deriving extensions  http://hackage.haskell.org/package/deriving-compat-0.5.1 (ryanglscott)
04:47:41 <lyxia> pie_: what error do you get with the monomorphic type annotation?
04:47:48 <pie_> lyxia, the same error
04:48:01 <lyxia> ambiguity?
04:48:18 <pie_> but i just discovered that if i concretize the types i still get an error from using extT, ill paste'
04:48:53 <quchen> hso: You can access the local binary path (i.e. where stack compiles to) with `stack path --bin-path`, so you could do something like »stack build && cp "$(stack path --local-path)/executable-name" "$MY_DIR"«.
04:48:53 <lyxia> Ah, it's because mkT needs to be annotated too
04:49:03 <pie_> https://bpaste.net/show/41ca31de528b
04:50:41 <pie_> lyxia, hm, but then wouldnt f also remain unspecialized?
04:53:45 <hso> quchen  : `stack path --bin-path`  gives something like this https://lpaste.net/6417916557501923328
04:54:21 <pie_> lyxia, so after reading around a bit, is it that its picking a monomorphic type of the wrong type, somewhere before it gets to f?
04:55:48 <lyxia> pie_: it's that there is nothing to say what the output type of mkT should be
04:55:59 <lyxia> pie_: in fact mkT and extT together are redundant
04:56:29 <quchen> hso: Sorry, I meant --local-path
04:56:35 <quchen> not --bin-path
04:56:49 <quchen> hso: See »stack path --help«
04:57:01 <pie_> lyxia, why are they redundant?
04:57:24 <pie_> hm well i guess the type of f doeant necessarily contain all the type informaiton of its constituents, that's true.
04:57:31 <hso> quchen  : `stack path --local-path`  gives something like Invalid option `--local-path'
04:57:48 <revskill> how to turn a -> [b] into a -> [c] if i have b -> c ?
04:58:17 <quchen> λ. stack path --local-bin
04:58:17 <lyxia> pie_: maybe mkT is redundant on only one side, but both are doing casts. A cast of a cast is a single cast, which has the added benefit that there is no middle type to specify
04:58:26 <quchen> I should think more before writing.
04:58:39 <quchen> --> /home/david/.stack/bin
04:58:43 <quchen> That looks right.
04:59:16 <lyxia> pie_: I think you can drop the mkT on the right
04:59:36 <pie_> lyxia, hm that kind of makes sense.
05:00:02 <pie_> lyxia, there's an extQ example here http://web.archive.org/web/20070427092934/http://www.cs.vu.nl:80/boilerplate/testsuite/freeNames/Main.hs
05:00:38 <pie_> going by that, maybe droppable on both sides, im not sure what const [] is
05:01:44 <mniip> revskill, compose 'map f' on the left
05:02:52 <pie_> lyxia, now its just https://bpaste.net/show/598e68857196
05:03:18 <revskill> mniip: Great, i use fmap for it
05:03:44 <pie_> uh well that depends on if thats a new or a fixed error...
05:04:00 <revskill> The correct code to get fields of a record is: foldMap (fmap pack . constrFields) <$> dataTypeConstrs . dataTypeOf $ (undefined :: a)
05:04:05 <revskill> Haskell is so cool !
05:04:21 <pie_> lyxia, if i only drop one mkT i still get 2 of the earlier errors
05:05:11 <mniip> revskill, is there a particular reason you're playing with Data.Data?
05:05:47 <revskill> Yes, i have a bunch of models, so i need to write one generic code to get fields for them
05:06:09 <mniip> have you seen Generics?
05:06:26 <revskill> Not much
05:06:35 <revskill> Can it help in this case ?
05:06:40 <pie_> lyxia, yeah the left thing should most likely be wrapped by *something*...
05:06:53 <revskill> My use case is to get fields to render to HTML table headers
05:09:04 <jit10> :)
05:09:13 <c50a326> withSocketsDo :: IO a -> IO a   -- it's not very clear what this does?
05:09:28 <riddle00>  /msg NickServ VERIFY REGISTER riddle00 wbqmvhtjhxpj
05:09:43 <c50a326> oh dear
05:09:52 <riddle00> lol wtf
05:09:54 <dmwit> c50a326: It's documented, though.
05:10:02 <c50a326> dmwit: http://hackage.haskell.org/package/network-2.7.0.2/docs/Network-Socket.html is it?
05:10:04 <dmwit> riddle00: Seems like a good time to change your password!
05:10:22 <liste> c50a326: as to why, https://stackoverflow.com/a/28730709/1283954
05:10:24 <dmwit> c50a326: http://hackage.haskell.org/package/network-2.7.0.2/docs/Network-Socket.html#v:withSocketsDo yes?
05:10:33 <c50a326> dmwit: I've read this documentation, it doesn't say anything about how it works or what's it for or what it does... I mean there's an example
05:10:38 <pie_> ok there's an example here https://github.com/paf31/haskell-slides/tree/master/syb
05:10:46 <c50a326> dmwit: have you read what it says? It doesn't explain anything, it just says something about if you're on Windows and that it's okay to nest
05:11:10 <dmwit> c50a326: It says what it's for: "The networking subsystem must be initialized using withSocketsDo.".
05:11:37 <c50a326> dmwit: that comes after "With older versions of the network library (version 2.6.0.2 or earlier) on Windows operating systems,"
05:11:42 <pie_> which brings back the orignal issue..
05:11:59 <dmwit> c50a326: Correct.
05:12:05 <dmwit> c50a326: What part of that is unclear?
05:12:07 <c50a326> I'm not on Windows and if it's also the case for Linux, then why is it so, why must "the networking subsystem be initialized with withSocketsDo", and when that happens, what is happening?
05:12:23 <liste> c50a326: on other platforms, it's a no-op
05:12:48 <dmwit> c50a326: It is not also the case for Linux. I admit the documentation does not explicitly say this, but it is a *very* strong convention in English that implies it.
05:13:40 <pie_> ok i think i understand the problem now...
05:14:46 <c50a326> and it says only on versions 2.6 or earlier... so it's unnecessary for Windows also now, if you're using a later version of the package?
05:15:55 <dmwit> Correct.
05:16:33 <dmwit> Except in the situation stated in the documentation, of course.
05:17:37 <c50a326> okay cool thanks
05:19:03 <mniip> is the ambiguity check for \forall \vec a. T(\vec a) basically trying to solve  \vec a ~ \vec a'  from T(\vec a) ~ T(\vec a') ?
05:20:35 <dmwit> Is this question about a specific document?
05:22:06 <romanix> Sanity check: https://lpaste.net/5745333088494288896 - are the 'undefined reference' errors caused by those symbols missing from the .so library?
05:22:36 * hackage hpqtypes 1.6.0.0 - Haskell bindings to libpqtypes  http://hackage.haskell.org/package/hpqtypes-1.6.0.0 (MikhailGlushenkov)
05:22:55 <lyxia> romanix: that sounds about right
05:25:22 <romanix> lyxia, thanks! Do you know if stack uses something else than LD_LIBRARY_PATH for library path locations? I'm sure I have a (manually compiled) libLLVM.so in the path which contains those symbols
05:27:13 <pally> :t (<*>)
05:27:14 <lambdabot> Applicative f => f (a -> b) -> f a -> f b
05:27:16 <dmwit> Two questions: 1. I thought .a's were statically linked, in which case no .so is going to help, 2. Perhaps even in case it is doing dynamic linking it hasn't requested a link to libLLVM.so in the first place for some reason?
05:27:30 <mniip> dmwit, no, a question about the haskell language
05:27:31 <dmwit> ldd can help answer the latter
05:27:48 <mniip> er, if you were asking me
05:28:13 <dmwit> mniip: I was.
05:28:25 <lyxia> romanix: I have no idea sorry
05:28:49 <romanix> no worries, lyxia
05:29:17 <mniip> dmwit, are you familiar with typechecker internals?
05:29:19 <dmwit> mniip: I'm not sure I know what *the* ambiguity check is. But my guess is that it's just checking whether there's enough information to direct typeclass search, not trying to check that T(\vec a) ~ T(\vec a') implies \vec a ~ \vec a'.
05:29:26 <pally> question: would it make sense for the 'f' (above) to be, for example, binarytree ?
05:29:41 <pally> that would make it a binary tree of functions
05:29:47 <mniip> typeclass search?
05:29:48 <dmwit> pally: I think it would be sensible, yes.
05:29:57 <dmwit> mniip: Sorry, instance search specifically.
05:30:03 <mniip> ?
05:30:31 <dmwit> e.g. if F is a type family, F a is not enough information to direct instance search to solve a C a constraint.
05:31:33 <mniip> not sure how typeclasses are involved here exacrtly
05:31:39 <pally> dmwit, I am trying to convince myself that it'd make sense by imagining what the scenario would be like
05:32:12 <dmwit> > (+) <$> Node 3 [Node 4 [], Node 5 []] <*> Node 6 [Node 7 []]
05:32:14 <lambdabot>  Node {rootLabel = 9, subForest = [Node {rootLabel = 10, subForest = []},Node...
05:32:26 <mniip> dmwit, I'm talking about bindings' ambiguity check
05:32:29 <dmwit> pally: This adds up node labels in matching positions.
05:32:40 <dmwit> pally: Like `zip`, it drops any positions that don't appear in both trees.
05:33:00 <dmwit> pally: Along the way, it builds a tree of functions -- namely, (3+), (4+), and (5+).
05:33:54 <pally> dmwit you are a quick wit individual.
05:33:58 <mniip> consider e.g
05:34:01 <mniip> @let foo :: c => a; foo = foo
05:34:02 <lambdabot>  .L.hs:158:8: error:
05:34:02 <lambdabot>      • Could not deduce: c0
05:34:02 <lambdabot>        from the context: c
05:34:09 <mniip> this sort of ambiguity check
05:34:31 <mniip> where a polymorphic binding's type doesn't determine all used tyvars
05:35:07 <LOGOUT> test msg
05:35:11 <dmwit> Neat! That's a corner I don't know much about.
05:35:23 <mniip> :(
05:35:44 <mniip> the GHC notes aren't particularly helpful either
05:36:00 <mniip> in particular I'm trying to figure out this mystical type error:
05:36:20 <mniip> @let foo1 :: (forall k. (KnownNat k) => q k) -> (); foo1 _ = ()
05:36:21 <lambdabot>  .L.hs:158:22: error:
05:36:21 <lambdabot>      Not in scope: type constructor or class ‘KnownNat’
05:36:21 <lambdabot>      |
05:36:35 <mniip> not *that* one...
05:36:49 <mniip> ah right, typelits isn't safehaskell is it
05:36:57 <mniip> okay consider
05:37:02 <mniip> % foo1 :: (forall k. (KnownNat k) => q k) -> (); foo1 _ = ()
05:37:02 <yahb> mniip:
05:37:11 <mniip> % foo2 :: (forall k. (KnownNat k, k <= 0) => q k) -> (); foo2 _ = ()
05:37:11 <yahb> mniip: ; <interactive>:22:9: error:; * Couldn't match type `q0' with `q'; `q0' is untouchable; inside the constraints: (KnownNat k, k <= 0); bound by the type signature for:; foo2 :: forall (k :: Nat). (KnownNat k, k <= 0) => q0 k; at <interactive>:22:9-53; `q' is a rigid type variable bound by; the type signature for:; foo2 ::
05:37:19 <riddle00> test msg
05:37:29 <riddle00> (sorry, just trying to learn irssi)
05:38:35 <mniip> I'm reading the OutsideIn paper where the touchable/untouchable variables are defined and I have no idea why q would be untouchable there
05:39:13 <lukelau> Is there a version of state’s modify that lets you operate inside a monad?
05:39:36 * hackage sort-by-pinyin 2018.4.9 - sort by pinyin  http://hackage.haskell.org/package/sort-by-pinyin-2018.4.9 (JinjingWang)
05:39:55 <lukelau> Maybe it would be easy enough to write myself
05:40:04 <liste> lukelau: MonadState's modify
05:40:45 <liste> https://hackage.haskell.org/package/mtl-2.2.1/docs/Control-Monad-State-Lazy.html#v:modify
05:40:59 <sarna> hey guys, how can I enable logging in my program? are there any good libraries/blog posts about it?
05:41:00 <mniip> liste, I thought they meant (s -> m s) -> m ()
05:41:06 * hackage hpack 0.29.0 - An alternative format for Haskell packages  http://hackage.haskell.org/package/hpack-0.29.0 (SimonHengel)
05:41:06 <liste> oh
05:41:27 <liste> lukelau: do you need it to be atomic?
05:41:34 <pally> :t Node
05:41:36 <lambdabot> a -> Forest a -> Tree a
05:41:45 <lukelau> liste: Not particularly
05:41:50 <lukelau> modifyM f = get >>= f >>= put
05:42:04 <lukelau> I see now though why its not in base
05:42:04 <mniip> yup that works
05:42:10 <lukelau> That was pleasant
05:42:36 <mniip> none of this is in base, not even StateT
05:44:04 <jit10> :t (<>)
05:44:05 <lambdabot> Monoid m => m -> m -> m
05:46:57 <c50a326> hey if stack says "network-2.6.3.6 from stack configuration does not match ..." whatever, which stack configuration is it referring to?
05:47:02 <romanix> sarna, not sure about blog posts but this seems to be a popular logging package: http://hackage.haskell.org/package/monad-logger
05:47:14 <c50a326> I put network >= 2.7 && < 3 in the package.yaml
05:47:21 <lyxia> c50a326: stack.yaml
05:47:30 <lyxia> c50a326: package.yaml is the package configuration
05:47:31 <sarna> romanix: thank you, I'll check it out
05:47:34 <c50a326> stack.yaml in this project directory is just comments mostly
05:47:56 <lyxia> but usually the conflict is between the two...
05:48:01 <c50a326> there isn't any network package in  stack.yaml, and I thought I was supposed to add dependencies in package.yaml, or is that wrong?
05:48:24 <lyxia> c50a326: package versions are pinned via the "resolver" field.
05:49:13 <c50a326> the resolver is lts-12.0, that should be late enough for network >= 2.7 surely?
05:49:18 <lyxia> c50a326: so the resolver corresponds to a specific version of network, and it is outside the bounds of your package.
05:49:41 <lyxia> c50a326: you can go on stackage.org to see that
05:49:54 <lyxia> c50a326: or query stack exec ghc-pkg -- something
05:50:41 <lyxia> stack exec ghc-pkg -- list network
06:04:06 * hackage primitive-extras 0.1 - Extras for the "primitive" library  http://hackage.haskell.org/package/primitive-extras-0.1 (NikitaVolkov)
06:07:06 * hackage hpqtypes-extras 1.6.2.0 - Extra utilities for hpqtypes library  http://hackage.haskell.org/package/hpqtypes-extras-1.6.2.0 (MikhailGlushenkov)
06:12:33 <sarna> also, where will I be able to find a haskell study group?
06:17:12 <shafox> How do I write a parser for this grammar: https://gist.github.com/shadow-fox/677cc89445b65ef0cec6a3c8d87cc9cb  ?
06:18:09 <mniip> shafox, I don't see a grammar
06:18:14 <dstolfa> me neither
06:18:39 <dstolfa> grammars are usually specified with a BNF-like syntax and eBNF or aBNF if context-free
06:18:58 <dstolfa> if it's not context-free, you use a similar syntax but you have to augment it to address the fact it's not context-free
06:19:06 <shafox> dstolfa: mniip :: It is a text file which has the format of the grammar file in the gist.
06:19:33 <mniip> it's not clear at all what you want to do
06:19:38 <dstolfa> mniip: +1
06:20:14 <shafox> Let me clean up the gist.
06:20:28 <dstolfa> shafox: also, w.r.t parsers, i suggest you go through Write you a Haskell
06:20:38 <dstolfa> it's focused on building up a programming language and has a chapter on parsing
06:20:48 <dstolfa> it's one of the first
06:21:10 <mniip> dstolfa, I wonder does it use StateT [] parsing?
06:21:22 <dstolfa> mniip: IIRC it doesn't
06:21:27 <dstolfa> mniip: i could be wrong though, been a while since i read that
06:21:36 <mniip> what else is there
06:22:39 <__monty__> I think it uses Megaparsec.
06:22:41 <dstolfa> mniip: in the "Parsing" chapter i think it just uses parsec for a simple (functional?) language
06:23:05 <mniip> ah, that's pretty much StateT String Maybe
06:23:36 * hackage primitive-extras 0.1.1 - Extras for the "primitive" library  http://hackage.haskell.org/package/primitive-extras-0.1.1 (NikitaVolkov)
06:24:52 <dstolfa> mniip: kind of, i think that they build their own simple parsec using newtype Parser a = Parser { parse :: String -> [(a, [Char])] } in the book itself
06:25:01 <dstolfa> (or something equivalent to it, can't remember
06:25:04 <dstolfa> )
06:25:12 <mniip> well guess what
06:25:31 <mniip> @unmtl StateT String []
06:25:31 <lambdabot> Plugin `unmtl' failed with: `StateT String []' is not applied to enough arguments, giving `/\A. String -> [] (A, String)'
06:25:34 <mniip> @unmtl StateT String [] a
06:25:34 <lambdabot> String -> [] (a, String)
06:25:52 <dstolfa> mniip: yeah, i didn't say no, just "kind of" because it's not explicit :)
06:26:08 <mniip> oh I just didn't wanna spell all the brackets and parentheses out :p
06:26:54 <dstolfa> mniip: lazy, like haskell!
06:26:55 <dstolfa> :>
06:27:20 <mniip> non-strict*
06:27:48 <dstolfa> mniip: unless you call someone that's strict w.r.t all of its arguments
06:27:57 <dstolfa> at least in ghc's case
06:28:11 <shafox> mniip: dstolfa I have updated the text that I am trying to parse. The data type that I want to hold is either a concrete record or a tree.
06:28:40 <dstolfa> mniip: FWIW i don't like using lazy/script, CBN/CBV is usually easier to explain to people
06:28:45 <dstolfa> wow, script
06:28:47 <dstolfa> strict*
06:28:52 <dstolfa> me englis very good
06:29:38 <dstolfa> shafox: that is still not a grammar though
06:29:43 <mniip> javastrict
06:30:25 <mniip> this time it's more understandable though
06:30:29 <dstolfa> shafox: what are you trying to do, a word-like formatting?
06:30:41 <dstolfa> and then keep a "context" of what styling you're in?
06:30:54 <mniip> not sure what field the text is supposed to go though
06:32:04 <shafox> So what I am trying to do is, it is kind of similar to xml/html, level of indentation is depends on the number of "=" sign e.g. ==some header==, this ndenotes 2nd level, it is closed when another ==someother header== starts.
06:32:34 <mniip> and what happens if you jump 2 headers down at once
06:33:32 <mniip> anyway this is easily solveable if your parsing library allows backtracking
06:33:43 <shafox> Everything inside the 2nd level is children to this. If there is no 3rd level e.g. ===header3=== then there wont be any children. I will update the values that I am expecting in the data structure.
06:34:35 <dstolfa> shafox: i still don't get it though. can i create a top level header and close one without reopening a new one to go back to its parent?
06:34:49 <dstolfa> are you trying to build a DOM-like thing that JS has?
06:34:53 <mniip> parseLevel n = string (replicate n '=') <> many (notChar '=') <> string (replicate n '=') <> many (parseLevel (n + 1) | notChar '=')
06:35:03 <mniip> replace monoids with applicatives at your discretion
06:35:40 <dstolfa> because in reality if all you're doing is closing things when you open a new one, it's a linked list
06:35:44 <dstolfa> if you can't go back
06:35:55 <dstolfa> it's only a tree if you can close one explicitly and go back to the parent
06:36:04 <shafox> dstolfa: yes
06:36:09 <mniip> dstolfa, think python indentation
06:36:23 <dstolfa> mniip: yeah but it's not obvious to me how the headers are closed here
06:36:32 <mniip> they aren't
06:36:37 <mniip> again think indentation
06:36:44 <dstolfa> mniip: okay but indentation can go back as well
06:36:45 <enterprisey> is this mediawiki?
06:36:46 <mniip> an outdent indicates closing 1 or more blocks
06:36:56 <mniip> how many depends on how much you outdent
06:37:12 <shafox> dstolfa: the headers are not closed, only to be handled if there is another header starts, if the next header is same level as the first one then it is a different section otherwise it is a part of the first header.
06:37:34 <dstolfa> oh, so the numbers indicate the names
06:37:34 <dstolfa> okay
06:37:36 <dstolfa> i missed that part
06:38:13 <mniip> the right intuition to think about this is that a section spans from its header until a header that's a lesser level than ours
06:38:32 <mniip> i.e while we meet headers of higher level than ours
06:38:33 <dstolfa> mniip: yep, i missed the fact that Header3 actually needs to contain the number "3" to identify it
06:38:39 <mniip> no
06:38:47 <mniip> it contains 3 equals signs
06:38:55 <dstolfa> OH.
06:38:55 <dstolfa> okay
06:39:23 <dstolfa> yeah, in which case i agree with mniip's function
06:43:36 * hackage hw-json 0.7.0.1 - Memory efficient JSON parser  http://hackage.haskell.org/package/hw-json-0.7.0.1 (haskellworks)
06:44:36 <ocharles_> Hi all. Can anyone help explain what happens to child threads when my main thread receives Ctrl+C? I understand the main thread receives an async UserInterupt exception, but my child threads seem to be dying with no cleanup
06:44:49 <ocharles_> I'm creating them with async's `concurrently_`
06:45:17 <cocreature> ocharles_: once the main thread dies all other threads die immediately
06:45:22 <ocharles_> :|
06:45:36 <cocreature> if you don’t want that, you need to explicitely wait for the threads to terminate
06:45:42 <ocharles_> which makes sense I guess
06:46:03 <cocreature> withAsync is one way to get that (in somewhat recent versions of async)
06:46:09 <ocharles_> yea, I thought that might be the case
06:46:12 <ocharles_> maybe my async is just too old
06:46:43 <cocreature> it would have to be fairly old, the fix was released two years ago or so iirc
06:47:01 <cocreature> previously it would throw the exception in the child thread but not wait for the finalizers to terminate
06:47:07 <ocharles_> hmm
06:47:46 <ocharles_> http://hackage.haskell.org/package/async-2.2.1/docs/src/Control.Concurrent.Async.html#concurrently%27 might have a bug then
06:47:49 <ocharles_> it doesn't use withasync
06:47:55 <ocharles_> or maybe it shouldn't use it
06:48:03 <cocreature> looking at the changelog 2.1.1 is the version that has the fix
06:48:44 <cocreature> the fix is in cancel iirc. withAsync just uses that internally but it looks like cancel isn’t used here either
06:48:48 <cocreature> no idea if it should be used :)
06:48:53 <ocharles_> hmm no, that seems to be throwing to child threads too. then wtf aren't I seeing it
06:48:55 <ocharles_> I'll try withAsync
06:50:02 <cocreature> throwing to a child thread is asynchronous so it might not be sufficient
06:50:25 <cocreature> ah but it seems to wait after that
06:56:06 * hackage primitive-extras 0.1.2 - Extras for the "primitive" library  http://hackage.haskell.org/package/primitive-extras-0.1.2 (NikitaVolkov)
06:56:15 <ocharles_> ok, it seems to work with withAsync (my child thread sees `thread killed`)
06:57:06 <rotaerk> your child thread witnessed a thread being killed? :-O
06:57:35 <mniip> always reap your children!
06:58:27 <Ariakenom> If the parent is about to die make sure it kills its children
06:58:40 <Ariakenom> life lessons
07:07:36 * hackage consumers 2.1.2.0 - Concurrent PostgreSQL data consumers  http://hackage.haskell.org/package/consumers-2.1.2.0 (MikhailGlushenkov)
07:14:13 <quchen> Reminds me of when someone asked »What’s the easiest way to murder children« on the DF Reddit
07:14:39 <mniip> ugh
07:25:36 * hackage latex-live-snippets 0.1.0.0 - Automatically inline Haskell snippets into LaTeX documents.  http://hackage.haskell.org/package/latex-live-snippets-0.1.0.0 (isovector)
07:26:36 * hackage deferred-folds 0.5.2 - Abstractions over deferred folds  http://hackage.haskell.org/package/deferred-folds-0.5.2 (NikitaVolkov)
07:28:36 * hackage primitive-extras 0.1.2.1 - Extras for the "primitive" library  http://hackage.haskell.org/package/primitive-extras-0.1.2.1 (NikitaVolkov)
07:32:06 * hackage deferred-folds 0.6 - Abstractions over deferred folds  http://hackage.haskell.org/package/deferred-folds-0.6 (NikitaVolkov)
07:37:25 <c50a326> what is type ServiceName in Network.Socket
07:38:02 <Rembane> c50a326: My guess is that it is a newtyped String.
07:38:24 <quicksilver> c50a326: like, 'http' maps to 80
07:38:36 <quicksilver> nobody uses service name lookups, everyone hard codes port numbers
07:38:59 <quicksilver> but in princple port numbers could be looked up like that from service names
07:39:38 <quicksilver> (at the haskell end it is not even a newtype'd String. It's just a type synonym)
07:39:49 <quicksilver> `type ServiceName = String`
07:41:06 * hackage primitive-extras 0.1.2.2 - Extras for the "primitive" library  http://hackage.haskell.org/package/primitive-extras-0.1.2.2 (NikitaVolkov)
07:42:06 * hackage ghc-events 0.8.0 - Library and tool for parsing .eventlog files from GHC  http://hackage.haskell.org/package/ghc-events-0.8.0 (MitsutoshiAoe)
07:42:45 <c50a326> ah okay thanks
07:46:15 <pally> Can someone please illustrate the purpose of the `pure` method of class `Applicative`?
07:46:59 <pally> or demonstrate
07:47:35 <lyxia> do you know about Monads already
07:47:57 <pally> no.
07:48:20 <pally> I know Applicatives and Functors
07:48:27 <cloudhead> > pure (+) <*> Just 1 <*> Just 2
07:48:29 <lambdabot>  Just 3
07:50:20 <pally> :t pure
07:50:22 <lambdabot> Applicative f => a -> f a
07:50:33 <mnoonan_> pally: if your Applicative is container-like, you can think of `pure` as making a container with the single provided element
07:50:52 <mnoonan_> e.g.
07:51:03 <mnoonan_> > pure 1 :: Maybe Int
07:51:05 <lambdabot>  Just 1
07:51:10 <mnoonan_> > pure 1 :: [Int]
07:51:13 <lambdabot>  [1]
07:51:51 <Ariakenom> > fmap (+1) (pure 1) :: Maybe Int
07:51:53 <lambdabot>  Just 2
07:51:58 <Ariakenom> > fmap (+1) (pure 1) :: [Int]
07:52:00 <lambdabot>  [2]
07:54:28 <Ariakenom> :t fmap (+1) (pure 1)
07:54:30 <lambdabot> (Applicative f, Num b) => f b
07:57:50 <sarna> hey, I'm reading the "Haskell from first principles" book and I'm confused by the associativity laws on Monoids
07:58:08 <sarna> "Associativity means the arguments can be regrouped (or reparenthesized, or reassociated) in different orders and give the same result, as in addition"
07:58:27 <quicksilver> sarna: like (4+5)+6 gives the same result as 4+(5+6)
07:58:59 <sarna> quicksilver: oh! I thought it's about the arrangement of arguments. like 2+3 vs 3+2
07:59:04 <quicksilver> no
07:59:05 <sarna> which made it very confusing
07:59:10 <quicksilver> that's called 'commutativity'
07:59:15 <sarna> now I get it, thanks :)
07:59:16 <sarna> ohh
07:59:24 <c_wraith> Many more things are associative than commutative
07:59:41 <quicksilver> > "hello" ++ "world"
07:59:44 <lambdabot>  "helloworld"
07:59:48 <quicksilver> > "world" ++ "hello"
07:59:50 <lambdabot>  "worldhello"
07:59:52 <quicksilver> not commutative :)
08:00:06 <sarna> yes, that's what got me confused :)
08:01:01 <Rembane> > "hell" ++ ("o " ++ "world")
08:01:03 <lambdabot>  "hello world"
08:01:09 <Rembane> > ("hell" ++ "o ") ++ "world"
08:01:12 <lambdabot>  "hello world"
08:02:45 <c50a326> hey do I need to do something about this https://ptpb.pw/FWwA
08:03:03 <pally> I have trouble with the very first example: pure (+) <*> Just 1 <*> Just 2
08:03:12 <pally> :t pure
08:03:13 <lambdabot> Applicative f => a -> f a
08:03:36 <pally> the first parameter to pure is of type a
08:03:38 <c50a326> last 5 lines, where I try to show defaultHints in ghci, it works but then also displays an error? I guess it doesn't work completely :\
08:04:01 <c_wraith> pally: `a' unifies with `Num b => b -> b -> b'
08:05:11 <c_wraith> pally: (->) is a regular type constructor, much like Maybe or []
08:05:14 <Ariakenom> Applicative f => (Num b => b -> b -> b) -> f (Num b => b -> b -> b)
08:05:32 <c_wraith> pally: It takes two arguments and is usually written infix, but the theory is identical
08:06:17 <c50a326> it's gonna shove the (+) into a Maybe type isn't it?
08:07:12 <c_wraith> :t Just (+)
08:07:13 <pally> I don't know what you are saying.
08:07:13 <lambdabot> Num a => Maybe (a -> a -> a)
08:08:26 <mnoonan_> pally: `a` can be anything there, even a function type.
08:08:30 <c_wraith> pally: functions aren't special in Haskell.  They can be handled like any other value.  Passed to functions, returned from functions, kept in a list, etc.
08:08:38 <c50a326> does `pure (+)` become `Just (+)` when on the left side of a <*> with a Maybe type (e.g. Just 1) on the right?
08:08:56 <c_wraith> c50a326: yes.  whenever it's used with f ~ Maybe, pure = Just
08:09:04 <mniip> 1531321415 [18:03:35] <c_wraith> pally: `a' unifies with `Num b => b -> b -> b'
08:09:05 <mniip> uhh
08:09:06 <c50a326> what's ~ ?
08:09:09 <Ariakenom> pure has this type (Applicative f => a -> f a)
08:09:13 <Ariakenom> the first argument is (+) which means  a = (Num b => b -> b -> b)
08:09:16 <c_wraith> mniip: yeah, I lied a little bit
08:09:36 <enterprisey> c50a326: it's = for types (roughly)
08:09:37 <c_wraith> c50a326: type equality, in a form the compiler can prove
08:09:54 <c50a326> cool, thanks
08:10:30 <quicksilver> or assume
08:10:37 <quicksilver> depending which way you look at it
08:10:46 <c50a326> so how about err... let me up arrow...
08:10:50 <c50a326> hey do I need to do something about this https://ptpb.pw/FWwA
08:11:01 <c50a326> I think clearly I do but how do I figure out what is wrong :(
08:11:20 <c_wraith> I guess it's assumed when you match a GADT constructor, proven when used as a top-level context in a signature
08:11:52 <c_wraith> Hmm, no.  Proven when you *use* something that has it as a top-level context.
08:11:55 <[exa]> or someone just put undefined in there, just as expected in a default hint
08:11:58 <c_wraith> that's the distinction
08:12:12 <mniip> ugh where'd all typechecker experts go
08:13:17 <[exa]> c50a326: why is that wrong btw?
08:13:45 <pally> Ariakenom, is it important that you switch from type variable ("letter") 'a' to 'b'?
08:13:55 <Ariakenom> pally: yes
08:14:07 <pally> could they not be of the same type?
08:14:10 <c_wraith> :t [(+), (-), max, (\x y -> x + y * 3 - (1 :: Int))] -- pally: a list of functions!
08:14:11 <pally> is it possible?
08:14:11 <lambdabot> [Int -> Int -> Int]
08:14:38 <Ariakenom> pally: no
08:14:55 <Ariakenom> "a" is the thing in "f"
08:14:59 <c50a326> [exa]: huh?
08:15:04 <Ariakenom> "b" is a part of the type of "a"
08:15:12 <c50a326> [exa]: I dunno I was trying to look at defaultHints and it's throwing some exception...
08:15:44 <c_wraith> c50a326: it just means that the addrAddress field was set to undefined
08:15:45 <Ariakenom> "a" is the same as "Num b => b -> b -> b"
08:15:57 <c50a326> oic, thanks, brb
08:16:14 <pally> okay
08:16:17 <Ariakenom> Both "a" and "b" can be any type. As long as they satisfy everything we said about them.
08:16:28 <[exa]> c50a326: well it contains undefined and you're forcing it, it complains :]
08:16:40 <[exa]> c50a326: you can put some address in there and retry
08:17:07 <Ariakenom> Which is that "b" is a Num. And that "a" = "Num b => b -> b -> b"
08:17:17 <Ariakenom> and that second part implies they can't be equal
08:18:06 * hackage streamly 0.4.0 - Beautiful Streaming, Concurrent and Reactive Composition  http://hackage.haskell.org/package/streamly-0.4.0 (harendra)
08:18:59 <mnoonan_> c50a326: the docs on defaultHints are pretty clear about what you need to fill in: http://hackage.haskell.org/package/network-2.7.0.2/docs/Network-Socket.html
08:19:22 <mnoonan_> (not that I'm saying it's a good idea that they left those fields undefined, but whatever)
08:19:54 <Ariakenom> We don't need to say Num b twice so a = b -> b -> b is also true
08:21:39 <Ariakenom> pally: Can you figure out the type of "pure (+)"?
08:22:37 <pally> (+) has the type "Num a=> a -> a -> a"
08:23:07 <c_wraith> pally: you can rename type variables if you like, as long as you do it consistently.
08:23:38 <c_wraith> pally: in particular, Num a => a -> a -> a is the exact same type as Num elephant => elephant -> elephant -> elephant
08:23:45 <c_wraith> or other, less ridiculous, examples
08:24:46 <c_wraith> pally: renaming type variables in different definitions is often useful for preventing confusion
08:25:13 <c_wraith> pally: in particular, the `a' in the type of pure is a totally different type variable from the `a' in the type of (+)
08:25:43 <c_wraith> pally: so to help prevent confusion, you can rename the variables in one or both of the definitions, so they don't collide.
08:27:06 * hackage primitive-extras 0.1.3 - Extras for the "primitive" library  http://hackage.haskell.org/package/primitive-extras-0.1.3 (NikitaVolkov)
08:30:06 * hackage primitive-extras 0.1.3.1 - Extras for the "primitive" library  http://hackage.haskell.org/package/primitive-extras-0.1.3.1 (NikitaVolkov)
08:30:40 <Ariakenom> There is a scope for each type variable, that you can write explicitly (+)::(forall a. Num a => a -> a -> a)
08:37:06 * hackage primitive-extras 0.1.4 - Extras for the "primitive" library  http://hackage.haskell.org/package/primitive-extras-0.1.4 (NikitaVolkov)
08:39:52 <Myrl-saki> :t choice
08:39:54 <lambdabot> error:
08:39:54 <lambdabot>     • Variable not in scope: choice
08:39:54 <lambdabot>     • Perhaps you meant ‘choose’ (imported from Lambdabot.Plugin.Haskell.Eval.Trusted)
08:40:07 <Myrl-saki> Why is `choice` only in parser combinators?
08:40:12 <Myrl-saki> :: Alternative f => [f a] -> f a
08:40:28 <Ariakenom> :t asum
08:40:29 <lambdabot> (Alternative f, Foldable t) => t (f a) -> f a
08:40:34 <Myrl-saki> Thank you.
08:40:40 <Ariakenom> :t many
08:40:41 <lambdabot> Alternative f => f a -> f [a]
08:40:48 <Ariakenom> np
08:42:06 * hackage haskell-tools-ast 1.1.0.2 - Haskell AST for efficient tooling  http://hackage.haskell.org/package/haskell-tools-ast-1.1.0.2 (lazac)
08:43:06 * hackage haskell-tools-debug 1.1.0.2, haskell-tools-daemon 1.1.0.2, haskell-tools-cli 1.1.0.2, haskell-tools-builtin-refactorings 1.1.0.2, haskell-tools-backend-ghc 1.1.0.2 (lazac)
08:43:40 <Gurkenglas> Oh man, the roundtrip. interact $ unlines . map solve . (unfoldr . runStateT . ($ StateT uncons)) parse . lines
08:44:06 * hackage haskell-tools-demo 1.1.0.2, haskell-tools-rewrite 1.1.0.2, haskell-tools-refactor 1.1.0.2, haskell-tools-prettyprint 1.1.0.2, haskell-tools-experimental-refactorings 1.1.0.2 (lazac)
08:44:51 <Ariakenom> Gurkenglas: Hole in one!
08:45:17 <Gurkenglas> Oh hey with IO on Alternative it's just "many $ solve <$> parse getLine"
08:45:42 <Gurkenglas> *Alternative on IO
08:46:03 <Gurkenglas> Oh and output, dangit
08:46:16 <Gurkenglas> (parse was of course defined to be generic on the monad)
08:47:26 <Ariakenom> of course
08:48:57 <Gurkenglas> http://hackage.haskell.org/package/alternative-io-0.0.1/docs/Data-Alternative-IO.html requires old base. Where do we get the instance nowadays?
08:49:56 <glguy> instance Alternative IO -- Defined in ‘GHC.Base’
08:52:04 <Gurkenglas> That makes sense :D
08:54:36 * hackage hapistrano 0.3.5.8 - A deployment library for Haskell applications  http://hackage.haskell.org/package/hapistrano-0.3.5.8 (juanpaucar)
08:59:00 <zincy> How do you debug channels? Is there a way of viewing the contents?
09:02:28 <mniip> hey glguy are you perchance familiar with OutsideIn
09:02:49 <glguy> I'm aware of it, but probably not ready to start answering any questions unfortunately
09:03:22 <mniip> hmm
09:03:38 <mniip> having some issues with untouchables...
09:04:50 <Gurkenglas> "many getLine >>= traverse_ putStrLn . zipWith (\x y -> show x ++ y) [1..]" reads in everything before it outputs anything. Options?
09:05:19 <glguy> mniip: Is there some code involved?
09:05:24 <mniip> yes
09:06:19 <mniip> (forall k. (KnownNat k, k <= 0) => q k) -> ()
09:06:30 <mniip> fails the ambiguity check on the q (!) tyvar
09:06:35 <ara_> Has anybody seen some strange linker behaviour with ghc-8.4.2? I'm having it work correctly on some distributions, while others are failing. The particular issue is on Ubuntu and Fedora, which pick up `libffi.so.7` from within `rts`, but at runtime the valid version on the system is `libffi.so.6`. Arch and Gentoo work because they seem to add /usr/lib or /usr/lib64 to the linkline.
09:06:35 <mniip> while without the (k <= 0) it's fine
09:07:45 <mniip> it complains that it can't match q ~ q' under a local equational constraint (<= desugars into one)
09:08:02 <mniip> I have no idea what's the problem with that
09:12:06 * hackage ffmpeg-light 0.12.2.1 - Minimal bindings to the FFmpeg library.  http://hackage.haskell.org/package/ffmpeg-light-0.12.2.1 (AnthonyCowley)
09:18:19 <cocreature> ara_: is that using the binary distribution or something that you built yourself?
09:18:23 <Gurkenglas> zincy: perhaps you could, right after the channel c's creation in an IO do block, insert a line "forkIO $ print =<< getChanContents =<< dupChan c"
09:20:45 <Gurkenglas> http://hackage.haskell.org/package/base-4.11.1.0/docs/src/Control.Concurrent.Chan.html#writeList2Chan <- why isn't this "traverse_ . writeChan"?
09:20:57 <Gurkenglas> ("writeList2Chan ch ls = sequence_ (map (writeChan ch) ls)")
09:22:05 <lyxia> maybe no reason
09:22:05 <dmwit> It probably predates traverse_. Now, why it isn't mapM_ is a harder question. I doubt there's a good answer.
09:23:07 <pie_> lyxia, oh by the way turns out ext1T was what i wanted earlier and clears everything up nicely
09:23:15 <pie_> dmwit, ^
09:23:20 <dmwit> great
09:24:06 * hackage math-functions 0.3.0.0 - Collection of tools for numeric computations  http://hackage.haskell.org/package/math-functions-0.3.0.0 (AlexeyKhudyakov)
09:25:06 * hackage mwc-random 0.14.0.0 - Fast, high quality pseudo random number generation  http://hackage.haskell.org/package/mwc-random-0.14.0.0 (AlexeyKhudyakov)
09:26:27 <ara_> hey cocreature! Been a while. This is using the binary distributions downloaded via `stack`.
09:27:22 <ara_> cocreature: The platform keys vary though, it doesn't seem to matter.
09:33:39 <fresheyeball> Anyone around know about Database.Beam ?
09:34:00 <cocreature> ara_: hm, at least for ubuntu you could use herbert’s ppa https://launchpad.net/~hvr/+archive/ubuntu/ghc in combination with system-ghc: True
09:34:10 <cocreature> I think there is some repo for fedora as well
09:34:57 <cocreature> I haven’t seen your particular issue (but I’m not on ubuntu or fedora) but stack sometimes fetches bindists that don’t work on a given system
09:35:25 <ara_> cocreature: The strange thing is that the bindist on Fedora is the same one I've been using on arch, and it works fine on arch
09:35:35 <cocreature> ara_: also just to be sure, I would try 8.4.3 in case it’s a GHC issue
09:35:50 <cocreature> that’s not particularly strange, software is often not directly portable between different distros
09:36:13 <ara_> cocreature: That is true. And I've tried 8.4.3, which has the same issue.
09:36:17 <cocreature> also make sure you are using the latest version of stack. there have been some changes to how it fetches bindists
09:36:33 <ara_> cocreature: We're on the latest released version of stack, yes.
09:37:05 <glguy> mniip: Yeah, that's certainly curious :)
09:37:53 <cocreature> ara_: although I am somewhat surprised if stack would be broken on a standard ubuntu install. might be worth opening an issue about
09:39:00 <ara_> cocreature: Quite. Hence my surprise right now. I will open an issue if I run out of options to work out what's up!
09:39:39 <glguy> mniip: Oh, I've run into this before, I wonder if I can find the right reference
09:43:29 <c_wraith> istr someone wrote a library for running arbitrary MonadIO code in ghci via forkIO and an MVar. if that was a real thing, what was the name of it?
09:51:36 <mniip> glguy, like I get the part of the paper where they discuss touchable variables
09:51:58 <mniip> in e.g  case d of Dict -> e
09:52:15 <mniip> if d contained an equational proof then the whole expr has no principal type hence inference must stop
09:52:23 <ara_> cocreature: Your instinct was right, thank you. My colleague using the ubuntu ppa was able to build and link it properly
09:52:34 <ara_> Time to file an issue with stack
09:52:36 * hackage bhoogle 0.1.3.1 - Simple terminal GUI for local hoogle.  http://hackage.haskell.org/package/bhoogle-0.1.3.1 (andrevdm)
09:52:58 <mniip> this doesn't at all affect the case where a type sig is explicitly given
09:53:45 <mniip> I'm not exactly sure local axioms in pattern matches are related to local axioms in higher rank types
09:56:27 <mniip> I guess the idea is, for f :: (C => A) -> B
09:56:46 <mniip> f x  works kind of like  case d :: Dict C of Dict -> x
09:57:00 <mniip> but then again, the wanted type (A) is known here
09:57:29 <glguy> The problem isn't in implementing f, it's in using it later
09:57:42 <mniip> yes I know
09:58:19 <mniip> it's the well-typedness of the arguments that is being questioned
10:00:06 <mniip> if we have
10:00:21 <mniip> f :: forall a. (C => A a) -> B
10:01:34 <mniip> then by invoking  'f x' with x :: tau, we require  'C implies tau ~ A a'
10:01:37 <mniip> where a is rigid
10:02:45 <mniip> tau is a unification variable so it's all fine
10:04:40 <mniip> really not sure how a rogue equational constraint in place of C can give a different solution to this unification thing
10:10:18 <mniip> this very ticket https://ghc.haskell.org/trac/ghc/ticket/13655
10:16:19 <mniip> goldfire argues that 'a ~ A implies b ~ B' should also be insoluble because a solution is 'b ~ F a' where type family F where F A = B
10:17:04 <mniip> question is, does this case stretch to 'a ~ A implies b ~ tau' where tau is unification
10:17:55 <mniip> if I'm even using the right words
10:31:09 <Annnonym> test
10:32:54 <fresheyeball> Annnonym: hiya
10:36:36 <fresheyeball> So I have one error in Database.Beam that I can't see a way around
10:36:48 <fresheyeball> I just want to make an "expression" in beam doc speak
10:37:00 <fresheyeball> _val (x :: Price)
10:37:04 <fresheyeball> produces an erro
10:37:32 <fresheyeball> error
10:37:54 <fresheyeball> expect type "HaskellLiteralForQExpr (Columnar f0 Price)" with actual type Price
10:38:13 <fresheyeball> Its a bunch of type families and I don't see how to resolve it
10:44:19 <dmj`> When alex lexes a string, how can I get it to drop the quotes
10:46:11 <glguy> dmj`: You have the rule that matches string literals do that
10:46:36 <glguy> or you implement string literals as multiple alex rules with a string literal state
10:46:46 <glguy> or a mix of the two :)
10:47:02 <glguy> example: https://github.com/glguy/language-lua/blob/master/src/Language/Lua/Annotated/Lexer.x#L87-L101
10:47:38 <glguy> or https://github.com/glguy/config-value/blob/master/src/Config/Lexer.x#L78-L85
10:51:03 <dmj`> glguy: hmmm interesting :) I’m not that familiar with using state in Alex… here is what my current string parsing rules look like
10:51:03 <dmj`> https://gist.github.com/dmjio/f69df908d8eb459f0abb8673fab9f978
10:51:56 <dmj`> glguy: and while I have you here :) is [\”\b] the same as \“ | \b ?
10:51:57 <glguy> dmj`: You're going to have to process all of the escape sequences anyway
10:52:12 <glguy> so when you're processing those, strip off the leading and trailing "
10:52:17 <itsmeee3> Hello world! 31337
10:53:03 <glguy> dmj`: one is a character set, the other is a regular expression
10:53:20 <glguy> but yes, they behave similarly as regular expressions
10:54:15 <dmj`> ah, so this might be a source of my errors
10:54:18 <dmj`> @stringToken { TokenString . filter (`notElem` "\"") }
10:54:18 <lambdabot> Unknown command, try @list
11:08:09 <dmj`> glguy: I think part of the problem is (@stringCharacter+)?, I have no granular control over how this string is constructed, so I can’t pattern match on the escape codes. I suppose I could do a post-processing pass where I filter out certain input
11:08:40 <dmj`> @stringtoken { \s -> TokenString (process s) }
11:08:41 <lambdabot> Unknown command, try @list
11:09:01 <glguy> yeah, you'll need to write a processing function that will behave like read but for your format
11:26:06 <dmj`> glguy: so I have a pretty printer, and a lot of QuickCheck generators for this AST and am attempting to check that the round trip property holds, the errors I have been receiving seem to be coming from the fact the generator for String has been producing invalid source characters, so the lexer was failing.
11:26:34 <glguy> Your string literals won't survive the round-trip in general
11:26:44 <glguy> if you're going to interpret the tokens in place
11:27:14 <glguy> That's why in the language-lua package string literals are uninterpreted in the AST, they keep their escapes and their outer quotes
11:27:30 <glguy> then there's a separate module for interpreting them if you want: http://hackage.haskell.org/package/language-lua-0.11.0/docs/Language-Lua-StringLiteral.html
11:29:06 <dmj`> Hmm, interesting. For some reason the strings seem to be surviving the round trip property… I gen the AST, then invoke the pretty printer, taking care to wrap the string pretty '"' <> pretty str <> pretty '"'
11:29:34 <dmj`> And when I go to tokenize it again, it doesn’t seem to have issues.
11:29:45 <glguy> then your test isn't thorough enough. There's more than one way to encode a character in your string literal format
11:31:06 * hackage jni 0.6.1 - Complete JNI raw bindings.  http://hackage.haskell.org/package/jni-0.6.1 (FacundoDominguez)
11:31:25 <glguy> or perhaps you haven't implemented the process function. You definitely don't want to blanket filter out " like the first version since you can have those in the middle of a string literal escaped with \
11:31:34 <pong> any way to do sum . map (product) . nonEmptySubsequences faster?
11:32:06 * hackage inline-java 0.8.4 - Java interop via inline Java code in Haskell modules.  http://hackage.haskell.org/package/inline-java-0.8.4 (FacundoDominguez)
11:32:17 <dmj`> glguy: to gen a source character I use this (and note, I’m not currently generating escaped characters or escaped unicode) https://gist.github.com/dmjio/9a1c817b9eadb6b5b0a08bfba85a65e5
11:32:38 <lyxia> pong: that looks like a good dynamic programming exercise
11:32:56 <dmj`> glguy:  the process function I have is basically TokenString . reverse . drop 1 . reverse . drop 1
11:33:49 <dmj`> Where the top-level definition of encoding a String is \" (@stringCharacter+)? \” for now (there is another way to do it with triple quotes but haven’t gotten there yet
11:33:53 <glguy> It's probably not worth bothering the outer "s since you'll have to process the string literal later to do anything with it
11:34:06 * hackage singleton-typelits 0.1.0.0 - Singletons and induction over GHC TypeLits  http://hackage.haskell.org/package/singleton-typelits-0.1.0.0 (mniip)
11:34:20 <glguy> but yeah, if your test doesn't test escapes then it won't find any problems with escapes
11:35:10 <mniip> when your types are so complicated you have to resort to the good old examples \o/
11:36:09 * dmj` tests escape sequences
11:36:28 <dmj`> glguy: but w/o testing escape sequences, +++ OK, passed 100000 tests. looks pretty nice ;)
11:38:18 <dmj`> glguy: Is it safe to say that alex / happy will always parse faster than monadic parser combinators for context free grammars? Even w/ String this thing is pretty fast.
11:40:09 <glguy> My experience is that they're pretty speedy. I like running Alex on Text instead of String, but yeah it's usually quite fast even on string
11:41:17 <dmj`> @glguy Is there a special directive for that? I found the Alex user guide to be very helpful (moreso than happy), but I didn’t see anything mentioned about using Text, just “basic”(String) and “basic-bytestring” (ByteString)
11:41:17 <lambdabot> Unknown command, try @list
11:41:36 * hackage finite-typelits 0.1.4.1 - A type inhabited by finitely many values, indexed by type-level naturals.  http://hackage.haskell.org/package/finite-typelits-0.1.4.1 (mniip)
11:41:44 <dmj`> or do you just Data.Text.decodeUtf8 inside of the \s -> s
11:43:17 <glguy> dmj`: You don't use the built-in skeletons, you either manually write one, https://github.com/glguy/config-value/blob/master/src/Config/LexerUtils.hs or you use a library that did that http://hackage.haskell.org/package/alex-tools
11:45:24 <exarkun> Can I get rid of the grossness in the `stack ...` output under `build` here - https://circleci.com/gh/LeastAuthority/haskell-tahoe-lafs-storage-server/13 ?
11:46:34 <dmj`> glguy: oh wow, did not realize alex wrappers were extensible. `alex-tools` looks nice, I’ll eventually want line numbers as well...
11:46:57 <glguy> alex wrappers are just some code with magic names that gets pasted into your file
11:47:03 <glguy> so you can implement the magic names yourself
11:56:05 <dmj`> glguy: oh I see, just bypass the wrapper altogether, copy the code manually
11:56:21 <dmj`> sure
11:59:20 <pong> lyxia: will the dynamic programming approach be faster than n^2?
12:07:14 <Ariakenom> Would (maxBound :: forall a. Bounded a. a) make sense as constraint syntax?
12:07:51 <lyxia> pong: I think there's a linear time solution. You realize the original program is exponential though, right?
12:08:27 <pong> yea, I just submitted the linear solution tho
12:08:42 <geekosaur> Ariakenom, I think '.' means too many things already and complicates parsing too much as it is
12:10:29 <Ariakenom> geekosaur: True. I don't much care about the "." itself though. what about (forall a => Bounded a => a) then?
12:10:45 <tabaqui> hey all
12:11:04 <geekosaur> that's a problem because forall would have to function as a constraint instead of as a scope modifier
12:11:07 <tabaqui> I'm trying to implement Proof of Work by solving some hash problem
12:11:22 <tabaqui> but cannot write parallel client solving using monad-par and parallel packages
12:11:23 <Ariakenom> geekosaur: what do you mean? why?
12:11:38 <tabaqui> and I have two questions:
12:11:42 <geekosaur> I had a feeling you were going to ask that
12:11:51 <Solonarv> => makes a lot of sense for constraints: under the type-as-propositions view, it means "implies"; and it's similar to the function arrow ->, which also makes sense
12:12:20 <geekosaur> Solonarv, I think Ariakenom doesn't get that forall is about limiting the scope of an identifier
12:12:40 <dstolfa> Solonarv: what do you mean by "constraints" here?
12:12:46 <geekosaur> they think it is in some sense a constraint instead. but this kind of "constraint" is fundamentally different from the others
12:12:49 <tabaqui> 1) Is it possible to run parallel functions in Eval monad and wait only for one of them?
12:12:52 <dstolfa> Solonarv: sorry i just read this
12:12:56 <dstolfa> Solonarv: no context :)
12:13:01 <tabaqui> 2) Same thing with Par monad
12:13:35 <Solonarv> I mean the exact same thing that Haskell does. The discussion is about why => is used as syntax for specifying constraints.
12:13:44 <geekosaur> dstolfa, a constraint is a limitation on a type, for example (a ~ b) (a and b must have the same type) or (Num a => a) (type a must have a Num instance)
12:13:55 <dstolfa> Solonarv: ah okay, those constraints.
12:14:12 <dstolfa> geekosaur: thanks for the detailed answer, i was just confused about which "constraints" here
12:14:16 <dstolfa> people use the word for too many things
12:14:21 <geekosaur> whereas forall limits visibility instead of limiting what types are valid
12:14:51 <Ariakenom> My line of thought was that they are both declarations. a is a Num. introduce a type variable a.
12:15:02 <geekosaur> but that's not how it works
12:15:31 <geekosaur> constraints are modifiers for type resolution, forall limits visibility of a given type
12:15:54 <geekosaur> they're in some sense "declarations" but each has a different variety of effect
12:16:14 <Ariakenom> can extend as well as limit
12:16:46 <geekosaur> hypothetically 'forall' could be done as a constraint outside of its scope forcing the tyvar to not be bindable, but (a) that's a much harder constraint (b) you have a probolem if there's another tyvar witht hat name in scope at that point
12:16:52 <geekosaur> (forall introduces a new scope)
12:18:24 <geekosaur> in short, you can't emulate scoping with a type equation sensibly
12:18:34 <geekosaur> so you can't implement forall as a constraint
12:18:54 <geekosaur> if this still does not make sense, you probably need to learn how type resolution actually works
12:20:32 <geekosaur> also it would be bad if forall used => but meant something different than other uses of => at top level
12:20:41 <geekosaur> as far as being able to read programs
12:21:01 <Ariakenom> So I'm far off Haskell but similarly. If foralls could only be used in where-clauses and there would be no implicit introduction of type variables. Would that be an issue?
12:21:29 <Ariakenom> So not introducing scope. just shadowing
12:21:48 <geekosaur> shadowing *requires* introducing scope
12:22:02 <geekosaur> if you aren't in an inner scope, it's a double/conflicting declaration
12:22:26 <Ariakenom> true. But the where clause implies some scope
12:22:38 <geekosaur> not enough for this
12:23:40 <Ariakenom> really?
12:24:29 <geekosaur> maybe you need to show an example of what ypu're thinking of. (which might demonstrate to you why there are problems)
12:26:29 <Ariakenom> I'll reform the example. maxBound :: a where {forall a; Bounded a}
12:27:44 <geekosaur> so you want to boot constraints to somewhere else than the type? is ConstraintKinds illegal in this system?
12:28:17 <geekosaur> or more to the point, being able to use type synonyms to introduce synonyms for constraints
12:28:38 <geekosaur> work out what ytou can express with this and how it compares to things that actual programs do need to express
12:29:22 <edmundnoble> Moving constraints away from code that uses them in general leads to hidden coupling, never found anything like that to be worth it.
12:32:04 <Ariakenom> I don't want to do anything. I just wanted to think about what could make sense. I guess the where shouldn't be on the type declaration but where the normal where clause is. woops.
12:32:44 <Ariakenom> I was considering this to be the same as (maxBound :: forall a. Bounded a=> a)
13:18:54 <dmj`> glguy: is there a way to peek at the previous and next token? I’m parsing multi-line comments and it’s turning them into 3 tokens in a row. So there is a specific token pattern I’m looking for, of course, it would be nice if alex could lex this all into a single TokenString
13:34:27 <meat_wiggler> with cloud haskell, there's no reason to use erlang anymore right?
13:36:35 <rihards> hey, could anyone take a look at this? https://lpaste.net/4322552977589010432 i'm trying to "bind" constraints in a data constructor and a typeclas function. the comments explain it in a bit more detail
13:38:06 <mniip> rihards, I can't understand what you're trying to achieve there
13:39:03 <rihards> well, i'm sort of creating data which encapsulate some parameters
13:39:33 <mniip> why do you need a typeclass?
13:39:43 <rihards> given such data i can call applyS on it and get a function that works on streams
13:39:51 <mniip> why is RealFloat bound inside the GADT?
13:43:19 <rihards> one of the reasons for the typeclass is that in the full codebase i'm creating an existeantial data type from it so that i can put EdFunctionS in a list. then i basically have a bunch of functions that process a Stream each in some different way
13:45:11 <rihards> RealFloat being bound inside the GADT isn't actually essential i guess. i put it there because i wanted to be able to pass a RealFloat to the process function
13:51:54 <rihards> if this helps make more sense of the code, here's the existential data type i'm using: `data ApplicableS = forall a . EdFunctionS a => ApplicableS a`. given that i can have, say, `runall :: (RealFloat a, Monad m) => [ApplicableS] -> Stream (Of a) m r -> [Stream (Of a) m r]`
13:52:21 <rihards>  (this is something similar to what i actually have but not exactly so i might be messing something up here)
13:57:10 <mniip> that's not how constraints work
13:57:45 <rihards> which part are you referring to?
13:57:53 <mniip> rihards, I suggest you lay the GADTs aside for now and see how you can solve this without them
13:58:40 <mniip> e.g with  data ApplicableS a m r= ApplicableS (Stream (Of a) m r -> Stream (Of a) m r)
13:58:59 <mniip> glguy, so I found a problematic type
13:59:10 <mniip> data T a b = (b ~ Int) => C a
13:59:23 <mniip> then \(C x) -> x  has two types, neither principal:
13:59:26 <mniip> T a b -> a
13:59:29 <mniip> T Int b -> b
14:04:07 <dmj`> glguy: nvm, it was just bad lexing on my part
14:08:14 <mniip> I think the question is whether a determines b
14:09:26 <mniip> i.e in  C :: Ctx => T a b
14:09:57 <mniip> whether (a ~ a', Ctx, Ctx[b \ b']) resolves b ~ b'
14:10:06 <mniip> hmm
14:10:13 <mniip> whether (a ~ a', Ctx, Ctx[a \ a', b \ b']) resolves b ~ b'
14:13:03 <rihards> mniip: ok, thank's for the advice. I don't actually remember why i didn't choose to use a `ApplicableS a m r= ApplicableS (Stream (Of a) m r -> Stream (Of a) m r)`, as you suggest, in the first place. the code has been working fine, though, and it has been getting messy only now when i'm in the process of switching from lists to Streams
14:15:42 <cpn-uml> emacs's global prettify symbols mode renders unit as an empty set
14:15:48 <cpn-uml> what's the reasoning behind that?
14:17:16 <Tuplanolla> That sounds like a misunderstanding, cpn-uml.
14:17:49 <Tuplanolla> It should really be the singleton set, but there's no standard symbol for that.
14:18:30 <mniip> asterisk or blackcircle is kind of that but asterisk is already used in haskell
14:19:43 <Tuplanolla> I guess ⊙ could work.
14:21:17 <mniip> > generalCategory '⊙'
14:21:20 <lambdabot>  MathSymbol
14:21:25 <mniip> maybe
14:22:11 <mniip> glguy, I think ima email goldfire
14:22:13 <__monty__> Empty set sounds right. There's only one empty set but infinite singleton sets, given an infinite domain.
14:23:29 <Tuplanolla> @let data EmptySet = EmptySet deriving (Eq, Ord, Show) -- Here's another one, __monty__.
14:23:30 <lambdabot>  Defined.
14:23:35 <orion> Is there a more idiomatic way of writing this?: fmap (fmap fst) (fmap decimal m)
14:23:39 <fishythefish> well, are you thinking of the unit type or unit value, __monty__?
14:23:42 <Solonarv> Tuplanolla that's not an empty set...
14:24:03 <Tuplanolla> Indeed, Solonarv.
14:24:20 <Tuplanolla> Follow the discussion.
14:24:36 * hackage ghc-exactprint 0.5.7.0 - ExactPrint for GHC  http://hackage.haskell.org/package/ghc-exactprint-0.5.7.0 (AlanZimmerman)
14:25:28 <__monty__> Tuplanolla: That's only a different one up to isomorphism.
14:25:33 <Tuplanolla> The point was that in this context uniqueness should only be considered up to isomorphism.
14:36:15 <__monty__> In the context of syntax conceals?
14:36:53 <Tuplanolla> Let me clear this up.
14:40:07 <Tuplanolla> There is never "only one empty set but infinite singleton sets". If you do not consider things up to isomorphism, then `Void` is distinct from `AnotherVoid` and `()` is distinct from `AnotherUnit`; if you do consider things up to isomorphism, then all empty sets are isomorphic and all singleton sets are isomorphic (because you can always map the sole members to each other).
14:41:09 <fishythefish> also note that we need to be clear about whether we're talking about () as a type or as a value - it's hard to prettify () in only one way while preserving both meanings
14:41:11 <Tuplanolla> Using empty set to stand for the unit type is misleading, because it goes against the typical interpretation of the category of types being morally isomorphic to the category of sets.
14:43:52 <Tuplanolla> If you had to pretty print the thing, then the most sensible solution would be something akin to using ⊙ for the type and ‧ for the value.
14:46:05 <__monty__> I'm not convinced. {} obviously equals {}, {1} obviously doesn't equal {2}. I don't know how to express that in more precise terms.
14:49:27 <__monty__> My intuition is simply based on counting the number of inhabitants over the natural numbers.
14:49:42 <dmwit> orion: It would definitely be idiomatic to combine the first and last fmap, as in `fmap (fmap fst . decimal) m`.
14:49:48 <__monty__> There's only 1 empty set. There's infinity singleton sets.
14:51:01 <fishythefish> there are infinitely many unit types too
14:51:10 <fishythefish> there's only one up to isomorphism
14:51:10 <dmwit> orion: For readability, you might look for more monomorphic names than fmap. Opinions on this vary.
14:51:43 <fishythefish> this is what lets us say "the" unit type
14:54:35 <__monty__> fishythefish: Yes but "the unit value" is obviously isomorphic to the empty set, since there's only one of both. It's obviously not isomorphic to singleton sets even if you can construct an isomorphism between those.
14:54:58 <fishythefish> __monty__: see all of my comments about specifying whether we're talking about () as a value or as a type
14:55:11 <__monty__> If it were then singleton sets would be isomorphic to empty sets and that's ridiculous.
14:55:33 <fishythefish> what does it mean for two values to be isomorphic?
14:55:35 <__monty__> The value is empty set the type is All sets of size 0.
14:59:15 <__monty__> Anyway, feel free to convince me tomorrow. nn peeps
14:59:41 <Tuplanolla> That's my favorite question of the day, fishythefish.
14:59:48 * fishythefish shrugs
15:00:21 <fishythefish> perhaps I should have just said that rendering "const () :: a -> ()" as "const ∅ :: a -> ∅" is problematic and left it at that
15:00:57 <Tuplanolla> This way is more interesting.
15:02:02 <bwe> How can I build a "constrained" type constructor?  https://bpaste.net/show/a91d7e61e0b9
15:02:46 <glguy> bwe: You'll need a new type if you want a type for colors that are only Blue or Red
15:03:47 <bwe> glguy: I want to implement kind of a hierarchy with plenty of these subsets. Is there a better way to do it?
15:04:15 <glguy> No, this isn't something that gets to appear in the types
15:05:02 <glguy> You can approximate it with some GADTs and a bunch of different parameters on the GADT for different subsets, but that's not a serious solution and doesn't scale
15:05:55 <bwe> I felt types would be a nice way to implement that hierarchy.
15:06:05 <glguy> An example of the above would be: http://hackage.haskell.org/package/hoopl-3.10.2.2/docs/Compiler-Hoopl.html#t:Pointed
15:06:22 <glguy> but no, types aren't the places to put arbitrary subsets
15:06:24 <mniip> glguy, I figured out the most general case
15:06:32 <glguy> mniip: OK, what's that?
15:06:34 <mniip> brace
15:06:47 * glguy grabs on
15:06:57 <mniip> if a determines b in the sense that there's a type family F such that C :: (b ~ F a) => a -> T a b
15:07:07 <orion> dmwit: Thank you
15:07:12 <mniip> then for any left section CoF of F
15:07:28 <mniip> \(C x) -> x  can have a type of T3 (CoF (F a)) b -> CoF b
15:07:53 <Tuplanolla> With dependent types you could have `(c :: Colour) -> (c /= Green) -> Product`, bwe.
15:07:55 <mniip> for that to typecheck you need an axiom F (CoF (F a)) ~ F a  which witnesses the section property
15:08:31 <mniip> that type is never comparable with T a b -> a
15:08:37 <Tuplanolla> Haskell doesn't have that, at least until Eisenberg works his magic.
15:08:49 <orion> Does anyone know of a function with this type signature?: (a -> m b) -> (n a -> m n b).
15:09:10 <mniip> orion, that doesn't kind-check
15:09:29 <orion> How did you determine that?
15:09:51 <mniip> a :: *, m :: k -> *, n :: * -> *
15:10:04 <mniip> m :: (* -> *) -> k -> *
15:10:17 <orion> Oh, sorry, you're right
15:10:24 <orion> (a -> m b) -> (n a -> n (m b))
15:10:35 <orion> bah
15:10:38 <orion> (a -> m b) -> (n a -> m (n b))
15:10:39 <glguy> :t traverse
15:10:40 <lambdabot> (Applicative f, Traversable t) => (a -> f b) -> t a -> f (t b)
15:11:27 <bwe> glguy: Where can I learn more about arbitrary subsets?
15:12:03 <orion> glguy: Amazing! Thank you. :)
15:12:17 <glguy> bwe: you can look at the example Pointed type above
15:12:23 <mniip> glguy, I conjecture that when b isn't determined by a, not even locally, there's no useful alternative type
15:12:39 <mniip> "locally" meaning for some subset of the kind 'a' ranges over
15:13:20 <mniip> iow forall a. there exist b b' for which C _ :: T a b and C _ :: T a b'  typecheck
15:14:38 <bwe> glguy: I did so. I want to understand how that works exactly. How is it different from a sum type ... | ...?
15:14:46 <glguy> I've copied your messages into a buffer to save them to understand later tonight. This is more than I can internalize with my normal IRC glance :)
15:14:53 <glguy> mniip: ^
15:15:29 <pikajude> so it seems like haddock can't properly preserve documentation that's reexported from a mixin'd module?
15:17:19 <bwe> glguy: Would you exclude liquidhaskell for my requirement?
15:17:30 <schell> hi all
15:17:35 <srk> how can I flip arguments in this case?  Error <$> getByteStringLen <*> getInt, I need to parse in this order but Error accepts Int first
15:18:01 <Solonarv> have you tried flip?
15:18:09 <srk> hmm :D
15:18:12 <Solonarv> % :i flip
15:18:12 <yahb> Solonarv: flip :: (a -> b -> c) -> b -> a -> c -- Defined in `GHC.Base'
15:19:33 <srk> oh, right
15:19:46 <srk> simple as flip Error <$> getByteStringLen <*> getInt
15:19:55 <srk> thanks
15:20:25 <Solonarv> for more complex cases (e.g. three arguments) there's also ApplicativeDo
15:21:55 <koz_> Solonarv: I actually had a question about ApplicativeDo. How does it 'know' whether osmething can be desugared to applicative instead of monad operations?
15:22:30 <Solonarv> good question, I'm not entirely sure how the algorithm works
15:22:52 <schell> i was recently using StateT (for fresh vars) inside Cofree, building up a Cofree f (m a), then running sequence $ extend  ... and being surprised that my vars were not fresh - they are about as fresh as the branches are long, if that makes sense
15:22:54 <bwe> Tuplanolla: Oh, I just see your answer. Would my situation be a usual case for dependent types?
15:23:12 <schell> is this expected? (obviously i was not expecting it)
15:23:28 <schell> and is this something i would use StoreT for instead of StateT?
15:23:46 <Tuplanolla> I don't know about usual, because I've never seen finance collide with dependent types, but I've used that pattern in Coq, bwe.
15:24:19 <Solonarv> the rule AIUI is that Applicative is enough iff no variables bound by a "<-" statement appear in a subsequent expression *other* than the final return / pure
15:24:41 <koz_> Yeah, that makes sense, because that way, there are no linear deps on results of prior computations.
15:25:01 <koz_> Since Applicatives can't guarantee order liek that.
15:26:38 <Solonarv> with ApplicativeDo enabled, do blocks are desugared using fmap, (<*>), (*>), and join; the usual desugaring uses (>>=) and (>>)
15:28:44 <koz_> Solonarv: I guess this is a good reason for me to enable ApplicativeDo everywhere?
15:28:50 <bwe> Tuplanolla: I'll take a look at coq. Worth a try for a fresher?
15:30:21 <Tuplanolla> Possibly.
15:30:49 <Solonarv> ehhh I'm not sure about that; ApplicativeDo is rather more complicated at compile-time
15:31:03 <Solonarv> https://ghc.haskell.org/trac/ghc/wiki/ApplicativeDo if you want to know more
15:31:12 <bwe> glguy & Tuplanolla: Thanks for your support.
15:31:16 <koz_> Solonarv: In the sense that it takes longer?
15:31:33 <Solonarv> yes
15:31:50 <Solonarv> I don't *think* it's ever worse at run-time than the vanilla desugaring
15:31:51 <hpc> it might also lead to worse generated code if you -O0 or have sufficiently obtuse instances?
15:32:14 <hpc> it'd be marginal
15:32:48 <koz_> So then what's the point?
15:33:07 <Solonarv> letting you use do notation for things that don't *have* a monad instance
15:33:09 <hpc> do error messages get worse?
15:33:50 <koz_> Solonarv: Ah.
15:33:51 <hpc> in terms of learning the language, it makes do-notation more complicated to learn
15:34:12 <hpc> because you can use a subset of it on lots of things, but then you do something that looks correct and bam, it needs Monad now
15:34:13 <Solonarv> the wiki page I linked mentions something about having a more complex algorithm in order to improve error messages
15:34:42 <hpc> i thought for a while GADTSyntax should be the default but someone here made a similar argument and convinced me otherwise
15:36:47 <Solonarv> ApplicativeDo is also useful for some monads which are only morally law-abiding and that are able to parallelize computations using (<*>) but not ones using (>>=)
15:37:49 <Solonarv> i.e. (,) <$> fetchFoo <*> fetchBar can run fetchFoo and fetchBar in parallel, but (fetchFoo >>= \foo -> fetchBar >>= \bar -> (foo, bar)) can't
15:38:25 <Solonarv> without ApplicativeDo it's impossible to use do-notation *and* perform queries in parallel
15:39:12 <Solonarv> A monad like this (Haxl, developed by facebook) was the original motivation for ApplicativeDo, IIRC
15:39:40 <koz_> Solonarv: Oh, OK. INteresting.
15:41:16 <hpc> i didn't know that was the history of it
15:44:14 <benzrf> Solonarv: hmm, couldn't laziness possibly allow parallelism in a monad...? :)
15:44:26 <benzrf> i suppose it would be easy to accidentally fuck that up
15:44:44 <Solonarv> it... kinda does? maybe? depends on the monad
15:45:14 <Solonarv> it definitely can if you use lazy IO but that's not a great idea
16:12:06 * hackage threadscope 0.2.11.1 - A graphical tool for profiling parallel Haskell programs.  http://hackage.haskell.org/package/threadscope-0.2.11.1 (MitsutoshiAoe)
16:12:37 <mniip> hmm never seen the "blow your mind" page on the haskell wiki
16:12:46 <mniip> let's see how good I actually am
16:13:31 <hpc> say what now?
16:15:12 <fishythefish> https://wiki.haskell.org/Blow_your_mind
16:17:49 <mniip> hmm
16:17:53 <mniip> nothing too mindblowing
16:23:33 <Solonarv> "liftM2" - that's when you know you're looking at old haskell...
16:27:19 <jit10> hello
16:28:04 <mniip> Solonarv, I wouldn't lift anything that isn't an M416 these days
16:29:17 <hpc> enumerating the rationals is pretty entertaining
16:34:18 <pikajude> finally, a function that produces all the rationals
16:39:36 * hackage stratosphere 0.24.2 - EDSL for AWS CloudFormation  http://hackage.haskell.org/package/stratosphere-0.24.2 (jdreaver)
16:41:14 <mniip> a completely rational function
16:48:55 <hpc> there was a pretty great thread in /r/math about what you would rename things, knowing modern math
16:49:12 <hpc> someone suggested renaming complex numbers to rational numbers, because complex analysis is so easy
16:49:23 <hpc> the reals should be called complex numbers because real analysis is so hard
16:49:36 <hpc> irrationals should be called imaginary because you can't construct them, etc
16:49:56 <fishythefish> analysis is still called analysis because it tears you a new one
16:50:10 <hpc> :D :D :D
16:50:11 <fishythefish> holomorphicity is a helluva drug though
16:50:39 <hpc> math jokes best jokes
16:51:26 <buttons840> why was 6 afraid of 7?
16:54:54 <hpc> because 6 7 14
16:54:56 <hpc> https://oeis.org/A268448
16:54:58 <hpc> obviously
16:55:22 <dmwit> What did zero say to eight?
16:55:30 <dmwit> "Nice belt."
16:55:46 <buttons840> these math jokes just keep getting better :D
16:56:21 <fishythefish> let ε < 0
16:57:57 <hpc> someone needs to tell schoolhouse rock that it should be "conjunction junction, what's your forall term"
16:58:45 <fishythefish> besides, if you're not sure what the function is, you're probably dealing with a disjunction junction
16:58:52 <hpc> haha
16:59:07 <hpc> my favorite anagram of banach-tarski is banach-tarski banach-tarski
17:00:31 <hpc> fun fact: if you round a hexagon you get a circle, but if you round pi your circle is a hexagon again
17:00:54 <dmwit> What's the volume of a cylinder with radius z and height a?
17:01:04 <dmwit> pizza
17:03:26 <hpc> this one is true: schroedinger was kicked out of oxford for sharing his campus housing with two women
17:04:20 <fishythefish> all of a sudden the wavefunction collapsed and he wasn't sharing campus housing with anyone, huh?
17:05:54 <fishythefish> the pigeonhole principle: if there are n pigeons and n+1 holes, then at least one pigeon has at least two holes in it
17:06:41 * Clint twitches.
17:07:05 <srk> hm, I'm using socket AF_UNIX Stream 0 and it looks like recv wont yield data if the message is all NULLs, is there some socket option for this?
17:07:05 <Rembane> Wild west pigeons.
17:08:14 <hpc> if there are n feet and n+1 socks, none of them match
17:08:44 <fishythefish> hpc: what do you get when you cross some citrus with a bull?
17:09:04 <fishythefish> the trivial lime bundle on a taurus
17:09:10 <hpc> haha
17:09:25 <fishythefish> what's purple and commutative?
17:09:31 <fishythefish> an abelian grape
17:12:13 <nai> hi, i'm learning haskell and was wondering if there's another way to define function composition, rather than  f . g = \x -> f (g x)  , using $ and partial application?
17:13:56 <Squarism> nai \x -> f $ g x
17:13:57 <Squarism> ?
17:14:11 <nai> sorry, i meant "without using a lambda function"
17:14:27 <Rembane> h x = f $ g x
17:14:31 <Solonarv> oh, sure: "(.) f g x = f (g x)"
17:15:00 <nai> ah, but that doesn't satisfy me either. i don't want x to appear
17:15:17 <nai> basically, only an operation on f and g
17:15:26 <hpc> f . g = cheatyRedefineFunctionComposition f g
17:15:30 <Rembane> :D
17:15:35 <nai> stop cheating!
17:15:52 <hpc> (.) = unsafeSolveIRCQuestions
17:16:12 <Rembane> Isn't there a . in the other direction?
17:16:15 <Rembane> :t (&)
17:16:17 <lambdabot> a -> (a -> b) -> b
17:16:20 <Rembane> Hm...
17:16:22 <nai> you can just tell me if there's no way, i won't be offended :'D
17:17:11 <Solonarv> you can probably whip up something using SK calculus
17:17:21 <nai> i was feeling like maybe sticking ($g) or (g$) somewhere might do it
17:17:36 * hackage xmobar 0.27 - A Minimalistic Text Based Status Bar  http://hackage.haskell.org/package/xmobar-0.27 (JoseAntonioOrtegaRuiz)
17:17:37 <nai> but i don't have enough FP experience to come up with it
17:17:38 <hpc> (g $) = g
17:17:49 <nai> hm, that is right
17:17:59 * nai slaps nai
17:18:20 <hpc> i think yeah, you'd have to resort to more complicated definitions like S and K
17:18:26 <hpc> (const and (<*>)
17:18:27 <hpc> )
17:18:38 <nai> i haven't covered that yet
17:18:40 <nai> i'll keep reading
17:19:11 <Rembane> f <> g
17:19:13 <Rembane> should do it
17:19:16 <Rembane> Cheating though.
17:19:36 <nai> clearly seems like cheating :D
17:19:47 <nai> you just replaced the . with something more general i guess
17:19:53 <Rembane> Indeed. :)
17:20:00 <Rembane> :t (<>)
17:20:01 <lambdabot> Monoid m => m -> m -> m
17:20:12 <hpc> oh if we're doing that, just use fmap
17:20:22 <Rembane> hpc: Show us! :D
17:20:30 <hpc> actually, let's be really blatant
17:20:36 <hpc> (.) = (Control.Category..)
17:21:06 <Rembane> A beauty!
17:21:13 <nai> what have i started
17:21:35 <hpc> nai: we were already memeing pretty hard when you joined :D
17:21:46 <nai> ah :D
17:28:38 <OmegaDoug> Does anyone know why Stackage lists the operator <> twice in the Semigroup type class: https://www.stackage.org/haddock/lts-11.16/base-4.10.1.0/Data-Semigroup.html#t:Semigroup
17:28:54 <OmegaDoug> One with a Monoid constraint and one without
17:28:56 <mnoonan_>  the constrained one is a default instance
17:29:39 <mnoonan_> so if m is already a monoid, you can just write "instance Semigroup m" to get the Semigroup instance for free
17:30:26 <hpc> in the source (pasting here because it's super short):
17:30:28 <hpc>   (<>) :: a -> a -> a
17:30:28 <hpc>   default (<>) :: Monoid a => a -> a -> a
17:30:28 <hpc>   (<>) = mappend
17:30:32 <mnoonan_> It would be nice to have some better way of rendering defaults into haddock :|
17:31:00 <pikajude> or reexported modules at all
17:31:10 <OmegaDoug> So when you say it's a default instance it's a default instance for Monoids only
17:32:15 <OmegaDoug> I haven't read much about default instances or how they work so this is a bit fuzzy at the moment
17:32:21 <mnoonan_> yeah, if you try to do "instance Semigroup m" where `m` *isn't* a monoid, you'll get an error
17:32:37 <hpc> OmegaDoug: if you don't write a definition in your instance, it uses the default
17:32:41 <hpc> and if that happens to work, yay
17:36:37 <OmegaDoug> Is there a distinction between writing "instance Semigroup m" when my type is or is not a monoid? I would assume that I can make any valid type an instance of Semigroup. Was there some assumed knowledge in your example I'm missing?
17:37:13 <OmegaDoug> As in I can just write "instance Semigroup m" without the "where" portion
17:41:16 <mnoonan_> right, "instance Semigroup m" is literally *all* you have to write, if you're using the default signatures
17:42:55 <OmegaDoug> That's what I though but wanted to be sure,
17:42:56 <OmegaDoug> Thanks
17:49:43 <mniip> so much to do so much to see
18:05:41 <Solonarv> bah, I just spent half an hour manually translating (.) to SKI and all I got was "occurs check: cannot construct the infinite type t2 ~ t2 -> t3"
18:08:31 <mniip> Solonarv, \f g x -> f (g x)
18:08:38 <mniip> \f g -> S (K f) g
18:08:45 <mniip> \f -> S (K f)
18:08:53 <mniip> S (K S) K
18:09:30 <mniip> :t (pure (<*>)) <*> pure
18:09:31 <lambdabot> Applicative f => (a -> b) -> f a -> f b
18:09:41 <mniip> not sure what your problem was
18:12:16 <Solonarv> I'm not sure either! I ended up with some massive expression completely unlike the actual correct result
18:15:03 <fishythefish> % :t (pure (<*>)) <*> pure @((->) _)
18:15:03 <yahb> fishythefish: (a -> b) -> (w -> a) -> w -> b
18:15:36 * hackage lenses 0.1.8 - Simple Functional Lenses  http://hackage.haskell.org/package/lenses-0.1.8 (JobVranish)
18:16:02 <mniip> Solonarv, ski is dead simple
18:16:53 <Solonarv> in my defense, I was blindly following the reduction rules on wikipedia, and I was using notepad.exe
18:17:53 <mniip> @let data LC v = Var v | Lam v LC | App (LC v) (LC v) deriving (Show, Foldable)
18:17:54 <lambdabot>  .L.hs:159:19: error:
18:17:54 <lambdabot>      • Expecting one more argument to ‘LC’
18:17:54 <lambdabot>        Expected a type, but ‘LC’ has kind ‘* -> *’
18:18:00 <mniip> @let data LC v = Var v | Lam v (LC v) | App (LC v) (LC v) deriving (Show, Foldable)
18:18:02 <lambdabot>  Defined.
18:18:14 <vasiliy_san> Hi all. I've heard that Haskell is good at implementing EDSLs. Which known libraries are implemented as state-of-the-art EDSLs? And probably there are libraries which are not super complicated but rather practical and have a nice interface which leverages Haskell features?
18:18:27 <mniip> @let data SKI = S | K | I | SKI :$ SKI deriving Show
18:18:28 <lambdabot>  Defined.
18:20:23 <mniip> hmm, not quire sure the two are enough
18:21:19 <Solonarv> S and K? SKx is equivalent to I, so you don't need I
18:21:30 <mniip> no I mean the two datas
18:21:37 <mniip> I need a data that is an intermediate representation
18:21:46 <Solonarv> oh, yeah
18:21:59 <mniip> I suppose I know what that could be
18:22:06 <mniip> @let deriving instance Functor LC
18:22:08 <lambdabot>  Defined.
18:28:34 <mniip> @let deriving instance Eq SKI
18:28:35 <lambdabot>  Defined.
18:28:38 <mniip> @let skify :: Eq v => LC v -> SKI; skify = collect . go . fmap Left where go (App f x) = App (go f) (go x); go (Lam v x) = var v (go x); go e = e; var v e | not (elem v e) = App (Var $ Right K) e; var v (App f x) = App (App (Var $ Right S) $ var v f) $ var v x; collect (Var (Right v)) = v; collect (App f x) = collect f :$ collect x
18:28:40 <lambdabot>  Defined.
18:29:17 <mniip> > skify (Lam 'f' (Lam 'g' (Lam 'x' $ App (Var 'f') (App (Var 'g') (Var 'x')))))
18:29:19 <lambdabot>  (S :$ ((S :$ (K :$ S)) :$ ((S :$ (K :$ K)) :$ ((S :$ (K :$ S)) :$ ((S :$ (K ...
18:29:24 <mniip> that's curious
18:29:39 <revskill> What's the best way to override show instance for Maybe ?
18:29:50 <revskill> For example, i want show (Just "a") to be "a"
18:29:55 <revskill> and show Nothing to be ""
18:30:48 <infinisil> revskill: Don't do that preferably
18:31:17 <revskill> i have some Maybe fields in my record, so to render to html, we need to override , right ?
18:31:41 <Solonarv> you don't have to (and in fact probably shouldn't) use show to render html
18:31:47 <infinisil> ^^
18:31:48 <mniip> don't use Show
18:32:05 <revskill> I use Miso
18:32:24 <revskill> text $ Miso.ms (show getPet)
18:32:35 <revskill> pet is Maybe Text
18:32:52 <Solonarv> you see the part where you wrote "show"?
18:32:56 <Solonarv> put a different function there
18:33:27 <Solonarv> @let showMaybe = maybe "" show
18:33:29 <lambdabot>  Defined.
18:33:37 <Solonarv> > showMaybe Nothing
18:33:39 <lambdabot>  ""
18:33:44 <Solonarv> > showMaybe "cat"
18:33:46 <lambdabot>  error:
18:33:47 <lambdabot>      • Couldn't match expected type ‘Maybe ()’ with actual type ‘[Char]’
18:33:47 <lambdabot>      • In the first argument of ‘showMaybe’, namely ‘"cat"’
18:34:23 <Solonarv> @let showMaybe :: Show a => Maybe a -> String; showMaybe = maybe "" show
18:34:24 <lambdabot>  .L.hs:183:1: error:
18:34:24 <lambdabot>      Multiple declarations of ‘showMaybe’
18:34:24 <lambdabot>      Declared at: .L.hs:180:1
18:34:35 <Solonarv> @let { showMaybe :: Show a => Maybe a -> String; showMaybe = maybe "" show }
18:34:36 <lambdabot>  .L.hs:183:1: error:
18:34:36 <lambdabot>      Multiple declarations of ‘showMaybe’
18:34:36 <lambdabot>      Declared at: .L.hs:180:1
18:34:43 <infinisil> > showMaybe $ Just "cat"
18:34:45 <lambdabot>  "\"cat\""
18:34:53 <revskill> Solonarv: Make sense
18:35:06 <mniip> some more fiddling to actually use the I
18:35:44 <Solonarv> you could try traversing the AST and replacing any occurence of SKx with I ?
18:35:49 <mniip> > skify (Lam 'f' $ Lam 'g' $ Lam 'x' $ Var 'f' `App` (Var 'g' `App` Var 'x'))
18:35:51 <lambdabot>  (S :$ ((S :$ (K :$ S)) :$ ((S :$ (K :$ K)) :$ ((S :$ (K :$ S)) :$ ((S :$ (K ...
18:35:58 <mniip> now supposedly,
18:37:25 <mniip> @let redSKI :: SKI -> SKI; redSKI (((S :$ f) :$ g) :$ x) = redSKI ((f :$ x) :$ (g :$ x)); redSKI ((K :$ x) :$ y) = redSKI x; redSKI (f :$ x) = redSKI f :$ redSKI x; redSKI e = e
18:37:27 <lambdabot>  Defined.
18:37:31 <mniip> > redSKI $ skify (Lam 'f' $ Lam 'g' $ Lam 'x' $ Var 'f' `App` (Var 'g' `App` Var 'x'))
18:37:34 <lambdabot>  (S :$ ((S :$ (K :$ S)) :$ ((S :$ (K :$ K)) :$ ((S :$ (K :$ S)) :$ ((S :$ (K ...
18:37:40 <mniip> still the same huh
18:38:52 <mniip> there's no SKx there
18:39:40 <mniip> the problem with skify is it doesn't do eta contraction
18:40:50 <Solonarv> the first clause of your redSKI eats most things that could be SKxy, and doesn't actualy shrink the tree
18:41:37 <Solonarv> ...it does evaluation, not simplification
18:42:12 <mniip> some whitespace had to be sacrificed
18:42:14 <mniip> @let skify::Eq v=>LC v->SKI;skify=collect.go.fmap Left where go(App f x)=App(go f)(go x);go(Lam v x)=var v(go x);go e = e;var v(Var v')|v==v'=Var$Right I;var v e|not(elem v e)=App(Var$Right K)e;var v(App f(Var v'))|not(elem v f)&&v==v'=f;var v(App f x)=App(App(Var$Right S)$var v f)$var v x;collect(Var (Right v))=v;collect(App f x)=collect f:$collect x
18:42:16 <lambdabot>  Defined.
18:42:21 <mniip> > skify (Lam 'f' $ Lam 'g' $ Lam 'x' $ Var 'f' `App` (Var 'g' `App` Var 'x'))
18:42:24 <lambdabot>  (S :$ (K :$ S)) :$ K
18:42:40 <Solonarv> a-ha!
18:43:35 <mniip> > skify (Lam 'f' $ Lam 'g' $ Lam 'x' $ (Var 'f' `App` Var 'x') `App` (Var 'g' `App` Var 'x'))
18:43:37 <lambdabot>  S
18:46:33 <mniip> this is also incidentally a theorem prover!
18:47:06 <Solonarv> how does it prove things?
18:48:02 <mniip> are you familiar with propositional logic?
18:48:18 <Solonarv> yeah
18:48:27 <mniip> A1 :: a => (b => a)
18:48:44 <mniip> A2 :: (a => (b => c)) => ((a => b) => (a => c))
18:49:03 <mniip> a => b,a |- b (MP
18:49:06 <mniip> (MP)
18:51:21 <Solonarv> what I'm asking is "how do you encode a theorem to prove" and "what does a proof look like"
18:51:40 <benzrf> mniip: @letlpaste
18:52:34 <mniip> Solonarv, you give it a proof deduction-style and it gives you an axiom tree
18:52:41 <benzrf> mniip: cute
18:52:44 <Solonarv> oh, I see
18:52:52 <benzrf> too bad hilbert-style sux B)
18:53:02 <mniip> good luck with anything else
18:53:06 * hackage dfinity-radix-tree 0.1.1 - A generic data integrity layer.  http://hackage.haskell.org/package/dfinity-radix-tree-0.1.1 (EnzoHaussecker)
18:53:31 <mniip> which reminds me, quantifiedconstraints sitll broken
18:55:16 <benzrf> rip
18:55:29 <benzrf> mniip: what do you mean by "good luck with anything else"?
19:00:48 <mniip> benzrf, all interesting stuff tends to be incomplete
19:01:09 <benzrf> wait, what does incompletelness have to do with it?
19:01:20 <benzrf> i meant like hilbert style as opposed to something like a sequent calc
19:01:49 <benzrf> also i was being a bit tongue in cheek
19:02:30 <Zemyla> cyberpunk.jpg https://twitter.com/InnerPartisan/status/1016857384571023360
19:02:39 <Zemyla> Wrong channel.
19:02:54 <benzrf> lol
19:07:24 <Welkin> Zemyla: Why is every word capitalized!!?!
19:09:20 <Zemyla> Because it was made by a middle-age middle manager.
19:09:47 <monochrom> I was reading Gulliver's Travel and almost every noun was capitalized.
19:09:47 <fresheyeball> is there a Word type that is isomorphic to Float?
19:10:07 <monochrom> which is consistent with what Zemyla just said. :)
19:10:27 <monochrom> ObHaskell: Why is every noun (aka data constructor) capitalized? >:)
19:11:28 <Welkin> aren't all nons capitalized in german?
19:11:31 <Welkin> nouns*
19:12:09 <Welkin> also, types and data constructors don't need to be capitalized, but that is the convention chosen by the designers of the language
19:12:28 <Welkin> however, look at the mess that is ocaml types because they are lowercase instead
19:12:49 <fresheyeball> ok this is weird, how can I store a Float in Postgresql with beam
19:12:56 <Welkin> I like how in lisp/racket everything can be lowercase
19:13:38 <Zemyla> I'm pretty sure Postgresql has a Float type.
19:14:06 * hackage finite-typelits 0.1.4.2 - A type inhabited by finitely many values, indexed by type-level naturals.  http://hackage.haskell.org/package/finite-typelits-0.1.4.2 (mniip)
19:15:27 <monochrom> Better than being allowed to be lowercase.  If you want to (let [(x*x+4 (+ (* x x) 4)] ...) just go ahead.
19:15:53 <monochrom> Like, there is really no better name than "x*x+4" for this.
19:16:39 <monochrom> Of course the price is that the whole language syntax is consistently prefix.
19:16:45 <Welkin> yeah that too, having symbols in function names
19:17:10 <Welkin> html->string, for example
19:17:15 <Welkin> that is common
19:17:24 <Welkin> instead of, in Haskell, htmlToString
19:18:06 <monochrom> Yeah, that one completely solves the Haskell community problem of "should I call it fromList, toSet, listToSet, setFromList, fromListToSet, or toSetFromList?"
19:18:34 <mniip> and the worst package mantainer of the day badge goes to
19:22:49 <monochrom> and "pure->impure" completely solves our dilemma of "why is it called pure instead of impure?"
19:22:50 <Welkin> monochrom: there is a way to make functions infix (at least in racket) by wrapping it in dots (.)
19:22:51 <monochrom> Interesting. Like (1 .+. 2)?
19:22:51 <benzrf> yeh
19:22:51 <Welkin> I think so, it's been a while since I read that part of the language guide and I don't recall ever using it
19:26:19 <monochrom> Oh haha for Racket I can start a religious war on "should it be html->string or string<-html?"
19:26:48 <monochrom> I'm a genius!
19:27:25 <Welkin> or just `->html`
19:33:02 <jackdk> a language isn't mature until it has a few active holy wars
19:34:35 <marxS> hi
19:35:52 <jackdk> hi marxS, don't feel like you have to wait for a response to a "hello", just open with your questions/thoughts. A "hi, has anyone..." combines politeness with the request, if that's your jam
19:36:06 <marxS> im not here to ask any questions
19:36:15 <marxS> just lurking to try and learn from some of the ongoing (or future) conversations
19:36:19 <iqubic> What are the haskell holy wars?
19:36:23 <marxS> and maybe provide some input if I can
19:36:37 <jackdk> cool beans
19:37:09 <Welkin> iqubic: monad transformers
19:37:24 <iqubic> What's the war there?
19:37:34 <iqubic> What are the opposing sides?
19:38:12 <Welkin> there are none
19:38:22 <Welkin> people just like to complain
19:38:52 <Welkin> there were many attempts at making something better, but they all failed
19:43:38 <Solonarv> I guess there's type families vs. fundeps, but that seems pretty well settled in favor of fundeps
19:49:00 <iqubic> I thought people still used type families.
19:49:23 <suzu> i use type families
19:50:04 <suzu> Welkin: nah i am a warrior in the haskell holy war
19:50:15 <suzu> i think freer effects are better than trans
19:50:45 <pdxleif> Lots of the libs I use use type families
19:51:27 <pdxleif> I thought the war was "strict vs lazy"?
19:53:56 <Solonarv> oh I was talking specifically about MTL
19:55:18 <Solonarv> i.e. `MonadReader e m | m -> e where ...`  vs. `MonadReader m where type ReaderEnv m :: *`
20:00:46 <pdxleif> thank god there's an enum instance for ()
20:00:54 <pdxleif> so I can write stuff like:
20:00:57 <pdxleif> > [()..()]
20:01:00 <lambdabot>  [()]
20:01:07 <pdxleif> Everything else on that instance throws an exception.
20:01:11 <benzrf> lol
20:01:37 <benzrf> [()..()] is a cute lil bus
20:02:36 <pdxleif> You get an infinite list of units with [(),()..()], but not with [()..]
20:02:59 <thebnq> > maxBound::()
20:03:01 <lambdabot>  ()
20:04:10 <pdxleif> > mempty :: ()
20:04:12 <lambdabot>  ()
20:06:05 <pdxleif> honestly why do we even need any other types - unit has it all.
20:07:15 <thebnq> I think thats the formalization of dynamic typing
20:08:29 <pdxleif> Well, in dynamic typing, you have a ton of values that all have the same type. Here, we've got one value that has one type.
20:11:10 <thebnq> true, I was just thinking of the type
20:22:56 <mniip> Monoid is cool but check *this* out
20:22:58 <mniip> % GHC.Generics.from ()
20:22:58 <yahb> mniip: M1 {unM1 = M1 {unM1 = U1}}
20:26:24 <Solonarv> % :t GHC.Generics.from ()
20:26:25 <yahb> Solonarv: GHC.Generics.D1 ('GHC.Generics.MetaData "()" "GHC.Tuple" "ghc-prim" 'False) (GHC.Generics.C1 ('GHC.Generics.MetaCons "()" 'GHC.Generics.PrefixI 'False) GHC.Generics.U1) x
20:39:50 <mniip> so a little haskell quiz for yall
20:40:30 <mniip> what would  typeOf (Proxy :: Proxy (() :: Constraint))  show
20:44:23 <dreamer_> what is the most convenient way to use case of in IO when you don't care about the result ?
20:44:47 <dreamer_> I usually do that https://lpaste.net/8819886999293919232
20:44:52 <dreamer_> but it feels weird
20:45:03 <dreamer_> because when you use let ... you have to indent like crazy
21:03:42 <blankhart> in your example idc has type ()? so really you are just pattern matching on var and executing dothing1 or dothing2. the do block is redundant because you could write someIO SMTH = dothing1...etc.
21:03:53 <vasiliy_san> dreamer_: https://lpaste.net/77071508794507264
21:09:35 <vasiliy_san> dreamer_: if you want to discard results then you can use `void` function https://pastebin.com/YKBzQDiK
21:10:03 <dreamer_> my exemple is too simple sorry
21:31:37 <jchia> What can I do to fix "sequence_ $ zipWith8 doSomething v1 v2 v3 v4 v5 v6 v7 v8"? There is no zipWith8 for vectors, and for lists, it goes up to only zipWith7. The vectors are vectors simple scalars or simple scalar lists, like Int32, Bool and [Int32].
21:34:01 <rotaerk> jchia, implement zipWith8
21:34:51 <cocreature> you could combine two zip4 with a zipWith
21:35:41 <geekosaur> note that zipWith is something of an obvious Applicative
21:35:59 <geekosaur> although you proabbly lose out on some vector optimizations
21:36:45 <cocreature> or you just can’t use it because Unboxed vectors are not Applicative iirc
21:36:54 <jchia> cocreature: Is there a concise way to convert a "f :: (a -> b -> c -> d -> ... -> h -> r)" to a "f' :: ((a ->.. -> d) -> (e -> .. -> h)) -> r)?
21:37:29 <cocreature> that looks wrong, I think you want to convert it to (a,b,c,d) -> (e,f,g,h) -> r
21:38:00 <cocreature> I would just write the plain old boring conversion function
21:38:15 <jchia> geekosaur: Yes, I suppose I could use a a straightforward doSomething <$> v1 <*> v2 <*> ... I'll have to check whether the performance is a real problem.
21:38:31 <jchia> cocreature: Yeah, the r should be outside.
21:38:32 <geekosaur> except cocreature just noted there's no Applicative instance :(
21:38:56 <jchia> geekosaur: I'm using boxed vectors
21:39:53 <rotaerk> I would just implement zipWith8, using the same mechanisms that all the standard ones are implemented with
21:40:00 <rotaerk> although it looks like it goes a few layers deep
21:41:07 <jchia> rotaerk: With vector, it's quite deep
21:41:48 <cocreature> heh, it looks like vector already implements zipWith6 as two zip3s
21:42:33 <rotaerk> Data.Vector.zipWith6 = Data.Vector.Generic.zipWith6
21:43:00 <cocreature> it’s on some lower layer
21:43:14 <cocreature> iirc it was in the implementation that uses the bundle stuff
21:43:30 <rotaerk> which is based on Data.Vector.Fusion.Bundle.zipWith6, which is based on Data.Vector.Fusion.Bundle.Monadic.zipWith6
21:44:16 <rotaerk> and that's based on zipWithM
21:44:35 <rotaerk> oh yeah zipWith6M is based on two zip3s
21:59:46 <jchia> Actually, I need to apply (ZipList . toList) to each vector if I want to take the applicative approach. Otherwise I get a cartesian product.
22:00:26 <cocreature> hm, I would have hoped that there is a ZipVector newtype but that doesn’t seem to be the case
22:38:48 <sras> Can someone take a quick look at a short video https://youtu.be/cwUzDjgaI1c,  that shows how I use a python script to control a running ghci instance to get live errors in neovim editor?
22:40:16 <sras> I have also added subtitles so if you have trouble understanding what I am saying, please enable them.
22:54:00 <cocreature> sras: reminds me of the ghcid integration available for neovim
23:04:06 <sras> cocreature: One thing that I like about this setup is that it can work if you can get 'stack ghci' working for your project. So there is no issues caused be version incompatibilities..Which is not the case with ghcid and similar things, IIRC
23:05:43 <cocreature> sras: I don’t think that’s true. ghcid is literally a wrapper around ghci so if you can get ghci working, ghcid works as well
23:08:53 <dataN> a -> (a -> (forall b. (a -> b) -> b)))
23:09:11 <dataN> ?
23:11:05 <dataN> actually; a -> (a -> (forall b. (p => a -> b) -> b)))
23:11:48 <dataN> to make the return type of a function satisfy some constraint
23:14:36 <sras> cocreature: You seem to be right. I must have been thinking of something else. hdevtools perhaps..
23:15:21 <dataN> nope, maybe; f -> (f -> (forall b. (p => a -> b) -> b))
23:16:11 <dataN> where 'f :: ... -> ... -> a' is implied, possibly...
23:17:17 <dataN> sorry that :: should be an =
23:22:12 <sras> cocreature: Have you used ghcid? how is your experience with it?
23:23:18 <cocreature> sras: I use ghcid all the time and it works great for me! but I have not used the neovim integration (because I don’t use neovim)
23:23:25 <cocreature> I just have it run in a separate window
23:41:25 <sras> cocreature: I just tried ghcid.  Some how it does not update when I make a change to the files.
23:41:51 <sras> cocreature: I tried it in the stack repo, and the command I used was just "ghcid"..
23:44:18 <cocreature> sras: maybe try ghcid -c "stack ghci"
23:45:34 <sras> cocreature: I also tried this, ghcid --command="stack ghci src/main/Main.hs"
23:46:17 <glguy> Could be that it's targeting the library and not the executable?
23:46:28 <glguy> Or the other way around
23:47:20 <sras> cocreature: Works now. Looks like the file I was editing was not included in the build. But it works with the Python script. Not sure what is different...
