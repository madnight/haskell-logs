00:02:07 --- mode: adams.freenode.net set +v sclv_
00:02:07 --- mode: glguy set -v sclv_
00:08:35 --- mode: ChanServ set +o glguy
00:08:57 --- mode: glguy set +v isacl_
00:08:58 --- mode: glguy set +v cyjiao
00:08:59 --- mode: glguy set +v typetetris
00:19:29 <MarcelineVQ> Hey you, yeah you reading this right now, have a gander at https://en.wikipedia.org/wiki/Type_theory it's pretty short and you'll probably find something interesting to explore.
00:19:45 <Ariakenom> no
00:20:29 <MarcelineVQ> If you believe in me I promise that all your wildest dreams will come true.
00:22:17 --- mode: glguy set +v randP
00:22:20 <randP> how do i solve this https://lpaste.net/3862518257420337152
00:23:00 <lingeeal> Hi, is ghcjs not maintained anymore? The last commit has almost a year ago.
00:23:28 <MarcelineVQ> lingeeal: check the other branches if you haven't
00:28:42 <lingeeal> Right, branch ghc-8.4 has the latest activity (5 months ago). Why do people prefer contributing/using different languages like purescript or elm? Isn't it nicer to be able to share the code between server and client. For ocaml/bucklescript seems a very nice way to start doing things. Ghcjs seemed to have started long time ago, but does not seem to attract as much contribution as I would have thought
00:30:33 <dmj`> lingeeal: ghcjs is still good, most stable is probably, ghcjs 7-10.3, some regressions have been introduces since ghcjs-8_x
00:31:11 <dmj`> s/introduces/introduced
00:31:23 <dmj`> lingeeal: yes, sharing types is best imo. 
00:32:16 <dmj`> lingeeal: contributing to GHCJS isn’t too trivial, it uses the GHC api to emit STG, and then converts this to javascript, and links with its own runtime system. If we had a better GHCJSi, I think adoption would pick up, and reinstated stack support. 
00:36:02 <lingeeal> dmj`: I see. Another big problem is that it introduces its own runtime, which will probably always be bigger that the competitor to->js compiled languages, right?
00:37:45 <dmj`> lingeeal: it’s not too bad tbh, most large scale javascript projects are MBs anyways. GHCJS’s code is made for google closure compilers ADVANCED_OPTIMIZATIONS
00:37:53 <dmj`> lingeeal: the rts.js is 536K
00:38:46 <dmj`> lingeeal: When you do things like pre-rendering (isomorphic js), and gzip the static assets, it’s a lot smaller, and caching. You can obviate the entire cost. Plus, these days, people download movies on their phone, so. 
00:39:36 <lingeeal> Right :)
00:40:06 <lingeeal> great that it uses google closure compiler, didn't know that
00:41:16 <dmj`> lingeeal: this site is fully ghcjs, https://haskell-miso.org/ and google chrome’s audit shows 100% on performance, best practices and SEO
00:42:24 <lingeeal> nice
00:42:30 <dmj`> lingeeal: this site is also 100% ghcjs (miso), and highly interactive, it has a 86-90% performance rating.
00:42:33 <dmj`> https://www.polimorphic.com/
00:42:57 <lingeeal> would you then recommend doing js part of web app with ghcjs instead of purescript? :)
00:43:51 <dmj`> lingeeal: yes, it’s all about type sharing. Having a single cabal file and a nix script that invokes two different ghc’s to both build and deploy your site feels like the future.
00:44:45 <lingeeal> I really dont get why all those new frameworks focus so much on single page apps only, not some kind of middle ground approach. Or you download the app.js and start rendering 100% of your apps logic in browser or you use the server side rendering without using those frameworks
00:44:58 <dmj`> lingeeal: you can share everything, the views, the model, the helper functions, types, even some IO. Everything except browser specific IO.
00:45:35 <lingeeal> dmj`: is there some repo with a small template project that includes nix, yesod and ghcjs?
00:46:13 <lingeeal> Right, I also see this as an inmense value.
00:46:41 <lingeeal> Sharing the stuff all around and writing the same language
00:46:49 <Ariakenom> ghcjs can do some native-web mix too right?
00:47:02 <dmj`> lingeeal: most pure javascript frameworks are extremely small, especially with the rise of the micro virtual dom movement. They load so fast that pre-rendering isn’t worth it. 
00:47:17 <dmj`> lingeeal: https://github.com/dmjio/miso/tree/master/examples/haskell-miso.org is all the source for https://haskell-miso.org
00:47:27 <dmj`> lingeeal: this is good as well, https://github.com/y-taka-23/miso-tutorial-app
00:47:34 <dmj`> lingeeal: or this https://github.com/FPtje/miso-isomorphic-example
00:47:52 <dmj`> lingeeal: native web mix?
00:48:07 <dmj`> lingeeal: oh like react-native?
00:48:30 <Axman6> koz_: what do you mean sequentially?
00:48:33 <lingeeal> dmj`: but rendering all the stuff in the browser will never be as SEO friendly as rendeering in server
00:49:01 <Axman6> (argh, I was scrolled up, oops)
00:49:09 <dmj`> lingeeal: well, try curl’ing https://haskell-miso.org the views are shared on the client and server. So google bots get their html and your site gets ranked. Otherwise, you have to rely on google bots indexing your javascript
00:50:16 <dmj`> lingeeal: single page apps that don’t share the view just show <html><head><script src=/path/to/server/all.js></head><body></body></html> which will bootstrap the app once the js loads, but this HTML isn’t good for SEO obviously
00:50:35 <lingeeal> exactly
00:50:45 <lingeeal> those are the single page apps im familiar with
00:51:24 <dmj`> lingeeal: yea, well with miso you can even share a router. And we just discovered a very fast way to perform diffing using some GHC tricks
00:53:13 <dmj`> lingeeal: basically, its an optimization technique to safely perform pointer equality to bypass Eq’ing models, and view generation altogether.
00:53:33 <lingeeal> so, I have a doubt about that you were mentioning. Then does https://haskell-miso.org/ render html in server and attaches js written in ghchjs? Or is it some single page app that is able to prerender views in server?
00:55:35 <dmj`> lingeeal: so you write some haskell code (view = div_ [] [ text “hey”), then you compile this for both client and server. So now you have a binary, and some javascript. You run the binary web server, point your browser at it, the browser receives the HTML, populates the DOM, it then sees the javascript tag, fetches your ghcjs app, the ghcjs app notices the DOM already exists, so it traverses the DOM, copies the pointers...
00:56:03 <dmj`> into the virtual dom, then begins listening on events, and your application proceeds as normal without any initial DOM mutation.
00:56:56 <dmj`> *the browser sees the javascript tag
00:57:11 <koz_> Axman6: Sorry, what was this in reference to?
00:59:01 <dmj`> lingeeal: it’s important to note the browser fetches the javascript asynchronously, so the DOM is populated and the user can look at the screen w/o any delay waiting for a few MBs of js to load.
01:00:52 <Axman6> koz_: you asked about Folds being run sequentially, but that might have been a very long time ago :)
01:01:14 <koz_> Axman6: Ah. I figured it out: F.fold F.whatever is just a function.
01:01:19 <koz_> So you can just compose them.
01:01:21 <lingeeal> dmj`: right, which is why I dont like that mainstream single page apps only have one line in html (fetch app.js and rendering it in this div). This is not SEO friendly at all.
01:01:22 * koz_ should have guessed.
01:07:04 <dmj`> lingeeal: I agree, but some would argue that Google’s bots now crawl javascript
01:11:13 <dmj`> lingeeal: Google’s bots are better at indexing html than js I’d say.
01:15:10 --- mode: glguy set +v randN
01:20:10 <randN> i have a fnc :: (Some x y) -> ... when i call fnx it cannot resolve y and for Some i only need x is there a way to solve this or it's not possible at all ??
01:27:28 <dmj`> randN: can you paste your code and the error into lpaste.net
01:35:37 <randN> dmj' : https://lpaste.net/3862518257420337152
01:37:07 <randN> dmj` : https://lpaste.net/3862518257420337152
01:37:23 * dmj` looks
01:42:30 <noan> a compiled haskell appliaction is generally statically linked into a single binary blob right? (inherently portable)
01:42:33 <dmj`> randN: first let me ask, what are you trying to accomplish
01:43:03 <dmj`> noan: no, call ldd on it
01:43:30 <ventonegro> noan: GHC normally links all Haskell libraries statically, but not system ones
01:43:31 <noan> dmj`, cheers
01:43:53 <randN> dmj` : nothing really was trying to learn things and came up with this and now wondering if it works like if you have multiple contraints
01:44:09 <noan> trying to reason about how to compose a docker container for a haskell application XD
01:49:25 <mpickering> cabal.project files + git dependencies are just awesome
01:53:35 <dmj`> noan: there are some haskell docker images, you can build your project inside of it. Or if you like to live on the edge and your CI server is the same architecture (and OS) as your docker image then you could copy the binary in
01:54:09 <noan> dmj`, yeah, I was originally considering a copy, but the dynamic linking has me going NAH
01:55:22 <dmj`> yea, in general I wouldn’t recommend statically linking because glibc doesn’t do well with it, you’d need something like alpine linux and musl. There might be docker containers for that. 
01:55:32 <dmj`> s/containers/images
01:55:41 <randN> dmj` : so can it be solved ? 
01:55:47 <aleator> Quick question: If I copy&paste the source of List.sum to my own module and benchmark it with -O2, it is 2.5 times slower than sum from Data.List. Any ideas why thing like this would happen?  (I'm making an example for my course..)
01:56:18 <noan> dmj`, yeah, I'll just build it inside the container. I was feeling minimalist but it's not worth it
02:00:35 <Axman6> aleator: probably better inlining, and specialisation
02:02:01 <aleator> Axman6: It's not inlining, since it is fold' which is not inside anything. It is polymorphic though, so specialization might be it. Are there any other factors than specialize pragma that would affect this?
02:02:26 <dmj`> randN: you need to provide concrete types for the arguments to mkHandler, since they are typeclass methods, GHC can’t infer which types you’re referring to. Also, the definition of AppM2 is recurisve, is that intentional?
02:02:38 <dmj`> noan: sweet
02:04:29 <randN> dmj` : yep that's intentional 
02:05:44 <randN> dmj` : there's no way to have abstract arguments to mkHandlers because then i can't have typeClass design that i have rn 
02:09:37 <Axman6> aleator: go look at the Core and the assembly:)
02:09:51 <trcc> Hi guys, I am trying to obtain a FunPtr from a C struct passed to haskell. It is testStructFunPtr. The FunPtr is the same used in testFunPtr, which is working. My issue is with peek in instance Storable CbFuncs. Anyone available for assistance? 
02:11:15 <cocreature> trcc: I’m not following. what’s CbFuncs, testStructFunPtr and testFunPtr?
02:11:29 <trcc> Ah forgot the gist, sorry! https://gist.github.com/CThuleHansen/40e8852907d03b1ba4bdaf0531ea2735
02:11:30 <trcc> haha
02:12:04 <cocreature> trcc: that looks like you just forgot to import Foreign.Storable
02:12:39 <cocreature> or to add peek to the import list of Foreign as the error message suggests
02:12:42 <trcc> haha
02:12:46 <trcc> cocreature: thank you
02:13:01 <cocreature> the suggestions that GHC provides are at least worth a look, they tend to be helpful quite often :)
02:13:58 <trcc> Yes, I received as much as peek was not available. But the suggestion of adding peak to the import list puzzled me. Should I import foreign.peek or?!
02:14:47 <trcc> if file A imports module B, does it then import the imports of module B?
02:14:51 <trcc> module A*
02:14:56 <cocreature> trcc: "import Foreign (Ptr, FunPtr)" imports only the symbols Ptr and FunPtr from the Foreign module
02:15:03 <cocreature> if you add peek to that list, it will also import peek
02:15:11 <trcc> and then I do not need to import Storable?
02:15:12 <cocreature> so change it to "import Foreign (Ptr, FunPtr, peek)
02:15:13 <cocreature> "
02:15:18 <cocreature> right
02:15:31 <cocreature> Foreign reexports Foreign.Storable so importing one of them is sufficient
02:16:19 <trcc> if I do import Foreign - do I then import all of foreign? e.g. Foreign.C.Types as well?
02:17:11 <dmj`> trcc: only this is re-exported, http://hackage.haskell.org/package/base-4.12.0.0/docs/Foreign.html
02:17:30 <trcc> dmj`: ahh so it depends on the given module
02:17:44 <trcc> thank you
02:23:26 <trcc> cocreature: follow-up question: f `ap` x = f >>= \g -> x >>= \y -> return (g y) (https://www.mjoldfield.com/atelier/2014/01/monads-algebra.html). Then why must I do return in the peek implementation? 
02:23:54 <trcc> ahh nvm
02:23:57 <trcc> got it. I think
02:30:05 <randN> can this be solved without having concrete types https://lpaste.net/7072844506877394944 
02:38:19 <trcc> dmwit: thank you for answering my question as well. Did not know about that lamdabot feature to view messages! cool!
02:39:56 <c50a326> why is list's Alternative implementation of <|> = (++) ?
02:41:09 <c50a326> I thought it might be something like: l1 <|> l2 = case l1 of; [] -> l2; _ -> l1
02:41:38 <c50a326> mplus and <|> are (++) it seems
02:42:30 <noan> dmj`, the haskell8 image is 3 gigs lol
02:47:21 <Taneb> c50a326: the idea is the [] monadplus is a list of possibilities
02:47:25 <byorgey> c50a326: conceptually I think it comes from the "replacing failure by a list of successes" point of view
02:48:00 <byorgey> c50a326: but in general there may be multiple valud instances
02:50:24 <c50a326> thanks... and what is all this stuff about "left-bias" and "right-bias" ?
02:50:59 <byorgey> c50a326: which stuff?
02:51:27 <byorgey> s/valud/valid/
02:51:29 <c50a326> well I was just reading this https://chplib.wordpress.com/2010/05/05/choose-anything-adding-an-alternative-instance/ from this https://mail.haskell.org/pipermail/haskell-cafe/2010-June/079282.html and I'm sure I've come across this kind of talk before, about left and right
02:51:35 <c50a326> I don't think they used the word "bias" before though
02:51:43 <c50a326> I think it was more about parsing from the left
02:52:40 <dmj`> noan: heh, sounds about right
02:53:25 <byorgey> c50a326: left- vs right-bias has to do with which of two alternatives is chosen if both would succeed
02:53:41 <byorgey> c50a326: the list instance of Alternative does not have any bias since it chooses everything that succeeds.
02:54:02 <c50a326> ah yeah so like in the Maybe instance, that's got a clear left bias, claro
02:54:03 <byorgey> but most instances have a bias (mostly left-).
02:54:07 <byorgey> right
02:54:14 <byorgey> I mean, correct.
02:54:18 <c50a326> lol :D
02:59:51 <noan> dmj`, yeah that shit aint gonna fly for me
03:02:32 <dmj`> noan: should be a one time cost, layers get cached.
03:03:10 <noan> I suppose that would be the disc footprint, not the memory one
03:07:19 <noan> my problem is currently I'm using tavisci so layer caching would be nonexistent in the continually re-provisioned instances
03:09:36 <dmj`> noan: could use nix, deploy to bare metal ;) 
03:12:25 <c50a326> huhhh... can't find mplusIO on any Hoogle O.o
03:12:33 --- mode: glguy set -v typetetris
03:12:49 <c50a326> weird, it's right here http://hackage.haskell.org/package/base-4.12.0.0/docs/src/GHC.IO.html
03:29:23 <cocreature> c50a326: you’re looking at the source. that doesn’t mean that it’s exported
03:35:55 <EvanR> clear
03:35:58 <EvanR> oops
03:38:02 <Ariakenom> "clear" wow rude
03:38:45 <Rembane> Soon the channel's heart will restart
03:39:10 <Ariakenom> %kill
03:39:11 <yahb> Ariakenom: Done
03:39:15 <Ariakenom> eZ
03:41:11 <Rembane> :(
03:41:20 <Rembane> You'll never get a job in the ER.
03:41:56 <Ariakenom> "Have you tried turning it off and on again?"
04:33:29 <the_2nd> I have a type that can be combined similar to Monoid, but where order matters
04:33:41 <the_2nd> is there a type class for that, or do I just define my own?
04:34:13 <the_2nd> a <> b != b <> a
04:34:14 --- mode: glguy set +v hpc
04:34:19 <hpc> ah
04:34:30 <hpc> Monoid doesn't have that either
04:34:38 <hpc> it has (a <> b) <> c = a <> (b <> c)
04:34:56 <Ariakenom> (using != like that implies they're always different)
04:35:03 <hpc> this voice thing is confusing too, i thought i was registered
04:35:21 <the_2nd> so there's no built-in class for that, is there?
04:35:33 <hpc> thi: Monoid should already work for you
04:35:40 <hpc> the_2nd: rather
04:35:59 <the_2nd> ah I'm silly
04:36:07 <the_2nd> no idea why I thought that was required
04:36:16 <the_2nd> since for ++ order matters as well
04:36:24 <the_2nd> but it's still Monoid
04:36:43 <the_2nd> it was nice chatting then ;D
04:37:17 <Ariakenom> % msum ["Hello ", "world"]
04:37:17 <yahb> Ariakenom: "Hello world"
04:38:01 <Ariakenom> % asum ["Hello ", "world"]
04:38:02 <yahb> Ariakenom: "Hello world"
04:55:42 <joehh> is there a way to serve up my haddock docs on a website?
04:56:16 <__monty__> joehh: I've seen haddocks served on github, so I'm gonna go with yes.
04:57:24 <joehh> :)
04:57:25 <hpc> hooray for existence proofs
04:57:52 <hpc> although if you wanted to give a really trolly answer, you would have cited hackage :D
04:58:08 <joehh> ideally I'd also have all dependent packages available
04:58:14 <joehh> true
04:58:31 <hpc> iirc the output of haddock is just static html
04:58:47 <hpc> you just have to make sure you're building documentation for all the packages you want, and then copy those files
04:58:57 <hpc> maybe edit some absolute urls depending on where you're hosting
04:59:18 <joehh> I can do it by running cabal haddock, but the links for all the dependencies go into lots of local files (nix store in my case)
04:59:37 <__monty__> joehh: Here's where I saw it: https://woehr.github.io/open-adt/open-adt-tutorial-1.0/Data-OpenADT-Tutorial.html So just have a look-see how they did it : )
04:59:51 <joehh> great thanks
05:00:26 <joehh> they seem to have all dependencies hosted there too :)
05:25:28 <bollu> https://lpaste.net/2687581742591639552 
05:25:38 <bollu> Could someone tell me where my haskell implementation doesn't match the C implementation?
05:25:41 <bollu> I get different answers
05:25:59 <bollu> (change 100000000 to 200 in the C code and you get different answers)
05:28:48 <Ariakenom> % maxBound :: Int
05:28:48 <yahb> Ariakenom: 9223372036854775807
05:29:58 <heaven> % maxBound :: Integer
05:29:59 <yahb> heaven: ; <interactive>:10:1: error:; * No instance for (Bounded Integer) arising from a use of `maxBound'; * In the expression: maxBound :: Integer; In an equation for `it': it = maxBound :: Integer
05:30:31 <Ariakenom> % maxBound :: Word8
05:30:32 <yahb> Ariakenom: 255
05:37:26 <Ariakenom> bollu: I would suggest explicit int sizes like Int64
05:39:59 <bollu> Ariakenom You think overflow is the problem?
05:40:08 <bollu> I don't think so, because it's just running on 200 values right now
05:40:20 <Ariakenom> No, I don't think it's a problem
05:40:54 <bollu> Yeah, I don't care about perf right now, I want correctness :) 
05:41:42 <Ariakenom> I didn't suggest it for performance
05:42:08 <bollu> Then
05:42:09 <bollu> ?
05:44:18 <mlehmk> I just wonder why you translate C code like 1:1 into Haskell code
05:44:38 <Ariakenom> It was for correctness. It may break when you change size
05:45:57 <delYsid> bollu: intToBool = toEnum
05:46:23 <delYsid> bollu: And, are you sure you just want to test bit 0?
05:47:43 <cocreature> yeah it isn’t obvious to me that it is fine to treat the char as if it has only two values, i.e., represent it by a boolean
05:47:44 <Ariakenom> intToBool = (/=0)
05:47:45 <delYsid> er, forget that about toEnum.  But the testBit question still stands
05:50:35 <ScriptRunner> Ho 
05:51:28 <ScriptRunner> Hi, everyone. I've got a question what is the best way of splitting a list based on a delimmiter, using only standard prelude functions? Thanks for any help.
05:51:30 <Ariakenom> Christmas isn't _that_ close
05:51:54 <ScriptRunner> Ariakenom: That was my sloppy typing :-(
05:52:29 <Ariakenom> I was trying real hard to be funny
05:52:34 <cocreature> bollu: if I replace the Bool by a Word8 to actually reflect what the C code is doing I get the same result
05:52:37 <c50a326> how can I understand how `many` and `some` work? they seem to be defined circularly? I guess the `many_v = some_v <|> pure []` works as a break/exit condition on the right side?
05:53:15 <Ariakenom> ScriptRunner: splitAt https://www.haskell.org/hoogle/?hoogle=a%20%2D%3E%20%5Ba%5D%20%2D%3E%20(%5Ba%5D%2C%5Ba%5D)
05:53:39 <Ariakenom> n owait
05:53:52 <Ariakenom> That doesn'
05:53:56 <Ariakenom> t match
05:54:25 <Ariakenom> c50a326: Do you know parser combinators? Or regex?
05:54:45 <c50a326> Ariakenom: I'm learning parser combinators, that's why I'm looking at it
05:54:59 <Ariakenom> what about regex?
05:55:01 <delYsid> c50a326: if some_v doesn't match at all, return an empty list
05:55:19 <bollu> cocreature oh, hm
05:55:30 <bollu> cocreature thanks!
05:55:35 <delYsid> I am fascinated by Alternative, <|> is something nice.
05:55:39 <c50a326> Ariakenom: not via Haskell, only in the same way most everyone knows of regex
05:55:51 <bollu> cocreature Oh my god, I'm so retarded, For some reason, in my head, I replaced "1 byte" with "1 bit"
05:55:54 <bollu> thanks a TON!
05:56:22 <cocreature> heh :)
05:56:46 <Ariakenom> c50a326: many and some are analogous to * and +
05:57:18 <c50a326> yeah I pretty much understand what they do, I've used them in ghci
05:57:19 <delYsid> bollu: you're welcome :-)
05:57:26 <c50a326> it's just the way they're written that's a bit confusing
05:57:28 <bollu> delYsid: thanks :D 
05:57:33 <Ariakenom> ah ok
05:57:37 <c50a326> is there a name for this where the functions call kind of circularly?
05:57:42 <c50a326> maybe something like "circular recursion" ?
05:57:53 <c50a326> and are there other examples of this kind of thing?
05:58:05 <cocreature> mutual recursion
05:58:12 <cocreature> even/odd are another classical example
05:58:41 <delYsid> c50a326: https://en.wikipedia.org/wiki/Mutual_recursion
05:58:49 <cocreature> even 0 = True; even n = not (odd (n - 1)); odd 1 = True; odd n = not (even (n - 1))
05:59:07 <cocreature> eh remove the "not"
05:59:13 <cocreature> I should think about what I’m typing :)
05:59:41 <cocreature> and the basecase for odd is screwed up
05:59:46 * cocreature starts crying
06:00:18 <delYsid> I was thinking just recently, are there any Haskell projects to get program synthesis or at least hole filling into GHC?  The example that came up is suggesting flip.
06:00:19 <Ariakenom> odd doesn't need a base case, right?
06:00:35 <bollu> cocreature how did you convert the Int to Int8?
06:00:36 <max3> trying to install intero
06:00:37 <max3> https://paste.rs/4XN
06:00:48 <cocreature> even 0 = True; even n = odd (n - 1); odd 0 = False; odd n = even (n - 1)
06:00:53 <cocreature> bollu: fromIntegral as usual
06:01:20 <Ariakenom> oh it does
06:01:31 <max3> is this happening because i have the wrong resolver for my the new stack project i created in order to compile all of this stuff?
06:01:49 <bollu> cocreature is it "fast"?
06:01:56 <bollu> Ah, nvm, I'll just read the Core and find out ;) 
06:02:11 <dmj`> ScriptRunner: https://gist.github.com/dmjio/4e3ce5c25ac003133c63ec93fe1f2114
06:02:27 <cocreature> bollu: fromIntegral has a bunch of rewrite rules so hopefully yes
06:02:46 <bollu> I see
06:02:49 <ScriptRunner> Ariakenom: It has to spit at a certain string so - f ",," "this is,, a very, nice thing" = ["this is", " a very, nice thing"]
06:04:52 <dmj`> > splitOn "," "hey,there"
06:04:54 <lambdabot>  ["hey","there"]
06:05:01 <dmj`> ScriptRunner: not like this?
06:08:54 <delYsid> I wrote a function yesterday where I am not sure if this can be done with primitives, or if it should be written out like that. https://blind.guru/BDB.hs  Can this be done with composition of standard functions without loosing perf?
06:09:56 <the_2nd> how can I derive a Show instance later on?
06:10:21 <max3> how do i use stack solver to solve my build problem?
06:10:21 <the_2nd> within the type definition file I can't define the Show instance of a member, but later on I can
06:10:33 <the_2nd> so how can I basically delayed do a deriving Show ?
06:10:36 <max3> i don't undestand. i added my deps to stack.yaml and stack solver just tries to delete them again 
06:10:58 <dmj`> the_2nd: you should be able to add deriving (Show) to the type, what’s keeping you from doing that
06:11:02 <dstolfa> the_2nd: instance Show Foo where ...
06:11:27 <dmwit> delYsid: sortOn, then groupBy, then ap zipWith tail ?
06:11:54 <the_2nd> dmj`, within the file there's no Show instance for a field of it (is added in an Instances file later)
06:11:59 <dmwit> delYsid: In fact, you can probably get even better efficiency by extending the decorate-undecorate bracket to include both the sort and the group operation.
06:12:09 <the_2nd> dstolfa, that forces me to actually implement it?
06:12:14 <dstolfa> the_2nd: well, yes.
06:12:15 <dmj`> the_2nd: did you define this type or is this type from a library elsewhere that you’re depending on
06:12:42 <the_2nd> dmj`, my own, but since its instance is rather complex, I'd like to not have it within my Types file
06:13:39 <dmj`> the_2nd: that will cause an orphan instance. An orphan is when the class, instance and type are all defined in different modules. I think you should define the Show instance for your type at its definition site (along with all other instances as well).
06:14:58 <the_2nd> that would work fine as long as instances don't need other logic
06:15:14 <dmwit> :t \f -> ap zip tail . map (map snd) . groupBy ((==) `on` fst) . sortOn fst . map (\x -> (f x, x))
06:15:15 <lambdabot> Ord a => (b -> a) -> [b] -> [([b], [b])]
06:15:21 <the_2nd> I often have Types.hs with definitions and deriving
06:15:43 <the_2nd> then possibly files with some first layer logic
06:16:02 <dmwit> the_2nd: StandaloneDeriving
06:16:02 <the_2nd> then Instances using logic in those files to implement Monoid etc
06:16:31 <delYsid> dmwit: Thanks, i'll have to study that, not very familiar with ap
06:17:02 <dmwit> the_2nd: With StandaloneDeriving you can even avoid the orphan problem, e.g. `deriving instance Show MyField => Show MyNewTypeThatUsesMyField`
06:17:21 <dmwit> ?quote zip`ap`tail
06:17:21 <lambdabot> quicksilver says: zip`ap`tail - the Aztec god of consecutive numbers
06:17:36 <dmwit> > ap zip tail [1..]
06:17:39 <lambdabot>  [(1,2),(2,3),(3,4),(4,5),(5,6),(6,7),(7,8),(8,9),(9,10),(10,11),(11,12),(12,...
06:17:52 <dmj`> the_2nd: oh, that would be fine. If you defined helper functions for the instances elsewhere, sure. You probably will hit a circular dependency problem though.
06:17:56 <Ariakenom> reader ap is invaluable for code golfing
06:18:30 <the_2nd> I'll move the complex show instance to the Types file
06:18:37 <the_2nd> seems to be the lesser evil
06:18:45 <dmwit> the_2nd: (I mean, because standalone deriving lets you say what the context for your instance is, you can put as-yet-nonexistent instances in the context.)
06:19:05 <mlehmk> what about [1,2,3,4,5,6...] -> [(1,2),(3,4),(5,6),...]?
06:19:18 <dmwit> > transpose . chunksOf 2 $ [1..]
06:19:20 <lambdabot>  [[1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,5...
06:19:28 <dmwit> oh, lol
06:19:33 <dmwit> > chunksOf 2 [1..]
06:19:35 <lambdabot>  [[1,2],[3,4],[5,6],[7,8],[9,10],[11,12],[13,14],[15,16],[17,18],[19,20],[21,...
06:19:42 <mlehmk> good enough
06:20:22 <dmwit> the_2nd: I don't understand "lesser evil". Doesn't my proposal avoid all the evils you've mentioned so far? No orphans needed, no code restructuring needed, no hand-written code needed.
06:20:28 <mlehmk> I think I could \(x:y:[]) -> (x,y) myself
06:20:38 <dmwit> mlehmk: needs a recursive case
06:21:05 <mlehmk> > fmap \(x:y:[]) -> (x,y) $ chunksOf 2 [1..]
06:21:07 <lambdabot>  <hint>:1:6: error: parse error on input ‘\’
06:21:14 <dmwit> Oh, I see.
06:21:19 <mlehmk> uhm... I don't do that much Haskell
06:21:30 <dmwit> > (\[x,y] -> (x,y)) <$> chunksOf 2 [1..]
06:21:32 <lambdabot>  [(1,2),(3,4),(5,6),(7,8),(9,10),(11,12),(13,14),(15,16),(17,18),(19,20),(21,...
06:21:48 <mlehmk> ahh, yes <$> being just fmap ... $
06:21:59 <dmwit> Yes. But the real difference is that I added parentheses.
06:22:06 <mlehmk> I thought about that
06:22:07 <dmwit> (Around the lambda.)
06:22:18 <Ariakenom> > (\[x,y] -> (x,y)) <$> chunksOf 2 [1,2,3]
06:22:20 <mlehmk> and you've written (x:y:[]) more readable as [x,y]
06:22:20 <lambdabot>  [(1,2),*Exception: <interactive>:3:2-16: Non-exhaustive patterns in lambda
06:22:48 <ScriptRunner> dmj`: sorry for the long wait, thank you for helping, exactly as you described, where you used a comma any string could be passed.
06:22:59 <mlehmk> Could add the Maybe monad into play
06:23:15 <delYsid> :t \f -> ap zip tail . groupBy ((==) `on` f) . sortOn (Down . f))
06:23:16 <lambdabot> error: parse error on input ‘)’
06:23:18 <dmj`> ScriptRunner: ok, did you see the code snippet I gave above?
06:23:26 <delYsid> :t \f -> ap zip tail . groupBy ((==) `on` f) . sortOn (Down . f)
06:23:28 <lambdabot> Ord a1 => (a2 -> a1) -> [a2] -> [([a2], [a2])]
06:23:41 <delYsid> thats it
06:23:43 <dmwit> delYsid: Right, equivalent. But calls f more.
06:23:51 <dmwit> Well, equivalent to what I wrote, anyway.
06:24:09 <delYsid> oh
06:25:16 <bollu> to profile a haskell application, one must rebuild the universe? o_O
06:25:43 <dmwit> delYsid: Actually, I think there's a small wrinkle in in my ap zip tail vs your go.
06:25:49 <dmwit> bollu: yep
06:25:54 <mlehmk> bollu, to properly profile haskell to C, you'd have to profile writing the project from scratch as well
06:26:00 <the_2nd> dmwit, data Outer { inner :: Inner } |||| data Inner {...}
06:26:11 <dmwit> delYsid: Specifically, yours returns the "first group" plus "the entire rest of the list". Mine returns "the first group" and "the second group".
06:26:13 <mlehmk> see, which is faster to implement, then check the runtime of the separate implementations
06:26:23 <the_2nd> I tried Outer ... deriving instance Show Inner => Show Outer     
06:26:35 <the_2nd> but get parse errors on "instance" already
06:26:39 <delYsid> dmwit: You forgot the Down in the sortOn, but thats minor
06:26:48 <mlehmk> I'd guess that of mathematical algorithms, the Haskell implementation is faster, cleaner and with less bugs than the C approach
06:27:01 <mlehmk> faster meaning faster in development
06:27:03 <dmwit> the_2nd: Read the docs. Anyway the deriving clause must be standalone -- on its own line, not part of the data declaration.
06:27:13 <delYsid> dmwit: ah, yeah.  I actually need the rest, and not the next group
06:27:25 <dmwit> delYsid: But this infelicity (whole rest of the list vs. just two groups) is easy: use `tails` instead of `ap zip tail`.
06:27:35 <mlehmk> A simple dumb C -> Haskell translation doesn't do Haskell any good
06:27:43 <dmwit> delYsid: Then you not only get the rest of the list, but also the grouping of the rest of the list. More structure is better, right? =)
06:28:24 <delYsid> dmwit: not sure, I need to do a isInfixOf search, so I need to de-do the structure anyway.
06:29:17 <the_2nd> dmwit, I think I got it. Do you know the person maintaining that wiki page? XUndecideableInstances  has a typo
06:29:18 <delYsid> But thats, this was informative.  I'll keep my handrolled function for now since it is easier to read (at least for me, now)
06:29:30 <the_2nd> XUndecid[]ableInstances
06:29:41 <dmwit> :t \xss -> [(xs, concat xss') | xs:xss' <- tails xss]
06:29:42 <lambdabot> [[a]] -> [([a], [a])]
06:29:56 <dmwit> delYsid: ^
06:30:14 <dmwit> the_2nd: No idea what wiki page you're even talking about.
06:30:34 <dmwit> But... it's a wiki. So the answer is probably "nobody" and also "fix it yourself". ;-)
06:30:51 <the_2nd> dmwit, I somehow thought you linked it to me, sorry
06:31:54 <cocreature> I demand that we make dmwit personally responsible for maintaining all wiki pages
06:32:03 <the_2nd> aye
06:32:37 <the_2nd> and to figure out which page I mean
06:33:33 * dmwit gropes around in his backpack for his old, discarded scrying devices
06:35:57 <dmwit> delYsid: Anyway I think your hand-rolled implementation is fine. I would adopt the extended-decoration approach, but otherwise fusing list functions manually when you don't trust the compiler is understandable, I think.
06:36:17 <dmwit> delYsid: And drop that crappy Down. If it's wanted, the caller can put it in the function they pass. =)
06:36:40 <delYsid> What do you actually mean with "extended-decoration approach"?
06:38:17 <dmwit> Use `map (\x -> (by x, x))` before the sort, and only erase the extra parts of the tuple after you've done your grouping. This way `by` will be called once for each element of the input list instead of twice for each and three times for some.
06:39:29 <delYsid> I see.
06:40:48 <delYsid> That could even help to reduce runtime (right now, about a day :-)
06:40:49 <dmwit> ...unless you think calling `by` an extra time will be cheaper than creating and destroying a tuple, I guess. Seems unlikely.
06:41:11 <delYsid> by = Text.length
06:41:17 <delYsid> (in my case, at least)
06:41:25 <Ariakenom> O.o a day
06:41:46 <delYsid> Ariakenom: with +RTS -N, I actually never managed to complete a run without that :-)
06:42:10 <dmwit> Okay. Text.length's documentation says it's O(n), so if your texts are long it could help.
06:42:25 <delYsid> max 20 or so
06:42:30 <Ariakenom> Oh right because unicode
06:43:10 <dmwit> Ariakenom: ?
06:43:19 <delYsid> one day, I will realize this code is all crap and could have run in a few minutes.
06:44:15 <Ariakenom> ByteStrings have fast length but text does unicode-points length
06:44:21 <Ariakenom> I assume
06:44:22 <dmwit> I don't have enough expertise to predict whether building and destroying a tuple is faster or decoding 20 characters is faster.
06:44:23 <delYsid> we're talking about https://github.com/mlang/wikiwordfreq BTW.
06:45:19 <delYsid> ok, I sort of assumed (without checking, stupid me) Text.length is O(1), so I'll definitely adopt this trick dmwit
06:45:23 <dmwit> Ariakenom: I still don't see what "unicode points" has to do with it. I think you mean to blame using a variable-length encoding, but even then the data structure could just store the length inside.
06:46:48 <Ariakenom> I just assumed it was constant because bytestring. Didn't think it was different. Ofc it could still have been stored
06:47:03 <bollu> If I want to use stack with the GHC LLVM backend, is there some easy way to do this?
06:47:10 <bollu> (does GHC ship with LLVM by default now? )
06:47:29 <cocreature> no it doesn’t but I think it should be sufficient if llc and opt are in your PATH
06:47:47 <dmwit> delYsid: Why isn't this whole program just Data.MultiSet.fromList?
06:47:54 <bollu> mniip you have successfully nerd sniped me, BTW :( I'm investigating that example of yours, and I see a 3x-5x slowdown on doing the "straightforward thing"
06:47:54 <cocreature> and if they aren’t there are some options for passing the path explicitely but I don’t remember them so you need to look at the user guide
06:47:56 <bollu> cocreature ty
06:47:58 <bollu> OK, will do
06:48:05 <delYsid> Last time I tried this, it complained about not being able to detect my LLVM version, while I had 5.0 installed on Debian.
06:48:14 <dmwit> delYsid: Even if you need parallelism, you can use Data.MultiSet.fromList on chunks and then Data.MultiSet.union them together at the end in the usual MapReduce style.
06:48:14 --- mode: glguy set +v Boarders
06:48:16 <delYsid> probably something about executable naming (version suffix)
06:48:30 --- mode: glguy set -v Boarders
06:48:51 <Boarders> If you have a multi-line type can that cause a parse error on a haddock comment next to it?
06:48:56 <delYsid> oh, I didn't know MultiSet
06:51:12 <Boarders> (oh nevermind, I needed to put the haddock annotation after the whole type...)
06:51:17 <dmwit> Boarders: Comments generally do not cause parse errors. But I have a guess: you thought you wrote a comment, but wrote an infix operator instead because you didn't put a space after the `--`.
06:52:33 <Boarders> dmwit: I did something like this: https://lpaste.net/19163572844101632
06:52:47 <Boarders> with correct bracketing and so on
06:52:48 <dmwit> delYsid: Actually, if MultiSet meets your needs, you might even want to look into using a trie instead. They are generally faster for key-value stores than Data.Map when the keys are text.
06:52:55 <Boarders> but I didn't put it after the whole type
06:52:59 <bollu> "%ln8P0 = ptrtoint i64* %ln8OZ to i64" :( ptrtoint = AA feels sad
06:54:08 <bollu> cocreature: is the LLVM dumped by `-ddump-llvm` before or after optimisation?
06:54:11 <cocreature> bollu: as a first step, remove the MutVar and just write a recursive function that passes around a parameter (or use StateT if you want to)
06:54:19 <cocreature> before afaik but I might be misremembering
06:54:27 <bollu> cocreature is that better or worse in terms of performance?
06:54:35 <delYsid> dmwit: I killed the Trie idea so far, since I want proper unicode isAlpha, so Text is the way to go AFAICS.  But using a Trie would mean I need to encode all keys to ByteString, which seems pretty wasteful
06:54:40 <cocreature> bollu: MutVar is worse
06:54:47 <bollu> cocreature why?
06:54:49 <dmwit> Boarders: Could not reproduce. This works fine for me: https://lpaste.net/4531532286482448384
06:55:04 <Boarders> oh hmm
06:55:06 <bollu> cocreature oh, because we're pointer chasing instead of neatly passing something?
06:55:10 <cocreature> exactly
06:55:12 <dmwit> delYsid: Why would it mean that?
06:55:20 <cocreature> afaik GHC will never promote a MutVar to something passed in a register
06:55:23 <bollu> mh, thinking about haskell perf from a C mindest is weird
06:55:26 <bollu> yeah, that makes sense
06:55:33 <Boarders> does it work if you have brackets before the Maybe dmwit?
06:55:38 <bollu> I need to think of Hask -> STG -> ASM -> perf
06:55:49 <cocreature> bollu: the parameter passing looks almost like ssa which you might like :)
06:55:54 <bollu> yeah, true
06:55:57 <bollu> :) 
06:56:01 <dmwit> Boarders: If by brackets you mean `(`, yeah, sure, works fine.
06:56:04 <bollu> Let me do that and see if I get a performance boost
06:56:11 <Boarders> how weird
06:56:29 <dmwit> Boarders: Time for an MCVE. I'm sticking with my stated guess.
06:56:46 <Boarders> the spacing was correct
06:57:08 <Ariakenom> bollu: It's not that weird to avoid mut. Consider SSA.
06:57:11 <Boarders> I literally just copied the line and put it after the type and it fixed the parse error
06:57:25 <Boarders> idk
06:57:40 <Boarders> I'll see if I can re-produce when I get a second
06:57:59 <bollu> Ariakenom Indeed, but SSA is usually compiled into something mutable :P One does not copy phi node values, for example. But this "pointer chasing" versus "pack into the closure", I guess.
06:59:18 <Ariakenom> bollu: You dont copy you assign registers. Which doesn't mut either
06:59:32 <bollu> Ariakenom what do you mean?
06:59:55 <cocreature> bollu: parameter passing can end up with that parameter being passed in a register
07:00:03 <bollu> cocreature yeah
07:00:09 <cocreature> so it’s really not that different from SSA here
07:01:13 <Ariakenom> I like this ladder (C-mut, SSA-nomut, x86-mut, register renaming-nomut)
07:01:39 <Ariakenom> 2 of these are interfaces :p
07:02:54 <bollu> xD
07:03:22 <bollu> Ariakenom: do you work on GHC/LLVM/compilers?
07:03:47 <Ariakenom> Did do my masters on compilers. Otherwise an amateur
07:03:53 <bollu> Ahh, cool
07:06:16 * ski idly wonders whether SSA can have an explicit operation for forgetting the value of a register
07:07:11 * Ariakenom glances at -offtopic rant
07:07:32 <Ariakenom> ski: But why? You can't change a SSA anyway
07:08:17 <ski> it might perhaps help with lifetimes stuff
07:08:22 <ski> just a random thought
07:08:27 <ggole> You can mark last uses
07:08:31 <ski> ok
07:09:12 <ggole> Instead of SSA representing that in the IR, it's usually calculated during liveness analysis
07:09:51 <Ariakenom> A name being to "Drop". Can do it in rust
07:09:59 <ski> (if we have a branching structure, with a common join point, then if one branch forgets the value of a register, arguably all branches should then forget the value of that register. obviously it's another thing if one of the branches ends by looping back)
07:10:50 <ski> sometimes in lambda-calculus stuff, it's nice to consider an explicit operation `forget x in <expr>', where `x' is considered a free variable of this expression, but is not available for (free) use in `<expr>'
07:11:03 <ggole> Remember there are thing like early return which mean a value can be dead on one path much earlier than on other paths, even when there are no cycles
07:11:49 <ggole> I think Rust's non-lexical lifetimes thingy is a bit like that?
07:11:53 <ski> (one could consider it as a meta-operation, like substitution, instead of as syntax. Paul Taylor does this is "Practical Foundations to Mathematics", and he wants this to be explicit, in order to be able to discuss adjunctions to this forgetting operation)
07:11:54 <ggole> Anyway, I'm way off topic here.
07:11:57 <bollu> Mh, why do I keep seeing `primitive` in my performance report? Shouldn't that have been inlined away?
07:12:39 <bollu> I would have expected to see "IO"
07:12:42 <cocreature> bollu: profiling messes with optimizations. you probably want to enable cost centres explicitely instead of relying on one of the automatic cost centre insertions if you really want to dig into the details
07:12:49 <bollu> ah
07:13:00 <bollu> cocreature link to something that teaches me how to do this?
07:13:09 <cocreature> read the user guide on profiling :)
07:13:10 <ski> ggole : hm, any pointer or short explanation of "Rust's non-lexical lifetimes thingy" ?
07:13:26 <bollu> :) OK
07:13:46 <cocreature> you can also use ticky ticky profiling but then you will have to read the stg to figure out what the results mean
07:13:52 <Ariakenom> I believe it was Swift and their SIL lower language that had arguments to basic blocks instead of phi-nodes. Which makes it look a lot like lambda calculus.
07:13:53 <Boarders> does anyone know a resource that talks about the precedence of type constructors (mostly just ->), or where it is in the language report?
07:14:00 <Boarders> can't seem to find it by googling
07:14:42 <ski> Ariakenom : nice
07:15:21 <ski> (Apple language ?)
07:15:42 <ggole> ski: instead of there being a single point at which a lifetime ends, you can end it early in some paths
07:15:56 <geekosaur> precedence doesn't really apply as such, and the language report in particular doesn't know ghc's type level language which is rather more complex than standard haskell
07:16:31 <glittershark> wjjkj
07:16:31 <ski> ggole : ah. sounds like what i was thinking about, yes
07:16:54 <ggole> Ending 'lifetimes' early is useful in rust because they use those for controlling mutation, not just when to call free
07:17:08 * ski is also reminded of that in Erlang (and Prolog,Mercury) you can instantiate/bind/define a variable in all branches of a `case', and then use it afterwards
07:17:09 <Ariakenom> ski: Snoyman had a recent blog where he used drop to demonstrate safe file closing https://www.snoyman.com/blog/2018/10/raii-better-than-bracket-pattern
07:18:06 <ski> that not related to Swift, right ?
07:18:14 <Ariakenom> No but non-lexical lifetimes
07:18:51 <ski> ok, ty
07:21:21 <davr0s> so haskell has strict execution option as well,right,
07:21:53 <davr0s> after seeing LambdaCube, i'm wondering if it's viable to describe functions (via some system of wrappers) that could be compiled to C with control over memory aswell
07:22:12 <davr0s> like saying "here's a calculation that will actually map to an inplace update, strict"
07:22:14 <geekosaur> not really. there's an extension btu it doesn't actually turn haskell into a strict language --- and you pretty much can't use the prelude or libraries with it because they all are built with and expect laziness.
07:22:30 <glittershark> davr0s: have you seen spj's talk on linear haskell?
07:22:32 <davr0s> (whilst being able to develop the peices experimentally with lazy eval)
07:22:35 <davr0s> not yet
07:22:41 <glittershark> you'd enjoy it
07:22:51 <davr0s> i've heard vaguely of linear types but dont remember details
07:23:03 <ggole> Linearity doesn't really give you control of memory
07:23:06 <Ariakenom> % let x :: Void#; x = undefined; in () -- strict :D
07:23:06 <yahb> Ariakenom: *** Exception: Prelude.undefined; CallStack (from HasCallStack):; error, called at libraries/base/GHC/Err.hs:78:14 in base:GHC.Err; undefined, called at <interactive>:14:21 in interactive:Ghci12
07:23:08 <Boarders> is there any way to make hlint work better with record wild cards e.g. I get this suggestion
07:23:12 <ggole> It still seems quite useful though
07:23:16 <davr0s> ok
07:23:17 <glittershark> linearity is part of it I think
07:23:18 <Boarders> https://lpaste.net/3780317810350096384
07:23:32 <glittershark> the idea of "prove that this can be compiled to an in-place update" probably requires linearity
07:23:50 <davr0s> what i'm imagining at the moment is : writing a big high-order functino that says
07:24:02 <Ariakenom> glittershark: You can just use ST
07:24:18 <glittershark> well sorta
07:24:19 <dmwit> Boarders: What's bad about that suggestion?
07:24:25 <davr0s> runThisStrictOnThisMutableArrayInPlace array   function
07:24:47 <cocreature> davr0s: are you looking for ST?
07:25:05 <davr0s> and then even more advanced versions with things like filters (update the array size), scatter gather (permuting as you go) or 'source/dest' separation
07:25:12 <davr0s> whats ST 
07:25:33 <davr0s> again i have no project in mind here
07:25:46 <davr0s> if i want to do real work.. C++,    even Rust is more viable if i need this right now but..
07:25:54 <davr0s> .. i'd like to know how far this can go
07:25:57 <cocreature> ST allows you to work with things like mutable arrays locally while presenting a pure API to the outside world
07:25:58 <Boarders> dmwit: the names introduced by the binding are those used in the record
07:26:03 <dmwit> Boarders: ...and?
07:26:13 <davr0s> cocreature right , it would be like that
07:26:15 <Boarders> dmwit: maybe I am being really dumb
07:26:27 <ScriptRunner> dmj`: Yeah I saw the snippet thank you. I didn't understand the code, so was looking into it further.
07:26:30 <davr0s> 'it's going to mutate, but only internally'
07:26:40 <cocreature> that’s exactly what ST gives you :)
07:26:42 <Boarders> dmwit: I was being really dumb
07:26:43 <Boarders> sorry
07:26:52 <dmwit> ^_^
07:26:57 <davr0s> and that's basicall what rust is like , with an unsafe{} back-door that's easy to preclude with a build script
07:27:19 <ski> > let x :: Bool; !x = undefined in ()
07:27:21 <lambdabot>  *Exception: Prelude.undefined
07:27:31 <davr0s> project wide you just have to audit unsafe{} to check any mutation/side effects are sane.
07:27:48 <davr0s> i must say after haskell rust looks fugly
07:27:56 <ski> glittershark : linearity, or uniqueness
07:28:03 <ski> (not the same thing)
07:28:08 <davr0s> thats an exageration but.. it defintely stabs you in the eye a bit. But it is the best model for me
07:28:48 <davr0s> part of it's unavoidable because all that markup is how it guarantees whats going on
07:29:07 <ski> Boarders : hlint suggestions should sometimes be taken with a grain of salt. you can consider them, but there may be a sound reason to deviate from them
07:29:15 <davr0s> but some of it is avoidable - they dont want any 'inter-function' inference, and they make you copy out the full signatures in 'trait impls' (class instances)
07:29:31 <Ariakenom> % let f x = (undefined :: Void#)
07:29:31 <yahb> Ariakenom: 
07:29:42 <Ariakenom> % let x = f () in () -- ski
07:29:42 <yahb> Ariakenom: *** Exception: Prelude.undefined; CallStack (from HasCallStack):; error, called at libraries/base/GHC/Err.hs:78:14 in base:GHC.Err; undefined, called at <interactive>:17:12 in interactive:Ghci13
07:30:03 <davr0s> and i do have tasks/interests for which GC is viable,even superior.
07:30:11 <ski> Ariakenom : strict language enabled in yahb ?
07:30:35 <Ariakenom> % :t f -- no just an annoying type
07:30:36 <yahb> Ariakenom: p -> Void#
07:30:40 <ski> hm, no, just unboxed
07:30:46 * ski nods
07:31:39 <ski> cocreature : being able to do update-in-place stuff, with "pure syntax", like in Clean would be nice
07:33:29 <ski> (Clean is "the other lazy functional language". it didn't get merged in when Haskell was designed, because they wanted to experiment with uniqueness typeing. Mercury also allows "pure update-in-place", using uniqueness modes)
07:34:15 <cocreature> ski: that’s one of the goals of linear Haskell
07:34:16 <ski> (hm, i wonder whether one could do quicksort with SPJ's linearity system ..)
07:35:05 <ski> cocreature : mm, i was just commenting on the `ST' suggestion, which imho doesn't fit the "pure" bill
07:35:36 <cocreature> well it does present a pure API to the outside
07:35:49 <cocreature> here’s the array API that you can make using linear Haskell https://arxiv.org/pdf/1710.09756.pdf#subsection.2.2
07:36:06 <ski> which is all well and good. but sometimes we'd like more, if possible :)
07:39:06 <ski> cocreature : one thing i'm not that happy about, for that API, is that you get back the array as a result, when reading
07:40:00 <ski> it would be nicer if one could express that (in terms of uniqueness) one passes a unique reference to an operation, which reads it, but doesn't consume it, so that one can go on to use the same reference afterwards
07:40:08 <cocreature> I actually like that. that makes the code where you pass around an array look just as if you pass around any other type
07:40:19 <ski> (Mercury has that in its design, but iirc they never got around to make the support for that complete)
07:40:29 <Athas> It just requires nasty alias analysis.
07:41:05 <Athas> I have implemented uniqueness types for in-place updates in a type system, and it's probably not something I'd do again.  The rules are substructural/nonsyntactic, which are awkward to reason about.
07:42:05 <ski> let's say we want to read at two distinct indices. then with `let (ar1,!x) = read ar0 i; (ar2,!y) = read ar1 j in ..ar2..x..y..' we're over-sequentializing the computation
07:42:37 <ski> an implementation would have to realize that it can actually commute these two reads, if it wanted them in the other order
07:43:36 <ski> Athas : elaborate on what you mean by "The rules are substructural/nonsyntactic" ?
07:44:20 <Ariakenom> But you do have to sequentialise it wrt writes. Which introduces a non-data ordering on declarations?
07:44:42 <Athas> ski: a value 'x' is not just of type 't', it is of type 't and also it aliases this set of other variables in scope'.
07:46:16 <Athas> Or 'type t but you cannot use it anymore because it consumed (possibly through an alias)'.
07:46:56 <Athas> I think some linear type systems, like the one proposed for GHC, adresses the aliasing issue with a purely syntactical occurs-analysis, but that can be very inflexible.
07:47:12 <Ariakenom> my last comment was wrong
07:48:40 <ski> Athas : *nod*, so not just type, but also (definite) instantiation state info
07:49:09 <ski> (whether you regard that as part of the type, proper, is probably a matter of taste)
07:49:34 <Athas> Yeah, it's not even clear what "type" means!
07:50:02 <ski> in Clean, uniqueness is part of type. in Mercury, it isn't (they have additional mode/inst info. also determinism info)
07:50:06 <Athas> The usability issues are not trivial.  Monads, on the other hand, are notationally cumbersome, but predictable.
07:50:22 * ski nods
07:50:29 <Athas> Algebraic effects seem to be a good middle ground, but I don't have enough experience to say for sure.
07:50:44 * ski has ideas about (possibly) improving the cumbersomeness situation
07:50:56 <ski> yea, those are interesting
07:51:11 <ski> but i'd like an approach which can handle continuation effects
07:53:19 <ski> Ariakenom : yes, for writes (but still data dependency ordering, as you say)
07:54:40 <ggole> The monadic approach is pretty much a linearisation of the data dependency graph
07:54:53 <ski> indeed
07:54:53 <ggole> If you squint it looks a bit like three-address code, actually
07:55:19 <ggole> So presumably there is a design in which the compiler does most of that
07:55:51 <ski> so, if we're introducing an alternative, it would be nice to be able to get away from over-specialization of sequencing, to the extent attainable (with reasonable constraints on complexity of system ..)
07:56:14 <ski> (an alternative, in the case of state monads, to be specific)
07:58:08 <ggole> You still want the effects to be manifest in types, though - otherwise you've got an impure functional language
07:58:35 <ski> yep -- or at least in static information, whether that being part of types or not
07:59:13 <ski> also, you'd want some kind of syntactic salt to warn you about presence of effects or side-effects .. apart from the static information
07:59:50 <ggole> Yeah, it's nice to know what can change underneath you and what can't.
08:00:23 <ski> in Mercury, there is uniqueness for doing I/O. but there's also a separate notion of impure operations (and semipure, which can read mutable stuff, but not change) -- *every* call to an impure operation has to be preceded by `impure'
08:01:04 <ski> (and it also is contagious, surrounding code gets infected, `impure' turning up in the static interface .. unless you insert a `promise_pure' proof obligation at some point)
08:01:29 <ski> (`impure' is mostly intended for FFI stuff, before you wrap in-language with a more declarative interface)
08:01:46 <ggole> Hmm, that seems pretty strict
08:02:08 <ggole> It's common for effects to be limited to regions, eg, use a mutable array as an implementation detail
08:02:16 <ski> i like this approach better than `unsafePerformIO'
08:02:30 <Ariakenom> ski: why?
08:03:10 <ggole> It seems as if that ties into the region/lifetimes stuff
08:04:00 <ggole> If the lifetime of possible observations of an effect is within a function, surely that function need not be impure
08:04:00 <ski> ggole : yea, but `impure' in Mercury is mostly used for global mutable variables (to implement constraint solvers), and for the FFI stuff. so the state is already non-local there. for local state (like with effect systems), i agree one'd like an implicit discharge of the contagious when you reach a point where it can't affect outside
08:04:25 <ggole> Right.
08:04:26 <p0lyph3m> anyone took a closer look at mythryl ? https://mythryl.org/
08:04:51 <ski> Ariakenom : (a) the name `unsafePerformIO' is unclear. what does "unsafe" mean ? it can refer to several different things. the actual "requires" and "ensures" contract on its correct use isn't that clear
08:04:56 <ggole> I'm sure that there has been work done on this, although I can't remember anything specific off the top of my head.
08:05:32 <ski> Ariakenom : (b) when using `unsafePerformIO', one often has to mark something as non for inlining. `unsafePerformIO' is from the language POV just a function
08:05:35 <Ariakenom> ski: unsafe just means read documentation and don't trust the type in my reading
08:05:36 <ggole> Algebraic effects are scoped, I suppose
08:05:55 <ski> Ariakenom : in Mercury, `promise_pure' is a separate construct
08:07:28 <ski> (and the "promise" part of the name imho better suggests to the user that it's fine to use, as long as you fulfill your proof obligation)
08:08:16 <ski> "unsafe" can mean that the type system can be broken. it can also mean that equational reasoning can be broken (so (non-local) side-effects)
08:08:49 <Ariakenom> but unsafePerformIO can do both those
08:08:50 <ski> (also, there's `unsafeInterleaveIO', where it's not clear that this is a case of either of these previous readings)
08:09:04 <ski> yes, via `IORef'
08:10:31 * ski idly recalls how this issue is (and was) handled for the MLs
08:11:46 <Ariakenom> init :: IO Module
08:12:49 <dolio> Do they actually handle it?
08:13:53 <ski> anyway, the contract i tend to use for `unsafePerformIO' is `unsafePerformIO (return x) = x', iow if you pass an action that has (behaviourally/observationally speaking) no (externally visible) effects, just a monadic result `x', then it returns `x'
08:14:12 <ski> this would handle the case of local side-effects
08:14:44 <ski> (where either one can't implement what one want in ordinary Haskell, or it'd be too inefficient)
08:15:28 <ski> dolio : there's the dreaded "value restriction". earlier SML (or some implementations at least ?) had this notion of "imperative type variable", which i believe was more flexible, but also more complex
08:16:01 <dolio> Well, that's just avoiding type unsoundness.
08:16:33 <Ariakenom> solution, work around, tomato, tomato
08:16:36 <ggole> Yeah. If you have currying, polymorphism and mutable refs, you get that problem
08:16:45 <ski> the value restriction means that it can be cumbersome to do e.g. monadic parsers
08:17:05 <ski> s/currying, //
08:17:29 <ski> dolio : yes. obviously they don't avoid side-effects
08:17:33 <dmwit> Doesn't the reference itself need to be polymorphic?
08:17:34 <dolio> Okay.
08:17:44 <ski> dmwit : yes
08:17:48 <dmwit> Just having polymorphism isn't enough, or else we'd be in trouble in Haskell, too, with IORef.
08:17:57 <dmwit> But we're not, because we never have `IORef (forall a. a)`.
08:18:28 <dmwit> uh
08:18:30 <ggole> OCaml lifts the restriction a bit using variance
08:18:39 <ggole> But you still need to eta-expand a fair bit
08:18:51 <ski> dmwit : we distinguish `IO (IORef a)' from `IORef a'
08:18:52 <dmwit> `forall a. IORef a` is the thing we don't have, I guess.
08:19:09 <ski> iirc, you can also break type soundness with continuations (together with polymorphism, no value restriction), rather than mutable references
08:19:18 <ski> yep
08:19:36 <ski> in `do x <- ...; ...', `x' is not polymorphic
08:19:43 <dmwit> right
08:20:17 <ggole> 1ML suggests having pure and impure arrow constructors
08:20:51 <ski> hm, that reminds me of distinguishing between "serious" and "trivial" arrow constructors
08:21:04 <ggole> Which would ease the value restriction significantly without taking the step of making the language pure
08:21:07 <ski> trivial being used for (non-serious, in a technical sense) currying
08:21:53 <ski> ggole : i suppose one'd then want to have purity variables, with polymorphism over those. perhaps ordering, or lattice operations
08:22:09 <ggole> Yeah, you would probably want some polymorphism
08:22:20 <ggole> Polymorphism over the arrow constructors is a pretty obvious step
08:22:24 <ski> (which brings us back to linearity)
08:24:10 <ski> (a "serious" use of currying would be when you do some non-trivial computation before returning a function. so "run-time compilation", e.g. compiling a description of a matcher (like e.g. for regexen) into an efficient recognizer (or more))
08:24:18 <ski> )
08:25:12 <ggole> What was the motivation for making the distinction?
08:25:50 <ski> iirc, for implementation reasons, wanting to know when we can convert into a multiple-arity procedure, and when we have to do multiple partial applications
08:26:06 <ggole> Hmm, I see
08:26:20 <ggole> Implementations manage to do a fairly good job of that transparently.
08:26:29 <ski> (so this would probably not be something that would be visible in the surface language, but only in intermediate code representations, and compiled interfaces)
08:26:39 <ggole> Although, maybe this idea predates the necessary techniques.
08:28:03 <ggole> Oh, I see
08:33:50 <bollu> cocreature:  After explicit parameter passing, old: 1.973275762 seconds time elapsed  | new: 1.027870164 seconds time elapsed
08:34:03 <bollu> cocreature It's still a while to get to C: 0.724995176
08:34:17 <bollu> there's a ~1.5x slowdown
08:34:31 <cocreature> not particularly surprised by that
08:34:50 <cocreature> you could use a PrimArray instead of an unboxed vector but I doubt that buys you anything significant
08:35:06 <cocreature> have you looked at the core to see if everything is being specialized and inlined as one would hope?
08:36:46 <bollu> cocreature no, that's the next step
08:37:13 <bollu> cocreature What I would want to see is worker-wrapper + stuff working on fully unboxed types + integer primops for bit fiddling, yes?
08:37:19 <bollu> (anything I'm missing?)
08:37:50 <bollu> cocreature also, is there any win from running in ST instead of IO? (Maybe the compiler has stronger guarantees about what can happen inside ST? Wild guess here)
08:38:17 <cocreature> afaik that shouldn’t make a difference
08:38:24 <cocreature> and yeah everything should be unboxed, so no allocations
09:16:11 <Taneb> Is there something comparable to Data.List.Split.chunksOf but takes a ByteString?
09:20:34 <cocreature> Taneb: afaik sadly not at least not in any reasonably popular package
09:20:52 <cocreature> there is one in pipes-bytestring but if you’re just working with lists that’s overkill
09:30:10 <Taneb> cocreature: ah, that's a shame
09:40:28 <maerwald> is lazy evaluation possible without purity?
09:40:44 <maerwald> (reasonably possible)
09:44:45 <davr0s> maerwald  in a pure subset of a program i' guess
09:45:12 <maerwald> no, I mean in a language
09:45:15 <davr0s> eg if you can specify the lazy functions wont depend on other changes
09:45:47 <davr0s> do you mean in an existing language or theoretically
09:46:05 <Athas> maerwald: definitely possible, but probably hard to use.
09:46:22 <Athas> Well, *definitely* hard to use.
09:46:32 <davr0s> my theoretical answer is the lazy part must specify it wont depend on data that changed after instantiation
09:46:59 <davr0s> there's definitely code that can look pure from the outside, but only mutate inside (it's own temporaries)
09:47:24 <Athas> You can try it yourself in Haskell by using unsafePerformIO (but beware that this also pokes hole in the type system).
09:47:37 <Boarders> if I have a sum type with a record then how do I export the record fields when I export the constructors?
09:47:42 <Athas> But that problem can be solved, although not in Haskell.
09:47:52 <davr0s> i think you could do this in rust eg set up closures 'demanded' later
09:48:14 <davr0s> but there you'd have to make your own assumptions about their IO use
09:51:51 <c_wraith> even in ghc Haskell, you have things like unsafeInterleaveST
09:52:28 <c_wraith> which let's you use imperative code lazily. which can be nice if done well, or break everything if done wrong.
09:52:54 <c_wraith> so you already can experiment with how hard it is.
10:06:43 <the_2nd> can I somehow use the "pipe" branching syntax within an arm of a case of ?
10:06:53 <the_2nd> or what's the most similar/cleanest syntax to it?
10:07:22 <the_2nd> Just x -> | x == 3 = "three" ...
10:07:33 <cocreature> the_2nd: that should work just fine?
10:07:45 <cocreature> although for this particular case you can also just do Just 3 -> "three"
10:08:15 <geekosaur> it's: Just x | x == 3 -> ...
10:08:25 <the_2nd> ah
10:08:56 <the_2nd> yep, geekosaur that works
10:09:05 <cocreature> oh right I should pay more attention
10:14:24 <elgoosy> hi, which are the most active projects compiling haskell->web assembly? I see this one https://github.com/tweag/asterius
10:15:13 <cocreature> elgoosy: asterius and webghc (https://github.com/WebGHC) are the most active ones afaik
10:15:31 <cocreature> but neither of them is in a usable state iirc
10:21:01 <elgoosy> thanks
10:48:22 --- mode: glguy set +v mitchellsalad__
10:48:50 --- mode: glguy set -v mitchellsalad__
11:02:31 --- mode: glguy set +v Valxzxz
11:02:47 <Valxzxz> Hi there! Has anyone worked with Data.Fixed
11:02:59 <Valxzxz> I have value of Text type
11:03:17 <Valxzxz> and it corresponds to the value of Micro type
11:03:22 <Valxzxz> How do i parse it?
11:03:32 <Valxzxz> is there any function from the lib?
11:05:32 <mitchellsalad__> Valxzxz: Data.Text.Read.rational
11:05:34 <cocreature> Valxzxz: depends on how the value is represented as Text
11:10:55 <Valxzxz> @cocreature 
11:10:56 <lambdabot> Unknown command, try @list
11:10:59 <Valxzxz> cocreature 
11:11:09 <Valxzxz> do i need to specify type?
11:12:39 <Valxzxz> ok i got it
11:12:48 <Valxzxz> since Mirco is fractional
11:12:56 <Valxzxz> we have everything for free
11:12:58 <cocreature> Valxzxz: my point is there are a ton of different ways of encoding a value of type Micro into Text. how you go from Text to Micro depends on how you encoded it
11:12:59 <Valxzxz> Thank you a lot!
11:19:53 --- mode: glguy set +v leifmetcalf
11:34:56 <shapr> Is there a Haskell lib that lets me run a shell command on multiple servers?
11:35:06 <Valxzxz> how do i convert Fixed to Integer?
11:35:11 <Valxzxz> how do i convert Fixed to Word64
11:36:08 <shapr> Valxzxz: I'd start with hoogle https://www.haskell.org/hoogle/?hoogle=Fixed+-%3E+Integer
11:36:22 <hexagoxel> regarding roles, does the following have a "solution" ? https://gist.github.com/lspitzner/2e3f0257f390bd9a97016cdc96820d5f
11:36:27 <mitchellsalad__> Valxzxz: floor, ceiling, or round
11:36:45 <hexagoxel> does the `Monad m` constraint really not imply a representational role?
11:40:14 <Valxzxz> I need to convert Fixed E6 ~ Micro value to its representation, so basically get the MkFixed (Integer) value
11:40:21 <hexagoxel> hmm Proxy is Monad, but has a phantom type arg, so "no"
11:40:42 <hexagoxel> but are there Monads for things with a nominal type arg?
11:44:39 <monochrom> Valxzxz: Then just use pattern matching.  The data constructor MkFixed is exported.
11:45:28 <geekosaur> fromEnum should get the Integer, and it has a Num instance + various "sub"classes thereof
11:45:42 <Janiczek> If I want to add a dependency to Stack project, what file to add it to and what commands to run? I'm confused by the files *.cabal, package.yaml, stack.yaml
11:48:17 <monochrom> Yeah fromEnum does that too.
11:52:50 <glguy> Janiczek: The .cabal file describes the version ranges of packages that your directly depend on
11:53:08 <glguy> Janiczek: the stack.yaml provides information about the specific versions of all transitive dependencies to be used for that project
11:53:39 <glguy> a "resovler" is a shorthand for specifying a bunch of specific versions of packages
11:54:40 <glguy> so the cabal file describes the versions you intend to support and rely on and the stack.yaml setup up a local build environment that should satisfy those constraints
11:55:01 <Janiczek> so, to use JS metaphor, stack.yaml is kinda like yarn.lock, .cabal file is kinda like package.json (generated from the other files when using stack), and package.yaml is the high-level file I should edit?
11:55:21 <glguy> package.yaml is the file you should delete that generates the initial cabal file
11:55:44 <glguy> the cabal files are supports by all of the various build tools
11:56:22 <glguy> one of the default stack templates happens to create a package.yaml
11:56:28 <Janiczek> right. so after `stack init` I can remove the package.yaml
11:56:38 <Janiczek> (or `stack new` or whatever I did)
12:04:03 <sssilver> hi all, would this code be possible to write in Haskell using reduce? https://dpaste.de/nx2r
12:08:17 <dmwit> Don't use fromEnum on Fixed. =(
12:10:40 <dmwit> > fromEnum (2^57 :: Data.Fixed.Micro)
12:10:42 <lambdabot>  -9223372036854775808
12:12:27 <dmwit> sssilver: ...yes, Haskell is a rich enough language to express matrix multiplication.
12:13:16 <dmwit> Or maybe the reason I find this question strange is that I haven't yet understood the "using reduce" constraint in your question.
12:14:16 <monochrom> What is "reduce"? There is nothing with that name in Haskell Prelude.
12:14:52 <dmwit> jinx
12:16:44 * byorgey guesses perhaps sssilver means 'foldr', but of course this is only a guess
12:16:45 --- mode: glguy set +v systemfault_
12:17:20 <c_wraith> we could pretend it means "foldl, but I've never used a language where foldr makes sense so I wasn't aware there is a difference"
12:18:53 <byorgey> that too
12:18:57 <sssilver> byorgey, dmwit: I'm curious -- what would code that does the same thing look like in Haskell?
12:19:06 <sssilver> if it's not too much work to write a small snippet
12:19:06 <byorgey> that Min( N, M ) in the third loop condition is strange.
12:19:09 <sssilver> (if it's small)
12:20:17 <monochrom> I would just use the hmatrix library.  It would be "outer v".
12:21:11 <monochrom> Err no, I misread.  "m <> v".
12:21:27 <sssilver> monochrom: I'm more interested in the code that does 3 nested for loops and some math operation inside rather than actually doing matrix math
12:22:43 <monochrom> If you have cons lists, there is list comprehension.  If you have Vector (from the "vector" library), there is do-notation or monad comprehension.
12:24:07 <byorgey> sssilver: something that corresponds pretty directly would be  \m1 m2 -> [ [ sum $ zipWith (*) v1 v2 | v2 <- transpose m2 ] | v1 <- m1 ]
12:24:26 <byorgey> @let (*.) = \m1 m2 -> [ [ sum $ zipWith (*) v1 v2 | v2 <- transpose m2 ] | v1 <- m1 ]
12:24:27 <lambdabot>  Defined.
12:24:43 <byorgey> > [[1,2], [3,4]] *. [[6,-1], [2,5]]
12:24:45 <lambdabot>  [[10,9],[26,17]]
12:25:28 <sssilver> byorgey: is that identical to the C++ snippet I pasted?
12:25:35 <elgoosy> Hi, I followed the nix tutorial here https://github.com/dmjio/miso#sample-application. Once in the shell ghcid command starts well but when I change and save the file, it does not reload (with ghc compiler it does). Neither dante plugin is able to execute 'nix-shell --run "cabal repl"'. If i use this command directly from the console it does work well.
12:25:44 <byorgey> sssilver: it is doing pretty much exactly the same computation, yes.
12:25:56 <shapr> looks like cheating compared to that C code
12:26:40 <c_wraith> having transpose already helps.
12:27:09 <monochrom> You will not get identical.  But you can ask what's the difference so you can judge whether it matters.
12:27:22 <monochrom> If you use list comprehension then you're using cons lists not arrays.
12:27:43 <monochrom> If you use transpose then you're creating intermediate data structures that will be thrown away.
12:28:24 <sssilver> what'd this look like with list comprehension? I understand list comprehension but I feel like it wouldn't work here, I'd need some kind of a fold operation
12:28:43 <monochrom> byorgey's code uses both cons lists and transpose.
12:29:21 * sssilver scratches his head
12:29:22 <shapr> byorgey's code is two nested list comprehensions
12:30:00 <monochrom> If you are not using "PrimVector" or "UArray" then you incur one extra level of indirection per element.
12:30:43 <shapr> > [
12:30:45 <shapr> doh
12:30:45 <lambdabot>  <hint>:1:2: error:
12:30:45 <lambdabot>      parse error (possibly incorrect indentation or mismatched brackets)
12:31:39 <monochrom> "sum" hides a fold.
12:32:06 <shapr> aha! there IS a fold!
12:32:51 * shapr goes back to writing xml
12:33:04 <davr0s> i'mm guessing that ghc must do a lot with lists at compil ttime,
12:33:28 <davr0s> eg does it turn them into unrolled link lists
12:33:52 <davr0s> (in the case of list items smaller than cache lines)
12:33:53 <monochrom> FWIW you can't even waltz into ##python and demand python code identical to C or C++.
12:34:30 <monochrom> An integer variable in Python takes 24 bytes, today I learned. Because it has to be a whole bloody object, unlike C's int.
12:34:45 <shapr> sssilver: did that help?
12:35:20 <matheus23> Hi everyone! Say I wanted to test my servant API, however not in-memory, but actually starting up a server and sending actual requests. Would that be possible? How would you do it best?
12:35:21 <monochrom> So even a simple "j++" in Python is not identical to any C code you actually write in practice.
12:35:23 <byorgey> monochrom: but it can represent arbitrary-sized integers.
12:35:47 <matheus23> So I guess my question, more precisely, is: Is there some way to easily generate requests from a servant API?
12:36:33 <sssilver> shapr: yes, I'm trying to wrap my head around it
12:36:52 <sssilver> yes it makes sense, multiplying 2 matrices results in a matrix, no fold operation necessary
12:37:01 <davr0s> i dont suppose there's a way to automatically swap all the [T] into a user specified sequence type so long as it supports the same interface , i realise you could just define a type to use instead.. it's just [T] is pleasant to read and write . 
12:37:03 <shapr> well, sum is a fold
12:37:30 <davr0s> [T] = MyDefautSequenceType
12:37:34 <shapr> davr0s: What do you mean? in ghci?
12:37:51 <davr0s> when compiling. ghci wouldn't matter (just testing)
12:38:14 <davr0s> like ghc  myprog --replace-lists-with MyCustomSequenceType
12:38:36 <davr0s> i suppose you could do that as a source code transformation
12:39:38 <davr0s> but what i have in mind, i'd hope GHC is doign internally anyway however it would be nice to see and control it (and experiment to verify the effects)
12:40:08 <yushyin> monochrom: btw. there is no j++ in python
12:40:11 <davr0s> what i'm imagining is tthat whilst it talks about them being singly linked lists, they must turn them into unrolled link lists where possible and according to some heuristics
12:40:16 <monochrom> GHC does not replace [] by a "more efficient" type.
12:40:36 <monochrom> or s/type/data structure/
12:40:54 <monochrom> But it does try to eliminate cons cells altogether.
12:41:05 <Ariakenom> monochrom: python "int" is actually unbounded
12:41:19 <Ariakenom> oh I missed the other response
12:41:27 <davr0s> is there a paper describing all this
12:41:30 <davr0s> or youtube presentation
12:41:49 <davr0s> "an overview of haskell for C++ programmers who are paranoid about pointer chasing"
12:41:50 <monochrom> Maybe several?  Generally look for "list fusion".
12:41:59 <davr0s> "and why you shuold still consider using haskell despite that"
12:42:24 <monochrom> foldl' (+) 0 [1..n]  does not create intermediate list/cons at all.  It becomes a loop from 1 to n.
12:42:44 <davr0s> thats good,
12:42:54 <Ariakenom> davr0s: Please do write one when you find out :)
12:43:13 <monochrom> P.S. I'm going to just ignore all the anal pedantic nitpicking.
12:43:14 <davr0s> Ariakenom write one presentation?
12:43:28 <davr0s> i dont have the information about what GHC does and doesn't do :(
12:43:44 <davr0s> but i'm guessing there must be a fair amount along the lines of what monochrom just reported
12:44:11 <davr0s> i'm embarrased enough to be using a GC langauge :)
12:44:27 <monochrom> there is also "deforestation" as another keyword to search for.
12:44:37 <davr0s> a GC language which presents syntax guiding you toward linkliists aswell... eek
12:46:05 <Ariakenom> monochrom: To add pedantry: Haskell Int is also 20ish bytes afaik
12:46:13 <davr0s> you what?!
12:46:30 <monochrom> 16.
12:46:39 <dolio> Haskell Int doesn't specify how many bytes, just a lower bound.
12:46:57 <Ariakenom> Shield your eyes davr0s :p
12:46:57 <davr0s> woudl that still be the case if it was placed inside a structure
12:46:59 <dolio> Or, bits, rather.
12:47:12 <davr0s> inside a 'record' , 'data element' , whatever you call it
12:47:18 <monochrom> Let's call it "GHC Int" instead.
12:47:30 <Ariakenom> davr0s: in it's basic form yes but it's usually annotated with unboxing chants
12:47:45 <jle`> sssilver: a dot product is essentially a 'zipped' fold; you can implement it as sum (zipWith (*) xs ys)
12:47:45 <davr0s> like if you say   'data  Foo  =  Foo Int Float String ...    is that Int still 16 bytes
12:47:53 <monochrom> []'s cons cell is 24 bytes though.
12:47:57 <jle`> sssilver: and matrix-matrix mult is just a bunch of dot products
12:48:35 <Ariakenom> davr0s: Yes but you can write "data Foo = !Int Float String" to make it less (no overhead?)
12:48:38 <alp> matheus23, yes, servant-client =)
12:49:11 <davr0s> Ariakenom i'm nt suggesting doing that, i'm just making an illustrative example of 'a stuct that just happens to have an int in it along with other stuff the struct needed'
12:49:12 <Ariakenom> "data Foo = {-# UNPACK #-} !Int Float String" to be explicit
12:49:19 <alp> matheus23, we'll quite likely have a page or something about this on https://haskell-servant.readthedocs.io/en/stable/ at some point soon, but there are basically 3 different ways to test servant apps.
12:49:21 <matheus23> alp: Thanks! This seemed way too obvious. It seems to be exactly what I'm looking for
12:49:24 <monochrom> You're also missing a data constructor :)
12:49:35 <matheus23> alp: what is the third?
12:49:42 <matheus23> I'm quite sure I know the 2 other
12:49:56 <alp> matheus23, 1/ testing the business logic, e.g you can't register the same user twice, you can't buy a product that doesn't exist, you can't checkout an empty cart, you can checkout a normal cart, etc.
12:49:57 <matheus23> (now)
12:50:01 <monochrom> {-# UNPACK #-} !Int is back to 8 bytes (64 bits)
12:50:17 <Ariakenom> GHC Int is always 64 bit?
12:50:18 <davr0s> is there any kind of   "unpack anything that is under a certain threshold size'
12:50:19 <matheus23> ah so basically testing without servant involved
12:50:31 <dolio> It depends on the architecture.
12:50:35 <monochrom> Not really.  32-bit GHC is 32, 64-bit GHC is 64.
12:50:37 <davr0s> again as a tuned ecosystem wide default whch programs could override
12:50:37 <Ariakenom> davr0s: laziness semantics means you can't do it unless its a strict field
12:51:03 <davr0s> it could be lazy in terms of filling it, but reserve the space
12:51:14 <alp> matheus23, for this I definitely recommend servant-client. you don't want to spend a lot of time putting the suitable requests together, you want to say "perform this operation and this one, make sure you get what you expect", etc. that's all for servant-client, it'll kill the boilerplate you'd otherwise have and let you write tests quite easily by just using the derived clients.
12:51:16 <monochrom> Common trick to instantly reduce memory footprint by half on "I rented a 0.5GB virtual machine": download 32-bit GHC instead.
12:51:31 <Ariakenom> davr0s: No you need to be able to store a closure there
12:51:58 <Ariakenom> aka a pointer
12:52:01 <davr0s> ok so basically laziness means 'every value is a closure', but
12:52:03 <alp> matheus23, 2/ is about testing how the app reacts to malformed requests and what not. for this you can use things like hspec-wai, which _do_ let you build malformed requests unlike servant-client.
12:52:16 <matheus23> alp: Yes. I love this. Context: I'm trying to build another implementation of https://kinto-storage.org in haskell. Having a test suite that could test the original implementation as well would be golden
12:52:26 <davr0s> one should not panic about how insane that sounds because lists basically translate into generators of lists (as we'd think of it in traditional langauges..)
12:53:01 <davr0s> like it's not "heres a list of insanely padded items", rather "here's a closure in a cell tht will generate a list on demand..."
12:53:10 <Ariakenom> right
12:53:28 <monochrom> If you use [] as lazy lists, you have little to worry about memory usage.  Even without optimizations, you're just keeping one cons cell at a time.
12:53:40 <alp> matheus23, finally 3/ is about testing properties of the entire application, e.g "try and make sure we don't throw any 500 error" or "do all 301 (the status code) responses come with a Location header?", etc. for this, I'd recommend servant-quickcheck
12:53:47 <Ariakenom> struct {int head; iterator<List<int>>}
12:54:17 <davr0s> so i suppose if i want to test my theory about padding out 'unrolled link lists for trivial things' ... i'd have to try that explicitely
12:54:19 <monochrom> But if you accidentally or intentionally have your whole 1000-element list completely evaluated and kept and live in memory, it's 1000*24 bytes.
12:54:39 <davr0s> the fly in the oiintment is the size of the elements affects the amount i'd want to put in the unrolled cells
12:54:43 <monochrom> (At which point we recommend using Vector instead.)
12:55:06 <alp> matheus23, and regarding what you just said above, well if your implementation conforms to the same API, you can only derive the clients once but run them against a different (target) host when you want to hit your impl or the other one
12:55:16 <davr0s> i suppose real dynamic arrays / VEctors are a whole different ball game
12:55:45 <alp> you might even be able to write something that makes use of servant-quickeck or mimics it to compare that the two implementations behave the same in general
12:55:59 <alp> maybe servant-quickcheck has some helpers for this already? I don't know, I haven't used it in a whil
12:56:01 <alp> while*
12:56:02 <monochrom> Here is how to calculate data structure memory footprint.  Suppose you have "data T = C1 X Y | C2 Z".
12:56:07 <matheus23> alp: exactly! Thanks for the writeup
12:56:15 <matheus23> wait the last part I dont get yte
12:56:41 <monochrom> Let k be 32 bits or 64 bits according to which GHC you chose.
12:57:11 <matheus23> alp: ah you mean I generate a couple of requests via quickcheck and compare both responses from the servers?
12:57:27 <alp> matheus23, yes, and I just checked, it's already in the library: https://hackage.haskell.org/package/servant-quickcheck-0.0.7.2/docs/Servant-QuickCheck.html#v:serversEqual
12:57:31 <monochrom> C1 x y is k bits for C1, k bits for pointer to x, k bits for pointer to y.  This has not counted how much memory x and y take up.  Do your recursive counting.
12:57:45 --- mode: glguy set +v clody
12:57:47 <monochrom> C2 z is k bits for C2, k bits for pointer to z.
12:58:01 <matheus23> alp: what the f. I'm impressed
12:58:19 <davr0s> ok monochrom i had sort of guesssed most 'objects' would infact be references, fair enough
12:58:20 <monochrom> Example: "data List a = Nil | Cons a (List a)".  Cons x xs is 3k bits right there.
12:58:30 <davr0s> as they're immutable, there's no reason to ever copy
12:58:42 <davr0s> when 'passing a value'.. it can always be a reference to the original, right
12:58:51 <monochrom> Yes, just copy the address.
12:59:10 <monochrom> You will actually thank these indirections when playing with binary search trees.
12:59:21 <Ariakenom> huh. I thought there was more overhead. Doesn't there need to be some pointer or data indicator for the GC?
12:59:44 <monochrom> Inserting a key requires only creating lg n new nodes.  The rest of the tree can be shared.
12:59:57 <alp> matheus23, heh, well that was the goal along, if we make enough data about the API available and inspectable, we can do a lot of things :-) by the way, if you ask servant questions here but they don't get addressed or they crawl under the many other simultaneous discussions, you can hop in #servant which is quieter and dedicated to the servant libs.
13:00:24 <davr0s> yeah monochrom i figured that sort of thing must be going on aswell
13:00:31 <NemesisD> isn't there a monad that replaces Writer without the space leak?
13:00:59 <monochrom> Ariakenom: I forgot which one is true. Either "64 bits ought to be enough for your GC marks" or "copying GC doesn't need that".
13:01:33 <monochrom> GHC does double-buffer copying GC (plus other tricks).
13:01:41 <monochrom> (Maybe s/tricks/techniques/)
13:01:47 * Ariakenom has doubts
13:02:05 <davr0s> there's an interesting 'default colleciton' for 'prototyping in c++' one of my friends used to throw around which was a doubly linked list which has a dirtyable pointer array regenerated when you index it,
13:02:47 <davr0s> i think there's better ways of doing that  ("a datastructure which will behave the least bad when you either want to insert/delete items randomly or index it, unknown which is happening more..")
13:03:15 <Ariakenom> There's a StgHeader https://ghc.haskell.org/trac/ghc/wiki/Commentary/Rts/Storage/HeapObjects
13:04:05 <davr0s> i always remember people pushing haskell for games pointing out "the majority of your memory use is beyond the GC, ie textures and vertex arrasys"
13:04:27 <davr0s> but i also know of hellish problems with the '20% of code you think shouldn't matter" in practice
13:04:40 <Ariakenom> Do other languages have these nice docs on implementation? When doing my master's on IRs the Stg and Core papers/wikis were great
13:04:56 <davr0s> like when writen wrongly it ends up taking 10x slower so it's actuall more like 50% of your CPU time (i've seen worse)
13:05:24 <monochrom> Unfortunately StgHeader is one single pointer.
13:05:40 <Ariakenom> unfortunately?
13:05:49 <monochrom> And it plays the role of telling you "I'm C1" or "I'm C2".
13:06:11 <davr0s> i could take the view 'dont worry ,just enjoy the elegance of expressing algorithms in haskell', as i'm coding for myself 
13:06:21 <monochrom> Dunken ist das Lieben, ist der Tod.  Everything is unfortunately.
13:06:30 <davr0s> it would be nice to help the world somehow while i'm at it though
13:07:03 <monochrom> Actually how GHC pulls off these tricks is pretty elegant too for the most part.
13:07:04 <davr0s> like produce some data that can inform compiler optimizations ( i mean by correlating examples of things i write between hs and c++)
13:07:23 <Ariakenom> So Int is 24 bytes on 64-bit GHC including the pointer to it
13:07:36 <monochrom> No, 16.
13:07:55 <davr0s> just keep saying "int generator.." to re-assure me
13:08:03 <monochrom> It's "data Int = Ctor Int#".  Ctor 8, Int# 8.  No further indirection.
13:08:22 <monochrom> Err, including pointer to your Int, I guess.
13:08:23 <davr0s> if all the fields of a data item have been evaluated , can it change to a more compact representation
13:08:49 <davr0s> oh it needs to potentially collect indidividually
13:08:51 <Ariakenom> pointer to Int, InfoTable pointer, Int constructor, actual Int#
13:08:53 <monochrom> But I tend to count that as part of whatever holds that pointer, not part of the pointee.
13:09:18 <monochrom> No, Ctor's 8 bytes are already InfoTable pointer.
13:09:20 <davr0s> but what if the overhead of the headers is more than the padding if you assume the whole thing is just 1 item
13:09:54 <monochrom> Here, enjoy this: https://github.com/takenobu-hs/haskell-ghc-illustrated
13:09:59 <davr0s> like a float4 type in graphics, thats 16 bytes. but if it's 4 values individually traced, yikes.
13:11:22 <davr0s> thanks
13:13:29 <Ariakenom> Right I accidentally said the right number while counting wrong
13:13:32 <Ariakenom> thanks
13:14:09 <monochrom> I wouldn't count "pointer to x" as part of x's memory footprint.
13:14:26 <monochrom> Because what if I have 1000 pointers all pointing to the same x.  How do you count that.
13:14:50 <Ariakenom> Which is why I explicitly counted is as part of my statement
13:15:04 <davr0s> i guess laziness and strictness means haskell's back end is unique
13:15:16 <davr0s> no other languages can share it
13:15:27 <davr0s> i mean laziness and purity lol
13:15:34 <Ariakenom> purity also has some effects, on GC design at least
13:15:42 <Ariakenom> ah
13:15:52 <davr0s> right
13:15:53 <monochrom> Purity makes STM much simpler.
13:16:18 <davr0s> and as such it means it can't re-use work from other GC langauges, they miss out on that
13:16:45 <monochrom> I take a brief look at STM research outside Haskell, and basically their only open problem is pervasive mutability.
13:17:07 <monochrom> s/take/took/
13:17:47 <davr0s> are there any attempts to brute force optimize like 'profile guided optimizatoins', e.g. (i) supply a test environment with what you think is typical load, and (ii) randomly try a load of different permutations and thresholds for automatically unboxing etc, (iii) measure which is faster.
13:18:09 <davr0s> i just have this picture in my head that there's a granularity of object below which strict would be faster
13:18:19 <monochrom> No I think outside work from GC is all useful.  Because lazy evaluation adds back mutation.
13:18:38 <dolio> You can't just switch over to strictness below some threshold.
13:18:45 <dolio> It gives different answers.
13:18:53 <Ariakenom> mutation in a specific shape
13:18:53 <boeingx> Hi! Is there any simple way to ignore inline comments while parsing a line? Basically I would like to get `foo bar` for `foo bar -- this is comment` but `foo-bar` for `foo-bar -- this is comment`.
13:18:59 <davr0s> surely if pure it doesn't
13:19:06 <monochrom> The GCer is still playing against a mutator.  Just that the mutator is the lazy evaluator rather than the programmer.
13:19:16 <davr0s> ok
13:19:44 <dolio> Technically the different answers are not answers at all.
13:19:45 <boeingx> I have two difficulties in writing a parser combinator for this: 1) the trailing space before the comment and 2) the single dash
13:20:33 <davr0s> right so it can do both, "passing by value is always a reference to the original object", *and* "it might be an actual evaluated thing , or a closure waiting for eval.."
13:21:02 <monochrom> Yes, there is/was a program someone uploaded to hackage that goes "let me randomly add !s and test if it improves"
13:21:12 <davr0s> this is all simultaneously fascinating by how different it is, and terrifying regarding predjudices i have from ,say, console gamedev.
13:21:22 <boeingx> The library I use is `Trifecta`, but I am pretty sure it is libraray independent.. 
13:21:40 <davr0s> like explain a system like this back in the xbox 360 or PS2 days and see the reactions you'd get
13:22:15 <cocreature> boeingx: the underlying implementation is library independent but most libs have high-level functionality for this that differs slightly, e.g., here’s the one for megaparsec https://markkarpov.com/megaparsec/parsing-simple-imperative-language.html#lexer
13:23:18 <boeingx> cocreature: so a `lexer` is the way to go? it is not a good idea to achieve this only with a parser?
13:23:44 <Ariakenom> davr0s: Yes it is fascinating!
13:24:27 <cocreature> boeingx: what megaparsec and trifecta call “lexer” isn’t really a separate lexing pass. it’s just a bunch of convenient combinators that roughly correspond to what you would typically do in a lexing phase
13:25:03 <davr0s> its funny because the things that terrify me are due to machines being designed to run a certain type of code. I can imagine simpler CPUs being 'less hit' by this, but you cuold have more of them, and haskell's model should be better at parallel.
13:26:14 <Ariakenom> Have you seen Marlow's concurrent & parallel book?
13:26:20 <davr0s> no
13:26:24 <cocreature> boeingx: L.space and skipLineComment are not magic builtin combinators, they are just convenient library functions
13:26:45 <boeingx> cocreature: I see.. wasn't aware of megaparsec and was struggling to do so from scratch
13:27:31 <Ariakenom> davr0s: https://web.archive.org/web/20180108044627/http://chimera.labs.oreilly.com:80/books/1230000000929/index.html
13:27:36 <boeingx> cocreature: thx for the reference, I will check how the "lexer" is implemented
13:27:43 <cocreature> megaparsec is definitely worth a look. I rarely use anything else these days
13:27:57 <Ariakenom> (Not pirated :p https://simonmar.github.io/pages/pcph.html)
13:28:18 <davr0s> i am also curious to know  if:   could the closures be batched  , i.e. think of the way in which some Java engines map vtable objects to certain adress ranges. "find the N most used closures, and map them to some address ranges which can be processed in batches"
13:28:28 <davr0s> r.e. lazyiness/re-ordering potential
13:28:28 <cocreature> trifecta’s main selling point is error messages but since megaparsec started adding carrets to error messages I don’t bother with trifecta
13:28:53 <Ariakenom> davr0s: The entire book is available online free of charge
13:28:56 <davr0s> processed in batches, even by a vector processor (i.e. GPU) if you had enough
13:29:42 --- mode: glguy set +v noipmups
13:29:50 <Ariakenom> kmett did some scheduling of tasks for parallel execution talking
13:29:51 <noipmups> Are Multi parameter type classes, Functional dependencies and Type families trying to solve the same thing? If so, which one to use?
13:29:53 <davr0s> but actually trying anything like this out would be a huge job
13:29:53 <boeingx> cocreature: that's good to know :) just searched megaparsec it seems that more tutorials are available
13:30:05 <davr0s> and in my experience ttrying to retrofit to complex systems is really hard
13:30:37 * Ariakenom goes to look at kmetts 240 githup repos
13:30:38 <Ariakenom> https://github.com/ekmett
13:31:55 <davr0s> 'copying GC'. can you give it a 'gameloop hint' (realtime hint) eg 'make sure you do the copy /compaction at least once a frame' (even if its not *faster*, in the name of consistency)
13:32:15 <mnoonan> noipmups: no, not really
13:33:11 <Ariakenom> davr0s: System.Mem.performGC
13:33:22 <davr0s> ok nice.
13:34:25 <davr0s> anway i should stop worrying
13:34:42 <davr0s> 'transforming data', haskell is awesome for that
13:34:43 <Hijiri> so is it reasonable to think that that would reduce the maximum GC time per frame
13:34:49 <Hijiri> I was thinking about the same question at some point
13:34:57 <davr0s> and its not like i'll forget how to code c++
13:37:17 * Ariakenom supresses urge to quote people that have been "ruined by Haskell"
13:57:15 <jle`> noipmups: they are not, but there is some overlap in the areas where they are applied
14:06:07 <geekosaur> that was a fairly confused question, actually
14:33:21 <fvr> I have a record with bytestring fields, and I have to print the fields separated by a space in a line, what is the efficient way to print a list of such records?
14:34:36 <fvr> I tried appending the fields and printing, and putStr each field, both seem to be much slower than shows and printing the resulting string
14:35:29 <_deepfire> fvr, just print them in a loop, emitting a space inbetween -- concatenation is unnecessary work
14:38:29 <_deepfire> mapM_ putStr . intersperse " "
14:39:08 <_deepfire> (you have a record, so it'll be slightly different, but that is the idea)
14:39:54 <fvr> _deepfire, when I run the code, where I print around 16k records it takes around 3s to print that way, but if I use shows and (' ' :), it takes only around 1s
14:42:33 <_deepfire> fvr, intersperse doesn't concatenate the elements -- it intersperses a list of elements with single-space ones -- unless I misinterpret what you mean by "that way"
14:43:32 <c_wraith> that's still doing a copy that shows lets you skip if you're careful.
14:43:32 <fvr> _deepfire, I mean, when I print each field using a putStr, it's slower
14:43:32 <_deepfire> The 3x difference you quote easily sounds like concatenation of the elements themselves, though.
14:44:04 <_deepfire> I see, withdrawing my suggestion, then : -)
14:44:08 <fvr> _deepfire, no not concatenation, I was refering to printing them one by one
14:44:26 <monochrom> Perhaps show actual code.
14:44:29 <fvr> c_wraith, can we do something similar for ByteStrings?
14:45:36 <c_wraith> sure. just use (ByteString -> ByteString) instead of ByteString.
14:45:50 <c_wraith> that's the same thing shows does.
14:47:43 <fvr> c_wraith, I thought part of the magic is due to consing (:) operator as well?
14:47:46 <c_wraith> hmm, it doesn't get you the same wins, as ByteString isn't a biased shape. I
14:47:59 <fvr> but ByteString's cons is O(n)
14:48:13 <monochrom> More pointedly, most ByteString operations are not lazy enough.
14:48:44 <monochrom> But "ByteString Builder" exists if it matters.
14:49:28 <c_wraith> in fact, since ghc 7.8 or so, it's even part of the ByteString package
14:50:43 --- mode: glguy set +v fvr_
15:02:51 <wz1000> huh, you can define a second order type that corresponds to the axiom of induction and use it to prove stuff about type families. https://gist.github.com/wz1000/25c60a0b150dfa121dacb8f35bd05a91
15:03:34 <mniip> wz1000, that's a relevant proof thogh
15:03:57 <mniip> it's computationally expensive
15:05:25 <mniip> wz1000, I came up with these btw http://hackage.haskell.org/package/singleton-typelits-0.1.0.0/docs/GHC-TypeLits-Induction.html
15:06:07 <wz1000> nice
15:06:29 <wz1000> what about structural induction for things like lists etc?
15:08:51 <lekskovsky> elgoos
15:10:38 <boj> is there a way to load optparse-applicative options in ghci? i was hoping  :set args --foo bar  would do it, but no luck
15:11:37 <geekosaur> I thik you have to run with :main to get them present? or wrap the invocation in withArgs
15:12:35 <boj> yeah, calling :main so it takes the args. modifying main to use withArgs is not satisfying
15:13:50 <geekosaur> main's just a function, "withArgs ["--foo", "bar"] main" is entirely valid
15:13:52 <fvr> monochrom, c_wraith Thanks! Using ByteString builder is indeed wayy faster than all the other options. But seems to be using a bit more memory with the standard GC settings, have to figure that out 
15:13:52 <fvr>  
15:15:00 <geekosaur> ad I'm nto catching what's wrong with :main. or :run if you want something other than main
15:15:19 <geekosaur> https://downloads.haskell.org/~ghc/8.6.1/docs/html/users_guide/ghci.html#the-main-and-run-commands
15:16:23 <boj> geekosaur: i suppose it is how optparse-applicative works, it is just not reading these options
15:16:45 <boj> or i am doing it wrong :)
15:19:41 <monochrom> I am not sure whether ":set args" actually exist or you just imagined it intuitively.
15:20:00 <boj> geekosaur: thanks, i did something wrong. apparently if an option is a file it needs to have the relative path ./foo
15:20:16 <boj> it does indeed exist, there are docs referencing it
15:21:16 <geekosaur> it's documented separately from :set for ghc/ghci optios options
15:21:23 --- mode: glguy set +v jackdk
15:21:24 <boj> https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/ghci.html
15:21:35 <geekosaur> I have no idea when it's sued, unelss it's a default if you jsut say ":main"
15:22:07 <boj> it allows you to call main instead of :main. so possibly if you want to add them to a .ghci file i imagine
15:23:12 <monochrom> Ah yes OK.
15:26:18 <geekosaur> that, or if you use it youcan't use :main because that overrides, or something
15:27:53 <monochrom>  :main probably ignores :set args altogether.
15:28:29 <monochrom> It is possible that :set args is a later addition than :main and no one bothered to change :main
15:28:59 <monochrom> Naw, I don't need that.
15:30:01 <monochrom> ":main" cannot telepath whether you want it to use what's in :set args or you mean "no args this time".
15:36:26 <geekosaur> right, that was my point about overriding
15:47:28 --- mode: glguy set +v lbhudda
15:52:55 <c_wraith> monochrom, might it employ non-telepathy divination methods, such as reading tea leaves or casting bones?
15:53:26 <monochrom> That requires too much I/O.
15:54:57 <monochrom> We can test a whole spectrum of that and understand human psychology.
15:55:52 <monochrom> If I sold you software that doesn't work until you show a cup of tea with the/a right tea leaf pattern to the camera on your computer, would you buy it?
15:56:35 <hpc> monochrom: you buy the cup of tea, and the leaves read out the activation key
15:56:36 <MarcelineVQ> Sure, just slap an apple on it :>
15:56:48 <c_wraith> that's purely cost/value analysis. can I get the intended output in sufficiently few cups of tea for my goals?
15:57:11 <monochrom> How about you can pre-print a photo of that on paper and just need to re-show that picture and not bother making tea?
15:57:19 <c_wraith> also, does it work with my preferred tea, or do I have to drink earl grey?
15:57:36 <monochrom> What if it's just a dongle you have to plug into the parallel port?
15:57:40 <hpc> c_wraith: it's spelled "tea, earl grey, hot" :D
15:58:01 <monochrom> I think it's also s/hot/90 degrees celsius/
15:58:05 <Rembane> I hear that you need a replicator and a ship computer.
15:58:14 <c_wraith> monochrom, cost is too high. I can't find a parallel port anywhere!
15:58:21 <geekosaur> within a specific temperature range, and make sure they included just the right amount of bergamot >.>
15:59:44 <monochrom> What if it's just your face, and the software is reasonably flexible about ambient light, whether you have/haven't shaved in the morning, etc?
15:59:55 --- mode: glguy set +v cgois
16:00:10 <monochrom> (I mean showing your face to the camera, not plugging your face into the parallel port!)
16:00:27 <Rembane> Shoving your face to the camera!
16:03:51 <monochrom> What if every time the software runs into an unsafePerformIO call, it does a Captcha test on the user?
16:04:12 <monochrom> Like, it's already unsafePerformIOing already, why not.
16:04:23 <c_wraith> sounds good to me.
16:04:34 <hpc> it has to be a test that you know what you're doing
16:04:38 <hpc> so like, what's this lens operator :D
16:04:51 <monochrom> Oh it breaks someone's proposed law earlier today about "unsafePerformIO (return x) = x" but what the heck.
16:05:05 <davean> unsafePerformCapcha
16:05:12 <hpc> huh
16:05:25 <hpc> that's a pretty good law
16:05:44 <monochrom> Yeah!
16:05:48 <hpc> it pretty much perfectly captures what its intended purpose is
16:05:56 <hpc> (to eliminate pointless IO in FFI)
16:07:36 <hpc> this makes me realize, unsafeInterleaveIO is more evil than unsafePerformIO
16:08:21 <c_wraith> unsafeInterleaveIO is roughly (return . unsafePerformIO)
16:08:25 <hpc> with unsafePerformIO's "law" you can't necessarily implement unsafeInterleaveIO with it
16:08:32 <hpc> so you don't even get to carry that over
16:08:32 <monochrom> unsafePerformIO has its share of problems with circumventing types.
16:09:02 <hpc> maybe unsafeInterleaveIO (return x) = return x?
16:09:07 <c_wraith> hpc, how does that law interfere with that hack implementation?
16:09:10 <hpc> okay, unsafePerformIO is more evil again
16:09:10 <monochrom> I think they're on two orthogonal axes in the evil space.
16:09:17 <hpc> c_wraith: it doesn't interfere, it just doesn't imply
16:09:23 <MarcelineVQ> don't leave dupable out of the fun
16:09:30 <c_wraith> hpc, yeah.
16:09:43 <c_wraith> MarcelineVQ, eh. that's just about making it slightly less unsafe.
16:10:13 <hpc> dupability is a pretty deep implementation detail
16:10:22 <hpc> i understand maybe 20% of it
16:11:46 <monochrom> We need an unsafe feature that is the sum of all fears.
16:12:05 <monochrom> We need an unsafeEmbedTheFollowingCoreCode
16:14:03 <Rembane> GHC's answer to inline assembly.
16:14:12 <hpc> http://hackage.haskell.org/package/vector-0.12.0.1/docs/Data-Vector-Generic-Mutable.html#v:unsafeNew is pretty evil
16:14:28 <hpc> oh wow, or unsafeGrow - "Grow a vector by the given number of elements. The number must be positive but this is not checked"
16:14:58 <nshepperd> dupability... is that about different threads entering the same unsafePerformIO's thunk concurrently? or what was it
16:15:14 <monochrom> Yeah there are a few need-for-speed unchecked functions like that.
16:16:12 <nshepperd> i expect that if x = unsafePerformIO m is shared that m won't be executed twice just because of evaluating x, but unsafeDupablePerformIO is allowed to?
16:16:27 <monochrom> I am just a bit appalled at the simplistic naming scheme because there can be 10 checks you could omit and one single "unsafe" prefix cannot possibly cover all 2^10 - 1 of them.
16:16:32 <texasmynsted> How do I list all the packages installed from "cabal new-install"?
16:17:25 <texasmynsted> I see a package in ~/Library/Haskell/bin/ but the name does not match anything I can google.
16:29:05 <dmwit> monochrom: For what it's worth, I have adopted the practice of explicitly enumerating the caller's obligations in documentation whenever I write a new function with unsafe in its name.
16:58:08 <tathougies> do we have benchmarks comparing performance of Data.Map and Data.FingerTree for lookups on sorted lists?
17:10:54 <jackdk> Is there a good way to find functions that mention a specific type? I'm trying to see if helper functions exist for the ErrorItem type in megaparsec
17:11:35 <marvin2> hoogle?
17:11:51 <marvin2> https://hoogle.haskell.org/
17:12:07 <dmwit> What's a lookup on a sorted list? Why is Data.Map a good type for a sorted list?
17:13:42 <dmwit> I mean, the answer is almost certainly "no" no matter how you answer those two questions. But it is worthwhile to practice asking good questions.
17:16:25 <dmwit> Hm. We lost one.
17:23:56 <jackdk> marvin2 didn't realise hoogle could do that. I usually use hayoo
17:24:00 <jackdk> tyvm
17:36:01 --- mode: glguy set +v leifmetcalf
17:36:20 --- mode: glguy set -v leifmetcalf
17:50:25 --- mode: glguy set +v juan-lin
18:40:02 <pacak> Greetings. Suppose we have a datatype with some laws, laws can be tested with unit test "test_foo :: (Foo a, Arbitrary a) => a -> Bool". What's the least perverted approach to ensure that this property is tested for every instance? Some "obvious" high energy TH magic comes to mind, but is there anything simplier?
18:43:52 <c_wraith> pacak, you mean class rather than data type?
18:47:18 <nshepperd> how can you test with every instance when an instance might be created in the future
18:49:49 <benzrf> pebkac more like pacak
18:50:05 <pacak> c_wraith: My bad, class.
18:50:25 <dmj`> pacak: you’d have to know all of the datatypes at the call site of test_foo statically, don’t think that’s possible.
18:50:38 <dmj`> all the datatypes that are instances of Foo
18:51:21 <pacak> Well, it's internal codebase so I can know all the datatypes that declare instance with some grep/th.
18:51:25 <c_wraith> use a proof assistant language and make the laws part of the class.
18:51:59 <pacak> c_wraith: Might be tricky, one of the classes is Show on steroids with backward compatibility support.
18:52:06 <benzrf> lol
18:52:12 <c_wraith> oh, only for one specific code base. then that's a lot easier.
18:52:30 <pacak> Well, Show/Read combo
18:53:31 <c_wraith> I don't know of any solution offhand, but you could at least find all the instance declarations and then make sure they have matching tests. it's not impossible!
18:53:46 <nshepperd> well, I guess the most logical method of testing typeclasses would be to put a 'testSuite :: (Foo a, Arbitrary a) => Benchmark' somewhere, then make the implementer of each instance responsible for instantiating testSuite next to their instance
18:53:50 <monochrom> There is nothing to prove until you have a conjecture.
18:54:22 <monochrom> Likewise there is nothing to test until you have expected answers.
18:54:28 * geekosaur woudl consider tooling. hasktags fins instance decls, doesn't it?
18:55:16 <pacak> monochrom: Expected answers are something like this - forall a. read (show a) == a
18:55:31 <pacak> geekosaur: Great idea, will check.
19:39:20 --- mode: glguy set +v orzo
19:39:38 <orzo> Hello, i'm pleased to discover that () implements Monoid, but it's important to me that mappend or (<>) is strict in this case.  Is it?
19:41:19 <boj_> > undefined <> ()
19:41:20 <lambdabot>  ()
19:41:22 <boj_> > () <> undefined
19:41:24 <lambdabot>  ()
19:41:31 <orzo> damn
19:41:46 <orzo> i think that's wrong
19:42:25 <orzo> i'm doing something where you build an object with lazy io, or you can act directly and return () as your monoid
19:42:39 <orzo> but because of laziness, that wont work out and will require you to force the () at the end
19:43:15 <orzo> what other purpose could Monoid () have?
19:46:23 <orzo> > (undefined <> undefined) :: ()
19:46:25 <lambdabot>  ()
19:47:08 <orzo> is there another trivial monoid but uses a strict op?
19:47:52 <glguy> orzo: This is what I did when I wanted that: https://github.com/glguy/irc-core/blob/v2/src/StrictUnit.hs
19:49:04 <nshepperd> can't you rearrange your program so that you don't have to rely on the side effects of evaluating ()?
19:49:31 <glguy> nshepperd: It can be the difference between leaking lots of space and not
19:51:54 <orzo> they should make ()'s monoid instance strict
19:52:01 <orzo> i doubt anyone is using its laziness
19:52:21 <glguy> I bet people are and that some of them don't even know they are
19:53:04 <orzo> can you think up a scenerio?
19:53:45 <glguy> Sure, I see people use mtl's RWS all the time and not use all 3 components, tossing in a () in the case they aren't using
19:54:00 <glguy> like in the Writer component
19:54:13 <shachaf> People use RWS?
19:54:24 <glguy> yeah, it's surprising but happens
19:54:45 <glguy> You should expect things to be as lazy as they can be unless they're specifically documented to be strict for some reason
19:55:11 <nshepperd> making functions unnecessarily strict in order to serve some obscure lazy IO use case seems like a bad idea
19:55:23 <glguy> nshepperd: Who's talking about lazy IO?
19:55:27 <nshepperd> > fold [()..]
19:55:29 <lambdabot>  ()
19:55:36 <glguy> Oh, orzo is :)
19:55:45 <glguy> There's the issue , then :)
19:56:01 <orzo> huh?
19:58:19 <orzo> glguy: you didn't invent StrictUnit for a lazy-io situation?
19:58:42 <glguy> of course not :)
19:59:40 <glguy> I was using it as a hack to get strictness out of existing lens combinators
20:02:31 <orzo> I'm implementing a haskell interface to a c library for doing binary diffs and patches.
20:02:50 <cbarrett> anyone else receive their copy of Haskell School of Music recently?
20:02:53 <orzo> it's mostly IO because of pointers and state
20:02:53 <cbarrett> RIP paul hudak :(
20:03:13 <orzo> i wanted to make it lazy so i could run a patch incrementally and feed the output into a parser
20:03:30 <orzo> but i might also might want to write the result to a file directly
20:03:52 <glguy> orzo: It'll probably be better to not rely on lazy io for that
20:04:11 <glguy> many parser frameworks support incrementally supplying chunks of data
20:04:56 <dmj`> > id flip const (flip id) id id id $ 4
20:04:59 <lambdabot>  4
20:05:18 <orzo> why wouldn't i want to support making a lazy bytestring?
20:06:25 * nshepperd . o O (shitpost: but if you make (<>) strict, then () works as a two-element monoid {(), ⊥} with () as the unit)
20:07:48 <shachaf> Right now it's not even a monoid.
20:11:05 <orzo> this whole algorithm could probably be done with STRefs.  Its IO because of ffi and pointers
20:11:41 <orzo> is it really so bad to provide lazy io in that situation?
20:15:05 <nshepperd> that seems like it should be possible to do without relying on anything in particular being evaluated
20:16:01 <orzo> the reason i'm relying on evaluation is that i'm sharing the same basic worker function that creates a lazy object to alternatively perform IO directly
20:16:34 <orzo> if i don't share the code, then sure, i don't have the issue
20:16:39 <orzo> but that seems lame
20:16:55 <glguy> I think once you start worrying about the strictness of () because you're trying to control evaluation as it relates to running your IO that you shouldn't be using lazy IO
20:17:29 <glguy> It's fine up to the point you start caring when it's evaluated, then we have better tools for managing it than tying it to evaluation
20:20:31 <orzo> why don't you just admit that you would not use lazy io under any circumstances
20:21:54 <glguy> to avoid lying
20:22:09 <nshepperd> consider this definition for lazily reading an infinite stream from a file (a very simplified version of hGetContents): hReadForever h = unsafeInterleaveIO (do { c <- hGetChar h; cs <- hReadForever h; return (c:cs) })
20:22:22 <nshepperd> it's lazy, and it does IO
20:22:49 <nshepperd> but it doesn't care about the order of evaluation
20:23:09 <orzo> that situtation is excatly the same as mine
20:23:57 <nshepperd> the structure of the do block ensures that the characters can't be read out of order or any such thing
20:24:05 <glguy> It's the same as long as you also don't care if anything gets evaluated
20:24:07 <orzo> i have the same situation
20:24:16 <nshepperd> so there's no need to force anything or worry about strictness
20:25:28 <orzo> now, imagine hGetContents was a higher order function that lets you plug into the IO it does.  Then maybe you want to perform the io directly and return ().  Well, you better make (<>) strict for () then.
20:25:57 <orzo> when i'm using the lazy io, i don't care about the evaluation, its the -strict- case where it becomes an issue
20:26:10 <glguy> Right, that's where things went wrong
20:26:47 <orzo> so making a combinator instead of a function like hGetContents which can -only- do lazy, is the prefered solution?  Code-reuse be damned?
20:27:05 <orzo> seems like StrictUnit is a better solution
20:27:37 <orzo> er, s/is the prefered soution/is the problem/
20:27:44 <nshepperd> i'm not really sure what you're talking about, but
20:28:02 <nshepperd> lazy io isn't for 'performing' things
20:28:14 <nshepperd> it's for reading things
20:28:25 <nshepperd> in other words, doing things without side effects
20:29:01 <nshepperd> or at least with side effects that don't matter
20:29:01 <orzo> it's side-effect is only internal state variables.  Like the ST monad
20:29:25 <orzo> when you use a lazy monoid and don't add your own dubious io 
20:29:55 <orzo> but why not do-stuff directly and not use the lazy monoid using StrictUnit as a placeholder?
20:30:44 <orzo> it's a library interface, so i wanted to provide for both cases
20:33:45 <nshepperd> you still haven't really explained why it matters that the () is evaluated
20:34:03 <nshepperd> if the thing has side effects that matter its type should be IO ()
20:34:13 <orzo> hReadForever h actOnChar = unsafeInterleaveIO (do { c <- hGetChar h >>= actOnChar; cs <- hReadForever h actOnChar; return (c <> cs) })
20:35:13 <orzo> actOnChar can return StrictUnit and print the character immediately, or it can return a singleton list and build the lazy string
20:35:50 <orzo> i could have made that as two seperate functions and then you'd have no complaint
20:35:58 <orzo> but hReadForever is simple, my code fills a page
20:36:02 <orzo> why duplicate it
20:38:08 <orzo> also, my code acts on a Ptr and byte-count.  If i can act direclty, that will avoid a copy, but if am building a bytestring, i'd want the coppied chunks to come lazy
20:43:08 <nshepperd> alright
20:43:22 <nshepperd> well, if the goal is to print the characters, you don't want lazy io
20:43:42 <nshepperd> so yes, you should have a separate function without unsafeInterleaveIO
20:45:07 <orzo> i could add an argument to do the delay.  You pass 'id' for strict, and 'unsafeInterleaveIO' to do it lazy
20:45:38 <nshepperd> hReadForever h actOnChar isLazy = (if isLazy then unsafeInterleaveIO else id) (do { c <- hGetChar h >>= actOnChar; cs <- hReadForever h actOnChar isLazy; return (c <> cs) })
20:45:40 <nshepperd> sure
20:45:56 <nshepperd> refactor from there...
20:46:10 <orzo> i'm not sure why we're bothering
20:46:37 <nshepperd> but unsafeInterleaveIO should only ever be applied to an argument that you don't care if it's ever executed
20:46:47 <nshepperd> is the general idea
20:50:55 <nshepperd> if you want to use StrictUnit i can't stop you but imo that's a hack and it will only lead to regret
20:52:09 <orzo> data BufferEater m where { Lazy :: (ByteString -> m) -> BufferEater m; Strict (ByteString -> IO ()) -> BufferEater () }
20:52:57 <orzo> the Lazy case can be fed a copied bytestring for safety, and the strict one can be given a pointer to a c library's internal buffer
20:54:52 <orzo> i also removed teh posibility of adding side-effects when doing lazy
21:04:03 <nshepperd> did you know that IO () is also a monoid
21:05:17 <nshepperd> so 'hReadForever h (\c -> pure (printChar c)) :: IO (IO ())' also works
21:05:44 <nshepperd> that lazily reads the file, and produces a non-lazy io action that prints all the characters
22:21:38 --- mode: glguy set +v Delvis
22:22:59 --- mode: glguy set +v Delvis_
23:10:44 <leifmetcalf> Why are type functions called type families?
23:19:40 <c_wraith> leifmetcalf: they're not really functions in the sense of term-level functions.  You can't partially apply them, etc.  They're really restricted in comparison.
23:33:02 --- mode: glguy set +v rockman37
23:33:15 <rockman37> Hi. I am new to Haskell. I'm trying to understand how the compiler knows when it has reached the end of a function definition. I had assumed it reached the end when it had found enough arguments to satisfy any functions called within the function body, but a quick test shows this to not be the case. Can anyone point me to something to read that will correct my understanding?
23:35:27 <cocreature> rockman37: it depends on the indentation
23:35:53 <trcc> I am trying to send a C struct to Haskell, and to create the Storable in Haskell I am using hsc2hs. In the struct, the fifth element is a void *. How would I implement this in the Storable (since it is not possible to use #peek to void*), such that the peekByteOff becomes correct? I could manually write ... `ap` ((\hsc_ptr -> peekByteOff hsc_ptr 32) p), but I would like hsc to generaete 32
23:36:10 <rockman37> cocreature: Ah, okay. Is this similar to how semantic whitespace works in Python, if you're familiar with that?
23:36:47 --- mode: glguy set -v rockman37
23:36:48 <cocreature> rockman37: yeah the exact rules are slightly different but the idea is the same
23:36:58 <rockman37> cocreature: Got it, thanks.
23:39:13 <cocreature> trcc: what error do you get when you try to use #peek on void*? I seem to recall that this should work just fine
23:39:17 <tdammers> actually it depends
23:39:26 <tdammers> not all function definitions use layout
23:39:39 <trcc> rror: offsetof requires struct, union, or class type, 'fmi2ComponentEnvironment' (aka 'void *') invalid
23:39:40 <trcc> cocreature: 
23:41:23 <cocreature> trcc: that looks like you are trying to peek in the void pointer itself instead of the peeking in the field of type void * in your struct
23:42:09 <trcc> cocreature:     `ap`  (#{peek fmi2CallbackFunctions, fmi2ComponentEnvironment} p)  
23:42:48 <trcc> Struct fmi2CallbackFunctions here: https://github.com/modelica/fmi-standard/blob/master/headers/fmi2FunctionTypes.h and fmi2ComponentEnvironment here: https://github.com/modelica/fmi-standard/blob/master/headers/fmi2TypesPlatform.h
23:43:03 <rockman37> Another question: LYAH tells me that I should use 'let' when defining things inside ghci, but the examples work without it. What, then, is the purpose of 'let'?
23:43:06 <trcc> ahh!
23:43:29 <trcc> Thank you cocreature
23:43:45 <trcc> used typename instead of variable name
23:43:55 <cocreature> :)
23:44:03 <trcc> ^^
23:44:25 <cocreature> rockman37: being able to omit "let" is a relatively new addition to ghci
23:44:38 <rockman37> cocreature: Ah, thanks.
23:46:26 <trcc> it is fair to represent void* as Ptr () right?
23:46:35 <cocreature> yeah
23:46:37 <trcc> cool
23:47:12 <cocreature> although you might be able to come up with a better type parameter than ()
23:48:13 <trcc> cocreature: it is unknown what it will contain at the state it is passed
23:48:25 <trcc> just allocated memory I believe
23:49:55 <cocreature> trcc: in the C API it might be unknown but once you built a Haskell API on top of that, you might want to fix the type
23:50:11 <trcc> I will try to do so
23:50:24 <cocreature> or even omit it alltogether since we have closures in Haskell so the common case of passing an environment as a void* isn’t required
23:50:56 <Ariakenom> C's void ~= Haskell's ()
23:51:50 <cocreature> Ariakenom: I’m not sure that really applies in the case of a void*. that’s commonly used to work around the lack of polymorphism
23:58:18 <Maxdamantus> I imagine it'd be more logical to use a void type.
23:59:21 <Maxdamantus> void in C is a void type .. it's just weird language semantics that enable it to be used for purposes that would be better fulfilled with a unit type.
