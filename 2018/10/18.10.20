00:42:55 --- mode: glguy set +v robstr
00:43:43 <robstr> Morning, is there a convenient way to embed javascript inside scotty applications ?
00:54:41 <c_wraith> what do you mean by "embed"?  source literal?
01:09:48 --- mode: glguy set +v shiro[cloud]
03:05:05 <oo_miguel> is there some function like 'words' but it will break on tabs as well?
03:05:48 <oo_miguel> Or should I use splitRegex ?
03:07:04 <Ariakenom> % words "a\tb"
03:07:04 <yahb> Ariakenom: ["a","b"]
03:07:15 <Ariakenom> oo_miguel: it already does?
03:09:45 <oo_miguel> Ariakenom: oh, sorry. hmm
03:12:14 <fiatjaf> dmj`, my miso onClick handlers have suddenly stopped being called, they were working and at some point they aren't called anymore. everything else still works. is that a trivial problem you've seen many times and are able to quickly help me or should I open an issue?
03:12:15 <oo_miguel> Then I have a mistake somehwere else, thank you 
03:12:57 --- mode: glguy set +v Confused
03:13:35 <Ariakenom> oo_miguel: np gl
03:14:23 <oo_miguel> Ariakenom: ah I was reading the wrong input file, how emberassing... 
03:49:23 <lavalike> @src words
03:49:24 <lambdabot> words s = case dropWhile isSpace s of
03:49:24 <lambdabot>     "" -> []
03:49:24 <lambdabot>     s' -> w : words s'' where (w, s'') = break isSpace s'
03:54:46 <cppxor2arr> using BangPatterns is "data T = T !Int; f (T x) = ..." the same as "data T = T Int; f (T !x) = ..."?
03:55:26 <cppxor2arr> is "data T = T !Int; f (T !x) = ..." the same as the first?
03:56:05 <boj> well, if you use T in a non-F function then the Int could very well not be fully evaluated
03:56:51 <cppxor2arr> ok
03:57:14 <desperek> hi, what IO [String] is?
03:57:34 <dminuoso> desperek: It is an action that, as a result would produce something of type `[String]`
03:57:41 <dminuoso> desperek: But itself it is just an *action*
03:57:56 <desperek> dminuoso, and what can i do with it
03:58:11 <ski> combine it with other actions, into a larger action
03:58:14 <desperek> i mean, can i print it or something :?
03:58:20 <cppxor2arr> yes
03:58:21 <ski> eventually defining `main' to be such an action
03:58:36 <ski> there is no `Show' instance for `IO'-actions
03:58:42 <boj> desperek: you cannot print it until you "run" the action
03:58:46 <cppxor2arr> oh nvm talking about IO a
03:58:52 <cocreature> you can create a new action that will first run that and then print it
03:59:08 <ski> (you can also execute `IO'-actions in the interactor. that's similar to defining `main' to be an `IO'-action, then executing the program)
03:59:31 <cocreature> :t (\xs -> print =<< xs) :: IO [String] -> IO ()
03:59:32 <lambdabot> IO [String] -> IO ()
04:00:34 <ski> if `xs' is your action of type `IO [String]', then `print =<< xs' is a larger action that, when (later) run/executed, will first execute `xs', then print the resulting `[String]'
04:01:04 <ski> one could also write `do strings <- xs; print strings', instead of `print =<< xs', it means the same thing
04:01:32 <ski> desperek : what are you trying to do/achieve ?
04:02:03 <desperek> ski, the =<< worked actually. http://adit.io/posts/2012-04-14-working_with_HTML_in_haskell.html#hello-world something like that BUT separated it by functions
04:04:30 <dminuoso> @tell kosmikus Hey, do you have a rough time when Munihac will begin on Friday?
04:04:30 <lambdabot> Consider it noted.
04:04:56 <ski> desperek : perhaps you should first try to grasp basic `IO', before trying to tackle `HXT' arrows ?
04:06:56 <cocreature> or even avoid hxt altogether :)
04:07:36 <desperek> ski, maybe, though i find it kind of easier to learn when doing something and i have an idea to do something (fml for this english);; cocreature yea, ill probably use tagsoup instead of handsome
04:08:16 <dminuoso> desperek: Well the thing is arrows are a rather abstract concept. You should probably be comfortable with the basics in Haskell before stepping into more advanced topics.
04:08:25 <dminuoso> It's just more efficient for your sake as well as ours.
04:10:16 <desperek> probably :v
04:14:35 <oo_miguel> I suppose I should not use Map.Map to insert a lot of elements on runtime right?
04:20:45 --- mode: glguy set +v _AK3R_
04:23:41 <_AK3R_> Hi  every  body!!
04:23:57 <dminuoso> Hello there.
04:24:02 <_AK3R_> somebody here?
04:24:27 <dminuoso> Yes, there are exactly 1270 people in here right now.
04:25:35 <_AK3R_> hoo, i can  see it.. but nobary  talk...
04:26:22 <dminuoso> _AK3R_: Most are perhaps busy building programs, reading papers, sleeping, debugging or socializing?
04:26:44 <ggole> Or we are bots.
04:27:08 <noumenon> No offense, but, uh, you are a robot, aren't you?
04:27:20 <ski> we all are
04:28:26 * ski idly wonders whether _AK3R_ is new to IRC
04:29:48 <desperek> is there a reason why does cabal compile all the packages?
04:29:58 <desperek> s/le/les
04:30:02 <desperek> \/
04:30:38 <alexelcu> Hi all — so I'm trying to build a simple app with Haskell and I want to read some sort of configuration file — was thinking of using `deiko-config` for parsing HOCON files; what do people use with Haskell normally for config files? Any preferred format or libraries?
04:31:02 <boj> check out dhall
04:33:24 --- mode: glguy set +v alexknvl_
04:33:36 <bollu> quick theory question: are arrows analyzable statically like applicatives are?
04:34:13 <dminuoso> alexelcu: I usually use environment variables.
04:35:13 <alexelcu> dminuoso: that works, but I need to describe a list of things; checking out `dhall` now
04:35:53 <boj> dminuoso: that gets a little unwieldy once you push 50+ config variables
04:35:54 <dminuoso> alexelcu: I use semicolon separated lists or similar tricks
04:35:57 <dminuoso> alexelcu: or JSON encoding.
04:36:03 <dminuoso> boj: Nope, it actually makes it bearable.
04:36:17 <ski> bollu : that's part of the motivation for them. however the presence of `arr' means that it can't be perfect
04:36:18 <boj> to each their own i suppose
04:36:24 <dminuoso> boj: files are persistent state - an environment variable is - to me at least - just program arguments. ;)
04:36:41 <dminuoso> but ones that are easily injectable into a docker container
04:36:46 <bollu> ski I see. IIRC, arrow-based parsers try to preserve maximal static information for optimisation, while still having a dynamic part, right?
04:37:07 <boj> dminuoso: to be fair we use habitat to update some of the variables in place using its orchestration capabilities
04:37:08 <ski> iiuc what you mean, yes
04:37:15 <bollu> ski what's the "largest" / "most powerful" statically analysable structure? If such a thing doesn't exist, is there some collection of structures? Applicative is one, right?
04:37:37 * ski doesn't know about "largest" / "most powerful"
04:38:07 <ski> `Applicative' is a nice candidate, at least
04:38:26 <boj> alexelcu: dhall is a nice non-turing complete configuration language that gives you type safety and programming capabilities. the author is also very thorough
04:38:26 <alexelcu> So I need to build a really simple web app; what do you guys think of — https://github.com/scotty-web/scotty ?
04:38:36 <bollu> ski :) What are the "maximal elements" in this case, then?
04:38:55 <boj> alexelcu: scotty is great for simplicity. move on to servant if it grows more complex
04:38:56 <dminuoso> alexelcu: Scotty is a fine library to make simple things with. :)
04:38:58 <ski> bollu : i don't even know how to define the partial ordering :)
04:39:35 <bollu> ski "intuitively" ;) 
04:40:16 * ski isn't very good at thinking "intuitively"
04:40:39 <dminuoso> boj: Right now we are playing with the thought of making docker containers completely independent of input arguments.
04:40:46 <dminuoso> Baking the complete config into docker containers.
04:41:16 <alexelcu> boj: dminuoso 
04:41:21 <alexelcu> thanks
04:41:23 <dminuoso> So in order to change the config you'd make an appropriate pull request, and have CI build, test and deploy it :)
04:42:10 <dminuoso> Not quite sure of possible consequences, but the idea seems appealing.
04:42:19 <ski> bollu : the main point here which distinguishes `Applicative' and `Arrow' from `Monad' say, is that the latter has `(=<<) :: (a -> m b) -> (m a -> m b)', which takes an arbitrary function that computes an action as result. and we can't really analyze functions in general
04:42:56 <bollu> right. 
04:43:24 <ski> bollu : while otoh we don't have that with the two former (though we have `arr :: (a -> b) -> ar a b' with `Arrow ar', which i still bad, but not quite as bad, since the function doesn't involve a computed arrow)
04:43:54 <ski> (s/which i still bad/which is still bad/)
04:44:36 <ski> .. however, one could wonder, with a formulation of `Monad' using `join' instead, where does the problem lie ?
04:45:29 <cppxor2arr> if i had a config loaded and would use it everywhere i would use a ReaderT. should i use StateT if i want to read the config and modify it?
04:45:45 <ski> `fmap :: (a -> b) -> (m a -> m b)' might be considered somewhat comparable to `arr'. however, even `Applicative' gives us `fmap', via `pure'
04:46:13 <boj> dminuoso: we do something similar with habitat. the moment an artifact comes out of CI it goes into bldr, then auto-deploys and auto-updates the templated dhall configs
04:46:28 <ski> still, `join :: m (m a) -> m a' takes an action that "dynamically" (when executed), will produce another action, which is comparable to the `a -> m b' callback in `(=<<)'
04:47:10 <dminuoso> cppxor2arr: Personally I've learned to be careful with StateT. You do not need ReaderT though, you could as well just manually pass it around.
04:47:17 <bollu> Hmm
04:47:21 <ski> bollu : not sure whether this helps any, or it's all things you already knew
04:47:23 <cocreature> Monads aren’t necessarily as opaque as people sometimes think. http://www.cse.chalmers.se/~josefs/publications/icfp2013.pdf provides a pretty nice example of that
04:47:24 <bollu> f =<< x = join $ fmap f x 
04:47:28 <cppxor2arr> dminuoso: but i dont want to manually pass it out :P
04:47:33 <cppxor2arr> around*
04:47:38 <bollu> I had never considered the question as to why `join` isn't problematic
04:47:41 <bollu> that's a good question :) 
04:47:46 <bollu> Thanks for asking me that
04:47:52 <bollu> join is* problematic
04:48:02 <boj> cppxor2arr: ReaderT is a decent solution, especially once you start passing things around to a few hundred functions
04:48:03 <ski> right, was just about to say :)
04:48:39 <cppxor2arr> can i modify the config (for example reloading it) with ReaderT?
04:48:56 <boj> cppxor2arr: in the case of modifying things, possibly using a TVar from STM? i do that to pass around a seeded StdGen
04:49:14 <boj> depends on your application architecture really
04:50:38 <cppxor2arr> wont i have to pass around the TVar?
04:51:00 <cppxor2arr> or do i use a ReaderT with a TVar?
04:51:09 <boj> the latter
04:51:25 <boj> well
04:52:03 <boj> i do the latter at least, but i pass a lot of config data around as well
04:53:30 <cppxor2arr> hmmm ok
04:53:54 <ski> cocreature : "In a sense you're doing evaluation at the same time as compilation." :)
04:54:13 --- mode: glguy set +v asib
04:54:49 <ski> (oh, and the writer monad comment occured to me as well)
04:54:53 <asib> is there a way to take a two argument function and apply another function to just the first argument
04:54:57 <ski> cocreature : nice paper, ty :)
04:55:04 <asib> e.g. I have this: (\f _ -> n *> f)
04:55:28 <asib> is there something like appFst (n *>)?
04:55:35 <dminuoso> asib: const . (n *>)
04:55:50 <cocreature> ski: yeah I really love that paper :)
04:57:08 <asib> dminuoso: ah of course, thank you!
04:57:53 <dminuoso> The trick "use lambdabot in private" to appear really smart works great!
04:58:14 * dminuoso puts his "Make People Smart Again" hat on
04:58:37 <cppxor2arr> boj: is there a better way to lift readTVar to the ReaderT monad than "liftIO readTVarIO"?
04:59:04 <cocreature> dminuoso: “use lambdabot in private so that people think you have nothing better todo than codegolfing other people’s code” :)
04:59:42 <dminuoso> I just feel shabby that I didn't do *that* in my head.
05:00:05 <dminuoso> cocreature: Heh yeah
05:00:50 <boj> cppxor2arr: i am not sure what you are asking, sorry
05:01:15 <ski> cocreature : re compositionality and `Return',`Bind' -- the fact that they directly encode these as data constructors means that the representation doesn't follow the monad laws. but if we consider a quotient type (effectively an abstract data type) represented by this "tree" type, it could still satisfy the monadic laws, as long as no operation is exported which allows us to tell the difference between trees which are rebalanced according to the laws
05:01:30 <ski> (er, cut off near ".., as long as no operation is exported which allows us to tell the difference between trees which are rebalanced according to the laws")
05:02:16 <cocreature> ski: it means that the representation doesn’t follow the monad laws with regards to (==) if we insisted on (==) then we couldn’t talk about IO, (->) r, … either
05:02:35 <cppxor2arr> boj: to access the config wouldn't i do "config <- ask; config' <- liftIO $ readTVarIO config" to get the config?
05:02:47 <__monty__> ski: It wasn't cut off : )
05:03:03 <ski> __monty__ : ok, i suspected it, anyway :)
05:03:37 <boj> cppxor2arr: you probably want to use atomically $ readTVar config, especially if your app is multithreaded. you don't have to be in IO to use it
05:03:50 <ski> i don't insist on `(==)'. however if `(==)' is defined, then i expect `forall x y. x == y = True => x = y' (`x = y' in the sense that we can't observe any difference between `x' and `y')
05:04:16 <cppxor2arr> thanks
05:04:46 <cocreature> boj: huh? how do you not have to be in IO to use atomatically $ readTVar config
05:05:06 <ski> (so, when i say "allows us to tell the difference", i'm really talking wrt `=', not `=='. however `(==)' would be an *example* of an operation which might allow us to tell a difference where no (denotational) difference ought to be observable)
05:05:16 <boj> cocreature: huh, yeah. i need to stop giving advice late at night :p
05:05:39 <cppxor2arr> wait then i have to do... liftIO . atomically $ readTVar config
05:05:44 <boj> cppxor2arr: sorry, atomically is an IO action
05:05:51 <boj> yeah
05:06:03 <cocreature> ski: if you really want to be pedantic, they haven’t derived Eq in their code afaict ;)
05:06:20 <ski> cocreature : doesn't matter, is what i'm saying :)
05:06:33 <ski> i'm not really talking about `(==)'
05:06:48 <cocreature> imho what they have presented is the internal implementation, not necessarily the public API
05:06:54 <ski> right
05:07:09 <cocreature> so arguing about what the public API allows you to do is somewhat silly if it doesn’t exist
05:07:11 <ski> i like the way Mercury does quotient types better than the Haskell way, btw
05:08:08 <bollu> ski we can do quotients in haskell?
05:08:21 <ski> we can simulate them, using abstract data types
05:08:34 <ski> that's what implementing `Set' or `Map' in terms of trees does
05:08:54 <bollu> ah, right. 
05:09:30 <ski> the point is that in Haskell, there's no type difference between the quotient type (necessarily abstract (outside of the implementation) in Haskell), and the representation type
05:09:31 <boj> cppxor2arr: maybe a better example would be modifying the contents. atomically $ modifyTVar f
05:09:48 <bollu> cocreature, ski the paper referenced would be "Embedded Languages for Data-Parallel Programming"? Or the general array programming stuff in haskell?
05:10:24 <cocreature> bollu: referenced where?
05:10:25 <ski> the only help you have to distinguish is whether you're currently inside the implementation or not .. and that's a somewhat vague notion
05:10:26 <bollu> ski in haskell? or in mercury?
05:10:36 <ski> bollu : Haskell
05:10:41 <bollu> cocreature you said something along the lines of "I really love that paper" a couple screens ago, but I wasn't around to know what the context was
05:10:50 <cppxor2arr> boj: thanks for the help! trying to write an irc bot in haskell
05:10:51 <cocreature> bollu: the one I linked two messages or so before that
05:11:04 <boj> cppxor2arr: sounds like fun :)
05:11:15 <bollu> cocreature ty. Paper, welcome to read-pile 
05:11:27 <deltasquared> hmm, paper, sounds interesting, but my head has just caught fire trying to wrap itself around ReaderT
05:11:32 <ski> in Mercury, you declare a new type (operationally a `newtype') to be represented by a representation type, and you simultaneously give a custom equivalence relation on the representation type, to use as equality on the quotient type
05:11:46 <deltasquared> I thought it'd be a good start for understanding a transformer... nope, brain still on fire
05:11:53 <ski> the important point is that the data constructor for this new type is *not* considered to be injective !
05:12:15 <ski> that means that pattern-matching on it is a non-deterministic operation. and the system tracks this non-determinism for you
05:12:22 <__monty__> deltasquared: Maybe start with the Reader monad?
05:12:40 <Lycurgus> head catch fire, that's a good thing, right?
05:12:44 <deltasquared> __monty__: I get the general principle of that; I was more trying to approach transformers in general
05:12:53 <bollu> ski neat! 
05:12:57 <ski> (this is similar to Haskell distinguishing between `IO a' and `a' (or `() -> a'), while most other languages do not make such a distinction)
05:12:59 <jebes> afaik its just the sum of all the monads in the stack
05:12:59 <jebes>  
05:13:03 <deltasquared> Lycurgus: not in this example :/
05:13:14 <jebes> so if you have Readter
05:13:32 <__monty__> Lycurgus: It's the only side-effect haskell hasn't managed to wrangle : )
05:13:38 <Lycurgus> :)
05:13:54 <deltasquared> besides, last time I checked, Reader was just ReaderT stacked on Identity... at least I'm pretty sure I saw that in the source code
05:14:00 <jebes> whoops, ReaderT over MaybeT, you first have the concept of failure, but on top of that you can read from an environment
05:14:07 <ski> bollu : anyway, you have to promise to the implementation that your equivalence relation really is an *equivalence* relation. also, at the point where you think that your output doesn't depend anymore on the actual representations picked for the inputs, you also have to insert a "promise" pragma stating this proof obligation on your part
05:14:34 <deltasquared> jebes: I'm more trying to understand how that happens; my initial intuition was "wrapping" >>= and co, but it seems a little more complicated than that
05:14:37 <jebes> ski: I'm a huge prolog fan but haven't done much with mercury, is it used anywhere
05:14:38 <ski> bollu : in Haskell, it's not so clear in the source where the latter type of promise occurs
05:15:27 <deltasquared> __monty__: if nobody is around to hear your brain explode, is it really a side effect? :P
05:16:03 <ski> jebes : there are some companies who use it. if you like logic programming, then i think taking a look at Mercury is worth it (for the static mode and determinism system, if nothing else). Mercury also is pure, no side-effects, like Haskell and Clean
05:16:26 <deltasquared> logic programming as in wiring up boolean gates and such?
05:16:28 <ski> jebes : that said, "Re: Mercury in academic teaching?
05:16:34 <Lycurgus> as in prolog
05:16:44 <deltasquared> well I ain't used prolog...
05:16:48 <deltasquared> *wikis*
05:16:51 <jebes> ski: i'll check it out whenever i have an modicum of free time.
05:17:12 <jebes> swi-prolog is a really nice environment, tbh. 
05:17:28 <ski> jebes : that said, "Re: Mercury in academic teaching?" by Richard A. O'Keefe in 2006-10-(09|10) at <http://www.mercurylang.org/list-archives/users/2006-October/004000.html>,<http://www.mercurylang.org/list-archives/users/2006-October/004011.html> contains some interesting reflections (applying more generally than just logic programming)
05:17:32 <lavalike> why does this list 8.6.1 before 8.4.4? https://www.haskell.org/ghc/
05:17:32 <Lycurgus> it's the ghc of pl
05:17:35 <ski> SWI is nice, sure
05:18:11 <bollu> ski I actually don't see, won't we need the promise everywhere? As in, pretty much any operation you would try to perform on a set-as-balanced-tree would need to prove that it is equivalence relation friendly, right? Well, maybe not lookup, but insert /delete would have to?
05:18:12 <cocreature> lavalike: because 8.6.1 was released before 8.4.4?
05:18:14 <Lycurgus> but unlike hs there are more options in prolog
05:18:16 <boj> lavalike: probably due to the release cycle. 8.4 is still being worked on
05:18:33 <[exa]> wow the benny vs. björn paper is good
05:18:40 <lavalike> I am finding this confusing, is there a secret meaning to this?
05:18:40 <deltasquared> interesting, MaybeT is a newtype, ok I'm definitely going to have a look at this
05:18:43 <Lycurgus> there are even some hs pl melanges
05:18:45 <ski> deltasquared : functional programming expresses computation through expressions and functions. logic programming expresses computation through logical formulae and relations/predicates. predicates can be "reversible", can often be run both "forwards","backwards" and "sideways"
05:19:23 <__monty__> [exa]: Benny vs bjorn?
05:19:32 <boj> lavalike: patch versions are still released while a newer compiler is being worked on and released
05:19:40 <cocreature> lavalike: a fair amount of people are still going to be using 8.4 for quite some time so it makes sense to make a bugfix release if it’s not too much effort
05:19:53 <[exa]> __monty__: the one that cocreature posted    (cocreature: thanks a lot)
05:19:58 <lavalike> clear as the sky! thanks friends
05:20:01 <ski> bollu : as long as we only use operations that act on the abstract quotient type, not peeking ourselves into the representation, we don't have to promise anything. it's enough that the primitive operations that *do* peek into representation fulfills the relevant promises
05:20:35 <bollu> ski Ah, I see. so once you prove it for the "building blocks", the rest is guaranteed to respect the equivalence relation. Gotcha
05:20:58 <ski> deltasquared : logic programming (especially if you add constraints to it) can be likened to solving an equation system
05:21:04 <ski> bollu : *nod*
05:21:32 <ski> bollu : this is one think that the Mercury approach makes more clear : where you do in fact have proof obligations, and where you don't
05:21:41 <ski> s/think/thing/
05:22:07 <bollu> ski can we actually write proofs in mercury? I didn't know it was dependently typed..
05:22:40 --- mode: glguy set +v drets
05:22:46 <ski> btw, fwiw, one can also use abstract data types to simulate subtypes, not only quotient types (in practice, these two are often combined)
05:22:51 <drets>  Hi, I am doing some crazy stuff like: let array = maybe [] (const $ [A]) myMaybe1 ++ maybe [] (const $ [B]) myMaybe2. How can I make it more elegant?
05:23:19 <bollu> ski how do you simulate subtypes?
05:23:26 <bollu> ski like lens does? ;) 
05:23:31 <__monty__> gentauro: You mentioned a talk where SPJ talked to Stroustrup. You linked this: https://youtu.be/06x8Wf2r2Mc It was interesting but there wasn't really talk between them, just a single remark from SPJ. Are you sure this was the talk you were thinking of? Discussion between originators of C++ and Haskell sounds too good to miss out on.
05:24:26 <cocreature> drets: toList (A <$ myMaybe1) <> toList (B <$ myMaybe2)
05:24:35 <ski> bollu : no proof writing. but you explicitly state at which point in the program you're promising something. you can also declare general laws (which the implementation is allowed to check (and complain about if incorrect), but is not required to), and which the implementation can use for some optimizations. mainly commutativity and associativity (and i think idempotency as well) is actively supported in that way
05:24:50 <__monty__> ski: Does mercury do backtracking like prolog? And if it does, how does that interact with effects or does it just have no effects whatsoever?
05:24:52 <bollu> ski I see, that is quite cool.
05:24:59 <lavalike> from brew: «we can't ship 8.6.1 because it doesn't pass its own testsuite» sad face
05:25:39 <drets> cocreature, thank you. it seems I also have somewhere bad design of my data model, otherwise I'd not have such code.
05:26:46 <cocreature> drets: converting maybes to lists is quite reasonable. what does feel a bit weird and might be worth thinking about is ignoring the value in the Maybe
05:26:48 <__monty__> lavalike: There is in fact a bug in 8.6.1: https://ghc.haskell.org/trac/ghc/ticket/15696
05:26:54 <ski> bollu : "how do you simulate subtypes?" e.g. `newtype SortedList a = SL [a]; sorted :: Ord a => [a] -> Maybe (SortedList a); sort :: Ord a => [a] -> SortedList a; toList :: SortedList a -> [a]; ...' -- you have "smart constructors" like `sorted' that refuse to construct a value if the representing value wouldn't be in the intended subtype
05:27:34 <ski> bollu : in the case of `Set' and `Map', a condition that the representing tree is balanced according to some balancing condition would correspond to such a subtype requirement
05:28:14 <lavalike> __monty__: wow!
05:28:19 <deltasquared> ski, bollu: the refined package comes to mind
05:28:47 <deltasquared> though I personally had difficulty in figuring out how to implement predicates for them...
05:29:40 <ski> __monty__ : yes, it has backtracking (however you can't alias as freely as in Prolog. the instantiation state is (mostly, apart from constraint logic stuff) known exactly by the compiler)
05:29:48 <bollu> ski  Hm, I see. But, throwing a runtime error/ Maybe-ing for the subtying (eg. check if the list is sorted) check feels distasteful somehow. 
05:30:31 <ski> __monty__ : the provided I/O operations (relations between old world state and new world state) are either deterministic or `cc_multi' which means that there may be multiple solutions but the implementation reserves the right to pick any one of them it likes (like what you get with scheduling of concurrent processes)
05:30:42 <cocreature> bollu: how else do you expect a conversion to a subtype to work?
05:31:06 <ski> __monty__ : the restrictions on handling unique references to data (like the I/O state) ensure that you don't backtrack over such operations
05:31:09 <bollu> cocreature prove the obligation? :) 
05:31:11 <cocreature> (I wouldn’t call them subtypes but that’s another story)
05:31:21 <deltasquared> bollu: you could always do the sort in-place if desired, so sort and then you get back the refined type. if the list is already sorted, no harm done
05:31:22 <cocreature> bollu: that assumes that you statically know the value
05:32:03 <deltasquared> for other data types, it may not always be possible to do such a transform, e.g. the subtype of some numeric type greater than 5
05:32:18 <cocreature> you can throw as much type systems and proofs as you want at it but if you want to go from a runtime, user provided value of type [Int] to SortedList you need a check somewhere
05:32:22 <ski> __monty__ : .. otoh, there is a notion of I/O tabling/memoizing, for debugging. basically it generetes IDs for each I/O state, and records the resulting value(s) of each primitive I/O operation. then when you rewind time in debugging, it just replays this trace of primitive I/O ops, rather than actually performing them again
05:32:30 <bollu> cocreature fair. 
05:33:01 <deltasquared> it'd be nice if you could guarantee at compile time that you'd get a valid subtype out (instead of Nothing because it failed the test) from a literal... sort of like constexpr pattern matching on the resulting Maybe I guess
05:33:19 <__monty__> ski: I don't quite see how you can guarantee you can't backtrack over the effects.
05:33:26 <ski> bollu : "how else do you expect a conversion to a subtype to work?" -- "cocreature prove the obligation? :)" -- well, in many cases, at some point you want to do run-time data validation :)
05:33:35 <bollu> deltasquared right, but It think the point that cocreature was trying to make is that there are cases when you _truly_ don't know 
05:33:52 <cocreature> the literal case is somewhat boring
05:34:20 <cocreature> if you really care about that you can throw TH at it, see merijn’s validated-literals package
05:34:39 <ski> __monty__ : Mercury keeps track of whether backtracking can occur, using static determinism checking
05:36:20 <ski> __monty__ : this really helps with the "I expected a result, but unexpectedly got \"No\"/`false' back instead. I have no idea where things got wrong." (which isn't helped by that some internal failures are just normal operation)
05:37:09 <ski> (see the "Prolog" entry of "A Brief, Incomplete, and Mostly Wrong History of Programming Languages Brief, Incomplete, and Mostly Wrong History of Programming Languages" by James Iry in 2009-05-07 at <http://james-iry.blogspot.com/2009/05/brief-incomplete-and-mostly-wrong.html>)
05:37:10 <bollu> cocreature neat package
05:39:01 * deltasquared has a look at the source code for MaybeT
05:39:10 <deltasquared> ok, that's a bit more understandable, I can sort of follow what it's doing now
05:39:30 <ski> it's short-circuiting `Maybe's in results
05:39:46 <deltasquared> that's different from the way ReaderT wrapped types though, intruiging
05:40:13 <deltasquared> it would appear the former guess at an intuition I had has been blown out the water. not to worry
05:40:20 <ski> yes, here we "add stuff" "inside" the monad `m'
05:40:36 <ski> (and `StateT' does both)
05:40:57 <deltasquared> now where has that "lift" thing gone, I assume lifting e.g. IO a into MaybeT IO a would be essentially fmap Just
05:41:08 <ski> (`ContT' is also fun in this regard)
05:41:20 <ski> deltasquared, yep
05:41:40 <deltasquared> :t lift
05:41:41 <lambdabot> (Monad m, MonadTrans t) => m a -> t m a
05:42:03 <deltasquared> oh, MonadTrans instance is where I'd look then
05:42:17 <ski> @type MaybeT . fmap Just
05:42:18 <lambdabot> Functor m => m a -> MaybeT m a
05:42:26 <bollu> next, monads that don't commute!
05:42:41 <deltasquared> ski: the source says it's liftM: lift = MaybeT . liftM Just
05:42:55 <ski> yes, but `liftM' is equal to `fmap' by law
05:43:01 <deltasquared> :t liftM
05:43:02 <lambdabot> Monad m => (a1 -> r) -> m a1 -> m r
05:43:05 <ski> @type fmap
05:43:06 <lambdabot> Functor f => (a -> b) -> f a -> f b
05:43:10 <deltasquared> well shoot
05:43:16 <deltasquared> why is liftM even there then
05:43:43 <ski> before `Functor' was a (transitive) superclass of `Monad', one had to use `liftM' rather than `fmap', in case one was polymorphic in a monad `m' (such as `lift' is)
05:44:03 <deltasquared> ski: so, legacy essentially?
05:44:10 <ski> now, there's still two reasons left for using `liftM' over `fmap' (or `(<$>)', which is the same thing)
05:44:49 <ski> (a) you may want to use a more specific operation over a more general one, for readability purposes. cf. using `map' instead of `fmap'
05:45:20 <ski> e.g. you may already have `fmap' for some other function in the snippet of code under question. using `liftM' for the monad may help keep things straight in the mind of the reader
05:45:50 <ski> the (a) point is of course up to subjective judgement. i'm just saying that sometimes some people would like to have this option
05:46:12 <deltasquared> fair enough, though in this particular case (maybe it's just my particular taste) I feel fmap would have made more sense and given a more intuitive explaination. but yeah, subjectivity warnings etc
05:46:18 <ski> (b) if you have already implemented `Monad' (not using `fmap'), then you can implement `Functor' by `fmap = liftM'
05:46:35 <ski> so `liftM' can serve as a default implementation of `fmap', in terms of `return' and `(>>=)'
05:47:02 <ski> ditto holds for `liftA' serving as a default implementation of `fmap', if you already have `Applicative'
05:47:24 * deltasquared holds hands to his head
05:47:28 <ski> (`liftA' is defined in terms of `pure' and `(<*>)')
05:47:37 <deltasquared> always so much information to take in with haskell >_<
05:47:52 <ski> deltasquared : in this particular case, it's probably just legacy, yes
05:49:11 <ski> (`liftM' (and `liftA') might perhaps be less efficient than a direct `fmap' implementation. i'm not sure whether there's a case where this makes a big difference, though)
05:53:52 --- mode: glguy set +v Mrbuck
05:54:15 <ski> __monty__ : in Mercury, `main' is allowed to be either `det' (deterministic, exactly one solution), or `cc_multi' (committed-choice multideterministic, conceptually at least one solution, implementation will pick one for you, rather than enumerate on backtracking)
05:55:31 <Mrbuck> Hi onepecular doubt I have which makes you better programmer Algorithms or Haskell  as noth teaches the way to program
05:56:00 <ski> __monty__ : the extant determinisms are `det' (one solution), `semidet' (semi-deterministic, at most one solution), `multi' (at least one solution), `nondet' (any number of solutions possible), `failure' (always fails), `erroneous' (doesn't terminate normally), together with the committed-choice variants `cc_multi' and `cc_nondet' which doesn't perform backtracking
05:56:52 <ski> __monty__ : `cc_multi' and `cc_nondet' are used in places one'd use a cut, or once/1, in Prolog, to prune away alternative solutions.
05:57:23 <ski> Mrbuck : what's noth ?
05:57:56 <ski> Mrbuck : i'd say you have to know at least some basic stuff about algorithms, to be a good programmer
05:57:58 <Mrbuck> ski:  both* 
05:58:32 <ski> learning Haskell would ideally entail also learning some things about algorithms. there's obviously other ways to learn about algorithms as well
05:58:35 <Mrbuck> ski:  But again algorithms if we see they are just a way of thinking right 
05:59:06 <Mrbuck> ski:  you mean you say learning haskell make you learn algorithms also 
05:59:09 <__monty__> Mrbuck: Algorithms are more important than the language you write them in *but* you do need to learn *a* language to write them in.
05:59:14 <ski> what i'm trying to say is that i think "Algorithms vs. Haskell" is an apple vs. orange comparision. you don't compare them with each other that way
05:59:42 <ski> yes. basic concepts of computing are more important than particular languages and technologies
06:00:03 <Mrbuck> Okay Thank you 
06:00:34 <ski> that said, i think Haskell is a good way to learn more about some particular concepts of computing :)
06:01:10 <ski> Mrbuck : i would suggest that you try to learn several languages, the more different, the better
06:01:25 <ski> (you don't have to learn them all at the same time, obviously)
06:01:40 <Mrbuck> ski:  different like one oop one logic and one functional right ?
06:01:46 <ski> yes
06:02:03 <Mrbuck> ok 
06:02:03 <ski> different approaches/methodologies to problem solving
06:02:17 <ski> more alternate tools in your thinking toolbox, to attack problems with
06:02:23 <__monty__> Also, Mrbuck, avoid thinking whatever language you choose to learn is "the best" language. That's a very counterproductive mentality.
06:03:02 <Mrbuck> __monty__:  wht do you mean? I didnt understand 
06:03:31 <ski> (otoh, also avoid thinking "all languages are basically the same, under technical considerations, it doesn't matter which i pick". some are "more equal than others", at least in some important regards)
06:04:07 <Mrbuck> but haskell is different and if we learn others we have to undo that learning
06:04:16 <Mrbuck> is what I haerd and read every where
06:04:28 <__monty__> Mrbuck: The first language I learned was python and I liked it. That made me look for a defense every time anyone said something critical of python. That doesn't help you learn anything, quite the opposite. I had to find out the hard way.
06:04:59 <__monty__> Mrbuck: Only if you already know other languages well.
06:06:25 <ski> Mrbuck : unlearning is unavoidable. prepare for it
06:07:25 <Mrbuck> ski:  thats why I want to learn Haskell first
06:07:52 <Mrbuck> but I am considering algorithms which are most focussed in job interviews
06:07:53 <alexelcu> Mrbuck: undoing the learning is imo overrated; all learning happens, and becomes more efficient, if it's based on prior experience. And while a language like Haskell is different from Python, or other mainstream choices, all prior knowledge can be put to good use
06:07:59 <__monty__> I posit that it's not. I knew python and java before learning haskell. I had no trouble learning it. Prolog otoh was way more difficult to grok.
06:08:22 <ski> when later learning imperative ways, you'll have to (temporarily) unlearn Haskell (or really functional) ways. after you have a firmer grounding in both ways, you can compare more fairly
06:09:35 <ski> alexelcu : yes. but there's also something to be said for suspending premature judgement/assumptions, while trying to learn to alternative way of thinking
06:10:42 <__monty__> I wonder whether functional -> imperative is really an easier transition than vice versa.
06:11:00 <ski> (often you'd not be aware of making such assumptions. attempting to come at it with a "beginners mind" can really help, rather than "an experienced Fortran programmer can write Fortran in any language")
06:11:01 <alexelcu> I don't think the two are very different to be honest
06:11:11 <ski> __monty__ : the data is inconclusive
06:12:18 <__monty__> alexelcu: That's what I thought at first too. I was like "Where are these mind-blowing epiphanies everyone talks about?"
06:12:21 <ski> when learning a new approach to something, you tend to focus more on what's different
06:13:13 <ski> also, some people already have more experience with higher-order programming (say. or recursion) in the imperative world, than others
06:13:18 <Mrbuck> ok cool thanks all
06:15:14 <ski> imo, it's clear that some portion of the "mind-blowing epiphanies" people talk about wrt FP is really about higher-order programming, or becoming more familiar with recursion. or with type inference, or sum types (with pattern-matching), for that matter
06:15:36 <ski> (but then, it's not exactly clear how one should define "FP", either)
06:15:37 <alexelcu> __monty__: there are epiphanies to be had, but those come much later, after you gain some experience ... interestingly if you look at the "best practices" in mainstream languages, the sane practices converge on functional programming; so I think there's a gradual evolution going on; e.g. I'm a Scala developer, former Java, Python, Ruby and Perl, now playing with Haskell :-)
06:16:05 <deltasquared> __monty__: the only epiphany I really had was when I realised I could apply haskell to a problem because it was a good fit, everything to do with the language itself beyond the basic term-level stuff has been a hard slog to comprehend
06:16:41 <deltasquared> (said good fit was reading a file from /sys on linux, and deciding a response (if any))
06:17:06 <cynapse> I can't seem to find any information on how to download a file over https. Anyone have any insight? 
06:17:21 <Deide> What's the mechanism for extracting a value from a Functor like Maybe without pattern matching?
06:17:29 <ski> Deide : no
06:18:16 <Deide> What do you mean no?
06:18:17 <Rembane> Deide: the fromMaybe might help you there.
06:18:28 <Rembane> :t fromMaybe
06:18:29 <lambdabot> a -> Maybe a -> a
06:18:36 <Deide> I know there are functions
06:18:48 <Deide> What's the implementation without using pattern matching?
06:18:56 <Rembane> Deide: There is none afaik
06:19:00 <Deide> Aha
06:19:04 <ski> Deide : for `Maybe', and `Either', and ..., there are library operations that do the pattern-matching for you
06:19:21 <ski> Deide : for a type that you *only* know is an instance of `Functor', there is no way
06:19:31 <ski> Deide : so, there is no general way. it depends on the particular type
06:19:51 <deltasquared> not all functors would really "contain" a value anyways...
06:19:53 <ski> also `fromMaybe' uses pattern-matching in its definition
06:20:07 <ski> deltasquared : indeed :)
06:20:31 <Deide> Right, so there's no other "basic" way of doing it without pattern matching I guess
06:21:11 <ski> (`IORef' is an example to consider. not it isn't a functor, but you can easily make a wrapper (`Coyoneda IORef') which is a functor, while it still doesn't "contain any value")
06:21:21 <deltasquared> ski: my internal understanding of functors and monads (not sure about applicatives, I haven't played with them much) is they're somewhat akin to promises, in the async sense. there may at some point be an a, or many a, and then (e.g. for Functors) your code runs... or it may never! (e.g. mapping empty list, Nothing, ...)
06:21:22 <ski> @src fromMaybe
06:21:22 <lambdabot> fromMaybe d Nothing  = d
06:21:22 <lambdabot> fromMaybe _ (Just v) = v
06:21:35 <ski> ^ how `fromMaybe' can be implemented
06:22:58 <ski> deltasquared : yes, although i would turn that around, saying promises might be a particular case of a functor, and a monad
06:22:58 <Deide> I'd always wondered if that sort of pattern matching desugared to something more basic, which is why I asked.
06:23:51 <deltasquared> ski: for me the idea of promise came first.. but yeah. in fact I read a bit of a "proof" in a github code fragment that suggests javascript ES6 promises can act as a monad. (though IIRC there wasn't a way to come up with "join")
06:24:12 <ski> (iirc, i hear people saying that, the way they've been formulated, they don't actually form a monad say. but that, presumably with no hurt in expressivity, one *could* have expressed them such that the monad laws are upheld)
06:24:45 <deltasquared> I assume functor too, I'm not sure but I'm pretty sure promises in other languages have a map operation of some sorts
06:25:11 <deltasquared> my brain is trying to say .then but I don't think that's quite how that bit works
06:25:15 <ski> deltasquared : imo, it's good to think that monads capture something about what promises provide. however, there's many *very* different monads, so you shouldn't expect other monads to behave in more detail like promises
06:25:55 <deltasquared> ski: oh, I'm aware, it's always a bit more abstract in general. getting to know a particular instance never hurts
06:26:10 <ski> as long as you're aware, it's fine :)
06:26:15 <deltasquared> (personally, I don't actually find the monad laws alone all that useful except in knowing how they enable do-notation to work, but eh)
06:26:54 <ski> Deide : nah, pattern-matching is the basic way to pick apart values of an algebraic data type (sometimes people says sum types or variant types, or disjoint union types, or variant record types, or ...)
06:27:01 <c_wraith> I think of the monad laws as being a formalization of "this doesn't do anything dumb"
06:27:46 <deltasquared> c_wraith: hah, that is certainly one way to put it
06:27:59 <ski> yes. the monad laws amount to "the refactoring laws re sequencing that you're already applying subconsciously without realizing and reflecting on it"
06:28:23 <Deide> Gotcha
06:28:46 <ski> that you can inline a call, by expanding it to a "sequence of commands", or vice versa, folding a subsequence of commands into its own definition
06:28:49 <deltasquared> it's a bit like with the applicative laws. I worked through them by substituting types, and realised what they were telling me, but they don't really tell you much about given instances, that's not really the point - it just stops the instances from giving you "teacup" as a response every time or something daft
06:30:19 <deltasquared> that's a point, I wonder if the prelude defines an Applicative instance for (Monoid m) => (m, a) like it does for Monad
06:30:53 <ski> deltasquared : yea. only knowing something is an instance of `Applicative' or `Monad' doesn't really tell you much of use, in itself (the exception is library operations which express complicated patterns of "abstract" sequencing, e.g. traversals over some data-structure, virtual or not). at some point, you need to know more about it than it being a monad or an idiom, to do any nontrivial useful stuff
06:32:25 <deltasquared> ski: yeah, I mean if you can write an operation that is weakened enough in what it requires (e.g. not a concrete type, it can only assume what Monad says), then great, but that's not true of all things
06:32:26 <ski> @type pure () :: Monoid m => (m,())
06:32:27 <lambdabot> Monoid m => (m, ())
06:33:24 <deltasquared> ski: I like to think of that monoidal monad (heh) as being useful as a primitive logging mechanism when it concats things...
06:33:33 <deltasquared> maybe make the monoid [LogMessage] or something
06:34:11 <deltasquared> no timestamps of course but I find it a nifty use of lazy eval all the same
06:34:18 <ski> the main use of an operation that is polymorphic over a monad or an idiom is when it's higher-order in the sense that an argument contains (or references) actions of that monad/idiom
06:34:22 <ski> e.g.
06:34:26 <ski> @type (>>=)
06:34:28 <lambdabot> Monad m => m a -> (a -> m b) -> m b
06:35:03 <ski> the first argument is a callback `m'-action, the second is a callback function producing an `m'-action
06:35:07 <ski> @type traverse
06:35:08 <lambdabot> (Applicative f, Traversable t) => (a -> f b) -> t a -> f (t b)
06:35:27 <ski> the first argument is a callback function producing an `f'-action
06:35:32 <deltasquared> does anyone else see a fish from that operator, I don't use >=> a lot but >>= makes me think of fishes too... or perhaps a plunger
06:35:37 <ski> the exception, of course, is
06:35:39 <ski> @type return
06:35:41 <lambdabot> Monad m => a -> m a
06:36:36 <deltasquared> > traverse f = sequenceA . fmap f
06:36:39 <lambdabot>  <hint>:1:12: error:
06:36:39 <lambdabot>      parse error on input ‘=’
06:36:39 <lambdabot>      Perhaps you need a 'let' in a 'do' block?
06:36:41 * deltasquared reads that a bit more
06:36:55 <deltasquared> oh, didn't realise that'd set the bot off, I was just quoting
06:37:54 <ski> one can define an operation `f :: M T -> M U' (for some monad `M') to be "referentially transparent" (wrt monadic actions) iff `f = (=<< (f . return))', which is the same as there being a `g :: T -> M U' such that `f = (=<< g)'
06:38:40 <ski> this means that `f' is not "serious" in the sense that it always executes its argument callback action immediately, and then doesn't touch it further, using the monadic result from that point on
06:39:24 <deltasquared> ski: err, at this point I'm afraid my brain has ran out of juice, I'm no longer following >_>
06:39:55 <ski> (er, sorry, the equations above should have been `f = ((f . return) =<<)' resp. `f = (g =<<)'. sorry)
06:40:08 <ski> deltasquared : let's say you have
06:40:20 <ski>   foo :: IO Bool -> IO ()
06:40:23 <deltasquared> no really stahp give me five minutes
06:40:33 <ski> ok, sure
06:40:52 <deltasquared> or ten. idk. had to get up early and I think the mid-afternoon slump is coming >_<
06:41:23 <ski> (i agree what i just said re "referentially transparent" above is a bit compact/opaque. if you're interested, i could try to elaborate on what i mean)
06:50:48 <deltasquared> ok, a bit better now...
06:50:50 <deltasquared> < ski>   foo :: IO Bool -> IO ()
06:50:53 <deltasquared> so you were saying
07:01:07 <ski> deltasquared : hm, ok
07:01:37 <ski> let's say you have
07:01:39 <ski>   foo :: IO Bool -> IO ()
07:02:04 <ski>   foo act = do b <- act
07:02:06 <ski>                ..b..
07:02:37 <ski> where `..b..' may involve `if b then ... else ...' or using `b' in a boolean operation, or something else
07:03:18 <ski> then i'd say this is not a "serious" use of a callback action `act', because you execute it immediately, and then don't execute it later
07:03:45 <ski> instead of having a call to `foo' in a `do'-expression, like
07:03:48 <ski>   do ...
07:03:59 <ski>      foo (do ...)
07:04:02 <ski>      ...
07:04:16 <ski> you could instead define `bar' as a variant of `foo', like
07:04:24 <ski>   bar :: Bool -> IO ()
07:04:30 <ski>   bar b = do ..b..
07:04:53 <ski> and then instead of the snippet that called `foo' above, we could replace it with one which calls `bar', like
07:04:56 <ski>   do ...
07:05:05 <ski>      b <- (do ...)
07:05:08 <ski>      foo b
07:05:11 <ski>      ...
07:05:59 <ski> (and then, if `(do ...)' contains a sequence of more commands, we could just inline that into the larger `do'-sequence, replacing the last command `cmd' in the sequence with `b <- cmd' to capture the result)
07:06:43 <ski> deltasquared : the important point is the realization that since `foo' immediately executes its action callback, we could instead just ourselves call that action right before calling `foo', and then instead pass the `b' result to `bar' instead
07:07:16 <ski> the point is that we don't *need* to pass a callback action to `foo' here, we could just as well pass only the monadic result of that action to `bar', otherwise behaving the same
07:08:08 <ski> so, `foo' is a "non-serious", or "referentially transparent (wrt monadic actions)" operation, in terms of it having a callback action
07:08:47 <ski> otoh, a "serious", or "referentially opaque (wrt monadic actions)" operation would be one that takes a callback action, and *doesn't* immediately execute it (and then doesn't execute it later)
07:08:55 * deltasquared reads over that a few times to try to get it to sink in
07:09:02 <Dark_Ethereal> All making sense to me. Why write a function that produces an action when fed another action if instead you can write a function that takes a pure value, and can be fed an action that produces a value using `>>=`
07:09:44 <deltasquared> I may get it in a minute, I just have challenges reading the code of others, it doesn't process
07:09:52 <ski> e.g. you might want to let such an operation do something else *before* calling the callback. or you might want to "bracket" the callback invokation in some way, e.g. allocating some dynamic resource, establishing a dynamic context, adding an exception handler, &c.
07:10:08 <ski> or you might want (possibly) execute the callback many times
07:10:29 <ski> or you might want to register the callback to (possibly) be executed later, after the current operation has already finished execution
07:10:54 <ski> all these would be deviations from the trivial case of "execute callback immediately, then never execute later"
07:12:34 <ski> so .. since we (almost never, unless we have to fit a particular predefined interface) write "non-serious" operations-with-action-callback, in practice, if we see an operation with an action callback, it's normally safe to assume that the operation *does* use the callback in some "interesting" (or "referentially opaque") way
07:13:17 <ski> deltasquared : *nod*. i could take a pause, if it helps. any questions ?
07:13:57 <deltasquared> ski: right, ok, I think I get it now, because it would be otherwise pretty pointless to pass an IO a unless something special was going on apart from running the action just once to get the value out...
07:14:18 <deltasquared> :t forM
07:14:20 <lambdabot> (Monad m, Traversable t) => t a -> (a -> m b) -> m (t b)
07:14:33 <deltasquared> ... no, what was the other one, or am I thinking of a wikibook exercise
07:14:40 <ski> of course, you should note that `act >>= continue' is, strictly speaking, "non-serious" in the use of the callback `act'
07:14:43 <ski> @type (>>=)
07:14:44 <lambdabot> Monad m => m a -> (a -> m b) -> m b
07:15:09 <Franciman> Hi
07:15:27 <ski> but that's to be expected, since `(>>=)' (which desugaring of `do'-notation amounts to) is how we *specify* what it means that an operation-with-callback is "referentially transparent"/"non-serious" in the present sense
07:16:14 <ski> (when `act >>= continue' is executed, it immediately executes `act', then doesn't execute it later. this formally fits the pattern we're talking about, even though it feels a bit strange to apply the definition i suggested to a primitive like `(>>=)')
07:16:30 <deltasquared> the thing that comes to mind was essentially the haskell IO equivalent of a numerical for loop, like "for 1 10 (putStrLn "BANG")" where "for" was actually written as a library construct (that part, imperative constructs in a freaking library, now that blew my mind)
07:17:23 <tdammers> yeah, and it gets better
07:17:54 <tdammers> you can write that imperative stuff such that the same code can be used to run it, inspect it, generate code, etc.
07:18:02 <ski> @type forM :: Monad m => [a] -> (a -> m b) -> m [b]  -- this is a good example of a useful operation that does *not* (in itself) depend on knowing more about the particular monad. of course, to actually *use* this for good effect, you *do* have to know more about the monad (so that you can do something interesting in the callback)
07:18:03 <lambdabot> Monad m => [a] -> (a -> m b) -> m [b]
07:18:11 <Franciman> I want to do web scraping (I'm using scalpel) from multiple sources. Now the thing is that from the same source I want to extract different infos, and I want to separate the scrapers for each type of info (I want to download some data from different sources and compare them). Is there any abstraction that could help me express independent computations? Independent in the sense that they could be run in parallel, in principle
07:18:24 <deltasquared> tdammers: the "traced" package comes to mind, yeah a "symbolic monad" and such that builds up an AST internally
07:18:31 <Franciman> In this way I could take the different scrapers and compose the ones scraping from the same source
07:18:34 <tdammers> deltasquared: that, or free monads
07:18:41 <Franciman> while still having the user keep them separate
07:18:43 <Franciman> so I could have
07:18:48 <deltasquared> tdammers: another term I'm still trying to absorb :P
07:18:56 <Franciman> natalityScrapers = [ scraper1 fromSource1 , scraper2 fromSource2 ]
07:19:10 <Franciman> deathScrapers = [ scraper3 fromSource1, scraper4 fromSource2 ]
07:19:55 <deltasquared> tdammers: oh wait, my brain snapped into gear now, free monads was sort of like defining your own imperative AST right? then either writing an interpreter or doing other things
07:20:03 <Franciman> but do the scraping all at once for each source
07:20:12 <ski> deltasquared : anyway, if an action `act :: M T' is actually (at least conceptually) of the form `return x' for some `x :: T', we may say that `act' is a "trivial action" or "performs no effects"
07:20:34 <tdammers> deltasquared: http://www.haskellforall.com/2012/06/you-could-have-invented-free-monads.html <- this is a fairly decent intro
07:20:53 <deltasquared> ski: might I ask, are these definitions used somewhere, or are you proposing they be used, just curious
07:21:05 <deltasquared> I haven't come across this particular terminology before
07:22:12 <ski> deltasquared : so, what i was doing above is roughly an extension of this expressing that some action *expression* `act' or `...' "has no effects" to expressing that some "action context" `foo act' or `..act..' (for any arbitrary action `act' filling the hole in the context) "is transparent to effects" ("is referentially transparent")
07:22:13 <deltasquared> *reading tdammers article* hmm, save it to a file... I vote for S-expressions
07:23:26 <deltasquared> ski: right, I understood what you explained above, but I may just be being a bit slow here, does this definition gain us anything
07:23:56 <deltasquared> in other words, not to be rude (or I may have already lost track of context >_>), but er, what was the point of it all? :P
07:24:00 <ski> deltasquared : compare this with knowing that `square (f x y)' in Haskell is the same as `let z = f x y in square z'. the context `square (...)' is transparent to computing values of subexpressions we plug into the context : it doesn't matter whether we plug in the subexpression directly, or bind its result to a variable outside the context, and plug the context with that variable instead
07:24:31 <Dark_Ethereal> what was deltasquared's original question anyhow?
07:24:49 <deltasquared> Dark_Ethereal: even I forgot, but that's because my brain appears to be unresponsive to caffiene today
07:25:11 <ski> deltasquared : "are these definitions used somewhere, or are you proposing they be used, just curious" -- the "referentially transparent (wrt monadic actions)" definition is something i came up with, which i think can be somewhat useful in clarifying issues about what effects are about
07:25:20 <Dark_Ethereal> deltasquared: Well if you were to crystalize what you're confused about into one question, what would it be right now
07:25:34 <dmwit> "where is my coffee?"
07:25:46 <Dark_Ethereal> Asking the important questions I see...
07:25:49 <deltasquared> dmwit: maybe, maybe... :P
07:25:53 <ski> deltasquared : i'm not really saying i state something very deep here. i'm merely saying i'm spelling things out (hopefully) more clearly, in a way that people might not have thought about this
07:26:11 <deltasquared> Dark_Ethereal: I think it was originally related to monad transformers, but honestly I've now lost track
07:26:44 <deltasquared> partly from having to concentrate on some of the code snippets above. I really do have trouble reading code sometimes, for all haskell's brevity being nice to write I find it a pain to take in and read at times
07:27:01 <ski> deltasquared : "what was the point of it all?" -- to be honest, i'm not quite sure, yet ;) .. at least it has seemed to help me clarify things for myself (e.g. wrt what does "referentially transparent" really mean ?)
07:27:29 <ski> perhaps, or perhaps not, you'll find this viewpoint useful or not
07:28:12 <dmwit> Definitions rarely do anything by themselves anyway, except help with being concise.
07:28:23 <dmwit> It's the theorems that do the work.
07:29:45 <ski> anyway, you can similarly define a notion of "referentially transparent (wrt idiomatic/applicative actions)", where we don't ask whether `foo act = act >>= bar' for some `bar', but rather as whether `foo act = bar <*> act' for some `bar'
07:31:23 <ski> (hm, it now occurs to me that a different variant of the latter would be to ask whether `foo act = act <**> bar' for some `bar'. the difference being whether `act' is always executed at the end, or always executed at the start (and in any case, not more than once). in the monadic case "at the end" doesn't make sense in general)
07:31:51 <ski> @type (<*>)
07:31:52 <lambdabot> Applicative f => f (a -> b) -> f a -> f b
07:31:53 <ski> @type (<**>)
07:31:54 <lambdabot> Applicative f => f a -> f (a -> b) -> f b
07:34:45 <ski> Dark_Ethereal : we walked across different topics, fwiw
07:35:56 <deltasquared> ski: couldn't help but notice, that's a lot of comp sci channels you're in there :P
07:36:19 <deltasquared> I didn't even know freenode had a category theory channel...
07:37:02 <kosmikus> dminuoso: afaik, it will begin in the morning
07:37:23 <ski> Dark_Ethereal : the corresponding idea of "Why write a function that produces an action when fed another action if instead you can write a function that takes a pure value, and can be fed an action that produces a value using `>>=`", for idioms would be why do `I T -> I U', when you can do `I (T -> U)'
07:37:42 <ski> (the monadic case being why do `M T -> M U', when you can do `T -> M U')
07:37:55 <ski> deltasquared : yw :)
07:38:28 <deltasquared> category theory definitely crosses the boundary of "way too vague to comprehend on it's own" for me...
07:39:21 <Lycurgus> you prolly meant abstract instead of vague
07:39:21 <ski> as with all abstractions, you need enough concrete/practical experience, to motivate and suggest it
07:39:48 <Peter_Storm_> I aspire to intuitively connect category theory and haskell
07:39:57 <Peter_Storm_> It takes a whole long while though
07:40:05 <ski> don't worry about it being above your head (many things are above my head as well). perhaps you'll later see a use for it. perhaps not
07:40:07 <kosmikus> @tell dminuoso afaik, it will begin in the morning
07:40:07 <lambdabot> Consider it noted.
07:40:20 <Lycurgus> vague is like how the saudis at first said khasoggi left out the back door then said he died in a fist fight
07:40:40 <ski> Lycurgus : in which order ? :)
07:41:00 <deltasquared> Lycurgus: ok, abstract then...
07:41:14 <deltasquared> I'm sure it's not vague at all but I have no reference points currently.
07:41:26 <ski> (exactly my point above)
07:41:46 <Lycurgus> haskellers tend to be people who are very comfortable with advanced math
07:42:03 <Lycurgus> maybe a lil too comfy
07:42:06 <ski> well, at least some Haskellers
07:42:10 <Dark_Ethereal> ski: I'd be concerned with confusing referential transparency as the general idea that what a the same symbol refers to in two separate locations should be the same in both locations (assuming they're in the same scope) with what you seem to be talking about, which seems to be a something about how certain kinds of statements can, and probably should be reduced to other, simpler ones.... maybe if I hadn't joined in the conversation la
07:42:10 <Dark_Ethereal>  and was more well read, I'd see how they're both the same thing, but atm it seems confusing
07:42:32 <ski> i'm sure there're more mundane people who don't bother much with the lofty abstractions
07:42:38 <ski> (nothing wrong with that)
07:42:44 <deltasquared> ski: problem free activity, one paper called it. this was in the context of maths education, essentially students will never absorb it if there's no pain that the teached material becomes aspirin for - "pain" being a problem they couldn't solve previously
07:44:02 <ski> Dark_Ethereal : if you go back to the philosophical roots of the term "referential transparency", i do think it's closer to what i was talking about, than "that what a the same symbol refers to in two separate locations should be the same in both locations (assuming they're in the same scope)"
07:44:10 <deltasquared> oh, ffs, I didn't keep the paper and now I can't find it, rip
07:45:32 --- mode: glguy set +v stephenmac7
07:45:32 <ski> unfortunately, people have been using terms like "purity" and "referentially transparent" is quite confusing ways, in FP. perhaps this is unavoidable, to some extent, but i'd like to attempt to clear up some of the resulting confusing (not the least the confusion about it in my own mind)
07:45:34 --- mode: glguy set -v stephenmac7
07:46:10 <ski> @where purely-functional
07:46:10 <lambdabot> "What is a Purely Functional Language?" by Amr Sabry in 1993-01 at <https://www.cs.indiana.edu/~sabry/papers/purelyFunctional.ps>
07:46:23 <ski> might be a relevant paper to take a peek at
07:46:26 <stephenmac7> Hello. I was wondering if there is any good way to compute TimeOfDay from a DiffTime representing epoch time.
07:46:27 <deltasquared> oh, a postscript document, I haven't had to render one of those in ages :P
07:46:46 <stephenmac7> The best I can come up with is localTimeOfDay . utcToLocalTime tz . posixSecondsToUTCTime . realToFrac
07:46:54 <stephenmac7> But it's pretty slow
07:47:58 <ski> also "Referential Transparency, Definiteness and Unfoldability" by Harald Søndergaard,Peter Sestoft in 1987-11-30 - 1990-01-04 at <http://www.cs.tufts.edu/~nr/cs257/archive/peter-sestoft/ref-trans.pdf>
07:48:34 <ski> (also <http://www.reddit.com/r/haskell/comments/x8rr6/uday_reddy_on_referential_transparency_and_fp/>,<http://www.reddit.com/r/haskell/comments/xgq27/uday_reddy_sharpens_up_referential_transparency/>)
07:49:16 <hpc> stephenmac7: how did you get the DiffTime?
07:49:49 <hpc> stephenmac7: if you can start from something like getCurrentTime :: IO UTCTime, that would save you some trouble
07:50:49 <ski> deltasquared : "problem free activity" -- interesting notion. reminds me of the slides "What is mathematical thinking, and why should we care?" by Dag Wedelin in 2018-02-08 at <http://www.cse.chalmers.se/~dag/pres/promFeb2018.pdf>
07:51:17 <stephenmac7> hpc: It's a timestamp from a packet. I'm using the Network.Pcap library's http://hackage.haskell.org/package/pcap-0.4.5.2/docs/Network-Pcap.html#v:hdrDiffTime function
07:51:39 <ski> (those slides are also in the context of math eduction, improving the in many ways bad situation)
07:52:22 <ski> deltasquared : if you do find the paper later, i'd be interested
07:54:57 <hpc> hmm
07:55:25 <hpc> i expect utcToLocalTime is going to be the slow part
07:56:01 <hpc> or well, slowest part
07:56:12 <hpc> stephenmac7: how slow is it?
07:58:21 <Dark_Ethereal> deltasquared: I'm sure category theory can pose questions that category theory is needed to answer... but "what are the roots of this quadratic?" is a question that you might need algebra to solve, but it may or may not be a particularly interesting or motivating question to students...
07:58:41 <Dark_Ethereal> So to learn, do you need problems, or personally interesting problems?
07:59:21 <deltasquared> Dark_Ethereal: I think it was more that you'd show them the problem, then make them feel that mental discomfort when their existing tools cannot solve it or would be impractical
07:59:30 <deltasquared> that creates the "need" to learn the new thing
07:59:51 <deltasquared> headache, aspirin.
07:59:55 <hpc> (that will also be wrong if you let it run across a change in time zones, like when DST starts)
08:00:01 <stephenmac7> hpc: I'm not exactly sure how to benchmark it, but it shows up at the top of my benchmarks for the software I'm writing
08:00:52 <stephenmac7> The timezone will be constant. There is no DST for the timezone I'm interested in.
08:01:11 <ski> deltasquared : hm, now that you mention that, i may have read a blag that talked about something similar
08:01:15 <stephenmac7> Also, most of the timestamps will be very close together, if that's helpful.
08:01:47 <hpc> hmm
08:01:56 <deltasquared> ski: I found it from a blog that mentioned the mental aspirin phrase, I'm trying to get to it from that
08:02:48 <deltasquared> ski: AH FOUND IT https://www.math.ucsd.edu/~jrabin/publications/ProblemFreeActivity.pdf
08:02:56 <ski> ty :)
08:03:10 <ski> (if you find the blog as well, that'd be great)
08:04:05 <deltasquared> "  For example, it is arguable 
08:04:05 <deltasquared> (and has been argued historically) that proof by contradiction does 
08:04:05 <deltasquared> not explain what 
08:04:09 <deltasquared> makes an assertion true."
08:04:12 <deltasquared> damnit, paste newlines
08:04:49 <deltasquared> it's got some bits in there that make me go "this, so much, to the nth power"
08:05:06 <deltasquared> (I never really was satisfied with the proof by contradiction of the halting problem...)
08:07:48 * deltasquared throws the PDF on his kindle for later
08:08:05 <stephenmac7> hpc: A little more than half the time is spent on posixSecondsToUTCTime
08:08:11 <deltasquared> it's a nice rarity to find a PDF with nice big text that isn't unreadable on a display only three inches wide...
08:09:07 <ski> (hm, i think i may have looked very briefly at this paper earlier. ty for reminding me)
08:09:09 <lyxia> deltasquared: is the proof of undecidability of the halting problem really a proof by contradiction, as opposed to a direct proof of negation (cf https://existentialtype.wordpress.com/2017/03/04/a-proof-by-contradiction-is-not-a-proof-that-derives-a-contradiction/)
08:09:20 <dstolfa> deltasquared: you're right to say that proof by contradiction doesn't always necessarily say why it is true, but it does say what it *must* be true
08:09:30 <Dark_Ethereal> deltasquared: I think one reply to that would be that the question is wrong: that proof by contradiction is something that comes from the axioms of classical logic. There are formal logics that avoid proof by contradiction, but they aren't as powerful, and empirically there are lots of cases where real-world experiences line up with classical logic.
08:09:45 <dstolfa> well, also this ^
08:09:53 <dstolfa> but talking purely about propositional logic or HOL
08:10:02 <Dark_Ethereal> There are formal logics that allow contradiction: they just aren't useful for proving much at all.
08:10:47 <ski> Dark_Ethereal : i wonder to which extent those real world cases corresponds to direct proof of negation, rather than proof by contradiction
08:11:34 <ski> (also, for finite (and thus discrete) domains, even constructivists doesn't abstain from PbC)
08:11:38 <dstolfa> ski: idk, go gather all the proofs by contra/negation out there and count? :-)
08:12:01 <ski> dstolfa : yea, it's something that's probably hard to measure :)
08:12:18 <lyxia> We want to show "NOT (exists a machine deciding halting)" i.e., "(exists a machine deciding halting) -> False", so we start by assuming the existence of the machine and derive a contradiction. That does not make use of excluded middle.
08:13:01 <ski> (lyxia : you've probably already seen it, just mentioning <http://math.andrej.com/2010/03/29/proof-of-negation-and-proof-by-contradiction/> as another take on it)
08:13:33 * deltasquared tries to phrase what the excluded middle would be but fails
08:13:41 <ski> Dark_Ethereal : "formal logics that allow contradiction" -- are you talking about paraconsistent logics ?
08:13:52 <deltasquared> I'll be back in a bit anyways, IRL stuffz
08:14:13 <ski> ("the excluded middle" ("tertium non datur") is really a misnomer)
08:14:27 <ski> deltasquared : have fun
08:14:32 <Dark_Ethereal> ski: aye
08:14:48 <dstolfa> ski: that one is fun because it's a subtle mockery of horribly overloaded notation
08:14:50 <dstolfa> ski: i like that post
08:15:00 * ski notes that linear algebra can probably be thought of a paraconsistent logic, from some POV
08:16:29 <Dark_Ethereal> This chat always makes me feel very small. You all are too well read.
08:17:11 <deltasquared> Dark_Ethereal: don't worry, I have no idea what's going on with half of it either xD
08:17:20 <deltasquared> welcome to the club so to speak :P
08:17:41 <deltasquared> #haskell-easymode ?
08:18:28 <Dark_Ethereal> We choose to write haskell in this decade and do the other things, not because it is easy, but because it is hard!
08:18:49 * ski smiles
08:19:49 <cocreature> the trick is to lurk around here long enough that you start to absorb some of the knowledge
08:20:19 <ski> having people talk about apparently interesting and suggestive stuff that i don't know much about (but would possibly like to learn) is one of the things i like about this channel
08:20:59 <ski> (of course, we should strive to also be welcoming and accomodating to newbie and beginner questions. there needs to be a balance)
08:22:38 <Dark_Ethereal> "Many  years ago the great British explorer George Mallory, who was to die on  Mount Everest, was asked why did he want to climb it. He said Because it  is there. Well, Haskell is there..."
08:22:52 <dstolfa> ski: what, you mean explaining category theory to someone asking how to print hello world is not the right thing to do?
08:23:06 * ski smirks
08:24:43 <ski> @quote rules.of.Go
08:24:43 <lambdabot> sarah says: "But I don't _want_ functional programming!" -- Sarah Peyton Jones, age 11, upon hearing the rules of Go
08:25:08 <Dark_Ethereal> TBH working on ways to explain haskell to newcomers without mentioning category theory OR burritos is something I'm very much interested in.
08:25:24 <deltasquared> wait, burritos? xD
08:25:30 <ski> @where burrito
08:25:30 <lambdabot> http://byorgey.wordpress.com/2009/01/12/abstraction-intuition-and-the-monad-tutorial-fallacy/
08:25:36 <deltasquared> oh, I've read that one too
08:25:48 <ski> obligatory read, if you're tempted to write a monad tutorial
08:25:58 <deltasquared> monads are like tao; that which is written is not the true thing. or something like that
08:26:24 <Dark_Ethereal> I mean I am tempted but I don't want to talk in terms of analogies like burritos, so I don't know if I'm still the bad-guy
08:26:33 <Dark_Ethereal> I probably am
08:27:19 <deltasquared> Dark_Ethereal: I prefer to think of it in terms of "a thing where there may eventually be an x". idk. maybe it's a case of having a index of analogies, while suggesting they also work with concrete examples
08:27:34 <deltasquared> and the caveat that "monads by themselves are hard because they don't actually tell you a lot, don't worry about it too much"
08:27:46 <ski> one of the earliest monad tutorials (possibly the earliest non-paper one ?) is "What the hell are Monads?" by Noel Winstanley in 1999 at <http://www-users.mat.uni.torun.pl/~fly/materialy/fp/haskell-doc/Monads.html>
08:28:14 <ski> i relatively often suggest this to newbies who want to get a somewhat better ideas about what monads (in programming) are good for
08:28:16 <deltasquared> I'll have a look on account of having "what the hell is ..." in the title
08:28:30 <sm> ski: nice!
08:28:33 <ski> it's short, and to the point
08:29:04 <siraben> A monad is a monoid in the category of endofunctors, what's the problem?
08:29:48 <ski> (summary is roughly "monads arise as particular patterns of boiler-plate code that we'd like to avoid repeating (and introducing bugs in), and so we abstract over the commonalities of different such patterns")
08:29:53 <siraben> Or a special type of endofunctor equipped with two natural transformations
08:30:12 <siraben> ski:  That's a pretty good tutorial.
08:30:54 <siraben> For me the relevation came in when I was reading a book by Graham Hutton on Haskell
08:31:25 <siraben> And he sneakily uses monads throughout some chapters like that on parsing
08:31:33 <siraben> And then has a full chapter dedicated to it
08:31:54 <ski> @quote analogies.are
08:31:54 <lambdabot> dmwit says: analogies are endofunctors in the category of bad explanations
08:32:00 <ski> @quote trivial.religion
08:32:00 <lambdabot> Cale says: desrt: Did you hear about the trivial religion that I came up with? Its tenets consist of a single statement: "Believing in this statement will make you happier". It's like a terminal
08:32:00 <lambdabot> object in the category of religions and theomorphisms.
08:32:14 <deltasquared> ski: *having read article* nice, it hits on the point that there is a reason we use monads, even if it doesn't touch on the definition of Monad itself
08:32:22 <deltasquared> I think that's another thing a lot of tutorials fail at
08:32:29 <hpc> heh, http://hackage.haskell.org/package/time-1.9.2/docs/src/Data.Time.Clock.POSIX.html#posixSecondsToUTCTime - that divMod could probably be quotRem
08:32:32 <deltasquared> they don't explain *why* we use them, for IO in particular
08:32:49 <ski> deltasquared : *nod*. it starts at the right end, so to speak. deeper knowledge can be filled in afterwards
08:32:50 <siraben> lambdabot:  That implies that analogies preserve morphisms
08:32:50 <Dark_Ethereal> Aaaa you're making me want to write a tutorial
08:33:03 <hpc> stephenmac7: i think once you have the initial UTCTime, it's better to add DiffTimes to it?
08:33:11 <hpc> maybe that will be faster
08:34:05 <ski> siraben : i've heard good things about PIH, yea
08:34:41 <ski> Dark_Ethereal : resist the temptation ? ;)
08:34:51 <siraben> The IO monad can be explained like this:  you can't modify the "world" directly, but you can pass it into a function and return a "changed world".  So, putstrln :: String -> IO ()
08:35:12 <siraben> Meaning that it returns nothing, but wrapped in a changed world (which corresponds to the output)
08:35:24 <Dark_Ethereal> No no no no
08:35:26 <siraben> ski:  The IO monad was also in PIH
08:35:40 <Dark_Ethereal> the world passing idea is bad, I've been told this before
08:35:44 <deltasquared> concur
08:35:57 <Dark_Ethereal> forking threads = coping the entire world, aaaaaa scary!
08:36:00 <siraben> Ok then please correct me.
08:36:13 <Dark_Ethereal> Ok let me give it a go?
08:36:23 <siraben> YEs.
08:36:39 <siraben> Of course it's not using the entire world, but I'd like to see a different explanation of the IO monad.
08:37:16 <deltasquared> I would probably try to go with the explaination that IO actions are an indication for the runtime to safely handle your impure bits, and you supply a continuation of sorts to run when that value is available. an "IO plan" I guess?
08:37:41 <deltasquared> with the continuation then being able to decide on a further plan, once it knows that information
08:38:25 <siraben> How are IO actions actually implemented?
08:38:58 <siraben> Hm.  I can't seem to follow the use of continuations to explain IO
08:39:36 <cocreature> siraben: data IOAction a = GetLine (String -> IOAction a)
08:39:38 <cocreature> | …
08:39:54 <deltasquared> siraben: IO a >>= f, f is the continuation, that produces a compound IO plan, that when it is "run", first runs the left IO plan, gets a result, then lets the continuation decide what to do next
08:40:05 <deltasquared> that implies there are some "primitive" IO actions
08:40:23 <alexelcu> siraben: what languages are you familiar with?
08:40:26 --- mode: glguy set +v literallyCrevice
08:40:28 <literallyCrevice> In my code I currently have this: main = mapM_ putStrLn [desc x | x <- [1..20]]. How can I "move" the desc operation so it's chained with putStrLn? (desc is a function I wrote, Int -> String)
08:40:58 <lyxia> mapM_ (putStrLn . desc) [1..20]
08:41:45 <literallyCrevice> lyxia: thanks!
08:42:22 <lyxia> yw
08:42:26 <hpc> siraben: in ghc, there's a semi-magical definition data IO a = ...
08:42:33 <hpc> siraben: which uses the RealWorld formulation
08:42:45 <hpc> but it's a lie, and only exists to make ghc sequence things correctly without extra code
08:42:54 <ski> Dark_Ethereal : "the world passing idea is bad" -- i think it can still be useful as a stepping-stone, while it has its limitations
08:43:00 <deltasquared> I don't find that useful as an explaination tool though, rather just to explain how they get around reordering issues
08:43:20 <deltasquared> that said, it was certainly a stepping stone for me
08:43:45 <hpc> it ends up being that an IO action is implemented as an ordinary thunk that happens to do stuff
08:44:03 <hpc> which is consistent with what it /has/ to be for unsafePerformIO to be definable at all
08:44:25 <hpc> you shouldn't think about IO in that way though, it's an abstraction for a reason :D
08:44:33 <ski> another explanation is that a value of type `IO a' represents an imperative program, that the RTS then executes for you. so your Haskell program computes an imperative program, which is then executed (conceptually these are one stage after another. operationally, they are interleaved with each other)
08:44:46 <hpc> ^ is the explanation i prefer
08:45:00 <hpc> it's consistent with purity in other languages as well, such as puppet
08:45:33 <siraben> alexelcu: The ones I understand really well atr Scheme, Forth, assembly, C but I'm continually groking Haskell
08:45:34 <deltasquared> ski: damn, I was trying to get to that :P
08:45:34 <siraben> Are*
08:45:43 <ski> @quote /bin/ls
08:45:43 <lambdabot> shachaf says: getLine :: IO String contains a String in the same way that /bin/ls contains a list of files
08:45:44 * alexelcu hpc: that's how I explain `IO` and it's pretty clear in other languages where it isn't a primitive and it had to be implemented on top of other primitives; e.g. in JavaScript  you could implement it as ... `type IO<A> = () => Promise<A>` ... and it would be easy, if JavaScript's Promise wasn't leaking memory when chaining "then"
08:45:47 <hpc> (in puppet the pure code runs on one server and outputs operations to execute on a totally different server)
08:45:52 <deltasquared> "computing a program" which it definitely does, you can stick IO's in a list and all sorts
08:46:08 <ski> deltasquared : i'm still reading the scrollback. sorry if i repeated what was already said
08:46:19 <deltasquared> ski: no, as in, you beat me to it ;)
08:46:30 <deltasquared> little niggle in my head as it were
08:46:49 <Dark_Ethereal> ski: you've beat me to my explanation. I guess at least the fact that it's not unique to me makes it more likely to be correct
08:46:49 <deltasquared> I was getting there with "deciding what to do next", it was the "computes imperative program" part that I hadn't gotten to
08:47:13 * deltasquared gives ski a cookie
08:47:19 <deltasquared> hurray for beating everyone :P
08:47:53 <deltasquared> giving someone unsolicited cookies isn't against some CoC or anything is it? :P
08:48:18 <ski> hpc : nice :)
08:49:20 <ski> (reminds me of that you can still (only) use monads for composing I/O effects, in a dynamically typed language. you just need an opaque notion of I/O action, which can't be inspected)
08:50:41 <ski> Dark_Ethereal : if you'd like to, you could still express it in your own terms, and we could compare and contrast, maybe
08:50:47 <alexelcu> interestingly even in imperative languages you still need Monads to force ordering, because ordering of statements is only guaranteed from the point of view of the running thread, but not when observing shared state from other threads, ordering problems being a common problem in multi-threading code
08:51:24 <ski> (afaik, the "CoC" of this channel is still "Be nice, or else." (hey Shae !))
08:51:44 <hpc> heh
08:53:25 <Dark_Ethereal> The way I see it: the haskell-y part of haskell is basically pure... so how do you do impurity? Well you can do impure actions in C, and you can store strings in Haskell, so at the very least we could come up with a way to store chunks of C programs in haskell...
08:53:25 <Dark_Ethereal> Then you'd just need to represent the action of joining up two chunks to make a bigger chunk (which is what >>= does for you). We'll also need a way to take a pure value haskell value and turn it into a C chunk, that's what pure/return does, and then we can imagine that the compiler comes in, reads our string of chunks and binds, and does the clever bit of transforming that into a single C program, which can then be executed.
08:53:31 <Dark_Ethereal> Is that actually the way the compiler works? ofc not! But it gives you an idea of how you can do impure things with a pure language.
08:53:46 <ski> (deltasquared : same goes for you, obviously)
08:55:23 <deltasquared> ski: "be nice or else" is usually implied ;)
08:57:13 <ski> Dark_Ethereal : i think that's a good summary
08:59:27 <Dark_Ethereal> Exactly how the impurity is represented under-the-hood isn't so important. What is important is that the base IO actions and functions that produce IO actions that come in the base libraries and compiler-specific libraries represent the atomic nuggets of impure action, which you can thing of as indivisible and un-inspectable (even if they actually do include more pure haskell inside), and with the glue of (>>=) and the ability to turn
08:59:27 <Dark_Ethereal> ure values into impure computations that return those values, you can use these to express basically anything by stitching these pieces together.
08:59:32 <ski> i might add/emphasize that we *model* (usually implicit, like in imperative languages) side-effects in Haskell by *explicitly* returning a value which includes the modelled *effect* as part of it. this goes for any monad (and any idiom / applicative functor). an `M'-action that produces an `Integer' result is distinguished from an `Integer', both in the types (the interface), and on the implementation level
09:01:03 <ski> the question whether something has side-effects, or merely effects, is a question of POV. saying "it all compiles to machine code anyway" is irrelevant. what matters is the *language* in which we program and in which we *reason* (like refactoring, checking correctnes, maintaining, &c.)
09:01:38 <ski> which reasoning principles are and which aren't allowed to use, in general, is the question
09:02:32 <ski> Haskell manages to *separate* effectful parts from non-effectful parts of the program from each other. the effectful parts are still hard to reason about, but at least they don't infect/pollute the non-effectful parts, where we prefer to do a majority of the meat of the program
09:03:22 <ski> (instead of monads (and idioms), one could use e.g. effect systems to be explicit about, and segregate effects. it's not the only approach to effects management)
09:03:56 <ski> @quote recipe
09:03:56 <lambdabot> ski says: <ski> `getLine :: IO String' is a recipe for how to interact with the world to acquire a `String'  <ski> the recipe is not the cake
09:06:49 <ski> (by "on the implementation level", i mean in the definition of ones' actions, the Haskell source having expressions, like `do'-expressions. you can't write `getInt > 3' if `getInt :: IO Int'. `M'-actions giving a result of type `A' dosn't fit in the same places in the program as expressions evaluating to a value of type `A')
09:19:21 <bollu> does anyone know of a categorial / algebraic treatment of monad transformers?
09:19:40 <bollu> Also, does anyone know of a programming language where all valid programs are guaranteed to be in some complexity class? (say PTIME or PSPACE or what have you)
09:20:55 <hpc> bollu: regexes are guaranteed to run in constant space
09:21:55 <cocreature> there is some work on type systems that track complexities
09:23:38 <bollu> hpc right. But what about "larger" classes, such as LOGSPACE/NLOGSPACE, AC0, NC, etc.
09:23:42 <bollu> cocreature any pointers?
09:24:10 --- mode: glguy set +v naomi_
09:24:54 <cocreature> sorry, I don’t have any links at hand
09:25:46 <fragamus> is there something like [1,2] + [3,4]  which yields [4,6] without using zip
09:26:05 <ski> there are fragments of linear logic (like e.g. MALL, iirc), which can only express polynomial algorithms
09:26:22 <cocreature> fragamus: why are you trying to avoid zipWith?
09:26:23 <ski> fragamus : without `zipWith' ?
09:26:35 <ski> there's also `ZipList'
09:27:16 <fragamus> just wanted something simple looking
09:28:07 <cocreature> if that’s something you do in a lot of places, it sounds like you might want to use a type for representing vectors (which could just be implemented as a newtype over lists) instead of regular lists
09:29:02 <cocreature> > [1,2] ^+^ [3,4]
09:29:04 <lambdabot>  error:
09:29:04 <lambdabot>      • Variable not in scope: (^+^) :: [Integer] -> [Integer] -> t
09:29:04 <lambdabot>      • Perhaps you meant ‘^^’ (imported from Prelude)
09:29:08 <cocreature> @let import Linear
09:29:09 <lambdabot>  .L.hs:136:1: error:
09:29:09 <lambdabot>      Could not find module ‘Linear’
09:29:09 <lambdabot>      Use -v to see a list of the files searched for.
09:29:14 <cocreature> % import Linear
09:29:14 <yahb> cocreature: ; <no location info>: error:; Could not find module `Linear'; Perhaps you meant Linker (needs flag -package-key ghc-8.6.0.20180620)
09:29:26 <cocreature> gnah
09:29:40 <cocreature> fragamus: the linear package provides various functionality for linear algebra, e.g., https://hackage.haskell.org/package/linear-1.20.8/docs/Linear-Vector.html#v:-94--43--94-
09:29:50 * ski . o O ( `class Num r => Linear r v | v -> r where zero :: v; (<+>),(<->) :: v -> v -> v; (.*>) :: r -> v -> v' )
09:29:53 <cocreature> it looks like there is also an instance for lists so [1,2] ^+^ [3,4] works
09:30:12 <cocreature> it just fails because the package is not available in either of the bots
09:33:47 <vilu> Hi, I'm struggling a bit with lenses
09:34:13 <vilu> I'm having trouble understanding if it's possible and what and how I should compose things.
09:34:44 <vilu> I have an that on the top level is a sum type, each of those types are a product type and all share a common field.
09:35:15 <vilu> Can I make a lens that gets me the third field of each "leaf type?"
09:35:58 <vilu> i.e. data ExampleType = MkType1 a b c | MkType2 d e c | MkType3 f g c
09:36:14 <vilu> I want to create a lens so that I can get c?
09:37:28 <cocreature> myLens f (MkType1 a b c) = MkType a b <$> f c; myLens f (MkType2 d e c) = MkType2 d e <$> f c; myLens f (MkType3 f' g c) = MkType3 f' g <$> f c
09:43:47 <elgoosy> hi, in the snippet like this `BackendRoute_Test :=> Identity () -> do...` how do I find what the operator :=> is, its type, etc?
09:44:17 <ski> that's defined in some library module you're importing
09:44:34 <ski> (it's not in `Prelude', and it's not built-in to the language)
09:44:56 <elgoosy> ok, with dante, selecting it and asking for type does not give anything
09:45:18 <elgoosy> however, in the repl in konsole i was able to do :t (:=>)
09:45:18 <cocreature> https://hoogle.haskell.org/?hoogle=(%3A%3D%3E) gives you some suggestions of what it might be
09:45:50 <ski> dante ?
09:46:06 <elgoosy> that's so annoying for a noob, open some source and see a tons of  imports and tons of operators, the books were not speaking of..:)
09:46:27 <elgoosy> plus the editors do not help almost nothing
09:46:34 <elgoosy> thanks ski, cocreature
09:46:53 <ski> operators are just functions that happen to be written infix, more or less
09:47:33 <ski> Haskell programmers tend to (to some extent) make use of the possibility to define their own infix operators
09:47:40 <elgoosy> yeah, thank i know. ski, dante is an emacs plugin
09:47:41 <ski> (it can be taken to extremes, of course)
09:47:48 <cocreature> elgoosy: in the repl you can also use :i (:=>) which should show you the module name where it is defined
09:47:55 <ski> ah, ok. i was searching Hackage, but found nothing
09:48:53 <vilu> cocreature: oh thanks! What type is that expression then? 
09:49:10 <vilu> Still new with Lenses, and I have yet to define my own. I've so far used the generated ones and composed them.
09:50:02 <cocreature> vilu: depends on the type of c but could be something like Lens' ExampleType Int if c=Int
09:50:04 <bromsson> "(it can be taken to extremes, of course)" => http://hackage.haskell.org/package/plumbers-0.0.4/docs/Control-Plumbers.html
09:50:18 <bromsson> ^ This is pure madness :D
09:50:50 <vilu> cocreature: Oh, that makes sense.
09:51:06 <bromsson> Anyone knows more about empty record updates and how to make sense of them?
09:52:01 <bromsson> Eg. why does `[]{}` type and evaluate fine, same with `(){}` but `""{}` or `(1,2){}` will fail (not even type)..
09:52:42 <bromsson> On the other hand `(:){}` and `(,){}` will both type to `[a]` and `(a,b)` respectively.
09:53:01 <nshepperd1> 310 pointless combinators
09:53:36 <cocreature> bromsson: that’s record construction not a record update
09:53:41 <cocreature> (1,2) is not a constructor
09:53:45 <bromsson> Initially I thought that it will only work on `data`, but it doesn't work with 2-tuples and that would still not explain how `(:){}` evaluates to `[a]` :S
09:54:33 <bromsson> cocreature: Now that makes sense!
09:54:46 <cocreature> (:){} creates a list using the (:) constructor but the fields will explode in your face
09:54:58 <cocreature> which is why GHC warns about this :)
09:55:21 <bromsson> I mistook it for update because `(1,2){}` fails with "Empty record update", but this makes sense.
09:56:14 <bromsson> cocreature: Yep, GHC's warnings are nice :)
09:59:34 <the_2nd> am I missing something, or does the regex package (tdfa) not work with Data.Text?
10:00:31 <stephenmac7> hpc: That's what I was thinking too. Thank you. I'll try it out.
10:01:10 <cocreature> the_2nd: there is probably a reason why there is a second package called regex-tdfa-text :)
10:01:40 <the_2nd> ah :D
10:04:08 <the_2nd> =~ is not exported there? Can I get the operator by referencing the base package?
10:05:18 <vilu> the_2nd: Isn't that in the top level package?
10:08:33 <vilu> I think if they have instances for the RegexMaker and RegexContext you should be fine with =~
10:12:29 <geekosaur> the_2nd, it's all doen with typeclasses; importing that module gets you the instance you need, but the typeclass interface comes from the standard package
10:18:34 <the_2nd> got it
10:18:55 <the_2nd> I thought -text was a sibling of the normal
10:19:16 <the_2nd> I had to use both and get the operator via the base one, while the instances via the text one
10:20:19 --- mode: glguy set +v rpeck
10:25:58 <cocreature> the regex API in regex-base makes me angry everytime I remember it
10:27:17 --- mode: glguy set +v rpeck
10:30:23 <vilu> Btw, I was told that regex is completely frowned upon by the Haskell community when I used them while applying for a job. Is this true more so than in other languages?
10:30:45 <vilu> I mean, they have some negative parts to them. But, I still reach for them from time to time. 
10:31:20 <monochrom> I don't frown upon it.  If you know what it can't do, you're fine.
10:31:43 <monochrom> Once again, the mass needs sensational oversimplifications to comfort themselves.
10:31:59 <the_2nd> are there also Text version of e.g. readProcess? Or should I just call pack on them?
10:32:05 <alexelcu> vilu: technically being against regular expressions is being against finite state machines and when speaking of parsing, there's nothing simpler than finite state machines
10:32:10 <cocreature> the regex-base API doesn’t exactly help making regexes popular in Haskell :)
10:32:33 <cocreature> the_2nd: process-extras has Text versions iirc
10:32:50 <vilu> cocreature: Hehe, as someone that's still starting out with haskell I can definitely understand that.
10:33:14 <cocreature> vilu: if you’re looking for a pleasant way to use regexes in Haskell, take a look at regex-applicative
10:33:18 <monochrom> Yes, the classes are quite a bit overly abstract and poorly explained.
10:33:32 <vilu> I mean, ALL that ceremony, with quite complicated typeclasses and then in the end they still throw exceptions :).
10:33:34 <monochrom> Actually, the classes and the instances.
10:34:14 <vilu> monochrom: I will look into that library. I used them for a job interview though, I didn't want to send anything that had dependencies. How's regex-applicative in that sense?
10:34:42 <vilu> sorry, that last remark was for cocreature 
10:34:45 <cocreature> there is a conspiracy theory that regex-base was explicitely designed to discourage people from using regex and the sad part is that this seems plausible
10:35:13 <cocreature> vilu: well you are going to need some dependency if you want to do regex in Haskell. I don’t see why depending on regex-tdfa is better than depending on regex-applicative
10:35:14 <monochrom> Nah, that's nothing.
10:35:48 <cocreature> I’m also not sure why you should avoid dependencies in a job interview unless they explicitely ask for it
10:35:50 <monochrom> The real conspiracy theory is that multiple parameter type classes was invented to enable regex-base so as to discourage people from regex. >:)
10:36:04 <cocreature> monochrom: ah nice one, I hadn’t heard that :)
10:36:11 <vilu> cocreature: I referred to some library outside of Haskell. Many of the others required me to have library x installed on my computer.
10:36:32 <vilu> Or at least it seemed so to me when I tried. It complained about missing some libc whatever.
10:36:56 <vilu> Btw, coming from the JVM "native dependencies" would be understood as Haskell dependencies not as non Haskell dependencies?
10:37:07 <dolio> The reason I'd 'frown on' regexes is because almost all parsing problems aren't regular languages, but regexes are the only tool most programmers know of to solve parsing problems.
10:37:17 <vilu> How should I refer to libraries unrelated to haskell.
10:37:34 <dolio> If you're actually parsing a regular language, they're okay.
10:37:39 <cocreature> vilu: regex-applicative doesn’t depend on any foreign libs
10:37:58 <vilu> dolio: Agreed, it's not the first thing I would reach for either. That being said, they do serve a purpuso imho.
10:38:06 <cocreature> vilu: if C libraries are missing you need to install them separately, e.g., using your distribution’s package manager if you’re on linux
10:38:14 <monochrom> regex also tends to be write-only.
10:38:28 <alexelcu> monochrom: why do you say that?
10:38:30 <vilu> cocreature: Right, that's just not something I wanted to send ask of anyone that would be reviewing my code to do.
10:38:40 <geekosaur> most people can't read them well
10:38:44 <dolio> They're also not very good for a complicated regular language, because they don't let you decompose pieces very well.
10:39:03 <monochrom> When you write a new regex, it makes 100% sense to you.  Two years later you can't figure out what it means.
10:39:31 <alexelcu> I don't agree. I mean you can say the same thing about Haskell, for exactly the same reasons.
10:39:46 <monochrom> Although, if you're a documentation buff, you would write 3 paragraphs of comments to explain it, and then it would be fine.
10:40:00 <geekosaur> the difference is most people do't pull haskell out the minute they see something ti could be used for
10:40:28 <monochrom> Ugh, I do pull out Haskell all the time!
10:40:45 <monochrom> You can't say the same thing about Haskell.
10:40:46 <geekosaur> golook at the number of people who imemdiatelyt hink regex and then spend the next hour on a regex-building site
10:41:15 <dolio> Haskell gives you the tools to decompose your solution into understandable pieces.
10:41:33 <dolio> Regexes proper don't, really.
10:41:39 * ski . o O ( "IrRegular Expressions" by foof at <http://synthcode.com/scheme/irregex/> )
10:41:59 <monochrom> Yeah a "let ... in ..." construct in regex would be nice.
10:42:02 * alexelcu well, no, Haskell is turing complete and hence much more complicated than regular expressions
10:42:38 <monochrom> But I am not talking about arbitrary regexes and Haskell programs. I am talking about those you wrote two years ago.
10:42:46 <dolio> ski: Bad gateway?
10:42:56 <monochrom> You don't happen to be a random number generator, do you?
10:43:13 <dolio> Oh, now it works.
10:45:05 * ski . o O ( <https://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags/1732454#1732454> )
11:13:44 <alexelcu> Hey — what do people do in Haskell for logging — e.g. the equivalent of Logback / Slf4j in Java?
11:19:11 <p0lyph3m> Need a hint , i don't understand why the errors : https://thepasteb.in/p/ElhJcPl42QooOuN
11:19:12 <cocreature> alexelcu: the logging landscape is somewhat fractured. among the more popular packages are monad-logger, katip and logging-effect
11:20:52 <cocreature> p0lyph3m: the "s" in the type of nts needs to be polymorphic
11:21:12 <cocreature> if you want to be explicit, the type of nts needs to be "forall s. Sym s => g -> [s]"
11:21:24 <cocreature> _nts doesn’t work for all s
11:22:00 <cocreature> it looks like you probably don’t want "s" to be polymorphic but rather have a fixed "s" for each "g"
11:22:27 <cocreature> you can achieve that using a multiparam typeclass + functional dependencies or an associated type family
11:22:45 <ski> `nts     :: Sym s => g -> [s]' (inside `class Grammar g') means that you're promising a caller of `nts' (for your particular choice of `g' in the instance you're making) can pick any `s' they like, as long as it's an instance of `Sym'
11:22:54 <p0lyph3m> cocreature: the class should work with all s , the instances for special type should specialize the s
11:23:16 <cocreature> I’m not sure what you mean by “the class should work with all s” if the instances don’t
11:23:25 <cocreature> but it sounds like my comments still apply :)
11:23:29 <ski> p0lyph3m : each `s' depending on the corresponding `g' ? what cocreature said
11:24:09 <ski> (you'll need to decide whether there can be at most one `s' corresponding to a given `g' in `Grammar', or not)
11:25:09 <p0lyph3m> i'd like to have different Symbol types for different Grammars
11:26:23 <ski> that sounds like "each `s' depending on the corresponding `g'" (so multi-param type class, or ..) and also "there can be at most one `s' corresponding to a given `g' in `Grammar'" (so functional dependency `g -> s' "`g' determines `s'")
11:26:27 <p0lyph3m> i'll try to work it out ...
11:27:03 <cocreature> p0lyph3m: but do you need different Symbol types for a single grammar?
11:27:26 <p0lyph3m> ok , do i need both multi parameter typclass && functional dep ?
11:28:10 <cocreature> you need the functional dependency in addition to a multiparam typeclass if you want to express that there is only a single symbol type for a given grammar
11:28:10 <ski> either that, or associated types
11:28:21 <ski> so, either `class Sym s => Grammar s g | g -> s where nts :: g -> [s]; ...' or `class Sym (GSym g) => Grammar g where type GSym g; nts :: g -> [GSym g]; ...'
11:28:35 <p0lyph3m> cocreature: no , 1 concrete grammar has its symboltype , another grammar might hava another smbol type
11:28:45 <ski> (i'm not convinced the class `Sym' has any use whatsoever here, but i kept it, just in case. quite possibly you can just scrap it)
11:29:06 <cocreature> p0lyph3m: try https://gist.github.com/cocreature/6c80e45ef3725fa0b701dc05c698bdff
11:29:14 <ski> p0lyph3m : the question is : can the same concrete grammar type be associated with several distinct symbol types, or not ?
11:29:16 <cocreature> ah ski beat me to it :)
11:29:34 <ski> p0lyph3m : if not, then you want the FD (or equivalently go the associated type way)
11:29:55 <kuribas> I am writing a MySQL backend for Selda.  It seems Selda doesn't have support for transactions, is that right?
11:30:36 <ski> p0lyph3m : more concretely, the question is whether you want to be able to have both `instance Grammar SymbolA MyGrammar' and `instance Grammar SymbolB MyGrammar', or not
11:31:39 <cocreature> kuribas: I’ve never used selda but https://hackage.haskell.org/package/selda-0.3.4.0/docs/Database-Selda.html#v:transaction very much looks like it does support transactions
11:32:33 <p0lyph3m> ski , no not both; MyGrammar1 MySymbolType ; MyOtherGrammar MyOtherSymbolType 
11:32:41 <ski> p0lyph3m : `GSym g' above would be the associated type. the idea is that `GSym g' corresponds to the earlier `s'
11:32:57 <kuribas> cocreature: ah thanks.  I see it doesn't use the backend for that.
11:33:25 <ski> p0lyph3m : there you also have different grammars. the question was about the *same* grammar type, but different symbols types
11:33:56 <kuribas> cocreature: I am a bit confused about the disableForeignKeys :: Bool -> IO () "Turn on or off foreign key checking, and initiate/commit a transaction. When implementing this function, it is safe to assume that disableForeignKeys True will always be called exactly once before each disableForeignKeys False."
11:34:03 <monochrom> Maybe you should just draw a table of instances of Symbol and Grammar.
11:34:32 * ski suspects p0lyph3m only has one candidate instance, for the moment
11:34:50 <monochrom> Yeah, don't even design a class until you have at least 3 instances.
11:34:59 <ski> (which could be grounds for questioning whether a type class is adviced at all)
11:36:27 <p0lyph3m> will have more grammars, but each has its on symbol type , thats why the grammar typeclass
11:37:03 <p0lyph3m> thanks for your answers , try to figure it out 
11:38:33 <ski> each has its own *single* symbol type ?
11:40:52 <monochrom> At least you can draw a table of the names of the instances you plan to add.
11:41:27 <monochrom> At this point you need to see the 1-to-many, many-to-1, and/or many-to-many relations between grammars and symbols.
11:41:43 <monochrom> Or even 1-to-1.
11:42:15 * ski . o O ( 0-to-1 )
11:43:17 <monochrom> With multiple parameter type classes you have an entity-relation diagram, among other things.  Yes you now have to do some of those things they made you do in that database course you hated.
11:46:29 <cocreature> next monochrom is going to make you find the normal form of something
11:47:09 * ski . o O ( "Let's insist on BCNF for type classes" )
11:52:14 <jkachmar> Are there any good methods people have for testing GHC compile time regressions in an automated way in continuous integration?
11:52:35 <jkachmar> Surface effort poking around Google hasn't turned up much, so now I feel justified asking everyone here :P
12:09:02 <monochrom> 4th normal form: https://mail.haskell.org/pipermail/haskell-cafe/2017-May/127147.html  >:)
12:09:41 <monochrom> Plus, I love all the puns I put into it!
12:13:20 <vilu> A question about monads, specifically when you stack them. I find myself in the pattern that I have for example a WriterT [String] a. I want to create for example a method log :: MonadWriter [String] m => String -> m a.
12:13:44 <vilu> I find myself writing a do block, I call tell and give it the string.
12:13:59 <vilu> But now I don't know how to finish the do block. I need to "return a" or similar.
12:14:13 <vilu> In my view, the tell shouldn't have lost the initial a value.
12:14:36 <vilu> Can I just call that method and make sure that the monad returned at the end of the block is the "same" as came in?
12:14:59 <monochrom> Why is it "m a" not "m ()"?
12:15:31 <vilu> Oh... because I have been programming the whole day :) obviously that's the answer.
12:15:33 <vilu> Silly me
12:15:37 <vilu> Thanks.
12:21:51 <ski> vilu : nitpick. there is no "the monad returned". monads aren't values. presumably you mean "the monadic action ending the sequence of commands in the `do'-expression". `WriterT [String] m' would be a monad (if `m' is a monad); as would `m', in case `MonadWriter [String] m' holds
12:22:47 <ski> vilu : a value of type `WriterT [String] m a' (for any type `a', like e.g. `()', given `m' a monad) would be a monadic action, as would a value of type `m a' (given `MonadWriter [String] m')
12:23:33 <vilu> ski: Hehe, I appreciate nitpicking. Actually, still struggling with the FP language. That being said, what you said was also my understanding although I was incapable of expressing it.
12:23:40 <ski> (an `WriterT [String] m'-action, respectively an `m'-action, specifically)
12:23:57 <ski> vilu : good, then
12:24:14 <vilu> Thanks for helping to clear it up though!
12:24:52 <ski> (upholding (relevant) important distinctions will make it easier to communicate, and also to think about this on your own. of course sharing a common terminology also helps for communication)
12:25:49 <vilu> Couldn't agree more. In fact in FP very often I find myself not even being able to search for information because I can't even express my question.
12:26:00 --- mode: glguy set +v akfp
12:26:03 <vilu> In IRC it works because people make the effort to understand. Google or StackOverflow, not so much.
12:26:30 <akfp> i.e. in the code block examples in the Lens library, none of the identifiers are linked.  Is this a haddock limitation or not?
12:26:38 <ski> perhaps it has something to do with being more present, and being able to respond with less latency ..
12:27:27 <akfp> can identifiers be linked in haddock literal code blocks?
12:27:51 * ski doesn't know :/
12:28:37 <akfp> for example the docs will write: >>> Left "hello" & _Left %~ length - I'd like to click the _Left symbol.
12:29:05 <ski> @hoogle _Left
12:29:05 <lambdabot> Control.Lens.Prism _Left :: Prism (Either a c) (Either b c) a b
12:29:05 <lambdabot> Lens.Micro _Left :: Traversal (Either a b) (Either a' b) a a'
12:29:05 <lambdabot> Lens.Family2.Stock _Left :: Traversal (Either a b) (Either a' b) a a'
12:30:59 <ski> @where Backus
12:30:59 <lambdabot> "Can Programming Be Liberated from the von Neumann Style?: A Functional Style and Its Algebra of Programs" (Turing Award lecture) by John Warner Backus in 1977-10-17 at <https://amturing.acm.org/
12:30:59 <lambdabot> award_winners/backus_0703524.cfm>,<http://www.thocp.net/biographies/papers/backus_turingaward_lecture.pdf>
12:31:22 <ski> fwiw, if "the FP language" is mentioned, i tend to think about ^
12:31:39 <ski> (as opposed to "the FP programming paradigm", or however you want to express it)
12:37:34 <Zipheir> ski: Such a cool language.
12:39:25 --- mode: glguy set +v Haskell_
12:40:23 <Haskell_> pow2 b e      | (e < 0) = error "Negative exponent"      | (((e `mod` 2) == 0) && (e /= 0)) = b* pow2 (b*b) (e/2)      | ((e `mod` 2) == 1) = b* pow2 b (e-1)      | otherwise = 1 why this doesnt work ?
12:42:00 <ski> Haskell_ : you want integral division, not rational division
12:42:00 <Haskell_> Could not deduce (Fractional a10) arising from a use of ‘pow2’     from the context (Num a)       bound by the inferred type of it :: Num a => a . a10 is ambigous is the error message
12:42:11 <ski> > 18 `div` 7
12:42:13 <lambdabot>  2
12:42:15 <ski> > 18 / 7
12:42:17 <lambdabot>  2.5714285714285716
12:43:24 <ski> (you also have one other problem in that snippet of code)
12:44:00 <Haskell_> what ?
12:44:36 <ski> `/' is for division on rationals, floating-point numbers, complex numbers, &c. -- getting exact (or as close as possible) result of division. no remainder here
12:45:01 <ski> `div' (together with `mod') is for getting integral division and remainder, on integer types
12:46:16 <ski> in case `e' is say `13', you clearly want to recursively call `pow2' with second argument being `6', not `6.5'
12:46:25 <ski> > 13 `div` 2
12:46:27 <lambdabot>  6
12:46:28 <ski> > 13 / 2
12:46:30 <lambdabot>  6.5
12:46:46 <ski> Haskell_ : making any sense ?
12:47:04 <Haskell_> yeah thanks
12:47:18 <Haskell_> helped me a lot
12:47:25 <ski> you may also remove all the brackets in your guard conditions -- they are redundant
12:47:52 <ski> possibly you also want to change your type signature for `pow2'
12:49:04 <Haskell_> ok
12:49:17 <ski> (s/other problem/other bug/, should i perhaps say)
13:11:52 <haasn> am I going crazy? according to haddock, `arithmoi`'s Math.NumberTheory.Primes.Factorization should export `divisors`, and I always remember it doing so
13:11:55 <haasn> but in practice it does not, fo rme
13:12:01 <haasn> arithmoi version 0.8.0.0
13:13:37 <haasn> ah it was moved to ArithmeticFunctions
13:29:29 <alexelcu> cocreature: 
13:30:00 <cocreature> alexelcu: hm?
13:30:15 <alexelcu> cocreature: sorry, I'm new to IRC :)
13:30:28 <alexelcu> thanks for the pointers on logging, although looking at them I got a headache 
13:30:53 <alexelcu> I'm new to Haskell, so mtl-style stuff is a little hard to digest
13:48:59 <berndl> Is there a comprehensive code style-guide for Haskell? In particular, I need one that shows how to format functions, type classes and instances  with tons of constraints and type families with lots of parameters.
13:52:07 <hpc> just make it read good, really :P
13:54:04 <berndl> I've tried a couple of things, but they all look ugly. The better ones don't follow some the "standard" styles I've seen either.
14:01:15 <zachk> @type (<*>) 
14:01:16 <lambdabot> Applicative f => f (a -> b) -> f a -> f b
14:01:38 <zachk> is there something like: Functor f => f (a -> b) -> a -> b
14:01:58 <Tuplanolla> Sounds like `Comonad`, zachk.
14:02:30 <zachk> what if f is Maybe? 
14:03:24 <Tuplanolla> Then you're in trouble.
14:11:54 <__monty__> berndl: I'd take a look at the formatters, brittany and hlint mainly.
14:14:35 <nkaretnikov> gloss/macos question: i'm on macos 10.14 and hello-world examples show black canvas for me. is there a fix for this, or is it somehow related to macos issues?
14:14:59 <nkaretnikov> https://www.irccloud.com/pastebin/POx5Vf98/
14:15:01 <jle`> zachk: there is no such function for all Functors, no
14:15:09 <nkaretnikov> here's the example i'm using^
14:15:13 <fragamus> Data.Set.powerSet no workie?
14:15:38 <jle`> zachk: but are you really looking for something that works for all functors, or are you looking for something for a specific Functor/type?
14:15:51 --- mode: glguy set -v literallyCrevice
14:16:10 <berndl> __monty__: never heard of brittany. I'm checking it now.
14:17:01 <literallyCrevice> I want to convert a simple while loop to haskell, but want to do it the "pure" way (without whileM_). This is my failing attempt: https://ptpb.pw/KND3 I would love some help or notes on how you would structure this
14:19:09 <zachk> im just looking for something of Maybe (a -> b) -> a -> b would that also include Maybe (a -> b -> c) -> a - > b - > c ? 
14:19:30 <berndl> literallyCrevice: The type of guessName is wrong.
14:20:51 <infinisil> I'm currently checking out different serialization packages
14:21:05 <infinisil> And https://hackage.haskell.org/package/safecopy seems to be the coolest, based on cereal
14:21:57 <infinisil> There's also packages binary, store-core, serialise, store and bytes
14:22:14 <literallyCrevice> berndl: I'm not complaining about my attempt not working. It seems like a very forced attempt at this. If you were to rewrite the whole thing, what would be your approach?
14:23:07 <__monty__> zachk: Sounds like you're really looking for something with the type `Maybe a -> a`, which suggests you're thinking about the problem wrong. What would it return if the Maybe is Nothing?
14:24:28 <zachk> would have to default or specify a default I guess
14:24:48 <__monty__> Then you're looking for `maybe`.
14:25:02 <__monty__> @type maybe
14:25:03 <lambdabot> b -> (a -> b) -> Maybe a -> b
14:25:43 <__monty__> The (a -> b) is the code where you wanted to use the value you'd get "out" of the Maybe.
14:25:56 <__monty__> The b is the default.
14:27:05 <berndl> literallyCrevice: https://ptpb.pw/DTDb
14:29:01 <literallyCrevice> berndl: Thanks!
14:33:56 <ski> literallyCrevice : do you know the types of `main' and `guessName' ?
14:36:35 <nkaretnikov> okay, nevermind my gloss question: it's caused by me using nix. with new-build it works fine.
14:39:54 <literallyCrevice> ski: I understand now why my code wasn't compiling. I was trying to ask what would be the proper way to restructure this program in a way that fits FP
14:42:16 <ski> do you understand why your original type signature for `guessName' wasn't (quite) correct ?
14:42:17 <berndl> literallyCrevice: welcome to the world of types.
14:43:51 * ski looks at literallyCrevice
14:48:56 <literallyCrevice> ski: Yes, because I need a `return` statement when returning from a `do` and that wraps whatever it was in IO
14:49:40 <ski> it may be prudent to point out that `return' doesn't actually cause premature termination of a `do'-block
14:50:22 <literallyCrevice> Huh, good to know
14:50:22 <ski> `return' is just an ordinary function. it is used to "wrap a value in a trivial action"
14:50:34 <Solonarv_> e.g. if you have do { blah blah; return x; more stuff } -- the "return x" doesn't actually do anything, and might as well not be there
14:51:14 <ski> this is related to how Haskell does I/O. a function that "does" I/O really returns an "`IO'-action" that's like a recipe, describing what input/output interactions with the OS to perform
14:51:50 <ski> Haskell takes the idea of separating internal machinery code from user interface code (I/O code) seriously
14:52:15 <ski> so seriously that a function that may do some I/O has a different type than one that definitely doesn't
14:52:43 <literallyCrevice> That's interesting
14:52:54 <ski> your original signature `guessName :: String -> Int' stated that `guessName' took a `String' as input, and outputted an `Int'
14:53:35 <ski> the correct (in this case) signature would be `guessName :: String -> IO Int', indicating that performing `guessName' may (iow "is allowed to") perform I/O operations
14:54:45 <ski> in Haskell, all functions always produce the same result, if you pass it the same (or an equal) input
14:54:59 <literallyCrevice> Except IOs?
14:55:00 <ski> *all* functions, including your `guessName' function
14:55:16 <ski> this may seem contradictory at first glance but it really isn't
14:55:52 <lavalike> is there a groupBy with intermediate state that resets at each False of the predicate?
14:56:17 <ski> conceptually, what your `guessName' does is take a `String' as input, and as output produce a "recipe" (or "list of instructions") of what Input/Output interactions we *would* perform, if we ever were to *execute* the recipe
14:56:36 <ski> (and then, at the end of executing that recipe, we'd get an `Int' back as result)
14:56:41 <hpc> > groupBy (==) [1, 1, 2, 2, 1, 1]
14:56:44 <lambdabot>  [[1,1],[2,2],[1,1]]
14:56:56 <hpc> lavalike: it's hard to tell what you mean, you mean this? ^
14:57:09 <lavalike> hpc: a little spin on that
14:57:20 <ski> literallyCrevice : so, if you give `guessName' the *same* `String', it will always give you back the *same* recipe of I/O interactions
14:57:42 <ski> literallyCrevice : actual execution of such instructions is distinct from evaluating expressions (which includes calling functions)
14:58:07 <literallyCrevice> ski: to clarify, is that "recipe" whatever is in the `do` block?
14:58:38 <ski> the whole `do'-expression "computes" a recipe, or an action (an `IO'-action in this case, there are also other kinds of actions)
14:58:51 <ski> the action is the value of evaluating the function call to `guessName'
14:59:01 <lavalike> hpc: this isn't perfect but something like:  f 0 (\s x y -> (s + x + y, s+x+y > 3)) [1,2,3,0,2,0,1,3]  ->  [[1,2],[3],[0,2,0,1],[3]]
14:59:13 <literallyCrevice> I better go back to reading because half of that flew over my head
14:59:25 <lavalike> I guess that's also wrong I'm a bit tired
14:59:34 <literallyCrevice> Anyways, thanks a lot for taking the time to explain everything. I really appreciate it!
14:59:36 <Zipheir> literallyCrevice: Also, 'do' isn't magic. It's a layer of syntactic sugar on top of lambda and >>=.
14:59:42 <hpc> lavalike: so you have an accumulator of some kind
14:59:48 <ski> literallyCrevice : yea, it'll take some time to sink in the ramifications of this. i'm just trying to give a brief sketchy overview of what's happening
14:59:58 <hpc> and you want to group from left to right in a way that's add up to 3, put all of those in a list
15:00:05 <hpc> then reset to 0 and continue with the remainder?
15:00:24 <lavalike> hpc: yes as soon as your state would exceed 3, back to acc = 0
15:00:31 <hpc> hmm
15:00:34 <literallyCrevice> Well, thanks a lot for the explanations but I've gotta go sleep. Good night guys!
15:00:53 <ski> literallyCrevice : at first, this might seem a bit roundabout way to actually do I/O. but it does achieve total separation of I/O from normal evaluation. this is sometimes called "purity" (given equal inputs, functions give equal outputs. an expression always evaluates (not executes) to the same value, whenever it's evaluated)
15:01:06 <hpc> i think i would have to write out that function explicitly, and intuit the right abstraction from that
15:01:12 <lavalike> hpc: I have done it with a fold but it is not clear what the underlying primitive abstractions it is composed out
15:01:12 <ski> literallyCrevice : ok. have fun with your further adventures in Haskell. pleasant dreams
15:01:20 <literallyCrevice> thanks
15:01:24 <lavalike> hpc: haha I had to stop typing and press return just to show that we thought the same thing
15:02:10 <hpc> this is definitely some sort of fold
15:03:12 <lavalike> hpc: https://pastebin.com/raw/5CztiheN
15:04:07 <lavalike> I was thinking maybe if I could go from (Int,[a],[[a]]) to something like (Sum _, _) there might be a nice abstraction to use
15:04:55 <lavalike> (the use of Text.length as a view pattern would be better abstracted too)
15:05:09 <hpc> i think the next place go to is factor out the counting logic into that (\s x y -> (s + x + y, s+x+y > 3)) you mentioned
15:06:26 <hpc> and then once you have that, look at the types and rearrange things a bit until something stands out?
15:06:28 <lavalike> hmm right can definitely use   \s x -> (s <> x, pred $ s <> x)   to do it
15:06:57 <lavalike> pred is not a good name, oopsie
15:08:24 <hpc> i guess a general process is look at your code and see what makes it gross to even look at
15:08:25 <Solonarv_> "this is definitely some kind of fold" - *every* function that takes a list is some kind of fold, actually
15:08:33 <hpc> then make it so you don't have to look at it by abstracting it away
15:08:43 <hpc> and what better abstraction is there than a function!
15:08:56 <lavalike> that's just the "ugly" part
15:09:03 <lavalike> I like what's around it, using it
15:09:07 <hpc> heh
15:09:23 <lavalike> …and it's not *that* ugly (:
15:10:41 <hpc> yeah
15:10:51 <hpc> it's hard sometimes to write truly ugly code in haskell
15:10:55 <hpc> my best attempt was:
15:10:56 <hpc> sortBy compare = head . head . dropWhile (isn't unsafeCoerce . drop 1) . group . iterate bubble
15:11:02 <hpc> where ... bubble (x:y:ys) = if compare x y == GT then y:(bubble (x:ys)) else if compare x y == EQ then x:(bubble (y:ys)) else if compare x y == LT then x:(bubble (y:ys)) else x:y:(bubble ys)
15:11:13 <lavalike> eeeeeep
15:11:41 <lavalike> the two-line treatment isn't kind to it
15:11:53 <hpc> i was trying on purpose there too :D
15:12:17 <lavalike> >:)
15:13:06 <hpc> but writing a pointfree sort function that legitimately used unsafeCoerce was completely worth it
15:13:16 <lavalike> agreed
15:13:42 <lavalike> another approach would be to write a more specialized version instead of a composition of more general things, but I couldn't figure out how to nail that with say takeWhile/dropWhile
15:14:31 <lavalike> chunksOf length (<=8) ["blah","blah","blah"] => [["blah","blah"],["blah"]]
15:14:43 <lavalike> if you will
15:14:59 <hpc> ooh
15:15:17 <hpc> and for your example, chunksOf sum (<=3)
15:15:22 <lavalike> aye
15:16:40 <hpc> i think that's the abstraction
15:17:05 <lavalike> (I was thinking chunksOf (+) (<=3) actually)
15:17:49 <lavalike> otherwise the other one needs to be chunksOf (sum . map length) which seems overkill
15:18:59 <lavalike> otoh this seems to get away with not having a base case for the accumulator, it's embedded in `sum`
15:18:59 --- mode: glguy set +v neallred
15:19:42 <hpc> yeah
15:20:14 <lavalike> something along the lines of   last . dropWhile p . inits   gets the first part, but then what
15:20:33 <lavalike> (and it's safe!)
15:22:37 <catch22> q
15:24:35 <lavalike> *takeWhile
15:34:02 <bollu> What are some uses of the (#.) function in Profunctor.Unsafe?
15:41:29 <berndl> :t (#.)
15:41:30 <lambdabot> error: parse error on input ‘)’
15:43:33 <jle`> berndl: it's mostly used for performance reasons to get around faulty inlining
15:43:35 <jle`> in lens
15:43:51 <geekosaur> someone should fix that so it doesn't assume (# always starts an unboxed tuple
15:47:34 <bollu> ah, I see
16:04:35 <fragamus> we can use [] in a pattern to detect the case where an empty list is passed but is there a way to do the same for empty set
16:05:39 <geekosaur> only with OverloadedLists and an appropriate instance, I think
16:05:51 <fragamus> gah
16:06:07 <fragamus> we need to make that more natural
16:06:11 <geekosaur> otherwise there's no exported constructor to match against
16:07:43 <bollu> GHCi is giving me really weird outputs (different types from :t and :info). Does anyone have any insight into this? https://gist.github.com/bollu/8e117e1e4ac0359ec32959161372d384 (It looks like my message got swallowed?)
16:07:59 <geekosaur> conceivably there could be a pattern :∅ or similar
16:10:50 <ski> > let isEmpty :: S.Set a -> Bool; isEmpty (S.null -> True) = True; isEmpty _ = False in isEmpty S.empty   -- fragamus ?
16:10:52 <lambdabot>  True
16:11:12 <geekosaur> bollu, is PolyKinds turned on?
16:11:57 <bollu> geekosaur Let me check. BTW, reload the file, stack returns the same answer for both `:info` and `:t`, presumably because of a different GHCi version
16:12:01 <bollu> (reload the gist, that is)
16:12:37 <geekosaur> https://downloads.haskell.org/~ghc/8.6.1/docs/html/users_guide/glasgow_exts.html#pretty-printing-in-the-presence-of-kind-polymorphism is relevant here
16:12:55 <geekosaur> :set -fprint-explicit-kinds might give some hints
16:13:34 <fragamus> ski that syntax with the arrow is new to me
16:13:46 <fragamus> where do I learn about that
16:14:34 <ski> search for `ViewPatterns'
16:16:19 <fragamus> OMFG thats cool
16:17:01 <hpc> fragamus: is this your first language extension?
16:17:11 <fragamus> no
16:17:30 <hpc> i was going to say, it only gets cooler from here ;)
16:17:49 <fragamus> how the fuck do I not know about this
16:18:36 <ski> there's also `PatternSynonyms'
16:18:51 <ski> not sure whether `Data.Set' defines any, though
16:19:14 <geekosaur> right, that as what I was suggesting as a potential solution
16:21:12 <ski> hm, i suppose the equation `x  =  (f -> f x)' would hold, yes ? .. at least for an iso `f'
16:26:58 <jle`> fragamus: yeah, [] works because [] is a constructor for list; the onyl way to do it for set is probably using pattern synonyms
16:27:05 <jle`> which lets you 'simulate' constructors
16:29:14 <jle`> set is an abstract data type
16:37:50 <Solonarv_> you can also define :{ pattern EmptySet <- (null -> True) where EmptySet = empty :} and that should let you pattern-match on EmptySet
16:38:10 <Solonarv_> (that's the pattern synonym)
16:39:42 <bollu> Could someone please explain an implementation to me? There's a constructor that takes a function which has *four* arguments, but gets constructed by a function that takes *three arguments*. How? https://gist.github.com/bollu/8e117e1e4ac0359ec32959161372d384#what-is-the-explanation-for-this-implementation
16:40:29 <jle`> Data.Set should probably provide such a pattern synony, since it works pretty well with the current internal representation
16:40:44 <jle`> pattern EmptySet = Data.Set.Internal.Tip
16:41:20 <jle`> no guaruntee that the internal rep won't change though
16:41:37 <hpc> bollu: is it polymorphic at all?
16:41:40 <hpc> > id id 5
16:41:42 <lambdabot>  5
16:41:53 <hpc> oh, you pasted it
16:42:13 <jle`> bollu: remember all functions take one parameter, really
16:42:37 <hpc> or it's curried
16:42:49 <jle`> haskell makes it really easy to do partial application
16:43:01 <hpc> > (\x -> id) "param one" "param two"
16:43:02 <lambdabot>  "param two"
16:43:03 <jle`> > map ((+) 2) [1..10]
16:43:05 <lambdabot>  [3,4,5,6,7,8,9,10,11,12]
16:43:07 <bollu> I don't see how the types would align
16:43:08 <bollu> no, that's okay
16:43:15 <bollu> but if that's the case, the types don't match, right?
16:43:30 <jle`> the paste itself doesn't ever define Plan
16:43:35 <jle`> so there's not much we can say
16:43:57 <hpc> :t \kp _ kr -> kr kp h
16:43:58 <lambdabot> FromExpr t1 => t2 -> p -> (t2 -> t1 -> t3) -> t3
16:44:00 <bollu> oh, Plan k o a = forall m. PlanT k o m a
16:44:02 <bollu> let me paste it
16:44:30 <ski> (some partial applications)
16:44:36 <jle`> bollu: remember that it's possible to return a function
16:44:37 <ski> `:t awaits' does look weird
16:44:37 <bollu> updatd
16:44:44 <hpc> and (t2 -> t1 -> t3) unifies with (forall z. (z -> m r) -> k z -> m r -> m r)
16:44:50 <hpc> so t3 = (m r -> m r)
16:45:13 <hpc> so t2 -> p -> (t2 -> t1 -> t3) -> t3 is actually t2 -> p -> (t2 -> t1 -> m r -> m r) -> m r -> m r
16:45:23 <jle`> bollu: do you understand the implementation of "doubleAll = map (*2)" ?
16:45:27 <bollu> yeo
16:45:28 <bollu> yep**
16:45:42 <jle`> doubleAll takes one argument, but we explicitly only name one
16:45:47 <jle`> that's becasue we're returning a single-argument function
16:45:49 <bollu> right
16:45:51 <hpc> your gist has await's definition way to the right on the same line btw
16:46:03 <bollu> hpc fixed that
16:46:29 <bollu> Right, I should have phrased the question better, I meant more "help me unify these types"
16:46:31 <jle`> it might help to re-parenthesize the type of the PlanT constructor
16:46:43 <bollu> I messed it up on pen and paper, let me retry thi
16:46:44 <bollu> thi*
16:46:46 <bollu> this**
16:47:04 <jle`> instead of thinking of it as A -> B -> C -> D -> E
16:47:10 <jle`> think of it as A -> B -> C -> (D -> E)
16:47:17 <bollu> (a -> m r) ->(o -> m r -> m r) ->(forall z. (z -> m r) -> k z -> (m r -> m r))
16:47:18 <bollu> yeah
16:47:18 <jle`> the first thing "takes four parameters"
16:47:25 <bollu> indeed.
16:47:26 <jle`> the second thing "takes three parameters"
16:47:31 <jle`> so that's what is going on here
16:47:41 <hpc> also try writing awaits h = PlanT foo where foo :: _; foo = ...
16:47:41 <jle`> instead of taking four parameters and returning E, it's taking three parmaeters and returning D -> E
16:47:49 <hpc> and see what type it tells you that function has
16:48:10 <bollu> Indeed :) 
16:48:13 <bollu> Will do, thanks!
16:48:14 <jle`> bollu: in this case it's taking an (a -> m r), an (o -> m r -> m r), and a (z -> m r), and returning a (k z -> (m r -> m r))
16:48:26 <ski> `\kp _ kr -> kr kp h' is equal to `\kp _ kr mr -> kr kp h mr', by eta
16:48:34 <bollu> ski yeah
16:48:55 <bollu> ski oh, that's a nice way to see it. eta-expand and then view it
16:49:15 <jle`> so `kr kp h` is a (k z -> (m r -> m r))
16:49:22 <bollu> Right
16:49:33 <jle`> in fact you could even double eta-expand it
16:49:41 <bollu> I still have no idea what this thing does :P 
16:50:01 <jle`> \kp _ kr kz mr -> kr kp h kz mr
16:50:20 <jle`> bollu: it's a church encoding
16:50:37 <jle`> the "constructors" are given as comments
16:50:53 <bollu> Right, but, I mean, I have no idea what "Await" does, really
16:51:07 <jle`> data PlanT k o m a = Done a | Yield o (Plan k o a) | forall z. Await ... | Fail
16:51:34 <jle`> so PlanT as it has been given is the church encoding of that above data type
16:52:17 <ski> jle` : `kz' ?
16:52:25 <jle`> it's a bit weird because it has to cps-transform the existential Awaits
16:52:32 <jle`> 🎿 from the type in the paste
16:52:42 <jle`> oh heh, my emoji autoreplace kicked in
16:53:13 <ski> jle` : that defininition of `PlanT k o m a' doesn't use `m'
16:54:25 <jle`> ah yeah, drop the m as a type parameter
16:54:25 <ski> ("cps-transform the existential" ?)
16:55:06 * ski . o O ( `(exists a. ..a..) -> ...  =  forall a. (..a.. -> ...)' )
16:55:07 <jle`> well they need to do something about the existential constructor, forall z. Await (z -> Plan k o a) (k z) (Plan k o a) 
16:55:28 <jle`> so they turned it into a (forall z. (z -> r) -> k z -> r -> r)
16:55:53 <jle`> just to be clear we're both referring to the same paste right?
16:56:20 <ski> that's not something extra CPS done in the `Await' case. it's just the CPS enabled that `exists' into `forall' reformulation
16:57:00 <jle`> ah yeah. but it's something we have to do to church-encode with the await constructor, right?
16:57:11 <ski> right
16:57:13 <jle`> i'm saying that that's the only 'tricky' part involved in the transform
16:57:32 <ski> well, it'd say the `m' business looks a bit tricky
16:58:12 <jle`> hm yeah, i was going to say it's just a simple substitution, but it's a little deeper than i thought
16:59:20 <jle`> bollu: referring to your question though, do you understand the other constructors, Done, Yield, Fial ?
16:59:50 <bollu> Yeah, thoss seem to make sense
17:00:11 <bollu> Those*
17:00:21 <bollu> My question is, what is the intuition for `Await`?
17:00:21 <ski> hm, if `f :: * -> *', can we yoneda `f' into `forall g. (f ~> g) -> g', by which i mean `\a. forall g. (forall b. f b -> g b) -> g a' ?
17:00:35 <bollu> my question is now*
17:02:18 <jle`> ah yeah, looks something like the yoneda embedding/transform
17:02:25 <ski> hm, i suspect `Await success act fail' presents `act' for the interpreter to execute, giving a result `z'. then the interpreter continues with `success z'. in case `act' fails, we instead continue with `fail'
17:02:30 <ski> but that's just my guess
17:03:50 * ski isn't even sure what this data type is trying to model precisely. .. looks like some kind of stream processor, anyway
17:04:14 <ski> (also the type of `z' there is unknown to the interpreter, so it can't tamper with its value)
17:04:23 --- mode: glguy set +v fsharper
17:06:44 <bollu> ski if it can assume nothing about z, what can such a thing even do
17:06:57 <ski> well, it does know what `k' is
17:07:02 <ski> it might e.g. be `IO'
17:07:09 <bollu> isn't (forall z. z -> Plan k o a) ~= Plan k o a?
17:07:31 <ski> so, it gets an `IO z', which it can execute, getting back a `z' which it can pass to `success', and then continue
17:07:40 <jle`> bollu: it gives you a way to 'make' the z, the 'k z'
17:08:07 <ski> where did `forall z. z -> Plan k o a' come from ?
17:08:11 <jle`> the z roughly refers to an intermediate value necessary in the computation
17:08:48 <jle`> that's why it's existentially quantified -- throughout the computation, there may be many intermediate values of many different types
17:09:02 <jle`> and it's Plan's job to tell you *how* to make the intermediate value (k z) if it ever needs one (z -> Plan)
17:09:04 <bollu> ski Ah, nvm, I'm reading  the type signature wrong :)
17:09:06 * ski is thinking either a higher yoneda, or some kind of kleisli thing
17:09:31 <jle`> bollu: Await will pause to wait for a z (intermediate value), but not without telling you how to make the z (k z)
17:10:24 <jle`> it's basically deferring the act of "creating" the z (the `k z`) to the thing consuming the Plan
17:10:50 <bollu> jle` why does it have a spare "r" lying around then?
17:10:56 <jle`> the r is the cps transform
17:11:00 <jle`> er sorry, the church transform
17:11:07 <jle`> it's kinda funky
17:11:12 <jle`> the r isn't in the original data type, remember
17:11:44 <jle`> bollu: how familiar are you with church encodings?
17:11:48 <ski> hm, say `Plan k o a = a + o * Plan k o a + (exists z. (z -> Plan k o a) + k z + Plan k o a) + 1' (for the sake of argument)
17:12:08 <bollu> jle` I'm familiar with them for numbers, lists, etc
17:12:28 <jle`> bollu: yeah, for lists, we have constructors [] and a : [a], so the transform is:
17:12:49 <ski> er, sorry, typo, that ought to be
17:12:50 <jle`> churchList :: forall r. r -> (A -> r -> r) -> r
17:13:03 <jle`> as a transformation of [A]
17:13:07 <ski>   Plan k o a = a + o * Plan k o a + (exists z. (z -> Plan k o a) * k z * Plan k o a) + 1
17:13:28 <ski> then, since we're doing an inductive data type (which is regular, all recursive calls pass the same arguments), this is really
17:13:33 <ski>   Plan k o a = mu p. a + o * p + (exists z. (z -> p) * k z * p) + 1
17:13:53 <jle`> (and i use r in the same way)
17:13:57 <jle`> (bollu)
17:14:14 <ski> using the general law `mu r. ..r..  =  forall r. (..r.. -> r) -> r', we can reformulate this as
17:14:38 <ski>   Plan k o a = forall p. (a + o * p + (exists z. (z -> p) * k z * p) + 1 -> p) -> p
17:15:01 <ski> hm, ok, i could use `r' instead of `p', i suppose
17:15:12 <ski>   Plan k o a = forall r. (a + o * r + (exists z. (z -> r) * k z * r) + 1 -> r) -> r
17:15:22 <bollu> jle` how is this a church encoding? isn't this a CPS? 
17:15:48 <bollu> (the church encoding of lists I know is to use a nested collection of pairs, which looks quite different IIRC)
17:15:53 <jle`> it's a church encoding because it takes the constructors and replaces them with a callback
17:16:11 <jle`> oh, hm, not sure what church encoding you are talking about
17:16:24 <bollu> This is the encoding I know: https://en.wikipedia.org/wiki/Church_encoding#One_pair_as_a_list_node
17:16:31 <ski> anyway, using the exponent law `a^(b + c) = a^b * a^c' (aka `b + c -> a  =  (b -> a) * (c -> a)'), and also the laws `a^1 = a' and `a^(b * c) = (a^c)^b', we get
17:16:56 <ski> (we also need to the law `(exists a. ..a..) -> ...  =  forall a. (..a.. -> ...)' mentioned before)
17:17:47 <jle`> bollu: hm, we're talking about the second one
17:17:51 <jle`> take a look at the data type Bool
17:17:54 <jle`> data Bool = False | True
17:18:03 <jle`> the church encoding, basically we replace a constructor with "what we would do with the consturctor"
17:18:04 <ski>   Plan k o a = forall r. (a -> r) -> (o -> r -> r) -> (forall z. (z -> r) -> k z -> r -> r) -> r -> r
17:18:19 <jle`> so we get bool ::: forall r. r -> r -> r
17:18:25 <ski> (that's several steps at once. if you prefer, we could do that in more detail)
17:18:37 <ski> point is, now we get something which looks quite similar to the given
17:18:54 <jle`> bollu: and a type like data Maybe a = Nothing | Just a 
17:19:06 <jle`> we'd have myMaybe :: forall r. r -> (a -> r) -> r
17:19:08 <bollu> forall r. r -> (a -> r) -> r
17:19:10 <bollu> right
17:19:15 <jle`> the first argument is "how to handle Nothing" the second is "how to ahndle Just x"
17:19:18 <jle`> for a list we have:
17:19:23 <ski>   PlanT k o m a = forall r. (a -> m r) -> (o -> m r -> m r) -> (forall z. (z -> m r) -> k z -> m r -> m r) -> m r -> m r
17:19:26 <jle`> data List a = Nil | Cons a (List a)
17:19:44 <jle`> this is where the church encoding differs from the scott encoding; here, we treat the recursive List as the r
17:20:02 <jle`> myList :: forall r. A -> (A -> r -> r) -> r
17:20:12 <jle`> the first argument is 'how to handle Nil', the second is 'how to handle cons'
17:20:24 <ski> jle` : you'd better swap out one of those `A's
17:20:29 <bollu> jle` I had expected: forall r. a -> (forall k. a -> k -> k) -> a?
17:20:42 <jle`> ah yeah, forall r. r -> (A -> r -> r) -> r
17:20:44 <bollu> whoops
17:20:45 <bollu> wait
17:20:55 <bollu> forall r. r -> (forall k. a -> k -> r) -> r?
17:21:03 <bollu> hm, no, that just looks weird
17:21:03 <ski> no `k'
17:21:35 <YellowOnion> Would anyone have any clue why GHC is trying to load an entry point from the wrong dll on windows?
17:21:37 <ski> `List' didn't have any existential quantification
17:21:48 <ski> so there should be no `forall k.' in the result there
17:21:51 <bollu> right. 
17:22:36 <jle`> so for list, we add a callback for every constructor.  the callback for Nil is just 'r', the calback for cons is (A -> r -> r) -- it's given the item in the cell and the result of induction on the rest of the list
17:22:45 <ski> (for a moment i was considering `Plan k o (m a) = PlanT k o m a', but then i realized that doesn't work)
17:22:49 <jle`> so ski just went through doing the same thing for all of the constructors of ADT PlanT
17:23:18 <bollu> jle` can you implement tolist: (forall r. r -> (a -> r -> r) -> r) -> [a] ?
17:23:30 <jle`> yup, and the answer is pretty enlightening
17:23:33 <ski> @type GHC.Exts.build
17:23:33 <lambdabot> (forall b. (a -> b -> b) -> b -> b) -> [a]
17:23:36 <jle`> and illuminating
17:23:45 <jle`> i recommend trying to figure it out :)
17:23:58 <jle`> think (1) how to handle empty list
17:24:00 <jle`> (2) how to handle cons
17:24:06 <bollu> toList f = f [] (:)
17:24:07 <bollu> ?
17:24:09 <jle`> mhm
17:24:13 <bollu> yeah, makes sense
17:24:21 <bollu> and the other way round would be:
17:24:34 <bollu> fromList :: [a] -> (forall r. r -> (a -> r -> r) -> r)
17:24:52 <ski>   build (\f z -> foldr f z as)  =  as
17:25:18 <ski>   foldr f z (build g)  =  g f z
17:25:33 <jle`> yeah, fromLIst would be basically matching the callback with the constructor you get (plus the the induction)
17:26:12 <jle`> fromList [] nil cons = nil
17:26:18 <jle`> fromList (x:xs) nil cons = cons x (fromList xs)
17:26:29 <jle`> er, fromLilst (x:xs) nil cons = cons x (fromList xs nil cons)
17:26:31 <ski> recursive call
17:27:40 <bollu> ah
17:28:25 <jle`> 🎿 the cps-to-m r pattern is something i've seen pretty often though, but i don't know what it is theoretically.
17:28:31 <ski> @type (\xs z f -> foldr f z xs) :: [a] -> (forall r. r -> (a -> r -> r) -> r)
17:28:31 <bollu> right, this is illuminating
17:28:32 <bollu> :) 
17:28:32 <lambdabot> [a] -> r -> (a -> r -> r) -> r
17:28:48 <bollu> @djinn [a] -> (forall r. r -> (a -> r -> r) -> r)
17:28:48 <lambdabot> Error: Undefined type []
17:29:00 <jle`> ski -- it's basically like withFile :: FilePath -> (forall r. (Handler -> IO r) -> IO r) 
17:29:03 <bollu> right
17:29:03 <ski> djinn doesn't know higher-rank
17:29:06 <bollu> it's a continuation
17:29:08 <bollu> ski I see
17:29:22 <ski> jle` : yea, it feels similar to working in the kleisli
17:29:40 <ski> but i'm not sure that's the full story (since we also had `m r' argument types)
17:29:48 <jle`> n this case it's just weird becasue the restriction feels arbitrary
17:29:55 <jle`> since withFile *needs* IO as a cosntraint
17:30:11 <jle`> 🎿 the mr argument types just popped out to be consistent
17:30:31 <jle`> since the induction is 'monadic'
17:30:45 <jle`> the equivalent for list would be forall r. m r -> (A -> m r -> m r) -> m r
17:30:48 <ski> imagine something like `data Blah :: * where Foo :: Int -> IO Blah'
17:30:53 <bollu> jle` any idea why they CPS'd Plan? performance? (to help inlining?)
17:31:03 <jle`> usually it's done for perf and inlining yea
17:31:29 <ski> bollu : i think they want to have ambient `m' effects, so to speak
17:31:31 <jle`> if you were doing the same thing for lists, you can't do forall r. m r -> (A -> r -> m r) -> m r
17:31:43 <bollu> ski not sure I follow
17:31:46 <jle`> you'd have to go full-m, forall r. m r -> (A -> m r -> m r) -> m r
17:32:07 <jle`> but i'm pretty sure that forall r. m r -> (A -> m r -> m r) -> m r is equivalent to lists
17:32:07 <ski> jle` : *nod*, and that's the part i dunno how to explain
17:32:24 <ski> jle` : well, if you `forall m. Monad m =>', possibly
17:32:40 <jle`> my arguemnt only makes sense if you don't, though
17:32:55 <jle`> so im perplexed
17:33:03 <jle`> or well, it's only relevant if you are allowed to not forall m.
17:33:22 <bollu> jle` isn't it "more powerful" than lists? you'd get list if you picked m = Identity, no? but if you know that `m = Monad`..
17:33:28 <jle`> ah yeah, if you can pick specific m, it's of course not equivalent to a list
17:33:37 <jle`> it's a way you can *consume* a list
17:33:41 <bollu> yeah
17:33:43 <jle`> but you can't go backwards
17:33:50 <ski> well, it seems reasonably that `PlanT k o m a' really is more powerful than a `Plan k o a' -- otherwise, why bother parameterizing on `m' ?
17:33:58 <bollu> with access to some monadic environment. Is that what you meant, ski?
17:34:31 <ski> bollu : something like that, yes
17:34:47 <ski> this is only a hunch. i can't substantiate it much more, atm
17:35:55 <jle`> yeah, i guess the question is what do you gain from indroducing the m, that you can't just do from using Plan k o (m a)
17:36:30 * ski . o O ( <https://www.xkcd.com/1724/> )
17:37:00 <jle`> heh
17:37:03 <ski> jle` : well, the `m r' arguments .. but what's the ramifications of that, i assume you're wondering (as well as i)
17:37:38 <jle`> ah yeah.
17:37:52 <jle`> well, you can get m r arguments as well, since it's forall r.
17:38:09 <jle`> (right?)
17:38:16 <bollu> you can do things like: MonadIO m => MonadIO (PlanT k o m a), I think?
17:38:26 <bollu> Because you can "thread" the monad through?
17:39:21 <bollu> what am I missing? :) 
17:40:05 <jle`> oh, the m must be required to let you touch the 'z' in an appropriate way
17:40:15 <jle`> er wait, nvm
17:40:58 * ski . o O ( Brouwer-Kripke Schema of the Creative Subject <https://plato.stanford.edu/entries/intuitionism/#CreSub> )
17:41:14 <zachk> whats Plan?
17:41:33 <jle`> bollu: we're saying that you can always just do that anyway with the directly cps'd Plan
17:41:36 <bollu> http://hackage.haskell.org/package/machines-0.6.4/docs/Data-Machine-Plan.html
17:41:38 <jle`> zachk: http://hackage.haskell.org/package/machines-0.6.4/docs/Data-Machine-Plan.html
17:41:42 <ski> <ski>   Plan k o a = a + o * Plan k o a + (exists z. (z -> Plan k o a) * k z * Plan k o a) + 1
17:41:43 <bollu> jle` ah, hm
17:42:16 <jle`> you just pick r to be m r
17:42:24 <ski> or `data Plan k o a = Done a | Yield o (Plan k o a) | forall z. (z -> Plan k o a) (k z) (Plan k o a) | Fail', if you prefer
17:42:31 <ski> zachk ^
17:43:36 <davean> Plan is a Monad, Machine isn't
17:43:38 <ski> jle` : hm, right. it only does `forall m.', not `forall m. Monad m =>'
17:43:46 <davean> You might want to note that.
17:44:02 <davean> Machine can't be a Monad.
17:44:19 <bollu> davean so, you use plan to build Machine using do-notation?
17:44:24 <davean> yes
17:44:26 <bollu> (which then gets reified?)
17:44:29 <zachk> ty
17:44:30 <davean> Exactly
17:44:37 <bollu> I see, I now see the point : 
17:44:38 <bollu> :) 
17:44:52 * ski hasn't seen `Machine' mentioned before, in above discussion
17:45:02 <davean> ski: I only infered it a lot because I use it a lot
17:45:11 <ski> machines ?
17:45:26 <davean> ye
17:45:28 <bollu> and this works because ContT is a monad?
17:45:46 <bollu> or is there something deeper?
17:45:53 <bollu> well, monad transformer
17:46:28 * ski allots some hyperbole
17:46:47 <jle`> hm, myabe the 'm' just a way to get the kinds to work out for a Monad instance
17:47:25 <ski> hm, going back to
17:47:31 <jle`> er, a MonadTrans instance
17:47:39 <ski>   Plan k o a = mu p. a + o * p + (exists z. (z -> p) * k z * p) + 1
17:47:51 <ski> i wonder what happens if we try to higher yoneda it
17:47:57 <jle`> bring me a higher yoneda ~
17:50:30 <ski>   Plan k o = mu p. I :+: K o :*: p :+: (exists z. ((z ->) . p) :*: K (k z) :*: p) :+: K 1
17:50:33 <ski> i think
17:52:13 <ski> using `I a = a',`K c a = c',`(f . g) a = f (g a)',`(f :+: g) a = f a + g a',`(f :*: g) a = f a * g a', and, hmm ..
17:55:16 <ski> `(mu p. \a. ..a..(p a)..) a = mu p. ..a..p..', if i'm not confusing myself
17:56:16 <ski> so, attempting to continue with `mu f. ..f..  =  forall g. ((f ~> g) ->) . g' as suggested before
17:56:48 <ski> er, sorry that must be wrong
17:56:56 <davean> I'm a bit lost
17:58:09 <ski>   mu f. ..f..  =  forall f. ((..f.. ~> f) ->) . f
17:58:31 <ski> corresponding to the usual first-order `mu r. ..r..  =  forall r. (..r.. -> r) -> r'
17:59:46 <ski> (note that `(forall f. ..f..) a' means `forall f. (..f..) a', here. so `forall f. ((..f.. ~> f) ->) . f' means `\a -> forall f. (forall b. (..f..) b -> f b) -> f a' (remember `(f ~> g) = forall a. f a -> g a'))
18:00:00 <ski> so, attempting to go on with this
18:00:34 <ski>   Plan k o = forall p. ((I :+: K o :*: p :+: (exists z. ((z ->) . p) :*: K (k z) :*: p) :+: K 1 ~> p) ->) . p
18:00:57 <ski>   Plan k o a = forall p. (I :+: K o :*: p :+: (exists z. ((z ->) . p) :*: K (k z) :*: p) :+: K 1 ~> p) -> p a
18:01:19 <ski>   Plan k o a = forall p. (forall b. (I :+: K o :*: p :+: (exists z. ((z ->) . p) :*: K (k z) :*: p) :+: K 1) b -> p b) -> p a
18:02:02 <ski>   Plan k o a = forall p. (forall b. b + o * p b + (exists z. (z -> p b) * k z * p b) + 1 -> p b) -> p a
18:02:26 <ski> (also `(exists z. ..z..) a' means `exists z. (..z..) a')
18:03:41 <ski>   Plan k o a = forall p. (forall b. (b -> p b) -> (o -> p b -> p b) -> (forall z. (z -> p b) -> k z -> p b -> p b) -> p b -> p b) -> p a
18:04:43 <ski> hm, so attempting now to compare this with the given
18:04:50 <ski>   PlanT k o m a = forall r. (a -> m r) -> (o -> m r -> m r) -> (forall z. (z -> m r) -> k z -> m r -> m r) -> m r -> m r
18:04:54 <ggVGc> uhm
18:07:15 <ski> hrm, something seems off
18:07:51 <davean> bollu: what prompted this question?
18:09:18 <ski> ah, i mistaked
18:09:27 <ski> restarting from
18:09:34 <ski>   Plan k o a = forall p. (forall b. b + o * p b + (exists z. (z -> p b) * k z * p b) + 1 -> p b) -> p a
18:09:52 <ski> (doing smaller steps, to not confuse myself again in the same way)
18:10:40 <ski>              = forall p. (forall b. (b -> p b) * (o * p b -> p b) * ((exists z. (z -> p b) * k z * p b) -> p b) * (1 -> p b)) -> p a
18:11:28 <ski>              = forall p. (forall b. (b -> p b) * (o -> p b -> p b) * (forall z. (z -> p b) -> k z -> p b -> p b) * p b) -> p a
18:11:53 <ski>              = forall p. (forall b. b -> p b) * (forall b. o -> p b -> p b) * (forall b z. (z -> p b) -> k z -> p b -> p b) * (forall b. p b) -> p a
18:12:12 <ski>              = forall p. (forall b. b -> p b) -> (forall b. o -> p b -> p b) -> (forall b z. (z -> p b) -> k z -> p b -> p b) -> (forall b. p b) -> p a
18:12:33 <ski> comparing again with
18:12:40 <ski>   PlanT k o m a = forall r. (a -> m r) -> (o -> m r -> m r) -> (forall z. (z -> m r) -> k z -> m r -> m r) -> m r -> m r
18:13:44 <ski> if we replace `p' by `m', removing the outer `forall m.', then they look more similar (iow `forall m. PlanT k o m a' looks more similar to `Plan k o a')
18:16:14 <ski> if we have `forall m. PlanT k o m a', we can attempt to construct `Plan k o a', by fixing all the `forall b.'s in the argument types in the latter with `r' (which comes from where ??)
18:17:13 <ski> that leaves us with `r -> m r' not matching `a -> m r', with `m a' at the end not matching `m r', and with the problem of where `r' would come from
18:17:23 <ski> (and that's just one direction)
18:19:15 <ski> the other direction (from `Plan k o a' to `forall m. PlanT k o m a') seems even harder. e.g. how to construct `forall b. o -> m b -> m r' from `o -> m r -> m r' (and having been given a particular `r') ??
18:19:49 <ski> so .. i think this attempt, at least by itself, is a red herring
18:20:11 <ski> perhaps something kleisli could work
18:22:00 <zachk> do I lose full type inference if I enable GADTs and use them in certain ways? 
18:22:31 <ski> you'll need to supply a signature when you match on the GADT
18:22:53 <ski> (it can't infer the typing of the GADT `case')
18:23:28 <ski> other code, such as merely calling operations which does such `case', should be ok
18:24:01 <ski> (unless of course that is higher-rank, or polymorphic recursion, which are other sources of non-inference)
18:24:18 <zachk> yea I kind of noticed the lack of the inference when pattern matching in a function definition, just wanted to know how general the loss was, thank you
18:41:40 --- mode: glguy set +v nolrai
18:46:25 --- mode: glguy set +v nolrai_
19:06:17 <Nolrai> I wonder if this place is as dead compared to what I remember, as haskell-game is.
19:07:53 <MarcelineVQ> Only you can know for sure
19:14:10 <Nolrai> True.
19:16:38 <Nolrai> Oh well. If I am going to have to actually read a bunch of packages and figure out if they are what I want, and have a good chance of working, I'm going to go sleep for now. I'll be back.
19:17:49 <MarcelineVQ> I miss Nolrai.
19:17:57 * Clint chuckles.
19:18:19 <Clint> Nolrai will be back.
19:19:49 * ski . o O ( who will be forward ? )
21:01:55 <juliusdeane> Would anyone be willing to give comments & critique on my Haskell game?
21:06:40 <MarcelineVQ> go ahead link to it and someone might chime in :>
21:07:08 <juliusdeane> https://gitlab.com/Bleu-Box/mint-chip
21:08:23 <juliusdeane> I'm self-taught and this game is my first big project so I want to see how I did
21:15:37 <kadoban> juliusdeane: Congratulations :)
21:20:17 <MarcelineVQ> pretty neat, not having pixel based collisions makes it a little hard to get by these narrows, but code-wide it's pretty good looking to me
21:21:41 <juliusdeane> Cool, thanks! The code was the main part I was wondering whether it was good or not! 
23:16:28 <alexelcu> Anybody has any experience with the IntelliJ plugins? I see there are 2 available — HaskForce and IntelliJ-Haskell. Which one would you recommend?
23:44:09 <leifmetcalf> In servant, how can you request a specific content type, and then accept a different one?
23:44:44 <leifmetcalf> For example, an http api will only respond if you specify Content-Type: application/json but it responds with application/x-download
23:50:28 <leifmetcalf> Ah, got it: `contentTypes` instead of `contentType`
23:57:54 --- mode: glguy set +v Mrbuck
