01:43:18 --- mode: glguy set +v Darwin226
01:44:09 <Darwin226> So I'm pretty sure I've found a bug in the optimizer. A function doing a bunch of floating point calculations produces different results in GHCi and in compiled, optimized code
01:44:17 <Darwin226> very different
01:44:46 <cocreature> Darwin226: do -O0 and ghci agree?
01:44:59 <Darwin226> Haven't tried yet
01:45:24 <Darwin226> But I was wondering if it's maybe a known bug that's fixed in newer versions, since I'm using 8.2
01:45:24 <Ariakenom_> well floating point is distilled evil
01:45:44 <Darwin226> maybe it rung a bell for someone
01:45:46 --- mode: ChanServ set +o Sigyn
01:45:47 <cocreature> Darwin226: can you post your function?
01:45:57 <Darwin226> I don't have a very minimal example yet
01:46:08 --- mode: ChanServ set +o Sigyn
01:46:14 <cocreature> doesn’t matter, I just want to see if I can reproduce it with 8.4 or 8.6
01:46:52 <cocreature> I vaguely recall some bugs that might be relevant here but I don’t remember the details
01:46:53 <Darwin226> I mean, I can push the whole project I guess, but it's much easier if I can just manage to isolate the problem
01:47:37 <cocreature> testing with a newer compiler to see if the bug has been fixed is usually easier than isolating problems :)
01:47:47 <cocreature> unless your program really depends on 8.2 for some reason
01:47:49 <Darwin226> Ariakenom_: This isn't just regular "floating point operations are associative" problem. It boils down to (Vec 20 (-20)) - (Vec 0 (-20)) resulting in (Vec 20 0) in GHCi and (Vec 20 20) in compiled code
01:49:08 <cocreature> I would first try -O0 just to make sure that it’s actually a bug in the optimizer and not some weird ghci thing
01:49:13 <cocreature> and if that works try a newer compiler
01:49:21 <cocreature> if the bug persists isolate it and make a bug report
01:49:29 <Darwin226> Ok. Will do
01:49:40 <tdammers> which GHC versions? I remember vaguely seeing a patch float by that might be related (sorry for the pun)
01:51:00 --- mode: ChanServ set +o Sigyn
01:51:42 <Darwin226> I've only tested on 8.2.2
01:51:44 <Ariakenom_> Darwin226: I meant more libc version used or fp state being set process wide but I'm sure the problem is different.
01:51:45 <Darwin226> Windows 64bit
01:52:34 <piyush-kurur> okey not sure whether my previous message reached. Is there a experimental hackage that is specifically tailored for backpack using packages ? 
01:52:42 <tdammers> unfortunately, searching for "float" or "floating" in phabricator or Trac coughs up a lot of noise related to float-outs and such
01:56:39 <cocreature> piyush-kurur: why does the normal hackage not suffice?
01:57:02 --- mode: ChanServ set +o Sigyn
01:57:35 <cocreature> there used to be one before backpack was released but now that we have multiple ghc and cabal releases supporting backpack it seems perfectly fine to push packages that use backpack to the “official” hackage instance
01:58:46 <piyush-kurur> cocreature: okey I did not know that the official hackage has incorporated these features sorry
01:59:01 <piyush-kurur> so hackage it will hit.
01:59:25 <cocreature> piyush-kurur: hackage doesn’t really care much about the details of your package. it mostly just provides a tarball containing the sources
02:00:00 <merijn> Although, for experimental packages try and not claim very valuable package names and make sure you properly set your cabal version and base bounds :p
02:00:34 <piyush-kurur> cocreature: the problem is with documentation. The haddock documentation (locally) that I see with backpack is not very nice. 
02:00:58 <piyush-kurur> merijn: no worries it is an experimental version of  raaz which itself is very much experimental
02:00:58 <merijn> piyush-kurur: That's probably a haddock issue, not sure how well haddock's support for backpack is
02:01:01 <piyush-kurur> ;-)
02:01:25 <cocreature> right that’s a separate question
02:01:44 <merijn> piyush-kurur: Might wanna pay a visit to github.com/haskell/haddock and check for any backpack issues (and maybe file some for the most egregious problems)
02:01:47 <cocreature> hackage won’t do better than what you can achieve locally
02:01:59 <cocreature> if you manage to get better results locally however, you can upload documentation to hackage
02:02:04 <merijn> In fact, you can do better locally than on Hackage :p
02:03:05 <merijn> Speaking of which, I wish more of the bigger packages would upload docs with Quick Jump support
02:03:52 <cocreature> why is quick jump not simply the default in haddock?
02:04:43 <merijn> cocreature: The main problem is that it's only in the Haddock shipping with GHC 8.4 and I think Hackage still uses an older GHC
02:04:58 <merijn> cocreature: So Hackage haddock doesn't have quickjump support anyway
02:05:05 <cocreature> merijn: right but even in newer versions of haddock it’s not the default iirc
02:05:36 <merijn> cocreature: I dunno why it's not the default. Ask Alex? :p
02:05:52 <cocreature> heh :)
02:05:53 <merijn> But yeah, it's one of the best features of Hackage in ages :>
02:06:46 <Darwin226> Ok, I've managed to make a "minimal" example. cocreature do you maybe want to try it before I make a ticket?
02:06:52 <cocreature> Darwin226: sure
02:07:22 <Darwin226> https://dl.dropboxusercontent.com/s/nafsihra3m9a4kl/floating-bug.zip
02:07:50 <Darwin226> compiling with "ghc Main.hs" and running gives a different result from "ghc Main.hs -O2"
02:08:36 <Darwin226> Also, the problem doesn't actually seem to be in the floating point operations. tracing just the input to the function gives different results
02:09:02 <Darwin226> even though the same parameters are provided
02:11:03 <cocreature> Darwin226: I get the same results with -O0 and -O2 for both 8.4.3 and 8.2.2
02:11:12 <cocreature> what should be the correct results?
02:16:16 <fendor> I want to use `lookupEnv` but the function seems to not find the variables that i define in the shell via `export ...=...`, what do i have to do so that the environment variable is found?
02:17:46 <Darwin226> cocreature: What does the output look like?
02:18:20 <cocreature> Darwin226: "(Vec {_vecX = 20.0, _vecY = -20.0},Vec {_vecX = 0.0, _vecY = -20.0},Vec {_vecX = 20.0, _vecY = 0.0},Vec {_vecX = 1.0, _vecY = 0.0},20.0,Vec {_vecX = 0.0, _vecY = 3.0})"
02:18:34 <Darwin226> Interesting. I get "Vec {_vecX = 20.0, _vecY = 0.0}" at the start
02:18:47 <Darwin226> 0 instead of -20
02:19:30 <cocreature> with -O0 or -O2? i.e. is that the correct or the incorrect output?
02:19:41 <Darwin226> With O2. That's the wrong output
02:19:57 <Darwin226> It should just print out the position of the second particle
02:20:11 <davr0s_> i've seen 'Either' etc composing types into a sum..  is there a general purpose way to do that without nesting (is it ML that can do that, e.g.  something like Cube=..   Sphere=.. (Cube,Sphere work as independent types)     Shape = Cube+Sphere+.. (then a 'Shape' can be matched as Cube,Sphere..)    conversely is it possible to do the opposite
02:20:12 <cocreature> maybe some windows-specific bug? maybe test locally with 8.4 and 8.6 on your system
02:20:20 <Darwin226> I'll see what I can do
02:21:15 <Ariakenom_> davr0s_: Not like Either3 a b c = A a | B b | C c ?
02:21:50 <cocreature> davr0s_: not really, that feature is usually referred to as “anonymous sumtypes”. you can get something like it but it requires a fair amount of type-gymnastics and the ergonomics of actually using the result are usually not worth the effort ime
02:22:29 <davr0s_> Ariakenom_ thats sort of ok , i was just curious if 'anonymous sumtypes' really exist
02:24:01 <tdammers> davr0s_: I've seen people make infix aliases for Either for that purpose
02:24:32 <tdammers> type Foo = Int \/ Bool \/ Float
02:24:54 <davr0s_> hah thats interesting
02:24:55 <cocreature> yeah that’s at least nicer to read although ofc it only hides the nesting that’s going on
02:24:59 <tdammers> and then operators to drill down into those nested Eithers
02:25:09 <Ariakenom_> Wouldn't you want to end with () to get accessors right?
02:25:27 <davr0s_> i dont strictly need it but its nice to know how far things can go 
02:25:57 <cocreature> Ariakenom_: what do you mean by “get accessors right”?
02:26:16 <cocreature> Either Int Bool and Either Int (Either Bool ()) are not isomorphic
02:26:28 <cocreature> you could do Either Int (Either Bool Void) but why would you :)
02:26:43 <Ariakenom_> cocreature: To have get the third be the same for a 3 sum, 4 sum and 5 sum
02:27:17 <tdammers> so it'd actually be more like Either (Either Void Bool) Int
02:27:28 <tdammers> flip the args
02:27:41 <tdammers> because you want the leaves to be Rights
02:27:50 <davr0s_> i suppose another quetison to ask is..
02:27:54 <tdammers> Either (Either (Either (Either ... (Either Void
02:28:27 <tdammers> and thus type a \/ b = Either b a
02:28:38 <cocreature> Ariakenom_: I don’t think there a lot of value in matching on the nth constructor of some type. the order is often fairly arbitrary
02:28:47 <davr0s_> if a definition exists in a sum type, will the compiler be smart enough to figure out place where that can be represented as an individual component where possible (kind of like de-virtualization in OOP language implementations)
02:29:25 <Ariakenom_> cocreature: what has value then?
02:29:45 <Ariakenom_> honest question. don't you use it to match on it?
02:30:51 <tdammers> the problem is, though, that if you write "nth" accessors, you have to commit to some maximum n, like with tuples
02:31:01 <tdammers> probably better to make composable accessors
02:31:19 <cocreature> Ariakenom_: my point is that most of the time you want to perform an exhaustive match on all constructors. and if you really want to match on only one specific constructor (and get back a Maybe to handle failures) then identifying the constructor by name or maybe by the type of its elements is a better choice than its number
02:31:33 <merijn> davr0s_: I'm not sure I understand the question?
02:31:58 <ggole> If you are using open/polymorphic variants, usually you can't perform an exhaustive match because the set of constructors is open
02:32:07 <Ariakenom_> cocreature: I assume you can make nice patterns
02:32:14 <Ariakenom_> for "third"
02:32:23 <Ariakenom_> well I think
02:32:30 <ggole> Which is why they are fairly rarely used even in languages with direct support for them
02:32:43 <Ariakenom_> maybe you have to add a void pattern
02:33:26 <davr0s_> a sum type will be represetned in memory presumably as an index and a reference to a component,  but there might be cases where a code path only uses one component - would the index be ditched.     compare with OOP compilers which try and figure out where virtual functions (pointers from tables) can be converted into static function callls) (where suffieicnet call-graph information could be traced to deduce the actual
02:33:26 <davr0s_>  type at compile-time)
02:33:40 <cocreature> Ariakenom_: I’m not arguing that you can’t make “third” nice. I’m arguing that “third constructor” is not a good way to identify a constructor in most cases so there is not much point in making this nice
02:34:48 <merijn> davr0s_: Ah, no. Generally you avoid these sorts of inheritance style hierarchies
02:35:20 <tdammers> merijn: well, but statically resolving typeclasses is arguably a similar optimization
02:35:31 <merijn> tdammers: But not at all related to his initial question
02:36:08 <tdammers> merijn: right, yes. Then again, similar optimizations do happen wrt pattern match branches
02:36:47 <merijn> davr0s_: Generally in Haskell you tend to lean more to composition style solutions than inheritance
02:36:52 <tdammers> at the Core level, case Foo bar of { Foo bar -> baz } can be optimized down to just baz
02:37:11 <ggole> There are ML compilers (MLton) that do things that are similar to speculative devirtualisation
02:37:17 <tdammers> this is actually a rather crucial optimization in GHC
02:37:33 <ggole> I'm not aware of Haskell implementations which work that way, though
02:37:38 <merijn> davr0s_: So you'd have "data Shape a = Shape { size :: Int, colour :: Colour, rest :: a }" then you could have 'Shape Circle' and have all the Circle specifics in "rest"
02:37:46 <ggole> It's a whole program compiler trick, really
02:37:52 <merijn> tdammers: That doesn't work with the previous example of nesting Either 5+ times
02:38:07 <merijn> tdammers: You have to actually carry around the 5 either constructors at runtime
02:38:19 <merijn> tdammers: You can't magically compact them away. At least not reliably
02:39:15 <merijn> tdammers: So, getting back to the crux of his question "can I make a n-times nested Either and use it without overhead?" the answer is pretty much "no"
02:40:11 <tdammers> merijn: if you literally write something like case Left (Left (Left (Left (Left a)))) of { Left (Left (Left (Left (Left x)))) -> print x; _ -> putStrLn "Nope!" } then that will most certainly optimize down to just print a -- but it's a bit of a contrived example, and won't work when you pass those nested eithers around more dynamically
02:40:55 <merijn> tdammers: Yes, but that's not realistically going to happen in the proposed approach
02:41:01 <tdammers> no, of course not
02:41:38 <merijn> tdammers: So then what's the point of arguing "GHC can do something like that", when in reality it can't do anything like that in any remotely interesting real world case?
02:42:18 <quicksilver> well GHC can it when it inlines
02:42:29 <merijn> davr0s_: Incindentally, these sorts of optimisation are what Ryan Newton was talking about in the talk I linked yesterday
02:42:30 <quicksilver> and the GHC inliner certainly comes into play in interesting real world cases
02:42:39 <quicksilver> I'm not sure how you define 'any remotely interesting' ;)
02:43:10 <quicksilver> certainly if we reduce the argument to the absurd we'd say "since this is never interesting, turn the inliner off, it won't make a performance difference to real programs'
02:43:16 <tdammers> if you need to cater for multiple constructors at runtime, then there really isn't a way to do it without overhead - you can't have the information without having it
02:43:18 <quicksilver> and I have a hunch that is ot the case :)
02:43:33 <merijn> quicksilver: The example was given as a solution to the C++ approach of having "Circle", "Square", etc. inheriting from Shape and mixing those in a single container, and someone suggested using arbitrarily nested Either's as solution to that problem
02:44:15 <merijn> quicksilver: So, if we don't incest on pedantically throwing away the conversational context my remarks were made in, then it is clear that having mixed containers of shapes will not magically result in GHC optimising away the overhead of all the either wrapping/poitner chasing
02:44:29 <merijn> s/incest/insist <- too much Crusader Kings >.>
02:44:39 <tdammers> and I would argue that in those cases where C++ can statically resolve the vtables and turn them into static function calls, GHC with a sum type or nested either could also statically resolve things and apply the optimization I mentioned
02:44:43 <davr0s_> merijn (composition -yes i'm familiar with the drive for that which happens in OOP-land aswell where inheritance is increasingly disliked, and I've already been through Rust where they explicitely dont have inheritance;    there's data-oriented design in gamedev which can even go further down that route in the name of keeping the data use in particular passes together)
02:45:05 <davr0s_> merijn i guess i should stop worrying about this until i need it. I dont have a zillion shapes
02:46:08 <merijn> davr0s_: More relevantly, there's often other ways of dealing with things too. Up to and including the approach of "OO" Haskell where you simply use records as the API/interface you'd use in imperative/OO languages
02:46:20 <quicksilver> merijn: certainly not my intention to express my pedantry by throwing away context.
02:47:11 <quicksilver> certainly GHC is far from the mythical "sufficiently smart compiler" but on the other hand it is good enough to produce good performance from quite naive data modelling approaches in many real situations
02:47:12 <davr0s_> although conversely thats why i started wondering.. i have a bunch of geometry code where shapes exist in isolation (conveninence for individual functions), and then something built as a composition. Of course with "a few options" , manually rolling a "Shape =  S_Cuboid Cuboid  | S_Cylinder Cylinder.."  is sort of ok
02:47:28 <quicksilver> and when the perofrmance is poor then you naturally think about it and make something better
02:48:21 <merijn> quicksilver: I just get annoyed with the occasional tendency of #haskell to turn off-hand "factually slightly incorrect, but pedagogically justified" remarks into "Well, actually!" discussions that are just intimidating to beginners/people who *aren't* familiar with GHCs implementation details :\
02:49:01 <quicksilver> that's fair
02:49:07 <quicksilver> there is plentty to be annoyed about here
02:49:14 <quicksilver> and I'm definitely part of that :)
02:49:46 <bwe> data Pair a = Pair a a -- why does Pair have kind * -> * and (,) * -> * -> * ?
02:49:59 <merijn> bwe: Because it only takes one type argument
02:50:02 <phadej> data Pair a b = Pair a b
02:50:09 <phadej> more like (,) -- ^
02:50:36 <merijn> bwe: Note that you have two "Pair" there, "Pair" the type constructor (taking one argument and having kind  "* -> *") and "Pair" the value constructor (taking two arguments of some type 'a')
02:50:39 <bwe> phadej: Got it ;).
02:51:01 <bwe> merijn: the value constructor is on the right side, correct?
02:51:05 <merijn> bwe: Yes
02:52:05 <merijn> bwe: Alternative (non-standard Haskell) way of writing that datatype would be "data Pair a where { Pair :: a -> a -> Pair a }"
02:52:37 <merijn> We should add GADTSyntax extension to Haskell Prime, I think it's far more beginner friendly when it comes to distinguishing value vs type constructor
02:52:56 <berndl> I second this ^
02:53:05 <bwe> merijn: Actually for me it seems just the reverse (right now).
02:54:48 <piyush-kurur> any one know how to use valgrind + haskell
02:57:18 <cocreature> piyush-kurur: I’ve used valgrind on Haskell executables that do FFI in the past and didn’t need to do anything special
02:57:19 <bennofs> what do you want to use valgrind for? 
03:13:42 <Wizek> Hello! Anyone has some experience with how Debug.Trace and ST interplays? I'm running into some strange issue over here: https://gist.github.com/Wizek/5f3cb2db3348173d58c5fe5354556e53
03:14:12 <Wizek> this is printing: 0, 1, 2, 3, 2, 3, 2, 3... I.e. 2 and 3 repeating
03:14:31 <Wizek> whilst I would expect it to repeat 1,2,3 indefinitely
03:15:44 <Wizek> also, `noop = pure ()`
03:16:21 <lavalike> Wizek: have you tried at different optimization levels? like -O0?
03:16:42 <Wizek> lavalike: I was trying this in GHCi, where only o0 is available, right?
03:16:50 <lavalike> Wizek: I don't know!
03:25:30 --- mode: glguy set +v nxt
03:30:17 <Wizek> I found something!
03:30:44 <Wizek> Seems to be the difference between ```fix f = f (fix f)```   ```fix f = let x = f x in x```
03:30:55 <Wizek> strange. Anyone any ideas?
03:33:49 <[exa]> Wizek: you're introducing a bit more polymorphism in the second case
03:34:23 <[exa]> Wizek: also the other is not a fixpoint
03:35:11 <[exa]> oh it is, my bad
03:37:56 <vasiliy_san> [exa]: could you please elaborate what is the difference? Both functions have the same type `(t -> t) -> t` ?
03:38:15 <Wizek> yup, I'm wondering about the same too
03:38:47 <vasiliy_san> [exa]: and equation reasoning converts the second definition into the first one using substitution
03:41:54 <Wizek> new reproducible example, even smaller: https://gist.github.com/b3c43e4e85b7b9d89cbb13e736abf304
03:42:10 <Wizek> now the issue persists even in IO
03:42:15 <Wizek> even without fix
03:42:31 <lavalike> fortunately in IO you can sequence your prints directly ;)
03:42:33 <Wizek> prints 1,2,3, 2,3, 2,3...
03:42:53 <Wizek> lavalike: look at my IO example above
03:43:06 <lavalike> Wizek: I mean with putStr!
03:43:09 <merijn> vasiliy_san: The difference is sharing
03:43:22 <lavalike> Wizek: here's another idea, what about hSetBuffering? does it change behavior?
03:43:58 <merijn> vasiliy_san: The second fix (with let) only computes the application of 'f' once. Whereas the first one (re)computes the application at every recursive step
03:44:04 <Wizek> lavalike: sure, but from how I understand `() <- trace ".." noop` to work, this is unexpected behavior surely, not?
03:44:57 <lavalike> Wizek: I am not sure people would put anything recarding `trace` under the umbrella of "expected"
03:45:35 <Wizek> Or asking another way: Is there any other way that I can get reliable tracing?
03:45:57 <Wizek> lavalike: I am most definitely expecting to be able to trace reliably somehow.
03:46:55 <Wizek> lavalike: are you suggesting perhaps for me to use IO instead of ST, putStr instead of trace, and slap it in an unsafePerformIO just to get reliable tracing?
03:47:21 <merijn> Wizek: As soon as you slap unsafePerformIO in, all reliability goed out the window again :p
03:47:46 <merijn> You're using trace? Have you tried using traceM?
03:47:56 <Wizek> merijn: yes, same issue
03:48:10 <lavalike> Wizek: what if you trace with "...\n" and hSetBuffering LineBuffering
03:48:43 <Wizek> checking
03:51:12 <Wizek> lavalike: same issue
03:58:19 <merijn> trace already flushes it's writes
03:58:39 <merijn> Wizek: You need to make the trace thunks depend on an input that varies every application
03:59:01 <Wizek> merijn: how could I do that?
03:59:02 <merijn> trace only prints the first time it gets evaluated
04:00:21 <merijn> By...passing it in arguments to whatever function has the trace inside it?
04:01:53 <Wizek> merijn: I am not quite following what you mean. How could I change this? https://gist.github.com/b3c43e4e85b7b9d89cbb13e736abf304 You mean perhaps that noop needs to be something else?
04:03:08 <Wizek> Also, it is very strange for me that 2,3 gets printed indefinitely. Following what you are saying merijn, shouldn't it print 1,2,3 then silence?
04:03:21 <merijn> Wizek: Here? You can't. If 'foo' had an argument you could pass that argument into the trace to reevaluate it
04:03:40 <merijn> Wizek: trace uses unsafePerformIO, there are no guarantees on consistent behaviour
04:04:06 <merijn> Wizek: unsafePerformIO = "I'm ok with this being executed 0, 1, or more times"
04:04:11 <lavalike> expect the unexpected
04:04:25 <merijn> GHC makes absolutely zero promises and guarantees about unsafePerformIO and (by extension) trace
04:04:49 <merijn> Wizek: It also doesn't even guarantee to produce consistent behaviour across multiple runs or even within the same run
04:04:49 <Wizek> Sure, but then is a reliable trace impossible in haskell?
04:05:17 <Wizek> That would be a pretty big admission of defeat for a language.
04:05:22 <merijn> Wizek: You can do reliable traces, but they require more work than just simply this and maybe you will have to change a bunch of code
04:05:41 <merijn> Wizek: You just can't do reliable traces *like this*
04:06:00 <merijn> But it's impossible to say what you *should* do without knowing what you're actually trying to do
04:07:07 <merijn> I suspect traceStack might work reliably IFF combined with a profiling build
04:07:52 <merijn> But I dunno enough of the details of the HasCallStack stuff
04:09:18 <cocreature> traceStack uses the profiling stacks not HasCallStack
04:10:23 <merijn> cocreature: I dunno the details of those either
04:12:04 <Wizek> merijn: I guess I can try that as a kind of last resort.
04:15:51 <Wizek> tried traceStack, not sure if compiled well though, same issue.
04:16:10 <Wizek> merijn: so what other way do you have in mind?
04:55:14 <Ariakenom_> Can i manage to use a {-# COMPLETE A, AEnd #-} pragma in ghci?
04:56:12 <merijn> Wizek: With cabal it should just be a matter of "--enable-profiling" when compiling
04:56:21 <merijn> Ariakenom_: Define "manage to use"?
04:57:03 <Ariakenom_> can I :set it?
04:59:15 <bwe> for which reason does pure return an effect free context? -- typeclassopedia 4.1
04:59:48 <merijn> bwe: What do you mean "for which reason"?
05:00:23 <bwe> merijn: When do I want to use   pure?
05:00:42 <bwe> merijn: Which problem does it solve?
05:01:44 <merijn> :t (<*>)
05:01:46 <lambdabot> Applicative f => f (a -> b) -> f a -> f b
05:02:04 <merijn> bwe: So, <*> let's us combine a function inside some "f" with values inside some "f"
05:02:22 <merijn> bwe: But what if I don't *have* an 'f a'? What if I just have 'a'?
05:03:12 <bwe> :t pure
05:03:14 <lambdabot> Applicative f => a -> f a
05:03:48 <merijn> bwe: Now, in this specific case you could actually abuse fmap to do the same, but as soon as you have multiple argument functions, that quickly stops working
05:04:20 <bwe> Is that the abstraction setting Application apart from fmap?
05:04:22 <merijn> bwe: You can think of <*> as "allowing you to fmap a multiple argument function" across some 'f', but sometimes you want to pass that function arguments that are not inside 'f'
05:04:30 <bwe> s/Application/Applicative
05:04:48 <merijn> bwe: Yes, the distinction between Appicative and Functor is that Applicative gives you useful ways of dealing with multi argument functions
05:06:12 <bwe> merijn: Is the following correct? pure does not have an f as an argument yet returns one. Since it is called within an Applicative f, it derives it from that context.
05:07:03 <merijn> bwe: I'm not sure I understand that description, so I can't say :)
05:07:20 <bwe> :t pure
05:07:22 <lambdabot> Applicative f => a -> f a
05:07:38 <bwe> -- there's no f as an argument to the function pure, right?
05:07:39 <merijn> bwe: Important to note here is that Haskell's type inference is bidirectional, so GHC can infer which 'f' you mean (and thus, which version of 'pure' to call) from how you use it
05:07:43 <nshepperd> bwe: the type f is inferred from the context it is used in, yes
05:08:04 <bwe> nshepperd: Thanks, that's what I wanted to learn.
05:08:18 <nshepperd> :t pure :: a -> Maybe a
05:08:20 <lambdabot> a -> Maybe a
05:08:20 <merijn> bwe: So if I do "pure 5 :: [Int]" then GHC infers that 'f = []' and then looks up the Applicative instance for '[]' and calls the corresponding 'pure' implementation
05:08:44 <bwe> merijn: That's kinda clever.
05:10:30 <merijn> bwe: It is!
05:10:34 <merijn> > pure 5 :: Maybe Int
05:10:37 <lambdabot>  Just 5
05:10:42 <merijn> > pure 5 :: [Int]
05:10:46 <lambdabot>  [5]
05:10:56 <merijn> bwe: This is also how things like "maxBound" can work
05:10:58 <merijn> :t maxBound
05:11:00 <lambdabot> Bounded a => a
05:11:22 <merijn> bwe: GHC infers what type you want from how you use it, then looks up the corresponding implementation and value
05:11:27 <merijn> > maxBound :: Int
05:11:29 <lambdabot>  9223372036854775807
05:11:31 <merijn> > maxBound :: Bool
05:11:34 <lambdabot>  True
05:15:17 <bwe> > pure 5 :: [Maybe Int]
05:15:19 <lambdabot>  error:
05:15:19 <lambdabot>      • No instance for (Num (Maybe Int)) arising from the literal ‘5’
05:15:19 <lambdabot>      • In the first argument of ‘pure’, namely ‘5’
05:17:35 <marvin2> > pure (pure 5) :: [Maybe Int]
05:17:37 <lambdabot>  [Just 5]
05:18:45 <merijn> bwe: It infers 'f a' compared to "[] (Maybe Int)", but that doesn't match (hence the error), as there's only one 'f' variable
05:19:01 <merijn> bwe: (Rather it goes one step further as we use the same trick for numeric literals!)
05:19:04 <merijn> :t 5
05:19:06 <lambdabot> Num p => p
05:19:27 --- mode: glguy set +v jakuma
05:19:47 <merijn> bwe: GHC works the same way for literals, using the Num typeclass to infer what type you want (which means you can have user-defined numeric literals in your code!), but then gets stuck, because "Maybe Int" is not an instance of Num
05:20:31 <merijn> @define newtype MyNumType = NumType Int deriving (Num, Show, Eq, Ord) --hope GeneralizedNewtypeDeriving is on
05:20:32 <lambdabot>  .L.hs:164:29: error:
05:20:33 <lambdabot>      • Can't make a derived instance of ‘Num MyNumType’:
05:20:33 <lambdabot>          ‘Num’ is not a stock derivable class (Eq, Show, etc.)
05:20:36 <merijn> aww...
05:20:41 <merijn> @undefine
05:20:41 <lambdabot> Undefined.
05:20:56 <merijn> @define newtype MyNumType = NumType Int deriving (Show, Eq, Ord)
05:20:57 <lambdabot>  Defined.
05:21:17 <merijn> @define instance Num MyNumType where fromInteger = NumType . fromIntegral
05:21:18 <lambdabot>  .L.hs:161:10: warning: [-Wmissing-methods]
05:21:18 <lambdabot>      • No explicit implementation for
05:21:18 <lambdabot>          ‘+’, ‘*’, ‘abs’, ‘signum’, and (either ‘negate’ or ‘-’)
05:21:27 <merijn> > 5 :: MyNumType
05:21:30 <lambdabot>  error:
05:21:30 <lambdabot>      • No instance for (Num MyNumType) arising from the literal ‘5’
05:21:30 <lambdabot>      • In the expression: 5 :: MyNumType
05:22:11 <merijn> @define instance Num MyNumType where { fromInteger = NumType . fromIntegral; (+) = undefined; (*) = undefined; abs = undefined; signum = undefined; negate = undefined }
05:22:12 <lambdabot>  Defined.
05:22:15 <merijn> > 5 :: MyNumType
05:22:17 <lambdabot>  NumType 5
05:22:32 <merijn> @undefine
05:22:32 <lambdabot> Undefined.
05:37:30 --- mode: glguy set +v f-a
05:37:45 <f-a> is there a way to put "--allow-newer" in a .cabal file?
05:38:24 <merijn> f-a: No, and that'd be a terrible idea, but let me put on my clippy hat: "Did you mean "should I switch to new-build and use cabal.project?"?"
05:38:43 <merijn> To which the answer is: Yes
05:38:51 <cocreature> merijn as an editor plugin
05:39:03 <merijn> In fact, that'd allow you to specify --allow-newer on a per-package/dependency basis!
05:39:19 <merijn> Merijn-as-a-Service
05:40:34 <f-a> thanks merijn. I already use new-build, I see how it (--allow-newer in options) can be a problem if a package is then released on hackage
05:41:14 <merijn> f-a: You can specify override in cabal.project, then
05:41:19 <merijn> and/or cabal.project.local
05:41:41 <merijn> f-a: https://github.com/merijn/GPU-benchmarks/blob/master/cabal.project#L15
05:42:03 <merijn> f-a: https://cabal.readthedocs.io/en/latest/nix-local-build-overview.html should have detail on what you can do and how
05:42:09 <f-a> oh, allow newer in project. Very nice, thanks
05:43:05 <merijn> f-a: cabal.project.local works as an auto-included override for cabal.project (so cabal.project should be the default, stored in version control setup) and .local should have dev specific overrides for your current machine/checkout
05:53:03 <f-a> that will do, many thanks merijn
06:31:07 <Ariakenom_> Anyone know if I can use this pragma to do basically {-# COMPLETE Left :: Either a Void #-}?
06:35:51 <merijn> Ariakenom_: Complete only affects typeclasses, afaik?
06:36:40 <Ariakenom_> merijn: complete is for exhastive patterns if I'm not terribly lost
06:39:43 <merijn> Ah, wait, I'm thinking of {-# MINIMAL
06:39:57 <merijn> Ignore me, carry on.
06:43:28 <Ariakenom_> ghc lets Void patterns be empty but doesn't allow omitting Left in Either Void Int
06:46:24 <merijn> Ariakenom_: That's because GHC can't prove that Void can't happen
06:46:35 <dmwit> Ariakenom_: Huh. I find the documentation of COMPLETE a bit puzzling.
06:46:40 <Ariakenom_> dmwit: same
06:47:17 <dmwit> Ariakenom_: In particular, it says "when all the pattern synonyms in a group are polymorphic in the constructor the user must provide a type signature" and then gives an example with a signature that is... not a type signatuer.
06:47:45 <dmwit> I *guess* what it means is that you can only specify the outermost type constructor.
06:47:51 <dmwit> But it is not super precise about that.
06:48:12 <dmwit> In the meantime, the (unfortunately verbose) workaround is to include `Left x -> case x of`.
06:49:42 <Ariakenom_> merijn: That's true for both of my cases though.
06:51:03 <dmwit> {-# COMPLETE Right :: Either Void #-} is not accepted, which I suspect is a pretty canonical answer of "no" to your original question.
06:52:08 <dmwit> I also tried `type Foo = Either Void; {-# COMPLETE Right :: Foo #-}` which gave a much more amusing error message. =)
06:52:56 <delYsid> Is there a SeqT / if not, why?
06:53:23 <ggole> Can't you 'usefully' pattern match on, eg, Left undefined by ignoring the argument?
06:53:45 <lyxia> delYsid: is that not ListT
06:53:47 <ggole> So I don't see why it would let you ignore the Left case, since it can actually happen.
06:53:52 <merijn> ggole: Yes, but what do you do on the right hand of a case that can't happen?
06:53:56 <dmwit> Ariakenom_: `data MyEither a b = MyLeft a | MyRight b; type Foo = MyEither Void; {-# COMPLETE MyRight :: Foo #-}` gives an even weirder error message.
06:54:09 <merijn> ggole: Well, the point of "Void" is that it can only happen if you already have a bottom
06:54:38 <Ariakenom_> dmwit: lol which?
06:54:56 <dmwit> Ariakenom_: "Couldn't match expected type `Foo' with `MyEither'"
06:55:14 <Ariakenom_> ggole: I can "morally" ignore it and not issue warnings?
06:55:31 <dmwit> ggole: COMPLETE always lets you declare incorrect things anyway.
06:55:45 <ggole> I admit, I'm not really familiar with COMPLETE
06:55:46 <dmwit> ggole: `{-# COMPLETE Right #-}` is accepted just fine, even though it's a blatant lie.
06:56:04 <delYsid> lyxia: maybe.  But ListT always uses lists as underlying data type, no?
06:56:06 <dmwit> (well, COMPLETE MyRight, anyway)
06:56:12 <Ariakenom_> dmwit: yes but I want it to check that it's void
06:56:24 <dmwit> Ariakenom_: I know.
06:56:32 <dmwit> Ariakenom_: That's why I told this to ggole, not you. =)
06:56:36 <delYsid> I guess I am wondering about m (Seq a) performance vs. m [a]
06:56:55 <ggole> As to what you can put on the RHS of impossible cases, you can have a construct that indicates to the type checker "please check that this is impossible"
06:56:56 <Ariakenom_> that does make sense :p
06:57:06 <dmwit> delYsid: But the correct definition of ListT m a does not use m [a]...
06:57:15 <ggole> I'm not sure whether Haskell has that
06:57:22 <Ariakenom_> :t absurd
06:57:23 <lambdabot> Void -> a
06:57:44 <delYsid> dmwit: what *is* the *correct* definition of ListT? I guess not that from mtl?
06:57:47 <dmwit> :t join either id . lmap absurd
06:57:47 <ggole> It gets hard with GADTs though
06:57:48 <lambdabot> error:
06:57:48 <lambdabot>     • No instance for (Profunctor Either) arising from a use of ‘lmap’
06:57:48 <lambdabot>     • In the second argument of ‘(.)’, namely ‘lmap absurd’
06:57:52 <Athas> Does anyone have experience packaging Haskell programs for Debian?  It looks like every Haskell package dependency must also be a Debian package.  Is that process (semi-)automatic?
06:57:55 <dmwit> :t join either id . first absurd
06:57:56 <lambdabot> error:
06:57:57 <lambdabot>     • Couldn't match type ‘(c0, d)’ with ‘Either a a’
06:57:57 <lambdabot>       Expected type: (Void, d) -> Either a a
06:57:58 <Athas> I.e. is all/most of Hackage in Debian?
06:58:19 <dmwit> :t join either id . Data.Bifunctor.first absurd
06:58:20 <lambdabot> Either Void a -> a
06:58:33 <dmwit> Ariakenom_: Perhaps it's worth defining that somewhere and using it.
06:58:47 <dmwit> :t either absurd id -- what am I thinking
06:58:48 <lambdabot> Either Void c -> c
06:59:11 <Ariakenom_> thinking categorically
06:59:27 <dmwit> delYsid: http://hackage.haskell.org/package/ListT-0.1.2.0/docs/Control-Monad-Trans-List.html
07:00:22 <dmwit> delYsid: Yes, the mtl definition is bad. ListT m is not a monad for most useful monads m.
07:01:58 <dmwit> (*ahem*, specifically mtl's ListT has that property. The ListT package's ListT lifts all monads to monads.)
07:03:14 <Ariakenom_> > case Right 1 of (either absurd id -> x) -> x -- so for this case I can viewpattern dmwit 
07:03:15 <lambdabot>  1
07:03:46 <dmwit> > case either absurd id (Right 1) of x -> x
07:03:48 <lambdabot>  1
07:04:05 <dmwit> > let x = either absurd id (Right 1) in x -- so many choices
07:04:07 <lambdabot>  1
07:04:29 <dmwit> Ariakenom_: Ah! I have a cunning plan.
07:05:55 <dmwit> Ariakenom_: `pattern OnlyRight x <- (either absurd id -> x); {-# COMPLETE OnlyRight #-}`
07:06:42 <dmwit> Maybe that's what you were suggesting with your lambdabot query and I was just too slow to understand, in which case, sorry. =P
07:07:53 <Ariakenom_> dmwit: nono that's nice
07:08:01 <dmwit> You can add `where OnlyRight=Right` to the end of the pattern if you want it to be bidirectional.
07:08:49 <delYsid> dmwit: thanks.
07:09:37 <Ariakenom_> dmwit: now the thing is ...
07:09:39 <dmwit> Ariakenom_: Thanks for leading me down this path. It's a nice trick that I think may come in handy in other situations, too, so I'll have to remember it.
07:10:10 <Ariakenom_> same. good discussion
07:10:44 --- mode: glguy set +v kitchent_
07:10:50 <greymalkin> Is there a strict array or vector type?
07:10:56 <Ariakenom_> I was actually trying to get completeness for anonymous sums of the form Either (Either Void b) a
07:11:12 <merijn> greymalkin: Unboxed and Storable vectors are (necessarily) strict
07:11:17 <dmwit> greymalkin: The unboxed variants are necessarily strict. I think there are also strict boxed variants if that's important.
07:11:39 <merijn> dmwit: Jinx!
07:11:48 <dmwit> I'll buy you a coke next time we meet!
07:12:46 <Ariakenom_> where I the constructors are polymorphic in the tail (Either tail head)
07:12:49 <dmwit> Ariakenom_: That's okay. It's `Left (OnlyRight b)` and `Right a`, no?
07:13:12 <Ariakenom_> where the patterns are polymorphic in the tail (Either tail head)
07:14:08 <Ariakenom_> dmwit: that doesn't work for a polymorphic tail no?
07:14:09 <dmwit> greymalkin: Seems there are not boxed strict variants after all.
07:14:14 <dmwit> Ariakenom_: Why not?
07:14:29 <dmwit> Ariakenom_: Or: what is a polymorphic tail?
07:14:55 <Ariakenom_> as in A is Right; B is Left, Right ; C is Left, Left, Right
07:15:14 <Ariakenom_> and the sum always ends in Void, which indicates the end
07:16:10 <dmwit> You need to know statically how deep to look for the Void. Then you can also know statically how deep to put your OnlyRight.
07:16:35 <Ariakenom_> dmwit: Right, but I wanted to add COMPLETE pragmas to get exhaustiveness
07:16:49 <dmwit> Perhaps you can cook up an MCVE...
07:17:01 <dmwit> You should only need a COMPLETE pragma for the very last layer.
07:17:48 <dmwit> What I mean by that is, I don't yet understand why OnlyRight as described above doesn't meet your needs.
07:18:22 <dmwit> (Or OnlyLeft if that's your preferred side. Doesn't matter to me.)
07:19:08 <greymalkin> dmwit: It's the boxed variant I need, but having `Storable` instances feels like significant overkill.
07:19:28 <Ariakenom_> I wanted "case _ of {A _ -> _; B _ -> _}" to work on sums of any length >2 but give exhaustiveness warnings on not 2
07:21:11 <merijn> greymalkin: It's pretty fast
07:21:44 <greymalkin> not Foldable, either :(
07:21:51 <merijn> greymalkin: I ported (read-only, somewhat random access) algorithm from C to Storable Vector and it's pretty fast
07:22:39 <merijn> greymalkin: About 40% slower than the C version (which, to be fair, averaged like 120 nanoseconds per prediction), but it's faster in combination with the surrounding Haskell due to better optimisation at the usage site
07:23:41 <merijn> greymalkin: What's your data look like?
07:23:48 <Ariakenom_> merijn: In particular I had in mind, for the interface, only a an infix type constructor and the value pattern-constructors (A,B,C,D,...)
07:24:17 <merijn> greymalkin: Also, if you can make a Storable instance, how come you can't use unboxed arrays? :p
07:24:34 <Ariakenom_> Which works. But I can't get it to do exhaustiveness
07:25:21 <greymalkin> merijn: I need a couple of these, but one should be a `Vector (Map Fixed Fixed)` at minimum.
07:25:58 <greymalkin> As for boxed vs unboxed, I haven't groked the distinction yet; so unboxed is currently somewhat frightening.
07:26:03 <merijn> greymalkin: hmm, yeah, I don't think you could make a Storable instance for Map anyway :p
07:27:14 <merijn> greymalkin: Boxed vs unboxed is pretty simple. If we have parametric polymorphism (aka generics), we have two options 1) we compile separate code for each possible input (this is a hassle and bloats executables) or 2) we enforce that all data must have the same size
07:27:38 <merijn> greymalkin: The simplest way to ensure all data has the same size? Replace it with a pointer to the actual data, so it's pointers everywhere!
07:27:39 <dmwit> Ariakenom_: Okay. I think that's hard, not least because it may not be known statically whether that's exhaustive or not.
07:28:03 <merijn> greymalkin: This process is called "boxing" (by stuffing everything in a box, you make sure everything has uniform shape)
07:28:06 <Ariakenom_> dmwit: yes. true.
07:28:22 <merijn> greymalkin: So "Int" isn't a machine integer, it is a pointer to a machine integer
07:28:22 <dmwit> Ariakenom_: You can probably make it work, with great effort, using the standard singleton-style dependent typing emulation, but it seems unlikely to be worth it.
07:28:35 <greymalkin> So anything that can't be represented in the same size as a pointer is boxed...?
07:29:09 <Ariakenom_> greymalkin: No. Everything is boxed. :p
07:29:11 <merijn> greymalkin: Which, obviously, is a bit slow, because you're chasing through pointers. So sometimes you want to write unboxed code, avoiding this overhead, but now you can't do polymorphism anymore
07:29:19 <merijn> greymalkin: In Haskell, normally everything is boxed
07:29:38 <benzrf> whenever i think about the sheer lack of polymorphism in C i get antsy
07:29:49 <dmwit> greymalkin: "unboxed" does not refer to a size, it refers to a bare representation or a pointer to a representation.
07:30:10 <benzrf> dmwit: wait, do you mean "vs", not "or"
07:30:12 <dmwit> greymalkin: bare representation (of any fixed size) is unboxed. Pointer to representation is boxed.
07:30:12 <merijn> greymalkin: For example "data Int = I# Int#" where Int# is an actualy machine int"
07:30:15 <benzrf> ah
07:30:22 <dmwit> benzrf: Yes, I did mean that, thank you for the clarification.
07:30:24 <greymalkin> right, but the purpose of boxing is to homogenize the sizes for polymorphism.
07:30:39 <benzrf> well, that's one purpose
07:30:50 <benzrf> it also homogenizes for other reasons too
07:31:05 <dmwit> greymalkin: Anyway I suspect there isn't going to be a sensible way to unbox a Map.
07:31:06 <merijn> greymalkin: Well, in a lazy language there are other benefits, because you can piggyback the homogenization between "thunk to be evaluated" and "evaluated value" too
07:31:42 <dmwit> greymalkin: But you can try pulling the same trick `Map` does to get a strict vs lazy implementation: just write some wrappers around the vector operations you want to do that force things at the appropriate moment.
07:31:43 <merijn> greymalkin: So now most code doesn't have to care whether something is evaluated yet or not!
07:32:10 <Ariakenom_> % let x = undefined :: Void# in () -- tricksy
07:32:10 <yahb> Ariakenom_: *** Exception: Prelude.undefined; CallStack (from HasCallStack):; error, called at libraries/base/GHC/Err.hs:78:14 in base:GHC.Err; undefined, called at <interactive>:33:9 in interactive:Ghci12
07:32:33 <Ariakenom_> strict evaluation
07:32:40 <benzrf> heresy!
07:32:46 <tdammers> .oO( strict and lazy data types are a lie, there are only strict and lazy operations )
07:33:01 <merijn> greymalkin: So unboxed vectors are just vectors which rely on/use the underlying unboxed representation. But the means your data needs to have a sensible unboxed (i.e. fixed size) representation, which Map does not
07:33:17 <dmwit> Ariakenom_: Yep. It was quite a shock when I first learned about that one, and I had fun just a day or two ago disabusing somebody on SO of the notion that you can't write infinite loops of unboxed type.
07:34:14 <merijn> greymalkin: See also the GHC.Prim module docs for a huge collection of dark arts and other fun :p
07:34:28 <dmwit> % let f :: Void# -> Void#; f x = f x; x :: Void#; x = f void# in ()
07:34:34 <yahb> dmwit: [Timed out]
07:46:38 <Taneb> Is it possible to express a value of a type with non-finite rank (in the RankNTypes sense) in Haskell?
07:48:42 <lyxia> newtype F a = F (forall x. F x -> Int) -- how's that
07:48:59 <benzrf> D:
07:50:42 <quicksilver> I think you want to mention 'a' inside
07:50:54 <quicksilver> otherwise the quantifiers aren't really doing meuch
07:51:12 <quicksilver> and they probably commute or collapes or something
08:01:32 <davr0s> is there a uility type to compose Functors, Foldables etc  eg gluing a maybe to a single item to make something thats  got capacity 1 or 2, that sort of thing   
08:02:12 <davr0s> the specific use case is i've made some fixed length 1,2,3,4 element vectors but before i do 8,16,32..   thought i'd make something to do that, then of course i could go back and say '1, 2 element',then '3=2+1', etc.
08:02:33 <davr0s> i suspect 1,2,3,4 are still handy for easy destructuring
08:02:43 <davr0s> but for higher counts i can compose
08:05:40 <lyxia> Taneb: there might be a kind of PHOAS like that.
08:07:18 <lyxia> davr0s: Data.Functor.Product ?
08:07:31 <davr0s> awesome let's see
08:07:41 <davr0s> i figured it must be a cmomon idea
08:12:20 --- mode: glguy set +v Jante
08:12:39 <Boomerang> % :set -fprint-explicit-foralls
08:12:39 <yahb> Boomerang: 
08:12:48 <Boomerang> % f :: forall a b . b -> a; f = undefined
08:12:48 <yahb> Boomerang: 
08:13:00 <Boomerang> % :t f
08:13:00 <yahb> Boomerang: forall {b} {a}. b -> a
08:13:14 <Boomerang> Why not "a b"?
08:13:33 <cocreature> :t f @Int
08:13:34 <lambdabot> error:
08:13:35 <lambdabot>     Pattern syntax in expression context: f@Int
08:13:35 <lambdabot>     Did you mean to enable TypeApplications?
08:13:38 <Jante> A description about Reflex Bahviours: https://reflex-frp.readthedocs.io/en/latest/overview.html#reflex-basics   – it sounds a bit like ordinary variables, as in C or Java no?
08:13:40 <Boomerang> What's the point of "-fprint-explicit-foralls" if it doesn't follow my explicit foralls? :p
08:13:46 <cocreature> % :t f @Int
08:13:46 <yahb> cocreature: forall {b}. b -> Int
08:13:52 <cocreature> huh
08:13:55 <cocreature> that’s stupid
08:14:51 --- mode: glguy set +v Jante
08:18:13 <cocreature> Boomerang: surprisingly I can’t even find a bug in trac for it
08:19:14 <cocreature> Jante: not quite, the changes are not necessarily discrete. e.g. you can have some (more or less) continous input, e.g., the current time and calculate the output of your behavior based on that
08:19:50 <Boomerang> cocreature: Where is the best place for me to report this? :)
08:20:09 <cocreature> Boomerang: ghc trac?
08:20:39 <cocreature> fwiw I also tested 8.6.1 so it’s not fixed there either
08:20:55 <Boomerang> Ah cool, I was about to try that :+1:
08:22:47 <Boomerang> cocreature++
08:23:00 <dmwit> % :t +v f
08:23:00 <yahb> dmwit: forall a b. b -> a
08:23:16 <dmwit> not a bug
08:23:31 <dmwit> It's a bad interface, but not a buggy one.
08:24:16 <cocreature> at the very least it’s a documentation bug since this is not mentioned in the user guide for fprint-explicit-foralls
08:24:19 <Taneb> dmwit: it's still a bug in -fprint-explicit-foralls
08:24:24 <Boomerang> I didn't know about +v that's exactly what I need! Thanks! :D
08:24:36 <dmwit> cocreature: It's documented in the user guide for :type +v =)
08:25:12 <cocreature> dmwit: why would you want -fprint-explicit-foralls to not respect the order given by explicit quantifiers? that just seems like a bad idea
08:25:39 <dmwit> It is :t that does not respect the order, not -fprint-explicit-foralls.
08:26:00 <dmwit> And you want that because it frequently simplifies the type a lot.
08:26:59 <cocreature> ah I guess “The type reported is the type that would be inferred for a variable assigned to the expression, but without the monomorphism restriction applied.” makes things clear
08:27:14 <cocreature> but there definitely should be a big warning in the docs of -fprint-explicit-foralls
08:27:22 <dmwit> I can get behind that.
08:28:29 <dmwit> It bit me on my first use of -fprint-explicit-foralls, too, or I wouldn't have been able to point you at :t +v =P
08:28:53 <cocreature> hm, the simplifications mostly come into play if you use :t on compound expressions right?
08:29:04 <dmwit> I guess so, yeah.
08:29:18 <dmwit> It would be *possible* for them to come into play on single identifiers, too, though.
08:29:22 <dmwit> Just... very unusual.
08:29:33 <cocreature> right but in that case I don’t think users expect types to be simplified
08:29:51 <dmwit> I suspect you're right.
08:29:58 <cocreature> so I wonder if changing :type to show the original type for single identifiers might be a good idea
08:30:32 <cocreature> that would still give you simplifications when you might want them while not confusing people for the common case of passing in a single identifier
08:31:13 <lyxia> yes that would be great
08:31:27 <dmwit> Definitely seems like the right UI. Would be annoying for tools that interface with ghci, though I suspect most of those would prefer the API to the CLI anyway.
08:32:43 <Boomerang> Oh, do I need `+v` as well as `-fprint-explicit-foralls`?
08:32:43 <cocreature> you could still have some flag for :type that always simplifies
08:32:48 <cocreature> that tools can then use
08:32:55 <dmwit> Boomerang: Yes, two great tastes that taste great together.
08:33:38 <Boomerang> Is there nothing that does both at once? `:t +ve` or something?
08:33:45 <dmwit> Very unfortunate, isn't it?
08:46:25 --- mode: glguy set +v hertbert
08:46:44 <hertbert> lol
08:46:57 <hertbert> any one else hear yet
08:48:24 <cocreature> yep, I’ve heard that GHC 8.6 has been released
08:48:35 <hertbert> what's GHC
08:49:00 <hertbert> lol
08:49:08 <cocreature> the main Haskell compiler
08:49:14 <yushyin> 'The Glorious Glasgow Haskell Compilation System'
08:49:27 <cocreature> although if you didn’t know that you might be in the  wrong channel as this channel is about the Haskell programming language :)
08:50:29 <hertbert> lol it's done family
08:52:07 <hertbert> oh thanks for the info though 
08:52:10 <hertbert> tho
08:53:17 <blackandblue> for arch you install static package right?
08:53:21 <blackandblue> or just  ghc package
08:53:47 <blackandblue> arch linux 
08:54:17 <dukedave> Does anyone know how to get the individual values out of a Linear.V2 (from linear), via a function (i.e. not `V2 x y`) ?
08:54:19 <hodapp> GHC Haskell Compiler?
08:54:21 * hodapp hides
08:54:41 <cocreature> blackandblue: I would recommend that you install the ghc-static package (and its dependencies) and nothing else
08:55:37 <blackandblue> cocreature, I see. not the "ghc" or "ghc-libs" package?
08:56:24 <cocreature> blackandblue: ghc-static depends on those
08:56:33 <cocreature> so they are included in the “and its dependencies” part :)
08:57:41 <hertbert> lol
08:59:27 <Wizek> Btw, I've made a bit of progress with my gist above (https://gist.github.com/Wizek/b3c43e4e85b7b9d89cbb13e736abf304). It turns out that -O0 exhibits the unexpected behavior while -O1 doesn't. So I am starting to think this is a GHC bug.
09:00:15 <blackandblue> cocreature, I see. lol
09:00:21 <blackandblue> thanks cocreature for clarifying that
09:00:30 <cocreature> Wizek: I don’t think optimizations affecting sharing can be called a bug
09:00:54 <blackandblue> cocreature, ghc-static and vim. is that all I will ever need?
09:00:55 <blackandblue> :)
09:01:25 <Wizek> cocreature: if it leads to an unusable trace function I would call that a bug somewhere.
09:02:17 <cocreature> Wizek: I don’t think trace attempts to provide the semnantics that you expects it to provide
09:02:29 <Wizek> cocreature: Is there anything that does?
09:03:15 <cocreature> Wizek: I think you first need to define what exactly you want. trace provides you the semantics that it prints something if its second argument is evaluated
09:03:34 <cocreature> you expect the ST action to be repeatedly evaluated every time it is executed
09:03:42 <cocreature> but there is no reason why GHC has to do that
09:04:32 <cocreature> if your question is “how do I print something in ST” unsafeIOToST + putStrLn should work I think
09:05:14 <Wizek> also, you may be mis-reading what I wrote above: More optimization produces correct behavior, less optimization produces incorrect behavior.
09:05:17 <cocreature> blackandblue: those are the only packages from pacman that you need. you also want cabal-install but installing that via pacman causes problems so I would recommend that you either grab a prebuilt binary from the website or build it using the bootstrap script
09:05:39 <cocreature> Wizek: no, I understood it correctly (and found the same behavior when I tried it locally earlier)
09:05:41 <blackandblue> I see
09:05:43 <blackandblue> thanks cocreature 
09:05:54 <cocreature> my point is neither behavior is incorrect
09:07:12 <delYsid> Is there a package that exports all unicode character names ?
09:09:34 <Wizek> cocreature: unsafeIOToST may indeed be interesting in this specific case. In general I just want reliable tracing. Could be in ST, could be in State, could be in IO, could be whichever monad. I want something that is able to print a line to stdout exactly after the previously bound expression is evaluated and exactly before the next one starts to be. Is that too much to ask for?
09:10:42 <Wizek> Referential transparency may be a nuance here. But Debug.Trace already doesn't fully care for that. I want to go one step further in the direction of usfulness: have it be reliable.
09:10:45 <cocreature> Wizek: be careful with wording here. what you seem to want is something that prints after the previously bound expression is _executed_ which is something that only applied to ST/IO
09:14:52 --- mode: glguy set +v zzz_
09:14:56 <Wizek> cocreature Does this not apply to the state monad as well? I can very much imagine there being a need for reliable tracing therein as well.
09:15:25 <cocreature> for State there is no notion of execution only evaluation
09:15:53 <Wizek> But bind ensures order there, does it not?
09:15:58 <cocreature> to simplify things a bit compare let x = trace "x" () in deepseq [x,x] () and deepseq [trace "x" (), trace "x" ()] ()
09:16:16 <cocreature> it is perfectly reasonably for the optimizer to transform one into the other
09:16:24 <cocreature> but one will only trace once and the other twice
09:16:34 <cocreature> that’s similar to what is going on in your example
09:16:43 <Wizek> perhaps, with a bit of a caveat
09:19:16 <Wizek> If I have an expression such as `pure () >> traceM "a" >> traceM "a" >> pure ()` I want to be guaranteed that as it is being evaluated "a" is printed twice. That would be _much_ more reliable for debugging. I want to be guaranteed that it doesn't get transformed into `let a = traceM "a" in pure () >> a >> a >> pure ()` or some such
09:19:39 <Wizek> I was even willing to do -O0 which I would argue should already prevent such optimization attempts
09:19:48 <Wizek> And if it is not enough
09:20:01 <Wizek> maybe we need a special pragma along the lines of NOINLINE
09:20:17 <cocreature> the sharing in your case comes from explicit sharing in the definition of fix
09:20:29 <cocreature> I definitely agree that there should be a better way to control sharing
09:21:23 <Wizek> cocreature: I have a version that doesn't use fix at all, look at my gist
09:21:31 <Wizek> the issue still persists there
09:21:49 <Wizek> it just uses explicit recursion
09:22:23 <cocreature> sure fix is definitely not the only way to get sharing
09:22:48 <cocreature> if you change foo to () -> IO () it will probably work without optimizations
09:23:31 <lukelau> Is there a type of mkQ in SYB that doesn’t return a default value if the types don’t match, but rather recurses further into it?
09:24:17 <cocreature> don’t get me wrong, I can definitely emphasize with the desire of making tracing easier and more reliable. but I don’t see an easy solution here
09:24:48 <cocreature> the reason why we get away with having not too much control about sharing is that we separate the parts where this matters into the execution of IO actions
09:26:47 <Wizek> cocreature: I can think of one conceptually easy solution (might still be hard to track down): see what kind of optimization still fires in -O0 and disable it. Are you implying it is okay for GHC to try to optimize code even with -O0?
09:28:15 <cocreature> Wizek: no, I am arguing that your program exhibits explicit sharing so there is no need for any optimization to fire
09:29:33 <cocreature> the second argument of >>= is wrapped in a function which without optimizations should prevent sharing (which is why I suggested changing foo to () -> IO ()) but the first is not
09:33:46 <Wizek> re "your program exhibits explicit sharing": I'm still not quite following what you mean there. Surely quite a bit of inconsistency is involved there, is there not? it prints 1,2,3, 2,3, 2,3, 2,3... if it was consistent sharing I would either expect to see `1,2,3` then silence or `1,2,3, 1,2,3, 1,2,3...` Do you think it makes sense that the first outcome is what happens and neither the second nor the third?
09:34:29 <Wizek> btw, I just tried your unit suggestion
09:34:39 <Wizek> and it worked for this very specific case. 
09:34:48 <cocreature> Wizek: as I mentioned the reason why 2,3 are printed repeatedly here is that they are wrapped in the second argument of >>= which is a function which prevents sharing
09:35:01 <cocreature> (I’m guessing here tbf but I’m reasonably sure :))
09:36:31 <Wizek> too bad in my original code segment where this issue came up I wasn't using explicit recursion but a `whileM_` function.
09:36:38 <Wizek> trying your other suggestion
09:37:43 <nshepperd> your io action is foo = trace "step 1" noop >>= (\_ -> ... >> foo)
09:37:59 <Wizek> nshepperd: yes
09:38:11 <nshepperd> 'trace "step 1" noop' would only be evaluated once, just as 'foo = 1 + 2 : foo' only evaluates 1 + 2 once
09:38:53 <Wizek> unsafeIOToST works too. In light of this it may make sense to add a traceST to Debug.Trace to avoid similar sure-to-come-up confusion for others.
09:41:46 <Wizek> nshepperd: that makes some sense as a post-facto explanation, but in my original situation I had multiple such traces ignored until a `readSTRef` call. I can try to share repro with you if you are interested.
09:47:08 <Wizek> cocreature: btw, for general, is there anything on the horizon -- if not beyond -- to be able to have better control over sharing? 
09:54:24 <cocreature> Wizek: afaik no, there is an ancient issue but there hasn’t been much progress
09:58:11 <cocreature> I would definitely support the addition of traceST
09:58:26 <Wizek> cocreature: 👍
09:59:10 <cocreature> that character is apparently too cool for my terminal font :)
09:59:39 <Wizek> it was a thumbs up emoji.
09:59:53 <cocreature> ah :)
10:00:36 <Wizek> I might put together a trac issue about adding traceST then. (afaik that might be an appropriate place for suggestions about base modules)
10:00:44 <yilin> Hi all, is there a particular way that I could express something like data Expr a = Expr (b -> a) b in haskell without adding b to the signature?
10:01:05 <Wizek> yilin: maybe with forall 
10:01:14 <Wizek> not sure if it would be useful
10:01:33 <cocreature> yilin: data Expr a = forall b. Expr (b -> a) b
10:01:54 <cocreature> requires -XExistentialQuantification
10:02:22 <Wizek> does that mean that for anything it will be able to return an `a`?
10:02:23 <cocreature> yilin: but note that Haskell is lazy so since the only thing you can do with that is apply the function to its argument you might as well do that immediately and just store the lazily computed a
10:02:32 <yilin> Ah, that looks great; I'll read up on the extension.
10:02:48 <yilin> Yes; that's what I wanted to do.
10:03:42 <cocreature> Wizek: it means that there exists a type "b" to which you can apply the function not that it works for all choices of b
10:03:59 <cocreature> that’s why it’s called ExistentialQuantification
10:05:00 <yilin> For reference, I'm playing around with a DSL which allows introspection i.e. imagine data Prop a = Prop1 | Prop2 | Mapped (b -> a) (Prop a).
10:06:10 <cocreature> yilin: did you mean Mapped (b -> a) (Prop b)?
10:06:26 <cocreature> forall b. Mapped (b -> a) (Prop a) doesn’t make much sense since you can’t do anything with the function
10:06:26 <yilin> Eep, yes
10:12:37 <Jetien> Hi! Is there another way to "wait forever" similar to "getLine" in this example (see link)? I can't seem to use the "getLine" solution, because the process will be started without a stdin. I was trying threadDelay, but this results in "AMQP callback threw exception: fd:6: hPutBuf: resource vanished (Broken pipe)". Link: https://github.com/rabbitmq/rabbitmq-tutorials/blob/master/haskell/receive.hs
10:13:59 <cocreature> Jetien: that exceptions sounds unrelated to threadDelay
10:14:16 <cocreature> that sounds more like you are trying to write some handle that has since been closed
10:14:26 <cocreature> maybe you’re trying to write to stdout but also don’t have stdout?
10:14:45 <Jetien> cocreature: thank you. yes that might be it
10:16:51 <cocreature> Jetien: try changing the putStrLn to write to a file or something like that
10:21:35 <Jetien> cocreature: hmm that's weird. if i replace the binary with a python script it is able to write to stdout. are haskell programs by default treating pipes differently?
10:23:15 <cocreature> Jetien: I don’t think so. what happens if you just use some Haskell hello world that writes to stdout and remove all the amqp stuff?
10:39:11 <Jetien> cocreature: Actually the python script isn't able to write to sdtout either. Okay, so then it's not haskell related and threaDelay should work. Thank you very much!
10:39:52 <z0> hi guys. im learning haskell and if im understanding function composition correctly, having `fun x y z = x + y + z` is the same as `fum x y = (+) y . (+) x` is that right?
10:40:44 <z0> or `(y +) . (x +)` if it makes it more readable
10:41:21 <cocreature> z0: at least if you assume associativity of (+)
10:41:36 <dmwit> > ((+) y . (+) x) z
10:41:38 <lambdabot>  y + (x + z)
10:42:00 <z0> oh I see
10:42:05 <Wizek> @pl fun x y z = x + y + z
10:42:05 <lambdabot> fun = ((+) .) . (+)
10:42:17 <dmwit> > (+) (x+y) z
10:42:19 <lambdabot>  x + y + z
10:42:20 <Wizek> now /that/ is fun!
10:42:57 <z0> > ((+) x . (+) y) z
10:42:59 <lambdabot>  x + (y + z)
10:43:04 <z0> ok i get it
10:43:08 <dmwit> ?pl fun z = x + y + z
10:43:08 <z0> thanks!
10:43:08 <lambdabot> fun = ((x + y) +)
10:44:46 <z0> wait what? what was that last one? what is lambdabot doing?
10:45:01 <z0> point free?
10:45:15 <cocreature> yeah
10:45:56 <z0> ok i get it. but `fun z = x + y + z` wouldnt compile right?
10:46:17 <fendor> can i build a haskell application in a static way such that c dependencies like opengl are bundled as well? If not, how would I deploy such an app on different OS, such as Windows and Ubuntu
10:47:00 <Wizek> z0: I think it's just exploiting pl such that it treats x and y not to be abstracted away
10:47:49 <Wizek> z0: so yes, that wouldn't compile (unless you define x and y as constants)
10:48:01 <EvanR> statically include opengl... like every driver for every video card for every OS ?
10:48:42 <EvanR> seems like one of those that MUST be linked to the end users system version, dll
10:49:20 <z0> alright. simple enough. thanks
10:49:55 <fendor> EvanR, is it reasonable to demand from my users that they install opengl on their own?
10:50:03 <geekosaur> yes,. you lose hard if you include your own opengl lib and then the end user has cuda installed
10:50:04 <geekosaur> or vice versa]
10:50:30 <dmwit> fendor: I think it is reasonable.
10:50:36 <geekosaur> nvidia has its own opengl, at least for cuda, and you must use it
10:51:40 <EvanR> isnt opengl on everyones system, in one form or another. even if its a software slow implementation
10:51:45 <fendor> ok... well... could i create an installer that installs the appropriate opengl version for the user?
10:52:43 <geekosaur> that knwos how to drive rpm/yum/dnf, apt, pacman, etc.?
10:53:04 <geekosaur> not to say whatever you have to do on windows.
10:53:33 <EvanR> the first thing people do when they need to have 3d graphics on their computer is install the opengl drivers
10:53:53 <geekosaur> ys, and everyone without exception obviously needs 3d
10:53:55 <geekosaur> ys, and everyone without exception obviously needs 3d
10:53:56 <geekosaur> oops
10:54:10 <EvanR> though i guess its possible the first thing they do is install fendor's app
10:54:20 <EvanR> before everything is working right
10:54:39 <fendor> right, I would not try to create an installer for every linux, but at least windows
10:54:42 <geekosaur> ...so your answer to that is "yes of course"?
10:55:07 <fendor> no it is obviously not 
10:55:18 <fendor> however, i'd like to make the installation process as simple as possible
10:55:34 <fendor> downloading a file and executing it sounds reasonable to me, however, that does not work on any windows
10:55:39 <geekosaur> sorry I meant EvanR's assumtpion that everyone in existence requires opengl immediately
10:56:32 <EvanR> i guess i'm still in the world where when you dont set that up, your desktop is turtle slow
10:56:37 <fendor> s/any/all/
10:56:55 <geekosaur> you appear to be in the world where every installation forces gnome or kde down your throat
10:57:03 <EvanR> or windows
10:57:18 <EvanR> no just force X down your throat
10:57:23 <EvanR> vesa X is turtle slow
10:57:39 <fendor> i like turtles. Still better than snails
10:58:13 <EvanR> i recall some windows installers installing "opengl.dll" or some such, but it doesnt make sense to me because, doesnt the contents of that file depend on the hardware backend
10:58:18 <geekosaur> vesa X is fie if you're not running gnome-shell
10:58:24 <geekosaur> or plasma
10:58:28 <z0> dont you mean turtoises? turtles can be pretty fast
10:58:39 <geekosaur> not a speed demn but plenty usabe
10:58:52 <EvanR> some apps require you install java first
10:59:07 <EvanR> not sure if it makes sense to bundle your own java
10:59:59 <geekosaur> EvanR, iirc you can emulate opengl on top of directx, which microsoft does pretty much force these days. it's sort of windows version of software emulation
11:00:26 <EvanR> is directx automatically set up?
11:00:37 <EvanR> or is that another step to automate 
11:00:46 <bontaq> any libraries that would be good for communication with a long-running process that only does stdin/stdout?  I've been trying to use io-streams but wanna tear my hair out since it closes the handle (which in turn shuts down the process) or locks up
11:01:10 <EvanR> theres System.Process
11:01:20 <z0> is (<<<) just a generalized (.)? if not, what are the relevant differences?
11:02:20 <lyxia> it is a generalized (.)
11:02:54 <EvanR> i guess what i'm confused about is, bundling your own opengl.dll doesn't seem to make sense because its not portable and fast at the same time
11:03:19 <fendor> EvanR, i understand you reasoning and have abononed the thought.
11:03:39 <fendor> However, how can i make the setup of an application that uses opengl the most pleasant?
11:04:31 <EvanR> check for support in the wizard, if not found alert "OpenGL support not found. Install it"?
11:04:40 <fendor> s/abononed/abandoned
11:05:30 <EvanR> otherwise a message like that will pop up if they try to run the exe
11:06:12 <fendor> The message that pops up is, could not find `libstdc++.so.6`?! hm, maybe this is not even related to opengl :D 
11:06:43 <fendor> however, you would recommend a wizard, i ll look into that
11:06:46 <EvanR> bundling your own stdc++ ... thats a whole nother can of worms
11:07:30 <fendor> do i have to do that?
11:07:50 <EvanR> i have only heard "don't do that" (at least on linux)
11:07:50 <fendor> i suppose, the haskell plattform installs one on its own?
11:08:55 <EvanR> one what?
11:09:17 <droplet> is there a ghci command to see which version of ghc i'm on?
11:09:21 <dmwit> I would be very surprised if the Haskell Platform bundled a libstdc++.
11:09:43 <fendor> then why do I have it on my windows?
11:09:55 <fendor> EvanR, a bundled libstdc++
11:10:06 <fendor> https://ghc.haskell.org/trac/ghc/ticket/4468 this ticket seems to be related
11:10:17 <EvanR> its used by every c++ program
11:11:07 <fendor> and why does my friend not have it?
11:11:16 <fendor> we both developed opengl programs in c++
11:11:21 <Solonarv_> the haskell platform on windows comes with a mingw install, and *that* includes libstdc++
11:11:41 * dmwit is very surprised, as promised
11:11:49 <MarcelineVQ> droplet: you can type  ghci --version  on the cli   or from in ghci   :! ghci --version
11:11:57 <fendor> i see, so, installing the haskell platform would solve the problem? that i should use it to solve the problem
11:12:19 <EvanR> i was about to say what C++ has to do with haskell, ghc, or haskell platform
11:13:55 <droplet> MarcelinVQ: thanks!
11:15:11 <dmwit> droplet: Of course beware that this isn't guaranteed to be the same ghci you're running. It will do the usual PATH lookup stuff, which may or may not coincide with how the current ghci executable was found.
11:15:18 <fendor> soo... maybe i should rephrase the question, how do i deploy on windows :D 
11:16:21 <dmwit> droplet: e.g. stack (and cabal, too, in advanced usage) likes to drop you into a repl that isn't the first ghci on your PATH.
11:31:25 --- mode: glguy set +v UnknownCombinato
11:31:26 <EvanR> fendor: good question. one thing to note about static linking is possible binary incompatibility with non static stuff expected on the users system. This is why a lot of people recommend building everything from source 
11:33:57 <droplet> dmwit: ah. that makes sense - how can i find the ghci i am running?
11:34:14 <UnknownCombinato> Quick question: In the old days, ghc(i) would not produce a stack trace when you called the error function. That would often be annoying and make debugging difficult. So they changed it, now error produces a stack trace. But sometimes you actually want to have a nice user-facing system that can die with an error but without a stack trace. So, is there a way to get the old functionality, errors but without stacktraces?
11:34:54 <UnknownCombinato> (Unfortunately, if you google this, you get lots on information on how to get stacktraces, not how *not* to get them.)
11:34:59 <MarcelineVQ> https://hackage.haskell.org/package/base-4.12.0.0/docs/Prelude.html#v:errorWithoutStackTrace
11:35:17 <MarcelineVQ> not used that myself tho
11:35:29 <edwardk> UnknownCombinato: throw (ErrorCall "wat")
11:35:45 <edwardk> using ErrorCall from Control.Exception
11:36:11 <edwardk> or do you want to do this for all top level error messages?
11:36:26 <edwardk> that should also be doable, there is a way to install the global uncaught error handler
11:37:06 <UnknownCombinato> I'm happy to use the more verbose-named function.
11:37:46 <fendor> EvanR, i dont think you can demand taht from the average windwos user. Not even linux user
11:39:47 <UnknownCombinato> It's kind-of a shame that the Google search results for this query, https://www.google.com/search?q=haskell+error+without+call+stack turn out to be so poor.  
11:40:24 <UnknownCombinato> But thanks MarcelineVQ, you rock. That's why I came here next.
11:41:24 <MarcelineVQ> edwardk's response is essentially the same thing as well, errorWithoutStackTrace is    and you left
11:41:54 <edwardk> MarcelineVQ: ah never noticed that function
11:42:47 <MarcelineVQ> it just thinks its too good to use throw directly :>
11:44:23 <cocreature> MarcelineVQ: MagicHash always makes everything better
11:44:36 <MarcelineVQ> Both raise# eventully :>
11:45:04 <cocreature> yeah but you don’t need to enable MagicHash if you use throw so it must be worse
11:45:07 <MarcelineVQ> Ed's doesn't need a GHC module though, if you have faith in module, so in the year 2525 its got a slightly better chance of being used on multiple haskell compilers
11:46:33 <cocreature> the number of Haskell compilers seems to be shrinking instead of growing so I’m not sure 2525 will be much better
12:04:57 <camsn0w> Was told this was like the most active channel 
12:05:05 <camsn0w> Where's everyone at ?
12:05:30 <lyxia> too busy writing Haskell
12:06:27 <Ke> all the discussion has been statically inferred, no need to actually have it
12:08:56 <z0> @pl f g = g y
12:08:56 <lambdabot> f = ($ y)
12:13:13 * z0 clicks
12:14:11 <EvanR> @pl f g y = g y
12:14:11 <lambdabot> f = id
12:15:00 <z0> haskell is beautiful
12:17:25 <monochrom> Nah, Haskell is just bearable. It's the other languages that are unbearable.
12:18:07 <z0> not False
12:18:41 <EvanR> no unbearable
12:23:54 <tommd> We need caching builds and Text=String before beauty.
12:24:46 <z0> what does ´const´ stand for?
12:24:54 <monochrom> constant
12:25:57 <EvanR> const 99 = the function that always returns 99
12:33:24 <davr0s> i made a little helper [t] ++? Maybe t    , does it have an official name?
12:33:40 <davr0s> `appendMaybe` might be less arcane
12:34:17 <davr0s> it's also possibly misleading because a++b needs lists right?  'append' puts an item in a list..
12:35:02 <EvanR> are you thinking of (:?) :: Maybe a -> [a] -> [a]
12:35:09 <EvanR> Nothing :? xs = xs
12:35:20 <EvanR> (Just x) :? xs = x : xs
12:35:56 <heptahedron> I currently have a naive implementation of a regex matcher that is written in a double-barrel backtracking continuation monad transformer, universally quanitified over the eventual return type `m r`--
12:36:30 <davr0s> ok thats flipped but perhaps ("its' a singly linked list..") thats better
12:37:08 <EvanR> append to the end of a list is... technically inefficient
12:37:44 <davr0s> right thats a mistake i need to avoid
12:38:03 <heptahedron> I feel like the way I'm implementing the "compilation" that changes the regex into a function that tries to find a match in a string, each invocation will end up unnecessarily creating new functions even if the same control path is being followed--is this where I should try to use MonadFix?
12:38:10 --- mode: glguy set +v bodisiw
12:38:29 --- mode: glguy set -v bodisiw
12:39:40 <alp> not necessarily, if you just keep hold of the result of "compiling" the regex into an efficient string matching function you won't "recompile" the regex
12:40:25 <dmwit> droplet: Dunno if you eventually got an answer, but you could look at System.Info.compilerVersion.
12:40:45 <EvanR> compile :: Regex -> String -> Result, keep compile "a?b+c*" around, it wont be recompiled or create new functions
12:40:47 <dmwit> droplet: It'll tell you the major-minor number, though the patch level is left out.
12:41:04 <alp> (by "keep hold" I mean: let matcher = compileRegex "<regex here>" in ... and then you just reuse 'matcher' there
12:41:06 <alp> )
12:41:33 <tsaka__> Is it possible to simplify "fn2" in this paste? https://lpaste.net/1488316681867493376
12:41:39 <alp> (or 'matcher' can be a toplevel binding, or defined in a where clause, or... you get the idea)
12:42:04 <dmwit> droplet: (e.g. ghci-8.2.2 will report [8,2] as its version number through that interface)
12:42:07 <alp> the idea is just to give a name to the application to some particular regex, and refer to that everywhere you need it
12:43:15 <dmwit> tsaka__: asks myField >>= fn1 arg1 arg2
12:43:23 <dmwit> tsaka__: Dunno whether you consider that simpler, though. =)
12:43:39 <tsaka__> dmwit: is it possible to do point free?
12:43:55 <dmwit> Yes. But not worth it.
12:44:26 <dmwit> (asks myField >=>) . fn1
12:44:27 <MarcelineVQ> it's pretty arcane in point free form
12:46:04 <jkaye> alp coming in a bit late, but aren't you just looking for http://hackage.haskell.org/package/regex-compat-0.95.1/docs/Text-Regex.html#v:mkRegex
12:46:08 <dmwit> asks myField >=> fn1 arg1 -- might be worth it, depending on exactly what these names are/how you think about this action
12:46:13 <MarcelineVQ> neato, less arcane with >=>
12:46:51 <dmwit> wait, no
12:46:57 <dmwit> That's not typed right at all.
12:47:18 <dmwit> I'm even more confident it isn't worth it now. =P
12:47:30 <dmwit> ?pl \arg1 arg2 -> asks myField >>= fn1 arg1 arg2
12:47:31 <lambdabot> ((asks myField >>=) .) . fn1
12:48:04 <heptahedron> My monad is essentially `ParsecT` except I don't care whether failure consumed any tokens (see http://hackage.haskell.org/package/parsec-3.1.13.0/docs/src/Text.Parsec.Prim.html#ParsecT ), and I know that keeping the binding for a specific invocation with one regex will keep the matcher around without having to be evaluated again but I was confused about whether certain subexpressions will be needlessly recreated aga
12:48:04 <heptahedron> in and again 
12:48:46 <tsaka__> Any idea about this one? https://lpaste.net/3656522778271547392
12:49:06 <tsaka__> (Notice the change of the funcion sig of fn from first paste)
12:49:16 <dmwit> heptahedron: Are you avoiding libraries on purpose? If not, I highly recommend regex-applicative. Very humane interface to regex parsing.
12:49:46 <dmwit> tsaka__: Make `fn1 :: MonadState (StdGen, B) m => Int -> Int -> Float -> m ()` instead.
12:50:13 <dmwit> tsaka__: And while you're at it, make `fn2 :: (MonadReader C m, MonadState (StdGen, B) m) => Int -> Int -> m ()` at the same time.
12:51:37 <tsaka__> dmwit: If I never plan to update the reader, should I use ReaderT C State instead?
12:51:52 <tsaka__> or the equivalent .. type class?
12:52:35 <tsaka__> or does the type classes allow it to be either way?
12:52:42 <heptahedron> dmwit: Honestly I'll probably switch to that, I wasn't aware of its existence before this but this was mostly an educational venture in the first place
12:53:12 <alp> jkaye, I wasn't the one asking about this, that was heptahedron 
12:53:13 <dmwit> tsaka__: The classes allow either order.
12:53:48 <dmwit> heptahedron: Right. As educational adventures go, regex parsing in a continuation monad sure sounds like a pretty good one.
12:54:17 <jkaye> My bad :)
12:54:30 <heptahedron> dmwit: It's been interesting for sure haha. Was inspired by the LogicT paper
12:54:34 <alp> no worries
12:54:38 <tsaka__> are the orders functionally equivalent? StateT s Reader r VS ReaderT r State s
12:55:07 <dmwit> tsaka__: In this particular case, yes.
12:55:22 <dmwit> It is not generally true that transformers commute.
12:55:35 <dmwit> In this case it's easy to see, though:
12:55:41 <dmwit> ?unmtl ReaderT r (State s) a
12:55:41 <lambdabot> r -> s -> (a, s)
12:55:46 <dmwit> ?unmtl StateT s (Reader r) a
12:55:46 <lambdabot> s -> r -> (a, s)
12:55:53 <dmwit> isomorphic types
13:01:11 --- mode: glguy set +v Boarders
13:01:32 <tsaka__> Thank you
13:01:33 --- mode: glguy set -v Boarders
13:03:41 <Boarders> I have some sort of bug where in ghci where the :sprint command always returns _
13:03:47 <Boarders> is anyone familiar with this?
13:04:28 <Boarders> GHCi, version 8.0.2: http://www.haskell.org/ghc/  :? for help Prelude> let l = [(1,2), (2,3), (4,5)] Prelude> :sprint l l = _ Prelude> last l (4,5) Prelude> :sprint l l = _ Prelude> head l (1,2) Prelude> :sprint l l = _
13:04:36 <Boarders> e.g. I get this
13:04:54 <Boarders> (sorry accidentally entered that too early whilst trying to format it)
13:04:55 <dmwit> Boarders: l is typeclass polymorphic, therefore really is re-evaluated each time starting from _
13:04:57 <MarcelineVQ> You need fully applied types to get useful info from :sprint
13:05:09 <Boarders> ah ok
13:05:10 <dmwit> It's not a bug. That's what the semantics of Haskell actually says to do.
13:05:13 <Boarders> thank you
13:05:20 <dmwit> Well. It's what GHC's semantics actually do.
13:05:54 <Boarders> doesn't it restrict to [(Integer, Integer)] though?
13:06:09 <dmwit> Why not ask? Run :t l and see what youget.
13:06:19 <Boarders> yes
13:06:32 <Boarders> I guess that is just for showing your result
13:09:31 <Boarders> another dumb question
13:09:35 <Boarders> Prelude> let l = ([(1,2), (2,3), (4,5)] :: [(Int, Int)])
13:09:50 <Boarders> Prelude> :sprint l;  l = [(1,2),(2,3),(4,5)]
13:09:57 <Boarders> why does it return the full answer
13:10:22 <Boarders> fully evaluated*
13:12:53 <dmwit> weird
13:12:58 <MarcelineVQ> I'd guess it's since you gave it the full answer up front.
13:13:07 <dmwit> `l = [(1,2),...] :: [(Int,Int)]` doesn't do that
13:13:20 <dmwit> (i.e. without the `let`)
13:13:29 <EvanR> o_O
13:13:30 <dmwit> I have no explanation.
13:13:41 <EvanR> annoying hacks in ghci
13:13:51 <dmwit> yeah, maybe
13:20:02 <tsaka__> dmwit: When changing from StateT to a MonadState constraint I ran into trouble. It seems that using a tuples as state no longer works when calling functions of only either monad: "Could not deduce (MonadState StdGen m1) from the context: MonadState (StdGen, EventGen) m" 
13:21:47 <dmwit> tsaka__: Can you show some code that worked with type `State (StdGen, EventGen) Foo` but does not work with `MonadState (StdGen, EventGen) m => m Foo`?
13:21:59 <dmwit> Or StateT or whatever.
13:22:03 <tsaka__> yes
13:25:52 <tsaka__> dmwit: https://lpaste.net/6738454931784597504
13:27:08 <tsaka__> The function "_generateEndEvent" was changed from having "State (StdGen, EventGen)" as monad to whatever you see in the paste
13:27:37 --- mode: glguy set +v lantti
13:27:55 <lantti> Boarders: I guess you hit this: https://ghc.haskell.org/trac/ghc/ticket/10160
13:33:26 <lantti> In short: yes it is a ghci optimization
13:36:00 <cocreature> tsaka__: zoom doesn’t really work with MonadState
13:37:39 <cocreature> the problem is that it’s not clear what monad it should zoom too
13:38:12 <cocreature> you can add a Zoomed constraint and then select "n" with TypeApplications/a proxy but it gets fairly messy
13:38:41 <cocreature> alternatively you can add a StateT layer on top of m so that your top-layer is concrete and zoom on that but that’s also ugly
13:42:14 <tsaka__> then I'm back to square 1.. how to fix this problem:  https://lpaste.net/3656522778271547392
13:47:05 <lyxia> tsaka__: fn1 uses State, i.e., StateT _ Identity, whereas fn2 uses StateT _ (Reader _)
13:47:29 <lyxia> tsaka__: change the type of at least one of them
13:47:41 <dmwit> tsaka__: Somewhat controversial suggestion: how about not using MonadState.
13:47:53 <dmwit> tsaka__: Like, not using State at all (except perhaps under a newtype wrapper).
13:48:35 <tsaka__> lyxia: Yes I know, but why can I not use the monad without a reader from the monad with a reader? it's only missing information
13:48:38 <dmwit> tsaka__: Specifically, make a ExponentialT that offers `exponentialSt` as its API, and a MonadRandom that offfers `randomR` as its API, and use those instead of State.
13:48:49 <dmwit> tsaka__: Luckily, the MonadRandom part is already done for you.
13:48:52 <dmwit> ?hackage MonadRandom
13:48:52 <lambdabot> http://hackage.haskell.org/package/MonadRandom
13:49:11 <lyxia> tsaka__: because the "monad without a reader" is using Identity instead
13:49:11 <dmwit> (Then you can reuse MonadState for the other part if you want, I guess.)
13:49:19 <dmwit> Bonus: no zooming.
13:50:01 <dmwit> Wait, I'm confused. You're already using MonadRandom. Why are you carrying a StdGen around, then?
13:51:33 <dmwit> _generateEndEvent :: (MonadState EventGen m, MonadRandom m) => ... -- ?
13:51:54 <tsaka__> That is a good question. I think it is because I started out using StdGen everywhere, but didn't figure out to do it with exponentialSt
13:52:30 <tsaka__> that seems more sensible, ill try it out
13:52:38 <infinisil> ?hackage apackagethatdoesntexist
13:52:38 <lambdabot> http://hackage.haskell.org/package/apackagethatdoesntexist
14:08:44 <tsaka__> dmwit: Since you can't use zoom, is there any other approach for having functions that only work on substate, i.e. a part of the main state (I need it for other things than StdGen)
14:09:43 <chessandgo> does anyone use type level programming to handle different types within your inbox when using Cloud Haskell?
14:27:26 <hexagoxel> tsaka__: there is the "has" approach, e.g. "data-has" package, or "unleashed" mtl versions like the "mtl-unleashed" or "multistate" packages.
14:28:25 <tsaka__> hexagoxel: okay. I will take a look at them if there really is a need. Thank you
15:15:44 <nfd9001> Is getting the nth element of stream >>= show O(n)? 
15:15:58 <nfd9001> I'd imagine it'd be n^2, but I'm not totally sure
15:16:32 <nfd9001> since stream is a list, and list uses (++) to implement (>>=)
15:18:05 <monochrom> If stream is list, why did you say stream? Also, the answer probably depends on how the list was defined.
15:18:14 <nfd9001> Else, can anyone offer a more efficient way to cat together an infinitely-large list?
15:18:50 <nfd9001> monochrom: people go running around calling infinitely-large lists "streams" in my circles for whatever reason, sorry
15:20:03 <monochrom> OK so how was your particular list defined? Actual code?
15:20:34 <monochrom> Also what is >>= doing there?  I could understand "... >>= print" but not when it's "show" not "print".
15:20:36 <nfd9001> monochrom: the precise list i'm using is the Fibonacci numbers, generated however. I used the basic zipWith implementation
15:21:04 <nfd9001> members of Show provide show, which hands back a string
15:21:31 <monochrom> @type [1,2,3] >>= show
15:21:32 <lambdabot> [Char]
15:21:36 <nfd9001> Basically, I want [0,1,1,2,3,5,...] to "011235"
15:21:41 <nfd9001> and so on
15:21:45 <monochrom> > [1,2,3] >>= show
15:21:47 <lambdabot>  "123"
15:22:19 <nfd9001> since show :: Show a => a -> String
15:22:49 <monochrom> With Fibonacci numbers in the list content, the exponential growth of the numbers is going to overshadow the pesky polynomial-time growth of the cons cells.
15:23:35 <monochrom> Computing the nth fib number takes time more than 1.6^n.
15:24:04 <nfd9001> Well, since I need all of the fib numbers anyway, it doesn't really matter that badly
15:24:13 <nfd9001> Each individual number takes constant time
15:24:20 <tsaka__> Is it possible to do something like this? https://lpaste.net/226537032120270848
15:24:26 <tsaka__> or perhaps with tuple types?
15:24:34 <monochrom> Wow you really believe in free lunches in computing.
15:24:53 <shachaf> monochrom: You mean the growth of the numbers themselves?
15:25:31 <nfd9001> monochrom: well, fib !! n == fib !! (n - 1) + fib !! (n - 2)
15:25:32 <Tops2> quick and dirty(?) solution: import Data.Char and then: map (chr . (+ ord '0')) [0..5]
15:26:20 <monochrom> shachaf: Oh oops, right. Still, not going to be constant time.
15:26:52 <nfd9001> I'm assuming addition is constant here
15:26:58 <monochrom> Why assume?
15:26:59 <nfd9001> Which I guess it strictly isn't, but
15:27:26 <nfd9001> I need to do that addition no matter what. What I want to avoid is excessive list re-traversals with ++
15:27:41 <monochrom> If you were living in the 15th century and you had no source to learn computing from, you could assume, that would be reasonable.
15:28:22 <shachaf> There's a big difference between exponential and linear
15:28:37 <nfd9001> Alright, lemme put it this way, then. Am I doing pointless re-traversal using >>= this way?
15:28:54 <shachaf> Probably.
15:29:02 <shachaf> But it's probably not that bad?
15:29:04 <shachaf> You can use shows instead.
15:29:29 <nfd9001> It's only maybe a problem because I'm going to need to look arbitrarily far down this list
15:30:41 <monochrom> How about we investigate it properly instead of either assuming or taking an authoritative answer without understanding.
15:30:57 <monochrom> How is >>= for [] defined?
15:31:44 <nfd9001> If I recall correctly, it does all of the computations in a functor-y way, then (++)s them all together
15:32:05 <nfd9001> xs >>= f = concat (map f xs)
15:32:19 <nfd9001> or to that effect
15:33:03 <monochrom> You need to be more precise than that, and you knew it.  "++ them all together" has at least two conflicting meanings.  Both (x++y)++z and x++(y++z).
15:33:42 <nfd9001> I don't know the complexity of concat, though. It could do it efficiently, or it could do it with (++). That's what I'm looking for, I guess
15:34:04 <monochrom> But you knew where to look for it's code.
15:36:41 <shachaf> The question was about "pointless re-traversal", though.
15:36:50 <shachaf> There's some of that either way.
15:36:56 <nfd9001> Well, actually, I don't know how concat is implemented. It's a bit of a maze to figure out how that's done, since I've got to jump through a bunch of sources to figure this all out, and I'm ignorant as to if the compiler could do any useful optimizations
15:37:44 <nfd9001> concat is mconcat is foldr mappend empty, so now I get to chase down the list implementation of (<>) and it feels like I may be hitting a dead end
15:38:14 <monochrom> <> is going to be ++. empty is going to be [].  foldr (++) []
15:39:04 <lyxia> tsaka__: MonadState has a fundep that forbids having multiple (MonadState s m) and (MonadState s' m) with s /= s'.
15:39:16 <monochrom> foldr is going to be what @src knows, apart from a constant multiplier.  I.e., what @src knows has the correct big-Theta even if not the exact thing.
15:39:19 <monochrom> @src foldr
15:39:19 <lambdabot> foldr f z []     = z
15:39:19 <lambdabot> foldr f z (x:xs) = f x (foldr f z xs)
15:39:51 <nfd9001> And (++) always forces the left list, yeah?
15:40:24 <monochrom> With this information you can at least answer this example question: concat [a,b,c,d], is that going to be a++(b++(c++d)) or is it going to be ((a++b)++c)++d?
15:40:28 <nfd9001> So I'll be fully traversing everything left of the number I'm appending if I use >>=
15:42:15 <nfd9001> It's the first one. Else the entire list would be forced no matter what, and using that bind would yield bot
15:43:29 <nfd9001> I know what the fold does; I just want a way to cat these numbers together a little quicker by not iterating through the entire LHS every time I'm adding a new one
15:45:33 <monochrom> OK, I have no point continuing until you finally admit "I don't know".
15:46:38 <monochrom> My experience is that 100% of the time on IRC when a person asserts "Look I know ____" they're also reaching all sorts of wrong conclusions therefore proving that they don't know.
15:47:17 <atchoum> monochrom: what do you think about XP (xtreme programming) ?
15:47:25 <monochrom> Why me?
15:47:32 <atchoum> because you are talking :D
15:47:53 <monochrom> OK, then I won't talk.
15:48:09 <atchoum> nfd9001: you seem full of questions and misconceptions :D
15:48:50 <atchoum> I wanted to know if anybody had definitive opinions about Xtreme Programming
15:48:58 <atchoum> but if nobody talks :he: 
15:49:05 <nfd9001> It has a really entertaining name
15:49:06 <monochrom> Wrong channel for that IMO.
15:49:21 <monochrom> WTF is :he:  ?
15:49:26 <nfd9001> atchoum: trying to place your tone there is a little tricky, lol
15:50:11 <atchoum> :he: I meant :hé:
15:50:18 <atchoum> or some kind of "interjection"
15:50:20 <atchoum> nevermind
15:50:30 <atchoum> there could be better chan to talk about that
15:50:32 <atchoum> cya
15:51:26 <nfd9001> monochrom: I know what foldr is, I know what >>= is doing, I know what (++) does, and I know the way I'm generating Fibonacci numbers is O(n) to find the nth element
15:51:58 <nfd9001> I'm asking if anyone can come up with a way to cat this list together that doesn't incur the cost of forcing the LHS of ++ so many times
15:52:56 <nfd9001> Since I recall that ++ is at least linear with respect to the LHS of the list, which is why people construct lists with cons and reverse them sometimes instead of (++)ing the RHS
15:53:21 <monochrom> The truth is that concat (n things) does not force the LHS of ++ n times. Therefore you don't know.
15:53:23 <nfd9001> ...maybe I haven't been totally clear about this, but I feel like I'm only really being met with antagonism
15:54:05 <monochrom> You have also misunderstood the circumstance under which people used cons and reverse.
15:55:23 <monochrom> You have also not known under those circumstance, cons and reverse was not the only solution, there is a way to keep having ++.
15:55:27 <nfd9001> wait, why doesn't it force whatever LHS exists n times if i'm using foldr?
15:55:40 <monochrom> OK, show me why you believe it should.
15:56:19 <nfd9001> ...okay.
15:56:37 <monochrom> Show me actual evaluating steps of, say, (a1:a2:[]) ++ ((b1:b2:[]) ++ (c1:c2:[]))
15:57:16 <nfd9001> [a] ++ [b] ++ [c] goes to [a,b] ++ c and hits NF at [a,b,c]
15:57:38 <monochrom> That is not evaluating steps.
15:57:56 <nfd9001> is it unclear in some way?
15:58:15 <nfd9001> ahhhh, i see what you're getting at
15:58:24 <tsaka__> is there such a thing as "execStateM"? If your inside, say, "MonadReader R m -> m A", How can you return an "m A" given an "A" which must be processed by a function "(MonadState A m, MonadReader R m) => m ()"?
15:58:37 <nfd9001> monochrom: yeah, i see my error now, thanks
15:58:40 <tsaka__> (I don't know if that last requirement makes any difference to the answer)
15:59:00 <monochrom> If I say "Could you pass me the bottle of salt" and you pass me a bottle of pepper and I say "that is not salt", do you say "is it unclear in some way?"?
15:59:55 <monochrom> I guess s/evaluating/evaluation/
16:00:03 <nfd9001> I suppose not; I see my logic error now
16:00:13 <nfd9001> sorry, I suppose so
16:01:00 <nfd9001> it should be just fine with a foldr, and I was wrong
16:02:02 <monochrom> concat is linear time and won't revisit the 1st item n times. It's OK.
16:03:24 <monochrom> SImilarly "map f (x:xs) = f x : map f xs" adds only linear time to the cost of using f.
16:04:25 <monochrom> tsaka__: Cannot.
16:05:16 <monochrom> You probably should delete all your code and start over from a cleaner design.
16:05:26 <monochrom> Also a less ambitious design.
16:05:57 <nfd9001> monochrom: this is a tiny project and I have very little haskell experience
16:06:08 <nfd9001> Basically a whiteboard code problem
16:06:17 <nfd9001> There isn't a huge sunk cost
16:06:35 <monochrom> I mean tsaka__.
16:06:39 <nfd9001> ohh sorry
16:06:53 <monochrom> fibnumbers >>= show  is a fine exercise.
16:07:23 <shachaf> I guess it's slightly more than linear.
16:09:53 <monochrom> foo >>= show is proportional to foo's length.  Put it in another way, (>>= show) is reasonable in its cost.  In today's particular case the real cost comes from fibnumbers.  It's going to have n^2 length if you ask for n fib numbers.
16:11:22 <nfd9001> monochrom: assuming that addition length scales with size, then? it definitely does O(n) additions
16:11:45 <monochrom> Yes. Each addition takes n time. The total time is n^2.
16:12:25 <shachaf> Why does each addition take n time?
16:12:36 <shachaf> Or, rather, what is n?
16:12:50 <nfd9001> shachaf: some of the integers are getting really big
16:13:07 <monochrom> Adding two k-digit numbers takes k time.  k = lg (1.6^n).
16:13:14 <nfd9001> n is arbitrarily large, since i need to go arbitrarily far into the fibbonaci numbers. i'm looking for subsequences of digits that fit some pattern
16:13:28 <shachaf> Yes, but the earlier integers are smaller.
16:13:42 <nfd9001> O is a weak upper-bound
16:14:05 <monochrom> Yes, but you know how "sum [1..n]" is n^2 up to big-Theta.
16:14:31 <shachaf> You're saying that only saves you a constant factor?
16:14:43 <monochrom> I was too lazy to type in "Θ" everywhere. Would you like to start over and do it properly?
16:14:50 <nfd9001> well, find the big-Theta yourself, lol
16:15:16 <nfd9001> time to try to remember the master theorem of computational complexity?
16:15:47 <nfd9001> may not even need that, i guess. it's been a while :D
16:15:47 <monochrom> sum [1..n] = n^2/2 + change ∈ Θ(n^2)
16:16:18 <monochrom> Actually the exact thing is n^2/2 + n/2
16:17:25 <monochrom> Another fun fact is lg 1 + ... + lg n ∈ Θ(n lg n).
16:21:32 <shachaf> monochrom: OK, makes sense, you meant it was directly the thing you were saying.
16:27:36 <leifmetcalf> How should I decide whether to represent eight stacks of cards as a list of stacks, `type Board = [Stack]`, or as a datatype like `data Board = Board Stack Stack Stack Stack Stack Stack Stack Stack`, where Stack is defined by `Stack = [Card]`?
16:29:00 <geekosaur> if you want to pick a particualr stack based on a value, you want a list or vector. indexing over record fields is painful
16:29:22 <geekosaur> (or map, etc. conceivably)
16:30:16 <leifmetcalf> Thank you, would you only use a new type (or a tuple) when you want to combine values of different types?
16:32:02 <leifmetcalf> Normally I see coordinates represented as a tuple, even though the x and y are the same type. Why would a tuple be used instead of a list?
16:32:26 <jle`> leifmetcalf: lists do not guaruntee the number of elements
16:32:32 <jle`> tuple sizes are 'fixed'
16:32:50 <jle`> so you can't have any runtime errors coming from out-of-bounds indexing
16:32:52 <EvanR> i have seen coordinates represented as e.g. data V2 a = V2 a a
16:32:56 <EvanR> V3 a = V3 a a a
16:33:05 <geekosaur> also faster, simpler than using a custom data type, and you don't usually pick x vs y based on another value
16:33:34 <geekosaur> yes, that's sued by vector types. mostly because it's easy to rearrange them for the internal representation of an unboxed or storable vector
16:34:03 <leifmetcalf> Sorry, what does 'sued' mean?
16:34:09 <geekosaur> "used"
16:34:46 <geekosaur> externally it's a V3 "tuple", internally the unboxed version may be a tuple of three vectors
16:35:50 <geekosaur> and this avoids a downside of tuples: relatively little type safety
16:36:27 <geekosaur> you don'tknow if some (x,y) is a valid point or not, whereas you can arrange that a Point x y is always valid via smart constructors
16:37:19 <geekosaur> so you have some tradeoff between convenience and type safety, etc.
16:47:05 <monochrom> It's the very same pros and cons of any encapsulation.
16:49:39 <EvanR> encapsulation ah one of the pillars of OOP 
16:50:19 <monochrom> You could also make it a pillar of a newtype behind a module that exports almost nothing.
16:53:38 <monochrom> And don't forget Backpack, which doesn't even require newtyping.
16:55:10 * EvanR pushes Backpack onto the stack of things to learn (again)
16:55:18 <jackdk> pfff. `FILE*` in C provided better encapsulation than anything I ever wrote in Ruby. Good encapsulation transcends paradigm.
16:58:37 <monochrom> In the case of C, encapsulation is not advocated by the language semantics, but rather by fearmongering.
17:01:28 <monochrom> Nothing in C denies me direct access to FILE's fields. Rather, it's the people who keep scaring me off it by "if you're changing from glibc to Solaris libc, the fields will be different"
17:02:13 <monochrom> But really, when was the last time I had to change from glibc to Solaris libc? When was the last time I actually my source code to be portable?
17:02:53 <shachaf> C certainly can deny you access to FILE's fields.
17:03:01 <geekosaur> …and then you find yourself porting ancient mh…
17:03:01 <shachaf> It can be declared as an opaque struct.
17:04:12 <shachaf> In my opinion hiding implementation details from determined library users is overrated anyway.
17:04:53 <shachaf> Declare expectations but also assume your users are competent and let them do whatever they feel like if they really want to.
17:06:52 <monochrom> A few days ago I heard that many Ruby programs work by monkey-patching standard library code.  So Ruby --- both the community and the language semantics (because it allows this) --- advocates decapsulation.
17:07:21 <dmwit> tsaka__: If `foo :: MonadReader r m => m A` and `bar :: (MonadState A m, MonadReader R m) => m ()`, then `foo >>= evalStateT bar` has type `MonadReader R m => m ()`.
17:07:39 <monochrom> So here is one paradigm that doesn't let encapsulation transcend paradigms.
17:08:05 <jackdk> I switched away from Ruby for $DAYJOB about 18mo ago. It used to be more prevalent but people learned their lesson there, I think. It wasn't something we allowed in our codebase, apart from well-known libraries like activesupport
17:08:17 <jackdk> we wouldn't add new stuff of our own that way, for instance.
17:11:20 <Arahael> monochrom: That was the one thing I hated about Ruby.
17:11:36 <Arahael> monochrom: Ironically, I see less monkey-patching in Python, despite it being easier to do there.
17:12:24 <geekosaur> because guido would reach out of your monitor and smack you silly if you did it
17:12:30 <monochrom> The Python people, for better or worse, has Guido-fearing fearmongering.
17:13:44 <Arahael> monochrom: They used to.
17:18:44 <monochrom> I would be OK to expose implementation details to those who had demonstrated that they were capable of stating, proving, and disproving loop invariants and data invariants.
17:19:01 <dmwit> tsaka__: Also: If `foo` and `bar` have the same types as before, `foo >>= put >> bar` has type `(MonadState A m, MonadReader R m) => m ()` and is much more likely to be what you intended.
17:20:41 <monochrom> Hell, even Wirth had wrote a paragraph in an anniversary article that he later hid away that said "the OS and hardware don't need to do memory space protection because supposedly every program has been proved to have no access violation".
17:21:28 <monochrom> But seeing that most programmers chose to be programmers precisely because they hate writing formal specifications and proving, meh.
17:22:24 <geekosaur> eh. not sure I'd say that so much as "chose not to be theoreticians"
17:22:46 <geekosaur> msot mechanics do't do formal specs and proving either
17:22:48 <Arahael> monochrom: I' not sure many of them ever start writing formal specifications at all.
17:25:27 <geekosaur> (I'mtempted to cite Volkswagen as an example of "more effort into covering up the mess than they'd have needed to do it right in the first place"
17:25:46 <monochrom> But mechanics have an excuse that programmers can't use.  Mechanics can do great without touching anything formal at all.  Programmers have to touch at least one thing formal: Their code.
17:27:14 <geekosaur> I used Volkswagen as an example for a reason: there tend to be regulatory "formal specs"
17:27:42 <Arahael> geekosaur: Software is no different there.
17:27:44 <geekosaur> granting that regulators' definitions of "formal" don't have much to do with a mathematician's definition
17:30:31 <monochrom> Perhaps Volkswagen hates regulations. :)
17:32:27 <monochrom> Some programmers of device driver exhibit similar behaviour.  Microsoft's DDK and possibly certification process too includes a technique coming from formal methods research to check some invariants of every device driver.
17:33:10 <dmwit> geekosaur: Depends on whether you amortize the cost over the other things where they took shortcuts and weren't caught.
17:33:40 <monochrom> Those some programmers respond by adding a boolean mode (think data Mode = Safe | Fast) to their device drivers.  Turn on the safe mode during certification.  Turn on the fast mode when shipping to you.
17:33:42 <dmwit> And we can't know how many of those there were (or else they would have been caught!).
17:34:03 <monochrom> (The fast mode is known to break the invariants left right and centre.)
17:34:42 <monochrom> The only difference from Volkswagen is that device drivers running in reckless fast modes don't cause more air pollution. (Oh wait.)
17:35:08 <geekosaur> no, they just cause more crashes. usually.
21:35:20 <mac10688> https://www.schoolofhaskell.com/school/to-infinity-and-beyond/pick-of-the-week/guide-to-ghc-extensions/explicit-forall
21:35:53 <mac10688> I really like this page. Anyone know of a book or online class that focuses on intermediate haskell concepts like this?
21:36:17 <mac10688> This page is good but I feel like I could use a lot more exercise in language extensions and types and stuff
21:37:00 <mac10688> I remember everyone used to say to use a CIS online class but the first problems I found seemed to only deal with haskell data structures and algorithms
22:14:42 --- mode: glguy set +v Viwor
22:15:04 <Viwor> wor> In parsec, <|> consumes the input, so I can't use it to parse either 'foo' or 'fuzz'. Anyone knows of another way to combine parser so that it would work?
22:15:57 <xacktm> there's a backtracking combinator iirc
22:17:13 <geekosaur> try (thing you want to backtrack) <|> ...
22:17:18 <xacktm> or lookahead, as it is http://book.realworldhaskell.org/read/using-parsec.html#parsec.lookahead
22:24:41 <Viwor> Thanks
22:33:30 --- mode: glguy set +v freefall
22:35:54 --- mode: glguy set +v freefallzhou
22:55:05 <Ariakenom_> How do you add fixity declarations to type operators?
22:56:56 <Ariakenom_> oh like normal worked now. I must've messed up my ghci paste
23:55:56 --- mode: glguy set +v Arin
