00:34:03 --- mode: glguy set +v onurer
01:50:55 --- mode: glguy set +v woodson
01:51:47 <woodson> Is it possible to fold the the output of a Conduit stream?
01:54:06 <akegalj> I am trying to figure out what is a difference between Generic derived instance vs Generic1 derived instance in example of `data Tree a` in https://hackage.haskell.org/package/base-4.12.0.0/docs/GHC-Generics.html#g:2
01:56:48 <akegalj> Generic1 example from https://hackage.haskell.org/package/base-4.12.0.0/docs/GHC-Generics.html#g:16
01:57:10 <merijn> woodson: Eh, sure?
01:57:21 <merijn> woodson: There's plenty of builtin fold combinators in the conduit library
01:58:13 <merijn> woodson: See the "consumers" section of Data.Conduit.Combinators
01:58:13 <woodson> merijn: Well, the problem that I am having it when using conduit's fold function it seems to just take the first value of my csv file
01:58:26 <woodson> however, I have 1000 lines and I am getting back only the first row
01:58:54 <woodson> It seems to sink the first line and stops from reading the other lines
02:08:25 <woodson> merijin: Here is an example https://lpaste.net/2078579513440075776
02:08:53 <woodson> The first function outputs the whole stream, however, the second functions just prints the first row
02:09:15 <woodson> I don't understand how it works
02:16:52 <merijn> I have no idea what mergeStream does, tbh
02:17:16 <woodson> merijn: sorry
02:17:18 <woodson> mergeStream :: Monad m => (Map Text Text  -> Map Text Text  -> Map Text Text ) -> Map Text Text  -> ConduitT (Map Text Text) o m (Map Text Text)
02:17:18 <woodson> mergeStream f x = CL.fold f x  
02:17:43 <woodson> its just fold from Data.Conduit.List      
02:19:00 <merijn> How are the CSV rows turned into Map's?
02:19:34 <woodson> http://hackage.haskell.org/package/csv-conduit
02:19:53 <woodson> with the function intoCSV
02:21:40 <merijn> Well, that makes sense then
02:21:56 <merijn> Every list gets turned into a Map with column headers as keys and contents as values
02:22:07 <merijn> Then those maps get combined via Map.union
02:22:38 <merijn> Except, "Map.union map1 map2" just does "keep every key-value in map1 and add any new keys from map2 to it"
02:22:56 <merijn> But map2 has the exact same keys as map1 (and so does every row), so just end up with the first row
02:23:36 <tsaka_> can this function be simplified or improved: https://lpaste.net/853772363810996224
02:23:56 <tsaka_> is the function description good
02:25:25 <tsaka_> perhaps it would better be named 'modifyPart'
02:32:42 <woodson> merijn: true, but I have another fuction that actually creates index based on some fields of the csv
02:32:54 <woodson> and I still only get the first row
02:34:32 <merijn> woodson: Try this: Before the fold map a function "Map Text Text -> Map Text [Text]" over the stream (turning it into a map of single element lists). Then, write your own fold, but instead of Map.union, use "Map.unionWith (++)"
02:37:21 <woodson> merijn: So something that folds all the Map Text Text value from the csv-conduit into Map Text [Text]?
02:37:34 <woodson> Just making sure I got exactly what you said
02:42:16 <merijn> woodson: First convert them to that, *then* fold with "Map.unionWith (++)"
03:03:12 <thyr15t0r> Hello World! This is my story. I need some GUI bells and whistles for my simple Haskell programs on Win7. All attempts to install wsHaskell + wsWidgets, gtk + gtk2xs, QT on ghci platform 8.4.3 were failed. Cabal returned tens of dependency errors on the installation request for any package Dependencies installs returned hundreds of new errors. It was The Great Cabal Tree Of Errors! I'm not a system guy, I'm cucumber. I just want to click install butt
03:03:13 <thyr15t0r> on and enjoing an installation autoprocess. After many solution schemes from google, I came to the conclusion that with the new platform all of the above is not compatible. In ancient book I read about GLUT. Probably this is the only way to make GUI on Windows. But the primitive program that does not do anything, only makes a colored window weighs 20mB! Haskell needs something like Delphi GUI drag and drop constructor
03:03:45 <thyr15t0r> *wx
03:03:53 <thyr15t0r> not ws
03:04:13 <thyr15t0r> *and gtk2hs sorry
03:30:32 <tsaka_> Any clue how to handle this error? https://lpaste.net/802888387311697920
03:30:49 <tsaka_> Creating and executing a MonadState inside other monads
03:33:20 <jle`> tsaka_: maybe try changing the type of fn to StateT EventGen m () ?
03:33:28 <jle`> as in, th etype annotation
03:33:35 <jle`> since that's the type it is inferring anyway
03:33:46 <jle`> at least now the 'm's ar ethe same
03:35:24 --- mode: ChanServ set +o glguy
03:36:31 <ski> looks like you need `instance Monad m => MonadRandom (StateT EventGen m)' ?
03:40:41 <tsaka_> jle`: Did not work
03:40:58 <tsaka_> ski: I have to implement that type class?
03:41:31 <tsaka_> is there another way to do it without using execStateT where I don't have to implement MonadRandom (StateT EventGen m)' ?
03:54:14 <tsaka_> :unmtl MonadRandom (StateT Bool (Reader Int))
03:54:34 <jle`> tsaka_: the instance should already exist
03:54:40 <tsaka_> @unmtl MonadRandom (StateT Bool (Reader Int) a)
03:54:40 <lambdabot> MonadRandom (Bool -> Int -> (a, Bool))
03:54:43 <jle`> so it's kinda weird
03:54:59 <jle`> is the error any different after making the change?
03:55:37 <jle`> tsaka_: what happens if you inline the definition of 'fn', or leave off the type signature?
03:56:40 <tsaka_> jle`: The error message stays exactly the same
03:58:12 <jle`> tsaka_: where is MonadRandom from?
03:58:32 <jle`> which import brings it into scope?
03:59:32 <jle`> the error message stays the same in all of those situations?
03:59:44 <tsaka_> jle`: Data.Random which is random-fu
04:01:18 <tsaka_> jle`: The error stays exactly the same with the sig:
04:01:19 <tsaka_>     fn :: (Monad m, MonadRandom (StateT EventGen m), MonadReader Opt m) =>  (StateT EventGen m) ()
04:01:34 <jle`> what if you leave off the sig completely
04:01:37 <jle`> or inline the definition
04:01:44 <piyush-kurur> when uploading documentation for a candidate package how does one create a documentation tarball ? cabal upload -d does not seem to work
04:01:54 <tsaka_> jle`: The error stays exactly the same in both of those situations
04:02:01 <jle`> tsaka_: ah hm.  are you sure you want random-fu's MonadRandom?
04:02:09 <cocreature> piyush-kurur: cabal haddock --for-hackage
04:02:15 <jle`> and not, say, MonadRandom's MonadRAndom ?
04:02:59 <jle`> monad-fu's MonadRandom isn't really compatible with transformers out of the box
04:03:56 <jle`> tsaka_: what are you expecting MonadRandom to be?  what do you think it is/what functionality do you think it offers?
04:04:00 <tsaka_> jle`: Do I have a choice, if the functions from random-fu depends on MonadRandom? Do they depend upon random-fu.MonadRandom in particular
04:04:21 <tsaka_> jle`: It allows be to use the functions from random-fu for generating random numbers
04:04:34 <jle`> ah okay, so you specifically want monad-fu's random number generation
04:04:46 <tsaka_> yes. Example: https://lpaste.net/6808149168528293888
04:05:06 <tsaka_> (ignore the comment in the paste)
04:05:07 <jle`> then yeah in that case, there is no type that is simultaneously an instance of MonadState s *and* MonadRandom
04:05:44 <jle`> that's the direct source of the error
04:06:06 <jle`> you can either give StateT an instance, or you can fix the type signature of generateNewEvent
04:06:33 <jle`> because the combination of constraints (MonadRandom m, MonadState s m) is not satisfiable by any type you have at the moment
04:07:14 <tsaka_> Can I import MonadRandom from that other package, will that help?
04:07:43 <cocreature> no
04:07:44 <jle`> probably not, since they are two unrelated types
04:07:49 <jle`> they only happen to have the same name by coincidence
04:08:14 <jle`> in any case it looks like random-fu makes it a little tricky to write new instances of random-fu's MonadRandom
04:09:54 <dmwit> Might be easier to make a MonadState s (RVarT (StateT s m)) instance.
04:10:01 <dmwit> uh
04:10:08 <dmwit> Depending on exactly what you're trying to do, I guess.
04:10:57 <jle`> you could use specific types instead of writing polymorphically
04:11:06 <dmwit> It's... a little tough to tell whether that's what you want or not from random-fu's documentation alone.
04:11:26 <dmwit> jle`: don't think that will help, will it?
04:11:32 <dmwit> You still need to write the instance.
04:11:32 <tombusby_> hi, let's say you have a big project (that doesn't use stack), what's the best way to get a GHCI prompt in a file (automatically handling all the deps)
04:11:47 <dmwit> tsaka_: Ah, I have a cunning plan.
04:11:55 <tsaka_> lets hear it
04:11:57 <merijn> tombusby_: "cabal repl" or "cabal new-repl"
04:12:05 <jle`> like have generateNewEvent be StateT s (ReaderT r (RVar m ())
04:12:11 <tombusby_> merijn: thanks
04:12:23 <jle`> er, with some swapped parentheses, no final m
04:12:33 <dmwit> tsaka_: False alarm. I reviewed the paste again and it won't work.
04:12:52 <tsaka_> I'm not bound to random-fu by any measure; I just need to sample from both the exponential and uniform distributions
04:12:57 <dmwit> jle`: But that still won't have a MonadRandom instance, which presumably they're actually using.
04:13:10 <deltasquared> heh, random thought, what's the longest stack of monad transformers anyone here has seen
04:13:12 <jle`> yeah
04:13:36 <jle`> but it might make the code 'work' in the end
04:13:40 <dmwit> deltasquared: long
04:13:51 <jle`> and you could lift all your MonadRandom functions with lift.lift
04:13:58 <deltasquared> dmwit: no example? :P
04:14:34 <dmwit> deltasquared: Let me illustrate for you why the question is impossible to answer correctly: how many characters was the longest line of code you ever saw?
04:14:46 <dmwit> jle`: ugh. I'd rather write the MonadRandom instance. =P
04:14:50 <merijn> dmwit: 300+ >.>
04:14:51 <cocreature> dmwit: OVER 9000!
04:15:08 <deltasquared> dmwit: ... huh, good point, I think it was ~150 columns
04:15:10 <dmwit> tsaka_: I don't know. Personally I'd just implement MonadRandom following the documentation's advice.
04:15:18 <dmwit> deltasquared: WHAT, NO EXAMPLE?
04:15:21 <AWizzArd> cocreature: and nearly all of it was literal data?
04:15:32 <deltasquared> dmwit: ok I see now, I can't remember where it was either xD
04:16:03 <cocreature> AWizzArd: I’m just making stupid jokes, don’t take me seriously :)
04:16:08 <deltasquared> my brain is telling me in some lua code... but yeah, I get it, no real clue
04:16:09 <jle`> dmwit: too bad all of the methods are hidden behind export lists :O
04:16:51 <dmwit> jle`: http://hackage.haskell.org/package/random-source-0.3.0.6/docs/Data-Random-Internal-Source.html#t:MonadRandom ?
04:17:22 <cocreature> to suggest that users use TH to implement instances seems really weird
04:17:23 <jle`> ah i see
04:17:32 <jle`> i guess random-fu doesn't re-export methods
04:20:45 <dmwit> tsaka_: As a side note, I'm sorry this has been such a nightmare for you. Seems like this is a pretty simple thing and you've been at it days already, and that doesn't seem to be because you're stupid or not trying -- this is just a pretty rough corner of the language to encounter on your first go at a program.
04:21:23 <deltasquared> dmwit: out of curiosity, I didn't see the context, what's the rough corner (if only so I could be aware of it myself)
04:22:01 <dmwit> Mixing monads correctly is pretty tough if it's your first time.
04:22:41 <deltasquared> well they're doing better than me then, monad transformers are still a little tricky for me
04:23:09 <deltasquared> I think I'm starting to get them in a rather vague way, just not how they really work.
04:24:20 <tsaka_> yes, it can get confusing all right
04:24:31 <dmwit> It wouldn't be so bad for tsaka_ if people didn't hate orphan instances so much.
04:25:42 <dmwit> Then we could and probably would have a library to point to that already had MonadRandom instances for the transformers types.
04:25:45 <deltasquared> my brain says probably wrapping types to contain extra "values" and wrapping >>= and >> appropriately... I will have to take another stare at some instances later
04:26:20 <merijn> hmm, does anyone know if there's a library for querying the hostname of the current machine?
04:26:37 <hpc> system "hostname"?
04:26:43 <hpc> or cat /etc/hostname?
04:26:45 <merijn> hpc: That was my backup plan, yes
04:26:53 <cocreature> dmwit: to make matters worse, at least the git version actually does have an instance for StateT but not the one that you would want here https://github.com/mokus0/random-fu/blob/master/random-source/src/Data/Random/Source/PureMT.hs#L83
04:27:21 <merijn> Honestly, I find MonadRandom kinda confusing and usually just use mwc-random directly
04:27:33 <hpc> oh, in C it's man 2 gethostname
04:27:33 <deltasquared> alas even in linux I guess you'd have to poke somewhere in /proc... as for windows... some corner of the win32 api I guess.
04:27:37 <dmwit> cocreature: Oh, what, that's terrible!
04:27:38 <hpc> maybe a cheeky bit of ffi?
04:27:41 <jle`> yeah, mwc-random works well because it just uses PrimMonad built into haskell
04:27:42 <deltasquared> oh, there's s system call? huh
04:27:51 <merijn> deltasquared: Luckily I only have to care about *nix :)
04:27:52 <jle`> and it also has staistical support with 'statistics'
04:28:00 <dmwit> cocreature: That seems like it would defeat the whole purpose of having MonadRandom in the first place, as a distinct entity from MonadState.
04:28:02 <deltasquared> merijn: oh, lucky for you :P
04:28:15 <merijn> hpc: gethostname has a super obnoxious API, though :p
04:28:35 <deltasquared> oh, it's a buffer write, how awkward
04:28:36 <merijn> Maybe unix has it
04:29:02 <deltasquared> well that's annoying, you'd need a retry loop with bigger buffers I guess
04:29:12 <cocreature> dmwit: yeah this is just really confusing
04:29:31 <deltasquared> another thing on my checklist, writing custom IO actions
04:29:45 <deltasquared> (that use FFI that is)
04:30:07 <merijn> deltasquared: Assuming you know the basics of C and compilation/linking that's super easy
04:30:23 <merijn> deltasquared: Start with Chapter 8 of the Haskell Report and the GHC user guide on the FFI.
04:30:38 <dmwit> merijn: very imaginatively named: https://hackage.haskell.org/package/hostname-1.0/docs/Network-HostName.html
04:31:34 <deltasquared> merijn: haskell 2010 language report, section 8, foreign function interface - looks promising, ok I'll read this
04:31:43 <dmwit> deltasquared: You might like to poke at the source of that package, too; it looks like a great intro to FFI programming and handles both Windows and nixes.
04:32:07 <dmwit> Short and simple, but still has to deal with all the annoying bits.
04:32:44 <deltasquared> dmwit: what's that, hostname?
04:32:53 <deltasquared> I'll chuck it at cabal unpack for later
04:33:01 <merijn> The FFI has fairly few annoying bits. The only things that are really obnoxious is: 1) writing Storable instances for C structs and 2) dealing with code that passes structs by value. But if you can manage to not deal with those it's fine
04:33:25 <dmwit> Oh yeah, no struct management in the hostname package, so you don't get to see that.
04:33:34 <cocreature> also FFIing to C++, especially somewhat modern C++, is a nightmare
04:33:37 <dmwit> Forgot about how annoying those are.
04:34:24 <deltasquared> cocreature: I would probably avoid that really hard unless the lib is purely C++ and I had to use it...
04:34:33 <deltasquared> I'd probably just write some extern "C" wrappers in that case
04:34:34 <dmwit> When I said "annoying bits" what I meant was the things I find annoying about C: manual memory management, making up buffer sizes and being forced to recover if you guessed wrong, that kind of thing.
04:35:30 <deltasquared> dmwit: hence why I regard C as (mostly) portable assembler.
04:35:42 <merijn> deltasquared: It's really terrible at that, though
04:35:49 <deltasquared> merijn: why, all the UB?
04:36:24 <merijn> deltasquared: That and the fact that everyone *thinks* they know what kinda assembly gets produced from C and how it executes on modern hardware. Spoiler: They don't
04:36:37 <merijn> The asm generated from your C code looks *nothing* like what you'd expect
04:37:27 <deltasquared> merijn: I don't claim that I would know the asm produced, I just work in terms of what C says it'll do (within the bounds of -std=c89 -pedantic -Wall -Werror that is...)
04:37:36 <hpc> deltasquared: what compilers do with UB is detect it, then work backwards to see if it can make the UB not happen
04:37:48 <hpc> deltasquared: then it just assumes that when generating the rest of the machine code
04:37:54 <deltasquared> I have been outsmarted by the optimiser on several occasions, in particular playing around with some SIMD stuff...
04:38:15 <deltasquared> I thought it wasn't doing what I wanted, only to realise it was doing something better
04:38:28 <hpc> you can use UB to do things like call functions that are seemingly never used in the source code
04:38:58 <deltasquared> hpc: not used as in non-taken branch, or as in not even mentioned
04:39:06 <hpc> not even mentioned
04:39:09 <deltasquared> oof
04:39:11 <deltasquared> that's a new one
04:39:35 <hpc> and you get zero help in avoiding UB, because it's everywhere
04:39:41 <hpc> even addition and subtraction have UB
04:39:47 <hpc> (overflows)
04:39:51 <deltasquared> hpc: signed overflow? g'argh
04:39:52 <nshepperd> the compiler assumes that you're a deity who only ever writes code with UB in order to signal something to the compiler, and works from there
04:40:29 <hpc> this is why rust advertises no UB so aggressively
04:40:32 <deltasquared> signed overflow is one case where I'd whack the compiler with that -f flag that says to treat signed arithmetic as wrapping...
04:40:44 <merijn> hpc: UB is a dumbass idea anyway
04:40:46 <hpc> even languages with exceptions would rather just throw one
04:41:00 <hpc> when your language is worse for /not/ having exceptions, you done screwed up
04:41:21 <deltasquared> it's apparently in the name of utmost performance first, though...
04:41:47 <deltasquared> apparently lacking quotes because they'd be planet sized and would therefore not fit on screen
04:42:09 <hpc> it's only in the name of having a high upper limit on speed
04:42:20 <hpc> even the linux kernel is still finding 40% speed improvements all over the place
04:42:36 <deltasquared> crank the optimiser up and... oops, another UB
04:42:43 <hpc> average case speed is what matters, because programmers are on average...
04:42:44 <hpc> well
04:42:45 <hpc> average
04:43:17 <deltasquared> I do agree that C is full of holes, and C++ just inherited them. I guess that's why we're all here though, using haskell for anything sane ;)
04:43:27 <hpc> same way when you're writing your own algorithms, average complexity is what matters
04:43:35 <tdammers> "average case speed = average speed across typical case distribution" is also a common fallacy
04:43:45 <hpc> who cares if bubblesort is O(n) fastest case, if it's hot garbage every other time
04:44:07 <hpc> tdammers: on average that's true though :P
04:44:18 <deltasquared> hpc: hence why I don't worry about performance too much in haskell. we can certainly control algorithmic complexity in it just fine, if not better
04:44:19 <dmwit> You say, "compilers work backwards to see if it can make the UB not happen". But that's not my experience. My experience is the compiler tries really hard to steer you into the UB path, because then it can do whatever the hell it wants and it likes freestyling with your assembly as a medium.
04:44:20 <Ariakenom_> hey! worst case is important too
04:44:23 <tdammers> hashmaps are O(1) average case, but it only takes one malicious input to make it go "whoops"
04:45:00 <deltasquared> tdammers: whoops as in overwrite or error?
04:45:19 <tdammers> deltasquared: whoops as in turn O(n)
04:45:30 <tdammers> a.k.a. the HashDoS attack
04:45:35 <deltasquared> tdammers: because of a linked list in a bucket slot?
04:45:45 <cocreature> n almost looks like 1 if you stare at it from far enough away
04:46:12 <hpc> that's why i write all of my algorithms to take exponential time
04:46:17 <hpc> for speed
04:46:24 <tdammers> yes. the attack is simple: just craft inputs such that all keys have the same hash, now your fancy hashmap is just a plain old linked list (or dynamic array or whatever) with everything in a single bucket
04:46:32 <philippD> Is there a library for dealing with Higer-Kinded-Datatypes/Functor-Functors?
04:46:56 <tdammers> you can typically take down a server with just a few thousand keys this way
04:47:15 <Ariakenom> O(n) = O(n*1e-30) and n1e-30 is honestly probably less than one. math-ed
04:47:40 <hpc> there's an algorithm with a complexity that people just call O(4)
04:48:01 <deltasquared> hpc: I'm going to guess that doesn't mean O(1)
04:48:02 <hpc> it's O(A^-1(n)) or something like that
04:48:22 <phadej> philippD: http://hackage.haskell.org/package/rank2classes might be what you are looking for
04:48:28 <hpc> technically it gets slower for large input, but you'd have to exceed the mass of the universe for it to take particularly long
04:48:55 <[exa]> hpc: inverse ackermann was in some kind of amortized tree-algorithm complexity? (pls remind me)
04:49:06 <cocreature> [exa]: union find iirc
04:49:10 <[exa]> aaaaaah yes
04:49:32 <hpc> yep, https://en.wikipedia.org/wiki/Disjoint-set_data_structure#Time_complexity
04:49:44 <philippD> thanks phadej
04:50:17 <deltasquared> I prefer to break the universe by conjuring up Void personally :P from a talk I watched about Contravariant and co recently, the running joke was when Void appeared that you'd broken the universe somehow if that ever actually ran
04:51:18 <cocreature> x :: Void; x = x
04:51:19 <cocreature> done
04:51:26 <cocreature> poor universe
04:51:39 <deltasquared> mr. haskell, I don't feel so good.... *disintegrates*
04:52:11 <hpc> totally new definition of snap framework
04:52:17 <deltasquared> ah, I think this is the talk - https://youtu.be/IJ_bVVsQhvc
04:52:19 <nshepperd> do not conjure up that which that which you can conjure up cannot put down
04:53:04 <deltasquared> nshepperd: but then if you do have something stronger for the original thing, how do you take care of the stronger thing
04:54:08 <nshepperd> it's horrorterrors all the way up
04:54:26 <deltasquared> nshepperd: I'll be in my cthulhu bunker
04:55:28 <__monty__> nshepperd: Sounds like one too little levels though. Because you might be able to conjure something up that can put down the thing you're about to conjure up but you don't require that hypothetical thing to be possibly put down by something that could be put down.
04:56:15 <deltasquared> __monty__: when conjuring one should always have insurance! :P
05:01:16 * deltasquared looks at Hostname.hs
05:01:24 <deltasquared> well, that's actually delightfully straightforward
05:02:00 <deltasquared> already neatly wraps the bare foreign function for you in IO if unsafe, I wasn't quite sure how that was going to work
05:03:08 <thyr15t0r> Hello world. Did you read my story?
05:06:06 <merijn> deltasquared: Like I said, calling simple (i.e. not taking structs as "by value" arguments) C code is super easy
05:06:24 <thyr15t0r> Hello World! This is my story. I need some GUI bells and whistles for my simple Haskell programs on Win7. All attempts to install wxHaskell + wxWidgets, gtk + gtk2hs+Glade, QT on ghci platform 8.4.3 were failed. Cabal returned tens of dependency errors on the installation request for any package. Dependencies installs returned hundreds of new errors. It was The Great Cabal Tree Of Errors! I'm not a system guy, I'm cucumber. I just want to click insta
05:06:24 <thyr15t0r> ll button and enjoing an installation autoprocess. After many solution schemes from google, I came to the conclusion that with the new platform all of the above is not compatible. In ancient book I read about GLUT. Probably this is the only way to make GUI on Windows. But the primitive program that does not do anything, only makes a colored window weighs 20mB! Haskell needs something like Delphi GUI drag and drop constructor. Give me advice please
05:08:38 <cocreature> thyr15t0r: afaik haskell-gi should work on windows but I have not tried it myself (for the simple reason that I don’t use windows)
05:08:44 <cocreature> https://github.com/haskell-gi/haskell-gi/wiki/Using-haskell-gi-in-Windows might be helpful
05:09:11 <cocreature> although I would probably use 8.4 instead of < 8.2 that looks a bit outdated.
05:09:39 <thyr15t0r> <cocreature> is latest version of Haskell platform supported?
05:11:10 <cocreature> at least ghc 8.4 is supported in general by haskell-gi. I don’t know about the windows specifics but I wouldn’t expect this to make a difference here
05:11:36 <thyr15t0r> thank you and bless
05:11:53 <thyr15t0r> went to try
05:20:27 <davr0s> just writing octree generation, poly clipping stuff. this is still taking me a lot longer than in c++. very satisfying to write though.   looking back at what i wrote, it seems like it should be possible to make it n-dimensional via some sort of nested split node + vector type,  (e.g. same codepath is a 2d quadree, 3d octree , or .. ) .. anyone done that sort of thing, in particular i've ended up writing helpers for
05:20:27 <davr0s>  maps/folds of 2d, 3d nested traversables
05:20:40 <davr0s> the 'nested traversables' sound like a much more common case
05:24:41 * Ariakenom looks through kmett packages
05:24:59 <Ariakenom> davr0s: this has vectors, maybe it's interesting https://hackage.haskell.org/package/linear
05:25:15 <deltasquared> davr0s: octree generation as in you load up a mesh and voxellate it essentially?
05:25:25 <davr0s> deltasquared yes. tree of 2x2x2 splits.
05:25:59 <deltasquared> intradesting
05:26:18 <davr0s> clipping into the cells, contrasted with 'bounding volume heirachies' which i usually use to avoid clipping geometry.
05:26:39 <davr0s> these days hardware does the clipping..   i just wanted to work through these tasks in haskell
05:26:47 <deltasquared> haven't looked a lot at triangle/polygon intersection much. I feel it'd be somewhat O(number_triangles_in_volume) at each level...
05:27:00 <deltasquared> davr0s: nothing wrong with learning ;)
05:27:17 <davr0s> octree = divide-and-conquer approach
05:27:41 <deltasquared> davr0s: I know what an octree is; just not how to convert a triangle-based mesh into one :P
05:28:02 <deltasquared> though it seems relatively simple on the outside. famous last words
05:28:23 <davr0s> ah well similarly, you can use a divide and conquer approach. start with your bounds, split it into 2x2x2,  recurse..
05:28:38 <ventonegro> My wild guess is that you measure the gradient of the normal vectors
05:29:18 <davr0s> now of course you might have heard recursive, trees etc have fallen out of favour becaue of cache behaviour. it's more common to do something simpler like divide a world into a single high level grid with flat lists inside each cell.. shallow approach. 
05:29:46 <davr0s> in all the guides on 'writing voxel enignes'... they always point out .. octrees are what most people go for, and they're not the best way on modern hardware :)
05:31:53 <davr0s> maybe next up will be BSP and trying to use that to implement CSG operations, the split generation is a bit simpler (again i'm looking at it wondering if haskell's greater agility with types will let me make some sort of  Tree split_container leaf    (plugin 'plane/front/back', or '2x2x2 (octee node) ..
05:32:15 <phadej> for csg there is https://github.com/dzhus/csg#readme
05:32:18 <davr0s> people have done things like octrees with nested BSP leaves and so on
05:32:40 <davr0s> right I figured that would definitely exist already . 
05:33:19 <davr0s> it would be interesting to mess with slicing for 3d printing (how to orient the components.. figure out the orientations wiht fewest artefacts)
05:34:45 <davr0s> one little point of pain reduction i found  was the   foo@Baz a b  stuff for destructuring and keeping the original. i was always finding it a PITA losing the c/c++   "foo.a" to get fields, this is a bit more useable
05:35:01 <davr0s> and i  continue to buzz irationally about "where"
05:35:10 <phadej> davr0s: learn lenses :)
05:38:07 <Cale> Note also that if you define your type using record syntax, you can use the field selectors that get defined for you.
05:38:32 <Cale> which, dependning on how you expect things to change in the future, might be more sensible than pattern matching sometimes
05:38:43 <davr0s> right i have been using that a bit, and i do see the utility in haveing accesor *functions* hence the tradeoffs elsewhere
05:38:56 <davr0s> (i am aware lenses does all that on steroids)
05:39:17 <cocreature> davr0s: it’s not so much a tradeoff, you still can use pattern matching even if you have accessor functions
05:39:25 <cocreature> it just adds another way of accessing fields
05:39:39 <Cale> I suppose it takes some getting used to that you can't reuse field names, but it's really not the worst thing.
05:39:47 <deltasquared> Cale: certainly it seems that record selectors would induce less coupling than destructuring would.
05:40:29 <Cale> deltasquared: Yeah, if you expect additional fields to be added to the record type, it'll just be a bit less work in the future
05:40:29 <Younder> When is pattern matching done at compile time?
05:40:38 <cocreature> one thing to keep in mind is that record accessors on sumtypes are partial
05:40:44 <davr0s> cocreature  i mean tradeoff vs C++ style fields
05:40:57 <cocreature> Younder: GHC has a case-of-known-constructor optimization if that is what you mean
05:41:03 <davr0s> not tradeoff between pattern matching and field syntax - i see you can do those simultaneously
05:41:58 <davr0s> i must say i'm favouring trying to keep the types small with bits that are plug-inable but i'll see how far that serves me
05:42:14 <Cale> Another thing I've been pondering lately is that Haskell's best extensible record system might be DMap.
05:42:26 <ggole> Runtime failure seems like the price you have to pay for field access being a function
05:42:29 <deltasquared> Cale: not one I'm familiar with
05:42:36 <ggole> If field access is primitive it's quite easy to avoid the problem entirely
05:42:49 <Cale> http://hackage.haskell.org/package/dependent-map
05:43:03 <deltasquared> ggole: why, I don't see how a record access could fail
05:43:22 <cocreature> deltasquared: data X = A { a :: Int } | B { b :: Bool }
05:43:39 <cocreature> ggole: I’m not sure how you would make it a primitive in a way that avoids the failure
05:43:49 <deltasquared> oh, sum types. well, I personally would avoid it in that case
05:43:50 <Cale> Usually people don't think of it as such, but it basically is. You define a GADT explaining what your fields and their types are, and then you have a library full of all the Map-like operations for working with these things.
05:43:55 <ggole> Prelude> data Foo = Z | S {x :: Int} Prelude> x Z *** Exception: No match in record selector x
05:44:10 <ggole> cocreature: as in OCaml or SML
05:44:20 <davr0s> it's so much fun
05:44:27 <cocreature> ggole: not knowing ocaml or sml this doesn’t tell me much :)
05:44:33 <davr0s> probably insulting to call haskell a toy
05:44:47 <davr0s> but it's existance is justified at the very least by how much fun it is
05:45:04 <ggole> cocreature: the record is local to the constructor
05:45:24 <ggole> eg, you match on the constructor and get a record type that can't escape.
05:45:24 <Cale> ggole: My solution has been to simply never ever use record syntax for types with multiple constructors.
05:45:32 <cocreature> ggole: ah I see!
05:45:54 <ggole> Cale: that seems like a sensible choice for Haskell, yes
05:46:11 <Younder> As long as there are QUANTS Haskell will be more than just a toy.
05:46:37 <cocreature> Cale: the annoying part about that is that it forces you to come up with two constructor names, it introduces an additional level of syntactic nesting and without unpacking it also introduces an additional runtime indirection
05:47:07 <ggole> It's quite nice to be able to have many names and only care about a few of them when matching, too
05:47:09 <Cale> cocreature: hm?
05:47:21 <Boomerang> % data A = A { a :: Bool } | B { a :: Bool }
05:47:21 <yahb> Boomerang: 
05:47:23 <Cale> cocreature: about what? Not using record syntax for sum types?
05:47:26 <Boomerang> % :t a
05:47:26 <yahb> Boomerang: A -> Bool
05:48:07 <cocreature> Cale: using "data X = A { a :: Int } | B { b :: Bool }" vs "data A = A { a :: Int }; data B = B { b :: Bool }; data X = A' A | B' B"
05:48:38 <deltasquared> I would personally get around it by defining the sum type parts separately with record accessors then requiring to match into the outer sum type.
05:48:52 <deltasquared> at least then the only failure would be in failing to handle a new branch that comes along
05:48:56 <Cale> Oh, well, if you really want the record syntax, that's a better option than the first one at least.
05:49:00 <deltasquared> (branch of the sum type that is)
05:49:17 <Cale> But depending on the situation, I probably would forego record syntax entirely.
05:49:30 <cocreature> it depends on why you are using record syntax. my primary reason for using record syntax is documentation and in that case the second option introduces a lot of overhead for that
05:50:14 <Cale> Having documentation in the form of a bunch of functions that crash your program if you use them isn't so handy imo ;)
05:50:53 <cocreature> right neither option is satisfying
05:51:10 <cocreature> there is a ghc proposal for disabling the generation of accessor functions, that would help for my usecase
05:52:04 <Cale> It might be worthwhile to define  data X = A Int | B Bool, and then define a :: X -> Maybe Int and b :: X -> Maybe Bool
05:52:15 <ggole> You could probably keep them for single constructor types
05:52:19 <Cale> Or, you know, appropriate prisms.
05:52:32 <ggole> It seems pretty common to use newtypes that way
05:53:03 <Cale> You get the same sort of documentation then, but without needing dangerous partial functions, and you haven't made it any more annoying to construct the things.
05:53:39 <cocreature> Cale: but now you can’t use record syntax in pattern matches and to construct values which is really annoying if you have say > 5 fields
05:54:05 <merijn> Cale: I think record syntax without accessors should be possible
05:54:31 <merijn> Cale: I often want record syntax so I can have readable patterns and know what fields are, but not want the same fields for each constructor
05:54:53 <merijn> Cale: The only reason we even demand a field exists for all constructors is partial accessors, but often times I don't use those anyway
05:55:18 <davr0s> one thing that's offputting about using anything else (than c/c++) is going through bindings for <libraries like gl> .. but it shouldn't be a showstopper
05:55:21 <cocreature> merijn: sounds like you also might like https://github.com/reactormonk/ghc-proposals/blob/master/proposals/0000-no-toplevel-field-selectors.rst :)
05:55:22 <merijn> cocreature: oh, sweet. Someone wrote up a proposal for that?
05:55:38 <davr0s> e.g. even learning a new load of wrappers for file io etc et c
05:55:56 <davr0s> but once one is inside haskell generating stuff.. (and now i see parsing too) , it's awesome.
05:56:12 <deltasquared> davr0s: speaking of gl, had a look at LambdaCube? declarative config of rendering pipelines and then you just generate some triangle list from pure code, in theory. looks pretty neat
05:56:24 <davr0s> (what i'm doing at the miniute is just spitting files out and spawning an external viewer.)
05:56:52 <davr0s> deltasquared that sounds really nice, and I was always interested to try something similar
05:57:27 <davr0s> it did seem to me you should be able to write code that can generate shaders
05:57:31 <Cale> Oh, here's a strange idea I had the other day: it would be nice to have an extension that let you define record fields whose content would be ignored entirely (perhaps parsed, but not even reference checked or typechecked)
05:57:39 <deltasquared> davr0s: I kinda wanted to learn openGL the imperative way first. needed to solidfy my conceptual knowledge of the pipeline.
05:58:12 <deltasquared> Cale: what use would that be, genuine question
05:58:42 <davr0s> the thing about gl is it's very stateful hence error prone, i guess building abstractions around it that track what you change etc could be great and i do often end up wrapping it in c++ a bit
05:59:07 <deltasquared> davr0s: my understanding is lambdacube abstracts just that, the state management.
05:59:25 <Cale> deltasquared: Being able to package code intended for both the backend and frontend of a web application together :)
05:59:31 <davr0s> openGL also seems to be on the way out (perf reasons)   so it's feasible that each language gets it's native graphics wrappers (developped on GL but then swap in Vulkan / Metal / D3D...)
05:59:47 <davr0s> the Rust commnunity is trying to go that way i think
06:00:05 <deltasquared> davr0s: ... except for all the existing platforms out there that won't be getting vulkan
06:00:34 <davr0s> deltasquared  i think this is going to be horrific: because some platforms are *losing* GL support.
06:00:46 <davr0s> i.e. apple. (-> iphones, macs)
06:00:52 <Younder> Vulcan? Isn't that just a more primitive OpenGl?
06:01:05 <Cale> i.e. sometimes it would be nice to be able to define application code all in one module, but certain concerns are really only relevant on the backend, and the dependencies they induce are unacceptable on the frontend
06:01:13 <davr0s> so basically "a language graphics wrapper" mapping to <platform graphics> would actually be a really good way to go
06:01:16 <deltasquared> Younder: spelt with a k ;) and, for the most part yes
06:02:07 <Cale> (while the backend usually can understand everything)
06:02:20 <davr0s> Younder yeah good description,   it's needed because GL's interface is really hard to make performant, becaues it needs to track and check so many states. Vulkan makes you present that upfront. it's more work to use, but can decimate CPU overhead
06:02:44 <Younder> I see
06:03:24 <davr0s> things like shaders.. they sometimes need to be patched to fit the runtime states.the runtime must figure this out eg lazily, but still has to keep some dynamic code for that
06:03:36 <davr0s> what vulkan relies on is precomputing all that, explicitely
06:04:06 <Cale> If we had such an ignored-field feature, we could define a data type which packaged together certain frontend components (in our case, reflex-dom widgets) with certain supporting code for the backend (stuff that would be used to interact with a database, for instance), and that might let us slice up our applications in a new way that currently is quite difficult.
06:05:13 <deltasquared> Cale: I have to say I suspect what you're thinking of is beyond my knowledge >_<
06:06:02 <kvda> Is there something inherently special about * -> * types?
06:06:13 <merijn> kvda: Not particularly
06:06:30 <Cale> hah, I was typing *exactly* the same thing as merijn 
06:06:47 <deltasquared> kvda: * -> * just says it's a type which needs a type parameter.
06:07:02 <kvda> merijn Although Functors -> A functors -> Monads chain seems to work with them
06:07:16 <deltasquared> it's sorta like a kind-level function from a type to another type in that respect, though no need to worry about that too much
06:07:16 <kvda> *exclusively with them
06:07:21 <merijn> kvda: That's a property of functors, not a property of types of kind "* -> *", though
06:07:32 <Cale> kvda: Yeah, those concepts all apply to specific types of kind * -> *
06:07:51 <merijn> kvda: Not all types of kind "* -> *" can be functors
06:07:52 <deltasquared> when I realised that * -> * indicated a type level function my brain imploded
06:08:18 <kvda> So it seems they are special Cale ? It seems a to be a way to control complexity to me. ie keep in on sum types vs product types
06:08:19 <deltasquared> :kind Maybe
06:08:27 <deltasquared> :k Maybe
06:08:28 <lambdabot> * -> *
06:09:14 <Cale> kvda: Well, depends on what you mean by "special" -- it's a common enough thing that we have some abstractions for patterns that arise in working with such types
06:09:43 <EvanR> if by special you mean very common hah
06:10:05 <Cale> kvda: But there's nothing inherently magical about * -> * in particular, or really any of those abstractions -- they just try to capture certain things that come up repeatedly.
06:10:32 <kvda> common might've been the better word to use, but it is special in enabling functors to happen, no?
06:11:10 <kvda> ie. we might be writing more complicated types, and lose compasiblity if functors didn't force them to the * -> * kinds
06:11:47 <Cale> I dunno. I guess Functor as an abstraction is a pretty nice idea.
06:12:34 <Cale> But really all it comes down to is that there isn't enough code that uses types of kind (* -> *) -> * or something for there to be many already-existing abstractions around that.
06:12:50 <Cale> There are lots of classes for types of kind * though -- more than exist for * -> *
06:14:38 <kvda> I see what you're saying, good point Cale 
06:14:58 <Cale> fwiw, I'm currently working on a whole ecosystem of types of kind (* -> *) -> * because it turns out that types that are parameterised by a choice of functor are really useful when you want to be able to express queries and responses to those queries using the same data type.
06:15:17 <deltasquared> Cale: link?
06:15:20 <deltasquared> if any
06:15:25 <Cale> It's not open source yet
06:15:35 <deltasquared> oh, so that's a Nothing response then ;)
06:15:38 <Cale> But soon :)
06:15:44 <deltasquared> well, not quite. /badjoke
06:16:27 <davr0s> anyone know off hand how to express a type constrant that a pair of two types can be multiplied yielding a specific output,     in particular i need    a*b->a
06:16:40 <Cale> The idea is that you have data types which apply a choice of functor at the "leaves", so that by applying it to Proxy, you get something which is effectively like a "blank form" to be filled in, and by applying it to Identity, you get something that holds actual values.
06:17:08 <davr0s> fundeps rings a bell but i think that was in typeclasses o somethgn (allowing c++ style 'matirx *matrix ... matrix*vector' but i dont need *that* right now
06:17:38 <Cale> and then for instance, using Compose (Map k) Proxy, you can hold many requests together, and Compose (Map k) Identity, you can hold all the responses.
06:17:57 <deltasquared> Cale: so (* -> *) -> *, a type constructor taking another type constructor... that sounds a bit like C++'s "template template" arguments
06:18:05 <Cale> yeah
06:18:17 <deltasquared> oh good, glad I actually understand a little xD
06:18:48 <Cale> and then I have this type which I call Vessel, which is effectively a map structure whose keys are indexed on a type of kind (* -> *) -> *, and whose values are containers of that sort.
06:19:04 <Cale> (whichever sort is indicated by the index type on the key)
06:19:20 <Cale> So, Vessel :: (((* -> *) -> *) -> *) -> (* -> *) -> *
06:19:32 <deltasquared> good heavens
06:19:32 <dmwit> davr0s: class Prod a b where prod :: a -> b -> a -- ?
06:19:35 <Cale> haha
06:19:52 <davr0s> that looks right
06:19:59 <deltasquared> Cale: shoot me a link when that's up, I'd have to have some code to stare at for a while for it to sink in
06:19:59 <Cale> deltasquared: and I'm going to use this to build network protocols for our applications
06:20:03 <deltasquared> ooooh
06:20:25 <deltasquared> only problem with haskell, sometimes you have to sit and stare for a while because of the amount of info contained in such a short space
06:20:58 <deltasquared> I was sat working through the Applicative laws for 15 minutes by substituting types before it clicked
06:21:33 <deltasquared> anyways, gtg lunch, afk
06:21:36 <Cale> The idea is that since Vessel is itself a functor-indexed container, we can nest Vessels, and by appropriate construction of key GADTs, we can define all the sorts of information that frontend widgets might be interested in receiving updates on from the backend.
06:21:55 <dmwit> davr0s: https://ocharles.org.uk/blog/posts/2013-12-02-24-days-of-hackage-linear.html may be of interest to you
06:21:59 <Cale> So the frontend will produce a Vessel k Proxy, for some appropriate choice of k
06:22:14 <Cale> and then the backend will aggregate all of these for different users
06:23:15 <Cale> and produce a Vessel k (Compose (Map ClientKey) Proxy), which can then be used when notifications come in from the database to determine who is interested in receiving an update
06:23:25 <Cale> and then the updates themselves have type Vessel k Identity
06:24:01 <Cale> and there are Monoid and Semigroup instances that allow us to combine these views of data
06:24:20 <davr0s> dmwit one thing i've used in anger in the past (and which does recur) is matrices with different types for the 'axxes' and 'centre' e.g more precision for the object centres. again not so common today but there's increasing support for f16 types. (f64 ? f32? f16? ).   Most of the time in the present era "i just use f32 all over the place,but f16 or other in meshes to be consumed by the GPU.." 
06:34:45 --- mode: glguy set +v freetheorem
06:41:51 --- mode: glguy set +v freetheorem_
06:44:34 --- mode: glguy set -v freetheorem
06:44:34 --- mode: glguy set -v freetheorem_
06:56:13 --- mode: glguy set +v tenniscp25
06:59:08 <tenniscp25> is it possible to use aeson to encode haskell Map to json object without deriving ToJSON on a newtype?
07:00:40 --- mode: glguy set -v tenniscp25
07:01:40 <cocreature> tenniscp25: yes, there already is a ToJSON instance for Map
07:02:36 --- mode: glguy set +v av
07:06:04 <tenniscp25> @cocreature thanks
07:06:04 <lambdabot> Unknown command, try @list
07:06:28 <tenniscp25> thanks, cocreature
08:03:59 <davr0s> is there somethng like 'functor' for a class holding 2 types (i'm just googling about 'Either')  e.g. somethign that you'd 'fmap' with 2 functions, i guess.
08:04:15 <phadej> pair?
08:04:23 <phadej> :t bimap
08:04:24 <davr0s> Bifunctor 
08:04:24 <lambdabot> Bifunctor p => (a -> b) -> (c -> d) -> p a c -> p b d
08:04:33 <phadej> ah, class,not type
08:06:39 <davr0s> bifunctor looks exactly like what i wanted, what i'm trying to do (attempt 1 has failed by running into generic instances clashing)   is  a semantically meaningful wrapper for a type, with a second,  to be combined into a list.   (i hasten to add ,i can acheive what i want by simpler means..)   
08:07:44 <davr0s> eg   type MyVertex =   Position (Vector3Float (TexCoord Vector2Float  (Normal  Vector3Float  Terminate)))
08:08:06 <davr0s> .. so i'd implement some stuff that recurses the type until it reaches 'Terminate'
08:09:20 <davr0s> it might be overkill because data-driven stuff wouldn't work this way. there'd be seperated buffers (independently iterable), or combined into buffers described to hardware ..
08:09:58 <davr0s> it was so that i could just shove stuff into clipping code. i could also just hold my nose and concatenate semantically different components into a longer vector
08:09:58 <infinisil> I have no idea what that example is supposed to mean
08:10:44 <davr0s> vertices for rendering typically combine various attributes e.g. texture coordinates, tangent vectors, blending weights
08:11:47 <davr0s> their components would have different types.. e.g some are 3 elements (XYZ), some 4 (ARGB) , different precisions  (8,16,32 bit or even packed in various ways)
08:12:25 <davr0s> most of the time it's data driven but if you want to generate programatically then you end up rolling various combinations 
08:13:09 <davr0s> of course i dont need to be 'so generic'. if i need one, i can just write it, when i need it. i'm just curious to see how far the type system can go, and of course now through this inquiry i've encountered 'bifunctor'
08:14:49 <phadej> friendly advice, you don't really want to represent colors (RGB) and positions (XYZ) using same type in Haskell.
08:15:24 <davr0s> thats why i want them wrapped semantically
08:16:02 <davr0s> but they should wrap the same underlying maths or representations potentially (3,4 elements whatever) - including the ability to use any compressed types for positions
08:16:10 <davr0s> and converting them to and from plain floats
08:16:26 <davr0s> ^and allow^
08:17:00 <davr0s> so sure the type system will know through wrapper and place in the structures 'dont add a position to a color' etc
08:19:11 <phadej> I have trouble to follow. So do you want to create a representation of a thing, which boils down to sequence of floats/doubles when "flattened"?
08:19:31 <phadej> but looks like a tree of types from outside?;
08:20:39 <hyperisco> how is endianness defined for floats? for integers, little-endian is a less significant byte at a lower address
08:21:37 <hyperisco> but with an IEEE float you can't call one byte "less significant" than another. Not in the same way anyhow.
08:22:13 <phadej> hyperisco: https://en.wikipedia.org/wiki/Double-precision_floating-point_format#Endianness
08:22:37 <phadej> there are still bytes in the representation which you can order
08:22:54 <hyperisco> I read that but it didn't clear anything up for me
08:23:33 <phadej> what's your actual problem?
08:23:33 <hyperisco> a single precision float has 4 bytes, and there is no obvious way to order them
08:23:39 <hyperisco> this is my problem
08:23:48 <ski> davr0s : you're looking to alternate two (possibly) different types of elements in a "list" ?
08:24:06 <davr0s> combine multiple different types ys
08:24:10 <davr0s> yes^
08:24:23 <hyperisco> starting on the left, the first byte includes the sign and part of the exponent. Second byte is part of the exponent and part of the mantissa. Then the last 2 are mantissa.
08:24:24 <ski> davr0s : `data SwapList a b = Nil | Cons a (SwapList b a)' would handle the two-type case
08:24:29 <phadej> hyperisco: there are 4 bytes, does the exponent part come first, or mantissa
08:24:30 <davr0s> not altenate , but use a nested structure rather to combine N types
08:24:39 <ski> (forced alternation, assuming that's what you wanted)
08:24:46 <hyperisco> if you don't know then that's fine
08:25:03 <davr0s> swaplist is interesting to know about thanks. it's not what i wanted but i'll take note
08:25:14 <ski> (if you always want the same number of `a' and `b's in a list, you could use `[(a,b)]', of course)
08:25:46 <davr0s> the mechanism for my pairing should demand/assume support for specific operations supported by all the members, but they are not interchangealbe
08:25:47 <phadej> hyperisco: if you read bytes from the network stream, which bytes come first
08:26:01 <phadej> that kind of defines which endianedness it is
08:26:07 <ski> perhaps you can elucidate on how your "combine" differs from "alternate", iow what you mean by "use a nested structure rather to combine N types"
08:26:09 <phadej> the names are just no-so-descriptive for floats
08:28:42 * ski still isn't really getting davr0s' picture
08:29:29 <ski> (what you last said could be interpreted as you possibly having a use for OO-style stuff, and/or existentials. but it's hard to tell, with so little info)
08:29:32 <davr0s> ski ok 1st step:   imagine making a 'Vertex' type, which has:   Positon:Vec3float,   TexCoord: Vec2float   ,    Color: Vec4float     
08:29:57 <ski> is that a record type ? sum type ?
08:30:05 <hyperisco> phadej, but I don't know which is the "big end" and which is the "little end"
08:30:19 <phadej> hyperisco: most significant is with exponential
08:30:28 * ski assumes record, unless told otherwise
08:30:32 <davr0s> step2 ... imagine making something *generic* to combine different semantically meaningful components, each with a different data type; the full range of options is :    Position, Color, Normal, Texcoord, TangentU,TangentV, BlendWeights,
08:30:37 <Ariakenom> hyperisco: https://en.wikipedia.org/wiki/File:IEEE_754_Double_Floating_Point_Format.svg the endianness should be the same as if that represented an integer
08:30:41 <davr0s> not every vertex will have every one of those
08:30:42 --- mode: glguy set +v dataN
08:30:49 --- mode: glguy set -v dataN
08:31:13 <dataN> why is this an error? https://lpaste.net/3178330040181981184
08:31:30 <ski> are all combinations of these valid ? can there be duplicates ?
08:31:42 <ski> ordering matters ?
08:31:46 <davr0s> i could roll some permuations i use manually. i dont need many.  howevre I am curious if this can be done through a nesting mechanism,  hence the idea of making semantic wrappers which hold a  vector, and 'the next', with a terminator to end it
08:31:58 <hyperisco> hard not to have your head explode with endianness
08:32:21 <dataN> (ignore the type on line 65)
08:32:26 <dataN> typo*
08:32:37 <davr0s> ski now i could also just make one type that holds all, and map most of them to some sort of Null
08:32:38 <Ariakenom> hyperisco: it's easy. little is the one that makes sense and then you ignore big /s
08:32:55 <davr0s> duplicates : texture coordinates yes
08:33:06 <davr0s> it's possible what I was trying is overkill
08:33:26 <hyperisco> it is especially confusing because the way you write literals is big endian
08:33:30 <davr0s> it just seemed interesting to try, regarding expansion
08:34:06 <davr0s> ski i will put this asside and just make the 'fixed layout, with nulling out ones i dont want', then type=.. the common ones.
08:34:19 <ski> ok
08:34:29 <ski> for "null", i assume you know you can use `Maybe'
08:34:34 --- mode: glguy set +v dataN_
08:34:44 <ski> (i suppose use a list for texture coordinates, since you can have more than one)
08:35:12 <davr0s> right making the texcoords a 2d array makes a lot of sense
08:35:32 <Ariakenom> hyperisco: yes. clearly our number system came from a right to left writing system. it is confusing that we do it backwards
08:36:29 <hyperisco> Ariakenom, we say it backwards
08:36:31 <nshepperd> endianness does seem kind of a weird thing for floats to have. that diagram looks like it could be describing a struct (with bitfields), and there's no such thing as a bigendian struct
08:36:39 <hyperisco> or we write it in the order we say it, left to right
08:37:21 <nshepperd> with structs, the first thing always has the lowest address
08:38:01 <hyperisco> when you write a literal like 0x12AB then that sometimes is little endian and sometimes big endian depending on interpretation =\
08:38:49 <dataN_> here is a version correcting the typo; https://lpaste.net/4580562662470975488
08:38:53 <Ariakenom> hyperisco: yes. I don't find that too confusing though
08:39:05 <nshepperd> but it also kinda makes sense because the exponent field has an endianness, and so does the mantissa field, because they're integers. and you presumably want that endianness to be the same as whatever the processor does for integers
08:39:17 <dataN_> there seems to be no need for TypeApplications because of the Proxy types, but still the switch value is ambiguous 
08:39:34 <Ariakenom> nshepperd: doesn't have to be the same. the wiki page said some ARM switches
08:39:53 <dataN_> perhaps it is something to do with the symbol for Id not carrying the injectivity of type family Id?
08:40:10 <nshepperd> no but i would guess that it's "usually" the same
08:40:20 <Ariakenom> it's also usually little
08:40:58 <ski> davr0s : hmm, i suppose, if you wanted to, you could make your `Vertex' type an instance of `Monoid', maybe .. so you can "concatenate&override"
08:41:07 <ski> not sure whether it'd be worthwhile in your case
08:42:42 <hyperisco> well at least it is just byte order to worry about… could you imagine if architectures also swapped word order or bit order… ugh
08:43:30 <ggole> Or word size
08:43:32 * ggole coughs
08:43:33 <cocreature> dataN_: providing a code sample without an error message that depends on modules that you haven’t provided (TyFun in this case) makes it hard for people to actually help you
08:43:45 <hyperisco> ggole, yeah that'd never happen
08:44:16 <dataN_> sorry, the original had the error message, but a type application as a typo; https://lpaste.net/3178330040181981184
08:44:46 <ggole> hyperisco: floats don't really make the endianness issue any worse, since the mapping of bits to sign bit, exponent and mantissa is standard and machine independent
08:44:54 <dataN_> here is TyFun; https://lpaste.net/6557422721683161088
08:44:57 <ggole> So once you have ints right, you should be good.
08:46:21 <hyperisco> ggole, I just didn't know what the "big end" and "little end" was of a float, because the format is nothing like an int
08:46:36 <hyperisco> is a sign bit bigger than a mantissa bit? lol
08:46:55 <ggole> The FP standard tells you where the bit is
08:47:08 <hyperisco> but not where the byte is
08:47:09 <ggole> Where in an int, that is, not where in memory
08:47:11 <hyperisco> that has the bit
08:47:31 <cocreature> dataN_: GHC doesn’t know what it should choose for "switch" when resolving the constraints in the instance
08:47:39 <ggole> That's the same as for ints
08:47:54 <hyperisco> yes but there is an obvious "big end" and "little end" for ints
08:48:06 <hyperisco> defined as "most significant" and "least significant"
08:48:12 <dmwit> Mmm. If we're talking about IEEE754, last time I read it, the standard gives a logical bit ordering but doesn't make any promises about the physical bit ordering that hardware uses.
08:48:26 <dmwit> And there's no provision for viewing the bits of an IEEE754 value in logical bit order.
08:49:05 <dmwit> So anything you're using to view the bits of an IEEE754 float is out-of-spec.
08:49:25 <dmwit> Not to say you can't rely on it working in the same way for a long time, because people are obviously doing that. It's just not part of the spec, is all I'm saying.
08:49:29 <davr0s> ski i have another issue to figure out . details too much for chat but basically: ive ended up with a "Lerp" (and "ScaleBy", "AddSub" class - NOT Num)  to allow 'things which can be interpolated, but which can't themselves be used as numbers' .  That works fine for my vector types and allowed me to genericise my clipper nicely (so now it handles N-D vectors of any component, so far so good),  but when actually making
08:49:29 <davr0s>  another 'Lerp-Able' type (such as the vertex i describe...) it fails.
08:49:33 <hyperisco> but phadej tells me the sign is bigger than the exponent is bigger than the mantissa
08:50:00 <davr0s> (again, i can dodge this, because i dont actually need to clip parameters. i can refer to the original unclipped primitives )
08:50:44 <hyperisco> so if the sign is at the lower address then it is stored big endian
08:50:54 <davr0s> what I needed was  specific output assumptions e.g. "ScaleBy t0  t1" must rerturn "t0"
08:51:01 <dmwit> (In fact, the only "observation" that the spec promises is conversion to an ASCII byte sequence that unambiguously identifies non-NaNs.)
08:51:12 <nshepperd> from what people here have said, it seems like floats have been defined as being encoded as a 64bit integer = 2^63 * sign + 2^52 * exponent + mantissa
08:51:19 * ski idly wonders what "lerp" stands for / comes from
08:51:30 <nshepperd> and the encoding of that integer in bytes is specified as "I dunno lol"
08:51:30 <dmwit> (Obviously most architectures offer many out-of-spec observations beyond that one.)
08:51:34 <dmwit> ski: linear interpolation
08:51:35 <davr0s> (in the general case num * num could yield anything ,eg fixed point, dimensional checked stuff) .. ski lerp = Linear intERPpolate
08:51:44 <dataN_> cocreature: its supposed to match on Specificity to determine switch
08:51:45 <davr0s> aka blend, mix
08:52:06 <hyperisco> nshepperd, no that's not right
08:52:21 <dmwit> nshepperd: basically right
08:52:54 <dmwit> nshepperd: (I don't recall if "sign-exponent-mantissa" is the right order, but the idea you have is basically right.)
08:52:54 <cocreature> davr0s: what do you mean by Specificity?
08:53:09 <ski> hmm .. what you're talking about sounds a bit like a type class for linear spaces (aka vector spaces), or for affine spaces
08:53:15 <nshepperd> and apparently on some ARM platforms, that integer is encoded in opposite order to normal uint64s
08:53:31 <nshepperd> but i guess of x86 it's probably the same order
08:53:35 <dataN_> cocreature: this example works; https://lpaste.net/4571180594175672320
08:53:56 <ski> davr0s : do you mean `scaleBy :: t0 -> t1 -> t0' ?
08:54:45 <greymalkin> Frustrating: if I add a particular dependency in cabal, I can `repl` on the command line with no warnings or problems, but haskell-mode complains "cannot satisfy -package sqlite-simple-0.4.14.0"
08:55:00 <hyperisco> nshepperd, oh I see you are saying how to encode the float using integer arithmetic
08:55:03 <dataN_> its a way to distinguish OverlappingInstances where a less specific default can be made to match after any more specific instance, where the constraint equality is used to make the 'Nothing value appear polymorphic (and hence less specific) until it is matched 
08:55:08 <greymalkin> And it's the same with just `sqlite` as the dependency.
08:55:42 <davr0s> ski yes. and t0 might not satisfy num
08:55:42 <greymalkin> But I've got something like 41 other dependencies that don't give me this problem.
08:56:08 <hyperisco> nshepperd, that still isn't right but the positions are
08:56:53 <davr0s> ski so basically the picture is,    2 things can be blended if you can difference them , scale the difference, and add the scaled difference back.   Infact it might even be better to say the *difference type* is the thing that gets csaled. I've been down this road in Rust and i tied myself in knots and gave up :)
08:57:06 <dataN_> Num?
08:57:31 <davr0s> it might not be Num. e.g. things which dont actually make sense to add, divide
08:57:47 <davr0s> liek i say even saying 'add' isn't strictly correct
08:57:54 <davr0s> it's adding a scaled difference
08:58:10 <nshepperd> hyperisco: well, and there is further encoding of sign, exponent, mantissa part because of denormalization and so forth yes
08:58:29 <ski> davr0s : "difference" = "vector" (elements of a linear/vector space). "things" = "points" (elements of an affine space) -- is what i'm thinkin
08:58:44 <dmwit> davr0s: http://math.ucr.edu/home/baez/torsors.html
08:58:45 <dataN_> so just add, negate and multiply, no reciprocal 
08:59:09 <nshepperd> multiply your mantissa, which is a real number 0.25297652whatever to make it an integer. turn your +1/-1 sign into 1/0 in whatever way you're supposed to do that
08:59:45 * ski notes it's Baez, looks closer
08:59:47 <davr0s> ski   for example, imaigne repreesnting a homogeneous coordinate vector but with the last coord (w for 3d)  set to a compile-time  number that behaves as one or zero.
08:59:48 <davr0s> you couldnt' add those
08:59:50 <davr0s> but you could difference, yelding another type with implied w=0
08:59:55 <monochrom> Oh w00t! So C pointers are torsors!
09:00:09 <dataN_> no identity for addition? like a semigroup? 
09:00:22 <dmwit> monochrom: Oh, no, definitely not. Doing anytihng with pointers from different allocations is UB
09:01:01 <monochrom> Yeah OK I can restrain myself to pointers from the same allocation.
09:01:03 <dmwit> "anything" is too strong. But there's lots of stuff you're not allowed to do with arbitrary pairs of pointers.
09:01:09 <dmwit> monochrom: Yes, then torsor. =)
09:01:34 <hyperisco> nshepperd, I am familiar with the conversion yes. That is what I have been doing.
09:01:36 <davr0s> Vec4<float,float,float,ConstantONE>   -    Vec4<float,float,float,ConstantONE> =   Vec4<float,float,float,ConstantZERO>   ..   the resulting difference type *can* be added tothe first type, yielding the first type again.    this is valid for the interpolation calculation
09:01:44 <monochrom> This is great. I have always thought that safe use of C pointers had a mathematical structure.
09:02:00 <dataN_> davr0s: sounds like the methods for the class you describe are fairly clear
09:02:05 <dataN_> functions*
09:02:39 <hyperisco> nshepperd, main points are to subtract 1 from the mantissa, add 127 to the exponent (for single precision), and handle the special cases of +/-Infinity and NaN
09:02:51 <ski> dmwit : hm, so torsors are transitive ?
09:03:03 <dataN_> cocreature: any idea why its ambiguous?
09:03:28 <dmwit> ski: Transitive?
09:04:04 <davr0s> yeah i've got as far as making my clipper generic through these, but whats happened is when i actually try to make such a type (other than  an N-D vector) there's some clash with over-zeelous generic implemnetations  (specific error::   Overlapping instances for ...        ). it doens't like the fact i did   "instance (Functor v,Num t)=>AddSub (v t)" for some reason, that clashes with the own instance (and it's not a
09:04:04 <davr0s>  functor itself as far as I know...)
09:04:17 <davr0s> again i'm stretching chat sorry i should pastebin or take it to a forum
09:04:18 <dmwit> (Reason for my confusion: "transitive" usually implies some relation between two things of equal type. The operations on torsors take two things of inequal type.)
09:04:58 <dataN_> davr0s: it could possibly be phrased better
09:04:58 <ski> dmwit : <https://en.wikipedia.org/wiki/Transitive_group_action#Types_of_actions> (first property)
09:05:16 <ski> but it seems that for a torsor, it has to be unique existence
09:05:18 <dmwit> ah!
09:06:02 <dmwit> Yes, I believe that kind of transitivity is implied for the torsor's action.
09:06:16 <monochrom> And next time someone complain about Data.Time on the ground that it is different from Unix's story, we get to say "but UTCTime is a torsor". >:)
09:07:43 <ski> davr0s : instance resolution wants to commit to an instance, while only looking at the head (stuff after `=>'). so `AddSub (v t)' will overlap with `AddSub (Blah a)', yes
09:08:20 <cocreature> dataN_: my guess is that the restriction on the kinds of the instance might cause it to not apply so the switch ~ 'Nothing restriction never kicks in but I can’t be bothered to work through the details of whether this actually applies here
09:08:28 <ski> davr0s : (re chattiness), nah, it's ok
09:08:33 <davr0s> ski i'm just trying a  experiment to see if my 'generic implementation' can be constrained by adding a dummy class thtat i can instance for the ones i actually want....
09:09:17 <davr0s> this is kind of a subject that's pulling me *into* haskell, i.e. the HKT here is beyond Rust and C++'s type systems
09:09:21 <dataN_> can anyone see why this is an error; https://lpaste.net/4514973641368141824
09:09:26 <davr0s> there's stuff i've done in either..
09:09:29 <dataN_> thanks cocreature
09:09:37 <davr0s> .. that doesn't quite translate to the other
09:10:18 <dataN_> cocreature: you mean the kind of switch is ambiguous and that makes switch ambiguous? 
09:10:58 <dataN_> cant see where its using 'a' of; forall {a} b (switch :: Maybe Bool).
09:11:04 <dataN_> its not mentioned in the error
09:11:25 <dataN_> but it appears at the front of the forall as if it were a kind
09:12:26 <davr0s> hah that didnt work, still overlaps
09:13:05 <dataN_> the idea is that it uses the kind of switch given in the Proxy as Maybe Bool
09:13:41 <dataN_> such as here in the example that works; https://lpaste.net/4571180594175672320
09:14:17 <dataN_> when trying to add a function on the kind, it seems to mess up the inference, but not in a way thats obvious to fix
09:14:52 <dataN_> like, really not obvious 
09:16:57 <dataN_> davr0s: if there is a clear example of what your trying to do / what your asking, it would help, as the discussion goes beyond the scrollup 
09:17:09 <davr0s> ah some success, via a restrictoin which doesn't affect me now.  (So: my generic Lerp will work for my own Vec2 Vec3 Vec4, and my chosen 'Lerpable objects', but not any Functor of Num)   actually maybe thats better, because 'Lerp' adn the other vec maths ops require same capacity..
09:17:48 <davr0s> basically on reflectoin i was an outright mistake to say "instance (Num t, Applicative v)=>AddSub.."  
09:18:37 <davr0s> whilst I used applicative to *write them*, the reverse is not true. ('if applicative exists, they should exist..') Silly me!
09:20:32 <davr0s> i made that mistake because *ScaleBy* DID make sense. (eg ScaleBy should work on lists or anytgin else.)
09:21:00 <davr0s> (ScaleBy..,AddSub..)=>Lerp ..
09:30:28 <dataN_> davr0s: what if the extra value of the datatype did not have a Subtract instance?
09:30:28 --- mode: glguy set +v Boarders
09:30:59 --- mode: glguy set -v Boarders
09:31:21 * Clint squints.
09:31:32 <dataN_> the argument that this interpolation class should also include anything which has an interpolation instances as part of a product type does not seem reasonable 
09:31:47 <davr0s> dataN_ it would be better to split it up even more like that,   but i'm going to just get as far to get this use case working then put it asside.  
09:32:12 <davr0s> what i want is 'if you can difference,  scale the difference, and add', -> 'linear interpolation works'
09:32:44 <davr0s> what i'm going to get in practice is:   the correct behaviour for my Vec1..4  and Vertex, and move on :)
09:33:24 <davr0s> spent too long on this already
09:33:45 <dataN_> yes, so thats defining your class, which is a good definition, and your types can instantiate it no problem, its just that the example above seemed as though an extra Bool value was confusing the situation, as it had no Add instance but a Subtract instance which was supposed to work
09:34:27 <davr0s> yea i'm not going to implement that 'ConstantZero, ConstantOne' stuff just yet
09:34:54 <dataN_> but if you were, they shouldnt have instances of your class.
09:34:58 <davr0s> i do like the idea of being able to say "it's 3 elements in memory, but it is semantically a homogenous 4 element vector with assumed w=1"
09:35:53 <dataN_> actually, they can have instances of your class, but it should just depend on the part that already has an instance
09:36:01 <dataN_> like Eq a implies Eq [a]
09:36:03 <davr0s> i can write more literal code that assumes 'it's a point' (i have seperate 'mulMatrixByPoint' and 'mulMatrixByAxis' just to be explicit where it really matters to me)
09:36:32 <davr0s> yeah i've got something liek that goign for 'Scale', i'd done it incorrectly for addsub asweell
09:37:21 <dataN_> and 'Eq a' implies 'Eq (Vector a)' regardless of the length of the vector
09:38:01 <davr0s> (i'm not actually implementing operators + - * etc for my own vector types at the moment)
09:38:16 <davr0s> (i'm using explicit  'vecAdd...      matMul..... ' functino calls)
09:39:07 <dataN_> what about Act f a as a class for the left action e.g. scalar multiplication of a vector?
09:39:28 <dataN_> that with Semigroup and negate gives your Lerp
09:40:03 <dataN_> the idea of taking differences without an addition on a linear vector space seems silly
09:40:33 --- mode: glguy set +v enlight
09:40:52 <dataN_> and it might as well be a Monoid since the 0 vector should be defined
09:44:39 <dataN_> and then as the thing the Action is by would be Num, which has negate and multiplicative identity, you can get the negate instance that way
09:44:53 <dataN_> (i.e. *(-1))
09:45:49 <davr0s> let me just read what you said , and check up on 'Monoid', 'Action'..(??)
09:47:07 <dataN_> yeah, group action
09:47:21 <dataN_> left group action specifically 
09:47:58 <dataN_> class Act f a where act :: f -> a -> a
09:51:07 <davr0s> ok what I wanted now works r.e. types, compiling, but i broke my clipper! (some previously unused erroneous codepath to generate a claculation has obviously been swapped in..)
09:52:08 <davr0s> just have to track that down now.. then maybe i'll read up what yo're saying
09:52:54 <dataN_> type Scale a b = (Num a,Act a b)
09:53:54 <dataN_> yes, if you dont know what a Monoid is that is defiantly a priority if your asking about classes relevant to vector spaces   
09:55:23 <dataN_> not sure what your Vector type looks like, but if its as polymorphic as it can be then it should take a parameter (Vec3 a), then it would have; instance Scale a (Vec3 a)
09:56:06 <dataN_> probably defined using (*) since there is a Num a instance
09:56:33 <davr0s> (^ ok that was a dumb cut/paste, fixed it.. lets see what a "Monoid" is...)   it takes a parameter, yes. it implements 'Functor', 'Foldable', Traersible',  and i used those to implement a generic 'vecAdd..' that works on Vec1,Vec2,Vec3,Vec4
09:56:54 <davr0s> not sure of all the jargon here.. ("Monoid??")
09:57:19 <davr0s> vecAdd::(Applicative v,Num t)=>v t->v t->v t
09:57:19 <davr0s> vecAdd a b = (+)<$> a <*> b
09:57:31 <dataN_> :t mappend
09:57:33 <lambdabot> Monoid a => a -> a -> a
09:57:35 <dataN_> :t (+)
09:57:36 <lambdabot> Num a => a -> a -> a
09:57:40 <dataN_> :t (-)
09:57:41 <lambdabot> Num a => a -> a -> a
09:57:44 <dataN_> :t (*)
09:57:46 <lambdabot> Num a => a -> a -> a
09:58:15 <dataN_> :t mempty
09:58:16 <lambdabot> Monoid a => a
09:58:54 <dataN_> :t (++)
09:58:55 <lambdabot> [a] -> [a] -> [a]
09:59:12 <dataN_> > [1,2,3] `mappend` mempty
09:59:14 <lambdabot>  [1,2,3]
09:59:27 <thyr15t0r> i can't install glib-0.13.6. cmd wrote "setup.exe: The program 'pkg-config' version >=0.9.0 is required but it could not be found". what is pkg-config and how to install it?
09:59:35 <dataN_> > mempty :: forall a. [a]
09:59:37 <lambdabot>  []
09:59:49 <davr0s> i'm unsure of details of convention on what <*> is supposed to do , because yesterday i had that given to me for  applying *concatenated* nested vectors. Something else i'm doing in parallel is 'nested arrays' and figuing out better wrappers etc ,  e.g. my OctreeNode currently uses a   Vec2(Vec2(Vec2 OctreeNode))) to represent the 2x2x2 split cell, and i have some helpers to   fold, adn generate NxMxL from a value
09:59:49 <davr0s>  expanded in each axis
10:01:07 <dataN_> good idea
10:01:10 <davr0s> again with that i'm pretty sure there must be 'official ways'..    what i did was wrote some clarity/helpers like  'map3dSeq..' etc.  i have something to fold along each axis back to a value, e.g. to traverse the tree itself
10:02:24 <dataN_> did you want something that would nest e.g. n nestings of Vec2 ?
10:03:07 <dataN_> for some fixed n, e.g. 3 for OctTree
10:03:14 <davr0s> yeah eventually, but for the moment i have 2d , and 3d using the 2d.
10:03:44 <dataN_> your not also partitioning in time or parallel universes?
10:03:58 <davr0s> i'm pretty sure it would at least be possible to generalize the 'Octree' to a 'Tree with split type holding nodes'
10:04:28 <dataN_> such as is needed to find recurring solutions to a dynamical system?
10:04:31 <davr0s> i might want to partition multidimensional data but in practice high dimensional wont use N-octrees well i think
10:04:55 <dataN_> (binary partition trees)
10:04:59 <davr0s> high dimensional... i think i'll go back to other clustering methods and possibly BSP yes
10:05:18 <davr0s> simpler structure, more options in how to build it..
10:06:04 <davr0s>  i have this and a 3d version    fold2d (fy,iny)  (fx,inx)  a2d = foldl fy iny (fmap (foldl fx inx) a2d)
10:06:50 <dataN_> its a shame so much vector linear algebra is done for use in graphics, as then there are not good abstractions for high dimensional data encountered in e.g. principal component analysis 
10:07:15 <davr0s> i.e. "supply a folder for each axis..". there's also a "just use the same folder on each axis", but that assumes the input & cell are the same.  I can fix that eventually but for the moment i can map the cells then fold those for my use case
10:07:33 <davr0s> yeah i'm aware of PCA and actually,
10:07:44 <dataN_> low dimensional molecular dynamics simulations for example are incredibly unrealistic 
10:08:37 <dataN_> wait, why fold each axis? dont you traverse each gridsquare in some order?
10:08:55 <davr0s> this is a usecase i'm going to do very soon . last week i wrote BSP and k-means *image clustering* (in python / numpy), and I absolutely want to re-implement that in this haskell sourcebase, *using extensions of the graphics stuff*.
10:09:35 <davr0s> the image clustering used thumbnails x r,g,b i.e. 32x32x3 , but i want then to move onto simple feature vectors (not quite NNs , just bucketed edges and some other simple things to calculate)
10:10:17 <dataN_> what about this? https://hackage.haskell.org/package/tsne
10:10:21 <davr0s> dataN_  i have different use cases, eventually there will be something that takes more decisions as it drops down the octree . for the minute i just needed to write the thign out to visualize it
10:10:42 <c50a326> is there any place to get (preferably free or very cheap) haskell tutoring/mentoring?
10:10:50 <davr0s> dataN_ right i'm pretty sure what I describe has been implemented far better by others, i  have heard of TSNE, great to see a haskell impl.
10:11:21 <cocreature> c50a326: this channel? :)
10:11:31 <davr0s> dataN_   i have mixed goals here.   coding for my own amusement, but try to take in new information along the way
10:11:41 <davr0s> i'm going to NIH a fair amount.
10:11:46 <c50a326> this channel is great and self-study is great, like 99% for me... but I'm just stuck right now like... on this bloody tree drawing thing still...
10:12:00 <davr0s> but at least getting better *at haskell* each time.
10:12:09 <c50a326> I feel like I need to just chat properly with somebody who is good at this stuff and for them to like... i don't know... hold my frigging hand and figure out what my stuckness is all about, basically... lol
10:12:24 <hyperisco> c50a326, are you in school? They often have tutoring programs
10:12:25 <c50a326> I'm just a bit at my wit's end, I can probably get there on my own in the end at some point but grrrr
10:12:43 <c50a326> nah, unemployed/freeman
10:13:10 <cocreature> davr0s: it sounds like you might be looking for a multi-dimensional array in which case "massiv" might be worth a look
10:13:33 <cocreature> c50a326: getting a single person to hold your hand might be hard here but asking questions that require a bit more guidance is perfectly fine
10:13:47 <hyperisco> well this channel is free, and Google is free, but to get one-on-one time with someone is probably going to cost you an hourly rate
10:15:45 <c50a326> ok gonna go clear my head for 5 min and then stare at it again and see if I can at least come up with a good question lol brb
10:16:54 <hyperisco> you can usually hook someone on here to talking for a long time… just saying
10:18:03 <dataN_> one last try to see if anyone can help fix this; https://lpaste.net/4571180594175672320 works, but https://lpaste.net/4514973641368141824 does not
10:21:52 <thyr15t0r> help me please to install pkg-config. i've got this error message: https://pastebin.com/5M5kJZMt
10:23:42 <dataN_> davr0s: anyway, your Lerpable things are Apllicatives containing Nums, and are Monoids under addition and have left group action by forall a. Num a
10:23:53 <cocreature> thyr15t0r: why are you trying to install hs-pkg-config?
10:24:10 <geekosaur> hs-pkg-config hasn't been updated for ghc8.4+, aparently. you woudl need to add a Semigroup instance. https://prime.haskell.org/wiki/Libraries/Proposals/SemigroupMonoid#Writingcompatiblecode
10:24:31 <geekosaur> but I aso ask cocreature's question. did you ets omething abut "a "pkg-config package" being msising?
10:24:36 <cocreature> I suspect that you probably want pkg-config the C tool not hs-pkg-config
10:24:39 <davr0s> ok.
10:25:00 <geekosaur> that is not the same thing; it meansa C lirbaryusing C's pkg-config (not Haskell's) is missing, and you need to use your system package manager to install the C library
10:25:14 <thyr15t0r> <cocreature> because i want to install  glib-0.13.6. cmd wrote "setup.exe: The program 'pkg-config' version >=0.9.0 is required but it could not be found"
10:25:22 <davr0s> so there's another thing called "VertexNCT" (normal color texture) , this is not applicative, but it is lerpable. the n,c,t are different types
10:25:26 <geekosaur> that is C's pkg-config
10:25:49 <thyr15t0r> <cocreature> i need glib for gtk3
10:25:50 <dataN_> how are they not Apllicative?
10:26:13 <davr0s> how would i make them applicative - in those defs i see it holding a specific type, not a multitude
10:26:22 <geekosaur> thyr15t0r, youened to use your system's package manager to install C's pkg-config.
10:26:34 <geekosaur> hs-pkg-config will not help you
10:26:45 <thyr15t0r> got it
10:26:46 <davr0s> even the component might be different precision,  ok let me read up on what Applicative actually is. they are not *functor* , *foldable*,
10:27:04 <dataN_> oh, so each component has a different addition method?
10:27:04 <davr0s> functor requires  a function taking one type. they contain many different types. 
10:27:07 <davr0s> yes
10:27:32 <dataN_> well the idea was that the Monoid was via Applicative and (+)
10:27:40 <geekosaur> and its absence suggests you will shortly get errors about not having the gtk3 devel packages installed; again, this must come from your system's package manager
10:28:04 <davr0s> it might be possible to express conversoins e.g.  taking packed compoents and expanding all to float32
10:28:26 <davr0s> in that case a typeclass for the component optins might work
10:28:29 <dataN_> so for this it just needs to have the various different additions being used to give the Monoid instance
10:28:35 <davr0s> again i've certainly got that sort of thing working in C++
10:28:53 <thyr15t0r> <geekosaur> where i can take my pkg-config?
10:29:03 <geekosaur> ?
10:29:25 <thyr15t0r> <geekosaur> my system is windows 8(
10:29:37 <geekosaur> you .. are goig to have problems
10:29:52 <davr0s> dataN_ i'm not doing it now but something some people do is dimensional values eg "the Position is in metres, the colours are physical flux measurements, the normal is dimensionless.."
10:30:31 <geekosaur> I think you want to do this in mingw and use its package manager (pacman) to install gtk3 and if necessary pkg-config
10:30:38 <davr0s> tahts sort of stuff gets more useful in physics engines, but i imagine peopleworking on "physically based rendering" might use it too..
10:31:07 <thyr15t0r> <geekosaur> may i use haskell's msys2 to install it?
10:31:14 <dataN_> not sure that would prevent a Monoid instance
10:31:31 <geekosaur> yes
10:31:55 <cocreature> thyr15t0r: have you followed the instructions in the wiki article that I linked to you earlier (https://github.com/haskell-gi/haskell-gi/wiki/Using-haskell-gi-in-Windows)? that seems to setup pkg-config among other things
10:32:45 <thyr15t0r> i tried to install gtk3 via msys2. i got it without problems but GHCi didnt see the library. i think i must install it via cabal
10:33:47 <cocreature> thyr15t0r: if you follow https://github.com/haskell-gi/haskell-gi/wiki/Using-haskell-gi-in-Windows#compiling-with-cabal cabal should install all the necessary libraries
10:33:50 <davr0s> dataN_ "mappend".. is that 'append',e.g. [a,b,c]+[d]->[a,b,c,d].  can it express 'appending a Vec3 t with a Vec1 t to yield a Vec4 t' - that would be useful r.e. constructors sometimes, i do certainly write code that moves between 3<->4 elems
10:34:09 <davr0s> everything i see for these monads etc seems to be 'the same type'...
10:34:55 <davr0s> dataN_ one thing i need is 'permutes', i usually have a bunch written out manually   eg  Vec4_getXZ    -> vec2(..)
10:35:04 <thyr15t0r> <cocreature> thank you again. i lost your links at last login 8(
10:36:09 * thyr15t0r went to fight
10:36:27 <davr0s> got that nagging doubt resurfacing r.e. *the volume of helper code around simple things*, although the counterarguemnt is "writing all this in a safe pure-functional manner yields the complexity of the potential bug solving in the simpler imperative languages.."
10:37:15 <hyperisco> is "yields" the word you meant?
10:37:45 <davr0s> the thing is the process becomes  extreme in intro/extroversion ..   "extreme introversion" in that you have to spend a huge time *inside* your code instead of dealing with IO,UI.. ; "extreme extroversion" in that things that you can just write yourself imperatively in 2minutes you have to stop and dig through someone elses jargon for..
10:39:26 <hyperisco> first of all, the world of programming is largely imperative and procedural, so you can't fairly compare how long things take without accounting for that
10:40:07 <hyperisco> for every dozen non-functional options there are zero to one functional options
10:40:57 <davr0s> (is that a sympttom of this.. ) but at the same time, i realise it's possibly "horses for courses". different types of code will look better in each
10:41:25 <dataN_> you should defiantly phrase your questions more clearly 
10:42:25 <davr0s> i should keep this momentum up, each time i get a bit further and maybe it'll help me when i oscilate back to also spend longer in rust.
10:42:35 <MarcelineVQ> Sounds like you're learning, a typically frustrating process in any field
10:42:59 <davr0s> it's getting familiar thats the problem, overcoming the extreme habits
10:43:37 <Boarders> what is an explicit example of what you have in mind
10:44:23 <hyperisco> and secondly, in my experience, most non-functional programmers only program on the happy path, whereas functional programmers I find are more considerate of such things
10:45:10 <hyperisco> and I think that is due to static typing, lack of null, and principles such as immutability which remove classes of issues
10:45:23 <mrm> I prefer to think of myself as a dysfunctional programmer thank you very much.
10:45:40 <davr0s> one issue is navigation e.g. dot-autocomplete IDE helps alot in OOPy syntax, navigating APIs .. when i think back to 'outward facing' tasks (navigating 3d plugin apis , or UI stuff) .. i think that would be missed - but even going back though my own code..
10:46:10 <davr0s> i'm somewhere between because I *dont* like pure OOP , i definitely like freefunctions, it's just i'm so used to working with c-structs..
10:46:17 <Boarders> that is quite different from writing lots of helper code
10:46:57 <hyperisco> in other words, the functional and nonfunctional programmer are typically not even making the same program to solve the same problem
10:47:08 <monochrom> You can define "data X = Ctor{x :: Int, y :: Bool, z :: Char}" and it gets pretty close to C structs. Apart from mutation.
10:47:09 <dataN_> what/
10:47:26 <davr0s> yeah i get that, there's nothing *missing* here.
10:47:41 <davr0s> and some parts of this do get increasingly pleasing
10:47:44 <monochrom> If you add lens, there are things C can't even hope for.
10:48:03 <davr0s> yeah i gather that stuff is all composable
10:48:09 <hyperisco> davr0s, the dot complete feature is really just a weak form of type assisted autocomplete
10:48:12 <dataN_> not to mention infinity nested for loops 
10:48:20 <davr0s> yes hyperisco . i should look around for that
10:48:57 <davr0s> i was also going to ask about navigation  assists for one's own code, e.g. is there something to generate soethig like the official docs 
10:49:04 <monochrom> Autocompletion is going to be problematic for functional languages. Intrinsically.  Especially when compared to statically typed OOP.
10:49:08 <davr0s> can you use 'hoogle' on your own stuff
10:49:27 <davr0s> monochrom i get that there's potential to possibly use more type informatino, i heard of the holes workflow..
10:49:47 <monochrom> Actually I can state more precisely. Problematic for statically typed parametric polymorphism.
10:49:48 <davr0s> monochrom the autocomplete hits me in Rust aswell actually, they're just not as mature as C++ 
10:50:03 <davr0s> anyway i can keep going, i'm still enjoying this
10:50:48 <davr0s> some of my real world aquaintainces are looking at Rust now, i was into it years before them heh
10:51:15 <davr0s> but the same doubts stopped me sticking with it compared to just continuing 'getting shit done' with established tools
10:51:19 <dataN_> whats the status of haskell WebGL?
10:51:26 <EvanR> still waiting for my real world aquiaintences to look at Haskell
10:51:36 <monochrom> So here is the thing. With Java for example, you type in "foo." and then you can just hit <tab>, right?  Let's consider how the computer does it.  It can find the class(es) that foo belongs, and from there you know what is possible and also very importantly what is impossible.
10:51:47 <Boarders> davr0s: if you are running stack then: "stack hoogle --server" will create a local searchable hoogle of your project
10:51:56 <Younder> RUST seems to have very little in common with Haskell..
10:51:57 <Boarders> that will then link to haddock documentation
10:52:27 <davr0s> Younder Rust is closer to C++, but a gateway drug to Haskell perhaps, it has haskelly elements
10:52:28 <hyperisco> monochrom, yeah but it is a curse in disguise
10:52:51 <davr0s> Rust made haskell make more sense to me
10:53:08 <EvanR> how?
10:53:21 <hyperisco> monochrom, what you pay for a closed list of possibilities (i.e. instance members) is the closed list of possibilities
10:53:33 <mrm> monochrom: That's because in Java all the types for which dot completion is applicable have statically associated namespaces/modules. It's not intrinsically tied to OOP.
10:53:35 <hyperisco> monochrom, which isn't so much a problem with how it is but how it ends up being used
10:53:45 <dataN_> bump; https://lpaste.net/4571180594175672320 works, but https://lpaste.net/4514973641368141824 does not
10:54:07 <mniip> monochrom, I think a more interesting analogy is that you get the same problem if you were to try to tab-complete a function call like
10:54:09 <monochrom> In contrast, with Haskell for example, you type in "foo" and then ask the computer, say, the two of you agree the question is "if foo is a parameter for a function, which functions are possible?"  You get a lot more answers, way more than manageable.  For example, id, repeat, and replicate n are legal candidates too, just because their types are all "forall a. a -> ..."
10:54:11 <mniip> ___(list, of, args)
10:54:32 <hyperisco> monochrom, where everything ever to do with a type is pressured to be an instance member of that class. And programmers can get lost on what to do with functions which use two types. Which class does the method go on?
10:54:55 <monochrom> mrm: Did you notice there is a reason why I carefully wrote "statically typed OOP"?
10:55:02 <EvanR> there are definitely some useful heuristics for what you want a functional IDE autocomplete to produce
10:55:13 <EvanR> this might be a situation to leave theory at the door
10:55:50 <monochrom> No we don't have to leave theory at the door. We just need more refined theory.
10:55:51 <mniip> EvanR, I want a mini-hoogle/hackage
10:55:54 <davr0s> i guess you can argue in Functional land, you dont *need* so many api functions, because you can compose more yourself on the fly
10:55:55 <mniip> almost like :info in ghci
10:56:01 <hyperisco> monochrom, if you break out of that nonsense and start using, say, static class imports in C#, you lose that autocomplete advantage
10:56:09 <davr0s> hoogle is certainly remarkable
10:56:49 <monochrom> For example you do get to say: Clearly, a less polymorphic function should enjoy a higher priority than a more polymorphic function.  (And that applies theory, not abandon.)
10:56:50 <Younder> davr0s, Well you nerver know to me the entrance was Common Lisp.
10:56:53 <mniip> sometimes I'm like, what's that function in Data.Profunctor.Choice called
10:57:10 <dataN_> does haskell autocomplete work in the presence of Undecidable or Overlapping classes ?
10:57:15 <hyperisco> polymorphism is going to get you a lot more autocomplete options, but I figure "so what?" because… well… they *are* valid options
10:57:35 <mniip> dataN_, good question, undecidable -> probably not
10:57:48 <dataN_> useless 
10:57:50 <EvanR> when more things are valid, theres less possibility for the computer to pick the one you want
10:58:01 <EvanR> and more burden on you to do more searching
10:58:10 <Younder> Autoprogramming has a bad rep from old
10:58:14 <dataN_> actually does ghcjs handle those?
10:58:25 <EvanR> in ruby everything is valid, so nothing can help you
10:58:27 <mrm> monochrom: Did you miss the part where I said "not intrinsically tied to OOP"?
10:58:41 <Younder> EvanR, That is Perl ;)
10:58:44 <monochrom> Non-sequitor then.
10:58:55 <hyperisco> when you have to tell the computer everything you could possibly want by making it a method of the class, it's the same problem
10:59:02 <dataN_> is it just ghc compiled to javascript?
10:59:13 <monochrom> Also I also had "Especially".
10:59:22 <monochrom> I.e., not exclusive.
10:59:56 <hyperisco> well, lets say a different problem but no more a pleasant one
11:00:00 <dataN_> hey mniip, you will know how to fix this surely https://lpaste.net/4514973641368141824
11:00:03 <monochrom> While I'm at it, since everyone feels like pedantic-anal-nitpicking on me...
11:01:00 <Younder> Anyhow something C++ programmers need to realize that object's have type not variables.
11:01:21 <Younder> though auto is a start
11:01:25 <hyperisco> when you qualify an import it can autocomplete based on the definitions in the module
11:01:39 <hyperisco> that is the same sort of mechanism
11:02:06 <davr0s> perhaps something is possible with type-assisted corrections to function names, e.g. if you write something wrong, it'll look for the closest matches both in 'type-space' and 'alphabetically' .. (does it already do that..)
11:02:09 <hyperisco> but it can't tell you what module you should be interested in no more than dot-complete can tell you what class to be interested in
11:02:55 <monochrom> I am well aware that if the language is untyped or unityped or non-statically-type (take your pick, you anal people), it is still possible to do a static analysis and so 99% of the time when you type "foo" the computer can figure out "ah you set foo to so-and-so recently" and therefore can still list good candidates.
11:03:31 <hyperisco> haha well what I see more often is just remembering the words you typed before and guessing you might mean one of those words again
11:03:54 <monochrom> I thought that's just smart phone completion. :)
11:04:17 <monochrom> Markov chains for PHP programming?!
11:04:29 <hyperisco> I need to get a virtual keyboard so I can use swipe typing to complete the experience
11:05:17 <dataN_> just go the whole hog and use a brain computer interface 
11:05:43 <hyperisco> why would I want to explain myself to a hog though
11:06:25 <monochrom> davr0s: GHC already does spelling proximity suggestions. But too bad it's during error message generation, rather than fix-it-for-you.
11:06:52 <davr0s> monochrom i'm not adverse to assists that require hitting compile, although realtime is nicer of course
11:07:30 <hyperisco> what we're really getting at is that computers have almost no understanding of our intentions while programming
11:07:48 <davr0s> a more advanced type-based autocomplete that can use more context..
11:08:16 <hyperisco> it would be nice to send a vague gesture and to have the computer intuit what we desire
11:08:24 <monochrom> emacs haskell-mode and dante can also do prefix-based completion, but they're really just calling up an obscure ghci command. (Therefore they need your recent load/reload to be successful.)
11:08:46 <monochrom> OTOH too bad that is not proximity-based, just prefix-based.
11:09:41 <monochrom> Naw, it would be nice if the computer interprets every gesture to mean "delete file". >:)
11:09:58 <hyperisco> hm I think I can implement that
11:10:50 <hyperisco> I think maybe what we need is a regexp-like language for types
11:10:55 <monochrom> You slice your hand at any angle, it means "delete file" because the gesture looks like chopping or cut-throat.
11:11:17 <hyperisco> so that you can hit a hotkey to bring up an input, then you can type in your type search term, then results are listed
11:11:32 <davr0s> ahhh
11:11:36 <hyperisco> for example, you might want to search for "n-ary functions which return an Int"
11:11:58 <monochrom> Your hand draws a circle approximately, it means "delete file" because the gesture looks like "finish it", and "finish it" in the sense of the villain boss telling/gesturing the villain minion to "finish it", like in movies.
11:12:14 <davr0s> what if ` could trigger complextions hinted on the type of a variable, at least for arity2 functions heh.   foo `doSomething` ...
11:12:24 <hyperisco> type searching has obviously worked well for Haskell, but it can be cumbersome if you have to explicitly say every constraint and constructor and variable and so on
11:13:07 <davr0s> obviosuly the instinctive thing about "  foo.  <completions> "   could even be handled with a keyswap if i'm desperate
11:13:41 <hyperisco> whereas I find I am usually thinking of a type which has certain features. I might not recall the complete type, or not care about it
11:15:08 <hyperisco> for example, maybe I'd like to search for "higher order functions which work on lists"
11:15:35 <hyperisco> or more precisely, some function which has at least a function parameter and a list parameter
11:16:16 <hyperisco> I find I am often doing exploratory searches like that to figure out how I can most easily solve a problem
11:16:35 <davr0s> perhaps part of the adaptaion i can make is to really push the genericization (like i was saying about an Octree and Bsp sharing tree like behaviour with a plugin split mechanism)
11:17:05 <davr0s> -> takes longer to write an octree that way, but then saves time when dealing with both
11:17:50 <hyperisco> I say to be careful with polymorphism
11:18:27 <davr0s> ok certainly i have heard "dont over abstract"
11:18:29 <monochrom> Generally you don't want to generalize prematurely. (Ah the irony.)
11:18:34 <hyperisco> in my opinion, the best use is to program with the abstractions themselves
11:19:04 <hyperisco> for example, there are many programs you can write generic to Functor or Monad or Monoid or other good abstractions like this
11:19:16 <monochrom> My personal guideline is when you have 3 or more examples you're ready to generalize.
11:19:46 <hyperisco> if you're unable to write interesting programs in that way, you may actually just be doing code generation, i.e. macros
11:20:17 <hyperisco> and you can tell because the only cases you use the polymorphic definitions is in their instantiated forms
11:20:28 <davr0s> well the octree/bsp tree,  thats 2, but i know of many variations and there's such a thing as nesting them too
11:20:35 <Younder> I like macro's, but then I'm from lisp. They automate tedious repitition.
11:20:46 <hyperisco> and when you're essentially just writing macros, in my experience the whole endeavour is unattractive
11:21:10 <hyperisco> well it doesn't matter if there are variations davr0s
11:21:10 <c50a326> what's the best way to stick n number of elements _in between_ elements in a given list?
11:21:19 <hyperisco> it matters if you can do interesting things regardless of variation
11:21:51 <c50a326> e.g. if I have ["abc", "def", "ghi"] and I want to stick arbitrary "!!!" in between, not leading or trailing
11:22:07 <Younder> Anoyhow Haskell humors people who like macros, but dosent force them on you. You get to choose.
11:22:08 <davr0s> in the concrete case of actually doing a voxel engine, the usual consensus mroe like  'use a grid of grids'
11:22:13 <c50a326> so for 3 it'd be: [ "abc", "!!!", "!!!", "!!!", "def" ... and so on
11:22:19 <monochrom> Split list and re-concat.
11:22:22 <hyperisco> and to do that you probably also need laws, else you can't be too sure what the abstraction is sans instance
11:22:27 <cocreature> > intercalate "!!!" ["abc", "def", "ghci"]
11:22:29 <lambdabot>  "abc!!!def!!!ghci"
11:22:37 <cocreature> > intersperse "!!!" ["abc", "def", "ghci"]
11:22:39 <c50a326> cocreature: keeping the elements split though
11:22:40 <lambdabot>  ["abc","!!!","def","!!!","ghci"]
11:22:44 <c50a326> ah intersperse, cool
11:22:48 <davr0s> intersperse is awesome
11:23:01 <cocreature> I’ll never be able to remember whether I want intersperse or intercalate
11:23:07 <c50a326> is there an intersperse that takes an n though?
11:23:21 <c50a326> or a (repeat "lala") maybe
11:23:27 <c50a326> err replicate
11:23:53 <c50a326> in any case I should look how intersperse is implemented
11:24:08 <davr0s> what if the  backtick really did just trigger OOP-y  autocomplete on the parameter to the left. How woudl that look overall.
11:24:21 <cocreature> > let f n xs ys = concat (intersperse (repeat n xs) (map pure ys)) in f 3 "!!!" ["abc", "def", "ghci"]
11:24:24 <lambdabot>  error:
11:24:24 <lambdabot>      • Couldn't match expected type ‘t -> [a1]’ with actual type ‘[a]’
11:24:24 <lambdabot>      • The function ‘repeat’ is applied to two arguments,
11:24:32 <davr0s> given that there *is* a syntactically valid way of using it i.e. the infix function call stuff (which is actually quite nice)
11:24:36 <cocreature> > let f n xs ys = concat (intersperse (replicate n xs) (map pure ys)) in f 3 "!!!" ["abc", "def", "ghci"]
11:24:39 <lambdabot>  ["abc","!!!","!!!","!!!","def","!!!","!!!","!!!","ghci"]
11:24:40 <davr0s> could you get the best of both worlds.
11:24:42 <cocreature> ^ c50a326 
11:25:02 <hyperisco> davr0s, for example, I made an abstraction for indexable things. I have laws which define what it means to be indexable. Then I have dozens of functions defined which work on any indexable thing.
11:25:12 <c50a326> nice, thanks
11:25:22 <hyperisco> davr0s, and the meaning of those functions can be completely understood by the definition of what it means to be indexable.
11:25:31 <cocreature> > let f n xs ys = intercalate (replicate n xs) (map pure ys) in f 3 "!!!" ["abc", "def", "ghci"]
11:25:33 <lambdabot>  ["abc","!!!","!!!","!!!","def","!!!","!!!","!!!","ghci"]
11:25:36 <cocreature> even better :)
11:26:06 <davr0s> what i can say is,  i do vastly prefer high-order functions to C++ style iterators
11:26:20 <monochrom> Me too.
11:27:06 <hyperisco> davr0s, without a clear definition of what the abstraction is sans any of the instances (such as arrays or strings), you really have nothing but a sophisticated macro system
11:27:49 <monochrom> Perhaps people just want macros. I mean look at word processors and spreadsheets and all their ardent users and defenders.
11:28:14 <davr0s> well if i have 2 examples,   (octree,bsp)  -> and actually a 3rd (quadtree for 2d images , even then i've  seen people use quad-trees for 3d maps because they split horizontally much more) 
11:28:22 <hyperisco> well they're not bad, but it is a different use. And I think just banging out the code by hand is underrated.
11:28:47 <Younder> If you want something more sophisticated I suggest 'Categorical logic and type theory' by Jacobs
11:29:10 <Younder> It geos well beyond macros
11:29:14 <Younder> goews
11:29:28 <hyperisco> you see, macros do not adapt to novelty, and they're often not that well thought out
11:30:10 <hyperisco> so when boss hands you the new requirements it can be more headache than worth. I dunno, maybe I am just a masochist for typing code :P
11:30:14 <monochrom> Hell, look at TeX, from the very Knuth himself. >:)
11:30:41 <davr0s> i can see haskell getting further with duplicate code detectors
11:31:14 <davr0s> those could be another way of searhcing apis. (you just write waht you want, then a tool comes back and tells you where you can re-use something else..)
11:31:18 <hyperisco> I unabashedly do copy/paste/tweak programming. *shrug*
11:31:28 <monochrom> A completely fragile anti-compositional monkey-patching macro system that inspired generations of language designers.
11:31:30 <Younder> monochrom, Knuth wrote LaTex in Pascal
11:32:30 <Younder> In fact LaTex is all languages withing languages..
11:33:05 <hyperisco> monochrom, I guess I misspoke. Macros only adopt to novelty by making more macros :P
11:33:37 <monochrom> Consider also the economical prospect that if the employer doesn't know of better ways, then employees get more security.
11:34:05 <Younder> Or you can do like Knuth, just make a new language all together and then you don't have to worry about macro's.
11:35:39 <Younder> Of course it to him 10 years to write Tex.
11:35:57 <hyperisco> davr0s, an example of polymorphism as macros… my foldapp package is just that. It uses lots of classes and type parameters but the only end is to generate functions. There's nothing interesting to do with the abstraction itself.
11:36:40 <hyperisco> "listOf" for example may as well be considered a macro for rewriting "listOf a b c … z" to [a, b, c, …, z]
11:36:55 <monochrom> Oh w00t polymorphism as macros!  Or is it macros as polymorphism?  Anyway enjoy: https://twitter.com/mosheroperandi/status/856946180810354688
11:37:35 <davr0s> i'll keep going.. haskell remains addictive, i can just look for the intersection of 'problems that interest me' and 'problems that haskell makes sense for'
11:38:10 <davr0s> there's something seriously satisfying about writing pure code
11:38:15 <hyperisco> which definitely has a use… I made the package to assist with parser combinators. That way you can write  listOf <$> a <*> b <*> … <*> z  and it automagically collects everything in a list
11:38:18 <dolio> monochrom: What!
11:38:38 <Ariakenom> davr0s: It makes sense?
11:38:58 <hyperisco> wonder if it would work with idiom brackets too… hrm
11:40:17 <hyperisco> monochrom, that is a magnificent horror.
11:40:32 <monochrom> hee hee
11:42:22 <monochrom> Code generation by humans at its finest. >:)
11:42:24 <davr0s> ok one thing that surprised me was   [(*10),(*100)]<*>[1,2] -> [30,40,300,400]  on 2 counts: firstly there's a want for 'elem by elem application' (and i was advised to use <*> for binary operator implementations with my fixed-len vectors),  and secondly there's a want for a nested result  [[30,40],[300,400]].     i'm not sure what the spirit of <*> is
11:44:16 <monochrom> davr0s: You are right, <*> for lists has two legal candidates. Cartesian product and (or?) zipping.  We chose cartesian product because it conforms to list's >>=.  But look for the ZipList newtype wrapper that gives you zipping <*>.
11:44:17 <hyperisco> davr0s, the spirit is the Applicative laws, and that ends up as a (poorly enumerated) Cartesian product for lists
11:45:21 <ski> > getZipList (ZipList [(*10),(*100)] <*> ZipList [1,2])
11:45:25 <lambdabot>  [10,200]
11:45:33 <hyperisco> well, it is fine if the lists are finite and you don't really care about enumeration order
11:45:50 <davr0s> so this is an artefact of lists, i've used it right elsewhere?
11:46:17 <ski> (nested lists wouldn't work with the signature of `(<*>)')
11:47:23 <ski> `Applicative []' and `Monad []' is "try all combinations/alternatives"
11:49:19 <hyperisco> > foldrM (:) [] [1..5]
11:49:21 <lambdabot>  error:
11:49:21 <lambdabot>      • Occurs check: cannot construct the infinite type: a ~ [a]
11:49:21 <lambdabot>        Expected type: [a] -> [a] -> [[a]]
11:50:22 <hyperisco> let me figure out what I actually meant
11:52:03 <ski> > sequence ["ab","01",".!"]
11:52:05 <lambdabot>  ["a0.","a0!","a1.","a1!","b0.","b0!","b1.","b1!"]
11:52:23 * ski . o O ( `sequence : (m -> (n -> a)) -> ((m -> n) -> (m -> a))' )
11:58:05 <hyperisco> > foldrM (\x xs -> (x:xs):xs:[]) [] [1..4]
11:58:07 <lambdabot>  [[1,2,3,4],[2,3,4],[1,3,4],[3,4],[1,2,4],[2,4],[1,4],[4],[1,2,3],[2,3],[1,3]...
11:59:16 <hyperisco> all the ways to pick the things
12:01:01 <ski> > filterM (\_ -> [True,False]) "1234"  -- different order of choices
12:01:03 <lambdabot>  ["1234","123","124","12","134","13","14","1","234","23","24","2","34","3","4...
12:03:15 --- mode: glguy set +v sleepster
12:03:48 --- mode: glguy set -v sleepster
12:08:23 <sleepster> What's the benefit of using the "mainWith function" approach here? https://mail.haskell.org/pipermail/beginners/2008-November/000496.html
12:08:36 <sleepster> I am going through the real world haskell examples
12:08:44 <sleepster> it seems that it can just be:  main = do ...
12:11:46 <hyperisco> sleepster, I don't know but I am guessing they just want you to have a parameter you can change later
12:11:51 <monochrom> If this code is from Real World Haskell, doesn't the book explain why?
12:12:08 <sleepster> monochrom: no explanation :(
12:12:47 <monochrom> I'm too lazy to read the book, but my experience on IRC is that 90% of people misread their books.
12:13:39 <sleepster> alrighty, I will double check :) 
12:14:59 <monochrom> Notwithstanding, there are always two things you can do.  1. You learn how this code works.  2. You rewrite it with whatever simplification/complexification you like, and verify that it still works.
12:18:03 <greymalkin> I feel dumb: It took me 2 years to realize that mapReaderT could map from and to the same monad, and thus be used for things like `forkIO` within a stack.
12:19:00 <monochrom> Yes, it is always easy to forget that a circle counts as ellipse, a square counts as a rectangle, and a point counts as both.
12:21:39 <monochrom> forkIO might not be an intended usage, but meh it does what you think.
12:21:47 <hyperisco> though the subtype relation is the other way around monochrom
12:22:38 <hyperisco> or is it not related at all… vague memories of my Java class
12:22:56 <monochrom> Are you repeating conventional wisdom, or did you critically, independently think of it?
12:23:12 <hyperisco> neither
12:23:15 <monochrom> Because the "misunderstanding" is due to immutable vs mutable objects.
12:24:04 <hyperisco> yes suppose it is the mutability that is the problem
12:24:13 <monochrom> (No one else took this angle because mostly everyone who discusses the Liskov principle at all just assumes mutable objects.)
12:24:14 <tsaka_> Is there a way to compose a function using nested case expression? https://lpaste.net/7601346503302447104
12:25:10 <monochrom> In math classes (pun intended) circle is a subtype of ellipse --- in fact even in the PVS predicate subtype sense --- because math uses immutable objects.
12:25:40 <monochrom> And integers a subclass of rational numbers.
12:25:50 <monochrom> or subtype? meh
12:25:59 <hyperisco> when mutable neither subtype relation makes sense
12:27:31 <monochrom> When mutable, I think they speak of: Have a rectangle type/class, then oh if you happen to set its width and height to the same number, you get a square, but maybe the type system doesn't need to know.
12:28:08 <phadej> as values integers are subset of rationals, as algebraic structure we call integers a superclass of rationals, as integers have less operations
12:28:13 <monochrom> But anyway later you may change the width so suddenly it mutates to a rectangle again.
12:28:35 <hyperisco> I think what happened in my Java class was this… circle subtypes rectangle but overrides the setWidth and setHeight methods to set the other dimension to be equal
12:28:40 <phadej> e.g. we can split rectangle in half, and still get a rectangle - doesn't work with square
12:28:58 <monochrom> Ah that works too.
12:29:02 <hyperisco> so when working with a circle you still have all the rectangle operations but they're mangled by an overridden setWidth/setHeight definition
12:29:18 <greymalkin> Now I must refactor all the things.
12:29:21 <phadej> that "violates laws"
12:29:26 <hyperisco> a big problem if an operation on rectangles only terminates if it behaves like a rectangle
12:29:53 <phadej> fwiw, (partially) because of this we have builders
12:30:01 <hyperisco> or just all the nonsense you can otherwise get not knowing a rectangle is a circle
12:30:13 * hyperisco means square and rectangle -.-
12:30:15 <phadej> you can have SquareBuilder and RectangleBuilder in jav
12:30:22 <phadej> which don't have getters
12:30:33 <phadej> and Square and Rectangle which don't have setters
12:30:44 <phadej> than you can make proper hierarchies
12:30:50 <hyperisco> but while you're at it may as well have circle extend rectangle too since a rectangle has two ints ripe for use :P
12:31:00 <hyperisco> not much different than mangling it to become a square…
12:31:22 <monochrom> Yeah, I made that leap. :)
12:32:38 <hyperisco> so SquareBuilder subtypes RectangleBuilder and Square subtypes Rectangle, okay heh
12:33:25 <hyperisco> I think there's a bigger problem with this hierarchy though
12:33:47 <hyperisco> and that is that simpler geometric objects subtype more complicated geometric objects
12:34:19 <hyperisco> which means to talk about the simplest geometric object in the hierarchy you have to already decide what the most complicated geometric object is
12:34:40 <hyperisco> this is like Monad not extending Applicative
12:35:14 <hyperisco> if you come up with a more general geometric object in the future you're going to be unhappy about the existing hierarchy
12:35:38 <monochrom> Somehow that doesn't pose a problem in reality.  We teach whole numbers before quarternions all the time.
12:36:05 <c_wraith> reality isn't concerned with a nominal type hierarchy
12:36:10 <monochrom> Hell, not just teach.  Research also comes up with more special theories before more general theories.  Most of the time anyway.
12:36:48 <monochrom> Reality is.  I mean everyone is.  But somehow mathematicians are fine with going the supertyping direction.
12:38:04 <hyperisco> I think this is just an accident of how the generalisation is working on shapes
12:38:28 <hyperisco> with more data points you can describe more things… so it is a more complicated description but more general in applicability
12:38:30 <monochrom> Look at how we got function composition long before we got category theory.
12:38:44 <hyperisco> whereas in the Functor Applicative Monad hierarchy, the most generally applicable is also the simplest
12:39:05 <monochrom> But we got Monad before we got Applicative.
12:39:09 <hyperisco> so in that hierarchy the harder thing is adding simpler definitions, whereas with shapes it is harder adding more complicated ones
12:39:23 <monochrom> I just don't know when we got Functor.
12:40:05 <monochrom> Actually I bet you $1 Grothendick got monad before functor.
12:40:52 <hyperisco> make it a donut
12:41:40 <phadej> monochrom: :)
12:42:01 <c50a326> why does this only print out the right half of the tree? :S https://ptpb.pw/R56d/hs
12:43:13 <c50a326> oh
12:43:13 <hyperisco> does it print out the right half recursively or does it print the right branch from the root node?
12:43:34 <c50a326> I'm not applying the function recursively to the st in (st:sts), nvm
12:45:19 <dolio> monochrom: Monad was way late.
12:45:35 <dolio> Before monad was "standard construction".
12:45:50 <hyperisco> was that like a standard transmission?
12:47:55 <dolio> Maybe we should change the name of the type class.
12:48:01 <dolio> Sounds much more official.
12:48:12 <monochrom> I think there is no technical difficulty, only cultural difficulty, in going the supertyping direction in programming.  Our culture is we always think in terms of addition, "Y's methods are X's methods plus two more".  We are not used to the subtraction method, "A's methods are B's method minus so-and-so".  But you can always design a language for the latter and write a compiler for it.
12:48:26 * ski . o O ( `class Triple t where ...' )
12:49:10 * ski . o O ( refinement types )
12:49:37 <dolio> And no one would be mystified or anything.
12:49:44 <hyperisco> class Rectangle subsumes Circle { … }
12:49:46 <Cale> Well, it's also about the order in which you'd rather have concepts introduced to you
12:49:52 <dolio> "What's a monad?" "Oh, it's just the standard construction. Nothing special about it at all."
12:49:57 * hyperisco can't believe he still can't disassociate squares and circles
12:50:08 <Cale> "What's a functor?" "Oh, it's a monad without the return and bind"
12:50:23 * ski . o O ( "Supertyping Suggestion for Haskell" by John Meacham at <http://repetae.net/recent/out/supertyping.html> )
12:50:43 <hyperisco> ski, are you always looking at yourself when you send those messages?
12:50:55 <dolio> Those are thought bubbles.
12:51:00 <monochrom> hyperisco: In the Yorkdale mall there was a pie shop that sold square-shaped pies.  They certainly solved the problem of squaring the circle by culinary art. :)
12:51:01 <hyperisco> oh I see
12:51:58 <hyperisco> monochrom, they must be proud of their crust!
12:53:43 <dmwit> Cale: There is a group of people for whom "What is a monoid?" "Oh, it's a group without an inverse." would be a perfectly cromulent exchange.
12:54:15 <hyperisco> a group of group people
12:56:02 <dmwit> Followup question: which would be the "fewer operations" direction, "a tree is a graph without cycles" or "a graph is a tree without the unique-path property"
12:56:35 <hyperisco> an acyclic connected graph
12:56:42 <monochrom> I am always looking at the display screen's reflection of myself when I'm sending messages on a computer or phone.  https://www.quantamagazine.org/the-new-science-of-seeing-around-corners-20180830/
12:56:51 <hyperisco> plus no node sharing… don't know the terminology for that
12:57:08 <hyperisco> though if it was nondirectional then acyclic works
12:57:22 <monochrom> I mean the screen content dominates, but my reflection is always there as a weak extra signal.
12:57:24 <dmwit> hyperisco: We can quibble about definitions, but it seems unimportant to the question.
12:57:54 <sssilver> I'm reading this book called "Category Theory for Programmers" and enjoying it a lot. Is it any good or should I stop right now and go play World of Warcraft?
12:57:55 <hyperisco> dmwit, well it kind of does if we're comparing how complicated the explanation is
12:58:44 <monochrom> A directed acyclic connected graph with no "two edges point to the same node" is a tree.
12:59:14 <dmwit> hyperisco: I'm willing to entertain your answer to any one of the questions in the family of questions that take varying definitions of graph and tree in terms of each other.
12:59:16 <mniip> a rooted tree at that
12:59:29 <monochrom> Yeah, rooted directed etc
12:59:37 <cocreature> sssilver: if you’re enjoying it a lot why would you stop :)
12:59:44 <cocreature> sssilver: but yeah it’s definitely a good book!
13:00:06 <monochrom> Naw, too much of any good thing is bad. You should go play. Maybe not right now but eventually.
13:00:12 <dmwit> hyperisco: I am even willing to expand the family further if you are interested.
13:00:31 <hyperisco> I am bothered by "a graph is a tree without the unique-path property" because it describes a graph by removing something from trees without adding what is possible
13:00:44 <monochrom> But hey is Category Theory for Programmers really that good?  What's good about it?  (I'm curious, I haven't read it.)
13:01:31 <dmwit> monochrom: It will not go far enough to interest you.
13:01:41 <monochrom> darn
13:01:42 <hyperisco> i.e. if I start with a tree and just remove that requirement it doesn't give me enough tools to discern if an object is a graph or not
13:02:39 <monochrom> Actually I haven't learned representable functors and Yoneda, so maybe I could use it.
13:02:56 <monochrom> Oh and Kan extensions.
13:03:23 <monochrom> Although, it's a matter of principle that I stay away from topoi.
13:03:34 <dmwit> monochrom: Ignore me, I'm thinking of a completely different book.
13:03:40 <monochrom> Ah heh OK.
13:03:48 <dolio> Big mistake. :þ
13:03:54 <monochrom> You were thinking Benjamin's Pierce's?
13:04:04 <dmwit> yes
13:04:05 <dolio> Oh yeah. That book is not that amazing.
13:04:21 <dolio> Although it covers some stuff that doesn't get mentioned in most 'real' category theory books.
13:05:03 <monochrom> It has helpful examples for whatever basic things it covers.  I got and read a photocopy anyway.
13:05:11 <hyperisco> dmwit, I feel like trees are far enough removed from graphs that I wouldn't be inclined to explain either in terms of the other
13:05:23 <hyperisco> dmwit, no more than I'd want to explain lists with trees or trees with lists
13:05:24 <monochrom> Actually I learned exponentiation from it.
13:05:52 <dmwit> I make no claims about whether Pierce's book goes far enough to interest past incarnations of monochrom.
13:06:05 <monochrom> Heh
13:06:12 <thyr15t0r> omg! cabal on windows: Installed gtk3 lol. but i got hundreds of different errors and warnngs in logs
13:06:27 <davr0s> anyone know much about attempts to compile haskell to *hardware* (eg FPGAs) .. there's claims that purity/dependancy graph can help describe operations in ways that can be mapped to hardware pipelines...?
13:06:42 <cocreature> davr0s: take a look at clash
13:06:49 <hyperisco> davr0s, see conal's work. That is exactly what he was working on at Tabula.
13:07:00 <dmwit> I changed my mind, I will make a claim. If we pick the right past incarnation of monochrom, Pierce's book will interest him.
13:07:05 <davr0s> thats the one. sounded awesome
13:07:07 <Athas> davr0s: compiling full Haskell to FPGAs would be extremely difficult.
13:07:19 <davr0s> of coruse
13:07:28 <cocreature> thyr15t0r: you’ll have to be a bit more specific as to what errors you are encountering
13:07:46 <davr0s> i guess the other thing to ask about is 'map-reduce' use of clusters
13:07:53 <Athas> There is also Lava, which I think is more low-level than Clash.
13:08:13 <davr0s> i dont have a cluster but i do have the beginings of a minature raspbery-pi cluster lol.
13:08:16 * hyperisco apparently has Clash bookmarked but has also never heard of it
13:11:52 <hyperisco> can you just use verilog for embedded programming or is that unnatural?
13:12:05 <Athas> It's very low-level.
13:12:18 <hyperisco> well sure but that is what high level languages like Clash are for, presumably
13:12:42 <hyperisco> I was looking at embedded options in Haskell a few months ago
13:13:38 <hyperisco> verilog is for programming fpgas afaik but presumably you could emulate it on a conventional CPU
13:13:52 <hyperisco> in what I would also presume an efficient manner
13:13:57 <thyr15t0r> <cocreature> i got 'gtk3 installed' in cmd console. no messages about errors there. but i chek logs. for example: tabs in code, gtkstock is deprecated, [-Woverflowed-literals], ignoring field. a lot of them. one of logs has 150 kB size! 8)
13:14:20 <hyperisco> obviously not going to achieve the highly parallel IO capabilities…
13:15:32 <cocreature> thyr15t0r: if you don’t get any errors then you’re probably seeing warnings and errors and most likely it’s fine to ignore those
13:15:47 <geekosaur> verilog is more about emulating hardware in order to design hardware. you can convert it to fpga programming but fpgas are themselves inherently inefficient because of that programmability
13:15:56 <hyperisco> at any rate it is really easy to get inexpensive MCUs to tinker with but not easy to get fpgas to tinker with
13:16:40 <hyperisco> geekosaur, well if you use an fpga for the right purpose, i.e. highly parallel IO, then that ought to be just the tool for the job no?
13:17:06 <hyperisco> I have nightmares about how ridiculous bit banging on a CPU is
13:17:11 <thyr15t0r> <cocreature> ok. you are great
13:17:15 <cocreature> thyr15t0r: but I’m also not entirely sure why you are installing gtk3 as opposed to gi-gtk as suggested in the page that I’ve linked you multiple times by now :)
13:17:45 <thyr15t0r> <cocreature> i did it and did that
13:17:49 <geekosaur> in soem relatively limited use cases. verilog is going to get youthe opposite side of that "ridiculous bit banging"
13:17:59 <geekosaur> i.e. why it's ridiculous
13:18:13 <hyperisco> not sure I follow
13:18:14 * ski idly wonders why thyr15t0r appears to be putting words in cocreature's mouth
13:18:57 <cocreature> hyperisco: you can actually get pretty cheap fpgas with fully open source toolchains for toying around. take a look at the lattice ice40 fpgas
13:19:14 <hyperisco> it is ridiculous because you burn so much CPU time doing nothing but polling pins
13:19:27 <c50a326> any chance anyone can tell me the vague pseudo-code to make this work? https://ptpb.pw/FvuN/hs#L-46 I've been trying different stuff and none of it works and I don't understand any of it :(((
13:19:40 <c50a326> I don't even know wtf I'm trying anymore
13:19:55 * ski . o O ( partial evaluation on FPGAs )
13:20:01 <geekosaur> hyperisco, exactly.and verilog is about pretending t be the polled pns
13:20:21 <cocreature> c50a326: can you provide some more details for what this is supposed to do?
13:20:25 <geekosaur> it's not an embedded programmng langaue and it's fairl ineficient when used as such
13:20:30 <geekosaur> fairly inefficient
13:21:37 <c50a326> cocreature: page 14 of this paper http://web.cecs.pdx.edu/~mpj/pubs/springschool95.pdf I tried to take a screenshot but screenshot tool isn't working right now :@
13:22:24 <c50a326> the paper even says "we sketch the implementation" but it doesn't really imo
13:23:19 <c50a326> it's really hard
13:23:30 <c50a326> I want to f'ing kill myself honestly
13:23:59 <c50a326> well not really but this is the worst I've felt in front of a computer in a long time
13:24:21 <c50a326> draw a f'ing tree... can't even draw a f'ing tree... ffs
13:24:31 <hyperisco> c50a326, when I get in states like that then first thing I do is stop. Maybe call it a day or work on something else and try again on this tomorrow.
13:25:03 <hyperisco> c50a326, second thing I do is go back to the drawing board to rediscover or rethink what the fundamental pieces are. Maybe I am taking on too big of a problem and need to dice it to smaller pieces.
13:25:21 <jle`> c50a326: it's definitely also not exactly an easy function to write, judging from the example inputs and outputs
13:25:32 <ski>  /wg 37
13:25:33 <c50a326> ah I already did that, I did a bunch of practice with zipping and concat/filter/map and stuff from "Introduction to Functional Programming"
13:26:06 <hyperisco> To get started, I try and fill in the blank of "This would be much easier to solve if only I could ____"
13:26:17 <c50a326> haskell aside I have too hard of a time trying to think how to solve the programming problem in general tbh
13:26:34 <c50a326> I've used pen and paper to dice up the chars/lines how they can be chopped
13:26:48 <hyperisco> then if I figure out a good candidate for that blank I'll refocus on how to solve that narrower problem
13:26:57 <orzo> Is there a common go-to data structure for something that is basically just [x] but with every operation updating a readily O(1) available length?
13:27:05 <hyperisco> human brains are pitifully limited but you'll get used to it ;)
13:27:25 <cocreature> c50a326: think about how you can combine drawings of the children and the current node to construct the full drawing
13:28:44 <orzo> And if there is not such a thing, is there a good reason why there's not such a thing?  Like, maybe it's pointless for reasons that escape me?
13:28:50 <hyperisco> c50a326, for processing data there is usually one or more intermediate structures you can create
13:29:39 <hyperisco> so you could look at the structure of the tree, then look at the structure of the string, then imagine, starting from the tree, what a structure would be that is a bit closer to the string
13:29:43 <orzo> I'm re-implementing an algorithm that was done in c++ using std::vector<> and [x] seems excelent for the most part, but there's a few cases where O(1) length is assumed
13:29:44 <c50a326> cocreature: https://lpaste.net/7059989068465045504 this function I wrote after the intersperse/intercalate stuff from earlier kind of does that
13:30:09 <c50a326> trying to apply it recursively from the drawTree function ended up with some massive mess on my screen
13:31:24 <hyperisco> if your string is multiline then a place to start thinking is what each line looks like
13:31:30 <c50a326> one problem is that you want the first sub-tree inline with the current node, like "--@--5" or "--@--@"
13:31:37 <hyperisco> because you can take a list of lines and make that a string
13:31:43 <Cale> orzo: You could always use Data.Vector
13:32:04 <hyperisco> and maybe the tree is easier to draw sideways in lines, then you can just transform the list to turn it
13:32:19 <hyperisco> or maybe easier to draw upside down and you can reverse the list to flip it
13:33:47 <orzo> Cale, without mutation, vector would be worse than what i'm doing with [x] even with my O(n) length
13:34:33 <Solonarv_> orzo: or Data.Sequence
13:34:42 <orzo> hm
13:35:06 <orzo> Data.Sequence makes sense i guess.  Does it do O(1) length?
13:35:18 <Cale> yeah
13:36:02 <Cale> It also does O(log n) concatenation where n is the length of the shorter piece
13:36:07 <Cale> (and splitting)
13:36:09 <monochrom> You can define your own O(1)-length-query list type. data MyList a = Ctor Int [a]   -- data invariant: the Int field equals the list length.
13:36:21 <monochrom> I even made it a question on my exam.
13:36:23 <cocreature> c50a326: it might be helpful to simplify this by removing all typeclass and work with a concrete tree type first, e.g., https://gist.github.com/cocreature/93c9e8a92ff92b830f5fc7a1c0648270
13:36:33 <orzo> monochrome, that's what i had in mind, i just figured it was probably in some library for me already
13:36:42 <monochrom> But with immutability, some operations will be slow.
13:36:57 <hyperisco> you might find it as "list with length" i.e. every cons includes the length
13:37:27 <monochrom> Oh yeah actually I gave "every cons cell has length field" on my exam.
13:37:44 <monochrom> data MyList a = Nil | Cons Int a (MyList a).
13:38:00 <monochrom> Not very pretty because Nil is an annoying corner case but meh.
13:38:13 <hyperisco> I wonder if you can eek out performance by specialising small lists
13:39:21 <orzo> the alrogorithm mainly does a lot of append, which i've successfully replaced with prepend(cons) in casting the collection as [x]
13:39:52 <hyperisco> up to size 16 would give you 256-sized jump tables
13:40:20 <hyperisco> for, say, list append
13:41:21 <orzo> these lists i'm working with should usually be small, around 10, but can be as large as 1000
13:41:59 <hyperisco> lists of arrays is probably more prudent
13:43:11 <orzo> entries are usually 32-byte objects except when they are recursively lists again
13:48:49 <orzo> hyperisco: maybe it would payoff to store lists as conses in the first generation and only do the specializing when we move data during collection
13:49:47 <orzo> i suspect that would workout rather nicely
13:49:58 <hyperisco> that is an interesting thought
13:50:29 <hyperisco> I heard of collections improving locality but didn't think of this sort of unboxing
13:51:24 <cocreature> c50a326: fwiw I made a quick’n’dirty implementation of the simplified version. I don’t want to ruin the fun of figuring it out yourself but if you want something to look at, let me know
14:03:18 <c50a326> hey was just walking home
14:06:34 <cocreature> c50a326: bedtime for me now but feel free to ping me tomorrow if you’re still having trouble and/or want to take a look at my code
14:06:41 <c50a326> okay awesome
14:06:42 <c50a326> thank you so much!
14:06:57 <dmwit> monochrom: You might enjoy pondering the Monoid instance for `type LL a = (Sum Int, [a])`. With `singleton :: a -> LL a` it is almost a complete list API on its own.
14:07:57 <[exa]> tree drawing has SO many possibilities to be done right
14:07:59 <[exa]> I like it
14:09:12 <dmwit> If only there was `instance Monoid (f (g a)) => Monoid (Compose f g a)` you could even get a `Foldable` and `Traversable` API for free, too.
14:10:23 <[exa]> there's none?
14:11:31 <[exa]> like, there is more than 1 possibility to do it right, but that's true with many more typeclasses that have monoid and fold/traverse
14:11:56 <dmwit> Are you responding to me or still talking about trees?
14:14:13 <benzrf> dmwit: how about reverse
14:17:38 <tsaka_> Is it possible to do what I want to achieve here? https://lpaste.net/8156580947408453632
14:19:07 <davr0s> pattern matching:   |  is guard syntax , right?  I'm trgint to find how to match on several options (to one arm) where in rust you'f write   match foo {    'a'|'b'|'c' =>  .....    'd'=> ... }
14:19:26 <benzrf> davr0s: yeah, haskell doesn't really have something analogous to that
14:19:38 <benzrf> unfortunately
14:19:54 <benzrf> well, i think you only want it occasionally anyway
14:20:27 <benzrf> quite often you can achieve your desired result by putting specific cases first and then having a wildcard handle the rest
14:20:48 <benzrf> for example, if a b c d are exhaustive, you can do case foo of 'd' -> ...; _ -> ...
14:20:56 <[exa]> dmwit: I was responding to you, sorry for ambiguity
14:20:59 <davr0s> yeah i was about to do  _|if .... ->
14:21:21 <[exa]> dmwit: OTOH it wasn't a particularly useful response.
14:21:29 * ski . o O ( `elem' )
14:30:50 <davr0s> is there the oppostie of "concat.intersperse" for strings, i.e. split by delimeter eg "," "1,2,3,4" -> ["1","2","3"]
14:30:59 <davr0s> (before i write it..   can't find in hoogle)
14:34:07 <phadej> davr0s: check `split` package
14:35:07 <phadej> http://hackage.haskell.org/package/split
14:35:24 <davr0s> ok grabbing it/ i see "splitOn"
14:38:20 <davr0s> perfect
14:43:03 <infinisil> Um, how can I convert a ByteString into a Vector [Word8]?
14:43:14 <infinisil> Or: How can I read a file as a Vector [Word8]?
14:43:34 <davr0s> realising you can also just write stuff with tail recursion to do things a bit more manually without having to go through the abstractions all the time is helping (sounds obvious i know)
14:44:15 <davr0s> 'here's what the language engine does, now you can do stuff.   <there's also these huge abstracionts you can wade through to do stuff *quicker* once you know it>'
14:45:36 <Cale> davr0s: One thing I found helpful starting out was learning that you can translate an arbitrary imperative program into a functional one where you turn each point of control into a function, and turn all the local mutable variables into function parameters.
14:46:02 <davr0s> right
14:46:04 <Cale> (all the locally-accessible mutable variables, I should say)
14:46:04 <davr0s> exactly that.
14:46:47 <Cale> You almost never actually *do* that, but I have actually done it in order to understand some weird C programs
14:47:08 <Cale> Translate to Haskell, then use equational reasoning to simplify until it's sane :D
14:49:08 <infinisil> Okay, I should be able to translate a ByteString into Vector Word8 by doing `BS.unpack :: ByteString -> [Word8]` and `V.fromList :: [a] -> Vector a`
14:49:28 <infinisil> But both of those seem to have O(n) runtime
14:50:14 <infinisil> Is that just O(n) because it needs to read all the chunks from the file and ByteString being lazy?
14:50:45 <Cale> infinisil: It's O(n) because it's literally enumerating each of the bytes
14:51:21 <Cale> infinisil: Think about the intermediate list you're constructing. Even if it's not all in memory at the same time, it still has n elements.
14:51:38 <infinisil> But it can be consumed immediately by V.fromList
14:51:47 <Cale> sure
14:51:58 <infinisil> I guess the Vector still needs to be constructed with each byte though
14:52:10 <Cale> yeah
14:52:12 <Cale> It's still going to take some amount of time on each byte
14:52:24 <infinisil> But from ByteStrings description: "A space-efficient representation of a Word8 vector, supporting many efficient operations."
14:52:41 <infinisil> So this is kind of a ironic, that Vector Word8 isn't something efficient to convert to
14:53:54 <infinisil> Cale: Maybe there's a way to do it with unsafe code
14:58:32 <orzo> is there a way to un-evaluate, that is turn a fully evaluated object back into a thunk for memory compression reasons?
14:58:51 <`Guest00000> gorgeous question
14:58:57 <Cale> orzo: Not really.
14:58:58 <`Guest00000> standardly, i think, no
14:59:06 <`Guest00000> but that's a cool idea
14:59:43 <`Guest00000> but... you can throw away the object and take a thunk again
15:00:06 <`Guest00000> use   myThunkForX :: () -> X   for having thunks
15:00:25 <`Guest00000> and bind   let myX = myThinkForX (); ... in ...
15:00:31 <`Guest00000> to evaluate an obj
15:00:37 <`Guest00000> probably how it works...
15:02:14 <orzo> would probably need a NOINLINE pragma
15:02:58 <orzo> maybe NOINLINE is more important than the () argument
15:04:02 <orzo> i was trying to code a data object that has the ability to generate a list as needed, but that doesn't internally remember data as a list
15:09:19 <davr0s> hehe. That "haskell works first time once it compiles" just hit me.
15:12:23 <jle`> feels good right davr0s :)
15:12:53 <davr0s> one of lifes rare *pleasant* surprises.
15:31:15 <greymalkin> I'm trying to make something like `bracket :: MonadIO m => IO a -> (a -> IO b) -> (a -> m c) -> m c` -- the only alternative I can find is MonadBaseControl -- which I feel is severe overkill 
15:33:00 <greymalkin> Ah... exception-transformes may be what I'm looking for.
15:35:18 <jle`> greymalkin: MonadBaseControl and family was pretty much invented to solve that specific problem, so it's pretty much the exact thing it was meant for, heh.  but people have been moving away from it in favor of unlift-io
15:36:15 <geekosaur> it seems like overkill until you start thinking abut recovery from exceptions and whether you're going to leak a filehandle or database connection sometimes
15:36:40 <geekosaur> "leak" in this case meaning "lose track of"
15:37:07 <geekosaur> so it's there but there's no way to either use it or close it properly
15:37:13 <greymalkin> geekosaur: I mean that having the acquire and release parts of bracket be anything deeper than IO is overkill.
15:38:59 <greymalkin> Not in every case, but in most that I've bumped into it has been.
15:46:02 <jle`> oh no
15:46:19 <jle`> the new ghc-8.6 hole fills feature is great
15:46:30 <jle`> but it often suggests partial functions :(
15:48:30 <davean> jle`: its got quite a few issues in its suggestion heuristics
15:48:37 <davean> I expect that will improve though!
15:58:43 <geekosaur> it'd help if "partial" were represented in the type system
15:59:36 <geekosaur> (of course, if we did that it the functions arguably wouldn't be partial any more. I mean, that's what Maybe is for.)
16:00:45 <dmwit> Then we can introduce partiality polymorphism.
16:01:01 <dmwit> So that e.g. `map` can work with partial or total arguments and be partial or total accordingly.
16:01:18 <dmwit> This is a great idea, we ought to be able to squeeze at least one paper out of this.
16:01:38 <alp> =)
16:01:49 <davean> Its lucky theres no problems with this idea at all
16:04:44 <geekosaur> heh. I kinda decided I didn't want to look there… because someone has to have already thought of it, and found the problems
16:05:16 <geekosaur> (not to say that "partial" is already poking the halting problem with a sharp stick)
16:37:11 <jle`> i wouldn't mind there at least being some sort of explicitly partial annotation one could provide when implementing a library
17:04:03 --- mode: glguy set +v hs2math
17:16:06 <chessandgo> how smart is GHC when it comes to tail call recursion? I've got some explicit recursion, where the function will either call itself at the bottom, or will end up calling itself self in the middle. None of these will return
17:18:32 <exio4> it's pretty good, because GHC works in a way where everything is a tail-call in `normal terms`, there's many stacks though :)
17:19:35 <chessandgo> thanks, well, my function isnt *too* complex, but it certainly cant be completly replaced with forever either! hopefully it doesnt explode
17:20:00 <dmwit> mmm, tail-call isn't super important in Haskell.
17:20:11 <dmwit> guarded recursion is the property of interest for lazy functions.
17:20:15 <dolio> Disagree. :)
17:20:32 <exio4> chessandgo: the trick here is that a function can make a big unevaluated expression
17:20:50 <exio4> chessandgo: i'd recommend checking on foldl / foldl' / foldr
17:21:29 <dmwit> Right, exio4 is making the point I wanted to but more clearly: it's easy to write a tail-recursive function that nevertheless has bad performance due to incorrect strictness.
17:21:30 <dolio> It's true that you shouldn't be thinking about tail calls, really.
17:21:36 <chessandgo> exio4: this is an IO performing function, so i cant just use a fold
17:21:55 <dolio> But it's also true that _every_ call in GHC is a tail call, like exio4 said.
17:21:57 <chessandgo> gameLoop = do something >> gameLoop 
17:21:59 <chessandgo> style kind of thing
17:22:09 <dolio> There are more tail calls than the languages where tail calls are important. :)
17:30:34 <exio4> chessandgo: on checking foldl/foldl'/foldr - I meant as examples on what Haskell (and GHC) will be doing with evaluation
17:31:29 <exio4> chessandgo: foldr - for example - is where lazy evaluastion excels, and foldl is more often than not a pretty bad with naive lazy evaluation
17:32:14 <chessandgo> well
17:32:19 <chessandgo> seeing as my ram usage is not going up
17:32:22 <chessandgo> it seems to be working
17:32:40 <exio4> chessandgo: this is where foldl' (which `seq`s the accumulator, and forces it to weak head normal form (WHNF) to avoid making a big unevaluated expression
17:32:53 <exio4> chessandgo: in your particular case - it seems to be right (it's how forever is implemented too!)
17:33:19 <chessandgo> I wasnt really worried about thunks, (as everything is evaluated) i was worried about stack frames
17:33:28 <chessandgo> since im calling the same function into itself 
17:33:33 <chessandgo> and in different place
17:34:34 <exio4> e.g. foldl (+) 0 [1,2,3] = foldl (+) (1 + 0) [2,3] = foldl (+) (2 + (1 + 0)) [3] = foldl (+) (3 + (2 + (1 + 0))) [] = 3 + (2 + (1 + 0)) = 3 + (2 + 1) = 3 + 3 = 6 
17:35:08 <chessandgo> in doing a blocking wait on the network, either I get some text data, I then call the same function normally, or I get a new serverid type, and I call myself, but from within another funcction, that runs the looping function with a new server ip
17:35:12 <exio4> chessandgo: the problem is that the concept of `stack frames` as conceptually thought in a strict programming language is not particularly useful within Haskell's semantics
17:35:21 * dmwit notes that `foo = bar >> foo` is not tail-recursive
17:35:43 <ski> `f x' is surely not a tail call wrt `case f x of ...'
17:35:52 <chessandgo> exio4: what does haskell do for functions if not creating a new stack?
17:36:02 <ski> dmwit : depends
17:36:28 <dmwit> It's not tail-recursive with the traditional definition of tail-recursive.
17:36:30 <dmwit> Which is kind of my point.
17:36:41 <dmwit> The property of interest in Haskell is rarely whether the thing is tail-recursive.
17:37:57 <ski> chessandgo : function calls per se doesn't need to use up stack, even in strict languages
17:38:24 <ski> chessandgo : remembering something to do after a call, will use up stack, however
17:39:19 <ski> in e.g. SML, in a call `g x' in `f (g x)', it's remembering to call `f' after the call to `g' that uses up stack. not the call to `g' itself
17:40:37 <ski> in Haskell, in a call `f x' in `case f x of ...', it's remembering to go to the appropriate branch after the call to `f' that uses up stack, not the call to `f' itself
17:41:13 <chessandgo> ski: the "remembering to do something after" part, is that avoided by the fact its the same function calling itself
17:41:23 <chessandgo> so it only needs one copy of the "things it might do after"
17:41:34 <dmwit> Nah, it's avoided by not having to do anything after. =)
17:41:36 <ski> that said, if your operation is incremental, rather than bulky (as tail recursions always are), then that's often better. e.g. `map' in Haskell
17:42:03 <chessandgo> how does it know if you dont have anything do after
17:42:26 <ski> (hence people saying tail recursion is not a big deal in Haskell. that's true, but it's still sometimes important, and a relevant concept)
17:42:56 <chessandgo> here let me paste a modified version of my function
17:42:57 <ski> chessandgo : same as with a strict language, except the definition of "tail position" is slightly different
17:44:46 <chessandgo> gameLoop game = do
17:44:47 <chessandgo>     _ <- CH.receiveWait [CH.match thisReturns, CH.match thisCallsgameLoop]
17:44:47 <chessandgo>     gameLoop game
17:44:54 <chessandgo> thats more or less what my function is
17:45:01 <ski> chessandgo : depends on the monad
17:45:39 <exio4> (is this why people get scared when they try Haskell? :P) 
17:45:40 <chessandgo> Process monad from Cloud Haskell if thats any help
17:46:07 * ski doesn't know it
17:46:19 <geekosaur> they don't get scared when they try it, they get scared when they see it
17:46:33 <geekosaur> because it "breaks all the rules"
17:46:36 <chessandgo> im just having a hard time believing it can be prepared for if the first line returns or calls gameLoop again
17:46:39 <ski> exio4 : "this" being ?
17:47:12 <exio4> ski: their knowledge on evaluation not being particularly useful when directly applied
17:47:18 <exio4> ski: what geekosaur said :) 
17:47:45 * ski didn't notice `thisCallsgameLoop' -- presumablt that's not going to be a tail call wrt the execution of `gameLoop'
17:48:51 <chessandgo> does that mean im slowly going to leak memory
17:50:55 <ski> depends on how deep that branch of the call tree will be, no ?
17:52:09 <ski> "proper tail recursion" (somewhat of a misnomer, since it doesn't, per se, have to do with recursion) means that you can support an unbounded number of active tail calls in bounded space (however you implement that)
17:52:14 <chessandgo> thisCallsgameLoop never returns, as gameLoop calls itself, so itll only keep getting deeper
17:53:15 <ski> if that branch will be bounded (or even shallow), it possibly won't matter much that it's not doing tail calls
17:53:18 <geekosaur> I'd be inclined to refactor just so it's easier for me to kep track, never mind the compiler
17:53:40 * ski has no idea what `CH.receiveWait',`CH.match' does
17:54:02 <dmwit> chessandgo: This almost certainly slowly leaks, yes.
17:54:40 <chessandgo> Cloud Haskell functions, receiveWait is a blocking wait for checking a process's inbox for some type
17:55:27 <chessandgo> where CH.match will match a type. Each CH.match can match any type (thus match against an inbox full of heterogenous types), as long as the return type is the same
18:09:49 <chessandgo> if I end a function with a case, will each branch be considered the end of the function and thus not leak when it recurses
18:10:36 <ski> branches are in tail-position wrt the whole `case' expression, yes
18:12:50 <chessandgo> its not as nice of a function as before, but it works
18:13:23 <chessandgo> this whole issue has to do with the inbox having any type in it, which is pretty hard to deal with
18:16:21 --- mode: glguy set +v scott_
18:17:41 <scott_> +v
18:20:07 --- mode: glguy set +v dsadsa
19:00:31 --- mode: glguy set +v DGL
19:01:49 <DGL> anyone available to help with a homework problem?
19:08:56 <jle`> DGL: you'll probably get best results by just asking your question
19:09:06 <jle`> anyone who is available will read it :)
19:09:24 <jle`> but it's rare that someone would volunteer to commit before knowing what the problem is
19:10:13 * monochrom . o O ( Two-phase commit. Byzantine generals. )
19:10:49 <monochrom> Also that twitter joke on TCP/IP.
19:11:15 --- mode: glguy set +v DGL_
19:11:42 <DGL_> I am getting an Occurs check error specifically cannot construct the infinite type:
19:12:10 <DGL_>   tupleAccept1 [] _ _ = False   tupleAccept1 [x : xs] fourTuple str      | null (findNext fourTuple x str) = False       | dfaAccept1 xs fourTuple (findNext fourTuple x str) = True
19:12:38 <monochrom> Perhaps "(x:xs)" instead. Haskell is not Prolog.
19:12:51 <monochrom> Or Perl.
19:14:41 <DGL_> thanks, though the error didn't change
19:15:47 <monochrom> You have not given complete code therefore you have not eliminated the hypotheses that you have extra problems.
19:16:41 <DGL_> I am sure I do I didn't want to spam chat I'll post more though
19:17:02 <monochrom> You don't know that the Internet has such a thing as "pastebin"?
19:17:56 <DGL_> ?
19:25:14 <DGL_> dfaFactory = (sta, ssta, fsta, trans)      where sta = [("S0", "S1", "S2", "S3", "S4")]            ssta = ["S0"]            fsta = ["S3"]            trans = [("S0", '0', "S1"), ("S0", '1', "S1"), ("S0", '.', "S2"), ("S1", '0', "S1"),                     ("S1", '1', "S1"), ("S1", '.', "S3"), ("S2", '0', "S3"), ("S2", '1', "S3"),                     ("S2", '.', "S4"), ("S3", '0', "S3"), ("S3", '1', "S3"), ("S3", '.', "S4"),                
19:25:34 <DGL_> getStates(states,_,_,_) = states getFirstState(_,firstState,_,_) = firstState getFinalStates(_,_,finalState,_) = finalState getTransitions(_,_,_,transitions) = transitions getFromState(fromState,_,_) = fromState getLabel(_,label,_) = label getToState(_,_,toState) = toState matchTransition state input trnsitn = if state == getFromState trnsitn && input == getLabel trnsitn then True else False findNextState dfa inChar state = filter (\x ->
19:27:02 <DGL_> (getTransitions dfa) dfaAccept dfa input = dfaAccept1 input dfa (getFirstState dfa) dfaAccept1 [] _ _ = False dfaAccept1 (x : xs) dfa state    | null (findNextState dfa x state) = False     | dfaAccept1 xs dfa (findNextState dfa x state) = True
19:29:34 <geekosaur> you could use gist.github.com or some other reputable pastebin
19:29:39 <boj> DGL_: please post your code into https://gist.github.com/ and link it
19:29:43 <geekosaur> code psted inc hannel is pretty much unreadable
19:30:12 <DGL_> thanks
19:33:51 <DGL_> https://gist.github.com/dgl247/ecfb3260e3e30116ef9c2d59b99c50c3
19:43:21 --- mode: glguy set +v gsdfgf
19:48:42 <NemesisD> does anyone have any experience with dimensional? i'm trying to figure out a safe way to serialize and deserialize a Mass value from the database
19:55:52 <mniip> hmm
19:57:10 <mniip> I wonder if anyone has considered a functional compiler that inlines closure passing for small numbers of free variables
19:57:45 <Zipheir> DGL_: The second equation of dfaAccept1 recurses on xs immediately, that looks suspicious.
19:58:51 <mniip> instead of making closures (code pointer with array of free variable isntantiations) the default, why not pass the code pointer and the free variable values in registers when possible
19:59:40 --- mode: glguy set +v freeuser99
20:02:30 <mniip> you can probably even come up with a type theory for this
20:03:15 <mniip> suppose (->N) are subtypes of (->) for all natural N and represent functions that are static code with N values closed over
20:03:47 <mniip> (+) :: Int ->0 Int ->1 Int
20:05:06 --- mode: glguy set +v florp
20:05:50 <Zipheir> DGL_: Your problem seems to be due to passing an argument of type [String] to dfaAccept1, which is expecting a String
20:06:03 <Zipheir> DGL_: Using type annotation will make this easier to spot.
20:06:13 <dmwit> mniip: I guess one of the costs of this would be incurring a conditional branch *every* time you passed a closure.
20:06:19 <mniip> apply :: (a ->i b) ->0 a ->i b
20:06:29 <dmwit> mniip: Since the thing receiving the closure would have to choose whether to look in registers or in array.
20:06:46 <nshepperd> how do you ensure nothing stomps on those registers?
20:06:52 <mniip> dmwit, no I was thinking it could be decided at compile time
20:07:26 <dmwit> mniip: Seems unlikely, given how dynamic closures are.
20:07:47 <mniip> well consider how C++ compiles lambda functions
20:08:27 <mniip> when you pass a lambda to a HOF you essentially pass a closure struct
20:08:49 <mniip> if the HOF is inlined, the code pointer and the closed over values can be register-passed instead of being packaged into an allocated struct
20:08:51 --- mode: glguy set +v freeuser99
20:10:07 <mniip> now I think I see what the problem is
20:10:21 <monochrom> Many RISCs had hundreds of registers so you don't have to worry about register pressure for a while. In fact they also come with a sliding window thing so you could use them as your call stack.
20:10:22 <DGL_> @tell zipheir thanks, I tried using type annotation, but it made things worse I know what it is doing, but I don't get why, it is a string being given to the function not a list of them
20:10:22 <lambdabot> Consider it noted.
20:10:26 <mniip> you can probably fit lambda calculus into this construction
20:10:29 <mniip> er
20:10:34 <mniip> you can probably fit simlpy typed lambda calculus into this construction
20:10:45 <mniip> but parametric polymorphism is where it gets complicated
20:12:39 <nshepperd> if the HOF is inlined and you can see where your lambda is called, can't you just inline it away already?
20:13:02 <mniip> nshepperd, code structure
20:13:13 <mniip> you wouldn't inline a comparator into a sort algorithm
20:13:25 <DGL_> mniip I am limited with how I can do this assignment I was only given a brief 2 page pdf of Haskell
20:13:40 <Zipheir> DGL_: It's pretty simple. Just look at the type of dfaFactory, getFirstState (DFA -> [String]), and dfaAccept1.
20:14:57 <Zipheir> DGL_: In particular, the second element of your DFA tuple is a list of String.
20:15:55 <monochrom> When I am a code optimizer I am trigger-happy to inline a comparator into a sorting algorithm actually.
20:16:19 <mniip> right, if that sorting algorithm is invoked once in your program
20:16:29 <mniip> and your program is performance bound
20:16:36 <mniip> and the values are small
20:16:50 <mniip> bytewidth-wise small I mean
20:18:27 <mniip> hmm
20:18:35 <mniip> there was a paper called types are calling conventions
20:18:52 <mniip> now that I think of it, in reality, kinds are calling conventions
20:19:06 <DGL_> @tell zipheir hmm so I need to make getFirstState return a String
20:19:06 <lambdabot> Consider it noted.
20:19:30 <monochrom> But hey a kind system is a type system at a meta level.
20:20:20 <monochrom> Plus maybe you need both types and kinds together to explain a calling convention. And maybe you just say "a completely described type system has to describe kinds too".
20:20:29 <Zipheir> DGL_: I'm still here. We don't need to talk via lambdapost.
20:21:00 <c_wraith> in GHC, it's more like levity is calling convention
20:21:33 <mniip> levity is so old fashion
20:21:37 <mniip> runtimerep is where it's at
20:21:54 <mniip> but yes that's the general idea here
20:22:12 <c_wraith> that's not types in general, just a tiny little part of them
20:22:13 <mniip> the exact kind the function arrow is used at determines the calling convention of the function
20:23:18 <mniip> basically what I'm saying that instead of (->) :: _ -> _ -> TYPE LiftedRep
20:23:21 <DGL_> Zipheir: sorry
20:23:41 <mniip> maybe it makes sense to sometimes have -> TYPE (UnboxedTupleRep [...])
20:23:43 <Zipheir> DGL_: The question that comes to mind is "why would the first state be a list?"
20:24:08 <DGL_> Zipheir: It can't be actually
20:25:06 <mniip> if I have a sequence of kinds 0,1,2..., with  (->) :: i -> j -> (i+j+1)
20:25:11 <mniip> and all type constants of kind 0
20:25:14 <mniip> does that make sense
20:26:20 <Zipheir> DGL_: Your DFA type is ([(String, String, String, String)],[String],[String],[(String, Char, String)]) and getFirstState returns the second element of a DFA tuple.
20:26:33 <mniip> that didn't make sense to me...
20:27:05 <Zipheir> DGL_: That's also a really convoluted type... but I guess that's someone else's code that you're required to use?
20:27:21 <mniip> oh yeah for simplicity's sake let's take a call by value language so an Int is always just an Int
20:27:36 <monochrom> mniip: Do you mean "(I use i registers) -> (I use j registers) -> (I use i+j+1 registers)"?
20:27:45 <mniip> that's the idea
20:27:50 <mniip> but I think the kind of (->) is wrong
20:28:55 <DGL_> Zipheir: I am limited to coding what is on the PDF that I was given, though coding is left up to me as long as I don't branch out from there
20:29:59 <Zipheir> DGL_: getFirstState (_, [x], _, _) = x
20:30:31 <Zipheir> DGL_: Since your dfaFactory function hard-codes a singleton list in that position, why not?
20:31:20 <mniip> :t let arr :: clos i -> clos j -> clos (i + j + 1); int :: clos 0 in int `arr` (int `arr` int)
20:31:21 <lambdabot> error:
20:31:21 <lambdabot>     The type signature for ‘arr’ lacks an accompanying binding
20:31:21 <lambdabot> error:
20:31:38 <mniip> :t let arr :: clos i -> clos j -> clos (i + j + 1); arr = arr; int :: clos 0; int = int in int `arr` (int `arr` int)
20:31:40 <lambdabot> error:
20:31:40 <lambdabot>     Not in scope: type constructor or class ‘+’
20:31:40 <lambdabot> error:
20:31:46 <mniip> dammit lambdabot smarten up
20:32:06 <mniip> anyway the result is 'clos 2'
20:32:10 <mniip> which is not the right kind
20:32:15 <DGL_> Zipheir: that is genius, but still doesn't change my error message
20:32:21 <mniip> a (+) :: Int -> Int -> Int should be of kind 0
20:33:47 <DGL_> Zipheir: Occurs check: cannot construct the infinite type: a2 ~ [(a2, a, c1)]
20:34:26 <Zipheir> DGL_: Yeah, that's another type error.
20:34:46 <Zipheir> DGL_: Specifically here: dfaAccept1 xs dfa (findNextState dfa x state)
20:35:07 <jle`> yay new stackage nightly is 8.6 
20:35:47 <orzo> is there a switch that will make ghc accept signatures without bindings and just fill in bindings to undefined?
20:36:27 <mniip> does the kind have to be  i -> (j + 1) -> j
20:36:39 <Zipheir> DGL_: I strongly recommend writing out the types for all of these functions.
20:36:53 <monochrom> orzo: I think no.
20:37:15 <DGL_> Zipheir: would love to, but I'd need examples it isn't on my pdf
20:37:20 <mniip> hey jle` are you any good at machine code
20:38:32 <Zipheir> DGL_: Start with the DFA type and its accessors. It'll make everything much clearer, and the compiler will be able to give you useful errors.
20:39:09 <mniip> monochrom, I think I know what this means
20:39:23 <mniip> if the kind is  (->) :: i -> (j + 1) -> j
20:39:30 <mniip> and constants can take any natural kind
20:39:37 <orzo> monochrom: sometimes in my workflow, i like to just write and think about types and fill in the details later.  It'd be nice if I didn't have to write bindings to holes
20:39:54 <mniip> then a constant T :: i means that it's a static function from i closed over values to a T value
20:40:41 <orzo> maybe -fdefer-typed-holes should make an implicit _missing_binding hole
20:40:49 <mniip> so like (+) :: ((Int :: 0) -> ((Int :: 0) -> (Int :: 2) :: 1)
20:40:52 <mniip> :: 0
20:41:01 <mniip> )
20:41:46 <jle`> mniip: not too much experience with machine code sorry, besides my experience with TIS-100
20:41:58 <mniip> but then  id :: (Int :: 0) -> (Int :: 1) :: 0
20:42:05 <mniip> so not really an identity function
20:42:39 <orzo> or _unbound
20:43:13 <orzo> x = _unbound should be implied if x has a signature and no binding and -fdefer-typed-holes was specified.
20:43:23 <mniip> so a function type of kind i has a drastically different meaning from a type constant of kind i
20:44:18 <mniip> on a third thought
20:44:27 <mniip> the kind should be  i -> (i + j + 1) -> j
20:50:12 <mniip> this makes sense
20:50:53 <mniip> if you have '\a -> e' and a is a closure with i registers, we translate this into '\ap a1 ... ai -> e'
20:51:13 <mniip> and if  #FV(e) = i + j + 1  then #FV(\ap a1 ... ai -> e) = j
20:51:40 <mniip> sorry \ap a1 ... ai -> e[a \ ap a1 ... ai]
21:07:28 <mniip> and you could have this alongside your usual typesystem
21:08:36 <mniip> close :: (a :: i) -> (a :: *)
21:08:45 <mniip> that makes no sense now though...
21:12:03 <mniip> naw it kind of does, with subtyping
21:13:25 <mniip> not subtyping
21:13:29 <mniip> higher rank quantification
21:13:57 <mniip> forall (a :: forall (k :: Kind). k) (i :: Nat). (a :: i) -> (a :: *)
21:14:47 <mniip> even more formally,  forall (a :: forall (k :: Kind). k) (i :: Nat). (a :: N i) -> (a :: *)
21:14:49 <mniip> sort Kind = * | N Nat
21:35:45 <Clint> 1/win go ##ehashman
21:36:11 <dmwit> nailed it
22:02:21 <mniip> dmwit, any iedas
22:29:16 <mniip> oooh https://i.imgur.com/u6JuDg9.png
22:29:25 <mniip> I know one more instruction set that has this
22:29:27 <mniip> elbrus2k!
22:31:00 <mniip> they've got 4 "control transfer registers" which are like prefetches of jumps, returns and calls
22:33:18 <shachaf> mniip: Is that the STG paper?
22:34:04 <mniip> yes
22:34:38 <shachaf> I guess the whole indirect jump thing works even less well compared to alternatives nowadays
22:34:49 <shachaf> And GHC tries to use pointer tagging and conditional jumps where possible
22:35:09 <mniip> I've never actually read the entire paper, I kind of started once and got to the point where the idea became obvious that I didn't need to read in any more - or so I thought!
22:35:26 <mniip> and I thought so until I tried to write a functional compiler
22:35:33 <mniip> turns out it wasn't obvious at all
22:37:31 <mniip> shachaf, yeah I figured there was a discrepancy somewhere
22:37:56 <mniip> I suspect the STG *language* is still useful nevertheless
22:52:44 <greymalkin> I'm trying to find some documentation on those classes (or instances) which have an inside line starting with `type` and using a tilde somewhere; searching is not kind with that combination.
22:53:01 <greymalkin> What is that syntax called?
22:54:43 <shachaf> greymalkin: Type families? Associated types? Type equality?
22:55:14 <shachaf> mniip: I think I learned more about how GHC compiles code from reading the generated code than from tha papers
22:55:22 <shachaf> (Probably because I did it first.)
22:56:13 <mniip> greymalkin, class Foo a where type Bar a...?
22:56:28 <greymalkin> mniip: I think that's the one.
22:56:32 <mniip> associated types
22:56:36 <mniip> no tildes here though
22:56:50 <shachaf> A concrete example would be a more helpful way to ask the question
22:56:55 <mniip> class (foo ~ bar) => Baz a...
22:57:02 <mniip> is unrelated and is just an equational constraint
22:57:05 <greymalkin> That may have been type equality used that I saw.
22:57:06 <shachaf> Also if you have a concrete example, you can give it to GHC, and it'll tell you what extensions to turn on.
22:57:33 <greymalkin> Unfortunately, I'd love to show an example, but every time I run across it I'm like "oh! I see what you did there!" and then I move on and forget where I saw it.
22:58:22 <shachaf> I wouldn't say it's entirely unrelated, since TypeFamilies turns on equality constraints and they often need to be used together
22:59:54 <mniip> sometimes yes
23:13:11 <c_wraith> there's also the thing where MPTCs often have far better type inference when instances are written with equality constraints instead of reused type variables
23:15:06 <mniip> because that's tested at different stages of instance lookup
23:15:42 <c_wraith> in particular, far later.
