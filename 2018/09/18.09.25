00:09:52 <jle`> koz_: you can use toSized . V.fromList
00:10:12 <jle`> koz_: alternatively you can use withSizedList, and then use sameNat
00:10:21 <koz_> jle`: How do I do the second one?
00:10:55 <jle`> case sameNat (Proxy @m @sizeOfNewVector) of
00:11:04 <jle`>   Just Refl -> ... (m and sizeofnewvector are the same)
00:11:15 <koz_> And Nothing -> explode?
00:11:16 <jle`>   Nothing -> error "something very bad has happened, i blame sql
00:11:20 <koz_> LOL
00:11:23 <jle`> yeah
00:11:24 <koz_> Works.
00:12:00 <jle`> it's essentially the same thing, you can implement toSized in terms of sameNat and withSized
00:12:23 <jle`> but i'd probably use toSized instead, since it is more efficient in the case that the second vector is too big
00:12:34 <jle`> or hm, it's actually still bad isn't itr
00:12:42 <jle`> either way, since it goes through Vector
00:12:43 <koz_> https://www.stackage.org/haddock/nightly-2018-09-23/vector-sized-1.0.4.0/Data-Vector-Sized.html#v:toSized <-- this one right?
00:12:57 <jle`> yeah. actually the two should be the same, performance wise
00:12:58 <koz_> I think I prefer the withSizedList approach.
00:13:07 <koz_> Especially if they're the same perf-wise.
00:13:40 <koz_> I guess my type sig would be getClassAttribute :: (KnownNat n) => DataSetMeta n m -> (forall k. ClassAttribute k -> IO r) -> IO r or something?
00:13:56 <koz_> (if I wanna use withSizedList, that is)
00:13:58 <jle`> well, unless k depends on n and m in a known way
00:14:06 <koz_> k ~ n _must_ hold.
00:14:20 <jle`> then you can just write DataSetMeta n m -> ClassAttribute n
00:14:20 <koz_> That's a database constraint.
00:14:32 <jle`> er, DataSetMeta n m -> IO (ClassAttribute n)
00:14:37 <koz_> OK, so how would I invoke withSizedList then? I need an f to give it.
00:14:49 <koz_> Well, not invoke, but 'write', I guess.
00:14:55 <jle`> withSizedList xs $ \v -> ...
00:17:36 <koz_> Where's Refl from?
00:19:54 <koz_> Data.Type.Equality, I see.
00:20:48 <koz_> So it should look something like this jle`? https://lpaste.net/1942274628902715392
00:40:22 <cheater> hi
00:41:47 <koz_> cheater: HIHI!
00:41:59 <koz_> @pl \(x,y,z) -> AttributeMeta x y z
00:41:59 <lambdabot> (line 1, column 7):
00:41:59 <lambdabot> unexpected "z"
00:41:59 <lambdabot> ambiguous use of a non associative operator
00:42:02 <koz_> :(
00:47:01 --- mode: glguy set +v dataN
00:47:13 --- mode: glguy set -v dataN
00:48:20 <dataN> is there a way to act on the values of a sum datatype with another (e.g. Just True) so that it can still be promoted?
00:49:28 <dataN> :k '(Just True)
00:49:30 <lambdabot> error: parse error on input ‘)’
00:50:33 <dataN> maybe its a problem with the parenthesis..
00:50:38 <dataN> :k 'Just
00:50:39 <lambdabot> a -> Maybe a
00:50:53 <koz_> :k 'Just 'Int
00:50:54 <lambdabot> error:
00:50:54 <lambdabot>     Not in scope: data constructor ‘Int’
00:50:54 <lambdabot>     Perhaps you meant one of these:
00:51:05 <koz_> Whoops.
00:51:10 <koz_> :k 'Just 'True
00:51:11 <lambdabot> Maybe Bool
00:51:21 <dataN> :k ('Just True)
00:51:23 <lambdabot> Maybe Bool
00:52:02 <dataN> hmm, do those have the same result?
00:52:47 <dataN> :k ('Just 'True)
00:52:49 <lambdabot> Maybe Bool
00:53:06 <dataN> should be Maybe (a :: Bool) ?
00:54:07 <dataN> or else 'Just True just cant express Bool as an unpromoted kind
00:54:17 <dataN> wait this is confused
00:55:19 <dataN> :k 'Just 1
00:55:20 <lambdabot> Maybe GHC.Types.Nat
00:55:26 <dataN> hmm
00:56:18 <dataN> maybe it promotes its args automatically?
01:01:34 <dataN> :k 'Just ()
01:01:36 <lambdabot> Maybe *
01:01:38 <dataN> :k 'Just '()
01:01:39 <lambdabot> Maybe ()
01:01:59 <dataN> apparently not
01:02:08 <dataN> cant see the pattern... 
01:08:44 <dataN> there is some rule just about ()?
01:15:01 --- mode: glguy set +v ZeuPiark
01:17:01 <phadej> () :: (), thus the confusion
01:17:11 <phadej> :k 'Just []
01:17:12 <lambdabot> Maybe (* -> *)
01:17:14 <phadej> :k 'Just '[]
01:17:15 <lambdabot> Maybe [k]
01:17:32 <phadej> same, [] :: [k] (for some k)
01:17:44 <phadej> dataN: ^^^
01:18:00 <phadej> yet, as e.g. there aren't type True
01:18:06 <phadej> :k 'Just True
01:18:07 <lambdabot> Maybe Bool
01:18:09 <phadej> :k 'Just 'True
01:18:11 <lambdabot> Maybe Bool
01:18:23 <phadej> are the same, as GHC is able to disambiguate
01:19:47 <phadej> iirc, with -Wall it gives a warning  about unticked data constructor as type
01:32:54 --- mode: glguy set +v WuErLing
01:34:43 <bahamas> does Vector preserve order? I see that aeson Array uses Vector. I want to keep the contents of the array in alphabetical order
01:34:57 <dataN> yes
01:35:40 <dataN> its a Traversable law?
01:37:36 <phadej> it's common sense
01:38:36 <bahamas> phadej: your sentence is not helpful. if it was part of my common sense, I wouldn't have asked
01:39:24 <bahamas> dataN: I don't see Vector offering anything in the way of sorting. does that mean that I have to traverse it comparing each element with my own and decide where to insert mine?
01:39:47 <bahamas> I want to add an element to the vector while maintaining the order
01:40:02 <dataN> huh? thats more like a set
01:40:29 <dataN> no, Vector does the opposite, it maintains the order of construction, first in first out style
01:41:28 <dataN> bahamas: the idea of inserting using Traverse is definitely not going to preserve the Vector length 
01:41:35 <dataN> not sure if thats a Traversable law...
01:42:00 <bahamas> dataN: sorry, I don't understand what you mean. I haven't been using Haskell for long
01:42:03 <dataN> :t traverse
01:42:04 <lambdabot> (Applicative f, Traversable t) => (a -> f b) -> t a -> f (t b)
01:42:35 <dataN> this acts on each element, how were you going to use it to insert an element?
01:42:52 <dataN> looks more like a monad action
01:43:01 <bahamas> dataN: I'm thinking I'll use traverse to find the index where I need to insert my element. then do the insert as a new operation
01:43:13 <dataN> thats a waste
01:43:31 <bahamas> dataN: or I found this http://hackage.haskell.org/package/vector-algorithms-0.8.0.0/docs/Data-Vector-Algorithms-Intro.html. so I might be better of just appending my element and then sorting the vector
01:43:37 <dataN> seems like you need to "suspend" a traversal, which is what is done using Zippers
01:44:06 <dataN> the sorting might befast if the list is already mostly sorted, but that depends on the algorithm 
01:44:31 <dataN> your task has an obvious fastest approach, so it should use that
01:45:24 <bahamas> alright. I'll look into Zippers then
01:45:45 <dataN> if the Zipper optimisation is not needed, use takeWhile and dropWhile, which are combined in various ways in the Split package 
01:46:46 <bahamas> this? http://hackage.haskell.org/package/split
01:47:39 <dataN> this at least guarantees the element is placed using the available properties (list is already sorted), rather than another call to e.g. Data.List.sort
01:47:46 <dataN> bahamas: yes
01:48:32 <cocreature> if you’re working with a vector, finding the index where you want to insert, splitAt + mappend is totally fine
01:49:03 <dataN> :t splitAt
01:49:04 <lambdabot> Int -> [a] -> ([a], [a])
01:49:14 <cocreature> the vector version of that ofc
01:50:07 <dataN> right, the Split library uses lists, and here a pair is specified 
01:50:32 <dataN> (lists of lists)
01:55:43 <dataN> having trouble defining and then using a Singletons class; https://lpaste.net/2443130513548902400
01:57:46 --- mode: glguy set +v lortabac_
01:58:03 <cocreature> dataN: the error message is pretty clear. your instances don’t respect the functional dependency
01:58:16 --- mode: glguy set -v lortabac
02:00:00 <jle`> koz_: yeah :) the last @n on line 10 is probably unnecessary
02:00:34 <jle`> koz_: but yeah, being able to do DataSetMeta n m -> IO (ClassAttribute n) (both n's are the same) is basically the entire "point" of using length-indexed types
02:00:51 <jle`> it describes to the user how the input shape is related to the output shape
02:01:03 <jle`> the reason why we had to use an existential before is that the input shape is not available at the type level
02:01:09 <koz_> Yeah, hence why I'm doing it. Having to fight SQLite constantly isn't fun, which makes me think I should consider a different form of my data.
02:01:24 <jle`> yeah, existentials are really only be used at the "boundaries" of your type-safe world
02:10:40 --- mode: glguy set +v Bala
02:11:18 --- mode: glguy set +v dataN
02:13:46 <dataN> cocreature: is it the wrong way to define the class Singleton? maybe the function needs a proxy type?
02:17:04 <lortabac> dataN: if I were you I would start by defining a single singleton (no pun intended :P) before making a type-class
02:17:07 <cocreature> dataN: take a look at the singletons package and the typeclass defined there. that will give you a better idea of what you might want to aim for
02:17:26 <dataN> ah, this works as expected; https://lpaste.net/4571180594175672320
02:17:46 <lortabac> dataN: you can have a look at singleton-bool for an example of a simple singleton
02:18:30 <staafl_> Anyone know why the Y combinator is called "Y"?
02:19:53 <tdammers> because Y, that's Y
02:20:44 <tdammers> seriously though, it's just one of a handful of combinators described in a foundational paper, and AFAIK that paper just assigned random letters to those combinators, and they stuck. I think.
02:29:59 <merijn> I feel like I'm in cartoon called "My Little Haskellers: Monoids Are Magic!" (This message brought to you by the "I love monoids, they're so easy!"-foundation)
02:32:15 <merijn> On a mostly unrelated note: What are some RTS flags that don't require a -prof build? I need to test some stuff on how the RTS handles flags
02:32:32 <cocreature> merijn: -s
02:32:56 <merijn> cocreature: I need minimum 2 flags :)
02:34:14 <cocreature> merijn: all of the GC flags should work https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/runtime_control.html#rts-options-to-control-the-garbage-collector
02:34:51 <dataN> getting an error with the following;
02:34:52 <dataN> class Switch switch x | x -> switch;  instance (switch ~ ('Nothing :: Maybe a)) => Switch (switch :: Maybe a) x
02:35:00 <dataN> Illegal instance declaration for `Switch switch x'         The liberal coverage condition fails in class `Switch'           for functional dependency: `x -> switch'
02:35:09 <merijn> hmm, actually I guess I'd need two that both do output. Maybe I'll just do "go and figure out how this works or I won't patch your feature request" instead >.>
02:35:45 <dataN> but it works if e.g. 'Maybe Int' instead of 'Maybe a'
02:36:44 <dataN> seems like 'a' is not bound as required?
02:40:35 <dataN> it makes sense that the functional dependency cant infer a polymorphic type, but the type annotation on switch should fix 'a'... 
02:42:13 --- mode: ChanServ set +o glguy
02:42:13 <dataN> hmm, replacing 'x' with 'x a' works
02:47:01 <dataN> is there a way to write something like | x -> a ?
02:52:32 <dataN> the closest thing that works is;
02:52:37 <dataN> class Switch f switch x | f x -> switch;  instance (switch ~ ('Nothing :: Maybe (f x))) => Switch (f :: * -> *) (switch :: Maybe (f x)) x
02:53:30 <thyr15t0r> hello! it's me dumbass beginner again. i need your help
02:53:47 <tdammers> don't ask to ask, just ask
02:54:03 <thyr15t0r> i can't install wx Haskell on Windows 7
02:54:30 <thyr15t0r> 'cabal install wx' returned many errors
02:54:40 <thyr15t0r> un cmd shell
02:54:43 <thyr15t0r> *in
02:54:52 <staafl_> @tdammers, thanks :-)
02:54:52 <lambdabot> Unknown command, try @list
02:56:49 <tdammers> thyr15t0r: I haven't used wx yet, but if you want any serious help with this, I guess you should at least paste those errors somewhere
03:02:35 <cocreature> apparently they don’t want serious help
03:03:21 <c50a326> https://ptpb.pw/cPKI/hs hey how is combine _not_ zipWith? If I try it on basic things like (+) with [Int] or (++) with [String], they both work the same. But in the bfs function in the linked code, swapping "combine" for "zipWith" changes the behaviour of bfs
03:03:58 <cocreature> c50a326: try it on inputs of different lengths
03:04:20 <c50a326> aha
03:05:21 <marvin2> :t zipWith
03:05:22 <lambdabot> (a -> b -> c) -> [a] -> [b] -> [c]
03:07:46 <cocreature> c50a326: note that just looking at the type of zipWith is sufficient to see that it has to behave differently than your implementation in that case
03:08:09 <cocreature> using the elements of the longer list wouldn’t typecheck
03:08:38 <fizbin> Well, sort of. It could be (until one looks at the implementation) that combine is just a type-restricted zipWith.
03:09:36 <fizbin> Though I guess you might mean "clearly zipWith must have a different implementation, because there's no way the code given for combine would work with zipWith's type"
03:09:38 <c50a326> in the paper, the type sig for combine is :: (a -> a -> a) -> ([a] -> [a] -> [a]) but I changed it to remove the 2nd set of parens because they're not necessary I don't think
03:09:42 <c50a326> (correct me if I'm wrong)
03:10:02 <fizbin> c50a326: Correct, they are not necessary
03:11:03 <cocreature> fizbin: if you really want to be pedantic, I said the type of zipWith tells you that it must differ from c50a326’s implementation not from some arbitrary implementation that has the same type as their implementation :)
03:11:53 <fizbin> me rereads scroll more carefully this time
03:12:01 <fizbin> cocreature: point.
03:12:54 <c50a326> ah yeah, (a -> b -> c) _must_ be applied to get to [c]
03:13:15 <c50a326> or an empty list returned
03:13:57 <c50a326> also, any idea why "lev" is called "lev" in that code?
03:14:14 <c50a326> (nested func in bfs)
03:15:07 <cocreature> c50a326: haven’t looked too closely whether that makes sense here but maybe it’s a shorthand for “level”
03:15:30 <c50a326> ah yeah maybe
03:15:41 <merijn> Anyone using 8.6.1, new-build and willing to do some test driving?
03:15:44 <c50a326> yeah I think it kind of chops the tree into level chunks so that makes sense
03:24:49 <deltasquared> merijn: not yet here, I don't think nixpkgs has pushed 8.6.x yet. lemme go update
03:26:20 <deltasquared> ... nope.
03:27:02 <cocreature> deltasquared: huh? 8.6.1 is in nixpkgs
03:27:21 <deltasquared> cocreature: I just did nix-channel --update and nix-env --upgrade, is that not sufficient
03:27:32 <cocreature> deltasquared: which channel are you on?
03:27:35 <boj> deltasquared: do you have the unstable channel?
03:27:46 <deltasquared> cocreature: unstable
03:27:51 <cocreature> and how are you trying to use it? it’s not the default but you can definitely use it
03:28:05 <deltasquared> boj: yes
03:28:09 <deltasquared> cocreature: what do you mean
03:28:41 <cocreature> nix-shell -p 'haskell.packages.ghc861.ghcWithPackages(_: [])'
03:28:59 <deltasquared> cocreature: no, I'm just using the default profile
03:29:03 <deltasquared> I'm not in nixos. should mention.
03:29:06 <deltasquared> it's a co-install
03:29:07 <dminuoso> :t unsafeCoerce
03:29:08 <lambdabot> error: Variable not in scope: unsafeCoerce
03:29:24 <cocreature> deltasquared: none of that should prevent you from executing that nix-shell command :)
03:29:39 <deltasquared> cocreature: but I thought that needed systemd integration or something
03:29:44 <cocreature> no?
03:30:16 <cocreature> systemd is for managing long-running services not for launching ghc
03:30:30 <deltasquared> cocreature: no, as in, nix-shell is container stuff
03:30:41 <deltasquared> hence needing assistance
03:30:41 <cocreature> no it’s not, it just sets up some environment variables
03:30:44 <cocreature> just try it out :)
03:30:55 <deltasquared> well at least let me try to understand the line you just gave me anyway
03:31:21 <cocreature> dminuoso: a -> b :)
03:32:14 <deltasquared> ack, I'll have to go now anyways, got somewhere to go
04:20:43 <c50a326> holy shit I nearly did it!
04:20:59 <c50a326> I mean, I made some slight progress at least... after like 2 days straight...
04:22:42 <c50a326> https://ptpb.pw/MAmz/hs but hmmm, I need to push that leaf down to the next line...
04:23:03 <c50a326> sorry I'm just venting steam, not asking for hints or anything... it's fun to not be completely stuck
04:24:04 <Ariakenom> c50a326: Woo! Go make code work
05:00:55 --- mode: glguy set +v toms
05:38:34 <oak> What would be the best library for implementing stuff using Hopfield networks?
05:39:00 <oak> I see there are few neural network and machine learning libraries that could be used to implement Hopfield network
05:39:02 <merijn> oak: For the less well-informed of us, it'd probably help to explain what Hopfield networks are? ;)
05:43:11 <oak> A specific form of recurrent neural networks
05:44:57 <oak> I've been having a look on Haskell library called Greande, but I'm wondering whether there could be other options
05:45:19 <davr0s> i just wrote something to apply a function to adjacent pairs of list items (with cycling at he end) , but i'm guessing there'd be an elegant way to do that composed from library functions, 
05:45:23 <merijn> oak: There might be a few options, but I'm not really aware of many highly-polished ML libraries
05:46:00 <cocreature> davr0s: usually I go for something like zipWith xs (tail xs)
05:46:20 <cocreature> eh that’s missing the function but you get the idea :)
05:46:42 <davr0s> right i now see 'tail' is rather handy.
05:47:10 <davr0s> ok "head", "tail" do the same job as the destructuring pattern x:xs  commonly seen, thats nice
05:47:39 <cocreature> you might want to use drop 1 xs instead of tail here, which doesn’t crash on an empty list
05:47:49 <davr0s> it'll be sometihg like     map  f    $ zip ls (tail ls)  --more detail for the cyclic aspect..
05:47:51 <deltasquared> cocreature: I'm back now, had to go do stuff IRL. do you recall than nix-shell command from earlier, I didn't manage to write it down.
05:48:05 <cocreature> deltasquared: nix-shell -p 'haskell.packages.ghc861.ghcWithPackages(_: [])'
05:48:14 <Ariakenom> tail (cycle xs)
05:48:46 <cocreature> :t \f xs -> zipWith f xs (drop 1 (cycle xs))
05:48:47 <lambdabot> (b -> b -> c) -> [b] -> [c]
05:48:48 <Ariakenom> > zip [] (tail []) -- cocreature 
05:48:50 <lambdabot>  []
05:48:51 <davr0s> map f  (zip ls (tail ls++[head ls])   ) seems to do it i think
05:49:00 <cocreature> Ariakenom: ah good point
05:49:52 <Ariakenom> davr0s: tail (cycle xs) also works
05:50:31 <davr0s> ok zip will terminate on the shorter, i see cycle is infinite but that's rather useful elsewhere
05:50:49 <deltasquared> cocreature: that seemed to work, ghc -V reports 8.6.1 in there. lemme see if I can get this into my nix-profile bin now then I guess
05:51:02 <cocreature> davr0s: cycle is infinite but since zip will terminate on the shorter this doesn’t matter here
05:51:10 <davr0s> right :)
05:51:59 <davr0s> is the haskell list implicitely same perf for accessing the front/back or is there a prefered order to do sometihng like this
05:52:34 <cocreature> davr0s: haskell lists are single-list lists so the performance is definitely not the same
05:52:34 <Ariakenom> davr0s: first is faster. what do you mean by something like this
05:52:40 <merijn> davr0s: They're linked lists, so anything other than iterating over/accessing the start is slow
05:52:48 <deltasquared> cocreature: I feel there is something I don't understand here as to why it didn't just link the latest version into my profile when I asked, so I'm going to see if someone on #nixos can explain it to avoid clutter here.
05:52:52 <davr0s> ok 
05:53:50 <deltasquared> random thought, what would one use for a random access list, some sort of binary tree I wonder?
05:54:26 <davr0s> would "tail(cycle ls)"  then be absolutely more efficient than "tail ls++head ls" , or does the laziness fix that ('it wont generate a new list then your caller iterates it, rather it will only actually do that concatenation when the caller draws the last item..")
05:55:06 <cocreature> deltasquared: haskell.packages.ghc is only bumped when stackage lts bumps the ghc release afaik
05:55:17 <cocreature> but really you should just always use the explicit versions imho
05:55:33 <deltasquared> cocreature: "explicit versions" well I'm still really a nix newbie
05:55:45 <dmwit> davr0s: They should be basically identical.
05:56:05 <deltasquared> ffs man pages bork...
05:56:18 <cocreature> deltasquared: i.e. in the example above use haskell.packages.ghc861 to specify the version instead of haskell.packages.ghc
05:56:41 <deltasquared> cocreature: so what would I want to give to nix-env --install? the same expression?
05:56:53 <dmwit> deltasquared: For random access, arrays are good, or Seq if you don't know up-front how big it will be.
05:57:29 <dmwit> And yes, it is "some sort of tree". =)
05:57:33 <dmwit> s/it/Seq/
05:57:42 <cocreature> deltasquared: you probably need to mess with nix-env -E and then pass the expression to that
05:57:43 <deltasquared> dmwit: only thing with arrays being that getting an altered version of them is somewhat awkward if you're not in IO or ST
05:57:59 <cocreature> personally I just don’t bother with nix-env and use nix-shells for local development environments
05:58:03 <deltasquared> cocreature: this is not exactly a very good user experience >_>
05:58:18 <dmwit> deltasquared: You asked about random access, not updates. =)
05:58:20 <cocreature> yes nix is definitely rough
05:58:25 <deltasquared> it doesn't show up in search, for instance. what was I supposed to do, grep -FR ghc nixpkgs/?
05:58:29 <dmwit> Ask the wrong question, get the wrong answer...
05:58:36 <deltasquared> dmwit: lel, fair enough :P
05:59:00 <deltasquared> sure if the data is frozen arrays are still faster access no matter what language you're in...
06:00:57 <merijn> deltasquared: Also, depends on the kind of alterations
06:01:09 <deltasquared> been reading the deriving via paper today. that's quite a neat trick with newtype wrappers
06:01:09 <merijn> deltasquared: Mapping over pure Vector's is pretty fast
06:01:27 <deltasquared> merijn: oh, I imagine if you do a transform that's fine, it's just modifying one element
06:01:42 <deltasquared> though in that case probably best to use some other data structure
06:01:58 <dmwit> Or mutable arrays.
06:02:21 <deltasquared> dmwit: yeah, if you're alright with IO...
06:02:25 <dmwit> Or ST
06:02:47 <merijn> My Haskell code has "IO all the things!" anyway :p
06:05:32 <deltasquared> cocreature: it annoys me because I really do want to use nixos, but there are so many glaring deficiencies I don't know where to start, and for me it's not worth the investment to fix
06:06:24 <nshepperd> the best data structure is a pure lazy array
06:06:40 <nshepperd> *if you can somehow make your problem into a dynamic programming problem :p
06:06:56 <cocreature> deltasquared: if you want a haskell specific introduction https://github.com/Gabriel439/haskell-nix is pretty good
06:07:37 <davr0s> (tangential thought, I know of file-mapped IO leveraging virtual memory; is there anything in the world that could leverage on-demand VM page acess to make 'lazy immutable vectors' in C++ from a generator function..
06:07:58 <davr0s> it would have to come with a lot of assumptions about whats going on
06:08:37 <davr0s> similarly could such an approach be used for large indexable collecitons in a functional language (generate on demand, whilst still being able to use random access..)
06:10:23 <deltasquared> cocreature: tbf the only reason I'm really using ghc from nix is because arch linux's one was causing issues.
06:10:41 <merijn> deltasquared: Yeah, Arch's setup is notoriously broken
06:10:50 <tsaka_> When I do "stack haddock --open" from project directory, a package (accelerate) is missing documentation yet the package shows up in "stack ls dependencies". How to attain the docs?
06:10:50 <merijn> deltasquared: You can just install GHC from bindist, though
06:11:35 <deltasquared> merijn: I might have to look into that in future. nix certainly seems to demand a lot of involvement at times
06:11:37 <Franciman> Hi
06:11:43 <Franciman> Is there any tutorial about using Network.TLS ?
06:11:51 <cocreature> installing ghc from the arch repos is totally fine. the problems arise from installing other Haskell packages from the arch repos
06:12:19 <merijn> deltasquared: Basically, you just download the tarball, unzip, run "./configure --prefix=/path/to/ghc", then "make install" and it'll copy everything into the right subdirs and Just Work
06:12:22 <tsaka_> Correction: when doing "stack haddock --open" the package is not there. However "stack haddock --open -- PKGNAME" works
06:12:55 <merijn> cocreature: Sure, I just think the bindists are an underrated way of installing GHC. It works on literally any *nix version that's supported, doesn't require root, has never failed me...
06:12:57 <deltasquared> cocreature: it seems impossible to not have some packages from the repos though, arch's ghc depends on them. it just caused a lot of issues with cabal.
06:13:25 <dmwit> Franciman: Presumably if you looked through the haddocks, looked through the website linked from Hackage (if any), looked through the repository linked from Hackage (if any), and did a cursory Google search, you know more than any of us about that question. And if not... well, do, cause that's probably how most of us would get an answer to the question, too.
06:13:30 <cocreature> deltasquared: the packages bundled with ghc and its dependencies are fine
06:13:33 <deltasquared> a lot of "missing files" errors, which I have seen caused before due to arch only having dynamic libs... they just don't seem to work that well at all.
06:13:42 <cocreature> deltasquared: basically install ghc, ghc-static and their dependencies and nothing else
06:13:57 <cocreature> merijn: sure I completely agree.
06:14:27 <deltasquared> cocreature: I'll bear that in mind. in the meantime the nix version is behaving itself, albeit slightly behind the bleeding edge.
06:14:47 <Franciman> right dmwit I have been searching, since i found nothing , i tried asking here too
06:15:07 <dmwit> Okay. I wouldn't hold my breath if I were you.
06:15:47 <deltasquared> not that I'm entirely sure it was worth the effort yet, looking into refined and I'm finding it does more than I needed anyhow.
06:17:13 <cocreature> sure use whatever you’re happy with :)
06:18:01 <deltasquared> cocreature: I wasn't expecting to have to grasp monad transformers in order to implement Predicate instances for Refined >_>
06:19:15 --- mode: glguy set +v Boarders
06:19:37 <cocreature> deltasquared: you’ll learn more if you ask actual question instead of grumbling about your problems in a way that makes it hard to help you :)
06:19:52 <deltasquared> ugggh, fine, I'll dig up the source code...
06:20:02 <merijn> deltasquared: Monad transformers aren't too bad, I recommend implementing StateT as a method of understanding them, if you haven't yet: https://gist.github.com/merijn/098106abd45c940dab09
06:20:16 --- mode: glguy set -v Boarders
06:20:28 <merijn> Actually, my recommendation is to first do State and *then* generalise to StateT, but anyway...
06:21:11 <cocreature> deltasquared: if you don’t want to that’s fine too but grumbling about your problems isn’t really helping anyone :)
06:27:53 <deltasquared> cocreature: honestly I'm just thinking for what I was actually going to do anyway, it wasn't worth the effort. I mean I was intrigued sure, but this turned out into more of a rollercoaster than I expected
06:28:38 <deltasquared> if I were to express it as a refinement type... probably newtype ABSPath = Refined (StartsWith '/') FilePath
06:28:46 <deltasquared> not that I'm sure we can have type level char constants
06:29:17 <deltasquared> err, AbsPath perhaps.
06:29:26 <merijn> deltasquared: "path" already has type-safe paths? :)
06:29:40 <merijn> Needs more DataKinds, though
06:29:54 <deltasquared> merijn: yeah, but does it have one with the constraint that it must be an absolute path
06:30:09 <merijn> "Path Abs File"
06:30:25 <merijn> deltasquared: It has "Path Abs" and "Path Rel" for that :)
06:33:46 <deltasquared> resolving to FilePath needing to be in IO what
06:34:01 <deltasquared> gah, I give up, my brain feels like it's trying to go several ways at once
06:34:09 <tdammers> problem with type-safe file paths is that "file path" means something subtly different across operating systems and even filesystems
06:34:10 <merijn> deltasquared: How else would you resolve it?
06:34:51 <deltasquared> merijn: it's supposed to just be an absolute path, what's so hard about that... evidently this takes into account other things like windows, so it's more complex than I need
06:35:12 <deltasquared> I can say for my case it's definitely linux path territory. systemd doesn't run anywhere else :P
06:36:19 <deltasquared> all I really needed for config checking purposes was FilePath -> Maybe AbsPath... guess I'll just go write that instead.
06:36:20 <merijn> deltasquared: Even on linux, how do you convert a relative path into an absolute one without IO?
06:36:28 <deltasquared> merijn: I don't need to convert
06:36:36 <merijn> deltasquared: Also, partial paths are relative to CWD, which also need IO
06:36:37 <deltasquared> I just need to assure it's an abs path from the start
06:38:16 <dmwit> deltasquared: so... don't resolve a relative path, then
06:38:22 <tdammers> merijn: makePathAbsolute = ("/" ++) -- YOLO!
06:38:22 * dmwit is confused about exactly what the complaint is
06:38:31 <greymalkin> Is there a QuickCheck (or similar) mechanism for testing level of evaluation?  I'm trying to strict-ify some datatypes and would like to have a way to say "yup, that's strict enough".
06:39:05 <deltasquared> dmwit: I just needed a file path with a type level constraint I guess, not the "resolution" that the paths package seems to want to do. hence, not what I needed
06:39:29 <mnoonan> greymalkin: https://github.com/kwf/StrictCheck maybe?
06:39:36 <dmwit> deltasquared: There's already `parseAbsDir :: FilePath -> Maybe (Path Abs Dir)` and `parseAbsFile :: FilePath -> Maybe (Path Abs File)`.
06:39:59 <dmwit> Don't use the bits you don't need.
06:40:15 <mnoonan> it's pretty new, so I haven't had a chance to try it yet, but the paper and idea seemed clear 
06:40:16 <dmwit> Obviously you aren't going to use every function in every dependency you pull in. (???)
06:40:55 <deltasquared> dmwit: I didn't get to those functions, I just saw the other thing and my brain is already going a bit wtf already... gah. mental capacity is not doing so well atm >_>
06:42:31 <davr0s> another little helper i just wrote was  mapping pairs of 2 lists,   e.g.... f [1,2,3] [10,20,30]  [f 1 10, f 2 10, f 3 10,   f 2,10, f 2 20, f 3 20   etc]    Q1 does this have a name Q2 anyone know of a very elegant way 
06:43:02 <davr0s> = map ((flip map) list_b) $ map (flip f_combine_ab) list_a   -- i ended up with flips for intuitive order, kind of hacking
06:43:21 <cocreature> > f [a,b,c] [x,y,z]
06:43:24 <lambdabot>  error:
06:43:24 <lambdabot>      • Ambiguous type variable ‘a0’ arising from a use of ‘show_M441237648973...
06:43:24 <lambdabot>        prevents the constraint ‘(Show a0)’ from being solved.
06:43:31 <cocreature> > f [a,b,c] [x,y,z::Expr]
06:43:33 <lambdabot>  error:
06:43:33 <lambdabot>      • Ambiguous type variable ‘a0’ arising from a use of ‘show_M211753057644...
06:43:33 <lambdabot>        prevents the constraint ‘(Show a0)’ from being solved.
06:43:41 <dmwit> deltasquared: What resolution are you even talking about? There's no instance of "resol" (which should match both "resolve" and "resolution") in the documentation I'm looking at.
06:43:41 <cocreature> > f <$> [a,b,c] <*> [x,y,z::Expr]
06:43:44 <lambdabot>  error:
06:43:44 <lambdabot>      • Ambiguous type variable ‘b0’ arising from a use of ‘show_M828613387986...
06:43:44 <lambdabot>        prevents the constraint ‘(Show b0)’ from being solved.
06:43:52 <cocreature> Apparently I forgot how simple-reflect works
06:44:06 <cocreature> davr0s: anyway, f <$> [1,2,3] <*> [10,20,30] should give you that behavior
06:44:22 <davr0s> hah wow
06:44:37 <cocreature> or liftA2 if you prefer that
06:44:39 <marvin2> > f <$> [a,b,c] <*> [x,y,z] :: [Expr]
06:44:42 <lambdabot>  [f a x,f a y,f a z,f b x,f b y,f b z,f c x,f c y,f c z]
06:44:54 <catern> there's this nice paradigm in OO/imperative languages called object-capability security, which allows you to reason about the effects of a piece of imperative code/sandbox that code; it looks like this: I have file path P and pure function f; I do file = open(P); f(file); and I know that f can only access that specific file and not do any other IO
06:44:56 <cocreature> ah there we go, thanks marvin2!
06:44:56 <deltasquared> ok, separate question, something that arose in my head: if I had a potentially partial function that would raise an error due to a config fail, and it e.g. returns a list of files that would be written out in IO, how would I cleanly ensure the list is fully evaluated (and any errors forced) *before* starting to write out any files
06:44:59 <catern> is this possible in haskell?
06:45:16 <deltasquared> catern: I would wager, probably not in IO
06:45:17 <davr0s> i'm ok with <$> and see how <*> allows more elegance
06:45:30 <dmwit> deltasquared: `evaluate` for WHNF, check out the `deepseq` package for deeper evaluation.
06:46:05 <davr0s> it still concerns me this isn't instinctive to write but its addictive figuring it out
06:46:11 <dmwit> deltasquared: But even better is to just return an `Either` or similar, so that just the pattern matching you were already going to do ensures that you know whether you're in an error condition or not.
06:46:13 <deltasquared> catern: in a sub-monad (??) maybe. as it stands though IO effectively allows access to ambient capability of the process.
06:46:20 <c50a326> do any of you remember ever doing the drawTree exercise from the Functional Programming with Overloading and Higher-Order Polymorphism paper?
06:46:47 <cocreature> c50a326: if you have a question you’re going to have a better chance of getting an answer by asking that question directly :)
06:46:48 <tdammers> catern: yes, very much; there are several strategies you can employ here
06:47:03 <catern> tdammers: interesting! please elaborate
06:47:08 <deltasquared> dmwit: idk I guess there's just this itch to allow pattern match failures as an easy way out
06:47:09 <c50a326> cocreature: I'm lost for questions by this point -.- I'm just wondering if you have to be a harvard professor or something to actually do it
06:47:24 <c50a326> couldn't actually find any solutions to that specific exercise on google
06:47:34 <dmwit> deltasquared: Yep, the hair shirt is scratchy sometimes. But it's worth wearing anyway.
06:47:38 <c50a326> there's a lot of stuff on various tree-drawing stuff tho
06:47:56 <cocreature> c50a326: I doubt you’ll have to be a harvard professor :)
06:48:00 <deltasquared> dmwit: I guess I'll try it later when my brain feels more engaged
06:48:12 <catern> tdammers: also, I want something that generalizes nicely to passing in more than one file, or a list of files, or a file and some different kind of IO object 
06:48:26 <catern> er, OS object
06:49:17 <tdammers> catern: the simplest way is of course to just write f as a pure function - then, by definition, it can only do things with FileHandle, but no other effects
06:49:25 <dmwit> catern: `newtype File = {- ... -}; class FileAccess m where readFile :: File -> m String; writeFile :: File -> String -> m ()`. Then anything which is polymorphic over all `FileAccess` instances can't do anything but those two actions.
06:49:51 <dmwit> catern: And you can give an `intsance FileAccess IO` so that it's nice and comfortable to use those actions from within an `IO` context.
06:49:55 <catern> tdammers: sure but for it to do anything with FileHandle, doesn't it have to be inside the IO monad, which means it can do anything?
06:50:00 <tsaka_> How to get accelerate to JIT the array code with LLVM instead of using an interpreter? There is an accelerate-llvm module -- I've installed it, but it has no documentation. I've browsed it, but can't find any "run" method to execute Acc computations.
06:50:01 <tdammers> catern: if you want it to do more, one option is to write f in terms of a "restricted" monad that only allows "safe" operations (and thus doesn't provide any means of opening other files)
06:50:33 <deltasquared> tdammers: that was pretty much what I was thinking for a general solution
06:50:46 <deltasquared> so you can't fling arbitary IO actions like readFile for instance.
06:51:01 <catern> dmwit: yes, but again: if I'm inside an IO context I already can do anything, right?
06:51:20 <deltasquared> catern: your object-cap computations wouldn't see that
06:51:22 <dmwit> catern: You missed this part: "anything which is polymorphic over all `FileAccess` instances can't do anything but those two actions".
06:51:56 <deltasquared> catern: you wouldn't execute your object-cap computations in IO; you'd execute them in something more restricted (even if it is backed by IO, but they wouldn't see that)
06:51:58 <catern> dmwit: yes, but you said that then I'd use it inside the IO monad, right? which means I could do anything
06:52:00 <dmwit> catern: So no, those actions, which are polymorphic (and can be *monomorphed* to `IO`, but *don't have an `IO` type*) can *not* just do anything.
06:52:21 <catern> hm
06:52:27 <dmwit> catern: No, you'd build a big action that is polymorphic over that class, and which you therefore knew could only do those actions.
06:52:28 <catern> what would be the type of a function taking a FileAccess?
06:52:31 <deltasquared> catern: again, your object cap computations would not be able to use IO - they wouldn't return IO x, they'd return ObjectCap x
06:52:40 <dmwit> catern: Then, at the top level of your application, you'd call those actions.
06:52:44 <deltasquared> or something. not quite sure how the types would look
06:53:08 --- mode: glguy set +v dataN
06:53:13 --- mode: glguy set -v dataN
06:53:32 <dmwit> The goal of the `IO` instance for `FileAccess` is to make using them from `IO` comfortable, not to make using them in `IO` mandatory.
06:53:43 <dataN> any ideas whats up with this error? https://lpaste.net/1563872239005204480
06:54:04 <dmwit> catern: You wouldn't take a FileAccess. You'd take the value computed from a previous `FileAccess` action, and use `(>>=)` as usual to compose larger actions.
06:54:40 <deltasquared> dmwit, catern: of course, conversely you could implement FileAccess in memory for testing purposes, using some state manipulation.
06:55:20 <dmwit> catern: e.g. if you have `foo :: FileAccess m => File -> File -> m Int` and `bar :: FileAccess m => File -> Int -> m Bool`, you could use `\f1 f2 -> foo f1 f2 >>= \int -> bar f1 int` to builde an action of type `FileAccess m => File -> File -> m Bool`.
06:56:42 <dmwit> (Oops, you would probably want to make `Monad m` a superclass of `FileAccess`, as in `class Monad m => FileAccess m where {- as before -}`. Sorry, I forgot that bit.)
06:56:52 <dataN> error is; Illegal type synonym family application in instance
06:57:17 <Taneb> Any idea why haddock 2.20 might give me an error that GHCi can't find a symbol from an autogenerated module?
06:57:52 <merijn> Taneb: Is the auto-generated module listed in your cabal file?
06:58:11 <Taneb> merijn: yes, in autogen-modules and other-modules
06:58:16 <merijn> hmm
07:03:32 --- mode: glguy set +v dataN_
07:05:49 <dataN_> is the rule that all type families acting to return new types that are used in the instance head be fixed by an equality constraint?
07:09:33 <dataN_> maybe this does not work if the result is used in a type; https://lpaste.net/5325956199491829760
07:10:16 <dataN_> one of the instances was left unchanged to retain the original error
07:14:35 <dataN_> this approach follows; https://ghc.haskell.org/trac/ghc/ticket/3485
07:14:54 <dataN_> but does not seem to work, any ideas?
07:25:04 <Taneb> Ugh, I can't get a minimal example easily...
07:26:24 <merijn> Taneb: How are you running haddock?
07:27:52 <Taneb> "cabal haddock" and "nix-build"
07:27:58 <Taneb> Both fail in the same way
07:33:45 <dataN_> also, this ruins the specificity matching, i.e. its supposed to match on 'Nothing, but this cant work its type is given by a constraint.
07:34:08 <dataN_> its kind*
07:36:54 <dataN_> because that makes it less specific?
07:43:40 <siraben> How can I find documentation for this package? https://hackage.haskell.org/package/xlsx
07:43:52 <siraben> There doesn't seem to be any apart from two examples linked in the website.
07:48:01 <dataN_> ok nvm, this works; https://lpaste.net/558997466817495040
07:48:21 <cocreature> siraben: the individual modules seem to be reasonably well documented
08:04:54 <davr0s> what processors does haskell fare less badly on compared to C++ (or other any other languages you may think of for performance):   desktop vs mobile,  high vs low end,  home vs server, few vs many core
08:05:25 <davr0s> (note i'm not criticising it's performance, it's more like "if i ilke writing haskell, what do i want to run it on..")
08:05:59 <davr0s> (add AMD vs Intel there^^)
08:06:04 <merijn> davr0s: I'd say anything that's about "mid-level tablet" and up in terms of performance/resources
08:06:36 <dmwit> What I know of the cross-compiler story suggests it might be a bit of work to get anything working at all on mobile platforms. Several teams have put work in, but I don't think anybody has stepped up to maintain that work.
08:06:38 <tdammers> embedded and very low end is going to be dire
08:06:48 <davr0s> so your answer probably alludes to "a hardware level at which it becomes worthwhile" (and I realise for much of the world heavy lifting is GPU anyway), 
08:06:49 <merijn> davr0s: It's super easy to drop into/call out to C if you already know C/C++ reasonably well
08:07:18 <davr0s> C/C++ is my primary lifelong emphasis 
08:07:22 <dmwit> But Haskell's concurrency story is second to none. We will eat all your cores if you feed them to us.
08:07:28 <merijn> davr0s: So I would use Haskell for everything whether the overhead of the RTS/GC/etc. isn't problematic (which means "90% of things")
08:07:36 <merijn> davr0s: Cross-compilation is a hassle, yes
08:07:44 <davr0s> dmwit ok thats more like the kind of answer i'm after
08:07:49 <tdammers> dmwit: citation needed -- Erlang
08:07:55 <merijn> dmwit: Not quite
08:08:02 <davr0s> this is sort of said in Rust-land aswell ("we do fearless concurrency"),
08:08:17 <merijn> dmwit: After about 15-20 ish cores GC pause will start killing your speedup
08:08:36 <davr0s> of course you probably also really mean *concurrency*, not s much data-parallel (e.g. compared to an application just churning arrays on a GPU)
08:08:52 <dataN_> davr0s: haskell uses the memory allocation of C, so the platform would need to support C. compiles to ARM and AMD/Intel, works fine on Windows, IOS and Linux, and Android, though this is not officially supported
08:08:55 <tdammers> but, well, both Rust and Haskell do threading orders of magnitude better than Java, C#, Python, JS, etc.
08:09:02 <merijn> davr0s: If most of your experience is in C, I would highly recommend going over chapter 8 of the Haskell report which covers the FFI
08:09:03 <dmwit> I think I said "concurrency".
08:09:11 <merijn> @where haskell2010
08:09:11 <lambdabot> http://www.haskell.org/onlinereport/haskell2010/
08:09:23 <davr0s> i'm guessing haskell would fare better on machines with bigger/better caches tradded of against computational resource ? (most *consumer* devices tend to do the opposite)
08:09:26 <merijn> davr0s: As you'll see, calling C from Haskell is super easy
08:09:51 <davr0s> parallelising legacy C or C++ .. not pleasant
08:10:01 <davr0s> better today now that C++ has lambdas
08:10:14 <davr0s> but still not as good as something built from the ground up..
08:10:18 <merijn> davr0s: I don't think you can easily generalise how caches affect Haskell in general as it depends a lot on the kinda code
08:10:44 <davr0s> generally i'm assuming you can't quite escpae the fact it's going to be heavier on pointer chasing etc (or ..?)
08:10:49 <tdammers> you can, in principle, apply most of Haskell's concurrency approaches in C++
08:10:51 <merijn> For me Haskell works well as a high-level default language from which I call out to situation specific alternatives when needed (CUDA, C, C++ etc.)
08:10:57 <davr0s> given it's execution model
08:11:12 <merijn> davr0s: In general no, but you can still get pretty solid inner-loops with stuff like vector
08:11:21 <davr0s> ok thats good to hear
08:11:25 <tdammers> but having it built more into the language and standard libraries has some whopping advantages
08:11:37 <merijn> davr0s: And a little bit of strictness can help
08:12:02 <davr0s> it remains hugely addictive to write. i'm just looking for posative excuses i guess 
08:12:24 <dataN_> oh, those are maintainability and type safety 
08:12:45 <merijn> davr0s: I ported a binary decision tree algorithm from C to Haskell and it's about 1.5x of the C version. (Keep in mind, the average prediction time of the C version is measured in "100s of nanoseconds")
08:13:03 <davr0s> right, 
08:13:14 <cocreature> I’d say in most cases Haskell is competing againist languages like Java (both in terms of performance and in terms of the usecases) and not so much languages like C/C++/Rust
08:13:15 <merijn> davr0s: So 1.5x of that is still pretty damn fast. And in the real world application the Haskell version is actually faster (since it gets inlined in my data processing conduit)
08:13:31 <davr0s> my perception: C could always beat *anything* else, but an important question is   performance per reasonable dev-time
08:13:53 <davr0s> "if you spend 1 day on a problem in C or haskell, which will be faster..." not "which languaeg is faster peak with fully optimized code.."
08:14:06 <dataN_> yeah, so some of the fastest things are already written for you
08:14:43 <merijn> davr0s: Being fast in C is a matter of "how much devtime do you throw at it?", but GHC Haskell can get you quite close to what you can get in C if you're willing to invest similar devtime
08:15:14 <merijn> davr0s: The advantage, of course, being that writing the initial version is generally easier in Haskell and the type system makes refactoring/switching out hotspots easier
08:15:20 <Boarders> more important than what you can do in a day is how many times must this be read and re-understood
08:15:27 <Chousuke> C is not a perfect language for performance oriented code :/ Oy'
08:15:29 <davr0s> I'm coding for my amusement , but trying to increase the chances that I *could* use anything i learn along the way to help the world
08:15:40 <Chousuke> It's not like you automatically get the best possible code because you coded in C
08:15:48 <tdammers> realistically, "how fast can you make it with infinite resources" isn't an interesting question to ask; what you want is "how much does it cost to make it fast enough"
08:15:51 <davr0s> right it takes time to refine
08:16:00 <davr0s> and the best solutoin obfuscates the program meaning often
08:16:17 <tdammers> and that obviously depends on your definition of "fast enough"
08:16:27 <Chousuke> C just has escape hatches for you to write stuff in assembly which is pretty much as close as you can get nowadays. And even then you could optimize further if you know exactly which processor you're targeting and your workloads.
08:16:40 <merijn> davr0s: C predictor https://github.com/merijn/GPU-benchmarks/blob/master/benchmark-analysis/src/Model.hs#L92-L104 vs the Haskell version https://github.com/merijn/GPU-benchmarks/blob/master/benchmark-analysis/src/Model.hs#L45-L54 :p
08:16:49 <davr0s> i'm sold on the idea that "a higher level representation is beneficial", it's just in practice acheiving maximum speed/efficiency *is* easier using human optimisation (for the things where it matters and the cost can be amortised across millions of users..)
08:16:59 <merijn> Chousuke: GHC Haskell has a metric crap-ton of escape hatches too :p
08:17:21 <dataN_> its not like you write rough code and then spend ages tweaking it to make it faster, trying laboriously to find inefficiencies. Higher order programming places precedence on abstracting common programming patterns, so something a developer might get wrong and implement slowly will likely already be available in haskell, allowing code reuse with a kind of inherent legibility because these algorithms are common parlance 
08:17:23 <catern> dmwit: hmm okay so I guess I understand the thing about File and FileAction, but it seems to me that the limitation is that if I want to have a bunch of different kinds of capabilities, I have to have a bunch of monad transformer stuff or one giant super-monad
08:17:30 <tdammers> you can always FFI into C, and from there drop into assembly
08:17:35 <davr0s> as i commented yesterday there's a really weird nostalgic sensation writing haskell
08:17:47 <merijn> tdammers: You can also write custom primops
08:17:51 <davr0s> it's reminiscent of the buzz of discovering computers for the first time
08:18:07 <Chousuke> merijn: yeah. Though Haskell is slightly disadvantaged for practical stuff because its model is so different from what actually happens. Which is actually a good thing in most cases.
08:18:19 <davr0s> and there's some simpler literal nostalgic cues i.e. losing the objects
08:18:37 <dataN_> Chousuke: is that true?
08:18:38 <Taneb> davr0s: C's model isn't really all that close to whant happens on modern architectures
08:18:53 <Taneb> Chousuke: ^
08:19:12 <davr0s> Taneb thats true and at the same time I still think there's things about C that make is useful
08:19:16 <tdammers> yeah... C is kind of like "let's pretend we're still using PDP-11's, only faster"
08:19:26 <Chousuke> Taneb: I am aware. it's somewhat closer than haskell's, though. :P
08:19:32 <Chousuke> which sometimes helps, and often doesn't.
08:19:39 <Taneb> Yeah... there also isn't really any language that is particularly close
08:19:39 <dataN_> davr0s: are there examples of this?
08:19:43 <davr0s> I am very aware that perfomance depends on caches and pipelines; however C still gives you the tools to manually tune; however I get what you're saying.
08:19:55 <merijn> Chousuke: If you wanna go fast in Haskell you just need more -XMagicHash in your life ;)
08:20:08 <davr0s> i.e. to write fast C, you need to think about mapping an abstract algorithm to hardware, not 'making the C representation elegant'
08:20:23 <dmwit> catern: `IO` is the usual giant super-monad.
08:20:41 <davr0s> Taneb +1
08:20:44 <dmwit> catern: And again, even if `IO` is *the only instance*, you still get the compiler-checked guarantee that actions which are polymorphic over all instances cannot do all of IO.
08:20:58 <Chousuke> I don't actually like C that much. When I have to code in C I'm always super defensive because it's so hard to not shoot your foot off
08:21:04 <Chousuke> and that hurts performance
08:21:05 <davr0s> C, C++ are the best/most prevalent we have.. and they have this glaring error regarding making it look like the cost of mutating anything anywhere is cheap
08:21:18 <cocreature> Chousuke: if your program segfaults it exits pretty fast!
08:21:21 <catern> dmwit: sure I see that second part
08:21:32 <Chousuke> cocreature: if it does
08:21:50 <Chousuke> cocreature: sometimes it only segfaults a few bazillion instructions after it should've exited :)
08:21:53 <merijn> davr0s: Did you ever see Ryan Newton's C++ keynote on "what C++ can learn from Haskell"?
08:22:04 <dataN_> davr0s: the prevalence of C is not justified by optimal language design 
08:22:18 <merijn> davr0s: It's quite nice and interesting: https://www.youtube.com/watch?v=lC5UWG5N8oY
08:22:21 <davr0s> i'm still faster at getting results i set myself with C++,including fixing the segfaults: because i find myself writing a lot of checks for other things (beyond the type system) - they help .. you're trying to reach one destination from multiple angles
08:22:40 <davr0s> where learning a new language appeals to me is... I fucking despise working with other people on C++ projects
08:23:12 <Chousuke> cocreature: I actually fixed a bug like this in sway once. it crashed only a few moments after corrupting its internal data, so the stack trace was kind of interesting :P
08:23:29 <cocreature> Chousuke: yeah those are really painful ):
08:23:37 <dataN_> there was a time Fortran was considered to be "fastest" and it was most prevalent, and there is a reason its not now, and thats because it was easier to write better languages than incorporate modern programming theory into such an inflexible model.
08:23:37 <catern> dmwit: I guess I'm also concerned about separating the "File" value and the "FileAction" typeclass... it seems like the two should be a single unit, because if they're separated then you could use a File with the wrong FileAction, or save a File and use it later when you aren't supposed to, or something
08:23:40 <davr0s> hence being drawn to langauges which might help composability, hence my fascination with pure-functional and haskel's seeming ability to make very versatile abstractions (HKT)
08:24:16 <dmwit> catern: Sure, you should use module boundaries in the usual way to make File an abstract type, only available for construction and destruction through your approved API.
08:24:28 <davr0s> merijn i haven't seen that specifically but i'm genearlly awre of the claims "haskell will make you a better c++ programmer"; of course you could say "Rust is what C++ could learn from Haskell..."
08:24:37 <Chousuke> I'm pretty happy that rust is gaining popularity. It seems like Haskell for people who think haskell can't perform well because it's a functional language :P
08:25:15 <catern> dmwit: of course, but I don't think that solves the problem? when I say "save a File and use it later" I mean store that File value somewhere - perhaps in a closure
08:25:19 <mnoonan> Haskell definitely made me a better *template* C++ programmer, for better or worse.
08:25:23 <davr0s> dataN_ II'm aware C is popular because it's popular (and continues to fill a specific niche it was established in), not because 'it's the best we can theoretically do for that ..'
08:25:43 <davr0s> Chousuke i like the 'gateway drug' analogy
08:25:45 <merijn> davr0s: Well specifically one part of the talk that seems interesting to you is the last part where he talks about "decoupling the high-level interface you're programming against from the low-level implementation code runs on"
08:25:51 <merijn> mnoonan: Same here
08:25:52 <dmwit> catern: Ah, yeah. Is that a feature that the object-capability mechanism you're describing from OO offers? If so, I'm a bit surprised.
08:26:00 <davr0s> haskell made very little sense to me before i'd used Rust for a while
08:26:22 <catern> dmwit: yes the issue of "saving a File and using it later" happens also with imperative languages, but the first part, not using a File with the wrong FileAction, is avoided by object capability 
08:26:24 <dmwit> catern: A linear typing discipline can help with that, but Haskell doesn't have a convenient way for user code to do linear typing (yet, I think).
08:26:31 <davr0s> merijn ok , yeah i agree with that as a goal for the world generally
08:26:32 <dataN_> davr0s: what niche?
08:26:39 <dataN_> the past!?
08:26:44 <Chousuke> davr0s: possibly. rust kind of drags you half-way to functional programming and away from OOP, so going from there to Haskell isn't that big a leap
08:26:48 <merijn> mnoonan: "I love templates, they're so easy!" https://github.com/merijn/GPU-benchmarks/blob/master/TemplateConfig.hpp#L286-L310
08:27:02 <merijn> mnoonan: Oh wait...that was monoids >.>
08:27:08 <dmwit> catern: Hm. Maybe I don't understand your "using a File with the wrong FileAction" concern yet, then.
08:27:14 <davr0s> OS's/embedded , gamedev .  ok i'm lumping C, C++ together because you *can* migrate ,and mix .  love or hate the term "C/C++" ...
08:27:38 <dmwit> catern: oops, lunchtime, afk for a bit. I'll see messages you send me, but won't be responding for a bit
08:27:52 <catern> dmwit: thanks for your help!
08:27:56 <dataN_> thats neither a niche nor something C is better suited to Haskell for!
08:28:36 <Chousuke> gamedev doesn't even require performance-oriented languages nowadays
08:28:48 <davr0s> dataN_ by gamedev i really do mean underlying engine, not game'applicatoin code','level scripting' etc
08:29:04 <davr0s> there's a lot of "gamedev" that happens in other languages ontop of engines yes
08:29:08 <dataN_> do you mean that some 3rd party tools are written in C? that does not mean its a good thing that they are, and if anything, companies will have to migrate
08:29:11 <davr0s> so let me clarify, *the underlying engine*.
08:30:03 <davr0s> and whilst processors are "faster" these days I do have an interest in energy efficiency (big picture r.e. civilizatoin), so reduing computational resources for a task is still  useful IMO.
08:30:12 <dataN_> yeah, so these are huge pieces of code, and its likely they could be made much more simple by abstracting the common patterns
08:30:36 <Chousuke> honestly though, haskell is fast enough. If ruby and python are fast enough, Haskell has nothing to fear :/
08:30:40 <davr0s> C+++ really not C these days. i'm just lumping C/C++ really
08:30:41 <mnoonan> merijn: "parser combinators make everything so much simpler!" https://github.com/GrammaTech/clang-mutate/blob/master/Parser/Combinators.h
08:30:49 <Chousuke> I wish less software were written in ruby and python
08:31:07 <dataN_> its not yet an established business sector to write the libraries rather than the programs  
08:31:13 <Chousuke> though OTOH I don't because they might be written in C
08:31:16 <davr0s> dataN_ seriously i think you'd have a hard time  trying to replace *everything* done by unreal engine or whatever with a haskell sourcebase
08:31:32 <davr0s> even if haskell could be used for 'a lot of game industry tasks'
08:31:43 <dataN_> only because their code is jumbled
08:32:00 <davr0s> i would take a lot of convincing that haskell could do this
08:32:05 <cocreature> the code being jumbled or not doesn’t change whether GC pauses are acceptable or not
08:32:22 <dataN_> and if they really do follow mathematically established programming paradigms then they will basically be written in a haskell style, and so the migration would be simple
08:32:23 <cocreature> “Haskell can replace anything” is about as silly as “don’t use Haskell because C is faster”
08:32:30 <Putonlalla> Forget performance. There's still no language language that gives integer overflows the attention they deserve.
08:32:49 <Chousuke> Ada? :/
08:32:54 --- mode: glguy set +v kuribas`
08:33:09 <Chousuke> I don't actually remember much about Ada but I remember you could define integer ranges as types
08:33:14 <davr0s> dataN_ now you're veering from the domain , 'mathematically established programming paradigms' dont tally with 'adapting systems that can work well within fixed consumer hardware' (making all the size/speed tradeoffs etc)
08:33:15 <kuribas`> Putonlalla: lisp?
08:33:34 <Putonlalla> Certainly not, kuribas`.
08:33:57 <davr0s> recently I saw a youtube video demonstrating squeezing C++ onto a Commodore 64
08:34:14 <davr0s> i very much doubt you could run as much haskell there
08:34:37 <davr0s> i say 'squeezing', they demonstrated how to use C++ zero-cost abstractions to write C64 friendly code
08:34:54 <Chousuke> I bet you could, but I doubt it'd look much like regular Haskell code.
08:34:57 <davr0s> i thnk this is the kind of challenge i'd like to see for you to convince me Haskell can handle the *whole* gamut
08:35:03 <merijn> davr0s: Conceptually you could
08:35:20 <merijn> davr0s: It's just that GHC and all work on it aren't really headed in that directory
08:35:37 <davr0s> right, no demand for it because we have C++ filling that niche
08:35:38 <Chousuke> I'm not sure how much work it would be to make Haskell not need its GC
08:35:41 <merijn> davr0s: There have been projects for bare-metal Haskell, etc. before.
08:35:52 <dataN_> the compiler can target these? or its just FFI?
08:36:03 <merijn> davr0s: Well, little demand and mostly, lack of manpower. Because the people hacking GHC are focussed on different problems
08:36:52 <davr0s> my own personal challenge would be a little higher, i.e. "could it do 90s console gamedev" which is probably a bit more forgicing than a C64 but still..
08:37:00 <davr0s> e.g. playstation
08:37:05 <Chousuke> I still think though that if Haskell is not for you, then use Rust. Or python, if you're writing something less than 500 lines in length. I wouldn't default to C for anything anymore without a good reason :P
08:37:26 <dataN_> so if the arguments for using higer order languages are all about code structure, given that specifically targeted hardware can use the available interface, then its not the argument 
08:37:27 <davr0s> Chousuke Rust is probably a great option all round
08:38:12 <cocreature> davr0s: it is an option all around but if you can afford a GC, it can make your life much easier than having to convince the borrow checker
08:38:41 <davr0s> Chousuke i need to draw a state diagram though of home i'm bouncing.  eg.   "revert to C++, i'm faster with it.."  ->   "Rust is the new thing,close enough.."  ->  "ok lets try haskell again, and why dont we just stick with c++ for the c++ey tasks.."
08:38:52 <davr0s> how^ damn autocomplete
08:39:01 <dataN_> even if a language had some specialised interface to some hardware, Haskell could just use that. 
08:39:39 <Chousuke> davr0s: well, C++ is probably a good fit if you're already an expert and don't make mistakes. :-)
08:39:41 <tsaka_> does anyone here have experience with the package linear-accelerate? How to use accelerate arrays (Acc Array ..) with it?
08:40:20 <davr0s> Chousuke there remains an issue - i hate working with others on C++ code. (which kind of rules out helping anyone else in this world while i'm coding today)
08:40:31 <cocreature> I think it’s also important to differentiate between “could Haskell be made suitable for this usecase if 10 people invest 10 years of their time in it?” and “is Haskell suitable for it in its current state”
08:40:33 <davr0s> (even though i have written C and C++ commercially in the past)
08:40:34 <dataN_> Chousuke: part of the pressure against migration is the individual cost to learning how to avoid errors that dont exist and feeling that expertise is being wasted 
08:40:35 <Chousuke> davr0s: I just tend to dislike things that let you do very unsafe things without even warning you just because you don't know any better
08:40:40 <berndl> Why not D instead of C++?
08:40:49 <davr0s> berndl good question:
08:41:01 <cocreature> the former is an interesting question but not that useful if you have to choose a language for a project that needs to be completed in the next few years
08:41:16 <davr0s> for some reason it doesn't seem enough of a departure e.g. Rust goes a bit further and D doesn't seem interseting by comparison
08:41:19 <Chousuke> davr0s: and if you have a tool that can straight out *forbid* entire classes of errors, then that's superior to a tool that doesn't. especially for collaboration.
08:41:34 <davr0s> berndl even though you might be right, having analyzed my experience/needs
08:41:52 <davr0s> or rather whats coming across in this chat
08:42:07 <davr0s> Chousuke ^^ especially for collaboration - thats the bit i'm sold on
08:42:23 <dataN_> thats the point about higher order parlance 
08:42:34 <davr0s> one of my 'big picture' concerns is: i think better tools can reduce the worlds transport requirements (hence save energy)
08:42:54 <dataN_> !?
08:42:59 <davr0s> Rust (and Haskell) are better at communicating automatically between programmers than C++
08:43:09 --- mode: glguy set +v vaibhavsagar_
08:43:19 <vaibhavsagar_> thank you glguy
08:43:28 <vaibhavsagar_> to repeat: I'm trying to trigger a bug with a function using unsafePerformIO under the hood, does anyone have any tips?
08:43:29 <davr0s> sorry if i'm sounding like an eco-freak but reducing energy use is the most important thing  for everyone to be doing 
08:43:45 <vaibhavsagar_> davr0s: why?
08:43:59 <davr0s> ^^ thats why I like *efficient* programs (as per optimized C++), but also "better inter-programmer collaboration, online (saving people from commuting)"
08:44:01 <vaibhavsagar_> is using more energy in and of itself a bad thing?
08:44:14 <davr0s> vaibhavsagar_ yes it's a bad thing unless we crack fusion or space-based solar
08:44:23 <davr0s> not a debate i want to open here
08:44:36 <dataN_> some people view Haskells constant evolution as meaning its somehow not ready yet, but some of the most fundamental and helpful features were incorporated at its creation. 
08:44:45 <cocreature> vaibhavsagar_: I’m not following, what makes you think that this function has a bug? it is possible to use unsafePerformIO in ways that are safe
08:44:56 <dataN_> and form the principles of the language
08:44:56 <vaibhavsagar_> cocreature: we found a bug in it
08:44:59 <davr0s> i strongly beleive we need to reduce energy use compared to where we are, unless we get a huge technological breakthrough 
08:45:02 <vaibhavsagar_> but my repro is too big :(
08:45:17 <davr0s> (like fusion power)
08:45:27 <vaibhavsagar_> davr0s: if you're not willing to explain why, then I don't want to talk about it either
08:45:34 <dataN_> davr0s: what energy use? paying people to use outdated languages for fear of job loss?
08:45:37 <davr0s> vaibhavsagar see peak oil etc.
08:45:54 <vaibhavsagar_> it doesn't follow that more energy usage == bad
08:46:01 <lortabac> vaibhavsagar_: if the function calling unsafePerformIO is inlined, that can cause bugs
08:46:04 <vaibhavsagar_> yes
08:46:04 <vaibhavsagar_> that
08:46:07 <davr0s> and if you dont beleive it's an issue.. i dont want to start an arguemnt here. i'm here to debate the merits of haskell vs other langauges, putting time into learning them
08:46:08 <vaibhavsagar_> is what is happening
08:46:26 <vaibhavsagar_> davr0s: haskell uses more energy than optimised assembly
08:46:28 <lortabac> vaibhavsagar_: you have to add a NONINLINE pragma to avoid the problem
08:46:34 <davr0s> vaibhavsagar more energy use is great if we solve fusion power . given certainties we need less energy use
08:46:38 <lortabac> NOINLINE
08:46:44 <vaibhavsagar_> lortabac: yes, that is the fix, but I would also like to demonstrate the problem
08:46:54 <vaibhavsagar_> see
08:47:09 <davr0s> vaibhavsagar right.  but if it can make collaborative code across the internet easier it can save transport energy
08:47:22 <vaibhavsagar_> lortabac: https://github.com/kadena-io/blake2/pull/1
08:47:45 <davr0s> lots of people still commute to programming jobs where information sharing happens face to face in an office
08:47:52 <davr0s> the more you can do online, the better
08:47:59 <dataN_> ha, some kind of perfect scenario where there is no code duplication
08:48:23 <davr0s> thats a big part of it - things like Hoogle help finding code
08:48:26 <davr0s> finding existing code
08:48:28 <lortabac> vaibhavsagar_: ok you want a small test for this issue
08:48:36 <cocreature> davr0s: if you turned off your computer right now you would also save energy :) it’s not as simple as you’re making it out to be. but either way this discussion is turning offtopic
08:48:38 <Chousuke> I don't think code duplication by itself is bad
08:48:46 <davr0s> but also the superior composability of haskell code
08:48:53 <Chousuke> I think most software projects could be improved with better focus
08:48:54 <davr0s> (given purity and the type system)
08:49:14 <dataN_> it is if people get it wrong and write it differently and run into the same errors over and over. thats a total waste
08:49:19 <davr0s> cocreature i did say i didn't want to start a debate. I can just state it as a goal.
08:49:20 <Chousuke> just look at your random ruby or python project dependency list and see what happens when you don't duplicate code ever :P
08:49:31 <vaibhavsagar_> lortabac: yes, exactly
08:49:41 <vaibhavsagar_> something that fails with INLINE and passes with NOINLINE
08:49:50 <vaibhavsagar_> but I have no idea how to make this happen
08:50:01 <vaibhavsagar_> I have a big test but that's not good enough
08:50:41 <davr0s> Chousuke sure it's a tradeoff, and also I'm accutely aware of the 'fill your own head..' , 'NIH' slant.  again part of my interest is anythign that might help me get back to collaborative coding, given i dont want to do that in C++ any more
08:50:42 <dataN_> davr0s: if the logical conclusion is to improve efficiency for the sake of profitability, then the tendency should be toward higher order languages. 
08:51:40 <davr0s> i'm aware there's 2 opposite types of software r.e. profitability (or even efficiency measureed physically:)   "dev time > runtime" and "runtime on cheap mass produced hardware > dev-time"
08:51:41 <dataN_> and the barriers to this are certainly nothing to do with performance considerations, as these are essentially supurious 
08:52:06 <davr0s> haskell is probably indesputably better for the former.  C++ is better for the latter
08:52:21 <davr0s> i'm aware both cases exist and have distinct concerns
08:53:14 <davr0s> even if you dont think reducing energy use is important, there's still a case under present oil fueled conditions where :  a peice of software that can run using less resources can find itself into more locations e.g. more users or small drones with smaller batteries, ...
08:53:36 <davr0s> thats actually where Rust can be interesting - IOT
08:53:48 <dataN_> they have everything to do with barriers to learning and individual and corporate stubbornness. however, competitive future software companies will share libraries more and these will be written in a more maintainable way, and these considerations will be more ingrained in the culture  
08:53:59 <davr0s> it's capable of C++ style efficiency , but easier to make secure. 
08:54:33 <davr0s> FP ideas have made it into the mainstream i guess
08:54:35 <dataN_> it would just use FFI!!
08:55:01 <davr0s> rust really can do the same tasks as C or C++, i have no doubt there.
08:55:04 <Ariakenom> davr0s: well c++ has lambdas :p
08:55:20 <hodapp> last place I needed to really optimize power usage I used Haskell, but by way of Ivory so that I could target an embedded system
08:55:40 <mniip> davr0s, er, what?
08:55:52 <davr0s> mniip "er what" r.e. what comment
08:56:00 <hodapp> which ends up not having much gap between "running Haskell on the target" and "using Haskell to compile other Haskell for the target"
08:56:04 <mniip> re: easier to make secure
08:56:25 <hodapp> but this was for something that idled at 100-150 uA
08:56:26 <lortabac> vaibhavsagar_: I tried this https://lpaste.net/3084161314554118144, but strangely it doesn't trigger the duplication
08:56:37 <mniip> I mean most of the issues with IOT do not come from non-memory-secure language issues
08:56:41 <davr0s> mniip ah right.    Rust's primary reason for existing is that subtle C++ bugs make exploits possible, it's not good for internet connected software.
08:56:42 <lortabac> vaibhavsagar_: maybe GHC is smarter than I think
08:57:02 <mniip> not memory safe*
08:57:20 <merijn> lortabac: What were you expecting?
08:57:28 <vaibhavsagar_> lortabac: thanks for trying :)
08:57:30 <merijn> ah, to have it inlined
08:57:31 <davr0s> i agree with the Rust people on their stated goals/philosophy
08:57:44 <merijn> lortabac: Maybe it inlines and then immediately does CSE :p
08:57:45 <mniip> I do agree with the thing you stated too
08:57:50 <davr0s> anyway.. i've spent a long time rambling
08:57:58 <vaibhavsagar_> merijn: I'm trying to come up with a small test case for https://github.com/kadena-io/blake2/pull/1
08:57:59 <mniip> but I'm not sure if this is The Answer for IOT
08:58:10 <merijn> lortabac: (Common Subexpression Elimination), lifting it back out of the duplication again :p
08:58:23 <davr0s> i should set myself some more goals to cross to make my haskell more likely to stick this time
08:59:04 <lortabac> merijn: do you know the flag to disable CSE?
08:59:34 <cocreature> lortabac: there is a flag called -fno-cse which does at least have a promising name :)
09:00:28 <lortabac> merijn: cocreature even with -fno-cse I get the right result
09:00:35 <merijn> vaibhavsagar_: Are you willing to invest some time experimenting?
09:00:55 <merijn> vaibhavsagar_: You could try out how well creduce does for you: https://github.com/csmith-project/creduce/issues/153
09:00:58 <cocreature> lortabac: there is also -fno-stg-cse and -fno-full-laziness
09:01:17 <Ariakenom> davr0s: You mentioned Haskell sentimentality before. For me it does bring back some "math that does something" feelings that made me like programming to begin with.
09:01:26 <cocreature> lortabac: oh also just to be sure, are you compiling with optimizations?
09:01:29 <davr0s> Ariakenom ++++1
09:01:31 <merijn> vaibhavsagar_: creduce was written for minimising huge C/C++ test cases into minimal test cases. There's some work on making it work for other languages
09:01:50 <lortabac> vaibhavsagar_: I tried with different options, with no success
09:02:11 <merijn> vaibhavsagar_: I'd be curious to hear how well it works!
09:25:28 <dminuoso> with cabal new-build Im getting some linker errors I cant make heads or tails of: https://gist.github.com/dminuoso/88cba8d3f7b99e5ed55d11afc2de2f1a
09:25:53 <dminuoso> Does anybody have an idea how to debug this, or perhaps what might be the cause?
09:28:42 <dminuoso> Ah itr just hit me. I was missing out some modules in other-modules, the price for not looking at the complete build output =)
09:36:09 <akr> hi
09:36:18 <akr> HDBC doesn't support sql arrays?
09:38:36 <infinisil> akr: Huh, since when does sql have arrays?
09:38:46 <akr> oh
09:38:55 <akr> it may that it's a postgres thing
09:39:07 <akr> may be*
09:39:08 <infinisil> What are they?
09:39:25 <akr> collections of values
09:39:34 <akr> https://www.postgresql.org/docs/9.1/static/arrays.html
09:39:35 * ski mumbles something about 1NF
09:40:35 <infinisil> Yes, that violates 1NF :/
09:41:31 <ski> well, perhaps 1NF wasn't much of a good rule to begin with ..
09:43:04 <ski> (the intension to not *needlessly* have relational (or list or tuple or array) attributes is good. but it's possible to take this dictum too far)
09:44:01 <ski> (also, relational attributes are useful to explain the semantics of `GROUP BY')
09:45:29 <akr> well, I don't see any other sensible way in some situations… imagine I have a table A with the primary key and then a table B with flags for entries in A. So the data looks like e.g. (1, [prime, odd]); (2, [prime, even]); (4, [even]) etc.
09:45:48 <akr> and I want to retrieve all numbers between 01 and 100 together with the flags
09:46:15 <akr> I can make a nice view that models this exactly with arrays
09:46:40 <ski> to me that looks like your second (the horror !) attribute is a set (a unary relation), not an array
09:47:01 <mniip> I'd be inclined to have a 'flag' column
09:47:05 <mniip> and have multiple rows per key
09:47:21 <akr> ski: I don't see how that is relevant
09:47:30 <akr> mniip: yeah and how do I retrieve this information?
09:47:47 <mniip> you're thinking of a key-to-set-of-flags map
09:47:54 <mniip> while in reality you have a key-flags relation
09:48:30 <mniip> a table's primary purpose is just that -  being a relation
09:48:31 <ski> (akr : it's a stepping stone to what mniip is talking about)
09:48:42 <mniip> not a function (map)
09:49:17 <mniip> ski, SELECT flag FROM flags_table WHERE key = 123;
09:49:21 <mniip> er
09:49:23 <mniip> akr: *
09:49:55 <akr> mniip: but I wanted all numbers between 1 and 100
09:49:58 <akr> not just one number
09:50:17 <mniip> WHERE key BETWEEN 1 AND 100
09:50:21 <mniip> basic sql innit
09:50:35 <mniip> for something more advanced, try
09:50:52 <akr> mniip: I don't see how to group those
09:50:54 * ski agrees relational attributes would be nice here, though sometimes it could probably be rewritten (horribly ?) in terms of ordinary SQL stuff
09:51:12 <mniip> akr, why do you need to group those
09:51:32 <akr> because there's a variable count of flags per item
09:51:54 <mniip> SELECT key, flag FROM keys_table JOIN flags_table ON keys_table.key = flags_table.key WHERE something(key);
09:52:01 <mniip> akr, and so what?
09:52:04 <infinisil> Really, the only reason for such postgresql arrays seems to be performance
09:53:05 <akr> mniip: hm, that works, but now I have to group them by key some other place down the line
09:53:56 <mniip> you mean for output?
09:54:01 <akr> yeah
09:54:12 <mniip> you can ORDER BY key
09:54:20 <mniip> then something like haskell's groupBy wouldn't choke on it
09:55:34 <akr> yeah alright, that makes sense
09:57:05 * ski idly wonders what would be a good example of a relational attribute, not trivially reducible (in a nice way) to non-relational attributes
09:57:20 <akr> I need to think about this some more in my specific situation
09:57:23 <akr> mniip: thanks!
09:57:44 <mniip> ski, child/parent?
09:57:56 <ski> (perhaps if you want a relation where a relational attribute (and possibly some more attributes) is to form a key ?)
09:58:18 <mniip> unless I'm misunderstanding what you mean by non-relational attributes
09:58:26 --- mode: glguy set +v noipmups
09:58:45 <mniip> not familiar with DB theory slang
09:58:46 <noipmups> Is it possible to, using Lenses, derive new record from record existing. Like derive DBUser from User with just adding an id field?
09:59:12 <mniip> can you rephrase it in an arbitrary CCC :P
10:00:10 <ski> well, if you have a map `A ---1 P B', then you can reduce that to a relation `A *---* B'. and if you have `A ---1 P B * P C', you can reduce that to `A ---1 P B' together with `A ---1 P C', which can then further be reduced to `A *---* B' and `A *---* C' 
10:00:12 <dmwit> monochrom: You are a prophet. https://stackoverflow.com/q/52501590/791604
10:00:36 <ski> here `A ---1 B' is a binary relation that is functional, and `A *---* B' is an arbitrary binary relation
10:00:40 <dmwit> monochrom: I'd like to ask you to refrain from making any further predictions on the grounds that maybe then they won't come true. =P
10:02:33 <ski> (perhaps i should write `*---1', not `---1')
10:03:09 <ski> mniip : however, if you have `P A *---1 B', then the powerset is on the domain side of the map, not the codomain, so would be less trivial
10:03:11 <EvanR> in *---* not everything in the domain may be related to something
10:03:26 <EvanR> but in functional relation you want it to be
10:03:48 <mniip> ski, what's P?
10:03:52 <ski> powerset
10:04:02 <mniip> oh I though the free pointed functor
10:04:51 <dmwit> noipmups: `data Identified x = Identified { identifier :: DBIdentifier, val :: x }; type DBUser = Identified User` or `data DBUser f = DBUser { ..., identifier :: f DBIdentifier }; type User = DBUser Proxy`.
10:04:56 <ski> EvanR : sure. i don't see why that's important here, though
10:05:43 <EvanR> so if 1 means 1 and * means "zero or more" *---1 is bad notation for functional relation
10:05:52 <EvanR> maybe you want +---1 :)
10:06:06 <ski> no, it isn't required to be total
10:06:11 <EvanR> oh
10:06:17 <EvanR> partial function
10:06:36 <ski> er .. sorry, that should be : it's not required to be *surjective*
10:06:45 <mniip> yeah you have a category of relations with Set and Set^op embedded in it
10:06:52 <EvanR> uh
10:06:57 <EvanR> i was griping about that total part
10:07:05 <ski> i was assuming totality of functional relations (though that's usually not assumed in rel. DB theory)
10:07:11 <EvanR> but half joking anyway
10:07:32 <ski> (for not-necessarily-total, i could write `*---0..1', i suppose)
10:08:07 <EvanR> *---Bool :)
10:08:44 <ski> yea, if we want to step away from common "multiplicity" notations in rel. DBs
10:09:16 <ski> (i only used them, because people might be familiar with them)
10:09:19 <EvanR> many to many, ok, but many to one doesnt seem functional to me
10:09:40 <mniip> 9/25/2018 [20:02:46] <ski> mniip : however, if you have `P A *---1 B', then the powerset is on the domain side of the map, not the codomain, so would be less trivial
10:10:00 <mniip> I would introduce an artifical key K and have 'B 1---* K', 'K *---* A'
10:10:33 <ski> by `R : A *---1 B' i mean `R : A *---* B' such that for all `x' in `A', there is exactly one `y' in `B' with `x R y' -- sounds pretty functional to me
10:11:53 <ski> mniip : i suppose it could work, if one doesn't need to reallocate keys all the time, or have a very large number of them
10:12:11 <ski> (and i assume you meant `K *---1 A', not `K *---* A')
10:15:54 <EvanR> yeah
10:16:39 --- mode: glguy set +v Morishio
10:20:05 <heptahedron> I love Gabriel Gonzalez' posts and have reason to believe he is correct 99% of the time but here http://www.haskellforall.com/2012/12/the-continuation-monad.html he says that `ContT` is a monad transformer--but this isn't technically accurate, is it?
10:21:03 <heptahedron> Or rather, its use with certain monads will fail to abide by the laws, won't it?
10:25:05 <Ariakenom> How implementable is STM without special runtime support?
10:27:28 <dmwit> pretty much not at all
10:28:18 <Ariakenom> dmwit: why?
10:28:56 <dmwit> heptahedron: Hm. The documentation for ContT doesn't mention anything about that; are you sure?
10:29:13 <dmwit> heptahedron: (In fact, the documentation seems to imply that it "works" even for things which are not monads.)
10:30:57 <heptahedron> dmwit: I could've sworn I read it months ago, and I'm inclined to believe it because of the somewhat tangled control flow that continuation manipulation can result in feels like it would mess with associativity. This is related, but I'm having trouble finding one related directly to `ContT`: https://wiki.haskell.org/ListT_done_right#Examples
10:31:40 <dmwit> Ariakenom: Try the intro to the STM paper. It has some quite convincing motivating examples, as I recall.
10:33:33 <Ariakenom> I'll go have a look
10:34:40 <dmwit> Ariakenom: page 2, paragraph 2 (starting "For example, consider a hash table with thread-safe insert and delete operations") is what I had in mind.
10:36:21 <dmwit> heptahedron: ...but ListT is not ContT.
10:36:26 * dmwit scratches his head
10:37:48 <Ariakenom> dmwit: I don't see anything directly excluding a library level implementation there
10:39:04 <heptahedron> dmwit: I am aware, haha. The thing that concerns me in the docs for ContT is that is is said to not be a "functor on the category of monads", something I have not seen stated in relation to any other monad transformer, and that "many operations cannot be lifted through it"
10:39:41 <dmwit> But that's a completely different claim than "ContT r m is not a Monad".
10:41:10 <dmwit> Ariakenom: Okay. Anyway I suspect if you tried, you would find retry to be the difficult piece: you want to wake up, efficiently, when anything you've touched so far has been modified by another thread, but without taking out any locks on those other values. Yikes.
10:42:28 <Ariakenom> dmwit: Yes quite tricky. I suspect a list of listeners and a sprinkling of weak refs would work.
10:43:08 <dmwit> The other thing that I think would be difficult to avoid would be a global lock for transaction commit.
10:43:34 <dmwit> STM allows transactions which don't step on each other's toes to proceed at the same time.
10:43:48 <Ariakenom> Yes. But I believe the semantics would work with a global lock.
10:43:49 <heptahedron> dmwit: I suppose "ContT is a monad transformer" does not directly mean "forall r m, ContT r m is a monad", if that's what you're saying
10:44:55 <dmwit> It isn't. I'm saying "ContT is not a functor on the category of monads" does not imply "exists r m, ContT r m is not a Monad".
10:46:02 <Ariakenom> I've done some implementation of stm that had 2 phases. It first ran the action and gathered up effects and then took a global lock, checked if failed, and performed effects.
10:46:17 <Ariakenom> But no blocking retry
10:47:17 <Ariakenom> Performance may well suck without runtime though.
10:47:20 <dmwit> I mean I guess the Haskell implementation is done in C without an underlying C implementation of STM, right? So it must be possible.
10:48:32 <heptahedron> dmwit: Oh! Thank you for the clarification. Do you happen to know why they would state that, though? It seems like a word of caution and I'm just trying to make sure I understand the interaction between its control flow manipulation and interleaving effects in the underlying monad properly
10:48:40 <dmwit> I could even imagine some way of having the library follow a lock discipline that avoided a global lock. Maybe lock each variable in the order they were created or something.
10:48:48 <dmwit> I dunno. Maybe I should roll back my original claim.
10:49:39 <phadej> ordering locks will allow only applicative interface
10:50:00 <dmwit> Not at all. We're talking about transaction-commit-time, where we know exactly which variables we want to read/write from.
10:50:51 <phadej> dmwit: which locks to get readVar foo >>= \x -> if x then modifyVar bar (+1) else modifyVar quu (-1)
10:50:55 <dmwit> heptahedron: I don't know exactly what the warning means, I admit. It would take some unpacking.
10:50:55 <phadej> all three?
10:51:31 <dmwit> phadej: No; we speculatively read foo as usual. Then at commit time if we speculatively read True than foo and bar are the things we lock before checking that nothing has changed out from under us.
10:51:59 <dmwit> (And, for completeness, if we speculatively read False then foo and quu are the locks we take.)
10:52:58 <phadej> dmwit: I don't follow, isn't _that_ exactly how STM paper describes one possible implementation of STM
10:53:23 <dmwit> Let's say "yes" and see where that gets us.
10:54:41 <phadej> (I lost context what your original claim was)
10:55:39 <dmwit> Original claim: STM would be hard to implement without RTS support. (I no longer feel confident making this claim.)
10:56:13 <dmwit> (Do locks count as "RTS support"? I don't know. I didn't ask the original question, and I was too stupid to clarify before I answered.)
10:56:45 <phadej> STM has other things, like transaction reordering
10:57:03 <Ariakenom> I meant the specific STM support.
10:57:04 <phadej> which are implementation details, but which you kind of need to it not to fall aprt
10:57:59 <phadej> e.g. if there are a lot of small transactions touching only few vars, but then few bigger which touch many vars -- latter are unluckily to commit in naive implementation
10:58:33 <Ariakenom> I feel confident the semantics (not that I checked what they are) are technically achievable. It's a question of in practise
10:58:37 <phadej> ... as small fast one will mutate vars, invalidating speculative reads of bigger/slower transactions
11:00:37 <dmwit> Ariakenom: Fun fact I discovered recently while trying to decide which concurrency primitives to use: without contention, TMVar is faster than MVar. So it might be quite hard indeed to get STM as fast as it is with only MVars available. =P
11:00:59 <Ariakenom> phadej: Interesting but I found it hard to find a concise explanation of reordering. Can you explain?
11:01:05 <phadej> dmwit: but that's because MVars are fair, TMVar's aren't
11:01:19 <Ariakenom> dmwit: Interesting! Do you have the numbers anywhere?
11:01:20 * dmwit nods agreeably
11:01:31 <dmwit> Ariakenom: https://www.reddit.com/r/haskell/comments/39ef3y/ioref_vs_mvar_vs_tvar_vs_tmvar/
11:01:35 <phadej> dmwit: i.e. with MVar the first one to wait first one to wake up
11:01:48 <dmwit> phadej: I know.
11:01:51 <phadej> +1
11:02:14 <phadej> IIRC marlow's book describes that
11:02:33 <phadej> but I don't recall what was the use case which isn't expressible with STM
11:02:45 <dmwit> (This caveat is also mentioned by several folks in the thread I linked.)
11:04:09 <Ariakenom> aww 404 on results
11:04:19 <Ariakenom> code is alive though
11:05:12 <phadej> Ariakenom: reorganization is probably wrong word. something like transaction prioritisation
11:06:03 <Ariakenom> oh? transaction reordering did seem used as a DB term
11:06:28 <phadej> ok. i'm not good with that terminology slang :)
11:07:17 <phadej> but that's true that similar problems are in DBs and STM
11:10:47 <Ariakenom> phadej: Right. Do you know any such tricks that would be hard?
11:12:03 <phadej> Ariakenom: I don't know how to fit that in "get locks in order" model, as you need some kind of coordination
11:13:12 <phadej> in STM-like PoC i made, I used a single write queue
11:13:23 <phadej> so I had concurrent reads, by serialised writes
11:13:33 <phadej> but*
11:22:41 <apostolis> Hello, I want to use the Data.Map type and I need to provide an Ord. What would be the effect if I implement it like this (a <= b = True)
11:23:20 <apostolis> I exect it would only degrade the performance , right?
11:23:56 <Ariakenom> apostolis: All keys are equal so you can only have one item?
11:25:02 <apostolis> Not Equal, but they have the same order.
11:26:20 <apostolis> If they are equal, they have the same order. If they have the same order, they do not have to be equal.
11:26:33 <dmwit> apostolis: That is not the contract that Ord makes.
11:27:18 <dmwit> apostolis: From the docs: "Antisymmetry: if x <= y && y <= x = True, then x == y = True".
11:28:20 <dmwit> apostolis: Anyway, to answer your direct question: the effect of implementing `a <= b = True` on `Map` would be that `Map` would all insertions as being at the same key.
11:28:33 <dmwit> s/would all/would treat all/
11:29:05 <apostolis> ok , thanks.
11:30:26 <apostolis> Is there a data structure like map that only accepts equality? Probably a hash structure?
11:30:41 <apostolis> /accepts/uses/
11:30:46 <dmwit> ...a hash structure will need at least Hashable.
11:31:00 <dmwit> :t lookup -- is the only thing I can think of that requires only Eq
11:31:01 <lambdabot> Eq a => a -> [(a, b)] -> Maybe b
11:31:01 <Ariakenom> apostolis: https://hackage.haskell.org/package/base-4.12.0.0/docs/Prelude.html#v:lookup
11:31:13 <Ariakenom> that was same as dmwit 's
11:32:23 <dmwit> (Also I think you are making a mistake. Why do you want to avoid Ord?)
11:32:44 <Boarders> What is the standard approach to debugging where you have a bunch of polymorphic functions and want to use trace statements (and maybe force) and are forced to add a bunch of Show and NFData instances to your functions?
11:32:54 <Boarders> is it just to defer type errors or is there a fancier approach?
11:33:19 <Boarders> assuming that those classes have instances at the top level
11:33:23 <dmwit> I don't think deferring type errors will help.
11:33:43 <dmwit> The standard approach is to add a bunch of Show constraints to your functions.
11:33:54 <dmwit> Of course there's always unsafeCoerce...
11:34:07 <apostolis> dmwit : Maybe I could use an Int as a key, but I need to make sure that each element is given a unique Int.
11:34:34 <dmwit> % let amazing :: a -> a; amazing x = traceShow (unsafeCoerce x :: Int) x in amazing (0 :: Int)
11:34:34 <yahb> dmwit: 0; 0
11:34:48 <apostolis> or not.
11:35:11 <dmwit> apostolis: I don't understand what that means. I also don't understand why that motivates avoiding Ord.
11:36:12 <dmwit> % let amazing :: a -> a; amazing x = traceShow (unsafeCoerce x :: Int) x in amazing "hi" -- but if you're wrong...
11:36:12 <yahb> dmwit: "-576460751195978811; hi"
11:36:20 <apostolis> I want to use intersection and union and difference on a key that has no Ord Instance, just Equality.
11:36:50 <dmwit> apostolis: Why do you want that? Why do you want to avoid having an Ord instance for your keys?
11:37:44 <apostolis> Because they do not have a way to order them while also preserving antisymmetry.
11:38:52 <Ariakenom> apostolis: what are they?
11:39:49 <apostolis> https://github.com/agda/agda-ocaml/blob/master/src/full/Agda/Compiler/Malfunction/AST.hs#L134
11:40:16 <dmwit> Surely the derived instance would work just fine...
11:40:26 <apostolis> It does not.
11:41:59 <dmwit> What goes wrong?
11:42:13 <apostolis> Ok, I think I need to put derivations to the other data types as well, then I think it will work.
11:42:31 --- mode: glguy set +v dataN
11:42:49 --- mode: glguy set -v dataN
11:45:11 <apostolis> ok, that was the problem, I needed to put derivations to the other datatypes. Thanks dmwit Ariakenom.
11:45:44 <Ariakenom> nice, np
11:46:12 <infinisil> Can recommend this library for handling processes: https://hackage.haskell.org/package/typed-process
11:46:54 <infinisil> Much better than 'process'. Nice interface, lazy ByteString based
11:47:51 <dataN> ok, this is a long shot but;
11:47:55 <dataN> this works; https://lpaste.net/7025340467776585728
11:48:05 <dataN> and this does not; https://lpaste.net/8158280229744279552
11:50:34 --- mode: glguy set +v dataN_
11:50:45 --- mode: glguy set -v dataN_
11:58:27 <Peaker> hey, do .cabal files intentionally not support "if" in the top-level? Is there any way to have conditional data files? (e.g: bin/node.exe on Windows and bin/node otherwise)
12:08:23 <phadej> that use case is quite suspicious...
12:08:32 <phadej> data-files... .exe... err
12:09:48 <tdammers> I can think of legitimate use cases though
12:11:23 <Peaker> phadej, https://github.com/lamdu/nodejs-exec <-- it's to get a "node" executable one can execute from Haskell code
12:11:34 --- mode: glguy set -v vaibhavsagar
12:13:39 <phadej> Peaker: what you should/could do, is provide a wrapper to find nodejs installed by the user. It's not a job of Haskell ecosystem to distribute node
12:13:44 <phadej> we don't bundle gcc either
12:13:56 <phadej> though many packages require (some) C-compiler to exist
12:14:14 <dataN_> ha! this works; https://lpaste.net/2026865083539259392
12:14:24 <Peaker> phadej, I have a package that either uses a user-downloaded nodejs, or builds one for you. I don't mind whether it's "the job" or not, I want it to "Just work" 
12:15:11 <Peaker> phadej, I wish more packages bundled the C sources so that cabal built them - instead of relying on the system-side package to exist (which is my next trouble -- installing leveldb on Windows is not found by the Haskell bindings :-( )
12:15:27 <phadej> Peaker: cabal isn't designed for that. You can use build-type: Custom, but I'd advise "just don't"
12:15:45 <Peaker> phadej, "just don't" leads to more frustration. I like "Just works"
12:15:56 <vaibhavsagar> Peaker: sounds like you want Docker
12:16:03 <vaibhavsagar> or Nix
12:16:11 <phadej> vaibhavsagar: +1
12:16:13 <Peaker> vaibhavsagar, On Windows? I want to build a Windows executable I can release
12:16:23 <Peaker> AFAIK Nix can't do that.  Can Docker?
12:16:28 <vaibhavsagar> Docker does run on Windows afaik
12:17:02 <Peaker> well, unless someone made a docker that has leveldb-haskell on it, it's probably not going to help
12:17:04 <phadej> fwiw, IOHK folks work on cross-compiler Linux -> Windows :)
12:17:23 <vaibhavsagar> yeah, they use Nix for that which I find hilarious :)
12:17:29 <vaibhavsagar> poor angerman
12:17:41 <vaibhavsagar> he has a lot to be angry about :D
12:18:09 <Peaker> even on Linux I can't use nix... I tried and it just builds executables that segfault with 0 debug info so I can't even debug why :(
12:18:09 <phadej> Peaker: my advice, if you do multi-language "thing", don't try to do everything with Cabal - just admit that you have complex setup and write Shakefile or something else
12:18:31 <vaibhavsagar> Peaker: that is very unusual
12:19:01 <Peaker> phadej, I use glfw-b package, freetype2, and various others that embed the C sources via cabal. They're awesome to use. They build with 0 problems. Can share the installation of these libs across many packages
12:19:05 <vaibhavsagar> I run NixOS on all my linux machines and I've never seen anything like that
12:19:26 <vaibhavsagar> but the 0 debug info issue can be fixed with a configuration option
12:20:21 <phadej> Peaker: so then just embed nodejs :)
12:20:23 <Peaker> vaibhavsagar, nix is hard for me -- it feels much much harder than it should be. The core idea doesn't seem to necessate the weirdness
12:20:58 <vaibhavsagar> the language and CLI tooling are less than ideal, but the ideas are good
12:21:23 <Peaker> vaibhavsagar, yeah, the devil is in the details though. Every thing I tried to do with nix had so much friction, required to learn so much irrelevant detail
12:21:24 <vaibhavsagar> at my last job I used Nix all day every day across hundreds of servers
12:21:39 <vaibhavsagar> Peaker: I could say the same thing about Haskell
12:21:56 <vaibhavsagar> me, 1 year ago: "wtf is a CAF???"
12:22:12 <vaibhavsagar> me, 2 years ago: "comonads wtf"
12:22:16 <Peaker> vaibhavsagar, true, Haskell shares much of the problems. And nix might be worth it too, but I can't afford to learn it at the moment
12:22:26 <vaibhavsagar> that's fair
12:22:52 <vaibhavsagar> but no other haskell build tool manages non-haskell dependencies
12:23:11 <vaibhavsagar> cabal won't do it, stack won't do it, and ghc definitely won't do it either
12:23:52 <vaibhavsagar> and that goes double for Windows, which doesn't enjoy the same level of support as Linux
12:25:46 <Peaker> vaibhavsagar, cabal/stack do it if you embed the C sources
12:25:57 <vaibhavsagar> but they don't manage gcc
12:26:07 <vaibhavsagar> as phadej pointed out earlier
12:26:08 <vaibhavsagar> or make
12:26:09 <Peaker> but gcc is easy to install, and is likely installed anyway
12:27:00 <vaibhavsagar> I think we're talking past each other: I said it doesn't manage non-Haskell dependencies, which is still true even given what you're saying about GCC
12:27:57 <vaibhavsagar> in fact I'm not quite right: Stack does manage system dependencies, but only when you use its shitty Nix integration, in which case it delegates the management to Nix
12:28:35 <vaibhavsagar> if you don't believe me, try installing Stack on a fresh OS image without GMP
12:29:07 <phadej> FWIW, nodejs is trivial to install on Windows
12:29:09 <vaibhavsagar> or using any nontrivial Haskell app without having the zlib headers available
12:29:13 <phadej> probably easier than GHCC
12:29:15 <phadej> GCC*
12:29:18 <Peaker> sure, nix is nicer - when it's already configured and it works. for me it doesn't work, and I find it very hard to learn to configure
12:30:26 <vaibhavsagar> Peaker: all you're supposed to have to do is install the package manager
12:30:38 <vaibhavsagar> if you're experiencing weird issues that's a bug in Nix
12:30:52 <vaibhavsagar> there's not much configuration you can do on non-NixOS anyway
12:31:09 <vaibhavsagar> I'd love to sit down with you and see what is actually happening
12:31:27 <Peaker> by configuring, I mean the equivalent of the stack.yaml/cabal file. Much easier to write those files than the .nix file for the same purpose
12:31:50 <Peaker> (because they're so much more restricted)
12:31:55 <vaibhavsagar> sure, but you could also just write the .cabal file and use cabal2nix
12:32:21 <Peaker> you can try to build lamdu via nix -- we have it in main repo, but for some it generates segfault-ing executable
12:34:41 <Boarders> Prelude Unsafe.Coerce> unsafeCoerce (3 :: Int) :: Bool ; False
12:34:51 <Boarders> why does this happen, is it because it chooses the first in a sum type?
12:35:53 <phadej> Boarders: "implementation details"
12:36:22 <phadej> i.e. if you will rely on that, you'll regret that choice
12:36:29 <Boarders> I absolutely would not
12:36:42 <Boarders> strictly "hmm wonder what that is about"
12:37:08 <phadej> Int and Bool happen to be represented similarly
12:37:52 <phadej> unsafeCoerce (Just 'a') :: Either String Char -- seems to work too
12:38:15 <fryguybob> Ariakenom: Your question about STM is a good one.  I'm curious what your goal is?
12:39:00 <Boarders> I suppose there is some sort of header info telling which disjunct of the sum type you are in and the rest is just it doing its best at pointer chasing and interpretting bits as whatever you ask for
12:40:02 <Boarders> Not really sure though
12:40:40 <Ariakenom> fryguybob: Ah, you were the guy for this stuff if I remember correctly
12:41:14 <dataN_> writing (k -> Constraint) where k can be e.g. ((* -> *) :: k) is not the same as (* -> * -> Constraint), because its ((* -> *) -> Constraint)
12:41:15 <phadej> Boarders: try unsafeCoerce (True :: Bool) :: Int
12:41:32 <Ariakenom> fryguybob: No particular goal really. It was a part of the theory "you can implement a lot user level haskell"
12:41:33 <phadej> Boarders: i'd suspect that Bool is somehow special
12:41:39 <phadej> in the implementation
12:41:41 <dataN_> how can something match over the constraint of a multiparameter typeclass?
12:41:42 <phadej> so it works by accident
12:42:01 <phadej> ... and might work less well not in GHCi
12:42:20 --- mode: glguy set +v dasli
12:42:46 --- mode: glguy set -v dasli
12:43:10 <dataN_> ((* -> *) :: *) sorry
12:43:17 <fryguybob> Ariakenom: One difficulty in writing low level things is GC.  We rely on GC not happening at critical times and that is hard to express in Haskell.
12:43:18 <Boarders> phadej: makes sense, anyway time to stop doing javascript in haskell
12:44:03 <fryguybob> Ariakenom: Getting good performance also relies on the right in memory representation which means we have to teach the GC new tricks.
12:44:59 <Ariakenom> fryguybob: Super interesting. Do you have an example?
12:45:30 <fryguybob> You can come pretty close to a good STM implementation if you can write cmm (foreign import prim) and you use structures that GC already knows about.
12:46:23 <fryguybob> Ariakenom: The STM metadata structures are all handled specially by GC (nothing particularly special about the handling, just that they are special cases).
12:46:52 <dataN_> is the distinction between type and kind level parenthesis because kinds cant be partially applied? 
12:47:35 <fryguybob> Ariakenom: Matt Le and I did a TL2 based implementation that changed that representation and prevented long blocking transactions from being traversed in GC more then once.
12:48:13 <Ariakenom> fryguybob: Hm would that cmm approach count as user-level though. Are there more pitfalls than say weak refs?
12:49:17 <fryguybob> Ariakenom: Largely that is to prevent GC at the wrong time (in the middle of commit).
12:52:25 <fryguybob> Ariakenom: You can probably design a commit algorithm that can handle GC in the middle.  I'm not sure why you would want to though.
12:53:20 <Ariakenom> Well I'm interested in if it can be done in regular  Haskell
12:54:20 <fryguybob> Ariakenom: What is included in "regular Haskell"?
13:03:36 <dmwit> See? fryguybob is smarter than me. His first question is "what does 'without RTS support' mean?".
13:03:42 <dmwit> Took me half an hour to get to that point.
13:04:03 <fryguybob> dmwit: I had the benefit of your previous conversation :P
13:04:37 <dmwit> Very diplomatic, thank you. =)
13:05:32 <fryguybob> Ariakenom: A goal that I have is to be able to provide alternative TM implementations without recompiling the rts.  We are fairly close to being able to do that now, but we do that by providing great features in the RTS already :D.
13:05:59 <fryguybob> Ariakenom: With mutable constructor fields we get even closer.
13:07:09 <dmwit> Oh, is that pretty sure to get into GHC, then? I knew there were murmurs about it.
13:08:17 <fryguybob> dmwit: I have to finish my thesis before I can devote much time to writing an implementation that can be in GHC, but mutable constructor fields extended to STM is a significant part of my thesis.
13:09:11 <fryguybob> I'll be at Haskell Symposium on Thursday and Friday and we will meet at some point to talk about what needs to be done.
13:09:24 <fryguybob> (for mutable constructor fields, not my thesis...)
13:11:50 <dataN_> what is this?
13:12:06 <dmwit> fryguybob: sweet!
13:13:08 <fryguybob> dataN_: https://github.com/simonmar/ghc-proposals/blob/mutable-fields/proposals/0000-mutable-fields.rst
13:13:38 <fryguybob> dataN_: It allows you to express heap objects with mutable fields while not breaking type safety.
13:15:16 <dmwit> One thing I've always found curious: `instance Eq (IORef a)` but not `instance Ord (IORef a)`.
13:15:37 <dmwit> (This sprung to mind thanks to the commentary on pointer equality in the "motivation" section there.)
13:16:47 <dolio> Eq doesn't require worrying about reordering pointers.
13:16:48 <vaibhavsagar> Peaker: I built and successfully launched Lamdu
13:17:04 <dataN_> so is this GC stuff only important in that setting?
13:17:09 <dolio> Or creating a separate, canonical value that doesn't change on GC.
13:17:28 <Peaker> vaibhavsagar, so much for reproducible builds? :) heh
13:17:31 <nitrix> Otherwise, IORef all have to become stable pointers afaik.
13:18:43 <fryguybob> dataN_: Which GC stuff?
13:18:43 <dataN_> as in, how much performance is gained by not using mutable variables?
13:19:02 <Peaker> can also create a data-type for IORef+serialNum  that grows with every new such ref - and use that for Ord
13:19:04 <dmwit> dolio: Okay!
13:19:05 <vaibhavsagar> Peaker: are you making assumptions about the video driver?
13:19:18 <vaibhavsagar> because I hear that is something that is funky with Nix
13:19:25 <Peaker> vaibhavsagar, I use OpenGL via glfw-b and the ordinary packages
13:19:36 <Peaker> vaibhavsagar, and some font rendering packages that have some glsl shaders
13:19:53 <dataN_> fryguybob: avoiding IORef for the sake of the GC
13:20:03 <fryguybob> dataN_: Ah, that is a tricky question.  I always assume you would be using IO or STM because some other requirement is forcing you to (such as concurrency).
13:20:40 <dataN_> while I always assume such considerations are handled by the OS threads!
13:20:57 <fryguybob> dataN_: Ryan Newton and his students have done some interesting explorations on data structures that increase their mutable components over time to avoid bottlenecks.
13:23:23 <dataN_> is there any advantage to assuming an immutable representation placed on top of some underlying concurrency handling layer?
13:24:52 <dataN_> thats what the question about GC was getting at, that by pulling in mutability from this lower level that it might interfere with whats assumed to be its efficient deallocation procedure 
13:25:12 <dolio> If you do mark-compact, could you do Ord?
13:25:36 <fryguybob> dataN_: I don't understand what you have in mind for "underlying concurrency handling layer", but some real costs with GC is you have to always traverse any thing that has pointers and mutated even to collect the young generation.
13:26:30 <dataN_> well like how programs written without mutable datastructures still run on many cores
13:27:03 <fryguybob> dataN_: Well those are deterministic programs, not concurrent ones right?
13:28:05 * [exa] puzzled at concurrency vs. determinism
13:28:09 <fryguybob> dataN_: There is also a non-GC cost to mutation of shared memory in that it invalidates cache lines on other cores.
13:28:15 <dataN_> and hopefully deallocate what can be determined at compile time to be without reference after some point (no idea how GC in haskell really works, just trying to articulate the naive assumptions that result from never using mutable datatypes) 
13:29:45 <dataN_> fryguybob: right, thats the kind of thing a good underlying concurrency layer would be designed to work with safely?
13:30:05 <fryguybob> [exa]: Running a program on many-cores and getting the same answer as running a program on a single core is what I'm getting at.  That is a different sort of use of many cores then concurrency.
13:31:15 <fryguybob> dataN_: Yeah you loose flexibility in implementation with mutablity.  Hence my assumption that it is something you need to begin with.
13:31:18 <dataN_> the question is really, how much danger is their in allowing the user access to the 'mutable' keyword 
13:31:41 <dolio> [exa]: https://existentialtype.wordpress.com/2011/03/17/parallelism-is-not-concurrency/
13:32:44 <dataN_> that all of the careful memory allocation handled by the compiler would be jeopardised by clumsy use of mutable datatypes, or is this false? 
13:32:51 <fryguybob> dataN_: It only makes things better in my experience :D.  It is improving the programs that already need to be written in IO.
13:34:24 <dataN_> but how would a new user not familiar with lazy evaluation not just presume a mutable type was the way to go in what would otherwise be a pure setting?
13:34:34 <fryguybob> dataN_: I think clumsy use of mutable fields would be pretty obvious.  It lives in IO.
13:35:10 <dataN_> that is certainly offputting! 
13:36:02 <[exa]> fryguybob: you don't have the same _answer_ on multiple cores? like, race conditions and locking trouble?
13:36:06 <dataN_> but presumably there are certain paradigms better suited to this (thinking e.g. actors models)
13:36:10 <[exa]> dolio: s/parallelism/determinism/
13:36:44 <fryguybob> [exa]: Like user input or packets from the network.
13:37:12 <dataN_> its kind of similar to a convolution over a graph though right?
13:38:41 <[exa]> fryguybob: oh I finally read the scrollback, you're pointing to mutability problems
13:38:58 <fryguybob> [exa]: Yes :D.
13:39:18 <dataN_> like, each node could communicate using concurrency, or it could rely on global updates of an immutable datatype
13:39:22 <[exa]> fryguybob: there are simple proofs that data won't change, either from TS or from runtime properties
13:40:18 <[exa]> fryguybob: guess people will apply a thick layer of those proofs before trying to break it :]
13:41:32 * fryguybob must go.  Hope to see everyone at Haskell Symposium soon :D.
13:42:03 <dataN_> so if there are timing considerations as to when each node can contribute, it would be difficult to determine which approach to use, unless the timings are of bounded predictability 
13:43:48 <dataN_> so that the cutoff point between when mutable or immutable datatypes are the best choice could be determined 
13:45:17 <Ariakenom> fryguybob: sry for dissapearing. ill be away for a while
13:59:07 <davr0s> haskell binaries.. standalone? 
14:00:25 <cocreature> davr0s: what exactly are you asking? GHC will by default link Haskell depedencies statically and only link dynamically against glibc, libgmp and libz iirc. you can also build fully static binaries if you want to
14:00:52 <davr0s> ok that answers my question
14:01:16 <koz_> If I want to propose adding something to base, is this the right place to propose it? https://github.com/ghc-proposals/ghc-proposals
14:01:59 <cocreature> koz_: iirc for changes to base the libraries mailing list is a better choice
14:02:07 <koz_> cocreature: Which mailing list is that?
14:02:57 <cocreature> koz_: https://mail.haskell.org/cgi-bin/mailman/listinfo/libraries
14:03:04 <koz_> cocreature: Thanks!
14:22:32 <greymalkin> getting Data.Vector strict is... challenging.
15:14:32 --- mode: glguy set +v xzhu
15:15:01 <xzhu> I'm using spacemacs with intero
15:16:05 <xzhu> What editor/IDE do you guys use nowadays?
15:17:05 <sleepster> xzhu: I like visual code
15:17:07 <Cale> Sublime Text and some terminals running ghcid
15:17:29 <sleepster> I am newb sauce though
15:17:35 <sleepster> so visual code is perfect for me
15:17:36 <xzhu> which extension do you use?
15:17:37 <koz_> Neovim with hdevtools, hlint and hindent via Neomake (for first two) and (Neo)vim's built-in formatter support.
15:17:49 <koz_> (controlled by project-level .nvimrc)
15:19:39 <sleepster> xzhu: https://marketplace.visualstudio.com/items?itemName=justusadam.language-haskell   and https://marketplace.visualstudio.com/items?itemName=hoovercj.haskell-linter
15:19:51 <sleepster> just those two
15:21:27 <boj> when using TypeApplications, can you still reference the type variable like you can with Proxy?
15:21:44 <jle`> boj: you can't yet use type applications in patterns
15:21:51 <jle`> but there's a ghc proposal in the works to allow it
15:22:08 <boj> jle`: ok, thanks
15:23:52 <Cale> You can add type annotations to patterns with ScopedTypeVariables though, and it will bind the mentioned type variables
15:24:11 <Cale> (personally I find the idea of using TypeApplications in patterns a little strange)
15:40:11 <sleepster> I read somewhere that packages in haskell are verifiably correct
15:40:16 <sleepster> not sure what that means though
15:40:29 <hpc> there's degrees of correctness
15:40:38 <hpc> the most likely degree to be true is type safety
15:40:45 <hpc> take a look at "safe haskell"
15:41:05 <sleepster> I think it was in this youtube video https://www.youtube.com/watch?v=lC5UWG5N8oY
15:41:07 <hpc> it's not correct in the way that you could say, statically guarantee that sortBy always returns a sorted list
15:41:43 <koz_> jle`: I finished writing everything up, but when I tried testing it, it blew up on me as so: https://lpaste.net/2723260456826306560
15:41:50 <koz_> Am I misunderstanding how to use getDSM or something?
15:43:11 <lyxia> with hs-to-coq there's a way to formally prove that kind of high-level properties now.
15:43:34 <Cale> koz_: What are the types of getDSM and constructDataSet?
15:43:44 <hpc> bleh, an hour and a half of C++ talk is a bit much
15:44:13 <koz_> Cale: getDSM :: T.Text -> (forall (n :: Nat) (m :: Nat) . (KnownNat n, KnownNat m) => DataSetMeta n m -> IO r) -> IO r
15:44:27 <toovs> stack is complaining about the wrong version number for a shared library (libicuuc.so.62 when I have libicuuc.so.56) and not sure how to fix. unregistering and recompiling text-icu doesn't seem to help.
15:44:38 <koz_> And constructDataSet :: (KnownNat n, KnownNat m) => DataSetMeta n m -> IO (DataSet n m)
15:44:54 <koz_> Do I understand correctly that I have to end up with something that doesn't refer to n and m at all?
15:44:56 <Cale> koz_: The type r can't mention n or m
15:45:01 <koz_> Ah, I see.
15:46:05 <hpc> you can think of it as scoped, sort of
15:46:06 <Cale> Conceptually, r is chosen "before" n and m, by whoever uses getDSM
15:46:13 <Cale> while getDSM gets to choose n and m
15:46:14 <hpc> (in a slightly different way than ScopedTypeVariables)
15:46:48 <Cale> and the function you pass to it needs to work for any choice of n and m
15:47:02 <jle`> yeah, this is an annoying point of working with continuation-based existentials in ghci
15:47:29 <jle`> because it requires you specify everything you want to do up-front
15:47:34 <jle`> to pass as the continuation
15:47:46 <Cale> Well, in ghci, sure :)
15:47:46 <koz_> jle`: So essentially, I'm gonna have to build a giant chain of things to do (say, 'doMyWorkForMe' which ends up with something that doesn't mention n, m), then feed it to getDSM?
15:48:02 <Cale> It's not so bad when you're actually writing substantial code though
15:48:08 <jle`> yeah, you can't "explore" the contents in your continuation interactively
15:48:14 <jle`> yeah, i'm talking specifically about interactive/exploratory programming
15:48:41 <jle`> it's one of the major roadblacks in exploratory interactive coding with dependent types, i've found
15:48:46 <dmwit> jle`: https://stackoverflow.com/q/42425939/791604 ?
15:48:48 <Cale> Too bad you can't pass ghci as an argument :)
15:48:58 <jle`> koz_: alternatively you can use an existential wrapper
15:49:12 <jle`> dmwit: that's cute, i'll look at that :O
15:49:17 <jle`> koz_: you can construct an ad-hoc one
15:49:36 <hexagoxel> does hackage expose some interface where i pass packagename and identifier and it jumps to the relevant bit? without the manual mouse-heavy go-through-index path?
15:49:41 <Cale> getDSM (\dsm -> ghciWith [("dsm", dsm)]) -- if only we could write something like this :D
15:49:42 <jle`> data WrappedDS = forall n m. DataSet (Sing n) (Sing m) (DataSetMeta n m)
15:49:51 <jle`> then you can do
15:50:04 <hexagoxel> (the relevant bit of the package docs, that is)
15:50:07 <jle`> WrappedDS sn sm dsm <- getDSM "blah" (DataSet Sing Sing)
15:50:23 <jle`> WrappedDS (Sing :: Sing n) (Sing :: Sing m) dsm <- getDSM "blah" (DataSet Sing Sing)
15:50:29 <jle`> if you want the type variables in scope too
15:51:13 <koz_> jle`: Ah, I see.
15:51:15 <jle`> or if we're not using singletons, data WrappedDS = forall n m. (Knownnat n, KnownNat m) => DataSet (DataSet n m)
15:51:23 <koz_> Is it worth using singletons here?
15:51:33 <jle`> DataSet (ds :: DataSet n m) <- getDSM "blah" DataSet
15:51:46 <jle`> ^ that works just as well using only GHC.TypeLits stuff
15:51:54 <jle`> nah, it's just the way i normally think about these things
15:51:54 <Cale> I usually do my best to avoid singletons
15:52:02 <Cale> and thus far have succeeded
15:52:17 <jle`> i just like having explicit KnownNat witnesses that i can manipulate first-class
15:52:32 <jle`> instead of having them being ambient typeclass contexts that are satisfied
15:52:36 <sleepster> what'sa  singleton?
15:52:46 <sleepster> I come from OOP background is it similar?
15:52:52 <jle`> not quite similar in practice
15:53:12 <koz_> jle`: Yeah, it certainly seems a bit easier to think about. I'll keep writing using the pseudo-ContT IO style and if it gets too annoying, I'll switch.
15:53:13 <sleepster> it looks like they are equally as bad
15:53:14 <jle`> i wouldn't think of them as related :)
15:53:14 <koz_> But it works!
15:53:32 <jle`> sleepster: they're mostly a band-aid over haskell's lack of dependent types
15:53:47 <jle`> so it's kind of the 'best we got for now' sorta situation
15:53:55 <Cale> sleepster: heh, they're something completely different. I don't think they're nearly so bad, just syntactically tedious sometimes.
15:54:39 <jle`> koz_: i'm not exactly sure of the second thing i wrote brings KnownNat n, KnownNat m into the context. but i suspect it does
15:54:44 <shachaf> Cale: They're similar in that in both cases a singleton is a type with a single value.
15:54:49 <Cale> Singletons in this case are types which are parameterised in such a way that there is a single element of the type for any given argument to the type, by design.
15:55:14 <jle`> koz_: this is the 'magical' part of typeclass contexts that i mean
15:57:47 <jle`> dmwit: ah, looking closer, it doesn't quite work in this situation because of the existential types involved
15:58:24 <koz_> jle`: I think in retrospect, I need to rename 'getDSM' to something more appropriate to how it's called.
15:58:38 <jle`> yeah, withDSM is consistent with a lot of places i've seen
15:58:57 <koz_> Yeah, because it's similar to the functions that auto-close files and suchlike.
16:00:11 --- mode: glguy set +v mmckeaveney
16:01:28 <benzrf> withDSM5
16:01:59 <lyxia> s/with/B/
16:02:29 <benzrf> O:
16:03:50 <jle`> D:
16:05:55 <koz_> Lol, DSM = DataSetMeta in my case. The pun was very much unintended.
16:06:10 <koz_> Also jle`: I think I'm gonna have pseudo-ContT IO inside pseudo-ContT IO.
16:06:20 <koz_> I'm feeling like a dependently typed Xzibit meme right now.
16:06:45 <koz_> Well, pseudo-ContT inside pseudo-ContT IO, but yeah.
16:07:32 <hpc> yo dawg i put a categorical dual in your categorical dual so you can while you
16:07:45 <koz_> hpc: Lol.
16:07:56 <koz_> You mean while you 'cocan' right?
16:08:16 <hpc> duals cancel out
16:08:24 <koz_> Makes sense.
16:08:24 <shachaf> Not 1-duals and 2-duals
16:09:16 <hpc> fun fact, they call it co-ding because you use mo-duals
16:09:33 <benzrf> booooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo
16:09:48 <koz_> hpc: That actually made me laugh.
16:09:49 <hpc> benzrf: <3
16:09:51 <koz_> Well done.
16:28:48 <zenspider> I've got hlint suggesting I refactor some code that's using the state monad and I have no idea how. https://gist.github.com/f7c4936d7bfcd99ae486a0f2fc1b2259 I took a whack at it and reduced the code some, but the get/put is still outside. I didn't really get how to get the types to match up properly to include get/put (starting lines 39-41 vs lines 43-45)
16:29:17 <zenspider> even just a type signature would (probably?) be enough of a hint
16:31:37 <lyxia> what do you mean by "refactor with state"
16:32:00 <lyxia> do you mean that the two clauses are repetitive
16:32:29 <zenspider> yes, the two clauses are repetitive... but they need to work w/ do/get/put ... not sure how to refactor that
16:33:19 <zenspider> right now I've got: idx <- get; let (m, idx') = renumber v idx; put idx' ... but it is still saying I should refactor. I'd love to know how.
16:33:35 <shachaf> Do you mean something like "helper t = do { idx <- get; ...; case t of { Leaf ... -> ...; Fork ... -> ...; }"?
16:33:50 <lyxia> almost, because the three lines refer to v inside Leaf and Fork
16:33:52 <shachaf> If you're asking about what hlint is suggesting, you should say what it's actually saying.
16:34:35 <lyxia> zenspider: you can refactor the three lines into a function
16:34:37 <zenspider> "Reduce duplication" on those 3 lines and pointing at duplicate section in Fork
16:35:10 <zenspider> lyxia: how? How do I push the state monad context down to the function (probably totally the wrong words)
16:35:39 <zenspider> right now I've got: renumber v l = (fromMaybe (length l) (elemIndex v l), if v `elem` l then l else l ++ [v])
16:35:43 <zenspider> all the middle bits, essentially
16:36:29 <zenspider> and since I need `v`, `modify` doesn't seem like a workable avenue?
16:37:05 <lyxia> zenspider: Take a look at my comment on the gist
16:38:18 <shachaf> You probably don't want to be doing things like (idx ++ [v]), or length for that matter.
16:38:18 <zenspider> I *swear* I tried that
16:38:32 <zenspider> probably not... but getting it working is my first step. :P 
16:38:57 <lyxia> another way to make the code more uniform is to rewrite the Tree type so the "a" is outside the sum.
16:39:03 <shachaf> Is the goal to label each node in the tree with its index in a pre-order traversal?
16:39:10 <zenspider> No really... I DID try that... but I was trying to put a type signature on it and probably got that totally screwed up
16:39:48 <lyxia> data Branch a = Leaf | Fork (Tree a) (Tree a)     data Tree a = Tree a (Branch a)
16:40:08 <shachaf> Oh, no, it's comparing elements too.
16:40:11 <zenspider> what's the type on helper' ? 
16:40:37 <lyxia> zenspider: maybe GHC will infer it if you put a hole-signature on top    helper' :: _
16:40:49 <lyxia> I mean it will tell you what it infers
16:40:59 <zenspider> ah. I didn't realize that I could do the hole trick in types
16:41:42 <zenspider> mostly inferred. I had to add classes: helper' :: (Eq a, Monad m) => a -> StateT [a] m Int
16:42:07 <zenspider> that helps a lot. thank you.
16:42:24 <lyxia> hmm, maybe   helper' :: _ => _   works better?
16:42:40 <lyxia> you're welcome
16:43:22 <shachaf> Possibly a nice way to write this would be to write a "traverse" function that works in the order you want to traverse the tree.
16:43:38 <zenspider> ooh. that does work better
16:43:47 <shachaf> yourTraverse :: Applicative f => (a -> f b) -> Tree a -> f (Tree b)
16:44:03 <shachaf> Then you can traverse with your state function which just needs to do the thing you want.
16:45:24 <zenspider> yeah. baby steps. I'm working through hutton. traversals are next on my list after I dig deeper on state
16:46:02 <shachaf> Aha.
16:46:05 <shachaf> Then I won't spoil it for you.
16:46:33 <zenspider> mmmm... brain glue wise... how does the helper-level state push down to helper'-level state?
16:47:34 <zenspider> also, I manually expanded one of these state monad examples to AAAALLL the code so I could draw lines and see how everything flows through. That was rough. Is there any tooling anywhere that'll "macro expand", so to speak?
16:47:45 <zenspider> rough... but really helped
16:47:52 <zenspider> I feel like I'm getting this now
16:48:02 <dmwit> I think there is nothing more helpful than expanding State manually a few hundred times.
16:48:11 <zenspider> haha. kk
16:48:17 <shachaf> I don't think a hundred times is necessary.
16:48:27 <zenspider> I'll need to start printing sideways 
16:48:27 <dmwit> As for "how does the helper-level state push down to helper'-level state", well... just expand it manually and you'll see. =)
16:48:46 <zenspider> I anticipated that. hence my second question 
16:48:47 <dmwit> shachaf: Me neither. Is just for drama.
16:51:22 <dmwit> I think there was one web-based Haskell step-evaluator floating around, but I can't find it now.
16:51:42 <lyxia> zenspider: the refactoring process here is entirely syntactic, the three lines are the same, so you give them a name and replace them.
16:51:43 <dmwit> It also wasn't full Haskell, and I don't remember whether it covered enough of Haskell to be helpful to you.
16:52:09 <dmwit> lyxia: Actually there's one application of a Monad law.
16:52:17 <dmwit> If we're talking about the refactoring I think we are.
16:52:58 <lyxia> hm, fair enough.
16:53:00 <dmwit> s/one/at least one/
16:54:29 <shachaf> The "helper" you'd probably really want here is :: Eq a => a -> State [a] (a, Int)
16:54:36 <shachaf> Which is what the traversal would take.
16:56:25 * dmwit . o O ( Tree a -> State (Bimap a Int) (Tree Int) )
16:57:07 <dmwit> Okay, okay, twist my arm and I'll throw in an `Ord a` constraint absolutely free, no strings attached.
16:57:22 <shachaf> Well, yes.
16:57:37 <shachaf> (Why Bimap?)
16:57:52 <dmwit> shachaf: So you can recover which `a`s are in the Tree afterwards if you want.
16:58:25 <shachaf> Maybe as a helper for a different function.
16:59:22 <dmwit> (Well, what I said motivates the `Map Int a` part. And having to look up previously-created `Int`s motivates the `Map a Int` part.)
17:14:30 <zenspider> I just did the Map version. I don't know Bimap
17:15:09 <zenspider> tho I did `Map a Int` ? seems arbitrary for this
17:15:34 <shachaf> Map a Int is what you need, because you're looking up indices of previously seen "a"s.
17:15:42 <zenspider> yup
17:15:52 <zenspider> but if it is a Bimap...
17:16:11 <shachaf> Bimap lets you look up in both directions, I guess? You're not using that.
17:25:07 <dmwit> If you build a `Tree (a, Int)`, a `Map Int a` isn't useful to you.
17:25:32 <dmwit> But if you build a `Tree Int`, and later wonder, "which `a` did that `Int` I see in this branch correspond to?", it might be nice to have a `Map Int a` lying around to help you answer that question.
17:25:57 <dmwit> zenspider: ^
17:26:09 <shachaf> dmwit: Hang on, hang on, "throw in" an `Ord a` constraint?
17:26:17 <shachaf> More like demand an extra `Ord a` constraint from us.
17:26:23 <shachaf> I know your tricks.
17:27:32 <dmwit> Dang, can't sneak anything by you!
17:31:57 <clever> ive got some haskell code that i suspect is either blocking or wasting cpu cycles due to conflicts over an atomic resource, and ive already compiled all libraries with profiling enabled, what should i check next?
17:32:26 <clever> it consumes all 8 cores of the cpu when running, and the unit tests take almost an hour when `+RTS -p` is active
17:32:38 <clever> and its still painfully slow without profiling
17:41:43 --- mode: glguy set +v cmsmcq
17:41:57 --- mode: glguy set -v cmsmcq
17:53:02 <dmwit> ooo, BlockArguments
18:11:32 <davr0s> <$> ... is written to look like $ but in the monad ?  'functoin $ arg'   'function <$> modic_arg
18:14:48 <pavonia> It originally came from Applicative, I think, but now is generalized to Functor
18:15:38 <davr0s> specific question:-  so i was working through rolling a parser myself (figuring out for myself how to write suhc a thing in haskell)
18:15:44 <davr0s> and i ended up doing this:-
18:17:15 <davr0s>      try_to_parse_foo Input -> Maybe (Result,Input)   .. and i chained some together with a function i rolled called "orElse" ,    e.g.   (parseFoo `orElse`   parseBar `orElse` parseBaz )  theInput
18:17:42 <davr0s> .. orElse  basically calls the left and if it fails tries the right
18:18:08 <davr0s> once it gets to one that suceeds it stops and passes it along instead of calling the rest
18:18:31 <davr0s> ... is there a thing like that ?    it reminds me a bit of  a chain of ? : ? : stuff in C
18:20:12 <pavonia> That's what (<|>) does
18:20:23 <geekosaur> <$> is just infix fmap, and can e thought of as ($) "lifted" into a Functor
18:20:34 <davr0s> ok i figured that might be the case.  i guess that really does read 'OR..'
18:20:44 <davr0s> like the | in grammars etc
18:22:22 <pavonia> Note that some parsers require an explicit "try" combinator for getting backtracking right, e.g. "try foo <|> try bar <|> baz" if all three parsers can accept common prefixes
18:23:22 <davr0s> ok i will read a bit now .. i wanted to see how much i could discover for myself
18:52:04 <NemesisD> any dhall users here? i'm having a hard time figuring how you'd creating a sum type like data Foo = Bar | Baz and having it be actually usable
20:37:47 <koz_> :t bimap join
20:37:49 <lambdabot> (Monad m, Bifunctor p) => (c -> d) -> p (m (m a)) c -> p (m a) d
20:38:13 <koz_> dmwit: What was that trick with bimap you showed me to implement the equivalent of both?
20:41:21 --- mode: glguy set +v Poi
20:43:32 <geekosaur> :t join bimap -- ?
20:43:33 <lambdabot> Bifunctor p => (c -> d) -> p c c -> p d d
20:43:45 <koz_> Oh yeah, that was it. Thank you geekosaur!
20:45:46 <koz_> I might have to grab my whiteboard and GHCi and derive that one from first principles later so I remember it.
20:49:16 <sleepster> are there any notable projects that use Haskell?
20:49:48 <koz_> :t maybe
20:49:50 <lambdabot> b -> (a -> b) -> Maybe a -> b
20:49:52 <sleepster> like large commercial projects
20:49:52 <koz_> (that wasn't a pun)
20:49:55 <sleepster> hah
20:50:04 <geekosaur> looks to me like straightforward join in ((->) e)
20:50:29 <koz_> sleepster: Check this: http://www.stephendiehl.com/posts/haskell_2018.html#industry
20:50:44 <sleepster> thanks koz_ 
20:50:52 <koz_> I'm pretty sure _one_ of these organizations uses Haskell for something 'large' and 'commercial'.
20:51:49 <sleepster> I'd imagine a company as large as Google or Amazon must have a few projects
20:51:50 <sleepster> as well
20:53:41 <geekosaur> google tends to build its own languages instead (dart, go)
20:53:56 <geekosaur> there's such a thing as "too big" here
21:01:18 <hololeap> :t join :: (a -> a -> b) -> (a -> b)
21:01:19 <lambdabot> (a -> a -> b) -> a -> b
21:01:36 <koz_> Uhh.
21:01:46 <geekosaur> % :t join @((->) _)
21:01:46 <yahb> geekosaur: (w -> w -> a) -> w -> a
21:01:54 <koz_> geekosaur: Beat me to it.
21:03:17 <geekosaur> so "jin bimap" pops the following function into both function slots of "bimap"
21:03:27 <geekosaur> *"join bimap"
21:03:49 <hololeap> :t join :: Bifunctor p => ((a -> b) -> (a -> b) -> (p a a -> p b b)) -> ((a -> b) -> (p a a -> p b b))
21:03:50 <lambdabot> Bifunctor p => ((a -> b) -> (a -> b) -> p a a -> p b b) -> (a -> b) -> p a a -> p b b
21:04:26 <koz_> :t foldM
21:04:27 <lambdabot> (Monad m, Foldable t) => (b -> a -> m b) -> b -> t a -> m b
21:05:29 <koz_> What's the derived instance of Ord for pairs do for (<=) ?
21:05:39 <mniip> lexicographical
21:05:50 <koz_> mniip: Ah, OK.
21:06:00 <mniip> (a, b) `compare` (c, d) = a `compare` c <> b `compare` d
21:06:03 <koz_> :t False <= True
21:06:05 <lambdabot> Bool
21:06:09 <koz_> Whoops, lol.
21:06:12 <koz_> > False <= True
21:06:15 <lambdabot>  True
21:06:56 <mniip> keep in mind that the Ord instance for strings is actually derived
21:07:08 <koz_> mniip: Is it the same as for [] then?
21:07:23 <mniip> [] comes before :
21:07:27 <mniip> head has precedence over tail
21:08:01 <koz_> mniip: I meant [a] for any a with an Ord instance.
21:08:08 <mniip> that's what I said
21:08:16 <koz_> Oh, right, my bad.
21:08:26 <mniip> > compare [] (undefined : undefined)
21:08:28 <lambdabot>  LT
21:08:37 <mniip> > compare (1 : undefined) (2 : undefined)
21:08:39 <lambdabot>  LT
22:06:51 <jle`> > minimum [[], undefined, undefined, undefined]
22:06:53 <lambdabot>  *Exception: Prelude.undefined
22:07:12 <jle`> oops
22:18:39 <jle`> > minimum [[], undefined:undefined, undefined:undefined, undefined:undefined]
22:18:41 <lambdabot>  []
22:55:18 <koz_> Is it standard operating practice to demonstrate anything with maximum laziness?
22:59:55 <benzrf> lol not really i don't think
23:00:14 <koz_> benzrf: I guess it's just fun to stick undefined in as many places as possible.
23:00:18 <benzrf> hehe
23:04:37 <mniip> I greatly restricted the possible implementations of that function by demonstrating its non-strictness
23:12:02 --- mode: glguy set +v codyw_
23:13:06 <codyw_> "Learn Haskell" has been on my TODO.md for about 1.7 years now. I should change this
23:16:12 <tdammers> codyw_: the best moment to tackle things like these is always "right now"
23:19:29 <maerwald> make sure you have a lot of time on your hands... pausing it for a week or two will throw you back to zero
23:31:11 <tdammers> not pausing will do the same though ;)
23:35:58 <koz_> Suppose I have a value of type 'Foo (n :: Nat)' in scope, and I wanna print what 'n' is. How would I do that?
23:39:11 <dminuoso> So say I have a `ReaderT Env IO` stack, and I happen to have a library that relies a lot on `Env -> IO`, is there a way to make this *just work* without wrapping each binding in the API?
23:42:43 <jle`> koz_: you can't know with just that alone, because of type erasure
23:42:52 <c_wraith> dminuoso: how awful is it?  I mean, that's just the type of ReaderT
23:42:56 <c_wraith> :t ReaderT
23:42:57 <lambdabot> forall k r (m :: k -> *) (a :: k). (r -> m a) -> ReaderT r m a
23:43:02 <koz_> jle`: In my case, I figured out how to do it, because it happens to be a Vector.Sized.Vector.
23:43:03 <jle`> dminuoso: what is Env -> IO ?
23:43:10 <jle`> koz_: nice :)
23:43:33 <koz_> Now I have to figure out one bug, and then I have a dependently typed implementation of the Gamberger-Lavrac feature construction algorithm.
23:43:36 <koz_> FINALLY.
23:45:10 <codyw_> maerwald: that's why it finds its way back onto the list :(
23:45:44 <c_wraith> dminuoso: I guess..  there's just a newtype between them.  How do you feel about coerce?  Admittedly, that's not really any advantage over using ReaderT and runReaderT to convert.
23:47:25 <dminuoso> jle`: Honestly I do not understand what you are asking for.
23:47:41 <c_wraith> dminuoso: well, you left an a out of both types
23:47:50 <c_wraith> dminuoso: I think jle wants to make sure that's what you meant.
23:48:40 <dminuoso> c_wraith: Huh? You lost me.
23:48:51 <dminuoso> I had only 2 hours of sleep. but I dont think I made a mistake there?
23:49:04 <dminuoso> Oh.
23:49:06 <c_wraith> I think you meant ReaderT Env IO a and Env -> IO a
23:49:36 <dminuoso> c_wraith: Heh yeah.
23:50:10 <dminuoso> Apparently network folks have "beerings" every now and then, yesterday I went with them. Heh.
23:50:31 <c_wraith> dminuoso: there's also stuff like Control.Lens.Wrapped for dealing with unwrapping and rewrapping.
23:50:39 <c_wraith> (yes, it has an instance for ReaderT)
