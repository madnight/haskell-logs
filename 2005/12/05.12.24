00:01:17 <benny> oh well for now i copied all the yampa source files into my project directory. i will link directcly with them :)
00:36:26 <benny> @seen Lemmih
00:36:27 <lambdabot> Lemmih is in #haskell-blah and #haskell. Last spoke 2 hours, 23 minutes
00:36:27 <lambdabot> and 42 seconds ago.
00:37:26 <Lemmih> Hi.
00:40:53 <benny> Lemmih: hey!
00:41:34 <benny> Lemmih: when i try to compile a SDL program i get a bunch of undefined references!
00:43:13 <Lemmih> benny: Oh, using Mac or Windows?
00:43:38 <sieni> Laeta Saturnalia!
00:44:15 <benny> Lemmih: linux
00:44:36 <benny> Lemmih: it works when i use runhaskell x.hs, but not when i do ghc x.hs
00:45:03 <Lemmih> benny: You need '-package SDL'.
00:45:46 <benny> when i do that i get a strange error:
00:45:59 <Lemmih> (my binding is known to be broken on Mac and Windows which is why I asked, btw)
00:46:02 <benny> gcc: unrecognized option '-rpath'
00:46:13 <benny> /usr/lib: file not recognized: Is a directory
00:46:24 <benny> collect2: ld returned 1 exit status
00:47:39 <Lemmih> sdl-config is being evil /-:
00:48:33 <sieni> Hmm... I wonder if they should name one of the two new moons of Uranus "Haskell", since it already has moons called "Oberon" and "Miranda"
00:48:35 <benny> hm... you are right, sdl-config --libs has some -rpath shit in it
00:49:02 <Lemmih> benny: http://www.haskell.org/pipermail/haskell-cafe/2005-July/010769.html
00:49:37 <Lemmih> benny: The 'solution': Remove -rpath from your package.conf manually.
00:49:56 <benny> do you happen to know what -rpath means anyway?
00:51:44 <Lemmih> It tells the dynamic linker where to look.
00:56:04 <benny> yay it works :D thanks man
00:58:57 <benny> too bad it takes forever to link hello world :'(
01:11:00 <Lemmih> benny: With GHCi you only have to link once.
01:32:26 <gour> dons: ping
01:37:48 <skew> It seems STM is not very good at pretending to be select
01:38:36 <benny> hm... anyone familiar with HOpenGL?
01:39:41 <Saulzar> I've been using it
01:40:50 <benny> there's no way to use it the old fashioned way glBegin...glVertex...glEnd?
01:41:11 <Saulzar> Erm - you can
01:41:58 <boegel|home> benny: a bit
01:42:18 <skew> I have one thread waiting on a bunch of empty TMVars, and another thread that puts increasing values into the last of the TMVars
01:42:26 <Saulzar> renderPrimitive Points $ do { vertex (Vertex2 0 0); vertex (Vertex2 1 0) }
01:42:26 <boegel|home> but I'm not too familair with it, it's been ages since I've used it
01:43:12 <skew> joining the waits with foldr1 orElse seems to take n^2 time to complete 100 rounds, building a balanced tree seems to take n sqrt(n) time
01:43:23 <Saulzar> They've gotten rid of the explicit begin-end and replaced it with something which takes an action (which it wraps in begin/end)
01:43:47 <benny> Saulzar: yeah, i'm wondering if it's still possible to use explicit
01:44:04 <Saulzar> Why would you want to?
01:45:12 * araujo hopes this quoted-expressions support to hashell behaves correctly.
01:45:35 <Saulzar> (I think that is the only way for the vertex-by-vertex method)
01:49:33 <benny> Saulzar: can be useful sometimes... more importantly though, does HOpenGL support opengl extensions? VBO is needed
02:08:30 <Saulzar> benny, I think so - at least the API seems to, I have not tested it :)
02:11:30 <Saulzar> I'm just using it for 2D sprites
02:16:31 <Saulzar> Seems to be various routines for reading/writing buffer objects - not sure how you'd use them, maybe the same way as with C... pass a null pointer as the array pointer!
02:18:18 <Saulzar> That has always seemed quite an unsatisfactory arrangement to me - reusing a pointer for an array index depending if you are using arrays or VBO's ..
02:53:52 <benny> Saulzar: yeah... it's been a while since i did VBO programming but i remember it having a strange api :)
03:01:54 <Saulzar> I wonder if you can even do something screwy like set a pointer to an integer value easily in haskell...
03:04:10 <Saulzar> nullPtr `plusPtr` I suppose :)
03:29:42 <joelr1> howdy folks
03:29:50 <joelr1> musasabi: do you have a wrapper around kqueue?
04:31:35 <dsacode> Is it possible to convert digit of type Integer to Char ? Like 3 -> '3'
04:32:19 <araujo> Good morning!
04:32:21 <araujo> Haskell Christmas for everyone!
04:33:45 <Saulzar> ... and a Monad new year? Oh dear :)
04:34:38 <Saulzar> dsacode, Heh, as it happens there looks like a routine to that exactly ..  Data.Char.intToDigit
04:34:43 <Saulzar> > intToDigit 5
04:34:45 <lambdabot> '5'
04:35:14 <Saulzar> dsacode, Though I was going to suggest you could just find out where 0 started and add...
04:36:04 <Saulzar> > chr $ (ord '0') + 5
04:36:06 <lambdabot> '5'
04:38:17 <cinema> head . show
04:41:13 <cinema> > head . show $ 5
04:41:15 <lambdabot> '5'
05:09:07 <benny> is there a way in a case to have 2 different pattern matches have the same result, without copy and pasting the result and without using a let or where?
05:11:59 <ski> not in haskell
05:12:13 <benny> ok, i guess using a where isn't that bad
05:12:21 <ski> OCaml (and SML/NJ ??) has 'or-patterns' for that
05:12:47 <benny> want to hear something cool?
05:13:14 <ski> sure
05:13:33 <benny> i just got yampa working with sdl and opengl :D
05:13:48 <ski> nice
05:14:14 <benny> hopefully soon i'll have a sphere moving to the beat of a sin wave :]
05:28:46 <benny> i have a Word32 value, how can i convert it to a double so that: 5 -> 0.005, 1000 -> 1.0, 200 -> 0.2, etc... ?
05:29:58 <benny> @hoogle Double
05:29:59 <lambdabot> GHC.Exts.Double :: Double
05:29:59 <lambdabot> Prelude.Double :: Double
05:29:59 <lambdabot> Text.PrettyPrint.HughesPJ.double :: Double -> Doc
05:30:09 <benny> @hoogle toDouble
05:30:10 <lambdabot> No matches found
05:32:47 <benny> argh i miss c with it's automatic numeric casting :P
05:34:29 <ski> Int to Double ?
05:34:59 <benny> alright i got this: (fromInteger (toInteger (5 :: Word32))) / 1000
05:35:01 <xerox> @type fromIntegral
05:35:02 <lambdabot> forall b a. (Num b, Integral a) => a -> b
05:35:14 <benny> > (fromInteger (toInteger (5 :: Word32))) / 1000
05:35:15 <lambdabot> 5.0e-3
05:35:55 <ski> > fromIntegral (5 :: Word32) :: Double
05:35:57 <lambdabot> 5.0
05:36:05 <ski> > fromIntegral (5 :: Word32) / 1000 :: Double
05:36:07 <lambdabot> 5.0e-3
05:36:26 <benny> ah, a little better thanks :)
05:36:39 <xerox> :)
05:36:42 <ski> > fromIntegral 5 / 1000
05:36:44 <lambdabot> 5.0e-3
05:50:52 <zagrius> How can I write an efficient version of the following? foldr (\e r->"127.0.0.1 " ++ e ++ "\n" ++ r) ""
05:51:12 <zagrius> This one has quadratic complexity.
05:58:12 <ski> hm, it has ?
06:00:00 <zagrius> ski: without a Sufficient Smart Compiler, yes. 
06:00:20 <ski> it seems to me that will walk through each 'e' once
06:01:19 <zagrius> ski: yes, but ++ is lineair. 
06:01:34 <benny> SHAWEEET!
06:01:35 <zagrius> ski: and that gets called a lineair number of times.
06:01:58 <ski> so, it's linear in size of all 'e' together, i think
06:03:02 <zagrius> ski: I know it's complexity. It's O(n^2). There's no need for discussion. I just want to know how to get it to lineair complexity without throwing away the fold.
06:03:28 <ski> O(n^2) where 'n' is what ?
06:03:41 <joelr1> musasabi: ping
06:05:04 <zagrius> ski: the length of the input ofcourse.
06:05:06 <ski> if 'n' is number of 'e's, then it's linear .. if 'n' is size of all 'e's, taken together, then it's also linear
06:05:26 <zagrius> ski: It's a curried function. 
06:07:57 <ski> foldr (\e r->"127.0.0.1 " ++ e ++ "\n" ++ r) "" [e0,e1,e2]  =  "127.0.0.1 " ++ (e0 ++ ("\n" ++ ("127.0.0.1 " ++ (e1 ++ ("\n" ++ ("127.0.0.1 " ++ (e2 ++ ("\n" ++ ""))))))))
06:08:31 <zagrius> ski: and ++ takes lineair time each time. 
06:08:47 <zagrius> ski: So, it has a total of O(n^2). 
06:08:48 <ski> yes, linear *in*each*'e'*
06:09:09 <zagrius> ski: and that's a plain ridiculous algorithm. 
06:09:11 <ski> so, total is linear *in*all*the*'e's*together*
06:09:29 <zagrius> ski: no
06:10:07 <zagrius> ski: I have multiple e's ofcourse.
06:10:42 <zagrius> ski: ["addadad","bdasdas","cgffgfg"] could be an input.
06:11:01 <ski> say 'e0' has length 'n0', and 'e1' has length 'n1' and 'e2' has length 'n2', then that fold above calls '(++)' one time for each 'e', and so those calls take time proportional to 'n' = 'n0+n1+n2'
06:11:23 <ski> > length . concat $ ["addadad","bdasdas","cgffgfg"]
06:11:25 <lambdabot> 21
06:11:32 <ski> so, 21 steps here
06:11:58 <zagrius> ski: One call to ++ takes lineair time, ok?
06:12:05 <ski> yes
06:12:07 <zagrius> lineair in 21.
06:12:11 <ski> no
06:12:33 <ski> > map length ["addadad","bdasdas","cgffgfg"]
06:12:35 <lambdabot> [7,7,7]
06:12:40 <ski> > sum $ map length ["addadad","bdasdas","cgffgfg"]
06:12:42 <lambdabot> 21
06:12:57 <xs> (doesn't also depend upon which argument ++ does pattern matching on?)
06:13:14 <ski> first '(++)' call takes time proportional to size of left arg, which here is 7
06:13:38 <ski> ('(++)' patternmatches on first arg)
06:13:54 <benny> i have yampa working in an sdl app using opengl for rendering!
06:14:36 <katafutr> hello
06:14:42 <katafutr> I've got a small question
06:15:02 <Cale> cool, what's the question
06:15:09 <ski> zagrius : it is true that you can often get O(n^2) complexity with '(++)' .. but i think this isn't such a case
06:15:10 <Cale> (Good morning all!)
06:15:17 <katafutr> let's say I've got a list of integers, for example [1, 6, 8, 1, 2]
06:15:36 <xs> Cale: thanks for the answer yesterday. it worked, but then my computer died.
06:15:48 <Cale> You can only get n^2 complexity if you use (++) repeatedly to build a list by appending one element to the end a bunch of times.
06:16:05 <Cale> (or short bits)
06:16:13 <ski> s/appending one element/appending/
06:16:23 <Cale> yeah
06:16:37 <zagrius> ski: you are right
06:16:48 <Cale> But if you append long segments, the constant factor makes it irrelevant :)
06:16:55 <katafutr> I want to find a list, where on n-th position there's a number telling how often number n occurs in the first list
06:17:15 <zagrius> ski: but still I'd like a more efficient algorithm, i.w. one without ++.
06:17:26 <Cale> > filter (==1) [1,6,8,1,2]
06:17:28 <lambdabot> [1,1]
06:17:54 <ski> zagrius : i'm not sure there is a better algo, if you start with a list of strings ..
06:18:00 <katafutr> I'd like to do this as efficiently as possible
06:18:23 <zagrius> ski: In an imperative language, there is. 
06:19:07 <katafutr> is there a better way than to sort the input first, and then do the rest (I think the whole thing should be nlogn - sorting is the limit)
06:19:16 <ski> katafutr : how about negative numbers ? .. also, should the result list be infinite, or do you want to crop it when the rest elements all are 0 ?
06:19:47 <ski> zagrius : with linked lists ?
06:20:00 <Cale> actually, zagrius, you're appending to the beginning, no?
06:20:12 <ski> Cale : he is
06:20:33 <katafutr> no negative numbers, and the list can be of any kind - but the maximum number in the input is know up front
06:20:38 <xs> "\n" at the end though.
06:20:44 <katafutr> the list can be of any kind -> output list
06:21:53 <Cale> > (group . sort) [1, 6, 8, 1, 2]
06:21:54 <lambdabot> [[1,1],[2],[6],[8]]
06:22:13 <Cale> > (map length .group . sort) [1, 6, 8, 1, 2]
06:22:15 <lambdabot> [2,1,1,1]
06:22:34 <Cale> do you want additional 0's if there are missing elements?
06:22:50 <katafutr> yes
06:22:58 <zagrius> ski: yes
06:23:45 <zagrius> ski: since a String is [Char], I can imagine that it should be possible to do the same algorithm in Haskell.
06:24:21 <zagrius> ski: I know one with a fold followed by some post-processing.
06:24:31 <Cale> zagrius: I think you won't see quadratic complexity here
06:24:43 <zagrius> Cale: no, I am convinced.
06:24:55 <zagrius> Cale: but I still would like to avoid the (++)
06:25:14 <Cale> You only have a constant amount of work to do due to appends for each element in the list, so it'll be linear.
06:26:10 <zagrius> Cale: yes, it's lineair, but it still does unnecessary work.
06:26:18 <Cale> Well, how so?
06:26:30 <Cale> It can't be constant time.
06:27:23 <Cale> are you actually finding it slow?
06:27:39 <Cale> or are you optimising prematurely?
06:27:54 <zagrius> The 127.0.0.1 in done twice. 
06:28:21 <Cale> no, it'll be shared
06:28:48 <Cale> i.e. the Chars will only get evaluated once
06:29:19 <zagrius> Why will it be shared? There was something with lazy evaluation, pureness and sharing. 
06:29:23 <Cale> though there will of course be some building of list structure every time one of those comes along, and there's nothing that can be done about that
06:29:46 <Cale> (you have to distinguish the cells from one another)
06:30:14 <Cale> Well, it'll be shared because those Chars came from the same string in the first place
06:30:29 <Cale> remember that a list is really a linked list of pointers to thunks
06:30:55 <zagrius> I completed the STG paper, btw.
06:31:02 <Cale> right
06:31:10 <zagrius> This time I could actually read it.
06:31:13 <Cale> :)
06:31:33 <zagrius> Do you know a paper which explains sharing properties?
06:31:45 <Cale> well, that paper does imply sharing properties
06:32:15 <Cale> but basically, things are shared if came from the same variable in the code
06:32:41 <Cale> here, in  foldr (\e r->"127.0.0.1 " ++ e ++ "\n" ++ r) ""
06:32:42 <zagrius> Sharing is just that one value is stored once, and that other merely have a pointer to it?
06:32:53 <Cale> there's only one "127.0.0.1 " in the code
06:33:10 <Cale> and so that list of chars will only get evaluated once
06:33:24 <ski> ('(++)' will copy that list, though)
06:33:41 <ski> (i.e. the skeleton)
06:33:42 <Cale> It'll copy the pointers to what are actually Chars
06:33:43 <Cale> yeah
06:34:00 <Cale> It'll only copy the conses
06:34:13 <zagrius> ++ will copy one pointer for each 127.0.0.1?
06:34:15 <Cale> (with some modification)
06:34:29 <benny> i need an idea for a simple yampa opengl demo
06:34:30 <zagrius> That's pretty neat. 
06:34:45 <Cale> well, it has to build a bunch of new (:)'s for each
06:34:57 <Cale> which is what we mean by copying
06:35:06 <Cale> but they are actually different in each case
06:35:53 <Cale> however, it does this work lazily, so you don't see it up front.
06:36:22 <zagrius> Cale: oh, you mean the building of it, yes, of course that should happen. 
06:36:40 <Cale> right
06:36:53 <zagrius> Cale: Unless I would never need 127.0.0.1 somewhere in my output.
06:36:57 <Cale> and those (:)'s just point to the same old Chars that were in the original list
06:37:02 <Cale> right
06:38:16 <zagrius> Cale: The x in x (:) xs is a pointer? 
06:38:41 <Cale> yes, every variable in Haskell is effectively a pointer
06:38:57 <Cale> btw (x : xs) or (:) x xs
06:39:06 <zagrius> Cale: yes, I know. 
06:39:28 <zagrius> Cale: I was too lazy to correct it.
06:39:32 <Cale> :)
06:39:35 <zagrius> pun intended
06:39:39 <Cale> hehe
06:40:50 <zagrius> The paper also states that since lazyness is implemented "cheaplu", and the syntax supports it (as are higher order functions), they also get used. 
06:40:58 <zagrius> *cheaply
06:41:21 <zagrius> That was the most important observation imho.
06:41:45 <zagrius> The same with multiple recursive functions.
06:42:31 <Cale> yeah, laziness is an important optimisation for the style of Haskell programming, so you want it to work well :)
06:42:38 <zagrius> In Lisp you have to do (labels (a bunch of multiple recursive functions)). It just takes time to decide that you want such a function. 
06:43:04 <zagrius> And in Lisp the compiler does not think for you, you have to tell it to the compiler.
06:43:50 <zagrius> And since the lazy and strict semantics are "the same"(in that a strict version will also work correctly when evaluated lazily) it buys you time. 
06:44:11 <zagrius> But Joel (on the mailing lists) has a hard time getting decent performance.
06:45:07 <zagrius> But maybe indeed his algorithms are flakey. Still I think real world usage is the best test for a language. 
06:45:20 <Cale> Joel is doing a lot :)
06:45:36 <Cale> His program spawns thousands of threads
06:45:55 <Cale> which all have a limited amount of time to do their work
06:46:10 <Cale> and I really think he should be doing *some* locking there :)
06:46:29 <xs> stm?
06:47:31 <Cale> Well, he's using STM to some extent. I haven't looked too carefully.
06:47:38 <zagrius> xs: stm was slow, IIRC. 
06:48:40 <Cale> Really all his problems come from the fact that he's doing some pretty complex things already, and that the scheduler isn't quite fair when you get up to that number of threads
06:49:02 <zagrius> Cale: what scheduler? OS, or GHC?
06:49:53 <Cale> GHC. forkOS seemed to work better, but triggered some runtime system bug after a while.
06:51:35 <zagrius> Cale: do they intend to fix that bug? Or is it reported? These things can be show stoppers.
06:51:54 <Cale> Yeah, I'm pretty sure
06:52:14 <Cale> I hope someone's put the beautiful test case in Trac :)
06:52:22 <Cale> It's completely repeatable
06:52:28 <Cale> so it should be possible to fix
06:52:43 <Cale> (on 3 platforms even!)
06:52:51 <xerox> ciao :-D
06:53:00 <Cale> hi xerox 
06:53:35 <goron> ghc-cvs has been broken in Debian for 154 days...
06:55:09 <Cale> Anyway, for most user apps, I think GHC produces code which performs reasonably well. With server apps that need to handle thousands of transactions at a time, maybe not as well for the time being.
06:55:36 <zagrius> What about OpenGL/SDL/OpenAL games?
06:55:45 <Cale> Oh, it works okay for those
06:55:47 <benny> zagrius: i'm gonna find out soon enough :)
06:55:58 <Cale> There's frag, did you try that?
06:56:09 <zagrius> No
06:56:14 <Cale> It hasn't got terribly good gameplay yet
06:56:20 <Cale> but it's a decent proof of concept
06:56:28 <benny> what's that?
06:56:39 <Cale> It's an FPS game written in Haskell
06:56:54 <benny> i think i've seen it... do you remember the url?
06:56:54 <Cale> http://www.haskell.org/hawiki/Frag
06:57:04 <zagrius> Oh, I did see it.
06:57:13 <Cale> go there :)
06:57:54 <benny> yeah it looks awesome, but the question is, how much is done in the IO monad?
06:57:54 <Igloo> goron: Is one that mostly works for amd64 useful to you?
06:58:16 <goron> Igloo: no, I only have athlon-xp
06:58:28 <Cale> I expect not as much as is done in the Yampa arrows :)
06:58:30 <goron> Igloo: but you are the maintainer, so what's the problem?
06:58:45 <benny> Cale: interesting
06:59:17 <goron> Igloo: I also tried building GHC from CVS, but there's some bug in the Make file, since it doesn't terminate.
06:59:27 <Igloo> xmltex is broken, concurrency issues mean the testsuite doesn't finish in a sane time
06:59:42 <goron> Igloo: or there's some bug in my make, or I don't know.
07:00:18 <goron> Igloo: Can you build GHC from CVS?
07:00:27 <Igloo> I could on Dec 12
07:00:31 <Igloo> Haven't tried since
07:00:44 <Igloo> Dec 7, sorry
07:01:06 <benny> Cale: so you think yampa arrows could be used for a bigger, more complex game? things like save/load game, multiplayer, "scripting", physics... they can be extremely complex
07:01:13 <Igloo> But given it's built nightly by a number of people I'd be surprised if it'sbeen brken fora significant amount of time
07:01:16 <goron> Igloo: could you do an cvs up, and try again? Then I can see whether it's my system that's the problem.
07:01:38 <goron> Igloo: or do you have any suggestion of what I can do.
07:01:46 <Igloo> Debug it
07:01:56 <Cale> benny: It's conceptually reasonable
07:02:16 <goron> Igloo: I already ran it with make -d. 
07:02:20 <Igloo> You can check the cvs-ghc list for HEAD build reports to see if it's buildable
07:02:22 <Cale> benny: The neat thing is that arrows abstract things enough that you can do arbitrary amounts of optimisation behind the scenes
07:02:34 <goron> Igloo: It most definately was in a loop. 
07:02:35 <benny> Cale: yeah... that's what i find interesting
07:02:50 <goron> er definitely
07:02:50 <Igloo> Then work out why  :-)
07:03:27 <goron> Igloo: but since you say that it's unlikely that other people have the problem, it must be something else.
07:03:51 <goron> Igloo: so, if e.g. you can build it, I might better to a clean checkout.
07:04:05 <lisppaste2> joelr1 pasted "how do i read this?" at http://paste.lisp.org/display/14972
07:04:19 <Igloo> It could be because you have a different library, missing dependency or something though
07:04:21 <joelr1> folks, how do i read this function? i don't understand the two lets 
07:05:26 <goron> joelr1: it defines a function using a let inside a do block. 
07:05:40 <joelr1> and the function is eh?
07:05:48 <goron> joelr1: yes
07:05:54 <goron> joelr1: and a function printer
07:06:08 <goron> joelr1: that's valid Haskell syntax.
07:06:15 <joelr1> and the function is captured from the context?
07:06:18 <Cale> the second let is unnecessary, you could just replace those characters with spaces :)
07:06:42 <joelr1> Cale: which one is the 2nd let? and what do you replace with spaceD?
07:06:44 <joelr1> spaces
07:06:48 <joelr1> err
07:06:53 <joelr1> the let is captured
07:06:54 <goron> joelr1: the one before printer
07:06:54 <Cale> I'll annotate
07:06:56 <joelr1> damn
07:07:00 <joelr1> goron: the handle :D
07:07:16 <joelr1> goron: it builds a closure, right? and the closure captures "handle", right?
07:07:19 <lisppaste2> Cale annotated #14972 with "." at http://paste.lisp.org/display/14972#1
07:08:03 <joelr1> Cale: i see now
07:08:10 <joelr1> Cale: so am i right about the closure?
07:08:25 <Cale> what closure?
07:08:32 <Cale> oh
07:08:40 <joelr1> isn't eh a closure that captures "handle"?
07:08:40 <Cale> I wasn't reading at that point :)
07:08:55 <Cale> well, yes
07:09:10 <Cale> because handle occurs in its definition
07:09:11 <joelr1> ok, now i understand. a slight twist of mind and everything is clear :) 
07:09:20 <joelr1> goron: then you for adjusting my viewpoint 
07:09:35 <joelr1> has anyone done heavy-duty networking apps in haskell?
07:09:46 <joelr1> apart from musasabi who's not disclosing what he's doing ;)
07:10:23 <benny> do i have to do anything special to enable arrow syntax in ghc 6.4.1?
07:10:33 <joelr1> benny: -farrows?
07:10:46 * ski thinks 'eh' could be put in 'where'
07:11:00 <benny> joelr1: thanks
07:11:02 <Cale> yeah, -farrows
07:12:11 <benny> man, ghc really could use better error messages
07:12:18 <imix> hi, anyone willing to throw a quick glance at a program of min that behaves unexpectedly (at least to my meager haskell skill)?
07:12:23 <TuringTest> sure
07:13:42 <Cale> imix: yeah
07:13:56 <imix> It's at http://ste.aeschbacher.ch/temp/sudoku/. the program in question is sudoku_short.hs. The needed input file is sudoku.txt. (sudoku_short.hs is a stripped town verision of sudoku.hs which by itself works)
07:14:50 <imix> sudoku_short.hs (a sudoku solver) gives me: 'a.out: (Array.!): undefined array element' unless I uncomment one of the 3 commented lines (which to my understanding should not change anything)
07:15:43 * TuringTest starts reading it
07:15:50 <Guest35569> bleh @ sudoku solvers.
07:16:16 * TuringTest wrote two solvers
07:16:36 <Guest35569> yeah so did i
07:16:42 <Guest35569> but its more fun to do it manually
07:16:44 <imix> it's nothing facy at all, just a first attempt in haskell ;)
07:17:21 <lisppaste2> ski annotated #14972 with "where" at http://paste.lisp.org/display/14972#2
07:17:36 <TuringTest> imix: There are many array implementations and I have found that haskell requires that you explicitly type the array somewhere.
07:17:49 <TuringTest> (just a guess)
07:18:00 <Cale> TuringTest: It's just a standard Array
07:18:35 <Cale> (he hasn't imported IArray)
07:18:41 <goron> Igloo: make uses 99% CPU. 
07:18:51 <TuringTest> Cale: So I guessed wrong.
07:19:12 <goron> Igloo: so that has nothing(that I know of) to do with the things you mention.
07:19:55 <Igloo> goron: The things I mentioned can affect what configure does, and that affects what Makefiles make is given
07:20:26 <Cale> oh
07:20:29 <Cale> ha
07:20:32 <imix> yes?
07:20:36 <Cale> imix: don't hClose the file
07:20:44 <Cale> you're using getContents right?
07:20:52 <Cale> hGetContents, yeah
07:20:52 <imix> yes i do
07:21:26 <Cale> If you close the file before the string is used, any elements you look at will become undefined
07:21:28 <Cale> er
07:21:33 <Cale> you haven't looked at
07:21:47 <Cale> basically, don't mix hClose with hGetContents
07:21:47 <imix> not closing the file solves the problem :)
07:21:50 <Cale> yes
07:21:56 <goron> Igloo: in other words: my system triggers a bug in the configure script?
07:22:10 <Cale> reading the whole string will close the file anyway
07:22:32 <goron> Igloo: Since my definition of a good configure script is one that stops when something is missing, and reports that. 
07:22:44 <imix> and how does a print/trace influence the hGetContents? it uses another file descriptor i assume
07:22:56 <Cale> imix: it forces the file to be read
07:23:01 <goron> imix: There's a function Trace in GHC.
07:23:08 <goron> goron: er trace
07:23:13 <Cale> hGetContents does lazy IO
07:23:28 <Cale> it gives you a string which reads from disk when you need the elements
07:23:36 <Cale> as opposed to doing the reading right away
07:23:50 <Pupeno> Good morning.
07:23:52 <Cale> (which is handy if your file is a couple GB or something)
07:23:55 <TuringTest> Also, "solvedSudoku <- mySudoku `seq` solveSudoku mySudoku" forces it to be read
07:24:11 <imix> i see, thanks a lot :)
07:24:29 <Cale> but essentially, don't bother with the hClose
07:24:58 <Cale> since it's already set up to close when the evaluation is finished
07:25:03 <Igloo> goron: I have no idea, you'll need to debug it
07:25:51 <zagrius> Igloo: Thus make -d is the only thing I have?
07:26:38 * Igloo raises an eyebrow
07:27:02 <imix> ok, the whole I/O stuff is indeed a little tricky in haskell
07:27:06 <Igloo> I suspect inlining and trimming the Makefile is the way to go, but I'm no very familiar with debugging Makefiles
07:27:15 <goron> Igloo: me neither
07:27:46 <goron> I think the whole autoconf stuff is a adhoc way of creating systems.
07:28:55 <Cale> imix: well, hGetContents is sort of evil
07:28:57 <goron> It's just waiting for things to break. 
07:29:29 <imix> what do you propose as alternative? (if any?)
07:30:19 <Cale> well, use it, but I really think they should provide a version which reads the whole file into a buffer at once, and only converts it to a String lazily
07:30:57 <Cale> There's code for that I could give you, but it's a little on the low-level side obviously :)
07:31:21 <TuringTest> Cale: Isn't that code on the wiki somewhere?
07:31:26 <Cale> TuringTest: probably
07:31:36 <Cale> It was on the mailing list
07:31:54 <imix> i think for mt current uses its enough to just be careful with hGetContents
07:32:02 <Cale> right
07:32:17 <Cale> it's fine as long as you know that you aren't responsible for closing the handle
07:32:34 <lisppaste2> goron pasted "Make output" at http://paste.lisp.org/display/14974
07:32:34 <lisppaste2> goron pasted "Make output" at http://paste.lisp.org/display/14975
07:34:55 <benny> how does IORef work?
07:35:30 <imix> ok, thanks again for all your answers. i'll continue my journey to learn a little more about haskell
07:36:02 <Cale> benny: like, what actions can you perform on an IORef?
07:36:19 <benny> Cale: no i mean how's it implemented
07:37:26 <Cale> Presumably it's just a pointer
07:38:12 <benny> memory gets allocated on the heap with malloc when i call newIORef?
07:38:35 <Pupeno> Has anyone wrote a parser for program arguments ?
07:38:37 <Cale> I wouldn't bother to think about it on that level
07:38:51 <benny> Cale: ok... but then when does the memory get freed?
07:39:08 <Cale> benny: well, the memory for the IORef, or the thing it's referring to?
07:39:51 <benny> the thing it's referring to
07:40:18 <Cale> When the IORef is overwritten, it'll become garbage unless there's something else referring to it.
07:40:44 <Cale> Or if the IORef is GC'd itself, and it was the last thing referring to it.
07:40:49 <benny> hm....
07:41:01 <benny> i guess i should first try to understand how garbage collection works in haskell
07:41:29 <Cale> are you having problems with memory?
07:42:34 <xerox> so.. merry christmas, people?
07:42:42 <Cale> hehe
07:42:49 <Cale> Merry Christmas?
07:42:51 <Cale> hehe
07:42:58 <xerox> :-D
07:43:00 <benny> Cale: no, just curious
07:43:14 <xerox> Cale: how is it going with the FreeMonads thingy?
07:43:33 <Cale> xerox: I haven't done anything too significant there :)
07:43:59 <xerox> Right, you didn't publicly explain them ;-)
07:43:59 <Cale> xerox: did you see my extended table of folds and scans?
07:44:04 <Cale> hehe
07:44:05 <xerox> Yes!  Very very very cool.
07:44:36 <Cale> Well, have you looked at the code for the free monads?
07:45:01 <xerox> Nope.
07:45:10 <Cale> oh, you should see it then :)
07:45:38 <Cale> http://www.scannedinavian.org/blog/ -- it's on shapr's blog
07:46:13 <xerox> ah
07:46:18 <Cale> basically it's just an easy way to trick a functor into becoming a monad :)
07:46:24 <xerox> I saw that, which is the same as the ltu post
07:46:30 <Cale> yea
07:46:44 <xerox> didn't really understand :D
07:46:54 <Cale> okay
07:47:56 <Cale> have you seen the use of  newtype Mu f = In (f (Mu f))  to explicitly do type recursion?
07:48:15 <benny> how to convert Word16 to Int?
07:48:31 <xerox> No.
07:48:37 <Cale> benny: fromIntegral
07:48:45 <xerox> OK, let me open the sensible url and concentrate on your explanation :)
07:48:49 <benny> danke
07:48:52 <Cale> xerox: okay, so let's look at that first :)
07:50:08 <Cale> Normally, Haskell lets you refer to a datatype when you construct it
07:50:10 <Cale> for example
07:50:22 <Cale> data List a = Nil | Cons a (List a)
07:51:06 <xerox> yes
07:51:41 <Cale> But another way to handle this is to provide an explicit type constructor to handle recursion
07:52:15 <Cale> suppose we have  newtype Mu f = In (f (Mu f))  as a builtin part of the language, and types are otherwise not allowed to be recursively defined
07:52:57 <Cale> then we could write data List' a x = Nil | Cons a x
07:53:19 <Cale> and then List a is the same as Mu (List' a)
07:53:50 <Cale> (roughly)
07:54:10 <xerox> hmm
07:54:21 <xerox> Okay.
07:54:26 <Cale> brb, phone
07:55:10 <benny> am i allowed to use unsafeIO for debugging?
07:55:21 <Cale> benny: sure
07:55:37 <benny> seems like it's the only way to put some print calls inside my yampa arrows to track some values
07:55:51 <Cale> benny: you'll have an easier time with Debug.Trace
07:55:58 <benny> hm...
07:56:03 <roconnor> @hoggle a -> String -> a
07:56:04 <lambdabot> Debug.Trace.trace :: String -> a -> a
07:56:04 <lambdabot> Prelude.error :: String -> a
07:56:04 <lambdabot> Graphics.UI.ObjectIO.CommonDef.dummy :: String -> x
07:56:07 <xs> there's Debug.Trace
07:56:23 <roconnor> Debug.Trace.trace :: String -> a -> a
07:56:48 <roconnor> ?
07:56:54 <roconnor> what is Graphics.UI.ObjectIO.CommonDef.dummy
07:57:17 <roconnor> @info Graphics.UI.ObjectIO.CommonDef.dummy
07:57:18 <lambdabot> Unknown command, try @listcommands.
07:58:52 <joelr1> Cale: i'm throwing in the towel
07:59:08 <benny> hm... but how can i force the evaluation of the unsafePerformIO expression? :\\
07:59:20 <SamB> benny: seq
07:59:34 <Cale> benny: what are you trying to do?
07:59:51 <Cale> unsafePerformIO is sort of a bad route for anything
07:59:55 <benny> Cale: i want to print the input value in a yampa arrow
07:59:56 <SamB> or you could use Debug.trace, which works great ;-)
08:00:03 <Cale> Debug.Trace will work
08:00:09 <benny> maybe i should look into this Debug.Trace shit then :)
08:00:16 <SamB> it does all the unsafePerformIO and seq for you
08:00:44 <benny> is there maybe a tutorial or something?
08:00:51 <SamB> tutorial?
08:01:01 <SamB> @type Debug.trace.trace
08:01:02 <lambdabot> Couldn't find qualified module.
08:01:02 <lambdabot> Maybe you're using the wrong syntax: Data.List.(\\) instead of (Data.List.
08:01:02 <lambdabot> \\)?
08:01:04 <Cale> joelr1: oh? That's too bad, though it seems like what you were trying to do was a little insane :)
08:01:08 <SamB> @type Debug.Trace.trace
08:01:09 <lambdabot> forall a. String -> a -> a
08:01:24 <roconnor> Do an import Debug.Trace
08:01:39 <joelr1> Cale: i'm switching to erlang. something that i should have done from the beginning :-) for this app at least
08:01:41 <SamB> see, you just pass a string and a value, and when something wants that value, the string will be printed
08:01:49 <roconnor> Then use trace ("here is a:"++(show a)) a
08:01:51 <joelr1> Cale: i'll probably have the whole thing working perfectly this weekend
08:02:55 <joelr1> Cale: when simon m. comes back i'll figure things out and file them for later reference
08:03:19 <SamB> 20/20 hindsight :-(
08:03:24 <Cale> joelr1: did anyone put that cross-platform repeatable RTS bug into trac?
08:03:28 <benny> roconnor: hm.... doesn't seem to work
08:03:36 <joelr1> Cale: don't think so. would you please?
08:03:36 <SamB> benny: whats the problem?
08:03:41 <roconnor> benny: what do you have?
08:03:50 <SamB> benny: it only works if something uses the value
08:04:28 <benny> i have an arrow composition
08:04:41 <benny> not sure exactly where to stick the trace expression in
08:04:45 <SamB> oh
08:05:01 <SamB> well, where do you want to trace something?
08:05:08 <joelr1> Cale: there's still so much stuff to try in haskell so i won't miss a whole lot. yampa becons me
08:05:15 <roconnor> what data do you want to trace (if any?)
08:05:18 <Cale> joelr1: okay, I'll see about filling out a ticket
08:05:21 <benny> > inc x = x + 1
08:05:22 <lambdabot>  parse error on input `='
08:05:38 <benny> > inc' x = x + 1
08:05:39 <lambdabot>  parse error on input `='
08:05:47 <benny> > let inc x = x + 1
08:05:48 <lambdabot>  parse error on input `}'
08:06:00 <benny> anyway, where would you stick the trace in there?
08:06:05 <roconnor> > let inc x = x + 1 in inc 7
08:06:06 <lambdabot> 8
08:06:32 <roconnor> > let inc x = (trace ("The value of x:"++(show x)) x) + 1 in inc 7
08:06:33 <lambdabot>  Not in scope: `trace'
08:06:46 <roconnor> > let inc x = (Debug.Trace.trace ("The value of x:"++(show x)) x) + 1 in inc 7
08:06:47 <lambdabot>  Not in scope: `Debug.Trace.trace'
08:06:50 <benny> hm...........
08:06:51 <roconnor> ah well
08:07:20 <roconnor> should print a 7 before the 8
08:07:41 <roconnor> well, that assumes you print the value of inc 7 in your program.
08:09:56 <benny> argh, i almost got it, problem is the value i want to print isn't actually needed :(
08:10:45 <roconnor> then you need to print trace the value, at a place where you have access to it, around a block that is needed.
08:11:12 <roconnor> > let inc x = (Debug.Trace.trace ("The value of x:"++(show x)) (x+1)) in inc 7
08:11:13 <lambdabot>  Not in scope: `Debug.Trace.trace'
08:12:09 <benny> argh, where'd he go?
08:12:56 <SamB> dunno!
08:13:12 <benny> my problem is the value isn't needed because of lazy evaluation
08:13:28 <SamB> are you trying to find a bug, or what?
08:14:22 <benny> no, i've just written a bit of code and i want to make sure that it works properly
08:14:42 <SamB> what do you mean by properly?
08:16:26 <benny> well at one point i use an equation for transforming a value and i want to make sure that the equation is correct
08:17:53 * araujo just released a new version of hashell
08:21:22 <SamB> how is printing going to help?
08:22:04 <TuringTest> SamB: Would Test.HUnit or Test.QuickCheck help?
08:23:35 <Cale> ugh, joel is gone
08:24:02 <benny> alright, it works
08:31:28 * benny needs a #yampa channel
08:33:59 <araujo> yampa?
08:34:15 <benny> either that or a Cale-bot
08:36:11 <goron> How can I do something like this: ifeq "$(stage)" ""
08:36:11 <goron> stage=1
08:36:11 <goron> echo "print something"
08:36:34 <Cale> er
08:36:37 <Cale> in sh?
08:36:42 <goron> Cale: in MakeFiles
08:37:49 <Cale> I'm not too familiar with writing makefiles by hand
08:37:55 <benny> is there a function f x = [x]?
08:38:02 <Cale> benny: return
08:38:12 <benny> hm..... attack of the monads
08:38:48 <benny> actually i think i prefer (\x -> [x]) over return for clarity
08:39:03 <benny> what do you say?
08:39:31 <Cale> either way is fine
08:40:47 <Cale> I suppose it depends on what you need it for.
08:40:54 <benny> Cale: btw, should i be worried that i think i am finding it easier to understand arrows then monads?
08:41:15 <Cale> benny: well, I think you should take another look at monads in that case
08:41:33 <Cale> arrows are more general than monads
08:42:28 <benny> Cale: i sort of get the idea of monads, but i have trouble programming with either combinator syntax or do syntax. but with arrows i feel confortable coding with arrow combinators and arrow syntax
08:52:24 <tennin> what are Haskell arrows in category theory terms?
08:52:45 <tennin> (haven't actually looked into them yet)
08:53:38 <Cale> Arrows, in a particular kind of category
08:55:42 <benny> Cale: do you know anything about yampa? i'm having trouble with one little thing
08:56:04 <Cale> I don't know too much about it
08:56:11 <Cale> but you can ask :)
08:57:05 <benny> i'm trying to make a Signal Transformer that takes as input a and puts as output the value of a as it was d seconds ago
08:57:24 <Cale> okay
08:57:40 <Cale> that should be doable
08:58:09 <benny> delay :: DTime -> SF a a
08:58:11 <benny> so far so good?
08:58:31 <Cale> sure
08:58:38 <benny> ok now i'm stuck
08:58:52 <benny> hm... actually i think i know the direction
08:58:53 * benny ponders
08:59:07 <Cale> hmm
09:01:16 <benny> ok i'm really stuck. it seems that i need to have it store some kind of state... but the amount of state would need to be infinite since it would have to store all the values of the continius time range that are in the history
09:02:14 <Cale> well, no
09:02:40 <Cale> A value of type Signal a is just a function  Time -> a right?
09:03:05 <benny> yeah
09:03:13 <Cale> shift t f = \x -> f (x - t)
09:03:32 <Cale> we want the SF corresponding to that
09:03:39 <benny> hm...
09:04:01 <Cale> can we just arr that?
09:04:06 <Cale> hmm
09:04:07 <benny> i'm gonna try it
09:04:12 <Cale> no
09:04:21 <Cale> since that would lift too far :)
09:07:33 <Cale> you definitely need something specific to yampa
09:08:00 <benny> prove it :P
09:08:20 <Cale> well, it involves time
09:08:31 <Cale> which isn't a generic arrow concept :)
09:09:12 <benny> yampa has the built-in time Signal Function which ignores it's input and outputs the time passed since the beginning of the world
09:14:21 <Cale> hmm
09:16:05 <benny> indeed. there seems to be something in the yampa source that is maybe supposed to do this called "pre"
09:16:17 <Cale> yeah, I'm looking at that right now :)
09:17:00 <Cale> that seems discrete though
09:17:01 <benny> but when i try to innocently use pre i get an exception "Uninitialized pre operator."
09:17:15 <benny> well, yampa is implemented discretely i think
09:19:27 <Cale> DTime = Double though
09:19:48 <Cale> as is Time
09:21:02 <Cale> it does sample things discretely in the end
09:21:12 <benny> did you see the reactimate function? that seems to be the "main loop"
09:24:42 <benny> hm... i'm gonna go eat something
09:25:36 <Cale> aha
09:26:17 <Cale> These "Initialization" operations look interesting
09:31:16 * araujo shouldn't hack today
09:33:53 <goron> Cale: what OS are you using?
09:34:02 <Cale> why?
09:34:06 <Cale> Debian
09:34:35 <goron> Cale: For some weird reason I can't build ghc on Debian. 
09:34:50 <goron> Cale: I just tried building the nightly snapshot.
09:35:03 <Cale> I just use the binary
09:35:05 <goron> Cale: And it halted on the same place as the version from CVS.
09:35:22 <goron> Cale: The Debian binary?
09:35:25 <Cale> yeah
09:35:37 <goron> Cale: ghc-cvs?
09:35:41 <Cale> no
09:35:44 <goron> Cale: Stable? Unstable?
09:35:52 <Cale> ghc6 in unstable
09:36:32 <goron> Cale: But that's not even 6.4.2, right?
09:36:48 <Cale> I'll check
09:36:56 <Cale> It's 6.4.1
09:37:25 <Cale> That's the current release
09:37:37 <Cale> 6.4.2 hasn't been released
09:37:58 <goron> You are right.
09:38:15 * benny returns and wonders if Cale has any last words
09:38:31 <Cale> benny: well, I'm still looking at it
09:38:46 <Cale> I think I see how to implement it internally to yampa
09:38:49 <benny> ok cool :) guess yampa isn't so great after all, eh :P
09:39:00 <Cale> but there ought to be a way to do it from their interface
09:39:05 <goron> Cale: wget http://www.haskell.org/ghc/dist/current/dist/ghc-6.5.20050722-src.tar.bz2
09:39:30 <goron> Cale: could you do that, and see whether it comes past ==fptools== make all -wr;
09:39:36 <Cale> benny: Well, it's okay, perhaps it just wasn't designed to allow you to look into the future :)
09:39:38 <goron> Cale: that should happen pretty fast. 
09:39:43 <benny> in the meantime i'm gonna try porting that space invaders game to my sdl/opengl framework
09:40:16 <benny> Cale: to peer into the past is what the desire is
09:40:18 <Cale> goron: okay
09:40:40 <Cale> benny: or that :)
09:41:13 <benny> Cale: i think i sort of in theory know how to solve this
09:41:20 <Cale> It would be trivial to implement for the SF' type
09:41:25 <Cale> but that's not exposed
09:41:57 <Cale> you might try sending a message to the Yampa mailing list
09:41:59 <benny> right, to prevent leaks
09:42:12 <benny> :O
09:42:20 <Cale> ah, that might also be an issue
09:42:40 <Cale> memory usage would go way up with delays hanging on to things
09:42:45 <benny> here is what i am sort of thinking about... a Signal Function that has a loopback that is a list that gets appended the latest value all the time
09:42:50 <Cale> but it still ought to be possible
09:43:24 <benny> and the no longer needed values are dropped from the front of the list
09:44:39 <Cale> hmm, not sure what that means really
09:44:49 <benny> me neither
09:44:56 <Cale> hehe
09:45:44 <benny> i'm gonna try first making a Signal Function that takes as input any value, and as output it is the list of all input values it has ever recieved
09:46:53 <goron> benny: Does Yampa work with newer GHC versions?
09:47:05 <benny> goron: yeah
09:47:49 <goron> benny: Where did you get your Yampa? http://www.haskell.org/yampa/?
09:48:14 <benny> goron: yeah, but download the "Core" release, not the Bundle
09:51:14 <goron> Cale: GHC builds?
09:51:20 <Cale> configuring
09:51:49 <[CotL]Godofe_Kei> Merry Christmas ppl!
09:52:21 <[CotL]Godofe_Kei> can anyone help me here? why isnt this working?
09:52:22 <[CotL]Godofe_Kei> agrupa1 s = map (\((n,x,y):xs) -> ((n,x,y):xs)) $ groupBy (\a b c -> fst a == fst b) s
09:53:14 <Cale> @type groupBy
09:53:16 <lambdabot> Not in scope: `groupBy'
09:53:20 <Cale> @type Data.List.groupBy
09:53:22 <lambdabot> forall a. (a -> a -> Bool) -> [a] -> [[a]]
09:53:36 <[CotL]Godofe_Kei> hmm
09:53:42 <Cale> @type \a b c -> fst a == fst b
09:53:43 <lambdabot> forall b a b1 t. (Eq a) => (a, b) -> (a, b1) -> t -> Bool
09:55:07 <araujo> as clear as the heaven
09:55:21 <[CotL]Godofe_Kei> then how to go from [(2,7,1),(2,12,3),(4,11,2),(4,2,4)] to [[(2,7,1),(2,12,3)],[(4,11,2),(4,2,4)]]?
09:57:23 * benny mumbles to Cale that he thinks that he is getting somewhere...
09:58:11 <araujo> > let v = [(2,7,1),(2,12,3),(4,11,2),(4,2,4)] in (take 2 v) : (drop 2 v) : []
09:58:12 <lambdabot> [[(2,7,1),(2,12,3)],[(4,11,2),(4,2,4)]]
09:58:24 <[CotL]Godofe_Kei> hmm
09:58:37 <[CotL]Godofe_Kei> but that only works if i give 2 arguments each
09:58:56 <araujo> uh?
09:59:12 <[CotL]Godofe_Kei> if i have: [(2,7,1),(2,12,3),(2,4,34),(4,11,2),(4,2,4)]
09:59:18 <[CotL]Godofe_Kei> i wont work will it?
09:59:42 <araujo> > let v =   [(2,7,1),(2,12,3),(2,4,34),(4,11,2),(4,2,4)] in (take 2 v) : (drop 2 v) : []
09:59:44 <lambdabot> [[(2,7,1),(2,12,3)],[(2,4,34),(4,11,2),(4,2,4)]]
09:59:50 <[CotL]Godofe_Kei> :D
09:59:54 <araujo> :-P
09:59:54 <[CotL]Godofe_Kei> see?
10:00:08 <araujo> No, i still don't see what you mean :-P
10:00:37 <[CotL]Godofe_Kei> all the ones that start with 2, or 4 ,or the same number should be placed in one list
10:01:29 <Cale> > let v = [(2,7,1),(2,12,3),(2,4,34),(4,11,2),(4,2,4)] in groupBy (\(x,_,_) (y,_,_) -> x == y) v
10:01:31 <lambdabot> [[(2,7,1),(2,12,3),(2,4,34)],[(4,11,2),(4,2,4)]]
10:01:33 <[CotL]Godofe_Kei> lo comprendes?
10:01:37 <Cale> like that?
10:01:44 * araujo didn't know [CotL]Godofe_Kei meant that
10:01:44 <[CotL]Godofe_Kei> yeah like that
10:01:56 <[CotL]Godofe_Kei> hmm let me see if i understand it
10:02:27 <araujo> There is practically nothing to understand there :-P
10:02:40 <Cale> goron: damn entropy :) My machine overheated running the configure script
10:03:30 <[CotL]Godofe_Kei> hmm
10:03:39 <Cale> I really should just shut my machine off and clean it up.
10:03:41 <[CotL]Godofe_Kei> but i dont think it stil does wohat i want
10:03:47 <[CotL]Godofe_Kei> i understand it yes
10:03:58 <franka> Cale, you spend a lot of time on #haskell.
10:04:01 <[CotL]Godofe_Kei> but i will only word for 2 different numbers right?
10:04:08 <[CotL]Godofe_Kei> can i do map?
10:04:12 <franka> We've all decided that you should be given a salary for your efforts.
10:04:24 <Cale> franka: :)
10:04:51 <xerox> @karma+ Cale 
10:04:51 <lambdabot> Cale's karma raised to 5.
10:04:56 <franka> However, life isn't fair...
10:05:00 <Cale> > let v = [(2,7,1),(2,12,3),(3,4,34),(4,11,2),(4,2,4)] in groupBy (\(x,_,_) (y,_,_) -> x == y) v
10:05:02 <lambdabot> [[(2,7,1),(2,12,3)],[(3,4,34)],[(4,11,2),(4,2,4)]]
10:05:13 <Cale> [CotL]Godofe_Kei: look!
10:05:14 <Cale> hehe
10:05:16 <[CotL]Godofe_Kei> hmm
10:05:21 <[CotL]Godofe_Kei> sry lol
10:05:23 <[CotL]Godofe_Kei> my bad
10:05:32 <[CotL]Godofe_Kei> im just not very familliar with groupBy
10:05:36 <[CotL]Godofe_Kei> its very useful
10:07:51 <Cale> okay, be back in a bit
10:09:29 <ricebowl> bah, anyone have any tips on improving performance?
10:09:37 <ricebowl> I'm using unboxed arrays in the ST monad :|
10:11:11 <ricebowl> here's the code: http://www.rafb.net/paste/results/j9Ezvw73.html
10:15:12 <benny> how to get the last element of a list?
10:15:22 <ricebowl> > last [0,1,2,3]
10:15:24 <lambdabot> 3
10:15:28 <benny> thanks
10:15:30 <ricebowl> np
10:15:39 <benny> sorry i can't help you out i'm still new
10:15:44 <ricebowl> 'sok :p
10:16:59 <gour> @localtime dons
10:17:02 <lambdabot> Local time for dons is Sun Dec 25 05:12:01 2005
10:17:39 <ricebowl> nobody familiar with tuning code for performance?
10:18:10 <ricebowl> my code runs slow with n=39; there is no way it can possibly run with n=200 :(
10:19:14 * Lemmih is having a hard time groking what the code is meant to do.
10:19:36 <ricebowl> it's an implementation of the Floyd-Warshall shortest path algorithm
10:20:03 <ricebowl> given a list of paths :: (i, j, dist), I populate a mutable array, and then run this algorithm
10:20:20 <ricebowl> and the result is an array with the minimum distance between every pair of nodes in the graph
10:20:33 <ricebowl> the initial population of the array is done before calling fw
10:20:40 <Lemmih> What does profiling say?
10:20:49 <ricebowl> that this one function is taking 90% of my program's time
10:20:57 <ricebowl> specifically fw', which is the inner 2 loops
10:21:16 <benny> hm... i need to debug, i'm apparently getting stuck in an infinite loop and i don't know where
10:21:59 <ricebowl> abusing notation a little, the algorithm is something like [a(i,j) = min(a(i,k) + a(k,j), a(i,j)) | i <- [0..n], j <- [0..n], k <- [0..n]]
10:23:34 <ricebowl> 85.7% of my time is spent in fw'
10:23:45 <ricebowl> 86.6% of my memory, too, so something strange is going on.
10:25:26 <Lemmih> The fold is a bit strange. Any reason you didn't use mapM_?
10:25:34 <ricebowl> not in particular
10:25:41 <tennin> hmm, that's a little straightforward for an algorithm with people's names attached
10:25:48 <ricebowl> haha
10:25:54 <tennin> I was bracing for something more clever and devious and beyond my comprehension
10:25:56 <ricebowl> it's pretty simple
10:26:23 <ricebowl> anyway, I basically want to iterate through all (i, j) pairs
10:26:38 <ricebowl> and modify the array in each case
10:27:01 <ricebowl> that's not possible with mapM, AFAIK
10:27:18 <ricebowl> well, I get something like Monad m => [m ()]
10:27:30 <Lemmih> @type mapM_
10:27:30 <ricebowl> hola {Arias}
10:27:31 <lambdabot> forall (m :: * -> *) a b. (Monad m) => (a -> m b) -> [a] -> m ()
10:27:36 <ricebowl> oh
10:27:38 <{Arias}> hola
10:27:39 <{Arias}> :D
10:27:45 <ricebowl> thought it was the same type as map...thanks
10:27:58 <ricebowl> @index mapM_
10:27:59 <lambdabot> Control.Monad, Prelude, Control.Monad.Reader, Control.Monad.Writer,
10:27:59 <lambdabot> Control.Monad.State, Control.Monad.RWS, Control.Monad.Identity, Control.
10:27:59 <lambdabot> Monad.Cont, Control.Monad.Error, Control.Monad.List
10:28:26 <TuringTest> @type foldM
10:28:27 <lambdabot> Not in scope: `foldM'
10:28:32 <TuringTest> @index foldM
10:28:33 <lambdabot> Control.Monad, Control.Monad.Reader, Control.Monad.Writer, Control.Monad.
10:28:33 <lambdabot> State, Control.Monad.RWS, Control.Monad.Identity, Control.Monad.Cont,
10:28:33 <lambdabot> Control.Monad.Error, Control.Monad.List
10:28:39 <ricebowl> @type Control.Monad.foldM
10:28:40 <lambdabot> forall a (m :: * -> *) b.
10:28:40 <lambdabot> (Monad m) =>
10:28:40 <lambdabot> (a -> b -> m a) -> a -> [b] -> m a
10:28:48 <TuringTest> which is what you want
10:29:18 <Lemmih> ricebowl: You should also make sure that the function is properly specialized and inlined.
10:29:28 <ricebowl> ah
10:29:33 <ricebowl> that could do it, then
10:30:43 <ricebowl> mapM_ is slightly more efficient, but not much...
10:30:56 <ricebowl> time seems to be proportional to the amount of memory generated
10:31:01 <Lemmih> Why do you pass 'a' to 'fwstep'?
10:31:21 <ricebowl> well, I s'pose that I don't have to, but does that make a difference?
10:31:30 <ricebowl> that's semantically the same as not passing it
10:36:34 <Lemmih> It does make a difference. You should also drop the 'k'.
10:37:17 <ricebowl> ok
10:38:06 <ricebowl> that does seem to have significantly improved the time, though I don't see how
10:40:35 <TuringTest> ricebowl: The compiler is not perfect at removing the redundant parameter, since it does not notice the dummy 'a' in the where fwstep definition is always getting passed the 'a' that was originally bound by the fw' definition.
10:46:43 <TuringTest> @paste
10:46:43 <lambdabot> http://www.haskell.org/hawiki/HaskellIrcPastePage
10:47:53 <ricebowl> TuringTest - I had the impression that it was passed either way
10:50:35 <lisppaste2> TuringTest pasted "modified" at http://paste.lisp.org/display/14981
10:51:04 <TuringTest> Thats the latest mutation of it that I came up with
10:51:17 <ricebowl> ah
10:52:16 <TuringTest> Nearly perfect use of lexical scope
10:52:23 <[CotL]Godofe_Kei> i just get the most unusual error on this function im working on
10:52:29 <[CotL]Godofe_Kei> Hugs just freezes
10:52:44 <[CotL]Godofe_Kei> testaConcorrente2 :: [(Int,Int,Int)] -> Corredores -> [(Int,String,Int,(Int,Int,Int,Int))]
10:52:44 <[CotL]Godofe_Kei> testaConcorrente2 [] [] = []
10:52:44 <[CotL]Godofe_Kei> testaConcorrente2 ((i1,i2,i3):ys) ((n,s):xs)
10:52:44 <[CotL]Godofe_Kei> 	|i3 == n = (i3,s,i1,(inverte i2)) : testaConcorrente2 ys ((n,s):xs)
10:52:44 <[CotL]Godofe_Kei> 	|otherwise = testaConcorrente2 ((i1,i2,i3):ys) ((n,s):xs)
10:52:47 <ricebowl> ack
10:52:51 <ricebowl> use a pastebin :P
10:52:53 <Lemmih> ricebowl: Why are you returning the mutable array?
10:52:55 <[CotL]Godofe_Kei> is there anything wron with it?
10:53:02 <[CotL]Godofe_Kei> it compiles find and it should work
10:53:13 <ricebowl> Lemmih - the parameter to runSTUArray
10:53:23 <ricebowl> it's not well-structured, but it's only used once in the program
10:53:27 <tromp_> anyone here running mac OSX tiger?
10:53:55 <monochrom> If I had an extra $1000 I would be. :)
10:54:20 <ricebowl> [CotL]Godofe_Kei - I don't see anything wrong with it per se... but obviously the recursion isn't terminating
10:54:23 <tromp_> macmini is under $500 :P
10:54:33 <[CotL]Godofe_Kei> ??
10:54:38 <[CotL]Godofe_Kei> isnt it?
10:54:54 <monochrom> macmini is of limited use to me.
10:55:11 <tromp_> afk...
10:55:14 <[CotL]Godofe_Kei> hmm ill check it out later
10:55:15 <[CotL]Godofe_Kei> gtg
10:55:16 <ricebowl> TuringTest - it doesn't seem to help performance any, though
10:55:20 <[CotL]Godofe_Kei> cya later peeps
10:55:24 <[CotL]Godofe_Kei> MERRY XMAS TO YOU ALL!
10:55:29 * TuringTest is running 10.4.3
10:55:32 <ricebowl> Merry Christmas :p
10:56:21 <ricebowl> TuringTest - do you know much about seq? I presume what's going on here is that it's building up computations and not running them until later
10:56:25 <ricebowl> I want it to be strict in this case
10:56:47 <TuringTest> If you use a STUArray it will be strict
10:56:51 <ricebowl> each iteration of fw reads *every* element of the array
10:57:20 <ricebowl> well I'm using STUArray, but my understanding is that it is still lazy--but when it evaluates any part of the array, then it evaluates the whole thing
10:57:32 <benny> anyone know how yampa works with recursive arrows?
10:57:36 <ricebowl> I'd rather it weren't lazy at all
10:58:19 <ricebowl> s/weren't/not be/
10:58:35 <TuringTest> If you are in Control.Monad.ST (aka Control.Monad.ST.Strict) and use a STUArray, then laziness is not your problem.
10:59:15 <ricebowl> :|
10:59:50 <franka> What is [CotL]?
11:00:00 <TuringTest> How large is (xs) ?
11:00:06 <franka> Oh, he''s gone...
11:00:14 <TuringTest> ricebowl:  How large is (xs) for your problem?
11:00:24 <ricebowl> could be pretty large, I guess. 40,000 at most. But I'm testing on 39*39
11:00:25 <ricebowl> > 39*39
11:00:27 <lambdabot> 1521
11:01:01 <TuringTest> The problem runs in O( (length xs)^3 )
11:01:13 <TuringTest> > 1521^3
11:01:15 <lambdabot> 3518743761
11:01:27 <TuringTest> > (200*200)^3
11:01:28 <lambdabot> 64000000000000
11:02:01 <ricebowl> no
11:02:11 <ricebowl> O((sqrt xs)^3)
11:02:32 <ricebowl> oh, sorry
11:02:38 <TuringTest> Oh...so (length xs)==39
11:02:39 <ricebowl> I was looking at ij
11:02:43 <ricebowl> yeah, sorry
11:02:48 <ricebowl> and maximum of 200
11:02:50 <ricebowl> > 200**3
11:02:52 <lambdabot> 8000000.0
11:02:58 <TuringTest> > 200/39
11:03:00 <lambdabot> 5.128205128205129
11:03:06 <TuringTest> > (200/39)^3
11:03:06 <ricebowl> 134x or so
11:03:07 <lambdabot> 134.864040189484
11:03:10 <ricebowl> I already worked it out :P
11:03:28 <ricebowl> I have 1 minute to complete on a test case of 200 nodes
11:03:45 <ricebowl> which means my time has to be substantially lower than 0.44 seconds :(
11:03:46 <TuringTest> The 39 case should be quite fast
11:03:52 <ricebowl> yes, it ought to be
11:06:45 <TuringTest> ricebowl: What is the element type of the array?
11:07:01 <ricebowl> ah, that could be it
11:07:03 <ricebowl> Int64
11:07:32 <ricebowl> but I've got no choice :(
11:07:50 <ricebowl> the maximum distance is 199,000,000,000
11:08:03 <ricebowl> Integer is slightly slower than Int64 in my tests
11:08:17 <TuringTest> Well..yes...
11:08:50 <rep> how about Int32?
11:09:19 <ricebowl> rep - do 32-bit integers hold values that large? :p
11:09:29 <ricebowl> last I checked they only go up to 2.1 billion
11:10:54 <Cale> well, that cleaning certainly seems to have helped my cpu temperature. 68 degrees to 31
11:11:07 <goron> Cale: I thought your computer had melted...
11:11:28 <ricebowl> 68, amazing it didn't catch fire
11:12:13 <ricebowl> heh maybe I'll just fix Int64 now that I've got time to do so
11:12:21 <ricebowl> Int64 and Word64 both (grr)
11:12:23 <Cale> the stuff I'd been using as thermal paste was finally starting to dry up, I think
11:12:43 <ricebowl> do you have an Pentium-4 or Athlon*?
11:12:51 <Cale> It was a combination of toothpaste and noncorrosive soldering flux
11:12:52 <Cale> P4
11:12:55 <ricebowl> haha
11:13:02 <glguy> lol
11:13:08 <Cale> This time I just went with straight soldering flux
11:13:14 <Cale> seems to work okay
11:13:17 <ricebowl> weird
11:13:24 <ricebowl> why not just use the stuff that comes with it?
11:13:38 <Cale> It only came with one sample
11:13:56 <Cale> you can buy more, but it's a waste of money
11:14:01 <glguy> it seems like the 5$ you spend of thermal compound is trivial next to the hundreds for a new P4
11:14:01 <ricebowl> ...normally that's enough, eh :p
11:14:09 <ricebowl> quite right
11:14:12 <Cale> The only point of that stuff is to fill up the airspace
11:14:17 <ricebowl> I think I paid $7 for Arctic Silver III
11:14:30 <glguy> yeah, I bought a tube of that stuff 4 computers ago
11:14:35 <Cale> Still, when just about anything around the house will work :)
11:14:57 <ricebowl> yes but less so these days
11:15:06 <glguy> apparently not if your computer overheated when it dried out
11:15:13 <ricebowl> the heat density is getting pretty nasty
11:15:16 <Cale> glguy: that was after 2 years or so
11:15:33 <ricebowl> AMD has stepped up heatsink and thermal paste requirements
11:15:50 <benny> Cale: i almost got it!
11:16:06 <ricebowl> Intel's right around the corner; they put out more raw wattage, but I think it's got more surface area
11:16:33 * ricebowl has a third-hand K6 where someone *epoxied* the heatsink to the chip
11:16:51 <Cale> and it still only overheated when I pushed it to 100% for over a few minutes
11:17:11 <glguy> most games do that constantly
11:17:15 <Cale> yeah
11:17:23 <glguy> my little brothers would destroy my computers if I did that :)
11:17:38 <Cale> only after a couple of years
11:17:51 <Cale> It works fine for quite a long while
11:17:58 <ricebowl> curious
11:18:45 <Cale> goron: what was it that you wanted to know about the ghc build?
11:19:11 <goron> Cale: whether it became in a state where make uses 99% CPU.
11:19:28 <Cale> actually toothpaste makes quite a good thermal paste because it has very good heat conductivity
11:19:36 <ricebowl> does it? Why?
11:19:42 <Cale> apart from the fact that it will eventually dry out
11:19:46 <ricebowl> heh :p
11:20:07 <Cale> goron: well, ghc will do that
11:20:31 <Cale> it's building okay though, so far
11:20:37 <Cale> how far into the build was this?
11:21:05 <TuringTest> ricebowl: Are you *sure* you are using STUArrays?
11:21:34 <goron> Cale: I am looking up the line, again.
11:21:50 <goron> ===fptools== Finished making `all' in building users_guide ext-core storage-mgt ...
11:21:54 <goron> PWD = /home/ron/fptools/ghc/docs
11:21:56 <goron> ------------------------------------------------------------------------
11:21:59 <goron> ------------------------------------------------------------------------
11:22:01 <goron> ==fptools== make all -wr; in /home/ron/fptools/ghc/compiler
11:22:18 <goron> Does it continue after this line?
11:22:43 <TuringTest> ricebowl:  I can do 200 case with Word64 in under 8.5 seconds (wall clock) 6.8 seconds (user time)
11:23:03 <ricebowl> hm
11:23:05 <TuringTest> ricebowl:  You said you tested with type Integer, but there is no STUArray for Integer.
11:23:11 <ricebowl> no, I didn't
11:23:19 <ricebowl> I compared Int64 to Integer once upon a time
11:23:25 <ricebowl> but you make a good point anyway
11:23:30 <Cale> goron: yes
11:23:41 <ricebowl> I'm trying to generate a test case for 200 nodes...
11:24:53 <lisppaste2> TuringTest annotated #14981 with "Runs in 8.5 seconds" at http://paste.lisp.org/display/14981#1
11:25:05 <Cale> lisppaste2: url
11:25:06 <lisppaste2> To use the lisppaste bot, visit http://paste.lisp.org/new/haskell and enter your paste.
11:25:17 <TuringTest> Now, I just used all zeros, but the algorithm does not care.
11:25:43 <goron> Cale: what gcc do you have?
11:25:55 <lisppaste2> Cale pasted "ghc build" at http://paste.lisp.org/display/14982
11:26:11 <ricebowl> yeah, I know
11:26:17 <Cale> gcc (GCC) 4.0.3 20051111 (prerelease) (Debian 4.0.2-4)
11:27:23 <ricebowl> wait--how fast is your machine?
11:28:14 <goron> Cale: make version?
11:28:24 <goron> Cale: I have no idea why it doesn't work then.
11:28:26 <TuringTest> ricebowl: Powerbook (1.33 GHz G4 from last year).  I used "ghc --make -O2" to compile it. 
11:28:34 <ricebowl> *nods*
11:28:41 <goron> Your gcc version is not from unstable, right?
11:28:43 <ricebowl> ah, d'oh, I removed the optimization flags
11:28:58 * TuringTest nods
11:29:36 <ricebowl> well then, let's see now...
11:29:48 <ricebowl> your box is probably a bit faster than mine, though
11:30:03 * ricebowl <-- dual 1.4 GHz Athlon
11:31:08 <ricebowl> it's still about 30 seconds or so
11:31:12 <ricebowl> but fast enough, I suppose
11:32:03 <ricebowl> did you use a SPECIALIZE pragma?
11:32:18 * TuringTest points at http://paste.lisp.org/display/14981#1
11:32:24 <ricebowl> ok
11:33:23 <ricebowl> hm, down to 24 seconds now
11:33:36 <TuringTest> ricebowl: I avoided giving any flags or type signatures aside from the ST s (STUArray ...)
11:33:44 <ricebowl> *nods*
11:34:44 <ricebowl> wow, that Powerbook is substantially faster I guess
11:34:49 <ricebowl> I get 25.24 seconds
11:34:57 <ricebowl> or at least GHC optimizes much better for it
11:35:12 <ricebowl> that's reassuring, though, since this has to run on a PPC-based box
11:36:45 <TuringTest> I am getting 10 seconds of wall time right now
11:37:02 <TuringTest> So the optimizer is better for PPC for this Word64 code.
11:37:05 <benny> holy lord it works Cale!
11:37:10 <benny> i'm a genious
11:37:24 <ricebowl> *nods*
11:37:42 <ricebowl> that could be the difference, I suppose
11:38:23 <ricebowl> G4 is still 32-bit, isn't it?
11:38:36 <TuringTest> yup
11:38:37 <benny> the only question is do i have a space leak
11:40:00 <ricebowl> oddly it only gets 4 seconds faster for me with Word32
11:40:51 <ricebowl> performance appears to be proportional to the amount of garbage it generates
11:41:12 <ricebowl> it generates 2.4 GB just to evaluate the array :|
11:43:08 <TuringTest> ricebowl: I run that test code in less than 2.8 MB of RSIZE
11:44:42 <ricebowl> I'm talking about the "total alloc" field in the profile output
11:45:02 <ricebowl> which AFAIK is the total amount of garbage generated
11:48:34 * TuringTest runs +RTS -p 
11:49:01 <TuringTest> ricebowl:  "total alloc = 770,897,856 bytes" "total time  =       14.78 secs"
11:50:27 <benny> how do you check these statistics?
11:50:36 <ricebowl> it produces a .prof file
11:50:46 <ricebowl> ghc ... -prof -auto-all ...
11:51:01 <ricebowl> -auto-all is useful if you don't want to do the annotations yourself
11:51:06 <ricebowl> to specify which functions to monitor
11:51:10 <TuringTest> benny: http://www.haskell.org/ghc/docs/6.4-latest/html/users_guide/profiling.html
11:51:46 <TuringTest> Though just looking at "top" while it runs is also quite helpful for space leaks.
11:59:56 <goron> benny: Do you know how rec is translated in arrows?
12:00:17 <benny> ricebowl: when i try that it tells me, "Could not find module `Graphics.UI.SDL'
12:00:27 <benny> goron: using some kind of loop combinator
12:01:30 <TuringTest> @index ArrowLoop
12:01:31 <goron> benny: you mean it's a function?
12:01:31 <lambdabot> Control.Arrow
12:01:32 <Lemmih> benny: You probably didn't compile hsSDL with profiling support.
12:02:05 <benny> Lemmih: but i don't need to worry about the performance of hsSDL itself
12:02:11 <benny> goron: yeah
12:02:39 <goron> benny: does GHC understand rec?
12:02:46 <benny> goron: yes
12:03:29 <goron> It's pretty nice. (FRP)
12:03:32 <Lemmih> benny: You can't use profiling if you're using a library which hasn't been compiled for profiling.
12:03:43 <benny> Lemmih: i see
12:05:04 <benny> well, i'm looking at top, and the RES is slowly climbing 1m every few seconds
12:08:05 <glguy> (sorry)
12:13:03 <Cale> goron: GNU Make 3.80
12:13:09 <Cale> benny: what did you do?
12:13:54 <Cale> (i.e. how do you create a delay arrow in Yampa?)
12:14:02 <goron> Cale: hmm, I have 
12:14:12 <goron> Cale: GNU Make 3.81beta4
12:14:26 <xs> hm. ghc-compiled (e.g., ghci, darcs) stuff sometimes doesn't properly flush the tty, is this normal?
12:14:59 <goron> xs: the programmer has to specify how it should work. 
12:15:10 <goron> xs: ghci/=ghc
12:15:11 <Cale> xs: which version of ghc?
12:15:23 <xs> 6.4.1
12:15:24 <goron> xs: everything else is a bug.
12:15:27 <Cale> hmm
12:15:40 <Cale> Well, you can set line buffering explicitly
12:15:48 <xs> goron: hm, yeah. but i would expect ghci to work..
12:15:58 <Cale> it might default to block buffering, but I thought they'd changed that
12:16:38 <xs> hmm. okay, it is a bit weird. i get stuff like: Failed, modules loaded: STM*STMArray>
12:16:49 <Cale> what?
12:17:02 <Cale> Your code doesn't compile?
12:17:15 <xs> the line is truncated
12:17:20 <xs> i didn't expect it to
12:17:38 <Cale> oh, that is a little odd
12:17:52 <Cale> which OS/terminal program?
12:17:52 <goron> Cale: the most likely explanation is that some bug went into make. I am now getting the 3.80 version. Thanks for your help.
12:18:06 <Cale> goron: no problem
12:18:24 <Cale> goron: yeah, I haven't done an upgrade in a few weeks now
12:18:53 <xs> this is ghci inside xemacs. but i've seen it in an xterm, and console. under netbsd.. hm. i'll try updating libc.
12:19:49 <Cale> I've had it do slightly strange things when run from eshell.
12:20:20 <xs> truncation? or other stuff?
12:21:06 <Cale> I can't recall exactly
12:21:34 <xs> hm, ok, thanks
12:22:14 <stepcut> Cale: I have had issues like that too.. 
12:22:19 <Cale> well, Ctrl-C doesn't quite work the way you'd like
12:22:54 <benny> Cale: i got the "delay" Signal Function working!
12:23:21 <Cale> benny: I heard -- but what did you write?
12:23:31 <benny> Cale: i'll paste the code... but it's ugly
12:24:21 <benny> and i also think there is a space leak
12:25:21 <goron> xs: you have to do M-x ans-term in emacs. 
12:25:25 <goron> xs: er ansi
12:25:32 <goron> xs: Dunno about xemancs
12:25:39 <goron> er xemacs
12:26:56 <stepcut> whoa, M-x ansi-term rocks
12:27:39 <goron> it does?
12:28:46 <goron> It is a terminal, and it works, but nothing to be very enthusiastic about.
12:29:09 <benny> Cale: http://rafb.net/paste/results/thQW3Z56.html
12:29:17 <xs> heh nice. ugh xemacs lacks. hmm.
12:30:56 <Cale> benny: ah, okay
12:31:17 <Cale> It doesn't seem like you should have to do that, but I suppose that works :)
12:32:16 <benny> Cale: the tricky part was figuring out the (iPre []) part, without it the recursive arrow gets stuck
12:32:25 <rep> kurisumasu omedeto!
12:33:41 <stepcut> benny: yeah I had that problem too
12:33:50 <benny> stepcut: you use yampa?
12:34:13 <Cale> It might be easier to implement in terms of SF' and just add it to the yampa library :)
12:34:16 <stepcut> benny: a bit, I am using it for a virtual analog synth
12:34:36 <stepcut> benny: did you see the paper about extending yampa to use GADTs ?
12:34:55 <benny> stepcut: no.... i don't think i'm advanced enough to understand it though
12:35:10 <stepcut> benny: me neither :p
12:35:32 <benny> i think i can also replace those filters with something more optimized
12:35:36 <Oejet> Lemmih: Merry Christmas!
12:35:36 <stepcut> benny: but it might be nice to use that version of the code instead -- since it supposedly has better performance
12:35:47 <benny> stepcut: interesting
12:36:50 <benny> well, my plan now is to watch some tv, then work a few hours on porting the space invaders game to the sdl/opengl yampa framework that i built
12:36:59 <benny> then i go to sleep and when i wake up i'm off the grid for 10 days :'(
12:37:21 <benny> hopefully this stuff will sink in during the 10 days
12:38:30 <stepcut> benny: are you using lemmih's sdl bindings?
12:38:47 <benny> stepcut: yes
12:39:15 <benny> stepcut: i had previously used some other bindings... Lemmih's are very similar but more polished
12:39:15 <stepcut> playing with yampa really clarified my understand of arrows, but things like the loop arrow took a while to sink in
12:39:25 <stepcut> yeah, lemmih's are the best I have seen
12:39:56 <benny> stepcut: i'm not sure that i understand the loop arrow but i think i might and it's cool :)
12:40:09 <benny> i mean, i understand at least the concept
12:40:16 <stepcut> heh
12:40:28 <benny> i found that yampa paper to be really good
12:41:57 <ricebowl> is there an efficient way to traverse a graph without looping?
12:42:22 <stepcut> ricebowl: do you mean the graph is acyclic? 
12:42:23 <Heffalump> have you read thee paper by Launchbury and King "Structuring Depth-First Search in Haskell"?
12:42:32 <Cale> use a set or array to keep track of which vertices you've visited
12:42:38 <ricebowl> the graph is most definitely cyclic
12:42:45 <ricebowl> ah, a set...
12:42:50 <stepcut> ricebowl: so you want to traverse it without getting stuck in a loop ?
12:42:56 <ricebowl> yes, essentially
12:43:31 <Heffalump> read that paper
12:43:55 <stepcut> ricebowl: I believe there are some well documented functional algorithms for that -- but I am not personally familiar with them
12:44:05 <ricebowl> Heffalump - where can I obtain it?
12:44:53 <Heffalump> did you try googling for the title to see if a free copy appears?
12:44:56 <Cale> http://www.cse.ogi.edu/~jl/Papers/dfs.ps
12:44:58 <ricebowl> yep
12:45:03 <Heffalump> there you go then :-)
12:45:06 <ricebowl> only link that shows on Google is a #haskell log
12:45:13 <Heffalump> IM what Cale said
12:45:23 <ricebowl> cool, thanks
12:45:25 <Cale> I just used google
12:45:39 <Cale> @google Structuring Depth-First Search in Haskell
12:45:42 <lambdabot> http://www.cse.ogi.edu/~jl/Papers/dfs.ps
12:46:47 <ricebowl> maybe it was the quotes
12:46:53 <ricebowl> @google "Structuring Depth-First Search in Haskell"
12:46:54 <lambdabot> http://tunes.org/~nef/logs/haskell/05.10.17
12:46:56 <ricebowl> :p
12:46:57 <Heffalump> hehe
12:47:02 * Heffalump is off
12:47:12 <Heffalump> I do have an implementation of that paper kicking round somewhere, actually
12:47:58 <Cale> Data.Graph
12:48:08 <Heffalump> oh, it's implemented in that?
12:48:14 <Heffalump> ok, I won't bother offering mine then :-)
12:48:19 <xerox> 'levels' ?
12:48:19 <Cale> yeah, not sure if it's quite that version
12:48:23 <Heffalump> (which I probably wrote before that appeared)
12:48:31 <xerox> bind and takeWhile or something
12:48:38 <Heffalump> it's somewhere in the source of mag - http://web.comlab.ox.ac.uk/oucl/research/pdt/progtools/mag/index.html - anyway.
12:48:39 <Cale> xerox: ?
12:48:43 <Heffalump> now I'm really off.
12:48:49 <xerox> @libsrc Data.Graph
12:48:50 <lambdabot> http://darcs.complete.org/fptools/libraries/base/Data/Graph.hs
12:49:11 <Cale> @type Data.Graph.dfs
12:49:12 <lambdabot> Data.Graph.Graph
12:49:12 <lambdabot> -> [Data.Graph.Vertex]
12:49:12 <lambdabot> -> Data.Tree.Forest Data.Graph.Vertex
12:49:22 <xerox> Nah, it wasn't that.
12:49:31 <xerox> Got it wrong hehe.
12:51:58 <xerox> @index levels
12:51:59 <lambdabot> Data.Tree
12:52:01 <xerox> Ah.
12:52:27 <xerox> -- | Lists of nodes at each level of the tree.
12:52:28 <xerox> levels :: Tree a -> [[a]]
12:52:28 <xerox> levels t = map (map rootLabel) $
12:52:28 <xerox> 		takeWhile (not . null) $
12:52:28 <xerox> 		iterate (concatMap subForest) [t]
12:53:22 <Saulzar> Hm, sounds more like bfs?
12:53:54 <Saulzar> Oh, it's a tree
12:59:36 <araujo> @index fileExist
12:59:37 <lambdabot> System.Posix.Files, System.Posix
13:30:06 * araujo just found that '$' doesn't work very well with >>
13:40:35 <[CotL]Godofe_Kei> hi ppl
13:40:39 <[CotL]Godofe_Kei> i need a favor from someone
13:46:02 <goron> Cale: Still there?
13:46:55 <lisppaste2> GOK pasted "GOK" at http://paste.lisp.org/display/14987
13:47:22 <[CotL]Godofe_Kei> can anyone go here http://paste.lisp.org/display/14987?
13:47:57 <[CotL]Godofe_Kei> that code seems to work..it even compiles, but when i run it and enter those or other values
13:48:03 <[CotL]Godofe_Kei> its just freezes hugs
13:48:09 <goron> [CotL]Godofe_Kei: I did, but your code is horrible.
13:48:15 <[CotL]Godofe_Kei> :P
13:48:20 <[CotL]Godofe_Kei> jesus sry...
13:48:22 <[CotL]Godofe_Kei> what can i say
13:48:24 <[CotL]Godofe_Kei> i suck
13:48:26 <goron> [CotL]Godofe_Kei: Use English for code.
13:48:53 <[CotL]Godofe_Kei> want me to repost it in english?
13:49:00 <goron> [CotL]Godofe_Kei: no, just tell me what you want. 
13:49:16 <[CotL]Godofe_Kei> there is the code there
13:49:25 <[CotL]Godofe_Kei> just try run it
13:49:27 <[CotL]Godofe_Kei> it compiles
13:49:40 <goron> [CotL]Godofe_Kei: What would that help?
13:49:42 <[CotL]Godofe_Kei> and paste this: testaConcorrente2 [(1,2,3),(3,4,1),(3,4,2)] [(1,"kjasgd"),(2,"ajhsgd"),(3,"asdsdas")]
13:49:54 <goron> [CotL]Godofe_Kei: I can create an infinite number of non-working programs.
13:49:57 <[CotL]Godofe_Kei> cause when i run it it freezes
13:50:01 <[CotL]Godofe_Kei> oh god
13:50:01 <goron> [CotL]Godofe_Kei: I want to know the semantics.
13:50:11 <[CotL]Godofe_Kei> but i want to know if it runs
13:50:23 <[CotL]Godofe_Kei> maybe it just freezes in my compiler
13:50:27 <goron> [CotL]Godofe_Kei: ok
13:50:28 <[CotL]Godofe_Kei> i dont know that
13:50:41 <goron> [CotL]Godofe_Kei: it's very unlikely to be a bug in the compiler.
13:50:42 <[CotL]Godofe_Kei> cause it should work, and i never seen hugs freeze.
13:51:25 <goron> [CotL]Godofe_Kei: I don't think I have an inverte function. 
13:54:26 <[CotL]Godofe_Kei> oh
13:54:30 <[CotL]Godofe_Kei> sry
13:54:42 <[CotL]Godofe_Kei> inverte :: Int -> (Int,Int,Int,Int)
13:54:42 <[CotL]Godofe_Kei> inverte x = ((div1 `div` 60) `div` 60 ,(div1 `div` 60) `mod` 60,div1 `mod` 60,x `mod` 1000)
13:54:42 <[CotL]Godofe_Kei> 	where div1 = x `div` 1000
13:55:00 <[CotL]Godofe_Kei> can u see why the code could possibly not work?
13:55:57 <ricebowl> > let inverte x = ((div1 `div` 60) `div` 60 ,(div1 `div` 60) `mod` 60,div1 `mod` 60,x `mod` 1000) in inverte 86522001
13:55:58 <lambdabot>  Not in scope: `div1'
13:56:10 <ricebowl> > let inverte x = let div1 = x `div` 1000 in ((div1 `div` 60) `div` 60 ,(div1 `div` 60) `mod` 60,div1 `mod` 60,x `mod` 1000) in inverte 86522001
13:56:12 <lambdabot> (24,2,2,1)
13:56:23 <[CotL]Godofe_Kei> remember that function dude :)?
13:56:26 <ricebowl> yep
13:56:33 <[CotL]Godofe_Kei> i made my own version
13:56:34 <[CotL]Godofe_Kei> it works
13:56:37 <ricebowl> it was obvious what it was doing, but I wanted to check the correctness
13:57:28 * ricebowl can half-read Portuguese and attempts to decipher the paste
13:57:39 <[CotL]Godofe_Kei> lol
13:57:52 <ricebowl> concorrente looks like "concurrent"...humm I can't think of anything else it might be
13:57:55 <[CotL]Godofe_Kei> you dont need to understant
13:58:02 <ricebowl> no, but it helps
13:58:07 <goron> [CotL]Godofe_Kei: I ran it, and it used all my CPU.
13:58:17 <ricebowl> Portuguese has a word "correr" -- "to run", right?
13:58:23 <[CotL]Godofe_Kei> lol yes
13:58:33 <[CotL]Godofe_Kei> so any ideas why it does that?
13:58:36 <araujo> dons, @ping 
13:58:51 <goron> [CotL]Godofe_Kei: I see the bug
13:58:55 <ricebowl> erm, yes
13:58:56 <goron> [CotL]Godofe_Kei: you don't lower n
13:58:57 <ricebowl> the otherwise case
13:59:09 <[CotL]Godofe_Kei> hmm?
13:59:18 <ricebowl> the otherwise case infinitely loops.
13:59:28 <ricebowl> if i3 /= n then it reinvokes itself with the exact same parameters
13:59:34 <[CotL]Godofe_Kei> ah
13:59:45 <[CotL]Godofe_Kei> so |otherwise = testaConcorrente2 ((i1,i2,i3):ys) xs ??
13:59:47 <Cale> newtype Sudoku a = Sudoku (StateT (DiffUArray (Int,Int) Int) Nondet a)
13:59:47 <Cale>     deriving (Functor, Monad, MonadPlus)
13:59:57 <ricebowl> you never consume the second list, anyway, and that's probably not what you want
14:00:05 <goron> Hmm, never mind.
14:00:09 <ricebowl> well, maybe, but I don't know what your code is supposed to do
14:00:10 <Cale> [CotL]Godofe_Kei: btw, what's with the really long nick?
14:00:15 <ricebowl> so I don't know what to recommend
14:00:23 <goron> ricebowl: indeed
14:00:26 <ricebowl> maybe if you give an example then I can help
14:00:38 <ricebowl> goron :)
14:00:42 <[CotL]Godofe_Kei> Cale:ah sry i have this nick for other IRC channel for Dark Galaxy
14:00:54 <[CotL]Godofe_Kei> well ill try to explain
14:01:14 <[CotL]Godofe_Kei> you have this:[(1,2,3),(3,4,1),(3,4,2)]
14:01:15 <goron> How do you call that again, a function that calls itself without a base-case? Infinite recursion? Self-recursion?
14:01:26 <[CotL]Godofe_Kei> (x,y,z)
14:01:28 <ricebowl> self-recursion is just a function invoking itself
14:01:34 <ricebowl> infinite recursion sounds right though
14:02:13 <ricebowl> mutual recursion is two functions that each call each other so that a composition thereof would be self-recursive...
14:02:17 <[CotL]Godofe_Kei> z is the number of a contestant, y is how many minutes he took to complete the race, and x is how many laps he did
14:02:34 <[CotL]Godofe_Kei> so im supose to order those for finishing positions
14:02:44 <[CotL]Godofe_Kei> in fact
14:02:45 <araujo> > [] !! 2
14:02:46 <lambdabot> Add a type signature
14:02:49 <goron> There are >1 million pages mention infinite recursion and 800 self-recursion, but Mathworld says self-recursion.
14:02:53 <[CotL]Godofe_Kei> their all sorted
14:02:54 <araujo> > [] !! 2 :: Int
14:02:55 <lambdabot> Exception: Prelude.(!!): index too large
14:03:08 <araujo> What kind of exception is that?, and how can i catch it?
14:03:09 <[CotL]Godofe_Kei> is anyone listening btw?
14:03:13 <ricebowl> goron - and how many people write "alot" or confuse "its" and "it's" ;)
14:03:14 <ricebowl> [CotL]Godofe_Kei - yes
14:03:20 <[CotL]Godofe_Kei> oh ok
14:03:22 <ricebowl> I'm just waiting for you to come to the point :p
14:03:26 <araujo> I am trying with Control.Exception.catch , but it ain't working
14:03:28 <[CotL]Godofe_Kei> so the numbers are all ordered
14:03:38 <goron> ricebowl: Yes, I know the concepts, I just forgot the name. 
14:03:39 <[CotL]Godofe_Kei> and when i give [(1,"kjasgd"),(2,"ajhsgd"),(3,"asdsdas")]
14:03:44 <ricebowl> araujo - it's just an "error" thingy, whatever that is
14:03:54 <ricebowl> goron - right, I know
14:03:56 <[CotL]Godofe_Kei> wich means the contestant 1 is called "kjasgd", etc....
14:04:04 <[CotL]Godofe_Kei> giving these 2 arguments
14:04:20 <ricebowl> > error "The answer is really 43 :("
14:04:21 <lambdabot> Add a type signature
14:04:29 <ricebowl> > (error "The answer is really 43 :(") :: Int
14:04:30 <lambdabot> Exception: The answer is really 43 :(
14:04:32 <[CotL]Godofe_Kei> it returns: (Number of contestant,Name of contestan,number of laps mande, total lap time)
14:04:40 <goron> http://en.wikipedia.org/wiki/Infinite_loop#Infinite_Recursion
14:04:51 <goron> It seems both are possible. 
14:04:56 <[CotL]Godofe_Kei> so the answer to testaConcorrente2 [(1,2,3),(3,4,1),(3,4,2)] [(1,"kjasgd"),(2,"ajhsgd"),(3,"asdsdas")] should be:
14:05:14 <ricebowl> araujo - up until a couple weeks ago I had GHC source on this box (deleted because I needed space); the (!!) operator just uses error when it hits an empty list
14:05:48 <araujo> @type error
14:05:50 <lambdabot> forall a. [Char] -> a
14:05:55 <[CotL]Godofe_Kei> well u got the point right?
14:06:04 <ricebowl> [CotL]Godofe_Kei - no...
14:06:07 <[CotL]Godofe_Kei> lol
14:06:11 <ricebowl> I'm confused
14:06:13 <[CotL]Godofe_Kei> just look at the 2 arguments
14:06:15 <goron> ricebowl: or people using 'u'. Those are the worst.
14:06:31 <ricebowl> goron - wut r u tryin 2 say d00d :P
14:06:33 <[CotL]Godofe_Kei> the first is already sorted
14:06:50 <[CotL]Godofe_Kei> and the last numbers of each (x,y,z) are the players numbers
14:07:04 <ricebowl> [CotL]Godofe_Kei - yes...how many pieces of data do you have?
14:07:09 <goron> ricebowl: wtf, omg, l3ts do this ROFL!
14:07:29 <[CotL]Godofe_Kei> as many as i want
14:07:36 <[CotL]Godofe_Kei> as many numbers of contestants as i want
14:07:41 <goron> I am not good at this stuff luckily :)
14:07:53 <[CotL]Godofe_Kei> ill post this realy simply
14:07:56 <[CotL]Godofe_Kei> gimme 2 min
14:08:19 <goron> Cale: I can compile GHC :)
14:08:35 <Cale> goron: nice, what fixed it?
14:08:36 <ricebowl> goron - lol omg mam si on fier brbbbb
14:08:47 <araujo> ricebowl, So, the exception show there, what is it?
14:08:48 <Cale> heh
14:08:52 <goron> Some idiot of the FSF probably introduced a bug in Make.
14:08:54 <ricebowl> [CotL]Godofe_Kei - ok... BTW I meant the different lists that you have
14:08:57 <Cale> ah
14:09:03 <goron> Stupid hairy hippies! :P
14:09:05 <ricebowl> araujo - I have no clue
14:09:12 <araujo> Anybody?
14:09:33 <araujo> mm.. Prelude.catch seems not working either....
14:09:37 <ricebowl> araujo - you have to remember, 3 months ago I could not write a single line of Haskell and did not know what a monad was... :P
14:09:49 <ricebowl> I don't know how it works
14:10:08 <Cale> araujo: you catch it as normal
14:10:12 <goron> Cale: I reported the bug, so I guess nobody will fix it. 
14:10:24 <Cale> araujo: but it actually has to occur in the catch
14:10:29 <Cale> goron: heh
14:10:37 <araujo> Cale, yes, right... 
14:10:39 <araujo> mm..
14:10:42 * araujo tries other thing
14:10:51 <Cale> @type Control.Exception.evaluate
14:10:53 <lambdabot> forall a. a -> IO a
14:10:58 <Cale> try that
14:11:44 <ricebowl> > Control.Exception.evaluate ((error "The answer is actually 43") :: Int)
14:11:46 <lambdabot>  Not in scope: `Control.Exception.evaluate'
14:12:01 * ricebowl sits down
14:12:34 <Cale> *Main Control.Exception> Control.Exception.catch (evaluate ([] !! 2)) (\x -> return 0) >>= print
14:12:34 <Cale> 0
14:13:14 <araujo> mm.. let see
14:13:41 <araujo> i was about to try with catchJust ... , though if ihave not made it to work with catch, i doubt it'll work with it....
14:13:52 <Cale> actually, it works without the evaluate
14:14:06 <Cale> *Main Control.Exception> Control.Exception.catch ([] !! 2) (\x -> return 0) >>= print
14:14:06 <Cale> 0
14:15:08 <lisppaste2> GOK pasted "GOk" at http://paste.lisp.org/display/14990
14:15:15 <araujo> mm.. yup... 
14:15:17 <[CotL]Godofe_Kei> Ah finaly
14:15:20 <araujo> definetly, it works...
14:15:20 <Cale> that's actually funny
14:15:27 <[CotL]Godofe_Kei> ricebowl
14:15:30 <[CotL]Godofe_Kei> see if u understand it now
14:15:34 <Cale> since [] !! 2 in that context has type IO a
14:15:35 <araujo> Cale, i must be missing something in the code
14:15:58 <Cale> but the error comes from !!
14:16:22 <Cale> i.e. the evaluation of the IO action, not the execution of it
14:17:35 <araujo> I see.
14:18:45 <ricebowl> ok
14:18:50 <ricebowl> in a moment, reboot time
14:19:01 <araujo> mm..
14:19:02 <[CotL]Godofe_Kei> u understand it like that?
14:19:19 <araujo> Cale, what i am actually doing, is to try to catch the exception from hs-plugins...
14:19:20 <goron> ricebowl: Do you see what I see?
14:19:38 <araujo> i don't know.. is it probably because hs-plugins doesn't propagate the exception?
14:22:07 <Cale> what's the type of the thing which is causing the exception?
14:23:25 <araujo>  eval ("(!! 2) [] :: String") [] :: IO (Maybe String)
14:26:38 <goron> Is doing make install as root(instead of via sudo) considered "stupid"?
14:27:01 <Cale> goron: there shouldn't be a significant difference between those
14:27:03 <[CotL]Godofe_Kei> ricebowl: well? u understand it?
14:27:07 <araujo> Cale, this precise expression: (eval ("(!! 2) [] :: Int") [] :: IO (Maybe Int)) >>= putStrLn . show . fromJust
14:27:31 <Cale> araujo: hmm, it might not be propagating the exception then
14:27:56 <Cale> but I think it has some way to hand you the exception
14:29:46 <araujo> Cale, ok, i'll check it, i thought so... thanks
14:30:06 <[CotL]Godofe_Kei> lol
14:30:28 <[CotL]Godofe_Kei> well i changed the last line and its like this|otherwise = testaConcorrente2 ((i1,i2,i3):ys) xs
14:30:47 <[CotL]Godofe_Kei> and now it gives me this error: 
14:30:55 <[CotL]Godofe_Kei> Program error: pattern match failure: testaConcorrente2 [(Num_fromInt instNum_v30 3,Num_fromInt instNum_v30 4,1),
14:30:55 <[CotL]Godofe_Kei> (Num_fromInt instNum_v30 3,Num_fromInt instNum_v30 4,Num_fromInt instNum_v30 2)] [] 
14:31:25 <ricebowl> [CotL]Godofe_Kei - I just got dinner, hold on...
14:32:14 <goron> Cale: I read the manpage, but it seems a user can execute *any* command via sudo. Then indeed it's almost completely useless. I would expect the user not being able to change kernels at least. 
14:32:23 <ricebowl> [CotL]Godofe_Kei - yes, it's probably the case that one list is empty but not the other
14:32:31 <ricebowl> and you don't have a case for one of them being empty
14:32:35 <[CotL]Godofe_Kei> so how to fix it?
14:32:50 <ricebowl> well technically I guess it's impossible for both to be empty at the same time because of the way your code works...
14:32:53 <ricebowl> well, add a base case for it
14:34:21 <[CotL]Godofe_Kei> hmm
14:34:22 <[CotL]Godofe_Kei> i cant
14:34:57 <ricebowl> [CotL]Godofe_Kei - why don't you just use map for this?
14:34:59 <Cale> goron: well, it's possible to restrict it, but if  sudo su  works, there isn't much difference :)
14:35:00 <[CotL]Godofe_Kei> cause if i do this: testaConcorrente2 [] _ = [] it gives the same eror
14:35:09 <[CotL]Godofe_Kei> map?
14:35:11 <ricebowl> yeah
14:35:20 <ricebowl> you have one list of data and produce another list of data of the same size...
14:35:46 <[CotL]Godofe_Kei> but the content is not the same
14:35:47 <[CotL]Godofe_Kei> hmm
14:35:54 <ricebowl> @type map
14:35:56 <lambdabot> forall b a. (a -> b) -> [a] -> [b]
14:35:59 <ricebowl> that's not a problem though ;)
14:36:05 <[CotL]Godofe_Kei> i know what map does
14:36:12 <[CotL]Godofe_Kei> i just dont understand why this isnt working
14:36:35 <ricebowl> because one of your arrays is empty and it doesn't match any case on the function
14:39:28 <[CotL]Godofe_Kei> but if i define it the same error comes out
14:40:15 <ricebowl> well there are 2 cases that you don't match
14:40:18 <ricebowl> did you define both?
14:40:24 <[CotL]Godofe_Kei> yes
14:41:00 <[CotL]Godofe_Kei> if i define this testaConcorrente2 [] _ = [] then only the first case comes out
14:41:32 <[CotL]Godofe_Kei> actualy, if i do that it gives error
14:41:46 <[CotL]Godofe_Kei> if i do this: testaConcorrente2 _ [] = [] it only gives the first case
14:42:16 <ricebowl> you probably meant to consume one element from both arrays for each iteration, but I'm still confused
14:42:54 <[CotL]Godofe_Kei> u stil dont understand whats it suposed to do?
14:44:09 <[CotL]Godofe_Kei> basicly it maches z from (x,y,z) to the number in the other argument (z"asdsad")
14:44:10 <Cale> heh, I have a framework now where the brute force sudoku solver is 3 lines :)
14:44:16 <Cale> solve = forM_ [(i,j) | i <- [1..9], j <- [1..9]] $ \(i,j) -> do
14:44:16 <Cale>     a <- option [1..9]
14:44:16 <Cale>     place (i,j) a
14:44:24 <[CotL]Godofe_Kei> if it is the same then do that operation, otherwise keep looking
14:44:32 <[CotL]Godofe_Kei> for all the elements in the list
14:44:35 <[CotL]Godofe_Kei> its simples
14:44:37 <[CotL]Godofe_Kei> simple*
14:46:39 <ricebowl> they're not in the same order?
14:49:06 <Cale> and, the following actually works in a reasonable amount of time:
14:49:10 <Cale> solve :: Sudoku ()
14:49:10 <Cale> solve = forM_ [(i,j) | i <- [1..9], j <- [1..9]] $ \(i,j) -> do
14:49:10 <Cale>     v <- valAt (i,j)
14:49:10 <Cale>     if v == 0
14:49:10 <Cale>         then do a <- option [1..9]
14:49:11 <Cale>                 place (i,j) a
14:49:13 <Cale>         else return ()
14:49:30 <Cale> Monads are fun :)
14:49:43 <[CotL]Godofe_Kei> ricebowl: ??
14:49:47 <[CotL]Godofe_Kei> what do u mean?
14:50:27 <[CotL]Godofe_Kei> the first argument in in places order, so the first is the contestant who got 1st prize and so on...
14:50:48 <[CotL]Godofe_Kei> and the second argument is ordered 1,2,3,4,5,etc... contestants
14:58:36 <Cale> It just uses a state transformed nondeterminism monad, and the only nontrivial thing I needed to write was place :: (Int, Int) -> Int -> Sudoku (), which determines if the requested move is valid and updates the state array if it is.
15:04:27 <Cale> hmm, I wonder how the list monad performs
15:06:36 <Saulzar> Hm, what is forM_ ? mapM_ with the argument order switched?
15:06:43 <Cale> yeah
15:08:08 <palomer> :o
15:08:09 <Cale> wow, the list monad performs better
15:08:13 <Saulzar> and that's a brute force solver? A lot of magic in the background.
15:08:22 <Cale> just backtracking
15:08:29 <palomer> someone explain me the reader monad:P
15:09:03 <Cale> palomer: it's just a monad where you have access to an environment
15:09:11 <Saulzar> What is the state used for? option ?
15:09:15 <Cale> which you can read from, but not write to
15:09:29 <Cale> the state is used to carry along the board array
15:09:45 <Saulzar> Ah, I was wondering if option was random generated
15:10:51 <Saulzar> What is the definition of Sudoku ? (the haskell definition)
15:10:52 <Cale> not random
15:10:59 <Cale> newtype Sudoku a = Sudoku (StateT (DiffUArray (Int,Int) Int) [] a)
15:10:59 <Cale>     deriving (Functor, Monad, MonadPlus)
15:11:20 <Pupeno> I am developing HaArguments, a set of functions and data type to manage program arguments (those that you get with getArgs). What name do you reccomend for the module (currently called ProgramArguments) ? Where do I put it on the library hierachy ?
15:11:21 <Cale> runSudoku (Sudoku k) = head (runStateT k initialSudokuArray)
15:11:22 <Cale> evalSudoku = fst . runSudoku
15:11:22 <Cale> execSudoku = snd . runSudoku
15:11:38 <Cale> Pupeno: System?
15:11:51 <Pupeno> Cale: System.Arguments ?
15:11:59 <Cale> that seems good
15:12:03 <Cale> you might want to claim that
15:13:11 <Pupeno> Argument or Arguments  (for the module name) ?
15:13:45 <Saulzar> Hmm
15:14:23 <Cale> Arguments
15:15:44 <Cale> funny
15:16:12 <Cale> Nondet is faster if I compile, and List is faster if I don't
15:17:57 <palomer> Cale: yeah, but how does the reader monad work?
15:18:38 <palomer> ugh, I have to learn tons of haskell to be able to do this
15:18:43 <Saulzar> So basically it is trying out all possible valid values for each square for all "current" solutions which are the state with array
15:19:00 <Cale> Oh, a value of type (Reader e a) is basically just a function (e -> a)
15:19:12 <Cale> yeah
15:19:34 <Cale> return x = const x
15:19:53 <Saulzar> Amazingly concise :)
15:20:00 <palomer> Cale: so I simply create a datatype e and each element of the datatype will be mapped to a value
15:20:06 <palomer> how do I update this value?
15:20:19 <palomer> with bind?
15:20:31 <palomer> no wait, that won't work
15:20:36 <Cale> well, the value of type e doesn't actually change
15:20:56 <palomer> Cale: the value of e? isn't it the value of an element of e?
15:20:56 <Cale> join x = \k -> x k k
15:21:06 <Cale> type e
15:21:20 <Cale> and fmap f x = f . x
15:21:52 <Cale> but what you are allowed to do is to run a computation with a modified environment
15:21:59 <palomer> a value of type (Reader e a) sends elements of e to elements of a
15:22:42 <palomer> so how can we speak of the value of type e?
15:22:51 <palomer> the actual datatype?
15:23:34 <Cale> e is the environment type which you will later provide
15:23:42 <Cale> to the computation
15:24:01 <palomer> yeah
15:24:03 <Cale> this is perhaps easiest to understand in terms of the state monad
15:24:15 <palomer> I've never seen the state monad
15:24:22 <Cale> a reader monad is just like a state monad where you're not allowed to change the state
15:24:31 <Cale> i.e. you have get, but not put
15:25:47 <Cale> @type Control.Monad.Reader.ask
15:25:49 <lambdabot> forall r (m :: * -> *).
15:25:49 <lambdabot> (Control.Monad.Reader.MonadReader r m) =>
15:25:49 <lambdabot> m r
15:26:07 <Cale> of course, that's in all its overloaded glory
15:26:21 <{Arias}> .... a function to filter a list whit values of another list?
15:26:24 <Cale> really, it's just  ask :: Reader r r
15:26:43 <{Arias}> for explample [1,2,3,4] [2,4] -> [1,3]
15:27:02 <Cale> > [1,1,2,3,4,5] \\ [1,2,3]
15:27:04 <lambdabot> [1,4,5]
15:27:24 <Cale> > filter (`notElem` [1,2,3]) [1,1,2,3,4,5]
15:27:26 <lambdabot> [4,5]
15:27:37 <{Arias}> thnaks :D
15:28:15 <Cale> @pl \filter xs ys -> filter (`notElem` xs) ys
15:28:16 <lambdabot> (. flip notElem)
15:28:20 <Cale> @pl \xs ys -> filter (`notElem` xs) ys
15:28:21 <lambdabot> filter . flip notElem
15:29:10 <{Arias}> mmm cool
15:29:16 <{Arias}> :t filter . flip notElem
15:29:19 <{Arias}> @t filter . flip notElem
15:29:19 <lambdabot> Maybe you meant: todo todo-add todo-delete topic-cons topic-init topic-
15:29:19 <lambdabot> null topic-snoc topic-tail topic-tell type .
15:29:33 <{Arias}> @type filter . flip notElem
15:29:34 <lambdabot> forall a. (Eq a) => [a] -> [a] -> [a]
15:29:45 <{Arias}> thanks a lot :D
15:29:57 <palomer> Cale: I still don't understand how to use the reader monad
15:30:24 <Cale> > runReader (do { x <- ask ; return (x + 1) }) 5
15:30:26 <lambdabot> 6
15:30:35 <Cale> there's a trivial example
15:30:53 <Cale> note that the computation I passed doesn't know the environment value, but can use it anyway
15:31:09 <Cale> later, I pass in the environment value '5'
15:31:28 <Cale> this is sort of a trivial usage
15:32:02 <palomer> Cale: so you read and update at the same time?
15:32:21 <Cale> no, just read, and then return a value based on that
15:32:31 <palomer> so reading is done with ask
15:32:39 <Cale> right
15:33:11 <Cale> local :: (r -> r) -> Reader r a -> Reader r a
15:33:36 <Cale> this lets you alter the environment locally
15:34:49 <palomer> why is it r->r?
15:35:41 <Cale> > let myComputation = do {x <- ask; y <- local (\x -> x + 5) anotherComputation; return (x + y)}; anotherComputation = do { x <- ask; return (x * 2) } in runReader myComputation 5
15:35:44 <lambdabot> 25
15:35:56 <Cale> see if you can follow that
15:36:34 <Cale> local takes a function which modifies the current environment, and runs the specified computation in the modified environment
15:37:34 <Cale> so, say, if you had a function which added a variable/value pair to a lookup table, you might pass that function to local, and run the rest of the computation with the updated lookup table
15:38:02 <palomer> hrm
15:38:08 <rep> http://www.puresimplicity.net/~hemi/Pics/Misc/pets/jinx/kool-cat.jpg
15:38:13 <palomer> I thought an environment was a mapping e -> a
15:38:27 <palomer> and you get values from your environment from ask
15:38:37 <palomer> but, shouldn't ask take an element of e?
15:38:39 <Cale> rep: do you ever actually talk about haskell, or just post silly pictures?
15:39:00 <rep> Cale depends :)
15:39:03 <Cale> e is r
15:39:18 <palomer> ok, shouldn't ask take a value of r and return a value of a?
15:39:19 <Cale> Reader r a is isomorphic to r -> a
15:39:23 <rep> lately i've been in a "silly pictures" phase
15:39:24 <Cale> nope
15:39:34 <Cale> it takes a function which modifies the environment
15:39:39 <Cale> rep: heh
15:39:54 <Cale> palomer: and runs the given computation in that modified environment
15:41:44 <palomer> Cale: y <- local ... modifies the environment
15:41:48 <palomer> right?
15:41:53 <palomer> now, where's the code to be run?
15:41:55 <Cale> y <- local f c
15:41:58 <palomer> (doesn't bind take 2 arguments?)
15:42:02 <Cale> will run the computation c
15:42:30 <Cale> with an environment which is f applied to the current environment
15:42:41 <Cale> and bind the result to y
15:42:53 <palomer> the current environment is of type f -> a
15:43:05 <Cale> r
15:43:14 <Cale> the current environment is of type r
15:43:20 <palomer> so you need to pass something which is of type (r->a)->(r->a)
15:43:27 <Cale> er, what?
15:43:33 <Cale> no
15:43:43 <Cale> the function r -> a isn't the environment
15:43:47 <Cale> it's the whole thing
15:43:53 <palomer> f applied to the current environment<--what's the type of f?
15:43:58 <Cale> r -> r
15:44:32 <Cale> local :: (r -> r) -> (r -> a) -> (r -> a), essentially
15:44:46 <Cale> and there aren't that many functions like that
15:45:10 <Cale> in our bare-bones representation of the reader monad,
15:45:26 <Cale> local f c = c . f
15:45:38 <palomer> so say my previous environment was {1=>5,2=>6} and I use f = \x->x+2 then my new environment is {3=>5,2=>6}?
15:45:48 <Cale> um
15:45:56 <palomer> err
15:46:01 <palomer> {3=>5,4=>6}
15:46:08 <Cale> {1=>5,2=>6} -- that doesn't look like a Num
15:46:19 <Cale> so \x -> x + 2  won't work
15:46:57 <Cale> In my previous example, the environment type was just Integer
15:47:06 <Cale> > let myComputation = do {x <- ask; y <- local (\x -> x + 5) anotherComputation; return (x + y)}; anotherComputation = do { x <- ask; return (x * 2) } in runReader myComputation 5
15:47:08 <lambdabot> 25
15:47:16 <Cale> sorry about the poor formatting :)
15:47:43 <Cale> but basically, 'myComputation' is run with environment 5
15:47:43 <palomer> ok, local takes an environment and a computation and returns the result of that computation in that enviroment, right?
15:47:59 <Cale> almost right
15:48:19 <Cale> it could do that, but it would be a little more awkward in lots of cases if it did
15:48:53 <Cale> that's about the same as passing a constant function as the first parameter to local
15:49:18 <Cale> return . runReader does that too
15:49:22 <palomer> so that's local...
15:49:24 <Cale> er
15:49:26 <palomer> what about ask?
15:49:28 <Cale> well, close to that :)
15:49:56 <Cale> Ask is nothing less than the identity function :)
15:50:11 <Cale> (it's only useful because of the syntax of things)
15:50:42 <Cale> > runReader ask 5
15:50:44 <lambdabot> 5
15:50:55 <Cale> > runReader (ask >>= \x -> x + 1) 5
15:50:57 <palomer> x <- ask; foo is >>= ask foo, right?
15:50:57 <lambdabot>   Occurs check: cannot construct the infinite type: r = Reader r b
15:50:57 <lambdabot>   Expected type: r
15:50:57 <lambdabot>   Inferred type: Reader r b
15:51:02 <Cale> oops
15:51:11 <Cale> > runReader (ask >>= \x -> return (x + 1)) 5
15:51:12 <lambdabot> 6
15:51:37 <Cale> well, it's the identity function, wrapped up as a Reader r r
15:52:30 <Cale> in this case, ask :: Reader Integer Integer
15:52:31 <araujo> Merry christmas for everyone.
15:52:34 * araujo off to eat
15:52:46 <Cale> it just gives the environment as its return value.
15:53:28 <palomer> so ask returns the identity environment
15:53:46 <Cale> it returns the environment
15:54:15 <Cale> I don't know what an identity environment would be
15:54:44 <Cale> like, say the environment type was, oh,  Array Int String
15:54:48 <palomer> well, erm, there would be an environment for every type
15:55:11 <palomer> identity environment
15:55:18 <Cale> Reader doesn't have to worry about anything like that, though Writer does
15:55:30 * palomer is very, very confused right now
15:55:33 <Cale> okay
15:55:33 <palomer> note that I'm a monad newbie
15:55:36 <Cale> yeah
15:55:52 <Cale> These are the 'computation-like' monads
15:56:03 <Cale> as opposed to the 'container-like' monads
15:56:12 <palomer> sure
15:56:15 <Cale> you can still think of them as containers, but it's a little strange that way
15:57:01 <Pupeno> see you latter! merry christmas and happy haskelling!
15:57:07 <Cale> if you like the container view, a value of type Reader r a is a huge container, indexed by values of type r, and at each index, it holds a value of type a
15:57:13 <Cale> Pupeno: later!
15:58:27 <palomer> ok, so reader is a function from elements of r to elements of a
15:58:29 <Cale> If you like the computation view, a value of type  Reader r a  is a computation which results in a value of type a, but which may read from a global environment of type r
15:58:32 <Cale> yes
15:58:46 <Cale> r is called the environment type
15:58:56 <Cale> and a is called the result type
15:59:13 <Cale> dinner time
15:59:18 <Cale> I'll be back in a bit
15:59:20 <palomer> sure
16:21:02 <Cale> back
16:27:52 <{Arias}> bye, happy christmas
16:38:50 <Cale> hehe, my solver even managed to solve this one, after several minutes :) http://www.menneske.no/sudoku/eng/showpuzzle.html?number=2155141
16:40:34 <Cale> (on all of the other Sudoku I've given it, it's only taken at most a couple of seconds)
16:45:55 <araujo> Cale, whatis your solver?
16:55:01 <TuringTest> Cale: try this "8.......1...95.................7.42.3.16...............4....57.6..3.8.........2.."  (left to right, top to bottom)
16:57:28 <Cale> okay
16:58:57 <Cale> starting...
17:00:24 <TuringTest> Cale: Also difficult to attack logically is ".....24..56.......1.........2.16..........85.....3....3......16..8..4......7....."
17:03:35 * TuringTest looks at watch
17:03:44 <Cale> yeah, it definitely takes some time :)
17:03:46 <TuringTest> Frohe Weinachten!
17:03:52 <Cale> hm?
17:03:59 <TuringTest> Merry Christmas
17:04:04 <Cale> ah :)
17:04:11 <Cale> Merry Christmas to you too
17:04:34 <exsisonek> on Sudoku: are they pure deduction, or do harder sudoku require constructing large hypotheticals? the ones in the free paper can be solved with no provisional guesses, but they're not hard
17:05:12 <yozora> the diabolical ones seem to require guessing, unless I'm missing something
17:05:14 <Cale> my solver is just a plain backtracking solution, implemented as follows in a monad which I constructed specifically for the purpose:
17:05:23 <Cale> solve = forM [(i,j) | i <- [1..9], j <- [1..9]] $ \(i,j) -> do
17:05:23 <Cale>     v <- valAt (i,j)
17:05:23 <Cale>     if v == 0
17:05:23 <Cale>         then do a <- option [1..9]
17:05:23 <Cale>                 place (i,j) a
17:05:24 <Cale>         else return ()
17:05:56 <Cale> all that place (i,j) a does is test if it's possible to put the value a at position (i,j)
17:06:09 <Cale> (and if so, puts it there)
17:06:29 <Cale> otherwise, it fails, which causes backtracking
17:07:01 <Cale> newtype Sudoku a = Sudoku (StateT (DiffUArray (Int,Int) Int) Nondet a)
17:07:02 <Cale>     deriving (Functor, Monad, MonadPlus)
17:07:05 <Cale> that's the monad :)
17:07:14 <TuringTest> I implemented the dancing links algorithm for sudoku that Knuth suggested.
17:08:15 <Cale> I figure there must be some decent graph colouring algorithms which one could use
17:09:54 * TuringTest points to http://en.wikipedia.org/wiki/Dancing_Links
17:10:05 <Cale> Well, it's taking a lot of time, but at least it's not chewing up any memory :)
17:12:45 <TuringTest> Dancing Links uses mutable doubly linked lists, and runs quite fast in Haskell
17:14:00 <TuringTest> Cale: Still running?
17:16:33 <Cale> yeah
17:16:55 <Cale> I wonder what the complexity is like :)
17:17:06 <TuringTest> My suggested board only has 17 starting hints.  That makes 64 empty squares. 
17:17:27 <TuringTest> 2^64 is essentially too big for brute force, cryptographically speakiing.
17:17:55 <TuringTest> 9^64 is...well..bigger.  But your system backtracks before being that bad.
17:18:00 <Cale> well, it's more like 9^64, but then there's constraints
17:18:05 <Cale> yeah
17:18:11 <TuringTest> > 2^64
17:18:12 <lambdabot> 18446744073709551616
17:18:21 <Cale> > 9^64
17:18:22 <lambdabot> 11790184577738583171520872861412518665678211592275841109096961
17:18:26 <exsisonek> hmm, one-time-pads by n-sudoku
17:18:29 <TuringTest> Somewhere in that range.
17:18:31 <Cale> hehe
17:19:05 <Cale> yeah, it's not likely to finish :)
17:19:05 <TuringTest> Well..it solves faster with a reasonable algorithm.
17:19:10 <Cale> right
17:19:17 * TuringTest killed Cale's program.
17:19:50 <Cale> However, the monad which I'm using is easily modified to implement Dancing Links too :)
17:19:58 <TuringTest> Sudoku is NP-Complete so some level of "brute force" is always needed in the general case.
17:22:42 <TuringTest> I took Knuth's paper and implemented the pseudo code first.  Then I got a straight port of the c-code working, but it was *ugly* (he uses a bunch of goto's).  But by then I understood how it worked so I was able to clean it up.  Later I added a module to attack it logically before triggering the dancing links attack.  The ones I posted had the minimal number of hints and could not be attacked logically with my routin
17:23:58 <Cale> Couldn't you implement it with a Set and a static array?
17:24:57 <TuringTest> The algorithm gets it speed from mutable links, the mutation is the dance.
17:24:58 <Cale> hmm, perhaps that's not the same, complexity wise
17:25:17 <araujo> @index isLeft
17:25:18 <lambdabot> Graphics.HGL.Window, Graphics.HGL.Core, Graphics.HGL, Graphics.SOE
17:26:03 <araujo> @index fromLeft
17:26:04 <lambdabot> bzzt
17:26:09 <araujo> @index Left
17:26:10 <lambdabot> Data.Either, Prelude
17:26:25 <TuringTest> You can delete from a doubly linked list and later undo the deletion with ease.  Very very fast.  And it is greedy, taking the tightest constraint first.
17:26:41 <TuringTest> But doubly linked mutable lists in Haskell are not the normal idiom.
17:27:18 <Cale> Yeah, I'm just thinking about how to translate this into something more idiomatic.
17:27:36 <TuringTest> They can be hidden inside (forall s. ST s), which is what I ultimately did.  So it is functional from the outside, producing a list of solutions given a starting specification.
17:27:39 <exsisonek> actually there's an interesting quasi-cryptographic technique here: use a sudoku on a big enough number basis as a one-time pad, and store a (provably) minimal set of clues for recoverability
17:28:51 <TuringTest> exsisonek: NP-Complete problems are not a good basis for cryptographic functions, as there are usually "weak keys" that are hard to avoid.
17:29:51 <TuringTest> Cale: The pseudo-code Knuth writes can be made into fairly idiomatic Haskell
17:29:55 <exsisonek> good to know
17:30:11 <Cale> hmm, I think I can do it idiomatically, only having to add an additional (log n) to the complexity.
17:31:13 <palomer> Cale: so...what about those reader monads, eh?
17:31:33 <Cale> palomer: have you looked harder at that piece of example code I gave?
17:32:14 <palomer> could you msg it to me so that it doesn't run off my buffer?
17:35:32 <palomer> thx
17:40:52 <palomer> I've never seen const used in code
17:40:55 <palomer> is it still used?
17:41:31 <TuringTest> it is a useful abbreviation 
17:42:08 <palomer> what does it do?
17:42:16 <Cale> const x y = x
17:42:21 <Cale> or
17:42:26 <Cale> const x = \y -> x
17:42:43 <palomer> const = \x y-> x ?
17:42:48 <palomer> that's K
17:42:50 <Cale> sure :)
17:42:51 <Cale> yes
17:43:24 <palomer> the YAHT instantiates Maybe with augment  (Just x) f = f x
17:43:33 <palomer> I don't understand what augment does
17:43:43 <palomer> (it's for the Computation typeclass)
17:44:16 <palomer> like, what does it represent?
17:44:30 <TuringTest> Cale: If you want to stress your solver, http://www.csse.uwa.edu.au/~gordon/sudoku17 is a list of inequivalent 17 hint puzzles
17:45:22 <Cale> nice :)
17:46:01 <Cale> palomer: what does  augment Nothing  return?
17:46:28 <palomer> \x -> Nothing
17:48:27 <Cale> palomer: what page?
17:48:34 <palomer> 112
17:48:42 <Cale> that looks a lot like bind
17:48:58 <palomer> I have to admit that I don't understand bind very well
17:49:03 <palomer> (this is the chapter before monads)
17:49:04 <Cale> ah
17:49:08 <Cale> yeah, it's bind
17:49:25 <palomer> so, erm, it takes a continuation?
17:49:30 <Cale> yeah
17:49:48 <Cale> > Just 5 >>= \x -> return (x+1)
17:49:49 <lambdabot> Just 6
17:49:54 <Cale> > Nothing >>= \x -> return (x+1)
17:49:55 <lambdabot> Nothing
17:50:20 <TuringTest> > [2,4,6] >>= \x -> return (x+1)
17:50:21 <palomer> gotcha
17:50:22 <lambdabot> [3,5,7]
17:50:28 <palomer> why is it called augment?
17:50:42 <Cale> because they're dancing around the idea of a monad
17:50:54 <palomer> what's the relationship between >>= and fmap again
17:51:17 <TuringTest> @type >>=
17:51:18 <lambdabot> parse error on input `>>='
17:51:29 <TuringTest> @type Control.Monad.>>=
17:51:30 <lambdabot> parse error on input `Control.Monad.>>='
17:51:36 <TuringTest> sigh
17:51:39 <Cale> @type (>>=)
17:51:40 <lambdabot> forall (m :: * -> *) b a. (Monad m) => m a -> (a -> m b) -> m b
17:51:47 <TuringTest> @type fmap
17:51:49 <lambdabot> forall (f :: * -> *) b a. (Functor f) => (a -> b) -> f a -> f b
17:52:04 <Cale> @type Control.Monad.join
17:52:06 <lambdabot> forall a (m :: * -> *). (Monad m) => m (m a) -> m a
17:52:30 <TuringTest> @type swap . fmap
17:52:31 <lambdabot> Not in scope: `swap'
17:52:31 <palomer> join is a member of Monad?
17:52:45 <palomer> @index Control.Monad
17:52:46 <lambdabot> bzzt
17:52:48 <palomer> >index Control.Monad
17:53:11 <TuringTest> > join [[1,2],[3,4,5],[6,7,8,9]]
17:53:13 <lambdabot> [1,2,3,4,5,6,7,8,9]
17:53:15 <TuringTest> join for list is concat
17:53:16 <Cale> it really ought to be in the definition of the class
17:53:16 <palomer> and why does Monad require both >>= and >> ?
17:53:26 <Cale> It doesn't really
17:53:27 <TuringTest> (
17:53:35 <Cale> there's a default instance
17:53:38 <Cale> er
17:53:42 <Cale> a default definition
17:53:47 <TuringTest> (>>) is like (>>=) but it ignores the parameter being passed
17:53:54 <Cale> x >> y = x >>= const y
17:54:14 <TuringTest> (a >> b) is (a >> (\ ignored -> b))
17:54:17 <palomer> yeah, so why must we define >> if we have >>= (doesn't come for free)
17:54:18 <Cale> and fail is stupid and shouldn't be there at all
17:54:27 <Cale> you don't have to
17:54:31 <Cale> you're allowed to
17:54:31 <palomer> Cale: how would we get around fail?
17:54:38 <Cale> just not include it :)
17:54:46 <Cale> It's not part of the definition of a monad
17:54:48 <palomer> what if the computation fails?
17:54:50 <TuringTest> It could be an extra type class
17:55:05 <Cale> palomer: computations which fail should really be in the MonadZero class
17:55:30 <TuringTest> Or error...
17:55:34 <Cale> which was removed from Haskell 98 for some stupid reason -- I think because all the existing instances were also instances of MonadPlus
17:56:00 <Cale> MonadPlus is where you really start to see interesting uses of failure anyway
17:56:07 <TuringTest> Or exception...
17:56:17 <Cale> or Exception type things
17:56:27 <TuringTest> And IO uses fail = error, I believe
17:56:27 <palomer> ok, I have a better grasp of monads
17:56:33 <Cale> I think there should be MonadZero, and subclasses MonadElse and MonadPlus
17:56:35 <palomer> but I still can't make heads or tails of monad reader
17:57:04 <Cale> palomer: I think the Reader monad is best looked at after you understand State. It's too simple
17:57:19 <palomer> State is a subclass of Monad?
17:57:20 * TuringTest agrees with Cale
17:57:36 <Cale> MonadState is a subclass of Monad
17:57:37 <palomer> oh, it's the next chapter of YAHT
17:57:44 <Cale> but State is a monad
17:57:47 <Cale> well
17:57:53 <Cale> State s for any type s is a monad
17:58:20 <TuringTest> "subclass" is an OO concept and thus maps poorly to Haskell type classes
17:58:41 <Cale> 'subclass' is used in the Report
17:59:01 * TuringTest pretends not to hear that
17:59:06 <Cale> and I think it fits
17:59:25 <Cale> Since one natural representation of classes is as sets of their members
18:00:20 <Cale> That is, one might as well think of Monad as the set of all type constructors m such that Monad m.
18:00:43 <palomer> so, anyone willing to give a wack at making me understanding the State monad constructor?
18:00:48 <Cale> And then a subclass of Monad is simply a subset which is a typeclass.
18:01:24 * TuringTest goes to bed.  Merry Christmas.
18:01:31 <Cale> (State s a) is the type of computations which return a value of type 'a', and have access to a mutable value of type 's'
18:01:40 <Cale> Goodnight TuringTest 
18:02:18 <Cale> An implementation for State is as  newtype State s a = State (s -> (a,s))
18:02:55 <Cale> The idea here being that the computation takes a state, and returns a value, together with a new state.
18:03:02 <palomer> State appears twice, is that even legal?
18:03:18 <Cale> Those two are in separate namespaces
18:03:35 <Cale> the first is a type constructor, the second a data constructor
18:04:02 <Cale> It's because of Haskell's strange syntax for datatypes
18:04:12 <Cale> In the GADT syntax, it'd be:
18:04:30 <Cale> newtype State s a where
18:04:44 <Cale>    State :: (s -> (a,s)) -> State s a
18:05:12 <Cale> Sort of clearer that one is in value-land and the other in type-land
18:05:35 <palomer> shouldn't that be datatype State s a where ...
18:05:43 <Cale> could be
18:05:46 <Cale> data
18:06:06 <palomer> data == newtype ?
18:06:14 <Cale> but we're essentially renaming an existing type, so we can use newtype to avoid the extra baggage
18:06:36 <palomer> okay
18:06:51 <Cale> Normally, data constructors exist as boxes at runtime, and you incur some extra performance loss
18:07:03 <carp> newtypes can only have one contructor
18:07:04 <Cale> as well as the fact that they change the semantics a bit
18:07:06 <Cale> right
18:07:43 <Cale> newtype basically creates a new type in the type system which is implemented in exactly the same way as an existing type
18:08:22 <carp> also list and tuple syntax is in both namespaces (i suppose) which always seems weird to me
18:08:22 <Cale> so the "data constructor" you have is completely virtual -- the type system uses it to make sure things work and then the compiler throws it away
18:08:46 <palomer> okay, so we have this one constructor datatype State
18:09:01 <palomer> who's constructor takes a function from states to state,value pairs
18:09:07 <Cale> right
18:09:16 <palomer> value,state pairs
18:09:17 <palomer> gotcha
18:09:31 <Cale> now, try writing return
18:09:44 <Cale> just taking into consideration the types involved
18:09:51 <Cale> return :: a -> State s a
18:10:34 <palomer> return x = \z -> (x,z)
18:10:43 <Cale> yeah, essentially
18:10:47 <palomer> err
18:10:50 <palomer> return x = State \z -> (x,z)
18:10:53 <Cale> yeah
18:11:23 <Cale> now, bind is more complicated
18:11:37 <Cale> if you'd like you can try writing it, or I could type it out :)
18:11:58 <palomer> the State type represents values which are state
18:12:06 <palomer> states to me are environments
18:12:12 <Cale> er
18:12:41 <palomer> surely functions from states to value,state pairs could not describe state!
18:12:48 <Cale> they can
18:13:04 <Cale> usually this is how you manage state in a functional language
18:13:14 <palomer> it looks like a list!
18:13:15 <Cale> by passing it around and returning it from your functions
18:13:35 <palomer> bind :: m a -> (a -> m b) -> m b, right?
18:13:42 <Cale> right
18:15:02 <Cale> now, there's more than one implementation for this, so you kind of have to be careful
18:15:29 <Cale> and remember that bind is supposed to be chaining the computations together in sequence
18:15:44 <palomer> (\State f) g = g f
18:15:47 <palomer> is that bind?
18:16:03 <Cale> nope, it's actually significantly more complicated :)
18:16:06 <palomer> bind (State f) g = g f
18:16:10 <palomer> but it has the right type!
18:16:13 <Cale> oh?
18:16:43 <palomer> oh wait, maybe not
18:17:20 <Cale> It might help to define:
18:17:31 <Cale> runState (State s) = s
18:18:54 <palomer> hrmph
18:19:37 <palomer> if I had a state, then I could get a state,value pair
18:19:44 <Cale> yeah
18:19:50 <palomer> I could pass it to the term of type (a-> m b)
18:19:55 <palomer> and then get an m b
18:20:03 <palomer> getting this initial state is tough stuff
18:20:18 <Cale> right
18:20:41 <palomer> so..how do I do it?
18:20:46 <Cale> so since you can't get an initial state, you'll have to start off with the State data constructor
18:21:08 <Cale> because it takes a function from the initial state
18:21:27 <Cale> so it'll free you from having to provide one :)
18:21:34 <palomer> I don't see how
18:21:44 <palomer> wait...
18:22:55 <palomer> State $ \x-> g.f x
18:23:30 <Cale> getting closer to the idea, but there's still the problem of types
18:23:39 <palomer> bind (State f) g = State $ \x-> g (f x)
18:23:42 <palomer> that should type check!
18:23:58 <Cale> *Main> let bind (State f) g = State $ \x-> g (f x)
18:23:58 <Cale> *Main> :t bind
18:23:58 <Cale> bind :: State s a1 -> ((a1, s) -> (a, s)) -> State s a
18:24:27 <Cale> Not quite the type you're looking for though
18:24:57 <palomer> bind (State f) g = State $ \x-> g (runState (f x))
18:25:15 <palomer> @type \(State f) g = State $ \x-> g (runState (f x))
18:25:17 <lambdabot> parse error on input `='
18:25:22 <palomer> @type \(State f) g  State $ \x-> g (runState (f x))
18:25:23 <Cale> type error
18:25:24 <lambdabot> parse error on input `$'
18:25:30 <palomer> @type \(State f) g ->( State $ \x-> g (runState (f x)))
18:25:32 <lambdabot> Not in scope: data constructor `State'
18:25:32 <lambdabot>  
18:25:32 <lambdabot> <interactive>:1:17: Not in scope: data constructor `State'
18:25:46 <Cale> <interactive>:1:49:
18:25:46 <palomer> oh, good point
18:25:46 <Cale>     Couldn't match `State s a' against `(a1, s1)'
18:25:46 <Cale>       Expected type: State s a
18:25:46 <Cale>       Inferred type: (a1, s1)
18:25:46 <Cale>     In the application `f x'
18:25:47 <Cale>     In the first argument of `runState', namely `(f x)'
18:26:14 <palomer> bind (State f) g = \x-> g  (f x)
18:26:24 <palomer> that should do it
18:26:38 <Cale> *Main> let bind (State f) g = \x-> g  (f x)
18:26:38 <Cale> *Main> :t bind
18:26:38 <Cale> bind :: State s a -> ((a, s) -> t) -> s -> t
18:27:15 <palomer> oh right, you need that initial state!
18:27:51 <Cale> bind x f = State $ \s -> let ... in ...
18:28:41 <Cale> I think it's actually clearer not to use pattern matching for 'x' here
18:29:03 <palomer> bind x f = State $ \s -> let u = runState x; v = g u in v
18:29:18 <palomer> oh wait, no!
18:29:27 <palomer> bind x f = State $ \s -> let u = runState x; v = g u in runState v
18:29:37 <Cale> runState :: State s a -> s -> (a, s)
18:29:47 <palomer> I think we have a winner!
18:29:54 <Cale> s isn't getting used there
18:30:32 <Cale> runState really takes two parameteres
18:30:36 <Cale> parameters*
18:31:01 <palomer> bind x f = State $ \s -> runState (g ((runState x) s))
18:31:14 <palomer> hrmphrm
18:31:16 <palomer> ignore that last one
18:31:31 * palomer curses the egg nog
18:31:47 <Cale> It's pretty tricky, but it's worthwhile to see how it works :)
18:32:25 <Cale> okay, so presently, you're passing x to runState, which gives you a function from states to value,state pairs
18:32:27 <carp> runState is the destructor
18:32:32 <carp> or it could be
18:32:54 <Cale> so, you probably want to apply the result to a state right away
18:33:01 <palomer> bind x f = State $ \s -> let u = runState x s in g u
18:33:33 <palomer> bind x f = State $ \s -> let u = runState x s in runState (g u) s
18:33:59 <palomer> that should work
18:34:05 <Cale> bind :: State s a -> ((a, s) -> State s a1) -> State s a1
18:34:08 <Cale> close :)
18:34:22 <Cale> runState x s is returning a tuple
18:34:25 <Cale> (a pair)
18:34:27 <palomer> yes
18:34:30 <palomer> is this a problem?
18:34:41 <Cale> well, you'll want to rip that pair apart first
18:34:44 <palomer> m a -> (a -> m b) -> m b
18:35:09 <Cale> want: bind :: State s a -> (a -> State s b) -> State s b
18:35:19 <Cale> have: bind :: State s a -> ((a, s) -> State s b) -> State s b
18:35:47 <palomer> bind x f = State $ \s -> let u = runState x s in runState (g (snd u)) s
18:35:55 <palomer> > snd (1,2)
18:35:57 <lambdabot> 2
18:36:25 <Cale> *Main> let bind x f = State $ \s -> let u = runState x s in runState (f (snd u)) s
18:36:25 <Cale> *Main> :t bind
18:36:25 <Cale> bind :: State s a -> (s -> State s a1) -> State s a1
18:36:50 <Cale> now it has the right type, but it's the one possible wrong version of this -- it doesn't quite do what we want
18:37:05 * palomer bites T-shirt off
18:37:12 <Cale> because it passes the original state to the second computation, and drops the new one we got
18:37:30 <Cale> bind x f = State $ \s -> let (y,s') = runState x s in ...
18:37:38 <palomer> bind x f = State $ \s -> let u = runState x s in runState (g (snd u)) (fst u)
18:37:42 <Cale> right
18:37:47 <palomer> ding ding ding!
18:37:55 <Cale> modulo the f/g thing
18:38:14 <palomer> bind x f = State $ \s -> let u = runState x s in runState (f (snd u)) (fst u)
18:38:20 <Cale> bind x f = State $ \s -> let (y,s') = runState x s in runState (f y) s'
18:38:36 <palomer> so I can think of state as a list of values
18:38:38 <palomer> indexed by time
18:38:42 <Cale> hmm
18:38:43 <palomer> seriously, state looks like a list though
18:38:58 <Cale> sort of, but not quite
18:39:10 <palomer> or, rather, state is a function which changes State
18:39:21 <palomer> (seems counter intuitive to use the same word for types and constructor
18:39:33 <palomer> and while changing State returns a value
18:39:40 <Cale> yeah
18:40:01 <Cale> and as you can see
18:40:06 <Cale> x >>= f
18:40:15 <palomer> data State a s = ChangeState (a->(s,a)) <--seems more intuitive
18:40:26 <carp> now what is it that's strange/unrealistic about this state
18:40:40 * carp hears a voice in his head
18:41:20 <Cale> data StateTransformer s a = ChangeState (s->(a,s))
18:41:34 <Cale> sure
18:41:48 <Cale> it's the type of State transformers
18:42:36 <Cale> or computations which can update some piece of state while returning a value
18:42:48 <Cale> so, some handy values in this monad...
18:42:57 <Cale> get :: State s s
18:42:59 <palomer> do {(x,y)<-someStateChanger initialState ; (x',y') <- someStateChanger y; print (x,x')} <--this is an example of using the state monad?
18:43:09 <carp> you get something for free that isn't what you'd expect or something...
18:43:34 <Cale> palomer: it's going to save you the trouble of keeping track of state parameters
18:43:59 <Cale> get = State $ \s -> (s,s)
18:44:06 <Cale> also
18:44:15 <Cale> put :: s -> State s ()
18:44:44 <Cale> put k = State $ \s -> ((),k)
18:45:17 <Cale> with these two, I can give a reasonably decent simple example
18:45:25 <palomer> get seems kind of silly
18:45:30 <Cale> inc = do { x <- get; put (x+1) }
18:45:50 <Cale> get just does the very simple thing of copying its state to its output
18:46:39 <Cale> with get and put, we can hide the State data constructor and never use it again
18:46:55 <palomer> so inc = \x -> (x+1,\y -> (y+1, \z -> .....))) ?
18:47:19 <Cale> inc = State $ \s -> ((), s + 1)
18:47:37 <Cale> is how we might otherwise write it
18:47:43 <palomer> we'll never be able to use the state, no?
18:47:47 <Cale> hm?
18:48:17 <Cale> we can mutate the state with put, we can observe it with get, and we're free to return any value we like
18:48:26 <carp> right i'm off
18:48:32 <palomer> hrmphrm
18:48:33 <Cale> see you carp 
18:48:34 <carp> happy christmas
18:48:56 <palomer> how can we ever use inc?
18:49:18 <Cale> > let inc = do { x <- get; put (x+1) }; runState { inc; inc; inc; get } 0
18:49:19 <lambdabot>  parse error on input `;'
18:49:24 <Cale> > let inc = do { x <- get; put (x+1) } in runState { inc; inc; inc; get } 0
18:49:25 <lambdabot>  parse error on input `;'
18:49:37 <Cale> > let inc = do { x <- get; put (x+1) } in runState (do { inc; inc; inc; get }) 0
18:49:39 <lambdabot>  Not in scope: `get'
18:49:43 <Cale> blah
18:49:48 <Cale> no state monad here
18:50:11 <Cale> Prelude Control.Monad.State> let inc = do { x <- get; put (x+1) } in runState (do { inc; inc; inc; get }) 0
18:50:11 <Cale> (3,3)
18:51:03 <palomer> the last expression in the second do is get
18:51:04 <Cale> evalState x s = fst (runState x s)
18:51:11 <Cale> execState x s = snd (runState x s)
18:51:11 <palomer> get is State $ \s -> (s,s)
18:51:19 <Cale> right
18:51:24 <palomer> runState get should be \s -> (s,s)
18:51:44 <Cale> Prelude Control.Monad.State> let inc = do { x <- get; put (x+1) } in evalState (do { inc; inc; inc; x <- get; inc; inc; return x }) 0
18:51:44 <Cale> 3
18:52:40 <Cale> note that since x gets the value of the state after 3 inc's, it's 3, and even though we increment the state a couple more times, that isn't seen by evalState
18:52:50 <Cale> Prelude Control.Monad.State> let inc = do { x <- get; put (x+1) } in execState (do { inc; inc; inc; x <- get; inc; inc; return x }) 0
18:52:50 <Cale> 5
18:53:01 <Cale> execState returns the final state, and drops the result
18:53:20 <palomer> but execState should return a function
18:53:27 <Cale> it does
18:53:34 <Cale> and I'm applying that function to 0
18:53:43 <palomer> oh hoh!
18:53:45 <palomer> I think I get it
18:53:55 <Cale> :)
18:54:19 <Cale> so now we have a simple imperative programming language with a single mutable variable
18:54:52 <Cale> but behind the scenes, it's all functional :)
18:55:08 <palomer> okay, I think I get it
18:55:31 <palomer> but wait, when you do
18:55:33 <palomer> inc;inc;inc
18:55:41 <palomer> doesn't that ignore the result of each call?
18:55:54 <Cale> yeah, but it still passes the state through
18:56:16 <Cale> do {inc; inc; inc} = inc >> inc >> inc
18:56:39 <palomer> sure
18:56:47 <palomer> and >> = \x y = y, no?
18:56:50 <Cale> = inc >>= const inc >>= const inc
18:58:36 <palomer> how is >> officially defined as?
18:59:29 <Cale> well, it's officially in Haskell 98 defined to be a member function of the class Monad
18:59:49 <Cale> with a default implementation as  x >> y = x >>= \k -> y
19:00:31 <palomer> x >> y = bind x \k -> y
19:00:53 <palomer> which means take an element of the monadic type, say x, and pass it to the continuation \k -> y
19:00:54 <Cale> x >> y = bind x (\k -> y)
19:00:56 <palomer> which means ignore it!
19:01:15 <Cale> yes, but bind may be doing more things
19:01:36 <Cale> write out the definition of bind again :)
19:01:48 <palomer> can I copy/paste:P?
19:01:49 <Cale> bind x f = State $ \s -> let (y,s') = runState x s in runState (f y) s'
19:01:55 <Cale> I will :)
19:02:05 <Cale> so
19:02:06 <palomer> phew, I thought I had to rewrite it from scratch
19:02:20 <palomer> so the s is ignore with >>
19:02:33 <palomer> ignore what  Ijust said
19:02:45 <Cale> bind x (const y) = State $ \s -> let (v,s') = runState x s in runState ((const y) v) s'
19:02:59 <Cale> = State $ \s -> let (v,s') = runState x s in runState y s'
19:03:08 <Cale> !!! s'
19:03:34 <Cale> the state still gets through
19:04:46 <palomer> but the value is lost
19:04:52 <Cale> right
19:05:04 <Cale> the return value of the left computation is thrown away
19:05:11 <Cale> only any side effects are preserved
19:05:24 <palomer> hrm
19:05:29 <Cale> the return value of inc is () anyway
19:05:56 <palomer> yeah, we just care about how inc changes the state
19:06:01 <Cale> right
19:06:35 <palomer> so, we could have done all this with data State = State (a->a) 
19:06:47 <Cale> erm
19:06:52 <Cale> I don't think so
19:07:04 <Cale> oh
19:07:12 <Cale> data State s = State (s->s)
19:07:15 <Cale> like that?
19:07:17 <palomer> yeah
19:07:23 <Cale> yeah, but then we don't have a monad
19:07:40 <Cale> only a monoid
19:08:06 <palomer> a group without inverses?
19:08:13 <Cale> yeah
19:08:56 <palomer> ok, how does this relate to reader monad?
19:09:32 <Cale> okay, so  Reader r a  is just like  State s a, except that computations aren't permitted to change the state.
19:09:45 <Cale> the initial state just gets passed down to everything
19:10:11 <Cale> So it's like having a global per-run constant.
19:10:31 <palomer> it's a restricted form of State
19:10:35 <Cale> yeah
19:10:49 <palomer> wait, shouldn't I use State for my lambda calculator?
19:10:55 <Cale> you could
19:11:06 <palomer> why is the monad reader more appropriate?
19:11:08 <Cale> but I think the suggestion to use Reader is kind of elegant
19:11:29 <palomer> but I need to generate new variable names
19:11:31 <palomer> nothing more!
19:11:43 <Cale> well, you can use state
19:11:51 <Cale> if you're interested in generating names
19:12:07 <palomer> how would I use the monad reader?
19:12:59 <Cale> I'll have to think some more about the details, but I think the idea is to use local whenever you need to locally bind a variable during the evaluation, and keep a table.
19:13:30 <palomer> once you have new variable names, everything else is a breeze
19:14:15 <Cale> you can get a unique supply with just State and getNew = do { v <- get; inc; return v }
19:14:47 <palomer> yeah, but then I have to update the state everytime I use getNew, no?
19:14:59 <Cale> no, it's doing that with inc :)
19:15:34 <palomer> no way
19:17:05 <palomer> main = do {printLn (getNew initialState);printLn (getNew initialState)} <--this is totally wrong
19:17:19 <Cale> getNew is a State monad thing
19:17:53 <dmg_> Hi there!
19:17:57 <Cale> hi!
19:18:21 <dmg_> I've got a quick question regarding ghc-6.4.1 build.
19:18:33 <Cale> palomer: so you'd write your evaluator in the State monad, and then runState at the end to get the result.
19:18:54 <palomer> Cale: it must be hell to compose monads
19:19:22 <Cale> palomer: well, we haven't gotten to Monad transformers, but let's just say that there's a reasonably elegant way :)
19:20:01 <dmg_> During execution of make all -wr in ghc/compiler, the process visually hangs. Stracing and printing debug messages showed: make prunes "main/Config.hs"
19:20:15 <palomer> ok, so what's the deal with monad readers?
19:20:17 <dmg_> uncounted number of times, more and more between each target built.
19:20:46 <dmg_> stracing showed no syscalls other than printing that debug message "pruning tils main/Config.hs"
19:20:56 <dmg_> sorry "pruning file ..."
19:20:56 <palomer> why were they recommended to me:o
19:21:05 <dmg_> Has anybody encountered this?
19:21:22 <dmg_> GNU Make version 3.79, by Richard Stallman and Roland McGrath
19:21:24 <palomer> runState will return a State a s, no?
19:22:14 <Cale> dmg_: there was someone else with a problem with make recently
19:22:24 <Cale> dmg_: he had 3.81
19:22:34 <Cale> I have 3.80, and I have no noticeable problems
19:22:48 <dmg_> Cale, do you remember when? I'll look up in the irc logs.
19:22:49 <Cale> and he said it must have been a bug in the new version
19:22:57 <Cale> earlier today
19:23:21 <Cale> palomer: runState returns an (a,s)
19:23:33 <Cale> after applying it to a State s a and a value of type s
19:23:51 <dmg_> Thanks, will look in the today's log.
19:24:32 <palomer> Cale: so a = string and s = lambda terms?
19:25:11 <Cale> palomer: If you like. You could also just use an integer, and construct a string from it
19:25:48 <palomer> regardless, the state type is going to be lambda terms
19:25:54 <Cale> er
19:25:55 <Cale> hmm
19:25:59 <Cale> oh
19:26:03 <Cale> perhaps
19:26:05 <palomer> and the value types the integers or strings
19:26:19 <palomer> s/types/type
19:26:21 <Cale> I was thinking you just needed a unique name supply
19:26:26 <Cale> for that, the state type is Integer
19:26:35 <Cale> and the result type is lambda terms
19:26:50 <palomer> there's a result type?
19:27:16 <Cale> yeah, in (State s a), we call s the state type and a the result type
19:27:24 <palomer> yeah, that's what I meant
19:27:30 <palomer> s = string and  a = lambda term
19:27:36 <Cale> ah, yeah
19:28:06 <palomer> wait, that doesn't make sense
19:28:16 <Cale> I think s = Integer makes more sense
19:28:28 <Cale> since then you just have some function to turn integers into strings
19:28:36 <Cale> integers are easier to increment :)
19:28:44 <palomer> and ChangeState :: s -> (a,s) ?
19:28:54 <Cale> yeah
19:29:09 <Cale> State :: (s -> (a,s)) -> State s a
19:29:33 <dmg_> OK, saw that: username "goron", description exactly as mine.
19:29:39 <palomer> so out of an integer I'm supposed to get a lambda term?
19:29:48 <Cale> dmg_: yeah, that's who it was
19:30:10 <Cale> palomer: well, it depends on what you're using the state for
19:30:28 <palomer> getting new variable names to avoid capture
19:30:34 <Cale> okay
19:30:53 <Cale> so what type of state will you need to keep track of the used up names?
19:31:20 <palomer> that's what I've been asking:o
19:31:25 <palomer> state = integer
19:31:27 <Cale> I suppose if you want to be really careful, you can use a Set
19:31:45 <Cale> but integers will do
19:31:54 <palomer> I'll just start with "__x1" and move on to "__x2",...
19:31:58 <Cale> yeah
19:32:29 <Cale> getNewVar = do { n <- get; inc; return ("__x" ++ n) }
19:32:48 <palomer>            does that type check?
19:32:55 <Cale> yep
19:32:55 <palomer> oh yes, it does
19:33:08 <palomer> oh yes, that'll work
19:33:26 <Cale> just don't touch the state otherwise
19:33:36 <palomer> return x = \k -> (x,k), right?
19:33:44 <Cale> yeah
19:33:45 <palomer> I wrote it before
19:33:47 <palomer> okay
19:34:00 <palomer> seems kind of unintuitive that I need to wrap my final term in a state
19:34:29 <palomer> wait, this'll go in my substitute function
19:34:33 <palomer> which will be run many times
19:34:42 <palomer> so my substitute also needs to return a state?
19:34:43 <palomer> argh!
19:34:46 <Cale> right
19:35:16 <Cale> basically, this state monad thing is just keeping track of your name supply
19:35:17 <palomer> this doesn't buy me much
19:35:27 <Cale> It buys you enough :)
19:35:41 <palomer> I still have to pass around the state everywhere
19:35:44 <Cale> as long as you don't need new variables, you just wrap your return values in return
19:35:47 <palomer> and I might have to pass around multiple states
19:35:53 <Cale> *you* don't pass it :)
19:36:01 <palomer> yes
19:36:04 <palomer> I need to pass it to substitute
19:36:25 <Cale> the only place where you actually see the state is putting in the initial 0
19:36:47 <Cale> (and, indirectly, whenever you get a new name)
19:37:39 <Cale> but you'll see lots of "State Integer" in the types
19:37:54 <Cale> btw, I also made a monad expressly for this purpose at one point
19:38:30 <palomer> t [u/v] = if capture is possible (state,term) = avoidCapture t initialState
19:38:38 <palomer> avoidCapture needs an initialstate every time it is run!
19:38:55 <palomer> (avoidCapture=substitution)
19:39:11 <Cale> t [u/v] :: Term -> State Integer Term
19:39:16 <Cale> [u/v] :: Term -> State Integer Term
19:39:34 <palomer> so everything becomes State Integer Term
19:39:39 <Cale> yeah
19:39:43 <palomer> this could work
19:39:50 <palomer> and then at the very top I extract the final term
19:40:13 <Cale> yep
19:40:43 <palomer> this seems interesting
19:40:46 <palomer> I'll have to try it
19:40:51 <palomer> and State is included in the library?
19:40:58 <Cale> Yep, Control.Monad.State
19:41:15 <Cale> (you might look that up, as there are more functions and values I didn't mention)
19:41:26 <palomer> and it's implemented in the same manner as you just made me do?
19:41:28 <Cale> yep
19:41:37 <palomer> but wait, return ignores the state!
19:41:46 <Cale> it just passes it through
19:41:54 <Cale> without touching it
19:41:58 <palomer> ahh, gotcha
19:42:13 * palomer will have to code this thing
19:42:22 <palomer> and then...a theorem prover to rival djinn!
19:42:48 <Cale> hence  do { <stmts1>; return () ; <stmts2> } = do { <stmts1> ; <stmts2> }
19:43:06 <Cale> which always confuses C programmers
19:43:10 <dmg_> Just upgraded make to 3.80 (marked the "latest stable": what is 3.81 anyway?) The build process seems to have bypassed the "magic" point.
19:43:13 <dmg_> Thank Cale
19:43:20 <Cale> dmg_: no problem :)
19:43:53 <Cale> palomer: there's one little design flaw here which we could easily fix too
19:44:05 <dmg_> Bye everybody, Merry Christmas!
19:44:36 <Cale> provided you're willing to pass -fglasgow-exts to GHC, or write {-# OPTIONS_GHC -fglasgow-exts #-} at the top of your source file :)
19:44:53 <Cale> (well we could fix it anyway, but it would be more hassle)
19:45:24 <Cale> The problem is that anyone can come along and mutate the integer in the state
19:45:35 <Cale> not just the function you provide to produce new names
19:45:55 <Cale> which is poor encapsulation
19:46:22 <Cale> To fix it, we can use a module, and make our own monad, (but let the compiler do most of the work for us)
19:46:55 <Cale> newtype Unique a = Unique (State Integer a) deriving (Functor, Monad)
19:46:57 <palomer> oh no, only functions I write could mutate the state
19:47:04 <palomer> since the state is only passed around locally
19:47:23 <Cale> well, that's true
19:47:39 <Cale> but there are functions other than the unique name supplier that can access the state
19:48:03 <palomer> locally
19:48:11 <Cale> yeah, in the evaluator
19:49:16 <Cale> if anything you write having type (State Integer a) decides to put 0, then the whole scheme gets messed up (possibly)
19:49:56 <Cale> You can construct, in just a few lines, a monad which only has the unique name supply
19:50:17 <palomer> by fixing how we can change the state?
19:50:21 <Cale> yeah
19:50:33 <palomer> so we'd supply const and inc and that's it
19:50:43 <Cale> only provide a "primitive" which provides a name
19:50:49 <palomer> 2 primitives
19:50:54 <Cale> no, just one :)
19:51:04 <Cale> it provides the name and updates the state in one shot
19:51:10 <Cale> and you never get to see the state
19:51:32 <palomer> but sometimes we need to pass along the state
19:51:41 <Cale> no, you always do that with bind
19:52:01 <palomer> for return
19:52:10 <Cale> well, it's going to be a monad
19:52:16 <Cale> so it'll have return and bind
19:52:35 <palomer> so we wouldn't have acces to the State constructor
19:52:41 <Cale> right
19:52:47 <Cale> well, our new constructor
19:52:58 <palomer> yeah
19:53:07 <palomer> and return would be fixed
19:53:19 <palomer> and we'd only export inc
19:53:51 <palomer> and initialState
19:53:59 <palomer> am I missing anything?
19:54:05 <Cale> module Unique
19:54:05 <Cale> import Control.Monad.State
19:54:05 <Cale> newtype Unique a = Unique (State Integer a) deriving (Functor, Monad)
19:54:05 <Cale> evalUnique (Unique u) = evalState u 0
19:54:05 <Cale> fresh = Unique $ do { v <- get; put (v+1); return v }
19:54:26 <Cale> oh
19:54:29 <Cale> wait :)
19:55:19 <Cale> {-# OPTIONS_GHC -fglasgow-exts #-}
19:55:19 <Cale> module Unique (evalUnique, fresh) where
19:55:19 <Cale> import Control.Monad.State
19:55:19 <Cale> newtype Unique a = Unique (State Integer a) deriving (Functor, Monad)
19:55:21 <Cale> evalUnique (Unique u) = evalState u 0
19:55:22 <Cale> fresh = Unique $ do { v <- get; put (v+1); return v }
19:55:24 <Cale> there
19:55:36 <Cale> er, damn
19:55:44 <Cale> add Unique to the export list
19:55:56 <Cale> (note that it refers to the type and not the constructor)
19:56:30 <Cale> oh
19:56:36 <Cale> hmm, that doesn't seem to    matter
19:56:59 <Cale> yeah, don't add it to the export list
19:57:53 <palomer> Unique, evalUnique and fresh ?
19:58:02 <Cale> no, just what I had
19:58:08 <Cale> it'll export the type anyway
19:58:27 <palomer> Unique corresponds to our old State constructor
19:58:31 <Cale> er
19:58:32 <Cale> hmm
19:58:33 <palomer> and fresh to inc?
19:58:44 <Cale> perhaps I'm silly
19:59:00 <Cale> let me check if you need to add it :)
20:01:02 <Cale> aha, you do
20:01:12 <Cale> (Unique, evalUnique, fresh)
20:01:16 <Cale> that's all you export
20:01:54 <palomer> what's evalUnique?
20:02:05 <Cale> that's your substitute for evalState
20:02:31 <palomer> it's the actual substitute function?
20:02:35 <palomer> why do we need anything else?
20:03:02 <Cale> evalUnique :: Unique a -> a
20:03:20 <Cale> that is, it runs the Unique monad, and returns the final result
20:03:29 <Cale> fresh just gives you a new integer
20:03:38 <Cale> which was never returned by fresh before
20:03:49 <Cale> each time that you call it
20:03:59 <Cale> (each time it's executed in the monad)
20:04:20 <palomer> and what's Unique?
20:04:43 <Cale> the monad
20:04:53 <Cale> which you'll use in place of State Integer
20:05:24 <Cale> *Main> evalUnique $ do { x <- fresh; y <- fresh; z <- fresh; return (x,y,z) }
20:05:24 <Cale> (0,1,2)
20:05:30 <palomer> Unique is a type?
20:05:38 <Cale> Unique is a type constructor
20:05:49 <palomer> and why does it need to be exported?
20:05:50 <Cale> (also a data constructor, but we're not exporting that)
20:05:59 <Cale> because you're going to want to use that type
20:06:18 <palomer> it wouldn't work if you didn't export it?
20:06:23 <Cale> right
20:06:35 <Cale> You're not exporting the Unique data constructor though
20:06:42 <palomer> oh, that's what you were debating before
20:06:46 <Cale> right
20:06:48 <palomer> (this is different from sml)
20:06:53 <Cale> yes
20:07:11 <Cale> I was wavering on the export list syntax :)
20:07:58 <palomer> the first expression in a do block is going to have to be x <- fresh, rigth?
20:08:00 <Cale> To export the constructor, you'd put Unique (Unique), or Unique (...) which means export all constructors.
20:08:13 <Cale> palomer: only if you need a fresh variable
20:08:18 <palomer> so it's pointless to export constructor if you're not going to export the type?
20:08:23 <Cale> right
20:08:30 <Cale> and in fact, you can't
20:08:39 <Cale> it's just syntactically impossible
20:08:49 <palomer> gotcha
20:09:42 <Cale> you might want to write  freshVar = do { v <- fresh; return ("__x" ++ show v) } again
20:10:24 <palomer> eval (App (Lambda t v) u) = substitute t u v -- t[u/v] <--how would I do this?
20:11:30 <palomer> would I have to write eval (App (Lambda t v) u) = return (substitute t u v) ?
20:11:35 <Cale> nope
20:12:16 <Cale> substitute :: Term -> Term -> Term -> Unique Term ?
20:12:20 <Cale> seems right
20:12:30 <palomer> oh
20:13:32 <Cale> maybe eval will apply runUnique
20:13:50 <palomer> would that work?
20:13:51 <Cale> hmm
20:13:57 <Cale> but not if it's recursive :)
20:14:03 <palomer> of course it is!
20:14:08 <palomer> actually, will any of this work?
20:14:21 <Cale> (well, are you going just one step, or doing the whole thing)
20:14:23 <palomer> I mean, you can think of evaluation as a tree
20:14:36 <palomer> eval will take one big step
20:15:08 <palomer> bah, I guess it will work because eval either stops or calls substitute
20:15:09 <Cale> do { x <- eval stuff; y <- eval otherstuff; return (f x y) }
20:15:39 <palomer> what's f?
20:15:57 <Cale> well, whatever you do to recombine the results of the two recursions
20:16:29 <palomer> hrmph
20:16:35 <palomer> so if I use small step evaluation
20:16:37 <palomer> this won't work
20:16:42 <Cale> It'll still work
20:16:52 <Cale> but you can't evalUnique too early
20:16:56 <Cale> hmm
20:16:59 <Cale> actually
20:17:07 <Cale> right
20:17:14 <Cale> yeah, that's right :)
20:17:19 <palomer> who's right?
20:17:48 <Cale> you just don't apply evalUnique unless you're done (or want to spy on a partially evaluated result)
20:17:54 <xah_> Happy Holidays, knights of the lambda. =(^_^)=
20:18:06 <Cale> :)
20:18:15 <palomer> happy holidays xah_
20:18:24 <Cale> happy holidays!
20:18:43 <palomer> calling evalUnique would be a bad idea, wouldn't it
20:18:51 <Cale> palomer: unless you're finished
20:19:09 <palomer> but, you see, you need to call evalUnique to find out if you're finished
20:19:15 <Cale> if you call it, and then go back to evaluating, you'll end up recreating names which you've already used
20:19:29 <Cale> oh, that's fine, you still have the other copy around :)
20:19:48 <Cale> it's not like it's going to destructively update your Unique Term into a Term
20:19:55 <palomer> good point
20:20:40 <Cale> anyway, I'll be back in a little bit
20:21:07 <palomer> hrmph
20:21:23 * palomer wonders if all these shenanigans are worth it
20:21:28 <Cale> hehe
20:21:36 <Cale> well, in general yeah
20:21:46 <palomer> but, like, this is 3 lines of code in sml!
20:21:49 <Cale> note that we've only really written 5 or 6 lines of code
20:21:55 <Cale> 3 lines?
20:21:57 <Cale> of what?
20:22:03 <palomer> mutability!
20:22:31 <lispy> hmm...where can i get an interactive debugger for ghc programs?
20:22:34 <Cale> but it doesn't offer the same guarantees about use, most likely :)
20:22:37 <palomer> local val a = ref 0 in fun getNext = (x:=(!x)+1;!x) end
20:22:46 <palomer> err, make that val x = ref 0
20:23:21 <Cale> however, you have no guarantee that nothing else modifies x
20:23:27 <palomer> and now all your functions have strange types
20:23:35 <palomer> Cale: sure: local
20:23:35 <Cale> not that strange :)
20:23:50 <palomer> local means x is accessible by getNext and getNext alone
20:23:57 <Cale> ah, okay
20:24:35 <Cale> however, the fact that you now have no guarantees about referential transparency throughout the language seems like a big loss
20:25:00 <palomer> Cale: ghc can't guarentee referential transparency!
20:25:22 <Cale> Haskell 98 does.
20:25:34 <Cale> and we're not using the extensions which break it
20:25:41 <palomer> true
20:25:46 <Cale> (only newtype deriving)
20:26:37 <Cale> newtype deriving is completely harmless and very convenient. If you have a newtype (not a data) you can use deriving to pull any class instances from the old type to the new type.
20:26:57 <palomer> I still don't see the difference between a 1 constructor newtype and a datatype
20:27:06 <Cale> okay
20:27:11 <palomer> except for what you just mentioned
20:27:30 <Cale> data MyData = D Int
20:27:42 <Cale> newtype MyNewType = N Int
20:27:53 <Cale> f (D x) = 0
20:27:59 <Cale> g (N x) = 0
20:28:10 <Cale> f (D undefined) == 0
20:28:21 <Cale> but g (N undefined) == undefined
20:28:40 <palomer> eh?
20:28:41 <Cale> since the N is really just a tag to convince the type system
20:28:42 <palomer> why is this?
20:29:06 <Cale> and really, N 5, is represented *exactly the same* as 5 at runtime
20:29:10 <lispy> N x doesn't atually construct anything where as D x does
20:29:29 <Cale> whereas D 5 is a box with a pointer to an Int (or an unevaluated thunk)
20:29:31 <palomer> so newtypes are type synonyms in disguise
20:29:35 <Cale> yeah
20:29:42 <Cale> but the type system enforces things
20:29:57 <palomer> so what's the undefined integer? 0?
20:30:00 <lispy> so newtypes are come efficient?
20:30:07 <Cale> bottom
20:30:18 <Cale> lispy: yeah, they're more efficient
20:30:24 <Cale> > undefined :: Int
20:30:24 <palomer> why is f _|_ = 0 ?
20:30:26 <lambdabot> Undefined
20:30:33 <lispy> come == more, blueh, i can't type
20:30:40 <Cale> f (_|_) == _|_
20:30:44 <Cale> f (D _|_) == 0
20:31:00 <Cale> that is, D _|_ isn't the same as _|_
20:31:01 <palomer> but _|_ and D _|_ are the same thing, no?
20:31:03 <Cale> no
20:31:22 <Cale> _|_ is an error, D _|_ is a box with a pointer to an error
20:31:23 <lispy> Cale: but can't ghc make a one constructor data just as efficient as a newtype?
20:31:41 <palomer> ah, gotcha
20:31:44 <palomer> now I understand
20:31:46 <Cale> lispy: maybe in some very special cases
20:31:50 <lispy> palomer: remember that D is a function
20:32:19 <palomer> if it had been newtype Foo = N Bar, then g (N undefined) == 0
20:32:19 <Cale> anyway
20:32:19 <pediddle> so is N the identity function (with a restricted type)?
20:32:27 <Cale> I should go, I'll be back in a bit
20:32:55 <Cale> pediddle: yeah, at runtime, N in fact doesn't even exist
20:33:19 <Cale> (whereas D is represented by a data structure with a pointer in it)
20:33:46 <lispy> see ya
20:35:41 <Cale> taken together with the fact that you can avoid exporting newtype constructors, you can think of them as proof to the compiler that your function is permitted to deconstruct the value.
20:36:35 <Cale> (or construct it for that matter)
21:05:26 <yozora> which extensions to haskell 98 break referential transparency?
21:06:42 <Cale> yozora: FFI, implicit/linear implicit parameter
21:06:45 <Cale> s
21:08:37 <Cale> The FFI extension is responsible for unsafePerformIO, which is the worst offender :)
21:09:31 <Cale> It breaks the type system even, by letting you write a function cast :: a -> b
21:12:57 <Cale> (despite the fact that that function will rarely do anything except introduce undefined behaviour and bugs)
21:20:16 <yozora> oh yeah, i remember hearing about the implicit parameter one
21:20:43 <yozora> monads or those crazy configurations are supposed to be preferable
21:21:17 <Cale> yeah, I'd say just use a monad
21:23:37 <Cale> That's (one of the things) the Reader monad is for.
21:23:55 <Cale> er
21:25:54 <Cale> I apologise for the grammar there, the parenthesised bit not being removable :)
21:43:19 <Pupeno> Hello! Merry Christmas.
21:46:22 <yozora> Merry Christmas
22:19:26 <palomer> man
22:19:37 <palomer> if sun is going to supply us with the only java library
22:19:45 <palomer> they should at least spend more time ironing out the bugs
22:22:49 <Cale> what are you using Java to write?
23:23:28 <Saulzar> I imagine they spent quite a while ironing bugs
23:24:07 <mjl69> for all holidays: happy holidays!
23:29:42 <Cale> hehe, the problem is that they're probably writing the Java library in Java
23:30:56 <Saulzar> It's not that bad, it's just slightly verbose :)
23:43:52 <audreyt> dons: I have a better implementation of isPrefixOf
23:44:56 <audreyt> http://perlcabal.org/~autrijus/isPrefixOf.txt
23:45:23 <audreyt> dons: also, *prod* hsplugins
23:55:02 <dons> audreyt, on holidays, but send me the code for isPrefixOf
23:55:28 <dons> i'll look to get an hs-plugins done in the next few days, but I won't be able to release till I'm back in sydney
23:55:32 <dons> in about a week
