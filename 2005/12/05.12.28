00:00:24 <Cale> Since you can only supply one pattern, it's more obvious that you either have to be really sure that's what you're getting, or expect failures to be handled in the monad.
00:01:05 <eivuokko> It is (strange thing to do)?  I match tuples (and other sincle constructor, for example newtypes) that way all the time.
00:01:20 <Cale> well, tuples, sure
00:01:27 <Cale> Just x <- ...
00:01:34 <Cale> should set off alarm bells :)
00:01:38 <eivuokko> Mhm.  Ok, I try to make use for it.  Maybe it'll come to me.
00:02:00 <Cale> It's really nice in the Maybe monad in particular
00:02:30 <eivuokko> Yeah, I see your point about sort of guards, esp with list and Maybe.
00:02:36 <Cale> yeah
00:02:57 <Cale> This also happens in list comprehensions
00:03:27 <eivuokko> I don't usually use list comprehension.  I think they are hard to read because a lot of operator-type characters.
00:03:34 <Cale> > [x | Just x <- [Just 5, Nothing, Just 7]]
00:03:35 <lambdabot> [5,7]
00:03:46 <eivuokko> Heh.
00:04:04 <Cale> they're sometimes clearer than do-notation or concatMap/filter
00:04:26 <eivuokko> That'd have taken a moment for me to get if not for the context of discussion.
00:05:14 <Cale> > [(x,y,z) | x <- [1..20], y <- [x..20], z <- [y..20], x^2 + y^2 == z^2]
00:05:15 <lambdabot> [(3,4,5),(5,12,13),(6,8,10),(8,15,17),(9,12,15),(12,16,20)]
00:06:15 <Cale> doing that without list comprehensions or do-notation is somewhat annoying :)
00:06:53 <Cale> > do x <- [1..20]; y <- [x..20]; z <- [y..20]; guard $ x^2 + y^2 == z^2; return (x,y,z)
00:06:55 <lambdabot> [(3,4,5),(5,12,13),(6,8,10),(8,15,17),(9,12,15),(12,16,20)]
00:07:29 <Cale> that works too, but the emphasis is somewhat different to me
00:08:22 <eivuokko> I prefer do-syntax here, but in truth I didn't know it exists.
00:08:35 <eivuokko> Or I don't understand how it works under the hood.
00:08:45 <Cale> well, List is a monad
00:08:53 <Cale> return x = [x]
00:09:01 <Cale> x >>= f = concatMap f x
00:09:17 <Cale> join xss = concat xss
00:09:27 <Cale> fmap f xs = map f xs
00:09:50 <sieni> > let f n = case n of 0 -> [0]; x -> x `mod` 53: f (x `div` 53) in map (['!'..'U']!!) $ f 7848290
00:09:51 <lambdabot> "STFU!"
00:10:00 <Cale> heh
00:10:44 <Cale> another important piece of the puzzle there is guard
00:10:48 <araujo> Hello.
00:10:58 <Cale> > guard True :: [Integer]
00:10:59 <lambdabot> Couldn't match `Integer' against `()'
00:11:03 <Cale> > guard True :: [()]
00:11:04 <lambdabot> [()]
00:11:09 <Cale> > guard False :: [()]
00:11:10 <lambdabot> []
00:11:29 <Cale> right
00:12:23 <Cale> so what happens, is that if the guard fails, an empty list is returned, and [] >>= f = [] for any f, so that basically kills that part of the computation.
00:14:40 <Cale> if it succeeds, it's the same as (return ()), which isn't an interesting value in and of itself to return, but future computations will usually end up deciding to return something else anyway :)
00:14:57 <Cale> (basically, it keeps the computation running)
00:15:31 <eivuokko> Yeah, I just didn't realise >>= being concatMap affects that way in do-syntax.
00:15:49 <Cale> yeah, it's cute
00:15:54 <eivuokko> You can say that :)
00:15:59 <Cale> you get nondeterministic computation
00:16:07 <Cale> it's rather like prolog
00:16:39 <Cale> and very handy for finding solutions to puzzles
00:16:44 <Cale> :)
00:17:02 <eivuokko> You get "free" backtracking, via error = no solution, you mean with being similar to prolog?
00:17:08 <Cale> yeah
00:17:53 <Cale> and the lists are all lazy
00:18:06 <eivuokko> And pain to make strict, I know ;)
00:18:08 <Cale> so you get to decide at the end how many elements to read out of them
00:18:44 <Cale> I designed my pipeline scheduler just like that
00:18:58 <sieni> Even cooler:
00:19:05 <sieni> >  map (['!'..'U']!!) $ take 5 $ map (`mod` 53) ((\x -> let y = x : (map (`div` 53) y) in y) 7848290)
00:19:06 <lambdabot> "STFU!"
00:19:13 <eivuokko> Pipeline scheduler as in optimier for compiler or what?
00:19:22 <Cale> yeah
00:19:35 <sieni> I like the "take 5" part, since I like Dave Brubeck!
00:19:36 <Cale> it decided how to schedule loop bodies of vectorised code
00:19:55 <Cale> On PPC + Altivec
00:20:07 <eivuokko> Sounds fun thing to implement :)
00:20:33 <Cale> We ended up with a snippet of code to compute sine and cosine which ran at 2.7 clocks/float
00:21:16 <eivuokko> Hmh?
00:21:34 <Cale> 8 floats per loop iteration of 19 or so cycles
00:21:51 <eivuokko> Ah.
00:21:55 <araujo> @pl (\ c -> case c of True -> True ; False -> False)
00:21:56 <lambdabot> (line 1, column 24):
00:21:56 <lambdabot> unexpected ">"
00:21:56 <lambdabot> expecting variable, "(", operator or ")"
00:21:58 <Cale> really that's 2.37, but with other processes, it's a little slower :)
00:22:05 <Cale> 2.375
00:22:14 <araujo> @pl (\ c -> case c of {True -> True ; False -> False})
00:22:15 <lambdabot> (line 1, column 19):
00:22:15 <lambdabot> unexpected "{"
00:22:15 <lambdabot> expecting variable, "(", operator or ")"
00:22:29 <Cale> araujo: id
00:22:57 <araujo> @pl (\ c -> case c of {True -> id True ; False -> id False})
00:22:58 <lambdabot> (line 1, column 19):
00:22:58 <lambdabot> unexpected "{"
00:22:58 <lambdabot> expecting variable, "(", operator or ")"
00:23:01 <araujo> hah
00:23:03 <araujo> give up
00:23:27 <Cale> I mean, the result of @pling that, if @pl supported case, would be id
00:23:37 <eivuokko> Cale, but I'm gonna go.  Thanks for explaining :)  Your explanations are always superb.
00:23:43 <eivuokko> @karma+ Cale
00:23:43 <lambdabot> Cale's karma raised to 5.
00:23:44 <Cale> eivuokko: thanks :)
00:23:55 <araujo> oh i see
00:24:03 <Cale> and of course, you're welcome :)
00:24:22 <araujo> Oh, well, i just wanted to know if @pl supported case
00:29:08 <pejo> Cale, (missed the start of the convo) did you implement the pipeline scheduler in Haskell? 
00:29:19 <Cale> pejo: yes
00:29:20 <pejo> Cale, and for what language was the compiler you were writing?
00:29:48 <Cale> It was for a new declarative signal processing language called Coconut
00:30:09 <Cale> (which, to the best of my knowledge is still in the works)
00:30:19 <pejo> Ah, nifty. 
00:33:37 <Cale> the idea is to have a declarative language on top of a simple functional language on top of a library of optionally-hand-tuned assembly, with the compiler doing directed search between each of the levels. The "assembly" would actually be in our intermediate language which is pre-register-allocation, and also allows for multiple implementations of the same result, which the scheduler chooses between.
00:34:21 <pejo> Cale, isn't the functional language a declarative one?
00:34:23 <Cale> by 'result', I mean, any step in the computation
00:34:40 <Cale> not as declarative as we'd like :)
00:35:34 <Cale> The top level language is to be equational -- you give it equations governing your signal, and it's the compiler's task to find a solution for you.
00:36:04 <araujo> Cale, Functional languages should be like that too?
00:36:13 <araujo> At least purely functional.
00:36:47 <Cale> araujo: well, somewhat, but usually functional languages don't know quite enough mathematics to be able to, say, invert functions if necessary
00:37:19 <araujo> Ah ok, you will make sure it has that kind of features?
00:38:14 <Cale> yeah, it doesn't even have to be Turing complete (with regard to the programs it produces), but it has to be able to handle that sort of thing
00:39:27 <Cale> Also, compiler speed isn't a major concern... if it takes a week to compile your program, and you get a fast implementation together with a proof/list of proof requirements out, that's good.
00:39:53 <Cale> (of course, we'd like it to be a bit faster than that :)
00:40:06 <Cale> I should really talk to them about working there again.
00:40:34 <Cale> My scheduler ran quite quickly actually.
00:41:15 <Cale> It was quite a nice case study for the use of monads and laziness.
00:41:36 * araujo usually isn't worried about compilation speed
00:42:28 <Saulzar> It's nasty to wait half an hour to build a small change
00:45:32 <pejo> Cale, hm. Have you seen the research done on program inversion by Glück and others at Diku?
00:47:18 <Cale> pejo: nope -- I'll have a look :)
00:49:18 <Cale> pejo: is there a specific paper you'd recommend?
00:51:09 <pejo> Cale, uh, oh. I must admit that I haven't looked much at them, just saw them when passing by. 
00:51:25 <Cale> http://citeseer.ist.psu.edu/696217.html -- this looks interesting anyway :)
00:54:09 <pejo> Cale, http://www.diku.dk/topps/bibliography/2005.html#D-523 might be another one of interest for you.
01:00:34 <Cale> thanks :)
03:06:55 <MarcWeber> Cale: I've found this definition for runState: runState::s-> State s a -> (a,s) runState s (S m) = m s 
03:07:39 <MarcWeber> So runState takes a state and a function. So why not runState "State" ( return "value) ?
03:10:36 <Saulzar> MarcWeber, That is what it is doing, no?
03:12:15 <Saulzar> (Not quite sure what you're saying)
03:12:27 <MarcWeber> Saulzar: ghci only accepts runState ( return "value" ) "State".
03:12:39 <ADEpt> @type runState
03:12:41 <lambdabot> Not in scope: `runState'
03:12:53 <ADEpt> @typ Control.Monad.State.runState
03:12:54 <lambdabot> forall s a. Control.Monad.State.State s a -> s -> (a, s)
03:13:12 <Saulzar> MarcWeber, Yes, it seems that it is the other way around in the ghc libs
03:13:28 <Lemmih> s/ghc/standard/
03:14:17 <ADEpt> the way with "state last" is more convenient for smthing liek mapM (someFunc) list_of_init_states
03:14:17 <Saulzar> There seem to be a lot monad tutorials around which vary in implementation slightly
03:14:20 <MarcWeber> *oh* I did use ghc 6.4.1 but ghc cvs library sources for Control.Monad.State..
03:15:12 <Saulzar> I would guess it is the same for both
03:26:37 <MarcWeber> Saulzar: The source definition was taken from ghc cvs.. Not any tutorial.. But THANKS @ll!
03:27:57 <Lemmih> ghc-cvs from how many years ago?
03:29:28 <MarcWeber> Lemmih: No more then 6 month ;-) But I can check..
03:29:49 <neologism> do you know what C-hard and C-complete languages are?
03:33:01 <Lemmih> Control.Monad.State hasn't changed in 10 months.
03:39:40 <MarcWeber> Lemmih: You're right.. It's CVS date is January..
04:13:01 <audreyt> @pl \rule input -> runParser (comp (parseRule rule)) (pack input)
04:13:02 <lambdabot> (. pack) . runParser . comp . parseRule
04:16:05 <Andrew_P> Wonder what are cryptography algorithms look like in functional languages :) Anyone tried that?
04:16:39 <CosmicRay> there are a few libraries out there of crypto stuff even
04:16:48 <CosmicRay> a new one was announced on the lists in the last few days
04:17:07 <Andrew_P> do you remember the name to google for?
04:17:34 <CosmicRay> not for the recent one, but for the others, I'd google for crypto haskell
04:17:42 <Andrew_P> thanks :)
04:19:56 <Andrew_P> RC4 is amazingly short :)
04:23:15 <Andrew_P> and so is blowfish )) interesting...
04:25:28 <shapr> @where cryptolib
04:25:29 <lambdabot> I know nothing about cryptolib.
04:25:57 <CosmicRay> hey shapr!
04:26:14 <shapr> hiya CosmicRay, what's up?
04:26:38 <CosmicRay> it's an exciting haskell week.  bjorn is adding HDBC support to HaskellDB
04:27:09 <CosmicRay> plus I've sent in a few patches to conjure.  do you think they would appreciate a patch to ditch their build system in favor of cabal? 
04:28:41 <shapr> yes
04:29:56 <ADEpt> CosmicRay: yes they would :)
04:29:57 <ADEpt> CosmicRay: hi
04:30:01 <CosmicRay> hey adept
04:30:37 <ADEpt> CosmicRay: among other things, this will enable us not to haul around "configure" (i think)
04:30:40 <CosmicRay> ADEpt: is jlouis away?  haven't heard anything on the stuff I've sent him so far
04:32:10 <ADEpt> CosmicRay: from what I head, he has end-of-semester, trouble with inet connection + something else on his hands right now.
04:32:19 <CosmicRay> ouch.
04:32:21 <ADEpt> I would expect him to re-emerge in a week or so
04:32:47 <ADEpt> CosmicRay: which reminds me: how, again, could I build haskell-v8?
04:32:47 <CosmicRay> shapr: anything fun going on for you?  get any sort of christmas break?
04:43:08 <audreyt> hm, can GHC perform a GC run on a single ptr?
04:43:11 <audreyt> foreignptr, even
04:43:17 <audreyt> instead of this global "performGC" thing
04:43:21 * dblhelix is doing binding-time analysis and partial evaluation: annotating lambdas as xmas decoration
04:43:25 <audreyt> or at least an aliveness check
04:43:34 <ADEpt> CosmicRay: it is "scons pdf", right?
04:43:43 <audreyt> on an weak ptr
04:54:07 <CosmicRay> ADEpt: yup
04:54:21 <CosmicRay> audreyt: see finalizeForeignPtr
04:58:46 <basti_> does anyone know a good data structure for this problem: I have a set of rectangles (which all have unit height, and never overlap vertically, though have arbitary width and might overlap horizontally - "piano roll display"). I now want to have a data structure, similar to set, that allows me to extract all rectangles that intersect a given rectangle (which has arbitary width and height) efficiently (that is, preferably O(log n)). 
04:59:09 <basti_> I thought about storing the start points and end points seperately. I don't know if that makes sense though.
05:00:27 <basti_> and also, this does not allow rectangles to overlap arbitarily
05:00:36 <Saulzar> So essentially it's a set of 1D ranges which might overlap
05:00:59 <basti_> thats a possible view yes
05:01:17 <audreyt> CosmicRay: so that will be noop if it's still referenced?
05:01:28 <audreyt> or it will force a run even if it's still reachable?
05:01:33 <Saulzar> Hmm
05:01:50 <audreyt> I'm faced with the problem of implementing timely destruction _some_ of lexical variables upon scope exit.
05:02:18 <CosmicRay> audreyt: ah, no.  it will run the finalizer regardless.  if it's still referenced, the finalizer won't be run later.
05:02:24 <CosmicRay> you may be interested in weak references
05:02:28 <CosmicRay> I'm not certain that's what you want.
05:02:38 <audreyt> I already got an object space full of weak refs.
05:02:43 <audreyt> problem is, they are not weak enough.
05:02:45 <Heffalump> audreyt: surely a run on a single pointer would be as costly as a full run
05:02:52 <Heffalump> since it needs to trace the entire heap either way
05:03:01 <audreyt> Heffalump: only if it's unrechable
05:03:07 <audreyt> if it's alive, surely it's less costly
05:03:16 <Heffalump> ok, on average half as costly if it is reachable
05:03:22 <audreyt> yup
05:03:31 <Heffalump> but still the same complexity factor
05:03:39 <audreyt> performGCon :: [Weak a]
05:03:44 <audreyt> or something like that
05:04:06 <audreyt> hm.
05:04:20 <audreyt> maybe I should write my own refcounting GC to handle those vars requiring timely destruction.
05:04:25 <audreyt> that'd be fun. hadn't written a GC before.
05:04:40 <Heffalump> you want to modify the RTS, or manually GC from inside Haskell?
05:04:52 <audreyt> Heffalump: this is pugs's new runcore
05:05:03 <audreyt> so it's built on haskell, not dircetly in RTS
05:05:04 <Heffalump> that doesn't really answer my question :-)
05:05:21 <audreyt> manually GC. :)
05:05:53 <Heffalump> so you won't have a finalizer on the pointers any more?
05:06:00 <Saulzar> basti_, You could use a spacial subdivision structure, ie. a tree which spans your range, storing a list of occupying rectangles at leaves
05:06:15 <Heffalump> or at least the finalizer won't do any real work, since your manual GC will already have done the cleanup
05:06:16 <Lemmih> CosmicRay: Got your conjure repo/patches online?
05:06:32 <CosmicRay> Lemmih: no but I can darcs send them to you if you send me your email addr
05:06:47 <basti_> Saulzar: hmm "a list of occupying rectangles"... you mean, rectancles that touch a certain point? or a span?
05:06:49 <Saulzar> basti_, But I'm not entirely sure what you mean - they can never overlap by height, so they will always overlap if they are in the same "x" range?
05:07:07 <audreyt> Heffalump: yeah, that's the basic idea
05:07:09 <Saulzar> basti_, Rectangles which intersect that span
05:07:14 <audreyt> Heffalump: timely vars will have noop finalizers
05:07:21 <basti_> hmm they might overlap like this: [a        [b    a]     b]
05:07:27 <basti_> or like this [a    [b   b]   a]
05:08:02 * Heffalump gets dragged off shopping
05:08:50 <Saulzar> This sort of thing is common in 2D or 3D for intersection tests, not sure if there is anything better for the 1D case
05:09:23 <basti_> you want to say "thats simple"? ;)
05:09:57 <Saulzar> It seems over the top, but maybe it's the best way :)
05:10:09 <basti_> I'll dig deeper
05:10:59 <Saulzar> Are they likely to be evenly spread or will they be heavily bunched? 
05:11:07 <basti_> rather evenly spread.
05:11:16 <basti_> i think, something like a tree would help a lot
05:12:57 <Saulzar> You could probably get away with having a fixed-depth tree with even spacing or something, an array would be even easier if it wasn't haskell :)
05:13:26 <basti_> .)
05:14:45 * audreyt praises the typeclass system
05:14:54 <audreyt> class F a where f :: a    -- extremely handy
05:15:08 <basti_> uh
05:15:13 <basti_> yea
05:15:19 <basti_> you could call that "inhabitated"
05:15:29 <audreyt> *nod*
05:15:40 <audreyt> I'm using it to make variadic functions that call each other
05:16:02 <audreyt> to simulate optional and named parameters
05:16:12 <basti_> i see
05:16:15 <basti_> yes that might be handy
05:16:31 <basti_> i often use error as a "blind" parameter
05:16:41 <basti_> i rarely encounter optional parameters...
05:16:56 <audreyt> and so far I managed to make it work without me feeling incoherent, overlapping, and undecidable
05:17:04 <basti_> -g-
05:17:35 <xerox> audreyt: is your work up somewhere? :D
05:21:07 <audreyt> xerox: sure
05:21:26 <audreyt> http://svn.openfoundry.org/pugs/src/Text/Parser/OpTable.hs
05:21:29 <audreyt> scroll to the very end
05:21:37 <xerox> Danke.
05:21:41 <xerox> Anyway, byebyeee.
05:21:49 <audreyt> see ya :)
05:28:24 <audreyt> hm, what's a more efficient way to do a two-way mapping?
05:28:28 <audreyt> two Maps?
06:12:30 <Pupeno> Hello.
06:16:55 <humasect> hello
06:34:21 <musasabi> evening
06:45:16 <musasabi> Is the syntax of package names (Cabal) specified anywhere?
06:48:37 <musasabi> Basically I am looking for a way to get a filename <-> (packageName,Version) mapping.
07:11:48 <Pupeno> :t Module
07:11:55 <Pupeno> @type Module
07:11:57 <lambdabot> Not in scope: data constructor `Module'
07:12:26 <dblhelix> @index Module
07:12:27 <lambdabot> Language.Haskell.Syntax, Language.Haskell.Syntax, System.Posix.DynamicLinke
07:12:27 <lambdabot> r.Module
07:12:55 <dblhelix> @type Language.Haskell.Syntax.Module
07:12:57 <lambdabot> String -> Language.Haskell.Syntax.Module
07:13:17 <dblhelix> @kind Language.Haskell.Syntax.Module
07:13:18 <lambdabot> *
07:23:31 <araujo> Good morning.
07:24:00 <joao> hello
07:25:40 <syntaxfree> hey. did someone call me?
07:27:06 <syntaxfree> > 0o31
07:27:07 <lambdabot> 25
07:31:51 <Heffalump> arrays just require the indexes to implement Ix, and there's no overhead if the index type is quite big, right? (except perhaps a couple of index values to store the bounds)
07:33:35 <musasabi> if the Ix operations are cheap, then it should not cost much
07:33:52 <Heffalump> ok
07:34:08 <Heffalump> (I have an array that I want to index by the values -200, -180 .. -20, 20, 40, ... 200
07:34:13 <musasabi> of course of use use one of the functions with an interface like Ix i => ... [(i,e)], then you will need many values of that type
07:35:23 <Heffalump> so I can either make a datatype that has that number embedded and make a custom Ix, or I could make a datatype that has 0-19 inc embedded, derives Ix and has explicit conversion functions to and from Int
07:35:40 <Heffalump> I guess the latter would be slightly more efficient
07:36:19 <musasabi> newtype ?
07:37:56 <Heffalump> either way it'll be a newtype, yes
07:49:53 <ptolomy2> somefunction query all@(x:xs) = (anotherfun query all) ++ (somefunction query xs) <-- I feel like I can factor this out into a fold, but I'm not sure how.
07:50:32 <ptolomy2> (given that: somefunction query [] = [])
07:51:15 <int-e> hmm. somefunction query all = concatMap (anotherfunc query) (tails all)
07:51:18 <hemstock> what is the command that does step by step evaluation in haskell?
07:51:38 <int-e> or, for fans of the list monad: somefunction query all = tails all >>= anotherfunc query
07:52:08 <ptolomy2> Hm. If that works, then I'm looking at the problem all wrong.
07:52:35 <Lemmih> hemstock: Perhaps you want to look at hat.
07:52:38 <ptolomy2> oh wait.
07:52:39 <ptolomy2> mm.
07:52:53 <int-e> ptolomy2: oh, there's a small problem - the empty list.
07:52:57 <int-e> > tails [1,2,3]
07:52:58 <lambdabot> [[1,2,3],[2,3],[3],[]]
07:53:59 <int-e> > tails [1,2,3] >>= reverse
07:54:00 <lambdabot> [3,2,1,3,2,3]
07:55:09 <ptolomy2> int-e: thanks for the insight.
08:06:49 <SamB> ADEpt: have you rung?
08:07:11 <SamB> oh, no, it was Lemmih 
08:10:44 <Lemmih> yeah, um, nevermind.
08:15:56 <SamB> hehe
08:16:24 <SamB> what was the subject of your ping?
08:16:32 * SamB is curious
08:19:06 <Lemmih> Some conjure stuff.
08:19:51 <CosmicRay> conjure is a great project.
08:20:04 <CosmicRay> I'm making it my goal to have a net reduction in lines of code with every patchset I submit ;-)
08:26:10 <CosmicRay> Does anybody know if the show command is guaranteed to generate the same representation for strings forever, or may it change at some point?
08:26:58 <Heffalump> DYM deriving Show?
08:27:20 <Heffalump> or are you talking about the Show instance for String?
08:27:25 <CosmicRay> I mean that, say, I run show in foo\0bar.  It will always generate "foo\NULbar", or at some future date, may it generate "foo\0bar"?
08:27:30 <CosmicRay> the show instance for string
08:27:49 <Heffalump> err, what's the difference?
08:28:01 <tromp_> it may be changed in fall 2043
08:28:21 <musasabi> CosmicRay: at least Haskell98 specifies one format.
08:28:30 <CosmicRay> Heffalump: there is a difference if I'm using the output from show as a key in a database table.
08:29:00 <Heffalump> I thought \NUL was \0, but I may be confused.
08:29:07 <Heffalump> Anyway, it seems to be defined in the report to do what you said above.
08:29:07 <CosmicRay> it is.
08:29:28 <CosmicRay> but what I'm saying is that I care about the difference between the 4-byte string \NUL and the 2-byte string \0 in the output generated by show.
08:29:35 <Heffalump> right.
08:29:39 <musasabi> it is defined to use showLitChar which is defined in http://www.haskell.org/onlinereport/char.html
08:29:42 <Heffalump> indeed.
08:30:49 <CosmicRay> so that sounds fairly stable.  ok, that's good.
08:41:22 <musasabi> of course for some datatypes even the show - read equivalence does not hold.
08:58:24 <maggesi> hi, I have a segmentation fault and I do not know how to trace it
08:59:16 <maggesi> I get it with LambdaShell compiled on ubuntu 5.10
08:59:28 <Cale> hmm, that's bad
08:59:49 <Cale> are there any other messages?
08:59:57 <maggesi> I am looking on info on segmentation fault in haskell (I am a novice)
09:00:04 <hemstock> what is the command that does step by step evaluation in haskell? i can't find it
09:00:32 <Cale> maggesi: Usually those only happen due to FFI calls or compiler bugs.
09:00:49 <Cale> hemstock: step-by-step?
09:01:07 <hemstock> yeah it shows you the evaluation steps
09:01:15 <maggesi> Cale, I use ghc 6.4 on ubuntu
09:01:15 <Cale> hemstock: There are some declarative debuggers you can use
09:01:22 <hemstock> hugs?
09:01:24 <Cale> like hat
09:01:34 <maggesi> the program display the licensing before the segmentation fault
09:01:40 <Cale> maggesi: hmm
09:02:04 <maggesi> I am looking in the code for FFI but I cannot see any
09:02:09 <hemstock> And it also shows you the number of steps
09:02:15 <hemstock> that they were needed
09:03:36 <Cale> maggesi: let me try it
09:03:41 <maggesi> Shellac-0.1 is the only prerequisite, I think
09:06:23 <Cale> hemstock: hat is good, but it doesn't work on a lot of real-world Haskell code due to not supporting all the libraries and extensions.
09:07:38 <Cale> hemstock: but 'step-by-step' is a lot less well-defined than with a language like C, since the compiler is at liberty to change that an awful lot through optimisation.
09:08:25 <hemstock> oh ok
09:08:51 <Cale> maggesi: hmm.
09:08:53 <hemstock> I was just asking because I remember a command in hugs something like :p <command>
09:08:58 <Cale> maggesi: it seems to work okay for me
09:09:04 <hemstock> and it does step by step evaluation
09:09:12 <maggesi>  I just finished to compile LambdaShell on a gentoo machine (ghc-6.4.1, Cabal 1.1.3) and it works!
09:09:23 <neologism> what is lambdashell?
09:09:28 <javed> what is haskell ?
09:09:47 <basti_> javed: a functional programming language.
09:10:13 <maggesi> neologism, http://comments.gmane.org/gmane.comp.lang.haskell.general/12824
09:10:20 <Cale> javed: The least broken programming language available today :)
09:10:40 <javed> can i have some more details about it ?
09:10:46 <Cale> javed: sure :)
09:10:59 <carp> hemstock: are you sure you not thinking of a prolog interpreter?
09:10:59 <basti_> javed: do you know lisp or the lambda calculus?
09:11:13 <javed> ya lisp and calu ?
09:11:25 <hemstock> hm.... yeah 
09:11:25 <javed> i have heard that lang. from books of programming
09:11:25 <Cale> It's strictly and statically typed, and has a fairly expressive type system. It uses lazy evaluation, so has no trouble dealing with infinite data structures
09:11:43 <javed> is it so ?
09:11:56 <javed> any values industry related /
09:12:09 <basti_> that depends if you can make money of it
09:12:25 <Cale> It's got a growing library and is getting fairly practical for lots of tasks
09:12:32 <Cale> http://www.haskell.org/ghc/docs/latest/html/libraries/index.html
09:14:03 <Cale> There are some really neat libraries available for Haskell which are largely unmatched in other languages. We have Parsec, a rather nice parser combinator library, if you're into things like building compilers and interpreters. We have quickcheck, which is a framework for automatically generating random tests to test program invariants.
09:14:43 <shapr> yargh
09:14:59 <Cale> hi shapr :)
09:15:04 <shapr> greetings Cale
09:15:14 <tromp_> hi shapr, cale
09:15:23 <Cale> perhaps you'd like to give javed the Haskell tour?
09:15:42 <shapr> hoi tromp_ 
09:15:50 <maggesi> Cale, which version of ghc you use?  Can be a problem related to ghc-6.4.0?
09:16:00 <shapr> Aha, a new tourist perusing the world of functional programming?
09:16:01 <Cale> maggesi: 6.4.1
09:16:17 <shapr> Greetings javed! Would you like the short tour of #haskell and Haskell?
09:16:27 <javed> ya y not
09:16:34 <javed> ty for info Cale 
09:16:49 <shapr> Ok! The first stop on this tour is the lovely lambdabot, everybody's favorite code-toy.
09:17:03 <shapr> lambdabot includes such useful features as a full Haskell repl
09:17:07 <shapr> > map (+1) [1..5]
09:17:09 <lambdabot> [2,3,4,5,6]
09:17:19 <shapr> lambdabot has many lovely plugins contributed by the #haskell community.
09:17:23 <shapr> @listmodules
09:17:24 <lambdabot> babel base code compose dice dict djinn dummy dynamic elite fact haddock
09:17:24 <lambdabot> help hoogle karma lShell localtime more pl plugs poll pretty quote search
09:17:24 <lambdabot> seen spell state system todo topic type version vixen where
09:17:30 <shapr> Actually, it's quite a long list.
09:17:43 <shapr> But we'll come back to the lovely lambdabot later...
09:18:09 <shapr> Next on your tour is the channel topic, which includes urls to previous days of discussions, links to interesting happenings and entertaining quotes.
09:18:13 <javed> i c
09:18:24 <shapr> The last two stop on our tour are links for learning Haskell...
09:18:26 <shapr> @learn
09:18:27 <lambdabot> http://www.haskell.org/learning.html
09:18:34 <shapr> That's the canonical learning Haskell page on Haskell.org
09:18:40 <shapr> @wiki HaskellNewbie
09:18:40 <lambdabot> http://www.haskell.org/hawiki/HaskellNewbie
09:18:59 <shapr> And that's an index into the compendium of knowledge that is the Haskell wiki.
09:19:13 <shapr> I wrote a very short intro on the Haskell wiki that gives you a taste of the syntax
09:19:14 <hemstock> How do I prove that the sum[x] is always x for every number? I can't understand how to prove it
09:19:15 <shapr> @wiki HaskellDemo
09:19:16 <lambdabot> http://www.haskell.org/hawiki/HaskellDemo
09:19:41 <basti_> hemstock: thats a homework problem?
09:19:45 <shapr> javed: I'd suggest you look over the HaskellDemo page and ask any questions that you have.
09:20:01 <shapr> Maybe you have some questions already?
09:20:06 <Cale> hemstock: expand the definition of sum
09:20:09 <javed> okay shapr
09:20:13 <javed> thankx
09:20:21 <hemstock> No it's not. I am revising for exams, and it's a possible exam question.
09:20:22 <javed> you know other programmming lang
09:20:25 <javed> ?
09:20:26 <shapr> Sure, feel free to ask any questions that you encounter.
09:20:28 <shapr> Me? Yes.
09:20:46 <Cale> Many people here know all sorts of programming languages :)
09:20:52 <shapr> I started with BASIC on a Sinclair some .. 23 years ago.
09:20:57 <hemstock> How do I check the definition of sum in hugs?
09:21:02 <Cale> oh
09:21:31 <shapr> I've learned Python and Java well, and probably some other languages I can't think of...
09:21:55 <shapr> I learn new programming languages for fun, but I don't end up using most of them for 'real work.'
09:22:07 <Cale> hemstock: you can have a look at the prelude http://www.haskell.org/onlinereport/standard-prelude.html
09:22:11 <shapr> Only Python, Java, and Haskell so far. (SQL doesn't count as a language imho).
09:22:22 <hemstock> thanks
09:22:29 <shapr> Althought shell scripting probably does count as a real language... hmm
09:23:46 <shapr> I could check my resume...
09:24:45 <shapr> lennart_: Hej, vet du nÃ¥n haskellfolk som bor eller arbetar i Stockholm? Jag vet FaxÃ©n, men kanske nÃ¥n vid SICS?
09:25:13 <javed> brb guys
09:25:23 <shapr> lennart_: I'm impressed that anyone could fit three Ss into a single name. That's pretty cool.
09:26:36 <Cale> shapr: like in Augustsson?
09:26:46 <shapr> Yeah, exactly.
09:27:27 <Cale> they're so densely packed too
09:28:40 <javed> hey any new start books for python ?
09:30:25 <shapr> I don't know. I got out of Python for the most part.
09:32:22 <carp> javed: "What's faster than C++, more concise than Perl, more regular than Python, more flexible than Ruby, more typeful than C#, more robust than Java, and has absolutely nothing in common with PHP? It's Haskell!" - Autrijus Tang
09:32:22 <Cale> > let primes = sieve [2..]; sieve (x:xs) = x : sieve [y | y <- xs, y `mod` x /= 0] in take 30 primes
09:32:23 <lambdabot> [2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71,73,79,83,89,97,
09:32:23 <lambdabot> 101,103,107,109,113]
09:32:53 <shapr> Hey stesch, how's code?
09:33:59 <javed> yes carp 
09:34:33 <javed> thanks for nice info carp
09:34:34 <shapr> javed: So, have any questions yet?
09:35:24 <stesch> shapr: Throwed a tutorial into the corner after reaching page 21 of 64. "layout" was a shock. Today I picked it up again ... :-)
09:37:09 <javed> ya i want the python book shapr
09:37:28 <javed> nice book
09:38:23 <shapr> javed: Python is a good language.
09:39:17 <tromp_> invented here:)
09:39:51 <shapr> heh, truly
09:39:52 <javed> ya know that
09:40:00 <javed> true !!!!!????
09:40:11 <shapr> Python is easy to learn and scales up to real applications.
09:40:23 <shapr> Python isn't as powerful as Haskell, but it's good for daily use.
09:40:29 <shapr> Yeah, tromp_ works at cwi.nl
09:40:58 <javed> ya but
09:41:05 <javed> do u know some good book for python
09:41:11 <javed> i want the pdf
09:41:24 <shapr> I learned from the tutorial that comes with the download.
09:41:28 <Cale> python's website has links to some good intros
09:43:04 <javed> okay 
09:43:06 <javed> ty
09:43:28 <stesch> I thought you guys all use Perl6 for scripting. :-)
09:44:17 * basti_ could take that as an insult
09:44:36 <javed> how is perl lang ?
09:44:42 <javed> easy to learn ?
09:44:46 <basti_> javed: have a look at this http://deimos.dynalias.org/kommutativdistributiv.pl
09:45:08 <javed> good basti_ 
09:45:20 <basti_> "good"? ;)
09:45:27 <basti_> i think its completely illegible
09:45:40 <basti_> javed: this program is more of a joke.
09:46:31 <javed> i dont get u basti_ 
09:46:59 <basti_> it abuses lambda-calculus like operators to find which pairs of the 8 commutative binary operators are distributive with regard to each other
09:47:16 <basti_> javed: the program only shows how bizarre perl programs can look
09:47:35 <javed> ok
09:48:03 <basti_> perl has some reputation of yielding illegible code
09:48:39 <basti_> its regarded as a scripting language. There are not many large programs written in perl
09:49:30 <javed> ok
09:49:46 <basti_> its a very popular language nevertheless
09:50:20 <carp> in reference to my previous quote google for pugs
09:51:13 <shapr> stesch: Found any new questions?
09:51:25 <stesch> http://images.google.com/images?q=pugs&hl=en&btnG=Search+Images
09:51:27 <stesch> :-)
09:52:10 <stesch> shapr: Not at the moment. I praise the magic TAB key of the haskell-mode in emacs. And I may have bad dreams after the layout shock.
09:52:15 <carp> bugger
09:53:00 <carp> oh, it is on the first page though
09:55:15 <javed> be guysss
09:55:18 <javed> bye
09:57:09 <shapr> It's been -26Â° all day long, too cold to unicycle :-(
09:57:41 <shapr> Below -20Â° the clothing/mobility tradeoff is too low.
09:58:39 <shapr> Anyone know where I can find Haskell ports of the executable code for Types and Programming Languages?
09:59:56 <palomer> is that book any good?
10:00:03 <gzl> yes
10:00:34 <shapr> Worth the price.
10:00:53 <gzl> the sequel is supposed to be very good too.
10:01:01 <gzl> but I haven't read that one.
10:01:11 <SlowByte> there are cheaper, shadier ways of obtaining it too *cough*
10:01:55 <palomer> cool, I have access to the ebook
10:02:27 <palomer> SlowByte: privmsg?
10:02:38 <araujo> *cough*
10:02:41 <araujo> mm..
10:02:47 <araujo> palomer, i am your friend too right?
10:02:51 <araujo> *cough*
10:03:02 <gzl> there's an ebook?
10:03:10 <palomer> yeah, my library has it
10:03:23 <palomer> I just need to figure out how to access my library's private collection from home
10:03:58 * palomer kicks vpn
10:04:12 <SlowByte> man, I wish my library had ebooks
10:04:16 <gzl> odd
10:12:17 <pejo> gzl, I've glanced over the sequel, it looks very useful. 
10:18:07 <shapr> I've been reading the TYPES forum lately, it's pretty good.
10:19:59 <JKnecht> @hoogle GADT
10:20:01 <lambdabot> No matches found
10:20:33 <shapr> Anything in particular you want to know about GADTs?
10:21:07 <JKnecht> Thanks. 'General Algebraic Data Type'? a library, monad, what?
10:23:47 <reddi> hi, short question! whats the best way (i only need an idea) to sort a tree?
10:24:11 <reddi> and the next question: how do i find out (i know the definition) in haskell wheter a function is reflexiv?
10:25:42 <shapr> JKnecht: It's an extension to the type system.
10:25:57 <JKnecht> is there an expository reference?
10:26:27 <shapr> yes, just a moment...
10:27:10 <shapr> JKnecht: http://www.scannedinavian.org/~shae/gadt/
10:27:53 <shapr> JKnecht: Aka wobbly types - http://lambda-the-ultimate.org/node/view/290
10:27:55 <JKnecht> Thanks! reddi: a tree normally wouldn't be sorted, otherwise the need (lexico on some attrib, eg) determines.
10:28:30 <reddi> JKnecht: i would "read" the values, put them into a list and build a new tree ....
10:28:58 <reddi> is this an adequate way?
10:29:32 <JKnecht> if there were an order mapping that made the new tree make sense.
10:30:19 <Cale> http://research.microsoft.com/Users/simonpj/papers/gadt/index.htm
10:30:29 <reddi> or: another idea: iterate the tree so long till itis sorted ;-)
10:32:16 <shapr> Cale: Is that the same as the 2005 draft @ http://www.cis.upenn.edu/~geoffw/research/ ?
10:33:11 <mahogny> if a C-function mallocs a string and sends it to haskell, would it be a CString and hence be automatically free'd?
10:33:32 <CosmicRay> CStrings are not automatically freed
10:33:39 <mahogny> urgh
10:33:43 <CosmicRay> they are if you create them with withCString (when withCString returns)
10:34:09 <CosmicRay> but you better define how exactly it is "sending it to haskell"
10:34:12 <Cale> shapr: it's one of those two
10:34:20 <mahogny> ok. so which functions would I free a CString with?
10:34:28 <mahogny> CosmicRay, it calls malloc() and then returns it
10:34:44 <CosmicRay> and you have a foreign import for a functio that returns an IO CString?
10:34:57 <mahogny> well, I assume that would be the correct type?
10:35:36 <CosmicRay> yes.
10:35:45 <CosmicRay> haskell will not take any special action to free that for you automatically.
10:35:45 <Lemmih> @type Foreign.free
10:35:46 <lambdabot> forall a. GHC.Ptr.Ptr a -> IO ()
10:35:56 <CosmicRay> you could, however, call free manually, or you could wrap it in a ForeignPtr.
10:36:14 <CosmicRay> or, if all you ever need is a simple haskell String out of it, just:
10:36:20 <CosmicRay> do hstr <- peekCSwtring cstr
10:36:25 <CosmicRay>     free cstr
10:36:45 <mahogny> ok
10:37:49 <mahogny> is the haskell free the same as the C free()? can I mix them freely?
10:37:57 <JKnecht> http://www.haskell.org/ghc/docs/latest/html/users_guide/gadt.html is what I was looking for from hoogle.
10:38:05 <CosmicRay> mahogny: I believe so
10:38:08 <mahogny> ok
10:38:15 <mahogny> thanks
10:45:40 <shapr> hey franka, what's up?
10:45:53 <franka> Hiya, shapr.
10:46:04 <franka> Just hanging.
10:46:19 <shapr> Had any neat type theory thoughts recently?
10:46:25 <astrolabe_> I can't seem to find an un-garbled definition of grobner basis :(
10:46:31 <astrolabe_> Hi guys :)
10:46:45 <franka> No, nothing new on that front, I'm afraid.
10:47:01 <franka> Hi, astrolabe_.
10:47:20 <JKnecht> http://en.wikipedia.org/wiki/Grobner_basis
10:47:34 <MarcWeber> Which source would you recommend to learn about fun deps and multi parameter type classes?
10:47:46 <franka> I have a definition of Groebner basis somewhere.
10:48:01 <franka> It is a chapter I skipped in a book.
10:48:19 <astrolabe> franka: that would be helpful.  I had a problem with the wikipedia one
10:48:46 <franka> OK, hold on.  And MarcWeber, I learned about fun deps from Mark Jones' paper.
10:48:54 <Cale> http://planetmath.org/encyclopedia/GrobnerBasis.html
10:48:55 <shapr> Hey, I have a totally off-topic question... Have you guys ever considered throwing out the paper and cases for your CDs and DVDs and only saving the actual discs?
10:49:11 <astrolabe> Thanks cale, but I had a problem with that one too.
10:49:23 <Cale> astrolabe: what problem did you run into?
10:49:43 <JKnecht> Wouldn't that damage the disks and make them harder to find?
10:50:01 <astrolabe> Cale: They define sup for a monomial, and then use it for a polynomial I think.
10:50:11 <shapr> I have a disc notebook that holds several hundred discs.
10:50:50 <JKnecht> How much was it?
10:51:26 <JKnecht> Also you loose the artwork and liner notes.
10:51:32 <astrolabe> shapr: Are they difficult to retrieve?
10:51:35 <Cale> astrolabe: supp(f) is just the set of terms with nonzero coefficients in f
10:52:01 <shapr> JKnecht: Yes, but, what value is in the artwork and liner notes?
10:52:03 <astrolabe> does term mean monomial, or indeterminate?
10:52:08 <franka> Let G := {f1,..fk} be a finite set of polynomials with head coefficients 1.  Then G is a Groebner basis of the ideal J iff J = <f1,..fk> and ->_G is confluent.
10:52:17 <shapr> astrolabe: It's easier to find and retrieve discs from the folder than from a shelf.
10:52:34 <shapr> It's also significantly simpler to store the folder instead of several hundred DVD cases.
10:52:35 <JKnecht> For older (music) recordings, a lot.
10:52:37 <Cale> for example, if f(x,y) = 3 x^2 + 2 x y + 5 y^3, supp(f) = {3x^2, 2xy, 5y^3}
10:52:46 <MarcWeber> franka: Typing Haskell in Haskell?
10:53:19 <astrolabe> franka thanks.  But what is 'confluent'?
10:53:22 <shapr> JKnecht: What percentage of your discs have liner notes or art that contribute value over and above the disc itself?
10:53:24 <JKnecht> But for data, normally nothing but SNs which can be written on the disk.
10:53:35 <astrolabe> Cale, thanks, I'll have another go bearing that in mind.
10:53:52 <shapr> Since I don't get an actualy license for DVDs or CDs, it seems they're just data as well.
10:53:58 <Cale> astrolabe: hmm
10:54:05 <Cale> maybe that's not what they mean :)
10:54:07 <Cale> hehe
10:54:07 <JKnecht> For recordings before say 1980, I'd say most of them.
10:54:22 <shapr> What about recordings after 1980?
10:54:23 <Cale> ah, a = x_1^a_1 ... x_n^a_n
10:54:47 <JKnecht> even then there's lyrics and the like.
10:54:56 <Cale> so they're saying that if a is a monomial, supp(a) is the set of indeterminates with nonzero exponents in a
10:55:03 <franka> -> is confluent iff x ->* y1 and x ->* y2 implies y1 and y2 are joinable (exists a z s.t. y1 ->* z and y2 ->* z)
10:55:07 <astrolabe> Cale: right
10:55:19 <franka> where ->* is the transitive closure of ->
10:55:33 <shapr> JKnecht: Ok, what about DVDs?
10:55:39 <franka> transitive-reflexive
10:56:04 <franka> MarcWeber: http://www.cse.ogi.edu/~mpj/pubs/fundeps.html
10:56:21 <astrolabe> franka: What is    ->     ?
10:56:42 <franka> astrolabe: I was wondering when you'd ask that. :)
10:56:49 <JKnecht> shapr: OK that one's good, let's trash all the DVD packaging :) Are you selling the folders? 
10:57:24 <astrolabe> franka :)
10:57:27 <shapr> JKnecht: heh, no... just trying to follow Wright's advice "Nothing in your home that's not beautiful or functional."
10:57:41 <franka> I will priv you.
10:57:49 <shapr> JKnecht: And I realized that 90% of my DVD and CD cases and papers are a waste of space.
10:57:50 <JKnecht> sounds like a terse suicide note.
10:57:56 <shapr> heh
10:58:03 <shapr> It's Frank Lloyd Wright, I believe.
10:58:23 <lisppaste2> Lethalman pasted "Test" at http://paste.lisp.org/display/15108
10:59:11 <JKnecht> Well his most famous quote is "form follows function", the aesthetic judgement was implicit.
10:59:27 <Cale> astrolabe: okay, yeah, that article is confusing -- my original interpretation is right
10:59:42 <Cale> they really ought to change the variables around
11:00:39 <JKnecht> By the way, many of his structures have'nt stood the test of time, they've tended to fall apart after a while.
11:01:37 <kala> hello. Im trying to write a function to insert a Node to a Tree, but I'm getting type error when I try out my function. I don't see, where I have made a mistake. if anybody could give me advice? http://pastebin.com/481864
11:02:47 <shapr> @where conjure
11:02:47 <lambdabot> http://j.mongers.org/pub/haskell/darcs/conjure/
11:02:48 <Cale> kala: Leaf readAttackNode ["foo"] = (Leaf readAttackNode) ["foo"]
11:03:33 <kala> Cale: ok, let me try that
11:03:49 <Cale> kala: you just need some extra parens
11:04:21 <kala> hugs gave me *** Does not match : a -> b -> c
11:04:24 <Cale> that is, try
11:04:41 <kala> now when I tried Main> insertAttackTree ( (Leaf (readAttackNode ["foo"])) (readAttackNode ["bar"]) )
11:05:30 <Cale> you're applying the leaf as a function
11:05:45 <Cale> (Leaf (readAttackNode ["foo"]))
11:05:48 <Cale> is applied to
11:05:52 <Cale> (readAttackNode ["bar"])
11:06:00 <kala> well ? 
11:06:09 <kala> this is good, isnt it? :)
11:06:13 <Cale> hm
11:06:36 <Cale> I don't think so, because AttackTrees can't be applied as functions
11:06:58 <kala> I can do "Main> showAttackTree (Leaf (readAttackNode ["foo"]))"
11:07:20 <Cale> insertAttackTree (Leaf $ readAttackNode ["foo"]) (Leaf $ readAttackNode ["bar"])
11:07:34 <Cale> I think that's more what you want
11:07:44 <kala> whats that "$" ?
11:07:50 <Cale> f $ x = f x
11:07:58 <Cale> but $ has low precedence
11:08:04 <Cale> it's a good way to avoid parens
11:08:38 <Cale> insertAttackTree (Leaf (readAttackNode ["foo"])) (Leaf (readAttackNode ["bar"]))
11:08:46 <Cale> that's without the $
11:11:24 <kala> both variants should work?
11:13:48 <kala> because I'm getting type error either way
11:15:43 <kala> what about this "showAttackTree (Leaf (readAttackNode ["foo"]))". It seems rather logical that it works?
11:17:48 <kala> wow, "showAttackTree (insertAttackTree (Leaf $ readAttackNode ["foo"]) (readAttackNode ["bar"]))" works too. good. 
11:35:57 * ski wakes up
11:49:23 <rep> - how do you prevent deadlocks?
11:49:32 <rep> - by holding locks the shortest time possible.
11:49:53 <shapr> use STM
11:50:15 <rep> hehe
11:50:23 <rep> i knew someone would say it
11:56:16 <mahogny> while we are in on threads, what is the common cause for this one: Fail: thread blocked indefinitely
11:57:17 <neologism> is there any nice description of stm?
11:57:21 <neologism> I found nothiing using google
12:00:02 <Heffalump> one of SPJ's talks on the subject?
12:07:06 <SamB> neologism: look in your library sources for references to papers?
12:07:27 <SamB> or look on spj's page of papers?
12:08:57 <mahogny> I don't really have anything that could be blocked as I see it. only one loop is blocked, the other one is live and well
12:12:08 <SamB> hmm.
12:13:11 * SamB greps RTS
12:13:23 <lennart_> @seen shapr
12:13:24 <lambdabot> I saw shapr leaving #haskell-blah, #haskell and #ScannedInAvian 17
12:13:24 <lambdabot> minutes and 34 seconds ago.
12:13:50 * SamB greps compiler
12:15:14 * SamB greps libraries
12:16:27 <SamB> mahogny: the string appears twice in IOBase
12:16:41 <SamB> ../haskell/fptools/libraries/base/GHC/IOBase.lhs:  showsPrec _ (BlockedOnDeadMVar)       = showString "thread blocked indefinitely"
12:16:42 <SamB> ../haskell/fptools/libraries/base/GHC/IOBase.lhs:  showsPrec _ (BlockedIndefinitely)     = showString "thread blocked indefinitely"
12:19:28 <mahogny> SamB, ok, I think that sorted it out. thanks
12:20:07 <SamB> wonder how an MVar dies...
12:20:25 <SamB> ... when something is blocking on it
12:20:28 <mahogny> well, it seems I just found out :)
12:22:31 <palomer> damnit
12:22:36 <palomer> linux is becoming an inconvenience
12:22:48 <basti_> SamB: "dies"?
12:29:22 <TuringTest> Anyone care to help with a new shootout entry?
12:29:30 <lisppaste2> TuringTest pasted "proposed shootout entry" at http://paste.lisp.org/display/15111
12:31:48 <Heffalump> what help?
12:32:16 <palomer> why doesn't haskell have its own pastebin?
12:32:23 * Heffalump isn't familiar enough with STM to help, actually
12:32:29 <Heffalump> palomer: cos that one is good enough?
12:32:48 <Trevion> But it's missing Haskell syntax highlighting!
12:32:49 <palomer> since when has that been a reason not to do something?
12:32:53 <SamB> palomer: because you haven't written one yet
12:33:00 <palomer> good answer
12:33:03 <palomer> but I'm like the biggest newb
12:33:17 <SamB> also, where would we put it?
12:33:23 <palomer> haskell.org ?
12:33:40 <SamB> and how would you integrate it with lambdabot?
12:34:11 <palomer> would this really be a problem?
12:34:56 <Heffalump> does haskell.org run arbitrary CGI?
12:35:25 * TuringTest goes off to the wiki to post it w/highlighting
12:43:01 * TuringTest points at http://haskell.org/hawiki/ChameneosEntry
12:43:06 <TuringTest> There is you highlighting
12:43:11 <TuringTest> you->your
12:43:54 <palomer> lambdabot should tell us about new wiki additions
12:44:28 * TuringTest looks at lambdabot, looks at watch, shrugs
12:45:43 <TuringTest> I can't directly compare performance, since I don't have the compilers for the other entries.  But the memory consumption with -O1 is good, and speed seems competitive.
12:47:04 * TuringTest goes to post wiki page to haskell-cafe
12:49:05 <glasser> Can't you just print 2*N?
12:52:43 * TuringTest shakes head
12:53:33 <TuringTest> glasser: It is an interesting test for concurrent programming with STM.  My first version did the wrong thing.
12:53:59 <glasser> I'm still trying to understand your entry, yeah. Definitely interesting
12:54:07 <glasser> (but when is the answer not 2N? :) )
12:54:16 <TuringTest> It is always 2*N
12:54:36 <TuringTest> Unfortunately I compressed the code, I should make an annotated version.
12:54:48 * TuringTest goes back to emacs to add comments
12:54:51 <glasser> I would be very interested in seeing that
12:56:18 <TuringTest> did you read the description of the task?
12:56:37 <glasser> Yeah.
12:56:42 <glasser> Well, I skimmed the linked paper
12:57:17 <glasser> So the order of chameneos entering the mall is basically nondeterministic? (Up to the thread scheduler or the equivalent?)
13:05:05 <palomer> lennart_: you around?
13:21:18 <TuringTest> glasser: yes, it is up to the schedular.  But they do converge on the same color.
13:21:57 <glasser> Interesting.  In general or just for this particular initial condition?
13:22:24 <TuringTest> This particular initial condition.
13:22:57 * glasser nods
13:23:23 * TuringTest goes to past the annotated version
13:23:41 * stesch is printing the 200 page long tutorial ... My poor little printer.
13:28:47 * TuringTest points to http://haskell.org/hawiki/ChameneosEntry (scroll down for annotated version)
13:29:15 <palomer> hrmphrm
13:29:17 <palomer> twelf
13:29:23 <TuringTest> glasser: Most of the difficulty is not screwing up "meet color"
13:29:26 <TuringTest> palomer: ?
13:30:13 <glasser> TuringTest: I will hopefully understand that statement in a few minutes :)
13:30:49 <glasser> I forget; is MVar the STM var?
13:32:58 <TuringTest> glasser: No.. TVar or TMVar are STM
13:33:17 <glasser> I see. So spawn isn't using STM at all?
13:34:55 <TuringTest> It calls enter
13:34:59 <TuringTest> enter calls meet
13:35:02 <TuringTest> meet uses STM
13:35:17 <TuringTest> Ok...spawn does not use STM
13:35:23 <TuringTest> child uses STM via enter/meet
13:35:26 <TuringTest> ooops
13:35:43 <glasser> Ah.  (Haven't gotten that far yet.)
13:35:43 <glasser> Why is the strict application ($!) in child necessary?
13:36:10 <TuringTest> I did a premature speed optimization
13:36:36 <TuringTest> I did not want to put a thunk there, since it needs to be computed anyway
13:36:55 <TuringTest> otherwise you might get 0+1+1+1+1+1...+1 all the way until the last print statement
13:37:25 <glasser> ah.  no use being lazy about work you're going to need to do?
13:37:30 <TuringTest> right
13:37:56 <TuringTest> The strict call to complement is less needed, but I decided to throw it in
13:38:03 * TuringTest goes off to speed benchmark that
13:44:25 <TuringTest> I removed the $! for the complement and this helped speed by a tiny fraction (updated the wiki).  The $! for the addition really does help by at least 40% the speed so I left it in.
13:53:02 <pediddle> woohoo, ghc exploded
13:53:57 <pediddle> don't try to compile this:
13:53:57 <pediddle> data Rank r
13:53:57 <pediddle> data Ascender a r 
13:53:58 <pediddle>   = Ceiling
13:53:58 <pediddle>   | Ascender (a r) (Ascender a (Rank r)) 
13:54:00 <pediddle>   deriving (Show)
13:58:59 <wilx> @indes StableName
13:58:59 <lambdabot> System.Mem.StableName
13:59:11 <wilx> @doc System.Mem.StableName
13:59:11 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/System-Mem-
13:59:11 <lambdabot> StableName.html
13:59:29 <wilx> Yay! for lambdabot's output wrapping.
14:01:00 <wilx> @indes StablePtr
14:01:01 <lambdabot> Foreign.StablePtr, Foreign
14:02:01 * TuringTest must go
14:04:10 * araujo back
14:05:07 <stesch> hmpf. The "Yet Another Haskell Tutorial" has a formatting problem. The page labeled "2" is on an odd page. All page numbers are on the wrong side. :-/
14:06:53 <stesch> Side notes are in the middle ... 
14:11:26 <stesch> After page xi comes 1. This schould be xii. Then everything would be fine.
14:17:42 <dons> Moin!
14:18:00 <stesch> OK, wrote an e-mail to Hal.
14:18:32 <stesch> Doesn't help me now, though. 
14:18:37 <stesch> |sigh|
14:21:53 <araujo> dons, hey!
14:33:24 <dons> @uptime
14:33:25 <lambdabot> uptime: 1 day, 1 hour, 39 minutes and 36 seconds
14:35:08 <araujo> dons, priv?
15:07:25 <esap> what is this I hear there's going to be a restriction on GADTs? does anybody have details?
15:08:13 <SamB> GADTs are already all about restrictions, aren't they?
15:09:07 <esap> yes. But it's essential that some code compiles, e.g. that you can still prove that two types are equivalent etc.
15:09:53 <SamB> so, where did you hear about restrictions?
15:10:12 <esap> mailing list
15:13:48 <musasabi> I think it is about fundeps
15:16:08 <glasser> TuringTest: neat, I think I get it
15:16:15 <glasser> Though I don't see what the join is doing
15:16:25 <TuringTest> hmmm
15:16:25 <esap> I just saw a fragment of a msg that said GADTs are going to be revised in some way.
15:16:29 <Philippa_> 'lo BlueBlazer
15:16:39 <TuringTest> > join (return $ print "Hello World")
15:16:40 <lambdabot> No IO allowed
15:16:58 <TuringTest> (would have printed hello world)
15:17:06 <Philippa_> TuringTest: lambdabot doesn't like running the risk of you killing its host system :-)
15:17:09 <glasser> ah, since print itself has an IO type, and return puts another one on?
15:17:15 <Philippa_> glasser: yup
15:17:16 <TuringTest> right
15:17:50 <TuringTest> join mmx is the same as do  mx <- mmx ; mx 
15:18:11 <TuringTest> Where mmx returns command mx, which is then executed
15:18:20 <TuringTest> join on list is concat
15:18:25 <BlueBlazer> lo Phillippa
15:18:26 <TuringTest> join [[1,2,3],[4,5],[6]]
15:18:28 <glasser> Oh, aha, I just saw the embedded atomically in the middle
15:18:38 <TuringTest> >  join [[1,2,3],[4,5],[6]]
15:18:39 <lambdabot> [1,2,3,4,5,6]
15:18:51 <TuringTest> > join (Just (Just "foo"))
15:18:52 <lambdabot> Just "foo"
15:18:54 <glasser> I wonder if there is a nice way to do this which doesn't switch back between IO and STM as much
15:19:20 <TuringTest> Lines of code is a metric used in the shootout.
15:19:37 <TuringTest> For whatever that is worth
15:20:22 <esap> ah, it was this mail: http://www.mail-archive.com/haskell@haskell.org/msg17379.html
15:21:03 <glasser> TT: oh, don't take that as a criticism
15:21:13 <glasser> i wouldn't have known where to start :)
15:21:23 <TuringTest> The "then return $ atomically $ do" will commit the put to firstVar and then block waiting for secondVar
15:22:09 <TuringTest> I learned by solving the cases in "The little book of semaphores" http://greenteapress.com/semaphores/
15:22:45 <TuringTest> I particularly liked the "Santa Claus" problem.
15:25:32 <musasabi> Is there a reason lambdabot does not have  Text.ParserCombinators.ReadP in the evaluation plugin?
15:39:17 <SamB> esap: well, the current GADT support is rather... um... messy and confusing...
15:39:30 <SamB> I wouldn't worry about it...
15:39:36 <esap> SamB: why? For me, it has worked well :-)
15:40:22 <Cale> The interaction with classes is a bit odd.
15:40:34 <SamB> well, sometimes it works fine, sometimes it does dreadful things!
15:40:38 <SamB> sometimes it even has bugs!
15:40:55 <Cale> SamB: what's the worst you've seen?
15:41:18 * esap has tried every trick in the book, and it seems to work beautifully :-)
15:41:50 <esap> GADTs require me to prove my code correct.
15:42:01 <esap> It's sometimes hard work, but very useful
15:42:48 <Heffalump> esap: I thought it's just the type checking algorithm that has been/will be redone
15:42:59 <Heffalump> what kind of things are you using them for, OOI?
15:43:03 <Philippa_> yeah, but there're some corner cases it doesn't handle now AIUI
15:43:47 <Heffalump> bugs keep coming up, but are there actual flaws in the algorithm? I don't really understand the differences between the old and new ways.
15:43:49 <esap> I'm using GADTs for my compiler's parse tree.
15:44:37 <esap> The type checked version of it, I mean. GADTs keep information about what things the type checker has proved correct about the parse tree.
15:45:32 <Heffalump> ok, so the type checker itself is forced to be correct?
15:45:37 <esap> yes.
15:45:45 <Heffalump> what kind of constraints did you manage to encode?
15:46:58 <SamB> Cale: just look at all the list threads with GADT in the subject line...?
15:47:28 <esap> For example, for composition, I have: TFunctorCompose :: (ModuleCtx mid) => TFunctor g mid cod -> TFunctor f dom mid -> TFunctor (CF mid g f) dom cod
15:47:39 <SamB> Heffalump: well, according to the paper and to SPJ's email, the new way is simpler
15:47:54 <SamB> something about either wobbling or not wobbling...
15:47:59 <Heffalump> SamB: yes, I understand that it's simpler, but does it have actual effects on which programs type check and which ones don't?
15:48:03 <SamB> rather than being partly wobbly
15:48:09 <Heffalump> (as opposed to just reducing the number of bugs etc)
15:48:12 <SamB> Heffalump: apparantly
15:48:24 <SamB> thats what the paper said
15:48:24 <Heffalump> and does it make some programs that used to type check not do so any more?
15:48:33 <Heffalump> oh, I remember SPJ asking for GADT code a while back.
15:48:44 <SamB> the question is, does it save trouble going down dead ends?
15:48:49 <esap> I'm using GADTs to encode lots of properties about the language itself.
15:49:30 <Heffalump> esap: right, the same kind of thing that darcs is hoping to use them for
15:50:10 <esap> probably yea. It's lots of work to prove type equivalence though.
15:51:45 <TuringTest> I think GHC translates Haskell into System F and the new GADT inferencing will let you express any System F construct in GHC, which may not have been possible before.
15:52:15 <esap> hmm.. that's nice.
15:54:15 <carp> esap: what language is your compiler for?
15:54:46 <esap> carp: I'm designing the language. It's basically trying to encode category theory in the language.
15:55:05 <SamB> it does not use System F!
15:55:05 <Heffalump> aren't GADTs all erased at compile-time, like with normal datatypes?
15:55:11 <SamB> it uses Core
15:55:12 <glasser> TuringTest: That semaphores book looks nice. You worked through the problems in Haskell?
15:55:17 <SamB> that may be similar, but not the same...
15:55:34 <TuringTest> glasser: The interesting ones.  Quite a few were interesting.
15:55:47 <esap> carp: That's why I need to enforce correctness for the type checker. I want to be able to change the language as I write the compiler.
15:55:51 <carp> Is core now System F + some datatype stuff?
15:56:05 * TuringTest looks confused
15:56:16 <TuringTest> I am but a simple caveman.. I know nothing of GHC internals.
15:56:29 <Philippa_> there's funky kinding for unboxed types and stuff like that
15:56:31 <SamB> I don't know what System F is, actually
15:57:07 <Heffalump> then how do you know Core isn't it?
15:57:08 <SamB> @kind GHC.Base.Int#
15:57:09 <lambdabot> #
15:57:28 <SamB> Heffalump: well, I didn't see it in any of the comments!
15:57:40 <SamB> or if I did, I forgot
15:57:46 <Heffalump> errm, right, great evidence there ;-)
15:57:50 <SamB> heh
15:58:07 <SamB> anyway, if it is System F, why call it Core?
15:58:10 <TuringTest> glasser: The key thing that simplified the code in Haskell was that I could pass IO closures to threads instead of data primitives such as MVar.  And I could put these closures into things like TChan and pass them from thread to thread.
15:59:13 <Heffalump> well, it might by System F + some stuff, as carp suggested.
15:59:24 <Heffalump> s/by/be/
15:59:39 <Heffalump> anyway, noone answered my question about GADTs being erased at compile time
16:00:14 <Cale> Heffalump: yes, they would have to be
16:00:22 <Heffalump> if they are, then you can't possibly express any System F program using them, since System F doesn't have erasure
16:00:33 <TuringTest> glasser: I even made a combinator which took an (IO a) and returned an (IO a) which could only be run once, by wrapping it STM or IO goodness. (Same for wrapping an (STM  a) )
16:02:10 <Heffalump> Cale: why 'have'?
16:02:20 <TuringTest> glasser:  Then the Santa thread could pass an IO command to a Reindeer thread which would decrement a semaphore, but could only be used once.  That made me happy.
16:02:32 <carp> System F is a typed lambda calculus
16:02:47 <Cale> Well, not strictly so, but afaik, the GHC runtime doesn't have any notion of types.
16:03:03 <Heffalump> Cale: it must do, type classes and existential types need that
16:03:14 <Cale> hmm
16:03:27 <Philippa_> er, type classes translate away cleanly last time I checked
16:03:40 <Heffalump> Philippa_: only if you unroll everything..
16:03:43 <Cale> I'd think those would be handled via dictionaries.
16:03:51 <Heffalump> otherwise you have to translate them into dictionaries, yeah
16:03:53 <TuringTest> Heffalump: Cale: It keeps pointers to dictionaries in the boxed types.  These are not the same as the types.
16:03:58 <Heffalump> and those are equivalent to having types
16:04:02 <Philippa_> not IMO
16:04:07 <carp> I'd quite like to know why System F + whatever is a good thing to use as core (if it is)
16:04:11 <Cale> TuringTest: yeah, that's what I thought :)
16:04:27 <fieldy> hello
16:04:27 <Heffalump> they are because you can write type classes that give you enough information to reconstruct something equivalent to the type at runtime..
16:04:30 <araujo> Hola fieldy!
16:04:34 <Heffalump> Data.Typeable or whatever it is.
16:04:57 <Cale> Heffalump: but you have to do that explicitly
16:05:06 <esap> I think system F is good, because it's very expressive [since it requires extensive type annotations]. The tricky part is adding type inference on top of System F.
16:05:09 <Philippa_> and it doesn't work overly well without compiler support
16:05:13 <Heffalump> the point is that dictionaries are semantically equivalent to keeping the types around
16:05:18 <TuringTest> Deriving Typeable stores alot of typing info in explicit data structures which is derives.
16:05:20 <Heffalump> it doesn't matter that it's a pain
16:05:30 <Heffalump> in principle GADTs _could_ be translated into something like that
16:05:32 <Philippa_> not quite. Two types could use the same underlying code and thus share dictionaries for example...
16:05:36 <Heffalump> although I'm pretty damn certain they aren't
16:06:23 <Heffalump> only if they were isomorphic, so then all you're saying is that it only stores type information up to isomorphism
16:06:35 * TuringTest points at newtype
16:06:38 <Heffalump> (i.e. you get generative equality rather than applicative equality)
16:07:16 <Heffalump> anyway, we are all agreed that GADTs _are_ erased at compile-time, right? ;-)
16:09:46 <TuringTest> Any idea how SYB (version 2 or 3 or...) deals with GADTs?
16:10:09 <TuringTest> (where SYB = Scrap Your Boilerplate)
16:10:30 <Cale> TuringTest: it doesn't? :) That would be my guess.
16:11:14 <Cale> GADTs are newer than SYB afaik
16:11:30 <Cale> a followup treatment would be interesting though
16:11:39 <TuringTest> SYB 4 : TH 4 GADTs
16:12:37 <Cale> noooo...
16:12:39 <Cale> hehe
16:12:48 <TuringTest> .. coming next xmas ...
16:13:19 <TuringTest> Would you prefer SYB 4 : Scrap Harder!
16:13:35 <Cale> hehe
16:13:47 <TuringTest> And on that that note...
16:13:50 <Cale> GADTs for TH might be interesting
16:13:50 * TuringTest leaves for bed.
16:13:52 <Heffalump> how about "SYB 4 : the nightmare continues" ? :-)
16:14:14 <TuringTest> SYB 4 : Hide the children!
16:14:18 <Heffalump> oh, could you embed the entire Haskell type system into a type parameter?
16:14:26 <Heffalump> (re GADTs for TH)
16:14:47 <musasabi> heh
16:14:58 <musasabi> JHC does that afaik (or at least plans to)
16:15:02 <Cale> Heffalump: I'm not sure, but it would be something to try :)
16:15:04 <TuringTest> SYB 4 : deriving you insane next xmas!
16:15:05 <musasabi> and I think GHC is going the same route.
16:15:15 <esap> "SYB 4: Proves your code correct at run-time" :-)
16:15:17 <musasabi> with type Type which is a GADT...
16:15:21 <Heffalump> you'd need Igloo's anti-unification at some point
16:15:42 <musasabi> of course that needs extensible GADTs..
16:16:17 <SamB> Is that anything like antifreeze?
16:16:39 * esap thinks anti-unification sounds like equalizers.
16:16:56 <Heffalump> equalizers?
16:16:57 <Cale> anti-unification... isn't that segregation?
16:17:16 <Heffalump> it's what you have to do if you want to type check TH programs properly
16:17:41 <Heffalump> right now a piece of TH that represents a Haskell expression just has type Exp
16:17:47 <esap> prob different thing what I thought about then.
16:18:00 <Heffalump> it would be nice if the type could be Exp a where a is the Haskell type of the expression
16:18:32 <Heffalump> but then you can't give a type to the TH expression if condition then (foo :: Exp String) else (foo :: Exp Int)
16:18:36 <Heffalump> s/foo/bar/2
16:18:45 <Cale> esap: equalisers in the sense of category theory?
16:18:54 <esap> Cale: yes.
16:19:36 <SamB> Heffalump: that would be quite insane indeed...
16:19:37 <esap> Heffalump: wouldn't that have the type Exp (Either String Int)
16:19:46 <Cale> I sort of think that equalisers are probably impractical in type systems, unless you severely restrict the kinds of functions you equalise over.
16:20:12 <Heffalump> esap: no, because you decide at "compile" time (i.e. when your TH program runs) which it should be
16:20:13 <esap> Heffalump: Or Either (Exp String) (Expr Int)
16:20:29 <Heffalump> esap: well, if it's the latter, then it's not Exp anything
16:20:58 <Heffalump> which makes life rather hard when you try to actually reify it
16:21:07 <SamB> Heffalump: how does that interact with types that do not yet exist?
16:21:24 <Heffalump> SamB: like what?
16:21:32 <esap> Exp (Either (Exp String) (Exp Int)) hmm...
16:21:38 <Heffalump> esap: errm, no :-)
16:22:04 <Heffalump> anyway, the point is that when you run into a conflict like that you have to give up and say Exp "something arbitrary"
16:22:06 <SamB> like, say, they are defined in the module you are splicing into?
16:22:19 <Heffalump> and then "something arbitrary" needs to unify with absolutely anything to give "something arbitrary".
16:22:21 <carp> sounds like you need some computation at the type level ;)
16:22:23 <Heffalump> so we have anti-unification
16:23:15 <Heffalump> SamB: well, you'd have a hole that you could hopefully do standard HM with
16:23:29 <Heffalump> if you have .... $(thprogram) ....
16:23:45 <Philippa_> carp: get the language ready for production use then? ;-)
16:24:02 * Philippa_ will actually make more than one CFR lecture next year assuming there was enough turnout to keep the module running?
16:24:14 <esap> Heffalump: Maybe the correct answer there is that compile-time if statements should have the same type in both branches.
16:24:15 <Heffalump> please tell me noone is planning to use Epigram for anything real? :-)
16:24:32 <Heffalump> esap: if you demand that, you rule out valid TH programs that would never go wrong.
16:25:04 <Heffalump> and since "going wrong" only happens at compile-time, it's considered worthwhile to have ones that you can't fully type check
16:25:08 <SamB> Heffalump: I do hope so! at least not until they get a decent UI going
16:25:51 <Philippa_> Heffalump: I'd have a go at it given IO, although FCVO "real"
16:26:06 <esap> Heffalump: ok, I have to admit there are cases where compile-time type checking just cannot be done, then you just have to isolate those parts of the program that cannot be checked from other parts.
16:26:18 <SamB> esap: if we could do it under the type-system, why wouldn't we just have oleg show us how to do it *in* the typesystem, rather than using TH?
16:26:27 <Heffalump> esap: and that's the rough idea behind Igloo's soft typing scheme
16:26:37 <Heffalump> which ends up using anti-unification somewhere in the guts
16:27:00 <SamB> wouldn't it be easier to just keep our Exp the way it is?
16:27:14 <Heffalump> yeah, but this would be better
16:27:25 <Heffalump> find programs that could _never_ work, catch errors earlier
16:27:35 * carp reads Boxy types
16:27:36 <esap> Heffalump: I've been thinking there must be two kinds of constraints that may need to be checked. Type checking is another, and resource limits are the other. These two are competing with each other in a way that produces very much complexity.
16:27:45 <Heffalump> as many of the benefits of a type system as possible, without going all the way to full type correctness
16:28:08 <SamB> how long does it take to wait for splicing?
16:28:29 <esap> Heffalump: But for template-haskell stuff, I haven't actually thought about it.
16:28:30 <Heffalump> SamB: "earlier" in the sense of closer to the place you made the mistake, not earlier in time
16:28:48 <SamB> Heffalump: oh
16:28:51 <SamB> there is that...
16:29:08 <SamB> if you can do it without making TH more painful, more power to me!
16:29:10 <Heffalump> anyway, I don't think it'll ever be implemented, cos Igloo doesn't have time
16:29:20 <esap> Heffalump: Maybe in template-haskell, we get a third kind of constraint, which is "compile-time resource consumption". hmm...
16:30:03 <SamB> esap: haha
16:30:21 <SamB> the type checker already has some serious issues in that respect...
16:30:33 * Heffalump goes to bed
16:30:41 <SamB> just ask joelr when you see him...
16:32:41 <esap> SamB: The problem is much worse when you give the programmer all the power he doesn't want :-)
16:33:57 <esap> SamB: Normally, language design is constrained by the decidability of type checking (and inference etc.). But with template-haskell stuff, I doubt such constraints are possible.
16:34:18 <esap> Unless you constrain it too much for it to be useful
16:35:12 <SamB> TH isn't supposed to be type-safe... but the type-errors you get as a result *will* be at compile time...
16:38:12 <carp> what does TH have over GH?
16:38:28 <Philippa_> you can't build a cheat compiler with GH
16:38:37 <Philippa_> to give an example
16:38:41 <Philippa_> or do compile-time IO, or...
16:39:00 <carp> fair, haven't looked at either
16:39:30 <Philippa_> TH basically uses haskell code to generate ASTs for haskell code which then get spliced into a module before it's compiled
16:39:51 <Philippa_> GH lets you derive implementations for typeclasses based on the structure (in the sums-and-products sense) of a type
16:40:18 <musasabi> TH allows one to subvert the safety mechanism in the language like modules.
16:40:40 <Philippa_> TH makes you /almost/ as unsafe as lisp ;-)
16:41:01 <musasabi> almost?
16:41:10 <Philippa_> the resulting code at least gets type-checked
16:41:24 * musasabi considers the ablity to mock inside the datatypes of other modules quite serious.
16:41:34 <SamB> thats a heck of a lot safer, IMO...
16:41:46 <SamB> also, you can't really go nuts adding things to the symbol table or anything...
16:41:49 <musasabi> Philippa_: yes, thus one uses unsafeCoerce# to make such puny attemps to stop things go away.
16:42:15 <sploo22> #python
16:42:25 <Philippa_> musasabi: I blame GHC! :-)
16:42:25 <sploo22> oops
16:42:26 <SamB> musasabi: but you must be explictly nasty, rather than accidentally so
16:42:47 <SamB> sploo22: has gone insane
16:43:01 <Philippa_> sploo22: we don't much like pythonistas in these parts...
16:43:02 <Philippa_> ;-)
16:43:34 <SamB> we loves python3k refugees, though
16:43:35 <sploo22> sorry, that was a typo anyway
16:46:53 <musasabi> SamB: point, but even if one does not use unsafe* one can get at the internal structure of datatypes.
16:47:17 <SamB> musasabi: so?
16:47:46 <SamB> can one DO ANYTHING with it?
16:47:59 <Philippa_> being able to see it I don't see as a problem so long as scope on everything's enforced on the generated code (so you can't really /do/ anything with it as such except via peeking, poking and general dirtiness)
16:48:05 <SamB> if so, I think that TH has scoping issues...
16:48:26 <SamB> Philippa_: exactly!
16:51:10 <musasabi> Philippa_: One can see inside datatypes which don't export the constructors or any accessors.
16:51:25 * esap once thought I needed to use unsafeCoerce#, but then realized I could prove myself out of that problem.
16:51:51 <musasabi> and write updaters which change some values inside the datatype (producing the new updated value etc)
16:53:57 <Philippa_> musasabi: can you do that without peek/poke or the moral equivalent?
16:55:01 <musasabi> Philippa_: yes.
16:55:29 <Philippa_> okay, that's bad. What's the trick?
16:55:35 <musasabi> http://cs.helsinki.fi/u/ekarttun/SerTH/SerTH/Codec/Serialize/SerTH/EvilAccessor.hs
16:55:48 <musasabi> (positional accessor into any datatype)
16:57:31 <musasabi> it is used like $(evilAccessor ''Dynamic 0)
16:57:43 <Philippa_> *ah*
16:57:49 <musasabi> (to get a function which extracts the first element from a Dynamic)
16:58:04 <musasabi> the same way one can build updaters etc
16:58:13 <Philippa_> okay, if I've understood that it's still a scoping fuckup, as in the constructor shouldn't be in scope in the first place?
16:58:28 <Philippa_> (and so reifying the typename to a declaration to find out what it's called shouldn't get you anywhere in the long run)
16:59:24 <musasabi> yes, one gets the constructor and it just compiles without checking whether it is in scope or not I think.
16:59:44 <SamB> bug!
16:59:50 <musasabi> then again one needs that hack to get the derivation to work too, so eliminating it makes things hard.
16:59:50 <SamB> or should be anyway
17:01:06 <esap> Some things should be hard.
17:02:36 <Philippa_> there should probably be a GHC "really really unsafe, no, really, I mean it" lib for that kind of peeking/poking
17:03:04 <SamB> you mean like Unsafe.Unsafe.Unsafe.* ?
17:03:43 <esap> I'd prefer something that would be designed to work at low level of abstraction.
17:04:08 <esap> With proper type system, of course.
17:04:17 <Philippa_> SamB: I think more something that's legit with a specific compiler flag only
17:04:19 <musasabi> Unsafe.Yes.I.Know.I.Should.Not.Do.This.Evil.Thing ?
17:04:45 <Saulzar> is "evil" one removed from "unsafe" ?
17:04:50 <Philippa_> -fyesIknowthiscouldsummoncthulhuintomykerneldoitanyway
17:05:08 <SamB> heh
17:05:11 <esap> I'm thinking more like support for OO. OO is low level.
17:05:13 <SamB> thats funny.
17:06:10 <esap> no need to be too unsafe.
17:06:11 <musasabi> --unsafe-please-fuckmeup ?
17:06:13 <SamB> I asked on ##c a while back if it would be conforming for "undefined behaviour" to summon cthulu
17:06:22 <SamB> the answer I was given was "yes"
17:06:50 * araujo wonders if it is worthy to have somehting like a backslash special character escape when you already have quote support.
17:07:01 <esap> sure, there was once a compiler that started nethack when the programmer did one of the things specified as undefined behaviour.
17:07:27 <SamB> well, starting nethack isn't nearly so dangerous.
17:07:30 <esap> the "feature" was quickly removed, of course, for practical reasons.
17:07:45 <SamB> I mean, the worst thing that could happen would be for the programmer to play nethack...
17:07:46 <Philippa_> http://www.cthulhulives.org/Solstice/index.html (speaking of cthulhu)
17:07:49 <SamB> hardly fatal!
17:07:52 <Philippa_> # I've got a friend in Cthulhu
17:08:21 <araujo> Anybody knows a nice game written in Haskell for Linux?
17:08:28 <Saulzar> Though it is fair to say you probably won't last 5 minutes in nethack unless you're lucky :)
17:08:32 <SamB> you mean besides Frag?
17:08:38 <SamB> or is that not nice?
17:08:48 <araujo> SamB, Frag?
17:08:49 <musasabi> mmh, it is quite easy to stay alive quite long.
17:08:50 * esap has played lots of nethack.
17:08:59 <musasabi> stupid deaths are quite annoying.
17:09:05 <SamB> @where frag
17:09:06 <lambdabot> http://www.cse.unsw.edu.au/~pls/repos/frag
17:09:33 <musasabi> (usually I am trying to gambit myself to the mine town and dying because one happens to walk into a trap is not very much fun)
17:09:35 <SamB> @google site:haskell.org hawiki frag
17:09:36 <lambdabot> http://haskell.org/hawiki/Frag
17:10:05 <SamB> I have no idea what any of that is...
17:10:07 <esap> musasabi: play Wizard, and you don't need to worry about traps too much
17:10:13 <SamB> well, not too much idea.
17:10:22 <musasabi> esap: mmh, how not to worry?
17:10:37 <SamB> what does it mean to gambit oneself to the mine town?
17:10:43 <esap> musasabi: resist magic traps
17:10:52 <araujo> SamB, ooh.. i didn't know about this game, thanks
17:11:03 <esap> musasabi: with cloak of magic resistance
17:11:05 <musasabi> esap: does not help against pits or flame traps killing you.
17:11:21 <SamB> also, feel free to do a roguelike in Haskell ;-)
17:11:40 <esap> musasabi: I haven't had trouble with those, you need to keep your HP up at all times of course.
17:11:58 <musasabi> with a healer the gambit is easy (blessed extra heal for hitpoints, so the traps won't be fatal)
17:12:24 <SamB> what is "the gambit"?
17:12:29 <musasabi> esap: but with the gambit one has to be on the first level till the mine town, and it is quite hard to get many extra hitpoints as a wizard early on.
17:12:54 <musasabi> SamB: getting into the minetown as a first level character so one has money to buy the max protection from there.
17:12:58 <esap> musasabi: I haven't played healer much, I don't know about the gambit.
17:13:24 <SamB> hmm?
17:13:49 <SamB> do things cost less that way, or do you have to pay money to level up?
17:13:54 <esap> musasabi: I usually get the protection by going for the treasure at the bottom of minetown.
17:15:11 <musasabi> SamB: max protection usually costs (3600gp * num_of_levels) from the minetown
17:15:30 <SamB> oh
17:15:37 <SamB> what is "max protection"?
17:15:40 <musasabi> will give a naked AC 1
17:18:08 <BlueBlazer> Newbie here --  What is a good Haskell IDE?
17:18:31 <Philippa_> um. There isn't one as such. GHCi and a good text editor with syntax highlighting set up works well for many people though
17:18:46 <Philippa_> there's an emacs mode and a small infinity of variants thereof floating around somewhere
17:18:57 <Philippa_> hIDE's not really ready for use from what I've heard
17:19:03 <musasabi> and if you are using Windows there is the Visual Studio integration.
17:19:45 <SamB> hmm. how do you run nethack for the best-looking display?
17:19:58 <BlueBlazer> Sorry --- I am OS X
17:20:04 <esap> SamB: linux console?
17:20:09 <BlueBlazer> failed to mention that
17:20:27 <SamB> hmm.
17:20:47 <Philippa_> pick a text editor, find a syntax definition file or similar, use GHCi. It's plenty workable
17:20:54 <Philippa_> (ghc --make is also useful)
17:20:55 <BlueBlazer> Ok
17:20:59 <musasabi> use something like http://youzen.b2.fi/~musasabi/nethackrc as .nethackrc
17:21:06 <BlueBlazer> I have ghc
17:21:12 <BlueBlazer> thanks Philippa
17:21:24 <BlueBlazer> and the rest
17:21:27 <musasabi> BlueBlazer: running ghci inside emacs is usually quite nice.
17:21:49 <BlueBlazer> I have done that with slime
17:21:51 <fieldy> GNU/Emacs rocks a lot with haskell
17:21:51 <fieldy> :$
17:21:56 <fieldy> (another haskell newbie)
17:22:18 <BlueBlazer> thanks musasabi
17:22:27 <SamB> how do you quit and save?
17:22:29 <BlueBlazer> and fieldy
17:22:37 <Philippa_> emacs sucks. Then again, vi's satanic (VIVIVI)
17:22:47 <fieldy> ah ah Philippa_ ;)
17:22:56 <musasabi> Philippa_: but it sucks quite well.
17:23:04 <fieldy> BlueBlazer: I use GHC + GNU/Emacs over OSX Panther
17:23:20 <Philippa_> sure, but I was looking for an editor that could use its tongue properly ;-)
17:23:54 <fieldy> sorry, I'm from spain and I don't understand this joke
17:23:57 <fieldy> excuse me
17:24:02 <musasabi> Philippa_: you just have to teach it few hundred lines of elisp and some discipline to make it behave nicely.
17:24:04 <carp> most gui emacs on mac are quite flaky :(
17:24:12 <fieldy> yes carp
17:24:21 <fieldy> but you may use vi too ;)
17:25:02 <carp> i've ended up going back using it in a terminal
17:25:16 <Philippa_> fieldy: not so good if you're working on a project with an emacs-based UI
17:25:39 * carp mutters
17:25:53 <Philippa_> I never really got to test the stability of the windows-based ports. My patience runs out too soon
17:25:54 <musasabi> vi emulation works nicely,
17:25:55 <Philippa_> carp: ?
17:26:26 <musasabi> emacs makes windows barely usable, the other alternatives seem to be putty or tightvnc.
17:26:45 <carp> the carbon ones are flaky, the guy that wrote both of them got fed up with each community in turn and then sacked it off
17:26:58 <Philippa_> that stinks :-(
17:27:27 <SamB> emacs users must be evil or something
17:27:29 <Philippa_> musasabi: there're ways to make windows okay. If you find usable = just like home then you're probably right though
17:27:43 <carp> SamB: no it's the developers!
17:28:12 <Philippa_> did jcm get involved? :-)
17:29:00 * esap thinks emacs hasn't developed much in 10 years or so. All the same stuff works just as badly as always. But it's still the best editor available.
17:29:43 <fieldy> windows isn't too bad 
17:29:50 <fieldy> if you care it too much, sure
17:29:51 <fieldy> :)
17:30:05 * carp would be happy if the mac ports worked as well as the linux ones
17:30:30 <Philippa_> is there no generally-accepted trick for running X apps on macs?
17:31:08 <musasabi> there is the X server thing, but that is not very well integrated.
17:31:09 <araujo> @index Either
17:31:09 <carp> yeah, but native is nicer, and even the X11 XEmacs is a bit crap
17:31:09 <lambdabot> Data.Either, Prelude
17:31:18 <araujo> @type Either
17:31:19 <lambdabot> Not in scope: data constructor `Either'
17:31:24 <fieldy> you may use X11 server over os x
17:31:25 <SamB> hmm, apparantly kicking chests is a bad diea
17:31:30 <SamB> er, idea
17:31:49 <araujo> fieldy, spanish?
17:32:24 <fieldy> yes araujo 
17:32:46 <fieldy> bad english speaking :(
17:33:00 <SamB> how do I save my nethack settings?
17:33:14 <Saulzar> Roguelike games are evil, you get complacent and die every time
17:33:15 <musasabi> SamB: write a .nethackrc
17:34:47 <araujo> fieldy, cool, we've got a #haskell.es !
17:37:10 <SamB> hmm, does "more info" ever give useful information (when using /)?
17:38:05 <araujo> fieldy, stop by there ;-)
17:54:12 <fieldy> araujo: thx
18:07:52 <lispy> @type maybe
18:07:54 <lambdabot> forall b a. b -> (a -> b) -> Maybe a -> b
18:08:18 <lispy> > maybe (+1) Nothing
18:08:20 <lambdabot>   Expecting a function type, but found `Maybe a'
18:08:20 <lambdabot>   Expected type: a1 -> a -> a
18:08:20 <lambdabot>   Inferred type: Maybe a2
18:08:40 <lispy> oh
18:08:49 <lispy> > maybe 0 (+1) Nothing
18:08:50 <lambdabot> 0
18:09:10 <lispy> hmm...maybe may not be what i want...
18:09:43 <lispy> > maybe () return Nothing
18:09:44 <lambdabot> Couldn't match `()' against `m a'
18:09:57 <lispy> oh well
18:10:40 <lispy> i had this problem today in VB where I had two objects, either one of which might be uninitialized.  If either was initialized I wanted to call member functions, otherwise ignore that one
18:11:00 <lispy> all day i was thinking "maybe" would have been a nice solution if i'd had that option
18:12:49 <lispy> even if maybe is the wrong function, it would have been easy to solve my problem in a functional language
18:21:12 <Saulzar> > maybe 0 (+1) Just 5
18:21:12 <lambdabot>   Expecting a function type, but found `Maybe a'
18:21:12 <lambdabot>   Expected type: Maybe (t -> t1)
18:21:12 <lambdabot>   Inferred type: a -> Maybe a
18:21:17 <Saulzar> > maybe 0 (+1) (Just 5)
18:21:19 <lambdabot> 6
18:22:38 <resiak> @type maybe
18:22:39 <lambdabot> forall b a. b -> (a -> b) -> Maybe a -> b
18:22:46 <Saulzar> lispy, I know what you mean, when you've got this idea in your head it just infuriates you when can't do it the way you'd like :)
18:22:48 <Pupeno_> DNS compression is evil.
18:22:55 <resiak> Cunning.
18:28:32 * carp tries to compile head for the millionth time
18:31:36 <shapr> main = head ?
18:32:33 <carp> i mean the head branch of ghc
18:32:58 <shapr> @seen roconnor
18:32:59 <lambdabot> I saw roconnor leaving #haskell 10 days, 7 hours, 26 minutes and 7
18:32:59 <lambdabot> seconds ago, and I have missed 7 days, 8 hours, 10 minutes and 49 seconds
18:32:59 <lambdabot> since then.
18:36:08 <shapr> carp: Are you a decorative japanese fish?
18:37:38 <carp> quite right, i have an waterproof computer 
18:37:50 <carp> s/an/a
18:37:56 <shapr> Nifty.
18:40:26 <tennin> hmm, I'm reading Hughes' original paper on arrows and he's lost me a bit in the ArrowApply discussion
18:40:41 <musasabi> Pupeno_: did you look at the code which implements it quite cleanly?
18:41:35 <shapr> tennin: Ross Paterson's Fun of Programming chapter on arrows is easier to read.
18:42:11 <tennin> he says: "...another conclusion to draw is that arrows supporting "app" are really of little interest to us here.  Our motivation, after all, is to find a generic interface for combinator libraries which cannot be based on a monad.  But clearly, any library which supports an arrow type with app could equally well be given a monadic interface..."
18:42:49 <shapr> Arrows are a superset of monads.
18:43:06 <tennin> I see how he's shown that some ArrowApply can be used to implement every Monad, and that every Monad can be used to implement some ArrowApply (w/ Kleisli)
18:43:39 <shapr> What parts are confusing?
18:43:46 <tennin> but, doesn't he need to show that some Monad can be used to implement every ArrowApply?
18:43:53 <tennin> is that implicit somehow?
18:43:59 <Pupeno_> musasabi: no, I'm sorry (I found code much easier to write than to read).
18:44:26 <shapr> I don't understand the question.
18:44:46 <musasabi> Pupeno_: well, if you look at it, then you can see how to decode the compression.
18:45:01 <Pupeno_> musasabi: and I was taking another aproach at serialization. Anyway, I am far from handling compression.
18:45:07 <shapr> Once I worked my way through the paper (months later), it was perfectly clear to me that arrows were monads and then some.
18:45:29 <musasabi> Pupeno_: you need to modify NewBinary to support that at least.
18:45:43 <Pupeno_> musasabi: to support compression ?
18:45:51 <shapr> oy, it's nearly 4am
18:45:56 <musasabi> to support DNS compression - and it won't be very elegant.
18:45:57 * shapr falls over asleep
18:46:03 <musasabi> shapr: good night.
18:46:20 <tennin> Right... but are ArrowApply's "just" monads?
18:46:43 <Pupeno_> musasabi: I can't understand what you mean.
18:47:44 <musasabi> Pupeno_: well you want something like the goto combinator in the code I gave you.
18:48:41 * Pupeno_ doesn't even know what a combinator is. I am not having a good day today.
18:48:52 <Pupeno_> How do you read a String out of a BinHandle ?
18:49:36 <musasabi> get_ bh :: IO String ;)
18:49:41 <musasabi> but that is not what you want.
18:50:14 <carp> tennin: does it mean that if you can create an instance of ArrowApply for something then you can also create a Monad instance and then use the monad interface instead?
18:51:01 <tennin> right
18:51:19 <Pupeno_> musasabi: I can't find that String is a instance of Binary, is it ? How does it know where to stop reading ? what do I want ?
18:53:31 <carp> I think one of the problems with Arrows is that nobody really knows what they are, they don't have the nice categorical explanation that Monads and Idioms have
18:53:45 <carp> they're just useful...
18:53:51 <carp> i think
18:56:58 <tennin> Idioms?
18:57:09 <musasabi> Pupeno_: It uses a lenght prefix which is either 4 or 8 bytes depending on the platform you are compiling NewBinary.
18:57:37 <Pupeno_> i333+
18:57:38 <Pupeno_> 6666666.96
18:57:54 <carp> tennin: http://www.cs.nott.ac.uk/~ctm/IdiomLite.pdf 
18:58:04 <Pupeno_> indeed that is not usefull :(
18:58:12 <carp> yet another way of structuring your programs
18:58:37 <Pupeno_> good night.
18:58:53 <carp> I think Ross has now added them to the library too
19:09:58 <Cale> tennin: Not every arrow is a monad.
19:20:17 * SamB mutters something about "^ |ong worm can be d???nec ?ec?rsivelv   So hcw sh?uld you ?t?ac|
19:20:17 <SamB> it?"
19:23:20 <Saulzar> Heh, character recognition?
19:24:46 <SamB> Saulzar: close. barely-legible writing in nethack ;-)
19:32:30 <Saulzar> Heh, an OCR simulator then :)
19:33:36 <javed> hi guys
19:33:45 <javed> i am doing perl 
19:33:48 <javed> lang
19:33:57 <javed> network programming in  perl
19:35:19 <araujo> ?
19:35:22 <musasabi> does it help if we tell that we are sorry for you?
19:35:27 <araujo> hahaha
19:43:25 <akemp> Anyone have any leads on genetic algorithm code for Haskell?
19:43:46 <akemp> I've got Vestin's thesis, but would like some more examples.
20:16:00 <Cale> akemp: actually, that might be a rather interesting thing to do in Haskell -- I suspect the approach would be different based on how flexible you want the genetic part to be
20:17:45 <Cale> You could easily create a reader-type monad which provided a supply of genotype material, which would be passed into the algorithm via a list, which would be consumed as the algorithm ran.
20:18:35 <musasabi> I think the OCaml people are likely to have some examples (as they have more numeric code) so it might be worth looking at.
20:18:53 <musasabi> of course they are probably doing dirty tricks with mutable state, but you might get some ideas.
20:19:05 <Cale> numeric stuff of this sort can be quite fun in a lazy language.
20:19:24 <Cale> basically, search problems are well suited to lazy languages
20:19:48 <akemp> Thanks for the suggestions.  I've grabbed a couple of Ocaml examples...
20:19:57 <akemp> ... but I frickin' hate Ocaml's syntax...
20:20:06 <Cale> You could create a tree of lazily evaluated variants
20:20:14 <musasabi> Cale: I find it hard to compute time bounds for my Haskell code.
20:20:48 <Korollary> akemp: Have you tried the alternative ocaml syntax? It's somewhat better, imho.
20:21:15 <akemp> I am a bit worried about memory consumption in Haskell, though.
20:21:17 <Cale> musasabi: yeah, it can be tricky, especially in isolation because performance is often more dependent on how the result is denanded than how it's written.
20:21:23 <Cale> demanded *
20:21:38 <musasabi> Cale: yes, makes things quite complex.
20:21:49 <akemp> Korollary: haven't seen the alternative ocaml syntax.  The other thing that frustrated me was the confusing messages output by the compiler.
20:21:51 <Cale> musasabi: it can also make things quite simple :)
20:22:08 <musasabi> akemp: that is usually not a problem when you get experienced.
20:22:09 <BlueBlazer> Yet another completely newbie question
20:22:11 <Cale> Well, it tends to help a lot in writing efficient implementations
20:22:25 <BlueBlazer> What is the standard file extension for a haskell source file
20:22:26 <BlueBlazer> ol
20:22:29 <BlueBlazer> lol
20:22:38 <Cale> BlueBlazer: .hs or, for literate haskell .lhs
20:22:39 <Korollary> BlueBlazer: hs or lhs if literate haskell
20:22:41 <musasabi> Cale: yes, but it is more of a "this code is fast" rather than "I know this is O(something)"
20:23:00 <akemp> musabi: true, but given the compiler error messages and the funky syntax, I picked Haskell.
20:23:35 <BlueBlazer> what is the difference between literate haskell and the well I guess illiterate haskell
20:23:47 <Korollary> musasabi: That is interesting. Shouldn't it be easier to figure out computational complexity in haskell?
20:23:49 <musasabi> akemp: usually I find that my first solution leaks memory. Then I profile things and change < 10 lines and memory problems go away.
20:24:23 <musasabi> Korollary: well it depends on evaluation time, CSE, deforestation etc
20:24:30 <Cale> BlueBlazer: In literate haskell, the default is a comment, and you type something special (either start your lines with > or use \begin{code} \end{code}) to denote sections of code
20:24:46 <BlueBlazer> thanks
20:25:29 <Korollary> musasabi: but doesn't that just blur the constant coefficient portion?
20:26:55 <akemp> musasabi: yeah, but I find that identifying those 10 lines in Haskell is a challenge.  Often it seems that a trivial re-monading fixes things, but, without being shown, I can't come up with the re-monading myself.  Add experience, re-monad, rinse, repeat, eh?
20:26:58 <Cale> If you think the right way, it's usually not too hard to judge at least approximate time/memory bounds, by rewriting the lazy evaluation into an imperative form in your head :)
20:27:46 <Cale> Lists are essentially loops.
20:27:53 <musasabi> akemp: profiling can help things, many times you have 98% of allocation in one function (in the naive version) and then just optimize that.
20:29:45 <musasabi> Korollary: not really. (or yes, if you think of allocation as a free-cost thing)
20:30:42 <Cale> It seems that the trend is that when things don't perform, the first thing people think of is to strictify things.
20:30:58 <Cale> It's often forgotten that making things lazier can also help.
20:31:29 <Cale> Usually the worst performing programs are somewhere in between being lazy and strict.
20:32:03 <musasabi> "first leave all the thunks on the heap, then strictly evaluate them and then discard the result."
20:32:10 <Cale> They demand too much because of strictness and then hold on to it too long due to laziness.
20:32:15 <akemp> musasabi: I spent a lot of time profiling and revising the n-body simulation of the Great Computer Language Shootout to little effect.
20:33:16 <Cale> I think the right view of things combines both ways of thinking. The general heuristic is this:
20:33:16 <musasabi> akemp: was it using mutable state?
20:33:28 <akemp> musasabi: nope.
20:33:43 <musasabi> akemp: that is why it is slow. Next problem?
20:33:49 <Cale> Large structure -> Small structure (where the entire large structure is needed) : Use strict evaluation.
20:34:01 <musasabi> (if I remember the test right it just loops mutating the Doubles)
20:34:01 <Cale> Large structure -> Small structure (where only part of the large structure is needed) : Use lazy evaluation.
20:34:14 <Cale> Small structure -> Large structure : Use lazy evaluation.
20:35:00 <Cale> Between structures of the same size, it usually doesn't matter, but you probably want lazy evaluation between large structures because it may help later.
20:35:15 <akemp> Which brings up my next question: what is a good functional technique to mutate a group sequentially without using a lot of memory?  (e.g. (a1,b1,c1) = f(a0,b0,c0) ) 
20:35:51 <Cale> akemp: well, that should be fine, memory wise, so long as you don't hold on to a0, b0, c0
20:36:08 <Cale> i.e. you never use them or refer to them, only to their mutations
20:36:11 <musasabi> akemp: uniqueness types + clean.
20:36:29 <akemp> "clean" as in the language?
20:36:35 <Cale> Even without uniqueness types, the concept of uniqueness will help make things more efficient
20:36:36 <musasabi> Cale: that is not enough for that benchmark, it is really just a microthing.
20:36:48 <Cale> which benchmark?
20:36:51 <akemp> n-body
20:36:54 <Cale> ah
20:36:55 <musasabi> the shootout n-body
20:37:05 <Cale> okay, well, I haven't looked at that myself
20:37:34 <musasabi> akemp: use something like FastMutDouble (with a shared array backend) + ST + syntactic sugar
20:37:46 <Cale> But you should be aware that you can just strictify everything if it makes you happy, though I probably wouldn't, in a refinement-type solution
20:38:15 <Cale> Have you read "Why Functional Programming Matters"?
20:38:23 <akemp> Yes.
20:38:38 <Cale> that shows some really nice applications of lazy functional programming to numerical techniques
20:39:26 <akemp> Doh.  Looks as though I need to read it again...
20:39:45 <Cale> Seems like lots of people read it and don't catch the point :)
20:39:47 <musasabi> The benchmark is about "do thing X this way without any algorithmic optimizations allowed" which makes it harder to compete with C without doing the same thing as C.
20:40:15 <Cale> The whole point of that essay is that Laziness is *the* major glue for functional programming.
20:40:17 <SamB> me too
20:40:32 <SamB> one of those, ey?
20:40:42 <SamB> those should *die*
20:40:56 <Cale> I wouldn't waste my time on something like that.
20:41:16 <SamB> you could just foreign import the C version...
20:41:20 <Cale> algorithmic optimisations are where it's interesting :)
20:42:07 <Cale> I think there should be a contest for modular design :)
20:42:16 <musasabi> The problem with shootout benchmarks is that usually after 20 or so solutions have been implemented someone finds an algorithmic optimizations. Then the test will just tell "which solutions use the specialized algorith and which the one given in the example" and not really compare the languages.
20:42:17 <Cale> I suppose that's what ICFP is about.
20:42:48 <musasabi> Thus one tries to specify what the program must do - thus making it harder to make natural solutions.
20:42:52 <Cale> musasabi: It's impossible and silly to compare *languages* anyway
20:42:58 <akemp> I'd still like to understand how performance is affected by design decisions, which is why I poked at the n-body problem for a few hours..
20:43:01 <Cale> you can only really compare implementations of languages
20:43:05 <musasabi> Cale: yes, language implementations.
20:43:26 <SamB> which is why thats what the shootout does...
20:43:31 <Cale> I might take a look at that code
20:44:13 <Cale> But even after you're comparing implementations, it's next to impossible to compare implementations of different languages in any sort of meaningful way.
20:44:29 <glasser> yeah, I'm still amused by the fact that the one TuringTest posted earlier optimizes to 2*N
20:44:33 <Cale> Maybe if you gave people the same amount of time to implement the algorithm
20:44:58 <akemp> musasabi: you referenced "FastMutDouble", which I assume is a fast mutable array of doubles?  Is that part of the GHC libs?  (I'm looking around for it.)
20:45:07 <musasabi> Another problem is that the problems have to be such that they can be implemented simply in quite short C/java code, which rules out problems that are interesting.
20:45:42 <musasabi> akemp: like fastmutint, only you take them all out of the same shared array which happens to be for doubles.
20:47:21 <Cale> akemp: btw, what did you mean above by monadifying things?
20:47:48 <Cale> Usually adding monadic abstraction should only force the compiler to have to work harder to optimise the code.
20:48:10 <Cale> Though it might give you access to mutable variables, which can help in some cases.
20:49:40 <musasabi> I think the problem selection is the largest single problem with shootout.
20:50:02 <Cale> hmm, why is the Haskell n-body solution using IORefs rather than just going with ST? Is that really faster?
20:50:05 <akemp> cale: I meant that it seems that a lot of computations can be expressed simply using functions, but that performance will be limited by huge memory consumption.  In a few examples I've seen, the solution to memory consumption is to use a monad to create mutable variables.
20:50:24 <musasabi> because if a problem where func. languages would shine would be picked an efficient implementation in C/Java would be too long.
20:50:26 <Cale> akemp: well, that's not necessarily the case
20:50:37 <musasabi> I think ST is faster than IO
20:50:57 <Cale> akemp: though I suppose that it can help you think in a way which is conducive to writing single-threaded code
20:50:59 <musasabi> at least it should be.
20:51:45 <Cale> musasabi: well, it ought to be similar, but this is using a reader monad to carry around the variables needed
20:52:09 <musasabi> the tests go for lowest common denominator which tends to make things attractive for C.
20:52:32 <Cale> I'd like to see some tests which would be serious effort in C.
20:52:41 <audreyt> has anyone benchmarked implicit params vs reader monads seriously?
20:52:44 <Cale> Pipeline scheduling of code would be neat :)
20:52:51 <Cale> hehe
20:53:23 <audreyt> certainly if half of your functions doesn't use implicit params, then it's going to be faster... but what if everything does consume all implicit params (making it equiv. to reader monad)?
20:53:24 <Cale> where you'd get marked on the performance of the resulting code as well as the speed of scheduling it
20:54:04 <Cale> audreyt: there's also just passing things explicitly
20:55:51 <Cale> My 600 line (1200 if you count documentation) pipeline scheduler would easily be 15000 lines of C. I'm quite certain I couldn't have written it in the time I had.
20:56:21 <audreyt> Cale: yeah, but I wonder if there's any diff (either positive of negative) with implicit param
20:56:26 <audreyt> guess I should just go ahead and benchmark.
20:56:32 <Saulzar> Cale, If you were worried about "hard to compare" earlier,  introducing additional variables isn't going to help I suspect :)
20:56:38 <musasabi> Cale: and a problem with a C solution if >200 lines, won't be very probably accepted into the shootout.
20:57:14 <musasabi> audreyt: at least the implicit param will make it harder to control inlining (and be more unportable)
20:58:07 <Cale> Saulzar: well, sure, but surely comparing on actual hard problems is more interesting than comparing on toy problems which are more dependent how close the language is to the machine than how clever the compiler is in optimising code, and how expressive the language can be
21:00:41 <Cale> I think a more interesting metric would compare human time spent writing the algorithm vs. execution speed.
21:01:16 <Saulzar> I see what you're saying... but I think at least the solution should be known - comparing different algorithms in different languages with different results seems a little hard
21:01:48 <Cale> well, if you have a way of measuring the quality of results, it's not so bad
21:02:18 <Cale> we're already measuring code length, memory, and cpu time
21:02:19 <Saulzar> With different numbers of authors :)
21:02:36 <Cale> well, yeah, that too
21:02:48 <Cale> I think the study done by the military was interesting
21:03:13 <musasabi> and sometimes the problems are just changed when one shows that they can be done in constant time in Haskell.
21:03:20 <Cale> I can't remember which military (probably US) or which part, but I could find that paper again
21:04:17 <musasabi> "Why is the Haskell solution beating everyone else?" "Well GHC just transforms what you wanted to be O(n) into O(1)." "oops, lets change the spec."
21:04:23 <Cale> It compared Ada and a bunch of other languages, including two Haskell implementations -- one by a beginner and one by an expert
21:04:42 <Saulzar> The other thing I suppose, is that the majority of code written in any practical software is not algorithms
21:04:57 <Cale> Saulzar: well, depends on the domain
21:05:06 <Cale> there's a *lot* of stupid business code
21:05:15 <musasabi> and what you think of as algorithms
21:05:19 <Cale> which does nothing very interesting at all
21:05:59 <musasabi> sometimes one can transform things into a business DSL which does the boring things with small fuss (of course sometimes it contains too many details)
21:06:55 <Saulzar> Just structuring programs so they can be better extended, maintained etc. seems to eat a fair amount of code
21:07:21 <Saulzar> At least in my programs, perhaps I'm doing something wrong :)
21:07:26 <musasabi> actually usually the definitions are quite short, just 50-150 lines.
21:07:31 <Cale> Usually it's a lot of stupid details, but I think that there's still an advantage to writing those details in a functional language.
21:08:55 <Cale> But what is really needed for that area is something which looks like MS Access, preferably with a more solid DB implementation, and something Haskell-like as the language.
21:09:28 <Cale> Being able to create forms and reports quickly and easily seems to be a major concern.
21:10:15 <Cale> often where all that's being computed is a simple pure function of the inputs
21:12:54 <Cale> A lot of business code is written in VB/VBA for that reason -- because it just needs to work right now, and it'll basically never need maintenance before it's completely rewritten. When it ends up needing maintenance, things become hairy.
21:15:24 <Saulzar> I agree, from my experience it is certainly not hard to structure the simple stuff in fp/haskell - though I probably tend to write it as if it were C++ a little :)
21:16:32 <Saulzar> Things like monads certainly help with eliminating some drudge code, (eg. if blah != null  ... )
21:24:55 <Saulzar> and a function seems to be a pretty nice abstraction for extending things, with currying/closures
21:30:00 <araujo> yup
21:30:17 <araujo> I foudn it more sweet than let's say... object.
21:30:24 <araujo> objects*
21:31:28 <Saulzar> It seems capable of serving the same role
21:32:09 <araujo> Yes.
21:33:48 <Cale> Did you folks see the existentially typed record syntax which is going into the next GHC?
21:34:11 <araujo> Yes.
21:34:30 <Cale> That looks like a nice thing to be able to show the OO people :)
21:34:30 <araujo> Cale, isn't it already there?
21:34:43 <Cale> It's in CVS.
21:35:26 <araujo> Good.
21:36:29 <Saulzar> Existential types do seem appealing (as an OO person), though I've never actually found a use in projects thus far.
21:36:34 <Saulzar> What is this syntax?
21:37:22 <skew> What's this latest weapon in the war on coalgebra?
21:37:46 <Saulzar> What's coalgebra? :)
21:38:06 <skew> It's dual to algebra.
21:38:29 <skew> See, people using object oriented languages are actually doing functional programming, they're just getting everything backwards :)
21:38:42 <Saulzar> Haha.
21:40:51 <Cale> http://www.haskell.org/hawiki/Existentially_20quantified_20record_20constructors
21:41:55 <skew> that's neat
21:42:43 <skew> I'm having fun making Sauerbraten levels with Haskell
21:43:49 <Cale> http://sauerbraten.sourceforge.net/ ?
21:44:49 <Cale> It looks really cool
21:45:00 <Cale> how is it related to Haskell?
21:45:22 <musasabi> what is it? (cannot open links here)
21:45:40 <Cale> an FPS(?) game
21:45:56 <musasabi> mmh, ok
21:47:04 <Cale> With in-game editing.
21:47:08 <skew> yeah, that one. the author Wouter also makes some very strange programming languages
21:47:30 <skew> Well, I wanted to define some fractal shapes algorithmically
21:47:48 <skew> so I implemented some serialization from Haskell
21:47:58 <Saulzar> Hmm, that's pretty cool - it's just the syntax which is new? You could do the same with a record and a type right?
21:48:43 <Cale> Saulzar: well, existentials didn't mix with record syntax before
21:52:02 <Cale> http://wouter.fov120.com/sauerbraten/50/screenshot_980138.jpg -- heh, that's a funny screenshot
21:52:20 <Cale> http://wouter.fov120.com/sauerbraten/50/screenshot_209479.jpg -- this one is impressive
21:52:41 <araujo> Cale, hey, that's definetly object orientation.
21:52:50 <Cale> araujo: yeah
21:52:59 * araujo happy
21:54:09 <araujo> Considering that i came to Haskell from an OO language, im happy to see such a nice way of doing OOP.
21:55:17 <Cale> Well, existentials kind of solved the problem, and this syntax makes the solution nice.
21:56:00 <araujo> Very much.
21:58:01 <Cale> combine it with the module system and you have functional OO exactly :)
21:58:08 <araujo> :-)
21:58:32 <lispy> Cale: are those shots of frag?
21:58:48 <Cale> lispy: no, Sauerbraten
21:58:54 <lispy> what is that?
21:59:12 <lispy> oh
21:59:29 <Cale> Another FPS-type game, not sure if it's in Haskell. Skew mentioned it.
22:00:17 <lispy> it looks interesting for the choice of primitive
22:01:35 <skew> no, it's written in C. Surprisingly little. I'm generating levels with Haskell, though.
22:22:19 <Cale> how are you even supposed to compile it? There's a makefile, but the build fails at some point, and there's no configure script at all.
22:23:09 <lispy> Cale: welcome to 1998
22:23:16 <lispy> Cale: ;)
22:23:42 <skew> readme_source.txt lists the packages you need
22:24:05 <skew> you have to go into enet and build there first
22:24:16 <skew> (that's not documented anywhere I can see)
22:24:32 <Cale> ah, okay
22:29:18 <lispy> have ya'll seen Ogre?
22:29:28 <lispy> it's a physics based game engine that looks cool
22:32:21 <Saulzar> I'm not sure it's anything to do with physics as such...
22:33:26 <Saulzar> It is purely 3D rendering, though people have written things to make it convenient to merge physics libraries
22:34:34 <lispy> hmm...interesting, when i learned about it, it was as a "physics based" game engine, but now that you mention it I don't see a lot about physics
22:38:01 <Saulzar> It's pretty cool - I would definately use it if I were to write a (C++) game these days
22:44:29 <Cale> someone wanted to see a Haskell binding to it
22:44:47 <Cale> It looks rather large, and C++ libraries are annoying to bind in the first place though.
22:45:05 <shapr> Megzl wanted a binding.
22:45:08 <Cale> yeah
22:45:27 <Cale> What in particular is cool/different about it?
22:45:42 <Cale> Perhaps the ideas could be stolen and readapted to Haskell :)
22:50:11 <shapr> Good morning #haskell!
22:50:15 <shapr> What's going on today?
22:51:19 <Cale> not too much at the moment
22:51:39 <Saulzar> Cale, Nothing in particular - it is just very  a) complete b) well designed 
22:51:53 <Saulzar> (and open source)
22:52:20 <Cale> I wonder how much would immediately break if I made the changes I wanted to the prelude.
22:52:48 <Cale> and I wonder how much more would break if I managed to reinstate monad comprehensions :)
22:52:50 <shapr> Oh, I should be asking about TMR articles... are there five?
22:53:07 <Saulzar> The trouble with a haskell binding to ogre is that everything would be IO Blah... 
22:53:56 <Saulzar> Where as there's a lot of concepts relating to games which fit well in pure haskell (and I'm sure it's not done that way in ogre)
22:54:04 <Cale> I have a partially written thing, which should get finished at some point :)  Philippa wanted to write one, I'm not sure how/if that's going.
22:55:08 <Saulzar> Maybe a binding can be more than just a straight mapping of the functions though
22:55:14 <shapr> jethr0's article is finished.
23:02:19 <lispy> shapr: i can write one about the banana phone
23:03:00 <lispy> http://www.albinoblacksheep.com/flash/badgerphone.php
23:03:32 <twb> Flash is evil!
23:03:54 <lispy> http://thefucksociety.com/anim.php?h=400&id=bananaphone&w=550
23:03:58 <lispy> yes, yes it is
23:04:05 <lispy> but those two go well together
23:04:54 <shapr> lispy: Yes, it's not a pony. It's not baloney.
23:05:08 * shapr sings the bananaphone song.
23:06:42 <twb> Well, the sound doesn't work in swfplayer.
23:07:38 <lispy> bananular phone!
23:22:23 <Cale> http://www.irregularwebcomic.net/polls/poll0133.html -- Lust, Sloth, and Gluttony, definitely the three fun sins.
23:52:42 <shapr> Ya know, I think the tools in lambdabot deserve credit for encouraging nifty #haskell discussions. I've realized that @type @libsrc and a bunch of other tools would make my life easier in any language or system I use.
23:53:17 <Korollary> @karma+ dons
23:53:17 <lambdabot> dons's karma raised to 21.
23:53:45 <shapr> yeah, go dons!
23:55:13 <Korollary> I ate too many cookies
