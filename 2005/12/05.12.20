00:00:09 <ski> jethr0_ : no .. it continues :)
00:00:24 <jethr0_> well, it stops continuing
00:00:25 <Cale> ski: I don't see how that's even remotely the same
00:00:31 <ski> jethr0_ : no
00:01:09 <ski> Cale : the stack together with return address (and maybe some registers etc) is a continuation closure
00:01:38 <Cale> In particular, suppose that a and b both contain more than one value. Then b -> 0 is empty, so (a, b -> 0) is empty so (a, b -> 0) -> 0 has a single element, whereas there's more than one function a -> b
00:01:44 <ski> the return address (together with it's env, the rest of the stack) is just another argument to functions as continuations
00:02:49 <ski> Cale : semantics is a bit troublesome .. yes
00:03:02 <Cale> I don't understand that isomorphism at all.
00:03:06 <C-Keen> moin
00:03:11 <Cale> Could you give the map?
00:03:18 <ski> map ?
00:03:35 <Cale> Well, it's an isomorphism, so there ought to be invertible maps between those types.
00:03:45 <ski> i could implement it with callCC :)
00:03:57 <Cale> What's the map ((a, b -> 0) -> 0) -> (a -> b) ?
00:04:29 <ski> \foo a -> callCC (\k -> foo (a,k))
00:04:44 <Cale> hehe, and the type of callCC here?
00:04:59 <Cale> give me a proof of callCC :)
00:05:00 <ski> callCC :: ((a -> 0) -> 0) -> a
00:05:23 <ski> i could, i think, in classical linear logic
00:05:48 <Cale> I don't believe that callCC is a function
00:05:59 <musasabi> morning
00:06:11 <ski> it's not an ordinary category, i think
00:06:18 <Cale> (at least, using the usual definition of 'function')
00:06:32 <ski> (i.e. it's not fully "Set"-like)
00:07:05 <ski> i think that ensuring linearity is one key part to make this approach pure
00:07:18 <ski> otherwise, we just get continuation side-effects
00:07:21 <Cale> How many elements does (Bool -> 0) -> 0 have?
00:07:35 <Cale> seems to me that there's one
00:07:42 <ski> meaningless question, in classical linear type theory :)
00:08:02 <ski> these are not sets
00:08:08 <Cale> why not?
00:08:18 <Cale> (why shouldn't they be?)
00:08:37 <ski> well, for starters, because Set hasn't coexponentials (even linear ones)
00:09:17 <musasabi> What is usually the best way to handle cyclic things in logic? (most simple extension because the normal finiteness requirement is broken)
00:09:23 <Cale> why do you want such an esoteric thing?
00:09:54 <ski> fully symmetric system ?  embedding of classical logic ?
00:10:20 <musasabi> Cale: because it seems more natural than playing with fixpoints
00:10:39 <ibid> musasabi: i can think of several things you could mean by "cyclic things". which is it?
00:11:20 <musasabi> ibid: mostly about trying to find proof for sentences involving themselves.
00:13:04 <ski> (Cale : anyway .. i've not seen any formal treatment of this .. but i think it could be done)
00:13:25 <ski> (s/this/all this/)
00:13:29 <Cale> hmm
00:14:46 <jethr0_> my mother offered to by me a book for xmas. any suggestions for a cool CS book i don't have yet :)
00:15:12 <ibid> musasabi: so, infinitely long terms and/or formulas?
00:15:19 <musasabi> yes
00:15:21 <ibid> musasabi: there are some extensions to FOL that allow it
00:15:40 <ibid> musasabi: there's something about it in the Salminen-V√§√§n√§nen textbook
00:15:45 <ibid> in the appendices
00:15:58 <musasabi> mmh, ok, I'll look at the appendices.
00:16:16 <ibid> nah, chapter 4, actually
00:16:20 <ibid> in my copy
00:16:39 <ibid> (johdatus logiikkaan 2nd ed, 1997)
00:17:02 <Cale> Okay, so to clarify this, you're saying that your (Cartesian closed) category has, for every pair Y, Z, an object Z_Y with a morphism coeval: Z -> (Z_Y x Y) such that for any map f: Z -> X x Y, we have a unique map f* : Z_Y x Y -> X x Y such that f* . coeval = f
00:17:37 <ski> Cale : not cartesian closed, i think .. more like monoidal closed
00:17:56 <Cale> okay, perhaps not CC
00:17:57 <sieni> musasabi: also http://en.wikipedia.org/wiki/Infinitary_logic
00:18:09 <musasabi> thanks
00:18:12 <Cale> well, let's just assume that it has binary products
00:19:01 <ski> for what i know, we want closedness wrt another monoidal structure than categorical product
00:19:04 <Cale> It's odd that it would fail to have ordinary exponentials.
00:19:27 <Cale> But what I just wrote would be what I'd call a coexponential anyway
00:19:35 <ski> maybe it can have that too, but those are not what one normall things of as "functions" here, i think
00:19:59 <Cale> well, our functions are arrows in the category
00:20:10 <ski> (and of course coclosedness would be wrt a monoidal structure too)
00:20:16 <ski> yes, global functions
00:20:24 <Cale> hm?
00:20:28 * ski was thinking more of internal functions
00:20:40 <Cale> I don't get the distinction
00:20:47 <ski> X-elements of Z^Y
00:20:49 <Cale> (remember that I'm a mathematics student :)
00:21:03 <Cale> ah, okay
00:21:40 <Cale> Well, Cartesian closed-ness is what lets you think of Z^Y as the set of arrows from Y to Z.
00:21:58 <Cale> (or perhaps not set :)
00:22:29 <Cale> well, no, it's definitely a set :)
00:22:46 <Cale> Z^Y might not be, but it may as well be once CC holds.
00:22:47 <ski> heh
00:23:40 <Cale> coexponentials are strange
00:23:53 <ski> the word is interesting :)
00:24:21 <Cale> I wonder if it's supposed to use the coproduct instead
00:24:27 <ski> for what ?
00:24:57 <Cale> For every pair Y, Z, an object Z_Y with a morphism coeval: Z -> (Z_Y \/ Y) such that for any map f: Z -> X \/ Y, we have a unique map f* : Z_Y \/ Y -> X \/ Y such that f* . coeval = f
00:25:19 <Cale> that is, how far do we take the dualism? :)
00:25:20 <ski> yes, that's a better approximation, i think
00:25:23 <Cale> okay
00:25:36 * Cale reevaluates the definition
00:25:45 <ski> except, coproduct in the cat corresponds to additive disj, and we want multiplicative disj. :)
00:25:56 <Cale> (perhaps I'm coevaluating it)
00:26:18 <ski> (same with exponentials .. we want multiplicative conj., there, not products = additive conj.)
00:26:35 <Cale> well, I have no idea what those are category theoretically
00:26:50 <Cale> (and only a very limited notion otherwise)
00:27:18 <ski> i think one could have a subcategory, in which the products are the multi. conj. (are similarily for coproducts)
00:27:19 <Cale> hmm
00:27:32 <ski> (hm, or rather, those are two different subcats, i assume)
00:27:40 <ski> (think i saw something like this in a paper)
00:27:44 <Cale> hmm
00:27:52 <Cale> this seems hard to implement
00:28:40 <ski> there are models for linear logic .. coherence spaces e.g. (don't recall if those were for intuitionistic or classic linear logic)
00:28:41 <dons> audreyt, sometime in the next week or so.
00:29:07 <ski> (though, iirc coherence spaces had some defects)
00:29:08 <Cale> ski: anyway, what do coexponentials have to do with Haskell?
00:29:20 <audreyt> dons: eggcellent -- just in time for pugs's next release
00:29:36 <ski> not directly, i suppose .. except to be able to do stuff in a pure way
00:29:36 <dons> ah, good good. i'll try to get it  out sooner then.
00:29:40 <dons> tomorrow if you're lucky..
00:29:46 <Cale> Can you show me a programming language in which I'm permitted to coevaluate values?
00:30:10 <audreyt> cohaskell?
00:30:13 <Cale> hehe
00:30:14 * ski wants to implement one :)
00:30:17 <dons> definitely cohaskell
00:30:21 <ski> hehe
00:30:29 <ski> not bihaskell, then ?
00:30:49 <Cale> I get the impression that this seems unimplementable, but perhaps there's a trick I'm not seeing
00:30:50 <audreyt> but you'll need a cotime comachine to find coimplementors
00:31:07 <ski> (the 'control operation' that esap is pondering seems related to this in some way too, i think)
00:33:43 <ski> Cale : i think it's implementable .. but one must take care so it retains purity .. that's one problem to attack, i think
00:33:55 <ibid> audreyt: hmm, is co-(x y) = co-x co-y? :)ss
00:34:01 <ibid> -ss
00:34:31 <Cale> Well, let's try this definition with actual types.
00:34:42 <Cale> Let Z = 2, and Y = 3
00:34:50 <Cale> (canonical 2 and 3 element types)
00:34:54 <ski> 2 = 1 + 1 ?
00:35:05 <Cale> (assuming that types still have elements :)
00:35:32 <Cale> Now, you have to give me an object 2_3
00:35:43 <Cale> together with a map  2 -> 2_3 \/ 3
00:35:52 <ski> (and '1' being additive or multiplicative unit ? (assumes multi.) .. '+' being additive or multiplicative disj. ? (assumes add.))
00:36:16 <Cale> 1 is the categorical 1
00:36:17 <ski> then '2' and '3' have '1' elements, yes
00:36:20 <ski> yes
00:36:33 <ski> arg
00:36:33 <ski> then '2' and '3' have '1'-elements, yes
00:36:56 <Cale> I'm assuming that the category is relatively rich, and has these things, since we're thinking of using it for programming :)
00:36:58 <ski> 2 resp 3 elements, they have
00:37:02 <Cale> yes
00:37:27 <ski> but, '1' is not a generator, i think
00:37:36 <Cale> now, the compiler has to give me an object 2_3 \/ 3 and a map coeval: 2 -> 2_3 \/ 3
00:37:38 <Cale> er
00:37:40 <ski> so, there's more to objects than '1'-elements
00:37:42 <Cale> an object 2_3
00:37:53 <tennin> I think it would at least be quite easy to implement in Universe_op.  =)
00:38:20 <Cale> yeah, it's easy in the opposite category
00:38:38 <Cale> but let's hope that's not the only way, because that's stupid :)
00:38:41 <ski> we're trying to have both in same cat, so to speak
00:38:48 <Cale> yeah
00:38:56 <Cale> and it has to be reasonable to implement :)
00:39:02 <ski> (but sufficiently weakened, to not give trivial cat)
00:39:08 <Cale> i.e. computable
00:39:15 <Cale> and not trivial
00:39:20 <ski> right
00:39:36 * ski tries to infer argument order of Cale's '_' coexponential
00:39:52 <Cale> 2 subscript 3
00:40:04 <ski> coeval : 2 --> (2 >- 3) \/ 3
00:40:07 <ski> i'd write, i think
00:40:09 <Cale> For every pair Y, Z, an object Z_Y with a morphism coeval: Z -> (Z_Y \/ Y) such that for any map f: Z -> X \/ Y, we have a unique map f* : Z_Y \/ Y -> X \/ Y such that f* . coeval = f
00:40:25 <Cale> Well, we normally write Z^Y for the exponential :)
00:40:34 <ski> (one '3' is in positive context, the other is in negative context)
00:40:35 <Cale> so I'm just turning that around
00:40:45 <ski> sure, just i know which is which
00:41:01 <Cale> draw the triangle :)
00:41:04 <lisppaste2> jethr0 pasted "books" at http://paste.lisp.org/display/14831
00:41:34 <Cale> note that we don't know X yet
00:41:39 <ski> i'd prolly instead say : f+ : Z_Y -> X such that (f+ \/ Y) . coeval = f
00:42:07 <ski> 'f+' is the cocurrying of 'f'
00:42:13 <Cale> er, hmm
00:42:24 <Cale> that will be taken care of
00:42:33 <ski> f : Z -> X \/ Y
00:42:35 <Cale> by universality, probably
00:43:05 <ski> in some sense, this is a bit like exceptions (but not dynamically scoped)
00:43:10 <Cale> mm
00:43:13 <Cale> anyway
00:43:25 <Cale> so I'm giving you Z = 2, and Y = 3
00:43:39 <ski> and X ?
00:43:44 <Cale> now you have to give me a type 2_3 and a map 2 -> 2_3 \/ 3
00:43:49 <Cale> you don't get to know X yet
00:43:54 <ski> ok
00:44:14 <ski> 2_3  ~=  2 * Not 3   i think
00:44:31 <ski> 2_3  ~=  2 /\ Not 3    actually
00:44:43 <Cale> by /\ do you mean x ?
00:44:49 <ski> no
00:45:08 <ski> /\ is mult. conj.
00:45:24 <Cale> that's the bizarre one?
00:45:27 <Cale> :)
00:45:58 <ski> (it might be that general recursion makes that not a fully iso, but, i think we at least have an inclusion (maybe retract ?))
00:46:01 <ski> er ?
00:46:19 <ski> 2 /\ 3  ~=  6
00:46:23 <ski> that's for sure
00:46:28 <Cale> okay
00:46:37 <Cale> so let's just choose 6
00:46:37 <ski> 2 * 3  is, well, another thing :)
00:46:55 <Cale> (that's the same as the categorical product then :)
00:47:05 <ski> '*' is the cat. product, here
00:47:08 <Cale> oh?
00:47:10 <ski> not '/\'
00:47:34 <ski> (in a certain subcategory, though, i think '/\' is the cat. prod.)
00:47:39 <Cale> I'm pretty sure that you'll have 2 x 3 ~= 6
00:47:41 <Cale> maybe not
00:47:49 <Cale> I've never seen a category like that though.
00:48:09 <ski> if it's doable at all, i think this is required
00:48:21 <ski> (i.e.  2 /\ 3  ~=  6)
00:48:39 <Cale> okay, so what map are you going to give me?
00:48:43 <Cale> hehe
00:48:48 * ski would like to get this more concrete etc ..
00:48:51 <Cale> I need a coeval :)
00:49:16 <ski> coeval : 2 -> 2_3 \/ 3
00:49:23 <Cale> that's its type
00:49:25 <tic> what's "~=" mean?
00:49:27 <ski> yes
00:49:30 <ski> tic : isomorphic
00:49:31 <Cale> tic: isomorphic to
00:49:41 <tic> hrm. another word to lookup. :) thanks.
00:50:36 <gzl> isomorphism is sort of like 'bijection' (in the category of sets, they're the same)
00:50:51 <Cale> ski: but there's got to actually be such a thing -- so how are we going to represent it in our language?
00:50:53 <ski> hm, iirc  2 * (Not 3 \/ 3) --> (2 * Not 3) \/ 3 ~= 2_3 \/ 3
00:51:07 <ski> an we have   1 -> Not 3 \/ 3   (excluded middle)
00:51:50 <ski> if have those, i think we can construct 'coeval'
00:52:02 <ski> (well, there's the matter of laws too, of course)
00:52:17 <Cale> What's Not A in category theoretic terms? Is it the same as 0^A?
00:52:30 <ski> no
00:52:36 <ski> Bot^A  i think
00:52:47 <ski> ('Bot' being multiplicative false)
00:52:49 <Cale> What's Bot then?
00:53:04 <ski> i.e. the unit to mult. disj. ('\/')
00:53:14 <Cale> that's 0
00:53:17 <ski> no
00:53:24 <ski> '0' is additive false
00:53:27 <Cale> by \/ I mean coproduct
00:53:31 <ski> it's unit to additive disj.
00:53:34 <ski> oh
00:53:48 <ski> i don't, here :)
00:53:51 <Cale> okay
00:54:09 <Cale> so we're going to end up being confused -- perhaps I should switch to using +
00:54:33 <Cale> For every pair Y, Z, an object Z_Y with a morphism coeval: Z -> (Z_Y + Y) such that for any map f: Z -> X + Y, we have a unique map f* : Z_Y + Y -> X + Y such that f* . coeval = f
00:54:36 <Cale> there
00:54:38 <Cale> + is coproduct
00:55:12 <Cale> (I'm just used to using \/ for coproduct from the category of based topological spaces)
00:55:13 * ski usually uses '0','+','1','*' for the additive ones and 'Bot','(+)','Top','(*)' for the multiplicative ones
00:55:38 <Cale> I'm sorry that I don't really know what you mean, categorically speaking.
00:55:49 <Cale> Could you define all those in terms of category theory?
00:55:53 <ski> (i use those because of cat. theory standard practice with the first part being the cat. products,coproducts with units)
00:56:26 <ski> the first part should be the usual categorical intial,coproduct,terminal,product
00:56:37 <Cale> okay
00:56:50 <Cale> I reserve the right to type 'x' for product :)
00:56:55 <Cale> hehe
00:57:11 <Cale> I suppose I could actually type √ó
00:57:12 <ski> the second is more hazy .. i think they should satisfy monoidal structures, each, but then it's not so clear how to be more precise in general
00:57:20 <Cale> hmm
00:57:43 <ski> and, re above, i want coproduct wrt '\/', not '+'
00:57:52 <Cale> hm?
00:57:58 <ski> (i.e. not normal categorical coproduct)
00:58:09 <Cale> I'm just dualising the notion of exponential
00:58:15 <ski> just as '^' here is not normal categorical product
00:58:27 <ski> because that's wrt '/\' and not '*'
00:58:31 <Cale> I don't really know what ^ and \/ are then
00:58:40 <araujo> functors are morphisms between categories instead of objects?
00:58:44 <ski> '^' is linear function space
00:58:47 <Cale> araujo: yes
00:58:53 <araujo> Thanks Cale 
00:58:56 <Cale> oh
00:59:06 <Cale> er
00:59:06 * araujo cracking his head with CT
00:59:08 <Cale> by ^ do you mean the exponent?
00:59:14 <Cale> or /\ ?
00:59:15 <ski> the linear exponent, yes
00:59:16 <Cale> hehe
00:59:24 <Cale> What makes it linear?
00:59:35 <Cale> How are these things actually defined?
00:59:59 <ski> it transforms one proof of A into one proof of B (locically speaking) (i.e. with 'B^A')
01:00:11 <Cale> hmm
01:00:42 <gzl> araujo: literally. in the category of categories, the morphisms are functors
01:00:52 <ski> C(X /\ A,B) ~= C(X,B^A)
01:00:58 <Cale> C?
01:01:03 <ski> our cat
01:01:08 <Cale> um
01:01:13 <araujo> gzl, yeah, reasonable
01:01:21 <ski> those two morphism classes should be essentially the same
01:01:32 <Cale> sorry, I don't know that notation -- is that the same as Hom(X /\ A, B) ~= Hom(X, B^A) ?
01:01:37 <ski> yes
01:01:40 <Cale> okay
01:01:55 <gzl> araujo: to guess at a question you'll probably have when you get to the next one or two pages, in the category of all functors the morphisms are natural transformations :)
01:02:10 <Cale> So X /\ A is quite a lot like X x A
01:02:18 <ski> (gzl : you could also tell him about 2Cat :)
01:02:28 <Cale> in a Cartesian closed category anyway
01:02:30 <araujo> gzl, haha ok
01:02:33 <araujo> Thanks :-)
01:02:35 <ski> Cale : well, it's *not* like 'additive product'
01:02:36 <gzl> np
01:02:49 <ski> but, it's like cartesian products, in a sense, yes
01:03:20 <Cale> How does it differ, in the category theoretic sense from the usual CT product?
01:03:28 <ski> a value of type 'X /\ A' is a pair of values of respectively type 'X' and type 'A'
01:03:38 <ski> (and to use the pair, you must use both parts)
01:03:47 <Cale> hmm
01:04:14 <Cale> I just want a translation into commutative diagrams :)
01:04:15 <ski> 'X /\ A --> X' is impossible in general
01:04:26 <Cale> So you're saying there's no projection map.
01:04:29 <ski> right
01:04:38 <ski> projections are for additive conj.
01:04:41 <Cale> Okay, that's different
01:04:48 <ski> aka categorical products
01:04:48 <Cale> So how do we define it?
01:05:10 <ski> i don't know how (or if) we define it, in general
01:05:17 <ski> one can define it in models
01:05:29 <ski> s/we/we can/
01:05:48 <Cale> well, how do we know when it's been defined? :)
01:06:27 <ski> for models of linear logic, one must of course define the meaning of '/\' in the model
01:06:45 <Cale> hmm
01:06:48 <Cale> okay
01:06:51 <ski> but i don't know a corresponding general definition, like categorical products are defined
01:06:52 <Cale> in that sense :)
01:07:50 <ski> do you want me to think more on your 'coeval', now ?
01:08:54 <Cale> sure
01:09:33 <ski> (i realize this is mostly intuitions from my part, so far .. gotten by reading and skimming diverse papers .. some of your questions might've been answered in such papers, but i don't recall all .. i'm of the hope that this all can be made to work)
01:10:18 <ski> you were asking for something like operational semantics of 'coeval' ?
01:10:28 <gzl> what are you guys talking about?
01:10:41 <gzl> working out some weird category?
01:10:48 <Cale> ski: well, yeah -- what should we make it do?
01:10:51 <ski> gzl : linear logic, and categories, and stuff
01:11:00 <gzl> ok
01:11:07 <ski> coeval : 2 -> 2_3 \/ 3
01:11:14 <ski> or, almost the same
01:11:28 <ski> coeval' : 2 -> (2 /\ Not 3) \/ 3
01:12:01 <Cale> why do you want \/ and not + ?
01:12:31 <ski> i don't want the usual constructive/intuitionistic disjunction
01:12:52 <ski> because we don't have  B^A  ~=  Not A + B
01:13:09 <ski> otoh, i think here we have  B^A  ~=  Not A \/ B
01:13:19 <Cale> Is there supposed to be *no* function of type X /\ A -> A ?
01:13:35 <ski> ('^' being linear exponential, not normal cat. one)
01:13:38 <twb`> Cale: snd? :-)
01:13:55 <ski> Cale : no one natural in X
01:13:56 <Cale> twb`: well, ski is saying that there's no projections
01:14:19 <twb`> It's all over my head, anyway.
01:14:22 <ski> 'Top /\ A --> A' surely exists
01:14:28 <Cale> Well, by what you said earlier, Hom(X /\ A, A) ~= Hom(X, A^A)
01:14:52 <ski> (well, what i said implied that, but, right otherwise)
01:14:57 <Cale> yes
01:15:13 <Cale> hmm
01:15:41 <ski> '3 /\ A --> A' also exists, etc
01:15:45 <Cale> do we have constant maps?
01:16:04 <ski> A --> 1
01:16:12 <ski> but, no 'A --> Top' :)
01:16:19 <Cale> mm
01:17:08 <Cale> Okay, so for any element of A^A, that is, for any morphism 1 -> A^A, we can form the composition X -> 1 -> A^A, where the first arrow is the unique one.
01:17:36 <ski> coeval above, first takes a value of '2', then returns a pair of that value and something else, this pair tagged with "Left"
01:18:29 <Cale> I'm just off on a tangent trying to construct a natural map X /\ A -> A :)
01:18:45 <Cale> natural in a somewhat informal sense
01:19:00 <ski> i think, usually '1 -> Foo'  morhpisms aren't interesting (if they exists)  (not fully sure about this)
01:19:03 <Cale> really, one that will always exist
01:19:18 <Cale> 1 -> Foo  morphisms are what we call the elements of Foo
01:19:29 <ski> yes, but those aren't as interesting
01:19:50 <ski> 'T -> Foo' morphisms more or less replace their use
01:20:03 <Cale> What's T?
01:20:04 <ski> there are 5 morphisms 'T -> 5'
01:20:07 <ski> oh, sorry
01:20:09 <ski> T = Top
01:20:18 <Cale> yeah, but what's that? :)
01:20:30 <ski> multiplicative true .. unit of '/\'
01:20:42 <ski> think "empty tuple"
01:20:54 <Cale> Is it terminal?
01:20:56 <ski> (i.e. empty cartesian product)
01:21:00 <ski> i don't think so
01:21:18 <ski> '1' is terminal
01:21:32 <ski> so, if 'Top' is terminal, then they would be same, upto iso
01:21:51 <Cale> So there exists an object X such that there is either more than one morphism X -> T, or that there are no morphisms X -> T
01:22:10 <ski> hm ?
01:22:21 <Cale> That's the same as saying it's not terminal.
01:22:30 <ski> mhm
01:23:03 <Cale> interesting :)
01:23:11 <ski> hm, i think there's no morphisms '1 -> Top'
01:23:14 * ski ponders
01:24:26 <ski> yes, i think that's true, in the intuition, and also wrt what's provable in the logic
01:24:41 <Cale> hmm
01:25:47 <Cale> okay, that means that Top has no elements.
01:26:03 <ski> it has exactly one Top-element
01:26:26 <ski> '1'-elements aren't so interesting, i think
01:26:31 <Cale> there can't be any maps X -> Top if there's no map 1 -> Top.
01:26:46 <Cale> er, hmm
01:26:49 <Cale> sorry
01:26:54 <Cale> for any X with an element
01:27:00 <ski> there are e.g. maps '3 -> Top'
01:27:04 <Cale> that is, if we have 1 -> X
01:27:06 <ski> well, map
01:27:11 <Cale> then we can't have X -> Top
01:27:21 <Cale> because we'd then have 1 -> Top
01:27:21 <ski> <ski> '1'-elements aren't so interesting
01:27:22 <ski> :)
01:27:36 <Cale> there's a map 1 -> 3 is there not?
01:27:40 <tic> Where can you read up on these things?
01:27:42 <ski> nope
01:27:48 <Cale> no?!
01:27:49 <ski> 3 = Top + Top + Top
01:27:52 <Cale> oh
01:27:54 <Cale> heh
01:28:01 <Cale> let's call that something else
01:28:09 <Cale> I want 3 to have exactly 3 elements
01:28:10 <ski> it's somewhat bad syntax, actually
01:28:14 <ski> yes
01:28:26 <ski> '3' above has exactly 3 'Top'-elements
01:28:31 <ski> tic : papers :)
01:28:40 <Cale> let's call that 3T
01:28:46 <ski> yes, better
01:29:20 <ski> since otherwise we could easily think  2 = Top + Top ..    1 = Top ???  and be a lot confused
01:29:46 * ski considers changing his syntax
01:29:50 <Cale> also, 0,1,2,... are used for exactly what I'm using them for, when they exist :)
01:30:17 <ski> anyway, the interesting things here are 0T,1T,2T, etc
01:30:23 <Cale> hmm
01:30:26 <ski> not additive sums of additive true
01:30:32 <Cale> But what about all those types with elements?
01:30:39 <ski> hm ?
01:31:01 <Cale> well, if we're in the context of a programming language, we want some types with elements in them
01:31:05 <ski> yes
01:31:12 <ski> Top-elements, to be precise
01:31:13 <ski> :)
01:31:25 <Cale> why Top-elements and not ordinary elements?
01:31:26 <ski> Bool = Top + Top  e.g.
01:31:54 <Cale> hmm
01:32:11 <ski> not :: Bool -> Bool
01:32:17 <ski> not (Left  ()) = Right ()
01:32:23 <Cale> Why bother with any of the rest of the category at all then?
01:32:24 <ski> not (Right ()) = Left  ()
01:32:47 <ski> <ski> '1'-elements aren't so interesting
01:32:53 <Cale> why not?
01:33:23 <Cale> 1-elements are the usual elements
01:33:26 <Cale> in a category
01:33:27 <ski> '/\' corresponds to 'both this value and this value'
01:33:46 <ski> 'Top' corresponds to 'no values', trivial to construct
01:33:51 <tic> ski, well, which papers? :)
01:33:58 <Cale> ski: um...
01:34:00 <tic> what's Bottom/False? All values?
01:34:12 <Cale> I'm afraid you lost me
01:34:21 <ski> '1' corresponds to, 'you must project out one element, even though no projections/elements exist'
01:34:39 <Cale> no, not project
01:34:46 <Cale> choose
01:34:51 <ski> yes
01:35:20 <ski> tic : well, like papers by Girard and Blass etc
01:35:35 <ski> tic : 'Bottom/False' ?
01:35:39 * ski thinks
01:36:11 <Cale> tic: you can learn about category theory in lots of books -- "Categories for the Working Mathematician" by MacLane is nice
01:36:34 <Cale> tic: but to be honest, I'm a little confused here :)
01:37:06 <tic> I'm pondering taking the Advanced Advanced Functional Programming class.
01:37:16 <Cale> ski: You're creating a rather strange category, and I'm not sure you can do what you're doing, even. :)
01:37:30 <ski> there are one introduction of '*' (pairing), and two eliminations (projection)
01:37:31 <tic> deals with category theor.
01:37:35 <Cale> Given some basic assumptions about what sort of category we have :)
01:37:46 <ski> there are one introduction of '1' , and zero eliminations
01:38:12 <ski> (logically speaking)
01:38:53 <ski> in a sense, i think if you've gotten an '1', you can't get rid of it
01:39:55 <dons> '1's are scary!
01:40:06 <ski> right :)
01:40:25 <Cale> huh
01:40:28 <Cale> odd
01:40:30 <ski> (in a similar sense as to why '0' is scary (coscary ?))
01:41:05 <ski> remember this is all linear, you can't just choose to not use something, unless explicitely allowed to
01:41:34 <ski> (i.e.  ! 1  ~=  Top)
01:41:51 <dons> > GHC.Base.Unit :: 1 -- oh no!!
01:41:51 <lambdabot>  Not in scope: data constructor `GHC.Base.Unit'
01:42:03 <dons> doh.
01:42:04 <Cale> dons: that 1 isn't so scary
01:42:12 <ski> m
01:43:05 <ski> values of '0' can't be constructed, and values of '1' can't be eliminated
01:43:28 <ski> you can trivially eliminate a (hypothetical) value of '0'
01:43:39 <ski> you can trivially create a "value" of type '1'
01:43:47 <ski> X --> 1
01:43:52 <ski> 0 --> X
01:44:31 <ski> (in a sense, there exists no continuation that deconstructs a value of type '1')
01:45:18 <ski> Cale : did you want to see my operational idea for how 'coeval' should work ?
01:45:22 <Cale> okay
01:45:24 <dons> @type GHC.Base.Inl () -- inlr/inr is under-used
01:45:25 <lambdabot> forall b. (GHC.Base.:+:) () b
01:45:26 <ski> Cale : or maybe this is enough of this, now :)
01:45:43 <Cale> though I feel that I don't understand these other types well enough without categorical descriptions
01:45:59 <ski> coeval : 2T -> 2T_3T \/ 3T
01:46:38 <kzm> @seen shapr
01:46:38 <lambdabot> I saw shapr leaving #ScannedInAvian and #haskell 2 hours, 1 minute and 54
01:46:38 <lambdabot> seconds ago.
01:46:58 <Cale> ski: remember that it has to work for arbitrary objects though
01:47:07 <ski> right, no problem
01:47:17 <xinming> for `runCont( ... ) fun', so, Is fun here the last continuation to call?
01:47:19 <Cale> including ordinary 2 and 3
01:47:38 <kzm> I have a compatibility problem with the wiki.  As SPJ suggested updating the newbie pages (re recent thread on the lists), I went to take a look.
01:47:39 <ski> this accepts a value of type '2T' (two such 'Top'-elements are possible), and returns "Left" tagged onto a (multiplicative) pair of that value of type '2T' and "something else" ..
01:48:39 <ski> this 'something else' is a continuation that, when it gets used (it *will* get used, since we're linear), will accept a value of type '3T' .. then 'coeval' returns yet again, this time with "Right" tagged onto this value of type '3T'
01:48:59 <kzm> The pages in question have the form of a web forum, with signed questions, answers, new questions in response to that, and so on.  Is it considered comme-il-faut to edit other people's signed statements?
01:49:05 <ski> (stuff of '\/' always return two times, ones for each "variant")
01:49:16 <ski> (s/ones/once/)
01:49:42 <araujo> gzl, hah, now i got to the natural transformation stuff :-)
01:49:49 <ski> Cale : this is natural in 'A' and 'B' which are '2T' and '3T' here
01:49:50 <Cale> ski: my main problem with using \/ in the definition is that this isn't really like coexponentiation anymore, because \/ doesn't have the same properties as +
01:50:09 * kzm shrugs indifferently, and goes back to work.
01:50:13 <Taral> morning!
01:50:17 <Cale> but hmm
01:50:20 <Taral> @time Taral
01:50:20 <lambdabot> Maybe you meant: dice type uptime
01:50:25 <Taral> Hm!
01:50:29 <Cale> that does seem like a promising direction
01:50:33 <Taral> hi Cale
01:50:36 <Cale> Taral: hi
01:50:53 <ski> Cale : i think it may be the case, that in a subcategory, '\/' will be coproduct, and then hopefully, '_' is your "usual" coexponential
01:50:58 <ski> (in that subcat, i.e.)
01:51:10 <ski> xinming : yes
01:51:41 <Cale> ski: hmm, yeah, possibly
01:52:25 * Taral reads logs.
01:52:33 <ski> ('_' has also been called "context" and "minus", btw)
01:52:45 <ski> ("context" as in the context of a function call)
01:53:23 <ski> Cale : anyway, i think that above can be implemented
01:53:29 <Cale> ski: hmm
01:54:51 <ski> kzm : hm, iirc, sometimes one rewrites the page into third-person style, instead of conversational, distilling the essentials
01:55:34 <ski> (Cale : what seems like a promising direction ?)
01:56:30 <Cale> that semantics for coeval
01:56:41 <ski> ok
01:57:00 <kzm> ski, hmm, okay.  So it's okay to remove other people's comments.
01:57:02 <Taral> Okay, what is this theory that ski has been talking about for hours
01:57:13 <ski> kzm : if you rewrite it, yes
01:57:46 <ski> Taral : linear logic and possible programming language based on it (and related category theory issues, etc)
01:58:04 * ski thinks he'll stop talking about this, now
01:58:41 <ski> @arr
01:58:42 <lambdabot> Arrr!
01:58:56 <Taral> Okay...
01:59:10 <Taral> Linear logic is nice for memory management?
01:59:37 <ski> yes, that too
02:00:21 <Taral> Heh, I ran into a problem with Caduceus where I couldn't work out how to generate conditions about locks. I wonder if linear logic would help?
02:00:54 * ski wonders what Caduceus is in this context
02:00:54 <jethr0_> RMS: "Once I put my coat over a camera before giving my speech, when I learned it was webcasting in RealPlayer format."
02:01:59 <dons> jethr0, that's funny.
02:02:13 <jethr0_> thought so, too
02:02:17 <dons> real really sucks. we need an open format that is widely used.
02:02:18 <Taral> @google Caduceus
02:02:18 <lambdabot> http://drblayney.com/Asclepius.html
02:02:20 <Taral> nope
02:02:22 <Taral> @google Caduceus VCG
02:02:23 <lambdabot> http://why.lri.fr/caduceus/index.en.html
02:02:25 <Taral> that
02:02:33 <Taral> VCG for C
02:02:59 <jethr0_> yes, open video formats (i.e. those withouth potential patent infringements) are a real bottleneck!
02:04:43 <dons> i just find it so annoying the prevelance of streaming in real format, which is just a pain on non-windows OS.
02:05:25 <jethr0_> not to speak of wmv and those weird microsoft streaming formats
02:05:44 <ski> (Taral : mayhaps .. i don't know)
02:06:20 <Taral> Linear logic is causing me trouble.
02:06:28 <Taral> What is top?
02:06:30 <ski> hmhm ?
02:07:10 <xinming> ski: what does callCC do then?
02:07:17 <Taral> I'm trying to understand what top means in linear logic.
02:07:21 <ski> xinming : call-with-current-continuation
02:07:21 <xinming> > runCont(do{x <- return 3;y <- callCC (\_ -> return 9); return (x)} ) (\h -> h + 5)
02:07:21 <lambdabot>  Not in scope: `callCC'
02:07:24 <Taral> The wikipedia description is kind of hard to understand.
02:07:42 <ski> (Taral : beware, i'm using slightly different notation than Girard)
02:07:55 <ski> @type Control.Monad.Cont.callCC
02:07:56 <lambdabot> forall (m :: * -> *) a b.
02:07:56 <lambdabot> (Control.Monad.Cont.MonadCont m) =>
02:07:56 <lambdabot> ((a -> m b) -> m a) -> m a
02:08:40 <ski> (Taral : are you looking at wikipedia ?)
02:08:44 <Taral> yes
02:10:06 <ski> Taral : what is denoted by 'Top' (i.e. 'T') there is the unit of additive conjunction
02:10:18 <Taral> yes
02:10:36 <Taral> I'm trying to understand what all of these operations mean, especially when combined.
02:10:40 * ski has called that '1' above (to conform better with cat. theory. terminal object standard notation, is one reason)
02:10:46 <xinming> ski: but I don't understand what it is used for. :-/
02:10:53 <ski> xinming : jump !
02:11:36 <Taral> There's the rule () => G |- T, S which bothers me.
02:11:41 <ski> (xinming : one very simple (and not so useful) example is you're taking product of a list of number, but you want to prematurely stop if a number is '0')
02:11:47 <Taral> It seems to say that you can derive anything if you include T with it.
02:11:52 <Taral> (Or 1, using your notation.)
02:11:53 <ski> true
02:12:23 <ski> <dons> '1's are scary!
02:12:30 <ProfTeggy> :-)
02:12:39 <Taral> yes scary
02:12:48 <Taral> I still don't understand what it is.
02:12:53 <ProfTeggy> 'terminal' implies danger somehow
02:13:04 <Taral> (in the resource/process metaphor)
02:13:30 <ski> right
02:14:11 <Taral> ah, I see the problem
02:14:22 <Taral> wikipedia's sequent calculus presentation doesn't show how the operators interact?
02:14:26 <Taral> s/\?/./
02:14:44 <Taral> No laws of distributivity, etc.
02:14:51 <ski> the connectives that are not so hard to understand (i.e. more familiar), from a computing perspective are additive false and disjunction,multiplicative true and conjunction,linear implication,additive conjunction
02:14:57 <Taral> is there a better page?
02:15:12 <ski> one can derive some distributions
02:15:25 <Taral> aha, they link a paper
02:15:53 <ski> A `mult_conj` (B `add_disj` C)  ~=  (A `mult_conj`B) `add_disj` (A `mult_conj` C)
02:15:54 <ski> e.g.
02:15:59 * Taral reads
02:16:10 <Taral> ski: Give me a sec to read paper.
02:16:14 <Taral> I might have less questions then. :)
02:16:15 <ski> hehe
02:16:37 * Taral gets food.
02:17:06 <dons> when was the last Hasekll Weekly News?
02:18:53 <Taral> Someone said there was going to be a missing one.
02:20:43 * ski eats food
02:22:14 <ski> (one other reason i use different notation is that i like the dual connectives to be similar looking, in a way)
02:23:42 <jlouis> This days conjure patches
02:23:51 <jlouis> Taral: oh, an extremely cool haskell hacker ;)
02:24:10 <jlouis> Well, I updated the conjure repo yet again
02:24:21 <dons> heya jlouis, how's the code comming along?
02:24:47 <Taral> jlouis: Cool. I'll take a look in a bit.
02:24:52 <Taral> ski: Are all operators commutative?
02:25:33 <Taral> looks like it
02:26:12 <ski> yes, in the usual variant
02:26:24 <ski> (well, of course exponential/implication is not)
02:28:05 <ski> "Linear negation 'Not A' is involutive, that is 'Not (Not A) = A', but is yet constructive. This is one of the fascinating aspects of linear logic." :)
02:28:17 <xinming>  runCont(do{x <- return([1..10]); return( x ++ [5]) } ) (\v -> v ++ [1] )
02:28:38 <xinming> ski: hmm, could you give a example which can teach me of callCC?
02:28:44 <ski> xinming : you need to make the argument to 'runCont' take an argument
02:28:47 <jethr0_> RMS: There are four essential freedoms, which we label freedoms 0 through 3.
02:30:06 <xinming> ski: ?
02:30:26 <ski> @type Control.Monad.Cont.runCont (\k -> do {x <- return 2; k x; y <- return (x+1); return (x+y)}) (\v -> show v)
02:30:27 <lambdabot>   The lambda expression `\ k -> ...' has one arguments,
02:30:27 <lambdabot>   but its type `Control.Monad.Cont.Cont r a' has none
02:30:38 <ski> hrm
02:30:46 <ski> ah
02:30:54 <ski> xinming : sorry, ignore that, that was wrong
02:31:59 <ski> @type Control.Monad.Cont.runCont (do {x <- return 2; y <- Control.Monad.Cont.callCC (\k -> do {a <- return (x*x); k a; return (a+1)}); z <- return (y+1); return (x+y+z)}) (\v -> show v)
02:32:00 <lambdabot> String
02:32:06 <ski> try that
02:32:25 <ski> > Control.Monad.Cont.runCont (do {x <- return 2; y <- Control.Monad.Cont.callCC (\k -> do {a <- return (x*x); k a; return (a+1)}); z <- return (y+1); return (x+y+z)}) (\v -> show v)
02:32:26 <lambdabot>  Not in scope: `Control.Monad.Cont.callCC'
02:32:29 <ski> (bah)
02:32:45 * ski wonders why Control.Monad.Reader is in scope, then ..
02:33:12 <xinming> 11 :-)
02:34:04 <ski> you understand why ?
02:35:15 <Taral> AHA!
02:35:21 <Taral> This rule is most illustrative:
02:35:43 <Taral> um, need symbols
02:36:26 <ski> xinming : > Control.Monad.Cont.runCont (do {x <- return "2"; y <- Control.Monad.Cont.callCC (\k -> do {a <- return (concat ["(",x,"*",x,")"]); k a; return (concat ["("a,"+","1",")"])}); z <- return (concat ["(",y,"+","1",")"]); return (concat ["(",x,"+",y,"+",z,")")}) (\v -> v)
02:36:33 <Taral> hm, *, +, &, ?
02:36:37 <ski> Taral : :)
02:36:38 <ski> which rule ?
02:37:02 <Taral> not (A * B) = (not A ? not B)
02:37:06 <Taral> where ? is mult_disj
02:37:11 * ski uses (*),+,*,(+) for those in ascii
02:37:38 <Taral> (.) is too many chars
02:37:39 <Taral> :)
02:37:47 <ski> (with corresponding units : Top,0,1,Bot)
02:37:47 <Taral> but ok...
02:38:01 <Taral> not (A (*) B) = (not A * not B)
02:38:25 <ski> (on paper, i write '(*)' as an 'X' (times) in a ring .. similarly with '(+)')
02:38:34 <ski> err
02:38:41 <Taral> yes
02:39:02 <ski> if you're using my notation, then   Not (A (*) B) = Not A (+) Not B
02:39:14 <ski> mult. conj. is dual to mult. disj.
02:39:30 <Taral> oh, you flipped it
02:39:38 <Taral> the multiplicative operators are usually (*) and *
02:39:46 <Taral> well, (*) and funny symbol
02:39:47 <ski> yes, i want the duals to be similar to each other :)
02:39:54 <Taral> okay, so...
02:40:02 <Taral> question: Why are they called conjunctions and disjunctions?
02:40:30 <ski> because they relate to intuitions about ordinary conj. and disj.
02:41:00 <ski> (Not A (+) B) = (A -o B)
02:41:01 <ski> e.g.
02:41:22 <ski> ((A (*) B) -o C) = (A -o (B -o C))
02:41:29 <ski> etc
02:41:31 <Taral> ok
02:42:49 <ski> e.g. mult. conj. also relate to cartesian product, wrt Top-elements
02:42:52 <Taral> ok
02:43:03 <Taral> looks like the multiplicative disjunction is "at least one of A and B"
02:43:10 <Taral> er, "at least one of A or B"
02:43:18 <ski> mult. disj. is a bit strange
02:43:41 <Taral> so if I have A * B, I can have A (*) not B, not A (*) B, A (*) B, but not not A (*) not B
02:43:50 <Taral> it is strange
02:43:50 <ski> i think it's one of connectives in linear logic that is hardest to get an intuition about
02:44:10 <Taral> I think I got it.
02:44:14 <Taral> Very strange, but manageable.
02:44:21 <ski> could you put quotes in that above ?
02:44:25 <Taral> quotes?
02:44:31 <ski> 'A * B', etc
02:44:47 <Taral> so if I have 'A * B', I can have 'A (*) not B', 'not A (*) B', 'A (*) B', but not 'not A (*) not B'
02:44:54 <ski> ty
02:45:21 <ski> and '*' there is ?
02:45:25 <Taral> your notation
02:45:38 <ski> so, '*' is add. conj. then
02:45:46 <Taral> ?
02:45:50 <Taral> damn, I got it wrong. :(
02:45:51 <ski> that's my notation
02:46:01 <ski> maybe i should make a table :)
02:46:09 <Taral> so if I have 'A (+) B', I can have 'A (*) not B', 'not A (*) B', 'A (*) B', but not 'not A (*) not B'
02:46:19 <Taral> It's multiplicative disjunction, either way.
02:46:36 <Taral> it's just that "multiplicative" means the * symbol for me.
02:46:41 <ski> multiplicatives :    true,conjunction : Top,(*)    false,disjunction : Bot,(+)
02:46:51 <ski> additives :    true,conjunction : 1,*    false,disjunction : 0,+
02:46:56 <Taral> yeah, I see that.
02:47:04 <ski> linear exponential :  -o
02:47:12 <ski> s/exponential/implication/
02:47:16 <Taral> heh
02:47:36 <Taral> okay, we'll use your notation, I'll just deal with it.
02:47:46 <Taral> The rule that bugs me is called "(+) Right".
02:47:47 <Taral> It says:
02:48:00 <Taral> G |- A, B, S => G |- (A (+) B), S
02:48:09 <ski> yes, looks right
02:48:21 <Taral> am I misunderstanding "A, B, S" then?
02:48:22 <ski> this is the dual of (*) ÷eft
02:48:25 <Taral> because I would expect:
02:48:30 <Taral> G |- A, B, S => G |- (A (*) B), S
02:48:46 <ski> ',' on left of '|-' works like '(*)'
02:48:48 <Taral> as in, if I start with "G", I get A, B, and S.
02:48:52 <ski> ',' on right of '|-' works like '(+)'
02:48:55 <Taral> I see.
02:49:14 <Taral> Why?
02:49:33 <ski> think of it as an entailment from a conjunctive collection of premises to a disjunctive collection of conclusions
02:50:06 <ski> ',' is supposed to be List (or Bag / Multi-Set) concatenation
02:50:32 <ski> and those two formulae lists are interpreted differently, depending on if they're on left or right of '|-'
02:50:47 <ski> it's somewhat silly
02:52:38 <ski> (btw, it may be helpful to know that add. conj. is sometimes called 'internal choice' .. and then add. disj. is 'external choice')
02:52:46 <Taral> yes, the additives are easy
02:55:36 <ski> (one can also think of add. disj. (with unit) and mult. conj. (with unit) as representing 'information' .. otoh, add. conj. and mult. disj. and linear implication is 'potential')
02:55:56 <Taral> okay, so I have A, B |- C, D => |- (A (*) B) -o (C (+) D)
02:56:02 <Taral> which is the same as
02:56:11 <Taral> |- ~A (+) ~B (+) C (+) D
02:56:13 <Taral> O.o
02:56:15 <ski> yes
02:56:22 <Taral> going the other way...
02:56:28 <Taral> A (*) B (*) ~C (*) ~D |-
02:56:39 <ski> right
02:56:47 <Taral> this makes |- very very odd
02:57:00 <ski> it's a dual logic
02:57:04 <Taral> ?
02:57:28 <ski> to each left rule, there is a corresponding right rule, for the dual connective
02:57:32 <Taral> yes
02:57:41 <Taral> I see
02:57:48 <Taral> So if I have A (*) ~A, I have nothing
02:57:50 <ski> (also, the id/axiom and the (admissible) cut are selfdual)
02:57:53 <Taral> and A (+) ~A is meaningless too?
02:58:16 <ski> A (*) ~A --> Bot
02:58:19 <Taral> ah
02:58:26 <ski> Top --> A (+) ~A
02:58:30 <Taral> of course
02:58:33 <ski> the latter is the excluded middle
02:58:43 <ski> (sortof :)
02:58:47 <Taral> heh
02:59:18 <Taral> so Top is the null hypothesis, and Bot is the impossible conclusion
03:00:11 <ski> yes, in a way
03:00:24 <ski> ~A  =  A -o Bot
03:00:34 <Taral> hm
03:00:43 <Taral> okay... let's have more fun.
03:00:59 <xinming> ski:  k a; return (concat ["("a,"+","1",")"])}); 
03:01:10 <ski> xinming : yes ?
03:01:11 <xinming> ski: where does a come from in `k a'?
03:01:27 * xinming is indenting the code in emacs. and haven't yet tried. :-/
03:01:42 <Taral> A |- B => A |- (Bot (*) Bot), B
03:01:42 <ski> xinming : do {a <- return (concat ["(",x,"*",x,")"]); k a; return (concat ["("a,"+","1",")"])}
03:01:54 <ski> xinming : 'a' comes from first action, in there
03:02:47 <ski> Taral : hm, how'd you do that ?
03:02:54 <Taral> hehehe
03:03:03 <ski> i think that's not possible
03:03:08 <Taral> A |- B => A |- Bot, B
03:03:12 <ski> yes
03:03:17 <Taral> then combine that with |- Bot
03:03:30 <Taral> you get A |- (Bot (*) Bot), B
03:03:37 <ski> '|- Bot' ? huh ?
03:04:00 <ski> you have '|- Top' and 'Bot |-', but not '|- Bot'
03:04:24 <Taral> aw
03:04:39 <Taral> so '|-' is not valid?
03:05:14 <ski> '|- Bot' would mean the same as 'Top |- Bot' and that is not derivable
03:05:38 <Taral> but isn't 'A |-' the same as 'A |- Bot'?
03:05:49 <ski> sure
03:05:58 <Taral> so '|-' is not valid.
03:06:04 <ski> in what sense ?
03:06:14 <Taral> '|-' => 'Top |- Bot'
03:06:31 <ski> '|-' is invalid, yes
03:06:33 <Taral> in more usual logics, '|-' (nothing entails nothing) is a valid conclusion.
03:07:06 * ski thinks he misunderstood what Taral meant by '|-' .. thought he was speaking about it as entailment, not as a judgement
03:07:30 <ski> Taral : name such a logic
03:07:34 <Taral> ?
03:07:47 <Taral> Classical logic?
03:07:47 <ski> in which '|-' is a valid conclusion
03:07:54 <araujo> Ok, just read a bit about CT... now, thinking in terms of Haskell, functions composition and the id function would come from CT right?
03:07:58 <ski> Taral : no
03:08:01 <xinming> ski: can you paste it in the web, so I can download it and test it.
03:08:06 <Taral> Why not?
03:08:20 <Taral> oh
03:08:21 <Taral> ;(
03:08:22 <Taral> :(
03:08:32 <Taral> same problem, you get 'True |- False'
03:08:48 <ski> '|-' means "from zero premises (i.e. true) we can get zero conclusions (i.e. false)"
03:08:51 <ski> right
03:08:57 <Taral> okay
03:09:07 <Taral> so...
03:09:27 <ski> implicit conjunctiveness resp. disjunctiveness of those two sequences of formulae biting you ..
03:09:31 <Taral> A |- B => A |- Bot, B => A, A |- (Bot (*) Bot), B, B
03:09:36 <araujo> Good morning.
03:09:48 <ski> good afternoon,araujo 
03:10:19 <ski> Taral : think si
03:10:26 <ski> s/si/so/
03:10:29 <Taral> interesting
03:10:39 <Taral> so I have to have multiple As to get there...
03:11:12 <Taral> okay.
03:11:19 <Taral> You can't just combine formulas...
03:11:45 <xinming> ski: because I got the parse error while trying your code. :-/
03:12:06 <ski> xinming : ok, waitamin
03:12:07 <Taral> 'A |- B; C |- D => A, C |- B, D' is not a valid rule
03:12:28 <ski> right
03:15:42 <Taral> okay, I just got the bit about |- A (+) ~A being excluded middle.
03:15:55 <Taral> heh
03:15:58 <Taral> okay :)
03:16:00 <Taral> happy now.
03:16:11 <araujo> > eval [[2,1],[2,4],[3,5]] >>= (return . (: []) . (: []))
03:16:12 <lambdabot>  Not in scope: `eval'
03:16:19 <araujo> > [[2,1],[2,4],[3,5]] >>= (return . (: []) . (: []))
03:16:20 <lambdabot> [[[[2,1]]],[[[2,4]]],[[[3,5]]]]
03:17:21 <Taral> wait...
03:17:32 <Taral> (A (*) B) (+) C = (A (*) C) (+) B
03:17:34 <araujo> > "HASKELL" >>= (return . (: []) . (: []))
03:17:35 <lambdabot> [["H"],["A"],["S"],["K"],["E"],["L"],["L"]]
03:18:52 <Taral> :(
03:19:16 <lisppaste2> ski pasted "example of callCC" at http://paste.lisp.org/display/14833
03:21:05 <ski> Taral : i don't think that works ..
03:21:42 <Taral> it gets close
03:21:56 <Taral> |- A; |- B, C => |- (A (*) B) (+) C
03:22:00 <Taral> |- A; |- B, C => |- (A (*) C) (+) B
03:22:04 <ski> otoh    (A (+) B) (*) C --> (A (*) C) (+) B
03:22:07 <Taral> that rule is giving me fits
03:22:12 <ski> hm
03:22:19 <ski> xinming : you saw the paste ?
03:22:59 <xinming> ski: yes, thanks, I'll go and take the suppor, bbl, I've downloaded it by the way.
03:23:15 <ski> (xinming : i've tested it, so it should work :)
03:29:56 <Dantares> mornin yall
03:30:11 <Dantares> can anyone tell me where to find the sort function?
03:30:16 <Dantares> its not defined in the prelude
03:30:28 <musasabi> @index sort
03:30:29 <lambdabot> Data.List
03:30:57 <Dantares> thx!
03:38:18 <Dantares> isnt there any simpler way to define sort?
03:38:35 <ProfTeggy> Simpler than what?
03:40:14 <Dantares> than the one defined in Data.List
03:40:21 <Dantares> something like:
03:40:52 <Dantares> sort (x:y:xs)
03:41:03 <Dantares> |x<y = x:y:sdlkfnsdfns
03:41:05 <Dantares> i dont know
03:41:08 <Dantares> something simpler
03:42:41 <musasabi> Dantares: like this:
03:42:45 <musasabi> sort [] = []
03:42:50 <kowey> is there a standard type class for things with a unique id?  Enum does not quite seem like what I have in mind
03:43:18 <musasabi> sort (x:xs) = sort [v | v <- xs, v < x] ++ [x] ++ sort [v | v <- xs, v >= x] 
03:43:46 <ProfTeggy> Dantares snippet smells more like insertion sort, mussabi
03:43:49 <ski> > foldr Data.List.insert [] [7,1,4,2,8,5]
03:43:50 <lambdabot> [1,2,4,5,7,8]
03:44:07 <Dantares> thx
03:44:18 <ski> but why define it ?
03:44:29 <Dantares> cause i need to understand it
03:44:34 <Dantares> to apply to something different
03:45:04 * ski leaves
03:45:22 <Dantares> for example u have this: [(2,"sdfds"),(1,"asfsfdsa"),(3,"sdfds"),(1,"asfsfdsa")]
03:45:25 <Dantares> and order it
03:46:44 <TuringTest> And you want to sortBy the fst of the tuple?
03:47:16 <musasabi> > Data.List.sort [(2,"sdfds"),(1,"asfsfdsa"),(3,"sdfds"),(1,"asfsfdsa")]
03:47:17 <lambdabot> [(1,"asfsfdsa"),(1,"asfsfdsa"),(2,"sdfds"),(3,"sdfds")]
03:49:08 <Dantares> hmm
03:49:27 <Dantares> how the hell does that work?
03:49:28 <Dantares> :P
03:49:36 <Taral> look up class Ord and its instances
03:49:45 <Taral> pairs have a derived instance
03:50:04 <Taral> > (1, "c") < (2, "a")
03:50:05 <lambdabot> True
03:50:10 <Dantares> oh
03:50:18 <Dantares> i didnt knew about that
03:50:22 <TuringTest> > ("c",1) < ("a",2)
03:50:24 <lambdabot> False
03:50:26 <Dantares> this is realy useful
03:50:32 <Taral> type classes are nice
03:50:37 <Dantares> hmm
03:50:39 <Taral> @index compare
03:50:39 <lambdabot> Prelude
03:50:53 <Dantares> but "a" is smaller than "c2?
03:50:53 <TuringTest> @help type
03:50:54 <lambdabot>  @type: return the type of a value
03:51:04 <Taral> http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t%3AOrd
03:51:13 <Taral> > compare "a" "c"
03:51:14 <TuringTest> @type sortBy (\a b -> compare (fst a) (fst b))
03:51:14 <lambdabot> LT
03:51:14 <lambdabot> Not in scope: `sortBy'
03:51:26 <Dantares> thx!
03:51:28 <TuringTest> @ type Data.List.sortBy (\a b -> compare (fst a) (fst b))
03:51:28 <lambdabot> Maybe you meant: . all-dicts arr babel botsnack choice-add code compose
03:51:28 <lambdabot> devils dice dict dict-help djinn djinn-add djinn-clr djinn-del djinn-env
03:51:28 <lambdabot> djinn-ver docs dummy dynamic-load dynamic-reload dynamic-unload easton
03:51:28 <lambdabot> echo elements elite eurohaskell eval fact fact-cons fact-delete fact-set
03:51:28 <lambdabot> fact-snoc fact-update foldoc fortune gazetteer get-shapr ghc google help
03:51:30 <lambdabot> [8 @more lines]
03:51:37 <TuringTest> @type Data.List.sortBy (\a b -> compare (fst a) (fst b))
03:51:38 <lambdabot> forall b a. (Ord a) => [(a, b)] -> [(a, b)]
03:51:58 <Taral> @pl \a b -> compare (fst a) (fst b)
03:51:58 <lambdabot> (. fst) . compare . fst
03:53:09 <TuringTest> For the record: the pointless form is not better in this case.
03:54:03 <xs> why?
03:55:58 <aleator> Hmm.. Once again: "comparing f a b = compare (f a) (f b)" makes life simpler.. (sortBy (comparing fst) )
03:56:19 <ProfTeggy> Oh, xs, is that you?  The xs in 'map f (x:xs) = f x:map f xs' ?
03:56:19 <Taral> @index comparing
03:56:20 <lambdabot> bzzt
03:56:59 * Cale boings
03:57:12 <Taral> @pl \f g a b = f (g a) (g b)
03:57:12 <lambdabot> (line 1, column 10):
03:57:12 <lambdabot> unexpected "="
03:57:12 <lambdabot> expecting pattern or "->"
03:57:13 <Cale> hehe, someone mentioned my trivial invention :)
03:57:18 <Taral> @pl \f g a b -> f (g a) (g b)
03:57:19 <lambdabot> join . ((flip . ((.) .)) .) . (.)
03:57:25 <Taral> that should be a standard function
03:57:28 <Taral> like (.)
03:57:46 <Taral> @type ((flip . ((.) .)) .) . (.)
03:57:47 <lambdabot> forall a b c a1 b1.
03:57:47 <lambdabot> (b1 -> b -> c) -> (a -> b1) -> (a1 -> b) -> a -> a1 -> c
03:58:10 <aleator> Cale: comparing?
03:58:15 <Taral> @type (.((flip . ((.) .)) .) . (.))
03:58:15 <lambdabot> forall a b c a1 b1 c1.
03:58:15 <lambdabot> (((a -> b1) -> (a1 -> b) -> a -> a1 -> c) -> c1)
03:58:15 <lambdabot> -> (b1 -> b -> c)
03:58:15 <lambdabot> -> c1
03:58:17 <Cale> aleator: yeah
03:58:30 <Cale> It's better applied to special cases, I think. It's not that often that you want such a combinator in general
03:58:42 <Taral> I dunno about that.
03:58:46 <Taral> @type curry
03:58:47 <musasabi> Cale: one wants such a combinator for Eq too
03:58:47 <lambdabot> forall c b a. ((a, b) -> c) -> a -> b -> c
03:59:09 <aleator> Cale: I tend to make use of it often.
03:59:13 <Cale> musasabi: yeah, Eq and compare mostly
03:59:18 <Taral> It's (.) used over two arguments
04:00:07 <Taral> @type \f g a b -> f (g a) (g b)
04:00:08 <lambdabot> forall t t1 t2. (t1 -> t1 -> t2) -> (t -> t1) -> t -> t -> t2
04:00:33 <musasabi> @djinn (t1 -> t1 -> t2) -> (t -> t1) -> t -> t -> t2
04:00:34 <lambdabot> f a b c _ = a (b c) (b c)
04:00:39 <Taral> @type \f (g :: forall a. a -> m a) a b -> f (g a) (g b)
04:00:40 <lambdabot> forall (m :: * -> *) a a1 t.
04:00:40 <lambdabot> (m a -> m a1 -> t) -> (forall a2. a2 -> m a2) -> a -> a1 -> t
04:00:48 <Taral> whee!
04:01:08 <Taral> I love higher-order polymorphism
04:22:13 <joelr1> afternoon!
04:22:21 <joelr1> dons: ping
04:23:01 <musasabi> morning
04:23:36 <joelr1> musasabi: i converted my serialization to pointers but it's still taking too long :( troubleshooting
04:23:50 <joelr1> dons suggested that i look at the "core", is that generated c files?
04:24:14 <Cale> core is an intermediate language iirc.
04:24:28 <musasabi> no, that is intermediate representation.
04:24:29 <joelr1> there was a -keep-... option
04:24:31 <joelr1> looking for it
04:24:44 <musasabi> joelr1: just simple profiling ought to tell you where the problem is.
04:24:46 <joelr1> keep c files or something like that
04:24:56 <musasabi> joelr1: +RTS -p
04:24:56 <joelr1> musasabi: not quite
04:25:00 <musasabi> hmm?
04:25:18 <joelr1> musasabi: i have been running that for ages ;) check the brand new "battling time leaks" thread on haskell-cafe
04:26:06 * musasabi goes look at mail
04:27:16 <musasabi> joelr1: the isBigendian thing?
04:27:23 <joelr1> what about it?
04:27:31 <joelr1> musasabi: let me be back in 15 
04:27:35 <musasabi> joelr1: did you look at how binser does that? or just use a #define if you are desperate
04:27:43 <musasabi> (i.e. #ifdef)
04:27:47 <joelr1> i don't think that's an issue
04:27:52 <joelr1> be back in 15
04:39:24 <joelr1> musasabi: ping
04:42:16 <jethr0_> @seen shapr
04:42:17 <lambdabot> shapr is in #ScannedInAvian. Last spoke 1 hour, 2 minutes and 46 seconds
04:42:17 <lambdabot> ago.
04:44:59 <joelr1> does anyone know the difference between No. and Entries in the profiler report?
04:45:51 <musasabi> pong
04:46:28 <musasabi> as for the ORANGE ALERT times they don't show that much variance that I would be worried (or are they just too slow?)
04:46:58 <joelr1> musasabi: well, i'm gonna try to debug that
04:47:18 <joelr1> i'm thinking that they just might be slow but i'm gonna annotate the pickling code and see what functions are taking the most time
04:47:35 <musasabi> joelr1: I would concentrate on getting overhead away rather than looking at the variance.
04:47:50 <joelr1> musasabi: i'm also gonna dump the packets at the point of failure and profile them separately 
04:47:53 <musasabi> joelr1: -auto-all + prof should tell you the function (if they are reasonably sized)
04:48:09 <joelr1> i _am_ compiling with -auto-all and prof
04:48:21 <joelr1> musasabi: wanna see the full profiling report
04:49:07 <joelr1> here
04:49:16 <joelr1> http://wagerlabs.com/randomplay.prof
04:49:48 <joelr1> wait, that;s pre-O2
04:50:56 <joelr1> and http://wagerlabs.com/randomplay.02.prof is the one witth -O2
04:51:16 <musasabi> 404
04:52:42 <joelr1> which one?
04:52:43 <joelr1> let me go see
04:53:18 <joelr1> http://wagerlabs.com/randomplay.prof
04:53:34 <joelr1> this one works too
04:53:35 <joelr1> http://wagerlabs.com/randomplay.O2.prof
04:54:00 <joelr1> still does not work?
04:55:15 <musasabi> it was 02 vs O2
04:55:54 <joelr1> sorry about that :(
04:57:24 <musasabi> joelr1: are the routines in Script.PokerClient specialized (with the pragma) ?
04:57:42 <joelr1> musasabi: line 942 in the O2 report is probably about where i would look since TableInfo is part of SrvServerInfo which is basically a huge list of TableInfos
04:57:55 <joelr1> musasabi: not at all. which ones would you specialize there?
04:58:06 <joelr1> there's nothing to specialize there from my prospective
04:59:51 <musasabi> well if have a: readStorableFunction :: Storable a => YourState -> IO a, then that one
05:00:12 <joelr1> musasabi: no such thing. read uses pickling, unstuff 
05:00:35 <musasabi> well how does unstuff work?
05:00:37 <joelr1> musasabi: let me upload the ptr-based pickling. the previous, array-based version is at http://wagerlabs.com/array.tgz
05:00:42 <joelr1> musasabi: give me a second
05:01:17 <musasabi> ok
05:03:58 <ProfTeggy> lecturing, bbl
05:04:22 <joelr1> musasabi: let me get a data dump as well
05:06:56 <xinming>        y <- callCC $ \k ->
05:06:57 <xinming>          do a <- return (x * x)
05:06:57 <xinming>             k a
05:06:57 <xinming>             return (a + 1)
05:07:05 <xinming> what's k here please?
05:07:20 <joelr1> k = continuation? :)
05:08:07 <xinming> joelr1: but...
05:08:25 <joelr1> ?
05:08:51 <xinming> http://paste.lisp.org/display/14833
05:08:59 <xinming> could you please explain this example for me?
05:09:33 <xinming> for test0, and I haven't read the test1.
05:09:47 <joelr1> i probably cannot :( it's beein a while since i used continuations and i did it in lisp :(
05:10:21 <xinming> joelr1: thanks anyway.
05:12:36 <musasabi> xinming: k is the escape continuation
05:12:59 <musasabi> let f x = callCC (\k -> do a <- return (x*x); k a; return (a+1))
05:13:10 <musasabi> runCont (f 2) id == 4
05:13:15 <joelr1> musasabi: for your viewing pleasure: http://wagerlabs.com/timeleak.tgz
05:14:19 <tic> musasabi, what's the a+1 doing then?
05:15:46 <musasabi> joelr1: at least reverseBytes is buggy
05:16:02 <joelr1> musasabi: it is? it does seem to work, though
05:16:08 <joelr1> buggy in what sense?
05:16:10 <musasabi> tic: well it would return the value if the computation was not aborted with the escape continuation
05:16:44 <tic> musasabi, shouldn't that yield 5 then?
05:16:58 <musasabi> joelr1: mmh, seems it is correct, you used just both shifts and I just misread things.
05:17:01 <tic> or is k = id?
05:17:20 <musasabi> k is the escape continuation.
05:17:38 <musasabi> id = the thing applied for the (a -> r) conversion
05:17:49 <tic> ah.
05:17:50 <joelr1> musasabi: orange.dump has the packets for the alert
05:18:02 <joelr1> musasabi: i'm planning to run unstuff on them and time it
05:18:09 <tic> musasabi, so when does a+1 happen?
05:18:19 * tic needs a call graph :)
05:18:28 <musasabi> tic: it does not happen at all.
05:18:40 <tic> musasabi, then why is it around?
05:18:59 <musasabi> tic: to show that the computation is aborted before the return.
05:19:18 <musasabi> joelr1: what benefits does sequ have over a monadic approach to things?
05:19:40 <tic> musasabi, ah.
05:20:04 <joelr1> musasabi: probably none but that's the way it was done in the pickler combinators paper
05:20:09 <joelr1> @google pickler combinators
05:20:10 <lambdabot> http://research.microsoft.com/~akenn/fun/picklercombinators.pdf
05:20:37 <joelr1> musasabi: probably the only benefit that i can see is that it works for both pickling and unpickling
05:20:43 <joelr1> you cannot do that in a single monad
05:22:32 <musasabi> true, but you can generate code for different monads from a single spec.
05:22:45 <joelr1> musasabi: how's that?
05:23:05 <musasabi> the binser code has that. (SerLang etc)
05:23:13 <joelr1> musasabi: overall, i just looked through the whole profiler report (O2) and the bottleneck seems to be 1) unstuff and 2) the bits around line 942
05:23:37 <joelr1> about 20 lines from 942 down
05:23:59 <joelr1> musasabi: do you think your serialization code would be faster?
05:26:07 <joelr1> musasabi: my issue is that 1) i need to deal with endian stuff, i.e. everything comes to me little-endian but i develop and debug on powerpc (BE) and deploy on intel (LE)
05:26:24 <musasabi> joelr1: I would try adding {-# INLINE #-} to various things carefully in the pickler.
05:26:31 <joelr1> musasabi: and 2) i deal with a lot of structures that can be described as list of A with the size given by B
05:26:54 <musasabi> joelr1: well you can deal with endianess using #ifdef - that is the fastest way.
05:27:33 <joelr1> musasabi: i don't think THAT is the bottleneck as my customer reports the same problems on intel where there's no reverseBytes
05:28:15 <Dantares> what do i have to import to be able to use "Data.List.sort"?
05:28:36 <joelr1> musasabi: if your SerTH would let me derive serialization somehow for my data structures, including lists of X prefixed by length of Y then i could try switching to see if things improve
05:28:49 <musasabi> joelr1: as for the speed part you could have a simple test case and add your code to that and see how it performs against the alternatives.
05:29:01 <joelr1> other than that, where would you add inline? the docs says that the compiler already tries that when in C mode (-O)
05:29:27 <joelr1> musasabi: the test case is in orange.dump, the packets it's having trouble with
05:30:14 <musasabi> http://cs.helsinki.fi/u/ekarttun/haskell/test.hs is what I am currently using for testing
05:30:49 <joelr1> musasabi: looking
05:31:31 <joelr1> musasabi: it would be excellent if you could show me how to use SerTH with the timeleak code. then I could time that
05:32:33 <gaal> hi! is there a flag I can turn on to get a more detailed error message than this?
05:32:37 <gaal> Prelude.head: empty list
05:32:49 <gaal> it isn't obvious where the head is being called
05:33:07 <musasabi> darcs uses #define head ...
05:33:24 <Dantares> what do i have to import to be able to use "Data.List.sort"?
05:33:33 <gaal> this is in pugs, GHC.
05:33:37 <tic> import Data.List ?
05:34:00 <Dantares> thx
05:34:34 <Dantares> ERROR "Data.List" - Unable to open file "Data.List"
05:36:09 <gaal> musasabi: got a more precise pointer?
05:36:17 <Dantares> now what?
05:38:14 <joelr1> musasabi: would you kindly show me how to serialize the stuff in Bits.txt?
05:39:42 <musasabi> gaal: no, I remember darcs doing it, wget + grep should tell you the answer.
05:39:47 <musasabi> joelr1: ok, looking at it.
05:40:57 <gaal> musasabi: cheers
05:42:04 <Dantares> help...plz?
05:45:47 <gaal> musasabi: I couldn't find this. Maybe it wasn't in darcs? :)
05:46:00 <Dantares> i cant use Data.List.Sort
05:46:05 <Dantares> why?
05:47:09 <jethr0_> anyone here with artistic talent? i had an idea for a logo for the next TMR, but it needs some artistic touch: http://haskell.org/tmrwiki/TemplateHaskell?action=AttachFile&amp;do=get&amp;target=xmas-lambda.png
05:48:52 <Dantares> dude
05:48:57 <Dantares> i rule with Photoshop
05:49:04 <Dantares> need my help?
05:49:31 <kowey> Dantares: maybe you could paste your code somewhere?
05:49:49 <jethr0_> dantares, sure, if you want you could either redo the whole thing or i could give you my slightly higher resolution files
05:50:05 <Dantares> ill redo it
05:50:15 <Dantares> kowey: its no need
05:50:23 <Dantares> i just wat to use Data.List.Sort
05:50:26 <Dantares> but i cant
05:50:32 <Dantares> i have to import something?
05:50:44 <kowey> import Data.List in your .hs file
05:50:52 <kowey> and then sort in your code (sort foo)
05:51:17 <jethr0_> Dantares: cool, you could try uploading it on the tmrwiki (http://haskell.org/tmrwiki/TemplateHaskell), although i'm not sure you will be able to...
05:51:18 <Dantares> ERROR "Data.List" - Unable to open file "Data.List"
05:51:28 <kowey> after the module ... where bit, but before the rest of your code
05:51:38 <jethr0_> Dantares: or show it to shapr, or mail me (softpro at gmx dot net)
05:51:51 <jethr0_> i'll have to run, gotta go 700km by train to get home :)
05:52:24 <Dantares> -- Este ficheiro contÈm o mÛdulo Corrida
05:52:24 <Dantares> module Corrida where
05:52:24 <Dantares> -- Importa as definiÁıes dos tipos
05:52:24 <Dantares> import Tipos
05:52:24 <Dantares> import Data.List
05:52:25 <Dantares> -- Importa o modulo de Char
05:52:27 <Dantares> import Char
05:52:30 <Dantares> i have it like thi
05:52:32 <Dantares> and it doesnt work
05:53:34 <jethr0_> Dantares: you using hugs or ghc?
05:53:38 <Dantares> hugs
05:53:45 <jethr0_> have you got ghc installed?
05:53:47 <jethr0_> ghci rocks
05:53:53 <Dantares> i dont even know what that is
05:54:13 <jethr0_> ghc is a haskell compiler, ghci is an "interpreter" like hugs
05:54:21 <jethr0_> Dantares: what OS are you running?
05:54:25 <Dantares> XP
05:54:30 <jethr0_> oh :)
05:55:11 <Dantares> so what do i do?
05:55:23 <jethr0_> http://www.haskell.org/ghc/download_ghc_641.html#windows
05:56:03 <Dantares> aww
05:56:07 <Dantares> i dont want to install that
05:56:10 <kowey> Dantares: i'm downloading hugs now to see if i can help
05:56:12 <Dantares> do i have toª
05:56:14 <jethr0_> Dantares: i'm not saying that's the smartest way to solve your problem. but for one it sounds like your hugs installation is broken (because a simple import should work) and also ghc/ghci is _way_ cooler than hugs
05:56:16 <Dantares> ok thx m8
05:56:23 <kowey> but i'm on a mac, so maybe i won't be too useful
05:56:45 <jethr0_> Dantares: how did you install hugs?
05:56:51 <Dantares> pressing next....
05:56:56 * jethr0_ just pressed TAB to complete the sentence for him *tststs*
05:57:02 <jethr0_> hmm
05:57:19 <Dantares> maybe its because the .hs file im working on is not in the lib
05:57:29 <jethr0_> Dantares: did anything ever run on hugs before?
05:57:33 <Dantares> sure
05:57:40 <kowey> just not without imports?
05:57:55 <kowey> does the hugs installer ask you to reboot windows?
05:58:01 <jethr0_> hmm, maybe it's not called "Data.List" in your version
05:58:06 <Dantares> maybe...
05:58:13 <Dantares> kowey:bo
05:58:14 <jethr0_> kowey: what was List import called before hierarchies?
05:58:14 <Dantares> No
05:58:35 <kowey> euh... List? jethr0_? don't remember
05:58:36 <jethr0_> Dantares: have you tried "import List"
05:58:43 <Dantares> yes
05:58:45 <Dantares> just now
05:58:46 <Dantares> lol
05:58:47 <Dantares> it works
05:58:51 <jethr0_> hehe
05:58:52 <kowey> ah... you have an old hugs :-)
05:58:55 <Dantares> :D
05:59:13 <Dantares> but i cant use Data.List.Sort
05:59:22 <jethr0_> why?
05:59:24 <Dantares> ERROR - Undefined qualified variable "Data.List.sort" 
05:59:28 <Dantares> dont know....
05:59:30 <kowey> just use "sort"
05:59:40 <jethr0_> or use "import qualified List"
05:59:56 <kowey> when you import List, you're importing all the names, so that you can use them without prefixes
06:00:12 <Dantares> hmm
06:00:14 <Dantares> lemme try
06:00:18 <jethr0_> Dantares: and you'll have to leave the leading "Data" out anyways
06:00:37 <araujo> Isn't nice when you need a function that you had already written? :-)
06:00:43 * araujo boings
06:00:45 <Dantares> sort [(2," 00:00:34.582"),(2," 00:01:01.332"),(3," 00:01:03.198"),(2," 0
06:00:45 <Dantares> 0:01:30.801")] 
06:00:50 <Dantares> this isnt working
06:00:58 <jethr0_> what's it saying?
06:01:06 <Dantares> well, nithing
06:01:08 <Dantares> nothing
06:01:15 <kzm> > sort [(2," 00:00:34.582"),(2," 00:01:01.332"),(3," 00:01:03.198"),(2," 00:01:30.801")]
06:01:16 <lambdabot> [(2," 00:00:34.582"),(2," 00:01:01.332"),(2," 00:01:30.801"),(3," 00:01:
06:01:16 <lambdabot> 03.198")]
06:01:24 <jethr0_> well, its sorted
06:01:29 <jethr0_> oh, that was kzm
06:01:45 * kzm is sorry to barge in, but he was bored. :-)
06:01:53 <Dantares> hmmm
06:02:01 <Dantares> why the hell doesnt it work?!
06:02:05 <Dantares> its so weird
06:02:09 <Dantares> i write it on my compiler
06:02:18 <Dantares> and it simply returns..nothing
06:02:18 <jethr0_> Dantares: ghci is seriously cooler :)
06:02:22 <Dantares> lol
06:02:26 <Dantares> ill instal that
06:02:27 <Dantares> :D
06:02:54 <xerox> Hi.
06:03:04 <kowey> in any case, you probably want the latest version of hugs or ghc, something recent so that when people suggest you stuff like "import Data.List", it actually works
06:03:04 <jethr0_> Dantares: and it would be seriously cool if you took a shot at that lambda-tree. really gotta go
06:03:06 <Dantares> downloading it
06:03:16 <Dantares> ok ill try dude
06:03:21 <jethr0_> merry xmas everyone unless i'll be in before then
06:03:29 <Dantares> dude
06:03:36 <Dantares> u have any time limit for the lambda thing?
06:03:49 <Dantares> cause im a little busy atm
06:04:20 <jethr0_> Dantares: hmm, i guess before xmas would be nice, but don't sweat it! my version isn't _that_ ugly :)
06:04:28 <Dantares> lol ok
06:04:30 <Dantares> ill try
06:04:33 <Dantares> ill may it
06:04:34 <Dantares> mail
06:04:46 <jethr0_> thx, and have fun with ghci...
06:04:46 <jethr0_> bye
06:06:01 <xerox> @quote xerox
06:06:01 <lambdabot>  > take 10 lol where lol = "ol" : zipWith (:) (intersperse 'o' $ cycle "l"
06:06:01 <lambdabot> ) lol
06:06:08 <xerox> @quote xerox
06:06:08 <lambdabot>  > take 10 lol where lol = "ol" : zipWith (:) (intersperse 'o' $ cycle "l"
06:06:08 <lambdabot> ) lol
06:06:11 <xerox> okay.
06:07:17 <kowey> haskell is call-by-reference?
06:07:25 <xerox> It's call-by-need
06:07:49 <xerox> > fst (1,map (*2) [0..])
06:07:51 <kowey> so if i've got functions that manipulate huge records... but only a small chunk of them
06:07:51 <lambdabot> 1
06:08:20 <kowey> then i don't get huge amounts of data being shipped around function to function... right? that's how i've always understood this laziness thing
06:08:48 <ibid> kowey: that's not what laziness means, but generally, that's what happens
06:09:05 <flux__> kowey, haskell doesn't copy stuff around anyway, because everything is immutable and can easily be just referred to
06:09:25 <kowey> hmm... then having code which strips records down to their bare neccesities before manipulating them is pointless, right?
06:09:34 <ibid> kowey: of course "manipulating" data does not mean what you think it means in haskell :)
06:09:38 <Philippa_> depends what you're doing - you get a big copy if you append to a list, prepending doesn't need one
06:10:02 <Philippa_> kowey: it can be useful as a binding or readability thing. But yes
06:10:10 <kowey> well... i am comfortable with the idea of immutability... but somewhere 
06:10:23 <kowey> i have this thing that builds automata... right.. and for the labels of my automata
06:10:35 <kowey> i used to use these huge data structures, where what i really wanted was the string
06:10:49 <kowey> but i thought that was ok, because of the consequences of lazy evaluation
06:11:17 <ibid> kowey: the point is, calling a function does not create a copy of the data you pass to it, generally
06:11:31 <ibid> kowey: (though the function being called is of course free to copy it itself:)
06:11:40 <kowey> ibid: thanks! very succint :-)
06:11:47 * kowey feels vindicated yet confused
06:12:47 <kowey> forgive me for not completely understanding the consequences yet... (still pushing this point through)
06:13:18 <kowey> say i have a function which given a huge record, returns the same huge record, but with one parameter different
06:13:22 <kowey> what's being copied around?
06:13:27 <ibid> kowey: the whole record
06:13:36 <kowey> ah-hah
06:13:38 <ibid> kowey: changing a record copies the whole recor
06:13:42 <ibid> +d
06:13:46 <flux__> well, aren't the record fields themselves shared?
06:13:55 <kowey> so stripping the record down (in my case) was neccesary then
06:13:56 <ibid> flux__: yeah
06:14:08 <ibid> kowey: i don't know what you mean by stripping the record down
06:14:22 <kowey> well... a function which converts the record to a similar one but having less data
06:14:27 <ibid> kowey: more precisely, it creates a _shallow_ copy of the record
06:14:36 <ibid> kowey: well, that makes a copy too
06:14:46 <ibid> (though a smaller one, obviously)
06:15:33 <kowey> to return to my automaton construction example: when i say that my huge data structures are the labels
06:15:49 <kowey> what i really mean is that some property (say an id) of huge data structures are the labels
06:15:51 <ibid> kowey: every time you call a data constructor in an expression context, you allocate a new record to hold (pointers to) the data given as arguments to the constructor
06:16:12 <kowey> a shallow copy, as you say, ibid
06:16:23 <ibid> ALS
06:16:27 <ibid> gah
06:16:39 <kowey> ?
06:16:43 <ibid> also, the syntax Foo { bar = baz } is just syntactic sugar,
06:16:46 <ibid> kowey: typos
06:18:00 <ibid> kowey: of course, lazy evaluation does create interesting (and sometimes hard to analyze) changes to the space and time behaviour of programs
06:18:30 <kowey> back again to my example: if the only thing that my automaton construction code does with the huge records is look at one of their fields... 
06:18:41 <kowey> then the automaton construction functions which pass these huge records around to each other
06:19:06 <kowey> are only passing pointers to the records... since i'm not making any changes to the records, i'm not even making a shallow copy, right?
06:19:11 <ibid> kowey: passing data around passes pointers around (or if the data is small enough, the data itself)
06:19:18 <ibid> kowey: yes
06:19:31 <kowey> ibid: right... so i wonder why rewriting my automaton stuff to restrain my records helped
06:19:41 <kowey> it shouldn't have made a difference
06:19:50 <ibid> kowey: the only time you allocate is when you invoke a constructor (of course, a function might do that for you, but it's the basic idea)
06:19:54 <ibid> restrain?
06:20:10 <kowey> (hence the vindication - i don't feel so stupid for passing huge records around, but confused - because...)
06:20:25 <kowey> by restrain, i mean, first map a function which builds minirecords from the huge records
06:20:31 <ibid> kowey: of course, lazy evaluation means that only those parts of the data structu≈ïe that has been needed is actually constructed in the memory (and only "just in time")
06:20:37 <kowey> containing just the stuff i need... by your explanation, that should actually cost more
06:20:45 <ibid> kowey: yeah, that's wasteful
06:21:12 <kowey> huh... maybe the extra efficiency was related to other changes in my code... wow victory then! laziness means less thinking!
06:21:19 <kowey> thanks, everyone :-)
06:22:52 <ibid> kowey: it is often helpful to think of Haskell as math, not programming. what the interpreter does is do the calculations for you so you don't have to do them by hand (this analogy works less well with compilers, but you can pretend it's an interpreter anyway:)
06:23:31 <kowey> that's what i like about it... i feel like i'm saying what i mean and not a bunch of irrelevant repetitive stuff
06:24:35 <ibid> kowey: and if you want to really get haskell, you will need to learn the calculus side of it eventually (lambda calculus or haskell core or similar)
06:24:46 <ibid> (of course, there's no rush to it)
06:25:04 <kowey> what exactly does learning lambda calculus mean? i mean, i've got some basics, like alpha conversion and beta reduction
06:25:23 <kowey> do you mean something deeper than that? i've got a very mechanical view of lambda calculus...
06:25:55 <ibid> kowey: no, beta reduction is the level i mean
06:26:06 <ibid> kowey: but you want to look at graph reuction at some point
06:26:18 <ibid> kowey: (not very deeply, but it's the heart and soul of haskell;)
06:26:29 <ibid> graph reduction
06:26:31 <kowey> graph reduction... noted (thanks)
06:27:19 <ibid> what the compilers do is essentially optimize away all the inefficiencies of the "naive" graph reduction
06:27:43 <ibid> but the dynamic semantics of haskell is basically lambda calculus with let and graph reduction
06:28:34 <ibid> (graph reduction is why "tying the knot" works)
06:29:11 <kowey> what is "tying the knot?" you mean the crazy stuff like the implementation of fibonacci?
06:30:00 <Cale> kowey: sort of worse :)
06:30:14 <Cale> (or better, depending on your perspective)
06:30:41 * kowey looks at hawiki
06:30:43 <ibid> kowey: stuff that allows you to create self-referential data structures without mutation
06:30:54 <xerox> Cale: the quote 'xerox says: ... befunge ...' is from SamB it seems, not me! :-) <http://tunes.org/~nef/logs/haskell/05.11.11>
06:30:55 <Cale> Basically, you can create cyclic data structures (which look just like infinite data structures, but aren't)
06:31:11 <Cale> hm?
06:31:28 <Cale> oh
06:31:40 <Cale> I don't think I've seen that quote before :)
06:32:04 <ibid> kowey: the example i like to pass around is this:
06:32:07 <xerox> <lambdabot> xerox says: you know, befunge is probably the only language I've seen <lambdabot> where you can run code pasted from IRC with the <nick> tags still in <lambdabot> place ;-)
06:32:20 <ibid> > let ones = 1 : ones in take 5 ones
06:32:21 <lambdabot> [1,1,1,1,1]
06:32:37 <xerox> Yesterday, uh, but weren't you to ask for the @quote, sorry
06:32:40 <ibid> where "ones" has a constant size, regardless of how much you take from it
06:33:03 <Cale> yeah, that's a nice simple example
06:33:39 <kowey> nice and simple.... 
06:33:55 <kowey> but do you think that people actually realistically make use of stuff like this?
06:34:01 <ibid> kowey: yes
06:34:22 <kowey> i mean, i'm a pretty average functional programmer, and my first reflex would be to look at that 
06:34:24 <ibid> kowey: it's one of the "tricks of the trade" in haskell programming
06:34:29 <Cale> basically, if you think of the variables which you're defining as pointers, everything works much like it would in a language with pointers (except that you don't get null pointer exceptions or memory access violations ;)
06:34:36 <kowey> and say "oh no! infinite!"... and then breathe a sigh of relief, because it's lazily evaluated
06:34:59 <ibid> well, i use infinite lists quite liberally
06:35:06 <Cale> kowey: I'm in the middle of writing an article about it
06:35:10 <kowey> i use them for stuff like applying an id to things
06:35:13 <Cale> the use of laziness
06:35:13 <ibid> of course, most of the time they aren't knots
06:35:19 <ibid> like this:
06:35:49 <ibid> > zip [1..] ["a","b","c","d","e"]
06:35:50 <lambdabot> [(1,"a"),(2,"b"),(3,"c"),(4,"d"),(5,"e")]
06:35:54 <xerox> Cale: will it touch the point where you show how does monads improve composability?
06:36:09 <ibid> (of course, the "a" ... list would in actual use be the payload list)
06:36:21 <kowey> i'd be interested in seeing that, Cale... i'm interested in seeing how to exploit this to make code more concise
06:36:30 <kowey> your paper, that is
06:36:57 <ibid> i think zip [1..] is one of the most common idioms i use that utilize infinite lists
06:37:07 <Cale> xerox: well, laziness anyway
06:37:32 <Cale> I might touch on how monads get wrapped up in it
06:37:40 <xerox> Great.
06:37:41 <ibid> often in stuff like map f (zip [1..] xs), where f needs to know the "index" to the list to work
06:38:15 <kowey> i'm witnessing a sort of "hmm... maybe laziness is more trouble than it's worth" cultural shift in my lab
06:38:27 <xerox> O_o
06:38:31 <kowey> former haskellers thinking of taking up caml... would be good to have some nice counterarguments
06:38:43 <tromp_> caml is ugly:(
06:38:47 <Cale> kowey: the basic idea is that laziness turns a whole lot of elegant but unreasonably slow/inefficient solutions to a problem and makes them viable
06:38:53 <kowey> not that i want to evangelise or anything, just give things more a fair chance :-)
06:38:58 <ibid> i tend to oscillate between "haskell is beautiful but useless" and "haskell is beautiful and useful" :)
06:39:26 <kowey> well... that's basically the thing, ibid, i'm loathe to give up haskell because i like the beautiful
06:39:41 <ibid> the main case for laziness imho is that it allows the producer-filter-consumer pattern to be used without threading
06:40:12 <ibid> multithreading
06:40:27 <ibid> which is a powerful decompositioning pattern
06:40:33 <flux__> well, doesn't python have some mechanism for that too?
06:40:38 <flux__> and ocaml has streams
06:40:48 <flux__> albeit it isn't quite as slick as just using lists
06:40:52 <ibid> well, streams are just restricted laziness ;)
06:41:15 <kowey> what about languages like alice, which let you say stuff like "evaluate this lazily?"
06:41:22 <flux__> and mayby laziness is just implicit threading :)
06:41:24 <kowey> (or doesn't ocaml have that too?)
06:41:34 <ibid> flux__: implicit coroutining actually
06:41:38 <flux__> well, yes
06:41:50 <flux__> coroutining is what you referred with not requiring threads, too?
06:42:59 <ibid> as i see it, the difference between threads and coroutines is that coroutines are based on explicit yielding
06:43:12 <ibid> laziness is somewhere in between, actually
06:43:17 <ibid> but my bus goes, bbl :)O
06:43:30 <flux__> you need to explicitly provide a value at the head of the list ;)
06:46:09 * araujo just implemented special quotes in hashell
06:49:57 <kowey> bye, and thanks again
06:54:47 <Dantares> how do i turn "00:00:43.322" into 0,0,43,322 ?
06:54:56 <Dantares> read doesnt work does it?
06:56:22 <Cale> well, you could create a data structure and your own read instance
06:56:33 <Dantares> how?
06:57:16 <Cale> data Time = Time Integer Integer Integer Integer -- or something like that, possibly with record syntax
06:57:21 <Cale> then
06:57:28 <Cale> instance Read Time where
06:58:09 <Dantares> ok ill try that thx
06:58:14 <Cale>     readsPrec n xs = ...
06:58:35 <Cale> basically it will be a bunch of calls to readsPrec for integers
06:59:32 <Cale> look carefully at the prelude for how things are supposed to work -- there's a bit more complicated of a framework set up than you'll actually need to make use of
07:00:24 <Cale> ask some more here if you get stuck -- I'm going to take a nap though :)
07:00:33 <Dantares> lol
07:02:54 <Cale> if you don't want to go to the trouble, you could do it more directly without a Read instance by manipulating that string with list functions (breaking it on : and '.'
07:02:57 <Cale> )
07:22:43 <araujo> mm...
07:23:12 <araujo> > let f (a:b:':':c:d:':':e:f:'.':r) = [read [a],read [c], read (e : f : []), read r] in f  "00:00:43.322" 
07:23:12 <lambdabot> Add a type signature
07:24:23 <araujo> > let f (a:b:':':c:d:':':e:f:'.':r) = [read [a],read [c], read (e : f : []), read r] :: [Int] in f  "00:00:43.322" 
07:24:24 <lambdabot> [0,0,43,322]
07:25:03 * araujo boings around
07:25:12 <xinming> ski: thanks for your example of using callCC, I think I know what it is used for. :-) and how to use the Cont Monad, though, I still don't know how it goes underneath... :-/
07:45:29 <araujo> Is there exist a function in the prelude to know if all the elements of a list are equal to a specific value?
07:46:04 <roconnor> @type \a -> all (a=)
07:46:05 <lambdabot> parse error on input `='
07:46:09 <roconnor> @type \a -> all (a==)
07:46:10 <lambdabot> forall a. (Eq a) => a -> [a] -> Bool
07:46:14 <basti_> > all (5==) [5,5,5]
07:46:15 <lambdabot> True
07:46:16 <basti_> > all (5==) [5,5,4]
07:46:17 <lambdabot> False
07:46:41 <roconnor> araujo: nope, but the function is really short
07:47:15 <araujo> yeah, all will work perfect.
08:24:35 <roconnor> > log(111111111111111111111)/log(2)
08:24:36 <lambdabot> 66.59056499119231
08:24:59 <basti_> ?
08:25:24 <roconnor> number of bits in that number.
08:26:22 <basti_> ah.
08:26:23 <basti_> yes.
08:26:27 * basti_ nods
08:27:54 <xinming1983> anyone here can tell me how can a get in `(Cont c) >>= f = Cont $ \k -> c (\a -> runCont (f a) k)' ?
08:31:17 <xinming1983> I mean from for example, from `return v >>= f'
08:34:42 <CosmicRay> @seen shapr
08:34:43 <lambdabot> shapr is in #ScannedInAvian. Last spoke 2 hours, 50 minutes and 3 seconds
08:34:43 <lambdabot> ago.
08:35:20 <CosmicRay> hey all
08:35:27 <CosmicRay> anyone want to take over HWN?
08:35:47 <roconnor> the nice thinga bout 11111111111111111 is that I think the bits are resonably distributed between 1
08:35:52 <roconnor> between 1 and 0
08:35:59 <roconnor> 10^n doesn't have this property.
08:50:49 * boegel|home just read the HWN editor ad and wheeps
08:51:09 <boegel|home> CosmicRay: what about the Christmas edition you promised us ?
09:01:16 * araujo wonders if he should take a nap or drinkg more caffeine
09:05:44 <boegel|home> araujo: probably take a nap :)
09:06:00 * Trevion always votes for the caffeine approach.
09:06:17 * kolmodin votes for both. first a nap, then the coffie
09:06:31 <araujo> haha
09:06:43 <araujo> kolmodin always going extreme
09:06:46 <araujo> ;-)
09:09:33 <CosmicRay> boegel: we'll see ;-)
09:09:57 <CosmicRay> boegel: sorry about it...  I haven't had time to read most of the lists lately, so HWN has become more of a burden than a joy
09:12:10 <boegel|home> CosmicRay: too bad, it was a great initiative
09:12:20 <boegel|home> I would take it over if I've had time, but I don't :(
09:12:26 <CosmicRay> boegel: I hope to maybe be able to restart it in January
09:12:32 <CosmicRay> but I just don't know right now
09:12:36 <xinming1983> how can callCC `\k ->do{ blablabla... k a; return 1;' skips the rest of the calculation in Cont Monad please?
09:13:38 <boegel|home> CosmicRay: oh, that' be cool
09:13:57 <CosmicRay> I'd rather have some interested party take it over entirely
09:14:01 <boegel|home> is there any way to pretty print a Double value (say with 3 digits after the . )
09:14:12 <boegel|home> CosmicRay: I think that'll be hard to find
09:14:31 <boegel|home> like I said, _if_ I had time... 'cause I think it's a really great initiative
09:14:35 <CosmicRay> boegel: printf may be what you're after
09:16:39 <boegel|home> @type printf
09:16:40 <lambdabot> Not in scope: `printf'
09:16:45 <boegel|home> @index printf
09:16:45 <lambdabot> Text.Printf
09:16:50 <boegel|home> @type Text.printf
09:16:50 <lambdabot> Couldn't find qualified module.
09:16:50 <lambdabot> Maybe you're using the wrong syntax: Data.List.(\\) instead of (Data.List.
09:16:50 <lambdabot> \\)?
09:16:57 <boegel|home> @type Text.Printf
09:16:58 <lambdabot> Couldn't find qualified module.
09:16:58 <lambdabot> Maybe you're using the wrong syntax: Data.List.(\\) instead of (Data.List.
09:16:58 <lambdabot> \\)?
09:17:03 <boegel|home> eh ?
09:18:36 <Trevion> @type Text.Printf.printf
09:18:37 <lambdabot> forall r. (Text.Printf.PrintfType r) => String -> r
09:19:21 <boegel|home> oh.. thanks Trevion
09:20:48 <boegel|home> CosmicRay, Trevion: but that'd an IO action, I want a String representation...
09:21:25 <boegel|home> > show pi
09:21:26 <lambdabot> "3.141592653589793"
09:21:50 <boegel|home> how do I trim this number to 3 digits after the '.' ? (without knowing anything about the number)
09:21:56 <boegel|home> > show 10^(-10)
09:21:56 <lambdabot>  add an instance declaration for (Num String)
09:21:56 <lambdabot>   In the definition of `rfp': rfp = (show 10) ^ (- 10)
09:21:56 <lambdabot>   In the definition of `v':
09:22:02 <boegel|home> > show (10^(-10))
09:22:03 <lambdabot> Exception: Prelude.^: negative exponent
09:22:11 <boegel|home> > show (0.000000000000000000000000000000001)
09:22:12 <lambdabot> "1.0e-33"
09:22:41 <boegel|home> should work for this too, so string stuff won't work... there's no such function available ?
09:22:50 <Trevion> boegel|home: unsafePerformIO?
09:23:42 <boegel|home> Trevion: hell no :)
09:24:02 <boegel|home> @type showsPrec
09:24:03 <lambdabot> forall a. (Show a) => Int -> a -> ShowS
09:24:14 <boegel|home> > showsPrec 3 (0.000000000000000000000000000000001)
09:24:15 <lambdabot>  add an instance declaration for (Show (String -> String))
09:24:23 <boegel|home> > showsPrec 3 "" (0.000000000000000000000000000000001)
09:24:24 <lambdabot>  add an instance declaration for (Fractional String)
09:24:39 <boegel|home> @type showFloat
09:24:40 <lambdabot> Not in scope: `showFloat'
09:24:46 <xerox> @index showFloat
09:24:46 <lambdabot> Numeric
09:24:50 <xerox> @type Numeric.showFloat
09:24:51 <lambdabot> forall a. (RealFloat a) => a -> ShowS
09:24:58 <xerox> @kind Shows
09:24:59 <boegel|home> hmm, nope, not that either
09:24:59 <lambdabot> Not in scope: type constructor or class `Shows'
09:25:00 <xerox> @kind ShowS
09:25:01 <lambdabot> *
09:25:11 <boegel|home> *? :)
09:25:16 <xerox> :-)
09:26:33 <boegel|home> any way to 'cast' a ShowS to a String or something ?
09:26:42 <Trevion> apply it to ""
09:26:43 <boegel|home> because I think showsPrec is what I want
09:26:48 <xinming1983> how can callCC `\k ->do{ blablabla... k a; return 1;' skips the rest of the calculation in Cont Monad please?
09:26:54 <boegel|home> > showsPrec 3 (0.000000000000000000000000000000001) $ ""
09:26:55 <lambdabot> "1.0e-33"
09:27:02 <boegel|home> > showsPrec 3 pi $ ""
09:27:03 <lambdabot> "3.141592653589793"
09:27:12 <Trevion> > showFFloat (Just 3) pi ""
09:27:12 <boegel|home> hmm, doesn't do what I'd expect
09:27:13 <lambdabot> "3.142"
09:27:18 <boegel|home> Trevion: ah !
09:27:28 <boegel|home> > showFFloat (Just 3) (0.000000001)
09:27:29 <lambdabot>  add an instance declaration for (Show (String -> String))
09:27:33 <boegel|home> > showFFloat (Just 3) (0.000000001) ""
09:27:34 <lambdabot> "0.000"
09:27:45 <Trevion> Also showEFloat and showGFloat, mimicking the behavior of %e and %g from the C printf.
09:27:46 <boegel|home> okay, _that's_ what I want
09:27:55 <Trevion> All in Numeric
09:28:03 <boegel|home> don't know those, what the difference ?
09:28:11 <tennin> xinming: this is a sloppy way of putting it but, each computation in the Cont monad evaluates to a function of the future of that computation.   if a computation evaluates to Cont (\_ -> x), it ignores the future and all subsequent computations are effectively skipped
09:28:18 <Trevion> http://www.haskell.org/ghc/docs/latest/html/libraries/base/Numeric.html#v%3AshowEFloat
09:28:36 <boegel|home> oh, ok
09:29:01 <boegel|home> Trevion: thanks !
09:29:43 <roconnor> @what is HWN
09:29:44 <lambdabot> I know nothing about is.
09:29:48 <roconnor> @what HWN
09:29:49 <lambdabot> http://sequence.complete.org/
09:30:30 <boegel|home> roconnor: it's the coolest thing ever, only the maintainer doesn't have time for it anymore...please help him find a replacement :)
09:30:35 <tennin> xinming: callCC f = Cont $ \c -> runCont (f (\a -> Cont $ \_ -> c a)) c
09:32:10 <xinming> tennin: yes, But can't follow the function implemention
09:32:15 <roconnor> oh gawd
09:32:21 <roconnor> I just saw the hoggle web page
09:32:26 <roconnor> for the first time
09:33:20 <tennin> xinming: the "\_ -> c a" is the key bit.  "c" here is the future as of when callCC was invoked.
09:34:51 <PupenoL> Hello.
09:36:07 <roconnor> Hi
09:41:31 <SyntaxNinja> 'morning
09:41:46 <chucky> hello everyone
09:42:27 <roconnor> I don't suppose anyone here works for the NSA.
09:42:45 * xerox bangs the head on the desk
09:44:06 <chucky> roconnor: If they are, I don't think they're allowed to tell anyone
09:44:31 <roconnor> I think they are, but that is about all they are allowed to say.
09:46:05 <roconnor> I'm trying to factor a 222 digit number.
09:46:08 <roconnor> the going is slow.
09:47:31 <tennin> xinming: when we have do {blah; callCC \k -> do {blah; k x; blah;}; blah;}, we're basically giving calculations in the inner do block access to the future of the outer do block.  "k x" will evaluate to "Cont $ \_ -> c x" where c is that outer future.  so all subsequent calculations in the inner block are ignored (since it's "\_ -> ...") but those in the outer block are still applied (as part of "c")
09:47:52 <xerox> ski: ping
09:49:30 <xerox> @seen TheHunter
09:49:31 <lambdabot> I saw TheHunter leaving #haskell-overflow, #haskell-blah and #haskell 1
09:49:31 <lambdabot> day, 14 hours, 49 minutes and 7 seconds ago, and I have missed 1 minute
09:49:31 <lambdabot> and 3 seconds since then.
09:49:31 <xinming> tennin: thanks, I think I understand a bit. by the way
09:50:00 <xinming> runCont( bla ) k,
09:50:06 <xerox> Hmm, I should try callCC.
09:50:16 <xinming> the key is passed in the bla block,
09:50:29 <xinming> why k won't be invoked?
09:50:58 <xinming> it's passed through the whole bla block, but it always leave the executing at the end.
09:50:59 <xinming> why?
09:51:36 <tennin> xerox: yes, if only to correct the likely errors in my explanation =)
09:52:00 <xerox> tennin: sorry didn't read.  I'm stuck with my continuations problems :-)
09:54:52 <tennin> k is an argument to the function in the Cont monad... it's only invoked if that function invokes it
09:59:16 <SyntaxNinja> wow. monk (cvs.haskell.org / hackage.haskell.org) had a 252-day uptime, until it needed kernel security updates.  That is its first reboot ever.
09:59:27 <SyntaxNinja> Yay debian!
10:01:27 <xerox> woot!
10:02:47 <xinming>     (Cont c) >>= f = Cont $ \k -> c (\a -> runCont (f a) k) -- i.e. c >>= f = \k -> c (\a -> f a k) 
10:03:20 <xinming> here, since runCont(f a) k have ever executed once, But why the out block executed immediately?
10:04:00 * xerox is going nuts on continuations too
10:04:07 <xerox> Dark mages, help me.
10:04:48 <xinming> for example, runCont(do{ x <- return 3; (\x -> return( x + 3) }) (\x -> show x)
10:05:21 <Oejet> Greetings all.
10:05:32 <xinming> why the show x won't be executed after runCont(f a) k?
10:05:33 <xinming> oops
10:05:56 <xinming> for example, runCont(do{ x <- return 3; y <- return( x + 3); return( x+y ) }) (\x -> show x)
10:06:19 <xerox> Howdy Oejet.
10:08:30 <tennin> isn't it executed?
10:09:13 <xinming> It's executed at last, But I don't know how it can be held so "long"
10:09:36 <xinming> hmm, I mean, If there is a function which is not return,
10:10:11 <xerox> What's wrong with this:
10:10:16 <xerox> any xs = reset (foldr (\x _ -> shift $ \k -> if x then True else k False) False xs)
10:10:40 <xerox> or this: any xs = reset (foldl (\_ x -> shift $ \k -> if x then True else k False) False xs)
10:12:53 <araujo> shift , reset?
10:12:56 <araujo> 0_0
10:14:56 <xerox> err yeah.
10:15:11 <araujo> @type shift
10:15:12 <lambdabot> Not in scope: `shift'
10:15:23 <araujo> @index shift
10:15:24 <lambdabot> Data.Bits, Foreign, Graphics.UI.GLUT.Callbacks.Window, Graphics.UI.GLUT.
10:15:24 <lambdabot> Callbacks, Graphics.UI.GLUT
10:15:26 <xs> hm, is it possible to get cabal to generate profiled packages?
10:15:36 <xerox> This doesn't wok either: any xs = reset (callCC' (\k -> foldl (const $ \x -> if x then k True else False) False xs))
10:15:39 <xerox> damn..
10:15:49 <xerox> Am I missing something?
10:16:35 <palomer> yay for callCC!
10:16:37 <tennin> xinming: well, the whole do block evaluates to Cont ($9) or Cont (\f -> f 9).  the value of the do block is totally independent of what's eventually done with it
10:16:44 <araujo> @type callCC'
10:16:45 <lambdabot> Not in scope: `callCC''
10:16:47 <araujo> @type callCC
10:16:48 <lambdabot> Not in scope: `callCC'
10:17:07 <araujo> @vixen you don't love me today?
10:17:07 <lambdabot> yes
10:17:16 <araujo> :-(
10:17:32 <xerox> palomer: can you help me?
10:22:02 <xinming> (Cont c) >>= f = Cont $ \k -> c (\a -> runCont (f a) k), here, since the inner block ever executed runCont(f a) k
10:22:43 <xinming> But why It won't run the k immediately?
10:24:45 <tennin> oh
10:25:12 <palomer> I don't know how haskell's callCC works
10:25:17 <palomer> man I'm so learning haskell this holiday season
10:25:19 <xinming> for there are many bindings, k will always be passed ..
10:25:49 <xerox> Hi TheHunter!
10:25:59 <TheHunter> hey xerox 
10:26:09 <xerox> TheHunter: I'm going nuts!
10:26:30 <TheHunter> why?
10:26:54 <xerox> any xs = reset (foldl (const $ \x -> shift $ \k -> if x then True else k False) False xs)
10:26:59 <xerox> What's wrong with this :-(
10:28:45 <xerox> This one doesn't work too:
10:29:13 <xerox> any xs = reset (callCC' (\k -> foldl (const $ \x -> if x then k True else False) False xs))
10:29:23 <xerox> Maybe I'm misinterpreting something.
10:29:29 <TheHunter> @type \f -> foldl (const f)
10:29:30 <lambdabot> forall a b. (b -> a) -> a -> [b] -> a
10:29:57 <TheHunter> your function ignores all but one element of the list
10:30:08 <xerox> Mumble.
10:30:20 <xerox> Why so?
10:30:30 <lightstep> maybe you need to seq it?
10:30:35 <TheHunter> because of the laziness of const
10:30:40 <xerox> URGH.
10:30:57 <xerox> any xs = reset (foldl (\_ x -> shift $ \k -> if x then True else k False) False xs)
10:31:07 <xerox> Not that it does work, but it helps?
10:31:29 <lightstep> @type or
10:31:30 <lambdabot> [Bool] -> Bool
10:32:04 <lightstep> xerox, i think you need to force the first parameter or something (but i never grokked continuations, even in strict languages)
10:32:18 <xerox> force, eh, mm.
10:32:42 <xerox> any xs = reset (foldl (\x y -> x `seq` shift $ \k -> if y then True else k False) False xs)  ?
10:33:00 <lightstep> that's what i meant
10:33:12 <xerox> Doesn't help, it seems.
10:33:22 <tennin> xinming: the >>='s are building a function that depends on k, they don't evaluate it
10:33:23 <lightstep> i /so/ don't like not having copy&paste
10:34:17 <xerox> TheHunter: I don't understand why does const matter in fact, but hmm..
10:36:59 <TheHunter> this works: let a xs = reset (callCC' (\k -> foldl' (const $ \x -> if x then k True else False) False xs))
10:38:07 <TheHunter> I don't understand how the shift thing is supposed to work.
10:38:15 <lightstep> oh
10:38:30 <lightstep> yes, it works this way in scheme too
10:38:39 <lightstep> it's only logical
10:38:51 <lightstep> you implemented `all'
10:39:10 <xerox> lightstep: no
10:39:17 <xerox> TheHunter: thanks.
10:39:18 <TheHunter> right, the shift one is and.
10:39:32 <xerox> hmm
10:39:39 <xerox> So I'm getting it wrongly somehow
10:39:50 <lightstep> you return to k when you find False, and continue while you find True
10:40:09 <lightstep> so you return True iff you didn't find False
10:40:28 <xerox> @index foldl'
10:40:28 <lambdabot> Data.List
10:40:44 <xerox> oooh.
10:40:56 <TheHunter> let or xs = reset (callCC' (\k -> map (\x -> if x then k True else False) xs `deepSeq` False))
10:41:53 <xerox> Isn't the shift one the only supposed to work?
10:41:58 * xerox has got something wrongly
10:42:08 <TheHunter> or rather:
10:42:10 <TheHunter> let a xs = reset (callCC' (\k -> map (\x ->  x && k True) xs `deepSeq` False))
10:42:15 <xerox> reset (1 + (callCC' $ \k -> k 1)) :: Int
10:42:20 <xerox> reset (1 + (callCC' $ \k -> 1)) :: Int
10:42:22 <xerox> both returns 2
10:42:29 <xerox> reset (1 + (shift $ \k -> k 1)) :: Int
10:42:31 <xerox> 2 again
10:42:36 <xerox> reset (1 + (shift $ \k -> 1)) :: Int
10:42:37 <roconnor> ?? How can seq change the semantics of programs?
10:42:38 <xerox> 1
10:43:06 <lightstep> roconnor, what do you mean?
10:43:15 <xerox> this is why I was trying to use shift, to goto to the 'reset' directly
10:43:21 <TuringTest> roconnor: If the first seq argument calls a continuation then it would not get the second
10:43:23 <TheHunter> roconnor, well there is unsafePerformIO involved
10:43:32 <roconnor> Oh
10:43:35 <TuringTest> Or am I on crack?
10:44:10 <syntaxfree> what are closures, and why are Lisp programmers so crazy about them?
10:44:23 <TuringTest> They come from the lexical scope
10:44:35 <roconnor> Aren't closures partially evaluated functions?
10:44:36 <lightstep> syntaxfree, a closure in programming is like a function in math
10:45:13 <lightstep> kinda
10:45:17 <TheHunter> something of type args -> IO a
10:46:24 <xerox> heh right
10:46:29 <lightstep> syntaxfree, like `lambda' in lisp and python, or `function' in javascript and ml, or `\' in haskell
10:46:34 <xerox> A partially evaluated function with mutability.
10:48:22 <TheHunter> xerox, it's more or less just coincidence that they all return the same result.
10:48:59 <xerox> TheHunter: interesting, can you show me a more interesting testcase?
10:51:04 <TheHunter> *Reflection> reset (1 + (callCC' $ \k -> k 1 + k 2)) :: Int
10:51:04 <TheHunter> 2
10:51:04 <TheHunter> *Reflection> reset (1 + (shift $ \k -> k 1 + k 2)) :: Int
10:51:04 <TheHunter> 5
10:51:29 <xinming> hmm, tennin, sorry, I still don't understand. eg: runCont( return 1 >>= \x -> return(x +1)) show
10:51:39 <Speck> I should learn what continuations are :-|
10:52:17 <xinming> tennin: since the >>= has runCont(f a) k, the k here is show which is passed in >>=
10:52:27 <xinming> why It won't be executed? :-/
10:53:40 <xerox> Speck: that's the continuation :-)
10:54:54 <tennin> because it doesn't really have runCont(f a) k, it has  \k -> c (\a -> runCont (f a) k)
10:55:35 <xinming> tennin: yes, then, the k is the function show, right?
10:55:40 <tennin> it evaluates to a function, it doesn't evaluate that function.
10:55:41 <xinming> in that example
10:55:42 <tennin> yes.
10:55:51 <tennin> eventually, it does get bound to show.
10:56:48 <xinming> that's what makes confuse. :-/
10:57:01 <syntaxfree> http://okmij.org/ftp/Computation/Continuations.html#zipper-fs
10:57:10 <xerox> cool one
10:59:28 <xinming> return 1 >>= \x -> return (x+1) >>= \y -> return( x+y ), if the >>= contains runCont(f a) k, here, k = show, the result should be "1" "2", and returns "3",
10:59:32 <xinming> that's what I think.
11:01:30 <tennin> > (\g -> \x -> \f -> g (x+3) f) (\x -> \f -> f (x+3)) 0 show
11:01:31 <lambdabot> "6"
11:01:41 <tennin> this is analogous
11:02:44 <tennin> the "f" above does ultimately get bound to show
11:03:44 <tennin> however, everything preceding "show" is an expression that evaluates to a function.
11:04:34 <tennin> er, everything preceding "show" is, collectively, one expression which evaluates to a function.
11:05:07 * xinming can understand the analogous version. But still in confusiong. :-P
11:05:10 <xinming> thanks anyway. :-/
11:05:54 <tennin> I'm not very good at explaining these things =/
11:06:25 <xinming> :-)
11:06:38 <xinming> I'll ask ski whlile he has time
11:10:10 <basti_> Speck: i know what continuations are, but i do not feel a strong urge to try coding like that.
11:10:49 <tennin> but the point is that "(\g -> \x -> \f -> g (x+3) f) (\x -> \f -> (f (x+3)) 0" evaluates to a single function, and "show" is used as the argument to that function.  it's not the argument to the individual parts of that expression.
11:11:11 <basti_> f-ck i need a safeguard against accidentally clicking the x in x11/irssi
11:11:37 <tennin> similarly, runCont( return 1 >>= \x -> return(x +1)) evaluates to a single function
11:13:27 <tennin> namely, \k -> k 2.
11:17:00 <tennin> or look at it step by step
11:17:06 <tennin> return 1
11:17:17 <xinming> ok
11:17:33 <tennin> = Cont (\k -> k 1)
11:17:43 <xinming> yes
11:18:33 <tennin> return 1 >>= \x -> return (x+1) = (Cont (\k -> k 1)) >>= \x -> return (x+1) = Cont (\k -> k 2)
11:19:41 <xinming> ...
11:20:07 <xinming> isn't it too fast?
11:20:33 <tennin> =(
11:20:42 <tennin> sorry
11:21:09 <xinming> It's ok, at least, you tell me that in callCC, the k is outer. :-)
11:22:21 <syntaxfree> What is wrong with n+k patterns?
11:23:03 <Philippa> the integers aren't defined that way, so it's a nasty piece of one-off syntactic sugar
11:23:11 <monochrom> I guess n+k patterns are a bit too special.
11:23:12 <basti_> n+k = 5 defines neither n nor k
11:24:28 <Igloo> k isn't a variable in the syntax
11:24:40 <Igloo> You have to write n+3 = 5, say
11:24:48 <basti_> ah.
11:25:15 <basti_> then you might have ambigous constructions.
11:25:19 <Igloo> Philippa: Why is it nasty?
11:25:24 <Heffalump> more charitably, it's a one-off implementation of a specific view.
11:25:31 <basti_> whats with f (n+3) = f n ; f 0 = 10
11:25:45 <Igloo> do notation and sections are also one-off pieces of syntactic sugar
11:25:57 <TuringTest> @djinn a->a
11:25:58 <lambdabot> f a = a
11:26:02 <basti_> what happens with f 2?
11:26:14 <SamB> Igloo: na uh!
11:26:14 <Heffalump> list comprehensions are more one-off than do notation
11:26:16 <Heffalump> basti_: it doesn't match
11:26:26 <TuringTest> @djinn (((a -> b) -> b) -> c -> d) -> c -> a -> d
11:26:26 <lambdabot> f a b c = a (\ d -> d c) b
11:26:35 <basti_> would f 5 match?
11:26:39 <Heffalump> yes
11:26:43 <basti_> with what?
11:26:47 <SamB> Igloo: not with the Monad typeclass...
11:26:51 <basti_> f 2?
11:26:51 <basti_> ^^
11:27:01 <SamB> and the ability to section whatever function you please...
11:27:06 <Heffalump> > (\n -> case n of { (n+3) -> "n+3 matched" ; 0 -> "0 matched" ; _ -> "nothing matched }) 2
11:27:06 <lambdabot>  lexical error in string/character literal
11:27:09 <syntaxfree> do notation hides away too much of the actual Haskell.
11:27:10 <Heffalump> > (\n -> case n of { (n+3) -> "n+3 matched" ; 0 -> "0 matched" ; _ -> "nothing matched@ }) 2
11:27:11 <lambdabot>  lexical error in string/character literal
11:27:15 <Heffalump> > (\n -> case n of { (n+3) -> "n+3 matched" ; 0 -> "0 matched" ; _ -> "nothing matched" }) 2
11:27:16 <lambdabot>   Warning: Pattern match(es) are overlapped
11:27:16 <lambdabot>      In a case alternative:
11:27:16 <lambdabot>       0 -> ...
11:27:18 <Igloo> SamB: n+k patterns have the Num typeclass (or whichever it is)
11:27:27 <Heffalump> hmph, how unhelpful
11:27:31 <Heffalump> and they're not overlapped.
11:27:40 <SamB> Igloo: well...
11:27:46 <SamB> so?
11:27:55 <basti_> basically it's a mess you want to say.
11:27:59 <Igloo> ghc has had bugs in reporting overlaps and n+k patterns
11:28:14 <basti_> so why don't you write f (n-3) in the recursion instead and keep to standard syntax? ^^
11:28:29 <basti_> i think pattern matching should be restricted to constructors.
11:28:36 <Heffalump> less convenient
11:28:36 <Igloo> SamB: I was just disagreeing with what Philippa said...
11:28:54 <Trevion> basti_, I believe the original idea was to parallel mathematical notation.  I agree that n+k constructors are not worth it, though.
11:29:18 <Igloo> basti_: You might want (n-3) multiple times, and n+k patterns give you a more direct transformation of formal/mathematical descriptions
11:29:45 <Philippa> really it's the one-offness that's nasty IMO
11:29:56 <Philippa> although once you fix that you might conclude the result's nasty too
11:30:15 <SamB> Philippa: you mean with views?
11:30:16 <Trevion> Views don't seem nasty to me, and generalize the one-offness.
11:30:19 <Philippa> in particular, I've not seen a view proposal that'd fix it?
11:30:23 <Igloo> Philippa: What about do notation, list comprehensions and sections then?
11:30:41 <SamB> Igloo: how are they one-off?
11:30:44 <Philippa> sections are no nastier than having infix operators at all
11:30:57 <Philippa> I'm tempted to agree with you wrt list comprehensions in favour of just using do notation
11:31:12 <Philippa> n+k patterns don't sugar something as fundamental to writing haskell programs
11:31:23 <Igloo> Philippa: do notation is also just one-off sugar for >>= etc
11:31:24 <Saulzar> Unless there were also general monad comprehensions?
11:31:31 <SamB> you can use do notation with any monad and and any actions in that monad that you like...
11:31:31 <Trevion> I think list comprehensions can be much more intuitive for some cases; I'd personally like to see them go back to monad comprehensions though.
11:31:38 <Igloo> Just like n+K is sugar for guards, -, etc
11:31:41 <Philippa> Igloo: "where's the base case?"
11:31:54 <Philippa> I think it's fair to say do notation is far more generally applicable than n+k patterns
11:31:55 <Igloo> Philippa: eh?
11:31:55 <Heffalump> SamB: do are general monad comprehensions
11:32:07 <SamB> and you can use sections on any named function (of the appropriate type)
11:32:20 <SamB> Heffalump: where are the filtering clauses?
11:32:24 <Igloo> Incidentally, I'm not advocating getting rid of more stuff, but saying we should keep n+k patterns
11:32:56 <SamB> Igloo: why?
11:32:58 <Philippa> I think the #1 reason for keeping them's backwards compatability, and were that not an issue I would have no problem with their disappearance
11:33:02 <Igloo> Because I find them useful
11:33:06 <SamB> they are more trouble then they are worth
11:33:16 <Heffalump> samb: guard
11:33:18 <Heffalump> @type guard
11:33:23 <lambdabot> Not in scope: `guard'
11:33:26 <Heffalump> @type Control.Monad.guard
11:33:27 <lambdabot> forall (m :: * -> *). (Control.Monad.MonadPlus m) => Bool -> m ()
11:33:42 <basti_> we're down to opinions? i think they're close to stupid, judging from haskell's general cleanliness
11:33:53 <Heffalump> I don't really like them either.
11:34:05 <SamB> just look at the ugly code they generate!
11:34:07 <Heffalump> I think they'd be more reasonable if they were just for a datatype of natural numbers.
11:34:15 <Heffalump> So if we had unsigned Int and Integer
11:35:01 <musasabi> of course if n+K is taken out some new toys would be nice.
11:35:01 <musasabi> monad comprehensions etc
11:35:23 <Trevion> Views?  I really wish I weren't the only one on that hobby horse.
11:35:24 <Philippa> monad comprehensions're only worth it if they can get good error messages IMO
11:35:34 <Heffalump> in what way is do not a monad comprehension?
11:35:34 <SamB> Views might be nice ;-)
11:35:36 <Philippa> Trevion: I'm not on it, but only because I know a good way to fake 'em
11:35:45 <Heffalump> Philippa: which is?
11:35:48 <musasabi> Heffalump: syntax
11:35:51 <Trevion> Pattern guards?
11:35:59 <Philippa> a toView function, then pattern-match on the resulting type
11:36:24 <musasabi> but a good record system would be the best precent
11:36:24 <SamB> Philippa: that only works if the views are non-overlapping...
11:36:28 <Philippa> if a views facility allows the use of different views in different patterns within one analysis, I might go with that. Or run screaming. I'm not sure which.
11:36:31 <Heffalump> that's pretty ugly
11:36:45 <basti_> i think functions should be defined on ADT's.
11:36:54 <SamB> ???
11:36:57 <Heffalump> you at least need pattern guards to make it work ok
11:37:00 <Philippa> it's not that ugly given that you'd need to annotate which view you're using and provide something much like a type anyway
11:37:00 <basti_> or by matching certain cases of non-ADT's
11:37:14 <basti_> n+3 is not a case. The case you mean is "n"
11:37:31 <Trevion> Philippa, that seems more like a work-around.
11:37:41 <monochrom> everyone should program telepathically and not bother with syntax  *duck* :)
11:37:57 <Philippa> Trevion: it's less fundamentally so than you might think. What do your propose that views offer beyond sugaring the same process?
11:37:59 <SamB> hmm. that could take a while...
11:37:59 <Trevion> Wadler's law of language design, I believe?
11:38:30 <Trevion> I like that sugar, though.  You can work around not having do notation by always putting your >>= operators in the 100th column.
11:38:39 <Heffalump> Philippa: but you need two levels of function, or a case statement, to use pattern matching
11:39:33 <TheHunter> Hi Lemmih, does ghc-src fix the fixities or do you know about code that does that for Language.Haskell.Syntax?
11:39:45 <Philippa> Heffalump: true. I dunno if this makes sense, but I'd rather a more general solution than views to that
11:40:41 <Heffalump> it's less ugly with pattern guards
11:40:45 <Philippa> I'm also not entirely sure the two-level solution's so bad - especially if you're using views on two or more parameters you match
11:41:11 <Philippa> Trevion: the sugar's not even that much sweeter but for the issue Heffalump mentioned
11:41:48 <Philippa> part of me likes the idea of having a 'canonical pattern' for documentation purposes anyway
11:41:49 <Heffalump> it's meaningless boilerplate
11:42:00 <Trevion> Philippa: what about pattern matching on, say, [1,2,_]?
11:42:11 <basti_> Trevion: thats constructors.
11:42:11 <Heffalump> you can teach monkeys to write meaningless boilerplate, but it's still a waste
11:42:15 <basti_> (and values)
11:42:21 <Philippa> Trevion: 1:2:_:[]
11:42:24 <Trevion> Cons x xs <- x, Cons y ys <- xs, ...
11:42:39 <Trevion> (oops, used x twice)
11:42:53 <Lemmih> TheHunter: ghc-src doesn't and I haven't seen code that does that for L.H.S.
11:42:58 <SamB> Trevion: huh?
11:43:14 <Philippa> Heffalump: it's at least well-scaling boilerplate. We've got a lot of that in Haskell anyway
11:43:21 <Trevion> Sorry - was attempting to suggest that nested use of a toView function is even more obnoxious.
11:43:35 <Philippa> deepView :-)
11:43:35 <TheHunter> Lemmih, thanks. Maybe I'll write it myself then.
11:43:55 <Trevion> MORE boilerplate!  I suggest scrapping it all.
11:43:56 <Philippa> which is what I'd expect a toView func to do anyway
11:44:10 <Philippa> Trevion: the toView function has to exist anyway
11:44:11 <Philippa> think about it
11:44:13 <jlouis> gmap!
11:44:21 <jlouis> (oy by the way)
11:44:26 <Philippa> 'lo
11:44:44 <Heffalump> Philippa: how does deepView figure out the right thing to with nested instances of the type?
11:44:50 <Trevion> Sure, but the calls can be inserted automatically.  >>= has to exist for do notation to work, but that doesn't make do notation not worth it.
11:45:15 <Philippa> Heffalump: when in doubt, use the same view again
11:45:18 <Trevion> Anyway, doesn't SamB's point about overlapping views torpedo the whole toView work-around?
11:45:37 <Heffalump> now you're descending into the realms of ad-hoccery.
11:45:54 <Heffalump> Trevion: not if you use a clever MPTC or something.
11:46:00 <Philippa> how does any other view determine which view to use for child nodes?
11:46:09 <Heffalump> in fact that might solve the deepView problem too
11:46:24 <Philippa> really, I'm not taking the piss here. There's a toView function /somewhere/
11:46:25 <Heffalump> Philippa: yeah, ok. See my MPTC answer ;-)
11:46:41 <Philippa> MPTC?
11:47:43 <Heffalump> multi-parameter type classes
11:47:47 <Philippa> ah
11:47:49 <Trevion> Heffalump, I don't see the MPTC.  Doesn't only the result type vary?
11:48:23 <Heffalump> only if you just want views of one type
11:48:52 <Trevion> But if there are multiple views of the same type, doesn't that require toView functions with only the result type varying?
11:49:30 <Philippa> yes. That's legit
11:49:40 <Philippa> we know the result type, it's the one being matched against
11:50:01 <Trevion> ah..
12:06:53 <C-Keen> re.
12:28:21 <astrolabe_> Is there any way to make parsec carry on parsing after a parsing error?
12:28:51 <neologism> astrolabe_: what sense does that make?
12:28:52 <SamB> astrolabe_: try?
12:29:08 <neologism> how the parser can know what its parsing
12:29:16 <neologism> thre are some recovery methods I think but...
12:29:29 <Philippa> astrolabe_: <|> skipCrap
12:29:30 <SamB> you could try one of those error-correcting combinator libraries...
12:29:47 <astrolabe_> I want parsec to output a list of things it has parsed, if there is an error, I only want it to affect one element of the list.
12:29:54 <Philippa> for appropriate values of skipCrap
12:30:18 <astrolabe_> But I want to keep the error message.
12:30:20 <Philippa> sounds like you need a monad transformer on top of it that applies a try-like function that provides appropriate skipping 'til it's done with an element
12:30:21 <SamB> Philippa: that only works if the left branch of the <|> didn't consume input, doesn't it?
12:30:34 <Cale> astrolabe_: you probably want to run a parser multiple times then
12:30:37 <Philippa> SamB: or if skipCrap doesn't need the initial input, yeah
12:30:50 <Philippa> the right branch'll run, it just might not run in the right place
12:30:57 <Philippa> oh, wait. Yes, you'd need try
12:31:06 <Cale> astrolabe_: you'll need some way to break up your input beforehand
12:31:07 <Philippa> still no biggie though
12:31:37 <astrolabe_> Cale: that was what I was thinking, but then I'd need to grab the unparsed data, which is ugly
12:31:38 <Speck> like tokenizing?
12:31:54 <Philippa> hrmm. Not entirely certain, I suspect you can still fuse in tokenising or similar - but you /would/ need a pervasive error handling strategy
12:33:44 <astrolabe_> Maybe I could parse in two stages, like tokenising, but the next stage will parse inside the tokens instead of outside.
12:34:06 <SamB> astrolabe_: why are there errors?
12:35:05 <astrolabe_> If someone enters a bad line for some reason, I'd like to be informative about what is bad with it.
12:35:17 <joelr1> good evening!
12:35:57 <astrolabe_> Evening.  I thought you were in the states.
12:36:12 <joelr1> who me?
12:36:18 <astrolabe_> yeah
12:36:23 <joelr1> @google haskell users
12:36:25 <lambdabot> http://www.cs.chalmers.se/~rjmh/Wash/Survey/Survey.cgi
12:36:32 <joelr1> hmm... not that
12:36:35 <joelr1> one sec
12:37:14 <astrolabe_> @where where
12:37:15 <lambdabot> I know nothing about where.
12:37:21 <astrolabe_> :(
12:37:44 <joelr1> astrolabe_: http://haskell.org/hawiki/HaskellUserLocations
12:37:47 <astrolabe_> @where map
12:37:48 <lambdabot> I know nothing about map.
12:37:55 <joelr1> check near the north-western tip of africa :D
12:38:21 * monochrom teaches lambdabot all about map.  A functor is ...
12:38:44 <astrolabe_> @where+ where http://haskell.org/hawiki/HaskellUserLocations
12:38:44 <lambdabot> Done.
12:38:47 * joelr1 is in tenerife, canary islands
12:39:01 <astrolabe_> Wow.  That sounds nice
12:39:05 <joelr1> :D
12:39:26 <joelr1> just very rainy today, happens once in a long while but when it rains it pours!
12:43:45 <syntaxfree> what the hell is "baidu"?
12:43:52 <astrolabe_> Thanks for the ideas everyone
12:44:15 * TheHunter converts Error-monadic-code into "pure" code, exceptions and unsafePerformIO.
12:44:23 <syntaxfree> it's one of the top winners in Google Zeitgeist 2005.
12:44:24 <joelr1> musasabi: ping
12:44:31 <syntaxfree> @seen palomer
12:44:32 <lambdabot> palomer is in #haskell-blah and #haskell. Last spoke 2 hours, 3 minutes
12:44:32 <lambdabot> and 36 seconds ago.
12:44:43 <joelr1> syntaxfree: what's that?
12:44:49 <Philippa> TheHunter: um. Ick? Why not at least build an Error-like monad that uses exceptions?
12:44:55 <syntaxfree> I don't know!
12:45:10 <TheHunter> Philippa, using monads for exception-handling sucks.
12:45:25 <TheHunter> it's just so much unnecessary work.
12:45:26 <astrolabe_> TheHunter: why?
12:45:46 <Philippa> I don't see it as unnecessary, but then I like the possibility of exceptions to be a known thing at the type level
12:45:46 <astrolabe_> oh
12:45:54 <TheHunter> because monadic code takes about twice as much time to write as pure code.
12:46:15 <TheHunter> and five times as much to modify
12:46:23 <Philippa> I find that varies somewhat, not least on how much can be done "just" outside the monad
12:47:20 <TheHunter> these were completely arbitrary numbers of cource, but you get the point.
12:47:36 <TheHunter> purity is overrated.
12:48:25 <TheHunter> in case of the error monad, I just don't care which error is returned, the important thing is whether the computation succeeds or fails, and that is relatively independent of evaluation order.
12:48:31 <astrolabe_> Seems a bit weird to code in haskell, and then subvert the purity.
12:49:14 <palomer> eh
12:49:23 <Saulzar> TheHunter, Hmm, isn't Maybe well suited there?
12:49:41 <palomer> I'm going through a mid life crisis
12:49:42 <palomer> and I'm 22
12:49:43 <palomer> wtf
12:49:51 <TheHunter> Saulzar, of course I want an error message to be returned, I just don't care which.
12:50:00 <Saulzar> I see..
12:50:31 <syntaxfree> palomer: #lambdarockers is a better place to discuss that! ;-)
12:50:31 <TheHunter> besides, we are still lacking syntactic sugar for commutative monads, so that wouldn't help anyway.
12:50:50 <palomer> oh, wrong channel
12:52:42 <Heffalump> gah. I saw something recently that I thought might make good syntactic sugar for those, but I forgot what it was.
12:54:13 <syntaxfree> have you read "Purely functional data structures"?
12:54:29 <Heffalump> no
12:54:51 <TheHunter> me neither
12:55:31 <SamB> I wants it
12:55:52 <SamB> my christmas present
12:56:05 <syntaxfree> @google Purely functional data structures filetype:pdf
12:56:06 <lambdabot> http://www-2.cs.cmu.edu/~rwh/theses/okasaki.pdf
12:56:37 <SamB> I meant the book
12:56:43 <palomer> time to learn about haskell IO
12:56:56 <palomer> what's the best tutorial about haskell IO?
12:57:01 <syntaxfree> hmm. the book and the thesis have the same title?
12:57:05 <Cale> odd, apparently xchat likes to close when I'm not at the computer
12:57:25 <Cale> palomer: do you already understand monads?
12:57:33 <palomer> Cale: no
12:57:50 <SamB> hmm
12:57:56 <Cale> Then start with a monad tutorial -- perhaps mine, and then All About Monads
12:57:57 * SamB is suspicious of palomer 
12:58:04 <palomer> SamB: eh?
12:58:20 <SamB> maybe I'm getting you mixed up with someone else, though...
12:58:22 <joelr1> how do you create a StorableArray?
12:58:24 <palomer> Cale: where's your tutorial?
12:58:24 <Cale> http://www.haskell.org/hawiki/MonadsAsContainers
12:58:28 <Cale> there :)
12:58:29 <syntaxfree> palomer: htut!
12:58:48 <palomer> SamB: I'm the guy who can tell you about every other programming language but haskell
12:58:52 <SamB> sometimes oldbies start acting like newbies for no apparant reason...
12:58:52 <palomer> htut?
12:58:53 <Cale> I think it's best to understand monads in the non-IO sense first :)
12:59:02 <SamB> Parsec!
12:59:41 <astrolabe_> I think it's best to understand IO in the non-monad sense first :)
12:59:46 * Heffalump thinks you might as well start with IO or state monads as anywhere else.
12:59:54 <Philippa> palomer: what's the easiest way to simulate monads in fortran 77?
13:00:07 <Philippa> avoiding IO is worthwhile IMO
13:00:18 <Philippa> it stops people thinking all monads're quite so black-box
13:00:48 <SamB> but lots of em are
13:00:54 <Heffalump> state is a good starting point
13:00:57 <Philippa> not really
13:00:58 <Cale> One of the nice things is that they can be black box when you want them to be, but anything which is completely black box is useless.
13:01:00 <SamB> and some of those that aren't don't advertise this fact
13:01:02 <palomer> Philippa: ok, haskell and fortran
13:01:10 <Philippa> every other monad has *something* you can do with it other than use it as main
13:01:13 * Heffalump actively disagrees with using the MonadsAsContainers approach as an introduction
13:01:13 <palomer> >:O)
13:01:14 <SamB> I mean, whats the difference between StateT and a black box?
13:01:20 <Philippa> (or unsafePerformIO, but YKWIM)
13:01:26 <ihope> Is there any way to access an IO value without using >> or >>=?
13:01:29 <SamB> the data constructor is exported, is the only thing...
13:01:40 <Philippa> the other "black box" monads tend to have a run function
13:01:42 <SamB> ihope: sure
13:01:45 <SamB> bind it to main
13:01:48 <Philippa> runStateT
13:01:52 <Philippa> that's the difference
13:01:55 <Philippa> you can *use* it
13:02:07 <ihope> SamB: then what?
13:02:22 <ihope> main returns an IO value.
13:02:27 <SamB> ihope: then compile your program and run it
13:02:43 <Heffalump> SamB: is that a first class citizen?
13:02:47 <ihope> ...
13:02:51 <ihope> How about at runtime?
13:03:02 <Heffalump> ihope: hs-plugins ;-)
13:03:17 <SamB> ihope: you definately need to use >>= for doing stuff with IO at runtime...
13:03:32 <palomer> Cale: bind is fmap in your tutorial?
13:03:43 <Cale> palomer: no, fmap is fmap :)
13:03:57 <Cale> palomer: or liftM, that's the same thing
13:04:10 <SamB> hmm.
13:04:21 <SamB> how to unchoke peers...
13:04:37 <palomer> so what's List's bind?
13:04:46 <palomer> oh, nevermind
13:04:47 <palomer> it's concat
13:04:51 <Cale> xs >>= f = concatMap f xs
13:04:52 <SamB> mapConcat, iirc
13:05:04 <Heffalump> no, concatMap
13:05:09 <ihope> > concatMap
13:05:09 <Cale> > [1,2,3] >>= \x -> [x,x+10]
13:05:09 <lambdabot>  add an instance declaration for (Show ((a -> [b]) -> [a] -> [b]))
13:05:10 <lambdabot> [1,11,2,12,3,13]
13:05:14 <Heffalump> well, flip concatMap
13:05:16 <SamB> only I always get the name backwards...
13:05:30 <lispy> i find myself using >>= inplace of concatMap to save keystrokes :)
13:06:14 <Philippa> ihope: main doesn't return an IO value. Rather, main *is* an IO computation
13:06:18 <Saulzar> Heh, lambdabot always loves turning concatMap into =<<, just to look cooler :)
13:06:36 <Cale> lispy: me too, though it actually lends a slightly different feel to the code
13:06:42 <joelr1> musasabi: ping
13:06:57 <Cale> When I use >>=, it sort of hints at the use of nondeterminism
13:08:09 <joelr1> does anyone know how to use musasabi's SerTH?
13:08:42 <lispy> not i
13:08:59 <Philippa> ask musasabi?
13:09:00 <joelr1> it's probably an excellent library but i just can't understand it :(
13:09:11 <joelr1> @seen musasabi 
13:09:11 <lambdabot> musasabi is in #haskell-overflow, #flippi, #haskell-blah and #haskell.
13:09:11 <lambdabot> Last spoke 1 hour, 32 minutes and 47 seconds ago.
13:09:31 <joelr1> the pickler combinators are killing me :(
13:09:38 <joelr1> @google pickler combinators
13:09:38 <musasabi> evening
13:09:38 <lispy> Philippa: how goes the haskell?
13:09:40 <lambdabot> http://research.microsoft.com/~akenn/fun/picklercombinators.pdf
13:09:41 <joelr1> ah!
13:10:12 <Cale> I wish Haskell had a good way to autoserialise/deserialise thunks of arbitrary type
13:10:17 <joelr1> musasabi: it's the pickler combinators :( i dumped my packets into a file and i launch 1k threads at it to read and deserialize. well, lo and behold
13:10:19 <Philippa> lispy: slowly, but that's just life as normal for me
13:10:33 <Philippa> Cale: the problem with that is it won't be portable
13:10:45 <Philippa> you could build a haskell implementation that had one though
13:10:51 <joelr1> musasabi: if these threads log to screen through a lock then everything is fine and my unpickling times are within 1s for the larger data structures
13:10:53 <Cale> Philippa: well, GHCi uses some form of portable bytecode already, iirc
13:10:59 <Cale> yeah
13:11:10 <Cale> perhaps not between Haskell implementations
13:11:18 <joelr1> musasabi: now if i let them run free (no lock, fail when time exceeded) then i get 4-10s (and more?) on all the larger structures :(
13:11:19 <lispy> or even ghc versions
13:11:32 <ihope> Say, I'd like it if Haskell programs automatically "map"ped them selves.
13:11:53 <ihope> Erm, functions, I mean.
13:12:18 <lispy> Cale: i bet if you start down the code serialization road you will want a way to verify code, ala jvm
13:12:18 <joelr1> musasabi: i would love to use your library but i can't figure out how to apply it to what i'm doing, including the wire representation that's different from the haskell representation
13:12:21 <Philippa> overloading function application is a really bad idea. The sanitised version's something like monads
13:12:24 <Cale> ihope: automatic lifting of that sort has problems
13:13:04 <Cale> ihope: have you looked at the list monad?
13:13:09 <ihope> Cale: yes.
13:13:16 <musasabi> joelr1: both binser and serth deserialize a ~3mb in 0.5-1 sec
13:13:22 <ihope> What if fmap had some special syntax?
13:13:40 <Cale> ihope: that would be fine :)
13:13:46 <joelr1> musasabi: that's great to hear. how can i use them? remember the stuff i showed you earlier?
13:13:48 <lispy> how special?
13:13:53 <Cale> I'd rather rename it to 'map', for one
13:13:54 * ihope goes off to implement
13:14:10 <Cale> The trouble is that we're running out of brackets
13:14:10 <lispy> Cale: yes, i'm with you on that one
13:14:14 <ihope> (then get scared off by GHC's source code)
13:14:27 <ihope> We can invent new brackets!
13:14:43 <ihope> <(Foo)bar>?
13:14:46 * Cale wishes that GHC's lexer was more Unicodey
13:15:01 <lispy> unicode++
13:15:03 <TheHunter> astrolabe_, the great thing about haskell is not purity, it's type safety.
13:15:32 <ihope> The great thing about Unlambda is the lack of both!
13:15:33 <Cale> TheHunter: well, there are lots of great things about Haskell :)
13:15:35 <musasabi> joelr1: well either you can scavenge code from SerTH (just not use the auto-deriving stuff) or use binser which has the explicit stuff.
13:15:45 <lispy> i thought laziness (a result of purity) was pretty high on the list of great things\
13:15:58 <Cale> laziness is a result of laziness :)
13:15:59 <musasabi> (in principle you could also just make a ~10 line change to SerTH to generate the wireformat you want automatically)
13:16:00 <lispy> (not a direct result i know...but enabled by)
13:16:04 <Cale> yeah
13:16:07 <ihope> @arr
13:16:08 <lambdabot> Well me hearties, let's see what crawled out of the bung hole...
13:16:19 <ihope> @elite it
13:16:19 <lambdabot> iT
13:16:20 <Cale> lispy: I'm in the midst of writing an article on that now :)
13:16:29 * ihope knew that wouldn't work
13:16:30 <lispy> Cale: tmr?
13:16:31 <joelr1> musasabi: can you lend a hand? i don't even know where to start. i would prefer the 10 line change to serth of course
13:16:49 <palomer> is it possible to send directly to ghci from emacs?
13:16:55 <Cale> lispy: yeah
13:18:40 <Cale> palomer: hmm, I seem to recall there was some ghci inside emacs mode, but I've never used it.
13:18:58 <musasabi> joelr1: is there a 1:1 correspondance between your structures and wireformat? (and how are Strings/lists handled) ?
13:19:19 <joelr1> musasabi: do you still have the code from earlier today?
13:19:29 <palomer> actually, it would be kind of silly to use ghci inside of emcas
13:19:29 <Cale> I always just keep ghci running separately and type :r whenever I save my file
13:19:34 <joelr1> can you take a look at Bits.txt with me?
13:20:29 <musasabi> joelr1: yes, I looked at it and then became distracted by workstuff, I could take an another look in 15min if that is fine with you
13:20:54 <joelr1> musasabi: i'll be here waiting. that code has examples of pretty much everything that i use
13:21:19 <joelr1> but lists are stored prefixed by length, in a given format
13:21:27 <palomer> Cale: do you have the answers to the questions on your tutorial?
13:21:27 <palomer> (like the tree monad instance)
13:21:31 <joelr1> i.e. length of numerical type X followed by list of type Y
13:22:00 <lispy> well, i should get back to work
13:22:01 <lispy> ttyl!
13:23:01 <musasabi> joelr1: is that list encoding constant or does it vary by the list?
13:23:34 <joelr1> musasabi: well, i have lists where length is endian 32bits or lists where the length is endian 16bits
13:23:41 <musasabi> ok
13:23:48 <joelr1> musasabi: and of course the list items themselves are different
13:24:39 <joelr1> i also have enumerated types that convert to a numerical type Y (endian 16, 32, byte)
13:25:18 <musasabi> fromEnum/toEnum + the type to convert to?
13:25:27 <joelr1> musasabi: the kicker is unicode strings since each character needs to be reversed and they end with 00
13:25:46 <joelr1>               (\f -> sequ tiGameType (enum endian16 :: PU GameType)
13:25:49 <joelr1> something like this
13:26:05 <joelr1> bool :: PU Bool 
13:26:05 <joelr1> bool = wrap (toenum, fromenum) byte
13:26:10 <joelr1> enum :: (Integral a, Bits a, Enum b) => PU a -> PU b
13:26:10 <joelr1> enum pa = wrap (toenum, fromenum) pa
13:26:21 <joelr1> toenum :: forall a b.(Enum a, Integral b) => b -> a
13:26:21 <joelr1> toenum = toEnum . fromIntegral
13:26:24 <joelr1> etc
13:26:32 <joelr1> it's in Pickle.hs
13:26:44 <araujo> Anyone uses Buddha here?
13:26:56 <palomer> hrm
13:26:59 * palomer wonders if there's a generalised tree datatype
13:27:08 <snk_kid_uncurry> Buddha?
13:27:58 <snk_kid_uncurry> palomer: generalised tree? you mean an n-ary tree?
13:28:54 <palomer> no
13:28:55 <palomer> I mean this:
13:29:18 <palomer> http://www.rafb.net/paste/results/BNQi6g37.html
13:30:23 <araujo> snk_kid_uncurry, yes
13:30:27 <musasabi> joelr1: so they are not length prefixed?
13:30:50 <musasabi> joelr1: I am no expert on unicode, but perhaps parsing them in reverse would be more efficient?
13:30:54 <joelr1> musasabi: who? lists always are. unicode strings, unfortunately are not
13:31:14 <joelr1> musasabi: you can't parse them in reverse i think. you need to search for end of string which is a 16-bit 0
13:31:55 <joelr1> and reverse each character if endian is specified
13:32:28 <Saulzar> palomer, If it has branches of type Tree a and Tree b .. then the whole type can't be parameterised by just 'a' (since there is also 'b')
13:32:53 <palomer> Saulzar: eh?
13:33:40 <Speck> it is certainly more general
13:34:03 <Saulzar> Sorry, i'm wrong .. 
13:34:10 <snk_kid_uncurry> bah, is that even legitimate haskell code?
13:34:27 <musasabi> joelr1: ok
13:34:35 <Saulzar> But by the time you combine branches of a and b several times the type is going to be very unwieldy
13:36:01 <Saulzar> Tree (Tree (Tree (Int, Int), Int), Int)  to represent  2 -> 2 -> (2, 2) right?
13:36:23 <palomer> Saulzar: what's interesting is that (Leaf (1,1)) is going to have the same type as Branch (Leaf 1) (Leaf 1)
13:36:31 <joelr1> musasabi: what do you think?
13:36:33 <araujo> data Tree a  = Leaf a | Node (Tree a) (Tree a) 
13:36:47 <palomer> araujo: that's the non GADTified version
13:36:50 <araujo> Or dunno, something like that.... im tired
13:37:20 <palomer> damnit, I can't get main to work
13:37:22 * palomer kicks haskell
13:37:24 <palomer> someone give me a silly main
13:37:28 <araujo> And.. i bet you want things harder and get the GADTified one?
13:37:43 <palomer> araujo: oh no, the GADTified one will be way more powerful
13:37:49 <palomer> araujo: it lets you have arbitrary trees
13:37:51 <araujo> hah *joing*
13:37:54 <astrolabe_> main = print 1
13:37:56 <araujo> joking*
13:37:57 <palomer> something you didn't have before
13:38:01 <boegel_> palomer: main = putStr "Hello"
13:38:27 <palomer> kthx
13:38:50 <araujo> palomer, And how is that GADTified one?
13:39:08 <Saulzar> palomer, Don't see how you can use them effectively though, since your base tree type is parameterised by all the branches
13:39:43 <palomer> well, you'd have to put conditions on the types that can be passed
13:39:46 <palomer> how can this be done?
13:40:08 <palomer> like, how can I say that the tree can only contain things which are showable?
13:40:45 <Cale> existential types?
13:40:46 <Saulzar> Existentials can do that, but then you can't do anything except show them :)
13:41:10 <palomer> http://www.rafb.net/paste/results/IDCDEJ61.html
13:41:19 <Cale> well, you could create your own class if you need more operations
13:41:26 <Saulzar> and you could probably do that with your standard 1-type tree 
13:41:33 <palomer> can I do something like (Show a | Monad a) ?
13:41:43 <palomer> Saulzar: no way!
13:41:52 <Saulzar> Sure...
13:41:52 <palomer> and (Show a & Monad a)?
13:41:57 <Saulzar> Show a, Monad a => ? 
13:42:07 <palomer> that's the | or the &?
13:42:09 <Cale> But that's a kind error for sure
13:42:14 <Cale> and
13:42:20 <palomer> what's or?
13:42:26 <Cale> there is none
13:42:36 <palomer> that sucks
13:42:39 <palomer> it would be useful for GADTs
13:43:04 <Cale> Well, actually, I think it would fail to be useful because you wouldn't know which held.
13:43:15 <palomer> Cale: so you'd have a case for each
13:43:18 <Cale> So you could never apply either
13:43:29 <Cale> You can do that already with GADTs though
13:43:42 <Cale> (assuming that GADTs interact with classes at all)
13:43:57 <palomer> ok, say I want a tree of things which are either showable or Num
13:44:00 <Cale> just create another constructor
13:44:07 <palomer> how would I do this?
13:44:20 <Cale> LeafShow :: (Show a) => a -> Tree a
13:44:26 <Cale> LeafNum :: (Num a) => a -> Tree a
13:44:52 <Saulzar> Hmm
13:44:54 <palomer> hrm, added work for my user
13:45:48 <Cale> Well, you'd incur that work at some point anyway
13:46:02 <Saulzar> But that restricts you to a tree of Shoable or a Tree of Num, still just 1 type 
13:46:12 <Cale> no
13:46:27 <Cale> Saulzar: those are existentials
13:47:21 <araujo> Cale, Can you elaborate please?
13:47:22 <Cale> *Main> :t Branch (LeafNum 5) (LeafShow "Hello")
13:47:22 <Cale> Branch (LeafNum 5) (LeafShow "Hello") :: forall a.
13:47:22 <Cale>                                          (Num a) =>
13:47:22 <Cale>                                          Tree (a, [Char])
13:48:05 <Cale> well, there's not really any real need to even encode the types in the type parameter, but here we do it anyway
13:48:11 <palomer> Cale: it would be cool to have foo x = if x is of type Num =>...| if x is of type showable =>...
13:48:22 <palomer> Cale: then it would offload the work to the library
13:48:24 <Saulzar> Oh I see.. still going with the Tree (a, b) thing... but you end up with a mass of types at your root node
13:48:28 <Saulzar> I don't see how it's usable
13:48:36 <Cale> palomer: however, there are ambiguous cases there
13:48:42 <palomer> Cale: for example?
13:48:48 <Cale> Saulzar: you don't have to remember those types
13:48:59 <Saulzar> What would you use to wrap it up?
13:49:09 <Cale> data Tree where 
13:49:09 <Cale>     LeafShow :: (Show a) => a -> Tree
13:49:09 <Cale>     LeafNum  :: (Num a)  => a -> Tree
13:49:09 <Cale>     Branch :: (Show b) => Tree -> Tree -> Tree
13:49:16 <Cale> that just forgets the types
13:49:26 <Cale> er
13:49:34 <Cale> forget that (Show b) on the last line
13:49:47 <Cale> *Main> :t Branch (LeafNum 5) (LeafShow "Hello")
13:49:47 <Cale> Branch (LeafNum 5) (LeafShow "Hello") :: Tree
13:50:07 <joelr1> does anyone know how to interpret core files?
13:50:12 <Saulzar> Hmm, ok - so the change you made was to use existentials inside LeafShow and LeafNum?
13:50:13 <Cale> palomer: for example, everything in the Num class is in Eq as well
13:50:22 <Cale> yeah
13:50:26 <palomer> Cale: good point
13:50:46 <Cale> Well, in a sense, they were already existentials, but not making full use of that fact
13:51:02 <psi> joelr1, gdb -c <core>
13:51:16 <joelr1> psi: not quite :) haskell core syntax is what i mean
13:51:31 <psi> aha!
13:51:35 <palomer> GADTs rock
13:51:49 <palomer> Cale: do you think type inference with GADTs without annotations is undecidable?
13:52:27 <Cale> palomer: I'd be unsurprised if it was undecidable.
13:52:51 <snk_kid_uncurry> has anybody read "The Fun of Programming", is it any good?
13:53:24 <Trevion> joelr1, just pass them to ghc.
13:53:37 <Trevion> along with -fglasgow-exts
13:53:48 <joelr1> Trevion: what do you mean exactly? pass what to ghc?
13:53:49 <Cale> Trevion: I think he wants to know how to read core himself
13:54:03 <joelr1> i'm reading this
13:54:03 <joelr1> http://www.haskell.org/ghc/docs/latest/html/users_guide/faster.html
13:54:08 <Cale> I've never looked at core myself
13:54:16 <joelr1> and trying to to figure out the function's strictness 
13:54:37 <ihope> > toHex
13:54:37 <lambdabot>  Not in scope: `toHex'
13:54:38 <joelr1> oops!
13:54:46 <Trevion> Core looks almost exactly like desugared Haskell.
13:54:50 <joelr1> you need the -O to the -dump-simple
13:55:01 <palomer>  Cale do you think the GADT showable tree is better than the non GADT showable tree?
13:55:01 <araujo> GADTs are GHC extensions right?
13:55:13 <palomer> araujo: right, but they'll be everywhere!
13:55:28 <Trevion> joelr1, are you wondering how to produce them or how to read what's produced
13:55:36 <joelr1> nested lambdas are bad
13:55:41 <araujo> palomer, :-P
13:55:43 <joelr1> Trevion: read waht's produced
13:55:51 <ihope> Nested lambdas are fun...
13:55:54 <palomer> showableOrNum tree
13:55:57 <joelr1> i have a lambda with a nesting of something like 500 :(
13:55:59 * araujo throws a nested lambda at joelr1 
13:56:01 <Cale> palomer: well, when you rewrite it to forget the types involved like that, you end up with something that's roughly equivalent
13:56:12 <Cale> palomer: though I much prefer the GADT syntax
13:56:32 <joelr1> maybe more than 500 since it builds a list on top of pair lambdas
13:56:35 <Trevion> joelr1, the only thing I know of is the paper on the ghc website: http://www.haskell.org/ghc/docs/papers/core.ps.gz
13:56:43 <joelr1> no wonder picklign takes a few seconds :(
13:56:43 <Cale> palomer: The strength of GADTs is that you can actually get it to remember the types of all the nodes.
13:56:49 <palomer> Cale: you wouldn't forget the types, the constructor would be Showable x => Tree x -> Tree x -> Tree x
13:56:57 <snk_kid_uncurry> so these GADTs are related to phantom types?
13:57:02 <Cale> snk_kid_uncurry: yes
13:57:03 <palomer> snk_kid_uncurry: yes
13:57:16 <joelr1> Trevion: thanks!
13:57:18 <snk_kid_uncurry> anyone else want to say yes ;)
13:57:23 <palomer> err ShowableOrNum x => Tree x -> Tree x -> Tree x
13:57:29 <Saulzar> snk_kid_uncurry, no :)
13:57:45 <Cale> data Tree a where 
13:57:46 <Cale>     LeafShow :: (Show a) => a -> Tree a
13:57:46 <Cale>     LeafNum  :: (Num a)  => a -> Tree a
13:57:46 <Cale>     Branch :: Tree x -> Tree y -> Tree (x,y)
13:57:47 <snk_kid_uncurry> Saulzar: good to be different ;)
13:57:54 <Cale> Or how about that?
13:58:00 <palomer> yeah, that's the GADTified version
13:58:04 <Trevion> joelr1, I seem to recall it being similar to reading Scheme... functional, but a little sugar would be nice.
13:58:04 * joelr1 needs help disposing of nested lambdas
13:58:16 <palomer> Cale: I'm talking about the non GADT version where you have to create a showableOrNum type
13:58:25 <Cale> ah, okay
13:58:32 <Saulzar> Ah, that's what that syntax is.. GADT - I thought it was pseudo-code or something :)
13:58:34 <Cale> well, that's about the same, except more awkward
13:58:50 <Cale> Saulzar: this is accepted by GHC today :)
13:59:03 <Philippa> better yet it does something useful ;-)
13:59:10 <joelr1> anyone willing to help me monadify http://wagerlabs.com/Pickle.hs?
13:59:20 <araujo> Cale, Ok, tell me what else you are doing to get that code running please :-)
13:59:45 <Cale> araujo: -fglasgow-exts
14:00:26 <Cale> joelr1: monadify?
14:00:32 <Cale> in which way?
14:00:36 <joelr1> Cale: right, take a look
14:00:37 <araujo> Cale, yeah, i just get:
14:00:50 <joelr1> Cale: well, i'm trying to optimize things a bit
14:01:13 <joelr1> Cale: a huge bit
14:01:24 <joelr1> take a look a http://wagerlabs.com/Bits.txt
14:01:46 <joelr1> SrvServerInfo has a list of 500 TableInfos
14:01:48 <snk_kid_uncurry> so does ghc support first-class phantom types (i'm look at a paper about them) as an extension?
14:01:53 <joelr1> the table infos are built on top of sequ
14:02:15 <Cale> snk_kid_uncurry: that's what GADTs are
14:02:16 <joelr1> and lists are built on top of pair which is built on top of sequ
14:02:19 <araujo> Bah!, was mistyping
14:02:21 <joelr1> the lambda list gets HUGE
14:02:37 <joelr1> i'm thinking that maybe there's a way to optimize things through the use of monads
14:02:39 * araujo doesn't go to bed since yesterday
14:02:47 <joelr1> but maybe that won't buy me anything
14:03:09 <Cale> joelr1: well, that would potentially clean things up syntax wise
14:03:16 <Cale> that's an awful looking type
14:03:23 <snk_kid_uncurry> Cale: i've only just come across GADTs coming in here now you know ;)
14:03:33 <Oejet> araujo: If you want to sleep less, I suggest, you take a 30 min nap 6-8 times per day.
14:03:54 <Cale> snk_kid_uncurry: http://research.microsoft.com/Users/simonpj/papers/gadt/
14:04:01 <joelr1> Cale: any suggestions?
14:04:50 <joelr1> actually, that won't buy me much
14:04:52 <joelr1> i think
14:04:57 <Cale> hmm
14:05:02 <snk_kid_uncurry> Cale: cheers ;)
14:05:03 <joelr1> the lambda list will still be huge
14:05:42 <Cale> well, your record type is huge
14:05:50 <joelr1> i know
14:05:53 <joelr1> but what can i do?
14:06:11 <joelr1> what about changing list to use an accumulator?
14:06:40 <joelr1> changing fixedlist to use an accumulator rather
14:06:55 <joelr1> fixlist
14:07:12 <Cale> hmm
14:07:52 <Cale> oh
14:08:37 <araujo> Oejet, i usually go with the caffeine :-P
14:08:49 <joelr1> actually, maybe it's worth building fixlist on top of an array 
14:08:52 <joelr1> mutable array
14:09:07 <musasabi> back from work stuff.
14:09:34 * joelr1 was anxiously awaiting musasabi's reappearance
14:09:39 <musasabi> today I have been able to 1) not do the jhc Ho thing, 2) look at the pickler combinators in depth, 3) not feel dead tired.
14:10:15 <musasabi> or rather I have been dead tired the whole day
14:10:15 <joelr1> musasabi: wow, you actually _did_ look at pickler combinators in-depth! did you look at the original paper?
14:10:20 <Cale> fixarray :: PU a -> (Int, Int) -> Array Int a ?
14:10:22 <joelr1> musasabi: and what's the jhc Ho thing?!
14:10:32 <Beelsebob> yhc Ho!
14:10:34 <Beelsebob> that?
14:10:37 <Beelsebob> :Y
14:10:39 <ulfdoz> musasabi: If you're bored, you could write a text for me about clustering in Databases. :)
14:10:39 <Beelsebob> :P
14:10:40 <joelr1> Cale: something like that, i think
14:10:46 <musasabi> joelr1: I have read the original paper some time ago, I looked through your code.
14:10:52 <araujo> Any Buddha disciple here?
14:11:13 <Beelsebob> araujo: I've looked at buddha quite a bit, but I write hat-detect and hat-delta
14:11:14 <Cale> Or possibly using IArray/MArray
14:11:16 <musasabi> joelr1: the jhc thing is about cleaning the interface to compilation, better support for libraries etc
14:11:17 <joelr1> musasabi: and what do you think?
14:11:39 <Philippa> Beelsebob is a yhc ho?
14:11:42 <joelr1> musasabi: why would you be using jhc? hacking it for fun?
14:12:00 <musasabi> joelr1: it certainly is elegant, but personally I prefer the monadic version for low level things because I have firmer grasp on performance in the monadic case.
14:12:01 <Beelsebob> Philippa: of course I'm a yhc ho!
14:12:01 <araujo> Beelsebob, how do you include modules from the prelude into the transformations?
14:12:17 <araujo> Sorry, modules from the stdlib
14:12:30 <Beelsebob> araujo: :o the stdlib?
14:12:39 <Beelsebob> you want a haskell tracer to trace C?
14:12:43 <joelr1> musasabi: i have been asking cale for advice on how to monadify this. it looks to me like both appP and appU should run in the state monad
14:13:15 <musasabi> joelr1: have you read the code in binser?
14:13:25 <joelr1> musasabi: but i'm not sure if that will buy me much (monadifying)
14:13:26 <araujo> Beelsebob, sorry, i meant prelude :-)
14:13:27 <musasabi> joelr1: because that has probably the monads you want.
14:13:33 <joelr1> musasabi: no, not yet
14:14:00 <ihope> Mmh... MonadPlus...
14:14:06 <joelr1> musasabi: i was trying to think how i could speed up what i have since i would not have to change the  interfaces then. the ideal alternative was using your SerTH and having that derive everything for me
14:14:09 <Beelsebob> araujo: not sure in Buddha, the easiest way in hat, and probably the easiest way in buddha too is to copy said prelude modules source to your project dir and use that
14:14:30 <araujo> Beelsebob, *agh* , i thought so....
14:14:33 <Beelsebob> alternatively, re-translate them without the -T option
14:14:37 <araujo> Let's se.....
14:14:51 <musasabi> joelr1: well SerTH will need some help, it cannot peek inside the brain and decide "this list must be using 16 bit length specifier, while that one uses a 32 bit one".
14:15:22 <joelr1> musasabi: how can i help serth?
14:16:21 <musasabi> joelr1: e.g. define a newtype and serialize it in a different manner from the basetype, or define the serialization instance for the basetype by hand.
14:16:24 * Beelsebob wanders off back to bed
14:16:25 <Beelsebob> nn all
14:16:47 <musasabi> joelr1: you might look at binser, after that you will know what the monadic approach is like. as that is more intended for the case of arbitrary wire format.
14:17:05 * joelr1 is looking at binser
14:17:27 <araujo> later Beelsebob 
14:17:31 * araujo should go to bed too
14:17:57 <joelr1> musasabi: i'm kind of stuck with haskell structures for now :( would monadifying my existing code be worth it?
14:18:16 <joelr1> musasabi: i think monadifying sequ would give me the lift that i'm looking for
14:18:23 <joelr1> and then i won't have to change my code
14:19:19 <musasabi> joelr1: yes, the reason I am pointing you to binser is that after that you have looked at a simple monadic way of doing it. Then it is more likely that you will get the monadification right on the first time.
14:20:01 <joelr1> musasabi: should i start with replacing the appP and appU to run in the state monad?
14:20:13 <joelr1> changing rather
14:23:00 <Oejet> Good night!
14:24:00 <musasabi> joelr1: yep, but try to avoid incurring overhead (the art of stricness, unboxing, avoiding frames etc), but I think you have experience with that.
14:24:59 <joelr1> musasabi: what's avoiding frames? first time i hear that
14:26:14 <musasabi> joelr1: e.g. things like unsafePerformIO cause an extra frame so it makes sense to lift them to outer levels if possible.
14:26:31 <joelr1> musasabi: what's a frame?
14:26:46 <musasabi> stack-frame.
14:26:53 <joelr1> musasabi: ah, ok
14:27:14 <joelr1> Cale, musasabi: can you guys give me a hand in monadifying sequ? 
14:27:34 <joelr1> is that just a case of a >> return b or something like that?
14:27:58 <ihope> > 3^27
14:27:59 <lambdabot> 7625597484987
14:29:19 * musasabi ponders going to bed (just too tired today)
14:29:35 <joelr1> musasabi: :-) you should then. i'll pester Cale :D
14:29:52 <ihope> > return 3 :: IO Integer
14:29:53 <lambdabot> No IO allowed
14:30:02 <ihope> > error "\a" :: Int
14:30:03 <lambdabot> Exception: 
14:30:03 <musasabi> mmh, night :-)
14:30:04 <musasabi> =>
14:31:08 <joelr1> good night!
14:31:10 <ex__nor> > take 5 [1..]
14:31:11 <lambdabot> [1,2,3,4,5]
14:31:14 <ex__nor> I wonder
14:31:58 <ihope> You wonder what?
14:32:05 <ihope> > last [1..]
14:32:10 <lambdabot> Terminated
14:32:15 <ex__nor> awwww
14:32:18 <ex__nor> that's sad
14:32:33 <ihope> > last [1,1..]
14:32:38 <lambdabot> Terminated
14:33:00 <ihope> @karma lambdabot
14:33:01 <lambdabot> lambdabot has a karma of 8
14:33:04 <ihope> :-)
14:33:13 <mahogny> ok. question: is it sensible to build a commercial quality app on wxwindows, what is it that it *can't* do yet, and is it sensible to assume that anyone easily can obtain and install ghc, wx etc?
14:33:37 <mahogny> anyone=average user of linux or windows
14:33:52 <mahogny> hm. skip windows
14:33:58 <ihope> :-)
14:34:21 <monochrom> I think you can ship executables. Users won't need ghc.
14:34:39 <mahogny> yeah. for windows. that's not the Unix Way (tm) though
14:35:37 <monochrom> The Unix Way (tm) is simply "apt-get install mahogny-app" or "rpm --install mahogny-app"
14:35:40 <mahogny> I think the burning question here is, is wx actively maintained
14:35:47 <Saulzar> I don't think ghc is hard to install if you use the binaries, then again you can probably distribute several different binaries in the same fashon
14:36:02 <ihope> So, what good NTFS partition resizers are there out there?
14:36:04 <mahogny> monochrom, right. is it sensible to assume wx and ghc is accessible in that way on all major distros?
14:37:39 <mahogny> if wx is maintained, then I will get to work immediately :)
14:37:58 <mahogny> nothing is worse than using a library that just detoriates
14:38:33 <monochrom> I am saying the point is moot.  "The Unix Way" is no longer the unix way.  The majority of *nix users (fedora, ubuntu, mac os x, ...) probably don't even have gcc installed.  They just fetch the binary packages of the programs they want.  Why should they need gcc or ghc?
14:38:40 <mahogny> hm. may 08 2005. I guess that update is recent enough
14:38:45 <dons> don't even have gcc? really??
14:38:51 <mahogny> dons, yup
14:38:54 <dons> wouldn't it come in the base system.
14:38:56 <monochrom> Really.
14:39:22 <xs> the curse of -devel packages.
14:39:25 <monochrom> "don't have gcc installed"  read this again carefully.
14:39:37 <mahogny> the unix way is still the way for smaller programs though
14:39:53 <monochrom> Must I need to spell out "it's on the CD but most users opt to not install it"?
14:39:59 <mahogny> can't assume that all distros will include your tiny program tomorrow :)
14:40:21 <monochrom> You can provide binary packages on your home page.
14:40:43 <dons> yes, I'm surprised it's not in the base system though. it's always been in base of every system I've used.
14:40:44 <monochrom> That is the Commercial Quality Way.
14:40:45 <mahogny> yeah. if I *feel like* compiling and testing it on 10 different distros. aaak -_-
14:40:56 <mahogny> monochrom, right
14:41:11 <mahogny> well, if the userbase is there, then it's feasible
14:41:38 <monochrom> If you ask users to compile for themselves, it is not Commercial Quality.  You can call it The Unix Way or whatever, but it is not Commercial Quality.
14:41:59 <monochrom> So, choose your poison.
14:42:22 <mahogny> monochrom, to me, commercial quality is more in terms of "compiling out of the box" and "running without tweaks". the rest comes with time
14:42:30 <mahogny> now... maybe it's time to do the world the next giant favour/antifavour... use this to "port" mirc to unix :/
14:43:47 <mahogny> is Happy still the best parser generator around?
14:44:00 <monochrom> mac os x has gcc installed but the majority never runs it.
14:44:30 <dons> happy is still the best, if you're not into using a combinator based parser, ike parsec.
14:45:02 <monochrom> ghc is easily obtained with rpm or apt-get.  I don't know about wxwindow, but you can do it.
14:45:15 <mahogny> I think wx is widely available
14:45:22 <mahogny> not installed by default though
14:45:53 <joelr1> what does this mean?
14:45:54 <joelr1> data DType t where
14:45:54 <joelr1>   W8    :: DType Word8
14:45:56 <joelr1>   W16   :: DType Word16
14:46:33 <mahogny> while I'm at it, is there a good networking library or should I write that myself?
14:46:49 <ihope> @djinn IO a -> a
14:46:50 <lambdabot> -- f cannot be realized.
14:46:57 <ihope> :-)
14:47:06 <ihope> @djinn a -> IO a
14:47:06 <lambdabot> -- f cannot be realized.
14:47:06 <monochrom> It is alright to ask users to download stuff.  Afterall even Macromedia Flash plugins require a separate download. :)
14:47:21 <ihope> @djinn a -> [a]
14:47:21 <lambdabot> -- f cannot be realized.
14:47:28 <ihope> Hmm...
14:47:32 <dons> joelr1, it's a GADT.
14:47:43 <dons> ihope, no recursive types
14:47:45 <joelr1> but that works in 6.4.1, right?
14:47:54 <dons> yep
14:47:56 <joelr1> dons: how do i interpret that?
14:48:02 <joelr1> is there a description someplace?
14:48:19 <dons> of course, the ghc type extensions in the user manual
14:48:29 <ihope> dons: what's recursive about those?
14:48:29 <dons> _everything_ about ghc is documented there ;)
14:48:33 <dons> [a]
14:48:46 <dons> lists are a recursive type..
14:49:04 <ihope> They're a type constructor.
14:49:30 <dons> you're using a recursive type, the list type.
14:49:47 <dons> which djinn doesn't know how to reason about (yet)
14:50:00 <joelr1> i learned something new today (thanks to dons and musasabi)
14:50:00 <joelr1> http://www.haskell.org/ghc/docs/latest/html/users_guide/gadt.html
14:50:07 <joelr1> dons: how do you read a core file?
14:50:12 <ihope> Those don't look recursive.
14:50:26 <joelr1> dons: the user guide says you can pick up the strictness but i don't see it
14:50:40 <dons> ihope, data [] a = [] | a : [a]
14:50:45 * CosmicRay announced HDBC on haskell@h.o
14:50:56 <ihope> Ah
14:51:09 <joelr1> dons: is this it? [Arity 1
14:51:09 <joelr1>  NoCafRefs
14:51:09 <joelr1>  Str: DmdType L]
14:51:45 <dons> ah, I think so. now, how to read those. umm, check the Guide to External Core?
14:52:02 <dons> but to work out strictness, the easier way is to read the .hi files
14:52:18 <dons> this is also described in the guide.
14:56:03 <dons> @where+ hdbc darcs get --partial http://darcs.complete.org/hdbc 
14:56:03 <lambdabot> Done.
14:59:09 <icb> some of the files from various projects ends with .as instead .hs or .lhs, what does the "a" stand for?
15:00:47 <ihope> Hmm, fancy error message.
15:00:51 <ihope> @type Just Just Just
15:00:52 <lambdabot>   The function `Just' is applied to two arguments,
15:00:52 <lambdabot>   but its type `a -> Maybe a' has only one
15:02:31 * CosmicRay disappears for the evening
15:03:02 <dons> hmm. .as ? never seen that.
15:03:15 <dons> maybe it's a non-haskell related language?
15:03:36 <icb> e.g. in the frag repo, the file "Game.as"
15:04:12 <ihope> ActionScript?
15:04:23 <icb> the content is haskell alright
15:04:54 <ihope> Hmm.
15:05:28 <ihope> Maybe somebody got lazy and named those after 'askell.
15:05:29 <dons> hmm, I'm not sure it's even used in compilation..
15:05:46 <dons> since frag's build is only going to use Game.hs
15:05:59 <dons> but Game.as seems to be the commented one.
15:06:30 <icb> hmmm
15:06:54 <dons> send Mun a mail, perhaps?
15:07:07 <ihope> @. elite type Just
15:07:08 <lambdabot> f0Ra|| a. A -> maybe 4
15:07:19 <icb> good point
15:07:57 <dons> I'll probably take over maintainership of frag sometime in the new year, btw. as Mun is leaving uni to get a real job :)
15:08:07 <franka> frag repo?
15:08:08 <dons> it would be good to see some hacking get done on it.
15:08:12 <dons> @where frag
15:08:13 <lambdabot> http://www.cse.unsw.edu.au/~pls/repos/frag
15:08:28 <dons> I think there are some real possibilities for improving performance, for one.
15:08:56 <icb> yeah, i have been studying the robosim and frag source to gain a better understanding of how to use afrp
15:09:22 <dons> ah, yes. nicce.
15:09:30 <franka> What is the A in AFRP?
15:09:42 <icb> arrow
15:09:59 <franka> Maybe that explains the .as.
15:10:14 <icb> possibly
15:10:52 <ihope> @. elite yow
15:10:53 <lambdabot> 4ND FuRTHeRm0Re, MY Bo\/\/lING 4\/ERA9E I$ UniMpE4ch4b1E!!!
15:11:17 <franka> All the .hs files I see use no Arrow notation; all the .as files do.
15:11:19 <dons> ndm, yow! yhc has a Java rts?
15:11:44 <ihope> So it is 'Askell!
15:13:48 <icb> ask hell is an anagram
15:16:21 <joelr1> how do i do this? pair :: m a -> m b -> m (a, b) ?
15:16:39 <dons> oh, sounds like a job for djinn.
15:16:43 <ihope> Aye.
15:16:46 <dons> @djinn m a -> m b -> m (a, b)
15:16:46 <lambdabot> -- f cannot be realized.
15:16:48 <dons> doh!
15:16:51 <ihope> \a -> 
15:16:54 <ihope> ...Whoops
15:17:00 <dons> ah well, have to code it manuually
15:17:05 <joelr1> does djinn know about liftM2, etc?
15:17:11 <dons> nope.
15:17:17 <joelr1> isn't it liftM2 (,)?
15:17:32 <dons> @type liftM2 (,)
15:17:32 <lambdabot> Not in scope: `liftM2'
15:17:38 <ihope> \a -> \b -> a >>= b >>= (return . (,))
15:17:42 <dons> @type Monad.liftM2 (,)
15:17:43 <lambdabot> forall a1 a2 (m :: * -> *). (Monad m) => m a1 -> m a2 -> m (a1, a2)
15:17:58 <joelr1> dons: can you help me monadify pickler combinators?
15:18:03 <ihope> > (\a -> \b -> a >>= b >>= (return . (,))) (Just 3) Nothing
15:18:04 <lambdabot> Couldn't match `a -> Maybe b' against `Maybe a1'
15:18:13 <ihope> > \a -> \b -> a >>= b >>= (return . (,))
15:18:14 <lambdabot>   add an instance declaration for (Show (m a -> (a -> m b) -> m (b1 -> (b,
15:18:14 <lambdabot> b1))))
15:18:14 <musasabi> :t (\a b -> do a' <- a; b' <- b; return (a,b))
15:18:21 <musasabi> @type (\a b -> do a' <- a; b' <- b; return (a,b))
15:18:21 <lambdabot> forall (m :: * -> *) a a1.
15:18:21 <lambdabot> (Monad m) =>
15:18:21 <lambdabot> m a1 -> m a -> m (m a1, m a)
15:18:31 <musasabi> @type (\a b -> do a' <- a; b' <- b; return (a',b'))
15:18:32 <lambdabot> forall (m :: * -> *) a b. (Monad m) => m a -> m b -> m (a, b)
15:18:35 <musasabi> now better
15:18:42 <joelr1> musasabi: i'm having trouble with my monadification :-( 
15:18:45 <ihope> Hmm...
15:18:53 <musasabi> sleep didn't work at least yet
15:18:58 <ihope> Care to do that without do-notation?
15:19:05 <franka> Is Djinn conservative?  Can it always find a witness?
15:19:10 <joelr1> musasabi: pair :: PU a -> PU b -> PU (a, b) is simple on the way out (appU), just liftM2 (,)
15:19:19 <ihope> @djinn a -> a -> a
15:19:19 <lambdabot> f _ a = a
15:19:37 <joelr1> but would would that work for appP? does it even matter?
15:19:48 <ihope> @djinn a
15:19:48 <lambdabot> -- f cannot be realized.
15:20:09 <dons> franka, Djinn will always find a (total) function if one exists.
15:20:21 <ihope> @djinn (a -> b -> c) -> (a -> b) -> a -> c
15:20:22 <lambdabot> f a b c = a c (b c)
15:20:41 <ihope> @elite R, me hearties!
15:20:41 <lambdabot> R, M3 heaRtiez!
15:20:43 <dons> @djinn ((((a, b) -> f) -> Either (a -> f) (b -> f)) -> f) -> f
15:20:43 <lambdabot> f a = a (\ b -> Left (\ c -> a (\ _ -> Right (\ d -> b (c, d)))))
15:20:49 <joelr1> @type Monad.liftM3 (,)
15:20:50 <lambdabot>   Expecting a function type, but found `(a, b)'
15:20:50 <lambdabot>   Expected type: a1 -> a2 -> a3 -> r
15:20:57 <joelr1> hmm
15:21:23 <ihope> Is there any fmap3?
15:21:37 <ihope> ...Never mind
15:22:28 <ihope> I notice >>= is infixl. Why is this?
15:23:23 <franka> @djinn forall a a1 (m :: * -> *). (Monad m) => m a -> m a1 -> m (a, a1)
15:23:23 <lambdabot> Cannot parse command
15:23:24 <musasabi> joelr1: if you can say the types then it makes sense
15:23:40 <joelr1> musasabi: the types of what?
15:23:42 <franka> @djinn (Monad m) => m a -> m a1 -> m (a, a1)
15:23:43 <lambdabot> Cannot parse command
15:23:57 <musasabi> joelr1: the appP pair function you want
15:24:27 <musasabi> "(a,b) -> m ()" or "a -> b -> m ()" perhaps?
15:24:29 <franka> @type \ma -> \mb -> ma >>= \a -> mb >>= \b -> return (a,b)
15:24:29 <lambdabot> forall a a1 (m :: * -> *). (Monad m) => m a -> m a1 -> m (a, a1)
15:25:05 <joelr1> musasabi: (a, b) -> m ()
15:25:18 <joelr1> musasabi: but how do i unify them?
15:25:45 <joelr1> can they be unified even?
15:26:30 <ihope> Um, unify what?
15:26:59 <ihope> I know ((a -> b) -> a) -> (a -> b) -> b and a -> a cannot be unified...
15:27:17 <ihope> :-)
15:27:27 <joelr1> ihope: see http://wagerlabs.com/Pickle.hs. they cannot be unified indeed but i'm looking to come up with a single spec that can be used both ways
15:27:56 <joelr1> musasabi: got a question re: binser
15:28:21 <joelr1> musasabi: why did you make "newtype MutEnv a = ME (FState -> IO (a, FState))" the monad instead of FState?
15:29:08 <musasabi> joelr1: because that is the way State monads are usually defined.
15:29:41 <musasabi> (I don't see how one would defined Monad for FState, but I might just be tired)
15:29:45 <joelr1> hmm. silly question
15:29:46 <ihope> Are functors all monads?
15:30:18 <joelr1> musasabi: trying to come up with a single-spec approach like you did for binser
15:30:25 <ihope> ...Apparently not.
15:30:39 <joelr1> musasabi: MutableEnv is just for decoding, right?
15:30:50 <arjanb> ihope: no but all monads are functors
15:30:50 <gzl> ihope: no. all monads are functors.
15:30:52 <SamB> okay, I've got Conjure sorta seeding ;-)
15:31:06 <ihope> ...Ah right.
15:32:11 <joelr1> musasabi: never mind, i think i'm getting your general idea
15:32:20 <joelr1> musasabi: did you say binser was wicked-fast?
15:32:27 <joelr1> or was that serth?
15:32:46 <ihope> Monads are more versatile, therefore more specific...
15:33:04 <ihope> The type a is not specific at all, and is therefore useless :-)
15:35:24 <musasabi> joelr1: it depends on the data, I have either one beating the other depending on circumstances.
15:36:02 <joelr1> musasabi: is binser part of serth? i don't see binser as a library
15:36:39 <musasabi> SerTH certainly has more performance hacks, but binser seems to compete with SerTH even without that.
15:36:59 <joelr1> musasabi: so can i have a single spec with SerTH?
15:37:37 <musasabi> SerTH is aimed for the case where you don't care much for wire presentation, while binser is aimed for the case where you do care.
15:38:11 <joelr1> musasabi: hmm
15:39:05 <musasabi> joelr1: If I were in your place I would read binser code and take all the nice ideas to your picklers.
15:39:10 <dons> musasabi, would you like to add some content to http://www.haskell.org/hawiki/BinaryIo ?
15:39:17 <ihope> Wait, is there anything that makes monads functors, or do all the monads currently defined happen to be monads as well?
15:39:24 <joelr1> musasabi: that's what i'm trying to do
15:39:30 <joelr1> musasabi: http://cs.helsinki.fi/u/ekarttun/haskell/test.hs, your example
15:39:44 <dons> I'm conduncting a bit of a survey of binary IO in Haskell atm, and would like to get an idea of what people are thinking
15:39:56 <SamB> ihope: fmap is equivalent to liftM
15:40:12 <SamB> however, not all Monads are Functors...
15:40:13 <musasabi> dons: if tomorrow is fine, I can push out a real webpage for the binser code.
15:40:35 <joelr1> musasabi: you are using C just to show how manual parsers can be done, right?
15:41:00 <musasabi> + link it to the wiki and write explanations there
15:41:33 <SamB> well, I'm using Parsec and replicateM
15:41:45 <SamB> its not very pretty...
15:42:22 <franka> Sorry, I killed lambdabot again.
15:42:27 <SamB> well, for input
15:42:31 <franka> The @prelude command is broken.
15:42:33 <joelr1> i think i need to learn about uncurry... or something
15:42:37 <SamB> for output, just list functions...
15:42:55 <SamB> @botsnack
15:42:55 <lambdabot> :)
15:43:05 <SamB> lambdabot looks okay to me...
15:43:37 <franka> SamB: All monads are functors.
15:43:48 <SamB> franka: note the upper case
15:43:54 <franka> OK.
15:44:43 <SamB> which is to say, not all types that have instances of Monad will have instances of Functor available to a given module...
15:44:47 <franka> Ah, OK, last time I got a "thread killed" error from lambdabot it crashed.
15:45:49 <franka> Yes, that is true.
15:46:16 <franka> Hello, SN.
15:46:22 <SyntaxNinja> hi franka
15:46:28 <SyntaxNinja> I wonder why I wasn't on this chan hmm
15:47:51 <joelr1> musasabi: how can i convert from a :+: b to Constructor a b?
15:48:30 <SamB> joelr1: "Constructor a b"?
15:48:36 <dons> franka, you were supposed to tell me what you did, and then send a patch...
15:48:56 <dons> there's no @prelude command anyway, is there.
15:48:59 <joelr1> SamB: well, yes, meaning that I have a constructor Foo a b 
15:49:05 <dons> it's being spell-corrected to something else.
15:49:06 <SamB> @prelude foobar
15:49:21 <lambdabot> Error: thread killed
15:49:34 <dons> @help prelude
15:49:35 <SamB> dons: that silent spell-correction is getting annoying
15:49:44 <dons> bah. why?
15:49:57 <franka> dons: It seems OK, anyway.
15:49:57 <Beelsebob> silent spell correction sucks
15:50:02 <dons> it was doubly annoying when it was verbose
15:50:14 <arjanb> couldn't that correction be limited to 1 or 2 chars?
15:50:16 <SamB> dons: because its too hard to tell what it decided to use instead
15:50:17 <musasabi> joelr1: like do (x :+: y :+: z :+: NIL) <- calculation; return $ Constructor x y z
15:50:20 <Beelsebob> apps should tell you when there's an error, rather that think they know best
15:50:37 <franka> @bot
15:50:40 <dons> arjanb, well, it currently uses 3 chars. perhaps 2 would be better.
15:50:48 <franka> OK, maybe not.
15:51:00 <dons> hmm
15:51:09 <joelr1> musasabi: i'm looking at this
15:51:10 <joelr1> instance (Serializable a, Serializable b) => Serializable ((:+:) a b) where
15:51:10 <joelr1>   encode (a :+: b) = encode a >> encode b
15:51:10 <joelr1>   decode = do a <- decode
15:51:10 <joelr1>               b <- decode
15:51:12 <joelr1>               return (a :+: b)
15:51:41 <joelr1> musasabi: and thinking that it does pretty much what i need it to except in my case it's Foo a b instead of a :+: b
15:51:47 <dons> one of the design goals of lambdabot is to be not noisy, so spelling correction, and silent correction, flows from this goal
15:52:07 <dons> it's unixy :)
15:52:30 <joelr1> musasabi: i think autrijus had an example of how to derive something like a :+: b for Foo a b through uncurry or something like that but i don't know Template Haskell
15:52:32 <dons> ah, the thread is killed, but something else goes wrong.
15:52:33 <dons> hmm.
15:52:34 <franka> What does it spell-correct @prelude to, then?
15:52:55 <franka> I thought I saw @prelude on @listcommands...
15:53:00 <joelr1> musasabi: how would i do the conversion with TH and uncurry?
15:53:10 <dons> @help prelude
15:53:11 <lambdabot> I perform dictionary lookups via the following 14 commands:
15:53:11 <lambdabot>  @all-dicts .. Query all databases on dict.org
15:53:12 <lambdabot>  @devils ..... The Devil's Dictionary
15:53:14 <lambdabot>  @easton ..... Easton's 1897 Bible Dictionary
15:53:16 <lambdabot>  @elements ... Elements database
15:53:18 <lambdabot> [10 @more lines]
15:53:21 <dons> ah..!
15:53:32 <dons> it's a timing-out dictionary lookup, maybe.
15:53:39 <franka> BTW, the help for @quote is wrong; @quote-add doesn't work.
15:54:01 <franka> @help quote
15:54:02 <lambdabot>  @quote <nick>/@quote-add <nick> <quote>
15:54:02 <lambdabot> Quote somebody, or a random person, or save a memorable quote
15:54:07 <dons> darcs send..
15:54:50 <dons> @quote-add Foo Bar
15:54:53 <lambdabot> Unknown command, try @listcommands.
15:54:53 <dons> @quote Foo
15:54:54 <lambdabot> Foo hasn't said anything memorable
15:55:04 <dons> @remember Foo Bar
15:55:04 <dons> @quote Foo
15:55:08 <Beelsebob> @quote beelsebob
15:55:08 <lambdabot>  Bar
15:55:09 <lambdabot> beelsebob hasn't said anything memorable
15:55:10 <musasabi> joelr1: template haskell is seriously undocumented.
15:55:12 <Beelsebob> booring!
15:55:34 <joelr1> musasabi: how would you convert from a :+: b to Foo a b with TH?
15:55:36 <musasabi> joelr1: I just look at the source, and make offerings to elder gods till it works.
15:55:40 <dons> ah, yes, that was a bug in the quote module.
15:55:54 <joelr1> musasabi: shouldn't that be a no-brainer?
15:56:20 <musasabi> joelr1: well generalizing that is the harder part.
15:56:44 <musasabi> is easy to say (\(a :+: b) -> Foo a b)
15:57:02 <musasabi> or even un2 f (a :+: b) = f a b
15:57:15 <joelr1> musasabi: take a look at this http://www.haskell.org/hawiki/TemplateHaskell
15:57:18 <joelr1> musasabi: the bottom of the page
15:57:52 <joelr1> musasabi: Generic Constructor for Records
15:57:57 <joelr1> musasabi: isn't that what i want?
15:58:01 <musasabi> joelr1: ok, now just use that.
15:58:19 <joelr1> musasabi: i can't. i think that does not compile and i don't understand what it does :(
16:00:02 <joelr1> musasabi: it would be something like return $ $(constrRecord PGD) a :+: b, right?
16:02:19 <dons> @prelude
16:02:20 <lambdabot> Unknown command, try @listcommands.
16:02:33 <dons> it was connecting to a non-existent dictionary server
16:05:51 <joelr1> dons: if i were to make a record into a storable, how would i define alignment? would it be the alignment of the first field?
16:06:41 <joelr1> Cale: ping
16:06:58 <Cale> hi
16:07:11 <joelr1> one sec, let me show you something
16:08:14 <lisppaste2> joelr1 pasted "TH" at http://paste.lisp.org/display/14848
16:08:53 <joelr1> Cale: i'm trying to see if i can make this into something whereby i can convert Foo a b into a :+: b
16:09:20 <joelr1> for use with
16:09:20 <joelr1> instance (Serializable a, Serializable b) => Serializable ((:+:) a b) where
16:09:21 <joelr1>   encode (a :+: b) = encode a >> encode b
16:09:21 <joelr1>   decode = do a <- decode
16:09:21 <joelr1>               b <- decode
16:09:23 <joelr1>               return (a :+: b)
16:09:54 <musasabi> joelr1: alignment is not really used for anything
16:10:11 <musasabi> joelr1: that is for SerTH ;)
16:10:34 <musasabi> if you looked at binser sources you would know that it does not define such a class ;)
16:10:59 <joelr1> musasabi: i'm trying to make them work with my stuff
16:11:17 <musasabi> you would also know why (:+:) is used and why it is completely optional.
16:11:21 <joelr1> musasabi: http://paste.lisp.org/display/14848 this does not compile, gives a silly error
16:11:49 <joelr1> musasabi: and i know why :+: is used. what i'm thinking is how can i pair the :+: spec with a record
16:11:51 * Cale considers the possibility of using Data.Generics
16:12:21 <joelr1> i.e. have a function that takes a :+: spec and a Data ... with as many fields
16:12:45 <dons> joelr1, what's this function: read                           Script.PokerClient    20.1   13.6
16:12:50 <dons> is that the normal `read'?
16:12:57 <dons> (read is slooowww)
16:13:05 <joelr1> dons: nono
16:13:23 <joelr1> dons: you should be looking here, btw, http://wagerlabs.com/timeleak.tgz instead
16:13:54 <dons> oh, just reading my email, not quite up to doing a full analysis atm
16:14:08 <dons> the `read' just caught my eye
16:14:16 <joelr1> dons: my issue, basically, is that serializing a a list of 500 table infos takes several seconds under certain circumstances
16:14:20 <joelr1> dons: ok
16:14:29 <dons> hmm. that seems bad though
16:14:36 <dons> 500 table infos are how big?
16:14:43 <joelr1> dons: about 50k
16:14:47 <joelr1> but that is not the kicker
16:14:58 <musasabi> that is very very very slow.
16:14:59 <dons> yeah?
16:15:09 <joelr1> i have 1000 threads all reading from the same file and deserializing stuff. 
16:15:17 <dons> yeah, I dump out 2M of hmp3 playlists in tiny ms fractions.
16:15:39 <dons> why do they all read from the same file?
16:15:42 <joelr1> they print messages to the screen. if i funnel these messages to the screen through a lock then everything is fine and each deserialize takes 0-1s
16:15:42 <dons> it can't be done once, and shared?
16:15:58 <joelr1> dons: the file is opened read-only. this is just a test
16:16:19 <joelr1> dons: so if they all write to the screen via a lock, i.e. there's some sequencing then everything is fine
16:16:56 <joelr1> dons: but if i remove the sequencing and have them _only_ print to the screen when there's an error (via fail $ ...) then the de-serialization starts taking seconds all of a sudden on the big packets
16:17:18 <joelr1> this is totally baffling
16:17:28 <dons> oh, is this read from a Handle?
16:17:35 <joelr1> dons: yes
16:17:42 <dons> Handles do locking as well, so you may end up with lots of locking
16:17:43 <joelr1> dons: but different handles
16:18:01 <dons> ah. differnet handles onto the same file?
16:18:16 <joelr1> dons: it exhibits the same behavior whether i'm reading from different handles onto the same file or from different sockets
16:18:51 <musasabi> joelr1: how about if you just use a memory buffer to eliminate IO effects?
16:19:09 <joelr1> musasabi: a single memory buffer?
16:19:18 <joelr1> musasabi: or multiple?
16:19:50 <joelr1> musasabi: actually, it _does_ use a memory buffer
16:20:09 <joelr1> musasabi: timing starts _after_ data is loaded into the buffer
16:20:59 <musasabi> after all threads have loaded data?
16:22:04 <joelr1> musasabi: no, not after all of them loaded
16:22:10 <joelr1> each thread is timed separately
16:22:22 <joelr1> after it loads the data. that is only the unpickling is timed
16:25:12 <musasabi> joelr1: you realise that the other threads blocking on IO will interleave with the unpickling?
16:25:46 <joelr1> musasabi: i guess i do not realize the consequences
16:26:16 <joelr1> musasabi: why would they block on io? io is non-blocking in haskell, right? in the sense that it does not block other threads
16:27:06 <musasabi> io is nonblocking in that calls to the local disk are not considered blocking in the *nix semantics.
16:27:24 <joelr1> musasabi: right, and?
16:27:48 <musasabi> joelr1: it just seems like a good source of timing errors.
16:28:31 <joelr1> musasabi: i'm not sure they are errors but something fishy is positively going on. i'm hacking together a repro case for everyone to use
16:28:39 <joelr1> i have the data as well
16:28:54 <joelr1> i should be done in 30 minutes or so and then everyone can see what i'm talking about
16:32:19 <dons> what's the state of the project these days, up, down, forward, backward?
16:32:32 <dons> you seem less stressed, anyway :)
16:32:35 <joelr1> dons: are you talking to me?
16:32:39 <dons> yep, sorry :)
16:32:46 <resiak> dons: up, up, down, down, left, right, left, right, A, B, start?
16:32:56 <joelr1> dons: well... i'm so fucked that i no longer care. thus more relaxed.
16:33:12 <joelr1> dons: plus, the customer paid me in full. 
16:33:13 <dons> ah, ok. hmm. well that's good and bad I guess.
16:33:15 <dons> ah, good.
16:33:26 <dons> and you're now an official Haskell hacker.
16:33:27 <joelr1> dons: this does not mean that i'm not working on it, it occupies me 100%
16:33:36 <joelr1> dons: i guess i am but it does not help me
16:33:41 <joelr1> dons: are you gonna be around for a while?
16:34:04 <joelr1> dons: i'm furiously hacking together a repro case that should demonstrate the wierd behavior that i'm experiencing
16:34:34 <dons> yeah, I'm around for the rest of the day.
16:34:42 <joelr1> @localtime dons
16:34:43 <lambdabot> Local time for dons is Wed Dec 21 11:29:39 2005
16:34:48 <dons> it's the other side of the world, here on the other side of the world.
16:34:49 <joelr1> cool
16:34:52 <joelr1> @localtime joelr1
16:34:55 <lambdabot> Local time for joelr1 is Wed Dec 21 00:34:31 2005
16:34:59 <joelr1> hehe
16:35:25 <cpatrick> ooh. how does that work?
16:35:28 <cpatrick> @localtime cpatrick
16:35:31 <musasabi> joelr1: if you have just <10 structures I would just hand encode things, not play with TH.
16:35:31 <lambdabot> Local time for cpatrick is Wed Dec 21 08:35:07 2005
16:35:38 <cpatrick> bah, it's 3 hours out :P
16:35:50 <musasabi> joelr1: hand encoding will take you 3hours of time TH few days.
16:35:52 <dons> cpatrick, that must mean your box is 3 hrs out.
16:35:55 <joelr1> musasabi: man, i have 250 constructors in the command record or something like that overall :(
16:36:05 <cpatrick> (though correct for where my irssi box is)
16:36:12 <musasabi> ouch
16:36:41 <dons> how many lines of code have you written? what does wc -l say?
16:36:53 * dons wonders how big this thing is getting for joelr
16:36:59 <joelr1> mm
16:37:02 <joelr1> never counted. lets see...
16:37:27 <joelr1> 15k :)
16:37:27 <dons> depending on your commenting of course. mines usually about 50% of wc -l as actual code
16:37:31 <dons> cool.
16:37:41 <joelr1> dons: barely any comments
16:37:44 <dons> ok, once you hit 10k you're in serious app territory :)
16:37:59 <joelr1> oh, wait
16:38:03 <joelr1> it counted darcs as well :D
16:38:05 <joelr1> hang on
16:38:09 <dons> no comments, well you just better keep hacking everyday, so you don't forget how it works.
16:38:55 <joelr1> dons: actually, never mind that :) the project is ~8k lines now
16:39:06 <joelr1> dons: although it has been written and rewritten many times
16:39:14 <dons> ok, still big. yeah, and lots of rewrites, I can imagine
16:39:17 <joelr1> over the past 3 months. originally bid at 3 weeks. fixed price
16:40:36 <joelr1> dons: this is the last hurdle :(
16:41:55 <musasabi> joelr1: btw using Drift is easier than TH
16:42:23 <musasabi> took my just one evening to get it to roll my own class instances
16:42:52 <dons> a lot less fiddly than TH
16:42:56 <joelr1> musasabi: i wouldn't know where to start with drift and the kind of wire-to-haskell conversion that i'm doing
16:44:13 <musasabi> joelr1: looking at the GhcBinary instance generation
16:44:30 * dons wants a derivable Binary 
16:45:00 <musasabi> http://repetae.net/dw/darcsweb.cgi?r=DrIFT;a=headblob;f=/src/UserRuleGhcBinary.hs
16:45:19 <musasabi> dons: why not just use -F -pgmF drift-ghc ?
16:45:30 <dons> yes yes :) ok, that's reasonable
16:45:41 <dons> deriving (Show,Read,Binary) would be fun though
16:46:04 <joelr1> musasabi: but does it support the type of list pickling that i'm doing?
16:46:13 <musasabi> dons: not when the spec would be written in a standard and it would become antiqueue.
16:46:38 <dons> anitqueue? antiquated?
16:46:48 <musasabi> joelr1: that is a tool to derive the instances, you just derive the right kind of instances for the serialization thing you are using
16:46:51 <musasabi> antiquated
16:47:01 <dons> yep, I agree.
16:47:15 <joelr1> musasabi: hmm... but then i would have two sets of instances and would need to convert between them 
16:48:34 <dons> musasabi,, but we need a standard binary class in the hier libs, don't you think?
16:48:52 <dons> the underlying byte-oriented IO can be standardised.
16:50:42 <musasabi> dons: yes, but the design space is still quite open, Binary has many annoyances and is pain for some things.
16:51:40 <dons> it's well understood, simple and has been in used for many years. it's a bit like the situation with concurrency, MVArs are well understood, but maybe STM will wipe them off the map
16:52:10 <SamB> dons: I don't see how
16:52:11 <dons> though, what are the many annoyances with Binary?
16:52:18 <SamB> MVars are so drop dead easy!
16:52:18 <dcoutts> have a good holiday folks
16:52:18 * dcoutts will be back in January
16:52:31 <dons> ciao dcoutts, don't eat too much pudding
16:52:40 <dcoutts> ta :-)
16:52:48 <SamB> dons: but remember, the proof is in the pudding!
16:52:55 <dons> ah, well, that's true.
16:53:11 <dcoutts> SamB, damn, I knew I'd been looking in the wrong place!
16:53:15 <dons> lambda hackers should all have more pudding then.
16:53:20 <SamB> now I've gotta get me some of that pudding sometime and figure out what the theorem is
16:53:43 <dons> ah, so we've been confused all along: it's the pudding-howard isomorphism!
16:53:55 <musasabi> dons: random access is pain, it is not really possible to layer them with e.g. compression, no support to actually control the wire format.
16:54:36 <dons> no support to control the wire format, why? (i've seen, e.g. ELF object parsers written in Binary)
16:54:46 <SamB> ELF is hardly a wire format
16:55:02 <dons> can you elaborate musasabi?
16:55:11 <SamB> ELF is an image format...
16:55:40 <musasabi> dons: e.g. endian conversions are a pain with Binary
16:55:52 <dons> yes, endianess is an issue.
16:57:10 <dons> so endianess, what else?  random access. layering.
16:57:39 <musasabi> yes.
16:57:46 <dons> however, if the IO primitives are in the standard, and a basic class for 90% of jobs is available. then fancier libs can be built as cabalised libs.
16:58:10 <SamB> well, as long as the primitives are sufficiently versatile
16:58:18 <dons> yep.
16:58:52 <SamB> like, what kind of buffer do I need to use the standard primitives?
16:58:54 <dons> anything in the hier libs is better than the current situation, where we have nothiiing.
16:59:04 <SamB> yes.
16:59:20 <SamB> even hGetChars would probably be better than nothing...
16:59:27 <dons> SamB, simplest would be Handle IO. then memory buffer (over arrays).
17:00:02 <SamB> what if I just want Binary IO? who said anything about memory streams?
17:00:31 <dons> right. I think a conservative step would be a basic Binary class with get/put on Handles
17:00:44 <dons> and enough useful instances to get jobs done quickly 
17:00:45 <SamB> eh.
17:00:59 <SamB> I think a conservative step would be some kind of primitive...
17:01:23 <dons> well, very conservative is just adding getWordN, putWordN
17:01:34 <SamB> hmm.
17:01:55 <SamB> perhaps you and I have different ideas of what primitive binary IO consists of
17:02:33 * SamB thinks read(2)/write(2) describe his wants of the standard fairly well
17:02:48 <dons> but then you need to interact with Haskell in some way
17:02:56 <dons> you need to marshal the data
17:02:58 <SamB> well, true.
17:03:11 <dons> marshalling is the interesting problem
17:03:19 <SamB> hmm, personally, I was thinking just reading into byte buffers would be nice for starters.
17:03:25 <dons> if it's just read/write, do a foreign import and play with Storable.
17:03:38 <dons> hGetBuf?
17:03:56 <SamB> well, not of type Ptr Word8
17:04:26 <dons> @type Data.Array.hGetArray
17:04:27 <lambdabot> Not in scope: `Data.Array.hGetArray'
17:04:27 <SamB> @index hGetBuf
17:04:27 <lambdabot> System.IO
17:05:01 <SamB> dons: what you are probably thinking of looked awfully inefficient when I read the source
17:05:10 <SamB> @type System.IO.hGetBuf
17:05:11 <lambdabot> forall a. GHC.IOBase.Handle -> GHC.Ptr.Ptr a -> Int -> IO Int
17:05:19 <dons> have you read hmp3/Binary.hs?
17:05:31 <dons> this is efficient. that's why ghc uses it for .hi files.
17:05:37 <SamB> maybe some kind of Buffer class...
17:06:01 <joelr1> is there a shorter way of saying
17:06:02 <dons> show me the code :)
17:06:02 <joelr1> (\_ -> return ())
17:06:03 <joelr1> ?
17:06:13 <dons> void?
17:06:18 <joelr1> dons: i'll show you the code in a second :)
17:06:21 <joelr1> @type void
17:06:21 <lambdabot> Not in scope: `void'
17:06:26 <joelr1> hmm
17:06:29 <SamB> well, I'm thinking something like
17:06:32 <monochrom> @pl (\_ -> return ())
17:06:32 <lambdabot> const return
17:06:36 <monochrom> heh
17:07:00 <joelr1> hmm
17:07:13 <dons> @type Foreign.Marshal.Error.void
17:07:14 <lambdabot> forall a. IO a -> IO ()
17:07:17 <monochrom> hmm! @pl interprets () as an empty expression !
17:07:24 <monochrom> @pl (\_ -> return x)
17:07:25 <lambdabot> const (return x)
17:07:28 <SamB> class Buffer a where withBufferAsPtr :: a -> (Ptr b -> IO c) -> IO c
17:07:32 <monochrom> replace x by ()
17:07:43 <dons> @todo-add BUG: @pl (\_ -> return ()) --> const return
17:07:44 <lambdabot> Entry added to the todo list
17:07:59 <monochrom> @pl ()
17:08:00 <lambdabot> ()
17:08:08 <monochrom> @pl const ()
17:08:09 <lambdabot> const
17:08:16 <SamB> ah
17:08:20 <SamB> the bug is with parens
17:08:24 <SamB> I've seen that before
17:13:32 <joelr1> dons: got a repro case!
17:14:53 <joelr1> Cale: ping
17:15:00 <joelr1> folks i need your help!
17:15:18 <joelr1> need you to run this and tell me if you see what i'm looking to see
17:15:28 <joelr1> http://wagerlabs.com/timeleak.tgz
17:15:36 <SamB> time leak!
17:15:39 <SamB> oh know!
17:15:51 <SamB> thats almost worse than a space leak!
17:16:12 <dons> ok, having a look.
17:16:13 <Cale> what's a time leak?
17:16:20 <joelr1> he
17:16:28 <joelr1> dons: wait a sec
17:16:30 <joelr1> one sec
17:16:32 <joelr1> one sec
17:16:32 <dons> a hole in the space-time continuum
17:16:37 <joelr1> one sec
17:16:39 <SamB> its like what happens when you sit down to code, you see?
17:16:40 <joelr1> ok now
17:16:57 <joelr1> i re-uploaded the tarball after including a small readme file
17:17:07 <joelr1> Cale: can you please take a look at tell me if you get any alerts?
17:18:16 <Cale> ./ZLib.o: In function `r2Ot_info': undefined reference to `uncompress'
17:18:21 * dons thinks you should always use -O for timing stuff..
17:18:24 <joelr1> Cale -lz
17:18:52 <Cale> ah, I just sourced the README :)
17:19:09 <Cale> a bunch of oranges, one red
17:19:21 * joelr1 is updating the readme and re-uploading
17:19:41 <dons> eventually, unstuff: trace.dat: openBinaryFile: resource exhausted (Too many open files)
17:19:49 <dons> but no alerts (I compiled with -O though..)
17:19:55 <joelr1> dons: ulimit -n unlimited
17:20:14 <Cale> I can't run it for too long because my machine has problems with heat at the moment, and it runs at 100% cpu
17:20:44 <joelr1> Cale: it runs through in a few seconds. that is you should start seeing alerts in a few seconds
17:20:56 <joelr1> dons: you really need to let it run a few hundred threads
17:21:01 <Cale> yeah, I get alerts almost immediately
17:21:04 <dons> 1 red, 10 or so orange.
17:21:10 <joelr1> dons: use ulimit -n 1024 or so
17:21:11 <dons> after a little while, not immediately.
17:21:14 <joelr1> now, do this
17:21:26 <joelr1> {-# NOINLINE lock #-}
17:21:26 <joelr1> lock :: MVar ()
17:21:26 <joelr1> lock = unsafePerformIO $ newMVar ()
17:21:26 <joelr1> trace s = withMVar lock $ const $ putStrLn s
17:21:36 <dons> where?
17:21:40 <joelr1> add this or re-download timeleak.tgz
17:21:42 <joelr1> add it to unstuff.hs
17:21:44 <Cale> with -O, it takes longer before I get an alert, I think
17:21:54 <joelr1> then pass that instead of the dummy lambda
17:21:58 <joelr1> and have read print something
17:21:59 <Cale> and they're farther between
17:22:06 <joelr1> no
17:22:09 <joelr1> just pass that in
17:22:14 <joelr1> to read instead of the lambda
17:22:21 <joelr1> which will cause read to print the time stats
17:22:34 <joelr1> then seat back and marvel at all the read completing in 0-1s. no alerts.
17:22:36 <joelr1> what gives?!
17:22:55 <dons> you mean, read h (\_ -> return ()) -> read h trace ?
17:23:05 <joelr1> nono
17:23:19 <dons> sorry, there's a meta -> in there ;)
17:23:22 <joelr1>     do cmd <- read h trace
17:23:36 <dons> yes, that's what I meant. -> was a transform :)
17:25:18 <joelr1> dons: did that eliminate the alerts?
17:25:21 <joelr1> passing in trace
17:25:39 <Cale> I'm getting the same alerts after downloading the package again
17:25:57 <joelr1> Cale: 1) download now and 2) uncomment the line as per comment
17:26:45 <Cale> okay
17:27:35 <joelr1> Cale: updated the readme for you as well
17:27:42 <joelr1> dons: what do you see?
17:27:49 <joelr1> dons: did it make a difference?
17:28:08 <Cale> read: InvalidCommand: 0s: 0s, 0s, 0s, 0s, 0s
17:28:13 <Cale> pages and pages of that
17:28:21 <Cale> read: SrvServerInfo: 1s: 0s, 0s, 0s, 0s, 1s
17:28:24 <joelr1> methinks if hackers like Cale and dons cannot improve this then i'm hosed
17:28:26 <Cale> and the occasional one of those
17:28:30 <joelr1> Cale: exactly
17:28:38 <joelr1> see how it makes a world of a difference?
17:28:43 <joelr1> no alerts!
17:28:59 <Cale> okay
17:29:07 <joelr1> now, i cannot use a lock since i'm gonna run 4k threads reading/writing from a socket and doing various calculations
17:29:25 <Cale> I don't really understand what the alerts are about, but presumably something about performance :)
17:29:27 <joelr1> i specifically trace by dumping udp datagrams to a separate logging server
17:29:35 <Cale> So what is the difference here?
17:29:39 <joelr1> Cale: take a look at unstuff
17:29:52 <joelr1> the alerts are brackets around de-serialization
17:30:08 <joelr1> and the alert means that it took more than 3 seconds to deserialize a packet
17:30:13 <dons> ok, no alerts.
17:30:15 <Cale> The difference is that you're forcing some evaluation with putStrLn, probably
17:30:20 <dons> yeah, I reckon.
17:30:22 <joelr1> dons: so why the difference?
17:30:28 <dons> stick a `seq` in there somewhere
17:30:31 <joelr1> are you kidding me? :)
17:30:42 <joelr1> ah, i see now
17:30:43 <joelr1> where?
17:30:43 <dons> putStrLn is going to force something, that wasn't forced before.
17:30:44 <Cale> yes, we're kidding. No. :)
17:30:45 <joelr1> i don't know
17:30:54 <Cale> it forces s
17:30:56 <joelr1> well, there's a test
17:31:02 <joelr1> just don't have trace print anything
17:31:18 <joelr1> just so that it goes through a lock
17:31:29 <Cale> one sec
17:31:34 <Cale> let me try something :)
17:32:23 <Cale> cmd <- read h (\s -> evaluate s >> return ()) 
17:32:25 <Cale> try that
17:32:43 <joelr1> you guys are right, i think 
17:32:45 <Cale> no alerts or messages of any kind here
17:32:51 <joelr1> putStrLn does force an eval of something
17:32:57 <Cale> it forces s
17:33:01 <Cale> so evaluate s
17:33:07 <Cale> and the problem goes away :)
17:33:09 <joelr1> but s has nothing to do with anything... no?
17:33:21 <Cale> er, it should anyway
17:33:25 <joelr1> hmm... except for time... which probably forces eval of other stuff
17:33:29 <Cale> if it really went away before
17:33:30 <joelr1> argh
17:33:47 <joelr1> but how do i figure it out? what is forcing what here?
17:34:05 <joelr1> ah! cmdDesc is forcing eval of cmd
17:34:18 <joelr1> but i thought return $! cmd was doing that!
17:34:30 <joelr1> was i mistaken?
17:34:40 <Cale> well, $! will force the top level data constructor of cmd
17:34:58 <joelr1> but everything is strict
17:35:05 <joelr1> all the fields in the structure are strict
17:35:07 <Cale> okay
17:35:19 <joelr1> Cale: the list is not strict, that's probably it
17:35:26 <joelr1> Cale: the list of table infos
17:36:17 <Cale> er, actually, this doesn't work, but s is a string, so that's no wonder -- one more second :)
17:37:39 <Cale> er, it looked better for 10 seconds
17:37:47 <joelr1> ;)
17:37:47 <Cale> but then I caught some alerts
17:37:55 <Cale> no red alerts
17:40:05 * dons strictifies some things
17:40:59 <joelr1> i thought i strictified the hell out of it already :)
17:42:08 * joelr1 is rubbing his palms -- the end is near!
17:42:09 <Cale> the code looks somewhat crazy. At this point, I think I'd have resigned myself to writing a code generation tool. :)
17:43:04 <joelr1> Cale: which part looks crazy? the table info, etc.? i got 250 of those or so :D
17:43:17 * dons compiles with -prof
17:43:18 <joelr1> Cale: too bad HList did not work out
17:43:30 <Cale> all the FFI stuff being used for non-FFI purposes :)
17:43:38 <joelr1> dons: tried that too but could not see the problem. sequ takes forever, sure but why the alerts?
17:43:45 <Cale> and just the insane level of nesting
17:43:51 <joelr1> Cale: what are you talking about? (FFI?)
17:43:58 <Cale> allocaBytes
17:44:08 <joelr1> Cale: well, i'm reading from a file, no?
17:44:11 <joelr1> err, handle
17:44:35 <Cale> yeah, usually that doesn't involve calls to FFI primitives -- at least not directly :)
17:44:37 <dons> yikes, puTableInfo
17:44:56 <joelr1> Cale: btw, i had this on top of mutable arrays just a little while ago then converted it to Ptr Word8 yesterday over the course of about an hour
17:44:57 <dons> puTableInfo                    Records               25.0   30.2
17:45:13 <joelr1> dons: of course, it's 50k when uncompressed (just the data)
17:45:20 <joelr1> the unboxed raw data
17:45:29 <joelr1> it's probably 3 times that when converted to haskell
17:45:39 <Cale> dons: look at the code for it :)
17:45:43 <joelr1> dons: plus, there are 500 or so table infos
17:45:53 <joelr1> in a single srv server info
17:45:59 <dons> yeah, I'm looking at the body of puTableInfo
17:46:11 <joelr1> now look at sequ and imagine it building a list on top of fixlist
17:46:46 <joelr1> that's at least 500 levels of lambda-nesting!
17:47:28 <joelr1> now, i thought of monadifying the code but... i would still have 500 levels of lambda-nesting, they will just look prettier :D
17:47:42 <joelr1> unless of course fixlist is done with an accumulator
17:48:24 <joelr1> rest assured, i'm gonna blog about the whole thing. i have profile reports, postscript graphs, notes, etc. saved
17:48:28 <joelr1> the whole shebang
17:48:40 <joelr1> the (in)definitive guide to haskell profiling :
17:48:51 <dons> it's unusual code, though.
17:49:00 <joelr1> dons: you think so? 
17:49:04 <joelr1> @google pickler combinators
17:49:05 <lambdabot> http://research.microsoft.com/~akenn/fun/picklercombinators.pdf
17:49:12 <joelr1> dons: i thought it looked pretty 
17:49:16 <joelr1> so i took it 
17:49:35 <dons> it does look pretty :)
17:49:45 <joelr1> i fell like i have been doing unusual things from the beginning :(
17:49:48 <dons> i'm just not sure how efficient it is. it's hard to tell.
17:50:08 <joelr1> dons: the underlying machinery is tricky... sort of. i think it would definitely look better monadified but i don't know how to do it
17:50:17 <dons> ah, deepSeq, hmm..
17:50:20 <joelr1> while keeping a single spec for pickling and unpickling
17:50:31 <joelr1> dons: yes, using it for primitives
17:50:46 <joelr1> dons: if you ask me, i think table info needs to be deep-seq-ed
17:50:56 <joelr1> dons: the list of table infos rather 
17:51:07 <joelr1> which would require table info to be an instance of DeepSeq
17:51:21 <joelr1> i think that's where it's coming from
17:51:39 <joelr1> because the fields in the table info record are all strict, same for SrvServerInfo
17:51:51 <joelr1> so it should hypothetically eval the whole thing when i return it with return $! cmd
17:51:59 <joelr1> but it apparently does not
17:52:35 * dons keeps hacking away..
17:54:59 <dons> stricitfying some things helps force stuff earlier, and: 
17:55:00 <dons> sequ                           Pickle                31.6   21.4
17:55:01 <dons> unpickle                       Pickle                12.2    2.1
17:55:26 <joelr1> dons: ok, alerts?
17:55:40 <joelr1> dons: sequ is the workhorse, don't know how to improve it 
17:56:16 <dons> still getting alerts, but takes a lot longe.r
17:56:18 <dons> hmm.
17:56:32 <dons> SCC time.
17:56:41 <joelr1> :D tried that too
17:56:59 <dons> all these nested lambdas, not sure how efficient they're going to be.
17:58:11 <SamB> dons: depends how many fields they need to copy over...
17:58:24 <joelr1> dons, you are falling into a trap i think, the same one that i fell into
17:58:36 <joelr1> the issue is not the performance of the code but a time leak somewhere
17:58:55 <joelr1> that goes away as soon as you eval the string by passing trace into read
17:59:38 <joelr1> although i do agree with you that there's no telling how efficient 500 levels of lambda-nesting are gonna be
18:01:27 <joelr1> dons: did you add strictness to fixlist?
18:04:43 * joelr1 is making sure all the pickle functions require instances of DeepSeq
18:09:37 <Cale> Hmm...
18:09:49 <joelr1> Cale: what?
18:10:36 <Cale> I wonder whether there isn't a better way to describe this long sequence of PUs
18:10:53 <dons> I want do or case notation
18:10:57 <joelr1> Cale: monads, monads!
18:11:12 <joelr1> the whole thing is a state monad, two state monads, actually
18:11:13 <joelr1> right?
18:11:17 <dons> just case a b of x -> ... would be nice. I'd know what was happening then.
18:11:18 <Cale> well, the problem is that as it stands, it's almost but not quite a monad
18:11:26 <Cale> sequ is almost bind
18:11:35 <joelr1> where the state is newtype MyState = MS (Ptr Word8) Int
18:11:51 <joelr1> it's two monads, that much i figured
18:12:03 <joelr1> but it's not clear how to unify them into a single spec
18:13:07 <Cale> I wonder if it's more naturally an arrow.
18:13:34 <joelr1> yes, yes! arrows! i want that!
18:13:37 <joelr1> a.out: user error (ORANGE ALERT: 0s, 18s, SrvServerInfo, ix1: 6, size: 49722)
18:13:37 <joelr1> a.out: user error (ORANGE ALERT: 0s, 20s, SrvServerInfo, ix1: 6, size: 49722)
18:13:51 <joelr1> i thought i nailed it down by making everything instances of DeepSeq. alas :(
18:13:54 <dons> if you just want it to run, don't go in for fancy games.
18:14:14 <joelr1> i actually need it to run now :( yesterday
18:14:26 <joelr1> i don't want to tell the client .. ugh.. you know, haskell was a mistake
18:14:47 <joelr1> really, i should have done it in ruby or erlang but please accept my apologies 
18:14:49 <joelr1> argh :(
18:15:01 <joelr1> dons: i just want the time leak to go away
18:15:02 <SamB> joelr1: last month?
18:15:15 <Cale> joelr1: when you're done this, you should write a binary IO library :)
18:15:24 <joelr1> SamB: 3-week fixed-price project. almost 4th month already.
18:15:52 <joelr1> when i'm done with this i'm gonna write several blog posts and a TMR article :D
18:15:53 <sethk> Cale, joelr1, maybe we can combine my i/o stuff with his.
18:15:54 <Cale> so, what do these alerts really mean?
18:15:59 <joelr1> recounting the experience
18:16:17 <SamB> well, personally my sense of time is awful
18:16:17 <joelr1> Cale: you didn't look ? :) they just time the call to unstuff
18:16:26 <joelr1> which deserializes the packet
18:16:44 <joelr1> eval s by passing in trace. no alerts, unstuff runs under a second. 
18:17:09 <dons> it seems to take a really long time to unstuff. 3s ! I'm surprised.
18:17:12 <joelr1> do not pass in trace. alerts!!!! unpickling takes 20 seconds
18:17:21 <sethk> SamB, mine's great.  I just take my estimate, multiply it by 10, multiply that by 2, and a week, and it's still too short
18:17:30 <joelr1> dons: but with the trace it takes < 1s
18:17:31 <dons> joelr1, oh, I've not seen it take more than 4s.
18:17:39 <joelr1> a.out: user error (ORANGE ALERT: 0s, 18s, SrvServerInfo, ix1: 6, size: 49722)
18:17:39 <joelr1> a.out: user error (ORANGE ALERT: 0s, 20s, SrvServerInfo, ix1: 6, size: 49722)
18:17:52 <joelr1> dons: this is after DeepSeq-ing everything
18:17:54 <dons> btw, I've written some code for you:
18:17:59 <dons> time :: String -> IO a -> IO a
18:17:59 <dons> time str a = do
18:17:59 <dons>     start <- getCPUTime
18:17:59 <dons>     v <- a
18:17:59 <dons>     end   <- getCPUTime
18:18:01 <dons>     let diff = (fromIntegral (end - start)) / (10^12)
18:18:04 <dons>     when (diff > 3) $
18:18:07 <dons>         fail $ str ++ ": " ++ show diff ++ " s"
18:18:09 <dons>     return v
18:18:12 <dons> :)
18:18:16 <dons> i.e. cmd <- time "RED ALERT" $ unstuff packet 0 size
18:18:22 <joelr1> thank you dons, this is very nice of you!
18:19:07 <Spark> heh googling for "dave cunningham intersection type" brings up some MSc work i did as the first result, out of 112000 results
18:19:30 <Spark> i reckon imperial has managed to get itself page ranked
18:19:57 <joelr1> dons: but now you cannot print the trace string ;)
18:20:10 <joelr1> dons: which prints several differences at once
18:20:56 <dons> not sure if all that extra is needed.
18:21:03 <joelr1> right
18:21:32 <dons> and CPUTime gives you more accurate numbers, which is nice
18:22:15 <joelr1> dons: any improvement vs. passing trace in?
18:22:57 <dons> well, there's less code. I never see it get above 3.8 or so sec.
18:23:21 <dons> but I've done a few other tweaks.
18:23:55 <dons> so basically it looks like:
18:23:56 <dons> sequ                           Pickle                29.8   19.7
18:23:56 <dons> time                           Main                  16.5   11.0
18:23:56 <dons> puTableInfo                    Records               10.6   16.3
18:23:56 <dons> unpickle                       Pickle                10.0    1.9
18:23:58 <joelr1> dons: but you agree that passing trace in solves it, right?
18:24:20 <dons> well, it didn't make much sense to me, since manually `seq` the components didn't seem to help.
18:24:31 <joelr1> @hoogle getCPUTime
18:24:32 <lambdabot> System.CPUTime.getCPUTime :: IO Integer
18:24:35 <dons> and I was wondering if all the extra IO was just slowing the system down.
18:24:48 <joelr1> dons: that was my first guess
18:24:56 <dons> threads were blocking on IO,  lowering the system load.
18:25:13 <rep> i thought ghc used non-blocking IO
18:25:20 <dons> blocking/competing to put to stdout handle.
18:25:27 <joelr1> dons: this load is NOTHING compared to what i get normally
18:25:36 <Cale> trace s = withMVar lock $ const $ threadDelay 20 
18:25:40 <joelr1> dons: the goal is to have 4k bots sitting there are doign stuff
18:25:41 <Cale> heh, that also solves the problem
18:25:58 <joelr1> Cale: see, i told you ;) it's not evaluating stuff
18:26:09 <joelr1> not about
18:26:51 <dons> I'd really try to improve this sequ stuff. 30% is a lot. 
18:27:09 <joelr1> dons: i don't even know where to start from
18:27:22 <joelr1> dons: but the issue is that EVERYTHING else is built on top of sequ
18:27:38 <joelr1> take a look around Pickle.hs. everything is on top of sequ
18:28:06 <dons> yeah ,I know. I'd have used a different binary IO lib :)
18:28:09 <joelr1> but sequ itself is just a conversion and a chaining of picklers
18:28:23 <joelr1> dons: well, musasabi has SerTH and binser
18:28:35 <joelr1> binser does the same thing. have you seen it?
18:28:45 <dons> a while ago, yep.
18:29:02 <joelr1> but it deserialzes into, say, a :+: b whereas i would need Foo a b
18:29:10 <joelr1> and the same on the way in
18:29:26 <joelr1> and i don't know template haskell to match up the constructor with the spec
18:29:55 <joelr1> i'm not even sure how that is possible
18:30:16 <joelr1> spj called me a genius at finding bugs :(
18:30:37 <Cale> are you sure that those 4 second waits are a problem?
18:30:47 <Cale> It might be that it's just getting ahead of itself
18:30:49 <joelr1> Cale: 100%
18:31:00 <joelr1> see, what happens is that the bot has a fixed time to act
18:31:11 <joelr1> in some cases that is 5 seconds, mostly 15, sometimes 35
18:31:15 <dons> what's appU_wstr doing?
18:31:29 <joelr1> but even with 200bots they time out and do not respond in time
18:31:33 <joelr1> dons: unicode
18:31:37 <joelr1> dons: wide string
18:31:59 <joelr1> dons: each character is little-endian, 16 bits. the string is terminated by a 16-bit 0
18:32:25 <joelr1> btw, on freebsd/intel there's no overhead from reverseBytes but still the same alerts
18:33:12 <joelr1> i think i just have a nack for getting myself into trouble
18:33:17 * Cale wonders about the semantics of withMVar
18:33:35 <joelr1> i mean, if the depe minds of haskell are having trouble then what chance do i stand?
18:34:06 <joelr1> Cale, dons: would it be worth posting this for discussion on haskell-cafe? then you could contribute to the thread and we could all learn from it
18:34:12 <Cale> well, hey, that's a lot of IO :)
18:34:24 <dons> well, we both think this sequ stuff is a bit of an issue though.
18:34:27 <Cale> I'm not used to dealing with more than a couple of threads
18:34:42 <dons> and yeah, hundreds of threads is new
18:34:43 <joelr1> dons: 100%
18:34:51 <Cale> and the pickler/unpicklers are unusual :)
18:34:53 <joelr1> try thousands of threads
18:35:26 <Cale> what happens with forkOS?
18:36:10 <joelr1> Cale: each thread gets a 2Mb stack under windows and you run out of memory?
18:36:23 <joelr1> constrast this with 1k for haskell
18:36:27 <joelr1> Cale: oh, i see
18:36:32 <joelr1> Cale: did you try that?
18:36:46 <Cale> trying it now
18:36:58 <jimapple> @seen lennart
18:36:58 <lambdabot> Last time I saw lennart was when I left #flippi, #gentoo-haskell, #
18:36:58 <lambdabot> haskell, #haskell-blah, #haskell-overflow, #haskell.es, #haskell.it and #
18:36:58 <lambdabot> scannedinavian 1 day, 3 hours, 3 minutes and 21 seconds ago, and I have
18:36:58 <lambdabot> missed 1 day, 19 minutes and 8 seconds since then.
18:36:58 <Cale> no problems
18:37:09 <Cale> have to link with -threaded
18:37:12 <jimapple> @uptime
18:37:13 <lambdabot> uptime: 2 hours, 35 minutes and 57 seconds
18:37:14 <Cale> but it runs just fine
18:37:26 <sethk> where did you see 2 Mb per thread?
18:37:44 <Cale> no alerts or anything
18:37:59 <dons> oh, we're not using -threaded. doh.
18:38:58 <Cale> yeah, so see if that solves it for you
18:39:04 <Cale> I don't have a windows machine to check
18:39:23 <Cale> But 2MB/thread seems extortionate
18:39:37 <Cale> (and unrealistic)
18:40:22 <sethk> Cale, 2MB/thread with GHC in windows?
18:40:23 <joelr1> dons: i tried that. did not help.
18:40:33 <dons> @karma+ Cale -- forkOS :)
18:40:33 <lambdabot> Cale's karma raised to 3.
18:40:41 <joelr1> Cale: that;s a Windows thing, not a ghc thing
18:40:43 <dons> yeah, no alerts on openbsd with forkOS either.
18:40:58 <joelr1> os threads on windows get a 2mb stack by default
18:41:11 <Cale> and all of that is allocated at once?
18:41:28 <sethk> joelr1, ugh
18:41:29 <joelr1> guys, i just started a thread at haskell-cafe, please feel free to reply with your findings (no problems with forkOS, for example)
18:41:30 <Cale> buy some ram :)
18:41:36 <sethk> joelr1, got to be a way to override that
18:41:50 <joelr1> sethk: yes, there is. probably not from within ghc, though
18:42:09 * joelr1 is trying forkOS
18:42:35 <sethk> joelr1, true, but we have the ghc source, so at the very least we can add an explicit thread stack allocation to the code where a thread is spawned.
18:42:51 <joelr1> sethk: i ain't using windows ;)
18:43:22 <joelr1> dons: can you launch 4k threads on freebsd>
18:43:29 <dons> on openbsd?
18:43:56 <joelr1> dons: whatever you are using
18:44:16 * Cale tries 4000 threads
18:44:21 <dons> forkOS seems to be the key, it's been running for 3 or 4 mins now, no timeouts, sitting on 33M heap.
18:44:23 <Cale> seems to be working
18:44:31 <dons> how do I check how many threads it's forking?
18:44:43 <joelr1> dons: top?
18:44:48 <Cale> dons: looks like it's a parameter to process
18:44:49 <joelr1> Cale: what did you do?
18:45:13 * joelr1 is counting threads
18:45:25 <joelr1> a.out: user error (ORANGE ALERT: 0s, 4s, SrvServerInfo, ix1: 6, size: 49722)
18:45:25 <joelr1> a.out: internal error: scavenge_stack: weird activation record found on stack: 21
18:45:28 <joelr1>     Please report this as a bug to glasgow-haskell-bugs@haskell.org,
18:45:29 <joelr1> at about 26
18:45:38 <Cale> hmm
18:45:46 <Cale> maybe it's not running long enough
18:45:55 <Cale> I'll keep it running
18:46:08 <Cale> though my machine is at risk :) ah
18:46:09 <joelr1> Cale: with os threads? what's your system?
18:46:10 <Cale> okay
18:46:20 <Cale> 2.4 GHz P4
18:46:27 <Cale> 1 GB of memory
18:46:32 <Cale> running Debian
18:46:35 <joelr1> nono
18:46:35 <joelr1> os
18:46:36 <joelr1> ah, ok
18:46:44 <joelr1> seems to be workig = forkOS?
18:46:49 <Cale> I finally did get that error
18:46:53 <dons> joelr, I've put my changes at www.cse.unsw.edu.au/~dons/timeleak-dons.tgz
18:46:54 <Cale> after a long enough wait
18:47:09 <joelr1> dons: thanks! is it working for you, though?
18:47:11 <dons> just a few strictness things and various tweaks as I tried to imporove the profile.
18:47:19 <dons> it's working for me with forkIO, yep.
18:47:35 <dons> before that, I wasn't getting alerts that were worse than 4s
18:47:39 <joelr1> forkIO?!
18:47:43 <dons> ah unstuff: internal error: scavenge_stack: weird activation record found on stack: 0
18:47:47 <dons> sorry, forkOS :/
18:47:48 <joelr1> dons: so you solved it? how?
18:47:57 <dons> forkOS was the trick.
18:48:07 <Cale> yeah, after a while that error happens
18:48:09 <dons> but looks like we found an rts bug..
18:48:14 <dons> on 3 platforms!
18:48:18 <dons> that's a good bug report :)
18:48:33 <dons> and we have a tarball to go with it :)
18:48:34 <joelr1> a.out: user error (ORANGE ALERT: 0s, 4s, SrvServerInfo, ix1: 6, size: 49722)
18:48:34 <joelr1> a.out: internal error: scavenge_stack: weird activation record found on stack: 9
18:48:37 <joelr1> bummer
18:48:40 <joelr1> again
18:48:42 <joelr1> with -threaded
18:48:50 <joelr1> -threaded just does not work for me :(
18:49:03 <dons> ah, I'll try 6.5
18:49:03 <joelr1> dons: i tried (tarball)
18:49:10 <joelr1> dons: did you get the scavenge bit too?
18:49:18 <dons> yep, see above.
18:49:21 <joelr1> dons: or are you talking about RTS?
18:49:34 <dons> but we have a nice reproducible bug here, so open up a bug report...
18:49:35 <joelr1> as in the moving to forkOS is a problem with RTS
18:49:46 <joelr1> dons: i'll let you have the honors
18:49:53 <dons> well, something happened after switching to the threaded rts and forkOS.
18:49:59 <joelr1> dons: care to reply to the killer picklers thread?
18:50:02 <dons> but it did seem to improve performance a lot.
18:50:19 <joelr1> dons: yeah, something happened for sure ;) my runtime started crashing
18:50:25 <joelr1> let me try forkOS and no -threaded
18:50:39 <jethr0> hi all
18:51:05 <joelr1> yep, and i cannot use forkOS w/o -threaded (makes sense)
18:51:19 <dons> oh, there's a foreign call into the zlib right?
18:51:23 <dons> so does that block?
18:51:32 <joelr1> dons: yes, there is. it should block but it will block all the same
18:51:35 <dons> and is that why -threaded improves the performance?
18:51:43 <joelr1> dons: wether you pass in trace or not
18:51:44 <dons> well, with -threaded it won't block all the threads
18:52:03 <joelr1> dons: you are wrong. look at the signature on compress et al
18:52:10 <joelr1> dons: unsafe = no forking of new threads
18:52:23 <dons> ah, ok.
18:52:25 <joelr1> dons: make that safe to get extra threads and non-blocking uncompress
18:53:13 <joelr1> dons: so you thinkit's an rts issue, right? not including the scavenging bug
18:53:31 <dons> I don't know. I think the serialising code is just too slow.
18:54:04 <dons> the crash is an rts bug, of course.
18:54:15 <dons> and a good one, since it's multi-platform and reproducible
18:55:12 <joelr1> dons: but you are not explaining everything /slow/
18:55:28 <joelr1> dons: because it _does_ work if you pass in trace
18:55:30 <joelr1> oh!
18:55:33 * joelr1 has got a bright idea
18:55:42 <joelr1> anyone up for forkIO + yield somewhere?
18:55:52 <joelr1> maybe a few key yields will solve this
18:55:54 <dons> oh, but didn't we decide that that's because it's just blocking threads on the stdout Handle, so other threads get a chance to do work.
18:56:02 <dons> yeah.. maybe a yield or two could help.
18:56:04 <joelr1> right
18:56:15 * Cale wonders again about the exact semantics of withMVar
18:56:34 <dons> or get the forkOS crash under load bug fixed, joelr1...
18:56:36 <joelr1> Cale: what do you want to know?
18:57:01 <joelr1> dons: well, i have a fresh ghc tree checked out. it's 6.5, though
18:57:14 <joelr1> so if i go that route it means i will have to maintain it for the customer
18:57:40 <joelr1> well, same thing with 6.4.1 i would think
18:57:41 <Cale> joelr1: well, does the MVar remain empty while the process acts on it?
18:57:46 <joelr1> the customer would have to apply the same patches
18:58:12 <dons> wouldn't you just check out a known working copy of ghc after the patch is made,  and use that until the next release?
18:58:12 <joelr1> Cale: take a look at the source code ;)
18:58:25 <Cale> I suppose I could
18:58:36 <joelr1> dons: you mean 6.5?
18:58:37 <dons> and since niightly builds are made, you don't even have to maintain anything, do you?
18:58:48 <joelr1> Cale: and let me know because i wanna know as well ;)
18:58:50 <dons> well, you can get a patch pushed back into 6.4, since this is a 6.4 bug too
18:58:56 <joelr1> dons: true, true
18:59:06 <dons> so it'll be in the next stable release, and the first nightly build after the fix.
18:59:14 <joelr1> dons: probably makes more sense to go with 6.5
18:59:30 <joelr1> dons: or are you talking about 6.4.1? which ones are the stable builds?
18:59:40 <joelr1> i'm confused
19:00:08 <dons> lunchtime. joelr, maybe attach your tarball and how to reproduce the forkOS bug on the trac bug list. (you're more familiar with that than I ;) 
19:00:11 * dons gets some lunch
19:00:27 * joelr1 thanks dons
19:00:32 <Cale> forkIO + yield seems to work for a while
19:00:37 <joelr1> dons: if you come up with anything else please let me know! 
19:01:08 <joelr1> Cale: please post to the list or send me an email when you get something working or if you have an imrovement. i really need to get some sleep, 3am :(
19:01:43 <joelr1> Cale: yeah, less alerts
19:01:44 <Cale> ah
19:01:53 <joelr1> a.out: user error (ORANGE ALERT: 0s, 4s, SrvServerInfo, ix1: 6, size: 49722)
19:01:53 <joelr1> a.out: user error (ORANGE ALERT: 0s, 4s, SrvServerInfo, ix1: 6, size: 49722)
19:01:53 <joelr1> a.out: user error (ORANGE ALERT: 0s, 4s, SrvServerInfo, ix1: 6, size: 49722)
19:01:57 <joelr1> but they are longer now
19:01:58 <joelr1> oops
19:02:02 <joelr1> i had 6s and 8s
19:02:38 <joelr1> wrong place to yield probably
19:03:07 <Cale> well, I'm yielding instead of tracing :)
19:03:33 <joelr1> Cale: did not help me :(
19:03:43 <Cale> it helped, but not much
19:04:19 <Cale> okay, so maybe we need some kind of locking?
19:04:30 <joelr1> Cale: no can do
19:04:39 <joelr1> Cale: bots will run really slow then
19:04:48 <joelr1> i'm supposed to have 4k of them
19:05:47 <joelr1> you will timeout anyway but instead of doing so in the picklign code it will be around grabbing the lock
19:06:02 <joelr1> i had this when i was logging to the screen and to file via a lock
19:07:21 <Cale> Is it too slow with the stupid sleeping trace?
19:07:41 <joelr1> Cale: no, it's quite fast in fact
19:07:58 <joelr1> Cale: now, is there something else that can be used as a replacement in the trace?
19:08:03 <joelr1> so that it does not print anything
19:08:10 <Cale> threadDelay
19:08:13 <joelr1> did you say eval-ing the string worked?
19:08:34 <joelr1> Cale: how big?
19:08:43 <joelr1> did that eliminate the alerts?
19:09:39 * Cale wonders why too many files are open on his system
19:09:57 <joelr1> ulimit -n unlimited
19:10:05 <joelr1> or ulimit -n 2048 
19:10:07 <joelr1> that should do
19:10:12 <joelr1> Cale: i do not close the file handles
19:10:21 <joelr1> they are closed automatically when the process exits
19:10:22 <Cale> well, this is new :)
19:10:57 <joelr1> Cale: i put in a thread delay of 1000 but it did not help 
19:11:17 <Cale> I had it at 20
19:12:22 <joelr1> Cale: so we have determined with 100% certanty that the  univesal fix is to print 
19:12:32 <joelr1> Cale: can you bring back that eval again please?
19:12:38 <Cale> hm?
19:12:45 <joelr1> because i think you were right before
19:13:01 <joelr1> hmm
19:13:06 <joelr1> got 1 timeout even with trace
19:13:29 <Cale> I can't run it anymore
19:13:37 <joelr1> ok
19:13:50 <Cale> ulimit -n 16384
19:13:55 <joelr1> :D
19:14:03 <Cale> wait, let me reunpack it
19:14:05 <joelr1> and you are running out of files?!
19:14:08 <joelr1> wierd
19:14:08 <Cale> maybe something stupid happened
19:15:27 <Cale> okay
19:15:36 <Cale> must have been something silly
19:15:39 <Cale> anyway
19:15:49 <Cale> threadDelay 20 works for me
19:15:54 <Cale> in place of the putStrLn
19:16:10 <joelr1> Cale: let me try
19:16:15 <joelr1> are you compiling with -threaded?
19:16:18 <Cale> in fact, threadDelay 1
19:16:20 <Cale> yeah
19:16:33 <joelr1> threadDelay 1 = yield?
19:16:34 <Cale> I'm using forkIO though
19:16:37 <Cale> er
19:16:37 <Cale> no
19:16:43 <Cale> I'm not compiling with threaded
19:16:48 <joelr1> me too
19:16:53 <joelr1> using forkIO, non-threaded
19:17:04 <Cale> this seems to be working
19:17:11 <Cale> changing it to yield fails
19:17:35 <joelr1> Cale: trying your solution
19:17:47 <Cale> I really have no idea what's going on :)
19:18:01 <joelr1> Cale: so long as it works i would not care
19:18:04 <Cale> but if it works, and you need it now, I suppose that it will d
19:18:06 <Cale> o
19:18:10 <joelr1> Cale: try upping the # of threads
19:18:15 <Cale> okay
19:18:15 <joelr1> to 2k or 3k or 4k
19:18:31 <joelr1> Cale: we are doing cutting-edge research here!
19:18:32 <Cale> unstuff: trace.dat: openBinaryFile: resource exhausted (Too many open files)
19:18:34 <Cale> argh
19:18:41 <dons> oh, I wonder if you couuld tweak the scheduler switching rate..
19:18:48 <dons> let threads get more work done each time.
19:18:51 <dons> (or less?)
19:18:53 <joelr1> the interplay between threadDelay 1 and the# of threads
19:18:59 <joelr1> dons: -C? -c?
19:19:03 <joelr1> dons: did you try?
19:19:19 <dons> trying..
19:19:46 <Cale> ulimit -n 1048576
19:19:49 <joelr1> dons: there's probably a timing issue indeed since i'm getting a lot of connections reset by peer
19:19:55 <Cale> still dies immediately
19:19:59 <joelr1> from the c++ server running on windows
19:20:03 <Cale> this is from setting it at 4000 threads
19:20:25 <Cale> or even 200
19:20:26 <joelr1> Cale: thread delay of 1 didn't help
19:20:27 <Cale> 2000*
19:20:39 <Cale> it worked here, so long as I could run the program
19:20:46 <Cale> did 20 work?
19:21:12 <Cale> I'm guessing that it gives the threads some kind of locking
19:21:49 <Cale> when the thread is in that call, it takes the MVar, and for a tiny amount of time, any other thread which tries that will block
19:22:05 <joelr1> wow
19:22:09 <joelr1> i got success
19:22:12 <Cale> So it keeps them synched
19:22:13 <joelr1> for the first time 
19:22:16 <Cale> oh?
19:22:21 <Cale> with what?
19:22:24 <joelr1> dang
19:22:29 <joelr1> i spoke to early
19:22:32 <Cale> hehe
19:22:40 <joelr1> i set the number of context switches to 1/2s
19:22:44 <joelr1> -C.5
19:22:46 <joelr1> a.out: user error (ORANGE ALERT: 0s, 10s, SrvServerInfo, ix1: 6, size: 49207)
19:22:46 <joelr1> a.out: user error (ORANGE ALERT: 0s, 9s, SrvServerInfo, ix1: 6, size: 49722)
19:22:46 <joelr1> a.out: user error (ORANGE ALERT: 0s, 44s, SrvServerInfo, ix1: 6, size: 49722)
19:22:46 <joelr1> a.out: user error (ORANGE ALERT: 0s, 43s, SrvServerInfo, ix1: 6, size: 49207)
19:22:48 <joelr1> hehe
19:23:34 <dons> yeah, I get no timeouts with -C0
19:23:39 <dons> (i.e. switch on every alloc)
19:24:16 <joelr1> with -C1 i seldom get timeouts
19:24:44 <Cale> I think it may be a subtle "bug" in the way that the scheduler is choosing threads
19:24:58 <joelr1> -C0 is _very_ promising so far
19:25:00 <dons> yeah, some behaviour
19:25:02 <Cale> ah
19:25:03 <joelr1> could this be IT?
19:25:14 * joelr1 sets his hopes high
19:25:18 * joelr1 holds his breath
19:25:18 <Cale> Well, it would make sense
19:25:26 <dons> yeah, it seems rarer with -C1, but -C (or -C0) seems to be doing the job here
19:25:27 <joelr1> dons: we are runnig without -threaded, cale and i
19:25:31 <Cale> especially make sense why the withMVar was helping
19:25:42 <dons> oh, without -threaded
19:25:44 <joelr1> Cale: why?
19:25:45 <dons> and just forkIO.
19:25:46 <Cale> because it was forcing threads to block
19:26:02 <joelr1> dons: yes, which just goes to prove that it's universal. works for you with -threaded, works for us without
19:26:02 <dons> it's all about giving more threads a chance to run.
19:26:05 <joelr1> Cale: works for you?
19:26:14 <dons> i'm not using -threaded.
19:26:18 <joelr1> dons: i'm gonna up the # of threads to 4k
19:26:21 <dons> I'll try now with -threaded
19:26:22 <Cale> well, I can't run it with more than 1000 threads for some stupid reason
19:26:24 <joelr1> without -threaded, 
19:26:31 <joelr1> Cale: hehe
19:26:37 <joelr1> Cale: ii can tell you why
19:26:38 <joelr1> probably
19:26:40 <dons> I was using 4000, and no -threaded
19:26:50 <joelr1> Cale: check FD_SETSIZE ;)
19:27:04 <joelr1> grep FD_SETSIZE /usr/include/sys/*h
19:27:18 <dons> now, you can in fact hard bake -C0 into the app if requried.
19:27:19 <joelr1> Cale: if it says 1024 then you gotta change that and rebuild ghc
19:27:29 <joelr1> dons: how's that?
19:27:31 <joelr1> the hooks?
19:27:32 <Cale> /usr/include/sys/select.h:    __fd_mask fds_bits[__FD_SETSIZE / __NFDBITS];
19:27:32 <Cale> /usr/include/sys/select.h:    __fd_mask __fds_bits[__FD_SETSIZE / __NFDBITS];
19:27:32 <Cale> /usr/include/sys/select.h:#define       FD_SETSIZE              __FD_SETSIZE
19:27:36 <Cale> that's all I get
19:27:37 <dons> joelr1, yep. hooks. 
19:27:37 <Cale> anyway
19:27:48 <joelr1> Cale: /usr/include/*h then
19:27:58 <joelr1> Cale: but that's basically the reason
19:28:00 <Cale> nothing there
19:28:11 <dons> you need  to link in a C object containing the string: char *ghc_rts_opts = "-C0"
19:28:21 <joelr1> Cale: if FD_SETSIZE is hardcoded to 1024 then you are not gonna be able to do more
19:28:27 <dons> yep, seems ok here with -C and -threaded too
19:28:28 <Cale> ah, okay
19:28:40 <joelr1> dons -C = -C0?
19:28:42 <Cale> but why am I getting an out of files error?
19:28:49 <dons> joerl1, yep.
19:29:05 <joelr1> interesting
19:29:07 <Cale> does it create a file for each thread?
19:29:14 <joelr1> dons: can i get cabal to compile my c object>
19:29:18 <dons> yep.
19:29:23 <joelr1> Cale: no, it opens a file descriptor
19:29:27 <joelr1> dons: how?
19:29:28 <dons> see hmp3 for a cabal example using hooks:
19:29:30 <dons> @where hmp3
19:29:31 <lambdabot> http://www.cse.unsw.edu.au/~dons/hmp3.html
19:29:36 <Cale> ah, yeah, that's basically what I meant :)
19:29:38 <joelr1> ok
19:29:39 <dons> c-sources:           cbits/utils.c cbits/hooks.c
19:29:49 <dons> include-dirs:        cbits
19:29:54 <joelr1> cool
19:30:16 <joelr1> dons: shouldn't that be static char ...?
19:30:34 <dons> weell, it could be. yes.
19:30:38 <joelr1> dons: would you care to reply to that haskell-cafe thread? after all you found the solution
19:30:44 <dons> hehe ok :)
19:33:25 * joelr1 high-fives dons and cale
19:33:32 <joelr1> what would i do without you guys
19:33:40 <Korollary> play poker yourself?
19:33:41 <joelr1> what a grand finale!
19:33:47 <Cale> :)
19:33:49 <dons> :D
19:33:51 <joelr1> a huge lesson for all haskell newbies.... now what is that lesson?
19:33:54 <joelr1> exactly
19:34:01 <joelr1> ROFL
19:34:05 <dons> 1000s of threads need more switches
19:34:18 <joelr1> yeah
19:34:21 <dons> and the rts is by default not tuned for such a high number of threads
19:34:31 <Cale> I can't believe that you can actually get that much IO to work, given that probably nobody else has ever tried that :)
19:34:57 <joelr1> Cale: this is nothing compared to my poker stuff
19:35:03 <joelr1> Korollary: no 
19:35:16 <joelr1> i wonder if that will solve my network errors as well
19:35:20 <joelr1> in fact i'm looking into that now
19:35:50 <dons> I think a few more cpus would be good
19:36:00 <dons> and a smp rts :)
19:36:12 <joelr1> 6.5?
19:36:27 <dons> it would be a fun game to play, anyway.
19:37:04 <joelr1> dons: how much did your tweaks improve performance?
19:37:20 <dons> a bit. they did slow or delay the occurence of timeouts
19:37:46 <dons> you could add a few of them in if you like. the strictness/seq stuff would be harmless
19:38:15 <dons> @where+ shellac darcs get http://www.eecs.tufts.edu/~rdocki01/shell/
19:38:16 <lambdabot> Done.
19:38:17 <joelr1> dons: i'll do a diff to see what you inserted and where
19:38:36 <dons> yep.
19:38:51 <dons> just cherry pick what you like the look of. not all of it helped.
19:39:56 <dons> now, I wonder if we can switch a bit less often then every alloc
19:40:37 <joelr1> dons: btw, with 5k threads i still get timeouts :D
19:40:54 <dons> well, that's a lot of threads.
19:41:08 <dons> tuning the scheduler to the number of threads might help though.
19:41:26 <dons> it's all about having threads get enough work done to finish inside 3s, but also making sure all get run 
19:41:28 <joelr1> dons: how would you do that?
19:41:38 <joelr1> i mean tune the scheduler
19:41:44 <joelr1> you can't tune it further can you?
19:41:58 <dons> well, work out what -Cn value of n is good for the number of threads you have.
19:42:15 <joelr1> i see, makes sense
19:42:36 <Cale> Shellac looks neat
19:42:59 <joelr1> Cale: just what the doctor ordered to connect to my running system ;)
19:43:04 <joelr1> and poke around the internals
19:44:38 <dons> -C0.01 also works for me.
19:44:50 <joelr1> dons: how many threads?
19:45:19 <dons> I also compile with -O -funbox-strict-fields
19:45:25 <joelr1> oh
19:45:44 <joelr1> is there a way to have multiple cmd line options fields with cabal?
19:45:44 <dons> that was with 1k, I'm now testing with 5k.
19:45:47 <Cale> does -O2 actually do anything extra?
19:46:01 <joelr1> cause my ghc options line is getting too long
19:46:11 <dons> :set wrap ;)
19:46:16 <joelr1> hehe
19:46:29 <dons> some of the cmd line options might go into their own fields, like Cpp and Includes
19:46:54 <joelr1> what about GlasgowExtentions?
19:47:04 <joelr1> no, wait i removed those
19:47:05 <dons> nope, unfortunaly.
19:47:08 <joelr1> never mind
19:49:56 <joelr1> dons: how is 5000 threads? do you let them run through?
19:54:35 <joelr1> dons: i'm falling asleep. 4am. thanks for your help and please post to the list the scheduler settings that work for you with 5k threads. or any other findins :D
19:54:40 <dons> well, no timeouts till I run out of fds
19:56:38 <Cale> http://70.86.201.113/imageserv2/temporary/PBF082ADChristmasCards.jpg
19:56:47 <Cale> aw, too late
19:57:11 <dons> oh, now we need a lambda plugin for The Lambda Shell
19:58:10 <Cale> hi shapr!
19:58:31 <shapr> hiya, what's up?
19:58:37 <Cale> not too much
19:58:48 <Cale> did you see my scratchings on tmrwiki?
19:59:06 <dons> @where+ lambdashell darcs get http://www.eecs.tufts.edu/~rdocki01/lambda/
19:59:07 <lambdabot> Done.
19:59:19 <shapr> Yeah, I look forward to seeing more scratchings.
19:59:49 <shapr> Oh, it's gotten larger since I last looked.
20:00:11 <Cale> oh, yeah, I saved after the first paragraph
20:02:38 <shapr> I like the isSubstringOf example
20:03:12 <Cale> :)
20:03:29 <shapr> 'Data structures as control flow' sounds like a great motto.
20:04:59 <monochrom> haha
20:05:16 <monochrom> I am not sure why the obsession with control flow.
20:05:38 * shapr is a control freak.
20:08:02 <Cale> monochrom: because it's tied up with how the machine actually evaluates the code, and performance and whatnot
20:08:18 <Cale> Of course, not having to think about control flow too much is great
20:08:43 <Cale> but it's nice when you stop and think about it and realise that things are being really clever :)
20:12:15 <xah> join lisp
20:13:09 <monochrom> There are other ways of determining and proving time and space without control flow.  My supervisor has the general scheme and I am adopting it to lazy languages.  At any rate, insisting that all languages must make control flow clear will not scale.
20:14:49 <shapr> I think it wasn't insistence, I think it was 'one valid viewpoint is that laziness can turn data structures into control flow'.
20:15:00 <ricebowl> blah, how can you track where an array out-of-bounds error occurs?
20:15:02 <Cale> well, you still need some insight into the evaluation mechanism
20:15:07 * shapr woke up before 5am, foo
20:15:10 <ricebowl> a stack trace would be cool :(
20:15:31 <Cale> ricebowl: I doubt it would be as useful as you think
20:15:42 <ricebowl> I know
20:15:44 <ricebowl> because of laziness
20:15:48 <ricebowl> but I'm at my wits' end
20:15:57 <ricebowl> I'm not indexing an array, yet I get an index-out-of-bounds
20:16:06 <Cale> are you creating an array?
20:16:09 <ricebowl> yes
20:16:15 <Cale> let's see that line :)
20:16:27 <ricebowl> well, I have tracked it to 1 function
20:16:32 <Cale> ensure that the bounds you pass are suitable
20:16:41 <monochrom> Unit testing can narrow down the spot.
20:16:44 <ricebowl> let me pastebin...
20:16:49 <Cale> does this happen to be a 2-d array?
20:16:50 <ricebowl> unit testing is very difficult in my case
20:17:01 <ricebowl> Cale - I have both vectors and matrices
20:17:06 <Cale> (just out of curiosity)
20:17:22 <ricebowl> I don't know which is causing the bug
20:17:26 <Cale> okay, remember that it's ((min1,min2), (max1,max2))
20:17:31 <monochrom> My advice is to rectify your program so that unit testing is not difficult.
20:17:36 <ricebowl> yeah, I know
20:17:49 <ricebowl> I would get a type error if I didn't set the bounds correctly
20:17:58 <Cale> no you wouldn't
20:18:07 <ricebowl> monochrom - unit testing is difficult because the array has to undergo various transformations
20:18:09 <monochrom> That would be too good to be true! :)
20:18:37 <ricebowl> Cale - UArray i e where i = (Int, Int) or i = Int
20:18:49 <ricebowl> if I try to index a UArray (Int, Int) e with an Int, I will get a type error
20:18:51 <Cale> right
20:19:14 <monochrom> OK, then my alternative advice (I was hoping I don't have to advise this) is to try to prove your program correct.  Where you fail, you have the error.
20:19:17 <Cale> but passing ((0,255), (0,255)) to 'array' isn't a type error
20:19:47 <ricebowl> ah
20:19:48 <Cale> what I'm saying is to ensure that things go in the right place in those tuples :)
20:19:58 <Cale> ((0,0),(255,255))
20:19:59 <ricebowl> a  = (MArray.newListArray ((0, 0), (n, n)) [(paths g)!(x, y) | x <- xs, y <- xs]) :: ST s (STUArray s (Word32, Word32) Int64)
20:20:04 <ricebowl> nope, looks fine to me :p
20:20:14 <Saulzar> Can n be 0?
20:20:18 <ricebowl> no
20:20:28 <ricebowl> actually, yes, it can
20:20:35 <ricebowl> but that would be a matrix of 1 element
20:20:44 <Saulzar> Hmm, maybe the list is not the same size as the array?
20:20:56 <ricebowl> that doesn't matter
20:21:06 <ricebowl> so long as it's larger, anyway
20:21:23 <monochrom> you sure the docs agree with you on that?
20:21:24 <ricebowl> > Array.listArray (0, 0) [0,1,2,3]
20:21:25 <lambdabot>  Not in scope: `Array.listArray'
20:21:32 <ricebowl> > Data.Array.listArray (0, 0) [0,1,2,3]
20:21:33 <lambdabot>  Not in scope: `Data.Array.listArray'
20:21:43 <ricebowl> > listArray (0, 0) [0,1,2,3]
20:21:43 <lambdabot>  Not in scope: `listArray'
20:21:46 <ricebowl> well wtf
20:22:17 <monochrom> another worry is that (paths g)!(x, y) causes an error
20:22:53 <Saulzar> Hmm, seems it can be larger..
20:22:54 <ricebowl> it can't
20:23:19 <Saulzar> Sure?
20:23:23 <ricebowl> these are NxN matrices, and xs is a subset of [0 .. N-1]
20:23:44 <ricebowl> I'm mapping a subset of elements in the matrix into a smaller one
20:23:55 <ricebowl> hold on, I just had an idea.
20:24:10 <Saulzar> n is not the size of the array
20:24:16 <Saulzar> n is the last element...
20:24:16 <ricebowl> the function that appears to cause the error does not index an array, *but* laziness would cause other arrays to not be evaluated
20:24:19 <ricebowl> so I can trace backward
20:24:32 <ricebowl> Saulzar - yes, that's why I said a subset of 0..N-1
20:24:52 <ricebowl> it works fine on one test case, but on my hand-crafted test case it fails
20:25:14 <ricebowl> the only difference, come to think of it, is that mine has a pair of disjoint graphs whereas in the other all nodes are connected
20:39:31 * shapr yodels fetchingly
20:40:09 <Cale> heh, that's a nice out of context quote :)
20:40:45 <Cale> (noting that I've been quoted)
20:40:54 <Cale> took me a while to realise when I'd said that
20:41:02 <ricebowl> aha, I have discovered the error
20:41:17 <ricebowl> that was...dumb
20:44:34 <shapr> Cale: Overall, that's a cool quote.
20:44:51 * shapr is very good at seeing things out of context.
20:45:32 <Lemmih> What quote?
20:45:35 <dons> @help lam 
20:45:36 <lambdabot> Evaluate terms of the pure, untyped lambda calculus
20:45:36 <lambdabot> darcs get http://www.eecs.tufts.edu/~rdocki01/lambda
20:45:38 <dons> :)
20:45:41 <Cale> <Cale> a bunch of oranges, one red
20:45:42 <dons> @lam \x . x
20:45:43 <lambdabot> \x. x
20:45:45 <dons> @lam S
20:45:46 <lambdabot> \f. \g. \x. f x (g x)
20:45:53 <dons> @lam fac
20:46:09 <dons> @lam four
20:46:27 <Cale> @bot
20:46:42 <shapr> dons: How does lam compare to @lambda ?
20:46:46 <Pupeno> Anyone interested in the Haskell repository for (K)Ubuntu ? http://pupeno.com/blog/a-haskell-repository
20:46:48 <dons> I hope lambdabot kills that fac thread.
20:47:03 <dons>  @lam is then new lambdaShell (see haskell.lorg)
20:47:36 <Lemmih> Pupeno: Neat!
20:47:52 <dons> not haskell.org, haskell@
20:48:08 <lambdabot> lShell module failed: thread killed
20:48:08 <lambdabot> \f. \x. f (f (f (f x)))
20:48:08 <lambdabot> :)
20:48:08 <Cale> @where lambdashell
20:48:08 <lambdabot> darcs get http://www.eecs.tufts.edu/~rdocki01/lambda/
20:48:26 <Cale> @lam fac four
20:48:27 <lambdabot> \f. \x. f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (f (
20:48:27 <lambdabot> f (f x)))))))))))))))))))))))
20:48:30 <dons> need to put a timeout on lambdaShell.
20:48:39 <Cale> @lam fac S
20:48:39 <lambdabot> \f. \g. \x. x (g x)
20:48:46 <dons> it has a pretty extensive prelude
20:49:01 <Cale> @lam X
20:49:02 <lambdabot> variable 'X' not in scope
20:49:07 <Cale> @lam K
20:49:08 <lambdabot> \x. \y. x
20:49:32 <Cale> @lam Y
20:49:53 <lambdabot> lShell module failed: thread killed
20:49:58 <Lemmih> @karma+ Pupeno 
20:49:58 <lambdabot> Pupeno's karma raised to 1.
20:50:10 <Pupeno> :)
20:50:14 <dons> stupid Y combinator ;)
20:50:29 <Pupeno> Lemmih: thanks. :)
20:51:04 <Cale> @lam id
20:51:04 <lambdabot> variable 'id' not in scope
20:51:17 <Cale> @lam Y (\x. x)
20:51:32 <dons> http://www.cse.unsw.edu.au/~dons/code/lambdabot/State/prelude.lam
20:51:33 <lambdabot> lShell module failed: thread killed
20:53:34 <Cale> @lam omega
20:54:20 <lambdabot> lShell module failed: thread killed
20:54:32 <Cale> @lam fst (pair three four)
20:54:33 <lambdabot> three
20:54:39 <Cale> @lam snd (pair three four)
20:54:40 <lambdabot> four
20:54:43 <Cale> @lam snd (pair three b)
20:54:44 <lambdabot> variable 'b' not in scope
20:54:51 <Cale> @lam \b. snd (pair three b)
20:54:52 <lambdabot> \b. b
20:56:04 <Cale> @lam not true
20:56:04 <lambdabot> false
20:56:17 <Cale> @lam not K
20:56:18 <lambdabot> false
20:57:38 <Cale> fac fst
20:57:41 <Cale> @lam fac fst
20:57:41 <lambdabot> \x. \y. \u. u
20:58:11 <Cale> @lam fac succ
20:58:11 <lambdabot> \f. f
20:58:26 <Cale> @lam succ succ
20:58:26 <lambdabot> \f. \x. f (\x_0. x (f x x_0))
20:58:40 <Cale> @lam succ succ zero
20:58:41 <lambdabot> \x. \x_0. x_0
20:58:46 <Cale> @lam succ (succ zero)
20:58:46 <lambdabot> \f. \x. f (f x)
20:59:29 <Cale> @lam not cons
20:59:30 <lambdabot> \w. w (\f. \x. f x) (\f. f (\t. \f_0. f_0) true)
20:59:55 <Saulzar> @lam two
20:59:55 <lambdabot> \f. \x. f (f x)
21:00:12 <Cale> @lam mul two two
21:00:12 <lambdabot> \f. \x. f (f (f (f x)))
21:00:18 <Cale> @lam mul two two = four
21:00:18 <lambdabot> expecting space, "(", "\\", letter, white space or end of input
21:00:39 <Cale> @lam mul two two == four
21:00:40 <lambdabot> equal
21:01:00 <Pupeno> musasabi: are you here ?
21:01:28 * shapr burbles
21:02:08 * waltz admires lambdabot's functionality
21:03:35 <Cale> @lam omega == omega
21:04:46 <lambdabot> lShell module failed: thread killed
21:05:28 <jimapple> @djinn-env
21:05:28 <lambdabot> data () = ()
21:05:29 <lambdabot> data Either a b = Left a | Right b
21:05:29 <lambdabot> data Maybe a = Nothing | Just a
21:05:29 <lambdabot> data Bool = False | True
21:05:29 <lambdabot> data Void
21:05:31 <lambdabot> type Not x = x -> Void
21:05:45 <jimapple> @listcommands djinn
21:05:45 <lambdabot> djinn provides: djinn djinn-add djinn-del djinn-env djinn-clr djinn-
21:05:45 <lambdabot> ver
21:06:13 <jimapple> @djinn-add data Equiv a b = (a -> b, b -> a)
21:06:14 <lambdabot> Cannot parse command
21:06:40 <jimapple> @djinn-add data Equiv a b = Equiv (a ->b) (b -> a)
21:06:49 <jimapple> @djinn-env
21:06:49 <lambdabot> data () = ()
21:06:49 <lambdabot> data Either a b = Left a | Right b
21:06:49 <lambdabot> data Maybe a = Nothing | Just a
21:06:49 <lambdabot> data Bool = False | True
21:06:49 <lambdabot> data Void
21:06:51 <lambdabot> type Not x = x -> Void
21:06:53 <lambdabot> data Equiv a b = Equiv (a -> b) (b -> a)
21:07:01 <jimapple> @djinn Equiv a a
21:07:02 <lambdabot> f = Equiv (\ a -> a) (\ b -> b)
21:07:15 <jimapple> @djinn Equiv (a,b) (b,a)
21:07:15 <lambdabot> f = Equiv (\ (a, b) -> (b, a)) (\ (c, d) -> (d, c))
21:07:33 <jimapple> @djinn Equiv (a,b) (Either a b)
21:07:33 <lambdabot> -- f cannot be realized.
21:07:37 <Cale> @djinn Equiv (Either a ()) (Maybe a)
21:07:38 <lambdabot> f = Equiv (\ _ -> Nothing) (\ a ->
21:07:38 <lambdabot>           case a of
21:07:38 <lambdabot>           Nothing -> Right ()
21:07:38 <lambdabot>           Just b -> Left b)
21:08:03 <jimapple> @djinn Equiv (Not (Not a) -> a) (Either (Not a) a)
21:08:03 <lambdabot> -- f cannot be realized.
21:08:10 <dons> the only theorem proving irc bot in town :)
21:08:37 <jimapple> @djinn Either (Not a) a -> (Not (Not a)) -> a
21:08:37 <lambdabot> f a b =
21:08:37 <lambdabot>   case a of
21:08:37 <lambdabot>   Left c -> void (b c)
21:08:37 <lambdabot>   Right d -> d
21:09:26 <jimapple> @djinn help
21:09:27 <lambdabot> -- f cannot be realized.
21:09:35 <jimapple> @listcommands djinn
21:09:35 <lambdabot> djinn provides: djinn djinn-add djinn-del djinn-env djinn-clr djinn-
21:09:35 <lambdabot> ver
21:09:40 <jimapple> @djinn-clr
21:09:43 <jimapple> @djinn-env
21:09:44 <lambdabot> data () = ()
21:09:44 <lambdabot> data Either a b = Left a | Right b
21:09:44 <lambdabot> data Maybe a = Nothing | Just a
21:09:44 <lambdabot> data Bool = False | True
21:09:44 <lambdabot> data Void
21:09:45 <Cale> @djinn Equiv (Equiv a b) (a -> b, b -> a)
21:09:45 <lambdabot> type Not x = x -> Void
21:09:47 <lambdabot> -- f cannot be realized.
21:09:59 <Cale> oh
21:10:03 <jimapple> sorry
21:10:08 <jimapple> want to make it a type, not a data
21:10:11 <Cale> @djinn-add data Equiv a b = Equiv (a ->b) (b -> a)
21:10:15 <Cale> oh
21:10:18 <Cale> @djinn Equiv (Equiv a b) (a -> b, b -> a)
21:10:19 <lambdabot> f = Equiv (\ a ->
21:10:19 <lambdabot>     case a of
21:10:19 <lambdabot>     Equiv _ _ -> c99) (\ (b, c) -> Equiv b c)
21:10:29 <Cale> @djinn-clr
21:10:40 <jimapple> @djinn-clr
21:10:40 <jimapple> @djinn-add type Equiv a b = (a -> b, b -> a)
21:10:41 <Cale> @djinn-add type Equiv a b = (a ->b, b -> a)
21:10:44 <Cale> hehe
21:11:00 <jimapple> @djinn-env
21:11:00 <lambdabot> data () = ()
21:11:00 <lambdabot> data Either a b = Left a | Right b
21:11:00 <lambdabot> data Maybe a = Nothing | Just a
21:11:00 <lambdabot> data Bool = False | True
21:11:00 <lambdabot> data Void
21:11:02 <lambdabot> type Not x = x -> Void
21:11:04 <lambdabot> type Equiv a b = (a -> b, b -> a)
21:11:40 <jimapple> @djinn-new type Contra a = Not (Not a)
21:11:40 <lambdabot> Maybe you meant: djinn-del djinn-ver
21:11:53 <Cale> @djinn-ad type Contra a = Not (Not a)
21:12:12 <jimapple> @djinn a -> Contra a
21:12:12 <lambdabot> f a b = b a
21:12:27 <jimapple> @djinn Contra (Contra a -> a)
21:12:27 <lambdabot> f a = void (a (\ b -> void (b (\ c -> a (\ _ -> c)))))
21:13:15 <jimapple> @djinn (Contra a -> a) -> (Either (Not a) a)
21:13:16 <lambdabot> -- f cannot be realized.
21:13:28 <Cale> @djinn Either a (Either (Not a) (Contra a))
21:13:29 <lambdabot> -- f cannot be realized.
21:13:39 <jimapple> @djinn Contra ((Contra a -> a) -> (Either (Not a) a))
21:13:40 <lambdabot> f a =
21:13:40 <lambdabot>   void (a (\ b ->
21:13:40 <lambdabot>      void (a (\ _ -> Right (b (\ c -> void (a (\ _ -> Left c))))))))
21:13:50 <jimapple> @djinn (Contra a -> a) -> Contra (Either (Not a) a)
21:13:50 <lambdabot> f a b = void (b (Right (a (\ c -> void (b (Left c))))))
21:14:33 <shapr> Hey, this is really cool http://lambda-the-ultimate.org/node/view/1183#comment-12896
21:14:37 <Cale> @djinn Contra (Either (Not a) a)
21:14:38 <lambdabot> f a = void (a (Left (\ b -> a (Right b))))
21:14:53 <jimapple> @djinn-add type Taut a = Either (Not a) a
21:14:54 <shapr> That link includes nifty stuff like: data MaybeSig x = Nothing
21:15:00 <shapr> data NonDetSig x = Fail | Amb x x
21:15:01 <jimapple> @djinn Contra (Taut a)
21:15:01 <lambdabot> f a = void (a (Left (\ b -> a (Right b))))
21:15:04 <shapr> data EitherSig s x = Error s
21:15:18 <shapr> Those things make perfect sense. Maybe that should be my Xmas TMR article?
21:16:05 * shapr wonders if GADT type sigs will improve clarity.
21:16:31 <jimapple> @djinn Contra (Not a) -> (Not a)
21:16:32 <lambdabot> f a b = void (a (\ c -> c b))
21:17:26 <jimapple> @djinn-add type Pierce a b = ((a->b)->a)->a
21:17:37 <jimapple> @djinn Taut a -> Pierce a b
21:17:37 <lambdabot> f a b =
21:17:37 <lambdabot>   case a of
21:17:37 <lambdabot>   Left c -> b (\ d -> void (c d))
21:17:37 <lambdabot>   Right e -> e
21:17:45 <jimapple> @djinn Pierce a b -> Taut a
21:17:45 <lambdabot> -- f cannot be realized.
21:17:58 <jimapple> @djinn Contra (Taut a)
21:17:59 <lambdabot> f a = void (a (Left (\ b -> a (Right b))))
21:18:25 <Cale> @djinn Taut Void
21:18:26 <shapr> I wish I knew enough math to see why being a free algebra is useful.
21:18:26 <lambdabot> f = Left (\ a -> a)
21:18:57 <jimapple> @djinn (Pierce a b) -> (Contra a -> a)
21:18:57 <lambdabot> -- f cannot be realized.
21:19:08 <jimapple> @djinn (Pierce a b) -> (Contra b -> b)
21:19:09 <lambdabot> -- f cannot be realized.
21:19:16 <Cale> @djinn Taut ()
21:19:17 <lambdabot> f = Right ()
21:19:24 <Cale> @djinn Taut (a -> a)
21:19:25 <lambdabot> f = Right (\ a -> a)
21:19:44 <jimapple> @djinn (Contra a -> a) -> (Pierce a b)
21:19:44 <lambdabot> f a b = a (\ c -> void (c (b (\ d -> void (c d)))))
21:19:59 <jimapple> @djinn Taut (Taut a)
21:19:59 <lambdabot> -- f cannot be realized.
21:20:11 <Cale> @djinn Taut (Not a)
21:20:12 <lambdabot> -- f cannot be realized.
21:20:30 <jimapple> @djinn Taut (Contra a)
21:20:31 <lambdabot> -- f cannot be realized.
21:20:33 <shapr> hiya binaryechoes, learning Haskell?
21:21:00 <Cale> @djinn Taut (Pierce a b)
21:21:00 <jimapple> @djinn Taut (Not (Contra a))
21:21:00 <lambdabot> -- f cannot be realized.
21:21:01 <lambdabot> -- f cannot be realized.
21:21:14 <jimapple> @djinn Contra (Pierce a b)
21:21:14 <lambdabot> f a =
21:21:14 <lambdabot>   void (a (\ b -> void (a (\ _ -> b (\ c -> void (a (\ _ -> c)))))))
21:21:43 <Cale> @djinn Not (Contra a) -> Not a
21:21:43 <lambdabot> f a b = void (a (\ c -> c b))
21:22:06 <jimapple> This is the only one that I think is really interesting:
21:22:06 <jimapple> @djinn (Contra a -> a) -> (Pierce a b)
21:22:07 <lambdabot> f a b = a (\ c -> void (c (b (\ d -> void (c d)))))
21:22:33 <Taral> @help djinn
21:22:34 <lambdabot> Generates Haskell code from a type.
21:22:34 <lambdabot> http://darcs.augustsson.net/Darcs/Djinn
21:22:34 <shapr> Good morning Taral, how's code?
21:22:39 <Taral> Bah, code is slow.
21:22:41 <Taral> @dji
21:22:42 <lambdabot> Maybe you meant: djinn djinn-add djinn-clr djinn-del djinn-env djinn-
21:22:42 <lambdabot> ver
21:22:45 <Taral> @djinn-env
21:22:45 <lambdabot> data () = ()
21:22:45 <lambdabot> data Either a b = Left a | Right b
21:22:45 <lambdabot> data Maybe a = Nothing | Just a
21:22:45 <lambdabot> data Bool = False | True
21:22:45 <lambdabot> data Void
21:22:48 <lambdabot> type Not x = x -> Void
21:22:50 <lambdabot> type Pierce a b = ((a -> b) -> a) -> a
21:22:51 <Taral> What are Contra and Pierce?
21:22:52 <lambdabot> type Taut a = Either (Not a) a
21:22:54 <lambdabot> type Contra a = Not (Not a)
21:22:56 <lambdabot> type Equiv a b = (a -> b, b -> a)
21:22:58 <Taral> oh
21:23:29 <Taral> @djinn Pierce a b
21:23:30 <lambdabot> -- f cannot be realized.
21:23:32 <shapr> What's the pierce thing?
21:23:38 <Taral> Pierce's law
21:23:43 <shapr> I assume it refers to BC Pierce?
21:23:43 <Taral> It's also the type of calCC
21:23:48 <Taral> callCC
21:23:58 <jimapple> I have learned more about it from djinn than I knew before!
21:24:06 <Taral> no
21:24:08 <Taral> it's misspelt
21:24:09 <jimapple> @djinn Taut a -> Pierce a b
21:24:09 <lambdabot> f a b =
21:24:09 <lambdabot>   case a of
21:24:09 <lambdabot>   Left c -> b (\ d -> void (c d))
21:24:09 <lambdabot>   Right e -> e
21:24:11 <Taral> It's Peirce's law
21:24:12 <Taral> Charles Sanders Peirce
21:24:15 <shapr> oho, http://en.wikipedia.org/wiki/Pierce's_law
21:24:20 <jimapple> d'oh!
21:24:29 <jimapple> stupid spelling!
21:24:38 <Taral> Common error.
21:25:32 <Cale> @djinn (Either a (Not b)) -> (a -> b)
21:25:32 <jimapple> Pierce is actually the weakest of the set (Contra a -> a) (Taut a) (Pierce a b)
21:25:32 <lambdabot> -- f cannot be realized.
21:25:45 <Cale> @djinn (Either (Not a) b) -> (a -> b)
21:25:45 <lambdabot> f a b =
21:25:45 <lambdabot>   case a of
21:25:45 <lambdabot>   Left c -> void (c b)
21:25:45 <lambdabot>   Right d -> d
21:25:59 <Cale> @djinn (a -> b) -> (Either (Not a) b)
21:26:00 <lambdabot> -- f cannot be realized.
21:26:01 * shapr has fun paying bills over the internet.
21:26:05 <shapr> @pay-bills
21:26:06 <lambdabot> Unknown command, try @listcommands.
21:26:21 <Cale> man that's annoying :)
21:26:40 <jimapple> @djinn (Taut a) -> ((a -> b) -> (Either (Not a) b))
21:26:41 * shapr is tempted to write a bill paying plugin.
21:26:41 <lambdabot> f a b =
21:26:41 <lambdabot>   case a of
21:26:41 <lambdabot>   Left c -> Left c
21:26:41 <lambdabot>   Right d -> Right (b d)
21:26:49 <Taral> @djinn (Contra a -> a) -> Taut a
21:26:49 <lambdabot> -- f cannot be realized.
21:26:56 <Taral> @djinn Taut a -> Contra a -> a
21:26:56 <lambdabot> f a b =
21:26:56 <lambdabot>   case a of
21:26:56 <lambdabot>   Left c -> void (b c)
21:26:56 <lambdabot>   Right d -> d
21:27:11 <jimapple> @djinn (Contra a -> a) -> ((a -> b) -> (Either (Not a) b))
21:27:11 <lambdabot> -- f cannot be realized.
21:27:20 <jimapple> @djinn (Pierce a b) -> ((a -> b) -> (Either (Not a) b))
21:27:21 <lambdabot> -- f cannot be realized.
21:27:22 <Taral> So Taut a -> (Contra a -> a) -> (Pierce a b) in order
21:27:34 <Taral> @djinn Taut a -> Either (Not a) b
21:27:35 <lambdabot> -- f cannot be realized.
21:27:39 <Taral> @djinn Taut a -> (a -> b) -> Either (Not a) b
21:27:40 <lambdabot> f a b =
21:27:40 <lambdabot>   case a of
21:27:40 <lambdabot>   Left c -> Left c
21:27:40 <lambdabot>   Right d -> Right (b d)
21:27:41 <jimapple> I agree
21:27:50 <shapr> Would someone be so kind as to write a TMR article describing the usefulness of Djinn?
21:28:01 <jimapple> @djinn Equiv (Taut a) ((a -> b) -> (Either (Not a) b))
21:28:02 <lambdabot> -- f cannot be realized.
21:28:03 <shapr> I'm lost :-(
21:28:12 <Taral> I'm not sure djinn is useful, really. More fun than useful.
21:28:22 <jimapple> I find it useful
21:28:28 <Taral> jimapple: For?
21:28:46 <Cale> Non-classical logics tend to annoy me for some reason :)
21:28:54 <jimapple> learning. Which I guess is as far as I find Haskell useful so far
21:29:02 <jimapple> Unless I get this job at Galois
21:29:05 <jimapple> :-)
21:29:10 <shapr> :-)
21:29:52 <dons> shapr, oh, I could write tbill pay plugin for you: payBill = const $ payBill "dons"
21:29:56 <jimapple> @djinn Equiv (for some reason) (because they are non-intuitive)
21:29:56 <lambdabot> Cannot parse command
21:30:12 <shapr> dons: Funny, but I wouldn't have internet then :-P
21:31:03 <jimapple> @djinn ((a -> b) -> (Either (Not a) b)) -> Pierce a b
21:31:04 <lambdabot> -- f cannot be realized.
21:31:18 <jimapple> @djinn ((a -> b) -> (Either (Not a) b)) -> Pierce a c
21:31:19 <lambdabot> -- f cannot be realized.
21:31:22 <Cale> @djinn Pierce (Pierce a b) b
21:31:23 <lambdabot> -- f cannot be realized.
21:31:30 <jimapple> @djinn ((a -> b) -> (Either (Not a) b)) -> Pierce b a
21:31:31 <lambdabot> -- f cannot be realized.
21:31:40 <Cale> @djinn Pierce (Pierce a b) c
21:31:40 <lambdabot> -- f cannot be realized.
21:32:22 <jimapple> This ((a -> b) -> (Either (Not a) b)) is enigmatic
21:32:45 <jimapple> Pierce and Contra a -> a cannot prove it, not can it prove them
21:32:54 <jimapple> however, Taut a can prove it
21:33:19 <jimapple> @djinn Not a -> Not b -> Equiv a b
21:33:20 <lambdabot> f a b = (\ c -> void (a c), \ d -> void (b d))
21:33:44 <jimapple> @djinn a->b -> Equiv a b
21:33:44 <lambdabot> f a b = (\ _ -> b, \ _ -> a)
21:34:10 <jimapple> @djinn Not a -> Equiv a Void
21:34:11 <lambdabot> f a = (a, void)
21:34:19 <Cale> heh
21:34:54 <Taral> @djinn ((a -> b) -> (Either (Not a) b)) -> Taut a
21:34:54 <lambdabot> -- f cannot be realized.
21:34:56 <Taral> hm!
21:35:13 <jimapple> yeah, it's somewhere out there
21:35:25 <Taral> @djinn (b -> a) -> (Either (Not a) b) -> Taut a
21:35:25 <lambdabot> f a b =
21:35:25 <lambdabot>   case b of
21:35:25 <lambdabot>   Left c -> Left c
21:35:25 <lambdabot>   Right d -> Right (a d)
21:35:52 <Taral> @djinn ((a -> a) -> (Either (Not a) a)) -> Taut a
21:35:53 <lambdabot> f a =
21:35:53 <lambdabot>   case a (\ b -> b) of
21:35:53 <lambdabot>   Left c -> Left c
21:35:53 <lambdabot>   Right d -> Right d
21:35:54 <Taral> !
21:36:06 <Taral> weird derivation
21:36:57 <Taral> I think it's because of the scope of b's quantifier.
21:37:17 <Taral> '(forall b. (a -> b) -> Either (Not a) b) -> Taut a' probably works
21:37:51 * juhp wonders what happened to the gtk support in yi, or if he is cracking up?
21:38:11 <Cale> juhp: there are two branches of yi
21:38:19 <juhp> oh
21:38:21 <jimapple> @djinn-add type MystL a b = (a->b)->(Either (Not a) b)
21:38:21 <jimapple> @djinn-add type MystR a b = (b->a)->(Either (Not a) b)
21:38:21 <jimapple> @djinn-add type StymL a b = (Either (Not a) b) -> a -> b
21:38:21 <jimapple> @djinn-add type StymR a b = (Either (Not a) b) -> b -> a
21:38:43 <juhp> Cale: so the scannedinavian branch is the one I want?
21:38:55 <dons> yep, it's also at: 
21:38:58 <dons> @where yi+gtk
21:38:58 <lambdabot> darcs get http://www.scannedinavian.org/repos/yi/
21:39:04 <jimapple> @djinn Equiv (MystL a b) (Taut a)
21:39:05 <lambdabot> -- f cannot be realized.
21:39:05 <Cale> juhp: probably, if you're looking for something that looks pretty but doesn't do much :)
21:39:14 <juhp> Cale: heh
21:39:17 <dons> right.
21:39:17 <Cale> can it even save yet?
21:39:21 <jimapple> @djinn Equiv (MystL a b) (Taut b)
21:39:22 <lambdabot> -- f cannot be realized.
21:39:30 <dons> hmm, can't rmemeber. i've been working on the curses versoin of late.
21:39:40 <dons> I think it can, yes.
21:39:41 <jimapple> @djinn Equiv (MystR a b) (Taut a)
21:39:41 <lambdabot> -- f cannot be realized.
21:39:48 <Cale> dons: it's too bad that they're not unified
21:39:52 <jimapple> @djinn Equiv (StymL a b) (Taut a)
21:39:52 <lambdabot> -- f cannot be realized.
21:40:02 <jimapple> @djinn Equiv (StymR a b) (Taut a)
21:40:03 <lambdabot> -- f cannot be realized.
21:40:07 <juhp> Cale: last I tried it coundn't even delete (with hanging;)
21:40:30 <Cale> juhp: it would crash for me if I held down a key
21:40:37 <jimapple> @djinn MystL a b
21:40:37 <jimapple> @djinn MystR a b
21:40:37 <jimapple> @djinn StymL a b
21:40:37 <jimapple> @djinn StymR a b
21:40:38 <lambdabot> -- f cannot be realized.
21:40:38 <lambdabot> -- f cannot be realized.
21:40:38 <lambdabot> f a b =
21:40:38 <lambdabot>   case a of
21:40:38 <lambdabot>   Left c -> void (c b)
21:40:40 <lambdabot>   Right d -> d
21:40:42 <lambdabot> -- f cannot be realized.
21:42:59 <jimapple> @djinn (Equiv (Either (Not a) b) (a -> b)) -> Taut a
21:43:00 <lambdabot> -- f cannot be realized.
21:43:11 <jimapple> @djinn (Equiv (Either (Not a) b) (a -> b)) -> Pierce a c
21:43:11 <lambdabot> -- f cannot be realized.
21:44:16 <jimapple> I have no idea what MystR and StymR are supposed to be
21:44:26 <jimapple> And I can take this all offline if it's bothering y'all
21:44:40 <jimapple> @where djinn
21:44:40 <lambdabot> darcs get http://darcs.augustsson.net/Darcs/Djinn
21:45:39 <Taral> @djinn Not (((a -> b) -> (Either (Not a) b)) -> Taut a)
21:45:39 <lambdabot> -- f cannot be realized.
21:45:50 <Taral> neither true nor false, hm
21:46:08 <Korollary> you can also private message the bot
21:46:35 <jimapple> duh! Thanks Korollary
21:46:57 <jimapple> I think I'll keep a session at home, too
21:47:05 <jimapple> then bring y'all the nice results
21:47:16 <jimapple> @djinn Contra (((a -> b) -> (Either (Not a) b)) -> Taut a)
21:47:16 <lambdabot> f a = void (a (\ _ -> Left (\ b -> a (\ _ -> Right b))))
21:47:38 <jimapple> @djinn Contra (Taut a)
21:47:38 <lambdabot> f a = void (a (Left (\ b -> a (Right b))))
21:48:14 <jimapple> @djinn Contra (((a -> b) -> (Either (Not a) b)) -> Taut a)
21:48:14 <jimapple> @more
21:48:15 <lambdabot> f a = void (a (\ _ -> Left (\ b -> a (\ _ -> Right b))))
21:56:25 <Taral> @djinn Contra (Taut a)
21:56:26 <lambdabot> f a = void (a (Left (\ b -> a (Right b))))
21:56:42 <Taral> @djinn (Taut a -> b) -> Contra b
21:56:42 <lambdabot> f a b = void (b (a (Left (\ c -> b (a (Right c))))))
21:56:45 <Taral> interesting
21:56:53 <Taral> @djinn Equiv (Taut a -> b) (Contra b)
21:56:54 <lambdabot> -- f cannot be realized.
21:56:56 <Taral> hm!
22:05:04 <Lemmih> SamB, jlouis: ping.
22:10:01 <Taral> wonder what happened to ski's linear logic programming language
22:13:42 <Taral> @when ski
22:13:42 <lambdabot> Maybe you meant: seen what where wn
22:13:46 <Taral> @seen wki
22:13:46 <lambdabot> I haven't seen wki.
22:13:49 <Taral> @seen ski
22:13:50 <lambdabot> Last time I saw ski was when I left #flippi, #gentoo-haskell, #haskell, #
22:13:50 <lambdabot> haskell-blah, #haskell-overflow, #haskell.es, #haskell.it and #scannedinavi
22:13:50 <lambdabot> an 1 day, 6 hours, 40 minutes and 12 seconds ago, and I have missed 1 day,
22:13:50 <lambdabot> 19 minutes and 8 seconds since then.
22:13:54 <Taral> hm
22:14:40 <jimapple> @uptime
22:14:40 <lambdabot> uptime: 6 hours, 13 minutes and 25 seconds
22:23:51 <Spark> haha lambdabot cant sustain a connection
22:24:27 <dons> umm, i've been working on lambdabot today, several core components were modified, hence the downtime.
22:32:52 <Spark> shame its not written in erlang :)
22:35:20 <dons> lambdabot is made up of hotswappable components, we just don't always hot swap them when inserting new code.
22:35:32 <dons> @dynamic-reload version
22:35:32 <lambdabot> module reloaded
22:36:44 <Spark> surely there is a core that cant be swapped though
22:37:12 <dons> it can be, but we don't usually use that feature.
22:37:16 <Spark> when i was writing a bot to learn java, i toyed with the idea of having a swappable core but gave up on the idea as it sounded too complicated :)
22:37:34 <dons> @where dynamic applications from the ground up
22:37:34 <lambdabot> I know nothing about dynamic.
22:37:42 <Cale> dons: How does one actually swap out the core?
22:37:43 <dons> @google dynamic applications from the ground up
22:37:44 <lambdabot> http://www.cse.unsw.edu.au/~dons/papers/SC05.html
22:37:52 <lispy> when i was writing an interpreter in java i was going to make it generate bytecode for everything dynamically
22:38:10 <lispy> but...then i had better things to do :)
22:38:27 <dons> Cale, flush the state, jump to the dyn linker, reload the new core, reenter through the quick reentry point
22:38:59 <dons> I don't bother running that code on lamdbabot on #haskell though. there's no pressing demand
22:39:22 <dons> @quit more code
22:39:31 <dons> @lam Y
22:39:55 <lambdabot> Terminated
22:40:06 <dons> good-o.
22:40:49 <Spark> @lam Y Y
22:41:01 <lambdabot> Terminated
22:41:04 <araujo> Hello people!
22:41:23 <dons> @version
22:41:24 <lambdabot> lambdabot 3p266, GHC 6.5.20050806 (Linux i686)
22:41:24 <lambdabot> darcs get http://www.cse.unsw.edu.au/~dons/code/lambdabot
22:41:26 <Spark> does terminated mean "artificially terminated"
22:41:45 <Cale> yeah
22:41:47 <dons> lambdaShell gives up after a point.
22:41:57 <Spark> http://www.cse.unsw.edu.au/~pls/images/pls-small.png
22:41:57 <dons> I patched it to do this.
22:42:00 <Spark> dons: that image cracked me up
22:42:18 <dons> that's our logo :)
22:42:38 <Spark> ive yet to see ecstacy pills with a lambda logo
22:42:40 <Spark> but i think that would rock
22:42:55 <Spark> 2D2D"hey dude got any lambdas?"
22:43:27 <Pupeno> are tail-call optimized in haskell like in Scheme ?
22:43:37 <dons> they're gootos
22:43:50 <dons> so yep.
22:43:50 <Pupeno> thanks.
22:43:56 <Korollary> that's an implementation question actually
22:44:21 <Korollary> Does the report mandate that they be optimized like r5rs does?
22:44:33 <dons> not that I can recall
22:48:16 <Korollary> dons: The Simons have always been helpful, but have they seemed more helpful that usual to you in the recent past?
22:48:29 <Korollary> that=than
22:53:25 <dons> more helpful than usual? hmm. didn't notice. they are trying to encourage people to contribute.
22:54:27 <Pupeno> lisppaste2: url
22:54:28 <lisppaste2> To use the lisppaste bot, visit http://paste.lisp.org/new/haskell and enter your paste.
22:54:57 <dons> lisppaste2: funky monkey
22:55:00 <lisppaste2> Pupeno pasted "Fibonacci" at http://paste.lisp.org/display/14861
22:55:10 <dons> oh, it ignored me. :/
22:55:15 <Pupeno> Is there a more Haskellish way of defining fibonacci ?
22:55:30 <dons> oh boy :$
22:55:40 <araujo> Pupeno, No, that is a scheme way
22:55:42 <araujo> :-)
22:56:00 <Pupeno> araujo: yes, that is scheme way, what would be the Haskell way ?
22:56:41 <dons> > take 10 $ scanl (+) 0 [1..]
22:56:42 <lambdabot> [0,1,3,6,10,15,21,28,36,45]
22:56:44 <dons> oh, um.
22:56:46 <araujo> > let fibs@(0:tfibs) = 0 : 1 : [ a + b | (a, b) <- zip tfibs fibs ] in take 9 $ fibs
22:56:47 <lambdabot> [0,1,1,2,3,5,8,13,21]
22:56:53 <araujo> Something like that :-)
22:58:15 <dons> > take 10 $ fix $ \f -> 1 : 1 : zipWith (+) f (tail f)
22:58:17 <lambdabot> [1,1,2,3,5,8,13,21,34,55]
22:58:27 <dons> oh, it's just not my fibbing day
22:58:55 <Taral> > take 10 $ scanl (+) 1 [1..]
22:58:56 <lambdabot> [1,2,4,7,11,16,22,29,37,46]
22:58:58 <Taral> hm
22:59:27 <Pupeno> I just want fib of n, not fib up to n.
23:00:06 <araujo> dons, :-)
23:00:07 <dons> once you've got the list, you've got any `n'
23:00:16 <Taral> > let { fib' 1 a b = a; fib' n a b = fib' (n-1) b (a+b); fib n = fib' n 1 1 } in fib 5
23:00:17 <lambdabot> 5
23:00:19 <Taral> > let { fib' 1 a b = a; fib' n a b = fib' (n-1) b (a+b); fib n = fib' n 1 1 } in fib 6
23:00:20 <lambdabot> 8
23:00:25 <dons> > flip (!!) 10 $ fix $ \f -> 1 : 1 : zipWith (+) f (tail f)
23:00:26 <lambdabot> 89
23:00:26 <Taral> > let { fib' 1 a b = a; fib' n a b = fib' (n-1) b (a+b); fib n = fib' n 1 1 } in map fib [1..10]
23:00:27 <lambdabot> [1,1,2,3,5,8,13,21,34,55]
23:01:18 <araujo> Any disciple of Buddha here?
23:01:30 <dons> > take 10 $ fix $ \f -> 0 : 1 : zipWith (+) f (tail f)   -- seems nice
23:01:31 <lambdabot> [0,1,1,2,3,5,8,13,21,34]
23:03:01 <dons> @pl \f -> 0 : 1 : zipWith (+) f (tail f)
23:03:02 <lambdabot> (0 :) . (1 :) . ap (zipWith (+)) tail
23:03:17 <dons> > take 10 $ fix $ (0 :) . (1 :) . ap (zipWith (+)) tail
23:03:18 <lambdabot> [0,1,1,2,3,5,8,13,21,34]
23:03:20 <araujo> @index ap
23:03:20 <lambdabot> Control.Monad, Control.Monad.Reader, Control.Monad.Writer, Control.Monad.
23:03:20 <lambdabot> State, Control.Monad.RWS, Control.Monad.Identity, Control.Monad.Cont,
23:03:20 <lambdabot> Control.Monad.Error, Control.Monad.List, Data.Graph.Inductive.Query.
23:03:20 <lambdabot> ArtPoint, Data.Graph.Inductive.Query, Data.Graph.Inductive
23:03:27 <araujo> :-P
23:04:54 * Pupeno finds the scheme way easier to read :|
23:06:04 <Cale> hehe, you're likely to get a lot of unlikely answers :)
23:07:27 <Cale> my favourite is  fibs = 0 : 1 : zipWith (+) fibs (tail fibs)
23:08:11 <Cale> which is sort of what's up above there
23:09:55 <Cale> fib 0 = 0; fib 1 = 1; fib n = fib (n-1) + fib (n-2) also works, though you wouldn't want to actually use it
23:10:37 <araujo> I find that way hardest to read :-(
23:10:50 <Pupeno> Cale: that last one can't calculate 610.
23:11:00 <Pupeno> Cale: on my computer I mean.
23:11:11 <Cale> Pupeno: right, because there's way too much recalculation
23:11:21 <Cale> but you can use a simple trick to keep the results live
23:11:41 <Pupeno> memoization ?
23:11:48 <Cale> yep
23:11:56 <Cale> fibs = map fib [0..]
23:11:56 <Cale> fib 0 = 0
23:11:56 <Cale> fib 1 = 1
23:11:56 <Cale> fib n = fibs !! (n-1) + fibs !! (n-2)
23:12:26 <Cale> this is still not as good as fibs = 0 : 1 : zipWith (+) fibs (tail fibs), but perhaps it's easier to comprehend :)
23:12:56 <Cale> if you knew that you'd only need so many of them, you'd use an array
23:13:03 <Cale> and get constant time lookup
23:13:04 <Pupeno> all this started because I accidentaly trigger the calculation of fib 610 on the example on House, and it just halted. A colegue that is anti-any-language-but-C went and wrote fib in C and showed me how good was C that showed the result of fib 610 instantly.
23:13:43 <Cale> that does fib 610 quite quickly
23:13:58 <Cale> Did he use a bignum library?
23:14:22 <Cale> Or implement bignums himself?
23:14:39 <Cale> If he did neither, his program is incorrect :)
23:14:48 <Pupeno> I started to wrote fib on Haskell to the a fair comparition and before I finished my computer blowed up, the power suply cooler halted and you could almost fry an egg on the chasis, impresive. I couldn't finish fixing it before he left.
23:15:03 <Cale> > let fibs = 0 : 1 : zipWith (+) fibs (tail fibs) in fibs !! 610
23:15:04 <lambdabot> 135823697912782666169062844948067355657769395021071830756126284090342094529
23:15:04 <lambdabot> 01850178519363189834336113240870247715060398192490855
23:15:18 <Pupeno> Cale: neither, he used Double. Yes, his program would be incorrec, that is one other thing I would like to point out.
23:15:46 <Cale> Oh, with Double, you're going to get numerical problems fairly quickly
23:15:57 <Cale> and you can't even say that you're doing the same thing
23:17:38 <Cale> hmm, it actually does manage to stay fairly precise
23:17:43 <Pupeno> even for 61000 on ghci it takes a second or so here and he can't even dream about doing that on C (without using some lib for bignums).
23:17:45 <Cale> *Main> (fib 610) :: Double
23:17:45 <Cale> 1.358236979127825e127
23:17:45 <Cale> *Main> (fib 610) :: Integer
23:17:45 <Cale> 13582369791278266616906284494806735565776939502107183075612628409034209452901850178519363189834336113240870247715060398192490855
23:18:10 <Cale> yeah
23:18:57 <dons> lambdabot does  a pretty good job
23:19:07 <dons> > let fibs = 0 : 1 : zipWith (+) fibs (tail fibs) in fibs !! 700
23:19:08 <lambdabot> 874708149557528462039784130175713273423672409676973810742304325925275019112
23:19:08 <lambdabot> 90377655628227150878427331693193369109193672330777527943718169105124275
23:19:16 <dons> > let fibs = 0 : 1 : zipWith (+) fibs (tail fibs) in fibs !! 10000
23:19:17 <lambdabot> 336447648764317832666216120051075433103021484606800639065647699746800814421
23:19:17 <lambdabot> 666623681555955136337340255820653326808361593737347904838652682630408924630
23:19:17 <lambdabot> 564318873545443695598274916066020998841839338646527313000888302692356736131
23:19:17 <lambdabot> 351175792974378544137521305205043477016022647583189065278908551543661595829
23:19:17 <lambdabot> 872796829875106312005754287834532155151038708182989697916131278562650331954
23:19:18 <araujo> @karma++ lambdabot 
23:19:19 <lambdabot> [23 @more lines]
23:19:21 <lambdabot> lambdabot's karma raised to 9.
23:19:39 <araujo> @more
23:19:40 <dons> the C program's not going to get close to a 1 liner, for n == 10,000 :)
23:20:41 <dons> > let fibs = 0 : 1 : zipWith (+) fibs (tail fibs) in fibs !! 1000 :: Double
23:20:42 <lambdabot> 4.346655768693743e208
23:21:50 <Cale> It's still nowhere near as fast as mathematica though
23:21:55 <Pupeno> I am tring to understand that one liner, fibs is a(n infinite) list, right ?
23:22:01 <Cale> yes
23:22:09 <Cale> its first 2 elements are 0 and 1
23:22:24 <Cale> and the rest is the sum of the list with its tail
23:22:42 <Cale> think about how you'd determine the 3rd, 4th, elements in turn
23:23:12 <Cale> Mathematica can do Fibonacci[5000000] fairly quickly.
23:23:30 <astrolabe_> using a recursive algorithm?
23:23:36 <Cale> "Fibonacci[n] uses an iterative method based on the binary digit sequence of n. "
23:24:24 <astrolabe_> that's a bit cryptic
23:24:59 <Pupeno> *Main> fib 5000000
23:25:00 <Pupeno> *** Exception: stack overflow
23:26:15 <astrolabe_> You can work out powers with an iterative method based on the binary digit sequence of the exponent.
23:26:56 <Cale> Given that it's Wolfram, it's probably some cellular automaton :)
23:27:04 <astrolabe_> :)
23:27:14 <Taral> > let { fib' 1 a b = a; fib' n a b = fib' (n-1) b (a+b); fib n = fib' n 1 1 } in fib 10000
23:27:18 <lambdabot> 336447648764317832666216120051075433103021484606800639065647699746800814421
23:27:20 <lambdabot> 666623681555955136337340255820653326808361593737347904838652682630408924630
23:27:22 <lambdabot> 564318873545443695598274916066020998841839338646527313000888302692356736131
23:27:24 <lambdabot> 351175792974378544137521305205043477016022647583189065278908551543661595829
23:27:26 <lambdabot> 872796829875106312005754287834532155151038708182989697916131278562650331954
23:27:28 <lambdabot> [23 @more lines]
23:28:04 <Cale> I want to see an implementation which enumerates domino tilings of a 2-by-n checkerboard
23:28:44 <astrolabe_> why?
23:28:49 <Cale> Why not? :)
23:29:34 <astrolabe_> I mean, why isn't that a boring backtracking tree search?
23:29:35 <sieni> Cale: Isn't that easy as breathing?
23:30:05 <sieni> Cale: since you can't have two dominoes like that:
23:30:06 <sieni> **
23:30:07 <sieni>  **
23:30:11 <palomer> I can do it without breathing
23:30:29 <Cale> sieni: yeah, it's pretty easy
23:30:35 <Cale> just esoteric :)
23:30:41 <dons> > let fibs = 0 : 1 : zipWith (+) fibs (tail fibs) in fibs !! 113164
23:30:46 <lambdabot> Terminated
23:30:59 <dons> > let fibs = 0 : 1 : zipWith (+) fibs (tail fibs) in fibs !! 113163
23:31:04 <lambdabot> Terminated
23:31:12 <dons> bah, the load on the box is getting too high
23:31:17 <Cale> heh, do a probabilistic version by repeatedly tossing a coin (n-2) times, computing the probability of not getting 2 heads in a row, then multiplying by 2^(n-2)
23:31:31 <dons> so I wonder what the fastest 72 char fib in Haskell is?
23:32:05 <dons> which finds the highest `n'
23:32:17 <dons> inside the 3 second @eval limit ;)
23:32:36 <sieni> I wonder if one can do the matrix multiplication "trick" in one row
23:32:42 <astrolabe_> You know there's an analytic formula?
23:33:15 <sieni> astrolabe_: it doesn't help too much with usual floating point numbers
23:33:47 * palomer will be impressed when compilers will be able to optimize matrix multiplication to O(n^(1.2))
23:34:23 <dons> this shows the benefit of using compiled plugins to implement @eval -- you get much faster arithmetic
23:34:42 <astrolabe_> sieni: Are you talking about rounding errors?
23:34:45 <sieni> palomer: why is that?
23:34:49 <sieni> astrolabe_: yes
23:35:14 <palomer> actually, make that O(n^(2.2))
23:35:24 <palomer> sieni: because it'll be impressive
23:36:00 <sieni> palomer: probably, since the fastest known algorithm is slower than that :-)
23:36:11 <astrolabe_> but isn't it an O(n^3) problem?
23:36:20 <sieni> astrolabe_: no
23:36:30 <palomer> nonono, matrix multiplication can be done in O(n^(2+e)) for any e
23:36:34 <sieni> astrolabe_: http://en.wikipedia.org/wiki/Coppersmith-Winograd_algorithm
23:36:35 <palomer> e greater than 0
23:37:01 <sieni> palomer: is that so new a result that even wikipedia doesn't know about it?
23:37:37 <palomer> sieni: this is what my prof has claimed
23:37:39 <Pupeno> Cale: the third element is calculated as [0, 1] : [0, 1] + [1], which ends up being [0, 1, 1], but on the fourth I get: [0, 1, 1] : [0, 1, 1] + [1, 1], which end up as [0, 1, 1, 1, 2]. What am I doing wrong ?
23:37:51 <astrolabe_> Interesting, but I suspect practically not useful.
23:38:43 <palomer> I'm sure wikipedia is wrong with this one
23:38:47 <Cale> Pupeno: um, where did that extra 1 come from?
23:39:31 <sieni> palomer: well a reference would be nice to have
23:39:40 <Cale> palomer: really? I'd only ever heard n^2.376
23:39:47 <sieni> palomer: i had only heard of the coppersmith-winograd before
23:39:56 <Pupeno> Cale: from the third element.
23:40:30 <Pupeno> lisppaste2: url
23:40:30 <lisppaste2> To use the lisppaste bot, visit http://paste.lisp.org/new/haskell and enter your paste.
23:40:47 <lisppaste2> Pupeno pasted "my reasoning." at http://paste.lisp.org/display/14862
23:41:01 <Pupeno> Cale: that is what I did, evidently wrong.
23:41:06 <Cale> :?
23:41:22 <Cale> ++ ?
23:41:32 <Cale> oh
23:41:38 <Pupeno> yes
23:41:51 <sieni> palomer: but i'm not actively following the subject so I might have missed some recent breakthrough
23:42:01 <Cale> fibs = 0 : 1 : zipWith (+) fibs (tail fibs)
23:42:07 <Pupeno> Cale: I used : and ++ losely.
23:42:23 <Cale> = 0:1: zipWith (+) (0:1:...) (1:...)
23:42:49 <Pupeno> oh...
23:42:50 <Cale> = 0:1:1:zipWith (+) (1:1:..) (1:...)
23:43:27 <Cale> = 0:1:1:2:zipWith (+) (1:2:..) (2:...)
23:43:41 <Cale> and so on
23:43:51 <dons> we need a @reduce plugin ;)
23:44:04 <dons> an interface to buddha or hat.
23:44:51 <Pupeno> why is the second step = 0:1:1:zipWith (+) (1:1:..) (1:...) instead of fibs = 0 : 1 : 1 : zipWith (+) (0:1:1...) (1:1...) ?
23:45:34 <Cale> well, let's look at the definition of zipWith carefully
23:45:53 <Cale> zipWith z (a:as) (b:bs)
23:45:53 <Cale>                  =  z a b : zipWith z as bs
23:46:08 <Cale> so,
23:46:41 <Pupeno> oic!
23:47:02 <Cale> zipWith (+) fibs (tail fibs) = (head fibs + (head (tail fibs)) : zipWith (+) (tail fibs) (tail (tail fibs))
23:47:11 <ski> guten morgen, #haskell
23:47:17 <Cale> morning :)
23:47:31 <Pupeno> Cale: thank you. :)
23:48:03 <Cale> Pupeno: laziness takes some getting used to :)
23:48:33 <ski> > let fibs = 0 : zipwith (+) (1 : fibs) fibs in take 10 fibs
23:48:33 <lambdabot>  Not in scope: `zipwith'
23:48:39 <ski> > let fibs = 0 : zipWith (+) (1 : fibs) fibs in take 10 fibs
23:48:41 <lambdabot> [0,1,1,2,3,5,8,13,21,34]
23:48:52 <ski> (that's an interesting varaint)
23:48:56 <Pupeno> Cale: indeed! but it is awesome.
23:49:06 <Cale> Pupeno: yep! :)
23:49:07 <Taral> ski: Any luck with your linear logic?
23:49:23 <ski> Taral : in what sense ?
23:49:31 <Taral> You were going to make a programming language out of it.
23:49:42 <Taral> All I found on the web were Prolog-derived things.
23:49:46 <ski> i want that, yes
23:50:09 <ski> linear logic can be used as a logic programming langague, too, yes
23:50:21 <Taral> logic programming languages make me twitch
23:50:23 <ski> i'm here more interested in basing a type system on it, though
23:50:29 <Taral> ah
23:50:34 <araujo> > let fibs = f where (a, b, f) = ((0 : 1 : b), zipWith (+) f a, tail a) in fibs !! 50000
23:50:36 <lambdabot> 174387413787277868303885543307269901639446115687823897326398233647860412089
23:50:36 <lambdabot> 391505107254431312183056302916200501379255920599759812636064902520844728036
23:50:36 <lambdabot> 035914484247957078465474043135755164882363827197961712407138357532419434916
23:50:36 <lambdabot> 225124765377005911110023797889395428855932145450462321511898812985287145889
23:50:36 <lambdabot> 864788909993349356468830629487132792557477522572294445428661430474574070611
23:50:38 <lambdabot> [23 @more lines]
23:51:04 * araujo throws some cookies at lambdabot 
23:51:06 <ski> (though, possibly one could have interesting synergy with a logic programming lang based on lin.log. and whose type-sys also is based on lin.log. :)
23:51:13 <dany2k|uni-na> sry for that noob question, how can i invite lambdabot to join anothre channel too?
23:51:20 * ski has some ideas
23:51:33 <ski> @join #math
23:51:33 <lambdabot> Not enough privileges
23:51:36 <Taral> ski: I have to go sleep, but mail me your ideas, maybe?
23:51:49 <dany2k|uni-na> thx, ski 
23:51:57 <ski> Taral : well, i don't have very concrete ideas, yet ..
23:52:05 <Taral> oh, well :)
23:52:14 <Taral> I am still interested, but it is late here in the US.
23:52:29 <ski> well, for some parts i have more concrete ideas, maybe i should say
23:52:46 <ski> Taral : have you looked at Clean (or Mercury) ?
23:52:54 <Taral> I've seen Clean
23:53:11 <Taral> Their type annotations are interesting but kludgy.
23:53:34 <ski> ok, that's partly based on lin.log.  though there is nothing like add. conj. (not to mention classicalities like mult. disj.) there
23:53:48 <Taral> *nod*
23:53:54 <tuomov> But it's supposed to be Clean, not kludgy!
23:54:06 * ski chuckles
23:54:09 <Taral> I'm not sure that CLL is useful for a type system. Would ILL suffice?
23:54:26 <ski> well, it'd still be interesting
23:54:38 <ski> add. conj. is in ILL
23:54:41 <Taral> yes
23:54:46 <Taral> the only missing thing is mult. conj.
23:54:48 <Taral> er
23:54:50 <Taral> mult. disj.
23:54:57 <ski> yeah
23:55:16 * ski has a few ideas of syntax for proff-terms for mult. disj.
23:55:23 <Taral> you have lin. impl., it should be enough
23:55:54 <ski> (doesn't give same power, unless we have negation)
23:56:00 <Taral> not a = a -> False
23:56:06 <ski> (also, 'why not' could be interesting)
23:56:22 <ski> (i meant an involuent negation)
23:56:23 <Taral> I think negation in a type system is of extremely limited use.
23:56:35 <ski> negation is continuation
23:56:42 <Taral> ?
23:56:59 <Taral> that's a very interesting statement, what do you mean by it?
23:57:08 <ski> a value of type 'Not a' is a continuation accepting value of type 'a'
23:57:22 <Taral> Interesting!
23:57:26 <ski> yes
23:57:40 <Cale> Only sort of :)
23:57:42 <Taral> heh
23:57:58 <Taral> but I still don't see how that makes mult. disj. useful
23:58:18 <Taral> A `md` B = (not A) `impl` B
23:58:27 <ski> not in itself, but i think with negation and lin. implication, we can recover mult. disj.
23:58:27 <Taral> so we have Cont a -> b
23:58:39 <Taral> yes, we can, but where would we use it?
23:58:40 <ski> right
23:58:45 <Taral> Cont a -> b is a very weird type
23:58:55 <Cale> I mean, there aren't many functions of that type usually. So unless you allow for some special things like side effects, you can't do much with that negation type.
23:59:16 <Taral> hm, I could see...
23:59:23 <Taral> Cont (a, Cont b) -> b
23:59:25 <Taral> as a useful type
23:59:31 <Taral> Cont (a, Cont b) is a callback type
23:59:42 <ski> that's basically (a -> b) -> b
23:59:48 <ski> (the former, i.e.)
23:59:59 <Taral> hm, yes it is.
