00:26:04 * boegel sends his greetings to everyone in #haskell
00:49:19 * boegel kicks shapr hard and in the exact right place
00:58:20 <bourbaki> moin
00:58:53 <boegel> hey boegel 
00:58:56 <boegel> woops :)
00:58:59 <boegel> hey bourbaki 
00:59:03 <bourbaki> :)
00:59:20 <bourbaki> boegel: have you seen my little app?
00:59:34 <boegel> bourbaki: no
01:00:15 <bourbaki> http://img13.exs.cx/img13/5263/unbenannt5gz.jpg
01:00:30 <boegel> bourbaki: the one where you need the last DX version ?
01:00:37 <bourbaki> yep
01:00:48 <boegel> nifty !
01:00:53 <boegel> what is it ? :)
01:00:56 <bourbaki> heh
01:01:07 <bourbaki> its a 2d height surface mapped to a sphere
01:01:07 * boegel loves everything which is graphic-related :)
01:01:29 <boegel> it looks like e beach ball which isn't inflated completly
01:01:32 <bourbaki> but you can map it to anything that is parameterizable with 2 coordinates
01:01:49 <bourbaki> its the interior of the sphere
01:01:55 <boegel> bourbaki: like cube's, cylinder, and so on ?
01:02:00 <bourbaki> yep
01:02:21 <boegel> it looks wicked :)
01:02:43 <bourbaki> thanks the cool thing is that you can project things into these spaces
01:02:44 <boegel> the problem with me is my maths aran't good enough for this kinda stuff
01:02:56 <bourbaki> ie you can map a torus into the sphere space
01:03:03 <boegel> bourbaki: nice :)
01:03:13 <boegel> any more pics ?
01:03:42 <bourbaki> sec i can make one of the torues
01:03:45 <bourbaki> torus
01:04:12 <boegel> okay
01:04:39 <wli> hmm, a torus is doable with just trig
01:05:41 <wli> squirt out a radius along s, for a radial arc of (cos(s), sin(s)), then in the plane through this arc perpendicular to its plane, pick another angle, t
01:06:23 <bourbaki> http://img13.exs.cx/img13/4569/unbenannt3zf.jpg
01:06:59 <bourbaki> the blue lines are the borders of the 2d surface i map to the torus
01:07:14 <boegel> bourbaki: cool :)
01:07:25 <boegel> you should try a stone texture or so
01:08:34 <wli> (1,0,0) + (cos(t), 0, sin(t)) rotated by s around the z axis, etc.
01:08:45 <bourbaki> yes i want to do some perlin noise maps for the thingy
01:08:52 <bourbaki> http://img13.exs.cx/img13/3015/unbenannt8go.jpg
01:09:01 <bourbaki> thats a shot of the original patch
01:09:25 <boegel> bourbaki: you should try perlin :p it looks really cool
01:09:44 <wli> I think this becomes (cos(s)*cos(t), sin(s)*cos(t), sin(t))
01:09:52 <bourbaki> i just dont know yet how to get it into a pixel shader
01:09:59 <wli> s in [0,2*pi), t in [0,2*pi)
01:10:11 <bourbaki> wli: do you want to know who to map :)?
01:10:18 <boegel> reminder: http://studwww.ugent.be/~kehoste/thesisPublic/website/17_11_2004/marble1Lights.png
01:10:42 <bourbaki> nico
01:10:48 <bourbaki> niceo
01:12:24 <boegel> anyway, I'm off again
01:12:28 <bourbaki> bye
01:12:41 <boegel> fuzzy set theory is calling :p bye !
01:12:48 <bourbaki> :)
01:12:48 <wli> sorry
01:12:56 <bourbaki> wli: sorry?
01:13:03 <wli> (cos(s)*(1+cos(t)), sin(s)*(1+cos(t)), sin(t))
01:13:10 <wli> bourbaki: "to map"?
01:13:39 <bourbaki> http://mathworld.wolfram.com/Torus.html
01:14:11 <bourbaki> i use the u and v in the parameterization as the coordinates of the 2d original surface
01:16:40 <wli> bourbaki: well, it took so little time to derive it wasn't really worth googling/whatever
01:22:34 <wli> I'm trying to brew up a different flavor of rational spline from that normally used in graphics. Not much success thus far. =(
01:22:57 <bourbaki> like what kind of spline?
01:29:47 <wli> bourbaki: piecewise rational functions, several continuous derivatives
01:30:08 <wli> bourbaki: constrained to interpolate given points of course
01:31:03 <bourbaki> wli: and where is that different from other splines?
01:31:37 <wli> bourbaki: "typical" rational splines utilize homogeneous (projective) coordinates instead of directly using rational functions
01:32:43 <wli> e.g. a 3D rational spline uses "points" of the form (w:x:y:z) where (c*w:c*x:c*y:c*z) is equivalent to (w:x:y:z) and they interpolate the 4D (w,x,y,z) quadruples, then divide out w
01:32:52 <wli> obtaining rational functions that way
01:32:58 <bourbaki> hm they do?
01:33:17 <bourbaki> i thought that they were independant of the underlying objects
01:33:32 <doojin> hi
01:34:25 <doojin> haskell is a name, too
01:34:28 <doojin> a person's name
01:34:55 <wli> where these are more brutish, f_k(x) is of the form (a0+a1*x+a2*x^2+a3*x^3+a4*x^4)/(1+b1*x+b2*x^2+b3*x^3+b4*x^4), you just say f_k(x_k) = y_k, f_k(x_(k+1)) = y_(k+1), f_k'(x_(k+1)) = f_(k+1)'(x_(k+1)), and so on for higher derivatives.
01:35:05 <kosmikus> doojin: yes, Haskell is named after Haskell B. Curry
01:35:35 <doojin> I remember a name in a movie
01:36:01 <bourbaki> wli: i dont get it :)
01:36:03 <doojin> haskell is not popular at the moment
01:36:09 <wli> (I actually want to use Chebyshev polynomials, T_n((2*x-(x_k+x_(k+1)))/(x_(k+1)-x_k)) etc.)
01:36:20 <kosmikus> doojin: depends on what you compare it to
01:36:23 <doojin> I just entered here because I was interested in the name, haskell
01:36:32 <wli> bourbaki: Well, what's the question?
01:36:49 <doojin> how about comparing to python?
01:36:59 <bourbaki> wli: you devide two polynomials in the first thingy?
01:37:08 <wli> bourbaki: that's what a rational function is
01:37:27 <doojin> huh?
01:37:42 <bourbaki> wli: ok and how do you get to the usual spline function then?
01:38:10 <kosmikus> doojin: generally, dynamically typed languages seem to be perceived as easier to use currently ...
01:38:18 <wli> bourbaki: well, they're special cases where b1=b2=b3=b4=0
01:38:33 <doojin> kosmikus : you think haskell will be popular someday?
01:38:56 <doojin> hmm I can name my language doojin language hehehe
01:39:00 <doojin> doojin language
01:39:04 <kosmikus> doojin: I am not sure ... but I certainly think that Haskell already influences other languages in a positive way
01:39:34 <bourbaki> wli: ok and what is the problem with them?
01:39:58 <doojin> kosmikus : what is haskell for?
01:40:55 <wli> bourbaki: they seem to be tough to compute
01:41:45 <bourbaki> wli: hm ok i think i dont get it sry
01:42:23 <kosmikus> doojin: it's a general purpose language, but it excels in parsing, compiler construction, and domain-specific embedding languages
01:43:16 <wli> bourbaki: finding the coefficients is slow
01:43:35 <wli> bourbaki: I may be able to find faster ways to find them.
01:43:47 <bourbaki> wli: so you speak of something like wavelets?
01:43:50 <wli> bourbaki: do you know what a cubic spline is?
01:44:14 <wli> bourbaki: They don't have quite the same goals as wavelets.
01:44:26 <bourbaki> wli: i just dont know what you wanna do :) i mean why do you need to find the cooeficients?
01:44:51 <bourbaki> approximateing a curve is always like wavelets
01:45:19 <wli> bourbaki: the point of using a spline to represent the things is for e.g. mesh refinement, using the spline approximation to compute approximate points between the ones you were given.
01:45:35 <bourbaki> yes i know
01:45:40 <wli> Or a general approximation, where you're trying to use it to evaluate a function.
01:46:04 <bourbaki> but how do cubic splines fit to the polynomial you posted?
01:46:06 <wli> The reason people want to, say, use rational functions is because they have much more flexible behavior than polynomials.
01:46:20 <wli> bourbaki: not sure what you're asking
01:46:46 <wli> bourbaki: cubic splines make the choice of using cubic polynomials with a continuous derivative
01:46:47 <bourbaki> the polynomial a0 + a1*x + .. + a4 * x^4
01:47:21 <wli> bourbaki: that's just the numerator, the function is a quotient of 2 polynomials
01:48:12 <bourbaki> ok
01:48:25 <bourbaki> you said  a spline had bx = 0
01:49:53 <wli> that would be a "usual" spline, using polynomials as the "basis functions"
01:50:27 <bourbaki> i see
01:52:02 <bourbaki> wli: and the x are of the dimension of the space you are in? like 3d?
01:52:58 <wli> this is 1D, if you want to do e.g 3D you do each coordinate separately
01:55:35 <wli> bourbaki: a0, ... a4, b1, ... b4 are just coefficients in the functions used inside each interval. They need to be determined by continuity constraints and interpolation constraints.
01:56:04 <wli> bourbaki: a0, ... a4, b1, ... b4 play the same role as the polynomial coefficients do for polynomial splines
02:11:28 <wli> bourbaki: doing better now?
02:14:50 <bourbaki> i still dont get it how that relates to splines :) i just read on splines atm
02:15:38 <wli> okay, a function is defined piecewise if you have different e.g. algebraic expressions on different intervals used to assign values
02:16:04 <wli> for instance, on [-1, 0] it's 1 + x, and on [0,1] its' 1-x
02:16:05 <bourbaki> wli: ok 
02:16:35 <wli> a piecewise polynomial function is when all the different intervals use polynomial expressions to define the value of the function
02:16:51 <kristnjov> fuck this.
02:17:37 <bourbaki> topologically speaking its a complex made up of cells
02:18:11 <bourbaki> there the cells have to overlap and have the same value at the seams to be continous
02:18:12 <wli> you can have piecewise polynomial functions defined so that they're continuous and have several continuous derivatives
02:18:32 <wli> bourbaki: that's more meaningful when you use multivariate polynomials/etc. for multivariate functions
02:18:37 <bourbaki> ie a 1d derivationable manifold
02:19:35 <wli> anyway, a polynomial spline is a piecewise polynomial function continuous to some extent that interpolates some points
02:19:55 <bourbaki> right
02:20:11 <wli> so, for my discussion, I back up to the "a function is defined piecewise"
02:20:42 <wli> a piecewise rational function is when all the different intervals use rational expressions to define the value of the function (rational expression == ratio of 2 polynomials)
02:21:17 <wli> you can have the piecewise rational functions defined so that they're continuous and have several continuous derivatives
02:21:42 <wli> and the rational spline is then a piecewise rational function continuous to some extent that interpolates some points
02:21:57 <wli> bear in mind that this is different from the typical usage in graphics
02:22:16 <bourbaki> and why is that different?
02:22:45 <wli> okay, typically in graphics the way rational splines come about is from using spline interpolation for "homogeneous coordinates"
02:23:38 <wli> homogeneous 2D coordinates have 3 actual coordinates, but are "scale invariant". 2 points in this "3-space" are equivalent if they differ only by a scaling.
02:24:14 <wli> you can map (x,y) to homogeneous coordinates as (x,y,1)
02:24:17 <bourbaki> ive never used splines on homogeneous coordinates why would you want to do that?
02:24:51 <wli> or something like (x/(|x|+|y|),y/(|x|+|y|), 1/(|x|+|y|))
02:24:58 <bourbaki> wli: codemages.sf.net/homotopy1.hs btw and .exe for an executable of the code
02:25:03 <bourbaki> its written with ogl
02:25:16 <wli> bourbaki: you've given me that already
02:25:48 <bourbaki> sry
02:25:55 * shapr yawns
02:26:03 <shapr> good morning #Haskell!
02:26:06 <wli> you're not using the graphics version of rational splines there that I can tell
02:26:07 <boegel> hey shapr
02:26:12 <bourbaki> anyway i think im just too dumb to understand what youre trying to tell me
02:26:13 <shapr> hoi boegel
02:26:15 <boegel> I kicked you a few hours ago :p
02:26:20 <bourbaki> wli: i do
02:26:41 <shapr> boegel: I still have a bruise!
02:26:46 <boegel> :D
02:27:07 <boegel> shapr: could you explain me that paradox thing again with the 'set of all sets containing themselves'
02:27:22 <boegel> I tried to explain it to a friend, but I got stuck :s the paradox was gone :p
02:27:27 <shapr> heh
02:27:53 <shapr> The set of all rocks is not a member of itself. The set of all sets is a member of itself.
02:28:01 <wli> bourbaki: heh, then they're thoroughly disguised (to me)
02:28:45 <boegel> shapr: okay...
02:28:49 <bourbaki> wli: the splines i use there are just the normal cubic splines
02:28:52 <shapr> Now think of the set of all sets that do contain themselves, and the set of all sets that don't contain themselves. Are they members of themselves?
02:29:20 <wli> bourbaki: that's what they looked like to me, no rational splines, NURBS, or anything like that.
02:29:56 <wli> bourbaki: Moving on, graphics uses the rational splines because there's some kind of perspective transformation they're useful for.
02:30:06 <wli> bourbaki: or some such nonsense
02:30:34 <wli> bourbaki: they're not there because they're "better approximations" or anything like that.
02:30:48 <boegel> shapr, first, yes, second, no
02:30:57 <wli> bourbaki: Apart from the sense that they can capture things like conic sections
02:31:17 <shapr> boegel: think about the second one again
02:31:38 <bourbaki> wli: ok i think im too dumb really sry
02:32:00 <shapr> If the set of all sets that does not contain itself is not a member of itself, then it is a member of itself, right?
02:32:12 <boegel> shapr: alright, here we go :)
02:32:31 <boegel> and if it does contain itself, it's not a member of the set of all sets not containing themselves
02:32:58 <wli> bourbaki: Well, if you feel more patient sometime later, feel free to come at it. There's nothing particularly deep about what's going on here. It's very much "brute-force" and a bag of random definitions, goals, etc.
02:34:21 * boegel =of
02:34:27 <boegel> thx shapr ! :D
02:34:30 <shapr> sure
02:34:48 <bourbaki> wli: i have a lot of time :) but i just dont think that i will understand it
02:36:09 <wli> bourbaki: Okay, for now can you take my word for it that there isn't really much to understand apart from a collection of goals, definitions, and equations to solve by brute-force (e.g. Newton-Raphson or Gaussian elimination)?
02:36:59 <wli> I'd even go so far as to say that understanding it is basically just memorizing those things.
02:38:24 <bourbaki> wli: can you derive the usual cubic spline from its polynomial?
02:38:40 <wli> bourbaki: yes
02:39:04 <bourbaki> wli: ok i think it would help to do this and do the other thing along cause they would be similar right?
02:39:59 <wli> okay, let's do f_1(x) = a10+a11*x+a12*x^2+a13*x^3 and f_2(x) = a20+a21*x+a22*x^2+a23*x^3
02:40:16 <wli> let's say the 3 points are -1, 0, and 1
02:40:36 <wli> and sin(pi*x/2) is to be interpolated
02:40:44 <wli> (basically, the identity
02:42:02 <wli> f_1(-1) = -1, f_1(0) = f_2(0) = 0, and f_2(1) = 1, plus f_1'(0)=f_2'(0), then f_1''(-1) = f_2''(1) = 0 ("natural spline" conditions)
02:42:28 <wli> these are a bunch of linear equations for the a's
02:43:22 <wli> we get a10 = a20 = 0, a11 = a21, and a12 = a22 = 0
02:43:55 <wli> er, not quite
02:46:08 <wli> a10-a11+a12-a13 = 0, a20+a21+a22+a23 = 0, a10 = a20 = 0, a11 = a21, and then 2*a12-6*a13 = 2*a22+6*a23 = 0
02:46:57 <wli> and I'm missing one, probably because I don't have enough points
02:47:06 <wli> anyway, you see the pattern
02:47:11 <wli> Gaussian elimination saves the day
02:47:17 <wli> it's even a band-diagonal system
02:47:33 <bourbaki> wli: i think this is useless on irc i dont understand a thing sry
02:47:54 <wli> you find the coefficients by solving linear equations
02:48:05 <wli> there's no magic
02:48:26 <wli> evaluate the polynomials and their derivatives with indeterminate coefficients and solve for the coefficients
02:48:42 <wli> big fat band diagonal system
02:49:21 <bourbaki> whats a band diagonal system?
02:50:02 <wli> bourbaki: A system of linear equations with a band diagonal matrix. For instance, a tridiagonal matrix is band diagonal. A band diagonal matrix can have more diagonals above and below the diagonal nonzero.
02:51:44 <wli> bourbaki: Do you see how to solve for a polynomial by considering its coefficients as variables, plugging in x values where you know what the polynomial has to evaluate to, and then solving for the coefficients? big huge linear system for the coefficients etc.?
02:52:15 <bourbaki> more or less
02:52:24 <wli> bourbaki: Okay, this generalizes that procedure
02:52:32 <wli> bourbaki: you have more than one polynomial
02:52:50 <wli> bourbaki: you only have 2 points per polynomial, the endpoints of the intervals
02:53:24 <wli> bourbaki: you get more linear equations by saying the derivatives have to be equal where polynomials' intervals touch
02:54:01 <wli> bourbaki: you build up all these linear equations into a huge matrix and solve, plug-and-chug, Gauss-Jordan, etc.
02:54:18 <wli> bourbaki: How's that sound?
02:54:33 <wli> bourbaki: comprehensible?
02:54:53 <bourbaki> heh i kind of get the idea but i wont be able to apply it
02:55:13 <wli> bourbaki: No need, "kind of an idea" is good enough for this.
02:56:11 <bourbaki> not te me to be honest :)
02:56:54 <wli> bourbaki: okay, my "idea" I'm after is doing this same process with rational functions instead of polynomials. Just set up evaluating the quoetient of polynomials at the points to be the values to interpolate, set up more equations to make derivatives equal, they're nonlinear but you don't need to care, then plug and chug with multtidimensional Newton solvers or something.
02:58:05 <wli> bourbaki: Did you pick up the same "kind of an idea" understanding there?
02:59:01 <bourbaki> yes but i dont see why these are better
03:05:55 <wli> bourbaki: well, one reason why people think they're better is that they can behave a lot more like the function they're approximating. For instance, suppose the function has poles in the complex plane at +/- i; you can capture the effect on the real line by dividing by 1+x^2. They also "condense" large parts of power series, basically all of the geometric parts (from the poles in the complex plane).
03:07:29 <wli> bourbaki: the main use of them is in Pade' approximants and least-squares approximations on an interval.
03:08:29 <wli> bourbaki: Pade' approximants are rational functions whose power series expansions match as many of the first coefficients of the power series of the function as possible. These are very useful for extrapolation because they capture the behavior far from the center of the expansion well.
03:09:20 <wli> bourbaki: least-squares rational approximants (computed by the Remington-Ramirez algorithm) can achieve the same accuracies as polynomial approximations with fewer terms.
03:10:06 <viirya> hmm
03:10:14 <wli> bourbaki: These don't constitute proof that they're better, but these experiences are basically why I'm chasing after using rational functions for this purpose.
03:10:16 <viirya> any idea for doing regex in haskell
03:10:19 <bourbaki> wli: ppl like you make me feel really dumb :)
03:10:44 <wli> bourbaki: Well, that's something of the opposite of the intended effect.
03:11:00 <viirya> looks like there's no built-in regex support
03:11:02 <wli> You're supposed to feel smarter because you know about some random new thing.
03:11:45 <bourbaki> with not knowing it exactly i have something new to look up ... and not knowing something makes me ill
03:12:46 * shapr feels smarter
03:12:55 <shapr> viirya: there's a regex lib
03:13:08 <shapr> comes with GHC
03:13:44 <wli> bourbaki: I guarantee, you'll smack your forehead and swear it's obvious once you look it up.
03:14:11 <viirya> shapr: do you mean "regexp library"?
03:14:38 <bourbaki> wli: the problem is that i havent found anything where i can look it up
03:15:20 <wli> bourbaki: Bulirisch & Stoer covers it, as does Comte & DeBoor
03:16:06 <bourbaki> wli: can i view that stuff online?
03:16:23 <musasabi> @index mkRegexp
03:16:24 <lambdabot> bzzt
03:16:32 <wli> bourbaki: Not that stuff in particular, but there's bound to be something online.
03:16:38 <musasabi> viirya: in Text.Regex
03:16:51 <wli> bourbaki: wikipedia, planetmath, and mathworld all have articles on them.
03:16:54 <musasabi> of course using parsec is nicer most of the time.
03:17:03 <wli> bourbaki: you're probably looking for more detailed things
03:17:14 <bourbaki> wli: i read some of that stuff and didnt understand it really
03:17:41 <viirya> musasabi: thanks. take looks. :)
03:18:47 <wli> bourbaki: it's not a very deep subject, so I've never gone looking around
03:19:06 <wli> bourbaki: something is bound to turn up though, worst case I could write a longer exposition myself
03:21:01 <bourbaki> wli: thanks for all the effords but i really think i wont understand it
03:22:35 <wli> bourbaki: I think you already understand it and are hung up on something that doesn't matter. =) But I won't press the issue.
03:23:18 <bourbaki> wli: maybe
03:23:26 <bourbaki> thanks anyway
03:24:24 <musasabi> Anyone willing to explain how C-- is used in the new GHC backend?
03:29:19 <viirya> musasabi: Text.Regex seems to work only on posix platforms, any solutions for windows?
03:42:48 <musasabi> parsec.
04:03:49 <bourbaki> hey TheHunter
06:07:11 <musasabi> Is there a good way of enforcing resource limits within haskell?
06:07:22 <musasabi> my only idea is to fork and setrlimit
06:07:38 <wilx`> -H16M or something?
06:07:51 <marcot> Hello. Is there a library for working with polygones in haskell?
06:08:10 <marcot> Just basic operation such as intersection, difference and addition...
06:08:28 <musasabi> wilx`: but that still needs a work or the problematic user influenced computation may take the whole app with it.
06:11:31 <marcot> Is nothing of this implemented yet?
06:12:42 <boegel> marcot, have you checked haskell.org and google ?
06:12:59 <boegel> btw, I believe the correct term is polygons
06:13:34 <marcot> boegel: I have checked haskell.org, let me try google. Thanks for the correction.
06:14:04 <boegel> marcot: what are you planning to do with the library ? do some graphics stuff ?
06:16:19 <TheHunter> hey bourbaki
06:17:07 <marcot> boegel: actually just some 2D geometry operations.
06:17:27 <marcot> boegel: I don't need an graphical output, just the right cauculus.
06:17:36 <marcot> calculus
06:34:33 <boegel> TheHunter: bourbaki has left a few hours ago :)
06:35:00 <TheHunter> oh, thanks
06:41:36 <musasabi> marcot: someone had an image drawing library.
06:41:56 <TheHunter> anyone got an idea how to implement a proper deepSeq function for IO a?
06:42:22 <TheHunter> {-# NOINLINE deepSeq #-}deepSeq :: IO a -> IO a
06:42:22 <TheHunter> deepSeq mx = x `seq` return x where
06:42:22 <TheHunter>   x = unsafePerformIO mx
06:42:57 <TheHunter> only works without optimization flags.
06:43:21 <Lunar^> TheHunter: deepSeq mx = do x <- mx ; return $ deepSeq x
06:43:22 <Lunar^> ?
06:43:25 <Igloo> deepSeq x = x >>= y `seq` return y?
06:43:28 <musasabi> marcot: There is a Cairo binding (http://www.ofb.net/~abe/cairo.shtml) and a Gd binding at least.
06:43:50 <Igloo> Oh, sorry, Lunar is right, you need to deepSeq y
06:44:31 <TheHunter> hmm, i'll check that.
06:44:59 <Igloo> Ug, and I forgot the lambda abstraction...must wake up...
06:47:17 <Lunar^> @type fmap
06:47:19 <lambdabot> fmap :: forall f b a. (Functor f) => (a -> b) -> f a -> f b
06:47:38 <Lunar^> I think you could even limit yourself to "fmap deepSeq"
06:48:10 <TheHunter> sorry, i doesn't work.
06:51:29 <TheHunter> deepSeq (return undefined :: IO Int) `seq` 5
06:51:31 <TheHunter> 5
06:55:25 <Asta> TheHunter: hmm I don't really understand how you expect it to work...
06:55:30 <kosmikus> me neither
06:55:37 <Asta> argh nick
06:57:35 <TheHunter> deepSeq (return x) should be bottom iff x is bottom, but thinking about it, i guess it breaks purity.
06:57:50 <kosmikus> yes, exactly
06:58:06 <jadrian> if you think of IO a as being a computation that returns an a
06:58:07 <Igloo> do deepSeq (return undefined :: IO Int); return 5  ==  undefined   whereas   do (return undefined :: IO Int); return 5   succeeds
06:58:14 <Igloo> That's all you can safely get I think
06:58:16 <jadrian> what is evaluating a computation to normal form...
06:59:01 <TheHunter> ok, i'm convinced. Thanks.
07:16:55 <boegel> I'm having a ^M problem with a file... how can I easily solve this in emacs ?
07:17:15 <boegel> how do I replace the ^M characters with actual newlines ?
07:17:53 <xerox> C-M-% C-q RET RET RET ! RET
07:17:54 <xerox> I think
07:18:10 <CosmicRay> boegel: is this a mac or a dos file?
07:18:26 <dxlvi> you can always use sed ;)
07:22:34 <boegel> CosmicRay: I'm in Linux, but the file is edited with Wordpad (Windoze)
07:24:31 <boegel> xerox, that removes all the ^M characters, but no newlines are added...
07:24:47 <xerox> I didn't saw "with actual newlines"
07:25:18 <boegel> xerox, any idea how I can do that ?
07:25:42 <dxlvi> perl -pe 's/^V^M$/\n/'
07:26:02 <xerox> I don't remember the C-* for inserting \n...
07:26:22 <xerox> C-q C-j
07:26:58 <xerox> C-M-% C-q RET RET C-q C-j RET ! RET
07:27:42 <boegel> xerox, thank you :)
07:27:50 <boegel> you just saved me a lot of time :)
07:27:50 <xerox> Np :)
07:27:51 <kosmikus> you could also use recode
07:28:07 <Lemmih> Or the dos2unix tool.
07:29:02 <boegel> Lemmih: I tried that, that didn't solve it
07:29:21 <xerox> :D
07:29:26 <boegel> Lemmih: the problem is that the Windows user edits a Linux-formatted file, and then sends it back t me
07:29:57 <Lemmih> Yes. Isn't that exactly what dos2unix is designed to fix?
07:31:15 <kosmikus> maybe dos2unix doesn't do anything by default on files which are inconsistent; I don't know, recode has the --force options for such situations
07:50:46 <xerox> Is there a function to compute the logarithm of some number in some other base?
07:51:12 <wilx`> Huh.
07:51:43 <wilx`> log(x, z) = log(x)/log(z)
07:51:50 <Nioate`> \base x -> log x / log base
07:51:57 <xerox> Right.
07:52:02 <musasabi> Does anyone have a good nice wikiparser in haskell (preferrably parsec) ?
07:54:52 <xerox> Double-dots notation cannot do [10..1] ? :(
07:56:49 <Nioate`> try [10,9..1]
07:57:11 <boegel> xerox: [(10)..1] ?
07:57:29 <boegel> @eval [(10)..1]
07:57:29 <lambdabot> (line 1, column 7):
07:57:29 <lambdabot> unexpected "."
07:57:29 <lambdabot> expecting simple term
07:57:37 <boegel> @eval [3..1]
07:57:37 <lambdabot> (line 1, column 4):
07:57:37 <lambdabot> unexpected "."
07:57:37 <lambdabot> expecting simple term
07:57:37 <xerox> hmm..
07:57:50 <boegel> oh, lambdabot isn't that smart ?
07:57:53 <xerox> [x | x <- reverse [1..10]] kinda works
07:58:02 <Nioate`> xerox: [10,9..1]
07:58:17 <boegel> xerox, [10..1] is quite different parsing wise
07:58:27 <xerox> Nioate`, I don't know the second term, hmm..
07:59:13 <Nioate`> [n,n-1..1] ?
07:59:48 <xerox> Okay
07:59:58 <xerox> n is an expression, I used let.
08:00:01 <xerox> Thank you
08:02:23 <musasabi> autrijus: what is the performance of the TH generated Binary instances?
08:02:58 <xerox`> hm.
08:09:53 <marcot> Hello again.
08:10:12 <boegel> hey marcot 
08:10:13 <marcot> musasabi: actually, what I want is just the math part.
08:10:30 <marcot> I don't want anything that shows forms on the screen.
08:10:33 <marcot> boegel: =) Hello.
08:11:06 <marcot> The math involved in polygons operations.
08:11:24 <marcot> Like union, intersection, difference.
08:11:33 <xerox`> Do you know HR? (http://mathworld.wolfram.com/HereditaryRepresentation.html) I'm trying to convert an Int to Hereditary Representation, but it's kinda difficult
08:13:31 <marcot> I thought that this would be already implemented in Haskell, and I don't know how to start doing this.
08:15:29 <marcot> xerox`: it doesn't seem to be difficult.
08:21:26 <xerox`> marcot, any hints?
08:55:25 <musasabi> Does a transformer version of STM exist?
08:57:10 <musasabi> I think I am after type STMT a = STMT (Writer [Log]) a
08:57:33 <musasabi> make that: type PH a = STMT (Writer [Log]) a
09:06:42 <Philippa> so an STM with a single global writer?
09:07:23 <musasabi> an STM containing a log of actions that is resetted whenever the STM is reset.
09:24:07 <xerox`> How can I fix an error like: No instances for (RealFrac Integer, Floating Integer) when calling a function?
09:24:30 <xerox`> f :: forall b a. (Floating a, Integral b, RealFrac a) => a -> a -> [b]
09:31:01 <Lemmih> xerox`: Don't call it with integers, perhaps.
09:32:03 <xerox`> Right
09:32:16 <xerox`> is it possible to call it with intgers, by the way?
09:33:11 <Lemmih> No. Not unless you make Integer an instance of both Floating and RealFrac.
09:34:11 <xerox`> Is it possible to modify the function in order to work as (Integeral a) => a -> a -> [a] ?
09:34:47 <Lemmih> Pasting your code would help a lot.
09:34:55 <Nioate> depends on what the function is, probably
09:35:04 <xerox`> Four lines is ok for pasting here?
09:36:13 <Nioate> sure
09:36:22 <xerox`> hr n b = let e = floor ((log n) / (log b))
09:36:22 <xerox`> 	     in if n <= b
09:36:22 <xerox`> 		then [e]
09:36:22 <xerox`> 		else [e] ++ (hr (n-(b^e)) b)
09:46:02 <xerox`> Any clue?
09:52:28 <musasabi> got it working.
09:59:32 <xerox`> musasabi?
10:01:00 <CosmicRay> does fptools for 6.4 contain any xml library?
10:04:38 <musasabi> serializing transactional collection ^_^
10:04:46 <Lemmih> CosmicRay: Yes, HaXml.
10:05:12 <Lemmih> xerox`: fromIntegral is your friend.
10:05:18 <CosmicRay> is there a particular reason that was chosen over the haskel xml toolbox?
10:06:01 <Lemmih> I doubt it.
10:06:06 <CosmicRay> heh, ok
10:06:17 <xerox`> Lemmih, hmm
10:09:29 * CosmicRay cackles evilly.
10:09:34 <CosmicRay> hugs is running on my pda.
10:09:47 <Lemmih> GHC from CVS should be able to build on a Windows box, right?
10:14:15 <Si\> HXT has only recently become namespace aware and easy to build as a package.
10:14:37 <Si\> plus it needs patching a little to work with 6.4
10:14:38 <Oeje1> CosmicRay: Nice achivement.  How big programs can it compile/handle?
10:15:55 <Si\> (by namespace aware I mean as in GHC namespaces, it has been able to deal with XML namespaces b4 HaXML could)
10:18:50 <CosmicRay> Oeje1: I haven't tried yet
10:19:17 <CosmicRay> Oeje1: I'd try ghc, but arm appears to be one of thep latforms that it has trouble on
10:19:20 <CosmicRay> anyway, lunch, bbl
11:02:28 <musasabi> autrijus: ping
11:02:52 <musasabi> Does anyone know where the whole deriving Binary from datatypes code is?
11:04:19 <Lemmih> I've written such code. Didn't knew other had done it already.
11:09:53 <CosmicRay> http://www.google.com/search?q=alarm+clocks&hl=en&lr=&start=10&sa=N
11:27:15 <Lemmih> blueboy2: Feeling blue, eh?
11:57:16 <b0gg1e> hi im
11:57:40 <b0gg1e> trying to compile ghc from cvs and make runs into an infinite loop.
11:57:45 <b0gg1e> is this a known issue?
11:59:54 * Lemmih just compiled GHC from CVS some hours ago.
12:02:37 <b0gg1e> Hm.  Suppose I did something wrong.  make all in ghc/compiler makes make cycle in an infinite dependency loop trying to Prune 'main/config.hs'
12:10:19 <xerox`> Okay..
12:10:48 <xerox`> How can I check if some n, given k, is n = k^m ? (I don't need m, I just have to check)
12:13:50 <gzl> m an integer?
12:14:11 <xerox`> Yes but
12:14:14 <xerox`> If I do
12:14:24 <xerox`> Prelude> log 8 / log 2
12:14:24 <xerox`> 3.0
12:14:42 <xerox`> for n=8 and k=2
12:14:53 <xerox`> it's not an Integer :-\
12:15:19 <gzl> oh, I see. integer but not Integer. I don't know Haskell well enough to answer then
12:15:55 <xerox`> That's it :-\
12:16:03 <gzl> maybe you could check if floor x = x ? (if there's a floor function)
12:16:12 <xerox`> There is one
12:16:21 <gzl> then that should work. I dunno if it's the nicest way
12:17:08 <gzl> oh, you'll run into trouble, floor returns an Integer, and 3 == 3.0 will blow up
12:17:25 <xerox`> gzl, it wouldn't work
12:17:26 <xerox`> yep :\
12:18:22 * gzl scratches head
12:18:34 <gzl> I started Haskell just a few days ago, so I'm just guessing wildly, fyi
12:19:18 <Igloo> xerox`: Is this a homework question or do you actually want to do it?
12:19:43 <Igloo> (and if you want to do it, why, OOI?)
12:19:55 <xerox`> Igloo, It's not an homework question
12:20:11 <xerox`> I want to do it for handle the case described above, in a function
12:20:11 <Oeje1> They all say that. ;-)
12:20:34 <Oeje1> xerox`: Just kidding. :-D
12:20:34 <xerox`> I don't do haskell at school :(
12:20:50 <xerox`> (Unfortunately, I admit)
12:20:55 <Oeje1> Me neither. :'(
12:21:59 <xerox`> Igloo, any clue?
12:23:31 <Igloo> A simple and probably reasonably fast way is to take the floor as a guess for m and do linear search around there
12:23:45 <Oeje1> xerox`: Is the set of n closed?
12:24:30 <Igloo> This seems a slightly odd thing to be doing if not for homework, though...
12:24:57 <gzl> linear search just to check if 3 == 3.0?
12:25:04 <xerox`> Igloo, it's not an homework!!!!
12:25:15 <gzl> and what is so odd? it seems perfectly reasonable to me
12:25:21 <gzl> just solving a simple equation
12:25:40 <xerox`> Igloo, I'm trying to implement
12:25:44 <Igloo> No, linear search to check the original equation
12:25:53 <xerox`> http://mathworld.wolfram.com/HereditaryRepresentation.html
12:26:19 * wli cheers
12:26:31 <boegel> Igloo: how dare you suspect xerox` of that :p
12:26:35 <Igloo> It's possible you only need to check x and x+1 if you use Double, but I'm not sure
12:26:41 <gzl> ah
12:26:48 <xerox`> I'll show you the code I made
12:27:03 <xerox`> aa n b = let e = floor (((log . fromInteger) n) / ((log . fromInteger) b))
12:27:03 <xerox`> 	     in if n <= b
12:27:03 <xerox`> 		then [e]
12:27:03 <xerox`> 		else [e] ++ (aa (n-(b^e)) b)
12:27:12 <xerox`> but it doesn't work for n = b^k
12:27:51 <xerox`> as in aa 8 2 that gives [3,-1797...hundred digits more]
12:29:37 <Igloo> You have log 0 / log 2 in the recursive case don't you?
12:29:58 <xerox`> Yes, if n = b^k
12:30:10 <xerox`> So I just need a guard on n?
12:30:40 <Igloo> Probably - I don't know what answer you want, but taking log 0 is generally a bad plan  :-)
12:30:59 <xerox`> Hm, can you help me writing a more stylistically-correct version of this function?
12:31:04 <Igloo> I'm not sure why you didn't get NaN or Inf or something, though, assuming you are using Double
12:31:08 <xerox`> I think it's not very "Haskellish"
12:36:00 <xerox`> Any idea?
12:37:43 <Igloo> Sorry, rescuing food
12:38:08 <Igloo> [e] ++   is just   e:   and tabs are evil
12:39:04 <xerox`> Hm, I thought I disabled tabs
12:39:10 <Igloo> The main issue is the Double stuff. You could pass Doubles around rather than converting all the time
12:39:25 <xerox`> Ok done
12:39:42 <Igloo> You probably also want round rather than floor
12:39:42 <xerox`> Igloo, It's for letting me pass integers on the interpreter
12:39:49 <xerox`> You think?
12:39:56 <xerox`> (Why?)
12:40:40 <Igloo> Because it has a higher probability of giving the right answer
12:40:49 <xerox`> *Goodstein> ab 8 2
12:40:50 <xerox`> [3]
12:40:55 <xerox`> (yuppie)
12:49:54 <wli> simonmar fixed up sparc64
12:50:51 <wli> uh-oh
12:50:57 <wli> alpha is broke
12:51:29 <wli> Loading package base ... /usr/lib/ghc-6.2.2/HSbase.o: unsupported ELF format
12:51:30 <wli> ghc-6.2.2: panic! (the `impossible' happened, GHC version 6.2.2):
12:51:30 <wli>         loadObj: failed
13:03:22 <CosmicRay> wli: ghci hasn't been portetd to alpha yet
13:03:28 <CosmicRay> wli: alpha is not alone in that.
13:05:16 <xerox`> Igloo, nooo, another error :( *Goodstein> hr 3 2 returns [2,-269653970..hundred more digits]
13:06:05 <wli> feh
13:06:18 <wli> CosmicRay: Why do I remember it working at some point in the past?
13:06:40 <wli> I dist-upgraded and it broke
13:06:49 <wli> It was there.
13:07:01 <xerox`> Igloo, uh, it's due to round, floor seems better.
13:07:25 * Igloo raises an eyebrow
13:07:29 <wli> I'm relatively sure, anyway.
13:07:41 <Igloo> wli: I think you are misremembering
13:08:11 <xerox`> Igloo, what?
13:08:56 <Igloo> xerox`: Do you know what the arguments to aa are when it goes wrong?
13:09:19 <xerox`> n 3 b 2
13:09:40 <xerox`> It gets 2^2 with round
13:09:52 <xerox`> 2^1 with floor
13:11:04 <Igloo> Oh, right, I got confused into thinking n was a power of b
13:11:22 <CosmicRay> wli: it doesn't work as far as I can remember
13:11:34 <CosmicRay> wli: which is about 3 months, as long as I've been using haskell :-)
13:11:43 <wli> well, they're saying it's unimplemented outright
13:12:12 <CosmicRay> Igloo: I'm searching for a bts report on arm support for ghc6
13:12:19 <CosmicRay> wli: #232727
13:12:28 <CosmicRay> Igloo: it's obviously not there under ghc6
13:12:29 <CosmicRay> Igloo: ideas?
13:12:50 <xerox`> Igloo, now I have a problem: if I try to reduce to HR the exponents, I get a list of lists and lists of lists, that's not appreciated by the system. How can I handle it?
13:12:50 <Igloo> I'm not aware of there being one
13:13:27 <CosmicRay> Igloo: according to http://packages.debian.org/cgi-bin/search_packages.pl?keywords=ghc6&searchon=names&subword=1&version=unstable&release=all, it doesn't build on arm
13:13:37 <CosmicRay> Igloo: and according to apt-get on my zaurus, it doesn't exist on arm :-)
13:13:47 <CosmicRay> and yes, I am trying to run ghc from an sd card on a pda :-)
13:13:53 <wli> ELF on Alpha doesn't really exist.
13:14:01 <Igloo> The problem was the different format for Floats
13:14:21 <wli> Richard Henderson made something up that's never been adopted as standard.
13:15:16 <xerox`> Igloo, I mean hr 266 2 => [8,3,1] but it's not enought 8 should be "hr 8 2" as 3 has. so [[3],[1,0],1]
13:15:18 <CosmicRay> wli: but everybody is using it obviously
13:15:26 <wli> s/everybody/linux/
13:15:29 <xerox`> and [[[1,0]],[1,0],1]
13:15:32 <CosmicRay> wli: netbsd?
13:15:40 <CosmicRay> Igloo: so does ghc not even build on arm then?
13:15:41 <Igloo> xerox`: hugs says this:
13:15:41 <Igloo> Main> aa 8192 2
13:15:42 <Igloo> [12,12]
13:15:48 <Igloo> When it should say [13]
13:16:03 <wli> linux is/was already negligible among alpha users, netbsd is even further down
13:16:11 <xerox`> Igloo, it does ;-) *Goodstein> hr 8192 2
13:16:11 <xerox`> [13]
13:16:13 <CosmicRay> wli: huh?
13:16:22 <CosmicRay> wli: from what I see, linux is the primary use of alphas
13:16:27 <xerox`> Igloo, 5 lines, should I paste here?
13:16:31 <CosmicRay> wli: even compaq recognized this in the latter days of the alpha
13:16:36 <Igloo> xerox`: In ghci?
13:16:41 <xerox`> Igloo, yep
13:16:49 <wli> CosmicRay: Most of the users I hear of are using Tru64 and/or OpenVMS.
13:16:50 <CosmicRay> wli: hence their production of the "Linux JumpStart for Alpha" CD that I own
13:17:09 <CosmicRay> wli: I very rarely run into anybody using either of those OSs anymore
13:17:24 <CosmicRay> and those that are, are trying to stop.
13:17:41 <Igloo> xerox: What about aa 243 3 then?
13:17:49 <wli> CosmicRay: Oracle customers...
13:18:04 <Igloo> CosmicRay: It didn't when I last tried
13:18:10 <xerox`> Igloo, *Goodstein> hr 243 3  ==>  [4,4,4]
13:18:17 <wli> CosmicRay: They'll never upgrade unless the hardware dies or they're threatened with termination of their support contracts.
13:18:21 <Igloo> Right, but 243 = 3^5
13:18:27 <CosmicRay> Igloo: is there a thread or anything about it anywhere I can read to educate myself about it/
13:18:44 <xerox`> Igloo, hmmm!!!!
13:18:48 <CosmicRay> wli: yeah I understand how that goes
13:18:58 <CosmicRay> wli: but new deployments of tru64 or openvms are exceedingly rare
13:19:02 <xerox`> Igloo, interesting, that's because of floor I think
13:19:31 <Igloo> CosmicRay: If you look in the channel logs you can probably find where I last told you about it  :-)
13:19:46 <CosmicRay> Igloo: maybe megamonad will know!
13:19:54 <CosmicRay> oh crap, died again.
13:19:55 <xerox`> Igloo, any idea on how to fix it?
13:20:38 <Igloo> xerox`: You need to test if you actually have the right answer
13:21:01 <xerox`> Igloo, how?
13:21:22 * Igloo doesn't have time to go into this, sorry
13:21:41 <xerox`> Thanks much for helping, btw
13:22:48 <CosmicRay> Igloo: checked the logs, didn't have any more info than this
13:22:55 <CosmicRay> 17:49:58 <Igloo> It's not on mipsel because of the above bug. It's not on arm be
13:22:55 <CosmicRay> cause of non-standard floating point representations due to be fixed within a fe
13:22:55 <CosmicRay> w months last I checked
13:26:32 <xerox`> Igloo, I resolved this way:
13:26:40 <xerox`> isPowerOf n b | n < b     = False
13:26:40 <xerox`>               | n == b    = True
13:26:40 <xerox`>               | otherwise = isPowerOf (n-b) b
13:26:53 <xerox`> hr n b | isPowerOf n b = [round $ log n / log b]
13:26:53 <xerox`>        | otherwise = if n > b
13:26:53 <xerox`>                      then [e] ++ (hr (n - b^e) b)
13:26:53 <xerox`>                      else [e]
13:26:53 <xerox`>                          where e = floor $ log n / log b
13:26:55 <xerox`> (sorry for the flood)
13:31:27 <xerox`> whoops some mistake :D
13:32:37 <xerox`> it was               | otherwise = isPowerOf (n/b) b
13:36:51 <tromp> surely 1 is a power of everything
13:37:43 <tromp> so replace n==b case by n==1
13:50:48 <xerox`> Is it possible to make an anonymous recurring function?
13:50:52 <xerox`> tromp, ah, ok thanks
13:51:27 <xerox`> tromp, but doesn't work
13:51:38 <xerox`> tromp, maybe n == 0 ?
13:53:09 <xerox`> tromp, okay
13:53:09 <xerox`> isPowerOf n b | n == 1    = True
13:53:09 <xerox`>               | n < b     = False
13:53:09 <xerox`>               | n == b    = True
13:53:09 <xerox`>               | otherwise = isPowerOf (n/b) b
13:55:21 <Oeje1> In Parsec is there a combinator for parsing at most one thing?  I made "atMost1 :: Parser String -> Parser String" myself.  I can't find something similar.
13:56:26 <xerox`> It's taking me many days to do this representation, sigh :D
13:57:04 <musasabi> Oeje1: option ?
13:57:51 <Oeje1> In Text.ParserCombinators.Parsec.Combinator?
14:00:00 <Oeje1> (option x p) tries to apply parser p. If p fails  without consuming input, it returns the value x, otherwise the value returned by p.
14:01:20 <Oeje1> What if p consumes input and fails?
14:02:25 <musasabi> you can use try.
14:02:35 <musasabi> (option x (try p))
14:02:44 <Oeje1> Ah.
14:03:25 <xerox`> 'night folks
14:03:56 <Oeje1> The thing is, I have a data structure data Message = Message { prefix :: Maybe String, command :: String }
14:04:20 <Oeje1> And I want to parse this grammar: message    =  [ ":" prefix SPACE ] command
14:04:44 <Oeje1> So prefix can be there or not, thus Maybe.
14:05:45 <musasabi> Oeje1: is this irc ?
14:05:55 <musasabi> that is are you parsing the irc protocol?
14:05:56 <Oeje1> So, "option Nothing (try parseOption)"
14:06:05 <Oeje1> musasabi: In fact yes.
14:06:14 <musasabi> Oeje1: I have a parsec parser for that.
14:06:19 <Oeje1> And I want to do it myself.
14:06:50 <Oeje1> :-P  I am exercising Parsec.
14:06:50 <musasabi> you don't need try for that...
14:07:10 <musasabi> (you can have one token of lookahead)
14:07:39 <Oeje1> Well, I want to do as little rewriting of the grammar as possible.
14:08:09 <musasabi> spoiler -  http://www.cs.helsinki.fi/u/ekarttun/hs-fltk/hs-fltk/example/hirc_fltk.hs contains the solution so you can compare when you are ready (and please do tell me if your solution is more elegant).
14:08:36 <Oeje1> musasabi: Ok, I will tell you.  Thanks.
14:27:54 <pesco> Igloo: You there? Do you know what is the easiest/quickest way to get GHC6 on debian woody?
14:28:30 <Igloo> It's in haskell-unsafe
14:28:42 <pesco> What's that? I'm no debian user?
14:29:16 <Igloo> http://haskell-unsafe.alioth.debian.org/haskell-unsafe.html
14:29:17 <pesco> I'm an ex-Debian user. I suppose you're talking about an apt repo?
14:29:27 <pesco> Thanks!
14:35:44 <pesco> Igloo: Many thanks, we're running. ;-)
15:02:52 <musasabi> Has anyone got a working version of binary for modern GHC?
15:02:58 <musasabi> that is freestanding.
15:09:01 <Lemmih> musasabi: Yes.
15:09:43 <musasabi> link?
15:10:22 <Lemmih> http://www.haskell.org/haddock/
15:13:44 <musasabi> thanks.
15:13:50 <Igloo> Did someone here have a ghc6 deb request?
15:14:23 <Igloo> Oh, I think I'm thinking of SM's sparc64 fixes
16:33:42 <tuomov> http://developers.slashdot.org/article.pl?sid=05/01/18/2157249&tid=156
16:33:45 <tuomov> *sigh*
16:34:01 <tuomov> someone is trying to make himself important again
16:34:31 <tuomov> "Programming writer and instructor Greg Wilson is proposing that the next generation of programming languages will use XML to store not only such things as formatting (so you can see indentation your way, and I can see it my way, via XSLT) but even programmatic entities -- like: <invoke-expr method="myMethod"><evaluate>record</evaluate></invoke-expr>."
16:35:08 <Pseudonym> Woohoo, he's only the 23rd person to propose this, and get shot down in the bargain.
16:35:47 <gzl> that sounds annoying, but I'm probably misunderstanding the proposal
16:36:11 <tuomov> basically he wants to move the parser from the compiler to the editor, and replace the compiler parser with xml parser
16:36:36 <tuomov> and maybe make the ide an awful clickety-clickety piece of shit instead of a text editor
16:36:41 <gzl> so he wants people to manually write that XML code to invoke a method?
16:36:56 <tuomov> no, he wants new ides to produce the xml
16:38:03 <Pseudonym> Once again, someone misunderstands that there's more to syntax than producing a parse tree.
16:39:01 <Pseudonym> Many modern languages can't be parsed (or, possibly, can't be parsed easily using common tools) without semantic analysis.
16:39:38 <Pseudonym> C++ is the obvious example, but even C can't be parsed using an LALR(1) parser without semantic feedback.
16:41:11 <Pseudonym> Moreover, yet again this guy doesn't understand the point of literate programming.
16:41:35 <Pseudonym> Mind you, Haskell doesn't do literate programming properly either. :-)
16:43:01 <wagle> i imagine that the xml would not have the ambiguities
16:43:16 <Pseudonym> Yeah, but it would push more work onto the editor.
16:43:29 <wagle> editors are too stupid
16:43:43 <gzl> so what is the point of literate programming to you?
16:43:46 <wagle> hmm...
16:44:07 <Pseudonym> The pont of literate programming, as Knuth intended it, is to present your program in the order which makes the most literary sense.
16:44:49 <Pseudonym> So if it would make more sense to describe some part of the middle of a procedure first, before presenting the rest of that procedure, you should be able to do that.
16:45:14 <wagle> i dont think linearly, and i resent people who want to try to force me to
16:45:45 <Pseudonym> And irrelevant details can be relegated to an appendix, even if they need to be in the middle of some critical function.
16:46:19 <wagle> multiple such views
16:51:41 <Pseudonym> Wow.
16:51:44 <Pseudonym> A youth who had begun to read geometry with Euclid, when he had learnt the first proposition, inquired, "What do I get by learning these things?" So Euclid called a slave and said "Give him threepence, since he must make a gain out of what he learns."
16:52:04 <Pseudonym> That's from Stobaeus.  Seems that the attitude is quite ancient.
16:54:36 <jadrian> I use literate programming quite a bit, I just miss better tools :-/
16:55:08 <jadrian> when coding sometimes hidding text could be useful for instance
16:55:16 <Pseudonym> Right.
16:55:25 <Pseudonym> Well, in those instances I tend to use editor folding.
16:55:29 <sh10151> M-x hs-minor-mode
16:55:38 <jadrian> hmm how is that?
16:55:49 <jadrian> let me try
16:57:14 <jadrian> sh10151: what does that do?
16:57:14 <Pseudonym> Well, in vim you can either do it using an auxilliary file or using {{{ / }}}
16:58:30 <jadrian> I use emacs regulary... I've heard vim mode was better
16:58:30 * Pseudonym has no idea
16:58:42 <sh10151> jadrian: hmm, in haskell, looks like nothing >:-(
16:58:46 <Pseudonym> I just use vim, so I can't comment on emacs.
16:58:46 <Pseudonym> Should probably be using yi anyway. :-)
16:58:50 <sh10151> hs-minor-mode does "code folding"
16:58:59 <jadrian> right :)
16:59:07 <sh10151> but not in my copy of haskell-mode, unfortunately
16:59:17 <sh10151> you could use selective-display mode though
16:59:22 <sh10151> that works on Python
16:59:25 <jadrian> yes that I have
17:00:00 <jadrian> well actually, I have shortcuts for Haskell and LaTeX modes
17:00:04 <jadrian> I don't like it automatic
17:00:42 <sh10151> wait, are you using selective-display-mode or narrowing?
17:01:12 <jadrian> maybe I didn't understand
17:01:30 <jadrian> by selective display I thought you meant the multi something mode
17:01:50 <jadrian> that allows you to combine LaTeX and Haskell modes
17:02:09 <sh10151> no, selective display hides lines indented past a column
17:02:09 <jadrian> all I have is 2 keys that allow me to change between Haskell and LaTeX modes, nothing more
17:02:43 <sh10151> so C-u 4 C-x $ will hide all lines that start past column 4
17:03:08 <jadrian> right, but identing all the LaTeX code past a column isn't that easy...
17:03:53 <sh10151> oooh, I thought you wanted to fold the code, hmmm
17:04:02 <sh10151> you want to hide comments, essentially
17:04:12 <sh10151> teaches me to read more carefully
17:04:15 <jadrian> yes to make it easier to work on the code
17:06:20 <jadrian> it shouldn't even be that hard to come up with something like that, it just has to hide everything that is outside the \begin{code}\end{code}... but I, like most people, have more important things to do than learn elisp :-/
17:07:29 <sh10151> your haskell code starts with > ?
17:08:55 <sh10151> check out http://www.emacswiki.org/cgi-bin/wiki/HideLines
17:08:59 <sh10151> I have never used it
17:09:09 <sh10151> but it looks like it could be cajoled pretty easily
17:14:14 <cm> hellow
20:02:51 * cm flips Philippa 
20:04:24 <Pseudonym> (flip Philippa) might be useful passed to a higher-order function.
20:05:57 <cm> doThings = map . flip Philippa
20:06:04 <desrt> haskell nerds scare me
20:06:25 <desrt> cm; this would give you a list of functions
20:06:45 <desrt> since if you can flip Philippa then map will only partially apply to it
20:06:58 <cm> actually it would give me just a function :)
20:07:17 <desrt> map always returns a list
20:07:36 <cm> given 2 arguments, that is
20:07:38 <cm> :)
20:07:43 <Pseudonym> some (`isScaryTo` Desrt) [ x | x <- nerds, x `likes` Haskell ]
20:07:49 <desrt> i assumed you'd give more stuff to map :P
20:08:07 <cm> (:
20:08:08 <desrt> True
20:09:46 <desrt> (is some like any?)
20:10:02 <Pseudonym> Ah, yes.  Sorry, slipped into Prolog briefly.
20:10:16 <desrt> we got asked to impliment some on a midterm
20:10:47 <desrt> i wrote some p xs = not (any (not.p) xs)
20:10:56 <desrt> ER.  s/some/all/
20:11:00 <desrt> damnit you confused me :P
20:11:44 <desrt> or actually s/some/any/ and s/any/all/, as the real story goes :P
20:44:40 <jadrian> desrt: you should do that the other way around, or you'll end up with s/some/all
20:45:10 <desrt> point taken.
20:45:53 <Gahhh> is there a way to use ghci like "runhugs" for scripts, or do I always have to compile and link ?
20:53:21 <desrt> i don't know of a way.
21:28:18 <ozone> desrt: hey, are you the desrt who's at the same uni as wolfgang, in hamilton?
21:46:35 <vdrab> hi all
21:47:53 <vdrab> could anyone help me out on this ghci error message? I don't get it....
21:47:55 <vdrab>     No instance for (Fractional Integer)
21:47:56 <vdrab>       arising from use of `/' at fca.lhs:310
21:47:56 <vdrab>     In the first argument of `show', namely
21:47:57 <vdrab> 	`((second - first) / 1000000000000)'
21:50:26 <dons> @type (/)
21:50:32 <lambdabot> (/) :: forall a. (Fractional a) => a -> a -> a
21:51:12 <desrt> ozone; yes
21:51:14 <vdrab> so, division can only be performed on members of the Fractional class?
21:51:25 <desrt> not too many desrts around, i think :)
21:52:02 <dons> @type (1 / 2)
21:52:04 <lambdabot> (1 / 2) :: forall a. (Fractional a) => a
21:52:10 <desrt> @type fromIntegral
21:52:11 <lambdabot> fromIntegral :: forall b a. (Num b, Integral a) => a -> b
21:52:16 <desrt> how does magic like this work?
21:52:18 <vdrab> dons: but I can type 3 / 6 in my ghci prompt, and it'l display 0.5
21:52:26 <desrt> @type read
21:52:27 <lambdabot> read :: forall a. (Read a) => String -> a
21:52:28 <desrt> and magic like this
21:53:01 <dons> vdrab, what's the type of 3 ?
21:53:12 <vdrab> Num, I'd say
21:53:35 <vdrab> 3 :: forall t. (Num t) => t
21:53:41 <dons> @type 3 2
21:53:43 <lambdabot> 3 2 :: forall t. (Num (Integer -> t)) => t
21:53:46 * desrt goes hunting
21:55:41 <desrt> OH
21:55:44 <desrt> oh that's clever
21:56:16 <desrt> fromIntegral isn't a function
21:56:19 <desrt> it's lots of functions
21:56:31 <vdrab> .... and....?
21:56:48 <desrt> or fromInteger, at least
21:57:03 <desrt> it's a method that you have to impliment in order to be a member of the Num class
21:57:19 <desrt> so there's a different fromInteger for each kind of Num
21:57:24 <dons> desrt: and some of them ultimately compile down to straight forward C casts
21:57:32 <desrt> dons; that's so cool :)
21:57:33 <vdrab> so, I need to fromInteger the (second - first) to be able to do division on it? 
21:58:09 <desrt> i guess read is just the same
21:58:29 <desrt> and it's just nice language magic that gives you read automatically for your own enum types
21:58:44 <vdrab> it's confusing, that's what it is.... :-)
22:00:31 <vdrab> anyways, I'll figure it out. thanks people
22:05:58 <musasabi> morning
22:06:39 <cm> good night :)
22:14:51 <ozone> desrt: oh, cool.  say hi to wolfgang for me!
22:14:58 <ozone> and thanks for all the ppc work :)
22:17:16 <desrt> heh.  np :)
22:17:28 <desrt> wolfgang has been kicking my ass lately, tho :)
22:19:35 <ozone> wolfgang kicks just about everyone's ass
22:23:27 <desrt> heh
22:23:52 <desrt> including simon marlowe :)
22:27:47 <dons> yay for wolfgang!
23:20:37 <juhp> does anyone have ghc running on x86_64 in 64bit mode yet?
23:22:12 <dons> yes. on openbsd
23:22:23 <dons> it has done for around 9-10 months
23:22:30 <juhp> how about linux? :)
23:22:41 <dons> don't have a linux box :)
23:23:36 <juhp> :)
23:23:51 <juhp> anyone working on it?
23:23:57 <dons> but simonm did the original amd64 port to linux around a year ago
23:24:10 <juhp> ah
23:24:33 <dons> and he is now waiting for a personal box, he said to me recently. whenever it turns up..
23:24:33 <juhp> dons: so current ghc should build on it?
23:24:54 <dons> oh, current. hmm. not sure how well the very latest head bootstraps.
23:25:05 <dons> there's been some work on that in the last week, however
23:25:17 <juhp> oh, ok - so it is just a matter of time?
23:25:22 <juhp> perhaps 6.4?
23:25:22 <dons> yep.
23:25:36 <dons> definitely. you'll be able to bootstrap again. 
23:25:37 <desrt> ghc builds and is registerised
23:25:41 <desrt> no ghci, though
23:25:57 <juhp> how about 6.2.2?
23:25:59 <dons> desrt: registerised on x86_64?!
23:26:06 <desrt> dons; someone in school told me today
23:26:08 <dons> 6.2.2 bootstraps and runs fine
23:26:17 <juhp> oh, cool
23:26:18 <desrt> i was pretty suprised too
23:26:20 <dons> unregisterised. still as fast as a p4
23:26:27 <juhp> must try that then :-)
23:26:28 <desrt> i doubt it :)
23:26:32 <dons> yeah, I don't think it is registerised && 64bit
23:26:42 * wli is dumb and couldn't figure out how to get it to build
23:27:09 * juhp has never tried bootstrapping though
23:27:18 <desrt> #if x86_64_TARGET_ARCH
23:27:18 <desrt> #define REG(x) __asm__("%" #x)
23:27:18 <desrt> #define REG_Base  rbx
23:27:18 <desrt> #define REG_Sp    rbp
23:27:18 <desrt> #define REG_Hp    r12
23:27:20 <desrt> #define REG_R1    r13
23:27:22 <juhp> but needs to, to get ghc into Fedora Extras...
23:27:23 <desrt> ...
23:27:38 <dons> desrt: I know that's there, but there other other things missing, right?
23:27:50 <dons> that's been there foreever, I think
23:27:52 <desrt> i don't know and i don't have an amd64 to test it with :)
23:28:10 <dons> neither
23:28:26 <dons> I just get access to the openbsd build machines somtimes
23:28:31 <desrt> but the person who told me would know what he's talking about
23:28:43 <desrt> he used to come here... went by 'saynte' i think...
23:29:04 * wli is mostly concerned with ghci
23:29:09 * wli uses ghci a *LOT*
23:29:25 * desrt too :)
23:29:36 <dons> yep. porting the linker is always a pain. but no real difficulties, right?
23:29:49 <desrt> porting the linker to powerpc64 == 800 lines of code
23:29:49 <wli> more than the compiler itself
23:29:57 <dons> desrt: !
23:30:13 <dons> a lot more than on ia64, if I remember
23:30:22 <desrt> ia64's port is somewhat limited
23:30:31 <dons> at least ghci runs
23:30:32 <wli> desrt: how so?
23:30:37 <desrt> as wolfgang was pointing out to me earlier today
23:30:47 <dons> but no -fasm
23:30:55 <desrt> ya.  NCG is a whole other story
23:31:22 <desrt> wli; they do some very strange things in the linker... and they set arbitrary limits on the maximum code size
23:31:31 <desrt> so if you try and load a reasonably large program it just doesn't work
23:31:46 <dons> hmm. haven't seen that. but wolfgang would know.
23:31:54 <desrt> (and if you load a smaller program then you're wasting lots of memory)
23:32:04 <dons> i know the binary sizes are huge
23:32:19 <desrt> that's probably a result of no splitobjs
23:32:39 <desrt>  /* These sizes sufficient to load HSbase + HShaskell98 + a few modules */
23:32:39 <desrt> #define GOT_SIZE            0x20000
23:32:39 <desrt> #define FUNCTION_TABLE_SIZE 0x10000
23:32:39 <desrt> #define PLT_SIZE            0x08000
23:33:17 * desrt needs to get the ppc64 code fixed up and commited
23:33:40 <dons> I thought they seemed much bigger than splitobjs alone would indicate
23:33:42 <desrt> in theory, we could do a lot of sharing with ia64 since there are some similarities
23:34:00 <desrt> maybe
23:34:08 <desrt> you gotta remember that you have 8-byte pointers too, though
23:34:25 <dons> yup
23:34:58 <desrt> you can address 4billion times as much memory.... but you use twice as much to store pointers
23:35:03 <desrt> net gain: factor of 2billion :)
23:37:51 <dons> could just be 64 bits, yeah. a mips64 machine shows similar bloat (15 times the size of hello-world on x86-linux)
23:38:22 <desrt> ow.
23:38:44 <desrt> with the new dynamic linking stuff that wolfgang has cooked up, you get like 16k binaries :)
23:38:58 <dons> yeah. cool. nice for plugin stuff too
23:39:10 <desrt> yi?
23:39:36 <dons> haven't tried that yet, but possibly. could make some of hs-plugins obsolete
23:40:04 <dons> and for foreign languages accessing haskell -- they no longer would need to statically link the rts
23:40:33 <dons> which would be good for, e.g. vim
23:41:05 * desrt hugs the rts
23:42:13 <desrt> i'm supposed to write a lambda calculus compiler and accompanying rts
23:43:07 <dons> can't be too hard -- it's been done in sed..
23:43:12 <dons> ;)
23:43:23 <desrt> i hope you're kidding
23:43:26 <dons> nope
23:43:34 <desrt> lambda calculus compiler in sed?
23:43:37 <juhp> how does one access haskell from vim?
23:44:20 <dons> desrt: for 'unlambda' anyway, which is S K and I. so close enough: ftp://quatramaran.ens.fr/pub/madore/unlambda/contrib/unlambda.sed
23:44:37 <desrt> what does it build it?
23:44:39 <desrt> *to
23:44:49 <dons> juhp: I don't think one can, atm.
23:44:55 <juhp> ah :)
23:45:15 <dons> desrt: sorry, it's an interpreter. not a compiled lambda machine
23:45:21 <desrt> ah
23:45:27 <desrt> that's sort of boring :)
23:45:46 <dons> but the unlambda guys do have tiny little compilers I seem to recall
23:46:18 <desrt> they are probably much smarter than me :)
23:46:40 <dons> http://www.eleves.ens.fr:8080/home/madore/programs/unlambda/
23:55:34 <desrt> this is obscene
