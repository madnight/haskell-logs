00:51:52 <bluegods> hide ho people
00:52:04 <bluegods> does haskell take pain of perl away?
00:52:24 <dons> yes, I believe it does
00:52:34 <bluegods> cool
00:52:45 <bluegods> do you use it for any kinda e commerce stuff?
02:01:47 <musasabi> morning
02:03:08 <lightstep> morning
02:17:36 <yonkeltron> what do comments look like in haskell?
02:19:02 <Oejet> {- inline comment -}  -- end of line comment.
02:54:42 <bluegods> hi
02:54:44 <bluegods> hows all
02:55:08 <Oejet> Good, thank you.
02:55:39 * Oejet is struggling to construct a Parsec parser for While.
02:55:41 <bluegods> is haskell a good bet to start a software company
02:57:56 <Oejet> bluegods: I don't know the ratio of bankrupt/succesful companies neither for C nor Haskell.
03:11:40 <xerox> sh10151, ping
03:11:43 <xerox> whoops.
03:11:45 <xerox> shapr, ping
03:31:45 <KiMoS> fst (tail, head) (map succ [1..10]) <<<  what will be done first?   
03:31:58 <KiMoS> (map succ [1..10]) ?  or   fst (tail, head)  ?
03:34:17 <musasabi> KiMoS: why should you care?
03:34:45 <KiMoS> i just want to know how haskell work
03:36:21 <KiMoS> i know fst return the first item in a tuple  but that will be tail?   or haskell will see everything as 1 tuple and therefor (tail,head) will be done first?
03:36:54 <musasabi> KiMoS: well all haskell implementations may do it in either order. Most likely they will just create a thunk denoting the value of that computation. Evaluating the thunk may eval fst first but that is just an implementation detail.
03:37:44 <KiMoS> but what will be the first step in there?
03:37:58 <KiMoS> i know that haskell always start from the rightside
03:57:24 <musasabi> What is the most readable out of http://youzen.b2.fi/~musasabi/a.html ?
04:07:38 <shapr> xerox: pong
04:09:21 <araujo> ping
04:13:18 <shapr> musasabi: I like the A choices in those.
04:15:57 <shapr> hej ski 
04:21:57 <ski> hej shapr
04:22:14 * ski reads some LtU
04:30:54 <musasabi> shapr: thanks.
04:49:34 <shapr> aww, phrack is closing down.
04:49:44 <KiMoS> what will be the answer of this calculus expression:   (? x . ? y . ? z . z x y) z x y   ?     (? = lambda)
04:50:24 <shapr> ski: what do you think of the OOP thread?
04:50:29 <KiMoS> (lambda x . lambda y . lambda z . z x y) z x y 
04:51:14 <shapr> @type \x y z -> z x y
04:51:15 <lambdabot> \x y z -> z x y :: forall t t1 t2. t -> t1 -> (t -> t1 -> t2) -> t2
04:53:41 <shapr> @type \x y z -> (z x y) z x y
04:53:43 <lambdabot> bzzt
04:54:36 <TheHunter> @pointless \x y z -> (z x y) z x y
04:54:36 <lambdabot> Sorry, I don't know the command "pointless", try "lambdabot: @listcommands
04:54:37 <thbot> ap (flip flip) . ap ((.) . flip flip) (flip flip id . (ap .) . flip . flip
04:54:37 <thbot> id)
04:55:01 <TheHunter> thbot: @pointless (\x y z -> z x y) z x y
04:55:01 <thbot> y z x
04:55:27 <shapr> thbot: @msg #haskell I am the next generation lambdabot!
04:55:28 <thbot> not enough privileges
04:55:29 <shapr> doh
04:55:41 <thbot> I am the next generation lambdabot!
04:55:45 * shapr grins
04:56:00 <shapr> that's a cute plugin
04:56:13 <KiMoS> y z x is the right answer :)
04:56:27 <KiMoS> thanks guys
04:57:51 <TheHunter> time and space usage is still a little unpredictable...
04:58:49 <TheHunter> @pointless \a b c d e f g h i -> i f a . f d b (w i c . e e)
04:58:49 <lambdabot> Sorry, I don't know the command "pointless", try "lambdabot: @listcommands
04:59:30 <thbot> (((((const .) .) .) .) .) . (((((const .) .) .) .) .) . (. ((. (((.) .)
04:59:30 <thbot> . (flip id .) . (. ap id id) . flip . ((.) .) . flip w)) . flip . ((.) 
04:59:30 <thbot> ) . (flip id .) . (((.) .) .) . (. flip id) . flip flip)) . (.) . (.) .
04:59:30 <thbot> (.) . ap . (ap .) . (((.) .) .) . (. flip id) . flip flip
05:02:25 <TheHunter> @eval \x y z -> (z x y) z x y
05:02:25 <lambdabot> <<EM Dynamic -> EM Dynamic>>
05:03:20 <Spark> :o
05:08:20 <KiMoS> when you use the case of  like this :  case (x, y) of
05:08:20 <KiMoS> (2, _) -> 1
05:08:50 <KiMoS> and u do set x = 2  y = 3
05:08:57 <KiMoS> (2,3)
05:09:07 <KiMoS> will the answer be 1  ?
05:09:25 <KiMoS> let f x y = case (x, y) of
05:09:25 <KiMoS> (2, _) -> 1
05:09:25 <KiMoS> (_, 3) -> 2
05:09:25 <KiMoS> (2, 3) -> 3	
05:09:33 <TheHunter> sure, numbers can be pattern matched against.
05:10:05 <KiMoS> so the (2, _)  wont be fired
05:10:12 <KiMoS> only the (2,3) ?
05:10:21 <TheHunter> the first matching rule will be fired
05:10:35 <KiMoS> thats (2, _) 
05:10:38 <KiMoS> ok
05:10:41 <KiMoS> thanks 
05:19:41 <ski> shapr : mm, some a bit interresting things, and a bit funny/tragic at places, too
05:21:53 * ski would like to look in ATiTaPL
05:25:20 <basti_> haskell can play csound lazily in realtime now.
05:29:17 <basti_> with a little help of perl.
05:41:40 <shapr> basti_: you got it all worked out?
05:42:11 <basti_> its working but it needs a little bells and whistles now.
05:42:44 <basti_> for example, i dont want to hardcode "i 1"/"i1" 
05:44:33 * shapr blinks cluelessly
05:44:51 <shapr> I just want to listen to lorenz fractals :-)
05:44:57 <basti_> uhm do you want the perl script?
05:45:03 <shapr> no, I'm scared of perl.
05:45:07 <shapr> Well ok, I can try it!
05:45:07 <basti_> i'm too.
05:45:11 * shapr hops randomly
05:45:20 <shapr> It's cold out there. I want to unicycle!
05:45:24 * shapr grumbles
05:46:12 <basti_> http://www.students.uni-marburg.de/~Zapf/haskocsd.pl
05:47:03 <basti_> it expects two parameters, first one is read, parsed (score => rt) and output to the second.
05:47:12 <basti_> i would recommend using it on two named pipes.
05:47:35 <shapr> er, ok
05:48:02 <basti_> and maybe adjust the prebuffer time.
05:49:03 <basti_> did i scare you now?
05:49:54 <shapr> Yes. I am scared.
05:49:57 * shapr runs away
05:50:00 <Spark> its quite mild here, but the heatings fucked so im using my hair straighteners and cpuburn to warm my room still
05:50:10 <shapr> You have hair straighteners?
05:50:20 <Spark> :o
05:50:27 <shapr> I wanted those until my hair got long enough.
05:50:46 <shapr> Now it only curls up when it has way too much energy.
05:50:48 <Spark> its long enough to tie back but i still prefer it straight, especially if going out
05:50:57 <Spark> heh
05:51:17 <Spark> i find it curls right at the tips
05:51:35 <Spark> i tried cutting off the tips but then it curled slightly further up and the problem was the same
05:51:39 <shapr> heh, yup.
05:51:47 <shapr> Life sucks with curly hair.
05:52:00 <shapr> My female friends are jealous, but I think it's just troublesome.
05:52:33 <Spark> life sucks <===> not(curly hair => hair straighteners)
05:52:52 <shapr> Is that an intersection type?
05:53:01 <Spark> alas no
05:53:23 <Spark> it was an attempt at a predicate i think
05:53:30 <shapr> @type highway + street
05:53:31 <Spark> i havent done enough logic to actually know any logic
05:53:32 <lambdabot> bzzt
05:53:41 <shapr> That's logical.
05:53:44 * shapr chortles
05:53:57 <Spark> the amount of logic you have to do before you know any logic appears to be infinite
05:54:11 <shapr> Isn't that Zeno's pair of dogs?
05:54:17 <Spark> wassat/
05:54:28 <shapr> Ya know, Zeno, and his pair of dogs...
05:54:43 <shapr> http://www.mathacademy.com/pr/prime/articles/zeno_tort/index.asp
05:55:29 <Spark> :o
05:55:55 <shapr> I am far more silly in person.
05:56:29 <shapr> Sadly, there aren't too many people who enjoy making and appreciating silly jokes about type theory, so I often end up laughing by myself.
05:58:14 <Spark> :f
05:58:23 <Spark> better than noone at all
05:58:42 <Spark> that seems to play on the definition of real numbers and how its not really like our intuition of them
05:59:37 <shapr> it's like you said.. "the amount of logic you have to do before you know any logic appears to be infinite"
05:59:44 <Spark> ah yeah
06:06:32 <Philippa> paging Goedel ;-)
06:07:56 <Spark> i still havent finished that report on intersection types
06:08:02 <Spark> i fell ill for a few weeks :(
06:08:07 <Philippa> erk
06:08:09 <Spark> and now im behind with all sorts of uni work, that included
06:08:15 * Philippa nods
06:08:17 <Spark> but im better now, i just have to catch up
06:08:33 <Spark> it was better that it happened at the begninning of the term while the work load was minimal, i think
06:08:34 <Philippa> I've come to the conclusion intersection types aren't overly interesting from Tyop's POV, as they're all expressible with union types
06:08:43 <ski> (Spark : report of your writing ?)
06:08:56 <Spark> ski: yeah
06:09:00 <Spark> summary of various things
06:09:09 <Philippa> (for those reading this who don't know about Tyop - no, I don't think that result applies generally)
06:09:13 <Spark> forsythe and also intersection type systems with type variables
06:09:18 <ski> Philippa : Tyop = ?
06:09:44 <Philippa> the not-quite-haskell lang I'm implementing to try out some ideas. Largely supertyping on ADTs coupled with most of the standard Haskell extensions (if I get time)
06:09:50 <Spark> Philippa: want the half written version?
06:09:54 <Spark> actually its about 2/3 done
06:10:02 <Philippa> supertyping on ADTs, rank-n polymorphism and type classes seems to be a scarily powerful combination
06:10:07 <Philippa> yeah, okay
06:10:17 <Spark> what is rank n polymorphism?
06:10:27 <Spark> is that like finite rank restrictions of system f?
06:10:31 <Philippa> yeah
06:10:35 <Spark> cos i thought they get quickly broken after about 3 or something
06:10:50 <Philippa> more just 'not commonly used'
06:11:00 <Philippa> but it turns out to be no harder to do n ranks anyway
06:11:13 <Philippa> the main restriction's that it's all in prenex form - keeps the inference sane
06:12:42 <Spark> http://xdev.net/~spark/dc04ISOReportTerm1.ps
06:12:52 <Spark> im a bit worried that im talking bollocks in most of that though
06:12:56 <Spark> since im new to type theory anyway
06:13:32 <Spark> i think the interesting thing about intersection types is that with finite rank restrictions you get both a decidable type inference algorithm, and principal typings
06:13:38 <Spark> which isnt true of anything else
06:13:38 <Philippa> yeah, I've been told to be very careful if I write anything mathematical in my dissertation, as I'll probably have Thorsten Altenkirch as my second marker
06:13:46 <Spark> heh
06:13:59 <Spark> theres no proofs in there though, just verbal waffle all the way through
06:14:07 * Philippa nods
06:14:44 <Philippa> I can do most of my stuff in prose. The only awkward bit's going to be if I implement multi-parm typeclasses - multidimensional subtype relationships're a bugger
06:14:52 <Philippa> or rather, "is this tuple a subtype of that one?"
06:15:39 <Spark> heh lets see
06:16:14 <Philippa> oh, I know I can do it the day I sit down and think in front of something I can write on :-)
06:16:18 <Spark> you could do it perhaps by forgetting the fields on the right? and also by subtyping any of the fields
06:16:33 <Philippa> oh, the tuples're all the same size
06:16:36 <Spark> thats about it for tuples isnt it
06:16:40 <Spark> ah thats ok then
06:16:53 <Philippa> the problem is I need to get this right because I'm using coinheritance to give me coherance on overloading
06:17:05 * ski searches for a PS-viewer on this comp. .. seems there are none, dang
06:17:15 * Spark pdfs it
06:17:16 <Philippa> I suspect the real result is that the syntax gets nasty
06:17:38 <Spark> done
06:18:26 <Spark> do you type tuples by adding a product type constructor and a rule for each of the tuple forming / extracting syntax?
06:18:44 <Philippa> that's one way to do it
06:19:11 <Philippa> admittedly it's a way I might actually use in Tyop itself, because there're funky things you can do with TCons and TNil constructors
06:19:33 <ski> Spark : ty
06:19:35 <Spark> hm you represent a list with tuples dont you
06:19:39 <Spark> np
06:24:06 <Philippa> Spark: you write anything much the last four minutes or so?
06:24:15 <Spark> not since yesterday :)
06:24:28 <Spark> oh
06:24:29 <Spark> no
06:24:34 <Spark> not on irc
06:25:17 <Philippa> heh
06:25:33 <xerox> shapr, ping again
06:25:53 <basti_> shapr is still scared of my perl script.
06:26:58 <Spark> i had a nice dream about sinking boats / drowning / dead bodies floating around the other night
06:27:02 <Spark> that was quite scary
06:27:08 <Spark> but not nearly as scary as perl
06:27:48 <basti_> i'm not saying no dead bodies would float around soon when you write something big in perl.
06:28:17 <Spark> i think one concept subsumes the other
06:28:52 <basti_> i lately had a dream of kissing a former school mate. Who was also male.
06:29:44 <Philippa> happens. Ignoring any sexual aspect, were you good friends?
06:29:54 <Spark> yeah ive had that too
06:29:55 <basti_> yes.
06:30:00 <Philippa> (a kiss doesn't mean you want to go rolling around covered in lube playing hide the sausage...)
06:30:25 <basti_> i'm not THAT homophobe either
06:30:38 <Spark> shortly before i was bitten by a spider, which jumped at my face, and then half falling asleep from the venom i blundered into his room and kissed him
06:30:55 * Philippa nods
06:31:30 <Philippa> It doesn't have to be about any fears. The idea men can't kiss to show friendship seems to be very much a cultural thing - it's not as if women don't do it all the time
06:31:31 <Spark> my pulling ratio of late is something like 3 male to 1 female, although thats largely because men are larger sluts
06:31:50 <Philippa> heh
06:31:56 * basti_ .o° ( ? )
06:32:56 <Philippa> there is /some/ truth to the stereotype about still being in the room the next morning constituting a relationship for gay men :-)
06:33:22 <Philippa> (or maybe it's just that at uni age I hear far too much 'we split up after two weeks, it's the end of the world, I'll never love again!'...)
06:33:59 <Spark> one of my faggy friends shagged a rentboy :o
06:34:00 <basti_> -g-
06:34:21 <Philippa> yeah, I know somebody who's done that (didn't pay, or at least didn't confess to doing so)
06:34:31 <Spark> oh, this guy did :)
06:34:35 <Spark> a hundred quid for gods sake
06:34:41 <Philippa> that's really, really sad
06:34:43 <Spark> apparently it was good though
06:34:50 <basti_> whats a quid?
06:34:57 <Spark> uk currency
06:34:57 <Philippa> slang for a pound (currency)
06:35:02 <basti_> i c
06:35:04 <basti_> thats a lot.
06:35:05 <Spark> 1.5 euros or something
06:35:07 <basti_> i'd say.
06:35:19 <Philippa> before coughing quietly? :-)
06:35:20 <Spark> i think he'd never done it before
06:35:49 <basti_> i have never been in bed with a prostitute of either sex.
06:36:19 <Philippa> strictly speaking, I've shared (non-sexually) a bed with an ex-sex worker
06:36:36 <basti_> that doesnt count.
06:36:38 <Spark> the way i see it, buying sex because you cant get it for free is like buying drugs because you cant get them for free :)
06:36:54 <basti_> huh?
06:37:01 <Philippa> not quite, /somebody/ has to do some work when it comes to drugs
06:37:05 <shapr> xerox: pong?
06:37:24 <basti_> indeed.
06:37:31 <xerox> shapr!
06:37:39 <xerox> shapr, you must see this: (let me find the url)
06:37:39 <shapr> xerox!
06:37:40 <basti_> ah the golden times.
06:37:57 <xerox> http://tlb.org/eunicycle.html
06:38:04 <shapr> Ah, I know that.
06:38:08 <xerox> Uh :)
06:38:09 <shapr> Trevor whatshisname.
06:38:13 <shapr> Black?
06:38:24 <shapr> And his self-balancing unicycle.
06:38:25 <xerox> Blackwell
06:38:32 <xerox> Yep!
06:38:35 <Spark> robot unicycle?
06:38:36 <shapr> He wrote the TV xscreensaver
06:38:53 <shapr> which *faithfully* emulates a real TV and its distortion.
06:38:59 <Spark> heh
06:39:01 <shapr> hiya Heffalump 
06:39:06 <Heffalump> 'lo
06:39:08 <shapr> How's the arm?
06:39:09 <xerox> :D
06:39:22 <shapr> xerox: eunicycle is neat.
06:39:29 <xerox> Agreeable
06:39:36 <shapr> I have a vaguely related derivative idea that I came up with.
06:39:47 <Heffalump> I'm sure all hundreds of millions of them are fine.
06:39:48 <xerox> His self-balancing two-wheeled scooter is too.
06:39:52 <xerox> http://tlb.org/scooter.html
06:40:05 <shapr> But my idea is sort of under wraps until I can get hold of an industrial designer friend of mine and see if I can actually build it..
06:40:07 <xerox> (Seems more "stable")
06:40:35 <shapr> TLB built the Eunicycle to experiment with the idea that the only significant numbers are zero, one, and infinity.
06:40:47 <shapr> I've been thinking about how that applies to the Icehouse game design set recently.
06:41:03 <shapr> I should probably just write a blog entry rather than dumping my unfinished musings here.
06:41:19 <xerox> ^__^
06:42:13 <shapr> I played a cool Icehouse game for the first time yesterday, "Blockade" it has elements of 'towers of hanoi', backgammon, and some other random stuff. It's very elegant.
06:42:43 <shapr> Do you guys know/play Icehouse?
06:43:16 <xerox> I dont
06:43:27 <shapr> it's worth trying - http://wunderland.com/icehouse/Default.html
06:44:21 <Heffalump> lambdabot: @seen cosmicray
06:44:21 <lambdabot> I haven't seen cosmicray
06:44:47 <shapr> It's a bunch of clearish plastic pyramids that come in three sizes that can stack inside the largest. You can design your own games with it, and there are existing rules for more than a hundred games on the website.
06:46:18 <shapr> Some of the games remind me of Piet - http://www.dangermouse.net/esoteric/piet.html
06:47:11 <shapr> xerox: thanks for the reference, I'm always interested in new and unusual things.
06:47:40 * ski would want to have a ccard deck nicely printed out ..
06:48:01 <shapr> Is that the Category Theory card game?
06:48:07 <ski> mm
06:48:43 <Spark> phillipa, ski: did you find the report interesting at all?
06:48:56 <Philippa> er, not read huge amounts of it yet
06:49:08 <Spark> thought not :)
06:49:09 <Spark> is it terse
06:49:14 <Spark> i can never tell with my own writing
06:49:15 <ski> Spark : sorry, haven't properly begun reading it yet (only browsing some yet :)
06:49:45 <Spark> the interesting bit i guess will be the bit at the end that i havent done yet
06:51:35 <xerox> shapr, yw :D
06:51:46 <ski> (was wondering a little over this BNF   tau ::= phi | rho -> sigma  ...  isn't it usual to reuse the same (tau, in this case) nonterminal in the RHS (in this case at rho,sigma) ?  not sure about usual practice. minor anyway)
06:52:20 <basti_> its usual but not mandatory
06:52:30 <basti_> a reuse in the RHS would be a recursion
06:52:31 <Spark> ski: dunno :)
06:52:49 <Spark> i could have done tau -> sigma i guess
06:52:56 <Spark> i wonder how its done int he course notes
06:52:58 <ski> (seems like it's intended to be recursive)
06:53:11 <Philippa> the recursion's implicit here, as the sigma production contains rho
06:53:16 <Philippa> er, tau even
06:53:18 <Spark> yeah its done like that there
06:53:29 <ski> Spark : in that case i meant like  tau -> tau
06:53:42 <Spark> ah that would imply that the two sides of hte arrow would have to be the same though
06:54:52 <Spark> thats how metavariables work isnt it?
06:54:57 * ski thinks he've seen something like (in this case) tau,sigma,rho ::= phi | rho -> sigma or tau,sigma,rho \in T ::= ... (with T used here) and with tau,etc used later as var names for individual types
06:55:03 <Philippa> oh, wait, different grammar, ignore what I said
06:55:29 <ski> Spark : not necessarily with BNF / abstract syntax, i think
06:55:38 <Philippa> using tau on both sides is valid as a grammar
06:55:57 <Philippa> it's when you're doing inference rules you have a problem
06:56:07 <ski> right
06:56:32 <Philippa> the one I usually see is naming the production and then listing variables that'll be used for expressions belonging to it
06:56:33 <ski> same issue with attr.gram.
06:56:59 <Spark> my best bet is to copy what the guy who is marking it does in his papers :)
06:57:06 <ski> hehe
06:57:15 <Spark> the other amusing thing about that part of the report is that \mu and \rho arent used anywhere else
06:57:32 <ski> in his papers, you mean ?
06:57:39 <Spark> in the report
06:57:44 <Spark> except later on in the forsythe section
06:57:56 <ski> (where's mu ?)
06:58:02 <ski> ok
07:08:48 <ski> Spark : hmm, is "certainity" or "certainty" the correct spelling ?
07:08:56 <Spark> :>
07:09:05 <Spark> i havent run ispell on it yet
07:09:10 <Spark> im scared to, to be honest
07:09:21 <ski> ok
07:09:23 <Spark> it'll take 10 years to step through all the false negatives
07:09:50 * ski 's not totally sure about the spelling of that, in fact
07:10:05 <Spark> certainty is good
07:10:24 <ski> mhm
07:27:12 <ski> Spark : hmm ..
07:27:47 <ski> (p. 6) should it be  tau = S(sigma)  ?
07:30:05 <Spark> yes :)
07:30:31 <Spark> i mean
07:30:32 <Spark>  no
07:30:33 <ski> not  sigma = S(tau)  then ?
07:30:35 <Spark> its wrong
07:30:49 <ski> heh
07:30:58 <Spark> sigma = S(tau) yeah
07:31:24 <ski> (few sent. later : s/This/Thus/)
07:32:17 <Spark> yeah just noticed that too :)
07:35:31 <ski> (hmm, maybe change  "free" variable  into  unconstrained (by basis) variable ?)
07:36:03 <Spark> yeah i wasnt sure if that was the correct term to use
07:36:10 <Spark> it certainly overloads the term used for term variables
07:36:11 * ski 's sure either
07:36:44 <ski> 'unconstrained' seems like it's better describing what it meant, though, IMO
07:37:26 <Spark> yeah i think youre right
07:37:46 <ski> (also, maybe s/"marked"/generalized/  .. ?)
07:38:15 <ski> at least for "marked" principal type/pair
07:38:35 <ski> hm
07:39:56 <Spark> i was trying to describe it in a way that wasnt dependent on combinatorial logic you see
07:40:19 <ski> mhm
07:40:58 <ski> i think it's called generalized in let-polymorphism (adding univ. quant.), at least
07:41:58 <ski> (hmm, for a moment wondered if comb. logic. used combinators for the types too .. :)
07:42:37 <Spark> in his course notes he just speaks of quantified variables i think
07:42:50 <ski> ok
07:42:55 <Spark> its just a notation though, the type itself is a piece of syntax, not a predicate that is satisfiable or whatever
07:43:26 <Spark> it just happens to be conceptually analogous with \forall, i think anyway :)
07:43:59 <Philippa> I dunno, you can meaningfully see a lot of types as predicates
07:44:11 <Philippa> "member of type foo", "member of the type of functions between..."
07:44:15 <ski> (the principal type (of "first/argument expr.") would be generalized in the let-rule to a type with former unconstr. tyvars now (univ.) quantified)
07:44:50 <Spark> yeah quantified
07:45:06 <Spark> hes using generalised probably because of the subsumption relation that you get in ML
07:45:13 <Spark> wheres that from?
07:45:31 <ski> Spark : you talking about quant as a part of type syntax, or quant in meta-lang desc. types ?
07:45:38 <Spark> part of type syntax
07:45:52 <ski> oki
07:45:58 <Spark> im not sure what that other thing is :)
07:46:18 <ski> like   forall t.  id :: t -> t
07:46:23 <ski> (e.g.)
07:46:41 <Spark> yeah
07:47:18 <ski> (or  forall B,M. B |- M : tau ==> B |- M : sigma)
07:47:24 <Spark> that meats the t in there is not constrained in any way, its free to be substituted without damaging the derivation
07:48:05 <Spark> hm where does that forall bind to
07:48:19 <Spark> the whole of the implication?
07:48:20 <ski> "bind to" ?
07:48:23 <ski> oh
07:48:24 <ski> yes
07:48:44 <Spark> ah right yeah thats implicit in what i said isnt it, since i took B and M to be arbitrary
07:48:45 <ski> (just as is usual in types :)
07:48:51 <ski> right
07:49:00 <Spark> but the second one is a statement of logic but the former is a type
07:49:08 <ski> yeah
07:49:15 <ski> um
07:49:49 <ski> if you're thinking of  forall t.  id :: t -> t   then that's meant to be a statement of logic, too
07:49:57 <Spark> is it?
07:50:01 <Spark> what does the id :: mean?
07:50:06 <ski> (as opposed to   id :: forall t. t -> t)
07:50:07 <Spark> is that like a field name
07:50:08 <ski> sorry
07:50:12 <ski> haskell syntax
07:50:21 <Philippa> id "has the type/is a member of the type"
07:50:21 <Spark> ah so it is then
07:50:25 <Spark> oh
07:50:39 <ski> id = identity function = lambda x.x      a :: t   meaning a has type t
07:51:28 <Philippa> putting the forall on the RHS of the :: still makes sense
07:51:43 <Philippa> "id has the type that for all t, it's a function from t to t"
07:51:47 <ski> yep
07:52:04 <Spark> ok you can say then  B |- M : \A.phi tau  ===> (forall sigma \in Types . B |- M : tai[sigma/phi])
07:52:20 <Spark> s/tai/tau/
07:52:46 <Spark> and the implication probably works the other way too i guess
07:53:38 <Spark> but you'd have to do that with induction over sigma or something as well as over the derivation for M
07:55:24 <Spark> actually in ML you cant substitute with another quanitified type can you?
07:55:37 <Spark> is it true that in HM you can if its on the left side of an arrow or something
07:56:10 <Spark> is that the whole rank polymorphism then
07:56:11 <Spark> thing
07:57:05 <ski> you can't substitute a quantified type (called type scheme) for a type var in ML, no
07:57:46 <ski> i think this holds for ordinary HM as well
07:58:12 <ski> not sure about rank poly.
07:58:47 <ski> if you can subst a type scheme for a tyvar, then i think the type sys. is called impredicative
07:59:03 <Philippa> you can't for most rank n inference systems, no
08:09:31 <ski> (Spark : hm, re limit. of curry sys. : would it be better that 'some *arguably useful* terms can not be typed', instead of just 'some terms can not be typed' ?)
08:10:29 <musasabi> What was the option to dump the cmm representation of a program with cvs ghc?
08:10:36 <Spark> i couldnt work out if they were useful though :)
08:11:07 <ski> (or is any nontypeable term seen as a limitation, even in extensions of pure lambda calc .. ?)
08:11:08 <Spark> i think the non-typability of xx etc is much more of an issue because it induces the other two problems
08:11:31 <TheHunter_> i think -ddump-cmm
08:12:08 <Spark> its hard to justify how a type system cannot type xx ==> the type system is unsuitable for practical programming languages :)
08:12:27 <ski> Spark : huh, you couldn't work out if what were useful enough ?  self-application (x x) ??
08:12:33 <Spark> yeah
08:13:13 <ski> but then it seemed like you didn't mean that ("i think the non-typeability of xx ...")
08:14:11 <Spark> i guess if anything cant be typed thats a problem actually
08:14:16 <Spark> since all terms are valid in the LC
08:14:39 <Spark> however xx isnt really analogous to real programming
08:14:58 <ski> (yeah, but ".. even in extensions ..")
08:15:07 <ski> mm
08:15:19 <Spark> if you extend a language, the original terms must still be valid in the extension... :)
08:15:39 <ski> yea
08:16:42 <ski> (but ext. can add nontypeable terms ..)
08:16:59 <Spark> yeah
08:19:03 <Spark> i dunno :)
08:19:24 <Spark> its very important to be able to type fix though
08:19:35 <Spark> i didnt mention how ml gets around that did i :S
08:19:59 <ski> mm
08:20:30 <ski> p. 5  section 1.3
08:21:06 <musasabi> TheHunter_: thanks.
08:21:08 <Spark> oh yeah :)
08:21:36 <Spark> you know its a long report when youve forgotten whats in the beginning by the time you get half way through
08:22:04 <ski> "The lack of fix would make the system impractical for ... sidestep ... extending .. operator .. special typing rule, as is done with the language ML."
08:22:10 <ski> heh :)
08:23:56 <ski> (hmm, i think there's some similarity betwixt intersection types and Pierce's "logical vs. operational" (IIRC) variant readings of the quantifiers ..)
08:24:37 <Spark> is that in his book?
08:24:42 <ski> yep
08:24:44 <ski> TaPL
08:24:48 <ski> have it ?
08:24:53 <Spark> i havent heard of ther terms logical and operational hbefore
08:24:54 <Spark> yeah
08:25:29 <ski> mentioned in some chapter on univ. and exist. quant. in types
08:25:33 <Lemmih> Greetings, Oeje1.
08:25:41 <ski> possibly he just invented the names
08:26:14 <Spark> not important enough to be in the index :)
08:26:57 <Oeje1> Lemmih: Greetings.  I am implementing an optimizing While compiler in Haskell.  It has lots of boilerplate code.
08:27:09 <ski> Spark : e.g. for univ. quant. : logical reading is "this term has all these types at the same time", operational reading is "this term is a function, that given a type (as argument), will give something of the specialized type"
08:27:33 <Spark> mm
08:27:37 * ski unfortunately doesn't have the book here atm ..
08:27:40 <Spark> thats the same though isnt it
08:27:55 <Spark> intersection vs quantification is like finite vs infinite though
08:28:02 <Lemmih> Oeje1: 'While' compiler?
08:28:03 <ski> think of e.g. the empty list
08:28:03 <Spark> same as union vs existential i think
08:28:11 <ski> mm
08:29:40 <ski> Spark : logical : "the empty list *has* many types at the same time", operational : "the 'empty list' is a kind of thunk, that when given a type, will give an actual empty list (constructor) for lists of that type"
08:30:51 <Spark> either way it has the potential to subsume an infinity of instantiations though
08:31:04 <Spark> i like that word
08:31:50 <Oeje1> Lemmih: Yes, the While language as described in Principles of Program Analysis by a.o. Hanne Riis Nielson.  Simple imperative language with if-then-else and while controls.
08:32:17 <Spark> heh
08:32:18 <ski> Spark : logical : "an intersection type has many types (which are in the intersection type) at the same time", operational : "a product/record, given a selection, will give something of the corresponding type part of the product/record type"
08:32:43 <Philippa> give or take. Last time I implemented it, it's just a tag and a lack of parameters
08:32:59 <Philippa> argh. Bloody scrolling. That's in response to the logical/operational views of the empty list
08:33:47 <Spark> ski: yeah ok
08:33:55 <ski> Philippa : some impl.s do the type-passing
08:33:59 <Philippa> yeah, I know
08:34:07 <Spark> ski: thats two ways of expressing meaning for the same idea though (in terms of two different things)
08:34:09 <ski> m, ok
08:34:25 <ski> two viewpoints/readings
08:34:25 <Philippa> it's almost weird that the Tyop implementation's type-agnostic, in that regard
08:34:29 <ski> S
08:34:29 <Spark> yeah i think
08:34:48 <ski> (with possibly different impl.s related)
08:35:11 <ski> Philippa : you mean how ?
08:36:11 <Philippa> you've got what's slowly turning into a scarily heavily-typed language, and the only run-time artefact of that's ADT tags
08:36:34 <ski> Spark : anyway, i thought that intersection types and product/record types would possibly be eachothers counterparts under those two viewpoints/readings ..
08:36:35 <Philippa> which, of course, don't give a damn about whether the ADT's polymorphic or not
08:36:57 <ski> Philippa : constructor tags ?
08:37:02 <Spark> ski: you can represent the typings of records / objects with intersection types, if you have a field type constructor too
08:37:30 <Spark> S2.9
08:38:03 <ski> Philippa : ok ("logical" reading/viewpoint, then (at least in impl ;) (hmm, maybe the word Pierce used was 'intuituin' instead of viewpoint or reading))
08:38:30 <Philippa> ski: yeah
08:38:30 <ski> Spark : how do you mean ?
08:38:45 <ski> s/intuituin/intuition/
08:38:51 <Philippa> thing is, this is a language where data constructors are also (possibly nullary) type constructors
08:38:56 <Spark> they are related, but not automatically
08:39:05 <ski> Philippa : oh ?
08:39:33 <ski> Spark : no ? and what is field type constructor ?
08:39:45 <Spark> check out section 2.9 for an example :)
08:39:45 <Philippa> ski: easy way to get the supertyping relationship I wanted. A type constructor is either a data constructor with a bunch of type parms, or a sum of data constructors of the same kind
08:40:11 * ski finally understands what that remark from Spark was supposed to mean ;)
08:40:16 <Philippa> (note that in that sense, it's the data constructor viewed as a type constructor's kind, so it's not just * automatically)
08:40:55 <Philippa> sooo. Cons a and Nil a are data constructors as well as type constructors, and have kind * -> *. List a = Cons | Nil
08:41:06 <Spark> ski: :)
08:41:11 <ski> Philippa : ok
08:41:25 <Philippa> and Cons and Nil are from then on subtypes of List
08:41:40 <ski> Philippa : maybe similar to hughes play system for type specialization, then .. ?
08:41:48 <Philippa> er, haven't seen it, possibly?
08:41:54 <ski> (in that respect)
08:42:39 <Philippa> anyway, that rather large restriction on the supertyping relationship makes inference a doddle - you just take the lub of two types when you unify them rather than checking they're equal
08:42:50 <Philippa> (oh, okay, and make the function type special)
08:43:54 <ski> Philippa : e.g. http://www.cs.chalmers.se/~rjmh/TypedPE/README.html#demo  (try specializing the Cons ... expr e.g.)
08:44:36 <ski> (more info on parent page ..)
08:44:51 <ski> :)
08:46:15 * ski tries to do some lubbing and glbbing in his hacking type system, too
08:47:11 <Philippa> the thing that's going to be a real PITA to do is type classes, largely because there's an outstanding syntactic issue
08:47:15 <ski> (though, just maybe, i should try to write down the inference rules and such correctly first before running to try to implement the next dozen features i can think up .. :)
08:47:42 <Philippa> I know how I'm going to get coherance, I just need good syntax so I can do it by means other than checking the constraints've been obeyed
08:48:06 <ski> hmm, how do you mean ?
08:48:29 <ski> (i.e. syntax)
08:49:51 <Philippa> probably the sanest thing to do for now is to just insist that there be instances on all subtypes before the supertype can be instanced. You just get lots and lots and lots of instance declarations that way
08:50:22 <ski> mhm
08:50:31 <ski> interresting
08:50:32 <Philippa> that, and it makes it a pain in the arse to read out the pattern-matching going on eg every time you declare a new instance on lists
08:50:42 <ski> mixing type classes and subtyping
08:50:44 <Philippa> yeah, you effectively coinherit everything
08:50:54 <ski> mhm ?
08:51:05 <Philippa> yep. You actually get two type hierarchies specifying different (arguably dual) things
08:51:14 <Philippa> the supertype uses the code from the subtypes
08:51:38 <ski> hm
08:51:52 <ski> sub-/super-types only for variants ?
08:51:59 <ski> or records, too ?
08:52:31 <Philippa> only for variants atm, you can encode it meaningfully for records given multiparm classes (and possibly fundeps)
08:52:43 <ski> hmm
08:52:46 <ski> how
08:53:01 <Philippa> you use classes to encode "has the record foo of type bar"
08:53:04 <Philippa> er, field even
08:53:20 <ski> hmm
08:53:25 <ski> sounds tedious
08:53:26 <Spark> heh i have to present a summary of a certain paper in the form of a lecture on thursday and ive just found the conference slides for that paper \o/
08:53:31 <Philippa> which is why you sugar it
08:54:03 <Philippa> helps
08:54:11 <ski> O'Haskell has subtyping for both variants and records, right ?
08:54:18 <Philippa> IIRC, yeah
08:54:24 <ski> m
08:54:31 <ski> Spark : ok, nice
08:54:34 <Philippa> they most likely do the record subtyping the same way under the hood
08:55:25 <ski> wouldn't it be more or less similar to variant subtyping ?
08:55:56 <Philippa> no, in fact it's almost exactly the opposite
08:55:58 <ski> (or what do you mean by "under the hood" ?)
08:56:07 <ski> yeah
08:56:18 <ski> dual, otherwise mostly same, i'd think
08:56:22 <Philippa> they probably base their record system on qualified types, which is the idea underlying type classes
08:56:22 <ski> ;)
08:56:44 <Philippa> there's very little meat that doesn't get dualised though. You extend in the opposite direction, even
08:56:56 <ski> like "has" or "lacks" predicates ??
08:56:59 <Philippa> yeah
08:57:20 <ski> iirc O'Haskell uses explicit struct declarations (like data but for records)
08:57:39 <Philippa> heh, that makes sense
08:58:11 <ski> if so, it wouldn't prolly be made underneath with type classes, i think
08:58:25 <Philippa> depends what they allow for records
08:58:47 <ski> like ?
08:59:01 <ski> (sorry for asking so much)
08:59:16 <Philippa> the typeclasses-underneath approach lets you do quite a lot (it's missing "lacks" predicates, so no record extension at run-time, but you get things like first-class labels...)
08:59:35 <ski> hm
09:00:21 <Philippa> there's the useful case where you want stuff to act both as subtyped records /and/ a variant type, which you can type rather precisely here
09:00:34 <ski> mhm ?
09:00:41 * ski hasn't heard of that
09:01:24 <Philippa> gives you a cheap way to both pattern-match and know you've got the right fields available
09:01:43 <Philippa> and because you know a lub ahead of time, you already know which dictionary you want
09:02:06 <ski> any example of how that might look like ?
09:03:20 <Philippa> (ignoring namespace collisions and assuming that patterns matching SuperRecord match SubRecord): data SubRecord = extend SuperRecord {fields...}; data SuperRecord = SuperRecord {more fields...} | SubRecord;
09:03:43 <Philippa> then when you pattern-match you know exactly which fields are known to be available at a given point
09:04:04 <Philippa> (it depends how far you've refined the type of what you're analysing - if you matched SuperRecord, you can't assume fields that're only in SubRecord)
09:04:57 <ski> aha, extending with more fields/arguments of particular constructors
09:05:03 <Philippa> yeah
09:05:05 <ski> nice
09:05:17 <Philippa> so you end up with a type that's "fixed" in both directions, but that may just be what you /want/...
09:05:26 <ski> hm
09:05:40 <Philippa> (this says a lot about why OO-style subtyping doesn't quite work so often)
09:05:46 <ski> this would be different from some kind of depth-subtyping, or not ?
09:06:06 <Philippa> not really. We're just making things rather explicit when we declare the types
09:06:47 <ski> (hm, also "fixed" in both dir.s, how ?)
09:07:17 <Philippa> you have to go annotate the supertypes when you add a new subtype, you have to annotate the subtypes when you add a new supertype
09:07:40 <Philippa> (why /not/ extend two record types at once? We're doing this statically, we can cheat when it comes to lacks predicates)
09:07:45 <ski> aha
09:07:54 <ski> hm
09:08:38 <ski> (hm, in "data SuperRecord = ... SubRecord", is SubRecord there just a constructor, or a reference to the type previously declared ?)
09:09:33 <Philippa> er, consider there to be two SuperRecord declarations, one just the data constructor, one summing that and SubRecord and shadowing the previous for situations requiring type constructors (but not those explicitly requiring data constructors)
09:09:52 <Philippa> if you really really want we can add a third type constructor, it just looks uglier
09:09:58 <ski> er
09:10:15 <Philippa> this is Tyop. All data constructors are type constructors.
09:10:26 <Philippa> The reverse doesn't apply, as type constructors can also be sums of type constructors
09:10:39 <ski> (just wondering if there's a mutual reference amongst the two decls, or not, i think)
09:10:48 <Philippa> yes, there is
09:11:12 <Philippa> but it's resolvable - SubRecord only needs to know about the SuperRecord data constructor, not the sum
09:11:38 <Philippa> the downside is that yes, this is an invitation to mutually recursive modules
09:12:05 <Philippa> but I've found a few places where I wanted those coding Flippi anyway
09:12:31 <ski> think i still don't understand why the SuperRecord decl refers to SubRecord ..
09:12:51 <Philippa> to include SubRecord in the SuperRecord variant
09:13:00 <ski> hm
09:13:05 <Philippa> (thus allowing pattern-matching on SuperRecord to include SubRecord)
09:13:07 <ski> aha (?)
09:14:02 <ski> so SuperRecord (type) includes both SuperRecord {some fields} and SuperRecord {some and more fields} ?
09:14:08 <Philippa> yeah
09:14:47 <Philippa> btw, thanks for the convo, you've made me realise I can go ahead and implement
09:14:52 <ski> and SubRecord (type) just the {some and more fields}, but it's decl get to decide on what 'more' is ?
09:14:59 <Philippa> yeah
09:15:00 <ski> (conco ?)
09:15:04 <Philippa> conversation
09:15:08 <ski> (convo ?)
09:15:23 <ski> (afk)
09:16:03 <ski> (back)
09:18:25 <ski> so, pattern-matching on (known) SubRecord, we can use more fields ?
09:18:54 <ski> or was there some "back-propagation", too ?
09:19:50 <Philippa> the former
09:19:56 <Oeje1> Jaaaa, compiling to C is fun and easy.
09:20:03 <Philippa> it is?!?
09:20:15 <Philippa> I guess so if you don't mind doing the continuation thing
09:20:29 * ski smiles
09:20:50 * Philippa ought to track down a copy of compiling with continuations sometime
09:21:00 <Oeje1> Well, when compiling the While language. ;-)
09:21:29 <Philippa> ah. My last effort had nested procedure declarations, that was less fun
09:28:20 * ski ponders array abstractions
09:47:17 <Spark> ski: :o
09:47:41 * Spark put pizza on etc
09:52:42 <ski> Spark : on the array abstractions ? :P
09:56:28 <Spark> yeah
09:56:33 <Spark> to cook
09:57:08 <Spark> is that referencing the forsythe array representations?
09:57:56 <Spark> its interesting how somethings like arrays and functions are implemented completely differently yet are essentially the same
09:58:22 <ski> no, not forsythe (at least that i know)
09:58:29 <ski> yeah
09:58:45 <ski> same in some senses
09:59:14 <Spark> well i guess you cant represent a semidecidable algorithm with an array :)
09:59:21 <Spark> so its a one-way thing
09:59:31 * ski has/wants general arrays in his type-sys.
10:00:00 <ski> problems though if index type is infinite
10:00:11 <Spark> an infinite type :o
10:00:29 <ski> ehm
10:00:43 <ski> inifitely many inhabitants, i meant
10:00:51 <Spark> is that possible?
10:00:59 <ski> like natural numbers
10:01:05 <ski> what possible ?
10:01:10 <Spark> i suppose so since the syntax is infinite
10:01:11 <ski> such arrays ?
10:01:28 <Spark> but you wont have any infinite datatypes will you?
10:01:36 <Spark> if theyre going to map directly onto cpu representations
10:01:40 <Spark> (of data)
10:01:59 <ski> um
10:01:59 <ski> maybe lazily
10:02:13 <Spark> actually you can get big numbers and stuff cant you
10:02:24 <Spark> it just needs a type structure with pointers and such
10:02:41 <ski> hm ?
10:02:44 <ski> referring to e.g. Integer in haskell
10:02:54 <ski> ?
10:03:44 <Spark> i dunno
10:03:47 <Spark> libgmp that sort of thing
10:03:58 <ski> anyway, i'm not sure how to handle array-bound variables in array-abstractions
10:04:03 <ski> yep
10:04:29 <ski> like  \i => ...
10:05:00 <Spark> is there a type system which has ranges encoded in the type syntax
10:05:15 <Spark> but thats not good enough really
10:05:17 <ski> as opposed to the special case \i => case i of C0 -> ... | C1 -> ... | ...
10:05:30 <Spark> i liked those dependent types mentioned the other day
10:05:55 <ski> i'm going to try adding something like that (ranges) to my type system
10:06:15 <ski> to be able to play with arrays indexed by such
10:06:46 <Spark> i think you have to go a lot further though
10:06:50 <Spark> or be very conservative
10:06:53 <ski> for what ?
10:07:14 <Spark> suppose you multiply m*n and m is int(3,4) and n is int(10,12), then you end up with (30,48)?
10:07:31 <ski> oh, that ,yes
10:07:36 <Spark> thats much wider than it needs to be
10:07:40 <ski> hm
10:08:08 <Spark> also things like floor(n/5)*6 or whatever :)
10:08:43 <ski> well, possibly just embed range types into int if something is done with them
10:09:01 <ski> like i : int(3,4) |- i+1 : int
10:09:44 <Spark> but then you can only look up array[i] and not array[expression(i)] cant you?
10:10:11 <ski> um ,dunno ;)
10:10:13 <ski> possibly
10:10:35 <ski> hasn't thought much about range types (not specific idea to try out)
10:10:48 <Spark> mm
10:11:08 <ski> i think i'll have some kind of subtyping in the system
10:11:29 <ski> (not that i really want to try around with subtyping for the moment, though)
10:11:51 <ski> just another feature seems to 'induce' them :)
10:12:11 <Spark> you know i think you only need to allow subtyping when typing term variables
10:12:27 <Spark> that makes things  lot cleaner since there arent many possible derivations
10:12:38 <ski> like   let x.a = 1 ; x.b = "bepa" in ...x...
10:13:40 <ski> or  let (x.a,(x.c,_),x.b) = ... in ..x..
10:13:50 <Spark> hm
10:14:12 <Spark> thats like prolog unification isnt it?
10:14:16 <ski> btw, this is meant to be a linear type system
10:14:19 <ski> a bit
10:14:25 <ski> patter-matching
10:14:28 <Spark> yeah
10:14:29 <ski> pattern-matching
10:15:32 <Spark> ooh, pizza :)
10:16:08 <ski> so i'll want to e.g. have a kind of "subtyping" of e.g. an array that essentially splits it into slices (to be passed down to different parts of a computation)
10:16:11 <ski> heh :)
10:16:39 <bourbaki> moin
10:16:55 <ski> good evening, bourbaki
10:17:28 <Spark> sigh ive managed to cook a pizza according to the instructions, such that the edge is burnt and the centre is frozen
10:17:29 <ski> (Spark : hm, speaking of things to slice .. :)
10:18:04 <ski> Spark : in microwave oven ??
10:18:44 <ski> (Spark : possibly too high temp., anyway)
10:19:00 <Spark> nah its cos the toppings are piled up in the middle
10:19:15 <Spark> normally i move them to the edge to free up the centre and stop the edge from burning
10:19:29 <ski> heh
10:19:30 <Spark> also i put the pepper on top of the peperoni because the fluid in the pepper has a higher heat capacity
10:19:51 <ski> liquid pepper ?
10:20:00 <ski> (hm, pepper sauce, prolly)
10:20:52 <Spark> bah green ones
10:20:55 <Spark> nah
10:31:44 <Spark> slices of pepper, but frozen :)
10:31:50 <Spark> ive eaten it now
10:31:51 <Spark> mnmnmnmn
10:31:56 <Spark> it was tasty
10:32:02 <Spark> but now i feel fat
10:33:21 <Spark> @eval something
10:33:21 <lambdabot> unbound variable: something
10:33:47 <Spark> @eval Fix 4
10:33:47 <lambdabot> unbound variable: Fix
10:33:50 <Spark> @eval fix 4
10:33:51 <lambdabot> type error
10:33:57 <Spark> @eval fix \x.4
10:33:57 <lambdabot> 4
10:34:16 <ski> @eval Y
10:34:17 <lambdabot> <<EM Dynamic -> EM Dynamic>>
10:34:30 <ski> @eval Y (\x -> 4)
10:34:30 <lambdabot> 4
10:34:38 <ski> @eval Y 4
10:34:38 <lambdabot> type error
10:35:11 <Spark> @eval fix (\f.\n. if n==0 then 1 else n * f (n-1)) 5
10:35:11 <lambdabot> 120
10:35:13 <Spark> :o
10:35:28 <Spark> im pretty chuffed i got that first time :)
10:35:38 <ski> @eval callcc
10:35:38 <lambdabot> unbound variable: callcc
10:35:51 <ski> bah!:)
10:36:01 <Spark> @eval malloc(10)
10:36:01 <lambdabot> unbound variable: malloc
10:36:30 <Oeje1> I have a compiler for the While language (parser not implemented yet), and there seems to be lots of boiler plate code.  I am not very familiar with generic programming in Haskell.  Any one care to look it over?
10:36:41 * ski thought of using callcc to get recursion, instead
10:38:44 <Spark> what does callcc do?
10:38:47 <Oeje1> http://eigil.dyndns.dk/While.hs
10:39:39 <ski> Spark : when applied to a function, it captures the current continuation and applies the function to that, returning whatever the function returns
10:39:54 <Spark> ooh continuations
10:40:07 <Spark> i went to a lecture given by reynolds about those
10:40:15 <ski> Spark : if the continuation is applied, the callcc application to the function returns with whatever was passed to the continuation
10:40:16 <Spark> didnt understand a word of what he said though
10:40:26 <ski> heh
10:40:37 <Spark> at the end, someone put up their hand and asked what a continuation was
10:40:44 <Riastradh> Spark, a continuation represents what a program does next given a result.
10:41:24 <Riastradh> E.g., in (f (g x)), there is a continuation for the call to g; when g returns a value, it can be thought of as passing that value to the continuation, which will then apply f to that value.
10:41:48 <Riastradh> The continuation is what will pass on the value g returned to f.
10:42:40 <Spark> right
10:43:21 <Spark> when is it useful to talk of things in such terms?
10:43:23 <ski> callcc (\k -> 3) = 3
10:43:31 <Riastradh> When considering control flow.
10:43:42 <Spark> ah
10:43:44 <ski> Spark : when reasoning about or constructiong control abstrations
10:43:49 <Spark> i have a lecture on control flow on tuesday :)
10:44:03 <ski> callcc (\k -> k 3) = 3
10:44:09 <ski> callcc (\k -> 500 * k 3) = 3
10:44:35 <ski> (assuming cbv haskell with control effects)
10:45:28 <Spark> weird
10:45:49 <Spark> i need to read this paper on answer engines by tommorow so i better depart
10:46:09 <ski> case callcc (\k -> Left k) of {Left k -> k (Right 2) ; Right n -> n} = 2    (though cyclic type in this case)
11:16:27 <ski> (hmm, "theory of classification" article mentions intersection types ..)
11:32:30 * basti__ blinks
12:04:35 <xerox> yo
12:04:46 <shapr> y0
12:05:00 <shapr> dang, I was hoping philippa would be online.
12:05:12 * shapr is hacking on Flippi
12:09:35 <Heffalump> have you seen Cosmicray recently?
12:12:54 <shapr> @seen CosmicRay
12:12:54 <lambdabot> I saw CosmicRay leaving #darcs 1 day 9 minutes 42 seconds ago.
12:13:18 <Heffalump> oh, is it case sensitive?
12:13:22 <shapr> I guess so.
12:13:33 <Heffalump> @seen cosmicray
12:13:33 <lambdabot> I haven't seen cosmicray
12:13:37 <Heffalump> yeah. bah :-)
12:13:40 <shapr> oops
12:13:43 <shapr> another bug to add to the pile
12:13:56 <Heffalump> where's the right place to darcs pull lambdabot from htese days?
12:14:00 <Heffalump> s/htese/these/
12:14:44 <shapr> I'd say the separate lambdabot repo.
12:15:14 <shapr> I've made a few stabs at folding in all the forks and additions, but it's a real pain in the ass.
12:15:19 <Heffalump> http://www.scannedinavian.org/repos/lambdabot/ ?
12:15:22 <shapr> yup, I think so.
12:15:42 <shapr> There are about six versions of lambdabot floating around with extensions past that.
12:15:56 <shapr> dons sent me some cool stuff, Lemmih fixed some things, etc etc
12:16:01 <Heffalump> surely darcs should make it easy?
12:16:30 <shapr> I think the problem is that many of the changes are incompatible.
12:16:36 <Heffalump> @seen LAMBDABOT
12:16:36 <lambdabot> I haven't seen LAMBDABOT
12:16:54 <shapr> kosmikus fixed the case sensitivity for channels
12:17:07 <shapr> I think that change got folded in...
12:17:44 <shapr> If no one else fixes it, I think I'll soon get frustrated and take lambdabot offline, rip out the old dynlinking code and upgrade to hs-plugins.
12:18:28 <shapr> That would fix most of the difficulties with maintenance.
12:18:33 <Cale> @seen lambdabot
12:18:33 <lambdabot> Yes, I'm here
12:18:37 <Cale> hehe
12:23:31 <shapr> hoi goron 
12:24:27 * Heffalump wonders if shapr would like an untested patch (it does compile)
12:25:44 <shapr> to lambdabot?
12:25:58 <Heffalump> yes
12:26:00 <shapr> what does the patch do?
12:26:08 <Heffalump> makes @seen be case-insensitive
12:26:18 <shapr> sure, send it
12:26:21 <Heffalump> well, if it works..
12:26:59 <Heffalump> sent
12:31:46 <Heffalump> hello
12:32:15 <goron> shapr: hej
12:38:24 * Heffalump wonders how to debug "Fail: unknown exception" emanating from HSQL
12:39:52 <Heffalump> ah, handleSql/catchSql
12:40:55 <shapr> yup
12:46:34 <Heffalump> hi
12:53:27 <Lemmih> Anyone hacking something spiffy?
13:00:13 <Lemmih> Guess not.
13:01:14 <Oeje1> What is the noticable difference between Haskell-mode 1.45 and 2.0?
13:01:42 <Oeje1> Lemmih: Have you tried to use generic functions?
13:35:27 <fjorden> hi all
13:35:42 <Oeje1> Hello, fjorden.
13:35:51 <musasabi> evening
13:35:56 <Gahhh> afternoon
13:36:07 <fjorden> :)
13:36:14 <fjorden> anyone know whether there's a built in function in haskell to check whether every element in one list exists in another
13:36:33 <tic> you could always do it with a list comprehension.
13:36:37 <fjorden> or do I have to go through the first list using elem on each element and the second list
13:36:51 <tic> think so.. but haskell is lazy, shouldn't be evaluating too much.
13:37:16 <tic> (len [x|x<-xs, y<-ys, x==y]) > 0
13:37:18 <tic> or something.
13:37:43 <Gahhh> I'd use fold . filter
13:38:11 <fjorden> ah, ok
13:38:18 <Lemmih> Crappy network /-:
13:39:44 <Lemmih> Oeje1: As in Generic Haskell?
13:40:52 <Oeje1> Lemmih: Yes.  You see I have some code which looks like it's filled with boilerplate code.
13:43:23 <Lemmih> boilerplate code?
13:44:21 <Oeje1> Yes, a lot of functions traversing the same data structure.
13:48:45 <Heffalump> gah. my mysql double(16,4) keeps getting reported as SqlUnknown (random number) by HSQL.
14:24:44 <stepcut> hurray for taxes!
14:24:56 <Pseudonym> Yeah, they pay for research!
14:25:43 * stepcut has to pay sales tax by Jan 31
14:25:48 <stepcut> :-/
14:37:45 <wilx> Hmm...
14:37:48 <wilx> ghc -Wall -Werror -fvia-C -funbox-strict-fields -O2 -Icbits -Imk  -package plugins -DLIBDIR=\"/usr/local/lib/yi\" -main-is Boot.main -c Boot.hs -o Boot.o -ohi Boot.hi
14:37:48 <wilx> ghc-6.2.2: unknown package name: plugins
14:37:55 <wilx> I have just installed hs-plugins.
14:38:00 <wilx> What am I missing?
14:40:15 <Lemmih> wilx: Did you register it?
14:42:37 <wilx> Nope.
14:42:40 <wilx> How?
14:42:56 <wilx> Where to find out? :)
14:42:57 <Lemmih> 'make register'
14:43:00 <wilx> oh
14:43:04 <Lemmih> The README file.
14:43:54 <Oeje1> What happens when a package is registered?
14:44:27 <Lemmih> Oeje1: Then GHC knows that it's installed.
14:45:26 <Lemmih> wilx: You're not the first one to miss the README file (-:
14:45:33 <wilx> :))
14:46:16 <wilx> Hm... More errors during Yi compilation :/
14:48:13 <wilx> http://www.nomorepasting.com/paste.php?pasteID=29950
14:49:28 <Oeje1> Lemmih: I mean, will it write to some files in GHC?
14:49:29 <Riastradh> lisppaste2!
14:49:33 <Riastradh> lisppaste2: url
14:49:34 <lisppaste2> To use the lisppaste bot, visit http://paste.lisp.org/new/haskell and enter your paste.
14:51:22 <Heffalump> anyone familiar with using hsql with mysql?
14:51:23 <Oeje1> Lemmih: I got Kaptajn Kaper running in DOSBox. :-D
14:51:43 <Lemmih> Oeje1: What's Kaptajn Kaper?
14:52:20 <Lemmih> Oeje1: It will most likely run 'ghc-pkg < [packagefile]'
14:52:34 <Oeje1> Lemmih: http://www.kaptajnkaper.dk/
14:56:45 <Lemmih> ...
15:04:20 <Lemmih> Greetings, SyntaxNinja.
15:06:59 <fjorden> I have a very basic question... what syntax should I use to pass a list to a function when I'm debugging in ghci?
15:07:31 <fjorden> something a bit like *Module>examplefunction {4} {4,5}
15:07:47 <fjorden> but I need the right brackets and delimiters for my lists...
15:07:47 <Lemmih> func [1,2,3]
15:07:55 <fjorden> thx!
15:08:28 <boegel> fjorden, why would it be different from the syntax in a haskell program?
15:08:31 <Lemmih> Is this intentional: http://haskell.org/hawiki/HaskellIrcPastePage
15:08:59 <Riastradh> lisppaste, Lemmih!
15:09:00 <Riastradh> lisppaste2: url
15:09:01 <lisppaste2> To use the lisppaste bot, visit http://paste.lisp.org/new/haskell and enter your paste.
15:10:41 <lisppaste2> Lemmih pasted "Bug in GHCi?" at http://paste.lisp.org/display/5206
15:10:42 <Oeje1> Riastradh: Maybe lisppaste would be more attractive if it had Haskell syntax hightlighting and library cross referencing.
15:10:52 <Riastradh> Ask chandler to implement it.
15:12:04 <Oeje1> Why would he do that?
15:12:46 <Riastradh> ...uh, because he'd like lisppaste users to be happy, perhaps?
15:13:48 <Oeje1> But no one is using it.  :-P
15:13:57 <Riastradh> ?
15:15:07 <Oeje1> Riastradh: Just kidding you.
15:25:39 <Shammah> Can anyone help me getting ghc running under OSX 10.2?
15:26:38 <Shammah> I'm trying to install from darwinports, but it's failing with a compile error.
15:27:13 <boegel> Shammah, paste your error here:
15:27:19 <boegel> @wiki HaskellIrcPastePage
15:27:19 <lambdabot> http://www.haskell.org/hawiki/HaskellIrcPastePage
15:27:51 <boegel> (I can't help you though, I not a Mac user :))
15:32:49 <Shammah> boegel: posted.
15:57:36 <Lemmih> shapr: How's Haskell Monthly?
16:10:55 <boegel> yeah shapr, any progress ?
16:17:06 <Lemmih> shapr: Could we use Flippi with some kind of LaTeX mode?
16:43:13 * juhp wonders if anyone has used c2hs on x86_64?
16:47:17 <dons> juhp: i've built it, and run some regress tests, that's about it
16:48:04 <juhp> dons: ok, thanks - just getting a ghc error when I run c2hsLocal from gtk2hs...
16:48:13 <juhp> c2hsLocal: internal error: update_fwd: unknown/strange object  12354912
16:48:13 <juhp>     Please report this as a bug to glasgow-haskell-bugs@haskell.org,
16:48:13 <juhp>     or http://www.sourceforge.net/projects/ghc/
16:49:04 <dons> haven't seen that. looks nice though :}
16:49:30 <juhp> of course gtk2hs pushes c2hs pretty hard ;o)
16:49:39 <dons> yeah, that's true
16:50:00 <dons> but this looks more like an amd64/unreg bug, I reckon. or maybe a 64bit rts issue
16:50:16 <juhp> yeah
16:51:39 <juhp> oh, seems it is already reported:
16:51:50 <juhp> http://www.haskell.org/pipermail/glasgow-haskell-bugs/2004-December/004539.html
16:52:42 <dons> ok.
16:55:28 <Heffalump> what's the best way of making a nice simple CGI program in Haskell? I don't want to use WASH.
17:01:00 <sh10151> hm
17:01:13 <sh10151> how complicated does it need to be?
17:01:22 <Heffalump> does what need to be?
17:01:29 <sh10151> the CGI program
17:01:38 <Heffalump> not very
17:01:44 <sh10151> just dynamic content, or some form processing too?
17:02:03 <Heffalump> in general both, but for my current application just dynamic content
17:02:32 <Heffalump> I think the fairly old CGI library by Erik Meijer (updated by Sven Panne) is about the best option, unless you have any other suggestions
17:02:45 <sh10151> well
17:02:49 <sh10151> it's just printing
17:03:00 <sh10151> I knew a guy who wrote his CGI crap in C
17:03:15 <Heffalump> yeah, but I don't want to reinvent the wheel for parameter parsing etc.
17:04:11 <sh10151> well, it was designed to be a pretty simple wheel to reinvent
17:04:17 <Heffalump> true
17:04:23 <sh10151> if someone else has done it in Haskell I would use that instead
17:04:32 <sh10151> as long as it's not doing a lot more you don't care about
17:05:24 <sh10151> is something like CPAN on the table for Cabal?
17:06:30 <Heffalump> I believe so, yes.
17:06:40 <Heffalump> "Hackage"
17:07:33 <sh10151> well good :)
17:07:45 <sh10151> esp. if it is distributed with the compilers/interpreters
17:08:05 <sh10151> that's one of the things that gives perl aficionados warm fuzzies about their language
17:08:13 <Heffalump> oh, do you mean the CPAN application, rather than the CPAN archive?
17:08:18 <Heffalump> if so, I don't know
17:08:25 <Heffalump> Hackage is the software that would run an archive.
17:08:31 <sh10151> hm
17:08:36 <sh10151> yeah, I meant the application
17:47:24 <adoarns> \quit
18:31:40 <vdrab> hi all
18:32:18 <vdrab> question
18:32:20 <vdrab> how would you write a function that maps a list of (Int,Int) pairs to a list of (Int,[Int]) pairs, where the first Int of the pair acts as a unique index?
18:32:34 <vdrab> for instance [(1,3),(1,4),(2,2),(2,6),...] -> [(1,[3,4]),(2,[2,6]),...]
18:33:10 <vdrab> I want to make the resulting list into an array
18:33:47 <vdrab> but the step inbetween proves to be harder than I thought
18:34:06 <vdrab> anyone have an idea? 
18:34:29 <vdrab> I tried recursing down the list using some sort of accumulator, but got stuck
18:36:51 <Lemmih> vdrab: Check 'group' and 'groupBy'
18:37:18 <vdrab> cool
18:37:38 * vdrab runs off to dig up GHC documentation
18:42:05 <jadrian> even with groupBy it's not imediate
18:42:20 <vdrab> yeah, it seems
18:42:30 <jadrian> do you want a list
18:42:33 <jadrian> you said array?
18:42:37 <vdrab> but at least it looks like a step in the right direction
18:42:41 <jadrian> do you really want an *array*?
18:42:55 <jadrian> because if you want an array, then it is trivial
18:43:30 <jadrian> in fact, one option would even be building the array, and then making it into a list
18:43:31 <vdrab> I just need some way to quickly access Int 's that are associated with the unique Int index
18:43:54 <jadrian> if you do not need to change that list often then use array
18:43:56 <vdrab> Array or Data.FiniteMap would do
18:44:07 <vdrab> but how would I build it?
18:44:08 <jadrian> or that
18:44:24 <jadrian> so why do you want to build that list first?
18:44:34 <vdrab> I just thought of generating the right list and then promoting it with listArray
18:44:51 <jadrian> it's worst
18:45:15 <vdrab> maybe there's easier ways, I 'm not familiar with haskell arrays
18:45:25 <jadrian> do you know the bounds of that array?
18:45:48 <vdrab> sure, (1,(length original_list))
18:46:11 <vdrab> the original list is a given
18:46:27 <jadrian> @type Data.Array.accumArray
18:46:30 <lambdabot> Data.Array.accumArray :: forall e i a.
18:46:30 <lambdabot> 			 (GHC.Arr.Ix i) =>
18:46:30 <lambdabot> 			 (e -> a -> e) -> e -> (i, i) -> [(i, a)] -> GHC.Arr.Array i e
18:46:38 <jadrian> I think this is what you want
18:47:22 <vdrab> let's see what that's all about... 
18:47:28 <vdrab> thanks for the hint
18:47:52 <jadrian> it build an array from a list of pairs
18:48:09 <jadrian> the array positions are initialized with  e
18:48:20 <jadrian> and whenever you add an element to a position
18:48:45 <jadrian> the new element in that position will be calculated using the function (e->a->e)
18:48:47 <jadrian> ...
18:49:05 <jadrian> you want to initialize the array positions with  []
18:49:10 <vdrab> then that sure sounds like I may want it :-)
18:49:29 <jadrian> and your function will be flip (:)
18:49:39 <jadrian> and that's it ;)
18:49:47 <vdrab> cool, thanks a bunch
18:50:28 <vdrab> as a side question, building this incremental array is not done in-place, right?
18:50:40 <vdrab> the array is not mutable?
18:51:11 <jadrian> not sure, it would be nice if it is. The array is not mutable.
18:52:01 <jadrian> but if you're just interested in fast access, it's probably a good choice
18:52:23 <jadrian> oh
18:52:24 <vdrab> yeah... the whole lazyness/monad/State issue has kept me away from arrays for a good long while, it may be time to look into them
18:52:36 <jadrian> vdrab: the elements (not indexes) are lazy
18:52:52 <jadrian> vdrab: so the elements are not even built until you need them
18:53:22 <jadrian> wether that's good or bad, it depends...
18:53:48 <jadrian> I think they are strict on indexes though...
18:53:50 <vdrab> so, doing the list appends in the elements, what does that mean? 
18:54:11 <vdrab> the real lists there only get built on lookup?
18:54:32 <jadrian> yeap, that's how I would exepect it to work
18:54:39 <vdrab> and the runtime just keeps a history of how the array was built?
18:54:41 <jadrian> you can even have infinite lists there
18:54:59 <jadrian> well it works like every other lazy structure...
18:55:06 <vdrab> wow, that sounds mighty inefficient :-)
18:55:22 <vdrab> I have laaaarge arrays in mind :-s
18:55:34 <jadrian> try and see how it works
18:55:39 <vdrab> will do.
18:55:48 <jadrian> if it's slow, then look into other stuff
18:55:49 <vdrab> thanks a lot.
18:55:53 <jadrian> np ;)
19:30:35 <Gahhh> how does ghc decide how much to memoize ?
19:56:50 <Lemmih> Gahhh: That's a trade secret. I can tell you if you sign this non-disclosure agreement.
19:57:55 * jadrian is going to bed...
19:57:56 * Lemmih hands Gahhh a document telling him how much [insert big evil firm] is gonna sue his ass if he can't keep the secret.
20:05:36 * tintin dcc's Lemmih the signed NDA
20:11:52 <Lemmih> tintin: Sorry. We got nothing. It was only a trick to keep the stock prices up.
20:15:38 <tintin> haha 
20:15:54 <tintin> is that Information under NDA ?
20:16:11 <tintin> or can i burst the bubble ? and make some money by shorting the stock :D
20:58:34 <juhp> dons: does yi work on x86_64 for you?
20:58:50 <juhp> I get: "ghc-6.2.2: internal error: getMBlock: mmap: Invalid argument"
20:59:26 <dons> haven't tried it on that arch yet.
20:59:35 <juhp> ok
21:00:05 * juhp ponders building a ghc snapshot
21:00:46 <juhp> hm, yi-static segfaults
21:00:54 <dons> hmm. not nice
21:02:09 <dons> mmap is failing in rts/MBlock.c:my_mmap() I think
21:03:56 <dons> now, why is it saying "Invalid argument". hmm. 
21:03:57 <dons>     ret = mmap(addr, size, PROT_READ | PROT_WRITE | PROT_EXEC,
21:03:58 <dons>            MAP_ANON | MAP_PRIVATE, -1, 0);
21:07:17 <juhp> that file seems to have changed significantly in cvs at least
21:07:46 <juhp> ok, I think I'll build the latest snapshot and see if that should help
21:09:54 <dons> I hope it builds with the HEAD. You should try 'make way=static' to avoid having to rebuild hs-plugins (which I don't think can read the new package.conf files use by the cvs version)
21:10:22 <juhp> ok
21:10:58 <juhp> dons: 6.4 will have a new package.conf too?
21:11:58 <dons> yup. all the cabal stuff caused changes to package.confs and .hi files, which hs-plugins parses. So have to port that code
21:13:33 <juhp> ah, I see
21:15:34 <juhp> the changelog for MBlock.c looks encouraging though
21:15:50 <juhp> "date: 2004/11/10 03:20:31;  author: wolfgang;  state: Exp;  lines: +56 -3
21:15:50 <juhp> Implement the mblock map for 64-bit architectures.
21:15:50 <juhp> Fairly primitive data structure, but one 4GB-block, described by a
21:15:50 <juhp> 12-bit block map, is cached for speed.
21:15:50 <juhp> Note that I've nuked the ia64-specific version (I think ia64 wants to
21:15:51 <juhp> use the general 64-bit solution, too)."
21:16:29 <dons> ah, that's right. hopefully that helps.
22:32:26 <musasabi> morning
22:47:23 <shapr> good morning
22:52:38 <shapr> Lemmih: The Monad.Reader is still on hold. I won't start it until there are several authors committed to regular monthly columns. Though someone else could start it before that and I'd still write a column or two.
22:53:10 <shapr> Lemmih: I've been thinking about WikiTeX for Flippi - http://wikisophia.org/wiki/Wikitex .  I think I'll need that at some point for FLM.
23:58:18 <tintin> anyone in here has the First edition of the book "The craft of functional programming " ? Is it different from the second edition ? which edition is better ?
