00:08:29 <Itkovian> meuning
00:19:07 <dblhelix> kosmikus: ping
00:53:17 <Itkovian> wtf?! http://www.thedailywtf.com/forums/37858/ShowPost.aspx
01:07:51 <dons> i'm so glad I don't have to write java
01:10:54 <earthy> itkovian: the daily wtf is not good for you
01:12:07 <Mameluke> what's matter?
01:12:44 <seidan> earthy: and let's not get started on the comments...
01:13:34 <Mameluke> java is not good enough, but it's not bad.
01:14:42 <dons> ah well, this is #haskell, so we encourage gloating
01:14:42 <lament> ah come on
01:14:44 <lament> it's bad
01:15:14 <Itkovian> hmm, we seem to be going down this road every once in a while ....
01:16:00 <Mameluke> official java -> gcj+classpath/kaffe    huh huh huh
01:16:35 <Mameluke> non-free -> free
01:16:43 <dons> quick! purify me with some functions!
01:16:45 <dons> @code
01:16:46 <lambdabot> Ix.hs: -----------------------------------------------------------------------------
01:16:50 <dons> bah :/
01:16:51 <dons> @code
01:16:52 <lambdabot> Strategies.hs: parZipWith :: Strategy c -> (a -> b -> c) -> [a] -> [b] -> [c]
01:16:54 <Mameluke> gpl free
01:16:56 <dons> yay!
01:17:11 * dons sighs with relief as the types wash over him
01:17:19 <earthy> WASH over him? :)
01:17:38 * dons throws types to everyone!
01:17:58 * genneth finds that types produce a good lather
01:18:01 * Mameluke no-type
01:18:08 * genneth wistles a tune and scrubs
01:18:11 <dons> @kind Maybe
01:18:13 <lambdabot> * -> *
01:18:16 <dons> oh I feel SO CLEAN!
01:18:40 <genneth> wait... doesn't that imply a proof of everything?
01:21:42 <earthy> no, why?
01:21:46 <dons> @kind (->)
01:21:47 <lambdabot> ?? -> ? -> *
01:22:04 * dons sighs, and relaxes back into the bubbly types
01:22:35 <lament> @hoogle a -> [a] -> a -> [a]
01:22:37 <lambdabot> Prelude.undefined :: a
01:22:44 <lament> boring
01:23:05 <earthy> @hoogle a -> [a] -> [b]
01:23:06 <lambdabot> Prelude.(:) :: (a -> [a] -> [a])
01:23:41 <earthy> @hoogle b -> [a] -> [b]
01:23:42 <lambdabot> Prelude.(:) :: (a -> [a] -> [a])
01:23:59 <lament> heh
01:24:12 <lament> @hoogle [a]
01:24:13 <lambdabot> Prelude.repeat :: (a -> [a])
01:25:06 <earthy> @hoogle (a -> b -> c) -> (a -> b) -> (b -> c)
01:25:09 <lambdabot> Prelude.seq :: (a -> b -> b)
01:25:24 <lament> @hoogle Bool -> Int -> Char -> Int -> Bool
01:25:26 <lambdabot> Prelude.undefined :: a
01:25:35 <dons> heh
01:25:44 <dons> unify me now!
01:42:42 <ski> @hoogle (a -> b -> c) -> (a -> b) -> (a -> c)
01:42:43 <lambdabot> Prelude.seq :: (a -> b -> b)
01:46:07 <Itkovian> anybody knows any interesting podcasts?
01:46:27 <earthy> I find catholic insider interesting
01:46:45 <Itkovian> erm :-)
01:46:55 <earthy> that's about the only one I religiously listen to. :P
01:47:01 <Itkovian> haha
01:47:06 <Itkovian> I'm not catholic
01:47:29 <earthy> oh, one of my best friends is very much an atheist, but even he enjoys the Catholic Insider
01:48:02 <earthy> where else would you get explanations on the parallels between catholicism and starwars?
01:50:08 <Itkovian> haha
01:50:09 <earthy> or hear Ahnold Schwarzenegger discuss podcasting in the future?
01:50:25 <Itkovian> 'I'll be bach' ?
01:51:22 <earthy> ;)
01:57:11 <Itkovian> earthy: you're from holland right ... do you ever listen to Studio Brussels? They have 'De Afrekening' as a podcast now
01:58:21 <earthy> studio brussel is nice
01:58:30 <earthy> but I don't listen to it that often
01:58:40 <earthy> so I don't really know 'De Afrekening'
01:59:32 <Itkovian> it's a user voted list of current songs
02:42:35 <MarcWeber> What's the way to create an array of random numbers? var <- using map and Random to change a array range to array of random numbers?
02:45:33 <lightstep> mapM randomRIO (for creating random numbers in the IO monad)
02:46:48 <TFK> howdy lightstep
02:48:11 <lightstep> hi
02:48:35 <lightstep> i met Shai Viborsky, he said you avengalize haskell
02:50:04 <TFK> Shai Viborsky? I know a Shai, but not his family name :-/
02:50:20 * genneth sees TFK with a bowler hat and a sexy woman in a catsuit fighting criminals for haskell
02:50:23 <lightstep> maybe i'm mistaken. i mean the one from ramat gan
02:50:38 <TFK> Yup, he's living in Ramat Gan :-)
02:50:49 <TFK> AKA as "deshe"?
02:50:56 <TFK> err
02:51:02 * TFK scratches out that 'as'
02:51:20 <TFK> genneth, stop in the name of the lambda!
02:51:54 <genneth> MarcWeber: i think a random list of numbers would have type IO [Integral] or something like that, so you would only be able to use in an IO context
02:52:14 <genneth> TFK: sorry. got carried away by classic tv :-D
02:52:15 <TFK> http://images.nana.co.il/upload/32005/IsraBlog/38449/posts/1735826.JPG <--- this dude? (Although I gather that he's shaved now.)
02:53:03 <TFK> lightstep, anyhow, I have mentioned Haskell in #israel a few times, but nothing I'd call "evangelizing".
02:53:54 <lightstep> he's less shaved
02:54:10 <lightstep> i think, the picture doesn't show all his face
02:54:23 <MarcWeber> Which kind of documentation do you use? (I'm new to haskell)
02:54:55 <lightstep> there's the documentation of Random in the Standard Libraries part in the Standard HAskell Report
02:55:19 <genneth> and the lambdabot here is very good
02:55:25 <genneth> @index randomRIO
02:55:26 <lightstep> http://haskell.org/onlinereport/random.html
02:55:26 <lambdabot> System.Random
02:55:30 <MarcWeber> lightstep: Is this installed on most systems or should I download it?
02:55:39 <genneth> @type hoogle randomRIO
02:55:45 <lambdabot> bzzt
02:55:47 <genneth> @hoogle randomIO
02:55:48 <lambdabot> Random.randomIO :: Random a => (IO a)
02:55:55 <genneth> MarcWeber: you can always find it online
02:56:05 <genneth> there are offline versions available for download i believe
02:56:12 <MarcWeber> I can use google but at home I don't have access to internet..
02:56:13 <lightstep> MarcWeber, you have the Random module on every system that supports haskell98 (ie, every haskell system(
02:57:16 <MarcWeber> Ok.. I've googled and I've found the function range.. But I don't know which module to import..  So I think it's a good idea to download the offline version
02:59:47 <lightstep> so you can say @index range
03:00:24 <TFK> @index range
03:00:25 <lambdabot> Data.Ix, Data.Array, Data.Array.IArray, Data.Array.Unboxed, Data.
03:00:25 <lambdabot> Array.MArray, Data.Array.IO, Data.Array.ST, Data.Array.Storable,
03:00:25 <lambdabot> Data.Array.Diff
03:00:46 <lightstep> so it's not really a Random stuff, only Ix
03:00:58 <TheHunter> This is the offline version library documentation: http://haskell.org/ghc/docs/latest/libraries.html.tar.gz
03:02:14 <MarcWeber> TheHunter: Thanks!
03:08:41 <MarcWeber> Is Language.Haskell.TH.Sytax the module containig the range function? ghc can't find it.. It's stability is marked as experimental..
03:09:10 <TheHunter> nooh, Data.Ix
03:13:08 <TheHunter> if you /really/ want an array of random numbers, probably the easiest way is do { gen <- getStdGen; newStdGen; return $ listArray (1,100) $ randomRs (1,6) gen }
03:13:24 <TheHunter> this creates an array of 100 random numbers between 1 and 6.
03:14:03 <TheHunter> inside the IO monad, of course.
03:14:09 <MarcWeber> TheHunter: Thanks. Exactly
03:14:18 <MarcWeber> I was trying  s <- map randomRIO(1::Int, 10) range(20)
03:15:55 <MarcWeber> Have to go now
03:15:58 <TheHunter> s <- listArray (1,20) =<< replicateM 20 (randomRIO (1,10))
03:16:22 <TheHunter> this would work, too, but is less efficient and somewhat more clumsy.
03:16:41 <MarcWeber> Thanks a lot.. Will have look at it later on..
03:17:26 <TheHunter> dang, that should've been fmap and not =<<.
03:17:30 <lightstep> TheHunter, doesn't ghc optimize that kind of stuff? after inlining, it only contains reducable sequences of calls
03:18:23 <TheHunter> ime, ghc optimizes almost nothing.
03:18:53 <TFK> What's "ime"?
03:19:11 <TFK> "estimate"?
03:22:16 <earthy> 'in my experience'
03:23:01 <TFK> ah, thanks
03:24:47 <TheHunter> re
03:24:51 <TheHunter> let's see.
03:27:31 <Beelsebob> mornin
03:28:08 <TFK> g'day
03:28:56 <Beelsebob> TFK I've got a new evil program :)
03:29:05 <Beelsebob> shaves of a further 10%
03:29:11 <TFK> What kinds of evil things does it do?
03:29:31 <Beelsebob> where's that paste we were working on again?
03:29:34 <lightste1> see no evil
03:29:39 <TFK> 10% won't cut it down from 7 seconds to 4 seconds :-P
03:29:44 <Beelsebob> hehe
03:29:52 <TFK> Is your program as bloated as it sounds?
03:29:57 <Beelsebob> yes
03:30:00 <TFK> At least the previous solution was quite concise.
03:30:17 <TheHunter> replicateM is (replicate .) . sequence, sequence uses foldr, so that's good.
03:31:10 <TheHunter> replicate uses take, ghc can't deforest that, i think, although the implementation is quite complicated
03:31:52 <Beelsebob> tfk: its actually slightly simpler than my last bloater
03:32:18 <michaelw> Beelsebob: http://paste.lisp.org/display/9709 ?
03:32:36 <Beelsebob> that's the one
03:32:38 <Beelsebob> http://paste.lisp.org/display/9709#9
03:34:30 <TheHunter> lightstep, it's only 6% faster here...
03:34:50 <TheHunter> the point is it's conceptually easier.
03:36:19 <lightste1> i meant the folding of getStdGen/setStdGen inside the randomRIO call. but if ghc can't optimize the items in replicate, it can't optimize this too
03:36:37 <lightste1> i also think the lower-order s easier in this case
03:37:16 <Beelsebob> michaelw: if you can see any gains in that last evil one, I'd be most appreciative
03:48:19 <Itkovian> 'noon
03:54:22 <TFK> 'gday
04:01:14 <Beelsebob> lo
04:06:18 <Itkovian> beelsebob: are you the same guy as tomdavie?
04:06:24 <Beelsebob> yes
04:06:27 <Itkovian> ok
04:06:31 <Beelsebob> work and home
04:06:35 <Itkovian> just to know who I was talking to yesterday
04:06:38 <Itkovian> ic
04:06:39 <Beelsebob> :)
04:06:47 <Itkovian> proly beelsebob at work, eh ;-)
04:07:05 <Beelsebob> hahaha, it's 12:05 and you think I'm in work?
04:07:11 <Beelsebob> *g*
04:09:05 <Beelsebob> speaking of which... I *should* be at work... bbiab
04:48:25 <tomdavie> lo again
04:57:20 <kosmikus> dblhelix: pong, sort of
04:57:22 <Itkovian> hi
04:57:29 <Itkovian> short route to work it seems
04:57:37 <dblhelix> kosmikus: well, a bit delayed :)
04:57:46 <dblhelix> kosmikus: how's life in freiburg?
04:58:14 <kosmikus> I've had to teach until 12, then had lunch, and I have another appointment at 2
04:58:24 <kosmikus> but life's good
04:58:30 <kosmikus> how's yours?
04:58:51 <dblhelix> quite good -- they've actually assigned me room B026 here ;)
04:58:54 <shapr> foo
04:59:01 <kosmikus> dblhelix: so I heard
04:59:06 <earthy> moritori te salutans
04:59:14 <shapr> selectio naturalis
04:59:16 <kosmikus> hehe
04:59:23 <dblhelix> you did? from whom?
04:59:30 <kosmikus> dblhelix: from jur
04:59:40 <dblhelix> ah :)
05:00:20 <dblhelix> what is it exactly that you're doing in freiburg?
05:00:20 <kosmikus> dblhelix: what's going to happen to adorp?
05:00:47 <kosmikus> ralf is filling in as a professor this semester, and I'm his assistant
05:00:59 <dblhelix> kosmikus: I defend it with my life until you indicate that you no longer need it
05:01:02 <kosmikus> actually, I'm only in Freiburg when I have to teach, which is about 2 days per week
05:01:23 <kosmikus> and next week is the last week
05:01:25 <dblhelix> what is ralf teaching?
05:01:28 <kosmikus> from august on, I'll work in Bonn
05:02:21 <kosmikus> he's giving a lecture on software technology; I was responsible for a seminar on program construction and specification and for a Haskell programming project
05:03:12 <dblhelix> what are you using adorp for anyway?
05:03:47 <kosmikus> I still have some data on the disk, and I'm still using it as a "base computer" for remote access
05:04:06 <kosmikus> Bonn infrastructure still has some issues I have to solve before I can move everything there
05:04:11 <kosmikus> and Freiburg is too temporary
05:04:20 <kosmikus> actually, I'm irc'ing from adorp currently
05:05:37 <dblhelix> well, have to see jur now ... -- all the best in freiburg and bonn!
05:05:52 <dblhelix> you'll be at the dgp workshop?
05:06:38 <kosmikus> sure
05:06:53 <dblhelix> guess I'll see you then :)
05:06:56 <kosmikus> yes
05:16:48 <MarcWeber> Which module must i import to access getStdGen?
05:17:35 <arjanb> @index getStdGen
05:17:36 <lambdabot> System.Random
05:18:26 <MarcWeber> arjanb: What is @index?
05:19:14 <arjanb> it's the same as :i in ghci
05:19:50 <arjanb> err no
05:22:56 <dons> no, we use our own lookup table
05:31:11 <MarcWeber> TheHunter has send me this peace of code:
05:31:14 <MarcWeber> { gen <- getStdGen; newStdGen; return $ listArray (1,100) $ randomRs (1,6) gen }
05:31:27 <MarcWeber> some minutes ago.. But I'm not sure how to use it..
05:31:51 <MarcWeber> Is this a function definition? (Because of return?)
05:35:03 <ndm> functions do not use return, monads use return
05:35:22 <MarcWeber> ndm: How to use this peace? Can I say let a= { .. } ?
05:35:27 <ndm> but i think it is a function definition
05:36:00 <ndm> I think you need "do" in front of that, as it looks like its in a monad
05:36:33 <ndm> foo = do get <- getStdGen
05:36:35 <ndm>                newStdGen
05:36:36 <ndm>                return ....
05:36:46 <ndm> then let a = foo
05:36:49 <MarcWeber> ndm: Thanks. All I have to do now is importing listArray..
05:37:21 <MarcWeber> ndm: Which is your prefered way to look for the corresponding module?
05:37:44 <ndm> I think you can use lambdabot to do it, not sure how though
05:38:31 <ndm> import Array would be my guess
05:38:46 <ndm> @hoogle listArray
05:38:47 <lambdabot> Array.listArray :: Ix a => ((a, a) -> [b] -> (Array a b))
05:38:57 <ndm> ah, yes it is
05:40:22 <MarcWeber> ndm: Thanks.. I think I'll use fpc to implement this little project and then I'll learn some more haskell..
05:40:38 <ndm> MarcWeber: fpc?
05:40:48 <MarcWeber> free pascal compiler
05:40:51 <ndm> ah
05:41:06 <MarcWeber> Delphi/Pascal was the first language I've learned and I know that quite well..
05:41:10 <ndm> if its using random numbers, then you have to use Monad's in Haskell, and that gets a LOT more complicated
05:41:28 <tomdavie> I feel compelled to point out Colin Runciman's sarcy comment again... " In the Era of Monadic Enlightenment, obfuscated imperative programming is the Way To Go.  :-\  :-) "
05:41:42 <ndm> www.cs.york.ac.uk/~ndm - at the bottom
05:42:08 <autrijus> you can also pregenerate an infinite supply of random numbers...
05:42:16 <tomdavie> indeed
05:42:16 <autrijus> or use (gasp) implicit linear parameters
05:42:36 * tomdavie stares at a plate of pasta
05:50:24 <Philippa> tomdavie: not everybody considers pure FP always-unobfuscated...
05:50:59 <tomdavie> true... but I do tend to consider monadic code to be obfuscated
05:51:10 <Itkovian> is anybody here following the matrix iv discussion on the cafe list?
05:51:26 <tomdavie> so it's a case of always obfuscated, or sometimes obfuscated
05:51:31 <Philippa> funny, much of it's the easiest-to-read code I've read in any language whatsoever - often even easier than some DSLs for the same language
05:51:48 <Philippa> granted the do notation helps a lot when it comes to de-obfuscating
05:52:00 <tomdavie> hmm, well I guess we find different things easy to read then
05:52:03 * TFK blinks
05:52:06 <Philippa> parsec parsers're absolutely beautiful
05:52:16 <tomdavie> because I honestly can't stand reading monadic code
05:52:21 <Philippa> I'm honestly not convinced it's even possible to make parsing less obfuscated
05:52:30 <tomdavie> heh
05:52:47 <tomdavie> I don't know... write a grammar... as the parser...
05:52:57 <tomdavie> if it could be done that would take the cake
05:53:02 <Philippa> that's what parsec does
05:53:16 <Philippa> only the grammar's annotated sufficiently to extract meaning from it, and the metalanguage is higher-order
05:53:25 <tomdavie> then why does it look in any way monadic?
05:53:45 <tomdavie> ah... okay
05:53:58 <tomdavie> well... that does sound quite spanglp
05:54:06 <tomdavie> s/p$/y$/
05:54:26 <tomdavie> but I'm not sure it has to be monadic
05:54:42 <Philippa> it has to be /something/ that hides piping the text being parsed around
05:54:45 <tomdavie> and I doubt that the code that the meta-language hides is easy to read
05:54:54 <tomdavie> indeed
05:54:55 <earthy> parsing obfuscated?
05:55:06 <earthy> what's obfuscated about parsing?
05:55:10 <tomdavie> not much
05:55:15 <tomdavie> it's really nice in haskell
05:55:18 <Philippa> the meta-language is just the set of combinators parsec provides, much as EBNF is a metalanguage
05:55:58 <tomdavie> okay... not the point I was trying to make
05:56:01 <ndm> Philippa: http://www-users.cs.york.ac.uk/~ndm/downloads/a_new_parser-17_nov_2004.pdf
05:56:01 <Philippa> the combinators include return and thus the whole of haskell which may or may not be considered cheating, but still
05:56:03 <tomdavie> but nm
05:56:11 <ndm> parsing is highly obfustcated
05:56:27 <ndm> i tried modifying a parser combinator grammar, it was not fun!
05:56:53 <tomdavie> anyway... I didn't think that the parser combinators were monadic?
05:57:04 <ndm> some are, some aren't
05:57:37 <Philippa> there's no "The parser combinators"
05:57:52 <Philippa> ndm: how well do you grok CFGs more generally?
05:58:05 <ndm> Philippa: grok?
05:58:08 <Philippa> understand
05:58:17 <tomdavie> e.g. certainly ghc's parser is non-monadic
05:58:29 <ndm> pretty well, i know LALR etc
05:58:40 <ndm> and I know the theory of pure CFG's well
05:59:21 <Philippa> fair enough. What combinator lib did it use etc etc? I've seen some that I find pretty hard to deal with, though I'm generally pretty good with what I consider idiomatic parsec code
05:59:34 * earthy types parsers for LL(1) grammars out at typingspeed, in C no less.
05:59:42 <Philippa> (there's the occasional surprise when something 'interesting' has been achieved with try, admittedly)
06:00:42 <ndm> Philippa: ParseLib - not sure its something thats officially released
06:00:49 <ndm> might just be something that was floating around
06:01:53 <Philippa> the one from The Craft of Functional Programming?
06:02:50 <ndm> quite possibly - it was already in teh project i had to modify
06:04:52 <Philippa> it doesn't look the most fun thing ever
06:05:15 <Philippa> one of the reasons monads work for parsing combinators is that they're a very clear match for what's going on
06:05:22 <Philippa> you /want/ a result, you /want/ sequencing...
06:05:39 <ndm> i intend to learn Parsec at some point
06:05:45 <ndm> but have not found the time yet
06:06:02 <shapr> warg!
06:06:19 <Philippa> it'll take you mebbe 2 hours max to learn the core of it. The rest's just finding all the useful derived combinators that come with it
06:06:39 <Philippa> (the many and chain variants, there's one that does bracketed-by kinda stuff, all sorts of things)
06:06:45 <tomdavie> you don't really want sequencing though, you want to be able to backtrack... It's something very pure - A ::= B C is very like, to get A you need to do B and C
06:07:12 <Philippa> tomdavie: you /can/ backtrack, the parser does it for you. The sequencing is "match B-and-then-C"
06:07:48 <Philippa> backtracking is one of those things monads can "just do". Parsec expects you to annotate where it can happen, but that's entirely an efficiency thing
06:08:03 <tomdavie> yes, I know... but it's not something that you want to say explicitly... you don't want to say "match a B" "when you match a B, try to match a C" "if you can't try to match a differet B"....
06:08:19 <tomdavie> it's something you want to say in a very functional way - there should be a B, then a C
06:08:38 <Philippa> why not? "(do foo; bar;) <|> baz"
06:08:58 <tomdavie> yes... but that's a very functional way of expressing it
06:09:08 <Philippa> and it /also/ contains the sequencing
06:09:12 <tomdavie> you aren't explicitly saying backtract
06:09:31 <tomdavie> anyway... can't that be expressed as (foo <+> bar) <|> baz
06:09:34 <shapr> tomdavie: try it main! It's way easy!
06:09:42 <ndm> i'm a slow learner, without much time unfortunatley!
06:09:56 <tomdavie> yeh... I know it's easy... I'm saying it isn't something very monadic
06:09:57 <Philippa> only if you don't mind not being able to usefully extract info from foo and bar
06:10:17 <Philippa> it's something exceedingly monadic, it's an exact damn match for the monad model. It's just not what /you/ think of as monadic
06:10:57 <Philippa> ever considered how the List monad effectively gives you DFS-with-backtracking?
06:11:02 <kzm> To add my $0.02, Parsec can be as monadic (or not) as it wants, it's simply a great tool.
06:11:10 <tomdavie> indeed
06:11:33 * kzm is off for the summer.  Whee!
06:11:41 <shapr> kzm: summer coding?
06:11:41 <Philippa> kzm: making it not-monadic would remove the do notation though, which'd make it significantly clumsier to use
06:12:05 <kzm> shapr - summer vacation.  With my laptop.  We'll see about the coding.
06:12:18 <Philippa> enjoy either way
06:12:28 <shapr> Sounds like fun. I have a week free now, I think I'll try to get someone to work with me on Fermat's Last Margin.
06:12:33 <tomdavie> philipa: but... I just demonstrated a neater solution to yours that get's closer to the origonal BNF, and looks nicer
06:12:49 <Philippa> and doesn't scale
06:13:05 <tomdavie> either way... the monadic code is more obfoscated, no?
06:13:09 <kzm> Philippa, yes - but the point is that you don't really have to think about it a lot.  Just 'do' it.  (How I learned to stop worrying, and love Monadic Parser Combinators)
06:13:15 <tomdavie> ... which was the original statment
06:13:32 <kzm> (I didn't get the start of this discussion)
06:13:33 <Philippa> for that one tiny case. It sure as hell isn't when you want to extract actual data during parsing rather than just matching something
06:14:06 <tomdavie> I was under the impression that you got a nice data structure back from the parse
06:14:19 <Philippa> you've left no way to actually define that structure
06:14:21 <tomdavie> so it would be quite easy to get information out
06:14:23 <Philippa> Parsec has that - it's the return value
06:14:24 <kzm> Okay - my CD is burnt to completion.  Gotta run!  Have a great summer, everybody!
06:14:33 * kzm packs his towel, and takes off.
06:14:57 <tomdavie> philippa: precicely... so I get my AST out, and work on that... also functionally
06:16:05 <Philippa> and you'll almost certainly end up reinventing monads
06:16:12 <tomdavie> not at all
06:16:18 <Philippa> or else finding something that all of a sudden /is/ more obfuscated
06:16:28 <tomdavie> I end up with two distinct stages - a parse that produces an AST
06:16:36 <tomdavie> and then a process that works on the AST
06:16:49 <tomdavie> and tree traversals look beautiful in pure functional code
06:16:59 * Philippa rolls her eyes
06:17:05 <Philippa> WTF do you think parsec /does/?
06:17:33 <tomdavie> well... it does either of our two approaches
06:17:43 <tomdavie> one of them comes out beautiful and pure
06:17:45 <tomdavie> the other doesn't
06:17:47 <Philippa> you seem to think our approaches are further apart than they are
06:17:51 <tomdavie> no
06:17:56 <Philippa> because the other isn't written in terms of pure code, oh no
06:18:03 <tomdavie> I appreciate that thef are remarkably similar
06:18:15 <tomdavie> but mine separates two distinct stages
06:18:24 <tomdavie> is easier to reason about
06:18:29 <tomdavie> is easier to debug
06:18:33 <Philippa> as does parsec, it just has incredibly powerful AST generation
06:18:34 <tomdavie> and is easier to read
06:18:58 <Philippa> I repeat: Parsec does /not/ force you to manually fuse AST generation and AST traversal
06:19:04 <tomdavie> yes... *it* does it - those stages are not clear to somone reading the code
06:19:21 <tomdavie> I don't want it to fuse the stages
06:19:22 <Philippa> traverse (parse input). Clear as day.
06:19:43 <tomdavie> yes... precicely... that's what I'm sugger
06:19:46 <tomdavie> suggesting
06:19:54 <Philippa> and gee, guess how parsec gets used in practice?
06:19:57 <tomdavie> and it doesn't need you to use monads
06:20:20 <Philippa> sure. Now show me how you're going to make AST generation easy
06:20:29 <Philippa> hint: you're going to have to juggle a crapload of bindings about
06:20:33 <tomdavie> no
06:20:47 <tomdavie> I'm going to use what the parser combinators give me back
06:20:52 <Philippa> or else you're going to have to force a specific AST structure, which is considerably worse
06:21:02 <Philippa> Ah. Your parser doesn't produce an AST then
06:21:07 <tomdavie> don't you think ghc's parser would be monadic if this was hard?
06:21:09 <Philippa> it produces a CST
06:21:33 <tomdavie> okay, yes, it probably gives me something slightly more concrete than yours
06:21:36 <Philippa> GHC's parser predates the research on monadic parser combinators if nothing else
06:21:41 <tomdavie> so what's hard about processing that
06:21:49 <Philippa> right. I get to go straight to AST.
06:21:58 <tomdavie> yes... in one ugly stage
06:22:09 <Philippa> I think you'll find it tends not to be ugly at all
06:22:16 <tomdavie> lots of short neat stages are better than one ugly complex one
06:22:33 <tomdavie> especially when it's all being done lazily
06:22:34 <shapr> tomdavie: try it!
06:22:49 <Philippa> as by and large it leaves out code ("don't bother generating and re-parsing/traversing nodes for separators and parens")
06:23:14 <tomdavie> philippa: lazyness deals with that
06:23:26 * Itkovian wonders if tomdavie will hold out against Philippa 
06:23:26 <Philippa> no, it doesn't. Because you still have to traverse all the damn separators
06:23:44 <tomdavie> and what's your point?
06:23:44 <Philippa> effectively you end up duplicating code
06:24:00 <shapr> I have the fifteen minute rule for movies, music, etc. If someone clueful suggests something to me, even if I think it's a bad idea, I'll give it fifteen minutes.
06:24:25 <tomdavie> indeed
06:24:28 <tomdavie> 20 mins here
06:24:35 <shapr> tomdavie: fifteen minutes of trying might be more enlightening.
06:24:47 <Philippa> that statements = statement `sepBy1` separator is a lot easier to work with - you just get a list of the results of the matches for separator
06:24:49 * ndm backs tomdavie up
06:24:51 <shapr> Sometimes I still don't like something after trying it.
06:24:58 <shapr> But at least I tried it :-)
06:25:34 <tomdavie> philippa: I seem to remeber that way back in this discussion the question was ``are monads in general more obfuscated than pure code''
06:25:49 <shapr> I'd say "no"
06:26:07 <Philippa> right. Show me pure code to match what that does, then?
06:26:23 <tomdavie> I already did
06:26:26 <Philippa> no, you didn't
06:26:30 <tomdavie> using the <+> combinator
06:26:37 <tomdavie> and even in your best case for monads, the discussion seems to be pretty rife about which one is better
06:26:42 <ski> monads abstract computation. if the monad a good fit for the problem, it will prolly be less obfuscated (but when is it a good fit ?)
06:26:54 <tomdavie> I will conceed, there are cases where it's better to use monads
06:27:01 <tomdavie> but they are few and far between
06:27:07 <Philippa> the discussion seems to be the two of us, with a lot of people pitching in occasionally but mostly getting bored
06:27:16 <ndm> and mainly involve IO
06:27:21 <shapr> I really like monads. I think they're elegant and powerful.
06:27:25 <Philippa> IO. List. Parsec. Unification. Want me to carry on?
06:27:29 <ndm> have you seen Clean? It doesn't have Monads, but does have uniqueness types
06:27:34 <tomdavie> yes... indeed... that's why I'm trying to end the discussion
06:27:50 <shapr> Yes, but the monadic interface is a powerful compositionality tool, uniqueness types do something else.
06:28:09 <Philippa> yeah, I've taken a brief look and immediately find myself missing monad transformers
06:28:14 <Itkovian> nono, get on with it ...
06:28:23 <ski> tomdavie : it seems you favour one combinator library/module, and Philippa another one. and that Philippa's preference happens to be monadic, and yours not. correct ?
06:28:38 <tomdavie> ski: that about sums it up :)
06:28:42 * shapr wants to play with *all* the toys
06:28:48 <tomdavie> hehe
06:28:56 <ski> (s/preference/preferred library/)
06:29:13 * tomdavie would rather not play with the toys with sharp bits on
06:29:22 <Philippa> ski: to go a step further, that the only thing tom can demonstrate as preferable beyond "it's non-monadic" is a restriction as to the kinds of results yielded
06:29:37 <shapr> uniqueness types are roughly linear values.
06:29:58 <tomdavie> philippa: yes... I tend to find that restricting yourself usually makes things a lot neater
06:30:09 <ski> ndm : uniqueness types are interesting. but does not cover the same issues as monads (though some overlapping, in IO)
06:30:21 * shapr agrees with ski
06:30:24 <tomdavie> after all... look at C... almost no restrictions, and a big mess
06:30:29 <ndm> ski: if i use a monad, typically i'm doing IO
06:30:51 <shapr> But, monads are just an abstraction like OOP. (though I claim monads are more like metaclasses)
06:30:52 <ndm> ski: in fact, i don't think I've _ever_ used another Monad
06:31:02 <tomdavie> anyway... I'm gonna bail... I have things to write
06:31:14 <Philippa> I find that in this case your restriction makes for significantly uglier code that actually obfuscates the transition from concrete syntax to abstract syntax tree - if you've no use for the concrete syntax tree itself, this really does not seem to be a gain
06:31:26 <shapr> I have to finish my ArrowsIntroduction.
06:32:20 * ski thought of mentioning arrow based parsers, before
06:32:43 <Philippa> ski: nice idea, but I want my higher-order parsing - which means the arrow's also a monad anyway
06:33:05 <ski> hm
06:33:10 <aheller> I'm probably the 20898345287th person to say it, but is the Attribute Grammar article still supposed to be unviewable?
06:33:27 * shapr fixes
06:34:58 <ski> dankedankevieledanke
06:35:15 <aheller> Thanks!
06:35:22 <shapr> I don't agree with everything in the AGs article, but I'll put my comments in the feedback.
06:36:16 * Philippa gives shapr an award for diplomacy
06:36:37 * shapr grins
06:36:47 <shapr> Well, I'll just put some AGs challenges into the feedback.
06:36:52 <Philippa> it strikes me as more than a little agit-prop, if you see where I'm coming from
06:36:55 <shapr> Like if you what you say is true, how can AGs do X ?
06:37:00 <Philippa> unification
06:37:04 <Philippa> that should be a good one
06:37:17 <shapr> Monads do more than sequencing.
06:37:29 * ski thinks the second paragraphs second sentence should be augmented with a "in some directions" ..
06:37:32 <Philippa> List-like stuff seems fairly easy unless I'm mistaken, and we already know RWS works
06:37:49 <shapr> And monad transformers cannot be commutative, their order is important for the semantics.
06:38:28 <Philippa> you're missing an "in general" there
06:38:36 <shapr> Right, sorry.
06:38:51 <Philippa> the RWS crowd're fairly trivially commutative with each other, for example
06:39:37 <ski> hm, seems he's going to use a traversal example
06:41:46 <musasabi> Having a reworked mtl would be nice for the future - but that would break lots of code.
06:41:58 <shapr> mtl?
06:42:25 <musasabi> monad template library
06:42:29 <shapr> oh
06:42:35 <shapr> Yes, that would be nice.
06:49:16 <earthy> monads do *less* than sequencing
06:49:35 <Philippa> they do offer a sequence-if-there-is-one, IYSWIM
06:49:48 <Philippa> if there is a sequence, it's going thataway
06:49:49 <earthy> um
06:50:03 <earthy> they offer the possibility for a sequence
06:50:36 <Philippa> yeah, but you also know which way it's going if there is one. You never have to read a do statement bottom-to-top
06:50:45 <ski> monads (rather the monadic bind), offer "logical/syntactical" sequencing
06:51:36 <ski> the code under the monadic layer may backtrack and except and fail and jump around, but you still read the monad level sequentially (wrt bind)
06:52:17 <earthy> philippa: if you add =<< you do
06:52:58 <Philippa> earthy: har har. Doesn't affect the 'statement' sequence within do, only what happens within an individual statement
06:53:18 <earthy> ;)
06:55:10 <musasabi> Sometimes =<< is most readable as it corresponds more closely to (.)
06:55:30 <musasabi> That is if one considers function composition to be readable.
06:55:59 <jyp> imho =<< is more like $
06:56:38 <jyp> hence quite readable
06:56:43 <Philippa> musasabi: that, and because binding goes <-
06:58:16 <Philippa> I suspect I'm going to end up using =<< more often than >>=, but that just gives you top-to-bottom, right-to-left code
06:58:32 <Philippa> (because I use do most of the time)
07:16:27 <ski> (.) corresponds to let (<@<) :: Monad m => (b -> m c) -> (a -> m b) -> (a -> m c); (bmc <@< amb) a = bmc =<< amb a in (<@<)
07:17:28 <ski> the important thing about bind is that it gives a kind of "logical" sequencing (in the sense of the monad). not as much a matter of how it's written
07:27:57 <shapr> I'm thinkin it's time for a shootout, AGs vs Monads.
07:28:08 * Philippa sniggers
07:28:22 <shapr> I really don't understand AGs well enough to argue with details, but they sure don't look equal to me.
07:28:27 <Philippa> I just wish the AG guys would pimp stuff more accurately
07:28:32 <ski> AGs *and* Monads !
07:28:33 <basti_> whats AG?
07:28:33 <ski> ;)
07:28:38 <shapr> Rather than argue by looks, I say it's time to code.
07:28:39 <ski> Attribute Grammars
07:28:40 <basti_> arrow generators?
07:28:41 <basti_> ahh.
07:28:42 <basti_> =)
07:28:42 <Philippa> ski: is the right answer
07:28:49 <Philippa> AGs for fold-like things, monads for semantics
07:28:58 <shapr> Yeah, but I have to know how they compare to be able to use them well together.
07:29:05 <basti_> attribute grammars are a tool.
07:29:20 <shapr> And I want as many tools as possible.
07:29:33 <basti_> hmm i think the sheer number doesnt count
07:29:48 <Philippa> shapr: and that's why the chan's so big? :-)
07:29:50 <shapr> I think it does, when the tools are unique and not just simple isomorphisms of each other.
07:30:09 <basti_> hmmk
07:30:24 <shapr> I think most mental tools are complex isomorphisms of each other, ya know the whole turing tarpit..
07:30:26 <basti_> but i have my doubts about many many non uniqueness assumptions ;)
07:30:32 <basti_> yes
07:30:42 <basti_> uhm non equality
07:30:43 <shapr> I think usability is the secret, so I want to see a bunch of tools to know what's easy to use.
07:30:47 <basti_> or non isomorphism
07:30:55 <basti_> like uhm, haskell? =)
07:31:26 <shapr> I mean like computational patterns: monads, AGs, Arrows, etc
07:31:34 <shapr> Haskell is on a different tool level from those.
07:31:44 * basti_ nods
07:31:55 <Philippa> though there's something to be said for the set of more basic patterns haskell supports
07:32:01 <basti_> i think AGs are fine if it is a real AG problem.
07:32:12 <basti_> sorting an array via an AG is possible, I'm sure.
07:32:20 <basti_> but if that is fun?
07:32:35 <Philippa> actually that might make an interesting question
07:32:47 * ski thinks AGs mostly work with algebraic datatypes
07:32:48 <Philippa> wonder how close the link to metamorphic programming is
07:32:55 <basti_> yes. maybe it might.
07:32:55 <basti_> =)
07:33:10 <basti_> ski: then a list...
07:33:15 <ski> Philippa : what was metemorphic prog. now ?
07:33:27 * Philippa always did think of quicksort as "convert array to bst, flatten bst into array"
07:33:29 <basti_> i want metaphoric programming...
07:34:12 <Philippa> ski: coding by specifying sequences of transformations between different data structures, where data structure is something you can layer on a carrier
07:34:22 <shapr> I want amphetic programming.
07:34:25 <Philippa> (for example, you can layer set or map on top of a List type)
07:35:16 <ski> Philippa : carrier ?
07:35:27 <ski> shapr : hehe
07:35:34 <ski> ah
07:35:36 <Speck> oooh, I understood that from reading CT papers
07:35:58 <ski> Philippa : you mean underlying representation type, i think
07:35:59 <Speck> at least in the form of catamorphisms
07:36:25 <Philippa> converting a List-as-list to a List-as-set and back removes duplicates, to give an example
07:36:30 <Philippa> ski: yup
07:37:08 <Philippa> Speck: you might find the papers on metamorphic programming interesting then
07:37:19 <basti_> carrier pigeon?
07:37:23 <Philippa> the cool thing is that a bunch of laws were dug up, you can optimise a lot of that stuff pretty heftily
07:37:46 <Speck> I might indeed. Would monad comprehensions be a good syntax for metamorphic programming? (to see if I have a jist of what it is)
07:37:47 <Philippa> I'm not quite sure if you can get in-place quicksort out, but IIRC you can get an imperative quicksort implementation
07:37:56 <Philippa> Speck: no
07:37:58 <Philippa> not AIUI
07:38:01 <ski> Philippa : and you must use same repr type ?  or just and sequence of folds, unfolds, etc ..
07:38:01 <Philippa> read the papers
07:38:12 <Speck> do you have a link?
07:38:25 <Philippa> ski: it's a sequence of folds and unfolds, so the representation type can shift
07:38:34 <Philippa> Speck: google "metamorphic programming", it's all I'd be doing
07:38:34 <ski> ok
07:38:44 <Speck> ok
07:48:50 <basti_> hmmm.
07:49:36 <basti_> what is a function that calculates a list from a tree? cata, ana or hylo (or none of these)?
07:49:49 <ski> depends
07:50:02 <ski> if it folds the tree, then it's a cata
07:50:29 * genneth imagine a karate champion laying in to a tree
07:50:31 <basti_> what if it folds the tree but unfolds a list?
07:50:50 <ski> if it e.g. each time deletes the smallest elem of the tree, and put that as elem in list, then make rest of list from rest of tree, then i think it's an ana
07:51:40 <ski> i'm not sure but maybe it's possibly to be both cata and ana at the same time ..
07:51:49 <basti_> thats what i was asking
07:52:07 <basti_> one should give that a name.
07:52:16 <basti_> "hypermorphism" or something.
07:52:18 <ski> if ti can actually happen
07:52:21 <basti_> anabolism
07:52:22 <ski> it*
07:52:25 <ski> heh
07:52:26 <basti_> hmm I think it can
07:52:35 <basti_> i should write a littel demo
07:54:08 <Igloo> JaffaCake: Are you here?
07:54:17 <JaffaCake> yup :)
07:54:31 <Igloo> Would you expect forkIO to work correctly on IA64/Linux?
07:54:54 <Igloo> and should I be able to share an MVar between things that are forkOSed?
07:55:18 <JaffaCake> you mean forkOS?
07:55:31 <Igloo> (IIRC the same problem happens for any non-x86 Linux)
07:55:43 <Igloo> I mean forkIO in the first line and forkOS in the second
07:56:04 <JaffaCake> 1. yes, I don't see why not, and 2. yes
07:56:12 <Speck> why is [] :: [a]
07:56:25 <Igloo> OK, ta
07:56:26 <JaffaCake> I presume you are going to follow this question with a bug report :)
07:56:39 <genneth> Speck: [] is a constructor that returns a list of anything
07:56:47 <Igloo> When I have more to say than "something odd happens", yes  :-)
07:57:03 <JaffaCake> ok
07:57:14 <genneth> Igloo: forkIO at least works on amd64
07:57:40 <Speck> data List a = Nil | Cons a (List a)   so.... [] == Nil would still be of type List a which is [a], right?
07:58:27 <Itkovian> bye
08:02:14 <Igloo> JaffaCake: Ah, I think I see the problem. If I do a forkProcess and a waitForProcess on the returned PID, how do I need to structure things so the process doing the waitForProcess is a parent of the forked one?
08:03:06 <Igloo> Currently the waitForProcess is inside a forkIO or forkOS. If I rearrange it so that isn't the case, should that be sufficient?
08:03:55 <genneth> Speck: yes, afaik
08:03:56 <ski> Speck : yes
08:05:52 <Igloo> (with -threaded, incidentally)
08:07:48 <tomdavie> anyone know how to resolve dependancy errors in ghc?
08:07:58 <tomdavie> Rebuilding dependencies ... ghc-6.4: Error; multiple packages match Cabal: Cabal-1.0, Cabal-0.5
08:10:13 <JaffaCake> Igloo: I don't see the problem (but perhaps I'm being stupid)
08:10:39 <JaffaCake> it shouldn't matter which thread does the waitForProcess
08:11:16 <JaffaCake> but forking a threaded program *is* living on the edge a bit
08:11:29 <Igloo> Doesn't it have to be a parent for the child to terminate completely etc?
08:12:21 <musasabi> Igloo: by posix semantics any thread is in the parent process.
08:12:39 <musasabi> Igloo: linux just does not implement posix threads by the book...
08:13:32 <tomdavie> or for that matter... do you know what's going on here... Rebuilding dependencies ... Could not find module `Language.Haskell.Hsx':
08:14:23 <basti_> i know that one
08:14:29 <basti_> haskell source extensions?
08:15:02 <Igloo> musasabi: hmm, OK
08:16:11 <tomdavie> what am I missing to make it work then?
08:16:29 <basti_> tomdavie: if i only remembered.
08:16:35 <tomdavie> found it actually
08:16:40 <basti_> oh cool
08:16:41 <basti_> what was it?
08:16:47 <tomdavie> http://www.cs.chalmers.se/~d00nibro/haskell-src-exts/#download
08:17:18 <basti_> ah.
08:17:19 <Igloo> Well, no matter what the theory, on IA64 Linux 2.4 it seems not to work
08:17:29 <basti_> i thought you had problems with your installed hsx lib
08:17:39 <basti_> no wonder that things break if you haven't got one
08:20:58 <musasabi> Igloo: linux (at least before NTPL) makes each thread essentially a process that just shares most things with its siblings.
08:21:53 * Igloo has restructured it now and it seems to work
08:22:20 <earthy> hm joy. this AG install seems to be beyond broken
08:24:14 <Speck> tomdavie, you can use ghc-pkg to remove the old Cabal
08:24:31 <tomdavie> yeh... I succeeded with that one now
08:24:38 <tomdavie> I'm trying to build hsx now
08:24:55 <Speck> the requirements are... I think Happy, Alex, and something else
08:25:12 <Speck> but I might be confused with hs-plugins :-P
08:25:13 <tomdavie> hmm, Alex might be what's causing my probs
08:26:21 <tomdavie> at the moment I'm getting Could not find module `Distribution.Simple':
08:26:51 <tomdavie> ... which is part of Cabal
08:26:52 <tomdavie> :/
08:28:43 <tomdavie> ah... that's better... Cabal was hidden
08:32:56 <tomdavie> yay... HsPlugins seems to be building this time
08:33:14 <tomdavie> it's somewhat annoying that it seems to get half way through building and then die
08:33:26 <tomdavie> rathter than just give you dependancy errors straight up
08:37:54 <basti_> tomdavie: yes.
09:17:11 * Beelsebob danced around covered in bees
09:18:05 <aheller> is that eddie izzard?
09:18:17 <Beelsebob> I think so
09:18:39 <Beelsebob> ah yes... I like my coffee like I like my women...
09:18:42 <aheller> I keep hearing my friends say it; I've probably seen the bit, but I can only really remember hearing it from them.
09:18:43 <Beelsebob> COVERED IN BEES
09:19:11 <wilx> @yow
09:19:18 <Beelsebob> it's from glorious
09:19:21 <wilx> Hmpf.
09:19:24 <lambdabot> I'm definitely not in Omaha!
09:19:31 <wilx> Somewhat lagged.
09:19:32 <aheller> ah; I only really know dress to kill.
09:20:36 <Beelsebob> ... and the 7th day god was running around fixing all the things that weren't quite finished... "oh no, magie thatcher hasn't got a heart... ahhh, a rock'll do"
09:21:08 <Beelsebob> I seem to remember god was Jams Mason, and Noah was Sean Connery
09:21:50 <aheller> Indeed.  And had long floppy ears that flapped next to the speedboat (sorry, shpeedb\:ot)
09:22:25 <Beelsebob> indeed, it provided a great photo opportunity
09:23:48 <Beelsebob> Noah, I want you to build me an ark
09:23:48 <Beelsebob> An ark? But look, I was working on this shpeedb√∂t, the dogs could all sit down the shide, it'd look really cool
09:23:51 <Beelsebob> No, no, I want an ark, with lots of space for poo
09:24:10 <aheller> :)
09:29:21 <Beelsebob> well, you can put a big engine in the ark
09:29:39 <Beelsebob> so he started to saw up pieces of wood to build an ark...
09:29:53 <Beelsebob> hooooo herrr hoooo herrrr.... and then, I was punching a baboon
09:30:56 <Beelsebob> stop hitting me!
09:31:10 <Beelsebob> I'm not hitting you, this is my mime, I'm building an ark!
09:31:57 <Beelsebob> and then he went round the world collecting two of each animal... including two baboons one a bit punch drunk
09:32:11 <Beelsebob> two dogs... long ears... along the side
09:32:31 <Beelsebob> two ducks... "We're not coming!"
09:32:51 <Beelsebob> well... there's going to be a huge flood, you'd better come!
09:32:57 <Beelsebob> so? We're ducks!
09:35:38 <jlouis> in Category theory: Let 0 be the empty category and C be any category. Then there is a unique functor F: 0 --> C. But what does F look like? You can't apply F (on objects or arrows), since there is nothing to apply it on?
09:36:18 <jlouis> Should it be treated as F takes nothing, and then constructs C?
09:36:31 <jlouis> thus, F _is_ C in some respect
09:37:30 <ski> just like a function from the empty set to some set, methinks
09:37:36 <ski> e.g.
09:37:51 <ski> foo x = case x of {}
09:38:21 <ski> F is not C
09:38:33 <ski> sortof, the type of F contains C
09:38:50 <ski> F :: Functor 0 C
09:39:02 <ski> jlouis : ok ?
09:39:07 <aheller> Again with my imperfect understanding of math, can you have pairs without first elements?
09:39:20 <SyntaxNinja> good morning
09:39:26 <ski> aheller : then i think it wouldn't be a pair, no ?
09:39:44 <aheller> ski: well, you could have {{y}}
09:39:50 <ski> aheller : any illuminating example of what you mean ?
09:40:02 <jlouis> ski: the problem as I see it, is that 0 as a category has nothing. There are no object x in 0 I can use f on
09:40:07 <jlouis> and neither an arrow
09:40:11 <ski> aheller : are you speaking of set theory encodings of pairs ?
09:40:23 <aheller> set theoretically defined functions.
09:40:26 <ski> jlouis : exactly
09:40:54 <ski> jlouis : so, it's trivial to define what the functor will do, when given an object or arrow *because* that will never happen !
09:41:06 <jlouis> ski: Just got the enlightenment
09:41:11 <jlouis> cool!
09:41:22 <jlouis> and it must be unique
09:41:44 <ski> jlouis : think of it like this, one way of defining the functor is of giving the answer for every possibly input. since there are zero inputs, we're already done ! :)
09:41:49 <ski> yes
09:41:59 <jlouis> I get it now
09:43:04 <ski> aheller : which encoding of <a,b> do you use ?  {{a}{a,b}} ?
09:43:19 <ski> er, {{a},{a,b}}
09:43:21 <aheller> ah, I tend to use {a,{b}}
09:43:44 <aheller> But I haven't thought about it in ages.
09:44:27 <aheller> I was just wondering what {} x {...} was.
09:44:30 <ski> from a CS or CT pov, it doesn't matter which, as long as we get the properties we want
09:44:40 <ski> cartesian product ?
09:44:42 <aheller> indeed.
09:45:09 <aheller> in that representing functions as lists of pairs seems not to make sense if you can't have a pair with no  first element.
09:45:29 <ski> lists of pairs ?
09:45:37 <ski> i've only heard of set of pairs
09:45:39 <aheller> err, having a function from {} -> {...}...
09:45:53 <aheller> sorry, can't type today, meant set of pairs.
09:49:41 <ski> still don't understand why you think you need "pairs with no first element"
09:50:35 <aheller> Well, the set of all pairs <x,y> with x \in X and Y \in Y ought to be empty when X = {}, unless you can have pairs with no x's.
09:50:49 <ski> yes
09:50:53 <ski> it *is* empty
09:51:16 <aheller> so f: X -> Y, being a subset of X x Y ought to be empyt.
09:51:21 <aheller> empty.
09:51:31 <ski> it is
09:51:52 <ski> ok ?
09:51:56 <aheller> I suppose.
09:52:20 <aheller> My problem is with the formalism behind having a function from the empty set to a non-empty set.
09:52:33 <ski> it needs (exactly) one pair for every element in X
09:53:03 <ski> in what way do you have a problem ?
09:53:44 <aheller> if f = {}, then how can it map onto Y != {} ?
09:54:01 <ski> *because* it is empty
09:54:16 <ski> hm
09:54:18 <ski> wait
09:54:22 <Beelsebob> ARGH!
09:54:24 <ski> of course it's not onto
09:54:32 <Beelsebob> tatd2@jet ~ $ ghc --make Main.hs -fglasgow-exts -package plugins
09:54:32 <Beelsebob> Chasing modules from: Main.hs
09:54:33 <Beelsebob> Could not find module `Eval.Haskell':
09:54:33 <ski> (unless Y = {})
09:54:47 <Beelsebob> anyone got any ideas?
09:54:52 <ski> aheller : i.e. it's not surjective
09:56:43 <aheller> right, that is, there's only one function from {} to Y, for any Y, and it's not surjective.  I completely agree.
09:57:36 <ski> (except the unique function (actually identity) from {} to {} is surjective)
09:57:40 <aheller> you had said ``just like a function from the empty set to some set, methinks'', and I was wondering how that function could be nontrivial.  I just expressed my wonder quite obtusely :)
09:58:04 <aheller> ski: of course.  I hate missing those.
09:58:15 <Beelsebob> ah... oddness... it appears to have registered plugins, hi, altdata, but not eval or printf
10:04:21 <Speck> how is a CPO different from a total order
10:04:56 <aheller> going for strike 2, isn't a total order a chain?
10:05:27 <Speck> a set with a total order is a chain
10:05:38 <aheller> ah. well, yes then ;)
10:06:53 <Speck> and a cpo is a partial order with a least element where each directed subset has a supremum
10:08:00 <aheller> what about the boolean lattice?
10:08:37 <Speck> what about boolean lattice?
10:08:56 <aheller> isn't it a cpo?
10:09:15 <aheller> That might not be what it's called... umm  _|_ < 0, _|_ 1, 0 < T, 1 < T.
10:10:06 <Speck> I don't know. I'm trying to figure out what a CPO is. I understand (I think) all the elements of its definition, just not the definition itself.
10:10:53 <Speck> total order and partial order make sense. least elements and supremums make sense. directed subset I'm not really sure, but it seems to just mean a subset with a total order.
10:13:04 <aheller> I think that's about right (mighht be that all chains are directed but not all directed sets are chains).
10:15:18 <aheller> wikipedia offers the power set of any set as an example.
10:16:05 <aheller> where < is inclusion.
10:19:46 <Beelsebob> why the fuck does hs-plugins not install eval???????
10:30:50 <Beelsebob> anyone here use hs-plugins?
10:35:50 <lightstep> google scite haskell mode
10:36:33 <lightstep> oh, i forgot the @. nevermind
10:37:18 <Lemmih> Beelsebob: Yes.
10:37:35 <Beelsebob> you successfully used the eval module?
10:40:23 <Leadhyena> it's oddly quiet here
10:40:31 <basti_> yes it is
10:40:34 <Beelsebob> indeed
10:40:40 <Leadhyena> aren't the changes for ICFP to be posted tomorrow?
10:40:47 <Beelsebob> we're pondering why hs-plugins is being dumb
10:40:50 <Leadhyena> I guess everyone's sleeping :)
10:41:11 * aheller apologizes for driving everyone off with his bad math.
10:41:17 <Leadhyena> hmmm... I'm only a blue-belt so I'm not at that level yet
10:41:44 <Beelsebob> hmm... I never knew there was a belt system for haskell...
10:41:49 <Leadhyena> had a question for a haskell guru if anyone has the time or inclination to help a semi newbie
10:41:53 <Lemmih> Beelsebob: Nope. Never used that module.
10:42:04 <Leadhyena> http://haskell.org/hawiki/HaskellIrcChannel
10:42:05 <Beelsebob> damn... because it doesn't seem to exist :/
10:42:15 <Leadhyena> lol
10:42:37 <Leadhyena> I'm trying to learn the language by writing a text adventure and having quite a time at it
10:42:53 <Leadhyena> figured out all the state monad stuff and implemented a shell
10:43:04 <Beelsebob> wow... on that scale I'm somewhere between a blue belt and a black belt depending on what you define as "proficiency"
10:43:05 <Lemmih> Beelsebob: Did you 'make register'?
10:43:17 <Leadhyena> now I'm in a mess of datatypes and I need to clean that up
10:43:22 <Beelsebob> yeh... it registered 3 packages
10:43:23 <Leadhyena> Beelsebob: yeah
10:43:32 <Beelsebob> not the 5 you should expect
10:43:39 <lightstep> Leadhyena, what are the detailes?
10:43:40 <Speck> for associative (bla), (bla) a . foldr (bla) b = foldr (bla) (b (bla) a)
10:43:50 <Beelsebob> leadhyena: I'm working on a text adventure game too
10:43:53 <Lemmih> What packages did it register?
10:43:54 <Speck> neat property, poorly notated
10:43:59 <Leadhyena> I have a module called space with 3 or more datatypes in it
10:44:19 <Leadhyena> all of these three types have attributes
10:44:21 <Beelsebob> lemmih: plugins, altdata and hi... it didn't register eval or printf
10:44:47 <Beelsebob> leadhyena: want to stare at the source for HAE?
10:44:57 <Leadhyena> that I tried to call attributes as data Place = Place {name :: String, attributes :: Map String String, etc... }
10:45:02 <Lemmih> Beelsebob: The Eval module is in 'plugins' now.
10:45:07 <Beelsebob> it actually works quite neatly for basic stuff... it needs a few tweaks to ake it shiny
10:45:17 <Leadhyena> I'll give it a whirl
10:45:22 <basti_> actually yes, i can get eval to work
10:45:30 <Leadhyena> where is HAE?
10:45:36 <Beelsebob> lemmih: ah... okay... in which case why does it bitch at me when I compile my source with -package plugins
10:46:10 <Beelsebob> tatd2@jet ~ $ ghc --make Main.hs -fglasgow-exts -package plugins
10:46:10 <Beelsebob> Chasing modules from: Main.hs
10:46:10 <Beelsebob> Could not find module `Eval.Haskell':
10:46:14 <basti_> Beelsebob: where you having problems with System.Eval.Haskell?
10:46:22 <Beelsebob> basti: yes
10:46:34 <basti_> how about trying to import "System.Eval.Haskell"?
10:46:55 <Beelsebob> ah... I'm a dumbass...
10:47:02 <Beelsebob> it's System.Eval.Haskell
10:47:07 <Beelsebob> and it works fine
10:47:28 <Lemmih> Hurrah. (:
10:47:33 <basti_> :)
10:48:16 <Leadhyena> anyway I try to use attributes in three datatypes and can't because I implicitly define three attribute functions that overlap somehow... the way around it that I found is clunky (create a class Attributable, make the accessor functions attributePlace, attributeArtifact, ... , and then link with instance functions). Is there a cleaner way to do this?
10:48:49 <lightstep> are there any viewers/editors with haskell highlighting and tabs?
10:48:50 <Leadhyena> sorry about the conventions, I'm a Java programmer by trade
10:48:52 <basti_> hmm
10:49:06 <Beelsebob> leadhyena give me two ticks and I'll chuck you our source
10:49:14 <basti_> Leadhyena: what are you trying to accomplish? similar sets of properties for different values?
10:49:15 <Leadhyena> cool
10:49:25 <mauke> vim does haskell highlighting
10:49:35 <mauke> I don't know what you mean by tabs
10:49:38 <lightstep> but no tabs
10:49:39 <basti_> emacs can do so too, but its indent is broken
10:49:49 <basti_> who needs tabs when he has buffers?
10:49:55 <Leadhyena> basti_: well, one attribute function that grabs the attributes without the class looming overhead
10:49:56 <Beelsebob> SEE does too... *g*
10:49:57 <lightstep> those little file names on the top or bottom, which you can click to switch to another open buffer
10:50:17 <basti_> Leadhyena: i'm interested, why do you fear classes looming?
10:50:29 <mauke> lightstep: there's a vim plugin for that
10:50:45 <Leadhyena> I guess that the Java programmer in me thought there was a polymorphic solution
10:50:56 * basti_ .o¬∞ ( ? )
10:50:57 <lightstep> mauke, do you know the name?
10:51:06 <Leadhyena> but maybe you're right
10:51:20 <lightstep> Leadhyena, you should use type classes for what you use virtual methods
10:51:40 <Beelsebob> www.cs.kent.ac.uk/people/rpg/tatd2/hae.zip
10:51:41 <Leadhyena> lightstep: okay... didn't know if there was a cleaner solution
10:51:47 <Beelsebob> don't chuck it around too much
10:51:56 <Beelsebob> and credit us if you use any of it
10:51:57 <Leadhyena> I won't... thanks
10:52:03 <Beelsebob> :)
10:52:20 <Leadhyena> at least I'll credit you for giving me more Haskell source to look at for inspiration
10:52:25 <basti_> Leadhyena: i'm typing
10:52:27 <basti_> wait a minute
10:52:28 <Beelsebob> sorry... I really should have cleaned it first
10:52:57 <Beelsebob> it's actually quite cool... the worlds are in fact haskell programs
10:53:01 <Beelsebob> as are the save games
10:53:12 <Beelsebob> this has the benifit that worlds can be infinite
10:53:16 <Leadhyena> Beelsebob: I would have thought that would be the right way to compose the worlds
10:53:19 <Beelsebob> because they're laze evaluated
10:53:22 <basti_> lisppaste2: @url
10:53:22 <lisppaste2> To use the lisppaste bot, visit http://paste.lisp.org/new/haskell and enter your paste.
10:53:22 <mauke> lightstep: hmm, http://www.vim.org/scripts/script.php?script_id=159 maybe
10:53:24 <Leadhyena> right
10:53:45 <lisppaste2> basti_ pasted "polymorphism?" at http://paste.lisp.org/display/9755
10:53:55 <basti_> Leadhyena: would you have a look at this?
10:54:03 <Beelsebob> I think the interesting problem is actually getting it to come up with an interesting world based on what you're doing
10:54:41 <Leadhyena> but... you save a haskell program for the save game??? how do you reconstitute?
10:55:00 <Leadhyena> basti_: right! that's how I solved it but I thought there would be a way around using the class A
10:55:11 <Leadhyena> but it makes sense that you shouldn't work around that now
10:55:20 <basti_> Leadhyena: whats the problem
10:55:20 <basti_> ?
10:55:23 <Leadhyena> because that class definition is important
10:55:50 <basti_> yes, without it you wouldn't know what values of types of that class could do or not
10:56:02 <Leadhyena> basti_: you have to understand I'm used to Java/C++ world... where int f(int x) and String f(String x) can coexist
10:56:26 <Leadhyena> well, more in C++ world than in Java world
10:56:27 <basti_> well in haskell a function like a->Int can exist
10:56:38 <lightstep> mauke, thanks, that's what i meant (i'm a vi user after all)
10:56:47 <Leadhyena> but with a class defiintion right?
10:57:05 <basti_> hmm well that type doesnt make much sense outside of a class definition.
10:57:14 <basti_> except for if you'd bind the a type variable before somehow
10:57:39 <basti_> you can also make types dependant
10:58:11 <basti_> (maybe the function "memory location of the value" could be a->Int, but besides that? mmm)
10:58:17 <Leadhyena> it just seemed a kludge to have to write an instance function for most of my types where for the most part the code was identical, and the datatype having to use a two-factor naming scheme to be unique...
10:58:37 <basti_> o.0
10:58:48 <basti_> somethings going wrong there
10:59:49 <lightstep> basti_, if a non-constant function with such a type exists, it breaks parameterizability, doesn't it?
11:00:03 <basti_> lightstep: uhm.
11:00:20 <basti_> whats parameterizability?
11:00:20 <Leadhyena> as in data Place = Place {attributesPlace : Map String String} then class Attributable a where getAttrib a :: a --> Map String then instance Attributable Place where getAttrib a = attributesPlace a
11:00:57 <basti_> Leadhyena: hmmm.
11:00:58 <lightstep> Leadhyena, sometimes the code is monomorphic enough, for example if you have `data Player = Black Attrs Height | White Attrs Age'
11:01:01 <ski> lightstep : yes, it does
11:01:27 <basti_> hmm
11:01:45 <Leadhyena> brb
11:02:47 <musasabi> Using polymorphism the haskell way is different from the C++ way so it may appear to be hard and pointless when one is trying to solve problems the C++ way.
11:02:56 <basti_> yes.
11:02:58 <basti_> thats true.
11:02:58 <basti_> ;)
11:03:21 <ski> by parametericity, a function of type forall a. a -> Int must always return the same value (if it returns at all)
11:03:32 <lightstep> parameterizability means you can annotate the definition with any type instead of `a', and it would still type-check
11:03:48 <basti_> hmmmm
11:03:54 <basti_> and what if the result depends on the type?
11:04:10 <lightstep> of course, my language center doesn't work, so my form is bad
11:04:12 <lightstep> basti_, what do you mean?
11:04:28 <ski> functions with class contexts is another matter
11:04:31 <basti_> well the function could return 1 for Int's, and 0 for everything else.
11:04:47 <ski> that's against parametricity
11:04:53 <basti_> hmm
11:04:58 <basti_> and haskell is parametric yes
11:04:58 <lightstep> you'd have to have a type class for that
11:05:05 <ski> yes
11:05:12 <lightstep> no
11:05:15 <Leadhyena> back
11:05:19 <basti_> wb lead
11:05:39 <lightstep> doesn't the official addendum to the standard break it?
11:05:52 <basti_> does it make a difference?
11:05:57 <ski> because with a class constraint, it wouldn't any longer be 'for all types a', but 'for all types a *which is in class Foo*'
11:06:01 <Leadhyena> wait... you could have a funciton that returned 1 for Int and 0 for anything else of that type class but not for everything
11:06:04 <ski> lightstep : seq ?
11:06:16 <Leadhyena> right?
11:06:17 <lightstep> unsafePerformIO
11:06:28 <basti_> Leadhyena: right, afaics
11:06:31 <ski> unsafePerformIO is not in Haskell98
11:06:38 <lightstep> Leadhyena, yeah, but you can create a default instance
11:06:38 <Leadhyena> lightstep: I heard that was a nasty monad
11:06:40 <ski> hm
11:07:10 <basti_> Leadhyena: did we mention the haskell type system is kinda backwards compared to the c type system?
11:07:15 <Leadhyena> lightstep: how would the default fit everything?
11:07:16 <ski> lightstep : but is unsafePerformIO in the addenda ? (i thought it wasn't, but i'm not totally sure)
11:07:39 <Leadhyena> basti_: I sorta figured, because C++ builds types and Haskell fences them in, right?
11:07:45 <lightstep> ski, yes, it is. having "safe" C functions amount to the same harm
11:07:57 <pejo> basti_, how is it backwards?
11:08:04 <lightstep> Leadhyena, instance Class a where method = ...
11:08:10 <basti_> pejo: its hard to explain.
11:08:14 <ski> lightstep : hm, i guess that depends on how you look at it ..
11:08:14 <basti_> Leadhyena: hmmm.
11:08:50 <lightstep> Leadhyena, that isn't actually useful in haskell98, but with overlapping instances, it becomes useful
11:08:57 <Leadhyena> basti_: what I mean is that in C++ you union primitives, functions, and other classes to make classes
11:09:01 <ski> Leadhyena : 'builds' vs 'fences' ??
11:09:04 <basti_> the C system is "everything inherits from X". In haskell, there is no X to derive everything from
11:09:09 <pejo> basti, pretend I already know HM typesystems with the ordinary extensions. Does that make it easier to explain?
11:09:26 <Leadhyena> basti_: whereas in Haskell you use class definitions to make restrictions that datatypes must follow
11:09:28 <basti_> pejo: i just know it by feel =)
11:10:01 <Leadhyena> basti_: I see that...
11:10:13 <basti_> Leadhyena: hmm. better: in haskell you can "put types into classes" afterwards, where in C you are forced to derive from some class always
11:10:19 <basti_> (some generic in default)
11:10:20 <basti_> C++
11:10:43 <Leadhyena> basti_: now that hits the AHA buzzer
11:11:06 <basti_> it seems like a restriction, but it just makes things a little more cleaned up
11:11:18 <Leadhyena> that reminds me of something in category theory
11:12:08 <basti_> you have some Type, and you can say "this type belongs to type class X, because of THIS:"
11:12:36 <Leadhyena> basti_: would it be that in C++ every class has an initial object, and in Haskell theoretically every datatype has a terminal object?
11:12:43 <basti_> :-o
11:12:54 <basti_> hum.
11:13:09 <basti_> actually i think, we should be careful
11:13:26 <basti_> in C the casts end at "Object"
11:14:03 <basti_> that means for every A you can get at least an Object
11:14:11 <basti_> (or how do C++ people call that)
11:14:17 <Leadhyena> so Object derives from all classes?
11:14:28 <basti_> no all classes derive from the "supremum" object
11:14:37 <basti_> uhm class
11:14:38 <basti_> sorry
11:14:53 <Leadhyena> right, like how you can always cast to (void *) even though they tell you not to
11:15:04 <basti_> uhm lets say you cast to (Object *)
11:15:11 <basti_> so that we dont have to talk about the primitives
11:15:12 <Leadhyena> okay
11:15:32 <mauke> what language are we talking about?
11:15:38 <basti_> mauke: generic OOP
11:15:42 <Leadhyena> like in Java everything derives from Java.lang.Object
11:15:56 <basti_> yes, and most C++ frameworks establish a similar standard
11:16:11 <Leadhyena> but in Haskell you don't have to derive from anything
11:16:21 <basti_> in haskell, you have kind of a "bottom up" method
11:16:41 <basti_> you have a lot of datatypes, and when it makes sense, you can put a few together in a class
11:16:50 <Leadhyena> so, what's the difference between a type class in Haskell and an instance declaration in Java?
11:17:00 <basti_> oh thats completely different!
11:17:06 <Leadhyena> is it?
11:17:09 <basti_> yes.
11:17:19 <basti_> We've to be a little careful now
11:17:26 <basti_> Types and Data are different concepts
11:17:44 <Leadhyena> that's something I don't yet comprehend
11:17:58 <basti_> in java, instance means "data of 'class' X", and in haskell it means "a type is member of class X"
11:18:14 <Leadhyena> oh
11:18:29 <basti_> in java an instance is data, in haskell its a declaration of type implications
11:18:29 <Leadhyena> basti_: I meant the instance keyword not an instance of a class
11:18:37 <basti_> oh
11:18:47 <basti_> does that check "member of class X" in java?
11:18:52 <Leadhyena> in Java you can say instance Runnable { public void run();}
11:18:58 <basti_> ahh.
11:19:04 <basti_> interfaces?
11:19:08 <Leadhyena> UGH yes
11:19:10 <Leadhyena> lol
11:19:15 <Leadhyena> that's what I meant
11:19:15 <basti_> you say implements
11:19:16 <basti_> btw.
11:19:16 <basti_> ;)
11:19:16 <Leadhyena> lol
11:19:40 <Leadhyena> rephrased then: so, what's the difference between a type class in Haskell and an _interface_ declaration in Java?
11:19:45 <basti_> ahhhh
11:19:47 <basti_> okay.
11:19:50 * basti_ rewinds
11:19:57 <Philippa> Leadhyena: in Haskell 98, not all that much
11:20:01 <basti_> not much
11:20:15 <Philippa> more generally though, typeclasses generalise to n-place relationships between types
11:20:30 <Leadhyena> n-place?
11:20:32 <Philippa> which Java interfaces just Don't Do
11:20:53 <Philippa> "a container c with element type e" would be an example 2-place relationship
11:21:04 <basti_> Philippa: java has mutated recently.
11:21:15 <Leadhyena> ahhh... that'd be like a java generic
11:21:26 <basti_> well haskell can do n types ;)
11:21:34 <Leadhyena> but still, seems that Haskell would be cleaner in it too
11:21:43 <basti_> oh yes.
11:21:56 <basti_> and you dont have to declare type nonsense just to keep the layout sane
11:22:05 <Leadhyena> that whole Eval <t extends Eval <extends t> > was too messy for my taste :D
11:22:15 <basti_> i often cite class ConstructorDestructorBorderlineFactory
11:22:23 <Leadhyena> ?!?
11:22:30 <basti_> j/k
11:22:33 <Philippa> basti_: point, I should've looked at how generics and interfaces interact
11:22:47 <Philippa> you still can't do compile-time logic programming with interfaces though, and I doubt they've got fundeps
11:22:57 <basti_> Philippa: did you really want to know?
11:23:07 <Philippa> I may have to code in Java again sometime
11:23:12 * basti_ shivers
11:23:19 <Philippa> in fact shit, if I don't graduate soon uni may make me redo the java courses...
11:23:21 <Leadhyena> lol I do it for the day job
11:23:33 <basti_> Leadhyena: poor, poor lad.
11:23:42 <Leadhyena> lol but it's a mixed bad
11:23:44 <Leadhyena> oops bag
11:23:56 <basti_> yes some things are fun in java
11:24:08 <basti_> anonymous inner classes eg.
11:24:10 <basti_> (lambda)
11:24:14 <Leadhyena> I do a lot of mixed scripting... my title is sysadmin but I'm basically a one-man IT shop
11:24:16 <wagle> Philippa: in grad school, they pay YOU to take classes
11:24:39 <Leadhyena> wagle: didn't know we were in Russia
11:25:11 <basti_> and then there's the possibility of uncheckedcasts.
11:25:16 <pejo> wagle, heh. A tad big generalisation there imho.
11:25:18 <Leadhyena> basti_: mostly conversions from DBase programs... now THAT should make you shiver
11:25:27 <basti_> oh and you don't need nor have pointers!!!
11:25:28 <basti_> =)
11:25:33 * Beelsebob yawns
11:25:42 <basti_> Leadhyena: well actually i dont think dbase was all that bad
11:25:59 <wagle> pejo: i'm assuming they'd give her support
11:26:03 <Leadhyena> basti_: have you ever transliterated dbase to perl?
11:26:08 <Beelsebob> leadhyena: was that source any use to youL
11:26:13 <basti_> please be silent about that.
11:26:22 <basti_> i do not want to know, honestly.
11:26:22 <basti_> ;)
11:26:25 <Leadhyena> basti_: you see my point... ;P
11:26:44 <Leadhyena> it'll be mostly over soon though
11:26:56 <basti_> -g-
11:26:59 <Leadhyena> looking to move out of the midwest
11:27:09 * basti_ is in the fareast
11:27:21 <basti_> (almost, from an USA perspective)
11:27:25 <Leadhyena> good or bad?
11:27:35 <basti_> germany... as good as it gets huh
11:27:36 <basti_> ;)
11:27:45 <Leadhyena> always wanted to go there...
11:27:51 <aheller> Leadhyena: whereabouts in the midwest?
11:27:55 <Leadhyena> took 6 years of German in school
11:27:57 <basti_> do so in summer
11:28:02 <Leadhyena> Indiana -shrug-
11:28:15 <basti_> and check if it hasnt suddenly gotten winter 3 days before you leave
11:28:19 <pejo> wagle, now that you're here - did you get an answer of how to interact with the world from Conal?
11:28:22 <Leadhyena> can barely speak a shred though...
11:28:31 <basti_> sag "√º√º√º"!
11:28:45 <basti_> "Streichholzsch√§chtelchen!" ;)
11:29:04 <Leadhyena> there are four words in there, aren't there?
11:29:11 <Leadhyena> I recognize two of them
11:29:13 <basti_> hmm3
11:29:14 <basti_> =)
11:29:17 <basti_> 2.5
11:29:20 <Leadhyena> I guess one then
11:29:20 <wagle> pejo: no, i left..  but read one of the PTM papers yesterday
11:29:29 <basti_> "streichholz" = match "sch√§chtelchen" = little box
11:29:43 <Leadhyena> oh
11:29:46 <Leadhyena> lol
11:29:58 <Leadhyena> well thanks for the help folks!
11:30:01 <basti_> -g-
11:30:05 <Leadhyena> gtg back to work
11:30:09 <basti_> hF
11:30:22 <basti_> that shocked him
11:31:27 <basti_> the one true german shibboleth
11:33:14 * Beelsebob farts loudly
11:34:11 <basti_> feeling better now?
11:34:54 <Beelsebob> yep
11:35:26 <basti_> you should make a monography: "details of my intestine's dynamics"
11:35:40 <Beelsebob> sounds good
11:35:43 <aheller> ... A Story of Hope
11:35:45 <basti_> "dimensions of my..." maybe
11:35:49 <Beelsebob> would you read it?
11:35:57 <basti_> mmm if its fun?
11:36:08 <basti_> you could add funny facts from the world of the farts.
11:36:25 <basti_> "a cow can fart 3 m¬≥ of gas in one pass"
11:38:09 * wagle cranks that through PV=nRT to calculate the final temperature
11:39:03 <basti_> now guess why they dont do that all the time.
11:39:04 <basti_> =)
11:40:12 <wagle> "I'm freezing my arse off!"
11:40:40 <basti_> and imagine the propulsion
11:41:02 <Beelsebob> I did once consider using intel CPUs as jet engines
11:41:10 <wagle> how do you think the cow jumps over the moon?
11:41:15 <basti_> the cow would just lift off if it doesnt adjust the angle carefully
11:43:26 <Philippa> you mean to say the Harrier had bovine inspiration?
11:43:38 <Beelsebob> it's true
11:43:50 <Beelsebob> how do you think the after burner was invented too?
11:43:53 <Philippa> bullshit, surely?
11:44:15 <Beelsebob> no... that's the cowes steamer
11:44:26 <basti_> how do they do the ignition?
11:44:33 <basti_> or is this hypergolic?
11:44:52 <Beelsebob> nah... there's a guy with a lighter wandering round the field
12:17:24 <Itkovian> evening
12:18:09 <basti_> hi itko!
12:21:40 <Frederick> ski_ are you there?
12:26:06 <shapr> shazam!
12:26:23 <basti_> calvin?
12:26:26 <shapr> hobbes?
12:26:39 <lament> suzie?
12:26:43 <Itkovian> mom?
12:26:45 * basti_ transmogrifies to a little soft tiger
12:27:10 * basti_ cant walk or talk when adults are watching
12:27:52 <basti_> my gf actually has a little soft tiger
12:28:20 <basti_> she desperately wanted one too when we were buying one for her second cousins little son
12:28:27 <basti_> (is that her second nephew then? ;)
12:28:42 <shapr> Is there a simple test to see if a parser is LL1?
12:29:00 <basti_> shapr: uhm
12:29:10 <basti_> LL1= regex iirc?
12:29:23 <mwc> isn't it the grammar itself that's LLN or LRN
12:29:30 <goron> shapr: I don't think your expression is valid.
12:29:43 <goron> mwc: yes
12:29:50 <basti_> oh yes.
12:29:50 <basti_> youre right.
12:30:27 <shapr> Sorry, I'm trying to fix up my ArrowsIntroduction, and someone said that Hughes' parsers are LL1 only.
12:30:46 <shapr> So I wonder, is PArrows LL1?
12:30:54 <goron> Well in that context it means, that it can only parse LL1 grammars.
12:32:52 <shapr> So my question is really whether arrows are limited to LL1 grammars. Obviously they're not, but I want to see if they lose their 'self-factoring' advantage when backtracking is added.
12:33:14 <basti_> backtracking??
12:33:18 <basti_> o.0
12:33:43 <goron> What is the 'self-factoring' advantage?
12:33:56 <shapr> LL and LALR are described here - http://en.wikipedia.org/wiki/Category:Parsing_algorithms
12:34:24 <shapr> goron: Read this - http://www.haskell.org/tmrwiki/ArrowsIntroduction
12:34:59 <goron> I know about parsing. So I will read your arrows stuff.
12:35:28 <basti_> so isn't LL(1) = one sided linear = Regex?
12:37:07 <lispy> i'm pretty sure LL(1) != regex
12:37:18 <lispy> 1 is the look ahead
12:37:26 <basti_> yes.
12:37:30 <lispy> and i think the LL is left linear
12:37:31 <goron> yes
12:37:42 <goron> "With these three parsers, you can't know that the string "four" will fail the parser nums until the last parser has failed."
12:37:47 <goron> shapr: it does?
12:38:04 <shapr> That's correct, look at the way monadic parsers work.
12:38:19 <shapr> The basic monad definition has bind and fail.
12:38:28 <goron> shapr: Well, I would say lazy evalation should solve it all.
12:38:31 <ndm> LL - left, lookahead 1 - as far as I remember
12:38:35 <ndm> not left linear
12:38:47 <Speck> oh boy, parsers!
12:38:53 <shapr> goron: Sadly, it doesn't solve it all.
12:38:57 <earthy> left-to-right left-to-right
12:39:09 <earthy> for scanning and recognising, respectively
12:39:17 <earthy> LR is left-to-right right-to-left
12:39:23 <basti_> oh yes i think earthy is right
12:39:28 <shapr> Monads have a certain minimum complexity that comes from the fact that they have no static component.
12:39:36 <lispy> ndm: that does ring a bell
12:39:52 <shapr> A parser can either pass or fail. Optional parsers are tried in order.
12:39:55 <ndm> lispy: actuallyk, i think earthy is right
12:40:16 <shapr> In parsec, word "shae" is actually four single char parsers.
12:40:25 <ndm> LL(1), the (1) in brackets is lookahead
12:40:55 * lispy checks the wiki page
12:41:21 <shapr> So, arrows have advantages in terms of space usage, shadowing, and something else I just forgot.
12:41:32 <lispy> LL -> t parses the input from Left to right, and constructs a Leftmost derivation of the sentence
12:42:07 <goron> shapr: Well, I read your claim as:"Suppose you have a ziljion monadic parsers that you run after each other, and the first character is 'a' and your parser only checks for a ziljion times the letter 'a' after each other, then it will take a lot of time to compute O(ziljion), instead of O(1)",  I can't believe monadic parsers will be that dumb.
12:42:18 <goron> shapr: Could you elaborate on that?
12:42:24 <shapr> On what?
12:42:30 <basti_> o0
12:42:49 <goron> Er, sorry the string is a ziljion times 'o'.
12:43:20 <shapr> goron: nah, it's more like, suppose you have a zillion parsers that all require input beginning with 'a', the input 'b' must be held in memory until the last of the zillion parsers has failed.
12:44:15 <shapr> Arrows can export static properties (among many other tricks), so you could immediately fail inputs that don't begin with any of the accepted beginnings.
12:44:16 <lispy> shapr: so the solution is to make order matter and use short-circuit logic?  (or redesign the grammar)
12:44:38 <goron> shapr: You mean memory for every parser? Thus you have a ziljion times 'b' in memory?
12:44:42 <shapr> Making order matter is packrat parsing, that's an article I haven't even started yet :-)
12:44:56 <shapr> short-circuit logic is right though.
12:45:17 <shapr> goron: Nah, you only have one copy of the input in memory, but what if that's a 5gb file?
12:46:02 <lispy> if you need to read a 5gb file then you need to read a 5gb file and I don't see much you can do to avoid it....
12:46:11 <goron> shapr: Well, don't you have lazy io for that?
12:47:04 <lispy> then there is the question of how do you load a 5gb file into memory on x86
12:47:42 <lispy> this is a problem because 2^32 = 4GB, which is how many addresses you have in memory
12:47:47 <shapr> Not always. Consider the case where the "one" "two" "three" parsers are being used deep into one branch of some optional parsers. That means that as much of the input as has been consumed by this branch must have been read off the disk and into memory so it can be passed to the second option in case this one fails.
12:47:57 <goron> lispy: There are other OS's.
12:47:58 <shapr> lispy: It's just an example :-P
12:48:04 <lispy> :)
12:48:11 <lispy> i know...chasing the wrong details...
12:48:57 <goron> shapr: Well, that's what I want.
12:49:10 <shapr> You want what?
12:49:37 <goron> shapr: I want to have that part of the string in memory that hasn't been parsed yet.
12:50:14 <goron> shapr: If it works differently, then Haskell is pretty f*cked up, imo.
12:50:34 <shapr> I don't think I understand.
12:50:49 <goron> shapr: Ok, an example.
12:51:09 <goron> shapr: Suppose you have the string "onetwotreenotfour"
12:51:30 <goron> And the parsers one two three four (which parse "one", "two" etc.)
12:51:45 <goron> thus four parses "four", and not "notfour".
12:52:06 <goron> And suppose you do them in sequence.
12:52:31 <goron> Then by the time "notfour" is reached, I don't need onetwotree anymore.
12:53:06 <shapr> You might, if the top level is an optional parsers "onetwotreenotfive"
12:53:41 <goron> shapr: Yes, but in that case, that's what I want.
12:53:45 <shapr> Let's say your entire parser is goron_parse string "onetwotreenotfour" <|> string "onetwotreenotfive"
12:54:10 <shapr> In your original case the GC automatically throws away the onetwotree, just as you said.
12:54:13 <goron> shapr: If you want to be more flexible and have more complexity, that will cost you more memory.
12:54:34 <shapr> In the second case, it cannot throw away the input because it might need to pass the input to the second option.
12:55:23 <shapr> Assuming the input of "onetwotreenotYOU", an arrow-style parser would be able to throw away the "onetwotreenot" input and then check whether it gets "four" or "five" or something else.
12:55:30 <goron> shapr: ok, but wouldn't you have to do that in almost any case (in general).
12:55:49 <goron> shapr: State machines, exploit grammar structure.
12:56:26 <shapr> Sure, but you can't do that parser trick from the monadic interface, because monads don't have static information.
12:56:35 <goron> shapr: Ok, I understand.
12:57:15 <goron> shapr: Although, I am not sure whether monads could never have static information.
12:57:27 <shapr> They can't, look at the type signature.
12:57:40 <shapr> You could pass around static structures, but it's not the same thing.
12:58:02 <goron> maybe you could do something with unsafe operations.
12:58:09 <shapr> Or you could use arrows :-)
12:58:14 <goron> shapr: Yes, sure.
12:58:44 <shapr> All monads are arrows, but not all arrows are monads.
13:00:52 <shapr> Anyway, back to my original question, are arrows limited to LL1?
13:00:53 <jyp> shapr: congrats for having Wouter Swierstra write the AG article :)
13:00:56 <jyp> it rocks
13:01:19 <shapr> Well, I disagree with parts of the article, but I'll argue about that later..
13:01:48 <shapr> In any case, it's nice to see an article I disagree with, hopefully I'll learn something.
13:02:00 <jyp> It can be argued, but the writing quality is great
13:02:10 <shapr> jyp: You want to write an article for next month?
13:02:43 <jyp> I'd really like to, and I'll have some free time;
13:02:58 <shapr> Ok! What subject?
13:03:00 <jyp> so it might be the right time to do something
13:04:09 <jyp> Lots of ideas spring to my mind ...
13:04:30 <jyp> any area you'll especially like ?
13:04:36 <shapr> Something Haskell related?
13:04:46 <jyp> !:)
13:04:49 <shapr> Other than that, I'm not so picky.
13:04:53 <goron> shapr: Is the AG article on the Wiki already?
13:04:57 <shapr> goron: Yeah, it's online.
13:05:04 <shapr> I fixed the permissions.
13:05:07 <goron> shapr: Well, it was more like: where?
13:05:14 <shapr> http://www.haskell.org/tmrwiki/WhyAttributeGrammarsMatter
13:05:50 <lispy> shapr: thanks!  this will be useful in my research/work this summer
13:05:55 <goron> shapr: thanks
13:06:03 <lispy> i'm needing to learn more about AG
13:06:27 <jyp> shapr: let me check the previous issues articles titles, I'll come up with something
13:07:02 <shapr> My preference for TMR articles is: 1. aimed towards motivated commercial programmers 2. Include code samples for reader experiments 3. includes ideas for extending the code 4. references to related research papers
13:08:59 <_timor> hi, does any one know of a good way to plot a function from haskell? (like anything better than outputting a table for gnuplot to do the graphing)
13:10:00 <_timor> it seems like there should exist some sort of an implementation.... I can't find anything...
13:10:06 <shapr> Many research papers are inaccesible to commercial programmers for reasons of cost of journals, articles aimed towards those already knowledgable in the subject, and lack of included working code.
13:11:38 <shapr> _timor: I don't know of anything, but maybe you could bind to an existing graph widget for wxWidgets, OpenGL, gtk2, or something like that?
13:11:51 <goron> Hmm, no new stuff.
13:12:26 <goron> But still nice of him to write an article for the 'public'.
13:12:26 <Beelsebob> hmm... I'm not sure if that's true in computer science... I haven't yet come across one I've had to pay for... unless it's detecting that my IP as at a registered uni
13:12:49 <goron> Beelsebob: acm costs money.
13:13:01 <Speck> I wish there were more materials on metamorphic programming that Philippa was talking about before.
13:13:04 <Beelsebob> hmm... in that case it's logging me in automagically
13:13:22 <shapr> Beelsebob: Many universities do have journal subscriptions by IP.
13:13:27 <bbls> hello
13:13:33 <goron> Beelsebob: yes, I can run the web via a proxy and then access asm.
13:13:35 <bbls> does anyone know a Clean channel?
13:13:37 <goron> er acm
13:13:50 <Speck> I can access acm though *.jhu; very nice :-)
13:14:21 * Beelsebob munches on smoked trout... mmmm...
13:14:33 <shapr> bbls: I don't know one, but you could start it :-)
13:14:38 <bbls> :)
13:19:45 <Beelsebob> mmm... tiramisu... this comes close to the best meal ever
13:22:36 <Speck> to sweet for me
13:22:42 <Speck> too*
13:23:08 <Beelsebob> hmm... there aren't many deserts un-sweeter
13:23:31 <Beelsebob> and the *best meal ever* bit was contributed to in large part by the smoked trout
13:23:57 <Speck> attribute grammars are like AOP?
13:23:59 <lispy> this looks like an interesting reference for PLs http://www.cs.uiowa.edu/~slonnegr/plf/Book/
13:24:42 <Speck> declarative aop, really
13:25:14 <lispy> that book mentions two-level grammars and attribute grammars as well as lambda calc
13:25:49 <shapr> hiya gord
13:26:07 <gord> Hey, Shae!  I was wondering if you were here. :)
13:26:30 <shapr> Yes, I'm here occasionally.
13:27:12 <gord> So, I'm finally taking the plunge and trying to learn Haskell.  Currently waffling on object reactive programming vs. all the GUI modules out there.
13:27:41 <Beelsebob> yay... another saved one
13:27:49 <gord> Arrows, ports, object reactive, oh my!
13:28:42 <shapr> I haven't tried any of the reactive gui libs for Haskell, have you tried some of them?
13:29:35 <gord> I'm just reading lots of docs, and trying to see what seems to be most elegant.  Now I'm looking at iHaskell and FG (Fudgets was interesting, but too Xish).
13:31:06 <shapr> In that case, have you tried Fruit?
13:32:07 <gord> Fruit scared me with its continuous signals; FG is said to be inspired by Fruit, but with discrete events.
13:34:52 <shapr> Who did FG?
13:35:19 <gord> http://kevin.atkinson.dhs.org/fg/
13:37:36 <_Codex> hmm, does fg really work? (the interface in docs looks pretty strange - even for arrow based design.)
13:37:38 <shapr> Oh, I have seen this before, but I haven't gotten around to trying it.
13:37:59 <shapr> Yeah, have you tried FG?
13:38:14 <_Codex> I havent, just looked at the docs.
13:38:40 <gord> I haven't had time yet either... I'm just cramming my home directory with things I can look at on the weekend. ;)
13:39:37 <jyp> shapr: here would be my submission to TMR: an article on practical usage of graphs in haskell.
13:39:38 <jyp> It would be based on cs.wellesley.edu/~fturbak/pubs/ppdp01.pdf
13:39:38 <jyp> The article would present an implementation/adaptation of the article ideas
13:39:38 <jyp> and how I applied its approach to "concrete" problems.
13:42:00 <shapr> jyp: Oh I like that!
13:42:53 <jyp> cool
13:44:10 <shapr> Ok, create an account on tmrwiki: http://www.haskell.org/tmrwiki/UserPreferences , then tell me the username and I'll add you the author list so you can start on your article.
13:46:14 <shapr> jyp: I'd suggest a username like JeanPhilippeBernardy or JeanBernady.
13:46:57 <Beelsebob> ahhh... *puts IRC user to email address*
13:47:25 <jyp> shapr: done, JeanPhilippeBernardy
13:48:12 <jyp> my parents gave me an annoying first name :)
13:48:22 <shapr> What's annoying about it?
13:48:30 <conal> gord: hi.  i'd like to understand your reaction to continuous signals.
13:48:47 <jyp> the length and high number of words :)
13:49:31 <jyp> often doesn't fit in forms, etc ... My name isn't even fully spelt out on my bank card, id card, etc.
13:49:46 <gord> conal: Well, I'm reading the Fruit paper now, and my fear is lessening.
13:49:50 <shapr> jyp: Ok, you're in. You may want to use the ArticleTemplate when creating the wikipage for your article, but it's not necessary.
13:50:04 <Beelsebob> heh... that's impressive
13:50:19 <conal> gord: was it really continuity that was scary?  or the arrow stuff maybe?
13:50:28 <Beelsebob> can you net get a specially extended bank card? :D
13:50:36 <gord> Yeah, I was just about to say: maybe it's just a general reaction to arrows.
13:51:28 <conal> that i can understand.  :-)
13:51:40 <gord> Long before I was interested in Haskell, I wanted to learn arrows, and I haven't yet made the conceptual link between the abstract intuitive stuff I read (at shapr's encouragement) and practical things that could be applied.
13:51:42 <jyp> Beelsebob: ::)
13:52:07 <Beelsebob> ... and then a specially extended wallet
13:54:16 <conal> gord: got it, thanks.  your comment on continuous-vs-discrete caught my eye, as i'm always curious about how many programmers find temporal discretess comfortable and continuous odd.  i suspect they've been programmed by their programming languages.
13:54:45 <conal> and not just for time but space also.
13:56:44 <gord> conal: Yup.  Especially if you do embedded systems in asm (or Forth or C), discreteness is comfort and anything resembling floating point is to be avoided at all costs.
13:57:38 <conal> gord: in that context, you want to stick with ints, for speed?
13:58:30 <gord> Yup, or because there's no floating point hardware, so floating point means more software to write. :)
13:59:15 <conal> got it. so the preference is motivated by the hardware, not by naturalness of specification.
13:59:30 <shapr> Maybe if we had analog computers?
14:00:14 <Speck> analog is the new quantum
14:00:25 <shapr> It's all about quantum -- Terry Pratchett
14:00:53 <gord> The only problem with analog is noise propagation.  Quantum computing deals with noise by reproducing the computation enough times that the statistics are accurate (the failed computations don't count for much).
14:01:28 <Speck> noise propagation is the new non-determinism
14:01:41 * gord chuckles.
14:04:58 <gord> conal: Have you used Fruit?
14:05:40 <conal> personally, i like movement in the direction of getting programming languages to support specifications friendly to the problems being solved, and away from reflecting the underlying hardware.  mainstream languages still reflect machines more than i care for.  and not even the modern machines they run on, but rather the original simple sequential machines.  modern mainstream CPUs have lots of parallelism, but they apply that parallelism to the problem of 
14:06:08 <shapr> Yeah, domain specific languages.
14:06:29 <shapr> I wonder if non-strict eval is more useful in certain domains?
14:08:16 <conal> shapr: yeah, for instance DSLs.  and yes, non-strict eval can be very useful.  certainly was for Fran.
14:08:44 <conal> And some very nice examples in "why programming matters"
14:09:58 <conal> to me, the point of that paper was that laziness is tremendously helpful for modularity, ie composability.
14:10:09 <shapr> I'd like to hear more about that.
14:11:05 <conal> ok.  a lazy programming style splits up computations into many stages, passing data structures between them.
14:11:21 <conal> the data passed can be large and even infinite.
14:12:24 <conal> but laziness ensures that values are computed when they're.  dually, gc ensures that values go out of existence when they're unnneded.
14:13:12 <conal> without laziness, the separate stages have to get munged together.  no more modularity / reuse.
14:13:41 <shapr> Or you have to use smaller datastructures.
14:13:43 <bbls> why does lazyness matters in a pure functional progamming language?
14:13:45 <shapr> But that doesn't scale well.
14:13:57 <shapr> bbls: fib = 0 : 1 : zipWith (+) fib (tail fib)
14:14:01 <bbls> it should be transparent
14:14:36 <shapr> bbls: or more simply: ones = 1 : ones
14:15:21 <lightstep> bbls, if you don't have lazyness, some  computations don't end without a reason
14:15:22 <bbls> shapr is that fib definition one that uses lists?
14:15:41 <bbls> so you send an infinite list as parameter?
14:15:41 <shapr> Yes, that's a lazy list fib.
14:16:09 <shapr> Yup, fib uses itself twice in its own definition.
14:16:29 <shapr> @plugs zipWith (+) [1,2,3] [5,6,7]
14:16:34 <lambdabot> [6,8,10]
14:16:43 <lament> plugs is just a hugs interface?
14:17:12 <shapr> Nah, it's an incremental compiler from hs-plugins.
14:17:28 <lament> can i define functions in it?
14:17:29 <shapr> A simple hugs or ghci interface leaves large security holes.
14:17:50 <lament> @plugs foo x = x + 42
14:17:51 <lambdabot> parse error on input `='
14:18:07 <shapr> bbls: But you see that "ones = 1 : ones" is also an infinite list, and it's easy way to create a stream. Same for [1..] which is all positive integers.
14:18:13 <lament> i guess that answers that question.
14:18:20 <shapr> @plugs (\x -> x + 42) 95
14:18:21 <lambdabot> 137
14:18:58 <lament> @plugs let fib = 0 : 1 : zipWith (+) fib (tail fib) in take 10 fib
14:19:00 <lambdabot> [0,1,1,2,3,5,8,13,21,34]
14:19:12 <lament> heh
14:19:20 <lament> shouldn't it really be 1 : 1 : etc
14:21:47 <Frederick> can I ask about sml here too?
14:22:13 <lightstep> lament, that depends on the definition
14:22:14 <shapr> You can, but I surely don't know anything about it.
14:22:42 <Frederick> lightstep how does it depends?
14:22:57 <Frederick> Im having a hard time to make sml accept a 9 line piece of code
14:23:03 <Frederick> patter matching problems
14:23:33 <lightstep> Frederick, i was speaking to lament. but you can paste into a paste page
14:24:18 <Frederick> sure http://rafb.net/paste/results/iLJI1F76.html
14:25:19 <Frederick> done ive fixed :)
14:25:21 <Frederick> extra ;
14:25:49 <lightstep> see how haskell can solve all your problems
14:26:05 <shapr> Just by standing near it!
14:27:01 <lightstep> also, in haskell you wouldn't need any semicolon with that coding style
14:27:10 <conal> Frederick: does "nil" work as a pattern, rather than "[]"?
14:28:06 <Frederick> yes
14:28:12 <conal> i wonder if sml would treat it as a variable pattern (matching everything), rather than the nil constructor.
14:28:16 <TheHunter> and of course you should write |imprime lista| instead of |imprime(lista)|
14:28:51 <_timor> does any one know of a good way to plot a function from haskell? (like anything better than outputting a table for gnuplot to do the graphing)
14:29:35 <shapr> _timor: There was a mailing list thread about that some months ago, some solutions may be in the archives.
14:29:46 <_timor> IC
14:29:53 <_timor> which mailing list?
14:30:11 <shapr> One of the haskell mailing lists, probably haskell-cafe, but it could have been some other list.
14:30:29 <_timor> thanks
14:42:39 <jlouis> shapr: ok, TMR article looks fine ;)
14:45:04 <gord> Thanks for the chat, all.  I'll be back when I have some GUI experience.
14:51:36 * Beelsebob sits about
14:53:39 <jlouis> conal: yes, nil works as a pattern in SML, yes
14:54:08 <conal> jlouis: as a non-variable pattern?
14:56:44 <jlouis> yup
14:56:48 <jlouis> nil and [] are the saem
14:56:50 <jlouis> same
14:56:59 <jlouis> nil is a reserved keyword if i remember correctly
14:57:28 <TheHunter> talk about namespace pollution.
14:57:33 <conal> thanks.  it's been a while since i programmed in SML.
14:58:10 <Igloo> I was horribly confused looking over the shoulder of an SML programmer 2 years ago
14:58:29 <Igloo> I never imagined that the "o" in "foo o bar" would be function composition
14:58:32 <TheHunter> is there also a reserved word cons?
15:04:30 <jyp> haskell (lack of) syntax definitely rules
15:04:36 <shapr> JaffaCake: Hey, will you be around tomorrow to talk about the GHC bug week?
15:08:15 <jyp> good night folks
15:23:54 <heatsink> I did a space profile of my program and found that a lot of space is going into MUT_ARR_PTRS_FROZEN and ARR_WORDS
15:23:56 <heatsink> @arr
15:23:57 <lambdabot> Avast!
15:24:05 <shapr> @arr
15:24:06 <lambdabot> Aye
15:24:15 <heatsink> I'm guessing that has somethign to do with arrays?
15:24:20 <heatsink> But what?
15:33:47 <MachinShin> hey all
15:33:52 <heatsink> hey some
15:45:52 <thedward> Does anyone have any opinions about "Haskell: The Craft of Functional Programming" or "Introduction to Functional Programming Systems Using Haskell" ?
15:54:42 <Beelsebob> thedward: Davie's or Thompson's
15:56:11 <thedward> Davie's
15:56:27 <thedward> hmm. it appears to predate Haskell 98
15:56:45 <Beelsebob> heh... yeh... and somehow I don't think it'll be updated
15:57:05 <Beelsebob> Tony Davie was my dad... note the *was*
15:57:51 <thedward> hah
15:57:53 <thedward> err
15:57:54 <thedward> ah
15:58:10 <Beelsebob> he was actually mid way through updating it when he died... sometime I might get round to finishing the job... when I feel I have enough knowledge to actually do him justice
16:01:16 <thedward> Do you think it might still be a good place to start? I've worked through a couple of the online tutorials, but want something a bit more in depth and structured.
16:02:35 <Beelsebob> if you want to learn pure Haskell, yes
16:02:42 <Beelsebob> it's what I learned it from
16:03:12 <Beelsebob> be aware though that I/O stuff has changed since then... but I would also avoid using I/O until as late as you can
16:03:32 <Beelsebob> and as the discussion on the haskell mailing list says, start by using the interact function
16:03:55 <thedward> yeah, I've played a little with IO, but am mainly trying to get a hang of the core language
16:04:03 <gord> I just have to say, transactional memory rules!  I've never seen such a simple approach to concurrent programming.
16:04:12 <Beelsebob> probably a pretty reasonable place to start then
16:04:29 <Beelsebob> IIRC the craft of FP starts with I/O, and isn't great for beginners
16:04:44 <Beelsebob> if I had to recommend a book, it would be Thompson's
16:05:25 <thedward> isn't the craft of fp by Thompson?
16:05:50 <Beelsebob> hang on... have I got my books muddled... *pounces on amazon*
16:06:11 <Beelsebob> yes... I have
16:06:23 <Beelsebob> the craft of FP (by Thompson) is an excellent book
16:06:36 <ski> craft of FP IO examples still work, afaik
16:06:40 <ski> yes
16:06:51 <Beelsebob> The Haskell School of expression starts with IO, and is not great for beginners
16:07:10 <Beelsebob> Introduction to FP by Davie is a good book, but dated
16:07:15 * thedward nods
16:07:27 <Beelsebob> and Introduction to FP by bird I haven't read
16:10:30 <thedward> thanks
16:28:21 <jlouis> if C is a locally small category, how does one define the Hom Functor C(-,-) : C^op x C --> Set? It is clear that the set Hom(A,B) is taken as objects, but what about arrows?
16:28:53 <jlouis> if (f,g) is an arrow of the product, how does one define the arrow between 2 sets?
16:30:51 <ski> f : A1 -> A0  g : B0 -> B1
16:30:59 <ski> hm
16:31:32 <ski> C(f,g) : Hom(A0,B0) -> Hom(A1,B1)
16:31:34 <ski> i think
16:31:53 <jlouis> it is clear it has to be contravariant in the first argument and covariant in the 2nd
16:32:16 <ski> C(f,g) = \h : Hom(A0,B0) -> g . h . f
16:32:17 <ski> ?
16:33:16 <ski> jlouis : does that look right ?
16:33:32 <jlouis> I am thinking
16:35:12 <jlouis> ski: yeah, looks right
17:28:36 <shapr> Anyone using reiser4 on debian/unstable?
17:28:47 <reffie> heh
17:29:04 <lispy> sorry
17:29:10 <lispy> i'm an ext3 guy
17:29:30 <lispy> i rely on backwards compatibility with ext2
17:32:14 <shapr> I heard good things about reiser4 from CosmicRay, so I'd like to try it. I think the patch isn't applying correctly though.
17:33:10 <heatsink> I've got reiser4
17:33:45 <shapr> How do you add both debian and reiser4 to --added-patches= ?
17:34:29 <heatsink> I built it from a debian kernel source package, it had reiser4 as one of the filesystem options
17:34:46 <shapr> Are you using kernel-package?
17:34:52 <heatsink> yes
17:36:06 <heatsink> okay, I don't know if it's reiser4 but it's reiser something.
17:36:24 <shapr> I'm having that same question right now.
17:36:57 <shapr> I patched the kernel, said yes to reiser, installed, rebooted, but I can't mount a reiser4 partition.
17:37:19 <heatsink> did you format it?
17:37:37 <shapr> Yep.
17:37:46 <heatsink> hmm
17:38:03 <shapr> I also wonder if the reiser4 format utility would be able to work without the reiser4 kernel module.
17:38:45 <heatsink> mount with flag -t reieserfs
17:38:56 <heatsink> mount with flag -t reiserfs
17:40:15 <shapr> "mount: wrong fs type, bad option, bad superblock on /dev/hdb2, \n missing codepage or other error\n In some cases useful info is found in syslog - try\n dmesg | tail  or so" and dmesg has "ReiserFS: hdb2: warning: sh-2021: reiserfs_fill_super: can not find reiserfs on hdb2"
17:40:18 <heatsink> I can't imagine why format would use kernel filesystem
17:40:46 <jlouis> nah, format is raw-disk write
17:41:29 * heatsink can't remember how it formatted its HD partitions
17:42:01 <shapr> I used mkfs.reiser4 /dev/hdb2
17:42:09 <heatsink> Yea, that sounds right
17:42:36 <heatsink> Hmm, I don't have one of those
17:42:53 <shapr> Did you install reiser4progs?
17:42:57 <heatsink> no
17:43:13 <shapr> Maybe you're using an earlier version of reiserfs?
17:43:23 <heatsink> could be
17:46:32 <heatsink> This says I have version 0.2
17:46:36 <heatsink> Or maybe 2.0 I'm not sure
17:47:23 <heatsink> I think I have reiserfs 3.6
17:50:30 <shapr> Well, I'll just go back to staring at monads and arrows then.
17:52:02 <heatsink> Is it fun?
17:52:23 <shapr> Sort of, yeah.
17:52:41 <shapr> Daan Leijen says that monads can do context-sensitive grammars and that arrows can't.
17:53:01 <shapr> And yet, everyone agrees that monads are a subset of arrows, so that doesn't seem right to me.
17:53:59 <shapr> At this point I suspect that arrows can do context-sensitive just as well as monads, but that they lose some of their advantages when it happens. But I'm not sure so I'm still puzzling it out.
17:54:31 <wagle> how does he justify the claim that arrows cant do csg's?
17:55:59 <musasabi> evening
17:56:33 <shapr> He says that monads must depend on previous input, and arrows cannot.
17:56:35 <shapr> hei musasabi
17:57:17 <autrijus> shapr: maybe by "arrows" he meant "non-monad arrows"
17:57:20 <autrijus> rehi, btw
17:57:20 <musasabi> shapr: One can do the monadic parser with arrows - but that loses (at least some of) the point of arrow parser and gives uglier syntax.
17:57:39 <shapr> wagle: section two of http://www.cs.uu.nl/~daan/download/papers/parsec-paper.pdf
17:57:49 <shapr> rehi
17:58:29 <shapr> I'm not sure. The basis of his argument is the arrow parser type, but I'm not yet convinced he's right.
17:59:45 <shapr> musasabi: Still, if monadic arrows were required for context sensitive, the advantages of arrows would be in place for all the code that didn't require context sensitive... I think.
17:59:49 <musasabi> shapr: I think he is making a point that modifiable parsers depending on previous input do not play nicely with arrows (unless one uses arrows to do the same things as monads)
18:00:24 <musasabi> shapr: you can embed such things in a parser arrow I think - but you lose some of the advantages.
18:01:26 <shapr> Thing is, do you end up with what is only a monad? Do you lose all of the advantages? Or are the advantages only lost in the part of the parser that must be context sensitive?
18:03:00 <musasabi> only in that part.
18:03:08 <musasabi> but that part will be a black box.
18:03:43 <shapr> The black box problem really sucks.
18:04:05 <shapr> gord mentioned FG today, and the black box is clearly described in the FG README.
18:04:30 <heatsink> FG?
18:04:33 <wagle> shapr: you seen the church-turing "breaking the myth" stuff:  http://www.engr.uconn.edu/~dqg/papers/
18:05:22 <wagle> seems to relate to the "previous input dependency" restriction
18:05:27 <shapr> heatsink: http://kevin.atkinson.dhs.org/fg/
18:05:40 * shapr looks
18:06:03 <wagle> the first paper is the easiest to read
18:07:06 <Spark__> that look sexy
18:07:11 <Spark__> (looks)
18:08:51 <heatsink> shapr: fg cool
18:11:38 <shapr> Yeah, but can't be efficient because of the arrow lifting black box problem.
19:57:25 <lispy> every time i try to run ghci from carbon emacs, emacs appears to lockup
20:00:35 <Spark> as a vim user i can only offer you my complete contempt :)
20:00:50 <lispy> heheh
20:00:55 <lispy> thanks! :)
20:01:38 <lispy> things are happy when done from non-carbon emacs
20:01:51 <lispy> (eg, emacs21 without graphical support
20:02:12 <lispy> tex is almost installed
20:02:14 <lispy> yay
20:03:28 * shapr reads up on the CH isomorphism
20:09:48 <gzl> shapr: from what source?
20:16:05 <dons> @hoogle map
20:16:06 <lambdabot> Prelude.map :: ((a -> b) -> [a] -> [b])
20:16:06 <lambdabot> Prelude.mapM_ :: Monad a => ((b -> (a c)) -> [b] -> (a ()))
20:16:06 <lambdabot> Prelude.mapM :: Monad a => ((b -> (a c)) -> [b] -> (a [c]))
20:16:47 <dons> @hoogle+
20:16:48 <lambdabot> List.mapAccumR :: ((a -> b -> (a, c)) -> a -> [b] -> (a, [c]))
20:16:48 <lambdabot> List.mapAccumL :: ((a -> b -> (a, c)) -> a -> [b] -> (a, [c]))
20:16:48 <lambdabot> Monad.mapAndUnzipM :: Monad a => ((b -> (a (c, d))) -> [b] -> (a ([c]
20:16:48 <lambdabot> , [d])))
20:16:56 <dons> @hoogle+
20:16:56 <lambdabot> Maybe.mapMaybe :: ((a -> (Maybe b)) -> [a] -> [b])
20:16:56 <lambdabot> Prelude.concatMap :: ((a -> [b]) -> [a] -> [b])
20:16:56 <lambdabot> Prelude.fmap :: Functor a => ((b -> c) -> (a b) -> (a c))
20:16:59 <dons> @hoogle+
20:17:01 <lambdabot> Array.ixmap :: (Ix a, Ix b) => ((a, a) -> (a -> b) -> (Array b c) ->
20:17:01 <lambdabot> (Array a c))
20:17:03 <dons> @hoogle+
20:17:08 <shapr> Lectures on the Curry-Howard Isomorphism by Morten Heine B. S¯rensen and Pawel Urzyczyn
20:17:58 <gzl> oh, a real book.
20:17:59 <shapr> I need a proof tutorial, I have no idea how to make or break the average proof.
20:18:08 <shapr> I downloaded the PDF from somewhere.
20:18:10 <gzl> average proof of CH-type stuff, or in general?
20:18:23 <shapr> I've never done a proof in my life.
20:18:36 <shapr> Any pointers to tutorials?
20:18:43 <gzl> do some group theory
20:18:53 <gzl> it's a nice way to learn proofs
20:19:23 <shapr> Is the CH iso close enough to real code that proof normalization and term reduction are used to replace each other?
20:19:53 <shapr> I bet if I read these 273 pages, I'll know.
20:20:23 <gzl> hmm
20:20:47 <gzl> I don't know the answer, but I would hope so
20:20:53 <gzl> my intuition may be bad though
20:21:06 <gzl> Pfenning has some notes on CH on his site that you may find useful
20:21:18 <shapr> It would seem that compiler optimizations would therefore be directly applicable to proof normalization.
20:21:59 <gzl> that's an interesting idea, but I've never seen a rigorous enough treatment of CH to know what to really think of htat.
20:22:23 <gzl> if you do decide to try group theory, let me know. :)
20:23:33 <gzl> (the barrier to entry is very low.)
20:23:58 <hyrax42> our libarry doesn't have that book
20:24:26 <gzl> http://www-2.cs.cmu.edu/~fp/courses/312/handouts/23-curryhoward.pdf
20:24:27 <hyrax42> is it a book or paper
20:24:31 <hyrax42> ah
20:24:39 <gzl> that's a different set of notes
20:24:44 <gzl> but also good, iirc
20:24:54 <gzl> I read them a year ago
20:26:04 <hyrax42> I'm just bookmarkign stuff for now
20:26:14 <hyrax42> I'll get to it when I get to it
20:26:18 <hyrax42> SICP atm
20:26:25 <gzl> I wasn't pressuring you to read it now
20:26:37 <hyrax42> I know
20:26:43 <hyrax42> just stating my position :)
20:26:44 <gzl> I could never get into SICP
20:26:48 <hyrax42> no?
20:26:50 <gzl> maybe I didn't give it enough of a chance
20:26:54 <gzl> at the time
20:26:57 <hyrax42> where you start then for this stuff?
20:26:59 <gzl> now I have no interest in reading it
20:26:59 <hyrax42> EoPL?
20:27:06 <gzl> what's EoPL?
20:27:11 <gzl> what do you mean by this stuff?
20:27:17 <hyrax42> PL theory type stuff
20:27:21 <gzl> TAPL
20:27:31 <hyrax42> hom hoom
20:27:36 <gzl> ??
20:28:04 <hyrax42> a nothing
20:28:11 <shapr> gzl: Tell me about group theory.
20:28:15 <hyrax42> still out at my library
20:29:12 <gzl> hyrax42: TAPL is a great book
20:29:20 <gzl> you should definitely keep it in mind if you're interested in that stuff
20:29:41 <gzl> it's very readable, covers a lot of material, and has a nice balance between theory and practice (it doesn't skimp on either)
20:29:47 <hyrax42> it's in mind, just out at the library
20:29:53 <hyrax42> and has been for ages
20:29:56 <gzl> shapr: ok
20:30:06 <hyrax42> I never got much group theory either
20:30:13 <gzl> shapr: do you want a 30 second sound byte or some motivation of where it came from?
20:30:25 <hyrax42> avoided taking the course this year
20:30:37 <gzl> take it
20:30:43 <hyrax42> idiots have it at 8.30 am
20:30:44 <hyrax42> :o
20:31:04 <gzl> ah, idiots!
20:31:05 <shapr> gzl: Er, I guess the 30 second sound byte to start out with.
20:31:26 <hyrax42> are the the most general algebraic structure or can you take out a rule
20:31:41 <gzl> shapr: the tagline I would give is that group theory is the study of symmetry; groups measure symmetry as numbers measure size
20:31:49 <gzl> shapr: symmetry takes
20:31:49 * shapr likes to beat idiots with a ruler...?
20:31:54 <shapr> Ah, tiling.
20:32:11 <gzl> many forms, though, so the main motivations of group theory came out of geometry, the study of polynomials, and number theory
20:32:14 <shapr> I am extremely fond of tiling in all its disguises.
20:32:24 <hyrax42> there's a bunch in physics these days too
20:32:29 <gzl> it's very heavily used in physics
20:32:35 <gzl> but symmetry need not be geometric symmetry
20:32:36 <heatsink> voronoi
20:34:23 * heatsink hit the 'enter' key accidentally
20:34:27 <gzl> shapr: that's the sound byte, I can motivate it more if you like
20:34:56 * shapr is reading http://en.wikipedia.org/wiki/Group_theory
20:35:20 <shapr> I think I should give up on programming and get into math.
20:35:23 <gzl> it turns out that symmetry of various kinds (again, not necessarily geometric) is extremely pervasive in mathematical systems, so groups are heavily used in many different branches of math and are also used in other sciences like chemistry, physics, and so on
20:35:55 <cm> lambdas!
20:36:13 <shapr> where?
20:36:18 <gzl> for example, the proof that there is no solution by radicals for the general quintic polynomial is a result that comes out of looking at the symmetry groups of polynomials
20:36:36 <gzl> but there is a much nicer geometric motivation I can give you for the group axioms
20:36:46 <gzl> if you want
20:37:08 <shapr> sure
20:37:25 <gzl> consider a square
20:37:45 <gzl> and consider its symmetries
20:37:56 <gzl> one pops to mind immediately: do nothing
20:38:26 <gzl> there are some other simple ones: rotate 90, 180, 270 degrees cw or ccw, flip along the diagonals, and so forth
20:38:48 <gzl> after playing around a little, a few things become clear
20:39:06 <shapr> ?
20:39:09 <heatsink> oh!
20:39:10 <gzl> (1) a symmetry is essentially a function that screws with the vertices and leaves the end result unchanged
20:39:39 <gzl> (2) you can combine symmetries to get new ones -- if you rotate by 90 degrees and then rotate by 90 degrees again, you still have the same square
20:39:39 <heatsink> neighbors remain neighbors through any symmetrical transformation
20:40:03 <gzl> (3) each symmetry has an opposite -- if rotating 90 degrees cw is a symmetry, so is rotating 90 degrees ccw
20:40:13 <gzl> with me so far?
20:40:28 <shapr> sure.
20:40:37 <gzl> ok
20:41:31 <gzl> if you generalize these properties to the abstract setting, you get the group axioms
20:41:34 <gzl> (more or less)
20:41:44 <gzl> so look at the definition of a group
20:42:24 <shapr> "A group is a set together with an associative operation which admits an identity element and such that every element has an inverse."
20:42:33 * cm mumbles something about rotation groups
20:42:35 <gzl> and that is closed under multiplication
20:42:42 <gzl> and such that the operation is associative
20:42:46 <shapr> That's a bit like set theory, and a bit like category theory.
20:43:07 <gzl> as it should be
20:43:18 <heatsink> Where does associativity come in?
20:43:30 <gzl> heatsink: it's more annoying to check it, but it also comes out of the square
20:43:46 <gzl> I just mentioned the ones you can easily visualize first
20:44:14 <gzl> an important point is also that groups aren't required to be commutative
20:44:20 <gzl> because these symmetries are not commutative
20:44:39 <gzl> if you pretend that the vertices are labelled, rotating and then flipping is not the same as flipping and then rotating (though both are symmetries)
20:45:05 <gzl> the axioms that aren't there are as important as the ones that are
20:45:34 <gzl> in any case, I think looking at the square provides a nice historical, geometric, and intuitive understanding of what's otherwise an abstract definition
20:45:54 <heatsink> cool
20:46:38 <gzl> there are a few important classes of groups you should look at, but the main point is that a *LOT* of different objects satisfy the group axioms
20:48:47 <gzl> like n x n matrices under matrix addition or multiplication, the integers, the permutations of a set under function composition, and so on
20:49:49 <shapr> Group theory is obviously important in the study of crystals.
20:49:53 * heatsink multiplies the square by four
20:49:53 <gzl> sure
20:50:33 <gzl> there's a thing called the crystallographic group, I think
20:50:41 <gzl> there are also things called wallpaper groups
20:50:56 <gzl> but those aren't the standard examples you usually deal with when you start
20:50:57 <shapr> This ties in nicely to a question I have, is there a branch of group theory dedicated to asymmetries like Penrose tiles?
20:51:30 <gzl> well, if the system has very little symmetry, there's not much you can do
20:51:55 <shapr> Penrose tiles have a lot of symmetry, but it acts strangely.
20:52:01 <gzl> (in a very specific sense -- if there is no symmetry, the group is trivial)
20:52:56 <shapr> Ok, how can I apply group theory to my long list of unsolved problems? What can I do with it in reality?
20:53:19 <gzl> you can accomplish your goal of learning how to write proofs
20:53:35 <cm> (is this list published on a Wiki?)
20:53:40 <gzl> cm: what list?
20:53:52 <cm> shapr's long list of unsolved problems
20:54:00 <gzl> oh, haha
20:54:14 <cm> (which i would find very interesting to have a look at)
20:54:42 <gzl> shapr: if they have a lot of symmetry it would be kind of neat to see a group theoretic analysis. you can do some interesting things with group theory and the Rubik's cube, to give an example
20:55:07 <gzl> I don't know if you would actually get any useful results out of doing it, of course
20:55:19 <shapr> cm: I guess I could publish the list, but some of the unsolved problems would appear very strange to people who aren't me.
20:55:40 <shapr> If I can apply it to a Rubik's Cube, I can do useful stuff with it.
20:55:59 <gzl> "apply it" is kind of a vague term, though
20:56:14 <gzl> it's not going to give you an algorithm for solving the cube
20:56:25 <gzl> it will tell you some neat stuff about the cube
20:56:28 <cm> you are already in the "special" category, which is kind of like strange but with a positive connotation ;)
20:56:32 <gzl> that you may or may not find "useful"
20:57:09 <gzl> what would be pretty neat is if you could prove that the group of Penrose tiles is isomorphic to some well-understood group
20:57:19 <shapr> cm: Yes, but realize that I still have to filter my output so that people keep me in that category ;-)
20:57:35 <cm> haha :)
20:58:33 <shapr> Actually, I think I do have some uses for group theory.
20:58:50 <gzl> well, even if you don't, you'll learn about proofs, no?
20:58:57 <gzl> but if you do, cool :)
20:59:58 * cm feels like simulating DSPs in Haskell
21:01:00 <shapr> http://haskelldsp.sourceforge.net/
21:01:22 <cm> sigh.
21:02:25 <cm> one less cool meta-problen,
21:02:29 <cm> m*
21:02:38 * cm should tackle problems instead of meta-problems
21:56:30 <dons> @hoogle a -> a
21:56:31 <lambdabot> Prelude.id :: (a -> a)
21:56:31 <lambdabot> Prelude.succ :: Enum a => (a -> a)
21:56:31 <lambdabot> Prelude.pred :: Enum a => (a -> a)
21:56:34 <dons> good hoogle :)
21:57:26 <dons> just added a simple heuristic to say that types without classes are better matches than types with classes
21:57:34 <dons> @hoogle a -> b
21:57:36 <lambdabot> Prelude.fromIntegral :: (Integral a, Num b) => (a -> b)
21:57:36 <lambdabot> Prelude.realToFrac :: (Real a, Fractional b) => (a -> b)
21:57:36 <lambdabot> Prelude.round :: (RealFrac a, Integral b) => (a -> b)
21:57:55 <autrijus> @hoogle ((a -> b) -> a) -> a
21:58:16 <dons> maybe my cutoff was too high.
21:58:27 <dons> I introduced a ranking cutoff
21:58:44 <dons> @hoogle (a -> b) -> a -> a
21:58:45 <lambdabot> Prelude.($) :: ((a -> b) -> a -> b)
21:58:45 <lambdabot> Prelude.($!) :: ((a -> b) -> a -> b)
21:59:29 <dons> paprika$ ./hoogle -v -l src/hoogle.txt "((a -> b) -> a) -> a"
21:59:29 <dons> -9:Prelude.($) :: ((a -> b) -> a -> b)
21:59:29 <dons> -9:Prelude.($!) :: ((a -> b) -> a -> b)
21:59:30 <dons> -10:Prelude.fromIntegral :: (Integral a, Num b) => (a -> b)
21:59:50 <dons> paprika$ ./hoogle -v -l src/hoogle.txt "(a -> b) -> a -> a"
21:59:50 <dons> -2:Prelude.($) :: ((a -> b) -> a -> b)
21:59:50 <dons> -2:Prelude.($!) :: ((a -> b) -> a -> b)
22:00:09 <dons> it currently cuts off at -2
22:00:18 <dons> should say so.
22:02:10 <dons> less sensitive now:
22:02:12 <dons> @hoogle ((a -> b) -> a) -> a
22:02:13 <lambdabot> Prelude.($) :: ((a -> b) -> a -> b)
22:02:13 <lambdabot> Prelude.($!) :: ((a -> b) -> a -> b)
22:02:13 <lambdabot> Prelude.fromIntegral :: (Integral a, Num b) => (a -> b)
22:02:58 <dons> @hoogle (a -> b) -> f a -> f b
22:02:59 <lambdabot> Prelude.fmap :: Functor a => ((b -> c) -> (a b) -> (a c))
22:02:59 <lambdabot> Monad.liftM :: Monad a => ((b -> c) -> (a b) -> (a c))
22:02:59 <lambdabot> Prelude.map :: ((a -> b) -> [a] -> [b])
22:03:23 <dons> ok, i think @hoogle is much more useful in #haskell now, with just a couple of little tweaks
22:06:11 <autrijus> :)
22:06:18 <autrijus> nice
22:06:21 <autrijus> @hoogle a
22:06:22 <lambdabot> Prelude.appendFile :: (FilePath -> String -> (IO ()))
22:06:22 <lambdabot> Prelude.asTypeOf :: (a -> a -> a)
22:06:22 <lambdabot> Prelude.and :: ([Bool] -> Bool)
22:06:43 <dons> well, we can talk to ndm about that. 'a' here isn't a tyvar, it's a identifier name
22:07:03 <autrijus> @hoogle a -> a -> a -> a
22:07:04 <lambdabot> Prelude.undefined :: a
22:07:04 <lambdabot> Prelude.minBound :: Bounded a => a
22:07:04 <lambdabot> Prelude.maxBound :: Bounded a => a
22:07:28 <dons> @hoogle+=
22:07:29 <lambdabot> Prelude.pi :: Floating a => a
22:07:29 <lambdabot> Monad.liftM3 :: Monad a => ((b -> c -> d -> e) -> (a b) -> (a c) -> (
22:07:29 <lambdabot> a d) -> (a e))
22:07:57 <dons> so 'a' directly unifies, then we get functions of 4 args
22:08:13 <autrijus> gotcha.
22:09:09 <dons> @hoogle a -> b -> a
22:09:09 <lambdabot> Prelude.const :: (a -> b -> a)
22:09:09 <lambdabot> Prelude.(^^) :: (Fractional a, Integral b) => (a -> b -> a)
22:09:09 <lambdabot> Prelude.(^) :: (Num a, Integral b) => (a -> b -> a)
22:09:48 <autrijus> @hoogle a -> b
22:09:50 <lambdabot> Prelude.fromIntegral :: (Integral a, Num b) => (a -> b)
22:09:50 <lambdabot> Prelude.realToFrac :: (Real a, Fractional b) => (a -> b)
22:09:50 <lambdabot> Prelude.round :: (RealFrac a, Integral b) => (a -> b)
22:10:26 <dons> ok, that's good.
22:10:35 <dons> no unsafeCoerce# ;)
22:10:40 <autrijus> :)
22:10:48 <dons> I'm not sure if it searches outside the Prelude, in fact.
22:10:50 <autrijus> @hoogle a -> b -> c
22:10:51 <lambdabot> Prelude.seq :: (a -> b -> b)
22:10:51 <lambdabot> Prelude.const :: (a -> b -> a)
22:10:51 <lambdabot> Prelude.(^^) :: (Fractional a, Integral b) => (a -> b -> a)
22:11:01 <autrijus> there's Monad.liftM3
22:11:17 <dons> oh, right.
22:11:20 <dons> but no GHC.*
22:11:25 <dons> maybe h98
22:11:34 <autrijus> yup
22:11:56 <autrijus> @hoogle m a -> (a -> m b) -> b
22:12:04 <autrijus> @hoogle m a -> (a -> m b) -> m b
22:12:05 <lambdabot> Prelude.(>>=) :: Monad a => ((a b) -> (b -> (a c)) -> (a c))
22:12:05 <lambdabot> Prelude.(=<<) :: Monad a => ((b -> (a c)) -> (a b) -> (a c))
22:12:05 <lambdabot> Prelude.concatMap :: ((a -> [b]) -> [a] -> [b])
22:12:30 <autrijus> @hoogle m a -> a
22:12:31 <lambdabot> Prelude.last :: ([a] -> a)
22:12:31 <lambdabot> Prelude.head :: ([a] -> a)
22:12:31 <lambdabot> Maybe.fromJust :: ((Maybe a) -> a)
22:12:36 <autrijus> nice!
22:12:43 <dons> that's cool.
22:12:53 <autrijus> @hoogle+=
22:12:54 <lambdabot> Ratio.denominator :: Integral a => ((Ratio a) -> a)
22:12:54 <lambdabot> Ratio.numerator :: Integral a => ((Ratio a) -> a)
22:12:54 <lambdabot> Prelude.product :: Num a => ([a] -> a)
22:13:01 <autrijus> @hoogle+=
22:13:02 <lambdabot> Prelude.sum :: Num a => ([a] -> a)
22:13:02 <lambdabot> Prelude.minimum :: Ord a => ([a] -> a)
22:13:02 <lambdabot> Prelude.maximum :: Ord a => ([a] -> a)
22:13:07 <dons> (it's just @hoogle+ actually, but the spell checking is kicking in ;)
22:13:31 <autrijus> what spellchecking?
22:13:40 <dons> @tpye 1
22:13:41 <lambdabot> forall t. (Num t) => t
22:13:52 <dons> lambdabot does spelling correction
22:13:56 <autrijus> nice
22:14:10 <autrijus> @type undefined
22:14:11 <lambdabot> forall a. a
22:15:55 <dons> @hoogle m a -> (a -> m b) -> b
22:15:56 <lambdabot> No matches, try a more general search
22:16:00 <dons> @hoogle m a -> (a -> m b) -> m b
22:16:01 <lambdabot> Prelude.(>>=) :: Monad a => ((a b) -> (b -> (a c)) -> (a c))
22:16:01 <lambdabot> Prelude.(=<<) :: Monad a => ((b -> (a c)) -> (a b) -> (a c))
22:16:01 <lambdabot> Prelude.concatMap :: ((a -> [b]) -> [a] -> [b])
22:16:30 <dons> @hoogle forall a. a -> a
22:16:31 <lambdabot> Prelude.fromIntegral :: (Integral a, Num b) => (a -> b)
22:16:31 <lambdabot> Prelude.realToFrac :: (Real a, Fractional b) => (a -> b)
22:16:31 <lambdabot> Prelude.round :: (RealFrac a, Integral b) => (a -> b)
22:52:29 <lispy> parsec question here: I want to parse 123 and 123. as integers and 123.4 as a float.  What is a good way to express this?
22:53:21 <lispy> i have integer = do {i <- many1 digit; return (read i) }
22:56:25 <dons> do it in the lexer?
22:57:38 * lispy reads the manual more
22:57:58 <ski> Parsec.Token ?
22:58:07 <ski> hm
22:58:18 <dons> sounds roughly like C syntax, here's a C float lexer:
22:58:19 <dons> floatconst  = (    mantpart +> exppart`quest` suffix
22:58:20 <dons> 	       >|< intpart +> exppart +> suffix)
22:58:41 <dons> 			    >|< intpart +> char '.'
22:59:07 <dons> mantpart  =     intpart`quest` char '.' +> fractpart >|< intpart +> char '.'
22:59:36 <dons> (this is in the CTK lexer combinators, btw. not parsec)
22:59:54 <lispy> ah, okay that would explain why it looks so foreign
23:00:02 <dons> it's just a regex language
23:00:38 <dons> but maybe it gives you some idea
23:19:20 <lightstep> where is the documentation page for Text.Html (the real one, not the haddock)?
23:19:37 <dons> the real one?
23:20:23 <lightstep> the one written by the author
23:20:51 <dons> i'm not sure this is one. what makes you think there is one?
23:20:52 <lightstep> which explains how to use the library, how to create new tags, etc
23:21:19 <lightstep> i used it a few months ago
23:21:23 <dons> ah, ok.
23:28:53 <lightstep> nevermind, the source is clear enough
23:31:59 <dons> @hooogle booogle
23:34:52 <lispy> @index concatM
23:34:54 <lambdabot> bzzt
23:38:20 <dons> @hoogle concatM
23:38:21 <lambdabot> Prelude.concatMap :: ((a -> [b]) -> [a] -> [b])
23:38:32 <dons> @hoogle sequence
23:38:33 <lambdabot> Prelude.sequence :: Monad a => ([(a b)] -> (a [b]))
23:38:33 <lambdabot> Prelude.sequence_ :: Monad a => ([(a b)] -> (a ()))
