00:24:30 <dons> @seen jyp
00:24:31 <lambdabot> jyp is in #haskell. I don't know when jyp last spoke.
00:24:40 <jyp> hoho
00:24:47 * jyp bows
00:24:50 <dons> hey jyp, yep, I was expecting you'd be a bit busy soon ;)
00:25:19 <dons> thanks for all the work you've done so far on yi, it's been much appreciated :)
00:25:38 <jyp> That's a bit unfortunate, otoh i'll get a bit more money at the end of the month
00:25:45 <jyp> Cool ;?
00:25:48 <jyp> :)
00:25:51 <dons> money is useful for things, so that is good
00:26:03 <dons> hehe
00:26:25 <jyp> Well I wish a lot of success to the Yi project
00:26:49 <jyp> so it's only logical to contribute, huh ? ;)
00:27:19 <dons> yeah, that's how the system is supposed to work :)
00:29:39 <lispy_> heh
00:29:47 <lispy_> yay, I have let and lambda now!
00:30:06 <lispy_> now to try a recursive function right?
00:30:31 * lispy_ gets the fire extinguisher ready
00:30:52 <lispy_> oh, wait
00:31:01 <lispy_> my let won't allow you to define a function
00:31:09 <lispy_> so i don't get to try recursion yet
00:31:49 <lispy_> i'll put it on my todo list to look at the reader monad
00:34:55 * lispy_ shares the latest version with the world
00:35:12 * lispy_ then feels the need to mention it in his blog
00:35:27 * lispy_ all the while giving #haskell the play by play
00:35:59 <jyp> Url ?
00:36:17 <lispy_> http://www.codersbase.com/Helisp
00:36:23 <lispy_> jyp: be gentle :)
00:36:57 <jyp> I'm demanding but respectful :)
00:37:34 <lispy_> jyp: the code is terrible because i need to get better, so if you have ideas on improving my code and style those would be the best
00:37:51 <jyp> aye
00:39:54 <lispy_> i've already discovered i need to reorganize my modules....
00:41:30 <jyp> data SExp = Cons SExp SExp
00:41:45 <MarcWeber> Which platforms are supported by haskell compilers? Can I also devellop for pocket pcs? Or is there simply a haskell to C compiler?
00:42:07 * lispy_ is on the edge of his seat
00:42:17 <jyp> I'm not lisp-educated, but shouldn't it be data SExp = Cons Atom SExp or something ?
00:42:43 <lispy_> jyp: lisp style "lists" are really binary trees
00:42:58 <jyp> ok :)
00:43:57 <jyp> What's the pocketPC arch ? ARM ?
00:44:23 <MarcWeber> jyp: Not one in particular.. I'm interested in portability more in general
00:44:41 <lispy_> MarcWeber: ghc seems to be most places that gcc is
00:45:11 <lispy_> MarcWeber: there is even a group that took the ghc runtime system and tweaked it a little to get it to run on the bare metal
00:46:22 <jyp> Ghc can normally be ported to a new arch in a few weeks
00:46:33 <jyp> from what I gather following the mailing lists
00:46:34 <MarcWeber> lispy_: So it's even possible to write programs fro micro processors and the like?
00:48:10 <jyp> You might also be interested in NHC which targets little memory usage
00:48:19 <Leimy> NHC?
00:48:21 <lispy_> MarcWeber: er?
00:48:36 <MarcWeber> jyp: But you still have to have the knowledge and the time.. I don't know haskell that well, yet (Next topic to learn are monads).. But i think it can save a lot of time of the developper compared to C/C++ but perhaps you also loose some time because of lack of some libraries
00:48:37 <lispy_> MarcWeber: most the programs i write run on mirco processors ;)
00:48:40 <jyp> http://www.haskell.org/nhc98/
00:50:18 <jyp> MarcWeber,  you can check out the haskell community report
00:50:39 <MarcWeber> I'll have look at that.
00:50:52 <jyp> that will probably give you insight in terms of what's available, and the sort of thing haskell can be used for
00:51:29 <jyp> although it's not limitative
00:52:48 <lispy_> MarcWeber: i think there is a kernel written in haskell called haus or something
00:53:10 <jyp> House ?
00:53:58 <dons>   hugs runs on palm pilots I think, also nhc has been ported to the palm a few times, so they're your best bet (though what arch is a pocket pc?)
00:55:31 <lispy_> MarcWeber: http://www.cse.ogi.edu/~hallgren/House/
00:55:43 <lispy_> jyp: yup, not sure why i remembered it as haus
00:57:13 <lispy_> geez, it's 1am
00:57:23 * lispy_ falls asleep
01:11:02 * MarcWeber begins to sing so that lispy_ falls asleep deeply and relaxed..
01:22:03 <nothingmuch> is the determination of graph planarity a hard problem?
01:25:40 <lispy> nothingmuch: seems like you could use how complete the graph is to determine it
01:26:20 <nothingmuch> uh, not determining it
01:26:28 <nothingmuch> there are easy ways to show a graph is not planar
01:26:32 <nothingmuch> but that's not what I'd like
01:26:47 <nothingmuch> organizing a graph on a plane in a planar way is what I want =)
01:27:09 <jyp> nothingmuch, this is a well studied problem
01:27:30 <nothingmuch> jyp: i thought so, but unfortunately i'm an ignoramous
01:27:46 <lispy> nothingmuch: check wikipedia
01:27:53 <nothingmuch> i did
01:27:54 <jyp> There's graphViz you can have a look at
01:28:10 <lispy> nothingmuch: oh :)
01:28:40 <nothingmuch> google for "graphviz planar" seems to yield some interesting links, thanks
01:29:55 <jyp> the research area is named "graph drawing" i think
01:29:58 <lispy> someone needs to write a short story about how in the future all of human knowledge will be stored in the great wiki
01:30:05 <nothingmuch> :Indeed, for most of
01:30:15 <nothingmuch> the layout programs, removing all crossings is NP-complete
01:30:18 <nothingmuch> https://mailman.research.att.com/pipermail/graphviz-interest/2004q2/001317.html
01:30:46 <jyp> http://www.cs.brown.edu/people/rt/gd.html
01:30:51 <jyp> (random link)
01:31:53 <jyp> we need a progam to parse, analyse, store and cross-check all wikipedia knowledge
01:32:04 <jyp> someone up to it? :)
01:32:06 <Korollary> nothingmuch: See http://www.kids.net.au/encyclopedia-wiki/pl/Planar_graph
01:32:19 <palomer> goooo haskell
01:32:20 <nothingmuch> i thin if you give wikipedia as a corpus for HAL9000 it might sounds smart
01:32:24 <palomer> lambda-mu calculus rocks!
01:33:15 <MarcWeber> compilation of nhc98 is currently broken on gentoo linux. But it already exists. That was what I was looking for.
01:33:47 <lispy_> a program to automatically add content to wikipedia would be nice, just let it run and datamine the internet adding articles to wikipedia as it goes :)
01:34:03 <MarcWeber> Is there some further support for console apps then ncurses?
01:34:37 <lispy_> MarcWeber: what do you mean?
01:34:39 <nothingmuch> lispy: copyright is probably the biggest issue =(
01:34:43 <jyp> Dunno
01:35:14 <lispy_> nothingmuch: in the future when all knowledge is housed at the GreatWiki copyright will not matter
01:35:28 <jyp> If the programs does semantic analysis and rewrites the articles I don't think there's a copyright problem
01:35:32 <jyp> :)
01:35:45 <nothingmuch> lispy_: when you find that place call me, so i can move there
01:35:58 <lispy_> nothingmuch: sure, np
01:36:16 <lispy_> i'm pretty sure the future is tomorrow...i think i heard that somewhere
01:37:15 <lispy_> i just realized that with time travel, we won't need things like backup systems on computers
01:37:35 <MarcWeber> lispy_: I was thinking about some libraries prviding edits, buttons/ windows?
01:37:36 <lispy_> in fact, having time travel would help with a lot of problems
01:37:59 <lispy_> MarcWeber: ah, ncurses should provide that
01:38:34 <lispy_> MarcWeber: if not, check out debians 'slang', i think it has that stuff
01:38:47 <MarcWeber> lispy_: Oh.. I've read some tutorials telling that ncurses is only about prividing the "paint" area for ascii characters on different terminals..
01:39:08 <nothingmuch> lispy_: i'd rather have darcs like dependency resolution for reality
01:39:21 <nothingmuch> that way I can commute and cherry pick the parts of reality i want to keep
01:39:45 <lispy_> MarcWeber: oh, actually the kernel should have something with windows and what not, check in the target 'make dialog' and look at the source for that
01:39:53 <nothingmuch> many time travel movies tend to get caught up in loops, which is kind of primitive
01:40:00 <lispy_> nothingmuch: that would be sweet
01:40:25 * lispy_ is waiting for programs like gimp to support darcs style cherry picking in the undo history
01:40:50 <dons> the `undo theory' papers from the 80s discuss models like this
01:41:16 <dons> a good reference:
01:41:17 <dons> -- >    T. Berlage, "A selective undo mechanism for graphical user interfaces
01:41:17 <dons> -- >    based on command objects", ACM Transactions on Computer-Human
01:41:17 <dons> -- >    Interaction 1(3), pp. 269-294, 1994.
01:41:36 <dons> covers all sorts of non-linear undo models
01:41:40 <lispy_> dons: is there anything  you don't know?
01:41:46 <lispy_> ;)
01:42:01 <dons> if you see the above, it's in haddock markup... as I just grabbed it from yi ;)
01:42:09 <lispy_> but....I do have to comment, that one is not from the 80's :)
01:42:25 <dons> true, but it summarises the history of this `undo theory' work
01:42:39 <lispy_> is yi planning on having that?
01:42:42 <dons> yi implements an undo model from this paper
01:42:48 <lispy_> *swoon*
01:42:52 <dons> yes, already. but not non-linear undo
01:42:53 <nothingmuch> if you google for that article name there is an article by someone named "Shmucker"
01:43:00 <dons> yi has restricted, linear undo
01:43:15 <dons> as does just about everything except darcs ;)
01:43:30 <nothingmuch> what is this 'yi' you speak of?
01:43:42 <dons> @where yi
01:43:43 <lispy_> yes, david is off in his own special part of the universe hacking away
01:43:43 <lambdabot> http://www.cse.unsw.edu.au/~dons/yi.html
01:43:52 <lispy_> i wish him luck
01:43:58 <lispy_> because i need darcs to be faster!
01:44:48 <lispy_> hmm...i why am i still here, i swear i fell asleep 45 minutes ago
01:44:56 <dons> time travel!!
01:44:56 * lispy_ waves
01:45:06 <lispy_> eggzackly
01:45:54 <jyp> dons, I've added the Emacs subdir as you suggested
01:46:14 <jyp> but the linker doesn't seem to find anything defined in there
01:46:18 <jyp> tip ?
01:46:42 <jyp> ... linking yi-static
01:48:11 <jyp> I suppose it should be added to yi.conf.in.cpp
01:48:31 <jyp> yet I don't find a reference to killring in there, so I wonder
01:54:24 <dons> hmm. the build system needs to know about new directories
01:54:40 <dons> augment the ALL_DIRS variable in Makefile, I think
01:54:51 <xerox> moOooOooOorning
01:55:03 <dons> and also, new filles should be added to the export list in the yi.conf.in.cpp file
01:55:13 <jyp> dons, ok, I'll try it
01:55:15 <dons> otherwise, that's all you need to do
01:55:47 * dons thinks using `otherwise' instead of `and then' is not good, in light of Haskell's otherwise
01:57:30 <jyp> in french we have different expressions for the 2 semantics
01:57:54 <jyp> rather, we always use "else" in the haskell semantic of otherwise
01:58:41 <jyp> Acually that's not completely true
01:58:44 <dons> right, and `otherwise' in english is the same. but in casual use you can say, as I did, `otherwise' with rather sloppy semantics
01:59:06 * dons proposes to only speak in typecheckable haskell from now on
01:59:29 * xerox stabs dons 
01:59:37 <basti_> hi
01:59:46 <xerox> 'lo basti
01:59:47 <dons>  Monad.fix $ \f -> oh no stuck!
02:00:00 * autrijus is having fun with linear implicits...
02:00:14 <autrijus> I wonder if dons will consider that as typecheckable haskell
02:00:17 <flodin> "We cannot offer you milkshake and icecream", a sign said in mcdonalds yesterday
02:00:29 <flodin> i figured if just order one of them i should be ok
02:00:32 <xerox> mapM_ (putStrLn) $ repeat "I'll not consider writing typecheckable Haskell english anymore."
02:00:51 <musasabi> Has anyone got some reference counting code for FFI?
02:01:39 <autrijus> hey musasabi. thanks for the GC code; but after some thoughts, the performance hit far outweights memory leaks
02:01:44 <jyp> flodin, that's what I understand as well
02:01:47 <autrijus> so I'm sticking with the native implementation
02:02:28 <flodin> jyp: i think it's programming damage. Noone else in the world cares much about the difference between 'and' and 'or', it appears
02:02:35 <autrijus> (it was triggering at least one extra IORef fetch/store for each finalization of natural GC'ed obj)
02:03:13 <basti_> flodin: the situation on the other side of an implication is too complicated for natural languages.
02:03:16 <jyp> flodin, I don't think so. A real english writer would have written "We cannot offer you milkshake nor icecream", I guess
02:04:15 <nothingmuch> when compiling alex I get:
02:04:15 <nothingmuch> /usr/bin/ld: Undefined symbols:
02:04:16 <nothingmuch> ___DISCARD__
02:04:49 <flodin> jyp: in this case it was originally in swedish that only has "or" and "and" equivalents, but the proper phrase would have been "we cannot offer you milkshake or icecream" where or is understood to be inclusive or
02:05:29 <ozone_> nothingmuch: use gcc 3.3
02:05:37 <ozone_> rather, don't use gcc 4
02:06:02 <flodin> gcc 4 seems to have broken half the world
02:06:09 <nothingmuch> oh, right
02:06:20 <basti_> no, c has broken half of the world
02:06:27 <basti_> gcc 4 is just the executor
02:07:18 <jyp> nah, computers have broken the whole world :/
02:07:24 <jyp> sry :)
02:07:47 <basti_> -g-
02:08:09 <autrijus> nah. the world is broken from the beginning
02:08:17 <autrijus> "if it starts broken, don't bother to fix it"
02:08:30 <jyp> damn, we're doomed
02:09:10 <basti_> aw.
02:09:22 <jyp> this sucks, let's play ball.
02:19:04 <musasabi> autrijus: true, there seems to be no really good way of doing things.
02:22:46 <astrolabe> Has the C standard changed somehow then?
02:23:20 <basti_> there is a standard? :)
02:23:24 <ibid> gcc 4 breaks C++ code, not C
02:23:30 <ibid> basti_: there are several standards :)
02:23:44 <basti_> everybody has his own huh? ;)
02:24:07 <ibid> basti_: not that bad, i think there are five or six versions of the standard
02:24:16 * basti_ nods
02:24:39 <basti_> i did C, and i know a few attempts to standardize it, but lets face it, it just isn't.
02:24:43 <astrolabe> Isn't there an ISO one? (for C++)
02:24:54 <ibid> for C++, there is only one standard
02:24:56 <basti_> i think this just covers parts of it
02:25:12 <ibid> but it's hideously complicated
02:26:02 <ibid> basti_: C is much better standardized than many other languages I know, all major compilers support at least C90 with little fault
02:26:30 <ibid> basti_: of course, C99 is less often supported (even GCC's support is incomplete)
02:26:30 <basti_> thats true, but it still has some problems. a[i++]=i++; for example
02:26:43 <ibid> basti_: that's standardized to be bottom :)
02:26:47 <basti_> .P
02:27:05 <musasabi> basti_: the compiler hopefully would spit an error out for that.
02:27:23 <ibid> but it can't for all cases of that stupidity
02:27:25 <basti_> i'd hope, yes.
02:27:36 <ibid> consider a[*p++]=*q++, where p == q
02:28:10 <ibid> (of course, a good compiler would complain if p and q aren't restrict pointers)
02:41:48 <astrolabe> Do functional languages have the same big O efficiency as procedural ones?
02:42:37 <ibid> languages are not algorithms
02:43:08 <basti_> did anyone ever think about making a haskell interface to cairo? http://cairographics.org/introduction
02:43:16 <vegai> short answer: yes. Long answer: <fill in>
02:43:20 <astrolabe> I mean, given an algorithm in one, is it possible to translate it into the other with the same efficiency?
02:43:25 <xerox> basti_: http://haskell.org/gtk2hs/ :-)
02:44:06 <basti_> xerox: i'm trying to generate graphics.
02:44:09 <vegai> probably possible, but not always easy
02:44:25 <xerox> basti_: http://cairographics.org/hscairo/
02:45:09 <basti_> :)
02:45:39 <astrolabe> vegai,ibid: thanks.
02:47:56 * Heffalump appears
02:50:15 * basti_ disappears Heffalump 
02:59:41 <musasabi> Can one do a fetch-and-decrement atomically with IORefs?
03:00:27 * musasabi remembers atomicModifyIORef
03:00:30 <basti_> musasabi: did you hear about STM?
03:01:54 <xerox> @hoogle atomicModifyIoRef
03:02:38 <autrijus> musasabi: TVar does that.
03:02:39 <musasabi> basti_: yes, but I am looking for low-level performance.
03:02:45 <autrijus> and TVar is quite fast.
03:02:58 <autrijus> the slowdown from IORef to TVar in Pugs is <3%.
03:03:01 <musasabi> iirc it is slower than plain MVars.
03:03:16 <autrijus> you mean TMVar vs MVar? maybe
03:03:22 <musasabi> + it kills anything resembling portablity.
03:03:23 <autrijus> but TVar is useful in settings other than MVar.
03:03:31 <autrijus> oh, hugs does MVar?
03:03:44 <musasabi> no, but hugs does IORef.
03:03:55 <autrijus> okay...
03:03:55 <musasabi> But atomicModifyIORef was kind of slow I think.
03:04:04 * autrijus gave up about portability a long while ago
03:04:26 * musasabi tries TVar, MVar and IORef to see which is fastest in this case.
03:08:09 <basti_> < paniq> Darcs is decentralized, based on a "theory of patches" with roots in quantum mechanics.
03:08:12 <basti_> wtf?
03:08:21 <xerox> Indeed.
03:08:53 <basti_> http://abridgegame.org/darcs/
03:09:30 <basti_> what does quantum mechanics have to do with it?
03:10:19 <xerox> http://abridgegame.org/darcs/manual/node2.html
03:11:21 <Heffalump> I think the notation has roots in QM. Nothing else.
03:11:46 <basti_> ah.
03:12:22 <Heffalump> my knowledge of QM is rather shaky, but there's certainly no obvious parallels
03:12:38 <Heffalump> but David Roundy is a physicist, so the notational thing is unsurprising
03:13:14 <ibid> aiui, qm served as an inspiration
04:20:30 * boegel curses
04:39:08 <Heffalump> 'lo
04:40:52 * jyp bounces
04:49:57 <basti_> oy!
04:54:40 <Heffalump> does GHC make any guarantees about finalizer execution after a performGC?
05:04:06 <musasabi> I don't think so.
05:05:15 <musasabi> I think the story is "Finalizers may run sometime after the object has become unreferenced".
05:34:48 <basti_> (a:b)@list <- how do you call these?
05:34:59 <basti_> non-destructive matching?
05:35:08 <xerox> Isn't it the opposite?
05:35:24 <basti_> hmm.
05:35:26 <xerox> synoniym@(decon:struction) ?  Maybe it works both ways.
05:35:27 <basti_> i dont know
05:35:41 <basti_> yes its the other way round
05:35:52 <xerox> -i, sorry
05:36:56 <Heffalump> as patterns
05:37:07 <basti_> ahh
05:37:12 <Heffalump> (cos in ML you use the keyword 'as' for that thing)
05:58:22 <CosmicRay> Igloo: I have an idea for ghc6 to make it easy to build.  I'm thinking of embedding the correct gmp version in the source tree, having it get built alongside ghc, linked in, and setting the dependencies manually.  This ought to get it correctly built on all archs.  Once it's there, it can be re-built like normal.
06:01:26 <Igloo> How will that help when ghc6 isn't installable?
06:01:53 <Igloo> Oh, I think I SWYM
06:02:40 <Igloo> No, I don't
06:02:48 <CosmicRay> ok...
06:03:08 <CosmicRay> I think we know that ghc6 is already installed on most of the buildds, right?
06:03:19 <CosmicRay> that is, the new libgmp3-dev hasn't hit?
06:03:26 <CosmicRay> or was that just for the debian developer machines?
06:03:41 <Igloo> I doubt ghc6 is on any buildd
06:04:00 <CosmicRay> just the developer machines then?
06:04:06 <Igloo> Yup
06:05:10 <CosmicRay> hmm.  I guess this would at least let us manually build there then, though in that case it probably wouldn't be necessary to put it in the source tree.
06:06:31 * Igloo thinks it would be less hassle to just unpack the ghc6 deb with an updated chroot and ignore that build-dep
06:07:37 <CosmicRay> true.
06:14:13 <basti_> @pl  CT ((aletter,mergeTrees atree btree):((\(CT a)->a) $ mergeTrees (CT ta) (CT tb)))
06:14:14 <lambdabot> (line 1, column 45):
06:14:14 <lambdabot> unexpected "a"
06:14:14 <lambdabot> expecting operator or ")"
06:14:31 <basti_> :-o
06:14:50 <basti_> ah.
06:14:57 <basti_> @pl  CT ((aletter,mergeTrees atree btree):bloop $ mergeTrees (CT ta) (CT tb)))
06:14:58 <lambdabot> (line 1, column 73):
06:14:58 <lambdabot> unexpected ")"
06:14:58 <lambdabot> expecting variable, "(", operator or end of input
06:15:09 <basti_> lets skip that part then.
07:37:41 <timbod> does anyone know what version of ghc Data.Map was introduced?
07:42:48 <jyp> 6.4
07:48:34 <timbod> Thanks jyp - I started Data.Map, and upgraded my compiler to 6.4 on debian. Trouble is, everything pre-built for debian is 6.2.x, so now I'm recompiling all sorts of stuff from source (wxHaskell at present).
09:20:51 <xerox> Do you know how much are the shipment cost for Amazon, to Europe (Italy) ?
09:21:39 <Beelsebob> nope
09:21:48 <Beelsebob> it's usually about Â£2 within the UK
09:22:07 <Beelsebob> why not run through the order up to the enter your credit card bit
11:16:29 <TheHunter> @timein Sydney
11:16:32 <lambdabot>  Monday, August 1, 2005 at 4:17:34 AM EST
11:16:56 <Korollary> @timein berlin
11:16:58 <lambdabot>  Sunday, July 31, 2005 at 8:18:00 PM CEST
11:17:06 <jyp> @timein brussels
11:17:08 <lambdabot>  Sunday, July 31, 2005 at 8:18:10 PM CEST
11:17:33 <jyp> @timein madison
11:17:35 <lambdabot>  Sunday, July 31, 2005 at 1:18:37 PM CDT
11:17:41 <resiak> @timein hell
11:17:43 <lambdabot>  Sunday, July 31, 2005 at 10:18:45 PM
11:17:47 <Korollary> lol
11:17:47 <resiak> :/
11:17:51 <basti_> o0
11:18:00 <TheHunter> @timein heaven
11:18:01 <lambdabot>  Sorry, don't know this city
11:18:05 <Korollary> is it "hell"as ?
11:18:06 <resiak> Oh, Hell's in Norway.
11:18:06 <jyp> @whereis hell
11:18:07 <lambdabot> Maybe you meant: where where+
11:18:17 <resiak> (I _think_.)
11:18:39 <Korollary> it's +1 athens
11:48:03 <lispy> dons: yi needs tab support!  I keep trying to edit files with tabs :(
11:50:13 <basti_> lispy: yi needs your support!
12:01:16 <lispy> basti_: dons told me he wanted to add tab support
12:01:26 <lispy> said it was complimacated
12:01:43 <lispy> involves a lot of layers in the editor and such
12:01:58 <basti_> hmm
12:02:00 <basti_> i see
12:02:48 <lispy> basti_: and i'm making progress on my elisp interpreter, and it will hopefully be a plugin for yi someday when it grows up :)
12:03:03 <basti_> .P
12:03:27 <lispy> today is hacking on darcs day, tho
12:03:59 <lispy> i want to add a hook for get scripts
12:06:34 <wilx> Hmpf.
12:06:51 <wilx> Sombody broke Darcs build for me :)
12:07:29 <lispy> wilx: with the latest unstable?
12:07:36 <wilx> Yup.
12:07:42 <lispy> which platform?
12:07:48 <wilx> Windows/MinGW
12:07:51 <lispy> oh
12:08:21 <wilx> Somebody ist trying to use AS_HELP_STRING m4 macro.
12:09:01 <wilx> IIRC it appeared somewhere after version 2.56 that MingGW uses.
12:09:24 <wilx> And the AC_PREREQ([2.54]) is still 2.54.
12:10:55 <lispy> does it unbreak if you change it to 2.56?
12:11:22 <pejo> lispy, AC_PREREQ only makes earlier versions of autoconf to bail out if they are too old.
12:11:25 <wilx> I don't think it will but I'll try.
12:11:29 <wilx> Yup.
12:12:05 <lispy> pejo: ah, i had thought it was a compatibility mode
12:12:37 <wilx> Wim Lewis <wiml@hhhh.org>**20050729185632 this patch is to blame :)
12:12:56 <lispy> hhhh.org?
12:13:01 <lispy> is that real?
12:13:10 <wilx> Huh, dunno, this is what I get from darcs annotate.
12:14:04 <wilx> Somebody should either find out what version has AS_HELP_STRING and bump up the AC_PREREQ version or revert the patch.
12:14:29 <lispy> i think bumping the version is thebest
12:15:01 <lispy> prehaps sending an email to the list saying what you've learned would be a good starting point.
12:15:18 <wilx> But that would mean signing up to the ml :/
12:17:47 <lispy> ah
12:20:19 <lispy> wilx: http://www.abridgegame.org/pipermail/darcs-devel/2005-July/002963.html
12:23:06 <Korollary> is it too late for this time of the year to apply to grad school ?
12:24:11 <wilx> Depends on country and school, I guess.
12:25:08 <Korollary> north america
12:25:31 <Korollary> I know that the typical deadline for fall 2005 is around february 2005
12:29:50 <lispy> Korollary: i applied in early december and started in january ;)
12:30:09 <lispy> Korollary: but that was a weird situtation
12:32:56 <wilx> Cool, autoconf 2.59 for Mingw seems to work.
12:33:21 <Korollary> lispy: oregon state says 30 days before the first day of classes heh
12:33:33 <Korollary> lispy: is that where you said they were using a lot of haskell ?
12:35:05 <lispy> Korollary: well, there are two professors that take turns teaching the PL classes and both of them teach haskell.
12:35:25 <Korollary> bah. deadline is jan 15 for eecs
12:35:31 <lispy> Korollary: i work with one of them, and sometimes with the other, so to me yeah there is a lot of haskell going on :)
12:36:00 <lispy> but it's mostly using haskell, not adding features or anything
12:36:20 <lispy> i had a class spring term where we used haskell to make DSLs
12:36:58 <lispy> the fact that haskell uses lists for strings simplifies soo many things
12:37:06 <lispy> it's genius I tell you!
12:38:46 <lispy> Korollary: but in the end, i think you could go to any school and use or not use haskell
12:49:04 <wilx> Let's see if the email I sent reaches the darcs ml even though I am not subscribed..
13:02:32 <lispy> wilx: it will be "frozen" and it's up to someone like david to approve it.  At least, that's how i think it works
13:03:25 <lispy> wilx: one thing you can do is to subscribe yourself and set it to never send you mail. That way you'll have write permissions but you won't have to deal wit hthe ml traffic
13:06:48 <wilx> Hmm.
13:16:29 <boegel> @seen Itkovian
13:16:49 <boegel> @yow
13:16:50 <lambdabot> I saw Itkovian leaving #haskell 4 days, 6 hours, 53 minutes and 22
13:16:50 <lambdabot> seconds ago.
13:16:54 <boegel> hmm
13:17:02 <boegel> I wonder if he'll be at work tomorrow
13:17:19 <lambdabot> I'm wet!  I'm wild!
13:30:21 <resiak> ...
13:31:30 <Cale> @yow
13:31:42 <lambdabot> I'm RELIGIOUS!!  I love a man with a HAIRPIECE!!  Equip me with
13:31:42 <lambdabot> MISSILES!!
13:39:58 * boegel goes to bed to start his first day as a Phd-student tomorrow early on
13:40:52 <reffie> so early
13:40:52 <Lemmih> Neat.
13:41:24 <lispy> boegel: congrats
13:42:38 <boegel> reffie: early ? I need to prepare myself, because I need to put together a subject proposal due September :)
13:42:50 <reffie> but it's only august!
13:42:55 <boegel> I hope the choice I made was the right one
13:43:10 <boegel> reffie: yeah, but I'm not very familiar with the subject I'll be working on
13:43:17 <Heffalump> what's that?
13:43:28 <boegel> hell, my subject isn't even perfectly known
13:43:52 <boegel> Heffalump: something with performance prediction
13:44:13 <boegel> probably involving statical analysis ('cause that's a bit more theoretic, the way I like it)
13:44:37 <boegel> I'm not sure which direction I'll be taking though, I'll have to figure that out in the next few days/week
13:45:41 <reffie> what is the subject?
13:47:17 <boegel> reffie: as I just said, that has to be decided in the next few weeks
13:47:23 <reffie> ah
13:47:28 <boegel> that's why I'm so early )
13:47:33 <reffie> but you said you weren't familiar with the subject
13:47:41 <reffie> which implies that you already had a subject
13:47:45 <boegel> being performance prediction
13:47:52 <reffie> oh
13:47:56 <reffie> sorry you said it before
13:47:57 <reffie> my bad
13:48:25 <boegel> also, it involves working inside the JVM and such, and I haven't done stuff like that yet
13:48:49 <boegel> but I guess the first thing tomorrow will be a tour or something like that :) installing myself on my desk, and so on
13:51:37 <Heffalump> oh, will you have to use JVMPI/JVMTI?
13:54:32 <boegel> Heffalump: don't know really
13:54:42 <boegel> why ? any experience with those?
13:54:55 <boegel> http://www.eweek.com/article2/0,1895,1841067,00.asp -> gotta love it
13:55:12 <Heffalump> a bit, and not much of it pleasant :-)
13:56:33 <boegel> oh
13:56:47 <boegel> well, I'll see what will happen
13:57:03 <boegel> it's kind of a leap for me, but so was doing my thesis in Haskell :)
13:59:17 <boegel> I should be in bed now, there's a Harry Potter book waiting there for me for another half hour or so :)
13:59:20 <boegel> bye everyone !
13:59:22 <Beelsebob> haha
13:59:31 <Beelsebob> have you worked out who it is yet?
13:59:44 <boegel> Beelsebob: it's not the new one
13:59:50 <Beelsebob> ah, okay
13:59:55 <Beelsebob> which one you reading?
13:59:57 <boegel> I'm readign 'the order of the phoenix'
14:00:04 <Beelsebob> ah, cool
14:00:11 <boegel> I haven't read the other ones yet though (but I've seen the movies :p)
14:00:11 <Beelsebob> t'is a good one that
14:00:24 <Beelsebob> (I assume other than the 4th)
14:00:28 <boegel> yeah, I was hooked after reading the first page :)
14:00:50 <boegel> really off now :) ttyl
14:00:59 <Beelsebob> have fin
14:01:49 <Heffalump> Beelsebob: did you work out who it was before the end, then?
14:02:02 <Beelsebob> about 100 pages to go
14:02:19 <Beelsebob> am I going to spoil it for anyone if I talk?
14:02:28 <Heffalump> you might, it's a big channel
14:02:36 <Heffalump> anyone reading scrollback for example
14:03:23 <Beelsebob> indeed
14:14:00 <interferon> spoil what?
14:14:15 <Heffalump> the ending of the 6th Harry Potter book
14:14:43 <interferon> ick
14:14:46 <interferon> spoil away
14:15:00 <Heffalump> we've had our discussion by msgs :-)
14:15:07 <reffie> six pack girls
14:17:18 <Beelsebob> ?
14:18:47 <Heffalump> is there a convention on package name capitalisation? (-package foo vs -package Foo)
14:20:31 <TheHunter> i've only seen -package foo.
14:21:01 <Heffalump> -package Cabal
14:21:03 <Heffalump> (for example)
14:21:16 <TheHunter> oh, really?
14:21:36 <Igloo> It should ignore case, shouldn't it?
14:22:04 <Heffalump> maybe, but I still have to pick one when naming things
14:22:28 <Igloo> Well if it ignores it then it doesn't really matter
14:23:07 <Heffalump> true.
14:23:14 <Heffalump> ok, next question, what does
14:23:16 <Heffalump> final link ... ghc-6.4: HSperl.o: unhandled ELF relocation(Rel) type 10
14:23:41 <Heffalump> I have a suspicion that ghci can't handle .o files with R_386_GOTPC relocations, but I'm not quite sure why.
14:24:58 <Igloo> Linker.c is written lazily, I believe
14:25:41 <Heffalump> ah, yes :-)
14:25:56 <Heffalump> should I just email glasgow-haskell-bugs then?
14:26:17 <Igloo> Yeah
14:27:51 <Heffalump> bit of a pain though, as it means antibuddha won't work in ghci for any current GHC
16:12:41 <Lemmih> @version
16:12:42 <lambdabot> lambdabot 3p55, GHC 6.4.1 (OpenBSD i386)
16:12:42 <lambdabot> darcs get http://www.cse.unsw.edu.au/~dons/lambdabot
16:12:53 <Lemmih> @what's-new
16:12:54 <lambdabot> Unknown command, try @listcommands.
16:13:20 <oxyl> @listcommands
16:13:21 <lambdabot> all-dicts arr babel botsnack code define definitions devils dice
16:13:21 <lambdabot> dict dict-help docs dummy easton echo elements elite eurohaskell
16:13:21 <lambdabot> eval fact fact-cons fact-delete fact-set fact-snoc fact-update
16:13:21 <lambdabot> foldoc fortune gazetteer get-definition ghc google help hitchcock
16:13:21 <lambdabot> hoogle hoogle+ index jargon karma karma+ karma- kind lambda learn
16:13:23 <lambdabot> libsrc listchans listcommands listmodules lojban moo more paste pl
16:13:25 <lambdabot> pl-resume plugs pointless prelude quote remember repo-add repo-del
16:13:27 <lambdabot> [4 @more lines]
16:13:34 <TheHunter> good morning, dons.
16:13:51 <Lemmih> @more
16:13:52 <lambdabot> repos resume seen source spell state timein todo todo-add topic-cons
16:13:52 <lambdabot> topic-init topic-null topic-snoc topic-tail topic-tell type uptime
16:13:52 <lambdabot> vera version vixen web1913 where where+ wiki wikipedia wn world02
16:13:52 <lambdabot> yow
16:14:07 <TheHunter> just some @pl-related changes
16:14:36 <TheHunter> @pl \mx my mz -> return mx >>= \x -> return my >>= \y -> return mz >>= \z -> return (f x y z)
16:14:37 <lambdabot> ((return .) .) . f
16:15:15 <oxyl> ah ok, it stands for pointLess
16:15:31 <Lemmih> @pl \x -> x * 2
16:15:32 <lambdabot> (2 *)
16:15:43 <TheHunter> @plugs join (,) 0
16:15:51 <lambdabot> <Plugins.Eval>:1:
16:15:51 <lambdabot>   No instance for (Monad ((->) b))
16:15:51 <lambdabot>   arising from use of `join'
16:16:28 <dons> hey
16:16:53 <TheHunter> there seems to be a race condition with hs-plugins and ghc-cvs:
16:17:01 <dons> oh!
16:17:03 <TheHunter> % ./plugs
16:17:03 <TheHunter> 1 + 2
16:17:03 <TheHunter> Compiling object ... ["ghc","-Onot","-o","/tmp/Mdnig26438.o","-odir","/tmp/","-hidir","/tmp/","-i/tmp/","-c","/tmp/Mdnig26438.hs"]done
16:17:03 <TheHunter> Compiled, but didn't create object file `/tmp/Mdnig26438.o'!
16:17:09 <dons> yes, I've seen this
16:17:20 <dons> Ii think it is a System.Process problem
16:17:27 <TheHunter> if I Ctrl+Z and then compile it by hand, it works.
16:17:45 <dons> yep, seen that too. also 6.2.2 doesn't exhibit it. neither does plugs (only runplugs)
16:18:16 <dons> oh, is that plugs above??
16:18:27 <TheHunter> that is the RunPlugs from lambdabot.
16:18:29 <dons> no, runplugs, but you've called it plugs
16:18:31 <dons> right.
16:19:05 <dons> are you using ghc-cvs since the recent System.Process fd changes?
16:19:24 <TheHunter> i'm using 6.5.20050728
16:19:25 <dons> (if you add -v to the ghc command line, you'll see an error about file descriptors and gcc)
16:19:37 <dons> hmm. ok. so it wasn't fixed by the recent changes
16:19:52 <dons> (the ghc command line used by RunPlugs.hs)
16:20:29 <Lemmih> lisppaste2: url
16:20:29 <lisppaste2> To use the lisppaste bot, visit http://paste.lisp.org/new/haskell and enter your paste.
16:20:37 <TheHunter> how do I change that? in the hs-plugins source?
16:20:40 <dons> Failed: gcc -I/tmp -c /tmp/ghc10349.s -o /tmp/MLvIUi1222.ogcc: setNonBlockingFD: invalid argument (Bad file descriptor)
16:21:17 <TheHunter> so this is a ghc bug?
16:21:19 <dons> add ["-v"] to the unsafeEval_ arguments: s <- unsafeEval_ ("(take 2048 (show ("++s++")))") context ["-v"] [] []
16:21:19 <Lemmih> @where paste
16:21:20 <lambdabot> I know nothing about paste.
16:21:35 <dons> not sure what's going on yet. but it's been bugging me for a couple of months
16:21:37 <Lemmih> @where paste
16:21:38 <lambdabot> http://paste.lisp.org/new/haskell
16:21:41 <fnord123> Hi all. I'm trying to build Yi in a non-static way. I get a complaint "unknown package: plugins" with ghc-6.4, OSX 10.4
16:21:50 <dons> you need hs-plugins
16:21:59 <dons> @where hs-plugins
16:22:00 <lambdabot> http://www.cse.unsw.edu.au/~dons/hs-plugins/
16:22:05 <TheHunter> @help where
16:22:06 <lambdabot>  @where <key>, return element associated with key
16:22:16 <fnord123> http://www.cse.unsw.edu.au/~dons/hs-plugins/
16:22:25 <fnord123> oh you beat my googling :)
16:23:07 <dons> setNonBlockFD is only called in 1 or 2 places in the std libs
16:23:20 <oxyl> @google hs-plugin
16:23:22 <lambdabot> http://www.mobilejoe.de/joeforums/showthread.php?t=13208
16:23:35 <dons> @google hs-plugins
16:23:37 <lambdabot> http://www.cse.unsw.edu.au/~dons/hs-plugins/
16:23:41 <oxyl> @help google
16:23:42 <lambdabot>  @google <expr>, search google and show url of first hit
16:24:36 <oxyl> @hoogle hs-plugins
16:24:37 <TheHunter> @where
16:24:38 <lambdabot> Prelude.undefined :: a
16:24:38 <lambdabot> Prelude.minBound :: Bounded a => a
16:24:38 <lambdabot> Prelude.maxBound :: Bounded a => a
16:24:38 <lambdabot> I can not handle empty facts.
16:25:57 <Lemmih> wtf?
16:26:11 <TheHunter> dons, yep, that's exactly the message I get.
16:26:58 <dons> maybe there's a bug in the exec implementation in hs-plugins
16:27:07 <dons> (though its the same as popen in lambdabot)
16:27:48 <dons> System.Plugins.Utils:exec
16:28:33 <dons> though its only 5 lines I took from SimonM
16:28:53 <TheHunter> so, this bug also is in 6.4?
16:29:03 <dons> I get it with 6.4, yes.
16:29:14 <dons> the only way to get a working runplugs is with 6.2.2
16:29:51 <TheHunter> so, that's why Data.Fintemap and friends are in there, I see.
16:30:23 <dons> oh, RunPlugs.hs hasn't been updated recently
16:30:40 <TheHunter> haskell.org is down?
16:30:43 <dons> the most current version is in hs-plugins/examples/plugs/runplugs
16:30:57 <TheHunter> ah, ok.
16:31:10 <dons> I should resync them
16:32:52 <dons> we could work around it by using the ./plugs program (an interactive version of runplugs) in hs-plugins/example/plugs/plugs
16:32:55 <dons> plugs> 1 + 2
16:32:56 <dons> 3
16:32:58 <dons> it works:
16:54:32 * heatsink tries to imagine Phillipa teaching CS in a classroom. Oh my geez. :]
16:56:07 <Beelsebob> haha
16:59:13 <Enveigler_> In formal type theory, is there any room for polymorphic values?
16:59:34 <dons> ?
17:00:01 <Beelsebob> most type rule systems can deal with them naturally can't they?
17:00:37 <Enveigler_> Eg. In a graphics system, points might use reals for the coords, but when plotting to a device, they need to be converted to discrete values.
17:01:05 <Enveigler_> That#s easy enough, but I'm wondering if there is anything formal to decribe that
17:01:56 <dons> polymorphism has been understood for about 30 years, but I think maybe your problem is different
17:02:11 <dons> its more like code generation
17:02:55 <dons> points are abstract values that need to be compiled down to a machine level encoding
17:03:56 <Pseudonym> I don't understand why this is actually a problem.
17:04:14 <Pseudonym> I do this in both C++ and Haskell all the time, using something like typeclasses.
17:04:57 <Enveigler_> It's not a problem as such. I just got to thinking about whether there was any formalisism behind it.
17:05:27 <dons> certainly, having functions that operate over a range of types, if that is what you require, is well formalised
17:05:51 <Pseudonym> http://www.alvyray.com/Memos/MemosMicrosoft.htm#SpriteTheory
17:05:55 <Pseudonym> Useful little tech memo there.
17:06:14 <Pseudonym> It deals with floating-point and integer valued "boxes".
17:06:27 <Enveigler_> I'm (almost) completely ignorant of type formality, but I've encountered several places where I'd like values to be usable as different "types" at different times.
17:06:34 <Pseudonym> If you take a look at the operations needed, it's actually fairly obvious how to encode this in Haskell.
17:06:44 <dons> Pseudonyms ref sounds useful
17:07:10 <Pseudonym> Oh, it's a fabulous tech memo.
17:07:21 <Pseudonym> Just about anything written by Alvy Ray Smith is worth reading if you're into graphics.
17:07:31 <Pseudonym> Just after you've read everything by Jim Blinn, that is.
17:08:42 <dons> Enveigler_, for the origin of polymorphic type systems, see Hindley and Milner's papers
17:09:02 <Pseudonym> Milner's is probably more applicable if you're a programmer.
17:09:34 <dons> yep.
17:10:01 <dons> also, Mark Jone's 1995 paper is good for Haskell people
17:10:28 <Enveigler_> Aren't they more to do with function's that operate on different types at different time rather than values that are treated as different types?
17:10:30 <dons> Functional Programming with Overloading and Higher-Order Polymorphism
17:10:42 <Enveigler_> s/'//
17:10:53 <dons> a function is a value
17:11:05 <dons> @eval undefined :: ()
17:11:08 <Pseudonym> Hang in, I might have fixated on your coordinate example and missed out on your main point.
17:11:10 <lambdabot> Fail: Prelude.undefined
17:11:16 <dons> @eval undefined :: Int
17:11:17 <lambdabot> Fail: Prelude.undefined
17:11:21 <Pseudonym> Do you have another example?
17:12:13 <Enveigler_> Another (possibly flawed) example. A 32-bit value that can be signed or unsigned. (or byteswapped).
17:12:27 <Pseudonym> Ah.
17:12:29 <Pseudonym> I see.
17:13:00 <dons> hmm. so maybe you want ad hoc polymorphism
17:13:11 <Pseudonym> I think what you want is nontrivial type synonyms.
17:13:41 <Pseudonym> http://haskell.org/hawiki/NonTrivialTypeSynonyms
17:13:56 <TheHunter> dons, exec appears fine, except when it's called from hs-plugins.
17:14:04 <Pseudonym> http://haskell.org/hawiki/WrapperTypes
17:14:05 <Pseudonym> That too.,
17:14:31 <dons> TheHunter, what do you mean `except'?
17:14:43 <Pseudonym> The example of coordinates probably isn't a good one, because you want two types (floats and integers) used in the same generic functions (coordinate manipulation).
17:14:48 <dons> except when called in the RunPlugs program? orr in general when called in hs-plugins?
17:14:52 <TheHunter> can somebody host www.haskell.org?
17:14:57 <Pseudonym> Which is where typeclasses shine.
17:15:06 <TheHunter> except when called from RunPlugs - that's all I have checked.
17:15:35 <dons> ok. yes, this was my observation too
17:15:50 <fnord123> do I need HSX to compile h-s plugins?
17:15:56 <dons> yes
17:16:02 <dons> grep for `darcs' in README
17:17:02 <TheHunter> cvs.haskell.org, too.
17:17:07 <fnord123> yes to who
17:17:17 <dons> fnord, yes to you
17:17:20 <fnord123> k
17:17:33 <fnord123> any more dependencies on yi I should know about? :)
17:17:46 <Pseudonym> TheHunter: Is the host going away?
17:17:48 <dons> just hs-plugins, which depends on hsx
17:17:57 <dons> seems up to me, TheHunter?
17:18:02 <dons> manzano$ cvs diff -u
17:18:02 <dons> cvs server: Diffing .
17:18:03 <dons> ...
17:18:18 <TheHunter> yeah, it's up. But I can't resolve it here.
17:18:36 <TheHunter> i've solved it by sshing to my old uni...
17:18:48 <dons> and I can ssh into haskell.org
17:19:38 <Igloo> ITHM "can someone run 'host www.haskell.org' and tell me what it says"
17:20:18 <Pseudonym> www.haskell.org is an alias for bugs.haskell.org.
17:20:18 <Pseudonym> bugs.haskell.org has address 128.36.229.215
17:20:29 <dons> that's what I get
17:20:33 <TheHunter> % host www.haskell.org
17:20:33 <TheHunter> Nameserver not responding
17:20:33 <TheHunter> www.haskell.org A record not found, try again
17:20:44 <Pseudonym> You heard it here first, folks!  Haskell is really bugs in disguise!
17:21:02 <dons> oh no!
17:34:50 <Enveigler_> Pseudonym: I think the "A pixel is not a square" hits the nail on the head. What got me started on this train of thought is the mapping of worlds coordinates to different device spaces. The other example was my attempt to find something comparable.
17:37:28 <Pseudonym> Right.
17:37:55 * Pseudonym still isn't sure what the issue is, though
17:38:20 <Pseudonym> I do find myself often wanting something stronger than type synonyms.
17:38:33 <Pseudonym> Something like type synonyms, only compiler-checked.
17:38:41 <Pseudonym> Which I tend to use "newtype" for.
17:45:11 <fnord123> dons, still around? I'm getting some trouble with building hsx on osx - 'runhaskell Setup.hs build' in the src/haskell-src-exts directory gives me an error in Parser.ly: no happy preprocessor available... Do you happen to know enough about hsx to know what the problem might be?
17:45:49 <Enveigler_> The problem is that the conversion only really works one way. contnuous->discrete. When you click a pixel in device space, if the pixel represents an edge or line, there is no way to convert the discrete -> continuous. Ie. which side of the infinitly thin line that bisects that pixel in the continous space. It's not  anything I'm likely to be able to fix, but I got thinking about it anyway.
17:46:28 <Korollary> Enveigler_: isn't the conversion with respect to properties of the output device, not the point itself ?
17:46:50 <Pseudonym> For the purposes of picking, I think you can think of a pixel as a small bounding box.
17:47:10 <Pseudonym> But pixels are so small these days, that "snap" picking seems more appropriate anyway.
17:47:15 <Pseudonym> e.g. "snap to object"
17:48:32 <fnord123> ok happy is another program. im downloading it now
17:48:49 <TheHunter> fnord123, you don't need happy.
17:48:57 <TheHunter> @wiki Lambdabot/Installation
17:48:58 <lambdabot> http://www.haskell.org/hawiki/Lambdabot/Installation
17:49:49 <TheHunter> hmm, maybe you do, i'm not sure.
17:51:32 <Enveigler_> Pseudonym: Probably. I was thinking about having a local zoom function that tracked the mouse and allowed more accurate picking, but each time you zoom, you get the same problem at a different scale.
17:52:51 <Pseudonym> There's a lot of research out there into picking objects.
17:53:02 <Pseudonym> Voroni decomposition is common.
17:54:11 <swalters> I'm trying to follow some haskell tutorials using ghci and the examples of defining functions don't work.  My prompt reads "Prelude," and the errors are either "Variable not in scope: 'foo'" or "parse error on input '='"  What am I doing wrong?
17:55:06 <Enveigler_> I actually playing with waveforms rather than "objects".
17:55:32 <Pseudonym> swalters: Almost certainly, you need to type this stuff into a text file and then load that into GHCi.
17:55:43 <fnord123> ffs, I'm getting an error making happy now because of some error citing "__DISCARD__"
17:55:51 <Pseudonym> Right, interesting.
17:56:00 <dons> fnord, you on OSX?
17:56:04 <fnord123> yes
17:56:07 <dons> ah!
17:56:14 <dons> forget hs-plugins for now then
17:56:21 <dons> cd yi ; ./configure ; make way=static
17:56:34 <dons> you get the yi experience, nonetheless
17:56:38 <fnord123> i did that but i want to make it non-static
17:56:59 <dons> this will be harder, as you are seeing :)
17:57:16 <dons> __DISCARD__ is a symbol being left behind by the mangler, iirc
17:57:27 <fnord123> i figured as much..
17:57:33 <dons> check the mailinglist, someone will have mentioned how to fix this.
17:57:44 <dons> in fact, maybe just check last night's logs, and grep for 'ozone'
17:57:49 <dons> he mentioned gcc 4, I think
17:58:28 <swalters> Pseudonym, can I load and reload it with the :load directive?  And is using haskell interactively something that doesn't really happen? (Like you don't have interactive C interpretation)
17:58:59 <Pseudonym> I use Haskell interactively all the time, but I tend not to modify my script while I'm doing it.
17:59:08 <dons> from hence for OSX is known as the OS with lots of eye candy but nothing builds or runs on it properly
17:59:12 <Pseudonym> But some do, of course.
17:59:22 <Pseudonym> Yes, you either reload using :load, or you exit and restart GHCi.
17:59:22 <Korollary> you can reload via :r
17:59:26 <Pseudonym> Right.
17:59:27 <Pseudonym> Yes, :r
17:59:35 <Pseudonym> That's what I meant. :-)
17:59:45 <Korollary> sure, exit and restart heh
17:59:58 <Pseudonym> I exit and restart when I'm editing multiple modules.
18:00:00 <Korollary> what is your TMR article on ?
18:00:04 <Pseudonym> Who, me?
18:00:06 <Korollary> yah
18:00:44 <Pseudonym> It's a hands-on approach to the theory of rendering.
18:00:54 <Pseudonym> Emphasis on the theory.
18:01:28 <Korollary> ah
18:02:08 <swalters> What is the "Prelude" anyways?  My neophyte stumbling through documentation hasn't enlightened me on it.  My best guess is that it's some sort of standard library and that my prompt reads "Prelude" because that's the scope I'm currently working in.
18:02:28 <Pseudonym> Yup, basically that's it.
18:02:41 <Pseudonym> http://haskell.org/onlinereport/
18:02:55 <Pseudonym> If you click on "standard prelude", it'll show you what's in it.
18:03:13 <Pseudonym> Basically, the prelude is the bit of the standard library which is always there.
18:04:06 <swalters> Thanks.  That's a good link to have any-which-way.
18:04:12 <Pseudonym> Definitely.
18:04:27 <Korollary> I wonder if it's possible to write a haskell tutorial that can be finished under 2 hours without prior fp experience.
18:10:18 <heatsink> I doubt it.  It just takes too long to get comfortable with the syntax.
18:10:49 <heatsink> and the semantics, but the syntax alone takes time.
18:11:28 <Pseudonym> Any such tutorial probably wouldn't get far past the command line.
18:11:33 <Lemmih> Matrix-style brain upload perhaps?
18:11:59 <swalters> I would be willing to bet that the difficulty of the syntax depends on how much prior mathematics training a person has.  So far, the syntax and idea of function domains and codomains hasn't really bothered me. (and I'm about an hour into looking at Haskell)
18:12:18 <Korollary> swalters: what other langs do you know ?
18:13:11 <swalters> Scheme, and then a few imperative languages, python, c/c++, etc.
18:13:20 <Korollary> ah
18:14:32 <swalters> But, I think anyone who's been exposed to some abstract algebra wouldn't be too terribly bothered by Haskell syntax.
18:14:34 <heatsink> What's the definition of a functional language? I think of scheme as imperative because it has things like set! and define.
18:14:46 <heatsink> swalters: it was the other way around for me.
18:15:17 <heatsink> swalters: learning haskell made it easier for me to understand maths notation.
18:16:16 <swalters> heatsink, How much mathematics had you completed by the time you started learning haskell?
18:16:59 <heatsink> swalters: Continuous stuff: calculus and differential equations.
18:17:48 <swalters> That's why.  I was referring to abstract algebra and the latter end of many undergrad discrete math courses.
18:18:22 <Pseudonym> heatsink: The most useful programming languages do tend to support more than one "paradigm".
18:18:32 <Pseudonym> But with most languages, there is a definite "dominant paradigm".
18:19:12 <Pseudonym> As an example, Haskell natively supports functional programming, imperative programming, generic programming and a certain style of object-oriented programming.
18:19:21 <Korollary> which style ?
18:19:23 <heatsink> swalters: Yea, I didn't have a class introducing those concepts, but I've had classes using things like set notation.
18:19:28 <Pseudonym> However, functional programming tends to dominate.
18:20:08 <Pseudonym> BRB
18:21:08 <swalters> I found scheme to be a nice playground to move from imperative to functional paradigms.  Now I tend to avoid side effects whenever I can in scheme programs.  If nothing else, it makes your programs easier to understand.
18:22:09 <Korollary> so how's the tutorial coming along ?
18:23:11 <swalters> I actually haven't been able to make it any farther yet.  I've been arguing with emacs for the past few minutes.
18:24:14 <Korollary> you need to M-x emacs-stop-arguing-with-me
18:24:35 <swalters> what's the haskell source file extensions?
18:24:44 <Korollary> .hs or .lhs (for literate)
18:24:58 <Korollary> there's an emacs haskell-mode
18:25:43 <Korollary> @yi
18:25:44 <lambdabot> Maybe you meant: pl wn yow
18:25:47 <Korollary> bah
18:25:55 <heatsink> @pl wn yow
18:25:56 <lambdabot> wn yow
18:26:10 <heatsink> @wn
18:26:11 <swalters> yeah, I just installed the haskell mode.
18:32:10 <swalters> Is four lines an acceptable paste in this channel, or should I use lisppaste?
18:32:30 <Korollary> 4 lines is ok. lisppaste is always welcome too
18:33:31 <swalters> I'm really confused by the types in the following example:rnfibGen :: Num a, Num b => b -> b -> a -> brnfibGen a b n = case n ofrn        0 -> arn        n -> fibGen b (a + b) (n - 1)
18:33:51 <swalters> Particularly, the multiple uses of b in "b -> b -> a -> b
18:34:30 <Korollary> b is a type, like Int. So "Int -> Int -> Char -> Int" is an analogy
18:35:32 <Korollary> do you understand the "Num a, Num b" part ?
18:36:31 <swalters> Why is it not: "fibGen :: Num a => a -> a -> a -> a" since both a and b are Nums?  Does it have to do with subclassing?
18:36:46 <Korollary> there is no subclassing in haskell
18:37:18 <swalters> Then why do the tutorials talk about choosing the most generic type?
18:37:27 <Korollary> This is exactly that subject
18:37:37 <Korollary> The function is not constrained to have b = a.
18:37:41 <Korollary> for types
18:38:07 <Korollary> b could be the same type as a, or it could be different
18:38:52 <Korollary> Int & Float maybe
18:39:02 <swalters> And my rewrite would require all four to have the exact same type whereas the original just requires that each be a sub-type of Num?
18:39:34 <Korollary> You as the programmer can force it to be all "a"s if you want. Otherwise the inference will be as general as possible.
18:39:47 <swalters> ("all four" meaning a -> a -> a -> a )
18:40:25 <Korollary> btw, there is no subtyping.
18:40:51 <swalters> Is there a heirarchy of types?
18:40:55 <Korollary> no
18:41:18 <swalters> Then why can Int and Float be used in a slot of type Num?
18:41:53 <swalters> And why not, say, a string?
18:42:02 <Korollary> they cannot be. The function definition is generic itself. That doesnt mean that there is a single function accepting either type as a param. It's more like c++ templates.
18:42:57 <Korollary> try this
18:43:09 <Korollary> in ghci, type "(1::Int) + (2::Int)"
18:43:28 <Korollary> and then try "(1::Int) + (2.0::Float)"
18:44:34 <Korollary> and then "(2.0::Float) + (3.0::Float)"
18:46:14 <swalters> By what I've seen typing those in, and only from typing those in, one might be expected to conclude that you cannot add an integer to a float in Haskell.  I'm sure I'm wrong there, but... why? (I know I sound like a 5 year old "why why why")
18:47:07 <Korollary> That's right. You need to explicitly cast the Int to a float so that you have two floats to add.
18:47:26 <Korollary> In other languages, that conversion is done automatically for you
18:47:40 <Pseudonym> Back.
18:47:43 <Korollary> wb
18:48:01 <swalters> wb
18:48:03 * Enveigler_ has similar concerns. It makes me think that Haskell is too concerned with machine representation.
18:48:47 <Korollary> Enveigler_: It's not that. Even in my cpp code I tend to be explicit and add static_cast's everywhere. They create hard to find bugs often.
18:48:48 <swalters> My tutorial mentions "The only values for which '>' and so on are defined are those which are members of class 'Ord', so named because an 'order' can be determined for them."  Is it erroneous by using the word "Class?"
18:49:24 <Korollary> swalters: Haskell's usage of class refers to a class of types, instead of class of objects.
18:50:24 <Korollary> You may use "brotherhood of types" if it helps the confusion :)
18:50:30 <swalters> *chuckle*  So, there's no subtyping, but there's classes of types.  Oy.
18:50:35 <Enveigler> (Dratted ISP) Before anyone gets offended--it's just my thoughts voiced, not a accusation.
18:50:57 <Korollary> Enveigler: ?
18:51:15 <swalters> Are you saying that a "class of types" is a very different beast than a "type"
18:52:06 <Korollary> swalters: Yes. It's a club that some types belong to, and some don't.
18:52:22 <Enveigler> Hm. Maybe my previous post got lost when I was disconnected. It showed up here. I said:"Enveigler_ has similar concerns. It makes me think that Haskell is too concerned with machine representation." regarding the Ints/Floats thing
18:52:23 <swalters> May classes contain classes?
18:52:50 <Korollary> ... Enveigler_: It's not that. Even in my cpp code I tend to be explicit and add static_cast's everywhere. They create hard to find bugs often.
18:53:37 <heatsink> swalters: classes can be instances of classes; that's like subtyping.
18:54:38 <heatsink> Hmm... I think that's a bad way to say it.
18:54:39 <Korollary> umm, subtyping is usually interpreted to mean you can substitute two values for each other if they are on the same hierarchy.
18:54:40 <swalters> (thanks for the patience guys...)
18:55:32 <Korollary> swalters: You can create a new typeclass by basing it on an existing type class: e.g. "class  (Eq a) => Ord a  where ..."
18:55:39 <Enveigler> Right. I understand the casting issue (and agree), but I would like a language that treated numbers and numbers with machiine representation hidden and where a function has a restricted nontion of a number (like integer), it would use that part of the number that complies with it's restriction.
18:55:53 <Enveigler> s/and/as/
18:56:24 <Enveigler> s/mistyped/correct/*
18:57:24 * swalters puzzles with his puzzler.
18:57:26 <Korollary> Enveigler: That would be cool.
18:58:43 <Korollary> swalters: My previous example states that "members of the Ord typeclub are required to be existing members of the Eq typeclub". and further list some more requirements.
18:59:10 <swalters> btw, what is this portion of the function declaration/definition called? "fibGen :: Num a, Num b => b -> b -> a -> b"
18:59:48 <Enveigler> I've been playing with Ocaml, and their approach uses different operators for ints and floats which means often times, you have to have two representations of the same value which seems messy and contradictory of a value being a constant.
19:00:53 <Korollary> swalters: type signature (optional)
19:01:24 <Korollary> Enveigler: Heh, I quit messing around with ocaml soon after I saw "+." for floats. Haskell spoiled me.
19:01:59 <swalters> So, if there were a class (of types), foo, for which bar is a class that is an instance of/member of/contained in foo and a function calls for a foo, would a type belonging to bar be accepted?
19:02:33 <swalters> (and that's probably my last question for the night...)
19:03:04 <Korollary> swalters: yes. It all happens statically, btw. No late binding.
19:03:33 <swalters> *nod*  I believe it's called "type inference?"  I think I read about it somewhere.
19:03:47 <Enveigler> Haskell is much nicer in that regard, and no "let" and "let rec" etc.. But for a set-in-his-was-imperical programmer like me, it's a little easier to get a handle on the IO side of things.
19:04:02 <Korollary> Either via inference or via your explicit type signature, the compiler determines what you are passing in.
19:04:50 <TheHunter> dons, runplugs is strange: runplugs and ghc communicate via 4 fds, two of which are equal.
19:06:06 <Korollary> Enveigler: I wish that there was a better tutorial for IO in haskell. Once you figure it out, you'll scracth your head thinking why it took that long because it's not even complicated or verbose.
19:06:21 <swalters> Korollary, one of us, almost definitely me, needs to brush up on their definition of "subclass" and "subtype" because this certainly sounds to me like a hierarchy of types with subtypes or classes with subclasses.
19:06:41 <swalters> Well, thanks all for entertaining a neophyte
19:07:05 <Korollary> swalters: No problem. Think of C++ templates instead of late binding.
19:08:14 <swalters> Sadly, I never quite got the hang of C++ templates, mainly because my resources were so poor when I would have learned them.  I'll take another look.
19:08:19 <Korollary> ah
19:11:08 <Enveigler> Korollary: A few worked examples that are more than Hello, world or Hello <input name> and less than Prelude.hs would be good. Most of the tutorial material spends way too much time talking about the theory and justifying the choice (which may be important in the big picture but is unnecessary when learning the syntax).
19:11:35 <Korollary> well, briefly, in C++ when you write a template function like "template class T void func1(T arg) { ... }" and call the function once with an int and once with a float, the compiler generates "two" function bodies for each call.
19:12:10 <Enveigler> A few examples of code (a picture) can save many thousands of words I think.
19:12:13 <Korollary> Enveigler: Yeah
19:12:43 <Korollary> Enveigler: Are you familiar with the syntactic sugar that is the do-notation ?
19:13:56 <Enveigler> Yes. But, writing that way, you end up with "One big monolithic do" syndrome.
19:14:20 <Korollary> Enveigler: It may help if you don't use it for a while and stick with the explicit syntax.
19:15:14 <TheHunter> dons, you won't believe how easily the problem can be fixed.
19:15:28 <Enveigler> The problem I'm having is getting to grips with breaking IO intensive programs into discrete chunks. I keep wanting to save state, but then get confused and frustrated trying constantly wrap and unwrap Monads
19:16:18 <TheHunter> dons, getContents closes stdin and that messes up exec. That's also the reason why the ghc-clone works.
19:16:28 <Enveigler> Or rather wrap and unwrap values in Monads
19:16:33 <TheHunter> dons, *ghci
19:17:47 <Korollary> Enveigler: I have a few short programs that are 85+% within do-blocks. It's not that hard once you get the hang of it.
19:18:44 <Enveigler> 85% within a *single* do block? Or a collection of small functions that contain do blocks?
19:19:04 <Korollary> Enveigler: Multiple functions with their own do-blocks.
19:19:35 <Enveigler> Any medium complexity ones available online simewhere for me to browse?
19:19:51 <Korollary> Enveigler: You of course don't have to try to separate aggressively into pure and impure parts. Some programs contain just too much IO
19:19:56 <Korollary> Enveigler: Sure
19:21:04 <Enveigler> Korollary: Hm. I'm not sure I follow that. If the application requires IO, there's not much choice about "too much IO"?
19:22:03 <lisppaste2> Korollary pasted "arrays" at http://paste.lisp.org/display/10399
19:22:51 <Enveigler> (I'd also like to understand how to write myown lazy IO, but I'm deferring that for now :) )
19:23:07 <Korollary> Enveigler: You separate as much as you can, but if the program does a lot of io, that means the do-block will be large no matter how hard you try.
19:23:51 <Speck> I bet there are some clever ways to make it modular
19:23:58 <Speck> custom monads anyone?
19:24:17 <Korollary> Enveigler: The code I pasted implements an array based algorithm to generate permutations. As you see, only the first two functions are pure.
19:28:17 <fnord123> I have a dir structure like dir/project/something1/someutilstuff/ and want someutilstuff to not have to have module names like project.something1.someutilstuff. Can't I have relative module paths, or do I need to make the directory stucture match the module paths?
19:28:35 <Enveigler> Speck: That's almost certainly where I need to go, but for now I'm trying to get to grips with using IO Monads effectively. I'm a long way from being able to write my own I think.
19:29:07 <Speck> it isn't so much writing monads as it is identifying monads
19:29:16 <Speck> but I can't admit to being good at either
19:30:02 <Enveigler> Needless to say, the distinction is a little lost on me ;)
19:30:26 <Speck> the hard part isn't in the writing, I meant to say, but rather the identifying of patterns in one's code as being a monad
19:30:29 <Enveigler> Korollary: Thanks. I'll spend some time playing with that.
19:32:02 <Korollary> Enveigler: You betcha. The nice thing about that is the c++ implementation is equally long and not more readable.
19:40:47 <Enveigler> @docs Data.Array
19:40:48 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Data.Array.html
19:43:32 <interferon> is there a complex number datatype in standard haskell?
19:43:37 <Enveigler> @docs Data.Array.IO
19:43:37 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Data.Array.IO.html
19:46:03 <dons> TheHunter!
19:47:09 <Korollary> ugh, do I need happy et al to build HSX ?
19:47:12 <heatsink> interferon: Data.Complex.RealFloat
19:47:44 <dons> I think pre-generated files are distributed with HSX
19:47:55 <dons> at least the snapshot ,not the darcs repo of course
19:48:13 <interferon> heatsink: do i have to include anything to get it?  i get type constructor or class not in scope
19:48:13 <Korollary> dons: I have the darcs repo. Shoud I download the tarball instead ?
19:48:29 <dons> or install happy, it's fun and it makes you happy :)
19:49:03 <Korollary> dons: right. We all need happy.
19:49:15 <dons> happy is good for your karma
19:49:23 <Korollary> a la @karma ?
19:49:27 <dons> why not?
19:49:55 <Korollary> I am trying to build Yi
19:50:15 <heatsink> interferon: you need to import Data.Complex
19:50:18 <interferon> xb
19:50:23 <heatsink> xb?
19:50:32 <dons> Korollary, yes. we should bug nibro about build dependencies in HSX
19:50:32 <interferon> damn it, fingers slipped on C-x b
19:51:04 <Korollary> dons: Do I need alex ? (why dont I have alex already anyway ? it was not in the ghc rpm)
19:51:08 <interferon> heatsink: i'm still getting that error
19:51:26 <Enveigler> Korollary: try1 seems to loop indefintly?
19:51:29 <interferon> heatsink: http://rafb.net/paste/results/EhEkLg18.html
19:51:37 <Enveigler> Try2 that is
19:52:20 <Korollary> Enveigler: the program expects a command line argument for the intial size of the array. Try 4 for instance.
19:53:03 <Enveigler> That's exactly what I tried. 4 and then 2. It never terminates.
19:53:03 <heatsink> oh! I was looking at the wrong part of the line
19:53:12 <heatsink> It's Data.Complex.Complex
19:53:52 <heatsink> Complex is a type constructor, you need to give it a RealFloat type
19:54:04 <Korollary> Enveigler: That is weird. It runs fine over here.
19:54:15 <heatsink> So Complex Float would work as a type.
19:54:25 <dons> I don't think hsx needs alex, but it does need happy
19:55:16 <interferon> heatsink: hmmm now i get "Complex is not applied to enough type arguments"
19:55:17 <TheHunter> dons, i don't understand at all what's going on, the runInteractiveProcess code (http://darcs.complete.org/fptools/libraries/base/cbits/runProcess.c) seems ok.
19:55:43 <Korollary> Enveigler: It runs fine on my linux and windows boxes here.
19:55:51 <heatsink> interferon: Complex is a type constructor, you need to apply it to a type.
19:56:11 <heatsink> interferon: For example, Complex Float is a complex number with Floats for its real and imaginary parts.
19:56:12 <interferon> heatsink: so what do i use for the parameter list?
19:56:13 <dons> TheHunter, I thought from the above that you've solved it? or at least have  a fix for runplugs?
19:56:41 <TheHunter> the fix is: whatever you do, don't close stdin.
19:56:46 <dons> ah, and I see plugs uses readline.
19:56:49 <heatsink> Complex Double uses Doubles for its real and imaginary parts.
19:56:52 <dons> right.
19:57:29 <dons> oh, and hGetContents says:   @hdl@ is effectively closed
19:58:10 <dons> closing stdin is doubleplus bad
19:58:46 <Korollary> I was having some socket io anomalies yesterday. I should have kept a good record of it.
19:58:56 <TheHunter> why would runInteractiveProcess care if stdin is closed?
19:59:21 <dons> doesn't it duplicate fds all over the place?
19:59:48 <dons> and then trys to set one of the closed handles non-buffered, and then we die, perhaps?
20:01:08 <TheHunter> it only duplicates a newly created pipe handle. According to dup2's documentation that's ok.
20:01:24 <TheHunter> dup2  makes  newfd  be the copy of oldfd, closing newfd first if necessary
20:03:39 <lisppaste2> Enveigler pasted "Korollary.hs" at http://paste.lisp.org/display/10401
20:04:27 <Enveigler> What'd I do wrong? (I marked the only additions I made with "-- !!"
20:04:50 <Korollary> Enveigler: You seem to be missing some functions from my original source
20:05:12 <TheHunter> still, ghc has no stdin handle when run by runplugs, says /proc/.../fd
20:06:03 <Enveigler> I omitted the top half as I haven't changed it
20:06:21 <Enveigler> I can paste the full thing again if you want?
20:06:21 <dons> hmm
20:06:24 <TheHunter> this runProcess code doesn't check dup2's return value though. Maybe it returns an error.
20:08:02 <Korollary> Enveigler: It's ok. I don't understand. I am using 6.4 on windows and linux and it works for me (and dons).
20:08:22 <dons> hmm, yes I see.
20:08:43 <lisppaste2> Enveigler annotated #10401 with "Korollary.hs (in full)" at http://paste.lisp.org/display/10401#1
20:10:01 <Korollary> Enveigler: Try replacing "unsafeFreeze" with "freeze" in getNextState
20:10:29 * Enveigler doesn't understand either? I'm using Glasgow Haskell Compiler, Version 6.4, for Haskell 98, compiled by GHC version 6.2.2 pre-compiled. Can;t think how I managed to screw that up :)
20:11:21 <Enveigler> @index Freeze
20:11:22 <lambdabot> bzzt
20:11:22 <Korollary> oops it loops for me too
20:11:49 <Enveigler> Phew!
20:12:34 <Enveigler> @index freeze
20:12:34 <lambdabot> Data.Array.MArray, Data.Array.IO, Data.Array.ST, Data.Array.Storable
20:13:02 <Korollary> Enveigler: This is most bizarre.
20:14:12 * Enveigler feels less cursed :)
20:14:40 <Korollary> Enveigler: It's cured by "-O"
20:14:52 <Korollary> The unoptimized version loops indefinitely
20:15:18 <Enveigler> Here too.
20:15:21 <Enveigler> :)
20:15:40 <Korollary> even with the safe freeze, it loops
20:15:56 <Korollary> what the monad...
20:16:49 <dons> cured by -O ? hmm :/
20:17:17 <Enveigler> That *is* weird. I rememebr the -enable-unsafe-optimisations switch on some C compilers, but I never encountered a -dont-perform-unsafe-nonoptimisations :)
20:18:21 <dons> usually means a bug in code generation
20:18:30 <dons> try switching between -fvia-C and -fasm
20:19:46 <dons> when you turn on -O you get -fvia-C, and -Onot gives you -fasm by default, so you could try -Onot -fvia-C, to see if asm generation is to blame
20:21:06 <Korollary> dons: no difference
20:26:46 <dons> so, in summary, -Onot fails, -O doesn't. so somehow the bug is optimised away. meaning there could be a bug in code generation (not just asm generation)
20:27:18 <dons> if this is a short program, then reporting it as a bug on the sourceforge seems reasonable
20:27:44 <Korollary> dons: You've seen the program. It's my permutation generator.
20:27:53 <Korollary> 90 lines
20:28:10 <dons> right, which exercises some odd things
20:28:14 <Korollary> heh
20:28:24 <dons> so a report is reasonable, I think.
20:28:31 <Korollary> ok
20:28:51 <dons> though you could play around with it some more to isolate the  error
20:29:04 <dons> 90 lines is still a lot of generated Core code ;)
20:29:26 <Korollary> dons: I've never used a haskell debugger.
20:29:52 <dons> play around == study behaviour, make a guess, remove code that doesn't contribute, continue
20:30:00 <dons> no need for a debugger
20:30:23 <Korollary> I'll try
20:30:39 <dons> we're just trying to find the smallest code that triggers the erroneous behaviour
20:30:48 <heatsink> One thing I do in freezing code is to print things with Debug.Trace.trace to find out where the freeze happens.
20:30:54 <Korollary> it's likely an array library issue. I don't think people use arrays much.
20:31:11 <dons> right
20:31:54 <dons> well, maybe not an array library -- because then it would happen with -O as well
20:32:01 <heatsink> Type inference question: How does type inference  in order to instantiate a polymorphic expression?  How does polymorphism work letrec work
20:32:05 <heatsink> oops
20:32:11 <heatsink> I was still typing -- disregard that
20:32:13 <dons> but how the compiler compiles the array code maybe
20:32:41 <dons> heatsink, see the references to peyton jones' book
20:33:10 <dons> p://research.microsoft.com/%7Esimonpj/papers/slpj-book-1987/index.htm
20:33:16 <dons> s/^/htt/
20:33:21 <Korollary> isn't wireless nice
20:33:36 <dons> no, that was a paste-o ;)
20:34:25 <Korollary> I still cannot believe that. Don't the packets have checksums ? If you lose packets, you shouldnt be sending garbage.
20:35:10 <dons> did I send garbage?
20:35:30 <Korollary> not now. but when you do, it doesnt make sense.
20:35:41 <dons> yeah. hmm
20:35:55 <Korollary> maybe the checksum is correct by accident ?
20:35:58 <dons> but I think its a layer higher
20:36:35 * dons shrugs and doesn't wish to ponder the intricky-sies of WANs
20:37:19 <Korollary> are you using ssh ?
20:37:31 <dons> of course
20:37:57 <Enveigler> How do I display the contents of an IOArray?
20:39:42 <Korollary> Enveigler: You can use the readArray function to access element by element.
20:40:37 <Korollary> Enveigler: or you can freeze it into an immutable array and then construct a list using "elems"
20:40:58 <Enveigler> and then give that to show and map those over the array?
20:41:14 <Korollary> right
20:41:23 <Enveigler> Or doesn't  map work on arrays?
20:41:35 <Korollary> map expects lists
20:42:08 <TheHunter> dons, this is what I have: http://hbin.dyndns.org/pastebin/73.html
20:42:09 * Korollary has successfully built Yi
20:42:22 <TheHunter> I think I should report that.
20:43:06 <dons> TheHunter: that looks reasonable
20:43:26 <dons> I concur, report away!
20:43:34 <Korollary> which --as=xxx should I use to get emacs ?
20:43:57 <dons> there are 3, the most recently worked on ones are "emacs2" and "mg"
20:44:04 <Enveigler> @type show
20:44:05 <lambdabot> forall a. (Show a) => a -> String
20:45:01 <Enveigler> Is there any guidance on interpreting Korollary.hs:72:16:
20:45:01 <Enveigler>     Couldn't match `IO ()' against `t -> t1'
20:45:01 <Enveigler>       Expected type: IO ()
20:45:01 <Enveigler>       Inferred type: t -> t1
20:45:01 <Enveigler>       Expected type: a -> b
20:45:02 <Enveigler>       Inferred type: IO ()
20:45:04 <Enveigler>     In the expression: print $ show
20:45:07 <dons> probably I will merge "emacs" and "emacs2" this week some time
20:45:28 <dons> show isn't applied to its argument?
20:45:36 <Korollary> Enveigler: You need to paste your modifications
20:45:54 <TheHunter> @docs System.Process
20:45:55 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/System.Process.html
20:45:58 <Enveigler>          fmap ( print $ show) (elems larr)
20:45:59 <Korollary> dons: mg seems more complete
20:46:13 <dons> its around 900 loc, whereas emacs2 is 300
20:46:19 <dons> but emacs2 has a kill ring :)
20:46:27 <dons> also, it does a better minibuffer
20:46:42 <dons> but, yes, mg is probably the more usable right now
20:47:03 <Korollary> it's very cute, tho
20:47:21 <dons> have you tried multiple windows? it does that nicely :)
20:47:29 <Korollary> C-x 2 works ?
20:47:34 <dons> sure
20:47:41 <Korollary> aww yeah
20:47:53 <dons> C-x ^ and C-x v also
20:48:22 <Korollary> dons: it would be nice to get a list of the implemented functions
20:48:26 <dons> C-x 0, C-x 1, C-x n
20:48:31 <dons> M-x describe-bindings
20:48:39 <dons> ;)
20:49:16 <Korollary> whoa that's quite a few
20:49:42 <dons> that's all of mg's global bindings, some will report "unimplemented" if you try to use them
20:49:52 <dons> probably most work though
20:50:22 <Korollary> Enveigler: fmap print [1,2] has type [IO ()]. It needs to be "IO something"
20:51:08 <Korollary> dons: this is very neat
20:54:12 <Enveigler> So, no way to display the contents of a IOArray then :(
20:54:24 <Enveigler> That boring.
20:54:58 <Korollary> Enveigler: Ugh. It is possible. not with fmap, though.
20:55:25 <Enveigler> A good answer save many questions.
20:55:48 <Enveigler> I#ll get outta ya hair . Thanks for your patience.
20:55:55 <Korollary> aww
20:56:04 <Korollary> I was typing an answer lol
20:58:19 <tewk> Is there a cvs,svn, or darcs repository for the haskell web server?
21:08:18 <TheHunter> dons, i think i figured out what happens.
21:09:17 <TheHunter> does pipe always use the lowest available fds?
21:09:44 <dons> not sure
21:09:47 * dons investigates
21:13:04 <TheHunter> yep, it does.
21:13:32 <TheHunter> what a mean bug!
21:17:05 <TheHunter> how do I convert an int into a FILE* ?
21:18:11 <heatsink> in C?
21:18:17 <TheHunter> yep.
21:18:22 <heatsink> use a cast
21:18:26 <heatsink> (FILE*)
21:18:31 <heatsink> oh wait
21:18:38 <TheHunter> the int is a file descriptor
21:18:43 <heatsink> convert an fd into a file
21:18:56 <heatsink> yeah, there was a function for that
21:19:35 <heatsink> fdioen
21:19:37 <heatsink> fdopen
21:20:07 <TheHunter> ok, thanks.
21:28:12 * heatsink discovers that page 181 is missing from SPJ's book
21:28:24 <TheHunter> done, http://sourceforge.net/tracker/index.php?func=detail&aid=1249226&group_id=8032&atid=108032
21:30:14 <TheHunter> night everybody!
21:30:23 <heatsink> goodnight thehunter.
21:33:53 <dons> thanks TheHunter
21:46:10 <heatsink> That cleared up the meaning of a type scheme for me.  But I don't see an explanation of how free type variables are identified.
21:46:50 <heatsink> I'm trying to come up with an example of what I mean using letrec but the example is causing an occurs error unless I explicitly type it.
21:47:43 * swalters does the victory dance.
21:48:02 * heatsink gives swalters a victory cookie.
21:48:15 <swalters> Learning a new language is the only time you can feel accomplished when turning out a four liner that calculates n terms of the fibonacci sequence.
21:48:18 <swalters> :-P
21:49:16 <heatsink> Pish.  Any program in haskell is a one-liner if you use the right punctuation. ;)
21:49:29 <Pseudonym> Or the right library.
21:49:37 <Pseudonym> { import Foo; main = foo }
21:49:39 <swalters> *chuckle*  Do you have ascii art programs like perl?
21:50:01 <dons> @eval let fibs = 1:1:zipWith (+) fibs (tail fibs) in take 10 fibs
21:50:02 <lambdabot> [1,1,2,3,5,8,13,21,34,55]
21:50:03 <dons> ;)
21:50:50 <dons> swalters, www.cse.unsw.edu.au/~dons/pretty.html hehe
21:51:22 <dons> though such programs tend to be rarer than in perl, I would say
21:51:39 * swalters shakes his head.
21:52:15 <swalters> dons, is what you wrote pretty much an expansion of fibSeq = 0 : 1 : [ a + b | (a, b) <- zip fibSeq (tail fibSeq)]
21:52:51 <dons> yep
21:53:22 <dons> zip fibsSeq (tail fibSeq) gives you a list of numbers to add
21:53:42 <dons> zipWith is a generalised zip, that takes a combining function, in this case (+)
21:53:54 <dons> so no need to store the intermediate pair list
21:54:14 <swalters> I find the self-reference of that comprehension //so// cool.  I would have never thought of doing something that way (and hence the reason I'm learning Haskell)
21:57:23 <Pseudonym> @plugs map fst $ scanl (\(a,b) _ -> (a+b, a)) (0,1) [1..9]
21:57:24 <lambdabot> [0,1,1,2,3,5,8,13,21,34]
21:57:42 <Pseudonym> That's _slightly_ shorter.
21:58:11 <dons> @pl \(a,b) _ -> (a+b, a)
21:58:12 <lambdabot> uncurry ((const .) . (flip =<< ((,) .) . (+)))
21:58:14 <dons> bah
21:58:35 <swalters> And it also looks like absolutely nothing I've learned.
21:58:47 <Pseudonym> And the @pl version looks even LESS like it.
21:59:15 <heatsink> dons: it seems that pointless is more verbose whenever variable names are multiply used.
21:59:31 <dons> that seems reasonable, yes
21:59:42 <swalters> I recognize =<< from a paper on monads that I once skimmed. :-P
21:59:44 <dons> points are good when you want to refer to them a lot
21:59:59 <Pseudonym> If it helps...
22:00:02 <Pseudonym> map fst $ scanr (\_ (a,b) -> (a+b, a)) (0,1) [1..9]
22:00:08 <Pseudonym> @pl (\_ (a,b) -> (a+b, a))
22:00:08 <lambdabot> const (uncurry (flip =<< ((,) .) . (+)))
22:00:13 <Pseudonym> That's a little prettier.
22:00:26 <Pseudonym> Unforutnately it returns the fibonacci numbers in reverse order.
22:00:29 <lispy> @type const
22:00:30 <lambdabot> forall a b. a -> b -> a
22:00:31 <Pseudonym> @eval map fst $ scanr (\_ (a,b) -> (a+b, a)) (0,1) [1..9]
22:00:32 <lambdabot> [34,21,13,8,5,3,2,1,1,0]
22:02:17 <Pseudonym> What You Really Want(tm) here is something like scan, except it support automata with output as well as states.
22:10:06 <heatsink> I'm still trying to puzzle out how type inference determines the number of free type variables in an expression.
22:10:24 <heatsink> For example, in main = let {x = const} in putStrLn $ x show () $ x 3 x
22:11:32 <Pseudonym> @type t {x = const} in putStrLn $ x show () $ x 3 x
22:11:34 <lambdabot> bzzt
22:11:41 <Pseudonym> @type let {x = const} in putStrLn $ x show () $ x 3 x
22:11:43 <lambdabot> IO ()
22:11:51 <Pseudonym> We can pull this apart if you want.
22:11:52 <heatsink> Type inference would have to know that x has two free type variables.  Otherwise the first and second call to x would be forced to the same type, and the expression wouldn't typecheck.
22:12:46 <Pseudonym> Do you want to go through this step by step?
22:12:51 <heatsink> Okay
22:12:53 <Pseudonym> OK.
22:13:01 <Pseudonym> First off, the outer let.
22:13:16 <heatsink> The one containing main?
22:13:28 * autrijus pulls a chair and sits down to listen to the Hindley-Milner tutorial
22:13:31 <Pseudonym> No.  We'll just typecheck the expression let {x = const} in putStrLn $ x show () $ x 3 x
22:13:40 <heatsink> okay.
22:13:51 <Pseudonym> Now, first off, the rule for a let.
22:13:58 <Pseudonym> 1. Typecheck the RHS of the equals.
22:14:04 <Pseudonym> Oh, hang on.
22:14:10 <Pseudonym> 1. Assign a new variable for the LHS.
22:14:17 <Pseudonym> 2. Typecheck the RHS.
22:14:23 <Pseudonym> 3. Unify that with the variable for the LHS.
22:14:33 <Pseudonym> 4. Typecheck the "in" part using that variable.
22:14:42 <Pseudonym> In this case, the let isn't recursive, so we can ignore most of this.
22:14:57 <Pseudonym> Which we will indeed do for the purpose of discussion.
22:15:12 <Pseudonym> Oh, one more thing: This is Haskell, so we also need to generalise the let and apply the monomorphism restriction.
22:15:28 <Pseudonym> All right.
22:15:30 <Pseudonym> @type const
22:15:32 <lambdabot> forall a b. a -> b -> a
22:15:44 <Pseudonym> We'll cheat and call this the type of x. :-)
22:16:02 <Pseudonym> Because you can inherit this right from const.
22:16:03 <autrijus> let { aba = const } ...
22:16:09 <heatsink> um...
22:16:30 <Pseudonym> have I lost you?
22:16:48 <Pseudonym> Maybe we'll start again.
22:16:49 <heatsink> I think you're glossing over the part I don't understand: how x gets the type (forall a b. a -> b -> a)
22:16:56 <Pseudonym> Ah, OK.
22:16:58 <heatsink> Rather than a and b being constand throughout main
22:17:00 <Pseudonym> Let's do this instead.
22:17:16 <Pseudonym> let { x = \a -> \b -> a } in x
22:17:22 <heatsink> okay
22:17:24 <Pseudonym> That's probably more interesting.
22:17:30 <Pseudonym> OK.
22:17:45 <Pseudonym> Type judgements are of the form gamma |- term :: type
22:17:54 <Pseudonym> Where gamma is a set of assumptions.
22:18:14 <heatsink> right
22:18:18 <Pseudonym> For the purpose of discussion, we'll use the fact that the let isn't recursive.
22:18:44 <Pseudonym> So, we need to know:
22:18:53 <Pseudonym> {} |- let { x = \a -> \b -> a } in x :: T
22:18:58 <Pseudonym> where T is a fresh type variable.
22:19:11 <Pseudonym> For that, we need to know:
22:19:21 <Pseudonym> {} |- \a -> \b -> a :: T2
22:19:24 <Pseudonym> Where T2 is fresh.
22:19:35 <heatsink> ok
22:20:01 <Pseudonym> Now the type of a lambda expression \x -> e is T1 -> T2, where x :: T1 and e :: T2
22:20:03 <Pseudonym> You agree?
22:20:34 <heatsink> yes
22:20:46 <Pseudonym> OK.  So we invent a new type variable for a, and recurse:
22:20:59 <Pseudonym> {a :: T3} |- \b -> a :: T4
22:21:21 <Pseudonym> Similarly, a lambda abstraction, so we invent a new type variable for b.
22:21:34 <Pseudonym> {a :: T3, b :: T5} |- a :: T3
22:21:41 <Pseudonym> This is an axiom, you'll note.
22:21:51 <Pseudonym> On the assumption that a :: T3, obviously a :: T3.
22:22:17 <Pseudonym> Right?
22:22:31 <Pseudonym> Or have I lost you?
22:22:39 <Pseudonym> BTW, I'm inventing way more type variables than I need to.
22:22:56 <heatsink> a is a bound variable, so it is looked up in the environment, which contains a and b.
22:23:03 <Pseudonym> Yes.
22:23:18 <heatsink> And the type bound to a is used.
22:23:27 <Pseudonym> Every time you encounter a lambda abstraction, you invent a type variable for it.
22:24:04 <heatsink> right.
22:24:09 <Pseudonym> OK.
22:24:23 <Pseudonym> Now we recurse out, gathering constraints.
22:24:27 <Pseudonym> {a :: T3, b :: T5} |- a :: T3
22:24:33 <Pseudonym> {a :: T3} |- \b -> a :: T4
22:25:02 <Pseudonym> The type of b is T5, and the type of the body of the lambda is T3.
22:25:04 <Pseudonym> So:
22:25:17 <Pseudonym> {a :: T3} |- \b -> a :: T3 -> T5
22:25:22 <Pseudonym> Pop again:
22:25:32 <Pseudonym> {} |- \a -> \b -> a :: T2
22:25:52 <heatsink> if b :: T5 and a :: T3, then \b -> a is T5 -> T3?
22:25:56 <Pseudonym> The type of the lambda-bound variable is T3, and the type of the lambda body is T3 -> T5.
22:26:01 <Pseudonym> So:
22:26:08 <Pseudonym> {} |- \a -> \b -> a :: T3 -> T3 -> T5
22:26:23 <Pseudonym> Uhm...
22:26:25 <Pseudonym> Yeah, sorry.
22:26:29 <Pseudonym> {} |- \a -> \b -> a :: T3 -> T5 -> T3
22:26:33 <Pseudonym> That's correcting the mistake.
22:26:38 <heatsink> ok
22:27:00 <Pseudonym> Then when you reach the top level, you examine the type, look for type variables and generalise them.
22:27:15 <Pseudonym> \a -> \b -> a :: forall t3 t5. t3 -> t5 -> t3
22:27:20 <Pseudonym> Which is more or less it.
22:27:39 <Pseudonym> In practice, the system does much less generating random type variables and more cleverness.
22:28:13 <heatsink> This requires that there be no recursive references, and that the let-bound variables are sorted in the right order.
22:28:34 <Pseudonym> I don't think they need to be sorted in the right order.
22:28:46 <Pseudonym> Recursive references are dealt with using a bit of trickiness.
22:29:00 <Pseudonym> let y = \f -> f (y f) in y
22:29:02 <Pseudonym> Let's say.
22:29:15 <heatsink> okay
22:29:22 <Pseudonym> What you do here is you invent a type variable for y first.
22:29:44 <Pseudonym> {y :: T1} |= \f -> f (y f) :: T1
22:29:49 <Pseudonym> Note it's the same T1.
22:29:53 <Pseudonym> Hmmm.
22:30:00 <Pseudonym> Hang on, let's do it this way.
22:30:05 <Pseudonym> {y :: T1} |= \f -> f (y f) :: ???
22:30:09 <Pseudonym> Where ??? is unknown.
22:30:15 <Pseudonym> Well, this is a lambda expression.
22:30:20 <heatsink> ok
22:30:24 <Pseudonym> So it has type VarType -> BodyType
22:30:43 <Pseudonym> So we invent a new type variable for the var, and typecheck the body under that assumption.
22:30:52 <Pseudonym> {f :: T2, y :: T1} |= f (y f) :: ???
22:31:00 <Pseudonym> Now, applications are a bit tricky.
22:31:17 <Pseudonym> e1 e2 :: B  where e1 :: A -> B and e2 :: B
22:31:22 <Pseudonym> e1 e2 :: B  where e1 :: A -> B and e2 :: A
22:31:24 <Pseudonym> Sorry.
22:31:33 <Pseudonym> So here, we invent a type variable for e2.
22:31:41 <heatsink> ok
22:32:08 <Pseudonym> So:
22:32:15 <Pseudonym> {f :: T2, y :: T1} |= f (y f) :: T3
22:32:16 <Pseudonym> where
22:32:23 <Pseudonym> {f :: T2, y :: T1} |= f :: T4 -> T3
22:32:24 <Pseudonym> and
22:32:35 <Pseudonym> {f :: T2, y :: T1} |= y f :: T4
22:33:08 <Pseudonym> This is also an application, but we'll cheat a bit because we already know the type of f.  (It's T2.)
22:33:15 <Pseudonym> {f :: T2, y :: T1} |= y f :: T4
22:33:17 <Pseudonym> where
22:33:33 <Pseudonym> {f :: T2, y :: T1} |= y :: T2 -> T4
22:33:34 <Pseudonym> and
22:33:41 <Pseudonym> {f :: T2, y :: T1} |= f :: T2
22:33:58 <Pseudonym> OK, so recursing up...
22:34:17 <Pseudonym> {f :: T2, y :: T1} |= y f :: T4 where T1 = T2 -> T4
22:34:48 <Pseudonym> This is much easier on a piece of paper, BTW.
22:34:50 <Pseudonym> Paper is 2D.
22:35:54 <Pseudonym> In fact, one of the easiest ways to do this on paper is:
22:36:01 <Pseudonym> 1. Write out the expression tree graphically.
22:36:07 <Pseudonym> 2. Assign a type variable to each mode.
22:36:16 <Pseudonym> 3. Collect equality constraints, then unify by hand.
22:36:36 <Pseudonym> Hell, since this is already getting a bit unwieldy, let's do that.
22:36:53 <Pseudonym> (e1 :: A -> B) (e2 :: A) :: B
22:37:16 <Pseudonym> (\x -> e) :: A -> B where x :: A and e :: B
22:39:18 <Pseudonym> So: \(f :: F) -> ((f :: F) ((y :: Y) (f :: F) :: T1 where Y = F -> T1) :: T2 where F = T1 -> T2) :: F -> T2
22:39:29 <Pseudonym> Collecting the constraints you get:
22:39:32 <Pseudonym> Y = F -> T1
22:39:36 <Pseudonym> F = T1 -> T2
22:39:47 <Pseudonym> and the type of the expression as a whole is: F -> T2
22:40:02 <Pseudonym> However, the let expression is let { y = (...) } in y
22:40:11 <Pseudonym> Where the (...) is of type F -> T2
22:40:18 <Pseudonym> sso we also add the constraint: Y = F -> T2
22:40:27 <Pseudonym> In summary:
22:40:29 <Pseudonym> Y = F -> T1
22:40:32 <Pseudonym> F = T1 -> T2
22:40:35 <Pseudonym> Y = F -> T2
22:41:16 <Pseudonym> You solve those and you get: Y = T1 -> (T1 -> T1)
22:41:22 <Pseudonym> Which is indeed the type of the fixpoint combinator.
22:41:27 <Pseudonym> That was too complicated, wasn't it.
22:42:03 <heatsink> not bad; I've read this damas paper from 1982.
22:42:09 <Pseudonym> Right.
22:42:16 <Pseudonym> Have you read the SPJ book?
22:42:24 <Pseudonym> The chapter on HM types is excellent.
22:42:45 <heatsink> dons linked me that earlier.  I read quickly through chs 8 and 9, it could do with a rereading.
22:43:01 <Pseudonym> Really, though, the way that you find out how many free types there are is you collect the constraints, unify them all, and it's however many free types you have left.
22:43:22 <Pseudonym> However, you're never going to have more than there are let- or lambda-bound variables.
22:44:48 <Pseudonym> Because that's the only time you really need to introduce an assumption.
22:45:11 <Pseudonym> BTW, is there a copy of the Damas paper online?
22:45:32 <heatsink> I got it from citeseer
22:46:02 <heatsink> or maybe from portal.acm.org
22:46:17 <Pseudonym> Don't see it on Citeseer.  I'll look on the ACM DL, thanks.
22:46:40 <swalters> Don't forget to check scholar.google.com
22:46:54 <swalters> (or maybe it's scholars)
22:47:12 <Pseudonym> Got it on ACM, thanks.
22:47:24 * Pseudonym prints it out
22:47:56 <Pseudonym> The thing that complicates it is let-polymorphism.
22:48:05 <Pseudonym> And in Haskell, that includes the monomorphism restriction.
22:48:05 <swalters> I love working in the same department as the computer lab.  I can print up all the huge manuals and freebie books.
22:48:17 <heatsink> Is there a way to instroduce the assumptions before a variable is typechecked, though?
22:49:12 <Pseudonym> I think the answer is "yes", but there's also renaming issues.
22:49:24 <Pseudonym> Oh, yeah, I forgot about that.
22:49:42 <Pseudonym> Every time you use something with a generalised type, you need to instantiate it with fresh type variables.
22:49:44 <heatsink> You mean issues like \x -> \x -> x
22:49:52 <Pseudonym> No, I mean like: map head
22:50:01 <Pseudonym> There are no lambda expressions in there.
22:50:08 <Pseudonym> @type map head
22:50:13 <lambdabot> forall a. [[a]] -> [a]
22:50:21 <Pseudonym> But clearly it's got type variables in it.
22:50:24 <heatsink> right
22:50:31 <Pseudonym> In this case:
22:50:33 <Pseudonym> @type map
22:50:34 <lambdabot> forall b a. (a -> b) -> [a] -> [b]
22:50:35 <Pseudonym> @type head
22:50:36 <lambdabot> forall a. [a] -> a
22:50:49 <Pseudonym> So what you need to do is rename the types from map and head.
22:51:25 <heatsink> yes
22:51:31 <Pseudonym> {map :: (TA -> TB) -> [TA] -> [TB], head :: [TA2] -> TA2} |- map head :: ???
22:52:02 <Pseudonym> And then generalise whatever you get in ???.
22:52:29 <heatsink> It is only generalized if it is bound to a name, right?
22:52:39 <Pseudonym> If it is let-bound.
22:52:46 <Pseudonym> (That includes being top-level bound.)
22:52:59 <heatsink> okay.
22:54:19 <heatsink> It's this instantiation that makes me think you need to introduce the assumptions before typechecking.
22:54:34 <heatsink> Because to rename the types, you need to know the free variables...
22:54:54 <heatsink> But you don't know the free variables until typechecking is complete on that let-bound expression...
22:55:21 <Pseudonym> Well that's why you typecheck the "let" part before the "in" part.
22:55:30 <heatsink> What if it's a letrec?
22:55:51 <heatsink> let x = f y; y = f x; in x y or something
22:56:09 <Pseudonym> In that case, you introduce two new type variables, one for x amd one for y.
22:56:24 <Pseudonym> Then you typecheck the right-hand-sides of the equals signs, using those as assumptions.
22:56:46 <Pseudonym> Then whatever you get for the type of the right hand side, unify that with the variable that you used as an assumption.
22:56:51 <Pseudonym> Then generalise them all.
22:57:21 <Pseudonym> In general, when you have mutual recursion, youhave to typecheck the definitions together.
22:57:34 <heatsink> What if the variable appears more than once in the RHS?  Are the types constrained to be the same?
22:57:38 <Pseudonym> Yes.
22:57:44 <heatsink> I see.
22:57:58 <Pseudonym> Strangely, it seems to work anyway.
22:58:20 <Pseudonym> Unless you have higher-rank types.  In which case you need to supply explicit type declarations for x and/or y.
22:58:37 <Pseudonym> I believe there are some technical distinctions which occur sometimes.
22:59:18 <Pseudonym> This is all covered in TaPL, by the way.
22:59:22 <heatsink> TaPL?
22:59:39 <Pseudonym> http://www.cis.upenn.edu/~bcpierce/tapl/
22:59:42 <Pseudonym> Excellent book.
23:00:02 <Pseudonym> All the subtleties are mentioned in there.
23:00:24 <heatsink> ok, thx
23:00:26 <Pseudonym> Your university library almost certainly has a copy.
23:01:21 <ibid> (any particular reason you think that?)
23:01:42 * heatsink reads the table of contents
23:02:25 <Pseudonym> Because almost all of them do.
23:02:29 <Pseudonym> ibid: Yours does not?
23:02:39 <ibid> Pseudonym: it would not have had i not requested a copy
23:03:05 <ibid> Pseudonym: basically, there needs to be a staff member or a grad student who says, this is a good book to have
23:03:05 <Pseudonym> Ah, well.  Self-fulfilling prophecy.
23:03:37 <ibid> Pseudonym: and i seem to be the only one interested in both this subject and knowledgeful of the procedure :)
23:04:26 <ibid> i think that sucks, but ...
23:07:38 <heatsink> I've bookmarked that.  I will be back at uni until next month.
23:10:23 <heatsink> You said earlier that after typechecking a let-bound variable, the free variables are identified.  I think that this is what the damas paper is saying when, after the type-inference algorithm is applied to a let-bound expression, the closure of the resulting type substitution is added to the set of assumptions.
23:11:38 <heatsink> Does that language make sense to you? I understand the meaning of a transitive closure, but this seems to be a different kind of closure.
23:12:59 <weirdcreep> ban me
23:13:00 <weirdcreep> ban me
23:13:00 <weirdcreep> ban me
23:13:01 <weirdcreep> ban me
23:13:03 <weirdcreep> ban me
23:13:06 <weirdcreep> ban me
23:13:07 <weirdcreep> ban me
23:13:09 <weirdcreep> ban me
23:13:11 <weirdcreep> ban me
23:13:13 <weirdcreep> ban me
23:13:15 <weirdcreep> ban me
23:13:17 <weirdcreep> ban meban me
23:13:19 <weirdcreep> ban me
23:13:21 <weirdcreep> ban me
23:13:23 <weirdcreep> ban me
23:13:26 <weirdcreep> ban me
23:13:27 <weirdcreep> ban me
23:13:29 <weirdcreep> ban me
23:13:31 <weirdcreep> ban me
23:13:34 <weirdcreep> ban me
23:13:35 <weirdcreep> ban me
23:13:37 <weirdcreep> ban meban me
23:13:39 <weirdcreep> ban me
23:13:41 <weirdcreep> ban me
23:13:44 <weirdcreep> ban me
23:13:45 <weirdcreep> ban me
23:13:47 <weirdcreep> ban me
23:13:49 <weirdcreep> ban me
23:13:51 <weirdcreep> ban me
23:15:19 <Pseudonym> Yes, that makes sense to me.
23:16:10 --- mode: ChanServ set +o Pseudonym
23:16:20 <Pseudonym> Anyone know who weirdcreep is?
23:16:48 <heatsink> was also in #python, but wasn't talking there.
23:16:58 * Pseudonym nods
23:17:11 <heatsink> I don't know.
23:17:21 <dons> a robot perhaps?
23:19:21 <Korollary> TaPL is dense
23:19:32 <dons> dense in a good way :)
23:19:34 <Pseudonym> I found it very easy to read.
23:19:40 <Pseudonym> Dense, but very readable.
23:19:42 <Korollary> yeah it is easy to read
23:19:49 <Pseudonym> Especially if you skip a couple of the proofs the first time.
23:20:02 <Korollary> I just wanna do the exercises along but it'd take some time.
23:20:35 <Korollary> we need matrix style brain upload
23:22:32 <Korollary> ok I do
23:22:58 <heatsink> Korollary: you need a good firewall too.
23:23:48 <Korollary> heatsink: yes, standard tech jargon of many scifi movies...
23:24:51 <Pseudonym> I think we need to interplex the comm systems to create a phased carrier wave.
23:25:04 <dons> heh
23:25:27 * Korollary crosses the streams
23:25:38 <heatsink> In other words, we need to play party music so that everyone dances in unison.
23:25:50 <Pseudonym> That's a real piece of Treknobabble, apparently.
23:26:32 <Korollary> I read that in the first few episodes of Star Trek the ships in space didn't make sounds. But then they caved in to audience pressure.
23:26:52 <heatsink> One bit of techspeak that comes to mind is... "I'm starting the landing cycle"
23:27:03 <Pseudonym> I bet they automatically aligned themselves so that each one is the right way up compared to all of the others, though.
23:27:15 * heatsink imagines the wheels lowering, raising, lowering, raising...
23:27:19 <Pseudonym> :-)
23:27:33 <Pseudonym> If you get them cycling fast enough, you don't need a heat shield.
23:28:10 * Korollary hears the aliens sync their clocks using satellite tv signals
23:28:16 <heatsink> Pseudonym: the ship alignment is caused by the inertial dampers.  If those go offline the ship starts to tilt.
23:28:37 <Pseudonym> Which inertial frame do they synchronise to, though?
23:28:45 <heatsink> The camera's. Duh.
23:28:46 <Pseudonym> Or do the ships vote on what the right coordinate system is?
23:28:49 <Pseudonym> Ah, of cours.e
23:29:01 <Korollary> exercise the right hand rule on the spot
23:29:01 * heatsink admired the babylon 5 space scenes for being relatively realistic
23:29:21 <Pseudonym> I really like the Galactica camera work.
23:29:28 <Korollary> the new BG ?
23:29:32 <Pseudonym> Yeah.
23:29:38 <Pseudonym> Oh, the old one was shocking, visually speaking.
23:29:43 * heatsink laughed at some of the space scenes from the old one
23:29:43 <Korollary> that show is better done than I expected
23:29:47 <Pseudonym> Even for 1980.
23:29:51 <Pseudonym> Yes.
23:29:57 <heatsink> You have to bank to turn your spacecraft!
23:30:08 <Pseudonym> I love the camera work on the space scenes in the new one.
23:30:22 <Korollary> well, you mean cgi work :)
23:30:32 <Pseudonym> It's all virtual, but it's like a camera at televised motor racing competition.
23:30:42 <Pseudonym> Well, it's a camera.
23:30:47 <Pseudonym> Just because it's not a physical one.
23:30:59 <Pseudonym> It's the director of photography who approves the camera movements.
23:31:01 <Korollary> right, but a real cameraman has real problems and fewer retakes :)
23:31:52 <Korollary> I love the pilot's illuminated helmets. That does nothing but help us see who's flying.
23:31:59 <Pseudonym> Actually, a virtual cameraman has fewer retakes.
23:32:23 <heatsink> Thanks for your help, Pseudonym, I don't think I'd've figured out about let type inference without it.
23:32:32 * heatsink goes to bed
23:32:34 <Pseudonym> Because by the time it comes to actual shooting, all the hard work is done.
23:32:36 <Pseudonym> Night.
23:32:38 <Korollary> wow. I'd've
23:32:38 <Pseudonym> No problem.
23:33:29 <Pseudonym> On a live action shoot, the ration of footage shot to final product is anywhere from 3:1 to 15:1, usually.
23:33:37 <Pseudonym> In animation, the ratio is 1:1.
23:33:55 <Pseudonym> That's because you previz the hell out of it.
23:34:03 <Korollary> in full detail animation. maybe they do faster renders and see if it would look good.
23:34:10 <Pseudonym> Oh, of course.
23:34:13 <Pseudonym> Like, OpenGL fast.
23:34:36 <Korollary> it's raytraced, yes ?
23:34:44 <Pseudonym> Don't know.  Probably not, actually.
23:34:53 <Pseudonym> More likely to be scanline.
23:35:38 <Pseudonym> Raytracing is unnecessarily slow for the most part.
23:36:30 <Korollary> they can get selective about how to render which scene anyway
23:36:40 <Pseudonym> Or even each LAYER.
23:37:01 <Pseudonym> It's common practice to do a beauty pass with one renderer and shadows with another.
23:37:09 <Pseudonym> And then composite them together.
23:37:28 <Korollary> I heard that Spielberg or somebody bought a ton of real estate for another animation studio near san francisco.
23:37:36 <Pseudonym> BTW, some time ago, I did the following image just to prove that Aqsis (the open source renderer I hack on) didn't need raytracing:
23:37:42 <Pseudonym> http://andrew.bromage.org/absolut.jpg
23:38:16 <Pseudonym> After all, the only reason you'd possibly need to use a raytracer is to do a mirrored-thing-over-infinite-chessboard.
23:38:18 <Korollary> That looks nice. Does it have aniso ?
23:38:29 <Pseudonym> Err... what?
23:38:45 <Korollary> err
23:38:49 <Korollary> I meant antialiasing
23:38:53 <Pseudonym> Yes.
23:38:56 <Pseudonym> Of course.
23:39:27 <Pseudonym> By the way, by "antialiasing", you probably mean "decent filtering".
23:39:40 <Pseudonym> But that's another topic. :-)
23:40:04 <Korollary> I dont know what I meant. I may have wanted to ask about anisotropic filtering :)
23:40:08 <Pseudonym> Ah.
23:40:16 <Pseudonym> Well, it does use analytic texture filtering.
23:40:37 <Pseudonym> And analytic environment map filtering, too.
23:41:26 <Korollary> it is weird that I don't remember much about opengl. It's a blur in my curriculum.
23:52:56 <reffie> good morning
23:53:02 <Korollary> greetings
23:57:17 * juhp wonders why there aren't case statements in python?
23:57:25 <juhp> better not to ask, I guess
23:57:29 <dons> hehe
23:57:45 <reffie> i think i'll have to learn python
23:59:07 <lispy> @hoogle when
23:59:08 <lambdabot> Monad.when :: Monad a => (Bool -> (a ()) -> (a ()))
