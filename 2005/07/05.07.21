00:00:41 <ski> and the 'cbv' part of that enforces evaluation in by-value order (i.e. eval arguments to values before substitution into function bodies)
00:01:26 <ski> [[x]] = \k. k x
00:01:45 <ski> [[\x. er]] = \k. k (\x. [[er]])
00:02:17 <ski> [[ef ex]] = \k. [[ef]] (\f. [[ex]] (\x. f x k))
00:02:26 <ski> that's the basic cbv CPS transform
00:02:47 <palomer> ef and ex are terms?
00:02:50 <ski> yes
00:02:56 <palomer> and for the types?
00:02:57 <ski> (and 'er')
00:03:47 <ski> [[t0 -> t1]] = [[t0]] -> forall alpha. ([[t1]] -> alpha) -> alpha
00:04:15 <ski> [[a]] = a   -- for (most) basic types, as well as for tyvars
00:04:35 <palomer> that's the simplest type?
00:04:47 <ski> sorry ?
00:05:30 <ski> (btw, one can fix a particular "result/answer" type, instead of doing 'forall alpha' if one wants)
00:05:40 <palomer> err, you'll be introducing two more implications for every implication
00:05:48 <palomer> result/answer?
00:05:57 <ski> yes, that's look like
00:06:09 <ski> [[t0 -> t1]] = [[t0]] -> ([[t1]] -> R) -> R
00:06:26 <ski> for your choice of fixed answer/result type, R
00:06:35 <palomer> what's a fixed answer/result type?
00:07:15 <ski> it's the return type of the functions similating continuations
00:07:54 <ski> if you think of it as a 'bottom' or 'always false' type/formula, then
00:07:58 <palomer> of the "k"'s?
00:08:13 <palomer> but, it's not inhabited
00:08:39 <ski> t0 -> (t1 -> False) -> False = t0 -> Not (Not t1) ={by double negation elimination}= t0 -> t1    (this in classical logic, i.e.)
00:08:47 <ski> of the "k"'s, yes
00:09:11 <Thu313> meuning
00:09:27 <ski> good morning Thu313
00:09:58 <palomer> ski: do you have any references on this good stuff?
00:10:02 <ski> in some CPS transformations, it can in fact be inhabited  (e.g. if you want to have effectful languages)
00:10:11 <palomer> I tried reading plotkin's paper, found it odd
00:11:18 <ski> palomer : i don't remember all the papers i've read on CPS transformation and related
00:11:20 <ski> but
00:11:32 <palomer> good ones, that explain semantics
00:11:37 <palomer> proves useful properties about types
00:11:43 <ski> the two first references given on http://www.haskell.org/hawiki/CpsTransform are interesting, i think
00:11:51 <palomer> gives the relation between t and [[t]]
00:12:02 <palomer> ski: do they only use lambda calculus?
00:12:17 <ski> 'only' as in what ?
00:12:28 <palomer> plotkin's paper uses his own calculus
00:12:45 <palomer> ski: ie, they don't use scheme, or lambda calculus with some wacky extensions
00:13:27 <Thu313> lambda calculus on steroids?
00:13:29 <ski> they use plain lambda calculus
00:13:44 <palomer> this is crazy cool
00:13:53 <palomer> ski: did you ever hear of "direct style"ification?
00:14:00 <palomer> it's the left inverse of CPSification
00:14:04 <ski> though, i think at least one of those two also considers lambda calculus with some call/cc and shift/reset extensions
00:14:27 <ski> yes, i've heard of it. have not looked much at it yet, though
00:14:41 <palomer> ski: do both papers discuss CBV CPSification?
00:15:00 <ski> mostly cbv
00:15:58 <palomer> hmm hmm, much to do
00:16:12 <ski> they use a CPS transformation that doesn't generate as much extra redices and lambdas and applications
00:17:08 <palomer> but this CPS transformation gives terms which are alpha/beta equivalent to our CPSification?
00:17:53 <palomer> btw, how does the call by name lambda calculus change the type?
00:17:54 <ski> yes
00:18:25 <ski> [[t0 -> t1]] = (([[t0]] -> R) -> R) -> ([[t1]] -> R) -> R
00:18:40 <palomer> oh, it's even uglier
00:19:04 <ski> btw, i think the transformation on types is easier to get, if you define two separate transformations
00:19:15 <ski> in that case, cbv for function types becomes
00:19:29 <palomer> is there a transformation such that [[t0->t1]] = (t0->t1) -> R -> R?
00:19:31 <ski> [[t0 -> t1]]_v = [[t0]]_v -> [[t1]]_e
00:19:36 <ski> while for cbn you have
00:19:40 <ski> [[t0 -> t1]]_v = [[t0]]_e -> [[t1]]_e
00:20:02 <palomer> ski: my calculus doesn't distinguish values and expressions!
00:20:21 <ski> palomer : not that i know of, but that looks very weird (you flip polarity of t0 and t1 !)
00:20:33 <ski> palomer : how do you know ? :)
00:20:41 <palomer> how do I know what?
00:20:53 <ski> that it doesn't distinguish values and expressions ?
00:21:01 <palomer> my goal is, given a term of type A -> R -> R, I want to create  a term of type A
00:21:15 <palomer> ski: there's no concept of values and expressions
00:21:31 <ski> are you sure you don't mean ".. of type (A -> R) -> R, I want to create  a term of type A" ?
00:21:36 <palomer> oh, right
00:21:41 <palomer> of type (A->R)->R
00:22:08 <ski> you want to do direct-style transformation ?
00:22:43 <palomer> let me correct myself
00:22:56 <palomer> is there a transformation such that [[t0->t1]] = ((t0->t1) -> R) -> R?
00:23:07 <palomer> ski: DS doesn't do that, since its the left inverse of CPS
00:23:19 <Pseudonym> Gotta go.
00:23:22 <Pseudonym> Nytol!
00:23:28 <palomer> and [[A]] != (A->R)->R in general
00:23:41 <ski> depending on what A is, yes
00:24:02 <palomer> right,
00:24:29 <palomer> so [[(A->R)->R]]_DS could not possibly be A in general
00:24:48 <ski> why do you want such a transform ?
00:25:29 <ski> i think (at least in some cases) you can have "local/partial" unCPS transform, so you get back something of type A
00:25:34 <palomer> I could apply the correctness and adequacy theorems to classical logic
00:25:52 <palomer> DS is unCPS
00:25:56 <ski> indeed
00:26:17 <palomer> which would be a major breakthrough in realizibility theory
00:26:25 <palomer> in fact, ill include your name in the paper
00:26:34 * ski chuckles
00:26:44 <palomer> I'm serious!
00:26:56 <ski> i don't doubt that
00:27:16 <palomer> hrm
00:27:17 * palomer thinks
00:27:34 <palomer> help me find a term of type A -> R -> R such that there is no term of type A
00:27:46 <ski> ?
00:27:58 <ski> (do you mean "(A -> R) -> R", again ?)
00:28:01 <palomer> yeah
00:28:07 <palomer> does such a term exist?
00:28:46 <ski> R is an uninhabited type here, yes ?
00:28:57 <palomer> yes
00:29:44 <ski> hm
00:30:14 <ski> if A and R are both empty types, then (A -> R) is inhabited
00:31:21 <ski> then, to make a term of type (A -> R) -> R, is making a function from an inhabited type, to an uninhabited type
00:31:31 <ski> so i think it's impossible
00:32:02 <ski> if your logic is sound, you shouldn't be able to prove false from true
00:32:08 <palomer> but, erm, we need a term of type (A->R)->R such that there is no term of type A
00:32:46 <ski> is such a term exists, it must be (equvalent) to a lambda term, yes ?
00:32:49 <ski> \f. ...
00:33:03 <palomer> must it?
00:33:14 <ski> hm
00:33:26 <palomer> every computable mapping can be represented as a lambda term?
00:33:41 <palomer> this would make my life _much_ easier
00:33:42 <ski> if you have a fixed point combinator, then answer must be no, of course
00:34:05 <ski> but then the typesystem as a logic, is an inconsistent logic
00:34:14 <palomer> ski: eh? why?
00:34:24 <ski> fix : forall a. (a -> a) -> a
00:34:35 <ski> or, of you just want the cbv variant
00:34:49 <ski> fix : forall a. forall b. ((a -> b) -> a -> b) -> a -> b
00:34:55 <ski> s/of/if/
00:35:18 <palomer> is it provable classically?
00:35:28 <ski> fix ?
00:35:30 <palomer> yeah
00:35:33 <ski> no
00:35:48 <ski> fix is often introduced to allow the use of general recursion
00:35:48 <palomer> and if you add it as an axiom, is the type system still sound?
00:36:01 <ski> it is not sound (as a logic)
00:36:09 <ski> it can still be sound as a type system
00:36:25 <palomer> I remember my prof talking about how fix is specifies some axiom in set theory
00:36:36 <ski> (i.e. no well-typed term will "go wrong" when evaluating it)
00:36:49 <ski> i doubt that
00:37:06 <ski> having fix is more or less the same as allowing circular reasoning
00:37:08 <palomer> anyways, you were about to show that if fix is typale then there is a computable lambda mapping which is not a lambda term(I don't see the relation)
00:37:16 <ski> if A, then A,  therefore A
00:37:24 <palomer> ski: oh, that's bad
00:37:41 <palomer> s/typale/typable
00:38:08 <ski> if you introduce fix as a primitive/axiom
00:38:25 <ski> you usually introduce evaluation/reduction axioms like
00:38:35 <ski> fix t = t (fix t)
00:38:39 <ski> or, in the cbv case
00:38:57 <ski> fix t0 t1 = t0 (fix t0) t1
00:39:10 <ski> so, then we can write this term
00:39:24 <ski> fix (\x. x) : forall A. A
00:39:43 <ski> and, what happens if we try to reduce that term ?
00:40:02 <ski> fix (\x. x) = (\x. x) (fix (\x. x)) = fix (\x. x) = ...
00:40:10 <ski> it has no normal form
00:40:19 <ski> hm
00:40:27 <Spark> fix would probably get you infinite sets
00:40:44 <ski> Spark : hm, how you mean ?
00:40:59 <ski> palomer : was this what you wanted to see ?
00:41:01 <Spark> because you can say the infinite set of 1s if you had a U operator
00:41:07 <Spark> that doesnt make sense
00:41:10 <Spark> the set of naturals :)
00:41:24 <ski> U ?
00:41:27 <palomer> the set of naturals can be had in second order logic
00:41:35 <palomer> quite easily too
00:41:42 <palomer> any inductive infinite set can be had
00:41:50 <Spark> thats what fix is though isnt it
00:42:09 <ski> Spark : the U i have seen is \x. x x
00:42:15 <Spark> or is it that fix allows you to make recursive statements that dont have a base case
00:42:30 <palomer> Spark: you mean coinduction?
00:42:30 <Spark> ski: i mean like set union
00:42:30 <ski> Spark : yes
00:42:38 <palomer> greatest fix point operator does that
00:42:50 <Spark> we had this exam question about typing an infinite list, but i cant remember it
00:42:51 <ski> Spark : aha
00:43:29 <ski> coinduction is related to lazy (cbn anyway) evaluation
00:44:06 <palomer> ski: you're getting sidetracked!
00:44:14 <ski> Spark : i'm not sure what you meant by "infinite set of 1s", anyway ..
00:44:19 <ski> palomer : hehe
00:44:37 <Spark> ski: i only just got up
00:44:59 <Spark> and in such a state the infinite set of ones makes a lot of sense :)
00:46:12 <ski> (Spark : surely a set of infinitely many 1's (and nothing more) is just a singleton set of 1, because set union is an involution (as opposed to multiset/bag combination ..))
00:46:25 <ski> hehe
00:46:40 <ski> palomer : what were we discussion, now ?
00:47:04 <ski> you said
00:47:11 <ski> <palomer> anyways, you were about to show that if fix is typale then there is a computable lambda mapping which is not a lambda term(I don't see the relation)
00:47:26 <palomer> if phi: Lambda -> Lambda and phi is computable then phi x = t x for some t in Lambda (up to alpha/beta equivalence, throw in eta if you want)
00:47:34 <palomer> you were about to show this false
00:47:56 <ski> i was ?
00:48:13 <palomer> <ski> if you have a fixed point combinator, then answer must be no, of course
00:48:30 <ski> i guess that depends on whether you define 'fix (\x. x)' as computable, or not
00:48:46 <palomer> oh, right, want me to define computable?
00:49:28 <ski> i wanted to state, that with fix in the lambda-calc, we can have terms that has no equivalent term beginning with a top lambda
00:49:59 <ski> of course, if you add fix, you can define terms that correspond to partial functions
00:50:07 <palomer> the set of lambda terms is defined inductively, so you create a computable bijection between them and the finite sets of 0 and 1's, call this bijection P, with computable inverse P^-1. the set of computable functions on Lambda is P^-1 f P where f is the set of turing computable functions
00:50:21 <palomer> finite lists of 0 and 1's
00:51:05 <palomer> oh, here I mean total functions
00:51:16 <palomer> phi is total
00:51:24 <ski> and with fix you can define partial functions
00:51:28 <ski> all clear ?
00:51:31 <palomer> righto
00:52:26 <palomer> anyways, I'm pretty sure it's false
00:52:40 <palomer> remember one of those theorems, when you started learning lambda calculus
00:52:41 <ski> sorry, what is false ?
00:52:45 <palomer> my statement
00:52:55 <palomer> if phi: Lambda -> Lambda and phi is computable(and total) then phi x = t x for some t in Lambda (up to alpha/beta equivalence, throw in eta if you want)
00:53:30 <palomer> "there is no lambda term such that  t something = something else"
00:53:34 <ski> and Lambda here is the inductively defined lambda terms ?
00:53:42 <palomer> ski: righto
00:54:00 <palomer> quotiented by alpha/beta/eta reduction
00:54:03 <palomer> if you wish
00:54:08 <ski> mm
00:54:43 <ski> hm, will ackerman do ?
00:55:04 <ski> iirc ackerman can't be defined with primitive recursion, but is total
00:55:28 <ski> hm
00:56:34 <ski> (though, i seem to recall something about ackermann being definable by some sort of structural recursion .. maybe dependent one ?)
00:57:47 <kosmikus> @seen dcoutts
00:57:48 <lambdabot> dcoutts is in #haskell. Last spoke 19 hours, 6 minutes and 58
00:57:48 <lambdabot> seconds ago.
00:57:57 <palomer> ski: I don't see the relation with my problem
00:59:01 <ski> i was thinking if one could prove that you can't define ackermann in your lambda lang ..
00:59:33 <ski> so, with ackermann being computable and total, you would have a counter-example, no ?
00:59:49 <palomer> ackerman is definable in pure lambda calculus
01:00:01 <ski> in typed pure lambda calculus ?
01:00:08 <palomer> nonono, pure lambda calculus
01:00:25 <ski> but you use a typed variant here, yes ?
01:00:28 <palomer> ackerman is definable in typed lambda calculus with sum and product types
01:00:35 <palomer> I don't think it matters
01:00:48 <palomer> we want a phi, total, such that phi isn't expressible in our lambda calculus
01:01:01 <palomer> ackerman is total and expressible
01:01:06 <ski> you need some kind of recursion ..
01:01:10 <palomer> (notice, I never mentioned typable)
01:01:15 <ski> what kind do you have ?
01:01:23 <palomer> I have LAMBDA!
01:01:24 <ski> hm
01:02:00 <ski> earlier you were speaking of CPS transforming types, so you were (at least then) thinking of a typed lang, no ?
01:02:43 <palomer> ski: yes
01:02:52 <ski> but not now ?
01:02:56 <palomer> nope
01:02:58 <ski> ok
01:03:15 <palomer> I just want a computable function from A -> R -> R to A
01:03:21 <palomer> that's my goal
01:03:22 <ski> (A -> R) -> R
01:03:30 <palomer> right
01:03:40 <palomer> anyways, I found a counter example
01:04:03 <ski> if you have implicit continuations, you can do stuff like that
01:04:04 <palomer> define phi(t (a b)) = b forall t and a
01:04:11 <palomer> and b
01:04:44 <ski> is that phi well-defined ?
01:04:51 <palomer> very good question
01:05:10 <palomer> and the answer is no:(
01:05:16 <palomer> good try though
01:05:35 <ski> hehe
01:06:10 <palomer> anyways, sticking to my calculus, can you find a type A such that  (A->R) -> R  is inhabitated but A isn't?
01:07:46 <ski> val foo : (('a -> void) -> void) -> 'a;   fun foo f = SMLofNj.Cont.callcc (fn k => ignore (f (fn a => SMLofNJ.Cont.throw k a)));
01:08:08 <palomer> SMLofNj.Cont.callcc certainly comes out of my calculus
01:08:32 <ski> i think the answer to that question is no, if the typesystem as logic is consistent
01:09:09 <ski> so you have continuations, then ?
01:09:14 <palomer> nope
01:09:35 <ski> what do you mean by "SMLofNj.Cont.callcc certainly comes out of my calculus", then ?
01:09:50 <ski> that it's related ?
01:09:51 <palomer> I don't have cc in my calculus
01:09:58 <ski> (which it probaly is)
01:09:59 <palomer> i'm using pure lambda calculus
01:10:26 <ski> right
01:10:44 <palomer> and besides, void is inhabitated
01:10:50 <ski> just plain   E ::= x  |  \x. E  |  E E   ?
01:10:52 <ski> it's not
01:10:55 <palomer> ski: yup
01:11:06 <ski> datatype void = VOID of void;
01:11:17 <palomer> yeah, that's inhabitated by one element
01:11:19 <palomer> VOID
01:11:19 <ski> least fixed-point of that is empty
01:11:35 <palomer> no way!
01:11:54 <palomer> unless we're defining our lfb differently
01:12:08 <ski> in haskell, a corresponding declaration would declare an inhabited type
01:12:12 <ski> lfb ?
01:12:18 <palomer> lfp
01:12:21 <palomer> least fixed point
01:12:23 <ski> hm
01:13:15 <palomer> take the predicate transformer Kx |-> forall^1.X (X(void) -> Xx)
01:13:28 <palomer> (notice it's constant)
01:13:29 <ski> a type satisying that declaration is basically a type T satisfying the recursive equation T = T, and surely the empty type satisfies that equation ?
01:13:31 <palomer> all fixed points are equal
01:13:41 <ski> and surely the empty type is the smallest of all types ?
01:14:09 <palomer> it also satisfies T = VOID
01:14:18 <palomer> which the empty type does not satisfy
01:14:26 <ski> VOID is a data-constructor, there
01:14:33 <ski> VOID : void -> void
01:14:46 <palomer> isn't it VOID : unit -> void?
01:14:50 <ski> no
01:14:58 <ski> datatype void = VOID of unit;
01:14:58 <palomer> oh, woops, getting late
01:15:01 <palomer> yeah, that type is empty
01:15:01 <ski> would give you that
01:15:20 <palomer> I didn't see your "of void"
01:15:26 <ski> heh
01:15:57 <palomer> so this val foo...could take any term of type A -> R -> R and give me back a  term of type A?
01:16:13 <ski> yes
01:16:27 <ski> but i'm not sure it will always terminate, hm ..
01:16:46 <palomer> this is important
01:17:16 <ski> but, surely, if you apply foo to a term of type (('a -> void) -> void) you get a term (namely a term of application top form) of type 'a
01:17:30 <palomer> I have my doubts...
01:17:36 <ski> but, this uses continuation effects
01:17:51 <ski> about what ?
01:17:56 <palomer> that it terminates
01:18:33 <ski> i guess that depends on how on defines 'terminate'
01:18:33 <palomer> and if it does, it totally changes how I interpret forall X ((A->X)-
01:18:43 <palomer> .forall X ((A->X)->X)
01:19:01 <palomer> err
01:19:15 <palomer> (forall X ((A->X)->X) -> A)
01:20:02 <ski> forall scopes over top implication antecedent, yes ?
01:20:08 <palomer> right
01:20:13 <palomer> call:
01:20:48 <palomer> |A->B| = |A|->|B|
01:20:54 <palomer> |A->B| = |A|=>|B|
01:21:31 <palomer> oh my
01:21:35 <palomer> getting too late
01:22:04 <palomer> anyways, I don't see how this fits in my assumption that A->B types the set of functions that send elements of A into B
01:22:42 <ski> m
01:23:14 <Speck> the difference between a bag and a list is that a bad is symmetric. what does "symmetric" mean (layman's terms appreciated :-D)
01:23:35 <Speck> *bag is symmetric
01:23:40 <ski> :)
01:23:46 <palomer> Speck: I don't like that use of the word symmetric
01:23:52 <Speck> I'm taking it from wadler
01:24:29 <ski> palomer : probably, having continuations in the language, will give not functions/morphisms in category Set, but some other (interesting) category  (at least if the continuations can be nonlinear)
01:25:09 <palomer> oh my, I want to explain realizability theory right now
01:25:13 <palomer> but im going to collapse
01:25:25 <palomer> you here often?
01:25:26 <ski> Spark : he means that for lists you generally not have  listA ++ listB = listB ++ listA,  but for bags, bag combination is symmetric in that way
01:25:33 <ski> palomer : yes
01:26:06 <Speck> aah, I see. thanks ski (and darn that spark! ruining my autocompleteness!)
01:26:15 <palomer> so we're positive that there's a function from (A->R)->R to A,right?
01:26:31 <ski> Speck : oh, just noticed that :(
01:26:47 <ski> in a language with continuations, yes
01:26:51 <palomer> gah!
01:26:56 <ski> :)
01:27:02 <palomer> I mean a computable function
01:27:13 <palomer> in the language of set theory
01:27:32 <ski> i'm not totally sure, but i would guess not
01:27:54 <palomer> ok, I mean to say:
01:28:09 <ski> hm, do we have an iso between  R * R and R ?
01:28:10 <palomer> say you have two sets of lambda terms
01:28:35 <palomer> when I say computable function between them, I treat them as sets!
01:28:37 <palomer> nothing more
01:28:49 <palomer> and the function is the good old function we learned about when we were 12
01:29:08 <ski> just a computable function between inductively defined trees, of a certain kind
01:29:23 <palomer> like, a function between {x,\x.x} and {y,\z.p} is x|->y and \x.x |-> \z.p
01:29:29 <palomer> ski: yes
01:29:35 <palomer> is the answer still no?
01:29:44 <ski> i don't know
01:29:50 <palomer> because, well ,your val foo seems to fit the bill
01:30:00 <ski> but it uses continuations
01:30:10 <palomer> but it returns terms!
01:30:17 <ski> also, that one doesn't operate on terms
01:30:20 <palomer> without continuations
01:30:33 <palomer> could we make it operate on terms
01:30:49 <palomer> doesn't it return pure lambda terms?
01:31:31 <ski> it's a function inside a programming language, not a function operating on terms in a programming language, from the outside, so to speak
01:31:48 <palomer> oh my
01:31:51 <palomer> so we don't know
01:32:10 <Thu313> would there be a serious gain from strength reduction? im not convinced
01:32:17 <palomer> hrm
01:32:19 <palomer> gotta go
01:32:25 <palomer> ski: think about this problem, it's big:O!
01:32:26 <palomer> cya guys
01:32:30 <ski> bye
01:32:43 <ski> Thu313 : what is strength reduction ?
01:34:43 <jyp> @google strength reduction
01:34:45 <lambdabot> http://foldoc.doc.ic.ac.uk/foldoc/foldoc.cgi?strength+reduction
01:35:18 <jyp> hail google
01:37:25 <Thu313> transforming a = i*b to a = a + b where you initialize a to i*b
01:37:36 <Thu313> so weakening the strength of the operator
01:37:57 <Thu313> with the idea that multiplication is more expensive
01:39:20 <vegai> http://entertainment.msn.com/tv/article.aspx?news=196936
01:41:01 <ski> Thu313 : i think it would be beneficial in some cases at least .. computing something incrementally instead of from the start each time
01:42:58 <pejo> Thu, Allen and Cocke discuss a seriees of applications in an article from 81, examples are replacing exponentiation by multipilcation, division and modulo by subtraction and continuous differentiable functions by quadratic interpolations.
01:43:22 <Thu313> what do you mean from the start....because internally the multiplication will be layed out as additions from the begin every time?
01:44:04 <pejo> Thu, and Muchnick says "Nevertheless, we restricut ourselves to discussing only simple strength reductions, because they are by far the most frequently occuring ones and, as a result, the ones that typically provide the greatest benefit.".
01:45:17 <pejo> Thu, 0, 3, 6, 9, 12 can either be written as s_i = 3*i for i = 0, 1, .. or as s_{i+1} = s_i + 3 with s_0 = 0. No multiplication in the last one.
01:46:13 <Thu313> as the code coming out of my tool will pass the compiler, im not going to do strength reduction i think...in THAT situation its not beneficial because i think...let the compiler sort it out
01:46:31 <Thu313> in the eventual compiler i think indeed that it can be beneficial because a lot of stuff boils down to addition
01:48:11 <pejo> Thu, in that case it's just someone else doing the strength reduction.
01:49:17 <Thu313> yeah, im just interested in those induction variables, because they can prevent parallelism. Totally different goal
01:49:41 <Thu313> if you have some statement i = i + 1, the right i refers to the i written in the previous iteration
01:49:59 <Thu313> i.e. preventing parallel execution of each iteration
01:50:17 <Speck> Man. Type inference is so awesome. (You may now return to your regularly scheduled programming) :-P
01:50:19 <Thu313> (if the i=i+1 occurs in some loop we wish to parallelize each iteration of)
01:51:18 <Thu313> ofcourse, i = i + 1 can be statically calculated (as for a = b*i + c where b and c are loop-invariant and i is the loop index)
01:53:28 <pejo> Thu, I agree, i = i + 1 will prevent paralellization with a naive compiler. I bet someone has thought about it though. (No references handy, sorry).
01:54:59 <Thu313> ow sure, but since im basically building a tool that will spit out parallel code, its my tool that has to do something about it :D
02:11:47 <Speck> yikes
02:11:53 <Speck> a big spider just crawled up my leg
02:12:07 <Speck> thought it was a cockroach :-\
02:12:35 <ski> you let cockroaches happily use your leg as an autobahn ?
02:12:40 <hyrax42> eww
02:12:58 <hyrax42> (cockroaches, anyway... not a huge fan of spiders, though, either)
02:13:13 <Speck> well I use my laptop in bed
02:13:34 <Speck> so no bugs are really welcome
02:13:48 <hyrax42> I thought you were about to use that as justification of allowing cockroaches
02:13:56 <Speck> hehe
02:14:11 <Speck> no I felt it on my leg and when I pushed away the covers I saw this black thing scuttling
02:14:17 <Speck> looked like a cockroach
02:14:24 <Speck> but it was just a cockroach-sized spider
02:14:25 <hyrax42> woke up with a cockroach in bed once... god I hate those things
02:14:41 <hyrax42> well not in bed
02:14:43 <hyrax42> near bed
02:14:45 <hyrax42> or on frame
02:14:46 <hyrax42> or something
02:14:50 <hyrax42> ugh
02:14:51 <Speck> yucky
02:14:57 <Speck> I've gotten used to cockroaches
02:15:00 <Speck> there are so many here
02:15:04 <Speck> and rats too
02:15:06 <hyrax42> asl?
02:15:08 <hyrax42> :o
02:15:11 <Speck> but thankfully not inside :-/
02:15:11 <hyrax42> well just l
02:15:17 <Thu313> i woke up once at the very moment a big spider walked over my face....
02:15:19 <Lemmih> Where do you guys live?
02:15:23 <Speck> baltimore, maryland
02:15:35 <hyrax42> Montreal, Quebec
02:15:42 <hyrax42> but home previously was in the middle east
02:15:58 <hyrax42> (suffering insomnia right now... guh)
02:16:06 * Lemmih can't remember ever seeing a cockroach in Denmark.
02:16:25 <hyrax42> prolly don't exist
02:16:28 <Speck> I never lived with cockroaches until I went to taiwan
02:16:31 <hyrax42> filthy scum of insects
02:16:41 <Speck> but they're bigger in baltimore
02:17:27 <Speck> oh man, last summer we got cicadas. every 17 years, there's this swarm. it's the largest swarm in recorded history. hundreds of thousands of them.
02:17:44 <Speck> From new york to tennessee
02:18:10 <Speck> probably more like thousands of millions over that large an area, but hundreds of thousands in baltimore at least
02:18:37 <Speck> they crawl up from the ground, molt, and fly around making this horrible sound
02:18:59 <Speck> walking around after the molting made this crunch-crunch noise
02:20:50 <hyrax42> icky
02:21:03 <Speck> it was gross, but also kind of amazing
02:22:19 <hyrax42> I need instant insomnia cure
02:22:21 <hyrax42> :(
02:22:30 <Speck> turn of the lights and the computer and close your eyes
02:22:40 <Speck> that has to be the first step
02:22:42 <hyrax42> I was doing that the last 2 hours since I woke up for no bloody reason
02:22:54 <hyrax42> got a bit boring
02:23:20 <Speck> I hear warm milk is good, but it sounds kind of gross to me
02:23:50 <Speck> a cigarette puts me to bed, but most people don't smoke nowadays
02:24:02 <hyrax42> I don't smoke
02:24:09 <hyrax42> but defintely doesn't seem like most around here
02:26:08 <hyrax42> oh well
02:26:14 <hyrax42> I suppose I'll try this sleep thing again
02:26:19 <Speck> hmm... I'm trying to find a good picture of the cicada swarm. This particular swarm is called Brood X.
02:26:23 <Speck> good luck!
02:26:29 <hyrax42> I was so pleased with myself for going ot bed by 12 tonight
02:26:36 <hyrax42> since I'm all arse about face sleepwise
02:26:41 <hyrax42> waking up at 4 as often as not
02:27:01 <hyrax42> *pm
02:27:25 <hyrax42> Starcraft: Brood Wars
02:27:27 <hyrax42> all I can think of
02:27:30 <hyrax42> to say
02:27:44 <hyrax42> well
02:27:49 <hyrax42> g'morning
02:27:49 <Speck> unless you have clinical insomnia, a rigorous sleep schedule is the best thing you can do for yourself
02:27:51 <hyrax42> I suppose
02:28:05 <hyrax42> what means clinical
02:28:06 <hyrax42> insomnia
02:28:19 <Speck> you need a prescription
02:28:26 <Speck> for medication
02:28:30 <hyrax42> well not afaik
02:28:39 <hyrax42> but it does take me never less than 30 mins to fall asleep
02:28:54 <hyrax42> generally an hour or more
02:29:03 <hyrax42> dunno if that means anything
02:29:04 <Speck> do you fall asleep around the same time every night?
02:29:07 <hyrax42> no
02:29:18 <hyrax42> hence waking up at 4pm :/
02:29:31 <Speck> well, if it's worth it to you, try doing that. You'll fall asleep faster and your sleep will be more effective so you'll feel more rested
02:29:44 <Speck> (eventually)
02:29:45 <hyrax42> try doing what precisely
02:29:52 <hyrax42> falling asleep same time?
02:29:54 <Speck> going to bed at the same time every night
02:30:13 <hyrax42> well
02:30:22 <hyrax42> I'm off to have a second attempt
02:30:27 <Speck> ok good luck
02:30:30 <hyrax42> morning :)
02:30:35 <Speck> :)
03:24:40 <bourbaki> moin
03:48:55 <Speck> hmmm....
03:54:12 <dcoutts> kosmikus, pong!
04:12:50 <frederik> why does Data.Map always put the Map data structure as the last argument of functions? it seems more natural to have it as the first argument
04:46:23 <dcoutts> does anyone know where I can find out about the changes in the upcomming cabal 1.2 release?
04:47:39 <JaffaCake> dcoutts_: there's a release candidate, with a ChangeLog file
04:49:21 <dcoutts> oh great, I'll take a look
04:52:40 <dcoutts> I wonder if it's too late to get a minor feature in :-)
04:53:55 <dcoutts> we'd really like a variant on the ./setup register --gen-script feature that just gives us the package config file(s) since the script cabal produces makes too many assumptions about our packaging model that run out not to be true
04:54:09 <dcoutts> run/turn
04:56:46 <dcoutts> " ./setup register --gen-pkg-conf " or something similar
05:02:07 <ski> frederik : maybe often the map argument varies more often than the other argument(s) ?
05:09:33 <mauke> is there a way to make all instances of a class instances of another class?
05:19:11 <pejo> JaffaCake, on the ghcperformance page in the wiki there's talk about Laszlo Nemeth's research. Any chance a link could be provided for us outsiders?
05:19:49 <JaffaCake> he has a paper, I can't remember where it was submitted... hang on I'll see if i can find it
05:21:04 <JaffaCake> http://www.tcs.informatik.uni-muenchen.de/~hwloidl/TFP04/Abstracts/17.html
05:21:48 <JaffaCake> the actual paper might not be online, you could ask Laszlo
05:27:47 <Thu18118> hey ion wm is from tuomov?
05:28:58 <tuomov> yep
05:29:02 <Thu18118> cool :D
05:29:08 <Thu18118> is it fedora friendly?
05:29:26 <Thu18118> and which version would you suggest...i see ion1,2 and 3
05:29:41 <CosmicRay> goooooooooddd mooooorning   #haskell!
05:29:41 <dons> ion2 or ion3
05:29:47 <tuomov> ion3
05:29:50 <dons> oh, tuomov is here :)
05:30:10 <tuomov> I don't know about "fedora friendliness". I'm not aware of any rpms at the least
05:30:19 <Thu18118> ah, il just try it
05:30:30 <tuomov> almost everyone who uses Ion uses debian, gentoo or *bsd :)
05:30:40 <CosmicRay> what's ion?
05:30:48 <Thu18118> im sick and tired of memhogging stuff. someone on #slayradio recommended ion :)
05:30:51 <tuomov> http://iki.fi/tuomov/ion/
05:30:53 <Oeje1> What's tuomov?
05:31:10 <dons> heh
05:31:45 <frederik> ski: do you really think that's true?
05:32:20 <frederik> ski: i mean, do you think it happens more often than the reverse?
05:33:42 <pejo> JaffaCake, ah, thanks. Added the link on the wiki.
05:33:54 <JaffaCake> cheers
05:34:28 <jyp> tuomov: my dream come true :)
05:34:39 <jyp> ... a tiling tabbed window manager
05:34:46 * shapr hugs ion3
05:35:40 <Thu18118> tuomov, psiborg from #slayradio (C64 remix radio station) says hi, if you even remember him.
05:35:50 <Thu18118> that last sentence is by him too :P
05:36:49 <tuomov> yeah I remember him from #ion
05:38:55 <dons> hmm. sometihng happening in london
05:39:05 <Thu18118> again?
05:40:12 <tuomov> seems so
05:40:25 <Thu18118> yeah im reading it
05:40:29 <Thu18118> a nailbomb
05:40:43 <Thu18118> and a bomb near a bus
05:41:00 <Thu18118> gunshots at the trainstation pff
05:44:23 <grimace_> wait and see, I'm reading that it's just detonators that have gone off
05:44:58 <frederik> where are you reading about a nailbomb?
05:45:27 <dons> @timein london
05:45:30 <Thu18118> on a dutch site
05:45:33 * grimace_ is reading http://blogs.guardian.co.uk
05:45:51 <Thu18118> "..Eén spijkerbom is ontploft op één van de stations, meldt Reuters.."
05:46:07 <Thu18118> Reuters reported that one nailbomb exploded on one of the stations
05:46:20 <CosmicRay> wow.  darcs and ghc for Windows Just Work.
05:46:24 <CosmicRay> pretty impressive.
05:46:29 <void-> Anyone using ghc in 64bit ubuntu?
05:46:42 <CosmicRay> 64-bit debian count?
05:46:50 <void-> probably
05:47:00 <CosmicRay> then, I am ;-)
05:47:24 <grimace_> the nailbomb story comes from Fox
05:47:38 <grimace_> so thoroughly reliable ;)
05:47:40 <Thu18118> Fox, lol sounds bogus in that case
05:47:55 <jyp> dons: have you tried the emacs binding ?
05:48:16 <dons> jyp, played around with it a little, and  its in the repo now
05:48:23 <dons> looks good
05:48:33 <jyp> good :)
05:48:46 <void-> CosmicRay; "panic! (the `impossible' happened), loadObj: failed" when trying to build the SDL bindings... /usr/lib/ghc-6.2.2/HSbase.o: unknown architecture
05:48:56 <tuomov> there are some other reports of shooting near the nailbomb scene
05:49:04 <jyp> Have you typed meta-stuff in there ?
05:49:04 <dons> void-: no ghci
05:49:18 <void-> I'm sure I installed it
05:49:21 <dons> nah, I don't know enough emacs :)
05:49:29 <dons> void-, ghci doesn't work on this arch
05:49:29 <CosmicRay> void-: hmm, is there no ghc6.4 in ubuntu?
05:49:48 <dons> if you're using amd64, then you need the latest head of ghc, to get a working ghci, iirc
05:49:58 <CosmicRay> it sounds like he's just using ghc though
05:50:19 <dons> but wasn't ghci support only just added?
05:50:26 <jyp> dons: because the keys strokes seem to arrive at the wrong time
05:50:28 <void-> ah, ok... no, no 6.4 in ubuntu yet
05:50:54 <dons> jyp, ah. hmm. haven't tried that -- don't know enough emacs, but i saw your thread last night
05:51:04 <void-> and I can't build from source, because 6.2 does not work =)
05:51:30 <jyp> ah, good... if you have any idea what's happenning i'm interested
05:51:48 <dons> i'll have a look tomorrow (late here now)
05:52:33 <jyp> thanks
05:52:48 <dons> feel free to send me examples to try, btw.
05:53:53 <CosmicRay> void-: how about the debian packages?
05:54:16 <CosmicRay> void-: amd64.debian.net
05:54:22 <void-> CosmicRay hmmm... I can try
05:54:23 <jyp> dons: type any unbound key (M-c) for example; then another regular key
05:54:57 <jyp> and see that the error message is displayed only when you type this last key
05:55:33 <dons> hmm. ok. i'll look into it
05:55:49 <dons> gotta go now, night!
05:55:55 <jyp> night
05:58:04 * shapr throws arrows
05:59:12 * CosmicRay dodges expertly
05:59:57 <shapr> Hey CosmicRay, I had some question I wanted to ask you, I think.. I wonder what it was.
06:00:24 <CosmicRay> something about tmr?
06:00:31 <CosmicRay> if so, you already asked ;-)
06:00:41 <shapr> I don't know what it was.
06:00:52 <shapr> Could have been about tmr.
06:11:00 <void-> CosmicRay: no, still "ghc-6.4: /usr/lib/ghc-6.4/HSbase.o: unknown architecture" with the debian packages
06:11:21 <CosmicRay> and you're sure you're using ghc and not ghci?
06:11:36 <CosmicRay> try running  file /usr/lib/ghc-6.4/HSbase.o for me
06:11:55 <void->  /usr/lib/ghc-6.4/HSbase.o: ELF 64-bit LSB relocatable, AMD x86-64, version 1 (SYSV), not stripped
06:12:21 <void-> so ghci is non working for amd64?
06:12:27 <CosmicRay> correct
06:12:35 <CosmicRay> well that's the correct platform
06:12:38 <CosmicRay> weird
06:12:51 <CosmicRay> <dons> void-, ghci doesn't work on this arch
06:13:03 <void-> ah ok... I am trying to build a lib, and the installcripts probably uses ghci
06:13:06 <CosmicRay> it may be there in ghc cvs
06:13:09 <CosmicRay> hmm.
06:13:17 <CosmicRay> could they be modified to use ghc or hugs?
06:13:27 <Lemmih> void-: Compile the Setup.lhs script and run it as a binary.
06:13:58 <void-> ok, thanks for the help
06:14:37 <void-> it works
06:31:58 <Thu18118> up and running ion3 baby
06:33:08 <Lemmih> Very creative handles you're using.
06:34:04 <Thu18118> que?
06:35:17 <CosmicRay> is there a Windows equivolent of getProcessID?
06:37:00 <Thu18118> do those windows equivalents not always bare impossible complex and useless names?
06:38:06 <CosmicRay> heh
06:38:27 <Thu18118> or did you not meant those windows api calls
06:39:12 <void-> there should be a GetProcessIdEx (or similar)
06:40:30 <Enveigler> CosmicRay: Funnily enough it's called Get ProcessId http://msdn.microsoft.com/library/default.asp?url=/library/en-us/dllproc/base/getprocessid.asp
06:42:46 <Enveigler> THough if you want the ID for the current process rather than a specific process you need http://msdn.microsoft.com/library/en-us/dllproc/base/getcurrentprocessid.asp?frame=true
07:05:49 <CosmicRay> eno-away: heh
07:05:54 <CosmicRay> err Enveigler: heh
07:06:03 <CosmicRay> I was actually wondering if there was something in Haskell to do that
07:06:05 <CosmicRay> no biggie
07:06:19 * Thu18118 puts his thumbs up for ion3 and tuomov
07:06:26 <CosmicRay> I'm not going to try to add a windows api call to fptools just to make syslog able to display a pid from windows ;-)
07:08:22 <CosmicRay> is there a way to test for whether or not a program is being compiled on Windows using just CPP and not hsc?
07:09:33 <Lemmih> There's mingw32_TARGET_OS
07:10:11 <CosmicRay> that may be what I need
07:10:34 <CosmicRay> hmm, where is that documented?
07:10:42 <CosmicRay> the ghc docs seem to indicate mingw32_OS, but it doesn't work
07:11:19 <CosmicRay> hmm, mingw32_TARGET_OS doesn't work either
07:12:46 <Lemmih> Define "doesn't work".
07:13:55 <CosmicRay> this:
07:13:59 <CosmicRay> #ifndef mingw32_OS
07:14:04 <CosmicRay> import System.Posix.Process(getProcessID)
07:14:06 <CosmicRay> #endif
07:14:12 <CosmicRay> still tries to import System.Posix.Process on Windows
07:14:29 <Lemmih> Uh... how about mingw32_TARGET_OS? (:
07:14:33 <CosmicRay> tried that too
07:14:35 <CosmicRay> didn't help
07:14:56 <CosmicRay> http://www.haskell.org/ghc/docs/latest/html/users_guide/options-phases.html#c-pre-processor is where I'm looking
07:16:01 <Igloo> You do have -cpp, right?
07:16:08 <CosmicRay> yes
07:16:09 <Igloo> Running with -v might show you what -Ds are passed
07:16:20 <CosmicRay> I'd expect a serious syntax error on #ifndef if not, as well
07:16:59 <Igloo> Yeah, but I'm not sure which would come first
07:17:08 <CosmicRay> ah ha.
07:17:13 <CosmicRay> mingw32_HOST_OS
07:17:55 <Lemmih> What's mingw32_TARGET_OS then used for?
07:18:04 <CosmicRay> I think it's used internally when building ghc
07:18:06 <CosmicRay> from a quick grep
07:18:12 <CosmicRay> so the docs on that above page are wrong
07:18:14 <CosmicRay> where should I report this?
07:18:21 <Lemmih> Cabal also uses it.
07:18:38 <Igloo> g-h-b I'd say
07:18:51 <Lemmih> Which means it should fail horribly on Windows.
07:19:12 <CosmicRay> Lemmih: well, the cabal in fptools would prboably work
07:19:21 <CosmicRay> it would probably be an independently-built cabal that would have issues.
08:17:27 <CosmicRay> is there any way to do something akin to #ifdefs with .cabal files?
08:17:34 <CosmicRay> so that parts of it are used on some platforms, and parts aren't?
08:18:49 <Lemmih> Call cpphs on it?
08:18:50 <JaffaCake> you need to use the hooks, I believe
08:24:35 <bourbaki> hidiho
08:34:32 <genneth> has anyone ever made a robocode-esque thing for haskell?
08:34:37 <shapr> Lemmih: Hey, how does hacanon compare to hsffig?
08:36:31 <Lemmih> GT, but that may change in the future (:
08:36:45 <shapr> As in, hacanon does more?
08:38:48 <Lemmih> Yep.
08:39:04 <CosmicRay> argh, windows compatibility sucks
09:02:02 <shapr> I'm getting tired of darcs spam.
09:03:03 <Lemmih> Darcs spam?
09:03:44 <shapr> The email accessible repos on ScannedInAvian have been around long enough that they got spam harvested somewhere.
09:03:54 <shapr> So they all show up in my inbox as darcs patches that failed to apply.
09:04:47 <_metaperl> I just use ssh for my scanned repo. darcs push metaperl@ScannedInAvian.org:/home/metaperl/haskell/craft-of-fp
09:05:55 <shapr> Yeah, but I have at least one repo that I wish to keep email accessible, it's used for the GettingStarted page.
09:06:28 <CosmicRay> huh.  Any idea why I would be getting:  Text.Regex.Posix.regcomp: error in pattern
09:06:31 <CosmicRay> on Windows, but not in Linux?
09:07:29 <shapr> Maybe that's an escaping problem?
09:08:34 <CosmicRay> shouldn't the regexes work the same both places though?
09:08:51 <_metaperl> CosmicRay: same ghc version?
09:08:58 <CosmicRay> yes, 6.4 both places
09:09:48 <shapr> If ghc is using windows' posix layer, then maybe not.
09:10:13 <CosmicRay> weird.
09:10:23 <CosmicRay> ghc certainly omits lots of posix on windows
09:10:26 <Igloo> Have you worked out what pattern causes it?
09:10:33 <CosmicRay> no, I'm working on that now
09:10:41 <CosmicRay> it crashes so hard that hunit can't tell me what case caused it
09:11:15 <Igloo> It should have the test number printed out at the bottom
09:11:47 <CosmicRay> yeah but that doesn't help a whole lot.  It's like 99 out of 400 and they're spread out across dozens of modules
09:11:55 <Igloo> ah
09:12:13 <CosmicRay> I know what module these are in so I'mm just commenting out cases until I hit it
09:21:47 <shapr> greetz TheHunter, do you have access to the QuickCheckM extensions you wrote long ago?
09:22:35 <shapr> I checked the logs and found some bits of your code, a TestableM class with checkIO was part of it.
09:25:42 <TheHunter> shapr, no i never wrote any code.
09:26:10 <TheHunter> i was just sure it would be possible.
09:26:34 <shapr> Ah, ok.
09:28:27 <shapr> I gave in to unsafePerformIO, and I now have a QuickCheck property that tests ghc math against the gnu dc program.
09:28:52 <shapr> I'm not using the QuickCheckM monadic PropertyM yet, mostly because I haven't figured it out.
09:31:24 <TheHunter> monadic unsafePerformIO will probably do the trick to convert a PropertyM into a Property. Should be safe as long as this is immediately tested.
09:38:22 <shapr> So, I'd use "monadic unsafePerformIO" in the place of "imperative" ?
09:39:43 <shapr> Now to think of some property that requires IO...
09:41:15 <shapr> Enveigler: Any progress with monads?
10:07:33 <CosmicRay> SyntaxNinja: is there a way in a cabal file to depend on the unix package only if we're not building on windows?
10:07:52 <CosmicRay> hmm, where can I find out, in haskell, what the directory separator character is?
10:09:40 <SyntaxNinja> CosmicRay: to your first question, no, unfortunitely.
10:09:57 <CosmicRay> ok.  I managed to hack up a windows batch file to do what I need
10:10:04 <CosmicRay> would be nice to have some mechanism there
10:10:14 <SyntaxNinja> CosmicRay: how does it buidl on windows without that? we should just have a compatibility package
10:10:24 <SyntaxNinja> do you ifdef an include of hte unix stuff?
10:10:38 <SyntaxNinja> as to the directory separator, if you use hte FilePath module, I think it's there, but you shouldn't need it, technically
10:10:45 <SyntaxNinja> you should use the "pathJoin" type functions
10:10:46 <CosmicRay> I have added a bunch of ifdefs in the various source files to disable some functionality or provide alternative implementations
10:10:54 <SyntaxNinja> right
10:11:04 <CosmicRay> you mean Distribution.Compat.FilePath?
10:11:14 <SyntaxNinja> what we _should_ have is a package which does all that stuff for us, like copyPermissions or whatever.
10:11:19 <CosmicRay> yeah I saw those.  they look suspiciously familiar to this ex-pythoner ;-)
10:11:21 <SyntaxNinja> yeah, but you can use Lemmih's cabal-ized version of that.
10:11:44 <CosmicRay> well if the major compilers come with Distribution.Compat.FilePath already, I can just use it
10:11:45 <SyntaxNinja> yes, I started that as a copy from python, then krasimir fleshed it out; it's inspired from python and a few other places.
10:11:48 <CosmicRay> I assume hugs and nhc98 have it?
10:11:55 <SyntaxNinja> no, you can't use it; it's hidden
10:12:08 <CosmicRay> bummer
10:12:13 <CosmicRay> it's on the ghc online docs
10:12:18 <CosmicRay> http://www.haskell.org/ghc/docs/latest/html/libraries/Cabal/Distribution.Compat.FilePath.html
10:12:24 <CosmicRay> why hide it/
10:12:55 <SyntaxNinja> yeah, it's hidden on purpose so that ppl won't rely on it; some folks didn't like the library when it was introduced and demanded we not include it, but Cabal needed it, so it's squrrled away in cabal's belly.
10:13:07 <CosmicRay> bah
10:13:19 <CosmicRay> I hate that.  "this code isn't perfect!  you must not include it!"
10:13:24 <CosmicRay> that attitude is annoying
10:13:31 <CosmicRay> I'd say, include it with a disclaimer
10:13:46 <SyntaxNinja> darcs get http://www.scannedinavian.org/~lemmih/FilePath/
10:13:48 <shapr> I prefer "submit improvements or shaddup"
10:13:55 <CosmicRay> shapr: better yet
10:14:28 <SyntaxNinja> well, it's available, but not standard... a decent compromize, imo, but I would much have rathered gotten any bugs fixed and released properly
10:14:30 <shapr> Most libs are suggested for a reason, if they fulfill their purpose badly, fix rather than veto.
10:14:42 * SyntaxNinja agrees, though.
10:14:44 <CosmicRay> urgh, requires C
10:15:04 <SyntaxNinja> CosmicRay: cpp you mean?
10:15:10 <CosmicRay> #include "ghcconfig.h"
10:15:26 <CosmicRay> that's more than just needing cpp, no?
10:15:50 <CosmicRay> hmm, how can one include a C header file in a .hs file without using hsc?
10:15:53 <SyntaxNinja> hm. don't think so, I don't really remember that.
10:16:00 <SyntaxNinja> i mean, cpp will just inline it, right?
10:17:20 <CosmicRay> huh, is this lemmih or igloo's code?
10:17:33 <Igloo> "this"?
10:17:36 <CosmicRay> lemmih checked it in
10:17:42 <CosmicRay> igloo: <SyntaxNinja> darcs get http://www.scannedinavian.org/~lemmih/FilePath/
10:17:48 <CosmicRay> igloo's name is in the .cabal
10:17:56 <CosmicRay> err no!
10:18:03 <CosmicRay> is this lemmih's or syntaxninja's code?
10:18:04 <CosmicRay> bah
10:18:10 <shapr> it's mine!
10:18:12 <CosmicRay> heh
10:18:15 * shapr confuses CosmicRay further
10:18:22 <SyntaxNinja> heh
10:18:23 <CosmicRay> whoever owns it, put a real license in someplace please ;-)
10:18:25 <SyntaxNinja> <---- isaac
10:18:36 <CosmicRay> yesyes, I remember
10:18:37 <shapr> <---- Joe
10:18:37 <Igloo> What's wrong with LICENSE?
10:18:40 <CosmicRay> I just overclocked my reading
10:19:00 <CosmicRay> Igloo: well, the fact that it doesn't exist in this repo ;-)
10:19:18 <SyntaxNinja> heh
10:19:19 <Igloo> Ah. It's in working
10:19:24 <SyntaxNinja> darcs add and mail in a patch to lemmih
10:19:34 <SyntaxNinja> or just kick him out of bed
10:19:35 <Enveigler> shapr: I gave up on monads.I understand them, but they just make easy things hard and hard things impossibe (IMO). Arrows seem more orthoganal, but harder to grasp. I'm currently reading "Concepts, Techniques, and Models of Computer Programming" by P. Van Roy and S. Haridi. Which reenforces my feelings. It's an interesting (if very long) read.
10:19:42 <CosmicRay> Igloo: ok, so we already established that this wasn't your code, why do you have the only copy of the license? ;-)
10:19:45 <CosmicRay> <-- now more confused
10:19:56 <Igloo> SyntaxNinja: You means CosmicRay should add a license in your name and send to lemmih to apply?
10:20:04 <Igloo> CosmicRay: Go to the URL in your favourite web browser
10:20:16 <CosmicRay> ah.
10:20:23 <SyntaxNinja> Igloo: the license is there, it's just not added
10:20:28 <CosmicRay> bad syntaxninja.  forgot to darcs add.
10:20:34 <SyntaxNinja> that's not my damn repo!
10:20:40 <CosmicRay> heh
10:20:48 <CosmicRay> why is lemmih maintaining your code? ;-)
10:21:01 <CosmicRay> or did he pull it out of cabal?
10:21:19 * CosmicRay decides that must be it
10:21:22 <Igloo> Something's certainly gone wrong here
10:21:28 <Igloo> Possibly just the maintainer field in the .cabal file
10:21:38 <SyntaxNinja> he pullled it out of cabal and made a standalone package.
10:21:46 <CosmicRay> Igloo: that could explain it all, indeed.
10:22:08 <CosmicRay> from looking at the package it appeared that syntaxninja was maintaining it and yet lemmih had checked it in, wasn't sure what the deal was
10:22:15 <CosmicRay> Lemmih: ping
10:23:01 <SyntaxNinja> shapr: that's it, delete the directory
10:23:15 <shapr> which dir?
10:23:49 <shapr> Enveigler: Strange, monads are easier than objects now that I understand both.
10:25:04 <shapr> Maybe that's just because I think in strange directions.
10:28:22 <shapr> btw, I think the game 'enigma' is the closest thing yet to the Young Lady's Primer.
10:29:50 <Lemmih> CosmicRay: Pong.
10:30:04 <CosmicRay> Lemmih: can you darcs add LICENSE in your FilePath repo, please?
10:30:50 <CosmicRay> Lemmih: also I have a darcs patch to remove the unnecessary #includes
10:30:53 <CosmicRay> what's your e-mail?
10:31:30 <CosmicRay> thanks, sent
10:31:36 <CosmicRay> the module appears to compile fine without that
10:31:56 <Enveigler> shapr: I guess I can't get over how hard it is to do things with monads that are so easy in imperative code. My attempts to apply pure functions to monadic values result in endless rounds of trial and error, and when I do make something work, I have no idea why it works. I've still not seen an explaination of what Control.Monad.liftM actually does--and that was my first question.
10:32:05 <CosmicRay> oh, all these TARGET_OS should be HOST_OS...
10:32:08 <CosmicRay> one sec, I'll send you those...
10:32:21 <shapr> Enveigler: Really, I have explained it to you several times.
10:32:38 <Lemmih> We should probably fix this in Cabal, too.
10:32:56 <CosmicRay> Lemmih: it is correct for the cabal that exists within fptools.
10:33:05 <shapr> Enveigler: Things that are hard in imperative languages are easy in Haskell. That tradeoff means that the IO monad can only wind forward.
10:33:06 <CosmicRay> Lemmih: it is incorrect for the cabal that is distributed outside of fptools
10:33:08 <Lemmih> But Cabal is separate from GHC.
10:33:10 <CosmicRay> if my understanding is correct
10:33:21 <CosmicRay> Lemmih: well there is the cabal in fptools that is distributed with ghc
10:33:41 <CosmicRay> ok I sent a second patch to you as well
10:33:50 <Lemmih> Oki.
10:34:23 <shapr> Enveigler: Most monadic values can be unwrapped and used in pure code. Like I said before, monads are easiest if you use IO as a black box until you understand the easier monads.
10:34:49 <SyntaxNinja> Lemmih: you can set author to me and maintainer to you on that .cabal file :)
10:35:24 <CosmicRay> yes, that would apparently spare CosmicRay considerable confusion ;-)
10:35:54 <Lemmih> SyntaxNinja: Oh, right. Sorry.
10:36:11 <CosmicRay> once this all is done, I will be importing this into MissingH
10:37:14 <shapr> Enveigler: You may need to unlearn some 'imperative reflexes' to get into monads.
10:37:22 <Lemmih> CosmicRay: "darcs failed: Bad patch bundle!"
10:37:33 <CosmicRay> doh
10:37:45 <CosmicRay> did gmail molest it in any way?
10:38:05 <CosmicRay> well I can send you a diff
10:38:35 <SyntaxNinja> gmail has tended to molest darcs bundles somehow
10:38:45 <dmiles_afk> any froz users awake?
10:39:26 <CosmicRay> Lemmih: ok, I've emailed you a diff
10:39:29 <shapr> What's froz?
10:39:51 <dmiles_afk> froz: oz adventure game.. GHC thingy
10:40:06 <CosmicRay> oz?
10:40:11 <SyntaxNinja> is it the "hot coffee" mod hidden in ghc or something? ;)
10:40:12 <Speck> wizard of oz?
10:40:15 <CosmicRay> is this some sort of zcode interpreter?
10:40:26 <dmiles_afk> mozart interpreted adventure game
10:40:29 <CosmicRay> SyntaxNinja: that sounds a lot less entertaining than the mod hidding in GTA ;-)
10:40:38 <dmiles_afk> uses the Racer inference engine
10:41:15 <dmiles_afk> barely related to Haskell but i am sure it will be implemented in haskell soon
10:41:25 <shapr> Which? Froz or Racer?
10:41:38 <dmiles_afk> Racer hopefully first
10:41:55 <SyntaxNinja> cosmicray: I watched a video of that yesterday. it's such a stupid thing.  it changes the ratings from "appropritae for 17 year olds" to "appropriate for 18 year olds"
10:42:04 <CosmicRay> heh
10:42:19 <dmiles_afk> Froz just mixes inference engine Racer with game in oz
10:42:21 <CosmicRay> I haven't really looked at it.  i don't own the game anyway
10:42:44 <SyntaxNinja> CosmicRay: I don't own the game, there are .wmv files out there of this.
10:42:53 <shapr> Oh, I see.
10:43:34 <dmiles_afk> shapr, i am still on my 6 year search for an interesting computer game
10:43:38 <SyntaxNinja> it's really stupid
10:43:51 <CosmicRay> dmiles_afk: www.ifarchive.org
10:44:04 <CosmicRay> dmiles_afk: you might also try star wars: knights of the old republic
10:44:13 <CosmicRay> for two very different types of games ;-)
10:44:30 <shapr> dmiles_afk: What sort of games interest you?
10:44:36 <shapr> Have you tried enigma?
10:44:37 <CosmicRay> shapr: it appears "none"
10:44:52 <dmiles_afk> any game that the rules expand via infernce engine rules
10:44:52 <shapr> Good point :-)
10:45:14 <dmiles_afk> based on some first order logic declarations
10:45:42 <shapr> On the non-computer game front, have you tried Zendo (and all other Icehouse/Looney Labs games) or Gnomic?
10:46:26 <dmiles_afk> havent seen Gnomic implemented but thats the lines
10:46:44 <shapr> You might enjoy Fluxx the card game too.
10:46:45 <dmiles_afk> look for knight of old replublic first
10:46:56 <dmiles_afk> erm looking
10:47:37 <shapr> You could also try to take up my viewpoint that Open Source is the ultimate MMORPG.
10:48:04 <shapr> Type systems and the Curry-Howard isomorphism make for a fun inference game.
10:48:04 <CosmicRay> dmiles_afk: have you tried ICFP?
10:48:11 <dmiles_afk> oh odd. i was hopoign that knights thing was more 80s ;P
10:49:04 <dmiles_afk> goggling ICFP+Games
10:49:44 <vegai> has anyone grokked Yampa?
10:50:05 <vegai> care to write a for-dummies article on next TMR about it? =)
10:50:30 <reffie> shapr ha
10:50:42 <reffie> shapr you are right that open source is the ultimate MMORPG
10:51:18 <vegai> it seems to me that in that game, XP runs are more common than eq/$$$ runs
10:51:38 <reffie> eq?
10:51:44 <vegai> rep runs too
10:51:46 <vegai> equipment
10:51:57 <reffie> ah
10:51:58 <reffie> true
10:52:22 * vegai fears that no-one has grokked Yampa
10:53:39 <Lemmih> You could ask someone in the Yale Haskell Group.
10:53:43 <dmiles_afk> Brian Rice from #lisp has
10:54:40 <dmiles_afk> i am just taking a 80% probible guess he has been trying to implment the anonlgy of that
10:55:11 <vegai> alternatively, I wonder if event-based programming would be possible in a slightly less ambitious manner?
10:57:51 <shapr> vegai: Yeah, I dig Yampa.
10:57:55 <SyntaxNinja> vegai: I did a bunch of work w/ yampa, but I'm afraid I don't have much of it in my brain anymore.
10:58:28 <qbert> do yall use haskell for commercial products ? if so what kind of products /
10:58:55 <SyntaxNinja> vegai: might be able to answer some specific questions
10:59:01 <shapr> I have used Haskell for pay, one xml processing job and an email archive searching webapp.
10:59:07 <SyntaxNinja> vegai: I think event-based programming could be less ambitious
10:59:18 <SyntaxNinja> vegai: but yampa is very much a research project..
10:59:31 <SyntaxNinja> qbert: computer security-related products
11:00:06 <shapr> I think event based programming would work beautifully in a purely categorical system where FOL equality decidability isn't a problem.
11:00:08 <vegai> qbert: I've used it in some supporting products
11:00:13 <vegai> parsers mostly
11:00:33 <vegai> shapr: that's my initial feeling too
11:00:52 <shapr> vegai: Do know the black box problem with functions lifted into arrows?
11:00:56 <vegai> nope
11:00:58 <qbert> shapr, FOL ?
11:01:02 <shapr> first order logic
11:01:14 <qbert> hmm
11:01:26 <shapr> vegai: Read the bottom comment of http://kevin.atkinson.dhs.org/fg/FG.hs
11:01:46 <shapr> FG is much like (wx)Fruit, they're all event based GUIs.
11:02:11 <qbert> what kind of GUI's does haskell have ?
11:02:14 <shapr> They work just fine, but they're inefficient when you have something you can't introspect.
11:02:23 <vegai> Oh. Auch
11:02:50 * shapr thinks that was grammatically incorrect "can't introspect" ?
11:03:23 <shapr> vegai: On the other hand, check out dataflow languages like Lucid et al.
11:03:50 <shapr> The reason Yampa works so nicely is that you are limited to something very much like a purely categorical system.
11:03:55 * vegai so does.
11:03:57 <Lemmih> qbert: There are Haskell bindings to GTK, wxWidgets and TclTk.
11:04:18 <vegai> shapr: care to write a for-dummies article about it on TMR? =)
11:04:19 <shapr> You never get to handle the signals directly, you only get to produce signal transformers from the basic Yampa combinators.
11:04:25 <shapr> That way it works beautifully.
11:04:26 <vegai> or just the wiki, I don't know
11:04:47 <shapr> I've sort of already started on that article, the ArrowsIntroduction is the basics behind Yampa.
11:04:58 <vegai> ah, right
11:05:18 <shapr> But I only just now made the connection between Yampa and a purely categorical language.
11:06:21 <SyntaxNinja> anyone know why fdRead might get a "Bad file descriptor" error?
11:07:02 <shapr> Peter Simons wrote his fast blockio library first in arrow-style, and only later in monadic style. He said the arrow code was half the size of the monadic code. I suspect that arrows are in general more expressive than monads as the blockio comparison exemplifies.
11:08:01 <shapr> qbert: gtk2, tk, gtk1, wxWidgets, some others.
11:08:40 <shapr> vegai: I think my arrows introduction will turn into a series of articles. I'll try to cover Yampa as well.
11:09:27 <shapr> musasabi: got a moment?
11:10:47 <shapr> btw, anyone know how I can rename a bunch of foo1.flac .. foo9.flac to foo01.flac .. foo09.flac  with zsh or something?
11:11:04 * shapr wishes again for a haskell shell
11:11:47 <SyntaxNinja> hm. looks like it's one that's been closed
11:12:09 <SyntaxNinja> shapr: I wrote a haskell program to do that once
11:12:21 <SyntaxNinja> well, not quite, but almost
11:13:04 <shapr> For that matter, I wish I could pattern match part of strings with nicer syntax.
11:13:08 <shapr> I guess HaRP can do that.
11:14:10 <SyntaxNinja> shapr: do you want my little script that numbers files? it might be a good place to start.
11:14:24 <shapr> yes please!
11:15:41 <SyntaxNinja> @wiki HaskellIrcPastePage
11:15:42 <lambdabot> http://www.haskell.org/hawiki/HaskellIrcPastePage
11:15:53 <SyntaxNinja> try it out on some dummy files first.
11:16:39 <shapr> thanks
11:16:39 <aheller> for i in *.flac; do echo mv $i ${i:/foo([0-9]).flac/foo0\1.flac}; done
11:17:05 <shapr> Woa, that's a crazy looking match function.
11:17:13 <Enveigler> shapr: I guess that's the point I've reached. I do not see what benefits Monads give me that justify the complexity they add, and the "necessity to unlearn".
11:17:52 <shapr> Enveigler: Believe it or not, simplicity and predictability/compositionality.
11:18:12 <SyntaxNinja> Enveigler: isn't it worthwhile to just learn new things? it's not really too hard.
11:18:25 <aheller> shapr: zshexpn.  I didn't really look for a way to make it concise :)
11:18:34 <vegai> shapr: rename(1) perhaps
11:19:14 <vegai> the rename man page has an example that does exactly what you want... I think
11:19:36 <shapr> Cool, now I have lots of options, thanks =)
11:19:56 <vegai> (I mean exactly, it renames "foo" to "foo0" :))
11:20:32 <frederik> shapr: 'rename'. the one that comes with perl.
11:21:04 <frederik> (the -n option is mine :) )
11:21:36 <vegai> of course, the real option would be to implement a system that transcends filenames
11:27:57 <Enveigler> shapr: I love to learn, but it's a case of deciding /what/ to spend the time on. And from what I've seen so far, the balance of the equation doesn't add up. I keep watching and reading in case a "killer app" example turns up, but right now Oz seems to give me the best bits of Haskell's purity and laziness, but is rather more pragmatic about dealing with impurities (TRW).
11:29:10 <CosmicRay> is there some special magic for the "module" statement that says "export everything defined in this file, plus also re-export everything in this other module that I've imported"?
11:29:22 <Speck> god. some people really don't understand how to design systems.
11:30:35 <Speck> "Let's introduce a macro system for sql (nevermind that it's horribly susceptible to injection attacks), then store it in a way that makes it impossible to infer anything about it so nobody will every be able to test it!"
11:32:25 <SyntaxNinja> Enveigler: it was I who asked if you enjoyed learning new things, not shapr.
11:32:49 <perspectival> Hello--can anyone give me a tip on what to do after receiving a "Could not find module `Graphics.HGL':" in both GHCi and Hugs?
11:33:17 <shapr> Enveigler: You have to make your own choices. For me, purely functional programming and monads are and were worth it, that may not be true for you as well.
11:33:20 <Enveigler> Sorry SyntaxNinja/Shapr Your messages comeup sequentially and I read the two as one.
11:34:22 <shapr> Enveigler: Also, be aware that purely functional programming and linear types do the same thing. You may be able to leapfrog from linear types or uniqueness types (like in Clean) to monads more easily.
11:34:43 <SyntaxNinja> perspectival: have you installed the library? Are you working on the haskell school of expressiohn?
11:35:21 <Speck> monads are neat. they are explained in a way that makes them seem too difficult. I forget who said that monads should have been named something like "warm fuzzy things", but I think that the real fault lies in the ones documenting them. All the monad tutorials/docs I've seen start with "monads are hard to understand." it's immediate learned helplessness.
11:36:08 <shapr> Yeah, I don't think monads are difficult, just different.
11:36:45 <SyntaxNinja> Enveigler: learning to think in a purely functional way has a big payoff in your ability to program and to grok new things.   I would approach it from that angle, because you won't "see" any killer apps until you can understand them.
11:36:55 <Speck> I think that the abstraction caught me at first. If you explain what a monad is in layman ct-terms and describe the laws, if the reader hasn't just given up because it's "too hard", s/he will just think "so what?"
11:37:15 <SyntaxNinja> Enveigler: and even then, most modern languages are sufficiently powerful that killer apps are never that enormously different in different languages.
11:37:15 <Speck> Socrates' Cave comes to mind
11:37:22 <vegai> one advantage of Haskell is that it has relatively much momentum
11:37:23 <Enveigler> Speck: It's not the name that put's me off.  A clear, non-jargonal explaination of /using/ monads might help, but that doesn;t seem to exist.
11:37:25 <perspectival> I'm trying to work through SOE, yes. I can't figure out, however, how GHC or HUGS looks for or finds HGL. I'm working on FreeBSD, and HGL is installed on the system
11:37:44 <vegai> Enveigler: JustDoingIt(tm) seems to be the best choice
11:37:51 <Speck> Enveigler, look at part III (I think part three) of "All About Monads" it has examples for all the monads in haskell98
11:37:58 <shapr> "All About Monads" worked for me.
11:38:31 <Speck> some of the examples are perhaps too complicated, and don't showcase the monadic nature as well as they could, but it's hard to write examples that aren't contrived and are simple and precise
11:38:39 <vegai> I made the mistake that I tried to understand them without doing anything practical
11:38:51 <SyntaxNinja> perspectival: I'd pick one or the other, ghc or hugs. hugs is probably easier.  read the user's manual for how it finds modules.
11:38:56 <vegai> that cost me couple of months, at the least
11:39:11 <vegai> fortunately, I'm not in a hurry :P
11:39:30 <Speck> I might write a quick monad tut (over the course of a long time thinking of good examples), without explaining the monad laws until the end.
11:39:42 <Enveigler> Speck: Again, I am not looking for a showcase--there is much too much of that about--practical "use-cases" are much more convincing (to me).
11:40:00 <Speck> lists aren't practical?
11:40:30 <Speck> the maybe monad + sequence is very practical
11:41:46 <Speck> it makes a simple kind of transaction
11:42:23 <Speck> monads also let you modularize your computations in a neat way, then combine them back together
11:43:31 <Enveigler> A "use case" descriibes an application, then implements it in terms of the language. Showcases describe the langauge feature and then make up (usually trivial) examples to demonstrate it.
11:44:22 <vegai> what size would you like'em?
11:44:40 <perspectival> I agree completely with the helpfulness of reading documentation. Still, I can't find it. Perhaps this all has something to do with Cabal and the section called "Adding packages to a Hugs installation". Or perhaps it has something to do with the message I received after installing HGL:
11:44:40 <perspectival> Install notice:
11:44:40 <perspectival> ----------
11:44:40 <perspectival> Please set the environment variable HUGSFLAGS "-P{Hugs}/x11:".
11:44:41 <perspectival> In tcsh:  setenv HUGSFLAGS "-P{Hugs}/x11:"
11:44:43 <perspectival> In sh:    export HUGSFLAGS="-P{Hugs}/x11:"
11:45:24 <shapr> Enveigler: "All About Monads" has showcases for the monads it describes.
11:45:30 <Speck> Enveigler, I don't think your definitions of "use case" and "showcase" are mutually exclusive
11:45:43 <SyntaxNinja> perspectival: have you done that?
11:45:46 <SyntaxNinja> echo $HUGSFLAGS
11:45:51 <SyntaxNinja> perspectival: I don't think the HGL package uses cabal
11:45:58 <SyntaxNinja> if it did, I don't think you'd have this problem :P
11:46:26 <SyntaxNinja> perspectival: when you installed the HGL did you try the example it told you to try?
11:47:09 <perspectival> I'm not sure of the syntax for this. I'm using tcsh, and I tried putting different things into .cshrc
11:47:37 <SyntaxNinja> just try it on the command line first: setenv HUGSFLAGS "-P{Hugs}/x11:"
11:47:49 <SyntaxNinja> does tcsh read the .cshrc file?
11:48:26 <SyntaxNinja> in the HGL readme, I think there's a thing that says "to try this out, run the following command.." and it'll bring up an hgl window, you should definitely try that to make sure things are installed correctly.
11:48:41 <perspectival> so I tried it on the command line, and then started hugs
11:49:03 <Speck> Enveigler, if you think it not worth your time to learn monads, that is your choice and certainly a valid one. Monads aren't well expressed by a use case or a showcase/use case or even a handful. They're too general for that. You need to look at a lot of different ones and let the abstraction take shape in your head. THEN worry about the laws governing them as the final formalization.
11:49:17 <perspectival> it still can't find Graphics.HGL
11:49:54 <vegai> perhaps the lazy approach is best? Ignore everything until you need'em in your own project :)
11:51:03 <SyntaxNinja> perspectival: the -P flag tells hugs where to find the Graphics directory. You could ignore HUGSFLAGS for now and just fiddle with different values of -P, to tell it exactly where to find it.
11:51:15 <perspectival> OK
11:51:23 <Speck> vegai, the problem is that, if you ignore them, you won't know when you need them
11:51:43 <vegai> indeed..
11:52:28 <shapr> Speck: I'd argue that the motivation and Example sections in "All About Monads" do qualify as use cases and showcases. What do you think? --> http://www.nomaware.com/monads/html/listmonad.html
11:53:31 <Speck> I liked that section a lot and I agree with you, but I wish there were more examples. Trouble is thinking of them, because that's really hard.
11:53:38 <shapr> Of course, this whole discussion is similar to "Can you show me a concrete use of objects?", which is equally challenging to answer, imho.
11:53:52 <Speck> I definitely learn by example, but recently I'm getting better at learning by formal definition
11:53:55 <shapr> I remember when OOP first clicked for me, I was thrilled.
11:54:24 <Speck> OOP was such a mystery until I realized how simple it was.
11:54:39 <shapr> Yeah, same here.
11:55:00 <Speck> I didn't get monoids for so long. People would explain and explain and then I just sat down and said.... WAIT! It's so simple it's stupid!
11:55:03 <SyntaxNinja> perspectival: FWIW, my biggest complaint about SOE is that the graphics library is a PIA to get working; it's not just you, but it's a good book once youg et through that.
11:55:16 <shapr> One difference between objects and monads is that monads are more like metaclasses from my viewpoint. Objects don't let you change the semantics, but monads do.
11:55:28 <perspectival> My best guess, SyntaxNinja, is that the library resides in /usr/local/lib/hugs/x11/, because files like GraphicsCore.hs are all located there. Ergo, I would assume that I should do the following:
11:55:30 <perspectival> setenv HUGSFLAGS "-P /usr/local/lib/hugs/x11/:"
11:55:43 <Speck> objects are coalgebras, right?
11:56:01 <perspectival> when I try that command and start Hugs, I get the following from Hugs:
11:56:06 <shapr> I wouldn't know a coalgebra if it bit me.
11:56:29 <Speck> I was hoping you'd know better than I. I read it in the Metamorphic Programming paper.
11:56:31 <shapr> I've heard people claim that objects are coalgebras, but have no idea.
11:56:39 <Speck> It made a lot of sense when I read it there.
11:57:01 <shapr> Anyway, today's task is to get QuickCheckM working with IO ProperyM defs
11:57:19 <Speck> fun fun
11:57:26 <esap> Coalgebras and OOP are very closely related, although there are other things to OOP than coalgebras.
11:57:34 <perspectival> argh, No, I hear you. I've done this before. I even had the library working before.
11:58:03 <perspectival> the library is in /usr/local/lib/hugs/x11/
11:58:16 <perspectival> I'm just not sure how to tell Hugs to find it
11:58:23 <Enveigler_> shapr: Metaclasses are nothing new. I first encoumtered them in smalltalk and I had much less problems using them than monads. I keep trying to say, I understand monads, I just feel that they may serve the purpose of preserving purity, but they come at the cost of throwing away intuition.
11:58:56 <perspectival> OK, now it says ERROR "SimpleGraphics.hs" - Can't find imported module "Graphics.HGL"
11:58:56 <shapr> Maybe my intuition is different.
11:59:04 <perspectival> which is a bit different
11:59:27 <wagle> does metamorphic programming rock?
11:59:44 <wagle> or do metamorphic rocks program?
11:59:55 <wagle> (sigh)
12:00:03 <Speck> hehe
12:00:18 <shapr> Monads aren't really about preserving purity, they can be used in (impure) Scheme to good advantage as well. They do a lot of things, one of which is preserving order, another of which is preserving compositionality.
12:00:30 <Speck> I'd like to see bulk data types represented metamorphically (as their algebras and coalgebras)
12:00:58 <Enveigler_> okay shapr: I'll go back to lurking.
12:01:12 <wagle> >>= is sort of like CPS, but with more indirection
12:01:32 <shapr> Enveigler_: Do you understand continuation passing style?
12:01:40 <palomer> ooh ooh, a CPS tutorial
12:01:44 * palomer claps his hands
12:01:52 <astrolabe> Can you have a monad and x /= y for which return x == return y ?
12:02:10 <Enveigler_> shapr: Yes.
12:02:36 <shapr> palomer: Guess not :-P
12:03:08 <shapr> Enveigler_: Do you see any connection between monads and CPS?
12:03:23 <wilx> Hm, I could use CPS tutorial for dummies.
12:03:41 <wilx> Something that doesn't need Ph.D in math.
12:04:01 <Speck> not just math, Ph.D in math of the futures!
12:04:15 <wagle> indiaina university teaches CPS to juniors
12:04:25 <Enveigler_> shapr: Yes. A handle to a program state that you pass along.
12:04:35 <wagle> of course, half of them despise it with a passion
12:05:14 <SyntaxNinja> perspectival: the hugs man page has some useful information abut the -P that's non-obvious, wrt the default file locations. check that out.
12:05:59 <perspectival> Will do, thx. Appreciate the help ;-)
12:06:15 <esap> CPS is useful, because it makes explicit the future computation that is going to occur, and allows you to manipulate it.
12:06:27 * palomer chants "tutorial, tutorial, tutorial!"
12:06:29 <Speck> shapr, I know you're big on monads as sequencing computations, but the sequencing isn't the biggest part I think; the most important part is that you can define how the computation is carried out
12:06:42 <shapr> Speck: Thing is, there's a lot of biggest parts :-)
12:06:55 <shapr> Sequencing is a great benefit in Haskell, which ain't got none.
12:06:56 <Speck> sequencing is just a mandatory thing for haskell :-)
12:06:56 <arjanoosting> astrolabe: can you give a example why you should want this? I guess it might be possible as long as it still satisfies the monad laws
12:07:00 <SyntaxNinja> perspectival: no problem.
12:07:24 <shapr> I agree though, the greatest benefit of monads is user definable semantics.
12:07:35 <Speck> shapr, although I think lots of other operations (., $, function application) are kinds of sequencers too
12:08:27 <Speck> sure functions are defined in no sequence, but they are eventually sequenced through some means (or else we'd have a quantum kind of situation!)
12:09:47 <wagle> (1) do a primitive something (2) pass the result to a continuation
12:10:36 <esap> It's effects that need to be sequenced. Computation between the effects can occur at any order.
12:10:44 <Speck> someone explained continuations using the return keyword from c++ and it made sense to me, but I've never been able to understand code that uses them any other way
12:10:51 <astrolabe> arjanoosting:  I'm trying to understand how general monads can be, I don't actually want it for anything practical.
12:11:30 <wagle> the usual CPS is to use only tail-calls
12:11:41 <Speck> esap, functions "sequenced" by . can't be evaluated in any order (can they? I might just be limiting myself to point-free use of .)
12:12:12 <wagle> there's also an important concept of a "procedural accumulator"
12:12:12 <arjanoosting> astrolabe: I don't think it is really possible, you get problems with the first monad law (return x >>= f == f x)
12:12:29 <Speck> I guess they can be evaluated in any order, but the reduction follows a right->left pattern necessarily
12:12:37 <esap> Speck: Sure they can. Think call-by-value and call-by-need.
12:12:58 <wagle> right->left?
12:13:37 <astrolabe> arjanoosting:  thanks.  I'll have a think about that.
12:14:02 <Speck> oh I see
12:14:27 <Speck> for the call by need situation at least
12:14:42 <wagle> how did the first monad law come into play with astrolabe 's question?
12:15:23 <arjanoosting> astrolabe: f y == (return y >>= f) == (return x >>= f) = f x
12:16:10 <wagle> x and y are free variables in that equality
12:16:12 <Enveigler_> shapr: can you point me at an example of what you mean by  "user definable semantics"?
12:16:43 <astrolabe> I guess there is a zero monad where it breaks?
12:18:02 * wagle looks lost
12:18:31 * astrolabe is lost
12:18:58 * arjanoosting tries to explain his thinking... needs coffee first 
12:19:31 <palomer> whats the official distinction between cbn and cbv?
12:19:41 <astrolabe> m a = ()    return a = ()  etc.
12:19:49 <palomer> or rather, what are they exactly?
12:19:55 <esap> Speck: Call-by-value semantics evaluates the first component of composition first. Call-by-need propagates the demand for values of arguments, and in the process evaluates the expression beginning from the last component of the composition. Actually, you could define two different compositions, f . g = \x -> f (g x)  and f `strict_compose` g = \x -> f $! (g $! x)
12:20:02 <arjanoosting> if return x == return y then forall f . (return y >>= f) = (return x >>= f)
12:20:43 <arjanoosting> thus if return x == return y then forall f . f y == f x
12:20:44 <astrolabe> arjanoosting: so fx == fy, does that mean x = y?
12:21:04 <arjanoosting> if forall f . f y == f x then x == y
12:21:08 <arjanoosting> astrolabe: yes
12:21:18 <astrolabe> unless f : a -> ()
12:21:30 <astrolabe> f :: a->()
12:21:40 <arjanoosting> astrolabe: the monad laws should be satisfied for any f
12:22:12 <astrolabe> right thanks, that does make it clearer.  I think there is a single trivial counter-example
12:23:05 <arjanoosting> astrolabe: let me know if you find one that still (and still satisfy the monad laws)
12:23:19 <wagle> palomer: do you understand call-by-{value,name,need}?
12:23:26 <palomer> wagle: only vaguely
12:23:40 <astrolabe> arjanoosting:  why does m a = () not satisfy monad laws?
12:23:46 <palomer> not formally
12:23:59 <wagle> palomer: do you understand laziness?
12:24:01 <ski> palomer : hi again
12:24:28 <palomer> hey ski
12:24:37 <palomer> wagle: again, vaguely, not formally
12:24:39 <arjanoosting> how can it satisfy return x >>= f == f x
12:25:15 <musasabi> shapr: back home.
12:25:27 <astrolabe> Well... thinking out loud, return x == ()
12:25:37 <ski> arjanoosting : in that, 'x :: a' and 'f :: a -> m b', right ?
12:26:08 <astrolabe> ski: thanks!
12:26:12 <wagle> palomer: how familier with the pure lambda calculus?
12:26:17 <ski> arjanoosting : so 'f :: a -> ()', which means that 'f _ = ()'
12:26:20 <arjanoosting> ski: hmpf i need a type checker on my brain
12:26:47 <musasabi> shapr: btw for your rename question "perl -ne 'chomp;$o=$_;s/old/new/;rename($o,$_);' *caution - use first print instead of rename otherwise you end up doing mistakes (I do those too often with perl).
12:26:51 <ski> (barring nontermination in f ..)
12:27:04 <shapr> Enveigler_: http://www.lochan.org/2005/keith-cl/research/msc/proposal/node2.html or http://cs-www.cs.yale.edu/homes/hudak-paul/hudak-dir/ACM-WS/position.html or lots more I can turn if you want.
12:27:11 * arjanoosting wacks hiself with (>>=) :: m a -> ( a -> m b) -> m b
12:27:38 * arjanoosting really needs some coffee
12:28:02 <shapr> Enveigler_: Here's one of the very first examples: http://citeseer.ist.psu.edu/steele94building.html
12:28:06 <arjanoosting> astrolabe: sorry for the wrong info :(
12:28:33 <astrolabe> arjanoosting:  Not at all.  You were very helpful.
12:28:35 <ski> (hm, so if f = undefined or f = const undefined (which should be the same, barring seq :), then the monad law doesn't hold ..)
12:29:36 <palomer> wagle: of course
12:29:42 <ski> (hm, well depends on exact >>= def ..)
12:30:11 <shapr> musasabi: I was going to ask you about whether Yampa's limiting users to SF combinators only was an example of a categorically pure system where the black box problem doesn't happen. What do you think?
12:30:45 <wagle> palomer: do you know what weak head normal form is?
12:30:49 <astrolabe> There should be a type for which undefined is the only value
12:30:54 <palomer> wagle: yup
12:31:20 <palomer> wagle: t is in weak head normal form if t != (\x.u) v
12:31:25 <wilx> Btw, have any teams published their ICFP solutions yet?
12:31:29 <musasabi> shapr: doesn't yampa allow free functions inside the combinators?
12:31:47 <wagle> palomer: an expression is called a value if its in WHNF
12:31:49 <shapr> Hm, maybe so.
12:31:57 <ski> astrolabe : 'data Void'  (or if you want, 'newtype Void = V Void' or 'data Void = V !Void')
12:32:27 <wagle> a value might still have redexes, but you ignore them
12:32:30 <astrolabe> ski:  thanks :)
12:32:49 <ski> (astrolabe : the first version is not haskell98)
12:33:44 <astrolabe> It would be nice if they could webcast the ICFP competition (I mean graphics for the programs running).
12:36:12 <shapr> Yeah!
12:36:34 <ape> what's the challenge for the comp?
12:38:08 <wagle> palomer: in call-by-value, you find the first redex, and first reduce all the expressions in the application (the fun and the arg), only when they are both in WHNF, do you reduce the redex
12:39:11 <palomer> first redex = left most redex?
12:39:25 <wagle> palomer: in call-by-name, you don't reduce the arg, you just substitute it in to all occurance of the formal
12:39:55 <wagle> palomer: i forget what the order is precisely
12:40:07 <ski> palomer : first redex is top-most redex, there
12:40:48 <palomer> wagle: so call by name = left most reductions?
12:41:12 <wagle> normal order (of redex reduction)is guarantied to terminate if there is an order that terminates.  normal order corresponds to call-by-name
12:42:40 <wagle> applicative order corresponds to call-by-value.  and sometimes fails to terminate when normal order would.  for example, with a arg value that diverges..  for example (\x -> x x) (\x -> x x)
12:43:18 <palomer> wagle: isn't this equivalent to say that in cbv, bottom most redexes are reduced first?
12:43:55 <wagle> applicative order is "more efficient" than normal order since you reduce the arg expression to a value only once
12:44:03 <ski> palomer : they aren't
12:44:19 <ski> palomer : neither cbv nor cbn reduces under lambdas
12:44:45 <wagle> palomer: its not bottom most, and i think i'll be wrong if i try to (educated) guess
12:45:40 <ski> it think one could say cbv is bottom-most, if take care not to reduce under lambdas
12:45:53 <palomer> so, to evaluate a lambda term T in cbv, I find the top most/left most redex, if both terms are in WHNF then I reduce, else I cbv both terms
12:45:56 <palomer> then I start again
12:46:18 <wagle> (\x -> x x x) (1 + 1) -cbn-> (\x -> (1 + 1) (1 + 1) (1 + 1))
12:46:50 <palomer> correct?
12:47:01 <wagle> (\x -> x x x) (1 + 1) -cbv-> (\x -> x x x) 2 -cbv-> (\x -> 2 2 2)
12:48:04 <ski> wagle : no
12:48:22 <ski> you should remove the lambda, when beta-reducing :)
12:48:34 <wagle> cbn == call-by-name
12:48:53 <wagle> (\x -> x x x) (1 + 1) -cbn-> (1 + 1) (1 + 1) (1 + 1))
12:49:26 <wagle> (\x -> x x x) (1 + 1) -cbv-> (\x -> x x x) 2 -cbv-> 2 2 2
12:49:48 <Enveigler_> shapr: Thanks for the links. I'll need to see if I can find the last one somewhere on the web (outside of citeseer) and spend more time reading the others, but my first impressions are that all three describe how people have tried (and got closer to) solv[ing] problems using monads that aren't problem outside of "purely functional" code. That isn't meant to be inflammatory, just what I get from what I read.
12:49:48 <wagle> awww heck, i thought i could at least get that part right
12:50:46 <shapr> Enveigler_: The 1994 guy steele paper shows how monads are useful for building interpreters in Scheme. Scheme is not purely functional.
12:51:23 <palomer> wagle: is my interpretation of cbv correct?
12:51:58 <wagle> my first scheme compiler first worked, it was pure function
12:52:43 <wagle> palomer: i've said several times that i dont remember exactly how to describe the order of redexes
12:54:02 <wagle> palomer: so i'll leave that as a homework assignment
12:54:06 <wagle> 8)
12:54:27 <palomer> gah
12:54:44 <wagle> normal order, the args to a redex arent reduced
12:54:45 <ski> palomer : you could also say, to cbv-eval a term, if it's a) an application, then cbv-eval both subterms, then, if the operator-term is an abstraction (lambda), then substitute the operand-term for the abstracted var in the abstracted body;   b) an abstraction, then do nothing;   c) a (free) variable, then do nothing
12:55:20 <wagle> applicative order, the args to a redex are reduced to a value
12:55:28 <palomer> ski: gotcha
12:56:24 <palomer> ski: what about cbn?
12:56:26 <wagle> i didnt mean to get bogged down in the lambda calculus..
12:56:50 <ski> cbv starts evaling an application by recursively evaling both subterms, while cbn starts evaling an application by recursively evaling just the operator-subterm
12:57:27 <palomer> ah hah
12:58:06 <palomer> so why is there a call by name call/cc and a call by value call/cc?
12:58:18 <palomer> and a cbn CPS and a cbv CPS?
12:58:33 <ski> obviously cbv have variants, depending on how exactly to interleave the evaling of the two subterms, operator first ? operand first ? some kind of interleaving ? true parallel ? ...
12:58:47 <ski> because
12:59:59 <ski> the cbv CPS sortof *build into* the resulting transformed term the cbv order of evaling (the initial term), so we can eval the resulting term in cbv or cbn and it doesn't matter, it will still behave similarly to cbv-evaling the initial term
13:00:07 <ski> similar for cbn CPS
13:00:56 <wagle> cbv evaluates the arg exactly once
13:01:01 <ski> in other words, it makes the order to eval explicit in the term, so the system (cbv or cbn) which evals the resulting term has no choice but to follow the specified order
13:01:36 <wagle> call-by-name evaluates the arg each time the function refers to it
13:01:49 <wagle> (0 to N times)
13:02:11 <ski> in 'f (g 2) (h 3)' we haven't specified whether to eval '(g 2)' or '(h 3)' first (or interleaved or whatever)
13:02:17 <palomer> ski: do you mean: if t -cbv-> u then [[t]]_cbv -cbv->[[u]]_cbv ?
13:02:31 <palomer> where -cbv-> is one step reduction?
13:02:41 <wagle> call-by-need evaluates the arg when the functional first refers to it (at most once -- zaero or one time)
13:02:48 <wagle> function
13:03:18 <ski> in  "\k. g' 2 (\x. h' 3 (\y. f' x y k))" we have specified left to right and in-to-out eval order
13:04:46 <ski> palomer : the exact relation between evaling a term under cbv/cbn and evaling the cbv/cbn CPS transformed term under any of those orders depends on the details on the CPS transform
13:05:14 <palomer> but what invariant do we want to keep for cbn CPS and cbv CPS?
13:05:45 <ski> palomer : more specifically, the standard CPS transform introduced a lot of "administrative redices" (extranous ones), so you don't get a simple one-step for one-step relation :(
13:07:28 <ski> palomer : the optimised CPS transforms that are in those papers i pointed you to, fares better here, iirc (but i don't recall how close to one-step for one-step then come .. possibly it was exact, if not doing last-call-optimisation ("tail-recursion"-optimisation))
13:08:03 <ski> (s/then come ../they come ../)
13:09:11 <palomer> I still don't understand why we need a cbv CPS and a cbn CPS
13:09:27 <wagle> where does that show up?
13:10:14 <ski> one for choosing cbv CPS, and building/fixing that into the resulting transformed term   and    one for choosing cbn CPS, ...ditto..
13:10:45 <ski> (wagle : where does what show up ?)
13:10:49 <wagle> CPS in cbv and CPS in cbn will do things in a different order
13:11:06 <wagle> ski: cbv vs cbn CPS
13:11:55 <ski> maybe we should take a small example ?
13:12:12 <ski> e.g. "(\x. \y. y) ((\t. t t) (\t. t t))" :)
13:12:58 <Enveigler_> shapr: The 94Steele paper appears to be about addressing the problem that monads are(were?) incomposible: <cite>"However, the monad approach has a problem. In general, it is not possible to compose two monads to obtain a new monad [26]. A proposed solution was the use of monad transformers which transform a given monad into a new one adding new operations"</cite> Is that a fair summary?
13:13:09 <wagle> M_cbv[e1 e2] r k = M[e1] r (\v1 -> M[e2] r (\v2 -> v1 v2 k)
13:13:34 <ski> r is what ?
13:13:38 <ski> rho ?
13:13:53 <wagle> M_cbn[e1 e2] r k = M[e1] r (\v1 -> v1 e2 k)  {or some such)
13:13:58 <wagle> rho
13:14:02 <wagle> environment
13:14:09 <ski> skip that
13:14:27 <ski> that's not necessary for CPS transform
13:14:51 <ski> (but one can use it in CPS style interpreter, e.g.)
13:15:27 <ski> M_cbv[e1 e2] k = M_cbv[e1] (\v1 -> M_cbv[e2] r (\v2 -> v1 v2 k)
13:15:40 <ski> arg
13:15:41 <shapr> Enveigler_: You left out the part about modular monadic interpreters and how the different layers of semantics are defined with different monads.
13:15:44 <ski> M_cbv[e1 e2] k = M_cbv[e1] (\v1 -> M_cbv[e2] (\v2 -> v1 v2 k)
13:16:06 <ski> M_cbn[e1 e2] k = M_cbn[e1] (\v1 -> v1 M_cbn[e2] k)
13:17:15 <palomer> what does the M stand for?
13:17:29 <wagle> yeah, i was unhappy with the naked e2
13:18:12 <ski> palomer : meta-syntactic variable sometimes used for expression,  like  M,N ::= x  |  \x. M  |  M N
13:18:15 <wagle> M == Meaning od
13:18:18 <ski> aha
13:18:24 <ski> ok, can be that too, yes
13:18:30 <wagle> jjuumeaning of
13:18:45 <wagle> (keyboard jam)
13:18:47 <palomer> M stands for CPS?
13:18:55 <Enveigler_> shapr: I took the "modular monadic interpreter" to be the POC of the method used to address the problem described?
13:18:55 <ski> that is typical of denotational sematics
13:19:05 <ski> palomer : not specifically
13:19:30 <shapr> Enveigler_: What's POC?
13:19:39 <Enveigler_> Proof of concept.
13:19:46 <wagle> M is an interpreter
13:20:21 <palomer> what does M_cbv stand for in this case?
13:20:27 <palomer> what does it represent
13:20:28 <shapr> What qualifies as a proof of concept? Modular monadic interpreters are quite common in the Haskell world now.
13:20:35 <wagle> CPS is a source-to-source transformation, that mimics what a continuation based interpret would do
13:20:44 <ski> palomer : cbv variant of M ?
13:20:57 <wagle> Msubscript cbv
13:21:05 <palomer> ski: and what does M represent in this case?
13:21:15 <wagle> i have about a 1 second lag for each keypress
13:21:34 <Enveigler_> In terms of the paper, the MMI is the POC of Steele's approach to making monads composible.
13:21:46 <ski> palomer : just 'interpreter' or 'meaning of' or 'denotation of'
13:22:17 <palomer> ski: ah
13:23:51 <shapr> Well, modular interpreters and stacked monads were both research goals at the time. Monad transformers are the best solution discovered for stacked monads, and monad transformers make very nice modular interpreters as well. The paper is an excellent example of user definable semantics in a monad.
13:24:06 <reffie> lalalalla
13:24:08 <reffie> i'm so happy
13:25:14 <palomer> gah!
13:25:15 <palomer> he left
13:25:25 <reffie> :(
13:25:44 <palomer> wagle: how does it imitate a continuations based interpreter?
13:27:35 <wagle> palomer: did you follow what M did above?
13:28:05 <SyntaxNinja> shapr: dija like my file numbering thingy?
13:28:13 <gaal> hello lambdas! has -Mheap_size been renamed to -H in ghc 6.5?
13:28:28 <palomer> wagle: it looks like a CPS transformation
13:29:03 <gaal> my --make dies on heap exhaustion, and suggests -Msize, but using that gives  a command line error.
13:29:36 <gaal> ghc --help says -M does something else than the docs do
13:29:36 <wagle> palomer: yes, but the interpreter is doing it -- behind the scene -- to evaluate the program, which is not in CPS form
13:29:45 <Enveigler_> shapr: Okay, I accept that. But :) (I do hope you are smiling) ... that starts with the premise that monads are desirable. Most languages do not have (or need) monads, but it is perfectly possible (and in my current opinion; easier) to write interpreters in those other languages. There are even several other langauges that are perfectly able to provide functional operations and even lazy operations, that manage to deal with non-f
13:29:45 <Enveigler_> (IO / state/ exceptions etc.) without the complexities that moads introduce?
13:29:47 <Igloo> -M and -H mean what they always did AFAIK
13:29:54 <gaal> oh: my ghc-6.5 isn't a very new snapshot.
13:30:08 <Igloo> You need to be inside +RTS, don't forget
13:30:17 <gaal> aha!
13:30:23 <gaal> i'll try that.
13:30:44 <palomer> wagle: but in the end ,how do you get the original term back?
13:30:47 <rafl_> Hello. Is there a way to tell ghc6 to look at a special directory to find modules which aren't registered yet?
13:31:04 <palomer> wagle: I mean, the result is going to be in CPS form
13:31:28 <gaal> what does -H outside an +RTS say?
13:31:29 <Lemmih> rafl_: -idir
13:31:32 <wagle> palomer: an interpreter takes programs as input and emits values as output
13:31:52 <SyntaxNinja> Lemmih: you owe me some email :)
13:31:55 <shapr> Enveigler_: One desirable part of monads is that they are a way to separate different concerns into different pieces, such as an error monad, environment monad, and other pieces of an interpreter. Maybe you could compare other ways of abstracting interpreter pieces to a monad transformer based interpreter so you could see the benefits?
13:32:24 <Lemmih> Urk. That's right.
13:32:25 <palomer> wagle: sure, but don't we want M_cbv[t] = u iff u is in WHNF and t is beta/eta equivalent to u?
13:32:49 <wagle> the M interpreters above used (its concept of!) continuations to represent "what to do next (with the results of intermediate evaluations)
13:33:28 <shapr> Enveigler_: I've written a lot of code that needed clear separation of concerns. For most of the code I've written, monads would clearly be better than objects. (though not *all* of the code I've written is that way)
13:33:36 <wagle> M_cbv[t 2] == ?
13:34:19 <palomer> wagle: does that make sense?
13:34:29 <wagle> M_cbv[t 2] k == M_cbv[t] (\v -> v 2 k)
13:34:41 <wagle> M_cbv[t 2] k == u (\v -> v 2 k)
13:34:46 <palomer> what's M_cbv[2] ?
13:35:01 <wagle> M_cpv[2] k = k 2
13:35:33 <Enveigler_> shapr: That's where you defeat my arguments by default. I don't have the sufficient knowledge of using monads such that I am capable of making that comparison, or arguing the case one way or the other. :(
13:36:01 <wagle> M_cbv[t 2] k == M_cbv[t] (\v1 -> M_cbv[2] (\v2 -> v1 v2 k))
13:36:25 <wagle> i was trying to keep it simple
13:37:09 <palomer> so M_cbv[t] always returns a value?
13:37:34 <reffie> Google
13:37:37 <shapr> Enveigler_: The most useful suggestion I can make is to write a simple interpreter (scheme maybe?) based on one of the modular monadic interpreter papers, and write one or more other interpreter(s) using other abstractions, then compare. I'd very much like to see what you end up with.
13:37:47 <wagle> M_cbv :: expression -> continuation -> value
13:38:04 <rafl_> Lemmih: Hm. That gives me something like /usr/bin/ld: dir: No such file: File format not recognized
13:38:19 <wagle> continuation :: value -> value
13:38:52 <wagle> M_cbv[t] :: continuation -> value
13:38:52 <palomer> wagle: in a standard interpreter, if you have a function A->B and you pass an element of A, you get an element of B, is there an analogous statement for continuations based interpreters?
13:39:11 <Lemmih> rafl_: Did you put a space between -i and the directory?
13:39:38 <wagle> palomer: give an example?
13:39:51 <palomer> wagle: an example of what?
13:40:33 <rafl_> Lemmih: No.
13:40:48 <wagle> palomer: i find two meanings for your question, and dont know which one you are asking
13:41:01 <palomer> say t is int -> int, we've shown M_cbv[t 2] = u (\v -> v 2 k) which is not of type int
13:41:23 <Enveigler_> shapr: My gut reaction to your 'separation of concerns' argument, is an Exception class and an Environment class etc. Quite normal OO stuff. My attempts to do anything with Monads end up being frustrating exercises in trial and eror and guesswork and never knowing quite why one thing works and another doesn't as I mentioned earlier.
13:41:31 <Lemmih> rafl_: How did you invoke GHC?
13:41:42 <rafl_> Lemmih: Ah, I did multiple -i instead of -idir1:dir2...
13:42:04 <Enveigler_> shapr; Thanks for taking the time to converse.
13:42:06 <wagle> M_cbv[t 2] id :: int
13:42:59 <wagle> id == identity function == "initial continuation"
13:43:04 <palomer> oh, so to interpreting a term t is equivalent to evaluating M_cbv[t] id
13:43:18 <wagle> palomer: correct
13:44:16 <rafl_> Lemmih: Hm. So is there also such a possibility for the setup program generated by ghc6 -package Cabal Setup.hs -o setup?
13:44:30 <palomer> and M_cbv[t] == CPS[[t]], right?
13:45:18 <wagle> M_cbv[t] == M_cbv[CPS[t]]
13:47:08 <rafl_> Lemmih: I want to build two modules without installing them. But one depends on the other.
13:47:21 <Lemmih> rafl_: There should be a Hs-Src-Dir field in the Cabal description file.
13:47:40 <Lemmih> rafl_: How about: ghc --make ModuleOne.hs?
13:47:44 <palomer> t is alpha/beta equivalent to M_cbv[t] id == M_cbv[CPS[t]] id which is alpha/beta equivalent to CPS[t]
13:47:55 <palomer> wagle: this seems...false
13:47:56 <Lemmih> GHC will automatically compile the other module.
13:49:06 <wagle> M_cbv[lambda i e] k = k (\v' k' -> extend environment with (i, v') for M[e] k')
13:49:26 <wagle> CPS :: expression -> expression
13:50:57 <wagle> M_cbv[call/cc e] k = M_cbv[e] (\v -> v (\v' k' -> k' v') k)
13:51:24 <palomer> wagle: isn't t alpha/beta equivalent to M_cbv[t] id?
13:52:22 <wagle> notice that the interpreters continuations are type value->value, but procedures are type value->continuation->value
13:52:58 <wagle> and when the interpreter hands its continuations off to the program with call/cc, it has to turn them into procedures
13:53:16 <wagle> ohhh
13:53:46 <wagle> i overloaded the word "value"
13:54:11 <wagle> palomer: in the lambda calculus, "value" is a kind of expression
13:54:23 <palomer> I thought it was terms in WHNF
13:54:44 <wagle> palomer: to M, "value" is completely distinct from expressions
13:55:21 <wagle> i almost used "answer" instead of "value"
13:55:41 <wagle> so M_cbv :: expression -> continuation -> answer
13:55:53 <palomer> and answer is in WHNF?
13:56:09 <palomer> and answer is alpha/beta equivalent to expression when the continuation is the identity?
13:56:14 <wagle> answer = int + procedures
13:56:55 <wagle> the interpreter is written in a meta-language
13:57:17 <wagle> the meta-language might be the same (or similar) to the language it interprets
13:57:28 <palomer> in this case, it's the same language
13:57:33 <palomer> oh, wait
13:57:34 <palomer> nevermind
13:57:47 <palomer> yes yes, I understand this
13:58:30 <palomer> wagle: could you answer my last question?
13:58:51 * wagle thinks
13:59:30 <wagle> answer union expression = the empty set
13:59:39 <wagle> usually..
14:00:09 <palomer> so of what use is the answer?
14:00:12 <wagle> i'm thinking about allowing answer to be expressions-in-weak-head-normal-form
14:00:32 <wagle> 2 the answer is different than 2 the program
14:01:26 <wagle> evaluation is reducing programs to values
14:01:41 <wagle> normalization is reducing programs to programs-in-normal-form
14:01:56 <wagle> most programming languages evaluate.
14:02:12 <wagle> the lambda calculus normalizes
14:02:51 <palomer> when reducing programs to values, usually the values have some relation to the program
14:02:55 <palomer> in this case: what is it??
14:02:59 <palomer> what's the point of all this?
14:03:21 <wagle> i confused you by detouring into the lambda calculus (normalization), then switching back to evaluated languages without being clear that i was doing that
14:04:22 <wagle> its the historical approach to continuations
14:04:44 <palomer> nonono, I'm confused about the use of M_cbv[t]
14:05:01 <palomer> if I'm evaluating t to an answer, I want there to be some relation between t and the answer
14:05:04 <palomer> what is it in this case?
14:05:20 <wagle> continuations started out in denotational semantics, then moved to scheme as procedural value
14:05:31 <wagle> palomer: i hear you
14:06:59 <wagle> expressions and answers are both meta with respect to the M_cbv interpreter
14:07:36 <wagle> interpreters arent normalizers
14:07:46 <wagle> usually
14:08:30 <wagle> to an interpreter, expressions are one data type, and answers are another data type
14:08:47 <wagle> the interpreter itself has a representation
14:09:17 <palomer> yeah, sure
14:09:38 <palomer> in this case, the datatypes are the same though
14:09:42 <wagle> if the interpreters representation is "the same as" the expression data type, then the interpreter is "meta-circular", and can be used to interpret itself
14:10:34 <Lemmih> SyntaxNinja: I'll write an install rule for modhaskell if you poke me a little bit. (:
14:11:55 <wagle> palomer: notice that the interpreter is in CPS, but can interpret programs that arent in CPS
14:12:12 <palomer> the interpreter is in CPS?
14:12:15 <palomer> eh?
14:12:26 <wagle> CPS expressions are a subset of expressions
14:13:07 <wagle> the interpreter is written in a continuation passing style subset of its host language
14:13:20 <palomer> hrmph, I still don't see what's the point of finding the value of t
14:13:47 <palomer> wagle: why must the interpreter be written in CPS?
14:13:55 <palomer> can't I write it any way I want?
14:14:08 <palomer> the interpreter is M_cbv in this case
14:14:39 <ski> one can use the CPS transform more or less as an interpreter
14:14:58 <wagle> palomer: its doesnt need to be in CPS, its just easier to expression the semantics of some hairy control structures easier if you use continuations in the interpret
14:15:13 <wagle> ... express the semantics of some ...
14:15:50 <palomer> okok, lets get back to the answer, ie M_cbv[t], I'm really confused as  to the point of this guy
14:16:19 <palomer> if I say "intepret t" and you give me back M_cbv[t], I'll be like "what is this?"
14:16:41 <wagle> M_cbv[t] is a function that takes a continuation and returns an answer
14:17:02 <palomer> and whats this answer?
14:17:11 <wagle> "i have an answer, where do you want me to send it?"
14:17:13 <wagle> or
14:17:26 <wagle> "i have an answer, what do you want me to do with it?"
14:17:57 <palomer> is what do you want me to do with it
14:18:11 <wagle> M_cbv[2] =...=> \k -> k 2
14:18:29 <wagle> M_cbv[2] id=...=> 2
14:18:35 <palomer> AH
14:18:40 <wagle> M_cbv[2] id =...=> 2
14:18:55 <palomer> so M_cbv[t] id is alpha/beta equivalent to t?
14:19:07 <wagle> M_cbv[2] (\k -> 3) =...=> 3
14:19:33 <palomer> and M_cbv[t] k is alpha/beta equivalent to k t?
14:20:28 <wagle> k :: continuation = answer -> answer
14:20:56 <wagle> so if answer == expression, then yes, alpha/beta equivalent
14:21:08 <wagle> (answer subset of expression?)
14:21:56 <palomer> look at M_cbv as simply a function mapping pairs of lambda terms to lambda terms
14:22:04 <palomer> is this statement true or false:
14:22:17 <ski> 'M_cbv[t] id' is not always alpha/beta equivalent to t
14:22:30 <palomer> thank you:P
14:22:41 <palomer> ski: so what's the point of M_cbv[t]?
14:22:57 <ski> cbv CPS transforming ? :)
14:23:24 <wagle> ski: i've separated CPS and M_cbv
14:23:33 <wagle> CPS :: expresssion -> expression
14:23:38 <ski> aha
14:23:40 <ski> hm
14:23:45 <wagle> M_cbv :: expression -> continuation -> answer
14:24:08 <ski> so M_cbv takes an already CPS transformed term ??
14:24:09 <wagle> M_cbv[t] == M_cbv[CPS[t]]
14:24:09 <palomer> say I want to evaluate + 2 2 to get 4, how would I do this with M_cbv?
14:24:29 <ski> wagle : which CPS transform ?
14:24:33 <wagle> and normalization vs evaluation
14:24:50 <palomer> wait, you've changed M_cbv?
14:25:16 <wagle> i'm just stressing that CPS is a source to source transformation, and M_cbv might not be
14:25:18 <ski> wagle : you mean M_cbv[t] == M_cbv[CPS_cbv[t]] ??
14:26:08 <ski> anyway, i have CPS transformed '(\x. \y. y) ((\t. t t) (\t. t t))'
14:26:12 <wagle> probably..  CPS == CPS_cbv to me for the past many many years until today
14:26:26 <ski> if you wanna compare the cbv and cbn CPS transform result ..
14:26:31 <palomer> so what in the blazes is this new M_cbv?
14:26:51 <wagle> i've been using the same M_cbv all along
14:27:01 <palomer> the one ski used?
14:27:37 <wagle> palomer: quote him?
14:27:59 <ski> wagle : is M_cbv a CPS-style interpreter using call-by-value strategy for reducing/interpreting the term ?
14:28:04 <palomer> <ski> M_cbv[e1 e2] k = M_cbv[e1] (\v1 -> M_cbv[e2] (\v2 -> v1 v2 k)
14:29:00 <wagle> palomer: thats the same as mine
14:29:25 <palomer> that looks like CPS to me
14:29:30 <wagle> ski: yes
14:29:37 <ski> wagle : ok
14:29:53 <palomer> so how would I get 4 from M_cbv[+ 2 2] ?
14:30:00 <wagle> palomer: its cps in the meta (host) language that the interpreter is written in
14:30:06 <ski> wagle : but you have a rho (environment), also, yes ? or did you skip that ?
14:30:26 <palomer> M_cbv is the interpreter
14:30:33 <wagle> "same" up to the environment elimination
14:30:34 <palomer> I don't see why it matters in which language its written in
14:30:50 <wagle> i can write M in fortran
14:30:59 <palomer> sure
14:31:09 <ski> M_cbv[\x. e] k = k (\x. M_cbv[e])
14:31:15 <ski> wagle : you have that ?
14:31:37 <wagle> ski: somewhere above
14:31:49 <ski> wagle : but that's not in CPS :)
14:32:03 <wagle> 13:50 < wagle> M_cbv[lambda i e] k = k (\v' k' -> extend environment with (i,
14:32:03 <wagle>                v') for M[e] k')
14:32:06 <wagle> 13:51 < wagle> M_cbv[call/cc e] k = M_cbv[e] (\v -> v (\v' k' -> k' v') k)
14:32:18 <palomer> whoa, environments?
14:32:48 <ski> yes, an optimisation
14:33:12 <palomer> oh my.
14:33:19 <ski> to avoid direct substitution (doing it lazy, so to speak)
14:34:17 <wagle> ski: how is it not in CPS?
14:34:24 <ski> (s/lazy/lazily/)
14:34:42 <wagle> .. its a tail call
14:34:42 <ski> wagle : hm, wait
14:34:50 <palomer> brb
14:35:58 <wagle> shift is often written in non-CPS
14:36:17 <ski> wagle : sorry, i confused it :) the corresponding CPS transform rule is not in CPS :), but as an interpreter (only (and possibly repeatedly) calling recursively when the "\v -> ,,," is called) it is in CPS :)
14:36:25 <ski> wagle : yes
14:37:16 <wagle> M[shift e] k = M[e] (\v -> v (\v' k' -> (k . k') v') id)
14:37:18 <ski> wagle : if you do the CPS-transform, you'll have the tranforn rule being nqCPS (not-quite-CPS :), for which you can use shift/reset (even prompt/control iirc)
14:38:30 <ski> wagle : yes
14:38:57 <wagle> ski: you know scheme?  know what engines are?
14:39:17 <ski> i know some scheme
14:39:32 <ski> i'm not sure what engines are ..
14:39:51 <ski> (it's not in R5RS, is it ?)
14:40:00 <wagle> you can turn a thunk into an engine
14:40:10 <wagle> (might be R4RS)
14:40:31 <ski> (maybe it's not programmer level, but implementation level ..)
14:40:41 <wagle> an engine takes an integer and a success and failure "continuation"
14:41:03 <wagle> the integer is "fuel" (or "time")
14:41:30 <ski> is failure for "not done" ?
14:41:50 <wagle> if the computation ends before the fuel is consumed, then the success function is invoked on the answer (and the amount of remaining fuel)
14:41:57 <ski> is the number for "ticks" (steps) or real/clock/system/user/whatever time ?
14:42:28 <wagle> if the fuel runs out, then the failure function is invoked on a new engine that represents the remainder of the computation
14:42:48 <wagle> in scheme-84, it was steps of the interpreter
14:43:01 <wagle> in chez scheme, it was time (polled)
14:43:31 <wagle> thus timed-preemption could be modeled (and os's written in scheme)
14:43:43 <ski> ok
14:44:50 <wagle> anyway, they made the engines into (what i called) subcomputations, and so call/cc grabbed only the remainder of the engine's computation, and not the host's continuation..  thus you had something very much like shift and reset
14:46:25 <ski> yes, a bit similar, it sounds like
14:49:31 <wagle> thats how i discovered shift/reset, so i prefer thinking in terms of subcomputations than "concatenated continuations"
14:50:20 <wagle> ... but a naive notion of subcomputations is a bit too concrete
14:50:42 <wagle> (havent thought about this for a while..)
14:51:33 <ski> ok
14:52:10 <ski> i discovered them by reading 'Abstracting Control' and 'Representing Control' :)
14:53:37 <wagle> ski: werent written yet..  8)
14:54:58 <wagle> though bob was there when i described "warp engines"
14:55:42 <ski> bob ?
14:55:45 <wagle> hieb
14:56:19 <ski> do not recognize ..
14:56:29 <wagle> representating control
14:57:11 <wagle> oh..  there's an oliver representing control paper too
14:59:28 <ski> http://citeseer.ist.psu.edu/danvy92representing.html  http://citeseer.ist.psu.edu/danvy90abstracting.html
14:59:35 <ski> those two, i'm thinking of
14:59:55 <ski> Olivier Danvy and Andrzej Filinski
15:00:04 <wagle> he was doing a lot of interesting stuff with CPS around 1990..  i pinged him about where that went around 2000, and he said filinski took off with it..  tried to read filinski.  eee
15:00:49 <ski> mhm
15:01:15 <wagle> i took category theory after that, but didnt try again (yet)
15:01:27 <ski> as a course ?
15:01:45 <ski> (or on your own ?)
15:02:16 <xerox> dcoutts_: hi, there's a good news and a bad news, I'll probably post tomorrow morning.  Your work is promising, thanks much.  Mail me any detail :-)  Going to bed.
15:03:41 <wagle> course
15:04:11 <wagle> there's a bit of a hump to get over to get started
15:05:13 <wagle> took me something like a month to get over it..  which explains why the "couple days here" "couple days there" approach over the previous years didnt get anywhere
15:05:39 * ski 's only read CT on his own
15:05:59 <wagle> i came out totally amazed at what a major constrain associativity was
15:06:03 <wagle> constraint
15:06:23 <ski> heh
15:06:26 <wagle> i'd thought it pretty weak before that
15:07:51 <wagle> now i need to finish plowing through barr & wells 3ed
15:08:52 <ski> m
15:09:18 * ski 'll leave for bed
15:09:25 <ski> goodnight
15:09:28 <wagle> nite
15:17:18 <ocarina> greetings
15:18:27 <astrolabe> hi
15:19:00 <Excalibor> what's up?
15:19:55 <astrolabe> hmmm.  Not my eyelids, unfortunately.
15:20:34 <Excalibor> oops
15:22:50 <ape> hey, who knows german? what is Fudliburger?
15:23:09 <ape> hm... it just occurred to me that this might be a naughty word, if so please ignore
15:23:37 <Lemmih> @babel de en Fudliburger
15:23:40 <lambdabot>  Fudliburger
15:23:47 <Lemmih> @babel de en Fudli burger
15:23:49 <lambdabot>  Fudli more burger
15:24:13 <wagle> @google Fudliburger
15:24:14 <lambdabot> http://www.radio.rai.it/radio3/razione_k/fudliburger.cfm
15:24:23 <wagle> http://translate.google.com/translate?hl=en&sl=it&u=http://www.radio.rai.it/radio3/razione_k/fudliburger.cfm&prev=/search%3Fq%3DFudliburger%26hl%3Den%26lr%3D%26c2coff%3D1%26client%3Dsafari%26rls%3Den-us
15:25:37 <wagle> all clear now?  8)
15:26:34 <ape> not exactly... but i now know that "the Fudliburger is one of the great contributions of Switzerland to the European culture"
15:48:23 <palomer> back
15:48:32 <palomer> and I still don't get what interpreting a term means
15:54:13 <Excalibor> time for bed
15:54:17 <Excalibor> take care
16:04:16 <ape> hm... there's this website of this project in design stage where this guy is trying to make his own programming language and operating system
16:04:20 <ape> i can't seem to find it
16:04:30 <ape> starts with the letter e
16:36:12 <Number17> So, I'm still trying to find a project to learn haskell with.  No parsing things at work recently.  Any ideas for a short simple, yet interesting project for the purpose of learning?
16:41:27 <shapr> Something mathy?
16:41:44 <Number17> yea; I was thinking of maybe a physics simulation of some sort
16:42:34 * Pseudonym yawns
16:42:39 <Pseudonym> Need caffeine, I think.
16:43:07 * Number17 gives Pseudonym a double shot of espresso
16:43:14 <Pseudonym> Mmmm... espresso...
16:43:33 <wagle> Number17: my HelloWorld program in each new language is to write a scheme interpreter..  8)
16:43:44 <Pseudonym> Mine is to write Eliza.
16:43:46 <SyntaxNinja> Number17: you might look t the ICFP contest problems
16:43:46 <Number17> Espresso : Steak :: Coffee : Chuck
16:44:02 <Number17> err, Steak -> Filet Migon
16:44:12 <wagle> i like SyntaxNinja 's idea
16:44:21 <Number17> yea, it does sound good
16:44:32 <Pseudonym> While I like espresso, I have been turned onto the wonders of French coffee in recent years.
16:44:51 <wagle> French coffee?
16:48:29 <wagle> the scheme interpreter in jasva was quite interesting..  the one in haskell was boring..  of course, i couldnt (then) figure out how to use type classes well..  hmm..
16:48:37 * wagle rethinks
16:48:49 <wagle> s/jasva/java/
16:49:17 * Pseudonym nods
16:50:29 <wagle>  .sympatico.ca] has quit ["Leaving"]
16:51:34 <shapr> ?
16:51:50 <shapr> Anyone here plays the marble game enigma?
16:51:50 <wagle> runaway mouse (touchpad)
16:52:42 <Igloo> I've played it
16:52:50 * Number17 tries to decide whether to write Ant AI or a lisp parser
16:52:57 <shapr> Igloo: Have you beaten all the Enigma1 levels?
16:53:21 * Number17 has never written AI before, so he thinks that maybe he'll do that
16:53:42 <Igloo> DYM "Enigma" level pack?
16:53:44 <Number17> thanks for the idea, ICPF 2004's contest it is
16:53:57 <Igloo> 94% of 141 if so
16:54:38 <shapr> Do you think you'll remember the solution to some of the trickier ones like Need More Money?
16:54:49 <Igloo> What number is it?
16:55:01 <wagle> shapr: i think i played something like that a few years ago
16:55:13 * Igloo goes to messages to avoid spoilering for others
17:07:19 <Cale> Need More Money is cheap
17:07:28 <Cale> there's a seed hidden somewhere iirc
17:07:58 <Cale> you use it to form a block, which you can push over the money to make it worth more, if it's the level I'm thinking of
17:09:25 <Cale> hmm... which number is it?
17:10:23 <Cale> hmm, maybe that wasn't the level I'm thinking of
17:11:09 <shapr> Nah, Igloo gave me the hint I needed to solve it.
17:11:51 <shapr> I really enjoy enigma, it's a great programmer's game.
17:11:55 <Cale> "Send More Money" has a secret passage in the third room which leads back into the second
17:12:22 <Cale> Is that the one?
17:12:25 <shapr> Yeah.
17:12:35 <shapr> But I prefer small hints, so hopefully I can solve it myself.
17:12:45 <shapr> Igloo just told me there's a block you can move.
17:12:47 <shapr> That worked.
17:13:06 <wagle> need hdaps to do marble madness:
17:13:10 <wagle> http://lkml.org/lkml/2005/7/11/97
17:13:38 <wagle> what url for enigma?
17:14:02 <shapr> http://www.nongnu.org/enigma/
17:14:07 <shapr> Or apt-get install enigma
17:15:44 <wagle> $ port search enigma
17:15:44 <wagle> No match for enigma found
17:15:47 <wagle> 8(
17:17:39 <shapr> Anyone read the QuickCheckM paper? I'm trying to figure out how to make monadic properties.
17:18:22 <wagle> ooo..  they did a macosx port
17:18:26 <shapr> I have a pure QuickCheck property that uses unsafePerformIO to get results from gnu dc, but I want a PropertyM.
17:19:05 <wagle> you used pure and unsafe in the same sentence! </beavis>
17:19:16 <shapr> Well, it's only sorta pure.
17:19:39 <wagle> pure mud?
17:19:43 <shapr> Something like that.
17:19:49 <wagle> pure as the sucking mud
17:20:48 <wagle> its not like i can get over needing array updates to be in place instead of by copies
17:21:17 <wagle> www.cs.chalmers.se/~rjmh/Papers/QuickCheckST.ps ?
17:21:28 <shapr> Yup, that's it.
17:23:39 <wagle> the name server is dead!  may it rest in pieces
17:28:36 <wagle> enigma is bizarre..
17:28:46 * wagle starts skimming paper
17:29:50 <wagle> oooowwwww..  i played enigma for 1-2 minutes, and already i'm expecting trouble getting my mouse to stop when clicking on the previewer
17:31:41 <wagle> haha! "haskell is the world's finest imperative programming language!"
17:37:40 <Pseudonym> Lambda: The ultimate bug.
17:38:09 <wagle> Pseudonym: all programming should be pointless?
17:38:21 <Pseudonym> It arguably alread is.
17:39:22 <wagle> augh..  and i cant even throw myself upon my program in my anguish
17:56:38 <wagle> shapr: why do you use unsafePerformIO?  (and why dc?)
20:05:12 <MachinShin> hey all
20:46:36 <lisppaste2> metaperl pasted "any feedback on this function? would you write it differently?" at http://paste.lisp.org/display/10097
20:49:57 <dons> instead of if val == mx then 1 else 0, you could write: fromEnum $ val == mx
20:50:17 <dons> @eval fromEnum $ 1 == 1
20:50:23 <lambdabot> 1
20:50:25 <dons> @eval fromEnum $ 1 == 0
20:50:26 <lambdabot> 0
20:50:37 <metaperl> dons: sweet
20:51:39 <dons> also, mx_count = sum $ map tallypos [x,y,z]
20:51:51 <dons> sorry, [a,b,c]
20:53:41 <metaperl> dons: do you have any feedback on variable naming style? mx_count versus mxCount?
20:54:10 <dons> maybe mxCount is more Haskellish, but that's up to you
20:54:27 <gzl> why write "mx"? it seems gratuitously abbreviated
20:54:35 <dons> hmm.     mx = max d c
20:54:35 <dons>     d = max a b
20:54:38 <dons> looks like a fold?
20:55:18 <metaperl> gzl: max is reserved as a function name... cant use it
20:55:33 <dons> @eval foldl1 max [1,3,2,4,0,1]
20:55:34 <lambdabot> 4
20:55:41 <gzl> so write maximum
20:55:46 <gzl> much clearer than 'mx'
20:56:21 <metaperl> gzl: point taken
20:56:23 <dons> so metaperl, mx = foldl1 max [a,b,c]
20:56:54 <dons> and mxCount = sum $ map tallypos [a,b,c]
20:57:10 <metaperl> yup. got it
20:57:15 <metaperl> thanks for the input
20:57:48 <gzl> the nice side effect of dons' cleanup is that it has nothing to do with 3 arguments anymore
20:58:05 <gzl> (and it shouldn't)
20:58:09 <metaperl> yes, I had been wondering how to write a scaleable function
21:02:07 <dons> also, I think mxCount = sum $ map (fromEnum . (mx ==)) [a,b,c]
21:02:23 <dons> then no need for tallypos, but this change is debatable
21:02:38 <gzl> if you do want tallypos, I think you owe it a better name
21:02:44 <dons> yup
21:03:04 <dons> but it's just fromEnum . (mx ==), so maybe isMaximum ?
21:04:08 <gzl> I think this might be easier to read:
21:04:21 <gzl> length (filter (== maximum) [a,b,c])
21:04:38 <dons> yep, that's good
21:05:19 <dons> so maybeat this point generalise the type to something like: maxOccurs :: Ord a => [a] -> (a,Int)
21:05:34 <gzl> yep
21:05:50 <dons> because it's really a list function after all
21:05:53 <gzl> right
21:07:44 <dons> oh, mx is already redundant, we have Ddata.List.maximum :: Ord a => [a] -> a
21:07:55 <gzl> oh, I thought you knew that already
21:08:00 <dons> @eval maximum [1,2,4,2,14,5,2]
21:08:01 <lambdabot> 14
21:08:04 <gzl> I assumed you wanted to rewrite it for some reason :)
21:08:06 <dons> i'd forgotten it was called maximum
21:09:37 <gzl> the prelude is good
21:10:47 <gzl> dons: if it's any consolation, maximum = foldl1 max :)
21:11:41 <dons> :)~[6~[6~[6~[6~[6~[6~[6~[6~
21:11:54 <liyang> Saving all of 3 keystrokes!
21:12:33 <dons> silly wireless.
21:13:44 <dons> liyang, those 3 keystrokes could save your life one day ;)
21:16:55 <Pseudonym> A keystroke saved is a keystroke earned.,
21:17:09 <liyang> How do I avoid the monomorphism restriction when returning a function (as a value) in a monad? I can't seem to come up with the right type signatures...
21:17:31 <liyang> And a keystroke spent on IRC is a keystroke wasted. ;)
21:17:42 <dons> -fno-monomorphism-restriction, if you're lazy :)
21:17:51 <dons> but really a type signature is best
21:17:56 <dons> perhaps use ghci to find the type
21:18:03 <Pseudonym> Another option is don't use lambdas.  Give your function a name.
21:18:05 <liyang> e.g. do { f <- foo bar ; f a ; f b }
21:18:11 <Pseudonym> Oh, and don't use currying.
21:18:27 <Pseudonym> @type let foo = show in foo
21:18:30 <lambdabot> forall a. (Show a) => a -> String
21:18:41 <Pseudonym> Hmmm.  OK, let-polymorphism wins again.
21:18:48 <liyang> :)
21:19:11 * liyang tries to write up a short example.
21:19:17 <Pseudonym> Probably a good idea.
21:39:19 <liyang> mmkay, here: http://www.haskell.org/hawiki/HaskellIrcPastePage
21:42:58 <liyang> in fact, here's a one-liner version: return show >>= \foo -> foo 1 ++ foo "a"
21:47:50 <Pseudonym> @plugs return show >>= \foo -> foo 1 ++ foo "a"
21:47:52 <lambdabot> <Plugins.Eval>:1:
21:47:52 <lambdabot>   No instance for (Num [Char])
21:47:52 <lambdabot>   arising from the literal `1'
21:48:28 <Pseudonym> @plugs return show >>= \(foo :: (Show a) => a -> Maybe ()) -> foo 1 ++ foo "a"
21:48:29 <lambdabot> Illegal signature in pattern: (Show a) => a -> Maybe ()
21:48:29 <lambdabot>    Use -fglasgow-exts to permit it
21:49:06 <Pseudonym> OK, in your example, did you try putting a type signature on getFn?
21:51:10 <Korollary> @plugs return show >>= \foo -> (foo 1) ++ (foo "a")
21:51:11 <lambdabot> <Plugins.Eval>:1:
21:51:11 <lambdabot>   No instance for (Num [Char])
21:51:11 <lambdabot>   arising from the literal `1'
21:52:09 <Korollary> heh
21:52:59 <Korollary> @plugs (\foo -> (foo 1) ++ (foo "a")) show
21:53:00 <lambdabot> <Plugins.Eval>:1:
21:53:00 <lambdabot>   No instance for (Num [Char])
21:53:00 <lambdabot>   arising from the literal `1'
21:53:24 <liyang> Pseudonym: such as? getFn :: Monad m => a -> m (forall b. [b] -> Int)
21:53:33 <liyang> (that doesn't work.)
21:53:49 <Pseudonym> OK, I got a different error!
21:54:15 <Pseudonym> @plugs return show >>= \foo -> let { bar :: (Show a) => a -> String; bar = foo } in foo 1 ++ foo "a"
21:54:16 <lambdabot> <Plugins.Eval>:1:
21:54:16 <lambdabot>   Cannot unify the type-signature variable `a' with the type `[Char]'
21:54:16 <lambdabot>    Expected type: a
21:54:16 <lambdabot>    Inferred type: [Char]
21:54:16 <lambdabot>   In the first argument of `foo', namely `"a"'
21:54:19 <lambdabot>   In the second argument of `(++)', namely `foo "a"'
21:54:20 <lambdabot>  
21:54:22 <lambdabot> [5 @more lines]
21:54:23 <Pseudonym> Erm...
21:54:46 <Korollary> I got something else
21:54:47 <Pseudonym> @plugs return show >>= \foo -> let { bar :: (Show a) => a -> String; bar = foo } in bar 1 ++ bar "a"
21:54:49 <lambdabot> <Plugins.Eval>:1:
21:54:49 <lambdabot>   Inferred type is less polymorphic than expected
21:54:49 <lambdabot>    Quantified type variable `a' escapes
21:54:49 <lambdabot>    It is mentioned in the environment:
21:54:49 <lambdabot>     foo :: a -> String (bound
21:55:00 <Korollary> "Probable fix: add an instance declaration for (Num [Char])"
21:55:33 <liyang> Pseudonym: but you can't. Though bar can be as polymorphic as you want, foo can only be instantiated once...
21:55:44 <liyang> :-/
21:55:53 <Pseudonym> Maybe you could launder it.
21:56:12 * liyang ended up restructuring the code instead... 
21:56:22 <liyang> I would like to know how to get around it though...
21:56:32 <liyang> (or if not, why not. -_-;;)
21:57:02 <Pseudonym> OK, you can launder the type.
21:57:08 <liyang> ?
21:57:17 <liyang> What do you mean by that?
21:57:19 <Pseudonym> You're gonna love this.
21:57:22 <liyang> ...
21:58:24 <Pseudonym> Take a look at the paste page.
21:58:41 <liyang> (Someone should clear the paste page out... it's getting rather long...)
21:59:19 * liyang looks
21:59:38 <Pseudonym> I don't know if that technically has a name, but I call it "laundering".
21:59:41 <liyang> ...
21:59:46 <liyang> eww. XD
22:00:48 <liyang> There should be a page on the wiki for it. :)
22:01:07 <Pseudonym> You could add it to @wiki MonomorphismRestriction
22:02:01 <liyang> It's rank-2 polymorphism that I want isn't it... :(
22:02:53 <Pseudonym> Uhm... yeah, probably.
22:02:59 <Pseudonym> But that doesn't always help.
22:03:09 <Pseudonym> I tried to do that a couple of ways before I did the newtype trick.
22:03:46 <Pseudonym> The trouble is that let-polymorphism kicks in.
22:03:49 <Pseudonym> Oh!
22:03:52 <Pseudonym> Hang on, I think I have a solution.
22:07:11 * liyang thinks he misunderstood finite-rank polymorphism, after reading around a bit.
22:08:45 <Pseudonym> Nope, turns out that's not a solution either.
22:08:54 <Pseudonym> I would post this one to haskell-cafe.
22:09:39 <liyang> :)
22:10:14 * liyang puts that off for another day. More pressing things at hand... XD
22:10:44 * liyang also notes that it's been over a year since he's actually read either of the haskell* lists...
22:14:14 <liyang> Pseudonym: thanks for the help. :)
22:14:46 * liyang toddles off to do some more work
