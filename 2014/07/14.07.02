00:03:30 <jle`> copumpkin: i think i figured it out
00:03:39 <jle`> copumpkin: er... *ping*
00:06:09 <DarkLinkXXXX__> I'm having trouble installing hOpenPGP.
00:06:35 <DarkLinkXXXX__> Loading package bzlib-0.5.0.4 ... <command line>: can't load .so/.DLL for: libbz2.so (libbz2.so: cannot open shared object file: No such file or directory)
00:06:43 <DarkLinkXXXX__> More specifically, bzlib.
00:07:31 <DarkLinkXXXX__> But /lib/i386-linux-gnu/libbz2.so.1 exists, so me no comprehendo.
00:08:26 <merijn> Is that directory in cabal's linker path, though?
00:08:51 <merijn> There should be a --with-extra-lib-dirs flag or something along those lines in cabal's docs
00:12:50 <DarkLinkXXXX__> Nevermind.
00:16:51 <amosr> I just installed ghc 7.8.2 on OSX, and I’m getting linker errors like “ld: library not found for -lHStransformers-compat-0.3.3.4-ghc7.8.2” etc. anybody seen this?
00:29:08 <ninja_code> is it possible
00:29:11 <ninja_code> to do objective-c apps
00:29:12 <ninja_code> in haskell?
00:29:19 <ninja_code> either via swift or via objective-c directly?
00:30:18 <amosr> ninja_code: you may be interested in language-c-inline, which lets you put obj c code in haskell functions
00:30:32 <ninja_code> hmm
00:30:34 <ninja_code> so basically use FFI
00:30:42 <amosr> ninja_code: https://github.com/mchakravarty/language-c-inline
00:30:42 <ninja_code> I was hoping to write osx apps in haskell
00:30:44 <ninja_code> without learning objetive-c
00:30:48 <amosr> ah, right
00:31:06 <amosr> no, this is just a nicer way to do lightweight FFI, I guess
00:32:12 <ninja_code> doh
00:34:17 <xxen> What is the problem with plain Haskell to write OS X apps?
00:36:55 <ninja_code> someone
00:37:00 <ninja_code> needs to create a haskell plugin
00:37:04 <ninja_code> that lets me use swift for FFI
00:37:09 <amosr> xxen: I think it’s just that the libraries are so massive that it’s a lot of effort to write wrappers
00:37:13 <ninja_code> xxen: it can be fine; I just don't know how to do it
00:49:18 <johnw> probably easier to embed a Haskell library into a swift app, than to try to drive the whole process in Haskell
00:51:25 <tdammers> haven't paid a lot of attention, but generally speaking, I like the subprocess approach to polyglot projects
00:52:02 <tdammers> i.e., implement the parts as separate programs, and have them call each other as subprocesses
00:52:08 <johnw> yeah
00:52:08 <tdammers> communicate through pipes
00:52:26 <tdammers> there's some serialization overhead, but it's not usually a problem
01:09:17 <adas> I would like to install ghc and work with cabal sandboxes instead of the haskell-platform. I have a fresh install of ubuntu. Is there some resource for how i might proceed to install the latest ghc, cabal sandbox..?
01:09:58 <possiblywrong> https://github.com/bitemyapp/learnhaskell
01:10:21 <possiblywrong> adas: has some links and notes
01:10:49 <phadej_> adas: http://www.haskell.org/ghc/download_ghc_7_8_2
01:11:40 <adas> thans for the links. taking a look as we chat
01:12:32 <adas> by the way, is my method okay? i mean is this the typical way to write haskell code?
01:12:41 <adas> or do most folks just install the platform?
01:12:59 <ccapndave> Morning everyone
01:13:06 <adas> i've been using the platform for like a year now, and i want to start using sandboxes, thats why the move
01:14:24 <ccapndave> I am using IntelliJ as an IDE for Haskell, and the plugin just updated itself this morning and now it says it can't find some cabal dependencies.  The changelog for the new version says "Use ghc-modi instead BuildWrapper" and "On compilation use ghc from SDK".  Any idea how my packages might suddenly not be visible based on these clues?
01:15:22 <ccapndave> Specifically it says 'At least the following dependencies are missing: GA -any, json -any'.  I have these in build-depends and also did cabal install GA and cabal install json.  Is this the right way to do things?
01:15:44 <possiblywrong> adas: My 2c, platform is a pain. I find working with sandboxes much simpler
01:16:24 <alpounet> adas: just download a ghc binary and a recent enough cabal
01:16:27 <alpounet> and you should be good to go
01:17:05 <adas> possiblywrong: but everytime you create a new sandbox don't you find yourself waiting long time for the whole thing to finish compiling ..... again?
01:17:52 <possiblywrong> adas: I'll take that over broken deps and an ancient version of GHC
01:18:34 <adas> agreed
01:18:37 <mgomezch> I’ve been looking into nix as a way to tackle that precise problem. http://ocharles.org.uk/blog/posts/2014-02-04-how-i-develop-with-nixos.html
01:19:30 <mgomezch> It’s not fun at all to set up a new sandbox for an application with lots of dependencies.  It’s even less fun on a weak old netbook.  It’s actually quite painful when the dependencies include haskell-src-exts. ;)
01:19:57 <inforgx> pain in da arse
01:25:15 <adas> possiblywrong: that link is awesome. wish i saw that long ago.
01:25:20 <adas> but it looks like a new rrepo
01:35:37 * hackagebot Zora 1.1.9 - Graphing library wrapper + assorted useful functions  http://hackage.haskell.org/package/Zora-1.1.9 (bgwines)
01:37:21 <possiblywrong> adas: don't thank me thank @bitemyapp
01:46:21 <absence> has anyone looked at f# and knows if there are any useful resources online for someone already familiar with haskell to quickly get up to speed?
01:53:47 <KorriX> Hello! Does fork of protocol-buffers working with ghc 7.8.* exists somewhere?
01:54:17 <kvanb> @pl (\p f -> evalStateT (runErrorT f) p )
01:54:17 <lambdabot> flip (evalStateT . runErrorT)
01:55:03 <kvanb> neat
01:56:35 <absence> kvanb: it's like they were defined backwards, i always end up flipping them :)
01:56:53 <kvanb> I must admit it's a little annoying that StateT is the "wrong way around"
01:57:05 <kvanb> 90% of the time I'd like to do something like
01:57:20 <kvanb> evalStateT mempty $ \ .... -> ...
01:57:42 <tdammers> runStateT initialState $ do { whatever }
01:57:43 <tdammers> yeah
01:57:54 <tdammers> I end up flipping the *State(T) functions myself a lot
01:58:10 <tdammers> same for Readers, actually
01:58:11 <kvanb> yeah, imagine that was a do, sorry
01:58:24 <kvanb> been insane all day with this 3 deep transformer stack
01:58:43 <eikke__> anyone familiar with pipes around?
01:58:51 <kvanb> eikke__: a little bit
01:59:01 <tdammers> I tend to treat the stack as a rather monolithic thing outside of its own module
01:59:02 <eikke__> ah, right, of course you are :)
01:59:05 <tdammers> newtype it, even
01:59:10 <jle`> eikke__: just ask your question :)
01:59:16 <tdammers> and then expose specific accessors
01:59:18 <kvanb> ask it on the pipes mailing list
01:59:25 <kvanb> gabriel (or another) responds in hours
01:59:29 <absence> i've used pipes
01:59:34 <kvanb> https://groups.google.com/forum/#!forum/haskell-pipes
01:59:46 <absence> so go ahead, ask here as well :)
01:59:48 <jle`> i wrote a pipes tutorial once
01:59:54 <jle`> in another life
02:00:06 <kvanb> I like the new pipes a lot better than the old pipes
02:00:12 <kvanb> I would be sad if it mutated again
02:00:27 <eikke__> happen to know whether it's possible to create a Pipe which simply passes-through every element passing by, but also does some stateful calculation with every value (passing the intermediate result along recursively), and somehow returning the result when the stream is finished?
02:00:30 <jle`> oh i wrote it last week, it's on the new pipes ^_^
02:00:51 <jle`> eikke__: returning?
02:00:56 <jle`> as in, sending downstream?
02:01:01 <eikke__> no
02:01:03 <bollu> exit
02:01:12 <bollu> qhoops, sorry :)
02:01:14 <bollu> whoops*
02:01:27 <jle`> bollu: oh, i thought you were answering my question :)
02:01:33 <eikke__> jle`: not sure how to define 'returning'
02:01:42 <kvanb> eikke__: https://hackage.haskell.org/package/pipes-4.1.2/docs/Pipes.html#v:next
02:01:43 <jle`> returning as in the monadic sense?
02:01:52 <eikke__> jle`: yes
02:01:54 <kvanb> write a tight loop using next
02:02:11 <kvanb> well, keep in mind
02:02:14 <absence> eikke__: it sounds a bit like foldM
02:02:14 <kvanb> this can't be a Pipe
02:02:22 <jle`> yeah, look through pipes prelude
02:02:23 <kvanb> it must be a Producer ... -> ....
02:02:30 <jle`> you might find foldM or something like that
02:02:59 <kvanb> it has to be *around* the pipeline to detect termination
02:03:04 <kvanb> not part of it, I think.
02:03:13 <eikke__> ah, right, no longer thinking about it being a Pipe, but making it a Producer which takes the upstream Producer as an argument might help indeed
02:03:16 <eikke__> let me try :)
02:03:16 <kvanb> pipes doesn't convey that information for performance of sslt
02:03:30 <kvanb> *or
02:06:30 <jle`> eikke__: http://hackage.haskell.org/package/pipes-4.1.2/docs/Pipes-Prelude.html#v:foldM should do what you want
02:06:59 <eikke__> jle`: then I can't send the values I get downstream, can I?
02:06:59 <jle`> it takes a producer and continually pulls values from it, feeding it into a monadic stateful function (your fold), and pops out the reuslt at the end
02:07:08 <jle`> eikke__: well...do you want to?
02:07:30 <eikke__> jle`: yes
02:07:36 <jle`> do you want to return it too?
02:08:06 <eikke__> actual use-case: calculate a hash of a stream of bytestrings, but also being able to send that stream to a file
02:08:35 <jle`> send the stream to a file?
02:08:43 <jle`> so write the stream
02:08:47 <jle`> to the file
02:08:55 <jle`> and then have the whole pipe return the computed hash
02:08:55 <eikke__> yes
02:09:03 <kvanb> note it still has a producer argument
02:09:30 <eikke__> jle`: something along those lines, yes
02:13:21 <jle`> to tell you the truth i have never used the return parameter of a pipeline before
02:13:41 <jle`> you might also need pipes-parse
02:14:03 <jle`> because you can't respond on the producer terminating with vanilla pipes
02:14:15 <absence> eikke__: using the foldl package, you could maybe compose two folds, one that computes your hash, and one that simply yields, and then use foldM with that
02:14:18 <jle`> unless your algorithm works incrementally i guess
02:14:30 <jle`> pipes isn't really meant for "splitting computations" like that, i think.
02:14:31 <eikke__> I really thought this would be trivial :P
02:14:35 <jle`> but go ahead and ask it on the mailing list
02:14:39 <jle`> gabriel usually responds immediately
02:14:42 <eikke__> I know ;)
02:14:51 <jle`> it might be trivial, i just haven't needed to do something like it before :)
02:24:05 <eikke__> got it, I think
02:24:13 <adas> usually in a package, is the cabal file automatically created or manually created?
02:24:20 <adas> first time using cabal
02:24:38 <adas> tried cabal install --only-dependencies
02:24:48 <adas> said it needs a <package>.cabal file
02:28:37 <jle`> adas: in a new package?
02:28:50 <jle`> you need to a cabal file to even know what the dependencies are ;)
02:28:57 <jle`> $ cabal init
02:29:48 <merijn> adas: cabal files are always manually created (although "cabal init" does a good job of walking you through)
02:30:15 <eikke__> jle`, absence, kvanb: thanks for the help! got what I need @ https://gist.github.com/NicolasT/8b4aeba485ab45158d7f
02:30:33 <jle`> eikke__: yay :)
02:30:42 <adas> jle`: yea in a new package
02:31:11 <adas> merijn: so once i've done 'cabal sandbox init' i must do 'cabal init' again?
02:32:09 <eikke__> maybe I should create a package out of this & put on hackage, seems fairly useful (though admittedly rather simple once you get it as well)
02:33:14 <absence> adas: cabal init makes the .cabal file. cabal sandbox init makes a sandbox in the current directory regardless of any .cabal files
02:33:21 <merijn> adas: Those two commands have nothing to do with eachother
02:33:40 <merijn> adas: "cabal sandbox init" initialises a sandbox, "cabal init" creates an initial cabal file
02:35:01 <adas> so that mean if im developing in a sandbox .. 'cabal sandbox init' can be followed by 'cabal init'. ill try that
02:35:58 <absence> yes, cabal init is unaffected by the sandbox
02:36:09 <merijn> Developing in a sandbox without already having a cabal file doesn't make sense to me in the first place?
02:36:43 <eikke__> merijn: I use it once in a while to tinker with some new library I found out about, install & cabal repl
02:37:34 <absence> merijn: or installing a new version of cabal :)
02:37:43 <adimit> I'm trying to write a sequence operation for HLists: HList (m e ': l) -> m (HList e ': l) — but the "obvious" hlistSequence (HCons k l) = k >>= \e' -> return (Cons e' l) doesn't seem to correctly bind the types of m and e, and the type inferencer instantiates new types for k :: m0, and e' :: e0, which it can't match against the intended types m, and e, respectively.
02:37:53 <adimit> Maybe I can use ScopedTypeVariables?
02:38:07 <adimit> (Also, why does the inferencer instantiate new type variables here?
02:39:46 <adas> merijn: i've been developing without cabal files for my projects.. so i wasn't sure which to do first. sandbox and then cabal init or the other way around. now i realize it doesn't matter - )
02:40:25 <Yuu_chan> Is it possible to render a Gloss scene into some intermediate bitmap and then post-process it before drawing on the screen?
02:43:15 <adimit> For some reason it seems to infer the kind of e as [*], but that can't be right, no? e is the elemnt type, l being of kind [*]!
02:45:32 <merijn> Wait
02:45:37 <merijn> What is the kind of HList?
02:46:00 <adimit> merijn: [*] -> *
02:46:09 <adimit> … as it should be, no?
02:47:27 <merijn> oh, nvm, I thought I had an insight
02:47:39 <merijn> And then I realised that I'm just too jetlagged to think straight :D
02:47:50 <Adeon> HList on hackage looks like black magic
02:48:07 <merijn> Adeon: The code or the types? Or both? :p
02:48:13 <merijn> Black magic is best magic!
02:48:21 <adimit> merijn: https://gist.github.com/adimit/a14016e84ddbfe3d4454 ← that would be the full code example.
02:49:25 <ninja_code> where can I read about good indentation for haskell? for example, things like how should if/then/else be indented?
02:49:26 <merijn> adimit: Oh!
02:49:28 <merijn> Duh
02:49:37 <merijn> adimit: You don't have a monad constraint on m
02:49:38 <adimit> ok, I made a newbie mistake.
02:49:41 <adimit> ah!
02:50:04 <adimit> eh, no.
02:50:12 <adimit> same problem, slightly different error message.
02:50:12 <merijn> adimit: Well, it definitely needs one
02:50:15 <adimit> yes!
02:50:17 <adimit> I added it.
02:50:24 <merijn> ninja_code: I recommend reading: https://en.wikibooks.org/wiki/Haskell/Indentation
02:50:59 <ninja_code> merijn++
02:51:08 <ninja_code> oh shit, purity, too bad :-)
02:51:10 <adimit> wait, in the end it's a bracket problem.
02:51:24 <ninja_code> something like "do x <- readMVar merijn; putMVar merijn (x+1)"
02:51:24 <merijn> ninja_code: Once you know how the indentation actually works I'd just go with "whatever looks most readable", there's no one right way, but there is a few standard styles with variations on how to indent ADTs, etc.
02:51:38 <adimit> it was.
02:51:39 <adimit> duh.
02:51:41 <adimit> !!!
02:51:43 <ninja_code> merijn: i have a simpler goal
02:51:47 <ninja_code> to minimize fighting with emacs
02:52:05 * merijn minimized his fighting with emacs by enabling evil-mode
02:52:24 <adimit> My type signature read m (HList e ': l), but that of course forces the kind constraint [*] on e, since it was interpreted to be the first argument to HList!
02:52:38 <adimit> it has to be (HList (e ': l)). grrrr.
02:52:50 <merijn> ah
02:52:52 <merijn> duh :D
02:53:19 <adimit> I also need the Monad constraint, but GHC tells me that.
02:53:50 <adimit> I don't even need ScopedTypeVariables.
02:53:54 <adimit> Thanks :-)
02:54:37 <merijn> Everyone needs ScopedTypeVariables! :p
02:54:48 <adimit> merijn: also, emacs + evil is a great combo. Haskell-mode is pretty OK, even if weird at times :P
02:55:12 <ccapndave> I am using Text.JSON.Generic to turn some data into JSON, but part of the data is a Data.Map.Map and I'm getting this weird runtime error: toJSON: not AlgRep NoRep(DataType {tycon = "Data.Map.Map", datarep = NoRep})
02:55:13 <jle`> ugh is there really no mapMWithKey for Data.Map
02:55:18 <jle`> there is only traverseWithKey
02:55:25 <jle`> AMP can you come faster
02:56:02 <ccapndave> It looks a bit like encodeJSON doesn't know how to deal with Data.Maps, but I have no clue how to fix this :(
02:56:09 <adimit> yeah, well. I try to use as few extensions as possible. But every time I enable DataKinds I might as well just pull in Language.Haskell.Extensions.
02:56:22 <adimit> All of them.
02:56:32 <merijn> adimit: Yup
02:56:49 <merijn> adimit: DataKinds makes little sense without at least GADTs and TypeFamilies imo
02:57:11 <merijn> And once you have those you want KindSignatures and RankNTypes is usually not far away :p
02:57:25 <adimit> You'll also want TypeOperators, and soon you'll have PolyKinds, too.
02:58:14 <adimit> and yeah, when you have RankNTypes, ScopedTypeVariables aren't far away, either.
02:58:39 <adimit> dammit, this was supposed to be a unit test module, no showcase of all of GHC's extensions.
02:59:35 <merijn> adimit: Why do you need ScopedTypeVariables with RankNTypes?
02:59:54 <adimit> merijn: you don't. I just seem to write code that wants 'em bot.h
03:00:35 <adimit> i.e. when you start where'ing and let'ting inside your functions, at some point you'll want to specify a type from the signature somewhere, and then you'll need ScopedTyvars.
03:10:21 <tanmaig> Hi! Is there a way to active a source-code map with throwError?
03:11:01 <tanmaig> Right now, throwError takes a String. I would like to take append information about the source line no to the string.
03:11:13 <tanmaig> Maybe use unsafeIO ?
03:13:22 <iloverivi> > let f x = x in f 5
03:13:24 <lambdabot>  5
03:15:54 <quchen> tanmaig: You should be able to do that using CPP, which has __LINE__ magic constants
03:16:17 <quchen> traceShow (__LINE__ :: Int) foobar -- something like that
03:17:58 <quchen> See https://gcc.gnu.org/onlinedocs/cpp/Standard-Predefined-Macros.html
03:18:35 <tanmaig> quchen: Ah. Thanks. I'll check it out.
03:25:08 <tanmaig> quchen: How should I tell GHC that it needs to use the GCC macros?
03:26:03 <quchen> tanmaig: Like this, http://lpaste.net/106785
03:26:15 <quchen> -> "This is line 3"
03:27:29 <quchen> __LINE__ expands to a literal like "12" which is ambiguous, that's why the ::Int is necessary for printing here
03:28:48 <ocharles> Is there a way to show what the use of a #DEFINE with -XCPP would expand to/
03:28:49 <ocharles> ?
03:29:32 <quchen> Hmm? You mean something like "dump source afte CPP"?
03:30:32 <ocharles> yea
03:30:38 <dcoutts> ocharles: ghc -E iirc
03:30:41 <dcoutts> same as for gcc
03:30:45 <ocharles> ah, thanks!
03:45:52 * hackagebot tianbar 0.4.6.0 - A desktop bar based on WebKit  http://hackage.haskell.org/package/tianbar-0.4.6.0 (AlexeyKotlyarov)
04:00:53 * hackagebot text-ldap 0.1.0.0 - Parser and Printer for LDAP text data stream  http://hackage.haskell.org/package/text-ldap-0.1.0.0 (KeiHibino)
04:02:51 <frerich> Sometimes the wonders hidden in Haskell packages are really surprising. I just checked that text-ldap link and saw that it depends on "semigroups". Not knowing what that is, I looked it up and the description says "In mathematics, a semigroup is an algebraic structure consisting of a set together with an associative binary operation. A semigroup generalizes a monoid in that there might not exist an identity element.
04:02:51 <frerich>  It also (originally) generalized a group (a monoid with all inverses) to a type where every element did not have to have an inverse, thus the name semigroup"
04:03:08 <frerich> so I wonder "Why on earth would you want something like that for an LDAP parser??". Turns out: because 'semigroups' contains the type for non-empty lists :}
04:03:29 <frerich> Sometimes the gap between a mathematical definition and a practical application is so large that I can't mentally cross it.
04:04:14 <merijn> non-empty lists are semigroups because they don't have an identity for the append operation :)
04:16:59 <tanmaig> Hi. Enabling {-# RULES ... #-} causes GHC to throw a parse error on the first line of code: parse error on input `import'
04:17:16 <tanmaig> Does anybody have any idea what's happening?
04:17:36 <danilo2> Hello! :) If anyone is interested, I've just uploaded HaskellBooster - a set of extensions extending available Haskell syntax (which is sometimes very usefull) - you can grab it here: https://github.com/wdanilo/HaskellBooster :)
04:18:44 <Javran> I know `do { x <- mx; y <- my; return $f x y}` can be written as `f <$> mx <*> my` but instead of f :: a -> b -> c, what if I have f :: a -> b -> m c ?
04:21:58 <Javran> I see, `join (f <$> mx <*> my)` works as expected
04:23:57 <Soft> Hmm Could I get cabal to redo my dependency definitions
04:24:23 <Soft> I mean the dependency listings it creates when you first do cabal init
04:24:39 <Soft> or do I just have to manually update them
04:26:51 <tanmaig> Hi. Enabling {-# RULES ... #-} causes GHC to throw a parse error on the first line of code: parse error on input `import' ? What's happening?
04:27:35 <hpc> can you paste your code?
04:27:37 <hpc> @paste
04:27:37 <lambdabot> Haskell pastebin: http://lpaste.net/
04:32:08 <rwbarton> what does "Enabling {-# RULES ... #-}" mean?
04:32:28 <saml_> rwbarton, ghc extension
04:32:50 <saml_> https://www.haskell.org/ghc/docs/latest/html/users_guide/pragmas.html
04:32:51 <rwbarton> I know, but you don't "enable" it
04:33:30 <saml_> https://www.haskell.org/ghc/docs/latest/html/users_guide/rewrite-rules.html
04:34:18 <tanmaig> rwbarton: http://lpaste.net/106790
04:34:37 <tanmaig> I mean just writing that pragma. I have no clue what's going wrong!
04:34:50 <tanmaig> And I compile it with -O and -fenable-rewrite-rules
04:35:24 <saml_> -fglasgow-exts
04:35:54 <tanmaig> saml_: It says deprecated, use individual flags instead.
04:36:00 <rwbarton> have you tried just writing it after the import line?
04:36:33 <tanmaig> rwbarton: Ah. Trying now.
04:37:14 <tanmaig> rwbarton: Ok. That worked! Why?
04:37:30 <rwbarton> well normally import lines must go first, before all your other declarations
04:37:59 <rwbarton> I guess that applies to rules too
04:40:26 <saml_> tanmaig, what's your ghc version?
04:40:48 <tanmaig> saml_7.4.2
04:40:52 <tanmaig> saml_: 7.4.2
04:40:58 * hackagebot storablevector 0.2.9 - Fast, packed, strict storable arrays with a list interface like ByteString  http://hackage.haskell.org/package/storablevector-0.2.9 (HenningThielemann)
05:01:59 <eikke__> sweet. I wrote an `sha1sum` replacement using pipes and the thing I wrote about above, and it's consistently (slightly) faster than `sha1sum` on a 250MB input file ^_^
05:03:33 <t7> nice
05:48:57 <k_bx> Hi everybody! How would you express something like this HashMap.insertWith in lens? https://gist.github.com/k-bx/bff0ab005f80811cd34f Basically, I have a map of impressions by timestamp, so I need to either set it to 1 if absent or increase if it's present.
05:52:09 <quchen> Javran: Re "join (f <$> mx <*> my)` works as expected": That's because you can view Applicative as a class that supplies you with an n-ary fmap operation, namely the liftA* family. For ordinary (>>=), i.e. when you bind a function of one argument, m >>= f = join (fmap f m). If f takes more arguments than that, you have to use "fmap with more args", which is liftA2 for example, giving you "bind2 m n f = join (liftA2 f m n).
05:55:00 <rwbarton> k_bx: two possibilities: you can use 'at' together with a function (\oldValue -> case oldValue of { Nothing -> 1; Just n -> n+1 })
05:55:11 <rwbarton> k_bx: or, check out 'non'
05:55:44 <k_bx> @rwbarton thanks, will check out.
05:55:44 <lambdabot> Unknown command, try @list
05:56:20 <rwbarton> which would also use at I guess
05:56:38 <rwbarton> hash & at key.non 0 +~ 1
06:02:11 <adas> is there a way to find out exactly what dependencies to install so that those packages can be manually entered in the package cabal file?
06:05:03 <matheus23> Idk it's probably the wrong channel to ask about this, but if I have the inequality "1/n > e" and take both sides to the power (-1), is the resulting inequality "n < 1/e" right?
06:05:09 <k_bx> rwbarton: it works great, thanks! (I'm not sure which code is simpler thought, but I'll experiment more with other places)
06:06:09 <matheus23> I somehow couldn't find information about applying the -1st power to inequalityies...
06:09:42 <k_bx> matheus23: multiply both parts at "n" in first case and at "e" in second
06:09:51 <k_bx> s/parts/sides/
06:10:26 <matheus23> k_bx: ah no... I ment to go from the first case to the second by applying the -1st power...
06:10:34 <matheus23> and wondered whether it was allowed...
06:10:40 <matheus23> and it's just an example
06:10:56 <matheus23> I need that for a little bit bigger inequality
06:11:56 <rwbarton> k_bx gave exactly the argument for determining when that is valid, though
06:12:02 <k_bx> matheus23: I thought what I told you "proves" that this holds (except that you need to bring "for n /= 0" till the end of your proof  and take case for right part == 0.
06:12:33 <rwbarton> you need 1/n and e to have the same sign so that you mulitply by a positive number overall
06:12:43 <matheus23> k_bx: oh well, yeah that's right, thank you :) (it's provided that n >= 1)
06:12:52 <matheus23> (and e > 0)
06:13:04 <k_bx> rwbarton: ah, right.
06:13:07 <matheus23> (it's all about proving convergence of sequences)
06:13:23 <matheus23> k_bx: rwbarton: Thank you :)
06:14:14 <adas> parse of field build-depends fails...
06:14:20 <adas> but the syntax is proper
06:14:22 <adas> i checked
06:15:28 <kvanb> sigh
06:15:34 <kvanb> when your types are 3x as long as your code
06:15:39 <kvanb> you know you're programming Haskell
06:16:27 <deech> Hi all, I'm trying to pass a ByteString into a C function that accepts unsigned chars. It's not obvious to me how to do that from the API. Does anyone know of a better way?
06:17:12 <deech> s/unsigned chars/an array of unsigned chars/
06:17:54 <adas> in the cabal file, how come we can't use "package =0.1.2" and can only use "package =>0.1.2"
06:18:39 <adimit> adas: have you tried package == 0.1.2?
06:19:02 <rwbarton> deech: Data.ByteString.Internal.toForeignPtr
06:19:04 <adimit> I use package == 0.1.* over bounds with => and =<, because I find it easier to read and safer.
06:19:23 <adas> adimit: sry..will do now
06:20:16 <rwbarton> deech: then use withForeignPtr
06:20:30 <adas> adimit: much thanks. that works
06:20:44 <mzero> deech:  useAsCString
06:20:48 <deech> rwbarton: thanks!
06:20:48 <rwbarton> man, hoogle really needs to update its database or something
06:21:08 <deech> mzero: useAsCString converts ByteString to a Ptr CChar, I need Ptr CUChar.
06:21:10 <mzero> it's not even unsafe!
06:21:18 <rwbarton> oh, huh
06:21:23 <mzero> can't you just "cast" the Ptr
06:21:42 <rwbarton> yeah
06:21:55 <mzero> :t castPtr
06:21:56 <lambdabot> Not in scope: ‘castPtr’
06:22:10 <deech> mzero: I guess. I thought that converting it to CString truncated values over 127.
06:22:17 <mzero> what?
06:23:09 <mzero> nope - implementation is just pure memcpy
06:23:10 <deech> It was my understanding that a CChar goes from -127 to 127.  ByteString stores Word8's.
06:23:25 <deech> It's a memcpy + a castPtr.
06:23:48 <mzero> the castPtr does nothing - so your castPtr back will also!
06:24:08 <deech> mzero: Oh, ok then. I thought useAsCString lost information.
06:24:16 <mzero> doesn't appear to
06:24:21 <deech> mzero: Thanks!
06:24:25 <mzero> :-)
06:24:53 <rwbarton> what kind of C function takes a null-terminated unsigned char *?
06:25:12 <deech> rwbarton: It doesn't, I'd be using useCStringLen. :)
06:25:32 <rwbarton> oh, okay
06:26:07 <mzero> doesn't it depend on the architecture if char is unsigned by default, and if so, all string functions would take null terminated unsigned char *
06:26:16 <rwbarton> well, okay :)
06:30:51 <m_m> Hi. I ma quite new in haskell. Could you tell me how looks market place for haskell developers? Haskell have a lots of web frameworks. So job offers are in major part for web developers?
06:31:25 <tdammers> m_m: job offers are very scarce
06:31:45 <tdammers> m_m: if you want to learn haskell in order to get a haskell programming job, you're going to have a hard time
06:33:31 <m_m> tdammers: Im searching something new. Right now I am working in pyhon. It would be nice to have a chance for getting job in new technology.
06:34:13 <mwc> On the other hand, it might make it easier to get a Scala job or at least give you opportunities to work on projects with technologies like STM, massive concurrency, etc, that will look pretty good to a knowledgable recruiter
06:34:28 <tdammers> m_m: well, haskell is still an off-mainstream language
06:34:44 <mzero> m_m: you should learn Haskell, and at least 3 or 4 other langauges and frameworks - so that you can get a job that isn't tied to a technology.
06:35:13 <tdammers> but yes, knowing some haskell signals that you are interested in programming languages and paradigms beyond "does this make the customer happy" and "how much money can I make with this"
06:35:39 <mzero> Better programming jobs aren't those looking for "python developers" or "haskell developer"... they are the ones looking for "software engineers", where they'll look for you to be comfortable enough with development to pick up whatever langauge is needed for the job at hand.
06:35:57 <tdammers> yes
06:36:53 <mzero> and, really, learning Haskell will significantly improve your Python!
06:37:05 <tdammers> that, too :D
06:37:14 * mzero loves Haskell, codes Python for day job
06:37:45 <mwc> and your C++... template metaprogramming makes sense now (it's a lazy functional language modeled after Haskell and Brainfuck)
06:38:14 <tdammers> I think there's some influence from INTERCAL as well
06:38:40 <tdammers> but yes, learning more languages is a good thing in itself
06:38:54 <tdammers> and haskell is a great candidate because it challenges a lot of things you took for granted
06:39:02 <tdammers> forces you to explore new ways of thinking
06:39:15 <osfameron> mzero: that said, I'm working at a mutli-language shop (python, ruby, perl, bits of php and node) and though yes, if you're a good programmer, you can work in any *language*, you also have the hurdle of getting to know the libraries/frameworks/idioms, which is much slower
06:39:50 <mzero> sure - and if a startup is looking for someone, they can't afford to hire someone who is going to take two months to come up to speed....
06:40:27 <mzero> ... but many places (Google, say) would much rather have a developer spend a month coming up to speed on some library and framework stack ... then hire someone who only knows one thing
06:40:38 <osfameron> yeah, absolutely
06:41:03 <osfameron> but it's funny how coming back to the thing you know well feels like coming home :-)
06:41:11 <mzero> I often interview folks who have like 15+ years of Java Enterprise experience, and they've done nothing else.... they don't stand a chance -- even for a team that is coding in Java!
06:41:47 <mzero> No matter how many years I've done C++, it always feels like going back to war, rather than comeing home!
06:42:03 <osfameron> hehe
06:42:09 <mayski> c++ does that to you
06:42:45 <mzero> Whereas Python feels like coming home to a house made of toothpicks and clue
06:42:48 <mzero> er glue
06:43:19 <tdammers> idk
06:43:25 <tdammers> python feels more like play-doh to me
06:44:22 <mzero> well... when you build something big with it... the play-doh dries out and gets all crumbly... and then the slightest misspelling cause bits to crumble out all over the place...
06:44:33 <tdammers> yeah well
06:44:38 <tdammers> programming metaphors are dumb
06:45:00 <osfameron> which is why film/tv depictions of programming suck so  much
06:45:19 * osfameron wonders if there's any good poetry written about programming
06:45:33 <mwc> osfameron: none of it publishable
06:45:50 <osfameron> :D
06:46:27 <mzero> There is at least one excellent poety / performance peice: Guy Steele & Richard Gabriel's "50 in 50"
06:46:35 <albeit> Are there any recommended packages for running a websockets server?
06:48:10 <mzero> http://vimeo.com/25958308
06:48:49 <mzero> crummy recording though - it was great live
06:49:05 <augur> in case anyone awake now knows:
06:49:23 <mzero> albeit: I think both Snap and Yesod support web sockets
06:49:50 <augur> how can i represent a collection of values which are "more specific" and "less specific" versions of one another?
06:50:20 <augur> that is to say, a collection of values which encode something akin to an inheritance tree
06:50:52 <mzero> do you mean you have a range of values that are ordered by "specificity", or do you mean that in the "subclass models specialization" sense?
06:51:16 <augur> mzero: the former
06:51:22 <mzero> do the values actually have "increasing" functionality that can be applied to them?
06:51:28 <mzero> and, is the set bounded?
06:51:54 <augur> mzero: eg    word :> noun, verb,  verb :> tensed-verb, untensed verb, ... noun :> singular-noun, plural-noun, mass-noun, ...
06:52:10 <augur> mzero: there's finitely many of them, yes
06:52:15 <mzero> so - it is bounded - you know all the types before hand
06:52:50 <augur> yes
06:53:22 <augur> i mean obviously i can just define such a function, and leave it at that, but i was wondering if anyone know of a more natural approach
06:54:02 <mzero> well, if it is a total ordering (which it doesn't seem like), then you could just make a enum like ADT and derive Ordered
06:54:15 <augur> no, its partial
06:54:18 <mzero> right
06:54:58 <pjdelport> augur: What do you want to do with the collection and/or values?
06:55:04 <mzero> another idea is define a set of traits, and a function from types to list of traits, which could then be either compared lexographically, or set intersected
06:55:27 <Peaker> ran cabal-install on a coworker's computer, not sure which version (newest that "cabal update && cabal install cabal-install"  installed), and when trying to use --enable-executable-profiling, it silently ignored the command option, because ghc-prof package was not installed, only ghc (in Ubuntu).. quite confusing for a while!
06:55:52 <Peaker> it would be nice if it said "ghc with profiling support is not installed", would save me about 20-30 minutes of head scratching
06:55:56 <augur> pjdelport: basically its for a hacked-together subtyped version of function application used to describe grammatical constraints
06:57:05 <pjdelport> augur: Can you give an example?
06:57:09 <augur> sure
06:57:46 <mzero> I'm thinking    phyo UntensedVerb   would result in    [ WordT, VerbT, UntensedT ]        phylo Noun    would give  [ WordT, NounT ]
06:57:58 <Peaker> it's almost as if Haskell is so good at eliminating errors at compile-time that Haskellers like to make runtime errors more cryptic as to maintain the challenge :)
06:58:02 <augur> "sees" takes any noun phrase as its direct object (eg "john sees mary", "john sees me", "john sees them", etc.)
06:58:09 <mzero> and perhaps    phylo Mumble   gives   [ ]
06:58:12 <mzero> :-)
06:58:15 <augur> but it only takes third-person singular noun phrases as its subject
06:58:29 <augur> "john sees mary", but not "i sees mary" nor "they sees mary"
06:58:51 <augur> so you might say:   sees :: NP -> 3SgNP -> Bool
06:58:56 <augur> where 3SgNP <: NP
06:59:17 <mzero> Ah
06:59:52 <mzero> so, you want types on the functions to ensure you don't misapply - some values should function as multiple types
07:00:04 <augur> thats actually kind of a bad example because in this case the parameters are pretty shallow
07:00:27 <mzero> ugly, but you could do       sees :: (NP n, 3SgNP m) => n -> m -> Bool
07:00:33 <augur> i could probably just treat them like..   data Category = ... | Noun { number :: Number, person :: Person }
07:00:49 <augur> mzero: hmm.. no i dont want haskell to enforce it
07:00:52 <pjdelport> augur: Ah, so this is almost something akin to multiple-dispatch generic functions?
07:01:20 <mzero> I see, you want a data type that encodes that constraint
07:01:29 <augur> pjdelport: not quite, since theres no dispatch, it's actually not haskell doing this junk, im writing a parser that needs to code up these properties
07:01:32 <augur> mzero: ideally, yeah
07:01:55 <pjdelport> augur: Right, no actual dispatch, but the matching part of it.
07:03:02 <augur> another example would be something like this:   am is a present-tense-verb, were is a past-tense verb, both are tensed-verbs, being is a progressive-non-tensed-verb, be is a bare-non-tensed verb
07:03:04 <mzero> Sure, so why not have a set of descriptors:        data Role =  NP | SgNP3 | VB | VBT | VBU
07:03:16 <mzero> and then a function evaluates suitabliity
07:03:49 <augur> mzero: thats what i was thinking. just have a type for each possible value, and just manually write the (<:) function
07:03:55 <mzero> this function can easily do the "inheritance"        suitable VB n = suitable VBT n || suitable VBU n
07:04:09 <Ankhers> Without creating a wrapper data type, how would I go about creating an instance of ToJSON that would nest my data type like this? http://lpaste.net/106795
07:04:34 <mzero> one can easily feel the combintor coming on:     suitable VB n = suitsAny [ VBT, VBU, ... ] n
07:04:53 <augur> mzero: i wouldnt actually mind if haskell could enforce _some_ aspects of it, like, nouns only have number and plurality and such, they dont have tense, so that would be nice to enforce
07:05:19 <mzero> Ankhers: just create a function called responseToJson
07:06:46 <mzero> but why need a wrapper? just make Response be an instance of ToJSON
07:07:56 <augur> hmm.. ok, well, thank you for the ideas mzero, pjdelport
07:07:59 <mzero> well... you could have suitable be a member of a typeclass    where the typeclass instances were more general than all the categories
07:08:57 <mzero> Ankhers: here's a file full of data that I push, as JSON, across an HTTP API: https://github.com/mzero/plush/blob/master/src/Plush/Job/Types.hs
07:09:05 <augur> hmm... actually you know, i just had an idea
07:10:07 <augur> mzero, pjdelport: what i might be able to do is use haskell for matching, and use partially specified patter matches to handle this
07:10:37 <pjdelport> augur: Would that handle inheritance, though?
07:10:59 <augur> so like, to get 3SgNP use a pattern like    foo (Noun { Pers = Third, Num = Sg }) = ...
07:11:13 <augur> and to get just NP, something like   foo (Noun {}) = ...
07:11:51 <augur> most (all?) of the properties are like parameters, more so than like arbitrary subtyping, i think
07:12:00 <augur> so maybe that can be handled more elegantly
07:12:03 <Ankhers> mzero: The API I need to respond to requires that wrapper. I think it is dumb, but it is what I have to work with.
07:12:58 <augur> for verbs:   data Category = ... | Verb VerbProps   ;   data VerbProps = NonTensed | Tensed TensedProps   ;   data TensedProps = Past | Pres
07:13:25 <augur> so a past tense verb is marked as   Verb (Tensed Past)
07:13:38 <augur> while a non-tensed verb is just   Verb NonTensed
07:13:40 <augur> or whatever
07:13:47 <augur> hmmm
07:14:14 <augur> and if i want to match any tensed verb,   Verb (Tensed {})   or any verb   Verb {}
07:14:23 <augur> obviously i'd use records here so i can do {}
07:14:36 <augur> or i could use Verb _, Tensed _
07:14:51 <pjdelport> augur: Aha! Yeah, if you can encode things as orthogonal properties instead of subtyping, that should make things a lot easier.
07:14:52 <augur> something uniform tho, most likely {}
07:15:06 <mmmm_> Is there an good way to debug when using Data.Generics?
07:15:40 <augur> pjdelport: the tricky bit is that some properties are only relevant when others are set, so the property values have to themselves be hierarchical like that
07:26:16 * hackagebot psqueues 0.1.1.0 - Pure priority search queues  http://hackage.haskell.org/package/psqueues-0.1.1.0 (JasperVanDerJeugt)
07:37:13 <mzero> Ankhers: sorry - was eating breakfast
07:37:21 <mzero> OH you mean the extra outer JSON object
07:37:25 <mzero> oh - easy
07:37:53 <Ankhers> mzero: I figured it out already. I embedded an object call inside.
07:38:01 <Ankhers> Unless there is a better way?
07:39:23 <mzero> exactly
07:39:57 <Ankhers> mzero: Thanks for the help!
08:01:39 <albeit> When I install snap (cabal install snap), I have .cabal/bin in my path, but it still can't find the "cabal" program to run "cabal init". I'm on Ubuntu. Any ideas?
08:01:55 <albeit> * Sorry, the "snap" program to run "snap init"
08:02:36 <bergmark> albeit: are you sure the path is set correctly? does `which snap' work?
08:03:24 <albeit> No, returns nothing. I did install it to a sandbox, do I need to add the sandbox's .cabal/bin to the path?
08:03:31 <bergmark> yes
08:03:45 <eikke__> jle`, absence: regarding the my Pipes question before -> actually, using a State(T) layer in the base monad, I can do it as a pipe as well (which now made me write a 'hashPipe' function :-P )
08:04:12 <albeit> bergmark: Got it, thanks
08:04:15 <bergmark> albeit: i prefer to cp the binary to .cabal/bin instead of having lotsa sandboxes in my path
08:04:39 <albeit> bergmark: Yeah, just going to call the snap executable directly from taht folder
08:08:54 <augur> hmm
08:09:54 <augur> pjdelport: i think i found a way to make my thing on reddit that does record pattern matching into a more generic-ish version that pattern matches on normal data types
08:10:11 <augur> pjdelport: but not yielding bindings, probably those would have to be different
08:12:39 <augur> pjdelport: basically a CPS transform of predicates + generic accessors
08:13:24 <augur> pjdelport: (.=) :: (a -> b) -> (b -> Bool) -> a -> Bool  ;  k .= p = p.k
08:13:53 <augur> pjdelport: (&) :: (a -> Bool) -> (a -> Bool) -> a -> Bool  ;  p & p' = \v -> p v && p' v
08:14:33 <augur> pjdelport:  noun :: (NounInfo -> Bool) -> Cat -> Bool  ;  noun p (Noun v) = p v ; noun _ _ = False
08:14:55 <augur> sg :: Num -> Bool ; sg = (==) Sg
08:16:03 <augur> pjdelport: so you can now do stuff like   pat = cat .= noun (num .= sg)
08:16:29 <augur> which is like matching on   Word { Cat = Noun (NounInfo { Num = Sg }) }
08:16:47 <augur> only its an actual pattern you can store
08:18:01 <augur> its only predicational, unfortunately, but i think its all i need
08:20:08 <av> Hi.  I'm trying to use a C library (that I can modify) with FFI that defines a function which requires a function argument (to be used as a callback).  The callback has to pass a 1D array to the haskell code.  Is there an example for this scenario that I could look at?
08:20:52 <mwc> av: sounds like you want to write a haskell function and call it from your C code.
08:21:33 <albeit> When I try to install vector in a cabal sandbox, I'm getting an error: "<command line>: can't load .so/.DLL for: libHSprimitive-0.5.3.0.so (libHSprimitive-0.5.3.0.so: cannot open shared object file: No such file or directory)
08:21:34 <albeit> ". But primitive is installed. Any ideas?
08:22:01 <av> mwc: exactly, but I'm stuck with the type declarations.  I'm new to FFI and the wrapper magic etc.
08:22:09 <mwc> av: you'll need to create a "wrapper" with foreign import that turns your haskell function into a FunPtr, a C function pointer, which you can pass to your api, and release with freeHaskellFunPtr when you're done
08:22:36 <mwc> av: it's documented here http://www.haskell.org/haskellwiki/GHC/Using_the_FFI#Calling_Haskell_from_C
08:22:52 <StahlGrau> 1)      Dashboard – Create a dashboard of Unassigned issues and also their assigned tickets so that when they login they can better manage their tickets
08:22:55 <StahlGrau> 2)      Auto Nag
08:22:58 <StahlGrau> a.       Automatically notify helpdesk again if a ticket stays unassigned after 1 business day
08:23:01 <StahlGrau> b.      Automatically notify assignee if a ticket is in open or in progress state and has not been updated for 2 business days
08:23:04 <StahlGrau> c.       Automatically notify assignee if a ticket is in resolved state and has not been updated for 5 business days
08:23:07 <StahlGrau> 3)      Create additional state called “Awaiting Response”. Notification should be sent to all reporters and watchers if ticket is in this state without being updated for 1 business day. If no update after 5 business days, ticket should be closed automatically. Notification emails should reflect this policy.
08:23:10 <merijn> av: I think I have some code on github using callbacks
08:23:12 <StahlGrau> 4)      Create different priorities:
08:23:13 <merijn> @where ops
08:23:13 <lambdabot> arjanb bos byorgey Cale conal copumpkin dcoutts dibblego dmhouse dolio dons edwardk elliott geekosaur glguy Heffalump Igloo jmcarthur johnw kosmikus Lemmih monochrom nyc Philippa Pseudonym quicksilver roconnor Saizan shachaf shapr sjanssen ski sorear SyntaxPolice xerox
08:23:14 <StahlGrau> a.       Critical – System down, cannot perform job duties
08:23:17 <shergill> wtf
08:23:17 <StahlGrau> b.      High – Cannot perform major function of job
08:23:18 --- mode: ChanServ set +o dcoutts
08:23:19 <StahlGrau> c.       Medium – System degraded, but no serious impact to job function
08:23:22 <StahlGrau> d.      Low – Minor Issue or Question
08:23:24 <merijn> shergill: Just the usual freenode spam
08:23:24 <StahlGrau> 5)      Create issue classification (use component? Better way to do it?):
08:23:27 <StahlGrau> a.       Salesforce Issue
08:23:29 <StahlGrau> b.      InContact Issue
08:23:30 --- mode: ChanServ set +o monochrom
08:23:32 <StahlGrau> c.       Password Reset
08:23:34 <StahlGrau> d.      New User Request
08:23:35 --- mode: monochrom set +b *!*@216.25.131.2
08:23:35 --- kick: StahlGrau was kicked by monochrom (StahlGrau)
08:23:42 <dcoutts> weird
08:23:48 <shergill> merijn: i guess i usually sleep through it
08:23:58 <tdammers> looks unintentional to me
08:24:01 <tdammers> still rude though
08:24:08 <dcoutts> yeah, possibly accidental copy paste
08:24:18 * tdammers nods
08:24:21 --- mode: monochrom set -b *!*@216.25.131.2
08:24:23 <dcoutts> monochrom: perhaps unset the ban
08:24:25 --- mode: monochrom set -o monochrom
08:24:27 <dcoutts> monochrom: cheers
08:24:27 <merijn> tdammers: Really? Usually the spammers copy-paste wikipedia pages
08:24:28 --- mode: ChanServ set -o dcoutts
08:24:55 <merijn> av: Line 23 is the magic line: https://github.com/merijn/SNet2.0/blob/master/SNet/Interfaces/C.hs
08:25:29 <mwc> av: actually start at section 3: callbacks into haskell from foreign code
08:25:31 <monochrom> the flood looks like homework question more than wikipedia :)
08:25:35 <merijn> av: the "wrapper" between quotes is the magic bit that tells GHC this thing will convert haskell functions into fun pointers
08:26:02 <merijn> av: Note: this conversion is really expensive, so prefer saving converted functions over creating them "on-demand"
08:27:08 <StahlGrau2> sorry about that. I'm using putty and it automatically added all that text when I accidentally right clicked
08:27:17 <merijn> Word.
08:27:37 <StahlGrau2> Was I just kick, or banned?
08:27:42 <StahlGrau2> kicked*
08:27:46 <merijn> StahlGrau2: Use a better IRC client? ;)
08:27:47 <tdammers> maybe use an irc client with rate limiting and paste protection
08:27:56 <StahlGrau2> yeah I'm sorry about that :(
08:28:01 <merijn> irssi will prompt you with "are you sure you wanted to write more than one line?"
08:28:10 <av> merijn: thanks a lot, it looks like a very readable example of what I need, I'll take a look tonight
08:28:10 <StahlGrau2> for some reason it didnt
08:28:29 <StahlGrau2> I'll set it up to fix that
08:28:41 <tdammers> maybe the magic keystroke for saying "yes, I really want to paste this" happened to be in the pasted data?
08:28:50 <monochrom> heh
08:28:56 <merijn> tdammers: It's "ctrl-k", so that seems unlikely :p
08:29:01 <tdammers> yeah, I know
08:29:04 <StahlGrau2> I think the problem is that every line came in as a new one
08:29:11 <tdammers> I blame windows
08:29:48 <StahlGrau2> yeah, I'm logged in at work and putty is something we use daily so it doesn't look as suspicous
08:29:57 <kazagistar> StahlGrau2: well I for one forgive you
08:31:14 <StahlGrau2> haha thanks. merijn, if you banned my regular nick can you unban it? won't happen again.
08:31:16 <tdammers> irc is a valuable source of knowledge for me
08:31:19 <tdammers> totally work related
08:31:31 <hexagoxel> that leaves only 1372 other users to forgive :D (minus some bots)
08:31:41 <StahlGrau2> haha
08:31:45 <monochrom> already unbanned
08:31:53 <eikke__> some bots have feelings too, you know
08:32:03 <StahlGrau2> monochrom: oh thanks. I wasn't sure who did.
08:32:11 <tdammers> eikke__: I don't think I *want* to know
08:32:21 <eikke__> j/k
08:34:21 <jkarni> how do I get cabal repl to use my ".ghci" file?
08:34:33 <int3__> code review, anybody? http://www.reddit.com/r/haskell/comments/29ndnd/request_for_code_review_anagrammer_first_haskell/
08:35:59 <kazagistar> bots tend to not prompty and earnestly appologize, but if they did, I probably would forgive them as well... unless they repeated the mistake and proved they weren't really sorry
08:36:27 <StahlGrau> beep boop
08:37:16 <StahlGrau> does #haskell have any bots written in haskell?
08:37:23 <StahlGrau> like helper bots?
08:37:28 <nicoo> lambdabot
08:37:33 <nicoo> > ()
08:37:34 <lambdabot>  ()
08:37:52 <kazagistar> its not exactly a helper bot in the traditional sense as far as I know though, right?
08:37:54 <shapr> StahlGrau: check out lambdabot, the toy of champions!
08:37:55 <nicoo> > 123 ^ 4567
08:37:57 <lambdabot>  3950426116377910836167985518341324096246404810850526637683971458862788336451...
08:38:10 <nicoo> kazagistar: It kinda is.
08:38:14 <systemfault> How good is lambdabot’s code? Would you suggest that I read it to become better at haskell?
08:38:14 <nicoo> @ty (>>=)
08:38:15 <lambdabot> Monad m => m a -> (a -> m b) -> m b
08:38:30 <StahlGrau> haha he's cool
08:38:40 <StahlGrau> or she is?
08:38:53 <nicoo> @pl \x y z -> (x^2) + (y^2) + (z^2)
08:38:54 <lambdabot> flip flip (^ 2) . (((.) . (+)) .) . (. (^ 2)) . (+) . (^ 2)
08:38:59 <shapr> > let fibs = 1:1:zipWith (+) fibs (tail fibs) in take 5 fibs
08:39:00 <lambdabot>  [1,1,2,3,5]
08:39:25 <shapr> I wrote the plugin system for lambdabot some bazillion years ago.
08:39:36 <frerich> @djinn (a, b) -> c -> (b, c)
08:39:36 <lambdabot> f (_, a) b = (a, b)
08:39:47 * frerich thinks djinn is really one of the most impressive features
08:39:54 <kazagistar> apparently I heard that lambdabot... is no longer considered a she
08:39:58 <shapr> what?
08:40:09 <systemfault> kazagistar: It had a sex change?
08:40:22 <nicoo> frerich: That kind of thing is even more impressive in dependently-typed languages :]
08:40:29 <kazagistar> it evolved beyond such simple needs
08:40:41 <kazagistar> or simlple qualifications rather
08:40:49 <nicoo> systemfault: A sex `flip`.
08:41:14 <systemfault> Ba dum tssshhh!
08:41:29 <nicoo> <3
08:42:24 <kazagistar> I think djinn is kinda dumb due to the very very small subset of haskell in understands
08:43:01 <nicoo> @djinn Read a => IO a
08:43:02 <lambdabot> Error: Undefined type IO
08:43:05 <nicoo> :(
08:43:25 <kazagistar> @hoogle Read a => IO a
08:43:27 <lambdabot> Prelude readLn :: Read a => IO a
08:43:27 <lambdabot> System.IO readLn :: Read a => IO a
08:43:27 <lambdabot> Prelude readIO :: Read a => String -> IO a
08:43:33 <kazagistar> hoogle is where the magic is at
08:44:12 <kazagistar> unless you are doing conversions, in which case it is dumb as a brick
08:44:13 <nicoo> kazagistar: Hoogle and Djinn just don't do the same kind of things
08:44:20 <nicoo> Yup :)
08:44:28 <Peaker> weird. I've got a Parsec parser that runs OK as ParsecT over IO.  If I replace IO with   WriterT () IO   it gets stack overflows :(
08:44:34 <Peaker> (The strict version of WriterT)
08:45:11 <Peaker> hmm.. only in ghc 7.6.3, not in 7.8.2
08:46:01 <bluebelle> Is there any way to fix missing .dylib required during package installation? (http://stackoverflow.com/questions/24534860/some-haskell-dynamic-library-missing)
08:47:38 <geekosaur> bluebelle, if you're using homebrew then you should not have /usr/bin/cabal
08:48:00 <geekosaur> my guess is you have multiple haskell-platform packages installed and they're confusing each other
08:48:38 <bluebelle> /usr/bin/cabal is the newest one
08:48:57 <kazagistar> int3__: ill give your code a read and try to understand it, it looks interesting
08:49:07 <bluebelle> I tried using /usr/local/bin/cabal (version 1.16), that also didnt work
08:49:10 <int3__> kazagistar: thanks!
08:49:37 <Peaker> what does +RTS -K actually do? It seems to do something entirely different from its documentation
08:50:03 <geekosaur> they're still confusing each other. /usr/bin/cabal, unless you found a prerelease h-p somewhere, is for ghc 7.6.3 installed under /Library/Frameworks/Haskell and symlinked into /usr/bin
08:50:18 <bluebelle> basically I installed haskell platform via homebrew. Then I met this error so I tried using newer cabal built from source
08:50:27 <geekosaur> or homebrew is now installing links into /usr/bin which seems strange
08:50:32 <Peaker> using no +RTS -K at all, my program works with 7.8.2.  Then with +RTS -K8M (which is said to be the default!)  it fails
08:50:39 <geekosaur> and installed into /usr/bin? ugh
08:51:23 <bluebelle> uh no, in the end I symlinked to /usr/local/bin
08:51:43 <bluebelle> I should edit the stackoverflow question
08:52:37 <kazagistar> int3__: I am not a haskell expert by any means though, so don't take my thoughts at the end as authoratative, haha
08:53:11 <int3__> haha sure. I just started a couple of days ago though so any input will probably be helpful :)
08:53:20 <bluebelle> geekosaur : I also try finding the .dylib manually, it really doesn't exist
08:56:26 * hackagebot music-util 0.15 - Utility for developing the Music Suite.  http://hackage.haskell.org/package/music-util-0.15 (HansHoglund)
08:57:48 <eevar> bluebelle: did you try installing cabal-install from source (or homebrew) as well?
08:58:47 <kazagistar> int3__: as for building your findConstraints and findAnagrams as a traditional fold, I am not sure that is quite sure that will work, because I cannot come up with a reasonable instance of monoid for your solution... if there is a way, it is going to be a bit roundabout, hmm
08:59:45 <bluebelle> eevar: I installed cabal-install using the upgraded cabal (the one I built from source).
09:00:16 <int3__> kazagistar: good to know I didn't miss anything too obvious then, haha
09:02:53 <kazagistar> int3__: however, some kind of way of separating the method of traversing out of them should be possible, ill read it and then think about it
09:03:13 <int3__> mm okay
09:06:20 <Ankhers> I have something that looks like `IO ([Param], [File])`. Would anyone be able to help me retrieve the `[Param]`?
09:11:59 <kazagistar> Ankhers: what do you want to do with it?
09:13:01 <Ankhers> kazagistar: It will return json which I will be parsing. I already have the parser built.
09:13:19 <kazagistar> Ankhers: we cannot get a pure value out of an impure context, but we help bind or lift your function into a context where it can access the pure value
09:14:03 <kazagistar> er, where it can access it as a pure value
09:14:08 <Ankhers> kazagistar: If it makes a difference, I am using warp / wai and attempting to retrieve the post request via `parseRequestBody`.
09:14:50 <YurasShumovich> hi all. Quistion re http-client package. Is withResponse function really thread safe with respect to async exceptions?
09:14:57 <YurasShumovich> https://hackage.haskell.org/package/http-client-0.3.3.2/docs/src/Network-HTTP-Client-Core.html#withResponse
09:15:01 <kazagistar> Ankhers: what is the signature of the function you want to pass the [Param] into?
09:15:46 <YurasShumovich> responseOpen uses httpRedirect, with contains interruptable withs
09:16:05 <Ankhers> kazagistar: `ByteString -> ByteString`
09:16:14 <YurasShumovich> s/withs/things
09:16:27 <bluebelle> Ankhers : Basically you can't have f::IO a -> a. But you can 'lift' the a inside IO a using (>>=)
09:16:32 <bluebelle> :t (>>=)
09:16:33 <lambdabot> Monad m => m a -> (a -> m b) -> m b
09:16:50 <toki78> hi
09:17:01 <kazagistar> Ankhers: well, um, thats not quite right, because an input of the function that uses your params has to be [Param]
09:19:48 <kazagistar> Ankhers: does that make sense?
09:20:55 <Ankhers> kazagistar: Yes.
09:21:41 <kazagistar> Ankhers: if your function is [Params] -> ByteString -> ByteString, for example, then we can work something out
09:25:59 <kazagistar> int3__: the record syntax is odd to me... the formulations of trie that I have seen tend to use the concept of a special "terminal" character to represent termination, so you don't have to track terminals manally
09:30:48 <int3__> kazagistar: should I replace Char with my own ADT then, like `type Character = Letter Char | Terminal`?
09:31:19 <int3__> s/type/data/
09:36:29 <kazagistar> int3__: perhaps it is something to consider, dunno, ill keep looking through
09:37:25 <kazagistar> (I got distracted by looking at the implementation of Data.Map.alter)
09:39:35 <kazagistar> (the implementation of Map so pretty...)
09:39:56 <int3__> lol I see
09:41:30 <int3__> I can't see how packing the terminal into a special char value would help, though... seems like I'd still need to do the same checks, except this time with pattern matching rather than 'if's
09:43:21 <kazagistar> dunno, I guess I tend to see pattern matching more then ifs?
09:44:34 <kazagistar> int3__: on a more practical note, your first g should be replaced inline with (fromMaybe leaf)
09:45:48 <int3__> kazagistar: ah cool! it did occur to me that there should be something for this rather common pattern...
09:46:24 <kazagistar> @hoogle Maybe a -> a -> a
09:46:27 <lambdabot> Data.Maybe fromMaybe :: a -> Maybe a -> a
09:46:27 <lambdabot> Prelude asTypeOf :: a -> a -> a
09:46:27 <lambdabot> Data.Generics.Aliases orElse :: Maybe a -> Maybe a -> Maybe a
09:46:35 <kazagistar> yep :P
09:47:46 <int3__> ah, I see the point of searching by type now. nice
09:50:01 <kazagistar> personally, I just have terrible memory for function names, but I can remember that "something like that exists", so for me it is a godsend, haha
09:50:29 <int3__> haha I see
09:50:53 <augur> hmm
09:51:00 <augur> is there a type operator f
09:51:14 <augur> well, class of type operators f
09:51:56 <augur> such that f = Identity and f = ReverseReader a   are members?
09:52:06 <augur> where ReverseReader a b = Reader b a = b -> a
09:52:29 <augur> its not a functor, since (->) is covariant in that position
09:52:40 <augur> and its not a cofunctor since Identity is contravariant in that position
09:55:29 <augur> i guess its a special case of Store? but i dont think Store is a functor in its value position
09:55:35 <augur> nor a cofunctor
09:55:36 <augur> hm
09:56:32 * hackagebot aeson 0.7.0.0 - Fast JSON parsing and encoding  http://hackage.haskell.org/package/aeson-0.7.0.0 (BasVanDijk)
09:56:34 * hackagebot aeson 0.7.0.1 - Fast JSON parsing and encoding  http://hackage.haskell.org/package/aeson-0.7.0.1 (BasVanDijk)
09:56:36 * hackagebot aeson 0.7.0.2 - Fast JSON parsing and encoding  http://hackage.haskell.org/package/aeson-0.7.0.2 (BasVanDijk)
09:58:28 <kazagistar> int3__: hmm, the fact that constraints uses * instead of an algebraic datatype like "data Constraint a = Specific a | Wildcard" makes it less general and less extendable in certain ways, but I am sure you are aware of that already
10:00:00 <int3__> kazagistar: yeah, that did occur to me too, but it didn't seem like a pressing change (in that it wouldn't make the rest of the code any terser)
10:01:33 * hackagebot aeson 0.7.0.3 - Fast JSON parsing and encoding  http://hackage.haskell.org/package/aeson-0.7.0.3 (BasVanDijk)
10:03:41 <int3__> kazagistar: I keep thinking that it would be nice to avoid converting between Char / terminal :: Bool (or alternatively the Character datatype I declared earlier) and the elements of a list. That is, to store '[]' for the terminal value. but that would mean storing (Char:) instead of Char, and I can't use that as a key for my Map...
10:04:19 <int3__> I could store a tuple of (Char, (Char:)) I guess, but that seems kind of clunky too
10:07:40 <ReinH> ocharles: ping
10:08:15 <kazagistar> int3__: do you mean (Char:) as the prepend character function or something? I am confused
10:08:33 <bennofs> Using the Win32 package, is it possible to convert a Win32 HANDLE to a haskell Handle ?
10:08:40 <int3__> kazagistar: yeah that's what I meant. I know it's not valid haskell heh but I wasn't sure what the right type was
10:08:54 <int3__> [Char]->[Char], I guess
10:09:18 <int3__> but yeah, I didn't know how to convey that elegantly ^_^
10:09:40 <ReinH> int3__: prepending a char would be (:), which instantiates at Char -> [Char] or Char -> String
10:09:46 <ReinH> but is actually a -> [a]
10:10:19 <Pythonfant> isn't (:) a -> [a] -> [a] instead of a -> [a]?
10:10:23 <ReinH>  yes ofc
10:10:24 <kazagistar> ReinH: no, he got it right, he meant the type of something like ('a':)
10:10:38 <ReinH> Pythonfant: woops
10:10:41 <ReinH> kazagistar: ah
10:11:03 <kazagistar> the once curried cons
10:12:15 <ReinH> right
10:14:56 <ReinH> You can always replace a function call like that with a more initial encoding that you can use as a key, like data ConsChar = ConsChar Char deriving (Eq, Ord)
10:15:13 <ReinH> But I'm not really sure what you're doing
10:16:27 <athan> I must not be using sandboxes right... I'm trying to install a package that has a few of it's dependencies in external sandboxes, because they're conflicting on resourcet. However, when I'm trying to compile the monster, they're still trying to install resourcet! What did I do wrong? :(
10:17:52 <l0cust> Question for you all - what keyboard do you use?
10:18:01 <Zekka> l0cust: Crappy laptop keyboard.
10:18:08 <dmj`> same ^
10:18:29 <l0cust> I've got this old IBM model M
10:18:31 <athan> Here's my... attempt: http://lpaste.net/106796
10:18:41 <athan> ditto
10:18:48 <Ralith> http://pckeyboard.com/page/UKBD/UB4044A
10:18:53 <Ralith> which is like a model M
10:18:57 <Ralith> but USB and less ugly
10:19:07 <Ralith> and a few extra keys
10:19:26 <ajcoppa> i like my filco majestouch 2 with cherry browns
10:19:30 <l0cust> Ralith: that's what I mean
10:19:39 <l0cust> Ralith: they are fucking amazing, aren't they?
10:19:52 <coppro> Awesome laptop keyboard
10:20:04 <coppro> (thinkpad T440 series)
10:20:13 <Ralith> l0cust: I'm pretty happy with it
10:20:35 <athan> I'm actually using a joystick
10:20:43 <l0cust> athan: w the fuck
10:20:51 <athan> l0cust: xD
10:21:07 <l0cust> Ralith: My 5 year old das keyboard gave out, so it's back to the 10 year old model M
10:21:20 <athan> I'm trying to make an xOrg input device patchbay :(
10:21:28 <l0cust> athan: I see
10:21:29 <Ralith> I've got an original on my home machine
10:21:34 * hackagebot apiary 0.11.0 - Simple web framework inspired by scotty.  http://hackage.haskell.org/package/apiary-0.11.0 (HirotomoMoriwaki)
10:21:35 <Ralith> detachable cable model
10:21:36 * hackagebot apiary-logger 0.11.0 - fast-logger support for apiary web framework.  http://hackage.haskell.org/package/apiary-logger-0.11.0 (HirotomoMoriwaki)
10:21:38 * hackagebot apiary-persistent 0.11.0 - persistent support for apiary web framework.  http://hackage.haskell.org/package/apiary-persistent-0.11.0 (HirotomoMoriwaki)
10:21:40 * hackagebot apiary-websockets 0.11.0 - websockets supper for apiary web framework.  http://hackage.haskell.org/package/apiary-websockets-0.11.0 (HirotomoMoriwaki)
10:21:43 * hackagebot apiary-cookie 0.11.0 - Cookie support for apiary web framework.  http://hackage.haskell.org/package/apiary-cookie-0.11.0 (HirotomoMoriwaki)
10:21:46 <Ralith> I miss having a super key sometimes but damn if it isn't reliable
10:22:50 <rwbarton> still has more modifier keys than my laptop keyboard
10:23:43 <bluebelle> I started to think that newbie should build ghc,cabal,cabal-install manually instead of following haskell-platform...
10:24:15 <bluebelle> haskell-platform is outdated, and by building from source you store packages inside ~/.cabal/ which is better imo
10:24:21 <geekosaur> one problem is you're not actually using the platform
10:24:31 <geekosaur> you have ghc 7.8 installed
10:24:51 <geekosaur> platform is still waiting on ghc 7.8 bug fixes (I have not seen a release announcement for 7.8.3 yet)
10:25:15 <bluebelle> indeed, in the end I erased haskell-platform completely and everything works
10:25:45 <geekosaur> so this is because platform is not 7.8 yet, it is 7.6
10:25:57 <geekosaur> if ghc 7.8.3 will actually be released at some point...
10:26:24 <rwbarton> athan: if your dependencies conflict then they conflict
10:26:29 <rwbarton> athan: sandboxes don't solve this problem
10:26:45 * hackagebot apiary-clientsession 0.11.0 - clientsession support for apiary web framework.  http://hackage.haskell.org/package/apiary-clientsession-0.11.0 (HirotomoMoriwaki)
10:26:47 * hackagebot apiary-authenticate 0.11.0 - authenticate support for apiary web framework.  http://hackage.haskell.org/package/apiary-authenticate-0.11.0 (HirotomoMoriwaki)
10:26:49 * hackagebot creatur 5.5.0 - Framework for artificial life experiments.  http://hackage.haskell.org/package/creatur-5.5.0 (AmyDeBuitleir)
10:27:01 <athan> rwbarton: Hmm, what would be a good tactic to diagnosing & solving? Hacking the packages?
10:27:17 <rwbarton> sandboxes are for avoiding conflicts between thing A you want to build and unrelated thing B you want to build
10:27:27 <rwbarton> let me take a quick look at the error message
10:27:50 <l0cust> Haven't heard of that web framework
10:28:20 <athan> rwbarton: Oh okay, I think I'm starting to understand, thank you for helping me :)
10:28:43 <athan> l0cust: They're cropping up everywhere haha. Have you heard of Ur/Web? I'm making a CMS as we speak
10:28:44 <rwbarton> it's very likely that you can loosen some constraint somewhere in one of these dependencies to make it build
10:28:53 <l0cust> athan: in these cases, you usually have to edit a .cabal file
10:29:04 <athan> rwbarton: I'll get to it, thank you
10:29:18 <l0cust> athan: Whatever happened to good ol' happstack-server?
10:29:19 <athan> l0cust: *prays*
10:29:21 <athan> haha
10:29:27 <l0cust> athan: that's what I use
10:29:50 <l0cust> athan: I would probably use Warp were it not for the lack of documentation
10:29:58 <athan> l0cust: I'll check it out, I'm just accustomed to yesod
10:30:12 <l0cust> athan: Yesod is just so poorly documented
10:30:15 <l0cust> athan: I can't stand it
10:30:16 <athan> l0cust: It's pretty cool, I've made some basic middleware for it
10:30:23 <athan> It's not too bad haha
10:30:43 <athan> I love how fast it is
10:30:44 <l0cust> athan: Personally, I need to get shit done. I don't have time to play type tetris all day
10:30:57 <athan> it's monolithic, which is a pain, but i think it's got a lot going for it
10:31:00 <l0cust> athan: Yeah, I hate that it benchmarks so much
10:31:03 <l0cust> *so well
10:31:19 <athan> l0cust: Soon we'll be free
10:31:32 <l0cust> athan: You should show me this middleware
10:31:35 <athan> I need to fix shakespeare
10:31:38 <athan> it's not good enough
10:31:47 <athan> ehh, it's nothing great
10:32:04 <l0cust> athan: Anyway, I would happily use Warp if I didn't have to use the rest of Yesod to get anything done
10:32:15 <l0cust> athan: particularly if one could use it with the Happstack stuff
10:32:23 <athan> l0cust: I don't think it even works anymore https://github.com/athanclark/wai-ua-parser
10:32:26 <l0cust> athan: like web-routes
10:32:32 <kazagistar> int3__: so, just brainstorming, you might think about separating the process into two steps... filtering the trie, and building your resulting strings
10:32:52 <athan> l0cust: I'll check out happstack, I haven't gotten into it yet (or snap)
10:32:57 <ChrisBot2946> @bot cookie
10:32:58 <lambdabot> :)
10:33:01 <ChrisBot2946> @help bot
10:33:01 <lambdabot> help <command>. Ask for help for <command>. Try 'list' for all commands
10:33:08 <ChrisBot2946> @bot
10:33:08 <lambdabot> :)
10:33:21 <l0cust> athan: Snap is really nice. I don't care for its templating system, which is why I use Happstack
10:33:32 <l0cust> athan: also, happstack benchmarks ever so slightly better than Snap
10:33:33 <rwbarton> heh, i tried "cabal install --dry-run yesod-markdown-0.9.0" and it is just thinking at "Resolving dependencies..." for a good 30 seconds
10:33:49 <athan> hahaha
10:33:50 <l0cust> athan: neither of them compete with Warp
10:33:55 <athan> yeah this might be a fun project, too
10:33:58 <rwbarton> ok, it failed with a similar error
10:34:00 <athan> a hamlet output for pandoc
10:34:15 <l0cust> athan: that actually sounds pretty sueful
10:34:18 <l0cust> athan: useful
10:34:23 <l0cust> athan: well, it would have to be shamlet
10:34:28 <rwbarton> athan: since you seem to just be trying to install a single package, I'd try complaining to the maintainers of that package :)
10:34:28 <athan> l0cust: I still have no idea how it can be so fast haha
10:34:38 <athan> l0cust: :P
10:34:47 <int3__> kazagistar: mm okay I'll think about that
10:34:51 <l0cust> athan: If you don't write documentation, you can spend your time optimizing your code
10:35:04 <kazagistar> int3__:  now that I think about it, I am not positive that works for the second function
10:35:38 <Zekka> I can't help but think that I should feel grateful I'm in a shop that lets me write Lisp, but honestly I miss my type-safety
10:35:54 <athan> rwbarton: Will do haha. Thanks :)
10:37:08 <athan> l0cust: His design is awesome for it, wai is actually really simple
10:37:28 <athan> I have no idea how warp works, but it maps to wai which has never failed me
10:37:37 <athan> the crappy stuff happens at the yesod-level
10:37:48 <athan> That's where a lot of convolution happens
10:38:22 <athan> Zekka: I can't do without it
10:38:46 <athan> Zekka: I'll wake up in the middle of a cold sweat going "So that's what data kinds are for!"
10:38:49 <Zekka> athan: It doesn't help that builds take forever, so if I get something wrong it takes a little while to check
10:39:26 <athan> Zekka: I really like the ability to prove properties with type systems, it gives me confidence
10:40:46 <kazagistar> int3__: one thing to note, function parameters generally have the collection last, not first
10:41:29 <int3__> kazagistar: are you referring to `insert`?
10:41:37 <Zekka> By some miracle between the time I mentioned that and right now I seem to have fixed the bugs in the program I'm maintaining
10:41:52 <Zekka> because all of a sudden it works when previously it shouted about how I was turning strings into functions or something
10:42:14 <rwbarton> Zekka: the power of type systems
10:42:23 <kazagistar> int3__: Your functions are shaped like Trie -> String -> [String], as opposed to String -> Trie -> [String]
10:42:32 <rwbarton> just talking about them will fix your programs
10:42:47 <Zekka> Oh, there's actually one bug, but it's not types-related
10:43:29 <athan> Zekka: Haha! Magic!
10:43:31 <int3__> kazagistar: oh, I see what you mean. okay
10:43:43 <Zekka> Now that this portion's done I get to move back to a strongly-typed language: unfortunately, that language is Java
10:44:01 <benzrf> Zekka: :{
10:44:03 <Zekka> Er, I should say statically typed
10:44:13 <benzrf> what lang were u usin before
10:44:16 <Zekka> although even that's just politeness
10:44:26 <Zekka> We're doing the GUI stuff in Clojure
10:44:32 <benzrf> oh
10:44:50 <athan> Java makes my insides hurt
10:45:02 <MP2E> ^
10:45:04 <kazagistar> int3__: oh my, I just noticed... the fact that you are calling reverse on every word worries me, lemme figure out what you are doing exactly
10:45:10 <athan> Idris ftw
10:45:31 <Zekka> I didn't think Java would be as unpleasant as it ended up being when I suggested it
10:45:50 <int3__> kazagistar: I'm consing the characters together as I walk down the tree, so the words are getting built up in reverse
10:45:54 <MP2E> Idris, hmm.. I keep considering learning that :P
10:46:01 <MP2E> Dependent types look pretty cool
10:46:26 <MP2E> Do they overcomplicate things though, compared to haskell? I don't want to lose my power to weight ratio
10:46:29 <int3__> I could, I suppose, compose functions of the form ('a':) instead
10:47:03 <athan> l0cust: Happstack actually looks really nice, it looks like it has the same goals as yesod
10:47:11 <kazagistar> int3__: why? in the other function, you were doing it differently, where you filtered down, and then built the words back from the end. What made you change strategies?
10:47:17 <rwbarton> MP2E: I think that's a big open question
10:47:24 <athan> MP2E: Well, I value certainty a lot
10:47:40 <rwbarton> (my polite way of saying "yes" :P)
10:47:46 <rwbarton> at least, at present
10:47:49 <MP2E> hehe
10:48:05 <athan> I think they teach you more than they provide practical uses
10:48:09 <MP2E> I just can't help but think that Haskell will get them when the kinks are worked out :)
10:48:17 <MP2E> ahhh athan that makes sense
10:48:22 <athan> MP2E: Check out Omega :)
10:48:38 <athan> I think eventually Coq will rule
10:49:08 <Ralith> Coq is in some ways archaic
10:49:15 <Ralith> I'm hopeful for idris
10:49:22 <athan> Omega has an ingenious dependent-like type system (I still haven't gotten through it yet, though :P)
10:49:41 <int3__> kazagistar: findConstraints was originally written in the other form as well, but I rewrote it in a fashion I thought more elegant. then I realized that this was probably inefficient because each call to (>>=) was copying the same items over and over, but I was too lazy to redo findConstraints again
10:49:57 <int3__> plus most of the time findConstraints will only be called with one '*'... I'm just making it general for completeness
10:50:02 <int3__> so performance isn't as much of an issue there
10:51:01 <int3__> kazagistar: I also checked the Core output to make sure GHC wasn't optimizing the copies away, and it seems like it indeed doesn't
10:51:26 <napping> Is there any reason selector thunks are only used/work for single-constructor types?
10:51:30 <Peaker> I've got a case of a stack overflow with WriterT () and no overflow with StateT ().  Weird
10:51:41 <napping> is it that weird?
10:51:56 <napping> isn't WriterT building up a big lazy (() `mappend` ()) `mappend` () tree?
10:52:01 <Peaker> both are the strict transformer variants
10:52:08 <Peaker> does the Writer.Strict do that?
10:52:35 <rwbarton> yes
10:52:40 <Peaker> why?
10:52:42 <rwbarton> it's just strict in the pair (w,a)
10:53:02 <Peaker> well, I tried my own Writer just in case that at least tried to force the mappend results
10:53:08 <Peaker> rwbarton: what's the point of being strict on the pairs?
10:53:37 <rwbarton> well, for Writer, there is no point really because of the w build-up issue
10:54:37 <rwbarton> the strict State is also only strict in the pair, but because you can access the state from inside the monad, you can force it yourself
10:54:47 <Peaker> http://lpaste.net/106800 <-- I tried this one. it doesn't mappend anything, still stack overflow
10:55:14 <solidus-river> what are thoughts on pipes vs conduit
10:55:19 <Peaker> I've got a big "ParsecT m" computation that stack overflows when   m=WriterT () IO    but doesn't if m=IO or m=StateT () IO
10:55:55 <napping> are you quite sure it doesn't mappend anything?
10:56:03 <Peaker> napping: note the "undefined" there
10:56:14 <Peaker> I don't ever use the "w" result here
10:56:19 <rwbarton> try deleting the Monoid w context, then you can be sure :)
10:56:26 <rwbarton> and use undefined for mempty too i guess
10:57:00 <Peaker> yeah, doing so now :)
10:57:10 <napping> that should do it now
10:57:25 <kazagistar> int3__: hmm, lemme think about it a bit, it seems like as you iterate, most of findConstraints fuse, so the difference wouldnt be big? I am not sure I understand which copies you mean
10:57:29 <napping> but note you're still calling next not in a tail position
10:57:36 <napping> so that's probably taking stack space
10:57:37 <Peaker> http://lpaste.net/106800 <-- removed Monoid context
10:58:02 <Peaker> napping: is there any way to avoid that?
10:58:20 <napping> switch to StateT
10:58:24 <napping> or build WriterT on StateT
10:58:50 <rwbarton> or in your little test case, return (w',r') / replace lines 8-9 entirely by just 'net'
10:59:19 <napping> If you like, think of getting into tail form by passing a continuation saying how to transform the value
10:59:41 <Peaker> rwbarton: that does prevent the stack overflow!
10:59:46 <napping> then realizing you only use ones of the form (w<>), and Monoid is associative so you might as well pass in a w
11:00:05 <napping> Peaker: at the cost of only returning the writer stuff from next and ignoring those from act
11:00:21 <napping> after changing that, you have WriterT w m a = w -> m (w,a)
11:00:25 <napping> hmm, looks familiar
11:00:36 <Peaker> WriterT is weaker than StateT, so you'd expect it to have better performance characteristics
11:00:55 <Peaker> napping: there's something nice about weakness in WriterT though
11:01:12 <napping> sure, but implement your strict WriterT like that
11:01:14 <rwbarton> sure, then you can expose the WriterT interface on top
11:01:22 <napping> you can get some use out of a lazy writer
11:01:30 <napping> and may even avoid the whole stack overflow, not sure
11:01:33 <Peaker> well, for Writer (not WriterT), the fact it's a mere tuple can actually cause CSE
11:01:38 <int3__> kazagistar: e.g. if we called findConstraints with "f*r*", and "fare", "farm", and "fury" are in the trie. then at the first "*", we'd have [["ae", "am"],["uy"]] which we need to flatten
11:01:42 <int3__> so ["ae", "am"] gets copied
11:01:47 <napping> and this implementation is good for strict
11:02:01 <napping> I don't think anybody has any examples where the pair-based strict writer is a good idea
11:02:09 <int3__> if there were another wildcard higher up in the trie, the entire list of ["ae", "am", "uy"] would get copied again
11:02:24 <Peaker> I wonder if some sort of ContT transform somewhere could avoid the problem (allowing turning the mappend into tail form somehow?)
11:02:38 <Peaker> napping: I always thought the "Writer problem" was "mappend build up"
11:02:46 <rwbarton> me too
11:02:48 <Peaker> but now I see it's the non-tail-call to mappend
11:02:57 <rwbarton> well, it's both
11:02:57 <napping>  huh, I think that varies
11:03:06 <rwbarton> I think it depends on how you have your binds associated
11:03:12 <napping> if it wasn't a strict writer it at least wouldn't quickly lead to a stack overflow
11:03:26 <Peaker> If I ContT the WriterT (I forget from which direction) it re-associated everything to the right
11:03:39 <Peaker> napping: I don't think it matters if I use the lazy or strict writer
11:03:43 <l0cust> Is there any planned updates to RWH
11:03:56 <l0cust> Some of the information there is outrageously out of date
11:04:09 <kazagistar> copied? doesn't it just copy the pointer to each item in the iterator as you iterate through?
11:04:36 <Peaker> It seems like "WriterT" doesn't scale to any amount of binds, which makes it a bit useless, reliability-wise?
11:04:59 <Peaker> A bit pointless/dangerous to even have it, perhaps?
11:06:34 <ReinH> For foldl-shaped computations (i.e. worker/wrapper) you generally need both tail position (left-most, outermost) and a strict accumulator for constant space.
11:07:02 <ReinH> I think SimonM calls it "corner" position or something.
11:07:26 <Peaker> There was a nice article way back when about translating some Python code to Haskell, using Writer.  This made an exponential algorithm linear -- because GHC used CSE on two Writer actions (as they are just tuples). That optimization is not possible in the underlying State representation.. so I'm really saddened to throw that cool notion away because of the tail-call issue :(
11:08:12 <ReinH> Peaker: what "tail-call" issue?
11:08:43 <Peaker> ReinH: WriterT's >>=  has to mappend the two w's from the two computations *after* both
11:08:47 <napping> I don't see how you could CSE that in a transformer
11:08:58 <napping> at least not in a way that depends on the writer representation
11:09:04 <napping> if it's really visibly pure it should hoist anyways
11:09:12 <Peaker> ReinH: so >>= isn't tail-recursive, it has to apply an extra computation after. So every (>>=) builds up on the stack, and if you have many binds, you eventually stack overflow with WriterT :-(
11:09:17 <napping> and a if I might depend on the underlying monad you couldn't CSE it in general
11:09:34 <Peaker> napping: what do you mean by "it should hoist anyways"?
11:09:41 <Ankhers> :t (***)
11:09:42 <lambdabot> Arrow a => a b c -> a b' c' -> a (b, b') (c, c')
11:10:03 <napping> you can write something like let x = exensive in tell x >> tell x anyway
11:10:24 <napping> and couldn't possibly CSE something like (getChar >>= tell) >> (getChar >>= tell)
11:11:02 <napping> so I wonder if a value-passing implementation is really worse for that optimization
11:12:18 <napping> I think the lazy writerT can do interesting things with lazy patterns on the result tuple that avoid stack overflow
11:12:22 <Cale> Peaker: >>= isn't recursive at all, is it?
11:12:36 <Cale> Peaker: Unless you're talking about a different monad instance than I thought
11:13:07 <napping> not recursive, but it for a strict WriterT at least it doesn't call the right argument in a tail position
11:13:26 <Ankhers> Could someone please tell me the purpose of doing `f *** f`?
11:13:30 <Peaker> Cale: well, it's not directly recursive, true. But it calls the inner monad's >>= which then does bind again in WriterT, forming a recursion
11:13:39 <Peaker> Ankhers: you want to apply f on both components of a tuple
11:13:47 <ReinH> Peaker: lazy evaluation doesn't need to be recursive
11:13:57 <Peaker> ReinH: not talking about lazy evaluation though
11:14:06 <Ankhers> Peaker: Thank you!
11:14:09 <Peaker> ReinH: http://lpaste.net/106800
11:14:20 <Cale> Is that the code we're looking at?
11:14:20 <ReinH> Peaker: if you think you're talking about "tail calls" and "tail position" then you are definitely talking about lazy evaluation.
11:14:34 <ReinH> Peaker: since GHC does not perform any TCO aside from what is done by lazy eval
11:14:36 <Peaker> (w', r') <- next ; return (undefined, r')  <---- this stack overflows whereas replacing it all with "next" doesn't
11:14:45 <Cale> I always feel awkward when people start talking about tail calls in Haskell as if they have something to do with the contents of the stack
11:14:58 <ReinH> Cale: yes
11:15:24 <Peaker> Cale, ReinH: How would you describe the paste above behaving as I described?  i.e: Making the inner monad's >>= a tail-call removes a stack overflow?
11:15:30 <ReinH> tail calls are reduced because they are in the right place for left-most, outermost redex reduction
11:15:49 <napping> Cale: if the continuation of a recursive call is strict in that call,you'll get a stack overflow
11:15:51 <ReinH> @where lazy
11:15:51 <lambdabot> http://www.vex.net/~trebla/haskell/lazy.xhtml
11:16:41 <ReinH> see also http://stackoverflow.com/questions/23893320/why-isnt-this-recursive-function-being-optimized-haskell/23894550#23894550
11:16:45 <Cale> Peaker, napping: At least as I tend to picture things, the stack consists of pattern matches which are waiting for their scrutinee to be sufficiently evaluated to match.
11:16:56 <Cale> "Calls" don't really go on any sort of stack
11:17:05 <Peaker> Cale: then what is overflowing the stack in my example?
11:17:07 <napping> ReinH: fair enough that not using the words tail call might be clearer, even if it's accurate in places
11:17:37 <napping> Peaker: For the same reason you'd say "non-tail-call", the final result of your code depends on a pattern match which forces the pair coming from next
11:17:39 <Cale> Peaker: I didn't see the example
11:17:40 <statusfailed> Does anyone know the name of that XSS (maybe?) attack where you embed something like an iframe pointing at mybank.com/api/account/delete ?
11:17:49 <Peaker> Cale: http://lpaste.net/106800
11:17:50 <Cale> Peaker: Is it that http://lpaste.net/106800 ?
11:17:59 <Peaker> Cale: lines 8-9 in annotation
11:18:00 <int3__> kazagistar: no, I'm pretty sure concat is getting called repeatedly to produce the final result. The 'lazy' result would be something like `map ('a':) (["e"] ++ ["m"]) ++ map ('u':) ["y"]`
11:18:08 <Cale> Where's the code that actually triggers the stack overflow?
11:18:14 <Peaker> Cale: replace them with "next" and it stops overflowing
11:18:18 <int3__> so in this case, we copy "e" once to make ["e", "m"]
11:18:32 <int3__> kazagistar: and then we copy ["ae", "em"] again to concat with the final result
11:18:48 <ReinH> Peaker: you should read that lazy post. It helped me a lot.
11:18:50 <Cale> Peaker: Well, you have an extra pattern match -- you're decomposing the pair
11:19:12 <Cale> Peaker: So that pattern match is something which will wait on the stack, and could contribute to a stack overflow
11:19:18 <int3__> kazagistar: so "e" is getting copied twice, which is unnecessary
11:20:47 <Peaker> Cale: well, if an expression is in a tail position, it cannot have extra pattern matches waiting after it :)  I agree though that if the extra code happens not to be a pattern match, but a constructor call, it will not behave similarly
11:21:12 <Cale> It's just that it's not the *call* which waits on any stack, but the match.
11:21:16 <Peaker> So the question is how to fix this stack overflow -- without losing the CSE you get when m is known to be Identity or some other pure monad
11:22:20 <Peaker> Cale: well, I imagined it as the continuation waiting on the stack, and that the continuation happens to do a pattern-match, but you're right that it matters what the continuation does -- it has to pattern-match to be on the stack.  If you "see through" applications, then pattern match or constructor buildup are really all there is, right?
11:22:34 <statusfailed> ah it's "cross site request forgery"
11:23:03 <Cale> Peaker: Yeah, the only things which end up using the stack are pattern matches (case expressions) and applications which have to wait for the function to be a lambda.
11:23:31 <Cale> But I don't think I've ever seen a stack overflow in real code happen because of entries from applications.
11:23:32 <kazagistar> int3__: wont the same number of copes happen in the "reverse" case? I feel like I am missing something...
11:23:34 <bennofs> statusfailed: CSRF just says that you make the user access that url, but yes, it should be a special case of it
11:23:59 <ReinH> I am still trying to remove the term "function call" from my Haskell vocabulary
11:24:01 <ReinH> it is difficult
11:24:16 <Cale> Half the time I don't even really know what "call" means anymore
11:24:21 <Cale> :D
11:24:24 <ReinH> Cale: exactly why :)
11:24:58 <ReinH> My brain needs to s/call/application/g
11:24:59 <Cale> and all the call-by-X names for evaluation schemes are totally unintuitive to me
11:25:01 <monochrom> I still keep "call" because in rank-n types I want to say "caller chooses" and "callee chooses"
11:25:09 <Cale> because I think primarily in terms of graph reduction
11:25:17 <ReinH> monochrom: ah
11:25:18 <Peaker> Cale: it seems like this overflow is not unique to my circumstance but really inherent to how WriterT works -- and that the only way to solve it is to implement WriterT with StateT representation? :( Which loses out some nice advantages
11:26:10 <int3__> kazagistar: oh. uhhhh. I see what you mean... I think you're right :x
11:26:32 <Cale> Peaker: It would be good to see the code which actually triggers the stack overflow
11:26:34 <monochrom> to your delight, "call" no longer has control-flow meaning. it's just "use".
11:26:42 * hackagebot fb 1.0.2 - Bindings to Facebook's API.  http://hackage.haskell.org/package/fb-1.0.2 (FelipeLessa)
11:26:54 <int3__> (>>=) makes excessive copies of the characters at the end of the word, and `reverse` does that for the characters at the beginning...
11:26:54 <monochrom> just like "dashboard" no longer means dashboard :)
11:26:55 <int3__> welp
11:28:32 <Peaker> Cale: it's a big ugly ParsecT (WriterT ...) parser
11:28:46 <int3__> kazagistar: let me think about this for a bit more
11:29:34 <kazagistar> int3__: also, I found it interesting that you used >>= in one place, and concatMap in the other :P
11:29:58 <monochrom> throw in =<< somewhere to be complete :)
11:30:12 <rwbarton> and a list comprehension
11:30:27 <monochrom> \∩/
11:30:43 <kazagistar> and one with do notation to be thorough :P
11:30:53 <monochrom> yeah, I forgot do
11:31:31 <merijn> I have questions about Awodey...(or rather, I have questions about a bunch of stuff his book leaves implicit)
11:31:42 * hackagebot yesod-recaptcha 1.2.3 - Dead simple support for reCAPTCHA on Yesod applications.  http://hackage.haskell.org/package/yesod-recaptcha-1.2.3 (FelipeLessa)
11:32:09 <merijn> He mentions that "for any set X, we have the group Aut(X) of automorphisms (or "permutations") of X", it's not clear why any automorphism of X is a permutation?
11:32:11 <int3__> kazagistar: haha. I was excited to use my first monadic operator :P but then for the second line the 'computation' was flowing from right to left and it seemed weird to flip it around
11:33:02 <Peaker> another weird thing is that ghc-7.6.3 stack overflows always. ghc-7.8.2 doesn't stack overflow by default, but does stack overflow if -K8M is given where 8M is the default!
11:33:05 <Peaker> i.e: -K is a lie
11:33:16 <Peaker> (it's not really just changing the maximum, but something else too)
11:33:19 <monochrom> what is your criterion for "permutation"? because to me "permutation" and "automorphism" are synonyms.
11:33:32 <merijn> monochrom: I don't know, that's what I was asking you!
11:33:35 <geekosaur> I thought the stack was no longer limited in 7.8.2 by default?
11:34:22 <monochrom> f : {0,1,2} -> {0,1,2}, f(0)=1, f(1)=0, f(2)=2 is a permutation and an automorphism.
11:34:25 <Peaker> geekosaur: ah, so +RTS --help should be fixed to remove the "8M" default
11:34:31 <Peaker> ("default: unlimited")
11:34:45 <dmj`> is it true that cabal install automatically attempt to parallelise installs, but cabal build hasto explicitly be passed the -j flag to parallelise?
11:34:47 <schell> can one use pattern guards in a $ \a b c -> ?
11:34:48 <geekosaur> possibly. might ask in #ghc if the limit was actually removed
11:35:09 <geekosaur> I know it's *supposed* to be removed at some point, and I thought that got into 7.8
11:35:16 <merijn> monochrom: Is it that since any automorphism 'f' must be 'X -> X' (i.e. it maps to the same set 'X', so must have the same elements) combined with the fact that it's a group of automorphisms (i.e. each one has an inverse making it reversible)?
11:35:49 <monochrom> wait a second. I am just talking about one automorphism.
11:35:53 <int3__> kazagistar: so, I think I am correct about the efficiency thing. to go back to my example, if the result is ["ae", "am", "uy"], "e" would only be copied twice by `reverse`, regardless of how many N wildcards are used in the search string. however, the concatMap method would ensure "e" gets copied N times
11:36:12 <merijn> Oh, wait
11:36:20 <merijn> I guess an automorphism is invertible by definition
11:36:32 <monochrom> it's X->X and it's a bijection. and so it's a permutation.
11:37:06 <merijn> monochrom: I wish there was a CT book that spelled out the "obvious" implications of definitions like that for plebs like me >.>
11:38:08 <monochrom> all CT books have math majors in mind. there is only one exception. Lawvere's "conceptual mathematics".
11:38:52 <Pythonfant> monochrom: that's probably why I'm really having a hard time working myself through categories for the working mathematician
11:39:04 <int3__> kazagistar: in that example, "a" would get copied twice by reverse, and if there are M results that start with "a", it would get copied M times... but that's no different from the concatMap case, where `map ('a':)` would copy it M times too
11:39:18 <ticktockman> Is there a way to do "State s a -> StateT s IO a"
11:39:23 <monochrom> well, another exception, Pierce's "CT for CSists". but then it has CS majors in mind, hell, it has CS majors who took serious FP courses in mind
11:39:48 <Peaker> I'm still unsure when one can be safe in the reliability of WriterT -- should WriterT simply always be avoided like the plague?
11:39:59 <merijn> monochrom: I think Awodey is more readable than Pierce, tbh
11:40:37 <merijn> Peaker: There's a bunch of recurring discussion on WriterT and what it "should be", so yes there's people who agree with you
11:41:57 <Saizan> monochrom: is conceptual mathematics also for CS majors?
11:42:01 <zq> is it possible to control the in-memory runtime representation of a given datatype?
11:42:08 <monochrom> no
11:42:57 <kazagistar> int3__: ugh, I am still not seeing it, lemme step through it carefully
11:43:12 <merijn> zq: I did some serious digging about this and the answer is indeed "no" and the reason is that a datatype may not even necessarily have runtime representation!
11:43:32 <Pythonfant> btw if we are already talking about ct books: any easier to understand books about ct than categories for the working mathematician you can recommend? I'm getting to a point where I think it isn't much use to read further through it.
11:43:38 <merijn> i.e. it's gets CPS'ed/optimised away
11:43:54 <alpa_astero> Pythonfant: awodey?
11:44:13 <RchrdBrrll> zq, the one thing that you can do is make up a data type that has a Storeable instance whose representation you control.
11:44:15 <monochrom> everything mentioned so far is easier than Working Mathematician
11:44:37 <monochrom> mainly because none of us is a working mathematician :)
11:44:49 <merijn> RchrdBrrll: That still means explicit conversion which may or may not be costly
11:44:53 * monochrom has a BSc in math and still not a working mathematician :)
11:45:23 <merijn> zq: A better question might be: What makes you want to control the runtime representation? There may be better ways of solving your problem
11:45:43 <MP2E> Since I started learning Haskell, I realized that what I *really* want to do is major in Math, not CS
11:45:44 <rwbarton> you have some amount of indirect control
11:45:51 <RchrdBrrll> zq, why are you trying to get a datatype with a specific shape? If it's for efficiency then you don't really need *exact* control over the layout, just the facts about the layout that matter to performance. You have access to tricks like the UNPACK pragma to give the compiler hints about how your data type could be most efficiently arranged.
11:46:17 <ReinH> Trying to work through CftWM forced me to read Awodey's CT, which actually ended up working pretty well
11:46:32 <Pythonfant> alpa_astero: thx
11:46:49 <ReinH> Interstingly, Mac Lane's Algebra is very approachable for a layperson.
11:47:08 <ReinH> and actually does a pretty good job of introducing the basics of CT as well
11:47:21 <RchrdBrrll> zq, if on the other hand, you want to have a data type with a specific shape in order to be compatible with, say, a C struct or Cap'n Proto or something else which specifies a particular memory layout that you have to interoperate with, then a Storable instance is exactly what you want.
11:47:27 <Qfwfq> The _Survey_ he co-wrote with Birkhoff was my first introduction to formal math I think
11:47:58 <ReinH> Qfwfq: A Survey of Modern Algebra? It's not quite so modern any more, is it? ;)
11:48:17 <zq> merijn: what i'm after is an optimally compact representation, specifically encoding a series of enum-likes as bits of a Word64
11:48:18 <RchrdBrrll> merijn, (maybe, but it's the right thing to do if what you care about is interoperability with some external thing that specifies a memory layout, rather than just caring about performance)
11:48:39 <Pythonfant> crap the university library doesn't seem to have awodey's ct
11:49:05 <Lutin`> Bah
11:49:12 <Lutin`> Working with spreadsheets is a pain in my butt
11:49:13 <merijn> zq: Won't work, I was working on a nice way to do that with a preprocessor, some newtypes and PatternSynonyms, but it's currently shelved blocked on my haskell CPP implementation not being done
11:49:19 <zq> RchrdBrrll: controlling serialization wouldn't really help here, so i'm not sure how capnproto and its likes would help
11:49:30 <ReinH> rwbarton: in any event, you aren't going to do any structure packing in Haskell ;)
11:49:37 <zq> merijn: would Storeable not work?
11:49:44 <monochrom> we pirate Awodey's pdf around :)
11:49:48 <RchrdBrrll> zq, I brought that up because I hadn't established what your goals were.
11:50:03 <merijn> zq: Storable requires explicit conversion between a haskell datatype and whatever C wants
11:50:07 <RchrdBrrll> zq, and it's Storable, not Storeable. I made a typo the first time.
11:50:10 <ReinH> monochrom: we are terrlble people, yes ;)
11:50:15 <RchrdBrrll> Storable is really for interop with C.
11:50:17 <merijn> Or you essentially using Word64
11:50:51 <ReinH> monochrom: I found a 400+MB torrent of CT books and papers. I felt bad, but I still downloaded it. To be fair, I do own quite a few of the books in it already...
11:51:06 <Lutin`> I also have a copy of Conceptual Mathematics and Algebra: Chapter 0 if anyone wants one
11:51:15 <ReinH> I actually don't feel too bad about pirating papers, as the academic publishing industry is a racket that I feel ethically compelled to not support.
11:51:18 <monochrom> I don't want to read 400MB of anything :)
11:51:26 <ReinH> monochrom: it's a nice reference to have around :)
11:51:39 <monochrom> ah, that's handy, yes
11:51:51 <ReinH> monochrom: there's some nice categorical logic stuff
11:52:00 <ReinH> that I still haven't gotten around to reading :/
11:52:29 <monochrom> I have only read about 20% of the books I bought
11:52:38 <kazagistar> int3__: could you pastebin the core for that function or something? the most number of copies of a character I see are (1) once total per wildcard from the map into the curried cons, and (1) once per final word, as it evaluates the cons... other then that, I just see a bunch of list concats, which dont touch the characters at all
11:53:30 <ReinH> monochrom: btw I picked up Bird's _The Algebra of Programming_ and it's wonderful
11:53:31 <monochrom> http://www.vex.net/~trebla/tmp/act.pdf for a few minutes!
11:53:59 <monochrom> that one I managed to painstakingly read the first half
11:54:02 <Lutin`> monochrom: <3
11:54:14 <monochrom> it was almost 1 month per chapter!
11:54:39 <ReinH> monochrom: except that it uses Gofer, lots of uncurried functions, and writes function application and composition backwards, so you have to mentally translate everything
11:54:55 <monochrom> fortunately, "what doesn't kill you makes you stronger". after surviving it, I fear nothing anymore :)
11:55:12 <monochrom> oh, don't mentally translate. adapt.
11:55:16 <ReinH> monochrom: oh, Awodey?
11:55:24 <kazagistar> int3__: ah, is the idea that the first copy will happen regardless of if you find any matching words in the map or not?
11:55:26 <monochrom> Bird. Algebra of Programming
11:55:47 <ReinH> monochrom: Ah, yes, it's rather slow going
11:56:06 <ReinH> monochrom: but a very nice introduction to algebraic program derivation
11:56:12 <kazagistar> int3__: you know what? your program feels more like a strange form of zipWith of a sequence and a tree, that filters the tree as it goes... there has to be a nice pattern here somewhere
11:56:17 <ReinH> which puts his pearls book into better context for me, etc
11:56:32 <ReinH> int3__: can I see your program?
11:56:41 <Lutin`> monochrom: How do you like vex.net?
11:57:03 <int3__> ReinH: http://www.reddit.com/r/haskell/comments/29ndnd/request_for_code_review_anagrammer_first_haskell/
11:57:15 <monochrom> I like it very much. I rely on it for email, my web pages, and a few IRC bots
11:57:24 <int3__> kazagistar: http://pastebin.com/i2NecbZW
11:57:24 <Qfwfq> I liked _Pearls_. "Here's this problem specification! Here's how it looks in Haskell! OMG, they read alike! Not here's how to incrementally improve it toward being worth a damn."
11:57:51 <Lutin`> monochrom: I was thinking about buying a VPS, but not sure if I really need that much and I worry about the potential costs
11:58:20 <monochrom> a unix shell account may fulfil some of your needs
11:58:32 <Lutin`> Qfwfq: Pearls?
11:58:43 <Lutin`> http://www.cs.nott.ac.uk/~gmh/pearl.pdf ?
11:58:50 <Qfwfq> Lutin`: Bird's _Pearls of Functional Algorithm Design_. ReinH just mentioned.
11:58:54 <Lutin`> Ah
11:59:19 <monochrom> I have only read 2 chapters of that one!
11:59:25 <int3__> kazagistar: sooo I think I got mixed up a little bit -- you're right, the list appends don't touch the characters at all, I'd forgotten about that -- but we are still allocating lots of intermediate lists that get thrown away after appending at each level of the tree
11:59:29 <ReinH> monochrom: heh
11:59:33 <Lutin`> Time to find the PDF..
11:59:45 <Qfwfq> Lutin`: 's on LibGen.
11:59:49 <Ankhers> I have a strict ByteString, but I need a lazy one. Is there an easy way to make this transformation?
12:00:06 <ReinH> monochrom: One thing I learned from that book is that monoid morphisms give you free divide and conquer algorithms :D
12:00:18 <Lutin`> Qfwfq: Oh nice thanks
12:00:34 <Qfwfq> Ankhers: Usually when I ask myself similar questions I look up the relevant instance in string-conversions.
12:00:58 <Lutin`> Looks like the site is choking right now
12:01:17 <ReinH> Ankhers: I wish bytestring exported a function `relax' for this purpose ;)
12:01:22 <int3__> kazagistar: but the asymptotic cost should be the same as that required for all the other operations... so... uh yeah I think you're right :x
12:02:04 <int3__> sorry, too many years of writing quasi-functional code in JS leaves me seeing copies when there aren't any :x
12:02:11 <ReinH> int3__: GHC is pretty good at optimizing away ephemeral intermediate lists, e.g., via short-cut fusion
12:02:40 <kazagistar> int3__: right, but the full list is never allocated... lists in these sort of contexts function as iterators, they hold little other then the state needed to know "where they are in the tree"
12:06:13 <kazagistar> hmm, does ghc optimize deeply chained list monads in the same way python's "yield from" optimizes generators?
12:07:02 <Lutin`> Here is Lawvere's Conceptual Mathematics for anyone who wants it: http://expirebox.com/download/7908b7733b73c0eb4b799141549ba785.html
12:07:02 <kazagistar> ... I think so, but my reasoning here is still slow...
12:07:17 <Lutin`> As an epub
12:08:04 <int3__> kazagistar: the appearance of (++) in the Core code suggest it doesn't, I think... and I still don't understand enough about how GHC's allocation works, but my impression has been that even lazy evaluation results in heap allocation, just not of the whole list at once
12:08:35 <int3__> ReinH: yeah I'm aware of fusion but I think in my case the appends are not optimized away, judging from the Core output
12:11:14 <kazagistar> int3__: when you have nested iterators, each iterator has to store its state somewhere in memory, but you have at most as many as you have characters in your constraint string...
12:12:13 <Lutin`> int3__: Does that code work?
12:13:42 <int3__> kazagistar: I was told by some other #haskell people yesterday that this was the efficient way to convert a Tree to a List: http://lpaste.net/106683 (as opposed to calling append on every node) so I was trying to apply that idea to my own code... I think the difference really is that in my case I am applying an operation at each node that is of the same asymptotic complexity as the concatMap
12:13:53 <int3__> Lutin`: yeah, I've been testing it in ghci so far
12:14:44 <Lutin`> Because the way I would imagine doing it is you'd insert the sorted word but store the original word in a leaf
12:14:56 <ASHPrime> Afternoon gents
12:14:57 <Lutin`> That way finding anagrams is just a tree traversal
12:15:14 <int3__> Lutin`: that doesn't allow for wildcards, though
12:16:06 <Cale> int3__: The general idea is that when you have a piece of code which needs to do a lot of list concatenation, it can be more efficient to replace the list type [a] with functions of type [a] -> [a] which add elements to the beginning of a given list, replace [] with id, replace [x] with (x:) and replace (++) with (.)
12:16:44 <Cale> Since computing xs ++ ys takes O(length xs) steps while (.) is always constant time, this can improve asymptotic complexity
12:16:57 <int3__> Cale: yeah I understood that part
12:18:48 <Lutin`> Ah yes
12:18:58 <Cale> Which function are you having performance trouble with here?
12:19:55 <Cale> Honestly this code looks pretty reasonable
12:20:12 <int3__> Cale: https://github.com/int3/scrabble-solver/blob/master/Trie.hs#L30 not really performance trouble, just debating complexity
12:20:27 <int3__> since I'm calling (>>=) on every node
12:21:20 <int3__> I thought that would be inefficient, but I now realize that it's not any more asymptotically complex than calling map ('a':), which I'm already doing on every node
12:23:22 <Cale> int3__: Also, due to lazy evaluation, it's effectively depth-first
12:23:37 <int3__> right
12:26:17 <ticktockman> Is there a way to use a function of type "State t a" inside a function of type "StateT t IO a"?
12:27:25 <Cale> ticktockman: Use runState?
12:27:50 <dwcook> @hackage mmorph
12:27:50 <lambdabot> http://hackage.haskell.org/package/mmorph
12:27:50 <ticktockman> Then put the state, right?
12:27:57 <dwcook> ticktockman, that package contains a nice way
12:28:01 <dwcook> I think it's hoist generalize or something
12:28:03 <dwcook> @type hoist generalize
12:28:04 <Cale> ticktockman: Also, neither of those are function types (though internally the implementation uses functions)
12:28:04 <lambdabot> Not in scope: ‘hoist’
12:28:04 <lambdabot>     Not in scope: ‘generalize’
12:28:04 <lambdabot>     Perhaps you meant ‘generate’ (imported from Lambdabot.Plugin.Haskell.Eval.Trusted)
12:28:08 <monochrom> make that function have type "MonadState m t => m t a" to begin with
12:28:22 <monochrom> @type get
12:28:23 <lambdabot> MonadState s m => m s
12:28:37 <monochrom> oops, "MonadState t m => m t a"
12:29:09 <dwcook> From the docs: hoist generalize :: (Monad m, MFunctor t) => t Identity b -> t m b
12:29:24 <dwcook> That looks like exactly what you want
12:29:38 <ticktockman> dwcook: Yeah that looks good. Thanks
12:31:48 * hackagebot peyotls 0.0.0.12 - Pretty Easy YOshikuni-made TLS library  http://hackage.haskell.org/package/peyotls-0.0.0.12 (YoshikuniJujo)
12:33:09 <kazagistar> for all I know, recursion-schemes does exactly what I want >_>
12:35:11 <Lutin`> ticktockman: If you don't want all of mmorph : StateT (\s -> return (runIdentity (runStateT m s))) where m = your function
12:36:03 <ticktockman> Lutin`: Wouldn't I have to put the state too?
12:38:57 <Lutin`> You want to use a different state than the one in "StateT t IO a"?
12:42:04 <dfeuer> Cale, I wonder if you might be the one who can answer http://stackoverflow.com/questions/24484348/what-does-this-list-permutations-implementation-in-haskell-exactly-do
12:43:39 <Cale> dfeuer: Perhaps. I haven't looked at this code before, but we can take a look at it and see what the pieces do.
12:43:59 <dfeuer> OK.
12:44:21 <benzrf> :t embed
12:44:22 <lambdabot> Not in scope: ‘embed’
12:44:36 <Cale> dfeuer: First of all, looking at the second line, it appears that the original list is thrown in at the beginning, so that  perms xs0 []  must be the list of all non-identity permutations of xs0
12:44:44 <Ankhers> Could someone either explain or point to a tutorial on how (>>=) works? I apparently don't understand.
12:44:49 <dfeuer> Cale, I've pieced together some ideas about what sort of procedure a permutations implementation satisfying the desired laziness requirements must follow,
12:44:59 <dfeuer> but then everything gets very confusing in the implementation.
12:45:07 <Cale> Ankhers: (>>=) is overloaded. It does something different for each choice of monad.
12:45:17 <Cale> Ankhers: So, you'd have to say which monad you mean.
12:45:50 <Ankhers> IO
12:46:00 <dfeuer> The return value has to be partially ordered by the (original) position of the last element that is moved.
12:46:19 <Cale> Ankhers: Okay, so let's look at the type of it in this case. (>>=) :: IO a -> (a -> IO b) -> IO b
12:46:50 <Cale> Ankhers: A value of type IO t is a description of some action which could be carried out to eventually produce a result of type t.
12:47:00 <kazagistar> dfeuer: it sounds like the code's original author is confused by the code (or just forgot), so the best option might just be to let the code be
12:47:34 <bennofs> Can I tell cabal to enable C99 support when compiling c-sources?
12:48:17 <Lutin`> ticktockman
12:48:19 <Lutin`> :t (\f -> StateT (\s -> return (runIdentity (runStateT f s))))
12:48:20 <lambdabot> Monad m => StateT s Identity a -> StateT s m a
12:48:21 <Cale> Ankhers: and so let's look at x >>= f where we have x :: IO a, that is, an action producing some result of type a when executed, and f :: a -> IO b, which is a function from values of type a, to actions producing results of type b
12:48:37 <Lutin`> ticktockman: Is that not what you want?
12:49:02 <ticktockman> Lutin`: Oh, never mind. I see. No, I was confused. Thanks for your help.
12:49:09 <Lutin`> np
12:49:17 <Cale> Ankhers: This combined action will have a result of type b, and what it's going to do when executed is first to execute x, getting the result, say v of type a, and then apply f to that result to get f v, which is an action producing a result of type b
12:49:32 <Cale> Ankhers: It'll run that action, producing its result as its own.
12:49:54 <jg_> hi all, how can i simplify abParser_ = fmap (\p -> ()) abParser ? Tried fmap (id ()) abParser but it doesn't work for some reason...
12:50:06 <dfeuer> So the function first produces some representation of all permutations that leave everything alone past the nth element, and then uses that to produce all the (representations of) permutations that move the n+1th element.
12:50:13 <Cale> Ankhers: So it's sort of like "do this then that", only you're allowed to use the result of "this" to determine which "that" to perform.
12:50:51 <Lutin`> jg_: const ()
12:50:54 <Cale> Ankhers: and using do-notation, these things are equal:  x >>= f  =  do v <- x; w <- f v; return w
12:51:12 <Cale> Or more simply:  x >>= f  =  do v <- x; f v
12:51:26 <Lutin`> :t const ()
12:51:27 <lambdabot> b -> ()
12:51:27 <Cale> Ankhers: Does that help any?
12:51:28 <dfeuer> kazagistar, it only makes sense to let the code be if someone can come up with an equally efficient version that can be understood.
12:51:35 <benzrf> jg_: id () is just ()
12:51:46 <Ankhers> Cale: I believe so. I have a follow up question.
12:51:52 <benzrf> jg_: also, there's the (<$) operator
12:52:01 <benzrf> v <$ f = fmap (const v) f
12:52:21 <benzrf> jg_: so `() <$ abParser'
12:52:41 <jg_> Lutin`, benzrf: thanks!
12:53:05 <Ankhers> Cale: I have a type that looks like `IO ([Param], [File])`, `data Param = (ByteString, ByteString)`. I am currently using `fst <$> head <$> fst <$> a`, where `a` is my IO action, in order to retrieve the first element in the Param list. Someone earlier mentioned using >>= to 'lift' my function into IO. Should I be doing that instead?
12:53:33 <Cale> Ankhers: If it's starting to get confusing, just drop the infix operators and use do-notation.
12:53:55 <Cale> do (params, files) <- a; ... other stuff ...
12:54:52 <RedNifre> Hi, just a quick question: Which OS is best suited for haskell development?
12:55:09 <Lutin`> Anything but Windows lol
12:55:09 <Cale> RedNifre: Probably Linux
12:55:17 <dfeuer> Cale, one aspect of the Twan van Laarhoven that seems especially odd is the duplication of the "is" on the first line of the second case of perms. I don't know what "is" is even supposed to mean, but that duplication just seems *weird*.
12:55:34 <RedNifre> How well does it work on BSD?
12:55:40 <kazagistar> OSX had some pretty ugly errors a while back with LLVM/gcc issues
12:55:51 <benzrf> RedNifre: im sure itd be fine
12:56:15 <RedNifre> Okay, thanks. Gotta run, bye!
12:56:18 <dfeuer> Anything but Windows is probably right. Haskell Platform seems to be struggling to figure out how to lay itself out on OSX, but that doesn't seem likely to be a huge problem for users.
12:56:25 <Cale> Yeah, Apple broke gcc in Mavericks which created lots of issues, which now have known solutions, but it's still awkward.
12:57:20 <Ankhers> Cale: If I use do notation, would I be able to do something like `head params`, or will I still need to do something like `head <$> params`?
12:57:35 <Cale> params :: [Param]
12:57:38 <MP2E> Windows seems to work fine, as long as you are used to a more Unix workflow :P
12:57:39 <Cale> and files :: [File]
12:57:46 <Cale> Ankhers: in the code that I wrote
12:58:02 <MP2E> Though to be fair, I didn't really like the toolchain bundled with GHC by default on Windows so I ended up recompiling GHC to use my MinGW-w64 toolchain and things went smoother from then on out
12:58:06 <MP2E> heh
12:58:20 <Cale> Ankhers: So you *could* use head, if you really wanted to. I would usually recommend using a case expression to pattern match and handle the empty case also
12:58:46 <Ankhers> Cale: I'm getting expected type [IO b0], actual type [Param]
12:58:47 <dwcook> Ankhers, it's worth noting that f <$> x is equivalent to do { x' <- x ; return (f x') }
12:58:48 <Cale> Ankhers: If you really don't care about what happens when params is empty, then you could just pattern match the first element out in-place
12:58:52 <Lutin`> MP2E: I just don't have the patience to setup a unix workflow on top of Windows :P And I neeeeeed my tiling window managers
12:59:01 <Cale> Ankhers: Well, what are you writing?
12:59:03 <bgamari2> ghc 7.8 is the first to get the new event manager, yes?
12:59:12 <Ankhers> Cale: One sec. I will make a paste.
12:59:52 <kazagistar> dfeuer: hmm, that code does have the benefit of generating valid data if you take from the front, which the trivial implementation does not... its not an efficiency concern, but a feature concern (if you need guarentees about what order the permutations will arrive in)
12:59:53 <Cale> bgamari2: I think so
13:00:11 <Ankhers> Cale: http://lpaste.net/106810 That is the part that is complaining. It is a wai / warp application.
13:00:18 <Lutin`> bgamari2: If you mean the IO manager, yes
13:00:18 <bgamari2> I think it might have broken the usb package, or at least my usage of it
13:00:24 <bgamari2> Lutin`, thanks
13:00:32 <Cale> Ankhers: You're executing head params as an IO action
13:00:41 <Cale> Ankhers: So, head params had better actually be an IO action
13:00:48 <Cale> (but it's not, it has type Params)
13:01:03 <dfeuer> Cale, once you've calculated permutations up to k, you weave the k+1th element into each of them. The tricky thing is that to attach a permutation of the first k elements to the rest of the list, you probably want that permutation to have a representation akin to Hughes lists, but you can't weave anything into a Hughes list.
13:01:09 <joelteon> hey, can I convince aeson to convert UTF8 characters in my strings into the proper escape sequence?
13:01:24 <bgamari2> is Bas van Dijk around?
13:02:01 <Cale> Ankhers: Also, what's the type of bid?
13:02:21 <dfeuer> kazagistar, yes, that requirement makes it more complicated. It's still possible to implement it naively, but that apparently turns out slow. This implementation is supposed to get the right laziness properties without being too slow.
13:02:23 <Lutin`> Ugh why are .io domains $60
13:02:32 <Cale> Ankhers: It seems to be taking an IO action as an argument, which can be useful sometimes, but might also just be the result of confusion here :)
13:02:57 <Ankhers> Cale: bid :: t -> Network.Wai.Internal.Response
13:03:11 <Ankhers> Cale: I'm attempting to break it down to a ByteString
13:03:31 <Ankhers> But I obviously don't understand enough yet.
13:03:32 <Lutin`> Ankhers: Things inside a do block happen 'inside' the relavant monad
13:03:34 <Cale> Ankhers: Wait, if it's totally polymorphic in its argument, then it cannot use that argument for anything.
13:03:38 <Lutin`> In this case it's the IO monad
13:03:47 <Cale> Ankhers: Are you sure that's the right type?
13:03:48 <Lutin`> So you'd want to do: return (head params)
13:03:59 <kazagistar> dfeuer: im reading through the mailing list now, which is interesting
13:04:21 <jg_> i'm writing an Applicative instance for a Parser type. It looks clunky - http://lpaste.net/106811 . Can i please get a CR?
13:04:25 <Ankhers> Cale: I did `:t bidRequest`. I haven' explicitly set one. I can if it would make this easier.
13:04:31 <Cale> Ankhers: Can you paste more of your program?
13:04:39 <Ankhers> Cale: Sure, just one moment.
13:05:21 <Cale> jg_: Why not use the Maybe monad?
13:06:14 <Cale> (or applicative)
13:06:20 <Cale> Parser (\s -> do (f,rest1) <- runParser p1 s; (value, rest2) <- runParser p2 rest1; return (f value, rest2))
13:06:59 <dwcook> jg_, if your parser has a Monad instance you can define (<*>) = ap
13:07:32 <kazagistar> the "permutation lazyness law" is { map (take n) (take (factorial n) $ permutations [1..]) == permutations [1..n] }
13:07:41 <Ankhers> Cale: http://lpaste.net/106814 I think that is everything necessary.
13:08:05 <Cale> Ankhers: Okay, so bid actually wants a ByteString
13:08:22 <Ankhers> Cale: Yes. I just added that for clarity. I should have had it previously.
13:08:25 <Cale> Ankhers: So, bid rb cannot possibly be correct
13:08:32 <Ankhers> ever?
13:08:34 <Cale> because rb is an IO action
13:09:05 <Ankhers> Makes sense.
13:09:19 <benzrf> Ankhers: think about it this way
13:09:20 <dwcook> Is the syntax on lines 12 and 13 even correct?
13:09:25 <dwcook> Looks odd to me
13:09:27 <dfeuer> kazagistar, that's actually a sloppy version of it. The   [1..] should actually be [1..n]++undefined
13:09:31 <benzrf> Ankhers: are you familiarized with the unix shell
13:09:31 <jg_> Cale, dwcook: so i'd need to write a monad instance to simplify it?
13:09:38 <Ankhers> benzrf: Yes.
13:09:38 <Cale> dwcook: It's syntactically correct, but it doesn't typecheck.
13:09:48 <Cale> oh, no, he's missing a do
13:09:48 <benzrf> Ankhers: let's say you do
13:09:56 <benzrf> $ wc -l dmesg
13:09:59 <dwcook> jg_, you wouldn't *need* to, but if you have a Monad instance then you might as well use it
13:10:06 <Cale> jg_: No, you can just use the monad instance for Maybe
13:10:08 <benzrf> that will not work, because dmesg is a command, not an actual value
13:10:17 <Ankhers> I would need to pipe it.
13:10:19 <Cale> jg_: (as I showed)
13:10:20 <benzrf> precisely
13:10:25 <benzrf> Ankhers: similarly, bid rb won't work, because rb is an action that can be taken, not an actual value
13:10:41 <benzrf> you can use various operators to pipe the result of rb to bid
13:10:44 <benzrf> and get a new action
13:11:21 <Cale> cale@ender:/bin$ wc -l dmesg
13:11:21 <Cale> 73 dmesg
13:11:23 <Cale> ;)
13:11:27 <benzrf> Cale: cute
13:11:36 <Ankhers> lol
13:11:40 <benzrf> Ankhers: for example, if bid results in a new action, you can do `rb >>= bid'
13:11:41 <Cale> (Unfortunately, unix is very much untyped)
13:11:50 <merijn> Cale: *unityped :p
13:11:57 <benzrf> Ankhers: which will be a new action that runs rb, passes the result to bid, then runs the result
13:12:02 <Cale> Or   do v <- rb; bid v
13:12:15 <benzrf> Ankhers: or if bid is a pure function, you can do `bid <$> rb'
13:12:34 <Cale> However, that's also not quite right, given that bid results in a Response, and not an IO action
13:12:36 <kazagistar> dfeuer: right, that makes sense
13:13:01 <benzrf> Ankhers: `bid <$> rb' or `fmap bid rb' will make a new action that runs rb, then applies bid to the result
13:13:08 <Cale> So, you probably mean to have something like  do p <- rb; return (bid p)
13:13:30 <Cale> (or indeed, you can use fmap or (<$>) which is the same thing)
13:13:49 <jg_> Cale: i get "Couldn't match expected type `String -> Maybe (Maybe (b, String))'" for your solution
13:14:08 <Cale> jg_: hm
13:14:17 <jtakacs> Hi!
13:14:21 <jg_> not sure what's wrong there
13:14:42 <jtakacs> How can I convert a Word32 to ByteString in big endian byte order?
13:15:00 <Cale> jg_: Were you getting a type error before?
13:15:19 <jg_> Cale: sorry, my bad. Forgot the constructor
13:15:39 <jg_> Cale: thanks for the help
13:15:46 <Cale> jg_: No problem :)
13:16:18 <corgifex> jtakacs: one of the putWord32be's
13:16:49 <dmj`> jtakacs: http://hackage.haskell.org/package/bytestring-0.10.4.0/docs/Data-ByteString-Builder-Prim.html#v:word32BE
13:17:13 <corgifex> there's one in http://hackage.haskell.org/package/binary-0.7.2.1/docs/Data-Binary-Put.html#v:putWord32be for example
13:17:45 <jtakacs> could you please write me a specific example? I've been looking at the documentation all day, but still can't figure out. (I'm at a very beginner level.)
13:18:25 <jtakacs> putWord32be :: Word32 -> Put   this gives me a Put , not a ByteString, so I'm a bit confused hwo to use it
13:18:47 <corgifex> http://hackage.haskell.org/package/binary-0.7.2.1/docs/Data-Binary-Put.html#v:runPut
13:19:06 <dmj`> runPut :: Put -> ByteString
13:22:04 <dwcook> Huh, why isn't that just a Monoid?
13:22:24 <kazagistar> yeah, I was about to say, Put seems like a total abuse of Monads
13:22:38 <Lutin`> Ankhers: What is `ready`?
13:22:40 <jtakacs> ok, I tried it in ghci.  let x=2153709570 :: Word32           runPut $ putWord32be x
13:22:45 <jtakacs> and it gives me "\128_\NUL\STX"
13:23:04 <jtakacs> am I missing something?
13:23:09 <corgifex> what's the problem?
13:23:40 <jtakacs> how should I interpret the result?  x was not 128...
13:23:50 <corgifex> what
13:24:06 <rwbarton> as a 32-bit big endian number, like you asked
13:24:08 <Ankhers> Lutin`: The API pings this service to know whether or not it should be sending requests to me. It is only meant to return the number 1.
13:24:31 <Lutin`> You might could do this
13:24:33 <Lutin`> http://lpaste.net/106814
13:24:36 <joelteon> > foldr1 [a,b,c,d]
13:24:38 <lambdabot>  Couldn't match expected type ‘a -> a -> a’
13:24:38 <lambdabot>              with actual type ‘[Debug.SimpleReflect.Expr.Expr]’
13:24:40 <joelteon> > foldr1 f [a,b,c,d]
13:24:41 <lambdabot>  f a (f b (f c d))
13:25:00 <corgifex> > (((ord '\128' * 256) + ord '_') * 256 + ord '\NUL') * 256 + ord '\STX'
13:25:01 <lambdabot>  2153709570
13:25:38 <Lutin`> Ankhers: Fixed some errors http://lpaste.net/106814
13:25:55 <corgifex> > foldl (\z x -> z * 256 + ord x) 0 "\128_\NUL\STX"
13:25:56 <lambdabot>  2153709570
13:26:54 <jtakacs> :t "\STX"
13:26:55 <lambdabot> [Char]
13:27:06 <corgifex> toLazyByteString (primFixed word32BE x)? well, that's not convoluted at all
13:27:19 <jtakacs> :r "\NUL"
13:27:22 <jtakacs> :t "\NUL"
13:27:23 <lambdabot> [Char]
13:27:27 <corgifex> > ord '\STX'
13:27:28 <lambdabot>  2
13:27:48 <corgifex> > map ord "\128_\NUL\STX"
13:27:49 <lambdabot>  [128,95,0,2]
13:28:09 <jtakacs> ok, so when ghci prints out my serialized value, it interprets it as a character sequence.
13:28:21 <jtakacs> am i right?
13:29:29 <corgifex> > BS.pack [128, 95, 0, 2]
13:29:31 <lambdabot>  "\128_\NUL\STX"
13:29:45 <corgifex> well, technically that's ByteString's Show instance
13:29:57 <corgifex> not something ghci just made up
13:29:58 <jtakacs> I'm facepalming so hard right now.
13:30:05 <Ankhers> Lutin`: I don't fully understand it, but thank you!
13:30:13 <jtakacs> ok, so how do I display it in hexadecimal?
13:30:17 <Ankhers> Cale, benzrf: Thanks to you both as well.
13:30:36 <corgifex> I'd use printf
13:30:44 <ReinH> :t showHex
13:30:45 <lambdabot> (Show a, Integral a) => a -> ShowS
13:30:54 <ReinH> > showHex 10 ""
13:30:56 <lambdabot>  "a"
13:30:58 <Lutin`> Ankhers: The idea is f :: Response -> IO ResponseRecieved
13:31:11 <Lutin`> So this works in the case of ready :: Response
13:31:32 <corgifex> jtakacs: printf "%v02x" (...) :: String
13:31:35 <corgifex> assuming printf-mauke
13:32:08 <Ankhers> Lutin`: Thanks. I clearly have a lot more reading to do.
13:32:36 <corgifex> :t BS.unpack
13:32:37 <lambdabot> BSC.ByteString -> [Word8]
13:32:54 <Lutin`> But since rb :: IO ByteString you need to use >>= to pass the ByteString to bid
13:33:03 <benzrf> i hear you should use text and not bytestring ususally
13:33:10 <Lutin`> and then apply f to the results
13:33:26 <Ankhers> Lutin`: That makes a lot of sense.
13:33:31 <asfp`> is the function  x f g = do { a <- f; b <- g; return (a,b); } a known combinator?
13:33:43 <ReinH> benzrf: bytestring is good for strings of bytes.
13:33:47 <merijn> asfp`: liftM?
13:33:54 <corgifex> :t foldr showHex "" . BS.unpack
13:33:55 <lambdabot> BSC.ByteString -> String
13:33:56 <merijn> well, liftM2, I guess
13:34:02 <merijn> :t liftM2 (,)
13:34:03 <lambdabot> Monad m => m a1 -> m a2 -> m (a1, a2)
13:34:18 <_deepfire-laptop> How does haskell represent String's in memory?
13:34:26 <Lutin`> Ankhers: in this case (>>=) :: IO ByteString -> (ByteString -> IO ResponseReady) -> IO ResponseReady
13:34:28 <Nik05> with list wooo woo
13:34:29 <corgifex> _deepfire-laptop: type String = [Char]
13:34:34 <merijn> asfp`: Or, applicative style: "(,) <$> f <*> g"
13:34:38 <Lutin`> i mean ResponseRecieved
13:34:43 <merijn> _deepfire-laptop: Linked list of Char
13:34:47 <corgifex> data [] a = [] | a : [a]
13:34:59 <_deepfire-laptop> merijn, interesting..
13:35:05 <asfp`> merijn: thanks
13:35:11 <ReinH> you can do things like: instance Show InfoHash where showsPrec _ (InfoHash ih) = showString "0x" . showHex (BS.unpack ih)
13:35:13 <Ankhers> Lutin`: Thanks.
13:35:14 <Lutin`> So since bid :: ByteString -> Response and f :: Response -> IO ResponseRecieved then f.bid :: (ByteString -> IO ResponseReady)
13:35:19 <Lutin`> Received*
13:35:32 <jtakacs> Could not find module `Text.Printf.Mauke'
13:35:44 <_deepfire-laptop> merijn, but ByteStrings are actually arrays in memory?
13:35:46 <jtakacs> and I can't install it with cabal either
13:36:03 <corgifex> jtakacs: what happens when you try?
13:36:05 <pjdelport> _deepfire-laptop: Right.
13:36:07 <merijn> _deepfire-laptop: ByteString is a linked list of binary blobs (essentially arrays, yes)
13:36:28 <jtakacs> cabal: There is no package named 'printf-mauke'.
13:36:31 <merijn> _deepfire-laptop: There is also Text which is a linked list of unicode blobs
13:36:32 <kazagistar> ReinH: what do you mean "String of bytes"? That statement implies that String has a kind of * -> *, but as far as I know strings are kind *, since they are a list of characters...
13:36:35 <_deepfire-laptop> merijn, ah, so not entirely contiguous, and so not FFI-worthy?
13:36:48 <merijn> _deepfire-laptop: It depends on the type of ByteString, actually
13:36:52 <ReinH> kazagistar: I didn't say "String of bytes". I said "string of bytes".
13:36:56 <corgifex> jtakacs: that's weird because hackage thinks there is
13:37:04 <corgifex> did you run 'cabal update'?
13:37:15 <ReinH> or, in fact, "strings of bytes"
13:37:16 <Lutin`> _deepfire-laptop: string bytestrings are a single array
13:37:19 <Lutin`> strict*
13:37:27 <merijn> _deepfire-laptop: There's lazy and strict, I dunno all the details
13:37:32 <kazagistar> ReinH: which is why I asked you to clarify, since I have no idea what you mean by that statement
13:37:46 <ReinH> kazagistar: The same thing that "string" means in the term "bytestring".
13:37:53 <jtakacs> my bad, forgot to sudo
13:38:16 <_deepfire-laptop> Lutin`, is there a way to impose the strictness requirement through the type declaration?
13:38:46 <pjdelport> AFAIUI, strict ByteStrings are a single contiguous chunk, while lazy bytestrings are essentially lazy lists of strict ByteStricts under the hood.
13:38:47 <kazagistar> ReinH: that is hopelessly recursive... do you mean sequence?
13:38:53 <merijn> _deepfire-laptop: String can (on some architecures, ymmv, etc.) take 20+ bytes per character (pointers, boxing, etc.), Text on the other hand will probably be more like 1-2 byte per character (plus some "per blob" overhead of a handful of bytes, but blobs are measured in sizes of KB, so that's negligible)
13:39:03 <corgifex> _deepfire-laptop: that's the only way
13:39:05 <merijn> _deepfire-laptop: The strict and lazy versions are exported by different modules
13:39:21 <Lutin`> _deepfire-laptop: Just don't use ByteString.Lazy
13:39:27 <_deepfire-laptop> Thank you folks!
13:39:28 <Lutin`> _deepfire-laptop: use ByteString
13:39:29 <ReinH> kazagistar: sure
13:39:52 <Lutin`> _deepfire-laptop: The ByteString docs explain all of it very well
13:40:00 <Lutin`> https://hackage.haskell.org/package/bytestring-0.10.4.0/docs/Data-ByteString.html
13:40:08 <_deepfire-laptop> Lutin`, thank you!
13:40:17 <merijn> _deepfire-laptop: The golden heuristic is: ByteString for binary data, Text for textual data, String for easy pattern matching/stuff you don't care about performance
13:40:29 <Lutin`> Or if you want to know the difference between the two just click the contents link and it will take you back to the package main page
13:40:39 <Lutin`> Where they explain the difference
13:41:55 * hackagebot configurator 0.3.0.0 - Configuration management  http://hackage.haskell.org/package/configurator-0.3.0.0 (BryanOSullivan)
13:41:59 <asfp`> merijn:  if I want to do { guard (h arr); a <- f arr; b <- g arr; return (a,b) } how can I do that in applicative style?
13:42:32 <corgifex> guard (h arr) *> liftA2 (,) (f arr) (g arr)
13:42:53 <asfp`> :t (*>)
13:42:54 <lambdabot> Applicative f => f a -> f b -> f b
13:43:45 <asfp`> :t liftA2
13:43:46 <lambdabot> Applicative f => (a -> b -> c) -> f a -> f b -> f c
13:43:59 <Lutin`> And in fact
13:44:02 <Lutin`> @src *>
13:44:03 <lambdabot> (*>) = liftA2 (const id)
13:44:09 <corgifex> @src liftA2
13:44:10 <lambdabot> liftA2 f a b = f <$> a <*> b
13:45:24 <corgifex> (\_ a b -> (a, b)) <$> guard (h arr) <*> f arr <*> g arr
13:45:54 <phaazon> jle`: ahah
13:46:03 <phaazon> I saw you answered my tweet at flure_popsy, awesome :D
13:46:04 <Lutin`> And `const id` is just another way to write `flip const`
13:46:15 <jtakacs> thanks for the help
13:46:27 <phaazon> he really meant what I tweeted, so I decided to make that public to witness reactions :D
13:46:32 <benzrf> :t const id
13:46:33 <lambdabot> b -> a -> a
13:46:45 <benzrf> :t const
13:46:46 <lambdabot> a -> b -> a
13:46:51 <benzrf> hn
13:47:04 <benzrf> :t uncurry snd
13:47:05 <kazagistar> @pl (\f g h arr = guard (h arr) *> liftA2 (,) (f arr) (g arr))
13:47:05 <lambdabot> (line 1, column 13):
13:47:05 <lambdabot> unexpected "="
13:47:05 <lambdabot> expecting pattern or "->"
13:47:05 <lambdabot> ((a, b -> c), b) -> c
13:47:08 <benzrf> :t curry snd
13:47:09 <lambdabot> a -> c -> c
13:47:14 <corgifex> :t [const id, flip const, pure ask]
13:47:15 <lambdabot> [b -> a -> a]
13:47:19 <kazagistar> @pl (\f g h arr -> guard (h arr) *> liftA2 (,) (f arr) (g arr))
13:47:19 <lambdabot> (flip (liftM2 ((*>) . guard)) .) . liftM2 (liftA2 (,))
13:47:37 <benzrf> ask is polymorphic!!
13:48:30 <Lutin`> Well, that's using the MonadReader and applicative instances of ((->) a)
13:48:39 <mhl> How can I effictienlty iterate through list, starting from the end, and going towards the beginning? Shall I use reverse?
13:48:54 <corgifex> mhl: what do you need that for?
13:48:55 <kazagistar> I just saw lifting and wanted to contribute with the help of PL
13:49:13 <Lutin`> 'help' lol
13:49:33 <Marquis> hello haskellers. Lets say i have a number of lists and i want the first and last two elements of each list and forgett about what is in between. What is an efficient way to do it? (!! $length -1) seems not that nice but the list have different lengths. Although the lists are not that long
13:50:09 <moghedrin> Marquis: There's not really a great way to do that, as fetching the last item in each list requires traversing the entire list.
13:50:11 <asfp`> corgifex: this one made sense: (\_ a b -> (a, b)) <$> guard (h arr) <*> f arr <*> g arr
13:50:47 <rwbarton> @hoogle Alternative f => Bool -> f ()
13:50:49 <lambdabot> Control.Monad guard :: MonadPlus m => Bool -> m ()
13:50:49 <lambdabot> Network.BSD setHostEntry :: Bool -> IO ()
13:50:49 <lambdabot> Network.BSD setNetworkEntry :: Bool -> IO ()
13:50:49 <Lutin`> mhl: Yeah you can use reverse
13:50:55 <khax> haskell is a piece of shite
13:51:03 --- mode: ChanServ set +o corgifex
13:51:07 <khax> fagit
13:51:09 <mhl> corgifex: I am implementing some algorithms from Introduction to algoritms book, namely max subarray problem. there is a procedure that counts maximum crossing subarray.
13:51:09 <khax> fuck u
13:51:12 <kazagistar> Marquis: (take 2 . reverse) is a fine way to get the last elements of the list
13:51:24 --- mode: corgifex set +b *!*@2001:1af8:4700:a032:3::
13:51:36 <merijn> mhl: You may wanna use Array instead of a list?
13:51:38 --- mode: corgifex set +b-b $a:khax *!*@2001:1af8:4700:a032:3::
13:51:53 <kazagistar> Marquis: er wait, what I said is silly
13:51:54 <Marquis> thanks
13:52:06 <Marquis> why?
13:52:07 --- mode: corgifex set -o corgifex
13:52:15 <dmj`> map (\xs -> take 2 xs ++ (reverse . take 2 . reverse $ xs)) [[1,2,3,4,5,6],[7,8,9,10]]
13:52:19 <dmj`> > map (\xs -> take 2 xs ++ (reverse . take 2 . reverse $ xs)) [[1,2,3,4,5,6],[7,8,9,10]]
13:52:20 <lambdabot>  [[1,2,5,6],[7,8,9,10]]
13:52:21 <MP2E> [sarcasm] welp, kax convinced me! later guys lolol. [/sarcasm] But really, wat? That accomplished nothing :V
13:52:37 <jtakacs> My next problem:  Couldn't match expected type `C.ByteString' with actual type `Data.ByteString.Lazy.Internal.ByteString'
13:52:55 <merijn> jtakacs: You're passing something a lazy ByteString while it wants a strict one
13:53:12 <merijn> (or vice versa, I forget the order of the types in that error)
13:53:23 <Lutin`> You were right
13:53:31 <jtakacs> I'm trying to concatenate the results of multiple runPut into a ByteString with Data.ByteString.concat
13:53:42 <corgifex> merijn: order doesn't matter; they're labelled
13:53:43 <Lutin`> Use Data.ByteString.Lazy.concat
13:54:13 <merijn> ^^^
13:54:14 <Lutin`> Or switch to Strict ByteStrings
13:54:55 <ReinH> mhl: maximum subarray is very similar to maximum segment sum
13:55:05 <Lutin`> I also suggest `import qualified Data.ByteString.Lazy as L`
13:55:28 <ReinH> mhl: For algorithms like this, there is usually a functional solution using arrays that is very similar to the imperative solution
13:55:35 <ReinH> For lists you have to be a bit more clever
13:55:48 <jtakacs> Lazy concat works for now, but what is the difference between Network.Socket.ByteString and Data.ByteString?
13:56:00 <leonvv> In this infinite list: "fibs = 0 : 1 : zipWith (+) fibs (tail fibs)", how can the "tail fibs" part ever end?
13:56:18 <corgifex> leonvv: it can't
13:56:23 <ReinH> mhl: you can specify the problem as: mss = max . map sum . segments where segments = concatMap inits . tails
13:56:31 <merijn> jtakacs: The problem is there is Data.ByteString and Data.ByteString.Lazy
13:57:16 <ReinH> This pretty obviously has poor asymptotics but you can derive from it a more efficient version in the Bird style.
13:57:23 <Lutin`> jtakacs: Network.Socket.ByteString uses strict ByteStrings
13:57:26 <merijn> jtakacs: Network.Socket.ByteString uses strict bytestrings (Data.ByteString), your serialisation library (I guess you're using binary?) is producing lazy bytestrings (Data.ByteString.Lazy) hence the complaint
13:57:31 <ReinH> iirc doing so actually an exercise in Bird's _The Algebra of Programming_
13:57:36 <leonvv> corgifex, so why, if I do "fibs !! 50" my program doesn't crash?
13:57:45 <Lutin`> ReinH: Time to get that too!
13:57:50 <corgifex> leonvv: why would it?
13:57:54 <ReinH> Lutin`: it's very good :)
13:58:06 <Lutin`> I saw 'not maximum segment sum' in Pearls
13:58:16 <jtakacs> yes, runPut gives me a lazy ByteString, so I need to use lazy concat. but in the next step, I try to send out that bytestring over a tcp socket, how can I convert between the two versions of ByteString?
13:58:16 <merijn> jtakacs: cereal (another serialisation library, pretty much identical API to binary) produces strict bytestrings instead
13:58:22 <mhl> ReinH: Thank you for your respone. I will check Arrays.
13:58:37 <leonvv> corgifex, because it tries to read the 50th element, which would result in calling "tail fibs"?
13:58:43 <merijn> jtakacs: There are some plans to merge cereal and binary into a single library for both lazy and strict serialisation AFAIK, but this hasn't happened yet
13:58:53 <corgifex> leonvv: so?
13:59:09 <merijn> jtakacs: There are ways to convert, but it's kinda painful, it's probably better to switch to cereal over binary instead
13:59:13 <MP2E> leonvv : but tail fibs isn't what is needed here, it's merely the 50th head. So it just executes up to that point and takes the answer, throwing away tail fibs at that point
13:59:39 <ReinH> mhl: the functional solution involves folding and tabulation, as many of his do.
14:00:15 <corgifex> jtakacs: S.concat . L.toChunks converts from lazy to strict IIRC
14:00:18 <ReinH> mhl: ah, here's a nice writeup! http://www.iis.sinica.edu.tw/~scm/2010/maximum-segment-sum-origin-and-derivation/
14:00:27 <merijn> mhl: FYI, the FP equivalent of "Intro to Algorithms" would be Okasaki
14:00:52 <merijn> mhl: He describes efficient algorithms/datastructures for pure functional languages
14:01:01 <merijn> @where okasaki
14:01:01 <lambdabot> http://www.cs.cmu.edu/~rwh/theses/okasaki.pdf
14:01:02 <mhl> ReinH: What is tabulation?
14:01:07 <leonvv> MP2E, I get it! Thanks
14:01:27 <leonvv> corgifex, and now I also get your answers ;)
14:01:31 <MP2E> :>
14:02:18 <corgifex> understanding the problem is the first step towards understanding my answers regarding the problem
14:02:20 <asfp`> Can I put in the guard anywhere, like  (,) <$> f arr <*> guard (h arr) *> g arr ?
14:02:22 <mhl> merijn: Great, thanks. I wll look into that!
14:02:39 <merijn> mhl: I think there is a "proper" book of his thesis too
14:03:09 <ReinH> mhl: also definitely have a look at Bird's _Pearls of Functional Algorithm Design_, where he solves quite a few very similar algorithms.
14:04:09 <ReinH> mhl: also check out http://www.cs.ox.ac.uk/files/3378/PRG56.pdf
14:04:18 <ReinH> mhl: and http://www.cs.ox.ac.uk/richard.bird/online/BirdDeMoor93From.pdf
14:04:24 <merijn> mhl: There's some neat results, like a proof that the pure functional implementation of any algorithm is *at worst* a factor log n slower than the imperative
14:06:17 <ReinH> Bird's Pearls actually has a chapter about the maximum *non*-segment sum, apparently because mss was already old hat ;)
14:06:54 <mhl> Are there any cases of algorithms that perform better than imperative equivalents?
14:06:59 <ReinH> merijn: also list homomorphisms give rise to divide and conquer algorithms :D
14:07:47 <merijn> mhl: I'm not sure, I guess not since you could just implement the same in an imperative language, it may just be harder to get right
14:08:16 <merijn> mhl: Although lazy implementations of some algorithms may be asymptotically faster than their strict equivalents
14:09:03 <ReinH> merijn: if for no other reason than you can replace an array with a tree structure :)
14:09:55 <pjdelport> Is there really a divide between "pure functional" and imperative, in the limit?
14:10:23 <ReinH> pjdelport: no, the terms are really just suggestive
14:10:31 <ReinH> pjdelport: in the limit you have turing completeness :p
14:10:50 <pjdelport> ReinH: Turing completeness doesn't say anything about performance, though.
14:10:58 <ReinH> pjdelport: that's true
14:12:10 <pjdelport> I specifically mean a divide in terms of performance, because it seems that a sufficiently smart compiler can compile any given purely functional algorithm to use mutation internally at run-time, and vice versa any imperative algorithm can use explicit laziness to obtain whatever benefit a pure lazy language can have.
14:12:11 <ReinH> pjdelport: in the limit, you can implement all of Haskell in your imperative language :p
14:12:52 <Lutin`> in the limit, you can implement all of your imperative language in Haskell :)
14:13:04 <pjdelport> So any statement about their relative performance must be qualified by what implementation techniques are allowed and disallowed.
14:13:18 <MP2E> pjdelport : I would argue that you need a less intelligent compiler to compiler pure functional code into mutable imperative code than vice-versa
14:13:24 <MP2E> compile*
14:13:27 <ReinH> pjdelport: what is really meant I think is "imperative-style" and "functional-style"
14:13:34 <monochrom> in the limit, there is only naïve code generation vs smart code generation
14:13:40 <pjdelport> Right.
14:13:42 <ReinH> i.e. imperative-style assumes access to arrays
14:13:47 <ReinH> functional-style does not
14:13:47 <Pythonfant> can you have O(1) lookup (like in a hashmap) in a purely functional code?
14:14:17 <merijn> Pythonfant: You can't even have O(1) in a hashmap
14:14:23 <dmj`> pjdelport: you can use the ST monad to create imperative algorithms in haskell. There's an example of fib running in constant space.
14:14:34 <Pythonfant> merijn: well you have expected O(1) access, right?
14:14:39 <pjdelport> Hashing is O(1), for sufficiently wobbly values of "1" :)
14:14:50 <ReinH> haha
14:14:51 <merijn> Pythonfant: Only if you assume the hash function is constant time, it usually isn't
14:14:58 <Pythonfant> merijn: hm right
14:15:03 <Algebr> Was SmallTalk a big mistake?
14:15:06 <merijn> Pythonfant: string hashes tend to be linear in string length for example
14:15:07 <Lutin`> Even then depends on the hasmap implementation
14:15:13 <Lutin`> hashmap*
14:15:22 <Lutin`> Like your probing function
14:15:30 <Lutin`> Or if you use linked lists for your buckets
14:15:36 <merijn> And most hashmaps have O(n) worst case behaviour
14:15:37 <monochrom> instead of muddling the issue with hash tables which is a combination of many issues, you should ask about mutable array which is the real issue you mean.
14:17:25 <Pythonfant> so are there no functional data structures that allow random o(1) access to something like arrays?
14:17:31 <jle`> phaazon: :P
14:17:57 <merijn> Pythonfant: Sure there are, they just don't allow mutation
14:18:08 <dwcook> Pythonfant, functions :)
14:18:20 <monochrom> not done in haskell, but probably done in clean: using linear type or uniqueness type, you can use mutable arrays and write functional-style-ly
14:18:23 <dwcook> Integer -> Foo
14:18:40 <monochrom> look for Wadler's "linear types can change the world!" for example
14:20:30 <pjdelport> Haskell does have mutable arrays, but it may be a matter of opininion whether that counts as "purely functional" or not.
14:21:09 <monochrom> when using Haskell's mutable arrays, you have to write in the ST monad imperative-style-ly.
14:21:59 <jnott> hi, is this the jaskell channel
14:22:09 <monochrom> the saving grace is that it is just a small pocket of imperative style code you can embed in a large functional style context by runST
14:22:49 <Cale> jnott: This is the Haskell channel :)
14:23:02 <monochrom> this is not the jaskell channel. what is jaskell?
14:23:10 <pjdelport> monochrom: Right, but it's "purely functional imperative style", arguably. :)
14:23:52 <sipa> monochrom: sounds like a haskell implementation of java, or a java implementation of haskell :p
14:24:01 <sipa> or a typo
14:24:13 <dwcook> jaskell does appear to be a thing but only marginally related to Haskell from what I can tell
14:24:16 <Algebr> I wonder if Alan Kay would either write Haskell
14:24:20 <Algebr> ever*
14:24:38 <monochrom> can you ask him?
14:24:48 <Algebr> I don't think he's on twitter
14:25:07 <monochrom> but he definitely has email
14:25:10 <dwcook> jnott, you're unlikely to get good help for Jaskell here. If you meant Haskell, you're in exactly the right place though.
14:25:41 <monochrom> my guess: he prefers dynamic typing. he won't like haskell.
14:26:37 <MP2E> :V dynamic typing, more like dynamic pipe-dream *bad pun*
14:26:49 <dwcook> Pun? Where?
14:26:58 <monochrom> benzrf has a pipe dream. this is a real pun. :)
14:26:58 <Algebr> +1
14:27:14 <jtakacs> I hate typing, that's why i like the idea of type inference.
14:27:22 <dwcook> monochrom, is benzrf doing something with the pipes package that is unlikely to be realized?
14:27:47 <monochrom> yes. he wants me to learn, use, and promote pipes. unlikely to be realized. :)
14:27:52 <dwcook> Heh.
14:28:27 <Algebr> Anyone here doing iOS + Haskell?
14:28:39 <merijn> monochrom: Pffft, dynamic typing is "just a degenerate case of static typing"
14:28:58 <dwcook> That's why I sometimes refer to dynamic typing as unityping
14:29:09 <merijn> Guess who followed a Harper lecture :p
14:29:13 <pjdelport> Dynamic typing is just static typing with one type (for real, not jest)
14:29:18 <mgsloan> But Alan Kay certainly likes concision and dsls (the STEPS project was all about that), so there's hope :D
14:29:26 <monochrom> telepathic programmers hate typing :)
14:29:29 <Algebr> what is concision?
14:29:54 <merijn> Algebr: The property of being concise, I guess? Although I'd call that conciseness
14:30:01 <mgsloan> concision == using no more words than necessary
14:30:02 <mgsloan> yeah
14:30:13 <Algebr> oh haha, thought it was some coding thing.
14:30:22 <monochrom> racket people like dsls too. precisely why they created racket, not joined haskell.
14:30:49 <Algebr> Then did smalltalk not really add anything interesting?
14:31:00 <q66> <pjdelport> Dynamic typing is just static typing with one type (for real, not jest)
14:31:04 <q66> people usually get upset when i mention that
14:31:09 <benzrf> monochrom: pipes is totally cool tho
14:31:11 <dwcook> I like DSL. I rather disliked having to get off the internet when my parents wanted to use the phone
14:31:11 <mgsloan> True, in some ways static typing makes dsls more difficult.  Howerver, the advantages of doing edsls in a statically typed language is that you get all that good stuff for free
14:31:34 <monochrom> haha dwcook
14:31:36 <mgsloan> albeit, sometimes it'd be nice to be able to provide more domain specific error messages
14:32:01 * monochrom is guilty of starting the trend of silly puns!
14:32:25 <merijn> monochrom: There is no such thing as a silly pun!
14:33:44 <Algebr> Does 7.10 finally play nice with clang?
14:34:18 <monochrom> to a large extent I think the racket people chose scheme as their foundation because they drank the "everything is an s-expression" koolaid. it's understandable actually.
14:37:10 <dwcook> I accidentally my power
14:37:27 <MP2E> dwcook crossed the streams D:
14:37:30 <dwcook> monochrom, all I need is an excuse to make puns :P
14:37:30 <FireFly> all of your power?
14:37:33 <dwcook> Sometimes not even that
14:37:38 <monochrom> absolute power absolutely disrupts :)
14:38:16 <FireFly> clever
14:38:16 <benzrf> monochrom: kool aid is delicious though
14:38:25 <tnks> a while ago I found on Google a good discussion of some nuances between "import Prelude ()" hiding and NoImplicitPrelude.
14:38:32 <tnks> but I'm not finding it now.
14:38:39 <tnks> can someone help me out?
14:38:48 <hpc> tnks: the big one is that in the former you still get class instances
14:38:52 <dwcook> tnks, for one, you still get the instances in the former
14:38:54 <FireFly> I have no clue how kool-aid tastes...
14:38:59 <FireFly> I kinda want to know
14:39:12 <hpc> FireFly: it tastes like peer pressure :P
14:39:50 <monochrom> which one do you prefer, IOException or IOError?
14:39:50 <dwcook> tnks, also various things that refer to bindings in the Prelude in the report work with whatever is in scope with the appropriate identifier, in the latter case
14:39:56 <merijn> tnks: The former imports instances, I would guess
14:43:15 <tnks> catching up.
14:43:43 <dwcook> One of the things you got told three times by three people :)
14:43:56 <tnks> dwcook: yeah!
14:44:14 <tnks> now I need to look at those instances and and see if I care.
14:44:29 <tnks> I think it's really the partial functions that drive me bonkers.
14:44:42 <tnks> and then the non-polymorphic functions too.
14:44:56 <pjdelport> @quote stereo
14:44:57 <lambdabot> geheimdienst says: data Stereoloid = BanachTyvski | CoBanachTyvski
14:45:00 <pjdelport> @quote stereo
14:45:00 <lambdabot> monochrom says: Welcome to #haskell, where @remember's are in majestic stereo!
14:45:12 <monochrom> you want this:
14:45:14 <pjdelport> xP
14:45:15 <monochrom> @quote fugue
14:45:15 <lambdabot> monochrom says: Welcome to #haskell, where your questions are answered in contrapuntal fugues.
14:46:12 <monochrom> those were good days before reddit and stackoverflow. now all the fugues go there.
14:47:09 <jle`> real shame
14:49:05 <jtakacs> how can I create a typeclass that acts like a 4 bit integer?
14:49:22 <pjdelport> jtakacs: A type class or a type?
14:49:44 <jtakacs> a type I guess
14:49:52 <monochrom> a type class is useless without a type.
14:49:56 <dwcook> data FourBits = FourBits Bool Bool Bool Bool -- :)
14:49:58 <dmj`> data FourBit = FourBit Bool Bool Bool Bool
14:50:02 <dmj`> beat me to it
14:51:04 <pjdelport> jtakacs: There is http://hackage.haskell.org/package/base-4.7.0.0/docs/Data-Bits.html
14:51:17 <dwcook> monochrom, I wonder if someone has ever used a nullary typeclass
14:51:29 <jtakacs> this would be a counter in my binary packet structure, so i don't think Bools would work
14:52:00 * hackagebot spe 0.6 - Combinatorial species lite  http://hackage.haskell.org/package/spe-0.6 (AndersClaesson)
14:52:18 <phi__> I guess another way can be to have a newtype wrapper for Int and define all operations modulo 16
14:52:32 <pjdelport> jtakacs: Do you actually need it to work modulo 2^4, or would Word8 / Int8 work?
14:52:40 <pxqr> suppose we've got "thread blocked indefinitely on a mvar operation"; is there a simple way to find out which exactly operation caused blocking?
14:52:41 <dwcook> class False where {} ; class True where {} ; instance True where {}
14:52:43 <MP2E> jtakacs : A counter? Perhaps you could try (`mod` 16) on the input to ensure it stays within 4 bits? This assuming you want to allow the value to overflow
14:52:47 <monochrom> use Word8 and use only 4 bits. for interface boundary, newtype it, write utility functions, and control exports
14:53:08 <MP2E> err wait not 16 but yeah 2^4
14:53:26 <MP2E> oh wait I was right originally
14:53:30 <MP2E> blah
14:53:54 <dwcook> As it happens, 2^4 = 4^2
14:54:05 <monochrom> 2^2 = 2*2
14:54:26 <dwcook> I wonder if there's a simple rule to generate all such pairs
14:54:27 <monochrom> I really have students who mix up a^b with a*b
14:54:42 <MP2E> :V
14:55:04 <pjdelport> > (2^2)^2 == 2^(2^2)
14:55:06 <lambdabot>  True
14:55:11 <rwbarton> dwcook: that's the only one (besides trivial n^n = n^n)
14:55:25 <Algebr> I'm taking a compiler's course starting next week. I thought it was gonna be a 3 month thing, but apparently its just 5 weeks. Its done in OCaml...
14:55:36 <monochrom> going as far as writing a 2^n time algorithm and stating "2*n time, it's polynomial time"
14:55:46 <pjdelport> > (2^2)^(2^2) == (2^(2^2))^2
14:55:48 <lambdabot>  True
14:56:06 <dwcook> rwbarton, how'd you arrive at that conclusion?
14:56:30 <jle`> this just in, (^) is associative
14:56:41 <dwcook> jle`, :P
14:57:01 <dwcook> > (3^3)^3 == 3^(3^3)
14:57:03 <lambdabot>  False
14:57:04 <donri> but not monoidal, is it, no left identity?
14:57:05 <dmj`> pxqr: might help to use modifyMVar_ to make the operation atomic, debugging could be tough
14:57:05 <jle`> (^) is a monoid over the integers don't you know
14:57:09 <dwcook> It's not associative
14:57:09 <jle`> oh yeah
14:57:12 <jle`> a semiring
14:57:15 <jle`> ;_
14:57:17 <jle`> ;)
14:57:17 <rwbarton> you can rewrite a^b = b^a as a^(1/a) = b^(1/b), and then if you look at a graph of x^(1/x) you will see it is increasing up to x=e and then decreasing, IIRC
14:57:19 <jle`> er, a semigroup
14:58:18 <dwcook> rwbarton, neat.
14:58:30 <rwbarton> it equals 1 at 1, and converges to 1 as x -> infinity, so for any x > e, there is exactly one value of y < e s.t. y^(1/y) = x^(1/x)
14:58:36 <tnks> dwcook: I'm looking at the instances defined in Prelude, and I can't think about why to not disallow them.
14:58:55 <tnks> why might someone prefer NoImplicitPrelude to hiding it with an import?
14:59:07 <dwcook> tnks, I imagine the more important part is the other thing I said - Syntactic sugar can use whatever's in scope rather than in the Prelude
14:59:18 <rwbarton> and the other way around too, for any 1 < y < e there is exactly one x > e with the same value
14:59:24 <tnks> dwcook: oh, I missed that.
14:59:26 <dwcook> tnks, for example, people have used this to use do notation with indexed monads
15:00:06 <pjdelport> tnks: If you're doing unusual things, it can be useful to define alternative instances.
15:00:16 <donri> so (^) is a magma? :P
15:00:25 <dwcook> @type (^)
15:00:26 <lambdabot> (Num a, Integral b) => a -> b -> a
15:00:34 <dwcook> donri, for some types, I guess.
15:00:41 <dwcook> Not that that says much :P
15:01:03 <donri> i wonder if there are any "magmoids"
15:01:13 <donri> magmas without closure :P
15:01:15 <pjdelport> tnks: For example, you might want the behavior of ZipList by default, instead of the Prelude's Applicative instance for lists.
15:01:18 <tnks> okay, now I need to look at replacement Preludes like basic-prelude and see if they have instances.
15:02:27 <tnks> pjdelport: sounds suspicious. . . making a list behave like a ZipList by fiddling with imports (is that what you're suggesting?)
15:02:42 <donri> does ^ have an inverse? canhas quasigroup? :D
15:04:25 <pjdelport> tnks: That's just an example of an alternative instance that makes sense.
15:05:01 <tnks> pjdelport: okay, I'll take it as an example and not a recommendation.
15:06:06 <pjdelport> Oh, of course.
15:17:08 <marchelzo_> name <- putStr "What is your name?\nName: " >> getLine -- why does this go getLine before it prints Name: but after it prints What is your name?
15:17:22 <marchelzo_> why does this do*
15:17:43 <koala_man> line buffering, probably
15:17:58 <geekosaur> for the same reason it does in most languages: it's line buffered by default. (many but not all C stdio implementations use a hack to force the stdout buffer out before reads on stdin)
15:18:40 <marchelzo_> so I have to use two separate putStr calls?
15:19:09 <koala_man> marchelzo_: use hFlush and/or hSetBuffering
15:19:24 <geekosaur> http://lambda.haskell.org/platform/doc/current/ghc-doc/libraries/haskell2010-1.1.1.0/System-IO.html#v:hSetBuffering or http://lambda.haskell.org/platform/doc/current/ghc-doc/libraries/haskell2010-1.1.1.0/System-IO.html#v:hFlush
15:19:33 <geekosaur> you odn't necessarily need both
15:19:49 <Cale> Yeah, hSetBuffering stdout NoBuffering will make that problem go away
15:19:49 <asfp`> what happens to an uncaught exception in a thread?
15:20:21 <Cale> asfp`: It kills the thread.
15:20:30 <asfp`> no output on stderr?
15:21:18 <Cale> asfp`: You should see some message
15:22:02 <dmj`> asfp`: "an exception escaped to toplevel"
15:22:22 <marchelzo_> geekosaur, thanks for the link
15:22:25 <Cale> Typically including the source code location which threw the exception and a show of the exception value
15:22:34 <tolt> If, for example, I had a [Either a b] and I wanted just [a], what would the best way to do that be with lens?
15:22:59 <Cale> I wouldn't use lens, I'd just write [x | Left x <- xs]
15:23:29 <tolt> Cale: I have a much more complicated structure that already has lenses though.
15:28:28 <ACSpike[laptop]> Can I get a non-spoiler hint. I’m working through https://www.fpcomplete.com/school/starting-with-haskell/basics-of-haskell/8_Parser and I’m stuck at the Ex 1. I don’t think I’m misunderstanding anything about Haskell itself, I think I just don’t know about parsers.
15:29:36 <dmj`> tolt: you might be able to use both, can you show code?
15:32:03 <tolt> dmj`: I found the answer. It was to use ^.. traverse
15:33:43 <dmj`> tolt: ah cool!
15:41:40 <ACSpike[laptop]> :t span
15:41:42 <lambdabot> (a -> Bool) -> [a] -> ([a], [a])
15:53:54 <cdsmith> Anyone know a good way to parse the output of `ghc -e ":browse SomeModule"`?  Or do something equivalent?
15:54:48 <cdsmith> It seems to use some syntax extensions that defeat haskell-src-exts
15:57:37 <rwbarton> you could consider linking against ghc-the-library and see what ghci does to print it
15:58:40 <rwbarton> hmm, that might be kind of complicated actually
16:04:47 <solidus-river> jle`: you around for a netwire question?
16:04:52 <solidus-river> i'm ready to make my main game loop
16:04:54 <solidus-river> which i want to be
16:05:37 <solidus-river> wire Double () Identity (Set Key) renderInfo
16:05:45 <solidus-river> and have an internal state of gameState
16:06:04 <solidus-river> but i cant find out how to actually initialize that internal state or create the wire
16:06:14 <solidus-river> everything i find online is composition of existing wires
16:06:43 <solidus-river> and i found some wire creation stuff on hackage but it offers no explanation aside from a type signature
16:07:06 * hackagebot Hsmtlib 2.8.8.8 - Haskell library for easy interaction with SMT-LIB 2 compliant solvers.  http://hackage.haskell.org/package/Hsmtlib-2.8.8.8 (roger62)
16:08:14 <solidus-river> or anyone thats created custom statefull wires in netwire
16:08:20 <solidus-river> *stateful
16:13:22 <extraplanetary> http://lpaste.net/106821 - I'm having some trouble with GADTs. It's a really a simple DSL for querying an even simpler data model (that bit works), and inspection of queries and tell you what 'shape' the data you pass in must have. I can't figure out why GHC can't figure out the types though
16:15:05 <extraplanetary> note that I -could- specialise ATraverse to ATraverseMaybe and GHC can figure it out, but the original example I whittled this down from would also need ATraverseVector and ATraverseList, which is really grungy and redundant
16:17:48 <Margaret21>  You can find funny videos here. http://bit.ly/1mLnHne
16:22:12 <phaazon> @hoogle (Functor f,Functor g) => c f -> c g
16:22:14 <lambdabot> Control.Monad forever :: Monad m => m a -> m b
16:22:14 <lambdabot> Foreign.ForeignPtr castForeignPtr :: ForeignPtr a -> ForeignPtr b
16:22:14 <lambdabot> Foreign.Ptr castFunPtr :: FunPtr a -> FunPtr b
16:24:51 <kazagistar> phaazon: the reason forever can generate an arbitrary g is because returning from it is absurd
16:25:04 <kazagistar> phaazon: or were you just testing if it would find fmap for you?
16:25:21 <phaazon> no, I’m looking for a typeclass
16:25:38 <phaazon> I have a strcuture
16:25:42 <phaazon> something like
16:25:51 <phaazon> data Vx f = (f a,f b,f c)
16:26:05 <phaazon> I’d like to find something that let’s me change the f
16:26:33 <phaazon> lets*
16:26:36 <kazagistar> you need a lot more then Functor to do that
16:26:47 <extraplanetary> phaazon: it might not be what you're looking for, but have a look at vinyl and mmorph
16:28:25 <kazagistar> phaazon: do the typeclasses have some kind of meaningful structure like a sequence?
16:28:54 <phaazon> I’m actually rethinking the problem
16:42:56 <mightybyte> Is there any way to define pattern match aliases?  i.e. you can say "foo = bar" and have referential transparency, but you can't say "foo = Bar" and have foo be usable in a pattern match.  It would be really cool if there were some way of doing this.
16:43:31 <mzero> isn't that a feature going into 7.10?
16:43:50 <mightybyte> No idea
16:43:55 <mightybyte> But that would be really cool if it was.
16:44:38 <quchen> 7.8 has pattern synonyms already, but it's an experimental feature.
16:44:48 <quchen> Try it out, find it cool, don't rely on it.
16:44:48 <mzero> there ya go
16:45:18 <pjdelport> mightybyte: http://www.haskell.org/pipermail/ghc-commits/2014-January/005722.html ?
16:48:38 <meditans> hi, I'd like to hear your opinion on the subject of computer assisted coding in languages with strong type system
16:49:06 <carter> meditans: its awesome and we need more of it :)
16:49:13 <meditans> with computer assisted coding I mean tools that can help generate (most of the) code without need for programmer to write it
16:49:37 <carter> meditans: have you seen any of the videos of people live coding in agda during a talk?
16:49:40 <meditans> as a case in point, I'd like to know if for you the right way to go is dependent types, à la idris
16:49:45 <carter> @google live coding in aggda
16:49:46 <lambdabot> http://en.wikipedia.org/wiki/Live_coding
16:49:46 <lambdabot> Title: Live coding - Wikipedia, the free encyclopedia
16:49:51 <carter> @google live coding in agda
16:49:52 <lambdabot> http://wiki.portal.chalmers.se/agda/pmwiki.php?n=AIMXIII.ProgramEtc
16:49:52 <lambdabot> Title: The Agda Wiki - Program etc.
16:49:57 <meditans> yes, I prefer Idris, but the idea is the same
16:50:02 <meditans> here is my question, though
16:50:48 <meditans> in your opinion, should code inference being exclusively generated by types, or it should also be driven by some sort of heuristics_
16:50:51 <meditans> ?
16:51:30 <meditans> eg. in Idris, I could write filter : (a -> Bool) -> List a -> List a
16:51:31 <carter> meditans: what would the heuristics be? :)
16:51:56 <meditans> and, by types, there is not a single correct way to complete it.
16:52:04 <carter> idk
16:52:09 * hackagebot verilog 0.0.6 - Verilog parser and DSL.  http://hackage.haskell.org/package/verilog-0.0.6 (TomHawkins)
16:52:11 <meditans> of course I could refine the type, asking for a list of proofs of membership
16:52:12 <carter> are you sure its that cut and dried?
16:53:07 <meditans> carter: what do you mean?
16:53:19 <carter> not sure
16:53:22 <carter> about to go nap
16:54:19 <meditans> good nap ;). Do you know where I can find more information on the subject
16:54:28 <meditans> or maybe some papers?
16:54:32 <carter> agda or idris channels
16:54:41 <carter> more folks there use thse tooling
16:54:51 <carter> also the agda-mode tooling is more mature than the idris stuff afaict
16:55:09 <meditans> yes it is, indeed. Thanks, I'll ask there :)
16:55:20 <quchen> Hey, I've got a testsuite with main Test.hs, which imports a couple of other files from the `tests` directory. How do I tell Cabal to include all those in `sdist`? Currently, I've got this: http://lpaste.net/106822
16:55:27 <dfeuer> Cale, did you have any thoughts on that mysterious permutations function?
16:55:37 <quchen> I could of course add all the files to extra-source-files, but that feels hacky.
16:58:00 <kazagistar> dfeuer: oh, right, I was looking at that and got distracted
16:58:24 <dfeuer> Yeah, I'm distracted. I should probably go do more important things.
16:59:20 <mzero> quchen: if sdist isn't picking them up already (it might not), I think you need to list the modules in  Other-modules:
17:00:02 <mzero> and you list them by module name, not file name
17:01:27 <quchen> mzero: Ah, that sounds good. I haven't used other-modules with testsuites before, but it did the trick.
17:01:34 <mzero> yay
17:01:47 <quchen> other-modules was "this is where internal modules go" up to now ;-)
17:02:56 <dfeuer> kazagistar, any new ideas?
17:03:27 <amosr> hey, I installed ghc 7.8.2 on OSX yesterday, and am getting a linker error when compiling some packages - right now, distributive-0.4.4
17:03:35 <amosr> the error is “ld: library not found for -lHStransformers-compat-0.3.3.4-ghc7.8.2”
17:03:46 <kazagistar> dfeuer: yeah, lemme get my mind back into it, I feel like I am close :P
17:03:54 <amosr> I couldn’t find anything on the trac or mailing lists about it. has anybody seen that before?
17:05:19 <rwbarton> amosr: try ghc-pkg check
17:05:20 <kazagistar> dfeuer: the begining is simple... the first permutation is the list itself, returned as is
17:05:41 <dfeuer> kazagistar, yes, that part is indeed simple. It's everything else that's not simple.
17:05:44 <rwbarton> amosr: that often happens when someone does rm -rf ~/.cabal
17:06:06 <mzero> hmmm..., amosr - what *is* transformers-compat?    7.8.x ships with transformers 0.3.0.0
17:06:12 <amosr> if I look in /Users/amos/.cabal/lib/transformers-compat-0.3.3.4/ghc-7.8.2, the file “libHStransformers-compat-0.3.3.4.a” is there, but not with a -ghc-7.8.2 suffix
17:06:31 <matematikaadit> amosr: try: cabal install transformers-compat-0.3.3.4
17:06:33 <amosr> rwbarton: ghc-pkg check only gives me haddock missing info
17:06:38 <rwbarton> aha, it is looking for the shared library libHStransformers-compat-0.3.3.4-ghc7.8.2.so
17:06:53 <rwbarton> I wonder why that didn't get built also
17:07:10 <mzero> ah - that suffix is used for dylibs
17:07:19 <kazagistar> the next part, perms, passes a parameter from the first stack to the second, and seems to act like a continuation
17:07:20 <mzero> well, on a mac it is .dylib
17:07:39 <amosr> mzero: I’m not entirely sure, but it’s a dependency of a lot of lens stuff
17:07:40 <mzero> so, it seems that you aren't building dylibs by default?
17:07:49 <amosr> ah, I see!
17:07:59 <amosr> mzero: (and hello, by the way!)
17:08:16 <amosr> I wonder if that’s a ghc option I somehow accidentally set?
17:08:42 <mzero> or if it is a new cabal configuration option that is no set because you have a .cabal/config file
17:08:43 <jmcarthur> edwardk: for what it's worth, i have long given up on real time queues. i'm considering the far simpler, amortized constant time queues good enough
17:08:50 <mzero> this would be nice to know!
17:09:04 <edwardk> jmcarthur: i got the basic realtime-deque working
17:09:11 <edwardk> jmcarthur: how's that for a turn around ;)
17:09:26 <jmcarthur> to be clear, the catenable one?
17:09:38 <edwardk> the non-catenable one. just the basic T&M one that is O(1)
17:09:42 <jmcarthur> ah
17:09:48 <jack_rabbit> Hey, there. I'm having trouble loading compiled code into ghci. It always shows up as interpreted.
17:09:51 <edwardk> i now understand the shape of the problem space
17:10:05 <jack_rabbit> The only thing my module imports is Data.List
17:11:10 <edwardk> jmcarthur https://github.com/ekmett/thrists/blob/master/wip/Mini.hs  should have the cons side of it done
17:11:14 <jmcarthur> well, best of luck to you. :) i've decided not to spend more time on it.
17:11:18 <mzero> amosr: looks like cabal needs --enable-shared
17:11:41 <edwardk> jmcarthur: once i have that i can use it to manage 4s in the catenable form the same way i manage 1s in the non-catenable form
17:11:41 <amosr> mzero: oh, wow, thanks
17:11:42 <jmcarthur> still interested in the problem, but just for kicks
17:11:44 <rwbarton> maybe you have an old .cabal/config file actually
17:12:00 <rwbarton> with shared: False, oh yeah that's what mzero said
17:12:11 * hackagebot science-constants 0.1.0.1 - Mathematical/physical/chemical constants  http://hackage.haskell.org/package/science-constants-0.1.0.1 (cbou)
17:12:15 <amosr> mzero: I had “— shared: False” (commented out) in cabal/config, so I’ll try adding shared: True?
17:12:17 <edwardk> jmcarthur: i have to say that this is probably the most invariants i've ever tried to juggle ;)
17:12:28 <mzero> did you actually *want* shared libs
17:12:33 <jmcarthur> heh
17:12:34 <edwardk> and i find it hilarious that this is just to build a building block that everything else will sit atop
17:12:44 <mzero> or is the default for the think you are building to use shared libs and you didn't realize that?
17:12:44 <jmcarthur> yeah it's crazy
17:13:02 <edwardk> 'lets write out the most impossible data structure ever' and then use it to make syntax trees fast
17:13:06 <amosr> hmm. not really. but maybe this distributive just assumes it’s shared?
17:13:14 <dfeuer> kazagistar, can you explain why that "is" thing gets passed in *twice*?
17:13:17 <rwbarton> oh! is your cabal old?
17:13:22 <mzero> yeah - I think that might be a, er, problem
17:13:29 <edwardk> but i really want O(1) worst-case for streaming applications
17:13:41 <mzero> well - for the longest time we didn't default to shared libs on Mac - there didn't seem to be much of a reason to
17:13:42 <edwardk> and i want to replace the use of free monads in scala with this completely
17:13:47 <mzero> and it just made executables brittle
17:13:52 <amosr> rwbarton: I did a cabal install cabal-install yesterday, before installing stuff, so it should be fine
17:13:55 <edwardk> because they pay _such_ a price for the operational monad transformer
17:13:56 <mzero> *is* there a reason to?
17:14:04 <rwbarton> what does cabal --version say? maybe you're running the old one accidentally
17:14:10 <mzero> amosr: that won't updated your .cabal/config
17:14:21 <rwbarton> shared: True is the default in new cabal
17:14:22 <mzero> as it shouldn't - that's supposed to be stable
17:14:48 <mzero> the bigger issue I think is that GHC and or cabal is building your main now, defaulting to *using* dylibs for things
17:14:49 <amosr> cabal-install 0.14.0 with Cabal 1.14.0
17:14:50 <jmcarthur> edwardk: yeah i was thinking of doing this for ocaml too. however, there's some sadness due to the lack of higher kinded type variables
17:14:55 <rwbarton> that's way old
17:14:55 <mzero> and that is probably what we wnat to fix
17:15:07 <rwbarton> you need 1.18 or newer
17:15:14 <edwardk> yeah, you can't really parameterize it
17:15:16 <mzero> anyone know what the rationale for Share: True default is?
17:15:26 <amosr> oh wow. ok, thanks!
17:15:27 <MP2E> No idea, imo kill it with fire
17:15:35 <MP2E> I do first thing whenever I make a cabal config :P
17:15:39 <edwardk> for SML you could at least make a module, etc.
17:15:42 <jmcarthur> well, and most of the nicer queues use polymorphic recursion on higher kinded type variables :(
17:15:47 <amosr> I thought I upgraded, but it must not have quite happened
17:15:52 <rwbarton> mzero: one advantage is it means we can use the system linker in ghci, because loading dynamic libraries dynamically is actually supported
17:15:56 <jmcarthur> it's doable, but at great cost and verbosity
17:15:57 <kazagistar> dfeuer: kinda, I am still working out the details... is represents "the stack of things that have been processed and are at the start"... are you familliar with zippers? (I am only mildly aquanted, actually...) the idea is that as you go deeper into the source list, you have a "current position" identified by what is still ahead, (ts) what is the current element (t), and what has been passed (is)
17:16:07 <mzero> AHA
17:16:11 <mzero> good - that's a good one
17:16:19 <merijn> mzero: Also a whole bunch of linker bugs are fixed by using the system linker
17:16:29 <rwbarton> mzero: previously ghci implemented its own linker for static object files, but this meant some fancy object file features weren't supported, which caused problems when linking against C++ libraries, etc.
17:16:36 <mzero> but now we have to deal with the fact that there are zillions of folks out there with .cabal/config files that have shared: false in 'em
17:16:49 <dfeuer> kazagistar, I'm mildly acquainted with zippers, and also mildly acquainted with Hughes-style lists-as-functions. I have the feeling both ideas are embedded in that code ... somehow.
17:16:58 <mzero> and, I'm guessing, that is why jack_rabbit is having problems loading compiled code!
17:17:00 <rwbarton> well, most people should have a comment '-- shared: False', but, yeah
17:17:05 <edwardk> hahahahahaa https://twitter.com/drboolean/status/484427102599405568
17:17:23 <jmcarthur> that's awesome
17:17:27 <jack_rabbit> mzero, :) doubtful. I've not even gotten cabal into the mix.
17:17:58 <jack_rabbit> mzero, I've not used haskell in nearly a year now, so I'm just getting back into it with some basic stuff. Just a simple module with a few list length functions.
17:18:03 <dcoutts> mzero: let us know if you think it's a serious problem. As rwbarton says I expect most people have it unset in their cabal config, so our change of default should just work.
17:18:32 <amosr> ugh, silly me! for some reason I had a cabal in /usr/local/bin as well as ~/.cabal/bin, and was using the old /usr/local one
17:18:49 <mzero> okay - I stand corrected: the .cabal/config file that Haskell Platform on Mac OS X writes for new users has
17:18:53 <mzero> -- shared: False
17:18:56 <ReinH> edwardk: lol
17:18:59 <dfeuer> edwardk, I imagine *you* could understand http://stackoverflow.com/questions/24484348/what-does-this-list-permutations-implementation-in-haskell-exactly-do without blinking more than three times.
17:19:04 <mzero> this is good - things will default correctly for them (me hopes)
17:19:33 <mzero> so, it looks like amosr's problem is an old cabal, not the one that matches 7.8.2
17:20:04 <kazagistar> dfeuer: so, basically, perms moves an item from the list (or stack) which are just chained at the end unpermuted to the reversed list of items which are being permuted, recursively, as far as I can tell, like a zipper, and then it ALSO passes that just the items to permute in as the initial value of the fold
17:20:16 <amosr> is there an easy way to unregister all ghc-pkgs in /Users/amos/.ghc/x86_64-darwin-7.8.2/package.conf.d ?
17:20:37 <edwardk> dfeuer: ah the extra-fancy lazy version
17:20:39 <amosr> actually, I guess I don’t want to do that, since cabal is already there
17:21:01 <dfeuer> kazagistar, I can't even parse that sentence.
17:21:09 <phaazon> @hoogle f (c g) -> g (c f)
17:21:10 <lambdabot> Control.Monad forever :: Monad m => m a -> m b
17:21:10 <lambdabot> Foreign.ForeignPtr castForeignPtr :: ForeignPtr a -> ForeignPtr b
17:21:10 <lambdabot> Foreign.Ptr castFunPtr :: FunPtr a -> FunPtr b
17:21:20 <phaazon> yeah, of course. :D
17:21:24 <mzero> amosr: delete the directory!
17:21:28 <kazagistar> dfeuer: thats because the second half had wrong grammar, oops
17:21:49 <dfeuer> edwardk, yeah, *that* thing. Writing an implementation with the same laziness properties but that is *very slow* is easy...
17:22:52 <saclark> I am a haskell beginner but also appreciate deeper, more technical discussion (even if it’s over my head, perhaps in the hope that I’ll learn through osmosis). Should I subscribe to haskell-cafe or haskell-beginners?
17:23:33 <extraplanetary> http://lpaste.net/106821 - I'm having some trouble with GADTs. It's a really a simple DSL for querying an even simpler data model (that bit works), and inspection of queries and tell you what 'shape' the data you pass in must have (that doesn't work; I can't figure out why not)
17:23:47 <dfeuer> kazagistar, could you rewrite it so I can understand it? I don't understand what you mean by "the reversed list of items which are being permuted" either.
17:24:11 <mzero> dcoutts & rwbarton  - so we should set things up so that building all packages builds libraries with --enable-shared (by leaving Shared: to default to True in .cabal/config)
17:24:14 <jle`> ~
17:24:30 <mzero> and we should have ghc, by default compile executables so they are statically linked
17:24:42 <dcoutts> mzero: I think that is the case now
17:24:46 <dcoutts> mzero: for 7.8
17:24:49 <amosr> mzero: rwbarton: thanks a bunch, looks like it’s working
17:25:02 <dcoutts> mzero: with recent cabal
17:25:11 <mzero> but compile libraries both ways - statically against the static ones they use, and dynamically, against the dynamic ones they use
17:25:41 <dcoutts> mzero: we should double check, but I think that is also what we do
17:25:46 <dcoutts> for 7.8
17:25:53 <mzero> good, dcoutts - I'll verify this against the HP Mac alpha I'm building
17:26:28 <Lutin`> dfeuer: Try writing a couple of the elements out by hand
17:27:03 <dfeuer> Lutin`, you mean executing the function by hand?
17:27:16 <kazagistar> dfeuer: if you look at the sequence of permutations, it conceptually looks like [1,...], [2,1...], [3,2,1,...],[2,3,1,...],[3,1,2,...],[1,3,2,...],[4,3,2,1...]
17:28:29 <dfeuer> kazagistar, what's the concept, aside from the fact that (as I indicated) it's partially ordered by the position of the last element that moves?
17:29:10 <dfeuer> And that it seems to always start a new length with the next item....
17:29:37 <jack_rabbit> I don't want to be pushy. You guys are always really helpful, and I'm sure I'm doing something stupid.
17:29:54 * mzero is on a bus to S.F. with cellular data that cuts in and out
17:30:00 <benzrf> jack_rabbit: beginners often do :O)
17:30:09 <jack_rabbit> benzrf, no doubt. :)
17:30:13 <Cale> jack_rabbit: What was your question?
17:30:17 <kazagistar> dfeuer: perms is the function that represents the "outer loop" of pulling one item from the "..." and into the things we are permuting
17:30:26 <jack_rabbit> Cale, I'm just trying to get ghci to load my compiled module.
17:30:39 <jack_rabbit> Cale, but it always interprets the hs file.
17:30:40 <Cale> jack_rabbit: If the .o and .hi file are present, it should do that automatically
17:30:44 <jle`> solidus-river: i'm in and out, so just ask and i'll try to answer it when i can :)
17:30:55 <dfeuer> kazagistar, okay. That's what the foldr is about, I guess.
17:31:04 <mzero> jack_rabbit: by anychance are your sources in a subdir, like "src" or some such?
17:31:13 <jack_rabbit> nope, they're in the CWD.
17:31:16 * dfeuer goes to dinner for a bit.
17:31:52 <mzero> and you've built them with ghc directly, or via cabal and .cabal file?
17:32:11 <jack_rabbit> mzero, I've built them with 'ghc -c Counts.hs'
17:32:23 <benzrf> jack_rabbit: try the full filename
17:32:28 <benzrf> instead of the module nmame
17:32:34 <kazagistar> dfeuer: the foldr is inside that loop. the outer loop is "perms" calling itself, but shifting one item from "ts" (which represents "...") to "is" (which represents the stuff we are permuting now)
17:33:01 <mzero> benzrf: you mean   :l Counts.hs
17:33:03 <mzero> ?
17:33:07 <benzrf> ya
17:33:14 <jack_rabbit> benzrf, :load Counts.o: Not a module name or source file
17:33:20 <benzrf> o_o
17:33:22 <jack_rabbit> benzrf, :load Counts.hs: interpreted
17:33:27 <benzrf> dag
17:33:50 <mzero> hmmmm..... another idea:       ghci -i.      then     :m + Counts
17:33:57 <Cale> jack_rabbit: Does the module export anything?
17:35:08 <jack_rabbit> Cale, yeah, I explicitly export all of the functions I want.
17:35:22 <jack_rabbit> mzero, Tried that.: Could not find module 'Counts'
17:35:26 <kazagistar> dfeuer: so, the intial state of "is" is empty, and the initial state of "ts" is the full input sequence, and the ending condition is when we reach the end of the input sequence, and there are no more items to move to "is"
17:36:12 <kazagistar> dfeuer: I might be totally wrong and backwards about that though.... ugh
17:36:57 <dfeuer> kazagistar, it seems really weird that it calls `permutations` on each step.
17:39:01 <Cale> jack_rabbit: try running ghci with -fobject-code
17:40:42 <mzero> hmmm.... jack_rabbit - I did     ghc -c Foo.sh  ;  ghci       then    :l Foo
17:40:48 <mzero> and i got the compiled version
17:40:57 <solidus-1iver> jle`: client fail there. I made it into a lpaste, i'm stuck on creating a statefull wire with an initial state http://lpaste.net/106824
17:40:57 <Cale> mzero: Which ghc version?
17:41:04 <Cale> also jack_rabbit
17:41:07 <mzero> 7.6.3
17:41:10 <mzero> on Mac OS X
17:41:25 <solidus-1iver> i'm in and out today too, @ work late and getting pulled into random meetings so i might not respond immediately but i'll get it
17:41:32 <jack_rabbit> mzero, yeah, that doesn't work for me.
17:41:36 <jack_rabbit> Cale, that seems to work.
17:41:44 <Cale> Yeah, that's how I'd expect things to work. I just tried ghc 7.8.2 though, and found that it didn't load the .o as I expected
17:41:55 <jack_rabbit> Cale, it's strange, though. It causes GHCI to compile it, rather than using the existing .o file.
17:42:08 <Cale> jack_rabbit: Yeah, that's what that option does
17:42:18 <jack_rabbit> Cale, yeah, I'm using 7.8.2
17:42:21 <jack_rabbit> Is that a bug, then?
17:42:33 <mzero> what os?
17:42:47 <jack_rabbit> Linux 3.14.4
17:42:50 <jack_rabbit> Arch
17:43:09 <mzero> hmmmm....
17:43:11 <extraplanetary> jack_rabbit: try compiling it with -dynamic-too?
17:43:14 <mzero> alas - at my stop - laters
17:44:05 <jack_rabbit> extraplanetary, no good.
17:52:42 <jack_rabbit> Okay, so now that I've got compilation working, I'm playing with a couple list length functions, but I can't seem to quite reach Prelude's length's performance.
17:52:49 <jack_rabbit> I'm always about a second behind.
17:55:15 <Cale> jack_rabbit: Yeah, well, it does some hackery with unboxed Ints
17:55:41 <jack_rabbit> hmm. What exactly is a 'boxed' int?
17:56:02 <jack_rabbit> I'm looking at length's code now, and I see some '#' characters which I'm not familiar with.
17:57:09 <Cale> Well, the machinery which permits both lazy evaluation and polymorphism is called boxing
17:57:53 <jack_rabbit> Sure, I'm familiar with the concept of boxing. I'm just not familiar enough to know how it applies in this context.
17:57:55 <Cale> In GHC, it means that ordinary values are really pointers to code which might need to compute the actual value before returning it.
17:58:01 <Cale> okay
17:58:44 <jack_rabbit> I'm using strict evaluation to avoid a stack overflow. Can I somehow unbox the Int values further?
17:58:45 <Cale> So, GHC also has some support for unboxed types of data, you'll see Int# which is the type of unboxed integers
17:58:51 <jack_rabbit> ahhh.
18:00:13 <Cale> https://www.haskell.org/ghc/docs/latest/html/users_guide/primitives.html
18:00:16 <jack_rabbit> Looks like there are corresponding "unboxed int operators"
18:00:22 <Cale> yes
18:00:22 <jack_rabbit> like +#
18:00:27 <jack_rabbit> I'll have a look. Thanks.
18:00:43 <jack_rabbit> and I# is a function Int# -> Int
18:00:50 <Cale> Because you're throwing out the mechanism for polymorphism, you need to use special operations which aren't polymorphic also.
18:00:57 <jack_rabbit> right.
18:00:58 <Cale> yeah
18:01:01 <rwbarton> I'd be surprised if you can't write a version that matches Prelude.length's performance when optimized, though
18:01:05 <Cale> I# is actually a data constructor for Int
18:01:11 <rwbarton> ghc ought to be able to perform this unboxing
18:01:12 <jack_rabbit> Cale, interesting.
18:01:31 <rwbarton> @src Int
18:01:32 <lambdabot> data Int = I# Int#
18:01:32 <Cale> rwbarton: Well, the fact that Prelude.length uses explicitly unboxed stuff is a bit of an admission that perhaps it's hard to do so.
18:01:35 <jack_rabbit> rwbarton, hmm. what's the default optimization for ghc?
18:01:44 <rwbarton> none
18:01:49 <amosr> one thing to be aware of if you’re doing unboxed stuff: the fixity/precedence rules for unboxed operations are not correct. make sure you use explicit parentheses
18:01:59 <jack_rabbit> rwbarton, mayble I'll give it a shot with -O2 (or whatever ghc's equivalent is)
18:02:09 <jle`> solidus-1iver: what do you mean by "stateful wire", exactly?
18:02:20 <Cale> jack_rabbit: Yeah, -O2
18:02:23 <jack_rabbit> amosr, thanks. That's really good to know.
18:02:33 <jack_rabbit> Cale, hang on, I'll give optimization a shot and let you know.
18:02:41 <Cale> amosr: That should be easy to fix, interesting that they didn't set it correctly.
18:02:56 <jack_rabbit> Cale, wait...
18:02:57 <rwbarton> Cale: I think it means at one point in the past it was hard to unbox, and then why bother to change it
18:03:09 <jle`> solidus-1iver: if you are thinking of a wire as some sort of s -> (s, a), that's sort of the wrong way to approach it
18:03:15 <jack_rabbit> Cale, I don't know how to pass parameters to the compiler with -fobject-code
18:03:17 <Cale> rwbarton: Yeah, that's always possible :)
18:03:18 <jle`> what is GameState --- the entire state of your game?
18:03:48 <Cale> jack_rabbit: why not just build an executable?
18:03:48 <amosr> Cale: apparently it’s just more effort than it’s worth. I don’t quite know
18:04:35 <jack_rabbit> Cale, I've :set +s to time. I remember doing it with haskell types, but it'll take me a few minutes to look it up. Hang on.
18:05:08 <amosr> worker/wrapper or spec constr should often unbox recursive functions though. perhaps not if strictness analysis doesn’t realise they’re strict. adding bang patterns and reading the core output (-ddump-prep -dppr-case-as-let -dppr-suppress-all) can help
18:11:09 <jmcarthur> i find that assisting the strictness analyzer is often the biggest help i can give the compiler, after all the higher level optimizations are out of the way
18:15:24 <jack_rabbit> with 100M elements, my length is 2.29 seconds. Prelude's is 1.767 seconds.
18:15:30 <jack_rabbit> That's with -O2
18:15:35 <jack_rabbit> I'll try explicit unboxing.
18:15:54 <jle`> is there any reason why ghc wouldn't inline a super small function like f = g x
18:16:07 <l0cust> Hey, is there something like a (<<) operator anywhere
18:16:11 <jle`> (where g takes two arguments)
18:16:12 <l0cust> I can't find it on Hoolge
18:16:13 <jle`> l0cust: what would it do?
18:16:17 <solidus-1iver> jle`: by statefull wire i mean wire that has internal state thats transparent
18:16:26 <jle`> l0cust: there's (<*)
18:16:28 <l0cust> jle`: (>>) but with the arguments reversed
18:16:30 <jle`> but that's not exactly (<<)
18:16:33 <jle`> ah
18:16:37 <jle`> well there's the problem
18:16:45 <jle`> should (<<) behave like (<*), or like flip (>>) ?
18:17:28 <l0cust>   where a << b = b >> a
18:17:32 <l0cust> That's what I did
18:17:52 <jle`> l0cust: yeah, you can do that.   but the reason why there is no (<<) out there is because it's not clear which one it should behave like
18:18:00 <jle`> both (<*) and flip (<<) make sense
18:18:27 <jle`> solidus-1iver: hm.  the reason why it's not advised to have your wire be some sort of state stepper is because it's generally easy to leak the timestep that way and break the abstraction
18:18:34 <jle`> what sort of things does your state contain?
18:18:52 <solidus-1iver> jle`: the position and velocity of a space invader
18:19:01 <solidus-1iver> i'm never taking time out of the wire
18:19:14 <jle`> solidus-1iver: but how are you getting the position and velocity?
18:19:24 <solidus-1iver> its depending on the input of the wire
18:19:33 <solidus-1iver> the input of the wire is a set of keys
18:19:34 <jle`> in what way?
18:19:38 <solidus-1iver> if the left arrow is pressed
18:19:44 <solidus-1iver> the velocity of the space invader increases
18:19:57 <solidus-1iver> or object or whichever
18:20:06 <jle`> have you seen ocharle's netwire tutorial?
18:20:16 <solidus-1iver> i have
18:20:24 <solidus-1iver> but he doesnt ever create a wire with state it seems
18:20:24 <jle`> he basically does exactly that, doesn't he?
18:20:30 <solidus-1iver> i htink he does
18:20:35 <solidus-1iver> but i cant make out where the wire is actually created
18:20:46 <solidus-1iver> like i cant find in his code base where he is defining that wire and initial state
18:21:07 <l0cust> jle`: well, it didn't behave correctly, anyway
18:21:12 <l0cust> jle`: so fuck it
18:21:22 <l0cust> jle`: I'll cave and use *gulp* parentheses
18:21:23 <jle`> l0cust: what is "correctly"?
18:21:32 <jle`> you can use fixity declarations
18:21:35 <l0cust> x << y $ z x
18:21:42 <l0cust> I expected it to do
18:21:42 <solidus-1iver> i htink i want mkPureN
18:21:51 <l0cust> x << (y (z x))
18:21:52 <jle`> solidus-1iver: you want to compose wires
18:22:01 <solidus-1iver> jle`: but i dont understand how that works
18:22:10 <solidus-1iver> like how does it get the initial state thats encapsulated in the wire
18:22:13 <l0cust> jle`: but instead, it did (x << y) (z x)
18:22:20 <jle`> imagine this: data InvaderState = InvaderState { pos :: Double; hits :: Int }
18:22:22 <solidus-1iver> the state is not of type s, e, m, a, or b
18:22:29 <jle`> the state is not in the type
18:23:13 <jle`> and let's say you want invaderWire :: s e m (Event Hit) InvaderState
18:23:14 <solidus-1iver> jle`: so how do i give it an initial one if none of the inputs will set it
18:23:25 <jle`> you would do something like
18:24:08 <solidus-1iver> jle`: what i want is a little different, i'm shooting for invaderWire :: s e m (Event Hit) endPosition  which internally has invaderState
18:24:30 <jle`> endPosition?  you mean 'position at the time'?
18:24:36 <solidus-1iver> yeah
18:24:40 <solidus-1iver> so it doesnt return a whole state
18:24:43 <jack_rabbit> hmm... getting a syntax error with unboxed Ints.
18:24:45 <jle`> okay, well
18:24:46 <solidus-1iver> jsut the part my renderer needs to know
18:24:51 <jle`> you get a position by using integral
18:24:58 <jle`> pos <- integral x0 -< velocity
18:25:09 <jle`> where x0 is your intial position and velocity is something that gives the velocity
18:25:16 <jle`> and you can have velocity <- something -< hitEvent
18:25:22 <jle`> that changes the velocity based on your hitEvent
18:25:25 <jle`> using your something wire
18:25:41 <jle`> and ten at the end, returnA -< pos
18:25:42 <solidus-1iver> so theres no way to have an internal state thats different than a or b?
18:25:56 <jle`> your state is not determined by a or b
18:25:59 <jle`> it is unrelated
18:26:20 <solidus-1iver> so lets forget what i was trying to do with the state, i think i'm lost on something more fundamental
18:26:23 <jle`> let's say you have a function (a -> b) and a function (b -> c).  you compose them and get an (a -> c).  but the `b` you got in the middle is important
18:26:29 <jle`> but your final function is of type (a -> c).
18:26:29 <solidus-1iver> say i have wire s e a m b
18:26:34 <solidus-1iver> internally i need it to have a z
18:26:39 <solidus-1iver> how do i give it an initial z
18:26:41 <jle`> where did the `b` go in (a -> c) ?
18:26:56 <jle`> hold on, have to go for a bit
18:26:58 <jle`> sorry
18:27:04 <solidus-1iver> no worries :)
18:27:29 <solidus-1iver> i'm happy your giving explanations
18:30:51 <benzrf> > (<-)
18:30:52 <lambdabot>  <hint>:1:2: parse error on input ‘<-’
18:30:56 <benzrf> > (-<)
18:30:57 <lambdabot>  Not in scope: ‘-<’
18:30:57 <lambdabot>  Perhaps you meant one of these:
18:30:57 <lambdabot>    ‘-’ (imported from Prelude), ‘<’ (imported from Data.Ord),
18:30:57 <lambdabot>    ‘-=’ (imported from Control.Lens)
18:31:04 <benzrf> > (=_=)
18:31:05 <lambdabot>  <hint>:1:2: parse error on input ‘=’
18:31:25 <benzrf> @let (+.+) = "IM ANNOYED"
18:31:27 <lambdabot>  Defined.
18:31:29 <jmcarthur> jle`: i think ghc will pretty much always inline such a function
18:31:30 <benzrf> @let (+.+) = text "IM ANNOYED"
18:31:31 <lambdabot>  .L.hs:205:1:
18:31:31 <lambdabot>      Multiple declarations of ‘+.+’
18:31:31 <lambdabot>      Declared at: .L.hs:204:1
18:31:31 <lambdabot>                   .L.hs:205:1
18:31:33 <benzrf> aw
18:31:37 <benzrf> > (+.+)
18:31:39 <lambdabot>  "IM ANNOYED"
18:31:53 <benzrf> > text (+.+)
18:31:54 <lambdabot>  IM ANNOYED
18:32:03 <benzrf> :t text
18:32:04 <lambdabot> String -> Doc
18:32:06 <jack_rabbit> Yep. With explicit unboxing, the performance is nearly equivalent.
18:32:18 * hackagebot eros 0.5.0.0 - A text censorship library.  http://hackage.haskell.org/package/eros-0.5.0.0 (pharpend)
18:32:22 <jmcarthur> @undef
18:32:22 <lambdabot> Undefined.
18:32:28 <jmcarthur> @let (+.+) = text "IM ANNOYED"
18:32:29 <lambdabot>  Defined.
18:32:40 <benzrf> > (+.+)
18:32:41 <lambdabot>  IM ANNOYED
18:32:54 <benzrf> @let implying = text ">greentexting in irc"
18:32:55 <lambdabot>  Defined.
18:32:57 <benzrf> > implying
18:32:58 <lambdabot>  >greentexting in irc
18:33:04 <jmcarthur> jack_rabbit: could you lpaste the unboxed version of your function? i'm skeptical of all this
18:33:08 * benzrf spontaneously develops cancer
18:33:09 <jack_rabbit> Cale^
18:33:31 <kvanb> does anyone know how to fix the soft tab quirk in Atom
18:33:36 <kvanb> where soft tabs dont align to tab stops?
18:33:40 <benzrf> kvanb: jesus why are you using atom
18:33:53 <benzrf> thats like
18:33:56 <benzrf> the node.js of text editors
18:33:58 <kvanb> Sublime Text user, trying to go to atom because of those glyph things
18:33:59 <benzrf> bleh
18:34:09 <benzrf> kvanb: use vim or emacs u pleb
18:34:23 <kvanb> I can't, I'm pleb
18:34:24 <kvanb> https://github.com/i-tu/Hasklig
18:34:26 <jmcarthur> kvanb, benzrf: this kind of conversation should really be in #haskell-blah
18:34:33 * benzrf goes to -blah
18:34:37 <jack_rabbit> jmcarthur, sure, hang on.
18:34:45 <kvanb> benzrf: you derailed my question
18:34:46 <kvanb> ffff
18:34:50 <jack_rabbit> I'll switch irc to my dev box.
18:34:55 <benzrf> kvanb: the answer is:
18:34:57 <benzrf> don't use atom
18:35:12 <benzrf> ( ͡° ͜ʖ ͡°)
18:35:35 <jmcarthur> benzrf: actually, i have a screenful of text that's mostly from you and not really relevant to this channel at all :\
18:35:57 <jmcarthur> benzrf: and to think i assisted you! :P
18:36:19 <benzrf> shit
18:36:29 <benzrf> kvanb: your link says 'over 100 in lens alone!'
18:36:33 <benzrf> wrt operators
18:36:44 <benzrf> 'lens alone'
18:36:47 <kvanb> I'm unsure if you guys can see this but I'll try anyway
18:36:56 <kvanb> https://scontent-a-lax.xx.fbcdn.net/hphotos-xfa1/l/t1.0-9/10487392_779499508760986_5918871121065475711_n.jpg
18:36:59 <kvanb> its very purdy
18:37:10 <benzrf> gross
18:37:14 <benzrf> well
18:37:19 <benzrf> the bind glyph is gross
18:37:21 <benzrf> arrows are neat
18:37:23 <jack_rabbit> Okay, here's the paste: http://lpaste.net/106827
18:37:52 <jack_rabbit> fyi, import Primative imports my unboxed module.
18:37:56 <kvanb> the bind glyph isn't that bad
18:38:08 <kvanb> I really like the way it spaces everything else closer to the center for less noise though
18:38:16 <kvanb> cures some of my OCD w.r.t code spacing and layout
18:38:25 <jmcarthur> ah
18:38:35 * jmcarthur comments out Primative stuff...
18:39:04 <benzrf> kvanb: why not use a Superior Editor
18:39:17 <jack_rabbit> (heh. Should actually be "Primitive." I tend to confuse Primitive with Primate)
18:39:31 <benzrf> kvanb: atom is for People With Macs Who Use The Language Of The Month
18:40:00 <benzrf> kvanb: are you a Person With A Mac Who Uses The Language Of The Month???
18:40:10 <jmcarthur> jack_rabbit: i'm surprised you get a speedup with the unboxed version. ghc is unboxing the other one, for me
18:40:33 <kvanb> if you think its supposed to be optimized put it on the ghc trac as a performance bug
18:40:39 <kvanb> don't let it be forgotten
18:41:19 <kvanb> if anything, it could be visited in 5 years time or whatever if it's too hard, but the important thing is to let the devs know that it exists and have it on record
18:41:40 <jmcarthur> kvanb: if you are referring to jack_rabbit's thing, i claim it *is* being optimized. i'm looking at the core right now
18:41:59 <kvanb> :) keep me posted please
18:42:23 <kvanb> benzrf: I have a mac
18:42:34 <kvanb> and I think atom is a sensible but immature editor, as is Sublime Text.
18:42:53 <benzrf> :g/kvanb/d
18:43:03 <jack_rabbit> jmcarthur, I mean, that's all the code I have. I'm compiling with ghc -O2 Counters.hs Primative.hs
18:43:42 <benzrf> >
18:43:43 <benzrf> At GitHub, we're building the text editor we've always wanted. A tool you can customize to do anything, but also use productively on the first day without ever touching a config file. Atom is modern, approachable, and hackable to the core. We can't wait to see what you build with it.
18:43:50 <benzrf> this isnt emacs?
18:43:56 <MP2E> hahha
18:44:02 <benzrf> ( ͡° ͜ʖ ͡°)
18:44:03 <MP2E> Sooo... it's githubmacs?
18:44:12 <MP2E> eh. emacs has github-mode
18:44:19 <benzrf> >Atom is a desktop application based on web technologies. Like other desktop apps, it has its own icon in the dock, native menus and dialogs, and full access to the file system.
18:44:25 <benzrf> >Open the dev tools, however, and Atom's web-based core shines through. Whether you're tweaking the look of Atom's interface with CSS or adding major features with HTML and JavaScript, it's never been easier to take control of your editor.
18:44:29 <benzrf> w-who
18:44:30 <benzrf> who wants this
18:44:48 <kvanb> I liked that feature. Let me turn on glyphs in one line of css code.
18:44:55 <jack_rabbit> benzrf, it looks like it would be really excellent for people who don't already have emacs installed.
18:45:01 <benzrf> >Atom is composed of over 50 open-source packages that integrate around a minimal core. Our goal is a deeply extensible system that blurs the distinction between "user" and "developer".
18:45:05 <benzrf> >Don't like some part of Atom? Replace it with your own package, then upload it to the central repository on atom.io so everyone else can use it too.
18:45:11 <benzrf> still sounds like emacs to me :i
18:45:11 <jack_rabbit> benzrf, and don't know how to use apt, etc.
18:45:20 <jack_rabbit> benzrf, have you used the demo?
18:45:30 <jack_rabbit> benzrf, it basically *is* emacs.
18:45:41 <benzrf> then why use it instead
18:45:46 <benzrf> the answer is:
18:45:48 <kvanb> I wouldn't say its emacs
18:45:57 <benzrf> same reason people use node.js when langauges besides javascript exist
18:45:58 <kvanb> its emacs without the dependency on remembering keybindings, maybe.
18:46:01 * benzrf cries
18:46:06 <benzrf> kvanb: top lel
18:46:22 <jmcarthur> jack_rabbit: the boxed version is almost as fast as Prelude's, for me. the Prelude one might have some rewrite rules that's causing it to pull out ahead, but we're talking just a 9% difference, not like double or anything
18:46:24 <benzrf> vims the one that requires memorization of key bindings
18:46:41 <kvanb> it's closer to just a better Sublime Text
18:46:51 <benzrf> so... still worse than vim or emacs
18:46:52 <benzrf> :^)
18:47:10 <kvanb> please, take it to #blah
18:47:51 <jack_rabbit> jmcarthur, for me: http://lpaste.net/106828
18:48:02 <jack_rabbit> jmcarthur, that looks really funny to me. I must be doing something wrong.
18:48:15 <jack_rabbit> jmcarthur, especially since my RAM spikes, and it should be TCO'd.
18:49:30 <jack_rabbit> without any "thunks" getting built up, because it should be strict.
18:49:52 <rwbarton> oh
18:49:58 <jmcarthur> jack_rabbit: are you sure you're even compiling with -O2? i found that when i had all three benchmarks uncommented, the common subexpression elimination pass destroyed me because it tried to share the list
18:49:58 <rwbarton> I bet GHC is CSEing the three lists
18:50:00 <rwbarton> which is terrible
18:50:06 <jmcarthur> jack_rabbit: ah! it's biting you too
18:50:20 <jmcarthur> jack_rabbit: put {-# OPTIONS -fno-cse #-} at the top of the main module
18:50:29 <jack_rabbit> jmcarthur, Okay, I'll give that a shot.
18:50:47 <jmcarthur> this would make much sense
18:51:00 <jack_rabbit> THERE we go.
18:51:11 <jack_rabbit> Now both are faster than Prelude. :P
18:51:17 <jmcarthur> so the first benchmark was generating that whole list, which is why it was so slow
18:51:20 <jack_rabbit> by 0.3
18:51:43 <rwbarton> well that's also weird :P
18:51:58 <jmcarthur> i think cse should probably not be enabled by -O2
18:52:04 <jmcarthur> it's not one of those "safe" optimizations
18:52:31 <jmcarthur> i agree that it's weird that you would beat Prelude, too
18:52:37 <jmcarthur> is it consistent?
18:52:45 <rwbarton> I wonder if fusion is relevant here at all
18:52:46 <jack_rabbit> Don't know. I'll give it a few tries.
18:52:58 <jmcarthur> i don't remember if enumFromTo fuses
18:53:05 <jmcarthur> i'm thinking it doesn't?
18:53:08 <jmcarthur> (sadly)
18:53:19 <jack_rabbit> Yeah, it's consistently nearly exactly .3 seconds faster.
18:53:23 <jack_rabbit> Both of them.
18:53:39 <jmcarthur> maybe the fusion machinery is pessimistic here for some reason
18:53:47 <rwbarton> I don't actually expect it to fuse but yeah, maybe
18:53:59 <jack_rabbit> what is this fusion?
18:54:47 <jmcarthur> jack_rabbit: if you want to see fusion in action, import qualified Data.Vector.Unboxed as Vector and benchmark   Vector.length (Vector.enumFromN 1 100000000)
18:55:03 <jmcarthur> jack_rabbit: (although for this specific example it might not actually do much better)
18:55:11 <jmcarthur> (actually i bet it will)
18:55:34 <rwbarton> I think it will fuse down to simply 100000000
18:55:44 <jmcarthur> rwbarton: ah, actually, you're right
18:55:48 <jmcarthur> rwbarton: and it's not even fusion
18:55:50 <jmcarthur> it'
18:55:52 <jack_rabbit> With a billion, it's 3 seconds slower. Pretty consistent.
18:55:55 <jmcarthur> *it's just boring inlining
18:55:59 <jack_rabbit> Slower by about 3%
18:56:13 <jmcarthur> jack_rabbit: if you want to see boring inlining in action, do what i suggested ;)
18:56:29 <jack_rabbit> I'm nust not sure what fusion *is* in this context.
18:56:43 <jack_rabbit> Any particular literature I should look at, or should I just search?
18:56:45 <jmcarthur> jack_rabbit: anyway, fusion takes multiple loops in sequence and turns them into just one
18:56:52 <jack_rabbit> ahh.
18:56:57 <Lutin`> jack_rabbit: It might be due to the rule Prelude has
18:57:08 <Lutin`> Aside from that rule your implementations are the exact same
18:57:19 <jmcarthur> jack_rabbit: it's kind of a library-level optimization, mostly implemented in terms of rewrite rules and relying on existing compiler optimizations
18:57:33 <jmcarthur> jack_rabbit: at least that's how fusion in base and vector work
18:57:39 <jack_rabbit> Lutin`, that's what I thought.
18:57:53 <jack_rabbit> Lutin`, that our implementations were the same, that is.
18:58:16 <jack_rabbit> Either way, without that, why should my implementation be faster?
18:58:22 <Lutin`> Prelude has this rule: "length"     [~1] forall xs. length xs = foldr incLen I# xs 0#
18:58:54 <jack_rabbit> Can you explain that rule?
18:58:59 <jack_rabbit> I'm unfamiliar with rules.
18:59:10 <jmcarthur> jack_rabbit: okay, ready to be impressed with Prelude.length?
18:59:15 <jack_rabbit> oh, yeah.
18:59:22 <jmcarthur> jack_rabbit: change the 100000000 into 100000000::Int for that line
18:59:45 <rwbarton> yeah I just noticed that, reading the core
18:59:47 <jmcarthur> jack_rabbit: go ahead and do it for the other lines too...
18:59:48 <jack_rabbit> for all of them, or just prelude's?
18:59:50 <jack_rabbit> okay.
18:59:57 <jmcarthur> jack_rabbit: it will help them all, but Prelude.length the most
19:00:13 <dolio> This is kind of a contrived example to be complaining about CSE. Unless GHC has started doing a lot more CSE recently.
19:00:17 <jack_rabbit> wow.
19:00:19 <jack_rabbit> no doubt.
19:00:28 <jack_rabbit> 0.8 vs. 0.06
19:00:37 <jack_rabbit> that's incredible. Why is that the case?
19:01:09 <jack_rabbit> We've gone from 11 seconds with one naive implementation to 0.06 with another.
19:01:12 <jmcarthur> dolio: i honestly think this is a perfect example against CSE. this is totally natural code to write when you know you don't want to share the list, yet ghc shares it anyway
19:01:55 <benzrf> whats CSE
19:01:56 <dolio> It's not natural to want to compute the length of a statically known list.
19:01:57 <Lutin`> It sounds like CSE would destroy the memory benefits of fusion by saving the list to share on the second two calls
19:02:01 <jmcarthur> jack_rabbit: i actually now think it's probably fusing the Prelude.length with the Prelude.enumFromTo
19:02:06 <jack_rabbit> heh. It also nearly blew my memory by sharing that list.
19:02:30 <dolio> If I had to guess, I'd say that the fact that the lists can be constant floated to the top level is a factor in them getting shared.
19:02:30 <rwbarton> sure but you might want to compute the length of filter p of a statically known list for some p, and now you have the same problem
19:02:32 <jmcarthur> dolio: it's not crazy to want to fold over some sequence repeatedly
19:02:50 <rwbarton> you do it for two different p and then oops
19:03:50 <jmcarthur> benzrf: CSE = Common Subexpression Elimination
19:04:00 <jack_rabbit> It's a little concerning that without the -fno-cse the combination consumed like 6 GiB of RAM
19:04:11 <jmcarthur> benzrf: transform    ... f x ... f x ...   into   let y = f x in ... y ... y ...
19:04:32 <jack_rabbit> When it shouldn't have (as far as I knew) because of the strict evaluation
19:04:44 <jmcarthur> jack_rabbit: that memory was the list
19:04:53 <jack_rabbit> right, I know that.
19:04:54 <jmcarthur> jack_rabbit: without CSE it generates and destroys the list at the same time
19:05:00 <jmcarthur> ah
19:05:00 <jack_rabbit> right, I understand.
19:05:26 <jmcarthur> what confused me is that it only happened when i uncommented your unboxed implementation
19:05:26 <jack_rabbit> But I would have been utterly confused if I hadn't had this conversation, if I'd tried this experiment on my own.
19:05:36 <jmcarthur> with just Prelude.length and your boxed length, it was fine
19:05:44 <jack_rabbit> I'm guessing the compiler isn't smart enough to fuse the fold.
19:05:56 <jack_rabbit> but it can fuse my two recursive functions.
19:06:06 <jack_rabbit> oh, wait.
19:06:08 <jack_rabbit> that's not right...
19:06:12 <jmcarthur> jack_rabbit: it can fuse foldr. not sure about foldl.
19:06:24 <Lutin`> jmcarthur: What are your timing results after -fno-cse
19:06:24 <rwbarton> the compiler isn't smart enough to fuse anything; the fusion rules are specified by the standard library
19:06:30 <jmcarthur> jack_rabbit: and no, it won't fuse your functions
19:06:30 <jack_rabbit> Yeah, but my foldl implementation isn't being executed.
19:06:49 <parc> is there any difference between traverse/mapM and sequence/sequenceA except for the class constraint?
19:07:09 <dolio> parc: The names. :)
19:07:13 <jmcarthur> Lutin`: with fno-cse and the ::Int annotations, they are   0.893, 0.893, and 0.137
19:07:14 <jack_rabbit> rwbarton, good to know, but sort of a distinction without a difference here.
19:07:33 <rwbarton> well, it means since you didn't write any rules for your functions, there is no fusion happening there
19:07:45 <johnw> dolio: can I perhaps interest you further in a proving problem? ;)
19:07:50 <jack_rabbit> rwbarton, ahh. I stand corrected. :)
19:07:52 <Lutin`> jmcarthur: Last is prelude?
19:07:55 <dolio> Maybe.
19:08:01 <johnw> dolio: how may I entice thee?
19:08:03 <jmcarthur> parc: mapM can be specialized to be tail recursive. sequence cannot.
19:08:14 <jmcarthur> Lutin`: right
19:08:25 <jmcarthur> parc: not by the compiler, mind you. by hand.
19:08:32 <jack_rabbit> rwbarton, so how would I write a fusion rule for my functions?
19:08:39 <jmcarthur> parc: i said that wrong
19:08:46 <rwbarton> I still don't understand why your length is faster for the Integer list
19:08:51 <jmcarthur> parc: mapM can be specialized to be tail recursive. traverse cannot.
19:09:12 <johnw> dolio: I've dumped a few more hours into it, but still no joy
19:09:15 <jack_rabbit> rwbarton, *MY* length isn't faster for the explicitly ::Int list.
19:09:26 <jack_rabbit> rwbarton, mine *IS* faster without the type notation.
19:09:48 <johnw> as a bonus, I'd like to prove the monoidal formulation of the applicative laws in terms of the regular <*> versions, and that is proven likewise difficult, for perhaps similar reasons
19:10:02 <rwbarton> right, the default is Integer
19:10:05 <parc> jmcarthur: so the fact that there are different functions here isn't related to the Applicative/Monad historical lack-of-a-class-constraint deal?
19:10:48 <jmcarthur> parc: no, i think it is also related to that. but the different types do lend themselves to, perhaps, different implementations, even if the semantics must match in the end
19:11:25 <jack_rabbit> What I'm most confused about is why the ::Int type notation improved efficiency so much.
19:11:36 <jack_rabbit> Shouldn't the compiler be able to infer that?
19:11:40 <Lutin`> Maybe yours is being inlined?
19:11:43 <jmcarthur> jack_rabbit: it inferred Integer, not Int
19:11:49 <jack_rabbit> ahh.
19:11:52 <jmcarthur> jack_rabbit: compile with warnings to see
19:11:57 <jack_rabbit> And Integer is more costly...
19:13:09 <jack_rabbit> heh. Weird type, Int. "At least 30 bits"
19:13:28 <jmcarthur> jack_rabbit: in ghc, Int is just natively sized
19:13:41 <jmcarthur> jack_rabbit: but the spec allows for other representations, obviously
19:13:45 <jack_rabbit> jmcarthur, no doubt. It's just strange the standard chose 30 bits.
19:14:03 <johnw> I believe Lisp machines back in the day used 30 bit integers, didn't they?
19:14:03 <jmcarthur> jack_rabbit: it's so an implementation can choose to use some bits for various sorts of tagging, such as for the gc
19:14:11 <jack_rabbit> rather than 16 or 32. I'm unfamiliar with any platform with a 30-bit bus or register.
19:14:16 <jmcarthur> ocaml uses 31/63 integers
19:14:17 <jack_rabbit> ahh.
19:14:19 <jmcarthur> many languages do this
19:14:25 <jack_rabbit> that makes sense.
19:14:41 <Lutin`> jack_rabbit: Try adding {-# NOINLINE [1] counter #-} and {-# NOINLINE [1] counter_unboxed #-}
19:14:49 <Lutin`> I don't think that would be it but...
19:14:55 <jmcarthur> Lutin`: why?
19:15:07 <Lutin`> Because prelude does that on the list
19:15:11 <Lutin`> on the length*
19:15:19 <jack_rabbit> Lutin`, should I keep the -fno-cse ?
19:15:27 <Lutin`> Yeah
19:15:38 <jmcarthur> i don't think this will do anything interesting.
19:15:40 <Lutin`> Eh that would only explain a constant difference
19:15:42 <Lutin`> Yeah
19:16:13 <Lutin`> It must be something to do with the foldr rule
19:16:36 <jack_rabbit> Lutin`, module ‘main:Main’ is defined in multiple files
19:16:51 <jack_rabbit> Lutin`, don't know what that's about.
19:17:17 <rwbarton> yeah I am looking at the core, with Prelude.length it does fuse but into a loop that uses a boxed accumulator
19:17:40 <jmcarthur> gross!
19:18:02 <rwbarton> or maybe I'm reading this wrong, hang on
19:18:41 <rwbarton> oh this is the weirdest thing
19:19:41 <rwbarton> http://lpaste.net/106829
19:19:55 <jack_rabbit> the GHC devs will probably be laughing just about now. :)
19:20:02 <jmcarthur> rwbarton: yeah i am confused too
19:20:08 <jmcarthur> GHC.Types.True -> GHC.Types.I#
19:20:10 <jmcarthur> wtf
19:20:18 <rwbarton> yeah it's arity 1!
19:20:40 <jack_rabbit> rwbarton, where did you get that?
19:20:48 <rwbarton> I build with -ddump-simpl
19:20:51 <rwbarton> *built
19:20:57 <jack_rabbit> weird...
19:22:08 <jack_rabbit> This is the only thing I *don't* like about using higher level languages. With C, even if it's implementation specific, you basically know exactly what's happening.
19:22:25 <jack_rabbit> With higher-level languages, you get these nice surprises every once in a while.
19:22:36 <jmcarthur> rwbarton: it's been eta reduced...
19:23:42 <jmcarthur> wait
19:24:04 <jmcarthur> wow
19:24:23 <rwbarton> it's not surprising it's slower since it has to go through stg_ap_n_fast every iteration
19:24:30 <jmcarthur> this is just amazing
19:24:32 <rwbarton> because of this eta reduction
19:24:35 <rwbarton> yes
19:25:09 <jmcarthur> jack_rabbit: congrats. your simple benchmark seems to have uncovered very surprising behavior
19:25:27 <Lutin`> I forget what @ means in Core
19:25:39 <rwbarton> is this related to that call arity stuff?
19:25:44 <rwbarton> @ is for type arguments
19:25:54 <jack_rabbit> crap. I might be going dow.
19:26:00 <jack_rabbit> swap almost full.
19:26:04 <jack_rabbit> Can't kill...
19:26:18 <MP2E> Would the new call arity analysis pass in HEAD help with this, do you think?
19:26:18 <jmcarthur> jack_rabbit: kill -9!
19:26:21 <MP2E> ^^
19:26:26 <jmcarthur> MP2E: it might be the cause, even
19:26:31 <jmcarthur> oh not the cause
19:26:31 <MP2E> ahhh o.O
19:26:34 <jmcarthur> i'm not using HEAD
19:26:35 <rwbarton> yeah i'm thinking one or the other :P
19:26:42 <rwbarton> is it new in HEAD or 7.8? i forget
19:26:49 <MP2E> new in HEAD :)
19:26:52 <jmcarthur> i was thinking not 7.8
19:26:56 * rwbarton tries head
19:27:20 <jmcarthur> i don't have a remotely recent HEAD right now, so i eagerly await your results
19:27:41 <rwbarton> it's twice as fast
19:27:52 <jmcarthur> sweet
19:28:07 <MP2E> ! :D
19:28:16 <jack_rabbit> wow.
19:28:23 <jack_rabbit> That was unbelievable.
19:28:46 <jack_rabbit> Somehow the process stopped allocating right before filling swap, and I was able to kill -9 the process.
19:28:51 <MP2E> whew
19:28:54 <MP2E> that's good!
19:28:59 <jack_rabbit> Ctrl+C didn't work.
19:29:02 <MP2E> I've had Linux completely crash on me from GHC eating all of the memory before
19:29:14 <jack_rabbit> Luckily I had a spare bash shell open to pkill -9 Counters
19:29:17 <jmcarthur> i don't use swap anymore. i just let the oom killer do its magic
19:29:54 <jack_rabbit> heh. Does OOM do anything smarter in recent versions than shooting random processes in the head?
19:30:13 <jmcarthur> jack_rabbit: it seems to have been much smarter for me recently. i don't know what changed, but i'm usually happy with what it chooses
19:30:32 <jack_rabbit> for a while it was totally random, from what I've heard.
19:30:35 <jmcarthur> yeah
19:30:39 <jack_rabbit> Luckily I've never run up against it yet.
19:30:44 <jmcarthur> it might still be. i could just have been lucky
19:30:48 <jack_rabbit> I just got really frick'n close, though. :)
19:31:11 <jmcarthur> i still think shooting some random processes down is more pleasant than having to resort to hardware reset
19:31:32 <jmcarthur> or at least has a nonzero chance of being more pleasant
19:31:37 <jack_rabbit> surely.
19:31:54 <jack_rabbit> It'd be nice if there were an API for specifying the importance of processes, though.
19:32:09 <jmcarthur> jack_rabbit: anyway, we found out why Prelude.length is slower for [Integer]...
19:32:21 <jack_rabbit> jmcarthur, recap for me, if you would...
19:33:04 <l0cust>  /j #zsh
19:33:14 <l0cust> god dammit
19:33:15 <jack_rabbit> heh.
19:34:17 <jmcarthur> jack_rabbit: ghc is doing something bad. it eta reduces the inner loop, so on each iteration it's doing a closure allocation and taking the slow path for function application.
19:34:25 <jmcarthur> jack_rabbit: i'm actually amazed it's as fast as it is...
19:34:47 <jack_rabbit> :) I suppose we might thank Intel.
19:34:58 <rwbarton> yeah I was going to say, the wonders of branch prediction
19:35:04 <jack_rabbit> no doubt.
19:35:18 <jmcarthur> i think the cheap allocator is also a big factor in this
19:35:26 <jmcarthur> wait
19:35:28 <jmcarthur> it can't be
19:36:35 <jack_rabbit> hmm. So the thing that ate all my ram was a function that returned an [Int]
19:37:17 <jack_rabbit> or, at least, I replaced [1..1000000000] with produce_list :: [Int] \n produce_list = [1..100000000]
19:37:18 <jmcarthur> no i was right. that allocations are so cheap is probably a big deal here after all.
19:37:39 <jmcarthur> jack_rabbit: you basically just did what cse was doing before you disabled it
19:37:45 <jack_rabbit> hmm.
19:37:54 <jack_rabbit> But before the CSE didn't eat *all* my ram
19:38:11 <jack_rabbit> in fact, it didn't even eat all my physical RAM, much less all my RAM + swap.
19:38:11 <jmcarthur> maybe you were lucky? it was eating mine
19:38:44 <davean1> jack_rabbit: http://linux-mm.org/OOM_Killer it was never random, but it would target user process on a desktop frequently
19:38:45 <jack_rabbit> Well it ate around 7 GiB, but not the 11 Gib it just ate with that produce_list function.
19:39:07 <jack_rabbit> davean1, good to know. I'll bookmark that and read it later.
19:39:46 <jmcarthur> jack_rabbit: btw      +RTS -M4g
19:40:00 <jmcarthur> jack_rabbit: sets the maximum heap size the runtime will grow to
19:40:01 <jack_rabbit> I can't parse that. :/
19:40:04 <jack_rabbit> ahh.
19:40:11 <jack_rabbit> That's useful.
19:40:12 <jmcarthur> jack_rabbit: ./MyHaskellProgram +RTS -M4g
19:40:19 <jmcarthur> jack_rabbit: in this case, 4g, but you can adjust of course
19:40:36 <jmcarthur> jack_rabbit: +RTS --help for more fun
19:40:52 <benzrf> i heared that using RTS options on setuid binaries can be for hax
19:41:12 <jmcarthur> benzrf: the RTS options are more limited on more recent versions of ghc
19:41:22 <jmcarthur> benzrf: you have to pass -rtsopts to the compiler to get full functionality
19:41:46 <MP2E> you GNU/Hurd wrong *badumtiss*
19:41:50 <MP2E> *oh god what is wrong with me*
19:42:24 <benzrf> MP2E: :O)
19:42:30 <jack_rabbit> jmcarthur, yeah, I just ran up against that.
19:42:41 <jack_rabbit> jmcarthur, just compiled with -rtsopts, and it seems to be working.
19:42:53 <benzrf> why does ghc use x-style flags :(
19:42:57 <benzrf> thats the worst kind of flags
19:43:20 <jmcarthur> x-style?
19:43:25 <benzrf> --foo vs -fo
19:43:28 <benzrf> * -foo
19:43:30 <jack_rabbit> heh, although, with the produce_list function, it's taking an absurd amount of time.
19:43:33 <jack_rabbit> why is that?
19:43:44 <benzrf> -multilettersafteronedash should be switch clusters dammit!!
19:44:07 <jmcarthur> jack_rabbit: you're still using that? it's the same as when you used cse
19:44:14 <jack_rabbit> It can't be.
19:44:23 <jmcarthur> jack_rabbit: except now you're not allowing ghc to grow the heap, so it's churning the gc a lot more, too
19:44:23 <jack_rabbit> It's *much* slower, and using much more ram.
19:44:24 <benzrf> jack_rabbit: search your feelings
19:44:26 <benzrf> you know it to be true
19:44:31 <MP2E> hahaha
19:44:33 <jack_rabbit> XD
19:44:46 <jack_rabbit> THAT'S IMPOSSIBLE!
19:44:46 <rwbarton> didn't you switch from 100 million to 1 billion at some point?
19:44:54 <jack_rabbit> rwbarton, yeah.
19:45:04 <jmcarthur> that'd do it too
19:45:21 <jmcarthur> at 100_000_000 i nearly ran out of memory (would have if i hadn't caught it)
19:45:21 <jack_rabbit> My confusion, I guess, is *why* a function that returns a list is different from a list literal.
19:45:39 <jmcarthur> jack_rabbit: that's not even a function, is it?
19:45:56 <jack_rabbit> what do you mean?
19:46:02 <jmcarthur> jack_rabbit: it's just a list
19:46:07 <jack_rabbit>  produce_list :: [Int] \n produce_list = [1..100000000]
19:46:15 <jmcarthur> jack_rabbit: you just defined a list, not a function
19:46:28 <jmcarthur> jack_rabbit: so it's the same list in memory everywhere you use it
19:46:30 <jack_rabbit> it's a constant, or whatever.
19:46:37 <jack_rabbit> ahh, I see.
19:46:41 <jmcarthur> jack_rabbit: and this is not the same as three separate lists
19:46:44 <jack_rabbit> right.
19:46:46 <jmcarthur> again, this is what cse was doing
19:47:19 <jack_rabbit> But I thought these were immutable and separate. Shouldn't produce_list return a *new* list lazily each time?
19:47:21 <rwbarton> CSE is good for small, expensive values but bad for large, cheap values
19:47:28 <jmcarthur> jack_rabbit: each time what?
19:47:35 <jack_rabbit> each time it's invoked
19:47:36 <jmcarthur> jack_rabbit: it's not a function
19:47:43 <jack_rabbit> what's the difference?
19:47:51 <jack_rabbit> It's defined the same way a function is.
19:47:53 <toki78> Hi my freinds
19:48:00 <jmcarthur> jack_rabbit: if you said   let x = 5 + 5 in x * x   would you expect 5+5 to be evaluated twice?
19:48:06 <toki78> have you ever heared of disco chess ?
19:48:17 <jack_rabbit> jmcarthur, no.
19:48:18 <toki78> its off topic
19:48:22 <jmcarthur> jack_rabbit: same thing here
19:48:24 <jack_rabbit> jmcarthur, I guess that makes sense.
19:48:36 <jack_rabbit> jmcarthur, hmm...
19:48:42 <benzrf> toki78: >>>#haskell-blah
19:48:48 <rwbarton> if produce_list was a list of say three elements that each took a long time to compute you'd be asking "why is GHC recomputing my values? it's immutable, shouldn't it only need to calculate it once?"
19:48:58 <jack_rabbit> jmcarthur, I guess I just have to get used to this environment. It's a little strange.
19:49:01 <toki78> benzrf, thx !
19:49:43 <jack_rabbit> heh. poor ol' haskell just gave up evenutally.
19:49:49 <jmcarthur> jack_rabbit: you will be glad to hear that ghc HEAD fixes that weird behavior with Prelude.length, btw
19:49:56 <jack_rabbit> Counts: Heap exhausted;
19:49:56 <jack_rabbit> Current maximum heap size is 4294967296 bytes (4096 MB);
19:50:11 <jmcarthur> jack_rabbit: beats the oom killer or swap hell :)
19:50:16 <jack_rabbit> no doubt.
19:50:23 <jack_rabbit> I thought I was going to have to cold-boot this sucker.
19:50:33 <jack_rabbit> What is ghc HEAD, btw?
19:50:41 <jmcarthur> jack_rabbit: dev version of ghc
19:50:43 <MP2E> jack_rabbit : the very latest GHC development code from the git repository
19:50:47 <MP2E> master  branch
19:50:54 <jack_rabbit> oh, git HEAD
19:50:59 <jack_rabbit> that makes sense.
19:52:43 <jack_rabbit> Thanks so much, you guys. I've been more pleased with this channel regularly than with any other channel on Freenode.
19:52:50 <jmcarthur> :D
19:52:58 <jmcarthur> @botsnack
19:52:58 <lambdabot> :)
19:53:01 <jack_rabbit> Seriously, if Haskell has one thing going for it, it's the community.
19:53:14 <jack_rabbit> (and it doesn't just have *one* thing going for it)
19:53:22 <jle`> hm. looking to figure out how i can do this in a typesafe way
19:53:23 <benzrf> jack_rabbit: heck yes
19:53:37 <Lutin`> jle`: Do what?
19:53:43 <jle`> typing it out, heh
19:53:54 <Lutin`> jmcarthur: Maybe CSE could happen in a later stage, after fusion?
19:54:47 <jmcarthur> Lutin`: maybe. i'm just generally displeased with it. maybe it's something that usually i just don't notice, but it's certainly not something i rely on for my programs to be fast, and i only ever notice it when it bites me
19:55:54 <Lutin`> Because it seems as though all three ended up fusing out the list, so what's the point in saving it anyways?
19:55:55 <rwbarton> that would help here, but not in general
19:56:06 <rwbarton> or rather
19:56:09 <Lutin`> rwbarton: Yeah that's why I said easier said than done
19:56:19 <Lutin`> Oh wait i didn't say that, just thought it
19:56:24 <MP2E> lol
19:56:38 <rwbarton> it would probably not hurt
19:56:44 <MP2E> Again I raise the question, though, do you think that Call Arity Analysis might have an impact on the usefulness of CSE output?
19:56:47 <rwbarton> compared to the current system
19:57:02 <MP2E> Because maybe it's more CSE combined with incorrectly eta reduced code or something
19:57:14 <jmcarthur> i don't actually know that much about the new call arity analysis stuff
19:57:29 <jmcarthur> MP2E: the eta reduction and CSE thing were separate issues, here
19:57:33 <MP2E> Ahh
19:57:59 <jmcarthur> MP2E: turning off CSE made it work at all. then we were able to see the eta reduction issue.
19:58:31 <rwbarton> even if you forget about fusion, call arity analysis, bizarre eta reduction and everything, you still have the potential for space leaks due to CSE
19:59:17 <rwbarton> (I'm guessing/hoping the eta reduction was due to an overly clever RULE)
19:59:20 <jmcarthur> or the full laziness transform, to a lesser extent
19:59:30 <Lutin`> rwbarton: It was
19:59:36 <rwbarton> do you know which one?
20:00:12 <jmcarthur> {-# RULES "eta reduce" forall f. \x -> f x = f #-}
20:00:14 <Lutin`> I believe these two
20:00:15 <jmcarthur> :)
20:00:17 <Lutin`> "length"     [~1] forall xs. length xs = foldr incLen I# xs 0#
20:00:19 <Lutin`> "lengthList" [1]  foldr incLen I# = lenAcc
20:00:21 <extraplanetary> http://lpaste.net/106821 - I am very puzzled why it can't unify (Maybe Value) with (f a), especially when the error suggests it's already deduced Maybe ~ f
20:00:23 <rwbarton> the issue with the full laziness transform is that it is often genuinely useful
20:00:33 <jmcarthur> rwbarton: yeah, i mostly *like* it
20:00:45 <rwbarton> I've been meaning to implement -fsome-laziness some day
20:00:52 <jmcarthur> heh
20:00:56 <Lutin`> Where incLen :: a -> (Int# -> Int) -> Int# -> Int
20:01:00 <jmcarthur> ghc's full laziness actually isn't full laziness anyway
20:01:02 <rwbarton> that does the no-brainer instances of the full laziness transform
20:01:20 <rwbarton> like floating out a manifest function to top level
20:01:31 <rwbarton> (when it doesn't depend on variables in scope)
20:01:37 <Lutin`> removing those rules fixed the eta reduction issue
20:01:37 <jmcarthur> isn't that just lambda lifting?
20:01:47 <zzing> I am in need of a database api, and I was wondering what my options are. I am using a relational model, and would take anything that allows me to do relational algebra, relational calculus, or SQL (with prepared statements?).
20:02:09 <rwbarton> the ghc source code uses the terms interchangeably as far as I can tell
20:02:16 <jmcarthur> huh
20:02:22 <jmcarthur> they aren't the same though!
20:02:23 <Lutin`> zzing: These should be up to date http://www.haskell.org/haskellwiki/Applications_and_libraries/Database_interfaces
20:02:31 <rwbarton> any time it floats a computation out of a lambda binding a variable on which it does not depend
20:02:32 <zzing> meric
20:02:34 <rwbarton> what is the difference?
20:02:36 <zzing> merci*
20:02:49 <rwbarton> oh
20:02:53 <rwbarton> I don't mean lambda lifting
20:03:00 <rwbarton> well, sort of a trivial case where there is no lifted variable
20:03:29 <rwbarton> I mean exactly a case like   length xs = go xs 0 where go [] acc = acc; go (_:ys) acc = go ys $! (acc+1)
20:03:36 <rwbarton> floating go to toplevel
20:03:55 <jmcarthur> rwbarton: i might be taking to an extreme something i read once, really. http://research.microsoft.com/apps/pubs/default.aspx?id=67037   "We show that, on the contrary, full laziness can be regarded as a completely separate process to lambda lifting, thus making it easy to use different lambda lifters following a full-laziness transformation, or to use the full-laziness transformation in compilers which do
20:03:57 <jmcarthur> not require lambda lifting."
20:04:01 <rwbarton> lambda lifting is when you add an auxiliary argument right?
20:04:18 <jmcarthur> yes
20:04:28 <jmcarthur> okay, so you don't mean that
20:05:13 <jmcarthur> lambda lifting basically turns what would have been a closure into a supercombinator
20:05:26 <Lutin`> lambda lifting would turn go into an argument of length?
20:05:57 <rwbarton> it would turn xs into an argument of go
20:06:09 <Lutin`> Ah that makes sense
20:06:36 <rwbarton> but here go doesn't refer to xs of course
20:06:41 <jack_rabbit> Okay, so thinking about all this, I've heard someone use the phrase "a good argument against CSE."
20:07:15 <jack_rabbit> It seems like automatic CSE can cause some unexpected results. Was there a discussion at one point about whether or not to enable CSE by default?
20:07:35 <Aurelia21>  You can find funny videos here. http://bitly.com/1o3kUXN
20:07:53 <jmcarthur> jack_rabbit: there have been numerous such discussions
20:08:09 <jmcarthur> jack_rabbit: notably, i think it's not turned on for -O
20:08:32 <jack_rabbit> jmcarthur, that should go without saying. I would hope *no* optimizations would be on for -O
20:08:38 <jmcarthur> jack_rabbit: many people say -O2 is just not dangerous optimizations, but i disagree with that. i think -O is that
20:08:43 <jmcarthur> jack_rabbit: -O is -O1, not -O0
20:08:54 <jack_rabbit> oh, I see.
20:09:31 <jmcarthur> (i still use -O2 most of the time though)
20:09:44 <jack_rabbit> I think this example is probably a corner-case, but still...
20:10:03 <jack_rabbit> Ot
20:10:04 <MP2E> I like '-O2 -fllvm -funbox-strict-fields' until GHC starts to get RAM happy :)
20:10:05 <jack_rabbit> Ot
20:10:08 <jmcarthur> it's certainly not common for CSE to hurt quite this much
20:10:09 <jack_rabbit> argh!
20:10:18 <jack_rabbit> It's interesting, nonetheless.
20:10:25 <zzing> I notice the haskelldb-hsql packages haven't been updated since 2012, can anyone give me an idea if these work or not presently (I am on ghc 7.8.2) - or if I should even go in this direction.
20:10:37 <jmcarthur> MP2E: there's a safer, less aggressive alternative to -funbox-strict-fields now, at least
20:10:52 <MP2E> I didn't know that, what is it?
20:11:06 <platz> I thought GHC automatically unpacked all 'small' fields as of 7.8.2
20:11:08 <jmcarthur> h/o lemme find it. don't even remember if it's on by default or not
20:11:12 <jmcarthur> what platz said
20:11:15 <jack_rabbit> is -funbox-strict-fields unsafe?
20:11:15 <MP2E> ahh
20:11:26 <MP2E> neat :)
20:11:30 <jmcarthur> jack_rabbit: not unsafe, but... can still result in surprising behavior
20:11:33 <MP2E> glad to know that GHC isn't just leaving everything boxed
20:11:33 <Cale> jack_rabbit: No, but it's not always good for performance
20:11:46 <Lutin`> Looks like SPJ pointed out this issue with CSE 3 years ago
20:11:52 <jack_rabbit> okay, so here's a question.
20:11:54 <MP2E> Lutin`: ouch :(
20:12:12 <jack_rabbit> my produce_list function was a list definition, rather than a function that returned a list.
20:12:14 <jmcarthur> CSE can also result in algorithmic improvements :)
20:12:17 <Lutin`> This was before it was implemented though
20:12:22 <Lutin`> https://ghc.haskell.org/trac/ghc/ticket/701#comment:11
20:12:38 <jack_rabbit> How do I write a function that returns a *new* list each time, so that the code will behave as if I'd used a list literal?
20:12:44 <Cale> jack_rabbit: By which you mean that it was not a function at all
20:12:53 <rwbarton> Lutin`: yeah so specifically it was the rule "length"     [~1] forall xs. length xs = foldr incLen I# xs 0#
20:12:54 <jack_rabbit> Cale, indeed.
20:12:57 <rwbarton> followed by "fold/build"    forall k z (g::forall b. (a->b->b) -> b -> b) . foldr k z (build g) = g k z
20:13:03 <Cale> jack_rabbit: What do you mean by a new list?
20:13:28 <jack_rabbit> Cale, I mean anything that will behave as if I'd passed a list literal in place of the function call.
20:13:33 <Cale> jack_rabbit: If you define a constant, it will always be the same.
20:13:40 <jmcarthur> jack_rabbit: {-# INLINE thingYouWantInlinedAtAllCallSites #-}
20:13:56 <jack_rabbit> jmcarthur, is that really the easiest way?
20:14:02 <Lutin`> rwbarton: Ah, interesting
20:14:21 <rwbarton> Lutin`: now g (whatever it actually ends up being) is passed this weird higher-order stuff
20:14:22 <jack_rabbit> I would think there would be something more elegant than that. Although, I guess we are talking about some kind of extreme corner-case here.
20:14:27 <jmcarthur> jack_rabbit: you could also make it a function, but then you have to make sure it doesn't float out the constant
20:14:31 <Cale> jack_rabbit: I'm not exactly sure what you're looking for...
20:14:34 <hdgarrood> jack_rabbit: why do you want to do that?
20:14:48 <Cale> How are you expecting the program to behave differently?
20:15:01 <jmcarthur> Cale: you must not have been following earlier conversation
20:15:07 <jack_rabbit> I'm just confused. If you look at the code I posted, with the list literals, the runtime is extremely small, and uses almost no memory.
20:15:21 <jmcarthur> Cale: this is a huge list that he'd rather fuse into multiple loops than be shared
20:15:31 <jack_rabbit> With a list definition produce_list = [1..100000000], the memory is unmanageable.
20:15:40 <Cale> Oh, okay, so this is about avoiding sharing
20:15:49 <jmcarthur> right
20:16:01 <rwbarton> in general avoiding sharing is hard
20:16:52 <rwbarton> which is another argument against CSE by default, it's easier to explicitly introduce sharing (though you still have to watch out for inlining)
20:17:20 <jack_rabbit> So with -O, my program shouldn't blow up?
20:17:22 <jmcarthur> yeah, but at least NOINLINE is a thing
20:17:35 <jmcarthur> there is no NOCSE pragme other than for the whole module
20:17:38 <jmcarthur> *pragma
20:17:44 <jmcarthur> jack_rabbit: if i
20:17:47 <freakhill> hello, i'm slowly studying haskell by experimentation and i would like to ask why this doesnt work:
20:17:53 <rwbarton> right
20:17:55 <jmcarthur> jack_rabbit: if i'm right about it not including cse
20:17:58 <Cale> you could use  produceList x = [1..100000000]
20:18:02 <jack_rabbit> jmcarthur, I see.
20:18:06 <jmcarthur> jack_rabbit: and if you don't factor out the list like that
20:18:08 <freakhill> f :: Integral a => a -> a; f x = if x mod 2 == 0 then x else 0
20:18:14 <jack_rabbit> Cale, heh. Sort of silly.
20:18:16 <Cale> and apply  produceList ()  to get the list
20:18:36 <rwbarton> then you have to use -fno-full-laziness
20:18:37 <jmcarthur> Cale: works great until ghc decides to float the list out :(
20:18:40 <jmcarthur> yeah
20:18:48 <Cale> jmcarthur: Yeah, I was worried about that :)
20:19:18 <jack_rabbit> jmcarthur, doesn't work. Even with -fno-cse, it eats RAM.
20:19:22 <rwbarton> I thought about this problem for a while
20:19:25 <extraplanetary> freakhill: you want to write "x `mod` 2 == 0" there, the backticks are important
20:19:28 <jmcarthur> jack_rabbit: did you inline the list again?
20:19:28 <jack_rabbit> Cale, I'll try your method.
20:19:31 <hdgarrood> freakhill: what do you mean, doesn't work?
20:19:36 <jmcarthur> jack_rabbit: or are you still trying to factor it out?
20:19:37 <jack_rabbit> jmcarthur, what do you mean inline?
20:19:38 <freakhill> oh
20:19:44 <freakhill> backticks
20:19:47 <jmcarthur> jack_rabbit: i mean not define it as a separate value like you are at all
20:19:54 <jack_rabbit> jmcarthur, oh, yeah, I've got produce_list = [1..10000000] or whatever.
20:19:59 <freakhill> oh
20:20:00 <freakhill> thanks
20:20:03 <jmcarthur> jack_rabbit: cse is not the problem here because you are doing *exactly* what cse was doing before
20:20:03 <rwbarton> imagine you had a function depends :: a -> b -> b
20:20:04 <extraplanetary> freakhill: mod is just a normal function, which you usually use prefix. Enclosing a function in backticks makes it usable infix
20:20:15 <rwbarton> depends _ y = y but it's not inlined
20:20:19 <jack_rabbit> jmcarthur, ahh, so removing CSE doesn't work. I'll try Cale's method.
20:20:40 <rwbarton> then you could write produceList x = [1..depends x 100000000]
20:20:56 <jmcarthur> jack_rabbit: i think for cale's suggestion to work you might need to disable the full laziness transformation (this may not be enabled with -O, either, actually...)
20:21:19 <rwbarton> but ideally you could inline depends after the full laziness transform and then do further optimizations
20:21:21 <hdgarrood> freakhill: so for example x `mod` 2 is the same as mod x 2
20:21:36 <Lutin`> jmcarthur: cse is on by default, not just with an -O flag
20:21:42 <jack_rabbit> how do I inline?
20:21:46 <freakhill> thx! i though mod was infix by default, like +
20:21:49 <hdgarrood> does anyone know how to tell cabal to always use "--show-details=always" when testing?
20:21:55 <jmcarthur> Lutin`: ? you mean it's on even with -O0? that doesn't sound right
20:22:02 <jack_rabbit> it's not working when I apply produce_list to ()
20:22:05 <hdgarrood> freakhill: a function is infix by default if it's entirely symbols i think
20:22:12 <extraplanetary> freakhill: nope! Letter/number names are prefix. Symbol names are infix
20:22:27 <Lutin`> jmcarthur: Yep
20:22:28 * hackagebot http-streams 0.7.1.2 - An HTTP client using io-streams  http://hackage.haskell.org/package/http-streams-0.7.1.2 (AndrewCowie)
20:22:28 <jmcarthur> wow
20:22:28 <Lutin`> https://www.haskell.org/ghc/docs/7.8.2/html/users_guide/options-optimise.html#idp11716464
20:22:32 <jmcarthur> amazing
20:22:34 <jmcarthur> sad
20:22:50 <extraplanetary> freakhill: to turn a symbol name into a prefix name, wrap it in brackets (e.g., "(+) 2 3" is the same as "2 + 3"
20:22:51 <jmcarthur> one of the most magical optimizations in ghc, and it's on by default at -O0
20:22:58 <MP2E> hahaha
20:23:03 <MP2E> yeah I'm shocked as well
20:23:08 <jack_rabbit> heh. How do I disable it?
20:23:08 <MP2E> I thought O0 generated core and that was it :V
20:23:33 <Lutin`> -fno-cse
20:23:35 <carter> ghc --show-options
20:23:37 <jack_rabbit> That's odd. -O0 should do nothing but *exactly* what's expected.
20:23:38 <jmcarthur> jack_rabbit: -fno-full-laziness
20:23:39 <carter> and look for -fno-fooo
20:24:04 <Lutin`> Or just read that page I linked if you want to know more about what each flag means
20:24:07 <jmcarthur> jack_rabbit: cse might *also* bit you, so you probably also still need that disabled
20:24:15 <jmcarthur> jack_rabbit: this whole exercise is really saddening me :)
20:24:19 <MP2E> me too :(
20:24:29 <freakhill> extraplanetary: thx!
20:24:48 <MP2E> GHC, I thought you were better than this! *shakes fist* Maybe this is one for the bug tracker
20:24:56 <carter> idk
20:24:58 <jack_rabbit> jmcarthur, even with -fno-full-laziness, it's eating ram.
20:25:03 <Lutin`> Huh yeah, -ffull-laziness also increases sharing
20:25:04 <jmcarthur> jack_rabbit: lpaste?
20:25:04 <carter> jack_rabbit: what codes
20:25:10 <jack_rabbit> jmcarthur, hang on.
20:25:10 <Lutin`> jack_rabbit: Do -fno-cse too?
20:25:16 <benzrf> is there an emoji that describes the feeling i have when i have no gf
20:25:18 <jack_rabbit> Lutin`, yeah, it's in the code.
20:25:19 <benzrf> oops wrong channel
20:25:23 <carter> ghc is eating ram or the program you product?
20:25:23 <MP2E> benzrf: :MP2E:
20:25:28 <MP2E> I kid
20:25:42 <Lutin`> benzrf: :D
20:25:48 <benzrf> sadly i did not write that
20:25:50 <benzrf> it is a quoet
20:25:50 * Lutin` says this as a recently single man
20:26:11 <jmcarthur> how quickly we are derailed
20:26:29 <Lutin`> psh we're waiting for an lpaste
20:27:03 <jmcarthur> there's actually a -fdo-eta-reduction optimization? and it's on by default?
20:27:14 <jack_rabbit> Here's the paste: http://lpaste.net/106830
20:27:17 <carter> defautl is O1
20:27:22 <jmcarthur> oh!
20:27:24 <jmcarthur> duh
20:27:30 <jmcarthur> i forgot about that change
20:27:36 <jmcarthur> default used to be -O0
20:27:37 <jack_rabbit> Please forgive me if I'm doing something stupid. I'm still a haskell beginner, after all.
20:27:50 <carter> are you telling ghc -O0
20:27:53 <carter> or O
20:27:55 <carter> or O2
20:27:56 <Lutin`> carter: That's not what the ghc manual says
20:28:11 <jack_rabbit> I thought I tried -O0. The paste contains my latest compilation attempt.
20:28:15 <Lutin`> -O0 Means “turn off all optimisation”, reverting to the same settings as if no -O options had been specified.
20:28:26 <carter> i find that unlikely
20:28:33 <Lutin`> I'm just quoting the manual
20:28:43 <carter> its not turn off ALL the ops
20:28:45 <carter> then
20:28:59 <carter> lets assume default is O0.5
20:29:08 <carter> did you set -O0 explicitly
20:29:38 <jack_rabbit> I just did.
20:29:45 <carter> and what GHC version
20:29:52 <jack_rabbit> With -O0, the first takes 27 seconds.
20:29:59 <jack_rabbit> I'll paste the results, hang on.
20:30:25 <jack_rabbit> Here are the results: http://lpaste.net/106831
20:30:46 <jack_rabbit> Compiled with 'ghc -O0 -rtsopts -fno-full-laziness Counts.hs Primative.hs'
20:31:11 <carter> jack_rabbit: try makign the counter_foo stuff be   a -> IO b
20:31:12 <carter> instead of pure
20:31:15 <jack_rabbit> Again, here's the code: http://lpaste.net/106830
20:31:30 <jack_rabbit> carter, okay, hang on.
20:31:32 <carter> one issue when i've used criterion
20:31:51 <carter> whats the 01 and 02 times
20:31:52 <jack_rabbit> carter, that'll take time. I'm still an extreme newbie.
20:31:59 <carter> and are you doging -fforce-recomp
20:32:02 <carter> Doing
20:32:04 <carter> jack_rabbit: its ok
20:32:14 <carter> i'm talking through this all to help you learn how to explore
20:32:17 <jack_rabbit> carter, I'm not, but I removed all .o and .hi files.
20:32:29 <carter> do -fforce-recomp instead
20:32:30 <jack_rabbit> carter, that should force a complete recompile, no doubt.
20:32:31 <carter> easier
20:32:35 <jack_rabbit> indeed.
20:32:39 <jack_rabbit> I'll do that next time.
20:32:58 <carter> also -fllvm can change perf sometimes
20:33:04 <jack_rabbit> So what do I do for the IO types? Just return () at the end?
20:33:10 <jack_rabbit> carter^
20:33:26 <carter> sure
20:33:35 <zzing> If I have a cabal sandbox, is it possible to get ghc --make to use it?
20:33:57 <carter> i'd also suggest mark  them {-# NOINLINE fooo#-}
20:34:04 <carter> and then have the pure looking one internally
20:34:11 <carter> where  foo_pure x = blah
20:34:14 <jack_rabbit> carter, but then they don't print the results. Should I move the printf's into the counter_foo functions?
20:34:29 <carter> replace the $ with >>=
20:34:31 <MP2E> zzing : 'cabal exec $SHELL' in the sandbox folder, then use your ghc command as usual
20:34:33 <carter> :t (>>=)
20:34:34 <lambdabot> Monad m => m a -> (a -> m b) -> m b
20:34:47 <carter> i mean replace
20:34:52 <carter> $ with =<<
20:34:56 <carter> :t (=<<)
20:34:57 <lambdabot> Monad m => (a -> m b) -> m a -> m b
20:35:10 <carter> so don't return ()
20:35:13 <carter> return the answer
20:35:17 <jack_rabbit> This is getting over my head. :) I haven't touched haskell in more than a year. I can give it a shot, but it might take me a bit.
20:35:28 <zzing> that seems to work, thanks
20:35:33 <carter> jack_rabbit: soke
20:35:42 <carter> i'm just opining for your benefit
20:35:44 <Lutin`> carter: btw -O0 gives me the same performance as no -O flag
20:35:46 <carter> no horse in the race
20:35:50 <carter> ok
20:35:51 <Lutin`> And -O1 gives me better than both
20:35:52 <jmcarthur> carter: you're offering suggestions for small optimizations but he has a huge memory leak
20:35:56 <jack_rabbit> carter, I appreciate it.
20:35:57 <carter> oh
20:36:03 <carter> have you tried running profiling?
20:36:09 <jmcarthur> we know what it is
20:36:11 <jmcarthur> it's allocations
20:36:21 <jmcarthur> he's trying to stop it from sharing the huge list
20:36:37 <jmcarthur> bah. "it's allocations" was dumb to say :)
20:36:38 <carter> oh
20:36:53 <carter> jmcarthur: solution, mark the functions no INLINE
20:37:00 <jmcarthur> that's what i had said
20:37:01 <carter> and put the list in a function
20:37:04 <carter> oh
20:37:05 <carter> ok
20:37:07 <carter> yeah
20:37:07 <jmcarthur> :)
20:37:13 <jack_rabbit> I think I tried that, no
20:37:14 <jack_rabbit> ?
20:37:17 <jmcarthur> no
20:37:18 <carter> mkList :: Int -> [Int]
20:37:18 <jmcarthur> you didn't
20:37:26 <carter> {-#NOINLINE mkList #-}
20:37:38 <jack_rabbit> Is that it?
20:37:42 <carter> mkList x = [1..x]
20:37:47 <jmcarthur> oh, no, this is not what i had said
20:37:57 <carter> jmcarthur: that would work too
20:38:09 <jmcarthur> when it was just a list and not a function, i had said to force it to inline so it wouldn't be shared
20:38:11 <carter> if you used mkList in the different noINline functions
20:38:30 <jmcarthur> you're going the direction cale had pushed. turn it into a function. NOINLINE it. turn off full laziness.
20:38:59 <carter> i've had funnn bugs from too much sharing
20:39:06 <jmcarthur> i think the NOINLINE basically doesn't matter here, actually
20:39:17 <jmcarthur> unless the inlining would enable some CSE after, but we've disabled that too
20:39:34 <jack_rabbit> So what's the consensus here? Which should I do?
20:40:01 <carter> jmcarthur: i think mkList :: IO [Int] with a noInline woudl work too
20:40:06 <carter> erm
20:40:07 <carter> mebe
20:40:36 <jack_rabbit> error on import.
20:40:47 <jack_rabbit> ghc doesn't like the {-#NOINLINE mkList #-}
20:40:53 <carter> you have to define it
20:41:10 <jmcarthur> jack_rabbit: to be honest, this isn't taking gobs of memory for me, and it looks like it's inlining as i would hope and not being shared
20:41:14 <Hermit> I'm having troubles with TH. It's complaining about some type being un-promotable (wtf does that even mean). Is this a known gotcha? what could be the problem
20:41:25 <jack_rabbit> jmcarthur, paste?
20:41:42 <jmcarthur> jack_rabbit: it's just slower in this form than before you have factored out the list
20:42:00 <jmcarthur> jack_rabbit: pretty much just your code
20:42:23 <jack_rabbit> jmcarthur, mine's using an inexcusable amount of memory. Again, I'm relatively new to this runtime, so I might well be doing something stupid...
20:42:30 * hackagebot th-desugar 1.4.1 - Functions to desugar Template Haskell  http://hackage.haskell.org/package/th-desugar-1.4.1 (RichardEisenberg)
20:42:36 <jack_rabbit> but I don't see on initial inspection what's wrong with my code.
20:42:48 <jmcarthur> jack_rabbit: in fact, it's not even taking that long. i forgot you had increased the problem size by an order of magnitude
20:43:34 <jack_rabbit> Mine's at one to one billion.
20:43:39 <jack_rabbit> And my memory can't take it.
20:44:04 <jmcarthur> my memory isn't even growing
20:44:07 <jmcarthur> it's just a small constant
20:44:13 <jack_rabbit> With this post? http://lpaste.net/106830
20:44:15 <jmcarthur> yes
20:44:19 <jack_rabbit> :/
20:44:21 <jmcarthur> well, basically
20:44:36 <jmcarthur> i tweaked it so i could actually build it
20:44:37 <jack_rabbit> well I don't know what to say. Mine I have to kill -9 before it destroys my machine.
20:44:46 <jack_rabbit> how did you tweak it?
20:45:49 <jmcarthur> i just made it into one module instead of two, added {-# OPTIONS -fno-full-laziness #-} to the top so i don't have to pass it explicitly
20:46:03 <jack_rabbit> Oh, actually, with that code I posted, it runs.
20:46:15 <jack_rabbit> But yeah, it takes an insane amount of time.
20:46:19 <jack_rabbit> The time I posted.
20:46:26 <jack_rabbit> http://lpaste.net/106831
20:46:54 <jmcarthur> 44,312 bytes maximum residency
20:47:00 <jack_rabbit> Without -O0, though it break.s
20:47:03 <jack_rabbit> breaks*
20:47:17 <jmcarthur> jack_rabbit: well, i don't know about that 22 seconds thing, but the others seem fine
20:47:27 <jmcarthur> jack_rabbit: you did increase the problem size
20:47:28 <carter> jmcarthur: what GHC version
20:47:31 <carter> ghc --version
20:47:32 <jack_rabbit> I don't have a measurement, but my system monitor's memory usage graph didn't budge.
20:47:32 <jmcarthur> carter: i'm on 7.8
20:47:38 <jmcarthur> .2
20:47:47 <carter> and jack_rabbit ?
20:47:51 <jmcarthur> jack_rabbit: +RTS -s
20:47:58 <jack_rabbit> 7.8.2
20:48:07 <carter> what OS
20:48:14 <jack_rabbit> jmcarthur, hang on. Should that be without -O0?
20:48:17 <carter> you could just do a pure looping counter
20:48:27 <jmcarthur> jack_rabbit: i don't see any point in you using -O0...
20:48:35 <Lutin`> jmcarthur: What did you build with
20:48:42 <jack_rabbit> carter, Linux 3.14.4 Arch Linux
20:48:51 <jack_rabbit> jmcarthur, it makes a difference.
20:48:52 <jmcarthur> Lutin`: ghc -O BenchyThing -Wall -fforce-recomp -rtsopts
20:49:02 <Lutin`> ah okay -O
20:49:09 <jack_rabbit> jmcarthur, with -O0 it runs slowly without blowing up ram, with -O it explodes.
20:49:13 <jmcarthur> jack_rabbit: of course it does. i expect it to make it worse and/or remove whichever optimization is hurting
20:49:24 <jmcarthur> jack_rabbit: but pretty much nobody ever uses -O0
20:49:28 <jmcarthur> jack_rabbit: because it sucks
20:49:45 <Lutin`> As I said before -O0 just sets the optimzation flags back to default
20:50:14 <jle`> what do peole have against ViewPatterns
20:50:22 <jmcarthur> jack_rabbit: so those timings were with -O0? if so, they are great
20:50:35 <carter> jle`: try using them for a hwile
20:50:49 <carter> patttern synonyms are their generalization right?
20:50:51 <jmcarthur> ViewPatterns aren't so bad with PatternSynonyms at least
20:50:53 <jmcarthur> no
20:50:57 <jmcarthur> they harmonize well though
20:51:18 <carter> yeah
20:51:24 <jack_rabbit> actually, now regardless of -O* it doesn't use memory.
20:51:35 <jack_rabbit> what did I change?
20:51:35 <carter> what changed
20:51:37 <jmcarthur> i think you had some build issue
20:51:38 <jack_rabbit> :/
20:51:50 <jmcarthur> you weren't testing what you thought you were testing, or something
20:51:51 <jack_rabbit> I removed all .o and .hi each time...
20:52:01 <Lutin`> just use -fforce-recomp
20:52:02 <jmcarthur> what about the executable?
20:52:03 <jmcarthur> :)
20:52:14 <jle`> carter: all it does is save me an extra where clause, right?
20:52:51 <jack_rabbit> okay, so with the -fno-full-laziness the program runs.
20:53:00 <jack_rabbit> but it's still unforgivably slow.
20:53:14 <carter> jack_rabbit: are you using -fforce-recomp
20:53:16 <carter> or not
20:53:18 <carter> y/n
20:53:21 <carter> you need to do that
20:53:21 <jack_rabbit> n
20:53:24 <jack_rabbit> let me try
20:53:40 <carter> inclue that always in this tiny experiment
20:54:03 <jack_rabbit> Okay, still inforgivably slow.
20:54:11 <jack_rabbit> It's not done yet, but I can already tell.
20:54:43 <carter> jack_rabbit: try -O2
20:54:54 <jack_rabbit> I'll try, but I think that'll blow it up.
20:55:04 <jack_rabbit> I might get knocked out here. Hang on. :)
20:55:26 <carter> or just use
20:55:29 <carter> @hackage loops
20:55:30 <lambdabot> http://hackage.haskell.org/package/loops
20:55:31 <carter> or something
20:55:55 <jack_rabbit> Okay. No extreme memory usage. Down to 8 seconds from 27.
20:56:02 <jack_rabbit> That's with -O2
20:56:04 <carter> :)
20:56:06 <carter> yay
20:56:10 <MP2E> magic of -O2 <3
20:56:25 <jack_rabbit> heh. Hardly a win, considering we were at 0.06 seconds earlier. :)
20:56:27 <carter> try all the flags
20:56:35 <carter> jack_rabbit: rewrite with loops
20:56:38 <jack_rabbit> *ALL* the flags.
20:56:47 <MP2E> also use unboxed vectors for ultimate speed
20:56:48 <MP2E> hehe
20:56:55 <jack_rabbit> Maybe I should just use -funroll-loops
20:57:00 <jmcarthur> jack_rabbit: how slow are we talking here
20:57:05 <MP2E> I saw a 12x speed improvement on my prime number cruncher just by switching from List to Unboxed vectors
20:57:10 <jmcarthur> jack_rabbit: 8 seconds is sane
20:57:10 <jack_rabbit> jmcarthur, 8 seconds.
20:57:22 <carter> list for data is a bad pattern
20:57:23 <jmcarthur> jack_rabbit: that's 10 times more than it was taking with 100_000_000
20:57:24 <jack_rabbit> jmcarthur, compared to what we got earlier?
20:57:32 <carter> lists for single use control streams ... ok
20:58:00 <jack_rabbit> jmcarthur, OH!
20:58:10 <jack_rabbit> You're right. Before we were at one hundred million.
20:58:20 <MP2E> lol
20:58:23 <jack_rabbit> Okay, this is totally sane then.
20:58:26 <jack_rabbit> For a billion.
20:58:53 <jack_rabbit> Yeah, I just ran it for one hundred million and it's almost exactly the same.
20:58:59 <jack_rabbit> *as it was before*
20:59:25 <jack_rabbit> so the -fno-full-laziness really makes a difference.
20:59:32 <Lutin`> Still doesn't beat length ;)
20:59:52 <jack_rabbit> that's true.
20:59:55 <jack_rabbit> I wonder why.
21:00:09 <jack_rabbit> It does it the type is Integer, but not if it's Int.
21:00:37 <jmcarthur> the Integer change triggers the dumb eta reduction issue
21:00:49 <jmcarthur> i think with Int it's just fusing really well
21:01:01 <jmcarthur> it's fusing with Integer, too, but the other issue makes it worse
21:01:21 <Lutin`> Yeah length has some rules iwth it
21:01:59 <jmcarthur> anyway, it was fun breaking the compiler with you guys. time for bed now
21:02:24 <MP2E> night
21:02:28 <jack_rabbit> thanks, jmcarthur
21:02:35 <jack_rabbit> jmcarthur, you're one hell of a guy.
21:03:08 <jack_rabbit> Anyway, shouldn't it not be fusing, since I have {-# OPTIONS -fno-cse #-}
21:03:46 <jmcarthur> cse /= fusion :)
21:03:53 <jmcarthur> okay really bedtime gnite for real
21:03:57 <jack_rabbit> sensible.
21:04:04 <jack_rabbit> jmcarthur, g'night.
21:06:08 <jack_rabbit> So what determines fusion, then, if not the -fno-cse flag?
21:06:37 <MP2E> jack_rabbit: rewrite rules, which are implemented as compiler pragmas in the library next to the function they are associated with (typically at least)
21:07:03 <jle`> i love u haskell type system
21:07:10 <jle`> <3
21:07:28 <jfeltz> OT: my attempt at putting Functional Decomp. into the development lexicon (inspired by haskell): https://en.wikipedia.org/wiki/Functional_decomposition#Software_architecture
21:07:29 <jack_rabbit> okay. So this was the code I was looking at for the standard library's implementation of length: https://hackage.haskell.org/package/base-4.5.0.0/docs/src/GHC-List.html
21:07:32 <jack_rabbit> Is that right?
21:07:51 <jack_rabbit> I don't see anything funny there.
21:08:21 <MP2E> I don't see the rewrite rules there either
21:08:22 <MP2E> hmm
21:08:24 * MP2E looks
21:09:02 <MP2E> oh wait I see
21:09:19 <MP2E> jack_rabbit: the RULES for length were added in Base 4.7, we're looking at Base 4.5
21:09:29 <jack_rabbit> ahh.
21:09:42 <jack_rabbit> Can I just change the url? -.-
21:09:45 <MP2E> yep
21:09:53 <MP2E> just remove -4.5.0.0
21:09:57 <MP2E> hackage will find the latest for you
21:10:07 <jack_rabbit> ahh, yes.
21:10:26 <MP2E> neat little tip when googling hackage, because google loves to grab old versions of things
21:10:33 <jack_rabbit> There it is: "length"     [~1] forall xs. length xs = foldr incLen I# xs 0#
21:10:37 <MP2E> yep that's the one!
21:10:41 <jack_rabbit> ugh.
21:10:45 <jack_rabbit> This is so complex.
21:11:25 <jack_rabbit> thanks for the tip, btw.
21:11:27 <jack_rabbit> I'll use that.
21:11:42 <jack_rabbit> It's unfortunate...
21:12:01 <MP2E> jack_rabbit : it's actually not as bad as it looks :P I'm not sure what [~1] refers to, forall xs just means 'for every possible input xs' and it just replaces it with a right fold that uses an unboxed accumulator and index
21:12:15 <MP2E> the fusion magic actually then comes from CSE, I'm assuming
21:12:20 <MP2E> because it'll see more than one instance of foldr
21:12:20 <jack_rabbit> Is this really such an extreme corner-case?
21:12:48 <MP2E> Well, RULES aren't necessarily just for corner-cases. They are used pretty extensively in Vector, I'd say they are more like hand-guided optimizations :)
21:12:50 <jack_rabbit> That I can't write my own efficient implementation without all these pragmas and compiler-specific things?
21:13:09 <MP2E> you shouldn't need to as long as you use rules that *do* have these hand optimized structures
21:13:12 <MP2E> like vector
21:13:17 <MP2E> err use libraries*
21:13:17 <MP2E> not rules
21:13:41 <jack_rabbit> well... So are these pragmas standardized?
21:13:56 <jack_rabbit> That's one of the big problems with C...
21:14:22 <MP2E> No, they are just a GHC thing AFAIK :(
21:14:34 <MP2E> Other Haskell compilers probably hav something similar but I have no idea if they use the same syntax
21:14:52 <MP2E> I would guess that if they do have support for it they probably do use the same syntax
21:14:55 <MP2E> but that's just a guess
21:14:56 <jack_rabbit> Or do I really just have to leave it to some library to be efficient *AND* portable?
21:15:34 <jack_rabbit> It's unfortunate. It's no doubt not just a problem with Haskell if it is the case.
21:15:58 <jack_rabbit> Actually, every language I've found has this problem. It's just too bad we've not gotten past it.
21:16:18 <gcganley> are there any chatlogs for #haskell? i had a conversation with someone and i cant find his/her name after i installed gentoo
21:16:54 <johnw> see the topic
21:17:21 <extraplanetary> in practice, Haskell =~ what GHC does. Standardising pragmas across compilers depends on having other production-ready compilers
21:17:45 <jack_rabbit> extraplanetary, GHC is the go-to compiler, then?
21:18:04 <jack_rabbit> at least, it's the best maintained?
21:18:16 <extraplanetary> jack_rabbit: yes. The others are either bitrotted or research projects, more or less
21:18:24 <jack_rabbit> :/
21:18:28 <jack_rabbit> It's just too bad.
21:18:30 <nisstyre> extraplanetary: it would be nice if there were something like ANSI Haskell or something and lots of compiler choices
21:18:40 <MP2E> Yeah, I like to think that Haskell is a balance between an implementation defined language and a commitee defined language. The commitee grabs the things that are well liked and mature from the compiler extensions and makes them part of the 'core' and GHC keeps plugging along with language extension to test the waters for next time
21:19:06 <jack_rabbit> I enjoy using higher-level languages for their abstractions, but each time, I find myself rooting through compiler options and other nonsense.
21:19:07 <MP2E> we find things we like, we find things we don't, and stuff gets better. Albeit a bit slowly :)
21:19:20 <jack_rabbit> I end up wondering why I'm not just writing it in C.
21:19:34 <extraplanetary> there's Haskell 98, which -does- have several working implementations
21:19:37 <nisstyre> jack_rabbit: uh, you end up using tons of compiler flags with C
21:19:38 <dolio> Why do you do that?
21:19:41 <jack_rabbit> Granted, haskell is probably the best.
21:19:46 <jack_rabbit> Java is a nightmare.
21:19:48 <extraplanetary> the problem is that Haskell not-98 is so much nicer to work with
21:20:01 <nisstyre> jack_rabbit: see my current gcc command gcc -fPIC -c -DNDEBUG -O3 -m64 -std=c99 -pedantic -Wall -Wshadow -Wpointer-arith -Wcast-qual -Wstrict-prototypes -Wmissing-prototypes
21:20:02 <jack_rabbit> Clojure is okay, except it relies too heavily on Java.
21:20:08 <dolio> Did  you desperately need maximum performance for your computing the length of a 1 billion element list problem?
21:20:09 <jack_rabbit> And Scala compiles *SOOOO* slowly.
21:20:23 <extraplanetary> (I don't know what the practical compiler landscape is like for Haskell 2010, but that may be an option if you seriously care about multiple implementations.)
21:20:46 <jack_rabbit> nisstyre, I usually use -Wall -Wextra -Werror -std=c99 -pedantic
21:21:11 <johnw> they should have -Wcodereview
21:21:16 <jack_rabbit> heh.
21:21:17 <MP2E> hehe
21:21:46 <jack_rabbit> it says something about the C language that -pedantic is even a flag.
21:22:50 <nisstyre> johnw: -Wmalloc and -Wmemcpy would be useful
21:22:59 <johnw> -Wbuffer-overrun
21:22:59 <jack_rabbit> I don't actually know if there can exist a high-level language that does what you expect always efficiently.
21:23:10 <jack_rabbit> I've read some things that suggest there can't be.
21:23:19 <dfeuer> extraplanetary, even nhc98 has a good bit of stuff beyond Haskell 98, and it looks like it died in 2010.
21:23:27 <jack_rabbit> It seems similar to the halting problem.
21:24:43 <jack_rabbit> It is too bad that enterprise software seems to use a great deal of Java, though. I'd rather debug this problem than half the Java BS I deal with at work.
21:25:42 <jack_rabbit> One of the OSS projects I work on is written primarily in clojure, but now that it's become OSS, its components are slowly being replaced by java classes. It makes me sad.
21:25:48 <extraplanetary> jack_rabbit: on Java's own terms, that's a success--don't forget all the C++ and COBOL it replaced
21:25:54 <dfeuer> jack_rabbit, there doesn't exist a *language* to do that.
21:26:23 <Lutin`> Hell you couldn't even program in machine code and have it do what you expect it to
21:26:28 <jack_rabbit> Now that C++'s '11 standard has been released I'd actually rather work with that than modern Java.
21:26:45 <jack_rabbit> Lutin`, heh. With all Intel's re-ordering and whatnot.
21:27:00 <jack_rabbit> Lutin`, even our machine-code gets turned into Intel's micro-code now.
21:27:03 <dfeuer> And sometimes, interpreted code is faster than "bare-bones" compiled code because of cache effects.
21:27:17 <MP2E> jack_rabbit : I agree. C++11 isn't too bad, actually
21:27:39 <Lutin`> If I was going to do systems programming at this point I'd probably use Rust
21:27:41 <dfeuer> I've never looked at C++11. But ... it starts with C++, and that can't be good.
21:27:52 <extraplanetary> I can't speak for everyone, but I'd rather program in a memory-managed language than a non-memory-managed one for just about everything that's not in the kernel
21:27:55 <jack_rabbit> Yeah, this isn't at all a swipe at interpreted languages. I honestly do prefer C++11 to Java7. I've not worked with Java8 yet, but it looks a bit better, although still not as good as C++11.
21:28:18 <jack_rabbit> dfeuer, give it a shot. You might be surprised. I was.
21:28:24 <MP2E> Lutin` : Rust looks great :) hopefully it fully replaces C++ heh
21:28:35 <Lutin`> I love the ownership model
21:29:02 <jack_rabbit> Lutin`, I've given rust a read, but I'm suspicious of the salesmanship they're doing on their homepage.
21:29:13 <dfeuer> jack_rabbit, I'm not really all that interested in OO. And old-school C++ is undoubtedly the worst language I've ever attempted to learn.
21:29:23 <jack_rabbit> dfeuer, no doubt. It's horrible.
21:29:32 <jack_rabbit> dfeuer, it's inexcusably horrible.
21:30:08 <Lutin`> jack_rabbit: Try it out and you'll see it's really not that much salesmanship ;)
21:30:12 <dfeuer> I mean, I'm sure it's easier to understand than unlambda, INTERCAL, and Brainfuck, but ... that doesn't say much.
21:30:14 <jack_rabbit> dfeuer, hopefully they'l make some API-breaking changes and fix all the BS that came out of C++03
21:30:43 <jack_rabbit> Lutin`, with your bump, I might just.
21:30:55 <jack_rabbit> Lutin`, unfortunately, not much is written in it yet.
21:31:39 <dfeuer> C++ is, however, probably easier to understand than some of the deep macrology of TeX.
21:31:44 <jack_rabbit> Lutin`, I'd prefer a more C-like thing but with better types, for systems programming. Kind of like Go, but not terrible.
21:31:49 <Lutin`> Yeah that's the issue it has right now, being very much in development
21:31:58 <MP2E> kind of like Go but not terrible hehe
21:32:00 <MP2E> funny :P
21:32:01 <dfeuer> jack_rabbit, there's C--.
21:32:04 <extraplanetary> http://lpaste.net/106821 - take a look, anyone? I can't work out why GHC can't unify Maybe Value with f a.
21:32:12 <MP2E> C-- is delightfully concise, actually. I quite like it
21:32:12 <jack_rabbit> dfeuer, yes. Undoubtedly, in my mind, Tex is the single worst language.
21:32:22 <jack_rabbit> dfeuer, never heard of C--.
21:32:26 <jack_rabbit> I'll look it up.
21:32:34 * hackagebot linear-opengl 0.1.0.0 - Isomorphisms between linear and OpenGL types  http://hackage.haskell.org/package/linear-opengl-0.1.0.0 (BenGamari)
21:32:40 <dfeuer> jack_rabbit, TeX has to work with some seriously Hard Problems.
21:32:54 <jack_rabbit> dfeuer, no doubt. Typesetting isn't easy.
21:33:02 <jack_rabbit> But the syntax is still horrible.
21:33:11 <jack_rabbit> And the documentation is terrible.
21:33:13 <Lutin`> jack_rabbit: You could also look at D
21:33:25 <jack_rabbit> Lutin`, D looked more promising to me than Rust.
21:33:47 <dfeuer> Some things would surely have been done differently had it been designed today, but no one has yet come up with a replacement that's actually practical.
21:33:55 <jack_rabbit> But I haven't given either a decent shot yet, so I won't give either my *jack_rabbit* stamp of approval.
21:34:03 <jack_rabbit> (not that that means a frick'n thing)
21:35:11 <jack_rabbit> There are really two things I look for in a language. Either something that I can write a kernel in, like C, or something I can write excellently abstracted applications in, like Haskell.
21:35:31 <jack_rabbit> Haskell and C seem to both be at the top of their classes, as far as I'm concerned.
21:35:35 <MP2E> jack_rabbit : you found the 2, congratulations!
21:35:36 <dfeuer> But yes, I'd generally rather pore over Postscript manuals than C++ ones.
21:35:37 <MP2E> :)
21:35:43 <MP2E> C and Haskell are my two as well
21:35:52 <MP2E> for now, C still makes me a bit uneasy sometimes
21:35:52 <jack_rabbit> Neither is suited to the other's job, but they're both excellent (in my mind the best) at what they do.
21:36:37 <ReinH> jack_rabbit: I'm very interested in Rust as potentially filling C's role
21:36:42 <dfeuer> There are some nice things Over There in the ML family. And I've heard good things about Clean. And then of course there's Scheme, with its macro system to end all macro systems.
21:36:46 <jack_rabbit> And then there's the whole other world of applications that require programmer productivity over efficiency, where ruby and python are kings.
21:37:05 <ReinH> jack_rabbit: I think Haskell programmers are pretty productive...
21:37:06 <jack_rabbit> ReinH, I've not given it a decent shot. Maybe I should consider writing my kernel in Rust.
21:37:36 <jle`> i just wrote a complex function that i probably could have never gotten right if it weren't for the type system
21:37:39 <extraplanetary> dfeuer: I'm aware of modules as being something nice in ML that Haskell lacks; is there more?
21:37:41 <jle`> haskell is amazing o k
21:37:50 <jack_rabbit> ReinH, for heavily string-centric stuff, I'd rather work in Ruby. That's just my opinion.
21:37:52 <jle`> if only there was a way to capture this feeling of elation
21:37:56 <jle`> and show people that they too can experience it
21:38:01 <jack_rabbit> ReinH, unless I had a lot of time to make it right.
21:38:03 <MP2E> jle`: indeed
21:38:15 <MP2E> sometimes I feel like the productivity I gain from Haskell I immediately lose by staring in awe at my code for 30 minutes
21:38:17 <ReinH> jack_rabbit: How long have you been using Ruby?
21:38:23 <MP2E> but it's a beautiful feeling
21:38:30 <dfeuer> extraplanetary, they do better at impure stuff, arguably.
21:38:42 <johnw> MP2E: :)
21:39:03 <jle`> dynamic typing enables programmer productivity?
21:39:05 <extraplanetary> dfeuer: oh, that's a hair shirt I'm happy to wear :)
21:39:59 <ReinH> jle`: only if you don't include the full lifecycle costs of development and maintenance ;)
21:41:01 <jfeltz> one day, someone is going to take haskell's type system and bolt it on top of a more popular language, and declare victory, we must use Haskell or something to send a terminator back in time to stop this..
21:41:13 <jle`> even if you only consider writing the code the first time, too!
21:41:23 <jle`> that's been proven true to me multiple times today
21:41:27 <jle`> jfeltz: nah, no need for turf wars :)
21:41:34 <jle`> if the world is a better place then everyone benefits
21:43:29 <Lutin`> if you're going to switch languages for string centric stuff at least use Perl
21:43:52 <hdgarrood> jfeltz: have you seen Rust? I think the type system is quite similar
21:44:23 <hdgarrood> then again I've never used it in anger
21:46:33 <jack_rabbit> ReinH, not too long. On and off (mostly off) for about a year.
21:46:40 <jack_rabbit> ReinH, not at all professionally.
21:47:04 <jack_rabbit> ReinH, the main appeal to me is its immutability.
21:47:17 <ReinH> Ruby's immutability?
21:47:19 * MP2E points a big glowing sign at Haskell
21:47:25 <jack_rabbit> ReinH, that is, most of the operations you perform on a structure don't mutate the structure.
21:47:40 * hackagebot distributed-process-monad-control 0.5.0 - Orphan instances for MonadBase and MonadBaseControl.  http://hackage.haskell.org/package/distributed-process-monad-control-0.5.0 (jeremyjh)
21:47:42 * hackagebot http-streams 0.7.2.0 - An HTTP client using io-streams  http://hackage.haskell.org/package/http-streams-0.7.2.0 (AndrewCowie)
21:47:56 <ReinH> Um. That's not really true.
21:48:10 <jack_rabbit> ReinH, well...
21:48:17 <ReinH> A few array operations and such return new structures, but mutating state is part and parcel of OOP.
21:48:17 <jack_rabbit> ReinH, that's my beef with Ruby.
21:48:40 <jack_rabbit> It's hard to tell by convention which will and which *won't* mutate your structure.
21:48:45 <jack_rabbit> Unless you look at the docs.
21:48:57 <jack_rabbit> Most of the mutating methods have a bang at the end.
21:49:02 <ReinH> To the extent that Ruby does immutability, it's generally because it borrowed from lisp
21:49:13 <jack_rabbit> Yeah...
21:49:23 <ReinH> and things like map, reduce, etc vs. each are *functional* idioms.
21:49:23 <jack_rabbit> But I still prefer it to Python.
21:50:08 <ReinH> So you like Ruby to the extent that it is a functional language ;)
21:50:13 <covi> What are some researchers to watch on recent developments of succinct data structures?
21:50:18 <MP2E> That's what it sounds like to me :P
21:51:11 <jack_rabbit> ReinH, basically. :)
21:51:46 <MP2E> jack_rabbit : I figured out later that that is why I liked C++11 :P
21:51:53 <MP2E> I found Haskell later and it all kinda made sense
21:52:00 <ReinH> The problem with functional-style programming in Ruby is that its GC is really not designed for it, and it has no ways to fuse or otherwise optimize functional-style code.
21:52:31 <ReinH> So you end up paying a hefty cost in GC for your nice functional code.
21:52:36 <MP2E> C++11 brings C++ just that much closer to FP, and I hear C++17 may even have a monad-like structure for parallelism or something
21:52:39 <MP2E> kinda funny
21:52:48 <ReinH> and you often have to switch back to mutation at scale.
21:53:12 <ReinH> Although frankly putting Ruby and "at scale" in the same sentence is kind of funny.
21:53:17 <MP2E> hahaha
21:53:17 <jack_rabbit> exactly.
21:53:28 <ReinH> And this is coming from someone with a decade of Ruby experience, so I am definitely not a hater.
21:53:36 <MP2E> "How do I write a Ruby app that scales?" A: "You're doing it wrong"
21:53:36 <jack_rabbit> ReinH, luckily most of the programming that's done in Ruby is scripting, the kind of "glue" that perl used to be used for.
21:53:54 <dfeuer> Lutin`, it's been a long time, but Perl reminded me of GWBASIC.
21:54:10 <brrrrian> http://stackoverflow.com/questions/24545148/lazy-io-parallelism-converting-an-image-to-grayscale
21:54:53 <Lutin`> dfeuer: Wat
21:55:04 <ReinH> "Why is this so fast?" I love it.
21:55:35 <brrrrian> ReinH: basically, I am ignorant as to how GHC compiles & optimizes Haskell code :)
21:56:02 <ReinH> brrrrian: with data parallelism in Haskell you have to find a balance between spark size and spark number
21:56:17 <ReinH> too many, too small sparks is inefficient and can lead to fizzling
21:56:38 <ReinH> too few, too large sparks don't give the work-stealing queues a chance to work efficiently
21:57:02 <ReinH> Note that number in the RTS report: 2238 fizzled
21:57:17 <ReinH> That's almost exactly half of the sparks that were generated
21:57:30 <Lutin`> brrrrian: Why not just use parmap
21:57:37 <dfeuer> Lutin`, the extreme inconsistency of the syntax of early Perl reminded me of BASIC.
21:58:00 <Hermit> in TH, is it possible to convert/adapt a Name quoted as expression to a Name quoted as type? for example, where I could part from a str = "Test" and do $(conT (nameBase str)) and $(conE (nameBase str)), could I do both cases using just 'Test or ''Test?
21:58:22 <dfeuer> Needing to know that *this* procedure needs parantheses around its argument, but *that one* doesn't. And then all those weird things where variable names were based on the type of thing they could be assigned to.
21:58:58 <Lutin`> Yeah contexts can be confusing
22:00:22 <Lutin`> I'm used to it now though
22:00:27 <jack_rabbit> dfeuer, I actually really like perl.
22:00:33 <StoneCypher4k> jack_rabbit: why?
22:00:39 <jack_rabbit> dfeuer, it's a weird relationship I have with the language.
22:00:55 <StoneCypher4k> jack_rabbit: Mind you i also like a similar, also unpopular language; i'm not judging you
22:00:56 <jack_rabbit> StoneCypher4k, mostly because it's unlike anything else I've ever used.
22:00:59 <StoneCypher4k> ah
22:01:11 <jack_rabbit> StoneCypher4k, It makes me think differently.
22:01:18 <StoneCypher4k> fair enough.
22:01:25 <brrrrian> Lutin`: How would you use parMap instead of parBuffer in that example?
22:01:33 <jack_rabbit> StoneCypher4k, whenever I find a language that makes me think differently, I tend to form an attachment to it.
22:01:39 <StoneCypher4k> i am the same way
22:01:52 <StoneCypher4k> well, except when the language is a pain in the ass
22:01:55 <jack_rabbit> For me, those languages have been C, Common Lisp, Haskell, and Perl.
22:01:58 <StoneCypher4k> a
22:02:30 <StoneCypher4k> for me those were, in order, logo, delphi, c, c++, sql, dtd, erlang, and now is beginning to be haskell
22:02:37 <jack_rabbit> :)
22:02:41 <jack_rabbit> Glad to hear it.
22:02:42 <StoneCypher4k> i feel like maybe php should be in there but i'm not really sure
22:02:45 <jack_rabbit> I don't know most of those.
22:02:57 <jack_rabbit> Erlang i love, but it didn't really surprise me too much.
22:02:57 <jle`> any way to simplify these two "local type synonyms"?  forall foo bar m a b. (foo ~ Foo m a b, bar ~ Bar m a b) => ...
22:02:58 <StoneCypher4k> php is perl's immediate descendant, so you kind of know it
22:03:05 <jle`> can i pull out the common structure?
22:03:07 <Lutin`> brrrrian: You would just take your original example and replace `map` with `parMap strategy`
22:03:08 <jack_rabbit> In fact, I was a little disappointed in its expressiveness.
22:03:09 <jle`> sort of like a...type function?
22:03:26 <StoneCypher4k> erlang was the first tail recursive language i used with functional idioms, and also my first near-actor language, so i learned a lot there
22:03:35 <StoneCypher4k> man
22:03:39 <jack_rabbit> sure.
22:03:43 <StoneCypher4k> i hear people say "erlang's expressiveness is disappointing"
22:03:44 <StoneCypher4k> and i'm like
22:03:45 <Lutin`> brrrrian: Where strategy is the strategy you want to use
22:03:48 <StoneCypher4k> "nuh-uh"
22:03:59 <jack_rabbit> StoneCypher4k, You probably know better than I.
22:04:24 <jack_rabbit> But for me, at least, the tools I *felt* I had available to me were severely limited by the OTP framework.
22:04:25 <StoneCypher4k> my opinion is that in the way haskell makes you think harder about types, erlang makes you think harder about processes.  (though not in as extreme a fashion)
22:04:27 <brrrrian> Lutin`: I don't want to force the spine of the list.. which is why i am using parBuffer
22:04:35 <jack_rabbit> I basically *had* to write my application in a specific way.
22:04:40 <StoneCypher4k> i find processes as definition to be very satisfying, for roughly the same reason i like the unix way.
22:04:44 <jack_rabbit> It felt a lot like Java in that sense.
22:04:49 <StoneCypher4k> i don't usually use otp
22:04:52 <StoneCypher4k> and i hate java
22:04:54 <jack_rabbit> ahh.
22:04:56 <StoneCypher4k> i don't even really know why
22:04:58 <StoneCypher4k> i just hate it
22:05:07 <jack_rabbit> I do too, but I have reasons.
22:05:08 <StoneCypher4k> i love c++, so i shouldn't hate java, but i do
22:05:32 <cjenkin2> Jave is incredibly verbose
22:05:32 <jack_rabbit> Prolog is the next language I want to learn. It seems like it might give me another few of those "aha!!!" moments.
22:05:44 <yogurt_truck> c++ doesn't pretend to have a type system that you can rely on, that's one difference with java.
22:05:44 <jack_rabbit> cjenkin2, that's one of the reasons I hate it.
22:05:48 <StoneCypher4k> erlang is a descendant of prolog but it cut off the two defining features so they're effectively unrelated
22:05:52 <jack_rabbit> yogurt_truck, that's another.
22:06:01 <StoneCypher4k> still, if you speak erlang, you'll probably have less problems with prolog's notation than do most people
22:06:06 <jack_rabbit> StoneCypher4k, that's why I want to learn it.
22:06:08 <cjenkin2> C++ is reaching a critical mass of quirkiness and undefined behavior
22:06:18 <jack_rabbit> StoneCypher4k, the first point, not the latter.
22:06:23 * StoneCypher4k <3 c++
22:06:28 <StoneCypher4k> it's so perfectly broken
22:06:33 <StoneCypher4k> it's exactly wrong in the most precise ways
22:06:33 <cjenkin2> ^
22:06:37 <StoneCypher4k> it's so dangerous and useful
22:06:38 <jack_rabbit> cjenkin2, well hopefully soon it'll shed some of its C baggage.
22:06:51 <jack_rabbit> As much as I like C, C++ doesn't need it anymore.
22:06:57 <jack_rabbit> It's becoming too mature for that.
22:06:57 <cjenkin2> jack_rabbit: I don't think it can.
22:07:01 <StoneCypher4k> it's like any normal tool vendor would put safety gear near the blade
22:07:05 <jack_rabbit> cjenkin2, I do wonder.
22:07:07 <StoneCypher4k> c++ is like "how can we make this sharper"
22:07:24 <Kristina21>  Here some videos. I hope you like them! http://bit.ly/1qA5wsc
22:07:25 <cjenkin2> You need to start from scratch imo
22:07:32 <StoneCypher4k> jack_rabbit: whereas i agree with you, for political reasons i doubt c will ever be shed
22:07:35 <jack_rabbit> They need to rework the standard library, for start.
22:07:51 <StoneCypher4k> does bitly have a report spam link thing?
22:07:52 <jack_rabbit> Some of the things still handle errors in stupid ways.
22:08:00 <StoneCypher4k> i could make an irc bot that stalks the spambot and auto-reports them
22:08:01 <jack_rabbit> because of legacy reasons.
22:08:02 <StoneCypher4k> that'd be kinda fun
22:08:20 <cjenkin2> I really wished concepts had made it into C++11
22:08:23 --- mode: ChanServ set +o copumpkin
22:08:27 --- mode: copumpkin set +b *!~Kristina2@95.141.20.196
22:08:27 --- kick: Kristina21 was kicked by copumpkin (No. Bad.)
22:08:27 <StoneCypher4k> cjenkin2: agree so hard
22:08:28 <jack_rabbit> backwards-compatibility is C++'s main problem now, IMO. If they would just break their API, they could make a more solid language.
22:08:29 --- mode: copumpkin set -o copumpkin
22:08:39 <StoneCypher4k> cjenkin2: i too am still butthurt about that years later
22:08:45 <StoneCypher4k> copumpkin: thanks
22:08:52 <dfeuer> jack_rabbit,  Perl has evolved since I messed around with it in the late nineties....
22:08:56 <copumpkin> :)
22:09:02 <yogurt_truck> dfeuer: a lot
22:09:06 <StoneCypher4k> dfeuer: lol perl6 still isn't out
22:09:13 <jack_rabbit> dfeuer, indeed. And perl6 looks pretty awesome... If it ever actually gets a 1.0 release.
22:09:21 <StoneCypher4k> perl6 is the duke nukem forever of programming languages
22:09:23 <jack_rabbit> StoneCypher4k, yeah. Heh.
22:09:26 <jack_rabbit> XD
22:09:30 <cjenkin2> Or HL3 ?
22:09:30 <dfeuer> But I never got around to actually *learning* it. I just dug through the manual for whatever I needed.
22:09:37 <nexx> StoneCypher4k dnf is out
22:09:43 <StoneCypher4k> cjenkin2: halflife 3 joke on irc.  hl3 confirmed
22:09:47 <MP2E> haha
22:09:51 <cjenkin2> heh
22:10:01 <StoneCypher4k> nexx: that never happened, forget that
22:10:10 <jack_rabbit> dfeuer, That's the difference, I feel. Java's reference is garbage. With Haskell, I find what I need immediately.
22:10:10 <nexx> how about gnu hurd
22:10:14 <nexx> StoneCypher4k haha
22:10:14 <jack_rabbit> And it's comprehensible.
22:10:28 <StoneCypher4k> nexx: well i hate gnu so i love hurd, but yes, that's the parallel
22:10:31 <MP2E> If you take the first and last letters of haskell and you put the number of consonants left over on the end you get HL3, I get it! Haskell was made as a spoiler to Half Life 3!
22:10:39 <MP2E> lulz
22:10:42 <jack_rabbit> People complain about a monoid being a something in the something class of endofunctors or whatever as an excuse that Haskell is too complicated.
22:10:44 <yogurt_truck> jack_rabbit: hoogle <3
22:11:08 <yogurt_truck> jack_rabbit: those people don't want to learn or have had bad teachers
22:11:14 <MP2E> jack_rabbit: you mean that a monad is a monoid in the category of endofunctors?
22:11:15 <jack_rabbit> But I've consistently found great documentation for the haskell libraries, whereas for Java, I've got ages of cruft and garbage to deal with.
22:11:23 <jack_rabbit> MP2E, exactly.
22:11:23 <dfeuer> jack_rabbit, in Haskell, figuring out what you need may be harder than finding it, but then again knowing what it's called is important too.
22:11:34 <cjenkin2> jack_rabbit: you should see the Scala docs
22:11:41 <cjenkin2> They actually lie to you
22:11:41 <jack_rabbit> cjenkin2, are they horrible?
22:11:45 <jack_rabbit> :/
22:11:51 <cjenkin2> Seriously. There are "use cases"
22:11:54 <jack_rabbit> I was looking at Haskell today...
22:12:00 <jack_rabbit> s/Haskell/Scala/
22:12:06 <cjenkin2> which are garbage, and sometimes not even well-kinded garbage
22:12:14 <jack_rabbit> implicit arguments as a way of implementing typeclasses...
22:12:18 <yogurt_truck> cjenkin2: add to that the Java interop
22:12:25 <nexx> I haven't spent much time with scala but I didn't understand what is different when "use case" stands in front
22:12:26 <cjenkin2> jack_rabbit: Hey, that's how Agda does it
22:12:27 <jack_rabbit> It looks horrible, and it performs more horribly.
22:12:41 <cjenkin2> but no ugly implicit conversions
22:12:49 <jack_rabbit> cjenkin2, wrong...
22:12:51 <g06|in> what does it mean by ‘foldl’ is strict in the tail of its list argument ?
22:12:58 <StoneCypher4k> scala is the most underscore happy language ever, and this comes from an erlang programmer
22:13:02 <cjenkin2> jack_rabbit: ?
22:13:02 * hackagebot helm 0.6.0 - A functionally reactive game engine.  http://hackage.haskell.org/package/helm-0.6.0 (ZackCorr)
22:13:04 <yogurt_truck> just the other day I was using the damn Casbah MongoDB driver for Scala, and couldn't find the docs. Turns out that the docs were in Java, because of the interop.
22:13:08 <jack_rabbit> cjenkin2, oh. NVM. I thought you meant in Scala.
22:13:17 <jack_rabbit> cjenkin2, just reread the backlog.
22:13:24 * StoneCypher4k does not trust mongo
22:13:42 <yogurt_truck> I don't mind Scala's syntax. But then again I don't mind any syntax
22:13:43 <jack_rabbit> However, If you want to write code in a java style, you can probably do it better in Scala, provided you want to wait for Scalac to do whatever the heck it's doing.
22:14:05 <jack_rabbit> I can't believe how long it takes for scalac to compile.
22:14:05 <StoneCypher4k> yogurt_truck: smoke perl and cobol and intercal for a week each then say that again with a straight face
22:14:14 <dfeuer> g06|in, foldl is actually strict in the entire *spine* of its list argument.
22:14:15 <nexx> yeah it is super slow
22:14:29 * yogurt_truck has a hard time becoming agitated by a matters of concrete syntax (shitty abstract syntax trees that are disparate with the language's own specc do piss him off!)
22:14:31 <StoneCypher4k> operator come from is wrong on every level that has ever existed and makes my brain hurt badly
22:14:49 <g06|in> dfeuer: what does being strict in the …whatever… mean?
22:15:02 <StoneCypher4k> yogurt_truck: have you actually read the intercal spec?
22:15:06 <jack_rabbit> StoneCypher4k, I've been meaning to learn Cobol, but I can't find a free compiler.
22:15:15 <StoneCypher4k> jack_rabbit: gcc has a cobol frontend i think
22:15:20 <MP2E> haha really?
22:15:21 <dfeuer> g06|in, it means that it actually has to traverse the entire list before it starts to produce any results.
22:15:25 <MP2E> oh man, cobol gcc frontend
22:15:26 <jack_rabbit> StoneCypher4k, the only reason is my dad is a Cobol programmer, and I need something to talk to him about. :/
22:15:30 <yogurt_truck> StoneCypher4k: I did Perl for years before Scala existed. That must have given me some tolerance for syntax aesthetics, for better or worse!
22:15:30 <g06|in> dfeuer: thansk!
22:15:34 <StoneCypher4k> jack_rabbit: that's generous
22:15:47 <StoneCypher4k> yogurt_truck: fair.  but have you actually read the intercal spec?
22:15:49 <jack_rabbit> StoneCypher4k, heh.
22:15:56 <StoneCypher4k> yogurt_truck: it's one of the trolliest things i've ever seen.  on the internet.
22:15:59 <yogurt_truck> StoneCypher4k: no I haven't. crazy?
22:16:07 <yogurt_truck> haha. will check
22:16:09 <StoneCypher4k> oh, no wonder you aren't laughing
22:16:09 <StoneCypher4k> sec
22:16:20 <StoneCypher4k> http://www.muppetlabs.com/~breadbox/intercal-man/home.html
22:16:27 <MP2E> StoneCypher4k : okay now when I look at this I'm expecting it to switch to a video of Rick Astley
22:16:28 <StoneCypher4k> there are implementations.
22:16:35 <StoneCypher4k> nope.  much better.
22:16:36 <StoneCypher4k> it's real.
22:16:37 <MP2E> haha
22:16:39 <dfeuer> g06|in, the head and tail functions are only strict in the *front* of the list. foldr is entirely lazy. foldr is strict in the spine...
22:16:59 <StoneCypher4k> intercal is like a mind toxin for haskell people
22:17:05 <StoneCypher4k> i just gave you the necronomicon
22:17:08 <StoneCypher4k> and you're thanking me
22:17:24 <yogurt_truck> love all the statements
22:17:46 <MP2E> "PLEASE GIVE UP"
22:17:52 <MP2E> that just about sums up how I feel about this whole language
22:17:54 <MP2E> and I've only seen one page
22:18:33 <StoneCypher4k> this is like if brainfuck and apl had a baby
22:18:46 <StoneCypher4k> and the baby had a triple sized sarcasm gland, and brass knuckles
22:18:47 <StoneCypher4k> you have no idea
22:18:48 <MP2E> "Since it is an exceedingly easy language to learn, one might expect it would be a good language for initiating novice programmers."
22:18:52 <MP2E> I just... hahahahahahaha
22:18:54 <yogurt_truck> I'm busy writing my programs entirely with equations and you throw these STATEMENT_THINGIES at me. so cruel :(
22:19:01 <yogurt_truck> MP2E: oh definitely
22:20:20 <zRecursive> Anyone here using maxima ? In maxima, tlimit((atan(7*x)-(%pi/2))/(sin(10/x)),x,inf); => 1/70 which is ok, but limit((atan(7*x)-(%pi/2))/(sin(10/x)),x,inf); => 1/35 ?  sorry, it is off topic
22:25:05 <biscarch> WRT postgres-simple: Has anyone been able to store a JSON array in a postgres-json field?
22:26:14 <biscarch> I'm using `toJSONField` for my toField instance, but getting a syntax error when attempting to execute an insert
22:35:32 <flux> biscarch, I have not, but as far as I know, an array is not a valid JSON object. the root is always a dictionary.
22:37:03 <Freundlich> flux: I'm pretty sure "top-level" arrays are allowed and I've seen that being used (an RFC about json says that this is ok).
22:37:11 <biscarch> flux: afaik the rfc says arrays are valid "top level"
22:37:22 <flux> oh, ok. I've just used bad implementations then :)
22:37:47 <Freundlich> A lot of implementations assume that an object is at the top-level, yeah...
22:39:13 <biscarch> pg seems to be a bit weird about storing them though, since it uses curly braces instead of brackets arrays.
22:39:19 <jle`> i got corrected by edwardk on reddit, that must mean i'm going somewhere :)
22:39:31 <edwardk> did i?
22:40:48 <MP2E> haha
22:42:51 <dfeuer> Oh gosh, the INTERCAL manual has a "tonsil" instead of an "appendix".
22:43:30 <flux> reading the RFC 7159 it seems to me it depends if the implementation supports JSON objects or JSON values - or I suppose JSON arrays
22:43:41 <StoneCypher4k> dfeuer: it's in many ways a work of surreal beauty
22:43:54 <flux> but if it supports JSON objects, then I would expect {} at the top-level, but if it supports values, {}, [] and "hello" etc are fair game.
22:44:01 <jle`> edwardk: yeah, i made the comment about arrows and monads existing on different scales
22:44:50 <kazagistar> flux: if "it depends", then any implementation worth its salt will allow both, especially one like Aeson or something
22:46:00 <flux> kazagistar, well, it's not so clear-cut I think. it can be beneficial to be able to assume it's, say, an JSON object instead of something else.
22:46:08 <biscarch> aeson allows both
22:46:29 <flux> in any case, postgresql has no issues with select '[]'::json
22:46:42 <flux> so it seems to be an issue in the library then?
22:46:55 <biscarch> could be, I'm digging deeper into the code now
22:47:08 <flux> (also '42'::json works)
22:47:23 <kazagistar> flux: right, but with the design of Aeson, you make it pretty explicit what the top level is in how you declare a parsing for something
22:48:05 <kazagistar> flux: even in something "softer", you would want a flag at the very least, the cost of supporting that feature seems pretty minimal
22:48:06 * hackagebot hoauth2 0.4.1 - hoauth2  http://hackage.haskell.org/package/hoauth2-0.4.1 (HaishengWu)
22:48:22 <biscarch> it really just calls aeson though, which spits out a singly quoted array with escaped quotes: '[{\"key\":\"val\"}]'
22:49:57 <edwardk> jle`: ah. now i remember. the profunctor arrow thing is a pretty neat connection. apparently it had been observed a coupe of years before i noticed it
22:50:19 <flux> hmm, they shouldn't escaped
22:50:35 <flux> only if a string contains " then that should be escaped
22:50:40 <gamegoblin> > (fix id) “lol”
22:50:41 <lambdabot>  <hint>:1:10: lexical error at character '\8220'
22:50:56 <gamegoblin> Wat
22:51:01 <Lutin`> brrrrian: Still around?
22:51:15 <jle`> edwardk: thanks for the tip :)
22:51:35 <gamegoblin> > fix id undefined
22:51:39 <lambdabot>  mueval-core: Time limit exceeded
22:52:33 <kazagistar> the reddit post about dependant types has 143 comments... take THAT articles claiming only 37 people in the world care about haskell
22:52:46 <MP2E> haha
22:53:07 <biscarch> flux: could easily just be the error message display doing the escaping.
22:54:00 <kazagistar> owait, some of those posts could be the same person posting more then once... foiled again!
22:58:07 * hackagebot benchmark-function 0.1.0.0 - Test the time it takes to run a haskell function  http://hackage.haskell.org/package/benchmark-function-0.1.0.0 (AlanHawkins)
22:58:42 <lfairy> gamegoblin: watch your curly quotes
22:59:01 <gamegoblin> lfairy: gotcha. Still haven’t gotten around to disabling that in my irc client.
23:01:07 <Lutin`> brrrrian: You don't need to manually chunk your image if you're using parBuffer, it actually slows it down
23:02:28 <Lutin`> But there's still a massive number of sparks and lots of GC
23:07:18 <isomorpheous> Is there any truth to Hackage's download stats?
23:15:59 <jack_rabbit> kazagistar, must be exactly 37 people, then.
23:19:29 <jle`> isomorphismes: honestly sometimes i wonder that myself
23:21:05 <jack_rabbit> isomorphismes, how do I view these stats?
23:22:41 <kazagistar> jack_rabbit: http://hackage.haskell.org/packages/top
23:23:23 <kazagistar> mtl, text, attoparsec, scientific, aeson ... checks out
23:23:27 <ReinH> I had no idea semigroups was so popular
23:23:45 <jack_rabbit> Thanks.
23:24:44 <kazagistar> ReinH: I wonder how it tracks if a package was pulled by deps or not, if at all?
23:25:03 <jack_rabbit> ReinH, Just wait till you hear about Plan9 groups.
23:27:37 <lfairy> non-empty lists are amazing though
23:35:07 <kazagistar> ... and I get why they are in that package! thanks person (whose identity I forgot) who explained what "free" means to me the other day!
23:48:10 * hackagebot despair 0.0.1 - Despair  http://hackage.haskell.org/package/despair-0.0.1 (Heather)
23:49:08 <kvanb> despair is useful
23:49:20 <kvanb> one day if I want to get depressed, I could just read through the quote bank
23:51:11 <joelteon> Does anyone know how I could hijack trifecta's rendering capabilities to render my own error message?
23:53:45 <kvanb> joelteon: I asked edwardk once
23:54:16 <kvanb> I forget the response he gave me, but I think you can or he was planning to make it easier maybe?
23:54:50 <joelteon> okay
23:55:15 <joelteon> what I have is "a parse error has occurred here" and I want to give the user "it might be because of a thing on another line, over here"
23:56:10 <kvanb> oh, you can easily append more to the leijen doc
23:56:33 <joelteon> well my library just provides the parser
23:56:34 <kvanb> detecting the kind of error is harder maybe
23:56:53 <kvanb> ah
23:57:04 <kvanb> looked at Idris?
23:57:16 <kvanb> they hack trifecta something crazy
23:57:17 <joelteon> no
