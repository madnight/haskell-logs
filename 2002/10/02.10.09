01:33:05 * Heffalump reappears
02:14:50 * Marvin-- fiddles with prolog
02:18:51 <Heffalump> using it for anything interesting?
02:18:59 <Marvin--> type inference ;)
02:19:01 <Marvin--> feels like cheating :)
02:19:20 <Marvin--> type_of(add, fun(int, fun(int, int))).
02:19:20 <Marvin--> type_of(x, int).
02:19:20 <Marvin--> check(num(_), int).
02:19:20 <Marvin--> check(var(X), T) :- type_of(X, T).
02:19:20 <Marvin--> check(app(F, X), S) :- check(F, fun(T, S)), check(X, T).
02:19:31 <andersca> now _that_ is nice
02:19:42 <Marvin--> check(app(var(add), num(2)), T)  --> T = fun(int, int)
02:20:07 <Marvin--> check(app(app(var(add), num(2)), var(x)), T) --> T = int
02:20:13 <Heffalump> monomorphic or polymorphic?
02:20:16 <andersca> what if you introduce other types
02:20:30 <andersca> how'd <Marvin--> type_of(x, int). look like then?
02:21:18 <Marvin--> the type_of declarations define the environment
02:21:30 <Marvin--> (yes, I cheat, I could do the check predicate ternary instead)
02:22:38 <Marvin--> type_of(if, fun(bool, fun(T, T))).
02:22:43 <Marvin--> type_of(b, bool).
02:22:54 <Marvin--> check(app(var(if), var(b)), T).  -->  T = fun(A,A)
02:23:04 <andersca> cool
02:23:29 <Marvin--> doh, sorry, if should be bool->t->t->t of course
02:23:55 <Marvin--> check(app(app(var(if), var(b)), num(2)), T).  -->  T = fun(int,int)
02:24:21 <Marvin--> check(app(app(app(var(if), var(b)), num(2)), var(b)), T).  -->  no
02:26:41 <Marvin--> right, enough playing ;)
03:37:18 <BlizzNL> Consider the folowing functoinal program: (\x -> x) ((\y -> (\z -> z y)) 3)  , what does the expression evaluate to?
03:39:03 <Heffalump> that doesn't look well-typed to me
03:39:12 <Heffalump> oh, sorry
03:39:18 <Heffalump> \z -> z 3
03:39:45 <BlizzNL> Well hugs doesn't eat it indeed.. but that's not a proof, right?
03:39:59 <Heffalump> any Haskell evaluator ought to be fine with it
03:40:27 <BlizzNL> Prelude> (\x -> x) ((\y -> (\z -> z y)) 3)
03:40:27 <BlizzNL> ERROR - Cannot find "show" function for:
03:40:27 <BlizzNL> *** Expression : (\x -> x) ((\y -> \z -> z y) 3)
03:40:27 <BlizzNL> *** Of type    : (Integer -> a) -> a      
03:40:34 <Heffalump> yeah, but that's just cos it can't print it out
03:40:49 <Heffalump> it evaluated it fine
03:41:53 <BlizzNL> Heffalump: is their a possibility to print it out?
03:42:26 <Heffalump> no.
03:43:14 <BlizzNL> great answer;)
03:43:43 <BlizzNL> BTW remember I talked to you about these anamorphisms and stuff a few weeks ago?
03:44:22 <Heffalump> yes
03:44:29 <Heffalump> now isn't a good time for me to talk actually, sorry
03:44:38 <BlizzNL> Ok sorry but I was surfing through the rest of the text suddenly your name comes up! 
03:44:51 <Heffalump> which text?
03:45:11 <BlizzNL> LNCS advanced functional programming
03:45:45 <Heffalump> oh, yeah
03:45:48 <BlizzNL> a topic on generic program transformation
03:45:57 <Heffalump> that was the stuff that became my PhD topic
03:46:07 <BlizzNL> ahh ic .. but you should get back to work .. thnx
03:46:40 <Heffalump> not exactly work, I just got back from PLI (ICFP and stuff) and need to catch up with some RL things
03:46:56 <Heffalump> saw lots of current and former Utrecht people there
03:46:57 <BlizzNL> ok have a nice day
03:47:08 <BlizzNL> Was E.VIsser their too?
03:47:14 <Heffalump> yep
03:47:25 <BlizzNL> Yeah he is my current 'mentor'
03:47:25 <Heffalump> Eelco Visser, Johan Jeuring, Arthur Baars
03:47:33 <Heffalump> cool
03:47:40 <Heffalump> are you doing anything with Stratego then?
03:47:46 <BlizzNL> I don't know A.Baars, nut JJeuring is great
03:48:22 <BlizzNL> Well I am taking Visser's course on program transformation next semester
04:56:03 * shapr bounces
04:58:24 <shapr> igloo: hey, did you get gtk2hs compiling?
04:59:16 <Igloo> I'd gone back to gtk+hs which worked
04:59:44 * Igloo was about to find GTK docs to print  :-)
05:05:14 <shapr> oh, ok
05:09:08 <shapr> Heffalump: hey, I hacked SimonMar's HWS into working with ghc5.04.1
05:09:27 <shapr> Heffalump: you have any ideas for a plugin interface?
05:17:29 * shapr reads a bit about functional dependencies
05:39:32 <cleverdra> when using getChar with NoBuffering set on stdin, how can I also not have the characters echo to the screen?
05:41:43 <shapr> maybe execute "stty echo -1" or whatever that really is?
05:41:48 * shapr notes that a cheesy solution
05:42:12 <shapr> stty echo something
05:42:15 <shapr> 0 maybe?
05:42:37 <cleverdra> stty -echo, IIRC
06:07:30 <shapr> wow cool
06:07:54 <shapr> I was wondering yesterday about the connection between Quantum Computing and Monads
06:14:53 <shapr> Shin-Cheng Mu and Richard Bird wrote a paper about it.
06:14:59 <shapr> wish I could find a copy online.
06:16:37 <shapr> aha, http://ropas.kaist.ac.kr/aplas/paper/mubi.ps
06:17:25 <shapr> wow, cool paper
06:18:28 <shapr> "In this paper we see quantum programming as a special kind of non-deterministic programming where negative probabilities are allowed."
06:18:29 <shapr> spiffy
06:19:11 * cleverdra gets.
06:20:24 <shapr> I bet Pseudonym would be interested in this
06:36:01 <Jii> what's the status with the haskell wiki, btw? :)
06:36:20 <shapr> hi Jii!
06:36:26 <Jii> hi!
06:36:32 <shapr> you mean purl.org/wiki/haskell/RecentChanges ?
06:36:40 <shapr> or you mean a wiki written in Haskell?
06:37:15 <shapr> the online wiki uses RCS locks, some of which get stuck
06:37:24 <Jii> ai mean haskell.org/wiki/wiki/
06:37:24 <shapr> that's why some of the pages are blank
06:37:28 <Jii> oh
06:37:31 <shapr> I dunno when they'll fix it.
06:37:48 <shapr> I'll find out who has access to the content and get a copy
06:37:52 <shapr> then I can put it up somewhere else
06:38:01 <shapr> or maybe convert it to MoinMoin
06:38:10 <shapr> they offered to run a MoinMoin wiki if someone would convert it.
06:38:15 <shapr> what's up with you?
06:38:40 <shapr> does anyone know who the HaskellWiki maintainer is? who should I email about getting the content?
06:38:54 <Jii> nothing much, i am searching for motivation, again, for my master's thesis ;-)
06:38:58 <shapr> ah, I see.
06:39:10 <shapr> what's your thesis about?
06:39:20 <shapr> I think you told me before, but I've forgotten :-(
06:40:19 <shapr> hi buggs
06:40:20 <Jii> i am comparing the "expressivity" of python and java, on a small scale, ie. how much smaller are python programs and why
06:40:29 <shapr> hm, neat
06:40:44 <shapr> are you comparing cyclomatic complexity and stuff like that? or what?
06:41:18 <buggs> hoi shapr
06:41:21 <Jii> the problem is that i have no resources to do "real" empirical study, like, making people do programs and comparing them
06:41:30 <Jii> like lutz prechelt did
06:42:13 <Jii> so the strategy is to compare similar implementations of small problems in both languages (and the differences are small too, then)
06:43:06 <Jii> like, for example, an implementation in haskell would be totally different, due to the different paradigm
06:44:34 <Jii> but i don't know, it's just a silly master's thesis, i should just finish it, and forget about it ;-)
06:44:41 * ski reappears
06:44:46 <shapr> you could compare orthogonality
06:44:47 <Jii> shapr, you have snow there already?
06:44:50 <shapr> nah, not yet.
06:44:57 <shapr> there has been snow south of roi though
06:45:41 <cleverdra> Jii - you might find http://www.cs.uu.nl/people/daan/papers/com.ps useful, particularly the 'Why Haskell?' section.
06:46:10 <cleverdra> Jii - but the points made against VB and Java are I think mostly applicable to Python, as well =)
06:46:28 <shapr> ?
06:47:31 <cleverdra> sorry, the section is "Why use Haskell?"
06:47:58 <Jii> cleverdra, yes, but my point isn't exactly making any general assesments, just to see where the differences are in the small scale, given that they are, in many ways, quite similar languages
06:48:22 <shapr> python allows you to put post-it note attributes on instance
06:48:27 <shapr> java doesn't
06:48:48 <shapr> python does runtime typing, java's is compile time
06:49:07 <Jii> and java is _explicitly_ typed
06:49:11 <cleverdra> Jii - in the sense that they're both imperative languages with GC and an OO bent, perhaps.  I'd say that they're 'quite similar' when compared to Prolog or Haskell, sure.
06:49:41 <shapr> python has first class functions
06:49:52 <shapr> and map,filter,reduce
06:50:12 <shapr> java has method polymorphism, whatever you really call that
06:50:34 <cleverdra> 'method polymorphism' sounds like what all OO languages have, shapr.
06:50:43 <shapr> python doesn't have it.
06:50:53 <ski> subtyping polymorphism ?
06:50:59 <cleverdra> I don't understand what you mean, then.
06:51:01 <Jii> but, i just talked with a friend of mine, and he said that someone has implemented a (for example) red-black tree type in haskell so that the _type itself_ carries information about the conditions for the rb-tree, i think it's quite amazing
06:51:24 <shapr> I think that's in the book I'm reading....
06:51:25 <shapr> why is that amazing?
06:51:34 <shapr> a type in Haskell is a lot like an object instance.
06:51:34 <Jii> i never dived enough into the whole typing thing in haskell :)
06:51:40 <ski> just ADT hiding or is it another thing ?
06:51:59 * shapr dunno
06:52:04 <Jii> well, the source doesn't even compile if it doesn't obey the balance rules of rb trees
06:52:10 <ski> (like one can make a PrimeNumber ADT type in haskell, if one want's to)
06:52:37 <Jii> maybe i'm just thinking in some obscure way, but i think i never quite understood it that way ;)
06:52:56 <ski> what source ? the red-black tree implementation or the code that uses the red-black tree ?
06:53:12 <shapr> one of the strong points of haskell is that you can use the type checking system as a tool to validate your code.
06:53:27 <shapr> people always told me that's true about Java, but it's not so in my experience.
06:53:47 <shapr> of course, annotating your functions with more specific types really helps.
06:54:18 <shapr> imho, one of the strong points of Python is that I don't have to worry about the type... Haskell has that strong point also.
06:54:25 <ski> well, simple ADT hiding can certainly (i think) be made in Jave (if your data-structure implementation is correct i.e.)
06:55:45 <Jii> ski, i don't see any spectacular point there if it weren't for some code that does something with the tree
06:56:05 <Jii> but i have to ask for the reference for that, and see for myself :)
06:56:14 <shapr> I like languages where there are less rules
06:56:25 <shapr> for example, using function calls to replace loops
06:56:33 <ski> Jii : i don't understand what you mean
06:57:09 <ski> or using jumps to replace loops ? ;-)
06:57:23 <shapr> yah, coroutines are a superset of threads
06:57:56 <ski> they are ?  i think i haven't entirely grasped what coroutines is
06:57:57 <shapr> continuations are a superset of function calls
06:58:12 <ski> ah, ok. in some sense, yes
06:58:27 <shapr> coroutines are continuations that call each other
06:58:43 <cleverdra> I like the word 'fiber' for lightweight cooperative threads which coroutines tend to be a subset of.
06:58:43 <ski> (i.e function call can be seen as two continuation jumps)
06:58:56 <shapr> right, jump forward, jump back
06:59:05 <ski> only two coroutines or more ?
06:59:25 <shapr> for what?
06:59:34 <ski> for coroutines
06:59:36 <Jii> ski, umm, if i understand correctly, the type itself insures that the tree is balanced correctly
07:00:11 <Jii> ski, (for a specific implementation of RB tree, of course, not generally)
07:00:28 <shapr> coroutines are two continuations that call each other, thereby making non-preemptive lightweight threads
07:00:40 <shapr> you can add schedulers and stuff by making them all call a scheduler continuation
07:00:41 <ski> Jii : ok, so then i'll take that to imply that the type-system checks if (at least some part) of the implementation of the red-black tree is correct (balance is kept correct)
07:00:53 <ski> Jii : of course
07:01:21 <shapr> jii: I think Simon PJ wrote a cute app that used the type system to prove that Enron had negative money.
07:01:29 <Jii> heh
07:01:29 <ski> so there are just two continuations that call each other in coroutines, right ?
07:01:41 <shapr> there can be more
07:01:50 <shapr> any number
07:02:14 <ski> so there couldn't be say three ones, calling each other in a circle, say just clockwise, or perhaps able to change direction..
07:02:17 <ski> ok
07:02:53 <cleverdra> ski - some people have an arbitrary number of coroutines, a global data-structure to hold a list of them, and a function to coroutinely-call each of the coroutines in this list.  They call this 'cooperative multitasking'
07:02:53 <ski> (shapr : Enron ?)
07:03:24 <shapr> big company that went bankrupt in the US
07:03:32 <ski> data-structure : but then the coroutines usually don't pass each other values, do they ?
07:03:34 * cleverdra has implemented such in Forth, where coroutines tend to be trivial.
07:03:41 <ski> oops
07:03:48 <ski> s/data-structure/cleverdra/  :)
07:04:05 <shapr> you can still call other coroutines
07:04:07 <shapr> and pass values
07:04:15 <cleverdra> ski - no, some people make a distinction between calls that pass values and cals that don't.
07:04:23 <o3> ski: they do ... if you know how to write a compiler, parsing/lexing is the classic example of using coroutines
07:04:25 <ski> and they can pass values back, i suppose
07:04:25 <cleverdra> ski - they call the former 'coroutines', I think =)
07:04:29 <shapr> hi o3!
07:04:40 <o3> hullo
07:04:59 <shapr> wassup?
07:05:01 <ski> hi o3
07:05:10 <o3> hullo hullo
07:05:58 <shapr> o3: what about re/unloading of modules? hard to do?
07:06:03 <ski> o3 : you mean compiler asks parser for more info on abstract syntax tree, which in turn asks lexer for next lexeme, which in turn ask filesystem for next character ?
07:06:31 <o3> shapr: unloading modules is fine ... unloading .so's isn't possible right now, because the ghc linker doesn't support it
07:06:40 <shapr> hrm :-/
07:06:42 <o3> (i.e. the code in Linker.h)
07:06:52 <o3> hmm
07:06:58 <shapr> I was hoping to be able to reload modules
07:07:02 <o3> you _may_ be able to provide your own .so unloading code
07:07:11 <shapr> how would that work?
07:07:18 <o3> shapr: if you restrict yourself to .o's, that's no problem.  after all, ghci does it all the time
07:07:28 <cleverdra> shapr - do you know where Simon's app is?  I can't google through the Enron pages, and I don't get a hit on clf
07:07:32 <shapr> hm
07:07:40 <o3> shapr: i'm not sure, but maybe you can compile RuntimeLoader and link it against your own, hand-written Linker.c
07:07:43 <shapr> cleverdra: I'll see if I can find it
07:07:53 <shapr> ouch, I don't do C
07:08:02 <o3> ski: something like that, yep ... you basically are switching between a small set of functions all the time
07:08:05 <shapr> well, this is a good reason to do some
07:08:43 <o3> shapr: see ghc/rts/Linker.c (from GHC source) if you're interested
07:08:57 <o3> those are the "primitives" that RuntimeLoader hooks into
07:09:44 <shapr> cleverdra: I think this is it: http://link.springer.de/link/service/series/0558/bibs/2021/20210435.htm
07:10:00 <shapr> o3: cool, thanks for the pointers
07:10:08 * shapr wasn't intentionally punny there
07:10:22 <o3> har :)
07:10:35 <cleverdra> shapr - thanks =)
07:11:43 * shapr reads Linker.c
07:12:23 <o3> shapr: the runtime loader is mostly a wrapper around that file ... so i really wasn't being modest when i said that i didn't do much work :)
07:13:27 <shapr> ok, basic question number 1, what's the big difference between .o and .so files?
07:13:37 <shapr> or should I just find a linking/dynload tutorial somewhere online?
07:15:08 <cleverdra> shapr - you need to pay, or something, to read that article.  /me shrugs
07:15:24 <shapr> I've seen a free version I think
07:15:35 <o3> probably, yeah.  i don't really know the technical differences either, except that .so's are like .a's, and obviously have some extra machinery so that they know their dependencies, etc
07:16:29 <shapr> cleverdra: http://research.microsoft.com/Users/simonpj/Papers/contracts-icfp.htm
07:17:10 <ski> cleverdra : seem like i can read "Composing Contracts" from the link.springer.de site in Acrobat Reader without having to pay anything
07:17:59 <ski> cleverdra : hmm, perhaps you were right after all. it seems i only got the abstract :(
07:18:02 <cleverdra> shapr - ah.  Thanks again.
07:18:11 <shapr> me heap big index
07:18:31 * cleverdra downloaded all of Simon's papers some time ago, and thought the title was familiar =)
07:18:35 <cleverdra> shapr =)
07:19:39 <ski> Are generators related to coroutines ?
07:20:29 <shapr> I'm not sure
07:20:40 <shapr> I've heard the Python guys say that generators can be implmented as coroutines
07:20:44 <shapr> hey Erwin
07:20:51 <shapr> oh, you're a C expert, right?
07:20:57 <ski> I seem to remember that the language Icon used generators
07:21:02 <cleverdra> skis - what shapr said, only with more certaintly
07:21:05 <shapr> can you tell me where I can find the details of the differences between .o and .so files?
07:21:22 <Erwin> an .so file is more like a binary than and .o file
07:21:25 <o3> ski: not really
07:21:30 <shapr> um
07:21:48 <shapr> erwin: ghc can reload .o files, but not .so files... any idea why? is that a big deal?
07:22:28 <Erwin> shapr: really? that sounds backwards. it's .so files you can open with dlopen and execute code from. You can't do it with .o files on most operating systems (there's something about AIX AFAIR)
07:22:31 <o3> Erwin: oh, if you look through Linker.c, there's no code there to unload .so's
07:22:37 <ski> o3 : not really what ? i seem to have lost the context
07:22:40 <o3> you can write it in yourself
07:22:49 <o3> ski: oh, coroutines aren't really related to generators
07:23:00 <o3> grr, s/erwin/shapr/
07:23:12 <o3> shapr: that's why i was saying that myabe you can modify Linker.c to suport it
07:23:13 <Erwin> well, with .so files you can simply call dlclose to close the SO file and dlopen it again. You have to careful not to have any references to stuff that was in that shared object
07:23:18 <cleverdra> coroutines are a pretty good way to implement generators.
07:23:19 <ski> o3 : ok
07:23:43 <o3> shapr: the addDLL function in Linker.c (which RuntimeLoader uses to load .so's) does a dlopen(), but there's no corresponding function to do a dlclose()
07:23:55 <o3> all you need to do is write one.  there's no reason it can't be supported
07:24:01 <shapr> yah, I just grepped for dlclose
07:24:02 <shapr> isn't there
07:24:07 <o3> i should probably get around to it one day when i have some time (haha)
07:24:45 <ski> cleverdra : so what is the definition of generators ?  (and coroutines as well, if you know)
07:24:58 <shapr> I wonder how complicated the "not to have any references to stuff" part is
07:25:13 <shapr> probably scary
07:26:04 <Jii> ski, in python at least, generators are functions that can be suspended and restored
07:26:11 <o3> shapr: you can probably just copy all the code from unloadObj, but replace a few lines with dlclose()
07:26:29 <shapr> that would mean the user would have to be sure all references are gone, right?
07:26:49 * shapr tries
07:26:59 <ski> Jii : can't one see that as a special case of coroutines ?
07:27:00 <Jii> ski, but python's generators are really simple
07:27:37 <Jii> ski, i guess so ;)
07:27:38 <ski> Jii : well, i haven't looked into Python yet :(
07:27:45 * shapr likes Python lots
07:27:52 <o3> shapr: presumably
07:28:36 * ski has understood that  (and plans to look into Python not too far into the future)
07:29:22 <shapr> I'd be happy to help you with Python
07:29:52 <Jii> it's even remotely functional ;) (and has list comprehensions, well, sort of :-)
07:30:29 <ski> (but, right now i have lots of things to do. one lab for friday and one for monday and one for tuesday, and then a project also (1 lab of those finished))
07:31:40 <Jii> don't we all ;-)
07:31:55 <ski> ;)
07:32:04 <shapr> I'm confused, can ghc use .so files?
07:32:09 <shapr> if so, why are the executables so huge?
07:32:37 <ski> (i probably will have only one (perhaps two) courses next quarter, instead of the three i have now)
07:32:41 <o3> shapr: they can't, for reasons i don't know
07:33:09 <shapr> I thought I read that it was only because no one has done it
07:42:45 <o3> shapr: i'm pretty sure that chilli has told me that ghc itself can't be a .so for various reasons, although i might be wrong about that
07:43:19 <shapr> I don't really understand the issues enough to even ask the right questions...
07:43:35 <shapr> I do know that my goal is to have runtime reloadable modules
07:43:51 <shapr> runtime upgrading would be even spiffier
07:44:04 * shapr creates a HaskellWiki page
07:44:25 <cleverdra> shapr - where?
07:45:44 <shapr> http://purl.org/wiki/haskell/RuntimeModuleLoading
07:49:12 <ski> any ghc docs (haddock) for RuntimeModuleLoading on the web ?
07:49:32 <shapr> I think it's WYSIWYG
07:50:04 <o3> ski: not yet.  i need to install the new version of haddock before that happens ...
07:50:07 <o3> (adds to todo list)
07:51:15 <shapr> the #c guys said that .o files are linked in at compile time, .so files at runtime
07:51:29 <shapr> so how does ghci do that?
07:51:29 <ski> o3 : which ghc version ? 5.02.3 ? 5.04 ?
07:52:01 <o3> ski: haddock, you mean?  i use ghc 5.04, haddock ... 0.3, i think
07:52:09 <ski> .o at link time to be pedantic :)
07:52:18 <shapr> ok, good point
07:52:23 <o3> shapr: ghci is different, it loads in .o modules at runtime
07:52:45 <ski> o3 : no whet version of ghc contains RuntimeLoader ?
07:53:06 <shapr> ski: o3 wrote RuntimeLoader, it's not the base yet, you gotta grab it from his page
07:53:18 <ski> perhaps one could say "static link time" as opposed to "dynamic link time" ..
07:53:24 <o3> ski: oh.  sorry, the page is misleading, ghc doesn't include runtimeloader (yet) -- grab that example from the algorithm page
07:53:27 <ski> ah, ok
07:53:41 <o3> i'll go update it now, i think that's at least the second time somebody has said that
08:01:17 <o3> yay, page updated
08:01:22 <o3> that should make things clearer
08:02:06 <ski> (just paragraph added at bottom ?)
08:03:18 <o3> nah, i modified a few
08:03:56 <ski> ok, i'll reread it from the beginning then. thanks !
08:04:37 <ski> (but you didn't change the archive now ? because in that case i have to download it again :)
08:05:50 <o3> no, there's no archive change :)
08:05:57 <ski> ok
08:08:13 <ski> (um, should it say "(Last modified at 2002.10.10, 0:59 by ozone)" at the very bottom ? i thought it was the 9th of October now (or is it tenth in austria (australia) ?))
08:10:13 <o3> 10th in .au
08:10:16 <o3> Thu Oct 10 01:10:15 EST 2002
08:10:38 <Heffalump> shapr: btw, I was actually hoping to use Haskell to make dynamically loadable Apache modules
08:10:39 <ski> Wed Oct  9 17:10:23 MET DST 2002  in GBG in Sweden
08:10:56 <shapr> Heffalump: oh well
08:12:05 <o3> Heffalump: what's stopping you?
08:12:11 <Heffalump> time :-)
08:12:13 <o3> i was thinking of doing the same for my thesis
08:12:15 <o3> oh 8)
08:13:21 <o3> rightio
08:13:27 <o3> naptime -- night
08:13:28 <Igloo> Waaah, people aren't allowed to check in new TH stuff before I have a fast machine!
08:13:53 <shapr> TH?
08:14:03 <shapr> Template Haskell
08:15:14 <Igloo> Yup
08:17:25 <Heffalump> who checked in?
08:18:27 <Igloo> SPJ
08:20:29 <Heffalump> he hasn't emailed the list about the vote thing, has he?
08:20:50 <Igloo> Oh, I completely forgot about that. Not that I've seen,
08:21:04 <Heffalump> hmm. he did say he would.
08:26:02 <shapr> vote thing?
08:26:27 <Heffalump> about the copyright on the report
08:26:57 <Heffalump> check logs for the time of the future of haskell discussion at the Haskell workshop (17:00EDT on Thursday 3rd IIRC)
08:28:00 <shapr> oh
08:29:46 * shapr tries to find .so and .o info files
08:30:00 <shapr> gcc-3.2 docs don't seem to have it, nor do ld docs
08:30:06 * shapr wonders where they could be
08:35:28 <shapr> hi hal
08:35:38 <shapr> hi teeku
08:35:41 <hdaume> hi
08:35:58 <shapr> hey hal, have you played with the Runtime module loader any?
08:36:09 <hdaume> nope, sorry
08:36:16 <shapr> ok, just wondering
08:52:46 <shapr> hi sili
08:54:58 * shapr bounces
08:55:09 <shapr> Heffalump: of course, HWS with loadable modules would be far cooler.
08:55:37 <Heffalump> not unless you can make it as flexible and performant as Apache
08:56:03 <shapr> it's actually pretty close in the benchmarks from the HWS paper.
08:56:19 <shapr> above a certain very large number it's worse
09:00:31 <shapr> my fixes get rid of some of the speedy parts
09:00:55 <shapr> I had to hack out the the mutable array stuff (since I don't know how to really fix it)
09:36:34 * shapr bounces
09:38:45 * liiwi rolls
09:43:23 <shapr> hi liiwi!
10:03:20 <ludde> how do I handle multiple variable scopes in a big-step semantics?
10:03:31 <shapr> ?
10:03:43 <ski> what do you mean by multiple variable scopes ?
10:03:52 <shapr> hi toadx
10:03:56 <toadx> hello
10:04:35 * toadx hopes to build a FreeBSD + Haskell system today
10:04:44 <ludde> ski: like in C, the variables inside a { } are in their own scope
10:04:46 <shapr> yay haskell!
10:05:35 <ski> ludde : aha, you mean local scopes, with perhaps possibility of over-shadowing variables in outer scopes ?
10:06:11 <cleverdra> test = let x = 1 in let x = 2 in x
10:06:47 <shapr> what are big-step semantics?
10:06:51 <ludde> ski: i know how to do it in haskell, basically my environment is [[(Variable,Contents]]
10:07:10 <ludde> ski: The outermost list has one entry for each "scope" level
10:07:27 <ski> shapr : big-step (operational) semantics is when you define a relation between expression and final result
10:07:58 <ski> shapr : small-step (operational) semantics is when you define a relation between expression and expression reduced one more step
10:08:16 * shapr knows nothing of such things
10:08:48 <ski> ludde : ok, we did it as [(Variable,Contents)] but your solution (with list of lists) is probably better
10:11:43 <ski> ludde : hmm, well perhaps your list of lists is better ... hmm i think i could rework the semantics so it uses a list of lists instead (or, if you prefer, a stack of aactivition-records :)
10:14:41 <ludde> ski: how do you handle variable shadowing?
10:15:03 <ski> well our variable access is basically :
10:15:12 <ski> --------------
10:15:16 <ski> <x,M> =>e M[x]
10:16:39 <ski> so we just had a single environment, not a list (stack) of them as you had. but probably this can be reworked to extract the value of x in the first environment in the env stack that x occurs in (implementing shadowing)
10:17:45 <ski> and we only did allow variable declarations (includes memory allocation) in a block statement (and only at the top of it)
10:20:08 <ski> so the more interesting things are how are the new bindings from a declaration in top of a block included into the environment ? (and also how to combine several variable declarations so that one can declare more than one variable at the same time (in the same block, i.e.))
10:20:53 <ski> ludde : did you more or less get the semantic rule for variable access above ?   or do you want me to explain it ?
10:21:10 <ludde> ski: i'm trying to ssh to my lab account :)
10:21:30 <ski> (M stands for Memory, i.e. state (we already use S for statement :) )
10:21:36 <ski> ludde : ok
10:22:08 <ski> (So we have more or less conflated memory/state and environment here :)
10:22:55 <ludde> ski: I don't understand what the e next to => means.
10:23:00 <ski> oh
10:24:07 <ski> thats just our way of saying that this is the (big-step) relation for *Expression* as opposed to =>s which we use for *Statement* (this is perhaps not totally neccesary, though)
10:24:34 <ski> you get it ?
10:24:47 <ludde> ah
10:24:48 <ludde> yeah
10:25:12 <ludde> that's what's my variable access looks like too
10:25:14 <ski> (so it's there to more or less avoid the ad-hoc overloading of the relation)
10:25:23 <ludde> ad-hoc?
10:25:47 <ski> ad-hoc overloading, as opposed to overloading though type-classes
10:25:56 <ski> as in C++ and Java
10:26:51 <ludde> ok, right.
10:27:18 <ludde> my problem is that the semantics doesn't correspond to the implementation though.
10:27:44 <ludde> since the semantics treats the environment as a single list
10:27:52 <ski> so the M[x := V] bit is syntactic sugar for a function taking a variable name, a value and a memory/state/environment and gives a new "updated" memory
10:28:05 <ski> i think this is the usual interpretation
10:29:10 <ludde> Also, I have a SGroup [Statement] constructor in the Statement (which corresponds to { } in C)
10:29:34 <ludde> my semantic for that one looks like:
10:29:46 <ludde>           (p1,s) => s1 
10:29:46 <ludde> -----------------------------------
10:29:46 <ludde>       (SGroup p1, s) => s1
10:30:10 <ludde> but I need to specify in some way that a new scope is to be created before evaluating p1, and also removing the new scope when done.
10:30:11 <ski> if you want a list/stack of environments, you either have to specify it some other way, or perhaps using the same notation but noting that your _[_ := _] function takes a stack of environments instead of one environment (since this seems to be the conventional interpretation)
10:30:46 <ludde> (i.e. adding an empty list to the beginning of the environment before running p1, and removing this element when done.
10:30:56 <ludde> that's what I do in the interpreter code.
10:31:16 <ludde> hmm
10:31:28 <ludde> what do you mean by the _ in _[_ := _] ?
10:31:35 <ludde> ah, nevermind
10:31:54 <ski> so can you have variable-declarations anywhere is your statement lists, or only at the top of a block (i.e. SGroup). (Or perhaps you don't have explicit declarations at all (as C=64 BASIC did it :) )
10:31:55 <ludde> but is it considered formal if I write how [ ] behaves with text
10:32:10 <ludde> ski: I have explicit declarations, anywhere in the group
10:32:25 <ski> text ?
10:32:34 <ludde> english text
10:32:53 <ski> sorry, i still don't understand what you mean.
10:33:16 <ski> ok (i.e. you have explicit declarations, anywhere in the group)
10:33:17 <ludde> is it considered formal if I write how a[b] behaves using english language? don't I need to use formal notation?
10:34:28 <ludde> i.e. is it okay to explain how it should work by using a few sentences of english
10:34:54 <ludde> do you understand what I mean?
10:35:10 <ski> i don't know exactly :)  but i think that an english description of your modified _[_ := _] should be appropriate, because it isn't obligatory to do the rest of the semantics in the formal style either. but i think it has to be sufficiently unambiguous
10:35:19 <cleverdra> GHC probably won't understand you, but a student may be relieved.  What are you doing?
10:35:48 <ludde> cleverdra: I'm creating a formal operational semantics for a language I invented (it's a laboration in school)
10:36:05 <cleverdra> ah.
10:36:25 <ski> well, it doesn't nessecarily have to be formal (but as they said, the formal one is probably shorter :)
10:36:45 <ski> s/nessecarily/neccesarily/
10:37:08 <ludde> ok
10:37:46 <ski> ok so you have declarations anywhere (like C++ and Java but not C (well perhaps C99 ?))
10:38:07 <ludde> ski: yes
10:38:29 <ludde> ski: SType Type VariableName is a constructor in Statement
10:39:19 <ski> but how do you interpret that ? do you just add a memory cell to the top environment when elaborating a declaration. and then all cells in the top environment/state are of course discarded as the block/group is left ?
10:39:29 <ski> ok
10:39:31 <ludde> ski: I handle it by adding the new type to the head of the list which is on top of the environment stack.
10:39:43 <ski> ok, i though that
10:40:04 <ludde> then when I leave the environment, I simply discard the element at the top of the stack.
10:40:11 <ludde> err, s/environment/block/
10:40:26 <ski> perhaps you'll want to look at our semantic definition of our declarations and block ?
10:40:38 <ski> ok
10:41:07 <ludde> sure, but i'm not sure if it would help since you're using a single list. 
10:41:15 <ludde> can you expressions modify the environment, btw?
10:41:24 <ski> (that, is a little simpler that what we did, so your interpreter is probably a little bit simpler in that than ours :( )
10:41:26 <ludde> s/you/your/
10:42:08 <ski> well, it could perhaps help with ideas about how to represent your design decision formally ..
10:42:33 <ludde> yeah, ok
10:42:59 <ski> no, our expressions are side-effect free (exept division-by-zero (IIRC), but that halts the program)
10:43:29 <ski> well our assignment is :
10:43:35 <ski>       <E,M> =>e V
10:43:43 <ski> -----------------------
10:43:47 <ski> <x = E,M> =>s M[x := V]
10:44:06 <ludde> heh, mine is
10:44:07 <ludde>       (e1,s) => (v1,s1)
10:44:07 <ludde> ---------------------------------------
10:44:07 <ludde>   (x=e1,s) => (v1,s1[x=v1])
10:44:23 <ludde> pretty similar
10:44:45 <ski> (so you'll proboably have to redefine the _[_ := _] here)
10:45:25 <ludde> or just write as a comment that [] writes to the first matching variable searching the stack from top to bottom.
10:45:51 <ski> but your s1[x=v1] doesn't accurately dislay the stack of states (unless the update is redefined from the conventional, as said) ?
10:46:55 <ludde> it won't work unless I "overload" the _[_=_] operator by writing a few explaning lines, no :)
10:47:00 <ski> you'll need some syntax of saying how to add a new (empty) frame to your stack, as well as remove the frame when leaving a block
10:47:11 <ludde> yeah
10:47:40 <ludde> would it be okay to write:
10:47:42 <ludde>           (p1,[]:s) => _:s1
10:47:42 <ludde> -----------------------------------
10:47:42 <ludde>       (SGroup p1, s) => s1
10:47:58 <ludde> (assuming : means what it does in haskell)
10:48:14 <ski> *or*, you describe it more explicitely by, say inventing another function you'll use instead of _[_ := _] (same for _[_]) and then define it in terms of the original _[_ := _] ..
10:48:55 <ludde> but i have no idea how to write an operational semantics which implements that behavior.
10:48:57 <ski> yeah, i think so. So long as you explain what you new syntax means, somewhere (perhaps formally).
10:49:38 <ski> so you : here is an example of what i just said (in the "*or* ..")  :)
10:49:57 <ski> s/you/your/  s/:/":"/
10:51:09 <ski> so our update in the haskell interpreter has type  (Var,Value) -> Memory -> Memory   where our Memory = [(Var,Value)]
10:51:40 <ludde> writevar :: String -> Int -> Environment -> Environment
10:51:51 <ski> yeah
10:52:02 <ludde> (I represent booleans as ints in the interpreter)
10:52:38 <ski> but your Environment = [[(Variable,Contents]] i believe
10:52:44 <ski> ok
10:53:00 <ludde> right
10:54:44 <ski> but perhaps, you should replace your _ in the nearest rule about with a variable (not sure, but i think i haven't seen any wildcards in operational semantics). perhaps not too important ...
10:55:32 <ski> so what you your variable declaration rule be ?  or would you rather see mine first ;)
10:55:56 <ski> s/you/would/
10:56:06 <ludde> no, I can give you mine, but i'm currently editing it
10:56:10 <ski> ok
10:56:46 <ludde> -----------------------------------        
10:56:46 <ludde>  (SType _ t, (x:xs)) => (((t,0):x):xs)
10:57:08 <ludde> (the t is the variable name)
10:57:20 <ski> what's the first argument to SType ?
10:57:24 <ludde> the type
10:57:25 <ski> the type ?
10:57:26 <ski> ok
10:57:56 <ludde> i'm not really sure if this is the way i'm supposed to write an operational semantics though
10:58:06 <ludde> it maybe looks too much like haskell?
10:58:24 <ski> (i would perhaps write the last line as "(SType _ x, (f:fs)) => (((x,0):f):fs) but what the heck)
10:59:09 <ski> i don't think that's a large problem as long as you somewhere explain a little what you mean by : and stuff
10:59:09 <ludde> what is the f an acronym for?
10:59:23 <ski> f = frame = activition frame/record
10:59:29 <ludde> oh
10:59:43 <ski> could use a also, or anything else
10:59:56 <ludde> yeah, it's just a name :)
11:01:22 <ski> i think thats a standard terminology, but there are probably other words. i just not so fond of using x for this concept which is neither a number (as in x*x - x = 0) or a variable (as i used x above) or can stand for anything (as in your everyday polymorphic functions)
11:01:27 <ski> yeah
11:01:54 <ski> your mileage may vary :)
11:02:21 <ludde> mileage ?
11:03:29 <ski> just a saying :)  it means that one is accepting that other persons may/can (is allowed to, according to oneself or society moral) to have a different opinion or preference. satisfied ? :)
11:03:48 <ludde> ok, yes.
11:04:07 <ski> (also commonly abbreviated as YMMV)
11:04:18 <ludde> i've never heard it before
11:04:36 <ski> first time i say it, i think was on usenet
11:04:42 <ludde> anyway, i had problem with reading/writing from the user
11:04:48 <ludde> how do I specify that in the semantics?
11:04:49 <ski> s/say/saw/
11:05:01 <ski> what ?  that YMMV ? ;)
11:05:03 * ludde is not really a usenet you
11:05:06 <ludde> you=guy
11:05:15 <ludde> no
11:05:20 <ludde> the language has In and Out constructs.
11:05:28 <ludde> In:
11:05:28 <ludde>        read_keyboard => x
11:05:28 <ludde> -----------------------------------
11:05:28 <ludde>       (SIn v, s) => s[v=x]
11:06:02 <ski> so your variable declaration and block entering and exiting and variable accesses are finished/correct then (?)
11:06:07 <ski> ok
11:06:09 <ludde> yeah
11:07:47 <ludde> is it okay to write the In rule like that?
11:07:50 <ski> we just included a non-formal english description (well a little formal :) of how to read from input and write to output. cuz we though it would be too cumbersome to make a full-fledged semantics tracking the inputs and output (quite complicated i think)
11:08:04 <ludde> ski: okay
11:08:12 <ski> you want to see our read rule ?
11:08:35 <ludde> it's enough if you comment my rule :)
11:08:44 <ludde>        write_screen s[v] 
11:08:44 <ludde> -----------------------------------
11:08:44 <ludde>       (SOut v, s) => s
11:09:10 <ludde> that last one is not really right
11:09:18 <ski> ok (our rule had 4 rows (albeit short) of english text for read and two for write :)
11:10:03 <ski> hmm, so you only write the contents of a variable, not the value of an expression ?  (for symmetry, right ?)
11:10:14 <ludde> that's correct.
11:10:27 <ski> we had
11:10:28 <ski> <E,M> =>e V  (run-time system converts V to its
11:10:32 <ski>               textual representation and prints it)
11:10:34 <ski> ---------------------------------------------------
11:10:37 <ski>                  <write E,M> =>s M
11:10:41 <ludde> we initially had a more general syntax for input/output, but Marvin-- thought it would become too complex to implement type systems for it.
11:11:05 <ludde> in/out was implemented as function calls
11:11:18 <ski> (ok, so you and Marvin-- are in the same labgroup)
11:11:25 <ludde> no, he's my lab corrector
11:11:31 <ludde> :P
11:11:42 <ski> (ok :)
11:12:02 <ludde> but I didn't know this channel existed at that time, so I didn't know that my lab corrector in fact was Marvin--
11:12:11 <ski> (i don't really know how Marvin-- looks like yet)
11:12:15 <ski> :)
11:12:31 <ludde> he has long red hair
11:12:47 <ski> aha, then i know who he is
11:13:00 <ludde> I don't know what you look like :)
11:13:38 <ski> maybe unfair, because i know how you look like (seen you on AFP, matching your description)
11:14:11 <ski> i'm quite short and looks mostly ordinary looking
11:14:22 <ludde> hmm, doesn't really tell me a lot :)
11:14:35 <ski> rat-colored hair
11:14:41 <ski> (more or less :)
11:14:59 <ludde> you have a bicycle?
11:15:03 <ludde> (to school)
11:15:32 <ski> yes, a orange one (though it's quite broken by now. should probably buy a new one soon)
11:15:38 <ski> s/a/an/
11:16:29 <ludde> was it you that told the supervisor about lacking () around (x:xs) on the first exersice on wednesday 15-17 ?
11:17:08 <ski> (everybody : i hope we're not boring all the others about this trivia and this local GU/Chalmers laboration ..)
11:17:20 <ski> what course ?
11:17:25 <ludde> programspråk
11:18:23 <ski> hmm, yes, can have been me. not totally sure, though (don't remember)
11:18:30 <ski> s/can/could/
11:18:55 <ludde> the supervisor forced people to write a solution on the black board, and someone wrote a pattern match without () around (x:xs)
11:19:14 <ludde> I think you wrote the solution for:
11:19:14 <ludde> Infer the types of the following functions: 
11:19:15 <ludde> a. 
11:19:15 <ludde> \n x -> x 
11:19:15 <ludde> b. 
11:19:15 <ludde> \(_,(x,_)) -> x 
11:19:17 <ludde> c. 
11:19:19 <ludde> \(x,y) -> (y,x) 
11:19:29 <ludde> (if that's you)
11:20:08 <ski> yes :) but i'm still not totally sure if that was me. But it was me who discovered a slight discrepancy between two BNFs for Lambda Calculus :) if you can remember that
11:20:41 <ludde> I havn't been on any more exersices.
11:21:18 <ski> (don't remember if that was the first exercise time or not)
11:21:44 <ludde> the first exercise only covered basic haskell stuff.
11:21:53 <ski> (hmm, the BNF was in exercise 2 the webpage tells me)
11:21:59 <ski> yes
11:23:02 <ski> hmm, i think it was me who (publically) inferred the type of the expressions is exercise 1.2, which you pasted above
11:23:08 <ski> yes, i did
11:23:37 <ludde> ok, in that case I know who you are :)
11:23:42 <ski> ok, good
11:24:04 <ski> (so you have seen me on AFP lectures as well, i suppose ?)
11:24:06 <ludde> I drove into your table slightly when you had a cup of (coffee?) on it last week?
11:24:28 <ski> perhaps. i don't remember (again !)
11:24:31 <ludde> heh
11:24:37 <hdaume> someone has a terrible memory :)
11:24:57 * ludde has a pretty good memory
11:25:21 <ski> yes, sometimes my memory seems to be plain bad. *or* perhaps i don't pay enough attention to the outside world ;-)
11:25:26 <ludde> did you sit to the right of the projector on the last AFP lecture?
11:25:41 * ski tries to remember ...
11:25:49 <ludde> haha, ok, I won't ask anything more :)
11:26:20 <ski> hmm, i think i actually sat right behind the projector (but perhaps that was the previous lecture ..)
11:26:41 <ludde> yeah whatever, but I think I noticed you standing right to the projector during the pause.
11:26:59 <ludde> right of the
11:27:07 <ludde> whatever, never mind.
11:27:18 <ski> could likely have been, cuz i think i asked Roorda some questions (or maybe just one)
11:28:13 <ludde> there was some other one which asked roorda a lengthy question
11:28:34 <ski> so i think, that a english description of I/O in the formal rules ought to be ok, if they are more or less clear
11:28:41 <ski> perhaps
11:29:57 <ski> so youv'e stared with AFP lab 2 yet (or perhaps already finished ?) (i haven't started yet)
11:30:08 <ludde> i'm done with it
11:30:13 <ski> s/youv'e/you've/
11:32:06 <ski> ok, i had some problems with handing in lab 1 which i didn't detect until last week, and my lab had a minor deviancy from the lab corrector idea of what it should do, so i have to fix that also (and i have had a problemfull concurrent lab 2, *whine* *whine* , etc)
11:32:29 <ludde> the parallell composition feature?
11:32:34 <ludde> paralell
11:32:49 <ski> yes. i think i mentioned it someday before here
11:33:11 <ski> (i think the hompage uses parallel, but frankly i'm not sure what
11:33:13 <ludde> yeah, i don't remember, but I've heard someone mentioning it.
11:33:19 <ski> what's the correct spelling)
11:33:32 <ludde> parallel :)
11:33:51 <ludde> (according to my dictionary)
11:33:59 <ski> ok, so be it then.
11:38:13 <ludde> the concurrency paper by koen was very good
11:38:21 <ludde> (as lab2 help)
11:38:43 <ski> i have printed it out but haven't read it yet ..
11:46:06 <ludde> ski: have you decided what you will do in lab 4?
11:46:15 <ski> what course ?
11:46:49 <ludde> programming languages
11:47:11 <ski> no
11:47:27 <ludde> bbiab, reboot.
11:50:39 <ski> bbiab ?
11:50:46 <ludde> be back in a bit
11:50:52 <ski> ok
11:51:41 <ludde> i installed TortoiseCVS, it gives you CVS support in explorer.exe
12:38:18 <|Fo|Ns> hi
12:38:28 <ski> hi
12:39:57 <ski> you wanted to ask/discuss something ? :)
12:40:19 <|Fo|Ns> ski: no, not now
12:40:21 <|Fo|Ns> :)
12:40:42 <|Fo|Ns> well, just a thing
12:40:48 <ski> 'Kay .
12:41:10 <|Fo|Ns> can I use gdb to debug compiled hs files?
12:41:30 <hdaume> yes, but it's not very pretty :)
12:41:43 <hdaume> (as long as you go -fvia-c)
12:50:43 * shapr wonders whether runtime module loading or counterstrike is more tempting
12:50:58 <ski> counterstrike ?
12:51:10 <shapr> it's a first person shooter game, kind of like Quake
12:51:30 <ski> umhm
12:51:54 * BlizzNL remembers the time he did nothing but counterstrike for months ;)
12:52:16 <shapr> yah, the downside of counterstrike is how much time it takes away from coding.
12:52:41 <BlizzNL> shapr: indeed, I completely deleted it including my online code for self protection
12:52:48 <shapr> wow
12:52:57 <shapr> I deleted windows.
12:53:04 <shapr> but now counterstrike runs on winex
12:53:35 <BlizzNL> hehe .. I know it's rigorous but my coding and girlfriend really are happy with it ;)
12:53:39 <shapr> heh
12:53:41 <shapr> I understand.
12:54:02 <shapr> yah, last time I quit counterstrike I got very much stuff learned and written.
12:54:36 <BlizzNL> BTW I never played a game since.. Nothing can beat counterstrike
12:54:56 <shapr> yah, it's the best and also the most addictive.
12:57:16 <cleverdra> bah.  empire.cx
12:58:34 <shapr> full icfp scores are online
12:58:40 <shapr> http://icfpcontest.cse.ogi.edu/scoring/
12:58:47 * shapr tries to figure out which one is postman
13:00:12 <BlizzNL> see you later, good night
13:00:23 <shapr> we got 620
13:00:24 <shapr> hmm
13:02:44 <Igloo> We're quite high u pthe first table
13:03:04 <Erwin> My Python submission (#269) placed 25 in round 0
13:03:16 <Erwin> Weird though, I used 0.70 cpu seconds according to the table (?!)
13:03:19 * Igloo tries to find a list of team -> sub number mappings
13:03:46 <Erwin> I'm not sure what the 4 in 0.70s/4 means
13:04:16 <hdaume> probably averaged over 4 runs?
13:04:25 <shapr> igloo: we're submission 172 I think
13:04:50 <Igloo> Yeah, I was wondering about other teams I know, though
13:04:56 <shapr> looks like being flushed was our most common death
13:05:11 * hdaume wishes he had entered :(
13:05:34 <shapr> next year :-)
13:05:38 <hdaume> yeah
13:05:53 <hdaume> right in the middle of working on my thesis ;)
13:06:02 <shapr> what's your thesis about?
13:06:13 <shapr> plus, it's only 72 hours, and it's worth it
13:06:21 * hdaume is not entirely sure yet...something related to automatic document summarization, undoubtedly
13:06:47 <shapr> you going to use compression programs to analyze the structure?
13:06:50 <Erwin> Oh, there are detailed logs too
13:07:26 <shapr> ah, it looks like Postman died with a 500x500 map
13:07:30 <hdaume> shapr: in what sense?
13:07:32 <Igloo> Did chilli say that TeamGHC came second in the lightning tournament?
13:07:58 <shapr> well, compression programs look for redundancy
13:08:19 <Igloo> Hmmm, if htey were 8 then they did better than us
13:08:20 <shapr> I'd use that to find the structure of the document
13:08:55 <hdaume> ah...i see what you mean...the problem is that it's very difficult to identify if two phrases (for example) overlap and if so which shoul dbe kept (if either)...
13:09:10 <hdaume> just using word overlap isn't really sufficient
13:10:01 <hdaume> sharp: i'm trying to develop a machine learning scheme for learning how to do summarization based on looking at example document/human-generated-summary pairs
13:10:05 <shapr> well, assuming a thesis statement and then expansion on the thesis in the rest of the doc
13:10:14 <shapr> oh, that's interesting.
13:10:35 * shapr thinks about that
13:10:46 <shapr> neural network?
13:10:57 <hdaume> most of the work to date has been very ad-hoc...there's really no way to tell whether what's coming out is actually what humans would do or not
13:12:03 <hdaume> the most recent working system i have which only works on extractive summaries (rather than abstractive summaries) uses a noisy-channel, information theoretic model (http://www.isi.edu/~hdaume/docs/daume02noisy.ps)
13:12:32 <hdaume> basically it says "okay we have a document d.  i'
13:12:49 <hdaume> m going to guess that the summary is s.  now, what's the sequence of steps i would need to take to expand s to d"
13:12:55 <shapr> I think I'd try to make one of those spiffy non-deterministic neural networks based on Mikhail Zak's work.
13:12:58 <hdaume> the most likely expansion gives us the most likely s.
13:13:05 <hdaume> in haskell?
13:13:09 <shapr> yup
13:13:13 <hdaume> cool!  :)
13:13:33 <shapr> that's how I would try to make document summaries.
13:14:12 * shapr download's hal's paper
13:14:20 <hdaume> i believe there's a guy at U Mich using NNets to do summarization...i'm not sure how much success he's had
13:15:16 <shapr> imho, M. Zak's terminal chaos nnets would be the best for that sort of thing.
13:15:28 * hdaume needs to read more about that :)
13:16:09 <shapr> I've never even thought about automatic document summarizing before, so that might be waaay off
13:20:37 * shapr gives in to counterstrike
13:20:43 <hdaume> have fun :)
13:38:55 <Heffalump> is the ICFP page slashdotted or something?
13:44:52 <Erwin> It's not on slashdot, but it's also inaccessible from here.
13:45:46 <hdaume> down here too
13:46:21 <Heffalump> I didn't mean literally slashdotted
13:48:18 <Erwin> So it's a common verb for overloading/overrunning something now? Are we going to hear Bush saying he'll slashdot Iraq then? :) "First post, Saddam! BLAM!"
13:48:56 <Heffalump> :-)
13:49:36 <o3> 06:14 <hdaume> i believe there's a guy at U Mich using NNets to do summarization...i'm
13:49:40 <o3> whoops
13:49:42 <o3> morning
13:50:10 <hdaume> hi
14:38:28 <Igloo> Aarg, I think I managed to build all the GTK stuff with the wrong version of GHC
14:39:07 <hdaume> oops
14:53:40 <Heffalump> btw, we came 32nd in round 0 of the ICFP scoring
14:53:55 <Heffalump> (I think)
14:58:11 <Igloo> Oh, the team names are there, only hidden
14:58:24 <Heffalump> you have to do the lookup yourself
14:58:47 * Igloo makes it 39 after round 1
14:58:49 <Igloo> What lookup?
14:59:03 <Igloo> If I put the mouse cursor over a team number I get a tooltip with the name
14:59:19 <Heffalump> oh
14:59:38 <Igloo> And 32 after round 0, yup
15:00:07 <Igloo> Looks like TeamGHC weren't in the top 20 after round 1 either
15:00:08 <Heffalump> better than I expected
15:00:13 <Igloo> Yeah
15:00:30 <Heffalump> Oege is talking about the group doing an entry next year, btw
15:00:38 <Heffalump> s/talking about/suggesting/
15:00:46 <Heffalump> apparently he's suggested it before and nothing happened, though
15:01:34 <Heffalump> 38 or 39 after round 1
15:02:09 * Igloo finds there are similar things for the results
15:03:02 <Igloo> I'm puzzled by the first yellow one. I wonder if that's the bug I realised we had when the packages were already where they had to be delivered - but I thought that we'd just move randomly rather than break
15:03:17 <Heffalump> TeamGHC's 3 day entry was 19th or 20th in round 1
15:03:18 <Igloo> Cool - does he know we entered as part of #haskell this year?
15:03:42 <Heffalump> he knows we entered with other random people, I didn't describe #haskell in detail
15:03:55 <Igloo> Right
15:05:03 <Igloo> Cool, we beat london.pm  :-)
15:05:26 <Heffalump> phew :-)
15:05:40 * Igloo wonders what X means
15:05:44 <Igloo> (they are 139 BTW)
15:06:11 <Heffalump> nothing perlish beat us
15:06:17 <Heffalump> X means it died early on
15:06:39 <Igloo> No, but C, Java, ...
15:06:50 <Heffalump> yeah :(
15:07:15 <Igloo> Still, they probably put more man hours in than us  :-)
15:07:37 <Igloo> There's a python too
15:08:36 <Igloo> More than one. Unless that isn't perlish, in which case I can't think of anything that is that isn't perl  :-)
15:09:13 <Heffalump> I meant nothing that used perl
15:09:19 <Heffalump> as in a perlish entry, not a perlish language
15:09:26 <Igloo> Ah, right
16:47:10 <vtra238> hi 
16:51:01 <ski> hi
16:52:35 <vtra238> i'm trying to figure out a function that takes only the last digit of a number
16:52:49 <vtra238> i know there must be some simple solution
16:53:06 <vtra238> but i just can't think of it atm
16:53:25 <vtra238> can some1 help plz
16:55:06 <hdaume> hi
17:03:52 <ski> well, can't you use modulo ?
17:04:02 <ski> (was away for a little while)
17:04:09 <vtra238> modulo...
17:04:13 <vtra238> hmm lemme see
17:04:55 <ski> 16 modulo 7 is 2 because 16 = n * 7 + 2 (for some n, in this case 2)
17:05:25 <ski> so if you use  x modulo 10 you get the last digit (in base 10 i.e.)
17:05:39 <ski> modulo in haskell is "mod"
17:05:44 <ski> used like :
17:05:48 <ski> mod 16 7
17:05:56 <ski> or if you like this better :
17:06:00 <ski> 16 `mod` 7
17:06:18 <vtra238> oh yea
17:06:22 <vtra238> thats it
17:06:28 <ski> does that solve your problem ?
17:06:32 <ski> ok
17:06:36 <vtra238> i knew it was dividing by 10
17:06:51 <vtra238> thank a bunch
17:07:30 <ski> yes, but you want the rest (modulus) of integer division (so float/real division "/" won't work here)
17:08:10 <ski> "div" is integer division (ignoring the rest) and "mod" is just the rest  (rest = modulus)
17:08:41 <ski> you can get both at the same time if you want, by "divMod" (returns a pair of integers)
17:09:09 <vtra238> yea so basicly instead of writing a recursive div function mod does it for you
17:09:55 <ski> yes, and probably much more efficiently as well (using processor instructions for it directly, probably)
17:10:16 <vtra238> yes i suppose
17:12:18 <ski> so the time it takes to do a "mod" or a "div" (or a "/" for that matter) doesn't depend on how big the number is, as it would depend on if using recursion  (well, if you use (arbitrarily precision) Integers, it probably *does* depend on how big the numbers are. but that's another matter)
17:17:12 <ski> ok
17:17:21 <vtra238> oh ok
17:18:10 <ski> you wanted anything else ?  otherwise i think i'll go home and sleep now (local time is 3 after midnight :)
17:19:28 <tche369> are u al good as ghci?
17:19:48 <hdaume> tche369: i think that's  probably a pretty safe bet
17:19:59 <ski> excuse me, i don't understand what you mean
17:21:01 <ski> ok, i'll be leaving now. bye !
