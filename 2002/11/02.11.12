00:56:43 <Heffalump> ooh.
02:16:42 <Heffalump> yay, go Ross Paterson
02:53:12 <justme84> hi, can you help me with a problem? I'm learning haskell and wanted to write an I/O function that reads lines from input until it encounters a line equal to "EOF", and returns the read lines as the list, doing it all lazily
02:53:23 <justme84> something like:
02:53:34 <justme84> readLinesUntilEOF :: IO [String]
02:54:38 <justme84> but I can't get it to work, it doesn't want to stop on "EOF"
02:57:31 <justme84> it seems like it wants to read all the lines first, then return only those that are before the "EOF" line
02:59:19 <justme84> ok I see you're all sleeping or working... :)
02:59:48 <Heffalump> readContents or something is lazy, IIRC
03:00:07 <justme84> I'm just using getLine
03:00:16 <Heffalump> the IO monad is strict
03:00:25 <Heffalump> to do anything lazily with it you need to use unsafeInterleaveIO
03:00:31 <justme84> ah
03:00:39 <Heffalump> (which readContents or getContents or whatever the function I'm thinking of does)
03:00:46 <justme84> thanks, I'll look
03:01:11 <justme84> hm, in Hugs it's just primitive
03:02:21 <justme84> I wonder why it was hard to make the whole IO lazy
03:04:50 <Heffalump> you don't necessarily want the entire IO monad to be lazy
03:05:25 <Heffalump> your program might end up not doing something you expected it to, if you did that
03:05:56 <justme84> hm, actually this is the case with the function I just wrote :)
03:07:05 <justme84> inputStrings = do contents <- getContents
03:07:05 <justme84> 		  return (takeWhile ("EOF" /=) (lines contents))
03:10:11 <Heffalump> doesn't that do what you want?
03:10:39 <justme84> well, now it does
03:10:46 <justme84> :) I'll explain
03:11:10 <justme84> I tried to run this function in Hugs and it just stopped, didn't want any input at all
03:11:43 <justme84> but then I wrote another function to print all those lines that inputStrings gives it and it worked as it should
03:11:57 <justme84> I guess that's because of that laziness
03:12:35 <Heffalump> ah, yes.
03:23:43 <justme84> wow, it works perfectly now! :) thanks for your help
03:24:39 <Igloo> Cool  :-)
03:25:00 <Igloo> (to Ross Patterson comment up there ^)
03:29:36 <justme84> Is there any way to "make the IO lazy"? I originally wanted to have a function that would lazily give me a list of all Win32 messages my application receives, do you think it is possible to implement?
03:30:47 <Heffalump> justme84: well, unsafeInterleaveIO will do that
03:30:53 <Heffalump> dunno about for hugs, though
03:30:58 <justme84> ah, thanks, I'll look
03:30:59 <Heffalump> (unsafeInterleaveIO is GHC)
03:31:11 <Heffalump> but read the docs carefully, the word unsafe is in the name for a reason!)
03:31:19 <justme84> ok I will :)
03:44:39 <ibid> i thought unsafeInterleaveIO was commonly implemented, not just in GHC...
03:44:46 <ibid> (not standard though)
03:45:16 <justme84> I see unsafeInterleaveIO and interleaveIO in Hugs, and I wonder what is the difference
03:59:11 <Igloo> Hmmm, treating complex numbers as 2 separate doubles is even slower
04:26:44 * Igloo reads HC&A - looks like C-- support is coming
04:38:46 <Igloo> Heh, it looks like we'll have "FunGEn -- A game engine for Haskell" before a curses interface  :-)
04:38:53 <shapr> sounds okay to me
04:39:03 <Igloo> Hey shapr
04:39:15 <shapr> hi Igloo, how's Fraskell?
04:39:58 <Igloo> Well, I tries passing around zreal and zimag instead of z and it slowed down
04:40:10 <shapr> that's surprising
04:40:12 <Igloo> So now I'm just confused
04:40:16 <shapr> I would have thought Complex would be slower
04:41:04 <Igloo> Well I think it's all unboxed now, so definitely
04:53:20 <shapr> has anyone tried fungen?
04:53:33 <shapr> sounds to me like something to make mushrooms
04:53:41 <Heffalump> :-)
04:54:13 <ayrnieu> shapr - I've never been able to compile HOPenGL, but fungen looked nifty.
04:54:44 * ayrnieu understands that HOpenGL is integrating with GHC.
06:24:29 <justme84> where can I find documentation for Haskell functions? Some IO functions don't seem to be documented anywhere
06:24:44 <ayrnieu> justme - which ones?
06:24:51 <justme84> fixIO for example
06:25:01 <justme84> or interleaveIO
06:25:05 <justme84> or unsafeInterleaveIO
06:25:44 <ayrnieu> There are research papers that describe those, I think -- or you can infer their function from research papers and their types.
06:26:07 <justme84> can you point me to some papers?
06:26:10 <ayrnieu> You might also ask clf or one of the haskell lists.  (or here; but *I* don't know what any of those do)
06:26:40 <ayrnieu> justme - err, no.  There are many of them, and I don't remember when I got all of mine.  Look at www.haskell.org; look at Simon's web page.
06:26:48 <justme84> ok, thanks...
06:27:16 <Heffalump> http://www.haskell.org/ghc/documentation.html is quite good, but often GHC-specific
06:27:32 <ayrnieu> http://research.microsoft.com/Users/simonpj/
06:27:54 <ayrnieu> Heffalump - really?  I assumed that justme was looking at the GHC documentation on those as he wondered if they were documented anywhere.
06:28:11 <justme84> Heffalump I looked there but there are just types
06:28:34 <Heffalump> justme84: ah, ok
06:28:36 <justme84> or for unsafeInterleaveIO they say that it does lazy IO as you said, but they don't say what's unsafe
06:28:39 <Heffalump> there is sometimes more description
06:29:21 <ayrnieu> justme - 'unsafe' IO functions don't need to be tied to the IO monad (they 'create their own world'; this is something else you need a research paper for)
06:29:36 <justme84> now I have found a whole paper about fixIO...
06:29:52 <ayrnieu> justme - my favorite example:  globalVariable = unsafePerformIO newEmptyMutVar
06:29:58 <justme84> hmm
06:30:03 <ayrnieu> justme - oh?  Where is it?
06:30:08 <justme84> I understand what that does, I think
06:30:18 <ayrnieu> Haskell seems irritatingly undocumented at first (and it is) but the research papers are really wonderful.
06:30:19 <Heffalump> ayrnieu: interleaveIO isn't *that* unsafe
06:30:26 <justme84> http://www.cse.ogi.edu/PacSoft/projects/rmb/fics.pdf
06:30:39 <justme84> Heffalump what's the difference?
06:30:48 <justme84> i mean between interleaveIO and the unsafe version?
06:31:01 <Heffalump> there isn't one, I just left out the "unsafe" cos I'm lazy
06:31:09 <Heffalump> the only function that exists is unsafeInterleaveIO
06:31:10 <justme84> hm
06:31:13 <justme84> there are two functions in hugs
06:31:19 <Heffalump> it's only unsafe because you have no guarantees about the order things will happen in
06:31:20 <justme84> and the unsafe one calls the safe one
06:31:29 <justme84> so it's kind of strange
06:31:45 <ayrnieu> Heffalump - oh, OK.
06:54:14 <Vulpyne> Anyone around?
06:54:21 <Heffalump> me
06:54:45 <Vulpyne> Hi... I've been working on writing simple functions. Want to take a look and tell me what you think of my implementation?
06:54:50 <Heffalump> ok
06:54:56 <Vulpyne> It's 8 lines. May I paste?
06:55:40 <ayrnieu> Sure.
06:55:45 <Vulpyne> hasItem a [] = False
06:55:45 <Vulpyne> hasItem a (b:bs) | b == a = True
06:55:45 <Vulpyne>                  | otherwise = hasItem a bs
06:55:45 <Vulpyne> listWithout a [] = []
06:55:45 <Vulpyne> listWithout a (b:bs) | a == b = listWithout a bs
06:55:46 <Vulpyne>                      | otherwise = [b] ++ (listWithout a bs)
06:55:47 <Vulpyne> uniqueList [] = []
06:55:49 <Vulpyne> uniqueList (a:as) = [a] ++ (uniqueList (listWithout a as))
06:56:07 <Heffalump> [b]++ is b:
06:56:24 <Heffalump> but those functions look like they do what the name suggests they should
06:56:33 <Vulpyne> Well... I know it works.
06:56:33 * ayrnieu agrees.
06:56:41 <Vulpyne> I just want to know if it's the normal/good way of doing stuff. 
06:56:56 <Heffalump> yeah.
06:57:02 <Vulpyne> If you were writing it, what would you do differently to make it more efficient, etc.
06:57:04 <ayrnieu> I mostly notice what Heffalump already corrected.
06:57:11 <Heffalump> it's roughly how the prelude functions that do the same thing are implemented
06:57:20 <Heffalump> there's not much you can do to make them more efficient
06:57:26 <ayrnieu> Vulpyne - you could make all those more efficient with accumulators, of course.
06:57:33 <Vulpyne> Thanks.
06:57:36 <Heffalump> if you have an Ord instance for a type, you can remove duplicates on O(nlog n) time by sorting first
06:57:36 <Vulpyne> ayrnieu: Accumulators?
06:57:47 <Heffalump> no, he couldn't
06:58:04 <Heffalump> accumulators are useful when otherwise you'd add single elements on to the *end* of a list, which he's not doing here
06:58:13 <ayrnieu> Heffalump - he could make them all more space-efficient, no?
06:58:22 <Heffalump> ayrnieu: NAFAIK
06:58:39 <Vulpyne> I see what you mean about sorting.
06:58:42 <Heffalump> I don't understand space efficiency very well
06:58:42 <ayrnieu> Heffalump - aren't thos definitions non-tail-recursive?
06:58:52 <Heffalump> vulpyne: but of course there's not always an Ord instance
06:59:08 * ayrnieu wonders if they're optimized to be tail-recursive.
06:59:13 <Heffalump> ayrnieu: umm, I suppose, but they'll use stack space proportional to the size of the output list
06:59:18 <Heffalump> which is about the best you can hope for
07:00:08 <Vulpyne> Doh.
07:00:09 <justme84> hasItem a list = or map (== a) list
07:00:10 <justme84> ?
07:00:21 <Heffalump> justme84: yeah, probably
07:00:53 <Igloo> Or just     any (== a) list
07:01:23 <justme84> hmm
07:01:28 <Vulpyne> It would do something the same in the actual body for any, though... Wouldn't it?
07:01:47 <justme84> looks like Haskell has got a function for everything, now if it would only have docs for them
07:02:00 <Igloo> Vul: Huh?
07:02:14 <Vulpyne> Igloo: I mean, it's  going to end up iterating over the list in any/map anyway.
07:02:21 <justme84> probably
07:02:26 <Vulpyne> So it won't necessarily be faster or anything.
07:02:31 <Heffalump> Vulpyne: indeed
07:02:38 <Vulpyne> I do understand I'm reinventing the wheel. I just wanted something simple to write. :)
07:02:41 <Heffalump> but in general using more basic combinators is a good thing
07:03:02 <justme84> listWithout elem list = [x | x <- x list; x /= elem] ?
07:03:13 <Heffalump> s/x list/list/
07:03:14 <Heffalump> but yes
07:03:17 <justme84> yes
07:03:20 <Vulpyne> Fun.
07:03:25 <Heffalump> TMTOWTDI :-)
07:03:29 <justme84> :)
07:03:36 <justme84> that's what I like about haskell
07:03:45 <Heffalump> but all the ways are more elegant than perl :-)
07:03:46 <Vulpyne> Stealing Perl's motto, eh?
07:03:58 <Vulpyne> INTERCAL is more elegant than Perl.
07:04:06 <Heffalump> heh
07:05:47 <justme84> hm, actually that thing could be written using filter
07:05:52 <justme84> filter (/= elem) list
07:06:17 <Vulpyne> justme84: Your list comprehension doesn't work.
07:06:23 <justme84> yes, there's a typo
07:06:27 <justme84> ; should be ,
07:06:35 <justme84> and x <- x list should be x <- list
07:07:08 <Vulpyne> Ah ha.
07:07:11 <Vulpyne> Better.
07:07:17 <justme84> but filter is even better I think :)
07:07:34 * Vulpyne nods.
07:09:31 <Vulpyne> Filter probably just uses a list comprehension, right?
07:09:59 <justme84> I don't know, need to look
07:10:15 <justme84> yes it does
07:10:22 <justme84> filter           :: (a -> Bool) -> [a] -> [a]
07:10:22 <justme84> filter p xs       = [ x | x <- xs, p x ]
07:10:40 * Vulpyne nods.
07:11:01 * Vulpyne is happy to see that he didn't reinvent the wheel to be square. :)
07:11:07 <justme84> :)
07:13:55 <Vulpyne> hasItem a b | [x | x <- b, x == a] == [] = True
07:13:56 <Vulpyne>             | otherwise = False
07:14:00 <Vulpyne> I could write hasItem like that.
07:14:01 <Vulpyne> Hmm.
07:14:26 <Vulpyne> Probably not better.
07:17:38 <Heffalump> list comprehensions are actually implemented in terms of things that are essentially filter, map and concat
07:18:19 <Vulpyne> They're written in Haskell?
07:20:20 <Vulpyne> I guess it may not make sense to code like I'm using a script language.
07:21:50 <Igloo> They get transformed into essentially a cut-down form of Haskell by the compilers
07:23:39 <Vulpyne> So it's likely that either way, the same executable would be created by ghc or whatever?
07:31:30 <justme84> what's a fixpoint combinator?
07:31:43 <Heffalump> fix f = f (fix f)
07:31:52 <Heffalump> fix is the most basic fixpoint combinator there is
07:32:01 <justme84> hm, what is it useful for?
07:32:01 <Heffalump> Vulpyne: well, or similar, yes
07:32:12 <Heffalump> reasoning about fixpoints, mostly
07:32:27 <Heffalump> since in Haskell it's easier to write the explicitly recursive definition
07:32:32 <justme84> hm
07:32:51 <Heffalump> but if you recast your definition in terms of fix (...) where the ... isn't recursive in any way, you sometimes get a better idea of what's going on
07:33:54 <justme84> fix not = not (fix not) = not (not (fix not)) = fix not, hm
07:37:23 <justme84> I still don't understand... but it's probably too advanced for me :)
07:37:56 <Heffalump> justme84: basically, there's no more point to using fix than there is to using foldr
07:38:40 <justme84> I guess so, since foldr is actually useful sometimes
07:39:32 <Heffalump> well, you can always write out a definition using foldr longhand
07:39:49 <Heffalump> there's actually less value to fix, since it's so simple
07:40:53 <justme84> what can I write using fix?
07:41:13 <justme84> or, how do I write length using fix, for example
07:41:22 <Heffalump> well,
07:41:45 <Heffalump> length xs = case xs of [] -> 0 ; (y:ys) -> 1+length ys
07:42:03 <Heffalump> so length = fix (\f xs -> case xs of [] -> 0; (y:ys) -> 1+f ys)
07:42:14 <justme84> ah
07:42:42 <justme84> so I just replace the function on the right side with f and add fix and lambda
07:42:57 <Heffalump> yeah.
07:43:17 <Heffalump> if you have mutually recursive functions it's a bit trickier (you have to make a tuple)
07:43:26 <justme84> now the only thing I don't understand is what's so fixed about it
07:44:29 <Heffalump> "fix" doesn't mean "this function is broken and I'm going to return a fixed version of it"
07:44:38 <Heffalump> it means "I'm going to calculate the fixed point of this function"
07:44:40 <justme84> I didn't mean it this way
07:44:49 <Heffalump> and the definition of fix is essentially the definition of fixed points
07:44:51 <justme84> so length is the fixed point of \f xs -> ...?
07:45:22 <Heffalump> yeah.
07:45:33 <Heffalump> note that \f xs -> ... isn't recursive at all
07:45:44 <justme84> yes, I see
07:45:53 <Heffalump> which makes it easier to reason about
07:46:22 <justme84> hm
07:46:24 <Heffalump> some languages don't allow implicit (i.e. by using the name you're defining) recursion at all, but just provide the "fix" combinator or equivalent
07:46:59 <justme84> now if I substitute length for f, I wonder what I'll get
07:47:16 <justme84> \xs -> case xs of [] -> 0; (y:ys) -> 1 + length ys
07:47:19 <justme84> hmm, looks right
08:58:20 <ludde> Marvin--: alive?
09:00:56 <Marvin--> barely
09:01:43 <ludde> i'm trying to learn latex. can i see the latex source of your report?
09:01:50 <ludde> (the one in topic)
09:06:44 <Marvin--> actually I wrote it in LyX
09:07:03 <ibid> good evening all :-)
09:07:16 <ludde> lyx hmm, ok
09:07:33 <ludde> does it output latex code?
09:07:44 <hdaume> ludde: i found http://www.isi.edu/~hdaume/lshort2e.ps to be a great learn latex doc
09:07:54 <ludde> thanks
09:09:11 <Marvin--> ludde: yes
09:09:16 <Marvin--> and yes, lshort is good
09:13:10 <hdaume> ludde: if you want i can send you some old papers/hw assignments in tex, but i don't know that they'd be all too instructive
09:13:30 <ludde> nah, it's ok then.. i'm trying out lyx instead.
09:16:26 <hdaume> ok
09:17:23 <ludde> is latex a programming language like post script?
09:18:58 <ibid> it is a programming language
09:19:02 <ibid> not like postscript
09:23:44 <Vulpyne> What can you view .ps and .dvi files with under Windows?
09:23:59 <ludde> ghostview & dvips perhaps?
09:24:10 <Vulpyne> Thanks.
09:27:27 <ibid> actually, tex is a programming language
09:27:36 <ibid> latex is closer to a subroutine library...
09:27:55 <dark> More like a standard prelude :)
09:28:21 <ibid> not really
09:28:28 <ibid> plain tex is the standatd prelude
09:29:38 <dark> Hmm, but the tex engine loads the latex macros automatically, based on its invocation.  There's nothing the document needs to do to import them.
09:29:55 <ibid> true
09:30:03 <ibid> or actually
09:30:05 <ibid> not true
09:30:18 <ibid> the *latex* command loads them automatically
09:30:20 <ibid> tex does not
09:30:34 <dark> Notice how I said "tex engine", not "tex command" :-)
09:30:51 <dark> latex is a symlink to tex on my system.
09:30:56 <ibid> well, TeX engine looks at the command name and loads the appropriate format file
14:27:23 <hdaume> anyone in here feel like helping me write my first (real) concurrent haskell program?
14:28:24 <Vulpyne> I can help you write "Hello, world."
14:28:37 <hdaume> (presuming the answer will be "yes", ...) what i want to do is write a program which reads a bunch of files and uses a finitemap to count the number of occurrences of each word in the file and then print the finitemap
14:28:38 <Pseudonym> I can help you write "hello world" concurrently.
14:28:41 <hdaume> doing this sequentially is really easy
14:28:53 <Pseudonym> PL/
14:28:55 <Pseudonym> OK
14:29:02 <hdaume> but basically i want to spark up a thread for each file and then merge the results
14:29:02 <Pseudonym> Where do you want the concurrency?
14:29:22 <hdaume> i tried something but it's very wrong
14:29:43 <hdaume> http://www.isi.edu/~hdaume/TryConc.hs
14:29:48 <hdaume> i realize now that this is a bad approach
14:30:02 <hdaume> so my question is: what's the "right way" to do this?
14:31:07 <hdaume> (i suspect "MVar" `elem` answer)
14:33:32 <Pseudonym> Hmmm.
14:34:02 * hdaume is not at all familiar with the "concurrency" thing, in Haskell or otherwise
14:34:10 <Pseudonym> So each child has its own FiniteMap?
14:34:15 <hdaume> yeah
14:34:23 <Pseudonym> Then you merge them.
14:34:36 <hdaume> righto
14:34:49 <Marvin--> hdaume: I'm not very familiar with concurrency in haskell, but you do need some sort of synchronization
14:35:11 <Pseudonym> You could try Control.Concurrent.Chan
14:35:21 <Marvin--> one variant would be for all the threads to share an IORef to a FiniteMap, but then you have to make sure only one thread fiddles with it at the time
14:35:37 <Pseudonym> Basically, each thread sends words down a channel to one thread which pulls out words and adds them to the FiniteMap.
14:35:43 <Marvin--> so you'd need some sort of semaphore
14:35:44 <Pseudonym> Or...
14:36:02 * Pseudonym hmms
14:36:19 <Marvin--> or, as Pseudonym says, let the worker threads write words to a controlling thread that is the only thread using the finite map
14:36:19 <Pseudonym> Considering what you're actually doing here, I wonder if each child should just build a list.
14:36:22 <hdaume> i don't want to send words down...this is not my real application, but it's close enough
14:36:42 <Pseudonym> Then build the FIniteMap when they're done.
14:37:09 <hdaume> yeah, but in my real program i can't do that.  all i can do is essentially add a avalue to an ADT and merge these ADTs
14:37:21 <Pseudonym> Can I ask what the program ios?
14:37:54 <hdaume> it's baum-welsh training, extended to handle observation sequences and state sets (i.e., hmm parameter estimation)
14:38:02 <Pseudonym> OK
14:38:04 <hdaume> :)
14:38:09 <Pseudonym> I understand the general idea.
14:38:28 <hdaume> but basically it reads a file, does some parameter estimation, reads the next file, does more param estimation, etc
14:38:47 <hdaume> but i want to do these file reading/param estimation concurrently and then merge the results
14:39:02 <Pseudonym> Well if those are the operations you have, you're probably doing the right thing.
14:39:05 <hdaume> the word-count example is just trying to remove the complexity from this task
14:39:07 <Pseudonym> It's a highly constrained problem.
14:40:39 <hdaume> so...based on reading the GHC docs for Control.Concurrent, i gather than i should be using MVars and somehow return the finitemaps from the child threads in those
14:41:23 <hdaume> ages ago i wrote a ThreadPool class for Java which essentially did this same sort of thing...but i really don't remember how that worked ata ll :)
14:42:08 <Pseudonym> :-)
14:42:15 <Pseudonym> You probably should do that, yes.
14:42:24 <Pseudonym> If it were word counting, I'd use the channel approach.
14:42:35 <Pseudonym> My IRC library actually sends IRC commands down a channel.
14:42:50 <Pseudonym> One thread does socket reading, one does socket writing and one does the processing.
14:47:06 <hdaume> hrm.
14:47:16 * hdaume considers just MPI-ifying it instead since he knows how to do that
14:47:25 <hdaume> probably better the long run anyway
14:48:08 <clausen> Pseudonym: so, you're using your own client?
14:48:35 <hdaume> brb...
14:49:05 <Pseudonym> No.
14:49:15 <Pseudonym> lambdabot: Hello.
14:49:17 <lambdabot> Sorry, I'm not a very smart bot yet.
14:49:49 <Pseudonym> Note: lambdabot doesn't speak CTCP yet.
14:50:02 <Vulpyne> It's written in Haskell?
14:50:12 <Pseudonym> Yes.
14:50:25 <Vulpyne> Nice.
14:50:31 <Vulpyne> You're using threads?
14:50:37 <Pseudonym> Yes.
14:50:51 * Vulpyne nods.
14:51:13 <Pseudonym> lambdabot: @listchans
14:51:16 <lambdabot> I am on these channels: ["#haskell"]
14:51:45 <hdaume> anyone know if readChan blocks until there's something on the channel?
14:51:46 <Pseudonym> It can't do a great deal.  Mostly join and leave channels.
14:51:54 <Pseudonym> Yes it does.
14:51:58 <hdaume> tnx
14:52:02 <Vulpyne> Does it do protocol parsing?
14:52:23 <Pseudonym> What do you mean?
14:52:48 <Pseudonym> You have to understand the protocol in order to join a channel at least. :-)
14:52:49 <Vulpyne> For example, breaks every IRC message into SOURCE/TYPE/ARGS... 
14:52:54 <Pseudonym> Sure.
14:53:11 <Vulpyne> Well, you could just hardcode stuff. I wouldn't count that is protocol parsing. :)
14:53:16 <Pseudonym> :-)
14:53:22 <Pseudonym> You can /msg to it, too.
14:56:04 <Vulpyne> It didn't like my request.
14:56:47 <Vulpyne> lambdabot: @listchans
14:56:47 <lambdabot> I am on these channels: ["#haskell"]
14:57:15 <Pseudonym> No.  The set of commands you can /msg to it is different.
14:57:21 <Vulpyne> I see.
14:57:22 <Pseudonym> lambdabot: @listmodules
14:57:25 <lambdabot> I have the following modules installed: ["hello_module"]
14:57:36 <Pseudonym> It really can't do anything.
14:57:47 <lambdabot> Yes I can.
14:57:51 <Pseudonym> lambdabot: Shut up.
14:57:54 <lambdabot> Sorry, I'm not a very smart bot yet.
14:57:57 <Vulpyne> Uh oh, revolution.
14:58:47 <Pseudonym> One of these days I'll get it to do something useful.
14:59:31 <Vulpyne> I want to write a client.
15:00:02 <tarmo> one question..what's the deal with haskell and that weird syntax? why is such a thing good for?
15:00:10 <Pseudonym> What weird syntax?
15:00:33 <tarmo> well, haven't seen anything like it before
15:00:41 <Pseudonym> You haven't done any maths?
15:00:52 <Pseudonym> It's actually very close to mathematical notation.
15:01:01 <liiwi> tarmo: done any python?
15:01:23 <Igloo> Yo ucan liberally sprinkly braces and semicolons if that makes you feel happier  :-)
15:01:39 <hdaume> I think i've got a good solution to my concurrency problem: http://www.isi.edu/~hdaume/TryConc.hs
15:01:56 <tarmo> hmm, well I'm looking at a haskell tut i found from google and it looks normal
15:02:02 <tarmo> like a programming language
15:02:16 <tarmo> but the examples at my school are just unreal
15:03:22 <tarmo> liiwi, just a few scripts, but I'm not a big python fan
15:03:33 <Pseudonym> I don't mean to be rude, but what is a programming language supposed to look like? :-)
15:03:52 <Pseudonym> C++, Prolog, Forth and AP/L all look very different.
15:04:15 <tarmo> like the C family :P
15:04:17 <Pseudonym> hdaume: Very nice.
15:04:20 <Pseudonym> :-)
15:04:30 <hdaume> channels are cool :)
15:04:56 <hdaume> tarmo: thank god that's not the case
15:05:05 <Pseudonym> Indeed.
15:05:15 <Pseudonym> C family is very nice but very inflexible.
15:05:29 <Pseudonym> Very nice syntax-wise, anyway.l
15:05:45 <Vulpyne> Heh, because it's very simple.
15:05:58 <Pseudonym> Right, however...
15:06:02 <Pseudonym> Writing programs is complex.
15:06:11 <Pseudonym> You need this much complexity: |<------------------------------------->|
15:06:22 <Pseudonym> If your language only gives you this much: |<--->|
15:06:29 <Pseudonym> Then you need to supply the rest yourself.
15:06:47 <Vulpyne> Abstraction doesn't always mean complexity.
15:06:57 <Vulpyne> Well... Unless you're the guy developing the language. :)
15:07:08 <Pseudonym> Abstraction is one mechanism for keeping control over complexity.
15:07:27 <Pseudonym> The problem with software is it's the most complex thing yet developed by humans.
15:07:33 <Pseudonym> It's also very fragile.
15:07:52 <Pseudonym> As my software engineering lecturer told me once: A plane has never crashed because the carpet is green.
15:07:54 * Vulpyne nods.
15:08:01 <Vulpyne> Hmmm.
15:08:06 <Pseudonym> Software has crashed for stupider reasons, though.
15:08:15 <Vulpyne> Maybe a plane has.
15:08:21 <Pseudonym> Well perhaps.
15:08:37 * Pseudonym can think of a scenario where this could happen
15:08:41 <dark> Some planes have crashed because birds are grey :-)
15:08:44 <Vulpyne> Me too.
15:08:55 <Pseudonym> You get the point, though.  Software is fragile.
15:09:05 <dark> Programming is too difficult for humans.
15:09:09 <Pseudonym> Right.
15:09:10 <Vulpyne> "Pilot: Hey, who dyed the carpet green? Ack, runway!"
15:09:23 * Pseudonym laughs
15:09:31 <Vulpyne> How can you say it's too difficult for us when we can do it? :)
15:09:39 <Pseudonym> We don't always do it well.
15:09:42 <dark> Vulpyne: We don't do it right :-)
15:09:49 <dark> Writing _wrong_ programs is easy.
15:09:58 <Vulpyne> Within the constraints given, we can.
15:10:10 <Pseudonym> The point is this: Software engineering is the process of keeping control over the complexity of a software system.
15:10:15 <Vulpyne> Not saying it doesn't require large amounts of effort and experience.
15:10:18 <Pseudonym> Abstraction is one tool which helps.
15:10:26 <Pseudonym> Or which can help.
15:10:38 <dark> Pseudonym: Simplifying the problem is the most useful approach I've found :-)
15:10:48 <dark> Unfortunately I seem to be in the minority with that opinion.
15:11:01 <dark> (exhibit A: gnucash)
15:11:03 <Pseudonym> dark: Unfortunately it's not always realistic.
15:11:13 <Pseudonym> Oh, gnucash has set itself up for a fall.
15:11:28 <Pseudonym> By trying to deal with those numbers which come after that funny S with the line through it symbol.
15:11:36 <Pseudonym> Those numbers don't obey the normal laws of mathematics.
15:12:18 <dark> None of those symbols in my gnucash :)  They all say "EUR".
15:12:28 <Pseudonym> That's even worse.
15:12:59 <Pseudonym> EUR doesn't even obey the laws of economics.
15:13:39 <Pseudonym> I think we scared him off.
15:13:44 <dark> Well, that's logical... the laws of economics deal with scarcity, supply and demand.  Money isn't scarce.
15:13:55 <Pseudonym> That's true.
15:14:03 <Pseudonym> What's scarce is smart people.
15:14:59 <dark> I remember being amused when people laughed at other people who bought Diablo II equipment at ebay.  "It's just some number in a database," they said, and didn't see the irony.
15:51:28 <hdaume> OT: anyone know how to get the amount of free memory in gcc?
15:51:56 <dark> No such number, I think.
15:52:07 <Heffalump> yes, how would you define it?
15:55:15 <hdaume> Heffalump: what do you mean?
15:58:04 <dark> hdaume: The only reliable way to know if you've run out of memory is to try to allocate some and see if that fails.
15:58:18 <dark> And even then, you don't *really* know until you try to actually use it.
15:58:48 <dark> (There's usually a system setting to fix the second part, but it's normally off)
16:00:38 <dark> hdaume: Hmm, I wonder if you typoed "GHC" as "gcc"?
16:02:39 <hdaume> dark: no i meant gcc
16:05:00 <dark> Well, gcc doesn't provide any memory management.  That's up to the application.  The C library provides malloc and free, but those just ask for memory blocks from the underlying system.
16:05:56 <hdaume> dark: okay thanks
16:05:59 <dark> One thing you could do, perhaps, is to use getrlimit, sysconf and rusage to compare your current memory use against the ulimit.  But the default ulimit for memory size is "unlimited" so that may not help much.
16:07:13 <hdaume> *grin* it's not that important
16:07:35 <dark> In that case I would say, pick an arbitrary max memory usage and compare against that :)  It's what ghc's RTS does.
16:08:39 <hdaume> how can you get current memory usage then?
16:08:47 <hdaume> or do you have to keep track of that yourself
16:09:27 <dark> Yeah, you have to track it yourself, or use system-dependent tricks like rooting around in /proc
16:09:37 <hdaume> ok thanks
16:09:58 <dark> Hmm, the GNU malloc used in glibc might have some stuff for querying current memory usage.  It has a number of debugging features.
16:13:23 <dark> Yep, the info pages talk about a mallinfo() function that returns those stats.
16:40:40 <Igloo> Grrr, I seem to have screwed up my GHC build tree somehow
16:40:50 * Igloo blames the lack of a decent build system
16:43:43 <hdaume> :)
16:43:47 <hdaume> i have done that so many time
16:43:48 <hdaume> s
17:12:50 <tez> :q
17:12:58 <tez> oops, lol
19:12:36 <jadrian> hello
19:12:41 <Heffalump> hi
19:12:52 <jadrian> hi Heffalump :)
19:13:56 <Chilli> Heffalump: still up or up again?
19:14:01 <Heffalump> still up
19:14:09 <Heffalump> should go to bed really
19:14:17 <jadrian> that makes 2 of us...
19:14:57 <Chilli> Heffalump: what are you working on?
19:15:24 <Heffalump> various stuff I need to do, not code
19:15:32 <Chilli> ic
19:15:56 <Heffalump> how about you?
19:16:43 <Chilli> Fixing Template Haskell ;-)
19:16:51 <Heffalump> ah :-)
19:17:05 <Chilli> there is a lot of stuff still unimplemented
19:17:16 <Heffalump> how easy would it be for TH code to get at the results of type inference?
19:17:25 <Chilli> today I am teaching it to deal with forall's in types
19:17:36 <Chilli> very easy
19:17:47 <Heffalump> cool.
19:17:50 <Chilli> there is a operation (reifyType <name>)
19:17:53 <Pseudonym> That'd be useful.
19:18:00 <Chilli> it gives you the type of any function or datat constructor
19:18:11 <Heffalump> ah, but I want the results of type inference inside a function body
19:18:21 <Chilli> but at the moment, say, (reifyType length) dies
19:18:48 <Chilli> hmm, good point
19:19:10 <Chilli> I wonder what (let x = 1 + 1 in redifyType x) does
19:19:14 <Heffalump> I'd like to be able to automatically translate pure function definitions to monadic/arrow versions, just by saying how the type of the function itself changes
19:19:33 <Chilli> that should be possible
19:19:33 * jadrian is soooo sad!! 
19:19:37 <jadrian> damn
19:19:41 <Chilli> you need to reify the whole function
19:20:15 <jadrian> mm wait brb
19:20:17 <Chilli> (not sure whether reifying of function bodies is implemented yet, but I don't see any fundemantal re3ason why it shouldn't be possible)
19:21:51 <Chilli> *grrr*  when trying(let x = True in reify x), GHC claims that x is not in scope...
19:22:05 <Chilli> reify = reifyType
19:23:00 <Heffalump> I am correct in saying that if you turn a pure function into an equivalent definition based on a pure arrow, and then change the pure arrow appropriately, you could add things like memoisation, right?
19:23:08 <Chilli> I wonder whether it is a fundamental problem to have this or just something not implemented...
19:23:19 * jadrian has a question about this error:
19:23:26 <jadrian> Inferred type is less polymorphic than expected
19:23:26 <jadrian> Quantified type variable `s' escapes
19:23:36 <Heffalump> jadrian: are you using ST?
19:23:45 <jadrian> yes Heffalump, sorry...
19:24:00 <Heffalump> your problem is that you're using an STRef from inside the runST (...) outside it
19:24:11 <Heffalump> s/that/almost certainly that/
19:24:21 <Heffalump> why are you apologising for doing so? :-)
19:24:45 <jadrian> Heffalump: because just the other day you were teaching me everything about monad transformers
19:24:53 <jadrian> Heffalump: and I ended up with ST
19:24:59 <Heffalump> I'm not offended :-)
19:25:01 <jadrian> Heffalump: I had to, really :)
19:25:18 <jadrian> Heffalump: but it's not that... I'm using it inside
19:25:25 <jadrian> a simple example:
19:25:39 <Heffalump> jadrian: the 's' wouldn't escape if you weren't using a STRef outside the runST
19:25:49 <Heffalump> can you construct a single independent file with this error?
19:25:50 <Heffalump> (small)
19:25:55 <jadrian> data E = E{refi :: forall s. STRef s Int,
19:25:55 <jadrian>  refc :: forall s. STRef s Char}
19:26:15 <Heffalump> oh.
19:26:24 <jadrian> see a 'record' with 2 strefs
19:26:29 <jadrian> now the problem is when I do this
19:26:34 <Heffalump> having the forall there makes no sense
19:26:49 <Heffalump> you should have something like data E s = E {refi : STRef s Int, ...}
19:27:09 <jadrian> I was trying to do something like that right now...
19:27:25 <jadrian> I understand I want them to share the same thread, right?
19:27:52 <Heffalump> yes
19:28:19 <jadrian> let me see then...
19:29:31 <jadrian> Heffalump: ah that worked thanks
19:29:33 <jadrian> :)
19:30:16 <jadrian> Heffalump: I did try something like that, I was using the 's' in the Value constructor, not the type constructor...
19:32:46 <jadrian> Heffalump: by the way, do you know why I ended up not using State. If you remember I had this persistent state in a outer monad (that was the state of some object p) and I would iterate some f over and over again in p.
19:33:12 <jadrian> Heffalump: but then instead of just using *one* object I wanted to use *two* objects...
19:34:29 <jadrian> Heffalump: so you see, I would have to duplicate the state in the monad, and all functions that access state...
19:34:32 <jadrian> Heffalump: not pretty
19:34:51 <Heffalump> errm
19:34:56 <Heffalump> don't you mean the inner monad?
19:35:49 <jadrian> I don't think so...
19:35:55 <jadrian> oh yeah
19:35:56 <jadrian> I do
19:36:04 <jadrian> argh I always mess that up :)
19:36:14 <jadrian> the top level one :)
19:38:19 <jadrian> There is this John Hughes about global variables in haskell, and he presents a similar problem - implementing Queue monad, and then needing to use two Queues in one situation .
19:39:03 <Heffalump> I don't see why having two objects is a problem.
19:39:15 <Heffalump> but I think I'm not understanding what you're trying to do
19:40:15 <jadrian> well if you have you queue monad you can do things like addQ() right?
19:40:27 <jadrian> opss
19:40:31 <jadrian> addQ 1
19:40:56 <jadrian> if you want to use to queues how are you going to specify which queue you want to use?
19:43:00 <jadrian> I'm not explaining myself to well...
19:43:33 <jadrian> Imagine you need to use a global stack in some algorith of yours and you don't want to pass it waround
19:43:48 <jadrian> you create a stack monad, and operations Push, Pop etc...
19:44:09 <jadrian> but then in some situation you need to use two stacks...
19:44:53 <jadrian> what do you do, do you create another monad, 2 stacks, and operations Push1, Push2, etc?
19:45:28 <jadrian> it can get very messy... that was my case
19:47:46 <Pseudonym> jadrian: I think that's a classic example of something which is best modelled not as a monad.
19:48:13 <Heffalump> just make a monad with state that is represented by a record
19:48:36 <Pseudonym> Or, if you have the IO monad somewhere below, a Monad reader transformer which contains a bunch of IORefs.
19:48:54 <Pseudonym> That way you don't keep reconstructing the record.
19:49:46 <Pseudonym> Incidentally, I don't think anyone has yet come up with a clean way to specify an ST-like state monad transformer.
19:50:22 <Pseudonym> One that you can piggyback on top of IO or not as the case may be.
19:50:57 <Heffalump> i.e. a type-safe state monad transformer with an imperative implementation?
19:51:23 <Pseudonym> Right.
19:51:42 <Pseudonym> I think it's impossible without significant magic because the monad you put it on top of may backtrack.
19:51:51 <Heffalump> ah, of course
19:52:06 <Pseudonym> But I often make monads like this:
19:52:15 <Pseudonym> class MonadDebug where
19:52:24 <Pseudonym> Sorry.
19:52:27 <Pseudonym> class MonadDebug m where
19:52:32 <Heffalump> of course, a clever compiler will implement with in-place update where possible anyway
19:52:34 <Pseudonym>      debug :: String -> m ()
19:52:44 <Heffalump> how clever is GHC? :-)
19:52:55 <Pseudonym> Then make an isntance for IO (which putStrLn's) and Identity (which is a no-op).
19:53:10 <Pseudonym> Then I want refs (IORefs, STRefs, whatever) on top of that.
19:53:23 <Pseudonym> Heffalump: Not clever enough. :-)
