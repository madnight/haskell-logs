00:06:41 <Luke> does ghc have some equivalent to the hugs Set module?
00:17:05 <Luke> hm, it seems like ghc has the Set module, but claims not to find the "interface file"?
00:23:28 <dennisb> Luke you have to start with -package data
00:23:56 <dennisb> (when you start ghc or ghci)
00:26:50 <Luke> thanks
01:00:38 <sethk> bye, all, thanks for the help...
01:15:06 <Luke> can someone tell me why this memoization code apparently doesn't work:
01:15:15 <Luke> memo_solutions = (([error "No solutions for 0 nines", [9]] ++
01:15:16 <Luke>                    [find_solutions n | n <- [2..]]) !!)
01:16:35 <Luke> I want to then say "memo_solutions n" and get a cache value..
01:17:54 <clausen> hmmm
01:18:32 <clausen> so, what forces the evaluation?
01:18:43 <clausen> you need a complete program for that to make any sense
01:19:44 <Luke> well, that'd be 72 lines :)
01:19:56 <Luke> also, tweaking and changing based on snippets from the web..
01:20:09 <Luke> now I have:
01:20:19 <Luke> solutions = memoize find_solutions
01:20:20 <Luke> memoize f = ([f n | n <- [0..]] !!)
01:21:06 <Luke> my program makes various calls to solutions with a number, and often calls with the same index. however, I can't detect any speed difference with/without memo
01:21:51 <clausen> ah, but calling with the same number doesn't help
01:22:02 <Luke> aha, why not?
01:22:03 <clausen> it has to be the result of the same invocation
01:22:15 <clausen> basically, think of it like this:
01:22:20 <clausen> everything in haskell is lazily evaluated
01:22:38 <clausen> so, data is often not stored as data
01:22:47 <clausen> but rather as code saying how the data should be computed
01:23:03 <clausen> but, once that computation is actually executed, the [reference to] code is replaced with the data itself
01:23:12 <clausen> so, if you did something like:
01:23:21 <clausen> someprimes = take 100 primes
01:23:39 <clausen> and then used "head someprimes"
01:23:46 <clausen> it will force evaluation of the first element of that list
01:23:59 <clausen> (someprimes, and primes)
01:24:09 <clausen> if you use it again, it will quicker the second time
01:24:27 <Luke> ok, so I need to hang on to that same list
01:24:33 <clausen> right
01:24:46 <clausen> memoization isn't some magical cache
01:24:52 <clausen> that remembers function calls, etc.
01:25:22 <clausen> it's just the natural way to implement lazy evaluation
01:25:24 <Luke> ok, I was assuming this memoize function was like the lisp ones (which actually bung a wrapper around the function with a hashtable)
01:25:31 <clausen> ah, ok
01:26:31 <Luke> I still don't really understand though, shouldn't my list of memoized values be in a closure-like thing, and the function just being a wrapper that always looks up in the same lazy list object?
01:27:05 <Luke> or, can I force those semantics with a lambda?
01:27:51 <clausen> to be honest, I can't understand what you're trying to do
01:28:06 <clausen> i.e. how you intend to use the code, and what output you're hoping for
01:28:25 <clausen> hmmm
01:28:30 <Luke> it's a dynamic programming problem. heard of the "nine nines" puzzle?
01:28:36 <clausen> no
01:28:47 <clausen> so, are you referencing "solutions" only?
01:28:51 <Luke> yeah
01:29:42 <clausen> hmmm, it should work!
01:29:52 <Luke> well, maybe it does any the slowness is coming from somewhere else :)
01:29:56 <clausen> can you make a dummy program for me to try out?
01:30:08 <Luke> sure, I can send you the prog - 1 sec
01:30:24 <clausen> (it's helpful to remove irrelevant details, like the problem you're trying to solve...
01:30:30 <clausen> for both of us ;)
01:30:59 <Luke> hmm, well, I really don't know which parts are relevant :)
01:31:10 <Luke> hold on, I'll refer back to a memoized factorial example I have, and see if I can spot a difference
01:32:23 <Luke> if you're feeling brave, the full code is at http://www.bluetail.com/~luke/misc/NineNines.hs :)
01:33:08 * Luke checks if ghc's profiler is super-easy, would be nice to establish that this to-be-memoized function is actually the bottleneck
01:33:20 * clausen has just been using hugs
01:33:26 <clausen> perhaps it's too simple/broken for all of this
01:33:27 * clausen has no idea
01:35:06 <dennisb> It's hard to know about these thing. I would have guessed that the example you pasted above wold have been memoized
01:35:50 <Luke> on a modest-size example, memoization doesn't seem to make an appreciable difference in run-time (which is about 3 seconds) - that's all I'm really going on. I'll try some larger inputs
01:37:06 <dennisb> Luke: it seems like it work
01:37:26 <Luke> ok, maybe I've done something stupid elsewhere that's taking a lot of time
01:37:32 <dennisb> I loaded your file and tried solutions 8, first time it took 1.59s and the second 0.06
01:38:19 <Luke> interesting, must be something else then. thanks
01:38:55 <dennisb> you can do :set +s in ghci to get the number of seconds
01:39:19 <Luke> I've been compiling to native and using 'time'
01:39:28 <dennisb> I just loaded it and tried it in ghci
01:40:01 <dennisb> *Main> length $ solutions 10
01:40:01 <dennisb> 141835
01:40:01 <dennisb> (37.91 secs, 1511315092 bytes)
01:40:01 <dennisb> *Main> length $ solutions 10
01:40:01 <dennisb> 141835
01:40:02 <dennisb> (0.01 secs, 267424 bytes)
01:40:15 <Luke> oh, hm - yes something has changed. I seem to be getting 50 seconds to run the native one to solve for 9, and it used to be 18 minutes
01:40:35 <Luke> no, I'm mistaken I think :)
01:40:49 <Luke> pft, separate compilations, I keep losing track of source/binary relatoinship :)
01:41:03 <dennisb> aha
01:41:28 <Luke> thing is, the very first call to (solutions 9) is supposed to be fast, because it should result in a lot of recursive calls to itself reusing the same indicies
01:41:43 <Luke> much like fibonnaci
01:42:03 <dennisb> well, i don't know how slow it would be without memoization
01:43:18 <Luke> eek, now I'm getting a faster time but an incorrect answer :) must have munged something.
01:43:51 <Luke> no, mistaken again :). should probably just hit the sack, but it's hard to give up on these things :)
01:45:01 <Luke> from what you've seen of the code, do you notice any e.g. grotesque use of language constructs, or something else to make it generally slow?
01:45:38 <dennisb> looks good
01:45:53 <Luke> hmm. I also need to specially increase my stack space to solve it for 9
01:46:27 <dennisb> I just loaded the file in the interpretor (ghci), no compiling and it was no problem here fo size 10
01:46:56 <Luke> you can do 10 "from scratch", without computing smaller ones first? wondering if the memo'ing is only happening at certain times
01:47:03 * Luke tries ghci
01:48:08 <dennisb> I'm not sure, maybe not. Hmm, It seems to take longer time when I restarted. How strange
01:48:44 <dennisb> took 47 seconds the first time here on my duron 800
01:49:01 <clausen> hunting down journal articles online is *painful*
01:49:08 <Luke> you mean calculating >= 9 from a "fresh run"?
01:49:19 <Luke> citeseer!
01:49:42 <Luke> unless they're f'ing ACM journals :)
01:49:47 <dennisb> Luke: yes, i started ghci fresh and did: length $ solutions 10
01:50:02 <clausen> citeseer doesn't get 5%
01:50:14 <clausen> (fulltexts, that is)
01:50:19 <Luke> CS journal articles? I find citeseer pretty good
01:50:31 <clausen> I have to go through this crappy firewall blah blah blah
01:50:45 <clausen> and figure out how to get there from this webpage for each journal
01:50:46 <Luke> but if they're from ACM journals, they're not very liberal with distribution in general :(
01:50:54 * clausen has ACM access via uni
01:51:06 <clausen> I have access to practically every journal, just it's a PITA to figure out *how*
01:51:15 <Luke> dennis: what about if you just do "run" on a fresh start?
01:51:35 <Luke> which ghc are you using? maybe I'm out of date with 5.02.1 ?
01:52:07 <Marvin--> morning
01:52:10 <dennisb> I use 5.04
01:52:23 <Luke> "length $ solutions 9" in ghci has had a minute on my athlon 800 so far
01:52:26 <Luke> I'll upgrade, then
01:52:43 <dennisb> Marvin--: It's not morning
01:52:53 <clausen> Luke: BTW: when you said "dynamic programming"...
01:53:05 <clausen> Luke: where you expecting this memoization thing to speed up recursion?
01:53:22 <dennisb> clausen: I would expect that
01:53:37 <clausen> dennisb: well, you'd have to do your recursion via your memoized list
01:53:39 <Luke> well, to speed up by caching recursive calls with the same arguments
01:53:41 <dennisb> He uses the memoized version in the recursive step
01:53:47 <clausen> ah, good :)
01:55:31 <Marvin--> dennisb: it isn't?
01:55:42 <dennisb> Nope, real men get up at 6:00
01:55:55 <Marvin--> I thought that in English, it's morning until noon
01:56:21 <dennisb> not in my world :-)
01:58:40 <Luke> so, what's wrong with my mental model? it looks to me like memoize returns a closure (via currying) that should have the cache array as part of its local state. is that from the wrong world?
01:58:42 <Marvin--> meh, the only fun thing about the Semantics course are the assignments
01:58:55 <dennisb> Luke: with and without memo in this case makes no big difference, how strange. I get 60s without memo end 45s with memo
01:59:15 * dennisb can't really get a grip on this...
01:59:18 <Luke> well, maybe something is drastically broken with my find_solutions functoin :)
01:59:38 <Luke> but for me it's still slow as (solutions 9) or (run), so I'm upgrading ghc first
02:08:19 <dennisb> The only explanation I can think of is that you are not memoizing the operation that takes the longest time. Then the difference between memo and no memo can't be that big
02:08:48 <Marvin--> what is the problem you're soling?
02:08:48 <Luke> not out of the question
02:08:51 <Marvin--> solving either
02:09:07 <Marvin--> err... s/either/even/, maybe I should just crawl back into bed
02:09:21 <Luke> the "nine nines" puzzle. http://www.itasoftware.com/careers/programmers.php
02:09:43 <dennisb> Marvin--: No way, they day is here. No more sleep
02:10:13 <Luke> definitely past my bedtime, starting hacking this around midnight, now its 11am :)
02:10:51 <dennisb> there are a lot of concat, ++, folds and stuff that can take a lot of time, I simply don't know the problen enough to see where is the biggest bottleneck
02:11:34 <Luke> I'm thinking ++ should be pretty much O(1) in a lazy language?
02:11:42 <Marvin--> uh, no?
02:11:50 <Marvin--> it's linear over the lhs
02:11:53 <dennisb> it's O(length of left argument)
02:12:35 <Luke> ok, I thought it would just delay the concatenation to the point where it's really just a deep list
02:12:38 <Marvin--> Koen showed us the trick of putting a monad inside a monad and using continuations to get rid of left-recursion over bind... way cool
02:12:56 <Marvin--> Luke: lazy evaluation is nice, but not magical :)
02:13:00 <Luke> however, the ++'s have very small LHSs and shouldn't be a problem
02:13:14 <Marvin--> As long as you don't do left-recursion over ++ you should be fine
02:13:22 <Luke> in erlang we just use deep lists for that, and cons instead of ++'ing :)
02:14:03 <Luke> if GHC ever finishes compiling I'll do some more measurements :)
02:14:33 <dennisb> you compile it yourself? Can't you use a binary? It takes a long, long time to compile ghc
02:14:39 <Luke> but, there is definitely something "wrong". the program is taking ~18 minutes to solve for 9 for me, and it's a port of a common lisp program that runs in 2.5 seconds
02:15:14 <Luke> I tried an RPM but it didn't like my ancient (~ year) redhat release :)
02:15:23 <dennisb> add_combinations seems like it's expensive
02:15:34 <Marvin--> can I see the code?
02:15:46 <dennisb> Marvin--: he pasted the url above
02:15:57 <dennisb> <Luke> the "nine nines" puzzle. http://www.itasoftware.com/careers/programmers.php
02:16:04 <Luke> 1 sec, I'll copy the current code over
02:16:10 <dennisb> no
02:16:18 <dennisb> that's the wrong one :-)
02:16:18 <Marvin--> oh, is it the "mystery M function" we're talking about?
02:16:30 <Luke> http://www.bluetail.com/~luke/misc/NineNines.hs
02:16:35 <Luke> no, it's the Nine Nines problem
02:16:41 <Marvin--> bear in mind that I just joined! :)
02:17:04 <BlizzNL> morning
02:19:12 <Marvin--> why don't you express pair_sizes like [ (a,b) | b <- [1..n], a <- [b..n], a+b == n ]... unnecessary to generate a's that are smaller than b...
02:20:03 <Luke> n <= 9, so I didn't bother
02:20:12 <Marvin--> ah, true
02:21:15 <Luke> I tell you, I had a bastard of a bug before I put the parens around line 58 :) precedence rules are tricky to the novice
02:21:22 <BlizzNL> are there more polymorphism principles in haskell besides ad-hoc and parametric?
02:22:10 <Marvin--> Luke: heh
02:23:06 <Marvin--> Luke: sure, combinations works on lists of length 3 to 4, but wouldn't it make sense to do the conditional ++ at the head, instead of at the end?
02:23:38 <Luke> well, yeah. but it's O(1) either way which is good enough for me
02:23:58 <Marvin--> of course it's O(1), but that doesn't say anything about how fast it is
02:24:04 <Luke> .. unless it somehow turns out to be the bottleneck ;-)
02:24:16 <Marvin--> no of course it's not *the* bottleneck
02:24:28 <Luke> I think I had them at the head, but randomly jumbled that function around in an effort to get insight from some type errors :)
02:26:11 <Luke> well, that's a good point - that function is the most frequently called
02:26:39 <Marvin--> hmm, why only abs (x-y)? because you randomly throw unary minuses around?
02:27:24 <Luke> yeah, only keep track of absolute values, but `combinations' treats them as +/- (but gives absolute results)
02:27:57 <Marvin--> when combinations is called with 0 as either argument, you return more than one 0, seems kinda excessive
02:27:58 <Luke> which mostly/totally cancels out the +/- ness
02:28:27 <Luke> that would be an error - lax guards
02:29:00 <Marvin--> but these are all minor things
02:29:21 <dennisb> don't be to sure about that
02:29:21 <Luke> pair_sizes always returns >= 1 for each size
02:29:31 <Luke> (theoretically at least :)
02:29:37 <dennisb> put a nub on the result from combinations and try it again
02:29:46 <Marvin--> Luke: ah, true
02:30:06 <Marvin--> Luke: but if that's the case, why have the checks for divison anyway?
02:30:46 <Luke> oh, my mistake - combinations does accept zero.
02:30:52 <Luke> I was thinking of add_combinations
02:31:23 <Luke> combinations deals in combining two actual numbers by all operators
02:33:53 <Luke> the checks for division are because each number can be on LHS or RHS, and I don't want to include any undefined results
02:35:56 <Marvin--> combinations 0 0 = [0], combinations 0 y = [0, y], combinations x 0 [0, x], combinations x y = [x/y, y/x, ...]
02:38:00 <Luke> the basic idea is that for each solution size, I find all the ways it coul be divided into subexpression pairs, and all the sets of possible results of subexpression of that size, and then combine all the possibilities with each operator to get the complete set of possible values for the whole expression
02:38:28 <Marvin--> http://www.gamespy.com/comics/dorktower/images/comics/DT16Page19.JPG <- hahahaha
02:40:21 <Luke> I'm playing with hacking around with this haskell as part of a "language of the year" idea. there's a support mailing list, maybe I should punt the problem there and get some sleep :)
02:41:04 <Luke> ghc shouln't take more than about an hour to build on an athlon 800, right? :)
02:41:16 <dennisb> maybe 10 hours :-)
02:41:41 <Luke> great. :) my older RPM install doesn't seem to have any profiling support
02:41:57 <Luke> or - does hugs have a profiler?
02:41:59 <dennisb> it's faster to upgrade redhat .-)
02:42:18 <Marvin--> dang, the ghc5 package in Debian was built too long ago for the buildd to remember the build log
02:44:45 <Luke> so, are there any simple tricks for ad-hoc profiling, printf-style?
02:45:15 <Luke> infact, how do I slip in a a printf - can I do it without mucking with declarations?
02:45:24 <dennisb> there is a trace function you can put anywere
02:45:30 <dennisb> in IOExts
02:45:39 <Luke> Hugs has it?
02:45:45 <dennisb> yes, in Trace
02:46:29 <Luke> can you give an example usage?
02:46:40 <dennisb> trace :: String -> a -> a
02:46:57 <Luke> I saw that, but don't get it :)
02:46:58 <dennisb> f x = trace "I was called" (x+1)
02:47:03 <Luke> ahh, thanks
02:47:34 <dennisb> it prints out the string and returns the second value
02:48:09 <dennisb> maybe it's no so easy to use if for profiling, but with some use of unsafePerformIO that might work too
02:48:35 <dennisb> but it's handy for debugging
02:48:35 <Luke> can I get some args into what it prints easily, something printf'ey?
02:48:50 <dennisb> it's just a string
02:49:05 <dennisb>  f x = trace ("I was called with " ++ show x) (x+1)
02:49:09 <Luke> is there a handy format function I can use to generate that string?
02:49:16 <Luke> ah, perfect
02:50:24 <Luke> ok, it establishes that the memoizatoin is working correctly
02:51:04 <dennisb> maybe it's the conversion between lists and sets that are the bottleneck (just a guess)
02:51:30 <Luke> list->set itself shouldn't be worse than O(n log n) right?
02:51:54 <dennisb> It could use a lot of memory to build up a set from a list with 100000 elements or what it is
02:52:09 <Luke> but yeah, it does seem like its the crunching together of combinatinos in general that's eating time
02:52:14 <dennisb> yes
02:53:11 <Luke> a profiler would make all the difference :)
02:53:26 <dennisb> so, get ghc's profiler working!
02:53:38 <Luke> just as soon as it finishes compiling :)
02:54:25 <Marvin--> i.e., get some sleep ;)
02:54:59 <Luke> don't suppose set union is expensive or something?
02:56:18 <Luke> lesse what happens if I remove all the set stuff and just live with duplicates
03:02:22 <Marvin--> union shouldn't be more than O(n*log n), should it?
03:03:38 <Luke> so it seems to me. but I'm testing replacing the union with an ungodly number of foldl's to put everything into the original set
03:04:43 <Luke> eek, ghc ate all my disk space :)
03:05:14 * Luke deletes a 50mb core file from ~/ and carries on :)
03:07:12 <Luke> generally speaking, GHC's code should be pretty fast, right?
03:07:35 <Luke> I mean, I'm not misguided to be expecting similar performance to CMUCL, which on this app is similar to C?
03:09:07 <dennisb> it is fast, but one have to remember that dynamic structures are built upp on many programs. Sometime one have to make sure that an structure (like a set) is updated inplace in an imperative way. To just create a new copy when one element changed can be expensive
03:09:33 <dennisb> you have to know your data, and how it is used
03:09:52 <Luke> if the sets are trees I guess they should be able to do semi-cheap non-destructive updates
03:10:04 <dennisb> you can work with imperative arrays, sets and so on in haskell
03:10:52 <dennisb> but in haskell you normaly don't update, at least you cant be sure about it
03:11:05 <Luke> well, it looks my union -> foldl addToSet optimization roughly halved the speed :)
03:11:28 <dennisb> for big datastructures you sometimes have to use updatable arrays, or updatable sets and so on
03:11:47 <dennisb> well, I have to leave for a while.. see you!
03:11:51 <Luke> thanks for your help!
03:12:16 <Luke> I guess monads make that stuff "safe"
03:16:19 <Luke> though in this case efficiency doesn't actually matter in the absolute, it's just that if I'm doing something grossly inefficient, I'd like to know about it :)
03:18:11 <Marvin--> eh? I would expect union to be implemented with foldl addToSet... Hmm, or possible foldr in order to have infinite sets
03:19:12 <Luke> well, I may have mis-measured
03:19:44 <Luke> having win2k running in vmware tends to take all the predictability out of my available resources :)
03:20:15 <Marvin--> haha
03:22:34 <Marvin--> hmm, sets are implemented with finite maps which are implemented with self-balancing trees?
03:22:56 <Luke> that's how it looks to me from the outside
03:24:39 <Luke> is either foldl or foldr "better" in haskell, when ordering doesn't matter?
03:28:44 <Luke> g'day olc. you guys inspired me to do some haskell hacking, which I've been struggling with for many hours now ;-)
03:28:51 <Luke> and taking up plenty of channel time in the process :)
03:33:23 <Marvin--> heh
03:33:42 <Marvin--> Luke: foldr can be used lazily, foldl is tail-recursive
03:34:13 <Marvin--> Luke: so e.g. anything that you can do "from the head and onwards" where you want to have infinite lists, use foldr
03:34:24 <Marvin--> Luke: but e.g. reverse is implemented with foldl since it only works on finite lists anyway
03:35:37 <Marvin--> how the heck do I specify the semantics of a "generate a random integer" construct?!
03:48:16 <olczyk> Isn't there already a Random class?
03:52:43 <olczyk> What precisely do you mean by "semantics"?
03:53:01 <olczyk> Signature? Description of what it does?
03:53:19 <Marvin--> I'm taking a course called Semantics of Programming Languages
03:53:37 <Marvin--> and one of the assignments this week is to model the semantics of a "random" construct in a basic language
03:53:56 <Luke> model it with what?
03:54:37 <olczyk> Step one figure out what you mean by semantics.
03:54:46 <olczyk> IE what are the semantics of semantics.
03:55:20 <olczyk> In haskell I belive the signature would be:
03:55:30 <olczyk> MakeRandom::Int
03:55:52 <Marvin--> no no, this isn't related to Haskell at all, I just spewed it out here because this is the channel I happened to be in ;)
03:55:54 <olczyk> But come to think of it. Random has no meaning in a purely functional language.
03:56:09 <Luke> or "MakeRandom is a procedure of no arguments that returns a number that cannot be predicted" would be good enough for me :)
03:56:13 <Marvin--> well the language we're modelling has side-effects, so don't worry about that
03:56:22 <Marvin--> Luke: well the whole point is to formalise it
03:56:29 <Luke> why? :)
03:56:45 <Marvin--> `random' is supposed to be an expression with a side-effect
03:56:59 <Marvin--> so x := random; y := random can result in x != y
03:57:28 <Marvin--> Luke: because the course is about formal semantics of programming languages?
03:57:42 <Marvin--> we're using plotkin's structured operational semantics
03:57:43 <BlizzNL> How can I create a new user-defined type and make it part of the Num class?
03:57:49 <olczyk> Actually the point about functional makes sense.
03:57:58 <Luke> I find that stuff a real turn-off - but that's philistine me :)
03:58:01 <Marvin--> BlizzNL: instance Num YourType where ...
03:58:27 <olczyk> There is no such thing as a "Random" number. Just pseudorandom numbers.
03:58:33 <BlizzNL> Marvin--; thnx
03:58:46 <Marvin--> of course there are random numbers, they're just not used in regular programming languages
03:59:39 <Marvin--> but the assignment says 'random', not 'pseudorandom', which really complicates it :/
03:59:56 <Marvin--> 'course, I'm not sure how I would model pseudorandomness either, I'd have to extend the state to carry around a seed I suppose
04:00:11 <olczyk> No. From a mathematical viewpoint there is no such thing as a random number. Only pseudorandom
04:00:13 <olczyk> numbers.
04:00:55 <olczyk> I'm not sure of the course is trying to get at that point, but the semantics of random are really nonexistent.
04:01:05 <Marvin--> well, from a mathematical viewpoint obviously there's no such thing as a *random number* without context, there is "real" randomness though
04:01:11 <olczyk> Or maybe they just mean pseudorandom.
04:01:28 <olczyk> Such as?
04:01:43 <Marvin--> quantum physics?
04:01:51 <Marvin--> deals with randomness afaik
04:02:17 <Luke> so I guess all .se unis are quite into haskell nowadays?
04:02:18 <olczyk> In the underlying stuff yes.But once we measure them, they are no longer random,
04:02:28 <Marvin--> probability theory deals with randomness, it's the applications of proability theory that deals with pseudorandomness
04:02:41 <Marvin--> well, obviously
04:02:41 <olczyk> so we never see themm.
04:03:20 <Marvin--> but as I said, the issue isn't really that of randomness <-> pseudorandomness, I don't know how to model pseudorandomness in a satisfactory way either, aside from writing down a whole function for it
04:03:26 <Marvin--> s/function/algorithm/
04:04:12 <Marvin--> Luke: no I don't think so... most .se unis have courses in functional programming, but in some places they use lisp/scheme and in some places they use *ML
04:04:30 <Marvin--> Luke: I think that in Linköping for example, they have a lot of research on AI, and therefore use lisp a lot
04:08:12 <Luke> hm, right, I have a friend who went to LIU who learned that stuff instead of haskell
04:08:26 <Luke> though I thought ML was pretty american, and Ocaml pretty french
04:09:02 <Luke> I'm probably mostly thinking of people I see from gothenberg
04:09:20 <Marvin--> well, you're biased because most Swedes here are from Göteborg ;)
04:09:38 <Luke> ok :)
04:09:56 <Marvin--> I think SU (Stockholm) uses scheme, though I know they have a course in "programming languages paradigms" where they learn haskell and prolog, but I heard the lecturer sucked at haskell :/
04:10:30 <Marvin--> Umeå uses ML I think, but not that much... Uppsala I don't know
04:10:43 <Marvin--> and the smaller "colleges" rarely use functional languages at all
04:12:14 <olczyk> Well certainly ML is New Jerseyian.
04:12:45 <Marvin--> where does Lazy ML stem from? Göteborg? *ponders*
04:13:04 <Marvin--> not that anyone uses it when they can use haskell instead... ;)
04:13:32 <Marvin--> I know that Augustsson has worked on Lazy ML anyway
04:14:32 <Luke> in my ignorance, it seems like Lazy ML would pretty much be haskell :)
04:15:47 <Marvin--> doesn't ML have side effects too?
04:16:20 <Marvin--> though, I can't imagine what havoc laziness + side effects would wreak
04:16:29 <Marvin--> *shrug* I don't know much about ML
04:16:49 <Luke> did Monads originate in haskell?
04:17:07 <Luke> as far as programming languages go, that is
04:18:05 <olczyk> I've seen some papers about Monads in SML. 
04:18:20 <olczyk> But I believe Monads sprung up from theory.
04:18:55 <ibid> Luke: i believe haskell was the first "mainstream" language to use them, but wasn't the first pl to do it (vague memory)
04:19:04 <ibid> yes, monads come from category theory
04:19:53 <olczyk> I do think that there was some pressure from Haskell since previous IO methods
04:19:55 <olczyk> stunk.
04:20:27 <Marvin--> monads come from type theory, don't they?
04:20:34 <ibid> i have a vague recollection that the early haskell monad papers referred to some other guy who was applying then in programming
04:20:37 <Marvin--> or well, category theory
04:20:39 <ibid> Marvin--: category theory
04:21:02 * Marvin-- should read the *complete* scrollback before writing anything when he's been away a few minutes :)
04:21:48 <dennisb> I belive it was Eugenio Moggi that came up with it
04:22:17 <ibid> Marvin--: i've often scrolled up and read something, thought i was reading the most recent stuff, responded, and then realized that the topic was dead and buried, and downscroll there was lots of other discussion :-)
04:24:28 <ibid> hm, how many debianers do we have here? :-)
04:24:38 * Luke raises a hand
04:24:52 * ibid too
04:25:09 * Marvin-- too
04:25:51 * dennisb lowers his hands
04:27:25 <ibid> how evil would it be for me to introduce values, objects (non-oo), types and variables in a popl course by using a combination of natural language and denotational semantics (of which the students know very little)? :-)
04:28:21 <Marvin--> reasonably evil? :)
04:28:53 <ibid> is that good or bad? :)
04:29:48 * ibid thinks this course should really be split in two, a "comparative languages" in the cl level and a true, theoretical popl at the l level
04:30:00 <ibid> but the cl level is full already...
04:30:03 <Marvin--> for the students or for you?
04:30:19 <Marvin--> are you worrying about your karma, or what?
04:30:20 <ibid> ?
04:30:24 <ibid> ??
04:30:32 <Marvin--> <ibid> is that good or bad? :)
04:30:44 <Marvin--> good or bad for the students, or for you?
04:30:50 <ibid> i was just wondering what reasonable evil means
04:31:00 <ibid> for the course
04:31:34 <Marvin--> I think reasonably evil is the notch where a majority of the students start cursing the lecturer
04:31:44 <ibid> (did you see my practical work assignments i gave them last monday?:-)
04:31:46 <ibid> heh
04:31:53 <Marvin--> no?
04:32:17 <Marvin--> right, now I've solved all the assignments except the one about randomness *sigh*
04:32:21 <ibid> http://www.mit.jyu.fi/antkaij/opetus/okp2002/demo/demo1/
04:32:27 <Marvin--> I'm wondering if I'm thinking too hard on this
04:32:43 <ibid> (their job is to understand that code and make it better - they knew no haskell beforehand)
04:33:09 <Marvin--> ouch :)
04:33:31 <ibid> i think i crossed the reasonable level then :-)
04:33:38 <Marvin--> probably :)
04:34:26 <ibid> so i may as well continue on my chosen path
04:34:27 <Marvin--> ugh, the course I'm teaching in now has assignment deadlines on the next four mondays, man am I going to be swamped with work
04:35:08 <Marvin--> I suppose that on monday I'm going to see how many didn't understand the difference between concrete syntax tree and abstract syntax tree :(
04:35:23 <Marvin--> no wait, it's next monday... hooray, one more week's respite!
04:35:27 <ibid> well, even the better ones do that :-)
04:35:37 <ibid> (cf. sablecc:-)
04:39:04 <Marvin--> I told them at my last lesson that I don't want anyone to leave this room until they understand the difference, so noone dared come ask me after the lesson ;)
04:39:28 <ibid> are you lecturing some course?
04:40:59 <Marvin--> not lecturing, just exercise lessons
04:41:06 <olczyk> Doh!
04:41:21 <Marvin--> and lab supervision, and lab correcting
04:41:57 <Marvin--> dang, www.battle.net is down again
04:42:01 <ibid> right
04:42:11 <ibid> all the stuff i hate to do. lecturing is fun.
04:44:38 <Marvin--> exercise lessons and lab supervision is fun, correcting assignments is just boring
04:45:44 <ibid> in my experience, lab supervision is just sitting and waiting if somebody runs into trouble they have to report (even if i go and ask them their status, they just say "it's going well")
04:46:09 <ibid> report: can't solve on their own so have to go ask the supervisor...
04:46:27 <ibid> finns have a tendency to not talk about problems...
04:47:08 <ibid> correcting assignments is fun, if the assignments are correct (i mean the problems, not the answers)
04:47:41 <ibid> Marvin--: btw, which course=?
04:51:45 <Marvin--> ibid: it's called Programming Languages
04:52:15 <Marvin--> ibid: some basic material on syntax, type systems and semantics, the three first assignments together lets them create their own imperative language
04:52:19 <Marvin--> pretty standard stuff I suppose
04:53:11 <olczyk> ibid: americans too.
04:53:17 <ibid> basically the same course i'm giving
04:53:20 <olczyk> The trick is to ask them questions.
04:53:20 <ibid> Marvin--: which level?
04:54:20 <Marvin--> second year on CS and third on CE I think
04:55:25 <ibid> mine is advanced level (between bsc and msc essentially), but i think it should be split up
04:56:17 <Marvin--> well, I don't have a msc yet, so it's kinda ruled out that I'd teach at that level ;)
04:56:40 <ibid> well, me neither, but who's counting :-)
04:56:45 <Marvin--> heh
04:57:08 <ibid> (i have a bsc, and my msc is almost finished)
04:57:21 <Heffalump> here you have to be a phd student to do any teaching
04:57:29 <Heffalump> (though not all phd students have mscs)
04:57:49 <ibid> (i just need to get this course off my back so i can concentrate one more month on my thesis)
04:58:22 <Marvin--> here the phd students teach on the advanced courses and pretty much anyone who's taken a basic course successfully can assist on it
04:58:32 <ibid> well, out here there's a lot of shortage on good teachers. and i am a phd student, just not yet officially :-)
04:58:58 <Marvin--> I'm going to apply for an amanuensis to make stuff a bit more formal
04:59:21 <ibid> Marvin--: basically the same arrangement here
04:59:33 <Heffalump> what's an amanuensis?
04:59:33 <ibid> (amanuensis? the person who does all the boring work?)
05:00:20 <Marvin--> well, an amanuensis is employed, whereas our normal teaching assistant system is a payed-per-hour thing
05:00:27 <Heffalump> ah
05:00:46 <Marvin--> I suppose the work is pretty much the same though :)
05:01:32 <Marvin--> but hopefully it's a way to get to know the staff better and find someone who can speak for me when I apply for a phd position in a year or two ;)
05:02:20 <ibid> the funny thing is, i'm employed as an "assistant" (basically, a spot for phd students, includes teaching and research) for which the official requirement is an msc. i don't have an msc so i get paid less than a regular assistant, but still in all my papers it says i'm qualified :-)
05:02:47 <Marvin--> beuracracy :(
05:03:05 <ibid> Marvin--: out here, the amanuensis is the person who runs the department administration: assists the dept head, prepares all the official decisions, prepares employment paperwork etc
05:03:05 <Marvin--> teaching assistants here get paid more if they have a msc too
05:03:50 <Marvin--> oh, I don't know what the amanuenses do here, it just says it's a 20% employment or something like that
05:03:56 <Marvin--> dennisb? do you know?
05:04:01 <ibid> this is a 100 % employment :-)
05:04:05 <Marvin--> oh
05:04:14 <Marvin--> maybe it's a lingual clash :)
05:04:18 <ibid> yes
05:05:11 <Marvin--> A friend of mine has an amanuensis in the maths department, he's teaching on some sort of intro course
05:05:49 <Marvin--> well, I'm off to do some stuff... see you later
05:19:12 * olczyk ponders the question. If you are in a multithreaded program and one thread ascends into a Monad, What happens to the others?
05:22:50 <Heffalump> "ascends"?
05:23:18 <Heffalump> threads are controlled in IO
07:00:50 <Marvin--> mesa back
07:11:09 <Luke> and on ghc compiles....
07:14:42 <Marvin--> heh
07:24:51 <o3> hullo
07:29:01 <Heffalump> hi
07:29:11 <o3> got .so loading working 8)
07:30:02 <Heffalump> ooooh
07:30:05 <Heffalump> how'd you manage it?
07:30:31 <o3> found out that ghci's Linker.c had a dlopen() in it
07:30:37 <o3> in a function called addDLL()
07:30:53 <o3> so i just added stuff in to the runtime loader to handle that
07:31:29 <Heffalump> wdym "handle that"?
07:31:38 <Heffalump> hangon, what kind of .so are you loading?
07:31:50 <o3> oh, added a function loadLibrary, which calls Linker.c's addDLL
07:31:59 <o3> a .so constructed from a haskell module
07:32:05 <o3> ghc -o Foo.o Foo.hs
07:32:13 <o3> gcc -shared -fPIC -o Foo.so Foo.o
07:32:32 <o3> check your email 8)
07:33:04 <Heffalump> nice.
07:33:24 * Heffalump just needs to find some time to write all the things I want to make use of this now :-)
07:33:31 <o3> 8)  ditto!
07:35:20 <Marvin--> huh? Haskell "plugins"? :)
07:36:05 <Heffalump> so this should make what norpan (?) was trying to do possible, right?
07:36:17 <dennisb> Heffalump: sounds just right
07:36:43 <o3> Heffalump: maybe
07:36:56 <dennisb> o3: so, where do I find out more? Did you post it to a list or just to some people
07:37:30 <o3> dennisb: it's posted to glasgow-haskell-users
07:37:37 <Heffalump> o3: I don't understand how you got round the problem of making .so files from ghc-compiled code
07:37:38 <o3> there's a mailing list archive around ...
07:37:57 <o3> Heffalump: what problem?
07:38:13 <Heffalump> the thing about the way it lays out code next to data or something
07:38:32 <o3> no idea ... seems to work okay in my (very minimal) testing
07:38:48 <Heffalump> oh well, we'll see what happens :-)
07:38:54 <dennisb> o3: I'm on the list, it's just that it's so many lists i'm on...
07:40:10 <o3> dennisb: http://www.haskell.org/pipermail/glasgow-haskell-users/2002-September/004093.html
07:40:21 <dennisb> o3: I just read the mail
07:40:36 <dennisb> And I'll play with this some day. Sounds like great fun
07:48:49 <Marvin--> This looks way cool
07:56:24 <Marvin--> hmm, this takes forever to link
07:58:04 <o3> yeah, it does
07:58:33 <Marvin--> Lower.so: not a relocatable object (.o) file
07:58:52 <Marvin--> the .o files work though
07:59:50 <o3> Marvin--: oh?  hmm, that's odd
08:00:20 <o3> oh
08:00:43 <o3> sigh, don't change things unless you test them *slaps self*
08:00:50 <Marvin--> :)
08:00:55 <Marvin--> what should I tweak?
08:01:59 <o3> i'm checking it now ...
08:02:01 <o3> (it's linking :)
08:02:30 <Marvin--> :)
08:02:56 <Marvin--> hmm, how much trickery do I have to employ to use RuntimeLoader from ghci?
08:03:38 <o3> i don't think it'll work at all from GHCI
08:03:44 <Marvin--> dang
08:03:50 <o3> it's basically using GHCI's own linking functions
08:04:04 <Heffalump> but ghci can presumably load itself?
08:04:12 <Heffalump> IM it's own source
08:04:16 <Heffalump> s/it's/its/
08:04:18 <Marvin--> hopefully things like this will become part of the standard distribution
08:04:21 <o3> i'm not sure
08:05:32 <Marvin--> the code in RuntimeLoader is very evil ;)
08:06:57 <o3> Marvin--: edit src/Main.hs, remove the . in the string from lines 57 and 58
08:07:06 <o3> (so it becomes "so" instead of ".so")
08:07:11 <Marvin--> haha
08:07:18 <o3> and while you're there, note line 56
08:07:22 <o3> i was very proud of that effort ;)
08:07:39 <Marvin--> reverse reverse? eew
08:08:00 <o3> chilli will lart me for that :)
08:08:17 <Marvin--> "if it works, it works"
08:11:43 <Marvin--> hmm, I think I'll do a make clean and rebuild again
08:20:07 * o3 does a make distcheck and goes to have a shower
08:20:08 <Marvin--> o3: still doesn't seem to work :/
08:20:13 <o3> Marvin--: no?
08:20:18 <Marvin--> Fail: Couldn't load library: ROT13.so: cannot open shared object file: No such file or directory
08:20:31 <o3> Marvin--: do you have a ROT13.so file in the directory?
08:20:38 <Marvin--> yes
08:21:56 <o3> *puzzled*
08:23:34 * Marvin-- tries to understand Monad.Cont
08:25:21 <o3> that's quite strange, it shouldn't give that error if the file exists
08:25:33 <o3> (that error's reported by dlopen() itself; nothing to do with the haskell code)
08:25:47 <Marvin--> Aha, hmm, then I probably need a . in my LD_LIBRARY_PATH?
08:25:59 <Marvin--> with ./ROT13.so it worked :)
08:26:22 <o3> i don't have a . in my $LD_LIBRARY_PATH, and it worked without the ./ for me
08:26:47 <Marvin--> odd
08:27:06 <o3> oh well, i'm glad it worked :)
08:27:08 <Marvin--> you sure you're not doing ./src/TextFilter plugins/ROT13.so?
08:27:22 <Marvin--> 'cause if it finds a / in the path it won't go looking in the path
08:27:31 <Marvin--> err.. in LD_LIBRARY_PATH that is
08:27:54 <o3> 1:27 .../example/plugins % echo foo | ../src/TextFilter ROT13.so 
08:27:54 <o3> sbb
08:28:25 <Marvin--> odd
08:28:34 <Marvin--> oh well
08:28:54 <o3> nod.  oh well, new version is up :)
08:29:55 <o3> (only difference is that the bug that you mentioned)
08:30:01 <o3> right, really showertime now :)
08:43:52 <o3> night!
08:44:31 <Heffalump> night
09:00:27 * Marvin-- toys a bit with runCont
09:49:32 <Marvin--> Eehh.. I must be misunderstanding how to work with ErrorT
09:49:40 <Marvin--> somehow, return (return True) doesn't feel right
09:49:45 <Marvin--> :)
10:32:32 <Heffalump> does return (return T) type check?
10:33:57 <Heffalump> oh, of course it would
10:34:25 <Heffalump> you want the join operation, you do :-)
10:35:08 <BlizzNL> Anyone knows a third kind of polymorphism available in Haskell? I know of parametric and ad-hoc but I need another one ;)
10:35:37 * BlizzNL is writing a paper on different kinds of polymorphism and likes to give examples in both Haskell and C++
10:35:46 <ibid> well, there are only four kinds in the world, according to cardelli
10:36:14 <sethk> Haskell has some operator overloading...
10:36:15 <BlizzNL> ibid: yeah I read about that, but it focusses on Java subtypes, doesn;t it?
10:36:23 <ibid> BlizzNL: no
10:36:34 <BlizzNL> sethk: overloading == ad hoc
10:36:36 <Heffalump> operator oberloading is ad hoc
10:36:43 <BlizzNL> Heffalump: yep ;)
10:36:43 <ibid> BlizzNL: this was an article called "type systems" iirc
10:36:55 <Heffalump> genericity (a la Generic Haskell) is something Haskell istself doesn't have
10:37:03 <Heffalump> ibid: what's the 4th?
10:37:25 <sethk> What type is "deriving" (limited as it is...)?
10:37:33 <BlizzNL> Heffalump: coercion, overloading, parametric, inclusion
10:37:42 <ibid> what BlizzNL said
10:37:49 <Heffalump> oh, ok.
10:37:53 <ibid> coercion and overloading are ad-hoc
10:37:54 <Heffalump> hmm.
10:37:59 <ibid> parametric and inclusion are universal
10:38:07 <BlizzNL> ibid: indeed
10:39:33 <BlizzNL> but to make the link to my question: Haskell only has overloading + parametric ?
10:39:37 <sethk> If I can change the subject for a moment :-) I have a function, type [String] -> [[String]]-> [[String]]...
10:39:54 <sethk> The pattern (l:[]) x
10:39:59 <ibid> BlizzNL: well, one can argue that it has some coercion :-)
10:40:16 <ibid> BlizzNL: although it is implemented as an implicit call to fromInteger
10:40:22 <ibid> or defined...
10:40:30 <sethk> Does not match against an input where the "l:[]" argument is [String], length 1.
10:40:41 <sethk> Should it?
10:40:42 <BlizzNL> ibid: mmm interesting :) I'll look into it
10:42:10 <ibid> sorry, the reference was luca cardelli & peter wegner: on understanding types, data abstraction, and polymorphism.  acm computing surveys vol 17 no 4
10:42:21 <ibid> dec 1995
10:42:45 <ibid> a little early to be talking about java (unless cardelli or wegner was involved in the java project)
10:43:00 <ibid> http://research.microsoft.com/Users/luca/Papers/TypeSystems.A4.pdf
10:43:03 <ibid> bah
10:43:15 <ibid> wrong url
10:43:22 <ibid> http://research.microsoft.com/Users/luca/Papers/OnUnderstanding.A4.pdf
10:46:01 <BlizzNL> ibid: thnx
10:50:12 <sethk> Does a pattern (x:[]) match a list of length 1?
10:50:20 <Heffalump> Haskell 98 doesn't have coercion, I think GHC might sometimes allow it
10:50:23 <Heffalump> sethk: yes
10:50:49 <BlizzNL> ibid: BTW this paper is from Dec 1985 ;)
10:50:59 <olczyk> Assuming you have getInt:: IO Int and putInt:: IO Int -> IO () and add::Int->Int->Int how would you write a program that reads two integers and prints their sum.
10:51:11 <sethk> Heffalump:  hmm, it doesn't seem to; when I changed to to a guard which checks for ((length x:xs) == 1), it works.  What could I be doing wrong?
10:51:20 <ibid> Heffalump: haskell 98 does have a feature that has some similarity to coercion
10:51:35 <sethk> heffalump:  (Obviously I also change (x:[]) to (x:xs))
10:51:36 <ibid> BlizzNL: hmm, so it seems. so much the better, definitely not talking about java :-)
10:51:42 <Heffalump> ibid: not really, since it uses overloading to implement it
10:52:05 <Heffalump> sethk: your bracketing looks strange there
10:52:09 <ibid> Heffalump: that does not invalidate what i said
10:52:17 <Heffalump> length x:xs is (length x):xs, not length (x:xs)
10:52:48 <Heffalump> ibid: well, if coercion is classified separately to overloading, then implementing coercion using overloading probably isn't true coercion.
10:52:50 <sethk> Heffalump:  Yes, I wrote it wrong here but correctly in the program.
10:53:09 <Heffalump> sethk: I don't really understand what the rest of your code is, can you show me a bit more?
10:53:48 <sethk> Heffalump:  Sure, it is quick.  Let me pull out the trace messages so you don't have to wade through them.  One second...
10:53:58 <ibid> Heffalump: actually, it's not implemented as overloading. it's implemented by inserting an invisible fromInteger call
10:54:41 <Heffalump> ibid: but fromInteger does use overloading
10:55:04 <ibid> Heffalump: yes it does. but we don't write (fromInteger 10), we write 10
10:55:17 <Heffalump> but that's the way literals are parsed
10:55:22 <Heffalump> rather than true coercion
10:55:26 <sethk> Heffalump:  "run sentence" runs a Parsec parser which turns a csv line into a list of string; this works.
10:55:32 <ibid> Heffalump: and coercion is basically inserting invisible function calls
10:55:35 <sethk> Heffalump:  
10:55:50 <sethk> Heffalump:  
10:55:58 <Heffalump> ibid: I thought coercion usually involved explicit function calls
10:56:05 <ibid> Heffalump: no
10:56:07 <Heffalump> ok
10:56:29 <Heffalump> the thing is that it /only/ applies to literals in Haskell
10:56:34 <ibid> Heffalump: if you have int c; and double d; in C, then c + d includes a coercion of c to double
10:56:38 <ibid> Heffalump: that's true
10:56:41 <Heffalump> no non-literal values get invisible calls inserted
10:56:46 <sethk> Heffalump:  doSentences :: [String] -> [[String]] -> [[String]]
10:56:55 <sethk> Heffalump:  doSentences ([]) res = myTrace ("doSentences 0\n") (res)
10:57:03 <ibid> Heffalump: true
10:57:18 <sethk> Heffalump:  Wrong copy, wait a moment (still has the trace statements...)
10:57:20 <Heffalump> sethk: {as an aside, the brackets around [] in that pattern are redundant}
10:57:21 <ibid> (and in C, + is not a function)
10:57:37 <sethk> Heffalump:  doSentences :: [String] -> [[String]] -> [[String]]
10:57:45 <sethk> Heffalump:  doSentences ([]) res = res
10:57:52 <sethk> Heffalump:  doSentences (l:ls) [[]] = doSentences ls [(run sentence l)]
10:57:59 <sethk> Heffalump:  doSentences (l:ls) res
10:58:07 <sethk> Heffalump:      | ((length (l:ls)) == 1) = ((run sentence l):res)
10:58:15 <sethk> Heffalump:      | otherwise = doSentences ls [(run sentence l)]
10:58:33 <sethk> Heffalump:  The rest is a main program that supplies the lines to as [String]
10:58:44 <Heffalump> so in the last case you throw away res?
10:59:31 <Heffalump> anyway, can you explain what goes wrong?
10:59:44 <sethk> Heffalump:  No, that is a mistake, but it never gets there...
11:00:06 <Heffalump> well, is doSentences ever called with the first parameter of length 2?
11:00:12 <sethk> Heffalump:  The code I just showed you works.  Here is what didn't work (didn't match the pattern I expected):
11:00:22 <Heffalump> ok.
11:00:46 <Heffalump> I would expect doSentences (l:[]) res = run sentence l:res
11:01:06 <Heffalump> doSentences (l:ls) res = doSentences ls [run sentence l]
11:01:11 <Heffalump> to be equivalent to the above.
11:01:17 <Heffalump> (well, the last clause of the above)
11:01:39 <sethk> Haffalump:  Yes, that is correct.  Here is the other line...
11:02:19 <sethk> Heffalump:  doSentences (l:[]) res = ((run sentence l):res)
11:02:43 <Heffalump> the other line?
11:03:16 <sethk> Haffalump:  The line that doesn't match when (l:[]) is [String], length 1
11:03:54 <Igloo> Do you get an error about it not matching or just behaviour you don't expect?
11:03:57 <sethk> Heffalump:  The last line (blush) I pasted from the wrong place (where res is [[]]), it is really...
11:04:05 <sethk> Heffalump:  as you surmised...
11:04:08 <Heffalump> YM when the first parameter is a [String] of length 1?
11:04:28 <Heffalump> could you put two programs on the web that only differ in the way you do the guards and behave differently?
11:04:37 <Heffalump> (or email me them or something)
11:05:01 <sethk> Heffalump:  Can you do the IRC file receive?  Or, what's your email address?
11:05:10 <Heffalump> ganesh@earth.li
11:05:13 <Heffalump> is simplest
11:05:20 <Heffalump> I can do DCC receive if you prefer
11:06:52 <sethk> Heffalump:  Either way.  Your choice.
11:07:13 <Heffalump> email
11:09:27 <sethk> Heffalump:  They are on the way.  TIA.
11:11:12 <Heffalump> those two programs have quite a few more differences than just different guards
11:11:47 <sethk> Heffalump:  Yes, let me modify the "outfile.hs" to have only the one change and send it again.
11:12:19 <Heffalump> ta
11:14:14 <sethk> Heffalump:  On it's way.  (I had checked the earlier one out of version control.)
11:14:35 <olczyk> I'm sorry. I jumped in with a question when people were too busy. Is it a good time to ask now?
11:14:55 <sethk> Heffalump:  There is a typo, sending again (or just change "run2" to "run")
11:15:11 <sethk> oclzyk:  I always jump in anyway, as you may have noticed...
11:15:33 <sethk> oclzyk:  But the question has scrolled into never-never land
11:15:51 <olczyk> Yeah but if you're to preoccupied with something else you won't anser my querstion. Anyway here goes...
11:15:53 <olczyk> Assuming you have getInt:: IO Int and putInt:: IO Int -> IO () and add::Int->Int->Int how would you write a program that reads two integers and prints their sum.
11:16:49 <Igloo> Why do you need putInt to have that type?
11:17:27 <sethk> olczyk:  Well, since I'm too brain dead to use the "do" construct, I do it like this:
11:17:51 <olczyk> I'm sorry put int should look like putInt::Int-> IO().
11:18:10 <sethk> olczyk:  getInt >>= \i1 -> getInt >>= \i2 -> putStrLn (show (i1 + i2))
11:18:36 <sethk> olcyzk:  (or perhaps return(putStrLn..., I can never remember)
11:19:07 <Igloo> do notation isn't very complex, and you didn't use add or putInt  :-)
11:19:11 <olczyk> GBut aren't i1 and i2 of type IO Int?
11:19:21 <Heffalump> the code is still different, because your clauses are in a different order
11:19:31 <Igloo> ol: Look at the type of (>>=)
11:19:38 <Heffalump> doSentences (l:[]) res = trace ("doSentences 1\n") ((run sentence l):res)
11:19:38 <Heffalump> doSentences (l:ls) [[]] = doSentences ls [(run sentence l)]
11:19:41 <sethk> Igloo:  That's true.  Olcyzk:  no, the lamdba removes the IO part.
11:19:54 <sethk> Heffalump:  I'm listening, let me look...
11:19:55 <Igloo> The lambda does not remove the IO part
11:19:58 <Heffalump> but
11:19:58 <Heffalump> doSentences (l:ls) [[]] = doSentences ls [(run sentence l)]
11:19:59 <Heffalump> doSentences (l:ls) res
11:19:59 <Heffalump>     | ((length (l:ls)) == 1) = ((run sentence l):res)
11:19:59 <Heffalump>     | otherwise = doSentences ls ((run sentence l):res)
11:20:13 <Heffalump> the exact equivalent of the latter code would be:
11:20:17 <Heffalump> doSentences (l:ls) [[]] = doSentences ls [(run sentence l)]
11:20:26 <sethk> Igloo:  perhaps not really, but it has that effect.
11:20:29 <Heffalump> doSentences (l:[]) res = ((run sentence l):res)
11:20:40 <Heffalump> doSentences (l:ls) res = doSentences ls ((run sentence l):res)
11:20:46 <Heffalump> could you try that?
11:20:47 <Igloo> It's (>>=) doing the, ermmm, unlifting I think?
11:21:25 <sethk> Igloo:  True (blush) 
11:21:36 <sethk> Heffalump:  I will try that now...
11:23:17 <sethk> Heffalump:  In that order?
11:23:28 <Heffalump> the order I said
11:25:00 <sethk> Heffalump:  Yes, that works.  Can you elaborate?
11:25:08 <Heffalump> well, clauses are matched in order
11:25:25 <Heffalump> I didn't look exactly what difference that would have made here, but it would probably have had some effect
11:25:33 <Heffalump> (and it clearly did, since it fixed your problem :-)
11:25:44 <sethk> Heffalump:  So you are saying that the reason it didn't match is because it matched an earlier pattern?
11:25:53 <Heffalump> probably, yes
11:26:43 <Heffalump> in fact, definitely, given that changing the order fixed it
11:27:19 <sethk> Heffalump:  The first pattern is ([]) res, which doesn't match...
11:28:32 <Heffalump>  doSentences (l:ls) [[]] = doSentences ls [(run sentence l)]
11:28:37 <Heffalump> must have been the one that was matching
11:28:44 <Heffalump> cos that's the one that it got moved around
11:29:39 <sethk> Heffalump:  The second pattern is (l:[]) res, which should have matchedHeffalump:  Yes :-), but, in the code, I added a generic pattern (x y) so I could print out the input, I added the generic pattern at the end, and the generic pattern matched.
11:29:59 <sethk> Heffalump:  Let me make sure that is really what I did.
11:30:08 <Heffalump> if changing the order fixed things, then the clause that was originally at the top must have been matching before.
11:31:01 <sethk> Heffalump:  Clearly.  I will study the patterns more closely to figure out what I'm missing.  Thanks for the fix.
11:32:01 <olczyk> getInt >>= \l1-> getInt >>= \l2 -> printInt (add l1 l1 )
11:32:36 <sethk> olczyk:  That looks like it will work.  Does it?
11:32:59 <olczyk> I think I see what I didn't understand now. I expected the 'unlifting' to happen as a result(rhs), but it happens on the parameter(lhs) side. 
11:34:32 <olczyk> AFAIK getInt and printInt don't exist. I ask because I'm trying to understand "how to move between the Monad side and the 'standard' side".
11:35:04 <sethk> Igloo:  When I try using the "do" syntax, I always get one of:  IO needs to be lifted (and I can't figure out how to lift it other than with the >>=), or "last statement in do must be an expression".  The latter is probably just sloppy code, but what about the former?
11:35:06 * Heffalump scrolls back to see what olczyk is asking about
11:35:06 <Igloo> ol: It doesn't explicitly happen anywhere
11:35:28 <Igloo> (>>=) :: Monad a => a b -> (b -> a c) -> a c, or in this case (>>=) :: IO b -> (b -> IO c) -> IO c
11:36:11 <Igloo> So it takes an IO b and then must unlift it (as it can't get a b from anywhere else) before applying its second argument (which it must do as it can't get an IO c from anywhere else)
11:36:28 <Igloo> (well, ignoring undefined etc)
11:37:00 <Igloo> sethk: I'd need to see an example for the first one as I've never seen the error
11:37:32 <sethk> Igloo:  It isn't an error, per se, it is a type mismatch that I don't know how to eliminate.  Hold on, I'll give you an example...
11:37:43 <Igloo> I don't think it ever makes sense to not have an expression as the last thing in a do
11:37:55 <olczyk> Yes and I basically expect a function like drop::IO a-> a . Instead it's sort of squeezed in via >>= and lambda.
11:38:07 <sethk> Igloo:  When it complains the last thing in the do is a putStrLn call
11:38:15 <sethk> (this is about the "last expression" error)
11:38:36 <Igloo> Can you give me an example of that too?
11:38:51 <sethk> Igloo:  Yes, wait a moment...
11:39:15 <Igloo> OK  :-)
11:39:46 <Heffalump> you can't have a binder as the last thing in a do, certainly.
11:39:53 <Heffalump> so x <- foo
11:39:59 <Heffalump> isn't valid as the last thing in a do
11:40:03 <Heffalump> similarly for a let
11:40:05 <Igloo> Oh, yes, so it can make sense
11:40:11 <Heffalump> (as opposed to let ... in)
11:40:15 <Heffalump> and anything else is an expression
11:40:26 <Igloo> Oh, I guess not as you can drop the binding in that case anyway
11:41:38 <sethk> Igloo (et. al):  The following gets "Couldn't match String against IO String":
11:42:15 <Igloo> That's not the error you said above, but go on anyway
11:42:19 <Heffalump> that probably means you need a return around it
11:42:28 * BlizzNL has to go
11:42:30 <Heffalump> adding return $ to the beginning will fix the type error.
11:42:39 <Heffalump> and is probably the correct thing to do
11:42:50 <sethk> Heffalump:  I'll try that, hold on...
11:43:06 <Igloo> I would have thought the problem was the other way round, but always have to think about which way round error messages are
11:43:27 <Heffalump> igloo: the last generator in a do needs to be of IO type
11:43:31 <Heffalump> so it must be that way round
11:43:46 <Heffalump> (well, of m type for the appropriate monad, but IO in this case)
11:43:47 <Igloo> I suspect he's trying to go putStrLn getcontents or something
11:43:55 <Heffalump> OIC.
11:44:02 <Heffalump> sethk: ok, possibly ignore what I just said then
11:44:06 <Heffalump> let's see the code :-)
11:44:10 <Igloo> Most things you'd put as the last line in a do have type a -> IO b anyway
11:44:22 <Heffalump> not if you want to return a value
11:44:27 <Igloo> Oh, except that brackets the wrong way. YKWIM.
11:44:30 <Heffalump> that you've calculated above
11:44:33 <Igloo> Oh, true
11:44:51 <Heffalump> but given the rest of the conversation putStrLn getContents makes sense.
11:45:03 <sethk> Igloo:  Yes, that is close.  Heffalump, it doesn't change the error.  Here are the lines:
11:45:24 <Heffalump> sethk: it wouldn't, I was wrong (well, guessing what you'd done incorrectly)
11:45:42 <sethk> do ifile <- openFile name1 ReadMode
11:45:48 <sethk> ofile <- openFile name2 WriteMode
11:46:39 <sethk> lns <- (lines (return((hGetContents ifile))))
11:46:55 <Heffalump> right, yeah
11:46:58 <sethk> Which is where the error occurs.  As Igloo suggested, this isn't the end of the code.
11:47:06 <Heffalump> you want:
11:47:11 <Heffalump> contents <- hGetContents ifile
11:47:20 <Heffalump> let lns = lines contents
11:47:22 <Heffalump> (...)
11:47:39 <Heffalump> cos hGetContents returns an IO type, and lines wants a non-IO type
11:48:13 <sethk> Heffalump:  Exactly, but with the combinators I can lift; is there a way to lift in the do context.  In this case as you point out there are other ways, but not always.
11:48:55 <Igloo> You can use return to lift and <- to unlift with do notation
11:49:01 <Heffalump> you can use liftM
11:49:14 <Heffalump> lns <- liftM lines (hGetContents file)
11:49:37 <sethk> Heffalump:  I didn't know that existed.  Igloo:  How would I unlift with "<-"?
11:49:57 <Igloo> contents <- hGetContents ifile
11:49:58 <Heffalump> liftM is implemented using <- and return
11:50:04 <Igloo> hGetContents ifile :: IO String
11:50:07 <Igloo> contents :: String
11:52:38 * Heffalump goes shopping
11:53:00 <sethk> Igloo:  I'll play with that.  I thought I had tried it but I must have mangled the syntax.  Thanks, all, for the help.
11:54:40 <Igloo> np
13:46:35 * Heffalump ungoes shopping
20:18:02 <sethk> Anybody home?????
20:29:49 <ChilliX> Hi Seth
21:05:46 <sethk> Hello, if you are still there :-)
21:07:32 <ChilliX> :-)
21:09:46 <sethk> Do you happen to know whether Parsec reverses the order of a list of strings (they way Happy does if you use left recursion)?
21:10:38 <ChilliX> not sure (haven't used parsec), but would guess that it doesn't if you use the combinator for parsing a list of things
21:11:24 <sethk> I thought the same.  Maybe something in my code is backwards (wouldn't be the first time).
22:59:58 <sethk> Hi, all, (anyone?)
