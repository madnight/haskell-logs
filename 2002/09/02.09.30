01:31:40 <Marvin--> Is 'select' exposed in ghc somewhere?
01:32:36 <sethk> Yes, in I believe the network package.
01:33:22 <Marvin--> I've been grep:ing and grep:ing :)
01:34:31 <sethk> I can't remember which document, but I found it in the help a couple of weeks ago.
01:35:41 <Marvin--> and it's called 'select'? or 'hSelect' or something?
01:36:16 <sethk> I don't think so, but I'm not sure.  Look for asynchronous
01:37:30 <Marvin--> There isn't much *in* the network package to look at, except Network, BSD and Socket...
01:38:30 <sethk> I'll see if I can find it.
01:40:35 <Marvin--> find -name \*.hs\* | xargs egrep -i 'async|select'  <- doesn't give me anything in the network/ dir
01:56:59 <sethk> look in conc.lhs
02:09:01 <Marvin--> uh, where is that file?
02:09:36 <Marvin--> or do you mean Conc.lhs?
02:10:10 <sethk> Yes, Conc.lhs.  The "waitFor" methods.
02:10:47 <Marvin--> Hmm
02:12:43 <Marvin--> So how do I get a fileno from a Handle?
02:12:53 * Marvin-- hasn't learned to navigate the docs yet
02:13:39 <Marvin--> My problem is that I want to select over several filenos though :/
02:13:46 <Marvin--> i.e. no threads
02:25:30 <andersca> hey shapr
02:25:35 <shapr> hi andersca, what's up?
02:25:45 <andersca> not much
02:30:38 * Marvin-- solves the dang exercises for Wednesday
02:30:56 <andersca> semantics stuff?
02:31:08 <Marvin--> nod
02:31:13 <Marvin--> it's not hard, it's just a lot of work
02:31:15 * shapr wonders what dang stands for ;-)
02:31:28 <Marvin--> shapr: darn, damn, or whatever you feel like
02:31:35 * shapr grins
02:31:50 * Marvin-- is going to torture the students with two ways of modelling I/O
02:32:03 <Heffalump> what are the two ways?
02:32:12 <andersca> the right way and the wrong way
02:32:17 <Marvin--> no, both ways are acceptable
02:32:45 <Marvin--> One approach is to couple the I/O in the state, so you'd have (env, qi, qo)
02:32:51 <Marvin--> an input queue and an output queue
02:33:35 <Marvin--> Another approach is to make the transition rule ternary: <S, st> -a-> <S', st'>, carrying an action a as well
02:33:48 <andersca> nod
02:33:55 <Marvin--> where actions might be either nop, put(n) or get(n)  (simple example)
02:34:31 <Heffalump> but then to write -->* you need a sequence of actions
02:34:35 <Marvin--> yes
02:34:47 <Marvin--> nop* == nop :)
02:34:50 <Heffalump> and some of the actions in that sequence might depend on previous ones
02:35:05 <Marvin--> yes
02:36:22 <Marvin--> There's a notation â standing for "if a is nop, then â is nop*, else, â is nop* a nop*"
02:36:57 <Marvin--> 'course, no matter which approach you take, defining semantic equivalence becomes tricky
02:53:50 <Marvin--> sethk: So, no hopes for me?
02:54:33 * shapr begins to bounce
02:55:09 <Heffalump> hmm?
02:55:27 <shapr> I have enough coffee to open my eyes now
02:56:11 <Heffalump> ahh
02:56:30 <shapr> good morning Heffalump!
02:56:33 <shapr> how's life?
03:03:50 <Marvin--> well, I should be going
03:04:04 <shapr> have a nice day Marvin--
03:04:13 * shapr yawns
03:05:33 * Marvin-- waves
03:52:16 * shapr boings
03:52:26 <shapr> hi spikeymikey
04:19:13 <shapr> wow, c++ must warp minds permanently
04:19:32 * shapr reads http://homepage.mac.com/kevinmarks/personality.html
07:38:44 <Blizz>  Anyone knows a good paper or something on evaluating expressions (e.g. proposition logic) in haskell?
08:50:28 <Heffalump> hi
08:50:32 <hdaume> sup
08:50:45 * shapr is writing for-pay code again
08:50:50 <shapr> not haskell :-/
08:51:01 <shapr> hdaume: what are you doing?
08:51:40 <norpan> i am writing for-pay haskell code, life is good :)
08:51:42 <hdaume> trying to get some quick results to show my advisor in 9 minutes :)
08:51:59 <shapr> wow, for-pay!
08:52:05 <shapr> I'm impressed
08:52:10 <hdaume> for-not-too-much-pay :)
08:52:36 <Heffalump> I ought to be getting paid to do it from November, but I'm in a uni so that doesn't count :-)
08:52:49 <Heffalump> (and I was paid to do it as a student, but that was a grant, not a salary)
09:29:55 <Chilli> Moin
09:31:32 <Igloo> Hiya
09:31:56 <Heffalump> hiya
09:32:05 <Heffalump> no networking in the hotel then?
09:32:24 <Chilli> We are staying at Bob Harper's place
09:32:32 <Heffalump> ah, right
09:32:39 <Chilli> and he has networking, but I haven't had much time to get online
09:32:54 <Heffalump> do you know what there'll be at the conference?
09:32:55 <Chilli> we did some sight seeing yesterday :-)
09:33:02 <Chilli> no idea
09:33:03 <Marvin--> Hmm. Monads come from category theory, right? How is that related to domain theory?
09:33:04 <Heffalump> anything worth seeing?
09:33:04 <Chilli> but I can ask
09:33:25 <Chilli> yeah, there is something definitely worth seeing
09:33:31 <Chilli> namely Fallingwaters
09:33:40 <Heffalump> how far away? I won't have a car.
09:33:56 <Chilli> http://www.wpconline.org/fallingwaterhome.htm
09:34:21 <Chilli> hmm, it's a bit; probably took 45min-1h by car
09:34:42 <Chilli> maybe there is alternative transportation
09:34:46 <Chilli> but it is worth the effort
09:34:52 <Chilli> IMHO
09:35:12 <hdaume> falling water is pretty cool, though i don't really like the expansion part of it
09:35:15 * hdaume went to CMU
09:35:25 <Chilli> and there is a really good South Indian restaurant on the way back
09:35:33 <Chilli> had really good dosas yesterday :-)
09:35:43 <hdaume> mmm...srees
09:35:53 <hdaume> i think there's actually a srees.com :)
09:36:15 <Chilli> hdaume: are you coming to PLI?
09:36:29 <hdaume> (srees is really good indian food sold out back of cmu)
09:36:42 <hdaume> alas, no...i couldn't get cheap enough airfare (i had even arranged to stay with some friends)
09:37:09 <Heffalump> well, I'd have to skip some session to do that
09:37:51 <Igloo> There's one on .NET IL transforming stuff you already know about. You could skip that one.
09:37:57 <Chilli> Heffalump: you leave immediately after the conf?
09:40:09 <Heffalump> chilli: yeah
09:43:11 <Heffalump> igloo: :-p
09:43:22 <Heffalump> it won't be any good anyway :-)
09:43:57 <Heffalump> hmm, 5 1/2 days of solid talks.
10:23:02 * Chilli -> lunch
11:10:18 <Chilli> Heffalump: there *may* be networking at the conf
11:10:58 <Chilli> currently, the hotel wants to charge an outragous price for it, but the organiser try to negotiate
11:11:16 <Chilli> if they go down with the price, there will be networking; otherwise, not
11:11:30 <Chilli> in any case, dialup should work from the hotel rooms
12:59:57 <engstad> Greets. I'm pretty confused about the libraries. I need the state monad ST, and mutable arrays (MutArr). From where should I import them?
13:02:20 <hdaume> what compiler?
13:02:22 <Heffalump> Control.Monad.ST ?
13:02:24 <Marvin--> with ghc you'll get the state monad from Control.Monad.State
13:02:30 <Heffalump> nearly :-)
13:02:34 <hdaume> arrays from Data.Array.ST
13:02:44 <Marvin--> sorry, ST
13:02:57 <engstad> GHC.
13:03:01 <Heffalump> oh, I thought I was wrong :-)
13:03:13 <engstad> So, which is it, Control.Monad or Data.Array ?
13:03:19 <Marvin--> Heffalump: there's both State and ST :)
13:03:34 <Heffalump> and State is a pure State monad and ST is GHC state threads?
13:03:37 <engstad> I know.. that's what is confusing me.
13:03:46 <Marvin--> Heffalump: dunno
13:03:50 <Heffalump> (just guessing here, I should actually RTFH)
13:04:04 * Heffalump --> do so
13:04:13 <engstad> ;-)
13:04:24 <hdaume> you need both control.monad and data.array
13:05:09 <Heffalump> ah, Control.Monad.State uses fundeps and the like
13:05:30 <Marvin--> I've only used C.M.State
13:06:14 <engstad> Hmm... I also need regular Array-s as well.. I get a name conflict between Data.Array and GHC.Arr.
13:06:26 <Heffalump> import qualified
13:06:29 <hdaume> you'll need to qualify at least one of them
13:06:39 <engstad> Okey.
13:07:58 <hdaume> (note that i, too, find that incredibly obnoxious)
13:08:16 <engstad> :/
13:08:49 <Heffalump> it doesn't seem unreasonable
13:09:14 <hdaume> i think so...you shouldn't have to qualify bounds, esp. since bounds isn't even monadic
13:09:18 <Heffalump> the alternative would be contriving different ways of saying "Array"
13:09:19 <hdaume> it really should be overloaded
13:09:33 <Heffalump> is "bounds" the only collision?
13:09:40 <Heffalump> a quick glance suggested to me that "Array" would be
13:09:45 <hdaume> bounds, indices, etc
13:09:46 <Heffalump> I agree bounds should be in a type class
13:10:00 <hdaume> i think the only reason it's not is for bw compat with h98 array
13:15:25 <engstad> Odd: import qualified Data.Array.MArray as M
13:15:38 <engstad> type Set s = M.MArray s Vertex Bool
13:15:58 <engstad> Gives me: Class `Data.Array.Base.MArray` used as a type 
13:16:06 <engstad> It _is_ a type. 
13:17:15 <hdaume> no, it's a class :)
13:17:25 <hdaume> STArray and IOArray, etc are types :)
13:17:29 <hdaume> (i think -- checking)
13:17:40 <engstad> Hmmm... you might be right.
13:17:58 <hdaume> yeah, MArray is a class :)
13:18:04 <Heffalump> heya
13:18:09 <Heffalump> thanks for the networking info
13:18:16 <Chilli> :-)
13:18:32 <Heffalump> I'll check out finding a dial-up ISP before I leave :-)
13:19:00 <engstad> Perhaps MArray isn't what I'm looking for..
13:19:30 <hdaume> i think you want 'type Set s = Data.Array.ST.STArray s Vertex Bool'
13:19:54 <Chilli> I have signed up with an ISP that is part of gric.com
13:20:05 <Chilli> that's quite convenient
13:20:18 <Chilli> and you can work without their win32-only software
13:21:15 <Heffalump> sounds good (though I do run Windows so that doesn't matter to me, except on principle)
13:38:55 <Marvin--> omg
13:39:14 <Marvin--> here's actually a group who's implemented their own parser without using the combinator library we provide
13:40:38 <Marvin--> how am I supposed to read this code? :/
13:42:56 <andersca> uh oh
13:42:59 <andersca> I hope that wasn't our group
13:43:14 <andersca> but we used the combinator library so it can't be :)
13:43:25 <Marvin--> duh
15:06:49 <engstad> What is "rank-2" polymorphism?
15:07:12 <hdaume> it's when you have interior foralls
15:07:22 <engstad> Like in runST?
15:07:36 <hdaume> yup
15:08:34 <hdaume> so (i think) rank 0 means no foralls, rank 1 means foralls at the beginning, rank 2 means foralls embedded in 1 "set of parens", rank 3 means foralls embedded in 2, etc... (i am likely wrong on that tho)
15:08:47 <hdaume> but rank n definately means foralls not at the beginning for n >= 2 :)
15:10:02 <engstad> Ok. But what does it _mean_? In math, the forall sign can be moved pretty freely without changing meaning.
15:12:22 <engstad> Like, runST :: (forall s. ST s a) -> a, why is that different from: runST :: ST s a -> a.
15:12:32 <hdaume> okay
15:12:39 <hdaume> so suppose it were the latter
15:12:44 <engstad> *nod*
15:13:16 <hdaume> and suppose you wrote a function 'f :: ST Int Int -> Int; f _ = 0'
15:13:22 <hdaume> what would runST f do?
15:13:48 <engstad> Return 0?
15:13:50 <norpan> not run it :)
15:13:55 <hdaume> hehe
15:14:20 <norpan> since Int is not forall s.s
15:15:04 <engstad> In the former case, yes, but not in the latter.
15:15:21 <hdaume> the thing is, the compiler needs to know that *no matter 's' is provided*, your state function will be able to do something with it
15:16:10 <hdaume> so it's like saying '(forall s .ST s a) -> a' means "no matter what s" whereas 'forall s . ST s a -> a' means "for some 's'" or something lke that
15:16:40 <hdaume> i dunno...it's hard to explain and i know i don't even understand it fully
15:16:58 <engstad> :-) I think you're closer to understanding it than I am. :-)
15:17:27 <norpan> engstad: i'll explain simply
15:17:34 <norpan> consider
15:18:09 <norpan> in first-order logic: (forall s.P(s)) -> Q
15:18:20 <norpan> compare with
15:18:27 <norpan> forall s.(P(s)->Q)
15:18:32 <engstad> Ah, I see where you'r going.
15:18:51 <engstad> -> meaning =>, right?
15:19:04 <norpan> the forall is to the left of an implication, and really is an existance quantifier, not a forall
15:19:12 <norpan> since it occurs negatively
15:19:17 <norpan> the same with types
15:19:50 <Marvin--> engstad: no I think he's meaning ->, material implication
15:20:13 <engstad> *nod*
15:21:00 <norpan> so, (forall s.P(s)) -> Q is !(forall s.P(s)) | Q which is (exists s.P(s) | Q
15:21:25 <engstad> *voila* :-)
15:21:28 <norpan> the same goes for the types, since there is an isomorphism here, so it's a fake forall
15:21:44 <norpan> it's really there to make sure that s exists
15:22:17 * Marvin-- had to think really hard to figure out that | meant disjunction
15:22:29 <engstad> :-)
15:22:39 <norpan> Marvin--: i should have written \/
15:22:50 <Marvin--> I've been modelling semantics of parallel processes today, | means something quite different there :)
15:22:52 <norpan> and ¬
15:23:26 <engstad> Even when I scribble math-proofs, I use '&' and '|'. Easier to remember than \/ and /\.
15:23:44 <Marvin--> engstad: for me it's quite the opposite :P
15:23:59 * hdaume cannot write '&' by hand :)
15:24:17 <Marvin--> sometimes it's + and *, sometimes | and &, sometimes \/ and /\, who cares
15:24:22 <norpan> engstad: anyway, it's a bit involved, but you can see the difference between the foralls
15:24:38 <engstad> When I read math texts, I translate '/\' to the letter 'aa' in norwegian, which means 'and'.
15:24:55 <norpan> simply put it's there to guarantee that the s really is bound within the ST function, and does not "slip out"
15:24:56 * Igloo thinks of /\ looking like n in and
15:25:16 <norpan> anyway, it's time for bed
15:25:20 <clausen> how about "A" in And?
15:25:26 <engstad> norpan: Thanks VERY much!
15:25:41 <Igloo> That's not what I think of
15:26:19 <engstad> 'aa' (I cant type it here) is really an 'A' with a circle over it. :-)
15:26:33 <Marvin--> &aring; ;) we use it in Sweden too, you know :)
15:26:41 <engstad> Of course. :-)
15:27:05 <Marvin--> oh heck, I was going to go to bed, that's it, yes
15:27:52 <engstad> G'night!
15:27:55 <ski> what's'y're discussing ?
15:28:14 <Marvin--> ski: boolean algebra notation
15:28:27 <engstad> How to "translate" \/ and /\ into your mind.. :-)
15:28:37 <ski> into your mind ?
15:29:09 <ski> you mean how to think or pronounce it or what ?
15:29:48 <ski> (whatever, wasn't perhaps that important..)
15:29:58 <engstad> Greets again.
15:30:12 <ski> you rejoined ? switched account/computer ?
15:30:19 <ski> greets
15:30:23 <engstad> No, my link was "severed"...
15:30:52 <ski> you're on a modem line right now ?
15:31:07 <engstad> To answer your question though: Just how you mentally map those two symbols so that you understand them.
15:31:27 <engstad> ski: No, but I can't IRC from work, so I'm using my home computer as a relay.. ;-)
15:31:41 <ski> Isn't it just "or" and "and" ?
15:31:49 <engstad> Yes, but which is which?
15:32:06 <hdaume> i think or is like union, and is like intersection
15:32:12 <ski> engstad : ok, so your at work now ? what country ?
15:32:12 <hdaume> (though after a while, it's just natural)
15:32:19 <engstad> California.
15:32:26 <ski> hdaume : i agree
15:32:30 <hdaume> engstad: me too, where about?
15:32:37 <engstad> Santa Monica.
15:32:46 * hdaume : marina del rey
15:32:51 <engstad> :-)
15:32:58 <engstad> I used to live down there.
15:33:02 <ski> hdaume : where's that ?
15:33:09 <engstad> In Los Angeles.
15:33:26 * ski is in Gothenburg in Sweden
15:33:27 <ski> ok
15:33:40 <engstad> I'm Norwegian though.
15:33:49 <ski> aha, ok.
15:34:18 <hdaume> that explains it :)
15:34:28 <ski> (It's half past midnight here now though, so i'll probably won't stay very long. have to sleep and so on ...)
15:35:05 <engstad> Here's what I'm currently working on. I've been messing around with implementations for the good old Sutherland-Hodgeman clipping algorithm (naturally, because I'm programming for the PS2). Anyways. it is a very intersting algorithm.
15:35:24 <ski> First i thought that you were discussing /\ as big lambda and how it could be confused with And ..
15:35:41 <ski> ok
15:35:43 <hdaume> ski: ah
15:35:50 <engstad> I've implemented recursive ones, simple for-loop style ones, and continuation based ones.
15:36:06 <engstad> Now, I've translated it into Haskell (the continuation based one).
15:36:31 <engstad> I want to "prove" that you can go from continuation to recursive and back.
15:36:35 <ski> I'm not very familiar with 3D gfx (as i presume that algorithm is about, is it ?)
15:36:40 <ski> ok
15:36:48 <engstad> Well, it could be 2D as well.
15:36:57 <ski> and 4D and so on ?
15:37:00 <engstad> Yes.
15:37:12 <ski> is it a complex or big algorithm ?
15:37:17 <engstad> It's actually a _very_ simple algorithm, I could probably explain it in two-three lines.
15:37:51 <ski> you could try, if you think that i could grasp it now ..
15:38:19 <engstad> It's basically this. Split the problem into four sub-problems (each of the planes to the left, right, top and bottom).
15:39:49 <engstad> Then, follow the points in the polygon, and if a point is inside, output it, if the next is outside, output the intersection point and store it, if it comes back from outside to inside, make a new point on the intersection and draw a line from the stored
15:39:51 <engstad> .. one.
15:39:52 <ski> Hmm, is it this that's called quadtrees or something like that (my little brother is trying to make a 3D first-person game right now, and i'm helping him with some part, and i seem to recognise it from somewhere there. whatever)
15:40:19 <ski> what you mean by output ? return as part of result ?
15:40:31 <engstad> No, it's even simpler than that. It's just half-planes. { (x,y) | x < x_0 } (left half-plane).
15:40:41 <engstad> Yes, you want the clipped polygon out.
15:40:55 <ski> as function result ?
15:40:57 <engstad> type Polygon = [Vertex].
15:41:33 <engstad> So, yes, the clipper is basically  clip :: Polygon -> Polygon
15:41:43 <ski> ah, now i think i get it. seems quite simple
15:42:05 <engstad> But, the interesting thing is how you combine the planes.
15:42:33 * toadx wishes he could build FreeBSD binarys under linux with ghc :(
15:42:34 <ski> but i'll gather i gets at least a bit more complex if you add more primitive gfx objects like ellips arcs :)
15:42:35 <engstad> Here's the simplest way. for each plane (clipVersusPlane plane.(i) polygon)
15:42:59 <ski> why do you split the polygon in two planes ?
15:43:01 <engstad> Sorry, plane!i
15:44:11 <engstad> The idea is: You have a polygon. Clip against the left plane, then you get a polygon where all the points are to the right of the left line. Then you take this polygon and clip against the top plane, and so forth.
15:44:12 <ski> go on, proceed .. :)
15:45:12 <ski> hmm
15:45:17 <engstad> The problem with this solution is that you'll have to maintain 4 intermediate lists of points.
15:45:39 <engstad> Imagine a polygon (Norway's coastline), with 1000s of points.
15:45:53 <ski> so you mean that the plane splitting in two border is the clipping line ?
15:46:02 <ski> :)
15:46:39 <engstad> Actually, imagine a figure on a piece of paper, then you scissor it in a straight line.
15:47:06 <ski> yes, so you get intersection points by the clipping line, right ?
15:47:12 <engstad> Yes. :-)
15:48:01 <ski> i first though that the plane splitting was to have all edges face the same way or something, but now i understand that the plane splitting *is* the clipping..
15:48:29 <ski> or isn't it ?
15:49:08 <engstad> Perhaps it is easier to define the scissoring planes exactly?
15:49:52 <ski> i don't understand
15:49:54 <engstad> inside Lft (x,y) = x > -1.0
15:49:59 <ski> ok
15:50:01 <engstad> inside Rgt (x,y) = x <  1.0
15:50:12 <engstad> inside Top (x,y) = y <  1.0
15:50:20 <engstad> inside Bot (x,y) = y > -1.0
15:50:24 <ski> ok
15:51:06 <engstad> crossesPlane plane a b = (inside plane a) /= (inside plane b)
15:51:45 <engstad> So, a line from a to b crosses a plane if one is outside and the other is inside the plane.
15:51:59 <ski> ok
15:52:31 <engstad> So, imagine you have a triangle:  (0,0) - (2,0) - (1,1)
15:52:51 <ski> ok
15:52:56 <engstad> So, (2,0) is outside to the right. And we have to clip it.
15:53:29 <engstad> Thus, we have to create the intersection point from (0,0) to (2,0) against the right half-plane. I.e.: (1, 0).
15:53:32 <ski> i this case we get a new triangle, right ?
15:53:38 <ski> s/i/in/
15:53:49 <engstad> Yes. The result should be: [(0,0), (1,0), (1,1)].
15:54:23 <ski> but we don't unneccesarily duplicate vertices that already are in the polygon ?
15:54:33 <ski> ok
15:55:23 <engstad> Well, it is easier to understand if you take one plane at a time. So, clip only against the right plane first. Then clip against left plane, Then clip against right plane, and so on.
15:56:06 <engstad> But yes, a potential problem with this is that you might generate more point than nescessary.
15:56:30 <ski> ok, then i *think* that if one codes the algorthm in a certain way, one doesn't have to check for duplicates afterward, right ?
15:56:38 <engstad> Yes.
15:56:51 <ski> s/afterward/afterwards/
15:58:15 <engstad> The interesting thing about Sutherland-Hodgeman's algorithm is that they only require storage for two points per clipping plane (i.e. 2x4 = 8 points in our case).
15:58:17 <ski> so this particular clipping is just against some rectangular camera window (e.g. a whole screen), right ?
15:58:23 <engstad> Yes.
15:58:35 <engstad> It could be any plane though.
16:00:05 <engstad> Basically, the two points per plane that is needed to be kept in storage is the last intersection point _out_ of the plane, and also the first point that was inside the plane.
16:00:19 <ski> yes, now i remember : there was some clipping function in allegro (used in abovementioned 3D game) that did 3D Frustrum clipping, but for some reason it didn't allocate it's own working memory, so one had to give a pointer to a memory area twice as big as the vertices array
16:00:45 <engstad> Ah, that's the bad implementation.
16:00:48 <ski> perhaps that function in allegro uses Sutherland-Hodgeman's algorithm for clipping ?
16:01:10 <engstad> No, basically they are doing this (in a strict language):
16:01:41 <ski> i'm all ears
16:01:44 <engstad> let res0 = clipP Lft input in
16:01:53 <engstad> let res1 = clipP Rgt res0 in
16:01:59 <engstad> let res2 = clipP Top res1 in
16:02:07 <engstad> let res3 = clipP Bot res2 in
16:02:10 <engstad>   res3
16:02:26 <engstad> So, they need to have a temporary buffer for each of the runs.
16:02:54 <engstad> clipP :: Plane -> [Vertex] -> [Vertex]
16:03:05 <ski> ok
16:03:28 <ski> (clipP Bot . clipP Top . clipP Rgt . clipP Lft) input  :)
16:03:28 <engstad> S-H's algorithm requires no temporary storage, only 2 points per plane.
16:03:38 <engstad> Yes. :-)
16:04:22 <ski> ah, i misunderstood (or misread) you before, it was 2 points per *clipping plane*, not vertex. ok
16:04:47 <engstad> Basically, if you could "continue" on with the calculation, you would be able to do it, right?
16:05:04 <ski> "continue" on ?
16:05:22 <engstad> So, if the Lft plane could send it's result to the Rgt plane, which would send it's result to the next plane, it would be equivalent, no?
16:06:00 <ski> but doesn't the result occupy at most 2 * #ofVertices ?
16:06:24 <engstad> Well, yes. The same order.
16:06:50 <engstad> If you have a 1,000,000 big polygon, that's a lot of space.
16:07:22 <engstad> Besides, you don't need it, when considering the operation functionally.
16:07:29 <ski> so why isn't allegro algorithm just reusing the space again. or isn't the computation suffiently "local" ?
16:07:44 <engstad> I don't know to be honest.
16:08:11 <ski> hmm, you mean it's better to display/render the points as they are generated, instead of storing them all in memory ??
16:08:18 <engstad> For instance.
16:09:10 <ski> so is that the continuation passing idea in this algorithm version ?
16:09:15 <engstad> So, if you have a line from A to B, there's four cases.
16:09:20 <ski> ok
16:09:29 <engstad> A inside, B inside => output A
16:09:58 <engstad> A inside, B outside => output A, output (A intersect B)
16:10:11 <engstad> A outside, B inside => output (A intersect B)
16:10:18 <engstad> A outside, B outside => no output
16:10:29 <ski> ok
16:10:41 <engstad> A interect B = intersect plane A B
16:11:00 <ski> ok
16:11:30 <engstad> So, you have a function that for each line (vertex) may output 0, 1 or 2 points to the next plane.
16:11:49 <ski> ok, i follow you
16:12:10 <engstad> In a chain (clipP Bot, clipP Top, ... )
16:12:44 <ski> mm
16:13:03 <engstad> So, that's what we do, for each plane, we also get a continuation which is the "next plane function", and if we have case 2 or 3, we intersect.
16:13:51 <engstad> Actually, the continuation is the next clipper. :-)
16:13:57 <ski> but does this continuation want one result (vertex) or the whole result (in a list for instance) ?
16:14:21 <engstad> The continuation recieves one point at a time.
16:14:38 <ski> or after the final clipper, whatever comes after. e.g. a displayer/renderer, right ?
16:14:39 <engstad> So, it needs to record: a) the previos outputted point.
16:14:41 <ski> ok
16:14:48 <engstad> Yes.
16:14:58 <ski> b) ?
16:15:02 <engstad> b) the first point inside (for when it needs to close the polygon).
16:15:29 <ski> (what does need to record that ? the current clipper or the continuation ?)
16:15:42 <engstad> All the clippers.
16:15:53 <ski> ok
16:16:05 <engstad> That's why the S-H algo needs to store 2x #planes points.
16:16:21 <engstad> That's pretty much it.
16:17:00 <engstad> In Haskell, there's a couple of hindrances. These two points are really "state variables".
16:17:11 <engstad> So, you need monads..
16:17:14 <ski> I'm not totally sure about how that first vertex inside the clip area is to be used, care to elaborate ?
16:17:33 <ski> ST monad ?   :)
16:17:37 <engstad> Yes.
16:18:02 <engstad> Well, think of [(0,0), (2,0), (2,2)].
16:18:28 <ski> couldn't a sufficiently smart compiler (SSM (tm) ) optimise a pure functional version to do a similar thing ?
16:18:31 <engstad> The first point is inside, but the last is outside. We need to clip the line from (2,2) to (0,0) as well.
16:18:36 <ski> ok
16:18:37 <engstad> Perhaps.
16:19:26 <engstad> I'm more interested in proving relationsships in the algorithm. :-)
16:19:42 <ski> for instance ?
16:20:03 <engstad> Like, e.g. if you have an "outcode" for each polygon, i.e.: a function outCode :: Point -> (Bool, Bool, Bool, Bool)
16:20:29 <ski> semantics of that ?
16:20:43 <engstad> Where each of the four bools tells us if we are inside or outside the plane, how can it reduce the number of interpolations.
16:21:11 <ski> for the 4 clipping planes/lines, right ?
16:21:28 <ski> interpolations ?
16:21:30 <engstad> (yes) Also, I am implementing all of these in assembler in the end anyways, so no compiler could help me. :-)
16:22:11 <engstad> I just want to reason about the algorithm, so that I can transform it and see if I can make a better assembly program based on that.
16:22:26 <ski> but perhaps you can experiment and learn better how to do it right in assembler in the end, by first doing it in higher-level languages ..
16:22:31 <ski> ok
16:23:18 <engstad> Yes, exactly. :-)
16:23:30 <ski> ok, good
16:23:42 <engstad> People are amazed when I tell them that my current algorithm is recursive. :-)
16:24:21 <ski> What people ? assembler dudes ?  Or do you mean that it doesn't look recursive, or what ?
16:24:35 <engstad> Yes. Assembler dudes. (Of which I am as well, btw.)
16:25:27 <engstad> Of course, I only need 5 levels of stack, (5 clipping planes in 3D), so it's not that impressive. :-)
16:25:48 <ski> No neccesary harm in that IMO. (I learned 6502 (actually 6510, but it's the same) assembler as the 2nd programming language i learned :)
16:25:59 <engstad> C64?
16:26:20 * Pseudonym woohoos
16:26:23 <Pseudonym> I had a C64.
16:26:28 <engstad> Me too.
16:26:35 <Pseudonym> Cool hacker's machine.
16:26:38 <sethk> So what?  I had a slide rule.    :)
16:26:40 <ski> s/i learned//  (stoopid one line irc interface, you can't see the beginning of a long line, and no cursors, *sigh*)
16:26:50 <ski> C64 yes :-)
16:26:56 <Pseudonym> Probably the most-pushed hardware there has ever been in a home machine.
16:27:48 <engstad> Anyways, the PlayStation 2's hardware doesn't have xors, shifts, etc. etc., so it's kind of tricky sometimes.
16:27:51 <ski> engstad : aha so it's recursive in the # of planes, now i understand what you mean (must people would see that as a loop in imperative languages, but i guess CPS converts that to recursion in this case)
16:28:11 <engstad> ski: very well observed! :-)
16:29:49 <ski> Pseudonym : I still boot it up form time to time to listen and watch to good demos :)  (And i programmed Sink Ship in it when i had a laboration of sink ship in java. also i've tried out lunix and ace a little (unix-like OS for C64 :) )
16:30:11 <Pseudonym> :-)
16:30:21 <engstad> There's some ok emulators for Linux now.
16:30:23 <ski> engstad : no xor and shift ? what ? i'm shocked ! (well perhaps not very much :)
16:30:34 <ski> ok
16:30:41 <engstad> It does do 4 madds per cycle though. :-)
16:30:51 <ski> engstad> There's some ok emulators for Linux now.
16:30:54 <Pseudonym> I actually designed a virus for the C64.  Never implemented it, though.
16:30:55 <engstad> floating point madds.
16:31:05 <ski> engstad : VICE is not so bad ..
16:31:12 <Pseudonym> It stayed resident inside the disk drive's memory.
16:31:55 <engstad> The way to shift is to start with the float 32.5, then multiply with 0.5 for each loop, and convert the float to an int. :-)
16:32:01 <ski> Pseudonym : i've had similar ideas, also thought a little about possible misuses of tape auto-load :)
16:32:24 <ski> engstad : the PS2 does 4 madds per cycle ? or the C64 ?
16:32:28 <engstad> PS2.
16:32:31 <ski> ok
16:32:33 <engstad> One unit of the PS2.
16:32:45 <Pseudonym> The C64 doesn't have floating point hardware.
16:32:50 <ski> got a little confused there about what we were talking about :)
16:32:52 <ski> ok
16:32:59 <ski> yes, i know
16:33:02 <Pseudonym> It had this weird 5-byte floating point format, though.
16:33:38 <ski> with basic (or was it Kernel ?) rountines to perform operations on FP Acc 1 and 2, i remember..
16:33:53 <Pseudonym> Right.
16:34:16 <engstad> If you add all the f.p. units, it can do 10 f.p. ops per cycle at 300 MHz, i.e. 3,000 M fp ops per sec.
16:34:28 <ski> engstad : just continue with what you were saying about floating point madds and shifts on the PS2. i've not lost interest :)
16:35:10 <engstad> A pentium can do one per cycle?
16:35:18 <ski> Pseudonym : I have even spent some thought about implementing a graph reducing functional language on the C64 ..
16:35:31 <engstad> :-)
16:35:32 <ski> engstad : ?
16:36:03 <engstad> One or two fp ops per cycle on Pentium 4's nowadays? I don't know.
16:36:15 <ski> (That was inspired by some paper i read on the web about "TIGRE" ..)
16:36:45 <ski> Pseudonym : madd = ?
16:37:00 <ski> s/Pseudonym/engstad/  :)
16:37:12 <engstad> madd = multiply w/add. ACC = ACC + REG * REG.
16:37:14 <ski> memory address fetch ?
16:37:20 <ski> ok
16:38:24 <ski> doesn't need to be the same register, there, right ?
16:38:36 <ski> (i guess)
16:41:23 <ski> so the PS2 has 2,5 FP units ? ;-)  (4 madds/cycle for 1 FP unit,10 f.p ops/cycle for all units. Or was that a simpler kind of FP op there ?)
16:41:51 <Pseudonym> Give me offline rendering any time.  No scraping for every cycle.
16:42:11 <ski> heh :)
16:43:38 <ski> (Pseudonym : was the C64 FP format *that* strange. Funny, i never noticed. Though i've never used it much anyway (in asm i.e))
16:44:59 <engstad> ski: One regular fp unit: 1, one with 4 fp units, one with 5 fp units = total 10 fp units.
16:45:03 <Pseudonym> OK, it wasn't that strange.   But 5 bytes _is_ a strange alignment.
16:46:34 <ski> Pseudonym : isn't 80 bits a standard FP format (ISO perhaps) ?  and 80 bits is 10 bytes (hrm octets) which is just double of the C64 one.
16:47:30 <ski> engstad : so one processor has 1 FP, one has 4 and one has 5, or what do you mean ?
16:47:41 <engstad> ski: correct.
16:47:48 <ski> ok
16:48:11 <engstad> The 1 FP one is the regular mips coprocessor.
16:48:40 <ski> So the PS2 runs on mips processors, right ?
16:48:47 <engstad> Then there's two "vector units" VU0 and VU1, that has 4 fp units each, but VU1 has one additional fp unit.
16:48:52 <ski> ok
16:48:52 <engstad> Yes. R5900.
16:49:31 <ski> so VU0 and VU1 can operate in SIMD mode each ?
16:49:52 <engstad> Wow.
16:50:04 <ski> (why so many signoffs at same time ??)
16:50:12 <engstad> *shrug*
16:51:19 <ski> almost everyone signoff:ed at the same time. must have been some problem with irc server or something i guess. strange that you and me (and perhaps someone else) didn't signoff at the same time ..
16:52:02 <ski> So are VU0 and VU1 basically SIMD units ?
16:53:07 <ski> and can their assisting FP units operate in parallell (interacting with the owner VU{0|1}) ?
16:58:39 --- mode: card.freenode.net set +o ChanServ
16:59:12 <engstad> ski: Basically correct.
17:00:01 <ski> Now everone joined again :)
17:00:19 <ski> Why you Signoffed all at once ?  network problem ?
17:00:26 <engstad> VU0 can operate as a co-processor to the CPU or operate independantly. VU1 always operated independantly.
17:00:30 <ski> engstad : ok
17:00:39 <ski> ok
17:02:13 <ski> (engstad : about clipping algorithm : so the recursion is statically bounded, yes ?)
17:03:12 <engstad> Yes.
17:03:20 <ski> ok
17:03:24 <engstad> I think....
17:05:25 <Pseudonym> ski: It was you who signoffed.
17:05:25 * Pseudonym was here all the time
17:05:32 * Pseudonym thinks . o O ( I love netsplit )
17:06:08 <ski> Pseudonym : to my knowledge i did not signoff, but perhaps i did anyway ..
17:06:18 <ski> Pseudonym : netsplit ?
17:07:06 <Pseudonym> I'm logged onto one server, you're logged onto another, they lost communication for a moment.  That's netsplit.
17:07:25 <ski> ok, ah. thanks.
17:07:52 <ski> ( 
17:07:54 <ski> oops
17:09:45 <ski> (engstad : so did the continuation in the S-H algorthm take a (lazy) list/stream of vertices or did it just take a vertex and a continuation to which it will send a continuation to which the clipper will send then next vertex (and next cont.) ? :) or anything different ?)
17:10:34 <engstad> Only takes a single point and the continuation.
17:10:43 <ski> ok
17:12:38 <ski> I've been thinking for a while about implementing a toy version of a continuation-based language (*not* implicit continuation embedded in functional or imperative, i mean *continuation-based* i.e. no functions or procedures (well perhaps syntactic sugar), but just plain jumping, non-returning continuations :)
17:13:00 <engstad> I believe the signature is something like this: makeClipper :: Plane -> Clipper -> Maybe Point -> [(Vertex, Vertex)] -> (Maybe Point, [(Vertex, Vertex)])
17:13:06 <ski> But i haven't completely decided on syntax yey.
17:13:11 <ski> s/yey/yet/
17:13:16 <ski> engstad : ok
17:13:42 <ski> what is Clipper ?
17:14:11 <engstad> The Clipper, i.e.: Maybe Point -> [(Vertex, Vertex)] -> (Mayby Point, [(Vertex, Vertex)])
17:14:25 <engstad> So, makeClipper :: Plane -> Clipper -> Clipper
17:15:03 <ski> as i was just going to write :)
17:15:06 <ski> ok
17:15:07 <engstad> The list of pairs of vertices is the state, i.e. the two vertices you need to keep track of.
17:15:32 <ski> list ? one element for each plane ?
17:15:37 <engstad> Yes.
17:15:50 <engstad> Since I recurse in, I use the tail in the continuation call.
17:15:50 <ski> first plane arg to makeClipper is ?
17:16:05 <engstad> data Plane = Top | Bot | Lft | Rgt
17:16:28 <ski> yes, but what does makeClipper do with it ? what's its purpose ?
17:16:47 <engstad> Oh, it's generating a function, but the function is different for each plane.
17:17:10 <engstad> The difference is what is "outside" / "inside", and the calc for intersection.
17:17:24 <ski> so you call makeClipper for each plane and then composes them together passing the state on, right ?
17:17:52 <engstad> Yes: clip x = (makeClipper Rgt . makeClipper Lft . <and so on> ) x
17:18:05 <ski> ok
17:18:47 <engstad> I didn't want to use IO or ST. 
17:19:06 <ski> ok
17:19:22 <engstad> But notice that Clipper = Maybe Point -> ST [State] (Maybe Point)
17:19:28 <ski> for explaining purposes ?
17:19:40 <engstad> For translating it to assembly. :-)
17:19:41 <ski> yes, i recognised that
17:20:34 <ski> is there any problem with making it update the state in the correct order (i.e. all uses of old state should finish before new state is written) ?
17:21:05 <engstad> Hmm, well, I'm not sure.
17:21:38 <engstad> Well, it can't run back out of it... hold on, let me think..
17:22:38 <ski> probably, ain't a problem. but it could be in some cases i think (when converting pure state-passing to impure implicit state updating and accessing)
17:22:46 <engstad> It needs to keep its own state, because if there's two outputs out, then the status for the second point needs to be intact.
17:22:47 <ski> ok
17:23:21 <engstad> I.e., I couldn't get away with the fact that it is a recursive algorithm.
17:24:59 <ski> so you mean that the state dependencies imply that each clipper must have it's own 2 local vertices in imperative implementation, have i understood right ?
17:25:08 <engstad> Yes.
17:25:20 <ski> ok
17:25:38 <engstad> Oh, and it needs a stack pointer (counter). 
17:26:18 <ski> yes, of course (a continuation closure environment frame pointer, i.e ?)
17:26:19 <engstad> Well, I guess that's pretty obvious. :-)
17:26:44 <engstad> Basically, yes. :-)
17:28:25 <engstad> But, since it is no crazy order (i.e. the routine either sends data to the next plane, or exits out of this plane, there is no allocations and I can use "framep += sizeof(frame)" and "framep -= sizeof(frame)".
17:28:30 <ski> I'm quite interested in continuations, so i sometimes try to rethink different concept in terms of continuations ;)
17:28:33 <ski> ok
17:28:45 <ski> ok
17:29:55 <engstad> Well, continuations are fairly easy to implement in assembly as well. It's just a goto with a frame pointer. :-)
17:30:25 <Pseudonym> They're easy when you don't have closures to deal with.
17:30:31 <engstad> True.
17:30:38 <ski> except for the closure environment part if it's used non-locally
17:30:44 <ski> yes
17:30:48 <Pseudonym> Appel pointed out in "Compiling with Continuations" that if it wasn't for closures, all memory could be stack allocated.
17:31:19 <ski> seems true.
17:31:47 <Pseudonym> You have continuations if you need, for example, non-tail recursion.
17:31:56 <ski> unfortunately i haven't read that book yet :(
17:32:43 <engstad> That depends on how you define continuations. I mean, in C/C++ you don't need continuations in order to use the heap, but you don't usually call allocated memory continuations. :-)
17:33:15 <Pseudonym> In C/C++ you also have loops.
17:33:37 <ski> a continuation is both a code pointer and some data (on a stack or a heap or sothing ..)
17:33:42 <engstad> Well, restricting to functional languages, I agree.
17:34:02 <Pseudonym> Appel's book is about ML, so he's right. :-)
17:34:24 <ski> yes
17:34:25 <Pseudonym> pushd
17:34:32 <Pseudonym> Oops.
17:34:41 <Pseudonym> I hate it when that happens.
17:34:45 <engstad> Well, Ski, it's actually a little bit more. :-)
17:35:06 <engstad> See, if you make that argument, then I could say that it is a limited form of OO. :-)
17:35:21 <Pseudonym> Almost anything could be argued as a limited form of OO.
17:35:31 <ski> so what would you change in the description for say imperative (or object-oriented or logic or constraint or concatenative or ...)
17:35:37 <engstad> But... the real power of continuations stems from the ease of use and conceptual elegance.
17:35:55 <ski> engstad : ok ?
17:36:28 <engstad> It's basically a super-powerful "goto", which is _great_. :-)
17:36:42 <ski> unfortunately, i'm not quite clear how you mean (about OO), elaborate ?
17:37:13 <engstad> Oh, an "object" is a _set_ of code pointers and some data. :-)
17:38:23 <ski> yes
17:39:24 <engstad> So, in OO you could argue that it is bigger/greater etc than continuations, but that doesn't quite capture why we like continuations.
17:39:27 <ski> yes. but i would argue that the code pointers is just data also. but usually nonmutable (i.e. can be stored in a global static message table instead of in each object)
17:39:41 <ski> no
17:40:26 <engstad> So, that's why I say that the beaty of continuations lies in the concept and the use, not nescessarily what it "is".
17:40:46 <ski> And then there's always compsable/delimited continuations to confuse the picture more ;-)
17:40:55 <ski> yes
17:40:56 <engstad> :-)
17:41:38 <engstad> Btw, why did you pick "ski" as your handle?
17:44:04 <ski> well, i'm more or less a newbie on irc (irc:ed first time less than a year ago), so i just choose whatever came upon my mind (SKI calculus combinators in this case) :) . And then i haven't bothered changing handle. could perhaps confuse people and so ..  So i have stuck to that handle for this long anyway ;)
17:45:27 <engstad> So, nothing to do with skiing?
17:45:40 <ski> But perhaps it would be more natural now, on afterthought, to have chosen slj instead (Initials of Stefan Ljungstrand btw) which i otherwise often use
17:45:56 <ski> no, it hasn't ..
17:46:36 <engstad> :-)
17:47:16 <ski> my personal account on uni is md9slj, and i've mostly posted from that to usenet, and so on ..
17:47:21 <engstad> Calculus combinators. I don't think I know what that is.
17:48:10 <ski> also, i seem to be terribly bad at inventing/choosing a good (non-personal name) handle. i just can't decide what to choose. too perfectionistic i guess :(
17:48:36 <ski> "SKI calculus combinators"
17:49:39 <ski> well, one can "compile" Lambda-calculus to a variable-free language, with just application and a few predefined combinators "functions" : i.e. S, K and I
17:50:04 <ski> the meaning of the combinators/functions is thusly :
17:50:07 <ski> I x = x
17:50:20 <ski> K c x = c         (haskells  const)
17:50:47 <ski> S f g x = f x (g x)   (or  (f x) (g x)  which is the same thing)
17:50:58 <ski> I is of course haskells id
17:51:33 <ski> so SKI calculus hasn't any variable binding, so in a sense it's more low-level
17:51:45 <engstad> So, let's take an easy example, ST (a -> (s,a)), how does that translate?
17:52:06 <ski> i think graph-reduction implementation of FP is based on SKI calc (but with "supercombinators" added)
17:52:19 <engstad> Oh, not types, expressions?
17:53:22 <engstad> Lambda expressions, ok, I think I get it. :-)
17:54:01 <ski> well, the compilation is from pure unextended Lambda-calc to SKI-calc, but one can of course always extend the SKI-calc with some appropriate combinators/function constants (i.e. like primitives in haskell) to do work on non-lambdacalc values like ints etc ...
17:54:36 <ski> SKI-calc is basically untyped just like Lambda-calc is. But one can of course make typed versions of it, no prob
17:55:04 <ski> so [[\x.x]] = I  of course :)
17:55:41 <ski> would you like to see the compilation process (if i can remember it now, i.e. :)
17:55:43 <Pseudonym> S, K and I are supercombinators.
17:56:00 <engstad> Yes, take an easy example though. :-)
17:56:13 <Pseudonym> The thing behind the G machine and advanced graph reduction techniques like that is to make your own supercombinators instead of just using those three.
17:56:17 <ski> Pseudonym : so you mean all combinators are supercombinators ? then what's the difference ?
17:57:15 <ski> Pseudonym : yes, of course. to make it more efficient we try to extract some part into supercombinators
17:57:15 <Pseudonym> A combinator has no free variables.
17:57:20 <ski> yes
17:57:27 <Pseudonym> All variables are bound by lambdas.
17:57:32 <ski> yes
17:57:34 <Pseudonym> A supercombinator also has no _internal_ lambdas.
17:57:52 <ski> i thought it was the other way around
17:58:02 <Pseudonym> So Y = \f -> f (\x -> x x) (\x -> x x) is a combinator, but not a supercombinator.
17:58:10 <Pseudonym> Hang on.
17:58:14 <Pseudonym> That's not Y.
17:58:19 <ski> no
17:58:21 <Pseudonym> But it's still a combinator. :-)
17:58:45 <Pseudonym> http://wombat.doc.ic.ac.uk/foldoc/foldoc.cgi?combinator
17:59:00 <ski> Y = \f. (\t. t t) (\g. f (g g))    (lazy or call-by-name one, if i'm not mistaken)
17:59:49 <ski> engstad : well, in the meta-language we basically has two functions :
18:00:21 <ski> compile :: LambdaExpr -> SKIExprWithSomeVariablesLeft
18:00:32 <ski> abstract :: 
18:00:34 <ski> hmmm
18:00:40 <Pseudonym> Y = \f -> (\x -> f (x x)) (\x -> f (x x))
18:00:42 <Pseudonym> That's it.
18:00:42 <ski> let's see now how it went
18:01:09 <ski> Pseudonym : equal to my one i think (my one is also a little shorter :)
18:01:39 <Pseudonym> abstract :: LambdaExpr -> LambdaExpr where the second LambdaExpr contains no lambdas
18:01:59 <ski> mmm, yes, that seems right
18:02:05 <ski> so 
18:02:49 <ski> compile (LamApply e0 e1) = SKIApply (compile e0) (compile e1)   right ?
18:03:14 <Pseudonym> Oh, hang on.
18:03:22 <Pseudonym> No, abstract :: Var -> LambdaExpr -> LambdaExpr
18:03:25 <Pseudonym> Thart's right.
18:03:30 <ski> compile (LamLambda x e) = compile (abstract x e)   or something like that i think
18:03:32 <Pseudonym> Yes, you're right, ski.
18:03:35 <Pseudonym> You got it.
18:03:40 <Pseudonym> Oh, hang on, no.
18:03:48 <Pseudonym> compile (LamLambda x e) = abstract x (compile e)
18:04:04 <Pseudonym> I've got some code to do this somewhere...
18:04:16 <ski> hmm... yes !  so abstract :: Var -> SKIExprWithSomeVariablesLeft -> SKIExprWithSomeVariablesLeft
18:04:18 <engstad> What does abstract do?
18:04:30 <ski> lets see/find out
18:04:35 <engstad> ok.
18:04:44 <Pseudonym> (abstract v e) turns \v -> e into SKI form.
18:04:45 <ski> abstract x (SKIVar x)
18:04:51 <ski> no
18:04:57 <Pseudonym> abstract x (SKIVar x) = I
18:04:58 <ski> abstract x (SKIVar x')
18:05:13 <ski>   | x == x'           =
18:05:16 <Pseudonym> abstract x (SKIVar y) = SKIApply K (SKIVar y)
18:05:23 <ski> = SKI_I
18:05:28 <Pseudonym> Yes.
18:05:43 <Pseudonym> OK, if you don't have real namespaces. :-)
18:05:50 <ski>   | otherwise = SKIApply SKI_K (SKIVar x')
18:06:13 <Pseudonym> It might be better to hink about this not in Haskell.
18:06:17 <Pseudonym> \x -> x = I
18:06:17 <ski> i.e in one piece hopefully :
18:06:21 <Pseudonym> \x -> y = K y
18:06:22 <ski> abstract x (SKIVar x')
18:06:23 <Pseudonym> and so on.
18:06:25 <ski>   | x == x'           =
18:06:28 <ski> SKI_I
18:06:30 <ski> | otherwise = SKIApply SKI_K (SKIVar x')
18:07:09 <ski> yes, something like ML-Lambda or MetaML or LambdaProlog, would be better (with data-lambda !! oh wonder :)
18:07:17 <Pseudonym> Anyway...
18:07:48 <ski> ok
18:07:52 <Pseudonym> abstract x x = I
18:07:56 <Pseudonym> abstract x y = K y
18:08:11 <Pseudonym> abstract x (e1 e2) = S (abstract x e1) (abstract x e2)
18:08:21 <Pseudonym> But then you optimise the S expressions.
18:08:28 <Pseudonym> S (K x) (K y) = K (x y)
18:08:32 <Pseudonym> S (K x) I = x
18:08:36 <ski> brb
18:09:00 <Pseudonym> So, for example, consider the compose function: compose f g x = f (g x)
18:09:10 <Pseudonym> compose = \f -> \g -> \x -> f (g x)
18:09:30 <engstad> ok
18:09:32 <Pseudonym> = \f -> \g -> abstract x (f (g x))
18:09:47 <Pseudonym> = \f -> \g -> S (abstract x f) (abstract x (g x))
18:10:03 <Pseudonym> = \f -> \g -> S (K f) (S (abstract x g) (abstract x x))
18:10:12 <Pseudonym> = \f -> \g -> S (K f) (S (K g) I)
18:10:20 <Pseudonym> = \f -> \g -> S (K f) g
18:10:23 <ski> back
18:10:29 <ski> yes
18:10:35 <Pseudonym> = \f -> abstract g (S (K f) gf)
18:10:37 <Pseudonym> = \f -> abstract g (S (K f) g)
18:10:39 <Pseudonym> Sorry.
18:11:11 <ski> S (K I) f = f   or isn't it ?
18:11:12 <Pseudonym> = \f -> S (abstract g (S (K f)) (abtract g g))
18:11:32 <Pseudonym> Yes.
18:12:07 <Pseudonym> = \f -> S (S (abstract g S) (abstract g (K f))) I)
18:12:28 <Pseudonym> = \f -> S (S (K S) (S (abstract g K) (abstract g f)))) I)
18:12:35 <Pseudonym> And so on and so forth.
18:13:02 <ski> engstad : So, basically the S combinator takes an "environment" (the argument) and duplicates it and passes it down two branches of the code tree, and K just kills a stray variable passed down by S
18:13:42 <Pseudonym> Miranda, which was Haskell's direct ancestor (and SASL, Miranda's ancestor) were both implemented using SK combinators.
18:13:55 <Pseudonym> Someone even implemented SK combinators in hardware, like the Symbolics LISP machine.
18:13:55 <ski> S K _ = I
18:14:04 <engstad> Sorry, my wife on the phone... have to read it.
18:14:59 <ski> engstad : ok
18:15:18 <Pseudonym> Incidentally, compose = S (K S) (S (K S) K)
18:16:36 <ski> and then one often adds B and C combinators to remove unnessecary copying (S) and killing (K) (but you might wan't them if you'd like to program in a linear type-system (like Clean))
18:16:59 <Pseudonym> B f g x = f (g x)
18:17:06 <Pseudonym> C f g x = (f x) g
18:17:17 <Pseudonym> Note, B == compose.
18:17:38 <Pseudonym> You can implement them by inserting new optimisation rules:
18:17:44 <Pseudonym> S (K f) g = B f g
18:18:07 <Pseudonym> S f (K g) = C f g
18:18:08 <ski> one of B and C is  defined as BorC f g x = S (K f) g x = f (g x)   and the other is S f (K g) = f x g  but i can never remember which is which :(
18:18:14 <ski> ye
18:18:16 <ski> yes
18:18:22 <ski> yes
18:18:40 <Pseudonym> Compare with S f g x = (f x) (g x)
18:19:18 <engstad> That's pretty cool. So, you go from lambda expression to ski-expression, optimize the ski-expression, and then you go back to lambda-expression?
18:19:31 <Pseudonym> No, you implement SKI expressions directly.
18:19:38 <engstad> Oh, ok. :-)
18:19:51 <Pseudonym> This is how Miranda and SASL were actually implemented.
18:20:30 <Pseudonym> Before the G machine, this was actually the most efficient known way.
18:20:42 <ski> yes
18:21:20 <Pseudonym> You can implement functional languages like this using only very small graph rewrites.
18:21:36 <Pseudonym> Small enough to implement in microcode.
18:22:25 <engstad> How does this fit in with regular expressions, like '+', '*' etc?
18:22:51 <ski> a paper about "TIGRE" i've found on the net, implemented the graph by self-modifying programm assembler code, is this usual ?
18:23:37 <Pseudonym> Er... no.  Self-modifying code kills instruction caches.
18:23:47 <Pseudonym> engstad: Not at all, really.
18:23:48 <ski> \x.x * x    ==>   S (S (K *) I) I
18:24:10 <Pseudonym> And, of course, S (K x) I = x
18:24:15 <Pseudonym> So that's S * I
18:25:00 <ski> actually the links in their graph was just jsr instructions jumping to the first (operator) subnode of the current node
18:25:30 <ski> yes
18:26:22 <engstad> The SK expressions are trees, not graphs, right?
18:26:37 <Pseudonym> They are trees, but they turn into graphs pretty quickly.
18:26:49 <Pseudonym> In general, when you have recursion, you have cyclic graphs.
18:26:50 <engstad> Commons sub-expression elimination?
18:27:09 <ski> well, if you have a textual representation of an SKI expr and parse it you sure get a tree (if not common-subexpression elimination is done)
18:27:10 <Pseudonym> When you have S combinators, you have at least DAGS.
18:27:17 <ski> yes
18:27:24 <ski> DAGS = ?
18:27:27 <Pseudonym> Because S makes a copy of its third argument.
18:27:32 <Pseudonym> DAG = Directed Acyclic Graph
18:27:40 <ski> ok
18:27:49 <Pseudonym> S f g x = (f x) (g x)
18:28:02 <Pseudonym> That makes two arcs to x.
18:28:10 <Pseudonym> x is shared, so it's at least a DAG.
18:28:21 <ski> Y f = f (Y f)    or perhaps  Y f = x  where x = f x
18:28:28 <ski> that's cycling
18:28:28 <Pseudonym> Incidentally, in the SKI machine, recursion was handled with Y, yes.
18:28:35 <ski> s/cycling/cyclic/
18:28:51 <ski> for efficiency, i guess
18:28:57 <Pseudonym> For example, ones = 1 : ones is compiled to ones = Y (\ones -> 1 : ones)
18:29:13 <Pseudonym> ones = Y ((:) 1)
18:29:14 <ski> could have been implemented by standard turing or church combinator
18:29:33 <Pseudonym> It could have, but a) it's less efficient (much more efficent to use cyclic graphs), and b) it's not typable.
18:29:35 <ski> yes
18:29:42 <Pseudonym> Not in Hindley-Milner types, anyway.
18:30:03 <ski> yes (i.e. without cyclic types)
18:30:33 <ski> (like ocaml can do with -rectypes (used internally mainly for objects)
18:30:34 <Pseudonym> The only other gotchas are if-then-else, construction, pattern matching and so on, but you just introduce primitives for those.
18:30:38 <engstad> How do you get: Y(\x-> 1:x) ===> Y ((:) 1)
18:30:50 <Pseudonym> Well, 1:x = (:) 1 x
18:30:52 <Pseudonym> Right?
18:30:56 <ski> but can't you make a datatype in haskell and define y that way ?
18:30:57 <engstad> *nod*
18:31:18 <Pseudonym> OK.  \x -> (:) 1 x = S (S (K (:)) (K 1)) I
18:31:27 <ski> (i.e. a recursive datatype (perhaps even a newtype == no extra run-time penalty :) )
18:31:28 <Pseudonym> = S (K ((:) 1)) I
18:31:32 <Pseudonym> = (:) 1
18:31:47 <ski> mm
18:31:54 <Pseudonym> Using the rules S (K x) (K y) = K (x y) and S (K x) I = x
18:31:54 <engstad> cool.
18:32:25 <ski> easier to just eta-contract and voila, it's already in ski-form
18:32:38 <engstad> I was thinking that.
18:32:39 <Pseudonym> Absolutely, but it's less mechanical.
18:32:48 <ski> yes, i concur
18:33:28 <Pseudonym> We won't get onto S', B* and C'.  They're unimportant unless you're actually implementing this stuff.
18:33:48 <ski> they're important for linearity too !
18:34:06 <Pseudonym> I didn't think they were.
18:34:08 * Pseudonym thinks
18:34:15 <Pseudonym> They're important for space efficiency.
18:34:21 <engstad> Very interesting stuff, actually. While learning OCaml I went through some papers compiling/interpreting lambda expressions, but I haven't realized the power of this until now.
18:34:28 <Pseudonym> But I thought that if you have B and C, you have no unnecessary copying.
18:35:09 <Pseudonym> engstad: See if you can find a copy of Simon Peyton-Jones' book "The Implementation of Functional Programming Languages" from 1985 or so.
18:35:19 <Pseudonym> Your local university library probably has a copy.
18:35:53 <ski> i mean linearity as in linear/uniqueness types (i.e. guaranteed only 1 pointer to object so may safily destructively update), not as in linear complexity or something, ok ?
18:37:13 <ski> also useful for reversible computations, methinks
18:37:52 <ski> (Henry Baker has many interesting papers about that and similar things :)
18:38:13 <Pseudonym> I seem to remember Curry also used W, which had the effect of S x I
18:38:23 <Pseudonym> So, for example, \x -> x*x = W *
18:38:33 <Pseudonym> Might be wrong about that.
18:39:01 <Pseudonym> It's been a while since I read any of Curry's papers.
18:39:56 <ski> see http://www.uq.net.au/~zzdkeena/Lambda/  : " To Dissect a Mockingbird: A Graphical Notation for the Lambda Calculus with Animated Reduction) is interesting and talks about many combinators
18:39:57 <Pseudonym> Er... books, I meant.
18:43:34 <ski> (also : http://www.computer.org/conferences/vl95/html-papers/citrin/citrin.html , if you're interested about visualisations of Lambda-calc)
18:52:55 <engstad> Btw, almost all assembly instructions are easily modelled in Haskell as some kind of monad-like structure. You *could* write things like: do { iaddiu x y z; ... }
18:53:49 <ski> of course, so same pitfalls can of course be made (un-detected aliasing, etc) but mostly it's harder
18:54:46 <ski> (Henry Bakers's ARchive of Research Papers : http://home.pipeline.com/~hbaker1/  can perhaps be of interest to some)
18:55:01 <MangyDog> hey guys :) any1 wants to help a haskell newbie w/ some haskell homework?
18:55:21 <ski> what's the problem ? how far have you come ?
18:55:55 <MangyDog> um, well, i'm a c++ person myself... learning haskell for a CS class... unforts I haven't a clue how to approach this one...
18:56:17 <MangyDog> basically they want a haskell program that solves quadratic equations of integer coeffiecients given as a,b,c
18:57:02 <MangyDog> i looked through gentle intro to huskell... but that didn't seem to help much
18:57:11 <ski> have you figured out the start ? i.e. how many arguments the program (ITYM function) should take ?
18:57:54 <MangyDog> hrmph. not really.
18:58:01 <ski> it seems that at least some people doesn't find that tutorial as gentle as it claims to be .. :(  perhaps it isn't
18:58:12 <engstad> Mangy : I just started out with functional languages as well. Many years of C++ experience. I might help you with some of the "conversion".
18:58:24 <engstad> It isn't. :-)
18:58:29 <MangyDog> that'd be great e:)
18:58:30 <ski> well how would your function head look like in say C (or C++) ?
18:59:18 <engstad> ski: Tell him first, _why_ are you interested in knowing that?
18:59:36 <ski> engstad : I have only read it after i already learned FP, so my voice does not count about Gentle intro..  
18:59:48 <ski> engstad : ok
18:59:49 <engstad> *nod*
19:00:13 <MangyDog> ok -- embarrassing but true -- i need to even remember what a quadratic function looks like. :) as far as i recall something along the lines of x^2 + y + d = 0? sorry, math was about 10 yrs ago
19:00:19 <MangyDog> and even then i sucked at it :)
19:00:35 <engstad> Well, first off, Haskell is kind of like math. The whole point with Haskell is _equations_ and _reasoning_ about programming.
19:00:48 <engstad> Isn't ax^2 + bx + c = 0?
19:00:59 <ski> well, MangyDog, this problem would most probably be solved in haskell by a function (just a plain old integer or similar won't do. we need code) and because haskell is an functional language, we make a function.
19:01:05 <MangyDog> ah, i think you're right
19:01:28 <engstad> The good ole abc-formula. :-)
19:01:47 <ski> so , i was wondering how you would begin to solve this in C++ (or C) if you would use a functions (as opposed to some objects with methods say) ,  you understand ?
19:02:27 <Pseudonym> MangyDog: Have you been given a type declaration?
19:02:35 <MangyDog> well, as far as i recall there was a method for solving quadratic functions -- something involving a square root as far as i recall
19:02:49 <ski> ax^2 + bx + c = 0  is correct definition of a 2nd degree (quadratic) equation (in, say, real numbers)
19:02:53 <MangyDog> it says "integer coefficients given as a,b,c)
19:03:04 <MangyDog> i think he's talking about 2nd degree
19:03:08 <Pseudonym> Yes.  x = (-b +/- sqrt(b^2 - 4ac)) / 2a
19:03:10 <engstad> Btw, mangy, I'll help you look up the formula, you can easily find it anywhere: x = (-b +/- sqrt(b^b - 4.a.c)) / (2a).
19:03:28 <MangyDog> sounds familiar :)
19:03:32 <MangyDog> ok, so in c I would do something like:
19:03:35 <Pseudonym> Not b^b. :-)  That's a typo.
19:03:36 <ski> seem right, yes
19:03:46 <engstad> oops, yes, b squared.
19:03:48 <ski> b^2 as Pseudonym wrote
19:03:56 <MangyDog> int quad(int iA, int iB, int iC)
19:04:03 <ski> good !
19:04:11 <Pseudonym> Except the return value might not be int.
19:04:14 <ski> so here we have a function taking 3 arguments
19:04:15 <Pseudonym> In fact it probably isn't.
19:04:20 <ski> yes
19:04:20 <engstad> Ok, yes, the math teacher objects!
19:04:27 <MangyDog> so if i'm correct the haskell declaration should be something like:
19:04:27 <engstad> (I used to teach math btw.)
19:04:36 <ski> (engstad : i beg your pardon ?)
19:04:49 <MangyDog> Integer quad :: Integer,Integer,Integer -> Integer
19:04:51 <MangyDog> ?
19:04:51 <engstad> What about the +/-?
19:04:56 <ski> almost right
19:05:08 <engstad> What is a mathematical function?
19:05:28 <ski> quad :: (Integer,Integer,Integer) -> Integer   is a little bit better (i.e. legal haskell :)
19:05:44 <ski> engstad : you asking me or MangyDog ?
19:05:52 <MangyDog> eng: words like domain and range come to mind :)
19:05:52 <ski> engstad : never mind
19:05:54 <engstad> All of you. :-)
19:06:07 <MangyDog> something like conversion from range to domain? sigh. <--- math twink.
19:06:13 <ski> yess, good
19:06:19 <MangyDog> ski: ok
19:06:27 <MangyDog> but how do i reference the individual parameters?
19:06:27 <engstad> Good, MangyDog! :-)
19:06:35 <MangyDog> (i.e. in C i'd use the iA, iB, iC...?)
19:06:57 <engstad> So, iA, iB and iC are in the domain.
19:06:58 <ski> one can see it as a machine, or method, of converting an input (a value in the domain) into an output (a value in the range)
19:07:01 <engstad> What is the range?
19:07:16 <MangyDog> range is +- x?
19:07:34 <engstad> Let's take an easy example: x^2 - 1 = 0.
19:07:34 <ski> the set (or as we say in programming the type) of the result of a function
19:07:39 <engstad> What can x be?
19:08:02 <MangyDog> 1 or -1
19:08:08 <Pseudonym> G'day, shapr.
19:08:18 <Pseudonym> We're doing quadratic root finding, today.
19:08:20 <engstad> Ah. So there is no _one_ solution, it is two, no?
19:08:35 <MangyDog> right...
19:08:36 <ski> shapr : hi
19:08:46 <shapr> hi ski
19:08:51 <shapr> g'day Pseudonym
19:08:59 <MangyDog> hi shapr. these guys are rapidly changing my opinion of quality of help that can be gotten on IRC. :) 
19:09:07 <engstad> So, then it should be quad :: (Integer, Integer, Integer) -> ???
19:09:10 <MangyDog> (er, for the much, much better, that is)
19:09:15 <ski> :)
19:09:26 <MangyDog> so can a function return two values in haskell?
19:09:27 <Pseudonym> Yes.  On IRC, you can get a lot of helpful (if conflicting) advice.
19:09:33 <engstad> Yepp. :-)
19:09:39 <shapr> hi MangyDog, there are a few places on irc where people are helpful and well-informed
19:09:44 <shapr> this is one of those places.
19:09:52 <engstad> In C++ too btw. 
19:09:54 <Pseudonym> Either that or we're really good at faking it.
19:09:56 <MangyDog> yes, so i see! 
19:10:11 <MangyDog> in c++ i'd just pass the return values as arguments by reference
19:10:15 <MangyDog> (in c by pointer)
19:10:20 * Pseudonym <- clever troll
19:10:22 <MangyDog> can that be done in haskell?
19:10:29 <engstad> No, I'd return make_pair(1, 2), for instance.
19:10:31 * shapr is entertaining himself by running emacs in console mode at 132x80
19:10:42 <Pseudonym> shapr is easily entertained
19:10:54 <MangyDog> eng: right, w/ STL
19:10:58 <engstad> *nod*
19:10:59 <shapr> for some values of entertained, yes
19:11:14 <engstad> So, how do you make a pair in Haskell?
19:11:29 * shapr wonders if you're comparing apples and pairs
19:11:47 <MangyDog> (hopefully that's a question for ski?)
19:11:56 <engstad> Mangy, no it's for you. 
19:11:56 <Pseudonym> How do you construct an apple in Haskell?
19:12:11 <shapr> Pseudonym: that's an excellent question
19:12:13 <engstad> :-) data Fruit = Apple | Orange
19:12:20 <shapr> good answer
19:12:23 <ski> data Fruit = Apple Color | Banana | Orange
19:12:28 <MangyDog> um, beats me eng. i retain only what i use, and i haven't done any haskell yet at all
19:12:31 * shapr tries to find an ASCII screensaver
19:12:32 <ski> :)
19:12:34 <Pseudonym> But it can't be a member of Ord.
19:12:43 <Pseudonym> As you clearly can't compare Apples with Oranges.
19:12:48 * shapr laughs
19:12:49 <ski> engstad : ow, you got before me ! :)
19:12:50 <engstad> Mangy: Ok, I'll tell you, cause it's easier than you think:   (1, 2)
19:13:06 <MangyDog> oh, i.e. a list
19:13:07 <shapr> Pseudonym: wouldn't that be can't be a member of Eq?
19:13:12 <shapr> isn't Ord a subclass of Eq?
19:13:16 <MangyDog> so the actual declaration for the function would be
19:13:19 <engstad> No, it's not a list (not like Lisp and Scheme).
19:13:27 <MangyDog> quad :: (Integer,Integer,Integer) -> (Integer,Integer) ?
19:13:29 <shapr> Pseudonym: that's worthy of quoting
19:13:31 <Pseudonym> Eq would work.  You can show that apples and oranges are not equal, but you can't compare them.
19:13:32 <engstad> Very good!.
19:13:41 <shapr> hm, true.
19:14:00 <engstad> But now, we have a problem. what if the equation is: x^2 = 0.
19:14:06 <ski> (brb)
19:14:10 <engstad> Or even x^2 + 1 = 0.
19:14:22 <MangyDog> then we throw an exception :)
19:14:27 <MangyDog> oh wait. c++. sigh.
19:14:31 * shapr finds an ascii screensaver
19:14:45 <engstad> We _could_, or we could say that there is _no_ solution, or _one_ solution.
19:14:54 <shapr> Pseudonym: you may find it normal to run a text console at 132x80, but it's a new thing for me
19:14:55 <Pseudonym> Or "no" soluions.
19:15:08 <Pseudonym> shapr: No, I don't use text consoles, generally.
19:15:11 <MangyDog> how?
19:15:17 <engstad> You mentioned it earlier.
19:15:29 <shapr> sometimes I get bored of graphical windows, not sure why.
19:15:39 <MangyDog> hmmm?
19:15:40 * Pseudonym likes his screen real estate
19:16:13 <engstad> So, a pair always have two elements, a regular value is one element, how can we easily make something that has 0, 1 or 2 elements?
19:16:18 <Pseudonym> Give me a 1600x1200 screen with 8 point fonts any day.
19:16:37 <clausen> !
19:16:49 <MangyDog> something to do with x:xs?
19:16:51 * clausen prefers 20 point fonts, 1024x768
19:16:58 <engstad> Mangy: A list?
19:17:00 * Pseudonym likes squinting
19:17:09 <MangyDog> right...
19:17:11 <shapr> the best I get is 1280x1024
19:17:11 <MangyDog> ?
19:17:35 <shapr> though I'm planning to purchase a nice LCD monitor soon, hopefully I'll be able to afford 1600x1200
19:17:36 <engstad> So, we could say: [] is no solution, [1.0] is one solution and [1.0, -1.0] is two solutions.
19:17:55 <MangyDog> right, so how do we indicate that a function returns a list? 
19:18:20 <engstad> The list type, is simply [ElementType], so [Float] ?
19:18:22 <Pseudonym> I have a 20" trinitron at home and a 21" trinitron at work.
19:18:43 <engstad> Did you learn about the "data" declaration?
19:18:48 <Pseudonym> It's worth the weight.
19:18:51 <MangyDog> ok, so the definition is quad :: (Integer, Integer, Integer) -> [Float]
19:18:57 <MangyDog> ?
19:19:02 <engstad> Yep. :-)
19:19:03 <MangyDog> yeah, that defines the equivalent of enums, right?
19:19:13 <engstad> Not quite. It's a bit more powerful.
19:19:26 <MangyDog> enums + structs?
19:19:28 <engstad> In this case, can you get 3 return values?
19:19:33 <Pseudonym> MangyDog: Enums + unions + structs
19:19:37 <Pseudonym> Sort of.
19:19:39 <engstad> For quad, I mean.
19:20:08 <MangyDog> -x, 0, x?
19:20:26 <engstad> No, that's impossible. You've got a plus/minus, but that's it.
19:20:40 <MangyDog> ok.. then only two values?
19:20:49 <engstad> Max 2 solutions.. but your result type can have more than 2 values.
19:21:00 <MangyDog> oh, so what you're saying is simply [Float] is not enough.. have to gate it to two values...?
19:21:08 <MangyDog> how to do that in haskell?
19:21:14 <Pseudonym> It depends on your requirements.
19:21:22 <Pseudonym> Lists are overkill, but overkill is not necessarily a bad thing.
19:21:30 <engstad> So, here's one way of doingn it: data QuadResult = NoSolution | SingleSolution Float | TwoSolutions Float Float
19:21:32 <MangyDog> not [Float, Float]??
19:21:41 <engstad> Nope.
19:21:49 <MangyDog> aaaaaah. ok, so a union
19:22:04 <Pseudonym> Technically it's a discriminated union.
19:22:07 <engstad> Anyways, so that's two different ways of doing it, I'd actually prefer the list one.
19:22:08 <MangyDog> well, actually it looks like a weird union/enum mix :)
19:22:17 <Pseudonym> MangyDog: exactly
19:22:21 <engstad> It is a union. :-)
19:22:23 <MangyDog> so how do you gate the list to two values?
19:22:23 <Pseudonym> Like variant records in Pascal.
19:22:52 <MangyDog> i actually used to be good in pascal..... 10 years ago.
19:22:58 <engstad> Using lists or the union type?
19:22:59 <MangyDog> now i don't remember the first thing about it.
19:23:00 <Pseudonym> engstad: No it's not.  C unions are undiscriminated.
19:23:08 <MangyDog> using lists
19:23:14 <MangyDog> union type i understand, i think
19:23:23 <ski> (i'm talking to a friend now, so thats why i'm aren't responding right now ..)
19:23:26 <engstad> I know..
19:23:38 <Pseudonym> Just being anal.
19:23:53 <engstad> It's a beefed up union type, ok?
19:24:12 <MangyDog> ok. :) so how do i gate to two values using a list?
19:24:32 <engstad> Let's say you have two values x0 and x1, then for a list: [x0, x1]
19:24:46 <engstad> For the union type: TwoSolutions x0 x1
19:25:09 <MangyDog> but in this particular case, i have 0,1,2 solutions, returning floats... how does that look in a list?
19:25:14 <engstad> It's actually very "natural". 
19:25:19 <MangyDog> you said [Float, Float] is wrong?
19:25:24 <engstad> Yes.
19:25:37 <Pseudonym> [Float] is like float[] in C++.
19:25:45 <engstad> I'm thinking: data List x = [x]
19:25:49 <MangyDog> wait, is it [[], [Float], [Float, Float]]?
19:25:53 <Pseudonym> [Float,Float] doesn't make sense.
19:25:56 <engstad> So, a list of floats is:  [Float].
19:26:07 <Pseudonym> Any more than float float[] would in C++.
19:26:10 <engstad> A list of ints is: [Int].
19:26:11 <MangyDog> right, but what if that list shouldn't contain more than 2 values?
19:26:22 <engstad> You can't specify that. 
19:26:28 <engstad> A list is by default infinite.
19:26:40 <Pseudonym> No more than you can specify that an integer should be between 0 and 100 in C++.
19:26:48 <MangyDog> ok. so if I return [Float] as the result of the quad function it's up to the caller to only look at the first two elements
19:26:50 <engstad> That's why the union (sum) type might be good in some cases.
19:27:01 <engstad> Yes.
19:27:12 <engstad> Do you have an interpreter like hugs, or ghci?
19:27:27 <MangyDog> ok. i think i'm pretty clear on the declaration. how would this function actually look though?
19:27:30 <MangyDog> hugs
19:27:58 <engstad> Start it up, and try to type: length [1, 2, 3]
19:28:32 <MangyDog> makes sense. like a sizeof declaration
19:28:41 <engstad> No, not at all. :-)
19:28:46 <MangyDog> or an stl size()
19:28:59 <engstad> Yes, that's better.
19:29:07 <MangyDog> well, for a statically allocated array sizeof would return the right value
19:29:10 <MangyDog> right result
19:29:15 <engstad> Yepp.
19:29:39 <MangyDog> ok, so what about the actual function? how do i reference those three ints that get passed in?
19:29:45 <engstad> Ok, so now we've defined the type:   quad :: (Float, Float, Float) -> [Float]
19:29:58 <MangyDog> righ
19:30:00 <MangyDog> right
19:30:07 * Pseudonym is afk
19:30:16 <engstad> Now, the first line. You just type:
19:30:27 <engstad> quad iA iB iC = ...
19:30:41 <engstad> Sorry... quad (iA, iB, iC) = ...
19:31:03 <engstad> Or even: quad (a, b, c) = ...
19:31:12 <MangyDog> wait. i tried typing in that declaration into hugz, it gave me an error
19:31:19 <engstad> You can't. 
19:31:26 <engstad> It has to be in a file.
19:32:01 <MangyDog> er. ok. so i need to make a .hs file?
19:33:15 <MangyDog> hmm. hugz just crashed
19:33:19 <MangyDog> :)
19:33:21 <engstad> ;-)
19:33:39 <MangyDog> so i make a .hs file?
19:33:43 <engstad> Yes.
19:34:03 <engstad> Start by typing:   module MyQuad where
19:34:20 <MangyDog> in the interpreter, or in the file?
19:34:24 <engstad> In the file.
19:34:42 <MangyDog> what does that do?
19:34:44 <engstad> That's kind of like a namespace declaration.
19:34:51 <MangyDog> ah ok
19:35:06 <MangyDog> and then i assume MyQuad :: (Integer, Integer, Integer) -> [Float]
19:35:07 <engstad> In another file, you could write: MyQuad.quad (1, 2, 3)
19:35:09 <MangyDog> ?
19:35:18 <MangyDog> god it
19:35:21 <MangyDog> er, got it :)
19:35:30 <engstad> Well, I would change Integer to Float.
19:35:46 <MangyDog> the assignment spec says three integers
19:35:50 <MangyDog> as input
19:35:51 <engstad> Oh, ok.
19:36:49 <engstad> Btw, do you know the difference between "curried" and uncurried form?
19:37:15 <MangyDog> i heard those words, i read about them, but for the life of me can't recall right now
19:37:26 <engstad> If you do not, we'll skip it.
19:37:39 <MangyDog> ok
19:37:50 <engstad> In C/C++, you are used to f(1,'a'), right?
19:38:17 <MangyDog> er, f being a function of format f(int, char)?
19:38:22 <engstad> Yes.
19:38:29 <MangyDog> right
19:38:48 <engstad> In functional languages, you can _also_ type this as: f 1 'a'
19:38:56 <engstad> Looks wierd, right?
19:39:00 <MangyDog> ok
19:39:02 <MangyDog> yup
19:39:23 <engstad> Remember the 'tuple' construction: (1, 'a')
19:39:30 <engstad> Or a pair?
19:39:38 <MangyDog> right...
19:39:55 <engstad> So, when you write: quad :: (Integer, Integer, Integer) -> ...
19:40:16 <engstad> It means that quad takes _one_ argument, and that argument is a 3-tuple of three Integers.
19:40:34 <MangyDog> ok...
19:41:01 <engstad> See, quad (1,2,3), is in C/C++:  quad(ThreeTuple const &tuple) { ... }
19:41:30 <MangyDog> ok...
19:41:41 <engstad> So, it depends on what you like most. :-)
19:42:03 <engstad> Do you like: quad (1,2,3) or (quad 1 2 3)
19:42:05 <MangyDog> doesn't matter. as long as it works. (ah, the perennial rule of computer industry)
19:42:15 <MangyDog> i'll take quad (1,2,3) please :)
19:42:21 <engstad> Okey. :-)
19:42:42 <engstad> Ok, so: quad (a,b,c) = ...
19:42:47 <engstad> That's your start.
19:42:59 <MangyDog> so that goes below the declaration, i assume
19:43:13 <engstad> Then you have three cases, depending on the sign of the expression under the square root.
19:43:16 <engstad> Yes.
19:43:34 <MangyDog> so i actually have the ...? what do they mean?
19:43:38 <engstad> Call the expression under the square root 'd'. 
19:43:48 <engstad> No, the ... is your code. :-) 
19:44:00 <MangyDog> ah. lol. ok
19:44:19 <engstad> What is the d again?
19:44:56 <MangyDog> b^2 - 4ac?
19:45:03 <engstad> How do you write that in C?
19:45:27 <MangyDog> pow(iB, 2) - 4 * iA * iC
19:45:34 <engstad> Nah, that's overkill.
19:45:50 <engstad> pow(iB, 2) = iB * iB right?
19:45:52 <MangyDog> ok, iB * iB - 4 * iA * iC
19:46:01 <MangyDog> right
19:46:06 <engstad> So, d = iB * iB - 4 * iA * iC
19:46:11 <engstad> ?
19:46:28 <MangyDog> right... incidentally can you bitshift in haskell?
19:46:37 <engstad> Nope.
19:46:41 <MangyDog> (incidental to the problem, but i'm curious)
19:46:45 <MangyDog> darn :)
19:46:48 <engstad> You have to trust the compiler.
19:46:50 <MangyDog> ok, nevermind
19:47:04 <MangyDog> ok
19:47:21 <engstad> So, in functional languages there are no "variables" as you think of them in C.
19:47:22 <MangyDog> so how do i represent d in haskell then?
19:47:42 <MangyDog> ok..
19:48:18 <engstad> But, you can make "substitutions". And in our case, we want "d" to stand for the expression "iB*iB - 4*iA*iC".
19:48:47 <engstad> We do that by a "let" statement, or with a "where" statement afterwards.
19:48:57 <MangyDog> ok...
19:49:08 <engstad> So, I'd write: <TAB> let d = iB * ... in
19:49:14 <engstad> on the next line.
19:49:29 <MangyDog> this is after the quad (a,b,c) = 
19:49:31 <MangyDog> ?
19:49:37 <engstad> ... with the rest of the expression for the ... 
19:49:40 <engstad> Yes.
19:49:46 <engstad> quad (a,b,c) = 
19:49:58 <engstad>     let d = iB * iB - 4 * iA * iC in
19:50:12 <MangyDog> ok, that makes sense
19:50:16 <ski> MangyDog : i think some hugs/ghc library allows bitshifting (or perhaps it was just hugs ..)
19:50:19 <MangyDog> can i nest let statements?
19:50:21 <ski> (i'm back again)
19:50:23 <engstad> Note, that is _not_ the same as putting the value into the "d" variable on the stack. :-)
19:50:29 <MangyDog> ski: ok :)
19:50:37 <MangyDog> eng: makes sense. 
19:50:54 <engstad> Finally, look up the "if" instruction. :-)
19:51:31 <engstad> Oh, one more thing. The "if" instruction is more like the (test) ? expr0 : expr1 statement in C/C++.
19:52:00 <MangyDog> ok found it
19:52:00 <MangyDog> ok so something like 
19:52:19 <MangyDog> if d < 0 then ... else ...
19:52:21 <MangyDog> ?
19:52:22 <engstad> Yes.
19:52:23 <ski> yes
19:52:38 <MangyDog> got it
19:52:44 <engstad> So if d < 0, you can't take the square root and you return .... fill in the blanks.
19:53:08 <MangyDog> how do you return?
19:53:18 <engstad> You _always_ return. :-)
19:53:33 <ski> like x > 3 ? 2 : 5  returns 2 or 5
19:53:40 <engstad> Functions always have to return a value.
19:53:40 <MangyDog> lol. right.... but how do you return in the middle of a function?
19:53:46 <engstad> You can't.
19:54:05 <MangyDog> ok, so in this particular case, what do i say for if d < 0 ?
19:54:28 <engstad> Like you saud above: if d < 0 then ... else ...
19:54:52 <MangyDog> right... but what goes into d < 0 then ...? in c i'd say return; ...
19:55:08 <engstad> and in haskell you don't say 'return x;', you just write 'x'.
19:55:21 <engstad> No, you have to return something!
19:55:32 <engstad> What was the return type?
19:55:34 <MangyDog> but there's no x to return... there isn't a solution..?
19:55:35 <ski> but,NB, a let expression returns the same value as it's body (the thing after the "in")  and an "if" expression returns the value of either the "then" branch or the "else" branch
19:55:52 <MangyDog> [Float]
19:55:56 <MangyDog> so do i just return []
19:55:59 <MangyDog> ?
19:56:01 <engstad> Yes!!
19:56:08 <MangyDog> ah. ok :)
19:56:11 <ski> so in this case what you put at the "then" and "else" branches, the function can return
19:56:14 <engstad> if d < 0 then [] else ... 
19:56:14 <MangyDog> so then after that let line it looks like this:
19:56:17 <ski> yes
19:56:22 <MangyDog> got it :)
19:57:11 <engstad> In functional languages, there are no "statements", only "functions". 
19:57:17 <MangyDog> so else [-b + d / (2*a), -b - d / (a*a)] ?
19:57:30 <engstad> Very good, except you forgot one case.
19:57:45 <MangyDog> yeah, when there's only one solution
19:57:55 <engstad> when d = 0.
19:57:56 <MangyDog> sounds like i need another if then else case
19:58:01 <engstad> Yes.
19:58:19 <MangyDog> ok. so final statement would be:
19:58:33 <engstad> Okey, no a question for the gurus here: What about the type's Integer / Integer ---> Float ???
19:59:03 <MangyDog> if d < 0 [] else if d == 0 [-b] else [-b + d / (2*a), -b - d / (a*a)] 
19:59:05 <MangyDog> ? 
19:59:12 <MangyDog> is that right?
19:59:15 <engstad> forgot the 'then'
19:59:18 <engstad> s.
19:59:26 <MangyDog> ah, right. 
19:59:40 <MangyDog> if d < 0 then [] else if d == 0 then [-b] else [-b + d / (2*a), -b - d / (a*a)]
19:59:43 <MangyDog> ?
19:59:54 <engstad> In principle that should work. There's just one thing...
20:00:06 <engstad> I don't know if it will type check. :-/
20:00:41 <MangyDog> shouldn't the / automatically convert into floats?
20:00:44 <MangyDog> that's what it'd do in C if i recall
20:01:35 <engstad> I'll check.
20:01:44 <MangyDog> thanks :)
20:02:18 <engstad> Nope.
20:02:27 <MangyDog> yeah, i just tried it
20:02:33 <MangyDog> should i just return [Integer]?
20:02:39 <engstad> No, that won't work.
20:03:09 <ski> engstad : Integer / Integer ---> Float ?
20:03:14 <MangyDog> so what do i do ? :)
20:03:21 <engstad> Oh, you need to change it to: (-b + d) / (2 * a)
20:03:27 <ski> engstad : aha
20:03:30 <engstad> I really don't know.
20:03:43 <engstad> How do you get Integer/Integer -> Float?
20:04:04 <ski> fromIntegral :: Int -> Float  (amogst other things)
20:04:15 <engstad> Ok.
20:04:16 <ski> also  fromIntegral :: Integer -> Float
20:04:36 <MangyDog> so how would this change the declaration?
20:04:58 <engstad> Btw, Mangy: Your second solution (one answer) is wrong.
20:05:32 <MangyDog> oh right. -b/2a
20:05:34 <ski> (/) :: Float -> Float -> Float  (rounding division)
20:06:00 <ski> (  div :: Integer -> Integer -> Integer  (integer rounding division))
20:06:38 <engstad> Mangy, what about this:
20:06:46 <engstad> quad (iA, iB, iC) =
20:06:54 <engstad>     let a = fromIntegral iA 
20:06:59 <ski> oops : i meant not to say that / is rounding (well of course it is at a fine grain level, but it doesn't round to nearest smaller integer)
20:07:00 <engstad>        b = fromIntegral iB
20:07:07 <engstad>          c = fromIntegral iC in
20:07:18 <engstad> :-)
20:07:20 <MangyDog> aaah. ok let me try
20:07:49 <ski> this is unfortunately a little bulk sometimes (the explicit coercing i.e. )
20:08:25 <ski> s/bulk/bulky/
20:08:45 <MangyDog> it's returning empty list every time
20:09:08 <engstad> Odd.
20:09:27 <MangyDog> oh wait
20:09:31 <MangyDog> i forgot the square root
20:09:34 <MangyDog> in let d = ...
20:10:00 <MangyDog> what's square root ?
20:10:04 <MangyDog> just sqrt?
20:10:17 <engstad> Nod.
20:10:28 <engstad> Wait. :-)
20:10:39 <engstad> Yes, sqrt(d)
20:11:00 <MangyDog> can i do
20:11:07 <MangyDog> let d = sqrt(b * b - 4 * a * c) in
20:11:11 <MangyDog> ?
20:11:52 <engstad> Nope.
20:12:06 <engstad> Hmm.
20:12:22 <ski> can't tou ?
20:12:28 <ski> s/tou/you/
20:12:45 <engstad> No, we have to check the sign of d first.
20:13:28 <ski> yes, of course. i though too mathematically about this :)
20:13:55 <ski> (engstad : ITYM, the sign of b * b - 4 * a * c)
20:13:57 <MangyDog> sorry. dogs and network cables don't mix
20:14:16 <MangyDog> anyway, i put that sqrt into the let declaration, and it works :)
20:14:16 <MangyDog> thank you guys! 
20:14:41 <ski> t'was fun :)
20:14:43 <engstad> Nop!
20:14:47 <engstad> Don't!
20:14:51 <ski> what ?
20:15:06 <ski> you mean sign checking ?
20:15:13 <MangyDog> i'll probbly be back again to bug you some more in the days to come :) i really appreciate the help
20:15:21 <engstad> Yes, you need to put the sqrt into the lists.
20:15:26 <MangyDog> gotta run -- gf is bugging me about making dinner :) see ya all later.
20:15:33 <engstad> Try: quad 1 0 1
20:15:40 <ski> MangyDog : i think enstad was trying to point out a possible problem
20:15:55 <MangyDog> oh wait
20:15:56 <MangyDog> program error
20:16:03 <engstad> PUT THE SQUARE ROOT IN THE LISTS!!!
20:16:21 <MangyDog> makes sense.. can't take it if it's less than zero
20:16:26 <MangyDog> sigh. not thinking :)
20:16:30 <engstad> if d < 0 then [] else if d == 0 then [(-b)/(2*a)] else [(-b + sqrt d) / (2*a), (-b - sqrt d) / (2*a)]
20:16:34 <ski> so you have to check sign before
20:16:55 <engstad> :-)
20:17:04 <MangyDog> thanks again! :)
20:17:05 <ski> actually i think it is custom to call b*b -4*a*c  d and not the square root of that
20:17:38 <ski> so say   let d = b*b - 4*a*c  in    ....  sqrt(d) ....
20:17:55 <MangyDog> makes sense.
20:18:04 <engstad> Oops, I have to run too, my wife will kill me. :-)
20:18:17 <MangyDog> later guys :)
20:18:20 <ski> good luck
20:18:34 <engstad> So did I teach well?
20:18:39 <ski> i think so
20:18:43 <engstad> :-)
20:18:48 <ski> :)
20:19:18 <ski> e.g. no need to rush into currying and partial application ..
20:19:29 <engstad> Exactly.
20:19:34 <ski> one step at a time
20:19:51 <engstad> At least we mentioned it. 
20:20:04 <engstad> It'll dawn on him later.
20:20:10 <ski> yes
20:20:13 <ski> good
20:21:17 <engstad> When I first started messing around with argument types and return types I finally realized the niceness of currying. :-)
20:22:37 <engstad> But.... i really gotta go. CY!
20:22:39 <ski> firstly i thought, what a strange notation for multiple arguments to a function
20:22:42 <ski> bye
20:22:46 <engstad> :-)
20:22:51 <engstad> me 2!
20:22:54 <engstad> bye!!
20:22:59 <ski> Pseudonym : you here still ?
20:23:05 <ski> bye bye :)
20:41:53 <ski> anyway, one *can* define Y in haskell *without* using recursion and *still* be Hindley-Milner typable
21:20:55 <Pseudonym> Yes, I'm here.
21:21:31 <ski> i only wanted to point out that one can make a H-M typable Y without recursion
21:21:47 <ski> want to see how ?
21:33:09 <Pseudonym> Sure.
21:33:16 <ski> ok
21:33:19 <ski> newtype Y a = Fix {unFix :: Y a -> a}
21:33:26 <ski> y :: (a -> a) -> a
21:33:31 <ski> y f = (\t -> unFix t t) (Fix (\g -> f (unFix g g)))
21:33:54 <ski> or y f = (\g -> f (unFix g g)) (Fix (\g -> f (unFix g g)))   if you like that better
21:34:03 <Pseudonym> OK, I see.  It uses constructors, though, which is not vanilla lambda calculus.
21:34:10 <Pseudonym> But very ingenious.
21:34:43 <ski> or even y f = unFix g  where g = Fix (\g -> f (unFix g g))
21:35:10 <ski> (or y f = g (Fix g)  where g g' = f (unFix g' g') )
21:35:13 <Pseudonym> Well if you can do that, you can do y f = f (y f)
21:35:14 <ski> yes
21:35:35 <ski> but because we have newtype, Fix and unFix is operationally equal to id :)
21:35:41 <Pseudonym> Yes. :-)
21:35:50 <Pseudonym> It's not even any less efficient.
21:35:59 <Pseudonym> Very clever.
21:36:00 <ski> no, the where clause only used sharing, not recursion
21:36:08 <Pseudonym> Oh, you'
21:36:11 <Pseudonym> you're right
21:36:47 <ski> i think i saw this sometime ago on c.l.f
21:36:51 <Pseudonym> Oh, hang on.  It did here: y f = unFix g  where g = Fix (\g -> f (unFix g g))
21:36:52 <Pseudonym> There's recursion there.
21:37:11 <ski> no. two different g:s
21:37:19 <ski> should probably have written :
21:37:34 <Pseudonym> Oh, yes.
21:37:39 <ski> y f = unFix g  where g = Fix (\g' -> f (unFix g' g'))
21:37:43 * Pseudonym nods
21:38:51 <ski> quite a nice idea, i think :)
21:41:05 <ski> s/unFix g/unFix g g/ in the above equation though
21:41:11 <ski> (typo)
21:45:10 <ski> but, of course. it uses recursion on the (static) type-level, i.e. in the type Y. (but in a static type-system this have no whatsoever run-time penance/whatever.. :)
22:44:14 <MangyDawg> hi again guys. :) eng, ski, u guys still here by chance?
22:45:19 <MangyDawg> er, or any1 who can tell me how to write a haskell function to display the m-th fibonacci number?
23:37:22 <ski> MangyDawg : i'm still here.
23:38:03 <ski> do you know the definition of the fibonacci numbers ?
23:53:47 <ski> i'll leave now
23:53:49 <ski> bye
