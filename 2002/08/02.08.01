02:54:21 * shapr awakens
02:55:51 <shapr> aha
02:56:26 <shapr> cool, Oege de Moor and Richard Bird wrote "Algebra of Programming"
02:56:55 <shapr> I'm in the market for more advanced Haskell books...
02:57:17 <shapr> I'm sure I want Chris Okasaki's "Purely Functional Data Structures"
02:57:23 <shapr> any other recommendations?
03:00:47 <pesco> Where did you find these titles? On the Haskell web page? 
03:01:57 <shapr> in an email that just hit the haskell mailing list
03:02:31 <pesco> Oh, I'm on that list! *runs to his mailer*
03:02:43 * shapr grins
03:02:53 <shapr> from Fritz Ruehr
03:03:13 <shapr> seems amazon.co.uk is gonna take 3-5 weeks to ship Okasaki's book.
03:03:13 <pesco> Oh, I'm sorry, I'm not... duh, it's the GHC list I'm on...
03:03:23 <shapr> want me to forward the mail to you?
03:03:40 <pesco> Yes, pesco@haquebright.de
03:03:48 <shapr> hey Jerub
03:04:39 <shapr> ok, sent
03:04:43 <pesco> thx
03:18:04 <pesco> "Book sales on advanced functional programming titles skyrocketed this week, after word had spread through an underground mailing list about two particular volumes which one coder described as 'good', a commonly-used code for sources of new powerful knowledge pertaining to the long-term achievement of world domination."
03:18:27 * shapr laughs
03:18:43 <pesco> *g*
03:19:03 <shapr> I gotta put that on the #haskell quotes page when the wiki gets fixed.
03:19:15 <pesco> Yeah!
03:19:50 <pesco> Please do, what a honor!
03:20:21 * Igloo appears briefly and giggles
03:20:28 <shapr> hi Igloo!
03:20:39 * pesco waves
03:24:11 * Jerub laugh
03:24:26 <Jerub> s
03:24:26 <Jerub> heya shapr.
03:24:31 <shapr> y0
03:24:33 <shapr> wassup?
03:26:13 * Heffalump rejigs his haskell.org subscriptions so the email going to them gets filtered through spamassassin
03:44:03 <pesco> shapr: Has someone notified haskell.org of the Wiki breakage?
03:44:26 <shapr> I sent email to someone, but I don't remember who the real maintainer is
03:44:53 <shapr> I think it was John Heron at some point
03:44:56 <pesco> ic
04:25:00 <Jerub> I grok foldr!
04:25:13 <Jerub> I just figured out a one line (as opposed to 2) factorial.
04:25:29 * pesco is away: Schwimmen
04:26:20 <shapr> yay foldr!
04:28:20 <Jerub> in fact, its less error prone.
04:28:30 <Jerub> it returns 1 for any negative numbers tho..
04:28:42 <Jerub> foldfact n = foldr (*) 1 [1..n]
04:29:00 <shapr> Jerub: you realize foldr == python's reduce for most things?
04:29:06 <Heffalump> what do you want it to return for negative numbers?
04:29:10 <Jerub> don't use python reduce.
04:29:13 <shapr> ohh
04:29:16 <Jerub> Heffalump: I have nfi.
04:29:21 <Heffalump> 1 sounds ok then :-)
04:29:23 <Jerub> well, I don't know what python reduce does.
04:30:25 <shapr> same thing
04:30:39 <shapr> for some reason, very few people use python's reduce
04:30:42 * shapr isn't sure why
04:31:25 <Jerub> whats the difference between foldl and foldr?
04:31:43 <shapr> which way it reduces
04:31:56 <shapr> left associative, or right associative
04:32:05 <shapr> 1 + 1 + 1 could be:
04:32:10 <shapr> 1 + (1 + 1)
04:32:10 <Jerub> ohhh, which way it traverses the list?
04:32:15 <shapr> or (1 + 1) + 1
04:32:31 <shapr> doesn't make a difference for addition
04:32:39 <shapr> but for other things it very much does
04:32:51 <Jerub> foldr a b c = foldr a b (reverse c)
04:32:56 <Jerub> ?
04:33:03 <Jerub> s/foldr/foldl/
04:33:14 <Heffalump> not quite, because of the types
04:33:34 <Heffalump> I think foldl f e xs = foldr (flip f) e (reverse xs)
04:33:43 <Jerub> oh, okay.
04:33:49 <Jerub> still makes sense :))
05:31:02 --- topic: set to 'We put the Funk in Funktion || HOpenGL 1.03 released - http://haskell.org/HOpenGL || looking for team members for a #haskell ICFP contest entry, more info on http://purl.org/wiki/haskell/IcfpContest' by shapr
05:32:41 <shapr> #haskell - We put the Funk in Funktion
05:41:52 * Jerub laughs
05:41:58 <Jerub> shapr: I think haskell is funky now
05:44:26 * Pseudonym thinks we might change the channel topic while the wiki is down
05:46:44 --- topic: set to 'We put the Funk in Funktion || HOpenGL 1.03 released - http://haskell.org/HOpenGL || looking for team members for a #haskell ICFP contest entry, more info when the HaskellWiki returns.' by shapr
06:38:41 * pesco is back (gone 02:13:11)
06:38:49 <shapr> y0
06:38:52 <pesco> yay
06:39:15 <shapr> wassup?
06:39:45 <pesco> I'm tired. After recovery, I'll implement the last TLU training function.
06:40:20 <shapr> yay!
07:31:50 <pesco> Wooh! It works.
07:31:58 <shapr> hey redcrosse, wassup?
07:32:09 <redcrosse> heya
11:07:34 <shapr> boing
11:35:11 <liiwi> sproing
12:31:35 <shapr> any Parsec users here?
12:31:48 <liiwi> players, ym?
12:32:05 <shapr> no, I mean the Parsec part of the text package of GHC
12:32:10 <shapr> it's a parser builder
12:32:15 <shapr> for Haskell
12:32:40 <shapr> why does this return ')' ?
12:32:40 <shapr> openClose :: Parser Char
12:32:40 <shapr> openClose = do{ char '('
12:32:40 <shapr>               ; char ')'
12:32:40 <shapr>               }
12:33:07 <shapr> oh
12:33:08 <Heffalump> how did you invoke the parser?
12:33:26 <shapr> run openClose "()"
12:33:51 <shapr> the Parsec tutorial gets you to define the run function yourself
12:34:01 <shapr> and it's:
12:34:03 <shapr> run :: Show a => Parser a -> String -> IO ()
12:34:03 <shapr> run p input
12:34:03 <shapr>         = case (parse p "" input) of
12:34:03 <shapr>             Left err -> do{ putStr "parse error at "
12:34:03 <shapr>                           ; print err
12:34:04 <shapr>                           }
12:34:06 <shapr>             Right x  -> print x
12:34:20 <shapr> so obviously, the last succeeding parser will print its successful input
12:34:24 <shapr> and...
12:34:27 <Heffalump> oh, right
12:34:38 <Heffalump> you need your parser to actually build an abstract syntax tree or something
12:34:41 <shapr> since openClose is built of two separate parsers, the second one prints its output.
12:34:43 <shapr> right.
12:34:50 <shapr> I've just started reading this doc though :-)
12:35:06 <shapr> so I'm tracking down any parts I can't figure out till I do understand them.
12:38:18 <shapr> hm, I'm not sure my reasoning is correct.
12:38:35 <Heffalump> what is the type Parser a?
12:38:54 <shapr> something in Parsec
12:38:55 <shapr> dunno what
12:39:17 <shapr> here's another example that does return "()"
12:39:19 <shapr> parens  :: Parser ()
12:39:19 <shapr> parens  = do{ char '('
12:39:19 <shapr>             ; parens
12:39:19 <shapr>             ; char ')'
12:39:19 <shapr>             ; parens
12:39:19 <shapr>             }
12:39:21 <shapr>         <|> return ()
12:39:42 <shapr> it gets called the same way, so why does it return "()" with input "()"?
12:40:07 <Heffalump> *shrug*
12:40:26 <shapr> maybe something later in the doc will tell me
12:45:10 <shapr> wow
12:45:14 <shapr> many1 rocks
12:45:19 <shapr> I'm in luv!
13:04:02 * shapr chortles happily
13:04:10 <shapr> Parsec is a cheerful thing.
13:23:21 <shapr> it's weird how people drop in, then disappear.
13:25:09 <shapr> I wonder what's up with that.
13:33:56 <pesco> hey
14:35:17 * shapr blinks
14:37:35 <Igloo> I would expect there to normally be a data constructor before the subparsers called, shapr
14:37:43 <Igloo> But I haven't used parsec itself
14:37:54 <shapr> hi Igloo!
14:37:59 <Igloo> Hi  :-)
14:38:07 <shapr> how are ya?
14:38:23 <Igloo> Disoriented
14:38:24 <shapr> you seem busier lately, are you getting a life? :-)
14:39:03 <Igloo> I'm sure if disorientate exists then disorientated should be allowed
14:39:10 <Heffalump> a house, I'm sure they're almost the same thing...
14:39:11 <Igloo> These last few days I've been decorating
14:39:28 <shapr> lambda wallpaper?
14:39:43 <Heffalump> hmm....
14:39:44 <Igloo> This is the earliest I've got back to civilisation (well, bandwidth) in a few days
14:39:48 <Igloo> :-)
14:40:01 * Heffalump wonders what Caroline would think of that...
14:40:19 <Igloo> I could do a deal...tiggers in one room for lambdas in another
14:40:23 <shapr> hah
14:40:33 <pesco> heheh
14:45:05 <shapr> tiggers are good for wallpaper.
14:46:44 <shapr> Parsec is good stuff.
14:48:42 <Igloo> Writing predictive grammars by hand isn't fun, though
14:48:56 <shapr> really?
14:49:01 <shapr> I'm writing a lojban parser.
14:50:13 <Igloo> dict seems to think that is a language; predictive parsers are the "type" of parser parsec uses (I think)
14:50:31 <Igloo> Oh, actually, I think it has a try function or something so it's not purely predictive
14:50:34 <shapr> lojban has a YACC grammar already.
14:50:46 <shapr> and yes, it has the try function, though it says that's really slow compared to the other stuff
14:51:41 <Igloo> Yeah, the advantage of purely predictive parsers is they are linear time, whereas try can introduce bactracking leading to exponential time
14:54:33 <shapr> iirc, YACC is predictive
14:54:47 <shapr> so is the META thingy from Common Lisp
15:01:59 <Igloo> Am I right in thinking you need this parser for the second banana layer, shapr?
15:02:14 <shapr> well
15:02:18 <shapr> hey it's hdaume
15:02:32 <shapr> y0 Hal, I don't think I've seen you on here before.
15:02:35 <shapr> I'm Shae Erisson.
15:03:16 <shapr> I strongly suspect that hdaume is Hal Daume, regular contributor to many Haskell mailing lists
15:03:36 <shapr> I also suspect he's thinking about problems with hMPI =)
15:04:12 <shapr> Igloo: nah, I don't really need Parsec, I just wanted to know about it before the ICFP contest happened.
15:04:39 <shapr> I started reading the Monadic Parsing paper from Meijer & Co., and I had to try it.
15:04:47 <hdaume> how'd you guys guess :)
15:05:09 <shapr> Hi Hal, nice to meet in realtime.
15:05:22 <pesco> Welcome to the world of tomorrow!
15:05:43 <shapr> hm, it is after midnight.
15:05:54 <hdaume> same to you
15:05:59 <hdaume> it is most certainly not after midnight
15:06:13 <shapr> it is in Finland :-)
15:06:24 <hdaume> sure sure :)
15:06:28 <Igloo> shapr: Ah, makes sense
15:06:50 <shapr> it's @962.75 in Internet Time.
15:07:31 <pesco> "@ Internet Time". Why couldn't they name it something less ridiculous?
15:07:56 <shapr> because it's from Swatch
15:07:59 <Heffalump> isn't it Internet Time that got us the dotcom boom?
15:08:03 <shapr> and it was a marketing gag.
15:08:25 <pesco> Heffalump: *raiseseybrow*
15:08:32 <pesco> eyebrow even
15:08:37 <Heffalump> they did everything on internet time.
15:08:49 <hdaume> out of curiousity, how many people here use haskell as their primary programming language?
15:09:01 <Heffalump> define primary?
15:09:33 * Heffalump works with SML, used to work with Haskell (well, code for my PhD), tries to write the odd shell script in Haskell instead, writes perl for his main hobby project atm...
15:09:54 <hdaume> hrm...perhaps % of time-wise, or perhaps what you develop your "primary" project in
15:10:07 <shapr> I get paid to write Java and Python, and I'm trying to integrate Haskell into my Python job.
15:10:52 <pesco> My primary projects switch rapidly, but for my current obsession (neural nets) I'm using Haskell.
15:11:13 <pesco> Crypto was done in Haskell, too.
15:11:20 <Igloo> My last and current project (in terms of actively coding on) are in Haskell
15:11:52 <pesco> A graphics demo in Haskell is on my list.
15:13:11 <hdaume> graphics in haskell is one thing i've never really touched...i wrote a pong game using the Hugs Graphics Library (curse that for having the same possible abbrev as Haskell GL) a while back, but that's it :)
15:13:42 <pesco> I'll most probably go with HOpenGL.
15:14:46 <hdaume> that's what i figured
15:15:11 <pesco> I'm also thinking about implementing a volume renderer in C++ to visualize 3-dimensional Julia sets which I've already coded up in Haskell.
15:15:38 <shapr> I want to replace J2EE with H2EE.
15:16:09 <pesco> Hrm. I don't like things with "Enterprise" _or_ "Edition" in them.
15:16:42 <shapr> I get paid to build spiffy dynamic websites. I want to use Haskell to do it :-)
15:17:24 <hdaume> well if all you care about is IE, you could build COMs out of haskell code :)
15:17:28 <hdaume> (afaik)
15:17:57 <Heffalump> ick!
15:18:01 <shapr> yah, ick!
15:18:19 <hdaume> i get the impression that the intersection of haskell programmers and windows users is quite small
15:18:33 <Heffalump> hdaume: outside MSR, you mean :-0
15:18:35 <Heffalump> s/0/)/
15:18:37 * shapr grins
15:18:58 <hdaume> Heffalump: do they actually use windows as a dev os there?
15:19:06 <hdaume> Heffalump: i'd always assumed not
15:19:13 <pesco> Poor buggers.
15:19:14 <Heffalump> I've heard they use a fair bit of Linux too
15:19:25 <Heffalump> have you read Simon PJ's page on making Windows vaguely usable?
15:20:03 <hdaume> yeah; back when i used windows i did that, but i use solaris at work and now use  linux at home & on my laptop, just because it's easier
15:20:20 * Heffalump runs Linux inside VMware on his Windows machines
15:20:29 * shapr runs away from windows
15:20:39 * pesco laughs
15:21:59 <shapr> one of my irc friends is blind
15:22:18 <shapr> screen readers in linux don't support X yet
15:22:20 <shapr> only console
15:22:59 <shapr> that's had a profound impact on how I design websites.
15:23:26 <pesco> You're a good person.
15:24:19 * Heffalump makes sure he writes valid HTML
15:24:49 <Heffalump> writing valid XHTML 1.1 is a good way of keeping a website usable in many different circumstances
15:24:56 <Igloo> Valid HTML can produce a page in which the content is contained entirely within pictures
15:25:21 <Igloo> The website for something like Currys did that, which was a pain as I wanted to copy and paste opening hours
15:25:25 <Heffalump> s/1/& and not being stupid about it/2
15:25:36 <Heffalump> and the ALT tags should describe what's in the pictures, anyway
15:25:54 <Igloo> Yeah  :-)
15:25:56 * Igloo disappears
15:27:22 <shapr> hdaume: from what I've heard talking to various people, Haskell would be more used if more libraries were available.
15:31:09 <hdaume> shapr: i have the same impression; i'm sure there are other reasons though :)  (for instance, very few people in the US at least know what a functional language is -- even college grads)
15:32:21 <shapr> best thing to do is keep talking about it.
15:32:48 <shapr> I'm convinced that Haskell is more orthogonal than other languages I've used, and that I can write software faster in Haskell than any other language I've used.
15:33:21 <hdaume> i am as well...i've been using it for a little over a year now and can develop much faster in it than anything else
15:33:33 <shapr> I'm not yet proficient to the point of being able to develop commercial applications with Haskell, but when I reach that point, I will start doing that.
15:33:47 <shapr> I've only been using it since September
15:34:04 <hdaume> i think my code is a lot cleaner; a lot of times in, say, C, i'll think to myself "i could do this the right way or i could just put it in a global variable" which makes my code basically unusable
15:35:43 <shapr> My Haskell code is far more elegant than my Python code.
15:36:04 <shapr> that's impressive since I'm fluent in Python, and just vaguely familiar with Haskell.
15:36:29 <shapr> I'm addicted to recursion!
15:37:32 <hdaume> i wrote some C code about 8 months ago and i don't think i had one loop
15:37:50 <shapr> wow, cool!
15:38:14 <hdaume> probably wasn't the most efficient code, since gcc doesn't optimize tail recusion (i don't think)
15:38:28 <shapr> I've not had much success explaining the elegance of purely functional programming to my Java using colleagues.
15:39:34 <hdaume> nor i; i've convinced one of my friends to learn haskell "when he has time" (he uses C# at work), but he was in my college SML course so he's biased...most of my contemporaries here don't want to spend the time learning a new language
15:39:48 <shapr> I see that too.
15:39:55 <hdaume> i'd say for me the hardest thing about using haskell is that no one else here uses it, so when i need support, i have to turn to the mailing lists
15:40:19 <shapr> ah, but now you've found #haskell!
15:40:38 <hdaume> true (or is it better ettiquette here to say "True")
15:40:44 * shapr grins
15:42:41 <shapr> there are several very knowledgable people here.
15:44:26 <hdaume> well i'm not having any new problems that i haven't posted ot the mls yet, but when i do... :P
15:45:02 <shapr> maybe I should advertise #haskell on the mailing list.
15:46:36 <hdaume> i've known for a while that it existed; i just never bothered to actually come here
15:46:59 <hdaume> perhaps it should be featured more prominently on the haskell.org site, thoguh
15:47:39 <shapr> is it mentioned anywhere other than the Wiki?
15:48:34 <hdaume> i don't think so
15:48:49 <shapr> time for an advert
15:52:40 <shapr> hi Andrew
15:52:46 <shapr> how are ya?
15:52:55 <Pseudonym> Not bad, not bad.
15:53:27 <shapr> doing anything fun today?
15:53:48 <Pseudonym> It's 8:54am.  I got up and had breakfast and commuted to work.
15:54:03 <Pseudonym> So no, not really.
15:54:07 * shapr grins
15:54:17 * Pseudonym rarely finds any of the above fun
15:54:25 <Pseudonym> Unless I have a good book to read while commuting.
15:54:32 <Pseudonym> Yourself?
15:54:44 <hdaume> shall i play there "where do you live" guessing game?  australia?
15:54:44 <shapr> it's 1:54am, and my mind is full of monadic parsing.
15:54:56 <shapr> I luv monadic parsers!
15:54:57 <Pseudonym> Correct.  Melbourne, in fact.
15:56:10 <shapr> Pseudonym: do you do most of your daily code in Haskell?
15:56:17 <Pseudonym> No.
15:56:24 * Pseudonym hacks in C++ for a living
15:56:27 <shapr> oh
15:56:51 <Pseudonym> At my previous place of employment, I was working up a Haskell prototype for the next generation of one of their shipped products.
15:57:10 <Pseudonym> So that was kinda cool.
15:57:37 <Pseudonym> I still own the IP, and they didn't pay me for it, so I figure I can open source it now. :-)
15:57:50 <hdaume> what was the product?
15:57:53 <Pseudonym> When it's finished, anyway.
15:57:58 <Pseudonym> RenderMan shading language compiler.
15:58:41 <Pseudonym> Problem is it compiled for their renderer (RDC), so it's kinda no use without buying that.
15:58:59 * Pseudonym is considering portiing it to Aqsis
16:01:36 <hdaume> in your free time, right? :)
16:01:41 <Pseudonym> Right. :-)
16:01:55 <Pseudonym> I'd still like it to see the light of day, though.
16:02:29 <Pseudonym> People who write high-end renderers tend to be graphics people, which means when it comes to writing the scripting system, they tend to write poor compilers.
16:02:42 <Pseudonym> Whereas I'm a compiler writer who got into graphics.
16:07:07 <hdaume> that's cool...cross pollenation is always a good thing
16:08:31 <Pseudonym> I think so.
16:08:52 <Pseudonym> Haskell, IMO, is a natural.  It's a compiler, but the target code is very complicated.
16:09:00 <Pseudonym> Not the actual instructions, mind.
16:09:15 <Pseudonym> The problem is... anyone care if I get off topic for a bit?
16:09:28 <hdaume> not at all
16:09:33 <Pseudonym> Cool. :-)
16:09:50 <Pseudonym> You know about shading systems, like Cg?
16:10:41 <hdaume> yeah
16:10:51 <Pseudonym> Basically, to model a material and how it reacts to light, you write a little program to be run on every sample.
16:11:05 <Pseudonym> Cg compiles down to NVIDIA microcode.
16:11:33 <Pseudonym> The RenderMan spec doesn't specify how to implement their shaders.
16:12:15 <Pseudonym> Most compile to abstrat assembler of some sort (stack machine or expression trees plus control flow stuff).
16:12:33 <Pseudonym> Then run an interpreter to actually execute the code.
16:13:03 <Pseudonym> The problem is that you're typically running the program over many thousands of samples.
16:13:30 <Pseudonym> The overhead of an optimised interpreter compared with native code is something like a factor of 10x.
16:13:43 <Pseudonym> For typical interpreters anyway.
16:13:52 <hdaume> wow
16:14:03 <Pseudonym> So you want to avoid that cost if you can.
16:14:09 <hdaume> i would say so
16:14:13 <Pseudonym> Especially since in a high-end renderer, this is the inner loop./
16:14:32 <Pseudonym> So what you do is simulate a SIMD parallel architecture.
16:14:45 <Pseudonym> Run the same program on multiple data points at the same time.
16:15:23 <Pseudonym> If you do it on, say, 256 samples at a time, you amortise the cost over each sample.
16:15:33 <Pseudonym> The overhead goes from 1000% to something like 4%.
16:15:46 <Pseudonym> With me so far?
16:16:42 <hdaume> yeah
16:17:12 <Pseudonym> OK.  For straight-line code, this is pretty straightforward.  The tricky part comes when you have if-then-elses, loops and so on.
16:17:50 <Pseudonym> For an if-then-else, for example, you need to run some of the processing elements for the "then" part, then other processing elements for the "else" part.
16:18:25 <Pseudonym> For a loop, you start with all processing elements (assuming you're not already inside a loop or if-then-else, that is), and they slowly drop out as the loop goes on.
16:18:41 <Pseudonym> Eventually, they all drop out and you can go on.
16:19:10 <Pseudonym> Basically, the way you do this is you maintain a bit vector, called the "runflags".
16:19:43 <Pseudonym> Traditionally (say, in the Pixar CHAP processor), the runflags are organised in a stack.
16:20:53 <Pseudonym> So if you hit an if-then-else, say, you push the runflags first, then evaluate the condition, see which processing elements should still be running, then execute the "then" part, do some bit fiddling to work out who should be executing in the "else" part, then pop at the end of that.
16:21:02 <Pseudonym> Still with me?
16:21:21 <hdaume> makes sense, though i probably couldn't implement it :)
16:21:32 <Pseudonym> The rules are actually fairly straightforward.
16:22:04 <Pseudonym> Incidentally, the CHAP microcode was mostly written by Bruce Perens.
16:22:12 <Pseudonym> Bit of trivia there.
16:22:53 <hdaume> :)
16:23:18 <Pseudonym> Anyway, the other thing is you want to optimise "uniform" code.
16:23:31 <Pseudonym> Some variables don't change between samples.
16:24:06 <Pseudonym> Some if-then-elses you can tell at compile time will all be the same for each processing element.
16:24:25 <Pseudonym> It helps that the source language lets the programmer say whether a variable is "uniform" or "varying".
16:24:36 <Pseudonym> Of course you want to optimise this.
16:24:50 <Pseudonym> So you tag everything on whether it's uniform or varying.
16:24:59 <Pseudonym> And the interpreter can avoid runflag computations some of the time.
16:25:28 <hdaume> ping?
16:25:33 <shapr> pong!
16:25:34 <Pseudonym> ack
16:25:42 <Pseudonym> Right.  That's the background you need.
16:25:46 <hdaume> okay, my net connection just went hay-wire
16:25:48 <Pseudonym> Now the real story.
16:26:20 <Pseudonym> RDC doesn't use an interpreter.  It compiles to C++ which is then compiled down to a DSO, loaded by the renderer.
16:26:29 <Pseudonym> This reduces the 4% overhead to 0%.
16:26:42 <Pseudonym> All well and good.
16:27:03 <Pseudonym> Except that now there's lots of opportunity for optimisation that wasn't there before.
16:27:41 <Pseudonym> For example: runflags were previously arranged in a stack.  Now you can make them pre-allocated local variables.
16:28:00 <Pseudonym> And you can be tricky about when you use them.
16:28:23 <Pseudonym> You still need the SIMD evaluation, despite no interpreter overhead.
16:28:56 <Pseudonym> The reasons are severalfold.  Some of the language primitives are more efficient if you run them in SIMD.
16:29:13 <Pseudonym> For example, texture accesses are more coherent, and can be cached more efficiently.
16:29:38 <hdaume> ok
16:29:40 <Pseudonym> Also, area operators.  The SL has derivatives as part of the language.
16:30:02 <shapr> shading language?
16:30:19 <Pseudonym> If you compute some variable, say q, then Du(q) is the derivative of q with respect to the grid coordinate u.
16:30:24 <Pseudonym> Shading language, yes.
16:30:34 <Pseudonym> You might want to check the logs.
16:30:38 <shapr> I have.
16:30:44 <Pseudonym> :-)
16:30:56 <shapr> still wasn't sure what SL was short for... :-)
16:31:00 <Pseudonym> OK.
16:31:28 <Pseudonym> Anyway, to cut a long story short, there are lots of optimisation opportunities and nobody is exploiting any of them.
16:31:44 <hdaume> that's cool...i didn't even know work like that was going on in graphics
16:32:12 <Pseudonym> There's a lot of everything going on in just about every field.
16:32:24 <hdaume> true :)
16:32:35 --- topic: set to 'We put the Funk in Funktion || See logs @ http://tunes.org/~nef/haskell/ || HOpenGL 1.03 released - http://haskell.org/HOpenGL || looking for team members for a #haskell ICFP contest entry, more info when the HaskellWiki returns.' by shapr
16:32:43 <Pseudonym> The thing about high-performance software is that you need to get 1000 little things all correct.
16:32:54 <hdaume> yeah
16:33:57 <Pseudonym> In the case of a renderer, for example, if it works with 2Gb of compressed geometry and 10Gb of compress texture data, then if you add another 100Mb or so the slowdown should be linear at worst.
16:34:10 <hdaume> all right, i gotta get going...nice (and informative) talking to you all....
16:34:13 <hdaume> Pseudonym: yeah
16:34:19 <shapr> nice meeting you Hal.
16:34:26 <Pseudonym> Nice meeting you too.
16:34:35 <Pseudonym> Farewell.
16:34:57 <shapr> Pseudonym: have you read about Chilli's Nested Data Parellelism stuff?
16:35:24 <Pseudonym> Nope.
16:35:30 * Pseudonym is looking it up now
16:35:33 <shapr> It's vaguely connected to this discussion at the SIMD point.
16:35:54 <shapr> Chilli has spoken about SPMD, Single Program, Multiple Data
16:36:16 <Pseudonym> Part of the thing about renderers in the Reyes style is that the SIMD evaluation is arranged on a rectangular grid.
16:36:39 <shapr> Chilli is writing an NDP array type for GHC
16:36:49 <Pseudonym> I suspect that nested data parallelism is more general than that.
16:36:55 <Pseudonym> Arbitrary topologies or something.
16:37:36 <Pseudonym> The other thing is the characteristics of the execution.
16:38:16 <Pseudonym> You have uniform computations mixed with data-independent parallel computations, then all of a sudden you have five synchronisation barriers all at once.
16:38:41 <Pseudonym> Ideally you want the cost of synchronisation to be small.
16:38:45 <shapr> Chilli pointed me to some discussion about that.
16:38:53 * Pseudonym nods
16:39:16 <shapr> I hadn't heard of SPMD before.
16:39:44 <shapr> I'm looking forward to setting up some fractal calculations on my LAN with his NDP stuff.
16:40:12 <Pseudonym> Is his implementation designed for distributed processing?
16:40:21 <shapr> Yes, it's implemented on top of MPI.
16:40:25 * Pseudonym nods
16:40:34 <Pseudonym> Probably not useful for this application, then.
16:40:53 <Pseudonym> The parallelism is too fine-grained.
16:40:56 <shapr> iirc, it's also good for SMP machines.
16:41:03 <Pseudonym> On the other hand, bucketed renderings might benefit.
16:42:23 <Pseudonym> Don't have time to explain, but the optimised reyes pipeline uses basically coarse-grained largely independent work units, with a small amount of communication between them.
16:42:32 <Pseudonym> Sounds like a good fit there.
16:42:50 <shapr> I can google for reyes pipelines.
16:43:03 <Pseudonym> Hang on.
16:43:26 <shapr> Though reading your posts on comp.graphics.rendering.renderman(?) might be equally illuminating.
16:44:08 <Pseudonym> Not mine.
16:44:11 <Pseudonym> Tom Duff's.
16:44:15 <shapr> Ok.
16:44:19 <Pseudonym> http://groups.google.com/groups?selm=3593DB90.794B%40pixar.com
16:45:27 * shapr reads
16:47:44 <shapr> Interesting stuff.
16:48:04 <Pseudonym> I think I have a copy of the original reyes paper around here somewhere.
16:48:31 <Pseudonym> If you care. :-)
16:48:57 <shapr> I would enjoy reading it, yes.
16:49:11 <shapr> if it's archived on citeseer, I can get it from there as well.
16:49:19 <Pseudonym> I don't think it is.
16:49:32 <pesco> Never leave the house without a paper to read on the bus, I say.
16:49:42 <Pseudonym> That's what I reckon, too.
16:50:02 <shapr> If you have a copy that you'd like to share, I'd like to read it.
16:51:03 <pesco> It's amazing how much knowledge you absorb just by utilizing the usually idle time on public transportation.
16:51:46 <Jerub> I usually read books.
16:51:50 <Jerub> good ones of course.
16:51:53 <pesco> Or that.
16:52:00 <Pseudonym> When I drove to work, I was shocked how little I read.
16:52:07 <Pseudonym> Overall.
16:52:17 <pesco> *g*
16:52:21 <shapr> I work ten feet from my bed.
16:52:35 <Pseudonym> I always take a paper just in case I finish the book.
16:53:13 <pesco> Also papers fit nicely into a pocket, while you might not always have enough room to carry a book.
16:53:15 <Jerub> I take my bible if I'm afraid I'm going to finish my book.
16:53:31 <shapr> I'm looking for more advanced Haskell and Functional Programming books, any suggestions?
16:53:42 <Pseudonym> What have you got at the moment?
16:53:56 <shapr> I have Thompson's Craft and Hudak's SOE
16:54:05 <Pseudonym> The Bible is kinda light on typed second-order lambda calculus, of course.
16:54:07 <shapr> I'm planning to purchase Okasaki's FDS
16:54:30 <shapr> Man cannot live on typed second-order lambda calculus alone.
16:54:33 <shapr> :-P
16:54:37 <Pseudonym> This is true.
16:55:11 <pesco> I prefer the Principia Discordia on religious occasions.
16:55:54 <shapr> I like to read both of those books, though I only take the former seriously.
16:55:58 * Pseudonym hasn't forgotten about the paper, of course
16:56:21 <shapr> Pseudonym: no hurry, I have enough to read for the moment.
16:56:35 <shapr> I'm learning about the Parsec parser that's part of GHC.
16:56:48 <pesco> shapr: Taking the Principia seriously wouldn't be healthy for anyone of course.
16:56:54 <Pseudonym> Not true.
16:56:56 <shapr> pesco: that is the point.
16:57:02 <Pseudonym> I have a friend who is genuinely a Discordian.
16:57:05 <Pseudonym> As in it's his religion.
16:57:11 <shapr> My last name is Erisson.
16:57:12 * Jerub looks at conversation and realises that it would be very easy to refer to a 'paper' as something a prole reads too.
16:57:27 <pesco> shapr: *G* I've noticed. :]
16:57:59 <shapr> There's a joke in there somewhere.
16:58:02 <pesco> Pseudonym: Even more a reason towards the argument of him not taking it seriously.
16:58:08 <Pseudonym> Son of Eris?
16:58:16 <shapr> Pseudonym: that's correct.
16:58:20 <Pseudonym> Cool.
16:58:34 <shapr> It's a joke.
16:58:46 <Pseudonym> Obviously.
16:58:51 <Pseudonym> It's still a cool one.
16:58:56 <shapr> Thanks ;-)
16:59:05 <shapr> My mother wasn't very happy when I changed it though :-)
17:00:02 <Jerub> shapr: what was your last name/
17:00:14 <shapr> My name was Robert Benjamin Gilliam.
17:00:20 <shapr> I was called "Ben"
17:00:30 <Jerub> What is it now?
17:00:39 <shapr> Shae Matijs Erisson
17:00:59 <Jerub> Its certiantly difference.
17:01:01 <Jerub> er different.
17:01:16 <shapr> My family has by now mostly figured out that I haven't joined a cult and become a different person.
17:01:29 <Pseudonym> Mind you, Gilliam isn't a bad surname.
17:01:45 <shapr> It doesn't fit me though.
17:02:08 * Jerub laughs
17:02:29 <Jerub> I would be perfectly happy to drift away from my family, if it weren't for the fact I like my grandparents so much.
17:02:45 <shapr> I still love my family just as much, there's been no change in that.
17:03:00 <Jerub> Its not like I don't like my parents, I do like them. But I don't really feel any need to stay close to them.
17:03:10 <shapr> I wish I could spend more time with my parents.
17:03:32 <Jerub> I wish I oculd spend more time with my wife ;)
17:03:52 <shapr> :-)
17:04:31 * Pseudonym laughs
17:04:37 <Pseudonym> I spent last year working from home.
17:04:47 <Pseudonym> Believe me, it's possible to spend too much time with one's family.
17:04:48 <shapr> Pseudonym: Supposedly Gilliam is from Guillame, aka William of Orange
17:05:10 <Pseudonym> My wife is now happy when I go away, because I come home.
17:05:18 <pesco> Heheh
17:05:40 <shapr> I haven't been back to the USA to see my family in over a year :-/
17:06:23 <shapr> On the good side of that, I've spent most of my spare time learning new stuff, and that pleases me greatly.
17:06:35 <pesco> lol
17:06:39 <shapr> Parsec is powerful!
17:07:19 <shapr> Pseudonym: Both of time together and time apart are essential to relationships.
17:07:43 <shapr> From what I've seen that's true.
17:09:10 <Pseudonym> This is true.
17:09:27 * Pseudonym is house-sitting for his parents atm
17:09:40 <shapr> Pseudonym, do you do Lojban?
17:09:52 <Pseudonym> No.  Used to do some Esperanto.
17:10:16 <shapr> Ok, seems like something that might interest you if you weren't already aware of it.
17:10:44 <pesco> shapr: What's Lojban?
17:12:25 <Pseudonym> http://www.mds.rmit.edu.au/~ajb/reyes.pdf
17:12:31 <Pseudonym> Got it finally.
17:12:37 <pesco> *yawn* Whatever it is, I will rest now. Have a good night my friends, talk to you tomorrow.
17:12:48 <Pseudonym> Night.
17:13:23 <Pseudonym> pesco, it's a language like Esperanto.
17:13:33 <shapr> g'night pesco
17:13:34 <Pseudonym> Except the syntax is based on first-order predicate logic.
17:13:40 <Pseudonym> That's basically it.
17:13:49 <shapr> and it has a YACC grammar.
17:14:01 <shapr> I'd like to try to make a spoken programming language out of it.
17:14:23 <Pseudonym> I think there might be too much phonemic ambiguity.
17:14:33 <Pseudonym> It's hard for computers to "wreck a nice beach".
17:14:51 <shapr> truly
17:15:29 <shapr> And yet, for spoken programming, Lojban is the best starting point I know of.
17:17:09 <Pseudonym> Actually, it goes the opposite direction that programming languages are going.
17:17:16 <shapr> How so?
17:17:17 <Pseudonym> Programming languages are getting _more_ ambiguous.
17:17:35 <shapr> Can you give me some examples?
17:17:40 <Jerub> Pseudonym: explain.
17:17:42 <Pseudonym> The C++ spec has a wonderful line in it:
17:18:00 <Pseudonym> If it looks like a declaration, then it is.  Otherwise, if it looks like a statement, then it is.  Otherwise, it's a syntax error.
17:18:24 <Pseudonym> This is because C++'s grammar is inherently ambiguous.
17:18:31 <Jerub> Pseudonym: I don't consider C++ to be recent enough to justify the use of the word 'more'.
17:18:39 <Pseudonym> How about Perl?
17:19:22 <Pseudonym> Even Haskell's lexical analyser can't be written in lex, when you take into account the offside rule.
17:19:43 <Pseudonym> The lexer needs lexical feedback to disambiguate where offsides end.
17:19:52 <Pseudonym> Sorry, the lexer needs _parser_ feedback.
17:20:01 <Pseudonym> I think.
17:20:20 * Pseudonym shouldn't shoot his mouth off like that before checking first
17:20:42 <Jerub> Pseudonym: perl is ambiguous because of the culture.
17:21:00 <Pseudonym> Right, because it's based more on natural language.
17:21:35 <Jerub> no, its based on larry walls brain
17:21:36 <shapr> I'd say Perl is based on unix command line utilities.
17:21:38 <Pseudonym> Edinburgh Prolog isn't ambiguous, but it does require infinite lookahead to parse.
17:22:11 <Pseudonym> Which is nasty because error reporting is hideous.
17:22:18 <shapr> I never got along well with Perl.
17:22:30 <shapr> I do use Python a lot though.
17:22:35 <Pseudonym> I've seen one parser which reports "Your program contains one or more syntax errors" with no further explanation.
17:22:36 <Jerub> ll(k) ?
17:22:55 <Pseudonym> No, Edinburgh Prolog is an operator grammar.
17:23:41 <Pseudonym> But it has weird operator fixities, not just infix and prefix like Haskell.
17:23:55 <shapr> By the way, monadic parsing is beautiful.
17:24:06 <Pseudonym> Monadic parsing is beautiful.
17:24:12 <shapr> Yes, it is.
17:24:26 <Pseudonym> I have only two problems with it.
17:24:33 <shapr> What are those?
17:24:41 <Pseudonym> 1) No lookahead support.  Fixed if you use arrows.
17:24:59 <shapr> I'll get into arrows as soon as I upgrade my brain.
17:25:03 <Pseudonym> 2) Performance model is non-obvious.
17:25:29 <Pseudonym> And by that I mean that a small change to your grammar may result in ugly changes in performance characteristics.
17:25:30 <shapr> Can you elaborate on 2?
17:25:43 <Pseudonym> Well you could introduce left recursion, for example.
17:25:49 <shapr> I see.
17:25:56 <Pseudonym> By accident.
17:26:09 <shapr> That's still true of Arrow parsing, isn't it?
17:26:14 <Pseudonym> Yes.
17:26:44 <Pseudonym> Parsing theory used to be a research interest of mine.
17:26:55 <shapr> Of course, compared to the recursive single character parsing code I've read before, this is like suddenly forgetting to bang my head against the floor.
17:27:17 <shapr> Is there something better than Arrows?
17:27:40 <Pseudonym> I think the best approach, and it's going to be difficult to do properly, is LR parsing combinators.
17:27:59 <Pseudonym> The difficult part is that you have to construct an LR machine.
17:28:03 <Pseudonym> It doesn't separate well.
17:28:07 <shapr> My list of things to research grows as this conversation continues.
17:28:16 <shapr> This is great :-)
17:28:22 <Pseudonym> So what you need is a precompilation step.
17:28:34 <Pseudonym> When the Wiki is back up, look at RunTimeCompilation.
17:28:46 <shapr> I'll check it out.
17:29:13 <shapr> My bedtime approaches.
17:29:29 <Pseudonym> I also added a section to TyingTheKnot which illustrates some more of the ideas behind RunTimeCompilation.
17:29:44 <Pseudonym> Anyway.  Lots to read. :-)
17:29:49 <Pseudonym> Good night.
17:30:13 <shapr> Thanks for the pointers to things to learn, good night.
21:36:23 * Chilli is back (gone 21:47:59)
23:47:54 * hornby thinks the link should be http://tunes.org/~nef/logs/haskell/
