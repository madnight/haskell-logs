00:17:29 <fog> see fig 2. of https://statistics.stanford.edu/sites/g/files/sbiybj6031/f/2017-12.pdf
00:17:42 <fog> its like a sigmoid activation function
00:19:11 <fog> so that the "nets as neurons" as a first approximation to "universal grphical lambda-net approximators", should have an equivalence between cumulative integrals of multimodal distributions as activation functions for the monadicity
00:19:41 <fog> then by cybenko, it being monotone should prove its universal approximation 
00:40:13 <[exa]> Arahael: "exporting functions that use the C ABI" ? so I assume you have a .hs with FFI exports, some of these functions can be broken by ABI changes, and you want to say make sure in the generated .h that the user has a chance to see if it's going to break?
00:41:20 <Arahael> [exa]: Yeah, I want to ensure that that .h file always corresponds to the haskell static library that contains those exported functions that were written in haskell.
00:46:42 <[exa]> well the best way is to push your packaging system into appending some kind of version string to the .h, so that the user needs to knowingly mess stuff up
00:46:49 <[exa]> or perhaps to the function/symbol names
00:47:01 <[exa]> ok s/best/one possible/
00:47:25 <[exa]> are you going to package this as a library?
00:51:07 <[exa]> another option would be to give out a dynamic library that explicitly links to a versioned runtime... esp. if the incompatibility problem happens between the HS library and your precompiled library and the header file contents stay roughly same
00:56:03 <Arahael> Actually it's more that I have an app, which consumes the library, which happens to be in haskell.
00:56:19 <Arahael> So I want to do: "build.sh", which builds the haskell library first, then copies it to the host app, then builds that.
00:56:44 <Arahael> So whilst yes, it'll be "a library", it's not going to be packaged as such for others.
00:56:59 <Arahael> Versions aren't needed, though it makes sense, really, I would not be opposed to adding versioning.
01:12:00 <[exa]> "consumes" in what sense? links to dynamically, or links statically?
01:13:14 <[exa]> anyway I guess that you just need to make sure that your app will get the correct libHSrts & pals?
01:14:06 <[exa]> (ideally the ones the internal haskell library is expecting?)
01:14:15 <dminuoso> https://hackage.haskell.org/package/unix-time-0.4.7/docs/Data-UnixTime.html `Please note that this uses GHC-derived Eq and Ord instances.`
01:14:38 <dminuoso> At times I wonder what motivated the package author to this. It seems non-sensical at first impression.
01:15:03 <[exa]> dminuoso: time diffing is hard
01:15:50 <dminuoso> [exa]: Sure. But simply not exposing the UnixTime constructor seems would have been enough.
01:16:22 <dminuoso> The underlying problem [ppears not that this uses GHC-derived Eq and Ord instances, but that you can create invalid data when using the data constructor.
01:17:02 <Arahael> [exa]: Links statically, at least, that's the aim.
01:18:54 <[exa]> dminuoso: agreed, but perhaps there are more corner cases (syscalls returning nonsense?)
01:19:51 <[exa]> (it would be great to have a code search engine that can e.g. search the hackage for stuff that imports the constructor and uses it directly)
01:20:08 <dminuoso> [exa]: I'd consider this a bug by whatever produces UnixTime, as whatever syscall wrapper you have should go through a smart constructor.
01:20:52 <[exa]> dminuoso: I'd file an issue (isn't the author idling here?)
01:21:07 <[exa]> Arahael: and the GHC libs are also linked statically?
01:21:16 <dminuoso> [exa]: If they are, I wouldn't know under which nickname :)
01:21:19 <dminuoso> But you are right
01:22:03 <Arahael> [exa]: Not yet. :)
01:22:08 <[exa]> nothing related to the maintainer name here :]
01:23:49 <[exa]> Arahael: so in particular, if I get it correctly, you have an .a (or .lib) of your library that expects that when linking your app, you will also link it with the correct HSrts .a or .lib, and you want to know the most reliable way not to mess that up?
01:24:43 <Arahael> [exa]: Pretty much. I mean, I have a few options. I could define a "schema" and use that to code-generate the FFI layers.  Or I could have the haskell code "produce" the library, which then gets imported into the host app and the types checked that way.
01:26:00 <mokulus> What's the difference between a functor and a function?
01:26:35 <[exa]> Arahael: ok well, I'd suggest just linking the final app with the same ghc you used for compiling your lib. The other way would be to extract the link options (paths etc) from the ghc (there should be some cmdline argument for that) and make sure you pass it correctly to your final linker
01:27:14 <Arahael> [exa]: Yeah, most likely be doing the latter, there, actually - but that covers the ABI, what about the API bit?
01:27:52 <[exa]> Arahael: if you use the same ghc for everything (and call `ld` just a GHC would) the problems you can encounter are likely problems of GHC :]
01:28:01 <[exa]> Arahael: perhaps I'm missing something that could still break
01:28:50 <Arahael> [exa]: What I want to do is ensure that: If the host app is expecting that a function exists, that should result in a compile-time, rather than a link-time, error.  Additionally, if that function returns an Int rather than a Float, that should also be a compile time error.
01:28:51 <[exa]> mokulus: functions do anything computable with data, functors are special (slightly restricted) functions that process types, not data
01:29:25 <mokulus> But in mathematics, isn't it the same?
01:30:06 <[exa]> yeah they behave very similarly in many aspects (but I wouldn't say they are same)
01:30:24 <[exa]> you may jump into category theory now
01:31:50 <Arahael> [exa]: What I also want to avoid is: Writing the same function interface, by hand, four times. (1x in the host language, 1x in the header file, 1x in the FFI syntax for haskell, and 1x in "nice" haskell)
01:32:02 <[exa]> Arahael: oh so. That should be ensured by that GHC puts together a "sane" .h from your .hs; your compiler should complain about non-existent functions on the other case.
01:32:03 <Arahael> [exa]: I want to write it *once*.
01:32:46 <Arahael> [exa]: At a pinch, I'm happy to write it twice - in haskell and in the host language, but I want the build environment to *ensure* that they are equivalent.
01:32:48 <[exa]> you certainly need to write a translation from the nice haskell to FFI (that also assigns it a symbol name), but you should be able to write the whole "type" exactly once at the exact ffi export
01:33:06 <[exa]> the C "types" get generated in the .h
01:33:30 <Arahael> Oh, so the .h file is already generated automatically when you use haskell's ffi?
01:33:56 <[exa]> yeah, it generates sourcename_stub.h
01:34:16 <[exa]> see here https://en.wikibooks.org/wiki/Haskell/FFI#Calling_Haskell_from_C
01:34:24 <Arahael> Ah, nice.  That would actually be good enough - what do I need to read to get familiar with that?  You're reading my mind.  Neat.
01:35:10 <[exa]> the 2 single points of linking truth should be present in the .h (which specifies the convention) and in the linker params (that specify the expected HSrts libs to link with)
01:35:21 <Arahael> I note that page does not state that compiling the haskell code produces the .h file.
01:35:28 <Arahael> [exa]: Absolutely.
01:35:50 <Arahael> [exa]: It's going to be a bit trickier since I will be cross-compiling, too, but I'll fight that bit later.
01:36:01 <Arahael> (If and when I have time - I'm really just playing)
01:36:43 <Arahael> Ultimate goal: To try producing a "simple" static library for use in a Catalyst app (macos, iOS, and iPadOS)
01:37:19 <[exa]> notably the wikipage also uses ghc to do the linking (although they lie that they _compile_ the C code with ghc, actually it calls gcc)
01:37:47 <[exa]> uh crosscompiling, wow
01:38:19 <Arahael> Yeah - I'm just hoping that all the bits out there already make this simple. (Eg, the reflex-frp project should have the tools, hopefully)
01:38:30 <[exa]> that might become a bit more complicated but it looks like you would pack in the static HSrts anyway
01:38:52 <Arahael> Yeah, definitely.  Plus iOS and iPadOS don't support dynamic linking anyway.
01:39:10 <Arahael> Apparently it's technically allowed by the operating system, but it's still not supported.
01:39:16 <[exa]> reflex has some kind of a huge "project template" that should make it run on most platforms
01:39:28 <[exa]> but I wouldn't really bet on crosscompiling and iPadOS :]
01:39:39 <Arahael> What do you mean? :)
01:39:58 <[exa]> making stuff portable is hard
01:40:02 <Arahael> But yeah, I'm actually looking to have a "simple" static lib, if supported.  I feel that reflex-frp does "too much".
01:41:11 <[exa]> anyway if you can pack all your haskell into a library, with a bit of static linking you should be able to transform anything to an executable that the operating system won't tell from a C one
01:41:37 <Arahael> I'm making things somewhat easier by ensuring, in this "homework" project, that the haskell static library has no external dependencies.  It certainly wouldn't be setting up the UI.
01:41:46 <[exa]> mokulus: btw, are you aware about the "generic wrap" intuition for Functors?
01:41:52 <Arahael> And yeah, that's the goal - making this look like a boring C library.
01:41:58 <Arahael> Which I just happened to use haskell for.
01:42:15 <mokulus> [exa]: no
01:44:00 <[exa]> mokulus: in haskell, the functors are mainly represented by the `fmap` function, which is basically a "generic `map`"
01:44:39 <[exa]> while map works only with the lists, fmap works on anything that, from the type perspective, looks like such a container
01:45:05 <Arahael> You can even 'map' a Maybe type.
01:45:19 <xsperry> more than just containers. fmap works on IO, parsers, etc
01:45:31 <[exa]> mokulus: technically, the type of map is `(a->b) -> [] a -> [] b`
01:45:53 <[exa]> mokulus: transforms a list of 'a's to a list of 'b's using a function (a->b)
01:46:27 <[exa]> mokulus: fmap has the [] abstracted out, as `(a -> b) -> f a -> f b` with the condition that `f` is a Functor
01:47:43 <Arahael> [exa]: Incidentially, this Apple Silicon thing is potentially going to mean that we'll not have to cross-compile to target iPadOS or iOS.
01:47:44 <[exa]> so you can happily do the map-style transformation on anything that kindof works like that kind of wrap -- lists, Maybes, trees, Eithers, tuples, Maps, Sequences, even functions (if you take them as containers for results) and IO (also a "container" for the "result" if viewed from the correct angle)
01:49:25 <[exa]> mokulus: fun thing, you can view the `f` in the fmap type as a function on types, which makes the primitive `a` and `b` a bit more complex (say, makes a tree of them). `fmap` is a way to get through this added structure
01:49:34 <mokulus> So monads are for that additional work, like applying a function to the whole list, or not applying it in Maybe Nothing case, right?
01:50:27 <[exa]> monads are functors with extra conditions and tools that allow e.g. combining the wraps in weird ways
01:50:53 <[exa]> :t join
01:50:55 <lambdabot> Monad m => m (m a) -> m a
01:50:58 <[exa]> join $ Just Nothing
01:51:07 <[exa]> oh noes
01:51:10 <[exa]> > join $ Just Nothing
01:51:12 <lambdabot>  Nothing
01:52:04 <[exa]> very simply, monads are functors that have a straightforward way of flattening a double "wrap" into a single one.
01:52:36 <[exa]> okay let's see some examples...
01:52:57 <[exa]> > fmap (fmap (+1)) [[1],[3,5],[]]
01:52:59 <lambdabot>  [[2],[4,6],[]]
01:53:21 <[exa]> > join [[1],[3,5],[]]
01:53:23 <lambdabot>  [1,3,5]
01:54:00 <[exa]> > fmap (fmap (+1)) $ Just (Just 3)
01:54:02 <lambdabot>  Just (Just 4)
01:54:14 <[exa]> > join $ Just (Just 3)
01:54:16 <lambdabot>  Just 3
01:54:53 <mokulus> > join $ Just 3
01:54:54 <lambdabot>  error:
01:54:55 <lambdabot>      • No instance for (Num (Maybe ())) arising from a use of ‘e_13’
01:54:55 <lambdabot>      • In the expression: e_13
01:55:00 <[exa]> interestingly, the `join` is the thing that allows sequential IO happen in a very convenient way (only it's expressed with >>=)
01:55:19 <[exa]> mokulus: `join` expects 2 levels of wrapping that it will squash into one
01:55:49 <Arahael> > join $ Just (Just (Just 3)) -- Will also fail.
01:55:52 <lambdabot>  Just (Just 3)
01:56:02 <Arahael> ... To produce 3. :D
01:57:42 <[exa]> mokulus: the magic thing is the polymorphism of `fmap`, really a lot of data structures are functors which gets pretty useful
01:58:19 <[exa]> fmap (+1) ('a',123)
01:58:40 <[exa]> --> ('a',124)
01:59:16 <mokulus> > fmap (+1) ('a',123)
01:59:17 <lambdabot>  ('a',124)
01:59:37 <mokulus> Why no change/error on 'a'?
02:00:26 <[exa]> mokulus: it's the way the default Functor for the tuples work (the types are different, applying a single function on those would basically require that both tuple items would have the same type...)
02:00:57 <mokulus> ahh makes sense
02:00:59 <[exa]> fun thing, IO is a functor. You can read a list of all words on a line using `fmap words getLine`
02:01:33 <mokulus> 'A monad is a monoid...' what is monad's binary operation? 
02:01:57 <Arahael> [exa]: I've always found it curious how that doesn't work for (123, 'a')
02:02:08 <[exa]> mokulus: monads in haskell aren't monoids but some intuition holds
02:03:17 <[exa]> mokulus: mostly, just as the order of applying the monoid <> in a sequence doesn't matter, the order of squashing a long structure with `join` shouldn't matter
02:04:31 <mokulus> :t <>
02:04:32 <lambdabot> error: parse error on input ‘<>’
02:04:43 <Arahael> :t (<>)
02:04:44 <lambdabot> Semigroup a => a -> a -> a
02:05:03 <[exa]> technically that has nice implications, most importantly you can construct sequences of computation with (>>) and don't care about the "important details" of execution
02:05:10 <[exa]> :t (>>)
02:05:11 <lambdabot> Monad m => m a -> m b -> m b
02:05:23 <[exa]> :t print "a"
02:05:26 <lambdabot> IO ()
02:05:30 <[exa]> :t print "a" >> print "b"
02:05:31 <lambdabot> IO ()
02:06:35 <mokulus> So functors are functions on types?
02:06:46 <Arahael> I think of (>>) as "and then".
02:07:08 <[exa]> mokulus: yes, they "belong" to a wider class of functions on types
02:07:25 <coot> @mokulus the trick with `A monoid is a monoid` is that one is not considerint a product as the monoidal product but functor composition which makes `join` to be the monoidal product.
02:07:25 <lambdabot> Unknown command, try @list
02:07:48 <coot> ^ ups I should say `A monad is a monoid ...`
02:07:57 <nil> :t join
02:07:59 <lambdabot> Monad m => m (m a) -> m a
02:08:02 <[exa]> mokulus: they are nicely restricted to have the working and law-obeying "fmap" which makes them predictable and useful
02:08:15 <Arahael> coot: `... in the category of endofunctors`?
02:08:22 <coot> yes 
02:08:25 <nil> if you squint a bit you can see that this looks like (m, m) -> m
02:08:46 <mokulus> But why is there a distinction between types and values? I'm new to this
02:09:27 <coot> If you change `(_, _)` for `_ . _` where dot is the functor composition: both satisfy the same laws: asssociativity and unit law.
02:09:43 <mokulus> hmm I guess because types are more restictive
02:09:49 <[exa]> mokulus: because values in algorithms are, say, necessary :D
02:11:09 <mokulus> Hmm, but could you only use types in theory?
02:11:13 <nil> some languages have types as first-class values (usually dependently-typed languages), but haskell does not; in haskell, types only exist at compile time, while values are used at runtime
02:11:29 <nil> (modulo some language extensions)
02:11:53 <[exa]> mokulus: very high-level view of that is that the types are theorems constructed from the programs. Methods of construction of the theorems can bring values to types and types back to programs. Technically, both types and values are values from the computer's point of view, just wrapped in weird ways
02:14:10 <[exa]> mokulus: more pragmatically, the distinction doesn't make much sense; in haskell the types are produced and consumed by the compiler as a working, relatively tangible formalism to see what the programs do and enable various forms of sane generic programming, etc.
02:15:50 <[exa]> incidentally, if you add to many stuff into types (say numbers), the work of the compiler is going to get much harder
02:16:17 <coot> Another take is from logic perspective, where types server the role of propositions, and values are proofs.  E.g. a type `a -> a is a proposition which sais `a` impiles `a`; the `id :: a -> a` is a proof.
02:17:05 <mokulus> Ok let me try this, I've read a bit
02:17:27 <mokulus> a -> b <=> ~a v b
02:17:42 <[exa]> finally, it's interesting how quickly the compiler problems become very easily undecidable if you add tiny bits of compelxity... :]
02:17:43 <mokulus> v is either
02:17:55 <[exa]> ....such as the negation.
02:17:57 <mokulus> but not?
02:18:14 <[exa]> mokulus: there's a wikibooks page on Curry-Howard correspondence that describes this problem
02:19:35 <nil> note that "a -> b <=> ~a v b" is only valid in classical logic
02:20:22 <nil> negation is usually encoded as ¬a ≡ a -> ⊥, where the ⊥ proposition can be represented with the Void type in haskell
02:20:27 <[exa]> (it would be something like `Either (a->Void) b`)
02:21:25 <coot>  the `<=` can be proven constructively, and it might be  a nice exercise.
02:21:39 <nil> the fact that this isn't valid in intuitionistic logic means that you can't make a (total) function of type `(a -> b) -> Either (a -> Void) b` in haskell. you could, though, if the language had a primitive call/cc (call with current continuation) operator
02:22:07 <nil> yes, i should have clarified that only the => direction is invalid
02:45:00 <mokulus> :t (>@>)
02:45:01 <lambdabot> error:
02:45:01 <lambdabot>     • Variable not in scope: >@>
02:45:01 <lambdabot>     • Perhaps you meant one of these:
02:47:48 <mokulus> What learning resources do you recommend?
02:48:11 <[exa]> for what precisely?
02:48:38 <[exa]> (there's been a wide spectrum of topics here ^^^ )
02:54:19 * hackage hascard 0.2.0.0 - A TUI for reviewing notes using 'flashcards' written with markdown-like syntax.  https://hackage.haskell.org/package/hascard-0.2.0.0 (Yvee1)
03:37:19 * hackage souffle-haskell 1.1.0 - Souffle Datalog bindings for Haskell  https://hackage.haskell.org/package/souffle-haskell-1.1.0 (luc_tielen)
03:38:26 <Arahael> Souffles!
03:48:05 <Uniaika> cheese soufflés are so good
04:24:19 * hackage stache 2.2.0 - Mustache templates for Haskell  https://hackage.haskell.org/package/stache-2.2.0 (mrkkrp)
05:38:19 * hackage Win32 2.9.0.0 - A binding to Windows Win32 API.  https://hackage.haskell.org/package/Win32-2.9.0.0 (TamarChristina)
05:47:31 <ezemtsov> Hi everyone. I have a problem loading "BootTidal.hs" script in ghci 8.8.3. It complains becuase of pragma line ":set -XOverloadedStrings" on ":" character. Running the contents of the script manually in ghci works well. Am I doing something wrong?
05:49:58 <phadej> in .hs files you should write {-# LANGUAGE OverloadedStrings #-}
05:51:32 <hpc> it's too bad you can't put {-# LANGUAGE OverloadedStrings #-} into ghci
05:51:39 <hpc> it just thinks it's a comment
05:51:50 <ezemtsov> Regretfully the project is not maintained by me. Is there any way to load it as a list of gchi commands?
05:53:13 <hpc> if i am reading :help right, ":script <file>              run the script <file>" should work
05:54:04 <ezemtsov> @hpc thanks a lot, this works well
05:54:04 <lambdabot> Maybe you meant: src rc pl ghc
06:09:49 * hackage transformers-abort 0.6.0.3 - Error and short-circuit monad transformers  https://hackage.haskell.org/package/transformers-abort-0.6.0.3 (MikhailVorozhtsov)
07:04:31 <nerdypepper> is there a way to write this in one line: filter strings from a list of strings of length 3 or 4
07:10:56 <ski> nerdypepper : you want to retain them, or remove them ?
07:11:36 <nerdypepper> ski: remove them, although i could do one if i knew the other right?
07:12:13 <ski> > (filter ((`notElem` [3,4]) . length) . words) "The quick brown fox jumps over the lazy dog"
07:12:16 <lambdabot>  ["quick","brown","jumps"]
07:12:19 <ski> > (filter ((`elem` [3,4]) . length) . words) "The quick brown fox jumps over the lazy dog"
07:12:21 <lambdabot>  ["The","fox","over","the","lazy","dog"]
07:12:34 <ski> > (partition ((`elem` [3,4]) . length) . words) "The quick brown fox jumps over the lazy dog"
07:12:36 <lambdabot>  (["The","fox","over","the","lazy","dog"],["quick","brown","jumps"])
07:13:05 <nerdypepper> sweet, thanks ski!
07:13:09 <ski> np
07:14:13 <ski> (note btw that you probably shouldn't be calling `length' many times of the same list(s))
07:15:56 <nerdypepper> ski: wouldn't this call 'length' exactly once per item of the list?
07:16:47 <nerdypepper> but i understand what you mean, i should probably store it if i need to use it again
07:17:15 <ski> yes, it would
07:53:27 <fog> I wanted to aske about this approach to buffering;
07:53:27 <fog> https://pastebin.com/raw/JtnK0WT5
07:55:22 <oats> anybody know what setting will stop lsp-mode from auto-highlighting other instances of the identifier under the point?
08:00:44 <sureyeaah> oats try setting lsp-eldoc-render-all to nil
08:10:26 <oats> sureyeaah: no dice :(
08:16:59 <Boarders> i'm trying to use brick but when I do:
08:16:59 <Boarders> txt "hello" <+> txt "\n    " <+> txt "world"
08:17:10 <Boarders> it ignores the newline and just renders everything on one line
08:17:20 <Boarders> is there something I can do to make sure newlines are rendered properly?
08:19:04 <Guest63907> There’s a different operator for joining things vertically
08:20:52 <Boarders> right but I don't want to join everything vertically
08:20:57 <Boarders> I just want it to handle newlines
08:21:27 <Guest63907> Why not txt “hello\nworld” then
08:21:46 <Boarders> well obviously I am doing something a lot more complicated than that....
08:22:11 <Boarders> I am trying to render with syntax highlighting and so I am trying to separately handle whitespace and words
08:22:38 <Guest63907> That operator joins widgets horizontally, so I’m not sure what you want it to do differently
08:23:05 <Boarders> I am just asking how I might be able to join text together
08:23:08 <Boarders> that is all I want to know
08:25:23 <Boarders> I don't care which operator I use to do that
08:25:30 <Boarders> I just want it not to eat newlines
08:26:19 * hackage packdeps 0.5.0.0 - Check your cabal packages for lagging dependencies.  https://hackage.haskell.org/package/packdeps-0.5.0.0 (MichaelSnoyman)
08:27:02 <monochrom> I hate it when people speak like that. Perhaps vertical join is close enough to what you want. If not, then perhaps that library is not at all what you're looking for.
08:27:49 <Guest63907> would you accept txt $ unlines [ “hello”, “world” ] ? :)
08:28:30 <monochrom> unlines just adds \n
08:28:58 <hseg> am getting spurious -Wunused-packages errors. but if i turn on -fkeep-going they go away. but if i put that in ghc-options in .cabal they stay in place. wtf?
08:30:13 <hseg> it looks like this is only triggered for module signatures
08:33:45 <gentauro> does `concatMapM` exist? If not, how can I define it? :)
08:34:14 <monochrom> It doesn't exist. I don't know what it would mean.
08:35:47 <hpc> it'd be something like what mtl does, i think
08:35:54 <hpc> since concatMap sort of /is/ the M
08:35:57 <hpc> in other definitions
08:36:01 <merijn> Conduit has that one
08:36:10 <gentauro> hmmm, maybe using `join` -> https://hackage.haskell.org/package/base-4.14.0.0/docs/Control-Monad.html#v:join
08:36:29 <hpc> gentauro: what type do you think it should have?
08:36:40 <gentauro> I found this with `hoogle` -> https://hackage.haskell.org/package/extra-1.7.4/docs/src/Control.Monad.Extra.html#concatMapM
08:37:37 <gentauro> hpc: instead of working with a container of type `[a]`, I want to do my (effectul) logic on a container of type `[[a]]` 
08:38:36 <gentauro> `mapM foo [0…9]` vs `concatMapM foo [[0…4], [5…9]]`
08:38:46 <merijn> hpc: "concatMapM :: (Monad m, Monoid r) => (a -> m r) -> [a] -> m r" or something along those lines
08:39:15 <merijn> So something like "\f -> mconcat . mapM f"
08:40:20 <oats> sureyeaah: heh, sorry, wrong channel. just realized I was in #haskell :P
08:43:45 <fendor> can I make optparse-applicative less strict in its parsing? e.g. if I have a `--version` option, just ignore any other given option? similar to how the `helper` works but without `exitCode 1`
08:46:15 <fendor> actually --help does not have an exitCode 1, so abortOption should work 
08:50:40 <Guest63907> You can also do your own command line processing before calling it
08:53:35 <hpc> do you specifically want to be able to do "foo --version --other-stuff", or do you just want "foo --version" to not error because you left out "--some-required-option"?
08:56:17 <fendor> hpc, the latter
08:56:25 <hpc> oh, that's super easy
08:56:38 <hpc> versionParser <|> actualCommandArgsParser
08:56:44 <hpc> it has an Alternative instance
08:57:18 <fendor> Guest63907, true but I would like to use optparse-applicative directly
08:57:22 <monochrom> nice
08:58:01 <fendor> hpc, but doesnt it apply the first parser, sees it fails and applies the second one then? It doesnt merge the option parsers, afaict. I am doing roughly that and it doesnt work
09:00:36 <hpc> your version parser should fail if it doesn't receive --version
09:01:43 <hpc> hmm, it's been a while since i had to do this
09:01:54 <fendor> hpc, the version parser seems to fail since the other option is not recognized
09:06:43 <hpc> something like (flag' () (long "version")) <|> (the rest of your parser)) isn't working?
09:07:49 <fendor> hpc, no, I dont think so: https://github.com/haskell/haskell-language-server/pull/241/files#diff-7657a7b7908444f2c0536b06d6df5dedR56
09:08:01 <fendor> but maybe I am doing something wrong
09:09:38 <hpc> you're not using printVersionParser, maybe that's it?
09:10:07 <hpc> somehow i don't have optparse-applicative installed, and cabal is erroring out
09:10:45 <oats> is there a sleeker way to do this? `action >>= \value -> if condition value then pure value else moreAction value`
09:11:03 <fendor> hpc, yes I am? Maybe it is easier to see here: https://github.com/fendor/haskell-language-server/blob/numeric-version/exe/Arguments.hs#L56
09:11:34 <frdg> question about yesod forms https://dpaste.org/fox6
09:12:34 <fendor> it used to work in one big arguments record. I did not like that design as it allowed options that didnt make too much sense in combination, but maybe it is the better model of my arugments?
09:12:54 <hpc> ah weird, ctrl+f somehow wasn't finding that
09:13:33 <fendor> yeah, github diff view is weird sometimes
09:15:00 <hpc> that looks like it should work, hmm
09:17:36 <fendor> I dont think that should work, alternative is one or the other, a combination of both would not concur with my understanding of Alternative
09:32:37 <hpc> finally got it installed
09:32:52 <hpc> fendor: a simple test works for me, parser = flag' "--version" (long "version") <|> flag' "--other-stuff" (long "other-stuff")
09:33:31 <hpc> passing it --version makes the first parser succeed, --other-stuff the second parser, and --invalid-option makes it fail out
09:33:46 <tomsmeding> oats: yes if you're okay with making a helper function :p
09:34:09 <oats> tomsmeding: yeah, that's what I'll end up doing :P just wondering if it's been a common pattern anywhere else :P
09:34:14 <oats> double :P
09:34:23 <oats> that was unecessary :P
09:34:42 <tomsmeding> well there is LambdaCase, which is similar but not quite this
09:36:49 <tomsmeding> @pl action >>= \value -> if condition value then pure value else moreAction value
09:36:49 <lambdabot> ap (liftM2 if' condition pure) moreAction =<< action
09:36:52 <tomsmeding> also that of course
09:37:29 <fendor> hpc, you are right that works. Re-reading your initial question I see that I actually meant the former. I am sorry for wasting your time :/
09:38:48 <hpc> at the very least, it helped me notice that my haskell setup is broken ;)
09:39:37 <fendor> hpc, still, I am sorry :(
09:40:23 <L29Ah> suggest me plz a .cabal project with hspec testsuite that works well with v2-test
09:56:49 * hackage haskell-gi-base 0.24.2 - Foundation for libraries generated by haskell-gi  https://hackage.haskell.org/package/haskell-gi-base-0.24.2 (inaki)
09:57:49 * hackage haskell-gi 0.24.3 - Generate Haskell bindings for GObject Introspection capable libraries  https://hackage.haskell.org/package/haskell-gi-0.24.3 (inaki)
10:00:48 * hackage fakedata-parser 0.1.0.0 -   https://hackage.haskell.org/package/fakedata-parser-0.1.0.0 (psibi)
10:01:48 * hackage gi-gobject 2.0.24 - GObject bindings  https://hackage.haskell.org/package/gi-gobject-2.0.24 (inaki)
10:02:49 * hackage gi-harfbuzz 0.0.3 - HarfBuzz bindings  https://hackage.haskell.org/package/gi-harfbuzz-0.0.3 (inaki)
10:56:33 <charms> I have a type Program = If' Program Program Program | Truth | Falsity; how can I have a megaparsec parser that takes in the string "true" with parser return truth?
10:58:04 <[exa]> charms: something like `Truth <$ string "true"` ?
10:59:03 <charms> that works perfectly, thank you [exa]
10:59:58 <[exa]> btw the symmetric variant with ($>) might look a bit nicer depending on the context
11:01:51 <[exa]> the pointy functors/applicatives operators may look really nice in situations, say in `char '(' *> expr <* char ')'`
11:02:37 <charms> it is nice to follow the flow of the text, even if it isn't imperative
11:02:48 <charms> no pun intended haha
11:03:24 <[exa]> (btw the previous example is easier as `parens expr` but you see the point :])
11:03:43 <[exa]> charms: yeah people read the code sequentially, arranging ideas in that way helps a lot
11:08:47 <hyiltiz> Let P, Q be statements. Is "If P then Q AND if Q then P while P =/= Q"  always invalid or simply just a circular logic? That is, can proofs be cyclic like data structures `x=1:x` and still be valid?
11:11:19 * hackage aeson-deriving 0.1.1 - data types for compositional, type-directed serialization  https://hackage.haskell.org/package/aeson-deriving-0.1.1 (Cliff_Harvey)
11:12:12 <dolio> What language is that supposed to be a proof in? And how does it parse?
11:12:14 <[exa]> hyiltiz: can you add parentheses around that?
11:12:58 <hpc> are you talking about "if and only if"?
11:13:52 <hyiltiz> No, not iff but just if (implication)
11:14:23 <hyiltiz> [exa]: not sure what exactly du mean
11:14:31 <hpc> (P -> Q) /\ (Q -> P) is iff though
11:14:57 <hyiltiz> [exa]: U meant (P -> Q) /\ (Q -> P), P /= Q ?
11:15:11 <hpc> or are you talking about ((P -> Q) /\ Q) -> P?
11:16:20 <hyiltiz> hpc: yes, it generally reduces to P <=> Q; is there any valid instance (in any branch/field of math) where that is not the case?
11:16:39 <hpc> ah, that's what the question is
11:17:20 <hyiltiz>  LOL I have been reading ((P -> Q) /\ Q) -> P when this question came to me but no, I am not asking about Peirce's law
11:18:39 <hyiltiz> More specifically, I am looking for some kind of encoding that encodes a statement into a value, and this composite statement could be encoded into a cyclic data structure
11:19:14 <hyiltiz> Being a cyclic data structure, it wouldn't just reduce to an atomic value (P<=>Q), or be regarded as circular reasoning (invalid)
11:20:03 <hpc> this doesn't seem cyclic to me
11:20:29 <hyiltiz> P points to Q and Q points to P?
11:21:03 <hpc> they don't actually point to each other though, P isn't defined in terms of Q or vice-versa
11:21:06 <hyiltiz> If we didn't learn logic, we might just start by drawing that as a cyclic graph with two nodes
11:21:20 <hpc> you just have two statements defined in terms of them with the implication going in either direction
11:21:43 <hpc> it's like saying (3 / 5) + (5 / 3) is cyclic
11:22:31 <[exa]> hyiltiz: if you insist on adding some kind of "pointy" structure, the implications can form a lattice but this just proves that P&Q are equivalent
11:22:50 <hyiltiz> hpc: not sure I see the sesemblence with your example
11:23:27 <[exa]> hyiltiz: you may want to read that as 'P ≤ Q && Q ≤ P'
11:23:41 <hpc> hyiltiz: P, Q, (->), (/\), 3, 5, (+), and (/) are just arbitrary symbols
11:24:06 <hyiltiz> hpc: agreed
11:25:18 <hpc> but if you look at the structure of the expressions, they're the same
11:27:47 <hyiltiz> Hmm, thx! I was wondering some graph theoretic approach to symbols, parsing, programs and logic
11:31:05 <akala> Hi everyone, I have a (hopefully small) questions about kinds in Haskell.
11:31:29 <akala> Oops, sorry. Not sure how to make a multiline message///
11:31:36 <akala> Oops, sorry. Not sure how to make a multiline message...
11:31:47 <hpc> you just post one line after the other
11:31:57 <hpc> but preferably not more than 3 or so
11:32:37 <hpc> the topic suggests gists for larger blocks of code
11:33:19 <monochrom> You can just use space instead of <enter>.
11:33:40 <hpc> heh, that too
11:35:06 <monochrom> You can also do https://www.smbc-comics.com/comic/language
11:37:04 <pixeleet> Does anyone have an idea when RecordDotSyntax will make it's way into the language? 
11:38:34 <akala> Thanks everyone. I've posted the question here so as to not overload the chat: https://write.as/hkx4wov7euxni.md
11:39:32 <monochrom> No, you get both the type version and the kind version.
11:39:32 <aldum> is that a dig on lisp?
11:40:06 <monochrom> I don't think there is any plan or even wish to change that.
11:40:24 <akala> Thanks for the quick answer, monochrom :)
11:40:49 <monochrom> A dig on lisp would also do prefix polish notation, so I think no.
11:41:47 <akala> Is there a technical reason why both the type version and kind version should exist? I haven't really done any type-level programming; I'm just curious.
11:42:33 <c_wraith> Nothing exists to do that.
11:42:40 <monochrom> I think it's because of this, but it's my impression, not researched history.
11:42:56 <monochrom> The motivation for DataKinds came from a desire for dependent typing.
11:43:17 <c_wraith> and effort on GHC is mostly moving in the opposite direction - eliminating the type/kind hierarchy
11:43:26 <monochrom> Dependent typing allows you to use a value, e.g., MyTrue, in a type.
11:44:25 <monochrom> People desire to bolt on a resemblance of this to Haskell. Their use case means usually they do want both MyTrue as a value and as a type.
11:44:48 <monochrom> (See also how they like the library package "singleton", which is for supporting this style.)
11:45:34 <akala> Ah I see. That makes sense. Thank you both for your responses :)  Sorry if these were silly questions
11:46:32 <akala> Enjoy the rest of the weekend folks!
11:46:44 <monochrom> thank you too
11:47:06 <monochrom> opportunity to make you groan:
11:47:10 <monochrom> "you're so kind"
11:48:26 <hpc> monochrom: don't you know puns are for records only?
11:48:36 <monochrom> haha
11:49:06 <monochrom> I have another one: For the record, I don't like dot syntax. >:)
11:49:42 <monochrom> Haha I should totally post that to the official proposal discussion place.
11:55:00 <hseg> hrmph. ok, so my presumption that my -Wunused-packages errors are caused by my use of backpack have a counterexample
11:55:29 <hseg> even worse, just writing {-# OPTIONS_GHC -Wno-unused-packages #-} at the top of the erroring file *still* causes trouble
11:55:57 <dolio> Regardless of the original motivation, the current behavior of DataKinds fills the need just fine, and having a separate data-kind-only extension is even more complicated.
11:56:48 <ADG1089> better way to write this short snippet?: https://hastebin.com/otoyomulay.coffeescript 
11:57:30 <dolio> Use `fmap W.minimum` instead of `(W.minimu <$>)`
11:58:32 <monochrom> Don't use $. Use parentheses so the structure is self-evident. https://www.smbc-comics.com/comic/language
11:59:30 <hpc> is smbc the new tautology page? :D
11:59:51 <ADG1089> monochrom: so $ is discouraged?
11:59:54 <monochrom> Nah, it just happens that the same comic has multiple relevance today.
12:00:14 <ADG1089> dolio: can you explain? Isn't that just an alias?
12:00:20 <monochrom> I discourage $. I can't speak for others.
12:00:23 <dolio> Yeah, but why write it as a section.
12:00:34 <ADG1089> monochrom: what about functional composition?
12:00:42 <monochrom> In fact, math haters encourage $ because they hate math parentheses.
12:00:45 <hpc> ADG1089: it's not so much discouraged as there's places where it applies and doesn't apply
12:00:58 <hpc> like, you wouldn't put ($) between every single function application in your program
12:01:01 <monochrom> and what hpc said.
12:01:19 <glguy> :t foldl' (foldl' (foldl' min)) 0
12:01:20 <hpc> but for something like f . g . h $ x, maybe that's actually cleaner
12:01:20 <lambdabot> (Foldable t1, Foldable t2, Foldable t3, Ord b, Num b) => t1 (t2 (t3 b)) -> b
12:02:37 <hseg> anybody else run into spurious -Wunused-packages errors?
12:02:44 <hpc> once you get into language extensions ($) can actually make code stop compiling, but that's a whole other issue
12:02:49 <ADG1089> I actually use $ extensively
12:03:00 <dsal> Save that $
12:03:06 <hseg> hpc: definitely have gotten bitten by that multiple times
12:03:24 <dolio> Like what code?
12:03:46 <ADG1089> https://imgur.com/a/BOSVs42
12:04:08 <hpc> almost all of those ($) should be (.)
12:04:16 <dolio> Those could mostly be (.), but I think that's fine.
12:04:21 <hseg> dolio: nearly impredicative code
12:04:42 <hseg> don't recall exact types off the top of my head
12:04:43 <dolio> What does that mean?
12:04:46 <ADG1089> I used to do f1 . f2 . f3 ... fn $ x
12:04:56 <ADG1089> but it's easier to do f1 $ f2 $ f3 $ .... fn $ x
12:05:09 <merijn> ADG1089: Until you refactor, than the first is easier
12:05:13 <glguy> . or $ doesn't matter in that kind of code
12:05:17 <hseg> iirc, argument had a type (forall a. ...) -> ...
12:05:21 <merijn> ADG1089: Because you can move any arbitrary part of it into a local binding
12:05:23 <glguy> the claimed refactoring convenience is minimal at best
12:06:00 <hseg> been a while since, don't remember exact type
12:06:24 <monochrom> I avoid unparenthesized use of unassociative infix operators.
12:07:00 <dolio> ADG1089: If you like the way it looks and don't have any trouble reading it, then don't worry about what people here say.
12:07:01 <ADG1089> dolio: I'm solving a recurrence relation with (iterate part), selecting values (sel1 . sel1), indexing (zip [0..]), removing fisrt 43, finding ones with 0 values and getting first index with 0 (fst . head . filter)
12:07:05 <hseg> indeed, they arguably shouldn't be infix to begin with
12:07:15 <int-e> f1 $ f2 . f3 $ f4 x -- just upset everybody
12:07:18 <monochrom> (x+y)+z and x+(y+z) are the same, it's why we feel free to just write unparenthesized x+y+z
12:07:27 <hseg> same as how noncommutative operators shouldn't be symmetrically shaped
12:07:28 <hpc> hseg: that's what breaks it - it used to happen constantly with ST, and i think there's a special case for it now?
12:07:50 <hseg> yup. but my type was *just* complicated enough to break the special casing
12:07:53 <hpc> or some kind of rewrite rule, i don't remember
12:07:55 <monochrom> (x$y)$z and x$(y$z) are not the same, you would want to remind the reader which one you mean by keeping the parentheses.
12:08:17 <int-e> monochrom: not really
12:08:57 <dolio> hseg: ($) is special cased to work for impredicative cases. So it seems unlikely to me that that is the problem.
12:09:06 <monochrom> OK, I would want to. You can disagree.
12:10:06 <hseg> dolio: again, i recall it being a bug of the form "f $ x doesn't compile but f x does", and the type being sth like (forall r. KnownNat r => L d r i -> W d i -> f) -> W d i -> f
12:10:26 <hseg> but it's been long enough that i've forgotten the details
12:11:37 <monochrom> A long time ago "runST $ do {...}" had that problem about predicativity.  Then GHC added special treatment for $ to fix that.
12:12:01 <hseg> monochrom: i should be more disciplined in that regard as well. only case i can really justify is for the last argument, and that's just to avoid (f) (x) situations
12:12:13 <hpc> that was a pretty important special case because you needed ($) to get it to parse
12:12:26 <hseg> ... scratch that
12:12:28 <hpc> i think there's an extension now that makes you not need that, or it's a work in progress?
12:12:36 <dolio> There has been one special case or another for it for like 10 years.
12:12:48 <hseg> recall seeing sth along those lines, yes
12:13:00 <monochrom> Today I would say that we no longer need this special treatment for $.  BlockArguments exists.  Just write "runST do {...}".
12:13:18 <hseg> that might've been it
12:14:04 <hseg> hrm. don't see why ghc is complaining about my dependency being unused. i have an import from it right there in my code!
12:16:15 <phadej> module or package?
12:16:30 <hseg> ?
12:16:45 <hseg> hrm. seems all my issues come from backpack-dependent packages
12:16:58 <phadej> heh, that's not surprising :)
12:16:59 <hseg> so module signatures and indeterminate packages
12:17:41 <hseg> managed to get ghc to ignore this for the signatures with -Wno-unused-packages, but the indeterminate package breaks even with it
12:17:48 * hackage shake-c 0.4.4.0 - Library for building C code with shake  https://hackage.haskell.org/package/shake-c-0.4.4.0 (vmchale)
12:18:04 <charms> @[exa] I did that change, also my program actually works now i'm really surprised. it just parses a nested if statement and can evaluate it
12:18:04 <lambdabot> Unknown command, try @list
12:18:20 <charms> definitely nicer with the $>
12:18:43 <hseg> .. although that'd explain why -fkeep-going saves it -- everything gets instantiated, so everything is needed
12:24:22 <merijn> monochrom: I'm torn between "special casing $ is an ugly hack" and "minor syntactical extensions like block arguments will be the death of haskell" >.>
12:25:56 <dolio> What if you could get minor syntactical extensions rolled into the report in under 12 years?
12:26:30 <monochrom> I have a feeling that it's "the news of Haskell's death is much exaggerated" :)
12:27:05 <charms> if haskell dies from bad syntax, i think c++ would have died a long time ago
12:27:16 <dolio> Like, Cale was ranting about how many extensions GHC has complicating it, but the flip side of that is that there's no functioning process for making all the simple things not-an-extension anymore.
12:28:11 <monochrom> I think Cale and merijn mean that some extensions are undesirable even if standardized.
12:28:39 <dolio> They don't have to be extensions. It could just be Haskell syntax.
12:28:56 <dolio> Except the current report is 10 years old again.
12:29:10 <monochrom> If IncoherentInstances got into Haskell 2030, they would be shifting the complaint to Haskell 2030, for an exaggerated example.
12:29:39 <dolio> Not every extension has to make it in to reduce the number of extensions complicating the compiler.
12:30:05 <monochrom> (But they have RecordDotSyntax, even LinearHaskell, in mind, IIUC.)
12:30:30 <dolio> LinearHaskell isn't a minor syntactic extension.
12:30:45 <merijn> I don't think BlockArguments is *inherently* bad
12:31:02 <merijn> I think adding it *now* gratuitously adding incompatible syntax and breaking many parsers and tools *is* bad
12:31:55 <merijn> There's 20 billion proposals for various minor changes to syntax and at this point any breaking syntactical changes should have *major* improvements to be worth it
12:33:31 <dminuoso> Even the ($) hack is debatable. I mean there's no inherent need for it, you could just go and say `runST go where go = ...` and it works with plain old haskell.
12:33:58 <dminuoso> Special casing things for minor inconveniences, especially as small extensions, creates gaps every time.
12:34:22 <charms4> could tuple sections be part of the next haskell report?
12:35:39 <merijn> IF we ever get a new one, I think tuple sections has like 100% chance of going in
12:36:01 <hseg> is there doubt about there being another report?
12:36:07 <hseg> ... eventually?
12:36:12 <charms4> BangPatterns too, are quite common
12:36:42 <dolio> Some committee was formed a while ago, right? But it's already been a long time since that.
12:36:47 <dminuoso> hseg: Well the more exotic extensions GHC creates that are hard to implement, the more unlikely it becomes to create another implementation supporting that feature. And if your implementation can't compile the bulk of hackage, you have much less chance of adoption..
12:37:08 <dminuoso> So with each passing year, the incentive and benefit for a haskell report reduces
12:37:43 <dminuoso> We could just pretend and say "Well whatever GHC has is the standard", and with advancing time this becomes the truth.
12:38:11 <charms4> surely that means mistakes are permanent?
12:38:19 <charms4> nothing can be removed
12:38:25 <dminuoso> Because at the end all that a standard is, is an agreement to some sort of definitions. If the community decides to accept GHC as the definition of such rules, then that's a standard
12:38:54 <merijn> There was a Haskell Prime around 2014-2015, it fizzled out, then another one for 2020 that has also fizzled out
12:39:15 <merijn> The problem is that everyone wants to do the *fun* parts of a new report
12:39:21 <merijn> Adding extensions into it, etc.
12:39:44 <merijn> No one wants to do the unfun bits of exactly specifying the semantics of each extensions and how they interact
12:40:21 <merijn> Not to mention there's only 2.5 Haskell 2010 implementations to begin with
12:40:28 <charms4> 2.5?
12:40:41 <hseg> are hugs and uhc still around?
12:40:57 <merijn> charms4: Mu isn't exactly Haskell and also it's closed source because the lawyers won't let us have it
12:41:04 <merijn> hseg: UHC is still around
12:41:34 <merijn> hseg: And supports a supert of Haskell2010 (so Haskell2010 + several GHC extensions, but far from everything and there's no money/motivation to make it support everything)
12:42:08 <merijn> Hugs is around in the sense that it's source still exists, but there's little to no reason to ever use it over GHC
12:42:10 <shapr> there's bits of NHC inside bluespec
12:42:23 <shapr> merijn: I much prefer Hugs for reading the prelude!
12:42:34 <monochrom> hugs isn't updated, and I think cabal devs don't check hugs compatibility anymore. It's still usable for now, but gradually problems will arise (are arising?) regarding e.g., building from source on latest linux etc.
12:43:17 <monochrom> But a good reason to use hugs is much simpler error messages wlog for beginners.
12:43:48 <monochrom> GHC's "inferred, expected, rigid skolem" simply sends beginners to a pointless rabbit hole.
12:44:05 <monochrom> And I dare say meanwhile experts don't need to be reminded either.
12:44:41 <monochrom> Hugs's straightforward "X doesn't match Y" is exactly right.
12:46:44 <MarcelineVQ> I still get confused between X and Y tbh. "Wait did I give it the X or the Y?"
12:46:59 <charms4> i was wondering, is ghc the only user of happy/alex?
12:47:02 <monochrom> sometimes you gave both.
12:47:09 <charms4> i only ever see people do monadic/applicative parsing combinators
12:47:09 <monochrom> "f :: Bool; f = 'x'"
12:47:35 <dminuoso> Anyhow. ParsecT over State is wonderful and amazing! :)
12:47:54 <dminuoso> charms4: Im confident that there's other uses of it.
12:48:07 <monochrom> ParsecT has a user state already.
12:48:08 <dminuoso> charms4: I wouldnt be surprised if many of the other haskell-implemented-languages use it as well
12:48:10 <dminuoso> say idris
12:48:21 <phadej> Cabal uses alex :)
12:48:22 <monochrom> IIRC alex is a user of happy. :)
12:48:46 <monochrom> Is happy a user of alex? That would be complete. :)
12:48:48 <dminuoso> monochrom: megaparsec?
12:48:59 <monochrom> ah OK nevermind
12:51:17 <dolio> I think Agda uses alex and happy.
12:51:26 <monochrom> Maybe you can look into agda and see if it uses alex and/or happy.
12:52:03 <tomjaguarpaw> Does GHCi have NoMonomorphismRestriction set automatically?
12:52:52 <MarcelineVQ> tomjaguarpaw: yes,  type   :showi language  in ghci
12:53:50 <glguy> charms4: I prefer using happy and Alex to parser combinators generally
12:54:01 <tomjaguarpaw> MarcelineVQ: Thanks, never knew about :showi
12:54:39 <charms4> i kind of agree, glguy they can be simpler. i've only used menhir but it is similar
12:54:47 <tomjaguarpaw> Hmm, but why is :show language different to :showi language?
12:55:12 <glguy> I'll default to parser combinators for throw away or tiny cases though
12:56:50 <MarcelineVQ> The i stands for interactive, there's also a corresponding :seti, options that are set for stuff you type into ghci rather than the source code you've loaded, iirc, the ghc manual would probably explain it better.
12:59:12 <MarcelineVQ> I'm not sure, behavior-wise, what the exact difference are or I'd have just said them hehe
12:59:28 <monochrom> I think parser combinators are popular because most are tiny cases.
13:00:50 <monochrom> I guess there are side-channels such as: "build-depends: megaparsec" is more reliable and automatic than "build-tools: happy, alex". :)
13:01:25 <MarcelineVQ> saw a  staged parser combinator  paper recently that aimed to recoved the performance that things like alex gain you  https://mpickering.github.io/papers/parsley-icfp.pdf  which was also a neat application of Selective
13:03:15 <monochrom> all monadic parsing benefits from selectiv.
13:04:08 <monochrom> I've just figured out that for CFG you only need Selective (rather than Monad) for "satisfy :: (Char -> Bool) -> P Char". After that, the rest can stay Applicative.
13:04:44 <monochrom> err Alternative!
13:08:19 <hpc> huh, Selective is pretty neat
13:15:44 <charms4> is it bad form to write `import Prelude hiding (getLine)` if I'm using `Data.Text`?
13:16:00 <dminuoso> charms4: It's probably more common to import Data.Text qualified.
13:16:06 <dminuoso> e.g. `import qualified Data.Text as T`
13:16:10 <dminuoso> But both are fine.
13:16:17 <charms4> thank you
13:16:18 <dminuoso> hiding exists for exactly that purpose. :)
13:16:30 <c_wraith> It's not bad form to hide things from Prelude, but it's uncommon to have only one name clash with Text. :)
13:44:49 * hackage typed-encoding 0.5.0.0 - Type safe string transformations  https://hackage.haskell.org/package/typed-encoding-0.5.0.0 (rpeszek)
13:51:43 <hseg> q: in backpack, is there a way to extend a signature? e.g. given a signature S defining a type T, i want to express that P needs S to be implemented so that Eq T
13:52:34 <hseg> iiuc, if i have P define a signature S whose contents are just the instance Eq T and have P depend on the remaining S signature, this should work
13:54:52 <hseg> hrmph. but that makes ghc complain of a cyclic package import
14:08:52 <hseg> ... why does cabal forbid renaming signatures?
14:09:50 <hseg> i.e. i have a package P depending on sigs S,T which are mergeable. i'd like to rename them to a larger signature U
14:20:37 <jumper149> Should I have QuickCheck as a dependency of my library and already define instances for Gen and Arbitrary or should I create newtypes within in my test-suite?
14:23:32 <c_wraith> quickcheck as a library dependency can cause downstream build issues
14:23:48 <koz_> jumper149: Deffo newtype.
14:23:56 <koz_> You may want _different_ instances for different tests.
14:24:06 <koz_> (to avoid heavy discarding if nothing else)
14:26:16 <jumper149> It just seems like a lot of boilerplate. Most of my types only have valid representations anyways.
14:28:50 <jumper149> Is there something like a shortcut for deriving literally every instance? Then I can also derive Arbitrary.
14:31:20 <hyiltiz> https://en.wikipedia.org/wiki/Yoneda_lemma reads completely unintelligible. Any recommendations to read instead?
14:32:37 <hyiltiz> I found Monad.Reader Issue 6 Adventures in Classical-Land and "When is one thing equal to some other thing?". Not sure if something more accessible/relevant is out there.
14:33:54 <fog> so how do i write all permutations in a buffer?
14:36:13 <fog> % Data.List.permutations [1,2,3]
14:36:13 <yahb> fog: [[1,2,3],[2,1,3],[3,2,1],[2,3,1],[3,1,2],[1,3,2]]
14:36:29 <fog> so, if this is a buffer length 3
14:36:44 <fog> the next value to add to it is 4, and it should discard the 1
14:37:36 <fog> % (map.map) (\a -> if a == 1 then 4 else a) $ Data.List.permutations [1,2,3]
14:37:36 <yahb> fog: [[4,2,3],[2,4,3],[3,2,4],[2,3,4],[3,4,2],[4,3,2]]
14:37:43 <fog> but this seems slow
14:38:05 <fog> im not sure if it could be faster with a way of shuffling the elements around or something
14:38:24 <fog> or having like, partitions so it could just do a head swap at some position
14:38:55 <rom1504> what is your actual problem ?
14:39:48 <fog> hang on...
14:39:51 <fog> % let replace i j = (map.map) (\a -> if a == i then j else a)
14:39:51 <yahb> fog: 
14:40:04 <dminuoso> hyiltiz: Why are you trying to understand Yoneda?
14:40:34 <fog> % replace 2 5 $ replace 1 4 $ Data.List.permutations [1,2,3]
14:40:35 <yahb> fog: [[4,5,3],[5,4,3],[3,5,4],[5,3,4],[3,4,5],[4,3,5]]
14:40:46 <fog> rom1504: like this, but faster
14:41:06 <rom1504> that is not a proble
14:41:09 <rom1504> that is a solution
14:41:11 <fog> % replace 3 6 $ replace 2 5 $ replace 1 4 $ Data.List.permutations [1,2,3]
14:41:12 <yahb> fog: [[4,5,6],[5,4,6],[6,5,4],[5,6,4],[6,4,5],[4,6,5]]
14:41:15 <rom1504> not sure to what problem
14:41:23 <fog> see how they get placed in different locations
14:41:47 <fog> then the way of making it faster by having a partition to just swap the head instead of inserting at some position
14:41:54 <fog> wont work because the position keeps changing
14:42:04 <rom1504> you didn't say what is your problem yet so I cannot say anything
14:42:27 <fog> so i could shuffle them around each time, or keep track of how the location was permuting... since i would have to repartition after shuffling anyway.
14:42:40 <fog> rom1504: the problem is that its matching by equality
14:42:42 <fog> and thats slow
14:42:47 <rom1504> no
14:42:52 <fog> otherwise its doing what i need it too
14:42:55 <rom1504> I'm not asking the problem with your solution
14:43:02 <rom1504> I'm asking what problem you are trying to solve
14:43:07 <fog> why?
14:43:22 <rom1504> because that solution doesn't seem to make sense
14:43:22 <fog> oh no, now im doing it!
14:43:37 <rom1504> and I bet a better solution could be found if we knew the problem
14:43:53 <fog> a larger program requires such a permuted buffering
14:44:14 <fog> i was using Seq for my buffer, to be fast
14:44:28 <fog> but this permutations thing seems to mess it up by needing replacement at all positions
14:44:34 <rom1504> "requires such a permuted buffering" why
14:44:42 <fog> while Seq is fast only at the head and tail positions
14:45:05 <hyiltiz> dminuoso: I was following a rabbit hole
14:45:14 <fog> ""requires such a permuted buffering" why" why, but we already did that. so why why why again!?
14:45:35 <rom1504> you didn't answer yet
14:45:38 <rom1504> http://xyproblem.info/
14:45:50 <fog> at least you did now
14:45:51 <hyiltiz> in fact a few rabbit holes; they all pointed towards it
14:46:03 <rom1504> "my solution is required" is not a problem description
14:46:41 <fog> ok, but i have given several pieces of data which mean it is not an XY problem
14:46:49 <dminuoso> hyiltiz: The Yoneda lemma is a far reaching and fundamental lemma in category theory. It's not easily explainable, the only sensible way to understand it is to prove it yourself. Perhaps repeatedly.
14:47:00 <rom1504> I bet what you want is just doing permutation of indexes from 0 to N then switching values using another array, but I'm just completely guessing as I don't know your problem
14:47:11 <dminuoso> hyiltiz: However, in Haskell you can understand as "Yoneda" as "functor with guaranteable fusion on fmap" :)
14:47:30 <dminuoso> (That is, if you want guaranteed fusion on repeated fmap applications, just wrap it with Yoneda)
14:47:42 <fog> rom1504: the *unit test* given, by equality to the provided solution, completely prescribes the problem
14:47:45 <hyiltiz> dminuoso: that much I understood from http://blog.sigfpe.com/2006/11/yoneda-lemma.html
14:47:46 <rom1504> fog: no that's not what xy problem is about. You're giving your solution to an unknown problem and asking how else to do it
14:48:02 <hyiltiz> But that left it open how does it relate to Representation theorem etc.
14:48:04 <rom1504> ok so then my answer above solves it
14:48:15 <rom1504> but I doubt very much this is useful
14:48:21 <fog> as do several of the varients i surgested
14:48:29 <MarcelineVQ> fog: he's asking, fairly directly which you seem to be ignoring, what you intend to use your solution for once it works how you want it to.
14:48:33 <rom1504> we could have avoided this 20 lines discussions if you just answered my question
14:48:36 <fog> a complexity analysis would decide which is best
14:48:39 <MarcelineVQ> use an Array or Vector if you want to change values at specific indexes in O(1) time
14:48:52 <dminuoso> hyiltiz: well the relationship is easy, really.
14:48:58 <dminuoso> hyiltiz: "relating structure" is captured by functors
14:49:02 <fog> i did anwer it
14:49:19 <fog> your claiming you need to know where i would use this
14:49:30 <hyiltiz> and?
14:49:39 <fog> and that a lack of this is equivalent to an incomplete problem specification
14:49:56 <rom1504> yes exactly
14:50:06 <MarcelineVQ> Not where exactly but why and how. It matters because the wrong solution can never be right, no matter how nice the solution performs.
14:50:06 <fog> right, well that *could* be fishing
14:50:20 <dminuoso> hyiltiz: Yoneda induces an isomorphism between hom sets.
14:50:43 <rom1504> heh you're the one asking for help, if you don't want useful help so be it :)
14:50:45 <fog> now not only do i need to give a complete problem specification, but, for no real reason, a hypothetical use case
14:51:08 <rom1504> if you won't tell us, at least define it for yourself
14:51:10 <MarcelineVQ> at least
14:51:12 <monochrom> Observational-empirically they just want to monologue.
14:51:12 <rom1504> that will help you
14:51:15 <fog> its not unreasonable to expect you to imagine i could need it *for some reason*
14:51:21 <dminuoso> hyiltiz: In abstract terms, we could perhaps put it like this:
14:51:40 <fog> you could suppose i am wrong to think i need something like this, and attempt to solve a wider problem in a different way
14:52:04 <fog> i contest this as being an available alternative avenue, and insist this is exactly the problem i would like to focus on
14:52:45 <MarcelineVQ> focus on it then, if you want help you also need to help the people help you
14:52:51 <hyiltiz> isomorphism between hom sets means functors, right?
14:53:19 <fog> *fine*. the use case, if for the thing my livlihood depends on me keeping secret
14:53:41 <fog> "if you want my help you will divulge your property"
14:53:43 <fog> no
14:53:45 <hyiltiz> feel free to throw me a link if I am asking too trivial questions to educate myself first
14:53:52 <MarcelineVQ> oh my, in that case don't bring it up at all, it could hurt you!
14:53:57 <monochrom> dminuoso: Wait a second! Am I misreading, or are you saying that Yoneda for Haskell simplifies to "fmap (f. g) = fmap f . fmap g"?
14:54:18 <dminuoso> monochrom: As a *guaranteed* mechanism, yes.
14:54:20 <MarcelineVQ> That was a close one, we almost ruined a life
14:54:27 <fog> i have determined that publicising this subproblem does not infringe on my companies software and so is ok to ask in public forum
14:54:54 <dminuoso> monochrom: We dont have RULEs for that, but with Yoneda you can guide GHC into fusing the latter into the former.
14:54:56 <monochrom> Hrm, interesting. Then again I haven't learned Yoneda in any form at all, oversimplified or full-glory or overblown. :)
14:55:09 <fog> MarcelineVQ: you can mock security concerns all you like, thats not going to make them less real
14:55:19 <dminuoso> (You just put Yoneda/Coyoneda around uses of the RHS, and you get the LHS out of it)
14:55:26 <MarcelineVQ> You do not have a security concern here.
14:55:27 <fog> it just seems like pressuring someone to divulge something they rather wouldnt
14:56:15 <hyiltiz> dminuoso: that is what a page on lens docs said "(You just put Yoneda/Coyoneda around uses of the RHS, and you get the LHS out of it)"
14:56:16 <monochrom> Oh! I think it's because "(a -> b) -> (F a -> F b)" some ->'s there are morphisms, some are expoentiation objects, some are possibly both.
14:56:18 * hackage pandoc-citeproc-preamble 1.6 - Insert a preamble before pandoc-citeproc's bibliography  https://hackage.haskell.org/package/pandoc-citeproc-preamble-1.6 (spwhitton)
14:56:19 <MarcelineVQ> I invite you to not ask about something you don't want to talk about in the first place
14:56:24 <dminuoso> monochrom: The relationship is more subtle than just stating that law, though. 
14:56:53 <fog> anyway, i can think of an equivalent example to show how such a thing *could* be useful, which would eleviate these XY concerns. im just a bit miffed with the assumption that *i dont know what im doing* and could be wrong about thinking i need a specific subproblem 
14:57:04 <MarcelineVQ> Luckily I don't think you did, ask anything I mean, since there's still a grey fog covering any semblence of a question here
14:57:31 <fog> % replace 3 6 $ replace 2 5 $ replace 1 4 $ Data.List.permutations [1,2,3]
14:57:31 <yahb> fog: [[4,5,6],[5,4,6],[6,5,4],[5,6,4],[6,4,5],[4,6,5]]
14:57:36 <fog> do that effeciently
14:57:36 <dminuoso> hyiltiz: So the problem is essentially this: Functor has a law `fmap f . fmap g = fmap (f . g)`. sadly however GHC does not know this and cant transform based on this law.
14:57:38 <MarcelineVQ> That's not something to get offended over, implicity when a person asks a question it means they don't know
14:58:00 <MarcelineVQ> So you must not know what you're doing, to ask about it, so it's meaningless to be mad about that
14:58:04 <dminuoso> hyiltiz: (Usually, if you have multiple fmap applications, GHC would then call `fmap` over and over again, when it could compose the internal functions together instead, and then fmap once)
14:58:08 <fog> but i have a working version, thats slow, designed specifically to be a complete problem specification
14:58:20 <__monty__> Hmm, I have a haddock line that's just "-- @inline code@" and it's being rendered as a code block. Is there a good way to force it to be an inline code span?
14:58:20 <fog> and have proposed several alternative optimisations
14:59:27 <dminuoso> hackage: (Co)Yoneda is just an elaborate trick to gain fusion. To the end user, it's just "plain old functor/fmap with guaranteed fusion" for whatever functor you like. :)
14:59:29 <fog> consisting of partitioning, swapping the head, and shuffling 
14:59:33 <dminuoso> hyiltiz: ^-
14:59:41 <hyiltiz> dminuoso: thx! I now see how is is relevant in Haskell
15:00:30 <MarcelineVQ> fog: use an Array or Vector if you want to change values at specific indices and Seq doesn't seem good enough
15:00:47 <hyiltiz> What about how something that look so "trivial/innocent"  can be a core theorem in category theory in math?
15:00:48 <fog> but i think i can do something more structured
15:01:09 <hyiltiz> aka what string implications/powers does it have in CT?
15:01:17 <fog> based on partitioning and head swapping and shuffling
15:01:18 <hyiltiz> s/string/strong/
15:01:18 <monochrom> Hand-optimizing code is a paid full-time job.
15:01:45 <rom1504> fog: I proposed a solution to your problem which consists in doing permutation from 0 to 2 (inclusive) and using an auxiliary Array containing your values (say [4,5,6]) when accessing the permutations values. You do not need to replace all permutations
15:02:09 <rom1504> so the replacement is no-op
15:02:13 <dminuoso> hyiltiz: So in Haskell we pretend there's a category called Hask, which is essentially a subcategory of Set. By pretend I mean with a bit of squinting.
15:02:25 <fog> rom1504: nice!
15:02:26 <rom1504> if it does not solve your problem, you'll have to explain more
15:02:27 <fog> thanks
15:02:38 <fog> no its a fantastic solution 
15:02:42 <dminuoso> hyiltiz: So the yoneda embedding embeds Hask in Hask...
15:02:49 <dminuoso> Things become a bit boring
15:02:54 <fog> so that would use IORefs or something?
15:03:19 <dolio> The yoneda embedding is not really related to the 'fmap fusion' stuff previously explained.
15:03:49 <fog> im projecting against random matricies
15:03:50 <hyiltiz> Oh "the yoneda embedding embeds Hask in Hask" doesn't mean "it guaranteese fmaps fuse"?
15:04:14 <fog> i can either shuffle the matrix of the thing its being applied to
15:04:20 <dminuoso> hyiltiz: The reason it (sort of) guarantees fmap fuse is rather a sequence of causalities. 
15:04:23 <fog> to make "more measures" for cheap
15:04:30 <dolio> The `Yoneda` type that people use for fmap fusion is not even the Yoneda embedding.
15:04:39 <dolio> It is the type involved in the Yoneda lemma.
15:04:57 <fog> so by running the random matrix over all permutations, its as if i had used many different random matricies
15:05:11 <fog> i get many measures for the price of one random matrix now
15:05:25 <Cale> dolio: btw, I agree that LinearHaskell isn't a minor extension, that's one of my main complaints about it being merged into mainline GHC.
15:05:28 <dolio> The Yoneda lemma is important for many reasons, and one is that it tells you important things about the Yoneda embedding.
15:05:36 <fog> the buffer is large, and generating the random matrix is expensive and almost fills ram
15:05:53 <Cale> dolio: It's very heavy, and I doubt it will ever justify its own cost
15:05:54 <dolio> Cale: Yeah, that's another whole can of worms.
15:06:02 <hyiltiz> Yoneda embedding guarantees existence for fmaps between arbitrary types?
15:06:09 <fog> its good to be able to reuse it witout shuffling it, by shuffling the thing its being applied to instead
15:06:13 <dolio> Not even in the same league as GHC having dozens of syntactic extensions.
15:06:34 <fog> MarcelineVQ: sell that to the banks^
15:07:09 <fog> the random projections are used as inputs to a net
15:07:33 <fog> and are shaped with bias to the distribution they are drawn from, to capture "indicators"
15:07:47 <fog> which serves as an alternative to net training
15:07:56 <fog> *ALL THE IP*
15:08:19 <dolio> hyiltiz: The Yoneda embedding is an embedding from a category C to the category of presheaves on C. yA = Hom(-,A). Or it can be yA = Hom(A,-) depending on the situation you want to talk about.
15:08:33 <Cale> Yeah, there's two problems: one is just that there are lots of extensions that people have to know about, and the other is that particular extensions, even if they're "small" incur costs without really solving problems that make up for it.
15:08:42 <hseg> Cale: remind me why it isn't a plugin, again?
15:08:50 <dminuoso> dolio: I dont think tossing category theory lingo at someone not versed into CT is helpful :(
15:09:06 <Cale> hseg: I don't know, but it does seem much too deep to just be a plugin
15:09:10 <dolio> Well, it certainly doesn't help to use the wrong lingo, either.
15:09:15 <MarcelineVQ> No one ever told him ideas are cheap I guess, if he's that worried about them being heard.
15:09:30 <rom1504> ah he left now
15:09:40 <dminuoso> Not sure what you mean by wrong lingo *shrugs*
15:09:46 <Cale> hseg: LinearHaskell introduces a whole new kind of type level binder and polymorphism (it has multiplicity polymorphism)
15:09:47 <hseg> i thought the promise of the plugin system was that we could outsource all the heavy stuff
15:10:17 <Cale> Yeah, but I don't know that it's been all that useful outside of forcing certain optimisations to take place
15:10:38 <dolio> dminuoso: `forall r. (a -> r) -> f r` is not the Yoneda embedding.
15:10:40 <hyiltiz> So it seems as long as I understand "embedding" "category" "presheaves" "Hom" I should be able to understand "Yoneda embedding"
15:11:12 <rom1504> people in companies publish whole papers describing pretty much what's used in prod so indeed sharing a few ideas about matrix projection is unlikely to be a problem...
15:11:47 <MarcelineVQ> rom1504: I quite liked your idea btw
15:11:57 <rom1504> as long as he's not pasting his ssh private key, or priviledged information, I doubt he's taking much risk :)
15:12:08 <Cale> But yeah, RecordDotSyntax just makes a mess of the lexical syntax with almost no real upside, unless you're super-concerned about the exact textual form of certain identifiers in your code.
15:13:15 <monochrom> I have a more self-interest-oriented view. They're saying that they want your free help on their IP they plan to profit from.
15:13:16 <Cale> It's hard to disambiguate expressions that use it, to the point that there were a dozen or so different conflicting proposals about how various things should be interpreted
15:13:38 <Cale> and in the end, the committee did a ranked vote and picked the least hated one
15:14:04 <Cale> But that does nothing for anyone who is new to Haskell and trying to read code that uses this
15:14:31 <Cale> Even for people who are familiar, it's going to be annoying
15:16:47 <dolio> hyiltiz: Presheaves are functors `C^op -> Set` or similar. This is an important category because it inherits a lot of structure from Set. And the importance of the Yoneda lemma in this context is that `yA -> yB` = `forall r. (r -> A) -> (r -> B)`, and the yoneda lemma tells us this is the same as `A -> B`. So, there is an exact correspondence between arrows `yA -> yB` and arrows `A -> B`.
15:16:59 <monochrom> I have thought more about record dot syntax, I sympathesize with it a bit more. Preferably I still wish no change at all. But if a change must come, dot is less messy than my favourite, #. Because dot is already special in syntax, e.g., "X.y" is lexically or grammatically different from "x.y".
15:17:44 <dolio> Something similar would happen with the other embedding, where the rs go on the right.
15:18:13 <Cale> monochrom: I just disagree that this sort of change must come
15:18:26 <monochrom> Yeah me too.
15:18:42 <monochrom> But the unstoppable force of the mass.
15:18:44 <Cale> It's also super-unfortunate that '.' is already special
15:18:49 <dolio> Yeah, they really dropped the ball back in 98, strictly speaking. :)
15:19:01 <Cale> because it's also the name of the most important thing
15:19:04 <monochrom> See? This is why I say that "promote Haskell to everyone!" is a bad idea.
15:19:24 <fog> iv no problem with the people that help benefiting - but inevitably thats not what open source publication results in
15:19:25 <MarcelineVQ> avoid success something something? :>
15:19:31 <hseg> whatever happened to "avoid success at all costs"?
15:20:22 <Rembane> +1
15:20:37 <monochrom> You get the average OO-minded programmers to adopt Haskell, you get average OO-minded changes that ruin the language.
15:21:00 <monochrom> I guess it has failed? :)
15:21:29 <hyiltiz> dolio: I am reading that sentence as a mantra until it makes sense and sinks in
15:21:39 <Cale> I think part of it as well is that it used to be that almost the entire Haskell community was on the mailing list and IRC
15:22:06 <fog> how am i supposed to combine the IORefs and the Seq!?
15:22:07 <Cale> That's no longer true, there are all these islands of communication now forming their own consensus and culture
15:22:42 <fog> if i use memory adresses for the buffer, then its expensive to update, having to shift every value along one position, the exact thing the Seq avoided
15:23:05 <hyiltiz> dolio: that sentence seem awfully related to continuation passing modad, isn't it? 
15:23:59 <fog> i saw an example by a user ages ago, i think they called puncture, where it had basically a constructor for every different values replacement
15:24:19 <Rembane> Cale: Do these islands ever meet and discuss things in a friendly way? 
15:24:20 <hyiltiz> in the sense that the stored continuation can either be applied as A->B or applied as yA -> yB
15:24:58 <fog> Rembane: are you talking about Lilliputians?
15:26:05 <dolio> I don't think I said anything about continuation passing.
15:26:28 <Rembane> fog: Not in this case, but I do strongly believe that eggs should be cleaved in half. 
15:26:38 <fog> they should be used as qubits
15:26:47 <MarcelineVQ> fog: the proposed solution didn't need Seq or IORef. Arrays are pure (immutable) structures in haskell and if you're just querying them they're nice and effcicient. The idea, iiuc, was to have the permutations be a list of indices and then to simply look up each index in the array as you consume the list. index lookup is O(1) for an array.
15:27:04 <hyiltiz> dolio: no u didn't; I am (maybe mistakenly) trying to connect some conceptual dots
15:27:31 <fog> MarcelineVQ: oh!
15:27:32 <fog> thanks
15:28:26 <fog> so you have like a list of (!!n) and you map over it with (\f -> f xs)
15:28:36 <fog> and you just supply different xs
15:28:44 <dolio> There are connections, but it'd probably take a long time to explain, after I thought about how to explain it for a while.
15:28:47 <moet> why is PrintfType's implementation intentionally hidden? i'd really like to implement it for monadtrans or something, so that i can use it without annotateding String or `IO ()`
15:29:03 <Cale> Rembane: Well, of course there's interaction and cross pollenation of ideas, but I have the sense that what "normal Haskell" looks like to various people is much more varied than it used to be
15:29:03 <fog> i think the point was that while the lookup is fast, now i need to generate new xs, and i have *slow buffering*
15:29:14 <fog> Seq was being used for fast buffering
15:29:54 <dolio> Any short thing I could say would require a very long time to unpack.
15:30:46 <fog> the problem seems to be that i can either have fast buffering and slow lookup, or fast lookup and slow buffering
15:30:58 <hyiltiz> dolio: I cannot refrain from a joke "your last sentence is quite short; care to unpack?"
15:31:48 <hyiltiz> jokes aside, thx! so far, ur explanations have been direct and accessible, reminds me of Feynman
15:32:02 <monochrom> moet: I think it's the opposite. If you could implement PrintfType, many use sites would still need type annotations. Instead, if you write "liftIO (printf ...)", that nails the type to IO () and you need no further annotation.
15:32:09 <deech> How do I force cabal to rebuild a specific component of a package? With stack I would do 'stack clean package:component' followed by 'stack build'.
15:33:06 <fog> hyiltiz: have you heard of the "feynmans face" problem? about integrating over the infinite histories to allow for smooth interpolation between expressions?
15:33:43 <moet> monochrom: i have a context which is (MyMonad => m ()) and in a do-block there I'd like to be able to call `myMon $ printf ...` but since `myMon` is polymorphic in its argument, this is requiring that i specify the return type of `printf` like `myMon (printf ... :: String)`
15:33:46 <MarcelineVQ> fog: I don't know what buffering is here when you say it, but generally that's the crux of computing, we can have pretty fast static things or slower arbitrary things. Seq does a pretty good job of the latter. Lookup in an array vs lookup in a binary search tree are examples of each.
15:33:54 <fog> i think it was one of the earliest versions of the manifold learning problem
15:34:05 <fog> c.f. eigenfaces of Saul et al
15:34:14 <moet> monochrom: so my thought was to extend `PrintfType` to provide a function `myMonf` which takes the printf args
15:34:17 <hyiltiz> fog: Nope; care to elaborate/point me to places?
15:34:56 <fog> https://cs.nyu.edu/~roweis/lle/papers/lleintro.pdf
15:35:03 <moet> monochrom: since that isn't possible, it seems the best runner-up i can do is to provide `myMonS` of type `MyMonad m => String -> m ..`
15:35:09 <MarcelineVQ> even lookup in an array is really more like BST lookup because memory isn't really flat
15:35:11 <Guest63907> Rembane: that's a good question (about the islands meeting for discussions). Conferences are one of the ways that happens and I guess there are some, but it kind of feels like Haskell could do with more and bigger ones, OOPSLA-like
15:35:49 <Guest63907> now in covid time we have Haskell Love coming up, but it's only two days and remote. Should be good though. Aug 31-July 1 IIRC
15:36:01 <fog> "Locally linear embedding" - basically you use the kernal trick, with a linear approximation that allows a point to be represented as a sum over its nearest neighbours in a reproducing kernal hilbert space 
15:36:14 <hyiltiz> what reminded fog about feynmans face prob.? talking about feynman, expressions, or embedding?
15:36:22 <fog> something to do with mercer kernals and representer theorem
15:36:46 <hyiltiz> seems hardly relevant to the Yoneda topic to me
15:36:47 <monochrom> > let {f :: String -> Int; f x = length x} in f (printf "%d" 50)
15:36:49 <lambdabot>  2
15:36:52 <monochrom> Like that?
15:37:02 <Rembane> Cale: I agree, I think there are at least three "dialects" of normal Haskell by now. 
15:37:07 <fog> idk, its either that or him manically playing bongos shouting "orange juice" 
15:37:31 <hyiltiz> oh wait representer theorem in linear algebra/optimization is the same as the representer theorem in CT aka yoneda?!?
15:37:49 <Rembane> Guest63907: Yes, conferences are good. I'll check out Haskell Love. 
15:37:53 <hyiltiz> s/same/isomorphic/
15:37:59 <moet> monochrom: yeah, kinda like that.. i fix string type in a wrapper around my monad function
15:38:30 <fog> well, im sure there is a categorical interpretation. but im not sure quite how the naturality diagram works for dimensionality reduction...
15:38:50 <moet> monochrom: i'd rather just call the printf internally by making my monad compatible with it, but since PrintfType's internals aren't exported, that's not possible
15:39:13 <Guest63907> Cardano recently did one ("Virtual Summit") that was very effective
15:39:17 <moet> monochrom: specifically PrintfType(spr) isn't exported, even though it has a trivial implementation in my monad
15:39:29 <monochrom> Yeah OK.
15:39:49 <moet> so kinda just wondering why the authors of `base` decided not to export it
15:39:49 <fog> MarcelineVQ: here is how i was doing buffering; with lists for simplicity https://pastebin.com/raw/JtnK0WT5
15:40:04 <moet> or maybe if there's another way to do what i'm after
15:40:53 <hyiltiz> fog: should there be only one natural map for dimentionality reduction? For a fixed matrix M mapping from X to Y, that matrix itself is the "natural" map?
15:41:38 <fog> "we can have pretty fast static things or slower arbitrary things". right, so i wanted to use the "structure" (not arbitrary) of the permutations
15:42:45 <fog> hyiltiz: generally you wouldnt be using a matrix. the "locally linear" is not that kind of linearity, its more like assuming the curved manifold being interpolated over can be fitted by linear (flat) regions 
15:43:16 <fog> s/flat/not curved
15:43:27 <fog> as opposed to constant 
15:44:27 <fog> idk, you were suggesting there was something about representer theorem common between category theiry and reproducing kernal hilbert spaces
15:44:33 <fog> which i cant really see
15:45:43 <fog> actually, the best work i have seen on the topic of manifold learning is "generative denoising autoencoders" 
15:46:06 <fog> Bengio et al.
15:46:32 <fog> https://papers.nips.cc/paper/5023-generalized-denoising-auto-encoders-as-generative-models.pdf
15:48:56 <hyiltiz> fog: a lot of my brain plasticity is being used up right now; I just presented that paper in a lab meeting a few months ago. 
15:48:58 <fog> ah no, thats not the good paper, its;
15:48:59 <fog> Deep Generative Stochastic Networks Trainable by Backprop
15:49:04 <fog> http://proceedings.mlr.press/v32/bengio14.pdf
15:50:10 <fog> "to correct the noised up inputs, it has to disentangle the features at the bottleneck"
15:50:17 <fog> quote me, now
15:51:01 <fog> the bengio team says that more like "to prevent it from learning the identity" 
15:51:08 <koz_> :t curry
15:51:10 <lambdabot> ((a, b) -> c) -> a -> b -> c
15:51:49 <hyiltiz> But I was given an impression that CT is pretty much non-applicable to machine learning/AI (so I can get away like my collageus by not learning it)?
15:52:23 <hyiltiz> Guess I'll grab a proper textbook on CT as my next read
15:52:34 <monochrom> I agree with that impression.
15:52:35 <fog> and then there was some stuff to do with regularization, such as noisy relus... which performs implicit marginalisation by the regularized loss function
15:52:39 <hyiltiz> and stop wasting people's time here with noob questions
15:53:26 <dminuoso> hyiltiz: You should study CT only if you have some personal interest in learning CT. For some it can be a valuable tool, but largely the time investment seems dispropotional to the benefits you gain in programming.
15:53:54 <MarcelineVQ> CT is the perfect tool for talking to people that know CT, but english can get you pretty far too
15:54:08 <fog> well, if you wanted to get at the categorical discription you should basically retrive the baysean reconstruction of the hidden model
15:54:39 <monochrom> When I relate to most people about x+y=y+x, I definitely don't bring up ring theory.
15:54:52 <hyiltiz> hmm, so both dminuoso, monochrom and MarcelineVQ are all suggesting CT can be a good hobby but not a good investment for ML research (or applications) in particular?
15:55:03 <monochrom> Right.
15:55:07 <MarcelineVQ> fog: the only gets you the emergent categorical analoge, you need a convergent prelog apropos of the aluvial templating model
15:55:21 <monochrom> But I know nothing about ML.
15:55:53 <MarcelineVQ> hyiltiz: currently yes, it's certainly applicable in that CT can model both graphs and computation but that's not the state of research afaik
15:56:02 <MarcelineVQ> *of ML research
15:56:04 <fog> basically, if you add noise, the DAE will "pinch it back onto the manifold" but, in the direction normal to the manifold. they prove the ergodicity of this as a markov chain, so that it sppraoches the hidden distribution as it covers the manifold by alternating steps of adding noise and having the DAE pinch it back to the manifold
15:56:12 <hyiltiz> No wonder my advisor keeps advising against me picking up any modern math stuff since they are by and large irrelevant
15:56:53 <monochrom> CT is also too broad.
15:57:10 <MarcelineVQ> intentionally :>
15:57:15 <fog> all your ever really trying to do is prove the observer of the distribution, with the estimated parameters, converges to the hidden generative model
15:57:17 <moet> syntax/conventions question: what's the best way to deal with code marching to the right for use of several nested `withBlah` or `bracket` invocations? in my case, they're doing some other things before/after and so i'm not able to just compose `withBlah . bracket ac rel . withFoo`
15:57:23 <monochrom> No, I mean many topics and many theorems.
15:57:48 <monochrom> You will find a few relevant to you, and the rest not.
15:57:59 <fog> i cant imagine a naturality square for that, so i dont see how yoneda is relavent 
15:58:22 <MarcelineVQ> fog: there's been research into inverting the model state to essentially render hidden generatives into into permeable abductions
15:59:03 <fog> but the aliens dont commute 
15:59:06 <MarcelineVQ> related the square becomes a diamond, but only in bayesian departments
15:59:20 <monochrom> For example, there are a few catster videos that could put a few common FP idioms in new light. And the rest, pretty much unrelated.
15:59:45 <Cale> Category theory can be very useful if you're going into a new area of research and you're uncertain about what the right definitions ought to be. If all you're interested in is getting programs written, I'd say avoid it -- you can get all the advantages of CT from libraries of abstractions that others have already written, and which only really solve a problem for how to structure things once in a blue moon as it is.
16:00:34 <fog> i think the svd of the canonical variate analysis approach seems almost industry standard 
16:00:34 <Cale> But if you have a broader interest in mathematics, category theory can be extremely valuable just in terms of providing a global perspective on how to think about different areas and the relationships between them.
16:01:02 <moet> lifting/transformers question: what do folks recommend when writing code using lots of bracket? "running" your monad stack in the `IO a` bound bracket? or using one of the "lifted brackets" in `exceptions`, `lifted-base`, `unliftio`?
16:01:14 <fog> i think it manages to do numerically what is analytically tractable from hierarchical KAM corrections
16:01:27 <hyiltiz> I am interested math in general, but not sure if it is broad enough to require CT
16:01:55 <monochrom> I don't learn CT for applications. I learn CT for perspectives. (As usual, when you let go of applications, you will get some good ones.)
16:02:16 <Cale> moet: Start with the former. If you need an abstraction, use the one which is specific to the meaning of the operation -- 'exceptions' would be the thing in this case.
16:02:40 <hyiltiz> I don't learn Haskell for applications. I learn Haskell for perspectives. (As usual, when you let go of applications, you will get some good ones.)
16:02:50 <hyiltiz> That was one of the reasons I've picked up Haskell
16:02:51 <monochrom> :)
16:02:56 <fog> MarcelineVQ: yeah, i guess if you have an inverse you could build it into a kalman filter. but i never saw a CT exposition 
16:03:39 <hyiltiz> gtg afk for a bit; discussing CT doesn't seem to provide applicative merits relevant to s/lunch/dinner/
16:04:30 <Cale> moet: I think the unliftio/MonadBaseControl/MonadTransControl sort of stuff is actively harmful in a bunch of ways. You can't write instances of that and know that they always are going to be the right thing for every higher order function someone's going to plug in.
16:04:58 <Cale> So it becomes a bit of a game of "here's a random thing which typechecks, let's see if it works"
16:05:10 <fog> hyiltiz: whats more important, dinner, or SCIENCE!?
16:05:11 <Cale> Much better to have classes for each operation.
16:05:54 <monochrom> Dinner is more important. And wine.
16:06:09 <fog> are we still allowed to go "computer says no" since they banned little britan? 
16:06:26 <monochrom> Do you want to know the nickname I gave to wine?  desugared grape juice.
16:06:50 <Clint> :|
16:07:34 <monochrom> do { x <- m; y } = wine m (\x -> y)  heh heh
16:08:26 <moet> Cale: yeah.. that's exactly how i feel as well (except, i'm not very confident in my conclusion that i lack confidence in a lot of that stuff)
16:08:28 <fog> % foldr (>>=) (>>=) >>= repeat (>>=)
16:08:28 <yahb> fog: ; <interactive>:188:23: error:; * Couldn't match expected type `((m b -> m b) -> (m b -> m b) -> m b) -> t ((m b -> m b) -> m b -> m b) -> b1' with actual type `[m0 a0 -> (a0 -> m0 b0) -> m0 b0]'; * Possible cause: `repeat' is applied to too many arguments; In the second argument of `(>>=)', namely `repeat (>>=)'; In the expression: foldr (>>=) (>>=) >>= repeat (>>=); In an equ
16:09:29 <monochrom> I tell you a true story of how I used CT to work out something that does not need CT to work out. :)
16:09:58 <monochrom> I was wondering how to write >>= or join for "data P a = P a a".
16:10:46 <monochrom> So I went: P is the composition of an adjoint functor pair, I know the formulas from CT for this, let me work it out that way!
16:11:30 <monochrom> An hour later, it goes: join (P (P x _) (P _ y)) = P x y
16:11:42 <koz_> LOL
16:11:53 <koz_> Ant, meet flamethrower.
16:12:09 <monochrom> I told this to #haskell. Someone ruined it all by: dude, P = (->) Bool, just use the ((->) e) monad instance.
16:12:53 <monochrom> This teaches you to not learn CT, you don't need it, there is always an easier way, 1000x faster.
16:15:30 <dminuoso> moet: Im a big fan of unliftio, where non-trivial effects are just local, globally I just keep ReaderT/LoggingT around. :)
16:16:28 <dminuoso> moet: Main reason is sooner or later I end up using things that end up with IO in negative position anyways.
16:16:52 <dminuoso> (And then you have no restrictions over where you want bracket, if you start with IO outside it means that's the only place you can catch exceptions)
16:17:25 <Cale> For some ReaderT's I think unliftio is pretty much guaranteed to be okay, for LoggingT, I'm already not sure.
16:17:45 <Cale> and I know there are cases where even just for ReaderT, you can end up in trouble
16:18:02 <dminuoso> Cale: are you hinting at ResourceT?
16:18:57 <Cale> One particular class of example I'm thinking about is ReaderTs which carry around references to IO-related stuff that isn't okay to access from more than one thread
16:19:11 <dminuoso> Sure, but that's unliftio unrelated.
16:19:21 <dminuoso> That's inherent to ReaderT in general. 
16:19:47 <Cale> I mean, it's a case where the unliftio instance for ReaderT is going to be inappropriate to have
16:19:57 <Cale> but you can't just get rid of the instance situationally
16:20:30 <hyiltiz> forell:  (talking about) Science over a scientific(ly prepared) dinner :p
16:20:50 <hyiltiz> hmm s/forell/fog/
16:21:17 <dminuoso> Cale: Mind my asking, how's that related to unliftio?
16:21:24 <moet> storing a reference and using it in a non-thredasafe way doesn't strike me as a ReaderT problem...
16:21:32 <dminuoso> I mean if you have mutable references in your environment, then *threading* is already problematic.
16:22:12 <moet> maybe this is a problem of mixing the usually-pure world of monad transformers with the facts of the impure world which includes threading..
16:22:16 <Cale> Because it helps people blindly do things which aren't safe, without knowing that's what's happening
16:22:31 <Cale> If a function has a MonadUnliftIO constraint on the monad
16:22:40 <Cale> I have no idea if it's going to fork a thread
16:23:06 <dminuoso> Equivalently, if it has a MonadIO constraint on the monad you have no idea if its going to launch a missile.
16:23:10 <Cale> If it had a MonadForkIO constraint, I'd at least be warned
16:23:16 <dminuoso> I can see what you're saying, but I dont think it's a real issue.
16:23:33 <Cale> It's a real issue, has come up a bunch in our projects at various points
16:24:19 <dminuoso> Cale: Do you have a blog?
16:24:23 <Cale> nope
16:24:31 <dminuoso> sad, I'd definitely like to see a story about this
16:24:57 <dminuoso> It's a bit hard to imagine how you can get into troubles
16:25:02 <moet> hrm.. ok, this has been helpful.. i like the idea of mtl-style constraints that call out the exact effects they allow and no more, but that's a boil-the-ocean sort of thing
16:25:30 <Cale> moet: It can get really annoying, but then you can also logically group them a lot of the time
16:25:57 <dminuoso> And then the inliner stops doing its job because its not seeing foldings, your program performance went down its drain...
16:26:10 <dminuoso> And then you want to talk about the "ordering of effects"
16:26:32 <Cale> Ah, yeah, we have -fexpose-all-unfoldings turned on everywhere
16:26:33 <dminuoso> It all ends up with long discussoins and dreams about better effect systems in reddit/irc/mailing lists.
16:26:37 <Cale> At the build-system level
16:26:52 <dminuoso> Cale: How badly has it affected your build times and memory consumption?
16:27:05 <Cale> Not enough to turn it back off
16:27:09 <dolio> 'How do I write this one function' seems like a really unrepresentative example of what category theory is useful for.
16:28:39 <Cale> dminuoso: It's hard to recall exactly, since it got wired in at a low level in our nix (intentionally making it hard for people to accidentally disable), and our entire Haskell ecosystem is built with that flag on.
16:38:49 * hackage hackport 0.6.6 - Hackage and Portage integration tool  https://hackage.haskell.org/package/hackport-0.6.6 (solpeth)
17:29:44 <moet> looking at warp and have a couple of questions..
17:29:56 <koz_> If I have foo :: Prism' s a and bar :: Prism' s b, how can I mash them together to get an optic which misses if either of foo, bar miss, and otherwise gives Just (a, b)?
17:30:50 <moet> why does `runSettings` call `setSocketCloseOnExec` just before calling `runSettingsSocket`? is this a security thing? (ie. if an attacker broke in and tried to exec bash, the socket would sever the connection)
17:48:39 <xsperry> :t mapM
17:48:41 <lambdabot> (Traversable t, Monad m) => (a -> m b) -> t a -> m (t b)
17:49:11 <xsperry> a bit annoying that there's no visible Traversable constraint on hackage https://hackage.haskell.org/package/base-4.14.0.0/docs/Data-Traversable.html#v:mapM
17:49:49 <haskell_noob> hello just wandering what does the -> operator do in [x | x <- xs, x `mod` p /= 0]
17:49:59 <haskell_noob> <-*
17:50:17 <solonarv> haskell_noob: it isn't an operator, it is part of the syntax for list comprehensions
17:50:36 <solonarv> I suggest you look up that term for a more thorough explanation
17:50:47 <haskell_noob> doing that now thanks
17:52:01 <Axman6> you can read that as: "Produce x, where x is drawn from xs, and x `mod` p is zero"
17:52:29 <solonarv> koz_: I can't seem to find a combinator for this
17:52:57 <solonarv> are you sure your arguments are Prisms? if yes then that combinator seems extremely pointless
17:53:12 <moet> re, my earlier question about sockets: it has to do with preventing leaks to subprocesses
17:54:00 <solonarv> prisms (with the same "source" type) are typically disjoint or equal
17:54:31 <Axman6> koz_: so you want Prism' s a -> Prism' s b -> Prism' s (a,b) yeah?
17:54:50 <koz_> Axman6: It won't be a Prism'.
17:55:03 <Axman6> roughly
17:55:06 <koz_> It'd be an AffineTraversal' at best, I think.
17:55:08 <koz_> But yes.
17:55:30 <koz_> solonarv: Argh, you're right.
17:55:39 <koz_> They're actually AffineTraversal's.
17:56:12 <koz_> So I actually want 'AffineTraversal' s a -> AffineTraversal' s b -> AffineTraversal' s (a, b)'
17:56:16 <koz_> Or near enough.
17:56:38 <ski> s/zero/non-zero/
17:57:24 <solonarv> hm
17:57:57 <solonarv> obviously you could handwrite it
17:58:30 <koz_> solonarv: Naturally. I was just wondering if it already existed.
18:02:06 <Axman6> :Rage: you can't scroll the results in the quick search on hackage
18:38:33 <crestfallen> hi at the bottom of this paste there is an evaluation of a function called tick. A member provided me with the eval to illustrate what is happening in the state monad. I have a question re: the first and second lines of the eval.  http://ix.io/2spR    ...
18:39:00 <Cale> What's the question?
18:39:29 <crestfallen> in (put (V+1)) s'   ..
18:39:34 <Cale> Also, while those equations are true, that's not what will ever happen in the evaluator
18:39:47 <Cale> because the evaluator never touches anything in the body of a lambda
18:40:28 <crestfallen> on line one we have s' , then on the second line we go to s . so we obtain s from the get function, that I see..
18:41:23 <crestfallen> so is that just a convention to show that s' is actually s from the get func? 
18:41:43 <Cale> s and s' are just different variables. They both refer to particular states.
18:41:45 <crestfallen> I would think the () would carry over to s' in the second line
18:45:16 <monochrom> Perhaps you just need this intermediate step: runState get s = (s, s)
18:45:43 <crestfallen> in other words s' loses its prime and is s again. it seems that notation is working backwards
18:46:01 <monochrom> To be sure, that equation could also need its own finer steps. I'm moving fast.
18:46:19 * hackage ats-pkg 3.5.0.1 - A build tool for ATS  https://hackage.haskell.org/package/ats-pkg-3.5.0.1 (vmchale)
18:46:31 <crestfallen> monochrom: kindly illustate
18:46:56 <monochrom> Exercise for you.
18:47:34 <crestfallen> well, runState get s = (s,s) I just keep in my head while going through the evaluation
18:48:18 <monochrom> No, you are not supposed to keep that in head.
18:48:44 <monochrom> You are supposed to go to the big calculation and replace "runState get s" by "(s, s)".
18:49:07 <crestfallen> ok one moment pls
18:49:11 <monochrom> So that when you zoom out you see "let (s',v) = (s,s) in ..."
18:50:01 <crestfallen> right so its just substitution where runState get s   is
18:50:58 <crestfallen> S (\s -> let (s', v) = (s,s) in runState (put (v+1)) s')
18:52:24 <crestfallen> it's just that I would think the s' notation would carry to the next line. 
18:52:45 <crestfallen> even though we are dealing with ()
18:53:38 <crestfallen> disregard that last post , I think its incorrect.
18:53:40 <monochrom> Many years ago you learned that "let (s', v) = (x, y) in foo s' bar v" means you can replace s' by x, v by y now, "foo x bar y". Please use that knowledge, please.
18:53:49 * hackage prometheus-client 1.0.1 - Haskell client library for http://prometheus.io.  https://hackage.haskell.org/package/prometheus-client-1.0.1 (fimad)
18:54:48 * hackage prometheus-metrics-ghc 1.0.1.1 - Metrics exposing GHC runtime information for use with prometheus-client.  https://hackage.haskell.org/package/prometheus-metrics-ghc-1.0.1.1 (fimad)
18:55:44 <crestfallen> ok so you're treating s' as x by the second line, which is still s from our get function's return value (s,s), correct monochrom ?
18:58:14 <monochrom> yes
19:00:17 <crestfallen> ...
19:01:27 <monochrom> what, you expect "no"?
19:02:31 <crestfallen> I'm trying to figure out what happenned to our field for () on the second line monochrom 
19:04:15 <crestfallen> why doesn't the () get included from the first line, such as    tick = S (\s -> let (s', v) = runState get s in runState (put (v+1), ()) s')
19:05:53 <crestfallen> correction
19:06:20 <crestfallen> why doesn't the () get included from the first line, such as    tick = S (\s -> let (s', v) = runState get s in runState (put ((v+1), ()) s')
19:10:53 <crestfallen> so in the let/in statement we have only  ' ...  in runState (f v) s')    '
19:14:10 <crestfallen> my question involves the convention(s) in writing out an evalution like this; I hope that is where my misunderstanding lies. 
19:17:48 <crestfallen> monochrom I get it now. thanks kindly for your help. the () value only appears when the wrapper S (\s -> (s+1, ())) s)   is substituted on the 3rd line. is that correct monochrom ? 
19:23:48 <crestfallen> Cale is that a correct statement?   ^
19:29:23 <Cale> I'm not sure I understand the question. The () is the result of the original put, and so it's also the result of tick
19:47:59 <crestfallen> Cale: thanks. yes it's basic substitution and I see how it was arrived at. really appreciate it, I'm getting State finally...
19:57:19 <mniip> odd question but, is there a way to relax version bounds with Distribution.Simple ?
20:01:27 <mniip> like I can say `cabal configure --allow-newer=base` but I can't say `runhaskell Setup.hs configure --allow-newer=base`
20:03:48 * hackage http-common 0.8.2.1 - Common types for HTTP clients and servers  https://hackage.haskell.org/package/http-common-0.8.2.1 (AndrewCowie)
21:11:19 * hackage http-streams 0.8.7.2 - An HTTP client using io-streams  https://hackage.haskell.org/package/http-streams-0.8.7.2 (AndrewCowie)
21:55:08 <jtm> I ran into a glitch in Haskell on Windows. I'm not sure of the workaround: https://pastebin.com/5eL3pPgN
21:55:37 <jtm> If I run this and enter a digit, it is fine, but if I do it again it'll print out "ERROR: Invalid digit"
21:56:17 <jtm> But I do believe it still reads the character despite printing out the error...
21:56:34 <Axman6> maybe change yout error to: putStrLn $ "ERROR: Invalid digit: " ++ show x
21:56:57 <Axman6> it might be reading the newline
21:57:24 <jtm> I think it's because Windows does \r\n
21:57:37 <jtm> https://pastebin.com/FjwjCmTm
21:57:45 <jtm> I'll try your suggestion in the meantime
21:58:20 <Axman6> I think it's because x is a '\n' or '\r'
21:58:29 <jtm> yeah, that is the reason
21:58:35 <jtm> It outputs \n using your code
21:59:16 <jtm> It shouldn't be reading this \n though...
22:00:46 <jtm> I know this code should work, and my guess is this is a Windows issue.
22:05:01 <jtm> Using getLine and indexing into 0 seems to fix it
22:05:08 <jtm> But I should be able to use getChar...
22:15:58 <Axman6> getChar will just return the next Char decoded from stdin, which is the \n
22:16:43 <jtm> I seemed to have fixed it by adding y <- getChar under the x <- getChar
22:17:50 <jtm> However if I accidentally put int "10" instead of 1-9, it will overflow into the y forcing the \n not to save into the y
22:18:00 <jtm> but rather 0 to save into the y
22:18:12 <jtm> And somehow x becomes \n again
22:19:21 <jtm> I'm pretty sure this is due to some buffering
22:19:39 <Axman6> you seem to be expecting the OS to drop input without you telling it to
22:19:41 <jtm> Where it is buffering the characters and reading them later on when it runs again
22:20:04 <Axman6> it seems to be lthat what is happening is exactly what you would expect when asking for one char at a time from stdin
22:20:06 <Cale> There's an input buffer. Are you pressing Enter after entering your first digit?
22:20:12 <jtm> Yes I have to press Enter
22:20:27 <Cale> You can turn off the input buffer with hSetBuffering stdin NoBuffering
22:20:30 <Axman6> stdin is a file. you read its contents from the front
22:20:53 <Cale> and that should also mean that you don't have to press Enter (default is LineBuffering)
22:21:34 <jtm> Cale, that doesn't work, it still buffers.
22:21:38 <jtm> I think it's a Windows issue
22:21:51 <jtm> or GHCi isn't letting me change the mode
22:22:15 <Cale> What does your code look like now?
22:22:36 <jtm> https://pastebin.com/iaKvGzec
22:22:51 <jtm> I shouldn't have to press Enter, pressing a digit should be ample to store the digit.
22:23:15 <jtm> I added the appropriate System.IO import.
22:25:22 <jtm> This seems to be a well-known bug. I am just not really sure of a workaround without using some third party package, etc.
22:27:34 <Cale> Weird, yeah, there's a GHC bug for this
22:27:39 <Cale> https://gitlab.haskell.org/ghc/ghc/-/issues/2189
22:27:51 <Cale> Surprised I hadn't heard of it before
22:27:54 <jtm> I tried the workaround, but it's also buggy as it results in hidden characters etc
22:27:58 <Cale> It's been around quite a while
22:28:44 <jtm> Yeah
22:28:56 <jtm> Seems using getLine and indexing into 0 works the best
22:29:20 <jtm> Obviously not the best solution
22:29:43 <Cale> Oh, which version of GHC are you using?
22:30:38 <Cale> Apparently a change that went into 8.10.1 fixes the issue on native Windows terminals, but not msys terminals
22:30:46 <Cale> https://gitlab.haskell.org/ghc/ghc/-/merge_requests/1224
22:31:10 <jtm> msys terminals, is that Powershell?
22:31:15 <jtm> I'm using Powershell
22:31:24 <Cale> msys is mingw, I think
22:31:38 <jtm> I'm using 8.10.1
22:32:41 <jtm> The issue exists within cmd.exe as well
22:33:09 <jtm> I'm using Windows 7.
22:33:16 <jtm> So I can't use WSL 1/2.
22:33:28 <jtm> Maybe I'll migrate to some virtual machine setup :-/
22:33:44 <Cale> Oh wait, did this get in...
22:33:49 <Cale> Maybe it didn't
22:34:07 <ja> but it was listed in the list of fixed bugs in the annuoncement
22:34:19 <ja> might be fun to test master or something jtm?
22:35:05 <jtm> I can try that.
22:35:13 <ja> oh weird, it is not listed here: https://mail.haskell.org/pipermail/ghc-devs/2020-July/019053.html
22:35:44 <ja> oh, yes it is! i was looking for the MR number, not the bug number
22:37:18 <ja> aaaah now i see what Cale was referring to, in the bottom of the MR description
22:38:11 <Cale> ah, and that post you linked is for 8.12, which is not out yet
22:38:26 <Cale> (and will apparently be 9.0)
22:38:39 <ja> yes, that is why i said master. it was just merged just over a week ago, the mailing list post is the merge announcement
22:38:43 <jtm> So I should just wait until 9.0 (or 8.12) for this to be hopefully resolved?
22:38:57 <jtm> I'm not sure how to compile the master for a Windows build.
22:39:01 <Cale> Yeah, I guess, and until then, maybe just use getLine :P
22:39:23 <jtm> It looks simple to do for *nix, but if I'm doing that that sort of defeats the purpose here.
22:39:49 <jtm> yeah getLine seems to work well, it's not perfect per se, but I'm just learning Haskell :)
22:41:18 <jtm> So it's not like I require getChar, I understand what it does, when I press say: 5, it immediately saves it into the x (for example), and that's it. But in this current build you need to press enter, which then results in the enter going into the buffer.
22:42:06 <jtm> And I can't disable the buffering (due to the bug in this current build).
22:42:47 <ja> not just the latest release, but all releases for the past 12 years :P
22:42:50 <jtm> "in this current build you need to press enter", I mean I need to press it BECAUSE of the bug.
22:43:24 <jtm> Yeah that's a big WIP, they've been working on this for over 3 years.
22:43:27 <jtm> So it's pretty exciting :)
22:44:33 <Cale> Yeah, it seems like a bug that probably had a more straightforward possible fix, but has been swept up in a major revision of how I/O is handled on Windows.
22:45:37 <jtm> Yeah, they were discussing some thread changes etc. I mean I don't understand exactly what is being changed and why, but I do know it is related to how I/O is handled in Windows.
22:46:21 <jtm> Thank you guys for looking into the bug, I'll just deal with it for now, if I plan to use Haskell for anything serious I wouldn't be doing it in Windows anyway so it doesn't impact me.
22:55:40 <sshine> when using 'cabal build', if a project depends on some version of GHC, how do you best make the GHC in your PATH be the one that it depends on? (as you can hear, I drank the Stack koolaid and am now terribly unhelpful.)
22:57:37 <Cale> sshine: I use nix-shell to enter a shell with the version of GHC that I want to use ;)
22:58:06 <Cale> (and the appropriate packages)
22:58:32 <ja> you could use --with-ghc= right?
22:58:53 <sshine> Cale, ah!
22:59:03 <sshine> ja, I'll try that first. :)
22:59:10 <ja> but afaik cabal is not really designed for multiple versions of ghc in mind
22:59:31 <ja> i got the impression that it is a lot of the motivation for stack
23:00:15 <ja> overriding just ghc makes me nervous, because what about hsc2hs and alex and happy and ...
23:00:35 <Cale> Well, nix also solves that problem
23:01:10 <Cale> but yeah, kind of a heavyweight solution
23:01:37 <sshine> yeah, the only reason why I didn't bother to learn nix is because I've never put any Haskell code into production yet, and Stack works pretty fine in my terminal. but I'd definitely rather use nix for deploying. :)
23:01:43 <Cale> I have a script containing:  nix-shell -p "(import <nixpkgs> {}).haskell.packages.ghc865.ghcWithPackages (pkgs: with pkgs; [ $* ])"
23:02:16 <Cale> and if I run that on the commandline with a bunch of haskell package names as arguments, it'll drop me into a shell with ghc 8.6.5 and those packages
23:02:31 <ja> btw i think the flag is called --with-compiler
23:02:54 <Cale> It's easily possible to choose a different ghc as you can probably tell by looking at that scrap of nix code
23:02:55 <sshine> ja, yes thanks.
23:03:13 <sshine> Cale, how do you feed it the package names?
23:03:23 <ja> oh that's a neat oneliner
23:03:26 <Cale> just as commandline args
23:03:27 <maier> I remember seeing a blog post about how it's not optimal to have one large module "Types" in your packages, but can't find it anymore. Do you happen to know something like it, or in general arguments for and against it?
23:03:30 <ja> the $* uses bash right?
23:03:47 <Cale> The $* interpolates the commandline args into that string
23:03:53 <Cale> yeah
23:04:30 <ja> you got lucky that nix list syntax is that same as bash ;)
23:04:36 <Cale> yeah
23:04:37 <Cale> haha
23:04:56 <maier> My gut always clenches when I see it because it at least forces so many recompiles on changes, and because you don't see any clear dependencies in your code/imports/modules. But I'm still quite new to Haskell and don't have a good intuition yet.
23:04:58 <Cale> I should also work out something which drops me into the env that callCabal2nix would have produced for building a package, that I can pass a .cabal file to
23:05:08 <sshine> maier, sounds like a Matt Parsons blog post. https://www.parsonsmatt.org/2019/11/27/keeping_compilation_fast.html ?
23:05:55 <Cale> maier: It's something which nonetheless often happens to sort out what would otherwise be mutually recursive module dependencies
23:06:22 <sshine> maier, you can of course avoid a Types megamodule, but you can also wait with dealing with this type of problem when compilation times actually begin to bother you.
23:07:10 <Cale> maier: But smaller solutions might be better -- it's not necessary to put *all* the type definitions in one big module, but it often makes sense to put types and their relevant instances in individual modules
23:07:46 <sshine> maier, I like to isolate types into libraries because they're easier to extract and put in their own module. I've had (wanted) to do that for even small projects because types can be a really nice thing to share between small projects that have the same domain in common.
23:07:56 <sshine> s/libraries/modules/
23:08:04 <Cale> In general, you should try to keep the amount of code in any one module down... there are a bunch of things in GHC which are not exactly linear in the size of the module being compiled
23:08:06 <sshine> s/module/package/
23:08:43 <maier> Cale: sshine: yes, that's the post, thanks! I tend to favor the method of keeping types with their "canonical" usage, thinking about "who should export this/whom does it belong to", and when I really can't help a circular dependency I factor out the types into their own module.
23:10:07 <maier> sshine: do you then have something like "Project.Foo" and "Project.Foo.Types", or try to find/define an own module name for the types that's closer to their domain?
23:11:57 <maier> another thing I like about having some types in the module that they "belong to" is that I can encode their meaning with using the namespaces, say Project.Authorization.Token instead of having a type AuthorizationToken. Ofc that kind of "forces" me to use qualified imports nearly all the way (which I like though)
23:15:19 <sshine> maier, I only have one example of this where the name of the project is 'evm-opcodes' and the parent project is a compiler with an unrelated name. so I'd always go for meaningful names. :)
23:16:20 <sshine> yeah, I haven't fully converged towards one style of imports yet.
23:17:38 <sshine> I do qualified imports of standard libraries and unqualified imports of locally related modules and in some other cases like tests.
23:17:54 <sureyeaah> Cale can you elaborate more on the things in GHC that aren't linear with the size of the module?
23:18:36 <sshine> sureyeaah, compilation time and memory use?
23:19:08 <Cale> Yeah, pretty much both of those things, haha
23:19:32 <sureyeaah> sshine yeah I get that but what i meant to ask was the reasons behind that.
23:19:54 <sshine> sureyeaah, whole-program optimizing compilers (like http://mlton.org/) are terribly slow, so GHC optimizes per... uh, compilation unit? (I'm not sure what the division is called.) so you get a natural slowdown when those grow.
23:22:32 <sureyeaah> sshine okay makes sense
23:22:34 <mniip> GHC can optimize between modules
23:23:17 <mniip> it stores definitions of small (c.f. INLINABLE pragma) functions in interface files, and can use those to do optimizations in other modules that use these functions
23:23:21 <sshine> sureyeaah, the combination of optimizing passes isn't linear in the size of the code. :) so if the running time f(x) is superlinear, then f(x+y+z) > f(x) + f(y) + f(z).
23:24:14 <sshine> mniip, oh right. so it's not either-or.
23:25:04 <mniip> fortunately, in functional programming, inlining and CSE (inlining^-1) are the only optimizations known to man
23:25:39 <ja> aww that's sad
23:25:56 <sshine> sureyeaah, if you're curious about measuring performance, Alexis King's "Effects for Less" talk at ZuriHac this year was a good intro to benchmarks. https://www.youtube.com/watch?v=0jI-AlWEwYI
23:27:19 <koz_> Yeah, that talk is excellent for many reasons.
23:27:24 <sshine> yes :)
23:27:25 <koz_> Lots of useful and insightful stuff there.
23:27:30 <dolio> There are many optimizations other than inlining and cse.
23:27:34 <ja> i was always dreaming of a way to tell the compiler "use this if you prefer CPU usage, use this if you prefer  memory usage, and here is how much they consume "
23:28:13 <sshine> ja, I was always dreaming of a compiler that makes this decision for me.
23:28:37 <ja> but then you need to prove they are total and all that, that is too hard
23:29:44 <ja> maybe it is related to those ideas of Unison with having libraries composed by functions... at least they'd need tools to talk about how functions relate to each other, or it'd be come unwealdy
23:29:49 * hackage fix-imports 2.3.0 - Program to manage the imports of a haskell module  https://hackage.haskell.org/package/fix-imports-2.3.0 (EvanLaforge)
23:34:37 <sshine> ja, I've thought that this relates to the distribution rather than the compilation of libraries.
23:35:39 <sshine> ja, but surely a side-effect of having a higher granularity means that you can pre-compile single functions; you just won't get the same whole-program optimization perks right off the bat.
23:36:19 <ja> that's not too bad or?
23:38:31 <dminuoso> Cale: Fair enough, perhaps I should relabel "impedes inlining" as "should remember to use -fexpose-all-unfoldings" in my head. After some additional pondering it's not good enough of a reason to not do tagless final.
23:38:41 <ja> who am i kidding, the worst performance killer with haskell will always be the lists anyway :O
23:38:47 <dminuoso> But it definitely warrants a warning. :)
23:39:28 <dminuoso> I think to the inexperienced, a performance issue of this type could be hard to chase.
23:40:39 <dminuoso> Would you mind elaborating the details behind "unliftio with mutable references in the environment" story though? I can imagine how that'd work out, but it's hard for me to come up with a realistic example of how that could happen.
23:41:31 <dminuoso> Every scenario I can come up requires closing both eyes while aiming the shotgun at your foot.
23:41:50 <sshine> ja, as the Alexis King talk starts out with saying, for the first many CRUD apps you build in any language, performance probably doesn't matter. :) and then when you get around to building some high-performance service, you begin to care. I've never had to really care (only pretend-care) about performance in my career except for a single project at my latest job.
23:42:47 <sshine> ja, which is mostly because I depend on, rather than build, systems where other people cared about performance for me. ;) like kafka, rabbitmq, etc.
23:44:15 <lexi-lambda> As a forewarning, -fexpose-all-unfoldings + -fspecialise-aggressively very often doesn’t do what people think it does.
23:44:47 <lexi-lambda> The problem is that the worker/wrapper transformation essentially defeats specialization.
23:44:49 <sshine> oh hi lexi-lambda :P
23:45:08 <ja> sshine: hmmm how can you know how much time you'd have spent debugging some quadratic algorithm if you had never heard about asymptotics? ;) so by saying "i never have had a problem with performance", that does not prove that performance doesn't matter ;)
23:45:45 <dminuoso> lexi-lambda: Incidentally this is unrelated to the current discussion. To put it into perspective, I made a remark that writing your code in mtl-polymorphic style (i.e. tagless final) could prevent inlining from firing properly. Cale then pointed out that -fexpose-all-unfoldings can counteract this, which is why they have it enabled globally in their build system.
23:45:51 <dminuoso> But that was last night.
23:46:52 <lexi-lambda> Counterintuitively, -fexpose-all-unfoldings does not necessarily counteract it.
23:47:15 <dminuoso> Can you elaborate?
23:47:39 <lexi-lambda> Are you familiar with the worker/wrapper transformation?
23:48:08 <sshine> ja, right :) so knowing about asymptotics you tend to avoid basic performance problems. but this kind of foresight comes with working with strictly evaluated languages. I have the impression that when you deal with performance in non-strict languages like Haskell, you have to think about thunking and how the compiler optimizes across chunks of code.
23:48:13 <dminuoso> Actually I don't. Reading up on it now.
23:49:38 <dminuoso> Just skimmed it quickly, I think I get the gist of it.
23:49:41 <lexi-lambda> dminuoso: The idea is that GHC sometimes splits a function into two functions: a worker and a wrapper. The worker, as the name suggests, does the meat of the work, but it can use a different calling convention. For example, it might take two Int#s instead of a single (Int, Int). The wrapper just wraps the worker and serves as an adapter to the user-declared calling convention.
23:49:52 <dminuoso> Right
23:50:03 <ja> sshine: right, i am in kindergarten too, i don't think about thunking and i don't want to. if i get a problem, i'll throw strictness all over the place. if that doesn't work, i'll probably elope to ocaml or something hahaha :P
23:50:18 <lexi-lambda> The problem is that this can defeat specialization, because the worker/wrapper transformation will sometimes unpack dictionaries.
23:50:45 <dminuoso> Okay, that makes sense
23:50:53 <lexi-lambda> So you might have a function that takes a Monad constraint, and the worker/wrapper transformation will split out a worker that takes (>>=) as a separate argument.
23:51:45 <lexi-lambda> This totally defeats the specializer. It will specialize the wrapper, but doing so is basically useless. It won’t specialize the worker (because there’s no longer a dictionary argument to specialize on), nor will it inline it (since it’s too big).
23:51:55 <sshine> ja, ideally, the sufficiently smart compiler will get you a good result in many cases without you having to know much about how it does. if you look at other language ecosystems, I don't think a whole lot of the total programmer pool knows deeply how their compiler works, even though the rabbit holes there might not be as deep. so it shouldn't be necessary for Haskell programmers to read GHC mailing 
23:52:01 <sshine> lists, either. :-P just think how much optimization you get for free just by importing 'text'.
23:52:09 <lexi-lambda> Writing INLINABLE pragmas explicitly avoids this problem, because INLINABLE forces GHC to store the unoptimized unfolding in the interface file.
23:52:48 <lexi-lambda> But that isn’t necessarily a win, because if specialization doesn’t happen, then the worker/wrapper version might have been an improvement!
23:53:05 <dminuoso> lexi-lambda: But couldn't GHC apply worker/wrapper to the interface definition as well?
23:53:22 <dminuoso> That is, if its inlined, wouldn't GHC have a chance to do worker/wrapper anyway?
23:53:51 <dminuoso> Surely GHC runs the same simplifier pipeline
23:53:54 <lexi-lambda> If it’s small enough to be inlined, then all of this is irrelevant anyway. You don’t need specialization in that case.
23:55:04 <dminuoso> lexi-lambda: Is worker/wrapper only applied to top level definitions?
23:55:45 <lexi-lambda> No, but I’m not sure when you are suggesting it be applied. INLINABLE forces the compiler to store the unoptimized (and therefore pre-worker/wrapper) unfolding in the interface file.
23:56:08 <lexi-lambda> If the unfolding is not inlined, then there is no code in the current compilation unit to apply the worker/wrapper transformation to.
23:56:39 <lexi-lambda> In theory, GHC could store both versions in the interface file, and only use the unoptimized unfolding for specialization. But GHC doesn’t currently have any notion of a “special, specializer-only unfolding.”
