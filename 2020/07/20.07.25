00:09:25 <kuribas> why is most type level programming intyped (or better unkinded), like in servant?
00:09:30 <kuribas> untyped
00:10:09 <kuribas> We like strong typing at value level, but it seems that on type level it's just the wild west.
00:10:15 <kuribas> It's more like lisp than haskell.
00:11:24 <fog> well, we have standalone kind signatures now, so im not sure thats a reasonable view to take
00:11:26 <kuribas> For example, I would expect the (:>) operator to be * -> *
00:11:48 <kuribas> but it accepts other kinds, which can make it harder to debug.
00:12:04 <fog> that seems more like a mistaken use of polykinds
00:12:26 <fog> similar to not supplying a type signature and allowing the typechecker to infer the most general type (or kind in this case)
00:12:45 <fog> its not so much a fault of the language. there is plenty of infrastructure to support explicit kind annotations
00:13:46 <kuribas> more like: * -> * -> *
00:14:09 <kuribas> fog: that's what I mean, the language has support for stricter typing (kinding?) at type level, but it isn't often used.
00:15:07 <fog> there are places where it has to be, in order for it to typecheck, but if not, then sometimes people are happy for ghc to infer the more general kind
00:15:34 <fog> even if this is either wrong, or like you say, makes it harder to debug, or makes the program less legible
00:15:57 <fog> i hope that standalone kind signatures can help get people in the habit of supplying explicit kind annotations 
00:16:33 <fog> accompanying classes and datatypes with kind signatures should become as commonplace as providing type signatures to accompany functions
00:17:30 <fog> but i guess we will have to wait for the newest ghc to make its way to the haskell platform before the majority of users will have access to this 
00:18:10 <fog> it should be one of the more considerable changes to haskell programs as a result of a new language extension
00:19:19 <kuribas> I think type level programming been kind of hacked on top of the base language, which is why it's not very convenient.
00:19:39 <kuribas> I wonder if it's possible to have more convenient type level programming without going to dependent types.
00:21:16 <kuribas> By still having a difference between value level and type level, and simply lifting functions and types into type level.
00:36:10 <fog> kuribas: at the moment, we have a situation which is slightly more involved, but equaly functional, and only slightly more burdensome in terms of syntax
00:36:32 <kuribas> the spoken rather euphemistically
00:36:38 <fog> the singletons and defunctionalization machinery seems functional, if inconvenient and difficult to read
00:37:01 <kuribas> singletons are a good example of how complicated it is to do type level programming.
00:37:14 <kuribas> I am not blaming haskell here, it's great we can have this functionality.
00:37:14 <fog> which is kind of detracting from some of the core tenants making haskell the industry leading language 
00:37:39 <fog> anyway, all you have to do is make a type level version of your value level functions
00:38:05 <fog> and TypeInType should have this be applicable across all higher levities
00:38:06 <kuribas> if this machinery can be hidding in libraries, and the average programmer doesn't need to know about it, it's ok.
00:38:51 <fog> well, then you resport to template haskell, which is arguably a similar form of inconvenience or detracting from haskells normal interface 
00:39:48 <fog> it would be better to have higher order functions implemented at type and value level
00:40:26 <fog> but that means, in order to have a unified appraoch, and value level being lazy by default, and type level being strict by default
00:40:51 <fog> that different encodings, such as the state encoding, would be needed to represent lists in a lazy way at type level
00:41:33 <fog> essentially this amounts to foldable at type level being kind of "fusioned" through, into the unfolding process that produced the list
00:41:55 <fog> at value level we dont worry about this, as we have rewrite rules and inline pragmas that take care of this
00:42:02 <fog> at type level we have no such things
00:42:17 <fog> but, and this is important, im not sure other languages do either
00:42:47 <fog> the issue of singletons seems then much less serious than issues to do with lazyness and compilation at type level
00:42:56 <fog> its not that you just need functions that lift to type level
00:43:03 <fog> you need the typechecker to aswell
00:43:18 <fog> then you have to basically put systemF and the whole of GHC at type level
00:43:24 <fog> which seems quite monumental
00:43:56 <fog> so, without similar features being reaonble to expect exist in other languages
00:44:13 <fog> im sure that the comparison between haskell and dependent languages is pretty shallow
00:44:48 <fog> if it mostly revolves around inconviniences to do with singletons and defunctionalisation, there are much larger things to do with lazyness and compilation
00:44:50 <kuribas> no, you write functions at value level, then lift them.  So you don't need system F at type level.
00:45:09 <fog> but how do you do rewrite rules?
00:45:12 <kuribas> That only works if value level is pure and total though...
00:45:24 <kuribas> rewrite rules?
00:45:32 <fog> yes, or inline pragmas
00:45:37 <kuribas> what do they have to do with type level programming?
00:46:04 <fog> the issue is to do with the state encoding 
00:46:05 <kuribas> the value level function just compiles as normally, as long as the semantics are correct.
00:46:18 <fog> but we dont have lazyness at type level
00:46:36 <fog> i can fuse through to the unfolding of a list at value level
00:46:38 <kuribas> well, I am speaking about a hypothetical language
00:46:48 <fog> i dont follow
00:46:49 <kuribas> which is total, so lazyness doesn't really matter.
00:46:57 <fog> how so?
00:47:12 <kuribas> if it's total, lazyness is an implementation detail.
00:47:21 <kuribas> it only affects performance;
00:47:27 <fog> basically, all im saying is that you cant have the same higher order functions at value and type level
00:47:32 <fog> thats the main issue
00:47:46 <fog> the lack of lazyness at type level forces you to use the state encoding
00:48:07 <fog> basically storing lists as the thing that would be unfolded to give them
00:48:20 <fog> and having the foldable instance revolving around that
00:48:59 <fog> kuribas: i feel like your playing devils advocate. lazyness is obviously not a mere performance issue
00:49:13 <fog> it allows programs that use infinite lists to terminate
00:49:20 <fog> thats pretty significant
00:49:27 <kuribas> but infinite lists cannot exist in a total language.
00:49:48 <fog> syntactically, it amounts to being able to use lists instead of state encodings
00:50:11 <fog> so, no lists at type level, would be an irreconcilable difference between type and value level
00:50:42 <fog> im not sure why your imposing strictness at term level. we are still working with haskell as a lazy language right?
00:50:50 <fog> you just want to be able to "lift" functions?
00:51:00 <kuribas> yes
00:51:16 <fog> im saying its not too much difficulty to write type level versions of term level functions
00:51:29 <fog> and that the real difficulty is to do with encoding lazyness
00:51:58 <fog> which basically forces you to do something *different* at type and term level
00:52:02 <kuribas> You'd be able to write a type safe printf, by writing a value level function String -> Type.
00:52:04 <fog> otherwise everything would be mechanic
00:52:44 <kuribas> just look at how complicated type level lists are.
00:53:16 <fog> i cant see how you could get round that with a lifting mechanism without type level lazyness
00:54:11 <kuribas> By forbidding infinte structures.
00:54:19 <kuribas> They aren't that useful IMO
00:54:34 <kuribas> they're cute, but not inexpendible.
00:55:03 <MarcelineVQ> kuribas: infinite lists can exist in total languages. there is totality that includes the notion of productivity: if you can show your function can produce some output whenever asked, and satisfies the other requirements of totality, it is also total.
00:56:42 <MarcelineVQ> That's a mangled summary I'm sure since it doesn't define what 'asked' means,  this is the kind of thing I mean though https://bentnib.org/productive.pdf
00:58:38 <MarcelineVQ> erf, that paper's not quite what I wanted, it covers the ideas but pretty tersely
00:59:02 <fog> kuribas: are you saying dependently typed languages are all total, and so are not lazy?
00:59:13 <kuribas> fog: no
00:59:16 <fog> wouldnt that be a major disadvantage compared to haskell?
00:59:50 <kuribas> I am not convinced lazyness is such a great advantage.
00:59:54 <fog> well how do they handle lazy lists at type level and function lifting?
01:00:23 <kuribas> you don't need to lift a function in a dependent language.
01:00:24 <fog> kuribas: well, many users of haskell are enamoured with it
01:00:38 <fog> then how do you have lazyness?
01:00:46 <kuribas> because type level and value level are the same.
01:00:57 <kuribas> I don't know...
01:01:08 <fog> i didnt know any dependent languages were lazy at type level
01:01:26 <fog> i thought the only way they managed to do it was by being strict
01:01:28 <kuribas> I think idris has optional lazyness
01:01:48 <fog> i guess thats the only option, to somehow handle the state encoding
01:02:15 <MarcelineVQ> it does, but not in types. or rather if you use it in types they won't normalize as far as you might need them to
01:02:40 <fog> can you explain that more, im not sure i understand...
01:02:59 <fog> whats the situation with normalization?
01:04:33 <fog> anyway, in haskell, all you need to do is settle on something that works for both type and term level
01:04:39 <fog> which is easy, its foldable
01:04:47 <MarcelineVQ> idris (ideally) will only normalize a type if it knows that's a total operation.  if I write  myTy : Bool -> Type; myTy True = Char;      and I write     foo : myTy True; foo = 'c'    I will (probably) get a compiler error saying you can't unify   myTy True  and  Char,  since myTy  isn't total, idris hasn't reduced/normalized it
01:05:00 <fog> then, the foldable instance of your lists and state encodings abstracts away the difference
01:05:26 <fog> its not exactly lifting, but its a unified approach that allows a more mechanistic style
01:05:35 <fog> where you just write a type and a term level version
01:06:34 <fog> MarcelineVQ: sounds almost like the a ~ [a] infinite type error in haskell
01:07:09 <fog> wouldnt you just need to provide a base case and a recursive step so that it will terminate?
01:07:26 <MarcelineVQ> I would just need to define the False case too, in this example.
01:07:33 <MarcelineVQ> for myTy
01:07:34 <fog> i guess the issue is that you cant prove that it will
01:07:45 <fog> oh right, more of an exhaustiveness checking issue
01:07:49 <fog> sorry, i musunderstood
01:08:43 <fog> whats that got to do with totality and lazy infinite lists at type level?
01:14:18 <MarcelineVQ> totality checking is largely exhaustiveness checking but actually that's a good question, this example doesn't show anything about lazyness, I'd have to get idris1 again and doublecheck how much lazyness affects types, I could be premature in saying that it affects normalization
01:18:59 <fog> hmm
01:19:08 <fog> anyway, what about type level scanners?
01:19:25 <MarcelineVQ> what is a scanner
01:19:38 <fog> mapAccumL without use of Traversable
01:19:43 <fog> in a monadic list
01:20:20 <fog> i cant seem to be able to write TraversableM, it seems in general impossible 
01:20:56 <fog> so, in order to visit every element, and modify it, while carrying something, and using this as an input for the update to each value
01:21:00 <fog> i use a scanner
01:21:07 <MarcelineVQ> TraversableM being?
01:21:24 <fog> :t traverse
01:21:25 <lambdabot> (Traversable t, Applicative f) => (a -> f b) -> t a -> f (t b)
01:21:31 <fog> that, but with more m
01:21:47 <MarcelineVQ> are you like this in real life?
01:21:49 <fog> t m a -> f (t m a)
01:22:10 <fog> i would have to be able to commute the f and the m
01:22:15 <fog> in general, this isnt possible
01:22:27 <fog> infact, perhaps *only* identity commutes with all monads
01:22:33 <fog> erm, all applicatives
01:22:52 <fog> so that traverse, being traverseM @Identity
01:23:00 <fog> is the only thing that works
01:23:08 <fog> but that, to get mapAccumL
01:23:19 <fog> i cant coomute StateL through the monad
01:23:42 <fog> i think this is the shortest demo of scanner i got; https://gist.github.com/fog-hs/0ac6533875b68508ec35da55c160c4f1
01:23:57 <fog> Monad m  => (s -> a -> m (b,s)) -> s -> t m a -> (t m b,m s)
01:24:03 <fog> :t mapAccumL
01:24:05 <lambdabot> Traversable t => (a -> b -> (a, c)) -> a -> t b -> (a, t c)
01:24:37 <fog> its got all the arguments kind of flipped around for convinience
01:25:05 <fog> anyway, the upshot is i cant traverse monadic lists
01:25:18 <fog> and scanner is mapAccumL wihtout using traverse
01:25:42 <fog> and then, i get the feeling this might be needed at type level
01:25:54 <fog> because really, i dont just want to be able to fold my type level lists
01:26:01 <fog> i want to traverse them
01:26:56 <fog> (a slight logic hole there is to do with seti/geti and setM/getM - to do with "structure directing indexes", which i dont want to explain again here)
01:27:51 <fog> basicaly i think scanner should allow for use of structure arguments at each encountered value in a "traverse"
01:28:17 <fog> such as could update a zipper "forwards", if thats the carry, to allow for an instance of zip for trees
01:29:02 <fog> but, its pretty elaborate to describe all that. basically, im overwhelmed at the prospect of having to write all that at type level
01:29:23 <fog> thought perhaps in exchange for a bushel of acorns... 
01:29:48 <[exa]> fog: could you summarize this in some kind of a paper or atleast blogpost so that the average people here can get the idea?
01:31:21 <MarcelineVQ> fog: is this all because you couldn't write Traversable for your special list type?
01:31:38 <MarcelineVQ> and is that type https://gist.github.com/fog-hs/0ac6533875b68508ec35da55c160c4f1#file-embed-hs-L63 ?
01:31:46 <[exa]> like, spewing a 500-line thought process into IRC might be an interesting way to rubberduck the problem, but hardly useful
01:33:59 <MarcelineVQ> because I had ghc derive an instance for that so it is possible
01:35:01 <MarcelineVQ> Anyway there are languages that support type-level things more directly, are you preferring haskell just for the challenge? :>
01:36:10 * [exa] .oO(universal type-level haskell interpreter would solve so many problems!)
01:39:55 <fog> MarcelineVQ: a Traversable instance?
01:40:20 <MarcelineVQ> yes
01:40:34 <fog> i can write one but i cant write it so its lazy
01:42:29 <fog> i guess you would want it to have mapAccumL be able to do what scanner is doing in the example
01:43:47 <fog> oh, it doesnt have an example use of scanner... hang on
01:44:17 <fog> here; https://gist.github.com/fog-hs/0ac6533875b68508ec35da55c160c4f1#file-embed-hs-L127
01:50:44 <fog> MarcelineVQ: i cant see what GHC must be doing to derive the instance if its possible. every time i tried i end up having to commute the f and the m which i couldnt do
01:52:09 <fog> [exa] i was hoping your expertise could be more helpful than that of a rubber duck
01:59:33 <[exa]> fog: I would really love to help but I'm obviously missing like 99% of the motivation and reasons you have. Writing that down into a coherent text helped me with similar problems (also with communicating them to others) so highly recommend doing that
02:00:49 <[exa]> the complexity of the problem has apparently just grown above the IRC communication capacity, that stuff happens :]
02:00:52 <fog> im not sure your correctly assessing my levels of motivation
02:01:28 <fog> [exa] sounds like elon musks "bandwidth problem" 
02:02:06 <[exa]> obviously not, which is a problem (I likely missed 80% of the reasons you wrote here, these are lost in scrollback and people have no time to dig them out)
02:02:12 <fog> IRC meets johnny mnemonic... 
02:02:49 <[exa]> your problem is complex, you seem to have an idea how to tackle it, so the suggestion is to write SPJ advice and write a paper
02:03:08 <[exa]> *follow SPJ advice
02:05:05 <fog> "the only way left is to hack your own brain and loop it through jones"
03:31:49 * hackage matchable-th 0.1.1.0 - Generates Matchable instances using TemplateHaskell  https://hackage.haskell.org/package/matchable-th-0.1.1.0 (viercc)
03:54:32 <kuribas> No instance for (KnownSymbol queryName0) arising from a use of ‘apiMeta’ • In the expression: apiMeta (Proxy @SQA_API) In an equation for ‘sqaApiMeta’: sqaApiMeta = apiMeta (Proxy @SQA_API)
03:54:44 <kuribas> really?  It's not even showing me the context?
03:58:16 <kuribas> queryName0 looks like an unbound type variable
03:58:37 <kuribas> but it should be always bound...
04:00:08 <kuribas> it's shitty ghc doesn't give me a bit more context
04:03:29 <kuribas> I guess this nicely demonstrates my earlier assertion that type level programming is convoluted in haskell.
04:06:59 <kuribas> Ah I found it, it was indeed free in some instance...
04:41:58 <kuribas> fortunately my colleagues wouldn't see such error, so I guess it's fine.
05:08:18 * hackage ghc-typelits-knownnat 0.7.3 - Derive KnownNat constraints from other KnownNat constraints  https://hackage.haskell.org/package/ghc-typelits-knownnat-0.7.3 (ChristiaanBaaij)
05:19:13 <bbarker> is there a hackage admin around I could message with an issue?
05:23:01 <Uniaika> bbarker: -> #hackage
05:23:28 <bbarker> ah ty
05:24:16 <mniip> how bad of an idea is it to create a bunch of threads interconnected by MVar's/Chan's doing fairly simple processing?
05:25:00 <mniip> my understanding is that in the GHC RTS, threads, and context switching due to mvar operations is relatively cheap?
05:25:05 <hpc> it's a perfectly fine idea
05:25:15 <Uniaika> oh, hello mniip :)
05:25:27 <Uniaika> I don't see anything against that idea
05:29:28 <mniip> I mean option A is to create a bunch of simple functions like, makeMapper :: (a -> IO b) -> MVar a -> IO (MVar b); makeMapper f x = newEmptyMVar >>= \y -> forkIO (forever $ takeMVar x >>= f >>= putMVar y) >> pure y
05:29:49 <mniip> option B is to create an eDSL for such operations and really worry about coalescing them together
05:29:57 <mniip> sounds like pipes eh?
05:58:49 * hackage dobutokO-poetry 0.6.0.0 - Helps to order the 7 or less Ukrainian words to obtain somewhat suitable for poetry or music text  https://hackage.haskell.org/package/dobutokO-poetry-0.6.0.0 (OleksandrZhabenko)
06:01:52 <ingenieroariel> Hello, I need some help with a qualified import. There is a pattern in one of the libraries I am importing : / that I do not know how to properly escape in the import line
06:02:19 <ingenieroariel> If i do `import Module` then I can use : / without issue
06:02:45 <ingenieroariel> But I cannot do `import Module as M` and then `M.(:/)`
06:03:08 <ingenieroariel> I also cannot do `import Module ( (:/) )`
06:05:46 <[exa]> I guess it should be M.:/  (iirc I used M.! with maps)
06:06:19 * hackage dobutokO-effects 0.13.0.0 - A library to deal with SoX effects and possibilities  https://hackage.haskell.org/package/dobutokO-effects-0.13.0.0 (OleksandrZhabenko)
06:07:04 <[exa]> the other example you say seems to work for me (testing as: `import Data.Map ((!?))`  )
06:08:35 <ingenieroariel> I believe I tried both - let me check again
06:10:13 <idnar> ingenieroariel: the leading colon means it's a constructor, so the import would be `import Module (SomeType((:/))` I think
06:15:21 <ingenieroariel> so in this case: https://github.com/obsidiansystems/obelisk/blob/master/lib/route/src/Obelisk/Route.hs#L27
06:16:11 <ingenieroariel> it would be `import Obelisk.Route (pattern( :/))` ?
06:17:02 <[exa]> :t (:/)
06:17:03 <lambdabot> error:
06:17:04 <lambdabot>     • Data constructor not in scope: :/
06:17:04 <lambdabot>     • Perhaps you meant one of these:
06:20:43 <[exa]> ingenieroariel: seems like it's specified here https://gitlab.haskell.org/ghc/ghc/-/wikis/pattern-synonyms
06:26:27 <ingenieroariel> Thanks for the link [exa], from what I see the spec says I should use the full name of the thing: `pattern (Arrow)` in the documentiation
06:26:49 <ingenieroariel> inspecting the file I linked above, I see `{-# LANGUAGE PatternSynonyms #-}` - will try to use that on my file to see if it triggers a different behavior
06:29:46 <ingenieroariel> it worked
06:52:02 <dmj`> It would be cool if there were hackage-wide statistics about extension usage
06:56:55 <infinisil> dmj`: It's not really that, but there was a survey that asked which extensions people want enabled by default: https://taylor.fausak.me/2019/11/16/haskell-survey-results/#s2q5
07:00:44 <dmj`> infinisil: yea, that'd be cool. But what we want, and what we actually use would be an interesting thing to see.
07:01:24 <dmj`> I'd like to see what percentage of hackage uses RankNTypes and ExistentialQuantification
07:01:55 <dmj`> we can even weight it by downloads (despite hackage download counter being broken)
07:02:01 <dmj`> weigh*
07:08:27 <gentauro> so when you use a lot of `<$>` and `mapM` to parse many files you apparently get -> `openBinaryFile: resource exhausted (Too many open files)`. Is there a way to fix this?
07:08:30 <gentauro> :| 
07:09:01 * gentauro fix this without having to write `unreadable` Haskell code?
07:11:56 <infinisil> I'm 99% sure this doesn't have anything to do with <$> or mapM
07:13:11 <infinisil> It might be because files are read lazily (which is what the default readFile does)
07:13:17 <infinisil> Or maybe your ulimit is just too low
07:14:01 <dmj`> gentauro: can you paste your code?
07:14:41 <dmj`> gentauro: you might need to make an explicit loop that opens and closes the handle before the next file is processed.
07:14:50 <gentauro> dmj`: not yet
07:15:28 <gentauro> infinisil: yes, I use `LBS.readFile` (lazy bytestring)
07:16:30 <dolio> If the problem is that 'the files are read lazily', but you are choosing to open them eagerly by doing something like `mapM` over a lot of file names to parse, then you can also fix it by making a lazier 'parse all these files' thing.
07:16:52 <dolio> Which will only open and parse the file when the result is needed for instance.
07:16:52 <gentauro> `tree` states the following -> `565 directories, 2827 files`
07:17:42 <infinisil> dolio: That sounds like lazy IO (which ideally should be avoided, but then again, that's how lazy readFile's work)
07:18:20 <infinisil> (I think)
07:18:34 <dolio> It is lazy IO.
07:18:49 <gentauro> each of the 565 folder has at most 5 files
07:18:49 <dolio> And I don't agree that it is ideal to avoid it.
07:18:56 <gentauro> so when I `mapM` over the folders
07:19:04 <dmj`> dolio: ++ 
07:19:26 <dmj`> long live lazy i/o
07:19:41 <gentauro> no `strict` version of `readFile`?
07:19:54 <dmj`> the only reason lazy i/o is a problem is because we don't have infinite resource
07:20:20 <dmj`> gentauro: you should check how many file descriptors you're allowed to have open at once, sometimes that is set too low
07:20:28 <infinisil> dmj`: Isn't the real problem with it that it can make pure code impure?
07:20:45 <dolio> No, it doesn't make code impure.
07:20:50 <infinisil> Ah no it doesn't
07:20:56 <infinisil> I mean it lets pure code throw exceptions
07:20:57 <gentauro> infinisil: dealing with `readFile` would always be impure
07:21:03 <dmj`> infinisil: the real problem is that it ties the evaluation of pure code to impure effects, and in the face of finite resources that can cause problems
07:21:26 <dolio> Pure code already can throw exceptions.
07:21:47 <infinisil> Hm I guess it can
07:22:05 <maerwald> unsafePerformIO an unsafeInterleaveIO can make code impure
07:23:09 <dmj`> infinisil: also, I think lazy i/o is actually faster than pipes / conduits, just because those abstractions are implemented on top of lazy i/o
07:23:31 <dolio> No, they aren't implemented on top of lazy I/O.
07:23:32 <gentauro> dmj`: `ulimit -Sn` => 1024
07:23:42 <gentauro> I guess it's the *nix OS that limits this
07:23:43 <gentauro> :(
07:24:10 <dmj`> gentauro: you can set it to be unlimited iirc
07:24:21 <gentauro> `ulimit -Hn` => 4096
07:24:29 <gentauro> soft and hard
07:24:46 <gentauro> `cat /proc/sys/fs/file-max` => 9223372036854775807
07:24:47 <gentauro> :o
07:26:03 <gentauro> but it seems it's not a Haskell issue but rather an OS issue
07:26:03 <gentauro> :)
07:27:15 <dmj`> dolio: are you saying they just don't use unsafeInterleaveIO when doing IO
07:27:39 <maerwald> they do chunking, that's all
07:28:07 <int-e> dmj`: if they did, what would be the point
07:28:32 <dmj`> right, but when they read each chunk is it using unsafeInterleaveIO
07:28:48 <dmj`> or bytestrings strict io
07:29:26 <dolio> dmj`: They don't use unsafeInterleaveIO.
07:31:16 <dolio> They are like a DSL for describing incremental processes that can then be executed in a loop with a small amount of buffering (hopefully).
07:33:04 <dolio> Fundamentally they have nothing to do with I/O even, but for some reason people associate them with that, including the library authors.
07:34:36 <dmj`> well that's how they're advertised, "solve the problems with lazy I/O non deterministic resource usage"
07:34:48 <dmj`> everybody just copied Oleg's iteratee paper
07:34:56 <dmj`> and claimed it as their own :)
07:35:14 <dolio> The iteratee paper is about how to traverse collections.
07:35:48 <dmj`> It mentions Iteratee IO first thing in the abstract
07:35:49 <dmj`> http://okmij.org/ftp/Haskell/Iteratee/describe.pdf
07:36:01 <dmj`> contrasting w/ lazy IO
07:37:06 <dmj`> I agree incremental and composable stream processing doesn't imply IO, but the streams have to come from somewhere
07:39:02 <dolio> That isn't the first iteratee paper, I think.
07:42:35 <dolio> At least, not the first with the general idea.
07:43:57 <dolio> http://okmij.org/ftp/papers/LL3-collections-enumerators.txt
07:47:16 <dolio> I think that is one of the earliest about 'turning a loop inside out' for traversing collections.
07:50:29 <dolio> Using iteratees for I/O is doing that for the string of characters in a file or such. File handles and the like are 'cursors'.
07:51:26 <niso> can this function signature ever be valid? (Traversable t, Monad m) => (b -> a -> b) -> b -> m (t a) -> m (t b)
07:52:22 <dolio> It's a valid type signature.
07:52:24 <dmj`> dolio: yea I always thought of it like a Handle can be the source or the sink, sink :: a -> IO () and source :: IO a
07:53:03 <dolio> niso: Do you mean: can a function with that type be implemented?
07:53:12 <niso> dolio: yes
07:53:39 <dolio> Probably.
07:57:26 <dolio> @type \f s0 m -> evalStateT (lift m >>= traverse (\x -> state $ \s -> let s' = f s x in (s', s')))
07:57:27 <lambdabot> (Traversable t1, Monad m) => (b -> t2 -> b) -> p -> m (t1 t2) -> b -> m (t1 b)
07:57:53 <dolio> Oh, I missed using s0.
07:59:52 <niso_> dolio: thanks
08:34:50 <monochrom> @type foldM
08:34:51 <lambdabot> (Foldable t, Monad m) => (b -> a -> m b) -> b -> t a -> m b
08:36:15 <monochrom> nah, won't do
08:45:12 <lisbeths> Does haskell have a call stack?
08:45:47 <monochrom> Why do you ask?
08:47:11 <maralorn> I wanna do a really simple pattern match on a string. It's so simple I can definitely do it, when I use list syntax. Is there a way to write something like a string pattern I want something like `f ("prefix"++str)  = str
08:47:19 <maralorn> I know, I could do that one with stripprefix.^^
08:49:09 <dolio> No, there's no pattern like that.
08:49:42 <monochrom> I think you won't like it, but it can be done.  f ('p' : 'r' : 'e' : 'f' : 'i' : 'x' : str)
08:50:13 <maralorn> monochrom: Yeah, I was thinking about exactly that and was hoppening for something more readable …
08:50:27 <Guest63907> or f s | "prefix" `isPrefixOf` s =
08:50:49 <monochrom> stripPrefix with pattern guard is far more readable
08:50:50 <dolio> You could build something out of view patterns and pattern aliases.
08:51:01 <maralorn> I just probably just write a megaparsec parser …
08:51:27 * Guest63907 didn't know stripPrefix.. nice
08:52:19 <dolio> That seems pretty new.
08:52:34 <Guest63907> lisbeths: kind of, see https://hackage.haskell.org/package/base-4.14.0.0/docs/GHC-Stack.html#t:CallStack
08:52:54 <monochrom> My "escape haskell code for xml" is basically a few f ('&' : str) = "&amp;" ++ f str
08:56:40 <lisbeths> Guest60204: What I guess I am asking is since haskell allows tail call recursion, does the stack ever grow or does it avoid unecessary growth during recursion but still can grow
08:57:47 <cjay> as long as you do actual tail calls you're fine
09:01:31 <monochrom> The stack grows when lazy evalution is used wrong.
09:02:34 <monochrom> This can happen regardless of tail call or not.
09:28:23 <EvanR> also you can write constant-space algorithms without doing tail calls thanks to lazy evaluation
09:30:18 <dolio> At least if you're using STG as your machine model, there are only tail calls.
09:39:19 * hackage hal 0.3.2 - A runtime environment for Haskell applications running on AWS Lambda.  https://hackage.haskell.org/package/hal-0.3.2 (nikeoss)
09:42:11 <tomjaguarpaw> Can anyone explain to me what incantations I need to use to get my overlapping instances to work?  In the cases they overlap the bodies are the same, so there is no conflict in principle.
09:43:50 <dolio> That's not how they work.
09:43:52 <tomjaguarpaw> I just want to make some progress with my prototype.  What's the nuclear option that will cause GHC just to pick either instance?
09:45:17 <tomjaguarpaw> I have `instance b ~ (b1, b2) => C (a1, a2) b` and `instance a ~ (a1, a2) => C a (b1, b2)` and I want GHC to just pick whichever it pleases.  They are the same.
09:45:32 <tomjaguarpaw> The reason I'm doing this is so that type information can flow between the type arguments to C.
09:46:05 <solonarv> looks like you want incoherent instances
09:46:10 <solonarv> https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#instance-overlap
09:46:18 <tomjaguarpaw> Hmm, that's a shame
09:46:36 <solonarv> if all matching instances are incoherent, GHC picks one of them arbitrarily
09:46:50 <tomjaguarpaw> Well, that is what I want.  What is "overlapping" then?  When one is a subset?
09:46:51 <solonarv> (put an {-# INCOHERENT #-} pragma on an instance to make it incoherent)
09:46:55 <tomjaguarpaw> (of the other)
09:47:18 <solonarv> overlapping makes the search fail if there is more than one instance in the end
09:47:33 <solonarv> (scrol down a bit from the link I posted to see the search procedure)
09:47:34 <tomjaguarpaw> Yes, it works! Great, thanks.
09:48:18 <tomjaguarpaw> I'm slightly surprised there isn't a possibilty to provide an instance with two heads, both of which match against the body.
09:50:03 <dolio> I think there's research on that kind of thing.
09:50:09 <dolio> Like 'Instance Chains'.
09:50:15 <tomjaguarpaw> I see, it seems like overlapping instances chooses the unique most specific instance, if it exists.
09:50:53 <dolio> I guess what you're meaning is a little more specific than chains.
09:51:06 <tomjaguarpaw> Well, I will live with Incoherent for now. It gets me closer to my goal.
09:51:28 <tomjaguarpaw> Thanks solonarv and dolio
09:52:32 <dolio> Instance chains are more like the sort of case-by-case fallthrough behavior in pattern matching.
09:54:49 * hackage fakedata 0.7.1 - Library for producing fake data  https://hackage.haskell.org/package/fakedata-0.7.1 (psibi)
09:56:22 <dolio> Whereas you're more interested in turning one instance into overlapping/incoherent instances for improved inference behavior.
09:57:55 <Zer000> Does anyone use nix here? Can anyone tell me why this shell.nix doesn't give me llvm in my environment? I added it to executableHaskellDepends to the script cabal2nix generated https://dpaste.com/2UWEL42ZG.txt
09:58:50 <Zer000> I used to use llvmPackage_6.llvm but that no longer works either (except the shell.nix file does not throw errors! I just can't build with -fllvm)
10:35:38 <maralorn> Once again I tried to write a "quick and dirty" solution in Haskell, because I wanted to "save time". Convert some strings to some strings. I feel like it wouldn‘t have taken much longer if I just had done it proper. i.e. a datatype, a parser and a printer for it instead of ugly string munching …
10:39:25 <ddellacosta> maralorn I know exactly what you mean, I'm doing some quick and dirty hacking on JSON as-is and keep thinking that I should convert some values to real data types, but lens makes the choice a bit harder
10:40:02 <ddellacosta> I mean not exactly what you're talking about wrt parsing but generally speaking I feel that tension a lot in Haskell
10:40:55 <maralorn> ddellacosta: Well it's exactly the same, when we abstract over the weakly typed input which is a string for me and json for you.
10:41:02 <ddellacosta> right!
10:42:23 <maralorn> But honestly my true problem is, that I don‘t know all the values needed to write simple parsers by heart.
10:42:42 <ddellacosta> it makes me think a lot about dynamic typing, like I feel like I can actually get a lot of the same benefit that folks claim dynamic typing gives you in Haskell--but it's restricted to this kind of quick and dirty hacking. However as soon as I want to get something more maintainable or larger and more modular in scale I have to change my style...into a more proper, thoughtfully modeled set of
10:42:43 <ddellacosta> types. Which Haskell handles very well of course
10:43:35 <ddellacosta> maralorn: yeah I don't write parsing code enough so I have to re-learn combinators every time I do some parsing
10:43:41 <ddellacosta> hoping it'll stick some day
10:44:19 <maralorn> I think they are nice, but I don‘t remember them as well as regexes …
10:45:34 <maralorn> otoh regex syntax is quite arbitrary and if I would have learned the combinators first, I would feel much different.
10:46:09 <ddellacosta> yeah, I think insofar as you can objectively consider it they are generally more clear in intent
11:03:52 <dolio> Yeah, I don't think untyped languages are really significantly better for quick stuff, either. It's way over sold.
11:05:27 <dolio> Rather, most commonly used languages with types aren't that good for quick stuff, and most commonly used languages that are good for quick stuff aren't typed.
11:10:46 <EvanR> so correlation and not causation?
11:11:15 <dolio> Yeah.
11:12:02 <EvanR> i can imagine doing quick stuff with haskell if it werent for the mountain of imports required. Yes i can paste a mountain of imports i have up my sleeve, but it's not something you do in... um
11:12:15 <dolio> I mean, it is some causation, because I think a lot of commonly used typed languages have the types get in your way a lot.
11:12:54 <dolio> You can write simple stuff in Haskell that doesn't talk about types at all.
11:13:06 <EvanR> yeah
11:13:23 <dolio> It looks like the stuff you'd write in an untyped language, but it's all typed.
11:13:28 <EvanR> and the vocabulary i have for that stuff, that i consider really part of the language almost, is behind imports
11:13:30 <merijn> EvanR: The difference is that the mountain of imports while a bit annoying isn't that much work and it's usually fairly easy to transform that quick and dirty stuff into something proper
11:13:50 <merijn> Whereas turning a quick&dirty python script into something proper is a hellish task :p
11:14:01 <EvanR> it's not work, that's kind of the point. I can type it all out in my sleep!
11:14:15 <EvanR> but why am i doing that
11:14:56 <maerwald> I don't know many truly untyped languages
11:15:10 <EvanR> also alternative preludes... after you set up a proper project with prelude as a dependency and proper compile flags to make it work
11:15:16 <maerwald> python has types, javascript too
11:15:20 <dolio> Even a lot of new languages that incorporate ideas from functional programming aren't good at not making you write in typing information.
11:15:20 <EvanR> not exactly like "open python"
11:19:14 <maerwald> and python has opt-in types
11:19:25 <maerwald> mypy
11:19:55 <maerwald> *opt-in static types
11:20:44 <maerwald> python done right scales, whether you like doing it is another question
11:20:44 <Guest63907> there's a lot that could be done to haskell much nicer for quick scripting
11:21:11 <Guest63907> not sure I agree maerwald , having maintained a medium-sized python codebase
11:21:24 <Guest63907> it was constantly breaking
11:22:14 <maerwald> eve online client and server are written in python
11:22:25 <Guest63907> I mean, much like all haskell projects. :) But at least here I have more tools for expressing bounds and pinning deps
11:22:31 <EvanR> with enough discpline you can do anything in anything
11:22:33 <maerwald> that's not a medium sized project
11:22:40 <maerwald> that's humongous sized
11:22:55 <Guest63907> yes, of course it's possible
11:23:03 <Guest63907> given enough will and resources
11:23:36 <maerwald> they are not the most successful game company, don't think they have much spare resources :)
11:24:14 <EvanR> is the purpose of languages to let you get away with less discipline, or to help you apply existing discipline... Dunno
11:25:10 <maerwald> Haskell wasn't built with any of that in mind either, those are properties emerging rather randomly, imo. Strong static typing can get you into a mess as well, just a different one
11:25:34 <maerwald> No language saves you from lack of discipline and thinking
11:26:00 <EvanR> wait... 
11:26:12 <EvanR> i wish i had learned that at the beginning :)
11:26:24 <ddellacosta> that's absolutely true, but some languages impose a higher level of discipline for success than is necessary or useful
11:28:43 <maerwald> yes, javascript is surprisingly difficult
11:29:05 <maerwald> the few js programmers, who know what they are doing, are absolute geniuses imo
11:30:25 <suzu_> they keep all the types of things in their head too
11:30:59 <monochrom> When I wrote in Lisp as a student, I thought up writing types in comments.
11:31:06 <maerwald> yeah, your working memory has to keep a dictionary of pitfalls online at all times
11:31:36 <monochrom> Hell, when I wrote in BASIC as a teenager, I meticulously wrote down specifications in comments, especially for GOSUB targets.
11:32:34 <monochrom> I am a disciplined programmer. Born that way. I do everything to uphold my discipline, because or despite the language.
11:33:12 <monochrom> But there are also undisciplined programmers, born that way, who do everything to stay undisciplined, because or despite the language.
11:33:24 <monochrom> Just look at Alan Kay.
11:33:34 <maerwald> That's why I don't think languages with high intellectual complexity or perceptional noise are that cool. You lose focus on the problem you tried to solve.
11:33:39 <monochrom> Larry Wall.
11:34:13 <maerwald> that's why algorithm competitions are using python a lot, afaik
11:35:52 <monochrom> When I wrote in BASIC as a teenager, I re-invented and stuck to Dijkstra's structured programming.
11:36:10 <monochrom> (5 years later, when I went to university and met Pascal, "YES!")
11:53:15 <kaol> Strictly not a Haskell question. But what would you use to make slides for a presentation that showed Haskell code?
11:53:57 <Cale> Beamer?
11:56:08 <dminuoso> beamer without a question :)
11:56:14 <dminuoso> I use that for all my presentations
11:56:37 <mmaruseacph2> beamer++
11:57:15 <kaol> Right, that was actually what I used the last time I gave a talk. And it had Haskell in it too. I just forgot about it. Thanks.
11:58:34 <romefeller> .
11:59:00 <dminuoso> Is there some existing solution to derive a Semigroup instance for a product type that just distributes (<>) over all fields?
11:59:21 <romefeller> Hi people
11:59:21 <dminuoso> I mean I can trivially write one with Generics, just wondering whether Im reinventing something I likely have in a dependency anyway
11:59:32 <romefeller> Hey everyone, we on the haskell.org committee are looking into how to best support the community, and we've turned our attention recently to the haskell wiki. We'd love your stories. How do you use the wiki? Anything you'd like to see addressed? If you don't use the wiki, why not? Feel free to comment here or email us at committee@haskell.org
12:03:09 <Cale> romefeller: I feel like the switch to MediaWiki kind of resulted in a very long and slow death -- it changed people's expectations about how the wiki was meant to be used
12:04:27 <Cale> Instead of being a place to communicate and ask questions, and then have those conversations organised and reshaped into articles, people just expected that it should kind of work like wikipedia, except it's not actually wikipedia.
12:05:07 <Cale> uh, okay
12:07:37 <MarcelineVQ> possibly an issue with using/knowing irc on their end, based on the stilted intro
12:08:03 <kaol> And IRC being IRC.
12:08:20 <romefeller> got dc
12:08:29 <romefeller> I hope you guys read the message about the wiki
12:08:44 <kaol> We did. Did you read Cale's response?
12:08:51 <romefeller> Yes
12:09:46 <tomjaguarpaw> romefeller: It's great you're taking the initiative on the wiki.  There is vast amounts of absurd and outdated information on the wiki and I fear it confuses new users who arrive on outdated pages via search engines.  I have a (very small) list of articles that probably ought to be removed.  It should be much bigger but I got tired of looking.  https://github.com/tomjaguarpaw/tilapia/issues/7
12:10:54 <romefeller> tomjaguarpaw: First of all, thank you about opaleye (Which I'm studying very closely). Secondly, the idea is to deprecate it. We are collecting community opinions.
12:11:26 <monochrom> romefeller: My complaint is in the opening paragraph at http://www.vex.net/~trebla/haskell/IO.xhtml
12:12:29 <tomjaguarpaw> romefeller: Big +1 on deprecation.  I'm glad you like Opaleye!  Let me know if I can ever help with anything regarding it.  There's also a big new release coming very soon :)
12:12:55 <Guest63907> what does deprecation mean, and are you also soliciting input on haskell-cafe ?
12:13:11 <romefeller> monochrom: noted!
12:13:45 <Cale> monochrom: It looks like maybe that issue with the paragraphs being combined got fixed? The demo on that page seems to place them separately.
12:13:58 <monochrom> Ah, nice, yeah
12:18:50 <fog> oh hey! i have a really cool result
12:19:20 <fog> you can think of parametric types as "storing the results of type level computations"
12:19:58 <fog> eg, lengthed lists building up the length, applying Succ at each Cons
12:20:29 <fog> then, eg, the kind (Type -> Type) -> Type -> Type
12:21:06 <fog> has its first parameter, taking the same thing as it takes when this first parameter is partially applied
12:21:32 <fog> (k -> Type) -> k -> Type, would be clearer, but i want the "contents" to be k ~ Type
12:22:11 <fog> then, basically, the (k -> Type) parameter, can be supplied with the input `k' input as the second parameter
12:22:30 <fog> as store *all* "results of type level computations"
12:22:44 <fog> that are supposed to accompany the datatype!
12:22:47 <fog> cool or what!?
12:23:06 <fog> notably, i can store the result of the type level function returning the "base functor"
12:23:44 <fog> so that, instead of actually having to have a type function to return the base functor, i just have it stored in this first parameter 
12:24:00 <fog> i would probably need a lens to retrive it, like if it were part of a monad transformer stack
12:24:22 <monochrom> But lens is term level, not type level.
12:24:32 <fog> a lens like thing
12:24:43 <fog> anyway, its basically just a tuple, and i can uncurry it
12:24:58 <c_wraith> edwardk did have a presentation a while back where he was talking about trying to find something like lenses at the type level
12:25:01 <fog> so i can have any number of (k -> Type) arguments as parameters to the type
12:25:42 <fog> i just thought it was cool that i could put them all in one parameter, but now that seems more novel than useful
12:25:47 <monochrom> The power-to-weight ratio won't look good.
12:26:06 <fog> hmm, actually no, it was for a reason, its because thats the kind of my monadic list
12:26:31 <fog> i want the monad to be able to have the base functor retrivable from it
12:27:13 <fog> then if only the most simple case is considered, if its not part of a stack, or a tuple of extra type information
12:27:33 <fog> then m of ListT m a, can be used to store the base functor
12:28:33 <fog> monochrom: is that a stats joke to do with information content and support from an overcomplete frame?
12:29:06 <monochrom> Are you on drugs?
12:30:27 <fog> thats quite forward, i would normally be quite offput by such an advance
12:31:14 <monochrom> Oh and you think you did not put off me.
12:32:29 <monochrom> Maybe I should be the one who should cry "off-putting" more early and more often. Is this a moral superiority thing or what?
12:33:04 <fog> im sure i can politic my way out of this rabbit hole
12:33:28 <thblt> parsnip0: Indeed, M-j it was, thanks!
12:33:35 <monochrom> You were babbling nonsense about types and I already didn't intervene, to give you the benefit of doubt that maybe you're on to something.
12:33:57 <fog> certainly this seems most generous 
12:33:58 <thblt> parsnip0: Sorry for the late reply, I was on the train and your reply was lost to connections hiccups, I just found it in the remote log.
12:34:09 <thblt> Err, sorry, wrong channel. 
12:34:36 <fog> lost consciousness due to hickups!?
12:34:40 <monochrom> But at my mere consideration of power-to-weight ratio, and that's for what c_wraith said about edwardk considering type-level lens, you out of the blue pull out stat and information and frame and whatnot. WTF.
12:34:40 <fog> omg!
12:35:18 <fog> ah, yes, i always mistake statistical power for information content 
12:35:50 <monochrom> But power-to-weight ratio is neither.
12:35:55 <fog> and i have been working with neural network "weights" as the ratios of various basis vectors
12:36:04 <tomjaguarpaw> This is a great channel
12:36:08 <monochrom> Gosh you are insufferable.
12:36:12 <tomjaguarpaw> I should come here more often
12:37:15 <fog> power-to-weight, i thought, was reference to the similarity between corelated statistics and non-orthogonal support vectors
12:37:44 <fog> but, i must "be on drugs" apparently, to think such things
12:37:50 <glguy> tomjaguarpaw: good to have you :)
12:38:34 <zeta_0> does any one here understand the nix tool lorri? i'm having a hard time setting it up with my ghc.nix setup: https://www.reddit.com/r/haskell/comments/htoxcg/help_setting_up_ghcnix_with_lorri/
12:39:18 <zeta_0> i already asked in the #nixos channel, i figured i'd ask here too, just to check
12:43:25 <fog> monochrom: actually, i thought you could have meant that having several parameters of kind (k -> Type) was unwieldy. but i just thought it was nice that instead of having constraints that associated types are instantiated over some type, that instead, the results of these computations can be stored parametrically 
12:46:40 <tomjaguarpaw> fog: Hmm, have you Church-encoded the type-level natural (for lengthed lists, mutatis mutandis the type level X for Ys)
12:48:15 <fog> that wouldnt work
12:48:39 <thblt> Is there a ghci flag for printing back its input before the result? 
12:48:46 <fog> since the "unfolding" carried thing would need a counter for when to terminate 
12:48:54 <tomjaguarpaw> Oh, that's what I thought you meant by "as store *all* "results of type level computations"
12:48:56 <monochrom> I think no.
12:49:44 <fog> no i just meant if you expect a type level computation to exist over the type, you might as well perform the computation and store the result in an extra paramater to the datatype
12:50:14 <fog> then you dont need the constraint corresponding to the associated type family
12:50:24 <remexre> hm, does microlens have something like ALens?
12:50:37 <fog> you dont actually need the type level function to exist, if you already have the result
12:50:58 <fog> eg, if i perform the computation of length incramentally while consing to a lengthed list
12:51:06 <fog> then i dont need the type level Length function
12:51:13 <fog> i just read it off from the length parameter
12:51:30 <fog> and i was using this logic to do the same with the determination of the base functor 
12:51:37 <tomjaguarpaw> But how are you storing the result of _every_  type level function?
12:51:40 <fog> which is normally an associated type
12:52:01 <fog> oh, that was just because it has that kind
12:52:10 <fog> whatever it is, that does all this storing
12:52:26 <fog> and you get to supply the "contents" argument to it
12:52:45 <tomjaguarpaw> Don't you have a `(Type -> Type) -> Type -> Type` parameter?
12:52:58 <fog> no thats the kind of the datatype
12:53:15 <fog> the first argument can be supplied the second
12:53:27 <tomjaguarpaw> Can you write something concrete, for lengthed lists?
12:53:47 <tomjaguarpaw> List n a :: (Type -> Type) -> Type -> Type?
12:53:50 <fog> well, length doesnt need the contents type supplied to it, it has kind *
12:54:01 <fog> it would just const it away i guess
12:54:33 <fog> List :: Nat -> Type -> Type
12:55:11 <tomjaguarpaw> And where are you putting the result of the type-level function?
12:55:12 <fog> List (n :: Nat) (a :: Type) :: Type
12:55:24 <fog> n is built incramentally
12:55:39 <fog> Const :: a -> List n a -> List (Succ n) a
12:56:14 <tomjaguarpaw> Cons?
12:56:20 <fog> yeah sorry
12:56:34 <fog> if it were '[a], i could have type family Length (xs :: [k]) :: Nat
12:57:33 <fog> but i dont need this with List, since i can just match the length directly, the calculation having been performed during Const
12:57:38 <solonarv> dminuoso: if you are still looking for that automatic Semigroup thing: 'generic-data' is the package you want
12:57:44 <fog> Cons*
12:58:27 <tomjaguarpaw> Hmm, are you saying to reflect the whole structure of the type at the type level?
12:58:27 <fog> oh i had a question about parametric monoids i wanted to ask
12:58:40 <fog> just the mase functor
12:58:43 <fog> base*
12:59:02 <solonarv> with it you can write: data MyProduct = MyProduct Text [Int] deriving (Semigroup, Monoid) via (Generically MyProduct)
13:00:19 <fog> tomjaguarpaw: suppose i have a Tree, then, if i traverse along the leafs, there is some internal navigation
13:01:12 <fog> like, i have a verticle and a horizontal zipper. i go up the branches from the leaf, to get to the junction with the verticle zipper, then accross one with the horizontal zipper, to the right ,and then down to the next leaf
13:01:26 <fog> this "substructure navigation" has some directions 
13:01:34 <fog> which are a "structure directing index"
13:01:45 <fog> in this case a pair of ints
13:02:03 <fog> if i uncons a branch, i need this data to be able to recons it on the same way
13:02:19 * hackage calamity 0.1.18.1 - A library for writing discord bots in haskell  https://hackage.haskell.org/package/calamity-0.1.18.1 (nitros12)
13:02:28 <fog> this is the data i want to be stored in the m of ListT m a
13:02:52 <fog> then i can flatten the tree in a reversable way, to a monadic list, where the monad captures the shape
13:03:15 <fog> this "structure directing index" is kind of like the base functor... actually its not, i was confused
13:04:22 <fog> ah, yes, its like the base functor because its like seti/geti
13:04:42 <fog> the base functor is the type of seti/geti (dual)
13:04:49 <fog> :t unfoldr
13:04:50 <lambdabot> (b -> Maybe (a, b)) -> b -> [a]
13:05:18 <fog> apparently here the base functor is Maybe (a,b)
13:05:45 <fog> but, if it was a tree that was being unfolded, it would need to be something like ((Int,Int),a,b)
13:05:52 <fog> with maybes for if its nonempty or a stream
13:06:44 <fog> (((Int,Int),a),b) would be better, since the b is going to be used again for the unfold, but the `a' goes with the structure directing index (Int,Int)
13:07:32 <fog> i think i explained all this like a year ago
13:07:50 <fog> but now, i can do without seti/geti, because i think the monadic lists are as expressive
13:08:46 <fog> and the cool thing i wanted to comment on is how i dont need an associated type, since the monadic list has as a parameter, the result of this computation, which is the type family returning the base functor
13:09:50 <fog> erm, actually the unfold above isnt with the base functor... it should be the tail not b
13:10:24 <fog> i think eg, Maybe (a,[a]) -> [a] as the type of set is better
13:11:00 <fog> then for trees its; Maybe (((Int,Int),a),Tree a)
13:11:16 <fog> which as you can see is kind Type -> Type
13:11:23 <fog> erm, if its a lambda taking a
13:11:50 <fog> so can go as the `m' param in ListT m a
13:12:49 <fog> so i can reversibly flatten trees into monadic lists, and not need recursion schemes for the base functor type family! cool or what!?
13:28:49 <fog> to see how its useful to have this structure directing index available during traversal, consider carrying a copy of the entire object, with its verticle and horizontal zippers, and navigating them according the the structure directing indexes encountered
13:29:07 <fog> this allows that at each leaf, the carry is the zipper corresponding to that leaf
13:29:22 <fog> then, the leaf can be replaced with the zipper corresponding to that location
13:29:33 <fog> this is the comonad instance for tree zippers
13:29:57 <fog> and then, you can map over that with a foraging scheme, that gathers up values and applies a function over them
13:30:03 <fog> which is a stencil convolution
13:30:11 <fog> and its lazy!
13:30:46 <fog> so you can have stepwise foraging schemes, like building up concentric squares on a tree representing a 2d grid
13:31:19 <fog> and even on an infinite domain, with an infinite stream of such increasingly wide stencils, they can be consumed only finitely many 
13:31:45 <fog> and then you want to be able to zipWith over these streaming stencils... 
13:31:52 <fog> but thats really difficult
13:33:03 <fog> but yeah, thats how you would do lazy covnets, 
13:33:45 <fog> and have addaptive increasing prescision where needed from taking larger stencils, like, having more edges if needs be
13:34:51 <fog> similar to gradient stencil computations for fluid solvers, where higher accuracy closer to convergence could take larger stencils
13:35:04 <fog> for higher order gradient information
13:35:28 <fog> the good thing about gradients is that you build the vector of taylor components by scanning with streaming input data in a buffer
13:36:39 <fog> so then you can run measures over that instead of historic timesteps. and infact do similarly over a range of scanning buffers
13:37:09 <fog> which i think ends up being something like a "multiple observer system"
13:37:26 <fog> over which you are running a "multiclassifier system" 
13:37:41 <fog> disentanglement of which is equivalent to net training 
13:38:03 <fog> but then i need MERA tensor nets
13:39:07 <maerwald> uhm
13:40:57 <MarcelineVQ> getting fed too often lately I think
13:41:08 <yushyin> wow
13:42:46 <solonarv> wow, I just checked the logs
13:42:51 <solonarv> I recommend putting them on /ignore
13:43:10 <tomjaguarpaw> Is it possible to set UndecidableInstances on a per-instance basis?
13:43:18 <solonarv> I don't think so
13:43:25 <tomjaguarpaw> Is there a good reason for that?
13:43:44 <tomjaguarpaw> Seems like it should go the way of OverlappingInstances
13:44:00 <solonarv> there might be? it does also control a bunch of other things, like recursion in type family equations
13:44:08 <solonarv> but despite the spooky name it is not actually that bad
13:44:40 <tomjaguarpaw> I'm OK with it. I'm not sure my users will be...
13:44:44 <solonarv> it removes the totality checker (which is very conservative and so often gets in the way of type-level programming), sure, but it just adds a recursion depth limit instead
13:47:16 <merijn> tomjaguarpaw: UndecidableInstances is fine
13:47:48 <merijn> tomjaguarpaw: Unlike Overlapping which can unpredictably break things silently, the "worst case" for UndecidableInstances is "code fails to compile"
13:48:09 <merijn> tomjaguarpaw: IF your code compiles with UndecidableInstances, then there's no problem/ambiguity
13:48:29 <solonarv> yes, as I said: spooky name, harmless extension
13:48:36 <tomjaguarpaw> I don't mind using it, I would prefer my users not to have to turn it on.
13:48:41 <merijn> (Theoretically it could infinite loop the typechecker, but in practice GHC just has a time out)
13:48:53 <tomjaguarpaw> I'm generating them an instance via TH, and it would be great if UndecidableInstances could go directly onto the instance.
13:49:00 <solonarv> ah, I see
13:49:20 <solonarv> you will probably just have to tell them "enable UndecidableInstances for this TH to work"
13:49:35 <solonarv> it would be nice if TH could enable extensions somehow
13:49:57 <tomjaguarpaw> Yes, in a splice-local way!
13:50:27 <merijn> solonarv: That sounds terrible, tbh
13:50:59 <tomjaguarpaw> It would be terrible if it were for the whole file, but why care if some TH uses extensions that the rest of your module doesn't use?
13:52:29 <tomjaguarpaw> In fact the ability to turn on instances locally _at all_ would be great
14:30:19 * hackage polysemy-optics 0.1.0.0 - Optics for Polysemy.  https://hackage.haskell.org/package/polysemy-optics-0.1.0.0 (nosewings)
15:24:22 <Fare> Hi. Is this the right place to ask for help with optical terminology?
15:25:04 <Fare> I am using the general "zipper" idea to incrementally manipulate tries (big endian patricia trees) in O(N) amortized time for batch operations
15:25:19 * hackage hs-gchart 0.4.2 - Haskell wrapper for the Google Chart API  https://hackage.haskell.org/package/hs-gchart-0.4.2 (tomjaguarpaw)
15:26:43 <Fare> my "zipper" data structure is a trie * height * key * (List 'a) where the 'a parameter is trie for standard editing, but can be digest for merkleizing.
15:27:17 <Fare> Is there a terminology / are there libraries for such data structures?
15:27:48 <Fare> the thing minus the trie is not exactly a lens, since it is a data structure rather than a function.
15:28:04 <Fare> although you can trivially turn it into a lens
15:31:49 * hackage haskoin-store-data 0.37.1 - Data for Haskoin Store  https://hackage.haskell.org/package/haskoin-store-data-0.37.1 (jprupp)
15:32:49 * hackage haskoin-store 0.37.1 - Storage and index for Bitcoin and Bitcoin Cash  https://hackage.haskell.org/package/haskoin-store-0.37.1 (jprupp)
15:56:48 * hackage either-result 0.1.0.0 - ‘Result a’ is a wrapper of ‘Either String a’.  https://hackage.haskell.org/package/either-result-0.1.0.0 (kakkun61)
16:00:37 <ADG1089> can someone comment on description of haskell here: https://tomassetti.me/best-programming-languages/
16:04:04 <c_wraith> ADG1089: well, "not specifically designed for concurrency" is misleading if possibly true in some technical sense.  It may not be part of the language design, but library support for it is excellent, and haskell is designed for libraries to be really good.
16:04:04 <unclechu> hey, can anyone tell does it matter if i give `-threaded` flag to the `library` section of a *.cabal file? or it’s only the `executable` which matters?
16:04:34 <unclechu> would it change anything to the produced `.so` file so instance?
16:04:48 <c_wraith> it only applies to the executable
16:05:00 <c_wraith> because all it does it change what runtime is linked in during final executable creation
16:07:43 <c_wraith> ADG1089 and or ADG1089_: catch my comment before getting booted?
16:09:11 <ADG1089_> what do you mean?
16:09:47 <c_wraith> ADG1089: I replied to your question a couple seconds before IRC reported that your connection was closed.  I'm not sure if my reply made it to you.
16:12:27 <ADG1089> i saw the logs
16:13:29 <ADG1089> well i expected them to put it at some place wkth widespread usage
16:13:52 <ADG1089> *haskell lang at a blog section
16:14:09 <ADG1089> with a widespread usage
16:14:19 <ADG1089> in industry
16:14:47 <sim590> I'm getting this weird error: https://paste.debian.net/1157804/ in this function: https://paste.debian.net/1157803/. Even though, you see I can write the same thing in the repl just after and there's no issue... What's wrong? It's parsing error...
16:15:58 <sim590> I can even remove the +96 and I'm getting the same error. :/
16:16:25 <c_wraith> sim590: you can't apply functions in patterns
16:16:36 <sim590> Oh.
16:16:55 <c_wraith> patterns must be against literals (numbers or strings) or constructors (everything else)
16:17:20 <c_wraith> I guess list literals exist, too.  But yeah.
16:17:31 <sim590> OK. I understand. I'm just coming back to haskell after a few months doing other stuff.. hehe.
16:21:48 <sim590> c_wraith: thanks for the answer by the way!
16:22:37 <c_wraith> you're welcome!
17:03:35 <jumper149> I noticed that `3` is a valid data constructor for `Data.Finite.Finite 2`. It just results in a runtime error. Is there a better solution, that the type checker would catch?
17:04:39 <solonarv> jumper149: not if you want to just write a numeral as a literal
17:07:17 <solonarv> you can do it with template haskell / quasiquotes / fancy types
17:08:00 <solonarv> but the literals won't be a nice number; instead they will be something like: $(finite 3) / [finite| 3 |] / finite @3
17:09:55 <jumper149> solonarv: I am kind of a newbie when it comes to TH. What do you mean with fancy types?
17:15:14 <solonarv> note that these are three separate options
17:15:25 <solonarv> not one option that's somwhow a mix of all three of these
17:15:58 <solonarv> (and the example literals are how each option would look at use sites)
17:28:54 <jumper149> solonarv: Aren't quasiquotes part of TH? I see the type application in the last example, but I'm still wondering how that could result in a value of type Finite 2 (I guess in this case the with @3 type checker wouldn't accept it).
19:31:12 <hololeap> ping
19:48:54 <oats> hololeap: pong
20:05:27 <halogen64> Can you have a HashMap or Map whose elements are some Monad m i.e. (HashMap String (Int -> m [String
20:05:58 <halogen64> My code doesn't seem to like it because it can't match the constraints on m for the function definitions
20:10:17 <ski> halogen64 : monads are not values you store and pass around
20:10:51 <ski> but yes, you should be able to have as values in the map a function which computes a monadic action as result
20:11:32 <ski> perhaps you could share the error you get, at least ? and possibly the code in question, as well ?
20:11:47 <halogen64> ski: Yeah, I expected the compiler to know what I was talking about, but I think I see the issue, I think my callsite doesn't have the monad in scope
20:13:16 <ski> you mean, doesn't have the `Monad' `instance' declaration, for the particular `m' you want to use, in scope ?
20:13:47 <ski> (or maybe you're trying to refer to some type variable `m', which is not in scope ?)
20:15:09 <halogen64> I have a function that has a constraint that is being called from another monadic action that doesn't have that constraint.
20:15:37 <ski> mhm
20:16:24 <halogen64> I incorrectly thought it was the HashMap for some reason, so I inlined it and the same error happened, but I sort of see it now
20:26:50 <ski> mhm
21:48:46 <Arahael> What's the current best way to generate the header file for when you're exporting functions that use the C abi?
