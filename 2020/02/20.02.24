00:08:11 <olligobber> ghc with -Wall is giving errors for missing cases, but those cases aren't missing: https://gist.github.com/olligobber/9f591a6a080395d4e2412cba5adde464
00:14:15 <olligobber> also, hlint cannot handle namespaces in imports
00:14:34 <olligobber> or exports
00:21:05 <lhurttila> I'm planning a project where I'll need loads of objects with internal states that change depending on input, while the output of said objects depends on both the input and the objects internal state. In addition, this whole thing most likely needs some kind of reactive push implementation. Any help, advice and tips of relvant sources would be much
00:21:05 <lhurttila> appreciated :)
00:24:44 <Rembane> That sounds like a whole bunch of state machines. 
00:38:29 <lhurttila> Have to look in to those. I should add that the reactive objects with internal state should be enough and I probably won't need any kind of global state.
00:45:24 * hackage direct-sqlite 2.3.26 - Low-level binding to SQLite3.  Includes UTF8 and BLOB support.  https://hackage.haskell.org/package/direct-sqlite-2.3.26 (sigrlami)
00:52:26 <rindolf> Hi all! How can I fix this error - https://paste.debian.net/1131848/ - Â«[__1] unknown package: hashtables (dependency of mniip)Â» ?
00:56:03 <xavo[m]> you gotta `cabal update`, line 2 in your paste 
00:59:19 <rindolf> xavo[m]: thanks - it seems to have worked
01:12:05 <boxscape> Is there some way to search through the committee mailing lists (e.g. https://mail.haskell.org/pipermail/libraries/ ) without having to download and grep through all the gzips?
01:17:03 <boxscape> what I really wish is a sort of reddit-like thread-based interface where you can read the emails
01:17:04 <boxscape> but I suppose "be the change you wish to see" applies to this
01:18:38 <__monty__> boxscape: Well you can browse the archive. It does not have search but you didn't list that as a requirement : >
01:19:30 <boxscape> That's true but by "reddit-like" I mean all the emails of a thread on one screen, and easy-to-discern the email structure (i.e. just levels of > isn't enough)
01:19:57 <boxscape> (that was weird grammar)
01:20:34 <boxscape> and threads that span multiple months should be visible all at once as well
01:25:47 <boxscape> oh this exists apparently https://groups.google.com/forum/#!forum/haskell-core-libraries
01:26:14 <boxscape> that's... pretty much all I wanted
01:26:44 <boxscape> You can't see nested thread structure but that probably isn't relevant often enough to matter
01:28:49 <boxscape> though I now wonder whether such a page exists for the ghc steering committee mailing list as well
01:30:20 <boxscape> I think it does but I don't have access to it, hm. I wonder if there's a way to grant read-only access to non-members
01:34:06 <boxscape> judging by a quick google search it looks like it is, somehow, impossible to do this
01:34:33 <boxscape> I might be wrong
01:35:38 <maxsu> boxscape, I am able to search for "hello site:https://mail.haskell.org/pipermail/libraries/" to find 81 results
01:36:15 <boxscape> maxsu ah, that's not a bad way to do it, thanks
01:36:18 <__monty__> boxscape: Just stumbled across this, search appears to work but only from the point a list was added: https://www.mail-archive.com/ghc-devs@haskell.org/info.html
01:36:44 <boxscape> okay, thank you
01:37:01 <__monty__> Neither of the committee lists is archived there yet though.
01:37:15 <boxscape> :/
01:37:25 <boxscape> the site: search should work at least
01:37:31 <boxscape> so that's good
01:38:00 <maxsu> hrm, google's search does not return any results on the word "burrito", this troubles me
01:38:18 <boxscape> hmmm
01:41:28 <maxsu> now I'm just typing random category theory terms to see what comes up
01:42:43 <Phyx-> @tell fog, that just means you need to initialize opengl. These packages have an init function you need to call in main to set things up before you can use it. 
01:42:43 <lambdabot> Consider it noted.
01:42:46 <__monty__> maxsu: Like "banana" or "barbed wire?"
01:43:08 <maxsu> like span/cospan, monad/comonad, etc
01:44:19 <maerwald> Ghc 8.8.3 is released? 
01:56:37 <__monty__> maerwald: Not afaict.
01:56:48 <maerwald> Check the downloads
01:56:51 <maerwald> It's there
01:58:26 <maerwald> https://downloads.haskell.org/~ghc/8.8.3/
02:12:21 <maerwald> Seems its a prerelease 
02:31:07 <rindolf> maerwald: hi, sup?
02:31:57 <rindolf> maerwald: i got your optimised program to run - it is about 19s here - still slower than cpython3.
02:32:17 <maerwald> Yes, here it's 14s
02:32:43 <maerwald> So the cost point went from 82 to 70 % roughly and is still the map inserts
02:33:50 <maerwald> Also, did you use the latest commit? I added mutation instead of lookup/insert
02:54:16 <zceejkr> ski: are you around?
02:54:56 <rindolf> maerwald: i cloned it about two hours ago
03:00:24 <maerwald> I think the only optimisation left is to not build the maps at all :p
03:27:52 <olligobber> just updated ghc and the bug still seems to be present
03:38:05 <olligobber> oh, I figured out why
04:11:28 <rindolf> maerwald: ah
04:35:24 * hackage rebase 1.5 - A more progressive alternative to the "base" package  https://hackage.haskell.org/package/rebase-1.5 (NikitaVolkov)
04:40:29 <boxscape> regarding the function `lazy`, the docs say "it is lazy in its first argument, even though its semantics is strict." what does this mean? it seems contradictory (surely to know if something will be bottom according to strict semantics, you have to evaluate it even if it's never needed, going against lazy evaluation?)
04:41:49 <fog> under; instance Monad (P s) in https://downloads.haskell.org/~ghc/8.0.1-rc2/docs/html/libraries/Cabal-1.23.1.0/src/Distribution-Compat-ReadP.html
04:42:01 <fog> there is an implementation of the function "fail"
04:42:14 <fog> which is not part of the class Monad
04:42:28 <fog> which is causing something im trying to build to fail
04:43:48 <boxscape> fog fail was taken out of the Monad class in ghc 8.8
04:44:04 <fog> rrg
04:44:48 <fog> is there a flag i can pass to cabal to get it to use a different ghc?
04:45:21 <fog> stack has installed plenty, and i guess i could build something using a different resolver to get a previous version on the PATH
04:46:20 <boxscape> here's some info on how to use multiple cabal versions https://stackoverflow.com/questions/7770100/using-cabal-with-multiple-ghc-versions
04:46:30 <boxscape> why are you trying to build cabal 1.23?
04:46:36 <fog> idk
04:46:56 <__monty__> #buildingisitsownreward : )
04:46:59 <fog> i just cloned a git repo and typed cabal v2-run example --allow-newer
04:47:37 <boxscape> interestingly hackage has cabal 1.22 and cabal 1.24 but not 1.23
04:48:03 <Fleuv> Hello anyone else running into issues with stack on aarch64? I got: Unable to find installation URLs for OS key: linux-aarch64-tinfo6
04:48:39 <Fleuv> I found this issue: https://github.com/commercialhaskell/stack/issues/3268 but it seems to be for: linux64-ncurses6-nopie
05:00:09 <dminuoso> boxscape: See Note [lazyId Magic] in compiler/basicTypes/MkId.hs
05:01:37 <dminuoso> boxscape: It might be interesting to note that: pseq x y = x `seq` lazy y
05:01:49 <dminuoso> boxscape: The important difference here is that: non-strict is not the same as lazy
05:02:12 <dminuoso> (lazyness is just a particular form of non-strictness)
05:02:49 <fog> here is what i was trying to build; https://github.com/fog-hs/sdl-diagrams
05:02:58 <fog> (sorry about it being in a zip)
05:03:19 <boxscape> dminuoso thanks, I'll take a look
05:03:24 * hackage yate 0.1.0.3 - Yet Another Template Engine  https://hackage.haskell.org/package/yate-0.1.0.3 (thoferon)
05:03:40 <dminuoso> boxscape: Also take a look at the comment right above the definition of pseq.
05:03:45 <boxscape> okay
05:04:44 <fog> its trying to mix a bunch of repos from cchalmers
05:04:45 <fog> packages: diagrams/ diagrams-sdl/ diagrams-gl/ geometry/ letters/
05:05:01 <fog> https://github.com/cchalmers/plots
05:05:41 <fog> the idea is to get it to work using his version of diagrams with a sdl backend 
05:07:33 <fog> there was this with a ghcjs backend; http://bergey.github.io/gooey/diagrams-reflex-follow/
05:08:10 <fog> i think im out of my depth here, but it would be like; plots-diagrams-reflex-sdl
05:08:18 <boxscape> lazy :: forall a?. a? -> a?   (i.e. works for unboxed types too)
05:08:24 <boxscape> and yet
05:08:25 <boxscape> % :t GHC.Exts.lazy 4#
05:08:26 <yahb> boxscape: ; <interactive>:1:15: error:; * Couldn't match a lifted type with an unlifted type; When matching types; a :: *; Int# :: TYPE 'GHC.Exts.IntRep; * In the first argument of `GHC.Exts.lazy', namely `4#'; In the expression: GHC.Exts.lazy 4#
05:08:27 <boxscape> hmm
05:08:29 <fog> the i could get live streaming graphs  
05:09:48 <fog> i almost had all the pieces together, but after this build error i think i forgot why i thought it would be within my capability... 
05:11:19 <dminuoso> boxscape: The documentation might have drifted
05:11:39 <boxscape> I see
05:11:52 <fishooter> hi, how can I write a function which has signature
05:11:53 <fishooter> (a->b) -> [[a]] -> [[b]]
05:12:05 <boxscape> was a? some sort of semi-official notation before we had levity polymorphism?
05:12:05 <dminuoso> % :t fmap . fmap
05:12:05 <yahb> dminuoso: (Functor f1, Functor f2) => (a -> b) -> f1 (f2 a) -> f1 (f2 b)
05:12:07 <fishooter> I found something at hoogle, but I don't want to import packages
05:12:08 <fog> oh, yeah, to reproduce the error after cloning and unzipping its; cabal v2-run simple --allow-newer
05:12:08 <dminuoso> fishooter: ^-
05:12:16 <dminuoso> Or, if you want it monomorphized to just lists
05:12:19 <dminuoso> % :t map . map
05:12:20 <yahb> dminuoso: (a -> b) -> [[a]] -> [[b]]
05:12:31 <fishooter> ah, alright :) thank you! 
05:13:22 <dminuoso> boxscape: Perhaps. If you look at the definition of lazyId you will see that it uses setNeverLevPoly
05:13:38 <dminuoso> So it explicitly is not levity polymorphic.
05:14:05 <boxscape> okay
05:15:18 <dminuoso> Judging from what I see, one of the main motivitations for `lazy` appears to be the implementation of catch#
05:15:44 <dminuoso> (Such that catch# is call-by-name, rather than call-by-value)
05:16:12 <boxscape> right, ok
05:16:20 <dminuoso> Though for the finer details, its probably easier to ask on the mailing list
05:26:40 <boxscape> "We have (as of August 2006) unified types and kinds as members of the datatype Type"
05:26:41 <boxscape> huh
05:26:46 <boxscape> I thought that happened in like
05:26:55 <boxscape> 2016 or something
05:27:22 <boxscape> (from https://gitlab.haskell.org/ghc/ghc/wikis/intermediate-types#KindsareTypes)
05:27:48 <boxscape> (though obviously changes have happened since then)
05:32:08 <dminuoso> boxscape: The article is that old.
05:32:25 <dminuoso> https://gitlab.haskell.org/ghc/ghc/wikis/intermediate-types?version_id=bb8a0e0510b5e00a930fbc013e1dff3d7a05e79a
05:32:29 <dminuoso> This is the 13 year old version of that
05:33:08 <dminuoso> What you are thinking of, is the TypeInType that has become
05:33:18 <dminuoso> Available since 8.0, which I guess is 4 years old?
05:33:51 <dminuoso> But it is curious indeed
05:34:05 <dminuoso> Perhaps GHC has been lying to us for a long time? :)
05:34:23 <fishooter> is there a way to simplify this function?
05:34:24 <fishooter> map f ( (map . map) g (map h xs) )
05:34:31 <fishooter> where f g h xs are given
05:35:07 <dminuoso> @pl \f g h xs -> map f ( (map . map) g (map h xs) )
05:35:08 <lambdabot> (. ((. map) . (.) . map . map)) . (.) . (.) . map
05:35:37 <merijn> "(map . map) g" is just "map (map g)" "map (map g) (map h xs)" in turn is just "map (map g . h) xs"
05:36:03 <merijn> And "map f (map (map g . h) xs)" is simply "map (f . map g . h) xs"
05:36:24 <dminuoso> fishooter: Decompose into more functions.
05:36:35 <merijn> dminuoso: Not really necessary, imo
05:36:50 <merijn> dminuoso: If you flatten out all the redundant maps it's plenty readable
05:36:53 * hackage reanimate 0.2.0.1 - Animation library based on SVGs.  https://hackage.haskell.org/package/reanimate-0.2.0.1 (DavidHimmelstrup)
05:37:52 <dminuoso> merijn: At the very least I'd do `let q = f . fmap g . h in q <$> xs`
05:38:02 <dminuoso> (Or where-equivalent)
05:38:23 <dminuoso> If q, f, g and h have sensible naming, this is likely more readable
05:39:18 <dminuoso> Plus, decomposing into more bindings is generally good practice for nested code like this - reduces chances of subtle bugs that are annoying to figure out if type inference found some type for the wrong code.
05:39:27 <dminuoso> Type errors in other places..
05:39:37 <boxscape> dminuoso yeah, I didn't think it was TypeInType, but I *did* think that it wasn't this way before TypeInType
05:40:25 <boxscape> s/*did* think/*had* thought
05:42:34 <dminuoso> boxscape: Ah I think the confusion might stem from the name of the datatype Type
05:42:55 <dminuoso> boxscape: To state that "types and kinds are members of the datatype Type" is a vastly different statement from "kinds are types"
05:42:55 <Poscat[m]> Hi all. Are there any tools that can generate module exports? It's quite tedious to add them by hand.
05:43:07 <boxscape> dminuoso hm, that's true
05:43:29 <merijn> Poscat[m]: If you're just exporting everything you can simply leave out the export list
05:44:53 <dminuoso> boxscape: So reading further, "Kind is just a synonym for Type" must be understood as a statement about the source code of GHC.
05:45:02 <dminuoso> boxscape: Not as semantics of Haskell itself.
05:45:13 <Poscat[m]> I don't want to export everything. It would be nice if I can generate all the exports and then delete the unneeded ones.
05:45:14 <boxscape> okay
05:45:58 <dminuoso> boxscape: https://hackage.haskell.org/package/ghc-lib-parser-8.8.2.20200205/docs/src/TyCoRep.html#Kind
05:47:05 <dminuoso> c.f. Type :: Type
05:47:21 <boxscape> dminuoso so, when they say "members of Type", they don't mean "Int :: Type", but rather something along the lines of the AST node for Int in a program being an element of Type?
05:47:35 <dminuoso> No
05:48:41 <dminuoso> boxscape: GHC is a Haskell program. As such, programs are represented using ADTs. Types are represented by `data Type = TyVarTy ... | AppTy ... | TyConApp ... | ForaAllTy ... | FunTy ... | LitTy ... | CastTy ... | CoercionTy ...
05:48:51 <dminuoso> boxscape: What the article is saying, that kinds use that same data type
05:49:22 <boxscape> hm maybe I expressed myself poorly but so far it doesn't seem like that disagrees with what I said
05:50:54 * hackage cabal-rpm 2.0.3 - RPM packaging tool for Haskell Cabal-based packages  https://hackage.haskell.org/package/cabal-rpm-2.0.3 (JensPetersen)
05:51:20 <dminuoso> Poscat[m]: You could use sed to grab all top level declarations.
05:51:38 <dminuoso> (type declarations should be easiest to grab)
05:51:58 <mark_stopka> Hi, I am trying to figure out conditional build of binaries using cabal flags with stack
05:52:58 <mark_stopka> But I am getting following when building
05:53:00 <mark_stopka> Cabal file warning in/usr/src/cardano-node/cardano-node/cardano-node.cabal@220:1: Ignoring section: "if"
05:53:44 <mark_stopka> my Cabal file contains condition like
05:53:45 <mark_stopka> if flag(with_wallet-client)
05:54:32 <mark_stopka> and Flag definition:
05:54:35 <mark_stopka> Flag with_wallet-client
05:55:12 <mark_stopka> this however results in mentioned warnings: stack install --flag cardano-node:-with_wallet-client
05:57:01 <fishooter> how can I sum tuples?
05:57:02 <fishooter> ie (1,2) + (2,3)
05:57:11 <fishooter> == (3, 5)
05:57:38 <zceejkr> Maybe define instance of Num for (Int, Int)?
05:57:44 <phadej> sumTuple (x,y) (u,v) = (x + u, y + v)
05:57:47 <Rembane> > ((+) *** (+)) (1,2) (2,3)
05:57:50 <lambdabot>  error:
05:57:50 <lambdabot>      â€¢ Couldn't match type â€˜(Integer -> Integer, Integer -> Integer)â€™
05:57:50 <lambdabot>                       with â€˜(Integer, Integer) -> tâ€™
05:58:08 <Rembane> Meh, I vote for phadej's solution.
05:58:12 <fishooter> I thought there might be already something "standard" :)
05:58:22 <fishooter> but I guess I'll go with phadej suggestion
05:58:36 <phadej> there is packages like `linear` which have data V2 a = V2 !a !a
05:58:41 <phadej> and operators on them
05:58:52 <fishooter> yep, because it'
05:58:57 <fishooter> it's like summing vectors
05:59:06 <Putonlalla> There's `biliftA2` in `base` already.
05:59:08 <phadej> using tuples (and not specific type) is semantically not right
05:59:34 <phadej> "stringly-programming" extended to  "structural programming"
05:59:55 <phadej> most often wrong thing to do, just define a type. It's "free" at run time
06:00:15 <fishooter> phadej: unfortunately it's a library that doesn't support it
06:00:15 <fishooter> https://hackage.haskell.org/package/gloss-1.13.1.1/docs/Graphics-Gloss-Data-Picture.html#t:Point
06:00:27 <fishooter> I'd be more happy if it were newtype
06:01:09 <dminuoso> Mmm, could we implement this with lens as well? Im thinking of partsOf here.
06:02:01 <phadej> fishooter: yes, gloss would benefit from using `linear` (or vendoring needed parts, vs. just using bare pair of floats for everything)
06:02:22 <phadej> I'm also in favor of having separate types for positions and vectors
06:02:38 <phadej> (you cannot add positions together, for example, it doesn't make any sense)
06:02:44 <boxscape> % join biliftA2 (+) (1,2) (3,4)
06:02:44 <yahb> boxscape: (4,6)
06:02:52 <fishooter> phadej: sure, makes sense
06:04:17 <boxscape> hm if we had idiom brackets would it make sense to have biidiom brackets for biapplicatives
06:04:37 <boxscape> and can you make a sensible bimonad
06:04:43 <boxscape> I'm guessing no because it's not in hoggle
06:04:47 <boxscape> hoogle*
06:09:08 <ziman> @pl \f g -> g . f
06:09:09 <lambdabot> flip (.)
06:10:04 <boxscape> :t( >>>)
06:10:10 <boxscape> :t (>>>)
06:10:12 <lambdabot> forall k (cat :: k -> k -> *) (a :: k) (b :: k) (c :: k). Category cat => cat a b -> cat b c -> cat a c
06:11:04 <boxscape> % :t (>>>) @(->)
06:11:05 <yahb> boxscape: (a -> b) -> (b -> c) -> a -> c
06:11:31 <ziman> thank you :)
06:11:42 <boxscape> welcome
06:12:00 <phadej> :t (&&&)
06:12:02 <lambdabot> Arrow a => a b c -> a b c' -> a b (c, c')
06:12:06 <phadej> :t (***)
06:12:08 <lambdabot> Arrow a => a b c -> a b' c' -> a (b, b') (c, c')
06:13:11 <ziman> :t (<&>) :: (a -> b) -> (b -> c) -> (a -> c)  -- looks like this works, too
06:13:13 <lambdabot> (a -> b) -> (b -> c) -> a -> c
06:13:38 <boxscape> actually why does (>>>) @(->) even work? shouldn't it expect the k first rather than cat?
06:14:02 <ziman> it doesn't parse in my ghci; i suspect it's a hack in \bot
06:14:28 <boxscape> ziman I'm using the TypeApplication extension to specialize the type to ->
06:14:47 <MarcelineVQ> :t (>>>)
06:14:49 <lambdabot> forall k (cat :: k -> k -> *) (a :: k) (b :: k) (c :: k). Category cat => cat a b -> cat b c -> cat a c
06:15:02 <MarcelineVQ> hmm
06:15:25 <boxscape> % :t (>>>) @_ @(->)
06:15:25 <yahb> boxscape: Category w => w (->) b -> w b c -> w (->) c
06:15:26 <ziman> that's strange, the module I've got loaded uses TypeApplications but apparently I can't use them in the repl
06:15:29 <MarcelineVQ> odd, that's not what my ghci gives
06:15:49 <Lears> Maybe yahb's ghc isn't new enough to have visible kind application, so k is always inferred?
06:16:05 <boxscape> ziman you have to enable it in the REPL separately, with :seti -XTypeApplications 
06:16:12 <boxscape> Lears oh, you're right
06:16:22 <boxscape> visible kind application was introduced in 8.8
06:16:42 <boxscape> % System.Info.compilerVersion
06:16:42 <yahb> boxscape: Version {versionBranch = [8,6], versionTags = []}
06:17:06 <boxscape> Lears I never realized that visible kind application applies to the term level as well
06:18:27 <Zemyla> How do I propose a change to the GHC Array library?
06:19:43 <yushyin> https://gitlab.haskell.org/ghc/packages/array you file an issue/make a merge request
06:20:05 <boxscape> Zemyla https://wiki.haskell.org/Library_submissions
06:21:24 * hackage stylish-haskell 0.11.0.0 - Haskell code prettifier  https://hackage.haskell.org/package/stylish-haskell-0.11.0.0 (JasperVanDerJeugt)
06:24:38 <boxscape> Lears never mind, you're not right :( it still happens on 8.11
06:27:00 <boxscape> oh but wait
06:27:12 <boxscape> the type on 8.11 doesn't include k
06:27:47 <boxscape> oh I probably have to enable PolyKinds to see it
06:28:08 <boxscape> % :t +v (>>>)
06:28:09 <yahb> boxscape: forall k (cat :: k -> k -> *) (a :: k) (b :: k) (c :: k). Category cat => cat a b -> cat b c -> cat a c
06:28:16 <boxscape> this is in fact different on 8.11
06:28:27 <boxscape> it's forall {k} (cat :: ....
06:28:59 <MarcelineVQ> % :set -fprint-explicit-foralls
06:29:00 <yahb> MarcelineVQ: 
06:29:08 <MarcelineVQ> % :t +v (>>>)
06:29:08 <yahb> MarcelineVQ: forall {k} (cat :: k -> k -> *) (a :: k) (b :: k) (c :: k). Category cat => cat a b -> cat b c -> cat a c
06:29:17 <boxscape> oh
06:29:25 <boxscape> how odd that explicit foralls changes that
06:29:26 <MarcelineVQ> confusing shit
06:29:37 <boxscape> where does the k come from anyway
06:29:45 <boxscape> are things kind polymorphic by default?
06:30:03 <boxscape> because it's nowhere to be seen in Control.Category as far as I can tell
06:31:32 <boxscape> % class Foo f where foo :: f a
06:31:33 <yahb> boxscape: 
06:31:36 <boxscape> % :k Foo
06:31:36 <yahb> boxscape: Foo :: forall {k}. (k -> *) -> Constraint
06:31:41 <boxscape> the answer is yes
06:31:42 <dminuoso> boxscape: PolyKinds is enabled in yahb
06:31:46 <nshepperd> PolyKinds makes things kind polymorphic by default
06:31:49 <boxscape> I see
06:31:59 <nshepperd> Control.Category has it enabled
06:32:36 <dminuoso> nshepperd: Mmm, doesn't GHC monomorphize when the import modules does not have it enabled?
06:34:25 <nshepperd> i don't see why it would
06:35:06 <boxscape> hm would it make an observable difference?
06:35:20 <dminuoso> Sure, it would.
06:35:46 <dminuoso> Consider the validity of `Const [] Int`
06:35:53 <dminuoso> Err, `Const Int []`, of course.
06:36:05 <dminuoso> Whether or not that kind checks depends on whether PolyKinds is on
06:36:38 <boxscape> could you enter it if Const is polymorphic and PolyKinds is off?
06:36:56 <boxscape> s/enter/compile
06:37:36 <dminuoso> nshepperd: Ah you are right. It needs to be in the module where its defined in.
06:37:49 <dminuoso> boxscape: Yes you can.
06:37:55 <dminuoso> Just checked. :)
06:38:17 <boxscape> okay, fair enough
06:38:54 <dminuoso> I must have misremembered this.
06:42:10 <nshepperd> well, it is true that if you don't have polykinds enabled locally, ghc won't generalize the kind variable of >>> after instantiating it somewhere
06:42:54 <nshepperd> but that doesn't matter for usage
06:43:46 <nshepperd> but it means that :t +v id (>>>) will show {cat :: * -> * -> *}
06:47:45 <Zemyla> boxscape: I sent a message to libraries@haskell.org. Can you tell if it looks right?
06:47:49 <boxscape> cat has round brackets but yeah
06:48:16 <boxscape> Zemyla I have no authority on this process
06:48:18 <Zemyla> If my cat had round brackets, he'd be chewing them off.
06:49:09 <Zemyla> For reference: https://cdn.discordapp.com/attachments/417384819828326428/681316756476002403/20200221_225648.jpg
06:50:55 <boxscape> cute
07:03:22 <ski> zceejkr : 12meow ?
07:06:04 <zceejkr> ski: hi
07:06:40 <ski> there you are
07:07:00 <zceejkr> Are you available to continue with exsistentials?
07:07:06 <ski> yea
07:07:10 <ski> you ?
07:07:18 <zceejkr> Awesome. I am also.
07:08:00 <ski> hm, so i realized i actually broke off an example of rank two, middleways, last time
07:08:17 <ski> would you like to continue with that ?
07:09:02 <zceejkr> Sure. I think we ended with somehing elated with the fix operator. I am still a little confused about that one.
07:09:28 <ski> it was supposed to be an example of how one could use rank two, not in order to specialize the polymorphic argument at several different types, but rather about how one could use rank two for information/implementation hiding purposes
07:09:50 <ski> yea, so maybe we'll rehash `fix' a bit at first, then
07:10:24 <ski> (and hopefully, this time, Sigyn will warn first, in case she becomes annoyed, like she usually does)
07:10:52 <ski>   fix :: forall a. (a -> a) -> a
07:10:55 <ski>   fix f = x
07:10:57 <ski>     where
07:10:59 <ski>     x = f x
07:11:08 <ski> how much sense does that make to you ?
07:12:27 <zceejkr> Hmm. A little.
07:12:34 <ski> we get a function, `f', of type `a -> a', as input, and then we feed the result `x' of calling that function `f' back as the input of the same call to `f'. that `x' is then the result of `fix f'
07:12:46 <ski> @type (False :)
07:12:48 <lambdabot> [Bool] -> [Bool]
07:13:10 <ski> > map (False :) [[],[False],[True],[False,True],[True,False]]
07:13:13 <lambdabot>  [[False],[False,False],[False,True],[False,False,True],[False,True,False]]
07:13:31 <ski> `(False :)' is the function that prepends a single `False' in front of a list of `Bool'eans
07:14:09 <ski> we can call `fix' on this function (so `a -> a' unifies with `[Bool] -> [Bool]', making `a' specialize to `[Bool]')
07:14:17 <ski> > fix (False :)
07:14:19 <lambdabot>  [False,False,False,False,False,False,False,False,False,False,False,False,Fal...
07:14:46 <ski> and we get an infinite list of `False'. the list that, when prepended with `False', yields the same list
07:14:55 <zceejkr> I see.
07:15:09 <ski> we can write a "trace" of this as
07:15:14 <ski>      fix (False :)
07:15:31 <ski>   =  x  where x = (False :) x
07:15:35 <ski>   =  x  where x = False : x
07:15:44 <ski>   =  False : x  where x = False : x
07:15:51 <ski>   =  False : False : x  where x = False : x
07:15:55 <ski>   =  ...
07:16:44 <ski> (here i write `..x..  where x = ...' which isn't actually a valid expression in Haskell, rather than the more proper `let x = ... in ..x..', just because the former looks more readable here)
07:17:17 <fishooter> suppose that I have a function like
07:17:17 <fishooter> myFun = f g xs
07:17:17 <fishooter>   where f = ...
07:17:18 <fishooter>         g = ...
07:17:21 <ski> in terms of implementation, you can think of `x = False : x' as allocating a single list cons cell, whose tail points to the same cell. so a cyclic implementation
07:17:30 <fishooter> is it possible to ask ghci for type of f?
07:17:37 <fishooter> something like :t f in myFun
07:18:07 <ski> not really, i think (maybe if one uses the GHCi debugger, i can't recall), fishooter
07:18:35 <fishooter> the only thing that I've come up with is to put a hole there
07:18:37 <ski> in case `f' doesn't depend on parameters of `myFun', you can temporarily lift it out of the `where', to the top-level, and then ask the interactor
07:18:45 <fishooter> but then I have to go back-and-forth from code to ghci
07:18:59 <ski> that's standard practice, anyway
07:18:59 <fishooter> ski: sure
07:19:06 <MarcelineVQ> you can also asset a wrong type. f ::â€‹ a; f = ...
07:19:12 <MarcelineVQ> *assert
07:19:12 <ski> yea
07:19:56 <ski> zceejkr : you follow the above reduction/evaluation trace ?
07:20:07 <zceejkr> I do.
07:20:15 <ski> ok, so how about
07:20:28 <ski> > fix (\fibs -> 0 : 1 : zipWith (+) fibs (tail fibs))
07:20:33 <lambdabot>  [0,1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946,...
07:20:34 <ski> (a classic example)
07:20:57 <zceejkr> :t zipWith
07:20:58 <ski> do you see how that one works ?
07:20:58 <lambdabot> (a -> b -> c) -> [a] -> [b] -> [c]
07:21:15 <ski> > zipWith (+) [0,1,2] [300,400,500]
07:21:17 <lambdabot>  [300,401,502]
07:21:25 <fishooter> MarcelineVQ: are you suggesting this?
07:21:26 <geekosaur> you can combin that with the hole by asserting f :: _
07:21:29 <fishooter> myFun = f g xs where f :: A; f = ...
07:21:47 <fishooter> myFun = f g xs
07:21:52 <fishooter>    where f :: A; f = ...
07:21:56 <MarcelineVQ> fishooter: if you want to know what type is being inferred for f
07:22:29 <geekosaur> well, strictly speaking it's a partial type signature, not a hole
07:22:47 <fishooter> cool, I didn't know about this syntax
07:23:01 <fishooter> any link for more examples like that?
07:23:14 <zceejkr> ski: I think I understand it. It creates a list of fibonacci numbers, and another one, offset by one, and adds them together.
07:23:40 <geekosaur> no, there's only one list
07:23:49 <geekosaur> it's zipped against itself offset by one
07:23:55 <ski> the list is recursively constructed from itself
07:24:00 <boxscape> fishooter https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#partial-type-signatures
07:24:01 <ski> `zipWith' is "chasing its own tail"
07:24:34 <ski> that `fix' call amounts to `fibs  where fibs = 0 : 1 : zipWith (+) fibs (tail fibs)'
07:26:17 <ski> would you like to see a trace, zceejkr ?
07:26:28 <zceejkr> If it's not too much of a hassel, yes.
07:26:43 <zceejkr> This one is a mind bender to me 
07:26:44 <ski> hm, perhaps i'll try pasting one at a paste site, actually
07:27:01 <boxscape> > fix (\fibs -> a : b : zipWith (+) fibs (tail fibs))
07:27:04 <lambdabot>  [a,b,a + b,b + (a + b),a + b + (b + (a + b)),b + (a + b) + (a + b + (b + (a ...
07:31:48 <boxscape> > fix (\fibs -> "O" : "-" : zipWith (<>) fibs (tail fibs))
07:31:50 <lambdabot>  ["O","-","O-","-O-","O--O-","-O-O--O-","O--O--O-O--O-","-O-O--O-O--O--O-O--O...
07:33:10 <zceejkr> boxscape: nice. 
07:34:30 <zceejkr> I assume this question shows my lack of undersatnding, but where does the first fibs come from?
07:35:17 <zceejkr> Does such a thing as the "first fibs" even make sense in this context?
07:35:47 <boxscape> there's only one fibs, but you're immediately declaring that the first two elements are 0 and 1
07:36:14 <boxscape> so you can use those while calculating the third element
07:37:03 <zceejkr> What I meant was, how does haskell find the value with which to kick-start the fix calls.
07:37:31 <boxscape> does it make more sense to you with "fibs = 0 : 1 : zipWith (+) fibs (tail fibs)" than with fix?
07:37:41 <comerijn> zceejkr: I find fix to be more obvious when using it to define a function
07:37:54 <comerijn> zceejkr: https://gist.github.com/merijn/b86649a6aa21bd140803
07:38:21 <comerijn> zceejkr: "What's the first argument to the lambda?" 'That same lambda'
07:39:54 <zceejkr> comerijn: this was helpful, thanks
07:40:58 <remexre> hm, if I have a type family, is there any way to assert that the type it returns meets a constraint?
07:41:05 <comerijn> zceejkr: This is all closely related to the notion of "tying the knot"
07:41:11 <comerijn> zceejkr: Do you happen to know C?
07:41:37 <int-e> > fix $ ("0" :) . scanl (flip (++)) "-"
07:41:40 <lambdabot>  ["0","-","0-","-0-","0--0-","-0-0--0-","0--0--0-0--0-","-0-0--0-0--0--0-0--0...
07:41:56 <hyperisco> remexre, C (F a) where C is your constraint and F is your family
07:41:57 <hodapp> ...did int-e just one-liner an L-system?
07:42:04 <zceejkr> boxscape: I think the one you wrote makes sense in english. In the sense: "The fibonacci sequence starts with 0 and 1, and every element is the sum of the previous two elements". I think "fibs = 0 : 1 : zipWith (+)
07:42:05 <zceejkr>            fibs (tail fibs)" matches that definition quite closely. 
07:42:29 <zceejkr> comerijn: I know a little bit of C. 
07:42:38 <comerijn> Does this code make sense? "struct list { int value; struct list *next; }; struct list ones = { 1, &ones };
07:42:40 <remexre> hyperisco: er, assert in such a way that I don't nede to prove it at the call site
07:42:57 <comerijn> (effectively an "infinite" linked list of ones in C)
07:43:32 <int-e> hodapp: Well, I really just wondered how the well-known  fix $ (0:) . scanl (+) 1  for the Fibonacci sequence relates to boxscape's variant of Fibonacci.
07:43:44 <boxscape> (ski brought up the variant)
07:43:44 <hyperisco> remexre, you can have your family return a kind that has a universal instance for your class
07:44:15 <boxscape> (or well I suppose you meant the string version)
07:44:56 <fishooter> how can I make block copies of Data.Array?
07:45:07 <fishooter> similarly to how you'd construct a matrix from block matrices
07:45:07 <hyperisco> remexre, you always have to prove it where it is used, but this makes it trivial
07:45:23 <fishooter> ie b = [[a, a], [a, a]]
07:45:31 <zceejkr> comerijn: this makes sense, yes.
07:45:31 <fishooter> in pseudocode
07:45:38 <fishooter> where a is Data.Array
07:45:41 <dmwit> fishooter: Just like that?
07:45:58 <dmwit> What goes wrong when you use exactly that code?
07:46:00 <fishooter> and the result b is Data.Array?
07:46:15 <dmwit> No, [[Array Whatever Whatever]].
07:46:19 <comerijn> zceejkr: So, constructing a self-referencing value like that is fairly straightforward in a language where everything is mutable, since you can simply first define a value and then mutate it to reference itself
07:46:33 <remexre> hyperisco: so this would be, instead of being Type -> Type, be Type -> ConstraintAndType, where data ConstraintAndType c a = MkCAT :: c a => a -> ConstraintAndType c a ?
07:46:51 <remexre> s/=/where/
07:46:59 <hyperisco> remexre, you cannot lift constraints
07:47:01 <fishooter> dmwit: any idea how to do it so b :: Data.Array? 
07:47:05 <comerijn> zceejkr: To accomplish the same in an immutable setting like Haskell you somehow need a reference to the final value you're going to build before you can actually build that value
07:47:09 <maralorn[m]> Sometimes I wonder if it would be cool to make recursivity opt-in in Haskell. Like: You have to use "fix" everytime which is a builtin or a bind has to be annotated explicitly with rec, like a bit like a "let mut" in rust.
07:47:21 <dmwit> You can use listArray to turn that into Array Whatever1 (Array Whatever2 (Array OriginalWhatever OtherOriginalWhatever)).
07:47:26 <remexre> hyperisco: then I'm not sure what you mean, sorry
07:47:34 <hyperisco> remexre, I do mean though that instead of Type you name a kind for which you can provide an instance for all types of that kind
07:47:43 <int-e> comerijn: There is mutation in Haskell, just enough to allow creating circular references.
07:47:43 <comerijn> zceejkr: Consider the case of "let ones = 1 : ones" in Haskell. That's straightforward, but what if we didn't have recursive names, so that definition is not allowed?
07:47:48 <maralorn[m]> I have shot myself in the foot a few times with accidental recursivity. Itâ€˜s like the one thing the compiler does not warn you about.
07:47:54 <dmwit> (`Data.Array` is not a concrete type. So the request cannot be realized exactly as stated.)
07:48:04 <comerijn> int-e: Irrelevant to my explanation because that's not necessarily about Haskell
07:48:18 <dmwit> (`Data.Array` is a module. `Data.Array.Array` is a type constructor which needs two more arguments to be a concrete type.)
07:48:30 <remexre> hyperisco: uh, I think I need an example
07:48:59 <hyperisco> instance MyClass (a :: MyKind) where ...
07:49:04 <comerijn> zceejkr: This is what the "fix" primitive provides "IFF you give me a reference to the final result, I'll use that reference to actually build that result"
07:49:22 <comerijn> zceejkr: We can mimic the "ones" definition above with fix as
07:49:25 <remexre> hyperisco: I mean what the kind would look like
07:49:28 <comerijn> > fix (1:)
07:49:31 <lambdabot>  [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1...
07:49:40 <hyperisco> not sure, you'd have to figure that out
07:50:09 <comerijn> zceejkr: "If you give me a reference to the final infinite list of ones, I can build one by having '1' followed by that list"
07:50:42 <comerijn> zceejkr: Note the symmetry between "fix (1:)" and "let ones = (1:) ones", we simply got rid of the name!
07:51:46 <ski> zceejkr : <https://paste.debian.net/1131907/>
07:52:09 <zceejkr> comerijn: I see. This is quite helpful. 
07:53:59 <zceejkr> comerijn: I think I also undersatnd this one now:  fix (\fibs -> 0 : 1 : zipWith (+) fibs (tail fibs)). It is basically inductive definition of the fibonacci sequence. "We can build fibs by starting with 0,1 and suming fibs and fibs offset to the left by 1".
07:54:21 <zceejkr> The fibs is just the name we use to refer to the final result.
07:54:51 <zceejkr> ski: thank you, looking now.
07:56:55 <comerijn> zceejkr: Right
07:57:30 <zceejkr> so the we can always think of the argument x in fix (\x -> ...) as basically the result of (fix (\x -> ...)) itself?
07:57:39 <comerijn> zceejkr: Yes
07:58:51 <ski> yes, which is also the result of `...' there
07:59:36 <ski> zceejkr : does the trace, with explanatory reasons for each step, make sense to you ?
08:00:07 <zceejkr> still reading. Thanks so much for the effort
08:01:10 <ski> hm, i see at one point i did both a force of `fibs1' and `fibs2', in one step, rather than in two separate steps .. oh well
08:06:08 <ski> (the GC steps can of course happen at any later time, as well. i put then in as soon as they could be applied)
08:08:04 <zceejkr> ski: got it. This was very helpful, thanks.
08:08:15 <ski> you can think of the current state of the computation roughly as `<(previously computed parts of result and) currently active and suspended calls (stack)>  where  <bindings heap, sometimes with active calls shown>'
08:09:07 <ski> note that `fibs' is not exponential in computing the `n'th element, because previous values are cached in previous elements of the list
08:09:46 <ski> so, `fibs' is a (simple) example of (bottom-up) dynamic programming (keeping track of the last two results)
08:10:39 <ski> (well, at least if you force each element, as you pass it (as printing a prefix of the list will do). if you start by traversing to an element, and only force that one, it will be top-down dynamic programming)
08:11:48 <patrl> I stumbled across a very useful continuationy function -- I was wondering if anyone can help me identify what it is (hoogle has failed me)
08:12:08 <ski> > fix (\fibs -> listArray (0,12) [case n of 0 -> 0; 1 -> 1; _ -> fibs ! (n-1) + fibs ! (n-2) | n <- range (0,12)]) ! 12
08:12:09 <patrl> (**) :: Monad m => m ((a -> b) -> c) -> (a -> m b) -> m c
08:12:11 <lambdabot>  144
08:12:16 <boxscape> ski so if the GC step happens instantly, the memory usage of `fibs !! n` is constant in n?
08:12:25 <ski> is another dynamic programming example, in this case defining an array recursively
08:12:51 <ski> boxscape : yes. even if it only happens "often enough"
08:12:55 <boxscape> neat
08:13:07 <boxscape> and yeah that makes sense
08:13:32 <ski> boxscape : this "streaming" facility can e.g. be used to process lists (maybe coming from a file or network stream) which wouldn't fit in memory all at the same time
08:13:46 <boxscape> I see
08:14:17 <zceejkr> ski: does "often enough" mean garbage colletion is happening at a higher frequency than "user forcing" frequency
08:15:42 <ski> imagine "amortized something something"
08:16:32 <ski> doesn't have to happen more often than the forcing. multiple things can be GCed in a single GC phase
08:16:57 <zceejkr> i see.
08:17:08 <aveltras> anyone having example of using lucid with HtmlT transformer ? i'd like to use it for a Reader context but i don't get how to go from HtmlT (Reader Int) () to HtmlT Identity ()
08:17:30 <ski> recursively defining an (immutable) array (or other data structure, sometimes, as the list above), can be a nice way to do some dynamic programming algorithms, in Haskell
08:17:45 <dmj`> aveltras: why not just pass in the value as a function, since that's iso to reader
08:17:50 * ski idly looks at patrl
08:18:58 <aveltras> dmj`: i want to use it for some kind of context for all the views in a website (Int here is just an example), passing the value in every handler is a bit cumbersome
08:19:15 <ski> patrl : i don't see how you could implement `(**)'
08:19:36 <ski> (for every monad `m', that is)
08:20:26 <ski> patrl : even if you replace `Monad m' with `MonadCont m', i think it can't be done
08:20:47 <ski> patrl : maybe for some particular `m' you have in mind ?
08:21:07 <ski> zceejkr : hm, so, we'll continue ?
08:21:36 <ski> or do you want to process the array example a bit more ?
08:21:49 <zceejkr> I think I got it. We can continue
08:22:34 <ski> hm, so how about this example :
08:22:56 <ski> > fix (\fact n -> if n == 0 then 1 else n * fact (n - 1)) 12
08:22:59 <lambdabot>  479001600
08:23:16 <ski> can you follow that ?
08:23:22 <zceejkr> yep
08:23:37 <zceejkr> oh wait
08:23:38 <ski> this is "simpler" in some sense, than the previous case
08:23:48 <zceejkr> 2 args now
08:24:04 <ski> yes. remember `\x y -> ..x..y..' means `\x -> \y -> ..x..y..'
08:24:15 <ski> (there's a slight pattern-matching difference, but it doesn't matter here)
08:25:42 <zceejkr> got it
08:26:50 <ski> so, considering `fix :: forall a. (a -> a) -> a', in this case that got specialized (assuming `Integer') to `fix :: ((Integer -> Integer) -> Integer -> Integer) -> Integer -> Integer'
08:27:34 <zceejkr> yep
08:27:50 <ski> now, by using a modified version of `fix', one can "instrument" the recursive calls, since we've factored out the recursion into `fix'
08:28:08 <ski> so, repeating, we had the example
08:28:13 <ski>   fib :: Integer -> Integer
08:28:16 <ski>   fib 0 = 0
08:28:19 <ski>   fib 1 = 1
08:28:24 * hackage myxine-client 0.0.0.2 - A Haskell client for the Myxine GUI server  https://hackage.haskell.org/package/myxine-client-0.0.0.2 (kwf)
08:28:26 <ski>   fib n = fib (n-1) + fib (n-2)
08:28:39 <ski> and a `data' type
08:28:44 <ski>   data Tree a = Node a [Tree a]
08:28:50 <ski> with a synonym
08:29:00 <ski>   type Traced i o = (o,Tree (i,o))
08:29:20 <ski> to represent the (recursive) call structure (of a single function, with input of type `i' and output of type `o')
08:29:29 <ski> so, we'd like to arrive at
08:29:44 <ski>   tracedFib :: Integer -> Traced Integer Integer
08:29:49 <ski> in some principled fashion
08:29:57 <ski> starting from something like
08:30:12 <ski>   fibThen :: (Integer -> Integer) -> Integer -> Integer
08:30:19 <ski>   fibThen fib 0 = 0
08:30:21 <ski>   fibThen fib 1 = 1
08:30:29 <ski>   fibThen fib n = fib (n-1) + fib (n-2)
08:30:38 <ski> note that `fib = fix fibThen'
08:30:44 <dmj`> aveltras: https://gist.github.com/996959732bab90f381e5dd4bf53f7448
08:30:48 <dmj`> aveltras: here's an example
08:31:14 <ski> ok so far, with the recap, zceejkr ?
08:31:23 <zceejkr> yes.
08:32:06 <ski> however, the callback to `fibThen', of type `Integer -> Integer', isn't giving us much to go with, here
08:32:48 <ski> we could wrap a recursive call to `fibThen', inside a modified version of `fix', with some operation, but we're only in `Integer', can't fit much useful stuff in there
08:33:20 <ski> however, we could do a monadic version of `fibThen'
08:33:41 <ski>   fibThenM :: forall m. Monad m => (Integer -> m Integer) -> Integer -> m Integer
08:33:58 <ski>   fibThenM fibM 0 = return 0
08:34:01 <ski>   fibThenM fibM 1 = return 1
08:34:06 <aveltras> dmj`: i wanted to get back to Html () from HtmlT (Reader Int) () but this doesn't seem to be the way the library is supposed to be used, thanks for the example though !
08:34:08 <ski>   fibThenM fibM n = do
08:34:23 <ski>     fib_n1 <- fibM (n-1)
08:34:26 <ski>     fib_n2 <- fibM (n-2)
08:34:37 <ski>     return (fib_n1 + fib_n2)
08:34:50 <ski> or, we could abbreviate the last defining equation to just
08:35:07 <ski>   fibThenM fibM n = liftA2 (+) (fibM (n-1)) (fibM (n-2))
08:35:19 <ski> (`liftM2' would work just as well as `liftA2')
08:35:37 <dmj`> aveltras: operating in HtmlT (Reader Int) () would feel identical to Html (), just don't call ask. What's the reasoning for wanted to go from one to the other like that
08:35:42 <zceejkr> :t liftM2
08:35:44 <lambdabot> Monad m => (a1 -> a2 -> r) -> m a1 -> m a2 -> m r
08:35:53 <ski> note that `fibThenM' doesn't actually (itself) do any monadic effects on its own (that's why it can manage to be polymorphic in all monads `m')
08:36:16 <ski> or, more properly speaking, it only does the monadic effects that its callback does
08:36:45 <ski> it doesn't know which monad `m' it is using, and so it can't, on its own, introduce any monadic effects
08:37:30 <ski> which is what we want, since we're attempting to model a function (`fib') that doesn't do any effects, and so we prefer having a type here that doesn't admit any effects to be sneaked in in this part of the code
08:37:59 <aveltras> dmj`: hmm now that you say it, i don't really need to be in Html () indeed, i can replace everything with the transformer over reader version
08:38:36 <ski> however, since the callback is allowed to do `m'-effects, we could let our modified version of `fix' pass in a callback, that isn't just the result of calling `fibThenM' on this callback (which is what `fix' would do), but actually does sneak in some additional effects
08:38:44 <ski> in this case, logging effects
08:39:03 <ski> making sense, zceejkr ?
08:39:42 <zceejkr> yes
08:39:52 <aveltras> dmj`: thanks
08:40:19 <dmj`> aveltras: cool, np
08:40:27 <ski> so, `Writer [Traced i o]' could be used to log the recursive calls to the function with input `i' and output `o'
08:40:37 <ski> so, we want something like
08:41:59 <ski>   fixTrace :: forall i o. (..i..o..) -> i -> Writer [Traced i o] (Traced i o)
08:43:05 <ski> so that, in addition to computing the result and the trace tree of the current recursive call, in the monadic result of type `Traced i o', we're also collecting (logging) such result&trace-tree of sibling calls, in the `Writer [Traced i o]' part (the effect part)
08:43:25 <ski> spelling out the argument to `fixTrace', which would be `fibThenM' in our example
08:44:58 <ski>   fixTrace :: forall i o. ((i -> Writer [Traced i o] (Traced i o))
08:45:33 <ski>                          -> i -> Writer [Traced i o] (Traced i o) )
08:45:42 <ski>                        ->   i -> Writer [Traced i o] (Traced i o)
08:46:00 <ski> (a bit of a mouth-ful)
08:47:01 <ski> so, what `fixTrace fThen' does is it defines `f', by calling `fThen', not on `f', but on a wrapped version of `f' that collects the current logged calls, and puts them in a `Tree' in the result
08:47:18 <ski> (i'll omit the details. they're not that hard to figure out, although a little bit tedious)
08:48:28 <ski> in fact, we'll make one more adjustment. changing the final return type of `fixTrace' from `Writer [Traced i o] (Traced i o)' to just `Traced i o', since we don't need the log outside of `fixTrace' this is just a simple wrapper operation around the code i just hinted at
08:48:53 <ski> zceejkr : does that make more or less sense ?
08:49:18 <ski> well, let me summarize the current type signature
08:49:38 <ski>   fixTrace :: forall i o. ((i -> Writer [Traced i o] (Traced i o)) -> i -> Writer [Traced i o] (Traced i o)) -> i -> Traced i o
08:51:07 <zceejkr> Makes more ot less sense. Although I will say I have never used Writer. But I think I can imagine what it does.
08:51:16 <ski> @src Writer
08:51:16 <lambdabot> type Writer w = WriterT w Identity
08:51:16 <lambdabot> --OR
08:51:16 <lambdabot> data Writer w a = Writer { runWriter :: (a, w) }
08:51:36 <ski> `Writer w a' just amounts to the pair type `(a,w)'
08:52:10 <ski> and the monadic operations on `Writer w' just "concatenate" the `w' parts from sibling effects
08:52:28 <ski> here `w' is `[Traced i o]', so that's just simple list concatenation
08:52:49 <zceejkr> Got it.
08:53:01 <ski> now, that's the built-up to this example
08:53:28 <ski> while the type signature of `fibThen' ensures that it can't do any effects (other than the effects that its callback might do)
08:54:05 <ski> the type signature of `fixTrace' doesn't ensure that it's only passed a function that is "agnostic" in effects, in this way
08:54:22 <ski> (that might be good, bad, or indifferent. let's say it's one of the two latter, here)
08:54:53 <ski> worse, the type signature of `fixTrace' leaks an implementation detail of it, that it's using the `Writer [Trace i o]' monad, internally
08:55:49 <ski> the caller of `fixTrace', one can argue, shouldn't (have to / be able to) know (and possibly make use of) this implementation detail (which is used, in order to compute the `Traced i o', which is an official part of the interface)
08:57:15 <ski> so, what we can do here, is make `fixTrace' rank two, hiding the `Writer [Traced i o]' part behind an arbitrary monad `m'. demanding that the caller provides a function (here `fibThenM') that doesn't care which `m' `fixTrace' picks for it (it will still pick only a single `m', namely `Writer [Traced i o]', just as before)
08:57:46 <ski> however, this way, it would be possible to adapt the implementation of `fixTrace' to use some alternative, or additional, effect, without changing the type signature
08:58:00 <ski> (probably not that likely in this particular example, but could be useful, in other examples)
08:58:06 <ski> so, the new type signature then becomes
08:59:15 <ski> hm, actually, we don't want the callback to know about the `Traced', either, i just recalled
08:59:27 <ski> so, the type sig that we end up with will be
08:59:46 <ski> fixTrace :: forall i o. (forall m. Monad m => (i -> m o) -> i -> m o) -> i -> Traced i o
09:00:47 <ski> (i forgot about that detail. it's not hard to modify the implementation of `fixTrace' to also hide the `Tree (i,o)' part of `Traced i o', leaving only the `o' part inside the `m' in the result type of the callback)
09:02:03 <ski> so, that's an example of using rank two, not because we want to be able to use multiple `m's with the callback, but because we want to hide which particular `m' we use (so that the caller doesn't know which `m' it is, so that the callback can't mess with our chosen `m')
09:02:06 <djanatyn_> using traverse has made my code so much more readable
09:02:40 <djanatyn_> time to go through Typeclassopedia to see if there's other methods i'm missing that will make my life easier
09:02:46 <eslo> Hi! I have stuff that haskell reads from a file. Then I do things with it in haskell and then I would like to check if the file has changed and then maybe reload the file. How should I do this kind of checking for changes in the file?
09:02:52 <ski> zceejkr : is it making more or less sense, the motivations, and modularity ramifications ?
09:03:56 <zceejkr> it is, yes. 
09:04:32 <zceejkr> We limit the caller in what he can do in the callback, since the callback has to work for any monad.
09:04:54 <ski> it was a sortof longish example. and perhaps not that much on the "practical side". i've seen more "practical" uses of this, but i don't recall details of them offhand
09:05:09 <ski> btw, note that e.g.
09:05:12 <ski> @type mapM
09:05:14 <lambdabot> (Traversable t, Monad m) => (a -> m b) -> t a -> m (t b)
09:05:25 <ski> is similarly limited as `fibThenM'
09:05:42 <ski> the only `m'-effects that `mapM' can do is those that its callback does
09:05:55 <ski> it's "pure in itself", in some sense
09:06:57 <ski> (i would say that it's "referentially transparent", using a particular formal definition of that which i thinks accords with the traditional philosophical account of "referential opacity & transparency")
09:07:59 <ski> of course, if we set `m' to the `Identity' monad, we can also recover the original `fib' from `fibThenM'
09:08:39 <ski>   trivialFix :: ((i -> Identity o) -> i -> Identity o) -> i -> o
09:08:54 <ski> or, perhaps, if preferred
09:09:10 <ski>   trivialFix :: (forall m. Monad m => (i -> m o) -> i -> m o) -> i -> o
09:09:23 <ski> (the outer `forall i o. ' elided, here)
09:10:33 <ski> (so `fib = trivialFix fibThenM', and `tracedFib = fixTrace fibThenM' .. hm, i suppose i should have called `trivialFix' instead `fixTrivial', for consistency)
09:11:06 <ski> zceejkr : ok, shall we continue ?
09:11:31 <zceejkr> yes.
09:11:54 <eslo> I think I will just use getAccessTime to read the linux time stamp of the file. That will just not work in windows world I guess. There were things like FSNotify but I'm not at all trying to run things in parallel.
09:12:23 <ski> hm, i was thinking of, a bit above, about maybe walking through some type inference example with you. in order to somewhat deepen your understanding of polymorphism and `forall'
09:12:36 <ski> what do you think about that, zceejkr ?
09:12:51 <zceejkr> sure, sounds fun
09:13:03 <ski> hm, let me think of some example
09:15:49 <ski> maybe we're representing some kind of game state, a rectangular "array" of bits (represented by `Bool'eans)
09:16:12 <ski> and maybe we want to turn it around, on its head, while also flipping all the bits
09:16:27 <ski>   turnAndFlip :: [[Bool]] -> [[Bool]]
09:17:05 <ski>   turnAndFlip bss = reverse (map (reverse . map not) bss)
09:17:21 <ski> does that implementation make sense to you ?
09:17:29 <zceejkr> yep
09:17:35 <ski> one could also write it as
09:17:44 <ski>   turnAndFlip = reverse . map (reverse . map not)
09:17:54 <ski> but let's go with the former
09:18:36 <ski> so, we could either try to type-check it, given the signature, or infer the types, without the signature
09:18:58 <ski> not that big a difference here, but lets do the inference, without the signature. so we just have
09:19:01 <ski>   turnAndFlip bss = reverse (map (reverse . map not) bss)
09:19:52 <ski> well, `turnAndFlip' has a formal parameter (aka a pattern) to the left of the `=' in the defining equation. so it must be a function, and so have a type of the general shape `... -> ...'
09:20:58 <ski> we don't know yet the argument and result types, so lets invent some placeholder names (aka meta variables, to be distinguished from ordinary type variables, like `a',`b',`m' above) for them
09:21:16 <ski> i'll write meta variables here, starting with a `_'
09:23:04 <ski> (in logic programming (like Prolog,Mercury,Oz,ECLiPSe,Curry,Escher,..), meta variables are called "logic variables", are used for ordinary computation (rather than (or inaddition to) types). well, in Oz, they're called "dataflow variables", since they're used to communicate information among concurrently executing threads, there)
09:23:14 <ski> so, we know
09:23:23 <ski>   turnAndFlip :: _a -> _b
09:23:24 <ski> say
09:23:47 <ski> and, since `turnAndFlip' is being applied to the formal parameter `bss', we also must have
09:23:51 <ski>   bss :: _a
09:24:00 <ski> finally, the result must have type `_b'
09:24:10 <ski>   turnAndFlip bss :: _b
09:24:27 <ski> but that's (by definition) equal to `reverse (map (reverse . map not) bss)', so we also know
09:24:32 <ski>   reverse (map (reverse . map not) bss) :: _b
09:24:44 <ski> now we work "inward" on this "body"
09:24:57 <ski> in general, we have
09:25:05 <ski>   reverse :: forall a. [a] -> [a]
09:26:09 <ski> typically, when using a polymorphic operation, it'll be used at a specific, monomorphic, instance of it (the exception is with higher-rank stuff, where we can actually pass a polymorphic thing-in-itself (Ding-an-Sich), without specializing it)
09:26:29 <ski> so, for this particular use site of `reverse', we'll assume
09:26:38 <ski>   reverse :: [_c] -> [_c]
09:26:53 <ski> for some fresh (previously unused) meta variable `_c'
09:27:28 <ski> (note that this `reverse' is now monomorphic. `_c' is a specific type. it's just that we don't know yet, in the process of type inference, which type it is to be)
09:27:52 <ski> however, this `reverse' was called on `map (reverse . map not) bss', and result expected to be `_b'
09:28:13 <ski> from the latter, we derive the following equation
09:28:23 <ski>   _b = [_c]
09:28:42 <ski> (expected result type should equal actual result type of the function)
09:28:56 <ski> in fact this equation is so simple that it's already "solved"
09:29:19 <ski> but now we also know (or "know") the type of the argument to `reverse'
09:29:28 <ski>   map (reverse . map not) bss :: [_c]
09:29:42 <ski> here we have a call to the polymorphic `map'
09:29:53 <ski>   map :: forall a b. (a -> b) -> [a] -> [b]
09:30:08 <ski> specializing this particular usage of `map', too, yields
09:30:21 <ski>   map :: (_d -> _e) -> [_d] -> [_e]
09:30:37 <ski> and, matching result type, we get the equation
09:30:44 <ski>   [_c] = [_e]
09:31:10 <ski> and, we get the following inferred typings for the two arguments
09:31:19 <ski>   reverse . map not :: _d -> _e
09:31:29 <ski>   bss :: [_d]
09:31:34 <ski> but we already know
09:31:38 <ski>   bss :: _a
09:31:40 <ski> therefore
09:31:44 <ski>   _a = [_d]
09:32:06 <ski> continuing with the other argument, we first can desugar it to
09:32:14 <ski>   (.) reverse (map not) :: _d -> _e
09:32:27 <ski> to make it a bit more clear what's happening, then recalling the signature of `(.)'
09:32:48 <ski>   (.) :: forall a b c. (b -> c) -> (a -> b) -> (a -> c)
09:32:55 <ski> specializing to
09:33:12 <sm[m]> my yesod form handler is getting text area content with \r\n line endings from firefox. I guess that's normal.. what would be best way to normalise that to \n ? unlines . lines ?
09:33:14 <ski>   (.) :: (_g -> _h) -> (_f -> _g) -> (_f -> _h)
09:33:30 <ski> zceejkr : still following along ?
09:33:35 <zceejkr> yep
09:33:52 <ski> matching result type gives
09:34:02 <ski>   _d -> _e = _f -> _h
09:34:09 <ski> and argument typings
09:34:18 <ski>   reverse :: _g -> _h
09:34:28 <ski>   map not :: _f -> _g
09:35:04 <ski> this is another call to `reverse', so we'll specialize the polymorphic version above, again, using new/fresh meta variables
09:35:19 <ski>   reverse :: [_i] -> [_i]
09:35:45 <ski> matching the expected type of `reverse' (expected by the surrounding context of it), with the actual type of it, we get
09:35:55 <ski>   _g -> _h = [_i] -> [_i]
09:36:16 <ski> and again, we specialize `map' for this new usage of it
09:36:35 <ski>   map :: (_j -> _k) -> [_j] -> [_k]
09:36:50 <ski> or, we can here write that as
09:36:54 <ski>   map :: (_j -> _k) -> ([_j] -> [_k])
09:37:02 <ski> since we're only passing one argument to this `map'
09:37:11 <ski> so, matching expected result
09:37:25 <ski>   _f -> _g = [_j] -> [_k]
09:37:32 <ski> and expected type of argument
09:37:38 <ski>   not :: _j -> _k
09:37:56 <ski> recalling the actual type of `not' (which is monomorphic, so no need to specialize)
09:38:01 <ski>   not :: Bool -> Bool
09:38:09 <ski> matching these gives us
09:38:16 <ski>   _j -> _k = Bool -> Bool
09:38:29 <ski> and we're done with traversing the abstract syntax tree
09:38:43 <ski> now, we have to collect all the equations into an equation system, and solve it
09:38:56 <ski>   _b = [_c]
09:38:56 <ski>   [_c] = [_e]
09:38:59 <ski>   _a = [_d]
09:39:05 <ski>   _d -> _e = _f -> _h
09:39:08 <ski>   _g -> _h = [_i] -> [_i]
09:39:11 <ski>   _f -> _g = [_j] -> [_k]
09:39:15 <ski>   _j -> _k = Bool -> Bool
09:39:54 <ski> also reminding ourselves that we want to get, in the end, the signature
09:40:03 <ski>   turnAndFlip :: _a -> _b
09:41:11 <ski> the first equation `_b = [_c]' already is solved for `_b'. we can remove it, while everywhere replacing `_b' with `[_c]' (not forgetting to also replace in the signature of `turnAndFlip' which we want to infer !)
09:41:15 <ski> so
09:42:22 <ski> in this case, `_b' only occured in that signature, so the rest of the equations don't change. we also notice that the same happens with `_a = [_d]'. `_a' occurs nowhere here except in that signature, so we just replace there, and also delete that equation, giving us
09:42:30 <ski>   [_c] = [_e]
09:42:33 <ski>   _d -> _e = _f -> _h
09:42:35 <ski>   _g -> _h = [_i] -> [_i]
09:42:38 <ski>   _f -> _g = [_j] -> [_k]
09:42:40 <ski>   _j -> _k = Bool -> Bool
09:42:56 <ski>   turnAndFlip :: [_c] -> [_d]
09:43:51 <ski> the equation `[_c] = [_e]' simplifies to just `_c = _e', and now we can replace (e.g.) `_c' with `_e' everywhere (deleting that equation. or else replacing `_e' with `_c', doesn't matter)
09:44:17 <ski> i this case, also only the signature changes, to
09:44:25 <ski>   turnAndFlip :: [_e] -> [_d]
09:45:24 <ski> (`[_c] = [_e]' simplifies to `_c = _e', because `[...]' is an injective type function : if two list types are the same, that can only be because the element types are also the same)
09:45:50 <zceejkr> what is an example of a non-injective type function?
09:46:21 <ski> `_d -> _e = _f -> _h' simplifies to two equations, `_d = _f' and `_e = _h', so we can replace `_d' by `_f', and `_e' by `_h', yielding
09:47:03 <zceejkr> and (->) is also a type function?
09:47:14 <ski> yes
09:47:16 <ski> consider
09:47:25 <ski>   type Const c a = c
09:47:48 <ski> `Const c' is not injective. equivalently, `Const c a' is not injective in `a'
09:47:54 * hackage hedgehog-gen 0.1.0.0 - Customizable Gen for ADT using Generics  https://hackage.haskell.org/package/hedgehog-gen-0.1.0.0 (magesh)
09:48:17 <ski> `Const Int Bool' is equal to `Const Int Char' (both are equal to `Int'), despite `Bool' and `Char' not being equal
09:48:43 <zceejkr> I see. Thanks
09:49:34 <ski> (there are also more advanced/interesting cases, than type synonyms that ignore a parameter. see type families. they're a more advanced extension, though, better learn higher-rank, existentials, and then GADTs, first)
09:50:48 <ski> oh, i just noticed i did a slight mistake above
09:50:57 <ski> from
09:51:01 <ski>   turnAndFlip :: _a -> _b
09:51:03 <ski> we get not
09:51:10 <ski>   turnAndFlip :: [_c] -> [_d]
09:51:11 <ski> but
09:51:15 <ski>   turnAndFlip :: [_d] -> [_c]
09:51:21 <ski> and then
09:51:31 <ski>   turnAndFlip :: [_d] -> [_e]
09:51:33 <ski> as before
09:52:40 <ski> anyway, after simplifying away `_d -> _e = _f -> _h' and the two equations it yields (so, matching `(->) _d _e' with `(->) _f _h', and `(->)' is injective in both arguments)
09:53:01 <ski>   turnAndFlip :: [_e] -> [_h]
09:53:40 <ski> (still no change to the other equations. in general, they could also get changed in a substitution step. i guess in the example i happened to pick, they came out in an order where this didn't happen)
09:53:50 <ski> the remaining equations, anyway, are
09:54:02 <ski>   _g -> _h = [_i] -> [_i]
09:54:03 <ski>   _f -> _g = [_j] -> [_k]
09:54:06 <ski>   _j -> _k = Bool -> Bool
09:54:19 <ski>   turnAndFlip :: [_e] -> [_h]
09:54:27 <ski> simplifying away the first of these yields
09:54:39 <ski>   _f -> [_i] = [_j] -> [_k]
09:54:54 <ski>   _j -> _k = Bool -> Bool
09:55:02 <ski>   turnAndFlip :: [_e] -> [[_i]]
09:55:29 <ski> (replacing `_g' with `[_i]' and `_h' with `[_i]')
09:56:25 <ski> next, we get `_f = [_j]' so we replace `_f' by `[_j]'; and we also get `[_i] = [_k]', which simplifies to `_i = _k', so we also replace `_i' by `_k'
09:56:36 <ski>   _j -> _k = Bool -> Bool
09:57:58 <ski> hm, actually, i see now i forgot to replace the `_e' in the signature by `_h' (which in turn would be replaced by `[_i]'). so the signature here should actually be
09:58:06 <ski>   turnAndFlip :: [[_i]] -> [[_i]]
10:00:43 * ski sighs
10:00:58 <sm[m]> how *would* you efficiently replace "\r\n" with "\n" in a Text ?
10:01:07 <ski> i think i must've also made some other oversight, since there's a stray `_f' left here
10:01:31 <ski> let's ignore that, and continue, anyway
10:01:52 <ski> in
10:01:53 <ski>  turnAndFlip :: [[_i]] -> [[_i]]
10:02:04 <ski> we were to replace `_i' by `_k'
10:02:10 <ski>  turnAndFlip :: [[_k]] -> [[_k]]
10:02:16 <ski> and we also had
10:02:21 <ski>   _j -> _k = Bool -> Bool
10:02:31 <ski> left, which yields `_k = Bool', so
10:02:38 <ski>  turnAndFlip :: [[Bool]] -> [[Bool]]
10:02:49 <ski> is the end result (monomorphic in this case)
10:03:10 <ski> zceejkr : i was thinking of doing also a polymorphic example, but i think i'll skip it, since this is dragging on a bit
10:03:22 <ski> let's just say that if we had ended up with just
10:03:27 <ski>  turnAndFlip :: [[_k]] -> [[_k]]
10:03:44 <zceejkr> we introduce forall?
10:04:10 <ski> not constraining `_k' any further, then, as a last step, we'd replace this meta variable by a type variable, wrapping in `forall' (on the outside of the whole signature)
10:04:13 <ski> so
10:04:19 <ski>  turnAndFlip :: forall a. [[a]] -> [[a]]
10:04:26 <ski> this last step is called generalization
10:04:35 <Athas> Yaaay, new GHC.
10:04:37 <zceejkr> makes sense.
10:04:43 <Athas> Maybe my code will finally start building on Windows again.
10:05:11 <ski> zceejkr : in general, apart from equations, and signatures, we might also have facts like `Ord _k' lying around
10:05:34 <ski> if that becomes `Ord Bool' e.g., then that's trivially true, so can be removed from the equation system
10:05:45 <ski> but if we have ended up with
10:05:51 <ski>   Ord _k
10:05:54 <ski>  turnAndFlip :: [[_k]] -> [[_k]]
10:06:21 <ski> then, the last generalization step would have been to collect the constraints mentioning the generalized-upon variables, like so
10:06:27 <ski>  turnAndFlip :: forall a. Ord a => [[a]] -> [[a]]
10:07:17 <ski> (and in cases there were any other remaining constraints, mentioning variables that are not mentioned in the final signature, we'd give an ambiguity error, since we don't know what types to pick for those variables in those constraints)
10:07:46 <Phyx-> Athas: ?
10:07:48 <zceejkr> Is this where AllowAmbigousTypes comes in?
10:08:17 <zceejkr> Tells haskell to not report this as error.
10:08:22 <Athas> Phyx-: I was a victim of the linking segfault.
10:08:42 <Athas> At least I think that was the one.
10:09:13 <Phyx-> Athas: which segfault?
10:09:31 <ski> zceejkr : yea, if we had gotten say
10:09:38 <ski>   Ord _l
10:09:49 <ski>   turnAndFlip :: [[Bool]] -> [[Bool]]
10:09:52 <Athas> Phyx-: I think this one: https://gitlab.haskell.org/ghc/ghc/issues/17599
10:09:56 <ski> then that'd've yielded
10:10:04 <ski>   turnAndFlip :: forall a. Ord a => [[Bool]] -> [[Bool]]
10:10:43 <ski> but then, in order to determine which `a' to use, say `Integer', we must do an explicit specialization, like `turnAndFlip @Integer', when using it
10:11:21 <ski> without that, there's no way to determine `a', since it's not mentioned in `[[Bool]] -> [[Bool]]', can't be inferred either from argument type(s) or from result type
10:11:45 <zceejkr> ski: i see. I actually used this a few days ago. I had a value isMonoid :: forall a. Monoid a => IO ()
10:12:09 <zceejkr> And it basically ran the tests for associativity and identity
10:12:24 <ski> yea, i see
10:12:29 <ski> another alternative would be to use
10:12:32 <zceejkr> So I was able to write isMonoid @type for my instances
10:12:49 <ski>   isMonoid :: forall a. Monoid a => Proxy a -> IO ()
10:13:28 <ski> calling like `isMonoid (Proxy :: Proxy Integer)', with an explicit type ascription on `data Proxy a = Proxy'
10:13:34 <ski> or, in fact, even
10:13:46 <ski>   isMonoid :: forall proxy a. Monoid a => proxy a -> IO ()
10:14:15 <ski> (call can be the same, but could also pass a list of `a's (`Integer's in this case), or some other "collection" thing)
10:14:27 <Phyx-> Athas: ah that one ok
10:14:51 <zceejkr> ski: I see.
10:15:52 <ski> zceejkr : i suppose the main thing i wanted to convey here, in the context of `forall' and `exists', was the distinction of meta variable (an internal concept used during the process of type inference/checking) from type variable (as bound by `forall', and also by `exists'. and by `type',`data',`newtype',`class',`instance')
10:16:52 <ski> zceejkr : although, getting a slightly more detailed overview/refresher of Hindley-Milner type inference is probably good, as well. with some practice, you'll probably be able to do it in head, without having to think that hard about it, at least in simpler cases
10:17:25 <ski> zceejkr : oh, i could mention (or reemphasize) one more thing, in this context
10:18:37 <ski> let's say we do have a type signature, when type checking. specifically, let's assume it specifies a polymorphic operation, so a `forall' (on top-level)
10:18:45 <ski> let's again take the example
10:18:56 <ski>   elem :: forall a. Eq a => a -> [a] -> Bool
10:19:03 <ski>   elem x0 = elem_x0
10:19:04 <ski>     where
10:19:15 <ski>     elem_x0 :: [a] -> Bool
10:19:24 <ski>     elem_x0 [    ] = False
10:19:30 <ski>     elem_x0 (x:xs) = x0 == x
10:19:44 <ski>                   || elem_x0 xs
10:20:29 <ski> here, we already start with a specific signature of `elem', that we only have to check against each node of the AST (Abstract Syntax Tree), traversing it
10:20:54 <ski> so, instead of doing the generalization step, at the end, we sortof do it, "in reverse", at the start
10:22:04 <ski> however, `a' is not replaced by a meta variable (say `_a'), but by a (so called) "skolem constant" (also "rigid variable"). let's write it as `?a'
10:22:50 <ski> a meta variable `_a' represents some specific type which we just haven't figured out yet. but we're allowed to choose it, so that the equations we've collected can be solved
10:23:26 <ski> otoh, `?a' is an "arbitrary" (in math terms) type, it's not under our control. it might be `Integer', it might be `IO (Int -> Bool)', it might be something else
10:23:56 <ski> if we have an equation `_a = Integer', we can solve this, by selecting/choosing `_a' to be `Integer', replacing `_a' everywhere by `Integer'
10:24:40 <ski> if we have an equation `?a = Integer', we can not solve this. `?a' might be `Integer', but might also be something else. we have to "assume the worst", that it is (or might be) something else
10:25:01 <ski> `?a' is only known to equal itself, so `?a = ?a' is still (trivially) solvable
10:25:17 <ski> so, as a first step, we actually get the signature
10:25:28 <ski>   elem :: ?a -> [?a] -> Bool
10:25:32 <ski> together with the constraint
10:25:35 <ski>   Eq ?a
10:26:03 <ski> and we want to check this expected type of `elem', with the actual code defining `elem'
10:26:54 <ski> from the POV of `elem', `?a' is a specific type, as specific as `Integer' or `Bool'. it's just that we have no idea which specific type this is (and we're not allowed to assume anything about it. except that's explicitly granted, which in this case is `Eq ?a')
10:28:08 <ski> you can think of `?a', from the POV of `elem', as being like an abstract data type, with unknown implementation. the only "operations" we have to play with, regarding it, are the arguments of `elem' (here just `x0 :: ?a'). in other cases, some of these could be callbacks
10:28:48 <ski> this also, hopefully, makes is clearer that, from the POV of `elem', `elem_x0' is monomorphic. it deals with the specific type `?a' (that the caller of `elem' will determine)
10:29:37 <ski> this means that we will not do any generalization step for `elem_x0' (regardless of whether we include its signature explicitly, or else infer it). there will be no `forall' in the type of `elem_x0'
10:31:15 <ski> technically, this is because, when (if) inferring the type of `elem_x0', its definition refers to the variable `x0' (not bound by formal parameters / patterns of `elem_x0's definition), whose type refers to this variable. so we're not allowed to generalize `elem_x0' on this variable, since it also occurs outside the type of `elem_x0' (namely in the type of `x0')
10:31:28 <ski> zceejkr : does this, sortof, make sense ?
10:32:12 <ski> (i realize the last parts were perhaps a bit less clear)
10:32:41 <zceejkr> yes. I sort of imagine it, by the time elem_x0 is introduced, the type of a was already fixed, so elem_x0 has to be a function working on that fixed a.
10:32:48 <ski> yes
10:33:08 <ski> also note that `elem_x0' calls itself recursively, at this same type
10:33:15 <ski> consider the version without `elem_x0'
10:33:18 <ski> @src elem
10:33:18 <lambdabot> elem x = any (== x)
10:33:25 <ski> er, actually i meant
10:33:35 <ski>   elem :: forall a. Eq a => a -> [a] -> Bool
10:33:47 <ski>   elem x0 [    ] = False
10:33:52 <ski>   elem x0 (x:xs) = x0 == x
10:34:02 <ski>                 || elem x0 xs
10:34:26 <ski> `elem' calls itself, recursively, using the same `a' that it was itself called at
10:34:32 <ski> this is called "monomorphic recursion"
10:35:09 <ski> `elem', despite being polymorphic, is "monomorphically recursive", from the POV of its own definition, it's monomorphic, on some specific unknown `?a'
10:35:20 <ski> it's only "from the outside", that it's polymorphic
10:35:46 <ski> it's also possible to have "polymorphic recursion", where the recursive call isn't at the same type
10:35:49 <ski> e.g.
10:36:05 <ski>   silly :: forall a. Show a => [a] -> [String]
10:36:19 <ski>   silly [    ] = []
10:36:42 <ski>   silly (x:xs) = show x : silly (map (: []) xs)
10:36:49 <ski> @let silly :: forall a. Show a => [a] -> [String]
10:36:51 <lambdabot>  .L.hs:227:1: error:
10:36:51 <lambdabot>      The type signature for â€˜sillyâ€™ lacks an accompanying binding
10:36:51 <lambdabot>      |
10:36:57 <ski> @let silly :: forall a. Show a => [a] -> [String]; silly [    ] = []; silly (x:xs) = show x : silly (map (: []) xs)
10:37:00 <lambdabot>  Defined.
10:37:07 <ski> > silly "abcd"
10:37:10 <lambdabot>  ["'a'","\"b\"","[\"c\"]","[[\"d\"]]"]
10:37:17 <ski> > silly [0,1,2,3]
10:37:21 <lambdabot>  ["0","[1]","[[2]]","[[[3]]]"]
10:38:01 <ski> when `silly' is called on an input of type `[?a]', it wraps each element of the tail of that in a singleton list, so that the recursive call is called on an input of type `[[?a]]'
10:38:42 <ski> this is another example of a type signature that can't be inferred. this one isn't even a language extension, polymorphic recursion was in Haskell 98
10:38:58 <ski> the other example we saw, was higher-rank operations
10:39:19 <ski> a third example is pattern-matching on GADTs (but i haven't talked about GADTs)
10:39:48 <ski> for a less frivolous example, consider the "irregular" (technical term) data type
10:40:00 <ski>   data NestTree a = Elems a
10:40:16 <ski>                   | Nest (NestTree [a])
10:40:32 <ski> note how this differs from
10:40:50 <ski>   data BranchTree a = Leaf a
10:41:05 <ski>                     | Branch [BranchTree a]
10:41:27 <ski> these are quite similar, but there's an important difference
10:41:31 <zceejkr> So its a polymorphic-recursive data contructor
10:41:51 <zceejkr> constructor*
10:42:09 <ski> a `BranchTree a' will have a list of branches, at each internal fork/node. the length of the list (the number of branches) may vary. the same also for `NestTree a'
10:42:42 <ski> however, all branches are the same length, in a `NestTree a' ! not necessarily so, for a `BranchTree a'
10:43:05 <ski> we can have `Branch [Leaf 0,Branch [Leaf 1,Leaf 2]]'
10:43:49 <ski> but for `NestTree Integer', we can only have trees like `Nest (Nest (Elems [[0],[1,2]]))', with the same number of list nestings, everywhere
10:43:53 <ski> note that
10:44:03 <ski>   [[0],[1,2]] :: [[Integer]]
10:44:12 <ski>   Elems [[0],[1,2]] :: NestTree [[Integer]]
10:44:20 <ski>   Nest (Elems [[0],[1,2]]) :: NestTree [Integer]
10:44:26 <ski>   Nest (Nest (Elems [[0],[1,2]])) :: NestTree Integer
10:44:46 <ski> the "element type" changes, as we apply more `Nest' constructors, around the single `Elems' one
10:45:01 <zceejkr> nice
10:45:34 <ski> and yes, zceejkr, this is because since the recursive "call" of `NestTree' is using not the same parameter, `a', but instead `[a]' (this is what makes it an "irregular" `data' type, rather than a "regular" one)
10:45:39 <ski> another example is
10:45:45 <ski>   data SwapList a b = Nil
10:45:55 <ski>                     | Cons a (SwapList b a)
10:46:15 <ski> evenly indexed elements have type `a', oddly indexed elements have type `b'
10:46:55 <ski> this is just to show that the parameters doesn't necessarily have to get "more complicated" (as when going from `a' to `[a]'), we could just rearrange them a bit
10:47:28 <ski> polymorhic recursion is, mostly, useful when dealing with such irregular `data' types. but, occasionally, can also be useful with ordinary data types
10:47:35 <ski> hm, one more `data' type example
10:47:50 <ski>   data PerfectlyBalancedBinaryTree a = Elems a
10:48:10 <ski>                                      | Double (PerfectlyBalancedBinaryTree (a,a))
10:48:18 <ski> sample value is
10:48:43 <ski>   (Double . Double . Double . Elems) (((0,1),(2,3)),((4,5),(6,7))) :: PerfectlyBalancedBinaryTree Integer
10:50:06 <zceejkr> Nice. I assume you would you this to enforce "balancedness" at compile time.
10:50:24 * hackage splitmix 0.0.4 - Fast Splittable PRNG  https://hackage.haskell.org/package/splitmix-0.0.4 (phadej)
10:50:31 <ski> (btw, we don't say `NestTree' (a type constructor) is "polymorphic-recursive data contructor" (it's not even a polymorphic type. it's a parametric type, or a type function). nor are the actual data constructors here, `Elems',`Nest' polymorphic-recursive (they're polymorphic, to be sure, but not recursive, since they don't have a definition))
10:51:37 <zceejkr> I see.
10:52:00 <ski> (`Nest :: forall a. NestTree [a] -> NestTree a' is not anymore recursive than `tail :: forall a. [a] -> [a]' is recursive)
10:52:37 <ski> yea, this could be used to enforce only being able to represent perfectly balanced trees
10:52:57 <ski> consider the `data' type
10:53:37 <ski>   data NestingList e f a = Nil
10:53:56 <ski>                          | Cons (e a) (NestingList e f (f a))
10:54:13 <ski> and consider `NestingList Maybe PerfectlyBalancedBinaryTree Integer'
10:54:32 <ski> ah, actually
10:54:34 <ski> define
10:54:43 <ski>   data Two a = Pair a a
10:54:55 <ski> and consider `NestingList Maybe Pair Integer''
10:55:33 <ski> so, the first element of the list will have type `Maybe Integer', the next `Maybe (Pair Integer)', the next `Maybe (Pair (Pair Integer))'
10:55:36 <ski> and so on
10:56:29 <zceejkr> Nice.
10:57:20 <zceejkr> ski: hey I have to run now. My bus is leaving soon. Thanks so much for this. If it is okay with you I would like to continue with this in the future.
10:57:45 <ski> so, we have âŒœbâ‚€â‹…1 + bâ‚â‹…2 + bâ‚‚â‹…2Â² + bâ‚ƒâ‹…2Â³ + â‹¯âŒ `Integer's in this list
10:57:55 <ski> sure
10:58:10 <zceejkr> Alright, thanks a bunch. Good night :)
10:58:28 <ski> have a nice day, later
11:31:25 <WASD> Why does "Just 3 >>= (return (Just 5))" work? The second argument to (>>=) has the wrong type?
11:31:54 <Rembane> :t Just 3 >>= (return (Just 5))
11:31:56 <lambdabot> Num b => Maybe b
11:32:16 <Rembane> :t return (Just 5)
11:32:19 <lambdabot> (Monad m, Num a) => m (Maybe a)
11:32:28 <amalloy> that return is in the function monad
11:32:51 <amalloy> > Just 3 >>= const (Just 5)
11:32:54 <lambdabot>  Just 5
11:32:55 <WASD> But (>>=) can't mix different monads? Maybe+function
11:33:16 <WASD> same m
11:33:27 <amalloy> :t return (Just 5) :: Int -> Maybe Int
11:33:29 <lambdabot> Int -> Maybe Int
11:33:49 <WASD> ah.. it does it that way
11:33:55 <ski> s/function monad/environment monad/
11:34:03 <WASD> thanks
11:34:35 <ski>   (>>=) :: Maybe Integer -> (Integer -> Maybe Integer) -> Maybe Integer
11:34:40 <ski>   Just 3 :: Maybe Integer
11:34:49 <ski>   Just 5 :: Maybe Integer
11:35:01 <ski>   return (Just 5) :: Integer -> Maybe Integer
11:35:34 <ski>   return :: forall a. a -> ((->) Integer) a
11:35:45 <ski>   return :: forall a. a -> (Integer ->) a
11:35:48 <ski>   return :: forall a. a -> (Integer -> a)
11:35:50 <ski>   return :: forall a. a -> Integer -> a
11:35:59 <ski> in your case `a' becomes `Maybe Integer'
11:36:00 <xavo[m]> ohh, return's @((->) Integer) and >>='s @Maybe, in other words
11:36:11 <ski> the monad is `(Integer ->)' aka `(->) Integer'
11:36:17 <ski> an "environment monad"
11:37:09 <ski> (aka "input monad" or "reader monad". i don't like "function monad", since it's not just about it being a function, it's about "distributing" the input in a certain sense)
11:38:17 <WASD> I wanted to ask another thing. I'm playing around with DataKinds and wondering if it's possible to make a function like "f :: Int -> whatever" that only compiles for "f 42" but not any other numbers. So it should use the "type" 42 as I understand it.
11:38:24 * hackage ghc-lib-parser 8.8.3.20200224 - The GHC API, decoupled from GHC versions  https://hackage.haskell.org/package/ghc-lib-parser-8.8.3.20200224 (shayne_fletcher)
11:38:28 <ski> (compare with "environment variables", when a processes spawn child processes. the environment variables there are also "distributed down" the family spawn tree. and, each parent can decide to change some inherited environment variables, on behalf of a child, when spawning it)
11:38:31 <jle`> WASD: you want f to only take 42
11:38:36 <jle`> WASD: in that case it's no different than f :: () -> whatever
11:38:58 <jle`> @let data Only42 = Only42
11:39:01 <lambdabot>  Defined.
11:39:17 <jle`> @let myFunc :: Only42 -> String; myFunc _ = "hi"
11:39:20 <lambdabot>  Defined.
11:39:24 <jle`> WASD: is that what you mean?
11:39:24 * hackage ghc-lib 8.8.3.20200224 - The GHC API, decoupled from GHC versions  https://hackage.haskell.org/package/ghc-lib-8.8.3.20200224 (shayne_fletcher)
11:39:33 <WASD> I want to literally write "f 42"
11:39:37 <WASD> using DataKinds?
11:39:52 <jle`> @let instance Num Only42 where fromInteger 42 = Only42
11:39:55 <lambdabot>  .L.hs:233:10: error: [-Wmissing-methods, -Werror=missing-methods]
11:39:55 <lambdabot>      â€¢ No explicit implementation for
11:39:55 <lambdabot>          â€˜+â€™, â€˜*â€™, â€˜absâ€™, â€˜signumâ€™, and (either â€˜negateâ€™ or â€˜-â€™)
11:40:14 <ski>   instance Num Only42 where ..; fromInteger 42 = Only42; fromInteger _ = error "blahblah !"
11:40:31 <jle`> @let instance Num Only42 where fromInteger 42 = Only42; (+) = undefined; (*) = undefined; abs = undefined; signum = undefined; negate = undefined
11:40:33 * ski low fours jle`
11:40:34 <lambdabot>  Defined.
11:40:35 <jle`> > f 42
11:40:40 <lambdabot>  error:
11:40:40 <lambdabot>      â€¢ Ambiguous type variable â€˜a0â€™ arising from a use of â€˜show_M472602587372...
11:40:40 <lambdabot>        prevents the constraint â€˜(Show a0)â€™ from being solved.
11:40:40 <WASD> I want compile error on "f 43"
11:40:45 <MarcelineVQ> "I want it to be a type error to apply f to anything other than 42"
11:40:45 <jle`> > myFunc 42
11:40:47 <lambdabot>  "hi"
11:40:52 <jle`> ah, hm
11:40:53 <ChaiTRex> abs can be defined
11:41:09 <jle`> nope, you can't do that with overloaded literals
11:41:19 <jle`> with numeric literals like that
11:41:32 * ski idly ponders Hughes' "type specialization" paper
11:41:34 <jle`> that's because the type of numeric literals, forall a. Num a => a
11:42:05 <jle`> you can't do it with numeric literals, but you *can* do it with specific non-literal Integers
11:42:21 <jle`> like (x :: Integer), you can have f x (in a way) only compile if x is 42
11:42:30 <jle`> but i don't think you can do it with numeric literals
11:42:54 <ski> hm, any singletons for type-level nats ?
11:43:00 <jle`> there are singletons
11:43:07 <jle`> but you can't really do it with numeric literals
11:43:17 <jle`> singleton-like ways are what i was thinking of, sorta
11:43:17 <ski> how do they look like ?
11:43:27 <WASD> I've gotten this to compile: class AlowedNumber n where; instance AlowedNumber 42 where; f :: AlowedNumber n => n -> String
11:43:46 <WASD> Can it work with string literals?
11:43:47 <jle`> ðŸŽ¿ data SNat n = KnownNat n => SNat n, roughly
11:44:05 <jle`> * ski 
11:44:15 <jle`> WASD: have you tried 'running' that?
11:44:23 <WASD> yeah I can't call it
11:44:25 * ski can't view that unicode glyph, anywa
11:44:26 <ski> y
11:44:33 <jle`> what's the rror?
11:45:12 <WASD> No instance for (AlowedNumber n0) arising from a use of ‘f’ ... • In the expression: f 42
11:45:31 <jle`> right, because you're giving it an Integer
11:45:35 <jle`> not an 'n'
11:45:48 <WASD> I see
11:46:17 <jle`> in any case, talking only about numeric literals is kind of restricting
11:46:34 <jle`> it sort of makes more sense to talk about being able to only call `f x` if x follows some sort of predicate (like, only being 42)
11:47:35 * ski . o O ( `f (eulerTotient 49)' )
11:49:13 <jle`> if you wanted to use singletons you can have something like ...
11:49:17 <jle`> f :: Sing 42 -> String
11:49:26 <jle`> or f :: SNat 42 -> String
11:49:41 <jle`> then call it with `f (SNat @42)`
11:49:51 <jle`> where f (SNat @41) would be a compile-time error
11:50:05 <WASD> I'm reading up on singletons as well, that sounds nice
11:50:06 <jle`> but this isn't too different than just doing `f :: (n ~ 42) => String
11:50:16 <jle`> and then calling f @42, vs. f @41
11:50:26 <jle`> so you don't need singletons for this approach i guess
11:50:31 <jle`> hm, you could actually only use proxy
11:50:53 <jle`> f :: (n ~ 42) => Proxy n -> String; f (Proxy @41) vs. f (Proxy @42)
11:51:01 <jle`> the version without the proxy is closer to what you originally had in mind
11:51:13 <jle`> er, that second one could be f :: Proxy 42 -> String
11:51:34 <WASD> does this use OverloadedLabels?
11:52:42 <WASD> hey, I got it to work
11:52:55 <WASD> just 'f :: (n ~ 42) => String'
11:53:25 <WASD> I haven't used that syntax before
11:59:38 <__monty__> Hmm, I'm getting an "Unexpected do block in function application:" error but the do block in question is the body of a lambda. Is this not allowed without the extension anymore?
12:00:45 <MarcelineVQ> show your work :>
12:01:03 <WASD> __monty__: BlockArguments extention might help, not sure
12:03:03 <int-e> __monty__: that sounds off; are you sure you're interpreting the indentation the way the compiler does?
12:03:31 <__monty__> MarcelineVQ: It's not a very minimal example but: http://ix.io/2cAT
12:05:20 <__monty__> int-e: Very possible. It's just that this problem only showed up when I changed the `closure` from a `<-` pattern match to the let.
12:05:55 <__monty__> Parenthesizing the lambda doesn't help, so I don't understand the error.
12:07:53 <int-e> __monty__: The suggestion is to parenthesize the do block. However, I share your confusion :-/
12:08:56 <__monty__> int-e: Am I right in thinking the application it's talking about is the `%>`?
12:09:57 <ski> __monty__ : probably doesn't help with your issue, but you can merge adjacent `let' commands into a single one (multiple bindings)
12:10:09 <__monty__> If I change the `let closure =` to `closure <- return $` the compiler doesn't complain.
12:10:58 <__monty__> ski: Hmm, it stops complaining if I do that.
12:11:22 <ski> hm, interesting
12:11:31 <__monty__> I don't mind the repetition of the keyword tbh. I suppose this is a GHC bug?
12:12:22 <ski> it does sound weird
12:12:25 <int-e> __monty__: what ghc version is this?
12:12:40 <__monty__> int-e: 8.6.5
12:13:03 <ski> first `foldr' is a `concatMap'
12:13:54 <ski> second is a `listToMaybe' with a `fromMaybe', i guess
12:14:02 <ski> (is that `case' exhaustive ?)
12:15:28 <ski> might use a `case' with `appDirDhall', possibly factoring the `applicationDir </> ' out of it
12:17:27 <int-e> __monty__: Well my naive attempt to reproduce this failed, namely doing   "//*.closure" %> \closureFile' -> do   return ()  with the return on the next line, and a dummy (%>) of the same fixity as in shake (infix 1 %>)
12:17:32 <ski> `coverSpec' and `resumeSpec' could be done with a `forM'/`for', i suppose
12:18:32 * ski also ponders factoring `closureFile -<.> "dhall"'
12:20:10 <ski> you checked that you don't have any lingering tabs, right, __monty__ ?
12:21:05 <__monty__> I haven't checked but I'd have to jump through hoops to insert tabs.
12:24:33 <int-e> __monty__: Oh. Is there anything below that at indentation level 3 that could be mistaken for an argument that the do block is applied to?
12:25:01 <ski> hm, good question
12:25:15 <__monty__> int-e: No, and after merging the two lets I split them again and now ghcid doesn't show an error.
12:25:28 <int-e> ala http://paste.debian.net/1131934/
12:25:45 <ski> > do {return ()} ()
12:25:48 <lambdabot>  <hint>:1:1: error:
12:25:48 <lambdabot>      Unexpected do block in function application:
12:25:48 <lambdabot>          do return ()
12:26:00 <ski> sounds likely, even ?
12:26:06 <int-e> That produces the same error, and it's consistent with having a lambda in front.
12:26:21 <int-e> > \x -> do { return () } ()
12:26:23 <lambdabot>  <hint>:1:7: error:
12:26:23 <lambdabot>      Unexpected do block in function application:
12:26:24 <lambdabot>          do return ()
12:26:55 <dmwit> __monty__: let closure = dhallClosure\n{- not enough indentation here -}("./" ++ dhall
12:27:00 <ski> sounds like you got some column indented too little, __monty__
12:27:16 <dmwit> __monty__: near the end
12:27:21 <ski> well spotted, dmwit
12:27:56 * ski didn't realize that would also end the `do', though
12:27:58 <__monty__> dmwit++
12:28:34 <ski> __monty__ : i guess you indented that more, when merging ?
12:29:16 <__monty__> ski: Yep. I realized then that it wouldn't work if it was less indented than the name.
12:29:22 <__monty__> But I didn't think it through.
12:29:30 <dmwit> The spec says to insert } any time you'd otherwise have a parse error. So I guess this closes all extant blocks.
12:29:59 <__monty__> I guess I should've paid closer attention to the "end of block" in the error message.
12:30:06 <ski> > do let {} ()
12:30:06 <int-e> dmwit: Oh, wow. I would have expected it to complain about the ill-formed do block first :-/
12:30:09 <lambdabot>  <hint>:1:1: error:
12:30:09 <lambdabot>      Unexpected do block in function application:
12:30:09 <lambdabot>          do let
12:30:17 <ski> > do {let {} ()}
12:30:20 <lambdabot>  <hint>:1:12: error: parse error on input â€˜(â€™
12:30:26 <dmwit> int-e: That does seem like it would be a (more) reasonable way to complain.
12:30:26 <int-e> But yes, that makes sense in retrospect.
12:30:30 <__monty__> The text of the error is not helpful in this scenario though.
12:31:13 <int-e> __monty__: Yes, absolutely not.
12:32:39 <int-e> Ah, I've never encountered this scenario because my default indentation depth is 4.
12:32:44 <dmwit> Ah, no, it closes *only* the closest-enclosing do block.
12:33:12 <dmwit> Then in interprets the result as the application `do { ...; let  closure = dhallClosure } (args)`.
12:33:25 <int-e> (And you get a different error if you indent that argument 2 spaces further)
12:33:48 <dmwit> > (do {let{}}) "foo"
12:33:50 <lambdabot>  error:
12:33:50 <lambdabot>      The last statement in a 'do' block must be an expression let
12:33:52 <int-e> "parse error (possibly incorrect indentation or mismatched brackets)" <-- not the most helpful either.
12:34:05 <int-e> However, it's reported in the right place!
12:34:11 <dmwit> > do {let{}} "foo"
12:34:14 <lambdabot>  <hint>:1:1: error:
12:34:14 <lambdabot>      Unexpected do block in function application:
12:34:14 <lambdabot>          do let
12:34:23 <dmwit> Fascinating that the parentheses make a difference there.
12:34:33 <dmwit> Oh, no, of course they do. That's the whole point of the error you got. =P
12:35:25 <dmwit> I guess the nice minimal version is `do{}""`.
12:37:01 <ski> % do {return ()} ()
12:37:01 <yahb> ski: ()
12:37:04 <ski> % do return () ()
12:37:05 <yahb> ski: ()
12:37:33 <dmwit> % return () () -- though
12:37:33 <yahb> dmwit: ()
12:37:38 <__monty__> ski: Going over your refactoring tips now. The concatMap doesn't seem like a win? The case is exhaustive yeah, it's a newtype. So I'm not sure what listToMaybe would bring?
12:38:25 <dmwit> ...wait. Why did `do{return ()}()` work, if do blocks are not supposed to be part of a function application?
12:39:03 <Tuplanolla> > case Just "yes" of (Nothing) -> mempty; (Just) x -> x -- Here's another curious one.
12:39:05 <lambdabot>  <hint>:1:41: error: Parse error in pattern: (Just)
12:39:59 <dmwit> Nothing is a pattern. Just is not a pattern.
12:40:11 <dmwit> > case Just "yes" of (Nothing) -> mempty; (Just x) -> x
12:40:15 <lambdabot>  "yes"
12:40:17 <ski> __monty__ : not having to parse what the `foldr' does
12:40:33 <ski> dmwit : `BlockArguments'
12:40:48 <dmwit> > case Just "yes" of (((Nothing))) -> "whoops"
12:40:51 <lambdabot>  "*Exception: <interactive>:(3,1)-(4,22): Non-exhaustive patterns in case
12:41:31 <dmwit> ski: Oh, I completely missed that it wasn't lambdabot, despite even typing the right character to chat with yahb myself!
12:41:35 * ski doesn't really get why people often insist on writing `case ... of (x:xs) -> ...; ...'
12:41:55 <dmwit> > do {return ()} ()
12:41:58 <lambdabot>  <hint>:1:1: error:
12:41:58 <lambdabot>      Unexpected do block in function application:
12:41:58 <lambdabot>          do return ()
12:42:02 <dmwit> All is well.
12:42:05 <ski> dmwit : yea, the point was that they happened to give the same answer, for different reasons ;)
12:42:24 <ski> __monty__ : win, in which sense ?
12:42:33 <dmwit> err. different reasons?
12:43:03 <dmwit> Sure, okay. ^_^
12:43:04 <ski> the second one is `do {return () ()}', which is `do ()', so not using any monad
12:43:35 <__monty__> ski: concatMap isn't more familiar to me so foldr seems simpler.
12:43:50 <ski> perhaps make it more familiar, then ?
12:44:07 <ski> or use `concat'&`map', or `(=<<)'/`(>>=)', as you prefer
12:45:00 <ski> `foldr' is more general, so can be overkill
12:45:16 <dmwit> I second the recommendation to use a more specialized fold when one is available.
12:45:21 <ski> i had to read over your `foldr's, to check what they were doing in detail
12:46:05 <dmwit> If you write `sum` I know immediately. If you write `foldl' (+) 1`, I have to check that you picked the right fold, the right base case, etc. (spoilers: nope)
12:47:16 <ski> if you have a `getDhallFile', then you can use it in place of the `case'
12:47:28 <ski> (if you don't have one, perhaps consider defining it)
12:48:30 <ski>   maybe "" getDhallFile (listToMaybe flags)
12:48:56 <ski>   fromMaybe "" (fmap getDhallFile (listToMaybe flags))
12:49:16 <ski> `maybe's probably better here, yea
12:53:54 <solonarv> fromMaybe mempty (fmap f mx) = foldMap f mx, btw
12:55:36 <__monty__> ski: Thanks for the notes. About the appDirDhall, I factored out the `applicationDir </>` using a nested `let in`, not sure how you'd use a case there?
12:57:38 <amalloy> ski: i can't find the scrollback: what's wrong with case .. of (x:xs) ?
12:59:33 <ski> redundant brackets, amalloy
13:00:30 <amalloy> ah. i think i write more function definitions than case statements, and in function definitions it is needed. i generally don't think about when they're superfluous
13:01:57 <ski>   let appDirDhall = applicationDir </> case closureFile of
13:02:04 <ski>         "cover.closure"  -> coverSpec
13:02:10 <ski>         "resume.closure" -> resumeSpec
13:02:14 <ski>         otherwise        -> closureFile -<.> "dhall"
13:02:19 <ski> __monty__ ^
13:03:06 <ski> amalloy : the brackets in `foo (x:xs)' are for grouping, not for "list cons cell"
13:03:16 <ski> (this is not Prolog or Erlang)
13:04:09 <int-e> __monty__: You might consider chiming in on https://gitlab.haskell.org/ghc/ghc/issues/16097
13:08:36 <amalloy> ski: yeah, i'm aware. i make the same mistake with (Just x) too
13:08:51 <amalloy> (though less often)
13:09:25 <amalloy> it's just easier to put parens around stuff that sometimes needs it than it is to be 100% accurate about when it's needed. if i put in some that's not needed, hlint can let me know
13:09:26 <ski> it's just that (unpremeditated) redundant brackets annoy me ;)
13:11:12 <ski> (putting in extra brackets, because you don't recall which of two user-defined operators wins, is partly a different matter)
13:23:01 <__monty__> int-e: Left a comment, hope it's helpful. Thanks for digging up the issue.
13:23:34 <d34df00d> Uh, levity polymorphism is hard.
13:23:39 <d34df00d> I no longer understand it at all.
13:24:04 <d34df00d> Interestingly, if I have class AsmArg a (rep :: RuntimeRep) (unboxedTy :: TYPE rep) | a -> rep, a -> unboxedTy where unbox :: a -> unboxedTy
13:24:25 <d34df00d> And if I ask for the type of `unbox` in ghci, it forces `rep` to be LiftedRep: unbox :: AsmArg a 'GHC.Types.LiftedRep unboxedTy => a -> unboxedTy
13:25:10 <d34df00d> But that doesn't stop me from having instances like instance AsmArg Int 'IntRep Int# where
13:27:20 <int-e> __monty__: Yeah I actually added a comment too. But let's see what happens.
13:36:13 <nshepperd2> d34df00d: are you using :t to check the type? might be some type inference funniness going on. try :i
13:37:01 <d34df00d> nshepperd: :i doesn't show the constraints as I'd expect them on any other function, it instead shows the class to which it belongs.
13:37:17 <d34df00d> Oh, wrong one. nshepperd2 that was for you.
13:39:09 <nshepperd2> or trying setting https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using.html#ghc-flag--fprint-explicit-runtime-reps before using :t
13:40:44 <nshepperd2> there's a bunch of defaulting stuff in ghc to make printed types less noisy since you usually don't care about RuntimeReps
14:01:23 * hackage mmsyn7s 0.2.0.0 - Shows a sorted list of the Ukrainian sounds representations that can be used by mmsyn7 series of programs  https://hackage.haskell.org/package/mmsyn7s-0.2.0.0 (OleksandrZhabenko)
14:06:43 <maralorn[m]> My program is outputing stuff like: Memory pressure relief: Total: res = 98361344/98172928/-188416, res+swap = 93872128/93872128/0
14:06:49 <maralorn[m]> Is that normal for Haskell? (Or is that reflex specific?)
14:06:55 <fendor> Is the DTO pattern sensible in haskell? 
14:09:16 <fendor> or is that just a mindset artefact from my java time?
14:10:05 <dasli> is there any advantage to optimizing the definition of return in a Monad instance?
14:10:14 <dasli> i.e. for let-expressions?
14:11:18 <dasli> In my case I can't preserve the optimized representation in the result of (>>=), so I
14:11:31 <dasli> wonder if it's pointless to do it at all
14:17:43 <jle`> 3/b 3
14:19:59 <jle`> dasli: what do you mean by optimization?
14:20:05 <jle`> do you have an example in mind
14:28:00 <dasli> I have a big complicated type that is a monad instance on its own, but it turns out that it is unnecessary to make the result of return as complicated as the result of (>>=).
14:28:03 <d34df00d> There's no such thing as an existential newtype, right?
14:28:36 <d34df00d> That is, nothing analogous to `data SomeFoo where forall a. Foo a -> SomeFoo`, but with strictness/performance characteristics of newtype.
14:28:55 <jle`> dasli: i mean the result should be different because tehy're different functions, right?
14:28:55 <dasli> So it seems weird to define "return rawValue = BigAssType rawValue dummy dummy dummy dummy ..."
14:29:00 <jle`> d34df00d: no, i don't think so
14:29:19 <jle`> dasli: so what optimization are you thinking of?
14:29:30 <d34df00d> jle`: I think that's because existential type erasure machinery doesn't play along nicely with what newtypes do, right?
14:29:47 <d34df00d> But, in this case, would it make sense to allow such wrappers over type variables that have phantom role?
14:29:56 <jle`> i'm not sure exactly if it's necessarily impossible
14:30:07 <fendor> d34df00d, I know something similar in cabal-helper: https://hackage.haskell.org/package/cabal-helper-1.0.0.0/docs/Distribution-Helper.html#t:Ex
14:30:27 <dasli> I can just make a new constructor that takes only one argument, for return, and handle it in (>>=).
14:30:27 <d34df00d> fendor: but it's data, not newtype.
14:30:29 <jle`> since Foo a is boxed, it isn't totally unthinkable to have a newtype SomeFoo that is the same runtime rep rep
14:30:56 <jle`> dasli: the answer to that doesn't really have to do with monad necessarily
14:31:08 <jle`> it's just a general question about what functions you are going to write on your type
14:31:22 <jle`> so it's the same question for any old data type, if you remove the 'monad' part of the question :)
14:31:32 <dasli> Well I wanted to know how return is used. I figured that let-expressions could be optimized with this representation.
14:31:44 <jle`> return is used as you use it
14:31:49 <jle`> it's never magically inserted anywhere
14:32:03 <jle`> it is only used if you type it out in source code, or use a function that uses it
14:32:21 <jle`> there isn't anything monadic about let expressions, or at least nothing built into the language
14:32:21 <dasli> let-expressions in do-notation imply an application of return
14:32:23 <jle`> let x = y in z
14:32:33 <jle`> dasli: ah, in do notation, they don't
14:32:35 <jle`> they're just aliases
14:32:40 <jle`> lexical aliases, pretty much
14:32:52 <jle`> @undo do let z = 7; blahblah
14:32:52 <lambdabot> <unknown>.hs:1:23:Parse error: EOF
14:32:59 <jle`> @undo do let {z = 7}; blahblah
14:32:59 <lambdabot> let { z = 7} in blahblah
14:33:07 <jle`> see, no return :)
14:33:22 <jle`> although i'm not sure what you mean by 'imply' exactly, maybe that's where the misunderstanding is coming
14:33:28 <jle`> are you talking about a conceptual implication?
14:34:55 <jle`> dasli: you can see the full descirption of how do notation is desugared here
14:34:57 <jle`> https://www.haskell.org/onlinereport/haskell2010/haskellch3.html#x8-470003.14
14:35:03 <jle`> you can see that return is never used
14:35:08 <jle`> only >>= and fail
14:45:12 <glguy> maerwald: Did anyone pester you about 8.8.3 coming out?
14:46:09 <dasli> jle': thanks for the insight
14:46:53 <dasli> I'm pretty upset that I've been operating under this misconception for a while. I thought it came from arrow notation, but I'm reading that even there the let-expression is just extracted from the entire thing.
14:48:56 <xavo[m]> I can kinda understand that tbh
14:49:14 <dasli> I thought "do {let x = y; f y}" was equal to "return y >>= f", and I guess it is...maybe only if the monad laws hold?
14:49:19 <xavo[m]> and may or may not have used `foo <- return $ f x` to get around layout rules lol 
14:49:37 <xavo[m]> I think so, yeah
14:49:59 <dasli> ughhhhhhhhhh
14:51:16 <dasli> *I meant "do {let x = y; f x}" above
14:51:16 <jle`> dasli: yeah, they are semantically equal in that one can be substituted for the other
14:51:30 <jle`> but the former does not desugar into the latter
14:51:55 <jle`> well, actually there are differences in terms of type inference, as well
14:52:10 <jle`> that means you can't substitute them in the face of polymorphism necessarily
14:52:19 <dasli> I can't be sure of anything anymore, but I feel like I could write a program that diverges in one case but not the other
14:52:20 <jle`> but if they're all monomorphic then yeah, one can be substituted for the other and mean the same thing
14:52:35 <jle`> dasli: what cases are you talking about exactly?
14:52:40 <crestfallen> hello I'm looking at nondeterminism of the List monad here  https://stackoverflow.com/questions/27265920/what-is-non-determinism-in-haskell The second paragraph of the upvoted answer, beginning with "That is.."       is that correctly stated?  
14:52:58 <dasli> the do notation with let versus using return
14:53:31 <jle`> do you mean do let {x = y}; f y vs. return y >> f ?
14:53:33 <dasli> If I made return use a different constructor...ah jeez. I gotta take a break
14:53:33 <jle`> * return y >>= f
14:54:04 <jle`> well they might be internally different in the underlying representation maybe, but they aren't allowed to be observably different, semantically
14:54:15 <jle`> otherwise you have an unlawful monad
14:54:16 <dasli> according to the monad laws
14:54:18 <dasli> right
14:54:23 <dasli> not according to the machine
14:54:50 <dasli> OK, good to know!
14:54:51 <jle`> yeah it just comes down to what the '=' means in the definition of the laws
14:54:54 <dasli> Thank you very much
14:55:04 <crestfallen> it seems to me that "computes outputs of type A from inputs of type B .." is incorrect 
14:55:05 <jle`> no problem
15:02:28 <monochrom> Right, should be outputs of type B from inputs of type A.
15:13:04 <crestfallen> monochrom, thanks!
15:13:13 <crestfallen>  I thought I was going bonkers again
15:20:30 <fishoote1> hi, how can I fold over Alternative?
15:20:32 <fishoote1> foldl <|> Nothing [Nothing, Just 1, Just 2]
15:20:35 <fishoote1> something like this
15:20:44 <dmwit> > asum [Nothing, Just 1, Just 2]
15:20:48 <lambdabot>  Just 1
15:20:54 <fishoote1> awesome, thanks :)
15:21:06 <dmwit> > foldl (<|>) Nothing [Nothing, Just 1, Just 2] -- your thing also works fine after fixing the syntax
15:21:09 <lambdabot>  Just 1
15:21:22 <fishoote1> ah, so that's why it didn't
15:21:23 <fishoote1> thanks
15:23:54 <dmwit> dasli: There is another, more subtle difference between let and binding with return as well: partial patterns behave differently. A bottom with let, a call to `fail` with bind+return.
15:24:56 <dmwit> > do { let c:cs = ""; Just c }
15:24:59 <lambdabot>  <hint>:1:28: error: parse error on input â€˜}â€™
15:25:09 <dmwit> > do { let { c:cs = "" }; Just c }
15:25:12 <lambdabot>  Just *Exception: <interactive>:3:12-20: Non-exhaustive patterns in c : cs
15:25:27 <dmwit> > do { c:cs <- return ""; Just c }
15:25:32 <lambdabot>  Nothing
15:33:04 <crestfallen> wow that SO was edited 9 minutes ago.. thanks vigilant community!
15:40:38 <d34df00d> I want to map a string to a string in an extensible manner, having a function, say, getUnliftedName :: String -> String which is used by my library and where the user can add their own mappings.
15:41:06 <d34df00d> What I want is almost expressible by, say, class AsmType (tyName :: Symbol) ty | tyName -> ty, ty -> tyName where ; unliftedName :: proxy tyName -> Name
15:41:33 <d34df00d> Which can be later used as getUnliftedName liftedName = case someSymbolVal liftedName of SomeSymbol p -> unliftedName p
15:42:08 <d34df00d> The fundamental problem is that there's no guarantee that liftedName in this definition satisfies AsmType liftedName ty for some ty (modulo the difference between String and Symbol).
15:42:14 <d34df00d> And the type checker rightfully reminds me about that.
15:42:17 <d34df00d> So what can I do?
15:42:17 <hseg> ffs. why isn't Map Applicative?
15:42:26 <hseg> and how can I work around it?
15:42:30 <dasli> dmwit: thank you
15:42:56 <hseg> (ie how do i apply functions requiring an Applicative constraint at Map k)
15:44:06 <jle`> hseg: no pure
15:44:11 <jle`> hseg: it really depends on what you want to do
15:44:38 <jle`> one way to hack around it is to wrap Map k in the 'pure Applicative'
15:44:46 <jle`> but in the end you still have to answer the difficult questions
15:45:36 <hseg> ah right, since Map should have finite support, but const doesn't
15:45:36 <jle`> i think also there might be a 'default-map' out there that allows a pure
15:45:47 <jle`> i'm not sure where const comes into this
15:46:07 <fishoote1> how do I make integer division that is ceiled up?
15:46:22 <hseg> because morally, Map ~ (->) except it's only explicitly defined at finitely many values
15:46:38 <hseg> whereas const is explicitly defined everywhere
15:46:50 <jle`> still not sure the link you're trying to make
15:46:58 <jle`> oh, did you want Map to have the same Applicative instance as for funtions?
15:47:02 <hseg> yep
15:47:10 <jle`> then pure is't the only problem there either
15:47:12 <hseg> but that doesn't make sense
15:47:14 <jle`> your <*> won't match up either
15:47:26 <hseg> right, because i need constrained classes
15:47:54 <jle`> i mean, because <*> would be intersection
15:47:59 <fishoote1> also, what is the difference between quot and div? in docs it says div is truncated toward -inf, but what does that mean?
15:48:00 <jle`> which drops items
15:48:19 <jle`> here's a Map with an Applicative instance, where pure is a 'default value' https://hackage.haskell.org/package/total-map
15:48:31 <hseg> ... right
15:49:34 <jle`> yeah, when you asked why Map k doesn't have an Applicative instance, i already assumed you weren't talking about the one related to (->), heh
15:49:36 <jle`> sorry
15:49:49 <hseg> omg that's *exactly* what i've been headbashing for the last few days trying to make work
15:49:50 <jle`> but i thiink the total-map Applicative instance should somewhat mirror (->)
15:50:01 <hseg> thanks
15:50:04 <hseg> thanks!
15:50:29 <hseg> yep, same instance
15:51:11 <jle`> np :)
15:52:46 <dmwit> fishoote1: \x y -> (x+y-1) `div` y
15:53:13 <dmwit> fishoote1: quot rounds towards 0, div rounds towards -inf. quot is faster, div is more elegant
15:53:23 <dmwit> > (-3) `quot` 4
15:53:26 <lambdabot>  0
15:53:28 <dmwit> > (-3) `div` 4
15:53:31 <lambdabot>  -1
15:55:10 <jle`> although the Free Applicative over Map would be kinda interesting
15:55:56 <dmwit> I don't like the docs for quot/div. "truncated" is a technical term that means something different than what is needed in that sentence.
15:56:07 <hseg> only complaint is that it doesn't seem to export neither its constructors nor a forgetful map TMap -> Map
15:56:45 <hseg> jle`: what would that look like? finitely-branching trees?
15:57:07 <jle`> hseg: probably TMap -> Map would break semantics/the abstraction
15:57:14 <jle`> so it would be bad bad
15:57:47 <hseg> how? you're forgetting the totality of the map
15:58:03 <hseg> would be like a map NonEmpty a -> [a]
15:58:04 <dmwit> Indeed, you can't go TMap -> Map because finite domains have multiple representations as a Map+default.
15:58:14 <jle`> hm, i guess it's doable if you can enumerate all keys
15:58:38 <dmwit> (And no way to choose one or the other as "correct" in a denotative way.)
15:59:02 <jle`> hseg: Ap (Map k) would be a chain of delayed <*>'s
15:59:12 <dmwit> Well. One could cook up a way. But then you'd lose much of the benefit, because in a lot of cases it would force you to create a complete Map.
15:59:34 <jle`> and you could choose how to collapse <*>'s after-the-fact
15:59:51 <jle`> as i said earlier it just defers the difficult questions
16:00:02 <hseg> ... ok, then how about TMap k v -> (Map k v, v) ?
16:00:12 <dmwit> `range` was my attempt at doing something denotative that addresses some of the use cases for TMap->Map, but... well. =)
16:00:14 <jle`> same issue
16:00:27 <jle`> actually it would be 'worse'
16:00:29 <dmwit> hseg: I was already talking about TMap->Map+default.
16:00:38 <dmwit> hseg: So all my comments stand exactly as-is.
16:00:49 <hseg> ok... don't know enough about denotational design
16:00:53 <fishoote1> dmwit: thanks!
16:00:55 <hseg> why is this wrong?
16:01:06 <jle`> hseg: basically you're not allowed to differentiate between two things that are supposed to be 'equal'
16:01:16 <fishoote1> what is an example of rounding towards -inf?
16:01:21 <hseg> ah ok
16:01:37 <dmwit> hseg: Two differently-internally-represented TMap's which represent the same `a -> b` function should have observationally indistinguishable output from all API calls.
16:01:47 <hseg> right
16:01:50 <jle`> hseg: so, say, `fromPartial "hi" M.empty` and `fromPartial "hi" (M.singleton 0 "hi")`
16:01:58 <jle`> you aren't supposed to be able to distinguish between those two
16:02:02 <dmwit> fishoote1: I gave a concrete example above that shows the difference between rounding towards 0 and rounding towards -inf.
16:02:08 <hseg> right...
16:02:08 <jle`> so a TMap -> Map + default would allow you to do that
16:02:49 <dmwit> Not necessarily. That particular case is actually pretty easy to handle (see `trim`).
16:03:04 <jle`> ah yeah, i was going to express some doubt
16:03:19 <jle`> in my self
16:03:24 <hseg> ok, then how would i write f * g = \m -> sum [f ! i * g ! j | i <- supp f, j <- supp g, i <> j == m] ?
16:04:02 <jle`> convolution?
16:04:05 <hseg> yep
16:04:35 <hseg> implementing a Laurent polynomial library, need finiteness of the support to be able to even write down convolution
16:04:49 <hseg> s/convolution/multiplication/
16:05:27 <dmwit> I don't see why the output of that should even be finitely supported necessarily?
16:05:45 <dmwit> Except for specific Monoid instances where you know some extra structure of the monoid.
16:06:25 <hseg> because its support is contained in liftA2 (,) (supp f) (supp g)
16:06:53 <dmwit> No way. i <> j == m means there's lots of i, j outside supp f and supp g that we could pick.
16:07:26 <dmwit> (...and for which the contribution to the sum may be nonzero.)
16:07:38 <hseg> yeah, but i'm setting f * g = 0 there
16:07:58 <dmwit> That's a *much* stronger property than total-map assumes.
16:08:07 <hseg> what? no
16:08:51 <hseg> supp (f * g) = liftA2 (<>) (supp f) (supp g)
16:09:07 <hseg> supp f, supp g are supposed to be finite
16:09:15 <hseg> hence supp (f * g) is as well
16:09:21 <dmwit> What is supp (\x -> compare x (0 :: Int))?
16:09:46 <hseg> ill-defined
16:09:46 <dmwit> Is it [1..2^63]? Or [-1,-2..-2^63]? Or [0]? or what?
16:09:57 <dmwit> This is kind of my point.
16:10:00 <hseg> wrt what default value?
16:10:20 <hseg> all my maps are supposed to be finite wrt default=0
16:11:05 <dmwit> Right. That's a much stronger property than TMap assumes.
16:11:23 <dmwit> So the bad news is you have to make your own TMap with blackjack and hookers. The good news is: blackjack and hookers.
16:11:42 <hseg> i must be reading TMap incorrectly then
16:11:43 <dmwit> You can probably lean on `DetectableZero`, and eliminate the explicit default arguments from much of the API.
16:13:01 <dmwit> `fromPartial True (M.singleton False False)` is *the same* TMap as `fromPartial False (M.singleton True True)`. Nothing you do to those two TMaps is allowed to let you distinguish between them.
16:13:01 <hseg> i understood TMap k v = (v, Map k v) with (default, map) ! k = findWithDefault default k map 
16:13:18 <dmwit> There is no blessed default.
16:13:34 <dmwit> It is only an illusion. An accident of representation.
16:13:38 <dmwit> Internal detail only.
16:13:49 <hseg> ... wtf
16:13:55 <nshepperd> do you even need Applicative
16:14:07 <hseg> that's a very different design than i thought
16:14:17 * dmwit nods
16:14:42 <hseg> nshepperd: well, want to be able to eg lift addition over maps
16:14:56 <nshepperd> why not just use Map.intersectionWith
16:15:40 <hseg> ... bc i don't want to leak that implementation detail all over the place?
16:16:20 <dmwit> Anyway, I don't see a big deal here. You can make a simple newtype over `Map` and add `Monoid` or `DetectableZero` constraints on the contained type in the right API calls.
16:16:42 <dmwit> Very similar to, but not quite the same as, the way TMap is implemented.
16:16:49 <hseg> right
16:18:08 <hseg> wrote a class that abstracts over this "finitely supported" stuff
16:18:34 <hseg> and then added constraints to my Semiring instance
16:19:03 <hseg> managed to do this all in terms of containers' Map
16:19:43 <hseg> except getting failures due to Map not being Applicative
16:20:43 <hseg> ... but then again, afaict that's not exactly what i want anyway, so might as well write my own newtype
16:22:23 <fishoote1> dmwit: oh yes, I don't know how I didn't notce. It's late hour here :)
16:22:27 <nshepperd> is it a problem that 'i <- supp f, j <- supp g' is O(size(f) * size(g))
16:22:59 <hseg> well, i'll optimize that later
16:23:25 <hseg> but yeah, probably would want to trim f and g before any large multiplication
16:24:15 <nshepperd> i mean maybe you would want to calculate j = m - i and check if it's in the map instead
16:25:16 <hseg> yeah. too bad it's hard to tell ghc "if m is a Monoid, generate then filter. if m is a Group, take smaller, generate targets, check if exist"
16:25:30 <hseg> they're equivalent, but one's faster
16:27:54 * hackage hw-prim 0.6.2.40 - Primitive functions and data types  https://hackage.haskell.org/package/hw-prim-0.6.2.40 (haskellworks)
16:35:26 <hseg> hrm. Is there a way to combine two terms :: C a => a, :: D a => a into a single term :: (C \/ D) a => a assuming the terms agree whenever they're both instantiable? 
16:37:17 <dmwit> nope
16:37:33 <dmwit> You can make a new class E, and add instances appropriately.
16:37:49 <dmwit> That dispatch to the right underlying class for each instance.
16:38:03 <hseg> :(
16:38:12 <dmwit> I know.
16:39:07 <hseg> every so often I wonder if my choice of Haskell for this project was worth it
16:39:14 <monochrom> This is known as Dreaded Multiple Inheritance in C++ and Java.
16:39:36 <hseg> monochrom: ?
16:39:47 <monochrom> (C \/ D) a => a
16:40:24 * hackage inline-asm 0.2.1.0 - Inline some Assembly in ur Haskell!  https://hackage.haskell.org/package/inline-asm-0.2.1.0 (0xd34df00d)
16:42:25 <hseg> ok, what if i add C a => D a?
16:43:07 <hseg> you get this eg with nub :: Eq a => [a] -> [a] being asymptotically faster with an Ord a constraint
16:43:08 <monochrom> As in "class C a => D a"?  Then you just say "myfunc :: D a => a".
16:43:12 <dmwit> Then you may add a method to C that does the thing you care about, and use DefaultSignatures to get an implementation that uses D methods when it's not given.
16:43:55 <hseg> dmwit: ... not about to edit Eq
16:44:22 <dmwit> Too bad then. Back to class E.
16:44:24 <hseg> monochrom: that fails to be applyable at a s.t. C a but not D a
16:45:56 <dmwit> I'll be honest: I don't actually see this as a problem.
16:46:02 <hseg> really?
16:46:05 <dmwit> Really.
16:46:13 <dmwit> Say what you want to happen. Say it with code.
16:46:16 <hseg> ok
16:46:20 <dmwit> `instance E Foo where ...` is how you say it.
16:46:31 <hseg> ah no
16:46:53 <hseg> no, i want my compiler, which is smart enough to do similar things, to optimize this for me
16:47:09 <dmwit> No. That is letting the compiler say what will happen. I say, *you* say what happens.
16:47:09 <hseg> without me having to wire things explicitly
16:47:16 <koz_> hseg: nub won't magically go faster if 'a' happens to somehow have an Ord constraint.
16:47:25 <koz_> You need (for example) 'ordNub'.
16:47:29 <dmwit> Optimize an algorithm? Great, love it, go to town. But *choose* an algorithm? No, we are not there yet.
16:47:29 <hseg> right
16:48:33 <hseg> koz_: want nub to basically be able to say nub = if (instance @Ord @a) ordNub eqNub 
16:49:00 <hseg> dmwit: ^ is as much wiring as i'm willing to accept having to explicitly tell ghc
16:49:30 <hseg> but having to make the nub/ordNub choice all over my code? why on earth would i accept that tradeoff?
16:49:35 <dmwit> Okay. Then you cannot proceed. Pick a different language and start over. (Is that *really* better?)
16:49:56 <dmwit> You don't need to make it all over your code. All in one place, right next to the creation of class Nub.
16:50:23 <dmwit> But you do need to make the choice.
16:50:44 <hseg> well, i'm lucky this isn't a showstopper for me
16:51:02 <hseg> however, this is another in a *long* list of paper cuts
16:51:02 <dmwit> (...and I am okay with this. If you are not, like I said, you are out of luck. No sense arguing with me about it, because you'll just spend time not making your fantasy come true.)
16:51:45 <dmwit> I think it is not luck. I think it is not an important language feature. =)
16:52:21 <hseg> yeah, bc the class of occasions where you want it is rather small
16:52:32 <hseg> but in those cases you want it, you *really* want it
16:52:44 <dmwit> And because on those occasions, the solution that doesn't require a language feature is also very small.
16:52:57 <dmwit> Probably less text than the two of us combined have created on the topic so far.
16:53:02 <hseg> :)
16:53:10 <hseg> wait, how would your class solution work?
16:53:41 <dmwit> class Nub a where nub :: [a] -> [a]; instance Nub Int where nub = nubOrd; instance Nub NotAnOrdThing (are there any?) where nub = nubEq
16:54:12 <hseg> so you'd have to enumerate all types you wanted to apply Nub at?
16:54:24 <dmwit> Of course not. Only all the type constructors. =)
16:54:32 <hseg> ... no.
16:54:35 <hseg> just no
16:54:47 <dmwit> (For nub specifically, I think just use nubOrd, though. Seriously, what implements Eq but not Ord?)
16:55:28 <hseg> right. in my case however, you have a larger difference between Monoid and Group
16:56:53 * dmwit squints
16:59:22 <hseg> basically i want decomps m xs ys = filter (`elem` ys) (map (m -) xs) = [(x,y) | x <- xs, y <- ys, x<>y == m]
16:59:43 <hseg> (mod labeling/unlabeling in first implementation)
17:00:29 <hseg> so that'd be more like filter ((`elem` ys) . snd) (map (id &&& (m -)) xs)
17:01:31 <hseg> note the O(|xs|+|ys|) vs O(|xs|*|ys|) speed, all enabled by replacing Monoid by Group
17:01:53 * hackage reanimate 0.2.0.2 - Animation library based on SVGs.  https://hackage.haskell.org/package/reanimate-0.2.0.2 (DavidHimmelstrup)
18:16:05 <koz_> Is there something like mapAccumLM? THe desired signature is something to the tune of '(Traversable t, Monad m) => (a -> b -> (a, c)) -> a -> t b -> m (a, t c)'?
18:16:38 <koz_> '(Traversable t, Monad m) => (a -> b -> m (a, c)) -> a -> t b -> m (a, t c)', sorry.
18:18:57 <koz_> Would settle for t ~ [].
18:20:26 <koz_> Well, there is such a function for t ~ [], in the 'ghc' package.
18:25:00 <MarcelineVQ> might need to traverse StateT yourself
18:25:08 <koz_> MarcelineVQ: It's what I'm doing now.
18:25:15 <koz_> Having inspected how mapAccumL is implemented.
18:26:33 <koz_> Looks like I'm back on my lift game.
18:26:39 <koz_> Gotta lift every day.
18:27:51 <ski> @type mapAccumL
18:27:52 <lambdabot> Traversable t => (a -> b -> (a, c)) -> a -> t b -> (a, t c)
18:27:58 <ski> @type ((state . (swap .)) .) . flip . mapAccumL . flip . (((swap .) . runState) .) :: Traversable t => (a -> State s b) -> (t a -> State s (t b))
18:28:00 <lambdabot> Traversable t => (a -> State s b) -> t a -> State s (t b)
18:28:14 <koz_> ski: Did you run that through @pl?
18:28:20 <ski> @type mapM :: Traversable t => (a -> State s b) -> t a -> State s (t b)
18:28:23 <lambdabot> Traversable t => (a -> State s b) -> t a -> State s (t b)
18:28:28 <ski> @type mapM
18:28:29 <lambdabot> (Traversable t, Monad m) => (a -> m b) -> t a -> m (t b)
18:28:33 <ski> @type (((liftM swap .) . runStateT) .) . mapM . ((StateT . (liftM swap .)) .)
18:28:35 <lambdabot> (Monad m, Traversable t) => (a -> b1 -> m (b1, b2)) -> t a -> b1 -> m (b1, t b2)
18:28:38 <ski> @type (runStateT .) . mapM . (StateT .)
18:28:40 <lambdabot> (Traversable t, Monad m) => (a -> s -> m (b, s)) -> t a -> s -> m (t b, s)
18:28:46 <ski> koz_ : i wrote it by hand, of course
18:28:51 <koz_> ski: Naturally.
18:29:09 <xavo[m]> @freenode_hseg:matrix.org: bit late, would you be able to use a ghc rewrite rule for that? not sure if the rewriter can do typeclass stuff like that
18:29:09 <lambdabot> Unknown command, try @list
18:29:24 <koz_> So are you saying what I sought was '(runStateT .) . mapM . (StateT .)?
18:29:30 <koz_> And isn't mapM just traverse?
18:29:51 <ski> yes
18:30:08 <koz_> And this, ladies, gents and tentacled horrors, is why I love #haskell. :P
18:31:01 <ski> xavo[m] : hseg left, close to an hour ago, in case that's who you're talking to
18:31:26 <xavo[m]> ohh yep
18:31:39 <xavo[m]> that's probably why my client did that then too
18:31:50 <xavo[m]> ty
18:32:50 <ski> "@freenode_hseg:matrix.org: ..." did look a bit strange
18:33:05 <ski> xavo[m] : you could always `@tell hseg ...' it
18:34:32 <ski> koz_ : `lift' ?
18:34:43 <koz_> ski: The transformer lift.
18:34:53 <xavo[m]> ah ok, I might but I'll test it first
18:35:11 <ski> yea, just not seeing how it relates to `mapAccumLM' or `mapM'/`traverse'
18:35:26 <koz_> ski: I'd need it inside the function passed to it.
18:35:36 * ski doesn't follow
18:35:40 <koz_> Since I'm already piling StateT atop an existing stack, and would need to do things in it.
18:35:55 <ski> did what i say above help, or were you already doing that ?
18:36:13 <koz_> ski: It did help, and I ended up doing the equivalent, but longer.
18:36:14 <ski> m.hm
18:36:35 <koz_> But it was quite enlightening.
18:39:56 <ski> @let arg :: (a1 -> a0) -> ((a0 -> b) -> (a1 -> b)); arg modArg f = f . modArg
18:39:59 <lambdabot>  Defined.
18:40:18 <ski> @let res :: (b0 -> b1) -> ((a -> b0) -> (a -> b1)); arg modRes f = modRes . f
18:40:19 <lambdabot>  .L.hs:243:1: error:
18:40:19 <lambdabot>      The type signature for â€˜resâ€™ lacks an accompanying binding
18:40:19 <lambdabot>      |
18:40:25 <ski> @let res :: (b0 -> b1) -> ((a -> b0) -> (a -> b1)); res modRes f = modRes . f
18:40:29 <lambdabot>  Defined.
18:42:15 <ski> @let infixr 5 ~>; (~>) :: (a1 -> a0) -> (b0 -> b1) -> ((a0 -> b0) -> (a1 -> b1)); (modArg ~> modRes) f = modRes . f . modArg
18:42:18 <lambdabot>  Defined.
18:43:30 <ski> @type res (state . res swap) . flip . mapAccumL . flip . res (res swap . runState)
18:43:33 <lambdabot> (MonadState s m, Traversable t) => (b -> State s c) -> t b -> m (t c)
18:43:44 <ski> hm
18:44:38 <ski> @type (flip . res (res swap . runState) ~> res (state . res swap) . flip) mapAccumL
18:44:40 <lambdabot> (MonadState s m, Traversable t) => (a -> State s c) -> t a -> m (t c)
18:45:56 <ski> @type ((res (res swap . runState) ~> res (state . res swap)) . (flip ~> flip)) mapAccumL
18:45:58 <lambdabot> (MonadState s m, Traversable t) => (a1 -> State s a2) -> t a1 -> m (t a2)
18:54:21 <ski> @djinn ((a0 -> b0) -> (a1 -> b1)) -> (((i -> a0) -> (o -> b0)) -> ((i -> a1) -> (o -> b1)))
18:54:21 <lambdabot> -- f cannot be realized.
18:54:24 <ski> hrm
18:57:48 <ski> @type ((uncurry (~>) . (res *** res)) (res swap . runState,state . res swap) . (flip ~> flip)) mapAccumL
18:57:51 <lambdabot> (MonadState b m, Traversable t) => (a1 -> State b a2) -> t a1 -> m (t a2)
18:57:57 <ski> @type ((uncurry (~>) . (res *** res) . ((res swap .) *** (. res swap))) (runState,state) . (flip ~> flip)) mapAccumL
18:57:59 <lambdabot> (MonadState s m, Traversable t) => (a1 -> State s a2) -> t a1 -> m (t a2)
19:03:31 <refusenick> I've seen talk of writing "simple Haskell" (avoid GHC extensions, typeclasses, and othre fancy features), which is encouraging to a newcomer like me.
19:03:45 <refusenick> Is there a list of libraries in this style?
19:03:50 <koz_> refusenick: I would hardly consider _type classes_ to be a 'fancy feature'.
19:04:16 <koz_> Also, GHC extensions vary widely in 'simplicity', for any definition of 'simplicity'.
19:04:28 <koz_> So without further qualification, I'm not sure what you're asking.
19:04:31 <refusenick> koz_: Like I said, I don't know very much about Haskell. I just read "Scrap Your Typeclasses". Is there a good rebuttal to it?
19:04:56 <koz_> refusenick: I assume you refer to the Gabriel Gonzales post?
19:05:16 <koz_> In which case it is semi-self-rebutting, since Gabriel now believes that 'type classes with laws are OK'.
19:05:26 <koz_> (or, perhaps more precisely, 'type classes should have laws')
19:05:29 <koz_> (an opinion I share)
19:05:51 <refusenick> I'd like to experiment with interactive DSLs and compiling existing Haskell modules in them. I've seen toy Haskell98 compilers (e.g. the pointfree obfuscated one), so I'm wondering how far that goes.
19:06:23 <koz_> What do you mean by 'interactive DSL' in this case? I've not heard that term before.
19:07:28 <refusenick> koz_: an embedded language which supports live code reloading (something which Haskell as a whole isn't great at)
19:07:41 <koz_> Ah, I see.
19:07:52 <koz_> In all honesty, I'm not the best person to ask. However, what I will say is:
19:07:55 <refusenick> e.g. live visualization of Lie group-theoretic constructs for physics
19:07:58 <koz_> 1) You want to do something fairly advanced
19:08:19 <koz_> 2) You may want to practice on something simpler before grabbing onto sweeping, context-free generalization of what is 'simple' or 'non-fancy'.
19:08:27 <koz_> s/generalization/generalizations/
19:11:26 <ski> @type uncurry (~>) ((uncurry (>>>) . (fst *** fst) &&& uncurry (<<<) . (snd *** snd)) (((res *** res) . ((res swap .) *** (. res swap))) (runState,state),(flip,flip))) mapAccumL
19:11:28 <lambdabot> (MonadState s m, Traversable t) => (a1 -> State s a2) -> t a1 -> m (t a2)
19:11:31 <ski> @type (uncurry (~>) . (uncurry (>>>) . (fst *** fst) &&& uncurry (<<<) . (snd *** snd)) . first ((res *** res) . ((res swap .) *** (. res swap)))) ((runState,state),(flip,flip)) mapAccumL
19:11:33 <lambdabot> (MonadState s m, Traversable t) => (a1 -> State s a2) -> t a1 -> m (t a2)
19:11:53 <koz_> ski: What is this pointfree monstrosity you're trying to birth?
19:12:13 <refusenick> Okay, something more specific then: I don't know much about category theory, but I do know from algebra that a monoid set satisfying the group axioms minus invertibility. I see a lot of talk about monoids in Haskell as representations of sequenced operations. Would an embedding of a group construct correspond to reversible programming a la Prolog, going backwards along a sequence?
19:12:45 <refusenick> a monoid is a set* 
19:14:12 <ski> koz_ : a better (more principled, structured) way to do the wrapping/unwrapping, turning `mapAccumL' into `mapM', and `mapM' into `mapAccumL' or `mapAccumLM'
19:14:26 <refusenick> To clarify, I see talk of monads as sequencing constructs and as "just monoids in the category of endofunctors"
19:14:28 <koz_> ski: Ah.
19:14:33 <koz_> refusenick: Was about to say.
19:14:48 <koz_> See if anyone chimes back at you, since that's far over my own head.
19:15:22 <koz_> THe thing is, we use monads for sequencing _effects_, and most effects can't be meaningfully undone.
19:15:26 <koz_> Try undo State, for example.
19:15:29 <koz_> Or IO.
19:15:41 <ski> bsically, i'm playing around with something SEC-like (maybe more advanced, not sure)
19:16:07 <refusenick> koz_: Do you remember matrix inverses from linear algebra?
19:16:14 <koz_> refusenick: Yes.
19:16:23 <refusenick> (I'm assuming you are/were a CS major and took lin alg)
19:16:29 <koz_> I was, and I did.
19:17:01 <ski> refusenick : what do you mean by "going backwards along a sequence"
19:17:13 <ski> refusenick : what do you mean by "going backwards along a sequence"
19:17:28 <refusenick> They let you compose one linear transformation with another such that the new transformation is the identity function (matrix)
19:18:02 <koz_> refusenick: Yup, makes sense.
19:18:14 <refusenick> In abstract algebra (which I don't think CS majors take - I'm a math undergrad ATM), you have generalizations such as free Abelian groups with bases and inverses
19:18:14 <ski> refusenick : you said "monoids in Haskell as representations of sequenced operations", but then said "monads as sequencing constructs" -- did you mean monad, or monoids, or both ?
19:18:24 * hackage avro 0.4.7.0 - Avro serialization support for Haskell  https://hackage.haskell.org/package/avro-0.4.7.0 (haskellworks)
19:19:00 <refusenick> ski: Both, I suppose. From reading the Wikipedia page on the categorical definition of a monoid, which kind of looks like a monoid in algebra.
19:19:08 <koz_> refusenick: My knowledge of abstract algebra is pretty damn small.
19:19:41 <refusenick> ski: When you say that a monad is in the category of endofunctors, is that akin to saying that it's an automorphism on a set?
19:19:49 <ski> refusenick : "A monad is just a monoid in the category of endofunctors, what's the problem?" -- Phil Wadler
19:20:17 <ski> "is that akin to saying that it's an automorphism on a set?" -- no
19:20:24 <refusenick> koz_: So's mine, tbqh. I'm an undergrad, so buly me.
19:21:19 <iqubic> What is an automorphism?
19:21:42 <ski> refusenick : also, i don't necessarily see how it'll "correspond to reversible programming a la Prolog" .. that's "non-deterministic reversible" (relational). while group representations are ordinary bijective functions
19:21:46 <refusenick> iqubic: https://en.wikipedia.org/wiki/Automorphism
19:21:55 <ski> iqubic : an isomorphism between an object and itself
19:22:13 <iqubic> :t id
19:22:15 <lambdabot> a -> a
19:22:21 <iqubic> Is that an automorphism?
19:22:25 <ski> @type [id,not]
19:22:27 <lambdabot> [Bool -> Bool]
19:22:30 <ski> sure
19:22:38 <iqubic> How is Not an automorphism?
19:22:52 <ski> it's invertible
19:22:59 <dmwit> Which requirement of automorphisms do you believe it does not satisfy?
19:23:05 <iqubic> Is an automorphism the same as an invertible endofunctor?
19:23:26 <ski> of course, typically one says "automorphism" when one has some more structure in mind than just `Set'
19:23:51 <ski> (since in that case, one can just say "bijection")
19:24:05 <dmwit> No. An automorphism is an arrow; a functor is a mapping on objects and arrows.
19:24:26 <iqubic> so an automorphism is just some function f :: a -> a, such that "(f . f) = id"?
19:24:29 <refusenick> haha I have no idea what that means
19:24:59 <dmwit> No. There are automorphisms for which `f . f = id` is not validated.
19:25:18 <zaifir> iqubic: Involution, I think.
19:25:20 <dmwit> For example, (+1) :: Int -> Int is an automorphism, but (+1) . (+1) /= id.
19:25:23 <iqubic> dmwit: Can you please show me a counter example?
19:25:48 <refusenick> I'm amazed that so many people here are familiar with the language of category and type theory but not abstract algebra (a generalization of the basic set theory and linear algebra which every CS and math major learns).
19:25:50 <iqubic> What's the difference between an automorphism and an endofunctor?
19:25:58 <dmwit> (Better make it Int32 -> Int32 to prevent some language lawyers from complaining. You get the idea.)
19:26:12 <ski> an automorphism is a morphism/arrow `a', in some category, from some object `X' in it, to `X', iow `a : X >---> X', such that `a' has a two sided inverse `b', iow there is `b : X >---> X' with `b . a = id_X' and `id_X = a . b'
19:26:46 <iqubic> That seems more strict than just an endofunctor.
19:27:00 <ski> an isoorphism is a morphism/arrow `i', in some category, from some object `X' in it, to some object `Y' in it, iow `i : X >---> Y', such that `y' has a two sided inverse `j', iow there is `j : Y >---> X' with `j . i = id_X' and `id_Y = i . j'
19:27:02 <iqubic> So, it's an invertible endofunctor.
19:27:07 <iqubic> :t involuted
19:27:09 <lambdabot> (Profunctor p, Functor f) => (a -> a) -> p a (f a) -> p a (f a)
19:27:16 <ski> no, there's no functors in the picture, here
19:27:18 <dmwit> It is neither more strict nor less strict.
19:27:30 <iqubic> Oh. Right... I see.
19:27:32 <ski> there is just one category, and no functors mentioned on it
19:27:43 <refusenick> iqubic: An automorphism is an isomorphism from a set to itself. For example, a linear map T: R^3 -> R^3 is an automorphism.
19:27:55 <ski> an automorphism is just an isomorphism where the domain and codomain are the same. above, `X' and `Y' are the same object
19:28:02 <dmwit> All four properties of "is automorphism, is endofunctor", "is automorphism, isn't endofunctor", "isn't automorphisms, is endofunctor", "isn't automorphism, isn't endofunctor" are occupied.
19:28:16 <iqubic> But it's basically the same thing as the involuted function from lens?
19:28:43 <dmwit> No. Involutions are self-inverse. Automorphisms need not be.
19:28:57 <dmwit> For example, (+1) :: Int32 -> Int32 is an automorphism but not an involution.
19:29:06 <dmwit> (Same exact counterexample, because same exact question.)
19:29:37 <iqubic> So its just an invertible morphism from one type, to the same type.
19:29:45 <iqubic> I see. That's not too complex at all.
19:29:51 <ski> iqubic : note that i said `a' and `b', mentioning `a . b' and `b . a'. rather than just saying `a', mentioning `a . a'
19:30:06 <iqubic> ski: Right. That makes sense.
19:31:09 <iqubic> So you can use the lens library to create isos.
19:31:11 * ski assumes refusenick meant abelian groups, free over a set (of generators). rather than, say, free over a group. (the latter is the abelianization)
19:31:13 <iqubic> :t iso
19:31:15 <lambdabot> (Profunctor p, Functor f) => (s -> a) -> (b -> t) -> p a (f b) -> p s (f t)
19:32:06 <iqubic> So, when you have "(iso f g) :: iso' a a" then both f and g are both automorphisms.
19:32:27 <iqubic> I think that is correct. Provided that (iso f g) is actually law abiding.
19:32:34 <refusenick> koz_: I suppose what I'm really asking is, can an infinite stream of objects guaranteed to be members of a group and be generated by other members of it be given a tree representation in memory such that the chain of operations leading up to a particular state can be efficiently manipulated knowing the generating set (presumably encoded in a type-theoretic fashion?) and the current element?
19:33:56 <refusenick> e.g. for graphics programming, interactive quaternion operations to manipulate an arbitrarily-detailed model with finite numbers of group operations and finite memory
19:34:25 <refusenick> and dynamically trim the past state such that it can be efficiently accessed while taking minimal resources
19:34:38 <dmwit> fieldtrip is an example of a Haskell graphics library where the semantic objects are infinite sequences of rendering instructions, each at a different level of detail, so that you can "zoom in forever" if you wish.
19:35:15 <dmwit> Excuse me. The semantic objects are infinitely detailed renderings, and the in-memory representation is as an infinite sequence of more-accurate renderings.
19:36:00 <refusenick> dmwit: Is it FRP-based? Does it take a different approach to embedding limit-based analytic constructs in a discrete structure?
19:36:05 <ski> refusenick : lists are free monoids (over sets). bags/multisets are free abelian monoids (over sets). they can be represented as functions (with finite support) to naturals
19:36:12 <dmwit> It is FRP-based. I don't understand the second question.
19:36:45 <ski> refusenick : free abelian groups (over sets) is some kind of "integral bags/multisets" (not sure what one'd call them), where one can have negative counts, can be represented as functions (with finite support) to integers. free groups (over sets) are more complicated. i'm not sure how commonly they'd be useful in programming
19:36:48 <refusenick> dmwit: You can't have the "real" infinite precision required to compute limits in general on a finite computer.
19:36:53 <dmwit> (Different than what? But even if I knew that, I don't think I would know the answer, because I don't know what "embedding limit-based analytic constructs in a discrete structure" means.)
19:37:40 <ski> iqubic : sounds right
19:37:47 <refusenick> ski: Given that lazy lists appear to be the standard way to represent streams in Haskell, I imagine free groups over lists would suffice for a lot of purposes.
19:37:53 <dmwit> Suppose I don't believe in real infinite precision. Then what?
19:38:15 <koz_> refusenick: _Pure_ streams.
19:38:29 <koz_> If you want effects in your streams, you may find that approach... disappointing.
19:39:20 <dmwit> (I'm okay with arbitrary precision, though.)
19:39:45 <iqubic> I feel like there's a way to rewrite this using _Wrapping or _Unwrapping, but I'm not sure which one to use.
19:39:46 <iqubic> (iso Sum getSum)
19:40:03 <refusenick> dmwit: No one wants to talk about resolution going down to the level of a Planck length. Showing that a limit converges like in standard calculus probably suffices for a lot of tasks in a pure language like Haskell, no?
19:40:07 <koz_> iqubic: Isn't there some Coercible-based lens thingo for this exact purpose?
19:40:15 <iqubic> I'm not sure.
19:40:30 <dmwit> It... probably suffices for the things it suffices for?
19:40:34 <ski> refusenick : not sure what you mean by "free groups over lists"
19:40:42 <dmwit> Most of my day-to-day Haskell programming does not rely on standard calculus at all.
19:40:55 <dmwit> I don't know what qualifies as "a lot".
19:41:14 <dmwit> Generally I find the question just weird and misguided. Let's talk about what *you* want to do, not what happens "a lot".
19:41:47 <refusenick> ski: I meant lists as free monoids over sets.
19:41:49 <koz_> iqubic: https://hackage.haskell.org/package/lens-4.19.1/docs/Control-Lens-Iso.html#v:coerced
19:41:51 <refusenick> I'm rally tired rn
19:42:07 <refusenick> really*
19:42:10 <iqubic> But how do I tell GHC to use Sum, and not Product?
19:42:14 <ski> refusenick : and relating them to groups, how ?
19:42:29 <koz_> iqubic: TypeApplications? Or just give a specific signature for the resulting Iso.
19:42:38 <refusenick> ski: In this instance, does free monoid mean the same thing as it would in algebra?
19:42:54 <koz_> You'd _have_ to do one or the other anyway, since type inference turns to custard around Coercible pretty fast.
19:43:15 <ski> refusenick : "free" has the standard categorical meaning, yes, if that's what you're asking
19:43:26 <dmwit> refusenick: Up to some quibbles about infinities and stuff, yes.
19:43:28 <ski> (which is a generalization of the abstract algebra one)
19:44:22 <refusenick> ski: What would something like a list whose concatenative operation (under which it forms a monoid in Haskell, IIRC) also satisfied an invertibility axiom such that it was a free group over a set?
19:44:22 <ski> yea, there some carpet-sweeping to do with whether we only allow finite list or not
19:44:59 <ski> yea, there some carpet-sweeping to do with whether we only allow finite list or not
19:45:16 <dmwit> I think it's probably relatively easy to cook up an abstract data type that behaves like a free group at the abstraction boundary.
19:45:28 <iqubic> I'll just use: (coerced :: Iso' a (Sum a))
19:45:38 <koz_> iqubic: That'd work.
19:45:41 <iqubic> And GHC seems to think that's valid.
19:45:53 <koz_> ... why would GHC _not_ think that valid?
19:45:57 <ski> refusenick : i'm missing a verb in that question
19:46:11 <dmwit> e.g. Seq offers efficient access to both ends, so you could smash two Seq's together and throw away any bits in the middle that cancel out.
19:46:21 <iqubic> koz_: No idea.
19:46:33 <koz_> Me neither, hence my line of questioning.
19:46:41 <ski> given `Eq', dmwit, yes
19:46:50 <dmwit> I haven't seen any interesting applications of that data structure, but it should certainly be creatable.
19:46:53 <dmwit> ski: right
19:47:41 <refusenick> ski: I'm actually specifically interested in the cases where infinite constructs can be represented finitely - I'd like to use Haskell to encode ideas from Crane's "Discrete Differential Geometry"
19:47:43 <iqubic> koz_: I just ran my tests, using this new definition. And all of them passed.
19:47:57 <refusenick> ski: over a set looks like?
19:48:06 <refusenick> I meant to put "looks like" at the end
19:48:16 <ski> refusenick : also, particular lists aren't monoids. a set/type of lists (equipped with law-abiding operations) would be a monoid, in fact even a free monoid (assuming we only admit finite lists)
19:48:43 * ski 's not familiar with that book
19:49:34 <ski> <refusenick> koz_: I suppose what I'm really asking is, can an infinite stream of objects guaranteed to be members of a group and be generated by other members of it be given a tree representation in memory such that the chain of operations leading up to a particular state can be efficiently manipulated knowing the generating set (presumably encoded in a type-theoretic fashion?) and the current element?
19:49:42 <ski> i also didn't understand most of this ^
19:49:57 <koz_> ski: IN all fairness, me either.
19:50:13 <koz_> But then again, I'm pretty maths-illiterate for the most part.
19:50:40 <refusenick> ski: I've read that FRP has a common problem with internal representations of data as lazy lists leading to space leaks due to being unable to tell what needs to be thrown away.
19:50:44 <ski> refusenick : i mean, i'm having trouble even parsing the grammar
19:50:48 <iqubic> why is Coerced in lens not defined as "Coerced = involuted coerce"?
19:50:52 <iqubic> :t involuted
19:50:53 <lambdabot> (Profunctor p, Functor f) => (a -> a) -> p a (f a) -> p a (f a)
19:51:17 <koz_> I think it has to do with type inference noping out at the first sign of trouble.
19:51:20 <mjrosenb> lens question: I have an array where one or 0 values be targeted by a lens, how can I get that value?
19:51:42 <Axman6> you's need to use... coerced $ involuted coerce :P
19:51:44 <refusenick> Can a Haskell program reify its in-memory data representation and trim it?
19:51:54 <koz_> refusenick: Of what?
19:51:57 <iqubic> mjrosenb: what do you mean by one or zero targets can be targeted?
19:53:51 <refusenick> koz_: Can asserted facts in a database (which a lazy list representation of past state effectively is) be dynamically retracted based on compile-time rules for program composition at runtime, treating new inputs as small programs in the way that new Prolog terms are themselves valid programs being added to a larger one?
19:53:53 <ski> perhaps refusenick is thinking about representing quotient sets, such that one representant from an equivalence class could be swapped out for another one, which might be a more efficient representation of the equivalence class
19:53:59 <ski> (cf. splay trees)
19:54:05 <mjrosenb> so, I have Array (Int, Int) Cell.  Cell is a rather large nested structure, but it is something like data Cell = A A | B B | C C
19:54:25 <iqubic> And what are you trying to do?
19:54:25 <refusenick> ski: Yes, that is roughly where I was headed.
19:54:46 <iqubic> mjrosenb: What are you trying to do with that data structure?
19:55:03 <ski> "compile-time rules for program composition at runtime" sounds interesting
19:55:34 <ski> and i wouldn't say that Prolog terms are valid programs
19:55:42 <ski> (but the other way around)
19:55:50 <refusenick> knows(john,sarah).
19:55:52 <iqubic> mjrosenb: We can only help you if we know what you're trying to do.
19:56:01 <iqubic> refusenick: That's a fact.
19:56:04 <mjrosenb> there's one cell where it should use the C data constructor, where the arguments to it are also specific data constructors
19:56:14 <mjrosenb> and I want to get that Cell.
19:56:45 <refusenick> iqubic: facts like foo(a,b). are syntactic sugar for terms of the form foo(a,b):-.
19:56:45 <iqubic> So you want to figure out which Cells are using the C data constructor?
19:56:51 <iqubic> Sure.
19:56:55 <iqubic> I'll alow it.
19:57:03 <iqubic> *allow
19:57:14 <mjrosenb> iqubic: C with its argument being a specific value
19:57:34 <iqubic> Ah. I see. I'm not sure what the best way of doing that is.
19:57:34 <ski> refusenick : actually not
19:58:09 <ski> refusenick : however, one may think of them like that, from a Horn clause POV
19:58:22 <iqubic> mjrosenb: I think it might be easier for you to first write this function without lenses, and then convert it to using lenses once you have the basic logic hammered out.
19:58:24 <mjrosenb> so data C = One Foo Bar | Two Baz Quux; and one cell would match the pattern C (Two _ PC)
19:58:29 <ski> (and clause/2 will view them like this)
19:59:43 * ski idly wonders whether refusenick's been in ##prolog at some point
19:59:43 <refusenick> ski: If Haskell can embed DSLs via free monads or tagless final form or many other ways which I can't remember, I don't see why a partial evaluator with rules specific to that language can't be embedded.
19:59:50 <refusenick> I have 
20:00:01 <refusenick> I'm sure what I'm thinking of has been done before.
20:00:11 <mjrosenb> iqubic: sounds reasonable.
20:00:16 <refusenick> I just don't know what it's called yet. I guess Haskell is like math after all.
20:00:27 <iqubic> mjrosenb: also, you originally said this could be matched 1 or 0 times. I don't see any reason why you can't have 2 or more cells that use the C constructor.
20:01:04 <ski> refusenick : hm, sounds reasonable (although i'm not really connecting this that much to what you said before)
20:03:07 <ski> refusenick : i suppose i'm not really following "Can asserted facts in a database (which a lazy list representation of past state effectively is) be dynamically retracted based on compile-time rules for program composition at runtime, treating new inputs as small programs in the way that new Prolog terms are themselves valid programs being added to a larger one?" either
20:06:11 <refusenick> ski:If that DSL encodes the operations over an algebraic object (say, the group of quaternions) such that it builds a sequence of user-input applications of its defined operations as a stream of operations, can it be given a partial evaluator encoding identities for cutting down existing program state when no longer reachable?
20:06:31 <iqubic> what does filteredBy do from lens?
20:06:53 <refusenick> What if you have two different DSLs and take the tensor product of the objects they represent? What past state becomes unreachable?
20:07:07 <ski> why a stream ?
20:07:13 <ski> what is the stream representing ?
20:07:25 <ski> (e.g. why not a tree ?)
20:07:25 <refusenick> ski: sequential user input
20:07:45 <refusenick> ski: I was wondering if there were tree equivalents of streams, actually
20:08:04 <refusenick> Like I said, I'm new to Haskell
20:08:06 <ski> so the user always modifies the current object, never combines it with previous, separately constructed, objects ?
20:09:16 <iqubic> About my question of "What does filteredBy do?" I remembered there being a section about filteredBy in Optics By Example. So I opened my pdf copy of the book and used control-f to go to the right section. I solved that myself.
20:09:29 <refusenick> ski: What if I say "I no longer need the object this DSL represents, only this new object formed out of a product or sum with this other object"?
20:10:22 <ski> mm, sounde like you want to, when reasonable, cut down on the representation size, by switching representation, to me
20:10:27 <refusenick> ski: What if there are intermediate objects in the construction of new ones which disappear afterwards?
20:11:01 <ski> as a simple example, you'd like to replace `0 * x' by just `0', so that the space for `x' can be reclaimed
20:11:34 <refusenick> ski: That's exactly what I mean. I'd like a runtime-interactive physics DSL in a language which can directly encode the mathematics I'm thinking in.
20:12:00 <ski> or, if you have `(y * x) + ((z - y) * x)', you'd want to replace that by just `z * x'
20:12:11 <mjrosenb> iqubic: here's the non-lensy code (sorry that took so long, I had to fix like 20 other compilation errors)
20:12:16 <mjrosenb> [rogueCellColor] = [c | Cell.Rogue (Cell {_character = Player _, _underlying = MC.MatchCell {MC._color=c}}) <- A.elems (ls ^. Model.grid)]
20:12:22 <iqubic> Totally fine.
20:12:48 <iqubic> I'll let someone else do the translation to the lens. I have to go now.
20:13:41 <iqubic> But first, I'm going ask you: Do you think the lens version of this function will be easier to understand?
20:14:45 <iqubic> mjrosenb: Also, what happens if there are no rogue cells, or 2 or more rouge cells? In that case the code will crash with runtime error because those are unmatched patterns.
20:15:33 <mjrosenb> possibly.  It'll certainly be nicer to have all of the flow in one direction, as opposed to now, where I start diving into the structure on the right, then continue on the left
20:15:52 <ski> refusenick : well, you could certainly build ASTs for such expressions, and manipulate them. perhaps normalizing them in some fashion. perhaps amorticizing that normalization over multiple operations
20:16:28 <mjrosenb> I can change the binding to a case, and handle the 0-matches situation as well.
20:16:40 <iqubic> mjrosenb: I have to go now, but hopefully someone else can help you.
20:16:40 <ski> i'd like a way to actually do under-the-covers representation switching (like one could say thunks are replaced with cached results), though
20:16:47 <mjrosenb> and if there is ever more than one match, then... the universe really should end.
20:17:29 <iqubic> mjrosenb: It's that sort of thinking that leads to really nasty bugs cropping up in the future.
20:18:20 <refusenick> ski: Can you encode an abstract machine (e.g. a virtual stack machine like Forth) for a DSL to optimize against?
20:18:28 <mjrosenb> this is the character that the player is controlling.  If there are 0 of them, then the player is dead. (this case should be handled).  If there are two of them, then, something has gone horribly horribly wrong.
20:18:50 <ski> refusenick : i suppose
20:18:52 <iqubic> I don't have knowledge of the code base you're working with, but in the little snippet you've shown, it looks like there can be any number of rouge cells.
20:20:04 <refusenick> Are there Haskell tutorials which introduce it by analogy to set theory or linear algebra (as in finite vector spaces, not matrix computations)?
20:20:15 <mjrosenb> There is nothing in the types that enforces it, but it definitely holds when a level is created, and if there's ever a state transition where this invariant stops holding, I do want to find out ASAP.
20:20:32 <ski> @where HR
20:20:32 <lambdabot> "The Haskell Road to Logic, Maths and Programming", by Kees Doets,Jan van Eijck, at <http://homepages.cwi.nl/~jve/HR/> (broken ?),<https://web.archive.org/web/20190528043209/https://homepages.cwi.nl/
20:20:32 <lambdabot> ~jve/HR/>
20:20:56 <ski> i dunno whether that ^ might be more along the lines of what you're looking for, refusenick
20:21:08 <iqubic> mjrosenb: I hope you can get the help you need with this project.
20:21:40 <ski> refusenick : i wonder what kind of analogies you'd like to draw
20:22:12 <ski> (also, by "finite", i suppose you mean "finite-dimensional")
20:22:50 <ski> (also, why finite-dimensional. hm, you mentioned being interested in representing infinite stuff finitely. can you elaborate on that ?)
20:23:54 <ski> (unless you're in a finite scalar field, there's just one finite vector space, the zero-dimensional one)
20:24:49 <refusenick> ski: I need to go now, but sort of. Thanks for the pointers.
20:25:07 <ski> no problem
20:25:16 <ski> (perhaps we'll chat later)
21:06:48 <refusenick> Is there a book which introduces Haskell by building DSLs like "Lisp In Small Pieces"?
21:09:05 <refusenick> How reusable are EDSLs in practice? If they define embedded interpreters, will the compiler make a new EDSL's interpreter as efficient as the ones it was built out of? What about combining different techniques for making EDSLs?
21:10:57 <Axman6> I don't think there's a direct answer to that question
21:11:10 <refusenick> Is "The Haskell School of Expression" still applicable?
21:12:03 <Axman6> EDSLs aren't "a thing", they describe something we do in programming all the time. There are lots of ways to implement many EDSLs, but many DSLs are just called "programs"
21:15:10 <refusenick> Axman6: Why are free monads called intepreters, then?
21:15:43 <Axman6> they aren't, interpreters for free monads are called interpreters
21:16:00 <monochrom> Is that what you actually saw, or is that your misquoting?  Because free monads aren't interpreters, instead we write interpreters for free monads.
21:16:05 <iqubic> I don't think they are. I've never heard free monads called that.
21:16:29 --- mode: monochrom set -o monochrom
21:16:40 <Axman6> free monads are interpreted by interpreters
21:16:53 <Axman6> (losely)
21:17:29 <glguy> as much as all algebraic data types are interpreted by interpreters, right?
21:17:35 <iqubic> Yes.
21:17:57 <iqubic> Hutton's Razor can be interperted with an interperter.
21:18:18 <refusenick> To consruct a new DSL sharing some properties of others arising from interpretation of a free monad, do you construct a new free monad from the ones which are interpreted as DSLs and interpret the resulting object?
21:18:37 <iqubic> With Hutton's Razor being: "data Term = Constant Integer | Add Term Term"
21:19:23 <dmj`> refusenick: there is "write yourself a scheme in 48 hours", still relevant
21:19:45 <refusenick> dmj`: Oh, I forgot about that one! I should follow that.
21:19:50 <iqubic> How hard is it to write a scheme?
21:19:56 <dmj`> russian lambdabot can find it for you
21:19:59 <glguy> It should only take about 48 hours
21:20:06 <dmj`> @google Learn yourself a scheme in 48 hours
21:20:08 <refusenick> iqubic: Not very. First interpreter I ever wrote was a Scheme interpreter in C++.
21:20:08 <lambdabot> http://www.google.com/url?q=https://en.wikibooks.org/wiki/Write_Yourself_a_Scheme_in_48_Hours
21:20:08 <lambdabot> Title: Ð£Ð²ÐµÐ´Ð¾Ð¼Ð»ÐµÐ½Ð¸Ðµ Ð¾ Ð¿ÐµÑ€ÐµÐ°Ð´Ñ€ÐµÑÐ°Ñ†Ð¸Ð¸
21:20:23 <iqubic> I haven't written any interperters.
21:20:31 <dmj`> sweet soviet lambdabot
21:21:38 <iqubic> Would scheme be a language you need to compile first?
21:22:10 <iqubic> I suppose if you want macro support you have to mix program compilation and program execution.
21:22:11 <refusenick> iqubic: No. Why would it be?
21:22:26 <iqubic> s/compilation/interpertation/
21:22:32 <refusenick> You don't need to add macros.
21:23:13 <iqubic> But I can if I want to.
21:23:20 <refusenick> If you write an interpreter, you can hardcode macro expansion anyways.
21:23:48 <refusenick> Lisp compilers are harder if you require macros: https://mpov.timmorgan.org/i-built-a-lisp-compiler/
21:25:24 * ski walks around with a lantern, in search for hygiene
21:26:02 * iqubic has no clue what hygenic macros are supposed to be
21:27:07 <ski> macros that respect lexical/static scoping (rather than employing dynamic scoping)
21:27:20 <refusenick> iqubic: Hygienic macros fake lexical scoping semantics. Macros, as compile-time constructs, traditionally don't have a notion of scope. They rewrite sexprs.
21:27:33 <iqubic> Ah. I see.
21:27:36 <refusenick> ninja'd
21:28:35 <ski> if `\case {...}' is expanded to `\x -> case x of {...}', you don't want any `x' in `...' to be captured by the local variable `x' introduced by the macro
21:29:23 * hackage egison-pattern-src 0.1.0.0 - Manipulating Egison patterns: abstract syntax, parser, and pretty-printer  https://hackage.haskell.org/package/egison-pattern-src-0.1.0.0 (coord_e)
21:29:35 <iqubic> isn't that dealt with by things like gensym and such?
21:29:49 <ski> furthermore, if `do x <- act; frob x' is expanded to `act >>= \x -> frob x', you (normally) don't want any local binding of `(>>=)' to shadow the reference to `(>>=)' introduced by the macro
21:30:09 <ski> `gensym' can't do the latter
21:30:24 * hackage egison-pattern-src-th-mode 0.1.0.0, egison-pattern-src-haskell-mode 0.1.0.0 (coord_e): https://qbin.io/let-aol-4srf
21:32:33 <ski> (a) you (normally) want identifiers passed inside phrases that are actual parameters of the macro, to refer to what was in scope at the macro invokation, not what was in scope in the macro definition, where the corresponding formal parameters are used
21:33:33 <ski> (b) you (normally) want identifiers used in the body of the macro, to refer to what was in scope at the macro definition, not what is in scope at the macro invokation site. (yes, even if said identifiers aren't exported from the module in which the macro was defined)
21:33:46 <ski> `gensym' can do (a), but not (b)
21:39:52 <ski> (just as there can be an argument to have dynamic scoping, as an opt-in (see "implicit parameters"), there can also be an argument to have "syntax parameters" for macros, using dynamic scoping. one could e.g. view `return',`break',`continue' (the latter two, used without labels) in this way)
21:43:10 * ski . o O ( "Dirty Looking Hygiene" by Eli Barzilay in 2008-02-23 at <https://blog.racket-lang.org/2008/02/dirty-looking-hygiene.html> )
22:01:24 * hackage rerebase 1.5 - Reexports from "base" with a bunch of other standard libraries  https://hackage.haskell.org/package/rerebase-1.5 (NikitaVolkov)
22:03:09 <refusenick> Obviously Haskell can't pull the same kinds of meta tricks as Lisp can with its pervasive code-data duality. To what extent can it manipulate its own structure?
22:03:36 <iqubic> There's Template Haskell, but I have no idea how well that works.
22:03:38 <refusenick> Can the compiler be imported as a library?
22:03:45 <refusenick> iqubic: templates, bleh
22:03:50 <refusenick> I've had enough of those in C++
22:04:35 <iqubic> I'm 90% sure Template Haskell is different from C++ templates.
22:04:43 <Axman6> template haskell is not templates, it is the language for meta-programming in Haskell
22:04:44 <mjrosenb> haskell templates are 0% like C++ templates.
22:05:20 <mniip> the compiler can be imported as a library but there are large but's there
22:05:37 <mniip> using GHC as a library to compile code at runtime is very untidy
22:05:48 <mniip> very unsafe APIs all over the plcae
22:06:01 <refusenick> mniip: Does it have to all be imported as one piece?
22:06:09 <mniip> yup
22:06:24 <refusenick> That shoots down what I was hoping for.
22:06:45 <mniip> what do you have in mind
22:07:31 <jol> Hello. I'm having trouble defining a Read instance. It compiles and the definition of readPrec runs as expected (returns my value), but readMaybe keeps evaluating to Nothing. Could someone help me understand what I'm missing? Here's a pastebin: http://dpaste.com/0D5MDAE.txt
22:07:47 <refusenick> mniip: Specifying the subset of code which I could possibly compile at runtime given how the rest of the program is already written.
22:09:06 <refusenick> Would there be less reliance on type-level programming if its Prologish style was more accessible at runtime?
22:09:28 <mniip> jol, `look` is a lookahead
22:09:31 <mniip> you're not consuming your input
22:10:03 <mniip> refusenick, I'm not entirely sure I understand
22:11:43 <refusenick> mniip: With types, you can specify how pieces of data relate to each other and establish truths. If your runtime only uses functions (no cheating by emulating nondeterministic search with the List monad), your final program maps a batch of inputs to a batch of outputs.
22:12:58 <jol> mniip: Thanks for the pointer. I think I've got it.
22:14:33 <refusenick> Pandoc is a fantastic project and plenty of proof to me that Haskell has something to offer over conventional languages. Its ability to map one format to another is beyond what I could imagine a C program doing, and I bet is has to do with clean representation of doc formats encoded in typs. What if, though, Haskell made it easier to access that representation at runtime as a Prolog-style fact database?
22:15:12 <Axman6> why no tjust use prolog?
22:15:29 <refusenick> Not that Haskell should try to be Mercury or Curry, but I do think there's a blind spot when the response is "you can emulate search with the List monad"
22:16:08 <refusenick> Axman6: Prolog is dead (I'm sorry to say, but it's true) and has a lot of baggage. MiniKanren, perhaps.
22:16:22 <mniip> "establish truths"
22:16:31 <mniip> it's a two sided coin
22:16:33 <Axman6> there are definitely other implementations of Search possible, and implemented, in Haskell
22:16:51 <mniip> types restrain you from doing invalid things
22:16:57 <refusenick> Axman6: Are any of them commonly used?
22:17:02 <mniip> and also assure you that things you're using will not in turn be doing invalid things
22:17:08 <Axman6> refusenick: you should talk to edwardk about MiniKanren and his current work
22:17:57 <mniip> "If your runtime only uses functions"
22:17:59 <mniip> I mean
22:18:06 <mniip> lambda calculus is the computation module that we employ
22:18:27 <mniip> doing that, indeed, computation per se happens by mapping inputs to outputs
22:20:48 <refusenick> mniip: I mean it very colloquially. I can see Haskell has abstractive power, but I'm talking about "do what's easy in another language/paradigm without building an interpreter for it". Technically C can do that as well because it's Turing complete, but in both languages, there's a common, "base language" which everyone uses because it's there.
22:21:26 <Axman6> refusenick: re: if they are used, I have no idea, it's not something I've ever needed or had an interst in. https://hackage.haskell.org/package/logict is an examle of one such implementation I believe
22:24:26 <refusenick> Axman6: I presume you write Haskell programs which aren't purely batch programs, which means they store state somewhere. Do you use an external database like PostgreSQL or an in-memory "database type" data structure?
22:25:41 <Axman6> generally some sort of database, yes, in the past PostgreSQL, currently a lot of DynamoDB
22:28:16 <refusenick> Axman6: There do exist APIs for Prolog to external DBs like those despite it having a fact database, just the same as BEAM languages can access external databases that aren't Erlang's Mnesia object store. If an in-memory database accessible via primitives like those were in Haskell, would you use it?
22:30:28 <Axman6> well, they do exist, and it would depend on the problem I were trying to solve.
22:31:49 <refusenick> Axman6: Do any exist that are easy enough to use that you'd pick them for a generic small project? Is there a point at which SQLite is better than them?
22:36:20 <refusenick> If I'm writing something in Lisp, my first thing to reach to is storing stuff in symbols (point it hashtable or anything else) and let the image handle persistence. Beyond that, something small and highly integrated like https://github.com/Wukix/LambdaLite would suffice. If it grew beyond that, I'd maybe go for an external heavyweight like PostgreSQL. At no point would I consider storing Lisp info in SQLite. The other options /within
22:36:20 <refusenick> the language/ are just so much easier. Can Haskell be like that?
22:36:31 <Axman6> There's acid-state, though it's a bit old at this point, it could do with a rewrite with some more modern ideas IMO
22:37:42 <refusenick> point it at a hashtable*
22:40:28 <opqdonut> refusenick: you can just call show on stuff and dump it to a file, and then read it back
22:40:40 <opqdonut> which is kinda lispy, and very easy
22:41:07 <opqdonut> I've used acid-state, it was nice, but I ended up doing json serialization into sqlite because I wanted more transparency and recoverability
22:41:52 <Axman6> yeah SQLite is lovely for persistence, since it can be read by anything
22:42:03 <Axman6> you can get a long way with both SQLite and JSON
22:42:19 <refusenick> opqdonut: I hope you see what's wrong with dumping to and reading from files.
22:42:50 <refusenick> There was a time when files were the de facto database for most programs. That's what Unix is, in a sense.
22:43:31 <opqdonut> sure it has downsides, but so has lisp image building
22:43:35 <heatsink> Is that different from what you would do in lisp?
22:43:35 <Axman6> refusenick: look, you're asking for specific answers to very general questions - if you have an actual usecase we can help you, but "how do you persist data" isn't really something we can give a good answer to, it depends on a lot of factors
22:44:06 <koz_> What the Man with the Axe Hands said.
22:44:11 <Axman6> "Which vehicle do I use?"
22:44:14 <koz_> He Who Ruins All Keyboards.
22:44:18 <opqdonut> even for work projects, I find myself using json-in-sql quite a lot. you get a nice blend of structure and structurelessness
22:44:30 <opqdonut> also, it's quite language-agnostic
22:44:31 <Axman6> The answer could be a moped, a 50t mining truck, or an A380
22:44:42 <koz_> Axman6: Or roller skates!
22:44:44 <opqdonut> (also, postgres has great json features these days))
22:44:54 <Axman6> Or roller skates indeed
22:44:54 <refusenick> Axman6: How do I do in Haskell what comes for free in a >60 year old language?
22:45:26 <Axman6> refusenick: it sounds like a feature I wouldn't use even if it were available
22:45:30 <koz_> refusenick: Uhh, you're actually writing in McCarthy's original LISP?
22:45:38 <refusenick> heatsink: Lisp predates file systems. Traditionally, Lisp state would be persistently serialized to disk as in-memory lists.
22:45:46 <koz_> Because at the very least, the thing you linked is for Common Lisp, which first got _defined_ in 1994.
22:46:02 <refusenick> Of course, modern Lisp goes far beyond that, but the basic idea remains.
22:46:49 <refusenick> It doesn't matter how typesafe Haskell is if it's so self-restrictive that it has to shell out (pun intended) to the Unix wilderness of unstructured plain text. 
22:47:19 <refusenick> Lisp isn't the future either, for a number of reasons, but everything which potentially is has some notion of persisting structured data.
22:47:34 <Axman6> obviously it doesn't have to do that, I have literally never done that in the 10+ years I've been programming in it
22:47:44 <refusenick> You could write an OS in Erlang by persisting actors. What would that look like in Haskell?
22:48:02 <refusenick> A typesafe file system is still a file system.
22:48:12 <koz_> To echo what Axman6 says: it depends on your goals. We don't have one hammer we hit every problem with.
22:48:28 <Axman6> nor should we
22:48:37 <refusenick> I'm not saying you should.
22:48:39 <koz_> And no, 'emulate feature X in a language exactly' does not a goal make.
22:48:44 <jle`> i'm saying you should
22:48:59 <koz_> Nor 'do things exactly like language X for problem Y'.
22:49:12 <koz_> Because that's a) a moving target and b) ultimately setting Haskell up to lose, unless X ~ Haskell. :P
22:49:24 <koz_> jle`: Haiiiiii!
22:49:36 <jle`> hullo beautiful haskell people
22:49:46 <koz_> jle`: We are beautiful, as are you.
22:49:56 <koz_> Join us in monadic reverie.
22:50:25 * jle` plays the monadic fiddle
22:50:36 <dminuoso> koz_: That sounds like it could be a piece from Debussy.
22:50:40 <refusenick> Prolog fact databases, Lisp images, Smalltalk images, APL workspaces, and Erlang actor persistence are nothing alike, but the general idea of "built-in language datastructure as database as OS" is the same.
22:50:40 <Axman6> This all puts me in a bind
22:50:48 <koz_> dminuoso: The Monadic Reverie in C. :P
22:50:52 <heatsink> refusenick: Lisp has to stay in its own closed world to accomplish that.  If your lisp program calls a C library and receives pointers, you'll run into the same problems
22:51:10 <koz_> Axman6: Lift yourself up!
22:51:12 <dminuoso> koz_: I think a Microsoft composed transposed it into F#
22:51:21 <koz_> dminuoso: Not C#?
22:52:19 <dminuoso> koz_: That was for some Monoid Concerco,not Monadic Reverie.
22:52:32 <dminuoso> *Concerto, boy my spelling is not good that early in the morning.
22:52:36 <koz_> dminuoso: Damn, I always get those two confused.
22:52:44 <refusenick> heatsink: Good thing C is dying, then. Eventually, the DOM and wasm will be integrated into OS kernels and be used to rewrite everything else because ideas like Lisp and Prolog were forgotten and Haskell didn't step up to the plate.
22:52:49 <Axman6> refusenick: part of that comes from the relatively poor type system, we prefer precise types to a small number of general ones. This necessarily makes a generic storage mecahnism much more difficult. We have to contend with things like what to do if we want to store functions? IIRC being able to do so has very big implications for purity, because being able to do so allows one to break referential transparancy
22:52:55 <jle`> F# is technically harmonically closer to C than C#
22:53:05 <iqubic> Sure.
22:53:16 <koz_> jle`: Is it to do with the interval between them or something?
22:53:32 <jle`> hm. actually i think i'm wrong
22:53:38 <jle`> well C# has seven sharps
22:53:44 <jle`> and F# only has six
22:54:00 <koz_> Lol, I'll take your word for it, since I forgot any music theory I think I ever learned.
22:54:05 <Axman6> I GUESS F# ISN'T THE SHARPEST TOOL IN THE SHED
22:54:08 <Axman6> sorry
22:54:10 <dminuoso> We should rename Haskell to Fâ™­.
22:54:15 <jle`> but F# is farther away on the circle of fifths from C so i guess you would consider that the most harmonically distant
22:54:33 <jle`> Axman6: A++ joke
22:54:36 <koz_> dminuoso: Is assembly then C-flat? :
22:54:39 <koz_> :P
22:54:43 <koz_> (which is B)
22:54:45 <Axman6> Thanks man, that means a lot
22:55:01 <dminuoso> koz_: This is so confusing. In German music notation you spell and pronounce it H. 
22:55:04 <monochrom> A# joke.
22:55:22 <dminuoso> koz_: Gets me every time. And if you think about it, it makes more sene.. the piano starts with A, B, C, D, E, F, G.. and then B?!
22:55:29 <jle`> Að„ª
22:55:30 <dminuoso> Err gah
22:55:45 <refusenick> Axman6: Doesn't that then wrap back to my original question about allowing more of the runtime data representation typical of logic program which is done at compile time in Haskell via the type system?
22:55:48 <dminuoso> I give up on the jokes. :(
22:55:56 <koz_> It was fun while it lasted.
22:56:01 <refusenick> of logic programming*
22:56:11 <koz_> Also, you folks should really hear jle` play keys and sing.
22:56:17 <koz_> (just as a complete unrelated aside)
22:56:30 <monochrom> keys? scales?
22:56:44 <jle`> nothing but 256bit secure keys for me
22:57:00 <monochrom> Or do you mean he uses door keys and locker keys etc for music instrument...
22:57:22 <koz_> monochrom: You'd have to ask him, I haven't heard him play keys-as-in-opening-devices, only keys-as-in-keyboard.
22:57:22 <Axman6> Ed25519forLyf
22:57:26 <dminuoso> You can use Haskell to make shit scale: https://icdn4.digitaltrends.com/image/digitaltrends/tailio-416x416.jpg
22:57:31 <jle`> i take commissions from people to sing their PGP pubkeys
22:57:35 <jle`> and turn it into a song
22:57:40 <koz_> jle`: Lol.
22:57:43 <jle`> i sing it then i sign it
22:58:12 <Axman6> refusenick: that certainly sounds like it would also break referential transparency to me
22:58:28 <jle`> dminuoso: does it do sharding too
23:00:01 <dminuoso> jle`: I fail to make a funny connection to geology here.
23:00:24 <koz_> #haskell - all about the compositional humour?
23:00:24 <dminuoso> Oh oh. Should have said "It rocks for sharding"
23:00:37 <jle`> nice
23:01:20 <refusenick> Axman6: Then it sounds like Haskell is evolutionarily unfit and will not pass its traits on to future languages. I don't want to believe that, and I don't think you want to either.
23:01:28 <monochrom> GHC is written in I# major.
23:01:33 <koz_> refusenick: That's an awfully sweeping claim.
23:01:35 <jle`> aw man i did a misquote
23:01:49 <dminuoso> refusenick: I really dont follow your line of reasoning.
23:01:51 <jle`>  > does it support sharding?
23:03:21 <monochrom> Haskell doesn't want to be anthropomorphized to a sexual object.
23:03:32 <refusenick> koz_: He's saying Haskell is unable to replace Unix. Everyone's trying to eat Unix's lunch right now. Now that the end of Moore's Law has made research in niche topics like hardware automata and neuromorphic computing acceptable, will we even have von Neumann computers in the future?
23:03:59 <iqubic> monochrom: I don't think I've heard of that musical tone.
23:03:59 <koz_> refusenick: Who's the 'he' in this sentence referring to?
23:04:09 <refusenick> Will a pure Haskell OS run on them?
23:04:14 <refusenick> koz_: Axman6 
23:04:39 <koz_> Uhh, I believe you are alone in drawing this conclusion. I am also interested in the line of reasoning you followed to reach it.
23:05:12 <iqubic> I don't think that the pure Haskell OS will work soon.
23:05:24 <koz_> For reasons entirely independent of Haskell.
23:05:25 <monochrom> Aww why are you people so interested in delusion or trolling?
23:06:21 <refusenick> monochrom: Most agree that thinking of people that way is reductive because humans are intelligent and independent. Crowd behavior - like language popularity - is more like a dumb animal.
23:06:45 <iqubic> I mean, GuixSD exists, but that's guile scheme.
23:06:52 <monochrom> If I go sniff up cocaine and start rambling on the philosophical isomorphism between the Holy Trinity and Javascript, will you be interested too?  I mean at least it's both prior art and funny.
23:07:20 <koz_> monochrom: You on coke is something I find amusing af.
23:07:26 <koz_> Or rather, the _thought_ of you on coke.
23:07:31 <koz_> I haven't experienced you on coke.
23:07:46 <refusenick> monochrom: Do you really think the von Neumann architecture will be around for much longer? I already see jokes about GPU standing for "General Processing Unit".
23:07:59 <monochrom> Because if I take coke I stick to Coke Zero...
23:08:09 <iqubic> monochrom: I would be amused by the thought of Haskell programers on drugs.
23:08:15 <koz_> monochrom: Not even Vanilla Coke?
23:08:26 <koz_> iqubic: GHC would probably save us from the worst of it.
23:08:35 <jle`> there will be a place for vNA in the world for a long, long time
23:08:44 <dminuoso> koz_: Sniffing vanilla coke is probably not the smartest thing to do though.
23:08:50 <monochrom> Haven't tried, but I want to avoid sugar in drinks.  (Gladly take solid-state desserts though.)
23:08:57 <koz_> I also find the implication that GPUs are somehow not von Neumann _hilarious_.
23:09:11 <koz_> monochrom: Yeah, the lack of a Vanilla Coke Zero is a bit sadface.
23:09:40 <iqubic> koz_: I'd love to see videos of someone high on drugs trying to argue with GHC.
23:09:52 <koz_> iqubic: It only takes a webcam and a supplier. :P
23:09:52 <dminuoso> Can't you just mix vanilla coke and coke zero to have vanilla coke zero?
23:09:52 <dminuoso> surely that counts.
23:10:16 <iqubic> "Woah dude, the compiler's so smart. It knows when my code is wrong and stuff"
23:10:18 <koz_> dminuoso: Well, wouldn't it be more of a Vanilla Coke [ratio], where [ratio] is the ratio in which you mixed them?
23:10:31 <koz_> So like, even mix wold be Vanilla Coke Half.
23:10:38 <dasli`> Why is "forall" used for existential types? I'm starting to think that it really is just the existential quantifier with exactly the wrong name.
23:10:54 <dasli`> And if this is the case can somebody please tell me why?
23:10:54 <dminuoso> dsal: Because the authors did not want to reserve another keyword.
23:11:00 <dminuoso> dasli`: ^-
23:11:04 <dasli`> NO
23:11:08 <dasli`> you're kidding
23:11:10 <koz_> I think there's some logic-related reason too.
23:11:22 <dasli`> well that's what I want to know
23:11:23 <koz_> But I forget and don't think I could properly explain it anyway.
23:11:24 <monochrom> Both are right.
23:11:31 <dminuoso> koz_: No, that's unrelated.
23:11:42 <jle`> logically
23:11:52 <dminuoso> koz_: Encoding existentials as continuations over forall quantified things is one thing, but I believe they are talking about `data Foo = forall t. Foo ...`
23:11:59 <monochrom> An existential constructor, when used as a function, has type (forall a. ...) -> MyType.
23:12:05 <dminuoso> And that really should read `exists`. :(
23:12:10 <dasli`> :( :( :(
23:12:21 <jle`> new keyword bad
23:12:44 <dasli`> I get that but diametrically-exactly-wrong keyword also bad
23:12:59 <dasli`> Today is my day for disturbing revelations.
23:13:04 <jle`> but which is the bad bad
23:13:26 <heatsink> I prefer GADT syntax for existentials
23:13:30 <dasli`> gonna try and stay zen here
23:13:40 <dminuoso> dasli`: Arguably, it should have read `data Foo = Foo (exists a. Show a *> a)
23:13:44 <monochrom> For example "data MyType = forall a. Ctor (a, a->Int)".  Then Ctor :: forall a. (a, a->Int) -> MyType.  (Also I messed up parenthesizing before.)
23:13:46 <iqubic> heatsink: What's the GADT syntax?
23:14:03 <jle`> yeah, i try to avoid existentials with normal adt syntax
23:14:07 <heatsink> data Ex where Ex :: forall a. a -> Ex
23:14:08 <dminuoso> iqubic: data Foo where Foo :: forall a. Show a => a -> Foo
23:14:15 <jle`> you don't even need the forall there
23:14:21 <jle`> data Foo where Foo :: a -> Foo
23:14:21 <dminuoso> But I like the forall.
23:14:32 <monochrom> Also I shouldn't need a tuple, I just need 2 fields!
23:14:32 <dminuoso> It should be explicit and required. Everywhere. :(
23:14:52 <monochrom> This is the closest you will ever get to monochrom-on-coke.
23:15:06 <dminuoso> Mmm, is `data Foo where Foo :: forall a. Foo` a thing?
23:15:25 <jle`> % data Foo where Foo :: forall a. Foo
23:15:25 <yahb> jle`: 
23:15:29 <jle`> i guess so
23:15:31 <dminuoso> Ah I suppose that's just the same as `data Foo where Foo :: forall a. Proxy a -> Foo a`
23:15:41 <iqubic> That forall is implicit. Adding a forall there is like adding a forall to "class Show a where forall a. Show a -> String"
23:15:43 <iqubic> I think.
23:15:55 <dminuoso> And you actually *need* the proxy if you ever want to recover the existential presumably
23:16:10 <iqubic> s/is implicit/can be implicit/
23:16:17 <jle`> dminuoso: i think so, but i have no idea how to access the 'a' in the non-proxy version. at least not until we get -XTypeApplications syntax in patterns maybe
23:16:28 <dminuoso> Right
23:16:38 <jle`> is there a way?
23:16:40 <jle`> hmm
23:16:58 <jle`> i suspect not
23:17:04 <dminuoso> jle`: I think perhaps if there's a constraint together with the constraints library.
23:17:07 <jle`> but i feel like there might be a trick
23:17:41 <dminuoso> Or constraints-extras even, I'll have to ponder about this
23:17:55 <jle`> so for something like
23:18:19 <jle`> % data Blah where Blah :: KnownNat a => Blah
23:18:20 <yahb> jle`: ; <interactive>:73:25: error: Not in scope: type constructor or class `KnownNat'
23:18:29 <jle`> % import GHC.TypeNats
23:18:29 <yahb> jle`: 
23:18:31 <jle`> % data Blah where Blah :: KnownNat a => Blah
23:18:32 <yahb> jle`: ; <interactive>:75:17: error:; * Could not deduce (KnownNat a0); from the context: KnownNat a; bound by the type of the constructor `Blah':; forall (a :: Nat). KnownNat a => Blah; at <interactive>:75:17-42; The type variable `a0' is ambiguous; * In the ambiguity check for `Blah'; To defer the ambiguity check to use sites, enable AllowAmbiguousTyp
23:18:48 <jle`> huh it's funny that that one required allowambiguoustypes but the first one didn't
23:18:54 <jle`> % :set -XAllowAmbiguousTypes
23:18:54 <yahb> jle`: 
23:18:59 <jle`> % data Blah where Blah :: KnownNat a => Blah
23:18:59 <yahb> jle`: 
23:19:13 <jle`> so we can do things like `Blah @3` but then the 3 disappears
23:19:28 <jle`> % Blah @3
23:19:28 <yahb> jle`: Blah
23:19:35 <dminuoso> Does it? If you pattern match you should have the dictionary in scope
23:19:36 <iqubic> The 3 is a phantom type, right?
23:19:37 <jle`> even if you match on the constructor there isn't a way to get the 3 back
23:19:53 <jle`> dminuoso: yes but how do you access the dictionary?
23:20:06 <iqubic> So it's a phantom type?
23:20:07 <jle`> i wouldn't call it a phantom type here because it's not a type parameter of Blah
23:20:11 <iqubic> Right.
23:20:23 <jle`> it's an existential type
23:20:29 <koz_> It's an even-more-phantom type.
23:20:45 <jle`> % let hidden3 = Blah @3
23:20:46 <yahb> jle`: 
23:21:02 <iqubic> Isn't that isomorphic to ()
23:21:09 <jle`> millenium problem #8: get back that 3
23:21:16 <monochrom> :)
23:21:25 <jle`> iqubic: well that's sort of what we are trying to solve here
23:21:36 <jle`> if we can get back the @3, then it's isomorphic to Natural
23:21:43 <jle`> if we can't then it's (), yeah
23:21:50 <iqubic> Is the 3 lost or not?
23:21:56 <jle`> that's what we're trying to figure out
23:22:21 <jle`> you should be able to get it back if that type-applications-in-patterns extension is in GHC
23:22:27 <jle`> but i wonder if it's possible today
23:23:15 <jle`> https://github.com/ghc-proposals/ghc-proposals/pull/126
23:23:24 <jle`> oh hey the proposal was accepted ...
23:23:37 <monochrom> makes sense
23:23:41 <dasli`> thanks everybody for the confirmation about "forall", btw
23:24:12 <jle`> idk it's kind of weird for me
23:24:17 <jle`> since @ is already used in pattern syntax
23:24:33 <jle`> the reason why it made sense to use @ for -XTypeAPplications is because @ isn't a part of expression syntax
23:24:48 <jle`> oh well
23:25:07 <monochrom> Oh, I mean the need for recovering types in patters makes sense, I didn't check the syntax.
23:25:26 <jle`> the syntax would have been case hidden3 of Blah @n -> natVal (Proxy @n)
23:25:46 <iqubic> So, turns out that Blah is an ambiguos type.
23:25:48 <monochrom> Or maybe more accurately s/recovering types/type bindings/
23:26:28 <monochrom> Yeah reusing @ is going to cause a mess in parsing.
23:26:33 <iqubic> In order to get: "data Blah where Blah :: KnownNat a => Blah" to compile, I needed "{-# LANGUAGE AllowAmbiguousTypes #-}"
23:26:45 <jle`> yes, we did that earlier in chat :)
23:26:51 <koz_> iqubic: Yeah, because how is GHC meant to know what a is otherwise?
23:26:54 <koz_> You gotta tell it.
23:27:13 <koz_> {-# LANGUAGE Telepathy #-} doesn't exist yet.
23:27:41 <dminuoso> % import Data.Constraint
23:27:42 <yahb> dminuoso: 
23:27:50 <nshepperd> % data Blooh where Blooh :: Integer -> Blooh
23:27:50 <yahb> nshepperd: 
23:28:00 <nshepperd> % case unsafeCoerce (Blah @3) of Blooh n -> n
23:28:01 <yahb> nshepperd: 3
23:28:06 <jle`> nice
23:28:11 <dminuoso> % instance HasDict KnownNat Blah where evidence Blah = Dict
23:28:12 <yahb> dminuoso: ; <interactive>:86:10: error: Not in scope: type constructor or class `HasDict'
23:28:17 <dminuoso> huh
23:28:51 <nshepperd> :3
23:29:05 <dminuoso> Oh perhaps thats still an old constraints version yahb has
23:29:22 <jle`> % let unBlah x = case unsafeCoerce x of Blooh n -> n
23:29:22 <yahb> jle`: 
23:29:27 <jle`> % unBlah hidden3
23:29:27 <yahb> jle`: 3
23:29:39 <jle`> time to pack it up
23:29:47 <koz_> Wait, why does this work?
23:29:52 <refusenick> monochrom: What makes you think I'm delusional? I'm saying the same thing as Alan Kay, just with less tact.
23:30:01 <refusenick> For the record, I think Haskell is really cool
23:30:07 <refusenick> Take a look at this: https://www.youtube.com/watch?v=SVRYcrhRCes
23:30:13 <jle`> it's a sort of 'newtype' optimization haskell does for single-method typeclasses
23:30:31 <refusenick> When I saw that, I thought "wow, Haskell could be the future of programming"
23:30:46 <monochrom> 1. Indistinguishable from a Markov chain.  2. Alan Kay is delusional too.
23:30:46 <jle`> a single method typeclass's runtime dictionary is literally just the single method, in this case natVal
23:30:49 <cjay-> Is there a way to export record field names without exporting the accessor functions?
23:31:00 <dminuoso> cjay-: No.
23:31:20 <iqubic> And just to prove that we can retrieve things, I present this: http://dpaste.com/08C3CYY
23:31:22 <jle`> or in this case, the single Natural/Integer that is in the KnownNat typeclass
23:31:29 <cjay-> thx
23:31:52 <iqubic> The last few lines of my paste are just queries I sent to GHCi and the returned results.
23:32:10 <dminuoso> nshepperd: Some mighty black magic there.
23:32:12 <dminuoso> How stable is this optimization?
23:32:19 <koz_> Ah, I think I see.
23:32:27 <nshepperd> koz_: actually two things. 1. knowing that => is secretly just ->; 2. knowing that KnownNat n is secretly just Integer, due to the single method typeclass optimization jle` explained
23:32:42 <iqubic> dminuoso: Are you asking how stable the unsafeCoerce is?
23:32:42 <koz_> Ah, yeah, that makes sense.
23:32:53 <jle`> afaik it's relatively reliable in GHC, since it's what the 'reflections' library is built on
23:32:55 <koz_> That unsafeCoerce is just 'forcing' it into the right 'shape' for us to interrogate.
23:33:02 <iqubic> Yes.
23:33:34 <iqubic> jle`: You said this would be Millenium Problem #8. nshepperd solved it. Is there a reword for them?
23:33:44 <jle`> but it basically exploits a quirk in how ghc does typeclass dicts for single method typeclass
23:33:56 <jle`> needs to solve #8b: do it without unsafeCoerce
23:33:58 <nshepperd> unsafeCoercing to 'data Bleh n where Bleh :: KnownNat n => Bleh n' would be a slightly less accursed method of recovering the 3 :p
23:34:38 <iqubic> jle`: I don't think it's possible without unsafeCoerce.
23:34:47 <jle`> then i'm keeping my money
23:34:49 <jle`> hehe
23:35:04 <iqubic> touche.
23:35:05 <monochrom> May I use a top-level polymorphic IORef? :)
23:35:16 <jle`> D:
23:35:35 <monochrom> Hey it's just the other trick in the book.
23:35:45 <nshepperd> hehe
23:35:50 <iqubic> monochrom: How would that actually help here?
23:35:51 <jle`> using unsafePerformIO to implement unsafeCoerce
23:36:22 <iqubic> Oh. Oh dear. So we're exchanging one magic black box for anothr.
23:37:23 <refusenick> monochrom: Okay, where's Haskell's Smalltalk environment? You can't say he's delusional when he has a working OS image and you don't. Isn't the point to replace unsafe code with safe code? If Haskell says it only wants to be a research language and a stepping stone to something which isn't, why is there so much talk of Haskell In Industry(tm)?
23:37:54 <iqubic> Can't you use a top-level IORef and unsafePerformIO to fake mutible variables/
23:37:55 <iqubic> ??
23:38:04 <refusenick> Do you want to eat your cake or have it?
23:38:28 <jle`> iqubic: why would it be fake
23:38:39 <dminuoso> iqubic: I've learned my share of "unsafe" means unsafe. My latest revelation is that unsafePerformIO can cause let-floating things in and outwards. Together with CSE, it can have some pretty funny results. :)
23:38:41 <monochrom> At this rate, Haskell will soon be my postdoc supervisor.
23:38:41 <nshepperd> dminuoso: pretty stable, I think. `reflection` package relies on it being implemented this way iirc
23:38:56 <koz_> dminuoso: CSE?
23:39:05 <jle`> yeah, and i use reflection for a lot of stuff
23:39:06 <dminuoso> koz_: common subexpression elimiation.
23:39:09 <jle`> so i hope it works D:
23:39:16 <iqubic> refusenick: Well, seeing as this is haskell, we don't actually have a cake. We have a recipe for a cake, and the GHC runtime creates the cake for us when we excute the program.
23:39:28 <koz_> *ba-doom-psh*
23:39:46 <nshepperd> having and eating your cake is easy. just bake two cakes
23:39:52 <dminuoso> koz_: The example basically had some `pure Foo { ..., someRef = unsafePerformIO (newIORef Nothing) }` inside some traversal. What GHC did, was float that thing out to the top level and alias all those buffers..
23:39:59 <iqubic> For those wondering, the Cake is secretly metaphor for IO.
23:40:00 <jle`> you can have your cake and then eat it, in that order
23:40:01 <dminuoso> It was *not* what I expected.
23:40:10 <koz_> dminuoso: Yeah, I can imagine not.
23:40:30 <monochrom> Actually I still don't understand "have xor eat your cake".  Doesn't eating subsumes having?
23:40:35 <iqubic> The cake analogy was something I found on reddit.
23:40:50 <dminuoso> monochrom: The word "have" is meant in the sense of possess.
23:40:52 <monochrom> Namely, "I'll have steak and tea" = I'll eat steak and drink tea.
23:41:05 <dminuoso> monochrom: The phrase is older
23:41:17 <jle`> it predates all known language
23:41:58 <monochrom> But if I eat a cake I don't possess, doesn't it count as stealing?
23:42:18 <dminuoso> monochrom: Sure, which is why in some cultures the phrase is "Eat a cake and steal it too"
23:42:20 <koz_> monochrom, the cake-haunting spirit.
23:42:22 <monochrom> Like, how about I come over and eat a cake that you possess...
23:42:31 <jle`> at this point i consider it more as an idiom than an actual aphorism
23:42:34 <dminuoso> Though, eating someone elses food is theft of food.
23:42:40 <jle`> like raining cats and dogs
23:42:56 <jle`> more "raining cats and dogs" and less "teach a man to fish"
23:43:48 <jle`> just a silly thing to say with a socially agreed-upon detached meaning
23:43:54 <iqubic> When did this change from a Haskell discussion to an etomology and grammar discussion?
23:44:06 <iqubic> Was it around the time I mentioned cake?
23:44:12 <jle`> we haven't talked about haskell here in years
23:44:20 <iqubic> Oh?
23:44:23 <refusenick> iqubic: I mentioned it. They don't want to answer my question.
23:45:12 <iqubic> If you want to talk about weirdness, I'm eating fish and chips.
23:45:23 <jle`> we all built irc bots out of haskell and tested them out in #haskell. one by one more bots came and people started leaving. now in 2020, 98% of channel activity is bots talking to each other
23:45:25 <iqubic> Except that it's more like fish and fries.
23:45:38 <koz_> jle` confirmed for bot.
23:45:48 <monochrom> I am a bot.
23:45:55 <refusenick> I wasn't considering a question like this earlier, but the downwards spiral of negative responses has led me to it: what is even the point of Haskell?
23:46:01 <jle`> 05*04*07* 08E03x09c10e11p02t12i06o13n05: 04P07r08e03l09u10d11e02.12u06n13d05e04f07i08n03e09d
23:46:03 <monochrom> Trying entering "@botsnakc"
23:46:09 <monochrom> err, "@botsnack"
23:46:17 <koz_> @botsnack
23:46:17 <lambdabot> :)
23:46:20 <monochrom> :)
23:46:24 <jle`> :]
23:46:29 <koz_> :D
23:46:31 <iqubic> monochrom has failed the turing test. Bots don't make typos.
23:47:24 <nshepperd> {â€¢Ìƒ_â€¢Ìƒ}
23:47:37 <mjrosenb> refusenick: it is a programming language in which you can write programs.
23:48:05 <refusenick> You can say "it's for the joy of it" like pure math, but they're allowed to run around and think about abstract proofs as they please because, as a side effect, it often sheds light on related fields and begins a process of applying an idea further and further.
23:48:26 <refusenick> Clearly, Haskell has no such side effects.
23:48:30 <jle`> i mostly use haskell for non-mathy things, just to write programs and applications and stuff like that
23:48:53 <glguy> I mostly use it to chat on irc
23:48:59 <iqubic> refusenick: If you don't want to use Haskell, no one's forcing you to use haskell.
23:49:16 <iqubic> glguy: Yes, yes, we all know you made a haskell IRC client.
23:49:16 <refusenick> iqubic: You're missing the point of what I'm saying.
23:49:44 <iqubic> refusenick: I think you should make you point clearer.
23:49:44 <refusenick> It looks really cool, and if someone asked me "what's Haskell for?", I imagine that I could give a response.
23:49:52 <mjrosenb> I'm writing a game in haskell at the moment.
23:50:09 <koz_> I have a job writing Haskell. 
23:50:16 <jol> I'm writing an email client in haskell at the moment.
23:50:19 <yushyin> haskell is just the most fun language of my choice to write programs in it.
23:50:20 <refusenick> It worries me that you guys are unwilling to give a straightforward general justification. Am I in the wrong for thinking that Haskell is worth learning?
23:50:24 <koz_> (which involves writing a compiler or two)
23:50:52 <nshepperd> it's a programming language, it's for writing programs
23:50:55 <koz_> refusenick: What do you mean by 'straightforward general justification'? Haskell can be used for many things, and has many advantages.
23:51:15 <koz_> As with nearly all your previous inquiries, we're _really_ not clear what exactly it is you want from us.
23:51:18 <mjrosenb> refusenick: and each person has a different reason for choosing haskell.
23:51:19 <jle`> people ask me why i use haskell for everything all the time
23:51:28 <yushyin> jol: can you write a need notmuch frontend for me in haskell? That would be nice!
23:51:37 <jle`> my usual answer is that it's the main programming language for things where maintainability and correctness are important
23:51:39 <refusenick> koz_: Yeah, but is it the future? APL has a lot of cool ideas too, but how will I build on it afterwards?
23:51:41 <jle`> long-term maintainability
23:51:41 <jol> I'm in it for the type security. Really though, only non-popular languages seem to need justification. Nobody would bat an eye if I said I was writing it in Python.
23:52:03 <jle`> i don't really use haskell for its mathy possibilities for the most part
23:52:04 <koz_> refusenick: Do you want a solution now, or a theoretical possibility of a solution in a decade?
23:52:15 <jle`> i mostly use haskell because of its advantages for maintainability
23:52:20 <koz_> Talking about 'the future' is pointless because we have no idea what's coming.
23:52:21 <iqubic> koz_: Haskell can give you both.
23:52:41 <refusenick> In fact, by that logic, I should be pouring time into APL because its execution model perfectly matches that of a GPU (which is why it's inspiration behind world-sweeping programs such as Numpy)
23:52:45 <jle`> if there was a language that was the future of programming but bad for maintainability i probably would not use it
23:52:48 <koz_> If you're asking 'is Haskell a silver bullet for undefined future issues that I can't articulate clearly', the response is 'I have no idea'.
23:53:08 <iqubic> jle`: Same here.
23:53:11 <jle`> the only reason i keep with haskell is the maintainability and correctness benefits, and not necessarily that it is the new paradigm of the future
23:53:23 <jle`> these are benefits i reap daily and that make my peers jealous
23:53:26 <koz_> I agree with jle`. Plus, it makes programming fun.
23:53:26 <jle`> (i like to imagine)
23:53:34 <koz_> I would _loathe_ to have to do anything I do in Haskell in anything else.
23:53:46 <koz_> Since it would be tedious, frustrating and probably about fifteen times harder.
23:53:51 <refusenick> koz_: Of course I'm not asking that. It's a pretty simple question at its core: can Haskell represent itself in itself and compile to new architectures?
23:53:53 <nshepperd> the future is an illusion, and choosing software based on whether you think it might be 'the future' is folly
23:53:56 <jle`> but it's somewhat of a secret weapon for me in a field where people don't know enough to care about maintainability
23:53:56 <koz_> I _certainly_ couldn't do my job in anything else nearly to the level I do now.
23:54:12 <nshepperd> in 20 years the world might be nanobot soup
23:54:25 <koz_> refusenick: Homoiconicity is not that cool an idea.
23:54:32 <nshepperd> seize the day!
23:54:41 <iqubic> The main reason I'm drawn to haskell is because the type system eliminates many classes of bugs that would be a pain to debug in other languages.
23:54:43 <monochrom> In 2000 I learned Haskell for how it's cute to me and fit my personal preference.  I thought it had no future though.  I thought OCaml actually would have a future.  That Frog guy who liked OCaml and kept attacking Haskell thought so, too.
23:54:53 <koz_> So I'm gonna skip the 'represent itself in itself' which is clearly not being asked in good faith.
23:55:02 <monochrom> 20 years later, where am I? Where is that Frog guy?
23:55:08 <jle`> refusenick: anyway i feel like haskell is worth learning for me because of its advantages in maintainability and correctness, so that's my straightforward answer
23:55:19 <koz_> As for 'compile to new architectures'... well, you can port GHC?
23:55:28 <refusenick> koz_: It's not quite homoiconity that I'm talking about.
23:55:36 <koz_> Like, are you talking about actual, _real_ architectures, or is this some kind of hypothetical Dyson sphere scenario?
23:55:46 <koz_> refusenick: Then please tell us all _exactly_ what you _are_.
23:55:48 <refusenick> The core of it is that I'm pretty sure vN is going away
23:55:58 <koz_> Since I can't read 'represent itself in itself' in many _other_ ways.
23:56:16 <koz_> refusenick: What do you define as 'von Neumann', and what gives you this idea?
23:56:21 <refusenick> There's already an abstract model for compiling lambda calculus to quantum computers, for example.
23:56:27 <koz_> Because I think pretty much _zero_ people who aren't marketers share it.
23:56:46 <refusenick> Obviously, anything like that being used realistically is years off.
23:56:59 <iqubic> I remember a time just last month when I was helping my father with some of his work for university. I was writing a python script using numpy for him. Coded the main logic in 5 minutes. Spent 50 minutes tracking down a runtime error. Turns out I had a functin call with two parameters in the wrong order.
23:57:10 <iqubic> I don't think I'd have that sort of trouble in Haskell.
23:57:12 <koz_> iqubic: Sounds about right. :P
23:57:13 <mjrosenb> quantum and van neumann architectures are not mutually exclusive.
23:57:39 <monochrom> Current model of quantum computing is just a quantum von Neumann model.  Change my mind.  (Haha von Neumann would be proud.)
23:58:17 <monochrom> (He loved physics and quantum, too.)
23:58:30 <jle`> he loved a lot of things, apparently
23:58:31 <nshepperd> a series of tiny John von Neumanns embedded in a supercooled silicon crystal
23:58:35 <koz_> (he also probably contributed major things to both, because he's hardcore)
23:58:36 <refusenick> monochrom: When he died, he was already working on a replacement architecture, an analog one.
23:58:40 <koz_> s/he's/he was/
23:58:50 <jle`> von Neumann is probably the last Gauss-like we'll have
23:59:55 <jle`> until i came along
23:59:58 <nshepperd> refusenick: it's useless to speculate about these things. we'll find out what the right programming language for new architectures is when we've tried them for >20 years
