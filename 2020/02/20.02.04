00:07:54 * hackage neat-interpolation 0.5.1 - A quasiquoter for neat and simple multiline text interpolation  https://hackage.haskell.org/package/neat-interpolation-0.5.1 (NikitaVolkov)
00:08:20 <a1tern> Hi
00:08:25 <dminuoso> Hello.
00:08:42 <a1tern> I have a question about types are not getting resolved when using DefaultSignatures: https://stackoverflow.com/questions/60048587/types-are-not-getting-resolved-when-using-defaultsignatures
00:09:39 <dminuoso> a1tern: You did not declare an instance for that.
00:10:11 <a1tern> dminuoso: I know, that's the whole point - having default instance
00:10:13 <dminuoso> a1tern: The existence of a default method is not sufficient. You must explicitly write `instance LoadFromFile [Requirement]` (with FlexibleInstances enabled)
00:10:33 <dminuoso> Oh.
00:10:38 <dminuoso> TIL, that is a thing?
00:10:52 <dminuoso> a1tern: Try enabling FlexibleInstances
00:10:59 <dminuoso> a1tern: Or newtyping [Requirement]
00:12:14 <dminuoso> a1tern: Judging from the manual you have to explicitly derive it though.
00:12:42 <dminuoso> Ah no
00:13:14 <dminuoso> a1tern: DefaultSignatures is not for default instances, its for providing a default implementation. You still have to explicitly declare the instance
00:15:16 <a1tern> dminuoso: could you give some example? should it be empty instance or..?
00:15:34 <dminuoso> a1tern: Right.
00:15:49 <dminuoso> a1tern: You'd just write `instance LoadFromFile [Requirement]` (again with FlexibleInstances enabled)
00:16:10 <dminuoso> a1tern: Default signatures lets you provide default implementations, such that the user can skip its definition.
00:17:37 <a1tern> dminuoso: providing empty instance worked! thanks a lot
00:22:27 <dminuoso> a1tern: Well more to the point, default signatures lets you specify type signatures for default implementations, such that they can be more constrained.
00:24:32 * Solonarv does the requisite grumbling about fromJust
00:29:50 <Solonarv> better: maybe pure (ioError (userError "informative error message here")) =<< fmap JSON.decode $ ...
00:30:19 <Solonarv> (or maybe just change the return type, but if you're in IO you should at least use the exception mechanism!)
00:32:24 * hackage polyvariadic 0.3.0.4 - Creation and application of polyvariadic functions  https://hackage.haskell.org/package/polyvariadic-0.3.0.4 (fgaz)
00:33:26 <dminuoso> Assume I have some `D -> Set T` that is midly expensive and I need it in various remote parts of the code. Is it dirty to move that into a field of D to gain sharing?
00:34:28 <Solonarv> slightly, but it doesn't sound too terrible to me
00:34:49 <Solonarv> especially if you don't use D's constructor so you can't forget to update/compute that Set
00:35:35 <Solonarv> depending on what D looks like you could maybe also memoize the 'D -> Set T' instead?
00:35:37 <dminuoso> Well another technique would be to just memo-trie that function I suppose..
00:36:03 <dminuoso> Solonarv: What do you mean by that last sentence?
00:36:18 <Solonarv> exactly what you said, actually
00:36:48 <Solonarv> or did you mean the second-to-last one about not using D"s constructor?
00:36:54 * hackage log4hs 0.9.0.0 - A python logging style log library  https://hackage.haskell.org/package/log4hs-0.9.0.0 (gqk007)
00:38:13 <dminuoso> Solonarv: The one regarding D's constructor
00:38:18 <Solonarv> ah
00:38:53 <Solonarv> well, I imagine D would look somewhat like: data D = D { foo :: Foo, ..., tset :: Set T }
00:39:01 <dminuoso> Right
00:39:29 <Solonarv> now construction *should* go through a smart constructor which ensures tset has the correct value
00:39:35 <Solonarv> and the same is true for updates
00:39:58 <Solonarv> suppose you have x :: D and you do x{ foo = newFoo }, but you forget to update the tset field
00:40:01 <Solonarv> horrible!
00:40:12 <dminuoso> Solonarv: Ah, I dont ever update them.
00:40:22 <Solonarv> that helps!
00:40:44 <Solonarv> then you just need a smart constructor, which you probably want anyway to avoid code duplication
00:40:58 <Solonarv> ...unless you only construct D in one place, I suppose
00:41:05 <dminuoso> I only construct D in one place anyway. :)
00:41:21 <dminuoso> The point regarding updates is important though.
00:41:36 <dminuoso> Perhaps MemoTrie is the more elegant solution, as it wont put down minefields in my code.
00:42:00 <dminuoso> Who knows, perhaps I want to refactor code later on to update Ds, and forget about this whole business and introduce subtle bugs.
00:45:27 <Solonarv> I'm going to venture a guess that you are passing it around via ReaderT or something similar; in that case you could instead do something like the following:
00:47:28 <Solonarv> newtype DT m a = DT (D -> Set T -> a) deriving (Functor, Applicative, ...) via ReaderT D (ReaderT (Set T)) m
00:47:29 <Solonarv> class Monad m => MonadD m where
00:47:29 <Solonarv>   getD :: m D
00:47:29 <Solonarv>   getTSet :: m (Set T)
00:47:29 <Solonarv> instance Monad m => MonadD (DT m) where ...
00:47:29 <Solonarv> runDT :: D -> DT m a -> m a
00:47:31 <Solonarv> runDT d (DT f) = f d (computeTSet d)
00:47:50 <Solonarv> wheee, I tripped sigyn ;P
00:49:30 <Solonarv> bah, it's full of typos! I'm sure you get the idea, though
00:54:04 <dmwit> a1tern: ...but you still haven't made an instance for RequirementsHistory.
00:54:35 <dmwit> (In other words, an instance for lists.)
00:55:00 <dmwit> e.g. `instance FromJSON a => LoadFromFile [a]` or whatever
00:55:10 <dmwit> But instances don't just magically appear because you use them.
00:55:58 <dmwit> You have to make them. We've invented a ton of tricks for the compiler to help you make them, but you still do actually have to make them.
00:56:07 <sicklorkin> I'm mid refactor on some type changes and am wondering how to get the top data tuype to compile w/o passing it an a.  Is there some way to do this with GATDs? the compiler suggests i use ImpredicitiveTypes - but that just seems wrong. 
00:56:15 <sicklorkin> https://pastebin.com/jWkaN9sn
00:58:46 <mniip> sicklorkin, what do you mean precisely
00:58:49 <lortabac> sicklorkin: you can do it with existentials (or GADTs)
00:58:55 <c_wraith> is that supposed to be holding polymorphic functions, or functions for an unknown type?
00:58:58 <zmagii> sup
00:59:36 <lortabac> however, depending on how you want to use APIConfig, it might make things more complicated
00:59:40 <merijn> sicklorkin: I think GHC is probably right that you need impredicative types, you are, however, also correct that you should *not* use -XImpredicativeTypes
00:59:48 <sicklorkin> This APIConfig is pass around everywhere.. maybe 100 or more places.. I want to avoid having to chase everywehre..
01:00:09 <c_wraith> but do you mean existential quantification or polymorphic components?
01:00:28 <c_wraith> they have incredibly similar syntax, but entirely opposite meaning.
01:00:40 <sicklorkin> s/chase everwehere/change to affect so many places/
01:01:17 <dmwit> This snippet makes me nervous.
01:01:32 <c_wraith> though the more I look at it...  that type variable is meaningless anyway
01:01:37 <dmwit> What if Paginate was a datatype instead of a class?
01:02:05 <Solonarv> actually we have not seen what APISource is.
01:02:10 <sicklorkin> dmwit: i def didnt' put much thought into Paginate... at the time a class seemed fine. 
01:02:27 <dmwit> data Paginate = Paginate { new :: Query -> QueryRange, next :: QueryRange -> QueryRange, ... }
01:02:29 <sicklorkin> APISource is an abstraction of how to get data from sites.
01:03:01 <sicklorkin> Under APISource we have a bunch of servant things
01:03:22 <c_wraith> The only way that type variable makes any sense is if it's existentially quantified as a sort of brand...  But that seems like it should be better expressed using laziness.
01:03:31 <sicklorkin> dmwit: thats worth a shot.
01:04:05 <sicklorkin> Well it was that class that force me to add the a
01:04:15 <dmwit> (And one value of type Paginate per instance you currently have.)
01:04:32 <c_wraith> then definitely follow dmwit's suggestion and get rid of the class
01:05:05 <dminuoso> Solonarv: Not quite. I have various graphs/maps that contain Ds
01:05:05 <sicklorkin> right, i will do that.. 
01:06:34 <sicklorkin> dmwit: i guess the other option would be to make APIConfig a class 
01:07:12 <sicklorkin> Ther is a lot of code share vbetween most implementation which the class defaults would clean up nicely
01:07:34 <dmwit> You can share code between records...
01:07:50 <sicklorkin> but you're left with \case Site1 -> ... 
01:08:08 * dmwit furrows his brow
01:08:12 <sicklorkin> lol
01:08:28 <dmwit> Why are you left with that?
01:08:36 <dmwit> And why is it undesirable to be left with that?
01:10:54 <dmwit> I dunno. You've given us waaaay too little info to give actually good API design advice.
01:11:48 <dmwit> We have no idea what you're trying to do, and what thoughts you've had that lead you to the point you're currently at, so it's next to impossible to direct you towards a more idiomatic way. But this way looks all kinds of strange to me.
01:11:52 <sicklorkin> dmwit: i realize this and i don't think i wanna put to much time tinto the gritty details... it wouldn't be so productive..
01:12:39 * dmwit shrugs
01:12:41 <dmwit> okay then
01:13:48 <sicklorkin> cheers!
01:19:44 <phaazon> hey
01:19:50 <phaazon> has something changed to push packages to hackage?
01:20:25 <merijn> phaazon: What makes you ask?
01:20:34 <phaazon> I don’t recall having to call cabal new-sdist
01:20:49 <phaazon> it’s been a while I haven’t pushed a package, but I remember it was pretty easy back then
01:22:51 <merijn> phaazon: What did you do, then? I don't think there's never been a time you didn't have to do "cabal sdist" to get a tarball...
01:25:54 * hackage aeson-default 0.9.1.0 - Apply default value to FromJSON instacnes' Maybe fields  https://hackage.haskell.org/package/aeson-default-0.9.1.0 (gqk007)
01:29:41 <phaazon> merijn: really?
01:29:50 <phaazon> what did I do, I’ll ask myself :D
01:30:24 * hackage storable-record 0.0.4.1 - Elegant definition of Storable instances for records  https://hackage.haskell.org/package/storable-record-0.0.4.1 (HenningThielemann)
01:32:30 <phaazon> maybe I was using stack
01:33:11 <merijn> phaazon: I mean, there's "cabal upload" but that still requires manually running sdist to create a tarball
01:33:14 <MarcelineVQ> stack upload maybe
01:34:15 <phaazon> yeah, I think I was using stack upload
01:34:22 <phaazon> but I prefer using cabal from now on
01:34:28 <phaazon> https://hackage.haskell.org/package/smoothie-0.4.2.10/candidate
01:34:36 <phaazon> yeah, looks like I’m okay with just cabal sdist + cabal upload
01:34:38 <phaazon> thanks peeps
01:34:47 <phaazon> I guess I also need to include the documentation
01:37:18 <Solonarv> hackage will build it too
01:37:21 <Solonarv> just takes a while
01:37:43 <phaazon> yeah, but sometimes it doesn’t
01:37:55 <phaazon> https://hackage.haskell.org/package/smoothie-0.4.2.10/candidate
01:37:57 <phaazon> it seems okay
01:38:07 <phaazon> I like the new style :P
01:38:11 <phaazon> purple is <3
01:41:18 <phaazon> hm, QuickJump
01:41:20 <phaazon> that’s new :)
01:41:24 * hackage smoothie 0.4.2.10 - Smooth curves via several interpolation modes  https://hackage.haskell.org/package/smoothie-0.4.2.10 (DimitriSabadie)
01:41:30 <phaazon> I’m glad to see Haskell is going in a more friendly way to do things
01:41:43 <phaazon> I switched lots of my packages from Haskell to Rust and I still miss working in Haskell a lot…
01:41:56 <phaazon> my website is still written in Haskell though, so I still have some brain candies :P
01:43:02 <lortabac> phaazon: why did you port your packages from Haskell to Rust?
01:44:16 <phaazon> lortabac: I mostly do graphics programming (i.e. luminance), and it makes more sense to use a language without a RT
01:44:39 <phaazon> however, I still keep in eye on the day Haskell (or another pure functional language) will remove the use of a GC
01:44:48 <phaazon> on that day, I will switch back from Rust to that language :D
01:44:56 <phaazon> I miss too much from Haskell
01:45:04 <phaazon> the syntax, the expressivness, etc.
01:45:06 <tdammers> I've been thinking about that quite a bit, but I don't know how that would work
01:45:08 <phaazon> however, I really don’t miss the tooling :D
01:45:14 <phaazon> Rust is a blast compared to Haskell
01:45:16 <phaazon> both rustup and cargo
01:45:33 <phaazon> tdammers: I had to adapt a bit, because Rust doesn’t have kinds
01:45:45 <phaazon> but it’s mostly “okay” in terms of abstractions
01:45:51 <tdammers> no, I mean, a pure-functional language without GC (or refcounting)
01:46:01 <phaazon> for instance, it doesn’t have type families but you can easily emulate them with traits and associated types
01:46:06 <phaazon> ah, tdammers so
01:46:09 <tdammers> if you know what you're doing, even C++ is almost OK in terms of abstractions
01:46:19 <phaazon> I’ve been asking the opposite question to myself
01:46:21 <phaazon> for years
01:46:26 <phaazon> why do you need a GC
01:46:31 <phaazon> and by GC I mean, a generational GC
01:46:38 <phaazon> not a ref-counting system as in Rust for Rc / Arc
01:46:46 <phaazon> tdammers: nah, C++ is never okay
01:46:55 <phaazon> (I do C++ at work on a daily basis, please kill me)
01:46:57 <tdammers> I said "almost"
01:47:02 <phaazon> yeah like
01:47:05 <tdammers> also, "C++ at work" is never OK
01:47:11 <dminuoso> 10:44:16        phaazon | however, I still keep in eye on the day Haskell (or another pure functional language) will remove the use of a GC
01:47:24 <dminuoso> phaazon: I do not see that happening in the distant future at all.
01:47:24 <tdammers> C++ is a language that one uses out of morbid curiosity, or for projects that nobody else will ever have to work on
01:47:25 <Taneb> phaazon: with laziness you can easily get cycles even by accident which make reference-counting more difficult
01:47:36 <merijn> phaazon: I have a better question for you: Why would I not want a GC?
01:47:38 <phaazon> |--horrible--really_bad--bad--C++---------------------------------------------------------------------------okay--good--great--Rust/Haskell/Idris--|
01:47:46 <phaazon> that’s your “almost” :D
01:47:59 <merijn> phaazon: The onlyr eason not too want it is "I cannot afford GC pauses", which only applies for real-time-ish code
01:48:06 <tdammers> so anyway, yeah, aggressive use of thunks and recursive data structures, I think, is the main reason why refcounting isn't the obvious choice
01:48:25 <phaazon> merijn: then you’ve answered your own question
01:48:33 <phaazon> as I said above to lortabac, I do graphics programming
01:48:33 <merijn> tbh, GHC's generational GC is perfectly fine for 95% of things
01:48:40 <phaazon> yes it’s really good
01:48:52 <phaazon> tdammers: yes but you can do those with RC
01:49:05 <phaazon> so I don’t get what a GC exactly can do a RC system cannot
01:49:10 <phaazon> to me it’s not even about capabilities
01:49:14 <phaazon> it’s just a choice of implementation
01:49:20 <phaazon> so, in theory, we could have a Haskell without GC
01:49:23 <tdammers> it's not that it can't be done, it's that it's hard to make efficient
01:49:32 <merijn> phaazon: Reference counting doesn't deal well with cycles
01:49:43 <phaazon> merijn: you have to account for weak ones, yes
01:49:51 <phaazon> I guess that a GC is better at pooling, also
01:50:00 <merijn> phaazon: You need to start doing complicated things like weak references, start properly deciding which is which, etc.
01:50:01 <tdammers> also that haskell is traditionally biased towards throughput, not latency or deterministic allocation
01:50:01 <dminuoso> phaazon: And no, we cannot trivially have Haskell without a GC.
01:50:02 <phaazon> I know that a GC can allocate a lot of memory soon
01:50:04 <phaazon> RC can’t
01:50:15 <phaazon> (but that would depend on the allocator behind the RC… so they could, actually)
01:50:17 <tdammers> RC with a pool cab
01:50:18 <dminuoso> phaazon: The execution model we employ itself makes it hard. We dont have callstacks to tell us when something is left behind.
01:50:30 <merijn> phaazon: Also, the borrow checker is good at what it does, but 90% of my life I don't wanna deal with that :)
01:50:44 <phaazon> dminuoso: that’s not completely true
01:50:46 <phaazon> you have a stack
01:50:47 <dminuoso> phaazon: Efficient Haskell implementations do something closer to graph reduction, we dont have sensible mechanisms to track when something has "gone out of scope"
01:50:53 <dminuoso> phaazon: That stack has a completely different purpose.
01:50:53 <phaazon> especially with linear types, it’ll get easier to track
01:51:00 <phaazon> ah really?
01:51:11 <phaazon> merijn: what do you mean?
01:51:27 <phaazon> dminuoso: yeah, graph reduction is really powerful, but I mean
01:51:38 <merijn> phaazon: Thinking about and managing ownership costs non-zero thinking. GC means I can skip all that'
01:51:44 <phaazon> I haven’t seen a paper or a good argument with technical implications stating why it has to be done with a GC
01:51:56 <phaazon> merijn: that’s true
01:52:41 <dminuoso> phaazon: Say you did something with refcounting and magically avoided/solved all the pitfalls of lazyness and circular structures. Just for the argument.
01:52:43 <tdammers> phaazon: I believe the main argument so far is that we have a GC that works and performs well; nobody has come up with an RC-based implementation yet, AFAIK
01:53:05 <dminuoso> phaazon: The execution model just doesn't have the notion of "We left here" to even decrement ref counters.
01:53:06 <phaazon> tdammers: interesting
01:53:29 <phaazon> dminuoso: how does ATS do? IIRC, it doesn’t have a GC
01:54:52 <phaazon> merijn: the main problem I have with the GC is that I care about predictability and memory consumption, and GCs don’t really play well with those for the type of low-level stuff I want to do
01:55:05 <phaazon> Rust is cool to allow “almost” the Haskell expressiveness at low-level
01:55:17 <phaazon> and you can build higher-abstracted blockes atop
01:55:27 <phaazon> but I really miss all the syntax and concepts from Haskell
01:55:28 <dminuoso> phaazon: I cant say, but a quick look suggests it has traditional call-by-value semanticvs
01:55:32 <phaazon> even though I also see pitfalls
01:55:43 <phaazon> like, monad transformers seem so weird when you look at them from outside :)
01:55:56 <phaazon> a friend of mine asked me what they would be “in Rust”
01:56:02 <phaazon> I couldn’t explain, because it doesn’t make sense
01:56:11 <phaazon> dminuoso: I see
01:57:15 <Solonarv> Rust is not higher-kinded enough to easily express Monad (the typeclass, not individual monads) or monad transformers
01:57:36 <Solonarv> it probably can be done but it'll be a horrible mess, which defeats the point entirely
01:58:10 <dminuoso> phaazon: It's the reason why something like obtaining a call trace when a bottom is thrown is impossible in the general way. It requires special instrumentation from RTS (using the HasCallStack hack)
01:58:26 <tdammers> there are lots of blog posts out there that show how you could make a Monad abstraction in a dynamically-typed language; some of them are even correct (they pass the Monad instance explicitly though, as an object), they're just too awkward and boilerplatey to convince anyone
01:59:14 <phaazon> Solonarv: yeah, I’ve done it once
01:59:22 <phaazon> just Functor is terrible to write instances (impl) for :)
01:59:29 <dminuoso> phaazon: The best you can do is what Rust is doing, really. 
01:59:50 <dminuoso> But then again, given our execution model that's not applicable for us either.
01:59:55 <tdammers> that, or make peace with the GC
02:00:11 <lortabac> tdammers: IMHO the problem is, if you cannot type-check it, why bothering with building such an abstraction? duck-typing is easier
02:00:20 <tdammers> lortabac: exactly
02:00:30 <Solonarv> yeah, higher-kinded type classes (i.e. type classes whose parameters have function kinds) are terrible to encode in Rust, because you have to *encode* them
02:00:31 <dminuoso> lortabac: Haha by the way! My graph now, is fully represented by adjacency matrices no.
02:00:45 <dminuoso> lortabac: Just what you proposed the first time.
02:00:46 <phaazon> tdammers: I’m at peace with the GC for lots of use cases (i.e. phaazon.net is written with servant and it’s fast enough to me)
02:00:49 <merijn> dminuoso: Why matrices, why not CSR?
02:00:51 <phaazon> but for low-latency graphics code
02:00:53 <phaazon> or embedded
02:00:55 <phaazon> or…
02:00:57 <phaazon> ;)
02:01:02 <dminuoso> merijn: What advantage to I have from CSR?
02:01:06 <tdammers> lortabac: which, I believe, is also the reason why nobody uses monads in clojure - there's a library for them, the syntax is tight and unobtrusive, but it still doesn't buy you anything
02:01:12 <merijn> dminuoso: Less wasted memory for sparse graphs
02:01:21 <dminuoso> merijn: The graphs are relatively small anyway.
02:01:29 <Solonarv> I've foolishly decided to write a (graphical, real-time!) game in Haskell, hopefully it will not be horribly slow
02:01:40 <dminuoso> merijn: Nodewise, we're talking low 3 digits, with the need to scale into 4 digits.
02:01:43 <phaazon> I know it might sound utopistic, but I like to use a language for all usecases (I don’t agree with people stating that each problem has one language; good languages can solve several of them, and Haskell already solve a lot — scripting, good performance applications, web, etc.)
02:01:50 <merijn> dminuoso: Plus I find it more easy to think about CSR representations recursively
02:01:59 <phaazon> but low-latency and embedded are not Haskell’s best scope
02:02:09 <tdammers> phaazon: for low-latency graphics, you might be interested in the new concurrent GC, which was concocted exactly to provide an alternative that prioritizes latency over throughput
02:02:33 <merijn> tdammers: Even that isn't super low latency, though
02:02:41 <dminuoso> merijn: Is there a particular ipmlementation on hackage for that?
02:02:54 <merijn> dminuoso: I don't think so, but it's also trivial, tbh
02:02:56 <tdammers> merijn: true, and it's nowhere near the predictability of what you can get out of C, C++, D or Rust
02:03:05 <phaazon> tdammers: I should have a look at it
02:03:07 <tdammers> merijn: but it may still be acceptable, and the other benefits might tip the scale
02:03:12 <phaazon> but yeah, I feel torn :)
02:03:15 <phaazon> because my heart is with Haskell
02:03:21 <phaazon> but pragmatism goes for Rust right now
02:03:25 <lortabac> there is a language called Formality, which has neither GC nor refcounting, however I don't think it will ever be suitable for graphics
02:03:55 <tdammers> fwiw, people have written commercial games in Haskell, even before the concurrent GC was a thing. I hear it was somewhat painful to performance-tune though.
02:05:26 <merijn> dminuoso: Basically for a graph with V vertices and E edges you have two vectors, one vector that's (V+1) elements and ones that has E elements. Every element in the first vector is an index into the second vector indicating where edges for that vertex start. (vertex[0] has the start idx for vertex 0, vertex[1] for vertex 1, etc. You can easily find the slice of edges for a vertex via "vertex[1] - 
02:05:32 <merijn> vertex[0]" to get the count and direct indexing
02:06:32 <merijn> dminuoso: Then in the other vector each element indicates a vertex that edge connects too. So if we have "vertex[0] = 0; vertex[1] = 5" (i.e. vertex 0 has 5 outgoing edges) then edge[0]-edge[4] hold the vertex it's connected too
02:06:49 <merijn> dminuoso: If you need state per vertex you can simply create another vector for each edge's state
02:10:53 <dminuoso> merijn: Mmm that seems to have simpler slicing operations too.
02:11:34 <merijn> dminuoso: Yes
02:12:12 <merijn> dminuoso: (the V+1 is obviously so that final element indicates the total count of the edge array, which I suppose is implicit in Vector, but simplifies things in C)
02:14:51 <dminuoso> merijn: Ah for accessing the final edge I suppose?
02:15:12 <merijn> Yeah
02:15:33 <merijn> Then you can basically safely always do "vertex[v+1] - vertex[v]" to compute the edges for v
02:16:41 <dminuoso> Interestingly, since I have a logical adjacency matrix, I dont need it either
02:16:52 <dminuoso> Or no hold on. Thats wrong
02:17:18 <merijn> dminuoso: CSR is originally a matrix representation for sparse matrices ;)
02:18:07 <dminuoso> merijn: Oh man, CSR actually fits my use case *so well*
02:18:39 <dminuoso> Essentially my vertices can be grouped by some property, and I have the need to analyze each group separately 
02:18:47 <merijn> dminuoso: That's because it's the most flexible & efficient graph representation if you don't need to mutate the actual structure. Most operations become trivial and efficient traversals are easy
02:19:04 <dminuoso> In my case, it's as simple as just `groupBy prop` on the vertex list/vector, and then work with each group
02:19:31 <dminuoso> (Well this is a bit pseudo of course, but you get the idea)
03:20:24 * hackage kubernetes-webhook-haskell 0.1.0.0 - Create Kubernetes Admission Webhooks in Haskell  https://hackage.haskell.org/package/kubernetes-webhook-haskell-0.1.0.0 (amarrella)
03:28:16 <Felipe> Hey, guys
04:00:44 <olligobber> (==) should be reflexive right?
04:01:09 <olligobber> > let x = 0/0 in x == x
04:01:11 <lambdabot>  False
04:02:08 <merijn> olligobber: 0/0 defaults to Double and IEEE754 requires that NaN /= NaN
04:02:35 <berndl> olligobber: welcome to floating-point hell
04:02:36 <merijn> olligobber: So you can either choose to have properly working Eq/Ord *or* IEEE-754 compliance, you can't have both*
04:02:59 <olligobber> I know which I'd choose
04:03:21 <merijn> olligobber: Well, carter has plans to improve/fix the floating point stuff in GHC so we can have both :p
04:04:05 <merijn> (by switching to/allowing trapping NaN, this would make NaN values impossible, so you can never end up comparing two NaNs and then the problem goes away)
04:04:39 <olligobber> hmm, the warning when you type -1 :: GHC.Num.Natural into ghci says "Natural only supports positive numbers", so I guess 0 is positive
04:04:52 <merijn> Yes
04:05:59 * olligobber sighs
04:06:22 <merijn> I know some mathematicians argue that 0 is neither, but those are clearly wrong, that's the same insanity as insisting that the natural numbers don't include 0
04:06:29 <merijn> Which is borderline heresy
04:06:43 <berndl> positive reads nicer than nonnegative.
04:06:53 <olligobber> the natural numbers include 0, the positive integers do not include 0
04:07:10 <merijn> olligobber: You say that, but many mathematicians claim the natural numbers start at 1
04:07:21 <berndl> Also, some math people use the term "strictly positive" to mean positive.
04:07:43 <olligobber> merijn, they are wrong, and I will fight them
04:07:48 <Ferdirand> positive numbers are numbers greater than 0, and strictly positive numbers are numbers strictly greater than 0, sounds fine, no ?
04:07:49 <merijn> This just in: There are many conflicting definitions of mathematica terms
04:08:13 <olligobber> everyone else is wrong
04:08:20 <merijn> olligobber: Anyway, wait until you learn more about IEEE-754 and find out that there's a negative 0 :p
04:08:24 <berndl> Yep. Math people suffer from naming issues just like in programming.
04:08:43 <tdammers> mathematicians also routinely suffer from cognitive bias
04:08:55 <tdammers> hard to avoid
04:09:06 <tdammers> especially when traditionally the whole thing hinges on manual diligence
04:09:06 <olligobber> merijn, yeah, the Eq instance of Float also fails substitutivity, and the Num instance fails additive identity
04:10:26 <tdammers> also, I believe the only serious argument for having Eq and Ord instances for Float/Double in the first place I've seen so far basically boils down to "but we want to"
04:10:40 <olligobber> >(0==(-0::Float),1/0==1/(-0::Float))
04:10:50 <merijn> tdammers: What? It's perfectly fine to have Eq and Ord instances
04:10:56 <berndl> tdammers: I thought the reason was notational convenience.
04:10:58 <olligobber> > (0==(-0::Float),1/0==1/(-0::Float))
04:10:59 <merijn> tdammers: It's value NaN that's the problem, the Eq/Ord are fine
04:11:00 <lambdabot>  (True,False)
04:11:26 <merijn> Let's not throw the baby out with the bathwater
04:11:54 <merijn> The Enum instance of Float/Double is unjustifiable, but Eq and Ord are fine
04:12:08 <tdammers> Eq is still problematic IMO
04:12:13 <merijn> tdammers: Why?
04:12:18 <olligobber> yeah, Float should be Bounded but not Enum
04:12:19 <tdammers> or rather, it's not as useful as you'd want it to be
04:12:40 <merijn> olligobber: Bounded makes no sense, since it's bounds are infinity
04:12:52 <merijn> tdammers: Disagree, it's exactly as useful as I want it to be
04:12:59 <dminuoso> merijn: Well Eq on Double/Float violates reflexivity
04:13:01 <olligobber> it makes sense to me, it has a maximum value and a minimum value
04:13:06 <dminuoso> Because NaN
04:13:15 <merijn> dminuoso: Not if you get rid of value NaN, which is what I was just saying
04:13:21 <tdammers> dminuoso: that's the argument though - the problem is NaN, not the rest of it
04:13:28 <olligobber> even without NaN, Eq fails substitutivity
04:13:46 <merijn> The solution to "value NaN violates reflexivity" is to throw out value NaN, not Eq
04:13:48 <dminuoso> olligobber: What property is that?
04:14:17 <olligobber> dminuoso, x == y implies f x == f y for publicly visible functions f
04:14:36 <merijn> olligobber: That's not guaranteed by Eq anyway
04:14:44 <merijn> Haskell isn't math
04:14:59 <dminuoso> olligobber: Oh I know that as Leibnizian equality.
04:15:01 <berndl> NaN is one problem. The other problem is that you're allowed to write 0.3 for a float when in fact it's not.
04:15:13 <olligobber> "== is customarily expected to implement an equivalence relationship where two values comparing equal are indistinguishable by "public" functions" - https://hackage.haskell.org/package/base-4.12.0.0/docs/Prelude.html#t:Eq
04:15:25 <tdammers> berndl: that's not a problem in this sense. that's just poorly chosen / inadequate syntax
04:15:27 <merijn> olligobber: "customarily"
04:15:29 <dminuoso> newtype a := b = Refl { subst :: forall c. c a -> c b }
04:16:07 <berndl> tdammers: poor syntax is a problem. It's deceiving.
04:16:08 <dminuoso> olligobber: How is that violated?
04:16:20 <merijn> dminuoso: -0 and 0, probably
04:16:32 <dminuoso> Ah I suppose so.
04:16:35 <olligobber> dminuoso, 0 == -0 is True, 1/0==1/-0 is False
04:17:20 <dminuoso> merijn: Im not convinced that tossing out NaN is the solution. If it is an IEEE-754 conform implementation, then you can't just throw out parts of it just to have convenient typeclass instances
04:17:40 <merijn> dminuoso: Ah, but I didn't say "toss out NaN"
04:17:46 <merijn> dminuoso: I said "toss out *value* NaN"
04:17:56 <merijn> dminuoso: because IEEE-754 does *not* require NaN to be a value
04:18:12 <dminuoso> merijn: So what you are suggesting is runtime exceptions on NaN?
04:18:13 <merijn> dminuoso: It explicitly defines behaviour for "trapping NaN" (i.e. exceptions/bottom)
04:18:15 <dminuoso> Right
04:18:29 <merijn> dminuoso: Which is much better behaved
04:18:34 <tdammers> berndl: yes, but it's a *different* problem; it has nothing to do with NaN or the Eq and Ord typeclasses
04:18:47 <merijn> dminuoso: Because we already know about bottoms when talking about Eq/Ord/etc.
04:18:54 <maralorn[m]> Isn‘t this the reason, why Rust has PartialEq and PartialOrd?
04:19:07 <Taneb> maralorn[m]: yes
04:19:10 <dminuoso> berndl: Amusingly, whether or not the literal 0.3 is a valid float depends on the implementation. IEEE-754 allows for decimal based representations.
04:19:54 <dminuoso> I dont think Ive ever seen a decimal IEEE-754 in existence though.
04:20:20 <olligobber> ooh, Haskell should have 3 bit floats
04:20:42 <maralorn[m]> (which in practice can be a real pain.) Because sometimes you really want Eq for some struct and if you just have one float field in at you can‘t have it.
04:21:10 <merijn> maralorn[m]: That's only because Rust has also committed to having value NaN since they don't want exceptions
04:21:40 <maralorn[m]> olligobber: Oh, that sounds like a nice exercise. What are those eight numbers?
04:22:04 <olligobber> maralorn[m], 0, -0, 1, -1, Infinity, -Infinity, NaN, NaN
04:22:28 <maralorn[m]> Uh, that‘s boring.^^
04:22:49 <Taneb> I do like one-tenth-width floating point
04:23:31 <Taneb> Two-bit is nice, you don't have NaNs, but you also don't have 1
04:24:50 <olligobber> doesn't the floating point standard require there to be a sign bit, exponent bit(s) and magnitude bit(s)?
04:27:35 <olligobber> https://i.imgur.com/22zDMpI.png
04:27:49 <maralorn[m]> dminuoso: I only just had time to look at your incoherent instances problem and I am not convinced that it is a problem.
04:28:14 <maralorn[m]> Ah, wait, I have not executed it.^^
04:30:52 <maralorn[m]> Now I have.
04:32:07 <maralorn[m]> It still feels a bit artificial to me, because the Eq and Ord instance in module B are so weird.
04:33:09 <dminuoso> maralorn[m]: Imagine what happens if Map assumes some precondition on the internal structure and starts doing unsafe operations that all assume some properties hold.
04:33:41 <maralorn[m]> Yeah.
04:33:45 <dminuoso> maralorn[m]: That is not even artificial, many high performance libraries do this.
04:34:36 <dminuoso> maralorn[m]: It could be as simple as a different ordering. Say the API functions *assume* the internal tree to always be balanced, and error out if its not.
04:34:54 <maralorn[m]> So I think in some cases it might even work, because if you define an orphan instance and use it you actually get the code behavior you expect.
04:35:16 <merijn> maralorn[m]: Maybe, maybe not
04:35:17 <maralorn[m]> The problem arises when you make assumptions about date you get from other code.
04:35:22 <merijn> maralorn[m]: You can't tell, that's the problem
04:36:04 <olligobber> huh, you can implement booleans with NaN and Infinity, just use (*) as or, max as and, and \x->max(-x,-1)+1/0 as not
04:36:40 <maralorn[m]> In general the assumption this data was created with the same instance is not enforced by the language.
04:36:49 <dminuoso> maralorn[m]: Orphans in executables are realistically not a problem because GHC will error out about duplicate instances if it overlaps. But the second its in a library you cant be sure anymore.
04:37:21 <olligobber> s/max(-x,-1)/min (-x) (-1)/
04:38:17 <maralorn[m]> Well I still feel like I can think of instances where it‘s not dangerous.
04:38:38 <dminuoso> maralorn[m]: The main problem is when GHC cant tell you that you have incoherent instances.
04:38:48 <dminuoso> You dont even know.
04:40:01 <dminuoso> maralorn[m]: The really tricky examples are not if your code errors out, but straight misbehaves. They are especially problematic because when trying to construct a test case you'd isolate a single instance and the problem goes away
04:40:26 <dminuoso> So if you consider my example, the only conclusion you could take "Map is buggy"
04:40:40 <dminuoso> Or I think it was Set.
04:42:22 <maralorn[m]> dminuoso: Well I think the rule is simple: Only define an orphan instance if you can be sure it won‘t lead to incoherent behavior. And while I still believe there are cases where you could argue/show that it won‘t go wrong, it‘s probably a better heuristic to just not do it.
04:42:23 <dminuoso> maralorn[m]: I recently pondered a fair 20 minutes about whether my usage of `D { members = unsafePerformIO (newIORef []), ... }` was safe. I was proven wrong after debugging for about an hour, just to figure out that unsafePerformIO caused GHC to float that `unsafePerformIO (newIORef [])` out to top level, aliasing all my mutable buffers.
04:42:31 <dminuoso> Unsafe things tend to be unsafe because they are really hard to predict
04:43:33 <maralorn[m]> But thanks for the example and the discussion, I think I have now a very much more precise understanding on how incoherent instances can go wrong.
04:47:00 <maralorn[m]> On example of a probably harmless instance would be a typeclass like PrettyDebug { createDebugOutput :: a -> Text }. If you use your instance only locally to print that output to stderr or something I can‘t see any danger in different code using another instance (well perhaps besides inconstent log output. But that might even be on purpose.)
04:48:05 <dminuoso> maralorn[m]: If you define that typeclass yourself, you dont need orphans.
04:49:54 <maralorn[m]> dminuoso: Yeah, my problem is probably artificial in that you can do it better without orphans.
04:50:31 <dminuoso> maralorn[m]: The usual issue is you require two libraries, one defines a typeclass and another some type, and you want an instance from the type on the typeclass.
04:54:31 <lortabac> dminuoso: "GHC will error out about duplicate instances if it overlaps" -> apparently it's not always the case in a partial recompilation
04:54:51 <dminuoso> Oh, really? :o
04:55:11 <maralorn[m]> Yeah, e.g. a ToJSON instance for UTCTime?
04:55:17 <lortabac> someone told me on Reddit, it's never happened to me
04:55:50 <lortabac> it'a a kind of known GHC bug
04:56:02 <dminuoso> maralorn[m]: I think much of Aeson suffers from being tied to typeclasses.
04:56:43 <maralorn[m]> I think that‘s actually something that could work, if I have two libraries in my program one using weird REST protocol a and the other using weird REST protocol b. Then I might even need incoherent instances.
04:57:02 <dminuoso> maralorn[m]: You can use much of aeson without them, so if you think you need typeclasses, its just your refusal to manually build parser/serializers. :P
04:57:18 <dminuoso> No you dont.
04:57:23 <dminuoso> Just stop using typeclasses there.
04:59:26 <maralorn[m]> dminuoso: I just think it‘s a realistic example for a use case for orphan instances.
04:59:33 <ph88> how do you do stack clean so that all dependencies get rebuild as well (even though that might be unnecessary) ?
05:00:31 <merijn> maralorn[m]: Well, why is PrettyDebug even a class? Like, what's the point
05:00:32 <maralorn[m]> I actually needed a FromJSON instance for UTCTime a while back and I painfully did not implement an orphan instance because everyone (including the compiler) told me it‘s a bad idea.
05:00:40 <merijn> maralorn[m]: You can just make it a function and everything "just works"
05:00:47 <maralorn[m]> And I‘ll probably stick with that.^^
05:01:14 <merijn> maralorn[m]: Why would it be painful? You can just define a newtype + instance and you're done?
05:01:16 <dminuoso> maralorn[m]: In case of ToJSON, you only need the outermost to be a typeclass instance.
05:01:45 <dminuoso> maralorn[m]: You can just define your own function `encodeUTC :: UTCTime -> Value`
05:01:52 <dminuoso> Voila. No typeclass, no instance, no orphan.
05:01:57 <maralorn[m]> merijn: I didn‘t want a newtype because I wanted the users of my library to just be able to access the date as a date.
05:02:14 <maralorn[m]> And yes, the other solution is exactly the one I picked.
05:02:21 <merijn> maralorn[m]: So? You can just do "fmap unwrap (yourWrappedParser)"
05:02:36 <merijn> Before returning it to your user
05:03:08 <maralorn[m]> merijn: Granted. But that‘s not better than just using a function.^^
05:04:24 * hackage rock 0.2.0.0 - A build system for incremental, parallel, and demand-driven computations  https://hackage.haskell.org/package/rock-0.2.0.0 (OlleFredriksson)
05:04:26 <nshepperd2> if you're interfacing with any kind of external data source you really need to *not* use typeclasses imo. since there's no guarantee given that From/ToJson will use any particular encoding
05:04:55 <merijn> nshepperd2: Agreed. Same reason why the instance for Binary are a bad idea to use
05:06:13 <boxscape> > [1/(-0)..]
05:06:15 <lambdabot>  [-Infinity,-Infinity,-Infinity,-Infinity,-Infinity,-Infinity,-Infinity,-Infi...
05:06:18 <dminuoso> Typeclasses in general for serialize/deserialize type are fine if there's truly only a single canonical way that makes sense, for everything else its easier to just write your own parser/serializer by hand.
05:08:18 <boxscape> hm, maybe the Enum instance of Double would make more sense if `toEnum (fromEnum x + 1)` were the smallest Double greater than x?
05:08:19 <boxscape>  On the other hand, it'd also be less intuitive in some ways, so maybe not
05:08:51 <merijn> boxscape: Then it'd be useless though
05:08:56 <merijn> It should je be removed, imo
05:09:13 <boxscape> hm, okay, I admit I can't think of a use off the top of my head, yeah
05:09:47 <nshepperd2> The prospect of [0..1] iterating through all floating point numbers between 0 and 1 is an interesting one
05:18:50 <boxscape> Is there something speaking against instance Bounded Double where minBound = -1/0; maxBound = 1/0?
05:24:21 <merijn> Infinity seems the exact opposite of Bounded? :p
05:24:36 <sshine> haha
05:26:25 <boxscape> I feel like there's interpretative freedom here; infinity is an upper bound in that you can't go above it. But I don't know whether the typeclass name alludes to some more technical definition
05:27:13 <sshine> I guess you can speak of open and closed bounds just as you can speak of open and closed intervals? my knowledge of topology is entirely improvised.
05:27:23 <fendor> > [(0/0) < (1/0), (0/0) > (1/0)]
05:27:25 <lambdabot>  [False,False]
05:28:10 <fendor> I would expect from: forall x (maxBound >= x)
05:28:23 <fendor> > (1/0) >= (0/0) 
05:28:25 <lambdabot>  False
05:28:28 <boxscape> sshine thing is, with the real numbers an interval up to infinity is open because infinity is not an element of the reals, but it is an element of Double
05:28:47 <boxscape> fendor that would be solved with trapping NaN as well though
05:31:02 <berndl> sshine: there's no such thing as an open/closed bounds. Perhaps you're thinking of max/min vs inf/sup?
05:31:23 <sshine> berndl, yes.
05:31:47 <argent0> hi, how does resource acquisition works in fused-effects. I'm thinking about something like the `braket` pattern. But how does one goes around abastracting that?  Here's what I've come up so far: https://gist.github.com/argent0/330452a5efe30f9c0a3ffa4c976bc8a5
05:32:37 <solonarv> but ±Infinity are members of Float. They are minimum/maximum, not mere inf/sup
05:33:18 <solonarv> oh oops, I'm too late
05:35:04 <solonarv> argent0: is the intent that the user calls 'Init' exactly once, 'PutChar' and 'GetEvent' any number of times, and finally 'CleanUp' at the end?
05:35:10 <berndl> argent0: So you want to pass around a "proof" as your resourse?
05:36:41 <argent0> solonarv: yes
05:40:25 <ph88> how to add some source code conditionally based on GHC version ?
05:40:58 <solonarv> ph88: CPP (short for C PreProcessor) is the usual way
05:41:29 <solonarv> pick any widely-used library (e.g. containers, vector, ...) to see an example
05:41:45 <boxscape> ph88 https://stackoverflow.com/questions/28292476/ghc-version-check-in-code
05:41:58 <argent0> berndl: that's would be a proof that init was called. I've considered another aproach with https://gist.github.com/argent0/330452a5efe30f9c0a3ffa4c976bc8a5
05:42:03 <ph88> thanks guys
05:42:23 <merijn> ph88: What's conditional on the GHC version?
05:42:51 <boxscape> FWIW, they always try to make it so there's some way you can write your code such that it will work in at least 3 (I think?) consecutive ghc versions
05:43:40 <solonarv> argent0: I don't think the way 'Proof' is used in PutChar and GetEvent is right. You want the caller to have to supply a Proof, but instead your type says that you give the caller one!
05:44:01 <ph88> merijn, wether to import Data.Monoid being required in GHC 8.0.1 or being redundant in 8.6.5  .. by the way how can i check in which GHC version this changed ?
05:44:23 <merijn> ph88: You can check in the GHC changelog
05:44:40 <ph88> is it something that was added in the prelude ?
05:44:51 <merijn> Yes
05:46:02 <ph88> i don't find this information in the changelog of base https://github.com/ghc/ghc/blob/master/libraries/base/changelog.md 
05:46:09 <ph88> maybe there is a seperate changelog for ghc
05:46:16 <solonarv> argent0: I would actually leave this init/cleanup business to the effect interpreter
05:46:21 <solonarv> that seems much cleaner to me
05:46:24 <merijn> ph88: There is, in the user guide and release note
05:46:36 <ph88> google can't find it
05:49:17 <tabaqui1> If I have some type with hidden constructors which is a instance of RealFrac, Real, and Fractional, how should I better convert Double to it?
05:49:37 <tabaqui1> Now I use "(`approxRational` 0.000001 >>> fromRational)
05:49:43 <tabaqui1> is there a better way?
05:50:54 <argent0> solonarv: that could work, nice idea thanks
05:51:05 <tabaqui1> oh, realFrac...
05:51:39 <boxscape> tabaqui that syntax works? or should it be (`approxRational` 0.000001) >>> fromRational?
05:51:41 <tabaqui1> allright, nevermind :)
05:52:16 <tabaqui1> boxscape: right, I put braces wrong
05:52:17 <boxscape> > (`approxRational` 0.000001 >>> fromRational)
05:52:19 <lambdabot>  error:
05:52:19 <lambdabot>      The operator ‘approxRational’ [infixl 9] of a section
05:52:19 <lambdabot>          must have lower precedence than that of the operand,
05:52:20 <boxscape> ah, okay
05:52:33 <tabaqui1> realToFrac is much better anyway :)
05:52:37 <boxscape> true
05:53:11 <kaol> Oof. I'm cleaning up some Haskell code that I wrote some 13 years ago. Looks like I had just found Data.Array.
06:12:11 <tabaqui1> oh, nice, you cannot reach hidden constructors with coerce, but you can with template-haskell
06:20:00 <L29Ah> https://github.com/l29ah/hatexmpp3/blob/master/Control/Concurrent/STM/TByteVector.hs r8 my stm byte vector
06:26:22 <dminuoso> tabaqui1: Or use safeCoerce = unsafeCoerce
06:26:32 <dminuoso> That will reach anything you want it to.
06:26:43 <tabaqui1> dminuoso: nope, nope, nope :)
06:27:01 <solonarv> well, if you *know* it's a newtype then it's safe ;)
06:27:47 <tabaqui1> yes, but no
06:27:51 <dminuoso> solonarv: Its enough that they are representationally equal :p
06:27:53 <merijn> solonarv: Not really
06:28:01 <merijn> solonarv: That's why we have coerce now
06:28:44 <solonarv> we have coerce because a) that makes the compiler check that it *really is* a newtype, and b) it allows libraries to say "nuh uh, don't touch my internals"
06:28:57 <solonarv> I guess unsafeCoerce'ing away newtypes is unsafe in the latter sense
06:30:36 <ph88> i'm using GHC 8.2.2  why doesn't this pragma activate?  #if ((__GLASGOW_HASKELL__ <= 801) || (__GLASGOW_HASKELL__ == 822))  
06:30:46 <dminuoso> merijn: That's not accurate. If you just unsafeCoerce between newtypes all is good.
06:30:59 <merijn> dminuoso: Not in the second sense of solonarv 
06:33:38 <solonarv> oh fun fact, you can also use unsafeCoerce to violate libraries like Data.Map (pretend that Data.Map.Internal doesn't exist)
06:35:06 <solonarv> you just define your own 'data MyMap k a = Bin {-# UNPACK #-} !Int !k a !(MyMap k a) !(MyMap k a) | Tip' and unsafeCoerce between that and the real 
06:35:10 <solonarv> Map
06:35:39 <solonarv> just be sure to exactly copy the constructors & fields
06:35:39 <ph88> how can i know the value of   __GLASGOW_HASKELL__  ?
06:35:59 <Cale> ph88: which version of GHC are you using?
06:36:04 <ph88> 8.2.2
06:36:15 <merijn> That's 802
06:36:18 <merijn> Not 822
06:36:24 <ph88> what's 8.0.1 then ?
06:36:27 <merijn> 801
06:36:36 <merijn> eh
06:36:38 <merijn> no
06:36:39 <merijn> 800
06:36:43 <ph88> oh ok
06:36:50 <merijn> 8.10 would be 810
06:37:02 <Cale> yeah, it leaves the least significant part of the version out
06:37:56 <ph88> thanks guys
06:40:15 <solonarv> L29Ah: are you looking for feedback, or...?
06:40:21 <L29Ah> yes
06:40:39 <L29Ah> it's the first time i try to write a STM primitive
06:43:22 <solonarv> I can't confidently say that it is bad, but your flagrant use of unsafeIOToSTM gives me the creeps
06:43:46 <L29Ah> i doubt you can write useful STM primitives w/o unsafeIOToSTM
06:44:12 <solonarv> well, TMVar is arguably a STM primitive and does not need unsafeIOToSTM.
06:44:39 <L29Ah> oh, ok
06:44:46 <solonarv> and it would actually have been very useful here - better than manually twiddling that isChanged flag
06:45:59 <L29Ah> yeah, thanks!
06:46:13 <solonarv> hm. with the interface you expose, I actually wonder if using a vector is even doing you any favors.
06:46:33 <solonarv> all you're doing is appending to one end, or mashing the entire contents together
06:46:45 <solonarv> you can do that with a list!
06:46:55 <L29Ah> list doesn't provide O(1) indexing
06:47:08 <solonarv> yes, and? I don't see any indexing happening
06:47:28 <L29Ah> https://github.com/l29ah/hatexmpp3/blob/master/Control/Concurrent/STM/TByteVector.hs#L66
06:47:36 <solonarv> ah wait, I misunderstood read
06:48:34 <solonarv> okay, then you can use a... well, it can just be a bytestring!
06:48:41 <solonarv> let me write up a gist real quick
06:49:18 <L29Ah> bytestring is stored in C heap, also cannot be grown
06:50:07 <solonarv> okay look, I don't know what your constraints are. maybe if you explained that we could help you find something suitable.
06:51:51 <L29Ah> i was looking for a data structure that would allow me to store a serialized appendable log efficiently that could be read with a blocking read(2) from multiple threads afterwards
06:51:54 <jophish> Hi all
06:53:09 <jophish> I'm trying to use singletons to reduce some code duplication, but I don't think that my use case really falls inside singletons's remit
06:53:18 <remexre> is there a name for `type Thingy f a b = (f a -> f b)` ?
06:53:24 * hackage language-protobuf 1.0.1 - Language definition and parser for Protocol Buffers.  https://hackage.haskell.org/package/language-protobuf-1.0.1 (AlejandroSerrano)
06:53:28 <remexre> especially for fixed f
06:53:30 <jophish> if anyone well-versed in that library would care to take a look I'd be grateful: https://gist.github.com/expipiplus1/be532d5db19728528429f7cdd73725d1
06:54:24 * hackage provenience 0.1.0.0 - Computations that automatically track data dependencies  https://hackage.haskell.org/package/provenience-0.1.0.0 (olf)
06:54:27 <jophish> basically I'd like a type family and the singleton of that family, but the type family uses another type family which has a hand written singleton already
06:54:32 <remexre> and I guess in particular, categories w/ constraint Category (Thingy f) for some fixed f
06:56:08 <dminuoso> remexre: Functor.
06:56:54 <remexre> oh, derp, yeah
06:57:23 <remexre> tho wait no
06:57:38 <remexre> my computations can't have arbitrary haskell functions fmapped on them
06:58:22 <solonarv> you don't even need Functor f. Your 'Thingy f' is always a Category.
06:59:18 <dminuoso> solonarv: And the reason it is, is because what are looking for is a functor on some sub-category of Hask.
07:00:09 <dminuoso> Ah but you are right, Category it is.
07:00:35 <dminuoso> But the matter whether a newtype for it exists, akin to Kleisli or Cokleisli
07:00:43 <dminuoso> Is interesting.
07:03:11 <remexre> Yeah, I was looking for a name like Kleisli so I could see if there were some useful proprties I was unaware of
07:04:52 <solonarv> well, it's a Profunctor when f is a Functor
07:05:10 <solonarv> ...actually, it probably has most of the instances that Star f and Costar f would
07:05:44 <remexre> okay, I'll read up on those, thanks
07:06:16 <Taneb> It's isomorphic to Biff (->) but that's not a great name
07:06:43 <solonarv> oh, Biff is whatthat's called?
07:06:49 <remexre> especially because my f isn't a functor...
07:07:11 <Taneb> newtype Biff p f g a b = Biff { runBiff :: p (f a) (g b) }
07:07:13 <Taneb> Not quite
07:07:22 <solonarv> yeah, I figured that's what Biff was
07:07:33 <solonarv> remexre: what *is* your f, anyway?
07:08:28 <remexre> I've got one for Identity, and one that, very approximately, is "types I can use in C"
07:08:44 <solonarv> ah.
07:13:23 <boxscape> type family equation imports work the same way as class instances, right? I.e. they get imported no matter what your import statement looks like
07:13:45 <boxscape> (that's specifically type family *equations*, not type families)
07:13:50 <solonarv> yes, that sounds correct to me
07:13:52 <boxscape> ok
07:15:57 <boxscape> are the type families in https://hackage.haskell.org/package/base-4.12.0.0/docs/src/GHC.TypeNats.html (say, Log2) compiler magic? They look open here but are in fact closed, and I they don't have instances defined in that module
07:16:42 <solonarv> compiler magic
07:16:47 <boxscape> ok, thanks
07:16:51 <solonarv> they have to be: Nat itself is compiler magic
07:17:30 <boxscape> ah, true, I was vaguely thinking of how you would make a definition of Log2 with Succs and Zeros but that doesn't make sense here
07:19:40 <solonarv> the thing is that Nat is not made of Succ and Zero (this is also what makes it so damn annoying to work with)
07:21:24 * hackage ghcide 0.1.0 - The core of an IDE  https://hackage.haskell.org/package/ghcide-0.1.0 (cocreature)
07:23:45 <fryguybob> L29Ah: It isn't safe to write to shared, non-transactional memory inside an unsafeIOToSTM.
07:26:11 <boxscape> solonarv right, that's what I meant with doesn't make sense here
07:27:18 <fryguybob> L29Ah: writeTVar ic True ... writeTVar ic False is equivalant (to any other transaction) to writeTVar ic False.
07:28:59 <L29Ah> fryguybob: the write i do in unsafeIOToSTM is not affecting any concurrent readers
07:29:49 <L29Ah> also, how do i lock it properly in case i actually write into shared memory?
07:30:14 <fryguybob> L29Ah: You do it in IO, not STM.
07:31:41 <fryguybob> L29Ah: You can build a transaction that describes the IO you want to do, and then after commit, run that IO action.
07:33:54 <L29Ah> do you suggest every reader consulting with the stored transaction, if any, and replaying it on top of the shared memory read?
07:34:24 * hackage language-avro 0.1.0.0 - Language definition and parser for AVRO files.  https://hackage.haskell.org/package/language-avro-0.1.0.0 (FlavioCorpa)
07:35:14 <Cale> L29Ah: I think fryguybob is just pointing out that IO actions are first class values, so you can return an IO action from an STM action, and run that resulting IO after.
07:35:39 <Cale> (but I don't know what the original context is)
07:36:14 <L29Ah> mutable array modification
07:36:30 <Cale> ah, I see the original post now
07:37:39 <Cale> hmm, I have no idea if this kind of thing is going to work
07:38:05 <Cale> You have to worry that those IO actions may be run arbitrarily many times
07:38:34 <Cale> (as transactions retry)
07:40:22 <Cale> Also, what happens in the face of someone doing an append followed by some other conditional that triggers a retry, and then that whole transaction is `orElse`d with some other transaction that succeeds instead?
07:40:45 <Cale> You have no opportunity to roll back any IO that you unsafely perform
07:41:47 <fryguybob> L29Ah: Does V.unsafeGrow always make a copy?
07:42:02 <L29Ah> dunno
07:42:27 <L29Ah> fryguybob: 
07:42:41 <dminuoso> fryguybob: https://hackage.haskell.org/package/vector-0.12.1.2/docs/src/Data.Vector.Generic.Mutable.Base.html#basicUnsafeGrow
07:42:53 <dminuoso> It seems to do a copy internally
07:43:26 <L29Ah> Cale: yes, you're right; i wonder if it's possible to make a never-retrying STM transaction, or i must drop the STM abstraction alltogether
07:43:57 <solonarv> you can have STM or you can have irreversible efficient in-place mutation.
07:44:23 <dminuoso> L29Ah: Well you can use optional to guard against retries.
07:44:33 <dminuoso> L29Ah: (Or more generally the Alternative interface)
07:44:52 <Cale> dminuoso: You can't stop someone from executing your STM action and then retrying though
07:45:04 <dminuoso> I suppose thats right
07:46:03 <fryguybob> You can newtype STM and not expose retry, but that won't stop failures and rollbacks.
07:47:27 <Cale> You'd also have to give up on exceptions
07:47:42 <Cale> Since an STM transaction which throws an exception is also supposed to have no effect whatsoever
07:48:31 <merijn> STM with no retry is just IO >.>
07:48:38 <Cale> (assuming the exception escapes, and apart from re-raising the exception in IO of course)
07:48:43 <fryguybob> L29Ah: The `isChanged`  as the code is, will never become True.  It isn't needed, however, as read cannot commit without `v` being observed unchanged.
07:49:22 <fryguybob> merijn: No :D.
07:49:33 <Cale> oh, yeah, that's the other thing, explicitly executing retry is not the only way that STM actions retry
07:50:16 <Cale> They also retry if one of the TVars they read on the way to finishing was committed to between the time they read from it and their completion
07:50:49 <Cale> (and is pointing at something different)
07:51:01 <fryguybob> L29Ah: If unsafeGrow is always a copy then you are never writing to shared non-transactional memory.
07:52:13 <L29Ah> actually i don't want it to be always copying, that defeats the point of using a vector, but that's another story
07:52:28 <fryguybob> L29Ah: Then this isn't a job for STM.
07:52:30 <L29Ah> probably i could store the virtual vector length in a TVar, but this won't save me from retries
07:52:49 <fryguybob> L29Ah: That is also problematic.
07:53:02 <solonarv> Vector is not very good for repeated appending.
07:53:18 <fryguybob> L29Ah: Transactions can see inconsistent state while running, unlike a critical section.
07:53:40 <L29Ah> i expected it to work like expanding the memory size twice when it runs out of it
07:54:02 <Cale> fryguybob: uhhh, what? You mean with unsafeIOToSTM?
07:54:33 <fryguybob> Cale: Consistency isn't checked until commit with GHC, so a running transaction can see a partial commit of another transaction.
07:54:50 <fryguybob> This ins't a problem until you start using unsafe.
07:54:55 <Cale> Well, yes, but if it does, then it won't be able to commit itself
07:54:58 <Cale> right
07:55:23 <Cale> Actually, wait, what do you mean by a partial commit?
07:55:37 <L29Ah> fryguybob: isn't that solved with a "retry plz, i'm writing" flag?
07:55:41 <Cale> It's not possible to see half a transaction log having been written
07:55:57 <Cale> because there's a global lock that's taken while transaction logs are played out
07:56:00 <fryguybob> Cale: If you have a vector and a size, appending updates both, but commiting could do the update in one order, while another transaction reads in another order.
07:56:41 <Cale> But yeah, if you're using unsafeIOToSTM, all bets are off, you get no transactionality for free
07:56:42 <dminuoso> 16:54:10 fryguybob | Cale: Consistency isn't checked until commit with GHC, so a running transaction can see a partial commit of another transaction.
07:56:46 <fryguybob> L29Ah: No, the `writeTVar ic True` only happens privately and no other transaction sees it.
07:56:52 <dminuoso> fryguybob: huh? Does that mean the transaction would fail?
07:57:08 <fryguybob> dminuoso: Yes, in the future.
07:57:14 <fryguybob> dminuoso: But only if it can get there!
07:57:37 <dminuoso> That's really interesting. Is that the regular mode of operation?
07:57:43 <Cale> Oh, no, you're right
07:58:12 <dminuoso> That is, STM does nothing to ensure consistency _inside_ a transaction?
07:58:14 <fryguybob> dminuoso: Yes.  STM in other languages don't take this approach.
07:58:17 <dminuoso> Interesting.
07:58:43 <Cale> Well, yeah, it's worth noting that we're talking about fine details of GHC's implementation that are subject to change
07:59:04 <Cale> The interface of STM tells you nothing about that, because it shouldn't matter
07:59:20 <dminuoso> I would have expected something closer to what postgresql does with multi version concurrency control.
07:59:29 <fryguybob> Yes.  I still need to fix the OOM bug though.
07:59:41 <Cale> If your transaction accidentally sees inconsistent state, it will ultimately fizzle out and have no effect other than wasting time
07:59:51 <fryguybob> dminuoso: STM's consistency is importantly stronger then MVCC.
08:00:12 <dminuoso> fryguybob: In what sense?
08:01:06 <Cale> Interestingly, you could initially see "inconsistent" state, but in the unlikely scenario that a later transaction commits and changes the values of TVars to be the ones that you read, your transaction will commit anyway :D
08:01:26 * fryguybob I have to run.
08:02:33 <Cale> (it's just that while your transaction log is finally being played out, all the reads have to match with what's actually there)
08:05:54 <boxscape> Is there any particular reason for Data.Version being in base? That seems like the sort of thing that belongs in a separate library
08:08:29 <jle`> boxscape: it's probably because it's the data type used for compilerVersion
08:08:35 <jle`> in System.Info
08:08:59 <jle`> > compilerVersion
08:09:01 <lambdabot>  Version {versionBranch = [8,6], versionTags = []}
08:09:22 <boxscape> Ah, I see
08:14:30 <dminuoso> fryguybob: Ah. I take it you are referring to write skews in MVCC.
08:25:55 <fryguybob> dminuoso: Yes
08:26:19 <merijn> boxscape: And it's tied into Cabal
08:27:47 <boxscape> merijn hm, but why would that be a reason for it being in base rather than being in the cabal package?
08:28:44 <merijn> boxscape: Time to visit version control and see when it was added :p
08:29:03 <boxscape> merijn incidentally cabal also has Distribution.Version which is very different
08:32:16 <boxscape> merijn but you're right it was for Cabal https://gitlab.haskell.org/ghc/ghc/commit/1336b22d8b5b93de02c057d0f653664dd915ea80
08:33:48 <remexre> augh, is there any way to use Control.Category* while stating "and all the objects in the category have constraint Foo obj")
08:34:14 <remexre> without redefining all the classes, that is
08:35:20 <solonarv> yes: you can pack that 'Foo obj' constraint into your category's constructor
08:35:52 <solonarv> for example: data OrdFunc a b where OrdFunc :: (Ord a, Ord b) => (a -> b) -> OrdFunc a b
08:36:11 <solonarv> but you can't write an Arrow instance for that, unfortunately
08:36:23 <remexre> oh, hm, okay
08:39:07 <solonarv> it's also kind of morally annoying because you end up packing this extra field into the constructor
08:39:10 <remexre> wait, how do I get the constraint in the instance methods though
08:39:16 <solonarv> pattern match!
08:39:49 <remexre> I don't think that works for e.g. Control.Category.Associative though, right?
08:39:53 <solonarv> case someOrdFunc :: OrdFunc a b of OrdFunc f -> <here you have (Ord a, Ord b) available>
08:40:09 <remexre> or even for id, I think
08:40:18 <solonarv> oh, you're right
08:40:26 <solonarv> yeah it doesn't work all that well
08:40:41 <remexre> rip, time to make Control.Category.WithConstraint.*
08:42:07 <solonarv> actually, constrained-categories seems to do exactly that
08:42:20 <remexre> oh, I'll give it a look
08:42:37 <solonarv> I literally just found it, so I have no idea how well it will work
08:43:24 <remexre> looks like I still have to make like Control.Category.Constrained.Cartesian etc, but looks like the "right" approach
08:44:20 <remexre> wait lol no it's just in the Control.Category.Constrained module
09:04:15 <dminuoso> Okay, so here's a challenge. Who finds a pattern in this? https://gist.github.com/dminuoso/9c10949714583fbdd87f3c8b215c806c
09:08:04 <remexre> something with "endianness" on 4-bit boundaries, maybe?
09:08:11 <remexre> just eyeballing, didn't actually work out math/bits
09:08:55 <heatsink> dminuoso: WIthin every group of 4 numbers, the value increases linearly
09:09:22 <remexre> er, 2-bits I guess I meant
09:09:31 <dminuoso> heatsink: Until it doesn't. The last group starting from swp49 can be ignored I think. 
09:09:43 <heatsink> That is linear also
09:09:47 <heatsink> The delta is 2 instead of 1
09:10:20 <dminuoso> heatsink: https://www.watchfront.co.uk/wp-content/uploads/2017/06/SN2410-2.jpg this is some extra resource
09:10:43 <dminuoso> The mapping in question is the external naming to the wiring on the internal hardware
09:11:29 <dminuoso> Based on the fact that swp49-56 are QSFP slots, I can live with them somehow differing in the naming. But the rest is so bizarre.
09:12:47 <int-e> > [60+x-(x-1)`div`4*8|x<-[1..32]]++[1..16]++[17,19..31]
09:12:50 <lambdabot>  [61,62,63,64,57,58,59,60,53,54,55,56,49,50,51,52,45,46,47,48,41,42,43,44,37,...
09:14:11 <heatsink> The connectors don't line up with the holes in the box
09:14:39 <dminuoso> heatsink: The holes are just LEDs. The numbers refer to the big rectangular slots.
09:14:59 <heatsink> I'm referring to the rectangular slots
09:15:31 <heatsink> Look at 23-24 for example
09:16:19 <heatsink> There are two sockets behind it, misaligned with the slot
09:21:09 <int-e> or maybe there's some sort of clear plastic cover that distorts things badly
09:23:49 <dminuoso> heatsink: Oh I see what you mean. That's just reflections from different angles.
09:23:57 <dminuoso> heatsink: The sockets are about 12-12cm deep or so
09:24:13 <dminuoso> And the connectors at at the end of that, with everything covered in stainless steel, it looks a bit weird.
09:25:13 <dminuoso> heatsink: https://img-en.fs.com/images/products_cache/550x550/11552.C.jpg this is a standard SFP you'd plug in there, if that helps.
09:25:32 <dminuoso> (It's flipped ontop as well)
09:26:03 <dminuoso> heatsink: Port 31/32 are straight, you're looking right at the center of it ther.e
09:26:17 <heatsink> oh, that explains it
09:26:54 * hackage fused-effects 1.0.0.1 - A fast, flexible, fused effect system.  https://hackage.haskell.org/package/fused-effects-1.0.0.1 (patrick_thomson)
09:46:17 <ezzieyguywuf> I'd like to write an `intersects` function that accepts two arbitrary "Geometric Shape" and determines if they intersect. Here is an outline for the approach I am considering: https://repl.it/@WolfgangSanyer/OldFrankWrapper.
09:46:40 <ezzieyguywuf> I think this method can work, however my spidey senses are tingling - is this type of approach sound Haskell/Functional Programming?
09:47:04 <ezzieyguywuf> specifically, I'm worried about using this `IsGeoShape` typeclass to later check for the type of a function argument
09:47:17 <ezzieyguywuf> seems like I may be working against the system rather than leveraging it appropriately
09:48:18 <ezzieyguywuf> also, I would be forced to exhaustively define every binary combination of `GeoShape` in the `intersects` function
09:52:08 <int-e> dminuoso: https://int-e.eu/~bf3/tmp/2410groups.jpg is what I make of it... basically the thing is organized in groups of 4, with each QSPF28 port counting as two slots... groups 0..7 start in the middle and spread to the right; groups 8..15 start in the middle again and spread to the left.
10:00:09 <ezzieyguywuf> hm, I guess the main alternative (at least that I can think of) is to write a distinct `pIntersectsL`, `lIntersectsL` etc... function. This has the added benefit of allowing for a type signature like `pIntersectsL :: Point -> Line -> Maybe Point` which returns the intersection point directly. The downside being more function names, but I guess the user should know at the time of the call what the 
10:00:15 <ezzieyguywuf> two geometric entities that are being compared are
10:00:18 <ezzieyguywuf> maybe I let my oop get a bit in the way there...
10:02:15 <ezzieyguywuf> (I wonder if `pXl`, `lXl` is too obscure for the function names...)
10:03:28 <wildtrees> why not something like: pointByLine , and lineByLine, if I am deciphering correctly, ezzieyguywuf 
10:03:55 <ezzieyguywuf> wildtrees: the 'X' is meant as a standin for "Intersects", though I guess "By" could be interpreted similarly
10:20:54 * hackage withdependencies 0.3.0 - Run computations that depend on one or more elements in a stream.  https://hackage.haskell.org/package/withdependencies-0.3.0 (SimonMarechal)
10:21:51 <solonarv> wildtrees: ezzieyguywuf if you are okay with having a bunch of XintersectsY functions, you can have them all under a single name using a typeclass
10:22:26 <solonarv> class Intersects a b r | a b -> r where intersect :: a -> b -> r
10:22:51 <solonarv> then you can have instances like: instance Intersects Line Line (Maybe Point) where intersect line1 line2 = ...
10:24:40 <ezzieyguywuf> solonarv: hrm... this `a b r | a b ` syntax is new to me.
10:25:03 <ezzieyguywuf> I had just decided that it does make more sense to make individual `XintersectsY` functions, so your comment intrigues me
10:26:27 <ezzieyguywuf> solonarv: in fact, I think I would mostly understand the syntax if it were `class Intersects a b r where intersect :: a -> b -> r`, but the `| a b -> r` does not make sense to me, can you explain it?
10:27:20 <geekosaur> functional dependency. "where the types a and b together imply the type of r", that is, for any given combination of a and b there can be only one type r
10:27:52 <solonarv> s/imply/determine/
10:29:14 <solonarv> so when you write 'intersect line1 line2' somewhere, the typechecker will immediately choose that 'Intersects Line Line (Maybe Point)' instance, and figure out: "ah, the type of that whole expression must be (Maybe Point)"
10:36:18 <ezzieyguywuf> oh neat!
10:36:24 * hackage git-annex 7.20200204 - manage files with git, without checking their contents into git  https://hackage.haskell.org/package/git-annex-7.20200204 (JoeyHess)
10:36:34 <ezzieyguywuf> I did not read about that in Learn You a Haskell For Great Good (or at least, if I did, I did not remember it)
10:36:49 <ezzieyguywuf> nor in Real World Haskell (though to be honest my eyes glazed over in most parts of this book :-P)
10:37:35 <solonarv> I'd expect it to be mentioned *somewhere* in RWH, but I haven't read that book
10:37:57 <ezzieyguywuf> solonarv: ah, but this functional dependency itself relies on Multi-parameter type classes, which are a language extension, not in the 'base' language, correct?
10:38:27 <ezzieyguywuf> I've been trying to avoid extensions mostly, as I don't want to accidentally start using some obscure feature that ends up hamstringing me in the long run
10:39:11 <wildtrees> multiparameter typeclasses are pretty common 
10:39:32 <solonarv> running away from language extensions is not a great long-term strategy :P
10:39:45 <solonarv> some are spooky and easy to overengineer yourself into a corner with
10:40:02 <solonarv> but others are entirely benign and can make your code a ton more readable
10:40:21 <ezzieyguywuf> solonarv: well, my plan was not to run away forever, but rather to understand the core language sufficiently in order to determine which extensions are actually useful/practical versus "spooky"
10:40:34 <geekosaur> MPTC's pretty practical
10:40:39 <solonarv> ah, that's fair enough
10:40:58 <ezzieyguywuf> i trust the opinion of the users in here, though, so perhaps I will start experimenting with multiparameter typeclasses, specifically in teh way that solonarv has outlined.
10:41:09 <solonarv> MPTC, and its... sibling? child? FunctionalDependencies
10:41:13 <wildtrees> I generally try to stay away from extensions that mention ambiguous or undecidable 
10:41:30 <wildtrees> solonarv, friend? :) 
10:41:32 <ezzieyguywuf> solonarv: right. it says so in the wiki, something like "it's easy to mess up with MPTC, you probably want to use functional dependencies too"
10:41:40 <solonarv> actually MPTCs can be kind of annoying without FDs, because the type inference is so weak
10:41:45 <solonarv> yup
10:41:54 <solonarv> wildtrees: sure :D
11:22:22 <dminuoso> int-e: The strange thing is, Id have expected an QSFP to count as 4 slots, based on how the wiring of QSFP works. 
11:28:00 <dminuoso> int-e: The pattern is as if they divided the ports into two halves, started counting from inwards to outwards in one direction, and then proceeded with the other half in the other direction.
11:28:23 <dminuoso> With the QSFP taking two internal ports (presumably), this makes some what sense.
11:33:40 <zincy> So I am parsing env variables for my server
11:33:58 <zincy> if they aren't available this doesnt show when I run the server
11:34:07 <zincy> but only when said variable is needed
11:34:13 <zincy> Is this due to laziness?
11:35:32 <dminuoso> zincy: How do you parse the environment variables?
11:37:22 <zincy> dminuoso: https://pastebin.com/6GteRUNZ
11:41:13 <dminuoso> zincy:  let Config {..} = either error id eEnv
11:41:44 <dminuoso> zincy: Pattern match instead.
11:43:14 <zincy> dminuoso: Is that not pattern matching?
11:43:25 <zincy> What do you mean?
11:43:45 <dminuoso> zincy: `case eEnv of Left err -> print err >> exitfailure; Right err -> ...`
11:44:22 <jle`> it is due to laziness, yeah
11:44:24 <dminuoso> zincy: Otherwise you leave boobytrapped thunks
11:45:05 <zincy> Ah great thanks
11:45:08 <jle`> basically _conv_authSecret isn't "computed" until it is needed
11:46:06 <jle`> Config{..} <- either (\_ -> print err >> exitFailure) pure eEnv
11:46:09 <dminuoso> zincy: A good rule of thumb is: do not use error for error handling.
11:46:17 <jle`> er, (\err -> ...)
11:46:22 <jle`> it sounds like that's what you were "trying" to do
11:46:26 <jle`> maybe
11:46:47 <jle`> exitFailure is an *IO action* that is an *IO exception*
11:46:54 * hackage front 0.0.0.3 - A reactive frontend web framework  https://hackage.haskell.org/package/front-0.0.0.3 (swamp_agr)
11:47:03 <jle`> so if you wanted to throw an IO Exception, you'd have to use an actual IO Exception, not error
11:47:42 <dminuoso> zincy: error is, generally, best reserved for code paths that are impossible to reach (say when you pattern match on a list you know that cant be empty). Otherwise lazyness will leak `error` in wrong places - ontop it's impossible to catch an error outside of IO.
11:47:54 * hackage sdl2 2.5.1.0 - Both high- and low-level bindings to the SDL library (version 2.0.6+).  https://hackage.haskell.org/package/sdl2-2.5.1.0 (OliverCharles)
11:50:23 <zincy> dminuoso: Right because error isn't forced to evaluated immediately it may do so later
11:52:15 <zincy> zincy: the reason I used it in the first place was because I wanted to halt the program if an env var wasn't provided
11:52:42 <zincy> but now I see that the problem with that is that error will only halt the program when evaluated
11:52:52 <jle`> yeah, 'error' isn't used to halt a program
11:52:59 <jle`> IO exceptions are what you would use to halt a program
11:53:24 <jle`> error may sometimes accidentally halt programs by coincidence...but it's not a good tool for program halting
12:05:34 <sakamoto_ryoma> I'm a bit of a haskell newbie, and I was wondering if there is a way to have a range of numbers so that the step is multiplication rather than addition. For example, if I want to map over the powers of two up to some n, I was hoping I could do something like map doSomething [0,2,8..n]
12:06:48 <jle`> it's not quite possible to do with list comprehensions directly ... you probably can't get around doing some math
12:06:57 <jle`> > takeWhile (< 100) (iterate (*2) 1)
12:06:59 <lambdabot>  [1,2,4,8,16,32,64]
12:06:59 <subleq> sakamoto_ryoma: like map (2^) [1..]
12:07:00 <subleq> ?
12:07:08 <merijn> sakamoto_ryoma: You can map the power and then the function?
12:07:20 <jle`> > takeWhile (< 100) (map (2^) [1..])
12:07:22 <merijn> > map (2^) [1..10]
12:07:22 <lambdabot>  [2,4,8,16,32,64]
12:07:24 <lambdabot>  [2,4,8,16,32,64,128,256,512,1024]
12:07:30 <dminuoso> `iterate (*2)` because iterate is such an underused function!
12:07:34 <dminuoso> jle` +1
12:09:00 <geekosaur> the syntax of ranges is fixed and converted to functions in Enum. hypothetically one might use a newtype with a distinct Enum instance, but I'm not sure what would break due to expectations about what "succ" (successor) does
12:09:14 <sakamoto_ryoma> sdidn't realize you could map a power function like map (2^)
12:09:24 <sakamoto_ryoma> also didn't know about the iterate function
12:09:32 <jle`> i think the general idea is sort of faulty, thinking that you can expect a compiler or something to 'analyze' a pattern and then figure out what you want from it
12:09:46 <jle`> just look at all the problems with Excel's drag-and-expand :)
12:10:01 <jle`> for example it's not really clear what [0,2,8..] should be
12:10:15 <merijn> sakamoto_ryoma: You can map any function, that's the point of map and functions ;)
12:10:17 <jle`> and that you want it to be some sort of geometric thing or linear thing or stuff
12:11:04 <jle`> for example the OEIS has 1593 sequences that begin with 0,2,8
12:11:06 <jle`> https://oeis.org/search?q=0%2C2%2C8&sort=&language=&go=Search
12:11:15 <jle`> er, that include 0,2,8, i suppose
12:12:12 <jle`> even as a human i wouldn't be able to guess how you want 0,2,8 to continue
12:12:22 <sakamoto_ryoma> merijn that's a good point. Weird that I didn't think of (^) as a function, even though it definitely is...
12:12:24 <jle`> so it's probably better to just do it as a map or something to construct what series you want :)
12:12:34 <jle`> er i mean, it's probably better to state what you want to do explicitly
12:12:34 <merijn> sakamoto_ryoma: You can even do this
12:12:40 <merijn> :t map (^) [1..5]
12:12:42 <lambdabot> (Integral b, Num a, Enum a) => [b -> a]
12:12:43 <jle`> instead of hoping it would be guessed
12:12:56 <jle`> sakamoto_ryoma: it's probably also better for readability not to rely on compilers 'guessing' what you mean
12:13:00 <merijn> sakamoto_ryoma: Which gets you back a list of functions (the partially applied (^))
12:13:07 <jle`> if you cna literally say "i want 2^n for n from [1..]", then that's easier for readability too
12:13:12 <jle`> even *if* the compiler oculd magically guess
12:13:35 <jle`> > [ negate y | n <- [1..], let y = 2^n ]
12:13:37 <lambdabot>  [-2,-4,-8,-16,-32,-64,-128,-256,-512,-1024,-2048,-4096,-8192,-16384,-32768,-...
12:13:46 <merijn> > map ($ 2) (map (^) [1..5]) -- f $ x calls 'f' with 'x' as argument, so we call every function in the list with '2'
12:13:48 <lambdabot>  [1,4,9,16,25]
12:14:15 <jle`> > [ f 2 | f <- map (^) [1..5] ]
12:14:16 <lambdabot>  [1,4,9,16,25]
12:15:41 <sakamoto_ryoma> jle` merijn agreed on readability - the compiler is already doing enough for me as it is
12:18:25 <sakamoto_ryoma> thanks for the help/info!
12:21:59 <jle`> np!
12:38:49 <solonarv> zincy: if you don't really care what sort of error message you're printing, you can also just write: Right Config{..} <- parseEnv
12:39:42 <solonarv> this desugars to: parseEnv >>= \x -> case x of Right Config{..} -> <rest of the do block>; _ -> throwIO (userError "blah")
13:00:41 <gues88> hey guys, im trying to use a do block and i get the error '    The last statement in a 'do' block must be an expression'
13:00:57 <gues88> i read its usually due to indentation but i have made absolute sure that's not the case
13:01:29 <koala_man> what's your code?
13:01:39 <gues88> main = do
13:01:51 <yushyin>    pure ()
13:01:56 <geekosaur> use a paste site, please
13:02:16 <maerwald> it's cooming
13:02:26 <gues88> https://pastebin.com/UYysc0HW
13:03:02 <geekosaur> that's not a complete expression
13:04:04 <gues88> so i put a print statement below it to print(bounds) and now it runs
13:04:07 <geekosaur> "do" is not some magical way to do I/O operations, it's a shorthand for use of various operators. that particular shorthand results in an incomplete expression
13:04:15 <koala_man> gues88: unsugared this is `main = getline >>= \bounds ->` where it makes more sense that something is missing
13:04:36 <gues88> okay yeah 
13:04:41 <geekosaur> you should probably learn how "do" works, or better yet use the operators directly so you understand what's really going on
13:05:55 <gues88> what does >>= mean
13:06:00 <gues88> is that like an input 
13:06:13 <gues88> getline inputs into bounds
13:07:54 <geekosaur> oversimpliying a bit, it performs an I/O operation ensuring that it happens in the correct order (normally Haskell will reorder expressions as part of optimization)
13:08:00 <MarcelineVQ> gues88: http://www.vex.net/~trebla/haskell/IO.xhtml
13:08:34 <geekosaur> that's a good guide, yes
13:09:45 <maerwald> quite some rile about the haskell wiki :>
13:15:41 <gues88> how do I check whether the enter key has been pressed in a getLine?
13:16:07 <gues88> do i have to use the ascii code?
13:17:31 <koala_man> gues88: getLine return a line without the linefeed, so if the user just hits enter you'll get an empty string
13:17:31 <geekosaur> getLine gets a line. it's already received and removed the line terminator
13:26:41 <dmj`> gues88: (=='\n') <$> getChar
13:27:13 <gues88> looks like it equals [] if your input is an enter
13:27:28 <gues88> im trying to make a loop that exits if it receives an enter input
13:28:47 <dmj`> gues88: fix $ \loop -> (=='\n') <$> getChar >>= \isEnter -> unless isEnter loop
13:30:42 <gues88> how do i use that dmj`
13:31:10 <gues88> Should I use a do block
13:32:15 <dmj`> gues88: put a 'main =' in front of it and import Control.Monad, Data.Char and Data.Function, should 'just work' ootb
13:33:51 <gues88> it doesn't loop back again for another input
13:38:08 <dmj`> gues88: oh, it will always be '\n' because you need to enter the input
13:39:15 <dmj`> gues88: https://gist.github.com/10cb2db47572d9f9fb4e205a4318a4df
13:41:36 <gues88> Is there an equivalent way of using recursion to do that?
13:42:47 <L29Ah> fix is recursion
13:44:32 <ph88> how can i resolve the same package name for local packages with stack ? https://bpaste.net/6QPQ
13:45:30 <dmj`> gues88: main = getLine >>= go where go [] = pure (); go xs = do { process xs; getLine >>= go; }
13:58:24 <gues88> I've gotten my input loop to work, now I'm trying to append the inputs to an array within the loop. if i have a<- getLine can i use something like a:[] within the do block continuously to get an array out with all of the inputs at the end?
13:59:24 * hackage util 0.1.17.1 - Utilities  https://hackage.haskell.org/package/util-0.1.17.1 (MatthewFarkasDyck)
14:01:30 <koala_man> gues88: Haskell doesn't really have loop in the sense that other languages do. How does your code look currently?
14:02:46 <gues88> dmj` provided the recursion https://gist.github.com/10cb2db47572d9f9fb4e205a4318a4df
14:03:16 <gues88> so if i want to append 'line' to an array and then when i get the enter key i want to print an array of the inputs
14:07:25 <dmj`> gues88: https://gist.github.com/34e28a657afa096f6f4503db1dad51f8
14:09:20 <gues88> damn that is so complicated to me
14:09:50 <gues88> what does MapM do?
14:10:26 <L29Ah> @type mapM_
14:10:27 <lambdabot> (Foldable t, Monad m) => (a -> m b) -> t a -> m ()
14:10:40 <L29Ah> the type tells it
14:10:45 <L29Ah> or, better
14:10:47 <L29Ah> @type mapM
14:10:49 <lambdabot> (Traversable t, Monad m) => (a -> m b) -> t a -> m (t b)
14:11:12 <L29Ah> also haddock
14:12:00 <dmj`> gues88: its trippy
14:12:29 <dmj`> gues88: so the loop is of type IO [String]
14:12:39 <dmj`> gues88: the String are accumulated inside the closure
14:14:56 <dmj`> gues88: once the base case is reached (the pure []) then all the xs are pulled out of the loop and returned
14:15:34 <dmj`> pure "a" : pure "b" : (loop : IO [String])
14:16:43 <dmj`> gues88: evaluation is driven by the mapM_ print
14:19:47 <gues88> dmj` this is some tricky shit, I will need to just write out the types and see whats happening
14:19:48 <dmj`> gues88: just use an explicit recursive function, will be easier
14:20:39 <gues88> basically what Im trying to do is take some inputs, run some transformation on the inputs then print the output. such a simple request is quite difficult
14:24:28 <dmj`> gues88: https://gist.github.com/65c97bb34552ca1ee7765ac4a15be061
14:24:41 <dmj`> gues88: check out `interact` its a function built exactly for that
14:28:16 <dmj`> gues88: if you had `main = interact (map toUpper)`
14:29:49 <dmj`> gues88: it would transform the input to uppercase
14:30:07 <dmj`> interact :: (String -> String) -> IO ()
14:30:12 <dmj`> :t interact
14:30:14 <lambdabot> (String -> String) -> IO ()
14:54:25 <patrl> any continuation pros in here tonight?
14:54:39 <patrl> i've been wondering about the join of the continuation monad
14:55:19 <patrl> it seems like, stripping away the runCont boilerplate, and treating Cont b a as (a -> b) -> b, join m = m . pure
14:56:05 <patrl> this strikes me as pretty interesting, since the monad instance comes for free once you have the applicative instance
14:56:11 <patrl> does anyone talk about this somewhere?
15:13:17 <srid-irccloud> I'm working on understanding constraints-extras, and specifying to try to a debug of problem of `ConstraintsFor` not being filled in properly. 
15:13:31 <srid-irccloud> Per https://github.com/obsidiansystems/constraints-extras/blob/develop/src/Data/Constraint/Extras/TH.hs#L83 - it should do it, yet even adding a `forall a.` to GADT constructor doesn't do it.
15:13:43 <srid-irccloud> The result is a `Could not deduce: c a arising from a use of ‘Dict’` but only on that constructor
15:15:27 <ph88> how can i run the test suite of cabal itself ?
15:15:47 <srid-irccloud> Aha, it is because I'm splicing in forM_. Not sure what that's problematic
15:16:18 <srid-irccloud> (my English is terrible now; manque de café)
15:16:54 * hackage haskell-lsp-types 0.20.0.0 - Haskell library for the Microsoft Language Server Protocol, data types  https://hackage.haskell.org/package/haskell-lsp-types-0.20.0.0 (AlanZimmerman)
15:17:54 * hackage haskell-lsp 0.20.0.0 - Haskell library for the Microsoft Language Server Protocol  https://hackage.haskell.org/package/haskell-lsp-0.20.0.0 (AlanZimmerman)
15:17:59 <zeta_0> hello there, i am a junior haskell developer and i am looking to work remotely(either through freelancing or a job-position), but i am having a hard time finding Haskell work, I've tried websites like functional jobs and functional works, but no one has responded yet, do you guys have any tips to help me find some work using Haskell? thanks in advance
15:18:45 <ph88> zeta_0, maybe send some pull requests to some projects
15:20:19 <zeta_0> I am self taught(no degree), but I know some other self taught haskell devs that work in the tech industry, I guess I haven't figured out how to get my foot in the door
15:20:27 <maerwald> zeta_0: remote is unlikely for juniors
15:21:13 <dsal> zeta_0: many great programmers are self-taught with a bunch of demonstrated passion in the form of OSS programs and libraries to show what they do.
15:23:19 <zeta_0> why do all the haskell job positions say senior developer, no one wants to hire junior haskell developers, i can't get that experience until i get my foot in the door?
15:23:45 <maerwald> remote is too risky for juniors, that's why you can't expect much there without a huge OSS footprint
15:24:04 <dsal> zeta_0: because there are a lot of senior developers who can fill those jobs.
15:24:17 <maerwald> dsal: not that much :>
15:24:55 <zeta_0> ph88: ya, i could do some pull requests
15:25:17 <dsal> maerwald: I'm sure I'm in a weird bubble of sorts...
15:26:05 <ph88> zeta_0, anything you like to work on ?
15:26:09 <maerwald> probably, because hiring haskell seniors isn't easy either
15:26:48 <dsal> zeta_0: Do you have any projects to demonstrate what you do?  I'm not looking for a job, but if I were, I'd have things to point people to just because for me, learning stuff often comes in the form of doing things I need done.
15:27:18 <dsal> maerwald: Yeah, it's a weird trap.  I could probably get a haskell job doing stuff I enjoy more, but I'd probably be paid less.  Tradeoffs are for engineers...
15:27:25 <zeta_0> maerwald: on my resume i have all the open source projects that i am currently working on, personal projects, also I just started contributing to the GHC compiler, so will that help me find/land some haskell work?
15:27:54 <dsal> zeta_0: possibly.  Depends on the nature of all those contributions.  :)
15:29:07 <maerwald> zeta_0: as I said, if you're trying remote, you're limiting your options. A lot
15:29:46 <Guest_44> hello there! just started the haskell platform installer on OS X 😊
15:29:50 <dsal> Constraints reduce search space.   Haskell && remote && junior     etc...
15:29:58 <maerwald> Guest_44: which one
15:31:16 <Guest_44> curling right now ghc version8.6, up to now nothing wrong I was just greeting
15:31:28 <maerwald> curling?
15:31:41 <dsal> Installation via bicep
15:31:54 <maerwald> lol
15:32:15 <maerwald> let's see whether the shell detection works this time...
15:32:21 <zeta_0> well,i live in a remote area, so remote work is my only option, should i just focus on finding work for other languages like python, javascript, etc, that are more in demand?
15:32:39 <dsal> OS X is getting super weird.  I just installed Catalina and now I just want to run NetBSD again...
15:32:51 <dsal> zeta_0: You could move somewhere local.
15:33:05 <dsal> Every constraint you remove from your search increases the possibilities.
15:34:18 <zeta_0> do you guys know any good freelancing websites for haskell? upwork does not seem to have that many haskell contracts?
15:34:24 <dsal> A couple weeks ago, I was on a tiny island in the Pacific.  I can't keep my job and live there, but maybe I can get another job and live there.  If it paid .10 what I get paid now, I'd be fairly well off...
15:34:24 <Guest_44> curl get-ghcup.haskell,org
15:34:51 <maerwald> Guest_44: call, make sure to read the pink instructions it spits out
15:34:57 <maerwald> *cool
15:35:10 <Guest_44> about PATH?
15:35:14 <maerwald> that too
15:36:16 <dsal> zeta_0: At some point, programming is programming.  Don't expect to get paid for being on a honeymoon with new, exciting technology.  If nobody wants to give you money to do the exact thing you want to do, do the things they do want to give you money for.
15:36:19 <dsal> Or don't.  Lots of options.
15:36:36 <zeta_0> have any of you worked in industry using haskell, what is it like?
15:36:54 <maerwald> It's like living on mars with nanobots
15:36:55 <dibblego> it's great when my code is compiling
15:37:12 <zeta_0> dsal: ok, I understand, this is very frustrating but I will keep trying
15:37:24 * hackage lsp-test 0.10.1.0 - Functional test framework for LSP servers.  https://hackage.haskell.org/package/lsp-test-0.10.1.0 (luke_)
15:37:26 <dsal> It's like programming.  Right now, I'm trying to decide whether my ideas are going to be amazing or stupid.  Should I proceed or abort?
15:37:44 <maerwald> always abort, unless you have clarity
15:37:57 <maerwald> I think that way software in general would suck less (and yes, maybe less random "progress")
15:38:02 <dsal> Just need a little more complication...
15:38:32 <dsal> It's clearer before I start typing.  Perhaps I need a scribe.
15:39:50 <zeta_0> I guess I would describe my haskell skills as intermediate, i am currently doing a lot of web development with Yesod, and i understand it pretty well
15:40:41 <maerwald> web dev is a safe bet
15:40:46 <dsal> Intermediate is a little high for me.
15:41:37 <dsal> I've done a variety of things... various parsers, runtimes, concurrency, protocol implementations, applications...  I'm pretty comfortable with a lot of things, but I know about a lot of things I'm not good at.
15:44:42 <zeta_0> well i'll continue contributing to ghc and yesod development, then i guess i could call the companies using haskell, that i have sent applications to, and ask if there is any junior developer positions open
15:45:34 <zeta_0> is the demand for haskell programmers increasing, or is it still a nich language?
15:47:01 <dsal> Haskell programmers program in haskell where haskell is acceptable and the best language to solve a problem.
15:47:29 <dsal> It's still bizarre to me that people use niche stuff like node.js, but it happened.  Niche is where the heart is, I guess.
15:59:32 <zeta_0> well thanks for the tips, guys, time to get back to coding
16:13:18 <phaazon_> I was thinking about something
16:13:31 <phaazon_> anyone here using both Rust and Haskell? what for?
16:14:33 <hpc> i did a comparison of sdl in rust and haskell, rust was a lot more pleasant
16:14:57 <phaazon_> what do you mean?
16:15:05 <hpc> oddly not for IO-related reasons, its case syntax is a bit easier to deal with for matching gamepad input stuff
16:15:05 <phaazon_> did you compared in terms of performance too?
16:15:10 <hpc> just for ease of use
16:15:12 <phaazon_>  * did you compare in terms of performance too?
16:15:26 <phaazon_> curious
16:15:29 <hpc> performance is all tied up in sdl itself
16:16:38 <hpc> i would like to see a typesafe ffi layer between rust and haskell
16:17:08 <hpc> where like, instead of writing C code and then having to tell haskell "this takes int, int, int*, long", it just knows
16:17:48 <phaazon_> yeah I see what you mean
16:18:40 <maerwald> phaazon_: naive implementations in rust should generally perform better, imo. And reasoning about performance is also much easier
16:18:44 <hpc> if it's ownership-safe too, that would blow my mind
16:19:12 <hpc> rust is very haskell-like though, as you're writing it
16:19:13 <phaazon_> yeah, I’m just trying to brainstorm with myself about both languages
16:19:20 <hpc> it feels like you're in this great big IO do-block
16:19:23 <phaazon_> I’ve been using Haskell for ~9 years
16:19:29 <phaazon_> and Rust for several years as well
16:19:33 <phaazon_> I migrated my graphics code from Haskell to Rust
16:19:41 <phaazon_> and now I look back and just miss Haskell :)))
16:19:41 <hpc> it even has things like to return a value you just make that value the last line of the block
16:19:44 <hpc> no "return" or whatever
16:19:52 <maerwald> low-level is just more pleasant in rust
16:20:07 <phaazon_> I’m just, you know
16:20:16 <phaazon_> unhappy with the current situation of having two languages
16:20:21 <maerwald> but I feel like once I've written 3k LOC even, I don't want to refactor a lot anymore, types or not
16:20:28 <phaazon_> like, I love Haskell and I love Rust, but if Haskell could do the low-level stuff
16:20:34 <phaazon_> I’d definitely use Haskell solely
16:20:45 <maerwald> well, our stdlib isn't good enough for that either
16:21:17 <maerwald> but in terms of refactoring, rust is definitely harder
16:22:33 <maerwald> I usually ended up with runtime borrow checking anyway (RefCell)
16:22:54 <maerwald> Unsafe code too
16:23:09 <maerwald> Things are more carefully "assembled" I feel
16:23:28 <phaazon_> yeah, the common `Arc<RefCell<T>>`
16:23:29 <phaazon_> :D
16:23:41 <maerwald> Right, and that works well... unless you refactor
16:29:06 <sim590> I'm trying to remember about Data.Vector. I did try to initiate myself to it multiple times, but for some reason I always gave up. I can't remember if STVector is really mutable. I believe that I've had a conversation about how IO is the only way to have true mutable data structure. Is that the case? I'm a bit confused and results on google are not great.
16:32:10 <dsal> sim590: What do you mean?  I've mutated vectors in ST.
16:32:50 <Guest_44> is there a better way to write [show x | x <- [0..9]] ++ [show x | x <- ['A'..'F']]
16:33:00 <Guest_44> as a range for hexadecimal values
16:33:56 <sim590> dsal: is it really mutable happenning in the background?
16:34:40 <dsal> sim590: Well, it's significantly faster and it's called "mutable" so I'd assume that's what's happening.
16:34:44 <dsal> Why the doubt?
16:36:29 <MarcelineVQ> Guest_44: depends what you're gonna use them for, your version treats every item as a String and has extra ' chars in it that it's unknown if you need. I'd be inclined to write ['0'..'9'] ++ ['A'..'F'] for example which has neither but idk what your use-case is too
16:36:31 <jle`> sim590: yes, it's implemented as an explicitly mutable algorithm
16:36:33 <sm[m]> phaazon[m]: come on back, you know you want to
16:36:47 <jle`> *mutation-based
16:36:58 <phaazon_> for sure I want to
16:37:30 <sim590> It's just that I believe that I heard or thought at some point in the past weeks that IO was the only way to do true mutability since it is sort of excluded from "normal" haskell rules such as "every data structure is immutable" and such.
16:37:38 <dsal> > flip showHex "" <$> [0..15] -- Guest_44 
16:37:41 <lambdabot>  ["0","1","2","3","4","5","6","7","8","9","a","b","c","d","e","f"]
16:37:48 <sm[m]> the cardano project is using both haskell and rust (for different things). Building comparable non-trivial apps (cardano blockchain node) in each, in parallel. It's a pretty interesting real world case
16:37:56 <dsal> sim590: ST is IO
16:38:07 <sim590> dsal: right, OK. Then it makes sense.
16:38:10 <sm[m]> s/for different things/separately/
16:38:18 <jle`> sim590: it's a little more subtle, I think
16:38:25 <jle`> sim590: ST is a way of *describing* a mutation-based algorithm
16:38:26 <sim590> But why would one use ST over IO?
16:38:39 <jle`> sim590: and 'runST' "executes" that mutation-based algorithm ... by using mutation
16:38:47 <dsal> ST doesn't let you do a lot of IO things.
16:38:58 <Guest_44> I've done this now:map f l = if l == [] then [] else [f $head l] ++ map f (tail l)hex = map show [0..9] ++ map show ['A'..'F']
16:39:01 <jle`> sim590: ST really only allows mutations that don't affect the outside world
16:39:08 <dsal> sim590: ST is IO that doesn't leak side effects.
16:39:11 <jle`> so things like, allocating a variable and then immediately reading it
16:39:23 <jle`> also you can't do any input-output
16:39:26 <jle`> so you can't do any I/O
16:39:35 <jle`> you can only describe mutation-based algorithms
16:39:35 <sim590> OK, got it. So, it's a controlled IO.
16:39:47 <jle`> i don't really think i would put it that way, since it doesn't do any I/O
16:40:16 <jle`> but you can kind of think of it that way i guess
16:40:26 <jle`> sim590: the IO monad is for doing I/O, input-output
16:40:43 <dsal> I think of it as just the bits of IO that do the mutation thing, but without being able to leak side effects.  So you can't prove that it did anything impure.
16:40:44 <jle`> it describes operations involving the external world, that you interact with using I/O facilities
16:40:46 <sim590> Yeah, I understand what you mean. It's not the proper term and that could be contradictory.
16:40:57 <jle`> so semantically it describes I/O actions
16:41:09 <jle`> the ST monad is for describing mutation-based algorithms
16:41:15 <jle`> so, unrelated to I/O
16:41:22 <jle`> if your goal is to express a mutation-based algorithm, you would use ST
16:41:32 <jle`> if your goal is to express I/O with external world, you would use IO
16:41:38 <jle`> so they aren't really comparable I think, in terms of their semantics
16:41:46 <sim590> Therefore, if the purpose of my function is solely to manage a mutable vector and don't do any IO, then ST is the way to go for consistency's sake.
16:41:59 <jle`> consistency with what?
16:42:10 <dsal> "mutable vector" is an implementation detail your callers can't care about
16:42:31 <jle`> i think it would be like, using Integer vs. Double
16:42:46 <jle`> you would use Integer for things like quantities, loop indices, etc.
16:42:55 <jle`> you would use Double for things like, continuous measurements
16:43:05 <jle`> but there isn't really a situation where you would really meaningfully be able to replace one with the other
16:43:05 <sim590> jle`: By consistency, I mean logically consistent. Like for example, you should work with Integer and not Double if your computations are always resulting in integers.
16:43:16 <sim590> Even though you can do your work with Double.
16:43:32 <sim590> lol. Yeah, we had the same idea I gues.
16:43:41 <jle`> ah, like consistent with how the type is supposed to be used?
16:43:47 <sim590> jle`: Yes.
16:44:33 <phaazon_> wait
16:44:39 <phaazon_> where is `Lift` defined again?
16:44:46 <jle`> phaazon_: template-haskell i think?
16:45:04 <jle`> which is sort of weird because it's a separate package from base
16:45:05 <phaazon_> ah?
16:45:14 <jle`> https://hackage.haskell.org/package/template-haskell/docs/Language-Haskell-TH-Syntax.html#t:Lift
16:45:38 <jle`> or do you mean the one from tranformers
16:45:52 <jle`> https://hackage.haskell.org/package/transformers/docs/Control-Applicative-Lift.html
16:46:09 <phaazon_> I don’t really know
16:46:10 <jle`> that lifts any Functor to give it a free Pointed instance
16:46:14 <phaazon_> I saw we can `deriving Lift`
16:46:21 <phaazon_> I wondered what it was
16:46:26 <jle`> ah it's probably Lift the typeclass, then, the one from template-haskell
16:46:28 <phaazon_> I guess it’s the one from `transformers` then
16:46:33 <phaazon_> ah
16:46:35 <jle`> oh wait
16:46:38 <phaazon_> `Functor` + `pure` then
16:46:50 <jle`> Functor + pure is Pointed
16:47:00 <jle`> and Lift is the "free Pointed", like how Free is the free Monad
16:47:12 <phaazon_> yeah
16:47:34 <jle`> if you see deriving Lift they probably mean Lift the typeclass, like in template-haskell?
16:47:50 <jle`> the typeclass that lets you embed a value of that type in Haskell AST
16:48:22 <phaazon_> wait, I’ll show you where I read that
16:48:45 <phaazon_> https://gitlab.haskell.org/ghc/ghc/wikis/commentary/compiler/deriving-strategies#the-deriving-strategy-resolution-algorithm jle` 
16:49:06 <sim590> But I guess, I don't need to specify whether I use ST or IO from the point of view of my function return type. I could simply use the generic type `PrimMonad m => m (MVector (PrimState m) a)`, right? With a substituting to Integer if I'm working with integers.
16:49:07 <phaazon_> in “The stock classes are:”
16:49:16 <phaazon_> `-XDeriveLift`
16:49:42 <jle`> sim590: right, yeah :) that would be like Num a => ...
16:49:50 <phaazon_> wait
16:49:53 <jle`> phaazon_: ah. that is probably the template-haskell Lift then
16:49:57 <phaazon_> I’ll just read the RFC of `-XDeriveLift` :)
16:50:08 <jle`> that would be pretty neat, and something a lot of people have wanted for a while i think ...
16:50:19 <phaazon_> https://typeclasses.com/ghc/derive-lift
16:50:39 <phaazon_> I need to send kudos to Mary and Chris for typeclasses.com
16:50:40 <phaazon_> damn it’s great :)
16:50:44 <phaazon_> I haven’t read it because, well, I already know Haskell
16:50:45 <jle`> Lift is pretty trivial to derive, you just replace `Foo x y` to be App (App (Constr 'Foo) (Lift x)) (Lift y)
16:50:50 <phaazon_> but I’ve been missing a few things lately
16:50:51 <phaazon_> so I’m updating
16:51:08 <jle`> yeah, sometimes i wish i had started learning haskell now. there's so much nice beginner material that wasn't available when i was learning D:
16:51:20 <jle`> s/Lift/lift
16:51:29 <MarcelineVQ> There's a lot more to learn now though...
16:51:36 <phaazon_> hm
16:51:48 <phaazon_> so `Lift` just lifts a type into the TH world for usage there
16:51:49 <phaazon_> interesting
16:51:54 <phaazon_> I can see use cases :D
16:51:55 <jle`> lift (Foo x y) = App (App (Constr 'Foo) (lift x)) (lift y)
16:52:05 <jle`> phaazon_: yeah. although i like to think of it as lifting it into Haskell AST
16:52:22 <jle`> so lift a literal value `Foo x y` into the haskell AST "literal" you would use to express it in source code
16:52:27 <phaazon_> well
16:52:30 <phaazon_> yeah
16:52:31 <phaazon_> it looks a lot like Rust’s procedural macro
16:52:41 <phaazon_> (what you can do with the `syn` + `quote` crate in a proc-macro, I guess)
16:53:06 <jle`> it's just too bad that haskell ast is so messy to work with for some reason
16:53:07 <phaazon_> okay, so, I think I got everything updated
16:53:21 <phaazon_> I just needed to read about `Lift` and deriving strategies
16:53:23 <phaazon_> cool :)
16:53:23 <jle`> i guess because there's just so much in the language
16:53:50 <phaazon_> yep
16:54:58 <phaazon_> oh yeah `BlockArguments`
16:55:04 <phaazon_> I remember seeing that one a few months ago :)
17:14:41 <tam1138> good evening
17:15:42 <tam1138> the cabal docs discuss v1 and v2 commands, and say that the former will go away and the latter will become default.  my understanding is that the latter became default as of version 3.0.0 of cabal, but i can't find anything to confirm that in the cabal docs (i might be missing it)
17:15:47 <tam1138> what's the story?
17:16:49 <glguy> V2 are default in version 3 , yes
17:17:24 <tam1138> thank you
17:39:42 <guest88> Hey guys, how would I loop through a string (e.g. "Turtles") and store the manipulated string in a list? for instance, if I want to change the case on each letter sequentially to get the list ["TUrtles", "TURtles", "TURTles", "TURTLes", "TURTLEs", "TURTLES"]
17:40:03 <sim590> I'm trying to use `minimumBy` on some list of integers where in the lambda, I'm reading some vector values. I'm having trouble to write that since the type of the lambda is (a -> a -> Ordering) and not (a -> a -> m Ordering) where m is the monad in which I'm running my vector.
17:40:10 <guest88> using each prvious string as the input for the next
17:40:33 <sim590> For instance, here's the code I have right now: https://paste.debian.net/1129205/
17:41:10 <sim590> I'm trying to recover the values ca and cb from the vector.
17:43:47 <sim590> Can it be done? Or should I implement my own minimumBy function adjusted to my needs?
17:48:25 <mniip> guest88, you could use unfoldr
17:50:02 <mniip> unfoldr $ \xs -> case span isUpper xs of { (us, l:ls) -> Just $ us ++ (toUpper l : ls); _ -> Nothing }
17:51:04 <mniip> sim590, you could map MV.read over the vector first, then minimumBy
17:51:11 <sim590> I guess that I need to use minIndexBy?
17:51:44 <mniip> not really, why?
17:51:44 <sim590> mniip: hmmmm. I'm trying to digest the information.
17:52:08 <mniip> also there's always the zipping trick
17:52:24 <sim590> mniip: well, what I want is the index in my vector for which the value is minimal.
17:52:52 <mniip> I thought you wanted the value of ca/cb
17:52:59 <mniip> do you want both that and the index?
17:53:04 <sim590> I guess, what I want is even simply Data.Vector.minIndex.
17:53:09 <mniip> > minimum . flip zip [0..] $ "hello"
17:53:11 <lambdabot>  ('e',1)
17:53:14 <sim590> mniip: I want those values only for comparison.
17:54:26 <mniip> minIndex would be the way to go I guess
17:55:03 <sim590> Actually, no. I need to compare indexes only found in "ns" plain list. Therefore, I cannot iterate on the vector.
17:55:18 <sim590> So, I have to use one of your magic tricks.
17:59:39 <guest88> mniip how do i use that?
17:59:48 <guest88> do i give it a string
17:59:55 <mniip> sure
18:00:01 <mniip> @src unfoldr
18:00:02 <lambdabot> unfoldr f b = case f b of
18:00:02 <lambdabot>     Just (a, b') -> a : unfoldr f b'
18:00:02 <lambdabot>     Nothing      -> []
18:00:13 <guest88> unfoldr $ \xs -> case span isUpper xs of { (us, l:ls) -> Just $ us ++ (toUpper l : ls); _ -> Nothing } "anything"
18:00:15 <guest88> didnt work
18:00:23 <mniip> see the $
18:00:34 <mniip> that takes precedence
18:00:56 <guest88> how do i use the $
18:01:01 <guest88> Not sure how it works 
18:02:07 <mniip> guest88, it applies the thing on the left to everything on the right
18:02:14 <mniip> it's just a way to avoid parentheses
18:04:24 <sim590> mniip: I don't understand your trick of mapping MV.read over the vector.
18:04:55 <mniip> sim590, well, suppose you want the maximal value 'f' takes over some vector v
18:05:11 <mniip> you're doing `f $ maximumBy (\x y -> compare (f x) (f y) v`
18:05:14 <mniip> why not:
18:05:20 <mniip> `maximum $ map f v`
18:06:03 <mniip> ...this is actually the free theorem of maximumBy!
18:08:00 <sim590> Just to make everything clear, I'm iterating over a [Int], let's call it `ns`, with maximumBy and for each pair of Int's `(a, b)`, I would like to compare `MV.read a v` with `MV.read b v` where v is not ns, but some other vector of values.
18:08:34 <sim590> ns is the list of valid indices that I can use.
18:09:23 <sim590> mniip: did you understand it like that? Because, I'm not sure that we're doing the same thing. Or perhaps, I'm just not quick enough to connect the dots.
18:09:45 <mniip> f = flip MP.read v
18:10:28 <sim590> But that is gonna return some `m Integer` which I cannot use with `compare`, right?
18:10:58 <sim590> where `m` is an instance of PrimMonad or something.
18:12:34 <sim590> I guess that what I need is `maximum $ map f ns` or something along those lines.
18:12:52 <sim590> notice I put ns and not v there. Those that work?
18:16:16 <topos> mniip more like mrnip
18:17:08 <mniip> sim590, if your reading function is effectful then you're going to need a version of minimum that can handle effects anyway
18:18:00 <mniip> not sure if that exists though, you might need to invoke sequenceA/traverse/mapM/...
18:18:49 <mniip> topos, funny you show up in this discussion ;)
18:19:44 <topos> hmm?
18:19:53 <mniip> @free minimumBy :: (a -> a -> Ordering) -> [a] -> a
18:19:53 <lambdabot> (forall x. g x = h (f x) . f) => f . minimumBy g = minimumBy h . $map f
18:20:28 <topos> ahh, minimums for free
18:21:21 <mniip> unfortunately I don't have much "free" time until sunday :(
18:21:42 <nshepperd2> get your minimums for nothing and your theorems for free
18:30:26 <topos> mniip no worries. I'm on vacation still
18:30:37 <topos> I've just been cruising in topology land and it's been nice
18:30:50 <topos> Also, optimizing `base64`  for different architectures!
18:30:54 * hackage base64 0.4.1 - Fast RFC 4648-compliant Base64 encoding  https://hackage.haskell.org/package/base64-0.4.1 (topos)
18:31:30 <topos> see? aww yiss. ^ this version features loops optimized for both word32 and word64-based architectures, which got ridiculously fast
18:32:17 * mniip opens xmmintrin.h
18:32:36 <sim590> mniip: I finally figured something: costs <- mapM (MV.read scosts) ns, then let (_, v) = minimum $ zip costs ns.
18:32:59 <mniip> sure that works
18:33:42 <sim590> mniip: You wouldn't have done it like that? I don't see how to do it otherwise.
18:34:22 <mniip> no it's good
18:34:52 <mniip> maybe I would've tried to use (&&& id) on the map instead of zip
18:39:55 <sim590> mniip: I'll have a look at &&&. I don't know that.
18:41:30 <sim590> mniip: Are you talking about Control.Arrow.&&& ? I don't get what it does.
18:41:48 <sim590> Anyway, I was just curious, but I guess I'll discover that someday. Thanks for helping.
18:41:53 <topos> :t (&&&)
18:41:55 <lambdabot> Arrow a => a b c -> a b c' -> a b (c, c')
18:42:14 <mniip> ah it's just the cartesian strength of the arrow
18:42:32 <mniip> % :t (&&&) @(->)
18:42:32 <yahb> mniip: (b -> c) -> (b -> c') -> b -> (c, c')
18:42:33 <topos> think `(b -> c) -> (b -> c') -> b -> (c, c')` by way of `\f g -> \b -> (f b, g b)`
18:42:38 <topos> yeah
18:43:34 <topos> :t \f g b -> (f b, g b)
18:43:36 <lambdabot> (t -> a) -> (t -> b) -> t -> (a, b)
18:45:17 <sim590> hmmmmmmmmm. I don't get anything of all that ¯\_(ツ)_/¯
18:47:11 <topos> I've seen a lot of people use it (i guess, idiomatically?) to pair data with some function applied
18:47:12 <topos> for example
18:47:15 <topos> > fmap (id &&& (+1)) $ [1,2,3]
18:47:18 <lambdabot>  [(1,2),(2,3),(3,4)]
18:48:17 <topos> unnecessary dollar. yolo
18:49:22 <mniip> yea you wanna save up your dollars for now
18:49:33 <topos> dollarydoos don't come cheap
18:49:37 <topos> they're at least $1
18:49:59 <mniip> 1 dollarydoo is 0.67 dollars
18:50:54 <topos> dibblego pls confirm
18:51:04 <hpc> it's a canadian dollar
18:51:41 <dibblego> topos: affirm, 1 dollarydoo is 0.67 dollars
18:51:58 <mniip> there he dibblegoes
18:52:06 <topos> it is settled
18:55:11 <ezzieyguywuf> I'd like for this instance to return either a list of one or two - http://dpaste.com/2J2EB7B. Can anyone help me with that? I'm a bit stumped
18:56:15 <ezzieyguywuf> here it is in context: https://gitlab.com/ezzieyguywuf/mycad/-/blob/haskell/src_haskell/HaskellCAD/src/Topology.hs#L50
18:56:51 <mniip> ezzieyguywuf, you could use `oneOf`, or manually bind an arbitrary Bool
18:58:01 <dibblego> you could bind Maybe
18:58:18 <mniip> or that
18:58:23 <ezzieyguywuf> can either of you provide an example of how this would work?
18:58:40 <ezzieyguywuf> I think I'm struggling b/c I don't fully undersand the whole Monad thing and the `do` block
18:58:53 <mniip> oneOf [gen1, gen2] where gen1 = {- generate a list of length 1 -}; gen2 = {- generate a list of length 2 -}
18:59:47 <dibblego> do v1 <- arbitrary; v2 <- arbitrary; return (Edge (maybe [v1] (\v2' -> [v1, v2']) v2)) -- something like that
19:00:45 <mniip> yuck
19:00:57 <dibblego> agree, tidy it up afterward
19:01:21 <ezzieyguywuf> hmm
19:01:26 <dibblego> data ListOfOneOrTwo a = ListOfOne a | ListOfTwo a a -- I'd probably do that tbh
19:01:40 <mniip> choose (1, 2) >>= (`replicateM` arbitrary)
19:01:44 <mniip> :P
19:02:48 <ezzieyguywuf> mniip: I tried `do v1 <- arbitrary; v2 <- arbitrary; vs <- choose ([v1], [v1,v2])...` but got an error on my use of choose
19:02:57 <mniip> ezzieyguywuf, that's not what I said to do
19:03:02 <ezzieyguywuf> mniip: I know.
19:03:07 <ezzieyguywuf> I'm just saying ....I'm confused, lol
19:03:24 <ezzieyguywuf> why can I use choose as you've outlined but not as I tried?
19:03:31 <ezzieyguywuf> also, where in the `do` block would I put your line?
19:03:54 <mniip> because [v1] :: [Vertex] or whatever
19:04:05 <mniip> oh err
19:04:10 <mniip> you're using choose and not oneOf
19:04:24 <mniip> choose expects an instance of Random and takes a range from which to randomize
19:04:43 <mniip> so like, random (3, 10) would be random numbers between 3 and 10
19:04:45 <mniip> err
19:04:48 <mniip> choose (3, 10)
19:04:54 <ezzieyguywuf> ah
19:05:03 <ezzieyguywuf> do you mean `oneof`, lowercase "o"?
19:05:14 <mniip> I guess I am
19:05:24 <mniip> oneof takes a list of generators
19:06:47 <ezzieyguywuf> ah that's right - but I could not figure out how to make a list of generators. What is a generator?! lol
19:07:45 <mniip> it's the things you've been writing
19:08:15 <ezzieyguywuf> hah I figured, but I still only have a cursory understanding of what I'm doing. I know what a "typeclass" is, and I know what "an instance of a typeclass is"
19:08:54 <mniip> `Gen a` is a generator producing values of type `a`
19:08:58 <ezzieyguywuf> but when the documentation for `oneof` asks for "a list of generators", I'm left wondering...do I need to write an instance of `Arbitrary` for...something that I can put in a list to pass to `oneof`?
19:09:07 <mniip> `Gen` is a monad hence you can use do-blocks to construct generators
19:09:32 <mniip> Arbitrary is a typeclass whose method is arbitrary :: Gen a, a generator
19:10:40 <ezzieyguywuf> hm, so do I write two functions, `oneV :: Gen a` and `twoV :: Gen a` where each one returns either a singleton or pair of Vertex?
19:11:00 <ezzieyguywuf> and then pass that to `oneOf` in my `instance Arbitrary Edge...`?
19:11:46 <mniip> yes
19:11:51 <dsal> ezzieyguywuf: There's also choose and vectorOf
19:11:54 <mniip> (they are not functions)
19:12:05 <ezzieyguywuf> or I guess I could do a lambda? `oneof [\_ -> Gen [Vertex], \_ -> Gen [Vertex, Vertex]`
19:12:26 <ezzieyguywuf> but then the actual `Vertex` is not being randomly generated, like it was when I did `v1 <- arbitrary` etc.
19:12:32 <ezzieyguywuf> ay yi yi...
19:13:04 <ezzieyguywuf> maybe, `oneof [[arbitrary], [arbitrary, arbitrary]]` and let the type system figure it out?
19:13:32 <dsal> arbitrary = choose (1,2) <<= \n -> Edge <$> vectorOf n arbitrary
19:14:11 <dsal> Heh, I typed something dumb, but something like that.
19:14:26 <amalloy> oneof [[arbitrary], [arbitrary, arbitrary]] has the wrong type
19:14:33 <ezzieyguywuf> amalloy: it does
19:14:53 <ezzieyguywuf> as does `oneof [[arbitrary :: Vertex], [arbitrary :: Vertex, arbitrary :: Vertex]]
19:15:18 <amalloy> :t oneof
19:15:20 <lambdabot> [Gen a] -> Gen a
19:15:28 <mniip> you're treating `arbitrary` as an effectful expression, which it is not
19:16:05 <ezzieyguywuf> well, the :t of arbitrary is `Arbitrary a => Gen a`
19:16:10 <ezzieyguywuf> so I thought I could use it as such...
19:16:32 <amalloy> :t [[arbitrary], [arbitrary, arbitrary]]
19:16:34 <lambdabot> Arbitrary a => [[Gen a]]
19:16:39 <mniip> ^
19:16:43 <amalloy> you can see that [[Gen a]] is not [Gen a]
19:16:55 <mniip> [[Gen a]] is not [Gen [a]]
19:17:12 <mniip> or should I say, could not match type ... with ...
19:17:13 <mniip> ;)
19:17:14 <crestfallen> sorry folks wondering what foldl (or foldr) does here:
19:17:30 <crestfallen> > foldl (+) 0 (2,3)
19:17:32 <lambdabot>  3
19:17:42 <crestfallen> no clue what it does there
19:17:53 <mniip> > toList (1,2,3)
19:17:55 <lambdabot>  error:
19:17:55 <lambdabot>      Ambiguous occurrence ‘toList’
19:17:55 <lambdabot>      It could refer to either ‘F.toList’,
19:17:57 <Clint> what do you expect it to do?
19:18:01 <mniip> > Data.Foldable.toList (1,2,3)
19:18:03 <lambdabot>  error:
19:18:03 <lambdabot>      • Could not deduce (Foldable ((,,) Integer Integer))
19:18:03 <lambdabot>          arising from a use of ‘F.toList’
19:18:08 <mniip> > Data.Foldable.toList (1,2)
19:18:10 <lambdabot>  [2]
19:18:17 <mniip> this is what's going on
19:18:20 <crestfallen> > foldl (+) 0 [2,3]
19:18:22 <lambdabot>  5
19:18:27 <crestfallen> that I understand
19:18:34 <ezzieyguywuf> dsal: I think your use of `choose` and `vectorOf` makes the most sense to me so far. I can't understand how to fit that into the `do` block in my `arbitrary` definition though
19:18:35 <dsal> ezzieyguywuf: this does work, though:    instance Arbitrary Edge where arbitrary = choose (1,2) >>= \n -> L <$> vectorOf n arbitrary
19:18:46 <dsal> Why do you need a do block?
19:18:52 <mniip> there's also quite a misnormer:
19:18:53 <ezzieyguywuf> dsal: I don't know! lol
19:18:57 <mniip> > length (3, 5)
19:18:59 <lambdabot>  1
19:19:22 <dsal> @do choose (1,2) >>= \n -> L <$> vectorOf n arbitrary
19:19:23 <lambdabot> do { n <- choose (1, 2); L <$> vectorOf n arbitrary}
19:19:37 <crestfallen> mniip so that takes the seed 0 and adds it as an element of the list [0,2,3] ?
19:19:49 <mniip> no
19:20:14 <mniip> I think it's easier if you understand how toList works for (a, b) first
19:20:20 <ezzieyguywuf> ah, I see, dsal has used `>>=` instead of the `do` block syntax "sugar"
19:20:21 <mniip> then foldr/foldl will follow naturally
19:20:27 <ezzieyguywuf> I really should spend some time understanding this
19:20:41 <crestfallen> I thought I understood l/r but only with lists I guess
19:20:43 <dsal> do syntax confuses people.
19:20:44 <Clint> > foldl (+) 0 ("billions and billions", 3)
19:20:46 <lambdabot>  3
19:21:21 <crestfallen> Clint, what's it doing in plain language?
19:21:36 <Clint> crestfallen: it's folding
19:21:38 <Clint> 0 + 3 = 3
19:21:54 <mniip> foldl f z (x, y) = f z y
19:22:16 <mniip> notice a peculiar lack of x
19:22:30 <ezzieyguywuf> dsal: what is `L` in the code you provided?
19:22:35 <crestfallen> yeah sorry what happens to the x? 
19:22:41 <mniip> nothing can happen to x
19:22:52 <mniip> it's impossible because of parametricity
19:22:57 <dsal> ezzieyguywuf: oh sorry, Edge.  I named it L in GHCI
19:23:24 <mniip> again consider the simpler  toList :: (a, b) -> [b]
19:23:28 <mniip> toList (x, y) = [y]
19:25:26 <ezzieyguywuf> dsal: ah hah! ok that works!
19:25:51 <crestfallen> If "billions and billions" is not allowed because of the (+) signature I understand, but not in the case of (2,3)
19:26:11 <crestfallen> I mean the type that (+) takes
19:26:26 <mniip> the implementation of foldl is not allowed to change behavior based on the type of x
19:26:43 <mniip> (x = 2 :: Int  versus  x = "billions and billions" :: String)
19:27:13 <crestfallen> but what is the purpose of foldl over a tuple then?
19:28:04 <mniip> there isn't any
19:28:22 <crestfallen> In a list I understand, because your just accumulating a value in the seed.
19:28:32 <mniip> you shouldn't foldl over tuples
19:28:35 <mniip> not explicitly at least
19:28:56 <mniip> it's just that it's sometimes useful for (a,) to be Foldable as it can appear nested in other structures
19:29:31 <crestfallen> mniip sorry I don't know what you're getting at. It's a video I'm reviewing, it's included as a quick aside.
19:29:54 <crestfallen> useful for (a,) to be Foldable?
19:30:11 <mniip> occasionally
19:30:50 <mniip> it makes perfect sense if you understand the types of everything involved
19:31:01 <mniip> but from an outside perspective everything about this instance might seem weird
19:31:08 <mniip> the most odd one perhaps being
19:31:10 <mniip> > length (3, 5)
19:31:13 <lambdabot>  1
19:32:06 <Cale> The Traversable instance has come in handy at least once or twice.
19:32:46 <Cale> It's generally best to think of pairs as being like containers for their second element which have a label on them which is the first element.
19:32:57 <mniip> yeah
19:33:02 <mniip> that's how their functor instance works too
19:33:35 <crestfallen> copy that, like key/value
19:33:42 <Cale> yeah
19:34:06 <crestfallen> thanks everyone that's great
19:34:17 <Cale> One of the things we have in reflex-dom is  performRequestsAsync :: (..., Traversable f) => Event t (f (XhrRequest a)) -> m (Event t (f XhrResponse))
19:34:21 <crestfallen> I thought it was an error in the video :)
19:35:19 <Cale> Basically, that type means you give it a thing which can occur at certain moments with an f (XhrRequest a) and it'll give you back a thing which can occur at some times with (f XhrResponse) values
19:35:39 <Cale> It can be handy to choose f to be a pair type if you want to know which response goes with which request
19:36:04 <Cale> You can put any extra data in the first part of the pair, and this will hand it back to you with the corresponding response.
19:36:26 <Cale> but at the same time, this can be used to make multiple requests at once, for example
19:36:35 <crestfallen> so haskell essentially defaults to the value and not the key, in a tuple, in the case of folds
19:36:57 <Cale> Yeah, if you think about it, it *has* to be the second component of the pair
19:37:11 <Cale> Because there's no way to write the instance to work on the first component
19:37:17 <crestfallen> that almost sounds like State, the "extra data" part
19:37:36 <Cale> Yeah, one of the annoying things about the definition of StateT is they got it backwards :P
19:37:44 <Cale> :t StateT
19:37:45 <lambdabot> (s -> m (a, s)) -> StateT s m a
19:38:01 <Cale> The s is in the second part, but it would have been much better to make that s -> m (s, a)
19:38:14 <Cale> Or s -> (s,a) in the case of plain State
19:38:41 <dsal> A lot of these kinds of things are easier to understand if you try to do it yourself.
19:38:42 <Cale> Well, it's a small difference in practice, but still kind of annoying :)
19:39:09 <dsal> State is actually another example of that.  I didn't understand the s and a in theory, but it was pretty obvious in practice.
19:39:10 <crestfallen> I actually thought that..why is it not in the first position?
19:39:24 <mniip> eh
19:40:01 <Cale> At the time the mtl package was first written, we didn't have all those instances for pairs
19:40:26 <Cale> In fact, I don't think Traversable and friends even existed yet.
19:41:18 <crestfallen> really appreciate it. I had to drop haskell for a while after a horrendous winter..
19:42:34 <crestfallen> winter break
19:44:32 <crestfallen> also I read something about monads that I'm curious about. that pure computations are separated by certain combinators. but which combinators are they? all I know is id, const and flip I believe
19:45:13 <crestfallen> just reading that gave me something to chew on anyway
19:48:01 <crestfallen> so I guess all combinators have no free variables, as in the above mentioned
19:48:41 <Cale> That's an extra-technical definition that people often don't mean when they use the word combinator informally
19:48:59 <crestfallen> hmm
19:49:09 <Cale> More generally, a "combinator" is just a function which is used to combine things (usually things which represent actions or computations of some sort)
19:50:47 <crestfallen> are you saying " comb. have no free variables" is the extra-technical part?
19:50:51 <Cale> yeah
19:51:55 <Cale> Actually, that one is usually "supercombinator"
19:52:21 <crestfallen> sorry which one?
19:52:52 <Cale> a lambda expression S is a supercombinator of arity n if it has no free variables and is of the form λx1.λx2...λxn.E (with n ≥ 0, so that lambdas are not required) such that E itself is not a lambda abstraction and any lambda abstraction in E is again a supercombinator
19:53:17 <crestfallen> holy smokes
19:53:28 <Cale> (but if you remove the arity restriction, that just means no free variables)
19:54:42 <Cale> oh, I guess not
19:54:58 <Cale> That does impose a restriction on where in E you're allowed to use x1,...,xn
19:55:43 <Cale> Anyway, be careful about the word "combinator", different authors use it to mean slightly different things
19:56:02 <Cale> But generally it has the sense of a function which is being used to combine things of some sort to produce other things of that sort.
19:57:04 <Cale> and there's a long history of "combinator libraries" whose philosophy is to provide the user with a bunch of extremely basic building blocks, and then some means of composing them together into more interesting things
19:57:12 <dmj`> like parsec 
19:57:16 <Cale> yeah
19:57:29 <Cale> You start out with parsers which parse single characters and stuff like that
19:57:49 <Cale> and then ways of combining parsers e.g. concatenation, alternation and so on
19:58:07 <crestfallen> also like SKI calculus?
19:58:09 <dmj`> @unmtl StateT s [] a
19:58:09 <lambdabot> s -> [] (a, s)
19:59:47 <crestfallen> see post re: SKI ^ .. but so really lambda calculus is implied in the monad, with the added element of "Kleisli" composition?
20:00:10 <dmj`> that's a basic type for a parser, which is just a function really, and can be composed like other functions using (.)
20:00:28 <crestfallen> dmj`, what is?
20:00:37 <Cale> crestfallen: Oh, well, maybe you're thinking of the case of the Applicative instance for (->) e?
20:00:53 <dmj`> type Parser s a = s -> [(a,s)]
20:00:58 <Cale> Applicative gives you exactly K and S there
20:01:07 <Cale> If we look at the types:
20:01:13 <Cale> pure :: a -> f a
20:01:20 <Cale> when f t = e -> t
20:01:31 <Cale> this becomes pure :: a -> (e -> a)
20:01:39 <Cale> which is exactly the type of K
20:01:56 <Cale> (<*>) :: f (a -> b) -> f a -> f b
20:02:09 <Cale> and this specialises to:
20:02:23 <Cale> (<*>) :: (e -> (a -> b)) -> (e -> a) -> (e -> b)
20:02:28 <Cale> which is exactly the type of S
20:03:57 <Cale> (oddly, this was for me a major part of what convinced me Applicative was something worth paying attention to)
20:04:20 <Cale> For some people, I'm sure that goes the other way around :)
20:04:43 <crestfallen> yikes ok thanks, so can you pass around the added data in Kleisli composition if you're working with lambda notation (whatever that added data is to the layman)
20:05:04 <Cale> Well, we could look at what Kleisli composition would be in this case if you like
20:05:10 <Cale> :t (<=<)
20:05:12 <lambdabot> Monad m => (b -> m c) -> (a -> m b) -> a -> m c
20:05:18 <Cale> So when m t = e -> t
20:05:46 <Cale> That becomes (b -> e -> c) -> (a -> e -> b) -> a -> e -> c
20:06:30 <Cale> and we could work through what function that needs to be based on the type
20:06:36 <Cale> If we're trying to define
20:06:48 <Cale> (f <=< g) x e :: c
20:07:01 <Cale> We have:
20:07:03 <Cale> f :: b -> e -> c
20:07:08 <Cale> g :: a -> e -> b
20:07:13 <Cale> x :: a
20:07:15 <Cale> e :: e
20:07:42 <Cale> We know we want to end up with something of type c, and the only way to get that would be to apply f
20:07:49 <Cale> So we try:
20:08:11 <Cale> (f <=< g) x e = f (... :: b) (... :: e)
20:08:20 <Cale> Now we need something of type b and something of type e
20:08:33 <helloworld123> hi isovector1
20:08:37 <Cale> We have a thing of type e, and no way of getting any other, so that bit is completely obvious
20:08:42 <Cale> (f <=< g) x e = f (... :: b) e
20:08:56 <Cale> and then to get something of type b, we must apply the function g
20:09:08 <Cale> (f <=< g) x e = f (g (... :: a) (... :: e)) e
20:09:35 <Cale> and here again, we have something of type a and something of type e (and they're the only things we could possibly have of those types)
20:09:42 <Cale> (f <=< g) x e = f (g x e) e
20:09:45 <Cale> and we're done
20:10:03 <Cale> So that's what Kleisli composition has to be in this instance
20:10:37 <Cale> Usually it won't be quite so uniquely defined as this, but often this kind of reasoning about types can reduce the search space and make it easier to think about how to write functions
20:11:44 <crestfallen> so for every type, Kleisli elements are defined in ghc. does the average programmer need to know the extent of it? I mean, I'd like to know, i.e. follow your instruction above
20:12:13 <Cale> er
20:12:26 <Cale> I'm not sure I understand that question, or the first part of that sentence
20:12:50 <Cale> What I specifically described there is how Kleisli composition works out in the case of the Monad instance for (->) e
20:13:09 <alc> what is Nat?
20:13:13 <Cale> People don't use that thing a whole lot, but it's good to have this skill of being able to work out what it must be from the type
20:13:20 <Cale> alc: Usually Natural numbers
20:13:57 <Cale> i.e. every natural number is zero or the successor of another natural number
20:15:59 <d34df00d> Alright, I have more funny questions.
20:16:13 <jackdk> there is a script called haskell-ci that generates .travis.yml files. I am trying to refresh the CI of an older repository which appears to have been generated from make_travis_yml_2.hs and has tests for stack. Does anyone know what the successor to that script might be?
20:16:35 <d34df00d> Let's say I have a type class, a few "base" instances of that class for some types, and a combining instance for something like a type-level list or (nested) pair.
20:16:56 <d34df00d> And I want to run an instance according to some run-time data (like a user's choice).
20:17:29 <d34df00d> Type erasure and existentials to the rescue! But the resulting code is hellishly slow, since the compiler cannot inline everything now.
20:17:53 <d34df00d> I think I'll just link to my SO question for more specific code examples: https://stackoverflow.com/questions/60065469/using-existentials-to-lift-values-to-types-without-hurting-performance
20:17:59 <crestfallen> ok, I'm going to work on this. something is beginning to dawn on me Cale . Let me ask, ultimately, does Kleisli composition stay "pure" as well as keeping the pure functions separate? 
20:18:00 <d34df00d> I'd be reposting code from there otherwise anyway.
20:18:16 <d34df00d> So, basically, what other options do I have, if any?
20:19:35 <Cale> crestfallen: Well, most instances of Monad are nothing special that you couldn't write with ordinary pure functions.
20:20:17 <crestfallen> like if you're keeping IO actions separate from computations, are these "combinators" also pure in themselves? if that makes sense..
20:20:25 <Cale> crestfallen: IO would be a challenge, because it's hard to come up with a representation of all the low-level things that a computer can do, but in principle, it could be an ordinary data type as well
20:20:37 <Cale> The things you're manipulating are descriptions of what action should be taken
20:20:44 <Cale> and you're computing pure functions of those
20:21:20 <Cale> (Lemme just look at d34df00d's question for a sec)
20:21:25 <d34df00d> Cale: thanks!
20:21:32 <crestfallen> excellent
20:23:44 <d34df00d> On a somewhat related question, if I have `foo (MkExist (_ :: proxy s)) = ...`, can I specialize it for some values of `s`?
20:23:46 <Cale> d34df00d: Ah, that's a tough problem, I suppose you would need to ensure that the compiler produces a bunch of specialised versions of all the combinations, and then actually selects them for use at runtime in the appropriate circumstances.
20:24:13 <d34df00d> Cale: exactly! And I don't really expect the compiler to do this for me fully automatically, since the combinations count (expressed this way) is infinite.
20:24:17 <d34df00d> But how can I help it?
20:24:47 <Cale> One easy thing would just be to branch on user input somehow and then use fully-monomorphic types
20:25:11 <d34df00d> No way I'm writing O(2^N) branches myself.
20:25:15 <Cale> right
20:25:30 <Cale> TH could do that for you, to be sure
20:26:23 <Cale> but yeah, not too pretty
20:26:27 <Cale> hmm
20:26:28 <d34df00d> Yeah, I'm actually thinking of this approach as less of a joke.
20:26:35 <d34df00d> But it feels like, you now, cheating, sorta.
20:26:37 <crestfallen> thanks kindly Cale I'm going to get to the bottom of this entire chat. take it easy. thanks mniip Clint 
20:26:48 <Cale> crestfallen: cool
20:26:49 <d34df00d> I wonder if there's a better way.
20:27:13 <Cale> crestfallen: I was going to maybe show you how to write a terminal IO monad as a completely ordinary data type if you think that'd help
20:27:35 <Cale> (like, if we just restrict ourselves to getLine and putStrLn or something)
20:27:56 <d34df00d> ...don't forget to write it in Idris too and prove that the monadic laws hold...
20:28:36 <crestfallen> If I could catch you later I'm rusty and a bit saturated right now. thanks so much Cale
20:29:21 <Cale> d34df00d: haha, would be easy enough :)
20:29:39 <ezzieyguywuf> is it possible to unpack a value in a lambda? I've tried `map (\(MyType data) -> doSomethingWith data) mytypes` but recieve a syntax error
20:30:00 <Cale> (though I haven't done proofs in Idris much, one of the first things I did in Coq was all the mtl monad transformers with proofs)
20:30:27 <Cale> ezzieyguywuf: That is valid syntax on the surface
20:30:34 <MarcelineVQ> ezzieyguywuf: best to include the error with questions like that
20:30:58 <ezzieyguywuf> hah, I should have read the error. "Not in scope" I think I can figure this out
20:31:24 * ezzieyguywuf face palms
20:37:50 <sim590> I'm trying to call my code which uses MVector. I don't get the sense of the error message... Here's the code: https://paste.debian.net/1129220/, and I get this error message https://paste.debian.net/1129221/.
20:38:16 <sim590> I'm trying to run this in GHCi invoking `runST $ dijkstra d1`.
20:38:20 <sim590> Isn't it right?
20:38:45 <sim590> With let d1 = dataDijkstra data1.
20:40:03 <Axman6> which line is line 122?
20:40:34 <mniip> sim590, you're asking to bring a mutable vector outside of a runST block
20:40:40 <mniip> that's not referentially safe
20:41:13 <sim590> Axman6: I think that this is referring to some file prepared by GHCi?
20:41:16 <mniip> the result of runST should not mention any mutable variables and/or vectors
20:41:37 <dsal> sim590: Imagine that nothing outside of ST can tell whether there was mutation or not.
20:44:09 <sim590> I'm not sure what to make of that information... :/ I don't understand the signature of runST. For example, I don't understand the whole story about "forall" and everything in (forall s. ST s a). I'm not sure what I should do. When I look at this page for instance https://gist.github.com/chrisdone/d22f41b683e333380c76dbc9c60ed72d, I see that runST seems to be called on some vector, just like what
20:44:10 <sim590> I'm doing. I don't get it ..
20:44:39 <Axman6> sim590: ok, so anything of type MVector s cannot escape ther runST call, otherwise the whole point of ST is invalid. yyou have a few choices, you could freeze the MVector so that you just have a Vector, or you can consume the MVector within the same runST call. Or you can use IO
20:44:53 <mniip> the "forall" is a bit of a detail that can go over your head now
20:45:31 <mniip> like I said, you cannot return anything mutable from runST
20:45:32 <Cale> sim590: The idea with being able to explicitly put foralls in your types like that is that, for instance, you can write functions who *demand* that their argument be polymorphic
20:45:40 <Axman6> sim590: notice that Chris' code calls V.freeze on the vector it creates - this gives back _Vector a_ not _MVector s a_
20:45:53 <Cale> sim590: Consider this simple function:
20:46:09 <Cale> f rev = (rev [1,2,3], rev "Hello")
20:46:42 <sim590> so, I should return a Vector instead?
20:46:50 <sim590> In dijkstra?
20:46:50 <Cale> Normally, this would be a type error. But surely, there are functions which would make that right hand side typecheck -- e.g. reverse, as I alluded to by the choice of variable name
20:47:22 <Cale> So, we could give f a type like (forall a. [a] -> [a]) -> ([Integer], String)
20:47:47 <Cale> and this would insist that the argument to f be polymorphic so that f would be free to use it at more than one type
20:48:16 <Axman6> sim590: well that's one solution, but it depends what you want to do with that vector if that's the right thing or not
20:48:59 <sim590> Cale: OK. I get it. I'm not sure if I'm going to use that very soon. I didn't read about that in my wikibook. May be I'm not there yet.
20:49:34 <sim590> Axman6: I just wanted to make dijkstra function independant of IO or ST, so that one could call this function wither with IO or ST.
20:49:38 <Cale> sim590: It's an extension
20:49:38 <Axman6> it's quite an advanced feature really
20:49:44 <Cale> (Specifically, RankNTypes)
20:50:00 <Axman6> then you probably just want top call freeze on tyour vector and return that
20:51:18 <Cale> ST uses this feature to make it impossible for mutable things that were constructed in one usage of runST to be used from inside a different occurrence of runST.
20:51:24 * hackage line-bot-sdk 0.5.2 - Haskell SDK for LINE Messaging API  https://hackage.haskell.org/package/line-bot-sdk-0.5.2 (moleike)
20:51:51 <Cale> You'll notice that all the STRefs and such have this mysterious 's' parameter, which if you like, you can think of as the type of the heap that's being used for that computation.
20:52:03 <Cale> runST gets to choose s
20:52:37 <Cale> and so if you somehow smuggle out an STRef from one runST, and try to read it from another one, there will be no guarantee that the 's' is the same
20:52:43 <Cale> and the compiler will stop yo
20:52:44 <Cale> u
20:54:43 <Cale> This case is a little funny, because the implementation never actually chooses a type for s, it just actually allocates memory and mutates things -- the 's' is purely a hack in the type system, but it is a reliable way to make sure that you don't break the guarantees about Haskell functions.
20:55:50 <jle`> i do the same thing for my backprop library -- i never use the 's', but i just use it to guarantee that you never let a "variable" escape a 'run ...'
20:58:07 <jackdk> sim590: the paper that introduces ST is https://www.microsoft.com/en-us/research/wp-content/uploads/1994/06/lazy-functional-state-threads.pdf
20:58:57 <Welkin> my favorite paper :D
21:00:04 <jackdk> There is also the ref-fd library that lets you abstract over IORef, TVar and STRef https://hackage.haskell.org/package/ref-fd-0.4.0.2/docs/Control-Monad-Ref.html#t:MonadRef
21:00:20 <sim590> OK. I've added a test function `test1` in my file https://paste.debian.net/1129222/. All types check OK, but I get a callstack error.
21:00:34 <sim590> Oh. I get index out of range.
21:00:51 <sim590> not sure why.
21:01:54 <sim590> Anyway, so I guess that's how I should use the Vector then.
21:04:31 <dmj`> @def digitsToInt = foldl' (\acc (power,x) -> x * (10 ^ power) + acc) 0 . zip [0..] . reverse
21:04:32 <lambdabot>  Defined.
21:04:35 <dmj`> :t digitsToInt
21:04:37 <lambdabot> Num c => [c] -> c
21:04:40 <guest88> what is a class constraint? can some homie give a man an easy explanation? cause its wack
21:04:42 <dmj`> > digitsToInt [1,2,3]
21:04:44 <lambdabot>  123
21:05:09 <guest88> ive read it in 4 different places
21:05:13 <guest88> still dont get it
21:05:20 <dmj`> guest88: A class constraint be like when you want to constrain a class on another class, like Eq a => Ord a
21:06:37 <guest88> dmj` but what does that mean
21:06:56 <guest88> i understand when you check the type of == you get (==) :: (Eq a) => a -> a -> Bool  
21:07:20 <guest88> but does that mean the type of the first input needs to be the same type as second input?
21:07:32 <dsal> There's only one type variable.
21:07:40 <guest88> why don't you just write a-> a-> Bool
21:07:55 <guest88> hows it gonna break
21:08:11 <mniip> dmj`, umm, what's wrong with fold' (\x y -> x * 10 + y) 0
21:08:24 <dmj`> guest88: It means for all a that are constrained on Ord, they must also be constrained on Eq as well. 
21:08:29 <Welkin> hi dmj` 
21:09:07 <dmj`> > fold' (\x y -> x * 10 + y) 0 [3,2,1]
21:09:09 <lambdabot>  error:
21:09:10 <lambdabot>      • Variable not in scope:
21:09:10 <lambdabot>          fold'
21:09:20 <dmj`> > foldl' (\x y -> x * 10 + y) 0 [3,2,1]
21:09:23 <lambdabot>  321
21:10:16 <dsal> guest88: You can try to write (a -> a -> Bool)
21:10:23 <dmj`> mniip: I like yours better
21:10:30 <dmj`> Welkin: hi
21:15:10 <guest88> (Foldable t, Eq a) => a -> t a -> Bool
21:15:53 <guest88> (Eq a) => a -> [a] -> Bool
21:15:59 <guest88> whats the diff?
21:16:24 <jle`> guest88: the first one you can use on things that aren't lists
21:16:30 <jle`> the second one you can only use on lists
21:16:42 <guest88> okay, like tuples?
21:17:11 <guest88> '2' `elem` ('2','3') returned false
21:18:25 <mniip> oh no it's this all over again
21:19:17 <jackdk> the foldable instance for tuples is lawful and handy, but confuses newbies. Time to reset the clock =/
21:19:41 <opqdonut> > length (1,2)
21:19:43 <lambdabot>  1
21:21:40 <dibblego> @kind Foldable
21:21:42 <lambdabot> (* -> *) -> Constraint
21:21:48 <dibblego> it is 1 — QED
21:25:23 <guest88> when I look at the type of read it looks like it only has 1 input of type 'String' 
21:25:25 <guest88> read :: Read a => String -> a
21:25:47 <guest88> but when i use read "4.2" it doesn't work. It only works if i do something like read "4.2" + 2.0
21:25:58 <guest88> so is it actually taking 1 input or 2?
21:27:06 <jackdk> guest88: one input. `read` needs to know a return type to work out what type to attempt a parse for. in GHCi, this is deafulting to ():
21:27:09 <jackdk> > read "()"
21:27:11 <lambdabot>  ()
21:27:54 <jackdk> in your second example, the fact that the result of a read is applied to (+) gives it enough information to figure that it's some fractional numeric type
21:28:17 <jackdk> you can use a type annotation to force the type it reads into:
21:28:23 <jackdk> > read "4.2" :: Double
21:28:25 <lambdabot>  4.2
21:28:49 <jle`> guest88: you can use `elem` on things like Maybe, or NonEmpty lists, or Map, or Set -- those are kind of useful
21:29:02 <jle`> @let letters = S.fromList ['a'..'z']
21:29:04 <lambdabot>  Defined.
21:29:06 <jle`> :t letters
21:29:06 <jackdk> (your second example, `read "4.2" + 2.0` is equivalent to `(+) (read "4.2") 2.0`
21:29:07 <lambdabot> S.Set Char
21:29:16 <jle`> > 'q' `elem` letters
21:29:18 <lambdabot>  True
21:29:20 <jle`> > '?' `elem` letters
21:29:22 <lambdabot>  False
21:29:33 <mniip> uhhh
21:29:35 <mniip> uhhhhhhh
21:29:41 <zeta_0> sorry if i am little of topic, can you guys help me with a clojure installation problem? no one is on the #clojure channel
21:29:46 <mniip> elem on sets is linear time
21:29:54 <mniip> unlike S.elem which is logarithmic
21:29:54 <jle`> hehe
21:30:04 <jle`> i just wanted to use an example of a non-list type that wouldn't be dumb to use 'elem' for
21:30:14 <guest88> ah cool
21:30:15 <jle`> s/that wouldn't be dumb/that would be interesting
21:30:30 <jle`> other Foldable's have sort of boring elem's
21:30:35 <jle`> > 3 `elem` Just 7
21:30:37 <lambdabot>  False
21:30:39 <jle`> > 3 `elem` Just 3
21:30:41 <lambdabot>  True
21:30:42 <jle`> meh
21:30:53 <mniip> > 3 `elem` Left 3
21:30:55 <lambdabot>  False
21:31:04 <mniip> obviously
21:31:04 <zeta_0> using nix, i installed clojure which seems to be working fine, but i am not sure how to install clojurescript?
21:31:06 <jackdk> ehehehe, Const r has a Foldable instance
21:31:07 <jle`> there's interesting, there's boring, and there's horrible
21:31:36 <jackdk> I suppose that means Proxy should have one also
21:31:43 <jle`> Proxy doesn't have one?
21:31:50 <zeta_0> if you guys don't know the answer i'll wait until tomorrow to ask this question on the #clojure channel
21:31:50 <jle`> > toList Proxy
21:31:52 <lambdabot>  error:
21:31:52 <lambdabot>      Ambiguous occurrence ‘toList’
21:31:52 <lambdabot>      It could refer to either ‘F.toList’,
21:31:57 <jackdk> it does, but I hadn't looked at the doccs
21:31:58 <jle`> > F.toList Proxy
21:32:01 <lambdabot>  []
21:32:02 <jle`> neat
21:32:13 <guest88> are Typeclasses just simply groupings of types and functions?
21:32:25 <jle`> pretty much yeah
21:32:32 <monochrom> Define "simply".
21:32:44 <jle`> define 'groupings' etc.
21:32:55 <jle`> but i think it gives a decent overall idea of what's going on
21:32:55 <Welkin> a word used to advertise food products
21:33:02 <monochrom> "Computers are simply logic gates" never informed you very much, did it?
21:33:06 <Welkin> define "are"
21:33:10 <guest88> like Ord type class contains things like the functions (>), (<) (<=), etc.
21:33:13 <guest88> its just a set
21:33:26 <Welkin> Just a?
21:33:33 <jle`> monochrom: in "X is simply Y", the thing that makes it informing or not is the X and Y
21:33:37 <jle`> monochrom: not the 'simply' :p
21:34:24 <guest88> philosophy aside tho
21:34:29 <guest88> its just a set
21:34:34 <guest88> its a set
21:34:36 <guest88> not even just
21:34:39 <jle`> i wouldn't say it's "just" a set
21:34:44 <jle`> there more to it than that
21:34:54 <jle`> but it's not a bad way to start looking at it
21:35:00 <monochrom> Look if you're "simply" "just" looking for someone to say yes, there is a unix program for that, so why are you asking.
21:35:43 <Welkin> open emacs and type M-x doctor
21:35:44 <guest88> because beginners need simplifications to focus on tackling the broadness of a new topic.
21:35:58 <Welkin> a typeclass is an interface
21:36:03 <Welkin> good enough
21:36:11 <mniip> an ordered set
21:36:17 <monochrom> Then you don't say "simply" you say "as a first cut can I start like this".
21:36:30 <mniip> not all sets are ordered/most sets can be ordered in multiple different ways
21:36:35 <monochrom> Like, listen to yourself, you confessed "broadness".
21:36:57 <Welkin> when you put a constraint on a function (a typeclass), it's dictionary gets passed in to look up that specific implementation of the function or whatever it is
21:37:16 <monochrom> This is not philosophy this is basic honesty and articulation.
21:37:30 <monochrom> "simply" "just" honesty
21:37:33 <Welkin> you too basic monochrom !
21:37:35 <guest88> I cant listen to myself, because i'm not saying the words, if you wanted to get real technical
21:37:37 <Welkin> you all BASIC
21:37:42 <Welkin> simply
21:38:14 <mniip> aight please be constructive
21:39:32 <guest88> didn't know I was entering a boarding school or a parish, but thanks for your criticism monochrom
21:40:20 <Welkin> you are now amish
21:40:34 <Welkin> no electricity for you
21:40:48 <Welkin> you'll send messages via pigeon
21:41:00 <jackdk> not helping...
21:41:12 <Welkin> the amish police are on their way to disconnect your internet and confiscate your computer
21:41:15 <guest88> I hope I can get some divine intervention so I can learn haskell, let's be honest
21:41:18 <Welkin> they'll be there in a fortnight
21:42:07 <Welkin> best advice: just do it
21:42:23 <Welkin> start writing programs, but not before reading lots of real code (not books about it)
21:42:47 <Welkin> it's more powerful than jesus
21:44:03 <dsal> Is there a Functor instance of Jesus?
21:44:21 <monochrom> I thought I was the only one drunk tonight.
21:45:43 <dsal> guest88: haskell is really simple from the bottom up.  It's pretty hard if you are working from the outside in.
22:25:54 * hackage core-program 0.2.4.2 - Opinionated Haskell Interoperability  https://hackage.haskell.org/package/core-program-0.2.4.2 (AndrewCowie)
22:26:54 * hackage libyaml 0.1.2 - Low-level, streaming YAML interface.  https://hackage.haskell.org/package/libyaml-0.1.2 (MichaelSnoyman)
23:50:24 * hackage hanabi-dealer 0.5.0.0 - Hanabi card game  https://hackage.haskell.org/package/hanabi-dealer-0.5.0.0 (SusumuKatayama)
