00:05:38 <glguy> Also try adding the executable name
00:05:51 <glguy> Frogulis: try: cabal v2-run exename -- --gamma
00:28:50 <Frogulis> found the problem: i was running in powershell. guess it doesn't like the "--" operator
03:40:23 * hackage arith-encode 1.0.2 - A practical arithmetic encoding (aka Godel numbering) library.  https://hackage.haskell.org/package/arith-encode-1.0.2 (Bodigrim)
04:10:14 <fendor> is there a quasi quoter to print a haskell expression into a readable string? e.g. [| let x = 5 |] -> "let x = 5" No desugaring required or wanted
04:31:08 <aveltras> using relude alternate prelude, how would one access this function https://hackage.haskell.org/package/text-1.2.4.0/docs/Data-Text.html#v:splitOn as it's not reexported (it seems), do i have to add text as a hard dependency in cabal file and act as if i didn't use relude here ? (relude text reexports are here https://github.com/kowainik/relude/blob/master/src/Relude/String/Reexport.hs)
04:49:09 <newhoggy> d34df00d: Your post inspired me to put together a proof of concept broadword programming based version of `wc`
04:49:35 <newhoggy> https://github.com/haskell-works/hw-wc
04:51:03 <newhoggy> https://www.irccloud.com/pastebin/Ui3fdrsn/
04:51:23 * hackage fcf-containers 0.3.0 - Data structures and algorithms for first-class-families  https://hackage.haskell.org/package/fcf-containers-0.3.0 (gspia)
04:52:23 * hackage req 3.1.0 - Easy-to-use, type-safe, expandable, high-level HTTP client library  https://hackage.haskell.org/package/req-3.1.0 (mrkkrp)
04:54:45 <__monty__> newhoggy: Which `wc` call is the hw-wc call equivalent to? And those identical bytes and chars numbers looks suspicious : )
04:54:47 <newhoggy> "Single threaded performance" is nearly `10x` faster than `wc` over UTF8, (although it uses up to 200% CPU)
04:55:14 <newhoggy> Command line utility.
04:57:08 <newhoggy> Tested on some Japanese:
04:57:12 <newhoggy> https://www.irccloud.com/pastebin/huImsd6Q/
04:57:39 <ivegotasthma> what are the problem contexts where haskell fits better than python or go?
04:57:58 <newhoggy> https://www.irccloud.com/pastebin/5IejszWz/
04:58:59 <newhoggy> The identical numbers was because I tested on a big ascii file actually, but it does work on utf8 as shown above.
04:59:38 <__monty__> I assumed broadword had something to do with widechars but I see that's not the case.
05:00:35 <newhoggy> Broadword roughly means simulating SIMD with non-SIMD instructions :D
05:01:11 <newhoggy> i.e. `Word64` instead of `Word8` to process eight characters at a time.
05:03:18 <__monty__> ivegotasthma: Anything where there isn't an acute lack of libraries or restrictions on linking : )
05:09:06 <__monty__> newhoggy: Hmm, isn't this less speedup than expected actually? It's closer to 4x than 8x.
05:12:23 * hackage sized 0.4.0.0 - Sized sequence data-types  https://hackage.haskell.org/package/sized-0.4.0.0 (HiromiIshii)
05:14:49 <aveltras> using polysemy, is there a way to get the kind of behavior depicted in widgetErr here ? (generating the links "inline" inside of html construction)
05:14:55 <aveltras> https://www.irccloud.com/pastebin/tCGw64kL/
05:18:24 <merijn> ivegotasthma: tbh, I'd say "all of them" :p
05:18:42 <merijn> ivegotasthma: Although it depends if we're talking just the language or language + ecosystem
05:19:01 <ivegotasthma> language + ecosystem
05:19:36 <merijn> ivegotasthma: I don't think go's ecosystem is particularly great, so I think the only thing it's got going for it is that crosscompilation is much better supported
05:20:42 <merijn> ivegotasthma: Python of course has quite a lot of major ecosystem stuff like pytorch, tensorflow, etc. otoh I find python's ecosystem annoyingly brittle and tooling for packaging quite bad.
05:21:30 <newhoggy> __monty__: Probably.  I'll need to look at it more closely.
05:21:36 <merijn> ivegotasthma: Python used to be advertised a lot as "the high level glue language", but tbh I find that Haskell is a much nicer glue language
05:23:10 <merijn> ivegotasthma: I use python for scikit-learn for example (honestly, probably a mistake in hindsight, but, you know, hindsight 20-20). I simply call a small python script from Haskell to function as a thing wrapper around the scikit-learn API
05:23:32 <ivegotasthma> how would you use the data science libraries with haskell?
05:24:23 <merijn> there's a bunch of Haskell libraries for that sorta thing, but they're not as big and comprehensive as the python stuff, atm. But running python in a subprocess is fairly easy
05:24:37 <ivegotasthma> good to know
05:24:48 <ivegotasthma> thanks for the 2c
05:26:06 <merijn> ivegotasthma: In general I think the areas where Haskell absolutely excels are: any form of parsing, stream processing (i.e. "i have 10 million records I need to run some sort of aggregate processing on), heavy concurrency (so workflows, connecting/plumbing lots of IO jobs)
05:26:29 <merijn> ivegotasthma: Abstracting away lower level muck behind high-level interfaces
05:27:08 <merijn> ivegotasthma: Writing a fast inner loop in C, then writing all the surrounding boilerplate like option parsing in Haskell works very well, since the C FFI is very nice
05:27:35 <ivegotasthma> isn't haskell <-> C interfacing a pain in the ass?
05:27:58 <merijn> ivegotasthma: No, it super easy
05:28:22 <merijn> ivegotasthma: I mean, obviously the C stuff generally ends up in IO due to lack of purity, but it's quite simple
05:29:18 <merijn> ivegotasthma: The only thing that's painful (and only a little bit, tbh) is wanting to mutate C structs from within Haskell or passing struct by value. If you only pass primitive types and pointers and don't want to mutate structs in Haskell it's as easy as can be
05:31:05 <ivegotasthma> awesome to hear
05:31:20 <merijn> ivegotasthma: I use it quite a bit because I'm using custom SQLite extensions written in C with an SQLite implementation that I use from Haskell. See for example: https://github.com/merijn/Belewitte/blob/master/benchmark-analysis/src/SQLiteExts.hs#L74-L116 (this is literally all that's necessary to use these functions)
05:31:45 <ivegotasthma> I've been afraid to start anything with haskell because I have the idea that it's a very isolated ecosystem where unless your usecase fits right in, you're on your own in terms of libraries / support / etc.
05:32:10 <merijn> ivegotasthma: You can find the C implementations of the cbits subdirectory, but they are just normal C functions. (The FunPtr stuff is because SQLite needs pointers to the functions, you could also import them directly as functions and just call them)
05:32:41 <newhoggy> I think if you measure it by wall clock time, it's `9.26 x` faster than `wc`, but if you measure it by CPU usage, then it is `4.51 x`
05:32:50 <merijn> ivegotasthma: tbh, the library ecosystem is fine in Haskell. Sure you don't have as many options as in python/JS/C, but all the major (and tons of minor) things are covered
05:33:35 <newhoggy> I'm guessing it's the garbage collector that's using the second thread?
05:35:36 <merijn> ivegotasthma: If you wanna learn a bit about the FFI I'd recommend having a look at chapter 8 of the Haskell Report (which covers it) and the GHC user guide. If you know the basics of C and linking, it's easy enough to understand, since it's basically all specified in terms of the C platform ABI
05:35:54 <ivegotasthma> I'm good with C / Rust
05:36:25 <ivegotasthma> I don't follow all the news that much, but is something happening with haskell2020?
05:37:06 <merijn> ivegotasthma: Seems unlikely, every so often there's some renewed interest in a new standard, but it seems to be hard to get it done
05:39:04 <srk> heh, system-filepath says ;Deprecated. in favor of filepath'
05:39:06 <srk> Please see: https://plus.google.com/+MichaelSnoyman/posts/Ft5hnPqpgEx
05:39:36 <srk> (which is dead) :)
05:40:46 <srk> https://github.com/Gabriel439/Haskell-Turtle-Library/issues/54 /o\
05:42:53 * hackage constructible 0.1.1 - Exact computation with constructible real numbers  https://hackage.haskell.org/package/constructible-0.1.1 (AndersKaseorg)
05:43:17 <srk> lol, just noticed GHC uses gitlab
05:44:33 <newhoggy> If I turn off threading it runs faster:
05:44:37 <newhoggy> https://www.irccloud.com/pastebin/PelSR8Sc/
05:44:52 <merijn> newhoggy: Oh, do you manually set the number of capabilities?
05:45:05 <merijn> newhoggy: i.e. "+RTS -N"?
05:45:40 <newhoggy> Yeah, I have that in all my cabal files 😆
05:45:58 <merijn> newhoggy: Yeah, then you're running into the issue that you're using parallel GC
05:46:02 <newhoggy> -threaded -rtsopts -with-rtsopts=-N
05:46:05 <merijn> And parallel GC is shite for most usescases
05:46:33 <merijn> newhoggy: Try adding the -qg RTS option
05:46:44 <merijn> newhoggy: Which disables use of parallel GC in the threaded runtime
05:47:06 <newhoggy> Should I change my cabal file?
05:47:25 <merijn> newhoggy: You can add it via -with-rtsopts to make it permanent, yes
05:47:44 <merijn> (I don't quite know the right way to specify multiple flags to -with-rtsopts
05:52:05 <newhoggy> https://www.irccloud.com/pastebin/xBQCxq7q/
05:52:10 <newhoggy> Wow, nice.  Thank you.
05:52:55 <zincy_> Is there a way of conditionally adding WHERE clauses in queries with postgres-simple?
05:53:37 <merijn> zincy_: "(? OR Foo = ?)" and then you can disable the where clause by passing true for the first argument
05:53:43 <__monty__> newhoggy: That's not really a speedup. Though it *is* only using half the cores, so that's certainly something.
05:54:43 <newhoggy> Yeah, it'll pay off when multithreading in that I don't have cores wasted to GC.
05:55:49 <merijn> newhoggy: For most use cases the parallel GC is pretty bad. In the GHC proposal to make -threaded the default they also agreed to disable parallel GC by default
05:56:09 <newhoggy> Oh nice.  Looking forward to it.
05:56:22 <__monty__> `wc` does strike me as an embarrassingly parallel task tbh. Just have to consider edge-cases across block boundaries.
05:56:59 <APic> lllllllll/g 69
05:57:02 <APic> Sorry
05:58:22 <zincy_> merijn: Thanks so much! Been searching for that solution for ages
06:00:16 <__monty__> zincy_: Maybe there's something to merijn's advice that every haskell programmer should read the GHC User's Guide : >
06:00:48 <merijn> __monty__: Ssshh! Next people will figure out that I'm not actually a savant Haskell programmer...
06:05:35 <zincy_> __monty__: How would that help with a question related to a database library?
06:06:10 <merijn> zincy_: I think he confused you with newhoggy about the -qg flag
06:06:37 <zincy_> Yeah
06:10:29 <__monty__> zincy_: Oh, yeah, sorry. Thought you were referring to the -qg.
06:10:57 <merijn> zincy_: I had the same problem earlier and then I realised "wait...boolean operators!" :p
06:11:00 <fendor> is there some template haskell magic or quasi quoters that can give me the string representation of an expression? e.g. Exp -> (String, Exp) or something like that?
06:11:20 <merijn> fendor: With what goal?
06:12:07 <fendor> merijn, to show the expression to the user, like for a test-case that has only single assertions
06:12:26 <hpc> ooh, like what rust has
06:12:48 <merijn> fendor: I don't think it exists, but it shouldn't be too hard to roll your own
06:13:31 <fendor> merijn, then I am just failing to roll my own :) I tried a quasi quoter, but it always parses my expression as a string
06:13:54 <merijn> fendor: Can you pastebin the quasiquoter?
06:14:23 <fendor> e.g. \s -> runQ [e|s|] >>= \x -> tupE [stringE s, pure x]
06:14:51 <fendor> type is `String -> Q Exp`
06:15:30 <fendor> and I think `runQ [e|s|]` is wrong 
06:15:36 <merijn> So do I :p
06:15:47 <merijn> fendor: Because you're quoting the 's' variable there
06:16:01 <merijn> fendor: You can just get quasi quoter as regular function
06:17:27 <fendor> merijn, how does it help as a regular function? Arent I still quoting the string s then?
06:17:51 <ph88^> i have a haskell binary (spago) which i can call like `spago build --watch`  But when i do `npm run dev` which in turns should do `spago build --watch & parcel index.html`   i get some output and also   spago: <stdin>: hGetLine: end of file    and spago doesn't work, what could this be ?
06:18:27 <merijn> fendor: If you have the regular quasi quoter "String -> Q Exp" then you wanna wrap it so that you get "\s -> fmap wrapWithSTuple (f s )" where 'f' is the existing quasiquoter
06:18:53 <merijn> ph88^: Looks like npm is closing stdin
06:19:04 <ph88^> ah ok
06:19:24 <ph88^> is stdin needed ?
06:19:34 <merijn> ph88^: That depends on what your binary is doing
06:19:39 <merijn> Apparently it's using stdin
06:19:54 <fendor> ah, ok, that makes sense. Ill try 
06:20:01 <ph88^> hi fendor 
06:20:19 <merijn> ph88^: Basically, npm is running your code with a closed stdin, your code then tries to read stdin via hGetLine and crashes (because stdin is closed)
06:20:38 <fendor> ph88^, hi!
06:20:44 <merijn> ph88^: The fix is to either 1) ensure npm runs your code with stdin open or 2) your code works with stdin closed
06:21:25 <ph88^> got it, thank you merijn 
06:21:36 <ph88^> it's not my code but i could debug it
06:23:52 <ph88^> merijn, do you have any idea how i could find the offending code?  https://github.com/purescript/spago/search?q=hGetLine&unscoped_q=hGetLine 
06:24:19 <merijn> ph88^: It could be hidden in one of your dependencies too, so hard to say
06:25:00 <ph88^> maybe it's possible to tap into the mechanism that makes the error be put on screen
06:25:07 <ph88^> with a stacktrace or so
06:25:22 <merijn> ph88^: You can compile with profiling enabled and run with +RTS -xc to get a stacktrace
06:27:19 <ph88^> great
06:42:56 <fendor> does the quasiquoter [e||] exist as a function? 
06:46:02 <newhoggy> Is there a way to generate just enough sparks to get performance but not too much that performance goes down the drain?
06:46:40 <newhoggy> I'm doing something like this:
06:46:45 <newhoggy> https://www.irccloud.com/pastebin/Y5ErEczB/
06:47:05 <newhoggy> Then using it with a lookahead of `10`:
06:47:10 <newhoggy> https://www.irccloud.com/pastebin/6zLI4Yzo/
06:48:25 <newhoggy> Also don't like how I'm dropping 10 for each element.
07:13:30 <John_Ivan> does haskell support OOP/classes
07:13:31 <John_Ivan> ?
07:14:30 <__monty__> John_Ivan: Depends what you mean by "support."
07:14:45 <__monty__> The language has no concept of objects built-in.
07:15:05 <John_Ivan> I mean if I can construct objects based on domain logic
07:15:07 <John_Ivan> oh
07:15:50 <John_Ivan> hmm. that's one thing I never quite understood about haskell then.
07:15:59 <John_Ivan> perhaps structures instead?
07:16:22 <__monty__> Closest thing is data types.
07:16:39 * John_Ivan writes some notes.
07:17:20 <__monty__> data Tree a = Empty | Leaf a | Node (Tree a) (Tree a)
07:17:38 <__monty__> Just as an example to show what you can do.
07:18:15 <__monty__> Haskell does have "record syntax" but it's limited in various ways because it's only syntactic sugar.
07:19:42 <John_Ivan> I mostly come from an imperative background where about 95% of problems I solved were "IO" oriented. I'm just wondering if I'm making a good choice in attempting to cover more haskell or if I'm in the wrong place.
07:20:07 <John_Ivan> IO oriented as in, GUI, networking, filesystem, processes.
07:20:11 <merijn> John_Ivan: tbh, I write tons of IO heavy Haskell and it's pretty great, imo :)
07:20:40 <John_Ivan> that's a relief to hear, so I haven't wasted my time putting in the effort for it :)
07:21:26 <__monty__> John_Ivan: Haskell's a different enough language that picking it up isn't a waste of time even if you never end up using it.
07:21:33 <merijn> John_Ivan: The GUI bit is still a bit painful, since most of the GUI frameworks are very...non-haskelly so all the bindings get kinda awkward
07:21:51 <merijn> John_Ivan: concurrency, networking, filesystem, processes, etc. is all fine
07:22:04 <John_Ivan> sweet
07:23:47 <merijn> John_Ivan: Without OOP/classes you just get very different looking solutions. For example, since you mention filesystems/networking. Take a common problem like "stream a bunch of data from disk/network into a processing pipeline"
07:24:54 <John_Ivan> well so far I understood that the goal is to separate the IO aspect from the functional pure functionality of a system.
07:25:35 <John_Ivan> currently reading through source code, I think I have some things deciphered
07:25:48 <John_Ivan> mostly trying to confirm if my conclusions aren't wrong
07:25:53 <merijn> John_Ivan: The goal is to make side-effects explicit and visible (instead of implicit and hidden)
07:26:53 <maerwald> minus exceptions :P
07:27:07 <merijn> maerwald: Yeah, that sucks >.>
07:27:33 <John_Ivan> I'm thinking in terms of logging and error checking. Not so sure how that'd fit in the code if most of my pure functions end up being short and not Io driven.
07:27:42 <John_Ivan> let alone not having any conditional statements.
07:28:05 <John_Ivan> in them.
07:28:08 <merijn> John_Ivan: You can easily do the equivalent of conditional statements, though
07:28:18 <merijn> % when True $ putStrLn "Conditional!"
07:28:19 <yahb> merijn: Conditional!
07:28:24 <merijn> % when False $ putStrLn "Conditional!"
07:28:25 <yahb> merijn: 
07:28:31 <merijn> :t when
07:28:33 <lambdabot> Applicative f => Bool -> f () -> f ()
07:29:24 <John_Ivan> I suppose that works. Just worried that it might behave differently when OS specifics come into play, like error codes.
07:29:38 <__monty__> John_Ivan: Feel free to think "I don't know how this is done in haskell." Rather than "I know this is impossible in haskell."
07:30:31 <merijn> John_Ivan: Lots of these things can't be done the way you'd do them in most imperative languages, but that doesn't mean there aren't (equally convenient/usable) solutions :)
07:31:34 <John_Ivan> well if that's the case, I'll keep looking :)
07:37:23 * hackage mongoDB 2.7.0.0 - Driver (client) for MongoDB, a free, scalable, fast, documentDBMS  https://hackage.haskell.org/package/mongoDB-2.7.0.0 (VictorDenisov)
07:46:22 <John_Ivan> so if I wanted to create an abstract IoC wrapper for a ProcessManager, this would be the way I'd go about doing it?
07:46:26 <John_Ivan> data ProcManager = { imageName :: String, isRunning :: Bool, run :: IO, pause :: IO, stop :: IO }
07:47:39 <merijn> John_Ivan: isRunning would probably be "IO Bool" since the value of that changes over time :)
07:47:50 <newhoggy> This works well: https://github.com/haskell-works/hw-wc/pull/1/files
07:48:13 <merijn> John_Ivan: YOu might wanna see the docs for the process package to see how working with subprocesses looks: https://hackage.haskell.org/package/process-1.6.7.0/docs/System-Process.html
07:48:17 <newhoggy> Although I have to magically know a lookahead of `32` us optimum for my laptop.
07:48:40 <John_Ivan> thank you
07:49:47 <merijn> John_Ivan: But besides the fact that you were missing an argument type for the various IO types that looks like a relatively realistic API for representing something like a process
07:50:15 <John_Ivan> understood. just wish to know if I'm on the right track with each haskell concept.
07:51:23 * hackage ghc-lib-parser-ex 8.8.5.1 - Algorithms on GHC parse trees  https://hackage.haskell.org/package/ghc-lib-parser-ex-8.8.5.1 (shayne_fletcher)
07:55:25 <merijn> John_Ivan: Which book (if any?) are you reading?
08:00:30 <John_Ivan> merijn, I always use multiple sources when learning something because I'm looking for very specific things and need a contrast. "Real World Haskell", "Learn you a Haskell for Greater Good", the Wikidocs on handling GUI in Haskell, and Tutorialspoint
08:01:22 <John_Ivan> I think I've figured out how to declare "structures", create/run "functions", handle "IO" separately and deal with pattern matching, guards and conditions.
08:01:27 <merijn> LYAH is not...great, it lacks exercises and glosses over lots of things, leaving you with cool impressions, but not a lot of confidence in your ability to write things
08:01:55 <merijn> Real World Haskell is nice, but kinda dated (I know someone was working on updating it)
08:01:59 <John_Ivan> sometimes reading a book isn't just about reading the book, thoughh :)
08:02:08 <merijn> Sure
08:02:23 <John_Ivan> if more than anything, I use LYAH mostly for the ToC.
08:03:15 <John_Ivan> I'm trying to think if there's anything else blocking my way into starting to write code.
08:03:36 <John_Ivan> switches, loops, if statements.... what else is there
08:03:43 <John_Ivan> ah
08:04:12 <John_Ivan> merijn, Higher Order Functions - based on my understanding, I've come to conclusion that these are more or less function pointers, aren't they?
08:05:01 <merijn> That's a loaded question if I ever saw one :)
08:05:33 <merijn> That rather depend on what you mean by "are" and "more or less" :p
08:06:25 <John_Ivan> they serve the purpose of flow control specific to passing functions as arguments around.
08:06:36 <merijn> Completely unrelated intermission: What's a good way to represent percentages (i.e. 0-100)? Just Double?
08:06:39 <John_Ivan> in particular, needed for events.
08:06:44 <John_Ivan> callbacks.
08:07:48 <merijn> John_Ivan: higher order functions is more about "functions that take other functions as argument", which in something like C is usually done via function pointers, but function pointers are much more limited...
08:08:25 <John_Ivan> I see.
08:10:41 <John_Ivan> next, I'll need multithreading.
08:13:26 <merijn> John_Ivan: You'll probably be interested in: https://simonmar.github.io/pages/pcph.html
08:14:00 <merijn> hmm...it's no longer unlimitedly available for free?
08:14:03 <KoFish> Hello! Just have a quick question, just trying to get back into haskell and would love to know if there are any widely accepted documentation on good praxis for how to structure hs code for distribution.
08:14:31 <merijn> KoFish: Are you referring to module structure or like directory layout?
08:16:42 <KoFish> merijn: Either basically. The hardest I've tried to find so far is where to put arbitrary declarations of types for quickcheck. The VSCode extension I use seem to have some issues and doesn't really want to recognize imports from the test folder so adding a separate module for arbitraries there seems to be wrong according to stack/the vscode ext I
08:16:42 <KoFish> use
08:17:25 <merijn> KoFish: I don't think there's a good answer to that question (in fact, that's one of the reasons hedgehog doesn't use typeclasses for property testing...)
08:17:57 <KoFish> check
08:18:48 <John_Ivan> merijn, thanks, I'll grab that in a minute - currently reading this - https://wiki.haskell.org/Haskell_for_multicores
08:22:19 <John_Ivan> merijn, what is the meaning of this syntax/keyword? "$"
08:22:29 <merijn> :t ($)
08:22:31 <lambdabot> (a -> b) -> a -> b
08:22:32 <John_Ivan> I see a thread being spawned with forkIO $
08:23:03 <merijn> John_Ivan: It's an operator that applies a function on the left to a value on the right, because people hate parenthesis
08:24:14 <John_Ivan> oh
08:24:15 <John_Ivan> I see
08:24:20 <John_Ivan> so
08:24:38 <John_Ivan> forkIO $ hashAndPrint fileA is the equivalent of forkIO ( hashAndPrint fileA )
08:24:49 <merijn> yeah
08:24:50 <solonarv> merijn: Double, but representing log odds because that way illegal values are not representable ;)
08:25:01 <John_Ivan> :pinkguymeme:
08:25:58 <John_Ivan> ok awesome. so, gonna save this page for later. what else will I need...
08:26:45 <merijn> solonarv: I think I'll just "newtype Percentage = Percentage Double"
08:27:17 <solonarv> oh yeah, I wasn't exactly being serious!
08:27:30 <John_Ivan> arrays... I'm guessing it's just going over lists with recursion and/or adding/removing things to them via the List type.
08:27:36 <John_Ivan> and related operations.
08:27:47 <solonarv> maybe if you were doing some bayesian calculations, but if you're talking about *percentages* that's probably not the case
08:28:03 <solonarv> John_Ivan: actually, there are arrays as well
08:28:49 <John_Ivan> noted.
08:28:51 <merijn> John_Ivan: Lists are common for simple loopy operations, but if you need random access arrays you probably want the vector package
08:28:55 <merijn> @hackage vector
08:28:55 <lambdabot> http://hackage.haskell.org/package/vector
08:29:22 <John_Ivan> ah yeah. this I'm familiar with. containers specific for computation.
08:29:32 <John_Ivan> excellent.
08:29:35 <juri_> what should i be doing with optparse-applicative to parse options like -m0 instead of -m 0?
08:29:59 <merijn> juri_: I don't think you can, since that'd be ambiguous
08:30:11 <merijn> oh wait, for single argument things it should work?
08:30:44 <juri_> yeah. basically, short parsing with no following space.
08:30:54 <merijn> juri_: The better question is: Why is it not working for you? ;)
08:31:04 <merijn> I just tested here and it "Just Works"
08:31:17 <juri_> oh? the space is optional?
08:31:23 <juri_> great! thanks. :D
08:31:25 <merijn> juri_: For short flags, yes
08:31:53 <merijn> juri_: At least, I didn't do anything special and it works in my program using optparse :p
08:32:05 <John_Ivan> is there low level/unsafe access in haskell? stuff like referencing memory directly and writing/reading to it?
08:32:06 <juri_> I'll give it a go, then. :D
08:32:25 <solonarv> John_Ivan: yeah, there is
08:32:28 <merijn> John_Ivan: Sure, there's a bunch of stuff related to the FFI for that
08:32:33 <solonarv> but it's fiddly
08:32:42 <merijn> solonarv: Not anymore so than C is...
08:32:49 <John_Ivan> awesome
08:32:58 <solonarv> syntactically, it is certainly more fiddle
08:33:15 <merijn> solonarv: That just ensures you have to really, really want it ;)
08:33:16 <solonarv> ... but that's not exactly a criticism, IMO
08:33:19 <solonarv> yup!
08:33:33 <John_Ivan> sweet.
08:34:11 <cyris212> I'm trying to learn Aeson and yaml. Could somebody tell me what the problem with the following snippet could be?
08:34:15 <cyris212> https://gist.github.com/winpat/20a36739b60e1bcd7d5750f75b715d50
08:35:05 <lyxia> cyris212: you're missing the Playbook constructor
08:35:27 <solonarv> you also flipped the order of \ and (
08:35:51 <solonarv> you have \(( but it should be (\(
08:36:52 <John_Ivan> interfaces and DI containers, is that available in by default or provided by libraries?
08:37:45 <merijn> DI containers?
08:38:00 <John_Ivan> dependency injection.
08:38:33 <merijn> We generally just call "dependency injection" "passing a function argument"
08:39:18 <John_Ivan> just wish to know if there's some structure that lets you do something similar to an interface (say in Java)
08:39:36 <John_Ivan> which will let you override functionality
08:40:05 <cyris212> solonarv: That would explain the parse error, thank you.
08:40:22 <cyris212> lyxia: `Playbook $ parseJSON ...` should do the job right?
08:42:36 <merijn> John_Ivan: It depends on the kind of functionality
08:43:32 <[exa]> John_Ivan: the usual answer is that "you don't want to do it", for multiple reasons. But otherwise yes, both can be done quite easily
08:44:16 <John_Ivan> that's satisfactory enough.
08:44:17 <John_Ivan> :)
08:44:25 <John_Ivan> thanks
08:45:37 <lyxia> cyris212: try again :)
08:46:31 <[exa]> John_Ivan: re overriding, haskell code tends to produce specialized things by composing them from smaller ones, which is easy in haskell. In OOP languages compositionality is sometimes problematic and it is easier to override small parts of the other things
08:47:15 <maerwald> composition is problematic everywhere :)
08:48:36 <[exa]> maerwald: try `fmap.fmap` in java :]
08:49:03 <maerwald> try subtyping in haskell :)
08:49:35 <[exa]> ...but... subtyping is evil!!!11 :D
08:49:52 <maerwald> works well with structural typing or row types
08:50:28 <John_Ivan> don't think I have any other questions, at least none that come to mind at the moment.
08:50:38 <John_Ivan> I will get into writing some code then
08:50:42 <John_Ivan> thanks everyone. means a lot.
09:53:09 <monochrom> composing values vs composing types
09:57:49 <d34df00d> newhoggy: wow, that's awesome result! I've never had much chance to play around with broadword programming, so now I'm curious to research that and see what I manage to come up with before reading your implementation :)
11:17:54 <sim590> I'm looking for a 2D vector library (I don't mean Data.Vector) which would define functions like the dot product, vector projection, etc.
11:18:21 <sim590> I can't find it really because I see a lot about Data.Vector which doesn't correspond to the type of "vectors" I mean.
11:19:05 <sim590> Oh. I just found Numeric.Vector. Sorry for bothering.
11:20:02 <MarcelineVQ> check out https://hackage.haskell.org/package/linear
11:21:54 <sim590> MarcelineVQ: Cool. I'll consider this one!
11:32:27 <sim590> MarcelineVQ: Unfortunately, it doesn't define dot product, neither vector projection. :/. It is however simple in its signatures and does define the sum and every minimal requirements for vectors. 
11:36:23 <phadej> linear definitely has dot product: https://hackage.haskell.org/package/linear-1.21/docs/Linear-Metric.html#v:dot
11:36:52 <phadej> same module has `project :: v a -> v a -> v a`
11:36:55 <sim590> :(
11:38:17 <sim590> I really don't find myself comfortable searching in documentation. Is there a way to search within the documentation of a hackage package amongst all the sections for search term?
11:38:31 <phadej> press `s`
11:38:34 <merijn> sim590: Press 's' or go to the index
11:39:06 <sim590> （　ﾟДﾟ）
11:39:16 <phadej> you get something like: https://imgur.com/a/qwpzdUS
11:39:45 <phadej> for most packages upload in past year or so
11:40:25 <sim590> I couldn't find it myself even by accident since I'm using a keyboard driven browser which has pretty much all keypresses already mapped to other things. Thanks
11:41:14 <merijn> The index link is also underrated, imo
11:41:24 <sim590> But, at aleast I can bypass my mappings to use the webpage's.
11:41:42 <sim590> merijn: oh nice. I didN't even notice it existed.
11:42:10 <sim590> Oh, so `s` is for `quickjump` button.
11:42:29 <sim590> I guess that those buttons should be more visible, but Idk.
11:42:56 <solonarv> I didn't even know that button was there :P
11:42:58 <MarcelineVQ> huh, yeah those are pretty unassuming links
11:43:24 <merijn> solonarv: Which one?
11:43:29 <sim590> Alright, after all I think that I really prefer Linear over Numberic.Vector.
11:44:22 <solonarv> the "quickjump" button which does the same thing as pressing S
11:44:44 <solonarv> I've only ever used that by pressing the key
12:19:53 * hackage util-logict 0.0.0.0 - See README for more info  https://hackage.haskell.org/package/util-logict-0.0.0.0 (MatthewFarkasDyck)
12:30:25 <d34df00d> Ok, more TH questions.
12:30:43 <d34df00d> Let's say I'm writing a function f : Type -> Type -> Type (where Type is the TH's Type, not Data.Kind's Type).
12:31:00 <d34df00d> And its body is     f accTy promotedTy = PromotedT '(:::) `AppT` accTy `AppT` promotedTy
12:31:09 <d34df00d> Is it possible to use TH's quasiquoters to express this more concisely?
12:31:30 <d34df00d> Like [| $(accTy) '::: $(promotedTy) |] or smth.
12:42:12 <MarcelineVQ> without the types to play with I'm not sure how things line up but what about  [t| '(:::) accTy promotedTy |]
12:46:25 <MarcelineVQ> you can use the examples on the right for the constructors for how you can write them in a quasiquoter  https://hackage.haskell.org/package/template-haskell-2.15.0.0/docs/Language-Haskell-TH.html#t:Type
12:46:46 <MarcelineVQ> and can check yourself via runQ    e.g.  runQ [t| '(:) 'True 'False -> Int |]
12:46:47 <d34df00d> Interesting, thanks!
12:47:03 <d34df00d> That sort of works, modulo [t| |] returning something in the Q monad instead of being pure.
12:47:19 <d34df00d> When should I use $(foo) instead of foo btw?
12:48:19 <MarcelineVQ> idk hehe. but if you do end up working in Q a lot then there's a handy list of things to use here that generally mirror the non Q versions https://hackage.haskell.org/package/template-haskell-2.15.0.0/docs/Language-Haskell-TH-Lib.html
12:48:40 <Kistero> hi!
12:49:38 <mniip> d34df00d, $(foo) is a splice
12:49:46 <d34df00d> mniip: I mean, in a quasiquoter.
12:49:54 <d34df00d> [t| $(foo) |] vs [t| foo |]
12:49:55 <mniip> foo is just using the identifier which probably has type Q Exp or Q Type
12:50:20 <d34df00d> I've seem $(foo) in that context somewhere, while MarcelineVQ did that without the $ part.
12:50:36 <mniip> % :t \foo -> [t| $(foo) |]
12:50:36 <yahb> mniip: ; <interactive>:1:13: error:; parse error on input `$'; Perhaps you intended to use TemplateHaskell
12:50:49 <mniip> % :set -XTemplateHaskell -XQuasiQuotes
12:50:49 <d34df00d> So I previously thought $() is like antiquotation or what's the right term.
12:50:49 <yahb> mniip: 
12:50:51 <mniip> % :t \foo -> [t| $(foo) |]
12:50:52 <yahb> mniip: Language.Haskell.TH.Lib.Internal.TypeQ -> Language.Haskell.TH.Lib.Internal.TypeQ
12:51:19 <mniip> antiquotation yeah - a splice
12:54:11 <Kistero> I wanted to learn about the "streamly" library, so I threw together a simple test program where I apply an attoparsec parser line-wise to the stream.  This, however, seems to be slower and consume more memory than doing the obvious `many (myParser <* endOfLine)`.  I must obviously be doing something gravely wrong, but I can't for the life of me
12:54:12 <Kistero> figure out why.  Code here: https://paste.rs/9Hu any help would be appreciated!
12:59:51 <maerwald> I don't think streaming lines is going to do you any good. You want the parser to be the consumer of the Word8 Stream directly
13:00:18 <maerwald> I think upstream is working on something like that
13:01:23 <merijn> Kistero: Eh, naive assumption: does the line streamer removes newlines?
13:01:38 <merijn> If so the attoparsec parser never terminates, since it consume until end of line
13:04:54 <merijn> \o/
13:05:19 <d34df00d> Yay, it works!
13:05:23 <merijn> "Man this problem is annoying..." 'wait, didn't I already implement a generic solution in a library?'
13:06:00 <d34df00d> I feel like needing to use TH to generate 15 or 31 cases is a bit ugly, but it works and works great.
13:10:17 <Kistero> merijn it doesn't remove any newlines, the parser parses the file (which is just a big file of "streamly-test i", where i is the number of the line) just fine
13:10:49 <Kistero> maerwald ah I see, so I have to somehow feed it the rest of the stream when parsec return a `Partial`?
13:14:05 <maerwald> Kistero: https://github.com/composewell/streamly/issues/395#issuecomment-583819953
13:20:22 <Kistero> mh I see, looks a bit above my pay grade right now, but thanks anyways!
13:28:00 --- mode: weber.freenode.net set +o Sigyn
13:38:46 --- mode: weber.freenode.net set +o Sigyn
13:38:46 --- mode: weber.freenode.net set +o ChanServ
13:53:45 * merijn frowns
13:54:05 <merijn> Who decided -Wmissing-fields should be a warning, rather than an error? >.<
13:54:53 * hackage hlint 2.2.11 - Source code suggestions  https://hackage.haskell.org/package/hlint-2.2.11 (NeilMitchell)
13:55:11 <dminuoso> merijn: well you can do -Werror=missing-fields in 8.2.1 and above
13:55:31 <dminuoso> It's not a reason, but at least better than nothing.
13:55:37 <merijn> dminuoso: Yes, but that doesn't help me recover the time I was waiting for my test suite to run >.<
13:55:45 <merijn> Well... "test suite" :p
14:12:53 * hackage gi-gtk-hs 0.3.8.1 - A wrapper for gi-gtk, adding a few more idiomatic API parts on top  https://hackage.haskell.org/package/gi-gtk-hs-0.3.8.1 (inaki)
14:46:57 <dminuoso> Is there a way to have GHC not report line ranges like lib/Odin/Stage1/Semantic.hs:(45,3)-(48,84)
14:47:10 <dminuoso> When it warns/errors out I mean
14:49:22 <dminuoso> Reason is, Im using a compilation minor mode, but compilation mode does not understand those references
15:16:20 <amalloy> maybe you could fix it with advice around the minor mode function that parses line numbers?
15:20:04 <fraggle> hello there
15:21:07 <dminuoso> amalloy: Mmm I suppose so
15:22:07 <homotopical> hi all
15:32:38 <d34df00d> Anybody tried updating hie recently?
15:32:46 <d34df00d> It doesn't see to work with stack-based projects for me anymore.
15:33:12 <d34df00d> Complaining about Setup.hs not belonging to the project or smth like that (I can post a full message if it's not a known issue).
15:45:23 * hackage BNFC-meta 0.6.1 - Deriving Parsers and Quasi-Quoters from BNF Grammars  https://hackage.haskell.org/package/BNFC-meta-0.6.1 (ArtemPelenitsyn)
15:59:20 <homotopical> can anyone give me a primer on STM?
15:59:20 <homotopical> like, how is it different from any other concurrency model
15:59:20 <Axman6> it generally makes things easier because race conditions become much harder to write - you can work in generalised transactions over all your shared state so the state is never inconsistent
15:59:44 <hpc> without something like STM you have to roll your own transaction mechanism, or hope that you lock stuff correctly
16:00:24 <hpc> STM can also perform better than locking
16:00:44 <merijn> hpc: What do you mean by concurrency model?
16:00:47 <merijn> eh
16:00:52 <merijn> s/hpc/homotopical
16:02:03 <hpc> merijn: i imagine they meant as opposed to locking, or coroutines, or pipelining
16:02:39 <merijn> hpc: For me a concurrency model would be about describing how things happen concurrently, but STM as abstraction is basically the opposite :p
16:02:58 <dminuoso> homotopical: Think of it to be something similar to database transactions, where you have a consistent view of the world, can atomically manipulate the entire database, abort transactions..
16:03:00 <merijn> You need a concurrency model to implement STM, but you don't need one to use STM, which is the entire point
16:04:53 <merijn> homotopical: I think an important question here is: Are you interested in how STM is implemented or how you would use it
16:06:06 <homotopical> mostly how to use it
16:06:39 <merijn> homotopical: Using is the easy bit. As dminuoso said, think of it as database transactions for your application logic
16:06:40 <homotopical> so STM isn't a concurrency model?
16:06:55 <homotopical> i imagine shared memory being opposite to say, the actor model
16:07:26 * dmwit . o O ( Who cares if "concurrency model" is a good label for STM or not? )
16:07:46 <merijn> homotopical: You have an STM transaction that does a bunch of mutation/operation and you get the guarantee that it happens atomically (i.e. nothing in your code can observe the intermediate states)
16:07:52 <dmwit> The original STM paper has a really good motivation for why it's a neat idea.
16:07:56 <dmwit> YOu might like to at least read the introduction.
16:08:35 <merijn> homotopical: STM is basically shared memory, but you have the ability to *atomically* make complex mutations on that shared state
16:08:46 <dminuoso> homotopical: With STM you can have shared mutable memory, but in a way that concurrency appears to not exist.
16:08:54 <dminuoso> safely.
16:08:59 <merijn> homotopical: Normally you've got atomics like "atomic min" "compare and swap", etc. right?
16:09:18 <dminuoso> homotopical: Are you familiar with database transactions from any of the popular relational databases?
16:09:34 <merijn> homotopical: STM lets you atomically do any mix of reading, writing, updating of shared variables with the guarantee that that will happen atomically
16:09:41 <monochrom> I can see how the mention of "database" suddenly puts one's mind into "not concurrent" mode because database and concurrency are taught in two separate courses.
16:10:01 <monochrom> Except for the irony that database has to be heavily concurrent for obvious reasons.
16:10:19 <Axman6> yeah databases are all about managing concurrency
16:10:26 <dmwit> homotopical: https://www.seas.upenn.edu/~bcpierce/courses/552-2008/resources/stm.pdf
16:10:58 <monochrom> This is what's wrong with just talking.
16:11:21 <dmwit> Don't be scared by the fact that it's an academic paper. SPJ has a particular skill for making academic papers accessible to non-academics.
16:12:07 <dminuoso> dmwit: That is not the original STM paper though.
16:12:22 <dmwit> Okay!
16:12:26 <dmwit> But it's the one I recommend, anyway.
16:12:32 <dminuoso> https://web.archive.org/web/20131101085557/http://web.mit.edu/mmt/Public/Knight86.pdf is the original one, but that's a rather harsh read
16:12:57 <dmwit> And it sounds like you agree with my recommendation, too! Nice.
16:13:21 <homotopical> i'm okay with academic papers-- i'm not familiar with database transactions or RDBMS
16:13:37 <homotopical> i'll look into that stuff
16:14:03 <merijn> homotopical: I mean, the super handwavy explanation is that "STM behaves as if your locks are always magically correct, regardless of how many locks you need"
16:14:57 <dminuoso> Without ever talking about a single lock.
16:15:08 <dminuoso> It's as if everything is always locked just the right way. :P
16:15:40 <dminuoso> Though, with things like `retry` you add so much more spin to that story
16:15:50 <merijn> homotopical: Basically multiple threads can (concurrently) run atomic transactions. You don't know in which order those transactions happen, but you get the promise that your program behaves as if there is some order in which all transactions happened and transactions don't observe each other
16:16:02 <dminuoso> I think, if it wasn't for an efficient `retry`, stm would be boring and not even half as useful.
16:16:54 <merijn> homotopical: So if you have concurrent transactions Foo, Bar, and Baz, then you know that 1) all 3 happened, 2) none of them ever saw any of the others "in progress" (so for every transaction the world looks like the others have either already finished or not yet started)
16:17:45 <merijn> homotopical: So you might get "Foo, Bar, Baz" or "Bar, Foo, Baz", etc. but always interleaved at the transaction level
16:17:57 <merijn> (Sequential consistency is best consistency!)
16:18:55 <merijn> Anyway...bedtime
16:19:12 <homotopical> thanks merijn!
16:32:45 <monochrom> What if Java AWT or Swing used STM to escape the dilemma between "GUI is very vulnerable to race conditions" and "but global locking is so slow" :)
16:34:17 <dminuoso> monochrom: Judging by the quality of global locking, you'd have even more GUI latency because the average Java developer might just write really really long transactions..
16:35:48 <homotopical> so just to confirm-- in STM atomic blocks are run repeatedly until it performs its block without any memory manipulation aside from its own?
16:35:59 <dminuoso> homotopical: No
16:37:19 <dminuoso> homotopical: So inside an STM transaction the runtime system will keep a log of all your reads and writes. If for some reason a transaction is retried, it is blocked until any reference that your transaction previously has attempted to read from is modified.
16:37:49 <dminuoso> homotopical: Furthermore, it gets retried when you tell it to.
16:38:50 <dminuoso> homotopical: so you could do something like { x <- readTVar; when (x > 5) retry; doStuff }
16:39:36 <dminuoso> homotopical: The other retrying that might happen is internal and transparent to you, we could pretend it doesn't happen.
16:39:55 <dminuoso> (In reality it will retry until it can complete the transaction without any conflicts)
16:40:32 <dminuoso> The weight of "without any conflicts" is that there might be multiple memory manipulations going on concurrently, but only if they are safe and isolated from another.
16:41:54 <chew2> hey everyone, do you know why I might get the following type error? https://gist.github.com/stevenfontanella/77f78fa41c26a46ef2627887d23640e3
16:42:01 <chew2> code is here in case you want to look https://gist.github.com/stevenfontanella/811f3e1799b020a8e0d2f1ab65290eaa
16:42:35 <int-e> chew2: don't use . or $ with runST; use parentheses instead
16:42:49 <chew2> oh really? I'll try
16:43:00 <dminuoso> int-e: $ is fine with runST
16:43:10 <int-e> dminuoso: I know, I simplified.
16:43:11 <chew2> wow that worked
16:43:25 <chew2> why would . not work?
16:43:27 <int-e> chew2: The problem is, basically, that for this code to type-check, a type variable of (.) would have to be instantiated with a rank-2 type, and ghc doesn't do that.
16:43:41 <chew2> ok interesting
16:43:43 <int-e> The same would be true for ($), except ghc has an ad-hoc hack to make this one function work.
16:44:01 <chew2> thanks int-e 
16:44:59 <dminuoso> int-e: It's interesting that GHC doesn't complain about lack of impredicative types though.
16:46:23 <int-e> chew2: So I guess the alternative is to exploit the hack to its fullest and replace all the . by $.
16:46:41 <chew2> agreed, I ended up doing that
16:47:13 <int-e> (is it enough to just do that for the . immediately after the `runST`?)
16:48:48 <chew2> yeah it is
16:49:16 <chew2> it works with runST $ (f1 . f2 ...) or runST $ f1 $ f2 ...
16:49:39 <dminuoso> What was the hack GHC employed to make ($) work? Does it just make ($) disappear?
16:50:17 <nshepperd> foo . runST $ bar doesn't work
16:50:28 <nshepperd> foo . bar $ runST $ baz works though
16:59:27 <int-e> Hmm, mixing $ and (.), I've been wondering, am I alone in *liking* things like   return $ f . g . h $ x  ? The point being that, mentally, I treat the `return $` as a single entity.
17:01:28 <int-e> Or maybe I should say that for me, ($) acts as punctuation there.
17:12:52 <dminuoso> int-e: I found that generally if ($) helps make code more readable than just parens, moving chunks onto separate binding helps more.
17:13:26 <dminuoso> `return (i x) .. where i = f . g . h` seems to be generally preferable
17:13:33 <int-e> dminuoso: then it would need a name... and an extra line. tedious.
17:13:37 <Tuplanolla> This sounds like a job for `BlockArguments`.
17:13:38 <dminuoso> heh
17:13:52 <dminuoso> Tuplanolla: That wouldn't help for the return case though, would it?
17:14:14 <Tuplanolla> What is that?
17:14:54 <mniip> names are hard
17:15:03 <int-e> But block arguments look ugly.
17:15:28 <int-e> (That's code for: "it's hard to adapt.")
17:15:32 <dminuoso> Tuplanolla: Well block arguments dont help in the case of `return $ f . g . h $ x`
17:16:12 <dminuoso> Unless I have miss something, they only help for cases where do-expressions, if-then-else expressions, lambda-expressions, etc. are arguments to functions themselves
17:16:27 <int-e> In any case, I meant  return $ f . g . h $ x  compared to  return . f . g . h $ x
17:17:24 <Tuplanolla> I think you should be able to write `pure do f . g . h x` with the `do` block indented to the same level as `x`.
17:17:46 <int-e> ... what.
17:18:49 <int-e> Tuplanolla: I would *hope* that to be parsed as  pure (do f . g . h) x, not  pure ((do f . g . h) x)
17:19:45 <shachaf> Wait, why?
17:19:58 <shachaf> I'd be surprised to have it parsed that way.
17:20:18 <int-e> Expectations? Also, I've never used BlockArguments.
17:20:32 <int-e> So I'm not familiar with its quirks.
17:20:35 <Tuplanolla> I'd try it, but I don't have GHC set up here.
17:20:49 <shachaf> Neither have I. But how would the ) get inserted between the h and the x?
17:20:58 <shachaf> Oh, wait.
17:21:08 <shachaf> I didn't read the whole sentence, never mind.
17:21:17 <nshepperd> just prefix every identifier with do
17:21:32 <Tuplanolla> Just `do` it.
17:21:34 <nshepperd> do pure do f . do g . do h do x
17:22:24 <int-e> nshepperd: That looks like a great argument against BlockArguments.
17:22:50 <int-e> . o O ( Can we make NoBikeshedding an alias for BlockArguments, please? )
17:23:02 <int-e> </silly>
17:23:37 <nshepperd>  > (+1) do (*2) do 3
17:23:39 <nshepperd>  7
17:24:11 <nshepperd> ($) is now obsolete :D
17:24:17 <int-e> Yeah, you're using do as $.
17:24:25 <Logio> I fear this will lead to `baby shark do do do` being legal syntax
17:24:40 <int-e> > do do do ()
17:24:42 <lambdabot>  ()
17:24:52 <int-e> doesn't even need BlockArguments
17:25:08 <Logio> right, so my fears are already true
17:25:09 <shachaf> i,i (+1) let in (*2) let in 3
17:26:14 <Tuplanolla> > let in case do not otherwise of qualified -> ({- -}) where
17:26:16 <lambdabot>  ()
17:27:21 <Axman6> :t ()
17:27:23 <lambdabot> ()
17:27:28 <Axman6> :t ( )
17:27:29 <lambdabot> ()
17:27:40 <Axman6> ... genuinely did not expect that to work
17:28:00 <Axman6> :t print :: Show a => a -> IO (   )
17:28:02 <lambdabot> Show a => a -> IO ()
17:28:22 <int-e> chomp!
17:30:13 <int-e> > ({-🥕🥒🥝-})
17:30:16 <lambdabot>  ()
17:31:50 <Tuplanolla> Syntax is my favorite thing.
17:38:04 <jle`> > baby shark (do do do do doodoo)
17:38:06 <lambdabot>  baby shark!
17:38:19 <jackdk> n000000
17:39:53 <Axman6> no no no no nooonooo
17:40:05 <mniip> https://cdn.discordapp.com/attachments/504358695971586049/676240501980135436/unknown.png
17:40:29 <nshepperd> mniip: hahaa
17:40:34 <hpc> wait a minute
17:42:07 <int-e> > let ( ) | ( \ ( ) -> ( ) -> ( ) ) <- ( ) = ( ) in ( )
17:42:09 <lambdabot>  ()
17:44:50 <mniip> :t \f (f -> x) -> x
17:44:51 <lambdabot> (t1 -> t2) -> t1 -> t2
17:45:00 <tuesta> .
17:45:19 <jle`> > let ( ) | ( \ ( ( \ ( ) -> ( ) ) -> ( ) ) -> ( ) -> ( ) ) <- ( ) = ( ) in ( )
17:45:21 <lambdabot>  ()
17:45:37 <int-e> :t \f g (g -> x) -> f x
17:45:39 <lambdabot> (t1 -> t2) -> (t3 -> t1) -> t3 -> t2
17:46:16 <jle`> :t \f (f -> g) (g -> x) -> f x
17:46:17 <lambdabot> (t1 -> t2 -> t1) -> t1 -> t2 -> t2 -> t1
17:46:30 <int-e> :t \f g (g -> (f -> x)) -> x
17:46:32 <lambdabot> (t1 -> t2) -> (t3 -> t1) -> t3 -> t2
17:46:51 <int-e> :t \f g (g -> f -> x) -> x -- oh don't need parentheses
17:46:53 <lambdabot> (t1 -> t2) -> (t3 -> t1) -> t3 -> t2
17:47:07 <Tuplanolla> :t \ x -> \ x -> x
17:47:09 <lambdabot> p1 -> p2 -> p2
17:47:14 <Tuplanolla> :t \ x x -> x
17:47:16 <lambdabot> error:
17:47:16 <lambdabot>     • Conflicting definitions for ‘x’
17:47:17 <lambdabot>       Bound at: <interactive>:1:3
17:48:06 <int-e> mniip: Funny. I guess this is proof that patterns do bind from left to right :)
17:49:03 <jle`> i know this might have been intended as nightmare code ish but i've done this
17:49:13 <mniip> :t \x (($ x) -> g) (($ x) -> ($ g) -> f) -> f
17:49:15 <lambdabot> a1 -> (a1 -> a2) -> (a1 -> a2 -> b) -> b
17:49:33 <jle`> i understand it more as `\f (f -> x) -> x` is suglar for \f -> \(f->x) -> x
17:49:51 <jle`> but i've written functions like `myFunction f (f->x) y z = ...
17:50:23 <tuesta> .
17:50:30 <mniip> tuesta, hello?
17:50:39 <jle`> well, with more descriptive parameter names :)
17:50:56 <mniip> hmmmmm
17:51:05 <jle`> i like to think that my expression was the last straw in tuesta nope-ing out of haskell
17:51:27 <Tuplanolla> Why do we have empty `let`, `case` and `where`, but no empty lambda?
17:52:21 <int-e> jle`: It's not the most unnatural pattern.
17:52:37 <Axman6> :t \case
17:52:39 <lambdabot> p1 -> p2
17:52:44 <Axman6> ...
17:52:53 <mniip> :t let h (h -> x) = x in h
17:52:55 <lambdabot> t1 -> t2
17:53:06 <Axman6> :t fmap (\case)
17:53:07 <lambdabot> Functor f => f a -> f b
17:53:15 <int-e> Tuplanolla: Because before \case, lambdat was purely 1-ary?
17:53:17 <jle`> :t vacuous
17:53:18 <lambdabot> Functor f => f Void -> f a
17:53:32 <shachaf> What a ridiculous language.
17:53:37 <jle`> > [vacuous, fmap (\case)]
17:53:38 <int-e> Tuplanolla: so you're comparing n-ary things to a unary thing
17:53:39 <lambdabot>  error:
17:53:39 <lambdabot>      • No instance for (Typeable f0)
17:53:40 <lambdabot>          arising from a use of ‘show_M125213368611120819418925’
17:53:45 <jle`> :t [vacuous, fmap (\case)]
17:53:46 <lambdabot> Functor f => [f Void -> f a]
17:54:00 <Tuplanolla> I mean that `\ -> x` should be `x`, just like `do x` is `x`, int-e.
17:54:04 <shachaf> int-e: What do you mean? \x y z -> has always meant \x -> \y -> \z ->
17:54:07 <jle`> although i guess with -XBlockArguments we could even write [vacuous, fmap \case], which is kinda weird
17:54:23 <jle`> or ... awesome?
17:54:30 <int-e> shachaf: Oh, that kind of empty lambda. Sorry, thinking in the wrong dimension.
17:55:19 <mniip> @let  fdr f z (f -> u : fdr f z -> u -> r) = r; fdr _ z _ = z
17:55:19 <lambdabot>  Parse failed: Parse error in pattern: fdr
17:55:21 <int-e> Tuplanolla: tbf, empty cases are an extension as well
17:55:31 <jle`> Tuplanolla: ah, like a base case for \x -> .., \x y -> ..., \x y z -> ..
17:55:33 <mniip> @let  fdr f z ((f -> u) : (fdr f z -> u -> r)) = r; fdr _ z _ = z
17:55:33 <lambdabot>  Parse failed: Parse error: ->
17:56:01 <Tuplanolla> > \-> "like this"
17:56:04 <lambdabot>  <hint>:1:1: error: parse error on input ‘\->’
17:56:10 <d34df00d> newhoggy: actually, how would you go about counting the words in broadword programming approach?
17:56:12 <int-e> So let and where were different from case and lambda, originally.
17:56:14 <mniip> % fdr f z ((f -> u) : (fdr f z -> u -> r)) = r; fdr _ z _ = z
17:56:15 <yahb> mniip: 
17:56:19 <d34df00d> I scratched my head for a little and I'm not sure.
17:56:39 <mniip> % fdr (++) "baz" ["foo", "bar"]
17:56:40 <yahb> mniip: "foobarbaz"
17:56:40 <Tuplanolla> :t (\->)
17:56:42 <lambdabot> a -> a
17:57:03 <int-e> Tuplanolla: Empty cases were added basically out of necessity (to bettwe accomodate empty data types and impossible cases when matching GADTs)
17:57:26 <int-e> necessity overrules sanity :P
17:57:36 <jle`> Tuplanolla: nice
17:58:23 * hackage cpkg 0.2.4.4 - Build tool for C  https://hackage.haskell.org/package/cpkg-0.2.4.4 (vmchale)
17:58:41 <int-e> > (\-> ())
17:58:44 <lambdabot>  error:
17:58:44 <lambdabot>      • No instance for (Typeable t0)
17:58:44 <lambdabot>          arising from a use of ‘show_M300116943686788104919057’
17:58:51 <int-e> Oh, right.
17:58:58 <int-e> That was stupid :)
17:59:07 <int-e> Too bad though.
17:59:18 <mniip> d34df00d, context?
17:59:25 <int-e> > (() \->)
17:59:27 <lambdabot>  ()
18:00:17 <d34df00d> mniip: reimplementing wc.
18:01:23 <d34df00d> Namely, https://github.com/haskell-works/hw-wc as a follow up to my https://github.com/0xd34df00d/hwc/ which is basically code for https://0xd34df00d.me/posts/2020/02/destroying-c-with-20-lines-of-haskell.html which is a reply to somebody else's post (second paragraph there).
18:02:08 <mniip> Tuplanolla, if 'f = \a b c -> x' means the same as 'f a b c = x' and 'f = \ -> x' means the same as 'f = x' then 'f = (Just \) -> x' should be 'Just f = x'
18:02:37 <iqubic> What are we doing here?
18:02:40 <shachaf> DESTROYING C!
18:02:45 <iqubic> What the heck is this syntax?
18:02:56 <shachaf> Poor old C can't keep up with modern super-fast Haskell.
18:03:14 <edwardk> =P
18:03:52 <iqubic> I don't understand the 'f = \ -> x' thing.
18:04:09 <mniip> that's not real syntax
18:04:25 <mniip> hi ed
18:04:32 * edwardk waves
18:04:49 <iqubic> How's life going for you Edward?
18:04:49 <d34df00d> shachaf: agreed, bad heading, but, dunno, what's would be a stronger adjective than "beating" that's in the original post?
18:05:11 <iqubic> edwardk: Any new updates on Candenza?
18:05:19 <shachaf> Beating one program with another program?
18:05:23 <edwardk> iqubic: not bad, trying to figure out a decent story of how to compile a joint haskell/rust project at the moment without turning to something like bazel or whatever which would cripple me and require me to give up all my nice backpacky bits
18:05:37 <shachaf> Don't make it about the languages.
18:05:38 <edwardk> iqubic: yeah, we figured out a trampoline story i don't hate
18:05:49 <mniip> you could say life is going ed-ward
18:05:50 <mniip> :P
18:06:07 <shachaf> If you're going to be putting work into optimizing a Haskell program, put the same work into optimizing a C program. It's just unfair benchmarking otherwie.
18:06:43 <mniip> I bet I could write a faster wc if I wanted to
18:06:56 <d34df00d> I've spent about half an hour optimizing the haskell version. I bet coreutils folks spent more on wc.
18:07:06 <int-e> d34df00d: "We’ve significantly reduced the time spent in kernel" <-- I suppose you've moved the kernel time to page faults which are harder to attribute and measure (can we measure time spent in page fault handling?).
18:07:06 <d34df00d> (although I'm indeed cutting corners somewhere, and that's mentioned in the post)
18:07:09 <iqubic> edwardk: What's a trampoline story?
18:07:11 <edwardk> iqubic: basically we figured out how to trampoline reasonably well using a horrible trick involving a bloom filter
18:07:34 <shachaf> I bet if you spend half an hour writing a simple 20-line C program it'll beat the simple 20-line Haskell program.
18:07:41 <iqubic> Sounds complex
18:07:59 * mniip eyes xmmintrin.h
18:08:06 <edwardk> we need to support arbitrary tail calls as we're using it for a functional language, but trampolines (functions that do while ((f = f()) != null) {} or the like) are super slow in java
18:08:07 <d34df00d> int-e: isn't page fault handling counted as kernel time?
18:08:19 <d34df00d> mniip: https://github.com/0xd34df00d/counting-chars/blob/master/main.c
18:08:24 <edwardk> (and other languages)
18:08:29 <int-e> mniip: maybe not half an hour?
18:08:43 <mniip> disgusting
18:08:43 <edwardk> so i want to figure out a way to get tailcalls optimization that doesn't suck
18:08:44 <mniip> I love it
18:08:54 <d34df00d> shachaf: nah, I'd probably be debugging segfaults and what not still.
18:09:16 <d34df00d> mniip: yeah, that's basically a playground for a faster implementation of ByteString's count.
18:09:20 <iqubic> edwardk: Does the JVM support TCO natively?
18:09:21 <d34df00d> Their current implementation is the _naive function.
18:09:26 <shachaf> OK, if a C programmer did it.
18:09:33 <edwardk> the new approach gives every closure a hash (java objects come complete with a convention hashCode()!) and breaks that hash up into 5 6 bit values i can use as hashes for a bloom 64 bit bloom filter
18:09:49 <edwardk> iqubic: no, but you can trick truffle into doing it by using exceptions for control flow and letting the jit help
18:09:59 <iqubic> Sounds cool.
18:10:03 <edwardk> the issue is something like figuring out when the same closure is above you on the stack,
18:10:10 <edwardk> so we use a bloom filter of the closures to approximate this
18:10:15 <edwardk> with a fall back on first failure
18:10:22 <edwardk> to do the slower path
18:10:25 <iqubic> Functional programing on the JVM is going to be awesome.
18:10:28 <edwardk> and this seems to be working well enough
18:10:35 <d34df00d> Ok, I need some bits sorcery advice here. How do I get 1 if two higher bits of a word are 10, and 0 otherwise, without branching?
18:10:48 <edwardk> so we get a small false positive rate, which causes us to use the expensive trampoline fallback sometimes
18:10:54 <Axman6> d34df00d: you doing urf-8 decoding?
18:11:01 <Axman6> utf-8*
18:11:01 <d34df00d> Axman6: not decoding, just counting.
18:11:04 <d34df00d> I don't need full decoder.
18:11:09 <d34df00d> Just wanna count the chars.
18:11:12 <edwardk> there are some dodges that might work around it, like loop peeling a few times before we start to use the TailCallException trick
18:11:12 <jle`> d34df00d: 1 like the integer in-memory?
18:11:16 <Axman6> Have I got come code for you!
18:11:18 <mniip> !!((x ^ 0x80000000) >> 30)
18:11:28 <d34df00d> jle`: like Word8, rather, but yeah.
18:11:29 <edwardk> which would directly reduce the pressure on the false positive code path
18:11:29 <shachaf> !! sounds pretty branchy to me.
18:11:38 <mniip> no?
18:11:59 <Axman6> d34df00d: https://github.com/text-utf8/text-utf8/pull/1
18:12:05 <mniip> test + setc
18:12:24 <shachaf> I guess it depends on your application.
18:12:26 <Axman6> roughly 100x faster than the stream based versions
18:12:52 <edwardk> iqubic: this is the current hardest part of cadenza right now
18:13:11 <mniip> in haskell tho
18:13:12 <mniip> hmm
18:13:15 <edwardk> acertain may take some time and write a small dependently typed version of the thing now that we have the bulk of it working
18:13:35 <edwardk> meanwhile i'm over in rust playing around with universal b-trees and cache-oblivious lookahead arrays
18:13:48 <d34df00d> Axman6: aha, I get the idea.
18:13:50 <mniip> signum ((x `xor` 0x80000000) `shiftR` 30)
18:13:52 <shachaf> edwardk: Universal B-trees?
18:13:53 <d34df00d> Thanks.
18:13:56 <iqubic> What's acertain?
18:14:07 <iqubic> Also, dependent types sound good, in theory.
18:14:31 <Axman6> d34df00d: the really cool bit of that code is you can count how many continuation bytes you have one word at a time, using only masks, shifts and multiplies
18:14:52 <Axman6> the multiplication bit is definitely the cooleat bit
18:15:06 <edwardk> shachaf: b-trees holding morton ordered data
18:15:25 <shachaf> edwardk: Oh, this is about multidimensional queries.
18:15:37 <shachaf> Is the actual data structure the same?
18:16:06 <edwardk> shachaf: normally, yes.
18:16:10 <d34df00d> shachaf: also, you know the saddest part.
18:16:21 <d34df00d> The more click-baitey the title, the more folks discuss it, the more feedbackI get.
18:16:22 <edwardk> here i'm trying to do something where i use a stratified b-tree or COLA instead so its a bit strange
18:16:24 <d34df00d> Encouraging click-bait.
18:16:26 <shachaf> I wrote a B+ tree in C recently and it's way faster than anything I compared it to. It's great.
18:16:39 <d34df00d> Compare that to another post of mine called "Writing a fast edit distance implementation" — nobody cares cause it's boooring.
18:16:57 <shachaf> d34df00d: Hmm, good point. I'm going to counteract that by refusing to talk to you about this program.
18:17:10 <d34df00d> Pls talk to me on that other one then!
18:17:14 <edwardk> COLA = the deamortized version of the cache oblivious maps i like in haskell w/ a fractal index to kill the extra log factor
18:17:23 <mniip> 1 shachaf vs hundreds of ppl who take the bait
18:17:41 <shachaf> mniip: I know which one I'd rather have!
18:17:55 <mniip> and it's not the shachaf
18:17:58 <d34df00d> Given that it's a strictly monotonic measure... (I know no folks who would like to discuss boring titles because they are boring)
18:18:06 <edwardk> you can theoretically replace a stratified b-tree with the 2-3-based binary number system i like, which would get you a much more 'functional' datastructure for multiple snapshot use
18:18:23 <shachaf> Wait, you're making a persistent B-tree?
18:18:33 <shachaf> That seems like a pretty bad combination.
18:18:45 <iqubic> That's what I was thinking.
18:19:07 <mniip> speaking of arcane hackery
18:19:21 <mniip> does anyone know of an easy way to test a program against  bunch of versions of linux
18:19:59 <edwardk> shachaf: persistent b-trees have been done
18:20:04 <mniip> although this is probably not relevant to #haskell...
18:20:09 <MarcelineVQ> mniip: can you pick your linux with travis/someci?
18:20:16 <edwardk> shachaf: the stratified b-tree stuff and cow trees have already been solved basically
18:20:18 <d34df00d> mniip: put a post with a click-bait title claiming the program does something impossible.
18:20:21 <Axman6> dockerdockerdocker
18:20:26 <shachaf> edwardk: Sure, it's not conceptually difficult, it just seems like you'd give up a lot of the benefits.
18:20:47 <edwardk> nah, you can fix basically all the asymptotics, surprisingly
18:20:56 <edwardk> in a cache oblivious manner to boot
18:21:01 <edwardk> so you don't have to even fix B
18:21:10 <shachaf> Sure, but the point of B-trees isn't the asymptotics in the first place.
18:21:14 <edwardk> so my question is is there an universal cache oblivious persistent b-tree variant
18:21:21 <mniip> I mean I currently have the linux kernel tree checked out at one version and I'm running it in qemu, but I'm afraid I'd have to juggle a lot of build toolchains to get all versions to build
18:21:28 <edwardk> the point of a B-tree _is_ the asymptotics, just measured in the IO model
18:21:28 * Axman6 ... in which Edward Kmett shows how to have your cake and eat it too, again
18:21:38 <edwardk> I want them measured in a cache oblivious model
18:21:38 <edwardk> =P
18:21:39 <iqubic> mniip: What are you doing that need to be tested against many verions of Linux.
18:22:02 <mniip> testing undocumented features in the ABI
18:22:54 <shachaf> Here's my mega-clickbaity article about B-trees: https://shachaf.net/w/b-trees
18:23:27 <edwardk> if you assume the IO model and ephemeral usage, its hard to beat a b-tree. the cache oblivious versions start to work well when you start exceeding working memory size (see acunu or tokudb's writings on the topic)
18:23:36 <shachaf> I'll get hundreds of angry emails about that sort of title, no doubt.
18:23:54 <edwardk> but they remain competitive up til that point, but the main thing about the cache oblivious versions are that they are way easier to write in many ways
18:23:58 <d34df00d> Sorry, I sent 99 of them.
18:24:15 <shachaf> If you have B-trees with a large page size, your tree depth is going to be, y'know, 3 or 4.
18:24:28 <shachaf> That's not asymptotics at that point. It's just about the constants.
18:25:19 <mniip> that reminds me the story with indices in DBs
18:25:34 <edwardk> shachaf: the asymptotics are w.r.t. an IO model with a fixed sized managed cache for holding onto those pages. the cache oblivious model versions are good in that they don't need to knjow how many pages you have in the cache or require you to manage them, therefore they work for all those OTHER caches own your system that you don't know about
18:25:37 <mniip> how with a sparse index you could end up with indices taking more space than the data itself
18:25:55 <shachaf> Hmm, I take back everything I said, I think persistent B-trees can be reasonable in some applications.
18:26:58 <edwardk> think of something like a datalog where you have an edb that has your base facts and an idb of rules. you want to dump the consequences of those rules into a table to get an expanded edb, but what happens when you have lots of candidate rule sets
18:27:22 <mniip> it's funny how we talk about all these tricky performance improvements from carefully working around the cache, but running a program from a different directory can change its performance by 10%
18:27:32 <edwardk> or consider my use of a database to back equality saturation, but now in the presence of deletes, etc. where i may have multiple copies of the database running around, all in different states
18:27:53 <edwardk> the 'snapshot' functionality is useful for different isolation modes for database transactions, etc.
18:28:57 <shachaf> I don't know how people do cache-oblivious B-trees. I'd be curious whether they could actually beat the standard kind in practice.
18:30:03 <d34df00d> mniip: I have some even weirder performance-related stuff that no folks here who tried can reproduce.
18:30:28 <mniip> I mean it's obvious
18:31:00 <mniip> ABIs/APIs hide a lot of implementation details that tend to resurface once we question performance
18:31:46 <edwardk> shachaf: the original COLA-based tokudb was basically competitive while the 'spine of the index' fit in memory, so you only needed to pay for a single memory access to get anything off disk, but once you went past that, that fractal index design crushed traditional b-tree performance. cow b-trees are a little worse, stratified b-trees bring them back up to COLA performance and give you persistence for free
18:32:34 <edwardk> http://supertech.csail.mit.edu/papers/sbtree.pdf take a look at the charts near the end for early COLA benchmark results
18:32:53 <shachaf> Hmm, I was thinking of in-memory B-trees which have different tradeoffs.
18:33:57 <shachaf> I'm pretty skeptical of "full persistence for free" though I suppose something like that might be possible.
18:34:14 <edwardk> in memory the only extra caches you can win on are L{1-3}ish
18:34:37 <edwardk> you don't hit that performance cliff that they show in the paper
18:34:52 <shachaf> Yep.
18:35:00 <edwardk> because you never blow out main memory and can fit everything in the page cache
18:35:41 <iqubic> I have no idea what you're talking about anymore.
18:35:58 <mniip> memory is complicated
18:36:39 <edwardk> iqubic: b-trees are great for block-based IO. in a 1980s like model where you have one cache between you and the data and you have full programmatic control of that cache, they are optimal for tons of things
18:36:54 <iqubic> the phenomenon known by some as "edward lag" is afflicting me.
18:37:01 <shachaf> OK, is this just about not having to read from disk to do inserts?
18:37:44 <mniip> I wonder if reading around %rsp is faster than reading from L1
18:37:49 <edwardk> there are refinements to b-trees. do you link sideways between nodes? do you strip common prefixes off string keys? do you allow for moment-in-time persistent snapshots so you can proceed with one transaction while another reads? what happens when you don't know about the page size you should be using for your disk?
18:38:21 <edwardk> the original model assumed i controlled all the memory on the system and could afford to manage it for the database, but really we rarely dedicate a machine to the database any more for most applications
18:38:32 <edwardk> its usually some sqlite thing we crapped into an application with a different purpose
18:38:32 <shachaf> mniip: You mean memory renaming?
18:38:52 <edwardk> why should we be using all the memory for caching data we aren't looking at?
18:38:54 <mniip> I mean how modern CPUs optimize access on the stack
18:39:01 <iqubic> edwardk: Are you implementing any of this in Haskell?
18:39:09 <edwardk> the nice thing to me about cache oblivious database variants is they are good in the presence of multiple users of the system
18:39:26 <mniip> I've heard that it behaves like extra registers, but I haven't verified myself
18:39:44 <edwardk> iqubic: most of this is stuff i worked on years ago, at the moment i'm playing around in rust with some of this because i need to invoke something like this from haskell, but the code is probably going to be c++ or rust
18:39:47 <shachaf> I think very recent Intel and AMD CPUs do a thing like that, from what I heard.
18:40:19 <mniip> rust HKT when
18:40:20 <iqubic> do we have haskell to C++ or Haskell to Rust FFI?
18:40:35 <Axman6> all the world is (at) C
18:40:46 <mniip> nothing has C++ FFI because C++ ABI is not standardized in any fashion
18:40:48 <edwardk> iqubic: you can pretty easily ffi to c++ from inline-c-cpp
18:41:03 <mniip> everything goes via C
18:41:03 <edwardk> i do a fair bit of it in the codex repo
18:41:09 <shachaf> C is so good. I'm using C instead of C++ or Rust or whatever and it's great.
18:41:16 <mniip> I bet inline-c uses extern "C"
18:41:17 <shachaf> The types are so higher-kinded you have no idea.
18:42:11 <dibblego> shachaf on hyper-kindness
18:42:25 <mniip> :k (->)
18:42:27 <lambdabot> * -> * -> *
18:42:29 <mniip> three-star programming
18:42:33 <edwardk> iqubic: e.g. https://github.com/ekmett/codex/blob/master/freetype/src/Graphics/FreeType.hsc#L455
18:43:02 <d34df00d> iqubic: I managed to call C++ code from Haskell, but it ended up being painful.
18:43:06 <d34df00d> Although there's inline-c-cpp.
18:43:10 <edwardk> mniip: inline-c-cpp sets up little c convention calling shims that internally do whatever c++ you need
18:43:22 <mniip> so as I said, via C
18:43:36 <shachaf> Even if C++ did have a standard ABI, I can't imagine why anyone would want to call it.
18:43:39 <d34df00d> But figuring out how to set proper optimization flags for inline-c-cpp gave me headache.
18:43:44 <mniip> shachaf, exceptions
18:43:50 <d34df00d> shachaf: most of my non-haskell code is C++.
18:43:59 <mniip> also return value optimization
18:44:00 <shachaf> C ABIs are much simpler and more usable.
18:44:07 <d34df00d> (although I'd rather it be idris or smth)
18:44:18 <edwardk> i use a mishmash of inline-c-cpp, hsc2hs (which should soon support hscpp files!) and classic ffi to talk to c++ libraries. my next step will be going in through libclang to produce more of it automatically
18:44:34 <d34df00d> > which should soon support hscpp files!
18:44:36 <lambdabot>  <hint>:1:39: error:
18:44:36 <lambdabot>      parse error (possibly incorrect indentation or mismatched brackets)
18:44:39 <d34df00d> edwardk: oh, that's so awesome!
18:44:41 <mniip> to think of it, at work the only non-haskell code I've written was shell
18:44:49 <d34df00d> No more pain of manually wrapping C++ code in extern "C" stuff!
18:45:11 <shachaf> Certainly you want to disable C++ exceptions if you possibly can. Putting them in your ABI would be ridiculous.
18:45:14 <edwardk> d34df00d: turns out it really only took passing the arguments in the other order from cabal!
18:45:28 <edwardk> so you could explicitly ask for the produced code generation file to be parsed as c++
18:45:47 <d34df00d> Incidentally I was playing around with calling C++ code from Haskell to do something funny with the C++ API of libclang (which is richer than the C one), so we've come full circle here.
18:45:49 <edwardk> and poof, now you can include c++ headers and do all the hsc2hs things
18:45:54 <shachaf> C code is also faster and safer than C++ code.
18:46:05 <d34df00d> shachaf: you're trolling with "safer".
18:46:06 <edwardk> shachaf: you'd like rust. no exceptions ;)
18:46:32 <mniip> C has great exception handling mechanisms
18:46:46 <shachaf> d34df00d: Hmm, I think it's pretty likely that C code is safer than C++ code.
18:46:49 <d34df00d> Also the "faster" point is questionable (unless that's generated C, where you can afford to offload making your primitives abstract enough to a higher language).
18:46:58 <edwardk> std::mem::size_of::<[();10000000000000000000000]>() = 0 still makes me happy (the size of an array of a gajillion units = 0)
18:47:05 <shachaf> I agree that faster is questionable.
18:47:22 <shachaf> It's only true in practice, rather than in theory.
18:47:35 <d34df00d> I mean, at work I'm relying heavily on templates to do something like OOP at compile time to make sure the compiler has a chance to inline everything together.
18:47:37 <mniip> edwardk, is that an unboxed unit or something
18:47:51 <edwardk> finally breaks the fact that sizeof an empty struct isn't required to be >= 1, unlike c/c++
18:47:57 <d34df00d> I cannot think how I'd write all that in C, like, manually, without making things either terribly error-prone or opaque to the compiler.
18:48:17 <mniip> d34df00d, just use a bunch of macros
18:48:29 <mniip> macros are great
18:48:37 <d34df00d> mniip: good luck writing that. I'd hand in my two-weeks notice if I were told to write that in macros.
18:48:45 <d34df00d> or with macros
18:48:46 <shachaf> edwardk: In GNU C sizeof (struct {}) is 0.
18:48:46 <mniip> heck, write your own preprocessor
18:48:47 <d34df00d> or whatever.
18:49:02 <monochrom> I'll follow mniip's footsteps and say: C has great macro systems. :)
18:49:02 <d34df00d> mniip: this is why I mentioned the "codegen" part.
18:49:16 <mniip> you can use an old version of GHC as a preprocessor
18:49:59 <d34df00d> Incidentally again, I did some Template Haskell earlier today to make sure ghc can see all the instantiations of a polymorphic function and specialize them accordingly, since doing that at run-time was just meh (see https://stackoverflow.com/questions/60065469/using-existentials-to-lift-values-to-types-without-hurting-performance for more context)
18:50:34 <d34df00d> Too bad I can't use TH to generate SPECIALIZE pragmas.
18:50:42 <mniip> you can't?
18:50:48 <d34df00d> Hold on, I can.
18:50:50 <d34df00d> Great!
18:50:53 <d34df00d> Yay!
18:52:31 <edwardk> shachaf: sorry yeah, gcc gets it right, but then g++ has to go and make it 1
18:52:34 <edwardk> http://www.stroustrup.com/bs_faq2.html#sizeof-empty
18:52:46 <edwardk> in standard c it is just a syntax error
18:52:53 <shachaf> Yep, that's C++ for you.
18:53:31 <mniip> quiz: sizeof 'a' = ?
18:53:40 <d34df00d> Depends.
18:53:45 <edwardk> but then c++ encourages you to pass these damn things all over as arguments to emulate named constructors
18:54:11 <iqubic> C++ is a hot bowl of wack.
18:54:20 <edwardk> this is basically my axe to grind of the day
18:54:21 <d34df00d> True.
18:54:27 <d34df00d> I'm burned out of C++.
18:54:30 <d34df00d> Do not want it anymore.
18:54:54 <mniip> I would pick up rust but no HKT
18:55:00 <edwardk> was pleased to see it sanely handled in rust by the simple expedient of making pointer arithmetic so hard to do that nobody does it
18:55:07 <d34df00d> I'll probably quit my current job soon and start looking for something purely Haskell-ish (or similar), preferably with some research component to it.
18:55:32 <mniip> d34df00d, would offer my place but your timezone placement is unfortunate
18:56:18 <d34df00d> mniip: Moscow?
18:56:22 <mniip> yea
18:56:26 <d34df00d> Yeah, unfortunate.
18:56:38 <mniip> I mean we do remote
18:56:46 <mniip> but within reasonable TZ
18:56:47 * edwardk looks on hackage and sees lens-core and gives up.
18:56:57 <d34df00d> Melodic post-lens-core.
18:57:11 <edwardk> look yet another copy-pasta version of my code that looks kinda officially like i was involved in some fucking way
18:57:44 <jackdk> they're all by the same guy, too.
18:58:12 <edwardk> yeah
18:58:22 <d34df00d> mniip: I'm probably out of the MSR league (no formal methods PhD, ugh), but I'm thinking of pinging a friend of mine there to see if I'll have a chance for an internal transfer eventually if I get into the regular MS without the R.
18:58:44 <d34df00d> But we'll see anyway.
18:58:50 <mniip> pensive bread
18:59:04 <d34df00d> wat
18:59:22 <d34df00d> Ah I see.
18:59:23 <d34df00d> Memes I missed.
19:00:36 <mniip> d34df00d, just get simon to vouch for you ;)
19:00:49 <d34df00d> I'll need to get him to know me first lol.
19:01:35 <mniip> hacking on GHC is the way to go
19:02:03 <d34df00d> That's one way to go, yea.
19:02:14 <mniip> or coauthor with him ;)
19:03:08 <d34df00d> I'll probably start with something close — a small research project somewhat related to type theory that somebody gifted me the idea of. I'll probably get to it full-time once I quit my current place (which is like really gonna be soon).
19:04:21 <mniip> I started a research project recently too :
19:04:23 <mniip> :O
19:04:32 <d34df00d> What're you working on?
19:04:51 <mniip> right now just looking into categorical semantics of parametricity
19:04:58 <mniip> with possible insights into gadts and hkt
19:05:36 <d34df00d> That's some quite cool stuff!
19:06:24 <mniip> like, relational semantics are quite trivially extended to various interesting lambda calculi
19:06:28 <mniip> but relational semantics ugly af
19:06:51 <mniip> profunctors are colloquially known to be somewhat related
19:06:56 <mniip> but they don't capture the idea exactly
19:07:19 <mniip> (other than the trivial case of  int_X Hom(FX, GX) = Nat(F, G)  and its relatives)
19:34:00 <iqubic> Profunctors are cool
19:42:53 * hackage sensu-run 0.7.0.5 - A tool to send command execution results to Sensu  https://hackage.haskell.org/package/sensu-run-0.7.0.5 (MitsutoshiAoe)
20:32:09 <cole-k> what is the time complexity for `\xs n -> take n $ sort xs`?
20:32:59 <cole-k> does the implementation of sort have to sort the full list before i can take the `n` smallest elements?
20:33:36 <cole-k> if so, is there a readymade alternative i can use
20:33:37 <Axman6> it uses a lazy merge sort, so IIRC it's O(k log n) (where k is your n here)
20:33:48 <cole-k> thanks Axman6 
20:34:48 <Axman6> since it's a lazy merge sort, it will do the minimum possible work to give you the first k items - so take 1 . sort is O(n) ... which probably means I got my complexity wrong
20:38:00 <Axman6> it should O(n log k) I think
20:38:24 <Axman6> complexity is hard and I should stop
20:48:28 <suzu> i think that's right
20:48:41 <suzu> it's a mergesort, and if you're taking k elements out of a list of n then it's n log k
20:52:15 <int-e> should be n + k log n
20:52:55 <sim590> Can't I nest `|` conditionals like this https://paste.debian.net/1129977/ ? I'm having syntax error on the second line ....
20:53:13 <int-e> no
20:54:10 <sim590> :/ It could be fun if we could. I guess the only thing I can do is to use if/else in there.
20:54:31 <Axman6> MultiWayIf
20:54:35 <sim590> What if I had lots of nested conditionals? I'd have to use if/else ?
20:54:57 <chew2> maybe put it in a where clause?
20:55:03 <Axman6> lots of conditionals mean make a new enum type, not using lots of Bools
20:55:22 <Axman6> one constructor per alternative
20:56:06 <sim590> Alright. Thanks!
20:57:12 <int-e> sim590: another thing that may do what you want is  case (pcAngle == 1, norm d < norm (pc - pb)) of (True, True) -> ...; (True, False) -> ...; (False, _) -> ...
20:57:46 <MarcelineVQ> :(
20:57:48 <int-e> (Relying on laziness and some compiler smartness for efficiency.)
20:58:48 <sim590> I see. Well. I have plenty of choices!
20:59:53 <Axman6> I find the enum per case works poarticularly well, you can give a name to each alternative which cvonveys some meaning - you still need a function to create those cases, but it now gives meaning to each combination of bools
22:24:53 * hackage VRML 0.1.0.0 - VRML parser and generator for Haskell  https://hackage.haskell.org/package/VRML-0.1.0.0 (junjihashimoto)
22:31:59 <davean> VRML is still a thing? 
22:52:00 <mac10688> Anyone familiar with Brick for tui development? I have a list of elements displayed in a list widget but when I call the page down function on the generic list, nothing happens
22:52:26 <mac10688> I tried replacing with list clear and reverse list and that works fine but reverse list only reverses the elements shown
22:52:49 <mac10688> however, I did some debugging and I know it's only showing half the of list that's really there
23:12:31 <alc> what's the different between String with Text?
23:12:53 <alc> if I want to handle ByteString, which one is better?
23:16:21 <alc> if I want to turn ByteString to Text with decoding UTF8, but that may contain invalid UTF8 characters, how to avoid exceptions?
23:16:52 <alc> toString can avoid that throwing exception by replace the invalid character, 
23:17:05 <alc> but I don't find it in Text
23:17:42 <davean> Data.Text.Encoding.Error
23:32:10 <jojojojojo> alc: Text is a "generally better" type for representing text -- iirc the two big things are that Text isn't character-wise lazy, and it's more unicode-smart
23:33:52 <jojojojojo> and it seems `decodeUtf8With` is what you want
23:35:18 <alc> jojojojojo: I don't understand that type onDecodeError
23:35:43 <alc> https://hackage.haskell.org/package/text-1.2.4.0/docs/src/Data.Text.Encoding.Error.html#OnDecodeError
23:36:26 <jojojojojo> String -> Maybe Word8 -> Maybe Char
23:36:28 <alc> jojojojojo: what Word8 and Char I should use?
23:37:09 <jojojojojo> Depends on your use case
23:37:11 <alc> decodeUtf8With :: OnDecodeError -> ByteString -> Text
23:37:30 <alc> type OnDecodeError = OnError Word8 Char
23:37:58 <alc> jojojojojo: do I need to set OnDecodeError?
23:38:03 <jojojojojo> type OnError a b = String -> Maybe a -> Maybe b
23:38:45 <alc> so it would be type OnDecodeError = String -> Maybe Word8 -> Maybe Char?
23:38:52 <jojojojojo> yep!
23:39:13 <alc> do I need to set it by myself?
23:39:55 <alc> I don't know what is the invalid character because that it's decoding in runtime
23:40:18 <jojojojojo> the invalid character gets passed in as the `Maybe Word8`
23:41:08 <alc> jojojojojo: then what's the point of String and Maybe Char here?
23:41:41 <alc> why not just decodeUtf8With :: Text -> ByteString -> Text?
23:41:50 <alc> that first Text as default for invalid character?
23:42:31 <jojojojojo> decodeUtfWith (\ _ _ -> Some t) would be the same as that
23:43:16 <jojojojojo> the Maybe Word8 allows you to do different recovery for different inputs, and the Maybe Char lets you skip the output
23:43:22 <alc> Some t :: Maybe Char?
23:43:34 <jojojojojo> oh sorry
23:43:36 <jojojojojo> Just t
23:43:42 <jojojojojo> been writing rust ;)
23:44:44 <alc> but I need a Text, not Maybe Char...
23:45:08 <jojojojojo> you want to replace single character errors with multi character outputs?
23:46:05 <alc> jojojojojo: I want this https://hackage.haskell.org/package/utf8-string-1.0.1.1/docs/Data-ByteString-Lazy-UTF8.html#v:toString
23:46:15 <alc> Convert a UTF8 encoded bytestring into a Haskell string. Invalid characters are replaced with '\xFFFD'.
23:47:06 <alc> there should have toText...
23:48:33 <jojojojojo> I don't see anything in the current API that allows this
23:48:43 <jojojojojo> probably because that means you can't precompute length and allocate
23:48:57 <jojojojojo> but `pack . toString` will do this
23:49:37 <jojojojojo> it'll be slower but probably fine
23:49:45 <alc> jojojojojo: but that would be ByteString -> String -> Text...
23:51:24 <jojojojojo> like I said, it'll be slower than a specifically-designed thing
23:51:58 <jojojojojo> but it's not even obvious how to implement such a thing for Text in a way that's much better than going through Strign
23:52:02 <jojojojojo> String*
23:52:44 <alc> jojojojojo: so why String can have that desing and Text can't
23:52:58 <alc> what's the different?
23:54:08 <jojojojojo> String (ie, [Char]) is lazy and internally pure, which makes it really slow. Text is implemented with preallocated buffers and some unsafe/impure code underneath its interface
23:58:52 <jojojojojo> implementing the equivalent of toString for Text would probably require either reallocating the Text midway if things get too long, or preallocating 6*(len bs) bytes, both of which kinda suck
