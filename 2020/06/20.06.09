01:00:23 <aveltras> i'm facing issues while trying to use hasql-th (not sure the problem comes from this particuliar package) which i never met in the past. My ghc-pkg list correctly states that the version found is hasql-th-0.4.0.8 (latest) but when i browse it in cabal repl on my package, the interface exposed is the one from a much older version. any idea ?
01:03:48 <ph88> what's the go-to data type to store date and time ?
01:04:12 <[exa]> ph88: human datetimes or timestamps?
01:05:27 <ph88> time from a computer log
01:05:39 <ph88> i don't understand the choice between human datetimes and timestamps
01:06:37 <[exa]> ph88: timestamps are precise and simple (you can basically save unixtime) but lack interpretation (ie there's no "morning", and the number may mean something completely different in different timezones)
01:07:03 <[exa]> human dates are the usual Y/M/D h:m:s (+tz), with all the manipulation problems involved
01:08:09 <[exa]> anyway, timestamps are pretty good as just Ints, you can probably find a few named wrappers for that. Use whatever your library generates. For human dates there's Data.Time
01:12:00 <[exa]> for logs I'd go with SystemTime and UTCTime from that package
01:12:18 * hackage stripeapi 0.1.0.2 - Stripe-Library  https://hackage.haskell.org/package/stripeapi-0.1.0.2 (remo_doerig)
01:19:15 <fragamus_> hi I am trying to sort out a problem; can anyone tell me the url of lts-15.16 on raw.githubusercontent.com
01:22:00 <fragamus_> my stack is not finding it
01:24:22 <Uniaika> fragamus_: I don't think there was one
01:24:32 <Uniaika> the last one of the 15.x series I remember is the 15.15
01:24:42 <Uniaika> and now we're at 16.0
01:25:26 <Uniaika> oh my bad, there is one
01:27:04 <ph88> thanks [exa] 
01:39:32 <fragamus_> Uniaika: what is the url of it
01:40:12 <fragamus_> i think mine is improperly formatted or something that's why I am asking
01:45:05 <Uniaika> fragamus_: what's the URL you're using? And why are you using a URL instead of just writing out "lts-15.16" ?
02:00:19 * hackage hanspell 0.2.0.0 - Korean spell checker  https://hackage.haskell.org/package/hanspell-0.2.0.0 (9beach)
02:02:34 <fragamus_> I am not finding it I get a 404
02:03:35 <fragamus_> raw.githubusercontent.com//fpco/lts-haskell/master//lts-15.16.yaml
02:04:52 <fragamus_> stack looks for it at that url
02:14:12 <fragamus_> Uniaika^^^
02:15:14 <merijn> Is your stack binary up to date? (Maybe the URL moved?)
02:15:16 <fragamus_> Uniaika: was there a change in the way that url is formed?
02:15:36 <fragamus_> I am using an old stack 
02:15:49 <fragamus_> I have to use old stack
02:18:34 <Uniaika> weirdly enough, the 15.x series does not appear on commercialhaskell/lts-haskell
02:18:41 <libertyprime> Hey guys. How can I determine the version of ghc used when I execute 'stack exec -- runhaskell' for a given haskell snippet?
02:19:07 <Uniaika> libertyprime: You can fetch the version by running 'ghc --numeric-version'
02:19:29 <Uniaika> I don't know your exact usecase, what are you trying to do?
02:19:55 <libertyprime> When I run things with stack, it automatically selects a ghc version. I'd like to know what that version is
02:20:12 <libertyprime> That way, when it says missing module, I can install the module to that ghc version
02:22:35 <Uniaika> libertyprime: the GHC version is based on the LTS you're using
02:22:53 <Uniaika> are you using a stack project, or are you doing so while simply invoking stack?
02:23:13 <libertyprime> I'm not using a stack project. Just running some snippets
02:24:10 <libertyprime> Are you referring to the resolver: field in ~/.stack/global-project/stack.yaml
02:24:38 <merijn> libertyprime: That's not a workflow that's well supported by stack, tbh
02:25:06 <merijn> (granted, also not really well supported by v2-build yet :p)
02:25:28 <libertyprime> Hmm. Not being able to run snippets without creating a full blown project does make it hard.
02:26:24 <libertyprime> I'm not sure what my workflow should look like. Perhaps I should specify the version when I run
02:27:22 <Uniaika> libertyprime: yes, if you're not using a particular stack project, you should modify the resolver for the global project, though I advise you to create a stack project
02:27:25 <merijn> libertyprime: Stack's workflow is centered around projects, using a specific snapshot (which determines available packages and GHC version), it doesn't really support the idea of "a global GHC"
02:32:17 <Uniaika> libertyprime: also, read this: https://tech.fpcomplete.com/haskell/tutorial/stack-script/
02:32:33 <libertyprime> thanks so much. 
02:48:44 <random7897> what's a good way to concat string lazily in haskell? I want to do "a" ++ "dnkjgndgfjk", but not have it compute till I need the overall string
02:48:48 <random7897> is ++ lazy?
02:51:12 <merijn> random7897: Are you prepending?
02:51:27 <merijn> Or appending?
02:52:10 <random7897> Is prepend ":"? I can't prepend because the left expr doesn't necessarily translate to a string
02:52:17 <random7897> to a char*
02:52:19 <random7897> sorry
02:52:57 <merijn> random7897: Anyway, if you want to do efficient appending you probably wanna read up on DList: http://h2.jaguarpaw.co.uk/posts/demystifying-dlist/
02:54:49 * hackage hanspell 0.2.1.0 - Korean spell checker  https://hackage.haskell.org/package/hanspell-0.2.1.0 (9beach)
03:29:18 * hackage dobutokO4 0.3.0.0 - Helps to create experimental music. Uses SoX inside.  https://hackage.haskell.org/package/dobutokO4-0.3.0.0 (OleksandrZhabenko)
04:14:30 <petersen> BTW Stackage LTS 16 was released :-)
04:14:53 <Axman6> GHC 8.10?
04:15:25 <Uniaika> nope, Axman6 
04:15:27 <Uniaika> still 8.8.3
04:18:11 <phadej> I guess now starts the pruning to move nightly to 8.10
04:20:39 <Axman6> There's so much good struff in 8.10 I want to use
04:21:22 <phadej> don't use stack ;)
04:21:41 <phadej> or Stackage, draft your own snapshots
04:24:05 <Axman6> I'm happy with stack for apps, it reduces a lot of pain (or reduced, I haven't used new cabal stuff). 
04:24:24 <tdammers> indeed - between ghcup and cabal v2 commands, any use I ever had for stack has vanished
04:24:47 <tdammers> I can understand how stack makes for a more gentle initial learning curve though
04:29:12 <yushyin> there was recently a nice little reddit post about cabal usage https://lukelau.me/haskell/posts/making-the-most-of-cabal/
04:29:19 * hackage cabal2spec 2.6.1 - Convert Cabal files into rpm spec files  https://hackage.haskell.org/package/cabal2spec-2.6.1 (PeterSimons)
04:29:59 <yushyin> about snapshots and freeze files and more
04:34:31 <merijn> 70% of the pain I have with v2-build is stack user packages having broken bounds and 30% bounds not being bumped fast enough in dependencies when I want the bleeding edge GHC :p
04:36:37 <phadej> both are fixable to some degree locally. (latter more easily)
04:37:52 <phadej> We have yet to introduce "implication constraints", i.e. something like `pkg-without-bounds >= 0.1 && <0.2 ==> its-dependency <0.3`
04:38:13 <phadej> that ^ syntax is bad (difficult to parse)
04:38:49 <phadej> that would make the former fixable
04:40:05 <phadej> and for interested: it's hard to parse because `pkg-without-bounds >= 0.1 && <0.2` looks like normal constraint syntax
04:40:34 <phadej> and current parser will actually eat ==> and say it's invalid version-range operator
04:41:44 <phadej> Maybe I should dump that into cabal issue tracker
04:42:31 <maerwald> tdammers: windows is still slightly smoother with stack I hear?
04:43:25 <maerwald> How to install on windows without stack is still an unresolved discussion, afair
04:43:28 <merijn> maerwald: The GHC install on windows is a mess, currently, yeah
04:43:44 <phadej> well, stack doesn't offer you an installer either, AFAIK
04:43:46 <merijn> maerwald: Well, the current answer is "chocolatey", but IMO that's really not ideal
04:44:09 <maerwald> https://github.com/kakkun61/ghcups -- although there exists this, but it requires powershell "skills"
04:44:17 <phadej> oh, they do
04:44:19 <merijn> Maybe the new official package manager will work
04:44:24 <phadej> well, than.
04:45:35 <maerwald> merijn: if I knew windows I would write an installer that just uses chocolatey under the hood, because the details don't matter
04:45:35 <phadej> but, there's really only 1.9 people who put effort into improving Windows story for GHC in general
04:45:49 <phadej> everyone else are just complaining or moved from Windows (or both)
04:54:23 <tdammers> everything on windows is a mess, I think, yeah, but stack's mess is a more practical one
04:54:24 <merijn> I think the problem is that the people who most care about windows support/installer are also the people least capable of helping produce it, which is unfortunate
04:55:05 <tdammers> merijn: that, and the fact that an enormous amount of unixisms is built into the design of GHC etc.
04:55:43 <merijn> I was helping my girlfriend install on Windows, (which I just don't know enough about to be any help) and I found the chocolatey install process...less than helpful, so I ended up having her use stack instead, just so I didn't have to look into chocolatey
04:57:19 <maerwald> merijn: should have given ghcups a go
04:57:29 <maerwald> powershell isn't that hard, is it?
05:02:37 <phadej> ghcups just calls the chocolatey, isn't it?
05:02:43 <phadej> sounds like a cardbox
05:02:47 <maerwald> yep
05:03:25 <phadej> The last time I tried chocolatey, it all worked well enough.
05:04:20 <phadej> I then run into not-so-haskell specific windows problems
05:04:31 <phadej> so I count my experience as success
05:16:22 <lukelau> merijn: allow-newer is really useful for broken bounds
05:16:47 <lukelau> especially for packages that pin base to <= 4.13 or stuff like that etc
05:18:07 <phadej> don't ever use <= 
05:18:10 <phadej> >= and <
05:18:15 <phadej> > and <= is a smell
05:18:18 <lambdabot>  error:
05:18:18 <lambdabot>      • Variable not in scope: is :: Expr -> t0 -> [Bool] -> Bool
05:18:18 <lambdabot>      • Perhaps you meant one of these:
05:18:24 <phadej> lambdabot agrees
05:21:06 <lukelau> I’m a ^>= man myself
05:21:50 <dminuoso> phadej: why is that a smell?
05:22:22 <merijn> dminuoso: If you believe in the PVP you're bounding to stric
05:22:33 <merijn> dminuoso: or too lose
05:22:53 <phadej> because <=4.13
05:22:57 <phadej> permits 4.13 version
05:23:09 <merijn> dminuoso: Suppose you have a package written against the 0.14 version of package foo. According to the PVP that means we're compatible with anything 0.14.x
05:23:11 <phadej> it's 99.999% surely a mistake
05:23:31 <merijn> dminuoso: So "<= 0.15" would be wrong (0.15 isn't the same PVP interface)
05:23:34 <dminuoso> Ah I see.
05:23:52 <dminuoso> It's interesting that I didn't see this, even though it's obvious.
05:23:59 <merijn> dminuoso: But "<= 0.14.7" would be overly strict, since there's version large than that, smaller than 0.15 which should be compatible
05:24:05 <dminuoso> Right.
05:25:10 <phadej> well, even smaller than 0.14.8
05:25:14 <phadej> e.g. 0.14.7.1
05:26:46 <phadej> I have hard time figuring out the good use-case for <=. > is occasionally useful when you want to forbid an individual version, i.e. have `> x && <x` kind of version range
05:27:08 <phadej> but that's very rare - I remember I needed that, but don't remember where and hyw
05:27:11 <phadej> why*
05:27:12 <dminuoso> The code I write is much tighter in constraints, most of it is just `foo == 1.3.*`
05:27:25 <merijn> dminuoso: You can simplify that to "foo ^>= 1.3" :p
05:27:28 <dminuoso> But then again its mostly internal, so testing for broader compatibility is not worht it.
05:27:34 <dminuoso> merijn: I find that hard to read.
05:27:41 <dminuoso> But I am aware of it.
05:27:43 <merijn> dminuoso: But it's better!
05:27:59 <dminuoso> Sigh. You're gonna explain to me why, right?
05:28:26 <merijn> dminuoso: That just turns into the "normal" PVP bounds
05:28:41 <dminuoso> well, its only better if you ever specify smaller than a.b
05:28:58 <merijn> So whenever I'm writing code for myself I just default to ^>= with whatever version I have locally
05:29:08 <merijn> dminuoso: If you don't it's still not worse ;)
05:29:20 <dminuoso> Just harder to read. :)
05:30:11 <merijn> dminuoso: You can manage >>=, <$>, <$, $>, <*>, <>, >>, etc.
05:30:16 <merijn> I'm sure you'll manage ^>=
05:35:00 <MarcelineVQ> ^>= is just >= but it also applies to the line right above
05:46:48 * hackage dobutokO4 0.4.0.0 - Helps to create experimental music. Uses SoX inside.  https://hackage.haskell.org/package/dobutokO4-0.4.0.0 (OleksandrZhabenko)
05:52:00 <maralorn> Can someone recommend me good tooling for symbolic calculation? Bonus points for Haskell. But in the end I have just some huge formulas in the complex numbers and I need to doublecheck my pencil results.
05:52:25 <srk> sympy :(
05:54:22 <Chuan> ?src ($)
05:54:22 <lambdabot> f $ x = f x
05:55:04 <Chuan> ?src (Maybe)
05:55:05 <lambdabot> Source not found. Abort, Retry, Panic?
05:55:28 <Chuan> ?src (maybe)
05:55:29 <lambdabot> Source not found. And you call yourself a Rocket Scientist!
05:56:51 <maralorn> ?src Maybe
05:56:52 <lambdabot> data Maybe a = Nothing | Just a
05:57:24 <ski> `Maybe' is not an infix operator
05:58:07 <merijn> Let's be honest that doesn't really matter, because ?src is just text matching :p
06:00:25 <ski> @src $
06:00:25 <lambdabot> f $ x = f x
06:01:11 <Chuan> Oh. I am just trying it out. I stumbled upon https://stackoverflow.com/questions/5786372/how-can-i-view-the-definition-of-a-function-in-haskell-ghci
06:03:35 <merijn> Chuan: Note that @src is filled with lies too
06:03:43 <merijn> Chuan: Since it's just textual lookup
06:04:01 <merijn> Chuan: If you browse the haddock docs of a package on Hackage there's a link to the actual source
06:05:30 <Chuan> Thanks for the advice. I guess it would be quite difficult for the bot to print out lines of src code as well.
06:11:49 * hackage th-lift-instances 0.1.17 - Lift instances for template-haskell for common data types.  https://hackage.haskell.org/package/th-lift-instances-0.1.17 (BennoFuenfstueck)
06:12:41 <maralorn> Would it? I guess printing the sourcecode of the first hoogle hit would be totally feasible. But I assume it is a bad idea in IRC•
06:13:21 <merijn> maralorn: How useful would that be?
06:13:28 <merijn> Lots of name clashes on hoogle
06:13:42 <merijn> Also, real implementation might not be helpful to people
06:14:06 <merijn> The implementations lambdabot shows are the ones from the Haskell Report
06:14:32 <merijn> (Which are merely example implementations exhibiting the intended semantics, implementations are not required to follow said implementations)
06:15:07 <maralorn> I didn‘t say it would be useful. I just objected to the claim that it would be difficult.^^
06:15:29 <maralorn> But learning this fact about the lambdabot is interesting.
06:15:46 <maralorn> I guess I actually have never looked at the Haskell report.^^
06:15:50 <merijn> There's some other implementations in there too
06:16:05 <merijn> maralorn: You should, it's probably one of the most readable language specs in existence
06:16:25 <merijn> And you can learn lots of fun niche facts :p
06:16:39 <merijn> Like the fact that you can pattern match at the top (module) level :p
06:17:52 <phadej> that is "ocassionally" handy
06:17:55 <maralorn> merijn: Does that bind top-level variables?
06:18:01 <phadej> yes
06:18:25 <phadej> (x,y,z) = calculateXYZ ... where ...
06:18:40 <maralorn> MyRec { .. } = def :: MyType ^^
06:18:45 <phadej> that too
06:18:50 <zincy__> Does Scientific use floating point arithmetic?
06:18:59 <phadej> but it's more evil
06:19:08 <maralorn> wait, that would create a name clash wouldn‘t it?
06:19:27 <phadej> zincy__: no, and in fact I'd strongly advice against using Scientific for any kind of computation
06:19:42 <phadej> other than converting from/to wire-(textual)-format
06:20:05 <merijn> maralorn: That's why I can't wait for our lord and saviour -XNoFieldSelectors ;)
06:21:35 <zincy__> phadej: Why is it to be avoided?
06:21:39 <ski> sometimes people also seem to forget that you can do `x,y,z :: ...'
06:22:19 <ski> (also for record fields)
06:22:34 <merijn> ski: That works for records too? :O
06:22:38 <merijn> *mind blown*
06:22:51 <ski> @let data Blah = MkBlah { xx,yy,zz :: Int }
06:22:53 <lambdabot>  Defined.
06:26:47 <phadej> also in GADTs
06:27:01 <phadej> @let data G where GA,GB :: G Int
06:27:01 <lambdabot>  Parse failed: Parse error: ,
06:27:23 <phadej> Hmm, or maybe not.
06:28:02 <ski> % data G a where GA,GB :: G Int
06:28:02 <yahb> ski: 
06:28:34 <phadej> that breaks plenty of tooling though :)
06:29:57 <zincy__> hmm so why can't you use Scientific for currencies
06:30:56 <merijn> zincy__: That's *double* terrible
06:31:06 <merijn> (ha! floating point pun!)
06:31:41 <zincy__> So does Scientific use floating point?
06:31:53 <zincy__> I am confused
06:33:53 <phadej> Scientific for currently would only make sense if you handle scientific amount of money, like 2e50EUR 
06:33:59 <phadej> even that's not that much.
06:34:09 <phadej> scientifically.
06:35:47 <phadej> % 1 :: Scientific
06:35:47 <yahb> phadej: ; <interactive>:14:6: error: Not in scope: type constructor or class `Scientific'
06:35:49 <phadej> :(
06:36:07 <maralorn> I guess for most scientists currencies on a nano scale are much more likely to encounter during research. ;-)
06:36:24 <phadej> Prelude Data.Scientific> 1 :: Scientific 
06:36:24 <phadej> 1.0
06:36:24 <phadej> Prelude Data.Scientific> 1 / 3:: Scientific 
06:36:24 <phadej> *** Exception: fromRational has been applied to a repeating decimal which can't be represented as a Scientific! It's better to avoid performing fractional operations on Scientifics and convert them to other fractional types like Double as early as possible.
06:36:29 <phadej> is what I wanted to show
06:37:31 <maralorn> zincy_: I feel like Scientific is about representation not about calculation.
06:39:17 <solonarv> yes. it's just unbounded base-10 floating point, basically
06:39:32 <solonarv> not actually any better than the usual base-2 floats for calculation
06:39:53 <solonarv> and because it's unbouned you can run into edge cases where it blows up your memory
06:41:35 <Taneb> Is Fixed what you're looking for?
06:42:55 <tdammers> Scientific is great when you need exact representations of unbounded but finite decimal fractions
06:42:58 <tdammers> which is pretty rare
06:43:21 <tdammers> for currency calculations, you need exact representations of finite decimal fractions, but you don't need them to be unbounded
06:44:02 <tdammers> but currency is actually a very tricky subject, because it also involves different rounding rules depending on the calculation in question
06:44:41 <tdammers> so just newtyping Integer to represent the smallest possible currency division (1 cent or whatever) isn't quite enough, especially when you need to calculate stuff like interest
06:44:43 <tdammers> (oof)
06:52:37 <zincy__> Yeah I am trying to explain this to someone who
06:52:54 <zincy__> thinks that because Float is base 2 floating point it is accurate for money
06:52:58 <zincy__> sorry not accurate
06:53:10 <zincy__> but Scientific being base 10 floating point is accurate for money
06:53:35 <zincy__> I am trying to explain that the problem isn't the base but the fact there is a mantissa exponent at all
06:54:03 <tdammers> it kind of is accurate, in the sense that it can represent any decimal fraction exactly
06:54:46 <tdammers> the problem is just that it's unbounded, so as soon as you start introducing division (which you need for many financial calculations), things can (and, in practice, at some point, will) blow up
06:56:03 <zincy__> I think the issue is shifted
06:56:18 <tdammers> > 0.00000001 :: Scientific
06:56:19 <zincy__> So you end up with different rational numbers having non-terminating expansions
06:56:20 <lambdabot>  error:
06:56:20 <lambdabot>      Not in scope: type constructor or class ‘Scientific’
06:56:28 <tdammers> @let import Data.Scientific
06:56:30 <lambdabot>  .L.hs:116:1: error:
06:56:30 <lambdabot>      Data.Scientific: Can't be safely imported!
06:56:30 <lambdabot>      The module itself isn't safe.
06:56:35 <zincy__> And this varies depending on the base
06:57:38 <tdammers> yes, of course, but with financial calculations, all the numbers we need to "show to the user" are, by definition, finite decimal fractions, and Scientific provides terminating expansions for any n*10^m, by construction
06:58:23 <tdammers> or, put differently, it just so happens that all the numbers that would cause Scientific to diverge are also numbers we cannot represent exactly in traditional treeware bookkeeping
06:58:49 <zincy__> Are they all finite decimal fractions?
06:58:55 <zincy__> 1 / 3?
06:59:14 <tdammers> $1/3 is not a sum of money you would encounter in financial calculations
06:59:48 <tdammers> it may occur as an intermediate value in some calculation, but before it gets written down, there will be rounding, so $1/3 will end up as either $0.33 or $0.34
06:59:51 <Luna9Media> This is very helpful
06:59:51 <zincy__> Ah ok
06:59:54 <sm[m]> actually...
07:00:00 <tdammers> or possibly $0.3333 or $0.3334
07:00:11 <zincy__> sm[m]: Really?
07:00:18 <tdammers> or maybe even $1
07:00:22 <tdammers> or $0
07:00:25 <sm[m]> When you’re splitting expenses etc, especially automatically...
07:00:40 <merijn> zincy__: We have a type for all finite decimal fractions :p
07:00:49 <merijn> It's the type everyone always forgets...
07:00:53 <merijn> Our great friend
07:00:59 <merijn> > 1/3 :: Rational
07:00:59 <tdammers> sm[m]: yes? when you do that, the splitting algorithm MUST take the integral nature of the smallest currency denomination into account
07:01:01 <lambdabot>  1 % 3
07:01:11 <zincy__> Yes exactly I am aware of the great rational
07:01:40 <tdammers> Rational is morally wrong for currency, because it can represent a huge class of numbers that are not valid currency amounts
07:01:42 <tdammers> such as 1/3
07:02:17 <ski> Luna9Media : if you have any (Haskell-related) question, feel free to state it
07:02:32 <merijn> tdammers: Debatable :p
07:02:39 <merijn> tdammers: Define "valid currency amount"
07:02:51 <zincy__> Why cant 1/3 be a valid currency amount
07:03:18 <zincy__> "The amount payable by each of a party of 3 for a 1$ Taxi Ride"
07:03:55 <sm[m]> well as tdammers says you have to round it to actually transact
07:04:21 <tdammers> zincy__: because none of the commonly used payment systems allow people to pay an amount of 33 1/3 cents
07:04:22 <sm[m]> since nobody carries recurring .3 coins
07:05:07 <merijn> tdammers: My backups are billed in nanodollars :p
07:05:12 <tdammers> so what you do is either you have everyone pay $0.34 and tip the driver an extra $0.02, or one of you pays $0.34 and the other two $0.33, or all three of you pay $0.33 and the cab driver says "keep that $0.01, it's fine"
07:05:34 <tdammers> merijn: sure - but those are still *finite decimals*. Just a finer resolution.
07:06:24 <zincy__> tdammers: I guess the rational representation just delays the inevitable
07:06:35 <tdammers> yep
07:06:55 <tdammers> that said, rational is probably one of the better choices for the intermediate steps
07:07:05 <tdammers> if there are any, that is
07:07:32 <sm[m]> I think Decimal is good
07:07:53 <sm[m]> exact representation of decimals, up to 255 decimal places
07:08:23 <tdammers> also, let's not forget that we're discussing a luxury problem here; JavaScript makes you choose between float and string
07:08:45 <merijn> tdammers: You forgot "object" ;)
07:09:19 <sm[m]> hehe yes it seems about 10 decimal places is all you can rely on across languages
07:10:22 <infandum> I'm a little confused about laziness within a monad. I thought that in a monad such as IO each action is run before the next, but with `do { x <- return (sum [1..10000000]); print "hi"; print x }` "hi" is printed before x is computed (as it hangs after the hi, not before).
07:10:52 <tdammers> infandum: Monad and laziness have practically nothing to do with each other
07:10:58 <zincy__> sm[m]: Decimal uses floating point no?
07:11:26 <sm[m]> zincy__: does it ?
07:11:41 <tdammers> no, it doesn't
07:11:46 <infandum> tdammers: Wouldn't that make progress bars semi-pointless unless you force strictness?
07:11:49 <nshepperd2> infandum: return doesn't compute anything
07:11:51 <tdammers> https://hackage.haskell.org/package/Decimal-0.5.1/docs/src/Data-Decimal.html#DecimalRaw
07:12:09 <sm[m]> phew
07:12:16 <tdammers> infandum: mind the difference between evaluation and execution
07:12:30 <merijn> infandum: You're conflating the sequencing of effects (which >>= does) with the sequencing of evaluation of values (which is entirely unrelated)
07:12:59 <tdammers> infandum: also, I STRONGLY recommend grokking the desugaring rules for do notation before attempting to reason about code written in do notation
07:13:36 <ski> @type evaluate
07:13:38 <lambdabot> a -> IO a
07:13:53 <chunchunmaru> Hi
07:14:08 <tdammers> infandum: but to answer your question, if you want a progress bar to feed back the progress of a pure evaluation, then you are, in fact, right - such a progress bar would be notoriously difficult to implement in Haskell
07:14:08 <ski> hello chunchunmaru
07:14:18 <chunchunmaru> Had a question regarding random generators in haskell
07:14:28 <tdammers> chunchunmaru: don't ask to ask, just ask
07:14:43 <wavemode_> infandum, the assignment to x did happen first. but what you assigned to x was a lazy sum, which wasn't computed until forced
07:15:08 <ski> (there is no assignment there, just binding)
07:15:21 <wavemode_> semantics
07:15:28 <tdammers> return (sum [1..10000000]) >>= \x -> print "hi" >> print x
07:15:31 <tdammers> it's not just semantics
07:15:44 <infandum> ski: That made it work as expected, so should I be using evaluate instead of return when I have a progress bar?
07:15:55 <ski> infandum : what tdammers said
07:16:19 <chunchunmaru> In order to get truly random values we do getStdGen in Haskell
07:16:46 <ski> you normally want `newStdGen' or `getStdRandom', rather than `getStdGen'
07:16:46 <chunchunmaru> but all random functions create the next random generator
07:16:57 <infandum> Is there a downside to using evaluate?
07:17:29 <tdammers> chunchunmaru: yes. that is necessary because all Haskell functions are pure - applying the same function to the same PRNG state will always produce the same "random" number
07:17:35 <chunchunmaru> so given the random generator we will always get the same sequence 
07:17:41 <tdammers> ye
07:17:44 <tdammers> s
07:17:55 <solonarv> yes, that's a feature of most PRNGs in fact
07:17:58 <ski> (that can help with debugging)
07:18:01 <tdammers> it's best to think of this "Gen" object not as the generator, but as the generator STATE
07:18:09 <chunchunmaru> This doesn't feel truly random for me
07:18:24 <tdammers> that's why it's called a PRNG, PSEUDO-random number generator
07:18:26 <nshepperd2> truly random numbers are an illusion
07:18:32 <chunchunmaru> Probably because I don't really know how PRNGs work
07:18:54 <solonarv> if you want "truly" random, you have to point a camera at a wall of lava lamps, or something of the sort
07:18:55 * ski thinks arguing semantics is commonly more interesting than arguing syntax
07:19:01 <tdammers> https://en.wikipedia.org/wiki/Pseudorandom_number_generator is a good start :)
07:19:12 <chunchunmaru> But getStdGen gets a truly random generator from the system right?
07:19:16 <tdammers> solonarv: that one is hilarious, actually
07:19:45 <ski> again, normally you don't want to use `getStdGen'
07:19:54 <merijn> chunchunmaru: Basically, every OS will have some system calls that provide "true" randomness (based on user activity, keyboard, mouse, network, etc.)
07:20:01 <chunchunmaru> Can't we get one a random generator based on system everytime?
07:20:04 <tdammers> chunchunmaru: no, not quite. it does usually get seeded from a reliably random source, but the PRNG algorithm itself is unspecified, and the practical implementation in the `random` package is weak
07:20:26 <merijn> chunchunmaru: So what essentially every programming language does is using "true" random data from the OS to see a PRNG and use the PRNG for actualy number generation
07:20:40 <tdammers> so System.Random is generally fine for things like generating noise for sound synthesis or procedural textures, but not for cryptography
07:20:42 <solonarv> s/see/seed/
07:20:53 <merijn> chunchunmaru: The system RNG is *slow* (and, incidentally on all major OSes uses a cryptographically secure PRNG anyway)
07:21:36 <merijn> chunchunmaru: "real" randomness requires weird hardware accelerators like the ones that use quantum photonic decay to generate (near perfect) random data
07:21:51 <merijn> chunchunmaru: In reality, the odds of you needing that are...basically 0 :p
07:22:13 <tdammers> if you need cryptographically sound randomness (or a reasonable approximation) in a cross-platform way in Haskell, the go-to implementation would be the Crypto.Random module from cryptonite: https://hackage.haskell.org/package/cryptonite-0.26/docs/Crypto-Random.html
07:22:36 <merijn> chunchunmaru: So in the end it depends on "what do you need the randomness for?"
07:22:37 <chunchunmaru> Its just that me getting the exact same sequence whenever I run random with same gen is eerie for me XD
07:22:50 <tdammers> well, that's because it's not actually random
07:22:56 <wavemode_> hey, improved testability :p
07:23:05 <tdammers> even with a cryptographically sound PRNG, you will see this behavior
07:23:05 <merijn> chunchunmaru: That's not eerie, that's expected behaviour
07:23:32 <solonarv> wavemode_: you joke, but that's actually important for property testing (QuickCheck &co) so you can exactly reproduce test runs
07:23:41 <tdammers> the difference is just that a cryptographically sound one will make it "very difficult" to predict future outputs given any number of previous outputs - until the outputs repeat, that is
07:23:45 <merijn> chunchunmaru: Given the same starting seed a PRNG will always generate the exact same sequence
07:23:55 <tdammers> and they always repeat, but in a good crypto PRNG, the cycle length will be gargantuan
07:24:15 <merijn> chunchunmaru: Which is actually great if you want deterministic simulations
07:25:53 <chunchunmaru> Well I just hoped there to be some in built function which took care of getting a new seed at least when we run the function everytime
07:26:10 <chunchunmaru> But I guess that flies right in the face of functional programming
07:26:14 <merijn> chunchunmaru: the IO based one does that
07:26:30 <[exa]> chunchunmaru: hardcoding the seed methods to languages/libraries has proven to be almost always wrong
07:26:41 <ski> @type getStdRandom
07:26:43 <lambdabot> (StdGen -> (a, StdGen)) -> IO a
07:26:59 <chunchunmaru> [exa] could you get some more insight on that?
07:27:04 <merijn> chunchunmaru: newStdGen seeds one from the system seed
07:27:15 <ski> @type newStdGen
07:27:16 <lambdabot> IO StdGen
07:27:37 <merijn> chunchunmaru: Although the default random PRNG in the random package isn't great
07:28:04 <chunchunmaru> merijn I am aware of that but to get "truly" random numbers you have to do newStdGen each time, which feels like an extra step
07:28:25 <merijn> chunchunmaru: Wait, I think you might be confusing things :)
07:28:30 <[exa]> chunchunmaru: quite related to the linux random vs. urandom discussion; various applications have various requirements on the randomness "quality", i.e. the complexity of methods that can be used to predict what's happening. If you don't do hardcore cryptography (which you shouldn't anyway), just go with the default, it's good enough.
07:29:00 <ski> chunchunmaru : usually you'd either be carrying on with threading the `StdGen' for some time, or else get an infinite list of randomly generated values
07:29:03 <merijn> chunchunmaru: Note that, for example "random" takes a StdGen and returns a value *and* a new StdGen
07:29:36 <merijn> chunchunmaru: So you do newStdGen *once* and after that, each time you use "random" or one of the other functions, you used the *new* StdGen they return
07:30:05 <merijn> chunchunmaru: StdGen is (effectively) the PRNG's internal state
07:30:23 <merijn> So everytime you generate a value you get a new, updated, PRNG state
07:31:10 <merijn> Or, indeed use randomRs which uses this trick to generate a lazy infinite list of random values
07:31:29 <chunchunmaru> Yes but you get the same StdGens given the same seed
07:31:44 <merijn> > randomRs (-10, 10) (mkStdGen 5)
07:31:46 <lambdabot>  [7,-6,9,5,4,0,-9,8,-3,8,6,-3,2,6,10,-4,-3,5,9,-5,-6,8,0,-4,-6,8,0,2,-2,-10,-...
07:31:54 <merijn> chunchunmaru: Well yes, that's the point of a seed
07:32:06 <merijn> chunchunmaru: The same seed *should* return the same sequence
07:32:20 <ski> % (getStdRandom . runState) (replicateM 10 (state (randomR (1,6))))
07:32:20 <yahb> ski: [4,3,1,4,2,5,5,1,6,1]
07:32:34 <merijn> chunchunmaru: If you want a different sequence, use a different seed, or use newStdGen (which creates a random seed for you)
07:32:41 <chunchunmaru> I was just hoping there was some function which took care of getting new random seed everytime without making your own
07:32:47 <ski> (or `getStdRandom')
07:32:52 <merijn> chunchunmaru: What does "every time" mean?
07:32:59 <chunchunmaru> based on external factors like time or clock speed
07:33:04 <merijn> chunchunmaru: Every time your program runs?
07:33:11 <ski> chunchunmaru : `getStdRandom' does that, arguably
07:33:22 <chunchunmaru> yes
07:33:32 <ski> % (getStdRandom . runState) (replicateM 10 (state (randomR (1,6))))
07:33:33 <yahb> ski: [5,1,3,6,1,2,6,5,6,2]
07:33:37 <merijn> chunchunmaru: That's what getStdRandom and newStdGen do...
07:33:39 <chunchunmaru> let me elaborate 
07:34:18 * hackage tree-sitter-php 0.5.0.0 - Tree-sitter grammar/parser for PHP  https://hackage.haskell.org/package/tree-sitter-php-0.5.0.0 (patrick_thomson)
07:34:19 <chunchunmaru> getStdRandom seems like truly random for me since you get a different value everytime you run it based on external factors
07:34:37 <ski> (different sequence, since `getStdRandom' makes an `IO'-action, which modifies the global `StdGen' that is accessed by `newStdGen',`getStdRandom' (and `getStdGen', but don't use that, unless you know why you shouldn't use it))
07:35:11 <ski> chunchunmaru : you may be conflating execution (of `IO'-actions, in this case), from evaluation (of expressions)
07:36:05 <chunchunmaru> but all the other random generators output same given a seed, so I was wondering why there wasn't an standard function which fetched a new generator from external seed everytime
07:36:06 <ski> chunchunmaru : calling the function `getStdRandom' will not give a different result value each time. the result value is the `IO'-action, which has not yet happened. executing that will (usually) produce different results, though
07:36:26 <chunchunmaru> yes 
07:36:27 <chunchunmaru> yes
07:36:31 <chunchunmaru> I know its lazy
07:36:42 <ski> it's not about laziness, or non-strictness
07:36:43 <chunchunmaru> Anyways what I understood so far is
07:37:15 <merijn> chunchunmaru: That's what randomIO does?
07:37:25 <ski> calling a function with equal inputs will always produce equal outputs
07:37:59 <ski> so, there can't be a function that fetches "a new generator from external seed everytime"
07:38:01 <chunchunmaru> Getting an external generator everytime might be slower and hardcoding such things into standard library is not a good idea
07:38:10 <ski> (`getStdRandom' certainly is not such a function)
07:38:43 <chunchunmaru> I was hoping IO's random generation depends on external factors like time and clock speed
07:39:00 <chunchunmaru> even though given the same input the output would be the same
07:39:05 <ski> anyway, fetching random bits from the OS everytime would be slower
07:39:13 <chunchunmaru> but inputs such as those can be considered random?
07:39:25 <ezzieyguywuf> you all are more familiar with haskell than I am - is it possible to tell whether something like than can 'easily' be used in haskell using the ffi? https://github.com/stepcode/stepcode/blob/master/src/test/p21read/p21read.cc
07:39:35 <infandum> This laziness I'm seeing, is it only because I'm binding? If I don't bind, then the IO action would just be run, right?
07:39:44 <chunchunmaru> Again I never studies PRNGs or anything like that
07:40:04 <chunchunmaru> studied*
07:40:05 <ezzieyguywuf> Specifically, this part with the 'extern' gives me some hope...https://github.com/stepcode/stepcode/blob/master/src/test/p21read/p21read.cc#L143
07:40:27 <ski> infandum : i don't understand the question, can you clarify ?
07:41:42 <ski> chunchunmaru : i don't recall how the initial global `StdGen' is constructed, maybe check docs ?
07:42:09 <infandum> ski: My earlier x <- return (sum [1..10000000]) statement, if that wasn't a bind then it would just compute, right? I believe so
07:42:20 <ski> infandum : `do x <- return v; f x' will be equal to `f v', by monad law
07:42:23 <merijn> ezzieyguywuf: That's C++, so you need to make a C wrapper first, but after that FFI should be easy
07:42:37 <ski> infandum : i dunno what your "it"s refer to
07:42:55 <ezzieyguywuf> merijn: ah, I see.
07:43:18 <wavemode_> infandum, can you post an alternate code example of what you're talking about
07:43:28 <infandum> if I do print (sum [1..10000000]) then it works as expected, is that because print is strict or is it because there is no bind?
07:43:30 <merijn> ezzieyguywuf: C++ does name mangling (to do overloading) which makes the name unpredictable (unspecified, even!)
07:43:46 <infandum> or both
07:43:53 <dolio> `do x <- return e ; m` = `let x = e in m`
07:43:57 <solonarv> ezzieyguywuf: a slight additional complication: you can't pass structs through the FFI, only pointers and (some) primitives like float, int, etc
07:43:59 <[exa]> chunchunmaru: highly suggest looking at `man 3 rand`, section "example"
07:44:01 <merijn> ezzieyguywuf: To call C++ code from C (and thus other language's FFI) you need a C++ wrapper using 'extern "C"' to call them
07:44:05 <dolio> Or, `let x = e in do m`
07:44:13 <[exa]> chunchunmaru: as I said, requirements on PRNGs vary wildly
07:44:19 <merijn> solonarv: That's not a restriction of the FFI, though
07:44:25 <ski> infandum : therefore, `do x <- return (sum [1 .. 10000000]); print "hi"; print x', which is equal to `return (sum [1 .. 10000000] >>= \x -> print "hi" >> print x' (do you see this ?) is equal to `print "hi" >> print (sum [1 .. 10000000])'
07:44:26 <merijn> solonarv: That's a restriction of the ABI
07:44:51 <solonarv> fair enough, s/FFI/ABI/ in my previous message
07:44:51 <merijn> solonarv: You can't do that between code build by different C compilers eithers (fun times!)
07:44:54 <[exa]> chunchunmaru: btw what's your use case? (i.e. what exact "quality" or "property" of randomnes do you need?)
07:45:35 <ezzieyguywuf> merijn: I can't pass a struct, but I can pass a pointer to...a struct?
07:45:42 <merijn> ezzieyguywuf: Yes
07:45:56 <ezzieyguywuf> but then on the haskell side I need to allocate the right amount of memory somehow
07:46:24 <solonarv> yes, and you can do this using the various functions in Foreign
07:46:26 <infandum> ski, dolio: yes, so without the bind there is no let, so it evaluates "first"
07:46:53 <ezzieyguywuf> it all makes sense
07:46:54 <infandum> err, no lambda argument I guess I mean
07:46:58 <merijn> ezzieyguywuf: Basically, every OS (that matters) defines a C ABI (Application Binary Interface) which is the calling convention used by C to invoke functions. The ABI doesn't specify how structs should be passed on most major platforms, so you can't assume you'll get sensible code
07:47:09 <ski> infandum : "it" being ?
07:47:16 <ezzieyguywuf> merijn: makes sense.
07:47:33 <merijn> ezzieyguywuf: I recommend reading chapter 8 of the Haskell report (which covers the FFI) and various parts of the GHC user guide, those cover everything important
07:47:36 <merijn> @where report
07:47:36 <lambdabot> http://www.haskell.org/onlinereport/haskell2010/ (more: http://www.haskell.org/haskellwiki/Definition)
07:47:39 <merijn> @where userguide
07:47:39 <lambdabot> https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/
07:47:43 <ezzieyguywuf> all of it makes sense. *sigh* I'll add this to the TODO list. It's frustrating how widely used step-file format is, yet how difficult it is to find open source libs for it
07:47:53 <ezzieyguywuf> merijn: thanks.
07:48:16 <chunchunmaru> Thanks guys for your insights, might visit here again if I encounter something baffling again in Learn you a haskell for great good
07:48:17 <infandum> ski: the sum
07:48:21 <merijn> ezzieyguywuf: If you're already familiar with C you should feel right at home with those docs :)
07:49:17 <wavemode_> infandum, so you're specifically asking why the hi is printed before the sum is evaluated? the simply reason is that the printing of hi was _needed_ first (to show a message on the screen). haskell evaluates expressions in the order they are needed, not the order you define them
07:49:24 <ezzieyguywuf> merijn: I'm more familiar/comfortable with c++, but i'm sure they will make sense
07:49:44 <ski> infandum : the sum is only evaluated (under lazy evaluation) if (and when) its value is demanded. in your example, it was only demanded by the `print x' at the end
07:49:53 <wavemode_> infandum, consider `do { x <- return (sum [1..10000000]); seq x (print "hi"); print x }` . here we use seq (aka sequential evaluation) to force x to be evaluated before print hi is evaluated
07:50:09 <merijn> ezzieyguywuf: I just mean that the basic concepts like "object files", "symbols", etc. are exactly the same
07:50:41 <ezzieyguywuf> merijn: got it. Yea I've seen some of the FFI stuff already when using GLFW-b, it seems very intuitive
07:50:54 <ski> infandum : apart from that, i can't follow what you're saying, so i can't tell whether it's correct or not
07:50:54 <wavemode_> :t seq
07:50:56 <lambdabot> a -> b -> b
07:51:20 <merijn> ezzieyguywuf: The report's chapter specifies all the gory details of "how are Haskell types mapped to C types" (which is mostly straightforward)
07:51:53 <wavemode_> seq makes it so that in the expression `seq x (print "hi")` , haskell is forced to evaluate x before evaluating the print
07:52:03 <merijn> wavemode_: No
07:52:14 <infandum> ski, wavemode_: No, you're being very helpful and I understand the issues, I'm just trying to figure out the best way to have this progress bar be meaningful by having the values computed when the bar says they are
07:52:35 <merijn> wavemode_: "seq x y" says "when the result of 'seq x y' is evaluated, both 'x' and 'y' will have been evaluated"
07:52:40 <frdg> does anyone know of a function in the `trifecta` library  that works like `parseString` but takes a regex ?
07:52:44 <ezzieyguywuf> This malloc-peek thing is still confusing me a bit, but I only spent all of like 2 minutes trying to understand it https://gitlab.com/ezzieyguywuf/learnopengl/-/blob/master/app/Main.hs#L125
07:52:44 <merijn> wavemode_: It explicitly does not specify an ordering
07:52:45 <infandum> wavemode_: But that only computes the spine, right?
07:53:17 <merijn> ezzieyguywuf: "peek" is just "dereference a pointer"
07:53:25 <infandum> So the only true solution is to use force from deepseq which seems like overkill
07:53:26 <merijn> ezzieyguywuf: "peek :: Storable a => Ptr a -> IO a"
07:54:01 <ski> merijn : fwiw, i don't think it implies that `x' will have to be evaluated before `seq x y' is .. only that `x' is eventually evaluated in such a way that the overall computation is bottom in case `x' is ?
07:54:05 <ezzieyguywuf> merijn: how does malloc know how much memory to make?
07:54:06 <merijn> ezzieyguywuf: i.e. read an actual 'a' value from the 'Ptr'
07:54:21 <merijn> ski: IFF the result is non-bottom, both will be evaluated
07:54:27 <merijn> ezzieyguywuf: Type inference :)
07:54:56 <ski> merijn : yes. i was just questioning the past tense "will have been"
07:55:09 <ezzieyguywuf> ah, so I could have explicitly stated the _type_ of pointer I wanted malloc to give me, in which case it would have been akin to `unsigned int* vboP` in c
07:55:12 <merijn> ezzieyguywuf: "malloc :: Storable a => IO (Ptr a)", the Storable class includes the size of the value
07:55:55 <ski> infandum : `seq' should be enough if the result is an `Int' or `Integer'
07:55:57 <merijn> ezzieyguywuf: There's also "mallocBytes" and various helpers from Foreign.Marshal.Array
07:56:38 <ezzieyguywuf> interesting
07:56:57 <infandum> ski: The results are usually more complex, like tuples of maybes of records
07:57:05 <wavemode_> merijn, how is the order not specified? if the value of seq is forced, so is the value of x. in other words x must be evaluated before seq is evaluated. no?
07:57:14 <ski> @type Foreign.Marshal.Alloc.malloc
07:57:15 <lambdabot> Foreign.Storable.Storable a => IO (GHC.Ptr.Ptr a)
07:57:17 <ski> @type Foreign.Marshal.Utils.new
07:57:18 <lambdabot> Foreign.Storable.Storable a => a -> IO (GHC.Ptr.Ptr a)
07:57:19 <merijn> wavemode_: Why?
07:58:32 <ski> infandum : so i guess either a manual `seq'ing, or, `deepSeq' or similar
08:00:02 <infandum> ski: I hope it doesn't destroy the performance of the program...
08:00:09 <wavemode_> merijn, in what scenario could seq evaluate to a value while the first argument remains a thunk? I'm curious, really
08:00:13 <infandum> either memory or time
08:00:28 <merijn> wavemode_: That's not what I said
08:00:31 * ezzieyguywuf still wonders what a thunk is
08:00:42 <merijn> ezzieyguywuf: "unevaluated expression"
08:01:09 <merijn> wavemode_: My point was that whether 'x' or 'y' is evaluated first is unspecified
08:01:46 <merijn> wavemode_: The only thing specified is that IFF 'seq x y' is not bottom THEN when 'seq x y' is finished evaluating, both 'x' and 'y' will be in WHNF"
08:02:20 <merijn> wavemode_: In fact, the report doesn't even require the order in which 'x' and 'y' are evaluated to be consistent across uses of 'seq'
08:02:40 <merijn> If you want a deterministic order, use pseq
08:03:28 <ezzieyguywuf> if I have a [State [Int] a], is that a list of thunks?
08:03:49 <merijn> ezzieyguywuf: Thunks are an implementation detail of GHC
08:03:53 <ski> "thunk" is an implementation detail
08:03:59 <ski> @quote infinite.list.of
08:04:00 <lambdabot> syntaxglitch says: SPJ is actually an infinite list of papers, if you read all he has so far it'll force the next thunk and he'll have a new one
08:04:07 <ezzieyguywuf> so I don't have to worry about thunks
08:05:02 <merijn> ezzieyguywuf: Basically, a "thunk" represents an unevaluated expression in the code generated by GHC
08:05:15 <merijn> ezzieyguywuf: So "map (+1) [1..10]" compiles to a thunk that says "map (+1) [1..10]", then, when you try to use that expression (forcing evaluation), GHC will start actually computing stuff
08:05:31 <wavemode_> merijn, ah I see now, thanks. I had misunderstood the difference between seq and pseq
08:05:51 <merijn> ezzieyguywuf: So you can think of it as "a placeholder for a future evaluated expression"
08:06:27 <merijn> ezzieyguywuf: See also: https://apfelmus.nfshost.com/articles/lazy-eval.html
08:07:28 <ski> @where lazy
08:07:28 <lambdabot> "Lazy Evaluation of Haskell" by monochrom at <http://www.vex.net/~trebla/haskell/lazy.xhtml>; "The Incomplete Guide to Lazy Evaluation (in Haskell)" by apfelmus in 2015-03-07 at <https://apfelmus.
08:07:28 <lambdabot> nfshost.com/articles/lazy-eval.html>; "Laziness, strictness, guarded recursion" by bitemyapp at <https://github.com/bitemyapp/learnhaskell/blob/master/specific_topics.md#user-content-laziness-
08:07:28 <lambdabot> strictness-guarded-recursion>
08:07:50 <ezzieyguywuf> thanks for the explanation and the links
08:41:25 <glow8> any good logic problems to practise haskell? something like the N queen problem :P
08:41:53 <dminuoso> glow8: I'd just do things you enjoy, things you need.
08:42:41 <glow8> I wanted something relatively popular and that's already been solved multiple times to look at other people's code 
08:42:58 <glow8> Reading code is a great way to learn programming imo
08:43:07 <dminuoso> Writing code is the better one.
08:43:59 <[exa]> glow8: kalotan puzzle?
08:45:42 <[exa]> glow8: description here https://ds26gte.github.io/tyscheme/index-Z-H-16.html#node_sec_14.4.1
08:46:56 <[exa]> glow8: don't spoil yourself with Scheme implementation. Haskell bonus: 1] make it look natural, i.e. the program should include the statements "translated" to haskell 2] don't touch Bool or boolean logic manually 3] use list or Logic monad
08:47:23 <hc> glow8: if you want to very simple, try calculating the fibonacci numbers ;)
08:47:35 <glow8> [exa]: sounds like fun, thanks!
08:47:46 <glow8> hc: I think that's too simple :P
08:48:47 <[exa]> glow8: I have a prolog implementation somewhere, which is a good guideline (it's quite hard to make the Haskell solution shorter and still readable)
08:50:29 <ph88> which function can i use to parse a datetime like 20190616051320 into an unix time ?
08:50:33 <glow8> oooh I just discovered this article, I might do that first: https://wiki.haskell.org/H-99:_Ninety-Nine_Haskell_Problems
08:50:46 <glow8> I gotta say haskell docs are one of the best I've read :)
08:51:14 <wavemode_> ph88, well theres: https://hackage.haskell.org/package/time-1.10/docs/Data-Time-Format.html
08:51:52 <Moosef> Has anyone recently had an issue installing spock with stack? I have followed the docs and have to keep adding dependencies until I am told that my build requires an unattainable version of base.
08:51:54 <ph88> wavemode_, i saw that one with a function formatTime that gives a string
08:52:14 <maerwald> fibonacci in O(1) not that simple
08:52:38 <ph88> [exa], ? :)
08:52:48 <[exa]> glow8: prolog version if you want it https://gist.github.com/exaexa/8138b899d4b76c6bf2c56714036e28f5
08:53:05 <[exa]> ph88: ^ ?
08:53:07 <wavemode_> there's a mathematical formula for the nth fib. but on a computer you need a lot of precision for it to be accurate
08:53:39 <glow8> [exa]: thanks a bunch!
08:53:42 <[exa]> wavemode_: involves square roots of 5 as generating functions :]
08:53:56 <ph88> [exa], how can i parse a datetime into an int
08:54:22 <[exa]> ph88: you can't parse that thing because you don't really know which timezone it is in
08:54:52 <[exa]> ph88: if you assume the timezone, I suggest splitting it manually and feeding it into appropriate Data.Time structures
08:55:15 <wavemode_> ph88, it also has parseTimeM which can parse to a Maybe, based on an arbitrary format string
08:55:37 <wavemode_> ph88, there's a code example on that page
08:56:23 <[exa]> glow8: anyway, fibonacci bonus: there are base-fib numbers, like base-2 and base-10. 1] prove programmatically that all numbers can be written in base-fib using just 0's and 1's as digits 2] implement a reasonable (O(lenght_of_input)) algorithm for adding the numbers in base-fib
08:58:18 <[exa]> glow8: eg. 5(dec) == 1000 (fib), 23(dec)==1000010(fib), etc. (there's only 1 digit for value '1')
08:59:35 <Finianb1> base fibonacci numbers? 
08:59:42 <Finianb1> my only question is why... 
09:00:33 <[exa]> that's a similar question as "why do fibonacci numbers at all" :]
09:00:44 <Finianb1> fair
09:01:18 * ski . o O ( fibonacci heaps )
09:01:20 <Finianb1> there are also negative bases, though if you're doing fibonnaci radix, then I'm guessing you're already aware
09:01:40 <ski> also factoriadic
09:02:07 <Finianb1> I have seen that one
09:02:11 <Finianb1> it seems very cursed
09:02:22 <ski> ?
09:02:28 <Finianb1> useful for permutations though? 
09:02:31 <glow8> wow I didn't know there was much else to fibonacci numbers
09:03:42 <Finianb1> p-adics are also fun. 
09:03:43 * ski . o O ( `Fin (n^m) -> Fin m -> Fin n' )
09:03:59 <ph88> wavemode_, i didn't get the return time   m t   of parseTimeM
09:04:48 <[exa]> glow8: btw if you know AVL trees, try proving the depth limit for number of nodes (also uses fibs)
09:05:49 <glow8> what is it, something like log2(N) where N is the number of nodes?
09:05:54 <glow8> ah no that's the last level
09:05:58 <glow8> hmm okay
09:06:13 <[exa]> very roughly and the logarithm base comes out a bit different
09:06:35 <wavemode_> ph88, m there just refers to any instance of MonadFail, which includes Maybe. in other words, if you expect a Maybe, it will return a Maybe. like in their code example `parseTimeM True defaultTimeLocale "%Y-%-m-%-d" "2010-3-04" :: Maybe Day`
09:08:57 <Finianb1> apparently there's even algebraic geometry with the p-adics
09:09:51 <Finianb1> I don't really get much of algebraic geometry, but doing p-adics as your field in an already extremely difficult area of math seems mind bending
09:12:30 <Moosef> Changed my resolver. That seems to have fixed it. Never mind everyone
09:19:28 <ph88> wavemode_, instead of Day how can i go directly to Int and not go to a Stringy type first ?
09:30:29 <fragamus_> hi I am having trouble finding lts-15.16
09:41:03 <ezzieyguywuf> if I need vector maths, only in 3-dims, and eventually quaternion stuff (so..up to 4 x 4 matrix maths), which haskell lib would you all recommend?
09:41:31 <ezzieyguywuf> it seems that there is Lineor, HaskellForMaths, easytensor
09:42:40 <merijn> hmatrix or hblas?
09:42:56 <merijn> Oh, maybe linear?
09:43:26 <merijn> ezzieyguywuf: Linear has a bunch of specific vector types for up to 4 dimensions
09:44:12 <ezzieyguywuf> yikes! linear has many more dependencies than easytensor or HaskellForMaths
09:44:39 <merijn> It's in the Kmett-iverse, yes :p
09:44:51 <ezzieyguywuf> hrm, never heard of  blas or lapack
09:44:54 <ezzieyguywuf> what is kmett-iverse?
09:46:14 <merijn> ezzieyguywuf: BLAS/LAPACK are probably overkill for tiny matrices of <4 dimensions, but they provide an API for high performance matrix operations (most platforms will have a BLAS implementation in, like, highly optimised Fortran or something)
09:47:08 <ezzieyguywuf> merijn: that may end up being what I need, I have a feeling I'll be doing so complex maths involving lines and curves and surfaces
09:47:22 <merijn> ezzieyguywuf: Kmett-iverse is a reference to the sheer ungodly amount of packages Edward Kmett produces ;) A lot of them highly general, math inspired stuff :p
09:47:30 <ezzieyguywuf> but maybe I start wit, say, easytensor, and then convert to blas when the need arises
09:47:47 <ezzieyguywuf> ah, so this Kmett fella is a known producer of quality stuffs?
09:47:57 <ezzieyguywuf> i.e. it should be OK to have dependencies on his works?
09:47:57 <merijn> ezzieyguywuf: Anyway, looking at https://packdeps.haskellers.com/reverse there's 134 packages using linear vs 1 & 3 packages using HaskellForMaths/easytensor
09:48:11 <ezzieyguywuf> (I'm generally leary of dependencies...)
09:48:44 <Finianb1> kmett? 
09:48:46 <ezzieyguywuf> that's a neat little resource
09:49:01 <Finianb1> https://cokmett.github.io/cokmett/
09:49:03 <ezzieyguywuf> where does it pull its data from?
09:49:03 <solonarv> Edward Kmett, prolific haskeller
09:49:05 <Finianb1> love this site
09:49:08 <merijn> ezzieyguywuf: Hackage
09:49:31 <Finianb1> Oh I know who he is 
09:49:49 <merijn> ezzieyguywuf: So it doesn't track stuff that's only on github/whatever, but Hackage should be fairly representative
09:49:57 * ezzieyguywuf nods
09:50:14 <solonarv> omg, that site is great
09:50:22 <ezzieyguywuf> probably will go ahead and just start with linear then. Again, I generally attempt to avoid deep dependencies, but it's not fully avoidable
09:50:25 <merijn> solonarv: It's actually better than it appears :p
09:50:33 <Finianb1> I can't even remember where I found it. 
09:50:43 <solonarv> merijn: what do you mean?
09:50:49 <merijn> solonarv: Packdeps lets you get an RSS feed that tells you when your package's bounds are tighter than latest version on Haskell
09:51:08 <merijn> solonarv: i.e. an RSS feed for when you need to check your bounds
09:51:17 <solonarv> merijn: oh, I thought you were referring to that cokmett site like I was
09:51:23 <Finianb1> what gets me is the moustache and all guys around him saying "algebraic" and "such mathmtical"
09:51:38 <solonarv> and '%%.%=.'
09:51:42 <merijn> solonarv: That's just a static image for me :p
09:51:48 <solonarv> click on it!
09:52:17 <merijn> ezzieyguywuf: Also, note that a large number of linear's dependencies are very standard and/or compat shims around very standard things
09:52:54 * ezzieyguywuf nods again
09:53:25 <merijn> Anyway, dinner time!
09:53:27 <ezzieyguywuf> lol, I had not clicked the image
09:53:32 <ezzieyguywuf> lunch for me!
09:56:38 <Finianb2> wait huh
09:56:40 <Finianb2> what
10:00:36 <Finianb2> yay I'm back 
10:00:44 <Finianb2> somehow still considered Finianb2 though
10:01:00 <Finianb2> oh
10:04:57 <ski> Finianb2 : you could have `ghost'ed the old connection
10:05:47 <Finianb2> yeah I switched from VPN 
10:05:48 <Finianb2> lol
10:15:17 <dminuoso> Is there a reason why TH can't splice an entire module?
10:15:41 <solonarv> there are lots of things TH can't splice :/
10:15:57 <dminuoso> Really? Like what? :)
10:16:06 <dminuoso> I mean beyond the staging restriction
10:16:27 <solonarv> anything that doesn't fall into one of these categories: type, expression, pattern, declaration
10:16:36 <solonarv> for example you cannot splice one branch of a 'case' expression
10:16:41 <dminuoso> Ah I guess things like pragmas fall into that
10:16:58 <dminuoso> Yeah that's fair enough
10:17:02 <solonarv> or one statement in a 'do' block, or...
10:17:13 <solonarv> lots of sensible subdivisions of the syntax that you can't splice
10:17:39 <dminuoso> Luckily in my case I really dont care since Im generating entire modules anyway. It's just a bit annoying to have to flush out the module by hand.
10:31:02 <zincy__> Is generics the way if you want to apply a function to all of a records fields at once?
10:31:59 <wavemode_> well, generics is the way if you want said function to work on any record of any length
10:32:07 <wavemode_> or lenses
10:36:23 <dmwit> If you want that, and Foldable/Traversable doesn't already give it to you, I would also consider asking myself whether a record was really the right data structure.
10:36:56 <wavemode_> very true
10:36:58 <merijn> It might be
10:37:07 <dmwit> Yes, it might. And also, it might not.
10:37:08 <merijn> zincy__: Are they all the same type?
10:38:14 <ezzieyguywuf> I have yet to fully read this, I've only skimmed, but I thought it'd be worth the question - are the techniques used here for dealing with things like "oh my gosh, we're going to have to track our own mutable state. In Haskell..." typical, or are there other 'better' approaches out there? https://lokathor.gitbooks.io/using-haskell/opengl/camera.html
10:38:57 <merijn> ezzieyguywuf: That link doesn't load here, so hard to say >.>
10:39:52 <ezzieyguywuf> hrm
10:40:04 <ezzieyguywuf> https://lokathor.gitbooks.io/using-haskell/
10:40:14 <ezzieyguywuf> how about this link? I was under the "Camera" sub-section on the left
10:40:40 <dmwit> Yes, using IORef/MVar/TVar for state in GUI code is fairly typical.
10:41:20 <ezzieyguywuf> neat, ok great thanks!
10:41:33 <ezzieyguywuf> IORef for single thread, the other two if I go multithread?
10:41:45 <dmwit> That seems like a reasonable rule of thumb to me.
10:41:56 <ezzieyguywuf> neat
10:42:11 <ezzieyguywuf> wow I've learned so much about 3d graphics I feel like a champ
10:42:14 <ezzieyguywuf> ^_^
10:42:31 <dmwit> It will cover 95% of uses. Then if you think you might be doing something weird or exceptional let's talk about when to look at the 5%.
10:43:01 * dmwit high fives ezzieyguywuf 
10:43:19 <merijn> ezzieyguywuf: IORef is threadsafe too
10:43:19 * ezzieyguywuf beams with pride
10:43:29 <merijn> ezzieyguywuf: wrt read/writes being atomic, that is
10:43:47 <ezzieyguywuf> merijn: but not wrt to other thing?
10:43:52 <ezzieyguywuf> s/thing/things
10:43:52 <merijn> ezzieyguywuf: But there's no way to really compose operations on multiple IORefs
10:43:58 <ezzieyguywuf> ah
10:44:07 <fragamus_> hi im having trouble with stackage
10:44:09 <fragamus_> https://gist.github.com/fragamus/1b1a85fce45a91a03cb1dfddb524e700
10:44:43 <merijn> ezzieyguywuf: So they basically function like std::atomic in that you have atomic read/write (and even CAS, I think?) but nothing else
10:45:21 <ezzieyguywuf>  I'm only passingly familiar with multithreaded stuff, and most of  that from python. so I know what atomic means but not CAS
10:45:28 <ezzieyguywuf> but I'll worry about that down the line :)
10:45:32 <merijn> ezzieyguywuf: Compare And Swap
10:45:50 <ezzieyguywuf> ah
10:46:33 <merijn> so "cas oldVal newVal ref" atomically writes newVal to ref IFF the current value is oldValue
10:46:38 <ski> @type Data.IORef.atomicModifyIORef
10:46:40 <lambdabot> GHC.IORef.IORef a -> (a -> (a, b)) -> IO b
10:47:21 <merijn> ezzieyguywuf: Otherwise you can get race conditions of someone modifying a variable in between you reading the variable and writing your update
10:47:49 <dmwit> Here I am, trying to protect him from the 5%, and y'all spill the beans. =P
10:48:03 <merijn> dmwit: I need to share my pain around ;)
10:48:09 <monochrom> We all protect him from the other 95%
10:49:20 <monochrom> http://www.vex.net/~trebla/humour/tautologies.html #12
10:49:48 <dmwit> "How do I add numbers?" One person answers (+), another answers "well it depends what primops you want GHC to emit and whether you're using LLVM, there are optimized type-specific primitives in GHC.Int and for some data structures you can do better with custom iterators..."
10:50:16 <monochrom> nerd-sniped
10:50:27 <MarcelineVQ> I'm that dickhead that goes "what  do you mean by add?"
10:50:36 <wavemode> nah, what he really wants is type-level Nats to do addition at compile time
10:50:43 <maerwald>  yeah, sounds like the UTF-8 nerd sniping
10:50:50 <dmwit> If you're at the point where you don't even know the name (+), it isn't time for the second answer yet. =P
10:50:56 <merijn> monochrom: #7 reminds me of one of my favourite quotes from an aerospace/rocket engineering course
10:51:11 <merijn> monochrom: "anything is linear when plotted on a log-log axis with a thick marker"
10:51:18 <monochrom> haha
10:51:39 <ezzieyguywuf> dmwit: lol.
10:51:53 <dmwit> And that reminds me of one of my favorite quotes from complexity class: forall n, log n < 60
10:51:53 <merijn> dmwit: In my defense, he mentioned doing C++ earlier!
10:52:17 <ezzieyguywuf> merijn: even with the oldVal check, how are you assured that someone hasn't changed the value _twice_, and it just so happened to end up as oldVal again?
10:52:29 <ezzieyguywuf> although I guess in that case, the atomic operation shouldn't care...
10:52:36 <dmwit> You are not assured.
10:52:46 <merijn> ezzieyguywuf: Real engineers only care about sequential consistency ;)
10:52:48 <dmwit> But then, MVar/TVar can't give you that assurance, either.
10:53:04 <dmwit> If you want it, you must implement it on top, see e.g. vector clocks
10:53:25 <ezzieyguywuf> dmwit: merijn: yea, I wouldn't say this stuff is above my "pay grade" (I do this stuff for fun not work), it's just out-of-scope of the current problems I'm trying to solve.
10:53:36 <ezzieyguywuf> I'm always cautious about scope creep and premature optimization.
10:53:42 <merijn> ezzieyguywuf: Sequential consistency meaning there is *A* sequential ordering of operations that explains the final state (whether operations happened in that order is a separate problem we just sweep under the rug) ;)
10:53:58 <ezzieyguywuf> hah.
10:54:19 <monochrom> I wouldn't say "sweep under the rug". Instead it's to allow optimizations and shortcut.
10:54:35 <ezzieyguywuf> as a Real Engineer (tm) myself, but of the Mechanical variety, I don't usually care how something came bout as long as it follows the fundamental newtonian laws of physics that I'm comfortable with
10:54:38 <monochrom> This is once again yet another instance that shows that programmers lack scientific thinking.
10:54:53 <monochrom> In particular the empirical kind of scientific thinking.
10:54:54 <dmwit> Haha, imagine subscribing to Newtonian physics in 2020. ^_^
10:55:09 <merijn> monochrom: Having seen the kind of code scientists commit I'm actually kinda happy with that :p
10:55:12 <MarcelineVQ> how can physics be real if our apples aren't real?
10:55:16 <ezzieyguywuf> hey, it makes the maths easier
10:56:03 <monochrom> It is not necessary to "actually know" what "really" happened. It always suffices to just have consistency between model (theory) and observable outcome.
10:56:04 <dmwit> Personally I swear by a system of physical equations I can neither comprehend nor reproduce.
10:56:07 <merijn> dmwit: I always like to ask phycisists if they believe in atoms/electrons :)
10:56:17 <dmwit> I believe in electron, singular. ;-)
10:56:18 <merijn> monochrom: ^^ Related
10:56:57 <merijn> Like, I believe the current model we have of electrons and atoms is *useful*, but I'm sure as hell not convinced about their existence >.>
10:57:49 <fragamus_> can anyone give me a clue as to why lts-15.16 is not available?
10:57:51 <ezzieyguywuf> I saw a video about a quantum computer
10:57:52 <fragamus_> https://gist.github.com/fragamus/1b1a85fce45a91a03cb1dfddb524e700
10:57:58 <ezzieyguywuf> and, like, quantum entangling
10:58:06 <ezzieyguywuf> I was like 😮
10:58:14 <ezzieyguywuf> and also, it reminded me of Ender's Game
10:58:30 <infinisil> fragamus_: https://www.stackage.org/blog/2020/02/discontinuing-legacy-snapshots
10:58:39 <merijn> ezzieyguywuf: The good news is that the odds of quantum computing taking over/replacing regular old classical computing are near zero
10:59:01 <ezzieyguywuf> merijn: why do you say that?
10:59:19 <mmaruseacph2> fragamus_: you need a newer stack
10:59:41 <merijn> ezzieyguywuf: Because it's unclear (and currently seems rather unlikely) that quantum computers can even take over all classical computing roles
10:59:51 <fragamus_> no they stopped supporting ghcjs so I need to get it working somehow
11:00:14 <merijn> ezzieyguywuf: So it looks like they will be less general, while being much less easy to program (you practically need a phd in both quantum physics AND CS)
11:00:16 <mmaruseacph2> then you cannot access lts-15
11:00:20 <maerwald> Time to use cabal?
11:00:52 <Finianb1> quantum complexity theory is annoying af. 
11:00:56 <ezzieyguywuf> merijn: I dunno, I'm an optimist - the first 'binary' (?) computers were the size of a room, and probably required a phd to figure out
11:01:12 <ezzieyguywuf> now they're in my phone and I'm thinking about teaching my 8-year-old how to program
11:01:14 <infandum> What's a tail recursive way to get the leaves of a tree graph (no cycles, directed edges). Right now I just have mconcat . fmap leaves on a list of suc from the current node, but I have a feeling this is inefficient as it's not tail recursive
11:01:21 <merijn> ezzieyguywuf: That doesn't solve the problem of "we don't even know if they're general purpose computers yet" ;)
11:01:21 <Finianb1> Also yeah many classical algorithms have 0 speedup on quantum, and especially since getting larger quantum computers is insanely difficult from a physics perspectire
11:01:31 <merijn> infandum: Why do you want tail recursion?
11:01:32 <dsal> infandum: inefficient is not a feeling.  :p
11:01:55 <fragamus_> im using stack 1.9.3    maybe i can give it a different resolver   any recommendations?
11:02:11 <maerwald> merijn: this seems to pop up every other day here, I'm wondering where it comes from
11:02:20 <dsal> fragamus_: you're going to have a hard time unless you upgrade to something modern.
11:02:25 <merijn> infandum: Other programming languages may have taught you that "you need tail recursion for tail-call optimisation which is required for efficient recursion", this is mostly nonsense in Haskell
11:02:30 <merijn> maerwald: What?
11:02:33 <dsal> I ran into that a bunch a couple of weeks ago.
11:02:36 <ezzieyguywuf> merijn: *shrug* I don't know too much about them, but my simplified understanding is that it goes from 1's and 0's to 1's and 0's and...both. so three states. It seems that you could use a subset of these (er, the 1's and 0's) to redo all the stuff we do with computers today
11:02:50 <ezzieyguywuf> of course, that'd probably be wasteful. More neat would be to just find new ways of solving old problems.
11:02:53 <maerwald> merijn: Maybe some haskell course gone wrong ;)
11:02:53 <merijn> ezzieyguywuf: See, it's not really "both"
11:03:09 <ezzieyguywuf> or "neither", #SchrödingersCat
11:03:11 <infandum> merijn: It's a slow part of the program and it's a recursive function walking through the graph, so I assumed it's slow because of that
11:03:13 <fragamus_> there is a war on ghcjs seemingly
11:03:24 <Finianb1> it's a lot more complicated than that, and most of the complex stuff is the really crazy impossible bits
11:03:35 <merijn> ezzieyguywuf: It's "a probability distribution over 0s and 1s" a computation potentially produces "all possible results" but *observing* the result will pick a single random one of those results
11:03:44 <Finianb1> you need big state space
11:03:47 <Finianb1> yeah 
11:03:58 <infandum> Right now the G.suc is the slow memory inefficient part according to the .prof file
11:04:02 <merijn> ezzieyguywuf: So the only way to get *correct* results is by somehow making "wrong" results interfere destructively to cancel out, so that ALL of the possible results you can sample are correct
11:04:11 <Finianb1> It's a thing called bra-ket, if you look it up there are some really good articles understandable from a linear algebra perspective 
11:04:37 <merijn> infandum: Most likely there's either a space leak or something (which may, or may not require a tail call formulation to solve), but the lack of tail call is not the problem
11:04:48 <Finianb1> most algorithms are probabilistic, meaning you have to run them multiple times to increase the chance of a right answer to anywhere near useful levels
11:05:20 <merijn> infandum: Can you pastebin the code somewhere (and profile?)
11:06:05 <infandum> merijn: https://github.com/GregorySchwartz/birch-beer/blob/master/src/BirchBeer/Utility.hs
11:06:26 <ezzieyguywuf> I've been meaning to walk through this http://www.quantumplayground.net/#/playground/5653164804014080
11:06:39 <infandum> Profiling this program, it points to line 207's G.suc
11:07:28 <Finianb1> some things quantum computers are stupidly good at is prime factorization, discrete logarithm, and black-box search
11:07:38 <Finianb1> all of which are pretty good at breaking crypto
11:13:11 <ja> what's black box search?
11:14:09 <Finianb1> like you have a function and you want to find the input that gives a specific output
11:14:51 <merijn> ja: "black box" search/optimisation/testing/etc. means "where you can't inspect the internals of the thing under investigation"
11:15:14 <ja> Finianb1: but then quantum computers would be able to break hash functions. i thought that wasn't the case
11:15:49 * hackage ldap-client 0.4.1 - Pure Haskell LDAP Client Library  https://hackage.haskell.org/package/ldap-client-0.4.1 (bcj)
11:15:59 <ski> @quote not.a.box
11:16:00 <lambdabot> lispy says: Schoedinger's cat is really in a thunk not a box
11:16:43 <dmwit> I don't think "quantum computers are stupidly good at black-box search" is correct.
11:17:17 <ja> dmwit: why would someone claim that, if it is not correct?
11:17:50 <dmwit> Probably they are thinking of Grover's algorithm, which is asymptotically faster at black-box search than a classical computer can do.
11:17:58 <dmwit> But it's still stupidly slow.
11:18:07 <ja> ah, interesting, thanks
11:18:28 <Finianb1> grover's algorithm is slow on current hardware
11:18:39 <Finianb1> but quadratic speedup is nothing to scoff at
11:18:53 <dmwit> Quadratic speedup is something to scoff at when you started with exponential cost.
11:19:04 <dmwit> You only have to double the exponent.
11:19:17 <dmwit> Okay, so we spit out hashes that are twice as long. Darn.
11:19:55 <Finianb1> haha 
11:23:36 <AndroUser> Can someone confirm the purpose of this channel?
11:23:55 <bbqsaussage> m
11:24:06 <Finianb1> haskell? 
11:24:08 <maerwald> confirmed
11:24:16 <solonarv> confirmed haskell channel
11:24:39 <maerwald> it's offical then!
11:26:36 <ja> you can /msg chanserv info #haskell to see the official url and original founder of the channel if you don't trust people
11:27:21 <wavemode> what if I don't trust chanserv either
11:27:25 <Finianb1> every few weeks we switch to fortran though
11:27:27 <wavemode> chanserv is a corrupt tyrant
11:30:28 <Finianb1> down with chanserv
11:51:11 <ezzieyguywuf> if this is 'unsafe' is there another way to go about things? https://hackage.haskell.org/package/vector-0.12.0.0/docs/Data-Vector-Storable.html#v:unsafeWith
11:51:32 <ezzieyguywuf> specifically, I'm reading the "generating textures" portion here https://lokathor.gitbooks.io/using-haskell/opengl/textures.html
11:51:48 <ezzieyguywuf> (and in case that link fails, the 'textures' section of https://lokathor.gitbooks.io/using-haskell/)
11:51:49 * hackage pandora 0.2.9 - A box of patterns and paradigms  https://hackage.haskell.org/package/pandora-0.2.9 (iokasimovmt)
11:52:35 <merijn> ezzieyguywuf: It's unsafe in the sense "Vector a" is an immutable Vector
11:52:54 <merijn> ezzieyguywuf: And there's no way to stop "Ptr a -> IO b" from mutating the 'a' Ptrs
11:53:37 <merijn> ezzieyguywuf: And if that happens you have massively violated purity, possibly leaking mutation into all sorts of pure code elsewhere
11:53:47 <merijn> (which all assumed the Vector was immutable)
11:53:57 <ezzieyguywuf> so is this to be avoided at all costs?
11:54:22 <merijn> ezzieyguywuf: It just means "be really sure this function doesn't secretly try to modify the Ptr!"
11:54:34 <ezzieyguywuf> hm, I see
11:54:45 <ezzieyguywuf> but really, there's no way around it.
11:55:02 <merijn> ezzieyguywuf: You could, theoretically mapM over the vector and for every element make a temporary copy, then run the function on that copy
11:55:19 <merijn> Which would be safer, but also slower
11:55:56 <merijn> ezzieyguywuf: All the "unsafe" stuff in vector just means "this has a sharp edge, so be sure you read the fine print about what you can(not) do"
11:56:07 <ezzieyguywuf> i see.
11:56:34 <merijn> Like "unsafeIndex" doesn't check whether you're accessing the Vector out of bounds, so if you use that, you better be *sure* you're in bounds
11:56:44 <ezzieyguywuf> it really wouldn't be any different in C - if a function expects a raw pointer, I have no guarantee that the function won't modify the value it points to
11:56:52 <ezzieyguywuf> same in c++ even I think...
11:57:12 <solonarv> well, in C++ you have const pointers and so on, don't you?
11:57:34 <ezzieyguywuf> yea, but that always tripped me up, b/c a const ptr just means that the ptr address itself won't change or something
11:57:38 <ezzieyguywuf> but the value itself can
11:57:38 <merijn> I'm actually confused we should have separate read/write class for Storable and then have "read only pointers!"
11:57:52 <ezzieyguywuf> but `ptr const` is the opposite?! i dunno, lol
11:58:03 <merijn> ezzieyguywuf: You can have const pointers to non-const values, non-const pointers to const values and const pointers to const values :)
11:58:17 <wavemode> you can have const pointers and pointers to const and const pointers to const
11:58:25 <ezzieyguywuf> merijn: yea exactly, that always tripped me up. so I used const references everywhere
11:59:43 <merijn> ezzieyguywuf: Basically, for a bunch of things (like pointer access) the only truly "safe" way is to make a copy of the entire vector, but that's slow if you need to do it a lot. So the unsafe stuff is there so you can just use the vector directly "but it's on you if you do something dumb"
12:01:17 <ezzieyguywuf> merijn: can you show me an example of how I'd do it the slow 'safe' way in this specific case?
12:03:28 <merijn> Something like "Vector.mapM (\v -> Foreign.Marshal.Utils.with v yourFun)"
12:04:04 <merijn> with allocates a new copy of a value, and calls a function on a Ptr to that. So now if yourFun mutates the Ptr it will modify a temporary copy you throw away
12:04:54 <ezzieyguywuf> ah, but if `yourFun` expects the entire Vector, then I'd hae to rebuild it using with and _then_ send the copy?
12:05:11 <merijn> For example
12:54:46 <glow8> is the "iff" in these descriptions intended or is it a typo? http://hackage.haskell.org/package/base-4.14.0.0/docs/Data-Maybe.html
12:54:55 <glow8> It's in isJust and isNothing
12:55:03 <glow8> I can't edit that wiki right?
12:55:54 <dwt> iff = "if and only if"
12:56:05 <glow8> really?
12:56:10 <wavemode_> lol
12:56:13 <glow8> why not just type if and only if lol?
12:56:19 <dwt> yeah, it's a fairly common abbreviation in math/logic
12:56:20 <L29Ah> also it's not a wiki but a generated documentation
12:56:30 <glow8> I hadn't heard that before
12:56:31 <dwt> I don't think it adds much clarity in the docs there, but it's not a novel coinage
12:56:50 <glow8> okay thanks TIL
12:56:58 <wavemode_> glow8 is discovering the difference between mathematicians and programmers
12:57:10 <glow8> there really is a big difference haha
12:59:17 <merijn> glow8: The main reason why people tend to write iff is because in many specification contexts you write it A LOT and that quickly adds a lot of textual noise
12:59:41 <glow8> yeah it makes sense it just looks like a typo haha
13:01:35 <L29Ah> are there GUI toolkit bindings except gtk that work well with multithreading?
13:09:46 <dsal> glow8: A lot of words I know often look like typos.
13:11:05 <ja> L29Ah: all the web stuff works with multithreading ;)
13:11:57 <ja> but isn't it weird to say multithreading in haskell when there are so many other abstractions to use?
13:12:45 <dsal> People often say "multithreading" when they mean "concurrency"
13:13:07 <dsal> They often say "parallelism" when they mean "concurrency" too.
13:13:25 <L29Ah> i don't see anything that beats haskell's green threads re easiness to do I/O and reactive stuff at the same time
13:13:57 <ja> do you think haskell works well with those?
13:14:04 <ja> no, i mean, gtk
13:14:23 <ja> because gtk doesn't know about the green threads of haskell right? so how can it be seamless?
13:14:31 <L29Ah> yes, at least it's better than qt and wx that lack the postGUI{A,}sync functions
13:15:34 <ja> i don't think gtk and qt are fundamentally different in this aspect, are they really? i know there is a python project for using the colored await/async functions with the qt event loop: https://pypi.org/project/Quamash/
13:15:44 <ja> surely if that works, it could work with a haskell event loop too
13:15:46 <L29Ah> event loop is cancer
13:16:02 <ja> event loop is the nature of computers are they work right now
13:16:11 <ja> *as
13:16:29 <L29Ah> qt's, that is; i don't see how to work with qt from haskell green threads model
13:16:30 <pong> you wanna express how a mind works
13:16:44 <pong> and let a genius with 20 phds on compiler's turn that into computer for you
13:17:20 <ja> how is qt's event loop from gtk's?
13:17:45 <L29Ah> no idea, i know neither's workings
13:18:30 <L29Ah> https://hackage.haskell.org/package/gtk-0.14.10/docs/Graphics-UI-Gtk-General-General.html#v:postGUISync how do i do this in qt?
13:20:08 <ja> in qt, you have signal/slots, and those are thread safe. you can send a signal in a thread safe manner. i guess you could have a thread safe queue for reading back the response. but you don't wanna be doing work on the gui thread, so why block on gui stuff?
13:20:44 <L29Ah> to retrieve data from gui
13:21:14 <L29Ah> or to wait for an user to press a button on a dialog
13:21:54 <L29Ah> or to handle whatever else kind of events the gui has to offer
13:24:53 <ja> most qt code does it the other way around, you have gui code calling into the other threads for work
13:25:52 <L29Ah> and this will mess up my haskell monadic state
13:26:26 <L29Ah> that is otherwise preserved and well-separated in my green threads
13:29:45 <ja> the model i propose is not so different from the web model
13:30:11 <ja> if you had to do a web based frontend, would you really set up a websocket and push events to the frontend? that is not how most apps work
13:31:36 <ja> imho, the whole "functional core, imperative shell" is pretty much unavoidable if you're working with gtk/qt/web...
13:49:16 <frdg> I'm having some trouble understanding `<*`.  If I read `*>` as execute the first action and ignore the result and then perform the second action, then how should I think about `<*`?
13:50:31 <frdg> What is confusing me is that if I have the actions `x` and `y`, I get a different outcome if I perform `x <* y` vs `y *> x`
13:51:21 <dolio> (<*) sequences in the same order, but keeps the left result.
13:51:43 <wavemode_> @src (<*)
13:51:44 <lambdabot> (<*) = liftA2 const
13:52:03 <wavemode_> like with const, the second argument is ignored
13:52:13 <dolio> x <* y = (\x _ -> x) <$> x <*> y; x *> y = (\_ y -> y) <$> x <*> y
13:53:20 <frdg> maybe my confusion is specific to my code because everything here makes perfect sense to me.
14:02:44 <ezzieyguywuf> how can I make ghcid run main after a successful compile? but then kill main and recompile when the file changes?
14:03:46 <phadej> --run doesn't cancel?
14:04:46 <ezzieyguywuf> doesn't seem to 'run' for me
14:04:50 <ezzieyguywuf> probably using it wrong...
14:05:20 <ezzieyguywuf> I tried "--run=':main'"
14:05:26 <ezzieyguywuf> it just says "....done"
14:05:28 <ezzieyguywuf> oh wait!
14:05:51 <ezzieyguywuf> hah, just needed to export DISPLAY
14:05:54 <ezzieyguywuf> doink
14:26:31 <scasc> hm.
14:26:51 <scasc> Type synonyms are not exportable from a module?
14:27:16 <solonarv> they are
14:27:29 <solonarv> what did you type in the export list, and what error are you getting?
14:32:05 <scasc> solonarv: https://pastebin.com/6fwYTgDf
14:32:13 <scasc> This is of course stripped down.
14:33:53 <hkjhkj> Let's say I have some x = (a++) . (b++), where a, b are lists. And then I try to pattern match x as y:ys
14:34:01 <hkjhkj> not s
14:34:05 <hkjhkj> not x
14:34:14 <hkjhkj> but pattern match x ""
14:34:19 <hkjhkj> as y:ys
14:34:23 <monochrom> scasc, you have confused types with terms.
14:34:57 <scasc> monochrom: don't think so.
14:35:00 <hkjhkj> Is the whole list evaluated before I pattern match?
14:35:06 <monochrom> "data constructor ‘TA.Radians’"  It says data constructor not type.
14:35:10 <hkjhkj> I couldn't figure out how the evaluation happens
14:35:17 <scasc> I *do* have a term 'radians', but also a type synonym 'Radians'
14:35:20 <solonarv> scasc: the error points to line 30 in your paste, right?
14:35:35 <solonarv> yes, and you use this type synonym as if it was an expression
14:35:39 <solonarv> that doesn't work!
14:35:45 <solonarv> it's a type, not a constructor
14:35:58 <scasc> right.
14:36:39 <scasc> I guess I can't synonym the constructor as well (without using newtype) so that it starts with a Capital letter?
14:37:05 <scasc> (API / UX considerations)
14:37:09 <solonarv> you can with pattern synonyms, actually
14:37:38 <scasc> Ah, read of those
14:37:48 <monochrom> Tautologically, type level needs type synonyms, term level needs term synonyms.
14:38:06 <scasc> thanks
14:38:49 <monochrom> Although OOP does not confuse terms with types, people do get the wrong message from it.
14:40:34 <scasc> In this particular case the confusion rather came from the Haskell convetion, that type constructors (term level) start with a capital letter, like Types.
14:41:59 <scasc> and that the type I gave a synonym itself was a newtype which therefore only had a single constructor (with the same symbol as the newtype itself)
14:42:48 * hackage smuggler2 0.3.4.1 - GHC Source Plugin that helps to minimise imports and generate explicit exports  https://hackage.haskell.org/package/smuggler2-0.3.4.1 (jrp)
14:42:59 <MarcelineVQ> man, I think my favorite thing about functional programming is being able to beg the answer, e.g. this sort of let use where you work with an answer you haven't gotten yet to create that answer  http://hackage.haskell.org/package/base-4.14.0.0/docs/src/GHC.List.html#span
14:43:56 <monochrom> Yes that's a crazy recursion, and on top of it, a crazy use of lazy evaluation.
14:44:35 <monochrom> So even if the input list is infinite, you can start producing output promptly.
14:45:18 <monochrom> Historically, this example also gave compiler writers some headache in space usage.
14:47:41 <MarcelineVQ> it sure it useful
14:47:52 <MarcelineVQ> I've written that kind of pattern 3 times today alone
14:47:59 <monochrom> :)
14:49:14 <scasc> solonarv: but how do I export the pattern synonym I just defined? The following does not work:
14:49:18 <scasc> https://pastebin.com/tYnYMvVf
14:49:54 <monochrom> The GHC user's guide has a section on how to export pattern synonyms. New syntax is involved.
14:50:15 <solonarv> you just export it separately: 'module Data.Angle.Compat where (type Radians, pattern Radians, type Degrees, pattern Degrees, radians)'
14:50:23 <scasc> thx
14:50:24 <monochrom> This is something unlikely to be found in blogs.
14:51:55 <solonarv> btw, you can also mention normal constructors explicitly that way, e.g. 'import Data.Maybe (pattern Just, pattern Nothing)' imports the constructors but not the type they belong to
14:52:06 <solonarv> (and this also works in export lists)
14:52:51 <scasc> Thanks you two, it all works fine now
14:53:19 <solonarv> oh, also have a look at the {-# COMPLETE #-} pragma
14:53:36 <solonarv> that allows you to tell GHC which set of pattern synonyms is enough to cover all the possibilities
14:54:52 <MarcelineVQ> monochrom: hoho, actually that pattern just let me avoid extending a datatype just now with Maybe, because I can fill in the not-really-optional fields 'later on'
15:11:04 <scasc> I'm starting to ponder to just wrap my newtype in another newtype instead of using two new language extensions and a pragma.
15:11:58 <scasc> (but then I have to rederive the instances, though much might be gained by {-# LANGUAGE GeneralizedNewtypeDeriving #-}, I guess.
15:26:19 * hackage serverless-haskell 0.12.1 - Deploying Haskell code onto AWS Lambda using Serverless  https://hackage.haskell.org/package/serverless-haskell-0.12.1 (AlexeyKotlyarov)
15:32:28 <hjkhj> Hey I would appreciate some help. If I have k = f . g, and I apply k to x, as k x, then does f need to get evaluated first, before g is applied to x.
15:33:05 <hjkhj> Assuming f, g are compositions themselves
15:34:55 <hjkhj> Or does it evaluate g first?
15:55:32 <hjkhj> sorry
15:55:33 <hjkhj> bump
15:55:34 <hjkhj> Hey I would appreciate some help. If I have k = f . g, and I apply k to x, as k x, then does f need to get evaluated first, before g is applied to x.Assuming f, g are compositions themselves
15:55:53 <hjkhj> I'm trying to understand this http://h2.jaguarpaw.co.uk/posts/demystifying-dlist/
15:57:05 <ja> why would f get evaluated first? i don't see why
15:57:14 <ja> which section of the article are you referring to?
15:57:40 <spatchkaa> f will be forced first if that is what you are asking
15:57:46 <hjkhj> oh yea
15:57:48 <hjkhj> it is
15:57:52 <hjkhj> why is f forced first
15:58:05 <spatchkaa> open ghci and go k = error "f" . error "g"
15:58:08 <hjkhj> and what is "forced". I might be misinterpreting the term
15:58:11 <spatchkaa> and then apply k to something
15:58:44 <ja> > error "f" . error "g"
15:58:46 <lambdabot>  error:
15:58:47 <lambdabot>      • No instance for (Typeable a0)
15:58:47 <lambdabot>          arising from a use of ‘show_M701361694026486095222290’
15:59:05 <spatchkaa> if you say 'thing = k x', you don't evaluate anything, but build a thunk that will be evaluated when thing is forced
15:59:41 <spatchkaa> it will only ever actually get evaluated when something asks for its value (or "forces" it)
15:59:46 <hjkhj> Right, so it's forced when we pattern match
15:59:47 <hjkhj> right
16:00:04 <hjkhj> So, assuming I'm pattern matching the expression to something
16:00:12 <hjkhj> then f will always get evaluated first?
16:01:18 <hjkhj> And how did you know that f will get forced first? Is that a property of the way . is written
16:01:22 <hjkhj> ?
16:04:14 <spatchkaa> f . g $ x is f (g x). to evaluate this, f will be applied to the "thunk" representing g x. f must then be evaluated far enough so that evaluation can proceed. Therefore if f is error "f", we will force error "f" causing failure before we ever force the thunk g x
16:04:50 <hjkhj> oh thanks
16:05:31 <spatchkaa> if f was say const 123, and g was error "g", we could say k = f . g, and apply k to x, and we would get 123 (without ever evaluating the function g, because we didn't need to)
16:05:32 <Axman6> > let k = error "f" . error "g" in k 10
16:05:33 <hjkhj> for some reason I kept thinking that g must be evaluated first since we don't need "f" yet. But it makes sense that g x will be represented as a thunk
16:05:34 <lambdabot>  *Exception: f
16:05:45 <Axman6> that surprises me
16:06:40 <spatchkaa> > let k = const 123 . error "g" in k 10
16:06:42 <lambdabot>  123
16:09:08 <solonarv> hjkhj: evaluation starts at the outermost part of the program/expression, and functions are evaluated before their arguments
16:09:12 <solonarv> (generally speaking(
16:09:13 <solonarv> ))
16:09:44 <Axman6> \x -> error "f" (error "g" x)
16:09:58 <Axman6> which of course makes sense why f is evaluated first
16:12:13 <hjkhj> What are some exceptions to arguments being evaluated before functions? solonarv
16:12:46 <hjkhj> but thanks everyone. This example was illuminating
16:13:26 <solonarv> exceptions are basically "GHC statically figures out which function is being applied and that it's a strict function, so it does some optimizations"
16:14:14 <spatchkaa> you could define your own version of compose that is strict in the second argument (so it would force g first, failing on error "g" in the above examples)
16:14:27 <hjkhj> I see
16:15:49 <solonarv> @let f .! g = g `seq` (f . g)
16:15:51 <lambdabot>  Defined.
16:16:04 <solonarv> > let k = error "f" .! error "g" in k 10
16:16:06 <lambdabot>  *Exception: g
16:17:11 <dolio> There's no guarantee that `\x -> error "f" (error "g" x)` will give the f error.
16:17:40 <dolio> And also no guarantee that the `seq` version will give the g error.
16:18:03 <hjkhj> Why not?
16:18:06 <hjkhj> dolio
16:18:11 <solonarv> 'f . g' is never bottom, so 'g `seq` (f . g)' is bottom iff g is bottom
16:20:03 <dolio> hjkhj: Because there is no guarantee of exact evaluation order, aside from 'non-strict', which allows the compiler to reorder things if it thinks it's beneficial for instance.
16:21:17 <sfogarty> Hello! We are trying to create a framework for autograding projects in my class. Inspired by hspec, we are working in the Writer monad to build a tree. This works great for making labeled sections  in the tree `censor (\lst -> [Node lst])`. This does not work well for adding a grading rubric: the best we have now is a function from a list of Bool
16:21:18 <sfogarty> to a number, where the inputs are matched up linearly to the list of tests. This is clearly Awful. Is there a better monad/way to connect the test items added through `tell` to a function of their post-evaluation outputs?
16:21:22 <hjkhj> So, if I have f . g, it's not a guarantee that f will be evaluated first?
16:22:03 <solonarv> I struggle to think of a situation where 'f' wouldn't be evaluated first in '(f . g) x'
16:22:36 <solonarv> note that 'f . g' doesn't evaluate anything. it reduces to '\x -> f (g x)', which is already in WHNF
16:22:56 <hjkhj> yea, when I say that I mean, when we apply it to something and pattern match
16:23:14 <sfogarty> I would assume (naively) the order would be x, then g, then (g x), then f, then f (g x )?
16:23:16 <dolio> Right, it is not guaranteed.
16:23:29 <sfogarty> wait, no
16:23:33 <sfogarty> That's exactly wrong.
16:23:34 <solonarv> sfogarty: that's completely backwards ;)
16:23:42 <sfogarty> 100% totally backwards.
16:23:55 <hjkhj> Then this DList implementation http://h2.jaguarpaw.co.uk/posts/demystifying-dlist/, isn't guaranteed to work as stated in the article
16:24:11 <hjkhj> Seems to me that they use the fact that `f` is evaluated first
16:25:37 <solonarv> I suppose if f is known at compile time and enough inlining and other optimizations happen, then '(f . g) x' could end up evaluating 'g' first at run time, or 'x'... because f and/or g were already "evaluated" at compile time! :p
16:27:00 <dolio> All the compiler has to know is that `f` will be strict, then it can choose to evaluate `g x` first. `error "f"` is strict.
16:28:00 <solonarv> 'error "f"' is strict in that it's bottom if its argument is bottom, but not strict in the sense that it always evaluates its argument
16:28:08 <solonarv> (in fact it never evaluates its argument)
16:28:53 <dolio> It is strict via the definition of what strict means, and not some other definition that is not what strict means.
16:29:13 <solonarv> well, instead of talking in circles let's ask GHC's strictness analyzer
16:35:34 <solonarv> GHC shows a strictness of 'x' for 'kaboom = error "kaboom"', '<B,1*U>x' for 'definitelyStrict !_ = error "definitelyStrict"', and '<B,A>b' for 'kaboomArgs x = error "kaboomArgs" x'
16:36:10 <solonarv> now I'll admit I don't know how to read those, but they sure don't look the same to me. Clearly GHC's strictness analyzer distinguishes between these cases somehow.
16:39:36 <solonarv> here's the test file: https://gist.github.com/Solonarv/f31084f7f32468bd65ca1b4073658693
16:39:49 * hackage hw-rankselect-base 0.3.4.1 - Rank-select base  https://hackage.haskell.org/package/hw-rankselect-base-0.3.4.1 (haskellworks)
16:46:02 <{abby}> 1*U is "used" and A is "absent"
16:47:54 <{abby}> https://gitlab.haskell.org/ghc/ghc/-/wikis/commentary/compiler/demand
17:10:35 <solonarv> {abby}: ah, thanks. hopefully I'll remember that the next time I want to look at strictness analyzer output :p
18:00:48 <d34df00d> Alright, bikeshedding time.
18:00:52 <d34df00d> How do you format code with `finally`?
18:01:54 <d34df00d> I currently have `handleAct (WithFile act) = withTempFile "" "pattern.pat" $ \path handle -> runStuff with file` without finally, and I want to run some computation after `runStuff` is done no matter what.
18:01:57 <ezzieyguywuf> "Could not find module ‘Control.Lens.Tutorial’"
18:02:06 <ezzieyguywuf> but I just did `stack install lens-tutorial`
18:02:11 <ezzieyguywuf> then `stack ghci`
18:02:31 <wavemode__> :set -package lens-tutorial ?
18:03:47 <ezzieyguywuf> wavemode__: tried that, "cannot satisfy -package lens-tutorial"
18:06:34 <nknk> hi, can data constructors be considered functions which take arguments and produce a value of some type? If not then what are they officially
18:06:59 <wavemode__> that's exactly what they are
18:07:47 <sm[m]> ezzieyguywuf: since you're not inside a project with a stack.yaml, you need to say stack ghci --package lens-tutorial
18:07:53 <L29Ah> nknk: yes, except you can't pattern match on arbitrary functions
18:08:26 <wavemode__> :t Just
18:08:28 <lambdabot> a -> Maybe a
18:08:56 <wavemode__> :t Just "hello"
18:08:57 <lambdabot> Maybe [Char]
18:11:00 <nknk> what is the difference between a "value" and a "function"? I know that expressions evaluate to values, and values of types. Functions are also values with types.
18:11:16 <nknk> I guess that's a dumb question
18:11:22 <nknk> There are values which are not functions
18:11:25 <nknk> like [1, 2, 3]
18:11:48 <ski> > let f . ((\g x -> f (g x)) -> fg) = fg in (map toLower . reverse) "Foo"  -- pattern-matching on an arbitrary function
18:11:50 <lambdabot>  "oof"
18:11:54 <sm[m]> ezzieyguywuf: and to make that happen by default, in ~/.stack/global-project/stack.yaml you could add
18:11:54 <sm[m]> extra-deps:
18:11:54 <sm[m]> - lens-tutorial-1.0.4
18:12:24 <ski> nknk : not data constructors are functions
18:12:48 <L29Ah> nknk: [1, 2, 3] is a function that takes zero argument
18:12:50 <L29Ah> s
18:12:51 <ski> er, "not all", i meant to say
18:12:56 <ski> L29Ah : no
18:13:06 <L29Ah> ski: why not?
18:13:11 <ski> all functions in Haskell takes exactly one argument
18:13:16 <nknk> Isn't [1, 2, 3] just a value of type [Int]
18:13:25 <ski> `[1,2,3]' is a list, not a function
18:13:54 <ski> `False',`True',`Nothing',`[]' are examples of data constructors which are not functions
18:14:49 <ski> Haskell doesn't have multiple-argument functions
18:15:23 <nknk> L29Ah I don't think it can be a function without the `->`. Is that right?
18:15:53 <ski> (but there's a common way -- in fact there's two -- for encoding multiple-argument functions, in Haskell. i tend to call them "curried style" and "tupled style")
18:15:58 <ski> nknk : yes
18:16:24 <ski> functions are exactly those values whose types have a shape like `... -> ...'
18:16:24 <nknk> thanks
18:16:33 <Axman6> d34df00d: break out the parts into named functions/values and then just fo foo `finally` bar
18:16:44 <ski> lists are exactly those values whose types have a shape like  `[...]'
18:16:49 <L29Ah> 04:11:26]<ski> > let f . ((\g x -> f (g x)) -> fg) = fg in (map toLower . reverse) "Foo"  -- pattern-matching on an arbitrary function
18:16:50 <L29Ah> wat happens, what should i read to understand that second ->?
18:17:07 <wavemode__> -XViewPatterns
18:17:10 <d34df00d> Axman6: well that works I guess.
18:17:20 <ski> L29Ah : look up the `ViewPatterns' language extension. and yes, that example is a bit silly
18:17:30 <jusss> that `fix`, is there a without `let` defintion?
18:17:31 <L29Ah> okay, i was frightened that it's the standard haskell
18:17:34 <jusss> @src fix
18:17:34 <lambdabot> fix f = let x = f x in x
18:17:38 <Axman6> d34df00d: I'm terrible at actually following that advice, but it always works out for the best
18:17:58 <Axman6> jusss: fix f = f (fix f)
18:18:00 <nknk> Wait if functions are values, do they have data constructors?
18:18:08 <Axman6> but it's not a good as the self referential version
18:18:09 <ski> nknk : no
18:18:13 <jusss> Axman6: ok
18:18:25 <ski> nknk : the closest thing is the lambda expression notation
18:18:43 <nknk> I see. So, is there any other value other than functions which don't have data constructors?
18:19:05 <ski>   fix f = x where x = f x  -- how i prefer to read it
18:19:44 <ski> nknk : depends on whether you include internal low-level implementation details
18:19:58 <ski> nknk : but you could take `IORef' as an example
18:21:01 <ezzieyguywuf> sm[m]: got it I'll try that
18:21:31 <ski> you can't define `IORef' from scratch, in Haskell
18:22:03 <nknk> i see thanks
18:22:05 <nknk> \leave
18:22:17 <L29Ah> nknk: `data Void` has no constructors
18:22:40 <L29Ah> :t undefined :: Void
18:22:42 <lambdabot> Void
18:22:46 <ski> nknk : if Haskell had a proper distinction between inductive and coinductive data types, the latter could probably in some sense be said to not have constructors
18:22:48 <Axman6> they left
18:23:30 <ski> mm
18:23:46 <Axman6> so rude
18:23:54 <wavemode__> lol
18:23:56 <ski> (i presume when they said "value", they didn't have bottoms in mind)
18:24:30 <ski> (since otherwise, `undefined :: Bool' is also an example)
18:45:02 <ezzieyguywuf> how do I do `p'=qpq-1` using a Quaternion and a V4 from linear?
18:45:08 <ezzieyguywuf> or am I using the wrong data structures?
18:45:40 <ezzieyguywuf> (this is what I'm referring to https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation#Using_quaternion_as_rotations)
18:49:40 <ezzieyguywuf> nvm, there is the rotate function in Linear.Quaternion
18:54:08 <jusss> Axman6: I tried that fix f = f (fix f), it won't work in python, does haskell do some magic on it?
18:54:26 <jusss> fix = lambda f: f(fix(f))
18:54:36 <jusss> reverse__ = lambda f: lambda l: [] if l == [] else f(l[1:]) + [l[0]]
18:54:50 <L29Ah> no magic
18:55:07 <L29Ah> probably python has no TCO though
18:55:19 <dolio> Python is call-by-value, so you'd need to use a different combinator.
18:55:37 <jusss> L29Ah: fix(reverse__) will stack over flow
18:55:56 <jusss> dolio: like what?
18:56:08 <L29Ah> https://stackoverflow.com/questions/13591970/does-python-optimize-tail-recursion yup
18:56:29 <jusss> this is not related to lazy eval?
18:57:18 <jusss> I will try it in racket
18:57:20 <L29Ah> no
18:58:48 <dolio> `fix f x = f (\y -> fix f y) x` or something along those lines.
19:01:08 <dolio> It's probably only important to guard the fix call.
19:01:33 <fog> https://pastebin.com/raw/q9z8AYpM
19:01:43 <fog> cant get the specificity matching to work
19:01:53 <fog> helpf!
19:05:31 <jusss> (define fix (lambda (f) (f (fix f))))
19:05:58 <dolio> Racket is also call-by-value.
19:06:32 <jusss> (define reverse_ (lambda (f) (lambda (l) (if (eq l '[]) '[] (cons (f (cad l)) (car l))))))
19:07:14 <jusss> dolio: so this fix is related to eval stratege?
19:07:31 <Axman6> cad and not cdr?
19:07:48 <jusss> cdr, yes
19:08:19 <jusss> I don't use scheme for a long time...
19:08:42 <Axman6> I've never written any lisp, but I remember that from SICP
19:08:56 <dolio> jusss: Yes. Call-by-value will just keep calling fix forever immediately.
19:09:14 <dolio> So you need to eta expand around the call to fix, and it can't work for values.
19:09:22 <dolio> Or, non-functions.
19:10:49 <ski>   (define fix (lambda (f) (lambda args (apply (f (fix f)) args))))  ; jusss
19:11:46 <jusss> dolio: you're right! fix = lambda f,x: f((lambda y: fix(f,y)),x)
19:12:01 <jusss> reverse_ = lambda f,l: [] if l == [] else f(l[1:]) + [l[0]]
19:12:07 <jusss> print(fix(reverse_,[3,8,9]))
19:12:10 <ski>   (define fix (lambda (f) (lambda (x) ((f (fix f)) x))))  ; or this, if you just want to support passing one argument to `f'
19:13:38 <ski> ok, you uncurried your Python version
19:14:33 <jusss> ski: I like currying, but python doesn't do it
19:14:43 <jusss> from functools import partial
19:14:47 <ski>   fix = lambda f: lambda x: f(fix(f))(x)
19:15:19 <ski>   reverse = fix(lambda f: lambda l: [] if l == [] else f(l[1:]) + [l[0]])
19:15:21 <jusss> f = partial(fix,reverse_)
19:15:37 <ski>   print(reverse([3,8,9]))
19:15:46 <ski> jusss : are you sure something like that ^ doesn't work ?
19:16:07 <jusss> ski: yes, it will work, 
19:16:22 <ski> so, Python does "support currying"
19:17:43 <jusss> "The obvious definition of the Y combinator (\f-> (\x -> f (x x)) (\x-> f (x x))) cannot be used in Haskell because it contains an infinite recursive type (a = a -> b). Defining a data type (Mu) allows this recursion to be broken. "
19:17:51 <jusss> https://rosettacode.org/wiki/Y_combinator#Haskell
19:18:18 <jusss> is that true?
19:18:36 <ski> oh, and `(cons (f (cad l)) (car l))' in your Scheme version ought to be `(append (f (cdr l)) (list (car l)))' (and i'd rather use `(null? l)' as the condition)
19:18:54 <fog> see, it works if the overlapping instances are not used, but then i cant get the defaults that are possible; https://pastebin.com/raw/AK0fncsN
19:18:59 <ski> jusss : yes. you can do it with `ocaml -rectypes', though
19:20:04 <ski> (but there's a reason why neither Haskell, nor OCaml (by default) supports equi-recursive types, aka "infinite types" or "cyclic types")
19:20:20 <jusss> dolio: "<dolio> `fix f x = f (\y -> fix f y) x` or something along those lines." you did twice eta-conversion?
19:20:40 <jusss> fix f = f (fix f); fix f x = f (fix f) x
19:20:51 <jusss> fix f x = f (\y -> fix f y) x
19:20:53 <ski> jusss : "It's probably only important to guard the fix call."
19:21:31 <jusss> ski: by how?
19:21:37 <ski> huh ?
19:21:49 <ski> (i don't understand the question)
19:21:55 <jusss> I don't understand "guard the fix call"
19:22:25 <ski> `fix f = f (\y -> fix f y)' is enough
19:22:46 <jusss> I will try it
19:22:56 <ski> (that's what i wrote in my Scheme and Python versions, anyway)
19:23:30 <ski> jusss : but, this is assuming a strict language (otherwise no eta is needed)
19:23:35 <fog> anyway,, the example shows how the "tape scanner" is supposed to work, which it does
19:23:59 <fog> its end to end composition of state encodings into a "producer"
19:25:06 <fog> it relies on a "finally" instane
19:25:11 <fog> instance*
19:25:21 <fog> i think there should be something dual to this with consumers
19:25:27 <jusss> ski: fix = lambda f: f(lambda y: fix(f(y)))
19:25:42 <jusss> ski: print(fix(reverse_)([3,9,2])) this won't work...
19:26:08 <jusss> my mistake
19:26:16 <fog> i think it gives a (Co)Monad instance for the State encoding...
19:26:34 <fog> but i could do with some help thinking it through
19:26:34 <jusss> fix = lambda f: f(lambda y: fix(f)(y))
19:26:34 <ski> jusss : of course it doesn't
19:26:52 <ski> the call to `f' should be inside the eta, not outside
19:27:57 <ski> (and you don't want to pass the composition of `fix' and `f', to `f' ..)
19:27:57 <jusss> ski: sorry, I don't know how to write it
19:28:16 <ski> starting with the (non-working, because of by-value) :
19:28:32 <ski>   fix = lambda f: f(fix(f))
19:29:07 <ski> you want to eta-expand `f(fix(f))' (not `fix(f)', which isn't even what you did, although it looked closer to that))
19:29:34 <stevenxl> Hi folks. I heard that type-level programming in Haskell is Turing Complete. Does this mean that, theoretically, you can write a web server with only type-level programming? How would that be possible? Don't you, at the end of the day ,have to send strings (or bytes) out to the real world?
19:29:52 <ski> to eta-expand `g', you write `lambda x: g(x)' (assuming `g' expects only one argument)
19:30:09 <ski> in your case, `g' is `f(fix(f))'. what's the eta-expansion, then ?
19:30:41 <jusss> it's really confused to use eta-conversion in python
19:30:44 <ski> stevenxl : Turing-completeness doesn't imply ability to do I/O
19:30:50 <ski> jusss : how so ?
19:31:02 <jusss> `fix f = f (\y -> fix f y)'
19:31:49 <jusss> f(lambda y: fix(f,y))?
19:31:51 <ski> recall that `fix f y' really means `(fix f) y'. or, if you want to write it in a way that reminds more of Python function call notation, it would be `fix(f)(y)' or even `(fix(f))(y)'
19:32:01 <stevenxl> ski:  Hi. I am no computer scientist. What I am trying to understand is that type-level programming means operating on types (instead of values). Is that ever useful if we never use teh type information to do something (or not do something, as teh case may be) at teh value level?
19:32:17 <ski> jusss : no, where did the second argument to `fix' come from ?
19:32:51 <fog> stevenxl: yes its very useful
19:32:54 <ski> jusss : `fix(f)' returns a function. you want to pass an argument to the function that the call to `fix' returns. `fix', as currently defined, takes only a single argument (`f')
19:33:16 <ski> jusss : as a later step you may, if you want to, "uncurry" `fix', so that it takes two arguments
19:33:16 <jusss> fix(f)(y)?
19:33:20 <ski> yes
19:33:30 <fog> stevenxl: even if you dont use singletons to get the type information at value level
19:33:33 <jusss> fix = lambda f,y: 
19:33:37 <ski> no
19:34:00 <ski> eta-expansion doesn't mean "add some extra arguments to a function"
19:34:18 <fog> stevenxl: it allows you to write types you otherwise couldnt, or at least, to factorise them eloquently into type level programs 
19:34:25 <ski> `fix' is a function that expects one argument. `f' is also a function that expects one argument
19:35:15 <stevenxl> Or do we need, at some point, to communicate information between these two levels of haskell's type system? For example, use a typeclass to go from a type to a value (we can think of Show Int as giving us the ability to go from a type (Int) to a value (a function from Int to String), and phantom types / GADTs to send information up to the type level. For example, given newtype Distance unit = Distance { unDistance :: 
19:35:15 <stevenxl> Double}, I can, at the value level, write `Distance 10 :: Distance Miles`,and send the type information from teh value level to the type level.
19:35:18 <fog> languages without type level programming are arguably much less useful 
19:35:35 <ski> if `f' returns a function, then `fix(f)' will also return a function. it's this function, that is returned, that you want to eta-expand. you don't want to add extra arguments to `fix'. `fix' itself is not being eta-expanded (and adding arguments wouldn't be how one would go about eta-expanding it)
19:36:20 <fog> stevenxl: have you encountered singletons? thats the more coherent way to interchange type and value level information
19:36:47 <ski> stevenxl : "Is that ever useful if we never use teh type information to do something (or not do something, as teh case may be) at teh value level?" -- well, type classes may be seen as a kind of type-level programming, in Haskell. the result of this type-level computation is how to construct particular instances, which may affect program behaviour
19:37:02 <fog> though, as stated, they are not at all nessacary to make type level programming "useful" 
19:37:04 <stevenxl> fog:  Hi. Thank you for responding. I think my understanding of everything else around type-level programming is too shaky to move on to singletons.
19:37:19 <fog> but its exactly what your talking about
19:37:38 <fog> you are essentially "moving on to singletons"
19:38:15 <fog> im not sure how complicated type level programing could be thought to be... that it would somehow prevent understanding as you say
19:38:21 <ski> stevenxl : type classes may be thought of as relations/predicates on types. so, you can do some (simple) relational / logic programming, using types, in Haskell
19:38:58 <jusss> ski: sorry, I'm really confused your anwser, could you show it? 
19:39:14 <jusss> fix = lambda f: f(lambda y: fix(f)(y))?
19:39:25 <ski> (you're limited quite a bit, by not having access to nondeterminism / backtracking (e.g. to implement a choice that doesn't immediately come from direct pattern-matching), though ..)
19:40:19 <ski> (.. now i wonder whether one could work around that, by defining type classes in CPS .. sounds like something Oleg would quite possibly have already tried, so i'd go look at his site a bit)
19:40:37 <fog> for sure, we could do with a more "haskelly" style of type level programming in haskell
19:40:46 <ski> jusss : you're still eta-expanding `fix(f)', rather than `f(fix(f))'
19:41:04 <ski> fog : yea .. type families do that, to some extent
19:41:22 <ski> @where Oleg
19:41:22 <lambdabot> http://okmij.org/ftp/
19:41:30 <fog> right, but pattern matching, and type-level-functions as first class citizens  
19:41:40 <fog> and even lazy evaluation
19:42:06 <fog> im not quite sure of the technical barriers that prevent these developments
19:42:14 <stevenxl> fog: So the idea that I have in my head - that communication between the value / type (and maybe kind) levels is part of type-level programming is not crazy right? type-level programming is about informing behavior at runtime - i.e, what values are / can be.
19:42:37 <fog> certainly this is normal 
19:42:40 <ski> @quote terrifying
19:42:41 <lambdabot> shapr says: <shapr> Oleg will do something terrifying like implementing type checking in tcp/ip checksums on the router level through someemergent property of BGP and he'll do it all with HSP!
19:42:44 <jusss> ski: please show me the code
19:42:50 <stevenxl> fog:  :-)
19:42:50 <ski> @quote type-hackery
19:42:50 <lambdabot> shapr says: <shapr> Yeah, it does require more than an oleg of type-hackery. <poetix> oleg's now a unit? <autrijus> is oleg an unit now? <shapr> Yup, a rather large unit of type-hackery too.
19:43:24 <ski> fog : there's no lambdas, on the type level
19:43:41 <fog> that too... but i guess thats a symptom of no first class functions
19:45:01 <ski> stevenxl : part of the cool thing about GADTs is that one can "let the run-time inform the compile-time", so that one can already at compile-time, in the appropriate branch, know something statically about a condition which may arise at run-time
19:45:42 <fog> oleg was working before type families, i guess there must be some kind of moors law to do with olegs of type level power increasing as SPJ and Eisenberg brute force their way through the ethereal maze of the haskell type checking machine
19:46:09 <stevenxl> ski:  OK - thank you.  That gives me a bit of confidence that I'm not just completely misunderstanding things. That there is communication between the two worlds - these ports (GADTs from value -> type and typeclasses from type -> value), and maybe even more.
19:46:11 <fog> et al.
19:46:38 <ski> jusss : eta-expanding `g' (for one argument) yields `lambda y: g(y)'. so, eta-expanding `f(fix(f))' (for one argument) yields `lambda y: f(fix(f))(y)' (i simply replaced `g' by `f(fix(f))')
19:47:19 <ski> jusss : so, in the definition `fix = lambda f: f(fix(f))', eta-expanding `f(fix(f))' there yeilds `fix = lambda f: lambda y: f(fix(f))(y)'
19:48:40 <dertoast> Hi, is anyone familiar with ghci's `:doc` functionality? In particular, how do I get it to work with dependencies? I'm using stack
19:48:53 <c_wraith> build haddocks for them
19:49:07 <Axman6> probably start with `stack haddock`
19:49:21 <Axman6> not sure if that'll make it work, but would be the place I'd start
19:49:28 <dertoast> I've run stack haddock, but it doesnt seem to find the generated docs
19:49:51 <ski> @quote standard.operating.procedure
19:49:51 <lambdabot> Pseudonym says: What was considered 100 milli-Olegs of type hackery five years ago is standard operating procedure these days
19:50:46 <dertoast> When I run stack haddock it appears that the generated docs are placed in my stack root, instead of the project's stack-work?
19:51:30 <dertoast> I am running windows, so that could be an issue too I guess
19:52:07 <jusss> ski: ok...
20:02:35 <ski> jusss : anything unclear ?
20:04:09 <jusss> fix2 = lambda f: lambda y: f(fix2(f))(y)
20:04:12 <ski> (if you then wanted to uncurry `fix', you'd first need to also eta-expand `fix(f)' ..)
20:04:36 <jusss> fix2 f = \y -> f (fix f) y?
20:04:47 <ski> yes
20:04:50 <jusss> fix2 f = \y -> f (fix2 f) y?
20:05:07 <jusss> but, "`fix f = f (\y -> fix f y)' is enough"
20:05:48 <jusss> fix f = f (fix f); do one eta-conversion, fix f = \y -> f (fix f) y
20:05:51 <ski> oh, sorry
20:05:54 <ski> that's my fault
20:06:12 <ski> <jusss> fix f x = f (\y -> fix f y) x
20:06:28 <jusss> ski: yes, I followed your code and turn it to python...
20:07:07 <ski> i wanted to emphasize that the outer extensionality there wasn't necessary. but failed to look close enough at the other part of what you'd written, which did the (inner) eta in the wrong place
20:07:34 <jusss> ski: wait, but f (fix f) == f (\y -> fix f y)?
20:08:30 <ski> but i see that led to some confusion, now :/
20:08:33 <ski> mea culpa
20:09:26 <ski> yes (although i'd say `='. `==' in Haskell is equality-checking, and you can't (in general) check the equality of functions (recall `f' is supposed to return a function, if we're considering the by-value fixed-point combinator)
20:12:32 <jusss> ski: fix f = f (fix f) = \y -> f (fix f) y = f (\y -> fix f y)?
20:12:56 <jusss> outsider and inner eta-conversion
20:13:55 <ski> hm, yes. so i ought to have said that `fix f x = f (fix f) x' is enough. sorry about that
20:14:14 <jusss> ski: oh, I see
20:14:53 <ski> you want the call `fix f' to not immediately call `fix' again
20:15:03 <monochrom> It is easy to lose track and forget that Haskell is merely a programming language.
20:15:33 <ski> so, if you define `fix f' to be `\y -> (...) y', then that lamda will "guard" the `fix' call inside `...', which here is `f (fix f)'
20:18:00 <ski> next, when you actually supply an input `y' to `fix f', you don't want the body `f (fix f) y' to run away into an infinite loop. but since `fix f' here will compute (say) `\z -> (...) z' (renaming `y' to `z', just for clarity), that call to `fix' won't cause any further immediate expansion. only when `f' decides to call its argument function, with some input `z', will that `...' inside the argument function `\z -> (...) z' happen
20:18:06 <ski> and so on ..
20:19:12 <ski> jusss : does that make any sense ?
20:19:44 <gaze__> hey what's the right way to understand the difference between uniplate and biplate?
20:19:56 <gaze__> uniplate mostly makes sense but the type signatures for biplate are throwing me for a bit of a loop
20:20:06 <jusss> ski: this trick is related to that trampoline?
20:20:27 <ski> jusss : not really
20:20:42 <monochrom> Completely unrelated to trampoline.
20:20:43 <ski> (at least not that i'm aware of)
20:21:17 <monochrom> Instead, this is how to fake call-by-name in a call-by-value language, by raising every basic value to the function level.
20:21:27 <ski> trampolines can be used to implement tail-calls on top of a system which doesn't provide them
20:21:52 <monochrom> You want "1+1" to be evaluated later not sooner? Turn it into a function, \() -> 1+1.
20:22:16 <ski> (such a function is often called a "thunk")
20:22:21 <jusss> ski: someone tell me that eta-conversion could be really help when do reduction in CPS, he suggest me to read <On One-Pass CPS Transformations>
20:22:39 <ski> hm, i don't recall if i've read that one
20:22:44 <jusss> and I have no idea what that is now...
20:23:06 <jusss> by Oliver Danvy
20:23:19 <ski> jusss : but you might perhaps have some use, reading either "Abstracting Control" or "Representing Control" (i forgot which), by Olivier Danvy & Andrzej Filinski
20:23:37 <ski> hah, doesn't surprise me that that was Danvy
20:24:05 <ski> and yes, strategic eta-expansions are helpful for that
20:24:17 <d34df00d> I have a function `compileTerm :: [a] -> a -> b` and I want to write a function `compileTerms :: [a] -> [b]` that will take each possible (prefix, elem) pair of the list and pass it into `compileTerm`, collecting results.
20:24:26 <d34df00d> Is there any combinator that's reasonably close?
20:25:02 <jusss> ski: I will take a little time to think about this, and thank you
20:29:02 <d34df00d> Alright, compileTerms terms = [ compileTerm ctx term | (ctx, term) <- zip (inits terms) terms ] brings me reasonably close.
20:29:05 <d34df00d> Or zipWith for that matter.
20:29:29 <ski> @type let splits xs0 = ([],xs0) : case xs0 of [] -> []; x:xs -> [(x:pre,post) | (pre,post) <- splits xs] in \compileTerm xs -> [compileTerm pre x | (pre,x:_) <- splits xs]
20:29:30 <lambdabot> ([t] -> t -> a) -> [t] -> [a]
20:29:59 <d34df00d> Hmmm.
20:30:04 <d34df00d> ski: what do you think about that vs above?
20:31:28 <ski> probably not too bad
20:31:41 <d34df00d> I find it hard to reason about performance of both.
20:31:50 <d34df00d> Or rather
20:31:52 <d34df00d> I find it hard to reason about performance.
20:32:30 <ski> i suspect the difference isn't too great
20:41:48 <Axman6> gaze__: what are you struggling with?
20:44:32 <Axman6> gaze__: does http://dev.stephendiehl.com/hask/ help at all? (search for biplate)
20:46:03 <gaze__> Yes perfect!
20:46:04 <gaze__> thank you.
20:46:19 <gaze__> that page is such a good reference-- I really should check there first more often.
20:46:22 <Axman6> make sure you bookmark than and refer to ir regularly
20:52:59 <gaze__> Axman6: Oh is the idea with biplate that you have definitions that allow you to cross from one type to another?
20:53:43 <gaze__> so if you're traversing some AST (as in the example) you can cross from statements to exprs
20:53:59 <gaze__> and then uniplate is just biplate where from = to... where you're moving around inside one type
20:55:19 <Axman6> I'm not that familliar with any of this, but my understanding is that biplats lets you access all values of a given type inside another type, so all Texts inside an aeseon Value for example
20:56:04 <Axman6> biplate*, aeson*
20:59:40 <gaze__> yeah that's sounding right
21:01:59 <gaze__> I have a situation where I want to figure out all the captured variables in a block of code...
21:02:32 <gaze__> I have some Expr a... I guess I want to map this to an Expr (a, captured) and go bottom up 
21:24:19 * hackage hanspell 0.2.2.0 - Korean spell checker  https://hackage.haskell.org/package/hanspell-0.2.2.0 (9beach)
22:02:35 <dsal> I'm not convinced biplate is useful for more than parlor tricks.  I used it once for a JSON thing and someone showed me a smaller, less magical way to do the same thing.
22:04:21 <Axman6> I think it along with lens can be super powerful - find me all strings in this object which are URLs, and set the hostnames to lowercase is a pretty simple one liner
22:10:47 <dsal> Sure, you can do that without biplate for JSON, though.  I guess I've not run into the other cases.
22:12:43 <Axman6> :t partsOf biplate
22:12:45 <lambdabot> (Functor f, Data t, Typeable a) => LensLike f t t [a] [a]
22:28:59 <dsal> Yeah, both of those are neat.  There are other paths that got me where I was going, though.
22:29:00 <dsal> :t deep
22:29:02 <lambdabot> (Conjoined p, Plated s, Applicative f) => Traversing p f s s a b -> Over p f s s a b
22:30:02 <dsal> Haskell has a pretty big vocabulary.  heh
22:34:19 * hackage flaccuraterip 0.3.9 - Verify FLAC files ripped form CD using AccurateRip™  https://hackage.haskell.org/package/flaccuraterip-0.3.9 (NicolaSquartini)
23:08:57 <hololeap> is there a module that has ByteString versions of functions in System.IO ?
23:12:44 <yushyin> what functions exactly? Bytestrings provides a lot of I/O related functions
23:12:47 <yushyin> http://hackage.haskell.org/package/bytestring-0.10.10.0/docs/Data-ByteString.html#g:26
23:28:08 <hololeap> yushyin: readLine for instance
23:32:07 <wavemode__> well, read has type `String -> a`. It's not for bytestrings
23:33:44 <Axman6> read . BS8.unpack <$> BS.getLine
23:34:24 <wavemode__> well, yeah you can do that. but then, why use bytestring for that :p
23:35:32 <Axman6> well yeah - that's very close to what's happening under the hood anyway
23:42:32 <hololeap> :t (read <$> readLine) :: IO ByteString
23:42:33 <lambdabot> error:
23:42:33 <lambdabot>     Not in scope: type constructor or class ‘ByteString’
23:42:33 <lambdabot>     Perhaps you meant one of these:
23:43:25 <Axman6> ... that would accept input that looks like `"\"foo\""`
23:43:33 <Axman6> which is probably not what you want
23:45:20 <EvanR> `"\"foo\""` my mental quotation system almost overflowed
23:52:23 <Axman6> needs moar stack
