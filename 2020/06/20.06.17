00:00:03 <fog> so i should be able to do things like producing random SNats at runtume and adding them to a list that always has an even sum
00:00:29 <fog> this would translate into the constraint that the added SNat itself is even
00:00:45 <fog> i would expect that this kind of percolation of constraints would be a common thing
00:01:14 <fog> "you can only implement it this way" being the kind of type level feature we want to impart onto the user
00:02:16 <fog> instead of having a pottentially badly implemented smart method to add the numbers, and do the evenness check (which the user could somehow do wrong...) 
00:02:50 <fog> that this check was instead at type level, would mean only the correct smart method should be possible to write
00:04:17 <fog> where the type error would be to the effect of "we have already determined at type level that you should be using even numbers here, your implementation is wrong! its trying to add *odd* numbers to the even-total list"
00:04:35 <fog> where im not sure how it would know at type level that the user had done that...
00:05:05 <fog> well, i guess they just wouldnt be able to provide a proof that they werent
00:10:14 <ph88> how can i fmap over a 2-tuple changing first and second at the same time with the same function ? is it bifunctor ?
00:10:31 <Axman6> :t bimap @(,)
00:10:32 <lambdabot> error:
00:10:32 <lambdabot>     Pattern syntax in expression context: bimap@(,)
00:10:32 <lambdabot>     Did you mean to enable TypeApplications?
00:10:37 <Axman6> %:t bimap @(,)
00:10:44 <ph88> is that lens ?
00:10:46 <Axman6> % :t bimap @(,)
00:10:46 <yahb> Axman6: (a -> b) -> (c -> d) -> (a, c) -> (b, d)
00:12:05 <EvanR> if you are using a tuple with two things same type, maybe you want a V2 instead
00:12:10 <EvanR> which is just a functor
00:12:26 <dibblego> @type both
00:12:28 <lambdabot> (Data.Bitraversable.Bitraversable r, Applicative f) => (a -> f b) -> r a a -> f (r b b)
00:12:48 <Axman6> :t both %~ show
00:12:50 <lambdabot> (Data.Bitraversable.Bitraversable r, Show a) => r a a -> r String String
00:13:11 <ph88> ( [(a, b)] , [(a, b)] ] -> ( ([a], [b]), ([a], [b]) )    this is the function i eventually need ... unzip twice on the inner components
00:13:27 <EvanR> ewww
00:14:16 <ph88> what's a V2 ?
00:14:29 <EvanR> from linear package
00:14:32 <dibblego> data V2 a = V2 a a
00:15:17 <ph88> that looks it might be the simplist solution
00:15:41 <EvanR> question, why are these things tupled in the first place
00:17:49 <fog> i wonder if this could be a way to do "conservation laws" - like conservation of energy, or conservation of total sum, etc.
00:18:05 <ph88> EvanR, not for any particular reason
00:20:15 <fog> i guess the problem with that is floating point operations - normally its only conserved up to machine precision  
00:20:40 <fog> i guess maybe fractionals could be of use
00:21:36 <fog> type safe conservation of energy for physics simulations could be pretty useful 
00:22:25 <fog> or maybe for markets or something, where you dont want money being created as a runtime error
00:22:38 <EvanR> type safe almost anything would be useful, if it were remotely attainable
00:23:03 <fog> yeah, the overhead is daunting - moreso than the unit checks...
00:23:14 <ph88> dibblego, and then derive Functor for it ?
00:23:14 <EvanR> the hard part is coming up with the theory, even if you do, often doesn't play nice with what someone else did
00:23:25 <fog> but i guess if corner cases were numerous enough, it could be worth it
00:23:47 <dibblego> I won't stop you
00:24:24 <fog> EvanR: how do you mean?
00:24:54 <EvanR> modularity
00:31:58 <fog> a problem to do with providing a useful interface for some of these global considerations? 
00:32:23 <fog> more than just the constraints library
00:33:00 <fog> or about porting existing code?
00:34:04 <fog> seems like its more of a style to get used to...
00:34:37 <fog> but some way to reduce the coding overhead would save the code being excessively complex to read
00:34:47 <fog> which often type level stuff tends to lead to
00:35:25 <ph88> what is the go-to package/function to randomize a list ?
00:36:37 <fog> ph88: System.Random + Data.List, or System.Random.Shuffle...
00:36:39 <dminuoso> ph88: Is the list large?
00:37:18 <ph88> 187960 elements
00:37:53 <fog> whats that, a gene sequence or something?
00:38:17 <dminuoso> ph88: Any performance constraints?
00:38:22 <EvanR> fog: the style doesnt' really exist. Check out all the code being written for agda, many times the stdlib is rewritten from scratch
00:38:25 <ph88> dminuoso, no
00:38:43 <ph88> fog, do you have any opinion about Distribution.Simple.Shuffle ? i saw this too
00:38:46 <dminuoso> ph88: Id probably just use `perfect-vector-shuffle` either way.
00:38:55 <dminuoso> Reason being, it's fisher yates which I can reason about.
00:39:05 <dminuoso> Plus, with lists that long, you probably want to go vector anyway.
00:39:10 <ph88> fisher yates ?? what's that
00:39:16 <fog> ph88: oh, that package has a really fast implementation of nub, i guess its shuffle things might be as good also
00:39:32 <dminuoso> ph88: It's the de-facto standard algorithm for shuffling a finite list
00:39:44 <ph88> fog, which package has fast nub ??
00:39:57 <ph88> thanks dminuoso 
00:41:12 <fog> ohh, it was; Data.Discrimination 
00:41:55 <ph88> is it the fasted nub ?
00:42:10 <fog> http://hackage.haskell.org/package/shuffle-0.1.4.0/docs/Distribution-Simple-Shuffle.html
00:42:13 <fog> incomprehensible 
00:42:24 <fog> ph88: one of!
00:42:53 <fog> certainly fast enough to actually use, unline the one from Data.List
00:45:11 <fog> EvanR: idk agda, still, im not sure how this kind of globally conserved quantity would work in practice
00:45:24 <fog> i guess thats just one possible use aswell
00:45:51 <fog> like, this thing about having two datatypes preserved to contain the same data during modifications
00:46:08 <fog> there must be many such concepts
00:46:29 <EvanR> conserved quantities is a non obvious feature of newton physics, requiring proofs
00:46:34 <fog> the only really overarching thing is the use of constraints to typecheck the runtyme generated types
00:46:53 <EvanR> if your code is newton... the compiler won't be able to just check conservation
00:47:07 <fog> no, but it can at least demand the proofs..
00:47:22 <EvanR> yeah.
00:47:39 <fog> this would be possibly quite difficult for the user
00:48:01 <EvanR> yeah
00:48:05 <fog> like, writing at type level, even just that the value added to the even total list is iven
00:48:27 <fog> instead of just doing a simple case expression over isEven
00:48:53 <fog> but, for larger code, there is more and more difficulty in ensuring that these value level checks are total
00:49:29 <fog> and unit testing and exhaustively enumerating corner cases ends up being the main burden for complicated program logics to ensure they work as expected
00:50:01 <fog> a type level mechanism for doing so, even if requiring some complicated syntax on implementation, could be a huge saving for large codebases 
00:51:51 <fog> im reluctant to refactor my current project to test this idea, but if i was already in the habit of writing such checks, it might have been easier to do from the beginning 
00:52:12 <EvanR> better use a language with desired properties already built in by design
00:52:25 <fog> but, now i feel like im being lazy - and that anything less than a type safe version would be inherently dangerous
00:53:06 <fog> EvanR: i wouldnt be keen to switch a language halfway through a project! seems even more work than refactoring
00:53:30 <fog> hmm, maybe thats why people dont use haskell as much as they should
00:54:28 <fog> but anyway, haskell seems to be able to do what i need it to, even if it doesnt have nice type level lambdas, pattern matching, case expressions and lazyness 
00:54:35 <fog> but i hope in time that it will
00:55:25 <fog> i think i managed to write a type leve encoding of lazyness, but i might have just dreampt it
00:55:59 <fog> i was going to try and use it for a version of list written using this;
00:56:00 <fog> https://gist.github.com/fog-hs/19abbf2ee8cf1f9f0c39abf0772da34e
00:56:15 <fog> it was supposed to be an extensible interface for hetrogenous datatypes
00:56:38 <fog> but i cant much see the point if i cant have lazy evaluation of them
00:58:57 <fog> i like how easy it is to write;
00:58:58 <fog> type HTree = HFree' []
00:59:13 <fog> and the corresponding sum version;
00:59:14 <fog> type SumTree = HFree' Sum_T
00:59:26 <fog> i can hardly envisage such a tree
00:59:56 <fog> i wanted to use it to enumerate datatypes
01:00:24 <fog> like, so  i could have all the different shaped trees (with shape at type level) as leafs in the sum tree
01:00:51 <fog> and then you could just choose a way to descend through the sum branches to get to the shaped tree you wanted
01:01:12 <fog> though, something makes me think this would end up being equivalent to specifying the shape of the tree directly...
01:01:41 <fog> still, seems like a cool equivalence, between the shape specification and the navigational path over the tree of shape choices
01:02:52 <fog> idk if maybe there are advantages to working with the tree of all shaped trees, like, being able to do genetic programming operations or something 
01:03:10 <fog> like, it would be a way to handle combinatorics in the space of nets
01:03:21 <fog> which i wanted to use for genetic lambda coding 
01:04:09 <fog> which gives a much more rational way to recombine net subregions, by expressing them as functional programs that can be rationally factorised
01:05:10 <fog> urgh, now im thinking of type level proofs of convergence. time to clean the kitchen...
01:07:29 <hc> lol :)
01:52:00 <xsperry> hi. how am I supposed to handle optional parameters in scotty? catch exception raised by param? I'm looking for param equivalent that returns Maybe, but I can't find it
02:04:42 <ph88> does somebody know a good example where optparse-applicative is used with commands?   like  myProgram command1 --flagA   myProgram command2 --flagZ
02:05:18 * hackage logging-effect 1.3.10 - A mtl-style monad transformer for general purpose & compositional logging  https://hackage.haskell.org/package/logging-effect-1.3.10 (OliverCharles)
02:05:25 <dminuoso> ph88: The haddock has examples.
02:05:53 <ph88> they are a bit minimal, no ?
02:06:19 <dminuoso> Sure, but they should be sufficient.
02:09:42 <xsperry> just wrote paramMay :: Parsable a => L.Text -> ActionM (Maybe a). seems odd that they provide version of param that throws exception, but not one that returns Maybe a
02:14:37 <xsperry> @hoogle (Maybe a, Maybe b) -> Maybe (a, b)
02:14:38 <lambdabot> Data.Functor.Adjunction zipR :: Adjunction f u => (u a, u b) -> u (a, b)
02:15:45 <xsperry> is there something similar in base?
02:16:37 <xsperry> sequence comes close
02:16:41 <phadej> % :t liftA2 (,)
02:16:41 <yahb> phadej: Applicative f => f a -> f b -> f (a, b)
02:16:42 <xsperry> > sequence (Just 10, Just 20)
02:16:43 <lambdabot>  Just (Just 10,20)
02:17:02 <phadej> % liftA2 (,) (Just 'x', Just True)
02:17:02 <yahb> phadej: ; <interactive>:119:1: error:; * No instance for (Semigroup Char) arising from a use of `liftA2'; * In the expression: liftA2 (,) (Just 'x', Just True); In an equation for `it': it = liftA2 (,) (Just 'x', Just True)
02:17:06 <phadej> % liftA2 (,) (Just 'x') (Just True)
02:17:06 <yahb> phadej: Just ('x',True)
02:17:37 <xsperry> nice. not quite sure how that works though
02:17:55 <xsperry> it uses Maybe applicative?
02:18:13 <xsperry> oh, you didn't use tuple
02:18:51 <phadej> if think you need function with a type (a, b) -> ... look for function with type a -> b -> ..
02:18:55 <xsperry> > (uncurry liftA2 (,)) (Just 'x', Just True)
02:18:57 <lambdabot>  error:
02:18:57 <lambdabot>      • Couldn't match expected type ‘(a1 -> Maybe Bool -> c,
02:18:57 <lambdabot>                                       (Maybe Char, a1))’
02:19:11 <xsperry> > (curry $ liftA2) (,) (Just 'x', Just True)
02:19:13 <lambdabot>  error:
02:19:13 <lambdabot>      • Couldn't match type ‘(a0 -> b0 -> (a0, b0),
02:19:13 <lambdabot>                              (Maybe Char, Maybe Bool))’
02:19:50 <phadej> :t uncurry (liftA2 (,))
02:19:52 <lambdabot> Applicative f => (f a, f b) -> f (a, b)
02:20:06 <xsperry> > (uncurry $ liftA2 (,)) (Just 'x', Just True)
02:20:08 <lambdabot>  Just ('x',True)
02:36:43 <dminuoso> ph88: What information are you missing?
02:37:48 * hackage streaming-postgresql-simple 0.2.0.5 - Stream postgresql-query results using the streaming library  https://hackage.haskell.org/package/streaming-postgresql-simple-0.2.0.5 (OliverCharles)
02:45:49 <xsperry> is there something like this already? [probably not, at least not with this behavior, but thought I'd ask anyway]. https://pastebin.com/0mhsn5jX
02:47:55 <phadej> probably no
02:48:17 <dminuoso> Mmm, my weechat log is failing me. How do I reliably get constant time equality on bytestrings?
02:48:28 <phadej> you don't
02:51:27 <phadej> ByteString is wrong type for something you would want constant time equality. You probably want something which carries the length in the type
02:52:21 <dminuoso> phadej: Mmm, I failed to mention a precondition. We can assume all bytestrings to be of the same fixed length of 32 bytes.
02:52:23 <xsperry> are you sure ByteString doesn't?  O(1) length returns the length of a ByteString as an Int.
02:53:03 <xsperry> or are you talking about length of unicode characters in the bytestring
02:53:11 <phadej> dminuoso: then rather use `data Foo = Foo Word64 Word64 Word64 Word64`
02:53:42 <phadej> I'm like 99% sure it will make your life a lot easier
02:53:48 * hackage hercules-ci-api-core 0.1.1.0 - Types and convenience modules use across Hercules CI API packages  https://hackage.haskell.org/package/hercules-ci-api-core-0.1.1.0 (RobertHensing)
02:55:14 <dminuoso> phadej: Im in the 1% because Im using cryptonite, so it's some Data.ByteArray.ByteArray type. ByteString, Bytes or ScrubbedBytes.
02:55:31 <dminuoso> Reimplementing the hash myself will likely make my life harder. :(
02:57:21 <dminuoso> % \x y -> foldl' (.|.) 0 (Data.ByteString.zipWith xor x y) == 0
02:57:21 <yahb> dminuoso: ; <interactive>:121:1: error:; * No instance for (Show (BS.ByteString -> BS.ByteString -> Bool)) arising from a use of `print'; (maybe you haven't applied a function to enough arguments?); * In a stmt of an interactive GHCi command: print it
02:57:37 <dminuoso> % :t \x y -> foldl' (.|.) 0 (Data.ByteString.zipWith xor x y) == 0
02:57:37 <yahb> dminuoso: BS.ByteString -> BS.ByteString -> Bool
02:58:05 <dminuoso> phadej: Or are you suggesting to turn the bytestring into such a Foo first?
02:59:00 <phadej> cryptonite's HMAC eq eg says  The Eq instance is constant time. No Show instance is provided, to avoid printing by mistake.
02:59:13 <phadej> maybe the primitives for writing it are exported, maybe not
03:00:14 <dminuoso> https://github.com/haskell-crypto/cryptonite/blob/master/Crypto/Internal/ByteArray.hs#L30-L39
03:00:15 <phadej> I'd also expected `memory` package to provide constant time equality for Data.ByteArray.Sized - but it looks like it doesn't
03:00:24 <phadej> that module is private
03:00:25 <dminuoso> It's not exported, but I could just copy and paste it
03:00:47 <dminuoso> Indeed.
03:01:03 <dminuoso> Perhaps a case could be made to export it to the public.
03:01:33 <phadej> or just don't use cryptonite, but e.g. libsodium :)
03:03:18 <phadej> though NaCl package seems to use memory which again doesn't have that equality
03:03:49 * hackage hercules-ci-api-agent 0.2.1.0 - API definition for Hercules CI Agent to talk to hercules-ci.com or Hercules CI Enterprise  https://hackage.haskell.org/package/hercules-ci-api-agent-0.2.1.0 (RobertHensing)
03:03:53 <phadej> open source secret handling code in Haskell is just not good
03:04:23 <phadej> preventing side-channel attacks is I dunno, lost battle.
03:06:04 <maerwald> phadej: rust tls just got a formal audit... doubt our haskell libs will
03:06:13 <maerwald> https://github.com/ctz/rustls/blob/master/audit/TLS-01-report.pdf
03:06:19 <dminuoso> You raise a valid argument, writing libsodium bindings would give us the highest quality crypto.
03:06:35 <dminuoso> Sadly in my case, Id also need libcrypt (because we're still rehashing some legacy bits).
03:07:42 <phadej> maerwald: auditing `tls`? That would be waste of time, IMO.
03:08:13 <phadej> you'd essentially need to audit GHC's RTS, which maybe is possible, but ...
03:08:22 <maerwald> yes, because it uses the wrong languagu :ß
03:08:25 <dminuoso> phadej: Not just the RTS, but GHC itself as well.
03:08:31 <phadej> yes, codegen too
03:08:49 <dminuoso> or the simplifier, if we want tls to perform sensibly.
03:09:07 <phadej> yet, if someone would even audit the cbits of cryptonite, that would be already something
03:09:10 <dminuoso> (optimizations/code restructuring are a great way to introduce side channel attacks)
03:10:23 <maerwald> this is why I'm not sure if a crypto expert would ever choose haskell as the implementation language
03:11:20 <maerwald> but I'm not one for sure
03:11:43 <phadej> for glue language for cryptoprimitives in something else? That would be fine, given primitives are quite high level themselves
03:12:00 <phadej> but shuffling bytes in Haskell, dunno.
03:18:46 <dminuoso> Strange that nobody has come around to providing a full and transparent binding library to libsodium..
03:19:03 <dminuoso> The ones I find are subsets or exotic abstractions of subsets of libsodium.
03:19:25 <dminuoso> Oh hold on, https://hackage.haskell.org/package/libsodium-1.0.18.1/docs/Libsodium.html
03:19:31 <dminuoso> That looks useful.
03:22:17 <[exa]> is there no DSL that could compile the crypto primitives down to "reasonable" code?
03:22:38 <[exa]> (like, at least without jumps if there aren't any)
03:23:40 <dminuoso> What do you mean?
03:24:20 <maerwald> [exa]: that's a lifetime project: https://project-everest.github.io/
03:24:53 <dminuoso> I've skimmed the abstracts of some papers researching provably correct cryptographic implementations using coq, where code extraction would only use primitives known to be safe against certain side channels.
03:25:32 <[exa]> dminuoso: for start, something that can produce code with some assurance that the jumps are data-independent
03:25:39 <maerwald> project everest is the closest you'll get
03:26:41 <maerwald> it has high and low level proofs
03:27:11 <[exa]> seems so... I even remember Low* from some other context
03:28:19 <maerwald> and for their purpose, haskell type system is not expressive enough
03:28:34 <kiwi_45> is Stack server down today ? I am getting  `ConnectionTimeout` error while my network connection is okay ! I am getting this error from last 8 hours
03:30:47 <dminuoso> phadej: Thank you for your input, I think we're going with libsodium - it never occured to me.
03:34:42 <kiwi_45> Anyone ?
03:35:27 <[exa]> kiwi_45: seems working from here
03:36:05 <kiwi_45> Thanks [exa], any input what I can do other than waiting ?
03:36:16 <[exa]> kiwi_45: what exact command is failing?
03:37:43 <kiwi_45> I added `uuid` package and did a stack build which results in this ```ConnectionTimeout
03:37:44 <kiwi_45> Progress 1/3``` 
03:38:45 <kiwi_45> [exa] : ^^
03:38:47 <[exa]> can you check where exactly is it trying to connect (ie. try to replicate the failure with curl) ?
03:39:32 <kiwi_45> `path                 = "/hackage.fpcomplete.com/package/entropy-0.4.1.5.tar.gz"
03:39:33 <kiwi_45> ` I don't know much how to do it with curl 
03:40:19 * hackage hexpat-lens 0.1.9 - Lenses for Hexpat.  https://hackage.haskell.org/package/hexpat-lens-0.1.9 (OliverCharles)
03:40:51 <[exa]> like, does it work if you paste the url to the browser? :]
03:41:42 <[exa]> if not- your internets have some serious problem or fpcomplete is filtering you, for whatever reason
03:42:16 <kiwi_45> Uploaded file: https://uploads.kiwiirc.com/files/4b7be564a52223061d37fd142a9a3980/pasted.txt
03:42:21 <kiwi_45> [exa] : which url ?
03:43:13 * [exa] -> PM
04:01:43 <mastarija> Do you know if it's possible to run cabal executable in interpreted mode?
04:02:09 <ph88> is there a function for repeat and concat ?  when i have a list like [1,2] i like to get an infinite series of [1,2,1,2,1,2 ..etc]
04:02:11 <dminuoso> mastarija: You mean running cabal-install from GHCi?
04:02:17 <dminuoso> % :t cycle -- ph88 
04:02:18 <yahb> dminuoso: [a] -> [a]
04:02:26 <ph88> thank you dminuoso 
04:02:53 <mastarija> dminuoso: no, I mean running an executable defined in cabal file but instead of compiling everything running it in interpreted mode
04:03:00 <mastarija> Without entering the repl
04:03:12 <ph88> what is a good package of randomly generating some alphanumeric characters ?
04:03:13 <dminuoso> mastarija: What is "interpreted mode" without ghci?
04:03:19 <mastarija> something like cabal run --interpreted
04:03:19 <dminuoso> mastarija: Im not sure what you are asking for.
04:03:24 <dminuoso> And what does that do?
04:03:24 <mastarija> like runhaskell
04:03:39 <dminuoso> Ah
04:03:57 <dminuoso> mastarija: I dont think that's possible generally.
04:04:14 <mastarija> damn
04:04:25 <mastarija> I kind of have long wait times when using Gloss
04:04:37 <mastarija> I can't run it from repl
04:04:50 <mastarija> and recompiling every time is slow on my pc for some reason
04:04:57 <mastarija> Even with a very small project
04:05:01 <dminuoso> mastarija: Why is it recompiling it frequently?
04:05:17 <dminuoso> I mean the dependency should be built only once, perhaps twice if you use different flags.
04:05:17 <mastarija> dminuoso, I want to check how my game is working
04:05:25 <dminuoso> Sure, but that doesnt require gloss itself to be recompiled.
04:05:32 <mastarija> Not gloss, my game
04:05:48 <dminuoso> Welcome to GHC. It's slow.
04:05:53 <dminuoso> we could try and improve the situation though
04:05:58 <mastarija> Yes, but I've never seen it so slow
04:06:23 <mastarija> I have like 100 lines in my file and it's killing me :D
04:06:25 <dminuoso> Is disabling optimizations an option?
04:06:28 <mastarija> Yes
04:06:51 <mastarija> How can I do that? Some flag in cabal file?
04:06:55 <Hopplahase> ph88: If you don't need cryptographic strength, you can use random-strings
04:07:28 <dminuoso> mastarija: Do you have a cabal.project file?
04:07:33 <mastarija> Yes
04:07:35 <ph88> thanks Hopplahase 
04:07:42 <dminuoso> mastarija: What's the content of that and your cabal file?
04:07:53 <mastarija> Just a sec
04:08:46 <mastarija> dminuoso: https://pastebin.com/atvF1W23
04:08:55 <mastarija> That's all for now
04:09:13 <dminuoso> mastarija: Alright, and your cabal.project file? Also, how slow is slow for you?
04:09:19 <dminuoso> That is, what kind of times are you suffering?
04:09:28 <mastarija> 30s sometimes
04:09:40 <mastarija> it's ridiculous for such a small file
04:10:30 <dminuoso> mastarija: Can you add `-ddump-timings -dshow-passes` to the ghc options?
04:10:38 <mastarija> Sure
04:10:39 <dminuoso> And recompile, and share the output
04:11:08 <mastarija> dminuoso: I can just put that in the GHC options in my cabal, right?
04:11:15 <dminuoso> mastarija: Yes.
04:16:29 <mastarija> dminuoso, there : https://pastebin.com/yf42BtAP
04:16:47 <mastarija> As I thought, it hangs on the linker every time
04:17:56 <mastarija> Although that's not visible from the output I've just observed it hanging on the "linker:" line :D
04:18:29 <dminuoso> Right, I guess you're in a tough spot then.
04:18:57 <dminuoso> Judging from some tickets Im reading, perhaps static linking could improve the performance.
04:19:04 <ph88> what function can i use to do an IO action while not sufficient amount of "success" from the IO action ?
04:19:41 <ph88> also i need to pass a value from the previous attempt into the next attempt
04:20:00 <dminuoso> ph88: What do oyu mean by "sufficient amount of success"?
04:20:22 <dminuoso> Are you talking about some retry that will try an action up to n times until it succeeds?
04:20:31 <ph88> let's say i want 300 times this action, but it can fail .. when it fails it doesn't count towards the 300
04:20:34 <boxscape> are haskell types defined or declared? Or are they defined with a declaration?
04:21:05 <ph88> i want to generate random files names but i need to check if the file does not already exist
04:21:40 <dminuoso> boxscape: The report calls then annotations and they are considered as part of the declaration.
04:22:26 <boxscape> dminuoso uh when you say annotation do you mean a type annotation like `value :: type`?
04:22:28 <ph88> can i like fold an IO action onto itself with an accumulator or so ??
04:23:15 <dminuoso> ph88: You can do a simple `execNTimes 0 _action = pure (); execNTimes n action = action >> execNTimes 0 action `catch` onErr where onErr = ...`
04:23:59 <ph88> o_O
04:23:59 <dminuoso> boxscape: Well, for type aliases it's a declaration according to the wording of the report.
04:24:14 <dminuoso> ph88: OOps, that recursive call should be `execNTimes (n-1) action`
04:24:24 <ph88> what is the stop condition here ??
04:24:57 <boxscape> found a section of the report that says "most “built-in” datatypes are defined with normal Haskell code, using normal type and data declarations"
04:25:41 <dminuoso> And other things like tyfas are not part of the report, so...
04:26:03 <boxscape> yeah
04:26:13 <dminuoso> Though, the word declaration is a bit confusing.
04:27:17 <dminuoso> Wiktionary's first definition of the word is `A written or oral indication of a fact, opinion, or belief.`
04:27:34 <dminuoso> So I suppose `newtype Foo = Foo Int` could be considered declaring a type Foo, along with a data constructor.
04:28:29 <boxscape> ph88 the stop condition iss the 0 in the first equation of execNTimes
04:29:06 <boxscape> i.e. if the argument matches 0 it stops
04:32:38 <dminuoso> ph88: https://gist.github.com/dminuoso/84edcd45163d93ec4310f53d29dc986d
04:33:03 <dminuoso> (Or maybe you dont need it parametrized over the action, but I hope you get the idea)
04:33:27 <ph88> thanks :)
04:51:08 <kuribas> MonadBaseControl looks evil, a means of creating complexity with zero gains.
04:51:40 <kuribas> And replacing a solution which was simpler.
04:52:41 <dminuoso> kuribas: The gains are being able to use existing primitives that have IO (or other things that you have in your monad stack as a base monad) in negative position.
04:53:28 <dminuoso> If you have some `newtype M a = M { runM :: StateT Foo IO a }`, and you want to use some `withConn :: (Conn -> IO a) -> IO a` from another librar with that, you're hosed.
04:53:48 <kuribas> dminuoso: there is the simpler solution of simply passing everything to the IO
04:53:59 <kuribas> while slightly boilerplatey, it's easy.
04:54:11 <dminuoso> kuribas: You cant.
04:54:22 <dminuoso> kuribas: If you want to have access to monadic state.
04:54:32 <kuribas> dminuoso: you mean Foo?
04:54:38 <dminuoso> kuribas: Sure.
04:55:15 <dminuoso> Say you want to do: withConn $ \conn -> do d <- fetchData; modify (d:); ... 
04:55:31 <kuribas> do foo <- get; (newfoo, res) <- withConn $ \conn -> let foo2 = ... something foo...in (foo2, result); put foo2
04:56:15 <dminuoso> kuribas: The problem with that approach is exceptions and persistence of stat ethen.
04:56:35 <kuribas> dminuoso: yes, exactly the same problem you have with monadBaseControl
04:57:40 <kuribas> and it's solved by storing state in IO (IORef), not by using monadBaseControl.
04:58:10 <kuribas> it looks to me like monadBaseControl saves a few bytes, at the cost of an nearly incomprehensible API.
04:58:22 <kuribas> And obfuscating
04:58:51 <dminuoso> Which is exactly the motivation behind unliftio :)
04:59:34 <dminuoso> (Which is not perfect either, since it lead to subtle bugs when used with ResourceT, but it's better than the rest)
04:59:52 <kuribas> yeah, but then I could just do myParams <- ask; withConn $ \conn -> somethingWith myParams ..
05:00:25 <dminuoso> kuribas: Sure, but that sort of defeats the point of having a ReaderT at all.
05:01:15 <dminuoso> And you're also misisng a liftIO there
05:01:18 * hackage hercules-ci-agent 0.7.1 - Runs Continuous Integration tasks on your machines  https://hackage.haskell.org/package/hercules-ci-agent-0.7.1 (RobertHensing)
05:01:30 <solonarv> kuribas: sure, and that's pretty much exactly what MonadUnliftIO instances do.
05:01:36 <kuribas> dminuoso: well, I wouldn't use ask, but I would have helper functions that take what I want, for example: getDB = stateDB . ask
05:01:41 <dminuoso> And then you could say: well just do `do myParams <- ask; liftIO (withConn $ \conn -> runReaderT something myParams;)` - then that's just the same as `withRunInIO $ \io -> withConn (io . something)`
05:01:50 <kuribas> well "stateDB <$> ask"
05:02:11 <dminuoso> kuribas: Sure thats perfectly fine.
05:02:24 <dminuoso> MonadUnliftIO is just convenience if you dont want to unwrap your ReaderT everywhere.
05:02:39 <dminuoso> While being easy to reason about
05:02:42 <kuribas> I would keep the monad for the servant event handlers.
05:02:57 <kuribas> But use explicit functions for most of the lower level functions.
05:03:47 <dminuoso> My go-to pattern is `newtype AppM a = AppM { runAppM :: LoggingT (ReaderT Env) IO a }`, with some GeneralizedNewtypeDeriving for MonadReader Env, MonadIO, MonadUnliftIO - and then I can just log everywhere without thinking.
05:03:59 <dminuoso> At least the larger projects Im working on
05:04:08 <dminuoso> (Oh and MondaLogger of course)
05:04:25 <kuribas> dminuoso: and LoggingT works with MonadUnliftIO?
05:04:39 <dminuoso> kuribas: Yes, it's isomorphic to ReaderT
05:04:55 <dminuoso> ReaderT LoggingFun
05:06:01 <dminuoso> I'm a big fan of monad-logger because it nicely seperates the logging interface from the implementation, it's completely agnostic of the implementation.
05:06:15 <dminuoso> And you can trivially have multiple loggers around
05:06:49 <merijn> dminuoso: I wish it was just slightly more minimal/clean in terms of dependencies
05:06:56 <emmanuel`> So I had a coworker (he's actually a product manager) raise this criticism of Haskell. He was upset that the disk and RAM usage of a Haskell compilation in a docker VM was too high (he had to give it 8Gb of ram usage for it to be functional). Is this a fair criticism?
05:07:21 <dminuoso> merijn: Yea :(
05:07:44 <dminuoso> emmanuel`: GHC is extremely wasteful indeed.
05:07:53 <merijn> emmanuel`: GHC is memory hungry, so I wouldn't run it with less than 1-2GB, but saying it needs 8 is exaggerated
05:08:16 <merijn> emmanuel`: That said, you only have to compile once to run stuff, so it's not that big a deal anyway
05:08:16 <dminuoso> Ive heard stories of people needing 32GiB of memory to compile their haskell projects..
05:08:19 * hackage exhaustive 1.1.9 - Compile time checks that a computation considers producing data through all possible constructors  https://hackage.haskell.org/package/exhaustive-1.1.9 (OliverCharles)
05:08:34 <phadej> if you don't set +RTS -M3G -RTS ghc will hog as much memory as it gets
05:08:46 <phadej> and docker doesn't report properly the max memory (iirc)
05:09:04 <merijn> emmanuel`: It's an issue if you're recompiling code every time on each machine then it's wasteful yeah, but the solution is "to not do that then"
05:09:05 <phadej> so it could easily use the memory of whole machine
05:09:11 <emmanuel`> This coworker is using GHC's memory usage during compilation as a justification for not using Haskell in production
05:09:38 <merijn> emmanuel`: Don't let him see how much memory/disk clang++ needs on my codebase >.>
05:09:38 <phadej> change your coworker(s) ?:)
05:10:02 <merijn> Everyone always complains "Why is GHC like 2 GB of disk space? That's so big!!"
05:10:03 <phadej> I mean, that's quite silly argument, if you debunk this one, I'm 99% sure they'll find another
05:10:13 <merijn> Meanwhile, my clang++/llvm install is 24 GB...
05:10:29 <emmanuel`> This same guy seriously thought that since Haskell binaries are large GHC doesn't perform dead code elimination.
05:10:31 <dminuoso> I'd try not to fight their argument, but rather present them with what Haskell buys you.
05:10:45 <dminuoso> Because arguing against someone elses proposition is usually a lost cause in such a situation.
05:11:14 <merijn> emmanuel`: Try compiling with "-fsplit-sections" and stripping the final executable
05:11:24 <phadej> If they decided that Haskell sucks, I'm not sure you can quickly change make them change their mind
05:11:26 <merijn> emmanuel`: In my code that reduces the size by about 12x
05:11:49 <emmanuel`> Yeah, I don't really mind that he hates Haskell (it is just his opinion). However, he wants to throw out an entire codebase simply because of his bias and it could cost us.
05:12:12 <boxscape> merijn I think it's -split-sections
05:12:33 <merijn> boxscape: I wouldn't know, I use cabal, like a normal person ;)
05:12:40 <boxscape> that makes sense
05:13:11 <emmanuel`> Ok, I'll try that.
05:13:44 <phadej> emmanuel`: what alterenataive that coworker has?
05:13:46 <phadej> Rust?
05:13:56 <emmanuel`> He wants to use Typescript.
05:14:04 <phadej> have fun :)
05:14:07 <solonarv> oh no
05:14:24 <merijn> phadej: But learning something new after JS is too hard :(
05:14:47 <emmanuel`> I don't really know much about Typescript (this job is actually my second software dev job). What is so bad about it?
05:15:02 <phadej> incomparable to Haskell
05:15:04 <merijn> emmanuel`: It's basically just JS with a bunch of complications on top :p
05:15:22 <phadej> merijn: I'm doing ok, I'd say, after PHP and JS.
05:15:56 <emmanuel`> So, basically it inherits all of the problems typically found in JS?
05:16:28 <boxscape> I much prefer using typescript over javascript. Only problem is my company's projects don't have the two or three flags enabled that actually force you to use its type safety features
05:16:35 <hpc> typescript is only a good language if you look at it from the perspective of that you're going to already be writing javascript
05:16:43 <boxscape> true
05:17:03 <hpc> if you look at it compared to non-browser languages, you're signing up for javascript on purpose, which sours anything typescript could ever accomplish
05:17:07 <phadej> I wouldn't say all of the problems, but Number is a problem which is definitely inherited
05:18:08 <hpc> emmanuel`: speaking from experience as well, i bet if you ported your code from haskell to typescript it would end up even larger
05:18:26 <emmanuel`> hpc: in terms of lines of code or binary size?
05:18:28 <phadej> but not the resulting "binaries"! :)
05:18:28 <ph88> when i have an infinite list, how do i take x elements and also the remainder of the list ?
05:18:38 <hpc> in terms of disk space
05:18:42 <phadej> ph88: `splitAt`
05:18:47 <ph88> thanks
05:18:49 <phadej> ph88: hoogle is your friend
05:18:55 <phadej> @hoogle Int -> [a] -> ([a],[a])
05:18:56 <lambdabot> Prelude splitAt :: Int -> [a] -> ([a], [a])
05:18:56 <lambdabot> Data.List splitAt :: Int -> [a] -> ([a], [a])
05:18:56 <lambdabot> GHC.List splitAt :: Int -> [a] -> ([a], [a])
05:18:57 <hpc> you don't really get a binary, you get all your dependencies concatenated together, more or less
05:19:15 <phadej> (there is also web version)
05:19:50 <hpc> there's ways to make it smaller, but usually you're pulling in multiple enormous frameworks in their entirety, just for stuff like event handling
05:20:36 <phadej> anyway, TypeScript is really silly choice
05:21:13 <phadej> Rust or Kotlin would be tougher to compare pros and cons
05:21:40 <phadej> but changing Haskell codebase to something else is ridiculuous idea
05:21:48 <phadej> (or Go)
05:22:08 <phadej> at least if the reason is "takes 8GB to compile"
05:22:13 <hpc> rust in particular is very similar to haskell
05:22:23 <phadej> I'd say it's not similar at all
05:22:36 <phadej> C++ is more similar to C
05:22:46 <ph88> how can i randomly pick an item from two lists with a certain probability ?
05:22:56 <phadej> and yet, those have barely anything else similar than a letter in a name
05:23:10 <maerwald> rust is low level, haskell is not
05:23:12 <emmanuel`> yeah...
05:23:18 <phadej> ph88: I think you exhausted your question quota here :)
05:23:25 <ph88> :P
05:23:25 <hpc> rust's code blocks are almost exactly do-notation
05:23:45 <emmanuel`> I've decided to write a document to my manager about the direction the project is heading in.
05:23:52 <hpc> they're expressions, and the last expression in the block is its return value
05:23:59 <phadej> hpc: syntax is irrelevant
05:24:22 <hpc> it's immutable by default
05:24:23 <maerwald> the only thing rust and haskell share are kinda ADTs
05:24:34 <emmanuel`> In it, I don't necessarily make a pro-Haskell argument. I just point out the amount of time it took to develop the Haskell codebase and then I make conservative estimates as to how long it might take to perform the rewriret.
05:25:05 <phadej> emmanuel`: then they will say, "this estimate seems acceptable"
05:25:25 <boxscape> ph88 you can use randomR or randomRIO to get random floats between 0 and 1, and then check whether the number is higher than that probabliity, and pick the item according to that
05:25:26 <emmanuel`> why do you think they'll do that?
05:25:45 <ph88> boxscape, that's a good idea !
05:25:47 <phadej> you have to mention that it will be worse quality and further development costs (or time) will increase
05:26:23 <phadej> boxscape: the randomR could also pick an integer in (0, n)
05:26:44 <emmanuel`> How would I go about showing that Typescript code will be worse?
05:26:47 <boxscape> ph88 actually random (without R) also uses [0,1) range by default
05:26:50 <hpc> emmanuel`: point out that you're not bottlenecking on disk space, so any work on changing, even if disk space improves, won't even solve a real problem
06:23:30 <dolio> phadej: I don't think any decent manager would say that unless the project is trivial.
06:25:14 <dminuoso> emmanuel`: One way would be to have them estimate the real cost impact of increased disk space (by the amount that Haskell would introduce ontop of say Go). For us, it's easily calculatable. We have a netapp providing some 100TiB of storage (I think), we can calculate the costs of every byte directly.
06:26:53 <dminuoso> And then, you can put up more cost numbers that display what you cost your company hourly, and then perhaps make a comparison how many hours are saved by using technology X (say because less development time, less bug fixing time)
06:26:56 <dolio> You don't just decide to rewrite a bunch of code because one guy is confabulating reasons to not use a language he dislikes.
06:27:13 <dminuoso> Managers tend to like numbers.
06:27:17 <merijn> dolio: Are you new to business? ;)
06:27:24 <merijn> People do that all the time :p
06:27:28 <dolio> No.
06:28:39 <phadej> dolio: that person is, quoting "So I had a coworker (he's actually a product manager) "
06:28:46 <phadej> dolio: so...
06:29:09 <dolio> Oh, I missed that. If the guy coming up with the excuses is the manager that's a different story.
06:29:19 <dolio> And he's a bad manager. :)
06:29:33 <phadej> that is how I understood it and interpreted that, yes.
06:31:06 <dolio> Because he's trying to waste a bunch of time. Like, in the opposite scenario, it wouldn't make sense to rewrite a ton of JavaScript just because you like Haskell.
06:31:19 <dolio> Even if there would be tangible benefits to having it written in Haskell.
06:31:46 <dminuoso> I rewrote our entire SDN automation in haskell because I liked haskell.
06:32:08 <dminuoso> I then told my boss how I spend the previous 4 weeks, he wanted to see the result, and was happy.
06:33:16 <dolio> 4 weeks is almost nothing.
06:33:59 <dolio> Especially 4 weeks * 1 person.
06:34:04 <dminuoso> Ask your boss whether he'd like you to not work on the things he thinks you're working in.
06:34:13 <dminuoso> For a month.
06:34:38 <dminuoso> I mean ultimately, there's 6 months work in this project now, but the prototype I build was enough to kickstart this project.
06:35:18 * hackage prometheus-proc 0.1.3.0 - Export metrics from /proc for the current process  https://hackage.haskell.org/package/prometheus-proc-0.1.3.0 (OliverCharles)
06:40:19 <dolio> No, people don't want to waste even a month of work. But if you can completely rewrite the project in a month, then it's easy to say, "let's switch to Haskell because I like it and it'd give some other minor benefits."
06:40:40 <dminuoso> well I didnt rewrite it completely, I just rewrote enough to get a working PoC out of it.
06:41:02 <dminuoso> To get the green light to start a rewrite project, that's gonna take until the end of the year
06:41:13 <dminuoso> Which was the plan all along. :)
06:41:58 <dolio> If it would take 6 months to get to the prototype stage, for instance, then it's extremely risky to start a rewrite based on, "I have to use 8GB RAM when I compile inside a docker container."
06:42:55 <merijn> Sure, but you're assuming rational actors :)
06:43:55 <dolio> Yes, a good project manager would be reasonably rational.
06:55:55 <ezzieyguywuf> is it possible to have a function `myFunc :: IORef MyData -> Bool` that actually _uses_ the IORef to return some Bool?
06:56:07 <ezzieyguywuf> or could it at best return an `IO Bool`?
06:56:26 <dolio> You could test it for equality against another IORef.
06:56:31 <dolio> I think.
06:56:35 <ezzieyguywuf> hrm
06:56:54 <ezzieyguywuf> but probably best to `myFunc :: MyData -> Bool` and have the caller unwrap the IORef as necessary
07:02:47 <maerwald> dminuoso: why did you rewrite?
07:04:57 <Cale> ezzieyguywuf: To read or write the IORef requires the execution of an IO action
07:29:04 <joehh1> hello, I have a haskell program (simulating processing sensor data coming in over the network) which slows down as it goes - memory usage appears stable, what is the best way to debug it?
07:30:13 <Cheery> joehh1: you know that it's something taking longer time as things progress. Have you noted what shape the slow down follows? is it linear?
07:31:25 <joehh1> I haven't measured it precisly yet, but my guess is probably linear
07:33:00 <joehh1> does that give any clues?
07:34:10 <Cheery> it could give. Do you know what kind of state it keeps while progressing?
07:34:56 <joehh1> I've been breaking my runs so they take a total of about 30 minutes. First part goes quickly (simulating a day or so every 5 seconds) at the end of the 30 minutes, each day seems to take 28 or so seconds
07:35:07 <joehh1> it keeps it state in a number of TVars
07:35:24 <joehh1> typically Map.Map UTCTime Double
07:35:33 <joehh1> though the double could be a more complex object
07:35:55 <joehh1> occaisionally a thread is executed to clear old data from the Map 
07:36:30 <Cheery> Would it be difficult to take state snapshots? Maybe it doesn't clean up?
07:36:42 <joehh1> If that state is not being forced - could that cause this sort of behaviour
07:36:56 <Cheery> Also, a state snapshot might help you compare, eg. take one day from begin and end.
07:37:16 <joehh1> relatively easy to take state snapshots (realtime version does this already)
07:37:42 <joehh1> could the act of taking a state snapshot and writing it to disk force everything and prevent any leaks
07:37:58 <joehh1> ?
07:38:07 <Cheery> maybe, but it's fun to see if it does.
07:38:35 <joehh1> true - looks like that is the next step
07:39:01 <joehh1> thanks for the help :)
07:46:51 <fog> how do doubles work compared with fractionals?
07:47:12 <fog> i can recall something about sign bits and exponent bits
07:47:41 <fog> the problem with fractionals using nats seems to be something to do with precision away from zero
07:47:42 <Cheery> double refers to a standardized floating point format.
07:48:03 <fog> its more fine grained close to 1 right?
07:48:49 <fog> like, with fractionals if i have a large number divided by another large (nat) number - then i get high precision close to 0 
07:49:25 <fog> but if i want similarly high precision for large numbers, then i end up needing arbitrarily large numerator and denomiantors
07:49:57 <fog> it seems to motivate something like, having an addition in there somewhere aswell
07:50:04 <ClaudiusMaximus> :t decodeFloat
07:50:05 <lambdabot> RealFloat a => a -> (Integer, Int)
07:50:07 <Cheery> fractional is (x,y), interpreted as x/y, if it's fractional that I know.
07:50:35 <fog> then i could have a nat plus a fractional - and this would give the same prescission for a smaller max nat at any position
07:51:14 <Cheery> double consists of sign, exponent and mantissa. it's kind of like a binary number system where the dot can slide and you got finite amount of digits.
07:51:16 <ClaudiusMaximus> something like decodeFloat a = (m, e) where a = m * floatRadix a ^ e
07:51:31 <fog> % decodeFloat <$> randomRIO @Double 
07:51:32 <yahb> fog: ; <interactive>:124:1: error:; * No instance for (RealFloat (IO Double)) arising from a use of `decodeFloat'; * In the first argument of `(<$>)', namely `decodeFloat'; In the expression: decodeFloat <$> randomRIO @Double; In an equation for `it': it = decodeFloat <$> randomRIO @Double
07:51:49 <fog> % decodeFloat @Double <$> randomRIO 
07:51:49 <yahb> fog: ; <interactive>:125:25: error:; * Couldn't match type `IO a' with `Double'; Expected type: (a, a) -> Double; Actual type: (a, a) -> IO a; * In the second argument of `(<$>)', namely `randomRIO'; In the expression: decodeFloat @Double <$> randomRIO; In an equation for `it': it = decodeFloat @Double <$> randomRIO; * Relevant bindings include it :: (a, a) -> (Integer, In
07:51:51 <fog> rrg
07:52:10 <ClaudiusMaximus> > decodeFloat (0.3 :: Double)
07:52:12 <lambdabot>  (5404319552844595,-54)
07:52:35 <Cheery> then it got something called subnormals, the format assumes there's 1. in the number, the subnormal has the 1. removed to get some lower numbers.
07:52:42 <fog> % decodeFloat @Double <$> randomIO 
07:52:42 <yahb> fog: (6255749751483368,-53)
07:54:02 <kuribas> does overloadedrecordfields work with recordwildcards?
07:54:04 <ClaudiusMaximus> :t uncurry encodeFloat . decodeFloat -- wish there was something like this that preserved infs/nans
07:54:05 <lambdabot> (RealFloat c, RealFloat a) => a -> c
07:54:33 <fog> the problem is to do with trying to ensure that there is no loss in precission
07:54:51 <fog> frac seems easier to do at type level for singletons versions
07:55:04 <ClaudiusMaximus> > floatDigits (0 :: Double)
07:55:06 <lambdabot>  53
07:55:16 <ClaudiusMaximus> it's only got that much precision
07:55:33 <fog> 53 precisions 
07:55:47 <ClaudiusMaximus> > floatRadix (0 :: Double) -- bits
07:55:49 <lambdabot>  2
07:56:16 <Cheery> https://en.wikipedia.org/wiki/Double-precision_floating-point_format
07:56:41 <fog> the only point was about where it has the precision concentrated around
07:56:42 <Cheery> 52 bits are explicitly stored. eg. 1. and 52 bits after that.
07:57:29 <fog> doesnt seem like it fits into the 64 bit hardware word memory blocks
07:57:39 <fog> is that wasteful at all?
07:58:17 <Cheery> it has 11 bit exponent, that's the dot sliding in the number
07:58:33 <fog> like, im worried that if i try and make my own kind of floating point number representation that its not going to be "machine effecient"
07:58:50 <Cheery> and then there's the sign bit.
07:58:56 <fog> idk if the processor has machine instructions to do sin or exponentials or stuff
07:58:57 <Cheery> that makes up 64 bits
07:59:06 <fog> ah ok
07:59:30 <Cheery> it may have.. I think several systems do have trigonometric functions and exponentials.
08:00:48 * hackage validity-containers 0.5.0.4 - Validity instances for containers  https://hackage.haskell.org/package/validity-containers-0.5.0.4 (Norfair)
08:01:25 <fog> hmm, maybe for the singletons version i could have the "closest frac" so its conservation can be exact, and at value level have an actual double, for fast machine opperations
08:03:53 <fog> like, say i had a distribution, and it was supposed to be normalised
08:04:11 <fog> and i wanted to only allow the user to do opperations over it that preserved normalisation
08:04:18 * hackage exigo-schema 0.1.0.0 - database schema for exigo marking/assessment tools  https://hackage.haskell.org/package/exigo-schema-0.1.0.0 (phlummox)
08:04:45 <fog> then they would have to provide a proof of that, but it would be impossible if there were machine errors at type level
08:05:14 <fog> idk if im thinking about this the wrong way - maybe it would be easier to simply have an "approximately equal" to some tolerance 
08:05:25 <fog> but again, that seems difficult to implement at type level
08:05:50 <fog> well maybe not, its just a subtraction and seing if its close enough to 0
08:06:28 <fog> i guess im only apprehensive because i have only ever worked with nats and not nums at type level
08:06:34 <fog> or RealFracs
08:07:13 <fog> % 3*0.1
08:07:14 <yahb> fog: 0.30000000000000004
08:07:37 <fog> % 3*0.1*10 == 3
08:07:37 <yahb> fog: False
08:08:14 <fog> % (3*0.1*10 - 3) < 0.0000001
08:08:14 <yahb> fog: True
08:08:41 <fog> not sure how difficult that would be to do at type level
08:08:48 * hackage gcodehs 0.1.2.0 - GCode processor  https://hackage.haskell.org/package/gcodehs-0.1.2.0 (srk)
08:10:27 <fog> % (3::Fractional a => a)*(0.1::Fractional a => a)*(10::Fractional a => a)
08:10:27 <yahb> fog: 3.0000000000000004
08:10:36 <fog> hmm, that doesnt work as i would have expected
08:10:59 <fog> i thought the fractional thing would have been able to invert the multiplication exactly
08:11:18 * hackage zre 0.1.1.0 - ZRE protocol implementation  https://hackage.haskell.org/package/zre-0.1.1.0 (srk)
08:11:32 <fog> oh, it must have been the use of 0.1, it must have defaulted to double
08:11:34 <fog> % (3::Fractional a => a)/(10::Fractional a => a)*(10::Fractional a => a)
08:11:34 <yahb> fog: 3.0
08:12:05 <fog> that seems like it might work better at type level than the approximately equal thing
08:12:32 <Cheery> fractional is a typeclass there
08:12:33 <Ariakenom> % 3 * 0.1 * 10 :: Rational
08:12:33 <yahb> Ariakenom: 3 % 1
08:12:51 <fog> oh, i didnt know any instances of Fractional!
08:13:11 <fog> still, it managed to work ok with the typeclass if division was used
08:13:30 <Ariakenom> (Fractional a => a) defaults to double
08:14:09 <fog> % (3/10)*10 == 3
08:14:09 <yahb> fog: True
08:14:12 <fog> hmm
08:14:36 <fog> idk whats going on there...
08:15:31 <fog> seems to introduce error when doing *0.1 instead of /10
08:15:47 <fog> but anyway, Rational didnt seem to suffer from that problem
08:15:51 <Ariakenom> % (3*0.1, 3/10)
08:15:51 <yahb> Ariakenom: (0.30000000000000004,0.3)
08:16:00 <Ariakenom> Rational is exact
08:16:09 <fog> and it seems easyer to implement at type level than Double
08:16:46 <fog> still, i dont know how i would write a proof that an opperation over a normalised distribution preserved normalisation
08:17:10 <fog> even if the problems to do with machine precision are avoided by using rational
08:17:28 <fog> and, yeah, there was still the issue of "prescision away from 0" with Rational
08:17:47 <fog> where it would need larger and larger numbers to give the same prescision further from 0
08:18:11 <fog> so there was the idea to have something like a rational that had a + as well as a divide, so using 3 Ints
08:18:21 <fog> or, 3 nats and a sign bit
08:18:49 <fog> are computations with rationals much slower than with Doubles?
08:19:29 <fog> i guess i could avoid trig functions in my computations - like, using RELU activation functions instead of hyperbolic tangents
08:19:55 <Cheery> doubles are very fast because they're approximate
08:19:56 <fog> might be easier to backpropegate through as well - which seems like something you wouldnt want to have to do at type level
08:20:09 <Cheery> and usually evaluated on hardware
08:20:42 <fog> this is a problem with no easy solutions
08:20:46 <wavemode> depends on what you mean by "much" slower. rationals aren't slow, they're just understandably not as fast as hardware-accelerated floating point operations
08:21:32 <fog> with training of nets, there is so many floating point operations that those machine operations become essential 
08:22:12 <fog> even slightly slower isnt really an option that can be considered
08:22:43 <fog> unless it has some monumental saving some other way - like by "quantizing" the neuronal activations
08:23:16 <fog> if i had something like rationals with really short words, it might end up being good for pretraining
08:24:09 <ClaudiusMaximus> :t approxRational
08:24:10 <lambdabot> RealFrac a => a -> a -> Rational
08:24:23 <fog> basically by forcing it to converge by some way other than by refining one specific neronal value, kind of sharing the error between the neurons
08:24:57 <fog> ClaudiusMaximus: whats that?
08:25:14 <ClaudiusMaximus> > approxRational pi 0.001
08:25:16 <lambdabot>  201 % 64
08:25:21 <fog> awesom!!
08:25:59 <fog> so somehow reflecting that up to type level with singletons, then it could acompany a real Double version
08:26:24 <fog> and the users "proof" that it preserved normalisation would be exact
08:27:19 <fog> up to the specified accuracy, like 0.001 above 
08:28:26 <fog> ok, well, thanks for the help, but i think i better abandon this before i actually end up trying to implement it, other things to do first
08:28:35 <fog> ciao
08:42:48 <zincy_> For configuring a web server which parts should come in through environment variables and which through a file lets say a Dhal conf file?
08:43:32 <zincy_> What is the general rule for deciding where a configuration parameter belongs?
08:43:40 <wavemode> If it were me I would avoid the use of environment variables altogether.
08:43:50 <wavemode> Why not keep all your configuration in one place?
08:44:47 <zincy_> Ah ok good question.
08:45:08 <zincy_> I thought perhaps secrets since I don't know how you would *secretly* store them in a conf file
08:47:07 <wavemode> who are you keeping them secret from? I would think only a trusted person should have access to the configuration file in the first place
08:51:31 <infinisil> zincy_: For secrets I'd recommend having a configuration option for a *file* where the secret is stored. This way the configuration is public but still specifies the secret. Also it allows you to configure secret access with filesystem permissions
08:51:55 <infinisil> So `passwordFile = /path/to/file` instead of `password = "passw0rd"`
08:53:27 <tdammers> haha, IMO *everything* should be environment variables
08:53:34 <tdammers> no configuration files at all
08:53:46 <syd> Hi peeps! I'm running a yesod website that has authentication.  How do I make sure that users have to login as few times as possible?
08:53:51 <infinisil> tdammers: That gets annoying with more complex configuration
08:53:59 <tdammers> infinisil: then don't have complex configuration!
08:54:12 <wavemode> hell, no code. just `export SRC = "main = do ..."`
08:54:47 <tdammers> environments are particularly great when you need to instrument your payload app with some sort of watchdog
08:55:22 <infinisil> tdammers: Also, no syntax checking with environment variables. All you can have is strings
08:55:31 <Entroacceptor> Someone even wrote a manifest https://12factor.net/
08:55:33 <infinisil> So you necessarily need a parsing step, which can fail
08:55:37 <EvanR> environment variabls get their values from somewhere
08:56:31 <EvanR> environment variable strings... still need to be parsed if there is any format at all (urls)
08:56:45 <Entroacceptor> Everything neesd to be checked anyway?
08:57:18 <infinisil> With e.g. Dhall at least, all the checks are implemented in Dhall already, so you don't need to do that in your own code
09:16:30 <Entroacceptor> Admitedely I've no idea about Dhall, at first look it's interesting.
09:28:49 <maerwald> doesn't have maps does it?
09:33:11 <Cheery> hm.. I just told somebody how to verify regex matching with idris.
09:33:51 <Cheery> I hope that person doesn't try to implement sets like I did.
09:40:18 * hackage units 2.4.1.3 - A domain-specific type system for dimensional analysis  https://hackage.haskell.org/package/units-2.4.1.3 (RichardEisenberg)
09:42:44 <LiStu> Hi, I have a question. Is there a way to have a type-level variable? For example, I'm working on known-length vectors. Now, given a normal List, I'd like to create a vector of unknown length N. Then, if I construct another vector of 1's also of length N, I should be able to add the two vectors elementwise. Bit since I don't know the exact length
09:42:45 <LiStu> statically, haskell won't let me do this. Or is there way?
09:44:32 <Cheery> yes, but you'll be like "how many extensions you want?" and the ghc is like "yes".
09:44:39 <srk> lol
09:44:52 <srk> sounds like ideal job for Agda ;)
09:45:15 <srk> I think I saw examples of exactly this out there
09:45:53 <LiStu> Of course I'm already using the first screenfull of code for ghc extensions. I have something working in idris already, but to reach a broader audience, I'd like to be able to it in haskell.
09:46:10 <Cheery> DataKinds maybe
09:46:31 <ja> LiStu: did you see fixed-vector? maybe would make sense to work from that
09:46:58 <ja> @package vector-sized
09:46:58 <lambdabot> https://hackage.haskell.org/package/vector-sized
09:47:05 <srk> cool
09:47:19 <ja> and that one, the difference is explained in the vector-sized README
09:48:17 <LiStu> vector-sized looks cool. I'll go look at that. Thanks!
09:50:30 <ja> but it doesn't support concatenation afaik
09:50:43 <ja> i just thought it would make sense to use it as a starting point
09:51:51 <LiStu> It uses the type constraint KnownNat everywhere, which looks like the kind of thing I want. I'll see how it works and if I can extend it
10:06:12 <justin2> Woke up this morning to a working cabal-install. Thank you so much for the help sclv. The trick that finally made it work was, I unregistered cabal, and did not use the Cabal build. Instead in the cabal-install bootstrap, I read through how it was installing packages, and had it install Cabal, but with GHC --prof on the build for Cabal, then rerand cabal-install, and after about 2 hours went to
10:06:14 <justin2> sleep hoping it would be finishing in the morning, and it was. Thank you to everyone who helped :).
10:09:25 <ezzieyguywuf> if I have a `myFunc :: Int -> Int -> Int` and `myData = [1,2,3,4,5]`, how might I go about calling `myFunc` with each successive pair of values in myData, e.g. `myFunc (myData !! 0) (myData !! 1); myFunc (myData !! 1) (myData !!2` etc.
10:11:03 <enikar> :t zip
10:11:04 <lambdabot> [a] -> [b] -> [(a, b)]
10:11:40 <ezzieyguywuf> enikar: perfect!
10:11:43 <enikar> ezzieyguywuf: you can with  zip l (tail l)
10:12:10 <kuribas> better zipWith then
10:12:12 <enikar> or something like that.
10:12:14 <kuribas> :t zipWith
10:12:15 <lambdabot> (a -> b -> c) -> [a] -> [b] -> [c]
10:12:28 <ezzieyguywuf> yea I need to figure out how to use the tuples to call myFunc, but I s hould be able to get there
10:12:42 <kuribas> zipWith myFunc l (tail l)
10:12:45 <dsal> That's uncurry, but zipWith is probably what you want.
10:12:50 <dsal> :t uncurry
10:12:52 <lambdabot> (a -> b -> c) -> (a, b) -> c
10:12:57 <ezzieyguywuf> ah, map ofc
10:13:08 <dsal> :zipWith (,)
10:13:14 <dsal> :t zipWith (,)
10:13:15 <lambdabot> [a] -> [b] -> [(a, b)]
10:13:31 <dsal> map?
10:13:45 <ezzieyguywuf> I can use map with the zipped list to call `myFunc`
10:14:10 <ezzieyguywuf> something like `map (\ a b -> myFunc a b) zippedList`
10:14:22 <enikar> i always think that zipWith is a kind of map2.
10:14:29 <ezzieyguywuf> er, the lambda would be `\ (a,b) -> myFunc a b`
10:14:42 <ezzieyguywuf> yea I can see that
10:14:44 <ezzieyguywuf> zip + map
10:14:54 <monochrom> I think "zip3 xs (drop 1 xs) (drop 2 xs)" helps a great deal.
10:14:55 <dsal> :t uncurry
10:14:56 <lambdabot> (a -> b -> c) -> (a, b) -> c
10:15:24 <monochrom> Actually zipWith3 myFunc xs (drop 1 xs) (drop 2 xs)
10:16:12 <monochrom> Note that drop is better than tail for this.
10:16:50 <monochrom> err, maybe not, depends on whether you want errorring out or silent empty list in case of list-too-short
10:17:24 <dsal> @src zip
10:17:24 <lambdabot> zip (a:as) (b:bs) = (a,b) : zip as bs
10:17:24 <lambdabot> zip _      _      = []
10:21:08 <dsal> ezzieyguywuf: why are you avoiding zipWith, though?  It's the exact thing you asked for.
10:23:19 <dsal> And `uncurry` is what your lambda does.
10:25:39 <solonarv> monochrom: actually tail won't cause an error if it's the second argument
10:26:03 <solonarv> zip (and zipWith) pattern match on the first argument first; so zip xs (tail xs) is always safe
10:28:32 <zincy_> tdammers: I was swaying towards env variables and no config files. What is your reasoning for preferring one over the other?
10:29:18 * hackage unordered-containers 0.2.11.0 - Efficient hashing-based container types  https://hackage.haskell.org/package/unordered-containers-0.2.11.0 (sjakobi)
10:48:18 * hackage hlibsass 0.1.10.1 - Low-level bindings to Libsass  https://hackage.haskell.org/package/hlibsass-0.1.10.1 (jakubfijalkowski)
10:50:02 <bifunc2> when / for what types of  things are vectors  slower than arrays?
10:50:21 <merijn> bifunc2: Why would vectors be slower?
10:50:37 <bifunc2> no idea. they're "higher level"?
10:50:54 <merijn> Are they?
10:51:04 <bifunc2> i guess not then lol
10:51:09 <dolio> Those are just two names for the same thing, unless you mean something more specific.
10:51:22 <monochrom> Good call.
10:54:56 <bifunc2> is a mutable vector almost as cheap as just a pointer to memory in C? (assume i'm only in the IO monad)
10:55:12 <monochrom> yes
10:55:18 <bifunc2> cool
10:55:22 <merijn> bifunc2: Mutable Storable vectors are literally implemented as a ForeignPtr, so yes ;)
10:57:11 <merijn> bifunc2: It depends a bit, though. For example the default Vector from the vector package is boxed (so it's similar to a Java array containing object references, or a C array holding pointers to structs). There's also various more specific vector types (unboxed, primitive, storable) that are different.
11:01:16 <bifunc2> yeah
11:05:36 <ezzieyguywuf> dsal: nah I ended up using zipWith
11:07:14 <tdammers> zincy_: experience, mainly. config files are messy: you need to "manage" them, they're kind of action-at-a-distance, they're easy to leak, easy to accidentally commit to source control, etc.
11:07:24 <ChaiTRex> bifunc2: Vectors can actually be faster than arrays due to fusion rules.
11:07:28 <tdammers> zincy_: I also like how environments are inherited
11:08:03 <mlugg> Hi, I'm doing some work with SDL 2, and have found what seems to be a bug relating to audio callbacks (https://github.com/haskell-game/sdl2/issues/219). I've filed an issue, but since the package seems somewhat poorly maintained, I thought I'd take a look myself. The error I'm getting seems especially interesting to me since it only happens in
11:08:03 <mlugg> certain cases - replacing the data I write in the callback with a simple `replicate` call seems to work just fine, and the fact that the errors I can get range from segfaults to GHC closure type errors (?!) suggest something very odd is afoot. I obviously don't expect someone to help debugging the library, but it'd be super helpful if someone could
11:08:04 <mlugg> give me a suggestion on where this kind of issue could be being introduced, since clearly some actual Haskell runtime info is being messed with by something. Thanks :)
11:08:54 <merijn> mlugg: Are you handy with gdb/lldb?
11:09:28 <mlugg> merijn: I'm not the best, but I can definitely use them
11:10:08 <mlugg> Does/can GHC emit debug info?
11:10:32 <merijn> mlugg: So, there's decent odds things go wrong when Haskell gets called from the SDL C code. The good news is that if you compile with -debug (I think?) you'll get a version of the RTS that has debug symbols and recent-ish (8.2 or 8.4+?) versions of GHC have basic DWARF support
11:10:45 <merijn> @where userguide
11:10:45 <lambdabot> https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/
11:10:56 <merijn> GHC user's guide should have the exact flags/details
11:12:07 <mlugg> Okay, thanks :D
11:19:48 * hackage colorful-monoids 0.2.1.3 - Styled console text output using ANSI escape sequences.  https://hackage.haskell.org/package/colorful-monoids-0.2.1.3 (minad)
11:20:48 * hackage intro 0.8.0.0 - Safe and minimal prelude  https://hackage.haskell.org/package/intro-0.8.0.0 (minad)
11:21:48 * hackage bip32 0.1 - BIP-0032: Hierarchical Deterministic Wallets for Bitcoin and other cryptocurrencies  https://hackage.haskell.org/package/bip32-0.1 (RenzoCarbonara)
11:22:48 * hackage paripari 0.7.0.0 - Parser combinators with fast-path and slower fallback for error reporting  https://hackage.haskell.org/package/paripari-0.7.0.0 (minad)
11:23:48 * hackage persist-state 0.1.1.6 - Minimal serialization library with focus on performance  https://hackage.haskell.org/package/persist-state-0.1.1.6 (minad)
11:24:45 <zincy_> tdammers: Thanks!
11:27:33 <kuribas> how can I make new-build use a modified package, instead of the official one?
11:28:19 <kuribas> I repaired the documentation for the fast-logger package, but how can I use my one now instead of the remote one?
11:30:18 * hackage simple-cmd 0.2.2 - Simple String-based process commands  https://hackage.haskell.org/package/simple-cmd-0.2.2 (JensPetersen)
11:30:36 <kuribas> I tried cabal new-install in the fast-logger directory, but that gives an error: "cabal: Could not resolve dependencies:"
11:31:55 <monochrom> I think you write it in cabal.project or cabal.project.local (I think either is fine, up to you), and you write a "packages: " clause to include both the directory containing your copy of fast-logger and the directory containing your own package.
11:34:19 <kuribas> ok, thanks
11:34:41 <monochrom> I haven't really tried though :)
11:39:46 <dolio> I have. That's how you do it, if I recall.
11:39:56 <monochrom> \∩/
11:44:55 <kuribas> it worked!
11:45:25 <kuribas> I added "packages: /home/kuribas/path/to/fast-logger-3.0.1" to cabal.project.local
11:53:14 <dminuoso> maerwald: Our SDN solution was error prone and slow.
11:54:16 <maerwald> I thought you were just bored :p
11:55:06 <bifunc2> what's the fastest way to get all possibilities for a single 3-byte mutable vector (and do something for each possibility)? this is how one would do it for ordinary triples: [ (b0,b1,b2) | b0 <- [0..255], b1 <- [0..255], b2 <- [0..255] ] and forM_ through them
11:55:49 <bifunc2> the main difference is that those are all different triples, unlike the single mutable vector i want
11:59:24 <monochrom> Why do you need mutable.
12:00:51 <monochrom> Are you OK with https://hackage.haskell.org/package/inline-asm if it comes down to that.
12:01:16 <monochrom> This is a scrutiny on how much you really mean "fastest".
12:02:39 <bifunc2> well almost same as three nested for loops in C
12:03:09 <bifunc2> now, i also need some "state" to move between iterations. (in c i can do that with an outer variable)
12:03:14 <monochrom> The list comprehension method is almost the same as three nested for loops in C.
12:03:57 <monochrom> You can use the State monad for that outer variable.
12:04:07 <monochrom> Since you're using forM_ anyway.
12:10:18 <merijn> bifunc2: What makes you think the list comprehension isn't fast? (I'm not saying it is, but what's your reason for thinking it's not?)
12:11:18 <bifunc2> oh, that was just meant as an example - a tuple analog to mutable vector
12:11:24 <monochrom> People misinterpret "reason" as "uninformed opinion". So I would go for evidence not "reason".
12:15:12 <merijn> If there's one thing I've learned about doing high performance code, it is that (as a first approximation) everyone is wrong when they ask about performance and how to do things fast :)
12:15:46 <merijn> If you're an expert you just find more subtle, convoluted, and advanced ways to be wrong
12:16:05 <bifunc2> one thing i've seen is it's hard to compare c with IO Haskell because c gcc optimization is insanely good compared to IO GHC optimization
12:16:39 <monochrom> It is even harder to compare no-I/O C with no-I/O Haskell.
12:16:52 <monochrom> Consider doing "mod 7" a million timees.
12:17:15 <monochrom> GHC generates honest-to-God a divmod instruction.
12:17:16 <merijn> bifunc2: That's why you need data :p
12:17:23 <monochrom> Guess what gcc generates.
12:17:43 <koz_> monochrom: Big loop?
12:17:46 <merijn> monochrom: I don't need to, I have heard about our lord and saviour Godbolt
12:18:01 <maerwald> as a novice C coder, you can do some pretty good optimisations without really understanding gcc... in haskell? no
12:20:14 <sm[m]> mlugg: good luck, and there are some SDL users in #haskell-game also
12:20:34 <monochrom> gcc generates a "multiply by magic number" instruction that, under 64-bit, is equiv to mod 7.
12:20:48 <koz_> monochrom: TIL.
12:21:09 <bifunc2> is there no work being done to bring ghc IO closer to gcc?
12:21:13 <monochrom> This is why gcc-generated code is like 5 times faster than GHC-generated code for this microbenchmark.
12:21:27 <monochrom> In fact, solely why.
12:21:53 <mlugg> sm[m]: thanks, I'll head in there too :)
12:21:56 <merijn> bifunc2: Sure, and once GHC has the same number of paid people working on it fulltime as gcc they might even succeed
12:22:03 <monochrom> merijn yes you're smart :)
12:22:12 <merijn> koz_: https://godbolt.org :)
12:22:31 <monochrom> godbolt has GHC too, just a pretty old version.
12:22:32 <koz_> merijn: Yeah, thanks. Should use that more.
12:22:33 <merijn> monochrom: I'm just incredibly lazy to the extent that I appear smart ;)
12:22:42 <monochrom> wise
12:23:17 <monochrom> energy-smart
12:23:39 <ja> would the llvm ghc backend also be able to do something like the magic number?
12:23:52 <ja> at least in theory?
12:23:52 <monochrom> I haven't tried. Too lazy.
12:24:10 <monochrom> In theory, every compiler generates God-like code.
12:24:44 <ja> intuitively, i always thought it should be easier to optimize haskell because of purity
12:25:07 <ja> llvm should know about purity too, that is related to constant propagation and such
12:25:17 <koz_> ja: A lot of things are true in theory. Code tends to be harder.
12:25:19 <monochrom> In theory, if you write code to brute-force search for a counterexample to the Riemann hypothesis, the compiler optimizes your code to "L1: jmp L1"
12:26:21 <koz_> monochrom: Wait, do we have a proof of Riemann? Or am I misunderstanding?
12:26:39 <monochrom> No, I'm exaggerating.
12:27:13 <ChaiTRex> koz_: The compiler proves it and then optimizes your code.
12:27:18 <monochrom> :)
12:28:03 <bifunc2> BTW, is Haskell's parallelism story as good as they say? I heard rumors that it's not that simple. I heard that beyond e.g. 12 cores the GC overhead starts to become too much, so the benefit of 6 -> 12 cores will be way bigger than 12 -> 24 cores.
12:28:12 <wavemode> that reminds me of this hilarious post: https://blog.regehr.org/archives/140
12:30:02 <maerwald> bifunc2: no idea. I haven't seen particular strong abuse of parallelism in haskell. 
12:30:28 <wavemode> haskell is renowned for concurrency, not parallelism
12:31:18 <Cale> bifunc2: It's hard to make blanket statements, because performance depends quite finely on exactly how your algorithm works.
12:31:34 <Cale> Haskell gives you some nice tools for expressing both parallelism and concurrency.
12:31:39 <dminuoso> Parallelism in Haskell is executed to very high degrees at facebook using haxl.
12:31:47 <dminuoso> But the parallelism is multi-node parallelism.
12:31:53 <Cale> But it's still up to you to actually make parallelism available.
12:40:14 <bifunc2> ok. hopefully some unfounded rumors then
12:46:50 <merijn> ja: For numeric stuff the LLVM backend can get better code, yeah. But for average Haskell it's still a bit worse
12:47:06 <Uniaika> (like in Erlang haha)
12:47:17 <koz_> I think someone did a writeup on why recently.
12:52:57 <rsoeldner> Hi, trying to use the FFI with the `xmlsec` library. I'm able to compile my document with the `pkg-config --libs xmlsec1-openssl` and ` ... --cflags..` options with when adding `pkgconfig-depends: xmlsec1-openssl` I receive quite some errors, cannot open shared object file, .. trying to load ltdl, which should be disabled by these flags
12:54:53 <rsoeldner> Is cabal picking all parameters, eg cflags and libs ?
13:04:18 * hackage git-annex 8.20200617 - manage files with git, without checking their contents into git  https://hackage.haskell.org/package/git-annex-8.20200617 (JoeyHess)
13:24:16 --- topic: 'https://www.haskell.org | https://wiki.haskell.org/IRC_channel | Paste code/errors: https://gist.github.com/ | Logs: http://tunes.org/~nef/logs/haskell/?C=M;O=D | https://www.reddit.com/r/haskell | Admin: #haskell-ops | Offtopic: #haskell-offtopic | https://downloads.haskell.org'
13:24:16 --- topic: set by glguy on [Sat Jan 05 07:21:52 2019]
13:24:23 <frdg> Is this a practical plan?
13:25:46 <dminuoso> frdg: Hard to say. Do you wanta Haskell job?
13:27:27 <rsoeldner> merijn, still same issue
13:28:25 <rsoeldner> merijn, but thanks
13:28:30 <frdg> dminuoso: Ya, or any functional language really. I'm very interested in math as well. 
13:29:02 <dminuoso> frdg: It's hard to say in general and depends on where you live.
13:29:37 <frdg> dminuoso: But really I just want to learn and I want my job to put me into the best position to learn. I'm in Boston if that means anything.
13:31:15 <ystael> frdg: I am tech lead at a small company that does about half of its development work in Haskell. We have hired people who did not complete their undergrad degree and had previous functional programming experience. For me as a hiring manager, _no_ higher education would need to be balanced by a very strong portfolio. You need to figure out how you are going to answer the questions that a degree (for better 
13:31:21 <ystael> or for worse) is usually your proxy for answering.
13:32:46 <wavemode> If you can get four years of relevant real-world work experience, it's worth more than a four-year degree in most software jobs. But, easier said than done.
13:34:27 <dolio> There's also a reason why it doesn't really matter whether a university teaches someone "functional programming".
13:35:08 <frdg> dolio: Could you expand on that
13:38:11 <dolio> It's not that hard to teach someone how to express an algorithm in a functional language, compared to teaching them the principles and concerns behind designing good algorithms in the first place.
13:39:01 <dolio> And the latter, among other things, is what you're supposed to learn at a university.
13:39:24 <frdg> dolio: I see
13:39:32 <dolio> You're supposed to learn roughly how a CPU works, and how operating systems work, and how compilers work, and ...
13:40:42 <dolio> And if you think there's nothing to learn from 'other paradigms,' that's probably also wrong.
13:44:43 <dolio> That's not to say that having a degree is a guarantee that someone actually learned that, or that you can't learn it outside a university, but there's a lot more that it's supposed to be about.
13:52:14 <EvilPyro> how can i generate an infinite list of Integers [0..]? All methods i know only work with Int
13:52:57 <ClaudiusMaximus> :t [0..]
13:52:59 <lambdabot> (Num a, Enum a) => [a]
13:53:17 <frdg> x  = [0..] :: [Integer]
13:53:23 <ClaudiusMaximus> % :info Integer
13:53:23 <yahb> ClaudiusMaximus: type Integer :: *; data Integer = integer-gmp-1.0.3.0:GHC.Integer.Type.S# Int# | integer-gmp-1.0.3.0:GHC.Integer.Type.Jp# {-# UNPACK #-}integer-gmp-1.0.3.0:GHC.Integer.Type.BigNat | integer-gmp-1.0.3.0:GHC.Integer.Type.Jn# {-# UNPACK #-}integer-gmp-1.0.3.0:GHC.Integer.Type.BigNat; -- Defined in `integer-gmp-1.0.3.0:GHC.Integer.Type'; instance Eq Integer -- Defined in `integer-gmp-1.0.3.0:GHC.Integ
13:53:31 <ChaiTRex> EvilPyro: [0..] works. [0..] :: [
13:53:45 <ChaiTRex> EvilPyro: [0..] works. [0..] :: [Integer] if the type isn't picked up.
13:55:05 <EvilPyro> I'm getting No instance for (Num [Integer]) arising from the literal ‘0’
13:55:27 <[exa]> EvilPyro: can you show the whole code?
13:55:40 <ChaiTRex> EvilPyro: [0..] :: [Integer] isn't 0 :: [Integer].
13:55:48 <EvilPyro> ofcourse, let me find a way to paste
13:56:19 <[exa]> EvilPyro: not necessarily "whole" though a minimal non-working example is sufficient :]
13:56:37 <EvilPyro> https://pastebin.com/raw/0MvEuHGM
13:56:42 <EvilPyro> its just 2 lines xDDD
13:57:22 <[exa]> EvilPyro: `cycle` expects a list, and you `map` it to the list of integers, thus you feed integers to the cycle
13:57:37 <wavemode> :t cycle
13:57:37 <EvilPyro> oh true
13:57:38 <lambdabot> [a] -> [a]
13:59:59 <mananamenos> hi, im trying to read through Reader docs. There is `newtype ReaderT r m a`. Why `type Reader r = ReaderT r Identity` is legal expression? Does it still miss one more parameter, the `a`?
14:00:23 <mananamenos> *doesn't
14:00:58 <[exa]> mananamenos: semantically, the 'a' disappears through eta reduction and the kinds match, so no problems
14:01:36 <mananamenos> so it because of Identity's kind, being `newtype Identity a`?
14:02:15 <ChaiTRex> mananamenos: No, it's equivalent to: type Reader r m a = ReaderT r Identity m a
14:02:19 <[exa]> no, just `type X a = Y a` is equivalent to `type X = Y` (with some minor technical limits)
14:03:00 <ChaiTRex> mananamenos: Sorry, without the m.
14:03:16 <mananamenos> good that i've asked :) would have been hours looking and wouldnt have thought about this
14:03:20 <mananamenos> thanks!
14:04:05 <[exa]> mananamenos: it is perfectly same as `f x = g x` being equivalent to `f = g`, just on type level. Try `:k Reader` in ghci to see the "functions" in there
14:06:44 <mananamenos> [exa], yeah, this is a great way to see Reader takes 2 type args `Reader :: * -> * -> *`. However, looking in the docs at `type Reader r = ReaderT r Identity` and being noob seems like the type Reader is supposed to be used with 1 type arg only :)
14:07:39 <[exa]> mananamenos: well sometimes it takes just 1 argument
14:08:08 <[exa]> say `StateT Int (Reader String) a`
14:11:40 <mananamenos> [exa], hmmm, in your example you partially applied Reader. Is this because the StateT requires a type of kinde *->* in its second argument?
14:12:19 <ChaiTRex> :k StateT
14:12:21 <lambdabot> * -> (* -> *) -> * -> *
14:13:28 <ChaiTRex> :t StateT
14:13:29 <lambdabot> (s -> m (a, s)) -> StateT s m a
14:13:55 <bitmapper> it has been done
14:13:56 <bitmapper> Yale Haskell Y2.2   Clozure Common Lisp version Version 1.12 (v1.12-23-g417f576e) DarwinX8664 on x86_64 
14:14:17 <ChaiTRex> mananamenos: It's supposed to be a monad, which is kind * -> *.
14:14:18 <monochrom> That's interesting
14:14:29 <bitmapper> what is?
14:14:55 <monochrom> Yale Haskell compiled by Clozuer Common Lisp.
14:15:10 <bitmapper> i found a 2.2 release which apparently is a thing?
14:15:15 <monochrom> and on x86-64, a platform that didn't exist back then
14:15:26 <bitmapper> i only knew of 2.05
14:15:35 <bitmapper> but i got it running perfectly on ccl
14:34:38 <jumper149> Is there a class providing methods like mapReaderT, but for any monad-transformer with an instance? I'm currently learning MonadBaseControl.
14:35:10 <_deepfire`> bitmapper: Lisp and Haskell, like milk and honey? : -)
14:36:54 * cons eyes nil
14:40:03 <garp> nil: ping
14:43:26 <berndl> I just noticed someting: Isn't replicateM n just fmap (replicate n)?
14:44:11 <nil> no
14:44:22 <nil> try it with getLine, you'll see the difference
14:44:34 <monochrom> try s/fmap/sequence/
14:44:42 <monochrom> or sequenceA
14:46:23 <koz_> Does anyone know what the automagic deriver for Aeson's FromJSON and ToJSON instances does for sum types?
14:46:30 <koz_> Or where I can find out this information?
14:46:31 <berndl> nil: I knew that IO was going to be the counterexample.
14:46:36 <berndl> It's always IO
14:46:39 <nil> it's not
14:46:58 <nil> any non-pure action is a counterexample
14:47:16 <nil> replicateM will replicate the effects, fmap will not
14:47:53 <berndl> IO values are pure, no?
14:48:04 <nil> > (replicateM 2 [1, 2], fmap (replicate 2) [1, 2])
14:48:06 <lambdabot>  ([[1,1],[1,2],[2,1],[2,2]],[[1,1],[2,2]])
14:48:20 <nil> berndl: only those created with pure/return
14:48:24 <monochrom> You can already notice "Maybe [X]" vs "[Maybe X]"
14:48:38 <dminuoso> berndl: Yes.
14:49:20 <nil> what's yes
14:49:47 <berndl> Alright. I think I get now. Thank you folks.
14:50:13 <dminuoso> berndl: IO values are pure in the sense that if you force their evaluation, they have no side effects.
14:50:33 <dminuoso> But IO itself carries an effect, that can be executed by main.
14:50:53 <berndl> or unsafePerformIO
14:51:20 <koz_> I just got a warning about an implicit kind var, because I wrote something like 'forall (foo :: k) . ...'. How would I add an explicit forall for that k?
14:51:20 <dminuoso> Well, I dont think its particularly helpful to call unsafe* primitives when talking about the semantics of the language.
14:51:44 <koz_> It is seriously 'forall k . forall (foo :: k) . ...'?
14:51:51 <dminuoso> koz_: No, you can include it in the same forall
14:52:03 <koz_> Ah, so it'd be 'forall k (foo :: k) . ...'?
14:52:43 <koz_> Seems to work, thanks.
14:52:52 <koz_> (thanks beam, you're making me learn things)
14:53:08 <jumper149> Can't you just replace k with foo in the type signature?
14:53:14 <monochrom> koz_: In the doc for FromJSON and ToJSON (which are pretty long), look for "Instead of manually writing", below it there are pointers to "defaultOptions", which is what it does and what you can change.
14:53:25 <koz_> monochrom: OK, will check. Thanks!
14:53:31 <dminuoso> jumper149: I dont even know what that would mean.
14:53:33 <koz_> jumper149: They're different things.
14:53:43 <koz_> 'foo' is a type, 'k' is its kind.
14:53:55 <jumper149> Ah yeah, I'm stupid x)
14:56:54 <koz_> Ideally it'd be something like 'forall (k :: Sort) (foo :: k) . ...' :P
14:58:15 <monochrom> We have TypeInType so we won't really have a Sort apart from aliasing it to Type.
14:58:28 <koz_> monochrom: Yeah, I do understand that part.
14:58:46 <koz_> Ditto Kind and 'whatever-is-'above'-Sort' too.
15:19:18 * hackage http-client-restricted 0.0.3 - restricting the servers that http-client will use  https://hackage.haskell.org/package/http-client-restricted-0.0.3 (JoeyHess)
16:08:49 * hackage TeX-my-math 0.202.0.0 - Render general Haskell math to LaTeX. Or: math typesetting with high signal-to-noise–ratio.  https://hackage.haskell.org/package/TeX-my-math-0.202.0.0 (leftaroundabout)
16:44:36 <joelg> I have a data structure which only ever stores finite sets of integers (the concrete underlying datastructure is an array of Int -> Bool, where an Int is considered in the set if the array is True in that spot). It doesn't seem possible to write an instance of Foldable for this structure. Is there some other way to automatically get the methods length, maximum, ... inside Data.Foldable for my datastructure?
16:45:12 <dminuoso> joelg: Why shouldn't there be a Foldable?
16:45:23 <dminuoso> Int is Bounded
16:45:54 <koz_> dminuoso: Foldable has kind (Type -> Type) -> Constraint, if memory serves. How is this structure of kind Type -> Type?
16:46:04 <dminuoso> Oh.
16:46:10 <dminuoso> MonoFoldable at the very least then.
16:46:36 <koz_> joelg: You can use a newtype deriving strategy, assuming MonoFoldable is compatible with your structure.
16:46:43 <koz_> Foldable is not, for the kindedness reasons stated above.
16:46:44 <joelg> I can write folds for it no worries, I was just wanting to see if there is some way of leveraging the existing functions in Data.Foldable
16:47:01 <koz_> joelg: Yeah, you can just unwrap the (I assume) newtype and call them.
16:47:12 <monochrom> Int->Bool isn't subject to MonoFoldable either, unless you really go out of your way to enumerate all 2^64 Ints.
16:47:12 <koz_> But you can't derive Foldable itself because your structure is ill-kinded to be an instance.
16:47:40 <koz_> monochrom: Oh yeah, I misread. If it's an array full of functions, you've got issues.
16:47:59 <dminuoso> monochrom: I was under the impression that thats exactly what they wanted.
16:48:11 <dminuoso> monochrom: For what its worth, it should be 2^61 right?
16:48:25 <joelg> Sorry, poor phrasing on my part. The concrete type is UArray Int Bool
16:48:25 <monochrom> GHC makes it really 2^64.
16:48:32 <dminuoso> Oh it does? 
16:48:50 <monochrom> GHC sacrifices something else to achieve it.
16:49:44 <dminuoso> joelg: Anyhow, MonoFoldable fits that bill.
16:50:09 <koz_> If it's a newtype around said array, you can likely borrow stuff by using a newtype deriving strategy.
16:50:22 <koz_> Although I dunno if MonoFoldable is amenable to that, because it has an asstype I think?
16:50:29 <dminuoso> asstype?
16:50:35 <koz_> dminuoso: Associated type.
16:50:42 <dminuoso> Oh. That came off wrong.
16:50:52 <koz_> Thank jle` for me adopting that 'convention'. :P
16:50:55 <dminuoso> Maybe assocty is a better abbreviatoin? ;)
16:51:21 <koz_> I assume it's analogous to 'fundep'.
16:51:53 <dminuoso> koz_: Anyhow, the assoc tyfam is just a way to link the Mono thing to its contained type.
16:52:14 <dminuoso> So for instance `newtype Foo = Foo { unFoo :: [Int] }` would be mono traversable with `Int` as its mono type.
16:52:22 <dminuoso> (Or mono foldable)
16:52:31 <koz_> dminuoso: Oh, I'm aware of why the [insert whatever name] is there. I was curious whether this permits you to do a newtype derive.
16:52:50 <dminuoso> With via probably
16:52:52 <koz_> Like, would it work to do something like 'newtype Bar = Bar [Int] deriving newtype MonoTraversable'?
16:52:55 <koz_> Ah, ok.
16:53:12 <koz_> Deriving via: What Iceland Jack gets out of bed for in the morning. :P
16:53:16 <dminuoso> Ah I see what you mean
16:53:32 <dminuoso> Well, there'd have to be a matching instance to begin with.
16:53:43 <koz_> Well, for MonoFoldable, I think [Int] qualifies, surely?
16:53:56 <koz_> Replace it with IntSet if that makes it more concrete.
16:54:19 <koz_> I am not too familiar with the Snoyverse.
16:57:37 <joelg> So this monofoldable thing relies on type families which are new to me
16:57:55 <dminuoso> joelg: a type family is essentially just a type level function that can associate types with other types.
16:57:57 <monochrom> "Be careful what you ask for."
16:58:11 <dminuoso> joelg: do you know fundeps with multi param type classes?
16:58:35 <joelg> dminuoso: I might know it by other names
16:58:58 <dminuoso> joelg: functional dependencies is the full name :)
17:00:14 <dminuoso> Anyhow, the tyfam just lets you associate the underlying element type to the container type.
17:01:56 <lemonpaul> Are there any features of working regex-pcre with unicode? I used regex-tdfa before and it will be ok. But now it doesn't match regex correctly.
17:02:17 <lemonpaul> https://gist.github.com/lemonpaul/1afc38615d1e54012d489c34fb60602a
17:03:24 <joelg> Thanks for the help dminuoso and koz_ , I will check these out and see if it is worth it
17:05:02 <lemonpaul> regex-tdfa worked properly
17:24:44 <wudis> @help
17:24:44 <lambdabot> help <command>. Ask for help for <command>. Try 'list' for all commands
17:29:32 <lemonpaul> Seems like pcre works properly if there're not unicode symbols.
17:42:06 <lemonpaul> Any ideas about how to match string with unicode?
17:50:15 <Hopplahase> lemonpaul: Have you tried pcre-heavy?
17:50:29 <lemonpaul> Not yet.
18:02:21 <remexre> what's the right way to run ghcup from a script?
18:04:24 <ezzieyguywuf> have you all ever heard of or used brick?
18:05:31 <sm[m]> ezzieyguywuf: certainly, it’s great
18:05:54 <sm[m]> except on windows
18:06:41 <lemonpaul> regex-pcre-builtin doesn't work too.
18:06:54 <ezzieyguywuf> but in windows is it b/c of the crappy console?
18:07:19 <ezzieyguywuf> are there any better alternatives? or something that _does_ also work in windows?
18:07:32 <sm[m]> windows has different libs and it takes work to adapt brick for those
18:07:36 <ezzieyguywuf> just wouldn't want to spend too much time learning it if the time would be better spent elsewhere
18:08:05 <sm[m]> no, I think there’s no TUI lib that’ll work in native windows
18:08:05 <wavemode> brick doesn't support windows because it depends on `unix`
18:08:10 <wavemode> find a library that doesn't
18:08:22 <ezzieyguywuf> hrm, I see.
18:08:53 <sm[m]> If you want a TUI, brick is probably the best choice
18:09:18 <ezzieyguywuf> ah hah
18:10:19 <sm[m]> ansi-terminal does work on windows, so you can do a little bit of TUI with that
18:10:44 <Cale> You might also like to check out reflex-vty
18:11:13 <dmwit_> Just looking at the name, I somehow doubt reflex-vty has better Windows support.
18:11:59 <ezzieyguywuf> thanks for the suggestions y'all
18:26:08 <jusss> about Cont Monad, what is the context? what's passing in >>= ?
18:26:44 <jusss> why it's so twisted? what's its point? archived?
18:29:18 * hackage pdftotext 0.1.0.0 - Extracts text from PDF using poppler  https://hackage.haskell.org/package/pdftotext-0.1.0.0 (geyaeb)
18:32:09 <ChaiTRex> jusss: Has something to do with continuations.
18:34:07 <fog> how does lens deal with hetrogenous lists?
18:34:44 <fog> i have a list of things that have internal states, where the type of this state is different between each 
18:35:01 <fog> i need methods to extract and replace them
18:35:10 <fog> these seem like basic lens opperations 
18:38:32 <fog86> there are plenty of varients of these hetrogenous things
18:39:03 <fog86> the type of the cons opperation is most informative
18:39:20 <fog86> HCons :: x -> HList xs -> HList (x ': xs)
18:39:33 <fog86> the one im using for these parametrised things is;
18:39:58 <fog86> FCons :: f x -> FList f xs -> FList f (x ': xs)
18:40:37 <fog86> (its like fmap over the types of the HList)
18:41:30 <fog> and there is CCons :: c x => x -> CList c xs -> CList c (x ': xs)
18:41:47 <fog> and any combination of these 
18:42:05 <fog> like, with constraints, and mapped parametrised things
18:42:20 <fog> anyway, each of them is going to have something like (!!)
18:42:33 <fog> to select an element 
18:42:44 <fog> and then, upon modifying this, to reinsert it
18:43:01 <fog> some kind of insertAt
18:43:11 <fog> which can be combined to give editAt
18:43:22 <fog> again, these all seem quite lensy
18:43:55 <fog> then, Traversable springs to mind
18:44:07 <fog> how does that work for hetrogenous things?
18:44:26 <fog> or Traversal, whatever the lens thing is called
18:44:52 <fog> i guess it needs an instance of that to be able to do the normall lens opperations like lookup and insert
18:44:55 <jusss> "what I'm reading" :)
18:45:27 <fog> ^?
18:45:35 <jusss> just kidding
18:46:27 <fog> your saying its not clear what i wrote?
18:47:16 <jusss> no, I mean I don't know those knowledge yet
18:47:35 <fog> well i guess your here to learn
18:47:35 <jusss> there're so many things I don't know yet
18:47:56 <Guest68588> hello, how do I go about deciding between `foldl' f x xs` and `foldr (flip f) x $ reverse xs`. It seems like foldr is preferred when possible but I don't know if the extra cost of reversing is worth it
18:48:10 <fog> well, feel free to ask for clarification on anything that seems like something you would like to learn
18:48:23 <Guest68588> I should add in this case I need the fold to go 'left to right' if that makes sense
18:49:00 <fog> Guest68588: why wuold you need to do that?
18:49:29 <Guest68588> this is for non-recursive `let` bindings, so each binding should be visible in the next bindings but not previous ones
18:49:40 <Guest68588> so left to right
18:49:42 <fog> it doesnt matter which order they recombine
18:50:11 <fog> oh right, your accumulating things
18:50:55 <fog> still, i guess there is some way to do this with foldr without needing to reverse the list
18:50:56 <Guest68588> yep, in the body it doesn't matter what the order is, but if the bindings want to reference each other they can only go backwards
18:51:09 <Guest68588> I guess it's like let* in scheme IIRC
18:51:27 <fog> i cant remember how mapAccumL and mapAccumR work, but i think they had a StateL and a StateR
18:51:46 <fog> idk how those applicatives are recombined, but maybe it can pass the values forwards
18:52:04 <wavemode> Guest68588: https://wiki.haskell.org/Foldr_Foldl_Foldl%27
18:52:46 <fog> is it called a paramorphism where it needs access to the yet-to-be encountered values?
18:53:00 <fog> or a zygomorphism or something strange like that
18:53:26 <fog> anyway, i guess that you should only ever need foldr if you wrangle it correctly
18:54:49 <fog> i guess the way i think of that is like with the credit card transform style of just like, leaving a kind of gap in your code and saying like "thing goes here when it exists, but it doesnt yet, but dont wory about that now"
18:55:17 <fog> and then some magic occurs and the values all end up where they are needed eventually
18:55:30 <wavemode> Guest68588: in particular, it's kind of a common misconception that foldr should be preferred generally. it should pretty much only be preferred when its laziness is desirable (e.g. you're using it to produce a lazy data structure, such as a list, rather than a strict value, such as a number)
18:55:37 <iqubic> fog: That's a futumorphism.
18:55:49 <fog> thats actually not a bad name for it
18:56:04 <fog> any idea how to implement it?
18:56:12 <Guest68588> wavemode: ok that's helpful, in this case I think there's no need for laziness
18:56:57 <fog> hmm, yeah i guess if your not doing fusion into the lazily consumed thing  - which you probably cant if its reading future values...
18:57:11 <Guest68588> I do feel dissuaded from foldl' though because I have read that it can cause space leaks anyway since it only reduces to WHNF
18:57:45 <dolio> No, you should always use foldl' over foldl.
18:57:58 <wavemode> foldl' is the one which most often _prevents_ space leaks. (but none of the folds are immune to them, per se)
18:58:00 <Guest68588> yep, I mean dissuaded from foldl' in favor of foldr
18:58:14 <fog> i guess in general the future references might be only not far into the thing, so lazyness is not precluded 
18:59:08 <fog> im assuming your carrying *all* the previously encountered values when your foldr'ing over the reversed list
18:59:24 <fog> so like, using *all* the future reference if folding over it in the forwards direction
18:59:32 <fog> which cant be lazy
18:59:50 <Guest68588> why future instead of past?
19:00:15 <fog> i thought thats why it was being reversed, or folded from the other side
19:01:05 <fog> and there was mention of " scheme like let binding" which i guess was something like accumulating values into the carried argument 
19:01:45 <Guest68588> yeah I'm not sure, I find it counter-intuitive that I need a left fold/reverse at all. Because all I"m doing is ensuring that the first binding is visible to subsequent bindings and the second to its successors and so on. That doesn't seem like it's reversed to me
19:01:56 <fog> if this wasnt destructive - like, if mapAccum was being used instead, then it shouldnt matter which direction it happens
19:02:02 <Guest68588> like that seems like forward, not backward
19:02:30 <fog> :t foldl
19:02:31 <lambdabot> Foldable t => (b -> a -> b) -> b -> t a -> b
19:02:49 <fog> oh yeah, doh
19:02:54 <Guest68588> the direction should matter in any case I think because if I try to access the second binding from the first that should be an error
19:03:16 <fog> but if you were going to be doing it with foldr to avoid the quadratic blowup or whatever the problem with foldl is
19:03:36 <fog> then it would be future-wise wrt that
19:03:47 <Guest68588> yeah, that seems to be the case
19:04:17 <fog> thats what i was saying about traverse and StateL and StateR
19:04:29 <fog> and instead of like, storing values as you get to them, 
19:04:38 <fog> you would like, post them forwards into the next
19:04:44 <fog> which you can do in a traversal
19:04:48 <Guest68588> I will look at those
19:04:55 <Guest68588> it sounds relevant
19:05:02 <fog> at the stage where you merge all the applicatives together 
19:05:31 <fog> Guest68588: i think its just the implementation of mapAccumL
19:07:04 <Guest68588> now that you mention it, maybe if I changed it to use State then I could do it with traverse instead, then I think I wouldn't have to reverse
19:07:18 <Guest68588> not sure if it's worth though considering I'm not using it already
19:07:57 <fog> certainly resorting to either reverse or foldl seems worrying
19:08:13 <fog> i dont think the same worry need apply to use of mapAccumL though
19:08:20 <fog> could be wrong about that, not sure
19:08:51 <Guest68588> oh really? I had assumed mapaccuml would have the same issue of thunk buildup
19:09:05 <Guest68588> also I think I would just be passing in `id` for the map part
19:09:59 <fog> you mean pure?
19:10:16 <fog> :t traverse
19:10:17 <lambdabot> (Traversable t, Applicative f) => (a -> f b) -> t a -> f (t b)
19:10:24 <fog> :t traverse pure
19:10:26 <lambdabot> (Traversable t, Applicative f) => t b -> f (t b)
19:10:34 <fog> oh, or for mapAccumL
19:10:38 <fog> :t mapAccumL
19:10:39 <lambdabot> Traversable t => (a -> b -> (a, c)) -> a -> t b -> (a, t c)
19:10:59 <fog> still doesnt look much like id... 
19:11:03 <Guest68588> yeah not `id` my bad
19:11:15 <fog> you mean c = b
19:11:19 <Guest68588> I guess probably passing in the `a` value for `c`
19:11:29 <Guest68588> yeah idk which
19:11:31 <Guest68588> a or b
19:11:42 <fog> i think the `a' value is the accumlating thing
19:11:55 <fog> see how it enters as where the basecase of the fold would go
19:12:04 <fog> and is returned alongside the t c
19:12:04 <Guest68588> yep
19:12:35 <fog> yeah, you probably wouldnt be doing id with that, or there wouldnt be much point in carrying anything at all!
19:12:57 <fog> i guess you mean leaving the `b' values unchanged in the `t b'
19:13:18 <fog> maybe you were just going to be doing fst to it anyway...
19:13:28 <Guest68588> yeah that's my point, I just need the `accumL` part not the `map` part, so I don't see how I benefit from changing it from a fold
19:13:29 <fog> :t (fst .) . mapAccumL
19:13:30 <lambdabot> error:
19:13:30 <lambdabot>     • Couldn't match type ‘[b] -> (a, [c])’ with ‘(c1, b0)’
19:13:30 <lambdabot>       Expected type: (a -> b -> (a, c)) -> a -> (c1, b0)
19:13:53 <Guest68588> it has 3 arguments, that's why it didn't work
19:14:02 <fog> :t ((fst .) .) . mapAccumL
19:14:03 <lambdabot> Traversable t => (c1 -> b -> (c1, c2)) -> c1 -> t b -> c1
19:14:44 <fog> i think the benifit could be to do with the use of the StateL applicative to get round the problem you were describing
19:14:52 <fog> i could be totally wrong here...
19:14:55 <Guest68588> yeah that might help
19:14:57 <fog> :/
19:15:00 <Guest68588> traverse instead of fold
19:16:19 <fog> :t \f -> (fst .) . mapAccumL (\a b -> (f a b,()))
19:16:20 <lambdabot> Traversable t1 => (c -> t2 -> c) -> c -> t1 t2 -> c
19:16:29 <fog> :t foldl
19:16:30 <lambdabot> Foldable t => (b -> a -> b) -> b -> t a -> b
19:16:39 <fog> seems ok
19:17:03 <fog> could be a good thing to benchmark!
19:17:21 <Guest68588> yeah definitely
19:20:39 <fog> if the concern is with building up thunks
19:20:58 <fog> then i guess the applicative of StateL come to the rescue
19:21:00 <fog> basically
19:23:07 <fog> and i guess it should work lazily too
19:23:18 <fog> if the fusion of traverse works as it should
19:23:34 <fog> again, just guessing. probably best to check
19:24:35 <Guest68588> yeah, just find it strange that it could give some benefit over some non-monad/applicative solution
19:24:40 <Guest68588> like there should be an equivalent at least
19:24:59 <fog> hmm
19:25:20 <fog> well, the applicative should be able to merge the thunks using <*>
19:25:24 <fog> :t (<*>)
19:25:26 <lambdabot> Applicative f => f (a -> b) -> f a -> f b
19:25:35 <fog> i think...
19:25:58 <fog> i guess it leverages that somehow
19:26:41 <fog> im not sure if you could expect there to be an equivalent that didnt use that
19:28:13 <fog> any takers on the question of lenses over variants of hetrogenous lists?
19:42:25 <no-n> what library should I use to parse command line arguments?
19:45:15 <dibblego> https://hackage.haskell.org/package/optparse-applicative
19:46:08 <no-n> thanks
19:51:21 <tengrinning10> is there some kind of reverse of $, allowing the logical flow to be left to right? something like https://en.wikipedia.org/wiki/Uniform_Function_Call_Syntax maybe
19:51:37 <dolio> tengrinning10: (&)
19:52:04 <dolio> It's in lens at least. Can't recall if it's defined somewhere less expensive.
19:53:13 <dolio> Apparently it's in Data.Function.
19:54:19 <tengrinning10> dolio: thanks m9 ;)
19:57:10 <justsomeguy> I often find myself writing something like "a |> f = f a" for that.
21:32:45 <grazfather> how do i get cabal (or stack) to install pinned dependencies in a fork? I am just trying to install https://github.com/nh2/hatrace and the config points to a fork of posix-waitpid, but cabal and stack don't seem to respect it
21:42:24 <iqubic> I really wish I could use the haskell megaparsec parser in the Godot open source game engine. IDK if that's even possible, but I want that.
21:57:27 <ja> of course it's possible but bindings are easiest if the types map cleanly to a C abi...
21:58:30 <iqubic> I know.
21:59:30 <iqubic> I mean, this exists: https://hackage.haskell.org/package/godot-haskell
21:59:40 <iqubic> But I have no idea how easy it is to use.
22:28:07 <justin2> :q
22:28:40 <sm[m]> no-n: or cmdargs
23:29:07 --- mode: ChanServ set +o Sigyn
23:38:09 <hs-nub> Is there a haskell resource that's similar to zed shaw's "learn [language] the hard way"?
23:39:32 <Axman6> all methods of learning HAskell are learning HAskell the hard way, so that sounds like a redundant book :)
23:39:44 <Axman6> man, how did I make the same typo twoce
23:39:57 <Cheery> MOnads
23:40:55 <hs-nub> haha Axman6... that is... true :thinking:
23:42:53 <Axman6> MOmoney MOproblems
23:43:15 <iqubic> MOmoney MOproblems MOnads
