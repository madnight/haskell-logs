01:28:12 <kuribas> dminuoso: I am giving up on unbound
01:28:48 <kuribas> dminuoso: it's a hassle to plug it in my language, and the inline substitution looks inefficient.
01:29:09 <kuribas> dminuoso: rather than just creating a new binding everything like here: http://dev.stephendiehl.com/fun/006_hindley_milner.html
01:33:40 <typetetris> What was that extension again, where I  can write function calls in a parameter position to directly work with some part of the data?
01:34:28 <ski> typetetris : `ViewPatterns' ?
01:35:17 <typetetris> ski: Thanks
02:10:58 <infinity0> is there something similar to These but for (Maybe a, Maybe b)? would be nice to have something that's more convenient than having to unwrap twice
02:15:36 <MarcelineVQ> How about (Maybe a, Maybe b) :>
02:16:11 <kuribas> I didn't know there was so much hate for haskell: https://news.ycombinator.com/item?id=23362648
02:17:23 <MarcelineVQ> or ~(Maybe a, Maybe b) to, I think, make it more similar
02:19:23 <infinity0> i mean, i'd prefer a single data type that implemetns bifunctor, so i don't have to fmap-twice
02:19:56 <merijn> kuribas: Dude, HN is one of the objectively worst "communities" when it comes to tech
02:20:31 <kuribas> merijn: but... but... it's called: news.ycombinator.com!
02:20:36 <merijn> kuribas: It's filled with trolls hating on anything non-standard (and trolls hating on everything standard)
02:21:19 <MarcelineVQ> infinity0: (,) implements bifunctor
02:21:26 <kuribas> hmm unfriendly community... I found the haskell community the friendliest.
02:21:33 <kuribas> with only rare exceptions
02:21:37 <infinity0> yes but then i have to fmap again to get at the value inside the Maybe
02:21:42 <merijn> kuribas: It's a propaganda front-end for rich people to convince young tech suckers into thinking that throwing away your carreer to a lottery to make said rich people richer
02:21:59 <kuribas> merijn: which rich people?  Bezos?
02:22:00 <infinity0> i agree, HN is getting crappy and they downvote everything that doesn't fit their precise beliefs
02:22:14 <MarcelineVQ> er, what would your wanted These version look like them?
02:22:15 <MarcelineVQ> *then
02:22:18 <merijn> kuribas: No, Y Combinator's angel investors
02:22:24 <infinity0> MarcelineVQ: Neither | This | That | These
02:24:15 * hackage vector-doublezip 0.1.0.0 - Some special functions to work with Vector (with zip).  https://hackage.haskell.org/package/vector-doublezip-0.1.0.0 (OleksandrZhabenko)
02:25:03 <infinity0> hm, i wished hoogle worked with data definitions
02:25:24 <MarcelineVQ> if you're going to write it yourself Diamond is a neat name
02:26:18 <MarcelineVQ> in fact I'm gona write that down..
02:26:51 <infinity0> i remember some package i saw a few weeks ago that had this, it was theory heavy and had some description linking to a paper with a diagram shaped like a cross
02:26:55 <infinity0> i just can't find it now :(
02:36:41 <infinity0> aha, this one https://hackage.haskell.org/package/smash-0.1.1.0/docs/Data-Smash.html
02:36:45 <infinity0> really unobvious name :(
02:37:05 <infinity0> well, the one i specifically wanted is https://hackage.haskell.org/package/smash-0.1.1.0/docs/Data-Can.html#t:Can
02:56:15 <merijn> bleh
02:56:34 <merijn> The catch of trying to optimise really slow code is that it takes a really long time to run and see if you actually did >.>
03:03:53 <infinity0> regarding speed, have you guys heard of this joke, i read it in one of scott aaronson's papers
03:04:23 <infinity0> in the quantum immortality interpretation, P = NP, the algorithm is simple - choose a random answer, check if it fits. if not, kill yourself
03:04:49 <nil> lol
03:06:32 <merijn> ...
03:06:49 <merijn> Now my profiling build is twice as fast as my non-profiling one >.>
03:12:01 <MarcelineVQ> that's always fun, especially when not only performance changes but crashes dissapear :o
03:12:42 <merijn> MarcelineVQ: After yesterdays "1 TB core dump" debacle I've decided to just no crash anymore :p
03:13:21 <MarcelineVQ> inimino: Diamond is way cooler than Can
03:13:36 <MarcelineVQ> Sure you can make a city out of cans but diamonds can be used to power ice suits
03:15:18 <merijn> MarcelineVQ: I just realised the the profiling config is using GHC 8.10, so I should probably do my baseline with the same compiler >.>
03:15:37 <MarcelineVQ> shucks buster
03:18:00 <merijn> Maybe all my dependencies have been updated and I can just declare 8.10 the only supported version if it's so much faster :>
03:18:51 <MarcelineVQ> shrug off the shackles formed of the detrius of past ages
03:19:15 <merijn> Backwards compat is for people who get paid
03:19:30 <MarcelineVQ> backwards compat is for dentists offices
03:32:01 <GreyFaceNoSpace> hi. i wrote this function. https://pastebin.com/qVKTLvs9 and i want to rewrite is using list comprehension
03:32:51 <GreyFaceNoSpace> [x+y | x<-xs,y<-ys] is obviously wrong since it doesn't add the elements one at a time
03:33:06 <GreyFaceNoSpace> can someone help me understand how to use list comprehension in this case?
03:33:43 <nil> GreyFaceNoSpace: you would have to use zip, although you could just write your entire function using zipWith
03:33:50 <merijn> GreyFaceNoSpace: Well, honestly the first thing that comes to mind is "I wouldn't", the second thing is something silly like "[x+y | (x, y) <- zip xs ys]"
03:34:01 <merijn> But yeah, zipWith is much more logical
03:34:07 <nil> allSums = zipWith (+)
03:34:18 <GreyFaceNoSpace> so its never possible to take one element at a time just with list comprehension?
03:34:43 <merijn> GreyFaceNoSpace: There's an extension that lets you do that, but I wouldn't recommend ever using it, tbh
03:34:46 <nil> hm, maybe using ZippedList and monad comprehensions
03:34:50 <nil> but yeah, overkill
03:35:06 <GreyFaceNoSpace> ok
03:35:15 <GreyFaceNoSpace> it was a question in my exam
03:35:18 <GreyFaceNoSpace> and i couldn't do it
03:35:31 <GreyFaceNoSpace> it specifically mentioned we have to only use list comprehension
03:36:38 <merijn> GreyFaceNoSpace: That's weird
03:37:04 <GreyFaceNoSpace> yeah
03:37:58 <merijn> There's no "standard" way of doing it and also list comprehensions are honestly fairly rarely used in the first place, so I don't really see a point in asking questions about them on an exam
03:38:14 <GreyFaceNoSpace> maybe i misunderstood the question
03:38:32 <GreyFaceNoSpace> merijn, i know. my university is outdated
03:38:49 <merijn> Your initial version does the cartesian product of xs and ys
03:38:50 <GreyFaceNoSpace> merijn, they focus on theory rather than practicality
03:38:59 <GreyFaceNoSpace> merijn, i know
03:39:00 <merijn> Nothing wrong with theory, tbh :p
03:39:36 <GreyFaceNoSpace> merijn, yeah its good....its just that when pointless questions come up. it gets annoying real fast
03:44:45 * hackage hsinspect 0.0.13 - Inspect Haskell source files.  https://hackage.haskell.org/package/hsinspect-0.0.13 (tseenshe)
04:27:23 <jusss> data P = P Int, does this `P Int` has a proper name?
04:27:56 <jusss> 'cause `P Int` is not a type neither a value
04:28:04 <jusss> P 3 :: P
04:28:33 <Cheery> the structure introduces a data constructor P :: Int -> P
04:28:42 <Cheery> and a type P :: *
04:29:15 * hackage ghc-lib-parser 0.20200601 - The GHC API, decoupled from GHC versions  https://hackage.haskell.org/package/ghc-lib-parser-0.20200601 (shayne_fletcher)
04:29:29 <jusss> Cheery: so `P Int` doesn't has a name?
04:29:52 <Cheery> I don't understand what you ask
04:30:13 <jusss> is there a term for the form `P Int`?
04:30:15 * hackage ghc-lib 0.20200601 - The GHC API, decoupled from GHC versions  https://hackage.haskell.org/package/ghc-lib-0.20200601 (shayne_fletcher)
04:30:24 <bor0> `P Int` is a value constructor
04:30:38 <jusss> bor0: P is the value constructor
04:30:46 <jusss> also the type constructor
04:31:01 <bor0> right
04:31:23 <Cheery> it's part of a data declaration.
04:32:07 <jusss> fine, I just give it a name "type notation" for myself
04:33:11 <jusss> is that ok?
04:33:29 <jusss> is there already a term call "type notation"?
04:34:47 <Cheery> constructor specification could be precise term for it.
04:35:09 <Cheery> https://wiki.haskell.org/Type#Data_declarations
04:37:09 <jusss> Cheery: Maybe is a monad, Maybe Int is an action?
04:37:24 <jusss> I'm a little confused
04:37:37 <jusss> function has type * -> *
04:37:52 <jusss> and monad has kind * -> *
04:37:57 <jusss> monoid has kind *
04:38:28 <jusss> IO is an action, IO is a type, IO has kind *
04:38:38 <jusss> no, IO a is a type
04:39:09 <Cheery> It can be confusing. Types are put together from pieces, just like how programs are.
04:39:10 <merijn> jusss: Function does not have kind "* -> *"
04:39:27 <jusss> merijn: but function has type * -> *
04:39:36 <merijn> No
04:39:49 <jusss> merijn: for example?
04:40:09 <Cheery> if you think of (->), it has kind * -> * -> *
04:40:13 <merijn> I think you're mixing up lots of things. To begin with "* -> *" is a kind, not a type.
04:40:14 <Cheery> it takes two types, and constructs a type
04:40:25 <jusss> :t getLine
04:40:26 <lambdabot> IO String
04:40:34 <jusss> getLine is an IO action, right?
04:40:42 <merijn> The kind of the function type is, as Cheery says "* -> * -> *"
04:40:46 <merijn> jusss: Sure
04:41:16 <Cheery> IO has kind * -> *, takes a type, constructs a type.
04:41:46 <Cheery> IO String has kind *, the type has been given to IO
04:42:01 <jusss> :t id
04:42:02 <lambdabot> a -> a
04:42:14 <jusss> id is a function, which type is a -> a, 
04:42:23 <merijn> jusss: Those are two different ->
04:42:23 <jusss> id has kind?
04:42:47 <Cheery> id is a term, it's of type a -> a, which has a kind *
04:43:27 <jusss> getLine is an IO action, it has kind?
04:43:38 <Cheery> getline is a term, with type IO action, has kind *
04:43:45 <Cheery> sorry. IO String
04:44:05 <jusss> so function id, and action getLine both has kind *?
04:44:29 <merijn> values (functions or otherwise) don't have kinds
04:44:30 <Cheery> types are of some kind, and terms are of some type.
04:44:41 <merijn> types have kinds, values have types
04:45:02 <jusss> merijn: id is a function, a value, so id doesn't has kind, right?
04:45:27 <merijn> id doesn't have a kind and neither does getLine or any other value or term
04:45:49 <jusss> I see
04:45:58 <Cheery> you could think that 'id' means nothing without a type.
04:46:05 <Cheery> the type tells what it means.
04:46:25 <Cheery> likewise, kind states that something is to be interpreted as a type.
04:49:15 * hackage ghc-lib-parser-ex 0.20200601 - Algorithms on GHC parse trees  https://hackage.haskell.org/package/ghc-lib-parser-ex-0.20200601 (shayne_fletcher)
04:49:47 <jusss> Just 3 is a action, a value, Just is a function, a value, right?
04:50:11 <Cheery> Just :: a -> Maybe a, yup, it's a function.
04:50:20 <Cheery> it's also a data constructor
04:50:22 <jusss> and both Just 3 and Just don't has kind, but Maybe has kind * -> *, and Maybe Int has kind *
04:50:57 <Cheery> yup. Just 3 is of type (Num a => Maybe a)
04:51:07 <jusss> ok
04:53:59 <Cheery> now, * -> * -> * should be clear what that means, how about (* -> *) -> * ?
04:56:12 <jusss> * -> * -> * is a kind, what about (* -> *) -> *?
04:56:23 <Cheery> it's kind as a well.
04:56:39 <jusss> (* -> *) -> * , monad transformer
04:57:06 <jusss> Cheery: right?
04:57:27 <Cheery> it can be, but it doesn't necessarily transform monads
04:57:34 <jusss> :k WriterT String Identity Int
04:57:36 <lambdabot> *
04:57:59 <jusss> :k WriterT
04:58:00 <Cheery> yup.
04:58:00 <lambdabot> * -> (* -> *) -> * -> *
04:58:02 <Cheery> :k List
04:58:03 <lambdabot> error:
04:58:03 <lambdabot>     • Pattern synonym ‘List’ used as a type
04:58:03 <lambdabot>     • In the type ‘List’
04:58:09 <jusss> :k []
04:58:10 <lambdabot> * -> *
04:58:15 <Cheery> oh right.
04:58:39 <jusss> Cheery: there's no such thing call `List` in haskell, :)
04:59:25 <jusss> that's really confused when I learn monad I was told List is not a monad
04:59:38 <Cheery> list is a monad.
04:59:49 <jusss> :k WriterT String
04:59:50 <lambdabot> (* -> *) -> * -> *
04:59:50 <Cheery> or is it?
05:00:08 <jusss> merijn: list is a monad?
05:00:33 <Cheery> well seems like it is.
05:00:52 <Cheery> :t [1,2] >>= (3:)
05:00:53 <lambdabot> (Num b, Num [b]) => [b]
05:00:56 <jusss> Cheery: yes, monad has kind * -> *
05:01:04 <Cheery> > [1,2] >>= (3:)
05:01:05 <lambdabot>  error:
05:01:05 <lambdabot>      • No instance for (Num [Integer]) arising from a use of ‘e_1123’
05:01:05 <lambdabot>      • In the expression: e_1123
05:01:58 <jusss> monad has kind * -> *, monoid has kind *
05:01:59 <Cheery> > [1,2] >>= \x -> [3+x, 2+x]
05:02:01 <lambdabot>  [4,3,5,4]
05:02:04 <jusss> Maybe is a monad, and Maybe String is a monoid only when String is a monoid
05:02:21 <jusss> [] is a monad, [a] is a monoid
05:02:39 <nil> jusss: well, to be more precise, Monad :: (* -> *) -> Constraint  and  Monoid :: * -> Constraint
05:03:01 <jusss> nil: what is Constraint here?
05:03:17 <nil> which means that when you have instances Monad a and Monoid b, a has kind * -> * and b has kind *, which i assume is what you meant
05:03:29 <nil> jusss: the kind of constraints, i.e. the things you find before =>
05:03:33 <merijn> nil: Honestly, I don't think adding more information is what's necessary here :)
05:03:42 <nil> sorry
05:04:07 <Cheery> just trying to say every * -> * is not a monad
05:04:15 <Cheery> some are.
05:05:07 <jusss> Cheery: what abot a type has kind * -> *, and implement >>= return fmap <*> for it?
05:05:16 <jusss> so it could be a monad?
05:05:31 <Cheery> then it's a monad.
05:05:33 <jusss> <$> <*> >>= and return join?
05:06:30 <nil> >>= and join are redundant (assuming you have fmap)
05:08:39 <jusss> nil: 0 is the unit in (+), 1 is the unit in (*), return is the unit in >>=, they're related to monoid?
05:09:01 <jusss> but Int is not a monoid
05:09:06 <jusss> not a semigroup
05:10:53 <jusss> [] is a monoid, which empty value is []
05:11:33 <Cheery> 0 and (+) form a monoid, likewise, [] and (++) form a monoid.
05:12:26 <jusss> Cheery: return and >>= form a monoid?
05:12:44 <Cheery> to form a monoid, you need an identity element, and an operator, such that the operator is associative, and the identity element can be used to remove and introduce that operator.
05:13:26 <Cheery> eg. (a + b) + c = a + (b + c), and 0 + a = a = a + 0
05:13:58 <jusss> Cheery: then return and >>= don't form a monoid
05:13:59 <Cheery> yeah, return and >>= form a monoid.. though it's easier to show with a variation of >>=
05:14:13 <Cheery> : (>=>)
05:14:15 <Cheery> :t (>=>)
05:14:16 <lambdabot> Monad m => (a -> m b) -> (b -> m c) -> a -> m c
05:14:22 <Cheery> :t return
05:14:23 <lambdabot> Monad m => a -> m a
05:14:46 <jusss> because a >>= b >>=c /= a >>= (b >>= c)
05:14:54 <Cheery> (return >=> a) = a
05:16:12 <jusss> Cheery: but >>= has associative? I forget that
05:16:24 <jusss> there're three laws for monad
05:16:44 <jusss> Identity, left associative and right associative, but I forget 
05:16:47 <jusss> what they're
05:17:38 <jusss> monoid has that three laws?
05:18:23 <Cheery> left identity, right identity, associative
05:19:00 <jusss> associative, (f . g) . h = f . (g . h)
05:19:32 <jusss> but (a >>= b) >>= c   /=    a >>= (b >>= c)
05:19:52 <jusss> (a >>= b) >>= c     =     a >>= (b >=> c)
05:20:19 <jusss> where is wrong?
05:24:13 <Cheery> not wrong technically, it's just that associativity of kleene arrow "mapped" into bind.
05:24:22 <seanparsons> I'm using `source-repository-package` in a `cabal.project` of one project, but I'm a bit bemused by how to reference another multi-project (one with `cabal.project` with a bunch of projects in it) with it.
05:24:40 <seanparsons> Without using `subdir`, cabal seems to deny anything in there exists.
05:25:10 <Cheery> ah not kleene, I forgot what it's called.
05:25:41 <merijn> seanparsons: Just list it multiple times with different subdirs for each package
05:25:43 <Cheery> kleisli arrow
05:26:10 <jusss> Cheery: aha, what is kleisli arrow?
05:26:25 <jusss> that fish operator >=> is kleisli composition?
05:27:10 <Cheery> yup.
05:27:25 <seanparsons> merijn: That doesn't seem to work either. Like I've added `subdir: semantic-typescript`, but I get: `[__1] unknown package: semantic-tags (dependency of semantic-typescript)`.
05:27:45 <merijn> seanparsons: Well, where is semantic-tags supposed to be?
05:28:03 <jusss> Cheery: I still don't understand what's wrong with >>='s associtivy
05:28:23 <Cheery> the >>= is not symmetric operator, so the associativity rules end up being a bit tilted.
05:28:23 <seanparsons> merijn: It's a sibling folder of `semantic-typescript` (which I've also specified with a subdir).
05:28:28 <jusss> a + b + c = a + (b + c)
05:28:32 <Cheery> it's a fine operator otherwise.
05:28:38 <jusss> a * b * c = a * (b * c)
05:28:45 <merijn> seanparsons: You need a source-repository-package entry for each of the package in the external repo (there's an issue to add a "subdirs" thing allowing multiple in one source-repository-package, but it's not there yet)
05:29:51 <seanparsons> merijn: Hmmm, multiple `subdir` entries works for something else, albeit those are individual projects, not one under a `cabal.project` "bundle".
05:30:17 <merijn> Adding a SPECIALIZE pragma should get me the same results as changing the type of my function, right?
05:30:21 <jusss> Cheery: err... that doesn't convince me...
05:30:42 <merijn> seanparsons: The remote repo having a cabal.project is irrelevant as it's not looked at
05:31:01 <kuribas> merijn: you also get a more general function
05:31:04 <bifunc2> If I already have a Foo (an instance of Storable) on the Haskell heap, is there a way to  pass  this Foo into a c_foreign_function :: Ptr Foo -> IO () without first doing an extra malloc?
05:31:26 <bifunc2> It's pity I have to do extra malloc just to get the pointer
05:31:39 <kuribas> merijn: which can be eliminated if not needed, but it's more work for the compiler
05:31:45 <Cheery> jusss: (a >=> (b >=> c)) = ((a >=> b) >=> c)
05:32:06 <Cheery> likewise (return >=> a) = a = (a >=> return)
05:32:12 <merijn> kuribas: Sure, that's obvious, I'm just wondering because I have some functions that are general because their types are a counter-intuitive
05:32:26 <jusss> Cheery: but monad ask `>>=` not `>=>`
05:32:46 <kuribas> merijn: you mean making them general makes testing easier?
05:32:49 <merijn> kuribas: I'm seeing lots of >>= and co in my profile though, so I was hoping specialising would collapse those away, I'm just wondering whether I should not bother and instead fix the actual types
05:33:00 <Cheery> (>=>) is of form (a -> m b) -> (b -> m c) -> (a -> m c)
05:33:04 <merijn> bifunc2: Not really
05:33:10 <seanparsons> merijn: How weird, thanks for that, it appears to have unblocked me.
05:33:15 <Cheery> (>>=) of form (m a) -> (a -> m b) -> m b
05:33:24 <merijn> bifunc2: The problem is that GHC uses a moving GC, so that heap object might get moved while the C code runs
05:33:25 <kuribas> merijn: sometimes I write my helper functions more general to make testing them easier, and also to catch errors.
05:33:45 <merijn> bifunc2: There's things like alloca which give you a temporary allocation for foreign calls
05:35:00 <Cheery> jusss: they are same thing described in slightly different way.
05:35:52 <bifunc2> merijn yeah, so i kind of have to alloca, poke into it, and then call the c func?
05:40:52 <jusss> Cheery: so return and >=> can form a monoid, return and >>= can form a monoid?
05:41:55 <Cheery> I'm not sure if >>= forms a monoid. but the laws come from tehre.
05:42:08 <Cheery> (return x >>= f) = f x
05:42:26 <Cheery> (return >=> f) = f
05:42:49 <Cheery> (m >>= return) = m
05:43:15 <Cheery> associativity has a similar "tilt" in it.
05:45:12 <Cheery> ((f >>= g) >>= h) = (f >>= (\x -> g x >>= h))
05:45:50 <Cheery> ((a >=> b) >=> c) = (a >=> (b >=> c))
05:49:02 <jusss> Cheery: ok
05:58:45 <seanparsons> merijn: Definitely feels like I'm doing the wrong thing as the `cabal.project` file for that repo also specifies some `source-repository-package` entries.
05:58:54 <seanparsons> So I've had to copy those over. :/
06:03:23 <siers> are functions, lenses and json codecs profunctors? (because the two latter are essentially holding a function inside)
06:12:45 * hackage tdlib-gen 0.1.0 - Codegen for TDLib  https://hackage.haskell.org/package/tdlib-gen-0.1.0 (Poscat)
06:45:38 <merijn> bifunc2: I don't remember of the top of my head, but Foreign.Marshall has a whole bunch of utility helpers
06:51:15 <chloekek_> I always wondered how to nicely combine (=<<) and ($), e.g. f =<< (g $ h x). It just occurred to me! f <=< g $ h x.
06:51:19 <merijn> seanparsons: cabal.project isn't really intended to serve as final configuration of dependencies. It's to locally override stuff while developing a package (such as working on a version that's using still unreleased dependencies). If you start having super elaborate complex setups there I'd start to question your setup
06:52:50 <seanparsons> merijn: That's I guess my question, is there an alternative? It's an unreleased package which is somewhat forcing my arm.
06:53:16 <merijn> seanparsons: Why is it unreleased? Is it just not ready yet or what?
06:53:32 <merijn> Or is it like an internal company package/etc.
06:53:48 <seanparsons> Well you'd have to ask Github why it's not ready. :)
06:54:53 <john20> Hi All, I'm trying to parse a csv file where some of the records may contain errors.e.g. "null" instead of numeric value.  Currently I'm using ghc generics to make my Object an instance of FromRecord, and then just caling ```toList $ (decode HasHeader bs)```
06:56:00 <john20> Is there a way to get a `[Either String Obj]` instead of getting a `Either String [Obj]` ?
06:56:07 <merijn> seanparsons: ah, then I think you're stuck copying the cabal.project setup for now
07:00:10 <john20> I've tried to implement my own FromRecord instance, but ghc doesn't seem to like it `instance FromRecord (Either String Obj) where `...
07:06:27 <bifunc2> merijn thanks there is a "with" function in there that does exactly what i need :)
07:12:32 <[exa]> john20: what's the precise error?
07:19:11 <john20> Hi [exa] the error is:
07:19:18 <john20> `    • Illegal instance declaration for
07:19:19 <john20> In the instance declaration for
07:20:38 <infinity0> chloekek_: i wrote https://hackage.haskell.org/package/op a while back, you could also write it as h x |> g >>= f or even x |> h |> g >>= f if it suits (e.g. if h is a complex expression)
07:20:56 <chloekek_> Cool!
07:30:14 <tomsmeding> john20: maybe ghc wants you to enable an extension before you can create that instance? something like FlexibleInstances IIRC
07:30:54 <tomsmeding> or if you want to stay in vanilla haskell, make a `newtype MyThing = MyThing (Either String Obj)` and then write an `instance FromRecord MyThing where ...`
07:31:26 <tomsmeding> not familiar with whatever library you're using, so I'm just responding to the "Illegal instance declaration" error :)
07:39:01 <john20> Thanks tomsmeding. Adding FlexibleInstances does resolve the error, but I'm not sure why I need it
07:39:38 <tomsmeding> the error you got should kind of explain why you need the extension to write that instance
07:39:56 <tomsmeding> though GHC errors are not always very clear, especially if you're not intimately familiar with the compiler and the language :p
07:40:12 <c_wraith> FlexibleInstances is for when you have an instance that looks like "instance Foo (Bar Baz) where ..." instead of "instance Foo (Bar a) where ..."
07:41:08 <tomsmeding> the error says 'All instance types must be of the form (T a1 ... an) where a1 ... an are distinct type variables'
07:41:20 <tomsmeding> that restriction is (partially) lifted with FlexibleInstances
07:41:38 <tomsmeding> 'String' is not a type variable, it's a type :)
07:41:39 <john20> ah. Thanks. That explains it. The newtype suggestion was also very helpful. I'm taking that path now.
07:41:51 <tomsmeding> newtype is what you """should""" do
07:42:14 <tomsmeding> some think it's neater :)
07:48:57 <john20> Thanks all. Just read the FlexibleInstances page, and was a bit surprised to see that stuff like `instance C (Maybe Int) ` isn't allowed by default. Does anyone know the reasoning behind that choice?
07:49:23 <john20> Here's the page - https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#extension-FlexibleInstances
07:49:45 * hackage cas-store 1.1.0 - A content-addressed storage  https://hackage.haskell.org/package/cas-store-1.1.0 (YvesPares)
07:53:56 <tomsmeding> I believe that a "flexible instance" (if I may call something like `instance C (Maybe Int)` that) does not play as nicely with haskell's type inference rules
07:55:04 <tomsmeding> e.g. if you have a polymorphic function `f :: Maybe a -> Maybe a`, and you pass it a Maybe Int, then you could reasonably expect `f` to be able to use your `C` instance for Maybe Int
07:55:08 <tomsmeding> except that of course doesn't work
07:56:09 <tomsmeding> I'm not sure whether there is a good explanation for whether they made the choice to _not_ support it in Haskell2010; perhaps it's more like "it's more difficult to implement, and it can be worked around with newtypes quite elegantly, so why would we?"
07:56:20 <tomsmeding> "why yes" instead of "why not"
07:56:28 <tomsmeding> but maybe someone else has more inside knowledge :p
08:05:38 <reirob> Hello #haskell
08:06:02 <reirob> I would like to get some help if possible
08:06:57 <reirob> I have changed to NixOS and there I started to convert my Haskell code to be build with nix
08:07:34 <reirob> It worked for some of my code but for a program that depends on the Pinchot package I got stack
08:07:40 <reirob> ... I got stuck
08:08:24 <reirob> Pinchot depends on Earley, but in the meantime Earley evolved and Pinchot does not build anymore
08:09:15 <reirob> Can anybody give me an advice what would be the best route to go
08:09:29 <reirob> ?
08:12:38 <Boarders__> does anyone know the furthest along attempt in Haskell to do neural networks on gpu?
08:12:54 <Boarders__> I don't know what ever became of adding ad to accelerate or if people are using something else?
08:14:59 <ja> reirob: build the old version of earley that pinchot needs?
08:15:25 <tomsmeding> Boarders__: I'm a master's student in Utrecht, NL, and my project is about adding AD to accelerate
08:15:39 <Boarders__> ah very cool
08:15:41 <tomsmeding> early in the project still, but it might work to some degree a few months from now :p
08:15:53 <tomsmeding> funny to see you talk about it here
08:16:04 <Boarders__> will it include reverse mode as well, or is the plan to start with forward mode?
08:16:12 <reirob> @ja, yes I tried this road, but then cabal complains that it needs an older base
08:16:12 <lambdabot> https://wiki.haskell.org/FAQ
08:16:20 <tomsmeding> forward mode is fairly easy to do even without modifying accelerate proper
08:16:23 <tomsmeding> the aim is reverse mode
08:16:30 <tomsmeding> also because that's far more useful :p
08:16:41 <tomsmeding> unclear how many language structures will be supported in the end though
08:16:54 <Boarders__> cool
08:16:57 <reirob> @ja: base >=4.6 && <4.10
08:16:57 <lambdabot> https://wiki.haskell.org/FAQ
08:17:11 <Boarders__> I've heard forward mode is actually quite useful so long as you have a fairly sparse problem
08:17:18 <Boarders__> and support for sparse matrices
08:17:30 <reirob> @ja: so I am a bit overwhelmed about what to do
08:17:30 <lambdabot> https://wiki.haskell.org/FAQ
08:17:34 <tomsmeding> forward mode is useful if the number of inputs to your function is around the same as, or more than, the number of outputs
08:17:59 <tomsmeding> reverse mode if you have more outputs than inputs, which is usually the case if you want to use AD (though not always)
08:18:04 <Boarders__> even if the number of inputs is larger than the number of outputs it can _still_ be useful if your network is fairly sparse
08:18:57 <tomsmeding> well for forward mode, you basically have to re-evaluate the function for every output variable you want to differentiate with respect to
08:19:06 <tomsmeding> you can vectorise that of course, but that's the complexity
08:19:18 <tomsmeding> if a function evaluation is cheap, then perhaps forward is cool, because forward also has very low overhead
08:20:51 <tomsmeding> Boarders__: for my information, where would you look for an announcement regarding AD in accelerate? (assuming of course that it's going to work out :p)
08:21:26 <Boarders__> I think it would be useful to have on the haskell mailing list but also on a separate hackage repo called something like accelerate-ad
08:21:34 <Boarders__> since realistically I would search for something like that
08:21:58 <tomsmeding> I'm unsure whether it's going to be a separate package, though possibly some supporting routines might be separate
08:22:33 <tomsmeding> implementing reverse AD might need to go deep in the innards of accelerate, which basically means you get it in the 'accelerate' package for free :p
08:22:45 <tomsmeding> but that's looking into the future
08:23:10 <Boarders__> ah ok!
08:23:22 <Boarders__> it would be very nice if you had a teeny example of a neural network with it too!
08:23:30 <tomsmeding> yes it would be, wouldn't it? :)
08:23:42 <Boarders__> I guess the best thing is announcing the new version of accelerate with this support in it
08:23:44 <tomsmeding> I'll be sure to write it down for if there's something to announce later :)
08:23:49 <tomsmeding> right
08:24:11 <tomsmeding> then if you're interested in following accelerate, you'll pick it up
08:25:23 <Boarders__> sounds fantastic, I think this will be an amazing addition to the haskell ecosystem
08:25:44 <tomsmeding> I hope so too :)
08:36:52 <kuribas> Which one is more general, (String -> Int), or Num a => String -> a?
08:37:22 <kuribas> which one subsumes which?
08:39:27 <hyperisco> Num a => String -> a  specialises to  String -> Int
08:40:00 <kuribas> but the first one is more applicableN
08:40:01 <solonarv> by "more general" do you mean to also allow conversions like fromIntegral etc ?
08:40:02 <kuribas> ?
08:40:10 <aodhneine> hey #haskell <3
08:40:15 <hyperisco> What does more applicable mean?
08:40:37 <hyperisco> The second can become the first, so whatever applicability the first has the second also does.
08:40:51 <solonarv> they are (almost) equally general
08:41:05 <dolio> `Num a => String -> a` is more general.
08:41:19 <solonarv> 'String -> Int' is a substitution instance of 'forall a. Num a => String -> a', and you can go the other way by tacking on 'fromIntegral'
08:41:35 <hyperisco> :t fromIntegral
08:41:36 <lambdabot> (Integral a, Num b) => a -> b
08:42:05 <hyperisco> Well, from a type standpoint, yes…
08:42:14 <solonarv> :t let f = undefined :: String -> Int in fromIntegral . f
08:42:16 <lambdabot> Num c => String -> c
08:42:37 <solonarv> there is still a slight difference if you expect values outside the range of 'Int' to exist
08:44:17 <dolio> I'm pretty sure this is a question about type checking.
08:44:27 <kuribas> dolio: yeah :)
08:44:46 <hyperisco> :t const 0
08:44:47 <lambdabot> Num a => b -> a
08:44:52 <hyperisco> such generality
08:45:18 <hyperisco> I presumed we were talking about a functional difference
08:47:10 <hyperisco> Assuming  (f :: String -> Int) = (g :: Num a => String -> a) @Int  then g is more general
08:48:01 <kuribas> To check if (f :: a -> b), f can be a -> c, if b is more general than c, or d -> b if d is less general then a right?
08:48:50 <dolio> Yeah.
08:49:38 <solonarv> I would say that a type A is more general than a type B if there exists a surjective 'specialize :: A -> B'
08:49:58 <dolio> kuribas: If you want to do that, though, you have to take quantifiers seriously.
08:50:05 <solonarv> perhaps with some added stipulation about being obvious or not horribly convoluted
08:50:27 <kuribas> dolio: yeah
08:50:32 <hyperisco> here comes homotopy
08:50:42 * solonarv waves hands furiously
08:50:54 <dolio> Like, if you just have `(Num b => String -> b) -> Double`, you can't just pull out the `Num b => String -> b` and check if it's more general.
08:52:45 <kuribas> more general than what?
08:53:11 <Ariakenom> Boarders__, not haskell but some pure fp ad on gpu. https://github.com/zfnmxt/futhark-forwards-ad ping Athas 
08:53:24 <Boarders__> I saw this, it is very cool
08:53:30 <dolio> Something else. The point is that the variable in that type isn't quantified in that particular part.
08:54:17 <dolio> So, really, the technically correct answer is that `forall b. Num b => String -> b` is more general than `String -> Int`.
08:54:50 <Boarders__> related to this: why can't you use a type application on something of type forall b . Num b?
08:55:09 <Boarders__> e.g. if you had f :: forall b . Num b => String -> b then you can't do (f "hello") @Int
08:55:11 <Boarders__> why is that?
08:55:14 <kuribas> Boarders__: because it already has a type?
08:55:25 <Ariakenom> there is a #futhark channel if you want to dig in
08:55:31 <dolio> Boarders__: The type argument comes first.
08:56:15 <Boarders__> sorry could either of you explain?
08:56:16 <dolio> And once you apply and re-generalize, the variables can end up in an unpredictable order in general, so GHC doesn't allow you to use explicit applications for those.
08:56:32 <Boarders__> ok but what about 0 @Int?
08:56:48 <dolio> I think they only work with explicitly given types, which guarantees that the type arguments occur in a particular order.
08:56:56 <Boarders__> because ghci tells me the type of (f "hi") is forall a . Num a => a
08:57:22 <kuribas> > 0 @Int
08:57:24 <dolio> Something like 0 is probably special cased to have a nice type.
08:57:24 <lambdabot>  <hint>:1:3: error: parse error on input ‘@’
08:57:32 <kuribas> Boarders__: that syntax isn't allowed.
08:57:39 <Boarders__> :t 0
08:57:40 <lambdabot> Num p => p
08:57:41 <kuribas> > fromIntegral @Int 0
08:57:43 <lambdabot>  error:
08:57:43 <lambdabot>      Pattern syntax in expression context: fromIntegral@Int
08:57:43 <lambdabot>      Did you mean to enable TypeApplications?
08:57:55 <hyperisco> > (0) @Int
08:57:57 <lambdabot>  <hint>:1:5: error: parse error on input ‘@’
08:58:17 <hyperisco> > id @Int 0
08:58:19 <lambdabot>  error:
08:58:19 <lambdabot>      Pattern syntax in expression context: id@Int
08:58:19 <lambdabot>      Did you mean to enable TypeApplications?
08:58:20 <dolio> Oh yeah, 0 @Int actually doesn't work.
08:58:28 <dolio> Even with TypeApplications.
08:58:34 <kuribas> Boarders__: you can put an explicit fromIntegral there.  But then you could just do (0 :: Int) :-)
08:58:46 <hyperisco> I wonder what dark corners of the parser are responsible for that
08:59:06 <Ariakenom> % (0 :: forall a. Num a => a) @Int
08:59:06 <yahb> Ariakenom: 0
08:59:08 <dolio> It's not a parser issue, I think.
08:59:19 <Ariakenom> :]
08:59:23 <Boarders__> well I am not confused about how to tell ghc I want a 0 of type Int, I am asking about type applications :p
08:59:38 <dolio> It's the same 'undetermined variable order' thing, I think.
08:59:48 <dolio> Even though in this particular case there's only one variable.
09:00:09 <kuribas> dolio: so wether something is in the input or output of a function, doesn't have an effect on the generalness of functions?
09:00:55 <hyperisco> well, I guess  id @Int 0  is fine for dependent Haskell preparedness
09:00:59 <Boarders__> oh, I think it is because if you don't provide a type sig then GHC just never let's you do type applications
09:01:14 <dolio> Boarders__: Right.
09:01:30 <Boarders__> ok, got it
09:01:43 <dolio> kuribas: `forall a. T` is more general than `T[a := U]`, regardless of where `a` occurs in `T`.
09:02:05 <kuribas> right
09:03:36 <dolio> But generality works like subtyping with respect to function variance.
09:04:08 <dolio> So, `(S -> T) <= (U -> V)` iff `U <= S` and `T <= V`
09:09:28 <kuribas> dolio: ah right, because the quantifier is inside the subterm
09:10:05 <Boarders__> so is () -> forall b . b more general than (forall u . u) -> (forall  b . b)?
09:10:19 <kuribas> Int -> String <= (forall a.Num a) -> String 
09:11:09 <kuribas> but I suppose that's illegal in haskell
09:11:39 <kuribas> (Int -> Int) -> String <= (forall a.Num a => a -> a) -> String 
09:13:23 <kuribas> Boarders__: yes
09:13:33 <kuribas> Boarders__: it's also illegal AFAIK
09:13:37 <kuribas> impredicative polymorphism
09:15:34 <chloekek_> No should be fine
09:15:47 <chloekek_> The forall can be shifted all the way to the left
09:16:08 <chloekek_> But not with e.g. () -> (forall b. F b)
09:19:08 <chloekek_> Depending on F i guess
09:21:24 <chloekek_> Not with () -> F (forall b. b)
09:22:12 <dolio> That's not actually what GHC considers impredicative.
09:22:47 <dolio> And you should be able to do that, although they're actually removing the ability to bring back impredicativity, I think.
09:23:32 <dolio> That was poorly phrased, I guess. They're removing the subtyping, and one of the effects is that it makes impredicative stuff more feasible.
09:57:51 <safinaskar> % (\x :: Int -> x + 1) 1
09:57:51 <yahb> safinaskar: ; <interactive>:38:5: error: parse error on input `::'
09:58:59 <wavemode> % (\(x :: Int) -> x + 1) 1
09:58:59 <yahb> wavemode: 2
09:59:25 <safinaskar> wavemode: thanks
10:11:33 <Boarders__> neil mitchell mentioned a trick on twitter where you replace const with \a _ -> (# a #) to ensure that the ignored argument is thrown away, why does that work?
10:15:34 <dsal> What does "thrown away" mean here?
10:16:42 <Boarders__> here is the relevant tweet: https://twitter.com/ndm_haskell/status/1267222669461794817?s=20
10:16:52 <Boarders__> I believe it means, it is not retained by the GC
10:17:15 <Boarders__> the point being that previously all of these values were being held onto because const was not being applied
10:17:32 <dolio> It's being applied but not reduced.
10:18:21 <Boarders__> yes, that is a better wording of what I meant to say
10:19:12 <dolio> In `let x = const a b in ...` x is a closure that points to both `a` and `b` until reduced.
10:19:42 <xsperry> this is weird.. I'm getting different parsing results depending if <|> is idented the same as the prior block, vs if I indent it one or more spaces deeper. but I can't replicate it in a test case
10:19:47 <dolio> But you may not want to evaluate x immediately to stop it from pointing to `a`.
10:20:49 <dolio> (# a #) is something you can demand without demanding the interior value.
10:23:45 * hackage base64-bytes 0.1.0.0 - Base64 encoding of byte sequences  https://hackage.haskell.org/package/base64-bytes-0.1.0.0 (andrewthad)
10:24:18 <Boarders__> dolio: what is let x = \ a _ -> (# a #) in ... doing instead?
10:24:27 <Boarders__> sorry if this is very thick-headed
10:24:59 <monochrom> xsperry: If do-notation is involved, layout changes grouping, watch out for that.
10:25:19 <Boarders__> as in, is that also not allocating a closure?
10:28:37 <EvanR> for one thing b doesn't even exist
10:28:58 <zfnmxt> Ariakenom: Boarders__ The ad stuff will get a lot cooler shortly :) 
10:30:53 <andyyyy_> Q: with the type: newtype Parser a = P (String -> [(a, String)]), as a monad, and given item is a parser, I don't get how the expression `x <- item` unwraps to `a`. I would expect [(a, String)] unwraps to (a,String) - what am I missing here? 
10:31:15 * hackage dobutokO-poetry 0.1.0.0 - Helps to order the 7 or less Ukrainian words to obtain somewhat suitable for poetry or music text  https://hackage.haskell.org/package/dobutokO-poetry-0.1.0.0 (OleksandrZhabenko)
10:31:34 <dolio> Boarders__: It returns an unboxed single containing `a`.
10:31:52 <dolio> And you must match on the result after calling the function.
10:32:22 <Boarders__> andyyyy_: if I have _any_ monad and I am in a do block where I have something of the form: f :: m a and I do: value <- f then within that scope f has type a
10:32:37 <dminuoso> andyyyy_: "unwraps" is a misleading idea.
10:32:53 <Boarders__> sorry within that scope value has type a*
10:32:58 <dminuoso> andyyyy_: Do you know how do-notation desugars into uses of >> and >>= ?
10:33:27 <andyyyy_> Yes, but it totally threw me off when the type is a function
10:33:57 <Boarders__> item >>= \x -> more stuff
10:34:00 <zfnmxt> Look at the instance of (>>=) for the type.
10:34:03 <Boarders__> x has type a
10:34:05 <dminuoso> Let's for the sake of discussion assume it desugars into `parserThen :: Paser a -> Parser b -> Parser b` and `parserBind :: Parser a -> (a -> Parser b) -> Parser b`
10:34:26 <wavemode> andyyyy_: can you provide a complete code example which you find confusing. then we can be more specific
10:34:55 <Boarders__> dolio: interesting, thank you. So I take it such a lambda doesn't allocate a closure any more and instead is like directly parsing a reference to whatever is inside the unboxed tuple?
10:35:27 <wavemode> if doesn't allocate a closure only if it gets inlined
10:37:47 <dolio> Boarders__: The lambda isn't allocating the closure. It's `let x = ... in ...` that is allocating a closure.
10:38:11 <dolio> But unboxed singles must be used like `case ... of (# x #) -> ...`
10:38:18 <dolio> Which does not allocate a closure.
10:38:35 <Boarders__> ah ok, I understand now. Thank you for patiently explaining!
10:38:42 <dolio> No problem.
10:42:43 <Boarders__> it is somewhat similar to the strict identity monad (as mentioned in the comments on the issue)
10:47:15 * hackage yaya 0.3.2.0 - Total recursion schemes.  https://hackage.haskell.org/package/yaya-0.3.2.0 (sellout)
10:48:32 <monochrom> This is why my IO tutorial states its prerequisite as "you have to be OK with types that look like F X -> (X -> F Y) -> F Y". You must not be thrown off by the function parameter X -> F Y there. Or else you are simply not ready.
10:49:27 <monochrom> But if you have done callback-based programming, that's exactly it. bind wants a callback parameter.
10:50:02 <monochrom> The logical conclusion is that node.js beginners are more advanced than IO/Parser beginners. :)
10:50:17 <andyyyy_> wavemode: Here is a minimal example that tries to show my confusion http://termbin.com/lciq
10:51:41 <monochrom> Yeah, please refer to "a >>= f = P \s -> case ...".
10:51:43 <andyyyy_> dminuoso: thanks for clearing up the "unwraps" idea
10:52:02 <monochrom> You are look at:
10:52:31 <monochrom> @undo do { x <- item; item; z <- item; return (x,z) }
10:52:31 <lambdabot> item >>= \ x -> item >> item >>= \ z -> return (x, z)
10:53:10 <monochrom> There is no unwrapping. However, "\x -> ..." is a callback given to >>=.
10:54:10 <monochrom> Also please try your hand at writing the Functor instance first. That's a better starting point.
10:54:56 <wavemode> andyyyy_, as for the question of "what decides the type of x?",  in any do block for a monad m, where `item` has type `m a`, then after `x <- item` , x will have the type `a` . Here, the m is Parser and the a is Char
10:55:43 <andyyyy_> wavemode: that clears it up, thank you
11:02:02 <Ariakenom> zfnmxt, oh you're here cool! Oh taht sounds good :D
11:04:45 * hackage mmsyn6ukr 0.7.3.0 - A musical instrument synthesizer or a tool for Ukrainian language listening  https://hackage.haskell.org/package/mmsyn6ukr-0.7.3.0 (OleksandrZhabenko)
11:09:29 <tomsmeding> zfnmxt: I have to say the commit messages in your futhark-forwards-ad repository are very enlightening
11:23:13 <amf> in https://mmhaskell.com/blog/2020/5/18/refactored-gameplay what is the `type Observation m :: *` and what's the use case?
11:24:06 <monochrom> look up "associated type family"
11:27:14 <amf> ahh, so a way to further refine that this general thing can look like this less general thing. i'm assuming this aids in the compiler being able to figure out complex types and better error messages
11:31:34 <dminuoso> andyyyy_: I think much of the "box" and "unwrap" notion that some learning resources teach is a big red herring.
11:32:06 <monochrom> "big red herring" is too kind. I say they are not even wrong.
11:34:03 <monochrom> However, the notion can also be independently thought up. Desperation for oversimplification inspired creative lies.
11:34:21 <monochrom> s/inspired/inspires/
11:35:30 <dminuoso> If the oversimplification holds for some non-trivial case it's a great start, but the "box/unwrap" idea only works for Identity, which is about the worst example to pick.
11:36:04 <dminuoso> (But then it becomes really hard to explain why you'd ever want >>= for Identity)
11:36:45 * hackage dobutokO-poetry 0.2.0.0 - Helps to order the 7 or less Ukrainian words to obtain somewhat suitable for poetry or music text  https://hackage.haskell.org/package/dobutokO-poetry-0.2.0.0 (OleksandrZhabenko)
11:36:59 <monochrom> If a model holds for a few non-trival cases, I wouldn't be using the word "oversimplification". :)
11:38:49 <zfnmxt> tomsmeding: :D
11:39:23 <dminuoso> amf: think of associated type families as being an alternative to functional dependencies.
11:39:50 <dminuoso> (With different ergonomics)
11:45:15 <sfogarty> Is there a call graph generator for haskellsrc / Language.Haskell? We can write our own, but it seems like the sort of thing that would already exist.
11:48:25 <slack1256> sfogarty: I also need this
11:48:58 <andyyyy_> dminuoso: yea it's what caused all my confusion
11:49:36 <dolio> monochrom: That's why I don't believe people who say that the concepts used in functional programming are too hard for most programmers. People have been writing manual continuation passing in JS for years.
11:49:53 <monochrom> :)
11:50:22 <sfogarty> slack1256: The closest I found was sourcegraph, which at least builds on top of haskell src exts.
11:51:34 <monochrom> I think it's universally hard. But people are brave and call it out, or afraid and suck it up, based on peer pressure.
11:52:39 <sfogarty> slack1256: but I can't tell if it handles sub-functions or not, which is a thing we need.
11:53:43 <dolio> Yeah, it's not that it isn't hard. It's that people are more willing to work through it in different situations.
11:55:45 * hackage yesod-test 1.6.9.1 - integration testing for WAI/Yesod Applications  https://hackage.haskell.org/package/yesod-test-1.6.9.1 (MaxGabriel)
11:56:46 <EvanR> people say functional programming is hard and then i see the state of build systems across the board
11:56:59 <EvanR> can people please say that's hard
11:59:11 <koala_man> I say that a few times a week, yes
12:00:13 <Lycurgus> tedious masquerades as hard a lot
12:00:33 <monochrom> Sometimes people have an abundance of sample code from the Internet to cargo-cult from. Then they don't feel it hard.
12:00:38 <EvanR> i was just fixing a broken build involving autogenerated perl
12:01:15 <EvanR> autogenerated perl to generate C
12:01:21 <Lycurgus> biggest build i ever worked with was a branded mozilla 
12:01:29 <Lycurgus> it's bigger than linux kernel
12:01:37 <Lycurgus> or it was then
12:02:05 <Lycurgus> on two platforms (dos,mac)
12:02:18 <maerwald> EvanR: do you think shake is easy?
12:02:41 <EvanR> i've never used shake
12:02:51 <maerwald> I haven't made up my mind about it yet.
12:03:08 <Lycurgus> but tedious, unwieldy and hard are different in my estimation
12:03:41 <maerwald> Not sure, those are all things that raise my blood pressure. I only measure my blood pressure.
12:03:46 <monochrom> My simple false dichotomy is sane vs crazy :)
12:04:03 <EvanR> in my case, it's hard because i am presented with 19 technologies in my face which directly interfaces with stuff i don't know yet and would have to learn
12:04:53 <EvanR> and they taunt me for good measure with 19 brochures which all say "this is next generation tech that improves your life and speeds up development"
12:05:00 <maerwald> The goal is to lower blood pressure while coding.
12:05:24 <maerwald> Maybe that's the only reason I do haskell
12:05:36 <Lycurgus> there's a reason the average IT worker burnout is so low in comparision with other fields
12:05:38 <monochrom> :)
12:05:50 <EvanR> i can be on board with that. Haskell is like therapy
12:05:56 <Lycurgus> or high rather, meant retention
12:06:33 <Lycurgus> resulting in the perpetual neotony of the workforce, although the capitalism is ofc the underlying reason
12:07:32 <maerwald> Capitalism thrives with high rotation of workforce. The problem is, in engineering, that's really bad.
12:08:14 <maerwald> I'm pretty sure that's one of the reasons of high burnout and high suicide rate in software engineering.
12:08:30 <Lycurgus> well actually it thrives period, other factors being the same, it prefers to retain at constant wage
12:09:01 <Lycurgus> the churn happens involuntarily and not uniformly everwhere but it is ofc pervasive
12:10:53 <Lycurgus> the capitalism certainly thrives in hs shops
12:11:27 <Lycurgus> making somekina point about technical elites
12:11:46 <EvanR> nothing wrong with making a lota money
12:12:02 <EvanR> hypothetically
12:12:07 <Lycurgus> attestation #1, can I get a second?
12:12:30 <maerwald> Money is only good for buying back time :) 
12:12:43 <EvanR> time is overrated
12:13:34 <Lycurgus> it's just one thing after another
12:13:49 <Lycurgus> which is why backward in it is senseless
12:14:01 <Lycurgus> except in the mind
12:18:57 <pie_> ocharles: I found an old SO question from you about database design stuff, do you hae any reading recommendations on SQL?
12:19:31 <pie_> ocharles: i started with http://gen.lib.rus.ec/book/index.php?md5=21F80D8B3D35FCF44C75EEF03E6BE70C on the recommendation of a friend
12:19:46 <ocharles> pie_: I can't recommend much but anything by Chris Date is worth it
12:20:04 <ocharles> Oh, Pascal is worth a read too, for sure
12:20:10 * Lycurgus recommends joe celkos 'sql for smarties' books
12:20:18 <pie_> ocharles: its kind of frustrating to read tbh
12:20:42 <pie_> i know almost nothing about sql except for some simple tutorials i ground through and peole are telling me the theoretical situation hasnt improved much
12:21:05 <pie_> this performancedba guy on stackoverflow seems very good at what he does though
12:21:20 <ocharles> Yea, I can't really suggest any one good source
12:21:27 <ocharles> You just need to immerse yourself
12:21:34 <pie_> yeah sure
12:21:46 <ocharles> The early papers from Codd, and others on normal forma might be worth a read
12:21:57 <pie_> - but I havent been able to figure out yet what this performancedba guy's "catalog" stuff is for 6NF, and he also says something about code generation
12:22:01 <pie_> but i havent seen any examples
12:22:13 <pie_> yeah i think i got a recommendation for a codd something or other too
12:22:18 <ocharles> Tbh, most DBAs aren't as relational as they could be, so you might not get too far with theory
12:23:03 <Nistur> morning all
12:23:15 <pie_> it seems to me like its going to be a question how to refactor databases you inherit, if youre allowed to
12:23:20 <pie_> and how to deal with them if not :/
12:23:34 * pie_ shrugs
12:24:07 * pie_ waits to see if he gets his part time job
12:32:51 <pie_> ocharles: thanks for the input
12:36:39 <bonz060> For language enthusiasts, why Haskell, and not say something like say a lisp with their strong macro system? NoOb question :')
12:37:00 <monochrom> I like Haskell's types.
12:37:12 <monochrom> I think I also like lazy evaluation.
12:37:28 <monochrom> maybe not always, but more often than not.
12:37:34 <enikar> you can have both: https://axellang.github.io/ :D
12:38:08 <enikar> I meant haskell+lisp macro.
12:38:16 <monochrom> actually I am not a language enthusiast in the first place. my answer is irrelevant.
12:38:59 <ja> bonz060: 'language' can mean a billion things
12:39:05 <monochrom> but I suppose a language enthusiasist is enthusiastic about all languages, they like both haskell and lisp, you can't ask them "why".
12:40:04 <xsperry> lisp and haskell are very different. lisp is dynamically typed, haskell is statically typed. lisp is mostly procedural [if we're thinking CL], haskell is purely functional. cl has eager evaluation, haskell is lazy
12:40:26 <monochrom> also I don't think you can hide behind your "NoOb question" façade if your question conveys you have already made up your mind by "a lisp with their strong macro system".
12:41:03 <bonz060> So I've been doing racket for a minute, and what I've seen so far is that Haskell has a darn high barrier to entry. I've barely used racket for a month and I'm kinda starting to build a DSL of my own to parse some org files. I get the vibe of "when you get it, YOU GET IT" from alot of haskellers in the wild. And I reckon that requires alot of patience. Fyi, I don't want to start a flame war around PLs... Just seeking out motivation to continue on this 
12:41:03 <bonz060> learning path.
12:43:53 <monochrom> No one else can motivate you. No one else is supposed to motivate you. This channel is not a scientology place.
12:44:22 <bonz060> monochrome: well I'm more familiar with lisps than Haskell so yeah, I'd default to using them as opposed to say, Haskell :)
12:46:14 <pie_> im not so much of an enthusiast as (-well...maybe im a conflicted enthusiast) much as someone that thinks if you care about your craft youll probably end up looking at both languages eventually and the question is just the order
12:46:26 <monochrom> I gave up on lisp and scheme and racket on the slightest pretext that sml and haskell's very straightforward "map (map f) [[a,b,c], [x,y,z]]" requires jumping through hoops in lisp, scheme, and racket.
12:47:04 <Heffalump> why does it require jumping through hoops, OOI?
12:47:15 <monochrom> anti-currying
12:47:49 <xsperry> similar examples while reading first few paragraphs of LYAH also convinced me to try to switch to haskell, after using lisp for years
12:48:03 <pie_> xsperry: any luck?
12:48:11 <monochrom> "(map f)" makes no sense in Scheme. It has to be some kind of "(curry map f)" I forgot the technical details (there are).
12:48:20 * pie_ hasnt meaningfully touched lisp yet
12:48:32 <xsperry> pie I've been using nothing but haskell for the past several years for my personal projects
12:48:37 <pie_> otoh i still have problems with haskells initial investment required
12:48:46 <pie_> xsperry: thats encouraging
12:49:08 <dsal> Haskell remains the easiest language I work in.  :)
12:49:27 <monochrom> Maybe more mildly s/gave up on/disappointed at/
12:49:36 <dsal> I've mostly finished my mqtt broker.  It's internet facing and I've got two bridged instances doing all my IoT stuff.
12:49:42 <monochrom> I thought they were functional in the Backus sense.
12:50:48 <dsal> pie_: The "initial investment" thing is kind of interesting.  Many languages that are easy on day 1 have really low ceilings.
12:50:54 <dsal> Haskell seems to be a convertible.
12:51:53 <bonz060> So do you just jump in and start building things once you've had your head wrapped around some basics? I've found myself stuck in some learning phase. Every time I try to read something, I discover this new thing. And when you start trying to learn this new thing, you get into some rabbit hole(that's some times enjoyable to be in). My current rabbit hole is the book "Book of monads"
12:51:55 <monochrom> I now pitch Haskell as an anti-fast-food language.
12:52:03 <pie_> dsal: yeah python is still the only thing i can get anything done in but im not writing anything more than at most a few thousand lines of code in it
12:52:23 <dsal> bonz060: I did.  I wrote a couple of big things without knowing much haskell.  I'm far more effective now, but my older programs worked.
12:52:50 <pie_> bonz060: someting that helped me a bit: you dont _HAVE_ to use fancy type fuckery. try to stick to simple functions when you can at least for starters
12:53:09 <dsal> pie_: large python codebases are where bad people go when they die.
12:53:13 <pie_> heh
12:53:22 <pie_> i dont think ive topped 1000loc tbh
12:53:27 <pie_> but im not a pro
12:53:48 <monochrom> You can just jump into python and start building web apps.  You can also just jump into McDonald's and start eating.
12:53:50 <dsal> My entire mqtt broker implementation is about 1500 lines of haskell.
12:54:05 <monochrom> These only prove that they are fast food. Do you still want them now? For the rest of your life?
12:54:11 <pie_> how many books did you have to read to do that :P
12:54:17 <pie_> i think im trying to learn haskell wrong or something
12:54:39 <pie_> also want to dig up another article but i dont remember how to find it - i havent read it myself yet but it was about "try to start with _less_ polymorphic stuff"
12:54:47 <dsal> I didn't read any books when I started writing haskell programs, but I was bad at it.
12:55:06 <monochrom> I would think eventually you would want to take a long time to learn good cooking of meals and IO recipes.
12:55:44 <dsal> LOL.  I was in the wrong tree.  My mqtt broker is 1300 lines.
12:56:06 <pie_> monochrom: you dont have to convince me - but the bottom line is im still useless at haskell right now
12:56:06 <monochrom> Wait, which tree has 1500 lines?
12:56:14 <dsal> my mqttd broker
12:56:55 <suzu_> does your mqttd broker have any hot stock tips?
12:57:42 <dsal> My initial implementation used lists for subscriptions.  It was stupidly inefficient, but I didn't want to think about the fancy data structure that could manage all the wildcard logic and stuff.  Then I realized, it's probably not that hard.  That data structure is 47 LoC and is a functor, foldable, traversable, monoid which made it *super* easy to do stuff with.
12:57:47 <dmwit> I have some stock tips that will make you broker.
12:57:51 <Philonous> monochrom, I don't know, IMO the problem with McD isn't that it's fast food, the problem is that it's bad food. On the other Hand, I've been wishing for a "fast food version" of Haskell for a while; the ability to just write a few lines in a single source file to get a small job done. Ideally it would also start up quickly. 
12:58:02 <dsal> (though it shrank a bit when I realized you could derive more of these things)
12:58:18 <monochrom> I never heard of "book of monads". I guess this is why I have been able to write useful Haskell programs and teach monads meaningfully to my students.
12:58:35 <dmwit> Philonous: Which fast food do you advocate as "good food"?
12:58:53 <monochrom> Philonous: Does yesod get close to that?
12:59:32 <bonz060> Thanks guys! At least I've got some pointers. I reckon I'll just dive in and try out things in the form of a side project and learn incrementally. And see how that goes :)
13:00:01 <Philonous> dmwit, I live in Malmö now, so falafel. But anything with fresh ingredients that's  not coming from a big chain will usually be OK 
13:00:32 <monochrom> Actually McDonald's in Canada gets very close to good food for fast food.  They have a garden salad.  Their Big Mac has shrunk, this means Big Mac is not so bad after all.  They have fruit smoothies.
13:00:35 <dsal> bonz060: what kinds of things are you interested in?  I've got a pretty good variety since I write everything in haskell these days.
13:01:19 <Philonous> monochrom, How does yesod help with the single-source-file problem? I don't think you can get it to work without at least a cabal file 
13:01:30 <dsal> Philonous: #!/usr/bin/env stack
13:01:36 <monochrom> :)
13:05:26 <sm[m]> Philonous: https://docs.haskellstack.org/en/stable/GUIDE/#script-interpreter
13:06:42 <Nistur> It is proving strangely difficult to get ghc running properly on my pi
13:07:28 <dsal> I build on a linux PC and deploy on Orange pi
13:08:12 <Nistur> I don't have a PC set up properly. It is in the corner of my attic, but I've not needed to apply power to it in about 2 years
13:08:12 <bonz060> dsal: web servers and web stuff. Also parsers to some extent. I want to port twint to racket or guile, and then package it in guix.
13:08:46 <bonz060> dsal: this is twint: https://github.com/twintproject/twint
13:09:07 <bonz060> dsal: But I'm pretty open to anything as long as it is interesting.
13:09:51 <dsal> Oh neat.  I used to run a twitter <-> xmpp gateway before various ends of that got killed off.
13:10:25 <dsal> bonz060: Speaking of working with things that aren't APIs, I did this recently:  http://dustin.sallings.org/2020/04/29/gopro-plus.html
13:10:32 <xerox_> dsal: what did you use in the end for the structure to match subscriptions
13:10:56 <dsal> xerox_: https://github.com/dustin/mqttd/blob/master/src/MQTTD/SubTree.hs
13:12:18 <dsal> It doesn't clean itself up all that well on unsubscribe (i.e., it leaves structure around), but I'm not worried about that currently.
13:13:51 <dsal> I've got ~240 subscriptions on my little orange pi here and the process has < 20MB resident, so I'm not all that worried.  :)
13:14:49 <xerox_> (:
13:15:46 <dsal> There's a weird special case where patterns don't match the first element of a topic that starts with $.  Other than that, it was much easier than I expected.
13:22:18 <bonz060> dsal: twitter nowadays has a lot of annoying restrictions if you want to use their API :(
13:22:38 <bonz060> dsal: wow! That's really neat. 
13:23:08 <dsal> Yeah.  Back then, it was just a little twisted app that pulled all the content out and let me (and a few other people) use our chat clients as our primary twitter interfaces, plus feed search results in.
13:23:48 <bonz060> dsal: why elm? I ditched it when I "discovered" purescript a while back. Writing purescript feels like writing Haskell to some extent
13:24:17 <dsal> I hear elm was cool.  Never tried it.  It was a reasonably good experience.  There were a couple things I didn't like about it.
13:24:41 <dsal> My least favorite part of elm is their preferred formatting.  :)
13:25:36 <bonz060> What did you not like? The reasons I hear is that it's opinionated and comes with alot of boilerplate. But, imho it has a great community and some nice docs. I've tried my hand at it in some abandoned projects 
13:27:16 <dsal> The lack of typeclasses is somewhat understandable, but makes a few things kind of annoying.  There's no concept like 'Show' other than for debugging, so I've got a ton of code that just converts a sum type to a string and back (which, IMO  but very much not in their opinion, should be automated).  If you want to display a day, you have to write your own Monday -> "Monday" for example.
13:28:39 <dsal> They have functors and monads by convention, which is fine.  The "elm architecture" seems decent.  I don't think I fully understand how to scale stuff.
13:37:17 <dsal> You also can't use custom types as dictionary or set keys, which is quite painful.
13:37:17 <bonz060> dsal: so the quickest way _you_ learn stuff is by straight up getting your hands dirty; even when you don't know what your doing? Then learn sed thing properly when "cleaning your hand" later?
13:37:33 <dsal> Yes.  Launch first, read manual late.r. heh
13:38:48 <dsal> Sometimes that doesn't work well.  I had a few "production" apps before I got around to reading haskellbook.com.  Understanding what I was doing did make it less frustrating.
13:39:09 <dsal> Like most things, you look back on it wondering why it was hard after you get the basics down.
13:45:38 <dsal> My memory graph for my mqtt broker is super flat (gc varies a bit). https://usercontent.irccloud-cdn.com/file/nATPoGFM/gcstats
13:45:41 <RENNNN> aw, the cplex interface looks dead
13:53:10 <fog> is there a good haskell package or abstraction for modelling sensor arrays (like ELISA tests) as multiclassifier systems?
13:55:05 <crestfallen> > sequence ["cbs","ae","tb"]
13:55:06 <lambdabot>  ["cat","cab","cet","ceb","bat","bab","bet","beb","sat","sab","set","seb"]
13:55:28 <crestfallen> hi wondering what "lists 'modeling' non-determinism means
13:55:38 <dsal> @src sequence
13:55:38 <lambdabot> sequence []     = return []
13:55:38 <lambdabot> sequence (x:xs) = do v <- x; vs <- sequence xs; return (v:vs)
13:55:38 <lambdabot> --OR
13:55:38 <lambdabot> sequence xs = foldr (liftM2 (:)) (return []) xs
13:57:25 <crestfallen> I understand non-determinism but Im reading about how some programs 'model' it
13:58:00 <dsal> I don't exactly understand what you're asking.  I use similar constructs for things like logic puzzles.
13:58:53 <fog> crestfallen: can you briefly explain what you understand the term to mean, so that we can get a better idea of your question?
13:59:08 <crestfallen> one moment please
14:00:01 <dsal> > let nums = [1..10] in do { a <- nums; b <- nums; guard (a + b == 10); guard (a > b); pure (a,b) }. -- e.g, given a list of numbers, give me all of the ways you can combine two of them where the first is bigger than the second and the sum is 10.
14:00:03 <lambdabot>  <hint>:1:245: error:
14:00:03 <lambdabot>      parse error (possibly incorrect indentation or mismatched brackets)
14:00:13 <dsal> (which is a dumb example, but more useful in more useful logic puzzles.
14:00:25 <dsal> > let nums = [1..10] in do { a <- nums; b <- nums; guard (a + b == 10); guard (a > b); pure (a,b) } -- why did my keyboard suddenly start injecting periods...
14:00:28 <lambdabot>  [(6,4),(7,3),(8,2),(9,1)]
14:04:57 <crestfallen> "In this context, what's nondeterministic isn't the computation that Haskell is performing, but instead the computation that is being represented." 
14:05:14 <crestfallen> That quote is from this SO post https://stackoverflow.com/questions/29886852/why-is-the-following-haskell-code-non-deterministic
14:10:37 <crestfallen> so the quote above is causing my confusion. I guess the 'model' is the "computation that is being represented"
14:11:10 <crestfallen> and not being performed by haskell
14:13:04 <dsal> I used to think "nondeterministic" meant something closer to "random", but that's not quite it.  Some of the other answers there are closer.  You can get something other than one result for given input.
14:13:49 <crestfallen> something different, but only in terms of order, right dsal 
14:13:50 <crestfallen> ?
14:13:58 <fog> ah something to do with effects in an IO context?
14:14:12 <monochrom> No, random has an extra probability distribution that nondeterminism does not have.
14:14:20 <monochrom> There are also deeper differences.
14:14:26 <dsal> So in the example above, I want to ask from a list of numbers, how I can combine them into two things that satisfy a given set of criteria.  It may not be satisfiable, or it may be satisfiable in multiple ways.
14:14:40 <fog> i mean, from stochastic process, it just means unpredictable 
14:15:44 <monochrom> The best explanation and contrast of both is not in how a computation is performed, but what kind of specifications is considered and what the correctness criterion is.  Programmers naturally keep forgetting that specifications and correctness exist outside code.
14:16:25 <dsal> bah.  I don't have time for specification and correctness *in* my code, why would I consider anything outside of it?
14:16:50 <fog> isnt this answer from the SO post good enough;
14:16:52 <fog> "If "non-determinsitic code" is just code that has "zero or more outputs of type t", this sounds a lot like a function returning a list of t."
14:17:21 <monochrom> Random is when your specification talks about which outcomes have how much probabilities of happening. You may think in terms of weighted average (weighted by probabilities of random choices) over outcomes.
14:17:45 <infinity0> also you'd probably don't want to actually deal with a list of 10^100 elements
14:17:57 <fog> yeah, but you still need IO to get actually unpredictable random seed
14:18:53 <fog> same with the idea of race conditions in parallel threads being non-deterministic 
14:19:06 <monochrom> Nondeterminism splits into angelic vs demonic nondeterminism.  Most programmers assume demonic nondeterminism.  This means that your specification is to be satisfied regardless of choices made.  (Angelic: satisfied if some choice works.)
14:19:33 <fog> it seems like this consideration of purity is totally different to the set membership argument of how "lists model nondeterminism"
14:19:40 <crestfallen> so should I focus on fog 's observation ""If "non-determinsitic code" is just code that has "zero or more outputs of type t", this sounds a lot like a function returning a list of t."     and not worry about probability, since haskell is going to return every possibility including the repeats of whatever the function is returning?
14:20:47 <fog> what? how would haskell generate all possible outputs of a function? you would have to pass in all possible inputs...
14:21:21 <crestfallen> sorry it didn't mean it like that...
14:22:31 <fog> you mean, haskell is going to produce any possible output deterministically given an input in a pure setting?
14:24:00 <fog> and not to worry about that, because purity seems aside from whatever this logic-programing interpretation of "only one output" (not returning a list) is
14:24:24 <crestfallen> I fully understand this:
14:24:29 <crestfallen>  > sequence ["cbs","ae","tb"]
14:24:38 <crestfallen> > sequence ["cbs","ae","tb"]
14:24:40 <lambdabot>  ["cat","cab","cet","ceb","bat","bab","bet","beb","sat","sab","set","seb"]
14:24:48 <crestfallen> what I don't understand is :
14:25:12 <crestfallen> " what's nondeterministic isn't the computation that Haskell is performing, but instead the computation that is being represented. "
14:25:33 <infinity0> i think you are getting stuck on representation vs the actual thing
14:25:42 <infinity0> this is only *representing* a non-deterministic computation
14:25:49 <infinity0> the map is not the territory, this is not a pipe, etc
14:26:11 <infinity0> now representing things using other things is a very useful technique a lot of times in CS, but this is not one of those useful times
14:26:16 <xerox_> my 2 cents is just that a->a will get you always the same thing, and a->[a] also gets you always the same list of things, but it also represents how you can get multiple things out of one, as a nondeterministic process could do
14:26:30 <fog> ahh
14:26:40 <infinity0> this is a really really bad way of representing a non-deterministic computation
14:26:50 <fog> its because by using that applicative its "modeling" choices
14:27:18 <fog> your calculating it for every possiblity, *as if you didnt know which possibility was input*
14:27:33 <infinity0> or if the output is inherenetly ambiguous even with a single unique input
14:27:59 <infinity0> like rolling a dice, hey rollDice = [1,2,3,4,5,6]
14:28:03 <infinity0> no inputs
14:28:13 <fog> right
14:28:43 <fog> and the example of "nodeterminisitic addition" from dsals code, was ranging over all posibilities of output, by ranging over all posibilities of input
14:29:12 <fog> or maybe it was from the SO post...
14:29:28 <fog> yeah, here it is;
14:29:29 <fog> > (+) <$> [1,2] <*> [4,5,6]
14:29:31 <lambdabot>  [5,6,7,6,7,8]
14:29:50 <fog> "You add a number that could be 1 or 2, to another number that could be 4, 5, or 6"
14:30:20 <fog> i guess if you added a weight, this would be like a soft set
14:30:49 <fog> the weight would be referred to as the soft membership function (or something like that)
14:31:10 <fog> seems similar to the discussion about enumerating trees
14:31:18 <crestfallen> yeah I thought I understood the idea being that the list returned doesn't tell you exactly which two operands were being treated by the operator (+) if that makes sense
14:31:50 <crestfallen> like the list can't show you what the inhabitants are representing
14:32:02 <crestfallen> what each inhabitant represents
14:32:08 <fog> well they are ordered, so thats not quite right
14:32:16 <fog> you just mean (+) isnt invertable
14:32:26 <fog> but there could be an invertable version
14:32:34 <fog> > (,) <$> [1,2] <*> [4,5,6]
14:32:36 <lambdabot>  [(1,4),(1,5),(1,6),(2,4),(2,5),(2,6)]
14:33:11 <fog> now the ordering and the internal values of the output tell you exactly what were the inputs
14:33:20 <fog> thats not part of the nondeterminism thing
14:33:51 <fog> i wonder if we have soft sets in haskell
14:34:02 <fog> well, i guess we do, but if there is a nice representation
14:34:27 <fog> it could be good to eg, associate probabilities to different values, like "importance sampling" 
14:34:28 <koz_> fog: By 'soft' you mean 'fuzzy'? As in, the membership function has values in [0,1]?
14:34:35 <fog> fuzzy set, yes sorry
14:35:08 <fog> i think you get fuzzy nets when there is uncertainty built into neronal values for example
14:35:23 <fog> neuro-fuzzy...
14:35:57 <crestfallen> so fog your last example in lambdabot is deterministic?
14:36:02 <koz_> I mean, you could. Just have a fuzzy set of a be a Map from a to (some representation of) [0,1].
14:36:04 <fog> im not sure if thats like uncertainty propagation in a Bayesian setting
14:36:28 <fog> crestfallen: no, it still "models" that any possible input could have been given, but just by giving all possible inputs
14:36:30 <monochrom> Let's not get carried away.
14:37:02 <fog> koz_ im not sure if there are performance issues there
14:37:07 <koz_> Why would there be?
14:37:19 <koz_> You _do_ realize sets and maps are backed by the same structure right? :P
14:37:52 <fog> i mean, to get a value from the set, wouldnt you have to integrate the weights?
14:38:09 <fog> % randomRIO (0,1)
14:38:09 <koz_> Why?
14:38:09 <yahb> fog: 0
14:38:17 <fog> % randomRIO (0,1 :: Double)
14:38:17 <yahb> fog: 0.1481445203829168
14:38:52 <fog> so that evenly samples the range from (0,1), but if we have a pdf, then we would want it to be more likely in some region
14:39:13 <koz_> fog: OK, let me be more precise.
14:39:15 <infinity0> a probability distribution is indeed a monad, i wrote one in python yonks ago
14:39:15 <fog> so we have to integrate over all the space, of the probability there, and then normalise by dividing by the total
14:39:30 <koz_> How is integration required to 'get a value from a set' in the representation I just outlined?
14:39:47 <infinity0> https://github.com/infinity0/bjsim/blob/master/bj/prob.py#L73
14:40:17 <monochrom> Getting an expected value needs integration. :)
14:40:17 <infinity0> only discrete finite ones, since they can be represented with a finite table
14:40:25 <fog> ok, so your idea was that you would enumerate all the values, eg, for the set [1..10] you would do fromList to put it into a Map 
14:40:32 <koz_> Where do expected values come into this?
14:40:39 <koz_> I have a Map Foo Double, say.
14:40:45 <koz_> What do you mean by 'expected value' in this context?
14:40:45 <monochrom> But I learned a cool trick that may sidestep that sometimes.
14:40:48 <koz_> How is this a _set_ operation?
14:40:56 <crestfallen> yeah fog I see your last example is also non-deterministic, it's only more clear where the operands are. but even if there is a repeated internal result in the list, you can see that it's in order
14:41:34 <monochrom> expected value doesn't come into this. hell, fuzzy set doesn't in the first place. What were we talking about again? Or is it all digression for digression's sake?
14:42:23 <monochrom> Like if someone asks about choices, someone else has to attach weights to choices for their hidden agenda of carrying away to neural networks.
14:42:27 <koz_> monochrom: I'm asking why fog believes that representing a fuzzy set as a map from values to degrees of membership requires integration.
14:42:38 <crestfallen> the short way to understand a computation that is being performed, vs. one being represented
14:43:00 <crestfallen> is what I asking about
14:43:07 <fog> the discussion about lists modeling non determinism. where the many possible values represent different possible inputs. i guess that is actually different from the scheme to actually select which of those inputs to use
14:43:13 <monochrom> And a 3rd someone else has to bring up expected value because he (that's me) recently learned the cool trick of using Cont as a probability monad.
14:43:37 <infinity0> to implement monadic bind for a probability distribution, it is necessary to "look into" the weights and you have to sum up some of them, so you can view it as integration
14:43:52 <Rembane> monochrom: How can you use Cont as a probability monad? 
14:44:14 <infinity0> if your first action turns 1 -> (1,2,3) then your second action turns 2 -> (4, ..) and 3 -> (4, ..), you will have to sum up the relevant probabilities for the several paths of getting to 4
14:44:59 <monochrom> (a -> Real) -> Real (or replace Real by any fractional number type you prefer, I'm being a mathematician here).
14:45:02 <fog> koz_ it was about inverting that to get a value from a evenly weighted random value, you have to add up all the weights to see which random value "histogram bin" this corresponds too
14:45:24 <monochrom> where "a" is the type of the sample space (possible outcomes)
14:46:02 <monochrom> the type of "random variable" is then a->Real, mapping an outcome to a number meaningful to you.
14:46:09 <koz_> fog: This doesn't correspond to any fuzzy set operation I am aware of, either in the theory of fuzzy sets (as best I know it) or in an implementational notion of 'set'.
14:46:35 <infinity0> maybe someone has a fuzzier definition of things that you're sticking to
14:46:43 <infinity0> than you're*
14:46:47 <fog> crestfallen: if your asking about what computation is being performed, that seems fairly obvious. i guess when they are saying that this computation "represents" another, is because depending on how the input output mapping is interpreted by the user in this context, it seems to be "modeling" nondeterminism, but only very roughly
14:47:08 <monochrom> "expected value" then maps a random variable to the weighted average according to that random variable.
14:47:50 <monochrom> Example!  Suppose you have in mind this probability distribution: 0.1 chance X, 0.7 chance Y, 0.2 chance Z, that's all.
14:48:13 <awpr> but that only adds up to 0.999999999999999998
14:48:43 <fog> koz_ doesnt you need a way to retrive the values from the set? for opperations like union etc?
14:48:43 <monochrom> You can code it up as: \r -> 0.1 * r X + 0.7 * r Y + 0.2 * r Z.  This is the expected value of r under your probability distribution of the X,Y,Z.
14:48:58 <monochrom> > 0.1 + 0.7 + 0.2 :: Rational
14:49:00 <lambdabot>  1 % 1
14:49:04 <monochrom> works :)
14:49:09 <koz_> fog: Union of two such sets can be defined in several ways.
14:49:12 <koz_> Which are you going with?
14:49:19 <koz_> And the 'values' of this set are... the keys of the map?
14:49:35 <fog> um, well, i was just trying to get an excuse to try and select values from the set
14:49:36 <koz_> (fuzzy union isn't specified in one exact way as with crisp sets)
14:49:52 <monochrom> It turns out that >>= for general (a->r)->r does exactly the right thing for this expected value monad (a->Real)->Real
14:50:08 <monochrom> (I was totally horrified that it's that simple.)
14:50:10 <koz_> 'select values from the set' - this can mean about ten different things. Please state your question or issue more precisely.
14:51:08 <monochrom> (Needless to say, pure a = \r -> r a corroborates the story perfectly as well.)
14:51:14 <fog> if i wanted eg, to sample from a gausian distribution
14:51:40 <fog> i would be assigning selection weights to the reals
14:51:47 <fog> ie, probabilities 
14:52:12 <fog> so for a fuzzy set, i would expect, eg, the set of all Reals, with the associated probabilities of selection
14:52:17 <nil> monochrom: that sounds fascinating, but how would you actually use such an (a -> Real) -> Real value? what kind of `r` functions would make sense there?
14:52:21 <koz_> You can't _define_ the set of all reals like that.
14:52:34 <fog> and then, to sample the distribution, i would be "getting a value from a fuzzy set" ?
14:52:36 <koz_> Unless only finitely many of them have non-default weights.
14:52:51 <fog> for any given set
14:52:59 <koz_> Fuzzy sets aren't for sampling probability distributions. So not only are you asking for a solution to an impossible problem, you're also using the wrong tool to do it.
14:53:08 <fog> and a way to give a probability to the values, so as to define a distribution over the set
14:53:09 <monochrom> http://www.cs.tufts.edu/~nr/pubs/pmonad.pdf has all the detailed math and also doing the sufficiently general measure-theory proof (so >>= is still right for continuous random variables)
14:53:57 <fog> well, there are features of fuzzy sets that could be good no? such as combining distributions?
14:54:00 <nil> cool. i guess sampling is what i'm most curious about
14:54:02 <monochrom> nil: I can ask for individual probabilities by providing Bernoulli random variables.
14:54:24 <koz_> fog: All I can say is 'maybe, but your line of questioning fundamentally makes it impossible for me to give an answer'.
14:54:26 <monochrom> I cannot ask to enumerate all non-zero-prob outcomes. That's a shortcoming.
14:54:37 <koz_> Therefore, to answer your _original_ question, no, there are no issues of efficiency I can observe.
14:54:51 <koz_> There are deficiencies to this representation, I agree.
14:54:58 <monochrom> But if I already have a desired outcome X in mind, I can ask for the prob of X specifically.
14:55:00 <fog> if i *select a random value* from a fuzzy set, and reject it with a liklihood proportional to its weight, then its doing sampling
14:55:15 <monochrom> Not to mention that a lot of other interesting questions can be reduced to expected value questions.
14:55:37 <koz_> fog: OK. So you want to select a random value with probability proportional to its membership.
14:55:43 <koz_> There's finitely many.
14:55:50 <koz_> You can use any number of sampling methods to do this.
14:55:53 <koz_> Done.
14:55:56 <koz_> Where's integration involved here?>
14:55:59 <fog> ah right, that was the fundamental misuderstanding, i thought you were describing fuzzy sets
14:56:09 <koz_> I am describing _an implementation of_ fuzzy sets.
14:56:09 <nil> monochrom: now i'm thinking... if that r was provided by callCC, maybe interesting things could happen?
14:56:13 <fog> oh
14:56:25 <monochrom> yikes
14:56:25 <koz_> That was _literally_ one of the first three sentences out of my mouth.
14:56:52 <koz_> (or fingers I guess, same diff)
14:56:56 <fog> the integration would be to avoid that described approach, of rejecting the randomly selected value according to its weight
14:57:07 <fog> basically, you need integration for finding the *index*
14:57:13 <monochrom> insert finger into mouth...
14:57:26 <koz_> fog: What's an 'index'?
14:57:37 <fog> :t (!)
14:57:38 <lambdabot> Ix i => Array i e -> i -> e
14:57:48 <koz_> Note the distinct absence of anything like a set in that signature.
14:57:55 <koz_> Stop mixing metaphors and muddying the waters.
14:58:23 <fog> i might be misunderstanding how your selecting values from your "Set"
14:58:33 <koz_> I specified an implementation.
14:58:37 <koz_> (Map from a to Double)
14:58:42 <koz_> (can be HashMap if you prefer)
14:58:43 <monochrom> That's literally my complaint against all humanity.
14:58:46 <koz_> (makes zero difference)
14:58:54 <koz_> In either case, 'index' makes no sense.
14:59:04 <fog> right, im with you now
14:59:25 <monochrom> I had students who "reasoned" "the empty set is empty, the empty string is empty, they are the same".  Mixing metaphors of "empty".
14:59:31 <fog> well, unless they were enumerable, like with a range instance. but that would be like inverting your use of what appears to be a Store
14:59:37 <monochrom> Why can't people just work with axioms?
14:59:53 <koz_> fog: How does this have anything to do with that?
15:00:12 <dolio> monochrom: Set theorists probably told them they were correct. :P
15:00:22 <koz_> dolio: Everything's a set in ZFC, after all. :P
15:00:24 <fog> well because on one side of that duality, you have the integrated probabilities, and on the other you have your mapping
15:00:42 <koz_> fog: So, not relevant to the case at play. Got it.
15:00:58 <fog> you kind of abstracted it away. i guess what im saying is to flip between those 2 represenations, you would need to do the integration and ranging
15:01:08 <koz_> And why would you want to do this?
15:01:16 <koz_> Like, what's the benefit?
15:01:29 <fog> well, because i might have started from a range instance, and need to derive your weightings
15:01:37 <koz_> How is the range represented?
15:01:43 <fog> :t range
15:01:44 <lambdabot> Ix a => (a, a) -> [a]
15:01:48 <koz_> OK, range is finite.
15:01:51 <koz_> There are no weights.
15:01:56 <koz_> I don't get the analogy.
15:02:31 <crestfallen> fog would you mind looking at timestamps [14:31:54] - [14:32:58] ?  I'm confused where you say " thats not part of the nondeterminism thing "
15:03:59 <fog> well, your only going to be able to get your (a -> Double) by ranging over the values if they are finite. thats ok, because in my idea it was for choosing between nested sum type layers in a big datatype
15:04:06 <fog> crestfallen: ok
15:04:28 <koz_> fog: We can't, in general, represent infinite sets.
15:04:44 <fog> basically, i guess thats what range is for
15:04:49 <koz_> So if your 'a' is arbitrary (up to constraints required by whatever underlying dictionary data structure you're using), this is 100% not the issue.
15:04:51 <fog> specifying the setting where we can
15:05:50 <fog> its basically just an upper and lower bound, to specify a subsection of the infinite range, and the enumFromTo or, nextValue, proves they are not dense
15:06:02 <fog> wait thats not quite right, well, however range works...
15:06:20 <koz_> OK, so what you're saying is that you have a finite collection of values.
15:06:29 <koz_> How do we determine their degrees of membership?
15:07:11 <fog> no. given their degrees of membership, how do we sample
15:07:34 <crestfallen> so the list of tuples, that's nondeterministic even though it's clear where each tuple came from -  fog?
15:07:47 <koz_> How are these degrees of membership specified in your representation?
15:07:49 <fog> sorry, cant find the thing your asking on the logs
15:07:52 <koz_> You're basically talking about a list.
15:08:02 <fog> i want to get from [(Double,a)] to a -> Double
15:08:03 <koz_> The list has values in it, OK. Drawn from somewhere, OK, Unique, OK.
15:08:14 <koz_> :t lookup
15:08:15 <lambdabot> Eq a => a -> [(a, b)] -> Maybe b
15:08:28 <monochrom> I think you're just looking for: (,) <$> [1,2] <*> [4,5,6] =  [(1,4),(1,5),(1,6),(2,4),(2,5),(2,6)]
15:08:30 <koz_> With a default of 0 in the case of Nothing.
15:08:40 <fog> crestfallen: yes, its not about purity, ie, outputs depending with certainty on inputs
15:09:03 <fog> its about how they are "thinking about lists as if they represented different possible inputs"
15:09:42 <fog> monochrom: thanks
15:10:07 <crestfallen> that one is called invertable ?
15:10:23 <fog> well, (+) isnt, but (,) is
15:10:45 <crestfallen> ok copy thanks kindly fog monochrom 
15:11:09 <koz_> :t flip lookup
15:11:10 <lambdabot> Eq a => [(a, b)] -> a -> Maybe b
15:11:18 <koz_> There ya go, to make this analogy even clearer.
15:11:50 <fog> koz_ so you get why we have to traverse the [(a, b)], to add up the `a' so that we can select given a double from (0,1)
15:12:00 <koz_> No we don't.
15:12:09 <koz_> Have you looked at any weighted sampling algorithms on finite structures lately?
15:12:15 <koz_> I can give you two.
15:12:32 <koz_> https://en.wikipedia.org/wiki/Reservoir_sampling#Weighted_random_sampling
15:12:34 <koz_> Heck, three even!
15:12:46 <koz_> You will observe _zero_ integration is required for _any_ of them.
15:12:47 <fog> im not sure why you claim im wrong about something your not understanding.
15:13:30 <fog> the (0,1) is "where" in the list it is
15:13:50 <fog> 0 corresponds to head, 1 to last
15:13:54 <koz_> In what sense? There's no order to a set's elements liek that.
15:14:19 <fog> it should be order independent 
15:14:26 <monochrom> I don't think it's healthy to continue this.
15:14:31 <koz_> monochrom: I'm starting to agree.
15:14:38 <koz_> fog: How would that work even in theory?
15:14:47 <koz_> You wanna select a single element based on a value in (0, 1).
15:14:59 <koz_> So suppose I have this (or equivalent) representation
15:15:12 <koz_> [(1, 0.1), (2, 0.5), (7, 0.2)]
15:15:17 <fog> to save monochrom, i should probably just write a paste implementing exactly what i mean, so we cant get confused about english language translations
15:15:19 <koz_> If I feed this 0.34, what do I get back?
15:15:29 <koz_> (conceptually speaking)
15:16:28 <fog> ok, so, i first check to see your weights add up to 1. ok they dont, so its not normalised, and i multiply your weights by (1/(0.1+0.5+0.2))
15:17:03 <koz_> (for the record, fuzzy sets don't require that degrees of membership sum to 1, even in theory)
15:17:08 <fog> which still seems like 0.34 is in the "histogram bin" corresponding to 2
15:17:16 <monochrom> I once took a look at fuzzy sets because a friend asked "what should union do?"
15:17:17 <koz_> OK
15:17:24 <koz_> So now I give you the equivalent rep
15:17:35 <koz_> [(2, 0.5), (1, 0.1), (7, 0.2)]
15:17:40 <koz_> Sets don't have an order remember.
15:17:46 <koz_> So how does this give the same answer?
15:18:04 <koz_> monochrom: There are several different unions possible.
15:18:05 <fog> no, but it would still be sampled the same
15:18:12 <fog> thats the point
15:18:22 <monochrom> Then I found out there are several different ways. They are all pretty reasonable, and all have their use cases. They even satisfy the same common axioms, so in this sense they're all no-surprise.
15:18:35 <koz_> fog: What if I had [(1, 0.1), (2, 0.1), (7, 0.1)]?
15:18:38 <monochrom> At that point I decided I don't want to care anymore. :)
15:18:49 <koz_> monochrom: Yeah, you gotta pick an underlying t-norm logic I think?
15:18:56 <monochrom> yeah, that.
15:19:17 <fog> koz_ it should not matter how you shuffle the list, integrating the weights will allow you to sample accodingly - with equal probability of sampling in the limit of many samples
15:19:18 <koz_> There's a few common candidates. I believe Zadeh's original formulation took or as max and and as min.
15:19:27 <fog> sure, they would occur in a different order
15:20:07 <koz_> fog: OK, assume I'm daft. Given the above (all weights 0.1), walk me through the process of getting the value for 0.35.
15:20:16 <monochrom> like, "cool math, good luck have fun folks, I'm outta here"
15:20:19 <koz_> Assume I'm a five-year-old. Or a computer. State every step.
15:20:35 <koz_> monochrom: I get the feeling that what t-norm logic you pick depends what you're trying to do.
15:20:37 <monochrom> "I'll tell you when you grow up."
15:20:55 <monochrom> What you should insist is ELINT = explain like I'm not telepathic.
15:21:15 <fog> normalize, so your weights add up to 1. integrate (scan +) over each weight to get its cumulative weight, then, find the 2 adjacent elements that have cumulative weights to either side of your selection number 
15:21:24 <fog> its the lowest of these
15:21:31 <fog> the first*
15:21:37 <koz_> fog: OK, so the normalization step makes each weight 1/3.
15:21:50 <koz_> Scan + _inherently relies on a linear collection's order_.
15:21:57 <fog> so?
15:22:06 <koz_> So if I change it, I get a different answer?
15:22:11 <koz_> Which destroys the fact we have a set?
15:22:12 <fog> its only in the limit of many samples that you are going to recover the equivalence
15:23:00 <koz_> OK, so we've officially left computing behind ten streets ago, got it.
15:23:13 <fog> all we are trying to do is ensure that some portion of the range (0,1) is assigned to a number, with its weight proportionally the same as the length of the subsection of (0,1)
15:23:33 <fog> ill bring you the implementation.
15:23:40 <koz_> Sure.
16:00:33 <peter14> hi everyone, I am trying to do list comprehension but I need the same number (without increment) in the infinite list, like [1,1,1,1,1,] etc
16:00:42 <peter14> what is the list comprehension syntax for that?
16:01:15 * hackage retrie 0.1.1.1 - A powerful, easy-to-use codemodding tool for Haskell.  https://hackage.haskell.org/package/retrie-0.1.1.1 (AndrewFarmer)
16:02:44 <solonarv> you can't generate that with a list comprehension.
16:02:55 <solonarv> but 'repeat' may be what you are looking for
16:02:59 <yushyin> [1,1..]
16:03:11 <solonarv> that isn't a list comprehension
16:03:30 <Hoppelhase> > [ 1 | _ <- [0..] ]
16:03:32 <lambdabot>  [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1...
16:03:49 <Rembane> > [1,1..]
16:03:51 <lambdabot>  [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1...
16:03:58 <peter14> i am implementing repeat so I can't use the builtin! so I was gonna make another function with the infinite list
16:04:33 <solonarv> okay, implementing 'repeat' is not too hard - unless you really insist on using a list comprehension ;)
16:05:06 <peter14> ok, actually that comprehension worked
16:05:10 <peter14> (y) 
16:05:50 <monochrom> That's a strange notion of "work".
16:07:03 <monochrom> <Q> make infinitely many 1's.  <A> I can't, but I can give you 0,1,2,3,4... unending.  <Q> that's wrong answer.  <A> But it's infinite therefore it works.
16:07:19 <monochrom> Err sorry, misread.
16:07:35 <solonarv> still a very convoluted way of solving the exercise
16:07:42 <monochrom> Yeah, XY problem.
16:07:52 <monochrom> There is a very simplistic recursion.
16:08:01 <wavemode> can GHCI also limit its output when printing something infinite?
16:08:25 <fog> koz_
16:08:26 <monochrom> I have slowly become able to articulate why simpler solutions are harder.
16:08:31 <solonarv> can it? probably. but it doesn't in reality. you're free to Ctrl-C to abort it!
16:08:40 <monochrom> or at least fewer people can reach simpler solutions.
16:09:12 <fog> https://gist.github.com/fog-hs/a4b9695266d4080e2d2df80ba71dac24
16:10:27 <justsomeguy> Why are simpler solutions harder?
16:11:58 <fog> NP
16:12:02 <monochrom> Some mixture of: reflects and requires broader learning and deeper understanding; when people don't understand, they work harder not smarter; not first instinct; not invented here ego.
16:13:07 <fog> man, that reminds me of all the different representations of recursion schemes
16:13:32 <fog> in the end, its probably that a canonical approach is unlikely, and that standard approaches should *all* be lerned
16:13:45 <monochrom> refusing to rethinking, refactor, rewrite.
16:13:48 <fog> because each has an intuition, which is more natural for a particular algorithm
16:14:21 <fog> like the different representations of graphs too...
16:14:38 <fog> and even things like actor models in concurrent paradigms  
16:14:55 <fog> concurrency paradigms*
16:16:09 <fog> I would argue cyclic free lists are concurrent graphs, but some people prefer edge representations with Int indicies
16:16:46 <fog> instead of the not too easy to interpret [Int] indices for nested lists. (can traverse to place Ints though...)
16:17:33 <fog> canonical graphs*
16:25:45 <peter14> i have another noob question, is it alright to post 4 code lines here?
16:32:29 <peter14> nvm got it
16:35:52 <trajafri> Has anyone tried Agda like case splitting for haskell-mode? 
16:35:54 <trajafri> https://agda.readthedocs.io/en/v2.5.4.1/getting-started/quick-guide.html
16:36:27 <trajafri> By tried, I mean tried implementing it for haskell-mode
16:39:20 <fog42> i think the problem with canonical datatypes is that they become confused by performance issues
16:39:45 <fog42> like, if people are used to working with memory addresses for performance reasons
16:40:04 <fog42> this should arguably be handled by the compiler
16:40:12 <fog42> or at least by the internals of the library
16:40:36 <fog42> hiding these performance enhancing steps, and the types associated to that proceadure
16:40:53 <fog42> the API given should be that most intuative
16:41:27 <fog42> but then the problem is that we have a tradition of *thought* which results from memory access address driven languages
16:41:43 <fog42> the higher order functional programing paradigm being quite new
16:42:26 <fog42> so, because the tradition of literature surrounding graphs for example, has edges and nodes with memory like indexing
16:42:55 <fog42> and that because of the obfuscation of the higher order overhead meaning "fast" datastructures have the same lookup style
16:43:38 <fog42> then despite the higher order paradigm existing to distance these implementation details from the user - and allow them to use an abstracted API
16:44:02 <fog42> we still get held back, by performance considerations, into using non-canonical representations. 
16:44:32 <fog42> or, at least, in the absence of a conanical representation, we get tied to a particular intuition, which may be suboptimal for algorithmic design
16:52:25 <peter14> i'm using an Ord instead of a set here: 
16:52:27 <peter14> powerset (x:xs) = [x:ps | ps <- powerset xs] P.++ powerset xs
16:52:41 <peter14> how can I preserve set uniqueness without changing type to set?
17:14:54 <dsal> What is P?
17:15:28 <dsal> Not sure what you mean by "Ord instead of a set" -- Ord and Set aren't the same kind of thing.
17:16:45 <ski> `P' might be prelude ?
17:17:26 <ski> peter14 : what do you mean by "preserve set uniqueness" ?
17:18:05 <ski> if the input list has no duplicates, then each output list (in the list of lists) will also have no duplicates
17:52:15 <peter14> ski dsal the input 2 lists are unique, but they might contain duplicates between them. P is indeed prelude
17:52:37 <peter14> what I meant by ord is that the function is defined with ord rather than set inputs
17:53:00 <dsal> Is there a reason not to use Set in the implementation?
17:53:54 <dsal> Perhaps it'd be more precise if you defined what you meant in Haskell.    Is this    `powerset :: Ord a => [a] -> [[a]]` ?
17:55:14 * hackage graphql-w-persistent 0.9.0.0 - GraphQL interface middleware for (SQL) databases.  https://hackage.haskell.org/package/graphql-w-persistent-0.9.0.0 (jasonsychau)
17:55:51 <dsal> What are the "two lists"?  I only see the one.
17:56:31 <koz_> fg
17:56:34 <koz_> Whoops.
17:57:31 <dsal> > let powerset = fmap S.toList . S.toList . S.powerSet . S.fromList in   powerset [1, 2, 3, 4, 5]
17:57:32 <lambdabot>  [[],[1],[1,2],[1,2,3],[1,2,3,4],[1,2,3,4,5],[1,2,3,5],[1,2,4],[1,2,4,5],[1,2...
17:59:40 <ski> > filterM (\_ -> [False,True]) "012"
17:59:41 <lambdabot>  ["","2","1","12","0","02","01","012"]
18:00:29 <dsal> I think I've used that before...  So many ways to do things.
18:01:05 <dsal> I think if you have an Ord constraint and you want your "sets" to be unique, it makes sense to just make them Sets.
18:03:50 <peter14> yes, the definition is powerset :: Ord a => [a] -> [[a]]
18:04:02 <ski> > (map reverse . foldM (\xs x -> [xs,x:xs]) []) "012"
18:04:04 <lambdabot>  ["","2","1","12","0","02","01","012"]
18:04:18 <ski> > foldr (\x yss -> yss ++ [x:ys | ys <- yss]) [[]] "012"
18:04:20 <lambdabot>  ["","2","1","12","0","02","01","012"]
18:04:22 <ski> > (map reverse . foldl (\yss x -> yss ++ [x:ys | ys <- yss]) [[]]) "012"
18:04:24 <lambdabot>  ["","0","1","01","2","02","12","012"]
18:04:32 <ski> peter14 : what do you need ordering for ?
18:05:21 <peter14> it is to preserve set properties, so no duplicates, and sorted
18:05:23 <dsal> Mine is the only implementation that used it.   And it's going to be more expensive than the other ones.
18:05:38 <dsal> peter14: If you want that, you want a Set, not a list, and Set already has powerset.
18:05:54 <ski> peter14 : what do you mean by "preserve" ?
18:06:41 <peter14> ski as in, the passed in list has no duplicates and is sorted, so the resulting powerset must also satisfy those conditions
18:06:54 <enikar> are sets sorted?
18:07:01 <peter14> dsal yes, but i am trying to implement powerset outside of set as an exercise
18:07:01 <dsal> :t S.insert
18:07:02 <lambdabot> Ord a => a -> S.Set a -> S.Set a
18:07:05 <ski> peter14 : you don't need an `Ord' constraint for that
18:07:46 <ski> only if the implementation needs to do some comparision, do you need `Ord' in the type signature
18:08:24 <ski> if you just want to ensure that, assuming the input list is sorted and has no duplicates, then also each output list is sorted and has no duplicates
18:08:35 <ski> then you don't need order comparision for that
18:08:58 <peter14> I see
18:09:37 <dsal> (though you can have the Ord constrain for your test properties when you're making sure the results are sorted)
18:10:27 <ski> peter14 : just make sure you never duplicate any input element, in an output list. and also make sure you always give (some of) the output elements, in each output list, in the same order they occured in the input list
18:10:55 <ski> then, if the input list had no duplicates, you have not introduced any (more), and so there's also no duplicates in each output list
18:11:19 <ski> also, if the input list was sorted, and you didn't change the relative ordering of elements, for each output list, then each of them will also be sorted
19:06:27 <fog> im using System.Process to try and get an error message piped from stderr
19:06:33 <fog> but it throws an exception
19:06:47 <fog> is there a version that will not do this?
19:07:31 <fog> i can create something like what i want by running the command (its on linux, so i have stderr piped using 2>)
19:07:33 <fog> eg;
19:07:42 <fog> ls 2> err.txt
19:08:25 <fog> this throws no error, and the error message thrown to stdout ends up in the err.txt
19:08:56 <fog> if i try to do the same thing though using the error pipe handle for stderr, using System.Process
19:09:10 <fog> it throws an error every time the internall process throws an error
19:09:26 <fog> so i can never actually load the error message into an IO context
19:10:36 <fog> https://hackage.haskell.org/package/process-1.6.7.0/docs/src/System.Process.html#readProcessWithExitCode
19:11:17 <fog> the only mentions of "error" i can see are not responsible for the error being thrown
19:11:25 <fog> i dont see where it originates
19:11:59 <fog> its not failing to get the file handle, which is the only thing i can see which would throw an error
19:12:35 <fog> there are uses of functions from control.exception, but i cant see where, if ever it manages to get some data from stderr, that it throws this as a haskell error
19:18:06 <ezzieyguywuf> why is there a "parse error  on input 'it'" on line 20 here? http://dpaste.com/1V7TRPT
19:18:20 <ezzieyguywuf> if I comment out lines 20-23, the parse error goes away
19:19:13 <ezzieyguywuf> I tried lining up the `where` on line 18 with  the `length` on line 17 but i still get the parse error.
19:20:26 <ski> `where' attaches to the whole defining equation of `spec', not to individual commands in a `do'
19:20:29 <enikar> where can only be used at function level.
19:20:57 <monochrom> Use "let" instead.
19:20:59 <ski> use `let'-`in'
19:22:28 <monochrom> Also a lot of blogs are criminal on this. They indent their "where" more than the "do", misleading beginners to think that the "where" is part of "do".
19:22:29 <ezzieyguywuf> ah hah
19:22:49 <ezzieyguywuf> i was trying to mostly avoid let-in, but I guess here it cannot be avoided
19:23:39 <ski> you could break out individual `it ...' commands into definitions of their own .. which could have attached `where's
19:23:40 <ezzieyguywuf> a different question: if I have `type MyMaybe a = Maybe a`, how do I create a `MyMaybe`? I can't do `MyJust`
19:23:54 <monochrom> Just
19:24:01 <ezzieyguywuf> ski: (a) how would I do that, and (b) would I want to.
19:24:13 <ski> (those individual definitions could be declared locally, within a `where', to the whole `spec' defining equation)
19:24:41 <ezzieyguywuf> ski: (still confused)
19:25:11 <ezzieyguywuf> monochrom: so is the `type` alias strictly only useful for defining my type signatures?
19:25:43 <ski> `type' just introduces an abbreviation, a synonym, for an existing type
19:25:50 <monochrom> It is strictly alias, synonym.
19:25:52 <koz_> ezzieyguywuf: Think of it like a C typedef.
19:25:54 <ezzieyguywuf> just for the type, nothing about constructors
19:25:59 <ski> it doesn't meddle with how you construct, and inspect, valus of that type
19:26:00 <monochrom> yes
19:26:10 <ezzieyguywuf> I guess I could do a newtype if I wanted it's own constructor
19:26:17 <ski> yes
19:26:22 <ezzieyguywuf> cool
19:27:01 <monochrom> newtype still doesn't change Just to MyJust, Nothing to MyNothing.
19:27:35 <monochrom> Instead, "newtype X a = Ctor (Maybe a)" boringly changes Just x to Ctor (Just x), Nothing to Ctor Nothing.
19:27:49 <monochrom> It's pretty disappointing really.
19:29:34 <ski>   spec = do
19:29:37 <ezzieyguywuf> But if you have a `newtype Vertex a = Vertex Glue (Geo.Point a) Topo.Vertex`, then it should make the code easier to read, i.e. with also `newtype Edge a = Edge Glue (Geo.Curve a) Topo.Edge`
19:29:50 <ski>       describe "emptyWorkspace" $ do
19:29:54 <monochrom> Syntax error.
19:30:02 <ski>         foo
19:30:10 <ski>       describe "addVertex" $ do
19:30:17 <ski>         bar
19:30:20 <crestfallen> sorry back to basics if I may: first, is line 13 correct or is that backwards?  http://ix.io/2o52
19:30:20 <ski>         baz
19:30:44 <ski>     where
19:30:45 <ezzieyguywuf> ah, sould be describe "nullEntity" anyways, lol.
19:30:56 <ski>     foo = ...
19:31:05 <ski>     bar = it "Adds a single Vertex to the Entity" $
19:31:14 <ski>             length vs `shouldBe` 1
19:31:21 <ski>       where
19:31:32 <ski>       vs = E.getVertices (E.addVertex nullE p)
19:31:37 <ezzieyguywuf> ski: can you maybe dump this in a pastebin?
19:31:40 <ski>       p  = Geo.makePoint 0 0 0
19:31:43 <ezzieyguywuf> having a hard time following along.
19:31:45 <ski>     baz = ...
19:31:52 <ski> that's all
19:32:14 <ezzieyguywuf> oh wait I think I get it
19:32:39 <ski> as for (b), that's up to you, your personal taste and judgement
19:32:50 <ezzieyguywuf> I guess back to my second question "would I want to do that", I'm not sure that's any more readable than just using let
19:34:37 <monochrom> :)
19:35:04 <ski> crestfallen : i don't understand the question
19:35:33 <monochrom> Yes, if the definition is too far away from the use site, especially for use-once definitions, that could be hard to follow.
19:35:55 <ski> ezzieyguywuf : `newtype' data constructors must take exactly one argument
19:36:03 <ezzieyguywuf> womp womp.
19:36:14 <ezzieyguywuf> guess I'm back to data
19:36:21 <ezzieyguywuf> which actually makes sense
19:36:26 <ezzieyguywuf> i think
19:36:43 <monochrom> And especially for use-once definitions whose whole point is to organize would-be-too-long expressions.
19:36:44 <ski> or `newtype Vertex a = MkVertex (Glue,Geo.Point a,Topo.Vertex)'
19:37:20 <crestfallen> ski it's a comment that says (+) isn't invertible, but (,) is. Isn't the tuple the one that isn't invertible?
19:37:23 <ski> crestfallen : what you do mean / have in mind, when you say "invertible" ?
19:38:01 <crestfallen> it was a word used by a member today. no opinion yet..
19:38:47 <monochrom> ski: In the sense that from 5 I don't know whether it came from 1+4 or 2+3, but from (2,3) I know it came from (,) 2 3
19:39:04 <monochrom> This was fog's perspective.
19:39:10 <ski> you could say that if you compute `m + n', then you can't recover `m' and `n' from the sum. since the sum may be equal to `k + l', where `k' is different from `m' and `l' is different from `l'
19:39:59 <monochrom> The overall goal was understanding the [] applicative as a model of nondeterminism.
19:40:07 <crestfallen> oh so it means invertible from the result to looking back at the function.
19:40:13 <ski> e.g. `2 + 3' is equal to `4 + 1'. so you can't match `5' on `m + n', since it's ambiguous what `m' and `n' would become. one alternative is `m = 2' and `n = 3'. another is `m = 4' and `n = 1'. and there's more alternatives, of course
19:40:15 * hackage haskell-src-exts 1.23.1 - Manipulating Haskell source: abstract syntax, lexer, parser, and pretty-printer  https://hackage.haskell.org/package/haskell-src-exts-1.23.1 (DanBurton)
19:40:28 <monochrom> Then I don't know why, but somehow this notion of "do you know where each answer came from" popped out.
19:40:36 <monochrom> err, s/popped out/popped up/
19:40:49 <ski> monochrom : oh. i didn't see that discussion
19:41:21 <monochrom> Generally when nondeterminism is discussed, no one cares about recording histories, so I don't know why they would discuss it at all.
19:41:28 <crestfallen> so once it's resolved, you can't 'convert' back to see how the results were computed.
19:41:44 <ski> crestfallen : but if you call `(,)' on `2' and `3', you get `(2,3)', and you can't get that result by calling `(,)' on anything else than `2' and `3'. so, yes. in that sense, `(,)' (but not `(+)') is invertible
19:42:16 <crestfallen> yes I see thanks a lot. so if I may..
19:42:37 <crestfallen> the part at the bottom of the paste
19:43:03 <crestfallen> what would A look like there in f :: A -> [B]     ?
19:43:14 <crestfallen> I figured that would need to be a list
19:43:38 <ski> crestfallen : btw, if you want to, you could write a function `unAdd :: Integer -> [(Integer,Integer)]' so that `unAdd o', for `o' a non-negative integer (aka a natural number), you compute all pairs `(m,n)' of natural numbers, satisfying `m + n = o'
19:43:51 <ski> iow, the function would "split a number in every possible way"
19:44:09 <monochrom> I would rather prefer to discuss how (,) is a product and (+) is a non-product pushout. Equivalently, how they're both pushouts but (,) uses the initial object so it's of the free kind. >:)
19:44:50 <crestfallen> I see, so unAdd is also non-deterministic?
19:45:05 <ski> `unAdd' would represent a non-deterministic computation
19:45:22 <crestfallen> yes that's cool
19:45:30 <ski> (or more specifically, `unAdd o' would)
19:45:37 <crestfallen> interested in monochrom 's comments...
19:46:02 <ski> monochrom : not seeing atm how it's a pushout
19:47:28 <ski> crestfallen : i think there's one `concat' too many, in the first definition of `h'
19:47:34 <ezzieyguywuf> ski: is that a comma after Glue?
19:47:36 <monochrom> Hrm, maybe not, I haven't thought it through at all.
19:47:54 <ski> ezzieyguywuf : yes
19:48:45 <ski> crestfallen : also, i think the last definition of `h' should use `>=>', not `>>=' ?
19:48:50 <monochrom> Perhaps I should go for an algebra and corresponding free algebra.
19:49:12 <crestfallen> ski if you want to take a look   https://stackoverflow.com/questions/27265920/what-is-non-determinism-in-haskell    the upvoted entry
19:50:23 <crestfallen> I couldn't figure out how to use inputs and what the functions should look like
19:51:03 <crestfallen> what
19:51:08 <ski> crestfallen : yes, the poster there also have one `concat' too many. also, recheck the last definition (version) of `h', it doesn't use `>>=', which you had in your paste
19:51:08 <crestfallen> 's a pushout?
19:51:56 <crestfallen> ok I thought that was straight beta reduction
19:52:33 <crestfallen> so the inner concat is wrong? ski
19:52:56 <crestfallen> meaning the first one
19:53:04 <ski> crestfallen : you could imagine making a small family relations "database", by defining functions like `childOf :: Person -> [Person]',`parent :: Person -> [Person]'. for simplicity, you can have `type Person = String'
19:53:08 <crestfallen> sorry meaning the second one :(
19:53:09 <ski> crestfallen : either of them
19:53:21 <ski> remove either, doesn't matter which
19:53:34 <ezzieyguywuf> ski: so in your example Vertex a is a tuple?
19:53:39 <ski> s/parent/parentOf/
19:54:03 <ski> ezzieyguywuf : a value of type `Vertex a' would be represented as (or would contain) a triple, yes
19:54:04 <ezzieyguywuf> bc Glue is `data Glue = Glue (Point a) Topo.Vertex`
19:54:13 <ezzieyguywuf> (maybe I'm just being dumb in how I'm setting it up...)
19:54:18 <crestfallen> thanks working ...
19:54:52 * ski has no idea about what these types `Vertex',`Glue',`Geo.Point',`Topo.Vertex' are meant to model
19:55:04 <ezzieyguywuf> so really I _could_ use `newtype Vertex a = Vertex Glue...` right?
19:55:31 <ezzieyguywuf> nah just saying, in your example with the triple, I don't think it works, because Glue has kind * -> *
19:55:34 <ski> only if you have exactly one (possibly compound) type listed after the data constructor there, ezzieyguywuf
19:55:39 <ezzieyguywuf> no, kind * -> * -> *
19:55:46 <ezzieyguywuf> ski: yea, I do.
19:55:56 <ski> oh
19:56:05 <ski> then, maybe what you intended was actually
19:56:22 <ski>   newtype Vertex a = MkVertex (Glue (Geo.Point a) Topo.Vertex)
19:56:24 <ski> ?
19:57:15 <ezzieyguywuf> ski: yes
19:57:19 <ezzieyguywuf> precisely
19:57:27 <ski> crestfallen : anyway, `f' could be `parentOf', and `g' could be `motherOf', and then `h' could be `grandMotherOf'
19:58:34 <ezzieyguywuf> hah, but I see now how even the newtype doesn't really clean up the code like I thought. I still need to explicitly construct Glue. I should probably rethink things...
19:59:29 <ski> crestfallen : if you want to try it, then, in order to not have to write down the concrete family relations as much, you could define a list `parentChild :: [(Person,Person)]' which contains all the pairs `(parent,child)' for specific individuals `parent' and `child' that you're considering
19:59:46 <ezzieyguywuf> this is the context in case you're interested - Since alanna never ended up coming in April, I never ended up responding to this email.
19:59:54 <ezzieyguywuf> lol whoops, wrong paste.
19:59:57 <ezzieyguywuf> https://gitlab.com/ezzieyguywuf/haskellcad/-/blob/Entity/src/Entity.hs#L43
20:00:18 <ski> crestfallen : then, you can define `childOf' and `parentOf', in terms of that list. and then go on to define `grandChildOf',`siblingOf',`ancestorOf' and so on ..
20:02:51 <crestfallen> thanks trying to do it.. ski
20:04:02 <crestfallen> the types are all identical right ski ?
20:04:25 <crestfallen> P -> [P]
20:04:59 <ski> yea, in this example
20:05:57 <ski> anyway, `parentOf' and `childOf' would refer to this list, but the definition of the other family relations should not refer (explicitly) to this list, but only to `childOf',`parentOf' and other family relation functions
20:08:53 <crestfallen> ok hmm
20:12:19 <crestfallen> so h should be named 'relation' ski, which will give a list of all relatives nonDeterministically
20:36:13 <ski> crestfallen : why `relation' ?
20:37:12 <crestfallen> so i.e. if you enter siblingOf value you get all their relations in a list?
20:37:50 <crestfallen> I'm going as deep as grandSon, grandDaughter, sibling
20:38:07 <ski> you'd get a list of all siblings of the particular person you passed as input, yes
20:38:45 <ski> you can also define `cousin', and `sameGenerationAs'
20:39:08 <crestfallen> very sorry I don't know how to go about it
20:39:30 <crestfallen> I'm reading a bartosz lesson on nonDeterm. list monad
20:39:32 <ski> do you see how to define `siblingOf' ?
20:40:01 <ski> mhm, ezzieyguywuf
20:52:46 <crestfallen> sorry ski no
20:55:41 <ski> crestfallen : how about `grandParentOf' ?
20:56:30 <ski> oh, right. to be able to define `grandMotherOf' and `grandFatherOf', you need `motherOf' and `fatherOf', not just `parentOf'
20:56:58 <crestfallen> no... apologies, sadly I cannot implement functions based on types yet.
21:00:10 <ski> crestfallen : well, consider `h = f >=> g' as in that post
21:01:20 <ski> `f' transforms an `A' into a list of `B's. then `g' transforms a `B' into a list of `C's. overall, `h' transforms the `A' into a list of `C's (not a list of lists, because they're concatenated together to a single list)
21:01:31 <ski> crestfallen : do you understant this part ?
21:02:39 <crestfallen> yes like syllogism
21:03:18 <crestfallen> so we won't use 'elem' . I started with that
21:05:12 <d34df00d> Hi!
21:05:43 <crestfallen> its not a logical syllogism my bad ..
21:05:43 <d34df00d> I'm trying to build a stack-based project on OS X and one of its dependencies depends on a C library.
21:05:54 <d34df00d> But it's failing due to dyld complaining "image not found".
21:06:40 <d34df00d> Namely, I'm getting https://bpa.st/3VNQ
21:07:15 <d34df00d> libz3.dylib is in my ~/local/lib, that path is also in extra-lib-dirs in my global stack config, and I even tried setting DYLD_LIBRARY_PATH to that location — to no avail.
21:07:18 <d34df00d> How do I fix that?
21:08:04 <crestfallen> but B ~ C in this case
21:08:13 <ski> crestfallen : well, it is in fact a bit like "If A, then B. If B, then C. Therefore, if A, then C."
21:08:54 <ski> crestfallen : so, what happens if both `f' and `g' are `parentOf', there ?
21:09:40 <crestfallen> then yeah h will return childOf
21:13:48 <crestfallen> we could use a tree structure it seems
21:14:08 <ski> hm, not exactly `childOf'
21:14:32 <ski> but the call structure will be like a tree, yes
21:14:51 <ski> each `A' may generate many `B's, and each of those `B's may generate many `C's
21:15:13 <ski> although, in the case of `parentOf', there should be at most two (known) parents of a person
21:18:56 <crestfallen> so ultimately will any call be of the form h x = concat [g y | y <- f x]     ?
21:19:21 <crestfallen> I just took out the where statement
21:21:03 <ski> well, if you want to, you can phrase that with only a list comprehension, not needing to call `concat'
21:21:33 <ski> and, probably not all the family relations i suggested will be like that. but several could
21:22:11 <ski> do you see how to avoid the `concat' ?
21:23:14 <crestfallen> The monad will use the equivalent of 'join' under the hood?
21:23:24 <ski> > [[y-1,y,y+1] | y <- [-5,5]]
21:23:26 <lambdabot>  [[-6,-5,-4],[4,5,6]]
21:23:30 <ski> > concat [[y-1,y,y+1] | y <- [-5,5]]
21:23:32 <lambdabot>  [-6,-5,-4,4,5,6]
21:23:47 <ski> > [z | y <- [-5,5],z <- [y-1,y,y+1]]
21:23:49 <lambdabot>  [-6,-5,-4,4,5,6]
21:23:56 <ski> do you see how that works ?
21:24:53 <crestfallen> yes z | puts all the calculations in one list
21:26:41 <ski> now, can you imagine
21:27:12 <ski>   [grandMother | parent <- parentOf person,grandMother <- motherOf parent]
21:30:36 <crestfallen> yes thanks kindly ski. I need to work on this and further my landlady is asking something of me. catch you later?
21:31:38 <ski> sure
21:32:14 <crestfallen> thanks take it easy
22:17:14 * hackage rio 0.1.16.0 - A standard library for Haskell  https://hackage.haskell.org/package/rio-0.1.16.0 (MichaelSnoyman)
