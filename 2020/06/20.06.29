00:19:44 * hackage socket 0.8.3.0 - An extensible socket library.  https://hackage.haskell.org/package/socket-0.8.3.0 (LarsPetersen)
01:41:48 <fendor> why does ghci :add only add the last command to the interactive import list?
01:44:50 <Arahael> nshepperd2: Crosscompilation is awesome, I love building stuff on my macOS laptop, and trivially spitting out a windows or linux build.  When it's easy, people use it.
01:45:35 <Arahael> This is the killer feature for Go, imho: GOOS=windows go build; done
01:45:55 <Guest2322> is it possible to use read inside a function? e.g. my code:  map (\(x:y) -> replicate (read x :: Int) y ) (words "1O 1W 1i 1O 1W 1i 1O 1W 1i")
01:47:51 <dminuoso> Guest2322: Absolutely, its just not a very wise idea.
01:48:04 <dminuoso> You should use readMaybe rather, and then use traverse_ rather than map :)
01:48:08 <dminuoso> Err, *traverse
01:48:12 <Arahael> dminuoso: Oh, why?
01:50:06 <boxscape> Guest2322 the reason it doesn't compile is that read takes a String, but you're giving it a Char
01:51:40 <Guest2322> thanks!
01:54:37 <dminuoso> Arahael: because read is partial.
01:56:57 <Arahael> dminuoso: Ah, fair enough.
01:58:07 <merijn> Also, read's performance is god awful
02:04:36 <boxscape> presumably to fix that you'd have to choose something other than readMaybe?
02:04:37 <Arahael> Fair enough, was just wondering if there was something more obvious. :)
02:33:44 * hackage nom 0.1.0.1 - Name-binding & alpha-equivalence  https://hackage.haskell.org/package/nom-0.1.0.1 (gabbay)
02:45:02 <kuribas> is there a faster way than (readMaybe x) :: Maybe Double ?
02:48:56 <jusss> is Either type a kind of ad-hoc polymorphism?
02:49:01 <merijn> There's a bunch of double parsers on Hackage
02:49:47 <jusss> I mean when x::Either String Int, then you can only pass Left (x::String) or Right (x:: Int) in there
02:49:49 <dminuoso> If you just need to read a double in a small setting, readMaybe is probably fine, but read is usually not.
02:52:32 <jusss> Either a b, Either a is a monad, only when a is an instance of monoid, but when a is not an instance of monoid, and Either a is not monad?
02:53:06 <jusss> and what Maybe? when a is not an instance of monoid, is Maybe still a monad?
02:57:51 <kuribas> :i Either
02:58:28 <kuribas> instance Monad (Either e)
02:58:35 <kuribas> no monoid constraint there
02:59:06 <jusss> oh, my fault, I thought it would be same as Writer 
02:59:30 <jusss> :info Writer
02:59:43 <jusss> :i WriterT
03:03:18 <phadej> writer is (a,)
03:05:30 <jusss> Sum type is related to ad-hoc polymorphism?
03:07:48 <kuribas> no
03:07:59 <kuribas> Bool is a sum type, but not polymorphic
03:09:45 * hackage gi-harfbuzz 0.0.2 - HarfBuzz bindings  https://hackage.haskell.org/package/gi-harfbuzz-0.0.2 (inaki)
03:12:08 <fog> updated HFoldable https://gist.github.com/fog-hs/4f0b1c6f05bfaa9b7cb050751e84ec6d
03:12:46 <fog> corrected kind simplification (the compiler is not able to infer the correct kinds...)
03:13:12 <lortabac> thinking of sum types as a form of ad-hoc polymorphism seems quite reasonable to me
03:13:52 <lortabac> with ADT's you can easily add more functions but adding more cases is hard, with type classes it is the opposite
03:14:08 <lortabac> but both can be used to solve the same problems
03:16:58 <sheepfleece> Hello, how can I write effects which return other effects with polysemy? Say I want to write a two-step registration, so that I can call the second function only if the first one is successful?
03:17:30 <sheepfleece> With simple functions I would have just returned `Maybe SecondStep` where SecondStep is a function.
03:18:20 <sheepfleece> Or I could have used phantom variables for that, either way I don't know how to do it in polysemy.
03:22:03 <sheepfleece> Now I just have one effect with firstStep and secondStep functions, but I want to do better, somehow.
03:26:45 * hackage haskell-gi 0.24.2 - Generate Haskell bindings for GObject Introspection capable libraries  https://hackage.haskell.org/package/haskell-gi-0.24.2 (inaki)
03:27:44 * hackage haskell-gi-base 0.24.1 - Foundation for libraries generated by haskell-gi  https://hackage.haskell.org/package/haskell-gi-base-0.24.1 (inaki)
03:37:44 * hackage haskoin-store-data 0.34.2 - Data for Haskoin Store  https://hackage.haskell.org/package/haskoin-store-data-0.34.2 (jprupp)
03:38:44 * hackage haskoin-store 0.34.2 - Storage and index for Bitcoin and Bitcoin Cash  https://hackage.haskell.org/package/haskoin-store-0.34.2 (jprupp)
03:40:44 <nate48423> the american government and denaro are getting my human brain they are able to have me not able to comprehend and change my taste of drinks and food at times. can you please tell your world leaders to help me I am  nathan biernatt if you have questions you can message me
03:43:15 <Arahael> Is that the new bot-spam?
03:53:44 * hackage shake-plus 0.1.8.0 - Re-export of Shake using well-typed paths and ReaderT.  https://hackage.haskell.org/package/shake-plus-0.1.8.0 (locallycompact)
04:09:13 <maerwald> change the taste of drinks? what?
04:11:22 <maerwald> maybe had too many burritos
04:11:37 <maerwald> they start to taste all the same
04:35:19 <maralorn> sheepfleece: When you say "returning Effects" do you mean two different handlers for the same type or do you mean effects with different types?
04:46:40 <sheepfleece> maralorn: effects with different types
04:47:43 <sheepfleece> I want to be able to use the second effect only if the first one allows me.
04:48:29 <sheepfleece> In my case I have a protocol in which I first need to send a Handshake message, and only after that be able to send other messages.
04:49:20 <sheepfleece> Now I have an effect with three functions send, recv, init, but I'd like to split it in two
04:50:00 <sheepfleece> first which initializes the protocol, and allows me to call send and recv of the second one.
04:51:10 <maralorn> sheepfleece: So in practice you have to different Actions one which needs the second effect and one without it? I think I would do this in the businesslogic something like do { initiated <- runInit m; if initiated then runInitiated ma else runUninitiated mb; }
04:52:50 <sheepfleece> Yes, but I don't want to be able to call runInitiated before runInit.
04:54:01 <sheepfleece> runInit :: Env a -> IO (Maybe (Env Initiated)) ; runInitiated :: Env Initiated -> IO ()
04:54:12 <sheepfleece> is how I would have done it w/o effects
04:54:35 <maralorn> sheepfleece: Well I think you can‘t prevent the user from writing a handler to run your effect. But you can maybe write a handler which requires the token?
04:56:51 <maralorn> sheepfleece: That would just be a property of the handler and not of the effect. But that seems fine to me.
04:57:45 <maralorn> Something like runInitiated :: Env Initiated -> Eff (r : Connection) () -> Eff r ()
04:58:06 <maralorn> Sorry, if the polysemy syntax is wrong, haven‘t used it in practice.
04:58:55 <sheepfleece> I thought about hiding (Env a) in interpretators, so a user would only use runInitiated :: (Member Init r) => Sem r () 
05:00:47 <maralorn> sheepfleece: Hm, so just in theory the signature of uninitiated effect could maybe contain a function that is actually an interpreter?
05:01:35 <sheepfleece> I'm not sure I understand? 
05:02:30 <maralorn> sheepfleece: I think your idea is nice. But I think it just shifts the point where to "prove" that you are allowed to run the effect.
05:04:33 <sheepfleece> Ah, I haven't tried writing interpreters yet, maybe it will work, thank you! 
05:04:44 <sheepfleece> I'll try writing an example now.
05:07:50 <maralorn> Your runInitiated requires r to contain Init. So you will need another function to put Init into r. And this other function (which I guess will be an interpreter) will need to confirm it is allowed to put Init in there. I can think of two general ways to do that. a) via a Token generated by "init" or b) via "init" itself running the effect.
05:11:46 <maralorn> For b) your "Uninitiated" effect would maybe need to contain something like "init :: Uninitiated (forall r. Eff (Init : r) a -> Eff r a)"?
05:12:47 <maralorn> But this is just wild guessing. I have to repeat, that I have never written a working line of polysemy code.^^
05:28:50 <sheepfleece> Polysemy is scary, I have no idea how to proceed from here https://paste.debian.net/1154350/
05:29:57 <sheepfleece> I guess I just can't because I would need to thread the effect itself.
05:29:59 <sheepfleece> Like here
05:30:01 <sheepfleece> runInit :: Env a -> IO (Maybe (Env Initiated)) 
05:31:50 <sheepfleece> Maybe tokens with CPS? Like ST monad? 
05:32:23 <maerwald> does `reverse . dropWhile p . reverse` fuse? 
06:14:10 <AWizzArd> How can I unlift this?  https://gist.github.com/ath/f5d9ee3d1d6dde10f9658e17986b967c
06:15:12 <AWizzArd> I could add a new field to the `Context` in which I store the function (SMTPConnection -> IO a) – but this woudl look ugly to me.
06:15:17 <dminuoso> AWizzArd: Either you drop the ExceptT, or you have to use MonadBaseControl
06:15:41 <dminuoso> AWizzArd: I personally opted to drop the ExceptT in my servant apps, and catch it in the hoisting
06:15:47 <dminuoso> That way you get full unliftio access
06:17:02 <AWizzArd> dminuoso: and does that mean that you can only do a generic "catch all" in the hoisting part?
06:17:19 <dminuoso> AWizzArd: Yeah. Like this: https://gist.github.com/dminuoso/48df2957aea199c9dbbcd00aba9fcc04
06:17:41 <dminuoso> (I've then decided to just throwIO the ServantError instead.
06:19:44 <AWizzArd> We have spread tons of throws already in the code base. I will first have a look at what MonadBaseControl is good for.
06:20:21 <merijn> AWizzArd: It's good for confusing everyone looking at it ;)
06:20:33 <dminuoso> It's precisely for what you want, but the semantics are messy and hard to grasp.
06:21:01 <AWizzArd> Hallelujah :-)
06:21:11 <dminuoso> MonadUnliftIO is the much cleaner variant of it
06:21:25 <dminuoso> But it only works for ReaderT/isomorphic-to-readert based stacks.
06:21:49 <AWizzArd> dminuoso: And mine isn’t ReaderT based?
06:21:56 <dminuoso> AWizzArd: It has ExceptT in it
06:22:22 <AWizzArd> And the ExceptT is deeper, and that’s the problem?
06:23:30 <dminuoso> AWizzArd: Well, the problem is essentially related to primitives like `bracket`.
06:23:56 <dminuoso> And lack of control transfer.
06:25:32 <dminuoso> With ExceptT and StateT for example you have additional "state" that you'd have to throw away
06:27:18 <dminuoso> So either you try and find an elaborate way to capture and restore the monadic state (which is what MBC tries), or you restrict yourself to monad transformer stacks that dont add monadic state (which is what unliftio does)
06:27:21 <AWizzArd> I see. So you get rid of it in the first place.
06:27:28 <dminuoso> Right
06:27:45 <AWizzArd> Damn :)
06:27:59 <AWizzArd> Unexpected work lies ahead.
06:28:03 <Cheery> hmm lets see
06:28:04 <AWizzArd> Thanks for the tips.
06:29:04 <Cheery> are you writing a mail transfer agent?
06:29:25 <Cheery> or smtp service
06:29:38 <AWizzArd> Cheery: we just want to send out mails when somebody enters data in the web frontend, in the contact form.
06:31:13 <dminuoso> AWizzArd: You could go a different route then.
06:31:32 <dminuoso> You could just keep a TQueue, and you just shove the notification in there, and have a separate thread just pop it off.
06:31:42 <dminuoso> That way you can keep your ExceptT in your servant app
06:32:22 <dminuoso> Just as an option to consider.
06:33:03 <Cheery> AWizzArd: what kind of scenario is it? Does the frontend need to know whether the mail was actually sent?
06:33:05 <AWizzArd> dminuoso: sounds good, indeed
06:33:18 <AWizzArd> Cheery: not too important
06:34:00 <AWizzArd> Could be a queued service, or dockerized into its own microservice. 
06:34:24 <Cheery> good. It'd be probably quite hard to do besides. I remember the mail transfer actually sends you back a mail if the mail is not received.
06:34:47 <AWizzArd> Cheery: possibly even with a big delay
06:34:50 <dminuoso> AWizzArd: Actually, you can also just use it in your handlers.
06:35:07 <dminuoso> Chances are, you dont need the monad stack in your withSMTP thing.
06:35:37 <dminuoso> (Because why would you want to abort with a HTTP error right in the middle of your mail routine)
06:35:43 <Cheery> the next question is when does the mail send happen?
06:38:05 <AWizzArd> dminuoso: currently we call this directly and use liftIO. But we want to remove MonadIO from the constraints.
06:39:05 <dminuoso> It's a library function, why do you want to get rid of it?
06:39:24 <dminuoso> (You can just write a simple `sendMail :: Mail -> App ()` that internally uses liftIO as well)
06:39:28 <AWizzArd> We want to test the handler.
06:39:38 <AWizzArd> So no liftIO.
06:39:54 <AWizzArd> During the test we "send" the mail into a TVar.
06:40:07 <dminuoso> fair enough
06:40:10 <AWizzArd> We _want_ to do this, but aren’t doing it yet.
06:40:21 <dminuoso> I dont think ths is related to liftIO though
06:41:03 <dminuoso> If you use `class SendMail m where sendMail :: Mail -> m ()` with some `instance SendMail App` and `instance SendMail Mock`, then the first instance can use liftIO
06:42:00 <AWizzArd> dminuoso: yes, also a good option, probably the best
06:43:49 <dminuoso> AWizzArd: I mean you're already there, you just assumed you had to mimic the continuation passing style.
06:44:07 <AWizzArd> yes, I think I understand this now
07:01:14 * hackage wai-saml2 0.2.0.0 - SAML2 assertion validation as WAI middleware  https://hackage.haskell.org/package/wai-saml2-0.2.0.0 (mbg)
07:05:14 * hackage language-dickinson 0.1.0.0 - A language for generative literature  https://hackage.haskell.org/package/language-dickinson-0.1.0.0 (vmchale)
07:35:14 * hackage lifted-async 0.10.1.1 - Run lifted IO operations asynchronously and wait for their results  https://hackage.haskell.org/package/lifted-async-0.10.1.1 (MitsutoshiAoe)
07:40:21 <NewToHaskell> Hello, could someone answer a question of mine? 
07:40:47 <mmaruseacph2> please ask question directly
07:41:25 <NewToHaskell> https://imgur.com/a/mWq6xtU
07:41:41 <NewToHaskell> Or should I paste the code? its a simple question
07:42:56 <mmaruseacph2> paste is usually better as then text is selectable and greppable
07:43:33 <mmaruseacph2> what is the question though?
07:43:43 <NewToHaskell> sumOfAllOddSquares xs = sum (filter' odd (map (^2) xs))
07:43:58 <NewToHaskell> So this function sum all odd squares in a list 
07:43:58 <mmaruseacph2> oh, I see it
07:44:20 <mmaruseacph2> :t ($)
07:44:21 <lambdabot> (a -> b) -> a -> b
07:44:30 <NewToHaskell> I wonder if we can call it like sumOfAllOddSquares' = sum (filter' odd (map (^2) )
07:44:44 <NewToHaskell> partially applied function 
07:44:49 <NewToHaskell> since filter takes a list
07:44:59 <mmaruseacph2> if you have `f (g (h x))` you can also remove parantheses using `$`: `f (g $ h x)` and then `f $ g $ h x`
07:45:06 <mmaruseacph2> :t (.)
07:45:08 <lambdabot> (b -> c) -> (a -> b) -> a -> c
07:45:23 <mmaruseacph2> and then `f $ g $ something else` is `f . g $ something else`
07:45:34 <mmaruseacph2> so now you get to `f . g . h $ x`
07:45:37 <NewToHaskell> no idea what $ or . means
07:45:39 <mmaruseacph2> and then you remove the `$ x` part
07:45:53 <mmaruseacph2> `f $ x = f x`
07:45:58 <mmaruseacph2> that's the definition
07:46:21 <mmaruseacph2> it just binds more tightly than parantheses so it can remove `(` and `)`, as in the example above
07:46:42 <mmaruseacph2> `.` is the function composition `(f . g) x` is the same as `f (g x)`
07:47:50 <Cale> NewToHaskell: One thing I'll say is that sum (filter' odd (map (^2))) won't work because map (^2) is a function, but filter' odd wants a list
07:48:12 <Cale> NewToHaskell: But yeah, you can use function composition to express what you want without needing to mention the argument
07:49:16 <NewToHaskell> That I know, I wonder if there is a solution to that or if my sumOfAllOddSquares xs = sum (filter' odd (map (^2) xs)) is the way to do it
07:50:56 <Cale> Usually, I'd just go with something like what you've got, but yeah, there's the option of writing  sumOfAllOddSquares = sum . filter' odd . map (^2)
07:52:44 * hackage wai-saml2 0.2.1.0 - SAML2 assertion validation as WAI middleware  https://hackage.haskell.org/package/wai-saml2-0.2.1.0 (mbg)
07:56:43 <NewToHaskell> Cale: Oh that's what I was looking for, thanks for helping me out. =)
07:57:35 <mmaruseacph2> that's what I said above too :P
07:59:58 <Cale> I'm torn on whether to mention the monomorphism restriction :P
08:03:19 <ezzieyguywuf> hm, if I'm using TMVar and ":reload" in ghci to see changes to my code, weird things seem to happen
08:03:32 <ezzieyguywuf> I have to exit/reenter ghci before I can truly see if my changes fix issues
08:03:34 <ezzieyguywuf> is this normal?
08:03:54 <dminuoso> "weird things seem to happen" is rather non-specific
08:04:43 <kuribas> ezzieyguywuf: maybe you want this?  https://hackage.haskell.org/package/rapid
08:05:16 <ezzieyguywuf> dminuoso: yea, I can't really pin my finger on the "weird things", I just know I spent 30 min trying to troubleshoot a problem that was actually already fixed, but I had to restart ghci to see it
08:05:55 <ezzieyguywuf> kuribas: maybe.
08:06:17 <Cale> ezzieyguywuf: Note that if you reload in ghci, your existing threads will continue to run
08:06:35 <ezzieyguywuf> Cale: maybe that's it? How do I kill all threads?
08:06:40 <ezzieyguywuf> I was using ctr+c to bail out
08:06:59 <Cale> Restarting ghci is easier than any of the other options (which mostly involve keeping track of all the ThreadIds you got)
08:07:38 <ezzieyguywuf> I'll just do that then
08:07:44 <ezzieyguywuf> and try to keep this forking to a minimum...
08:07:51 <ezzieyguywuf> thanks all!
08:11:42 <Cale> ezzieyguywuf: Depending on what you're doing, using the async library (and especially withAsync) might also help a bit, since that gives you a way to automatically have child threads killed when an exception is thrown in the parent
08:13:16 <Cale> I've always felt a bit strange about using async in cases where my threads are not trying to compute some result, but it's actually pretty useful in nearly all cases, just because of the extra thread management stuff it does.
08:14:59 <nootnoot> Does anyone know what dependency i need to use the command "create_xpm_icon" in this script? https://github.com/jaor/xmobar/issues/239#issuecomment-233206552
08:19:46 <kuribas> let's say I have a REST API endpoint with filters.  I have a datatype for each filter, and a meta-endpoint which describes each filter.  How can I ensure the meta-data is consistent with the filters?
08:20:31 <kuribas> Should I use each filter as a key, using a GADTs, then I can enumerate it for the meta-endpoint?
08:20:54 <kuribas> Or is there a simpler way?
08:21:38 <kuribas> Or keep it simple and use quickcheck to check for consistency.
08:24:46 <sm[m]> Gday all. So yesterday I was trying to figure out why the cabal user guide did not look quite so out of date as I remembered for the day before. I was of course looking at different versions; the one linked on haskell.org, and the up to date one at readthedocs.io. This is horrible, perhap a cabal dev would like to fix it ?
08:25:18 <merijn> sm[m]: I recall there's already an issue about making a redirect on the haskell.org site
08:25:31 <merijn> But that's something the haskell.org admins need to do
08:29:58 <sheepfleece> Oh, oh, can I somehow use Control.Concurrent with polysemy? `concurrently` and the like all require an IO monad.
08:31:25 <sm[m]> merijn: any idea who could solve this conundrum ?
08:33:34 <sm[m]> I suppose a pr to haskell.org would be a start
08:35:09 <hololeap> how would I make this work using DeriveVia? http://dpaste.com/1BQYT00
08:35:14 * hackage mpi-hs 0.7.2.0 - MPI bindings for Haskell  https://hackage.haskell.org/package/mpi-hs-0.7.2.0 (eschnett)
08:36:54 <NewToHaskell> Is it bad practice to write code like this in functional programming?
08:37:42 <NewToHaskell> `collatzSeq :: Int -> [Int]
08:37:52 <NewToHaskell> ´sumCollatzSeq = length . collatzSeq´
08:38:00 <NewToHaskell> `sumCollatzSeq = length . collatzSeq`
08:38:45 <NewToHaskell> --Given a number n, if n is even we divide it by two else multiply it by 3 and then add 1
08:39:34 <hololeap> Is there no Coercible instance from `data T = T { _tA :: A, _tB :: B }` to `(A,B)` ?
08:40:33 <merijn> hololeap: Why would there be?
08:41:13 <hololeap> because they are isomorphic and have the same structure?
08:41:28 <lortabac> hololeap: I saw this proposed somewhere
08:41:50 <lortabac> apparently it is more difficult than it seems
08:41:57 <merijn> hololeap: Define "same structure"
08:42:24 <hololeap> if we looked at the Generic reprensentation of both, they would be identical
08:42:35 <merijn> hololeap: Coercible is for safely coercing things that have the exact same runtime representation (i.e. newtypes), there's no real reason to expect it to coerce different datatypes that happen to be isomorphic
08:43:04 <merijn> hololeap: So? Does that automatically mean their runtime representation is the same? I don't see why it should/is required too
08:43:08 <lortabac> TBH the idea is not unreasonable
08:43:27 <merijn> lortabac: If you first define Coercible to be something else than it currently is, it may be reasonable
08:43:42 <merijn> lortabac: But then we'd need to invent a new name for the current meaning of Coercible.
08:44:00 <merijn> lortabac: So I think "it's reasonable to have something that supports this, but Coercible is not that thing"
08:44:07 <merijn> And also, that thing doesn't currently exist
08:44:25 <hololeap> i just want to derive Semigroup for T like I would be able to for `newtype T' = T' (A,B)`
08:44:46 <sm[m]> why are there both haskell and haskell-infra organizations on GitHub ? Is there a clear rule for choosing one or the other ?
08:45:07 <lortabac> the fact that I've heard this proposed several times is a hint that this "thing" somehow resembles Coercible
08:45:29 <merijn> sm[m]: haskell-infra is the the organisation for, well, the haskell.org infrastructure :p
08:45:32 <glguy> haskell-infra is the subset of stuff providing infrastructure. Most users won't need that code.
08:45:33 <lortabac> so it is not that crazy to modify Coercible to include this kind of coercions
08:45:48 <glguy> It's for running the actual haskell.org services, builds, website, etc
08:46:27 <sm[m]> I’m trying to figure out where the /cabal part of haskell.org comes from
08:47:14 <sm[m]> I think maybe haskell/Cabal/Cabal/doc
08:47:44 <sm[m]> no..
08:48:33 <hololeap> NewToHaskell: it isn't clear to me what your code does... which can be considered a bad practice in itself ;)
08:48:52 <lortabac> hololeap: there is a package called generic-deriving, maybe it helps?
08:50:04 <hololeap> it looks... interesting, but you have to use classes like GSemigroup instead of Semigroup
08:50:26 <sclv> sm[m]: https://github.com/haskell/cabal-website/
08:51:02 <sclv> feel free to make a pr to the readme.md to point this out, its very not discoverable
08:51:02 <ezzieyguywuf> async does look handy - what would the a situation in which one _wouldn't_ want to use async?
08:51:14 * hackage goldplate 0.1.1 - A lightweight golden test runner  https://hackage.haskell.org/package/goldplate-0.1.1 (JasperVanDerJeugt)
08:51:30 <sm[m]> there it is, thanks sclv
08:51:57 <sclv> also there’s a bunch of untriaged tickets for it in the main cabal tracker :-/
08:52:01 <ezzieyguywuf> hm, I guess it uses MVar, not STM
08:53:15 <dmwit> NewToHaskell: Personally that looks fine to me, though "sumCollatzSeq" is a funny name given that it doesn't sum the Collatz sequence. ^_^
08:53:24 <sm[m]> sclv: how does user-guide in this repo relate to Cabal/doc in the Cabal repo ?
08:53:55 <sclv> the latter is the manual — the readthedocs/docbook stuff, iirc
08:54:03 <hc> hmm, fortunately haskell's async has nothing in common with many other languages' async
08:54:47 <ezzieyguywuf> hc: I'm familiar with async being a single-threaded, poll-type of 'concurrency' whereas haskell seems to actually fork new threads for you
08:54:50 <ezzieyguywuf> which is nice
08:55:01 <ezzieyguywuf> (unless I don't actually know how async works in other languages ^_^)
08:55:05 <hc> ezzieyguywuf: in other languages it's just a hack around the language's limitations (imho)
08:55:19 <hc> ezzieyguywuf: in haskell it actually makes things easier for you that were already possible without async
08:55:27 * ezzieyguywuf nods
08:55:33 * ezzieyguywuf wonders about python async
08:55:58 <hc> I recently had to use rust's async stuff and that was one of the moments where I longed to do a haskell project again *g*
08:56:25 <ezzieyguywuf> I thought rust was supposed to be pretty capable with that sort of thing
08:56:36 <ezzieyguywuf> "OOP when you need it, FP when you want it"
08:56:59 <hc> Yeah, but since rust doesn't have green threads, doing async in it is just as painful as in JS&co
08:57:08 <hc> s/green threads/preemptive green threads/
08:57:52 <ja> preemptive means that it can switch tasks even when you don't do IO?
08:58:15 <hc> Preemptive means it doesn't need the "cooperation" from your code to be multithreaded
08:58:22 <hc> i.e., doesn't require you to clutter your code with uglyness
08:58:27 <ezzieyguywuf> hrm, interesting, TIL what a green thread is
08:58:29 <merijn> Haskell threads are kinda preemptive
08:58:33 <merijn> not really, though
08:58:43 <hc> Yeah, but most of the uglyness is abstracted away :)
08:58:46 <merijn> ezzieyguywuf: It's kinda old terminology that went out of fashion and then came back :)
08:59:09 <ezzieyguywuf> hah, yea the wiki mentions Java as the originator of the name.
08:59:19 <hc> Basically, the last time I had to deal with this kind of thing was when I wrote code for windows 3.11. If you didn't yield from time to time, the whole system would freeze until your computation was done
08:59:21 <merijn> Yeah, it was a Sun thing
08:59:23 <ja> i don't think the problem with pythons async is that it is not preemptive... the problem is that the official async/await library is not very good and alternatives are incompatible.
08:59:44 <ja> but i was never cpu bound anyway, so ...
09:00:09 <merijn> ezzieyguywuf: Basically, most/all blocking IO operations are implemented as primitives in the RTS and instead of really blocking the RTS has a central event manager tracking all events and whose waiting for them
09:00:12 <hc> Actually, cpu intensive things is where "that" async approach fails anyway
09:00:46 <merijn> ezzieyguywuf: So your thread blocks and gets unscheduled so other forkIO threads can run, when the IO is done (network data arrives, file data was read, etc.) the thread unblocks again
09:00:52 <ja> what is 'that' approach? task switch on yield/await?
09:00:57 <hc> ja: yes
09:01:12 <hc> ja: If you use that, you'll need to move cpu intensive code to a threadpoool
09:01:17 <merijn> ezzieyguywuf: The event manager itself is implemented using async IO (kqueue/epoll/select/etc. depending on what your platform supports)
09:01:58 <merijn> ezzieyguywuf: So the practical behaviour is similar to having a single event loop of async IO, except in the Haskell threads you can pretend it's all just blocking and not worry about the details
09:02:08 <hc> this. :)
09:02:50 <merijn> ezzieyguywuf: Which means you just write your "dumb" blocking IO code and let the event manager sort it out
09:03:07 <ja> but if i do IO in FFI's, it won't work?
09:03:13 <hc> s/dumb/not cluttered with "unrelated" logic/
09:03:15 * hackage derive-lifted-instances 0.2 - Derive class instances though various kinds of lifting  https://hackage.haskell.org/package/derive-lifted-instances-0.2 (SjoerdVisscher)
09:03:23 <hc> ja: afaict that depends whether you declare your ffi as safe or unsafe
09:03:37 <merijn> ezzieyguywuf: And since forkIO is much more lightweight than an OS thread you can easily have like 10k threads on the average dev machine and 100k would be doable on a beefy server
09:04:08 <ja> does forkIO work on windows too?
09:04:28 <hc> yup
09:04:37 <hc> It's pretty much OS independent afaik
09:04:44 <ja> oh great, i remember something about haskell IO on windows not being the best
09:04:44 * hackage free-functors 1.1.2 - Free functors, adjoint to functors that forget class constraints.  https://hackage.haskell.org/package/free-functors-1.1.2 (SjoerdVisscher)
09:04:55 <ja> it doesn't use completion ports, does it?
09:04:57 <hc> Those are related, though different issues :)
09:06:44 <sm[m]> https://github.com/haskell/cabal-website/issues/8 seems to be the issue for fixing haskell.org cabal user guide links, please reply if you can help with www.haskell.org config
09:06:52 <hc> ja: no idea. Probably the #ghc channel knows more
09:07:18 <ja> i will enter that channel one day when i feel worthy :O
09:07:50 <sm[m]> hehe nice ja
09:08:29 <hc> ja: given that much haskell research is sponsored by microsoft, I'd consider it less than zero probability that such windows specific APIs are implemented... but... no idea :)
09:19:25 <ezzieyguywuf> merijn: thanks for the primer.
09:23:43 <Cheery> I've wondered about teaching haskell few times, because it's getting obvious that I may have figured an approach that's a bit different than usual.
09:24:47 <Cheery> it starts with interpreting program as a plan.
09:25:26 <Cheery> or in terms of game semantics, it's a strategy to "win" in some arena described by the type.
09:26:59 <Cheery> therefore proof search, such as in prolog, is also such search of a strategy into successfully carrying some interaction.
09:27:22 <Cheery> that you can directly use to construct haskell programs.
09:32:23 <ezzieyguywuf> what does ghcid do when it 'reloads'
09:32:41 <ezzieyguywuf> i.e., if I had it call `:main` upon succesful compile, how does it kill main?
09:32:50 <Cheery> I'm guessing it just reads the file again and typechecks
09:32:57 <Cheery> but we can read the source
09:33:39 <ski> Cheery : in anyway related to ILP ?
09:34:03 <sheepfleece> If we give away `local` function from Reader, and if we are not averse of using unsafePerformIO we can get a global variable which scope we then can limit with some type level hackery. 
09:34:09 <Cheery> ski: ILP?
09:34:10 <sheepfleece> This way we don't need to thread our Reader anymore, which is nice.
09:34:13 <sheepfleece> Is this even worse considering?
09:34:15 <ski> Inductive Logic Programming
09:34:26 <Cheery> that's a new one to me
09:34:56 <ski> generating logic programs, from a set of positive and negative facts about the relations one would like to generate definitions for
09:36:04 <Cheery> that sounds quite formal. I think I'll take a look
09:36:28 <ski> it's a kind of machine learning, one could say
09:38:18 <Cale> sheepfleece: Why do that to yourself though? It just makes it a little harder to understand what's going on, and means that if you ever happen upon the situation where you need to run more than one of (what would have been) that Reader, you're out of luck.
09:38:46 <Cheery> ski: it's likely not a new technique by any means, but I think it may be not as mainstream as it should be.
09:39:27 <Cheery> I developed the skill when I was tinkering with logic programs and learned idris
09:40:41 <Cale> sheepfleece: But if ReaderT is your only transformer over IO, I also strongly recommend not introducing it, unless you have a clear plan for how you're going to newtype it and create a new monad with a special meaning.
09:41:36 <ski> Cheery : could you elaborate a bit on it ?
09:41:41 <Cale> Function parameters are not that bad :)
09:43:21 <Cheery> ski: it's kind of programming by grabbing tightly to the curry-howard-lambek correspondence of the language.
09:46:26 <ski> example of how it's type-directed, in a game semantics sense, and how you apply proof search ?
09:46:53 <Cheery> do you want it presented to solve more formal problem, or less formal problem?
09:47:54 <Cheery> for example, lets say we wanted path search, it's quite easy problem because we already know a lot about that subject, it's been chewed through long time ago.
09:48:04 <ski> i'm just trying to understand how your teaching approach would differ
09:48:25 <Cheery> but how do you come up with a method to do path search if it was not chewed through?
09:49:03 <Cheery> you'd ask yourself what do you want exactly?
09:50:49 <Cheery> so we're on guidance here because we already know it, but basically you can see we could think of things in terms of paths we know about, and how do they connect together.
09:51:39 <Cheery> identify that it's certain kind of a graph that is getting formed there. Then you'd ask what kind of path do you want to find?
09:52:43 <Cheery> try to identify some sort of properties you can, eg. it's connected path, or shortest path, eg. it's connected path that's shortest from some node to an another.
09:53:01 <Cheery> shortest meaning, that it makes some sum of weights smallest.
09:54:09 <Cheery> those are things and properties you can model in a language as types.
09:54:38 <ski> with dependent types, at least
09:55:54 <Cheery> so you'd like to find some path, plug it into the type.. your type would now be: 'Path'. Then you'd wonder, what do you need to know before you can start searching for such path? Well, the network where you want to find the path.
09:56:41 <Cheery> the type becomes, given a network, get a path. Then you keep asking those things, eg. does every network have this kind of a path?
09:56:56 <Cheery> if not, then it becomes network -> Maybe path
09:57:34 <Cheery> eg. you'd do things you'd do in dependently typed language every time, but informally.
09:57:46 <ski> mhm .. sounds like an approach for how to formulate relevant types from informal requirements
09:58:24 <Cheery> yup, this could be applied to something simpler, such as building a snake game.
09:58:51 <Cheery> and I think it gets just better with linear types, because you get types that can describe choices and option.
09:59:15 <ski> okay
10:00:28 <Cheery> if you think of such game, it gets presented, and player moves it somehow, and it proceeds in steps.
10:00:56 <Cheery> then you recognize snake, walls, pellet.
10:01:34 <Cheery> they interacting together in certain way, snake consisting of parts that are in order
10:02:02 <Cheery> pellet causing some change to snake when they connect in a gamestep
10:02:18 <Cheery> you can encode lots of that information in types
10:02:58 <EvanR> dependently typed snake game. How to make game programming unfun :)
10:03:33 <monochrom> I think gamedev has always been unfun when it comes to the technical part.
10:07:00 <maerwald> In gamedev, you barely now what you are doing.
10:07:14 * hackage patat 0.8.5.0 - Terminal-based presentations using Pandoc  https://hackage.haskell.org/package/patat-0.8.5.0 (JasperVanDerJeugt)
10:07:37 <EvanR> i resemble that remark
10:15:47 <arianvp> I'm trying to generate coverage report for haskell code but I have a feeling the reports are lying to me
10:16:18 <arianvp> I have an instance   ToJSON Alg where toJSON Blah = Aeson.Number (-7)
10:16:33 <arianvp> and a test that asserts     toJSON Blah === Aeson.number (-7)
10:16:48 <arianvp> but the hpc coverage reports marks  "Aeson.number (-7)" as "Never executed"
10:17:02 <arianvp> whilst this hsould cause 100% coverage no? Im so confused
10:19:40 <arianvp> aha no; there's a bug in my quickcheck generator it seems :)
10:19:50 <Cheery> anyway, just thought about then when was watching this "parking lot system design | object oriented design" -video, then realising the guy is telling to query requirements first.
10:20:07 <Cheery> when summarizing a plan would be likely more effective when somebody asks you to design a parking lot system.
10:20:24 <Cheery> how can you know the person asking about it knows any more of such thing than you do?
10:20:52 <Cheery> well, the law of the internets, present a wrong answer, get the right answer.
10:23:05 <Cheery> then realising it sort of connects to how you'd program it.
10:31:10 <phadej> arianvp: try with -O0
10:32:53 <maerwald> anyone experience with golden tests?
10:33:09 <srk> a bit
10:33:41 <srk> used tasty-golden recently
10:33:47 <srk> there's tasty-silver as well
10:33:56 <halogenandtoast> I wanted a way to describe computations of type (a -> a) that could be "paused", "resumed" and "skipped", so I came up with https://gist.github.com/halogenandtoast/0514c5f3011245d70b101f2eeb84000d and I want to make sure something like this doesn't already exist (and/or there isn't another better pattern). Has anyone come across anything like this?
10:34:52 <sm[m]> and shelltestrunner
10:35:18 <maerwald> I was hoping to use hspec, but it's golden package doesn't compare to tasty's
10:38:34 <maerwald> maybe use both and glue them together with tasty-hspec
10:39:16 <wantingpawer> hi 
10:40:09 <wantingpawer> I'm a complete beginner to haskell, I've been trying to install GHC on my windows computer and I'm getting the error "Error while running 'C:\ProgramData\chocolatey\lib\ghc\tools\chocolateyInstall.ps1'"
10:40:17 <wantingpawer> I was wondering if anyone knows what's up 
10:40:42 <wantingpawer> I'm definitely running in a privileged command prompt 
10:42:13 <halogenandtoast> I don't want to be the guy to say use WSL2 but I'm going to say use WSL2 because it makes everything so much simpler (at least for me on the windows instance I sometimes run).
10:42:57 <halogenandtoast> Unfortunately I can't provide any assistance for chocolatey as I've never gone that route
10:43:56 <maerwald> ghcup supposedly works on WSL, afair
10:44:22 <maerwald> https://gitlab.haskell.org/haskell/ghcup-hs/-/issues/32
10:44:45 <halogenandtoast> wantingpawer: what GHC version are you trying to install?
10:45:03 <justsomeguy> Installing stack is another way to go. It seems a little easier, since you start by running an .exe https://docs.haskellstack.org/en/stable/install_and_upgrade/#windows
10:45:08 <wantingpawer> I haven't specified a version, I just wrote choco install ghc 
10:45:10 <halogenandtoast> or are you just getting the "latest availeble" via choco install ghc
10:45:53 <wantingpawer> I'm getting the latest available 
10:46:17 <wantingpawer> I'm installing the stack thing you mentioned justsomeguy 
10:47:31 <wantingpawer> oh also, haskell-dev installed perfectly fine, it was just ghc, idk if that's of any importance but I might as well mention it 
11:16:21 <NewToHaskell> Can someone help me create a function for the number of moves to complete a Tower of Hanoi game with four rings? Our function should be recursive and be simple.
11:16:31 <NewToHaskell> I've done Tower of Hanoi for three rings here;
11:16:42 <NewToHaskell> `hanoi :: Int -> Int
11:17:21 <halogenandtoast> The number of moves?
11:17:24 <NewToHaskell> Yes sir
11:17:46 <halogenandtoast> 2 ^ n − 1
11:17:54 <monochrom> rings? pegs?
11:17:54 <halogenandtoast> where n is the number of rings
11:18:02 <NewToHaskell> That is for three pegs
11:18:06 <NewToHaskell> I want four pegs
11:18:20 <monochrom> Is it OK if I don't use all 4 pegs? >:)
11:19:00 <Cheery> how to prove it's really giving the right answer?
11:19:19 <NewToHaskell> The sequence of the 10 first should be 1, 3, 5, 9, 13, 17, 25, 33, 41, 49
11:19:31 <NewToHaskell> https://dl.acm.org/doi/pdf/10.1145/126459.126460#:~:text=Since%20at%20least%2018%2C446%2C744%2C073%2C709%2C551%2C615%20moves,before%20i%20t%20was%20completely%20moved%20.
11:20:02 <halogenandtoast> NewToHaskell: sounds like you might want to translate https://pdfs.semanticscholar.org/fb87/0a772baf96a2e11901122a2b04c3dd25596d.pdf
11:20:53 <halogenandtoast> The abstract gives a general solution for a 4 peg hanoi game with n rings
11:25:14 <monochrom> If you want a direct coding, there is one single paragrah you just need in the paper you cited. "An Algorithm for the Four-Peg Puzzle", "We now present our algorithm..."
11:26:12 <Cheery> yup.
11:26:31 <NewToHaskell> Φ, what does that mean in the equation?
11:26:35 <monochrom> Err, nevermind, how to choose k is a long story.
11:27:12 <monochrom> But the rest of the section says how.
11:30:12 <Cheery> what kind of approach the paper takes to it?
11:30:53 <Cheery> the 3-peg solution was just plain induction, then you just count it out.
11:31:49 <halogenandtoast> In the 4 peg case k is n - round (sqrt (2n  + 1)) + 1
11:33:24 <NewToHaskell> Cool, now how would that be implemented recursively? =D 
11:33:33 <halogenandtoast> It might be floor instead or round, not sure
11:33:49 <halogenandtoast> That's not the recursive part
11:34:17 <monochrom> The 1st paragraph is the recursive part.
11:34:21 <Cheery> it can be modeled as shortest path problem, btw.
11:34:29 <monochrom> Gosh, did you read the paper you yourself cited?
11:35:01 <monochrom> The paragraph even uses explicitly the word "recursively".
11:37:03 <monochrom> What code did you actually write for the 3-peg problem anyway?
11:38:00 <monochrom> One would think that if you did not merely write "hanoi n = 2^n - 1", then you would by now have known how to code up the informal "move x discs from peg 3 to peg 2".
11:38:11 <Cheery> I remember you can start the induction by recognizing that the largest platter is always lowest on whatever peg it is on.
11:38:50 <Cheery> therefore the motion "in middle", is always motion of that platter to target peg, unless it's already in place.
11:38:54 <NewToHaskell> `hanoi :: Int -> Int
11:38:59 <NewToHaskell> 3 pegs, n of rings
11:39:21 <monochrom> "3 pegs, n of rings" is not legal Haskell.
11:39:34 * [exa] vaguely recalls constructivism
11:46:46 <Cheery> The motion of the lowest plate means you move all plates over it somewhere else.
11:47:06 <Cheery> then you have to move them back over the plate when you're done.
11:48:18 <Cheery> in 3 peg case, there's only one place where to move them, and it's empty in the start.
11:48:40 <Cheery> well you can consider it empty, because whatever is on it, it's larger than the platter you're moving.
11:49:53 <Cheery> the smallest plate moves in single motion to where it needs to be.
11:50:00 <Cheery> that's the base case
11:51:42 <Cheery> then you got to assume you have a way to move a stack that's smaller by one unit, and you use it to describe how to move a bigger stack.
11:52:40 <Cheery> then apply induction to base case and that thing, you got a method to solve tower of hanoi.
11:53:41 <Cheery> after that the task is to figure whether you can predict how many number of moves it needs, without computing every move.
11:55:03 <Cheery> it's a nice toy to practice formal mathematics. That's probably why it's usually picked up although it's a very damn boring thing once you've figured it out.
11:59:21 <NewToHaskell> Sent a mail to my professor hopefully he can solve it. :)  
12:00:38 <Cheery> I feel like it was left a bit open what was being asked, but it's fun subject anyway.
12:04:16 <monochrom> Unfortunately, some open-ended problems come from people who fish for homework solutions without learning.
12:05:21 <Cheery> people who don't wish to learn what they're going to practice are free humor.
12:12:44 * hackage dobutokO-frequency 0.1.1.0 - Helps to create experimental music. Working with frequencies and types.  https://hackage.haskell.org/package/dobutokO-frequency-0.1.1.0 (OleksandrZhabenko)
12:16:33 <ezzieyguywuf> *sigh* I'm worried I'm adding too much complexity. In order to do openGL stuff in a separate thread, I need to GLFW.makeContexCurrent, but then that means I have to pass around a TMVar of GLFW.Window so that only one thread at a time can make it current. Maybe I should just make my GUI and my TUI two separate things entirely...
12:17:25 <ezzieyguywuf> nah, that's not even it - even if I forget the TUI part, how can I have my main loop *both* accept user-input for, say, moving the camera, while listening for new data that needs to be rendered
12:17:44 * hackage hspec-golden 0.1.0.2 - Golden tests for hspec  https://hackage.haskell.org/package/hspec-golden-0.1.0.2 (stackbuilders)
12:18:29 <[exa]> ezzieyguywuf: what are you trying to achieve btw?
12:19:51 <Cheery> That sounds quite architecture dependent.
12:20:24 <ezzieyguywuf> [exa]: hm. I'm using GLFW to create an openGL context. GLFW also provides callbacks for handling user input.
12:20:59 <ezzieyguywuf> I want my render loop to do two things. (1) listen for new Vertices to draw in the openGL context, (2) use GLFW's poll mechanism to check for user input
12:21:26 <[exa]> ...and the user input in (2) comes from the terminal?
12:22:16 <ezzieyguywuf> the data will eventually come from a TCP socket or something
12:22:36 <[exa]> use a separate green thread (with forkIO) and a TChan
12:23:18 <Cheery> GLFW has no camera motion callback
12:23:33 <ezzieyguywuf> cursorPositionCallback
12:23:40 <[exa]> (perhaps there's an easier variant of the TChan but it should be good for the expected usecase)
12:24:33 <[exa]> (especially if you don't expect your (remote) user to do 10000 actions per second)
12:25:22 <[exa]> mainly, there's no real reason to use the glfw poll if there's the nice polling mechanism right in ghc's RTS
12:25:30 <ezzieyguywuf> Well, right now I have two separate Main, one for TUI and one for GUI, and i'm trying to figure out a good way to smash them together. I was thinking that the user would launch the TUI and then launch the GUI from in there if they want
12:25:42 <ezzieyguywuf> the TUI is the only place (currently) that they can create more data that would need to be rendered
12:26:08 <[exa]> that almost calls for an infix `forkIO` :]
12:26:20 <ezzieyguywuf> [exa]: the glfw poll is for the input though, i.e. mouseEnteredWindow, mouseButtonClicked, etc.
12:26:50 <[exa]> yeah, you need that
12:26:51 <ezzieyguywuf> [exa]: if that was a joke, it went above my head :-P
12:27:09 <ezzieyguywuf> (the infix thing)
12:27:35 <[exa]> ezzieyguywuf: I meant 'Main1.main `forkIO` Main2.main' but the interface is monadic
12:27:36 <ezzieyguywuf> I expect the (eventual) remote user to not do 10000 actions per second
12:27:43 <Cheery> Maybe you should create a little service that communicates with a channel to its user interfaces.
12:28:39 <[exa]> ezzieyguywuf: if the event count is humane, then TChan should be perfect. Mainly it has a tryRead- style function that you can effectively use to poll the input in the rendering loop
12:28:58 <ezzieyguywuf> hm, I see
12:29:00 <[exa]> anyway I'm really not sure how GLFW interacts with the RTS
12:29:48 <ezzieyguywuf> me neither. But I think the concept you've presented is sound. Each loop, (1) glfwPollEvent (let it does what it oes), (2) poll TChan (or TMVar or w/e) for new data - handle appropriately, (3) loop again
12:30:04 <[exa]> but I suspect the poll call might interrupt normal GHC event handling; you might want to put some "maximal poll time" there so it doesn't... say to 1ms
12:30:44 <ezzieyguywuf> [exa]: the glfw poll? It doesn't block. They have a separate `glfwWaitEvent` or some such that _does_ block
12:30:56 <[exa]> oh so, nice
12:30:59 <monochrom> Is this why every video game has like 50% CPU usage even when paused?
12:31:08 <ezzieyguywuf> and they do have a third `glfwWaitForSomeTime` or some such that mostly waits but then bails out after the timer
12:31:19 <ezzieyguywuf> monochrom: yea, I'm trying to avoid that
12:31:32 <ezzieyguywuf> monochrom: but yes. They just max out that `forever` loop and don't look back
12:31:38 <[exa]> monochrom: no that's because kids require realistically shaded pause screen today
12:32:11 <monochrom> But I mean like AoE2 classic CD version around 2000.
12:32:30 <[exa]> oh 2000, good ol'days
12:32:42 <[exa]> when no one cared about powersaving modes
12:32:47 <ezzieyguywuf> lol
12:33:42 <[exa]> still I somehow judge game quality by being able to consume less than a full CPU if it "does nothing"
12:34:08 <monochrom> That's probably more about game engine quality.
12:34:24 <[exa]> quite likely
12:34:37 <monochrom> But yeah I don't understand why CPU usage stays constant.
12:35:17 <ezzieyguywuf> if you don't roll your engine you're not living
12:35:32 <ezzieyguywuf> monochrom: it's exactly the reason you said - loop never stops, even when there's nothing to do.
12:35:34 <[exa]> monochrom: on certain configurations of certain operating systems, doing a syscall may cause a really unprecedented tear in framerate...so game developers usually just busywait
12:35:47 <monochrom> Anyway, busy polling is OK for now. For a more ethical solution, you have to know a lot more about GHC multithreading and/vs FFI etc, it will take a while.
12:36:24 <[exa]> most effective method: just insert sleep(10ms)
12:36:26 <ezzieyguywuf> "busy polling"  being the TChan idea?
12:36:47 <monochrom> the whole loop about poll GLFW, poll TChan, repeat.
12:36:53 <ezzieyguywuf> right
12:37:12 <[exa]> glfw should have some high precision waiting that can hold framerate, right?
12:37:27 <ezzieyguywuf> well, I'm not worried about framerate
12:37:44 <[exa]> threadDelay may be safest
12:37:44 * hackage dobutokO-effects 0.2.0.0 - A library to deal with SoX effects and possibilities  https://hackage.haskell.org/package/dobutokO-effects-0.2.0.0 (OleksandrZhabenko)
12:38:05 <ezzieyguywuf> but if I were, I think the 'right' approach...or rather, the typical game approach, is to keep track of time in your loop, and once enough time has accumulated, call render and reset counter
12:38:20 <ezzieyguywuf> that way physics and stuff can keep going
12:39:10 <[exa]> ezzieyguywuf: I was usually measuring the time before render, time after render, and just called delay(target_frame_time-measured_difference)
12:39:31 <ezzieyguywuf> yikes, sounds like your wasting time there!
12:39:49 <ezzieyguywuf> b/c if you have a ball moving to the right but you delay, it won't move any more
12:40:17 <[exa]> the delay was like a few milliseconds usually
12:40:37 <monochrom> After the delay, you draw the ball at its rightfully new position.
12:40:45 <[exa]> ...no one complained :]
12:41:05 <monochrom> Every motion picture has been doing this.
12:41:19 <ezzieyguywuf> ah, right
12:41:22 <[exa]> syncing to display vblank is a completely different problem though, but don't care about that now :]
12:41:24 <ezzieyguywuf> yea, so you keep track of real time
12:41:29 <ezzieyguywuf> not loop ticks
12:42:07 <ezzieyguywuf> updatePhysics (currentTime - lastUpdate), something like that
12:42:18 <ezzieyguywuf> but that's also not perfect, because if your deltaT is too high you get some weird effects
12:42:32 <[exa]> yeah... also, in haskell you can probably stuff a bit of the garbage-collecting business into the inter-frame delay time, to avoid the gc interrupting you elsewhere... not sure how though. :]
12:42:34 <ezzieyguywuf> *shrug*, i made an incomplete pong once, and had to deal with this, I forgot how I did though :-P
12:44:07 <[exa]> programming hint: use delay(10ms), you can worry about unsubstantial details later
12:44:35 * pong
12:46:44 * hackage calamity 0.1.17.1 - A library for writing discord bots in haskell  https://hackage.haskell.org/package/calamity-0.1.17.1 (nitros12)
12:56:56 <EvanR> updatePhysics (currentTime - lastTime) hurts my soul
12:57:19 <monochrom> Why?
12:59:04 <EvanR> ok, i was assuming it implied you will use the amount as a literal time delta in an integration scheme
12:59:29 <ezzieyguywuf> that's what I was implying
13:00:02 <monochrom> OK, let me spell it out. All of you all along have been assuming a linear model.
13:00:33 <monochrom> But nothing says that your physics engine, or even your integration engine, must assume a linear model. Even though it's bloodily popular.
13:00:34 <EvanR> fun story, 1 supertux used this a long time ago. 2 windows had this feature where the event loop blocked if you dragged the window, freezing the game. 3 you could use this to run through a 1 block-wide wall as you jumped across the collision test
13:00:57 <monochrom> s/must assume/must implement/
13:00:58 <ezzieyguywuf> right!
13:01:06 <ezzieyguywuf> that's why delaying is tough
13:01:39 <EvanR> a better way would be to consume the time delta in a way that produced the same result through time independent of how it's chopped up
13:01:40 <ezzieyguywuf> monochrom: by linear model, you mean linearly interpolatig between ticks?
13:01:45 <monochrom> Yeah
13:01:46 <[exa]> I said _delay_ for the rest of measured time, not update physics every now and then :]
13:01:54 <EvanR> which doesn't have too much to do with linear interpolation
13:02:05 <ezzieyguywuf> I ready a reallly good blog about this once
13:02:39 <[exa]> that being said even delaying is a problem, the usual scheme gets you 2 frames lag with vsync
13:03:01 <EvanR> yeah a random sleep 10ms also hurts my soul for other reasons
13:03:15 <EvanR> has anyone tried this whizbang low latency collector ?
13:03:39 <ezzieyguywuf> this was the one: https://gafferongames.com/post/fix_your_timestep/
13:03:46 <ezzieyguywuf> it's very popular
13:04:05 <EvanR> a fixed time step would fix it, indeed. There might be other ways
13:04:19 <MarcelineVQ> the typical game approach is to call update (i.e the logic and physics) on a fixed schedule but draw as often as possible
13:04:33 <EvanR> ... why
13:04:50 <EvanR> why draw as often as possible, even if it would show the same picture
13:04:53 <ezzieyguywuf> EvanR: for maximum graphical fidelity?!
13:05:00 <ezzieyguywuf> twitch response?
13:05:01 <ezzieyguywuf> *shrug*
13:05:16 <EvanR> or maybe, as often as possible implies "60 Hz"
13:05:38 <ezzieyguywuf> I mean, gaming is a professional sport now. Why does formula one folks design the engine to the point that it won't even start on its own, or idle properly?
13:05:48 <EvanR> lol
13:05:57 <ezzieyguywuf> I think it's a fair analogy
13:06:04 <EvanR> let's not even speak of nascar
13:06:08 <[exa]> play the game or the playstation burns
13:06:39 <ezzieyguywuf> [exa]: lol!
13:06:56 <ezzieyguywuf> I actuall laughed out loud, now my wife knows I'm not actually working :-P
13:07:09 <ezzieyguywuf> EvanR: nascar is supposed to be 'stock' right?
13:07:43 <MarcelineVQ> iiuc it's because drawing tends to include interpolations in various forms so it's not really the same image each draw. and if your loop does end up taking too long (say you're reading the hdd or something) that lets it smooth it out. I wonder if I could find the source I read about that
13:08:14 <ezzieyguywuf> ahh yess, fix your timestep. I really do like the final approach outlined - use actual deltaT unless it's bigger than a certain amount, then once a certain aount of deltaT has accumulated, consume it step-by-step using a fixed, er, step
13:08:26 <EvanR> that might be true for the new 2D interlacing that everyone is raving about
13:08:44 * ezzieyguywuf wonders when he's going to ever delve into the world of raytracing.
13:08:52 <EvanR> ezzieyguywuf: that would still introduce non-determinism
13:09:33 <ezzieyguywuf> EvanR: because of the reliance on system time.
13:09:45 <EvanR> because sometimes you use a smaller random time step
13:09:51 <ezzieyguywuf> but it has the advantage of allowing better systems to do...better
13:09:59 <EvanR> does it?
13:10:00 <ezzieyguywuf> or "better" maybe
13:10:05 <ezzieyguywuf> hah, you beat me too it
13:10:12 <EvanR> your integration scheme can be as fancy as you want while being deterministic
13:10:21 <ezzieyguywuf> I'm sure there's a ceiling after which a smaller timestep doesn't help, due to rounding stuff
13:10:42 <EvanR> integration scheme being better is generally better than using dumber scheme with smaller and smaller steps
13:11:01 <ezzieyguywuf> that seems like some very sage wisdom there.
13:11:17 <EvanR> ya... one day math will make it's way into games
13:11:29 <ezzieyguywuf> ofc, like I said earlier, I'm not writing a game (presently) so issues of framerate and physics and such are currently out-of-scope for this project.
13:11:47 <ezzieyguywuf> though I do expect it will eventually be relevant if I wish to do kinematic simulations.
13:12:50 <EvanR> also "better" depends completely on the target effect, realistic physics isn't always the goal
13:13:41 <EvanR> but quantum tunneling through a wall by hacking the window manager can't be right (famous last words)
13:15:03 <ezzieyguywuf> hah
13:15:09 <ezzieyguywuf> it shouldn't be right at least.
13:17:26 <ezzieyguywuf> hrm, I'm thinking TBChan instead of TChan, just b/c I don't trust myself not to mess it up and use up all my memory.
13:18:26 <monochrom> Then you're exchanging unbounded space for unbounded time.
13:18:52 <ezzieyguywuf> I'd rather tht
13:19:03 <monochrom> Yeah OK as long as you know.
13:19:14 <ezzieyguywuf> it's obvious (I think?) if something is hung up due to a TBChan being full
13:19:29 <monochrom> I just like the poetic parallel "unbounded space" and "unbounded time" :)
13:19:29 <ezzieyguywuf> hrm, or maybe putStrLn "chan is full waiting"
13:19:52 <ezzieyguywuf> i really do need to figure out how I want to do logging, I guess using WriterT somehow
13:22:44 <dsal> MonadLogger isn't too bad.
13:23:18 <dsal> It can log to a Writer, or some sort of IO thing.
13:24:46 * ezzieyguywuf nods
13:40:22 <nshepperd2> unbounded space is where the USS enterprise goes
13:50:07 <merijn> ezzieyguywuf: tbh, WriterT is know for having abysmal performance :p
13:51:29 <glguy> WriterT is known for being misused
13:52:36 <ezzieyguywuf> merijn: well, I haven't delved into the world of logging with haskell yet
13:52:42 <slack1256> Is there any case where the usual WriterT is a great choice?
13:52:49 <ezzieyguywuf> but I do expect to want to do that at some point
13:53:04 <ezzieyguywuf> or maybe logging isn't needed in haskell
13:53:08 <ezzieyguywuf> since things 'just work'
13:53:16 <glguy> slack1256: when you're streaming outputs and the outputs are what drive the process. It's not for logging
13:53:19 <ezzieyguywuf> 🤔
13:53:38 <EvanR> "logging isn't needed" famous last words
13:53:43 <ezzieyguywuf> lol
13:54:19 * ezzieyguywuf dissapears into a cloud of ash. "Be thee forewarned," you hear a booming voice "any who falter shall perish"
13:54:30 <EvanR> what did was have each 'process' (thread) report interesting situations to stderr directly
13:54:37 <EvanR> what i did
13:54:40 <ezzieyguywuf> dang, I kind of want to make an rpg now...
13:55:06 <ezzieyguywuf> EvanR: yea, that's what I'm thining of starting with. Well, stdout, using putStrLn
13:55:16 <ezzieyguywuf> b/c I haven't decided to figure out file handles in haskell yet
13:55:19 <ezzieyguywuf> ^_^
13:56:22 <EvanR> complain :: String -> IO (); complain = hPutStrLn stderr
13:56:40 <ezzieyguywuf> seems easy
13:56:56 <slack1256> glguy: Oh, meant to question whether the classic WriterT is a great choice knowing that it has space leaks by default https://mail.haskell.org/pipermail/libraries/2013-March/019528.html .
13:57:03 <ezzieyguywuf> wifeComplains :: String -> IO (); wifeComplains = hPutStrLn "/dev/null"
13:57:37 <EvanR> type error
13:57:38 <Faye> When I need to do error-handling in Haskell I usually create a type class
13:57:55 <Faye> that's like a custom MonadError type of thing
13:58:04 <EvanR> um... what does this class do
13:58:06 <Faye> and for IO I might implement it as error, or something else
13:58:08 <glguy> slack1256: WriterT would be the wrong choice for a (Sum Int) being accumulated
13:58:21 <ezzieyguywuf> wifeComplains :: String -> IO (); wifeComplains = hPutStrLn (open "/dev/null")
13:58:24 <ezzieyguywuf> maybe
13:58:27 <ezzieyguywuf> I dunno, lol.
13:58:36 <EvanR> another type error
13:58:42 <glguy> WriterT.Strict and .Lazy at least. The .CPS implementation would probably be OK
13:58:49 <ezzieyguywuf> hah, obviously I need to check the docs
13:58:49 <Faye> @EvanR it's just a class that has some basic functionality around like "show this error to the user, I don't care how you do it"
13:58:50 <lambdabot> Unknown command, try @list
13:58:58 <Faye> so like a complain method or something similar
13:59:08 <Faye> a catch method of some sort
13:59:13 <Faye> the reason I like this
13:59:21 <Faye> is because I can hot-swap error-handling methods
13:59:30 * hackage xrefcheck 0.1.2 -   https://hackage.haskell.org/package/xrefcheck-0.1.2 (gromak)
13:59:32 <EvanR> Faye: well... complain is sort of accomplish the task. It can be swapped out for whatever without being a class
13:59:43 <EvanR> ok, it can't hot swap
13:59:55 <EvanR> for that you can pass in a complain function
14:00:06 <Faye> but sometimes I want to use two different types of error-handling
14:00:15 <Faye> and a complain that reports in IO
14:00:19 <Faye> can't be used outside of IO
14:00:38 <EvanR> or can it
14:00:40 <Faye> so if I want a pure method of compiling errors somewhere, say for unit testing, it's hard to do it
14:00:46 <Faye> unsafe IO doesn't exist :3
14:00:47 <EvanR> insofar as "outside IO" isn't a thing
14:01:13 <Faye> This has always seemed the most convenient to me bc it lets me write reusable code
14:01:22 <Faye> that lends itself to testing and stuff well
14:01:50 <Faye> I could probably do the method of passing it as a function in
14:01:58 <Faye> but then I might as well pass all my class definitons in :P
14:02:03 <EvanR> my suggestion would have been used in IO code itself, as part of a threads top level loop
14:02:09 <Faye> sure
14:02:36 <Faye> if you're doing a supervisor thread then that works pretty well
14:02:45 <EvanR> i doubt i could come up with a one size fits all way to pass errors around among a variety of purely functional code (that doesn't produce IO values somehow)
14:02:49 <Faye> but it's still not general in the way I like to write code
14:03:32 <EvanR> also pure code can throw IO exceptions
14:03:48 <Faye> a fact that is lamentable :(
14:04:03 <Faye> head should type as [a] -> Maybe a
14:04:32 <EvanR> well... there is a lot of code the type system can't guarantee won't crash. It won't crash because of a proof you have on this napkin. A napkin that is not checked as development continues
14:04:33 <dolio> That function exists already.
14:04:42 <dolio> It's also usually useless.
14:05:12 <EvanR> rather than reengineer the world to return a Maybe that is supposed to never be Nothing... you could use an IO exception (and supervisor threads maybe)
14:05:36 <Faye> yeah idk
14:05:44 <Faye> and I know it exists dolio
14:07:27 <EvanR> one reason i always run into is, after all the reengineering is done... i have often have no recourse but to use 'error' ... seemingly defeating the purpose of the whole exercise
14:10:45 * hackage haskoin-store-data 0.34.3 - Data for Haskoin Store  https://hackage.haskell.org/package/haskoin-store-data-0.34.3 (jprupp)
14:11:45 * hackage haskoin-store 0.34.3 - Storage and index for Bitcoin and Bitcoin Cash  https://hackage.haskell.org/package/haskoin-store-0.34.3 (jprupp)
14:27:20 <Shiranai> Hello, how would you represent an order (a graph without cycles) as an algebraic data type?
14:27:47 <Shiranai> since any given element could have multiple elements both above and below it I am not sure how to do it
14:37:35 <EvanR> There's graph datastructures in general
14:38:05 <EvanR> but to allow sharing they use node indexes
14:38:28 <EvanR> so arguably not algebraic data
14:39:40 <EvanR> if you don't care about sharing, you can come up with a DSL for constructing such orders, and make the DSL operators into constructors
14:42:19 <taylskid> .
14:51:47 <siiky> hello everyone! what would be the equivalent in Haskell of the `union` in C/C++ ? the closest i see is a sum type, but that's not quite right, because a sum type is represented as a tagged union in C, and also with a union in C, theres no way to know what type the value is (thats why union is mostly useless alone)
14:52:42 <monochrom> No equivalent unless you allow manual tagging.
14:53:05 <monochrom> But even then the space usages don't perfectly match.
14:53:16 <monochrom> There is no perfect equivalent.
14:53:36 <monochrom> Why do you ask?
14:53:37 <[exa]> siiky: the "storage sharing" from C unions does not make much sense in haskell
14:53:46 <[exa]> (neither in C++)
14:54:34 <siiky> monochrom: right, thats what i though... im doing a PA comparing Haskell to C++ functional style, and im writing about data types right now
14:55:55 <siiky> [exa]: im not too interested in how things are represented in memory (for this PA)
14:56:54 <siiky> i was basically saying a struct would be a `data` with several "fields" (maybe even with records), an `enum` would be a `data` of the variants, but then, wth is a union in Haskell? :p
15:02:35 <dolio> Union is an unsafe, worry-about-how-things-are-represented-in-memory construct that can be used to implement sums, in a way that the compiler won't ensure is actually correct.
15:04:21 <EvanR> yeah i'm not sure what a union would be if not a memory thing. 'storage which is big enough but no other defining characteristics'
15:05:04 <infinisil> Is there any reasonable use of untagged unions in C/C++?
15:05:26 <infinisil> I feel like the only way you can make use of them if you slap tagging on top
15:05:37 <dolio> There are union types, but they don't really work like C.
15:06:46 <dolio> They go with intersection types, and the point is that they're similar to parametric polymorphism.
15:06:59 <siiky> the only use ive ever seen was to destructure basic types into array-like... `union { int x; unsigned char xs[4]; }` (for one specific size of int)
15:07:15 <monochrom> When you deliberately use union { int i; unsigned char b[4]; } to expose the 4-byte format of int.
15:07:57 <dolio> Where unions and intersections classify things that work uniformly on both types.
15:08:13 <[exa]> infinisil: various hardware interfacing code that's basically C, most popularly the portable deconstruction of SIMD data. Anything with the c++ raii semantics doesn't fit at all
15:08:22 <dolio> monochrom: Isn't that undefined behavior?
15:09:06 <monochrom> Yes. Never stopped low-level code to do it.
15:09:20 <siiky> haha exactly
15:09:24 <EvanR> that settles it. the equivalent of union in haskell is unsafeCoerce
15:09:35 <[exa]> +1 EvanR
15:09:42 <monochrom> Or rather, I don't know whether it's undefined, implementation dependent, or what.
15:10:57 <monochrom> s/to do/from doing/
15:11:26 <dolio> Sure.
15:13:06 <dolio> I guess my point was, the only thing the C specification might say you can actually do with union is implement sums.
15:13:46 <dolio> Although I'm not that knowledgeable on the spec.
15:18:00 <EvanR> if that were the case i would have greatly appreciated it if they threw generations of programmers a bone and just made tagged unions a language feature
15:21:44 <siiky> at least it allows for a memory efficient way to implement sum types... so it's not completely useless
15:22:43 <infinisil> Oh one usecase of union types I can think of is: Something like [Either Int Double], but where the tags of whether it's an int or a bool are stored outside the array for space reasons
15:23:28 <infinisil> Which makes sense if e.g. the array only has like 10 Int's, but 1000000 Double's. You could store just the indices of the Int's in a separate part
15:24:16 <EvanR> devil called wants his advocate back
15:25:32 <dolio> You don't need untagged unions for tagged unions to be implemented efficiently.
15:25:44 <dolio> The tagged unions could just be implemented efficiently.
15:26:00 <infinisil> There is a necessary overhead to general tagged unions
15:33:11 <dolio> Anyhow, you don't really need C to add tagged unions, you just need the 'generation of programmers' to finally realize that they don't need to write C.
15:39:48 <siiky> unfortunately, "general purpose" isn't really true, so C is required (or a similarly low-level language, but there's no good popular alternative i think)
15:43:39 <dolio> That sounds like a bad excuse.
15:47:20 <siiky> haha i wish it was... maybe im just ignorant
15:49:41 <Cale> LLVM is a thing now
16:19:25 <infinisil> siiky: Rust is getting there
16:21:36 <fog> when we make the classes of the haskell prelude work at type level, then term level functions which depend on them become possible
16:21:59 <fog> for instance, using Foldable at type level, allows for HFoldable at term level
16:22:42 <fog> but, because of levity recursion, with TypeInType flattening all levels, then Foldable at type level gives Foldable at kind level and so on
16:23:03 <fog> so immediately there is HFoldable at type level, and kind level etc 
16:23:42 <fog> then the question is, what do we get *after* HFoldable in this list of newly possible things
16:24:23 <fog> HFoldable requires folding a Foldable of types
16:24:46 <fog> but what requires folding a Foldable of kinds?
16:25:28 <fog> at term level, there should be something like FList, but that is hetrogenous in the kinds of the parameters
16:25:49 <fog> FList being hetrogenous in the types of the parameters, these being held in a type level list
16:26:28 <fog> this new thing would store something like an FList of hetrogenous types 
16:26:38 <fog> at type level
16:27:04 <fog> FList has a type list param, where the stored types all have kind *
16:27:19 <fog> this thing would allow those kinds to be different, and stored in a kind list
16:27:43 <fog> folding an FList requires folding the list of types
16:27:58 <fog> this new thing would require folding an FList of types
16:28:08 <fog> which in turn would require folding a list of kinds
16:28:54 <fog> what is this new datatype? and what can it be used for as an example?
16:29:57 <fog> and, is there a way to represent *all* of the datatypes corresponding to pushing the list to be folded higher into the levity? 
16:30:14 <fog> what would *they* be useful for?
16:30:24 <siiky> infinisil: yeah, good thing too! thats one of the languages id like to learn
16:31:26 <fog> all that can be immediately obvious about them is that they should be foldable, and the result type produced by folding at the level above it recursively   
16:32:17 <fog> until reaching, at some hight in levity, a list of higher level kinds, that can be folded as the basecase of this recursion
16:34:56 <fog> here is HFoldable, which implements the first in this sequence; https://gist.github.com/fog-hs/4f0b1c6f05bfaa9b7cb050751e84ec6d
16:36:20 <fog> after HFoldable, there would be something like FList that requires folding an FList of types, and so a list of kinds 
16:37:58 <fog> to understand how the recursion proceeds, identifying this next thing, after FList would be helpful
16:38:21 <fog> what is a hetrogenously kinded list?
16:38:47 <fog> as a stage beyond hetrogenously typed lists... 
16:40:20 <fog> it has to be an "FList" not just a HList, because you cant have kinds other than * as values to a list
16:41:51 <fog> the type parameters xs in; FList (f :: k -> *) (xs :: [k]) 
16:42:23 <fog> are applied to f, ie, the values stored are of type `f x'
16:42:52 <fog> where k :: * represents that the kinds are homogenous
16:45:03 <fog> this new datatype should be :: (f :: g s) -> (xs :: FList g (xs :: [s])) -> *
16:45:05 <fog> i think...
16:45:41 <fog> does that look right?
16:46:49 <fog> where xs is the list of sorts...
16:47:39 <fog> and;  g :: s -> * is the way of producing kinds from them
16:48:03 <EvanR> you need universe polymorphism now
16:48:24 <EvanR> and whatever come beyond that
16:48:44 <EvanR> multiverse polymorphism
16:48:49 <fog> yeah, i dont know how to express the entire sequence as one thing
16:49:23 <fog> probably some class to allow recursion which matches on the higher levity parameters
16:50:05 <fog> but id rather get this first extra thing working first, to build intuition as to what they actually do
16:50:48 <fog> being able to fold hetrogenous lists is pretty cool, i have no idea what might be enabled by the kind heterogeneity
16:51:30 <EvanR> you need at least 8 type variables before the system becomes remotely usable
16:51:41 <fog> or, a GADT with a Nat being recursed over for the level
16:51:43 <EvanR> and they need to spells curse words or something
16:52:13 <fog> dont say that!
16:53:10 <fog> better to just find something which requires the next in the sequence to type hetrogenous lists
16:54:15 <fog> what list like thing would require a hetrogenous list of types? 
16:55:10 <fog> ie, where the values require a kind parameter of sort *
16:55:32 <fog> to be stored in a sort level list
16:55:45 <fog> erm, kind level list sorry
16:58:09 <fog> probably should have a simple thing that requires a parameter
16:58:18 <fog> so, take lengthed lists for example
16:59:00 <fog> so the FList, with the basecase list at type level (the normal hetrogenous list)
16:59:09 <fog> with lengthed lists for the value
16:59:20 <fog> they are hetrogenous because they are of different length
16:59:38 <fog> and these lengths are stored in the type level list of Nats
16:59:57 <fog> where Nat :: *, so there is no hetrogenaity at kind level
17:01:27 <fog> shifting this all up a level, there is something at term level that requires a type level param that is an FList, where the values are lengtheds lists, with these lengths being stored as a kind level list of Nats, of sort *
17:01:53 <fog> what is this!?
17:04:23 <fog> the Cons of the term level container takes f x, where x is consed onto the type level FList
17:04:35 <fog> so x must be a lengthed list
17:04:51 <fog> where the length gets consed onto the kind level list
17:06:51 <fog> i *guess* that if whatever these lengthed lists contain, that they could be Nats corresponding to lengths, possible of the lists at other levels.. that might be wrong 
17:07:29 <fog> but then, f (x :: LengthedList (n :: Nat) Nat)
17:07:57 <fog> could this make a tensor?
17:08:12 <fog> or like, a tensor with uneven lengths?
17:08:49 <fog> probably this logic is wrong and i made a mistake somewhere
17:09:40 <MarcelineVQ> EvanR: 8 is probably about right
17:10:56 <ezzieyguywuf> dang, any time fog comes in here all I see i a long stream-of-consiousness that ostly everyone seems to ignore.
17:15:29 <MarcelineVQ> For me it's that I don't know if it's that I don't know what he's talking about or he doesn't so it's hard to engage fruitfully either way.
17:17:10 <ezzieyguywuf> I just can't be bothered to read such a wall of text
17:29:08 <crestfallen> Hi I'm looking at the evaluation order from filterM powerset [4,5]. This is a textbook example. Online I found the applicative version with the evaluation written out. It's calling the list elements "flags," like flg1 flg2. I understand the bools create a cartesian product of the "powerset", but I don't follow precisely what is happening in the evaluation (the paste includes the handwritten evaluation) There's no step in the evaluation where flg2 
17:29:09 <crestfallen> (False?) is included. https://termbin.com/i9eq   thanks for any explanation
17:30:16 <Cale> That's a really confusing choice of name for (const [True, False])
17:30:31 <crestfallen> so since the applicative version uses foldr, the output would be different, but in any case I cannot follow the evaluation, or imagine what the order would look like with the Monad version
17:30:34 <Cale> But yeah, when you use filterM, it's going to construct the powerset
17:30:57 <Cale> The idea is that in the list monad, "running" a list means picking an element from it in all possible ways (and collecting a list of the eventual results)
17:31:11 <dsal> "evaluation order" is not something I think about much in Haskell.
17:31:14 <Cale> and so, when you apply the predicate for the items in your list
17:31:21 <Cale> it tells you "take it or leave it"
17:31:33 <Cale> and so you do this in all possible ways
17:31:48 <Cale> and collect up a list of the possible results of keeping or dropping each element
17:32:13 <crestfallen> thanks Cale I figured that much, but why is there no case where flg2 (False) is mentioned there?
17:32:32 <Cale> What's flg2?
17:32:56 <crestfallen> flags = [True,False], so I was assuming that False was flg2
17:33:24 <Cale> I see you have flg1 as a parameter to the lambda in filtMM
17:33:38 <Cale> I don't know why it's flg1
17:33:42 <Cale> Weird names
17:33:48 <crestfallen> so I guess I cannot follow each step from starting with [[]] 
17:33:53 <crestfallen> one moment pls
17:35:14 <crestfallen> the applicative version comes from this blog: https://blog.ssanj.net/posts/2018-04-10-how-does-filterm-work-in-haskell.html
17:35:35 <Cale> Let's simplify the first definition of filterMM by specialising p = (\x -> [True, False])
17:36:47 <Cale> So m is the list monad
17:36:52 <Cale> filterMM (\x -> [True, False]) [] = return [] = [[]]
17:37:12 <Cale> filterMM (\x -> [True, False]) (x:xs) = do
17:37:19 <Cale>   b <- [True, False]
17:37:34 <Cale>   ys <- filterMM (\x -> [True, False]) xs
17:37:45 <Cale>   return (if b then x:ys else ys)
17:38:33 <crestfallen> ok
17:38:50 <Cale> So, assuming that filterMM (\x -> [True, False]) xs will compute the powerset of xs
17:39:05 <Cale> This means that ys will be chosen to be an arbitrary subset of xs
17:39:42 <Cale> (or to be more precise, a sub-list)
17:39:58 <crestfallen> arbitrary? so this is a cartesian product right?
17:40:37 <Cale> Not exactly...
17:40:44 <Cale> Though you can do stuff like:
17:40:54 <Cale> > replicateM 3 [True, False]
17:40:56 <lambdabot>  [[True,True,True],[True,True,False],[True,False,True],[True,False,False],[Fa...
17:41:03 <Cale> This is a Cartesian product
17:41:18 <Cale> > do x <- [1,2,3]; y <- [4,5]; z <- [6,7,8]; return (x,y,z)
17:41:20 <lambdabot>  [(1,4,6),(1,4,7),(1,4,8),(1,5,6),(1,5,7),(1,5,8),(2,4,6),(2,4,7),(2,4,8),(2,...
17:41:39 <Cale> But yeah, in some sense, there's a Cartesian product taking place, and then some other stuff
17:41:45 * hackage parse-gcstats 0.1.0.0 - Parse machine-readable GHC GC stats.  https://hackage.haskell.org/package/parse-gcstats-0.1.0.0 (MateuszKowalczyk)
17:41:54 <crestfallen> but [True,False] is a full inclusion and full exclusion of all combinations of the list
17:41:59 <Cale> It's like we're taking the Cartesian product of [True, False] and (filterMM (\x -> [True, False]) xs)
17:42:17 <Cale> and then for each pair (b, ys)
17:42:29 <Cale> if b is True, we turn that into (x:ys)
17:42:36 <Cale> and if b is False, we produce ys
17:42:47 <fog> ezzieyguywuf: dont be put off by the tldr.. mostly im just trying to ask a question that needs an answer, but after i post it, a kind of answer seems more obvious after reading the explanations i give to try and make it eaiser for people to understand. so, if it takes me several minutes of thought to add a line of text that could take 2 seconds to
17:42:47 <fog> skim read - its probably just that you need to take it slower
17:43:12 <crestfallen> so the blogs uses "flg1" but not flg2, is that why I'm thrown off?
17:43:28 <Cale> Maybe?
17:43:37 <Cale> There's no flg2 in that code anyway
17:43:50 <Cale> For some reason, they named one of their variables flg1
17:43:56 <crestfallen> but there are two flags True and False right?
17:44:00 <Cale> It's a completely arbitrary name, feel free to change it
17:44:18 <Cale> flg1 doesn't refer to True or something
17:44:33 <Cale> (well, sometimes it will, sometimes it'll refer to False)
17:44:59 <Cale> I don't know why they weren't consistent and didn't just stick with b
17:45:03 <Cale> all the way
17:45:09 <crestfallen> what would be a better name? I thought each bool in the list would be a flag with a name
17:45:32 <Cale> Well, do you understand what liftA2 does?
17:45:42 <Cale> (in this context)
17:45:43 <fog> a good way to contribute is to confirm any understanding you can glean, while also offering a breakdown of it that could help other people understand it too
17:46:33 <crestfallen> essentially returns a cartesian product of list members, I thought
17:46:59 <Cale> Yeah, in some sense
17:47:07 <crestfallen> yeah there's so much going on here, sorry for the confusion
17:47:19 <Cale> liftA2 f xs ys will apply f to each combination of elements from xs and ys
17:47:36 <Cale> i.e.  liftA2 f xs ys = [f x y | x <- xs, y <- ys] -- if you like list comprehensions
17:47:49 <fog> MarcelineVQ: yeah, i wouldnt be asking if i understood, and i wouldnt be trying to explain if i thought it was comprehensible... 
17:47:54 <Cale> and the first argument to liftA2 here is (p x)
17:48:15 <Cale> and if p is (\x -> [True, False]), then (p x) is [True, False]
17:48:50 <Cale> So, flg1 will be bound to both True and False at various points, as the liftA2 goes over all the possible combinations
17:49:08 <Cale> This version isn't especially readable
17:50:15 <Cale> Also, "acc" is similarly a bad name, since it gives the impression that something is being accumulated there
17:50:48 <crestfallen> thanks Cale so do you mind showing the Monad version's output, since it's not using TWO accumulators acc and accx  ?
17:50:49 <Cale> But that simply refers to the result of processing the remainder of the list
17:51:27 <Cale> > filterM (\_ -> [True, False]) [1,2,3]
17:51:29 <lambdabot>  [[1,2,3],[1,2],[1,3],[1],[2,3],[2],[3],[]]
17:52:05 <Cale> You'll notice that in the first half of this list, all the lists contain 1, and in the second half, they all don't
17:52:13 <crestfallen> I meant the "trace" of [4,5] just to keep it short
17:53:22 <crestfallen> for the Monad version. oh would scanr work for the applicative version..just thought of that..
17:57:40 <fog> 16:45:03 <fog> this new datatype should be :: (f :: g s) -> (xs :: FList g (xs :: [s])) -> *
17:57:42 <fog> thats clearly wrong
17:57:52 <fog> (f :: g s -> *) -> (xs :: FList g (xs :: [s])) -> *
17:58:01 <fog> seems more likely
18:00:57 <slack1256> exit
18:05:14 <Cale> crestfallen: http://dpaste.com/05223GW
18:05:33 <Cale> crestfallen: I took some liberties with the evaluation, just doing it in whatever order seemed convenient
18:05:49 <Cale> All evaluation orders which terminate are guaranteed to produce the same result in Haskell anyway
18:06:26 <Cale> I also took some liberty when it came to unfolding the (>>=) for the list monad
18:06:34 <Cale> xs >>= f = concat (map f xs)
18:06:42 <crestfallen> one moment thanks so much Cale
18:06:48 <Cale> So, I just did the map by hand quickly, and left the concat
18:07:06 <Cale> There are actually a whole lot more steps that I'm skipping there
18:07:20 <Cale> (but reading through the evaluation of map would be boring)
18:07:30 <crestfallen> I'm using scanr in the FiltM program and it seems like it (also!) skips steps
18:07:43 <Cale> But also, this isn't at all how I think about the meaning of this program
18:07:52 <crestfallen> wow really?
18:08:04 <Cale> It's foolish to unfold recursive functions manually in this way
18:08:26 <crestfallen> that's a drag.. this is how I try to think of programs
18:08:40 <Cale> If you understand what they're meant to do, it's much much easier to simply assume they're going to do what is intended on all smaller inputs
18:08:58 <Cale> and simply try to convince yourself that they do what is required on an input of the given size
18:09:19 <Cale> i.e. you would prove that a recursive function is correct as a proof by induction
18:09:31 <Cale> So it also makes sense to reason about it that way
18:10:25 <Cale> So, when we get to the point of needing to evaluate filterM (\_ -> [True, False]) on the tail of our input list, we can just assume it does the thing we want, and produces a list of all the possible combinations of that tail
18:10:42 <Cale> and then we just need to check that the result will be a list of all the possible combinations of elements of the entire list
18:11:50 <Cale> which it will be, because every combination of (x:xs) will either include x or it won't, and apart from that, will consist of a combination of xs
18:12:35 <Cale> So when we pick b from [True, False], we're saying "either include x or don't"
18:12:44 <Cale> and then we pick ys to be some combination of xs
18:13:10 <Cale> and then we produce the combination x:ys if we meant to keep x, and ys if we didn't mean to keep x
18:13:44 * hackage optparse-generic 1.4.1 - Auto-generate a command-line parser for your datatype  https://hackage.haskell.org/package/optparse-generic-1.4.1 (GabrielGonzalez)
18:13:52 <crestfallen> but the thing is, is that you *know* how to do that (beautiful!) evaluation, so you *do* know what's happening under the hood. I don't but think I may know that I can study your extremely kind solution Cale
18:14:08 <Cale> If you're at the highest level of trusting that things are going to behave as they ought to, filterM (\_ -> [True, False]) [1,2,3] just reads:
18:14:18 <crestfallen> now* that I can study
18:14:22 <Cale> For each element of [1,2,3], take it or leave it (in all possible ways)
18:14:54 <Cale> (regardless of what the value of the list element is)
18:15:10 <crestfallen> yeah I essentially knew that from the textbook, but is there not an advantage to see what haskell is doing?
18:15:19 <Cale> > filterM (\x -> if odd x then [True, False] else [True]) [1,2,3]
18:15:21 <lambdabot>  [[1,2,3],[1,2],[2,3],[2]]
18:15:47 <Cale> ^^ "if x is odd, then take it or leave it, otherwise, be sure to keep it"
18:16:19 <Cale> > filterM (\x -> if odd x then [True] else [False]) [1,2,3] -- this is just a normal filter now
18:16:21 <lambdabot>  [[1,3]]
18:16:27 <Cale> (kind of)
18:17:01 <crestfallen> thanks very kindly Cale for your patience. I understand it on the surface .Can't wait to tear into this. 
18:18:06 <crestfallen> I was thinking about it at night... and tbh the blog evaluation did seem wrong or lacking...
18:18:10 <Cale> Well, even though I gave a fair amount of detail, my evaluation steps are not correctly ordered for how GHC is going to evaluate things, or how a generic lazy evaluator would.
18:18:24 <Cale> and I skipped a lot of steps as well
18:19:16 <Cale> But the nice thing about languages like Haskell where evaluation is pure is that it doesn't matter what order you evaluate things in if all you care about is the result (and you're smart enough not to pick an order which never terminates)
18:19:52 <Cale> Also: If any evaluation order terminates, the order where you evaluate outermost-first will terminate
18:20:07 <crestfallen> pardon?
18:20:30 <Cale> Maybe I should do my example for evaluation orders :)
18:20:36 <Cale> Suppose we have
18:20:40 <Cale> double x = x + x
18:20:48 <Cale> and we want to evaluate  double (double 5)
18:21:01 <crestfallen> k
18:21:02 <Cale> We could evaluate this innermost-first:
18:21:06 <Cale> double (double 5)
18:21:11 <Cale> -> double (5 + 5)
18:21:14 <Cale> -> double 10
18:21:17 <Cale> -> 10 + 10
18:21:18 <Cale> -> 20
18:21:35 <Cale> This is "eager evaluation"
18:21:43 <Cale> (also sometimes "strict evaluation")
18:21:47 <crestfallen> copy that
18:21:56 <Cale> We could also evaluate the outermost double first:
18:22:00 <Cale> double (double 5)
18:22:06 <Cale> -> (double 5) + (double 5)
18:22:12 <Cale> -> (5 + 5) + (double 5)
18:22:18 <Cale> -> 10 + (double 5)
18:22:21 <Cale> -> 10 + (5 + 5)
18:22:23 <Cale> -> 10 + 10
18:22:25 <Cale> -> 20
18:22:39 <Cale> This is sometimes called "normal order evaluation"
18:23:18 <Cale> You might notice a problem with this -- it can be quite wasteful
18:23:28 <Cale> We evaluated double 5 twice
18:23:35 <crestfallen> right
18:23:43 <Cale> because x occurred more than once in the body of the definition of double
18:23:51 <Cale> so we duplicated work
18:24:28 <Cale> So as an optimisation to this, we have lazy evaluation, which is like outermost-first evaluation, except that whenever we bind a variable, we share any work evaluating it between the occurrences
18:24:28 <crestfallen> so is foldr more efficient always or is that a leap?
18:24:40 <Cale> I'm not talking about foldr here
18:24:51 <Cale> But it's not *always* more efficient, just sometimes better
18:25:16 <Cale> So, with lazy evaluation, using "let" syntax to represent the sharing of work:
18:25:21 <Cale> double (double 5)
18:25:34 <Cale> -> let x = double 5 in x + x -- note that we still evaluated the outermost double first
18:25:43 <Cale> -> let x = 5 + 5 in x + x
18:25:48 <Cale> -> let x = 10 in x + x
18:25:51 <Cale> -> 10 + 10
18:25:52 <Cale> -> 20
18:26:08 <Cale> So now we avoided repeating work
18:26:10 <crestfallen> that's good info
18:26:14 <crestfallen> thanks!!
18:26:35 <Cale> and, something not obvious from this example is that outermost-first evaluation can also avoid doing some work altogether
18:27:04 <Cale> In innermost-first evaluation, if the argument to a function goes unused by the function, then you already wasted effort evaluating it
18:27:16 <crestfallen> I find let statements tough, esp when the result is on the lhs
18:27:28 <Cale> oh
18:27:36 <Cale> Is it not clear what is meant there?
18:27:53 <Cale> Really what happens in memory is that there's a graph structure built of pointers
18:28:08 <Cale> and reduction is manipulating these expression graphs
18:28:13 <crestfallen> no I meant in like applicative state, the result of threading state is written on the lhs
18:28:24 <Cale> hm
18:28:51 <Cale> In any case, in innermost first evaluation, we evaluate each of the arguments to the function exactly once
18:29:21 <Cale> In outermost first evaluation, we evaluate each of the arguments to a function zero or more times -- we can skip evaluating them sometimes, but sometimes work is duplicated
18:29:39 <Cale> In lazy evaluation, we evaluate each argument to a function zero or one times as needed.
18:30:13 <crestfallen> like    stf <*> stx = S (\s -> let (f,s') = app stf s (x,s'') = app stx s' in (f x, s''))
18:30:26 <crestfallen> sorry poor sending there
18:30:41 <Cale> I mostly find that hard to read because of the terrible variable names
18:31:08 <crestfallen> thank you yes I thought they were off!!
18:31:11 <Cale> and the fact that runState has been renamed to app
18:31:20 <Cale> errr
18:31:28 <Cale> yeah...
18:31:36 <Cale> and it... doesn't typecheck
18:31:48 <Cale> oh, you left out a ;
18:32:06 <Cale> stf <*> stx = S (\s -> let (f,s') = app stf s; (x,s'') = app stx s' in (f x, s''))
18:32:39 <crestfallen> oh god, I've been on that section of the book for months.   https://termbin.com/eagr   how should it be written?
18:33:49 <Cale> Which book is this?
18:33:54 <crestfallen> hutton
18:33:57 <Cale> ah, hm
18:34:06 <Cale> Okay, so
18:34:30 <Cale> I would usually introduce the State monad as:
18:35:15 <crestfallen> the Applicative instance I'm still struggling with there
18:35:19 <Cale> newtype State s a = S (s -> (s,a))
18:35:48 <Cale> Though often we name the data constructor of the newtype the same as the type constructor (i.e. you can use State for both)
18:36:09 <Cale> It *is* more convenient when learning/teaching to rename the data constructor like this
18:36:32 <Cale> It's possibly confusing to call this ST though, because there is an ST monad, but it's not this
18:36:50 <Cale> and usually the function:
18:37:01 <Cale> runState :: State s a -> s -> (s,a)
18:37:08 <Cale> is called runState
18:37:32 <Cale> Also, there's a choice of convention about whether the pairs are (s,a) or (a,s) -- it obviously doesn't really matter as long as you're consistent :)
18:37:46 <Cale> (but (s,a) is theoretically nicer)
18:38:29 <Cale> I think it's easier to go past the Applicative instance, and just do Monad first, and then never worry about Applicative, because every Monad is an Applicative for free
18:38:54 <crestfallen> catching up ...
18:40:29 <crestfallen> yeah thanks you did suggest that once before Cale
18:41:03 <crestfallen> plenty to work on tonight.. thanks kindly Cale
18:41:08 <Cale> cool
18:41:25 <Cale> If you want, I can take you through the State monad in detail at some point
18:41:38 <gushys> Maybe im doing something incorrect, but isnt aeson part of the standard library? I tried importing Data.Aeson and was getting a not found error
18:41:50 <crestfallen> absolutely if you have time now Cale I'm game
18:41:53 <Cale> gushys: Nope, it's part of the aeson package
18:42:06 <crestfallen> in pm should we?
18:42:27 <Cale> I didn't get enough sleep last night, I'm going to pass out early :)
18:42:36 <Cale> But maybe at some point tomorrow
18:42:58 <crestfallen> sweet many thanks. sleep well
18:43:10 <Cale> g'night!
18:43:15 <crestfallen> pax
18:44:35 <gushys> Im guessing that im getting user error, but when i run cabal-install i get "Cannot build executables of package because there are none". Am i missing a step before cabal install aeson
18:46:13 <dsal> aeson isn't a binary you can install.  I don't know how cabal works all that well, but for a project in general, you declare your dependencies and the build system resolves them.
18:47:11 <gushys> right, thats what i though 'cabal install aeson' is supposed to do
18:47:21 <gushys> maybe i dont quite understand how it works
18:56:25 <glguy> gushys: If you need aeson in your project you'd add the dependency to your project's .cabal file in the build-depends: section. cabal would make sure that the package was built and available as needed when building your project
18:58:44 <gushys> glguy: i see, ive been doing some digging and just stumbled across what you are talking about, i will give this a try. Thanks!
19:34:03 <maralorn> This is stupid. I am way to tired. And it's probably not even original. But I have found a way to loose all that functional baggage and demonstrate that Haskell is a very decent object oriented programming language: https://paste.linuxlounge.net/4SDA
19:36:36 <EvanR> lol
19:37:47 <maralorn> I mean next step would be inheritance and stuff.
19:37:58 <maralorn> Would certainly be doable.
19:38:53 <maralorn> The most important think if you want to program object oriented of course is passing around unit values at the right positions for cosmetic reasons.
19:38:57 <ezzieyguywuf> hm, how can I make ghcid close my GUI without using --restart
19:41:56 * ski . o O ( <https://augustss.blogspot.com/2009/02/is-haskell-fast-lets-do-simple.html>,<https://augustss.blogspot.com/2009/02/more-basic-not-that-anybody-should-care.html> )
19:46:57 <gushys> it seems that installing aeson with cabal install only works with v1-install?
19:47:38 <gushys> seems weird that the v2 install doesnt work
19:48:56 <monochrom> Generally for libraries, if you want v2, don't bother with "install", just add to build-depends: in your *.cabal
19:49:36 <gushys> i tried that earlier and it didnt seem to work for me
19:49:43 <monochrom> If you don't have a *.cabal, then "cabal v2-repl --dependencies ..." I forgot the details, you look it up.
19:50:30 <gushys> monochrom: thanks for the info
19:52:34 <gushys> oh i see what you mean by the build depends, makes sense
19:54:51 <ezzieyguywuf> hrm, looks like ghcid just calls :reload on ghci, so the question is, how do I capture whatever event ghci triggers in order to ensure my gui gets closed
20:06:33 <ezzieyguywuf> I guess this is where ghci actuall executes the reload command, but I can't decipher what it actually does to kill any currently long-running stuff https://hackage.haskell.org/package/ghcid-0.8.7/docs/src/Language.Haskell.Ghcid.html#local-6989586621679063130
20:06:43 <ezzieyguywuf> I'm sure it must send some sort of SIGKILL or something
20:08:19 <ezzieyguywuf> I think it has to do with syncFresh
20:18:36 <ezzieyguywuf> nope, probably consume
20:18:44 <ezzieyguywuf> oh well, that's enough of that diversion..
20:19:06 <gushys> Seems like ive been fighting with cabal-install to install a package from Hackage and it doenst seem to want to work. Im struggling to find anything that can help me understand cabal-install but either its old versions or doesnt have much info. Any suggestions? do i just move to using stack?
20:19:52 <koala_man> how do I make cabal not delete temporary files when it fails to install something? 
20:21:10 <koala_man> I tried cabal install --keep-temp-files  but apparently that's not a thing in cabal-install 2.4.1.0
20:22:01 <sm[m]> gushys: you can certainly try that, and/or you can show a paste of the command and output
20:24:33 <sm[m]> oh that sounded like your opening question, now I see the log
20:32:20 <sm[m]> still having trouble gushys ?
20:34:11 <glguy> koala_man: the current cabal-install is 3.2.0.0
20:36:34 <gushys> sm[m]: my client timed out, but yes im still having issues not sure if there were any responses i missed
20:36:50 <sm[m]> I can help if you like
20:36:56 <sm[m]> what's your cabal --version ?
20:37:13 <gushys> currently im on cabal 3.2
20:37:56 <sm[m]> so you did cabal install aeson, and saw a message like Warning: You asked to install executables, but there are no executables in target: aeson. Perhaps you want to use --lib to install libraries instead. ?
20:38:33 <gushys> i only got that first part about no executables in target
20:39:12 <sm[m]> well that's odd. Here's my version: $ cabal --version
20:39:13 <sm[m]> cabal-install version 3.2.0.0
20:39:13 <sm[m]> compiled using version 3.2.0.0 of the Cabal library
20:39:46 <gushys> thats the same output i have
20:40:15 <sm[m]> well in any case, it's working as intended.. https://cabal.readthedocs.io/en/latest/cabal-commands.html#cabal-v2-install is the doc. What are you wanting to do ?
20:42:43 <gushys> ive been trying to get aeson so that i can play with encoding and decoding json
20:43:16 <sm[m]> gushys: outside of a project I guess ? You're not in a directory with a .cabal file in it ?
20:43:21 <gushys> i am
20:43:43 <gushys> i do have a cabal file generated with cabal init
20:44:02 <sm[m]> ok.. well if you do what it says and add --lib, does that do it ?
20:45:48 <sm[m]> personally, when I try that command inside a project directory I get: cabal: Cannot build the executables in the package aeson because it does not contain any executables. Check the .cabal file for the package and make sure that it properly declares the components that you expect.
20:47:44 <gushys> that is normally what i get
20:47:52 <sm[m]> but don't worry about my troubles. I'm exploring new-cabal , too
20:48:28 <sm[m]> what happens when you rerun the command with --lib ? 
20:49:28 <gushys> i get 'resolving dependencies' then up to date
20:49:42 <sm[m]> ok, I guess it worked
20:49:54 <sm[m]> and probably this will show the package is installed: ghc-pkg list aeson
20:51:14 <gushys> it does appear there
20:51:21 <sm[m]> and maybe this will work: cabal repl, then: import Data.Aeson
20:51:21 <gushys> maybe it did work
20:52:41 <MarcelineVQ> There's no need to write  cabal install anything  if you're wanting to use a library. You add the package you want to youre build-depends and cabal makes it available when you need it, such as when you cabal build your project or cabal repl.
20:53:17 <gushys> ok then maybe my question isnt with cabal now
20:53:37 <MarcelineVQ> The question is what are you trying and what are you expecting to see
20:54:56 <MarcelineVQ> We can't see what you're doing on your end so you need to describe it :>
20:55:05 <gushys> well idk what i did but now it all works
20:55:33 <koala_man> glguy: I'm using the last version with windows x86 support for no convincing reason
20:55:35 <gushys> so maybe something did end up working properly. But i wasnt able to import Data.Aeson in a repl
20:55:58 <glguy> gushys: Did you start the repl with: cabal repl?
20:56:04 <gushys> yes
20:56:49 <gushys> my editor also wasnt recognizing that it was available
20:56:54 <gushys> but now it is
20:56:59 <glguy> What does your .cabal file look like?
20:57:13 <sm[m]> editor working! I'm on a roll! 
20:58:12 <gushys> the basic .cabal from a cabal init and i added aeson to the build depends
20:58:37 <glguy> You should paste the files you're using and some terminal output to a pastebin, what you're describing isn't normal
20:59:02 <gushys> currently it is working
20:59:12 <glguy> not if you can't import Data.Aeson from cabal repl
20:59:27 <gushys> sorry for any confusion but i can now
20:59:34 <gushys> it wasnt working properly before
20:59:53 <gushys> so i must have done something that made it work
21:00:47 <gushys> i'm somewhat unclear on what step was different from the everything else that i tried
21:01:30 <gushys> but at this time i can import Data.Aeson on a cabal repl as well as HLS recognizing it as an available import
21:03:55 <gushys> From what i gather, i should only need to add a library to my .cabal file and then when i `cabal build` or `cabal repl` it will become available
21:06:38 <MarcelineVQ> Yes. This is futher suspicious because afaik aeson should not appear in  ghc-pkg list aeson as sm[m] had you try if it was installed via a recent cabal.
21:07:48 <gushys> in my many attempts i did install using `cabal v1-install aeson`
21:08:02 <gushys> so this could be a reason as to why it appears there
21:08:34 <MarcelineVQ> probably
21:13:51 <sm[m]> MarcelineVQ: we added --lib. Doc says that'll install a library
21:14:46 <MarcelineVQ> it won't add it to the ghc pkg list though
21:14:50 <MarcelineVQ> It goes to the cabal store
21:17:31 <gushys> how do i go about removing it from there
21:21:27 <MarcelineVQ> looks like ghc-pkg unregister, but I'm not sure what all steps you need to be aware of as I don't use ghc-pkg directly
21:25:27 <MarcelineVQ> in a test just now doing cabal v1-install aeson stuck all the required libs in another directory so I was able to simply delete that directory. In particular my ghc lives in ~/.ghcup/  and the v1-install placed things in ~/.ghc/ so I could just delete .ghc to remove everything v1 installed without impacting the compiler.
21:26:28 <MarcelineVQ> I found I could do that because those two locations were listed in  ghc-pkg list  when only the .ghcup location was listed there before I did v1-install
21:28:42 <gushys> thanks for the info, the unregister seems to have removed it from the list
21:28:54 <gushys> illl see if the directories have been populated
21:31:32 <gushys> MarclineVQ: yeah, looks like mine did the same thing, i removed that directory also
21:33:37 <sm[m]> And you can always nuke ~/.{cabal,ghc,stack} from orbit
21:34:49 <gushys> if i nuke the .cabal folder, thats nuking the install? would there be any other locations taht would need to be purged?
21:47:50 <glguy> gushys: If you did a v1-install globally (no --user) then you'd need to restore your ghc install itself back to how it started
21:48:41 <glguy> v2-install is the default kind of install in the currently released version of the cabal-install
21:49:52 <monochrom> But v1-install has --user as default
21:50:11 <glguy> That wasn't alway the case was it, even it was most recently the case?
21:50:21 <glguy> v1-install is a blur to me now
21:50:33 <monochrom> It has been the default for at least 5 years.
21:50:48 <monochrom> Hell, I think it has been the default since the beginning.
21:51:01 <monochrom> Setup.hs is --global, cabal-install is --user
21:51:02 <glguy> People used to get in a lot of group doing global installs
21:51:09 <glguy> is that why that was?
21:51:48 <glguy> lot of trouble*
21:51:59 <monochrom> No, people say "global" when it's --user because they use single-user computers and they don't know the nuance.
21:52:19 <glguy> I know we had to help people reinstall GHC to get their global package database back into shape
21:52:54 <monochrom> Yes but they explicitly said --global
21:53:16 <monochrom> A lot of them did. I did. (But I was careful.)
21:54:27 <gushys> so i guess to nuke my stuff to start it clean, what needs to be deleted?
21:54:49 <glguy> What's broken?
21:55:22 <glguy> I still don't think I've seen any error messages pastes or anything like that
21:57:44 <sm[m]> gushys: what I said plus dist* in your project directories should be everything
21:57:45 <gushys> well i dont thinnk anythings broken, i just want to clean up any relics from messing around with cabal
21:58:17 <sm[m]> Plus any stray haskell related binaries in PATH
21:58:34 <sm[m]> but if it ain’t broke..
22:00:29 * hackage pandoc 2.10 - Conversion between markup formats  https://hackage.haskell.org/package/pandoc-2.10 (JohnMacFarlane)
22:05:02 <gushys> upon looking through the directories for ghcup and cabal and ghc i dont see anything related to any cabal packages installed so i think im clear
22:05:53 <gushys> may have spoken too soon
22:07:24 <gushys> `.cabal/lib/x86_64-linux-ghc-8.8.3` contains a folder named aeson-1.5.2.0-6uzVIPvUiXu9Xt2KEzSZqQ
22:07:36 <gushys> would this be from the v1 install
22:09:46 <MarcelineVQ> not sure but I would guess so since I think v2 should be placing things in .cabal/store
22:09:59 <sm[m]> So as I was saying the other day... isn’t it time we purged v1-/v2-/new- from cabal..
22:11:48 <MarcelineVQ> sm[m]: how do nix users do things? does nix provide the ghc-pkg environment without cabal at all and you use ghc yourself? Just wondering since if nix needs to use cabal it probably would want v1 because v2 does its own store
22:15:23 <MarcelineVQ> the v1/v2 naming is likely to continue since its purpose (afaik) was to replace 'new' with a scheme that could continue to be added to. It feels pretty silly though, like if a person gets to v3 I'd really question if that amount of backwards compat is reasonable to keep supporting. In terms of useage and documentation and teaching.
22:15:24 <glguy> sm[m]: I think those exist for compatibility with scripts. Most users should just be using 'install' and a recent version of the tool
22:16:56 <sm[m]> I know, but they create endless confusion
22:17:47 <sm[m]> and it seems like time to clean up
22:19:18 <sm[m]> MarcelineVQ: don’t know, but nix must solve their own problems
22:44:10 <fog> im trying to understand the correspondence between type level versions of term level functions
22:44:40 <fog> and the corresponding extension of these functions at term level, that make use of their type level counterparts
22:45:29 <fog> specifically for foldable, where folding lists of types is needed in folding hetrogenous containers parametrised by these type lists
22:45:46 <yushyin> sm[m]: what confused me most of the time was at the time of transition from old cabal-install to new cabal-install and if cabal build or cabal new-build meant v2-build or not etc. The documentation is not very keen to explain it to new users how and when commands get prefixed with vY- or new-. It is also not very useful, that if you google 'cabal documentation' the first link is most likely the
22:45:47 <yushyin> outdated 3.0 documentation from haskell.org, very confusing to newcomers.
22:46:46 <fog> it seems incredible that just by promoting a function to type level, that there is then an extended version of it possible at term level 
22:47:43 <fog> im wondering if this only applies to fold. like, if there is something special about how the type level operations correspond to those at term level 
22:48:06 <fog> is the fact that hetrogenous folding requires type level folding a unique case?
22:48:36 <fog> or is there always something like this happening when we promote functions to type level
22:49:30 <glguy> fog: Is there some Haskell code you're asking about?
22:49:53 <fog> i wrote it here; https://gist.github.com/fog-hs/4f0b1c6f05bfaa9b7cb050751e84ec6d
22:50:18 <fog> that implements type level folding, and term level hetrogenous folding
22:50:29 <glguy> If you have a specific question about that code that's good, but don't do that thing where you fill the channel with a blog post
22:50:48 <fog> oh you wanted a preamble to make an assertion
22:51:30 <fog> the implications of this code are worth discussing
22:52:06 <glguy> Perhaps , but not the way you tend to do that here
22:52:17 <fog> and the question is to field responses to that
22:52:41 <fog> i think the thing that would differentiate it from monologue would actually be response
22:52:51 --- mode: ChanServ set +o glguy
22:52:51 --- mode: glguy set -qq *!*@89.153.92.135 *!b23ec967@gateway/web/cgi-irc/kiwiirc.com/*
22:53:15 <glguy> fog, yup, but time and again you fill the channel with a monologue instead
22:53:36 <fog> instead of getting responses?
22:53:46 <fog> thats not under my control
22:53:48 <glguy> right, you go on in a way that doesn't engage people to make responses
22:54:20 <fog> so i should assume you know what im asking about?
22:55:31 <fog> its an ok question. its not my fault your training people not to respond to me
22:55:40 --- mode: glguy set +q *!*@*/ip.109.249.184.248
22:57:39 <fog100> you should at least put admin via pm
23:05:58 <sm[m]> yushyin: agreed! Here’s the issue: https://github.com/haskell/cabal-website/issues/8
23:06:02 <sm[m]> night all
23:14:22 <NewToHaskell> Are there a way for me to see how a function is implemented? E.g. the nub function.
23:14:29 <NewToHaskell> Zvon is great but it doesn't show me the code.
23:14:30 <NewToHaskell> http://zvon.org/other/haskell/Outputlist/nub_f.html
23:18:13 <NewToHaskell> https://wiki.haskell.org/Example_code if anyone wonder. =)  
23:21:24 <MarcelineVQ> you'd have to look up the particular nub you're using. you can search for it on hoogle  https://hoogle.haskell.org/?hoogle=nub  and then click the source link to the right of it when you've gone to the page hoogle gives you https://hackage.haskell.org/package/base-4.14.0.0/docs/Data-List.html#v:nub
23:21:34 <MarcelineVQ> le sigh
23:38:43 <ja> that hedgehog source annotation with inline generated values is so wonderful
23:39:02 <ja> i almost feel like haskell can do more than printf debugging ;)
23:39:52 <ja> it is so impressive to me somehow to have this feature in a compiled language!
23:41:32 <ja> i am happy that ghc doesn't worry about the standard so much anymore, because what really matters is the tooling!
23:47:30 * hackage yesod-bin 1.6.0.5 - The yesod helper executable.  https://hackage.haskell.org/package/yesod-bin-1.6.0.5 (MichaelSnoyman)
