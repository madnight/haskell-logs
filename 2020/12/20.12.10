00:47:40 <koz_> siraben: Ba-doom-psh.
00:59:35 <pavonia> Is there a way to make the handle opened by openTempFile read-access-only afterwards? I have to pass it to an external library that tries to gain write-access again
01:07:47 <pavonia> Never mind, I can just close the handle
01:27:31 <tomsmeding> koz_: mashing deps into the packages section might be inadvisable, but what if I want to put a flag on a dependency?
01:28:22 <merijn> tomsmeding: You can't put flags on dependencies in .cabal
01:29:29 <tomsmeding> also not in cabal without the . ?
01:29:49 <tomsmeding> that would explain my trouble :p
01:30:12 <tomsmeding> flags are really a niche feature then
01:32:07 <merijn> tomsmeding: Flags are intended to help toggle between multiple possible build configurations, *not* enabling/disabling features, which is why you cannot explicitly set them
01:32:32 <merijn> Of course people ignore what the docs say they're supposed to be used for and use them to control features *anyway*
01:32:50 <tomsmeding> so in layman's speak, flags are for the developers of a package, not for its users
01:32:56 <merijn> And then you're hosed, because you can't reliably depend on those features/flags
01:34:27 <maerwald> merijn: that's what happens if you give people too many tools 
01:34:31 <merijn> tomsmeding: look at, for example, the text package which has flags for depending on bytestring-builder and integer-simple
01:34:51 <merijn> tomsmeding: The idea is that cabal tries toggling flags to see if enabling those lets it solve the build plan
01:34:59 <tomsmeding> does cabal?
01:35:04 <tomsmeding> that's horrifying
01:35:19 <maerwald> I agree, it's a misfeature
01:35:21 <merijn> tomsmeding: Flags by default are automatic and cabal will try toggling automatic flags, yes
01:35:28 <tomsmeding> docs?
01:35:37 <tomsmeding> I want to make some people regret their decisions with this information
01:35:50 <merijn> https://cabal.readthedocs.io/en/latest/cabal-package.html#resolution-of-conditions-and-flags
01:36:10 <tomsmeding> "If the user does not fix the value of a flag" -- so they can?
01:36:11 <maerwald> if you're concerned about that, freeze files also pin the flags
01:36:20 <tomsmeding> right freeze files
01:37:32 <tomsmeding> does stack inherit this behaviour or does the snapshot-oriented structure make that unnecessary?
01:37:46 <merijn> tomsmeding: Relying on flags for features is broken even if cabal doesn't toggle flags, because, well, you can't specify flags of dependencies
01:37:57 <tomsmeding> except in a freeze file?
01:38:18 <merijn> a freeze file is simply "a fully specified build plan, serialised to disk"
01:38:38 <merijn> tomsmeding: a library can't really sensibly have a freeze file/build plan, that only works for executables
01:38:38 <tomsmeding> right so an adventurous user can change it and hence attain their goals of specifying flags
01:38:48 <tomsmeding> good point
01:38:54 <merijn> tomsmeding: imo, that's the biggest problem
01:39:04 <tomsmeding> luckily the case I'm thinking about does have an executable as the end-user
01:39:05 <merijn> Should've just not given users *any* tools for specifying flags
01:39:15 <merijn> That would've discouraged people from using them like this
01:39:20 <maerwald> merijn: or breaking API :p
01:40:03 <merijn> maerwald: hmm?
01:40:29 <maerwald> was just trying to go on a tangent why PVP is a similar problem :p
01:41:13 <maerwald> but then again, it's kind of the purpose there
01:42:49 <tomsmeding> people are slightly more used to versions meaning something, though
01:43:07 <tomsmeding> they're not used to flags not being for, well, configuration
01:43:27 <maerwald> *API* configuration
01:43:32 <maerwald> implementation configuration yes
01:44:04 <tomsmeding> I'm in particular thinking of a package that has a 'debug' flag that enables some extra stuff at runtime
01:44:24 <tomsmeding> is that a valid use of a flag? the API doesn't change code-wise, but that may be behaviour that a _user_ wants to toggle
01:44:29 <maerwald> but that's an easy one to solve: just create a package with a different name and the same API. Globablly unique module names is nonsense anyway
01:44:47 <merijn> tomsmeding: If both behaviours are reasonable the API should let you select them at runtime
01:44:51 <maerwald> that's what most distros do as well, only very few have actual flags... and those that do regret it
01:45:35 <merijn> tomsmeding: Instead of having 1 package supporting two variants, just implement a core package that gets wrapped by 2 independent packages for the specialisation
01:46:03 <maerwald> but then you ned || dependencies
01:46:22 <merijn> maerwald: did you have a stroke there? :p
01:46:37 <maerwald> ...
01:46:49 <merijn> tomsmeding: i.e. what persistent does via "persistent" and "persistent-sqlite", "persistent-postgres"
01:46:59 <merijn> maerwald: that sentence doesn't parse
01:47:13 <maerwald> try a different parser!
01:47:18 <tomsmeding> 'but then you need disjunctive dependencies'?
01:47:42 <merijn> Why wouldn't you be able to use both?
01:47:43 <tomsmeding> but I see merijn 
01:47:53 <merijn> I can mix persistent-sqlite and persistent-postgres just fine
01:48:10 <merijn> tomsmeding: Similarly, I have this (unusable for mere mortals) module https://hackage.haskell.org/package/broadcast-chan-0.2.1.1/docs/BroadcastChan-Extra.html
01:48:18 <tomsmeding> then again the debug flag here toggles whether the relevant functionality is available _at all_; it can still be turned on/off
01:48:26 <tomsmeding> so I assume it's for performance
01:48:30 <merijn> tomsmeding: Which I then use to have separate versions for conduit/pipes
01:48:45 <maerwald> merijn: no, I mean if you remove flags entirely and opt for creating a new package per flag, then you must be able to say || ( openssl libressl ) 
01:49:10 <tomsmeding> merijn: some neat type signatures in that module
01:49:39 <merijn> maerwald: I'm not saying "remove flags", I just meant that "the people who use flags to control API should invert their selection by having a separate package per choice"
01:49:55 <maerwald> I said "remove flags" :p
01:50:10 <maerwald> but I'm not sure that's a good thing
01:50:22 <merijn> maerwald: your || notation is literally what flags were added for, though :p
01:50:29 <maerwald> || deps are a wart for package implementation dependencies
01:50:39 <merijn> maerwald: We should just remove the CLI interface letting users control them :p
01:50:43 <maerwald> merijn: yes, that's what I said and they're still different
01:50:52 <maerwald> hmm
01:51:03 <tomsmeding> I tentatively agree with merijn
01:51:16 <merijn> tomsmeding: The more usable versions are in another module: https://hackage.haskell.org/package/broadcast-chan-0.2.1.1/docs/BroadcastChan.html#v:parMapM_
01:51:39 <merijn> tomsmeding: Or the conduit version: https://hackage.haskell.org/package/broadcast-chan-conduit-0.2.1.1/docs/BroadcastChan-Conduit.html#v:parMapM
01:51:40 <tomsmeding> or make it available to users, but under a conspicuous name like --override-build-flag kaas=true
01:53:15 <tomsmeding> merijn: side note, if anyone ever comes asking about controlling flags again, please pass that docs section to them; that will be cleansing enough
01:55:20 <tomsmeding> salient detail: that docs has the sentence "If a package descriptions specifies configuration flags the package user can [control these in several ways]."  -- where the [] is a dead link
02:03:39 <boxscape> % type family Undefined :: k where
02:03:40 <yahb> boxscape: 
02:03:51 <boxscape> % :k Undefined :: (forall k . k)
02:03:51 <yahb> boxscape: ; <interactive>:1:1: error:; * Expected kind `forall k. k', but `Undefined' has kind `k0'; * In the type `Undefined :: (forall k. k)'
02:03:56 <boxscape> % type family Undefined :: forall k . k where
02:03:56 <yahb> boxscape: 
02:03:58 <boxscape> % :k Undefined :: (forall k . k)
02:03:58 <yahb> boxscape: k
02:04:04 <boxscape> why are these type families different?
02:06:47 <siraben> Is it possible to write this function? `foo :: (u -> (a -> s -> r) -> s -> r) -> (u -> (a -> s -> Maybe r) -> s -> Maybe r)`
02:07:40 <boxscape> @djinn (u -> (a -> s -> r) -> s -> r) -> (u -> (a -> s -> Maybe r) -> s -> Maybe r)
02:07:40 <lambdabot> f _ _ _ _ = Nothing
02:08:16 <tomsmeding> technically correct
02:11:26 <siraben> @type \f u k s -> Just (f u (\a s -> fromJust (k a s)) s)
02:11:30 <lambdabot> (t1 -> (t2 -> t3 -> a1) -> t4 -> a2) -> t1 -> (t2 -> t3 -> Maybe a1) -> t4 -> Maybe a2
02:11:32 <siraben> i have this right now but is it possible to avoid fromJust?
02:11:57 <siraben> using applicatives don't seem to help since it's inside one of the args to f
02:12:20 <tomsmeding> I think you can't, precisely because f doesn't allow any kind of functor-like behaviour in its a->s->r argument
02:13:04 <tomsmeding> you'd be able to do it if 'f' instead had type 'Functor f => u -> (a -> s -> f r) -> f (s -> r))', but then you wouldn't be writing this function in the first place
02:13:29 <siraben> context: https://github.com/siraben/r5rs-denot/blob/c04fddb4d72e753d5bf65c7eb04b498704edf85b/src/SchemeEval.hs#L51
02:13:46 <siraben> Looks like I'd need to take `(u -> (a -> s -> m r) -> s -> m r)` as an argument instead
02:13:56 <tomsmeding> indeed
02:14:52 <siraben> Is there a library that will generate the reflect and reify functions for me?
02:14:56 <dminuoso> Is there a kind of `encodeAscii :: Text -> Either String ByteString` type of function somewhere?
02:15:35 <tomsmeding> dminuoso: https://hackage.haskell.org/package/text-1.2.4.0/docs/Data-Text-Encoding.html
02:15:46 <dminuoso> Yeah but
02:15:48 <dminuoso> Deprecated: Use decodeUtf8 instead
02:15:51 <tomsmeding> oh ascii
02:15:53 <dminuoso> Also the type is wrong
02:16:11 <dminuoso> I mean yeah, I can just scan the text for non-ascii characters 
02:17:30 <dminuoso> f s | all isAscii s = Right (T.encodeUtf8 s) | otherwise = Left ...
02:17:34 <dminuoso> But that will waste work
02:17:53 <dminuoso> On a happy pass that has to traverse the text twice
02:18:12 <tomsmeding> doesn't ByteString have something like  Functor f => Int -> (Int -> f Word8) -> f ByteString
02:18:23 <tomsmeding> though that's probably not any better than going via fromList
02:18:32 <tomsmeding> it will be a single pass though
02:18:38 <opqdonut> especially with fusion
02:19:27 <tomsmeding> Data.ByteString.unfoldr is kind of that function, though it has an unnecessary state component
02:20:01 * tomsmeding meant unfoldrN
02:21:26 <dminuoso> tomsmeding: by fromList you mean pack?
02:21:53 <dminuoso> It seems the most rational thing to do, is something like
02:22:08 <dminuoso> maybeAsciiLength :: String -> Maybe Int
02:22:26 <tomsmeding> I do but you'd want something like packN, which doesn't exist?
02:22:29 <dminuoso> And then write something like
02:22:48 <dminuoso> asciiPack cs = unsafePackLenChars <$> (maybeAsciiLength cs) <*> cs
02:23:07 <tomsmeding> https://hackage.haskell.org/package/bytestring-0.11.0.0/docs/Data-ByteString-Internal.html#v:packUptoLenBytes that apparently, though internal
02:23:21 <tomsmeding> lol yes
02:24:57 <dminuoso> tomsmeding: That function doesn't seem right.
02:25:09 <dminuoso> The primitive I want doesn't seem to exist.
02:26:25 <dminuoso> err, actually the above should be
02:26:46 <dminuoso> asciiPack cs = (`unsafePackLenChars` cs) <$> maybeAsciiLength cs
02:27:52 <dminuoso> It's possible this will perform much worse than just doing through the list twice, I'd have to hope fusion kicks in on the Maybe for maybeAsciiLength, or I have to write it with cont manually
02:30:00 <boxscape> I think I figured it out, `type family Undefined :: forall k . k` is nullary, but `type family Undefined :: k` is unary because it takes the invisible k
02:31:49 <dminuoso> boxscape: Huh, so the latter is kind indexed but the former is not?
02:31:54 <boxscape> yes
02:32:15 <dminuoso> Mmm, is that with PolyKinds on?
02:32:19 <boxscape> yeah
02:32:31 <dminuoso> Interesting, does `forall k. k` in general kind polymorphic?
02:32:44 <dminuoso> Or is this just a specialty in case of tyfams?
02:33:58 <boxscape> dminuoso hmm what sort of situation aside from tyfams are you thinking of?
02:34:25 <dminuoso> Mmm. Good question
02:34:32 <dminuoso> Can you write a data declaration with explicit forall?
02:34:50 <dminuoso> % data forall s t. Const s t = Const t
02:34:50 <yahb> dminuoso: ; <interactive>:53:6: error: parse error on input `forall'
02:35:00 <dminuoso> Mmm, apparently not
02:35:05 <boxscape> % data Proxy' :: forall k . (a :: k) where Proxy :: Proxy a
02:35:05 <yahb> boxscape: ; <interactive>:54:28: error:; * Expected a type, but `a :: k' has kind `k'; * In the kind `forall k. (a :: k)'
02:35:15 <boxscape> % data Proxy' :: forall k . (a :: k)-> * where Proxy :: Proxy a
02:35:15 <yahb> boxscape: ; <interactive>:55:28: error:; * Expected a type, but `a :: k' has kind `k'; * In the kind `forall k. (a :: k) -> *'
02:35:19 <boxscape> dammit
02:36:18 <absence> is there a library/concept that makes it easy to implement things like f (a, b, c, d) -> (f a, f b, f c, f d)?
02:37:20 <boxscape> % data Proxy' :: forall k . k -> * where Proxy' :: forall k (a :: k) . Proxy' a -- dminuoso
02:37:21 <yahb> boxscape: 
02:37:21 <dminuoso> absence: generics
02:37:35 <dminuoso> absence: or relying on something that has done the boilerplate for you, like lens
02:38:00 <dminuoso> e.g.: sequenceOf :: LensLike (WrappedMonad m) s t (m b) b -> s -> m t 
02:38:28 <dminuoso> % sequenceOf each (Just 1, Just 2, Just 3, Just 4)
02:38:28 <yahb> dminuoso: Just (1,2,3,4)
02:39:15 <dminuoso> oh wait, wrong direction :>
02:40:01 <absence> % sequenceOf each (Just (1, 2, 3, 4))
02:40:01 <yahb> absence: ; <interactive>:67:1: error:; * Ambiguous type variable `a0' arising from a use of `print'; prevents the constraint `(Show a0)' from being solved.; Probable fix: use a type annotation to specify what `a0' should be.; These potential instances exist:; instance Show a => Show (ZipList a) -- Defined in `Control.Applicative'; instance Show a => Show (Complex a) -- Define
02:40:24 <dminuoso> That actually looks like coapplicative rather, doesn't it?
02:40:59 <dminuoso> Or no, coapplicative would be be: 
02:41:25 <dminuoso>  f (a, b, c, d) -> Either (f a) (Either (f b) (Either (f c) (f d)))
02:41:38 <dminuoso> absence: What should the function above even do? What choices of f do you want to make?
02:42:20 <dminuoso> Mmm, that looks like cotraversable
02:42:24 <dminuoso> cosequence :: Functor g => g (f a) -> f (g a) 
02:42:32 <absence> dminuoso: returning (Just 1, Just 2, Just 3, Just 4) would be fine
02:43:10 <dminuoso> absence: Is monomorphized f ~ Maybe fine?
02:43:15 <dminuoso> Or do you want it for functors in general?
02:43:46 <absence> i was hoping to find something general
02:44:48 <dminuoso> absence: https://hackage.haskell.org/package/distributive-0.6.2/docs/Data-Distributive.html
02:45:03 <dminuoso> (I guess that's just a different name/version of the Cotraversable above)
02:45:23 <dminuoso> Note:
02:45:24 <dminuoso>  (Distributive a, Distributive b) => Distributive (a :*: b)
02:45:30 <dminuoso> So you can do just that with generics + distributive
02:47:52 <dminuoso> So to do the above, it should be enough to just write:
02:48:01 <dminuoso> to . distribute . from
02:49:25 <dminuoso> % let d = G.to . distribute . G.from in d (Just (1,2,3))
02:49:25 <yahb> dminuoso: ()
02:49:27 <dminuoso> Mmm, not quite
02:53:01 <absence> % G.to . sequenceA . G.from $ Just (1,2,3)
02:53:01 <yahb> absence: ()
02:53:07 <absence> :D
02:53:43 <dminuoso> Mmm, is this MMR?
02:53:50 <dminuoso> Where the heck does this unit come from
02:55:33 <dminuoso> % import Data.Distributive.Generic
02:55:33 <yahb> dminuoso: 
02:55:49 <dminuoso> % genericDistribute $ Just (1,2,3)
02:55:50 <yahb> dminuoso: ; <interactive>:99:1: error:; * No instance for (GDistributive (G.K1 G.R Integer)) arising from a use of `it'; * In the first argument of `print', namely `it'; In a stmt of an interactive GHCi command: print it
02:57:32 <boxscape> % type Undefined :: k; type family Undefined :: k where Undefined @Nat = 4; Undefined @Symbol = "test" -- FWIW this makes the difference more obvious; writing these equations wouldn't be possible with forall k . k
02:57:32 <yahb> boxscape: 
02:57:54 <dminuoso> Mmm  Distributive f => GDistributive (Rec1 f)
02:58:31 <dminuoso> Yeah no idea how to use this
02:59:18 <dminuoso> % data V2 a = V2 a a deriving (Show, Functor, Generic1)
02:59:19 <yahb> dminuoso: ; <interactive>:101:45: error:; Not in scope: type constructor or class `Generic1'; Perhaps you meant one of these: `G.Generic1' (imported from GHC.Generics), `G.Generic' (imported from GHC.Generics)
02:59:21 <dminuoso> % data V2 a = V2 a a deriving (Show, Functor, G.Generic1)
02:59:21 <yahb> dminuoso: 
02:59:29 <dminuoso> % instance Distributive V2' where distribute = genericDistribute
02:59:30 <yahb> dminuoso: ; <interactive>:103:23: error:; Not in scope: type constructor or class V2'; Perhaps you meant `V2' (line 102)
02:59:35 <dminuoso> % instance Distributive V2 where distribute = genericDistribute
02:59:35 <yahb> dminuoso: 
03:00:03 <dminuoso> % distribute (Just (V2 'a' 'b'))
03:00:04 <yahb> dminuoso: V2 (Just 'a') (Just 'b')
03:00:06 <dminuoso> absence: Ah there!
03:01:10 <absence> wow
03:07:51 <absence> dminuoso: unfortunately it breaks apart when the input type is Maybe (a,b) rather than Maybe (a,a)
03:09:30 <dminuoso> Well you can just newtype a uniform type
03:09:44 <dminuoso> But yeah
03:10:26 <absence> dminuoso: does that help? I mean e.g Just ("hello", False)
03:10:30 <dminuoso> Maybe edwardk has an idea whether you can turn single-type tuples into Distributive
03:10:41 <dminuoso> (or even poly-tuples)
03:11:09 <dminuoso> You can still write your generic code at least
03:16:05 <kuribas> After seeing so many lisp code, I am convinced that greenspun's law holds for haskell as well.  Any sufficiently complicated lisp or clojure program contains an ad hoc, informally-specified, bug-ridden, slow implementation of half of haskell.
03:16:45 <kuribas> I was speaking with my colleage about our clojure api, and he was basically designing some sort of type system to get rid of the inconsistencies because "everything is a hashmap".
03:17:02 <kuribas> Meanwhile I was thinking, "this is already solved in haskell".
03:17:40 <kuribas> lisp is so flexible, but in the end you just use this flexibility to implement what is already in haskell.
03:18:39 <absence> dminuoso: thanks for looking into it!
03:38:37 <kupi> is there a database which supports sum types?
03:39:48 <raichoo> There are enums in postgres, but I assume you want sums of products?
03:41:12 <kupi> yes
03:44:21 <raichoo> jsonb *runs*
03:45:39 <tdammers> question is, is there a database that supports types to begin with
03:46:21 <tdammers> because depending how you look at it, postgres doesn't really have types, just tags
03:47:21 <tdammers> kuribas: I have said this before, but s/Haskell/a type system/
03:47:34 <kuribas> tdammers: yeah, I guess so
03:47:49 * ski . o O ( "Modelling Large Datasets Using Algebraic Datatypes: A Case Study of the CONFMAN Database" by Markus Mottl in 2002-05-15 at <http://www.ofai.at/cgi-bin/tr-online?number+2002-27> ; "Algebraic Data Types for Language-Integrated Queries" by George Giorgidze,Torsten Grust,Alexander Ulrich,Jeroen Weijers in 2013-01 at 
03:47:52 <tdammers> (and also, just like Lisp isn't an adequate Lisp, Haskell is not an adequate Haskell)
03:47:54 * ski <https://www-db.informatik.uni-tuebingen.de/publications/AlgebraicDataTypesforLanguage-IntegratedQueries.html> )
03:48:19 <kuribas> tdammers: a type system with polymorphic parametrism and algebraic datatypes.
03:51:43 <lortabac> kupi: https://github.com/agentm/project-m36
03:51:49 <edwardk> dminuoso: single type tuples being things like V4, V3, etc. from linear? aren't they all?
03:52:07 <dminuoso> edwardk: No I rather meant something like (a,b,c)
03:52:15 <edwardk> then the answer is no
03:52:42 <edwardk> there isn't a 1-ary tuple, and the others aren't isomorphic to function spaces when you peel off the last arg
03:53:12 <edwardk> newtype V4ish a = V4ish (a,a,a,a) -- that you can do
03:54:33 <edwardk> but consider that you need to be able to convert (some representation -> c)   back and forth to (a,b,c) without losing any information, but there's no place to smuggle out the info for a and b in that.
04:02:08 <kuribas> wouldn't Identity be a 1-ary tuple?
05:26:05 <dminuoso> If I want to identify duplicate items in a list, is doing a foldM into a Set via alterF the most effective way?
05:32:58 <Lurkki> https://paste.debian.net/1176346/ Can anyone offer some advice on how do this?
05:36:07 <gentauro> ski, is that LINQ for Haskell?
05:37:14 <gentauro> just dl the paper. I guess not ‚Ä¶
06:15:47 <joel135> Lurkki: https://paste.debian.net/1176351/
06:34:56 <kupi> https://gist.github.com/theqp/17756e060816c039cd52cb3bb84c4ec0
06:35:07 <kupi> which function have i reinvented?
06:35:10 <kupi> hoogle did not help
06:39:47 <merijn> Isn't that just "traverse . traverse"
06:39:50 <merijn> :t traverse
06:39:52 <lambdabot> (Traversable t, Applicative f) => (a -> f b) -> t a -> f (t b)
06:40:01 <merijn> :t traverse . traverse
06:40:03 <lambdabot> (Applicative f, Traversable t1, Traversable t2) => (a -> f b) -> t1 (t2 a) -> f (t1 (t2 b))
06:40:19 <merijn> hmm, not quite
06:40:30 <merijn> What's the type of concat there?
06:40:45 <kupi> t [b] -> [b]
06:40:47 <tomsmeding> hoogle has similar things under the name concatMapM, though this has an extra >>=
06:41:06 <merijn> :t concat
06:41:09 <lambdabot> Foldable t => t [a] -> [a]
06:41:33 <merijn> :t \f -> traverse (concat . f)
06:41:35 <lambdabot> (Traversable t1, Foldable t2) => (a -> t2 [b]) -> t1 a -> [t1 b]
06:41:48 <merijn> :t \f -> sequence . traverse (concat . f)
06:41:50 <lambdabot> (Monad m, Traversable m, Foldable t) => (a1 -> t [a2]) -> m a1 -> m [a2]
06:42:46 <nshepperd> it's foldMapM with an extra >>=
06:42:57 <merijn> kupi: Anyway, this seems fairly specific so I'm not sure there really is a generic name
06:44:56 <nshepperd> which i guess would just be foldMap if we had the generic monoid instance for applicative
06:45:04 <merijn> We do
06:45:06 <merijn> :t Ap
06:45:08 <lambdabot> forall k (f :: k -> *) (a :: k). f a -> Ap f a
06:45:10 <nshepperd> alaf Ap foldMap
06:45:27 <merijn> I'd just use "getAp . foldMap (Ap . f)"
06:45:35 <nshepperd> we have it but we don't *have* it :p
06:45:46 <kupi> foo f = mapM f >>> fmap concat
06:49:06 <Lurkki> joel135 thanks very much
06:49:14 <Lurkki> works great
06:49:25 <joel135> np i needed some practice
06:56:36 <Lurkki> joel135 if it's not too much to ask, how could I use the `sumStats` function with that, since my actual record isn't so simple
06:57:11 <joel135> hmm
07:03:06 <joel135> https://paste.debian.net/1176356/
07:03:40 <joel135> wait it is not abstract enough
07:04:57 <joel135> https://paste.debian.net/1176357/
07:09:26 <merijn> ick...fromJust
07:11:18 <ystael> Anyone know where in lsp-haskell I can supply an option to tell haskell-language-server it should not default to optimizing compile?
07:11:24 <ystael> (emacs lsp-haskell, sorry)
07:16:01 <dminuoso> huh, it defaults to optimizing?
07:22:24 <fendor> ystael, it almost definitely disables all optimisations
07:24:41 <Lurkki> i think it'd be better to wrap Stats in a Maybe to make sumStats' Maybe Stats -> Maybe Stats -> Maybe Stats
07:26:04 <Lurkki> or use intersectionWith
07:26:59 <ystael> Well, I find that compiling in haskell-language-server inside emacs is slower than in stack build, and when I run the stack build with optimization turned off, it rebuilds a bunch of things because "Optimisation flags changed"
07:27:13 <ystael> so I can't find hard evidence, but the external behavior suggests that HLS is optimizing
07:27:50 <ystael> but my setup has enough weird ad hoc stuff in it that if there isn't "a standard place to set this" already it's not worth asking the channel to troubleshoot :)
07:35:22 <adder> hello, i have an issue with quoting, this is my code: `clickable' s w = xmobarAction ("xmonadctl view\\\"" ++ show s ++ "_" ++ w ++ "\\\"") "1" w` i expect it to produce `xmonadctl view"0_1"` for example, but it's producing 0_5"
07:38:42 <joel135> using Maybe seems more dangerous in my opinion
07:39:55 <tomsmeding> adder: what is the entire result? I guess it's not just `0_5"`
07:40:09 <adder> Couldn't find command 0_4"
07:40:26 <Lurkki> how's Maybe dangerous
07:40:37 <joel135> ... because it is more complex and it is not clear how to properly handle Nothing if the case Nothing is never supposed to happen.
07:40:59 <tomsmeding> adder: do you want the quotes " to be interpreted by the shell, or do you want the argument to xmonadctl to literally be view"0_1"?
07:41:11 <adder> yes the latter
07:41:17 <joel135> if in the future the behavior of sumStats changes to make Nothing a possible output for the first time, sumStatLists may not have made the right assumption about how to handle Nothing
07:41:38 <tomsmeding> are you sure that 'show s' doesn't result in spaces?
07:41:43 <tomsmeding> adder: ^
07:42:46 <adder> s is a ScreenId, i think it should be just a short numerical string
07:42:58 <tomsmeding> because if `show s` for example produces `abc 0`, then you'd be producing `xmonadctl view"abc 0_1"`, where xmonadctl gets two arguments
07:43:10 <tomsmeding> don't know xmonad so don't know how it would interpret that
07:43:17 <tomsmeding> "i think it should be" -- check that :)
07:43:40 <sm[m]> g'day all
07:44:30 <sm[m]> anybody else dealing with "can't load framework" errors on mac os 11 / big sur ? I think no GHC release fixes it yet, right ?
07:44:31 <joel135> how would you sum s1 := Nothing and s2 := Just s? a possible bug that one might fail to catch: s1 >>= \s1_ -> s2 >>= \s2_ -> sumStats s1_ s2_  discards s!
07:45:20 <joel135> this would fail silently
07:45:31 <sm[m]> aha, https://www.reddit.com/r/haskell/comments/k9r2cy/workaround_for_haskell_woes_on_macos_11_big_sur/
07:48:08 <Lurkki> i don√§t think that failing matters since we're always inputting `Stats` without the `Maybe`
07:48:26 <joel135> true
07:53:52 <joel135> but then these toMap and fromMap are not inverses anymore. if you decide to implement [[Stats]] -> [Stats] and "optimize" by removing some "redundant"  composites (toMap . fromMap) it may fail silently.
07:55:32 <kupi> is there a transformer for IO ([String])?
07:55:43 <kupi> Control.Monad.Trans.List is deprecated
07:55:55 <merijn> kupi: For doing what?
07:56:38 <kupi> getting a list of files recursively
07:57:20 <Lurkki> https://paste.debian.net/1176370/
07:57:40 <joel135> that's what i warned against
08:03:41 <tomsmeding> Lurkki: just passing by and saying that sumStats' in your latest paste can also be written as: liftM2 sumStats
08:03:41 <joel135> i think this is safer https://paste.debian.net/1176374/
08:17:51 <Kronic> Hey there, can I ask a question in relation to stack here? I am just a little bit curious as to what the motivation was for how dependencies are handled, to me it is just very not obvious how to install just install a package and use it. Dependencies are spread over multiple files. Why is that and where can I read about why this design decision was made?
08:19:27 <merijn> Kronic: Stack is project based, so the entire idea of "install a package and use it" isn't supported
08:19:41 <merijn> Kronic: You always use a package as "dependency of a project"
08:20:38 <Kronic> How is that different in comparison to say, installing an NPM package in JavaScript?
08:21:40 <merijn> Kronic: Basically, the idea of "globally installing a package" is just kinda dumb when you think about it. Because if you work on more than 1 project and those projects need different versions of the same dependency, then you're screwed
08:22:11 <merijn> Unless, of course, your package manager allows you to install the same package multiple times
08:22:15 <nicholassmith> et vim_mode_cmd_seq kj
08:22:23 <Lurkki> if you want to install libs "globally", use nix
08:22:29 <Kronic> Oh, I do not mean globally installing packages. I do not want that. I want to simply run one command and then just have a package work for my project
08:22:32 <merijn> But then you get the problem "if I have 3 versions of package "foo" installed, which version do I expect to use"
08:22:47 <Kronic> When I said install, I meant install ¬®to this project¬®
08:23:33 <Kronic> So, basically your second definition, with npm you differentiate those via npm install and npm install -g -- My point was that seemingly with stack install there are extra steps, and I was wondering why those are necessary
08:23:34 <merijn> Kronic: There's no real command for that, you generally just "add it to the cabal file" (or hpack, for people I haven't managed to convince to not use hpack)
08:23:36 <Lurkki> or you can use inline cabal
08:24:10 <Lurkki> i usually use nix-shell if i want to work with some lib temporarily
08:24:30 <merijn> Lurkki: There isn't a single beginner whose life was made better by adding Nix :)
08:25:03 <Lurkki> nix-shell was easier to me as beginner than trying to figure out cabal
08:25:07 <merijn> Kronic: If you say "I have to add it in two places" you presumably mean in both stack.yaml and your cabal file (or package.yaml for hpack)
08:25:11 <Kronic> Yea, honestly I appreciate the variety of options available, but I am just looking to get a simple workflow going so I can focus on learning the language more
08:26:42 <merijn> Kronic: Stack is based on "curated snapshots" with stack.yaml defining which snapshot (aka resolver) to use. If you wanna use something outside of the curated set, you have to tell it about it (which is why you may need to add things to stack.yaml)
08:26:59 <merijn> Kronic: .cabal is the thing that actually defines your package (see: https://gist.github.com/merijn/8152d561fb8b011f9313c48d876ceb07)
08:27:27 <merijn> (which is why everything has to go in .cabal, regardless of whether it's in the snapshot)
08:28:15 <Kronic> I see, so that makes some sense -- is there a flag I can use to just put it in both files automatically?
08:28:50 <merijn> I don't use stack, so I dunno, but I suspect "no"
08:29:13 <sm[m]> Kronic: normally you don't list packages in stack.yaml - only if they are not in the snapshot you specified
08:30:00 <sm[m]> you kind of have to read one or other of the intros to these tools, they are not obvious otherwise
08:30:12 <sm[m]> s/ otherwise//
08:31:24 <Kronic> I have read the intros to both and I more or less knew most of what was discussed here, I was just talking from a usability perspective. It just seems a little strange to me that there is not just one command I can use to install a package and focus on the actual problem I have. Thanks for your help though, I guess I will just learn them both separately and then come back to working on my code.
08:32:15 <sm[m]> Kronic: are you sure there isn't ? Can you describe this use case more exactly ?
08:32:51 <sm[m]> you're writing some software, you want to import code from some external package, so you need to add that package to your project deps.. right ?
08:32:52 <dolio> I don't really understand the issue. You just list the dependency in a file, and then you build. You have to list dependencies in a file with npm, too, if I recall.
08:33:54 <Kronic> My use case is the following: I have a package that I want to use. I want to run one command and have that be immediately available without editing any build files. Maybe I was being a little presumptious, but more or less every other language build/dependency management tool I have ever used allowed me to just run a command to get access to the dependency that I want
08:34:45 <Kronic> An example would be if I ran npm install <something> in javascript, the dependency is automatically added to the right place in the package.json file, with stack there is seemingly multiple places for dependencies to go, but I figured there would perhaps be a flag I could use on the install command to give me some sane default
08:35:18 <glguy> Does anyone understand why I get so many warnings "Warning: The package has an extraneous version range for a dependency on an internal library:..." https://gist.github.com/glguy/290dc1da6b4c9812aff05ef36a8a4ca4#file-output-txt-L31 
08:35:49 <sm[m]> that's interesting.. so in js you run the install command and it updates the project deps file. In hs we update the project deps file and it runs the install command (next time you do stack build or stack repl)
08:36:06 <glguy> oh, looks like it's just a known bug https://github.com/haskell/cabal/issues/5119
08:36:12 <Kronic> Ah... okay, that makes sense sm[m] 
08:36:35 <Kronic> I was figuring this was not a two step process. If I use the file-watch flag on stack build will it automatically do that?
08:36:49 <sm[m]> our way is different, but really pretty easy usually (add - somepackage-VERSION to package.yaml (or the .cabal file if you don't use package.yaml)
08:36:56 <sm[m]> yes it will
08:37:43 <Kronic> Okay, that is exactly what I was looking for. Thank you. I was just convinced there was no way I had to do two things when it is a one step process everywhere else. Thanks again 
08:38:35 <sm[m]> you will occasionally have to do more than one thing, I can't lie :)
08:38:59 <sm[m]> but not in that common case
08:39:08 <Kronic> Yea, that is why I opened with my original question
08:39:36 <Kronic> My thought was if this is just not obvious or easy, why is that, it sounded like a trade off but it was actually just thinking the opposite way to what I am used to
08:40:23 <sm[m]> example: you are using stack and you want to add a package that's not included in your stackage snapshot - then you must add it in both package.yaml and in stack.yaml's extra-deps list
08:40:41 <sm[m]> but that's not too bad
08:42:15 <sm[m]> another one: you are using VS Code & Haskell extension - I think it won't automatically notice a change in package.yaml or the .cabal file, so you have to Restart Haskell LSP Server 
08:43:41 <Kronic> I see, I will keep that in mind, thank you
08:44:45 <sm[m]> it would certainly be possible to write a script, and perhaps some day contribute as a stack/cabal command, that we could run for such a common task, and hide some of the variations
08:45:18 <sm[m]> maybe it's out there on hackage.. but editing the file is easy enough that maybe it doesn't exist
08:45:55 <Kronic> If I stick around long enough to get good enough to do something like that, I will do that. To me it is an obvious no-brainer coming from the JS world, but I appreciate that it was just a different thought process here.
08:46:23 <sm[m]> if you do, I'll test!
08:46:54 <sm[m]> would be interesting to compare the commands/workflows you're used to with ours
08:47:13 <dolio> I'm not sure it really makes sense except in particular scenarios.
08:47:40 <dolio> Like, there can be multiple sections in the relevant files, each with their own dependencies.
08:47:41 <ccapndave> Hey everyone - I'm pretty new to Haskell.  Is there a way to "unwrap" an `IO` value in GHCI?
08:48:04 <ccapndave> i.e. I run a function (in GHCI) that returns `IO Text`, but I want to get the `Text` in GHCI
08:48:19 <sm[m]> dolio: yes
08:49:03 <ccapndave> Ah, I just found the `<-` works on the prompt :)
08:50:08 <solonarv> ccapndave: yeah, the GHCi prompt is a Frankensteinish mixture of 'giant do-block in IO', 'top level of a Haskell source file', and 'interactive command interpreter'
09:20:36 <ezzieyguywuf> hrm, I think regexp may be the solution for my use-case, not writing a parser. I want my user's to be able to specify in a configuration file "take such-and-such portions of a string, and put them together. These other portions, save them for later", which sounds a lot like regexp capture groups
09:21:11 <ezzieyguywuf> to make this work with a parser I find myself essentially developing a mini-language in my configuration file and then translating that to megaparsec
09:21:15 <ezzieyguywuf> but it is non-trivial
09:23:03 <solonarv> that does seem like a sensible use of regex to me; another plus of that is being able to use an existing flavor of regex, so you can just point your users to that flavor's documentation
09:23:06 <glguy> regexp seems like the right solution for that kind of problem
09:23:13 <sm[m]> ezzieyguywuf: indeed, I think (some form of) regexps are that language
09:27:18 <ezzieyguywuf> solonarv: precisely
09:27:29 <ezzieyguywuf> well, glad we reached a consensus
09:27:36 * ezzieyguywuf pats self on back, and thumb's up to the team
09:27:56 <ezzieyguywuf> I did get a very basic version of the parser thing working though, but it scaled extremely poorly, lol.
09:28:08 <ezzieyguywuf> hats off to glguy because config-value/config-schema is up to the task
09:48:12 <ezzieyguywuf> üòç regex-tdfa
09:48:30 <ezzieyguywuf> (1) seems to already be here (I guess some other dependency built it), (2) seems very straightforward to use
09:50:03 <ezzieyguywuf> very clever use of polymorphism in =~
09:50:15 <ezzieyguywuf> (or maybe it's not so clever and I'm just so n00b)
09:51:35 <ezzieyguywuf> hrm, but maybe I want pcre, seems to be more prevalent
09:51:49 <ezzieyguywuf> i.e. I think pcre is the regex I think of when I say 'regex'
09:52:46 <sm[m]> ezzieyguywuf: regexps in haskell are a bit painful, choose with care. Do you need it to build easily on windows ? Do you need replace ? Capture groups ? etc.
09:53:02 <dminuoso> pcre-heavy is nice if you're into regular expressions
09:53:11 <dminuoso> And really light on the ergonomics, despite its name
09:54:10 <sm[m]> https://hackage.haskell.org/package/regex and the brand-new https://hackage.haskell.org/package/pcre2 are also worth checking out I expect
09:54:44 <ezzieyguywuf> yes capture groups, preferably yes windows, probably not replace
09:54:51 <sm[m]> for a portable solution, I use regex-tdfa plus some replace helpers
09:55:11 <dminuoso> There's also regex-applicative
09:55:32 <dminuoso> Which is a really darn well built library with a minimal dependency footprint.
09:55:52 <dminuoso> (Go ApplicativeDo, and capture groups is just monadic looking bind)
09:57:06 <ezzieyguywuf> 'Go'?
09:57:07 <sm[m]> dminuoso: hmm, it's hard for me to recognise that as a regular expressions package
09:58:16 <dminuoso> sm[m]: it parses regular grammars..
09:58:29 <dminuoso> you can parse regular expressoins with it
09:58:47 <dminuoso> Unless of course you confuse "regex" with "PCRE looking regex matchers"
09:58:54 <sm[m]> sure, but ezzieyguywuf wants to provide recognisable user-facing regular expressions 
09:59:42 <dminuoso> Hard to say
10:00:38 <dminuoso> Also consider, giving your user access to regex is an invitatoin for ReDoS depending on the underlying implementation
10:00:54 <ezzieyguywuf> ReDoS?
10:01:02 <dminuoso> https://en.wikipedia.org/wiki/ReDoS
10:01:25 <sm[m]> ezzieyguywuf is building a tool that users run offline on their own data I think
10:01:48 <dminuoso> Im just giving them the insight, I dont know how things are tied together at the end
10:02:03 <sm[m]> +1
10:03:34 <ezzieyguywuf> yea, not woried about ReDoS after reading the wiki
10:03:40 <ezzieyguywuf> dminuoso: appreciate it.
10:03:42 <dminuoso>  17:49:45      solonarv | ccapndave: yeah, the GHCi prompt is a Frankensteinish mixture of 'giant do-block in IO', 'top level of a Haskell source file', and 'interactive command interpreter'
10:03:59 <dminuoso> That is a scary thought. If GHCi starts to seek revenge against its authors..
10:04:04 <ezzieyguywuf> lol, I dove into the ghci code once, I was like üòµ
10:04:15 <ezzieyguywuf> ...or was it ghcid?
10:08:49 <ezzieyguywuf> so regex-pcre requires an external c-library
10:09:08 <ezzieyguywuf> probs present on most linux, ad probably mac, but for windows would it be a hassle?
10:09:46 <sm[m]> I think we could bet on it
10:10:22 <sm[m]> but worth testing eg with a stack build on windows
10:11:12 <sm[m]> I tested it some years back
10:11:15 <ezzieyguywuf> hrm, but regex-pcre-builtin bundles the pcre code, so it would build during cabal build I imagine
10:11:50 <ezzieyguywuf> i'll have to fire up my windows vm later to try it out
10:43:02 <dsal> I don't have a good mental model around what ~ does in a lambda parameter other than the opposite of !.
10:43:49 <dsal> e.g., when using criterion env, you're supposed to do something like this:  `env getInput $ \ ~x -> ...` ...  I don't fully understand why the ~ is necessary.
10:45:20 <monochrom> ~x is unnecessary, it's just x, you're right about that.
10:45:37 <dsal> Oh.  When would it be necessary?
10:46:07 <monochrom> I agree with your model that ~ and ! are opposites.
10:46:14 <geekosaur> in a case expression, as opposed to a lambda, when you need the pttern to be lazy instead of strict
10:46:46 <monochrom> (let !(x,y) = foo in ...) = case foo of (x,y) -> ...
10:46:47 <dsal> Oh interesting.  OK.  I don't really think about where stuff is forced.
10:46:54 <geekosaur> although, hm, I thought lambda patterns desugared to cases so ~ would be necessary; it was let pattersn that are default lazy
10:47:02 <monochrom> (case foo of ~(x,y) -> ...) = let (x,y) = foo in ...
10:47:24 <monochrom> So in that sense (which is very strong) ~ and ! are opposites.
10:48:05 <dsal> Well I don't know why I've cargo-culted this ~ as my parameter to env, then.
10:48:42 <monochrom> Although, (let !x = foo in ...) becomes (let x = foo in seq x ...) and this is not reproduced by (case foo of x -> ...)
10:49:05 <dsal> Is there something special about tuples?  It specifically mentions them in the docs.
10:49:35 <dsal> "The function that receives the environment must use lazy pattern matching to deconstruct the tuple (e.g., ~(x, y), not (x, y)), as use of strict pattern matching will cause a crash if an exception-throwing value is passed in."
10:49:50 <monochrom> (Although^2, GHC Core's "case foo of x -> ..." does a seq, different from Haskell's "case")
10:50:57 <monochrom> That sentence applies to your homebrew tuple/record types, too.
10:51:17 <monochrom> E.g., it applies to "data MyTuple a b = MkMyTuple a b" just as well.
10:51:48 <monochrom> "\(MkMyTuple x y) -> ..." is different from "\~(MkMyTyple x y) -> ..."
10:52:46 <dsal> Hmm...  So is it just about when the exception is handled?
10:52:53 <monochrom> When your function doesn't always need x or y, and when you anticipate that the caller of your function may give you bottom instead of a constructed tuple, you will need the extra laziness of ~
10:52:59 <dsal> I have this problem where laziness just does what I want most of the time and I don't have to think about it.
10:53:13 <monochrom> :)
10:53:33 <dsal> Oh, so like partially filled records and stuff would be fine for a particular test with ~ but fail with !
10:53:54 <monochrom> No no, not partially-filled record.  No record at all, plain bottom.
10:54:32 <dsal> I guess I just don't know why I would do that in this situation.
10:54:32 <monochrom> (\(MkMyTuple x y) -> ...) (MkMyTuple bottom bottom) is fine.  (\(MkMyTuple x y) -> ...) bottom isn't.
10:56:06 <monochrom> Here is my favourite example of ~(x,y).  It is tying a knot, therefore needs maximum laziness (tl;dr).
10:57:31 <monochrom> Define f ~(xs , ys) = (1:ys, 0:xs).  Define  xys = f xys.
10:58:24 <monochrom> If you forget the ~, my code becomes unproductive.
10:59:49 <dsal> Neat.
10:59:57 <monochrom> I am not familiar with any use case that involves errors instead of infinite data.  Normally I want errors to manifest as early as possible, no?
11:01:05 <ezzieyguywuf> I'm using the regex-tdfa documentation b/c the regex-pcre doesn't include as much info
11:01:08 <ezzieyguywuf> (why....?)
11:01:18 <ski> @src partition
11:01:19 <lambdabot> partition p xs = foldr (select p) ([],[]) xs
11:01:19 <lambdabot>     where select p x ~(ts,fs) | p x       = (x:ts,fs)
11:01:19 <lambdabot>                               | otherwise = (ts, x:fs)
11:02:30 <ski> @let partition' p xs = foldr (select p) ([],[]) xs where select p x (ts,fs) | p x = (x:ts,fs) | otherwise = (ts,x:fs)
11:02:33 <lambdabot>  Defined.
11:02:37 <geekosaur> ezzieyguywuf, presumably because (a) core documentation comes from the base regex package, which the others extend (b) and much of the rest for PCRE comes from the C PCRE package
11:02:55 <ski> > let (xs,ys) = partition even [0 ..] in (take 4 xs,take 4 ys)
11:02:58 <lambdabot>  ([0,2,4,6],[1,3,5,7])
11:03:00 <ski> > let (xs,ys) = partition' even [0 ..] in (take 4 xs,take 4 ys)
11:03:08 <lambdabot>  mueval-core: Time limit exceeded
11:03:08 <lambdabot>  mueval: ExitFailure 1
11:17:17 <scasc> is there something like `sleep :: Int {- seconds -} -> IO ()` in base? I could only find it in the package "extra" and "unix"
11:18:10 <scasc> Those are rather heavy dependencies
11:18:13 <dsal> scasc: `sleep = liftIO . threadDelay . seconds`
11:18:27 <dsal> @hoogle threadDelay
11:18:27 <lambdabot> Control.Concurrent threadDelay :: Int -> IO ()
11:18:27 <lambdabot> GHC.Conc threadDelay :: Int -> IO ()
11:18:27 <lambdabot> GHC.Conc.IO threadDelay :: Int -> IO ()
11:18:45 <dsal> seconds :: Num p => p -> p; seconds = (1000000 *)
11:18:59 <scasc> dsal: Thanks for the pointer to threadDelay!
11:19:18 <dsal> I'm annoyed there's not a proper type for time that these things use.
11:19:54 <scasc> (at least newtype)
11:21:27 <scasc> hm, before I asked I put `a -> IO ()` into hoogle, and this didn't show up. but that's not because hoogle interprets "a" as "user requests most generic type", as signatures with constraints (ie. less than unresticted) are displayed
11:21:58 <scasc> @hoogle liftIO
11:21:59 <lambdabot> Control.Monad.IO.Class liftIO :: MonadIO m => IO a -> m a
11:21:59 <lambdabot> GHC.IO liftIO :: IO a -> State# RealWorld -> STret RealWorld a
11:21:59 <lambdabot> Test.Framework.Providers.API liftIO :: IO a -> ImprovingIO i f a
11:23:29 <dsal> IO is MonadIO.  That sleep just works in all the transformers.
11:25:03 <scasc> I was just looking up the module name :-)
11:35:07 <justsomeguy> In ‚Äúclass Functor (f :: * -> *) where‚Äù ... is the ‚Äú(f :: * -> *)‚Äù a kind signature?
11:36:51 <koz_> justsomeguy: Yes.
11:37:01 <koz_> Although the more modern spelling of that is (f :: Type -> Type).
11:38:46 <justsomeguy> Where does ‚ÄúType‚Äù come from? I thought that kind signatures can only have ‚Äú*‚Äù, ‚Äú->‚Äù, and ‚Äú#‚Äù.
11:39:11 <koz_> justsomeguy: It's just another way of saying '*'.
11:39:15 <koz_> It comes from Data.Kind.
11:39:23 <glguy> They have * and ->; # is a GHC-ism from old-times
11:46:16 <jle`> justsomeguy: just to be clear, the * -> * is the kind here, and it's being ascribed to f
11:46:34 <jle`> like `id :: Int -> Int`
11:51:35 <justsomeguy> Could a type signature like ‚Äúf :: a -> a‚Äù be used to limit the arity of ‚Äúf‚Äù, instead of a kind signature?
11:52:26 <geekosaur> no, because f does not have a type, it's a typeclass and has a kind
11:54:36 <fresheyeball> is there anyone I can talk to about GHCJS? I have a hard one
11:54:43 <justsomeguy> Oh, ‚Äúf‚Äù is a type constructor, anyways. I got confused for a second there.
11:54:48 <fresheyeball> but it's not that I have a hard one
11:54:57 <fresheyeball> it's that I don't know if there is anyone I can talk to
11:57:47 <fresheyeball> like, when should I use syncPoint. Why is my IO monad not fully evaling when normally it should
12:01:46 <justsomeguy> I'm only a newbie, but generally I have more luck with long-form formats for complicated questions. Maybe it would help to make an example repository and do a short write up on the problem on the mailing list?
12:02:12 * justsomeguy is not sure which mailing list would be appropriate, though. Maybe #ghc would know.
12:02:38 <geekosaur> reddit might be better
12:02:59 <geekosaur> #ghc probably not unless it's a question about developing ghc / ghcjs
12:04:29 <sm[m]> or draft your q on a paste site and we could help you refine it
12:22:44 <fresheyeball> I posted my problem in #reflex-frp if anyone is interested
12:31:58 <bor0> I am trying to wrap my head around how `memoize` works, as defined in https://wiki.haskell.org/Memoization, especially this part: "= (fibMemo 1 + fibMemo 0) + fibMemo 1" and only a brief comment saying `fibMemo 1` will be evaluated only once. why is this the case?
12:34:48 <glguy> bor0: there's a block of text walking through why below. Did you have a question about a line or portion of that?
12:35:21 <glguy> let x = f y in x + x
12:35:46 <glguy> Does it make sense that 'x' need only get evaluated once there despite it being used twice?
12:36:02 <bor0> No, sorry. That's what confuses me.
12:36:34 <bor0> Does it hold in general that `f x + f y + f x` means evaluating `f x` once in Haskell?
12:36:37 <glguy> no
12:37:10 <bor0> I guess my question is. what makes this case special - (fibMemo 1 + fibMemo 0) + fibMemo 1
12:37:31 <glguy> what you wrote wouldn't reuse fibMemo 1
12:38:04 <glguy> It would have to be more like: let f1 = fibMemo 1; f0 = fibMemo 0 in (f1 + f0) + f1
12:38:10 <bor0> right below that, there's a comment saying -- Note: Because of the memoization, both ìfibMemo 1î terms refer to the same thunk,
12:38:17 <glguy> in this case instead of discrete names like f0 and f1
12:38:19 <bor0> Maybe this comment refers to the line below, not above
12:38:22 <glguy> you have a list of the expressions
12:38:34 <glguy> let fs = map fibMemo [0..]
12:38:46 <glguy> fs :: [Integer]
12:39:36 <glguy> if you look at the 3rd element of that list twice it will only have to be computed the first time you look
12:40:11 <glguy> The way GHC compiles things once a lazy "thunk" is evaluated it gets replaced with the answers
12:40:24 <bor0> So, let x = map (+1) [0..] in (x !! 0, x !! 0) evaluates `x !! 0` only once?
12:40:58 <bor0> Sorry, I meant "evaluates 0+1 only once"
12:41:22 <glguy> yeah
12:41:54 <bor0> Would that still be true for let x = map (+1) [0..10] in (x !! 0, x !! 0) ?
12:41:55 <glguy> you get something like:   let x = (thing that adds 0+1 when needed and replaces this sentence with 1 afterward) : map (+1) [1..]
12:42:48 <glguy> yeah, it doesn't matter that the list is infinite or not
12:42:49 <dminuoso> It should be said that if GHC spots `f x + f y + f x` and optimizations are enabled, then if it's possible-to-likely GHC will turn it into `let fx = f x in fx + f y + fx`, but that's not a guarantee you get from the language or the compiler.
12:43:09 <dminuoso> Equivalently, if you name it, GHC is still free to inline the definition (thwarting sharing)
12:43:17 <glguy> common subexpression elimination is not an optimization you should rely upon
12:43:19 <bor0> glguy, ah, right, the lazy load kicks in for both finite/infinite lists.
12:43:29 <glguy> and GHC tries not to do replacements that will blow up like that
12:47:29 <dminuoso> bor0: This is the definition of cycle: cycle xs = xs' where xs' = xs ++ xs'
12:47:46 <dminuoso> Do you understand why there's a seemingly useless binding xs'?
12:48:26 <bor0> yeah, that seems pretty similar to `fix`, for infinite computation right?
12:48:54 <bor0> > take 10 $ fix ((:) 3)
12:48:58 <lambdabot>  [3,3,3,3,3,3,3,3,3,3]
12:49:53 <dminuoso> This just ensures that the infinite list uses constant space. The rationale is: If you name it, you can share it - so this does sharing in a cyclic structure, ensuring that in memory the list will loop like a p sideways (where it goes back to itself)
12:50:41 <bor0> Wow. I guess this sharing isn't happening in the `fix` example?
12:51:27 <dminuoso> It does actually, it's sort of the point of fix. :)
12:52:25 <bor0> yeah but I thought like 3:3:3:... would generate new copies of 3 every time
12:52:45 <dminuoso> fix f = let x = f x in x
12:52:55 <monochrom> "x = f x" shares x.  "zs = 0 : zs" shares zs.
12:53:08 <bor0> ahhh!
12:53:16 <dminuoso> If its named (see the let x = ... binding site), it can be shared (usually).
12:55:00 <monochrom> f n = f (n-1) + f(n-1) takes time exponential to g n = let x = g (n-1) in x + x
12:55:26 <bor0> I am certain this is related to my memoization question (since we talk about `fix`) but there's too many dots for me to connect now. I guess the point here is that the space only grows when it meets a new number (memoized)?
12:57:51 <dminuoso> bor0: The space isn't necessarily the problematic part (it might still grow depending on whether reference prevent garbage collection). It's that the result is sharable, and thus can be reused.
12:58:13 <dminuoso> So it avoids re-computing what you already held in your hand, like in monochrom's example
12:59:20 <bor0> Going back to `let x = map (+1) [0..] in (x !! 0, x !! 0)`, I guess the sharing happens here as well? Since we have `let x = ... x ...`
13:00:14 <dminuoso> Right. There's actually a trick you can use to observe this
13:00:19 <dminuoso> % :t trace
13:00:20 <yahb> dminuoso: String -> a -> a
13:02:16 <dminuoso> If you wrote: let x = trace "forced" (map (+1) [0..]) in (x !! 0, x !! 0)
13:02:27 <dminuoso> Then it will print "forced" whenever x is evaluted/forced/demanded.
13:03:19 <dminuoso> That lets you experiment and observe when/whether something is evaluated at all. It's also a valuable debugging primitive when something goes wrong deep in pure code and you have no easy way of threading IO in.
13:03:32 <bor0> I am now wondering why it printed `forced` twice
13:04:02 <dminuoso> It's quite possible GHC decided to inline the definition of x.
13:04:05 <bor0> I would have expected (forced 1, 1) but it's instead (forced 1, forced 1)
13:04:49 <dminuoso> So what was said earlier about "you get sharing when you name it" only holds true if GHC doesn't inline your definition anyway
13:05:13 <bor0> What does inlining a definition mean and can we alter that behavior somehow?
13:05:39 <dminuoso> Simplest way is to disable optimizations entirely, this is perhaps better for experimentation here.
13:06:05 <dminuoso> In general GHC has pretty good heuristics to figure out when to inline regardless of whether you floated it out on a let.
13:06:36 <dminuoso> And inlining means replacing occurences of x with its definition.
13:06:50 <bor0> OK, so simple substitution
13:07:06 <bor0> This printed it only once `let x = trace "forced" (map (+1) [0..]) in take 5 $ repeat [x !! 0]`
13:07:28 <bor0> I get the feeling that this sharing thing seems to occur only when laziness is in play
13:07:53 <bor0> Maybe it is my optimization settings, I have no idea. But TIL that GHC is a monster with a lot of magic behind :)
13:08:17 <dminuoso> bor0: The thing with the previous example is, it's quite possible GHC figured out what you were doing and just inlined it all the way, such that it became ("forced" `trace` 0, "forced" `trace` 0)
13:09:05 <solonarv> bor0: you can tell GHC that it should or shouldn't inline a particular binding, sure; both of these can end up being useful
13:09:31 <dminuoso> bor0: The primary optimization mechanism in GHC is inlining, inlining and inlining!
13:09:40 <bor0> dminuoso, so can we say that in general GHC will not inline expressions when laziness is in play?
13:09:51 <dminuoso> Many of the other transformations GHC does in the optimizer is just to create opportunities for more inlining.
13:09:56 <bor0> Otherwise, how can we be certain that fibMemo will always work??
13:11:02 <dminuoso> bor0: Regarding "can we say that in general GHC will not inline expressions when laziness is in play?" - no.
13:11:55 <bor0> How does it know not to inline the memoized fibonacci implementation? Or I guess it can't inline it, but if it can't, why?
13:12:01 <dolio> I think it's pretty unlikely that it turned it into `("forced" `trace` 0, "forced" `trace` 0)`
13:12:29 <dminuoso> bor0: So lets take the previous example and dolio's comment and bring that together. Look at core!
13:12:45 <solonarv> there are a bunch of heursitcs, like "don't inline big things", "don't inline recursive things", and so on
13:13:14 <dminuoso> dolio: Oh well, it should be 1 rather than 0 I guess if that's what you meant. :P
13:13:15 <dolio> Like, it might have inlined stuff, but it doesn't do enough partial evaluation for that good a result, I think.
13:14:07 <dolio> Yeah, it should also be 1, but that wasn't what I was thinking.
13:14:44 <dminuoso> bor0: So if you take your previous example, run GHC with `-ddump-simpl` and observe the output.
13:15:18 <dolio> Like, I would be surprised if it turned `[0..] !! 0` into `0` at compile time. I didn't think it actually did much of that.
13:15:34 <bor0> How can I pass `--ddump-simpl` to `stack`? I am using `stack repl`
13:16:10 <dminuoso> bor0: add `--ghc-options '-ddump-simpl'`
13:16:35 <dminuoso> Make sure to clean first, or use --force-dirty/-fforce-recomp
13:17:38 <bor0> I am seeing a lot of code but I have no idea what it represents (looks like a lambda with IO and stuff), and (forced 1, forced 1)
13:17:41 <dminuoso> dolio: Oh, perhaps it floated the map definition out, and then inlined x?
13:18:09 <dminuoso> That is, turned it ito `let m = map (+1) [0..]; x = trace "forced" m; in (x !! 0, x !! 0)`
13:18:28 <dminuoso> bor0: Can you share the output in a gist?
13:18:32 <dminuoso> @where paste
13:18:32 <lambdabot> Help us help you: please paste full code, input and/or output at eg https://paste.tomsmeding.com
13:18:32 <dolio> I think you guys might be missing the obvious explanation.
13:19:05 <bor0> https://paste.tomsmeding.com/ZoqUZJJD
13:19:24 <dolio> bor0: Is this in the repl?
13:19:44 <bor0> Yeah I used `stack repl  --ghci-options '-ddump-simpl' --force-dirty`
13:20:09 <dolio> Well, I mean, are you typing the 'let' thing above in the repl directly?
13:20:25 <tomsmeding> the repl doesn't do sharing as aggressively as the compiler usually does
13:20:41 <bor0> oh yeah, if you search for `import Debug.Trace` it's right below that line
13:20:52 <bor0> (this paste has no line numbers it seems)
13:20:53 <tomsmeding> if you type that in a function in a normal haskell file, load that file in the repl and then run the function, you'll only see one "forced"
13:21:03 <tomsmeding> line numbers are todo sorry
13:21:18 <dminuoso> tomsmeding: Counting is a hard problem, don't worry. :)
13:21:28 <dminuoso> By the way, I have an explanation about the wildcard/type inference thing!
13:21:44 <dminuoso> Apparently `f :: _` does not subsume `f :: _ => _` ...
13:21:45 <dolio> dminuoso: Have you considered: what is the type of `x`?
13:21:49 <bor0> You're right! REPL seems to be different
13:21:59 <bor0> I get only one forced by just `stack repl test.hs`
13:22:04 <dminuoso> dolio: Ohhhh!
13:22:11 <dolio> :)
13:22:13 <dminuoso> Good catch. :)
13:22:57 <dminuoso> Yeah, so now we've told him about sharing, inlining, fix, showed how core works... and now we have to explain MMR and how polymorphism fits into all of this
13:23:12 <dolio> Yeah. And it's off in the repl.
13:23:41 <dminuoso> Right
13:24:27 <dminuoso> bor0: Do you want the tl;dr version, or the sophisticated explanation?
13:24:58 <bor0> I am writing a blog post about Advent of Code #10. For part two I wasn't able to use memoization (because I didn't know) so I learned how to use it but I had no idea why it works. I will write a short blog post with all of this info
13:25:20 <bor0> Oh I repeated the first and the last sentence. My energy has been drained.
13:25:33 <bor0> dminuoso, let's start with the tl;dr :)
13:25:48 <dminuoso> bor0: For your experimentation, it's best if you turned on `:set -XMonomorphismRestriction` (by default the REPL has this turned off). After you do this, you should see only one "forced"
13:26:26 <bor0> I know what polymorphism means but not monomorphism
13:26:39 <monochrom> The opposite.
13:26:46 <monochrom> Err, the negation.
13:27:38 <bor0> So `t a` vs `[Int]`?
13:27:42 <monochrom> Yes.
13:28:01 <dminuoso> The MMR, broadly speaking, causes code to be monomorphized when you might not expect it to.
13:28:12 <dminuoso> It's on by default, and that's a good thing.
13:28:25 <dminuoso> If it's off, you trip into problems *exactly* like yours
13:28:34 <dminuoso> Where sharing just doesn't seem to happen for no obvious reason
13:28:58 <monochrom> "x = 4" if its type becomes the polymorphic "Num a => a" then it requires re-computation every time you use it. Clearly, "4" is a simple example, imagine you have a formula there that takes 5 seconds to compute.
13:29:48 <monochrom> The monomorphism restriction says "so let's kill the polymorphism for x=4 so programmers aren't surprised by re-computations we think they didn't intend"
13:29:54 <dminuoso> The underlying reason is, something of type `f :: Num a => a` becomes a function internally, taking a dictionary. We can't memoize the result of `f 1 :: Int`, because what if the next person does `f 1 :: Double`?
13:30:03 <monochrom> But it will surprise you when you intend polymorphism, haha.
13:30:31 <dminuoso> The trade off is: Either programmers will have drastic performance bugs that are really hard to debug, or they have the occasional type error they have to fix with an explicit type annotation
13:30:43 <dminuoso> It was deemed better to have obvious-type errors than non-obvious performance bugs
13:30:51 <dminuoso> Especially because the former are really easy to fix
13:31:27 <bor0> Can you explain why polymorphic types require computation every time? Is it because of type inference (but if yes, this only affects the type checker no?)
13:31:44 <dminuoso> Well, let's say you had something `x :: Num a => a`
13:31:47 <dminuoso> With some elaborate implementation
13:31:52 <dminuoso> That took 5 seconds to compute
13:32:13 * tomsmeding thought that the repl just somehow did less sharing than ghc proper, but that of course makes no sense, default-NoMonomorphismRestriction explains it completely
13:32:17 <dminuoso> The consumer/user of a polymorphic binding decides on the type, so if you use `x` you decide what type you want it to have
13:32:51 <dminuoso> tomsmeding: It's funny, isnt it? 3 seasoned Haskell developers didn't spot it for half an hour.
13:32:54 <dminuoso> Precisely the reason we have MMR at all.
13:33:26 <tomsmeding> I didn't spot it in my own code (admittedly a bit more complex) for months
13:33:31 <monochrom> What you need is a seasoned user-guide lawyer like me. :)
13:33:32 <dminuoso> bor0: So if you decided to demand `x` at type Int, it would do the computation and hand you the result, say 11.
13:33:37 <dminuoso> Can it memoize the result 11?
13:34:02 <bor0> In some map of (Type, Value), yes?
13:34:13 <dminuoso> That could certainly be done, yes.
13:34:39 <monochrom> That's an idea there, but I think it doesn't fit the structure of any Haskell compiler so far.
13:34:42 <bor0> But I guess GHC doesn't do that for some reason (since we have the MMR problem)
13:35:30 <dminuoso> bor0: There's some other very subtle and curious reasons for the MMR. If you want to learn more, check the Haskell report on this.
13:35:38 <bor0> I guess the map gets more complex as the polymorphic type gets more complex so it's probably not that easy to solve
13:36:17 <dminuoso> bor0: I guess part of the problem is that the memoization we have is not an active caching we implement, it's rather an artifact of our implementation.
13:37:33 <dminuoso> Very roughly, evaluation in GHC is done by jumping into a thunk, and executing some entry code. Then this will cause the evaluation to occur, and when the result is obtained, the thunk rewrites itself such that the next time its entered, it will readily return the result
13:37:43 <dminuoso> (This is with a lot of handwaving, mind you)
13:38:45 <bor0> That's OK. I am used to it. In the beginning I thought Haskell was magical, then I got used to it, then I meet a concept like this that blows my mind and now I am back to the beginning - Haskell is magical
13:39:02 <bor0> Or probably not Haskell but just GHC (which I guess is really Haskell nowadays)
13:39:59 <dminuoso> bor0: Anyhow. Like I just said a short while ago, the fact that 3 seasoned Haskell developers didn't even spot why sharing didn't occur is very much the reason we have the "Dreaded Monomorphism Restriction in the Haskell report itself.
13:40:30 <dminuoso> So this MMR is not just GHC, it's part of Haskell (as per Haskell2010) itself
13:42:09 <bor0> Well thank you dminuoso monochrom and others. I've learned a lot! That was fun. I'll try to digest all of this and write about it so that I can understand it even better
13:43:57 <tomsmeding> thanks from me too :p
13:47:13 <AWizzArd> Anyone here who knows the IHS web framework?
13:47:51 <AWizzArd> IHP that is
13:53:34 <jle`> is that the pancake one
14:01:30 <AWizzArd> jle`: not that I know of
14:01:55 <AWizzArd> I just wonder how their html form knows which action/handler it has to submit its data to.
14:03:25 <tomsmeding> what does the html look like? :)
14:05:36 <AWizzArd> tomsmeding: 1) <form method="POST" action="/CreatePost" id="" class="new-form">
14:05:39 <AWizzArd> tomsmeding: 2) <form method="POST" action="/UpdatePost?postId=9d95a780-2c8a-4f58-b8ea-db2465389ae9" id="/UpdatePost?postId=9d95a780-2c8a-4f58-b8ea-db2465389ae9" class="edit-form">
14:06:22 <tomsmeding> looks like plenty of identifying information in there
14:06:55 <AWizzArd> tomsmeding: The more interesting question is: what Haskell code produced this html? Here I‚Äôve moved it all into one line:
14:06:59 <AWizzArd> renderForm post = formFor post [hsx|{(textField #title)} {(textField #body)} {submitButton} |]
14:07:10 <tomsmeding> oooh template haskell
14:07:16 <AWizzArd> The interesting bit is that in both cases the form got generated by that same line!
14:07:30 <AWizzArd> There is no information about the action=  part
14:07:54 <AWizzArd> How can it know that in one case it needs to send the data to /CreatePost  and in the other case to  /UpdatePost   ?
14:08:36 <tomsmeding> and that information is not in 'post' somehow?
14:13:59 <AWizzArd> tomsmeding: nope
14:14:43 <AWizzArd> tomsmeding: maybe, to be honest, I am not sure
14:17:17 <tomsmeding> just guessing, but it might be the ControllerContext being passed around in a implicit parameter?
14:18:31 <tomsmeding> going off the definition of formFor here ( https://github.com/digitallyinduced/ihp/blob/master/IHP/View/Form.hs#L75 )
14:18:39 <tomsmeding> it's defined here: https://github.com/digitallyinduced/ihp/blob/master/IHP/Controller/Context.hs#L13
14:18:58 * tomsmeding eww implicit parameters
14:19:52 <solonarv> I started using those for my advent of code thing this year :>
14:20:15 <AWizzArd> solonarv: them? Is that a) IHP or b) implicit parms?
14:20:23 <tomsmeding> like, I use HasCallStack too, but ew :p
14:20:33 <tomsmeding> I would be surprised if someone uses IHP for AoC
14:20:44 <tomsmeding> though people use Excel so perhaps I shouldn't be
14:21:28 <Clint> o_O
14:22:31 <tomsmeding> you haven't seen the Excel posts on the reddit?
14:22:35 <solonarv> AWizzArd: "them" = implicit params
14:23:19 <AWizzArd> tomsmeding: what is AoC?
14:23:24 <AWizzArd> https://github.com/digitallyinduced/ihp/blob/master/IHP/View/Form.hs#L75
14:23:35 <tomsmeding> https://adventofcode.com/
14:24:59 <solonarv> my framework gives the solution access to a (?dyns :: Map String Dynamic), which is used by tests to override paramteres that are different from the real input
14:25:28 <AWizzArd> What is that questionmark?
14:25:41 <solonarv> for example, 2020 day 9 (yesterday)'s problem involves a sliding window; in the real input, it's a 25-wide window, but in the example inputs, it's only 5-wide
14:25:52 <solonarv> the question mark is how implicit parameters are written
14:26:16 <AWizzArd> solonarv: Is that a unary operator or Haskell syntax?
14:26:31 <tomsmeding> special magical syntax
14:26:37 <tomsmeding> https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#implicit-parameters
14:27:27 <tomsmeding> mind you, I don't know if that thing is the answer to your question, but it seemed a likely candidate given that the question was "where is this information coming from that I'm not passing in"
14:32:20 <AWizzArd> tomsmeding: it probably will be something like that, indeed.
14:35:55 <ep1ctetus> Hi all, I'm experimenting to teach myself about Monad Transformers. I've successfully built a monad with ReaderT and LoggerT. I've never used Logger, and I've been looking through the docs for like 10 minutes, I can't figure out how to actually log a message. Can anyone help? It would be so nice to see an example of how it's used.
14:36:25 <glguy> What's a LoggerT?
14:37:01 <ep1ctetus> My mistake, LoggingT
14:37:16 <glguy> OK. What's a LoggingT :)
14:37:31 <ep1ctetus> https://hackage.haskell.org/package/monad-logger-0.3.36/docs/Control-Monad-Logger.html#t:LoggingT
14:38:23 <glguy> ep1ctetus: Libraries written in this style hide all the interesting operations in typeclass instances. In this case the MonadLogger class
14:38:28 <glguy> monadLoggerLog :: ToLogStr msg => Loc -> LogSource -> LogLevel -> msg -> m ()
14:38:38 <glguy> https://hackage.haskell.org/package/monad-logger-0.3.36/docs/Control-Monad-Logger.html#t:MonadLogger
14:40:17 <ep1ctetus> ok I see, thank you! let me try this out
14:43:18 <dminuoso> Hackage/haddock had a keybinding to open up the content window as a sort of overlay, what was the key?
14:44:17 <dminuoso> Or am I possibly just confusing this with <s> ?
14:44:28 <tomsmeding> well, s, yes, but what content window?
14:44:51 <dminuoso> https://hackage.haskell.org/package/optics-core-0.3.0.1/docs/Optics-AffineTraversal.html
14:44:55 <dminuoso> On the right side, the content box
14:45:05 <dminuoso> I swear there was a key binding that would bring this up like the <s> box
14:45:14 <tomsmeding> that Synopsis thing
14:45:15 <tomsmeding> ?
14:46:07 <dminuoso> No, the one that says content
14:47:32 <tomsmeding> oh, the contents box on the old haddocks pages?
14:47:43 <tomsmeding> on the new ones it's a sidebar on the left
14:47:56 <dminuoso> Yeah
14:48:04 <dminuoso> It seems as if the JavaScript comes from hackage, not haddocks
14:49:32 <tomsmeding> if I have to believe firefox devtools there's one event handler that runs when I press a key, and it seems to be the one for the 's' search box
14:49:48 <ep1ctetus> @glguy that was the direction I needed, thanks very much!
14:49:49 <lambdabot> Unknown command, try @list
14:50:41 <dminuoso> tomsmeding: Ah alright, cheers. Maybe I just misremember
14:51:41 <tomsmeding> yeah that listener just watches for 's' outside the box, and the various keybindings inside the box
14:51:46 <tomsmeding> ¬Ø\_(„ÉÑ)_/¬Ø
15:14:26 <dsal> TIL you can pass the same Map type between strict and lazy maps.
15:15:21 <dolio> They're the same type, just different functions, yeah.
15:15:30 <dolio> The Functor instance is lazy, too.
15:22:43 <dsal> Yeah, that's the magic.  So I was abler to fmap a strict map into a knot-tying lazy self-referencing map.
15:29:38 <dolio> It's probably better not to think of the map as strict. The functions are.
15:31:05 <dsal> Yeah.  I always thought they were two independent things.  Makes sense but now I can do things easily I couldn't do before.
16:16:50 <Squarism> Thought I was down with function composition. But apparently not
16:16:58 <Squarism> :t _1
16:17:00 <lambdabot> (Field1 s t a b, Functor f) => (a -> f b) -> s -> f t
16:17:16 <Squarism> :t (.)
16:17:19 <lambdabot> (b -> c) -> (a -> b) -> a -> c
16:17:30 <Squarism> :t _1 . _2
16:17:32 <lambdabot> (Field1 s t a1 b1, Functor f, Field2 a1 b1 a2 b2) => (a2 -> f b2) -> s -> f t
16:18:13 <Squarism> I cannot really see how that result is achieved
16:19:45 <Squarism> g . f assumes g takes a result f produces, but however I move the parantheses I cannot make _2 deliver something _1 consumes?
16:20:22 <dminuoso> Squarism: As a rough intuition, think of traverse.
16:20:47 <dminuoso> traverse f -- will traverse over a given list, right?
16:21:09 <Squarism> yes
16:22:16 <dminuoso> Squarism: And equivalently, how would you traverse over the Int in a `Tree [Int]`?
16:23:03 <dminuoso> Or rather, without going that far
16:23:05 <dminuoso> look at
16:23:07 <dminuoso> % :t traverse
16:23:07 <yahb> dminuoso: (Traversable t, Applicative f) => (a -> f b) -> t a -> f (t b)
16:23:28 <Squarism> ive not used traverse a ton (directly). Im just thinking in type terms here, looking at the signature
16:24:35 <dminuoso> Squarism: Ah well, lets continue anyway. So?
16:24:42 <Squarism> Sure
16:25:42 <dminuoso> Just to avoid confusion, Im awaiting your response here. :)
16:26:05 <dminuoso> Oh, maybe that was your response.
16:26:20 <dminuoso> So you'd just go `traverse (traverse f)`
16:26:27 <dminuoso> Similar to how you'd go `fmap (fmap f)` right?
16:26:36 <Squarism> yeah i mean, im glad for any help understanding. So im down with your approach
16:27:02 <dminuoso> Or say, you have a Tree [Int], and you want to fmap over the Int with (+1), how would you do that?
16:27:29 <dminuoso> (for extra points, use map for the list mapping, and fmap for the tree)
16:29:47 <Squarism> fmap (fmap (+1)) tree  ?
16:29:56 <dminuoso> looks good
16:30:05 <dminuoso> Now replace the correct fmap with `map` for the one that acts on the list
16:30:59 <Squarism> fmap (map (+1)) tree  ?
16:31:14 <dminuoso> Good. Can you refactor that into using function composition?
16:33:23 <Squarism> not sure how
16:33:49 <dminuoso> Oh well, Im just looking for:
16:33:57 <dminuoso> (fmap . map) (+1) tree
16:34:01 <dminuoso> Make sense so far?
16:34:41 <Squarism> oh ok. Sure
16:34:45 <dminuoso> If I renamed those mapping functions further, we might get
16:34:47 <dminuoso> (treeMap . listMap) (+1) tree
16:34:58 <dminuoso> Let's toss everything to the right away, and focus on just this part:
16:35:01 <dminuoso> (treeMap . listMap)
16:35:33 <dminuoso> Alright, so far so good?
16:35:43 <Squarism> yep
16:35:53 <dminuoso> Great.
16:36:01 <dminuoso> So, traverse works exactly the same
16:36:03 <dminuoso> We could have 
16:36:15 <dminuoso> (treeTraverse . listTraverse) f tree
16:36:44 <dminuoso> And then for some choice of `f`, we would map each element to an action, and sequence the actions and write the results back in
16:36:51 <dminuoso> For instance:
16:37:33 <dminuoso> % (traverse . traverse) Just [[1,2], [2,3]]
16:37:33 <yahb> dminuoso: Just [[1,2],[2,3]]
16:37:39 <dminuoso> Squarism: So far so good?
16:38:10 <dminuoso> Do you see the theme here? You first specify the thing acting on the "outer layer" first, and on the "inner layer" second in the composition.
16:38:35 <Squarism> yeah
16:39:25 <dminuoso> Here comes the cool trick. `traverse . traverse` is the relevant part here. Lens picks what goes in afterwards, and then comes your data structure
16:39:39 <dminuoso> So `traverse . traverse` is not just a similar example, it's actually a valid lensy thing, namely a Traversal
16:39:51 <dminuoso> % [[1,2,3], [2,3,4]] ^.. (traverse.traverse)
16:39:51 <yahb> dminuoso: [1,2,3,2,3,4]
16:39:59 <Squarism> i know about those view/over 
16:40:28 <dminuoso> Squarism: What view/over etc does, is it takes this `traverse.traverse`-like construction and then runs it with some functor
16:40:46 <dminuoso> except, you have:
16:41:11 <dminuoso> type Lens s t a b = forall f . Functor f => (a -> f b) -> s -> f t
16:41:14 <dminuoso> % :t traverse
16:41:14 <yahb> dminuoso: (Traversable t, Applicative f) => (a -> f b) -> t a -> f (t b)
16:41:41 <dminuoso> Squarism: Ignore the Traversable constraint here. The important difference is that the constraints.
16:41:51 <Squarism> ah ok. Im just surprise (.) did something more than I expected to. Like it could see a pattern or simplified the expression?! 
16:42:09 <dminuoso> What do you think did it simplify?
16:42:24 <dminuoso> (Field1 s t a b, Functor f) => (a -> f b) -> s -> f t
16:42:36 <dminuoso> Is a function from `(a -> f b)` to `s -> f t`
16:43:26 <dminuoso> If we set s ~ t and a ~ b for simplicity, we have:
16:43:37 <Squarism> ah ok
16:43:40 <dminuoso> (Field1 s s a a, Functor f) => (a -> f a) -> s -> f s
16:43:51 <dminuoso> Do you see how you can compose with, say, itself?
16:44:39 <dminuoso> It's for the same reason
16:44:40 <dminuoso> % :t map
16:44:40 <yahb> dminuoso: (a -> b) -> [a] -> [b]
16:44:45 <dminuoso> composes with itself
16:44:48 <dminuoso> % :t map . map
16:44:48 <yahb> dminuoso: (a -> b) -> [[a]] -> [[b]]
16:45:07 <Squarism> it become M a -> M b and M b  -> M c 
16:45:12 <Squarism> So to speak
16:46:07 <Squarism> i mean how you structured the functions
16:46:28 <dminuoso> I dont understand
16:46:40 <Squarism> type M x = k -> j x
16:47:38 <Squarism> or no.. =/
16:49:34 <Squarism> ill save this conversation and look through it when im less tired. Im sure it will come to me then
16:49:41 <Squarism> dminuoso, thanks for helping
16:50:19 <Squarism> but yes, i see how it composes with itself
16:56:06 <Squarism> atleast if you think of it in terms of (a -> f a) -> (s -> f s)
17:20:39 <Axman6> :t \x -> (uncurry x `asAppliedTo` (traverse, traverse)) (.)
17:20:41 <lambdabot> error:
17:20:41 <lambdabot>     ‚Ä¢ Couldn't match expected type ‚Äò((a -> f b) -> t a -> f (t b),
17:20:41 <lambdabot>                                      (a1 -> f1 b1) -> t1 a1 -> f1 (t1 b1))‚Äô
17:21:35 <Axman6> :t (\x -> (uncurry x `asAppliedTo` (traverse, traverse))) `asAppliedTo` (.)
17:21:37 <lambdabot> (Applicative f, Traversable t1, Traversable t2) => (((t2 a -> f (t2 b)) -> t1 (t2 a) -> f (t1 (t2 b))) -> ((a -> f b) -> t2 a -> f (t2 b)) -> (a -> f b) -> t1 (t2 a) -> f (t1 (t2 b))) -> ((t2 a -> f
17:21:37 <lambdabot> (t2 b)) -> t1 (t2 a) -> f (t1 (t2 b)), (a -> f b) -> t2 a -> f (t2 b)) -> (a -> f b) -> t1 (t2 a) -> f (t1 (t2 b))
17:22:06 <Axman6> hmm, yep, that'd definitely what I wanted...
17:22:26 <Axman6> :t (\x -> (x traverse traverse)) `asAppliedTo` (.)
17:22:28 <lambdabot> (Applicative f, Traversable t1, Traversable t2) => (((t2 a -> f (t2 b)) -> t1 (t2 a) -> f (t1 (t2 b))) -> ((a -> f b) -> t2 a -> f (t2 b)) -> (a -> f b) -> t1 (t2 a) -> f (t1 (t2 b))) -> (a -> f b) -
17:22:28 <lambdabot> > t1 (t2 a) -> f (t1 (t2 b))
17:29:40 <ep1ctetus> Is there a way to do something like `map` on a list, but remember and use some state in between each value it runs on?
17:30:03 <Clint> yes
17:30:11 <ep1ctetus> please enlighten me!
17:30:26 <Axman6> :t scanr
17:30:28 <Axman6> :t scanl
17:30:28 <lambdabot> (a -> b -> b) -> b -> [a] -> [b]
17:30:31 <lambdabot> (b -> a -> b) -> b -> [a] -> [b]
17:30:40 <Axman6> hmm, not the one I was after
17:31:42 <Clint> :t mapAccumL
17:31:44 <lambdabot> Traversable t => (a -> b -> (a, c)) -> a -> t b -> (a, t c)
17:31:45 <Clint> :t mapAccumR
17:31:46 <lambdabot> Traversable t => (a -> b -> (a, c)) -> a -> t b -> (a, t c)
17:32:05 <Axman6> % :t mapAccumL @[]
17:32:05 <yahb> Axman6: (a -> b -> (a, c)) -> a -> [b] -> (a, [c])
17:34:37 <ep1ctetus> ah very cool! thanks so much
17:34:38 <Squarism> Axman6, thanks. I guess the above was for me. Ill decipher it later
17:36:12 <Axman6> I'm not sure it made things any clearer - I was hoping for: ((a -> f b) -> s -> f t) -> ((s -> f t) -> p -> f q) -> (a -> f b) -> (p -> f q)
17:37:51 <dminuoso> mmm, mapAccumR is just traverse with State, isnt it?
17:50:27 <ep1ctetus> Clint dminuoso haha! It works perfectly! Thanks very again
17:50:45 <ep1ctetus> Haskell is so satisfying to me once it works
18:12:32 <koz_> > mapAccumL (\acc x -> (acc + 1, acc + x)) 0 [1, 2, 3, 4, 5]
18:12:34 <lambdabot>  (5,[1,3,5,7,9])
18:12:46 <koz_> > mapAccumR (\acc x -> (acc + 1, acc + x)) 0 [1, 2, 3, 4, 5]
18:12:48 <lambdabot>  (5,[5,5,5,5,5])
18:13:08 <koz_> Wait wat.
18:15:44 <Squarism> Axman that in itself is pretty clear. Im thinking its made possible because of functional dependencies FieldN? 
18:17:10 <Squarism> ..or if thats irrelevant?
18:44:55 <jle`> :t mapAccumR
18:44:57 <lambdabot> Traversable t => (a -> b -> (a, c)) -> a -> t b -> (a, t c)
18:45:34 <jle`> :t \f x xs -> runState (traverse (state . flip f) xs) x
18:45:36 <lambdabot> Traversable t => (s -> b1 -> (b2, s)) -> s -> t b1 -> (t b2, s)
18:45:57 <jle`> little but shuffled around, but yeah
18:46:45 <jle`> :t [mapAccumR, \f x xs -> runState (traverse (state . flip f) xs) x]
18:46:47 <lambdabot> error:
18:46:47 <lambdabot>     ‚Ä¢ Occurs check: cannot construct the infinite type: s ~ t s
18:46:47 <lambdabot>       Expected type: (s, t s)
18:46:52 <jle`> oh yeah, darn
18:53:39 <MarcelineVQ> koz_: come back, so jle` can explain how StateL and StateR differen in which side of <*> you pass your initial (and thus subsequent) state to
20:44:57 <essem> DDDDD=
21:28:42 <ezzieyguywuf> is it safe to skip ~/.cabal/store in my backup snapshots?
21:29:02 <ezzieyguywuf> i.e. will I still be able to use cabal, or am I better off just skipping ~/.cabal entirely?
21:40:42 <monochrom> .cabal/store can be skipped. This just means rebuilding libraries later.
21:41:16 <monochrom> .cabal/packages can also be skipped. This just means re-downloading Hackage packages later.
21:41:37 <monochrom> If you have customized .cabal/config, you will want to save it.
21:42:05 <ezzieyguywuf> monochrom: thanks for the input!
21:42:34 <monochrom> Also, .cabal/packages has the stuff you got from "cabal update". So just run it again.
21:42:50 <ezzieyguywuf> gotcha
21:44:04 <ddellacosta> "randomly glanced at latest comments in #haskell immediately after signing in and learned something" count now at 53
22:08:54 <jpcooper> Hello. Have there been any attempts at making an equivalent of the C++ STL for the ST monad?
22:12:43 <hyiltiz> jpcooper: not quite sure what u mean by "an equivalent of C++ STL"
22:13:18 <hyiltiz> seems to be Prelude and elsewhere provides lots of those, and you can lift those into ST or any monad of your choice
22:13:26 <jpcooper> I'm thinking mostly of implementations of the containers like unordered_map, unorderdd_set, map, the <algorithm> library
22:14:36 <hyiltiz> haskell has a lot of containers, and you can lift them into any monad, hence the benefit of abstracting away the monad interface so containers don't have to deal with IO or ST or whatnot
22:14:46 <jpcooper> Although for a lot of functionality, you would probably need pointers, which might be unsafe
22:15:39 <jpcooper> hyiltiz: My point is to have efficient implementations. For instance, replace a node in a linked list is O(N), as far as I understand with a normal non-mutable implementation
22:16:28 <hyiltiz> well now we are talking about efficient implementation of (functional) data structures, some of which is theoretically impossible without mutability
22:16:41 <jpcooper> Yes. This is why I'm interested in the ST monad
22:16:44 <hyiltiz> maybe you'd be interested to learn about fingertrees
22:17:31 <hyiltiz> functional data structures have quite different "mindset"; without giving away mutability, you simply cannot do a few things
22:17:40 <perry69420> jpcooper This might be helpful https://hackage.haskell.org/package/hashtables
22:18:43 <hyiltiz> Ahah now I understand why specify the ST constrain
22:19:10 <hyiltiz> You'd rather be stateful to be efficient
22:19:11 <jpcooper> Finger trees would be interesting. I'm quite well acquainted with Haskell, by the way. I'm simply interested in getting various things done in Haskell without worrying too much about trying to bend the functional paradigm, and I'm also interested in performance. With the ST monad, who cares if it is mutating state under the bonnet. The interface itself is referentially transparent
22:19:15 <jpcooper> Yes
22:19:38 <jpcooper> Thanks, perry69420 
22:30:43 <hololeap> i've been looking at edwardk's work on propagators and i don't really understand what a join-semilattice would look like in haskell
22:30:52 <hololeap> can anyone give me a simple example?
22:36:24 <perry69420> hololeap Would you like a mathematical example?
22:36:38 <hololeap> i know of the one involving natural numbers off wikipedia
22:36:53 <hololeap> perry69420: but sure
22:39:23 <perry69420> Consider any set of objects, call it S. Consider the power set of S without the empty subset. Then this power set is a join semilattice wrt inclusion
22:39:40 <perry69420> Notice that it is NOT a meet semilattice
22:40:51 <perry69420> So for example, if S = {1,2,3}, then the power set I'm considering is {{1},{2},{3},{1,2},{2,3},{1,3},{1,2,3}}. Notice that the empty set {} is not in this set
22:41:44 <hololeap> so then {1,2,3} would be the maximum meet
22:41:46 <perry69420> The "join" operation is given by union of sets
22:41:49 <perry69420> yes exactly
22:42:09 <hololeap> ok, sorry i'm getting a lot of this off wikipedia
22:42:10 <perry69420> hololeap maximum join, not meet
22:42:48 <hololeap> right...
22:43:26 <hololeap> i was reading the part about meet-semilattice accidentally
22:43:40 <perry69420> so meet is defined as greatest lower bound, and join is the lowest upper bound.
22:44:01 <perry69420> Note that we already have a partial order on the "power" set i defined via inclusion.
22:45:49 <hololeap> so, what would be an example of a join-semilattice that isn't also a power set?
22:47:43 <perry69420> hololeap That example I gave isn't a power set
22:47:51 <perry69420> It is a subset of a powerset
22:47:55 <hololeap> right, sans the empty set
22:48:46 <iqubic> Data.Array array? I.E. return Maybe e to indicate an out of bounds error?
22:50:17 <hololeap> i assume that any power set sans its "maximum" set is a meet-semilattice?
22:50:41 <perry69420> yes. Obviously, the empty set is the GLB here
22:51:00 <perry69420> but again, the partial order on the set has to be defined via inclusion
22:53:54 <jchia> My program has 1~2GB of resident memory even when it's doing no work. Can a heap profile help me identify where all that memory is going? E.g. maybe it can tell me allocation amount minus deallocation amount so the outstanding amount is from memory leaks?
22:56:17 <hololeap> perry69420: i think i thought of a trivial example, a power set, sans empty, where there are two diffenet "maxima", and a ^ b yields a different result than a ^ c and b ^ c
22:57:20 <perry69420> How can there be two different maximas in a power set? Can you expand the example a bit?
22:57:30 <perry69420> is your partial order still inclusion?
22:57:56 <hololeap> oh, you're right because the two different "maximal" results wouldn't have a join
22:59:06 <hololeap> but, if they _did_ have a join, that would be a different shape than the power set for three elements
22:59:37 <hololeap> so there's the answer to my question
23:00:03 <perry69420> I'm not quite sure what you mean by shape here. But if they did have a join, both of them cannot be maximal
23:00:28 <hololeap> i'm thinking of it as a directed graph
23:00:55 <hololeap> so i can pull away from the example we had earlier and get more abstract
23:01:09 <perry69420> x \le y iff directed edge x to y?
23:02:12 <perry69420> iff x meet y = x
23:02:50 <hololeap> that would require inclusion of identity arrows?
23:03:27 <perry69420> right.. every node will have a edge to itself
23:04:26 <hololeap> i understand what a dag looks like. is a join-semilattice any different?
23:05:19 <hololeap> oh, yes it is
23:05:23 <perry69420> yes! A DAG is always a meet-semilattice
23:05:31 <perry69420> it needn't be join-semilattice
23:05:42 <perry69420> Consider any tree as an example
23:05:48 <hololeap> i see
23:06:31 <perry69420> You can take the dual of the graph to make a join semilattice
23:06:50 <perry69420> dual of a DAG is DAG with all edges reversed
23:07:09 <hololeap> that's very interesting
23:07:54 <hololeap> i'm looking at the image here: https://en.wikipedia.org/wiki/Directed_acyclic_graph
23:08:17 <hololeap> and i can see how that if you reverse the arrows you get a join-semilattice
23:08:52 <hololeap> and it's a good example of what i was asking for earlier
23:09:50 <perry69420> I have absolutely no idea about uses/implementations of Join/Meet Semilattice in Haskell yet :P
23:10:38 <hololeap> but wait... the semilattice has a structure that's based off a binary function...
23:11:04 <perry69420> that is correct
23:11:22 <hololeap> so how can a dag be a meet-semilattice?
23:12:05 <perry69420> I define x meet y as the "maximal" node from which you can reach both x and y
23:13:04 <hololeap> ok, yeah that makes sense
23:13:09 <perry69420> Ahh I see a little problem. Every DAG isn't a meet semilattice
23:14:17 <perry69420> Consider 4 nodes. a,b,c,d. The available edges are (a,b),(a,c),(d,b),(d,c). Then there is no GLB here
23:14:58 <perry69420> We will need to restrict ourselves to tree rather than DAGs
23:16:35 <hololeap>  what does tree mean here?
23:17:13 <perry69420> A directed tree*. So we have a root node and exactly one path from root node to every other node
23:17:49 <hololeap> ok
23:18:38 <hololeap> thanks. that definitely gives me some room for thought on the propogators idea
23:19:52 <hololeap> perry69420: can there be more than one root node?
23:20:17 <perry69420> hololeap I think it'll be better to think of a Partial Order with GLB. Note that while every tree is meet lattice, I'm not sure if every meet lattice is a tree
23:20:44 <perry69420> hololeap We cannot have a GLB then, can we?
23:21:21 <hololeap> i was thinking of it in reverse, as a join-SL
23:21:44 <perry69420> You'll need to take the dual of the directed tree then
23:21:54 <hololeap> right, sorry :)
23:22:01 <perry69420> In which case, it is no more a tree, but it does represent a join SL
