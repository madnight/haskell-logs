00:01:30 <infosec_yo> haskell is bloated.
00:06:41 <jle`> nice
00:07:19 <infosec_yo> its also insecure.
00:10:33 <jle`> not nice D:
00:11:48 <infosec_yo> ?
00:13:13 <int-e> infosec_yo: your mom is just bloated and insecure
00:14:28 <infosec_yo> what?
00:14:40 <MarcelineVQ> I'm bloated and insecure
00:14:53 <infosec_yo> how come ?
00:14:55 <tomsmeding> people are, in general
00:15:06 <MarcelineVQ> All the haskell I ate earlier I think
00:15:37 <infosec_yo> 💩
00:15:54 <int-e> infosec_yo: do you have any specific insecurity in mind?
00:16:00 <infosec_yo> yea
00:16:06 <int-e> infosec_yo: or are you just throwing around negative adjectives?
00:16:18 <infosec_yo> no
00:16:28 <int-e> so what is it?
00:16:30 <perry69420> int-e yea, did she ever love me?
00:16:35 <infosec_yo> general insecurities
00:16:39 <infosec_yo> e.g. sandbox etc
00:16:59 <int-e> so... that's not specific
00:17:09 <infosec_yo> like ESCAPE
00:17:36 <MarcelineVQ> with the wig, you remind me, of julia...
00:17:40 <boxscape> > ESCAPE
00:17:42 <lambdabot>  error: Data constructor not in scope: ESCAPE
00:17:48 <int-e> There isn't much of a sandbox in Haskell.
00:18:24 <perry69420> oh how we used to play in the sandbox
00:18:35 <int-e> There's SafeHaskell which tries to contain effects in IO and is probably flawed, though demonstrating that isn't exactly easy.
00:19:20 <infosec_yo> well that can easily be bypassed.
00:19:47 <int-e> Show us how.
00:20:01 <infosec_yo> all the exploits i have for haskell are private.
00:20:08 <int-e> Then stfu
00:20:17 <infosec_yo> why
00:20:24 <MarcelineVQ> the ladies love my day-zero haskell exploits
00:20:45 <int-e> infosec_yo: because there's obviously nothing to talk about
00:21:07 <infosec_yo> i got TONS of haskell.
00:21:12 <infosec_yo> ready to be deployed.
00:21:28 <MarcelineVQ> int-e: we could talk about puyo puyo 2
00:23:13 <infosec_yo> i think that haskell can be redone better.
00:24:54 <perry69420> MarcelineVQ is that .... Candy Crush Tetris?
00:25:43 <jle`> pretty much every haskeller can think of some improvements to haskell they'd like to see, though
00:25:45 <MarcelineVQ> it's so much more
00:25:55 <infosec_yo> whos a haskeller in here ?
00:27:12 <boxscape> Any haskellers in #haskell?
00:27:29 <infosec_yo> ?
00:28:31 <tomsmeding> no
00:28:43 <dminuoso> As for security, I've been wondering about TH for a while. Considering how easy it is to upload a malicious package on hackage, or even straight up replace it without changing versions...
00:28:53 <dminuoso> TH has full unbounded access to IO, doesn't it?
00:29:00 <infosec_yo> yea hackage with the package.
00:29:23 <tomsmeding> well safehaskell will certainly forbid TH
00:29:42 <boxscape> oh I didn't know you could do that, I thought you could only change metadata without updating versions
00:29:49 <infosec_yo> i can easily bypass safehaskel..
00:30:07 <boxscape> do it
00:30:09 <dminuoso> tomsmeding: Sure, but maybe I do want some TH..
00:30:17 <tomsmeding> boxscape: keeping the same version isn't really a requirement for this being an issue I think
00:30:24 <dminuoso> Say, I trust well typed's optics TH code, but nothing else
00:30:26 <tomsmeding> who will notice if you do a patch upgrade
00:30:27 <boxscape> yeah that's fair
00:30:58 <dminuoso> tomsmeding: keeping the same version means people who maintain strict bounds dont even have the chance to audit the bump.
00:30:59 <int-e> dminuoso: I didn't think you can replace a package without bumping the version on Hackage? (You can modify dependency versions though which is bound to have security implications.)
00:31:17 <dminuoso> int-e: Mmm. Im convinced you could.. perhaps Im wrong?
00:31:37 <int-e> dminuoso: Of course uploading a new minor version will probably go unnoticed anyway.
00:31:43 <dminuoso> Right
00:31:54 <infosec_yo> why minor?
00:32:26 <int-e> Because uploading a major version will be caught by diligent use of the package versioning policy.
00:32:32 <boxscape> Isn't there a security issue here even without TH though? The difference being you'd have problems when running the code rather than when compiling it
00:33:07 <nfd> may've been a bit too cheeky in my solution to 11-2
00:33:10 <dminuoso> boxscape: When you compromise the compiler, you can hijack it to ruin your life completely
00:33:15 <infosec_yo> i still feel that haskell is a bit cheeky.
00:33:24 <nfd> wish i could solve my halting problem real fast here
00:33:32 <dminuoso> boxscape: Say I get to hijack your build server, then I can infest *all* resulting build artifacts.
00:33:33 <int-e> infosec_yo: There's little doubt that there's a lot of insecurities to find in Haskell and in particular its ecosystem. But if you're not willing  to discuss *what* specifically is insecure, you're not contributing anything, you're just bragging.
00:33:37 <dminuoso> As opposed to just your machine
00:33:40 <boxscape> dminuoso hm I see
00:33:45 <int-e> infosec_yo: Which is worthless to the rest of us.
00:35:00 <int-e> @bot
00:35:00 <lambdabot> :)
00:35:08 <dminuoso> Mmm, perhaps SafeHaskell is the right answer after all
00:35:39 <tomsmeding> couldn't you manually trust certain modules with safehaskell? I believe you could
00:35:46 <dminuoso> Right, modules or packages
00:35:48 <int-e> tomsmeding: you can trust packages
00:35:50 <dminuoso> You could do a safe import
00:35:54 <int-e> (not modules, I think)
00:36:05 <dminuoso> https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/safe_haskell.html
00:36:10 <dminuoso> int-e: You can do a safe import on a module.
00:36:28 <int-e> You mark a module Trustworthy, and then if you trust the package containing that module you can import it "safely".
00:36:40 <int-e> But this isn't a bypass, this is by design.
00:38:39 <int-e> Any Trustworthy module in a trusted package is part of your trusted codebase. Which means that the TCB is usually pretty big.
00:39:05 <int-e> (And then there's the compiler, as usual.)
00:39:42 <dminuoso> The compiler we kind of have to take for granted..
00:40:02 <dminuoso> Unless you're well-typed or facebook, it's not like you have any reasonable insight into the compiler..
00:40:38 <int-e> . o O ( MSR knows a thing or two? )
00:40:45 <dminuoso> Who is MSR?
00:41:00 <int-e> Microsoft Research
00:41:38 <dminuoso> Ah yeah, it was not a comprehensive list.
00:41:54 <int-e> Well, logically it was. :P
00:43:15 <dminuoso> The main problem with hackage is just that through transitive dependencies, it gets very hard to track changes. I'd _love_ it if cabal had an `update bounds` feature, that sends me through a pager, displaying the diff of the source code behind the versions.
00:43:31 <dminuoso> Hunk wise, like say `git add -p`, where I can simply audit the changes
00:43:46 <dminuoso> That I would definitely use
01:38:04 <maerwald> dminuoso: it would be so massive that I doubt it's useful
01:39:05 <dminuoso> maerwald: If your software is mission critical, would you not want to know how your dependencies changed every time you update? :0
01:39:19 <maerwald> not sure who would pay me for that...
01:39:36 <maerwald> also, reviewing GHC would be much more important than your deps...
01:40:04 <dminuoso> It's much easier to sneak malicious changes into hackage than into GHC.
01:40:13 <maerwald> I guess
01:41:28 <dminuoso> Dunno about you, but I generally look through a libraries implementatoin before I use it. I sadly don't do it transitively, but at least I do that much
01:43:01 <dminuoso> Eh by transitively I mean I dont check its dependencies transitively.
01:43:52 <dminuoso> Though at the very least I verify dependency trees regularly to prevent my packages from blowing up
03:33:01 <kuribas> is Control.Category used somewhere else in Base?
03:33:19 <kuribas> while it's nice to have the operators (>>>), it doesn't seem to have much use...
03:33:31 <Taneb> kuribas: it's used by Control.Arrow
03:33:46 <Taneb> Which has a bunch of subclasses of Category of varying utility
03:34:45 <kuribas> I've never really got into Arrows
03:34:59 <xerox_> nobody did
03:35:12 <Taneb> Only whoever wrote that one xml library did
03:36:13 <kuribas> hxt?
03:36:25 <Taneb> That's the one
03:36:55 <Taneb> (I think it turned out that Applicatives are about as powerful as Arrows and a lot easier to understand)
03:41:52 <kuribas> yeah, I find applicative/monadic processing of xml much easier
04:13:17 <scasc> Do you know of a good summary / lookup of the module namespaces used across Hackage?
04:14:00 <scasc> ... / analysis
04:16:17 <merijn> scasc: Depends what you wanna use it for?
04:20:49 <scasc> Sorry, I got disconnected. Did anyone give a pointer re used namespaces while I was gone?
04:22:25 <Taneb> scasc: merijn asked what you want to use it for
04:23:37 <scasc> Just a general overview. I was toying with a little package, and was trying to figure out where to put its modules.
04:25:07 <scasc> It provides functionality which can be useful in CLI and TUI "semigraphical" representation.
04:25:42 <merijn> There's no real organisation, tbh
04:26:29 <scasc> I know, that's why I wanted to look for inspiration / examples, should a collection / analysis exist.
04:26:49 <merijn> What's the name of the package?
04:27:13 <scasc> I mean, "brick" is a very popular TUI, and these could be arguably used in some custom Brick widgets, but I won't put it under "Brick." as it is more general.
04:27:20 <merijn> If the name isn't super generic, I'd just use the name as root for you module hierarchy
04:28:29 <scasc> "What's the name of the package" -- none yet. Well, none settled yet. I have an absolutely unrepresentative WIP-name. Naming is the hardest thing in CS :o)
04:30:13 <scasc> Even though it's String/Text related, "Data.Text." seems to be an overkill, as it's not really about "data".
04:30:26 <merijn> Data and Control are historical mistakes, imo
04:30:58 <scasc> Some packages use just "Text."
04:31:16 <merijn> When hierarchical modules were introduced a bunch of stuff got put under Data or Control, but none of these have a clear argument for why they're under Data or under Control and they just add useless noise
04:31:17 <scasc> Then I saw "Console."
04:32:45 <scasc> Maybe I'll go for "Text." (without Data). It's for console / TUI usage, so that seems fair.
04:32:51 <scasc> And There's https://hackage.haskell.org/package/ascii-art-to-unicode-0.1.0.1/docs/Text-AsciiArt.html as a precedent.
04:33:35 <merijn> Keep in mind modules are expected to be unique, so don't pick any overly general names
04:36:02 <scasc> "Keep in mind modules are expected to be unique" -- I had to utilize `-XPackageImports` myself.
04:36:27 <scasc> To be fair, that should be part of a new standard anyway.
04:36:32 <scasc> IMO
04:37:03 <merijn> scasc: I would not assume a new standard will happen any time soon
04:37:32 <merijn> and "I had to utilise PackageImports too" is a poor reason to inflict it upon everybody else...
04:42:42 <scasc> I was not implying I was going to willfully create a conflict. I was just trying to express I was feeling your pain.
05:06:19 <phaazon> I have to say that, writing some Haskell for AoC is a pure joy 
05:06:23 <phaazon> I missed writing Haskell too much :D
05:06:37 <phaazon> today’s exercise was super simple in Haskell, just, pure $ Joy
05:06:38 <phaazon> :)
05:09:52 <boxscape> funny, today's exercise is the one that I wouldn't have minded writing in another language
05:12:02 <Kronic> A design question: If I have a type that I defined as having say, 5 or 6 strings -- is there a pattern I can use to apply a function to all of them? Seems like it would be a functor or something but I'm not sure
05:12:16 <dminuoso> Kronic: You could make it MonoFoldable
05:12:38 <dminuoso> It would require either boilerplating this, or you could use Generics for it
05:13:19 <dminuoso> Oh, MonoFunctor of course, not MonoFoldable. but the latter would also exist :)
05:14:09 <Kronic> Hm, I did find search results for MonoFoldable but not MonoFunctor, could you point me in the right direction?
05:14:28 <dminuoso> https://hackage.haskell.org/package/mono-traversable-1.0.15.1/docs/Data-MonoTraversable.html#t:MonoFunctor
05:14:54 <dminuoso> This is largely only useful when you write stuff that works over generic mono* things.
05:17:03 <dminuoso> Say you yourself are writing some `lowerCase :: MonoFunctor f => f Char -> f Char` that you intend to use on various textual containers. If its just a one-off, you're best off just writing some `fooMap :: (Text -> Text) -> T -> T` 
05:17:31 <dminuoso> Err, the example of lowerCase is wrong.
05:18:05 <solonarv> dminuoso: wouldn't that actually be   lowerCase :: (Element t ~ Char, MonoFunctor t) => t -> t
05:18:06 <Kronic> you're probably right but perhaps I should learn how to use this, it looks a little bit above me at the moment but it seems very useful
05:18:13 <dminuoso> solonarv: Was just about to write that, yeah
05:18:33 <dminuoso> Mmm, I have yet to find a use for mono-traversable.. dunno..
05:18:51 <dminuoso> Out of the package, MonoTraversable and MonoFoldable seem most useful, MonoFunctor not so much
05:19:20 <Kronic> My use case is I have a type that represents some user data and all of it is Maybe, so I want to filter out users who have any one field that is Nothing 
05:24:03 <solonarv> I would usually just go straight to lens, tbh
05:24:54 <solonarv> :t each %~ toLower
05:24:56 <lambdabot> Each s t Char Char => s -> t
05:25:45 <solonarv> > let tlc = each %~ toLower in (tlc "Hello World!", tld (Data.Text.pack "Good Bye!"))
05:25:48 <lambdabot>  error:
05:25:48 <lambdabot>      Not in scope: ‘Data.Text.pack’
05:25:48 <lambdabot>      No module named ‘Data.Text’ is imported.
05:25:57 <solonarv> @let import qualified Data.Text
05:25:58 <Kronic> I've never used lens before, if this is a good use case for learning Lens I'm open to doing that
05:26:00 <lambdabot>  Defined.
05:26:02 <solonarv> > let tlc = each %~ toLower in (tlc "Hello World!", tld (Data.Text.pack "Good Bye!"))
05:26:05 <lambdabot>  error:
05:26:05 <lambdabot>      • Variable not in scope: tld :: Data.Text.Text -> b
05:26:05 <lambdabot>      • Perhaps you meant ‘tlc’ (line 1)
05:26:13 <solonarv> > let tlc = each %~ toLower in (tlc "Hello World!", tlc (Data.Text.pack "Good Bye!"))
05:26:15 <lambdabot>  ("hello world!","good bye!")
05:26:23 <solonarv> there! sorry for the spam, dang typos
05:26:24 <dminuoso> lens is definitely not a bad idea
05:26:41 <solonarv> lens is a large library that can do many things, so there are many use cases
05:26:58 <dminuoso> but, Im not sure whether something will generate a traversal for uniform types for you
05:27:06 <solonarv> this same large size also makes it somewhat hard to learn, however
05:27:17 <solonarv> dminuoso: generic-lens can!
05:27:38 <dminuoso> solonarv: Can generi-lens generate a `Traversal' T Text` for `data T = T { f1 :: Text, f2 :: Text }` ?
05:29:02 <solonarv> dminuoso: yes: types @Text --; that does a "deep" traversal, whcih is fine in this case
05:29:25 <Kronic> That looks pretty powerful
05:31:05 <Kronic> which library would you guys recommend? I heard microlens is a good starting place but I'm honestly not sure. I could start out with the main lens lib but that looks a little bit intimidating lol  
05:31:23 <solonarv> surprsingly there doesn't seem to be a shallow-traversal variant of 'typed' in generic-lens
05:31:38 <solonarv> Kronic: I jumped straight into 'lens' and simply ignored most of the library, lol
05:32:59 <Kronic> I guess I'll give it a whirl
05:33:47 <dminuoso> Kronic: For beginners, I'd recommend `optics` over `lens`
05:33:56 <dminuoso> (There's also an equivalent `generic-optics` library)
05:36:20 <Kronic> Hm... well would I be able to accomplish the same thing that I wanted the lens lib for?
05:36:27 <dminuoso> Yes.
05:36:31 <solonarv> oh yes, that might be a good idea. 'optics' didn't exist yet when I learned this.
05:36:46 <dminuoso> `optics` is a newer version of `lens` that has, mostly, the same operators and functions
05:37:18 <dminuoso> To you, it differs mainly by hiding its implementation behind newtypes and using type machinery to generate custom error message if you mis-use it
05:37:30 <Kronic> Oh okay, sounds good. Thanks so much for your help. I'll see where I can get to with that
05:37:49 <solonarv> oh yes, 'lens' type errors are famously impenetrable
05:38:34 <phaazon> boxscape: what did you write it in?
05:38:43 <boxscape> haskell
05:38:56 <phaazon> I’ve AoC in Lua this year… I wanted to test Lua and… I’ve had enough, switching back to Haskell :D
05:39:04 <phaazon> I’ve been doing*
05:39:25 <solonarv> I also wrote it in Haskell; fortunately I already had a little "2D grid" library left from day 3
05:39:36 <solonarv> so it was fairly painless overall
05:39:39 <phaazon> :)
05:39:50 <phaazon> yeah, from scratch, it’s ~50 lines on my side
05:39:58 <phaazon> I could compress it a bit more I guess, but it’s well enough
05:40:20 <phaazon> I liked recognizing an anamorphism :)
05:40:44 <solonarv> mine is 82sloc apparently: https://github.com/Solonarv/adventofcode-2020/blob/main/haskell/solutions/Day11.hs
05:41:04 <solonarv> a bunch of that is boilerplate, tests, and generous newlines, though
05:41:15 <phaazon> https://github.com/phaazon/advent-of-code-2020/blob/master/day11/Main.hs mine
05:41:41 <phaazon> oh I need to remove part1, it’s not used
05:41:54 <tomjaguarpaw> Who is responsible for the haskell.org website and/or where can I file tickets for issues on it?
05:42:30 <dminuoso> tomjaguarpaw: #haskell-infrastructure is one place
05:42:42 <tomjaguarpaw> Thanks, I shall try there
05:42:45 <dminuoso> https://www.haskell.org/haskell-org-committee/
05:42:47 <dminuoso> Is the proper place
05:42:53 <Kronic> https://github.com/haskell-infra/www.haskell.org/ is the github repo
05:58:52 <Kronic> There's a lot in this optics lib, but from the looks of things I'll need to build a Traversal 
05:59:46 <dminuoso> Kronic: If you check solonarv' example above you dont need to do it yourself.
05:59:55 <dminuoso> If you use generics-optics, it will do this out of the box
06:00:06 <dminuoso> You just need to derive your type from Generic, and then you can just use `types` and voila
06:08:55 <solonarv> hm. does anyone here have library recommendations for email access (read-only is fine)?
06:11:41 <solonarv> specifically, I'm looking to write a program that looks through my incoming emails, and if a particular email notification is found it does something else
06:34:41 <tomsmeding> is there a tool that lets me automatically find functions that are transitively unused in my haskell code?
06:35:19 <tomsmeding> I don't particularly care what it does with functions that are exported from public modules of the library, though if it considers those unused I'd need to be able to set custom "used" roots
06:36:19 <merijn> tomsmeding: GHC already does that at the module level?
06:36:30 <tomsmeding> I know, and I explicitly want it across modules
06:36:41 <tomsmeding> I think I'm exporting stuff that I'm not actually using anywhere
06:36:42 <merijn> Not that I'm aware off?
06:36:53 <tomsmeding> I thought so, but I wanted to ask before assuming
06:38:53 <solonarv> the closest I can think of is -split-sections which allows for eliminating these unused functions at link time
06:41:43 <tomsmeding> thanks; while relevant, it's not what I'm looking for here :)
07:15:39 <tomjaguarpaw> Perhaps I shouldn't have compiled Pandoc
07:29:39 <sm[m]> tomjaguarpaw: yes that's almost always a mistake :-)
07:30:36 <sm[m]> who would think a simple markdown reading module would humble our powerful machines
07:45:50 <dminuoso> solonarv: HaskellNet?
07:45:51 <exarkun> do "simple" and "markdown" belong in the same sentence?
07:47:10 <dminuoso> solonarv: Im using the SMTP portion of it, and aside from some oddities, it seemed fine.
07:49:35 <dminuoso> tomsmeding: https://github.com/ocharles/weeder
07:50:07 <sm[m]> I would think so!
07:50:35 <sm[m]> We're not parsing Perl or Haskell here
07:54:46 <merijn> sm[m]: Yeah, Haskell isn't ambiguous :p
07:54:51 <merijn> (Not sure about Perl)
07:54:52 <solonarv> dminuoso: I did find that one, it gave me pause due to being currently unmaintained; but I suppose email protocols don't exactly innovate very often
07:55:32 <merijn> sm[m]: Markdown is one of those things that seems superficially simple, but when you look into it you realise it's so underspecified there's tons of ambiguity in both possible syntax and what it should mean
07:55:56 <dminuoso> solonarv: Indeed, especially the older protocols are well designed that you can write a stable implementation around it very easily
07:56:00 <merijn> Which is also why we have like 15 billion markdown "flavours", rather than a single "correct" markdown parser
07:56:07 <dminuoso> fsvo "well designed"
07:56:20 <merijn> Restructured Text > Markdown for that reason alone
07:56:35 <justsomeguy> I like ReStructuredText, which is like a standardized alternative to markdown with a proper spec and rendering software.
07:56:41 <justsomeguy> Ah, beat me to it.
07:56:48 <merijn> justsomeguy: :p
08:26:09 <shapr> Wow, I love this paper https://www.microsoft.com/en-us/research/uploads/prod/2020/11/perceus-tr-v1.pdf
08:26:17 <shapr> It's a whole language inside the ST monad
08:27:30 <Uniaika> my gawd
08:28:19 <Uniaika> oh yeah that's Koka
08:28:23 <Uniaika> *used in Koka
08:28:25 <Uniaika> very neat
08:31:01 <Geekingfrog> I'm using amazonka and I have a bunch of lens setters like so: x & foo . bar . set1 .~ val1 & foo . bar .set2 .~ val2  Is there a way to group together the prefix? Something like x & (foo . bar) & set1 .~ val1 & set2 .~ val2
08:31:06 <Ariakenom> reads abstract. is confused. ctrl-f cycles. feels betrayed
08:32:42 <c_wraith> Geekingfrog: how do  you feel about using &~ and zoom?
08:33:36 <Geekingfrog> Never used that, but why not
08:33:56 <Geekingfrog> zoom seems straightforward, &~ though…
08:35:52 <aplainzetakind> My referential transparency is broken: https://dpaste.com/4DFLERT3B
08:36:24 <aplainzetakind> What's going on I have no idea
08:38:33 <c_wraith> > ("string", (([1, 2, 3], True), ())) &~ zoom (_2 . _1 . _1) (do ix 0 += 5 ; ix 2 %= negate) -- Geekingfrog: this would be a lot cleaner if it wasn't all on one line
08:38:36 <lambdabot>  ("string",(([6,2,-3],True),()))
08:39:02 <ski> aplainzetakind> :t foo
08:39:34 <aplainzetakind> ski: foo :: (Num a, Num b, Enum a, Enum b, Ord a, Ord b) => [(a, b)]
08:39:58 <Geekingfrog> c_wraith, thanks. Indeed, it's fine with multilines
08:40:40 <ski> aplainzetakind> :t m0
08:41:05 <aplainzetakind> ski: m0 :: M.Map (GHC.Word.Word32, GHC.Word.Word32) GHC.Word.Word32
08:42:21 <solonarv> you can also write it without zoom and &~, like so: x & foo . bar %~ (set1 .~ val1) . (set2 .~ val2)
08:42:23 <ski> > [-1 .. 1] :: [Word32]
08:42:26 <lambdabot>  []
08:42:46 <aplainzetakind> Ah of course.
08:42:48 <aplainzetakind> Thanks.
08:44:28 <aplainzetakind> It's interesting though.
08:44:59 <aplainzetakind> So when foo is defined, how it's generated is still relevant or what?
08:45:16 <aplainzetakind> After all no negative values survive that list comprehension.
08:45:18 <aplainzetakind> Hmm.
08:45:23 <aplainzetakind> OK.
08:45:23 <ski> `foo' is overloaded
08:45:43 <ski> it's presumably recomputed, each time you use it
08:45:49 <aplainzetakind> foo isn't evaluated until it's called.
08:46:30 <ski> it's most probably not even cached, even after its value has been demanded (at some particular type)
09:23:18 <phaazon> https://github.com/phaazon/advent-of-code-2020/blob/master/day11/Main.hs
09:23:34 <phaazon> I think I cannot compress more without losing type signatures or yielding ugly where clauses :D
09:23:57 <glguy> phaazon, You'll also find a lot of Haskell AoC chat on ##adventofcode-spoilers
09:24:45 <phaazon> glguy: neat :)
09:25:35 <glguy> phaazon, we're also hammering on that one https://github.com/glguy/advent2020/blob/master/execs/Day11.hs
09:26:27 <phaazon> Data.Array
09:26:30 <phaazon> interesting
09:27:01 <phaazon> hm your stable anamorphism is fun
09:27:05 <phaazon> it’s my “coFind” function
09:28:37 <glguy> phaazon, I think ti's a rule that you aren't allowed to shadow 'map' :)
09:28:50 <phaazon> meh
09:28:56 <phaazon> I’ll call it m4p then!
09:29:13 <phaazon> shadowing should be allowed, I like shadowing.
09:29:51 <glguy> Shadowing common names like that means I got very confused when I was reading out of order and found 'print $ solve <$> [rule1, rule2] <*> pure map'
09:30:08 <phaazon> eheh
09:30:14 <phaazon> yeah, you have a point
09:31:15 <glguy> print (solve map <$> [rule1, rule2])
09:34:43 <phaazon> I need to flip it if I do this
09:36:06 <phaazon> yeah, rewrote it with just fmap
09:38:34 <glguy> phaazon, just reorder the parameters to solve so you don't have to flip it
09:39:00 <ski> i guess it was more expedient to the definition of `go' to have the parameters in that order
09:39:11 <phaazon> yep already done :)
09:39:46 <glguy> ski, sounds right
09:40:15 <glguy> I like prioritizing the order for users rather than the implementation if I have to pick
09:40:24 <ski> yes
09:41:25 <tomsmeding> dminuoso: Maybe I should've done slightly more research myself. Weeder looks exactly like what I was looking for. Thanks!
09:41:33 * ski . o O ( `flip solve rule = go where ...' )
09:41:46 <dminuoso> tomsmeding: Oh I just know about it because it was mentioned about a week ago. ;)
09:42:31 <phaazon> ski: haha
09:42:49 <pja> Weirdly, my solution for today’s AoC ran /faster/ if I generated adjacent co-ords on the fly in a list comprehension (ok, actually a do .. return) than if I explicitly wrote the 8 entry list of pairs in the source file.
09:43:10 <pja> List fusion looking inside the comprehension? Maybe?
09:43:35 <dminuoso> ski: Do you know of languages that let you define equalities like `flip solve rule = go` in the sense that they have no direction?
09:43:49 <pja> Doing it the comprehension way chomped 20% off the runtime of Part1.
09:44:08 <qoppa> If I want to dive into lenses for the first time, should I take a look at the lens package or the optics package? Or does it even matter?
09:44:12 <dminuoso> That is, languages that have = as meaning an equation, rather than a declaration/binding
09:44:30 <dminuoso> qoppa: They are functionally equivalent, but optics has better diagnostics.
09:44:53 <dminuoso> lens has a few more exotic combinators, and optics is a little safer and more conservative, but it brings AffineTraversal/AffineFold to the game.
09:45:07 <ski> @type let (flip -> mele) = \x0 -> fix (\loop -> \case [] -> False; x:xs -> x0 == x || loop xs) in mele
09:45:09 <lambdabot> Eq a => [a] -> a -> Bool
09:45:45 <ski> dminuoso : not quite sure what you mean by "they have no direction"
09:47:19 <ski> can you clarify "languages that have = as meaning an equation, rather than a declaration/binding" ?
09:47:41 <dminuoso> qoppa: Another consideration is, lens has a rather hefty dependency footprint, whereas optics-core is very light. You might think of microlens now, but that doesn't bring Prisms or Isos.
09:48:20 <dminuoso> The ergonomics and names are mostly the same, so you can switch one for the other later on with relatively little work.
09:48:21 <koz_> AffineTraversals are indeed very cool.
09:48:36 <koz_> (also, what does the word 'affine' even mean?)
09:48:40 <koz_> (I keep seeing it everywhere)
09:49:54 <dminuoso> ski: Sure, so in Haskell (=) does not properly denote an equation, but rather a binding. The left side gets bound to the right hand side (with variable binders for function arguments), and you get to have multiple definitions, that sort of thing.
09:50:13 <ski> (i think i played around a little with goal_expansion/2 in Prolog, to make a fact `maplist(foo,[a,b,c])).' be a shorthand for facts `foo(a). foo(b). foo(c).'. it would be interesting to have a principled way to be able to do something like that, though ..)
09:50:27 <dminuoso> ski: So what I was wondering about, whether there were languages where you could just write `f = foldr (+) 0` or `foldr (+) 0 = f` either way, and have it declare an equivalence of expressions that can be used
09:50:43 <dminuoso> Am I making any sense?
09:51:43 <ski> equality in Prolog is used symmetrically, doesn't matter if you go `[X|Xs] = List' or `List = [X|Xs]', means the same thing
09:53:08 <dminuoso> Ah interesting, I keep getting back to Prolog. Perhaps I should really learn it.
09:53:10 <ski> and in Mercury, it doesn't matter if you type `Z = f(X,Y)' or `f(X,Y) = Z', when calling the function f/2. however, when defining it, i'm pretty sure you have to go either `f(X,Y) = ..X..Y..' or `f(X,Y) = Z :- ..X..Y..Z..' (you can have multiple defining equations, with pattern-matching, of course)
09:54:43 <dolio> koz_: Comes from geometry. It's a relaxation of linear maps.
09:55:51 <ski> koz_ : linear maps include scaling,rotation,reflection,shear -- affine further includes translations among those
09:56:15 <koz_> ski and dolio both: So how does this relate to 'AffineTraversal'?
09:57:11 <dolio> There, linear means stuff like `f(a*x + b*y) = a*f(x) + b*f(y)`, and affine allows you to also have a term that doesn't depend on the function argument. So it kind of preserves sizes.
09:58:45 <pjb>  /whoami
09:58:47 <Kronic> Does anyone run into any issues with the haskell package just not detecting certain imports? I´m importing a library and it just cannot seem to find it despite stack build/ghci being able to see it. I restarted the LSP a few times and still nothing
09:58:58 <Kronic> Haskell package in VSCode I should say
09:59:38 <ski> consider an affine function like `x |-> A*x + b'. `A',`x',`b' may be real numbers (say). or perhaps `x' and `b' are vectors, and `A' a matrix. now consider e.g. `type F x = Either (A,x) B'. a value of type `F x' contains at most one `x', hence `F' is affine. otoh with `type G x = (A,x)', a value of type `G x' contains exactly one `x', so `G' is linear
10:01:25 <dolio> There's a relationship between linear maps and logical functions that use their variable exactly once. Adding translation is like adding building blocks that can ignore the argument, so the variables are used at most once.
10:02:51 <ski> the presense of the "constant term", not involving `x', makes it affine. if there was any term (/ alternative) involving more than one value of type `x', then it would not be linear. e.g. i guess you could call `H', where `type H x = Either (x,x) (Either (Bool,x) C)', "quadratic" (cf. `x |-> x^2 + 2*x + C')
10:03:42 <koz_> OK, I think I get the idea now.
10:03:49 <koz_> Thanks!
10:04:05 <dolio> Then an affine traversal visits at most 1 location.
10:04:31 <dolio> A lens is a linear traversal.
10:05:11 <ski> it (the affine traversal) either refers to a single location, or it fails to refer (the location doesn't exist, in the given data structure that we're traversing in search for the location in question)
10:05:21 <koz_> dolio: In this case, linear means 'exactly 1 location'?
10:05:27 <dolio> Yes.
10:06:51 <koz_> Oh, neat.
10:07:03 <koz_> But yeah, big fan of the opticsverse, and also TIL!
10:07:51 <ski> dminuoso : anyway, imho, having some familiarity of logic programming is worthwhile, at least as general background knowledge, for a programmer, so that one can recognize when applying it may be worthwhile. "another toolset in your toolbox"
10:07:53 <solonarv> a Lens' s a is a witness that s ≃ a * x, for some x; this is linear!
10:08:20 <ski> hm, so it is a witness of a divisibility relation ?
10:08:50 <solonarv> a Traversal' s a is a witness that s ≃ sum_{i from 0 to infinity} a^i x_i, for some set of x_i
10:08:58 <solonarv> (i.e. a power series / polynomial)
10:09:10 <ski> (could we have called it `Divides a s' ?)
10:09:51 <solonarv> an AffineTraversal' s a, then, says that actually, this power series / polynomial is an affine function: s ≃ x_0 + a * x_1
10:10:44 <solonarv> ski: sure! there might even be a paper on that somewhere
10:12:12 <koz_> solonarv: I think jle` did a writeup saying something similar?
10:13:22 <solonarv> quite likely; if so then I probably read it at some point and just regurgitated what I remembered
10:13:26 * ski . o O ( ⌜s ≃ ⌊s ∕ a⌋ + (s % a) ⋅ a⌝ )
10:14:21 <solonarv> I think you meant to place that "⋅ a" next to the other term?
10:14:22 <ski> (er .. sorry, meant ⌜s ≃ s % a + ⌊s ∕ a⌋ ⋅ a⌝, actually)
10:14:35 <ski> yea
10:15:46 <ski> (this reminds me of numeral systems, and arithmetic operations on finite prefices of naturals, that i've been thinking about recently)
10:16:41 <enedil> Hey, is it possible to use guards inside anonymous functions? Something like \x -> | x<3 = 2 | otherwise 5
10:16:51 <jle`> enedil: you can use -XMultiWayIf
10:17:31 <jle`> \x -> if | x < 2 -> 2 | otherwise -> 5
10:17:43 <ski> % :t \x -> if | x<3 -> 2 | otherwise -> 5
10:17:43 <solonarv> or a 'case' expression (possibly merged into the lambda using LambdaCase)
10:17:44 <yahb> ski: (Ord a, Num a, Num p) => a -> p
10:17:45 <jle`> but since you only have two branches it might be better to use just a normal if
10:17:57 <solonarv> % :t \case x | x<3 -> 2; _ -> 5
10:17:58 <yahb> solonarv: (Ord a, Num a, Num p) => a -> p
10:18:06 <ski> % :t \x -> case () of () | x<3 -> 2 | otherwise -> 5
10:18:07 <yahb> ski: (Ord a, Num a, Num p) => a -> p
10:18:09 <jle`> ooh fancy
10:19:09 <enedil> oo, cool
10:19:27 <enedil> I fear using language extensions because when I use some, everything starts falling apart
10:20:27 <solonarv> LambdaCase and MultiWayIf are both harmless syntax extensions, enabling them will never break existing code and they work straightforwardly
10:20:41 <ski> the last version doesn't use any extensions
10:21:09 <solonarv> it's also definitely not something I"d recommend, tbh
10:21:39 <ski> `MultiWayIf' ?
10:24:46 <solonarv> sure, that one's fine; I meant that I wouldn't recommend your (ski's) last version
10:27:19 <ski> ah :)
10:27:55 <ski> i wasn't necessarily recommending it, either. just pointing out the possibility
10:28:08 <enedil> what's wrong with that case?
10:28:33 <ski> nothing wrong with it, really, i'd say
10:28:38 <enedil> solonarv: ^
10:28:47 <ski> but the other two may be clearer, more to the point
10:29:02 <enedil> ah, ok
10:29:39 <ski> (but if you didn't want to use those extensions, then you could use the latter. i have, occasionally, used it)
10:35:56 <enedil> thanks <3
10:36:10 <carbolymer> I have `foo :: STM ()` and `bar :: STM b`, how can I enforce that foo is executed before bar? 
10:36:38 <koz_> carbolymer: 'foo >> bar'?
10:37:48 <carbolymer> koz_, you sure about that? because I'm having weird issues with lazines
10:37:58 <koz_> carbolymer: What manner of issues?
10:38:06 <carbolymer> i.e. foo doesn't modify mutable collection as it should
10:38:53 <koz_> Could you pastebin a small example of what you've got?
10:39:02 <koz_> It's a bit hard to say what the cause or solution are just on that.
10:39:52 <carbolymer> hmm, I might try
10:40:07 <carbolymer> because I need to retype code from remote desktop....
10:40:08 <dolio> solonarv_: The problem with that explanation is that Haskell has infinite traversals that can actually work. :)
10:40:35 <solonarv_> dolio: eh?what's that referring to?
10:40:53 <dolio> The power series explanation of a traversal.
10:41:05 <dolio> That only includes finite powers.
10:41:36 <solonarv_> oh, right
10:42:15 <solonarv_> make the sum up-to-infinity-inclusive, then, I guess :p
10:48:22 * ski thought it was already intended to be inclusive
10:53:46 <dolio> The problem is that just saying 'inclusive' doesn't make a whole lot of sense. There are a lot of infinities that aren't reducible to a linear order or something.
10:55:55 <dolio> The weirder your infinites get, though, the fewer functors are going to work, I guess.
10:56:19 <monochrom> Yikes, it really comes down to explicating the ordinal ω then!  I was going to say a few words on that but refrained.
10:56:33 <dolio> No, I mean ω is not sufficient.
10:57:41 <monochrom> OK, explicating all necessary ordinals.
10:58:48 * ski idly ponders having the sequence of coefficients being convergent
10:59:39 <dolio> E.G. it's similar to how 'the free monad' isn't possibly-infinite-lists in Haskell, because you can't flatten every tree to a linearized list without destroying some information.
10:59:40 <monochrom> OK, confound it all! Maybe generally well-foundedness (i.e., not inflicting a total order) if you don't want to shoehorn tree structures to total orders.
10:59:49 <dolio> Even an infnite list.
11:00:33 <dolio> Free monoid, even.
11:00:51 * ski . o O ( "The intrinsic topology of Martin-Löf universes" by Martín Hötzel Escardó,Thomas Streicher in 2016-02-12 at <http://www.cs.bham.ac.uk/~mhe/papers/universe-indiscrete.pdf> )
11:03:01 <dolio> Because directed limits of the binary operation + unit presentation of monoids are not reducible to the list presentation, or something. Only finite limits.
11:04:23 <solonarv_> I was playing around with loeb and type-tetris'd my way into loebM :: (Traversable t, Monad m) => t (t a -> m a) -> m (t a)
11:04:29 <solonarv_> https://gist.github.com/Solonarv/16e2c3d1301a99b6c26f59d6a261884b
11:04:49 <solonarv_> does this have any merit? I have trouble wrapping my head around exactly what it does
11:08:54 <dolio> Actually, maybe the problem is not the presentations. But the presentations only say that you can do finite amounts of associativity, and that doesn't let you reassociate all trees into a stream.
11:14:35 <carbolymer> koz_, well, I can't give you code as I'm unable to reproduce that on my machine :|
11:21:41 <ski> > let loeb = fix . sequence; loebM = sequenceA . loeb . fmap (<=< sequenceA) in loebM [\xs -> [0],\xs -> [1]]
11:21:44 <lambdabot>  *Exception: <<loop>>
11:27:50 <tomsmeding> carbolymer: I assume you can't take a photograph?
11:31:35 <ski> > let loebM = mfix . runReaderT . traverse ReaderT in loebM [\xs -> [0,1],\xs -> [2,3,4]]
11:31:37 <lambdabot>  [[0,2],[0,3],[0,4],[1,2],[1,3],[1,4]]
11:33:12 <dsal> solonarv_: If you make a monadic möb, you can call it a mönad
11:35:39 <ski> > let loebM = mfix . runReaderT . traverse ReaderT in loebM [\xs -> [(f . tail) xs | f <- [sum,product]],\xs -> [xs !! 2 + 3],\xs -> [2,4],\xs -> [length xs]]
11:35:43 <lambdabot>  [[11,5,2,4],[15,7,4,4],[40,5,2,4],[112,7,4,4]]
11:46:15 * ski glances at solonarv_
12:00:03 <Unhammer> With QuickCheck, how do I label a test so that it shows *when it fails* ? If I do 
12:00:06 <Unhammer> let (lots of vars) in QC.label "prop1" x>y .&&. QC.label "prop2" z>y+x
12:00:08 <Unhammer> then it only shows the label when both labels pass, which is the opposite of helpful :)
12:04:24 <jpcooper> Hello. What's the name of the extension the associates data types to specific constructors by adding an apostrophe to the name of the constructor?
12:07:08 <monochrom> I'll just answer "DataKinds" and secretly expect that you're barking up the wrong tree.
12:16:13 <jpcooper> monochrom: It's not DataKinds. I seem to remember there being a way to get a type which is all values constructed with a chosen constructor
12:17:44 <monochrom> There are only two extensions that adds apostrophes to data constructors.  DataKinds and TemplateHaskell.  Neither fits your wording.
12:17:55 <jpcooper> Or does DataKinds support that as well
12:19:23 <jpcooper> It seems I am barking up the wrong tree. Is there any way to do this?
12:19:38 <jpcooper> (without splitting the data type up)
12:19:40 <monochrom> No.
12:19:51 <jpcooper> That's a shame
12:20:46 <Unhammer> and wtf is a Rose in QuickCheck https://hackage.haskell.org/package/QuickCheck-2.8.2/docs/Test-QuickCheck-Property.html#g:4 this tells me nothing except that a rose is a rose is a rose
12:21:50 <jpcooper> Unhammer: roses are trees
12:22:11 <jpcooper> With varying numbers of branches at each node
12:22:47 <monochrom> No, the doc tells you there are two cases.
12:22:57 <Unhammer> I got that part, but I still don't know what it's doing in QC.Property
12:23:06 <monochrom> And the first case has two fields.  Those fields have types written there.
12:23:12 <monochrom> And the second case etc etc
12:23:27 <monochrom> And overall this is a recursive type, too.
12:23:40 <Kronic> Question: what is the appropriate way to take all of the getters for a Record and apply them to a value typed as such?
12:23:53 <Kronic> getters generated through makelenses, I should say
12:23:57 <monochrom> So don't worry about it?
12:25:46 <jpcooper> Unhammer: aren't properties rose trees?
12:26:10 <jpcooper> or the group things
12:27:44 <solonarv_> ski: sorry, was off eating dinner; looks like that is indeed a sensible thing!
12:30:32 <mouseghost> hemlo, here to bother again; is arrow notation that popular?
12:30:46 <monochrom> Not popular.
12:30:46 <dolio> No.
12:31:11 <Rembane> It's generally seen as a dead end. 
12:31:11 <monochrom> It had two major use cases, both waned.  hxt and lava.
12:31:42 <mouseghost> 👀
12:34:07 <monochrom> I think a version of functional reactive programming uses it too?  But Cale will explain to you why the arr method is an obstacle, not a help.
12:34:37 <solonarv_> yes, there are one or two arrow-based FRP libraries
12:34:48 <koz_> solonarv_: More than one or two, I think.
12:35:01 <solonarv_> so I'm still right, technically? :p
12:35:31 <ski> solonarv_ : note that my version behaves differently
12:35:34 <monochrom> I played safe by wording "version" so it's always right FSVO "version" :)
12:35:38 <solonarv_> I've never managed to wrap my head around them, but I understand reflex (which is monadic, not arrow-based) well enough that I can write working programs with it
12:36:59 <monochrom> IMO modeling digital circuits is a great application of arrows, so Lava would be the champion use case. But Lava left Haskell entirely.
12:37:40 <monochrom> As for hxt, that's just being cute (more seriously, an MSc project) by being a Kleisli arrow, i.e., you may as well go monadic.
12:38:06 <geekosaur> ad iirc later versions did so
12:38:14 <monochrom> But you can see how if it's good for digital circuits, then it's good for reactive things, same idea.
12:38:29 <fuzzypixelz> hello. I am very new to Haskell and funcctional programming in general. How would you write a number generator in Haskell? One that each time you call it returns the next integer in line? Or does one simple use an expression like [1, 2 ..]?
12:38:43 <koz_> fuzzypixelz: What do you plan to do with it?
12:39:23 <fuzzypixelz> no I'm just wondering how an experienced person would do it
12:39:26 <monochrom> Simply [1..]
12:39:36 <solonarv_> fuzzypixelz: a basic fact of Haskell is that a function must return the same thing each time you call it; so instead you will need some sort of data structure that lets you keep track of what number should come next; an infinite list like [1..] is a simple way to do that
12:39:44 <fuzzypixelz> koz_: because I have no idea how to do it just using pure functions
12:40:09 <monochrom> Python generators dream to be lazy lists.  Haskell has real lazy lists.
12:40:10 <koz_> I would say that [1..] unless you have something specific in mind?
12:40:55 <monochrom> The generator is going to be [1..] regardless.  The real question is how to write the consumer.
12:41:06 <monochrom> Beware that programmers never mean what they say.
12:41:28 <fuzzypixelz> not really, I thought asking this question would reveal some black magic about functional programming but it turns out haskell people already a convinient solution implemented
12:41:57 <exarkun> Do Conduits have to be lists?  What if have two separate functions that can produce elements?  Can I merge them into one producer that produces elements from each as soon as they are available?
12:42:03 <monochrom> But laziness is black magic.
12:42:25 <exarkun> Do I leave the Conduit abstraction when things get that complex?
12:42:33 <monochrom> Convenient at the same time just because the language gives it to you.
12:43:09 <monochrom> I have seen how Scheme students emulate it with much confusion and pain, and it is still missing one feature that Haskell has.
12:43:13 <fuzzypixelz> maybe what I really ought to ask is how you implement it in the functional paragigm
12:43:33 <monochrom> from i = i : from (i+1)  ?
12:43:40 <Cale> monochrom: I'd say it's not so much arr's fault (although it does belong in its own class), but that because arr was included, Arrow left out a bunch of structural details that are usually part of the definition of a monoidal category, and once those details were included, the abstraction served its purpose a lot better.
12:43:44 <monochrom> then from 0 = 0 : 1 : 2 : ...
12:44:22 <fuzzypixelz> from is a kayword?
12:44:29 <monochrom> No, it's my function name.
12:44:47 <tomsmeding> > let  cheese i = i : cheese (i + 1)  in  take 10 (cheese 0)
12:44:50 <lambdabot>  [0,1,2,3,4,5,6,7,8,9]
12:44:51 <Cale> i.e. the maps which explicitly re-associate tuples, which introduce or eliminate units on one or the other side of a pair, and which swap the pair components (for a symmetric monoidal category)
12:46:23 <monochrom> Ah, one can use arr for that, but should be specific methods to explicate the structure.
12:46:35 <Uniaika> arr!
12:47:19 <ski> @arr
12:47:19 <lambdabot> I'll keel haul ya fer that!
12:47:27 <koz_> Arr!
12:47:30 <mouseghost> yarrr
12:47:33 <tomsmeding> are there more people using ghcide or HLS using neovim+ALE and running into this issue where all diagnostics randomly disappear when doing stuff?
12:47:42 <tomsmeding> if so, please upvote: https://github.com/haskell/ghcide/issues/949
12:47:52 <monochrom> Yes, I really had the temptation to write "Arr, one can use arr for that, ..."
12:48:48 <Kronic> God my solution to the day 4 AOC is really disgusting
12:49:49 <Cale> monochrom: Yeah, if you have those explicit methods, it becomes possible to figure out before running an arrow where most values are being wired to
12:50:04 <fuzzypixelz> monochrom: what is the ":" syntax?
12:50:12 <monochrom> List syntax.
12:50:15 <Cale> Any "arr" is still a black box, but you're not forced to put black boxes in between every pair of computations any longer
12:50:37 <monochrom> I trust that you survived the first few Haskell lessons and know that already.
12:52:35 <Kronic> Would anyone be interested in suggesting ways I can improve this code? It is for day 4 of the AOC, part 1 only; https://dpaste.org/9ts8 
12:53:00 <ski> fuzzypixelz : `2 : [3,5,7]' adds `2' in front of the list `[3,5,7]', giving back the list `[2,3,5,7]'. so it combines a single element, and a list of additional elements, into a new list
12:53:33 <fuzzypixelz> Oh so it's like Scheme's "cons"
12:54:03 <ski> (so `2 : 3 : 5 : 7 : []', which means `2 : (3 : (5 : (7 : [])))', is the same as `[2,3,5,7]')
12:54:06 <ski> yes
12:55:10 <ski> (in fact, the latter is syntactic sugar for the former. just like in the Lisps, `(2 3 5 7)' is syntactic sugar for `(2 . (3 . (5 . (7 . ()))))')
12:56:27 <monochrom> Kronic: I wonder if, for example, you can define "foo s = parseDataPoint chunks s", then you just have to say foo "byr", foo "iyr", etc.
12:56:32 <exarkun> Maybe `mergeSource` is what I was looking for
12:56:56 <exarkun> But I dunno ... the docs don't actually say what "merge" means ... anyone know?
12:57:51 <Kronic> oh I see what you mean I think
12:59:41 <Kronic> Yea that does make it less repetitive, thank you
13:00:54 <dolio> Cale: So, the issue is that you can't actually see the context structure of the monoidal category. There are just arbitrary functions inserted at various places?
13:02:41 <Kronic> By the way, on a completely different note, how many people are using rio, the base replacement? Is that moving towards a standard or is that just an alternative option? 
13:02:57 <koz_> Kronic: It's _definitely_ in the 'just an alternative' camp.
13:03:00 <Cale> dolio: Well, you can see some of it, but e.g. when desugaring proc/do notation, there will be an arr between literally every pair of lines, so that will obscure everything
13:03:09 <ski> @type isJust
13:03:11 <lambdabot> Maybe a -> Bool
13:04:01 <Kronic> koz_, thank you, I figured as much
13:04:31 <ski> @type all isJust  ::  [Maybe a] -> Bool
13:04:33 <lambdabot> [Maybe a] -> Bool
13:04:56 <Kronic> woah, didn know about that function
13:05:55 <ski> instead of having a guard `length res == 1', and then using `head res', match the `res' input with `[r]' (rename `r' to whatever you prefer), then use `r'
13:06:42 <ski> oh, right, it's not an input, but locally defined. you can use `case'-`of' to match on it
13:07:06 <Kronic> the isJust/isNothing thing was very helpful, i should have known something like that already existed
13:07:24 <ski> > words =<< lines "foo bar\nbaz quux"
13:07:27 <lambdabot>  ["foo","bar","baz","quux"]
13:07:38 <Cale> You might also be interested in sequence here
13:07:45 <Cale> > sequence [Just 1, Just 2, Just 3]
13:07:48 <lambdabot>  Just [1,2,3]
13:07:54 <Cale> > sequence [Just 1, Just 2, Nothing]
13:07:56 <lambdabot>  Nothing
13:08:17 <Kronic> that is useful
13:10:07 <ski>   [byr,iyr,eyr,hgt,hcl,ecl,pid,cid] = [parseDataPoint chunks x | x <- ["byr","iyr","eyr","hgt","hcl","ecl","pid","cid"]]
13:10:52 <ski> i would probably not bother with defining `parsePassports' (as opposed to `parsePassport')
13:12:14 <Kronic> nice I was able to wittle down isValidPassport p to  = isJust $ sequence res
13:12:45 <Kronic> Let me see what I can do with the case comment from before
13:13:40 <ski> perhaps you could define `validatePassport :: Passport -> Maybe ValidPassport', where `ValidPassport' doesn't involve `Maybe's (apart from country ?) ?
13:14:38 * ski would just write `isJust (sequence_ res)' there (alternatively `all isJust res')
13:21:27 <Kronic> Thanks for all of the suggestions, that helped a lot 
13:39:53 <dminuoso> ski: Do you think the value extends curiosity and broadening your horizon? Are there real-world problems worthwhile solving in Prolog?
13:42:18 <monochrom> I recently wrote pseudocode for type inference for my students. It felt like Prolog.
13:45:04 <monochrom> "\x -> body" has type U->V under type environment E :- "body" has type V under type environment E∪{x::U}.  U and V are unknowns to be solved.
13:46:05 <monochrom> "f e" has type V :- "e" has type U, "f" has type U->V
13:46:27 <monochrom> (all under the same type environment, omitted)
13:47:13 <monochrom> I don't need backtracking, but it's certainly unification all the way down.
13:47:58 <monochrom> http://www.vex.net/~trebla/haskell/type-inference.html
13:53:31 <monochrom> Actually there are also presentations of type inference that benefits from backtracking. :)
13:53:40 <lortabac> dminuoso: learning Prolog is a bit like learning Haskell for an imperative programmer, it's a different paradigm
13:54:30 <dolio> If your type inference uses backtracking you should probably get different type inference, though. :þ
13:55:37 <lortabac> monochrom: do you have examples of type inference with backtracking?
13:57:21 <dolio> Some systems can be inferred, but only by trying a bunch of different possibilities, because there is no "principal" choice for certain terms.
13:58:29 <dolio> Although stuff like that easily degenerates into just not being decidable at all.
13:59:51 <monochrom> The "practical type Inference for arbitrary rank" paper presents, for each of rank-1 and rank-n (I guess more so for rank-n), both a non-deterministic rule and a deterministic rule.
14:01:41 <lortabac> I need to read that paper again, I don't remember that part
14:02:36 <monochrom> Their wording is "non-syntax-directed" and "syntax-directed".
14:04:26 <AWizzArd> Anyone here using the IHP web framework?
14:07:08 <lortabac> monochrom: ok thanks, I understand what you mean now
14:43:44 <quantumvatican> Hello, big frustration, tiny annoying and non original question. I know this must have been asked a thousand times, especially now (advent of code and all that) but I really and honestly can't find any satisfying answer. The question is : "how the hell I am expected to model and manipulate 2d arrays of values?" (aoc day #11). I know about 846 ways to do it. The array package deprived of safe 
14:43:50 <quantumvatican> access functions that nobody seems to use. Two nested Vector from the vector package. A Map (Int, Int) value. Or... maybe an IntMap (IntMap value). And I have even seen people using [[value]]. This is level 9000 of frustration: there are so many documented libs and types out there but I find myself stuck trying to find which one to use. For now I have settled on (Vector (Vector value)), at least 
14:43:56 <quantumvatican> there are safe functions and it is easy to construct with fromList when parsing the input file of advent of code day 11. Are there any pseudo-official "current state of the art" recommandations on which libs or types to choose in general ?
14:44:30 <glguy> quantumvatican: I liked array best for that problem
14:46:13 <mouseghost> Matrix?
14:47:41 <glguy> quantumvatican: My array version: https://github.com/glguy/advent2020/blob/master/execs/Day11.hs
14:48:08 <glguy> quantumvatican: I think Map/IntMap works well for cases of sparse keys or small incremental changes
14:50:15 <aev> I'd make a list of pairs. Wouldn't use a map unless one of the dimensions is a key.
14:51:01 <quantumvatican> Thank you for your help. How do you choose one lib/type over another? I mean in general. There are always so many options. For example here, how would I choose between array, matrix, and vector?
14:52:14 <glguy> array is my choice when I need configurable indexes. In this case I wanted coordinate indexes
14:52:32 <glguy> Map/IntMap when I need sparse mapping
14:52:46 <glguy> vector works better as a fast list
14:52:55 <glguy> with some of its fusion optimizations
14:53:43 <quantumvatican> Ok I see
14:53:47 <quantumvatican> thank you
14:54:07 <quantumvatican> Do you know if there are safe functions in array?
14:56:18 <glguy> They're all "safe", but they raise exceptions if you wander out of bounds. The "unsafe" operations are the ones that read outside of valid memory when things go wrong
14:56:39 <glguy> but I don't think the package has an indexing operation that returns a Maybe built in. I just defined one when I needed it
14:58:06 <quantumvatican> Oh ok. I thought there were only exception in IO. In that case I was thinking it would come in handy to check neighboring cells without bothering about the edges.
14:58:28 <glguy> I wrote this for myself: https://github.com/glguy/advent2020/blob/master/common/Advent.hs#L176-L180
14:58:51 <Kronic> you can have exceptions in anything, e.g. head []
14:59:09 <glguy> pure code can throw exceptions, but those exceptions are trickier to catch reliably because when they are thrown is driven by evaluation
15:01:06 <iqubic> I just dove into lens, and wrote this for myself: "arrIx a i = a ^? ix i"
15:01:25 <iqubic> It does the same thing as glguy's arrIx.
15:01:35 <aev> Michael Snoyman wrote about how head, tail, and !! are a problem due to laziness and in production code should be replaced by something that returns a Maybe. What do you think about that? Valid? And do such solutions exist already?
15:02:29 <iqubic> aev: If you want safe functions, I recommend using this: https://hackage.haskell.org/package/safe-0.3.19/docs/Safe.html
15:02:52 <iqubic> findJust :: (a -> Bool) -> [a] -> a
15:02:59 <iqubic> findJust op = fromJust . find op
15:03:02 <iqubic> That's not safe.
15:03:11 <glguy> aev: sweeping generalizations aren't too useful
15:03:32 <aev> iqubic: thank you!
15:03:37 <glguy> aev: if you're doing a lot of indexing into your lists you probably just have the wrong type
15:03:58 <monochrom> I don't have a reason to use head, tail, !! unless I know I'm using them correctly.
15:04:03 <glguy> replacing things with Maybe when there's no reasonable case for a Nothing to be returned creates cases that have to be ignored anyway
15:05:08 <monochrom> No, scratch that. Unless both I'm using them correctly and I really need them.  The latter is rare.
15:05:30 <aev> OK. So for instance you expect someone to input some characters in a console. And you don't expect them to not enter anything. Then using head or !!0 will break.
15:05:54 <merijn> I think any use of !! is almost certainly wrong anyway
15:06:00 <aev> Of course that happens only once and after that you learned and never do that again.
15:06:06 <merijn> head and tail have their uses, but are incredibly limited
15:06:43 <phaazon> !? all the way!
15:06:55 <monochrom> No, a better example is "map head (group xxx)" so I know my head is fed non-empty lists, always.
15:07:12 <monochrom> User input? Use a proper parser already.
15:07:13 <aev> phaazon: !? ? Interesting. I'll look that up.
15:07:13 <iqubic> I've legit seen someone pattern match on [] and on xs, and proceed to use head xs and tail xs there, instead of just pattern matching on the ":" constructor.
15:07:19 <merijn> Also, I can already preemptively answer "does everyone agree with Snoyman?" with "no"
15:07:25 <phaazon> aev: it’s defined on Vector
15:07:30 <merijn> iqubic: Sure, so have I
15:07:41 <phaazon> (!?) :: Vector a -> Int -> Maybe a
15:07:50 <monochrom> head, tail, !! are very low priority issues.
15:07:55 <aev> merijn: I didn't think so! :)
15:07:56 <iqubic> And in that case, once you fail to match on the empty list, you know head and tail will be safe.
15:08:05 <Kronic> what would you say is a high priority issue 
15:08:22 <monochrom> In addition, every effort in "fixing" the issue is missing the point.
15:09:11 <monochrom> Apart from unwashed beginners, realistic use cases of head don't benefit from Maybe.
15:09:28 <merijn> monochrom: pfft, nuance is for losers
15:09:34 <merijn> Black and white opinions only!
15:09:57 <monochrom> Instead of policing them (and not policing really important things), they should be either left alone or recommended to change over to Data.Nonempty.
15:10:22 <Kronic> I think it would be nice if there was some kind of indicator that a function is partial like head
15:10:41 <phaazon> well, a safe “head” and a safe “tail” is super easy to get at once by simply pattern matching
15:10:47 <phaazon> I think I almost never call those functions
15:11:08 <monochrom> Snoyman is talented but that head-tail-!! blog is one unit of blog time wasted on an inconsequential trivia pursuit.
15:11:32 <merijn> Kronic: See...suggesting a new type of haddock notion that indicates partiality *that* is a much less controversial *and* more productive suggestion
15:11:33 <exarkun> How bad is this idea?  https://gist.github.com/exarkun/e1b0c67e409c3223206d60256fe31b5e
15:11:38 <exarkun> (Conduit)
15:11:45 <jle`> merijn: there's Data.List.NonEmpty.group :)
15:11:45 <monochrom> Right, what phaazon said. You should be using pattern matching already 99.99% of the time.
15:11:56 <jle`> erm ^ monochrom 
15:12:05 <phaazon> exarkun: oh I saw that in Idris
15:12:08 <phaazon> your unwrap
15:12:13 <phaazon> I think it’s called useless in Idris
15:12:13 <monochrom> I did say Data.Nonempty.  Just call it a typo.
15:12:17 <phaazon> or boring
15:12:20 <phaazon> I don’t recall exactly
15:12:25 <phaazon> it should be in base in Haskell :)
15:12:26 <merijn> exarkun: It's ok, but you might wanna consider using STM instead
15:12:55 <jle`> monochrom: oh, i missed that message, my bad
15:13:42 <Kronic> It is probably an operator that is in use elsewhere, but I thought when I first learned about partial stuff it would be cool if the type was head :: [a] ?> a -- Was that what you meant by haddock notion merijn ? 
15:14:57 <jle`> % type a -!> b = a -> Maybe b
15:14:58 <yahb> jle`: 
15:15:03 <jle`> whoops typo
15:15:08 <jle`> % type a -?> b = a -> Maybe b
15:15:09 <yahb> jle`: 
15:15:21 <merijn> Kronic: Haddock is the doc generator that's being used on Hackage, so I meant some kinda of indicator for partial functions in Haddock might be useful. otoh, you end up wondering "should functions that potentially don't terminate be marked as partial?" and then you've got a whole new rabbit hole!
15:15:41 <jle`> % safeHead :: [a] -?> a; safeHead [] = Nothing; safeHead (x:_) = Just x
15:15:42 <yahb> jle`: 
15:15:44 <jle`> % :t safeHead
15:15:45 <yahb> jle`: [a] -?> a
15:16:12 <Kronic> That is really what I mean, I am not sure what kind of implications it would have, it would just be nice to see in an unintrusive way that something is partial by the type
15:16:34 <glguy> If anyone's doing adventofcode.com this year and isn't on the Haskell leaderboard, grab the code from /topic !
15:16:35 <jle`> there is a way to do it manually, by using an empty constraint
15:16:38 <Kronic> I got what you mean about haddock now though, I had forgotten about it, only recently returned to haskell :) 
15:16:53 <jle`> some people use it to deal with IO exceptions
15:16:59 <merijn> Kronic: You might be interested in Liquid Haskell too :)
15:17:08 <jle`> oh i think actually purescript has this Partial typeclass constraint
15:17:14 <monochrom> @quote monochrom safefromjust
15:17:15 <lambdabot> monochrom says: I use safeFromJust :: Maybe a -> Maybe a
15:17:20 <jle`> and it automatically adds it to incomplete pattern matches
15:17:36 <jle`> so if you defined head (x:_) = x, its type will be inferred as head :: Partial => [a] -> a
15:17:47 <jle`> and so any code that uses 'head' will also have that typeclass constraint
15:18:00 <jle`> it's possible in Haskell too I think, but you have to manually add the constraint whenever you have a partial function
15:18:06 <jle`> % class Partial
15:18:06 <yahb> jle`: 
15:18:29 <jle`> % partialHead :: Partial => [a] -> a; partialHead (x:_) = x
15:18:29 <yahb> jle`: 
15:18:39 <dolio> It did at least used to be in purescript. I wouldn't describe it as useful.
15:18:42 <jle`> % :t \xs -> head xs + 3
15:18:42 <yahb> jle`: Num a => [a] -> a
15:18:53 <jle`> % :t \xs -> partialHead xs + 3
15:18:54 <yahb> jle`: ; <interactive>:1:8: error:; * Could not deduce Partial arising from a use of `partialHead'; from the context: Num a bound by the inferred type of it :: Num a => [a] -> a at <interactive>:1:1; Possible fix: add Partial to the context of the inferred type of it :: Num a => [a] -> a; * In the first argument of `(+)', namely `partialHead xs'; In the expression: partialHead xs + 3
15:19:01 <Kronic> Seems cool but I think I should stick to just regular Haskell for now, it is not surprising that someone else already has something like this though haha. Thank you for pointing it out merijn 
15:19:07 <jle`> hm.
15:19:50 <merijn> Kronic: Liquid Haskell are just special annotations + a GHC plugin on top of regular Haskell
15:20:14 <monochrom> I think it's the same phenomenon as: Just because you use "error :: HasCallBack => String -> a" doesn't mean callers automatically inherit that constraint.
15:26:27 <Kronic> ah I see
15:27:00 <dolio> The reasons are basically what monochrom said above. If I'm using `head`, it's because I know something the compiler can't figure out, and the null class thing just makes it a big pain to actually use.
15:27:21 <dolio> And on something like incomplete matching, a warning is probably better.
15:31:31 <phaazon> dolio: can’t you pattern-match the list instead?
15:31:37 <phaazon> so that your compiler knows
15:31:53 <dolio> And put what in the null case?
15:32:01 <dolio> Something equally inconvenient to use.
15:34:49 <monochrom> When I was younger I looked at all these freedoms offered by various languages and made doomsday speeches about how programmers would be reckless and stupid and malicious and abused those freedoms to produce completely broken code 24/7/365.
15:35:12 <dolio> Well, they do do that.
15:35:16 <monochrom> No, it didn't happen, and never will.  Programmers turn out to use that freedom wisely, in reality.
15:36:03 <monochrom> Or rather, statistical vast majority.  We all make mistakes, yes.
15:36:04 <koala_man> generally, most of the time
15:43:01 <dolio> The point is that it doesn't stop me from writing the 'unsafe' thing that I happen to know is safe, it just makes me waste time. Because adding time wasting to 'incorrect' code is an easier way to make it more expensive than 'correct' code than actually improving the ability to write the latter.
15:44:11 <jle`> i do agree with you dolio . plus having to thread that Partial constraint up through your entire codebase for something at the low level...is pretty inconvenient
15:44:38 <Kronic> C++ programmers probably say the same thing about many of the things available in C++ 
15:45:43 <jle`> maybe something useful (for my specific announce) would be `yesIKnow :: (Partial => a) -> a`
15:46:16 <dolio> I think that was how you actually were supposed to use partial stuff in purescript.
15:46:29 <jle`> D:
15:46:38 <dolio> But that's just clutter.
15:47:11 <jle`> maybe better would be demanding a blood sacrifice every time you use a partial function
15:47:15 <jle`> same sort of cost
15:47:43 <jle`> the idea is to slightly punish you for using it until you pay the pennance
15:47:55 <jle`> but that feels like an odd form of Boolean Blindness
15:48:11 <jle`> it doesn't really do anything meaningful other than require some sort of token
15:49:09 <random-jellyfish> are there any real world projects that use parsec
15:49:13 <random-jellyfish> ?
15:49:25 <dolio> I guess the real crux is: I don't need the compiler to punish me for using partial functions. I already don't want to use them. But sometimes they're better than the alternative, and I don't want to jump through hoops in those cases.
15:49:27 <jle`> isn't parsec a real world project?
15:49:56 <random-jellyfish> yeah but I mean some language parsers built on parsec
15:50:10 <random-jellyfish> that are used in production
15:50:11 <jle`> oh sorry, i thought you wrote pandoc
15:50:26 <jle`> hm, parsec in specific, or parser combinators?
15:50:37 <merijn> random-jellyfish: There's about 998 reverse dependencies of parsec, so..."yes"
15:50:38 <random-jellyfish> parsec in specific
15:50:42 <jle`> generally i see megaparsec, attoparsec, etc. used in the wild
15:50:47 <merijn> https://packdeps.haskellers.com/reverse/parsec
15:51:03 <jle`> megaprasec being a 'modern' fork of parsec, even though parsec is pretty modern now
15:51:27 <mouseghost> >acme-lolcat
15:51:42 <random-jellyfish> would it be possible to parse a language like c++ in parsec?
15:51:57 <jle`> the idris language implementation uses megaparsec
15:52:22 <MarcelineVQ> idris1 does yes
15:52:30 <jle`> lm uses parsec
15:52:32 <jle`> *elm
15:53:13 <jle`> pandoc uses both parsec and attoparsec (attoparsec presumably for the binary encodings)
15:53:15 <MarcelineVQ> speaking of which, re the last convo branc, you simply annotate just above your function whether it's partial, covering, or total in idris.
15:56:37 <aev> I'm pretty new to haskell. How do I recognize whether a function is partial? And why would I want to avoid it?
15:58:24 <monochrom> 1. can't.  2. wouldn't.
15:58:39 <MarcelineVQ> Something like  head  is partial in that given an empty list it crashes because it can't give you an element from the front of an empty list. avoiding crashes is usually a good thing to want to do, but not always
15:58:54 <jle`> aev: one of the major strengths in Haskell is how the compiler can help you with avoiding a major class of bugs by handling all cases of an ADT...it can be your friend in writing code. using partial (non-total matching) functions sort of dismisses a lot of the advantages you'd get over other languages
15:58:57 <monochrom> 3. spend your time on a more worthy issue, such as learning pattern matching and evangelizing it.
15:59:15 <jle`> at least when learning haskell, relying on partial functions steers you away from things like pattern matching, which give more robust solutions
15:59:28 <monochrom> and equational reasoning.
16:00:08 <dminuoso> aev: Sadly there's no good way to recognize partial functions. If you gain experience, you'll not only learn the common partial functions, you'll also learn to see whether a function is partial based on the type signature and the description..
16:00:14 <jle`> a simple mistake would be something like `head xs + 3`, which would crash if xs was empty. but if you wrote `case xs of x:_ -> 3; [] -> ???`, it makes you thiunk about what you'd really want to do in that case
16:00:30 <jle`> if you put in the thought about what to do in the empty case (or why it shouldn't come up), then it makes sense to use it
16:00:58 <jle`> but just leaving the pattern match can help with thinking about your code
16:01:02 <jle`> and later on when you decide to refactor it
16:01:21 <jle`> i guess they got scared
16:02:26 <monochrom> No, they got dodgy connection.
16:02:51 <monochrom> Perhaps the router go scared, yes. :)
16:02:58 <aev> oh dear, my connection just broke. And now my nick doesn't work.
16:03:16 <dminuoso> aev: See, partial code causes problems like spurious disconnects.
16:03:21 <aev> :D
16:03:33 <monochrom> No, I/O code does.
16:03:39 <dminuoso> heh
16:03:53 <monochrom> I/O and mutability are the ones worth fighting against.
16:04:18 <monochrom> partial functions *pfft*
16:04:19 <aev> What if I/O is exactly the effect I seek?
16:04:38 <dminuoso> I/O is not a particular effect, it's the sledge hammer of effects.. :)
16:04:59 <aev> I really dislike mutability. I worked hard to make all my java applications use immutable data.
16:06:00 <Rembane> aev: How did it go? 
16:06:04 <aev> It's what I like about haskell and rust: it appears everything is immutable by default. Unless I haven't seen mutable things yet. Which is possible.
16:06:31 <jle`> yeah, haskell values are all immutable (barring unsafe compiler hacks)
16:06:35 <aev> Rembane: it turned out quite possible, though only through a lot of preparation. And def. not canon java.
16:07:08 <Rembane> aev: Nice! I didn't think it was really possible. :)
16:07:21 <aev> Using immutable data had an unexpected side effect: my programs are much faster now.
16:07:31 <jle`> we can still describe mutable code, though, so it's nice
16:07:36 <jle`> kind of gets the best of both worlds in a way
16:07:47 <jle`> *mutable algorithms
16:08:16 * ski . o O ( (`-Woverlapping-patterns',)`-Wincomplete-patterns',`-Wincomplete-uni-patterns',(`-Wmissing-fields',)`-Wincomplete-record-updates',`-Wpartial-fields' )
16:08:46 <aev> Why doesn't -Wall include -Wincomplete-uni-patterns? 
16:09:35 <dminuoso> Why would you think -Wall included *all* warnings?
16:09:40 <dminuoso> Seems quite unreasonable.
16:11:14 <merijn> incomplete-uni-patterns is an annoying warning, that's why :p
16:11:28 <monochrom> all < everything  because -Wall turns on a strict subset of -Weverything :)
16:12:37 <Kronic> Does anyone know if there is anything special that needs to be done to get on-hover type lookups for a stack project with vscode haskell ?
16:12:55 <ski> (also `-Wincomplete-record-updates',`-Wpartial-fields')
16:13:27 <dminuoso> aev: I guess the ratoinale is `-Wall` turns on all the pessimistic warnings you'd likely want, without giving debatable warnings. Some particular examples that come to mind is `-fwarn-missing-import-lists` or `-fwarn-monomorphism-restriction`
16:13:37 <dminuoso> It's very unlikely you'd ever want to see warnings for these
16:13:41 <Kronic> Ah nevermind just restarting the lsp fixed it for some reason
16:14:00 <dminuoso> aev: So the choice of "which warnings should be excluded" is opinionated.
16:14:02 <merijn> dminuoso: That's explicitly the rationale in the user guide
16:14:21 <merijn> Also "-Wall" in gcc is "the standard thing you turn on" and gcc doesn't even *have* a flag to enable all warnings
16:15:20 <dminuoso> merijn: I dont see any rationale for -Wall.
16:15:25 <dminuoso> Just a description of what it does.
16:15:59 <merijn> hmm, maybe I misremembered
16:22:03 <aev> dminuoso: sounds reasonable. Thank you!
16:23:12 * ski . o O ( "Java Precisely" by Peter Sestoft (of Moscow ML fame) in 2002,2005,2016 at <https://www.itu.dk/people/sestoft/javaprecisely/> )
16:24:16 * mouseghost . o O ( . o O )
16:33:28 <koz_> mouseghost: You're thinking about thinking?
16:33:36 <mouseghost> koz_, yes
16:33:56 <mouseghost> about this "emoji"thing
16:34:15 <monochrom> https://ro-che.info/ccc/9
16:34:57 <koz_> ROFL
16:35:12 <monochrom> Don't forget the lens one, too.
16:36:03 <koz_> monochrom: Lens one?
16:36:42 <monochrom> https://ro-che.info/ccc/23
16:38:39 <koz_> Lol.
16:40:12 <phaazon> ahah
17:46:31 <Thoralf> Hello.  I haven't been irc for a while.  I'm just starting into Haskell.  I want to do algorithms on abstract datatypes.  Are their any particular libraries I should look into?
17:58:01 <Kronic> Thoralf, https://www.fpcomplete.com/haskell/learn/ you could see if something here interests you, not sure i have much for the topic you asked for though
18:01:19 <koz_> Thoralf: That's a very general question. It depends on what algorithms, and what abstract data types.
18:26:44 <dsal> Go möb for maximum abstraction
18:27:01 * dsal still hasn't used `möb foldMap`
21:23:10 <superstar64> are there any versions of the lambda calculus that don't have function application?
21:23:21 <superstar64> like a version that only has composition or something?
21:45:00 <ski> superstar64 : in a cartesian closed category, there is no application, per se (while there is composition). however, there's still an "application morphism" `app : (A -> B) * A >---> B' that plays the role of application
21:48:35 <ski> if e.g. `add : Nat * Nat >---> Nat' so that `curry add : Nat >---> (Nat -> Nat)', then `<curry add,id> : Nat >---> (Nat -> Nat) * Nat' and `app . <curry add,id> : Nat >--> Nat' then expresses `\n -> n + n'
21:52:11 <ski> (note that `curry add' is not application of `curry' to `add'. rather `curry f' is a special construct that converts from a morphism `f : A * B >---> C' to a morphism `curry f : A >---> (B -> C)'. another name for `curry f' is `lambda f'. compare with that if `..x..y.. :: C' depending on free variables `x :: A' and `y :: B', then `(\y -> ..x..y..) :: B -> C' depending on free variable `x :: A')
21:53:08 <superstar64> right, i need to go back to learning category theory eventually
21:54:12 <superstar64> ski that kinda reminds me of `ArrowApply`
21:54:16 <ski> yes
21:54:18 <ski> @type app
21:54:21 <lambdabot> ArrowApply a => a (a b c, b) c
21:54:59 <ski> except that doesn't really distinguish between the type of morphisms (i wrote `>--->' above), and the type of exponential objects (i wrote `->')
21:55:58 <ski> one could, very roughly, say that category theory is an abstract theory of "first-order functions". morphisms can not take morphisms as "input", nor produce them as output
21:56:30 <ski> in a cartesian closed category, we can simulate higher-order morphisms, by using exponential objects, though
21:58:01 <superstar64> something like this then right? `data Term = Variable String | Lambda String Term | Compose Term Term | App`
21:58:49 <superstar64> wait, do you need products for this?
21:58:59 <ski> `A >---> B' describes a *set* of morphisms, between the two objects `A' and `B' (in whatever category we're talking about). `A -> B', on the other hand, is an object, can be placed to the left and to the right of `>--->'
21:59:11 <ski> you need products in a cartesian closed category, yes
22:00:16 <ski> "something like this then right?" -- is that supposed to represent categorical morphism terms in a cartesian closed category ?
22:00:47 <superstar64> i'm just curious about other types of lambda calculi that don't have native application
22:01:08 <superstar64> like, ski combinator calculi don't have native lambdas right?
22:02:01 <ski> right
22:03:42 <ski> (although, i'd say SKI combinators do not form a calculus, since there's no bound/local variables. see <http://lambda-the-ultimate.org/node/533#comment-7712>)
22:04:44 <superstar64> what do i call it then? a turing machine?
22:04:47 <ski> i think most things people would call lambda calculi have application. either as a primitive, or at least as a macro-defined / derived construct
22:05:41 <ski> perhaps you could call it (SKI combinators) a "combinator/combinatory system" ?
22:06:07 <superstar64> wikipedia calls it a calculus https://en.wikipedia.org/wiki/SKI_combinator_calculus
22:06:24 <ski> i'm well aware
22:07:08 <ski> (Turing machines are something specific. SKI combinators are not a machine model of computation, they're a language model. see e.g. <http://existentialtype.wordpress.com/2011/03/16/languages-and-machines>)
22:07:19 <superstar64> some difference
22:07:21 <superstar64> *same
22:07:41 <int-e> . o O ( it's a pointless calculus )
22:07:54 <ski> anyway, i think there's some continuation-based systems, which have lambda, but not a primitive application
22:08:38 <int-e> My real objection to SKI is that the only way I know to make use of it is through abstraction elimination... there's no intuition to it.
22:09:26 <superstar64> well, there's this https://en.wikipedia.org/wiki/B,_C,_K,_W_system
22:09:31 <ski> it's pretty ad hoc yes. (just like Hilbert-style axiomatic systems commonly are)
22:09:35 <int-e> Lambda calculus is pretty much directly programmable once you have a few primitives; abstraction + applicatiin gives you a 'let' binding.
22:10:12 <superstar64> int-e bckw might be more manageable 
22:10:34 <ski> not really much better, i'd say
22:11:05 <int-e> superstar64: that really has the same issue, it still only makes sense (to me) through abstraction eliminiation. And the W is awkward.
22:11:08 <int-e> ymmv
22:11:40 <int-e> points -- that is, named values -- turn out to be important for understanding things.
22:12:31 <ski> i guess one should also mention concatenative languages, here ..
22:12:51 <ski> @where Charity
22:12:51 <lambdabot> http://pll.cpsc.ucalgary.ca/charity1/www/home.html
22:12:56 <superstar64> i mean you could augment the ski combinator calculus with let in
22:12:56 <int-e> Is anybody doing BCKS
22:13:08 <ski> superstar64 : ^ that's a language based on categorical composition
22:13:36 <superstar64> cool
22:15:37 <ski> anyway, i guess you could avoid products, if you use multicategories rather than categories ..
22:15:53 <superstar64> what do stack languages use for as stack manipulation primatives? 
22:16:20 <superstar64> how would it be to translate them bckw
22:17:10 <ski> stuff like `drop',`dup',`swap',`rot',&c.
22:17:43 <superstar64> i know nothing about concatenative languages
22:17:53 <ski> SKI and BCKW uses application, concatenative languages use composition (of stack-transformers)
22:19:26 <superstar64> well, it's easy to translate a bunch of compositions to bckw, it's the stack transformers that i'm curious about
22:19:30 <ski> `1 2 +' evaluates to `3'. `1 2 + 3 *' evaluates to `9'. `1 2 3 * +' evaluates to `7' (that's reverse polish notation, so far. doesn't need a concatenative explanation)
22:20:31 <nfd> hey, I'm sure there's some Traversable t => a -> t (a -> a) -> a that i'm just not thinking of that chains a value through a bunch of pure transformations, yeah?
22:20:50 <nfd> sitting around in the common library
22:20:58 <superstar64> right, i read about this before https://github.com/leonidas/codeblog/blob/master/2012/2012-02-17-concatenative-haskell.md
22:21:05 <ski> `3 dup *' evaluates to `9', `1 2 3 drop +' evaluates to `3', `1 2 3 4 + swap - +' evaluates to `6'
22:22:23 <nfd> i mean, i can just do this with simple recursion over the list, but something like that sounds really elegant
22:22:44 <ski> `+',`*',`-' takes the two top elements off the stack, performs the arithmetic operation, and pushes the result back on top of the stack. numerals like `1',`2',`3' pushes the corresponding number on top of the stack. `dup' copies/duplicates the top item. `drop' removes the top item. `swap' exchanges the order of the top two items
22:23:36 <superstar64> nfd, i think you want foldr or foldl for that
22:24:40 <superstar64> foldMap and Endo might work too
22:24:55 <ski> @type appEndo . foldMap Endo
22:24:57 <lambdabot> Foldable t => t (a -> a) -> a -> a
22:25:07 <ski> @type ala Endo foldMap
22:25:09 <lambdabot> Foldable t => t (b -> b) -> b -> b
22:25:12 <superstar64> ski, i know the extreme basics of concatnative languages, i've just never used them
22:25:28 <ski> ok
22:26:29 <nfd> thanks. I didn't want foldl because the function on the inside is unary
22:26:55 <ski> @type foldr (.) id
22:26:58 <lambdabot> Foldable t => t (b -> b) -> b -> b
22:27:23 <ski> @type foldr ($)
22:27:25 <lambdabot> Foldable t => a -> t (a -> a) -> a
22:28:30 <superstar64> or `foldr id` to make it more confusing
22:28:57 <ski> superstar64 : anyway, i prefer using CPS to get "heterogenous stacks"
22:29:46 <superstar64> i'm not too familiar with CPS either
22:31:18 <superstar64> what would be a good use case for the Cont monad?
22:40:21 <c_wraith> mostly it's good for confusing people
22:40:50 <superstar64> always a good use case
22:41:58 <c_wraith> you can find some literature on using it to linearize control in with-style functions, but it turns out somewhat simpler things like Codensity can solve the same problem with fewer opportunities for bugs
22:43:59 <ski> > let run f = f id; push x k = k x; dup k x = k x x; drop k _ = k; swap k y x = k x y; uop f k x = k (f x); bop f k y x = k (f x y) in run (push 1 . push 2 . dup . uop succ . push 4 . bop (+) . swap . bop (-) . bop (+))
22:44:02 <lambdabot>  6
22:46:25 <monochrom> http://www.vex.net/~trebla/haskell/cont.xhtml
22:49:56 <ski> @where Backus
22:49:56 <lambdabot> "Can Programming Be Liberated from the von Neumann Style?: A Functional Style and Its Algebra of Programs" (Turing Award lecture) by John Warner Backus in 1977-10-17 at <https://amturing.acm.org/
22:49:56 <lambdabot> award_winners/backus_0703524.cfm>,<http://www.thocp.net/biographies/papers/backus_turingaward_lecture.pdf>
22:52:12 <superstar64> `(\k -> k 1) . (\k -> k 2) :: (Num t1, Num t2) => (t2 -> t1 -> c) -> c`
22:52:19 <superstar64> feels like semantic editor combinators
23:01:06 <ski> (iirc, i worked out the above CPS representation of concatenative in Haskell, maybe fifteen years ago, or thereabouts ..)
23:02:17 <superstar64> jeez, that's a long time ago
23:03:30 <int-e> > let begin n = n id; end = id; run = ($ id); push c v n = n (c . (\k -> k v)); pop c n = n (c . (\k _ -> k)); uop c f n = n (c . (\k x -> k (f x))); bop c f n = n (c . (\k y x -> k (f x y))); swap c n = n (c . (\k x y -> k y x)) in run $ begin push 4 push 2 push 3 bop (*) uop succ swap bop (-) end
23:03:33 <lambdabot>  3
23:06:52 <shachaf> "Codensity is simpler than Cont" is, I guess, an argument you could make.
23:07:34 <ski> int-e : istr seeing some version of that, before
23:08:03 <ski> (maybe a paper or a blag)
23:08:13 <int-e> ski: yeah it has come up before... but I felt an urge to to reconstruct it
23:08:37 <shachaf> I feel like I saw a version without the pushes, but if it was just using Num instances I'm not sure how it would make (*) work as well.
23:08:52 <shachaf> Maybe it just called it mul or something. Or maybe I'm just making things up.
23:09:26 <int-e> > let begin n = n []; end [v] = v; push xs x n = n (x : xs); pop (_ : xs) n = n xs; uop (x : xs) f n = n (f x : xs); bop (y : x : xs) f n = n (f x y : xs); swap (x : y : xs) n = n (y : x : xs) in begin push 4 push 2 push 3 bop (*) uop succ swap bop (-) end
23:09:29 <lambdabot>  3
23:09:47 <int-e> I think that's closer to the original version.
23:10:29 <ski> being the one in the blag superstar64 linked to ?
23:10:35 <int-e> And in any case, this version is easier to understand.
23:11:28 <int-e> ski: I don't know, didn't look
23:11:50 <ski> > let begin n = n (); end (v,()) = v; push xs x n = n (x,xs); pop (_,xs) n = n xs; uop (x,xs) f n = n (f x,xs); bop (y,(x,xs)) f n = n (f x y,xs); swap (x,(y,xs)) n = n (y,(x,xs)) in begin push 4 push 2 push 3 bop (*) uop succ swap bop (-) end
23:11:52 <lambdabot>  3
23:12:04 <int-e> "original" being something I've toyed with before, probably after seeing it elsewhere.
23:12:14 <ski> ok
23:12:19 <superstar64> ski, are `drop`, `dup`, and `swap` enough to create any permutation the stack?
23:12:25 <ski> no
23:12:27 <int-e> ah. tuples for type-checking. right.
23:12:52 <ski> you'd need `dip' or something like that
23:13:21 <shachaf> Is there an analogy to BCKW?
23:13:25 <superstar64> it would be nice if i could make this complete https://gist.github.com/Superstar64/d9262b493da18c32839167ad78247341
23:14:38 <int-e> . o O ( "assumtion" is a typo )
23:15:03 <superstar64> i can't spell
23:16:59 <superstar64> i have a half complete c++ version too
23:18:13 <superstar64> ski, what's `dip`?
23:18:25 <ski> superstar64 : `dip' temporarily "lifts" up an element from the stack, and applies a word to the stack underneath it (then puts the lifted element back on top)
23:19:25 <ski> it's a higher-order word. you need to push the word you want to apply, to the top of the stack (Factor calls this a "quotation". see e.g. <https://docs.factorcode.org/content/word-dip%2Ckernel.html>)
23:19:28 <shachaf> I mean, CKW are certainly similar to swap/drop/dup.
23:20:12 <ski> (quotations makes the concatenative model deviate from a plain linear composition of words, adding nesting to it)
23:22:57 <int-e> superstar64: How about a constructor PushAssm :: (Logic g a -> Logic h b) -> Logic (x ': g) a -> Logic (x ': h)
23:23:05 <int-e> ... b
23:23:38 <superstar64> what does that do?
23:23:50 <int-e> superstar64: then you can push swaps to any desired depth in the stack. Look at  PushAssm (PushAssm ExchangeSwap)
23:24:42 <int-e> (same for contractions and weakenings)
23:25:24 <superstar64> i'm just trying to picture that the typing rule would look like for `PushAssm`
23:25:45 <ski> > let run f = f id; push x k = k x; dip k w x = w (k x); swap k y x = k x y; cons k xs x = k (x:xs) in run (push 1 . push 2 . push 3 . push 4 . swap . push [] . cons . cons . cons . cons)
23:25:48 <lambdabot>  [1,2,4,3]
23:25:50 <ski> > let run f = f id; push x k = k x; dip k w x = w (k x); swap k y x = k x y; cons k xs x = k (x:xs) in run (push 1 . push 2 . push 3 . push 4 . push swap . dip . push [] . cons . cons . cons . cons)
23:25:52 <lambdabot>  [1,3,2,4]
23:25:54 <ski> > let run f = f id; push x k = k x; dip k w x = w (k x); swap k y x = k x y; cons k xs x = k (x:xs) in run (push 1 . push 2 . push 3 . push 4 . push (push swap . dip) . dip . push [] . cons . cons . cons . cons)
23:25:56 <lambdabot>  [2,1,3,4]
23:28:00 <ski> (exercise : express `dip' in the pair-based formulation)
23:28:08 <int-e> superstar64: Oh right, it's not sound. Too bad
23:29:37 <superstar64> wait, isn't `dip` just `flip (.)`?
23:30:01 <ski> in my CPS formulation, yes
23:30:32 <siraben> ski: do you program in this pointfree way a lot?
23:30:43 <ski> .. not really
23:30:53 <int-e> it's a curiosity
23:31:02 <siraben> looks like forth at that point, heh
23:31:03 <int-e> it produces terrible type errors
23:31:17 <ski> siraben : yes, the point was to express concatenative programming
23:33:02 <ski> (see backlog back to about one hour and a quarter of an hour, ago, at least)
23:36:29 <ski> superstar64 : s/Constraction/Contraction/
23:36:41 <superstar64> i really can't spell
23:37:06 <int-e> siraben: hmm, but nothing is stopping you from doing ExchangeSwap :: Logic  (delta :++ x ': y ': gamma) a -> Logic (delta :++ y ': x ': gamma) a  directly (apart from interfering with type inference)
23:39:01 <superstar64> int-e did you mean me?
23:41:11 <boxscape> is there some smart (possibly lensy) way if you have a function (a -> a -> a) and two tuples (a, a) to basically zipWith them together?
23:41:22 <int-e> superstar64: yes
23:44:24 <superstar64> boxscape `\f -> join bimap (uncurry f)` maybe?
23:45:15 <koz_> @pl \f -> join bimap (uncurry f)
23:45:16 <lambdabot> join bimap . uncurry
23:45:22 <int-e> :t curry . join (***) . uncurry
23:45:26 <lambdabot> (a -> b -> c) -> (a, b) -> (a, b) -> (c, c)
23:45:31 <boxscape> nice, thanks
23:45:35 <int-e> oh, wrong way...
23:45:40 <boxscape> oh
23:45:50 <ski> @type \f -> curry (join (***) (uncurry f) . ((fst *** fst) &&& (snd *** snd)))  -- not terribly elegant ..
23:45:50 <int-e> :t join bimap . uncurry
23:45:52 <lambdabot> (a -> b -> c) -> (a, a) -> (b, b) -> (c, c)
23:45:53 <lambdabot> Bifunctor p => (a -> b -> c) -> p (a, b) (a, b) -> p c c
23:52:48 <ski> @type (uncurry (&&&) . (join (***) *** join (***))) (fst,snd)
23:52:50 <lambdabot> ((a, b), (a, b)) -> ((a, a), (b, b))
23:52:52 <ski> @type (uncurry (&&&) . join (***) (join (***))) (fst,snd)
23:52:54 <lambdabot> ((b, b), (b, b)) -> ((b, b), (b, b))
23:53:10 <ski> @type (fst *** fst) &&& (snd *** snd)
23:53:12 <lambdabot> ((c, b1), (c', b2)) -> ((c, c'), (b1, b2))
23:56:23 <ski> @type let diag x = (x,x); pap (f,g) (x,y) = (f x,g y) in \f x y -> diag f `pap` x `pap` y
23:56:25 <lambdabot> (t1 -> t2 -> b) -> (t1, t1) -> (t2, t2) -> (b, b)
23:56:27 <ski> @type let diag x = (x,x); pap (f,g) (x,y) = (f x,g y) in (pap .) . pap . diag
23:56:30 <lambdabot> (t1 -> t2 -> b) -> (t1, t1) -> (t2, t2) -> (b, b)
23:57:28 <boxscape> why pap?
23:57:35 <ski> "pair apply"
23:57:38 <boxscape> I see
23:57:56 <superstar64> unix level identifiers here
