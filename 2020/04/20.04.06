00:19:26 * hackage hgeometry-ipe 0.10.0.0 - Reading and Writing ipe7 files.  https://hackage.haskell.org/package/hgeometry-ipe-0.10.0.0 (FrankStaals)
00:45:42 <fragamus> ok, I need to understand what fix is for and how it works. I need to know. before i die.
00:45:58 <Axman6> fragamus: fix is just the essence of recursion
00:46:28 <fragamus> yes thats really quippy but WTF 
00:47:24 <Axman6> _any_ recursive function can be written using fix: f a b c... = ... f x y z ... becomes fix (\myself a b c ... ->  ... myself x y z ...)
00:47:38 <Axman6> @src fix
00:47:38 <lambdabot> fix f = let x = f x in x
00:48:05 <Axman6> what is a little trippy is the definition, which creates a cyclic definition where f is passed it itself
00:48:25 <[exa]> fragamus: `fix f` == `f (f (f (f (f (f (...infinite f...))))))`
00:48:30 <Axman6> it is exactly the same as fix x = f (fix f), which gives you f (f (f (f (f.....)
00:49:04 <fragamus> how does that do anything but _|_
00:49:38 <Axman6> > fix (\f n -> if n > 10 then  []  else n : f (n+1)) 1
00:49:40 <[exa]> fragamus: it's lazy. the main trick is that if you have this simple "fix", you can use it to implement any recursive function without "touching" recursion manually
00:49:42 <lambdabot>  [1,2,3,4,5,6,7,8,9,10]
00:50:14 <fragamus> ok lemme look at axmans thing above
00:50:38 <Axman6> not that the answer will be bottom if the result depends on the recursive call and that recursive call never terminates:
00:50:55 <Axman6> > fix (\f n) -> n + f (n+1))
00:50:58 <lambdabot>  <hint>:1:10: error: parse error on input ‘)’
00:51:02 <Axman6> > fix (\f n -> n + f (n+1))
00:51:05 <lambdabot>  <Integer -> Integer>
00:51:23 <Axman6> > fix (\f n -> n + f (n+1)) 1
00:51:31 <lambdabot>  mueval-core: Time limit exceeded
00:54:36 <fragamus> theres a lot going on with this thing and I do not yet understand it
00:55:21 <fragamus> for one thing... fix takes an (a->a)
00:55:29 <Axman6> fragamus: step through the evaluation by hand. 
00:55:51 <Axman6> yes, but a can be anything, including other function types. in my cases above, a is Int -> Int
00:56:03 <Axman6> :t fix `asAppliedTo` (\f n -> if n > 10 then  []  else n : f (n+1))
00:56:06 <lambdabot> (Ord a, Num a) => ((a -> [a]) -> a -> [a]) -> a -> [a]
00:56:21 <fragamus> that lambda takes two parameters but i see you have curried something in there
00:56:30 <Axman6> uhin the second example it's Int -> Int (or Num a => a -> a really)
00:59:03 <fragamus> yeah I will take another look in the morning. I woke up and decided i had to learn this but I am not up to it and I must return to sleep
00:59:12 <fragamus> thanks axman6
00:59:25 <qualiaqq> fragamus: this might  help https://www.parsonsmatt.org/2016/10/26/grokking_fix.html
01:13:44 <claes-magnus> Hello! My first visit to #haskell.
01:14:21 <fragamus> > fix (\f x -> if x == cos x then x else f (cos x)) 5
01:14:24 <lambdabot>  0.7390851332151607
01:14:27 <yushyin> hello and welcome claes-magnus
01:14:39 <fragamus> hello claes
01:20:17 <jackdk> hello claes-magnus 
01:43:32 <iqubic> fragamus: Is that finding the fixed point of "cos x" starting with an initial guess of 5?
01:44:10 <merijn> iqubic: Looks like it
01:44:38 <iqubic> I guess that only works if you're looking for an attractive fixed point. If the function divereges as you iterate it, then you have an infinite loop.
02:02:26 * hackage th-lift-instances 0.1.15 - Lift instances for template-haskell for common data types.  https://hackage.haskell.org/package/th-lift-instances-0.1.15 (BennoFuenfstueck)
03:08:35 <ph88> When i'm in (some) monad, is there something that stops evaluating the rest of the monad when one Effect returns true? and when all have been tried return false ?
03:20:25 <kuribas`> ph88: you mean the Maybe monad?
03:21:24 <kuribas`> ph88: it depends on the definition of the monad
03:21:45 <kuribas`> for the maybe monad, if the first argument to (>>=) is Nothing, the rest will not be evaluated
03:22:10 <kuribas`> so if you have do a <- Nothing; otherstuff...  otherstuff is never evaluated
03:24:39 <jakalx> ph88: what do you mean by returning True/False?
03:24:40 <ph88> that could work
03:25:12 <ph88> i mean when you do     return true    or     return false
03:25:29 <ph88> pure true     pure false
03:25:54 <kuribas`> ph88: no, there is no special behaviour for Bool
03:26:01 <siraben> @unmtl ContT [E] (State S) A
03:26:01 <lambdabot> (A -> S -> ([E], S)) -> S -> ([E], S)
03:26:03 <kuribas`> ph88: in fact that is impossible due to parametricity
03:27:23 <siraben> @unmtl ContT A (State S) [E]
03:27:23 <lambdabot> ([E] -> S -> (A, S)) -> S -> (A, S)
03:27:35 <siraben> Hmm.
03:28:27 <siraben> It always gets to me that Cont's first parameter is the "return" type, and the second is the "input" type.
03:30:17 <LarryTheCow> .t 
04:15:27 <siraben> I can't do Except instead of Cont?
04:16:31 <siraben> Wow, looks like Cont and Except don't commute.
04:22:46 <merijn> Why would you expect them too?
04:22:51 <merijn> Must transformers don't commute
04:22:55 <merijn> s/Must/Most
04:25:48 <siraben> I'm having a bit of troubling figuring out which order to put the monads in. I have eval :: Expr → Env → ([Val] → S → A) → S → A
04:25:58 <siraben> and I want eval :: Expr → Comp A
04:26:19 <siraben> Where S is the mutable state, env is read-only, the ([Val] → S → A) function is the continuation
04:26:43 <siraben> It works on its own, Reader over ContT over State
04:26:57 <siraben> But let's say I want the evaluator to be able to throw an error to Haskell.
04:27:23 <siraben> eval :: Expr → Env → ([Val] → S → Error String A) → S → Error String A
04:28:23 <siraben> Ah, finally
04:28:25 <siraben> @unmtl ReaderT U (ContT [E] (StateT S (Except String))) a
04:28:25 <lambdabot> U -> (a -> S -> Except String ([E], S)) -> S -> Except String ([E], S)
04:31:20 <siraben> But I can't seem to derive MonadError?
04:43:00 <siraben> Here's a minimal example for anyone wanting to try it
04:43:01 <siraben> newtype Foo a = Foo { runFoo :: ContT Int (Except String) a}
04:43:01 <siraben>               deriving (Functor, Applicative, Monad, MonadCont)
04:43:33 <siraben> Then, trying to throwError inside Foo gives me a "No instance for (MonadError String Foo)" error
05:11:55 * hackage morley 1.1.0 - Developer tools for the Michelson Language  https://hackage.haskell.org/package/morley-1.1.0 (gromak)
05:12:56 * hackage lorentz 0.2.0 - EDSL for the Michelson Language  https://hackage.haskell.org/package/lorentz-0.2.0 (gromak)
05:57:56 * hackage deriving-aeson 0.2.3 - Type driven generic aeson instance customisation  https://hackage.haskell.org/package/deriving-aeson-0.2.3 (FumiakiKinoshita)
06:15:32 <gentauro> dmwit: Now I can load the `Data.Octet` into `GHCi` :) http://blog.stermon.com/articles/2020/04/06/haskell-data-octet-nand-smaller-but-slower.html
06:15:58 <gentauro> dmwit: (this time I cite you on why I don't implement an instance of `Bounded`)
06:16:44 <gentauro> but, it uses 1/3 of memory (+110k to +35k), but execution time went from a few seconds to 120 :|
06:23:15 <siraben> I was able to make it an instance of MonadFail, but had to write it manually; http://ix.io/2gPj
06:26:55 * hackage ghc-trace-events 0.1.0.1 - Faster traceEvent and traceMarker, and binary object logging foreventlog  https://hackage.haskell.org/package/ghc-trace-events-0.1.0.1 (MitsutoshiAoe)
06:59:26 <pgiarrusso> hi all, wish everybody's safe
07:03:51 <pgiarrusso> question: how well-supported is Stack these days ?
07:11:37 <gentauro> pgiarrusso: I think it's pretty well supported by FP Complete :)
07:12:22 <pgiarrusso> gentauro: I was asking because of https://github.com/commercialhaskell/stack/issues/5212
07:17:55 <infinity0> are there any frameworks that help to automatically defunctionalise part of a haskell program
07:21:38 <polyphem> infinity0: defunctionalise ??
07:23:19 <infinity0> https://en.wikipedia.org/wiki/Defunctionalization
07:24:32 <infinity0> if this could be done automatically, we would be able to serialise continuation-based monads and send them across machines, which is something i'm trying to make
07:25:10 <merijn> hmm, is there a way to run a conduit section without actually consuming the input
07:26:34 <gentauro> pgiarrusso: oh, I see
07:26:56 <gentauro> pgiarrusso: I'm guessing you can't expect `stack` to support the newest of the newest straight away :)
07:27:47 <gentauro> infinity0: have you looked into the `template-haskell` library?
07:27:49 <pgiarrusso> infinity0: there have been projects doing that... iirc cloud haskell tried
07:28:10 <gentauro> last time I had looked into this, I ended up working with that library iirc
07:28:21 <pgiarrusso> gentauro: well that's not the newest, that's the GHC they already use in the latest LTS
07:29:21 <gaze__> Kind of a more general question but suppose I have a bunch of tabular data stored in memory and I wanna do joins and stuff on it. I guess something kinda like pandas. Are there libraries for Haskell for doing this kinda thing?
07:29:56 <srk> pgiarrusso: I now prefer nix over stack, can recommend if you don't have special reasons to use stack
07:30:32 <pgiarrusso> srk: I'm aware nix exists, I don't have a month to invest into switching
07:31:08 <infinity0> gentauro: yeah, you could probably achieve it with template-haskell but i'd have to roll the whole thing myself, was hoping something similar already existed
07:31:17 <srk> pgiarrusso: it's more like few hours :) except if you like it and decide to switch to nixos as well 
07:31:59 <pgiarrusso> if anything, I'd consider switching back to Cabal
07:32:13 <srk> well that's exactly what nix allows you to do
07:32:18 <pgiarrusso> srk: as I'm currently fixing a Nix-only performance bug in Agda, I disagree.
07:32:45 <srk> pgiarrusso: can help if needed :)
07:33:20 <pgiarrusso> I decided to not use Nix, that's not under consideration at this moment. Please respect that.
07:33:28 <pgiarrusso> insisting will _not_ make me use Nix.
07:33:55 <srk> well I'm not, just offering help
07:33:56 <hseg> hi. i'm stuck with a design problem: have product :: (Ring r, Foldable f) => f r -> r, (^) :: Group g => g -> Int -> g. Want to write a function sub :: Laurent n r -> Vector n (_ r) -> r. Unclear how to type-tetris my way out of this
07:34:08 <hseg> (laurent polynomials are polynomials in x, x^(-1))
07:34:08 <pgiarrusso> thanks, not interested.
07:34:57 <hseg> i.e. somehow need to express that the vector of elements i'm taking is invertible
07:35:42 <pgiarrusso> infinity0: Defunctionalizing arbitrary Haskell code to Haskell sounds like a research project. IIRC, you need to _add_ GADTs as soon as you defunctionalize... polymorphism?
07:37:04 <infinity0> pgiarrusso: i only need a subset so far, the "code" part would all be IO () or m () or something, with simple types
07:37:24 <infinity0> i tried searching for "cloud haskell defunctionalise" but didn't find anything, do you have something more specific i could look for
07:38:18 <pgiarrusso> on typed defunctionalization, the work I had in mind is https://link.springer.com/article/10.1007/s10990-006-8611-7
07:38:32 <sm[m]> pgiarrusso: that stack warning is annoying but harmless. stack upgrade —git fixes it for ghc 8.8
07:38:59 <infinity0> (a >>= \input -> b) would become (A >>= Apply Input B) and i'm not expecting those data types to need to be GADTs
07:39:00 <pgiarrusso> sm[m]: thanks, I eventually found a workaround, the latest release candidate fixes it as well.
07:39:03 <infinity0> ah, thanks i'll have a look
07:39:15 <sm[m]> stack is well maintained but perhaps overdue for a release. Probably they were waiting for ghc 8.10
07:39:28 <pgiarrusso> infinity0: on Cloud Haskell, see https://wiki.haskell.org/Cloud_Haskell#Serializable
07:40:38 <hseg> i see two ways forward - make sub partial (but then need to push partiality down, not clear how deep it'd need to be pushed) or provide some mechanism for a user of the api to promise the input is invertible
07:40:46 <pgiarrusso> infinity0: it sounds like you already need GADTs there — the set of constructors for `Fun A B` varies with A and B.
07:41:21 <hseg> and have there be an implicit contract that i have inv :: Ring r => Inv r -> Inv r 
07:42:10 <merijn> So I'm trying to determine if a Text conduit has *at least* N lines of text before running the rest of my conduit, but doing so is turning out rather tricky
07:42:34 <merijn> I did "C.linesUnbounded .| C.isolate (n-1) .| C.unlines .| C.fold
07:42:43 <infinity0> pgiarrusso: A and B would always be m () though
07:42:44 <merijn> ugh, copy paste fail
07:42:46 <pgiarrusso> hseg: is there a _type_ of invertible elements, that can be injected into your ring
07:42:52 <hseg> ... actually that could work - define an assoc'd type with such a acontract
07:43:12 <infinity0> Serializable seems useful but i don't see the part where it defunctionalises anything?
07:43:20 <hseg> pgiarrusso: that's what i'm considering creating
07:43:22 <merijn> "do { result <- C.linesUnbounded .| C.isolate (n-1) .| C.unlines .| C.fold; do stuff with result }"
07:43:37 <pgiarrusso> hseg: yeah, `inv : a → a`, and `inj : a → b` where the ring is on `b`
07:43:43 <merijn> However, this runs into problems because part of my inputs is left buffered inside C.linesUnbounded
07:44:12 <pgiarrusso> infinity0: sorry: I don't think it defunctionalizes anything, the question is whether/how/what it serializes.
07:44:16 <merijn> So what I really need is a way to peek at the first N values, without consuming them, or a way to properly push the linesUnbounded leftovers back into upstream
07:44:30 <pgiarrusso> maybe they just give you a type error if you try serializing functions? :-|
07:45:33 <infinity0> they can derive Binary from Generic but as i understand you can't derive Generic for a function
07:46:07 <hseg> sorry, computer rebooted
07:46:18 <hseg> pgiarrusso: you were saying?
07:46:34 <pgiarrusso> 4:43 PM <pgiarrusso> hseg: yeah, `inv : a → a`, and `inj : a → b` where the ring is on `b`
07:46:46 <pgiarrusso> hseg: that's all, but it sounds like you got that
07:46:59 <hseg> yeah.
07:47:18 <pgiarrusso> I don't know if it's the best way, but I can't think of anything better without dependent types, my mind is warped by Coq nowadays
07:47:24 <hseg> :)
07:48:14 <pgiarrusso> otherwise I'd suggest `class Inv (A : group) (a: carrier A) := inv : carrier A`
07:48:31 <pgiarrusso> (sorry for the Coq syntax)
07:48:39 <pgiarrusso> but not in Haskell
07:48:43 <hseg> i'd need an assertInv :: R -> R^x as well, ofc, with user promising not to abuse it
07:49:20 <hseg> pgiarrusso: does that declare inv to be a subgroup of A's carrier?
07:49:25 * hackage haddock 2.24.0 - A documentation-generation tool for Haskell libraries  https://hackage.haskell.org/package/haddock-2.24.0 (harpocrates)
07:50:01 <pgiarrusso> hseg: no, `carrier A` is the carrier type and `a` and `inv` are elements — it's a typeclass on values
07:50:26 * hackage haddock-library 1.9.0, haddock-api 2.24.0 (harpocrates): https://qbin.io/inches-math-jork
07:50:38 <pgiarrusso> infinity0: the other semi-relevant thing is https://www.mathematik.uni-marburg.de/~eden/ but it's too experimental AFAIK — it's a forked runtime for serializing arbitrary things
07:50:59 <hseg> ok, that bends my brain a little - you're lowering classes down to element level?
07:51:04 <hseg> interesting concept
07:51:05 <pgiarrusso> infinity0: (I can't find it in their docs, but I remember they can serialize arbitrary thunks without forcing them, and that includes code)
07:51:06 <dmwit> gentauro: Odd. Why no Bounded instance? Like, why not the derived one, which conforms to the spec and also does mostly what your previous one did with the exception of the off-spec boundary conditions?
07:51:18 <infinity0> data A = A (Int -> Int) deriving Generic -- compiles OK, surprisingly... i'll have to dig deeper on this
07:51:19 <dmwit> gentauro: err. s/Bounded/Enum/ I mean
07:51:24 <infinity0> pgiarrusso: ah thanks, i'll have a look at that too
07:51:27 <dmwit> oh
07:51:28 <pgiarrusso> hseg: yeah that needs dependent types
07:51:29 <dmwit> gentauro: oh
07:51:35 <dmwit> gentauro: gross =P
07:51:50 <pgiarrusso> infinity0: but again, research product, pretty cool, but likely not good for _production_ use 
07:52:34 <infinity0> understood, yeah what i'm doing is research/experimental too, for now
07:52:38 <gentauro> pgiarrusso: why not? Performance?
07:52:47 <hseg> iiuc, class Ring r where { (+),(-),(*) :: r -> r -> r; zero, one :: r; data Unit r; inv :: Unit r -> Unit r; forgetInv :: Unit r -> r } should do the trick? 
07:53:09 <gentauro> dmwit: now your `tag` will be forever combined with that `monstrosity` (muahahaha)
07:53:15 <pgiarrusso> gentauro: I'm not worried about performance but support
07:53:52 <gentauro> pgiarrusso: could you elaborate?
07:54:29 <dmwit> gentauro: Except your comment doesn't even say what decision that text justifies!
07:55:12 <dmwit> You should at least add something like "since I want the Enum instance to wrap around, I therefore do not make a Bounded instance so that the rules above don't prevent that" or something.
07:55:14 <pgiarrusso> gentauro: I should have clarified: it's a research _prototype_, I assume. Or are you asking why using research prototypes in production carries risk?
07:55:33 <Tuplanolla> Does pgiarrusso permeate the fabric of freenode?
07:55:52 <pgiarrusso> Tuplanolla: I had an Haskell issue and joined a channel
07:55:57 <pgiarrusso> *this* channekl
07:56:13 <gentauro> pgiarrusso: it's more the "I'm not worried about … support" part
07:56:19 <gentauro> support from GHC?
07:56:35 <pgiarrusso> "commercial" support
07:56:41 <gentauro> pgiarrusso: ahhh, roger that
07:57:00 <pgiarrusso> Eden is a GHC fork with changes to the runtime system
07:57:36 <infinity0> i wonder if "deriving Generic" is actually converting (Int -> Int) into a haskell AST... one advantage of defunctionalisation into an abstract symbol is you can upgrade/bugfix the underlying function if needed, and retain the symbol in the serialised form, so i think i'd actually prefer it not to be converted into an AST
07:57:55 <infinity0> yes i understand i shouldn't rely on Eden in a production system since nobody is supporting it
07:58:27 <pgiarrusso> infinity0: yeah yeah, I was answering gentauro now, you clearly got it earlier :-)
07:58:30 <dmwit> gentauro: (...then I'd be happy having my name attached, because *your* name would be attached to the actual objectionable decision of making Enum wrap around. ;-)
07:58:45 <infinity0> :)
07:59:16 <gentauro> dmwit: I will update the text :)
07:59:54 <pgiarrusso> infinity0: re "deriving Generic" is actually converting (Int -> Int) into a haskell AST
08:00:09 <pgiarrusso> I don't think it can.. Generic instances are for datatypes, so how could they?
08:00:52 <infinity0> i also didn't think so, but then why does my example not compile-error
08:01:08 <pgiarrusso> got some code?
08:01:21 <infinity0> data A = A (Int -> Int) deriving Generic -- compiles OK, surprisingly... 
08:01:22 <pgiarrusso> and btw, if you modify a datatype, however, you likely will face similar questions
08:01:35 <infinity0> yeah true
08:01:37 <pgiarrusso> infinity0: `Generic` just produces an instance that describes `A`
08:02:22 <infinity0> ok but there are libraries like Data.Binary and Codec.Serialise that can serialise *any* instance of Generic
08:02:40 <infinity0> i was assuming they don't runtime-error when met with something like A (Int -> Int)
08:03:21 <merijn> infinity0: Can you even make a generic instance of "A (Int -> Int)"?
08:03:22 <lyxia> The complete spec is that they are derived for instances of Generic whose fields are themselves instances of Data.Binary and Codec.Serialize
08:03:38 <lyxia> A is Generic, but its field (Int -> Int) is not Binary or Serialize.
08:03:53 <infinity0> oh i see ok, that solves this question
08:05:03 <pgiarrusso> infinity0: BTW check out https://www.microsoft.com/en-us/research/wp-content/uploads/2016/07/remote.pdf, they do discuss sending functions around.
08:05:35 <infinity0> ah thanks
08:05:56 <infinity0> Jeff Epstein, unfortunate name
08:06:13 <pgiarrusso> they use closure-conversion not defunctionalization; see Sec. 5 and 6 ("Faking it")
08:06:46 <pgiarrusso> lyxia, Tuplanolla : should we merge #haskell and #coq?
08:07:00 <infinity0> looks very relevant, thanks!
08:08:04 <Tuplanolla> That's effectively happening once Haskell gets Eisenberg'd, pgiarrusso.
08:16:13 <ahri_> I'm calling `forkIO` via `bracket_` and doing some cleanup - what happens if `main` finishes before the cleanup? does it hang waiting for the thread or will the cleanup be interrupted? I'm getting some weird results and I'm wondering if the latter might be the cause
08:16:42 <merijn> ahri_: Your program exits
08:17:12 <merijn> ahri_: When main finishes the program stops and all unterminated threads die
08:18:16 <ahri_> merijn: excellent, that solves that mystery then - I'll have to do a bit more investigation into this
08:18:52 <merijn> ahri_: You'll want to block main and prevent it from exiting until all other threads finish
08:19:26 <infinity0> depending on your use-case you might also want to check out unliftio and/or safe-exceptions (although unliftio mostly supersedes safe-exceptions)
08:20:00 <merijn> Probably async is more appropriate
08:20:22 <merijn> ahri_: Working with forkIO directly is incredibly tricky to do properly
08:20:44 <merijn> ahri_: You'll want something higher level like the async library that takes care of that stuff for you
08:22:22 <ahri_> looks like I have some reading to do!
08:23:13 <ahri_> I'm using safe-exceptions at the moment, will have to look at unliftio and async
08:24:12 <merijn> ahri_: Async basically provides some higher level functions for handling lifetimes of threads (propagating exceptions, waiting for termination, etc.)
08:57:40 <cocreature> `hClose` implies `hFlush` right?
08:57:54 <cocreature> Or is there a case where calling `hFlush` before `hClose` does something different?
08:59:18 <hseg> hrm. is there some way of requiring an associated type to be an instance of a class?
08:59:46 <hseg> e.g. class Group (Unit r) => Ring r where { data Unit r; ... }
09:00:56 <hseg> ghc doesn't seem to complain, let's see
09:01:35 <wasi_> shorturl.at/lFHX2
09:05:21 <maerwald> merijn: I found async to always be fairly low level. Lots of things you have to know that are not even in the documentation 
09:07:33 <hseg> hrm. i notice this reengineering means i'll need to split my DerivingVia strategies between deriving from Num (and inferring Unit r ~ +-1) and deriving from Fractional (and inferring Unit r ~ r - 0) 
09:08:35 <hseg> pity, though makes sense
09:08:44 <hseg> as usual numeric hierarchies are complicated
09:11:56 * hackage pagure-cli 0.2 - Pagure client  https://hackage.haskell.org/package/pagure-cli-0.2 (JensPetersen)
09:18:31 <quantumplate> If I have some function, say `average :: State (Seq Double) Double)`, and I want to use it inside of a `StateT (Seq Double) IO a` function, how would I do that? is there a liftState function similar to liftIO?
09:18:55 * hackage hadoop-streaming 0.2.0.2 - A simple Hadoop streaming library  https://hackage.haskell.org/package/hadoop-streaming-0.2.0.2 (zliu41)
09:18:58 <wasiihsan> https://shorturl.at/lFHX2
09:19:28 <merijn> quantumplate: You want the mmorph package
09:21:13 <Cale> It's also possible to use mapStateT for that in the situation described (but yeah)
09:22:01 <hseg> crazy thought: to avoid duplicating all my derivingvia support code, add a phantom type to the derivingvia skeleton that represents the behaviour of the group of units
09:22:07 <hseg> is this sane?
09:24:16 <Cale> hseg: hm?
09:24:33 <hseg> (so instead of newtype Proj a; instance Num a => Ring (Proj a); deriving via (Proj Int) instance Ring Int, write data Proj u a; instance Num a => Ring (Proj PM1 a); instance Fractional a => Ring (Proj NonZero a); deriving via (Proj PM1 Int) instance Ring Int; deriving via (Proj NonZero Double) instance Ring Double)
09:25:01 <quantumplate> @merijn so something like `hoist generalize $ average xyz`?
09:25:01 <lambdabot> Unknown command, try @list
09:25:14 <quantumplate> oof, slack habits lol
09:26:07 <hseg> will require some churn, but shouldn't be too bad
09:26:09 <Cale> hseg: Seems doable, but I'm not sure it's any better than just separate newtypes
09:27:28 <hseg> well, have a larger hierarchy than just Ring
09:27:52 <hseg> and it's only there that i branch on the group of units phantom
09:28:48 <Cale> hm?
09:29:24 <Cale> I'm confused. Whatever sentinel types you use as arguments to Proj it seems could just be the newtypes themselves.
09:30:58 <hseg> you mean i could replace Proj PM1 by ProjPM1, Proj NonZero by ProjNonZero?
09:31:03 <Cale> yeah
09:31:30 <hseg> yeah, but my point is that i'm using Proj for several more classes, and in those the code is parametric in the sentinel
09:31:44 <Cale> ah, maybe I guess
09:32:16 <Cale> If Proj is already a meaningful thing elsewhere, then there's no apparent downside to doing it that way
09:32:21 <hseg> good
09:32:52 <hseg> just a little annoying that i can't get reuse in Ring itself for the methods that are parametric in the sentinel
09:33:37 <hseg> ... well, could always break Ring up into the parametric and nonparametric parts and have Ring be a synonym for their intersection
09:34:10 <Cale> Also, why isn't Num already a good enough approximation of Ring?
09:34:41 <hseg> because i want interop with ekmett's algebra
09:35:04 <hseg> so i'm writing my code to be generic in the algebra implementation
09:35:32 <hseg> which is admittedly a bit navelgazey
09:36:35 <hseg> anyway, thanks for confirming i've not gone completely insane
09:36:47 <hseg> (:
09:40:25 <Phantom_Hoover> ok wait random question i can't find on google and am too lazy to google myself
09:40:38 <lauraaaah> Hi
09:40:53 <Cale> hello
09:41:56 <Phantom_Hoover> what's to stop you writing totalEq :: (Eq a, Eq b) => a -> b -> Bool which has, like, a specialised definition on a ~ b that's just (==) and is const False otherwise
09:42:23 <Phantom_Hoover> also that shouldve been 'to test myself' earlier
09:42:27 <Cale> You'll need (Typeable a, Typeable b) as well
09:42:32 <Cale> but other than that, nothing
09:42:34 <quantumplate> is there a `forever` equivalent for StateT? i.e. "continually run this state function maintaining state from one invocation to the next"?
09:43:06 <quantumplate> I tried a few relevant google searches and couldn't find anything
09:43:08 <Cale> Phantom_Hoover: The thing that stops you normally is parametricity, but that can be sidestepped if you have runtime type information
09:43:15 <dsal> :t forever
09:43:17 <lambdabot> Applicative f => f a -> f b
09:43:23 <dsal> quantumplate: Why doesn't that work for StateT?
09:43:44 <Cale> Phantom_Hoover: It's important to realise that types don't exist at runtime normally, and so there's no way to tell if a ~ b unless you do something to give yourself one
09:43:53 <Phantom_Hoover> hmm
09:44:45 <quantumplate> dsal: forever will "work", but it just continually runs the process on the initial state.  i.e. `forever $ runStateT process initialState` just kept calling process with initialState over and over, rather than feeding the previous state back into process
09:44:50 <Phantom_Hoover> right i'm guessing hindley-milner or whatever ungodly mutation ghc now uses can't actually totally infer all possible type equalities?
09:44:55 <dsal> quantumplate: You mean it runs forever?
09:45:03 <Cale> Phantom_Hoover: That's not it
09:45:12 <Phantom_Hoover> welp
09:46:04 <dsal> quaestor: In that particular invocation, it's not clear what else you'd expect it to do.
09:46:33 <dsal> `runStateT (forever process) initialState`  ?
09:46:50 <quantumplate> dsal: sorry, got disconnected.  Yes, it runs forever, but each time it runs, it starts over.  Instead, I went the resulting state of the first invocation to be fed into the next invocation.
09:46:55 <dsal> er, forever.process.
09:47:02 <dsal> You're telling it to start over every time.
09:47:22 <Cale> Phantom_Hoover: It's that by design, when you have a type that says "forall a." the implementation has no way of knowing which type a is.
09:47:27 <quantumplate> mmm, ok, didn't realize I could nest the forever like that
09:47:33 <quantumplate> thanks, that's what I was looking for :)
09:47:54 <Phantom_Hoover> i mean yeah i think i'm thinking of it in terms of compile-time specialisation rather than type erasure
09:48:10 <dsal> Yeah, it'll keep doing whatever you told it to keep doing.
09:48:20 <Cale> Phantom_Hoover: Type classes work by acting just like additional arguments for dictionaries of operations that get passed around, and ultimately supplied at the point where the type stops being polymorphic
09:48:48 <Phantom_Hoover> is that the type erasure part of what i said
09:48:56 * hackage haskell-gi 0.23.1 - Generate Haskell bindings for GObject Introspection capable libraries  https://hackage.haskell.org/package/haskell-gi-0.23.1 (inaki)
09:49:14 <Cale> I suppose
09:49:38 <Cale> Even if I'm given an Eq instance for a, and an Eq instance for b, that doesn't give me any operation that I could apply to my values of type a and b to compare them
09:49:53 <Cale> I can't tell whether a and b are the same type, and I can't assume that they are
09:50:28 <Cale> If I knew that a ~ b, and I had simply an Eq a instance, then I would be fine
09:50:59 <Phantom_Hoover> mm
09:51:02 <Cale> But unless some information is given that allows me to *prove* that a and b are the same type, I won't have any way to tell
09:52:06 <Cale> If I know statically that a and b are the same type, it's easy, I just use Eq a
09:52:42 <Cale> If I don't know statically, then I need some operation to check if a and b are the same type, and generally types don't have that
09:52:49 <Cale> But Typeable lets you have it
09:53:16 <Cale> :t cast
09:53:17 <lambdabot> (Typeable a, Typeable b) => a -> Maybe b
09:53:40 <Cale> cast x will produce Nothing whenever a and b are not the same type, and Just x only in the case that a ~ b
09:54:40 <Cale> :t eqT
09:54:42 <lambdabot> forall k (a :: k) (b :: k). (Typeable a, Typeable b) => Maybe (a :~: b)
09:55:04 <Cale> a :~: b is the data version of the constraint a ~ b
09:55:24 <Cale> data a :~: b where Refl :: a :~: a
09:56:05 <Cale> So pattern matching on Refl lets the compiler know that a and b are the same type.
09:57:13 <Cale> :t typeRep
09:57:15 <lambdabot> forall k (a :: k) (proxy :: k -> *). Typeable a => proxy a -> TypeRep
09:57:20 <Cale> :t typeOf
09:57:21 <lambdabot> Typeable a => a -> TypeRep
09:58:07 <Cale> Comparison of TypeReps along with what would otherwise be an unsafe coercion is how cast and eqT work
09:58:31 <Phantom_Hoover> right
09:59:55 <Cale> Often you can avoid needing Typeable at all if you use GADTs to allow yourself to remember the types of things that you otherwise forgot with an existential.
10:00:32 <fendor> in ghci, can I set a break point on a function in a where block?
10:00:42 <fendor> or should I just line numbers?
10:01:21 <Cale> https://hackage.haskell.org/package/dependent-map-0.4.0.0/docs/Data-Dependent-Map.html -- no Typeable in sight, and no unsafeCoerce in the implementation either.
10:02:30 <Cale> fendor: I would expect that you need to use the line number... or just move the function out of the where until you find the problem.
10:02:56 <fendor> Cale, ok, thanks!
10:03:37 <Cale> However, I'm not certain, since I haven't ever really used the ghci debugger in anger, and only played around with it slightly many years ago
10:05:05 <fendor> I am giving it a try to try understand how some stuff works. So far, it is actually pretty nice. It is just hard to follow control flow
10:05:13 <fendor> since there isnt really any
10:17:09 <jumper149> How can I tell cabal to use the packages from my nix-shell instead of downloading them again from hackage?
10:17:35 <srk> satisfy all the deps
10:17:52 <srk> jumper149: if you use callCabal2nix that should work automatically
10:17:55 <jumper149> My default.nix uses cabal@nix
10:18:02 <srk> ^^
10:18:25 <jumper149> Ahh I think the problem is that I used my default.nix and I have to create a shell.nix first somehow
10:21:25 <srk> I think shell.nix is not strictly needed if it's just (import ./default.nix).env
10:23:18 <jumper149> My default.nix looks like this: https://github.com/jumper149/go/blob/master/default.nix 
10:24:05 <jumper149> Everything builds fine with nix-build but when I use nix-shell it builds the derivation but doesn't give me ghcjs in the shell for example.
10:24:14 <srk> yeah, that's expected
10:24:29 <srk> as you are doing .env from runCommand not your haskell packages
10:24:44 <ggVGc> does anyone else put a comment at the end of functions to be able to quickly jump to next non-indented line (e.g end of function)?
10:25:09 <srk> jumper149: you can rework your default.nix to return attrset instead of just runCommand
10:25:28 <srk> jumper149: something like this https://github.com/HaskellEmbedded/ivory-tower-nix/blob/master/default.nix#L9
10:26:12 <srk> jumper149: then you can do nix-build -A hello and from shell.nix you use (import ./default.nix).shell
10:28:46 <maralorn> I am getting really frustrated by functional dependencies + overlapping instances. Is there some workaround to get class A a b | a -> b, instance Functor f => A (f a) Int, instance {-# OVERLAPPING #-} Applicative f => A (f a) String ?
10:28:49 <maralorn> I mean I know why it doesn‘t work.
10:30:17 <maralorn> But there is a semantic which makes sense to me. If A (f a) b if f is a functor and not Applicative then b has to be Int if f is Applicative the b as to be String.
10:30:57 <maralorn> So is there anyway I can get this semantic?
10:31:22 <monochrom> No. Precisely that kind of semantics is unsupported.
10:31:26 <ArticulateHacker> is it normal terminology to say that a type "has an instance of" a type class? I'm new to Haskell, but I keep wanting to read this as "implements the type class"... having an instance makes it seem like my data instantiates something other than itself
10:32:45 <monochrom> If you s/has/is/ it will be perfect.
10:33:25 <ArticulateHacker> i could see that, too
10:33:36 <ysangkok> is 'is' better because there is supposed to be only one instance?
10:33:43 <dminuoso> ArticulateHacker: It's sometimes common to just say "T is C"
10:33:45 <ysangkok> 'has' makes it sound like there could be more
10:33:53 <maralorn> monochrom: So would you say it is reasonable that I‘d like that or is that a sign that I am expecting to much?
10:33:53 <monochrom> No. "is" is the only correct word.
10:33:58 <ArticulateHacker> ysangkok that's my thought
10:33:58 <dminuoso> ArticulateHacker: For instance, Maybe is Functor, but it's also fine to say Maybe has an instance Functor.
10:34:19 <monochrom> 1 is an element of {1,2,3} :: Int is an instance of Num.
10:34:22 <ArticulateHacker> dminuoso you wouldn't say "is an instance of Functor" ?
10:34:52 <dminuoso> ArticulateHacker: Probably not. It's someone common this way for some reason.
10:35:22 <dminuoso> *somewhat
10:35:26 * hackage dobutokO2 0.24.2.0 - A program and a library to create experimental music from a mono audio and a Ukrainian text  https://hackage.haskell.org/package/dobutokO2-0.24.2.0 (OleksandrZhabenko)
10:35:30 <maralorn> "has a Functor instance" is what I‘d say …
10:35:47 <dminuoso> Ultimately all choices that were presented, including yours, are fine.
10:36:07 <monochrom> More completely: {1,2,3} has many elements such as 1 : 1 is an element of {1,2,3} :: Num has many instances such as Int : Int is an instance of Num : I own many devices such as my iPhone : my iPhone is a device I own.
10:36:11 <dminuoso> A good mindmodel is to remember that the word "class" is meant in a set theory way.
10:36:30 <dminuoso> So "class" is conceptually the same thing as "set", so an instance declares a kind of membership
10:36:56 <monochrom> You don't say "my iPhone has a device I own".
10:36:59 <maerwald> Apple owns your iPhone. 
10:37:05 <monochrom> haha OK
10:37:07 <ArticulateHacker> monochrom ^ that
10:37:09 <monochrom> s/own/use/
10:37:18 <monochrom> You don't say "my iPhone has a device I use".
10:37:23 <ArticulateHacker> exactly
10:37:41 <dminuoso> ArticulateHacker: But really, the most common phrasing is "Maybe has an instance Functor" as far as I can tell.
10:37:43 <monochrom> Thereforee, Int is, not has, an instance of Num
10:37:43 <jumper149> srk: I think I'm getting close :))) ty. Do you have an idea how I can combine client.env and server.env from my example above?
10:37:50 <ArticulateHacker> hm. I guess I'll have to adapt the terminology in my head
10:38:01 <monochrom> I think it's plain English.
10:38:02 <dminuoso> ArticulateHacker: If you have a preferred way of phrasing it, do it your own way!
10:38:09 <dminuoso> Honestly, develop your own intuition.
10:38:30 <monochrom> "red is a colour" not "red has a colour"
10:38:50 <ArticulateHacker> yea, "has" just makes it sound like my data is a collection of things instead of a thing that can be used in a collection of ways
10:38:56 * hackage dobutokO2 0.24.3.0 - A program and a library to create experimental music from a mono audio and a Ukrainian text  https://hackage.haskell.org/package/dobutokO2-0.24.3.0 (OleksandrZhabenko)
10:39:22 <dminuoso> monochrom: But Int *has* an instance of Num. The membership is a separate entity from Int.
10:39:22 <srk> jumper149: something like this https://github.com/HaskellEmbedded/ivory-tower-nix/blob/master/makeshell.nix#L6 (add both packages .env.nativeBuildInputs to buildInputs)
10:39:30 <dminuoso> So English-wise, the word "has" makes more sense.
10:39:43 <srk> jumper149: think shellFor should be able to do the same
10:39:44 <maerwald> Oh, the color one is interesting. You could argue red is a spectrum, so it has colors. 
10:39:44 <monochrom> Here is how you can shoehorn "has" somewhere:  Int has the property that it is an instance of Num.
10:39:52 <polyphem> ArticulateHacker: "has an instance declaration" or "is an instance"
10:40:05 <dminuoso> This is some mighty fine bikeshedding though.
10:40:21 * maerwald is being particularly helpful today
10:40:41 <ysangkok> or you could say "the set of colours has red in it" "the set of instances of Num has Int in it"
10:40:41 <dminuoso> The real question should be, why do we have the word "instance" at all?
10:40:49 <dminuoso> In what etymological sense do we use the word "instance"?
10:40:53 <monochrom> Oh let's take it to the next level: Theology!
10:41:05 <monochrom> "God is love".  True or false?  Fight!
10:41:07 <ysangkok> i can see why people don't like overloading "is". but english is a lost cause. cu vi parolas esperanton?
10:41:26 <dminuoso> monochrom: Hold on, what kind of logic are we using here?
10:41:36 <monochrom> Theologic. :)
10:41:44 <maralorn> monochrom: I think "There has God".
10:41:49 <gentauro> dmwit: hey, updated the text. I hope it's more clear on the feedback you provided ;)
10:42:14 <lauraaaah> 🤨
10:42:15 <maerwald> monochrom: if allowing genocide is love, then... yes? 
10:42:15 <dminuoso> The law of excluded reason applies then.
10:42:25 <maerwald> But this is too controversial :p
10:42:26 * hackage vault 0.3.1.4 - a persistent store for values of arbitrary types  https://hackage.haskell.org/package/vault-0.3.1.4 (sjakobi)
10:42:51 <monochrom> dminuoso: what word do you propose instead of "instance"?
10:43:13 <ArticulateHacker>  If you guys could solve my existential problems while you're at it, I'd be appreciative
10:43:23 <dminuoso> monochrom: member?
10:43:26 <polyphem> monochrom: "realisation"
10:43:41 <maerwald> After we've solved the theodizee problem 
10:43:41 <dminuoso> monochrom: I'm going to make the claim that the word "class" has its roots in set theory.
10:43:47 <monochrom> Yeah memeber is probably much better.
10:44:05 <ArticulateHacker> if you use member, you would definitely use "is"
10:44:18 <ArticulateHacker> a is a member of class b
10:44:30 <dminuoso> ArticulateHacker: Now, in GHC haskell we tend to think of typeclass instances as *dictionaries*...
10:44:44 <dminuoso> ArticulateHacker: Then one could say that Maybe has a dictionary for Functor..
10:44:58 <ArticulateHacker> whoa whoa whoa. I'm only on page 169 here
10:48:06 <monochrom> In some contexts, "memeber" and "instance" are very close.  So when asked to choose a word of "??? Num Int", someone may think "instance" first.
10:48:35 <dminuoso> But isn't that just because that's what Haskell (and friends) trained us to think?
10:48:54 <dminuoso> If you asked the average Java developer, they might disagree.
10:49:20 <monochrom> On the Haskell committee, a rule designed against syntactic bikeshedding states that when it comes to syntactic choices, the first proposal is automatically approved, no debate.  So probably someone said "instance" before someone else managed to say "member", and it was done.
10:49:49 <monochrom> Eh the average Java developer precisely says "x instanceOf Object"
10:50:33 <monochrom> Here is how: member -> example -> instance.  For instance, when people convey "for example", sometimes they say "for instance".
10:50:48 <Cale> In Java, classes are classes of values. In Haskell classes are classes of types
10:51:14 <Cale> So it makes sense that an instance of a class in Haskell would refer to a particular type.
10:51:23 <dminuoso> The closest analogy in Java are interfaces. What term do you use there?
10:51:33 <ArticulateHacker> implements
10:51:53 <monochrom> instance.  x instanceOf Comparable<Object>
10:52:27 <Cale> Also, people use the word "instance" in Haskell to refer to the declaration which makes a particular type be a member of the type class.
10:52:46 <dminuoso> Cale: Do you mean it in the dictionary sense?
10:52:47 <Cale> So "has an instance of" would be referring to the instance declaration.
10:53:02 <Cale> Or possibly the dictionary, I suppose.
10:54:18 <Cale> Java's subtyping makes this confusing of course.
10:54:51 <monochrom> But similarly Haskell has subclassing.
10:54:53 <Cale> Is a Java class actually the class of its subclasses? I think not, but the confusion sort of exists.
10:55:04 <dminuoso> monochrom: Does that rule regarding bikeshedding really exist? It seems harsh, albeit understandable.
10:55:11 <monochrom> Yes.
10:55:53 <dminuoso> But couldn't a proposal then be rejected on the basis that the syntactic choices were not liked?
10:55:59 <Cale> dminuoso: Well, it did exist, I'm not sure if one could say it still exists.
10:56:18 <Cale> The GHC proposals process doesn't have such a rule
10:56:39 <zincy__> Snoyman says that having an extendable hierarchy of typeclasses is an idea from Java
10:56:42 <Cale> and honestly, half of the proposals are about stupid concrete syntax things anyway
10:56:53 <zincy__> I hope that isn't true
10:56:54 <monochrom> "public class Foo extends Object implements Comparable<Foo>" => Foo ⊆ Object, Foo ⊆ Comparable<Foo>
10:57:04 <Cale> zincy__: That's... ridiculous
10:57:16 <monochrom> "Foo x = new Foo()" => x ∈ Foo
10:57:27 <zincy__> Cale: I had some doubts, what is your reasoning
10:57:59 <Cale> zincy__: Wadler added parametric polymorphism to Java after type classes were already a feature of Haskell.
10:58:04 <monochrom> "class Num a => Integral a" => Integral ⊆ Num.
10:58:10 <Cale> and Java still doesn't actually have type classes
10:58:23 <zincy__> Cale: :D
10:58:23 <monochrom> "instance Integral Int" => Int ∈ Integral
10:58:37 <Cale> It has interfaces which can constrain type variables though.
10:58:45 <zincy__> I hope I am not misrepresenting Snoyman on this 
10:59:10 <zincy__> I think the implication was that in a roundabout way typeclasses were an idea taken from Java's interfaces
10:59:32 <monochrom> interface in Java is there to allow a restricted form of multiple inheritance.  it's subclassing otherwise.
10:59:40 <srk> jumper149: now I've noticed it's miso project, cool. let me know if you manage a shell with both ghc and ghcjs, I didn't get that far
10:59:55 <srk> jumper149: (only switched between client/server .envs)
10:59:57 <zincy__> monochrom: I know someone who actually vehemently defends the notion that "God is love"
11:00:14 <zincy__> I may or may not be related to them
11:01:28 <Cale> zincy__: There was probably some sort of inspiration taken from object-oriented programming in the design of type classes, but what they ended up with is very different.
11:01:37 <jumper149> srk: That's what I'm now doing too (switchting .envs)
11:01:51 <zincy__> Cale: Yeah
11:01:58 <Cale> I vaguely recall that someone was suggesting an OO-like feature, and their suggestion was misinterpreted
11:02:49 <jumper149> https://github.com/jumper149/go/blob/master/default.nix I have it like this for now, I have to specify attributes with `nix-build -A build` or` nix-shell -A server`
11:03:16 <jumper149> <> ".env"
11:05:17 <monochrom> zincy__: I think Snoyman said it because he only knows Java XD
11:06:00 <monochrom> Like, dude, extendable hierarchical OO classes dates all the way back to 1960s Simula and probably even something before.
11:07:17 <monochrom> Take note that on the Haskell committee back then, even in Miranda and Gofer before that, those people were all old-geezers who all knew about Simula and Smalltalk and all those old-geezer stuff, and hell probably actually never heard of Java.
11:07:51 <heatsink> Rules for subclassing without breaking things date back to CLU
11:07:58 <phadej> Java didn't existed when Haskell was done :)
11:08:27 <phadej> Haskell is 30 years old, Java just "24"
11:09:24 <zincy__> Anyone want to give me their thoughts on a draft of a blog post on IO.
11:09:26 <zincy__> https://pastebin.com/6yWbiKJF
11:09:35 <zincy__> It is inspired from my learnings on this channel.
11:10:38 <Cale> getLine is not a function
11:10:48 <mpickering> if you fork a thread from another thread which is then killed, the child thread isn't killed is it?
11:11:04 <Cale> mpickering: No
11:11:05 <monochrom> I've been looking for a word to replace "function" for things like this.
11:11:08 <glguy> mpickering: correct, it's not killed
11:11:21 <Cale> haha, thanks glguy 
11:11:24 <monochrom> so far I only know of "combinator" but it's too long.
11:11:38 <Cale> I realised after I responded that it was entirely ambiguous what my response meant
11:11:46 <zincy__> Cale: Thanks!
11:12:07 <Cale> zincy__: getLine *is* an IO action.
11:12:23 <zincy__> Cale: Yeah so just an IO value
11:12:25 <Cale> If you want a function to use as an example, putStrLn might be good there
11:12:26 <yushyin> already 30 years! that's older than me by a good amount. Maybe I should stick to a more new&fresh language? golang? :P
11:12:29 <maerwald> Well, IO is a function type alias no? 
11:12:37 <Cale> maerwald: no
11:12:40 <maerwald> So get Line is a function 
11:12:55 <maerwald> Hmm, was it a newtype? 
11:13:03 <Cale> It's a newtype of a function type in a way that is a very hacky implementation detail
11:13:05 <monochrom> And ANSI C, 50 years or something.  Do you just stop using C?
11:13:21 <Cale> (and not a particularly good way of thinking about how things work in principle)
11:13:39 <maerwald> Yes, but this wasn't about concepts, but semantics bikeshedding 
11:13:41 <maerwald> :p
11:14:12 <monochrom> if you s/alias/newtype/ you may get better responses :)
11:14:15 <Cale> maerwald: Well, it's an article that is supposed to be explaining the concept, so it's important to introduce things in a way that's as helpful as possible :)
11:14:51 <yushyin> monochrom: no! c is part of my job.
11:14:53 <Cale> zincy__: I like to make the distinction between evaluation and execution
11:14:57 <maerwald> So getLine is a newtype :p
11:15:16 <glguy> wat, no, getLine is not a newtype
11:15:20 <monochrom> Just remember: * maerwald is being particularly helpful today
11:15:21 <zincy__> Cale: I think I made that distinction in the article right?
11:15:33 <Cale> I haven't read the entire thing
11:15:34 <maerwald> Yeah, I'm on painkillers, don't listen to me
11:15:46 <monochrom> ooohhh poor you
11:15:46 <Cale> ah, yeah
11:15:58 <zincy__> Cale: I feel like I haven't understood the concept of evaluation 100 percent.
11:16:27 <monochrom> Where is fog when we have maerwald on painkillers so the two of you could strike a really divergent conversation...
11:16:37 <maerwald> I miss him too
11:16:50 <Cale> zincy__: So, evaluation is the process of turning expressions into values.
11:17:05 <glguy> You could just read old fog monologues. They were never particularly interactive so it will be the same experience
11:17:07 <zincy__> Oh I thought expressions were values :o
11:17:09 --- mode: glguy set -o glguy
11:17:41 <Cale> It's common to think about expressions in terms of the values that they evaluate to, because this process is deterministic and has no side effects.
11:17:42 <monochrom> There are times you don't bother drawing a line.  There are other times you do, this is one of them.
11:18:23 <Cale> If evaluation caused effects, or produced different results each time for whatever reason, you wouldn't be able to have that convenient confusion.
11:18:52 <zincy__> Yes, spent too long in Haskell :D
11:19:05 <Cale> Evaluation in Haskell is driven forward mostly by pattern matching.
11:19:58 <zincy__> So evaluation is the process of turning an expression into one or more values
11:20:22 <Cale> The smallest useful amount of evaluation we usually think about is reduction to "weak head normal form". An expression is in weak head normal form if either it is a lambda, or it is some data constructor applied to any arguments at all.
11:21:23 <dminuoso> zincy__: I prefer to think of "evaluation" as just (expression) graph reduction.
11:21:27 <Cale> So, we've determined some partial information about the value of the expression, the least we might possibly need in order to match a pattern, or apply a function.
11:22:06 <dminuoso> Because really, reduction might happen at a stage where the notion of "value" might not be present, say during compilation.
11:22:22 <dminuoso> (i.e. compiler optimizations)
11:22:48 <zincy__> dminuoso: So graph reduction as in evaluating an AST
11:23:27 <dminuoso> zincy__: No, an AST is much more.
11:23:28 <comerijn> Apfelmus's lazy evaluation guide explaining graph reduction is back in the land of the living to explain just this ;)
11:23:35 <Cale> There is a partial ordering on the values of each type, the definedness ordering, which has a least element, called _|_ (this is ascii art for a sort of upside-down stylised T), which is the value of those expressions whose reduction doesn't terminate.
11:23:41 <polyphem> zincy__: Evaluation as in graphreducing an AST
11:23:50 <comerijn> zincy__: https://apfelmus.nfshost.com/articles/lazy-eval.html
11:23:51 <zincy__> Cale: Ah ok so WHNF is basically evaluating one node down and leaving sub expressions
11:24:01 <Cale> zincy__: yeah
11:24:26 <Cale> zincy__: and if the thing is a function, it gets it to the point of being a lambda, but doesn't try to reduce the body of the lambda
11:24:59 <Cale> (which is something that doesn't make sense to do with most practical strategies for compiling)
11:24:59 <dmwit> gentauro: =)
11:25:21 <dminuoso> zincy__: The graph reduction doesnt happen on the entire AST, as the AST of a Haskell program encompasses more than just expressions. It covers *declarations*, *modules*, *type signatures* and *expressions*.
11:25:34 <Cale> zincy__: Are you familiar with this partial ordering?
11:25:58 <zincy__> Cale: nope
11:26:13 <zincy__> dminuoso: Ah gotcha
11:27:02 <Cale> Generally, this ordering is defined in such a way that x <= y when it's possible to replace some occurrences of _|_ in x with values of the appropriate types to obtain y
11:27:37 <Cale> So for example, (True : _|_ : _|_) <= (True : _|_ : False : _|_)
11:28:11 <zincy__> comerijn: Thanks! 
11:28:11 <srandon111> guys what is a good programming book to learn functional programming concepts?
11:28:42 <Cale> One way to think about what evaluation is doing is that it's moving upward in this ordering, with _|_ taking the place of any as-yet-unevaluated expressions
11:28:47 <monochrom> Any of Bird's books.
11:29:56 <Cale> So, e.g. if you're evaluating a list of bools, you might start out at _|_, and then move up to _|_ : _|_, and then from there you might determine the first element and get to True : _|_ and then perhaps True : _|_ : _|_ and True : _|_ : [] and finally True : False : []
11:30:03 <zincy__> Cale: What does *partial* denote in partial ordering?
11:30:16 <Cale> zincy__: That not every pair of elements is comparable
11:30:22 <zincy__> Ah ok
11:30:58 <Cale> For example, True : _|_, False : _|_, _|_ : [] and _|_ : (_|_ : _|_) are all incomparable with one another in this order.
11:32:11 <Cale> The other thing we assume is that any ascending sequence of elements in this order has an upper bound.
11:32:44 <Cale> This is what models the occurrences of things like infinite lists
11:32:55 <Cale> We have an ascending sequence
11:33:30 <Cale> _|_ <= 1 : _|_ <= 1 : 1 : _|_ <= 1 : 1 : 2 : _|_ <= ...
11:33:56 <Cale> and for every such ascending infinite sequence of values, there is a value representing its limit
11:34:14 <Cale> (perhaps the infinite list of Fibonacci numbers in this case)
11:35:43 <zincy__> What do you mean by "upward" in  "evaluation ... is moving upward in this ordering"
11:36:31 <Cale> "Upward" in the sense that x <= y means y is "above" x
11:37:21 <zincy__> Ah right
11:37:30 <Cale> It's important to notice that the definedness ordering on Int consists of _|_ at the bottom, and then all Int values are above it and incomparable to each other.
11:37:40 <Cale> all the other Int values, I should say
11:38:09 <Cale> This ordering has nothing to do with the Ord ordering on types
11:38:25 <zincy__> Cale: ^ that is why I am confused then
11:41:16 <zincy__> So basically evaluation is removing  _|_s from graph in a way that allows comparison
11:42:07 <zincy__> between enough values so that progress can be made
11:42:13 <comerijn> zincy__: Basically the ordering he's referring to is one of "more evaluated" vs "less evaluated"
11:42:24 <zincy__> Ah gotcha
11:42:31 <comerijn> zincy__: And incomparable values are basically "equally evaluated, but in different ways"
11:42:53 <comerijn> zincy__: Consider (_|_, 1) and (1, _|_) those are both evaluated "the same amount"
11:46:14 <zincy__> So you have elements of two sets and comparison can only be carried out when the ordering is the same in both sets?
11:46:16 <Cale> https://i.imgur.com/DjhpPvk.png
11:46:21 <Cale> here's a picture to help perhaps
11:47:01 <Cale> oh, actually, let me amend that
11:48:19 <Cale> well, let's just say, one of the edges coming out of _|_ : [] is going up to True : []
11:48:41 <Cale> and one of the edges from _|_ : (_|_ : _|_) is going up to True : (_|_ : _|_) of course
11:49:22 <zincy__> It looks like all the possible permutations for the expressions of a particular type
11:50:29 <zincy__> But its not
11:50:49 <zincy__> Because after one data constructor is peeled away there is a _|_ there
11:51:25 <zincy__> Is that so you don't end up with an infinite graph in practice which wouldnt fit in memeory
11:52:29 <Cale> This is a mathematical structure, not something in memory
11:52:42 <Cale> I'm depicting the ordering on [Bool]
11:53:41 <Cale> as a kind of graph where there's an edge going up from x to y when x < y and there's no z for which x < z and z < y
11:53:51 <Cale> Called a Hasse diagram
11:57:24 <zincy__> So the diagram is a way of formalising an ordering on the arrangement of a set?
12:08:14 <zincy__> oh, but its "partial" because not all the arrangements can be compared
12:08:27 <zincy__> In "partial ordering"
12:08:46 <comerijn> zincy__: It's not a way of formalising an ordering, it's a way of *visualising* an ordering (among other things)
12:22:55 <infinity0> pgiarrusso: i think this effectively does what i want, thanks for the pointer earlier https://hackage.haskell.org/package/distributed-static-0.3.9/docs/Control-Distributed-Static.html
12:23:05 <infinity0> "This however requires special compiler support, which is not yet available in ghc. " -- i wonder if there's any update on this
12:34:24 <c_wraith> ghc added static values quite a while ago.  I'm not sure if that's exactly what that package is doing, though
12:42:57 <pgiarrusso> infinity0: cool to know!
12:44:10 <infinity0> c_wraith: ah, yes i just found this https://gitlab.haskell.org/ghc/ghc/-/wikis/static-pointers
12:44:28 <infinity0> so perhaps i don't even need that package, i'll have a play with it
12:55:50 <xe4> most stack projects have a single tests block. Is there a way to have multiple tests blocks? 
13:09:22 <jumper149> When I'm in nix-shell can I look through some offline haddock documentation of my dependencies?
13:16:57 <maerwald> Can you output dependency tree with cabal, similar to stack? 
13:29:43 <sm[m]> xe4: yes, just give them different names
13:32:32 <Franciman> hi maerwald yes
13:32:40 <Franciman> you mean the cabal plan?
13:33:25 <Franciman> probably cabal v2-configure does the trick btw
13:33:26 <infinity0> what is everyone's thoughts on Data.Binary vs Codec.Serialise
13:33:35 <Franciman> it should print all the dependencies needed
13:33:37 <Franciman> and their version
13:34:17 <infinity0> the latter encoding (CBOR) has support in other languages, not sure if the former encoding has that or any other advantage
13:34:40 <Franciman> ah maerwald also cabal v2-build --dry
13:35:06 <Franciman> this has the important virtue that it doesn't write a cabal.project.local
13:36:26 <Nolrai> So I have a list of `m` elements and I want to randomly select `n` pairs, such that for each pair: `p`, `fst p` is earliear in the list then `snd p`. 
13:38:32 <sm[m]> That’s not quite what maerwald wants, it won’t print things already installed
13:39:53 <maerwald> Background was https://www.reddit.com/r/haskell/comments/fvzvdp/blog_wide_haskell_reducing_your_dependencies/?utm_medium=android_app&utm_source=share 
13:55:26 * hackage hackage-security 0.6.0.1 - Hackage security library  https://hackage.haskell.org/package/hackage-security-0.6.0.1 (HerbertValerioRiedel)
14:05:56 <Nolrai> If I have a lens of type `(IntMap MyType1 -> f (IntMap MyType1)) -> MyType2 -> f MyType2` and a function (MyType1 -> MyMonad MyType1), will just applying the lens as a normal function do it seems like it should?
14:06:18 <Nolrai> * do what it
14:11:53 <ByteEater> Nolrai https://ideone.com/OmbYve
14:15:07 <ByteEater> you can add nub of you want distinct pairs (but then it loops forever if the requested number of pairs is impossible, i.e. greater than m choose 2)
14:48:29 <infinity0> c_wraith: re static values, there is a bit of difference between that package and the in-built static values, i described here: https://github.com/haskell-distributed/distributed-static/issues/19#issuecomment-610050296
14:52:56 * hackage configuration-tools 0.5.0 - Tools for specifying and parsing configurations  https://hackage.haskell.org/package/configuration-tools-0.5.0 (fosskers)
14:56:07 <koz_> :t any
14:56:09 <lambdabot> Foldable t => (a -> Bool) -> t a -> Bool
14:56:12 <koz_> :t all
14:56:13 <lambdabot> Foldable t => (a -> Bool) -> t a -> Bool
14:56:17 <koz_> :t and
14:56:19 <lambdabot> Foldable t => t Bool -> Bool
14:56:56 <dsal> I always confuse two of those.  Now I can't remember which two.
14:57:05 <dsal> I guess all and and.
14:57:11 <koz_> dsal: Yeah, but as I've realized, I actually want getAll . foldMap here.
15:00:21 <solonarv> that doesn't look like it typechecks.
15:00:38 <koz_> solonarv: Yeah, I'm sketching, since I need a function to actually make the Alls.
15:00:53 <solonarv> so you want: getAll . foldMap (All . f) ?
15:00:56 * hackage extrapolate 0.4.2 - generalize counter-examples of test properties  https://hackage.haskell.org/package/extrapolate-0.4.2 (rudymatela)
15:00:57 <koz_> Yeah, that.
15:01:06 <koz_> I could probably use ala if I was pro.
15:01:07 <solonarv> that's 'all', as you might've noticed already
15:01:16 <koz_> ... derp.
15:01:26 <monochrom> That's all. :)
15:01:33 <solonarv> hehe :D
15:01:37 <fog> what different effects do different monads have with ListT
15:01:39 <koz_> monochrom: Folks?
15:01:52 <monochrom> Yeah
15:01:54 <koz_> fog: I assume you mean a ListT done right?
15:01:58 <fog> yeah
15:02:03 <fog> https://wiki.haskell.org/ListT_done_right
15:02:05 <koz_> fog: It depends on how you stack-em.
15:02:13 <fog> how do you mean/
15:02:21 <koz_> Like, StateT s List a and ListT (State s) a do rather different things.
15:02:36 <fog> oh right, I meant the monad within ListT
15:02:52 <koz_> So you're assuming ListT m a for some m?
15:02:56 <fog> yes
15:03:00 <koz_> @unmtl ListT (State s) a
15:03:00 <lambdabot> s -> ([] a, s)
15:03:11 <koz_> @unmtl ListT (Reader r) a
15:03:11 <lambdabot> r -> [] a
15:03:14 <koz_> Etc.
15:03:22 <koz_> unmtl can probably answer that for you.
15:03:30 <fog> hmm, not sure its using the same ListT
15:03:47 <koz_> fog: For that, I'd need a definition of the ListT you care about.
15:03:54 <fog> [] a should be ListT (State s) ?
15:03:57 <koz_> You can do what unmtl does by hand, it's just more tedious.
15:04:12 <koz_> Nope. ListT (State s) a is isomorphic to s -> ([a], s)
15:04:29 <koz_> (modulo weird spelling there)
15:04:33 <fog> data MList' m a = MNil | a `MCons` MList m a; type MList m a  = m (MList' m a); newtype ListT m a = ListT { runListT :: MList m a }
15:05:23 <fog> eg. MList m a  = m (a `MCons` MList m a)
15:05:45 <koz_> Right, so now paste in, say, 'State s' for 'm' in that.
15:05:48 <koz_> What does this give you?
15:06:11 <fog> it seems strange the way we get a transformer directly with a newtype wrapping, with no extra monad appearing 
15:06:51 <fog> MList (State s) a  = State s (a `MCons` MList (State s) a)
15:07:32 <fog> ah, so thats how it ends up with a list, by passing this operation recursively into the tail
15:07:46 <koz_> That's essentially the core idea behind unmtl.
15:08:27 <fog> ok
15:08:32 <koz_> (although you're mixing type and value level a bit there)
15:08:35 <fog> what about other monads?
15:08:39 <koz_> fog: Rinse and repeat.
15:08:51 <fog> hmm, I guess thats the power of ListT
15:08:51 <koz_> I can't give you a general answer because this depends very much on the effect in question.
15:09:02 <fog> well Maybe is quite interesting
15:09:08 <koz_> How two transformers stack up isn't a trivial thing.
15:09:15 <fog> then it seems like we should strat from StreamT
15:09:20 <koz_> Only stuff like Reader/Writer/State can all be mashed in and out of each other in an arbitrary order.
15:09:23 <koz_> Most other things can't.
15:09:31 <koz_> (or rather, they _can_, but the meaning is very different).
15:09:34 <koz_> For example.
15:09:43 <fog> yeah, I never really get why ContT is useful 
15:09:48 <koz_> @unmtl ErrorT e (State s) a
15:09:48 <lambdabot> s -> (Either e a, s)
15:09:56 <koz_> @unmtl StateT s (Error e) a
15:09:56 <lambdabot> s -> Error e (a, s)
15:10:04 <koz_> Those two say _very_ different things.
15:10:15 <koz_> The former retains the state even if an error happens.
15:10:23 <koz_> The latter discards the state as soon as an error happens.
15:10:36 <koz_> Now, which you want depends on the circumstances - both are valid in some cases.
15:10:49 <koz_> Which of those _your_ case is can't be determined in general.
15:10:52 <fog> its wierd how the T varient ends up inside the nesting
15:11:02 <koz_> I like to think of it as resolution order.
15:11:21 <koz_> Think about where the corresponding run* functions would have to go.
15:11:22 <fog> because its closest in nesting to the thig its wrapping around
15:11:59 <koz_> An example where it _doesn't_ matter:
15:12:04 <koz_> @unmtl ReaderT r (State s) a
15:12:04 <lambdabot> r -> s -> (a, s)
15:12:10 <koz_> @unmtl StateT s (Reader r) a
15:12:10 <lambdabot> s -> r -> (a, s)
15:12:17 <koz_> Note that those are isomorphic.
15:12:25 <fog> yeah thats easy
15:12:28 <koz_> Hence, the ordering of Reader(T) and State(T) amongst each other can be whatever.
15:12:34 <koz_> THis is why RWS(T) is a thing.
15:12:35 <fog> they commute
15:12:52 <koz_> However:
15:13:00 <fog> hang on, ReaderT+WriterT /= StateT ?
15:13:06 <koz_> Nope.
15:13:10 <fog> not sure why I thought that
15:13:14 <koz_> ReaderT + WriterT \subset StateT
15:13:22 <koz_> ReaderT is 'a state I can read, but not write'.
15:13:29 <fog> ah, so whats the point in RWST ?
15:13:30 <koz_> WriterT is 'a state I can write, but not read'.
15:13:47 <koz_> If you need more than one of Reader(T), Writer(T) and/or State(T), you can get them all at once.
15:13:57 <koz_> With () 'filling in' whichever one you don't care about if needs be.
15:14:03 <fog> so then why does adding them together not give a state, since it can be read to and written from?
15:14:11 <koz_> Becuase they're different states, potentially.
15:14:17 <fog> hmm
15:14:23 <koz_> ReaderT Int (Writer Int) has _two different_ Int states.
15:14:33 <koz_> One can be read from but not written to, the other can be written to but not read from.
15:14:41 <koz_> That's not the same thing as having _one_ state which is read-write.
15:14:46 <fog> so what does RWST do?
15:15:01 <fog> it would just give a read write state?
15:15:06 <koz_> It's essentially ReaderT r (WriterT w (State s))
15:15:10 <koz_> Just all in one.
15:15:31 <koz_> So you get (up to) three different states, at most one of which is read-write.
15:15:32 <fog> so thats 3 variables in scope?
15:15:49 <fog> yeah
15:15:57 <fog> so this thing with Maybe and Streams
15:16:11 <fog> its kind of like Fix no?
15:16:19 <koz_> So for example, RWS Int String Double means I have a read-only state of type Int, a write-only state of type String, and a read-write state of type Double, all in one nice monad.
15:16:23 <shapr> dmwit: did you produce a monte carlo tree search library as part of your dr mario project?
15:16:25 <fog> or, StreamT is written easily in terms of Fix
15:16:44 <shapr> I was wondering if there's a respected monte carlo tree search library for Haskell
15:16:49 <fog> I guess the question for ListT would be how much is it like Free, what with all these nested Monads...
15:17:01 <koz_> It comes from the observation that among Reader(T), Writer(T) and State(T), the stacking order is irrelevant, since you get the same thing anyway.
15:17:20 <fog> shapr: thats just a metropolis hastings accept reject liklihood right?
15:17:25 <koz_> @unmtl RWS r w s a
15:17:25 <lambdabot> r -> s -> (a, s, w)
15:17:41 <fog> ah, nice
15:18:06 <koz_> Disclaimer: I haven't yet had cause for RWS(T).
15:18:10 <fog> so do we get anything similar with Free?
15:18:21 <koz_> I don't get what you mean here. Free isn't a transformer.
15:18:27 <fog> wouldnt CoFree be similar since it is like with the paired value
15:18:33 <koz_> Cofree is different.
15:18:38 <shapr> fog: don't know, but mcts is from 2006, and earlier markov sampling work is from the 1950s, I think
15:19:03 <fog> shapr: whats your idea? you want a novel descent to a leaf?
15:19:32 <fog> like, a particular path, obtained via this strategy? 
15:19:53 <fog> or a particular shaped tree?
15:20:19 <fog> which would be the leaf at the end of a particular path in the tree of trees
15:20:44 <shapr> I have a problem I'd like to investigate that's not as large as the state space of Go, but is larger than any tree I'd like fully flesh out, so I'd like to wrap it up in a monte carlo tree search if one is already available.
15:20:54 <fog> im not sure how you would define a pdf over this tree of trees...
15:21:53 <fog> ah, so your covering the space of discrete solutions from the branching time evolution trajectories 
15:22:20 <fog> and your accept reject weight mediation is via how good of a move it is
15:23:06 <fog> so your going to explore the local space, and after a while, reject a bad path from some previous branch point
15:23:31 <fog> and hope that via this sampling you can determine a more intelligent search
15:24:39 <fog> by getting something like a fitted surface over a parametrisation of the different paths, predicting correlation of regions in the space spanned by the parameters to where you might find good paths
15:25:58 <fog> which ammounts to finding an approximator to this correlation function, that is, creating a parametric model to unfold the manifold given some samples 
15:26:36 <fog> which is the strategy being learned, based on the evolution of some metric over the space of choices 
15:26:56 <fog> training a classifier 
15:27:26 <fog> which acts as an AI player with optimised strategy 
15:28:00 <fog> the parametric model being determined has an internal representation
15:28:17 <fog> which can take functional or more commonly, neural network form
15:28:54 <fog> since the weights of the NN can have gradients obtained by backpropegation, allowing to determine the optimal search direction
15:29:37 <fog> where then we can incorperate this information if available into the monte carlo search, essentially adding noise, becoming stochastic gradient descent
15:30:26 <fog> without backprop, for to-be-learned internal parameters of a haskell function  
15:31:04 <fog> pure monte carlo is all thats left, with no gradient information available (except via direct sampling, which is prohibitive in high dimensions) 
15:31:53 <fog> so add pure noise within some range, and dont keep the update if it is worse, which is where the metric appears 
15:32:53 <fog> which should evolve the best classifier 
15:33:26 <fog> by tuning its internal parameters, eg in a haskell expression or the weights of a net
15:35:37 <fog> actually, its anoying how you still need an unavailable metric, since you were trying to choose the best move, but this requires training, which is a similar kind of search! you end up with a nesting... as always
15:36:26 * hackage threadscope 0.2.13 - A graphical tool for profiling parallel Haskell programs.  https://hackage.haskell.org/package/threadscope-0.2.13 (MitsutoshiAoe)
15:37:25 <fog> trying to find the best update to the internal parameters - which was being done by monte carlo, requiring a metric to determine whats "best", which again must be learned :(
15:37:38 <fog> i guess at some point you have to add some heuristics 
15:38:28 <fog> actually, no, thats where backprop saves the day, by giving local gradient information to better direct the search, and the stochastic element is by adding noise rather than an accept reject based on a comparison, so the metric is not required
15:40:28 <fog> so if your going to have something like a haskell function, which you cant backpropegate over to find differentials using chain rule, then your always going to need to learn some internal comparison metric for the monte carlo step, since backprop isnt available so no stochastic gradient
15:40:56 <fog> then you end up always needing something differentiable as the basecase
15:41:31 <nshepperd2> i wrote a few implementations of MCTS in haskell
15:41:37 <nshepperd2> but i wouldn't call any of them good
15:41:50 <fog> which kind of supports the idea that you would have lambda calculus with arbitraritly represented optimisable approximators somewhere in the type system - allowing then for approximators to be derived for arbitrary functions
15:42:57 <koz_> MCTS?
15:43:16 <nshepperd2> https://en.wikipedia.org/wiki/Monte_Carlo_tree_search
15:43:32 <fog> like then basically, hierarchacally grained function implementations that boil down to mixture of experts models, via the Num instance, ie, the algebra of the functions in scope at the lowest level being (+) and (*), is the key to soft functional programming 
15:44:06 <koz_> nshepperd2: Oh, cool.
15:44:56 * hackage launchdarkly-server-sdk 1.0.4 - Server-side SDK for integrating with LaunchDarkly  https://hackage.haskell.org/package/launchdarkly-server-sdk-1.0.4 (launchdarkly)
15:45:45 <nshepperd2> fog: MCTS itself doesn't have anything to do with machine learning, it's more like a hierarchical multi-armed-bandit algorithm 
15:46:09 <fog> so they get their success metric by exploring local paths and keeping a score of how many win
15:46:17 <nshepperd2> you can add machine learning and NNs and stuff, though, in which case you end up with something like AlphaGo
15:46:43 <fog> well no, its exploration of the better space more is learning
15:47:04 <fog> it just has an inbuilt success measure, of score
15:47:40 <fog> ie, no need to learn some fancy way of reading the board to determine what a good move is
15:47:56 <fog> a crude form of classifier is introduced using sampling
15:48:48 <fog> which "fits" the manifold, again crudely, by just backpropegating the score
15:49:40 <fog> your metropolis hasings accept reject probability for the mote carlo step being directly proportional to this score 
15:50:05 <nshepperd2> there's no metropolis hastings, or curve fitting involved
15:50:21 <fog> so you dont reexplore space that was sampled and had a lower score earlier on in the path (a wider region)
15:51:14 <fog> nshepperd2: given the abstract framework, it seems like they basically have replaced these with the simple score 
15:52:14 <fog> an objective notion of success is available, so no classifier need be developed, but basically thats what this scored region is representing
15:52:53 <fog> just that its trivial to determine its worse from the data stored at the branches
15:53:35 <fog> if that was supposed to be some way of looking at the board to determine eg, commonly useful patterns, then this would struggle I think
15:54:23 <fog> so then you would have a net, for the classifier, in addition to these simple numeric opperations of keeping score on exploring
15:54:40 <fog> notice how easily the score backpropegates 
15:55:05 <fog> again its the algebra of Num
15:55:35 <fog> and instead of cahin rule for calculating gradients, we are just propegating the score fraction
15:57:17 <fog> i really suspect that in the most abstract form, these are all tensor nets, since they are approximators over the space of the input range
15:57:59 <fog> we should be able to represent any function over numerically restricted hierarchical function implementations -  as nonlinear fits
15:58:43 <fog> so this MCT algo should be interpreted under some proceadure into this form
15:58:56 <fog> which it almost already is
16:00:37 <fog> but really to see the utility you would have to go for something other than a brute force classifier
16:00:48 <fog> you would want gradients at some point rather than just a score
16:01:51 <fog> and having a more intelligent search strategy is basically what your trying to derive - the best path
16:02:21 <fog> so i dont see why you wouldnt just eveolve the internal parameters of the classifer that acts as a descision taker at each step
16:02:43 <fog> which i dont know if its where its easierst to see how it fits in with descision forrests
16:03:15 <fog> but anyway, both this and the hierarchical mixture of experts were supposed to examplify the point about the algebra
16:03:27 <fog> the experts are just a weighted sum, so all just Num
16:04:28 <fog> and then if all your functions can be approximated, by such mixture of experts, then hierarchical function implementations are just function application and numerical opperations 
16:05:02 <fog> so within the Num algebra, function implementations are mixture of experts - or something like that
16:05:28 <fog> mixture of functions, or something
16:06:36 <fog> i like the idea of adding functiona application to the Num algebra
16:06:41 <monochrom> I use Monte Carlo to choose subjects to learn, then iterative deepening to learn it. :)
16:07:34 <fog> rejecting branches as you go! and getting your attention captured and sold... 
16:07:34 <koz_> Is there a way to have an Aeson Value show as the JSON it is?
16:07:43 <koz_> (in GHCi ideally)
16:08:12 <monochrom> After sufficient learning, a set of logic rules is dumped, and henceforth I use an expert system without those rules for applications. :)
16:08:23 <monochrom> err, with those rules!
16:08:24 <nshepperd2> study the textbook until your brain explodes, then come back later with a stronger skull
16:08:51 <monochrom> koz_: I think that's "encode" again?
16:09:02 <fog> well you just want to cover the space of approximators sparsely and effeciently 
16:09:25 <koz_> monochrom: You'd be right! Thanks.
16:10:02 <fog> you get learning acceleration when you take a path of increasing complexity, learning partially on each model to identify the region to choose the next more complex approximator from
16:10:06 <hpc> whenever i hear "expert system", i imagine the end of snowpiercer
16:10:18 <fog> you kind of learn really coarse grained low complexity nets first
16:10:26 <fog> and then step to closeby larger nets
16:11:20 <dmwit> shapr: yep
16:11:29 <fog> by first stepping to a larger net approximating the small net, and then flowing away along its extra params
16:11:39 <fog> to get closer to the objective function
16:11:56 <fog> stepping to more and more complex nets, proving universal approximation
16:12:06 <fog> ie, dense cover
16:12:08 <dmwit> shapr: I guess I didn't separate it out as its own library, though I'm not against doing that.
16:12:25 <dmwit> This file has the implementation of all the stuff that isn't Dr. Mario-specific:
16:12:28 <dmwit> https://github.com/dmwit/nurse-sveta/blob/master/src/Dr/Mario/Sveta/MCTS.hs
16:12:50 <fog> so we find that learning acceleration is inverse to iterative net compression 
16:13:05 <fog> reminiscent of Amari's em-EM algo 
16:13:44 <fog> which presents the learning path as morphisms to the terminal object under the learning action to the best approximator
16:14:08 <fog> i just add the monotonicity of the complexity of the parametric models
16:14:38 <fog> optimal compression path in one direction, optimal learning path in the other
16:15:15 <fog> not sure if this is anything like boosting algos or turbocoding
16:15:51 <fog> which is where you end up getting channel capacity 
16:16:15 <fog> if you could get compressed sensing from that, somehow into functional programming, that would be totally badass
16:16:33 <fog> hi shannon! 
16:16:46 <fog> i think its called information geometry 
16:17:20 <fog> but we need it in a categorical sense for lambda calculus 
16:19:41 <fog> optimal sensor placement on the space of functional programs 
16:22:47 <tonymclane_> hello noob here can anyone tell me why chomd command is being rejected? tonymclane@system76-pc:~/Desktop$ chomd
16:22:48 <tonymclane_> Command 'chomd' not found, did you mean:
16:22:48 <tonymclane_>   command 'chmod' from deb coreutils
16:22:48 <tonymclane_> Try: sudo apt install <deb name>
16:23:10 <koz_> tonymclane_: Uhh... this is #haskell. 
16:25:42 <d34df00d> But they could write chomd in haskell and it would run correctly as long as it is accepted by the type checker.
16:26:24 <fog> actually, all that is just one step away from quantization. 
16:26:35 <koz_> d34df00d: Lol.
16:26:41 <koz_> Whatever 'chomd' is.
16:26:53 <solonarv> I think it is just a misspelling of chmod
16:27:10 <koz_> solonarv: Yeah, likewise.
16:27:28 <fog> the compression process, smoothing out quantum fluctuations, when done optimally, to retain salient features, along the path of optimal renormalization
16:27:30 <solonarv> which of course the error message suggested, but when people see an error message they recoil in fear as their eyes glaze over
16:28:54 <fog> is sectioning, which for dynamical systems via hierarchical-Kam theory (on the errors) is sort of like a nonlinear deformation from a net
16:29:36 <fog> in hodge theory you get harmonic sectioning, where these are kind of recurrent distorted loop trajectories which you average away
16:30:05 <fog> but this would have functional programs being qunatized by some similar sectioning of a bundle
16:30:32 <fog> which you could think of as tensor network compression
16:30:53 <fog> but extended to exist in lambda calculus
16:32:14 <fog> so that an optimal learning trajectory to create a haskell program would descend in the opposite direction to this renormalization or compression 
16:32:44 <monochrom> Yes if you just say "please press enter" people will it, but if you say "please press enter, this is an error message" people just petrify.
16:32:46 <fog> filling in the quantum fluctuations hierarchically to better fit the approximated function 
16:33:06 <d34df00d> ERROR please press enter
16:34:48 <fog> these hierarchical emergent backgrounds arise from curvature tensors, "beyond the standard model", but we dont seem to have nice curved spaces of programs, so i dont know how your supposed to do quantum graity there...
16:34:54 <fog> gravity*
16:35:10 <fog> maybe information geometry again
16:35:22 <monochrom> fog: Are you done?
16:36:01 <fog> i didnt even get to string theory (stacks! of bundle sections or something)...
16:36:37 <fog> i want a unified theory of functional programming! 
16:37:40 <fog> i want fuzzy feynman scattering...
16:37:52 <monochrom> OK just cause.
16:37:54 --- mode: ChanServ set +o monochrom
16:37:56 --- mode: monochrom set +b *!*@gateway/web/cgi-irc/kiwiirc.com/ip.82.1.242.231
16:37:57 --- kick: fog was kicked by monochrom (fog)
16:38:41 --- mode: monochrom set -o monochrom
16:49:40 <koz_> This is slightly non-Haskell, but does someone know of an online source (in textual form) for last names?
16:49:47 <koz_> Like, a giant list of last names as a text file.
16:51:52 <monochrom> It may be very hard to obtain under privacy laws.
16:52:01 <koz_> monochrom: I don't need ones of specific people.
16:52:09 <koz_> Just a big list of 'last names that exist as such'.
16:52:55 <koz_> Like, this: https://hobbylark.com/writing/cool-last-names, but as a big text file.
16:53:24 <Axman6> ther's the fake package I think
16:53:28 <Axman6> there's*
16:53:30 <koz_> Axman6: Link?
16:53:54 <monochrom> https://hackage.haskell.org/package/fake
16:54:21 <koz_> monochrom and Axman6: Thanks, this is _ideal_.
16:55:16 --- mode: ChanServ set +o monochrom
16:55:36 --- mode: monochrom set -b+q *!*@gateway/web/cgi-irc/kiwiirc.com/ip.82.1.242.231 *!*@gateway/web/cgi-irc/kiwiirc.com/ip.82.1.242.231
16:55:40 --- mode: monochrom set -o monochrom
16:56:20 <dmwit> fake is neat
17:03:58 <shapr> dmwit: thanks!
17:06:24 <d34df00d> Hmm.
17:06:30 <d34df00d> Why can't I have my type in repl?
17:06:44 <d34df00d> `:t sequence @[] @(String, IO Int)` shows nothing.
17:07:17 <d34df00d> @ty sequence @[] @(String, IO Int)
17:07:19 <lambdabot> error: parse error on input ‘@’
17:07:24 <d34df00d> :(
17:07:34 <solonarv> lambdabot doesn't have TypeApplications
17:07:36 <solonarv> yahb does, though
17:07:51 <solonarv> % :t sequence @[] @(String, IO Int)
17:07:52 <yahb> solonarv: ; <interactive>:1:15: error:; * Expected kind `* -> *', but `(String, IO Int)' has kind `*'; * In the type `(String, IO Int)'; In the expression: sequence @[] @(String, IO Int)
17:08:19 <monochrom> I too get an error message like that. Not really nothing.
17:08:55 <monochrom> maybe different GHC version
17:09:03 <solonarv> I claim that this error message is to be expected.
17:09:03 <d34df00d> https://habrastorage.org/webt/co/hn/fk/cohnfkecudvs5pnmuoiypdq-he4.png
17:09:05 <d34df00d> 8.8.3 for me.
17:09:09 <solonarv> % :t +v sequence
17:09:09 <yahb> solonarv: (Traversable t, Monad m) => t (m a) -> m (t a)
17:09:14 <solonarv> one sec.
17:09:22 <solonarv> % :set -fprint-explicit-foralls
17:09:22 <yahb> solonarv: 
17:09:24 <solonarv> % :t +v sequence
17:09:24 <yahb> solonarv: forall (t :: * -> *) (m :: * -> *) a. (Traversable t, Monad m) => t (m a) -> m (t a)
17:09:27 <solonarv> aha!
17:09:36 <solonarv> now look at the order of the type variables.
17:10:20 <d34df00d> Hmm.
17:10:29 <d34df00d> How do I feed it with the monad instance for (a,)?
17:10:48 <monochrom> (,) String
17:10:52 <solonarv> you just type-apply it to ((,) String)
17:10:52 <d34df00d> It doesn't accept @(String,) even with TupleSections.
17:11:01 <d34df00d> Ah lol right.
17:11:05 <koz_> d34df00d: TupleSections doesn't work at the type level.
17:11:07 <d34df00d> Simplicity is key.
17:11:10 <solonarv> i.e. use the prefix form of the tuple constructor
17:11:14 <monochrom> TupleSection is probably for terms only.
17:11:20 <d34df00d> koz_: crap, I am an idiot, right.
17:11:45 <monochrom> Common disease of dependent typing fans.
17:12:25 <monochrom> Is your lambda prompt from emacs haskell-mode? It's know to eat error messages and give you silence.
17:12:37 <d34df00d> monochrom: nope, just a custom ghci
17:12:44 <d34df00d> .ghci that is.
17:13:34 <d34df00d> I usually get all other error messages I expect.
17:56:40 <infinisil> Functor is to Applicative what Contravariant is to ???
17:56:59 <solonarv> hmm
17:57:07 <solonarv> I vaguely recall seeing something like this
17:57:44 <glguy> http://hackage.haskell.org/package/contravariant-1.5.2/docs/Data-Functor-Contravariant-Divisible.html
17:57:55 <Axman6> @hoogle f (a -> b) -> f b -> f a
17:57:56 <lambdabot> No results found
17:58:04 <infinisil> Oh nice, thanks glguy!
17:58:20 <solonarv> the method names are cute
17:58:25 <solonarv> 'divide' and 'conquer'
18:01:42 <infinisil> Context: I'm just implementing some serializations for binary data using the store package
18:02:07 <infinisil> And I think having a Divisible instance for https://hackage.haskell.org/package/store-0.7.4/docs/Data-Store.html#t:Size would allow me to write one part much nicer
18:03:32 <infinisil> Not entirely sure yet if there's a sensible implementation though, I'll play around with it
18:04:42 * infinisil is pretty sure there is one now
18:19:38 <ddellacosta> is there a nicer/more lens-y way to write the modify line in this function? https://gist.github.com/ddellacosta/96c01425b15524258f8447d261642516
18:19:51 <ddellacosta> this is just for learning, not meant to be production code btw
18:20:35 <solonarv> of course: (\x -> x & foo) is the same thing as (foo)
18:21:07 <solonarv> so you can simplify this to: modify (accounts %~ insert newId acct)
18:21:31 <solonarv> but! lens has a bunch of handy MonadState operators too
18:21:33 <ddellacosta> solonarv: ah jeez it's so obvious when you write it
18:21:36 <ddellacosta> lol
18:21:45 <ddellacosta> I guess it's always that way when you're banging your head against something
18:22:01 <ddellacosta> yeah I was wondering if there's an alternative form of modify too
18:22:04 <solonarv> as a rule of thumb, for each operator that ends in a ~ (like %~) there is a corresponding MonadState-y operator that ends in = instead
18:22:06 <infinisil> Just found https://github.com/mgsloan/store/issues/118 :)
18:22:12 <solonarv> so in this case that would be %=
18:22:23 <solonarv> and that line becomes: accounts %= insert newId acct
18:22:36 <ddellacosta> aha!! _That's_ what I wanted
18:22:43 <ddellacosta> but I appreciate the first point too since I was just not seeing it
18:22:47 <ddellacosta> awesome, thanks solonarv 
18:22:49 <solonarv> as a bonus, you can combine the other two lines into one as well
18:22:56 <ddellacosta> oh!?
18:23:39 <solonarv> for each operator that modifies a lens' target (like +=) there is a corresponding operator that (also) returns the new value, which has an extra < at the start
18:23:49 <ddellacosta> aha
18:23:49 <solonarv> so: newId <- lastAccountId <+= 1
18:23:54 <ddellacosta> oh man this is gold
18:24:02 <solonarv> (there are also variants with a << at the front which return the *old* value)
18:24:06 <ddellacosta> gotcha
18:24:10 <ddellacosta> so much to learn
18:24:32 <solonarv> lens has a lot of operators, but as you can hopefully see from my descriptions here they form a sort of mini-language
18:25:52 <ddellacosta> yeah, I've started getting comfortable with them in other contexts, like all the variations on % for traversals and whatnot, but I'm just starting to dig into the monad stuff
18:26:13 <ddellacosta> it's overwhelming at first but the utility becomes obvious pretty quickly
18:28:56 <ddellacosta> solonarv: much improved, thanks https://gist.github.com/ddellacosta/96c01425b15524258f8447d261642516#gistcomment-3243353
18:35:10 <MarcelineVQ> overwhelming is a word, I really wouldn't mind if it had more examples pretty much all around
18:43:50 <p0a> Why does stack build always download stack?
18:43:57 <p0a> Isn't it inefficient to always download 180MB of data?
18:44:13 <Axman6> it definitely should not always be downloading it, it should only happen once
18:45:27 <oats> “haskell is pure, immutable-data-driven, functional language”
18:45:43 <oats> (lastAccountId += 1) :: MonadState DB m => m ()
18:45:46 <oats> WHERE IS YOUR GOD NOW
18:45:49 <p0a> Axman6: okay a system upgrade may have made it redownload it then
18:46:13 <MarcelineVQ> unless you're specifically building stack it would be strange to download stack due to typing stack build, as well
18:46:20 <sm[m]> or multiple stacks in your PATH ? type -a stack
18:46:37 <sm[m]> curious indeed
18:46:40 <p0a> as soon as my copmputer is functional again
18:46:44 <p0a> right now its laggy
18:46:58 <oats> ddellacosta: if you like, you can make it even more unreadable :D
18:47:32 <oats> createAccount = (lastAccountID <+= 1) >>= ((accounts %=) . flip insert acct)
18:47:46 <oats> except I missed the 'acct' bind :<
18:49:58 <ddellacosta> MarcelineVQ: definitely agree re: more examples
18:50:03 <ddellacosta> oats: thanks I think, lol
18:50:16 <oats> ddellacosta: no, do not thank me
18:50:19 <oats> and do not use that
18:50:20 <ddellacosta> hahaha
18:50:35 <ddellacosta> I hadn't planned on it, but it's useful as a mental exercise :-D
18:51:23 <p0a> So here's the output
18:52:30 <p0a> https://termbin.com/xnfi
18:53:06 <p0a> I dn't know why `stack build' is not there; I ran that after init
18:53:13 <p0a> Oh, it's there.
18:54:41 <p0a> under my .stack I have ghc-8.6.5 and 8.8.1
18:55:18 <sm[m]> p0a: it's downloading ghc, not stack. And it downloaded a different version for the second project, which seems to need the terminfo build. (Are you on crazy Arch ?)
18:55:45 <p0a> sm[m]: right, sorry I'm a bit foggy
18:55:51 <p0a> I'm on ubuntu 19.10
18:56:33 <sm[m]> np. Ok, I'm not sure why there's two variants of GHC 8.8.3 then
18:57:15 <sm[m]> the stack.yaml's of each project may give a clue
18:57:34 <sm[m]> if they both used the same resolver, maybe it'd use the same GHC
19:17:52 <crestfallen> http://ix.io/2h19   hi the type signature for mapMM is confusing me:
19:18:25 <crestfallen> the func returns an m [b]     and..
19:19:50 <crestfallen> so those functions ee and ff, they return lists, so since mapMM must return a nested list , i.e. m [b]     ?
19:20:56 <crestfallen> I'm trying to relate it to: m a -> (a -> m b) -> m b
19:21:45 <dmwit> Nothing in that code connects mapMM and either ee or ff.
19:22:25 <dmwit> Are you asking what would happen if you did, say, `mapMM ee` or similar?
19:23:03 <crestfallen> no mapMM ee [4,5] works fine
19:23:14 <dmwit> Okay. Then I don't understand the question yet.
19:23:19 <crestfallen> sorry...
19:23:43 <crestfallen> so with a monad we have      m a -> (a -> m b) -> m b
19:24:07 <dmwit> Okay.
19:24:08 <crestfallen> the input value in mapMM is a list [a]
19:24:25 <crestfallen> so the return value must be a nested list right?
19:24:32 <p0a> [m b] you mean?
19:24:33 <dmwit> ...no?
19:24:48 <dmwit> The type signature tells you what the return value is.
19:25:10 <dmwit> It can be a nested list, but it can be any other monad, too, provided the function you supply uses that other monad.
19:25:21 <crestfallen> it's like a pattern match. if you have the function first in the signature, then..
19:25:47 <crestfallen> you have the input [a], the function is matching the return type
19:26:06 <crestfallen> instead of  m a -> (a -> m b) -> m b
19:26:22 <dmwit> Look, (>>=) and mapMM are just different functions with different types.
19:27:11 <crestfallen> right but Monad m => tells us it has this inherently :  m a -> (a -> m b) -> m b
19:27:32 <dmwit> Monad m tells us we can use a function of that type, yes. But mapMM isn't that function.
19:27:50 <p0a> In my notes about stack I've written that in an empty project, executing `stack setup; stack build' should work
19:28:11 <p0a> however now `build' complains that `init' was not ran; after running `init', it complains the project contains no local packages 
19:28:17 <p0a> I'm a bit confused, are my notes wrong?
19:28:33 <dmwit> And there's no reason to believe that the type of mapMM should line up with the type of (>>=) in any interesting way, either. (Maybe it does! But it's not *forced* to just because we have a Monad constraint lying around.)
19:29:13 <dmwit> For example, I can easily write a function of type `Monad m => m Int -> Bool`, and that doesn't line up with the type `m a -> (a -> m b) -> m b` no-how.
19:29:51 <dmwit> So I think looking for connections between the type of `(>>=)` and the type of `mapMM` is more likely to confuse than enlighten.
19:32:02 <crestfallen> right dmwit thanks.. I was working on type unification a long time back. I was just trying to look at mapMM in terms of unification, because all the parts are there, with the function first (in this case returning a list monad) the input monad list [a], and the return monad, which is a (nested list) monad
19:32:50 <crestfallen> so it sort of blew my mind, that the return of mapMM ee is a nested list. 
19:33:43 <p0a> aaah I forgot `stack new' nevermind. I forgot the template
19:34:22 <crestfallen> it wasn't a matter of "what else could it be"? I was just trying to see (not recommended!) connections
19:35:51 <dmwit> Looking for connections is good and smart. I like that. But you've let the perceived connection drive your understanding instead of the other way around. =)
19:40:56 <crestfallen> dammit. sorry not sure if I missed posts due to disconnection
19:41:54 <p0a> no you're good
19:43:14 <crestfallen> p0a, thanks
19:44:30 <crestfallen> yeah dmwit >>= is more complicated because it's linking results to sequential functions. a list monad otoh is just a simple data structure, right?
19:44:56 <dmwit> er?
19:45:03 <dmwit> (>>=) is more complicated than what?
19:45:21 <dmwit> Many monads are "simple data structures".
19:45:30 <koz_> crestfallen: _Every_ monad has >>=. That's kinda what makes it a monad.
19:45:58 <dmwit> I don't know of any class of objects which makes "(>>=)" vs "lists" a sensible pair of things to compare.
19:46:33 <crestfallen> ok...
19:47:57 <crestfallen> so in kleisli composition, would we have mapMM as [a] -> (a -> m b) -> m [b]   ?
19:49:00 <dmwit> "I am not able rightly to apprehend the kind of confusion of ideas that could provoke such a question." -- Babbage
19:49:36 <crestfallen> I followed a tutorial where it was (>=>) = flip (.)
19:50:24 <crestfallen> precisely:  (|>) :: (a -> b) -> (b -> c) -> (a -> c); (|>) = flip (.)
19:50:49 <crestfallen> so I think that was part of my confusion with mapMM
19:52:02 <dmwit> Okay. I don't understand why that would make mapMM confusing, since it appears to be completely unrelated to mapMM to me. But I'm willing to take your word for it.
19:53:08 <crestfallen> thanks a lot I'll just be content for now. pax
20:30:23 <stretchp> forgive my newbie questions but I am wandering how is this overcomplicated. Anyone care to explain? https://pastebin.com/dH7pcwBe
20:34:10 <lyxia> isEven n = (n `mod` 2) == 0
20:34:40 <Axman6> read it out in english: if n mod 2 is zero is trye then return true, otherwise (if n mod 2 is zero is False) return False
20:34:48 <Axman6> True*
20:38:42 <Axman6> you're essentially saying if x is true return true otherwise if x is false return false, which is the same as if x is true return x otherwise if x is false return x
20:41:42 <dsal> @src even
20:41:42 <lambdabot> even n = n `rem` 2 == 0
20:59:33 <stretchp> is there a haskell tutorial that i can follow that have working examples? Instead of me trying to follow alone and trying to figure out why the examples don't work?
21:06:25 * hackage dobutokO2 0.24.4.0 - A program and a library to create experimental music from a mono audio and a Ukrainian text  https://hackage.haskell.org/package/dobutokO2-0.24.4.0 (OleksandrZhabenko)
21:11:42 <ActinalW_> I'm just learning but I like this class: https://www.seas.upenn.edu/~cis194/fall16/index.html. It has solutions for all the homeworks which include building a working game.
21:22:10 <ActinalW_> I was recently confused by some functions using type aliases like this https://pastebin.com/J20r2xEQ. I think I now understand why those 'char' definitions are valid, and why a definition like 'char c1 i1 i2 c2 i3 i4 = c2' isn't allowed, but is there an easy way to get information about what params each type are matching without working through the aliases by hand?
21:39:18 <dmwit> Not really, no.
21:39:24 <dmwit> Kind of unfortunate.
21:39:37 <solonarv> actually I think there is a way to make ghci expand type synonyms
21:39:41 <solonarv> % :type words
21:39:41 <yahb> solonarv: String -> [String]
21:39:47 <solonarv> % :type! words
21:39:47 <yahb> solonarv: unknown command ':type!'; use :? for help.
21:39:51 <solonarv> hm, nope
21:39:59 <dmwit> You would think :kind! would do it, but it only expands type families, not type aliases.
21:40:08 <dmwit> Like I said: kind of unfortunate.
21:40:14 <dmwit> I've wished for this feature in the past as well.
21:42:49 <glguy> Prelude> type family Expand (x :: k) :: k where Expand (f x) = Expand f (Expand x); Expand x = x
21:42:49 <glguy> Prelude> :kind! Expand String
21:42:49 <glguy> Expand String :: * = [Char]
21:43:06 <glguy> (yes, that's a hack that's sure to only work on the simplest examples)
21:46:34 <dmwit> oh my glob
21:49:11 <dmwit> Well, thanks! =D
21:57:12 <ActinalW_> yes, thank you. seeing 'Expand Picture :: * = (Int -> Int -> Char) -> Int -> Int -> Char' definitely would have made it more intuitive for me
22:23:36 <jluttine> how can i list what some module Foo exports? that is, i'd like to know what gets into scope when i do `import Foo`
22:24:12 <d34df00d> What I usually do is type `:m + Foo` in ghci and then type `Foo.` and hit tab.
22:25:02 <dsal> I never use :m...  does it do anything special?
22:28:00 <Axman6> jluttine: a hacky way is to do this in ghci: import qualified Foo\n :t Foo.<tab>
22:28:18 <Axman6> there's also :browse in GHCi
22:32:26 <siraben> Anyone have advice on how to layer Cont and Except?
22:33:23 <siraben> I want write an interpreter that can access its continuations via call/cc but also fail (e.g applying 1 to "foo"),
22:33:28 <siraben> want to*
22:34:06 <jluttine> d34df00d Axman6: ok, thanks!
22:39:02 <jluttine> how can i check the version of a haskell package i've installed?
22:39:22 <dsal> How did you install it?
22:39:34 <jluttine> with nix
22:39:50 <jluttine> i have cabal file and then i ran nix-shell
22:40:23 <jluttine> but just wondering if there's some ghci magic that let's me check the version
22:40:29 <dsal> Hmm...  I don't know how that one in particular works.
22:42:20 <Axman6> ghc-pkg list or something?
22:42:31 <jluttine> ah, well, i realised why nothing worked as expected.. i was using dbus library but was reading the documentation of d-bus library.. :)
22:43:04 <wrunt> ghc-pkg field <packagename> version
22:44:01 <wrunt> from within your nix-shell
22:44:22 <jluttine> wrunt: yes, thanks!!
22:45:01 <wrunt> np :)
22:56:25 * hackage hslua-module-doclayout 0.1.0 - Lua module wrapping Text.DocLayout.  https://hackage.haskell.org/package/hslua-module-doclayout-0.1.0 (tarleb)
23:36:19 <pounce> im getting an "error in array index" error in ghc
23:36:25 <pounce> how can i have it print out the index/do a backtrace
23:54:15 <tdammers> does anyone know how to inspect a WAI request body without "consuming" it? I'm trying to look at POST variables in a Middleware, but doing this requires parsing the body, and that causes Scotty to fail parsing the body itself down the road
23:57:32 <tdammers> I think it's because `requestBody` is internally :: IO ByteString, and Warp will stream it directly from the network rather than buffer it in memory, so you can only get it once
23:58:29 <tdammers> I could modify the request before passing it down the middleware chain, but that would require access to the internal Request data structure
