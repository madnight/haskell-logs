01:44:53 --- topic: 'https://www.haskell.org | https://wiki.haskell.org/IRC_channel | Paste code/errors: https://gist.github.com/ | Logs: http://tunes.org/~nef/logs/haskell/?C=M;O=D | https://www.reddit.com/r/haskell | Admin: #haskell-ops | Offtopic: #haskell-offtopic | https://downloads.haskell.org | Survey 2020: https://haskellweekly.news/survey/2020.html'
01:44:53 --- topic: set by monochrom on [Sun Nov 01 11:31:39 2020]
01:44:56 <boxscape> the inferred kind seems to be the same one I gave it
01:45:04 <boxscape> why does it result in an error without type sig?
01:45:06 <boxscape> (kind sig)
01:45:44 <boxscape> ohh wait
01:45:53 <boxscape> is the Refl call changing the inferred kind
01:47:03 <idnar> jophish: last time I tried to use it, I got segfaults
01:49:16 <idnar> @type \f x -> traverse_ f =<< x
01:49:17 <lambdabot> (Monad m, Foldable t) => (a -> m b) -> m (t a) -> m ()
01:49:32 <idnar> ADG1089: ^
01:49:56 <ADG1089> Thansk!!
02:07:52 * hackage jsonifier 0.1.0.5 - Fast and simple JSON encoding toolkit  https://hackage.haskell.org/package/jsonifier-0.1.0.5 (NikitaVolkov)
02:27:15 <nerded> hi guys
02:27:51 <Zetagon> Hello
02:36:59 <jophish> idnar: cool, thanks
02:46:23 <bgamari> jophish, frankly I would need to check
02:46:32 <bgamari> jophish, it was a long time ago that I wrote that
02:46:38 <bgamari> and I had very particular needs
02:49:01 <dminuoso> What's the motivation behind: data :~: where Refl :: a :~: a
02:49:12 <dminuoso> Err
02:49:22 <dminuoso> data a :~: b where Refl :: a :~: a
02:49:36 <Franciman> Hi, does happy have some functionality for writing pratt parsers?
02:49:46 <dminuoso> I keep staring at this, not quite understanding how this works or what this is for.
02:50:47 <Franciman> dminuoso, the motivation is that you can say that two things are the same, when they are the same
02:50:48 <Franciman> :P
02:51:09 <Franciman> so that you surely want to conclude a = a
02:52:15 <kuribas> I am wondering, would namedFieldPuns be prefered over RecordWildCards?
02:52:19 <dminuoso> Does GHC bury a (a ~ b) into the GADT?
02:52:42 <kuribas> RecordWildCards add hidden fields to the namespace, but namedFieldPuns make them visible.
02:52:43 <dminuoso> % import Data.Type.Equality
02:52:44 <yahb> dminuoso: 
02:52:49 <dminuoso> % :t Refl
02:52:49 <yahb> dminuoso: forall k (a :: k). a :~: a
02:52:58 <boxscape> dminuoso as far as I know it does
02:53:00 <boxscape> or wait
02:53:06 <boxscape> I thought you wrote a ~ a
02:53:25 <boxscape> Oh nevermind
02:53:33 <boxscape> a ~ a wouldn't  make sense
02:53:43 <dminuoso> Well, a ~ a necessarily holds true, no?
02:53:47 <boxscape> so yes, as far as I know it does put a ~ b into the GADT
02:53:54 <boxscape> dminuoso right, that's what I meant
02:54:17 <dminuoso> The above type signature seems strange, Id have expected it to we
02:54:38 <dminuoso> Refl :: forall a b. (a ~ b) => a :~: b
02:54:44 <dminuoso> (ignoring the PolyKinds noise)
02:55:07 <boxscape> % :t undefined :: forall a b . (a ~ b) => a :~: b
02:55:08 <yahb> boxscape: forall k (b :: k). b :~: b
02:55:15 <boxscape> dminuoso same thing
02:57:30 <dminuoso> So Refl is just a reified ~ constraint?
02:57:40 <boxscape> yes
02:58:22 <dminuoso> im genuinely curious what this could be used for then
02:59:36 <boxscape> dminuoso to show that things are equal, for example, if you had data Nat = Z | S Nat, and defined plus for it, you could have plus_comm :: forall (n :: Nat) (m :: Nat) . Plus n m :~: Plus m n
02:59:53 <boxscape> and the proof would contain 2 or 3 Refls
03:00:34 <dminuoso> 2 or 3 Refls?
03:01:57 <boxscape> as in, the Refl constructor would appear in the proof two or three times - as the base case for the induction (though actually you need to add singleton arguments here I think to match on)
03:03:40 <boxscape> so if you also had data SNat :: Nat -> Type where SZ :: SNat Z | SS :: SNat n -> SNat (S n), i.e. the singleton type for Nat, you could have plus_comm :: SNat n -> SNat m -> Plus n m :~: Plus m n, and then the first equation, the inductive base case, could be plus_comm SZ n = Refl
03:04:21 <boxscape> assuming Plus is defined as type family Plus n m where Plus Z m = m; Plus (S n) m = S (Plus n m)
03:08:52 * hackage hadolint 1.19.0 - Dockerfile Linter JavaScript API  https://hackage.haskell.org/package/hadolint-1.19.0 (lorenzo)
03:09:08 <zyklotomic> soft question here, is there a reason behind the ". . . $" style? I think it's part of "point-free" style? but I might be wrong
03:09:39 <boxscape> (technically that base case isn't quite correct but let me write up the example real quick)
03:10:01 <zyklotomic> like just now, I wrote something like `drop 1 . foldl' f [a, start] $ xs`, but I honenstly find this style more difficult to read than `drop 1 $ foldl' f [a, start] $ xs` 
03:10:53 <zyklotomic> * in the second one, the second $ was a typo / extraneous
03:13:24 <dminuoso> zyklotomic: It's personal taste, some people like: . . . $, others prefer (. . .) (. . .), and there's other styles too
03:14:11 <dminuoso> I tend to avoid ($) generally except for do blocks/lambdas (cant get myself to enable BlockArguments)
03:15:48 <dminuoso> In my opinion it's good to use function composition and parens. It gives you a better view on code structure
03:15:50 <kuribas> dminuoso: so do you write (f . g . h) x then?
03:16:25 <dminuoso> kuribas: Generally I favor `... f x where f = g . h . i`
03:16:48 * kuribas wonders if he writes everything infix his lisp colleages will like haskell more...
03:16:50 <dminuoso> but `f (g (h x))` is not bad either
03:16:57 * kuribas means prefix
03:17:06 <dminuoso> It's somewhat situational
03:17:11 <kuribas> dminuoso: lispers agree :)
03:17:17 <kuribas> dminuoso: but clojurers not
03:17:34 <zyklotomic> ah i see
03:17:37 <zyklotomic> thanks for sharing
03:17:50 <zyklotomic> i've been generally writing (f . g . h) x too
03:17:59 <zyklotomic> and $ felt a bit unnatural at first
03:18:16 <kuribas> clojurers write (-> x h g f).  IMO it's strictly worse than ($) or (.), as it is a syntactic, rather than semantic construct.
03:18:53 <dminuoso> zyklotomic: Using function composition brings functions as first class objects more into view
03:19:05 <dminuoso> Say `fmap (f . g) ...`
03:19:14 <kuribas> zyklotomic: I think the reasoning behidn . . . $ is that if you remove the last argument it still works.
03:19:36 <dminuoso> (You could call this "point-free", but often its useful to think of functions as pipelines you can just compose to do more complex things)
03:19:37 <boxscape> dminuoso Refl example: https://gist.github.com/JakobBruenker/38251269a93cdd1f4979b771e613f4e6
03:19:40 <kuribas> zyklotomic: f x = g . h $ x => f = g . h
03:19:42 <zyklotomic> yeah, i do `fmap (f . g)` too
03:20:06 <zyklotomic> like the other pattern i've seen that parallels this, is f <*> g <$> h
03:20:09 <kuribas> zyklotomic: but with f x = g $ h $ x you have to replace all the ($)'s
03:20:12 <zyklotomic> which well it does make sense
03:20:40 <boxscape> dminuoso in the pattern guards the equality constraint is extracted
03:20:47 <dminuoso> zyklotomic: If you explore this much, there's some pretty cool tricks
03:20:53 <kuribas> zyklotomic: in the end it's your own preference
03:20:56 <dminuoso> Personally Im a big fan of foldMap for example
03:21:08 <zyklotomic> dminuoso: wait, I finally see exactly what you mean about the last argument now
03:21:15 <zyklotomic> I never came upon that realization
03:21:36 <dminuoso> % getSum . foldMap Sum $ [1,2,3,4] :: Integer
03:21:36 <yahb> dminuoso: 10
03:21:36 <zyklotomic> it was always trying to work out the order of operations/priority of the operetors idk what it's called
03:21:41 <zyklotomic> precedence?
03:22:05 <zyklotomic> like the PEMDAS of operators, i'm not sure what to calli t
03:22:28 <dminuoso> boxscape: Okay, so Im staring at this, my head is not quite ready to be contorted. 
03:22:38 <dminuoso> Superficially, I can read it and understand what this is doing
03:22:45 <dminuoso> But not quite why this works inductively
03:23:02 <dminuoso> Is this essentially a theorem prover like coq in action?
03:23:22 <boxscape> dminuoso yes, the main difference being that we can't be sure they're actually proofs because the totality checker is missing
03:23:37 <boxscape> (though if a proof terminates successfully for an input, you've proven it for that input)
03:23:43 <dminuoso> boxscape: Oh you mean because I can just sneak `undefined` in at any point to prove whatever?
03:23:46 <boxscape> right
03:24:17 <kuribas> dminuoso: how is that better than foldr (+) 0 [1, 2, 3, 4] ?
03:24:45 <dminuoso> kuribas: Sum carries monoid laws implictly
03:24:54 <boxscape> dminuoso tbh these kinds of proofs are a lot easier to understand while writing than while reading, because you can look at the hole types along the way
03:24:56 <dminuoso> with foldr you cant reason about laws
03:25:23 <dminuoso> say, will `foldr (+) 0 [1,2,3,4]` and `foldl (+) 0 [1,2,3,4]` do the same thing?
03:25:34 <dminuoso> Dunno really
03:26:06 <dminuoso> I mean for this case I can of course tell, but the associativity and identity is not clearly communicated, and it's extra verbose
03:26:11 <kuribas> dminuoso: depends on the Num instance
03:26:22 <dminuoso> kuribas: Im just very fond of traverse and foldMap
03:26:31 <boxscape> for example `plus_Z (SS n) = _` has hole type `'S (Plus n1 'Z) :~: 'S n1`, so we can call plus_Z n recursively and match on that to get out the `Plus n1 Z ~ n1` constraint, and then we just have to make something of type `S n1 :~: S n1`, which is Refl
03:26:31 <kuribas> also foldMap Sum is very ineffecient
03:26:42 <kuribas> it's too lazy
03:27:08 <dminuoso> Often efficiency is not a problem I need, expressivity is more important to me :)
03:27:23 <dminuoso> Consider this trick to implement traverse:
03:27:26 <kuribas> I prefer both
03:27:42 <kuribas> I mean efficiency and expressivity are not necessary mutually exclusive
03:27:52 <dminuoso> % ala ZipList traverse [[1,2,3],[10,20,30],[100,200,300]]
03:27:52 <yahb> dminuoso: ; <interactive>:32:1: warning: [-Wtype-defaults]; * Defaulting the following constraints to type `Integer'; (Show b0) arising from a use of `print' at <interactive>:32:1-55; (Num b0) arising from a use of `it' at <interactive>:32:1-55; * In a stmt of an interactive GHCi command: print it; [[1,10,100],[2,20,200],[3,30,300]]
03:28:02 <dminuoso> % ala ZipList traverse [[1,2,3],[10,20,30],[100,200,300]] :: [[Integer]]
03:28:02 <yahb> dminuoso: [[1,10,100],[2,20,200],[3,30,300]]
03:28:24 <dminuoso> Can't deny there's a certain beauty of both foldMap and traverse :)
03:29:01 <dminuoso> kuribas: Also, we have foldMap' now :p
03:29:29 <dminuoso> % ala Product foldMap [1,2,3,4]
03:29:29 <yahb> dminuoso: ; <interactive>:34:1: warning: [-Wtype-defaults]; * Defaulting the following constraints to type `Integer'; (Show a0) arising from a use of `print' at <interactive>:34:1-29; (Num a0) arising from a use of `it' at <interactive>:34:1-29; * In a stmt of an interactive GHCi command: print it; 24
03:29:50 <dminuoso> % ala Product foldMap [1,2,3,4]
03:29:50 <yahb> dminuoso: 24
03:29:53 <kuribas> foldMap' evaluated from left?
03:30:07 <dminuoso>     foldMap' f = foldl' (\ acc a -> acc <> f a) mempty
03:30:15 <dminuoso>     foldMap f = foldr (mappend . f) mempty
03:30:18 <kuribas> ah cool
03:30:42 <nshepperd> i presume foldMap' is strictly evaluated in whatever direction makes most sense for the type?
03:31:14 <kuribas> nshepperd: is that even possible?
03:31:28 <kuribas> nshepperd: ah by type you mean the foldable?
03:31:43 <nshepperd> ie. foldl' for lists, foldr' for snoc lists
03:31:46 <nshepperd> yeah
03:36:53 <dminuoso> what is a snoc list?
03:37:26 <pjb> A list from the end?  
03:37:46 <dminuoso> And that is different from a list... how?
03:38:16 <boxscape> I guess it's different in that foldl has been renamed to foldr and vice versa?
03:38:58 <dminuoso> boxscape: How's that?
03:39:09 <dminuoso> The difference between foldl and foldr is not the order of the lits
03:39:41 <dminuoso> It's how the function we replace the cons with associates
03:40:01 <boxscape> dminuoso I know, but for that you need to have some mental image of what left and right means in a list, right?
03:40:20 <boxscape> which isn't fundamentally part of the type
03:40:38 <kuribas> (a <> (b <> (c <> d))) should be the same as (((a <> b) <> c) <> d)
03:40:47 <kuribas> but one may be more efficient to calculate
03:40:56 <boxscape> so if you swap directions of that mental image, you rename foldr to foldl and foldl to foldr, and perhaps write the constructor as [a] : a, and I imagine that's what a snoc list would be
03:41:00 <boxscape> functionally the same as a list
03:41:18 <dminuoso> Ill await nshepperd's response. :)
03:41:21 <dminuoso> To clarify
03:41:22 <boxscape> that's fair
03:41:23 <kuribas> > foldMap' (<>) [a, b, c, d]
03:41:25 <lambdabot>  <Expr -> Expr>
03:41:46 <kuribas> > foldMap' Sum [a, b, c, d]
03:41:48 <lambdabot>  Sum {getSum = 0 + a + b + c + d}
03:41:52 <kuribas> > foldMap Sum [a, b, c, d]
03:41:54 <lambdabot>  Sum {getSum = a + (b + (c + (d + 0)))}
03:42:13 <dminuoso> kuribas: The difference matters in two respects: Is the input data structure infinite, and do we need to be lazy on the output (do we build a chain of data constructors)
03:42:40 <kuribas> those aren't the same value
03:42:46 <kuribas> are they?
03:43:21 <kuribas> ah they are since 0 is the empty element
03:43:42 <dminuoso> kuribas: by monoid laws they are the same
03:44:03 <dminuoso> because precisely, a monoid is associative (so it doesnt matter how they associate) and mempty is the identity element (it doesnt matter where you slap it onto)
03:45:09 <dminuoso> Guess that's the sort of things that makes foldMap so cool. You can just replace it with foldMap' without worrying whether it changes its meaning
03:45:17 <dminuoso> with foldr/foldl
03:45:29 <dminuoso> you have to manually check for associativity and identity
03:47:27 <boxscape> hmm I wonder if a monoid with separate left and right identity elements could be useful
03:47:53 <tomjaguarpaw> If you had left and right identities el and er what would el <> er be?
03:49:15 <boxscape> that's a very good question
03:49:39 <boxscape> I guess it wouldn't be useful then
03:50:55 <kuribas> dminuoso: it does change meaning wrt bottom
03:51:10 <boxscape> Although, I guess you could have a (not-quite-)monoid that *only* has left identity (or only right-identity)
03:51:44 <kuribas> > foldMap First [1, 2, undefined]
03:51:46 <lambdabot>  error:
03:51:46 <lambdabot>      • No instance for (Num (Maybe ())) arising from a use of ‘e_112’
03:51:46 <lambdabot>      • In the expression: e_112
03:52:13 <nshepperd> yeah a snoc list is just a cons list that has had left and right renamed
03:53:26 <kuribas> > foldMap First [Just 1, Just 2, undefined]
03:53:28 <lambdabot>  First {getFirst = Just 1}
03:53:34 <kuribas> > foldMap' First [Just 1, Just 2, undefined]
03:53:37 <lambdabot>  First {getFirst = Just 1}
03:54:10 <nshepperd> you won't often find them in the wild
03:54:58 <kuribas> > foldMap All [True, False, undefined]
03:55:00 <lambdabot>  All {getAll = False}
03:55:03 <kuribas> > foldMap' All [True, False, undefined]
03:55:05 <lambdabot>  All {getAll = False}
03:55:11 <kuribas> hmmm
03:55:58 <dminuoso> nshepperd: That sounds.. like a list.
03:56:26 <nshepperd> well yeah
03:57:00 <nshepperd> you can just do things with lists, and remember to reverse things in your head when reading code
03:57:53 <nshepperd> but sometimes it's easier to have a different type so that the syntax corresponds to the intended ordering
03:58:18 <dminuoso> So roughly a `data Tsil a = Snoc a (Tsil a) | Lin` differs from [] by conceptually reversing before folding/traversing?
03:58:37 <dminuoso> (or in case of traverse, revere, traverse, and then reverse again)
03:58:38 <kuribas> they are the same even with bottom then?
03:59:36 <boxscape> the list matches the intended left right order better with Snoc (Tsil a) a: Lin `SNoc` 3 `Snoc` 2 `Snoc` 1
03:59:39 <nshepperd> generally you write SnocList a = Nil | Snoc (SnocList a) a
04:00:10 <dminuoso> Why not just use Dual?
04:00:33 <nshepperd> performance
04:00:45 <dminuoso> Mmm, fair
04:00:56 <nshepperd> also, pattern matching
04:01:18 <dminuoso> boxscape: Ill take a look at your gist later tonight, think I need to sit down and employ the good ol' fashioned Feynman algorithm
04:01:40 <dminuoso> nshepperd: well, the pattern matching is a mood argument, since it's no different from (:)
04:02:06 <nshepperd> nooo
04:02:20 <dminuoso> Whether you write `1:2:3:[]` or `[]:%3:%2:%1` seems no different at all
04:02:29 <nshepperd> i mean, you can't use Dual when you're doing type level lists
04:02:32 <dminuoso> ah
04:04:04 <boxscape> dminuoso In a way I think these proofs are even harder to understand in Haskell than in some other languages, because the way constraint resolution makes it so it's not obvious how things are actually plugged together (though at least these are small proofs). But replacing the rhss with typed holes should help.
04:04:20 <boxscape> s/the way//
04:04:55 <kuribas> I find myself going back from typed holes to tuples
04:05:10 <kuribas> the error message is much better
04:05:29 <__monty__> Do you mean unit?
04:05:35 <kuribas> __monty__: yes
04:05:59 <kuribas> my-fun = () $ partial-implementation
04:06:34 <__monty__> That does change how associativity is parsed, no?
04:07:04 <boxscape> oh huh
04:07:07 <dminuoso> boxscape: Btw, I think there's a mistake in your proof
04:07:10 <boxscape> the error message is better, you're right
04:07:12 <boxscape> dminuoso oh?
04:07:15 <dminuoso> boxscape: plus_Z :: SNat n -> Plus n Z :~: n
04:07:20 <dminuoso> boxscape: Think you mixed up the order to Plus there
04:07:36 <dminuoso> The identity is only on one side in the tyfam
04:07:48 <dminuoso> Or am I confusing things?
04:08:08 <boxscape> dminuoso the identity of Plus Z n = n is trivial, but I have to write this proof to convince ghc that the other direction works, too
04:08:55 <dminuoso> boxscape: Ohh, so `plus_Z SZ = Refl` gives us `Plus Z Z ~ Z` for the base case
04:09:03 <boxscape> right
04:09:13 <dminuoso> (Which evalutaes to Z ~ Z, dischargable because every type is automatically equal to itself)
04:09:21 <dminuoso> So we dont need to provide proof ofZ ~ Z
04:09:57 <boxscape> I would hope that if there were a mistake ghc would have caught it, otherwise there'd be a bug in ghc (or in my copy-paste abilites)
04:10:37 <boxscape> uh, assuming it's not the sort of mistake that makes a proof non-total
04:10:56 <dminuoso> plus_Z (SS n) | Refl <- plus_Z n = Refl
04:11:06 <dminuoso> How does this inductive step work exaclty from the constraint solvers point of view?
04:13:39 <boxscape> so, if you write plus_Z (SS n), what you have to solve is 'S (Plus n 'Z) :~: 'S n. plus_Z n has type (Plus n Z) :~: n, so by matching on that, we can unify Plus n Z with n, and we have to solve S n :~: S n
04:13:54 <boxscape> and Refl is a value with that type, so we can just write Refl
04:14:01 <boxscape> dminuoso
04:14:37 <dminuoso> "what you have to solve is 'S (Plus n 'Z) :~: 'S n"
04:14:49 <dminuoso> do you mean `S (Plus n 'Z) ~ 'S`?
04:15:28 <boxscape> hmm I don't think I do. S by itself isn't a natural number, but S (Plus n Z) is a natural number, so that appears to be a kind error.
04:15:38 <dminuoso> err
04:16:39 <boxscape> ah but
04:16:45 <boxscape> I should have used a different letter
04:16:54 <dminuoso> boxscape: Sorry I think I cut off a quote there. We want to produce a value of type: 'S (Plus n 'Z) :~: 'S n
04:16:54 <boxscape> like S (Plus m 'Z) :~: 'S m
04:17:04 <dminuoso> So we use the data constructor Refl. That requires us to solve for a constraint
04:17:12 <dminuoso>  'S (Plus n 'Z) ~ 'S n
04:17:48 <boxscape> Ah, fair. What I meant by "solve" was "we have to write a value of that type on the rhs", but the terminology was a bit off, I admit
04:18:21 <dminuoso> The pattern matching `Refl <- plus_Z n` uncovers the dictionary for the proof of the inductive hypothesis
04:18:29 <boxscape> right
04:18:52 <dminuoso> And from that we can show that (Plus n 'Z) ~ n
04:18:58 <dminuoso> (or GHC can)
04:19:05 <dminuoso> Thus leading us to conclude that
04:19:13 <dminuoso> 'S n ~ 'S n
04:19:30 <boxscape> yeah, that sounds right
04:19:30 <dminuoso> which is what Refl demands
04:19:40 <dminuoso> mmm okay
04:20:24 <dminuoso> So the value here of :~: is that we can have it in *positive* position, such that things can *produce* proofs of this
04:20:34 <dminuoso> Whereas with => its, in effect, in negative position
04:20:46 <boxscape> right
04:23:13 <dminuoso> actually I missed one step!
04:23:20 <dminuoso> 13:18:42     dminuoso | Thus leading us to conclude that
04:23:38 <dminuoso> This requires injectivity of 'S
04:23:58 <dminuoso> Or.. mmm
04:24:10 <boxscape> I think any function would do
04:24:25 <boxscape> going the other way around would though
04:24:41 <dminuoso> I should really reimplement the type system myself to get an idea
04:25:09 <dminuoso> It's a bit mysterous what we can do with this though
04:25:39 <dminuoso> Surely the value is not to prove commutativity of peano naturals to ourselves, using GHC.
04:26:06 <boxscape> dminuoso the value is in using this proof for value level functions, let me see if I can think of a good example
04:28:38 <boxscape> dminuoso hmm for example you could use it to prove things about other value level functions, like if you wanted to prove that (<>) :: Vec n a -> Vec m a -> Vec (Plus n m) a is associative, you would need associativity of Plus first
04:29:36 <boxscape> dminuoso but it can also be useful for writing some regular type-level functions with complex types without explicitly trying to prove something about them, can't quite think of an example of that right now though
04:30:25 <dminuoso> boxscape: Well but whats the value of *proving* this to GHC?
04:30:39 <dminuoso> I mean providing a proof seems only useful if there's something demanding that proof
04:31:10 <__monty__> Certified libraries?
04:31:17 <boxscape> Right, that's what I meant with the example I can't think of right now :)  Though I would say a proof is also useful to convice yourself that the function you wrote is correct
04:33:02 <boxscape> dminuoso also when I wrote "regular type-level functions" I mean "regular value-level functions"
04:37:49 <p0a> Hello why is this happening to `stack ghci' in every new stack project of mine? https://pastebin.com/SHVA1zET
04:39:30 <__monty__> p0a: Looks like the same filename in a lib and an executable? Not sure why it's a problem though.
04:39:48 <__monty__> Is the fully qualified name identical?
04:40:09 <p0a> I don't know how to check whta you're asking me __monty__ 
04:40:20 <merijn> Who was asking about languages for low level/embedded stuff yesterday? I realised I forgot to mention a totally obvious candidate..
04:40:43 <p0a> __monty__: what lib has the same filename as an executable?
04:41:02 <p0a> merijn: texasny-something I believe
04:41:16 <__monty__> p0a: Paths_read_binfiles
04:41:50 <__monty__> I think the problem is the module identifiers are identical and GHC doesn't know which one to pick.
04:41:51 <p0a> __monty__: I don't know if it's a problem but `stack ghci' has some weird modules loaded 
04:41:58 <p0a> who decided on these names __monty__ ?
04:42:09 <__monty__> Don't know.
04:42:30 <__monty__> @hackage read-binfiles
04:42:30 <lambdabot> https://hackage.haskell.org/package/read-binfiles
04:42:32 <merijn> Paths_ modules are autogenerated by Cabal to access datafiles
04:42:41 <p0a> It happens to all my new projects __monty__ 
04:43:35 <merijn> Make an issue on the stack github? Presumably they'll know how to debug what's going on
04:43:52 <p0a> ok wanted to make sure it's not something obvious 
04:46:11 <merijn> It might be, but I don't use stack, so who knows :p
04:48:21 <boxscape> dminuoso I ran into an example yesterday where I did need a proof, though not an equality proof, and it was on the type level, but I think should work equally well on the value level: Let's say you have an ordered list, where the cons constructor carries a proof that a cons'd element is less than the next element in the list (thus making sure it
04:48:22 <boxscape> actually is ordered). If you want to delete an element in that list, you'll need a proof that less-than is transitive, as e.g. if you have [a,b,c] and want to delete b, you'll need to somehow construct a proof that a<c to get a new ordered list
04:49:18 <dminuoso> Makes sense
04:49:40 <dminuoso> So providing this proof is just to be able to re-construct this provably ordered list after the operation
04:49:46 <boxscape> right
04:50:01 <dminuoso> And the value is, you have some provable assurance the ordering is preserved by all operations
04:50:08 <boxscape> yes
04:50:46 <dminuoso> (in the absence of shortcircuiting the proof with bottom, of course)
04:51:07 <boxscape> right, though at least you can be sure that if your program *does* produce a result, it's a correct result
04:51:30 <dminuoso> well that depends though, if the proof of transitivity is just bottom.. ?
04:51:36 <dminuoso> It has to be runnable code
04:51:43 <Boomerang> We use Refl very often at work when writing circuits in Clash. Clash uses type level Nat everywhere, it's often useful to choose which sub-circuit to use depending on the type
04:52:22 <boxscape> right, it's still run to construct the actual proof object. Richard Eisenberg actually suggested in his thesis to replace equality proofs with unsafeCoerce Refl via a rewrite rule if you're sure they're total, for performance's sake
04:53:46 <dminuoso> Ah right, because Refl still has a runtime representation
04:53:53 <boxscape> yeah
04:59:45 <boxscape> (Though you can't do this unsafeCoerce stuff with all proofs, because for less-than for example, proofs will typically have different run-time reprenentations depending on how large the difference between the two values is, at least for comparing data Nat = S Nat | Z)
05:02:22 <boxscape> (that is, data (<) :: Nat -> Nat -> Type where ZltS :: Z < (S n); SltS :: n < m -> (S n) < (S m), so for example SltS (SltS (ZltS) :: 2 < 5)
05:02:41 <boxscape> (I guess what matters there is actually the size of the first value, not the difference between them)
05:40:22 * hackage subG 0.4.1.0 - Some extension to the Foldable and Monoid classes.  https://hackage.haskell.org/package/subG-0.4.1.0 (OleksandrZhabenko)
05:40:44 <n0042> Are there any rules or guidelines for messing with the Lambdabot? That looks like fun but I don't want to break it or anything
05:41:21 <Uniaika> don't try to form an emotional connection with it, you'll be disappointed
05:41:43 <n0042> :O 
05:41:53 <boxscape> n0042 you may know this but if you want to mess with it without spamming #haskell, you can do so in DMs. If you do find a way to break it, seems like a great opportunity for a bug report
05:41:56 <boxscape> @botsnack
05:41:56 <lambdabot> :)
05:41:58 <geekosaur> .oO { if you can break it, we did it wrong }
05:41:58 <tdammers> I thought lambdabot was a "she"?
05:42:30 <Uniaika> I don't have a habit of anthropomorphising bots
05:42:32 <n0042> Thank you boxscape. That is a good tip
05:42:47 <tdammers> ships are "she" too
05:43:35 <Uniaika> tdammers: that's a maritime culture convention :P
05:43:55 <boxscape> countries do, too
05:44:04 <boxscape> s/do/are
05:44:15 <Uniaika> is that so?
05:44:41 <boxscape> yes, I mostly hear it in geopolitical commentary
05:44:48 <boxscape> or cgpgrey's videos
05:46:30 <boxscape> ..or, actually, I think in geopolitical commentary I usually see the capital being used
05:47:02 <n0042> That's definitely a thing.
05:47:03 <tdammers> Uniaika: if sailors can have weird traditions, why can't we
05:47:47 <boxscape> because if you anthropomorphize lambdabot, you'll form emotional connections with it, and as we learned that means you'll be disappointed
05:48:19 <ski> lambdabot was anthropomorphized as a she, rather long ago, yes
05:48:28 <dminuoso> authoritatively?
05:48:41 * dminuoso didn't get the memo
05:48:49 <n0042> What is the command to make Lambdabot evaluate an expression or list comprehension?
05:49:09 <boxscape> > [ x | x <- [1..5] ]
05:49:12 <lambdabot>  [1,2,3,4,5]
05:49:19 <ski> the South Park style avatar for lambdabot, chosen by voting in #haskell-blah, was definitely female
05:49:22 <dminuoso> > fix error 
05:49:24 <lambdabot>  "*Exception: *Exception: *Exception: *Exception: *Exception: *Exception: *Ex...
05:49:31 <boxscape> (a list comprehension is an expression fwiw)
05:49:34 <Uniaika> ski: is that channel still alive?
05:49:40 <boxscape> ish
05:49:47 <boxscape> #haskell-offtopic is more popular
05:49:58 <dminuoso> ski: Maybe we could have the Haskell Foundation make an announcement then, as their first official act.
05:50:05 <dminuoso> It seems relevant.
05:50:20 <Uniaika> hahaha
05:50:27 <n0042> Excellent, thank you. I tried to do it without a space after the prompt, which is why it wasn't working.
05:50:33 <ski> i'm not sure if the page where there were some South Park style avatars for some people on #haskell / #haskell-blah, is still available somewhere. the original link doesn't work anymore, at least
05:51:31 * ski idly recalls the `@vixen' command
05:52:43 <hpc> i liked it better when @vixen was removed and it autocorrected to @nixon :D
05:53:02 <ski> that still happens
05:53:31 <boxscape> https://wiki.haskell.org/Lambdabot still has the lambdabot avatar, at least
05:53:44 <ski> yes, that was the one
05:55:15 <ski> (i think the idea was to portray someone being a bit overworked, eyes glazing over, by lots of queries, many of them not that interesting)
05:56:34 <ski> but there were also some similar style avatars selected, by some other channel regulars, including shapr, me, Philippa, &c.
05:58:30 <siraben> What's the shortest way to write r x y z = y z x, in pointfree?
05:58:45 <siraben> @pl \x y z -> y z x
05:58:45 <lambdabot> flip flip
05:59:00 <ski> @keal
05:59:00 <lambdabot> i try make program called Glyph to do it but my script lang called T too slow. i invent T
05:59:09 <ski> @palomer
05:59:10 <lambdabot> Brump!
06:01:26 <n0042> That's a pretty great bot lol. Its creators should be proud
06:03:45 <boxscape> tbh I tend to use yahb more often these days, it's nice to have a proper ghci with alls bells and whistles. Then again, you can't do this with yahb:
06:03:46 <boxscape> @pl \a b d c d e f -> f b d c a e
06:03:46 <lambdabot> ((const . ((flip .) .)) .) . flip (flip . ((flip . (flip .)) .) . flip . (flip .) . flip . flip id)
06:04:23 <siraben> boxscape: yahb?
06:04:37 <boxscape> % print "yahb"
06:04:37 <yahb> boxscape: "yahb"
06:04:53 * hackage prolude 0.0.0.9 - ITProTV's custom prelude  https://hackage.haskell.org/package/prolude-0.0.0.9 (saramuse)
06:05:06 * ski remembers preflex
06:10:25 <kuribas> I was just thinking how similar destructuring syntax for records in haskell is to clojure hashmaps.
06:10:37 <kuribas> with NamedFieldPuns it's almost the same.
06:11:46 <kuribas> And while haskell records are not extensible, you can still simulate it with overloadedFields and RecordWildCards.
06:12:23 * hackage subG 0.4.2.0 - Some extension to the Foldable and Monoid classes.  https://hackage.haskell.org/package/subG-0.4.2.0 (OleksandrZhabenko)
06:12:27 <kuribas> For example merging: merge PartialUser1{..} PartialUser2{..} = User{..}
06:13:20 <kuribas> the "drawback" is having to define partial types, although I think that's a feature, not a drawback.
06:14:12 <kuribas> haskell has a reputation for being terrible with records, my experience is quite positive.
06:14:58 <ski> it's too bad that Haskell records binds selector functions to the field names
06:15:08 <kuribas> yeah true
06:15:21 <ski> the ML way is, imho, much better
06:17:36 <merijn> ski: That's fixed soon!
06:17:48 <kuribas> and with overloadedLabels selector functions are even more useless
06:17:48 <merijn> ski: There was a GHC proposal for -XNoFieldSelectors
06:17:50 <ski> writing `#x pt' or `pt #x' or something along those lines would be much better than to write `x pt'. that way, you don't shadow the field extraction, with `NamedFieldPuns'
06:18:06 <merijn> ski: It's already implemented and slated to merge into 9.2, iirc?
06:18:28 <ski> yea, i've heard that mentioned. is there are proposal for a replacement field selector syntax, that you know ?
06:19:01 <merijn> Not directly, but if you use it the namespace is free to generate, for example, lenses with the field names
06:19:29 * ski nods
06:20:41 <xsperry> ski, how does ML do it?
06:21:05 <ski> (also, users (especially newbies) wouldn't be confused by the cognitive dissonance by the field signature `x :: Int' vs. the field extraction function signature `x :: Point -> Int')
06:21:41 <ski> xsperry : if `x' is a field in a record, then `#x' is a field extraction function, taking the record and extracting the field. that's in SML
06:21:50 <ski> O'Caml does `pt .x', iirc
06:22:16 <xsperry> so fields are in separate namespace?
06:22:24 <ski> (but the main point is to not simply bind the field name to a field extraction function)
06:22:44 <ski> yes
06:23:50 <xsperry> and what if multiple objects have field named x? 
06:23:55 <xsperry> multiple types*
06:24:20 <merijn> xsperry: With NoFieldSelectors, yes
06:24:38 <merijn> xsperry: i.e. you can only use them in pattern matches/record creation
06:24:41 <ski> in SML, you must pin down the record type
06:24:43 <xsperry> I mean in ML/Ocaml. just wondering if it basically works like structs/classes in mainstream languages
06:25:15 <ski> in OCaml, iirc, field extraction is polymorphic, using row types
06:25:48 <merijn> ski: uh
06:25:55 <merijn> ski: OCaml doesn't have rowtypes, does it?
06:26:10 <ski> (ML is a family of languages, including SML,O'Caml,F#,Alice ML,..)
06:26:12 <ski> it does
06:26:14 <merijn> Unless they added those super recently
06:30:19 <ski> object types and polymorphic variants have long been in O'Caml
06:30:59 <ski> "If 'ident denotes an explicit polymorphic variable, and typexpr denotes either an object or polymorphic variant type, the row variable of typexpr is captured by 'ident, and quantified upon."
06:34:36 <ski> "The type <{method-type ;} ..> is the type of an object whose method names and types are described by method-type₁ …, method-typeₙ, possibly some other methods represented by the ellipsis. This ellipsis actually is a special kind of type variable (called row variable in the literature) that stands for any number of extra method types."
06:35:35 <ski> (that's from <https://caml.inria.fr/pub/docs/manual-ocaml/types.html>)
06:41:07 <ski> xsperry : ah, ok. so it's just method selection for object types that's polymororphic, not field selection for record types. see <
06:45:17 <ski> see <https://caml.inria.fr/pub/docs/manual-ocaml/coreexamples.html#ss:record-and-variant-disambiguation> and <https://caml.inria.fr/pub/docs/manual-ocaml/objectexamples.html>
07:52:20 <dminuoso> Mmm, I have a file with lines of varying indention, and I intend to interpret that as a tree like this https://gist.github.com/dminuoso/7911cb8e16c4de0d48de20e7270ebc68
07:52:47 <dminuoso> I can cook up some sort of stateful unfold, but I was wondering whether there was some tree related library that would give me this for free
07:53:24 <dminuoso> (Doesnt have to be that exact tree data type)
07:57:51 <[exa]> dminuoso: you can preprocess the leading whitespace to 'indent' and 'unindent' marks easily, then it's pretty easy to do
08:02:21 <dminuoso> [exa]: Mmm, what kind of un/indent mark are you referring to? Should these become conceptual push/pop instructions of a stack of things?
08:11:38 <[exa]> dminuoso: yeah, it's not supersmart but safest way around I found
08:12:23 <dmj`> why can't we :unset -Werror in ghci 
08:14:41 <dolio> Seems like it doesn't no how to :unset any -W flag.
08:14:47 <dolio> Know, even. 
08:15:22 * hackage subG-instances 0.1.0.0 - Additional instances for the InsertLeft class from subG package.  https://hackage.haskell.org/package/subG-instances-0.1.0.0 (OleksandrZhabenko)
08:16:08 <dminuoso> [exa]: heh yeah that's what Im already doing. I just keep the previous indention as state around, so if it increases it becomes a push on a buffer where I push things onto, and on a pop I just flush the butter
08:16:11 <boxscape> does :set -Wno-error work?
08:16:14 <dminuoso> this is incredibly imperative, sadly
08:16:28 <[exa]> https://gist.github.com/exaexa/9920eb85d2bd20f4c575f2f1d307ae96
08:16:31 <dolio> You can `:set -Wwarn`
08:16:35 <boxscape> ah
08:16:36 <dolio> Which is supposed to reverse it.
08:16:48 <dminuoso> % :set -Wno-warn
08:16:48 <yahb> dminuoso: ; <no location info>: warning: unrecognised warning flag: -Wno-warn
08:16:55 <dminuoso> % :set -Wno-error
08:16:56 <yahb> dminuoso: ; <no location info>: warning: unrecognised warning flag: -Wno-error
08:16:58 <dminuoso> Mmm
08:17:07 <dolio> There's no `no-` for those for some reason.
08:17:25 <[exa]> dminuoso: I guess there's no better way, the indented stream itself is a series of commands encoded in the spaces...so what. :]
08:17:41 <dminuoso> [exa]: Well I can always throw `indents` at it!
08:18:43 <boxscape> hm I suppose if -Wno-warn existed the intuitive interpretation would be that it turns off warnings alltogether, and then it would be unclear if -Wno-error should put warnings into -Wwarn mode or into -Wno-warn mode
08:20:39 <larou> hello!
08:21:04 <boxscape> hi
08:21:14 <larou> I have code!!
08:21:33 <[exa]> dminuoso: careful not to end up with python. :D
08:21:38 <larou> no i dont, i only have rumours of code
08:22:30 <larou> i have a new type of tree
08:22:47 <larou> its better than normal trees
08:23:03 <larou> it has upwards branches
08:23:11 <larou> iv been trying to do it for ages
08:23:17 * [exa] briefly recalls "normal" trees
08:23:31 <larou> yeah, those have only downwards branches
08:23:54 <larou> these are way better
08:23:56 <[exa]> I mean the nature ones
08:24:26 <larou> never mind your vacant wonderings
08:25:04 <larou> they typecheck and everything
08:25:07 <boxscape> does it have upwards as well as downward branches or only upwards branches?
08:25:23 * hackage git-lfs 1.1.1 - git-lfs protocol  https://hackage.haskell.org/package/git-lfs-1.1.1 (JoeyHess)
08:25:27 <larou> sure, its not just an upside down tree...
08:25:36 <boxscape> ah, good
08:25:47 <larou> i put functions on them
08:25:52 <larou> at the branches
08:26:03 <larou> MIMO functions (multiple inputs multiple outputs)
08:26:20 <larou> just one input and one output argument, that are HLists
08:26:21 * boxscape thinks the upwards branches should be called "roots"
08:26:35 <larou> original!
08:27:00 <larou> i call them output edges
08:27:09 <larou> inputs go at the leafs
08:27:32 <larou> and they do the cyclic thing perfectly!!!
08:27:42 <merijn> So...graphs?
08:27:43 <larou> they are a list, instead of a free thing
08:27:57 <larou> meijn: no they are trees
08:28:03 <larou> they just have lookup tables 
08:28:11 <larou> but its just the same
08:28:12 <merijn> trees are graphs
08:28:24 <larou> but graphs can be cyclic, while trees cant
08:28:26 <merijn> They're just a more boring subset of graphs (i.e. on without cycles)
08:28:30 <larou> thats what makes them trees not graphs
08:28:33 <larou> and this is a tree
08:28:55 <larou> so... not graphs...
08:29:03 <larou> i have also "sparks"
08:29:09 <larou> these are the bits that make them not graphs
08:29:21 <larou> when you see a cycle, you must make a spark
08:29:23 <larou> it is a state 
08:29:28 <[exa]> larou: data structure folks demand a precise written definition
08:29:43 <merijn> [exa]: non-data structure folk too :p
08:30:03 <larou> it goes to an output instead of to the input variable, this is externally stored, as a state, and fed back in at the input at the next itteration
08:30:29 <larou> it would have been imposible to reference its current value to calculate itself at this iteration, so it has to be from the last
08:30:35 <larou> thats why we get "spark states"
08:31:24 <[exa]> like seriously, this sounds like the random rnn-generated paper about quantum physics. Get a piece of LaTeX and write it down, with examples and pics.
08:31:40 <larou> [exa]: its definition is an extension of the GADT for list, in that it has extra params on the thing being consed to. also, there is another record to the datatype which just wraps itself, but has a constraint that checks to see the sparks are correct in preventing cycles
08:32:12 <larou> oh you want the code, hang on
08:33:28 <larou> here
08:33:29 <larou> https://pastebin.com/raw/Kq05pARC
08:35:13 <larou> and here; https://pastebin.com/raw/gHZaze9F
08:35:13 <[exa]> on which line are the trees and sparks?
08:35:26 <larou> in the 2nd paste, its "Net"
08:36:35 <[exa]> ok cool, does it work?
08:36:36 <larou> now here i can specify the same graph, and using the definition of the input output pairs broken by designating "Sparks"
08:36:50 <larou> then, it will return a graph which passes the matrix test
08:36:55 <larou> ie, is not cyclic
08:37:04 <larou> this is the constraint on the CloseNet constructor
08:37:21 <larou> so you can, if you specify the correct sparks, as this check ensures you must
08:38:23 <larou> you add functions to your net any which old way, and ensure that you have a way in mind to break the cycles (where you put the sparks, which inputs matched with outputs you do not pass as internal edges
08:38:25 <larou> )
08:38:37 <larou> [exa]: i didnt make a graph yet
08:38:58 <larou> i need to shuffle them so the inputs to outputs are well ordered in the list of functions
08:39:07 <larou> so you can supply inputs to each of them in a fold
08:39:22 <larou> and the values it calculates serve as inputs to the rest
08:39:39 <larou> you specify type level symbols as annotations to the edges of the Net
08:39:48 <larou> thats how these new type of trees work
08:40:19 <larou> they dont sit underneath each other in a GADT, appearing as a self reference within a list, like a regular tree
08:40:42 <larou> so you give each of the edges a label, and have the nodes that are on either end of it both reference that
08:41:00 <larou> the matrix is a numerical representation of the resulting adjacency matrix
08:41:07 <larou> well, its directed from inputs to outputs
08:41:33 <larou> and then you exponentiate that to get, "if it is above itself" which would throw an error as a cycle
08:41:56 <larou> the constraint on the CloseNet constructor would not hold
08:42:06 <larou> you would have to specify better sparks as a type annotation
08:42:40 <larou> so what do you recon!? solved the ancient, upwards branching trees thing, finally
08:42:47 <merijn> I propose implementing a prototype and showing that to people, rather than roughly explaining in english
08:43:02 <larou> it works as in the links provided
08:43:13 <[exa]> cabal install <what>
08:43:14 <larou> i dont have it doing what i want yet though
08:43:28 <merijn> So...it doesn't work yet
08:43:38 <larou> i need to shuffle them so the nodes at the leafs pass inputs along for functions to be evaluated
08:43:53 <larou> merijn: exactly what i described is demonstrated in those pastes
08:44:03 <larou> what it doesnt do yet, it does not yet do
08:44:17 <larou> so its not with "the final demo"
08:44:26 <larou> which would probably be what you would want
08:44:49 <larou> so, basically its a state function
08:44:54 <larou> so i can put it on a graph!
08:44:58 <larou> and that makes it a monad
08:45:02 <larou> which is pretty mad
08:45:09 <larou> the "net" thing, with actual functions on
08:45:21 <larou> its the monad from; "programs are monads"
08:45:36 <merijn> "and that makes it a monad" <- I doubt that without a proof
08:45:44 <larou> i have explicitly named bound variables expressed at type level
08:45:53 <larou> meijn: it is a monad though...
08:46:18 <larou> you can break programs down and compose them, programs aka functions 
08:46:33 <larou> anyway, the point is its a *state*
08:46:35 <larou> so it changes
08:46:39 <larou> the whole program
08:46:48 <larou> and thats where these sparks sit, internally as states
08:47:13 <larou> they go along internal edges that you have brokn to make them external inputs and outputs directed to a state variable that acts as a memory store
08:47:21 <[exa]> larou: it makes no sense, seriously
08:47:43 <larou> you have the graph of functions, and with it, all of the spark states, that are returned when you run the function on its inputs and previous spark states
08:48:10 <larou> and you package all of that up as a state function
08:48:38 <larou> and put it on a graph of functions, with its cycles broken as another layer of sparks, stored as states in another state function wrapper and so on
08:48:46 <larou> its the "and so on" thats the monadic recursion
08:49:23 <larou> nodes, that internally, are graphs of functions
08:49:33 <larou> the "nets as neurons" monad 
08:49:58 <larou> you partition the program any which way into functions, depending on how you define them and with synonyms
08:50:05 <larou> or unpartition it
08:50:09 <larou> thats cobind and bind
08:50:30 <merijn> Just because you call them that, doesn't mean they obey the monad laws
08:50:37 <larou> yeah but they do though
08:50:59 <larou> in the same way a tree is
08:51:09 <larou> i guess i need them to be nonempty etc
08:51:21 <larou> but yeah, theres a monad there, no doubt 
08:51:40 <larou> anyway, thats not the fun part
08:51:58 <larou> the spark states get "hidden" when you package them into a state function wrapper placed on the net
08:52:14 <larou> because the net can handle state functions, so the sparks just get absorbed by that machinery 
08:52:23 <larou> you get new nodes to the graph
08:52:51 <merijn> I suggest writing a blogpost, rather than writing a novel in a channel meant for discussion
08:53:04 <larou> the spark cycles, end up at an input and output terminus, that stores the spark state, and can be written to and read from 
08:53:27 <larou> merijn: thanks for keeping me on track.
08:53:44 <larou> i have presented these new trees
08:55:55 <larou> anyway, all this stuff to do with new nodes for the sparks when the nets handle state functions on the nodes - is just the next part of the todo - and is just to say what i have shown does not yet do
08:56:08 <larou> so far it just checks to see that the sparks provided are correct
08:56:18 <larou> so you cant make it wrong!
08:56:26 <larou> almost as good as making it right... 
08:57:03 <larou> you basically just have to be sure the edges you define dont cause a cycle
08:57:12 <larou> but it will tell you if there is
08:57:49 <larou> the only thing worth discussing really is the fact we have a new notion of tree
08:57:58 <larou> not, how far i am at making it better
08:58:12 <larou> what i show completely defines it
08:58:29 <larou> but many other implementations of the same idea exist
08:58:35 --- mode: ChanServ set +q *!*@*/ip.94.174.37.145
09:00:50 <he9388> Hi everyone, I'm trying to install the Haskell extension for VSCode, and I'm getting the error "Couldn't figure out what GHC version the project is using"
09:01:11 <he9388> I couldn't figure out what's the issue. Can anyone give a pointer? Thanks a lot.
09:01:26 <merijn> are you using stack or cabal?
09:01:40 <he9388> Cabal
09:01:54 <he9388> Or I believe so at least...
09:01:57 <merijn> he9388: Is GHC in your path?
09:02:13 <he9388> Which path?
09:02:20 <he9388> Sorry, I am beginner :)
09:03:32 <he9388> I get some message like this:Couldn't figure out what GHC version the project is using: /home/he/.config/Code/User/globalStorage/haskell.haskell/haskell-language-server-wrapper-0.6.0-linux --project-ghc-version exited with exit code 1: Module "/home/he/Documents/learn4haskell/a" is loaded by Cradle: Cradle {cradleRootDir =
09:03:33 <he9388> "/home/he/Documents/learn4haskell", cradleOptsProg = CradleAction: Cabal} Failed to get project GHC version:CradleError {cradleErrorDependencies = [], cradleErrorExitCode = ExitFailure 1, cradleErrorStderr = ["Error when calling cabal v2-exec ghc -v0 -- --numeric-version","","cabal: unrecognised command: v2-exec (try --help)\n"]}
09:03:39 <merijn> he9388: Let's rewind further: What OS? :p
09:03:48 <he9388> I am on Ubuntu
09:04:03 <merijn> he9388: If you run "which ghc" in your shell, what do you get?
09:04:48 <he9388> Ok, weird, I ran in two different directory and got two different location :)
09:05:06 <he9388> One I get: /usr/bin/ghc. The other: /home/he/.ghcup/bin/ghc
09:05:37 <merijn> The first is probably from your package manager, the second from ghcup. So step one is figuring out which you want :p
09:06:17 <he9388> What's the difference :)
09:06:27 <monochrom> Ubuntu's is much older.
09:06:40 <he9388> Then probably I'll stick to the new one 
09:07:00 <monochrom> How old? How bad? Answer: So old that only a few profs who never take a look at the current outside world still think it's in use.
09:07:42 <monochrom> So old that it's like some Windows users hold on to Windows 98 because they still hold on to WinFax. (OK this is an exaggeration.)
09:08:01 <he9388> Point taken, ready to get rid of it :)
09:08:36 <merijn> he9388: Also, ghcup lets you install multiple different versions at the same time so you can test across compiler versions
09:08:44 <he9388> What's the proper way to get rid of it 
09:08:55 <monochrom> sudo apt remove
09:09:12 <he9388> oh right
09:09:16 <he9388> was almost going to rm -rf it... 
09:09:46 <he9388> now it says ghc not found
09:09:51 <he9388> when I run which ghc
09:09:53 * hackage rosebud 0.2.0.0 - Common rose tree/forest functions  https://hackage.haskell.org/package/rosebud-0.2.0.0 (jship)
09:10:27 <monochrom> You will need /home/he/.ghcup/bin to be an element of your PATH
09:10:46 <he9388> OK, got it! Now this part works
09:12:36 <he9388> Now I am getting this error message: The Haskell (learn4haskell) server crashed 5 times in the last 3 minutes. The server will not be restarted.
09:13:05 <merijn> hmm, what's learn4haskell?
09:13:41 <he9388> https://github.com/kowainik/learn4haskell
09:13:48 <he9388> It's tutorial I'm going through :)
09:14:53 <merijn> hmmm
09:15:06 <he9388> Why should the extension be dependent on the server?
09:15:37 <monochrom> Never heard of it.
09:16:33 <merijn> he9388: No clue. tbh, the editor plugin landscape has evolved rather dramatically over the past year, but it isn't quite at the "works reliably in all setups" state yet
09:17:23 <merijn> That said, for the vast majority of my haskell career I've worked without editor plugins just fine. It's not ideal, but I can't really recommend investing a lot of time into getting it working now
09:17:44 <he9388> Having type checking would be nice :)
09:18:02 <he9388> I'm just starting to develop
09:18:34 <merijn> he9388: Yeah, but the current editor plugin landscape that you can either invest hours fixing things or wait a month and the plugins has improved much more :p
09:18:44 <monochrom> -fdefer-type-errors achieves 90% of the same goal at 0.1% of the cost
09:19:05 <merijn> monochrom: -fdefer-typed-holes >> -fdefer-type-errors :)
09:19:41 <merijn> he9388: You can always try something like ghcid running in a separate terminal
09:19:51 <monochrom> It means it demotes die-hard-erroring-out to just warning. This means functions that are unaffected by the type error are still usable, so you can continue to explore and figure out what to do.
09:20:15 <merijn> he9388: That gets you 80% of the way there 
09:20:38 <monochrom> my "cost" refers to installation cost
09:21:21 <monochrom> cost of one-time installing extra software and long-time babysitting said fragile perpetually-in-beta-quality software
09:21:27 <he9388> Did not know about ghcide either haha
09:21:28 <monochrom> s/long-time/long-term/
09:21:43 <merijn> he9388: Confusingly ghcid and ghcide are different things :)
09:21:44 <monochrom> Oh, and ghcid != ghcide
09:22:05 <he9388> oh
09:22:08 <monochrom> This is ghcid: http://hackage.haskell.org/package/ghcid
09:22:27 <merijn> he9388: ghcide is what your current plugin probably uses, but it's not as robust as ghcid yet. ghcid is basically a program that just repeatedly runs compile for you and reports errors
09:23:14 <monochrom> It is just an inotify loop over "oh you have updated Foo.hs again, so let me run ghc again so you see the error messages"
09:23:54 <monochrom> I think it is very misleading to call it anything related to IDE.
09:24:07 <monochrom> I would describe it as continuous smoke-testing
09:24:27 <sm[m]> I will say that VS Code + Haskell extension is quite likely to just work and give he9388 a really nice experience these days
09:24:37 <monochrom> You save a file, it reruns type checking, build checking, and test cases.
09:24:41 <he9388> I am using VS Code + Haskell extension actually...
09:25:03 <sm[m]> he9388: isn't it giving you realtime type errors, types on hover, etc ?
09:25:12 <merijn> monochrom: Well to be fair it was "ghci daemon", presumably
09:25:23 <merijn> sm[m]: Well, no, it kept crashing, hence the start of this discussion :p
09:25:30 <he9388> Oh, the extension is not loading: when I make new folder, I got "The Haskell (test) server crashed 5 times in the last 3 minutes. The server will not be restarted"
09:25:41 <sm[m]> oops, missed that. #haskell-ide-engine would help
09:25:50 <sm[m]> would also help.
09:25:58 <he9388> Ok, thank you for the reference 
09:42:30 <koz_> monochrom: I don't recall if it was you, but someone complained that we say 'Big-O', not 'Big-omikron'. Bird and Gibbons' algorithms book is here to right this wrong!
09:42:53 * hackage easy-args 0.1.0.1 - Parses command line arguments  https://hackage.haskell.org/package/easy-args-0.1.0.1 (jlamothe)
09:42:55 <boxscape> "Big-omikron" isn't that just regular o
09:43:06 <merijn> I say death to Big O analysis :p
09:43:33 <merijn> It's just a mathematical way of lying about performance :p
09:43:53 * hackage cryptol 2.10.0 - Cryptol: The Language of Cryptography  https://hackage.haskell.org/package/cryptol-2.10.0 (AaronTomb)
09:44:03 <c_wraith> People are very bad at it, and believe lies like "hash table insert and lookup are O(1)" with shocking credulity
09:44:31 <merijn> c_wraith: A reasonable number people know about *that* 
09:45:37 <merijn> The people that realise "the fundamental base of assumption of Big O is just 100% lies" is dramatically less :p
09:47:01 <boxscape> which assumption is that?
09:47:14 <maerwald> it's one of those things that make you look smart in interviews
09:47:16 <dminuoso> boxscape: Stuff like constant random memory access.
09:47:21 <merijn> It only seems to work because people in general mostly only care about the happy path
09:47:36 <koz_> maerwald: Alternatively, if you inhabit certain academic spaces.
09:47:39 <koz_> (which was my fate)
09:47:44 <dminuoso> If that's your model of computation, fine, but the truth of the matter is memory access is not constant on a computer implemented within the laws of physics.
09:47:49 <merijn> boxscape: random memory access is constant time
09:48:02 <c_wraith> that's only an assumption if you make it one...
09:48:02 <merijn> maerwald: It has real world implications
09:48:06 <boxscape> is the problem there caching or something else?
09:48:10 <merijn> boxscape: Yeah
09:48:13 <boxscape> I see
09:48:19 <koz_> Yeah, the memory hierarchy is a thing.
09:48:20 <dminuoso> boxscape: blackhole thermodynamics and relativity, roughly
09:48:23 <koz_> For good reason.
09:48:34 <merijn> You can construct algorithms that are "worse" per big O complexity while being *much* faster in reality
09:48:58 <koz_> merijn: And that's before we get to abuses of the form 'simplex is exponential'.
09:49:17 <merijn> c_wraith: eh, that assumption is baked into classical big O analysis as taught in CS and parroted when talking data structure complexity
09:49:46 <c_wraith> merijn: hmm.  not in my courses/textbooks.  They explicitly called out that they were working in the RAM model
09:49:46 <dminuoso> c_wraith: Well, the question is what conclusions you can draw from complexity analysis if the model doesn't fit reality well
09:50:47 <merijn> c_wraith: Well, *CLRS* assumes that throughout the book and even calls it out as a wildly unrealistic assumption in the first 1 or 2 chapters
09:50:57 <merijn> Anyway, dinner time
09:51:16 <koz_> merijn: Yeah, you get this a lot. 'This isn't realistic, but we're just goin' with it.' came up a bunch when I was learning a lot of algorithms-related things.
09:51:22 <merijn> c_wraith: What does "RAM model" mean? Did they include caches or not?
09:51:38 <merijn> (Actually, don't bother answering, 'cause dinner time :p)
09:51:47 <koz_> merijn: I assume Random Access Model. AKA 'all memory is flat, if you have an address, you have that memory in Theta(1)'.
09:51:48 <c_wraith> merijn: it's the standard name for the model in which all memory accesses have the same cost
09:52:45 <koz_> I think monochrom (maybe?) mentioned that many presentations of Dijkstra's algorithm straight-up lie about their actual performance because they assume magical thinking in priority changes.
09:55:06 <monochrom> Rather, an important implementation question of decrease-priority is grossed over.
09:55:24 <koz_> I _love_ the expression 'to gross over'.
09:56:58 <monochrom> In practice, I think people just gave up.
09:57:10 <koz_> In general, the folks that taught me algorithm-related stuff in CS had an attitude to implementation that was roughly 'ehh, it can be done somehow, who cares, now do more analysis'.
09:57:32 <koz_> (one was outright dismissive, the other just mentioned that these issues were resolvable but gave zero explanation how)
09:58:15 <monochrom> I have seen programming-contest-quality code libraries that don't use a log-time priority queue at all. Every extract-min and decrease-priority is linear brute-force search over an array.
09:58:42 <monochrom> Dijkstra himself also said he did that for his first demo, it was fast enough for him.
09:59:15 <koz_> monochrom: So wait, their priority queue essentially amounts to Vector (Int, a) or so?
10:00:24 <monochrom> I gross over details too. But I make a judgment: If I think an average student can think up how to code it up, I can gross over it; if it would be new and clever to them, I have to spell it out.
10:00:32 <monochrom> Yeah!
10:01:22 <koz_> Somewhat ironically, this makes me feel better about a recent Real Haskell Job call I had to make.
10:01:25 <geekosaur> considering the kinds of things your average student comes up with, you must have to spell things out a lot
10:01:44 <monochrom> And this is U of bloody Waterloo world class for-ACM-ICPC has-been-world-champion code library they bring on paper to the contests.
10:02:10 <monochrom> Fortunately, it's in C, so it is still fast. >:)
10:03:21 <monochrom> Oh, to be sure, "average student" still depends on which school we're talking about.
10:04:34 <monochrom> Suppose you pose the 1st-year-CS problem of "find the max of an array" for example. Actually, more honestly, a word problem that doesn't say outright "find max of array" but if you understand the wordy problem you see it's that.
10:05:04 <monochrom> In my school, the average students wouldn't have any difficulty.
10:05:18 <monochrom> In U of Waterloo, haha are you kidding, that's too easy.
10:07:06 <monochrom> So, that kind of word problems is the usual kind of problems you see during the warm-up practice stage of an ACM-ICPC-style programming contest. The warm-up practice stage being the whole point being familiarizing yourself with the computing environment, so let's solve a trivial problem so you can focus on learning how to use vi and gcc, say.
10:08:08 <monochrom> I overheard the conversation of a team from another school.  <Coach> So, what do you think?  <Contestant> No clue.
10:08:33 <monochrom> That's their contestant. So now imagine the average of that school.  But compare to the average of Waterloo.
10:10:30 <maerwald> Man. Why not just get under the sun at the beach, instead of all this programming.
10:11:47 * ski . o O ( "The Myth of RAM, part I" by Emil Ernerfeldt in 2014-04-21 at <https://www.ilikebigbits.com/2014_04_21_myth_of_ram_1.html> )
10:11:50 <monochrom> IKR?  I saw a lot of people working hard for their 100-metre dash, or marathon, or something.
10:12:06 <monochrom> Why not just get a ride?
10:12:16 <monochrom> Why not just call uber?
10:12:20 <koz_> ski: Thanks! I was hoping someone did a teardown.
10:17:29 <koz_> @unmtl StateT s Maybe a
10:17:29 <lambdabot> s -> Maybe (a, s)
10:20:38 <koz_> :t guard
10:20:40 <lambdabot> Alternative f => Bool -> f ()
10:21:33 <koz_> And of course 'guard' is from Control.Monad. That odd sock drawer of a module.
10:21:33 <dolio> I think people should really leave out the 'black hole' stuff from write-ups like this.
10:23:24 <koz_> Rod Downey famously claims that 'it's an open problem' is an 80% accurate heuristic for correct answers to complexity theory questions. At this point, I think 'Control.Monad' is an 80% accurate heuristic for correct answers to 'where on earth in base is this function?'-type questions.
10:24:44 <monochrom> You have to narrow the scope to "combinators that are good for all Applicatives, Alternatives, Monads, or MonadPluses". But yeah.
10:25:05 <koz_> monochrom: I dunno if I'm just special, but those are the kinds of things I need a lot, and can never find.
10:25:43 <monochrom> It is historical. 2 decades ago, there was only Functor and Monad, and module-wise there was only Control.Monad, not even Data.Functor, so all the cool tools got into there.
10:26:21 <monochrom> I guess 2 decades ago the module name was just Monad, too.
10:26:23 <ski> (and before hierarchical, wasn't there just `Monad' ?)
10:26:28 <monochrom> Yeah that
10:26:59 <koz_> Oh, I get why it is that way.
10:27:06 <koz_> It's just amusing to me.
10:27:53 * hackage ivory-avr-atmega328p-registers 0.1.0.0 - Ivory register bindings for the Atmega328p  https://hackage.haskell.org/package/ivory-avr-atmega328p-registers-0.1.0.0 (erdeszt)
10:33:21 <monochrom> I enjoy using history to explain why things suck today.  Those who have learned from history are doomed to helplessly watching other people repeat it.
10:39:19 <koz_> monochrom: After all, everything is either history or applied history? :P
10:51:21 <zincy__> koz_: Are you by any chance from New Zealand?
10:51:32 <koz_> zincy__: I am, by chance, from there.
10:51:41 <koz_> Was the Rod Downey mention the giveaway?
10:53:17 <zincy__> Juspay?
10:53:25 <koz_> zincy__: Contractor, but yes.
10:53:44 <zincy__> Yes we talked a bit about logic and discrete mathematics there
10:53:54 <koz_> Oh hi!
10:53:57 <zincy__> hehe
10:54:07 <zincy__> Hi
10:54:25 <koz_> Guess it figures Haskellers hang out here.
10:54:55 <zincy__> Yeah I saw the name and thought hmm that is a familiar name.
10:55:05 <koz_> I'm some variant of 'Koz' everywhere.
11:14:22 * hackage nonempty-vector 0.2.1.0 - Non-empty vectors  https://hackage.haskell.org/package/nonempty-vector-0.2.1.0 (topos)
12:13:53 * hackage pcg-random 0.1.3.7 - Haskell bindings to the PCG random number generator.  https://hackage.haskell.org/package/pcg-random-0.1.3.7 (cchalmers)
12:29:29 <dminuoso> dolio: The black hole stuff is what justifies O(sqrt(n)) for random access. Without it, you'd arrive at the notion that the maximum of information storable in a region of space is defined by its volume, not its surface.
12:32:29 <dolio> It doesn't justify it for anything close to an approximation of practical situations, though. And I've heard doubt that the theoretical stuff actually means what people say it means. So it's both unnecessary and potentially discredits you.
12:33:23 <dminuoso> Well, it just so happens that the O(sqrt(n)) asymptotics nicely match what we observe in cache hierarchies, local storage, remote storage, etc..
12:33:40 <dolio> Right, so you don't need to appeal to black hole stuff.
12:33:53 * hackage phonetic-languages-permutations 0.1.0.0 - Commonly used versions of the phonetic-languages-common package  https://hackage.haskell.org/package/phonetic-languages-permutations-0.1.0.0 (OleksandrZhabenko)
12:34:02 <dolio> So don't.
12:34:07 <dminuoso> What's the alternative. "Random access is O(sqrt(n)) but I wont tell you why?"
12:34:22 <dolio> They already explained why before talking about the black hole stuff.
12:34:48 <monochrom> In the interest of pruning dependencies you don't actually use, if your analysis just needs cache hierarchies, prune everything else.
12:36:15 <dminuoso> I guess it depends on the audience, really.
12:36:17 <dolio> The reason is that nobody actually knows how to effectively cool 3D stuff on the small scale, so memory is effectively planar.
12:36:29 <dminuoso> From the theoretical approach of studying real asymptotics, it seems suitable
12:36:48 <dolio> And even when you scale up to data centers, you build on the surface of the earth, so you don't actually scale arbitrarily in 3 dimensions.
12:36:50 <dminuoso> Fair, I guess that's a good reason
12:38:45 <dminuoso> I was just under the impression that complexity analysis didn't just care for "How does this function behave in some arbitrarily fixed region", but about the limiting factor in theory
12:39:52 <dminuoso> But your arguments about 2-dimensionality are still valid, as it's reasonable to assume that if we increase memory, we still will approximately only fill the surface of the earth
12:40:37 <dminuoso> But then we should take into account that there's large regions on the earth where we wont build data centers
12:40:53 <dminuoso> And that we have limited resources to even build memory
12:41:22 * hackage phonetic-languages-permutations 0.1.1.0 - Commonly used versions of the phonetic-languages-common package  https://hackage.haskell.org/package/phonetic-languages-permutations-0.1.1.0 (OleksandrZhabenko)
12:43:10 <dolio> How is that going to inform a better asymptotic cost of memory access than √n?
12:43:56 <dolio> You don't need to address every possible nitpick. There just needs to be a reason to use one model over another.
12:45:25 <dolio> √n is actually better for a lot of things empirically, regardless of any theoretical justification. The latter only helps you understand why.
12:50:58 <monochrom> More meta-ly, a lot of programmers are unable to accept that we have and use models, not absolute truths; and even that some of those models are purely empirical, i.e., no one bothered to dig deeper for why the model fits observation.
12:51:30 <monochrom> Engineers have made peace with that for a long time, and it's why engineers are so successful.
12:52:04 <monochrom> This is one of many aspects programmers still have a long way to go before we can legitimately call them "software engineers".
12:52:43 <dolio> And since no one is using black holes for memory (and won't for the forseeable future), that isn't a good explanation for why the model works anyway.
12:53:42 <monochrom> From the engineering point of view, a model is judged for merely this: For the scope of your application (possibly very niche and narrow), how much computation you need to get how much prediction accuracy.
12:54:23 <monochrom> (A scientist then dig deeper for why the model works so nicely, what is the deeper model behind it.)
12:54:34 <merijn> monochrom: Not if you're me
12:55:03 <merijn> Then you just go "you guys all suck so hard at engineering I had to spend most of my phd doing the engineering to even investigate these models and now I can't tell you why it works and I blame you" :p
12:55:22 * hackage phonetic-languages-simplified-common 0.1.0.0 - A simplified version of the phonetic-languages-functionality  https://hackage.haskell.org/package/phonetic-languages-simplified-common-0.1.0.0 (OleksandrZhabenko)
12:55:58 <monochrom> The fact that programmers are so unhealthy OCD with absolute truths is one of many reasons why I say that programmers are in the same genre as priests.
12:56:10 <alephu5[m]> monochrom: Do you really think that programmers are more bound to theory than traditional engineers? That's not my experience of the industry at all
12:56:34 <merijn> alephu5[m]: His point is that they are, but the industry refuses to acknowledge it
12:56:41 <merijn> Which is why they keep building broken trash :p
12:56:55 <aoei> monochrom: lmao
12:56:56 <monochrom> I am saying that programmers are bound to theory in the wrong way.
12:57:24 <aoei> monochrom: I was in academic science for a few years.. many of those people are also like that :P
12:58:28 <merijn> Most of the HPC/"empirical" side of CS is a joke, tbh >.>
12:58:54 <monochrom> You give a piece of theory to engineers, they take it as a model. It works? Cool. It doesn't work? They just look for another model.
12:59:28 <aoei> monochrom: smart folk
12:59:44 <monochrom> You give a piece of theory to programmers, they take it as a religion. It can only be absolutely true or absolutely heretic.
13:00:22 <aoei> i wonder if programmers is too broad and you mean a specific subset
13:00:39 <dolio> Well, it isn't just programmers, either.
13:00:44 <merijn> monochrom: Pfft, I belief in paraconsistent logics, I'm perfectly happy believing piece of theory to be simultaneously absolutely true *and* heretical :)
13:00:51 <monochrom> Modulo the programer in question actually has the intellectual capacity to properly read the piece of theory in the first place, of course.
13:00:53 <alephu5[m]> But if assumptions A, B and C imply a particular model that fails drastically, it's often useful to the pragmatist to know that the assumptions are wrong
13:01:06 <davean> Yah, and I mean thats also true for one side of it. On the mathematical side its either true of false, on the HW side it can be more varied. Both sides often want approximations.
13:03:26 <dolio> The usual "theory vs. practice" truism is really a nonsense way of thinking. Theories are useful when they can be applied to practice, and they should be informed and developed by practice. And practice can be assisted by a good/suitable theory.
13:04:08 <dolio> Learning a "theory" that never applies to practice is just kind of useless unless you enjoy the activity in itself.
13:04:34 <monochrom> Yeah. Knuth said: The best theory is inspired by practice. The best practice is inspired by theory. (I forgot whether that's his order haha.)
13:08:39 <maerwald> monochrom: you got that wrong... some priests are good people :)
13:10:27 <alephu5[m]> <dolio "Learning a "theory" that never a"> Isn't that philosophy?
13:11:38 <davean> maerwald: unlike any programmers
13:11:50 <maerwald> I didn't say thate :p
13:11:57 <maerwald> (but I thought it)
13:12:27 <dolio> alephu5[m]: Maybe. I don't put a lot of stock in philosophy. :)
13:15:32 * Lycurgus .oO( what part of perpetuating stupid lies about the nature of reality and man's relation to it is good?)
13:16:17 * glguy wonders how far back he'd need to read to find Haskell in this
13:18:50 <zincy__> monochrom: Right, but don't most programmers implicitly accept they are using models?
13:19:18 <zincy__> A voltage is never exactly "high" or "low" ...
13:20:21 <zincy__> We dont even need electricity to build computers
13:20:41 <zincy__> Surely an acceptance of these facts is an implicit agreement that we use models
13:20:43 <dolio> Good thing the model doesn't talk about voltages, then.
13:21:06 <zincy__> dolio: What do you mean
13:21:41 <dolio> If you're not using electricity to implement computation, it wouldn't make much sense for your model of computation to talk about voltages.
13:22:34 <zincy__> Yeah
13:24:33 <zincy__> What is it Marvin Minsky said, a computer is a a physical model of an abstract process. 
13:41:03 <Bad_K4rMa> couple haskell books for sale cheap less than 24 hours left: https://www.ebay.com/usr/roph-rjp-nb5hus5uzh
14:56:22 * hackage pandoc 2.11.2 - Conversion between markup formats  https://hackage.haskell.org/package/pandoc-2.11.2 (JohnMacFarlane)
14:56:39 <monochrom> zincy__: Consider how many programmers simply insist that recursive calls must consume call stack space except for tail recursion under TCO. Especially being very unambiguously specific about "stack", "call stack", and "tail".
14:57:51 <monochrom> Here in #haskell we enjoy a pretty good proxy statistics based on the frequency of someone coming in to ask "so, does Haskell do TCO?"
14:58:56 <monochrom> A clear sign that the askers took their models too religiously.
15:01:27 <monochrom> OK, at least that's my model of why they ask it.
15:03:05 <monochrom> Better examples would be: hash table lookups are O(1)-time, big-O means worst case. Those they really hold dear to.
15:03:27 * ski . o O ( TCMC )
15:03:33 <dolio> Haskell's dead. He doesn't do anything.
15:04:07 <ski> @where haskel
15:04:07 <lambdabot> <http://web.archive.org/web/20070703001910/http://www.cs.chalmers.se/~augustss/pics/haskel.gif>
15:04:59 <monochrom> OK, obOnTopic: I'm reading the paper "Splittable Pseudorandom Number Generators using Cryptographic Hashing", it's pretty neat.
15:08:12 <monochrom> Heh, actually the only reason it's on-topic is because for some reason Claesen and Palka sent it to the Haskell 2013 Symposium.
15:09:08 <monochrom> splittable PRNGs are now a non-Haskell-specific topic, the Java and Rust people are equally interested for concurrent algorithms.
15:10:40 <dolio> I'm not sure being on topic here requires not being on topic anywhere else.
15:10:57 <monochrom> OK!
15:12:15 <monochrom> Conjecture: If Koen Claessen proves P/=NP one day, he'll submit it to a Haskell Symposium or ICFP. >:)
15:12:49 <Rembane> ^^
15:14:31 * ski imagines "You know, I recently proved this cool result : .." in Claessen's voice
15:14:57 <Rembane> :D
15:15:18 <Rembane> I wonder what the reason is that they started working on the number generators 
15:15:23 <Rembane> QuickCheck maybe...
15:16:11 <monochrom> Yeah, that paper begins with how the old random's split sucked totally for pretty simple QuickCheck use cases.
15:17:24 <Rembane> Ha! Nice! :D
15:18:39 <monochrom> This paper and the splitmix paper, together with what the splitmix paper cites and improves upon, all 3 use this basic idea:
15:18:50 <dolio> Maybe I shouldn't drag back the previous conversation, but P vs. NP seems like one of the most overhyped problems.
15:19:06 <dolio> Probably irrelevant to practice.
15:20:17 <monochrom> Your generator state consists of the initial seed, the history of how you got here via splitting (a list of lefts and rights), and how many times you've called "next".
15:20:37 <monochrom> And your random number is simply the hash of that state.
15:21:52 <monochrom> The implementation details are what hashing to use, and how to make that incremental so you never rehash the same lengthy history prefix.
15:22:46 <Rembane> It's beautiful.
15:23:00 <Rembane> How do you know if you should pick left or right?
15:23:22 <davean> The operation you're doing defines which you're doing.
15:23:28 <monochrom> Say my history is <left, right, left>, and I call split.
15:23:53 <monochrom> Now the two new states are <left, right, left, left> and <left, right, left, right>, respectively
15:25:06 <monochrom> split (seed, history, counter) = ((seed, history++[left], counter), (seed, history++[right], counter))
15:25:52 * hackage codeworld-api 0.7.0 - Graphics library for CodeWorld  https://hackage.haskell.org/package/codeworld-api-0.7.0 (ChrisSmith)
15:26:40 <monochrom> Now you need to bet everything on the quality of your hash function, yeah. :)
15:27:43 <Rembane> Oh. Got it! That's clever. 
15:27:45 <monochrom> splitmix basically just ran DieHard1 etc and reported very good scores.
15:27:52 * hackage zydiskell 0.1.1.0 - Haskell language binding for the Zydis library, a x86/x86-64 disassembler.  https://hackage.haskell.org/package/zydiskell-0.1.1.0 (nerded)
15:28:17 <monochrom> Claessen and Palka's simply went crypto.
15:32:30 <monochrom> The next cleverness is how to eliminate storing that lengthy history, bringing the time cost back down to O(1) regardless of how many times you've called split.
15:35:04 <monochrom> For Claessen and Palka, it turns out that popular crypto hash functions run a block cipher for as many rounds as your input (which is the history here), so you can just save "the hash so far" instead of the full history.
15:35:45 <monochrom> For splitmix, the hash is an inner product, so again you can just save "the inner product so far".
15:35:59 <monochrom> actually s/inner/dot/ to be specific.
15:37:31 <monochrom> Those two papers are both very fun and pleasing to read.
15:38:38 <jayw99> hi! is there a way to use the @ syntax for data types defined as records
15:39:04 <jayw99> say I have: data A = A { field :: Int }
15:39:15 <jayw99> and i want to make a function f {field=f}
15:39:27 <jayw99> is there a way to do something like f a@{field=f}
15:39:28 <monochrom> f x@A{field=y} = y+1
15:39:43 <jayw99> oh you have to have the A
15:39:49 <monochrom> Yeah, that's all.
15:39:56 <jayw99> thx!
15:52:53 * hackage yi-language 0.19.0 - Collection of language-related Yi libraries.  https://hackage.haskell.org/package/yi-language-0.19.0 (TomMurphy)
16:14:53 * hackage yi-core 0.19.0 - Yi editor core library  https://hackage.haskell.org/package/yi-core-0.19.0 (TomMurphy)
17:00:53 * hackage yi-core 0.19.1 - Yi editor core library  https://hackage.haskell.org/package/yi-core-0.19.1 (TomMurphy)
17:11:47 <dolio> Someone's working on yi?
17:16:22 * hackage yi-core 0.19.2 - Yi editor core library  https://hackage.haskell.org/package/yi-core-0.19.2 (TomMurphy)
17:19:29 <glguy> Maybe someone could tell Tom Murphy about package candidates
17:26:11 <iqubic> Well, I'm struggling right now. I want to write a function with the type [[a]] -> M.Map (V2 Int), where the first element of the first list is associated with (V2 0 0), and the rest follows from there. I'm not sure how to do that.
17:27:58 <iqubic> Can I get some help on how to do that?
17:28:13 <dsal> I don't understand how you get from `a` to whatever V2 is.
17:28:19 <dsal> Is `V2 Int` a type?
17:29:02 <iqubic> dsal: data V2 a = V2 a a.
17:29:20 <iqubic> It's from the Data.Linear package, but you can just use that definite.
17:29:26 <dsal> So something like this?  > fmap (\(x:xs) -> (x, xs)) ["abc", "def"]
17:29:37 <dsal> > fmap (\(x:xs) -> (x, xs)) ["abc", "def"] -- -> M.fromList
17:29:38 <lambdabot>  [('a',"bc"),('d',"ef")]
17:30:37 <dsal> Oh, I think I understand.
17:32:45 <dsal> > fmap (\(y,l) -> zipWith (\x a -> (x,y,a)) [0..] l) $ zip [0..] ["abc", "def"] -- something like this?
17:32:47 <lambdabot>  [[(0,0,'a'),(1,0,'b'),(2,0,'c')],[(0,1,'d'),(1,1,'e'),(2,1,'f')]]
17:34:27 <iqubic> Basically something like this:
17:34:29 <iqubic> https://dpaste.com/AVYCK9ULA
17:34:45 <iqubic> If that makes any sense.
17:35:10 <iqubic> I see what you've given me.
17:35:25 <iqubic> dsal: Does my paste make sense?
17:35:57 <dsal> Yeah, completely.  I just sketched that thing in lambdabot, but I think it gets you pretty close to what you want.
17:36:04 <iqubic> Yes. It does.
17:36:27 <iqubic> I just need to change the data types used, and feed the result into M.fromList.
17:38:25 <dsal> Cool...  There's probably a better way to do that, and I should probably come up with a nice way to do that.  Sort of a two dimensional zip.
17:39:37 <iqubic> For now, that's the least of my worries.
17:45:35 <iqubic> Can I use zip when the first argument is [0..]?
17:47:00 <dsal> :t zip
17:47:01 <lambdabot> [a] -> [b] -> [(a, b)]
17:47:12 <dsal> Oh, you mean will it terminate?
17:47:21 <dsal> zip ends when either input ends
17:47:41 <iqubic> :t zipWith
17:47:42 <lambdabot> (a -> b -> c) -> [a] -> [b] -> [c]
17:49:25 <dsal> `zip` is just `zipWith (,)`
17:50:52 * hackage yi-frontend-pango 0.19.0 - Pango frontend for Yi editor  https://hackage.haskell.org/package/yi-frontend-pango-0.19.0 (TomMurphy)
17:51:08 <dsal> Oh, I didn't notice a thing I did.
17:51:16 <dsal> `zipWith2D :: (a -> b -> c -> d) -> [a] -> [b] -> [[c]] -> [d];  zipWith2D f xs ys = foldMap (\(y, l) -> zipWith (\x -> f x y) xs l) . zip ys`
17:51:20 <dsal> That's a slightly better version.
17:51:52 * hackage yi-frontend-vty 0.19.0 - Vty frontend for Yi editor  https://hackage.haskell.org/package/yi-frontend-vty-0.19.0 (TomMurphy)
17:52:26 <dsal> using fmap meant you got a `[[d]]` back, which was confusing me when I tried doing it with a declared type.
17:56:23 * hackage yi-keymap-vim 0.19.0 - Vim keymap for Yi editor  https://hackage.haskell.org/package/yi-keymap-vim-0.19.0 (TomMurphy)
17:57:23 * hackage yi-misc-modes 0.19.0 - Yi editor miscellaneous modes  https://hackage.haskell.org/package/yi-misc-modes-0.19.0 (TomMurphy)
17:57:48 <dsal> I need to add that to my aoc toolkit.  I end up inventing something like that regularly.
18:00:26 <dsal> Oh cool, I had a function that was slightly related that could be built on that, and it already had tests, so I can wedge it in there.
18:01:04 <iqubic> dsal: I'm actually preparing my AOC toolkit as we speak.
18:01:23 <dsal> I should do more of that.  I always feel like it would've been a great idea after the fact.
18:01:26 <iqubic> I have a file literally called Grid.hs, for doing grid based stuff.
18:02:23 <dsal> I've got `parseGrid :: (Char -> a) -> String -> Map (Int,Int) a` which is pretty common for those map things for me.  And a bunch of `around` and distance functions.
18:03:19 <dsal> And stuff that takes those grid things and spits out text or png visualizations.
18:04:28 <dsal> Mostly just use this text one:  `draw :: Bounded2D a => FilePath -> a -> PixelFun -> IO ()`
18:12:00 <MarcelineVQ> I always think aoc is a really great idea until problem 3 or 4
18:12:19 <MarcelineVQ> Then I feel less and less sure about that until the curve becomes eliptical
18:12:45 <monochrom> haha
18:13:34 <monochrom> This proves that your sentiment is under Newtonian gravitation >:)
18:13:59 <MarcelineVQ> this explains why I'm always in free fall
18:15:54 <iqubic> What is Bounded2D?
18:16:06 <iqubic> My drawing function is quite primative.
18:23:11 <dsal> iqubic: Bounded2D gives me `bounds2d :: a -> ((Int,Int), (Int,Int))`-- (min x, min y), (max x, max y)
18:23:32 <iqubic> I see.
18:23:34 <iqubic> Nice.
18:23:47 <iqubic> I don't have any functions for dealing with Rectangles.
18:24:52 * hackage mprelude 0.2.1 - A minimalish prelude.  https://hackage.haskell.org/package/mprelude-0.2.1 (mbj)
18:25:42 <MarcelineVQ> you should steal conal's drawing stuff  http://conal.net/papers/functional-images/
18:28:26 <dsal> I end up drawing a lot of the stuff while I'm trying to understand it.  This junk helps.  Also that thing that translates my arbitrary bounds to 0-based bounds.  I get that wrong so much.
18:28:52 <dsal> I ended up with a data type that represents the size and has translation functions for each direction.
18:29:42 <dsal> I'm not trying to do super fancy drawing stuff, mainly just "take grid from memory and put on screen"
18:31:59 <dsal> e.g., this is about as fancy as I get:  https://asciinema.org/a/288366
18:33:00 <MarcelineVQ> Urist Akinhumor has drowned
18:47:38 <ski> dsal : seems to be missing an `o', just beside the start ?
18:49:23 * hackage devtools 0.1.0 - Haskell development tool agregate  https://hackage.haskell.org/package/devtools-0.1.0 (mbj)
18:50:26 <ski> MarcelineVQ : who ?
18:52:34 <MarcelineVQ> Urist is the generic surname for dwarfs when telling dwarf fortress stories, dsal's art was reminiscent of flooding water in dwarf fortress
19:02:14 <dsal> I don't remember the puzzle.  Something about flooding with air.
19:03:30 <dsal> Yeah, I don't remember what that gap was.  Probably should've painted it something that didn't make it look like an accident.
19:11:27 <ski> mhm
19:19:04 <magicman> I must be missing something. Is there a way in esqueleto to turn an SqlExpr (Entity x) into an SqlExpr (Maybe (Entity x))?
19:19:27 <magicman> The 'just' function works on SqlExpr (Value x) -> SqlExpr (Value (Maybe x)), so that's not what I want.
19:24:57 <magicman> I have a function that chooses between two queries, depending on if I want "Only those X that have some related Y, and their Y", or "All X, and possibly their related Y".
19:26:08 <magicman> So that translates to an inner join VS outer join, except esqueleto says no, because outer join gives Maybe. For good reason. So I want to wrap the result of the inner join in Maybe as well.
19:27:58 <magicman> And I kinda want to still be on the query-level. I could do the select $ from $ blah for both queries, and map Just where relevant, but that feels a bit off.
19:43:53 * hackage yi-mode-haskell 0.19.0 - Yi editor haskell mode  https://hackage.haskell.org/package/yi-mode-haskell-0.19.0 (TomMurphy)
19:44:53 * hackage yi-mode-javascript 0.19.0 - Yi editor javascript mode  https://hackage.haskell.org/package/yi-mode-javascript-0.19.0 (TomMurphy)
19:45:53 * hackage yi-fuzzy-open 0.19.0 - Fuzzy open plugin for yi  https://hackage.haskell.org/package/yi-fuzzy-open-0.19.0 (TomMurphy)
19:46:52 * hackage yi-ireader 0.19.0 - Yi editor incremental reader  https://hackage.haskell.org/package/yi-ireader-0.19.0 (TomMurphy)
19:47:53 * hackage yi-snippet 0.19.0, yi-keymap-emacs 0.19.0 (TomMurphy): https://qbin.io/weak-ratios-hjy8
19:52:10 <magicman> Hrm. Looks like I can maybe possibly use the EMaybe function from the Internal module. This probably will not break anything ever, because directly using datatype constructors from modules named Internal never breaks things... *knocks on wood*.
19:52:23 * hackage yi-dynamic-configuration 0.19.0 - Dynamic configuration support for Yi  https://hackage.haskell.org/package/yi-dynamic-configuration-0.19.0 (TomMurphy)
19:52:53 <magicman> (also, whoa, didn't know people still worked on Yi. It's been a while since I've seen that name show up!)
19:57:52 * hackage conversions 0.0.4 - Injective explicit total and partial conversions  https://hackage.haskell.org/package/conversions-0.0.4 (mbj)
20:20:40 <koz_> If I'm reading type judgments, should I read 'Gamma, x : A |- x : A' as something like, 'given the fact that x types as A (plus possibly other facts), it follows that x types as A'?
20:21:59 <monochrom> Yes.
20:23:02 <koz_> So basically, if I have '[above horizontal line] Gamma |- A : s [below horizontal line] Gamma, x : A |- x : A', this basically says 'if A is really a type, and we know that x types as A, then x types as A'?
20:23:17 <koz_> I guess I'm confused at the difference between the horizontal line and the turnstile.
20:24:25 <monochrom> But the left of a turnstile is a very special kind of "assumptions".
20:25:00 <monochrom> The left can only list the variables in scope, and their types.
20:25:16 <koz_> Ah, so in a way, to the left of the turnstile we have a 'typing environment' basically?
20:25:28 <monochrom> Yes, that's exactly it.
20:25:35 <koz_> So what's with the big horizontal line?
20:25:47 <monochrom> That one is really general implication.
20:26:32 <koz_> Ah! I think I see it.
20:26:54 <koz_> Since we have Gamma on the left of the top turnstile, with no mention of x, it means 'we can assume that every type has a kind'?
20:27:08 <monochrom> or dividing a proof step into "before" and "after"
20:28:18 <koz_> I guess I'm asking why this wasn't written as something like 'Gamma, x : A |- A : s, x : A'.
20:28:53 <monochrom> Instead of "assume that a type has a kind", I think this rules is saying "in this system, a type has a kind".
20:30:37 <koz_> The rule is called 'var' if that helps any.
20:35:53 * hackage yi-keymap-cua 0.19.0 - Cua keymap for Yi editor  https://hackage.haskell.org/package/yi-keymap-cua-0.19.0 (TomMurphy)
20:36:59 <monochrom> A:s in a conclusion position is very different, in some sense opposite, of A:s in a prerequisite position.
20:37:25 <koz_> Could you elaborate on that?
20:39:05 <monochrom> I was hoping that you could use what you already know about the difference between "G implies P and Q" and "G and P implies Q"
20:40:32 <monochrom> If you have a rule that says: "conclusion: x:monochrom |- monochrom is a legal type, and x:monochrom", then it defines that monochrom is a legal type.
20:40:45 <monochrom> But if you don't have rule...
20:41:15 <monochrom> If you have, instead, "premise: monochrom is a type; conclusion: x:monochrom |- x:monochrom"
20:41:39 <monochrom> now you still don't know whether monochrom is a type, and generally "expr : monochrom" has any chance of being legal at all.
20:42:02 <monochrom> You will have to look for other rules to see if you can prove "monochrom is a type" or not.
20:42:28 <koz_> Ah, I think I see what you're saying.
20:42:37 <monochrom> If there is no, this means the system is trying to say "monochrom is not a legal type, you will never have anything of the form expr : monochrom"
20:42:58 <koz_> Alright, thanks, that helps.
20:43:11 <koz_> I keep forgetting that I need to become ten times stupider than I am as a human to properly read logic. :P
20:43:27 <koz_> It's the optimist in me. 'Of course this is a type, what else could it possibly be?'.
20:44:51 <monochrom> Some authors write a separate CFG to define legal types, and don't include this in the type checking rules.
20:45:00 <koz_> These ones clearly didn't do that.
20:45:20 <monochrom> Other authors use the type rules to define both legal types and type checking at the same time.
20:45:20 <nshepperd> i think i would read that as saying that a typing environment containing x:A emits/proves that judgement (eg. so you can use it in other rules), but only if it also proves that A is a type
20:45:23 * hackage yi-dynamic-configuration 0.19.1 - Dynamic configuration support for Yi  https://hackage.haskell.org/package/yi-dynamic-configuration-0.19.1 (TomMurphy)
20:47:53 <monochrom> Dependent typing is likely to mean legal types don't match any CFG, so it may be better to merge type forming rules with type checking rules, because the format allows you to add more restrictions.
20:47:53 * hackage yi-frontend-pango 0.19.1 - Pango frontend for Yi editor  https://hackage.haskell.org/package/yi-frontend-pango-0.19.1 (TomMurphy)
20:48:01 <nshepperd> if A is not a type, but instead instead a potato, then "Gamma, x:A" does not let you use x:A in further rules
20:48:21 <nshepperd> (unless there's a separate rules that says so)
20:49:37 <koz_> Propositions as potatoes.
20:49:45 <dolio> Proper variable scoping isn't context free, I believe.
20:50:04 <dolio> So you're already screwed once you have variables.
20:50:19 <monochrom> Oh heh yeah.
20:51:29 <monochrom> http://www.vex.net/~trebla/weblog/declare-before-use.xhtml is my proof, at least of a related theorem.
20:52:19 <monochrom> If it's just a few issues such as proper scoping standing in the way, we can make do with "fits this CFG plus has scoping requirements". Many authors do.
20:52:33 <dolio> I worked on a project that tried to resolve variable scoping during parsing. I recommend not doing that.
20:53:05 <monochrom> But dependent typing can have so many more unwiedly restrictions that you can't scale that style.
20:53:29 <koz_> monochrom: That's a really cute proof using a technique I spent a lot of time with.
20:53:43 <koz_> (our whole ToC class consisted of assignments pumping damn near everything)
20:57:38 <dolio> Yeah. Now I remember almost nothing about that part. :)
20:58:32 <koz_> dolio: One particularly gory (non-pumping) question was about CE languages.
20:58:44 <koz_> Like, all the questions around CE-ness were unpleasant, honestly.
21:13:53 * hackage yi 0.19.0 - Yi editor  https://hackage.haskell.org/package/yi-0.19.0 (TomMurphy)
21:50:23 <hooper> hi! i have a design question: so I want to have shapes like triangles and squares. they should both share some common attributes like having a number of sides and functions like computing the area, but would have different functions specific to each class  as well 
21:50:31 <hooper> what is the best way to structure this?
21:50:43 <hooper> I'm thinking a shape typeclass
21:51:58 <hooper> but then not sure how to handle methods unique to one class
21:52:01 <glguy> hooper, you can make a record like: data Polygon = Polygon { sides :: Int, Area :: Double, etc }
21:52:44 <hooper> hm but i only want triangles and squares
21:53:01 <glguy> OK, then: data Shape = Triangle | Square
21:53:48 <hooper> so then lets say i declare like data Triangle = { a, b, c }
21:53:57 <hooper> where a b c are Double type
21:54:08 <hooper> how would I write an area function then
21:55:02 <hooper> i need area to be polymorphic for square and triangle
22:08:02 <dsal> hooper: what is the type of the area function?
22:22:59 <koz_> If you need a _closed_ set of shapes, your best bet as per glguy would be something like 'data Shape = Triangle Double Double Double | Square Double', then defining 'area :: Shape -> Double' and case-matching.
22:26:36 <koz_> If you need things that work for only one shape variety, you can either return Maybes, or you can do something like 'data Triangle = Triangle Double Double Double', 'data Square = Square Double', 'data Shape = ATriangle Triangle | ASquare Square', so then you can write functions that work only on triangles, only on squares, or on both.
23:18:42 <idnar> so I ran `cabal build` in my project and now if I run `cabal install` it wants to rebuild everything; how do I see why?
23:25:27 <glguy> Install bundles up the source and does a build and install fresh from that sdist
23:26:00 <glguy> It won't rebuild libraries installed from hackage though
23:43:13 <Martinsos> glguy, hooper: While I would also probably go with the approach you described, what is argument against not going with the typeclass approach? I was doing something similar recently and I had really hard time making this decision, it was mostly about trying to guess how I might extend this code later. With data types, adding a new function should be simple, but that function needs to know internals of all the shapes and has to be
23:43:13 <Martinsos> obviously in a separate module, so there is no encapsualtion there. Also, if I add a new shape, I have to modify all of these functions. With type class, I can have the `area` logic encapsualted together with the each shape, which sounds cool. If I add new shape, I don't need to modify any of the previous shapes or their logic. However if I add new method, I have to modify all of their type classes. Which actually sounds not so bad to
23:43:13 <Martinsos> me. Ok, one thing I can't do it put all these shapes in an array together, since they are different types, but I could create another data type that is just a box for them `data Shape = ShapeSquare Square | ShapeTriangle Triangle` and then make it also an instance of `IsShape` type class and I solved that problem.
23:45:27 <Martinsos> If I am correct this is officially called "expression problem"?
23:46:21 <Martinsos> I saw some solutions in Haskell for making it extendable in both types and functions direction, but all of them were pretty complicated and it seemed to me they were not really needed in pratice often. I would rather just go with simple, pragmatic solution that does not use complicated Haskell features, at least for the moment.
23:47:27 <dminuoso> Martinsos: There's roughly two opposing properties of a language. Adding new operations and adding new data.
23:48:50 <dminuoso> In Haskell it is easy to add new operations/functions for a data type, but like you put it, adding more constructors (that is extending the data type) is hard.
23:52:17 <idnar> glguy: well, I'm seeing all the deps "needs build"; but if I rerun `cabal build` it doesn't build anything
23:53:19 <idnar> glguy: my guess is some flag like --enable-tests is changing
23:54:26 <idnar> err, "requires build"
