00:18:57 <jophish> Did I imagine it, or did the topic here used to mention that replies on IRC aren't immediate
00:19:35 <jophish> #autotools says: Just Ask and be prepared to wait. Someone will get back eventually (Think hours).
00:19:56 <jophish> otoh, I'm sure that that's not true
00:31:51 <Feuermagier> if the argument to the function is a list and:    function list = zip [0..] list -- how can I make "list" implicit?
00:38:51 <jophish> Feuermagier: do you mean eta-reduction, you can just have: function = zip [0..]
00:40:09 <Feuermagier> thx. yeah, that was it
01:08:39 <suzu_> is there a name for using continuation-passing-style to make something tail recursive?
01:08:43 <suzu_> like this:
01:08:48 <suzu_> printList :: [String] -> (String -> String) -> String
01:08:49 <suzu_> printList [] f = f "[]"
01:08:51 <suzu_> printList (x:xs) f = printList xs (\r -> f $ x ++ ", " ++ r )
01:09:47 <suzu_> this also makes my brain melt if i think about it too much
01:31:58 <Feuermagier> I think I've broken ormolu
01:32:22 <Feuermagier> I have a compiling program, but ormolu refuses to beautify it
01:34:50 <Feuermagier> Error while reformatting by `ormolu`. Error: The GHC parser (in Haddock mode) failed:
01:34:50 <Feuermagier> 			Exercise02.hs:(25,34)-(92,0)
01:34:50 <Feuermagier> 			unterminated quasiquotation at end of input
01:35:07 <Feuermagier> line 25:     target = twoThirdsAverage [i | (_,i) <- l]
01:35:11 <Feuermagier> any ideas?
01:36:54 <Feuermagier> ok. found the error. I left no space between the i and the | at first. The compiler thinks this is valid, ormolu breaks on it.
02:15:50 <maerwald> quasi quotes break a lot of tools
02:16:22 <maerwald> but this isn't even one
02:16:23 <maerwald> lol
02:33:23 * hackage calamity 0.1.22.0 - A library for writing discord bots in haskell  https://hackage.haskell.org/package/calamity-0.1.22.0 (nitros12)
02:36:29 <sshine> what's a good way to express NominalDiffTime with a precision of one second? NominalDiffTime is implemented with 'Micro'. I'd just wrap it, but I was thinking something like Data.Fixed for time resolutions.
03:44:22 * hackage constrained-categories 0.4.1.0 - Constrained clones of the category-theory type classes, using ConstraintKinds.  https://hackage.haskell.org/package/constrained-categories-0.4.1.0 (leftaroundabout)
05:16:23 * hackage hakyll-convert 0.3.0.3 - Convert from other blog engines to Hakyll.  https://hackage.haskell.org/package/hakyll-convert-0.3.0.3 (AlexanderBatischev)
05:37:27 <matthew-> % :t (id 3, id "x")
05:37:27 <yahb> matthew-: forall {a}. Num a => (a, [Char])
05:37:58 <matthew-> so, this suggests that the typing env is cloned for each part of the tuple
05:38:36 <geekosaur> hm, I never shut that flag off, did I
05:39:00 <matthew-> but I've seen some texts suggest that (id 3, id "x") should error, presumably because the instantiation of the type of id is shared
05:39:56 <matthew-> this is one problem with a lot of the HM presentations not going into things like lists or tuples
05:41:42 <__monty__> matthew-: You do run into trouble with the monomorphism restriction if you expect this behavior in general though.
05:42:16 <matthew-> so I *thought* the monomorphism restriction only comes into play in recursion. Am I mistaken?
05:43:11 <matthew-> because, essentially, the fix instantiates the binder right at the start of the abstraction
05:43:48 <matthew-> well, that's how it can be implemented. I'm less familiar with the details of what is actually sound to do...
05:44:48 <bqv> suzu_: ow
05:45:34 <geekosaur> % :set -fno-print-explicit-foralls
05:45:34 <yahb> geekosaur: 
05:45:52 <geekosaur> (unrelated to your question)
05:46:57 <merijn> matthew-: The monomorphism restriction comes into play for "bindings that look like values (aka, no arguments on the left of =) and which are typeclass polymorphic"
05:47:56 <merijn> matthew-: The usual "tuple and id" quandary you see is that '(\f -> (f 3, f "x")) id' doesn't typecheck, but I'm not sure if you were referring to that or something else
05:51:56 <matthew-> merijn: thank you, yes that makes sense (though this is just for plain lc with HM, not haskell). I've just misread then. Ok, so each type inference for each child of a list or tuple ast node should be done in isolation. That's what I've got wrong :)
05:55:19 <merijn> matthew-: So, that specific example requires Rank2 types which is (theoretically) inferrable, but I don't think anyone ever implemented the inference in a real world compiler, because it's atrocious and hard
05:55:38 <merijn> And Rank3 and higher types are impossible to infer at all
05:56:19 <matthew-> yup, I'm completely avoiding anything above rank-1
05:56:53 <merijn> I assume you've got TaPL already? ;)
05:58:48 <matthew-> indeed. as basically everyone in this channel refers me to. I have it open on my desk in front of me, along with the attpl
06:00:15 <FTB> hello dear community, im about to start the book "learn you haskell for good"
06:01:17 <merijn> matthew-: Just checking ;)
06:03:33 <matthew-> merijn: :) It's funny how many resources you end up working with in order to build a usable language. For example, I have pattern matching, tuples and lists ... and finding a single text which covers them all is tricky
06:04:58 <matthew-> merijn: plus of course a lot of the impls you find are written in Haskell... which obviously isn't a problem or a surprise... but just teasing out some of the details - mistakes happen!
06:06:53 <merijn> matthew-: The GHC wiki should (somewhere) have a list of papers talking about various parts of GHC too, which may or may not be helpful
06:13:33 <matthew-> merijn: ahh, thanks for the pointer. I'll take a look
06:37:53 * hackage quickcheck-instances 0.3.25.1 - Common quickcheck instances  https://hackage.haskell.org/package/quickcheck-instances-0.3.25.1 (phadej)
06:43:15 <p0a> hello with ByteString.Lazy, what exactly is the logic of Get?
06:44:03 <p0a> Isn't it to read some input and then do something with it? So to repeat this until EOF, what would I have to do? use `until' for example, and check for eof on the handle?
06:46:42 <nshepperd2> p0a: You mean Get from the 'binary' package?
06:48:30 <p0a> yes nshepperd2, thank you
06:48:39 <nshepperd2> Get represents a parser
06:49:30 <nshepperd2> when you call runGet, it parses the bytestring and returns the decoded contents as a haskell object
06:50:24 <p0a> alright
06:50:52 * hackage shake 0.19.2 - Build system library, like Make, but more accurate dependencies.  https://hackage.haskell.org/package/shake-0.19.2 (NeilMitchell)
06:50:53 <nshepperd2> if your bytestring represents a series of many items, you need to either construct a Get parser that parses a list or items, then call runGet once
06:51:18 <p0a> so it's inappropriate to do things in a Get parser?
06:51:20 <p0a> such as printing results?
06:51:41 <p0a> How do you efficiently implement unix `cat' in lazy IO with Get?
06:52:19 <p0a> I'm sorry for the fragmented sentences, I'm a bit tired.
06:52:20 <geekosaur> I wouldn't be using the binary package to do that
06:52:21 <nshepperd2> or use runGetIncremental to do one-at-a-time type parsing
06:53:02 <p0a> geekosaur: I'm trying to write a utility like `hd' for fun
06:53:02 <nshepperd2> doesn't `cat` just read input and write it to the output? you don't need to parse anything for that
06:53:53 <p0a> alright
06:54:11 <p0a> so I just realized I was misusing that Get parser. I see I should've been using runGetIncremental
06:54:35 <p0a> but also I shouldn't be using readFile, I should use a handle instead with binary mode on. Using readFile, I don't know how to check for eof
06:54:46 <p0a> so... I don't know how to `read' in a loop until eof
06:54:48 <nshepperd2> hd, as in a hex dumping utility?
06:54:51 <p0a> yeah 
06:55:31 <nshepperd2> yeah I wouldn't use the binary package for that either, I think
06:55:40 <nshepperd2> it's meant more for structured data
06:56:31 <p0a> I see
06:56:50 <p0a> I did write something with strict IO that works fine 
06:56:55 <p0a> I was just trying to see what lazy IO is about 
06:57:18 <p0a> I was also recommended conduit which was the next thing I was going to look at
06:57:55 <nshepperd2> well, with lazy IO, what you get is a big lazy bytestring which contains the entire input
06:58:49 <nshepperd2> what you'd generally do is write a pure function which transforms that into a bytestring containing the entire output
06:58:55 <p0a> I don't know why I ran into Get, I guess I don't need it at all, you just made me realize. 
06:59:54 <nshepperd2> and then just call Data.ByteString.Lazy.putStr to write that to stdout
07:00:32 <p0a> right, thank you
07:00:43 <p0a> I was misled by what the purpose of `binary' is
07:47:54 <dminuoso> I have a typeclass for serialization with a method `putAttr :: Attr a => a -> (Word32 -> Put -> Put) -> Put` with the assumption that an implementor will do something like `putAttr (SomeThing s) h = h 16 (putThing s)`
07:48:46 <dminuoso> The idea is that this continuation lets us communicate to the caller the length of our attribute, such that they can use it in some manner.
07:49:14 <dminuoso> However, that signature doesn't actually enforce it, since you could accidentally just write `putAttr (SomeThing s) _ = putThing s`
07:49:46 <dminuoso> Is there a way to rewrite this method to make it less error prone in that sense?
07:49:48 <ski> `putAttr :: Attr a => a -> (Word32 -> Put -> o) -> o' ?
07:50:06 <dminuoso> Oh.
07:50:48 <dminuoso> ski: Why didn't I see that, cheers!
07:50:57 <ski> oh, it'll work ?
07:51:10 <dminuoso> Looks perfectly reasonable I guess?
07:51:30 <dminuoso> Let me play with it
07:51:39 <ski> it depends on whether you expect `putAttr' to always be in CPS, or else sometimes nqCPS
07:52:00 <ski> (and i don't know enough context to be able to tell that)
07:52:02 <dminuoso> What is nqCPS?
07:52:12 <ski> "not-quite CPS"
07:52:28 <dminuoso> So far, I intend to use this in CPS everywhere
07:52:41 <ski> like you sometimes "do something after the continuation". e.g. using `finally' or `bracket'
07:53:55 <ski> e.g. `Codensity IO a' enforces that the only "not quite" things you can do are general `IO' things (that are polymorphic in the result type)
07:54:47 <dminuoso> Think I might just have to start using Cont here.
07:55:12 <dminuoso> Perhaps the the explicit and manual CPS is just too thick to look through
07:55:24 <ski> (of course, one could also imagine `putAttr :: Attr a => a -> (Word32,Put)' (or even `putAttr# :: Attr a => a -> (# Word32,Put #)') .. but presumably the ergonomics of CPS is nicer, in your case
07:55:41 <ski> )
07:55:44 <dminuoso> Yeah, the ergonomics of CPS is a lot nicer indeed.
07:56:08 <dminuoso> (I tried it with the above, and there were bizarre edge cases I couldn't quite figure out)
07:56:29 <dminuoso> Plus, I have the need to callWithCC soon
07:56:37 <kuribas> since many libraries use CPS for exceptions (like attoparsec), wouldn't it be useful to have a ExceptT library that uses CPS?
07:56:55 <dminuoso> Err, callCC I guess its called in Haskell
07:58:33 <ski> hm. i wonder how you're intending to capture and later swap out the current continuation
08:00:22 <dminuoso> ski: Very roughly, the protocol demands to serializen an "attribute" into an "invalid attribute" (which would not invalidate the entire pass) under certain conditions.
08:01:10 <dminuoso> Oh wait..
08:01:13 <dminuoso> That's in the Get part...
08:01:15 <dminuoso> mmm
08:04:34 <Iceland_jack> hi alp
08:05:00 <alp> hello
08:27:04 <kuribas> Why do libraries handwrite their transformers?
08:28:47 <kuribas> with a generic cps'ed exceptT you could simply replace the current ExceptT with the CPSd version, and get the same performance gains, but without that difficulties.
08:31:11 <kuribas> for example, attoparsec uses a CPSed error handling, but it is hard to understand.
08:33:14 <Rembane> My guess is that they do it for (real or made up) performance gains.
08:34:18 <kuribas> the performance gain is real, but you could get the same with a custom ExceptT transformer IMO.
08:34:46 <davean> kuribas: prove it. GHC often fails to merge transformer stacks.
08:34:58 <kuribas> davean: when?
08:35:06 <kuribas> davean: in my tests it worked fine...
08:35:06 <davean> "almost always"
08:35:21 <davean> I've never actually seen it merge them fully. It gets close
08:35:27 <kuribas> davean: when the stack is in different modules?  In the same module?
08:35:55 <kuribas> or when it becomes so big it doesn't inline the functions?
08:36:01 <davean> see the part where I've said I've never seen it.
08:36:06 <davean> Litterly never seen it.
08:36:15 <kuribas> I've seen it many times...
08:36:22 <davean> Have you checked the actual core?
08:36:26 <kuribas> yes
08:36:32 <davean> Congrats.
08:36:34 <kuribas> with optimizations on of course.
08:36:49 <kuribas> davean: I'll do a test and report the result :)
08:37:03 <kuribas> no point in arguing when you can test :)
08:38:46 <dminuoso> Well, in case of attoparsec, CPS avoids the need for fusion in the first place.
08:39:09 <dminuoso> If you encode it with sum types, you rely on GHC to do deforestration
08:39:09 <kuribas> dminuoso: to get better compile times?
08:39:10 <davean> Yah fusion is really good. Its just not entirely reliable.
08:39:36 <dminuoso> kuribas: Not just that, you get much more reliable performance, rather than relying on GHC to do it for you
08:39:56 <dminuoso> Which can be dependent on build flags, how well inlining can take place, GHC version
08:41:14 <kuribas> letting the compiler do the work is a good thing IMO
08:41:57 <kuribas> I don't mind trading compile times for developper times, easier to understand code, and less chance of bugs.
08:44:51 <dminuoso> Its not about whether GHC can take work off you
08:44:55 <dminuoso> Its whether GHC can reliably do it for you. 
08:45:33 <kuribas> I don't need a 100% gain, 80% will do.
08:45:35 <kuribas> but not 20%
08:46:17 <davean> well most of the community thinks putting in a few extra minutes to get the 100% is more than worth it for core libraries.
08:46:34 <kuribas> yeah, I guess so
08:47:06 <davean> Also, like, often combining them can make the code conceptually simpler because you're no longer dealing with the product. Some cases thats not true. It varies.
08:47:14 <dminuoso> Right, especially since with libraries the compiler choice (version and flags) is out of the library authors control
08:47:33 <dminuoso> So by using CPS, the library author ensures you get optimizations without you your help
08:47:46 <kuribas> dminuoso: I am not advocating against CPS
08:48:05 <kuribas> dminuoso: I am proposing a CPSed version of ExceptT
08:48:49 <kuribas> that could be used as drop-in replacement for ExceptT
08:49:44 <dminuoso> ah
08:51:18 <davean> kuribas: oh, you know that inlining often ruins performance on non-microbenchmarks, right? Also in particular on lower-end CPUs.
08:51:37 <kuribas> what do you mean?
08:51:52 <kuribas> ghc compile times?
08:52:18 <davean> Inlining increases code size, and when you start spilling cache, or even not fitting in microop cache, performance degrades. So large pieces of code are often better off *without* inlining to get the sharing.
08:52:21 <goldcell> does haskell get around the need to conditionally express variables?
08:52:52 <davean> kuribas: inlining is a common case where a local optimization becomes a global pessimisation
08:52:56 <davean> goldcell: what is 
08:53:05 <davean> goldcell: what is "conditionally express variables"?
08:53:29 <kuribas> davean: yes, but in the case you want the inlining.
08:53:35 <kuribas> "this case"
08:53:43 <davean> kuribas: in particular you see this a lot with serialization/deserialization libraries.
08:53:47 <goldcell> e.g. when a value can be a null type or the type you actually want
08:54:13 <davean> goldcell: what is a "null type"?
08:54:15 <ski> we have `Maybe', for absence of values
08:54:27 <davean> A type is specific
08:54:38 <davean> you could designate one as ... no, I don't think "null type" makes sense.
08:54:52 <kuribas> davean: inlining also allows for other optimizations, like deforestation...
08:55:02 <davean> kuribas: sure.
08:55:12 <kuribas> without inlining, functional programs would be very slow.
08:55:33 <kuribas> maybe GRIN could improve on this.
08:55:51 <kuribas> by only inlining functions where you know there will be optimizations done.
08:56:14 <p0a> goldcell: yeah it does 
08:56:19 <davean> kuribas: we use inlining to get to deforestation, but thats not truly paired IMO
08:56:35 <p0a> goldcell: (1+) <$> Just 2 ==> Just 3, whereas if you do (1+) <$> Nothing you get Nothing
08:56:35 <davean> goldcell: are you sure you don't mean null values?
08:56:46 <goldcell> ski, yeah I think that's what I'm looking for
08:57:02 <davean> Maybe covers values being null, not types though?
08:57:24 <davean> (and even in C, there is "null" but there isn't a "null type", each type's null is different)
08:57:39 <davean> (Though with REALLY complicated rules saying they have to compare the same and such)
08:57:51 <goldcell> I was just programming in go, where it is called nil
08:58:00 * ski . o O ( "Null References: The Billion Dollar Mistake" by Tony Hoare in 2009-08-25 at <https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare/> )
08:58:23 <int-e> . o O ( small fries )
08:58:33 <davean> goldcell: mmm, ok, so I do think you're confused about values and types then.
08:59:01 <goldcell> go on ...
08:59:15 <davean> null values are the representation of absence inside a type, a type is a specification
08:59:46 <davean> you can trivially lift/extend any type to also include the concept of emptiness with "Maybe"
09:00:09 <davean> The TYPE just says what can be there though
09:00:21 <ski> (and you can do it again, adding another element that was not in the original domain. this is different from "nullable types")
09:01:00 <goldcell> ok, thanks :]
09:01:48 <davean> In Haskell the types represent if the value can be "null". This is true in go and C also, just there its implicitely required an entire set must have null values allowed.
09:01:57 * ski . o O ( "Option types, optional parameters" )
09:04:01 <hjdk09p> ;l
09:04:35 * ski . o O ( "Option types, optional parameters" by Riastradh in 2006-02-03 at their blag at <https://mumble.net/~campbell/blag.txt>,RSS <http://vrici.lojban.org/~cowan/blag.xml> )
09:47:23 * hackage brittany 0.12.2.0 - Haskell source code formatter  https://hackage.haskell.org/package/brittany-0.12.2.0 (fozworth)
09:51:22 <kuribas> devalot: well, the core is hard to read, but it looks fine.
09:51:31 <kuribas> erm davean
09:52:26 <kuribas> davean: my stack isn't complicated though: newtype EventParser l e m a = EventParser { getEventParser :: ExceptT (EventParseError e) (StateT (ParserState l) m)
09:54:20 <kuribas> davean: And I just had to replace ExceptT with my new CPSExceptT
10:01:22 <kuribas> davean: for example the "someTag" function now takes the failure continuation, success continuation and state.
10:17:48 <p0a> nshepperd2: "with Lazy IO you get a big ByteString containing the entire input" -> how do I get it?
10:18:10 <p0a> ohhhh sorry I just realized. There's function in ByteString.Lazy that work on handles
10:18:12 <p0a> my bad, ignore it :P 
10:19:59 <kuribas> p0a: you should be careful when reading lazy bytestrings from handles.
10:21:55 <kuribas> p0a: make sure you consume the bytestring before closing the handle
10:22:49 <nexii> hello. I'm trying to run through learn you a haskell and trying to implement a fizzbuzz-like function like boomBangs http://learnyouahaskell.com/starting-out found that if x `mod` 5 == 0 and x `mod` 3 == 0 then "FIZZBUZZ" issues an error. I was wondering how I can refactor this to make it not be bad and without pattern matching
10:24:37 <p0a> kuribas: it's possible to naively close the handle before the string is consumed?
10:24:46 <kuribas> p0a: yes
10:24:57 <p0a> so then when the string is attempted to be consumed it results to an io error right?
10:25:04 <kuribas> yes
10:25:06 <dolio> Just don't close the handle manually.
10:25:19 <p0a> that's a good point, thanks 
10:27:49 <p0a> nexii: https://wiki.haskell.org/Fizzbuzz shows an example
10:29:04 <nexii> p0a, thanks!
10:34:04 <pjb> p0a: nexii: https://www.youtube.com/watch?v=mZWsyUKwTbg&t=364s
10:34:15 <pjb> p0a: nexii: I mean: https://www.youtube.com/watch?v=mZWsyUKwTbg 
10:34:20 <nexii> I'm trying a non-pattern matching version and was wondering how I can fix this: fizzbuzzs xs = [if x `mod` 15 == 0 then "FIZZBUZZ" else x | x <- xs] (not considering fizz or buzz)
10:35:00 <pjb> (O(1) fizzbuzz; but check my comment with a lisp O(1) fizzbuzz).
10:35:30 <dminuoso> pjb: Without pattern matching somewhere, this is going to require some real trickery.
10:35:34 <nexii> this is issuing an error here "No instance for (Integral [Char]) arising from a use of `mod'"
10:35:44 <dminuoso> pjb: Generally, all evaluation in Haskell is driven by pattern matching...
10:36:18 <MarcelineVQ> you need to be explicit about converting  x  to a String since "FIZZBUZZ" is a String and both choices of an if need to result in the same type,   show x   is one way
10:36:19 <nexii> dminuoso, definitely. I'm just trying to align my expectations with reality
10:36:22 * hackage base64-bytestring 1.2.0.1 - Fast base64 encoding and decoding for ByteStrings  https://hackage.haskell.org/package/base64-bytestring-1.2.0.1 (topos)
10:36:27 <dminuoso> nexii: Ah, so imagine `x = if b then f else g`
10:36:32 <dminuoso> nexii: f and g have to be of the same type
10:36:43 <dminuoso> (Because what else would the type of `x` be?)
10:37:31 <dsal> p0a: have you looked at conduit?  You're taking a long path to doing relay conduit's core competency is.
10:37:48 <nexii> ooooh right!
10:37:49 <p0a> nexii: "FIZZBUZZ" and 2 are not the same type
10:37:54 <dminuoso> nexii: The error message is perhaps strange, because GHC simply infers `x` to be of type string (because "FIZZBUZZ" is a string), and then a constraint from the use of `mod` pops up
10:38:04 <nexii> can I cast as a string version of a number?
10:38:14 <nexii> cast *x
10:38:23 <p0a> You can create a 'supertype' that includes both strings and integers
10:38:36 <nexii> gotcha. thanks!
10:38:38 <p0a> or you can turn an Int into a String with `show', like `show n'
10:38:59 <nexii> ah. I think I wanted that
10:39:01 <p0a> dsal: not yet :) I will tomorrow probably. Woring slowly
10:39:45 <dminuoso> p0a: Regarding lazy IO, just dont do it. :p
10:40:42 <bqv> lol, for a second there i thought that was a reply to a message i'd sent a week ago about lazy IO
10:41:12 <dsal> bqv: turns out, it was just an async exception
10:41:44 <bqv> hahah
10:43:04 <dminuoso> dsal: If p0a just disconnected now, that'd be funny.
10:43:21 <p0a> :P 
10:44:36 <p0a> somehow I am using a function that knows that the ByteString is lazy and I'm getting an error 
10:45:15 <p0a> I'm trying to use fromBytes from hexstring, "Couldn't match expected type 'Data.ByteString.Internal.ByteString' with actual type 'Data.ByteString.Lazy.ByteString'
10:45:56 <p0a> dminuoso: I had abandoned the idea of using lazy IO but it's a last attempt before bed
10:49:08 <bqv> p0a: would it be too awful to strictify the bytestring?
10:49:23 <bqv> there's a convenient iso...
10:50:02 <p0a> okay I was confused because they have the same name as types
10:50:22 <p0a> I thought they were literally the same and that somehow the compiler knew when to be lazy. I now realize it's two different types 
10:50:26 <dsal> Huh.  I have a program that's been crashing occasionally.   There's nothing in the logs but an exit code.  That sucks.
10:50:29 <bqv> lol
10:50:53 <MarcelineVQ> slightly better than segfault
10:51:18 <MarcelineVQ> or is it
10:52:01 <bqv> to be fair, segfault's quite a lot of information. silent exit is basically an informational middle finger
10:52:42 <dsal> It's sometimes -1 and sometimes 1, so it even uses different hands.
10:53:07 <dsal> Many of them were last night when I was playing around with it and related bits, so that's not surprising, but the others are.
10:55:52 <p0a> thank you
11:43:23 * hackage hlint 3.2.2 - Source code suggestions  https://hackage.haskell.org/package/hlint-3.2.2 (NeilMitchell)
11:57:23 * hackage ormolu 0.1.4.1 - A formatter for Haskell source code  https://hackage.haskell.org/package/ormolu-0.1.4.1 (mrkkrp)
11:59:37 <monochrom> I don't simply say never use lazy I/O. But I say under very strict conditions, therefore you end up rarely using it.
12:00:37 <monochrom> My condition goes like: You understand lazy evaluation thoroughly, and based on that you see that your use case is dead simple to reason about.
12:06:43 <dolio> Hex dump of a file doesn't seem like it is a hard thing to reason about, if that was the actual problem.
12:06:53 <monochrom> An example is main = interact (unlines . map solve_one . lines). This is particularly idomatic for test-based programming contests.
12:08:25 <monochrom> Another one I use is lazy bytestring's hGetContents and giving it to cassava's decodeEither, and in case of cassava declaring parse error, the program quits very quickly.
12:09:21 <monochrom> Therefore, if there is no parse error, the whole stream will have to be exhausted for cassava to confirm there is no parse error, therefore the handle is closed before my program can proceed.
12:09:37 <monochrom> And if there is a parse error, my program quits without much further ado anyway.
12:10:10 <monochrom> Therefore, either way, the handle is closed deterministically.
12:22:20 <moet> is there some way to find the bit-width of Int and Word and Float and Double at compile time?
12:22:54 <moet> i don's see anything about it in the section on CPP macros https://downloads.haskell.org/ghc/latest/docs/html/users_guide/phases.html#standard-cpp-macros
12:23:41 <moet> i could do it at runtime, i guess, using Data.Bits.bitSize i suppose
12:24:05 <moet> i'm trying to select a representation for a type though, so it would be better done at compile time
12:24:40 <geekosaur> there are sized versions of most of those, e.g. Int32 vs. Int64 vs. Int
12:25:57 <geekosaur> and similarly for Word, but not Float or Double
12:26:24 <moet> Yes, there are sized versions (and i know there size at compile time!)
12:26:37 <geekosaur> but also be aware that usually they'll be stored as 64 bit values anyway
12:26:39 <moet> but if i want to create a sized representation of Int, i don't know it's size ..
12:26:44 <geekosaur> unless you're using packed vectors
12:26:56 <moet> hmm..
12:27:01 <moet> no packed vectors involved
12:27:23 <moet> but i need to know whether Int is 32 or 64 bit to select an appropriate representation for it in my work
12:27:23 <dolio> How static are you talking about? Like, are you generating code based on the static size?
12:27:45 <moet> i'm not generating code. i'm using a closed type family to map haskell types to information about their representation 
12:28:01 <moet> then i'm using instances on the representation type to implement my dsl thing
12:28:37 <moet> so in all my instance methods for Int's representation type, i could use bitSize to do the right thing at runtime i guess
12:29:13 <dolio> Well, primitive has sizes for everything, and I think it gets them from a header file.
12:29:23 <dolio> For the non-obvious ones.
12:29:26 <moet> oh! that's interesting.. i'll take a look there
12:31:07 <moet> https://github.com/haskell/primitive/blob/0e9141ca103c847e8ebe932a8663c5b8849f564a/Data/Primitive/MachDeps.hs
12:31:22 <moet> looks like they're importing the header and that just makes the defines available in haskell
12:31:26 <moet> i hand no idea that i could do that
12:31:36 <dolio> Well, it's using CPP.
12:32:53 <moet> well, when you put it that way :)
12:35:53 * hackage postgresql-simple 0.6.3 - Mid-Level PostgreSQL client library  https://hackage.haskell.org/package/postgresql-simple-0.6.3 (phadej)
12:36:25 <moet> dolio: geekosaur: thanks!
12:39:43 <dolio> I think it's unlikely that GHC will ever not be using IEEE for Float/Double, though, even though the Haskell report says they're implementation defined.
12:40:36 <dolio> So Int/Word is probably the only variable.
12:44:21 <dolio> At least as far as storage goes. There are probably flags that allow code to be generated using higher precision math on some processors, but once they get stored to memory, they'd be rounded back to 32/64 bits.
13:12:36 <justsomeguy> Does a list have to be traversed every time to access some arbitrary index, like with “[1..] !! 20”, or is there a compiler optimization for lookups like this?
13:14:10 <hpc> it's traversed every time
13:14:11 <electricityZZZZ> so if speculative execution in modern CPUs is very important for performance, has anyone examined program-specific execution speculation units?
13:14:32 <electricityZZZZ> i know that you can provide a clue to CPUs like "this branch is usually the one to take" but i mean something much more complex than this
13:15:14 <suzu_> seems like a hard problem
13:15:25 <merijn> electricityZZZZ: Yes, Intel has
13:15:48 <merijn> It's called the Itanium and it flopped spectacularly, because no one wanted a machine that couldn't run their old existing code :p
13:16:18 <electricityZZZZ> and so what i mean is that i have a 1 megabyte model "trained on common program execution patterns", which might supplement the existing speculative execution system.
13:16:37 <electricityZZZZ> and that 1 megabyte model is uploaded to the cpu and is active when my program runs
13:17:10 <electricityZZZZ> merijn: oh really? interesting. maybe it was just a market timing problem?
13:18:09 <dolio> So there are 300MB of 'models' stored on the CPU for my 300+ processes?
13:18:26 <hpc> there was never going to be a right time for it
13:18:48 <electricityZZZZ> yes it makes task switching hard
13:19:23 <electricityZZZZ> maybe a 10 MB cache of 1 MB models,...
13:19:49 <nitrix> SpaceX crew-1 mission for the interested: https://www.spacex.com/launches/
13:20:31 <electricityZZZZ> diverse astronaut group :D 
14:00:05 <koz_> For attoparsec's 'takeTill', when its predicate returns True, is the thing that caused the predicate to return True also consumed?
14:04:01 <koz_> Seemingly the answer is 'no'.
14:16:31 <moet> dolio: thanks for the note about Float/Double
14:16:56 <servo> HELLO
14:21:07 <boom> Hi, I am studying lambda calculus, and I heard haskell is based on it so, here is my question what does this expression  mean  λx.λy.x z y    ?     I have trouble understading    
14:22:18 <moet> boom: it seems like it's missing one set of parentheses, but i could be wrong
14:23:15 <moet> but it's a function that takes a parameter called x and returns a function that takes a parameter called y and then does an expression 'x z y' but that expression seems to be missing parentheses which would make its meaning clear
14:24:12 <moet> s/does an expression/returns the value of the expression/
14:24:42 <boom> the prof rewrote this expression as   λx.(λy.((x z) y))
14:24:53 <boom> he said something about priority
14:25:33 <koz_> boom: Most explanations of the lambda calculus define what binds more tightly than what.
14:25:34 <moet> i guess he's trying to teach you the associativity of application
14:25:39 <koz_> This is called 'precedence'.
14:25:55 <koz_> I would recommend looking at whatever source for its syntax you got given closely - this is usually somewhat buried.
14:26:15 <moet> yeah, it's very important to fully parenthesize an expression to avoid this ambiguity..
14:26:17 <koz_> The main reason is to avoid having to explicitly parenthesise everything.
14:28:22 <boom> I was told that      s t1 ...  tn ... =   (... (s,t1)...)tn    and the application has priority over the abstraction
14:28:50 <koz_> OK, so let's follow that through.
14:29:40 <boom> I'm saying to myself, in my formula what is s, t1 ?
14:29:43 <koz_> Since application has priority, \x\y x z y is really \x\y (x z y)
14:30:05 <koz_> Then, by the first rule, we have \x\y (x z y) is really \x\y ((x z) y).
14:30:33 <koz_> Then, by the first rule again, we have that \x\y ((x z) y) is really \x (\y ((x z) y))
14:31:02 <boom> Ok why is x y z part oif the application, I would expect only z and  y to be part of it
14:31:05 <boom> ?
14:31:20 <koz_> Because there's nothing else it could possibly be.
14:31:42 <koz_> In order to have anything other than application, you either have to have another \ there.
14:31:47 <koz_> (or lambda symbol, same diff)
14:32:12 <koz_> If you have a b c d e f g h i j k ...., all applications.
14:33:58 <koz_> Actually, I was slightly wrong - that last step isn't actually the first rule.
14:34:23 <koz_> The first rule there is application-related only based on your description.
14:36:15 <boom> in  s t1 ...  tn ... =   (... (s,t1)...)tn   is there a difference between s and the ts ?
14:36:24 <boom> t1, t2 ...
14:36:24 <boom> ?
14:36:33 <koz_> boom: In what sense do you mean 'is there a difference'?
14:36:43 <koz_> I'm not sure I understand your question.
14:36:46 <boom> are these all terms ?
14:36:58 <koz_> Yes.
14:37:08 <koz_> Because in the lambda calculus there isn't anything else.
14:40:25 <boom> Ok, so \x.s   is the abstraction. If I understand correctly this is like saying that s is and epression that depends on x, am I corrcect?
14:40:48 <boom> an expression*
14:41:06 <koz_> I'm not sure what you mean by that. \x . s is a lambda, correct. If by 'expression' you mean 'term', then the answer is 'it depends on what s is'.
14:41:26 <koz_> You can have \x . y, which is totally fine, and then nothing depends on x at all.
14:41:52 <boom> ok so what does \x . y mean ?
14:42:03 <boom> I'm not sure i've understood
14:42:06 <koz_> boom: We're not in the world of 'meaning' yet at all.
14:42:30 <koz_> \x . y is a lambda abstraction, whose body is y.
14:42:37 <koz_> In my case, 'y' is a free variable.
14:42:57 <koz_> In this case, nothing depends on anything.
14:43:05 <boom> ok
14:43:33 <koz_> If you had '\x . y x', then you can kind of argue that when you apply '\x . y x' to something, the _result_ of the application depends on the argument.
14:44:19 <koz_> For example: '(\x . y x) z' is an application, which reduces to 'y z'.
14:44:42 <koz_> However, '(\x . y) z' reduces to 'y', (\x . y) foobar' reduces to 'y', etc.
14:45:36 <boom> so here when you write  \x .y  x   here what is the body of the lambda expression ?
14:45:41 <boom> is it  y x
14:45:42 <boom> ?
14:45:53 <boom> or is it y  and then you apply x 
14:45:54 <boom> ?
14:45:55 <koz_> '\x . y x' has the body 'y x'.
14:46:11 <koz_> This has nothing to do with applying anything - it's a question of form.
14:46:30 <boom> ok so anything after the dot is part of the body ?
14:47:25 <koz_> boom: An abstraction has the form \VAR . BODY. I wrote them in caps to show that they stand for (respectively) an arbitrary variable and an arbitrary term.
14:47:44 <MarcelineVQ> var sometimes called head
14:47:55 <koz_> Yep!
14:49:01 <boom> VAR and BODY can be any term or varibale ?
14:49:13 <koz_> VAR can be any variable. BODY can be any term.
14:50:59 <boom> so if I go back to  λx.λy.x z y    Is  λy.x z y the body of  the abstraction λx ? 
14:51:07 <koz_> Correct!
14:53:55 <moet> oof, trying to use ((*) :: Nat -> Nat -> Nat) from GHC.TypeLits ...
14:54:09 <moet> since it collides with * (the kind of concrete types) ...
14:54:29 <koz_> moet: You probably want to import Data.Kind (Type) and use 'Type' instead of '*'.
14:54:48 <moet> koz_: i'm trying to refer to the Nat level multiply
14:54:55 <moet> and ghc keeps thinking i'm talking aout Type
14:55:14 <koz_> Did you enable TypeOperators?
14:55:16 <MarcelineVQ> Do you have/need TypeOperators on?
14:55:19 <moet> yes
14:55:30 <koz_> moet: Could you pastebin the exact error message?
14:55:38 <moet> let's see.. how do we do this with the bot again
14:55:48 <merijn> You need to disable StarIsType
14:55:57 <moet> merijn: that sounds promising
14:56:56 <koz_> Yeah, that's like {-# LANGUAGE NoStarIsType #-} or something.
14:57:26 <moet> NoStarIsType worked; thank you all
14:57:50 <boom> Ok, I'm stiil not sure why  \x\y x z y is really \x\y (x z y), I know you said that it can't be any other way, but I still don't get it.  
14:58:36 <MarcelineVQ> check out the wikipedia article for lambda calculus
14:58:52 <koz_> boom: What is the body of '\x . \y . x z y'?
14:59:21 <boom>  \y . x z y
14:59:39 <koz_> OK, so let's parenthesise it for convenience.
14:59:46 <koz_> \x . (\y . x z y)
14:59:56 <koz_> Now, we note that our body is an abstraction.
15:00:09 <koz_> Namely \y . x z y
15:00:13 <koz_> What is _its_ body?
15:00:18 <boom> so it also has a body
15:00:22 <boom> x z y
15:00:23 <koz_> Yes.
15:00:33 <koz_> So let's parenthesise _that_for convenience.
15:00:40 <koz_> \y . (x z y)
15:00:46 <koz_> And then paste that into our original.
15:00:52 <koz_> \x . (\y . (x z y))
15:01:12 <koz_> Now, to deal with 'x z y', we apply the rule you pasted way back above.
15:01:23 <koz_> Which says that 'x z y' is really what?
15:01:29 <boom> (x z) y
15:01:42 <koz_> So after convenience parenthesising and pasting, we get?
15:02:09 <boom> \x . (\y . ((x z) y))
15:02:30 <koz_> Does that help?
15:02:59 <boom> yeah! thanks
15:03:54 <koz_> @pl \f -> f x >=> f y
15:03:54 <lambdabot> liftM2 (>=>) ($ x) ($ y)
15:04:43 <koz_> So wait that'd be like (>=>) <$> ($ x) ($ y) f?
15:04:47 <koz_> Sorry
15:04:58 <koz_> (>=>) <$> ($ x) <*> ($ y) <*> f
15:04:58 <boom> But in this way of doing things  have we used the fact that application has priority ?
15:05:26 <koz_> boom: I don't think we have, no.
15:05:31 <MarcelineVQ> ((>=>) <$> ($ x) <*> ($ y)) f   ?
15:05:46 <koz_> MarcelineVQ: Egads lol nope.
15:18:11 <monochrom> You are also in for a lot of confusion and then disillusionment about what "priority" is really for.
15:18:49 <monochrom> TL;DR the highschool narrative of "do this first, do that later" is simplistic and inapplicable.
15:19:13 <monochrom> Truth be told it has never been about "do what first".
15:19:29 <Uniaika> :o
15:19:37 <Uniaika> so what is it about then?
15:19:38 <koz_> Something something order of reduction something something confluence something something.
15:19:52 <monochrom> Parsing. Where you may omit parentheses.
15:19:55 <koz_> I can something-something about a bazillion more terms in there.
15:20:03 <koz_> (heh)
15:22:14 <monochrom> It is just a happy coincidence that highschool operators are mostly eager (anti-lazy), therefore what's deeper in the parse tree are also what's "done" earlier.
15:22:21 <monochrom> However, consider this:
15:23:03 <monochrom> @quote monochrom lazy.eval
15:23:03 <lambdabot> monochrom says: some kind of lazy evaluation is already known to highschool kids. teachers tell you that in a*(b+c), "evaluate b+c first", right? well, I challenge you to take 0*(389238493+97283748)
15:23:03 <lambdabot> and find one single student who faithfully evaluate 389238493+97283748 first.
15:23:30 <koz_> :D
15:24:00 <monochrom> This proves that "precedence is about evaluation order" is a white lie.
15:24:51 <monochrom> We forgive highschools for this white lie because the average people cannot cope with both concepts, evaluation order and parse tree, at the same time.
15:25:24 <monochrom> But as advanced programmers we cannot hang on to that untenable model ourselves.
15:31:02 <pjb> monochrom: this is bullshit.  There are he precendence rules, and then there are simplifications and shortcuts.  There are numbers a, b and c with non-trivial values o such as a*(b+c) can be evaluated to d quickly, by following some simplification rule.  for example, 1289389183012*(812738127389173981+-812738127389173981).
15:31:12 <pjb> or 1289389183012*(812738127389173981+-812738127389173980).
15:33:06 <MarcelineVQ> non-trivial doesn't mean big, it means it won't show up as a question in a trivial pursuit board game
16:43:44 <boom> I want to calculate (λx.λy.x z y)[x y/z] now.   What does x y/z mean ?
16:43:58 <boom> [x y/z]
16:48:57 <monochrom> This depends on authors. Many authors write that to mean "replace z by (x y)".
16:49:24 <monochrom> The trouble is the other authors write [z/x y] for that.
16:50:13 <MarcelineVQ> oh so it's like, ommiting the := you'd see in places like the wikipedia lambda calculus article
16:50:30 <monochrom> Metaly, I cannot believe that the text you're reading this from didn't laid out this.
16:51:06 <monochrom> I very much prefer [var := expr], yes. It is much much more guessable.
16:52:53 <monochrom> My thesis supervisor recognizes that this is formalism going overboard, so he simply writes, e.g., "(λx. x+1) 5 = (substitute 5 for x in x+1)"
16:52:57 <boom> Somewhere in my notes its written x[u/x] = u , so i guess you replace x by u
16:53:56 <boom> so yeah replace z by (x y)
16:56:58 <monochrom> MarcelineVQ: A bit of addendum. Omitting := but putting back / in its place. And write in the other order.
16:57:23 <MarcelineVQ> well =: looks silly
16:57:30 <boom> if i look at λx.λy.x z y  the only free variable is z
16:58:12 <boom> for some reason  the x y in [x y/ z] are free ?
16:59:02 <boom> I don't understand why my prof meant
16:59:16 <monochrom> Ah, you may have to worry about variable capture, and pretend you're doing instead (λx1.λy1.x1 z y1)[x y/z] 
16:59:41 <monochrom> Such is the problem with named variables. >:)
16:59:49 <boom> yes there is somehting like that 
17:28:32 <justsomeguy> In the paper "Tutorial Introduction to Lambda Calculus",  I've seen [x/y] explained as "y is replaced by x for all its occurrences".
17:33:43 <justsomeguy> Sometimes it frustrating how much of math notations meaning isn't well agreed on, or up to individual interpretation.
17:34:39 <aoei> that's weird, i thought humans invented a standard symbolic language for mathematics
17:35:45 <dolio> [x/y] is pretty common. It's just not very good notation.
17:36:08 <dolio> With just variables, it's not really very clear which thing is being substituted.
17:39:02 <dolio> And it's notation that is isolated to things like lambda calculus, so it can't draw on familiarity with notation that's used in actual programming languages.
17:39:28 <aoei> ah
17:41:33 <dolio> One could argue that 'x := y' is no better if you haven't seen it, but a lot more people have seen things of that sort.
18:16:06 <monochrom> aoei: The greatest thing about standards is there are so many to choose from!
18:16:55 <dolio> I mean, it's also not true that mathematical notation is standardized.
18:17:39 <dolio> Which is probably okay, because there's a lot of bad notation out there.
18:18:08 <koz_> This might be slightly off-topic: how do web frameworks actually implement routing when URLs can have captures (meaning, stuff in the URL which isn't fixed, typically for use as an input into the handler)?
18:18:27 <koz_> I'm interested in 'what algorithms/data structures are used to make this not-garbage', but I'm turning up nothing.
18:24:27 <dsal> My mqttd SubTree type is similar, except it's always multimatch.  The naive thing worked quite well.
18:25:04 <koz_> dsal: Link?
18:27:53 <dsal> github.com/dustin/mqttd t SubTree
18:28:03 <dsal> (sorry: driving)
18:28:26 <koz_> Close enough - thanks!
18:29:36 <dsal> + and # are wildcards and I have to return everything that matches.  I don't care about the topics
18:31:05 <koz_> Hmm, now I need a Monoid of the form 'None | One a | TooMany'.
18:31:22 <dsal> The point is that I thought I'd need something complicated, but the easy thing worked.  Then all my hand-written instances could be derived.  I sat down to write difficult code that night.
18:31:38 <koz_> dsal: This is exactly what I wanted to see - thanks!
18:31:45 <dsal> This was very specific to my mqtt needs
18:31:53 <dsal> Ok, I was hoping it'd help
18:34:53 <koz_> :t maybe mempty
18:34:54 <lambdabot> Monoid b => (a -> b) -> Maybe a -> b
18:35:01 <koz_> :t foldMap
18:35:03 <lambdabot> (Foldable t, Monoid m) => (a -> m) -> t a -> m
18:35:05 <koz_> :D
18:35:17 <koz_> % :t foldMap @Maybe
18:35:18 <yahb> koz_: Monoid m => (a -> m) -> Maybe a -> m
19:14:03 <kushNYC> Anyone else try to install cross-compiled ghc binaries in iSH for iOS? It’s a musl-based Alpine Linux environment.  I get fairly far with installing the i386-musl build from https://github.com/redneb/ghc-alt-libc/releases - but ultimately come up against an error during install of ghc-pkg that eludes me...
19:14:07 <kushNYC> ```Installing library in /opt/ghc/lib/ghc-8.10.2/ghc-8.10.2"/opt/ghc/lib/ghc-8.10.2/bin/ghc-pkg" --force --global-package-db "/opt/ghc/lib/ghc-8.10.2/package.conf.d" update rts/dist/package.conf.installghc-pkg: Couldn't open database /opt/ghc/lib/ghc-8.10.2/package.conf.d for modification: {handle:
19:14:07 <kushNYC> /opt/ghc/lib/ghc-8.10.2/package.conf.d/package.cache.lock}: hLock: invalid argument (Invalid argument)make[1]: *** [ghc.mk:973: install_packages] Error 1make: *** [Makefile:51: install] Error 2```
19:15:02 <kushNYC> Tried messing with permissions and running ghc-pkg recache to no avail
21:15:53 * hackage vulkan 3.6.14 - Bindings to the Vulkan graphics API.  https://hackage.haskell.org/package/vulkan-3.6.14 (jophish)
21:16:53 * hackage VulkanMemoryAllocator 0.3.9, vulkan-utils 0.2 (jophish): https://qbin.io/cgi-immune-lgby
21:17:24 <jophish> What is this qbin thing?
21:18:24 <Axman6> probably a link shortening service?
21:18:49 <Axman6> looks like a paste service actually
21:22:07 <jophish> weird, I uploaded those three packages at the same time
21:57:46 <dminuoso> % data Foo = Foo { foo, bar :: Int }
21:57:46 <yahb> dminuoso: 
21:57:57 <dminuoso> Uh oh. This is permitted. :<
21:58:03 <dminuoso> % :t foo
21:58:03 <yahb> dminuoso: Foo -> Int
22:31:31 <moet> is there some requirement that a typeclass have a concrete (*) type?
22:32:03 <moet> >:kind! Num
22:32:27 <moet> ok, the bot doesn't like that but it prints 'Num :: * -> Constraint' for me
22:33:38 <moet> is there any trick defining instances of standard classes over a closed set of types (lifted by datakinds)  .. eg.. 'data T = A | B'
22:34:11 <moet> instance Num 'A where ... fails because `'A :: T` but `Num :: * -> Constraint`
22:39:10 <moet> nevermind.. the problem was a stuck type family upstream .. 
22:41:48 <moet> now i have questions about stuck type families if anybody has their polykinds hat on
22:42:02 <moet> otherwise i'll just figure it out
22:43:27 <quarters> hello. I'm following http://learnyouahaskell.com/syntax-in-functions and noticed that type declarations are shown above every function.  Is this something that can be replicated in the ghci repl?  when I try it, I get <interactive>:18:1: error:
22:43:27 <quarters>     • No instance for (Show (Integer -> String))
22:43:27 <quarters>         arising from a use of ‘print’
22:43:27 <quarters>         (maybe you haven't applied a function to enough arguments?)
22:43:28 <quarters>     • In a stmt of an interactive GHCi command: print it
22:47:34 <moet> quarters: yes, there are two ways https://termbin.com/zngt
22:48:09 <moet> quarters: one is to type a one-liner lambda on the rhs of a let, parenthesize the whole lambda, and then give it a type
22:48:37 <moet> quarters: the other is to write a multi-line-function just as you would in a file, by preceding it with :{ and then following it with :}
22:48:46 <moet> see the paste at https://termbin.com/zngt
22:49:56 <quarters> moet: awesome. thank you!
22:53:20 <moet> does making a type-family have a result of kind `k` automatically make the type family "stuck"? is there a way to inspect the result?
22:55:25 <Axman6> :kind! should show you it in as evaluated for as possible
22:55:54 <Axman6> (that's probably not a precide definition of what it does, but :kind! is probably what you're after)
22:58:41 <moet> Axman6: hrm.. that tool does help me to identify the problem but my question is more about what the meaning of a polymorphic typeclass is
22:59:00 <moet> Axman6: if you have a sec, take a look at this minimal example: https://termbin.com/n79h
22:59:35 <moet> in the example, i've made a type family that seems to be useless, because it is stuck due to its polymorphic result
23:01:10 <dminuoso> moet: No, typeclasses can have instances for non-* types as well. See Functor
23:01:34 <dminuoso> Oh, scrolled up again.
23:02:15 <Axman6> this is definitely beyond my knowledge of these things
23:03:13 <moet> dminuoso: heh, yeah, i realized the issue with that typeclass was actually the stuck type family not resolving to the type which matched the typeclass :)
23:03:31 <moet> Axman6: thanks for taking a look anyhow.. it's beyond my knowledge too!
23:03:39 <dminuoso> Im surprised this typechecks at all
23:03:59 <dminuoso> Or kindchecks, rather
23:04:33 <moet> dminuoso: it does admittedly require like 4 extensions
23:04:49 <keltono> try `:t funcName`
23:04:58 <keltono> whoops, wrong channel
23:05:03 <dminuoso> moet: which ones?
23:05:11 <dminuoso> TypeFamilies and PolyKinds presumably
23:05:13 <dminuoso> Which else?
23:05:18 <moet> DataKinds and KindSignatures
23:05:30 <dminuoso> Ah, well those make sense too
23:05:35 <moet> Though DataKinds is probably only because i used tuple on RHS
23:05:37 <dminuoso> Right
23:05:47 <dminuoso> You could alternatively say
23:05:54 <dminuoso> % type family TF (a :: *) :: k
23:05:54 <yahb> dminuoso: 
23:06:02 <dminuoso> % type instance TF Bool = Type
23:06:02 <yahb> dminuoso: ; <interactive>:102:25: error:; Ambiguous occurrence `Type'; It could refer to; either `Language.Haskell.TH.Type', imported from `Language.Haskell.TH' (and originally defined in `Language.Haskell.TH.Syntax'); or `Data.Kind.Type', imported from `Data.Kind' (and originally defined in `GHC.Types')
23:06:19 <dminuoso> % type instance TF Bool = Data.Kind.Type
23:06:19 <yahb> dminuoso: 
23:06:25 <dminuoso> % type instance TF Int = Data.Kind.Type -> Data.Kind.Type
23:06:25 <yahb> dminuoso: 
23:08:05 <moet> % :kind! TF Bool
23:08:05 <yahb> moet: k; = TF Bool
23:08:09 <moet> % :kind! TF Int
23:08:10 <yahb> moet: k; = TF Int
23:08:14 <moet> also stuck?
23:08:28 <dminuoso> I dont think "stuck" is the right terminology here
23:08:41 <dminuoso> % :kind! TF Int
23:08:41 <yahb> dminuoso: forall {k}. k; = TF Int
23:08:56 <dminuoso> (I added :set -fprint-explicit-foralls in a query)
23:09:09 <dminuoso> So it returns a polymorphic kind
23:09:21 <moet> yes, i think it's because k cannot be both * and (* -> *) at the sametime
23:09:26 <dminuoso> The confusing thing is why the tf instances type check at all, because `Type` is certainly *not* polymorphic
23:10:08 <dminuoso> But then again, I only know how you can have polymorphic kinds in negative positions (say like Const)
23:10:16 <dminuoso> Or *polymorphic types rather
23:10:40 <dminuoso> Let's say we did
23:10:52 <dminuoso> % data C (forall k. t :: k) = C
23:10:52 <yahb> dminuoso: ; <interactive>:111:9: error:; Unexpected type `forall k. t :: k'; In the data declaration for `C'; A data declaration should have form; data C a = ...
23:11:24 <dminuoso> Oh that's not allowed?
23:11:59 <glguy> % :kind! TF Bool :: *
23:11:59 <yahb> glguy: *; = *
23:12:10 <glguy> % :kind! [TF Bool]
23:12:10 <yahb> glguy: *; = [*]
23:12:33 <moet> % :kind! [TF Int]
23:12:33 <yahb> moet: *; = [* -> *]
23:12:37 <moet> oh, wow..
23:12:39 <dminuoso> Is it possible this tyfam crosses universes and returns a proper kind?
23:12:51 <dminuoso> (Sort of TypeInType)
23:13:12 <dminuoso> No this is still weird
23:13:13 <glguy> You have to know the desired result kind to know which TF instance to use
23:13:36 <glguy> % type instance TF Bool = (->)
23:13:37 <yahb> glguy: 
23:13:40 <dminuoso> glguy: What's the meaning of `TF Bool` without a kind signature then?
23:14:32 <dminuoso> % type instance TF Bool = Int
23:14:32 <yahb> dminuoso: ; <interactive>:103:15: error:; Conflicting family instance declarations:; TF Bool = * -- Defined at <interactive>:103:15; TF Bool = Int -- Defined at <interactive>:123:15
23:14:35 <dminuoso> % type instance TF Bool = Const
23:14:35 <yahb> dminuoso: ; <interactive>:119:15: error:; Conflicting family instance declarations:; TF Bool = (->) -- Defined at <interactive>:119:15; forall {k}. TF Bool = Const -- Defined at <interactive>:124:15
23:14:36 <dminuoso> Oh
23:14:40 <glguy> % :kind! TF Bool :: * -> * -> *
23:14:40 <yahb> glguy: * -> * -> *; = (->)
23:14:54 <glguy> % :kind! TF Bool :: *
23:14:54 <yahb> glguy: *; = *
23:14:57 <dminuoso> Interesting, so this tyfam is essentially parametrized over not just a type, but a kind as well?
23:15:29 <glguy> Yeah, this is relying on PolyKinds to work
23:16:42 <moet> soo.... this makes sense, kinda .. the result is polymorphic so we need to either infer or annotate the result for it to be computed
23:16:47 <dminuoso> Is this interaction documented anywhere in the GHC manual? I cant seem to find a reference in either the tyfam nor polykinds sections
23:19:03 <moet> glguy: dminuoso: thanks
23:20:23 <dminuoso> glguy, moet: Ah I think I found a reference. It's a bit short but it's there https://ghc.gitlab.haskell.org/ghc/doc/users_guide/exts/poly_kinds.html?highlight=polykinds#kind-inference-in-closed-type-families
23:20:34 <dminuoso> So these are called "kind-indexed type families"
23:22:31 <moet> i see that; it's rather brief... thank yo
23:23:19 <moet> since my only purpose was to create typeclass instances of the RHS of this type family, it's not going to work i think.. i'll take to take another approach!
23:40:53 <glguy> What was the original thing you were trying to do?
23:53:05 <bahamas> how do I get out of multiline mode in ghci? meaning, I just pasted a multiline string and noticed that the prompt changed from "ghci> " to "Prelude|". using the command `:unset +m` didn't change the prompt
23:55:11 <dminuoso> bahamas: :unset +m works for me
23:55:23 <dminuoso> bahamas: Perhaps this only works outside a multiline block?
23:56:24 <bahamas> dminuoso: ok, I found that Ctrl+D gets me back to `ghci> `. but the variable that I defined in the multiline mode is not available anymore
23:56:52 <dminuoso> bahamas: Oh you mean manually leave a multiline block?
23:57:03 <bahamas> I basically have a multiline string that I want to clean.
23:57:19 <bahamas> that's what I'm trying to accomplish
23:59:53 <dminuoso> % (&) = fromIntegral
23:59:53 <yahb> dminuoso: 
23:59:58 <dminuoso> % (10&)
23:59:58 <yahb> dminuoso: 10
