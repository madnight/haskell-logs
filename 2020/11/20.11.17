00:03:49 <PacoV> Hi there.
00:04:09 <andreabedini[m]> hi PacoV 
00:04:45 <PacoV> I've this type `Data.HashMap.String.HashMap String String` and I need to make it derive from Data.Binary.Binary to use it in Hakyll.
00:05:04 <PacoV> I've absolutely no idea how to do this.
00:05:37 <PacoV> I see that Data.HashMap.Map k e derives from Binary if k and e do too.
00:05:54 <PacoV> But why not the strict version?
00:06:23 <PacoV> https://hackage.haskell.org/package/binary-0.10.0.0/docs/src/Data.Binary.Class.html#line-645
00:08:32 <andreabedini[m]> I don't think there's any particular reason, perhaps suggest the author of the package to add an instance for strict maps too? if this is blocking you, you can always roll your own
00:09:03 <c_wraith> They're not different data types
00:09:26 <c_wraith> Data.HashMap.Strict.HashMap and Data.HashMap.HashMap are the same data type
00:09:49 <PacoV> I'm new enough to Haskell not to know how to roll my own tbh.
00:09:53 <c_wraith> the difference is the functions exported by their respective modules to work on them
00:11:13 <PacoV> c_wraith: Data.Hash
00:11:33 <PacoV> c_wraith: Data.HashMap.Map and Data.HashMap.String.HashMap are not the same right?
00:11:46 <andreabedini[m]> right, I forgot how it works. Both the .Lazy and the .Strict module re-export the same Map data type from .Internal
00:11:53 <c_wraith> Data.HashMap.String doesn't exist
00:12:00 <PacoV> I need the strict version of the map as I read it from a yaml file.
00:12:04 <c_wraith> I presume you mean Data.HashMap.Strict
00:12:08 <PacoV> Typo, sorry.
00:12:16 <PacoV> Force of the habbit :-)
00:14:03 <c_wraith> Both Data.HashMap.Strict and Data.HashMap.Lazy re-export Data.HashMap.Internal for their HashMap type
00:14:13 <c_wraith> The difference is the functions, not the types
00:15:44 <c_wraith> The problem I can see is that neither binary nor unordered-containers depends on the other, so neither one can have the instance you want
00:15:53 <c_wraith> If there is such an instance, it's orphaned in another package
00:17:30 <PacoV> Not sure what on orphaned package is yet.
00:18:09 <c_wraith> instances are orphans if they're not defined with either the type or the class
00:18:52 <PacoV> This code http://ix.io/2Erx gives me http://ix.io/2Erz.
00:19:14 <c_wraith> I don't see any package that suggests by its name or short description that it provides such an instance
00:20:04 <PacoV> I'm okay to write my own.
00:20:16 <PacoV> I juste don't know how :-/
00:20:19 <c_wraith> Binary has instances for containers, not unordered-containers
00:20:25 <c_wraith> is there any reason you can't use that?
00:20:41 <c_wraith> (there's rarely a reason to require unordered-containers)
00:21:17 <merijn> c_wraith: Usually the reason people have is "HashMaps are faster!!", which is a sentiment I blame on Python and JS :p
00:21:27 <PacoV> Well, the strict map is in unordered and I need the strict one to read it using Data.Yaml.
00:21:44 <PacoV> I don't care about performances here.
00:21:53 <PacoV> My maps will be small anyway.
00:23:21 <c_wraith> Ah.  "depending on a library written by someone who thinks hashing is automatically fast" is the second-most common reason
00:23:45 <c_wraith> Converting between the types is a one-liner, if you don't count the imports
00:23:50 <ocamler> anyone know if a way to pattern match on a file stream lazily, so that I can for example match on 
00:24:19 <PacoV> c_wraith: I'll look into this.
00:24:26 <dminuoso> ocamler: You'd use a streaming library.
00:24:30 <ocamler> "s" : ":" : a : b : c : xs
00:24:59 <ocamler> and it will read constant space
00:25:00 <dminuoso> You can also use lazy IO and just pattern match like that, but streaming tends to give less headaches
00:25:02 <c_wraith> depending on how sloppy you want to be....  readFile gives you that.
00:25:04 <dminuoso> Then streaming.
00:25:09 <dminuoso> If you want constant space.
00:25:11 <dminuoso> No way around it
00:25:47 <dminuoso> Look into conduit, pipe, streaming, etc
00:25:52 <c_wraith> meh.  streaming libraries don't guarantee constant space either.  If you generate an arbitrary-size data structure, they use arbitrary space
00:25:52 <ocamler> i see, nd pointers to a library? does conduit work here
00:26:07 <ocamler> ah yeah in my case messages are constant sized
00:26:19 <dminuoso> Sure, conduit would work
00:28:05 <PacoV> c_wraith: there is no function is the libs right, I've to write it.
00:28:25 <c_wraith> It's just toList and fromList
00:29:31 <dminuoso> c_wraith: That's just necessity vs sufficiency. It is necessary to use a streaming library if you want constant-space. :p
00:29:31 <c_wraith> https://hackage.haskell.org/package/unordered-containers-0.2.13.0/docs/Data-HashMap-Strict.html#v:toList and https://hackage.haskell.org/package/containers-0.6.4.1/docs/Data-Map-Strict.html#v:fromList
00:29:37 <dminuoso> But certainly not sufficient.
00:30:13 <c_wraith> Meh, I'm perfectly capable of using readFile in constant space - and perfectly capable of bailing out and saying it's the wrong tool for some problems.
00:32:51 <dminuoso> Well yeah, perhaps necessary is a bit too strong. But it's a lot more hassle to guarantee constant space because you have to be mindful of strictness, about accidentally leaving references
00:33:17 <dminuoso> (And the GHC simplifier can stab you in the back if it creates sharing where you dont expect it to)
00:33:58 <dminuoso> It's hard to guarantee constant space and deterministic behavior with lazy IO
01:04:02 <kuribas> is considered good practice to use empty type classes as constraints?
01:04:32 <dminuoso> Considering I haven't it used in practice anywhere..
01:04:42 <dminuoso> *seen it
01:05:01 <kuribas> it's to see if a relation between phantom types holds
01:05:13 <opqdonut> yeah that sounds about right
01:05:32 <opqdonut> empty type families are common once you start doing type-level programming
01:05:52 <kuribas> opqdonut: what's an empty type family?
01:06:17 <dminuoso> I guess its similar to things like `data Direction = Left | Right`, it still falls prey to boolean blindness because it doesn't carry any proofs aroud.
01:06:18 <opqdonut> err I mean non-associated type families, which are kinda equivalent to type classes with no contents (methods)
01:07:09 <kuribas> opqdonut: you mean a boolean valued type family?
01:07:18 <opqdonut> so something like `concat :: (Add k m n) => Vec k a -> Vec m a -> Vec n a` for length-indexed lists
01:07:38 <opqdonut> no, I'm confused, ignore me
01:07:54 <opqdonut> that would be `n ~ (Add k m)` or so with type families
01:07:57 <kuribas> here Add k m n is a type class constraint no?
01:08:09 <opqdonut> yeah, I wrote the class equivalent
01:09:05 <dminuoso> In general empty typeclasses feel not very useful because you can't do much with them
01:09:34 <dminuoso> The fact that two things relate does imply some fact on the value level
01:09:54 <dminuoso> kuribas: Are these plain single typeclasses or MPTC?
01:10:00 <kuribas> then I would have 'True ~ IsSubClass k1 k2 => Object k2 -> Attribute k1 t -> m t
01:10:02 <kuribas> dminuoso: MPTC
01:10:05 <dminuoso> kuribas: with fundeps?
01:10:11 <kuribas> dminuoso: no
01:10:40 <PacoV> Hi again.
01:11:01 <PacoV> I now have this code http://ix.io/2ErU/haskell and this error http://ix.io/2ErW
01:11:20 <PacoV> What does it mean `use a standalone 'deriving instance' declaration` here?
01:11:24 <Netsu> Hello. Are type constraint synonym and typeclass alias semantically the same?
01:11:52 <PacoV> As I now have a lazy Map String String, why can't it derive from Binary?
01:12:02 <kuribas> PacoV: it means it cannot derive the Binary instance
01:12:14 <dminuoso> PacoV: GND doesnt magically figure out things, it just "pierces the newtype wrapper"
01:12:26 <kuribas> PacoV: because LTranslation is not an instance of Binary
01:12:48 <dminuoso> So when "the thing contained has some instance" then GND lets you "copy" the instance for the newtype wrapper. But it requires the contained thing to already have that instance
01:12:56 <dminuoso> PacoV: At any rate. For binary, dont use typeclasses.
01:13:00 <dminuoso> Use put/get directly
01:13:21 <dminuoso> (It's the one big wart of the library)
01:13:29 <PacoV> dminuoso: But, Map String String derives from Binary.
01:13:37 <Netsu> like `type MyAlias m = (MonadA m, MonadB m)` and `class (MonadA m, MonadB m) => MyAlias m`. Is it the same, or second approach more nominal and require explicit instance declaration on the such constrained type? 
01:13:48 <kuribas> PacoV: maybe you want this?  http://hackage.haskell.org/package/binary-instances-1
01:13:59 <dminuoso> Netsu: They are not the same
01:14:02 <Netsu> Would instanced be resolved in same way in both cases
01:14:19 <dminuoso> Netsu: MyAlias *implies* MonadA and MonadB, so its stronger
01:14:27 <dminuoso> Say, there could be things MonadA and MonadB but not MyAlias
01:15:06 <dminuoso> And it does indeed require explicit instances
01:15:29 <dminuoso> Even if MyAlias is empty, GHC couldnt magically just induce instances from that. What if MyAlias demands extra laws?
01:16:13 <dminuoso> Netsu: Also the superclass version is more composable
01:16:50 <dminuoso> Oh, it's not. Interesting TIL
01:17:01 <PacoV> kuribas: that looks good. I'll see how to use it. Simply import Data.Binary.Instances.UnorderedContainers ?
01:17:03 <kuribas> dminuoso: In my case, the difference on value level is that one will be that without the constraint, you can generate queries which will generate an error.  However that is on the remote service, not in my program.
01:17:09 <kuribas> PacoV: yes
01:17:25 <PacoV> And, if I get you people right, 
01:17:37 <PacoV> i've to remove the newtype wrapper.
01:18:07 <Netsu> dminuoso: thank you a lot! Could you describe in more details, please? So first case (type constraint alias) -- it equal. And second one (type class) -- it just implies?
01:18:27 <kuribas> dminuoso: if I fetch an attribute for an object of the wrong class, the remote server will return an error.
01:38:36 <PacoV> It works!
01:38:47 <PacoV> \o/ Yeah \o/
01:38:51 <PacoV> Thanks all!
01:40:22 <PacoV> Damn... Same problem with Writable now...
01:43:22 <PacoV> Wich was easy, it works.
01:50:55 <dminuoso> Netsu: Right. If a class constraint is satisfied, that implies the superclass constraints.
01:52:07 <Netsu> thanks
02:59:52 * hackage haskoin-core 0.17.2 - Bitcoin & Bitcoin Cash library for Haskell  https://hackage.haskell.org/package/haskoin-core-0.17.2 (jprupp)
03:03:52 <nut> is bytestring a list of word8?
03:04:05 <nut> in the bytestring package
03:04:12 <merijn> nut: Define "is"
03:05:18 <merijn> Conceptually? Maybe. Is it implemented as a list? Definitely not.
03:05:18 <nut> well, i have a utf-8 string and i want to keep until it sees a \n
03:05:46 <nut> I don't know how to represent \n in Word8
03:05:47 <merijn> nut: Pretend the "String" part of ByteString doesn't exist
03:05:50 <merijn> ByteString = Bytes
03:06:12 <merijn> If you have unicode text, then you don't want ByteString
03:06:42 <nut> then I check the bytestring APIs, and I realize that conceptually a Bytestring is a list of Word8
03:06:55 <nut> Which would you recommend?
03:07:09 <merijn> nut: You probably want "decodeUtf8' :: ByteString -> Either UnicodeException Text" :)
03:07:12 <merijn> https://hackage.haskell.org/package/text-1.2.4.0/docs/Data-Text-Encoding.html#v:decodeUtf8-39-
03:07:33 <merijn> Alternatively, you can use decodeUtf8With to explicitly specify how to handle decoding errors
03:07:52 <nut> But I see there's also the Data.ByteString.Lazy.Char8
03:08:18 <merijn> https://github.com/quchen/articles/blob/master/fbut.md#bytestringchar8-is-bad
03:08:20 <nut> I thought that's supposed to be useful for mixed texual and binary data
03:08:34 <nut> Ok let me dig in
03:08:38 <merijn> nut: Char8 is a great way to silently corrupt your data! :)
03:09:28 <nut> So go with the text package right?
03:09:56 <merijn> nut: Text is almost always the right choice when you're, well, dealing with text :p
03:10:43 <merijn> Plus conversion to/from String (via pack/unpack) and to/from ByteString (via Data.Text.Encoding) is easy and well-defined
03:10:43 <nut> thx for the tip
03:11:26 <merijn> :t Data.Text.takeWhile
03:11:28 <lambdabot> (Char -> Bool) -> Data.Text.Internal.Text -> Data.Text.Internal.Text
03:11:33 <merijn> :t Data.Text.takeWhile (=='\n')
03:11:34 <lambdabot> Data.Text.Internal.Text -> Data.Text.Internal.Text
03:11:45 <merijn> nut: That solves your problem right away ;)
03:11:54 <merijn> eh
03:12:04 <merijn> takeWhile (/='\n'), of course :p
03:12:15 <nut> nice
03:27:58 <zenzike> I was looking at `RandomGen` and saw that `next` is deprecated due to poor performance. That makes sense if the default naive definition is used. However, it seems that `splitmix` provides its own `nextInt` which seems fine and is used in the instance of `StdGen` (which is `SMGen`). Am I missing something obvious?
03:37:22 * hackage haskoin-store-data 0.38.1 - Data for Haskoin Store  https://hackage.haskell.org/package/haskoin-store-data-0.38.1 (jprupp)
03:38:22 * hackage haskoin-store 0.38.1 - Storage and index for Bitcoin and Bitcoin Cash  https://hackage.haskell.org/package/haskoin-store-0.38.1 (jprupp)
03:39:21 <dminuoso> nut: Just to show how ByteString <> String confusion can be very surprising. Do you know how ByteString has an IsString instance, such that you can use OverloadedStrings for ByteString?
03:42:22 <kuribas> do you have a stragegy for versioning data?
03:43:05 <kuribas> an easy way I came up with was: simply update the data type, but pass a version number to functions.
03:43:53 <kuribas> so for sum types I could simply add clauses.
03:44:26 <kuribas> then each function has a "rest clause" that raises an error: myFun _ = error "unsupported field."
03:47:10 <kuribas> but then the burden to not break previous code is on the programmer.
03:47:52 * hackage microlens 0.4.12.0 - A tiny lens library with no dependencies  https://hackage.haskell.org/package/microlens-0.4.12.0 (Artyom)
03:48:53 * hackage microlens-platform 0.4.2, microlens-ghc 0.4.13, microlens-th 0.4.3.7 (Artyom): https://qbin.io/came-wage-exrj
04:24:12 <merijn> kuribas: My strategy is, convert old data to latest format on input and write code only against the latest format
04:24:38 <merijn> kuribas: The problem becomes limited to 1) detecting old input formats and 2) writing conversion logic
04:25:11 <kuribas> merijn: we have the opposite problem.  When we do computations, we should not use new computations on old data, only new data.
04:25:37 <kuribas> merijn: because otherwise the customer will be surprised their data changed.
04:26:00 <kuribas> so I want some versioning system where I can pass the version number to the computation, and it picks the right version.
04:26:07 <merijn> That's the same problem, except you can skip conversion forwards :p
04:26:25 <kuribas> and the compotation is a GADT describing what needs to be done (and can be serialized to disk).
04:27:24 <kuribas> merijn: you mean, convert to the latest format, but have custom logic for each version?
04:27:52 <kuribas> I wonder how to make it manageable...
04:28:28 <lortabac> kuribas: you need a way to convert from any version to the latest one
04:28:28 <opqdonut> that's the question various sql migration libraries have been trying to answer for ages
04:28:32 <dminuoso> 13:23:50    merijn | kuribas: My strategy is, convert old data to latest format on input and write code only against the latest format
04:28:34 <dminuoso> 13:24:49   kuribas | merijn: we have the opposite problem.  When we do computations, we should not use new computations on old data, only new data.
04:28:36 <dminuoso> How is that opposite?
04:28:42 <dminuoso> It sounds *exactly* like whe merijn suggests
04:29:08 <opqdonut> keeping around rich enough test data for all those conversions is the hard part in my experience
04:29:14 <kuribas> dminuoso: because the old logic should remain exactly the same
04:29:15 <opqdonut> the slow code bloat in itself isn't that bad
04:30:01 <kuribas> dminuoso: it's not new logic against old data, it's old logic against new data.
04:30:18 <lortabac> kuribas: if you only add and remove fields (never modify) it is more manageable
04:30:25 <dminuoso> opqdonut: I dont think its that complex of a problem. We just maintain a list `[Migration]` where `data Migration = Migration { migVersion :: Integer, migQuery :: Connection -> IO () }`, imho most "migration libraries" are just overengineered solutions because people seem to be afraid to write 5 lines of code for themselves.
04:31:10 <kuribas> lortabac: that's a way of course.  If I modify a function, represented by SomeFun in the GADT, I could make a new one SomeFunV2 when I modify SomeFun.
04:32:51 <lortabac> kuribas: most of the time when you add a new field the conversion function will simply provide some default value (ex. Nothing) on the fields that were missing
04:33:08 <opqdonut> dminuoso: I agree
04:34:28 <lortabac> then you have to ensure that the new logic does not do anything new when that field has the default value
04:34:37 <merijn> kuribas: That just means you need a "Map Version YourComputation" and do a lookup
04:35:15 <merijn> kuribas: I wouldn't bother with fancy polymorphic solutions, just keep a copy of each old version in a separate module and call as appropriate
04:35:29 <kuribas> merijn: or just compute :: Version -> ComputationExpression -> Result
04:36:15 <merijn> Either way, although having a data structure might be more convenient to keep up to date
04:36:22 * hackage hmatrix 0.20.1 - Numeric Linear Algebra  https://hackage.haskell.org/package/hmatrix-0.20.1 (DominicSteinitz)
04:36:34 <merijn> kuribas: https://github.com/merijn/Belewitte/tree/master/benchmark-analysis/src/Schema/Model
04:36:37 <merijn> kuribas: https://github.com/merijn/Belewitte/blob/master/benchmark-analysis/src/Schema/Model.hs#L71-L215
04:37:12 <merijn> kuribas: You can skip the data migration and instead dispatch
04:37:13 <kuribas> merijn: right, I could import the functions that haven't changed from the previous version...
04:37:40 <merijn> kuribas: Whenever I change the schema, I copy the old schema into a new V<n> module and import it qualified, then call it
04:38:03 <merijn> You get a lot of modules, but maintenance is a breeze (i.e. there is none :p)
04:38:33 <kuribas> the only worry I have is that you'ld need to dig through different versions of the module to find the implementation...
04:39:36 <kuribas> for example I have sumNumbers :: [Double] -> Double which hasn't changed from V3 through V1, then I would need to look in V3, then V2, then V1...
04:39:59 <kuribas> well I guess emacs or vscode where to find it...
04:40:20 <kuribas> merijn: alright, I'll give it a try :)
04:44:21 <Axman6> kuribas: have you seen what acid-state/the library it uses does?
04:48:17 <kuribas> Axman6: yes, some time ago, I don't remember it that well.
04:48:21 <kuribas> but I prefer a simple solution
04:50:08 <merijn> safe-copy
04:50:27 <merijn> Axman6: But that's basically the same scheme I proposed, but with TH
04:56:40 <kuribas> I prefer boring haskell :)
05:00:56 <aplainzetakind> What do I need to do to make a local library available to a v2-style build environment (specifically asking for xmonad-contrib to build xmonad from the repo).
05:02:00 <merijn> aplainzetakind: As in you have package A and B both locally, with A depending on the local copy of B?
05:02:33 <aplainzetakind> Yes.
05:02:55 <merijn> You'll want a cabal.project/cabal.project.local file
05:02:57 <merijn> aplainzetakind: https://cabal.readthedocs.io/en/latest/nix-local-build.html#local-versus-external-packages
05:02:59 <__monty__> aplainzetakind: I think you'll want to add a package stanza in cabal.project.
05:03:17 <aplainzetakind> Thanks.
05:03:18 <merijn> https://cabal.readthedocs.io/en/latest/cabal-project.html#specifying-the-local-packages
05:14:33 <m0b10s> Hi, just one question, if i have a tuple and i need to take one element “index i” but i have difrent types on the tuple, is it possible to take the element índex x with just one function?
05:19:40 <p0a> m0b10s: It should be, tuples don't need to have the same type
05:20:10 <p0a> m0b10s: for example, fst (1, 'a') ==> 1
05:20:33 <merijn> No, I think he wants a numerical indexing to extract from a tuple
05:20:41 <merijn> And the answer is "no, you can't write that"
05:20:57 <hc> I think you can, with 'hacks'...
05:20:58 <merijn> At least, not without a bunch of super ugly nightmarish extensions and mess
05:21:14 <hc> like fun :: Int -> Tuple -> Maybe a
05:21:27 <hc> where fun returns either a Just a or Nothing if the types don't match
05:22:35 <dminuoso> % (1, 'a') ^. _2
05:22:35 <yahb> dminuoso: 'a'
05:22:41 <dminuoso> % (1, 123, "foobar") ^. _2
05:22:41 <yahb> dminuoso: 123
05:22:51 <dminuoso> % (1, "str, 123, 'a') ^. _2
05:22:51 <yahb> dminuoso: ; <interactive>:159:26: error: lexical error in string/character literal at end of input
05:22:57 <dminuoso> % (1, "str", 123, 'a') ^. _2
05:22:57 <yahb> dminuoso: "str"
05:22:59 <dminuoso> m0b10s: This?
05:24:04 <PacoV> Hey again!
05:24:26 <hc> % :t (^.)
05:24:26 <yahb> hc: forall {s} {a}. s -> Getting a s a -> a
05:24:41 <hc> dminuoso: this will fail hard when the types don't match?
05:24:49 <hc> % (1, "str") ^. _1 == "foo"
05:24:49 <yahb> hc: ; <interactive>:162:2: error:; * No instance for (Num [Char]) arising from the literal `1'; * In the expression: 1; In the first argument of `(^.)', namely `(1, "str")'; In the first argument of `(==)', namely `(1, "str") ^. _1'
05:24:51 <hc> ah :)
05:25:06 <m0b10s> diminuoso, it’s that, but in a funcion... i think the “maybe” type is what i’m looking for! =)
05:25:20 <m0b10s> ty hc 
05:25:40 <PacoV> Thanks to you I was able to write http://ix.io/2EsV/haskell which is supposed to be a clean rewrite at my take in I18n of Hakyll that you can find here https://gitlab.com/swi18ng/swi18ng
05:25:55 <dminuoso> m0b10s: well you can just
05:26:03 <PacoV> Now, the real question : why is the new code failing on yaml parsing?
05:26:04 <dminuoso> % getFirst = (^. _1)
05:26:05 <yahb> dminuoso: 
05:26:08 <dminuoso> % :t getFirst -- m0b10s 
05:26:08 <yahb> dminuoso: forall {s} {b}. Field1 s s b b => s -> b
05:26:14 <xerox_> curl ghcup ... Unknown architecture: arm64 ... aw :|
05:26:19 <dminuoso> Admittedly, the type is awkward, but it works!
05:27:15 <dminuoso> hc: What do you mean "fail hard"?
05:27:30 <p0a> will `data List = Null | List a (List b)' with your own (!!) for it work?
05:27:35 <hc> m0b10s: have a look at https://hackage.haskell.org/package/vault , that's where i got the idea
05:27:45 <maerwald> xerox_: wip
05:27:50 <hc> dminuoso: I mean a run time error, I guess
05:27:55 <dminuoso> p0a: If you implement a Field1 instance for it, sure
05:28:04 <Orbstheorem> Hi o/ Why are ReaderT classes injective? I would like to run two Readers under the same monadstack.
05:28:08 <xerox_> maerwald: makes sense :)
05:28:11 <maerwald> xerox_: https://gitlab.haskell.org/haskell/ghcup-hs/-/issues/12
05:28:14 <dminuoso> Orbstheorem: Because newtypes are injective?
05:28:59 <dminuoso> Orbstheorem: Is "injective" really the word you mean to use here?
05:29:21 <dminuoso> In principle, you can run two ReaderT if you want, nothing prevents you from that.
05:30:12 <prez> @free x :: (((a -> b) -> b) -> c) -> c
05:30:12 <lambdabot> (forall q f1. (forall f2 f3. g . f2 = f3 . f                             =>                              g (q f2) = f1 f3)              =>               h (k q) = p f1) => h (x k) = x p
05:30:24 <dminuoso> Orbstheorem: It's probably better to just use `ReaderT (e1, e2)` instead of multiple ReaderT though
05:30:31 <Orbstheorem> dminuoso: Maybe injective is not the right word then. I see `MonadReader r m | m -> r` in the class definition.
05:30:36 <dminuoso> That's a functional dependency
05:30:44 <Orbstheorem> Oh, my bad.
05:30:47 <dminuoso> Also note that MonadReader /= ReaderT
05:30:56 <dminuoso> Albeit related, they are very much different things
05:31:15 <Orbstheorem> Yes, I'm probably a bit distracted :(
05:31:38 <dminuoso> Orbstheorem: Anyway. Use ReaderT with a tuple.
05:31:46 <dminuoso> Or data if you have even more things
05:31:49 <Orbstheorem> Anyways, I want to run `MonadReader Foo m` and `MonadReader Bar m` under the same monad stack.
05:32:22 <dminuoso> data Env = Env { envA :: A, envB :: B, envC :: C }; newtype T a = T { runT :: ReaderT Env (...) }
05:32:30 <dminuoso> Orbstheorem: ^- use that. either with data or (,)
05:33:00 <dminuoso> You can mix that with lens/optics and classy lenses (or at least mimic it) for convenient access
05:33:10 <dminuoso> say
05:33:13 <p0a> m0b10s: right, so you can stack tuples like (1, ('a', ("b", ⊥))) and then write (!!) 0 (x,_) = x ; (!!) n (_, xs) = !! (n - 1) xs 
05:33:17 <reactormonk> If I have a Recursive and a Corecursive instance for my AST structure (with recursion-schemes) can I write a Traversal' lens with these?
05:33:59 <Orbstheorem> Maybe there's something I fail to see, but that would imply that my consumers need to be aware of the structure of `Env` instead of just its components.
05:34:36 <dminuoso> Orbstheorem: It depends, either they need to be aware of Env, or you can use classy lenses (or something akin to them) 
05:34:39 <dminuoso> so say
05:34:56 <dminuoso> % data Foo { _fooInt :: Int; _fooChar :: Char }
05:34:56 <yahb> dminuoso: ; <interactive>:165:26: error: parse error on input `;'
05:35:03 <dminuoso> % data Foo = Foo { _fooInt :: Int; _fooChar :: Char }
05:35:03 <yahb> dminuoso: ; <interactive>:166:32: error: parse error on input `;'
05:35:15 <dminuoso> % data Foo = Foo { _fooInt :: Int, _fooChar :: Char }
05:35:15 <yahb> dminuoso: 
05:35:20 <m0b10s> p0a, what would be the signature in that case? 
05:36:04 <dminuoso> % $(makeLenses ''Foo)
05:36:04 <yahb> dminuoso: ; <interactive>:173:3: error:; * Couldn't match type `[Dec]' with `Exp'; Expected type: ExpQ; Actual type: DecsQ; * In the expression: makeLenses ''Foo; In the untyped splice: $(makeLenses ''Foo)
05:36:33 <dminuoso> Orbstheorem: err, see https://hackage.haskell.org/package/optics-th-0.3.0.2/docs/Optics-TH.html#v:makeClassy
05:36:35 <Axman6> Orbstheorem: if you go the lens route, you end up with code that looks like: foo :: (HadFoo r, HasBar r, MonadReader r m) => m Thing, which you can then access (assuming you have used classy lenses) with do theFoo <- view foo; theBar <- view bar
05:36:51 <p0a> m0b10s: oh yeah, of course that is the issue :) Sorry, my solution doesn't work
05:37:08 <Orbstheorem> Axman6: Yes, that's what I feared.
05:37:20 <dminuoso> Orbstheorem: You can mimic classy lenses without going all in on lenses.
05:37:24 <dminuoso> Say by writing
05:37:39 <dminuoso> class HasFoo e where foo :: e -> Foo
05:37:44 <dminuoso> class HasBar e where bar :: e -> Bar
05:37:48 <Axman6> it's quite pleasant to use, because your code only declares what parts of the environment it needs to know about, and can't access anything it doesn't declare, meaning you know know more about what your code can do, and you don't need to define a data type which everything depends on
05:37:50 <Orbstheorem> Yes, I've manually implemented it with `MonadReader a m, Convertible a Foo` in the past.
05:37:56 <dminuoso> And then you can just write `do f <- asks foo`
05:38:04 <dminuoso> No lens needed, same idea
05:38:27 <Orbstheorem> Oh well.
05:38:32 <Orbstheorem> Thanks ^^
05:38:45 <Orbstheorem> I think I'll go the classy way just to learn lenses.
05:39:10 <xerox_> maerwald: was it you that posted ghc-9.1.0.20201110-aarch-apple-darwin.tar.xz?
05:39:30 <maerwald> posted?
05:39:42 <xerox_> I forget who linked me to it
05:39:46 <Axman6> in the mail
05:39:49 <Axman6> :)
05:40:36 <Axman6> xerox_: could have been angerman or bgamari
05:40:57 <xerox_> oh yeah angerman thanks
05:41:01 <xerox_> I wonder how one uses it :)
05:41:22 <angerman> xerox_: https://www.dropbox.com/s/jskw2pjpkhquj4g/ghc-9.1.0.20201110-aarch64-apple-darwin.tar.xz?dl=0
05:41:36 <xerox_> angerman: can I pm you?
05:41:53 <prez> @free it :: Applicative f => f ((((a -> b) -> b) -> c) -> c)
05:41:53 <lambdabot> Extra stuff at end of line
05:41:54 <angerman> xerox_: unpack, ./configure --prefix=/path/to/install/in, make install
05:42:40 <angerman> xerox_: how you'd use any other ghc binary distribution. You'll want to bootstrap cabal after that using that ghc to provision some usable environment. Do note though that 9.1 is an in-flight build.
05:42:55 <xerox_> angerman: have been spoiled by ghcup
05:43:25 <m0b10s> Don’t know if you got the message but:Thank you all for the help! I have some ideas, time to press keys =)  (i got dc’d sry)
05:43:39 <angerman> xerox_: it's really only meant as a PoC for a aarch64/darwin NCG build. A lot of packages will likely complain about bounds
05:43:56 <xerox_> NCG standing for?
05:44:01 <angerman> xerox_: if all you want is to use ghc on arm macs, you can just use x86_64/darwin builds. Rosetta does just fine.
05:44:27 <xerox_> I see, native code generation, avoiding llvm now I remember
05:44:29 <prez> @free it :: f ((((a -> b) -> b) -> c) -> c)
05:44:29 <lambdabot> Extra stuff at end of line
05:44:29 <angerman> xerox_: native code generator backend (as opposed to the llvm backend); the pretty much only benefit is that it's substantially faster.
05:56:22 * hackage ghc-events 0.14.0 - Library and tool for parsing .eventlog files from GHC  https://hackage.haskell.org/package/ghc-events-0.14.0 (MitsutoshiAoe)
06:00:17 <xerox_> angerman: that was a good suggestion thanks
06:10:23 * hackage require 0.4.10 - Scrap your qualified import clutter  https://hackage.haskell.org/package/require-0.4.10 (NickSeagull)
06:23:30 <mlugg> How does GHC flatten pattern matches (specifically, in case expressions) when converting to Core? Is there a neat algorithm for it?
06:25:46 <lortabac> mlugg: https://www.microsoft.com/en-us/research/uploads/prod/1987/01/slpj-book-1987-r90.pdf
06:25:55 <lortabac> there is a chapter about pattern-matching
06:25:59 <PacoV> Hey again.
06:26:22 <PacoV> I need to use `toStrict` from bytestring.
06:26:30 <PacoV> But also pandoc.
06:26:45 <PacoV> Pandoc uses the 0.10 and toStrict is in 0.11
06:26:56 <PacoV> How am I supposed to deal with that?
06:27:03 <merijn> toStrict is in 0.10 too
06:27:13 <merijn> 0.11 just exported it from another module
06:27:41 <PacoV> Module ‘Data.ByteString.Char8’ does not export ‘toStrict’
06:27:44 <PacoV> Said ghc.
06:27:48 <merijn> iirc, toStrict/fromStrict are only exported from Data.ByteString.Lazy before 0.11 and as of 0.11 also from Data.ByteString
06:28:05 <merijn> PacoV: Because you're importing it from the wrong module
06:28:08 <mlugg> lortabac: Ah thanks, much appreciated
06:28:14 <merijn> Also https://github.com/quchen/articles/blob/master/fbut.md#bytestringchar8-is-bad
06:30:03 <PacoV> I'd use whatever you want. But telling someone who's new to Haskell that something is bad won't help.
06:30:37 <PacoV> Well, for this one, the article tells what to do.
06:30:41 <PacoV> So, my bad.
06:30:47 <merijn> :p
06:32:51 <merijn> Even if you decide you want to just ignore errors going via Text and "decodeUtf8With" is better, because you at least get to *pick* how to ignore them (i.e. replace with unicode "missing character", silently drop, replace with something else
06:32:55 <merijn> )
06:35:53 * hackage criterion 1.5.9.0 - Robust, reliable performance measurement and analysis  https://hackage.haskell.org/package/criterion-1.5.9.0 (ryanglscott)
06:39:49 <PacoV> I'll follow you article as soon as 
06:39:58 <PacoV> I'll follow you article as soon as I understand it.
06:40:40 <merijn> PacoV: How familiar are you with the difference between "unicode" and "encodings representing unicode"?
06:43:18 <PacoV> Not familiar at all at the moment :-/
06:44:06 <merijn> PacoV: Ah, then you probably will want to read this (which applies to basically all programming languages): https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/
06:46:35 <PacoV> Ho, I remember reading this a while ago.
06:46:43 <PacoV> I'll give it a second read.
06:46:52 <PacoV> Thanks!
06:47:09 <PacoV> BTW, my code works like a charm!
06:47:57 <PacoV> Time to go buy some food before my better half comes back and I'll read those two articles! Thanks again!
06:51:40 <int-e> . o O ( "works like a charm" -- if you believe in it strongly enough, under the right circumstances, after a ritual sacrifice )
06:53:18 <hekkaidekapus> merijn: You are apparently on a roll, carry on over at <https://github.com/haskell/haskell-language-server/pull/602>.
06:53:43 <merijn> ...
06:54:00 <hekkaidekapus> heh
06:54:11 <fendor> hekkaidekapus, did I do it wrong?
06:54:20 <merijn> fendor: Well, yes
06:54:32 <fendor> welp, I tried
06:54:55 <hekkaidekapus> fendor: Sorry, I’m short on time. But merijn will take care of you :)
06:55:00 <merijn> with-utf8 is a terrible package that makes me wanna stab people
06:55:16 <fendor> it was recommended on that reddit thread >_>
06:55:41 <merijn> Yes, because the internet is filled with clueless people >.>
06:55:41 <int-e> stabbing, hmm, does it have lenses?
06:56:07 <merijn> fendor: The problem is there is a no-win scenario
06:56:29 <int-e> locales are a terrible idea
06:56:44 <merijn> fendor: Basically, *some* systems have broken environments/configurations were the encoding isn't specified, then causes GHC to open handles with the wrong encoding leading to encoding errors
06:57:12 <fendor> right, so far I understood it
06:57:23 <merijn> fendor: The problem with "always UTF-8" is that it intentionally breaks for everyone who has a properly configured system with encoding different than utf-8
06:57:28 <int-e> for files, the encoding should be part of the file, not implicit in the environment
06:58:36 <int-e> merijn: there is no such thing :P
06:58:45 <merijn> fendor: So if someone in Japan is using a UTF-16 (or UTF-32) configuration system wide or something, then you are now unable to open their files, because they're not UTF-8, but you're overriding the environment
06:58:55 <fendor> and in this case, the error is more likely that the encoding of the stdout handle is wrong and it should suffice to explicitly set it, right?
06:59:05 <merijn> int-e: "encodings should be part of the file" <- sure, agreed, but that's not the world we live in
06:59:26 <merijn> "intentionally breaking a feature that has existed for over 30 years to control this" is not the right solution
06:59:46 <merijn> fendor: Well, but how do you know what encoding the terminal connected to stdout expects?
07:00:16 <merijn> fendor: You can set stdout to UTF-8 and write stuff to it, but if the terminal connected to stdout doesn't *expect* utf-8, you're outputting garbage
07:00:34 <fendor> right.
07:01:22 <merijn> The only standard way to figure out what the terminal expects is to check the locale, which is what GHC does to figure out the right encoding
07:01:54 <int-e> I'd be okay with the locale specifying what happens on terminals... it even makes sense. But AFAICS it tends to be used for everything else as well, including files that may be transferred between systems, and that makes it a huge mess unless everybody agrees on the same encoding.
07:01:56 <fendor> so, this is a user error that the user needs to fix?
07:02:32 <merijn> There was a related discussion on GHC gitlab, lemme look it up
07:03:06 <merijn> How do I search for tickets I commented on on gitlab?
07:05:43 <merijn> fendor: Related discussion: https://gitlab.haskell.org/ghc/ghc/-/issues/17755
07:06:08 <merijn> fendor: In essence the problem is that the use has his/her locale unset and/or set to the 'C' locale, which errors on non-ascii
07:06:41 <fendor> merijn, thanks will read it later!
07:07:56 <merijn> fendor: As for the issue you reference in the PR that is a cursed problem anyway
07:08:23 * hackage http-client 0.7.3 - An HTTP client engine  https://hackage.haskell.org/package/http-client-0.7.3 (MichaelSnoyman)
07:08:35 <merijn> fendor: The problem there is "can't open a file with an umlaut in the path" and I can already tell you know it's *impossible* to correctly and robustly fix/avoid this problem
07:08:48 <fendor> merijn, you make me sad :(
07:08:59 <fendor> thanks for the explanation! I have a better understanding now!
07:09:09 <merijn> fendor: Linux (possibly all of posix) has made the retarded choice to say paths are "unspecified bytes not containg NUL or /"
07:09:23 * hackage http-client-openssl 0.3.3 - http-client backend using the OpenSSL library.  https://hackage.haskell.org/package/http-client-openssl-0.3.3 (MichaelSnoyman)
07:09:37 <merijn> fendor: Since there is no encoding information in the filesystem/file API you have no clue what encoding was used to create the file
07:10:13 <merijn> And even if you know that the file was created with UTF-8 and you are using UTF-8 you *still* can't reliably open it
07:10:39 <merijn> Because ü has (at least?) two representations. As a single codepoint and as a composed codepoint
07:10:53 <merijn> And the produced byte encoding in UTF-8 is different for those two
07:11:22 <merijn> So depending on *how* the user types in ü you may get different byte sequence and thus non-existent paths
07:11:25 <merijn> Fun times!
07:12:17 <merijn> Windows was much smarter in specifying NTFS paths to be UTF-16 with a defined normalisation scheme, so you can unambiguously know how to access paths with unicode characters
07:13:33 <merijn> fendor: Making people sad is what I do. People tell me what they wanna do in the POSIX API and then I spend 10 minutes telling them they're fundamentally doomed because everything is terrible :)
07:15:00 <__monty__> Fun fact, linux and macOS tend to default to opposite normalization schemes for filenames, lots of fun to be had with rsync between those systems.
07:19:18 <nut> I have an English dictionary file encoded as utf8. There's also an index file giving the offset for each word. If I use Data.Text.IO to read in the dicionary, how can I make use of the offset info for an efficient lookup?
07:20:29 <merijn> nut: offset in *what*
07:20:43 <nut> offset in the dictionary
07:21:10 <nut> so that when people do lookup, they dont' have to pass the dictionary again and again
07:21:11 <Lycurgus> likely byte offset in a flat file
07:21:14 <merijn> offset in what? bytes? unicode codepoints? characters? lines?
07:21:20 <nut> bytes
07:21:45 <merijn> You can't really index Text in terms of bytes
07:22:11 <nut> ah, then it could be character, let me check
07:22:12 <merijn> You can read it as ByteString, do byte indexing on that, then selectively decode text starting from an offset
07:22:24 <merijn> nut: If it's character you're doomed too :)
07:22:30 <dolio> Once it's in Text all the offsets could be wrong anyway.
07:23:35 <nut> so for a Data.Text string, there's no way to move some kind of pointer within the string right?
07:23:57 <merijn> nut: You can index Text "by codepoint", maybe
07:24:44 <nut> so basically fseek equivalent
07:25:01 <merijn> nut: The real, honest answer is that: in every single programming language indexing strings is a broken clusterfuck you cannot rely on to do anything sensible (even though it may appear to do something sensible if you only ever look at ascii)
07:26:03 <nut> The offset idea does seem efficient. Without it, how do Haskell manage quick lookup?
07:26:42 <merijn> nut: Like I said, if the offset is in bytes you can easily read a bytestring and index that and then decode to Text "on demand"
07:26:56 <nut> ok I see
07:27:08 <nut> So i'll use the bytestring package instead of text
07:27:49 <nut> You gave me the hint to use text instead of bytestring a few hours ago before i went to the dentist
07:27:50 <merijn> nut: More practically for a deictionary I'd just read in the entire thing and create a Map
07:28:49 <nut> merijn: that would mean in memory lookup
07:29:01 <nut> merijn: How would you then serialize the thing?
07:30:00 <merijn> nut: I'd just write the entire thing to disk at once and read it in at once
07:30:28 <merijn> Rather than dynamically indexing an open file. You *can* dynamically index the file, but that doesn't seem worth it unless it's truly massive
07:31:19 <nut> Most dictionary files I;ve seem have some sofisticated file formate
07:31:44 <nut> Such as the stardcit file formate or dictd.org
07:32:41 <nut> It's not massive, a few hundred M only. But I want to find out for the sake of learning
07:32:45 <merijn> nut: Ah, but *that* sounds more like a different question, that sounds like "how would I parse complicated/sophisticated file formats into something usable?"
07:33:47 <nut> Those file formats are design to have less disk access times and at the same time quick search time
07:34:15 <merijn> @hoogle hSeek
07:34:15 <lambdabot> System.IO hSeek :: Handle -> SeekMode -> Integer -> IO ()
07:34:15 <lambdabot> GHC.IO.Handle hSeek :: Handle -> SeekMode -> Integer -> IO ()
07:34:15 <lambdabot> UnliftIO.IO hSeek :: MonadIO m => Handle -> SeekMode -> Integer -> m ()
07:34:17 <merijn> @hoogle hGet
07:34:17 <lambdabot> Data.ByteString hGet :: Handle -> Int -> IO ByteString
07:34:17 <lambdabot> Data.ByteString.Char8 hGet :: Handle -> Int -> IO ByteString
07:34:17 <lambdabot> Data.ByteString.Lazy hGet :: Handle -> Int -> IO ByteString
07:34:45 <nut> Indeed, at first I though there would be a Data.Text.hSeek
07:34:58 <merijn> nut: If you open a file Handle you can use hSeek to jump to offsets to read bytes from there in the file, the same way you would in other languages
07:35:21 <merijn> nut: You might also be interested in:
07:35:24 <merijn> @hackage binary
07:35:24 <lambdabot> https://hackage.haskell.org/package/binary
07:35:42 <merijn> nut: Which is a library for decoding ByteString into custom data
07:36:01 <merijn> @hackage attoparsec
07:36:02 <lambdabot> https://hackage.haskell.org/package/attoparsec
07:36:50 <dolio> You can just use the hSeek from base. Text doesn't need to provide its own.
07:37:14 <merijn> dolio: Of course hSeek and then trying to read a String is *also* cursed :p
07:37:31 <nut> There is no hSeek from base
07:37:41 <merijn> System.IO.hSeek ?
07:37:46 <nut> at least not from Prelude
07:38:07 <dolio> Prelude doesn't export everything in base.
07:38:10 <nut> i see
07:39:50 <merijn> Prelude only exports a fraction of base :)
07:44:52 * hackage hedn 0.3.0.2 - EDN parsing and encoding  https://hackage.haskell.org/package/hedn-0.3.0.2 (AlexanderBondarenko)
07:53:37 <tomjaguarpaw> merijn: Compact regions didn't help with my GC problem in the end because I realised my test cases are also generating large amounts of data!  However, I did manage to combine your System.Mem.performGC and GHC.Stats suggestions with RTS options to good effect: https://stackoverflow.com/a/64878595/997606
08:02:46 <merijn> tomjaguarpaw: Well, to be fair,if your code is producing lots of data, then perhaps including it in your benchmarks isn't so wrong :p
08:41:17 <tomjaguarpaw> Yes, but I want to benchmark the algorithm more than the code.
08:42:08 <sshine> CI/GitHub Actions question: I have a bunch of individual Haskell projects in the same repo. I'd like if they shared cache since they all use the same stack resolver. right now actions/cache@v2 uses key: ${{ matrix.resolver }}-${{ hashFiles('projects/*/package.yaml') }}, which means that if any one project file changes, the cache is invalidated for all exercises.
08:43:44 <sshine> wait, never mind. :)
08:52:46 <davean> tomjaguarpaw: The amount of data produced is a core part of the alhorithm, but you can try to seperate your code's inefficiency out.
08:52:59 <davean> tomjaguarpaw: the limiting factor on many, if not most, algs though is their memory usage.
09:18:59 <sszark> how do i install a package with cabal from github?
09:20:09 <merijn> sszark: "It Depends", are we talking "I wanna install an executable", "I want to develop against an unreleased dependency", or "I wanna install it to make accessible everywhere on my system"?
09:20:23 * hackage microlens-th 0.4.3.8 - Automatic generation of record lenses for microlens  https://hackage.haskell.org/package/microlens-th-0.4.3.8 (Artyom)
09:22:17 <sszark> merijn: i'm trying to install the git version of this. and yes, i would like it to be accessible globally. https://github.com/xmonad/xmonad-contrib
09:22:39 <merijn> And you have cabal-install >3.0?
09:23:58 <sszark> I have 3.2 merijn 
09:24:58 <merijn> sszark: Then the answer is "there's no real easy way to do that". But according to that repo's readme you need to use git version of xmonad too, in which case you can go into your git clone of xmonad and create a cabal.project file using: https://cabal.readthedocs.io/en/latest/cabal-project.html#specifying-packages-from-remote-version-control-locations
09:27:10 <sszark> Ah, i'll have a look. thanks merijn 
09:29:18 <geekosaur> the ideal way to do it is to set up a project which uses an environment, and use a build script that references the environment so you don't have to install globally. I think there's an example in the xmonad-testing repo
09:41:53 * hackage ngx-export-tools-extra 0.5.8.0 - More extra tools for Nginx haskell module  https://hackage.haskell.org/package/ngx-export-tools-extra-0.5.8.0 (lyokha)
09:55:23 * hackage easy-args 0.1.0 - Parses command line arguments  https://hackage.haskell.org/package/easy-args-0.1.0 (jlamothe)
10:08:04 <koz_> :t fromIntegral
10:08:06 <lambdabot> (Integral a, Num b) => a -> b
10:11:04 <monochrom> Don't forget that realToFrac covers many other cases. (And also overlaps with fromIntegral for some cases, e.g., Int -> Integer, Int -> Double)
10:36:23 * hackage haskoin-core 0.17.3 - Bitcoin & Bitcoin Cash library for Haskell  https://hackage.haskell.org/package/haskoin-core-0.17.3 (jprupp)
10:40:36 <merijn> Anyone know if cabal files allow conditional blocks on the top level? it seems not
10:41:56 <Uniaika> never saw such a thing, but doesn't mean it cannot
10:42:51 <merijn> ah, rats
10:42:55 <merijn> "Conditional blocks may appear anywhere inside a library or executable section."
10:43:16 <merijn> I've been hosed by own abuse of data-files!
10:44:43 <merijn> I had symlinks to files relative to my project, which works with cabal v2-run, but sadly borks the install command it seems >.>
10:50:53 * hackage haskoin-node 0.17.1 - P2P library for Bitcoin and Bitcoin Cash  https://hackage.haskell.org/package/haskoin-node-0.17.1 (jprupp)
10:56:07 <merijn> Anyone happen to have an "ancient" cabal-install lyying around? (i.e. pre 3.0)
10:57:00 <monochrom> ghcup knows 2.4.1.0
10:57:26 <tomjaguarpaw> I have 2.2.0.0.  Debian stable user!
10:57:37 <merijn> monochrom: I don't have ghcup :p
10:57:40 <monochrom> I can send you a copy, but I think you would trust ghcup more than trust me
10:58:01 <monochrom> Ah, ghcup just downloads it from some haskell.org URL, I can isolate that.
10:58:03 <merijn> monochrom: That was more of a "and is willing to quickly test something trivial for me" kinda question :p
10:58:23 * hackage hakyll-images 1.0.0 - Hakyll utilities to work with images  https://hackage.haskell.org/package/hakyll-images-1.0.0 (LaurentRDC)
10:58:34 <monochrom> pretty sure the cost of communicating what to test > the cost of testing it yourself
10:58:37 <tomjaguarpaw> merijn: Sure
10:58:57 <merijn> tomjaguarpaw: If you add a line "data-files:  foo/*" to any cabal file you have where foo is non-empty, does it error out?
10:59:28 <tomjaguarpaw> With what command? v2-build, say?
10:59:35 <merijn> anything, tbh
10:59:46 <monochrom> https://downloads.haskell.org/~cabal/cabal-install-2.4.1.0/cabal-install-2.4.1.0-x86_64-unknown-linux.tar.xz
10:59:51 <merijn> The question is whether the cabal format allows that at all
10:59:57 <merijn> monochrom: Nice, but I don't use linux ;)
11:00:09 <merijn> At least not when I can help it :p
11:00:46 * tomjaguarpaw is surprised to learn that cabal version 2 doesn't support v2- prefixes
11:00:47 <monochrom> I think mac would be https://downloads.haskell.org/~cabal/cabal-install-2.4.1.0/cabal-install-2.4.1.0-x86_64-apple-darwin-sierra.tar.xz
11:01:10 <merijn> tomjaguarpaw: Those were added in 2.4 I think, before then it was new-
11:01:11 <tomjaguarpaw> merijn: It doesn't error out before erroring out about broken packages ...
11:01:20 <merijn> hmm
11:01:24 <tomjaguarpaw> Ah yes, I remember now
11:01:36 <merijn> Cursed documentation disagreeing with reality
11:02:08 <tomjaguarpaw> And new-build seems to be progressing fine
11:03:17 <merijn> This is against the claims of the documentation...sadness
11:03:35 <tomjaguarpaw> What does the documentation say?
11:04:05 <tomjaguarpaw> Oh, cabal sdist /does/ error
11:04:09 <merijn> You can have wildcards without extension at all
11:04:15 <merijn> s/can/can't
11:04:31 <monochrom> "If a wildcard is used, it must be used with an extension, so data-files: data/* is not allowed."
11:04:33 <tomjaguarpaw> cabal: invalid file glob 'foo/*'. Wildcards '*' are only allowed in place of
11:04:33 <tomjaguarpaw> the file name, not in the directory name or file extension. If a wildcard is
11:04:33 <tomjaguarpaw> used it must be with an file extension.
11:04:48 <tomjaguarpaw> (but with cabal sdist only, cabal new-build doesn't show the error)
11:05:16 <monochrom> Oh, generally a lot of these rules are unenforced until sdist
11:05:50 <merijn> ah, cabal check also complains about it
11:05:59 <monochrom> Another one is if you forget your other-modules: field, you only get bitten when sdist decides to not include your source code.
11:06:29 <merijn> monochrom: That's why haskell-ci only tests via sdist+unpack
11:07:06 <sclv> i thought the new warn home modules stuff warns about missing other modules nowadays
11:07:26 <sclv> its all part of the messy legacy of how cabal relies in part on ghc's module discovery instead of doing its own entirely
11:07:29 <merijn> sclv: You have to use a ghc that's new enough
11:11:35 <merijn> Fortunately, I don't have to care about properly packaging this code, so who cares :p
11:14:04 <merijn> All problems can be solved by caring less and lowering your standards! Whoo! \o/
11:14:18 <monochrom> :)
11:14:44 <monochrom> Will you also be using "cabal install" down the road? Because that's another time data-files: really counts.
11:15:03 <merijn> monochrom: Well, that's actually were I ran into it not working
11:15:07 <monochrom> But if not, if you're just going "cabal run", I think you're set.
11:15:11 <merijn> monochrom: But I have a simple life hack
11:15:22 <merijn> monochrom: Just don't list the data files at all!
11:15:58 <merijn> I only need them for some codepaths I don't care about now anyway
11:16:06 <monochrom> I wonder how hard it is to enlist "*.dat *.txt *.bin"
11:16:27 <merijn> monochrom: they're symlinks :p
11:17:05 <monochrom> OK I begin to fathom how much you meant "abuse" now.
11:19:13 <merijn> monochrom: I have a make based build system that ends up calling cabal, but the Haskell code needs access to C++ build artifacts, so I have relative symlinks in data-files that point to the right executables/objects :p
11:20:12 * monochrom cries
11:20:21 <monochrom> This makes baby jesus cry.
11:20:57 <merijn> monochrom: It's simple, don't ever try to install or sdist :)
11:23:03 <merijn> monochrom: If people want robuster packaging that works beyond "clone the repo and run make" they should spend more funding on engineering in academia :p
11:23:36 <monochrom> You already have a makefile so I suppose it is not a stretch to add "make install" and script its Turing-complete behaviour to your heart's content.
11:23:54 <merijn> monochrom: Ah, see I have a simpler solution
11:23:57 <monochrom> and even "make run"
11:24:06 <merijn> monochrom: "just don't allow installs"
11:24:19 <monochrom> BTW why symlinks, why not hardlinks?
11:24:38 <merijn> monochrom: That doesn't work across git clones
11:24:43 <monochrom> Oh darn
11:24:50 <merijn> monochrom: Since the symlinks are in VCS, the build artifacts aren't
11:25:14 <monochrom> I guess this is what people mean by "sweet spot"
11:25:17 <merijn> monochrom: Actually, my actual solution is much more genius/maddening/depressing than make run :p
11:25:28 <monochrom> Actually make it Pareto optimum hahaha
11:25:44 <merijn> monochrom: I have differently named symlinks to 1 script: https://github.com/merijn/Belewitte/blob/master/cabal-run.sh
11:26:08 <merijn> monochrom: Which use make to find the right directory/executables, then invokes cabal v2-run based on the name of the symlink :p
11:26:09 <monochrom> "any tiny pertubation from this seemingly awkward arrangement, you would be actually worse off"
11:26:44 <merijn> monochrom: "organically grown" :p
11:27:39 <monochrom> I have understood the trick of arg[0]-dependent behaviour for a long time. That one isn't too bad.
11:27:46 <merijn> monochrom: tbh, aside from the fact the cabal/data-files interaction with make is insane it's stunningly robust.
11:28:21 <servo> hi 
11:28:43 <merijn> monochrom: I've have cloned this repo to 7+ machines macOS & linux and it works flawlessly each time if the small handful of prerequisites (mostly GHC, cabal, gmake and a non-ancient clang/gcc) are installed
11:29:46 <merijn> monochrom: I had to somehow turn it into something that my promotor can robustly check out and run without needing to know anything about Haskell besides "download these binaries here" and in the sense it's worked :p
11:38:05 <tomjaguarpaw> What is a promotor?
11:39:08 <tomsmeding> phd thesis adviser?
11:39:13 <merijn> tomjaguarpaw: As in doctoral supervisor
11:40:56 <tomjaguarpaw> Aha
11:42:23 * hackage haskoin-store 0.38.2 - Storage and index for Bitcoin and Bitcoin Cash  https://hackage.haskell.org/package/haskoin-store-0.38.2 (jprupp)
11:43:23 * hackage arxiv 0.0.2 - A client for the Arxiv API  https://hackage.haskell.org/package/arxiv-0.0.2 (TobiasSchoofs)
12:44:19 <nut> why do people derive Generic?
12:45:30 <merijn> Because handwriting sucks? :p
12:46:36 <nut>  I see this after deriving Generic: instance NFData Implementation
12:46:53 <nut> is it related to this instance? for the data Implementation
12:47:12 <nut> I mean Generic and NFData instance, are they related?
12:48:16 <nut> The data 'Implementation', is just a normal algebraic type without fancy data entries
12:48:57 <tomjaguarpaw> If the NFData instance doesn't have a body then yes, I guess it is filled in with defaults from Generic.
12:50:30 <nut> I see, tomjaguarpaw , indeed it doens't have a body
12:53:39 <tomjaguarpaw> It will be filled in the with default implementation you see at http://hackage.haskell.org/package/deepseq-1.4.4.0/docs/Control-DeepSeq.html#v:rnf (the one with Generic in the signature)
13:44:59 <koz_> You can use derived Generic instances to autoderive a bunch of things, including NFData. There's also Hashable and Binary, as well as the aeson type classes that come to mind.
13:50:25 <koz_> :t (*>)
13:50:28 <lambdabot> Applicative f => f a -> f b -> f b
13:50:36 <koz_> :t ($>)
13:50:38 <lambdabot> error:
13:50:38 <lambdabot>     • Variable not in scope: $>
13:50:38 <lambdabot>     • Perhaps you meant one of these:
13:50:46 <koz_> % :t ($>)
13:50:46 <yahb> koz_: forall {f :: * -> *} {a} {b}. Functor f => f a -> b -> f b
14:06:23 * hackage j 0.2.1.0 - J in Haskell  https://hackage.haskell.org/package/j-0.2.1.0 (vmchale)
14:07:21 <unclechu> hey, consider this piece of code: `data SBackend (β ∷ Backend (α ∷ Operation))`. `β` is “type”, `Backend α` is “kind” but `Operation` called here?
14:08:25 <unclechu> s/but/but what/
14:08:43 <Cale> It depends on what the type of Backend is
14:08:45 <monochrom> also kind
14:09:08 <Cale> Oh, yeah, I suppose regardless, it must be a kind
14:09:09 <edwardk> TypeInType made types and kinds basically the same thing
14:09:12 <unclechu> “kind of kind”?
14:10:59 <monochrom> Very simply, if "Foo :: Bar" is legal, and you have no problem with saying that Foo is a type, then you have no problem saying that Bar is a kind.
14:11:02 <edwardk> but since types have a few more things they can be than kinds do it is worth keeping the distinction. that being a kind of kind is actually picks up the limitations on kinds, so its just a kind.
14:11:20 <edwardk> monochrom++
14:11:23 <unclechu> Cale: it depends on a constructors, isn’t it? e.g. `β → SBackend (Backend 'Render)`
14:11:59 <Orbstheorem> Hello o/ How do I add `etc` as a dependency with flag `yaml` to my package.yaml? 
14:12:15 <edwardk> unclechu: it doesn't need to have constructors you could always leave a variable free to quantify over Operations, even if there are none
14:12:38 <unclechu> monochrom: but `Foo` in that context is not “type” but “kind”
14:13:34 <edwardk> unclechu: TypeInType made it possible to use types as kinds, the distinction is mostly eliminated, like i said
14:14:12 <monochrom> α is a type (specifically a type parameter), and "α ∷ Operation", so Operation is a kind.
14:16:42 <monochrom> Well I guess you're really asking what if Foo::Bar in which Foo is already at the kind level. Then what edwardk said. If Foo is a kind then Bar is a kind too.
14:17:52 <monochrom> In Agda it would be that Bar is one level above Foo. In GHC those levels are all merged.
14:20:56 <Cale> unclechu: What's the kind of Backend?
14:22:10 <dolio> Well, that would probably not be the perspective in Agda. Arguably the 'term vs. type vs. kind' thing in Haskell is a distinction of syntactic categories, and Agda just gets rid of that.
14:22:13 <monochrom> Yeah, that can be a much more useful piece of information than simple dichotomies.
14:22:32 <unclechu> Cale: `(α :: Operation) → Type`
14:22:39 <dolio> You could have all the 'levels' like Agda and also have a distinction of syntactic categories.
14:24:28 <unclechu> hackage links to this 404 page https://cabal.readthedocs.io/installing-packages.html#controlling-flag-assignments about using package flags 
14:27:39 <zephyz> How do I get an Exp out of a Pat in Template Haskell? I just want to return the variable that was given in argument in a lambda
14:27:53 * hackage subG 0.2.0.0 - Some extension to the Foldable and Monoid classes.  https://hackage.haskell.org/package/subG-0.2.0.0 (OleksandrZhabenko)
14:34:10 <monochrom> If the pattern is really just a variable, you will be seeing "VarP n", where n::Name, no?
14:34:37 <monochrom> Then the expression version of that variable is VarE n, no?
14:34:42 <zephyz> Ah Yes
14:35:00 <zephyz> is there a way to get the `Name` out of a `Pat`?
14:35:21 <monochrom> "the" sounds wrong.
14:35:42 <monochrom> Some patterns don't have any variable. Some other patterns have a million. What "the"?
14:36:08 <zephyz> You're asking this as if I already know about the APi
14:36:36 <zephyz> how can I tell if a pattern can have multiple variables? or conversly, how can I make sur emy patterns only have 1 variable?
14:36:49 <monochrom> No. You are supposed to know all the infinitely many legal patterns first.
14:37:30 <monochrom> You already know the name "Pat" so you can easily look up how many dozens of data constructors it has.
14:38:32 <zephyz> Geez thanks I guess I'll just keep reading undocumented TH source, thanks
14:39:01 <monochrom> I never read the source. I have only seen the doc.
14:39:48 <zephyz> it's literally the same, there is no documentation about how to use it, just constructors https://hackage.haskell.org/package/template-haskell-2.16.0.0/docs/Language-Haskell-TH.html#t:Pat
14:40:04 <monochrom> Language.Haskell.TH.Syntax
14:40:10 <zephyz> but now I see what you mean, "TupP" can have multple names
14:40:38 <monochrom> I trust that you know you can start with https://hackage.haskell.org/package/template-haskell-2.16.0.0/
14:41:12 <monochrom> Alternatively, if you say "hoogle didn't tell me any other URL", well then that's why I never use hoogle either.
14:41:54 <zephyz> great thanks, but if  someone's gonna tell me "just read the docs" I'd rather not ask at all
14:43:42 <monochrom> Damn right.
14:44:05 <monochrom> If a question is already answered by the docs, I would rather no one ask it at all.
14:46:58 <zephyz> are you braindead? how can you expect every beginner to have read every single piece of haskell code in the universe before they ask a question? Especially when the documentation you talk about is literaly just type signatures with no indication on how to use them
14:49:02 <_deepfire> Given 'type Fallible = Either Foo'; how could it be that:  Couldn't match expected type ‘Either Foo Blah’ with actual type ‘Fallible Blah’ ?
14:50:02 <monochrom> Could you post some self-contained code that reproduces that?
14:50:37 <_deepfire> Not easily, unfortunately.. that'd take some time to work through.
14:50:44 <Axman6> I assume, without looking at the definitions, that the type for patterns contains a list, which implies it could have zero to infinite sub patterns, which include variables
14:51:39 <_deepfire> In any case, it's already reassuring that this isn't supposed to be normal behavior -- I was thinking I'm going mad..
14:51:56 <monochrom> Then the explanation lies elsewhere.
14:55:43 <Axman6> zephyz: to be honest, we don't really expect a beginner to be looking at template haskell at all, since to understand it requires understanding Haskell quite well. Looking at the docs for Pat, it looks like the docs do a great job explaining what the type is and represents
14:57:51 <zephyz> Axman6 Cool thanks
15:01:59 <unclechu> it is still impossible in GHC to use higher-order type families? i mean that i can’t use partially applied type family as an argument for another type family
15:02:54 <dolio> I don't think you should expect to be able to do that.
15:04:25 <monochrom> _deepfire: Maybe do you have a name clash of two distinct "Foo"s hanging around?
15:04:53 <unclechu> dolio: why not? 
15:05:13 <unclechu> it would be extremely useful and straightforward
15:06:03 <unclechu> i could reduce amount of type families a lot by using “polymorphic” type famillies
15:06:09 <dolio> Because type families are definition by recursive matching on types, and type families are not generators the kind of types.
15:08:06 <unclechu> dolio: maybe then i should expect instead to have an another way to define “type-level functions”?
15:08:40 <unclechu> or maybe i should expect dependent types implementation in GHC so this ability would be delivered with it?
15:09:54 <unclechu> does it makes sense? i’m probably not the only one who wants to define type-level `fmap`
15:10:12 <_deepfire> monochrom: no, it turns out that 'cabal clean' fixed it..
15:10:35 <monochrom> Hrm that's a strange one indeed.
15:10:46 <dolio> Term-level functions don't allow this, either. You can't write definitions by higher-order matching against arbitrary other functions.
15:11:09 <_deepfire> I'm using a bit old cabal 3.0, so that might explain the occasional roughness..
15:11:42 <monochrom> Standard tech support drone script: 1. have you saved? 2. have you cabal cleaned? 3. have you tried rebooting? 4. have you read the docs?
15:11:47 <unclechu> dolio: but i’m not trying to do any matching, i just use variables to use them as functions
15:13:03 <unclechu> dolio: i can reformulate my question as: is it still impossible in GHC to define `fmap`/`map` in type-level?
15:14:45 <_deepfire> monochrom: yeah.. : -)
15:21:51 <dolio> Oh, I see what you mean. I'm not sure if they're attempting to deliver that before all the dependent type stuff.
15:25:31 <monochrom> I haven't checked whether map is definable or not. I worry more about possible use sites. At the use sites, you cannot have type-level lambda, you cannot have partially applied Haskell 2010 type aliases (so nevermind type families), so your map is not going to enjoy much desired use.
15:35:01 <dolio> I guess I would check if LiberalTypeSynonyms works, but I would guess it won't.
15:35:17 <dolio> I mean, it works, but not for that, I assume.
15:37:25 <dolio> Of course, it couldn't possibly work except for concrete lists.
15:41:28 <dolio> I would also guess they aren't trying to provide this before whatever dependent type plan goes through, because with the current type checker, you'd probably be guaranteed to have to use a bunch of explicit type annotations on anything that used this.
15:42:18 <dolio> Type applications, even.
15:42:44 <dolio> But maybe I'm wrong about that.
15:46:23 <unclechu> monochrom: actually you can have partially applied type family if it’s kind is `Constraint` if i’m not mistaken
15:47:41 <dolio> I'd be surprised.
15:50:57 <unclechu> maybe i’m mixing up something in my memory. i just remember some conclusion i made from long ago
15:55:37 <Axman6> there's a trick where you define a class which has other classes as superclasses, and have a single instance, is that what you're talking about?
15:55:38 <unclechu> hmm... maybe i mean type-classes back then, not type families
15:55:52 <unclechu> > f :: (a ~ MonadReader Int, m ~ b IO) => Proxy m -> String; f Proxy = mempty
15:55:55 <lambdabot>  <hint>:1:58: error: <hint>:1:58: error: parse error on input ‘;’
15:56:05 <unclechu> >      f :: (a ~ MonadReader Int, m ~ b IO) => Proxy m -> String
15:56:06 <lambdabot>  error:
15:56:06 <lambdabot>      • Could not deduce (FromExpr [Char]) arising from a use of ‘f’
15:56:07 <lambdabot>        from the context: (a ~ MonadReader Int, m ~ b1 IO)
15:56:07 <Axman6> class (Foo a, Bar a) => Baz a; instance (Foo a, Bar a) => Baz a
15:57:08 <unclechu> > f :: (a ~ MonadReader Int, m ~ a IO) => Proxy m -> String
15:57:10 <lambdabot>  error:
15:57:11 <lambdabot>      • Could not deduce (FromExpr [Char]) arising from a use of ‘f’
15:57:11 <lambdabot>        from the context: (a ~ MonadReader Int, m ~ a IO)
15:57:21 <unclechu> anyway, that works in ghci
15:58:23 * hackage predicate-typed 0.7.4.4 - Predicates, Refinement types and Dsl  https://hackage.haskell.org/package/predicate-typed-0.7.4.4 (gbwey)
15:59:36 <unclechu> Axman6: i was talking about type families explicitly. what i want is if i have a `type family (x :: a) :: b` i want to make `type family (x :: [a]) :: [b]` of it without adding a new type family
16:01:32 <unclechu> currently i have define a type family and another type family which is a multiple version of first one
16:03:16 <unclechu> like `type family FooMultiple (a ∷ [κ]) ∷ [b] where FooMultiple '[] = '[]; FooMultiple (x ': xs) = Foo x ': FooMultiple xs`
16:49:53 * hackage Frames-streamly 0.1.0.1 - A streamly layer for Frames I/O  https://hackage.haskell.org/package/Frames-streamly-0.1.0.1 (adamCS)
16:54:09 <koz_> When GHC describes a type variable as 'rigid', what does it mean exactly?
16:58:44 <dolio> koz_: It means it can't be unified with any type but itself, basically.
17:24:12 <koz_> dolio: Ah.
17:26:52 <jchia> Any general guidelines for making Arbitrary instances for my own types especially wrt orphaned instances?
17:27:24 <dibblego> newtype or use hedgehog
17:34:31 <koz_> You can also avoid the need for Arbitrary if you just define 'Gen a' for your stuff, and use combinators like https://hackage.haskell.org/package/QuickCheck-2.14.2/docs/Test-QuickCheck.html#v:forAll
17:34:44 <koz_> Or rather, define stuff like 'genFoo :: Gen Foo' and use those.
17:35:07 <koz_> It's more tedious though.
17:50:53 * hackage Frames-streamly 0.1.0.2 - A streamly layer for Frames I/O  https://hackage.haskell.org/package/Frames-streamly-0.1.0.2 (adamCS)
17:52:49 <Axman6> unclechu: ah sorry, I hadn't read all the history
21:03:52 * hackage hyraxAbif 0.2.3.26 - Modules for parsing, generating and manipulating AB1 files.  https://hackage.haskell.org/package/hyraxAbif-0.2.3.26 (andrevdm)
21:11:52 * hackage hyraxAbif 0.2.3.27 - Modules for parsing, generating and manipulating AB1 files.  https://hackage.haskell.org/package/hyraxAbif-0.2.3.27 (andrevdm)
21:54:15 <larou> hello!
21:58:21 <larou> unclechu your looking for defunctionalisation 
22:00:49 <larou> <unclechu> it is still impossible in GHC to use higher-order type families? i mean that i canâ€™t use partially applied type family as an argument for another type family
22:00:53 <larou> yes you can
22:00:56 <larou> defunctionalise it
22:01:30 <larou> type level functions as first class citizens, modulo, defunctionalization
22:02:03 <larou> then your type level map is easy
22:03:08 <larou> type family Map :: (f :: a ~> b) -> m a -> m b
22:03:34 <larou> erg,  Map :: (f a ~> b) -> m a -> m b
22:03:51 <larou> Map :: (a ~> b) -> m a -> m b
22:03:53 <larou> sorry
22:05:30 <larou> type family Map (f :: a ~> b)  (xs :: [] a) :: m b where Map _ '[] = '[]; Map f (x ': xs) = f @@ x ': Map f xs
22:05:47 <larou> that @@ is because f :: a ~> b, not f :: a -> b
22:07:13 <larou> https://pastebin.com/raw/U4Bd48Cq
22:07:43 <larou> and you make type instances for Apply for defunctionalisation symbols
22:08:06 <larou> that you want to apply using Map
22:08:29 <larou> that is, for every ~> you use, in order to get something of that type, you have to "defunctionalise it"
22:08:48 <larou> which consists of writing a datatype and making it an instance of apply
22:09:32 <larou> the type of the datatype you make has the same type signature as the type family you defunctionalising, except with ~> instead of ->
22:09:47 <larou> and you need one extra symbol for each arrow you change
22:10:18 <larou> the instance takes the function and its arguments, what it means to "Apply" the datatype
22:10:52 <larou> and simply calls the type family, or another defunctionalisation symbol that has fewer ~>
22:11:31 <larou> in order to build up all the symbols allowing apply to be chained over multiple inputs like f @@ x @@ y
22:15:36 <unclechu> larou: thanks! i’ll dive into this later
22:44:17 <Axman6> @hoogle (@@)
22:44:18 <lambdabot> Data.Singletons (
22:44:18 <lambdabot> Data.Singletons type a
22:44:18 <lambdabot> Diagrams.Angle (
23:24:23 * hackage subG 0.2.1.0 - Some extension to the Foldable and Monoid classes.  https://hackage.haskell.org/package/subG-0.2.1.0 (OleksandrZhabenko)
23:48:56 <dminuoso> koz_: A rigid type variable is one that is not wobbly...
23:49:19 <dminuoso> https://www.microsoft.com/en-us/research/publication/wobbly-types-type-inference-for-generalised-algebraic-data-types/
23:55:05 <dminuoso> dolio: Also, are you sure about your characterization that a rigid will not unify with anything else? Does it not unify with a unificational variable?
