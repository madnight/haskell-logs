01:00:48 <tdammers> does anyone know how I can convince postgresql-simple to consume postgres values of type 'interval'?
01:26:44 <dminuoso> define "consume"
01:27:07 <tdammers> map to Haskell values
01:27:27 <tdammers> I have a table with 'interval' values in it, and I want to read those with postgresql-simple
01:28:46 <dminuoso> tdammers: I didn't map interval yet, but roughly https://hackage.haskell.org/package/postgresql-simple-0.6.3/docs/src/Database.PostgreSQL.Simple.FromField.html#FromField shows how
01:29:16 <dminuoso> in particular, look at `attoFieldParser`, `doFromField` and `okXXX` primitives like `okBinary`
01:29:32 <tdammers> right. upon further thought, it turns out that interval is actually the wrong data type, so that means I won't have to write my own parser for it
01:29:46 <dminuoso> To figure out the underlying oids, use something like 
01:29:48 <dminuoso> elect 'interval'::regtype::oid;
01:37:42 <trcc> I am aware that this is not the right channel to ask the question, but I do not know where to ask :) Anyone familiar with a channel related to model checking?
01:37:57 <trcc> Usually there is a lot of knowledge contained in here
01:55:38 <[exa]> trcc: that sounds a bit too specialized even for #haskell, esp. in the morning :]
01:55:48 <trcc> hehe
01:56:04 <[exa]> do you seek papers, software, advice, or anything specific?
01:56:53 * hackage ukrainian-phonetics-basic 0.3.0.0 - A library to work with the basic Ukrainian phonetics and syllable segmentation.  https://hackage.haskell.org/package/ukrainian-phonetics-basic-0.3.0.0 (OleksandrZhabenko)
02:06:06 <ER> @hoogle displayShow
02:06:06 <lambdabot> RIO displayShow :: Show a => a -> Utf8Builder
02:06:06 <lambdabot> Stack.Prelude displayShow :: Show a => a -> Utf8Builder
02:06:06 <lambdabot> Tonalude displayShow :: Show a => a -> Utf8Builder
02:06:19 <ER> @hoogle Utf8Builder
02:06:19 <lambdabot> RIO newtype Utf8Builder
02:06:19 <lambdabot> RIO Utf8Builder :: Builder -> Utf8Builder
02:06:19 <lambdabot> Text.Printer newtype Utf8Builder
02:40:15 <trcc> [exa]: I have a program (c-like, but with objects) Y that uses an object X. X has a certain api. I want to verify that the given program Y does not violate the API of X. And I was hoping to code-generate the program to a model checker and have the model checker verify this.
02:42:34 <johnnyboy[m]> sounds interesting!
02:43:11 <johnnyboy[m]> I wrote an LTL theory generator for my model checking project in Haskell and it was fun!
02:44:30 <johnnyboy[m]> haskell seems to be a great tool for parsing and generating code
02:58:57 * Digit table flips attempting to install Euterpea (cabal v1-install --allow-newer Euterpea # didnt work either) ... goes afk to calm down, and to dispell angry defeatist thoughts he'll never get coding his music in functional programming.  
03:00:31 <tomsmeding> Digit: with what ghc version did you try that?
03:00:57 <tomsmeding> I found this issue, which you probably also found (https://github.com/Euterpea/Euterpea2/issues/35), that suggests using ghc 8.6.5
03:02:36 <Uniaika> hi tomsmeding :)
03:03:08 * tomsmeding wonders if you know me from somewhere outside #haskell
03:03:21 <[exa]> trcc: I'm usually going the other direction, write a DSL where breaking the model is non-representable and then generate the C program from that...
03:03:52 <Uniaika> tomsmeding: nope, not at all! :D
03:04:03 <tomsmeding> also hi, then :)
03:19:25 <ski> triteraflops : Clean also has some monadic operations, because they're useful at times (avoiding tedious boilerplate code), even with uniqueness
03:21:19 <ski> the Clean approach to I/O requires tracking uniqueness statically. (Mercury also uses the same approach, although it doesn't put the uniqueness in the types, but in separate mode declarations of functions and predicates). since Haskell doesn't have uniqueness, it has to use a different approach
03:24:13 <ski> in the past (before monadic I/O), Haskell has used two other approaches to (side-effect free) I/O, modelling I/O declaratively. first, you can model a program as a function from program inputs (standard input) to program outputs (standard output), both being `String's. the standard Haskell function `interact :: (String -> String) -> IO ()' can be used to convert from that input-string-to-output-string model 
03:24:19 <ski> to the current monadic I/O model, so that you can write programs in this style
03:26:01 <ski> however, this doesn't scale to doing other operations that transforming a single standard input character stream to a single standard output character stream. e.g. you might also want to emit some output on the standard error stream. or you might want to open named files, to read from them, or write to them. or do other effectful operations, like communicating over a network
03:31:27 <ski> so, instead of mapping lists/streams of input characters to lists/streams of output characters, we could generalize to mapping lists of OS responses to lists of OS requests (yes, in that order, not in the opposite order). you can imagine `data Request = HPutChar Handle Char | HGetChar Handle | OpenFile FilePath IOMode | HClose Handle ...' and `data Response = HCharPut | HCharGot Char | FileOpened Handle | 
03:31:33 <ski> Closed | Error IOError | ...'
03:32:48 <ski> and then a program doing I/O would be modelled as a function of type `[Response] -> [Request]'. the idea is that the function starts by producing a `Request' in the output stream, and only after that does it look at the corresponding `Response' in the input stream, which will contain the reply from the OS to the given request
03:33:24 <ski> you could define a function for outputting a `String' as follows
03:33:43 <ski>   hPutStr :: String -> [Response] -> [Request]
03:35:03 <ski>   hPutStr [   ] resps0 = []
03:35:33 <ski>   hPutStr (c:s) resps0 = HPutChar h c
03:35:44 <Digit> thanks tomsmeding. that was helpful.  i have a 8.8.4 which i've been getting "further" with than my 8.6.5 which chokes straight away, offering "cabal: failed to parse output of 'ghc-pkg dump'".  with my 8.8.4 i at least get to the https://dpaste.com/78CNMNNAU (& attempting to get alsa's -dev where i have the 8.6.5 errors out too).  ~ am currently working through the errors i got, getting the parts, on a fresh start with another 8.6.5 (i
03:35:44 <Digit> hope).
03:35:53 <ski>                        : case resps0 of
03:36:10 <dminuoso> I do wonder how error prone pre-monadic IO really was. Forget to pop a response, pop twice.. 
03:36:17 <trcc> [exa]: yes, I have thought of that. Unfortunately it is not really a possibility here...
03:36:30 <ski>                            HCharPut:resps -> hPutStr h c resps
03:36:34 <dminuoso> The interface seems incredibly awkward
03:36:56 <ski> (oh, there should of course also be a `Handle' argument to `hPutStr')
03:37:42 <ski> it's awkward yes to have to do local `case' in order to only check the corresponding response after the request has been given. one can use an irrefutable/lazy pattern, in order to make this a little nicer
03:38:05 <ski>   hPutStr (c:s) ~(HCharPut:resps) = HPutChar h c : hPutStr h c resps
03:38:22 <dminuoso> Did that mechanism support things like forkIO?
03:38:46 <dminuoso> Though..
03:39:05 <dminuoso> I guess that'd just be `forkIO :: ([Request] -> [Response]) -> [Request] -> [Response]`
03:39:14 <dminuoso> The rest is just an implementation
03:39:15 <ski> also, `hPutStr', as written above, is not composable. if one wants to output one `String' after another (and not by first concatenating them), one can't do it directly with `hPutStr'. we need to generalize it to take an additional parameter, a continuation, for what to do after the output of the given `String' :
03:39:33 <ski>   hPutStr :: Handle -> String -> ([Response] -> [Request]) -> [Response] -> [Request]
03:39:36 <ski> or, using
03:39:44 <ski>   type Answer = [Response] -> [Request]
03:39:46 <ski> it becomes
03:39:55 <ski>   hPutStr :: Handle -> String -> Answer -> Answer
03:40:01 <ski> and then one'd also do
03:40:15 <ski>   hGetLine :: Handle -> (String -> Answer) -> Answer
03:40:35 <ski> (another name for `Answer' that's been used is `Dialogue', for "dialogue-based I/O")
03:40:57 <ski> this is actually writing the program in continuation-passing style, and so one could express these using `Cont' :
03:41:08 <ski>   hPutStr :: Handle -> String -> Cont Answer ()
03:41:20 <ski>   hGetLine :: Handle -> Cont Answer String
03:42:12 <ski> and then we could define `IO' as `Cont Answer', and define monadic combinators on `IO' (like `returnIO',`bindIO'), or the overloaded ones that we have today, that applies to any monad
03:43:22 <dminuoso> ski: But this is also more error prone in a subtle way. Response is not parametrized over the type of result it yields.
03:43:33 <ski> (it's also possible to have `Answer' as an abstract data type, and base I/O directly on it, instead of defining `Answer' in terms of the dialogue-based I/O. Andrew Appel's "Modern Compiler Implementation in SML/C/Java" does that, in a chapter about a purely functional language)
03:43:49 <ski> dminuoso : it isn't intended to
03:44:08 <dminuoso> So you could pass the `Response` to something not compatible with what it produces
03:44:24 <ski> you can use the CPS `(a -> Answer) -> Answer' to express a computed answer `a', and the ability to continue with further I/O dialogue after that
03:46:12 <ski> "Did that mechanism support things like forkIO?" -- not really. the dialogue models a synchronized, fully linear, interleaving of requests and responses. the more or less arbitrary interleaving of multiple such dialogues couldn't really be expressed nicely here, that i can see
03:47:03 <ski> also, it's awkward to have to change `Request' and `Response', to add new primitive types of operations. it's better to have `Answer', or `IO', be an abstract type, and have ways of importing foreign operations dealing with them
03:47:05 <dminuoso> ski: well, I just thought that you could just dupliate another dialog machine on forkIO
03:47:38 <dminuoso> in the sense of forking the entire process
03:47:59 <ski> i guess something like `([Response] -> [Request]) -> ([Response] -> [Request]) -> ([Response] -> [Request])' could perhaps work, hmm
03:48:30 <ski> (btw, note that you got the `Response' vs. `Request' ordering wrong for `forkIO'. the `Requests' are the outputs, and the `Response' are the inputs)
03:48:48 <ski> hmm
03:49:56 <ski> well, i suppose you could have a request `ForkIO ([Response] -> [Request])', and defer to the OS how the interleaving of I/O operations should happen
03:50:20 <ski> (i was thinking about possibly describing, in-language, the interleaving)
03:52:57 <ski> triteraflops : in any case, uniqueness and monads are not directly comparable. they are at "different levels". it's more fair to compare uniqueness to `IO' and `ST'. the latter two can be thought of as abstract datatypes which conceptually makes use of uniqueness internally (even though the language doesn't allow expressing uniqueness). them being abstract protects the use of the "state-passing" to ensure 
03:53:03 <ski> uniqueness inside, so that "update-in-place" can be used. however, as noticed by someone else, for some notions of I/O, the "world-passing" isn't really a good fit
03:54:45 <tomsmeding> Digit: are you switching ghc's using ghcup? Not sure if I've seen that ghc-pkg error before, perhaps a version mismatch?
03:56:06 <ski> triteraflops : anyway, there are operations `return :: a -> St s a',`(`bind`) :: (St s a) -> (a -> St s b) -> St s b',`seqList :: [St s a] -> St s [a]' in Clean, `St s a' being defined as `s -> (a,s)'. these can be applied to passing unique values (the `World', or `File's or arrays) around, threading them through a computation. `seqList' corresponds in Haskell to `sequence', for the `State s' monad
03:58:18 <ski> triteraflops : one advantage of the uniqueness approach is that not all I/O operations, or array operations, need to be explicitly sequenced, wrt each other. if you open two `File's, or operate on two arrays, then these would be two different "unique state threads", can be evaluated independently of each other. this improves laziness, as compared to Haskell's monadic `IO' and `ST', which insists on 
03:58:24 <ski> sequentializing all the I/O or state operations, wrt each other
04:00:09 <ski> (unless you're using `forkIO' to spawn a new thread doing I/O, or using `unsafeInterleaveST' to spawn a new "state thread" (not actually using preemptive or cooperative threads in the conventional sense), which is intended to operate on state that's disjoint from the rest of the state (hence the `unsafe' in the name))
04:01:37 <hekkaidekapus> tomsmeding, Digit: Building with v. ≥8.8 requires patching usages of `Control.Monad.fail` (see <https://gitlab.haskell.org/ghc/ghc/-/wikis/migration/8.8#base-41300>). v. ≤8.6.5 will be fine modulo some tweaks in the cabal file.
04:20:53 * hackage phonetic-languages-simplified-common 0.3.0.0 - A simplified version of the phonetic-languages-functionality  https://hackage.haskell.org/package/phonetic-languages-simplified-common-0.3.0.0 (OleksandrZhabenko)
04:38:23 * hackage servant-exceptions 0.2.1 - Extensible exceptions for servant APIs  https://hackage.haskell.org/package/servant-exceptions-0.2.1 (ch1bo)
04:39:23 * hackage servant-exceptions-server 0.2.1 - Extensible exceptions for servant API servers  https://hackage.haskell.org/package/servant-exceptions-server-0.2.1 (ch1bo)
04:40:53 * hackage phonetic-languages-simplified-properties-lists 0.1.0.0 - A generalization of the uniqueness-periods-vector-properties package.  https://hackage.haskell.org/package/phonetic-languages-simplified-properties-lists-0.1.0.0 (OleksandrZhabenko)
04:52:22 <n0042> Hello folks. I have been experimenting with Data.Vector and I have noticed that it uses a lot of the same function names as the list class, which leads to complaints from ghc. How do you guys typically handle that? Should I call each function explicitly like `Data.Vector.length` or is there a one-liner to overwrite the normal commands in a program
04:52:22 <n0042> that will be using Vectors for everything?
04:52:45 <dminuoso> n0042: The common style is to use qualified imports
04:52:53 <dminuoso> import qualified Data.Vector as V
04:53:00 <dminuoso> Alternatively you can also hide imports from Prelude
04:53:12 <n0042> Excellent. Thank you very mcuh dminuoso
04:53:25 <n0042> *much
04:53:29 <[exa]> like, it is pretty common that if anyone writes V.length you just assume that's the vector length
04:53:45 <[exa]> same for other containers, M as Data.Map, S as Data.Set, etc
04:53:47 * dminuoso usually imports Data.ByteString as V and Data.Vector as BS.
04:53:55 * dminuoso then invites [exa] to fix his code
04:54:00 <[exa]> please no why
04:54:06 <n0042> ll
04:54:09 <n0042> *lol
04:54:22 <dminuoso> [exa]: Recall the tree parsing problem btw?
04:54:26 <n0042> Thank you both. I'll use those approaches.
04:54:43 <[exa]> dminuoso: yeah, how did that end up?
04:54:47 <dminuoso> [exa]: Strangely I had another similar problem shortly after, and now I have the *real* solution. Rather than a whacky stupid stateful parser...
04:54:49 <dminuoso> you know...
04:54:51 <dminuoso> build a trie.
04:54:56 <dminuoso> done :>
04:55:16 <[exa]> hell yeah tries
04:55:32 <[exa]> cool
04:56:05 <[exa]> btw I saw some Trie packages like 2 days ago, great there are good data structures for that now
04:56:22 <[exa]> s/data structures/container implementations/ ..so
04:56:54 <dminuoso> Well, Im just finding out that general trie implementations dont make much sense
04:57:04 <dminuoso> Something like `list-tries` for example is just containers with a trie implementation behind
04:57:32 <n0042> Got me looking up what a `trie` is on Wikipedia. Neat stuff. Thanks guys
05:01:12 <[exa]> dminuoso: it's good that there's the concept of tries. Cf. C++ STL doesn't have tries and people end up making stuff like map<list_of_path_elems, whatever>
05:01:38 <merijn> [exa]: Metric trees are even cooler!
05:02:24 <dminuoso> [exa]: to be fair, the map *could* be trie backed
05:02:27 <dminuoso> That's sort of what we have in haskell
05:02:58 <dminuoso> (well containers uses balanced binary tries)
05:03:23 <merijn> dminuoso: C++'s std::map is a balanced binary tree
05:03:55 <merijn> dminuoso: There's no such thing as a "binary trie" (well, I suppose if you have like, lists of boolean as input? >.>)
05:04:28 <dminuoso> oh that was a typo sorry
05:04:39 <merijn> Anyhoo, speaking of trees
05:06:12 <merijn> Suppose I have one a represenation of a tree that's efficient, but inconvenient to program against and wanna expose it as a regular ADT (which is easy to program with), anyone every do something like that? I feel like pattern synonyms should work, but not entirely sure how >.>
05:09:59 <Guest_10> hi
05:11:28 <dminuoso> merijn: write the iso by hand?
05:11:34 <dminuoso> two functions, done
05:11:48 <dminuoso> (you'd want one for testing anyway)
05:11:50 <merijn> dminuoso: I don't wanna reify the ADT
05:12:27 <ski> (you want some kind of slices ?)
05:12:32 <merijn> I just wanna program against the ADT representation like I've directly snorted a Ryan Newton talk :p
05:14:42 <tomsmeding> first write projection functions (for use in view patterns) and smart constructors, incrementally rewrite your program using them, developing the correct vocabulary along the way, and finally distill the result in some pattern synonyms?
05:14:54 <merijn> See 1 hour and 7 minutes into this talk: https://www.youtube.com/watch?v=lC5UWG5N8oY
05:15:17 * ski . o O ( <https://downloads.haskell.org/~ghc/latest/docs/html/libraries/ghc-compact-0.1.0.0/GHC-Compact.html> )
05:15:54 <merijn> ski: That's somewhat related, yes and in fact part of the talk I linked ;)
05:20:34 <kindaro> When I run `cabal build` and then `cabal install --installdir=./deployment --install-method=copy --overwrite-policy=always`, it appears that the same build work is performed twice. How can I only build once and copy the executable to the designated place?
05:21:47 <kindaro> Currently, `cabal install …` is taking the amount of time very near to that of `cabal build`, and also looking at `ps -o command` shows that `ghc` is being invoked.
05:23:53 <merijn> Currently the way you can only build once and copy is to, well, skip running cabal build first? :p
05:24:31 <kindaro> It is not acceptable because I need to acquire the exit status of `cabal build` and `cabal test` before I deploy.
05:24:46 <merijn> There are a bunch of obscure reasons why install rebuilds everything from a clean slate. Some practical, and some due to lack of engineering effort to reduce this
05:25:38 <kindaro> Unfortunate! Can I find out where `cabal build` stores the executable so I may copy it by hand?
05:26:31 <merijn> Latest alpha release of cabal-install has list-bins, if you use an older version there's
05:26:34 <merijn> @hackage cabal-plan
05:26:34 <lambdabot> https://hackage.haskell.org/package/cabal-plan
05:26:58 <merijn> kindaro: Note that copying by hand can get you in trouble if you use, e.g., data-files
05:30:45 <dminuoso> merijn: What's the protocol for that?
05:31:11 <dminuoso> Is there some release command planned, that would give me a tarball with build artifacts in the correct directory structure?
05:31:34 <dminuoso> Or.. can you override getDataFileName?
05:31:57 <dminuoso> Guess I could just write my own Paths_foo module
05:32:30 <merijn> dminuoso: When you run install you can control where they get put via flags, which will set getDataFileName, etc. as needed
05:32:47 <dminuoso> mmm j
05:32:49 <merijn> dminuoso: I wanna work on proper prefix-independence
05:33:03 <merijn> at some unspecified moment where I have time, energy, and motivation
05:33:10 <merijn> So...probably somewhere in the next 3 years :p
05:33:25 <kindaro> merijn, thank you for explanations. Is there a ticket somewhere tracking those obscure reasons?
05:33:34 <hseg> where did mtimes vanish to?
05:34:26 <dminuoso> % :t stimes
05:34:26 <yahb> dminuoso: forall {a} {b}. (Semigroup a, Integral b) => b -> a -> a
05:34:28 <dminuoso> This?
05:34:32 <hseg> or has it been deprecated in favour of stimes?
05:34:36 <hseg> :t mtimes
05:34:37 <lambdabot> error: Variable not in scope: mtimes
05:34:46 <Uniaika> there's Data.Semigroup mtimesDefault :: (Integral b, Monoid a) => b -> a -> a
05:34:53 <hseg> mtimes :: (Monoid a, Integral b) => b -> a -> a
05:35:54 <merijn> kindaro: basically, I think install *always* builds from "first do sdist, then build from there" to ensure the package description is sane, I couldn't quickly find a ticket
05:35:57 <hseg> right. and stimesMonoid :: (Integral b, Monoid a) => b -> a -> a is even better, using exponent halving
05:36:09 <dminuoso> hseg: I dont see a way mtimes and stimes could differ, it would lead to incoherence.
05:36:26 <dminuoso> The mtimes bit is odd, did it ever exist?
05:37:07 <dminuoso> https://www.google.com/search?client=firefox-b-d&q=haskell+ghc+mtimes&nfpr=1&sa=X&ved=2ahUKEwiKrtWd6J3tAhWu1VkKHc94DHEQvgUoAXoECAcQMA&biw=618&bih=638 this suggests it only ever occured in proposals
05:37:08 <hseg> only difference in whether 0 input should error
05:37:17 <hseg> https://gitlab.haskell.org/ghc/ghc/-/wikis/proposal/semigroup-monoid
05:37:24 <ezzieyguywuf> hrm, "[a] -> [b] -> Map a b", seems like a common enough need, i.e. "zip to Map", but I don't see anything like this in hoogle.
05:37:28 <dminuoso> And I cant find it in the git history of GHC
05:37:30 <ezzieyguywuf> is there a good reason why it doesn't exist?
05:37:35 <hseg> ah. have been reading too many propsals then
05:37:39 <dminuoso> % :t zip
05:37:40 <yahb> dminuoso: ; <interactive>:1:1: error:; Ambiguous occurrence `zip'; It could refer to; either `Data.List.NonEmpty.zip', imported from `Data.List.NonEmpty'; or `Prelude.zip', imported from `Prelude' (and originally defined in `GHC.List')
05:37:44 <tomsmeding> ezzieyguywuf: (Map.fromList .) . zip
05:37:48 <dminuoso> % :t Prelude.zip
05:37:48 <yahb> dminuoso: forall {a} {b}. [a] -> [b] -> [(a, b)]
05:37:49 <hseg> ^
05:37:53 <ezzieyguywuf> tomsmeding: nice.
05:39:23 <dminuoso> Anyway. Is there an alternative to haskell-src-exts for generating entire haskell modules? In particular I want quasiquoters and ideally support for comments and a pretty printer..
05:39:33 <ezzieyguywuf> tomsmeding: why are the parentheses needed in that expresion?
05:39:42 <ezzieyguywuf> how is it different from Map.fromList . zip?
05:39:49 <hseg> :t Map.fromList . zip
05:39:50 <dminuoso> ezzieyguywuf: take a look at the number of arugments to zip
05:39:50 <lambdabot> error:
05:39:51 <lambdabot>     Not in scope: ‘Map.fromList’
05:39:51 <lambdabot>     Perhaps you meant one of these:
05:39:54 <hseg> :t Data.Map.fromList . zip
05:39:56 <lambdabot> error:
05:39:56 <lambdabot>     • Couldn't match type ‘[b0] -> [(a, b0)]’ with ‘[(k, a1)]’
05:39:56 <lambdabot>       Expected type: [a] -> [(k, a1)]
05:39:56 <kindaro> merijn: so, why does `cabal build` skip `sdist` then?
05:40:25 <dminuoso> ezzieyguywuf: `(f .) . g` is just very dense for composing `f` after the second argument of `g`
05:41:08 <ezzieyguywuf> dminuoso: what would be a non-dense way of writing it? i see that zip takes two arguments but I guess I didn't realize that `(.)` was limited to one-operator stuff
05:41:17 <dminuoso> % :t let (.:) = (.) . (.) in Data.Map.Strict.fromList .: Prelude.zip
05:41:18 <yahb> dminuoso: forall {k} {a}. Ord k => [k] -> [a] -> M.Map k a
05:41:21 <dminuoso> This is a slightly more readable way
05:41:37 <dminuoso> Or you just use lambdas, parens
05:41:41 <dminuoso> extra binding
05:43:03 <maerwald> is there a way in hspec to mark a test as flaky and still have it run, but when it fails just print a warning and not error?
05:47:12 <ezzieyguywuf> maerwald: I've used pending before, but haven't tried having a potentially failing test run but keep going.
05:47:23 <ezzieyguywuf> maerwald: I guess you could add a check to the end of your test, and flip to True if needed?
05:48:00 <maerwald> Well, that doesn't give me a warning
05:48:59 <maerwald> https://github.com/hspec/hspec/issues/372
05:51:18 <tomsmeding> ezzieyguywuf: (.) :: (b -> c) -> (a -> b) -> (a -> c); it's composition of single-argument functions
05:52:41 <tomsmeding> ((f .) . g) a b  =  (\x -> (f .) (g x)) a b  =  ((f .) (g a)) b  =  (f . g a) b  =  (\x -> f (g a x)) b  =  f (g a b)
05:52:52 * hackage hspec-hashable 0.1.0.1 - Initial project template from stack  https://hackage.haskell.org/package/hspec-hashable-0.1.0.1 (mchaver)
05:52:54 <tomsmeding> you can work it out by hand :)
05:57:13 <tomsmeding> ezzieyguywuf: another way to see the same thing: for (.) we have the property that (f . g) x = f (g x), so that means that ((f .) . g) a b  =  (((f .) . g) a) b  =  ... you can work it out :)
05:58:38 <ezzieyguywuf> tomsmeding: lol, thank you.
05:58:39 <dminuoso> To me, it's just an idiom that I know what it does without knowing why
05:58:47 <dminuoso> I know I can do what tomsmeding did by hand too, just never bothered to
05:59:01 <tomsmeding> at this point it's also an idiom I know :p
05:59:14 <tomsmeding> I worked it out the first time I saw it though, because I was seriously confused back then
05:59:20 <dminuoso> Heh. I prefer f .: g over (f .) . g though
05:59:21 <ezzieyguywuf> if `test = [["abc", "def"], ["123", "456"]]` why does `[ header : body ] = test` result in a non-exhaustive pattern error?
05:59:35 <tomsmeding> (header : body) = test
06:00:00 <hseg> wait, Monad can no longer be defined in terms of join?
06:00:10 <dminuoso> correct
06:00:19 <hseg> :(
06:00:24 <dminuoso> it caused segfaults left and right because of GeneralizedNewtypeDeriving
06:00:35 <dminuoso> well okay only on the left side of things
06:00:38 <ezzieyguywuf> hrm,I think this is a function in Data.List actually...
06:01:00 <dminuoso> hseg: https://ryanglscott.github.io/2018/03/04/how-quantifiedconstraints-can-let-us-put-join-back-in-monad/
06:01:25 <dminuoso> It's a pretty wild story, at first it seemed so unlikely how join in Monad could cause segfaults with GeneralizedNewtypeDeriving
06:02:05 <hseg> ok, thanks
06:02:19 <honigkuchen> are there particular broader tasks in that functional programming languages or paradigms are better?
06:02:45 <honigkuchen> instead of answering a link can also help
06:03:19 <tdammers> bit of a vague question - to begin with, there isn't really a narrow definition of "functional programming" that enjoys a wide consensus
06:03:51 <honigkuchen> tdammers, is that an answer to me?
06:03:54 <tdammers> yes
06:04:15 <honigkuchen> tdammers, I do not care about an exact definination what functional programming is
06:04:45 <tdammers> OK, but if you look at languages that are sometimes labelled as "functional", there is quite some difference in where they shine
06:04:48 <Digit> tomsmeding: no ghcup.  am using different bedrocklinux strata for different ghc versions.
06:04:53 * hackage ukrainian-phonetics-basic 0.3.1.0 - A library to work with the basic Ukrainian phonetics and syllable segmentation.  https://hackage.haskell.org/package/ukrainian-phonetics-basic-0.3.1.0 (OleksandrZhabenko)
06:05:50 <tdammers> for example, scheme makes for a great scripting language, but lacks the type discipline you want in situations where you need a high degree of certainty about the code's properties, which in turn is something Haskell is good at
06:06:24 <honigkuchen> tdammers, lets forget all these others and only take haskell
06:07:00 <maerwald> no :p
06:07:07 <Digit> honigkuchen: wouldnt that be nice.  :)   lisps linger long though.  n_n
06:07:22 * hackage vulkan-utils 0.3 - Utils for the vulkan package  https://hackage.haskell.org/package/vulkan-utils-0.3 (jophish)
06:07:25 <honigkuchen> may it be that certain tasks are better for imperative languages and others are better for haskell
06:08:03 <tdammers> haskell *is* an imperative language /me runs away
06:08:05 <maerwald> at this point, I barely care about language paradigms anymore. The problem is that ADTs are still not a standard for all languages
06:08:22 <tdammers> anyway, if you want to know what haskell is good at, look at where it's used
06:08:23 * hackage vulkan 3.7, VulkanMemoryAllocator 0.3.10 (jophish): https://qbin.io/feof-nathan-jj0i
06:08:43 <maerwald> I'd pick any language that has a reasonable ecosystem and ADTs
06:08:47 <maerwald> the rest is details
06:09:37 <honigkuchen> abstract data type?
06:09:41 <maerwald> algebraic
06:09:45 <honigkuchen> ah
06:09:57 <tdammers> fintech, insurance, military, intelligence, economics, spam filtering, compiler research... generally, problem domains with a high degree of intrinsic complexity and a strong desire for static reasoning
06:10:34 <maerwald> fintech is more like high-speed anarchy, where haskell shines, because it's harder to constantly break your codebase
06:10:59 <tdammers> I think HFT is a domain where C++ still rules
06:11:04 <honigkuchen> what is intrinsic complexity
06:11:08 <n0042> Haskell has been kind of a learning curve coming from a mostly C background, but it's quickly become one of my favorite languages to use.
06:11:10 <maerwald> if there's something worse than agile, it's fintech :p
06:11:30 <tdammers> intrinsic complexity is complexity that is inherent to the problem itself, rather than being introduced by the mechanics of the tools you use to solve it
06:11:45 <maerwald> as opposed to accidential complexity
06:11:48 <tdammers> yes
06:11:55 <maerwald> there's papers and blog posts about this distinction
06:12:11 <honigkuchen> agile is a way of leading your team and fintech is a industry branch? how to compare those?
06:12:57 <ski> @quote is.the.world's.best
06:12:57 <lambdabot> SPJ says: Haskell is the world's best imperative language.
06:13:01 <honigkuchen> so a calculator has intrinsic complexity
06:13:04 <maerwald> honigkuchen: I'm just talking about my PTSD
06:13:27 <honigkuchen> but an editor maybe not
06:13:28 <ski> maerwald : "The problem is that ADTs are still not a standard for all languages" -- it seems some other more mainstream languages are slowly gaining them
06:14:03 <honigkuchen> https://en.wikipedia.org/wiki/PTSD_(disambiguation)
06:14:08 <yushyin> e.g. java
06:14:10 <tdammers> like, suppose you're writing a scheduling application for a logistics company. the routing and scheduling algorithms are fairly complex; no matter which language or tools you use, the problem will remain a complex one. that's the intrinsic complexity of the problem domain. now you build a frontend for that application, but the framework you pick doesn't quite get you the design you want, so you add all sorts
06:14:12 <tdammers> of quirks and workarounds to make it look like you want, and then more kludges to cover the edge cases that arise from that. that's accidental complexity.
06:14:34 <honigkuchen> ADTs seem to be cool and interesting, but what practical about them
06:14:48 <tdammers> in fact, centering things on a screen in HTML/CSS is a textbook example of accidental complexity
06:15:03 <n0042> Yay geometry
06:15:30 <tdammers> top = (screen.h - element.h) / 2
06:15:35 <tdammers> that's all the complexity there is
06:15:59 <tdammers> but if you want to do it with CSS, it becomes A LOT more complex. that's all accidental complexity
06:16:02 <maerwald> Depending on the problem, the Haskell itself can also be accidential complexity.
06:16:12 <tdammers> oh yes, very much
06:16:48 <tdammers> for example, when you need deterministic memory allocations - Haskell makes that really difficult, even though the problem itself is not intrinsically complex (call malloc() to get a chunk of memory, and free() to release it)
06:17:13 <maerwald> StrictData and pray the leaks go away
06:18:02 <tdammers> StrictData doesn't guarantee deterministic deallocation
06:18:22 <maerwald> yeah
06:18:29 <maerwald> so you pray
06:18:32 <maerwald> :D
06:19:16 <n0042> I have been having a heck of a time coming around to the way Haskell does I/O, but the rest of the language is so nice that it's made it worth the effort. It's complex but I get why it's complex.
06:19:33 <honigkuchen> is there one great example of a very special particular task, in that haskell code is hugely much faster written, than an imperative code
06:20:32 <maerwald> honigkuchen: yeah, quicksort, except it doesn't have the same properties :P
06:20:44 <honigkuchen> great
06:20:53 <n0042> Most of the benefits are about safety rather than speed, right?
06:21:05 <merijn> honigkuchen: My summary is: Getting started writing a simple project in Haskell is probably about 1.5-2x harder the same in Python. Writing a complex project in Haskell is about 10-100x easier than in Python :)
06:21:18 <maerwald> that's about right
06:21:34 <merijn> n0042: tbh, "just putting IO everywhere" is still nicer than many other languages :p
06:21:46 <maerwald> if you don't intend to maintain your code much, picking haskell is a weird choice
06:22:02 <maerwald> that's where it becomes useful
06:22:10 <merijn> n0042: Haskell is also much faster than Python/Ruby/PHP, tbh
06:22:36 <merijn> n0042: JS might be comparable, but only because google has thrown tens of thousands of man-years at V8 :p
06:22:48 <merijn> And even then only if you write careful JS
06:22:50 <honigkuchen> has haskell also an interpreter
06:22:55 <honigkuchen> or only an compiler
06:23:02 <maerwald> but these days ppl have different approaches with dealing with complexity... they see the language is too dumb to handle large codebases, so they think: let's split the code and do microservices
06:23:06 <n0042> It has an interpreter
06:23:14 <n0042> GHCi
06:23:15 <maerwald> I haven't really seen microservices in haskell, because what's the point
06:23:20 <honigkuchen> so it is both?
06:23:32 <merijn> honigkuchen: GHC comes with ghci which is a interpreter. It's not really great for writing code in, but you can quickly load and play with small code examples
06:23:58 <merijn> n0042: What difficulties have you been having with IO, btw?
06:24:18 <honigkuchen> there are not much programs that its languages comes with both, interpreter and compiler, right?
06:24:39 <merijn> Well, someone wrote a C and C++ interpreter too, so... :p
06:25:07 <n0042> honigkuchen: Many languages are not so black and white. Python is an interpreted language but it keeps compiled versions of what you write so that ti can be run faster next time (.pyc files)
06:25:36 <maerwald> writing fast python code is definitely possible, but requires crazy knowledge of the internals
06:25:52 <maerwald> And the code afterwards isn't really intuitive stuff
06:26:00 <n0042> Similarly, GHCi seems to pre-compile files that you load with `:l` even though it interprets what you write into the REPL
06:26:32 <merijn> n0042: It compiles to bytecode, not full compilation
06:26:43 <merijn> n0042: (which it also does for what you write in the REPL)
06:26:48 <n0042> That makes sense
06:26:59 <honigkuchen> you all always compare haskell always with python, but I never told that I use python most, and I do
06:27:27 <merijn> honigkuchen: It's one of the most common languages (together with JS), but I don't know JS :p
06:27:28 <maerwald> https://github.com/pkgcore/pkgcore is an example of a non-trivial optimised python application
06:27:47 <maerwald> so yes, you can do large projects in python too
06:28:18 <maerwald> but requires much more discipline
06:28:23 <tdammers> something being possible at all in a language is hardly an interesting metric, because pretty much anything can be done in any general-purpose language if you're thick-headed enough
06:28:38 <maerwald> tdammers: aren't we? =)
06:28:51 <honigkuchen> is there a reason that specifically fits to quicksort, why haskell is here "better" or whatsoever
06:29:04 <tdammers> haskell isn't better at implementing quicksort
06:29:13 <maerwald> honigkuchen: https://augustss.blogspot.com/2007/08/quicksort-in-haskell-quicksort-is.html
06:29:29 <tdammers> the famous "quicksort but not quite actually" example is used to demonstrate the elegance of the language
06:30:42 <n0042> merijn: The I/O difficulties I've been having are mostly just getting the hang of the syntax. I've been doing some assignments in Haskell that require using arrays, and the difference in syntax between ones that have to be treated like Monad-like objects and ones that don't is kind of a learning curve.
06:31:14 <n0042> I've been messing with immutable arrays, mutable arrays, and vectors to make my stuff meet the speed requirements (which are contrived and strict)
06:31:30 <merijn> n0042: ah, yeah, that can be a bit tricky
06:31:33 <n0042> And it has been pretty fun. Haskell is a really fun language. Glad I took the plunge
06:32:14 <honigkuchen> can it make sense to combine python and haskell in one program ?
06:32:54 <maerwald> python is used in GHC for the tests :p
06:32:57 <maerwald> does that count?
06:32:59 <n0042> Python is a great "glue" language (I use it for stuff instead of Bash all the time). So I could see myself writing a program in Haskell and then calling it from within a Python script. 
06:33:14 <merijn> n0042: tbh, I now consider Haskell a much better glue language :p
06:33:27 <LKoen> honigkuchen: https://github.com/jacquev6/Polyglot
06:33:31 <merijn> n0042: It's incredibly easy to call C code from Haskell
06:33:57 <tdammers> merijn: until that C code isn't reentrant, or takes callbacks, or involves variadic arguments
06:34:08 <LKoen> I once run into someone's code who used a makefile written in R, with code in C, C++, R and python
06:34:08 <merijn> tdammers: Yeah, but that's difficult in C too :p
06:34:20 <merijn> tdammers: tbh, even the callback one is easy
06:34:47 <merijn> Lack of reentrancy is hard, but also problematic in C and variadic arguments can't be used portably anyway, even within C :)
06:35:21 <merijn> tdammers: So at worst it's "no harder than using C from C" :p
06:35:31 <merijn> (which can, admittedly, be pretty hard)
06:36:10 <n0042> I love the way `readFile` works in Haskell. That's got to be the easiest way to do that ever.
06:36:10 <honigkuchen> lol
06:36:14 <merijn> tdammers: Anyway, I was mostly comparing to, say, the insanity of the FFI of python, Java, etc. which are much more convoluted and painful to use
06:36:23 <tdammers> no argument there :D
06:36:31 <merijn> n0042: Using the one from Prelude that returns String?
06:36:37 <n0042> Yeah
06:37:01 * ski . o O ( "Modelling Large Datasets Using Algebraic Datatypes: A Case Study of the CONFMAN Database" by Markus Mottl in 2002-05-15 at <http://www.ofai.at/cgi-bin/get-tr?paper=oefai-tr-2002-27.pdf> )
06:37:23 <merijn> n0042: Might wanna use Text for reading textual data: https://hackage.haskell.org/package/text-1.2.4.0/docs/Data-Text-IO.html#v:readFile
06:37:27 <gentauro> geekosaur: do you have a multiscreen setup with XMonad?
06:37:34 <merijn> (since you said performance matters)
06:37:42 <gentauro> more specifically, daisy chaining?
06:38:11 * ski . o O ( "Using Algebraic Datatypes as Uniform Representation for Structured Data" by Markus Mottl in 2003-03-07 at <http://www.ofai.at/cgi-bin/get-tr?paper=oefai-tr-2003-07.pdf>,<http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.13.5712> )
06:38:12 <n0042> merijn: Thank you very much
06:38:32 <tdammers> also, there's the caveat that readFile does lazy I/O, and that means the actual reading may happen at surprising times
06:39:29 <tdammers> e.g.: do { str <- readFile "foo"; unlink "foo"; putStrLn str } -- this may crash due to trying to read from a deleted file
06:39:44 <Boomerang_> I hear Data.Text.IO is not good if you care about locales
06:39:49 <Boomerang_> https://www.snoyman.com/series/haskell-bad-parts
06:42:49 <gentauro> tdammers: where do you delete the file? `unlink`?
06:42:54 <tdammers> yeah
06:43:15 <tdammers> although I believe on a typical (Linux) filesystem, you have to actually truncate it for that to crash
06:44:31 <n0042> Thanks Boomerang. Lots of information in that article.
06:44:54 <n0042> I wasn't aware of some of the pitfalls of `readFile`
06:45:21 <gentauro> tdammers: I recall me doing this -> `readFileStrict f = LBS.readFile f >>= \bs -> LBS.length bs `seq` pure bs` :'(
06:45:42 <gentauro> a strict version cos Linux complained about having to many files open
06:46:26 <merijn> tdammers: Text one doesn't do lazy IO
06:46:28 <gentauro> tdammers: how do you write `seq` in do-nation?
06:46:31 <tdammers> gentauro: why not just LBS.fromStrict <$> BS.readFile f
06:46:43 <tdammers> tdammers: lazy text one does I think
06:47:07 <merijn> Boomerang_: eh, that's wrong
06:47:17 <merijn> Boomerang_: readFile works fine if your locale isn't broken
06:47:45 <merijn> Boomerang_: readFileUtf8, etc. are dumb hacks that are broken on machines that are setup correctly
06:47:53 <tdammers> readFile does the correct thing: decode raw bytes into Unicode as per the current locale
06:48:05 <gentauro> tdammers: I don't think I have a `strict` ByteString
06:48:08 <gentauro> LBS is `lazy`
06:48:12 <merijn> Boomerang_: They're basically "ignore the local specified encoding and always use utf8", which is bad and anyone doing that should feel bad >.>
06:48:22 <tdammers> gentauro: yes, but you can read a strict bytestring and convert it to lazy
06:48:26 <gentauro> «fromStrict :: ByteString -> ByteStringO(1) Convert a strict ByteString into a lazy ByteString.»
06:48:31 <merijn> n0042: ^^ see above :)
06:48:44 <gentauro> tdammers: oh, got it
06:48:54 <merijn> gentauro: lazy bytestring is, effectively, just [Strict.ByteString] :p
06:49:23 <merijn> (i.e. a lazy list of strict chunks)
06:49:28 <tdammers> it's slightly more clever than [ByteString], but yeah, essentially that
06:49:36 <gentauro> merijn: yeah, I got that
06:49:45 <n0042> Luckily I'm only using it to read predictable input right now, so it works pretty well. 
06:50:12 <tdammers> anyway, the problem with readFile and locales is when people assume that any file they might possibly want to read from is encoded according to the current locale
06:50:27 <tdammers> which is of course often wrong, but just assuming UTF8 isn't any better
06:50:52 * hackage haskell-xmpp 2.0.0 - Haskell XMPP (eXtensible Message Passing Protocol, a.k.a. Jabber) library  https://hackage.haskell.org/package/haskell-xmpp-2.0.0 (Jappie)
06:50:55 <gentauro> tdammers: the only way to be 100% is to read the hole file
06:50:58 <merijn> tdammers: Also, people who have badly configured machines with broken locales complaining that they're broken and "fixing" it by breaking it for everyone who *does* have a properly configured locale >.>
06:51:23 <Boomerang_> merijn: I guess it depends on the use case but I think more often I would rather it reported an error if it's not UTF-8 than do something weird instead
06:51:40 <merijn> Boomerang_: It doesn't do anything weird, though
06:51:58 <merijn> Boomerang_: It literallys asks the environment "what is the environment encoding?" and then uses that
06:52:25 <merijn> Boomerang_: If you want explicit control over decoding you can either 1) override the encoding for a handle or 2) read a ByteString and explicitly decode it
06:52:43 <tdammers> indeed
06:53:47 <tdammers> readFileUtf8 is the correct thing to use when you know that the input is UTF8 even when the locale is not
06:53:58 <tdammers> but otherwise, readFile does exactly the right thing
06:56:15 <hseg> trying to work through the unifications behind (.) (.) (.)'s type. iirc there was an interactive tool that showed unifications
06:56:21 <hseg> can't find it though
06:56:56 <merijn> isn't that tool just called Cale and/or ski ;)
06:57:03 <hseg> :)
06:57:49 * ski grins
07:05:39 <hseg> nm -- this case is most easily understood as fmap.fmap
07:08:01 <ski> it's easy to derive the `(.) . (.)' formulation
07:08:17 <merijn> hmm, suppose I have mapping from Foo to Bar that requires "Foo -> IO Bar" to lookup, is there some convenient way to memoize that into a Map so repeated lookups only run the IO once?
07:09:19 <ski> hm, something like `Ord k => (k -> IO v) -> IO (k -> IO v)' ?
07:11:38 <merijn> ski: Something along those lines
07:14:19 <ski> @wiki Top level mutable state#Proposal 4: Shared on-demand IO actions .28oneShots.29
07:14:19 <lambdabot> https://wiki.haskell.org/Top_level_mutable_state#Proposal_4:_Shared_on-demand_IO_actions_.28oneShots.29
07:14:22 <ski> @wiki Global keys
07:14:22 <lambdabot> https://wiki.haskell.org/Global_keys
07:15:58 <merijn> Those are more ideas than implementation, afaict?
07:16:39 <ski> yes
07:16:46 <xe4> I don't see a difference in these toJSON instances: https://gist.github.com/xe-4/27c685e6d22e05251c1a653fec791926 will someone talk to when you might one over the other?
07:17:06 <xe4> I meant to say "when you might want one over the other"
07:18:32 <siraben> How can I check if something is a substring of a lazy bytestring?
07:18:41 <siraben> There's no `isInfixOf` for Data.ByteString.Lazy
07:19:37 <kuribas> merijn: put the Map in an IORef?
07:19:50 <merijn> kuribas: But I don't have a Map
07:20:01 <kuribas> merijn: put an empty Map in the IORef?
07:20:39 <merijn> I can wrap an IORef with a Map, but I was hoping someone would've already done the work for me of writing that logic :p
07:21:11 <kuribas> or better, use lazy IO and implement: Ord k => (k -> IO v) -> IO (k -> v)
07:21:37 <kuribas> as long as you know the v is determined by k
07:23:18 <kuribas> merijn: I don't know if it exists, but at least it doesn't sound hard to implement.
07:23:41 <siraben> isInfixOf is even commented out in the lazy bytestring source code
07:23:42 <siraben> hmm
07:23:54 <siraben> Is there no way to do it except convert it to strict then run isInfixOf?
07:24:36 <geekosaur> not easily. consider what happens when it crosses chunks. then what happens when it crosses multiple chunks
07:25:09 <geekosaur> you basically end up making it strict anyway just to avoid all the corner cases
07:25:57 <siraben> Ah, right.
07:26:37 <honigkuchen> one of my ex professors was always very enthustiastic about haskell but in a further lecture he proposes that there is a new star at the functional programming languages heaven
07:26:45 <honigkuchen> what might he had proposed
07:27:06 <honigkuchen> it is already around 6 years past
07:27:39 <PacoV> o/
07:30:11 <honigkuchen> something similar neat complex like haskell to can be entusiastic about
07:30:29 <honigkuchen> I can not remember
07:30:30 <Ferdirand> honigkuchen: Idris maybe ?
07:30:53 <honigkuchen> that could it be
07:31:09 <honigkuchen> very difficult for me to remember
07:31:18 <honigkuchen> he only named it
07:31:25 <Ferdirand> or Agda ?
07:31:31 <geekosaur> there are a number of languages that can be considered inspired by haskell, each going its own direction with some concept or group of concepts
07:32:13 <PacoV> Hey, I've a coupe of questions if you have the time. I've this package https://gitlab.com/pcoves/hakyll-contrib-i18n that build just fine with stack but fail miserably with cabal telling it can't find dependencies suchs as pandoc-types. What's up with that? Also, how does one push documentation to hackage?
07:32:53 * hackage haskell-xmpp 2.0.1 - Haskell XMPP (eXtensible Message Passing Protocol, a.k.a. Jabber) library  https://hackage.haskell.org/package/haskell-xmpp-2.0.1 (Jappie)
07:32:58 <merijn> PacoV: Can you pastebin the exact error?
07:33:49 <honigkuchen> what is cool or better or interesting about Agda or Idris
07:34:01 <honigkuchen> and when is haskell better
07:34:15 <hekkaidekapus> @hackage stack2cabal -- PacoV
07:34:15 <lambdabot> https://hackage.haskell.org/package/stack2cabal -- PacoV
07:35:32 <geekosaur> honigkuchen, they're both dependently typed. which means they can handle more things than haskell, but you have to carry more proofs around in your programs
07:36:02 <honigkuchen> what is dependently typing
07:36:41 <PacoV> merijn: http://ix.io/2Frk
07:37:20 <merijn> PacoV: What version of cabal-install?
07:37:59 <PacoV> merijn: 3.2.0.0-108
07:38:25 <PacoV> hekkaidekapus: I'll have a look, thanks!
07:38:27 <merijn> hmm, weird
07:39:29 <merijn> PacoV: Basically, for some reason it seems to think it *has* to use pandoc-types version (1.22), but another dependency (pandoc-include-code) doesn't support that version
07:39:30 <geekosaur> honigkuchen, where a type depends on a value. but now you have to carry around a proof that a value conforms to the type it's being used at
07:40:03 <maerwald> honigkuchen: F* wasn't around back then I think
07:40:04 <geekosaur> (consider a subset type, for example integers less than 20, for a simple example)
07:40:18 <maerwald> that's the only one I can think of with enough focus and purpose to take off
07:40:26 <maerwald> in... 10 yeahs
07:40:36 <honigkuchen> does anyone know a good page that explains that broader? or I just google for it
07:40:47 <hekkaidekapus> PacoV: `cd yourProjectTopDir; cabal install stack2cabal; stack2cabal; cabal build`
07:41:00 <PacoV> merijn: if pandoc-include-code depends on pandoc-types 
07:41:11 <PacoV> I can remove the later as an explicit dependency.
07:42:05 <merijn> PacoV: Yes, but pandoc-include-code depends on pandoc-types>=1.20 && <=1.20)
07:42:09 <merijn> (see the error)
07:42:27 <merijn> And for some reason it forces the use of the installed pandoc-types which is 1.22
07:43:19 <PacoV> Well, I can't even `cabal install` anything.
07:43:29 <PacoV> But it works with `stack install`.
07:43:41 <PacoV> Guess I f*cked up somehow.
07:44:41 <merijn> PacoV: oh...
07:44:50 <merijn> did you run "cabal install pandoc-types"?
07:44:51 <hekkaidekapus> maerwald: Without me looking far, would know what is this about? `user error (expected ResolverRef instead of tag:yaml.org,2002:map tagged mapping)`
07:45:00 <PacoV> Nop.
07:45:04 <PacoV> Will do.
07:45:10 <merijn> PacoV: No, don't :p
07:45:35 <merijn> That's what I was gonna try and fix, but if you didn't then I dunno where it's getting pandoc-types from
07:46:18 <maerwald> hekkaidekapus: what fails, stack2cabal?
07:46:44 <PacoV> stack2cabal: user error (expected ResolverRef instead of tag:yaml.org,2002:map tagged mapping)
07:46:47 <maerwald> where's the stack,yaml?
07:46:47 <PacoV> Hum.
07:47:14 <maerwald> the pantry syntax is excessive, so it's hard to cover everything
07:47:18 <PacoV> https://gitlab.com/pcoves/hakyll-contrib-i18n/-/blob/master/stack.yaml
07:47:25 <hekkaidekapus> Yeah, see above the chain of commands I suggested to PacoV. The project is at <https://gitlab.com/pcoves/hakyll-contrib-i18n>
07:47:35 <PacoV> hekkaidekapus: I've the same error.
07:47:58 <hekkaidekapus> I know, I was using your project. ;)
07:48:14 <hekkaidekapus> And maerwald is the maintainer of stack2cabal.
07:48:18 <maerwald> yep, I can reproduce
07:48:21 <hyperisco> if I have two prisms, how can I turn those into a traversal?
07:48:36 <PacoV> Ho, ok, sorry.
07:48:42 <maerwald> resolver: https://raw.githubusercontent.com/commercialhaskell/stackage-snapshots/master/lts/16/20.yaml
07:48:43 <glguy> hyperisco: with .
07:48:44 <maerwald> this fixed it
07:48:55 <maerwald> but there's another error
07:49:02 <siraben> Is there a variant of `simpleHttp` that automatically retries? I'm sending web requests concurrently but don't want the whole thing to stop because a single thread failed
07:49:16 <hyperisco> glguy, I don't want one prism after the other, I want both in parallel
07:49:55 <hyperisco> if I have a prism for the 1st value and 2nd value, I want a traversal over the 1st and 2nd values
07:50:05 <hyperisco> I don't want a prism from the 1st value into the 2nd value of the 1st value
07:50:18 <maerwald> hekkaidekapus: https://github.com/hasufell/stack2cabal/issues/26
07:50:30 <maerwald> I think it needs some adjustments to support that snapshot file
07:50:34 <hyperisco> or I want something other than a traversal that does this sort of thing
07:50:56 <maerwald> hekkaidekapus: the parser is here https://github.com/hasufell/stack2cabal/blob/master/lib/StackageToHackage/Stackage/YAML.hs
07:51:09 <glguy> hyperisco: you just want to traverse the structure twice then?
07:51:17 <hyperisco> no
07:51:25 <hyperisco> I have two prisms
07:51:33 <hyperisco> both are from X to Y
07:52:06 <hyperisco> okay lets put it this way… I have some lens to get deep into the structure
07:52:10 <maerwald> hekkaidekapus: shouldn't be hard
07:52:10 <PacoV> I made a clean install (deleted the ~/.cabal dir also) of cabal-install.
07:52:17 <hyperisco> now I have two prisms, there are two ways to go, I want to traverse over both ways
07:52:22 <hyperisco> I don't want to get deep into the structure twice
07:52:33 <PacoV> I can `cabal update` but can't `cabal install stack2cabal` either.
07:52:38 <glguy> Prisms degrade to traversals, so we can just forget that they are prisms
07:53:06 <glguy> You can combine them in any way other than to run one after the other
07:53:14 <hyperisco> that isn't what I want oO
07:53:17 <glguy> Can't*
07:53:49 <merijn> PacoV: Which os/distro?
07:54:00 <glguy> If 'failing' does what you want you can use it
07:54:03 <merijn> PacoV: What does "ghc-pkg list" show?
07:54:03 <PacoV> Arch.
07:54:07 <merijn> oof
07:54:16 <PacoV> It gives me a shit tonne of warnings!
07:54:28 <merijn> PacoV: Did you, by any chance install any packages via Arch's package manager?
07:54:29 <hyperisco> I think we're talking past each other because I am using profunctor lenses
07:54:35 <PacoV> Yep.
07:54:40 <merijn> PacoV: RIP
07:54:57 <PacoV> Ho, no big deal, I'll remove them.
07:55:04 <glguy> hyperisco: the issues would be the same except they don't degrade automatically
07:55:08 <merijn> PacoV: The Arch wiki should have a page on how to "unfuck" things :)
07:55:08 <PacoV> Mainly pandoc.
07:55:23 <PacoV> Haha, we all need this because of reasons.
07:55:30 <hyperisco> if you compose two prisms you absolutely do not get what I am describing
07:55:33 <hyperisco> I point back to my example
07:55:35 <PacoV> I'll give i a try.
07:55:43 <merijn> PacoV: Arch's Haskell packages have a...tendency to render your Haskell install unusable (if you ever get it working to begin with)
07:55:45 <glguy> hyperisco: yeah I know,
07:55:53 <hekkaidekapus> maerwald: Noted, thanks.
07:56:06 <merijn> PacoV: I believe there's several Arch wiki pages on the topic
07:56:37 <maerwald> hekkaidekapus: https://github.com/hasufell/stack2cabal/blob/e6fae40d913ed67363671fb7238e74afedd78ffc/lib/StackageToHackage/Stackage/YAML.hs#L87 needs another alternative for the syntax from the 20.yaml
07:56:38 <glguy> Hyper for the parallel behavior look at whatever failing got turned into in this other library
07:56:40 <merijn> PacoV: So, I believe the problem you have is the following: Arch's package manager is installing pandoc-types-1.22 into a global database forcing cabal-install to use it
07:57:07 <maerwald> hekkaidekapus: it's quite unfortunate how conflated packages and deps in stack.yaml is
07:57:11 <merijn> PacoV: But your other dependencies don't support pandoc-types-1.22 yet, so cabal-install is going "well, I can't find compatible versions of your dependencies!" (hence the error)
07:57:11 <glguy> Failing assumes the two are disjoint
07:57:41 <hyperisco> oh now this is feeling like I asked this 1-2 years ago
07:57:57 <merijn> PacoV: If the systemwide pandoc-types install is gone cabal-install should simply pick an older (supported) pandoc-types
07:58:06 <PacoV> I removed every bit of (easy to find) haskell packages and removed both ~/.cabal and ~/.stack.
07:58:15 <hyperisco> and I think then I just decided it was too complicated to bother and went back to explicit recursion lol
08:00:18 <PacoV> http://ix.io/2Frq
08:00:21 <PacoV> Fail.
08:00:35 <PacoV> On `cabal install stack2cabal`.
08:01:25 <geekosaur> now that looks like arch doing its thing
08:01:52 <maerwald> PacoV: there sre static binaries: https://github.com/hasufell/stack2cabal/releases/tag/v1.0.12
08:01:56 <geekosaur> tbh you should just jettison all haskell related pakages including ghc, then use ghcup to install a working ghc
08:02:23 * hackage reflex-monad-auth 0.1.0.0 - Utilities to split reflex app to authorized and not authorized contexts  https://hackage.haskell.org/package/reflex-monad-auth-0.1.0.0 (NCrashed)
08:03:06 <maerwald> PacoV: I'm not a fan of distributing binaries via hackage, but the original mainainer put it up there. The repo itself uses a freeze file.
08:03:23 * hackage reflex-monad-auth 0.1.0.1 - Utilities to split reflex app to authorized and not authorized contexts  https://hackage.haskell.org/package/reflex-monad-auth-0.1.0.1 (NCrashed)
08:04:49 <honigkuchen> are the "new" c++ concepts that enhance templating or whatsoever a form of dependently typing?
08:05:44 <siraben> http://ix.io/2Frs If any of the requests fail then `mapConcurrently` will fail, what should I do instead?
08:05:48 <siraben> I'm using `simpleHttp` to get the contents
08:06:17 <merijn> siraben: Well what do you wanna do on failure?
08:06:28 <siraben> merijn: Retry
08:06:38 <siraben> So I'd have to catch an IO exception?
08:06:58 <merijn> siraben: https://hackage.haskell.org/package/broadcast-chan-0.2.1.1/docs/BroadcastChan.html#v:parMapM_ :p
08:08:45 <PacoV> Looks like I need a better packages purge.
08:08:48 <PacoV> BRB
08:09:47 <geekosaur> either that or install ghc-static so at least the base package and relatives aren't broken but better is t just get a working ghc and core libraries from somewhere other than the arch repo
08:10:18 <siraben> merijn: should I not use simpleHttp then, since it returns IO ByteString.Lazy?
08:10:40 <merijn> siraben: That's easily solved with toStrict + evaluate ;)
08:11:24 <merijn> siraben: There's a conduit wrapper to stream request into too, btw
08:11:33 <honigkuchen> how is it that a dependently typed language can handle more than a not dependently typed one
08:13:29 <PacoV> WTF Could not find module ‘Prelude’ ?
08:14:02 <merijn> PacoV: That's usual if your GHC is installed via Arch packages
08:14:49 <merijn> Because the Arch package installs a GHC with a broken default config...on purpose...yay
08:15:16 <PacoV> I listed every single package installed on my system (haskell ones are prefixed with `haskell-` on arch), filtered them and remove all the `haskell-*` then installed `cabal-install`.
08:15:33 <maerwald> merijn: arch is starting to be more annoying than the macOS PATH issues :p
08:15:37 <PacoV> Ho, ok, you're telling me not to install cabal-install using pacman.
08:16:02 <PacoV> I'll give ghcup a try.
08:16:16 <merijn> maerwald: I mean, the macOS PATH issue is at least defensible, since those are indeed not standard PATH locations
08:16:55 <merijn> If Arch insists on shipping a dynamic GHC, could they not at least set it to link dynamic by default? >.>
08:23:57 <PacoV> Looks like ghcup is doing the trick.
08:24:42 <ski> @type let memoIO :: Ord k => (k -> IO v) -> IO (k -> IO v); memoIO f = do ref <- Data.IORef.newIORef M.empty; return (\k -> do map <- Data.IORef.readIORef ref; case M.lookup k map of Just v -> return v; Nothing -> do v <- f k; Data.IORef.writeIORef ref (M.insert k v map); return v) in memoIO
08:24:43 <lambdabot> Ord k => (k -> IO v) -> IO (k -> IO v)
08:24:56 <ski> @type let memoIO :: Ord k => (k -> IO v) -> IO (k -> IO v); memoIO f = do ref <- Data.IORef.newIORef M.empty; return (\k -> mfix (\v -> maybe (f k) return =<< Data.IORef.atomicModifyIORef ref (\map -> case M.lookup k map of Just v -> (map,Just v); Nothing -> (M.insert k v map,Nothing)))) in memoIO
08:24:58 <lambdabot> Ord k => (k -> IO v) -> IO (k -> IO v)
08:25:08 <ski> @type let memoIO :: Ord k => (k -> IO v) -> IO (k -> IO v); memoIO f = do ref <- Data.IORef.newIORef M.empty; return (\k -> mfix (\v -> maybe (f k) return =<< Data.IORef.atomicModifyIORef ref (swap . M.insertLookupWithKey (\_ _ v -> v) k v))) in memoIO
08:25:10 <lambdabot> Ord k => (k -> IO v) -> IO (k -> IO v)
08:25:17 <ski> @type let memoIO :: Ord k => (k -> IO v) -> IO (k -> IO v); memoIO f = do ref <- Data.IORef.newIORef M.empty; return (\k -> do v <- System.IO.Unsafe.unsafeInterleaveIO (f k); Data.IORef.atomicModifyIORef ref (\map -> case M.lookup k map of Just v -> (map,v); Nothing -> (M.insert k v map,v))) in memoIO
08:25:19 <lambdabot> Ord k => (k -> IO v) -> IO (k -> IO v)
08:25:26 <ski> @type let memoIO :: Ord k => (k -> IO v) -> IO (k -> IO v); memoIO f = do ref <- Data.IORef.newIORef M.empty; return (\k -> do v <- System.IO.Unsafe.unsafeInterleaveIO (f k); fromMaybe v <$> Data.IORef.atomicModifyIORef ref (swap . M.insertLookupWithKey (\_ _ v -> v) k v)) in memoIO
08:25:27 <lambdabot> Ord k => (k -> IO v) -> IO (k -> IO v)
08:25:32 <jollygood2> hi. I asked the other day, but I didn't keep logs. I need to make a simple personal website, and I want to explore FRP. what library do you recommend?
08:25:49 <PacoV> jollygood2: Hakyll?
08:26:34 <ski> merijn,kuribas : i don't really see how to do `Ord k => (k -> IO v) -> IO (k -> v)' (e.g. with `unsafeInterleaveIO'), without also passing a collection of valid `k's
08:27:49 <PacoV> ghcup actually allowed me to install stack2cabal.
08:28:02 <jollygood2> PacoV thanks, I'll take a look
08:28:17 <PacoV> But the later failed to process my package as we expected.
08:28:31 <maerwald> PacoV: yes, I posted above what needs to be adjusted
08:29:17 <PacoV> jollygood2: And if you plan on writting on multiple languages, I published https://hackage.haskell.org/package/hakyll-contrib-i18n yesterday :-)
08:29:25 <maerwald> PacoV: https://github.com/hasufell/stack2cabal/blob/master/lib/StackageToHackage/Stackage/YAML.hs both the packages and the resolver parser need another alternative
08:30:34 <PacoV> maerwald: I guess I'm too new to understand the meaning of this :-/
08:30:44 <maerwald> it's just a yaml parser
08:30:53 <PacoV> But cabal actually builds my package right now.
08:31:01 <PacoV> So I might not need anything else.
08:31:13 <maerwald> stack.yaml follows some weird "pantry" thing, which has so many ways to express the same thing that I can't keep up
08:31:40 <PacoV> It's okay. I mean, I'd gladly get rid of the stack part if possible.
08:31:47 <maerwald> the line between package and dependency is also completely blurred
08:32:05 <ski> @hoogle (a -> IO b) -> IO (a -> b)
08:32:06 <lambdabot> No results found
08:32:40 <PacoV> Well, it'll take time. I'll walk the dog in the mean time.
08:35:34 <ski> @type let unsafeInterleaveIOResult :: (a -> IO b) -> IO (a -> b); unsafeInterleaveIOResult f = return (System.IO.Unsafe.unsafePerformIO . f) in unsafeInterleaveIOResult  -- perhaps something like this could be used, assuming `NOINLINE',&c. precautions
08:35:37 <lambdabot> (a -> IO b) -> IO (a -> b)
08:40:39 <maerwald> what's a safe way to convert Integer to Word64
08:52:29 <ProofTechnique> @maerwald `fromIntegral`?
08:52:29 <lambdabot> Unknown command, try @list
08:53:05 <tdammers> define "safe"
08:53:36 <maerwald> 1. memory safe 2. doesn't truncate randomly or do other crap when the Integer is out of range
08:53:46 <maerwald> so a Maybe is ok too
09:02:53 <PacoV> \o/ Yeah, cabal build succeeded.
09:08:20 <xsperry> maerwald toIntegralSized
09:09:10 * [exa] smashes bookmark button
09:12:28 <[exa]> xsperry: hmmm.. isn't the check in the toIntegralSized docs example wrong? here https://hackage.haskell.org/package/base-4.14.0.0/docs/Data-Bits.html#v:toIntegralSized
09:14:01 <[exa]> (the comparison there does basically `toInteger x == toInteger x` does that make sense? I would understand if there would be `x == fromInteger y` instead)
09:18:50 <ProofTechnique> I expect the second `toInteger` to be at a different specialized type. The real implementation is _a read_, though
09:19:07 <ProofTechnique> Otherwise yeah, maybe just a typo
09:20:24 <ProofTechnique> Oh, yeah, the actual implementation says `y = fromIntegral x`, so maybe that's a typo in the docs
09:27:51 <[exa]> oh my, I'd report it but ghc gitlab is giving me http500 on auth
09:36:46 <erisco> is there anything to be said for Profunctor & Category because I think liftA2 (.) is how I want to compose optics
09:37:17 <ezzieyguywuf> what do y'all use for regular expressions in haskell?
09:37:37 <[exa]> erisco: you saw prolens package right?
09:37:46 <erisco> maybe
09:37:59 <geekosaur> parsing instead of regular expressions, generally
09:38:58 <[exa]> erisco: not sure about liftA2 (.) but I guess it will give easier than Control.Lens
09:39:26 <erisco> I am using profunctor lenses
09:39:31 <[exa]> ah ok
09:39:49 <ezzieyguywuf> geekosaur: I knew someone would say that.
09:40:11 <erisco> But I keep wanting to do things it seems Profunctor and friends cannot
09:41:00 <[exa]> anyway what would be the semantics of the lifted (.) ?
09:41:26 <erisco> basically, once you're at a point in a structure, you want to split and do two things, then bring the results back together
09:42:09 <erisco> (.) isn't precisely that but it suffices
09:43:14 <matta> Newbie question! I am setting up Haskell on macOS. haskell.org/platform recommends I use ghcup to install ghc and cabal, then use haskellstack.org to install stack. But it looks like stack then installs yet another ghc (but not another cabal, which it largely duplicates?). I don't relish this apparent duplication of fucnctionality, especially the possible screwups I could get myself into with two compiler installations. As a newbie who
09:43:14 <matta> wants to keep things as simple for myself as possible, should I just wipe everything and only install stack?
09:43:29 <[exa]> erisco: so, say "process all items from a list but take `lens1` from the first and `lens2` from the second" ?
09:43:35 <[exa]> s/second/tail
09:44:12 <erisco> say I have a prism for element 1 and other for element 2
09:44:23 * hackage hakyll-contrib-i18n 0.1.1.0 - A Hakyll library for internationalization.  https://hackage.haskell.org/package/hakyll-contrib-i18n-0.1.1.0 (pcoves)
09:44:24 <[exa]> matta: I'd advise for going without stack first, it's a brutal tool
09:44:52 <[exa]> matta: unless you need it to support an IDE that requires stack ofc
09:45:01 <erisco> I mean lens for 1 and 2... then I should be able to have both 1 and 2
09:45:02 <sm[m]> oh come on
09:46:26 <erisco> So I'm suggesting liftA2 (.) which does 1 then 2 in sequence
09:47:47 <matta> [exa]: great, so long as vanilla ghc/cabal won't be teaching me things that are widely deprecated I'm happy to start with them.
09:48:11 <erisco> but I don't know if there is a better formulation... is Profunctor & Category really a thing?
09:48:38 <koz_> Category implies Profunctor.
09:48:53 <koz_> (you can implement dimap using Category's first and second)
09:49:21 <erisco> Category doesn't have first and second
09:49:58 <koz_> Sorry, I was confusing Arrow.
09:50:03 <[exa]> matta: certainly not, stack is not "more advanced", it's just for more complicated&problematic setups. I'm using just normal ghc+cabal
09:50:09 <koz_> Basically, Profunctor + Category = Arrow, more or less.
09:50:22 <erisco> if the conclusion is "that's just Arrow" then I dunno
09:50:25 <koz_> (I should not reply so soon after waking lol)
09:50:44 <koz_> Well, Arrow is _a_ solution sure.
09:50:52 <merijn> matta: https://gist.github.com/merijn/8152d561fb8b011f9313c48d876ceb07
09:51:14 <erisco> I am not any expert on the aesthetics/objectives of optics
09:51:37 <[exa]> matta: also, for simple beginner-level programs it's usually sufficient to have ghci working, then load a file with :l, reload with :r, and test stuff by hand
09:51:52 <erisco> so I don't know if I am just throwing a wrench in
09:52:31 <[exa]> erisco: can you show an example of how would you like to use that? I'm still thinking it's just some kind of (reverse) traversal
09:54:34 <erisco> say I want to increment the first two numbers in a list, then if I can prism the first and prism the second ther ought to be an optic that does them both
09:57:08 <matta> merijn: great gist, thanks.
09:59:23 <monochrom> Heh stack goes way beyond the batteries-included principle.
10:01:01 <koz_> monochrom: Yeah, because it's 'undocumented nuclear batteries included, with mind-changing reserved for us'.
10:01:55 * geekosaur would have put it as "power plant included and rebuilt according to our whim on the fly"
10:02:59 <monochrom> Well, I was going for a "walled garden" wording.
10:05:11 <matta> I guess since I'm just typing oneliners into ghci at the moment, stack is overkill.  ;-)
10:06:19 <monochrom> I think people have accepted "real devs have 64-core 1TB-RAM 1Gbps-internet", they won't notice or mind frequent rebuilds and redownloads.
10:07:04 <monochrom> But devs are still divided on walled garden vs liberal wilderness.
10:08:01 <dolio> The stuff that comes with GHC is probably sufficient for lots of learning. You don't need any package management.
10:08:13 <dolio> At least, it was when I was learning. Package managers didn't exist.
10:08:47 <monochrom> Yeah, I was there when cabal didn't exist, too.
10:09:01 <monochrom> Even after cabal existed, for a while I ran Setup.hs by hand.
10:09:24 <maerwald> monochrom: if I clone my work project and try to build it with stack, I have to wait 30 minutes just for the git repos to be fetched :)m
10:10:12 <maerwald> https://github.com/commercialhaskell/stack/issues/5411
10:10:31 <maerwald> so yes, devs don't consider ram or my old cable under the house
10:10:40 <monochrom> I think people simply take advantage of https://xkcd.com/303/
10:11:27 <maerwald> either that or I'm waiting between 1-2 hours for CI to fail
10:11:29 <monochrom> oh haha, that one is a bit extreme though, "clone as many times as there are subdirs"
10:11:34 <maerwald> yep
10:11:44 <maerwald> nix does the same
10:11:49 <maerwald> only cabal doesn't
10:12:42 <monochrom> This is why devs should be confined to 10-inch netbooks, and unplugged. (Still remember "netbooks"?)
10:12:57 * geekosaur is using one, tyvm
10:13:14 <geekosaur> (and waiting for it to run out of swap space…)
10:13:16 <monochrom> (and on 802.11b wifi)
10:13:40 <hyperisco> [exa], did that make any sense?
10:13:50 <maerwald> or we could establish programmer licenses... I mean, doctors also have those and they also can lose them
10:13:53 <maerwald> right?
10:15:23 <monochrom> Confine devs to the one-laptop-per-child laptop, and its intended usage environment: slow or non-existent internet access, and electricity comes from a solar panel.  This will teach devs to respect accessibility and the value of all those "analyze the running time of these algorithms" courses.
10:17:49 <maerwald> I think bugs aren't embarrassing these days anymore, because everything is rolling release and agile. If you messed up multiple releaes in a row in the earlier tarball-ftp days, ppl would raise an eyebrow.
10:18:07 <monochrom> like I said last week: perpetual beta
10:19:45 <PacoV> Thanks all!
10:21:16 <[exa]> hyperisco: yeah I had to afk... So basically we want something that combines 2 prisms into a traversal? (or another prism-traversal?)
10:21:22 <hyperisco> > let (^>) = liftA2 (.) in (_1 ^> _2 .~ 3) ("hello","sailor!")
10:21:25 <lambdabot>  error:
10:21:25 <lambdabot>      • Couldn't match type ‘[Char]’ with ‘([Char], b)’
10:21:25 <lambdabot>          arising from a functional dependency between:
10:21:52 <hyperisco> well I don't know how things work with this sort of optics
10:22:50 <hyperisco> I question whether it makes sense as a traversal, I don't see how
10:23:21 <hyperisco> but anyways, the result of that was  (3, 3)
10:23:47 <monochrom> Do you have to use lenses and prisms?
10:24:20 <hyperisco> why wouldn't I
10:24:30 <monochrom> just checking
10:24:48 <hyperisco> I could choose not to use optics at all but I am trying to get some benefit from them
10:25:08 <dolio> I didn't read super closely, but it seemed to me that the problem with your example is that it relied on very specific knowledge of what your optics do that does not apply to all optics of the same type.
10:25:09 <solonarv> > ("hello", "sailor") & (_1 <> _2) .~ 3
10:25:11 <lambdabot>  error:
10:25:12 <lambdabot>      • No instance for (Num [Char]) arising from the literal ‘3’
10:25:12 <lambdabot>      • In the second argument of ‘(.~)’, namely ‘3’
10:25:29 <solonarv> huh, that got closer then I expected
10:25:37 <solonarv> > ("hello", "sailor") & (_1 <> _2) .~ "huh"
10:25:39 <lambdabot>  ("huhhello","sailorhuh")
10:25:59 <solonarv> well that's definitely not right.
10:26:15 <dolio> So, like, just because the example would make sense doesn't mean that there must be a function to combine two optics in this way in general.
10:27:01 <hyperisco> not sure what you mean by "must"… I mean "ought" in that it seems obvious from a pragmatic point of view
10:28:26 <dolio> The examples that don't make sense might prevent there from being such a function, unless you can narrow the types involved down to only the ones that do make sense.
10:29:03 <hyperisco> I haven't checked against the laws
10:29:28 <hyperisco> they seem rather immaterial to me
10:31:21 <solonarv> it's definitely going to be unsound because it'll produce nonsense when you give it overlapping optics
10:31:39 <solonarv> but that doesn't mean such a function can't exist, of course
10:34:18 <hyperisco> I would guess it probably is lawful
10:34:43 <hyperisco> but I am uncomfortable talking about laws on type synonyms
10:39:20 <slack1256> Apart from shell scripting, what is the way to determine which package exports certain module?
10:39:52 <dminuoso> slack1256: hoogle?
10:40:12 <dminuoso> It's not ideal because hoogle by default only looks at some stackage resolver
10:40:19 <dminuoso> And it varies between package versions
10:40:33 <jle`> stackage maybe (stoogle), if it's on stackage
10:40:34 <slack1256> dminuoso: You're golden, thanks.
10:42:28 <koz_> stoogle?
10:42:36 <solonarv> suppose I have 'jt = thatFunction _Just _Just' and I run 'toListOf jt (Just 3 & jt %~ succ)', I'll get [5,5]; this isn't the same as 'succ <$> (toListOf jt (Just 3'))', which is [4,4]
10:42:46 <jle`> stoogle is what i call stackage hoogle :)
10:43:14 <solonarv> the lens laws aren't formulated in terms of toListOf but still this should clearly show that 'jt' isn't a well-behaved (i.e. lawful) optic
10:44:04 <jle`> what is thatFunction ?
10:45:59 <monochrom> slack1256: "ghc-pkg find-module" can do it for what you have installed.
10:46:34 <p0a> Hello given a list of numbers such as [1,2] I'd like to generate [[1,2], [-1,2], [1,-2], [-1,-2]], all possible sign permutations 
10:47:13 <p0a> I had some sort of zipWith idea in mind, and I vaguelly recall that the monadic implementation of [] is not unique, and I need the other one, not the standard one
10:47:21 <slack1256> monochrom: Magic.
10:47:25 <slack1256> Thanks monochrom.
10:47:27 <monochrom> If you add --package-db=$HOME/.cabal/store/ghc-<version>/package.db , it looks there.
10:47:46 <jle`> > mapM (\x -> [x,-x]) [1,2]
10:47:48 <lambdabot>  [[1,2],[1,-2],[-1,2],[-1,-2]]
10:48:00 <jle`> not sure if that's helpful though :)
10:48:17 <p0a> nice! thank youl jle` that will do
10:48:34 <jle`> fwiw the Monad instance of List is unique-ish, but the Applicative is where you have other options
10:48:47 <jle`> > traverse (\x -> [x,-x]) [1,2]
10:48:49 <lambdabot>  [[1,2],[1,-2],[-1,2],[-1,-2]]
10:48:53 <jle`> > traverse (\x -> ZipList [x,-x]) [1,2]
10:48:56 <lambdabot>  ZipList {getZipList = [[1,2],[-1,-2]]}
10:49:06 <p0a> ah thank you.I think ZipList is the one I had on mind 
10:50:37 <jle`> trying to think of a more readable way to do it but i'm drawing a blank
10:51:18 <p0a> jle`: Well, what's the pointfree version of your lambda? :P
10:51:25 <p0a> That will make it more readable... :)
10:51:50 <jle`> heh, maybe a step in the opposite direction :P
10:57:14 <hyperisco> solonarv, I think the formulation is necessary to consider in its exact form
10:57:33 <hyperisco> it may be that combining Setters in that way doesn't give you another Setter or something, I don't know
10:57:38 <hyperisco> there are different types of optics
10:59:04 <solonarv> hyperisco: if you don't want to use the result as a setter then you can just use the Semigroup instance to combine them
10:59:21 <hyperisco> I am using a semigroupoid
10:59:32 <hyperisco> I think your example shows the semigroup is not quite right
10:59:45 <solonarv> no, I literally mean: ("hello", "sailor") ^.. (_1 <> _2)
10:59:59 <solonarv> my example shows that you don't get a sensible Setter by combining with <>
11:00:06 <solonarv> but the resulting Fold does work properly
11:00:24 <hyperisco> I don't know about folds
11:00:32 <hyperisco> my example was replacing both fst and snd with a value
11:00:40 <solonarv> yeah, that's a Setter
11:00:50 <hyperisco> sounds like you disagree though
11:01:39 <hyperisco> and I am guessing it does violate specifically Setter laws
11:04:20 <hyperisco> seems this all falls apart because the machinery for working with optics doesn't have semigroupoid/category instances
11:05:51 <hyperisco> I dunno it just seems weird that it sounds like the purpose is to do stuff with deep data structures, yet every time I try and use it it ends up seemingly very inefficient
11:06:03 <hyperisco> I don't get it yet
11:23:48 <ezzieyguywuf> if I have `char 'L'; digitChar; digitChar; digitChar` as part of a megaparsec parser, how can I make the error message say something like "Expecting Lnnn" for a failure on any of the four checks, rather than "Expecting an 'L'", "Expecting a digit" etc. for each?
11:24:34 <jle`> ezzieyguywuf: does it work if you wrap it and use (...) <?> "Expecting Lnnn" ?
11:25:31 <ezzieyguywuf> jle`: yes, thanks! though just "<?> "Lnn"" gets it done, megaparsec adds the "Expecting"
11:25:37 <jle`> nice :O
11:25:47 <jle`> good ol megaparsec
11:25:57 <sondr3> I'm back with yet another parsing question, I want to parse a line that can either end with a newline or EOF, but `takeWhileP Nothing notNewline <> eol <|> T.pack <$> someTill anySingle eof` always fail if the input doesn't contain a newline
11:26:13 <ezzieyguywuf> good ol that guy
11:26:37 <sondr3> I would've expected it to try the second parser when the first failed since it wants to end with `<> eol`
11:27:47 <monochrom> I would think you would have (eol <|> eof) grouped together?
11:28:22 <jle`> yeah, i definitely do not know how that is supposed to be parsed
11:28:41 <jle`> the haskell syntax i mean, not the parser it denotes
11:28:46 <xerox_> that was in Parsec too
11:30:55 <sondr3> monochrom: eof returns `m ()`, and I want to include the newline but only if it exists. I feel like I'm just missing something obvious
11:31:12 <sondr3> So that both `text` and `text\n` are valid
11:31:24 <jle`> sondr3: where are you expecting the parentheses to be in that?
11:31:38 <jle`> (takeWhileP Nothing notNewline) <> (eol <|> T.pack <$> someTill anySingle eof) ?
11:32:15 <jle`> or (takeWhileP Nothing notNewline <> eol) <|> (T.pack <$> someTill anySingle eof)
11:32:22 <monochrom> ((eol *> pure ()) <|> eof)
11:32:38 <jle`> aka void eol
11:34:49 <sondr3> But I don't want void eol, I want void eof but include eol :p
11:34:55 <monochrom> ((eol *> pure "\n") <|> eof *> pure "")  for the opposite expectation.
11:35:21 <monochrom> err, ((eol *> pure "\n") <|> (eof *> pure "")) 
11:37:06 <sondr3> monochrom: thanks, the final one was exactly what I wanted
11:37:10 <monochrom> I hope you have learned a lesson there. That you can always edit and manufacture return values, you are never stuck with what someone returns to you.
11:37:52 <sondr3> I was about to comment on exactly that, very obvious in hindsight but I've been to focused on only what I can parse
11:38:08 <sondr3> thanks jle` too :)
11:43:00 <dminuoso> solonarv: So I'm not really sure what the semantics of (<>) on the various optics even are.
11:43:43 <dminuoso> I usually tend to look at optics since its far more constrained and principled, and there you have
11:43:49 <dminuoso> failing :: (Is k A_Fold, Is l A_Fold) => Optic' k is s a -> Optic' l js s a -> Fold s a 
11:44:17 <dminuoso> This little fact suggests that mappending traversals together can be wonky
11:45:03 <dminuoso> or wait.. failing is not the right one
11:45:10 <dminuoso> summing :: (Is k A_Fold, Is l A_Fold) => Optic' k is s a -> Optic' l js s a -> Fold s a
11:45:12 <dminuoso> That's the one
11:46:56 <dminuoso> solonarv: At the very least for the documentation of `failing` on lens its suggested that its only lawful on disjoint traversals, Im guessing the same holds true for (<>)
11:47:35 <ezzieyguywuf> hrm, another megaparsec question: is there a more concise way of doing `a <- digitChar; char ':'; b <- digitChar; pure (pack [a, ':', b'])`?
11:48:50 <dminuoso> pack <$> traverse [digitChar, char ':', digitChar]
11:48:52 <merijn> ezzieyguywuf: "a <- digitChar <* char ':'; b <- digitChar" is one way
11:48:55 <dminuoso> err
11:49:00 <dminuoso> pack <$> sequence [digitChar, char ':', digitChar]
11:49:08 <merijn> ah, that's better
11:49:33 <ezzieyguywuf> ooooh, nice use of sequence there
11:52:22 <koz_> :t sequence
11:52:25 <lambdabot> (Traversable t, Monad m) => t (m a) -> m (t a)
11:52:28 <koz_> Ah, so sequenceA.
11:54:16 <frdg> I purchased a vps service but I do not have enough ram on the VPS to compile my program with stack. The problem with making binaries is that my OS is openSUSE but the VPS is centos. What are my options?
11:54:32 <dminuoso> frdg: Building inside a docker container
11:54:43 <sm[m]> frdg: temporarily increase the size of your vps
11:54:45 <merijn> frdg: Download VirtualBox, install centos in VM, build there, copy binary to VPS
11:54:49 <ezzieyguywuf> hrm, "Couldn't match type  'Char' with [Char]"
11:55:12 <frdg> ok many options
11:55:15 <dminuoso> frdg: If you build inside alpine, you can statically link it and then extract the build artifact out of the container
11:55:27 <dminuoso> that decouples you from any particular system
11:55:33 <sm[m]> frdg: try to configure stack/cabal/ghc to build in less ram
11:55:37 <dminuoso> haha
11:55:40 <dminuoso> that's a good one
11:55:42 <merijn> sm[m]: Pointless
11:55:43 <sm[m]> frdg: configure enough swap on your vps, and let it run overnight
11:55:56 <merijn> sm[m]: GHC just doesn't really work with less than 1-2GB
11:56:07 <merijn> A super cheap VPS will have 256-512 MB or something
11:56:07 <sm[m]> you can influence it
11:56:24 <frdg> ok I think I am going to start with building from a VM.
11:56:27 <sm[m]> we don't know how much frdg has, they might be close to success. And they asked for options
11:56:30 <dminuoso> sm[m]: its a fairly lost cause
11:56:31 <merijn> Yeah, but why bother? No reason to have GHC on the machine just because you plan to run it there
11:56:38 <dminuoso> you add one wrong line of code, and things blow up
11:56:42 <dminuoso> just because megaparsec
11:57:00 <sm[m]> you're assuming a lot. Sometimes the nearby fix is the cheapest and best
11:57:09 <dminuoso> sm[m]: No Im talking from experience
11:57:10 <sm[m]> I've said my piece
11:57:32 <dminuoso> I have a 70 LoC parser that takes about 30 seconds for a single module and memory goes to crazy
11:57:45 <dminuoso> for no reason other than megaparsec having inline on almost everything
11:58:01 <dminuoso> best part of it is
11:58:13 <merijn> It doesn't help performance? :p
11:58:15 <dminuoso> I have this `asum [ ... ]` and if I slightly modify that list, it gets exponentially worse
11:58:18 <int-e> dminuoso: But... how big is that single module?
11:58:23 <dminuoso> int-e: 70 LoC.
11:58:36 <int-e> ...
11:58:49 <dminuoso> oh
11:58:50 <int-e> dminuoso: You mean the compiler takes 30 seconds to compile the module?
11:58:53 <dminuoso> Yes
11:59:11 <int-e> Fun.
11:59:37 <dminuoso> It's fairly simple, nothing fancy. Just rudimentary megaparsec usage
11:59:50 <dminuoso> I debugged ghc a bit, filed a bug report. But it's just their overuse of inline
12:00:08 <merijn> dminuoso: But INLINE makes things fast!
12:00:13 <int-e> Right, overuse of inlining would've been my first guess.
12:00:20 <int-e> Then, exploding types.
12:00:36 <merijn> I love when people make annotations for "performance" without benchmarks
12:00:52 * hackage migrant-core 0.1.0.0 - Semi-automatic database schema migrations  https://hackage.haskell.org/package/migrant-core-0.1.0.0 (TobiasDammers)
12:01:29 <int-e> compilation is a one time cost, right?
12:01:32 * int-e runs.
12:01:36 <dminuoso> Result size of Simplifier iteration=1 = {terms: 4,972,599,types: 7,677,397,coercions: 516,358,joins: 146,810/146,811}
12:01:45 <maerwald> int-e: hahaha
12:01:46 <dminuoso> That's straight out of a minimalistic testcase
12:01:46 <merijn> int-e: In my case I had someone mark all of my foreign imports as unsafe
12:01:53 * hackage migrant-sqlite-simple 0.1.0.0, migrant-postgresql-simple 0.1.0.0, migrant-hdbc 0.1.0.0 (TobiasDammers)
12:02:04 <merijn> int-e: Because "unsafe foreign imports are faster, so you should use those by default"
12:02:05 <monochrom> https://xkcd.com/303/ applies again. Today is "compiling" day.
12:02:19 <koz_> dminuoso: Wat.
12:02:22 <int-e> merijn: I think I was there for a previous discussion of that incident
12:02:34 <dminuoso> koz_: https://gitlab.haskell.org/ghc/ghc/-/issues/17370
12:02:35 <dminuoso> :>
12:02:37 <merijn> int-e: On foreign calls that were all outside of the critical path and were mostly syscalls >.>
12:02:54 <merijn> int-e: Could be, I get sad every time I'm reminded :p
12:03:08 <int-e> fortunately, system calls never block
12:03:31 <dminuoso> until they do
12:03:41 <monochrom> Let's up the game. System calls are faster if the caller is in ring 0, too.
12:03:41 <int-e> it's true for gettimeofday, and I'm generalizing from there
12:03:53 <dminuoso> I know of at least one syscall that blocks
12:04:12 <int-e> dminuoso: sleep?
12:04:15 <dminuoso> ioctl 
12:04:32 <int-e> (which is probably implemented using select I guess)
12:04:51 <dminuoso> (well ioctl *can* block, depending on which ioctl you invoke)
12:04:57 <int-e> I think the list will be shorter if we list system calls that don't block
12:06:25 <frdg> when you initially compile a program from scratch will stack use more ram then it would when you later make small changes to the application?
12:06:55 <dminuoso> yes. no. perhaps
12:07:08 <int-e> frdg: I don't know. ghc tends to use less RAM when it (re-)compiles fewer modules
12:07:13 <monochrom> Most likely yes. Because the first time it builds aeson, the second time it doesn't, for example.
12:07:13 <dminuoso> frdg: It doesnt really matter at the end. GHC has no parallel module compilatoin
12:07:42 <ezzieyguywuf> is there a generalized "concat", i.e. something that would do `foldl (<>) "" ["A", "B", "C"]`
12:07:44 <frdg> ok thanks
12:08:05 <int-e> dminuoso: Yes it does, because everybody uses ghc --make and GHC has internal caches that are not flushed between module compilations.
12:08:16 <int-e> (everybody except ghc's own build system, incidentally)
12:08:34 <dminuoso> oh
12:08:40 <geekosaur> mconcat?
12:09:14 <geekosaur> or sconcat if it's a Semigroup
12:09:40 <dminuoso> int-e: well, recently Ive been annoyed by all the caching. There's subtle bugs in either cabal or ghc, I almost weekly have an issue where I have to nuke dist-newstyle before compilation can succeed
12:10:25 <merijn> dminuoso: You must be doing *something* I haven't encountered that in years
12:10:29 <int-e> Hmm. I'm still on v1 sandboxes... but I tend to nuke those a lot too.
12:10:40 <merijn> int-e: ... why? o.O
12:10:43 <monochrom> "Please wash your hands and run 'cabal clean' often." >:)
12:10:46 <dminuoso> merijn: I think its either this particular cabal or ghc version
12:10:50 <dminuoso> or combination
12:10:52 <ezzieyguywuf> geekosaur: I think one of those may be what I'm looking for thanks.
12:10:55 <int-e> merijn: why not?
12:11:25 <monochrom> Heh, I don't push everyone to go v2, I was a bit reluctant too.
12:11:30 <int-e> They work, they have a neat cleanup story, and I'm used to them.
12:11:40 <merijn> because v2-build is so much more robust and reliable >.> It already was years ago >.>
12:11:40 <sclv> i've certainly noticed that when i use nix to swap out entire package envs then the cached stuff goes stale on v1
12:11:47 <int-e> Well I'll be forced to switch eventually.
12:12:06 <sclv> because the hashing relies on version numbers and the like, so if i'm swapping between different local versions of deps it gets confused
12:12:08 <int-e> But this channel should understand the desire to not do so eagerly :P
12:12:41 <int-e> If you want a rational reason: The later I switch the more well-rounded the v2 commands will be.
12:13:11 <sclv> this is for $WORK$ which is pervasively nixified so i stick to v1
12:13:25 <sclv> for personal dev i use v2 and its pretty damn seamless at this point
12:13:29 <merijn> I switched to v2-build in 2016 or something, breaking all my editor tooling (like hdevtools in the progress) because it was less painful than fighting v1 >.>
12:13:32 <sclv> given that i sort of know what stuff doesn't work
12:14:17 <int-e> merijn: that's the thing though... ever since I switched to using sandboxes I never had to fight
12:14:48 <merijn> int-e: I had to reinit sandboxes *a lot*, though
12:14:53 <merijn> Because that's what I used before
12:14:58 <int-e> sure.
12:15:07 <int-e> I have a shell script for that
12:15:15 <merijn> If dependencies are in flux nuking and rebuilding the world every time is a *massive* time sync
12:15:29 <geekosaur> "sink"
12:15:31 <int-e> sink
12:15:51 <merijn> I got stuff to do that doesn't involve waiting for the kmettiverse to compile for the 15th time
12:16:05 <int-e> merijn: also, honestly, I don't really have big projects
12:16:15 <merijn> geekosaur: Fixing my brain to no output a random homophone when I type is a lost cause :p
12:16:18 <monochrom> If dependencies are in flux, v2 rebuilds enough of the world to be a time sink, too.
12:16:29 <merijn> monochrom: Depends of how much
12:16:39 <int-e> make all the dependencies that are in flux source dependencies :P
12:16:44 <merijn> monochrom: Like, adding 1 or 2 packages won't rebuild the entire kmettiverse :p
12:17:03 <koz_> merijn: Lol@'kmettiverse'. The Kmett Extended Universe.
12:17:15 <merijn> Actually
12:17:33 <monochrom> Well I should get out of this debate.
12:17:34 <merijn> Maybe we should start calling it the KCU Kmett Cinematic Universe or something :p
12:17:43 <koz_> I'm down for KCU.
12:17:53 <koz_> Avengers: Rise of the Profunctor.
12:18:18 <monochrom> I was going to say, the disease of the lot of you is debating until other people do things your way. This is already the second time within an hour, even half an hour.
12:18:27 <monochrom> Today is compiling day and bikeshedding day.
12:18:56 <merijn> monochrom: It *is* compiling day, that's why I have nothing better to do :p
12:18:58 <monochrom> Kmett Categorical Universe
12:19:05 <merijn> monochrom: Rats
12:19:10 <monochrom> Oh haha good cause
12:19:26 <merijn> monochrom: I spent 5 minutes pondering better a better word for C and somehow completely missed Category...
12:19:55 * geekosaur resembles that too (although now the compiling is mostly done but my poor little netbook is still recovering from it)
12:20:12 <koz_> Instead of GHC2021, we should have 'KCU' as a language option. :P
12:20:14 <merijn> monochrom: I'm messing with the database schema of my code, which is waaaaaaaay at the bottom of my module hierarchy, so it triggers nearly full rebuild that takes like 10 minutes each time >.>
12:20:26 <monochrom> You are in front of the guy who thought up how to expand "tl;dr" to "type-level instance diversification and resolution", "sicp" to "structure and identification of cabalized packages".  You really stand no chance.  :)
12:20:30 <merijn> monochrom: So lots of time to spread the gospel :p
12:20:48 <koz_> monochrom: Wordplay is how you flex in #haskell (and the ecosystem).
12:21:38 <tomjaguarpaw> Yes, we've already maxed out on pointfree flexing
12:21:46 <monochrom> Hey, Kmett Compiling Universe is appropriate, too.
12:22:09 <koz_> Lol.
12:22:39 <koz_> Steps to putting a package on Hackage: 1. Write it; 2. Agonize for hours over suitable worlplay-ey name.
12:23:21 <merijn> koz_: 3. generalize functionality so that name is now overly specific >.>
12:23:28 <koz_> merijn: Rofl this.
12:23:47 <koz_> Because if you don't have five type variables and ten constraints, what are you even doing?
12:23:58 <koz_> (four of which must be higher-order)
12:24:17 <merijn> koz_: Oh, more like "I named it broadcast-chan and now it's unclear that there's a bunch of super useful parallelisation things in there" :p
12:24:47 <koz_> merijn: I _cannot_ read '-chan' without imagining animu schoolgirls.
12:25:58 <monochrom> And the following is true of both complex analysis and lumber work: To take logs, you must cut branches.
12:26:11 <tomjaguarpaw> Or "I named it product-profunctors and now I realise that sum profunctors are useful too"
12:27:04 <merijn> tbh, broadcast-chan-conduit is some of the most massively useful code I've written and now it's under a cryptic name like that :p
12:27:29 <tomjaguarpaw> What does it do?
12:27:30 <koz_> merijn: Needs more wordplay.
12:27:38 <koz_> Quick, summon monochrom!
12:28:26 <merijn> tomjaguarpaw: Suppose you have a stream of items you wanna map an IO function over. You use Conduit.mapM. Except your IO is slow and blocking (like an HTTP request), why not parallelise that part of your conduit pipeline!
12:29:14 <tomjaguarpaw> Ah cool
12:29:32 <tomjaguarpaw> So you have a queue of items in progress whilst you wait for the first to finish?
12:30:29 <merijn> tomjaguarpaw: You can have N parallel running copies of you "a -> IO b" (or really anything MonadUnliftIO) and just process them in whatever order they finish
13:03:01 <dminuoso> merijn: Why not just mapM with forkIO?
13:03:12 <dminuoso> Oh wait
13:03:17 <dminuoso> This feeds the results back into the conduit?
13:05:24 <merijn> dminuoso: Yes
13:05:39 <merijn> dminuoso: Also it handles retrying on exception or other exception mechanisms
13:05:55 <merijn> dminuoso: Also the parallelism is bounded, unlike mapConcurrently
13:06:12 <merijn> Which is important, if you're gonna, say, push a few million entries through :)
13:06:47 <merijn> dminuoso: Also, the complexity of handling multiple parallel forkIOs is insane
13:07:11 <merijn> dminuoso: Because I implemented it like that in like 3 different projects and figured I might as well do it properly *once* and be done with it
13:07:36 <merijn> Because Async doesn't quite fit my wants/needs
13:10:27 <merijn> dminuoso: That's also why I made sure to keep the dependency footprint superlow (3 transitive dependencies: base, transformers, and unliftio-core), so I can easily slap it in/on things :p
13:35:28 <dminuoso> Huh wow, here's a class I've never seen
13:35:29 <dminuoso> https://hackage.haskell.org/package/base-4.14.0.0/docs/Control-Monad-Zip.html#t:MonadZip
13:35:38 <dminuoso> % :t mzip
13:35:39 <yahb> dminuoso: ; <interactive>:1:1: error:; * Variable not in scope: mzip; * Perhaps you meant one of these: `zip' (imported from Data.List.NonEmpty), `BSLC.zip' (imported from Data.ByteString.Lazy.Char8), `BSC.zip' (imported from Data.ByteString.Char8)
13:35:49 <dminuoso> Oh well. Strange I have never seen this
13:36:16 <dminuoso> liftM (f *** g) (mzip ma mb) = mzip (liftM f ma) (liftM g mb)
13:41:14 <shapr> dminuoso: write a monad comprehension now? :-D
13:45:16 <dolio> That lets you use zip comprehensions. [ E | x <- l | y <- r ]
14:02:23 * hackage mutable-lens 0.4.1.0 - Interoperate mutable references with regular lens  https://hackage.haskell.org/package/mutable-lens-0.4.1.0 (infinity0)
14:03:40 <koz_> Wait, I remember someone talking about mutable lens stuffs.
14:04:03 <koz_> infinity0: Was it you who inquired about them recently?
14:05:01 <infinity0> koz_: no but i had a conversation with jle` about it a while ago, here https://github.com/mstksg/mutable/issues/2
14:05:23 <koz_> infinity0: Ah, OK. I remember someone in here asking about this very thing not too long ago.
14:05:34 <koz_> Nice thing you've got there - I wonder if there's an optics version too?
14:06:03 <infinity0> i doubt it, i made this not too long ago, don't think anyone picked up heavily on the idea yet
14:06:26 <infinity0> probably could do with a bit of low-level optimisation but it performs reasonably ok
14:06:42 <koz_> Did you try benching it? Where's the part that makes it choke?
14:07:22 <infinity0> i have a benchmark showing ~13% slowdown, probably due to the boxing and unboxing
14:07:31 <infinity0> in ghc/haskell you can't mix the two in a polymorphic way
14:08:02 <infinity0> so in primitive monads the state is unboxed, in my mutable lens wrapper it has to be boxed to interoperate with regular lens, optics, etc
14:08:18 <infinity0> would be great if someone figured out a solution
14:08:41 <koz_> Ah, yeah, that's... a tricky prospect.
14:09:39 <infinity0> i also haven't tried running it on non-linear functors like [] to see if that would actually result in unsoundness, perhaps that's worth doing too...
14:10:14 <infinity0> actually on second thoughts it's probably fine, assuming the content of the reference is itself a pure immutable object and doesn't contain inner references
14:16:57 <koz_> But yeah, cool little thing you have there.
14:18:29 <infinity0> thanks!
14:18:51 <infinity0> to be clear the benchmark i quoted above does nothing except read/write to the reference/lens, so in a "real" program it won't be that much slower
14:18:58 <infinity0> so feel free to use it in your pet projects :)
14:19:43 <koz_> It'd be nice to have the various indexed stuff, since that'd be very useful for mutable arrays.
14:26:24 <infinity0> koz_: what works currently is various indexed lens (or anything really) composed with a mutable-lens, so you could use a MutVar (Map k v) or something like that
14:26:36 <infinity0> but yeah, i didn't think too hard about mutable arrays etc yet
14:26:36 <koz_> Oh, that's nice.
14:26:46 <koz_> It'd be very useful to have that baked in, though.
14:27:04 <kupi> does Data.ByteString.Lazy.Char8.uncons copy the first chuck?
14:27:28 <kupi> *chunk
14:29:00 <infinity0> koz_: i'm not sure how well mutable arrays fit into this lens-are-references paradigm, but there is a similar+different framework by jle` that is the "mutable" package https://hackage.haskell.org/package/mutable that covers mutable arrays
14:29:27 <koz_> infinity0: Noted.
14:29:46 <koz_> I might write an optics version for lols.
14:30:11 <infinity0> i wrote mutable-lens because i had a direct concrete need to abstract over mutable references and pure state monads in the same piece of code without repeating myself, mutable-arrays didn't appear to be part of that need
14:30:41 <infinity0> cool, yeah i'd be happy to look at it. you can likely re-use some of my types
14:33:10 <frdg> I dug up another of the same usb and get an entirely different issue. Do not buy `NXT USB 2.0`'s. Ill get a new usb tomorrow.
14:35:37 <sondr3> question about API design in Haskell, coming from Rust I'm not sure how to create a Haskelly API for my library. Does something similar to https://rust-lang.github.io/api-guidelines/ exist for Haskell?
14:38:19 <infinity0> i don't know of a document, your best bet would be to read the standard library and other common libraries and figure out the convention by osmosis
14:39:27 <koz_> It also depends very much on what you're trying to write.
14:40:12 <sondr3> A library for https://github.com/google/hrx to learn Haskell
14:42:44 <infinity0> sondr3: have a look at https://hackage.haskell.org/package/zip-archive-0.4.1/docs/Codec-Archive-Zip.html and other archive-format libraries and spot some naming patterns
14:44:52 <sondr3> infinity0: awesome, that looks like a great way to learn by osmosis 
14:45:32 <infinity0> welcome!
15:13:41 <kupi> i have found out it does not copy because uses plusForeignPtr
15:14:15 <ski> kupi : it slices, i'd imagine
15:38:45 <koz_> Lazy ByteStrings are like, arrays of chunks right?
15:39:59 <hpc> linked list of chunks
15:40:47 <koz_> hpc: So like [Chunk]?
15:40:56 <koz_> And chunks are... strict ByteStrings?
15:42:10 <hpc> more or less
15:42:12 <hpc> https://hackage.haskell.org/package/bytestring-0.11.0.0/docs/src/Data.ByteString.Lazy.Internal.html#ByteString
15:42:37 <koz_> Ah, they roll their own list.
15:42:45 <koz_> Is there a reason for this?
15:43:53 <koz_> Ah, strictness.
15:58:26 <int-e> koz_: unpacking saves an indirection
15:58:38 <koz_> int-e: Yeah, that too. 
16:02:34 <ezzieyguywuf> in megaparsec, how do I consume all the rest of the input and capture the values, rather than dumping them like eof does?
16:03:37 <koz_> ezzieyguywuf: takeRest?
16:04:17 <ezzieyguywuf> koz_: perfect thank you!
16:04:24 <koz_> ezzieyguywuf: No worries.
16:05:20 <int-e> koz_: https://github.com/haskell/bytestring/commit/130906ef928f9761978dd7d13bd4b3082badd1b1
16:07:11 <int-e> (I thought I remembered that it was defined as a list originally... and now confirmed it.)
16:14:30 <ezzieyguywuf> another megaparsec question (please be gentle y'all, I'm pretty new :-P) - how do I parse a single character, but ANY character, not a particular? I'm trying to parse exactly 16 characters, but `replicate 16 char` won't do it b/c char is `Token s -> m (Token s)`
16:15:04 <koz_> anyChar?
16:15:20 <ezzieyguywuf> koz_: hrm, I thought maybe printChar. Where do you see anyChar?
16:15:35 <koz_> One sec.
16:16:06 <koz_> anySingle
16:16:24 <koz_> (which is just a fancy way of saying 'satisfy (const True)')
16:17:07 <ezzieyguywuf> koz_: ah hah, yes this makes sense. thank you.
16:45:09 <ezzieyguywuf> hrm, I have a `parseEnd :: Parser Text` that parses some characters at the end of the input. I want everything leading up to this - it seems like `takeWhile` is the tool for the job, but I'm unsure how to combine this with `parseEnd`. I was thinking maybe `lookahead`, but this does not return a bool so can't be used as the predicate
16:46:50 <ezzieyguywuf> I'm trying to do the equivalent of the following in a regexp: ^(.*)SOMESTATICTEXT$
16:47:01 <koz_> That's ambiguous.
16:47:11 <ezzieyguywuf> koz_: how so?
16:47:32 <koz_> The first part could be anything, right?
16:47:37 <ezzieyguywuf> correct
16:47:40 <koz_> (including nothing at all)
16:48:11 <koz_> lookahead won't help here because you don't know how much you have to read.
16:48:14 <ezzieyguywuf> hrm, I guess really it's more like "^(.+)SOMESTATICTEXT$"
16:48:34 <koz_> Ah, so you know there'll be _something_ prior to SOMESTATICTEXT?
16:48:40 <ezzieyguywuf> I guess I can just read till the end of line then subtract the static text
16:48:45 <ezzieyguywuf> koz_: correct.
16:49:00 <koz_> Hmm.
16:49:28 <monochrom> I wonder if it's manyTill (string "SOMESTATICTEXT\n")
16:49:41 <ezzieyguywuf> monochrom: manyTill sounds promising, let me check that out
16:50:18 <ezzieyguywuf> hrm, is that from attoparsec?
16:50:21 <monochrom> But generally, most parser combinator libraries are designed for positively specified grammars, not negatively specified "anything except this".
16:50:23 <ezzieyguywuf> can I still use it in megaparsec?
16:50:53 <monochrom> I don't actually know megaparsec. I just assume if it's in parsec then it's in megaparsec.
16:50:57 <ezzieyguywuf> monochrom: hrm, if that's the case then option (b) should be fine, i.e. use the parsing library to get "everything else" and then I can post-process by taking off the static text at the end
16:51:21 <koz_> ezzieyguywuf: If you are parsing Text, stripSuffix might prove helpful.
16:51:32 <ezzieyguywuf> koz_: yea, I am doing it as Text
16:51:34 <monochrom> The exception (pun!) is those few parser combinator libraries that are built for nondeterminism and ambiguous grammars.
16:52:06 <ezzieyguywuf> this is non-deterministic, I'm parsing the "Description" field from my bank statements, lol.
16:52:38 <monochrom> but parsec, megaparsec, and a lot of others are designed for determinism.
16:53:10 <ezzieyguywuf> hrm. well I seem to be doing ok so far....
16:53:16 <ezzieyguywuf> 🤷
16:53:32 <ezzieyguywuf> I was going to use regexp, then someone was like "I usually just use a parser"
16:53:33 <ezzieyguywuf> lol
16:54:48 <monochrom> Well, I guess things like manyTill can help.
16:56:04 <ski> @quote Japsu regex
16:56:04 <lambdabot> Japsu says: iä iä, regex fhtagn
16:56:07 <monochrom> regex makes it look easy because every regex engine goes out of its way to implement nondeterminism by heavy backtracking or heaving compiling NFA to DFA.
16:56:17 <monochrom> s/heaving/heavy/
16:57:53 <monochrom> What I want you to notice that CFG tools seldom make this easy. It is not just our community. yacc also makes you explicitly enumerate what you allow, not what you don't allow.
16:58:34 <monochrom> Hell, yacc is strongly anti-nondeterminism.
16:59:46 <ski> having better support for intersection, difference, division/derivative could be interesting
16:59:56 <monochrom> Negative specification comes into this equation because in the regex .*ABC, the .* part no longer means "anything", it now means "anything except ABC"
17:02:54 <ski> (and i wonder how to best represent stuff like "maximal munch". to a large extent, i think i'd prefer it, if `p' parses `s' and `q' parses `t' implies that `p * q' parses `s ++ t')
17:03:59 <monochrom> Nondeterminism comes into the equation because it is a very good way of understanding any implementation strategy.
17:04:05 <sarahzrf> i like the earley library
17:04:50 <monochrom> CFG tools are mostly unsupportive of negative specification because set subtraction of two CFLs seldom give you a CFL.
17:05:18 <monochrom> Whereas RLs are closed under set subtraction, so regex tools are much happier with it.
17:06:06 <monochrom> and intersection too. CFLs not closed under intersection, RLs closed under intersection.
17:07:38 <monochrom> How to discover two CFLs that don't intersect to a CFL:
17:08:05 <monochrom> Always remember that the poster child non-CFL example is { a^n b^n c^n | n natural }
17:08:23 * hackage network 3.1.2.1 - Low-level networking interface  https://hackage.haskell.org/package/network-3.1.2.1 (KazuYamamoto)
17:08:27 <monochrom> So simply come up with two CFLs that intersect to that. This is within your reach. :)
17:11:12 <koz_> monochrom: Ah yes, that wonderful example that came up on my ToC assignment.
17:11:50 <ski>   { aᵐ⋅bᵐ⋅cⁿ | m,n : ℕ } ∩ { aᵐ⋅bⁿ⋅cⁿ | m,n : ℕ }
17:11:51 <ski> ?
17:11:57 <monochrom> Yeah!
17:12:04 <ski> cool :)
17:12:36 <monochrom> Generally, if a language has to synchronize three things, you can bet it has a problem.
17:12:56 <koz_> And that's even before we get to the fact that nondeterminism actually adds power to CFGs (but not RLs).
17:13:05 <monochrom> Synchronizing just two things, we know how to CFG it, it's just another "matching parentheses".
17:15:29 <koz_> sarahzrf: Earley parsers are quite cool, because their asymptotics are tied directly to matrix multiplication.
17:15:52 <shachaf> Hmm, is there some sort of dual-context-free that has intersection but not union?
17:16:20 <shachaf> Like there are NFAs and dual NFAs that make unions and intersections respectively easy.
17:17:01 <koz_> shachaf: You lose intersection closure _very_ quickly with most recognizers.
17:17:19 <koz_> (like, whichever way you increase expressive power tends to kill you)
17:17:50 <shachaf> Hmm, but maybe concatenation isn't supported either.
17:17:58 <shachaf> But I'm curious what this is like.
17:18:02 <koz_> So I doubt such a thing exists, or at least in any meaningful sense as a 'dual' to CFGs.
17:29:36 * ski . o O ( <https://en.wikipedia.org/wiki/Categorial_grammar>,<https://en.wikipedia.org/wiki/Montague_grammar>,<https://en.wikipedia.org/wiki/Pregroup_gramm> )
17:32:01 <shachaf> Instead of "dual NFA" I should say "existential NFA" for the normal kind and "universal NFA" for the weird dual kind.
17:34:32 <ski> are there any adjunctions present, involving them ?
18:11:39 <koz_> shachaf: Do you have a formal definition of these NFAs?
18:15:35 <koz_> Suppose I wanted to write a package that adds http://hackage.haskell.org/package/optics-core-0.3.0.1/docs/Optics-At-Core.html#t:Ixed definitions for, say, massiv arrays. However, the only way I can see to provide these instances is orphans, or asking massiv to cart around optics as a dep by integrating optics. Am I missing some third way?
18:17:08 <monochrom> asking optics to card around massiv :)
18:17:19 <koz_> monochrom: _Fourth_ way, you pedant. :P
18:17:35 <monochrom> My view is that this is one of those times orphaning is desirable.
18:18:06 <koz_> monochrom: Yeah, I can't think of a way to do this without orphaning or newtypes.
18:18:12 <koz_> And newtypes would kinda defeat the whole exercise.
18:19:18 <ocamler> hello friends! I have a probably simple question, I have a function which is wraps the state monad: `solve :: [(Int, Int)] -> ST s [Int]` which is called from `main :: IO ()`, how can I get these types to match?
18:20:45 <koz_> ST s [Int] would need to be runST'd to get out the [Int].
18:21:08 <koz_> (and state monad /= ST)
18:21:33 <ocamler> oh oops right, wow I never knew there is a runST, is that still considered pure?
18:21:40 <monochrom> yes
18:21:58 <koz_> ocamler: It's the effect describing (locally) mutable state.
18:22:09 <koz_> It's also the thing that powers IO.
18:22:18 <koz_> (read Lazy Functional State Threads if you want the details)
18:24:52 <ocamler> thanks! I'll check it out
18:26:10 <ezzieyguywuf> what does ghcid's --reload actually do? I can see that it does _something_, but it doesn't (for example), re-build a library that has chnaged
18:27:06 <ezzieyguywuf> hrm, I guess it re-runs --command
18:27:24 <ezzieyguywuf> but I'd expect `cabal repl` to rebuild something that's changed..
18:27:32 * int-e would expect something similar to ghci's :reload
18:27:52 <ezzieyguywuf> but it doesn't!
18:27:55 <ezzieyguywuf> int-e: yea it is :reload
18:28:23 <int-e> so... it would only recompile the modules of the "local" package, but not look at any dependencies
18:28:28 <ezzieyguywuf> so if I do `cabal repl exe:MyExe`, and then make a change to lib:MyLib (which MyExe uses), and then :reload, ghcid does NOT rebuild MyLib
18:28:46 <ezzieyguywuf> MyLib and MyExe are both local
18:28:57 <ezzieyguywuf> could it be I have something borked it my .cabal file?
18:28:58 <int-e> for this purpose they're not
18:29:03 <ezzieyguywuf> hrm
18:29:23 <int-e> lib:MyLib is built and registered as a package; ghci(d) would only see the executable's own modules
18:29:35 <ezzieyguywuf> ah, I see
18:29:46 <ezzieyguywuf> I don't think I need a lib - I think I just need modules for MyExe
18:29:52 <ezzieyguywuf> int-e: thanks for helping me think through that.
19:11:15 <ocamler> lol why is [0..10] inclusive
19:11:25 <ocamler> i just spent like 15 minutes debugging that
19:12:40 <koz_> ocamler: ... because it is?
19:12:52 <koz_> That's just how Enum-based ranges like that work.
19:13:58 <ocamler> ohhh I see, its for Enums as well
19:14:35 <koz_> > [LT ..]
19:14:37 <lambdabot>  [LT,EQ,GT]
19:17:52 <ocamler> damn thats cool
19:18:32 <ocamler> pretty sure thats impossible in ocaml
19:55:28 <ezzieyguywuf> how can I turn a [[String]] into a [[Text]]?
19:55:43 <ezzieyguywuf> fmap . fmap?
19:55:52 <dolio> (fmap . fmap) pack
19:57:25 <ezzieyguywuf> dolio: nice, thank you.
20:06:32 <incertia> would there be any interest in a prism equivalent for data-has
20:07:37 <incertia> e.g. class MightHave a t where hasPrism :: Prism' t a
20:08:09 <incertia> and then you would be able to lift up errors into more general contexts with mtl
20:09:03 <incertia> throwE :: (MightHave e err, MonadError e m) => e -> m ()
20:09:28 <incertia> throwE = throwError . review hasPrism
20:21:56 <arpl> Is it useful to define a class for the sole purpose of creating a constraint (and the only 'proof' is having an instance)? So when you have a (higher order) function that takes a compression function, for instance, you can constrain it to only lossless compression.
20:50:38 <koz_> arpl: It can be sometimes.
20:51:08 <koz_> However, you almost always have some kind of behaviour to go with this constraint, so you may as well define that too.
20:51:34 <koz_> Because otherwise, it tells you something but you can't do anything with this value you just got.
20:54:53 <arpl> That is true and I understand that. It is certainly nice when there are laws associated with a class. But I was thinking about situations (and maybe my example wasn't quite right) where there are no laws associated and you just want the user of that function to 'acknowledge' a certain constraint by making an instance and 'promising' to obey (when
20:54:54 <arpl> enforcement is not possible).
20:55:16 <koz_> If your type class lacks laws, you should ask yourself _especially_ hard if that's really what you want.
20:55:28 <koz_> (in fact, certain folks would go so far as saying that all type classes should have them)
20:56:02 <koz_> Also, I didn't say anything about _laws_ - I merely said that type classes which only satisfy a constraint, without some associated behaviour, have quite limited usefulness.
20:56:15 <koz_> (although maybe I misunderstood and your type class _does_ have some methods?)
20:56:32 <arpl> Fair enough. I was only wondering.
20:57:42 <arpl> No, I was asking about a class with no methods, just to have some kind of constraint that should be acknowledged. I wasn't thinking about actually implementing something like that, just asking about the usefullness, if any.
20:57:58 <koz_> Yeah, a type class with no methods has very limited utility.
20:58:15 <koz_> Mostly because 'some value satisfies a constraint' gives you very little  you can actually _do_ with that value afterwards.
20:58:27 <koz_> Because as far as the function it got passed into is concerned, it could literally be anything.
20:59:47 <arpl> Understood too. Just like the exhaustiveness check, this would be some 'user defined compiler warning' like: Are you sure this compression function is indeed lossless?
21:00:32 <c_wraith>  
21:00:36 <c_wraith> err, sorry
21:01:13 <koz_> Well, if a compression function is lossless, surely you want a type class with a 'compress' and 'decompress' method, with the law that 'compress . decompress == id'?
21:01:52 <koz_> (and probably an associated type for the compression result, although you could just use ByteString or something)
21:03:10 <arpl> To make clear: This is beginner's question. Just learning Haskell.       Yes, I agree ... compression would have associated laws/invariants.      Thank you for your time. Back to just pondering : )
21:19:23 * hackage typson-core 0.1.0.0 - Type-safe PostgreSQL JSON Querying  https://hackage.haskell.org/package/typson-core-0.1.0.0 (aaronallen8455)
21:26:58 <jle`> incertia: maybe not Has, but As :)
21:32:52 <crestfallen> hello is there a beginners channel or should I go to #haskell-overflow ? there is something fundamental I don't understand between do notation and bind notation; in the "divvy" example at the bottom of this paste: http://ix.io/2Fvz
21:33:54 <incertia> i mocked up a sample library basically by inlining the lens definitions, is there anything i can simplify? https://gist.github.com/incertia/f1386a06b7c2a008f0bbbd6d1d74a0b9
21:34:49 <MarcelineVQ> divvy is missing a read compared to divv
21:35:37 <crestfallen> thanks MarcelineVQ I've been trying put a second read in for a very long time. what's the trick?
21:35:59 <MarcelineVQ> do the same thing you did for the first read
21:38:18 <MarcelineVQ> x <- read   became   read >>= \x -> ...    so you just do that again
21:39:11 <crestfallen> o ne moment please 
21:41:30 <crestfallen> I think the return clause requires " \_ -> ...". also I thought return requires the State :: ((),s) of write
21:42:18 <crestfallen> I know it's a strange program, but I want the division by zero error when I use (-1)
21:43:12 <MarcelineVQ> monochrom made an IO tutorial that happens to cover how bind and do relate, by starting with bind only, http://www.vex.net/~trebla/haskell/IO.xhtml But any google search about do notation in haskell will cover it as well, googling "translating do notation" for instance
21:43:58 <crestfallen> I've been using this: https://en.wikibooks.org/wiki/Haskell/do_notation
21:45:10 <crestfallen> I can see that there is a slight difference but I don't know how to insert the second read so that the "write (x+1) is maintained downstream
21:48:34 <MarcelineVQ> That one's fine. You've got all the tools you need there. Just do what they did.Your only difference is that you have 4 '
21:48:41 <MarcelineVQ> actions' instead of 3.
21:49:10 <crestfallen> i.e. this doesn't change the behavior to that of 'divv'   divvy = read >>= \x -> write (x+1) >>= \_ -> read >>= \_ -> return (safeDiv (x*2) x)
21:49:34 <MarcelineVQ> no it wouldn't, because you don't bind x again
21:49:49 <MarcelineVQ> so you're using the old x instead of shadowing a new one like you did in divv
21:50:16 <crestfallen> yes, thanks I understand, but what is the notation?
21:50:59 <MarcelineVQ> :/  write x where you wrote _    in the same way you did it for the first read
21:52:54 <crestfallen> geez, I swear MarcelineVQ I thought I had done that 20 times. yes it works thanks kindly.
21:52:58 <MarcelineVQ> Rather than not getting do notation what is happening here is that you're not getting >>=  Otherwise you wouldn't need to ask what you're asking. the expression   x >>= \y -> ...   binds the result of computing/running/executing x, to the name y.
21:53:28 <MarcelineVQ> do notation let's use write this as    y <- x   but the meaning is the same, run x, call the result y.
21:54:35 <crestfallen> what is the rule where the lambda after the second >>= must have the wildcard ? MarcelineVQ 
21:54:50 <crestfallen> I'm foggy on that
21:56:36 <jle`> incertia: looks solid to me :)
21:56:56 <jle`> at least as a parallel to Data.Has
21:57:25 <incertia> there should be no reason to pick a specific choice right
21:57:41 <MarcelineVQ> You write _ if you don't care to name the result of some action. If you're not using the result in other words. For instance if you wrote
21:57:42 <MarcelineVQ> do x
21:57:45 <MarcelineVQ>    y
21:57:53 <jle`> incertia: what do you mean by specific choice?
21:58:12 <jle`> ah my 'at least...' was that i'm still not super comfortable with such polymorphic mptc's
21:58:20 <jle`> but it should be at least as usable as Data.Has
21:58:21 <MarcelineVQ> that would be x >>= \_ -> y    We don't bind a name for the result of x
21:58:36 <incertia> e.g. in the profunctor construction of lenses we have p a (f b) but we choice p = (->)
21:58:51 <jle`> ah, Choice
21:58:51 <incertia> Prisms appear to apply to anything with Choice
21:59:14 <incertia> and in such a way we can remove the lens dependency
21:59:20 <incertia> er profunctors
21:59:39 <koz_> @hoogle Choice
21:59:39 <lambdabot> Control.Lens.Combinators class Profunctor p => Choice (p :: Type -> Type -> Type)
21:59:39 <lambdabot> Control.Lens.Prism class Profunctor p => Choice (p :: Type -> Type -> Type)
21:59:40 <lambdabot> Network.AWS.Lens class Profunctor p => Choice (p :: Type -> Type -> Type)
21:59:44 <jle`> yup, you should be ok with using Data.Profunctor.Choice, you don't need a lens dep
21:59:45 <koz_> Ah that thing.
21:59:53 <jle`> oh btw there is an instance of `As () a` btw
22:00:14 <crestfallen> thanks a lot MarcelineVQ happy thanksgiving if it matters to you.
22:00:20 <jle`> er wait sorry
22:00:22 <jle`> i mean As Void a
22:00:31 <jle`> it's the analogue of Has () a
22:00:54 <jle`> ah, but there is no such instance in Data.Has.  probably because of overlapping instances
22:00:56 <jle`> nevermind :)
22:07:25 <incertia> _Void also happens to be Prism s s a Void and we are restricted to Prism s s a a
22:07:25 <thatlinuxguy> Hi im having troble with generic typing. I'm trying to make a function that will return a flattened version of a given list. What I can't figure out is how to know when you've reached an element and not another list when recursing into the list, I know all elements of the base list will have the same depth because the list must be homogeneous but how do you determine what that is.
22:08:02 <thatlinuxguy> sorry if I interrupted
22:08:06 <crestfallen> MarcelineVQ: wondering. in both divv and divvy, we bind the result of read to x, but that is just the s (not the 'a' in (a,s) as well); i.e in \x it is just the single value of state: 's'   .. correct?
22:08:53 <jle`> incertia: that unifies though, with a ~ Void
22:09:04 <jle`> so you can use _Void as a Prism s s a a
22:09:17 <jle`> oh ah, my explanation is wrong
22:10:39 <crestfallen> the second place of the tuple, (a,s) or (s,s)
22:10:46 <incertia> thatlinuxguy: if flatten :: [[a]] -> [a] your first pattern match will be on a list. e.g. flatten (a:as) = ... <-- here a is a list and you can further pattern match on that
22:11:51 <MarcelineVQ> It's the a, the first place of the tuple, because the a is what the Monad instance acts upon and >>= is from Monad.  read just happens to put the same value into both sides of the tuple.
22:12:07 <incertia> so like flatten ((b:bs):as) = b : flatten (bs:as) and flatten ((b:[]):as) = b : flatten as
22:12:27 <thatlinuxguy> ok cool that makes sense incertia
22:12:58 <crestfallen> very helpful, thanks, I think that's why I was having trouble writing the read into it MarcelineVQ 
22:14:05 <jle`> incertia: yeah, _Void works for As Void a, it unifies as a Prism a a Void Void
22:15:17 <jle`> previewer = const Nothing; reviewer = absurd
22:15:22 <incertia> jle`: Prism a Void => previewer :: a -> Maybe Void seems kinda weird
22:15:28 <incertia> do we just have previewer = const Nothing?
22:15:33 <jle`> it's weird, but lawful :)
22:16:25 <jle`> a Lens' S A means that there is some type x where S is equivalent to (A, x)
22:16:27 <incertia> i guess reviewer = absurd makes sense
22:16:33 <jle`> S is some product of A and some other type
22:16:40 <jle`> so you can "factor" S
22:16:51 <jle`> a Prism' S A means that there is some type x where S is equivalent to Either A x
22:17:03 <jle`> S is a sum of A and some other type, so you can "split" S, sum-wise
22:17:19 <incertia> splitting with void makes sense yeah
22:17:28 <jle`> in the case of united, Lens' s () is saying that any s is equivalent to ((), s)
22:17:44 <jle`> and in the case of _Void, Prism' s Void is saying that any s is equivalent to Either Void s
22:17:58 <jle`> maybe more of a theoretical nicety than a useful thing though
22:18:16 <incertia> the sum perspective makes much more sense
22:18:24 <jle`> that might be why there is no `Has () a` instance
22:18:33 <koz_> Maybe Void is actually () in disguise. :P
22:18:48 <incertia> no void is equivalent to empty set
22:18:54 <incertia> and () is a set with one element
22:20:51 <incertia> Has () a does not cause any overlapping instance warning
22:21:02 <incertia> ghc just tells me it's orphaned
22:21:18 <incertia> but it doesn't seem to be very useful which is probably why it's not there
22:21:24 <jle`> yeah, i'm guessing that there must have been some reason why it was not included
22:21:46 <jle`> i wonder
22:27:09 <koz_> incertia: There were missing quotes in what I said. I meant to say
22:27:19 <koz_> 'Maybe Void' is actually '()' in disguise.
22:27:42 <incertia> ooooooo
22:27:43 <incertia> that makes sense
22:28:16 <koz_> Maybe a has cardinality 1 + the cardinality of a.
22:28:24 <koz_> And since Void has cardinality 0... yeah. :P
22:30:30 <jle`> ha ha
22:30:44 <jle`> maybe the real void was the friends we made along the way
22:31:00 <koz_> The Void is clearly staring into jle` 
22:31:11 <incertia> the real friends were the voids we found along the way
22:31:14 <incertia> because i have no friends
22:31:15 <incertia> :)
22:31:28 <koz_> incertia: Void is unique. :P
22:31:33 <koz_> (thanks, axiom of extensionality)
22:45:06 <crestfallen> :quit
22:45:17 <crestfallen> exit
22:45:21 <crestfallen> oops
22:51:53 * hackage wai-extra 3.1.3 - Provides some basic WAI handlers and middleware.  https://hackage.haskell.org/package/wai-extra-3.1.3 (MichaelSnoyman)
22:59:46 <MarcelineVQ> place ur bets
23:00:53 * hackage data-as 0.0.0.1 - Simple extensible sum  https://hackage.haskell.org/package/data-as-0.0.0.1 (incertia)
23:01:53 * hackage typson-beam 0.1.0.0 - Typson Beam Integration  https://hackage.haskell.org/package/typson-beam-0.1.0.0 (aaronallen8455)
23:03:25 <jle`> woo hoo
23:03:30 <incertia> apparently haddock hates my life
23:17:57 <incertia> does hackage not build haddock automatically on upload?
23:18:05 <dminuoso> Correct
23:18:39 <incertia> ok maybe that is why no links are showing up
23:18:40 <dminuoso> 2Well
23:18:46 <dminuoso> Hackage *tries* to build the documentation
23:18:49 <dminuoso> But it can fail
23:19:03 <dminuoso> incertia: https://hackage.haskell.org/upload
23:19:47 <incertia> nvm it generated i just had to give it like 15min
23:32:38 <We> cleanup
23:39:50 <dminuoso> What would you call an operation `Tree (Maybe a) -> Maybe (Tree a)`?
23:40:21 <jle`> could it be done for any Applicative instead of Maybe?
23:40:25 <jle`> if so, i'd call it sequence
23:40:43 <jle`> s/instead of/and not just
23:41:02 <jle`> sequence :: Applicative f => Tree (f a) -> f (Tree a)
23:41:18 <dminuoso> Sure, I mean the actual types involved make it slightly more specialized, as I have
23:41:31 <dminuoso> Oh well, its the same.
23:41:45 <jle`> ah i meant, if you don't treat it in any way specific to Maybe that couldn't be done generically for all Applicative
23:42:15 <dminuoso> Right. Well I was just thinking of specifically calling that specialized function `hasLabel`
23:42:35 <dminuoso> I dont want to revisit later wondering about the uses of `sequence` here
23:42:47 <incertia> probably fine to give it a specific name if its use case in that location is specific
23:42:48 <jle`> the behavior of sequence would be more or less "allJust", maybe
23:42:55 <incertia> yeah
23:42:58 <jle`> i guess it depends on your use case too
23:43:05 <jle`> maybe 'validate'
23:43:34 <dminuoso> So I build up a patricia tree, and then I want to ensure it's also a valid regular labeled tree
23:43:44 <dminuoso> *patricia trie
23:44:14 <jle`> it sounds like you are describing a specific operation, then
23:44:26 <jle`> and not just "a thing of type Tree (Maybe a) -> Maybe (Tree a)"
23:44:38 <dminuoso> Well, internally it's very much just sequence..
23:44:45 <jle`> so i would give it a name to whatever describes what you are doing, semantically :)
23:44:51 <jle`> apart from just what the types tell you
23:44:58 <dminuoso> Right. Leading us back to my original question
23:45:00 <dminuoso> What would you call it :p
23:45:19 <jle`> toValidRegularLabeledTree ?
23:45:32 <dminuoso> heh
23:45:36 <incertia> i probably would just do let allJust = sequence in and go on from there
23:45:50 <incertia> but giving it a more apt name
23:46:03 <jle`> give a name based on the type = i'd say sequence, probably. but give it a name based on how you are using it, toValidRegularLabeledTree is something i'd use
23:46:08 <dminuoso> incertia: Yeah no, the reality is slightly more annoying. I have `Tree (ann, Maybe a) -> Maybe (Tree (ann, a))`
23:46:14 <MarcelineVQ> wwcd ::​Tree (Maybe a) -> Maybe (Tree a)
23:46:55 <dminuoso> So I need some double sequence/traverse
23:46:59 <dminuoso> With flip
23:47:09 <dminuoso> MarcelineVQ: wwc?
23:47:29 <MarcelineVQ> what would cale do
23:47:47 <asheshambasta> Anyone with more reflex experience than I can tell me why this traces: https://github.com/asheshambasta/flowerpower/blob/showcase/servant-reflex-dependency/fht-frontend/src/Frontend/Garden/Plant.hs#L93 while this doesn't: https://github.com/asheshambasta/flowerpower/blob/showcase/servant-reflex-dependency/fht-frontend/src/Frontend/Garden/Plant.hs#L103 (I couldn't provide a more minimal repro. of this)
23:48:22 <jle`> looks like `traverse sequence`
23:49:06 <dminuoso> traverse (sequence . swap)
23:49:11 <koz_> :t traverse sequence
23:49:13 <lambdabot> (Traversable t1, Traversable t2, Monad f) => t1 (t2 (f a)) -> f (t1 (t2 a))
23:49:17 <dminuoso> % :t traverse (sequence . swap
23:49:17 <yahb> dminuoso: ; <interactive>:1:26: error: parse error (possibly incorrect indentation or mismatched brackets)
23:49:19 <dminuoso> % :t traverse (sequence . swap)
23:49:19 <yahb> dminuoso: forall {t :: * -> *} {f :: * -> *} {a} {b}. (Traversable t, Monad f) => t (f a, b) -> f (t (b, a))
23:49:35 <dminuoso> Oh, no. Actually traverse sequence right
23:50:30 <jle`> traverse (sequence . swap . swap)
23:50:51 <dminuoso> :)
23:52:03 <dminuoso> traverse (sequence . swap . flip const id . swap)
23:52:37 <dminuoso> Bet hlint cant figure that one out.
23:52:55 <koz_> :t flip const id
23:52:57 <lambdabot> c -> c
23:53:01 <koz_> Lol.
23:53:17 <jle`> :t const id ()
23:53:18 <lambdabot> a -> a
23:54:24 <incertia> i had to think about flip const id for a bit
23:54:44 <dminuoso> Well you can put something more interesting into `id`, that is better for tripping you up
23:54:48 <dminuoso> like `flip const fmap`
23:55:10 <jle`> :t const id id
23:55:11 <lambdabot> a -> a
23:55:27 <dminuoso> % :t flip const fmap
23:55:28 <yahb> dminuoso: ; <interactive>:1:12: error:; * Ambiguous type variable `f0' arising from a use of `fmap'; prevents the constraint `(Functor f0)' from being solved.; Probable fix: use a type annotation to specify what `f0' should be.; These potential instances exist:; instance [safe] forall a. Functor (Q.Fun a) -- Defined in `Test.QuickCheck.Function'; instance [safe] Functor Q.Gen 
23:55:34 <dminuoso> Oh. wait what?
23:55:43 <jle`> it doesn't know what Functor instance to compile there
23:55:54 <jle`> :t flip const map
23:55:55 <lambdabot> c -> c
23:56:09 <dminuoso> Oh I guess this would need impredicative types?
23:56:23 <incertia> asheshambasta: i would imagine it wouldn't get traced if dEitherPlant is Left
23:56:31 <dminuoso> yeah `flip const map` it is
23:56:39 <incertia> could be wrong here
23:56:41 <jle`> flip const map itself only works because of defaulting i think
23:56:53 <dminuoso> Why defaulting?
23:56:56 <dminuoso> % :t flip const
23:56:56 <yahb> dminuoso: forall {b} {c}. b -> c -> c
23:57:05 <jle`> because it defaults to map :: (() -> ()) -> [()] -> [()]
23:57:20 <jle`> otherwise it wouldn't know what to pick for a and b
23:57:21 <jle`> :t map
23:57:22 <dminuoso> Ah, I see. Otherwise that would have required impredicativity
23:57:23 <lambdabot> (a -> b) -> [a] -> [b]
23:57:48 <incertia> in particular if any of eName or eDayPlanted are Left it would cause fst <$> maints/snd <$> maints to not be evaluated and thus not trigger the traceEvent
23:57:50 <incertia> but im no guru
23:57:56 <jle`> there should be defaulting for * -> *'s
23:58:22 <dminuoso> You should open an issue on gitlab about that. Name `flip const fmap` as the motivating example.
23:58:34 * dminuoso smiles
23:58:35 <jle`> bites me every day :)
23:58:47 <jle`> i wonder what the default should be
23:58:56 <jle`> maybe Identity first?
23:59:03 <jle`> or maybe Proxy
23:59:10 <jle`> ah yeah, Proxy first, then Identity
23:59:39 <jle`> this would be my dream haskell
