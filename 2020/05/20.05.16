00:01:10 <fog> the easierst way i can describe it is like, if you had a neural net, and fixed most of the neurons, and allowed some to vary, then this would trace paths over the space of function approximators
00:01:18 <fog> it would effectively section the space
00:01:27 <fog> and there is some notion of curvature on this
00:01:34 <fog> but anyway...
00:01:46 <fog> so the callee is the code being called by the caller
00:02:03 <ski> yes
00:02:36 <ski> they have opposite obligations and permissions, so to speak
00:02:39 <fog> and swapping forall and exists somehow changes the thing calling the code into the implementation!?
00:02:52 <ski> the caller has to ensure the precondition holds, before calling the function
00:03:13 <ski> the callee, that is the code implementing the function, is permitted to just assume the precondition holds
00:03:22 <ski> and the other way around, with the postcondition
00:03:40 <fog> ah, "the roles of the caller and calee" being to make sure about this existence
00:04:33 <fog> so with forall, the caller specifies the variable it wants, and the callee would have implemented it for any possible type
00:04:40 <ski> if you have `foo :: T -> Bool', then `foo' consumes `T's
00:04:43 <fog> and the other way round?
00:05:07 <ski> if you have `bar :: (T -> Bool) -> Bool', then `bar' really produces `T's (to pass to its callback argument)
00:05:42 <fog> oh its some kind of ps encoding
00:05:45 <ski> with `length :: forall a. [a] -> Bool', the caller picks `a'
00:05:45 <fog> cps*
00:06:05 <ski> with `mystery :: (forall a. [a] -> [a]) -> [String] -> [String]', the callee picks `a'
00:06:17 <fog> aha!!
00:06:21 <fog> woot
00:06:24 <ski> (in the implementation i gave, it picks `a' to be `String', in one call, and `a' to be `Char', in another call)
00:06:56 <fog> and then you can commute the forall from within the parens, and it becomes an exists
00:07:01 <ski> with `callCC :: forall m a. MonadCont m => ((forall b. a -> m b) -> m a) -> m a', the caller again picks `b'
00:07:28 <ski> fog : only if you were allowed to use classical logic
00:07:34 <fog> cant we?
00:07:56 <ski> in intuitionistic logic, `(forall a. ..a..) -> ...' isn't equivalent to `exists a. (..a.. -> ...)'
00:08:24 <ski> because in the latter, a value of that type picks a single type for `a'
00:09:02 <ski> while, for the former, it would pick one type for `a', for each call to its callback. it is allowed to usel the callback multiple times, or zero times
00:09:09 <fog> oh so it wouldnt be nice and polymorphic, and we would restrict its type as soon as we used it anywhere?
00:09:46 <ski> in intuitionistic logic, if `exists a. ..a..' is proved, one can extract from the proof a particular type that was selected for `a'
00:09:54 <fog> so is haskell intuintionalistic or classical?
00:09:57 <ski> not so in classical logic
00:10:08 <ski> intuitionistic/constructive
00:11:58 <fog> i guess since we dont have an exists keyword it is only going to be a forall within the parens, so we can get the use it anywhere on many different tpyes style thing of classical, but like with the MnadCont implementation of CallCC we have the intuitionistic type unification
00:12:14 <ski> e.g. you can prove `exists a. (P a -> (forall b. P b))', classically, but not intuitionistically
00:12:30 <fog> argh!
00:12:36 <ski> (that's a fun exercise to try, btw :)
00:12:58 <fog> you commute the forall onto the exists and they destroy each other
00:13:00 <ski> we don't have `exists', but we can encode it
00:13:17 <fog> right, like your mystery function
00:13:22 <fog> using continuations
00:13:33 <fog> finally i get this. 
00:13:44 <ski> @where logitext
00:13:44 <lambdabot> "Interactive Tutorial of the Sequent Calculus" by ezyang at <http://logitext.mit.edu/logitext.fcgi/tutorial>,<http://logitext.mit.edu/logitext.fcgi/main>,<http://blog.ezyang.com/2012/05/an-interactive
00:13:44 <lambdabot> -tutorial-of-the-sequent-calculus/>
00:13:52 <ski> might be fun to try
00:14:14 <fog> as fun as hetrogenous lenses?
00:14:52 <fog> so were we building up to SPJs impredictive thing?
00:15:41 <fog> oh no, theorem provers. wasnt there a haskell maple implementation or something using algebras over compositional functions?
00:16:29 <ski> hm, i haven't watched SPJ's talk yet. apparently it's at <https://www.youtube.com/watch?v=ZuNMo136QqI>. also see <http://chalmersfp.org/>
00:16:43 <fog> like, partially applying index contraction... or a dot product to a vector to make it a function, and then trying to do eqational term cancelation and inverses and stuff
00:17:05 <fog> "invert the matrix" etc
00:17:14 <fog> but with tensor nets...
00:17:29 <fog> its some kind of subtyping problem i think...
00:19:01 <fog> like, if you generalise nets so they can take values from this restricted set of types, and then you are passing a net of some rank into a net of some other rank along one of the input edges 
00:19:31 <fog> but you can only see the result, and one of the input nets, and your supposed to be able to do some algebra to figure out the other net
00:20:26 <fog> (this ends up with some terrible tensor indexed functions.. like, types all decorated with trees of nats instead of normal type signatures.)
00:21:59 <fog> and then you try and enumerate the low rank versions to make a sparse covering of the more dense covering of the higher rank function approximators
00:22:17 <fog> and then you enumerate the trees over the descent from the closeby low rank approximators
00:22:58 <fog> to the higher rank, better fitting "frame" of the better approximators 
00:23:30 <fog> and then there are some geodesics and you get optimal learning acceleration as the shortest path
00:24:27 <fog> and in the other direction its recursive coarse graining, crushing the nets, into low rank approximators, which label regions in the space of functions 
00:24:35 <fog> by which is closest
00:24:49 <fog> argh, im going afk
00:48:46 * hackage mmsyn4 0.3.0.0 - The "glue" between electronic tables and GraphViz  https://hackage.haskell.org/package/mmsyn4-0.3.0.0 (OleksandrZhabenko)
01:18:15 * hackage futhark 0.15.7 - An optimising compiler for a functional, array-oriented language.  https://hackage.haskell.org/package/futhark-0.15.7 (TroelsHenriksen)
01:54:15 * hackage monadic-recursion-schemes 0.1.8.0 - Recursion Schemes for Monadic version.  https://hackage.haskell.org/package/monadic-recursion-schemes-0.1.8.0 (KatsutoshiItoh)
03:00:16 * hackage mmsyn4 0.3.1.0 - The "glue" between electronic tables and GraphViz  https://hackage.haskell.org/package/mmsyn4-0.3.1.0 (OleksandrZhabenko)
03:12:15 * hackage monadic-recursion-schemes 0.1.9.0 - Recursion Schemes for Monadic version.  https://hackage.haskell.org/package/monadic-recursion-schemes-0.1.9.0 (KatsutoshiItoh)
03:13:15 * hackage mmsyn4 0.3.1.1 - The "glue" between electronic tables and GraphViz  https://hackage.haskell.org/package/mmsyn4-0.3.1.1 (OleksandrZhabenko)
03:38:00 <kuribas> the associative property of monoids means the can be reordered without changing the result.  I was wondering if there are parellel strategies that take advantage of this?
03:38:59 <phadej> reassociated*
03:39:11 <phadej> `reordered` has commutativity implication
03:39:14 <phadej> which monoids don't have
03:39:25 <phadej> > [1,2] <> [3,4]
03:39:28 <lambdabot>  [1,2,3,4]
03:39:29 <phadej> > [3,4] <> [1,2]
03:39:31 <lambdabot>  [3,4,1,2]
03:41:47 <phadej> yet, classic Map-Reduce is "just" foldMap, fold . map
03:41:55 <kuribas> phadej: right, the computation can be reordered, but not the values
03:42:04 <phadej> if it's pure computation, yes.
03:42:23 <phadej> or at least independent
03:44:34 <kuribas> I mean (((1 <> 2) <> 3) <> 4) can be parallelized as ((1 <> 2) <> (3 <> 4)) 
03:45:11 <kuribas> > getSum $ (((1 <> 2) <> 3) <> 4)
03:45:13 <lambdabot>  10
03:45:25 <kuribas> getSum $ ((1 <> 2) <> (3 <> 4))
03:45:32 <kuribas> > getSum $ ((1 <> 2) <> (3 <> 4))
03:45:35 <lambdabot>  10
03:48:45 * hackage reflection 2.1.6 - Reifies arbitrary terms into types that can be reflected back into terms  https://hackage.haskell.org/package/reflection-2.1.6 (ryanglscott)
04:05:01 <juri_> foldt is fun for those.
04:54:26 <merijn> ooh...ghc is getting multi-component support? :D
05:41:55 <eigenlicht> hi
05:42:55 <juri_> hi. ;)
05:42:57 <eigenlicht> anyone here uses hie?
05:44:48 <merijn> Presumably yes
05:45:21 <eigenlicht> Is it possible to get it working with 8.10?
05:48:40 <eigenlicht> ^ nvm that's stupid question
05:52:15 * hackage xrefcheck 0.1.1 -   https://hackage.haskell.org/package/xrefcheck-0.1.1 (martoon)
05:59:38 <juri_> eigenlicht: there are no stupid questions, just habitual imperitive language users.
05:59:59 <merijn> Nothing wrong with imperative languages. Haskell's my favourite :>
06:05:04 <Uniaika> what he said ^
06:05:20 <int-e> > do Nothing
06:05:23 <lambdabot>  Nothing
06:05:46 <merijn> int-e: That's obsolete, did you mean
06:05:51 <merijn> @hackage acme-dont
06:05:51 <lambdabot> http://hackage.haskell.org/package/acme-dont
06:07:16 * hackage xrefcheck 0.1.1.1 -   https://hackage.haskell.org/package/xrefcheck-0.1.1.1 (martoon)
06:07:31 <int-e> merijn: I did not.
06:08:22 <merijn> Uniaika: tbh, I think this whole attempt to market Haskell at people doing C by saying "look at how safe it is, no runtime issues!" is the wrong approach :p
06:08:24 <int-e> @hoogle did
06:08:24 <lambdabot> Network.AWS.SQS dId :: Lens' DeleteMessageBatchResultEntry Text
06:08:24 <lambdabot> Network.AWS.SQS.Types dId :: Lens' DeleteMessageBatchResultEntry Text
06:08:24 <lambdabot> Network.AWS.APIGateway dId :: Lens' Deployment (Maybe Text)
06:08:37 <int-e> pff
06:08:39 <merijn> Uniaika: One of these days I'm going to write an ode to unsafe Haskell and "IO-all-the-things"
06:09:15 <merijn> "Pfft, you can't even type pun pointers because that's UB? Watch me make arbitrary casts and get exactly the behaviour I expect and want!"
06:10:56 <merijn> I don't really understand how Haskell got the reputation of "so safe you can't do anything high performance in it". There's like a million escape hatches letting you break basically *everything*
06:15:13 <int-e> merijn: so it's unsafe and you still can't do anything high performance in it, unless it's memory-bound.
06:15:15 * hackage reanimate 0.3.2.1 - Animation library based on SVGs.  https://hackage.haskell.org/package/reanimate-0.3.2.1 (DavidHimmelstrup)
06:16:22 <merijn> int-e: The killer feature IMO, is the ease with which you can wrap dangerous low level abstractions with pointy edges into convenient APIs for regular people
06:17:05 <phadej> yeah, Haskell is very nice glue language
06:17:12 <phadej> a lot better than say, JavaScript...
06:17:15 <int-e> so sticky
06:17:25 <merijn> phadej: Or even python
06:17:44 <merijn> phadej: Remember how people called python "high level glue for C"? Haskell is a billion times better at that, tbh
06:17:59 <int-e> > 10^9
06:18:02 <lambdabot>  1000000000
06:18:28 <merijn> phadej: Hell, just straight up "writing C in haskell" by using Storable backed Vector's is...surprisingly performant
06:19:13 <int-e> Ah, whatever. I like Haskell. But I don't want to write that performance-critical inner loop in Haskell... yes it can sometimes be done, but the effort that goes into that is ridiculous.
06:20:05 <merijn> int-e: Sure, but that's fairly rare, tbh. The real question is "how easy is it to get to 80-90% of peak performance" getting peak performance is a ridiculous effort in C/C++ too
06:20:39 <phadej> at least you don't get it "by just writing code"
06:21:17 <phadej> in particular language*
06:21:25 <merijn> If we wanna go into the *real* performance realm it's a hollistic problem anyway
06:22:16 <merijn> Most people are terrible at understanding how to get good performance and how fast computers actually are
06:25:13 <asheshambasta> What does the error mean here? https://gist.github.com/asheshambasta/cb57a41cc8e968268ea31d8af6be0e76
06:28:15 * hackage reanimate 0.3.2.2 - Animation library based on SVGs.  https://hackage.haskell.org/package/reanimate-0.3.2.2 (DavidHimmelstrup)
06:32:12 <int-e> asheshambasta: what is JsRead?
06:32:16 <eigenlicht> why is :doc not working in ghci 8.10.1 ("ghci | ghc: Can't find any documentation for GHC.Base."?
06:33:31 <asheshambasta> int-e: https://gist.github.com/asheshambasta/cb57a41cc8e968268ea31d8af6be0e76#file-jsonread-hs-L1
06:33:37 <asheshambasta> (edited)
06:42:11 <int-e> asheshambasta: I suspect 'a' has a nominal role there, which thwarts the attempt to use `coerce` to change the return type. I seem to recall that this is a general problem with transformers.
06:43:46 <asheshambasta> int-e: I see, it could explain why deriving via works for FromJSON / ToJSON (Aeson), which do not seem to be using transformers. 
06:43:51 <int-e> (the problem being that if you do  newtype X m a = X (m a)  then since the argument of 'm' could have a nominal role, the only safe role to give a is a nominal role as well)
06:45:13 <int-e> Unfortunately I don't know how people deal with this.
06:46:00 <asheshambasta> int-e: being new to DerivingVia I was looking for some special syntax that could let me specify something on the lines of deriving JSONRead via (fmap EventId . jsonRead @NonEmptyText) (surely not valid sytax)
07:02:34 <Athas> I have a package with a ton of modules: https://hackage.haskell.org/package/futhark
07:02:34 <Athas> I would like to write an overview that explains the most important modules and where to start.  Is there a way to put information like that on the this front page, before the module list?
07:02:55 <Athas> I guess I can put stuff in the package description itself, but does that support all the Haddock referencing?
07:03:59 <hpc> you can link to modules in haddock
07:04:14 <hpc> and i think when you do module re-exports, you can attach haddock to those as well
07:04:28 <hpc> but that's from vague memory, you'll have to experiment
07:04:32 <merijn> Athas: You can link to modules on the front page!
07:04:39 <merijn> Athas: Exhibit A: https://hackage.haskell.org/package/broadcast-chan
07:05:24 <merijn> So you're entire problem just became trivial ;)
07:05:28 <merijn> s/you're/your
07:06:06 <Athas> So the package description permits Haddock syntax?  That's good.
07:06:27 <asheshambasta> int-e: thanks for replying to me, btw. I will post here if I find a workaround. 
07:06:40 <merijn> Athas: It didn't for a time, but that got fixed 1 or 2 years ago
07:11:15 * hackage reanimate 0.3.2.3 - Animation library based on SVGs.  https://hackage.haskell.org/package/reanimate-0.3.2.3 (DavidHimmelstrup)
07:20:21 <tukane> When `cabal install` is run on a local cabal package, would the files in the package be copied to some directory that cabal manages?
07:25:31 <merijn> tukane: Are we talking cabal-install 3.x or an older one?
07:29:23 <tukane> merjin: maybe 3.x? cabal --version told me it's 3.2.0.0
07:29:43 <tukane> merijn* sorry for the typo
07:30:10 <LCF> hi
07:31:45 * hackage fourmolu 0.0.6.0 - A formatter for Haskell source code  https://hackage.haskell.org/package/fourmolu-0.0.6.0 (parsonsmatt)
07:32:25 <merijn> tukane: Right, with 3.0 and later that question becomes trickier/more nuanced. Let's start with: Why do you want to know?
07:33:45 <LCF> s3mpr3 a b0mb4ar
07:36:47 <tukane> merijn: Because I'd like to install Agda's stdlib with cabal and the installation procedure requires me to supply Agda with the path of Agda's stdlib. If `cabal install` copies the files in the package I'd like to specify that path.
07:37:04 <LCF> hi
07:38:46 <merijn> tukane: So, libraries get installed into global store under ~/.cabal/store/
07:41:31 <tukane> merijn: thx. is that the only directory cabal could copy files into?
07:42:28 <merijn> tukane: If you're installing a library it should be there
07:43:13 <phadej> Agda stdlib's is definitely not installed with cabal
07:43:16 <phadej> there's some confusion
07:43:29 <phadej> I have
07:43:30 <phadej> % cat ~/.agda/libraries 
07:43:30 <phadej> /code/agda/agda-stdlib/standard-library.agda-lib
07:43:30 <phadej> /code/agda/cubical/cubical.agda-lib
07:43:30 <yahb> phadej: ; <interactive>:21:5: error: Variable not in scope: (~/.) :: ([Doc] -> Doc) -> t0 -> t; <interactive>:21:8: error: Variable not in scope: agda; <interactive>:21:13: error: Variable not in scope: libraries
07:43:44 <phadej> where those library paths are just git checkouts
07:47:24 <tukane> merijn: thanks!
07:48:09 <tukane> phadej: I see. I might be confused, but https://github.com/agda/agda-stdlib/blob/master/notes/installation-guide.md says optionally it's possible to install with cabal
07:51:03 <phadej> that's very confusing. that would install GenerateEverything and AllNonAsciiChars executables
07:51:06 <phadej> and nothing else
07:51:18 <phadej> I have no idea why that step is mentioned in the installation-guide
07:52:05 <phadej> at least it's optional, so just skip it.
07:52:18 <tukane> phadej: aha. that was helpful. thanks!
08:12:15 * hackage haskoin-core 0.13.5 - Bitcoin & Bitcoin Cash library for Haskell  https://hackage.haskell.org/package/haskoin-core-0.13.5 (jprupp)
08:18:45 * hackage structured 0.1 - Structure (hash) of your data types  https://hackage.haskell.org/package/structured-0.1 (phadej)
08:19:45 * hackage binary-tagged 0.3 - Tagged binary serialisation.  https://hackage.haskell.org/package/binary-tagged-0.3 (phadej)
08:28:02 <f-a> http://paste.debian.net/1147132/ what I am trying to do in currLens is not possible without wrapping `Int` and `Bool` in a sum type, right?
08:33:11 <Athas> When I run 'cabal haddock', I get a bunch of warnings about "could not find link destination" for pretty much all the names I re-export.
08:33:30 <Athas> How do I make cabal actually fix the problem (by doccing my deps) instead of just whining?
08:35:23 <phadej> currently you don't
08:35:54 <phadej> you need deps to be built with documentation, but I'm not sure how to do that
08:36:08 <phadej> maybe documentation: True in cabal.project will do the trick
08:36:12 <phadej> but if it doesn't, than it's hard.
08:38:07 <ski> f-a : looks like you really intended an existential, rather than a universal, there
08:38:37 <Athas> Ugh.
08:39:02 <Athas> I vaguely recall Stack not having this issue, so I guess it's a relatively shallow problem.
08:40:43 <Athas> So what do people actually do?
08:45:23 <f-a> ski: thanks, ExistentialQuantification will be then
08:45:45 <ski> f-a : i'm not so sure it's sensible, though
08:47:22 <ski> f-a : what're you actually trying to do ?
08:47:23 <phadej> Athas: I just don't care about not having links to symbols in dependencies
08:47:59 <Athas> But Hackage has them, so surely it's possible?
08:48:09 <Athas> Anyway, I don't really care that much.  How do I make Hackage shut up about it?
08:48:15 <Athas> s/Hackage/Haddock/
08:53:33 <f-a> ski: I have have a game state (product), composed by many game parts (one and two here) and a Selector which highlights which one is on. Functions for it are: run :: State -> Event -> State and draw :: State -> Surface. If I had something like `currLens` (and a typeclass `Playable` with `prun` and `pdraw`, I write a very short `run` function for state (e.g.: s & currLens s %~ prun) and same for draw (p ^. 
08:53:39 <f-a> currLens . to pdraw), without code duplication, too.
08:55:25 <ski> f-a : oh .. so you'd want a lens getting you an `exists a. Playable a *> a', then ?
08:59:41 <f-a> ski: what's *> ?
08:59:45 * hackage pdftotext 0.0.1.0 - Extracts text from PDF using poppler  https://hackage.haskell.org/package/pdftotext-0.0.1.0 (geyaeb)
09:00:55 <ski> f-a : `(->)' is to `(,)' as `forall' is to `exists' as `=>' is to `*>'
09:04:41 * ski looks at f-a
09:05:25 <f-a> I suppose so ski, I can't for sure say it as I don't grasp the notation
09:07:54 <ski> f-a : a value of type `forall a. ..a..' is such that a user/consumer/caller of the value may pick a type `T', and then treat the value as if it had type `..T..'. otoh, the producer/implementor/callee must be prepared for any choice, must treat `a' as an abstract type about which nothing is known, and provide a value of type `..a..'
09:08:14 <phadej> Athas: haddock --help
09:09:14 <f-a> that is clear, ski 
09:09:26 <ski> f-a : a value of type `exists a. ..a..' is such that the producer/implementor/callee of the value may pick a type `T', and then provide a value of type `..T..'. otoh, a user/consumer/caller must be prepared for any choice, must treat `a' as an abstract type about which nothing is known, and then make use of the value of type `..a..'
09:10:29 <f-a> excellent
09:10:38 <f-a> exactly what I want then
09:10:47 <f-a> (excellent explanation)
09:11:01 <ski> f-a : a value of type `Cxt => T' is such that if a user/consumer/caller of the value provides evidence for `Cxt', they may then use the value as if it had type `T'. otoh the producer/implementor/callee may freely assume that evidence for `Cxt' will be given, and may use thatn when providing a value of type `T'
09:12:22 <ski> f-a : a value of type `Cxt *> T' is such that if the producer/implementor/callee of the value must provide evidence for `Cxt', in addition to providing a value of type `T'. otoh a user/consumer/caller may freely assume that evidence for `Cxt' will be provided, in addition to being given a value of type `T'
09:13:12 <ski> so, for `Cxt => T', caller provides evidence for `Cxt', callee provides value `T'
09:13:48 <ski> while, for `Cxt *> T', callee provides both evidence for `Cxt', and a value of type `T'
09:14:13 <ski> see the analogy to `U -> T' vs. `(U,T)' ?
09:14:47 <ski> `=>' tends to be used after `forall', and `*>' after `exists'
09:17:54 <ski> if you have `exists a. Widget a *> [a]' you have a list of things, all of the same type `a', about which nothing is known, except that it's an instance of `Widget' (so you could call `Widget' methods on the values)
09:18:43 <ski> if you had `exists a. Widget => [a]', then the consumer of a value of this type would have to provide evidence of `Widget a', for an unknown type `a' .. which seems pretty impossible, so not really useful
09:18:49 <ski> f-a : making sense ?
09:18:54 <f-a> yes, clear!
09:19:38 <ski> oh, and `*>' is just notation i've invented, when talking about this here on #haskell, to discuss this distinction
09:20:45 <ski> i think it often helps to conceptualize things with existentials, in terms of pseudo-Haskell notation `exists' and `*>', before translating to one of the two current encodings in Haskell
09:26:14 * hackage machination 1.0.0 - Plot charts as unicode strings.  https://hackage.haskell.org/package/machination-1.0.0 (KtorZ)
09:27:15 * hackage scotty 0.11.6 - Haskell web framework inspired by Ruby's Sinatra, using WAI and Warp  https://hackage.haskell.org/package/scotty-0.11.6 (chessai)
09:29:15 * hackage scotty 0.12 - Haskell web framework inspired by Ruby's Sinatra, using WAI and Warp  https://hackage.haskell.org/package/scotty-0.12 (chessai)
09:30:04 <f-a_> ski: thanks for the explanation. Getting back to Haskell, that that is what ExistentialQuantification (and nothing else) does, am I wrong?
09:30:49 <ski> well, `ExistentialQuantification' (which is a misnomer, afaiac) enables one of those two encodings of existentials
09:35:06 <ski> (the other encoding is via CPS, and rank-2)
09:36:10 <f-a_> excellent, thanks again
09:36:36 <ski> is it clear what i intend, by these two encodings ?
09:38:48 <f-a_> do you mean if I have used/known rank-2 and cps?
09:43:34 <ski> f-a_ : rather, if it's clear how to represent existentials with those
09:45:00 <f-a_> cps yes, rank not really but I guess a search will get me on par
09:46:01 <ski> well, just knowing about those two wouldn't necessarily tell you how to use them in the way i had in mind
09:46:19 <ski> f-a_ : should i walk through an example, to show what i mean ?
09:46:49 <f-a_> sure, if you have time
09:47:24 <ski> well, perhaps a few examples, to not take it all at the same time
09:48:07 <ski> one example i tend to like is queues
09:48:41 <ski>   type QueueOps a = exists q. (q,a -> q -> q,q -> Maybe (q,a))
09:49:36 <ski> a value of type `QueueOps a' represents some implementation of queues with element type `a', with a type `q' of queues, an empty queue, an enqueue operation, and a dequeue operation
09:49:49 <f-a_> ok
09:50:12 <ski> if you want to, you may think of such a value as a "module" implementing such a queue abstract data type
09:50:27 <ski> it's easy to make
09:50:40 <ski>   trivialQueue :: forall a. QueueOps a
09:50:56 <ski>   trivialQueue = (empty,enqueue,dequeue)
09:50:59 <ski>     where
09:51:04 <ski>     empty :: [a]
09:51:07 <ski>     empty = []
09:51:10 <ski>     ...
09:51:41 <ski> where the hidden/abstract/opaque/forgotten type `q' has been chosen to be `[a]'
09:52:54 <ski> this is inefficient, though, so a better implementation is to represent a queue `front ++ back' as a pair `(front,reverse back)', so that you get efficient access to both start and end of queue. once in a while, as you exhaust the `revBack' part, you'll have to move `reverse front' over
09:53:43 <ski> anyway, the question is how to actually represent `exists q. ..q..' in current Haskell
09:54:46 <ski> `ExistentialQuantification' (which perhaps ought to be called `ExistentialDataTypes' or even `ExistentialDataConstructors') does this by inventing a new `data' type, for each `exists' that you want to encode
09:54:58 <ski> so, to begin with, you'd have
09:55:11 <ski>   data QueueOps a = MkQOps (exists q. (q,a -> q -> q,q -> Maybe (q,a)))
09:55:15 * hackage math-functions 0.3.4.0 - Collection of tools for numeric computations  https://hackage.haskell.org/package/math-functions-0.3.4.0 (AlexeyKhudyakov)
09:55:16 <ski> (still pseudo-Haskell)
09:55:30 <ski> or, using `GADTSyntax', that'd be
09:55:37 <ski>   data QueueOps a
09:55:39 <ski>     where
09:55:55 <ski>     MkQOps :: (exists q. (q,a -> q -> q,q -> Maybe (q,a))) -> QueueOps a
09:56:22 <ski> however, there's a logical law that says that `(exists a. ..a..) -> ...' is equivalent to `forall a. (..a.. -> ...)'
09:56:27 <ski> therefore
09:56:32 <ski>   MkQOps :: (exists q. (q,a -> q -> q,q -> Maybe (q,a))) -> QueueOps a
09:56:35 <ski> is equivalent to
09:56:50 <ski>   MkQOps :: forall q. (q,a -> q -> q,q -> Maybe (q,a)) -> QueueOps a
09:57:06 <ski> and, if we want to, we could elect to curry the `data' constgructor, giving us
09:57:19 <ski>   MkQOps :: forall q. q -> (a -> q -> q) -> (q -> Maybe (q,a)) -> QueueOps a
09:57:35 <f-a_> ok
09:57:51 <ski> so, an "existential data type" has a `data' constructor that is polymorphic in the existentially quantified variable
09:58:13 <ski> of course, this one is also polymorphic in `a'. but the difference is that `a' occurs in the result type, but `q' doesn't
09:58:20 <f-a_> yeah
09:58:40 <ski> without using the `GADTSyntax', one'd write
09:58:59 <ski>   data QueueOps a = forall q. MkQOps q (a -> q -> q) (q -> Maybe (q,a))
09:59:40 <ski> btw, note that some `data' constructors could be "existential" in this sense, while others not. hence it's really the `data' constructor, not the `type' constructor, which is "existential"
10:00:10 <f-a_> oh yeah
10:00:26 <ski> now, the second encoding relies on a type `T' being equivalent to `forall o. (T -> o) -> o'
10:00:52 <ski> in particular, `exists a. ..a..' is equivalent to `forall o. ((exists a. ..a..) -> o) -> o'
10:01:12 <ski> but that, in turn, is equivalent to `forall o. (forall a. ..a.. -> o) -> o'
10:01:31 <ski> so, instead of inventing a new `data' type, you get a rank-2 operation
10:01:37 <HeeloHaskell> \O/ 
10:01:47 <ski> which of these two encodings are to be preferred depends on the situation
10:02:45 <ski> if you intend to "open" the existential directly after calling your function, the CPS version may be simpler (no extra `data' type to clutter things up, that you have to go look up the implementation of)
10:02:46 <EvanR> ExistentialQuantification makes the usual weird "data" shorthand even weirder
10:03:02 <EvanR> GADT syntax all the way
10:03:03 <ski> weird, how ?
10:03:05 <ski> heh
10:04:24 <ski> anyway, if you want to represent `exists a. Widget a *> [a]', you could write `data SomeWidgets = forall a. Widget => WrapWidgets [a]' .. or use `forall o. (forall a. Widget a => [a] -> o) -> o'
10:04:25 <EvanR> i mean where should we start... data QueueOps a = forall q. MkQOps q (a -> q -> q) (q -> Maybe (q,a)). Does the left literally equal the right
10:04:50 <ski> well, this notation is inspired by BNF notation
10:05:12 <ski> perhaps it would have been better if this style of `data' declaration used `::=' in place of `=' ?
10:07:00 <EvanR> the left is a type the right is... sort of a template for a value expression but with types in the argument positions
10:07:19 <ski> yea .. perhaps it's missing some quasiquotations
10:08:14 * ski is reminded of people who define `S + T' to mean `{x + y | x in S /\ y in T}'
10:09:06 <ski> i guess, the main issue with using `GADTs' for everything is that you have to repeat the result type
10:09:18 <EvanR> yeah it's verbose
10:09:48 <ski> hm, in Agda1, you'd write something like `Maybe a = data {Nothing :: _; Just :: a -> _}'
10:10:18 <EvanR> interesting
10:11:55 <ski> (and `Vec a = idata {Nil :: _ Zero; Cons :: (n :: Nat) -> a -> Vec a n -> _ (Succ n)}')
10:13:51 <EvanR> idata?
10:17:48 <ski> indexed
10:22:33 <MarcelineVQ> In term of DRY, repeating type names at the end of constructors isn't really that big a deal, especially when quite often (in agda and with GADTs) you have differing types at the end due to differing indexes
10:22:45 * hackage blake3 0.1.1 - BLAKE3 hashing algorithm  https://hackage.haskell.org/package/blake3-0.1.1 (RenzoCarbonara)
10:23:50 <ski> which is why i mentioned that `_' thing
10:25:50 <dolio> You can still do it in Agda 2.
10:25:51 <ski> hello sushi1234
10:26:00 <dolio> data ℕ₂ : Type₀ where 0F 1F : _
10:26:31 <ski> is it just treated as an omitted part of the type, that it's to figure out on its own ?
10:26:41 <dolio> Yes.
10:26:44 <ski> (i got the feeling that's not how it worked in Agda1)
10:27:45 <MarcelineVQ> iiuc _ means if there exists in scope one unique solution then use it
10:28:34 <dolio> It's not smart enough to figure out Vec, though.
10:28:38 <MarcelineVQ> or to be less verbose "infer the unique value" :>
10:33:00 <dolio> I guess in Agda it's actually part of the syntax or something, because it's the only way to refer to the type being defined.
10:59:16 <danso> is there a nice way for combining an exit status with `interact` ?
11:00:14 <danso> e.g. if the output of interact is "", then exit with ExitSuccess, otherwise exit with ExitFailure
11:00:28 <ski> i guess you could define `(String -> (String,ExitCode)) -> IO a' ?
11:00:41 <ski> or even `(String -> (String,a)) -> IO a'
11:00:57 <ski> hm
11:01:43 <ski> oh, you want to not have any output, in case of successful termination ?
11:02:00 <danso> yes, essentially 
11:02:22 <ski> @src interact
11:02:22 <lambdabot> interact f = do s <- getContents; putStr (f s)
11:02:32 <danso> my program checks that input is valid and should silently exit with 0 if it is
11:02:43 <danso> and exit with non-zero and a message if the input is invalid
11:02:50 <ski> give `f s' a name, check whether it's empty, after the `putStr' ?
11:03:19 <danso> alright, nice thank you :^)
11:03:25 <ski> any particular reason you want to use something like `interact' ?
11:03:32 <danso> because it's so cool
11:03:39 <ski> heh
11:03:53 <danso> and my program only reads input and (maybe) produce output
11:04:03 <danso> it seems like the ideal use-case for interact
11:05:50 <ski> i guess your program is some kind of validator/checker for something
11:06:43 <ski> hm .. perhaps you could alternatively (or in addition ?) use `Validation' ?
11:07:28 <danso> i'm using Maybe right now
11:08:08 <danso> Maybe String ; where Just s indicates a failure and Nothing is no failure
11:08:58 <danso> would there be an advantage to Either/Validation? 
11:09:29 <danso> i can't think of anything meaningful to put in the Right 
11:09:57 <ski> well, if your internals of the validation needs to compute some intermediate values, in addition to checking things
11:11:14 <ski> you could compose `String -> Either Failure T' with `T -> Either Failure ()', getting `String -> Either Failure ()'
11:11:51 <ski> hm, and possibly it could also be useful to put the input `String' in a state, depending on how you want your checking structured
11:12:42 <ski> you might have some portion of the program which validates an initial portion of the `String', and which then is supposed to hand off the remainder to another portion, for some other validation
11:13:45 * hackage shakebook 0.3.0.0 - Shake-based technical documentation generator; HTML & PDF  https://hackage.haskell.org/package/shakebook-0.3.0.0 (locallycompact)
11:13:46 <ski> but possibly your checking is simple enough that the first portion could just call the second one, in such a case
11:14:21 <ski> danso : any thoughts/comments ?
11:17:57 <danso> i can see how keeping a state would be useful, where the state is some substring of the input
11:18:15 <ski> not a suffix, then ?
11:18:15 <danso> my program is intended to check that an input is syntactically valid C 
11:18:32 <ski> hm, so you're parsing
11:18:35 <danso> i *might* possibly add a type-checker later as well 
11:19:02 <danso> but i essentially want faster feedback about whether my C is syntactically valid before sending it on to a proper compiler
11:19:05 <ski> do you intend to have some kind of forgiving / error-correcting parser, in order to be able to report more issues in one go ?
11:19:28 <danso> nope, i intend for it to stop after one error
11:19:49 <ski> oh
11:20:08 <danso> that's actually why i'm doing it this way... there's no compiler i know of that has an option to stop parsing after one syntax error
11:20:27 <danso> syntax errors in code pretty much mess up anything that comes after them, so there's nothing more a compiler can usefully do, imo
11:20:38 <danso> but clang and gcc keep trying anyway
11:20:39 <ski> well, i think usually it's considered a feature to be able to report multiple issues in one go
11:21:02 <danso> it is, especially things like type errors or nonexistent variables
11:21:04 <ski> although, this tends to make more sense for type errors, than for syntax errors, i guess
11:21:11 <danso> but syntax errors leave the parser in an unknown state
11:22:00 <ski> hmm .. i wonder whether monoidal parsing could do something more sensible
11:22:03 <danso> so usually something like a missing semicolon is followed up by more "errors" as the compiler tries to guess where it should be
11:22:35 <ski> yea
11:22:44 <danso> my intention for this is to run it from within my editor every time i save
11:23:02 <danso> so that my editor either shows me nothing (valid C) or a single line showing the first syntax error
11:23:25 <ski> hm, so if you have an unfinished portion, then it won't check later portions
11:23:35 <danso> right
11:24:11 <ski> (even if you're currently working on said later portion)
11:24:31 <danso> mhm :^P 
11:24:56 <danso> but only if i've left the unfinished part syntactically invalid 
11:25:04 <ski> yes
11:25:25 <danso> if i comment out a block or whatever, then it will work fine
11:25:30 <danso> assuming my program is correct!
11:25:36 * ski . o O ( `paredit' )
11:26:06 <danso> is that a thought bubble 
11:26:08 <danso> hahaha
11:26:10 <ski> yes
11:26:11 <danso> genius
11:26:43 <danso> i don't know anything about paredit
11:27:12 <ski> it's a structural editing mode, sortof, for Emacs
11:27:51 <danso> and sublime text, apparently
11:27:56 <ski> makes sure your brackets and balanced, allows you to easily work on the level of whole phrases of the program, rather than on strings of characters
11:28:13 <danso> looks like there's a vim plugin, too
11:29:18 <ski> @hackage trifecta
11:29:19 <lambdabot> http://hackage.haskell.org/package/trifecta
11:29:46 * hackage ghc-lib-parser-ex 8.10.0.9 - Algorithms on GHC parse trees  https://hackage.haskell.org/package/ghc-lib-parser-ex-8.10.0.9 (shayne_fletcher)
11:30:24 <danso> interesting
11:30:36 <danso> i've been using parsec, but only because i'm familiar with it
11:31:01 <ski> iirc, that is meant to be able to cope with partially invalid input
11:31:18 <ski> and also meant to be able to use parallel parsing
11:31:42 <ski> splitting the input into several chunks, start parsing all of them simultaneously, then combine the results
11:32:23 <ski> you'd better ask kmett about it, for a more accurate description, though
11:32:40 <ski> (he's in this channel)
11:32:58 <MarcelineVQ> that edwardk guy gets around
11:37:33 <danso> wow, that sounds interesting. i have no idea how that could work
11:51:47 <Cheery> Elm's Cmd -thingy forms monad like structure although it's not a monad, right?
11:52:01 <Cheery> although they've not structured it as monad
11:52:28 <wavemode> um in what way is it a monad?
11:54:33 <Cheery> so shortly describing it a bit.
11:54:39 <Cheery> init : (Model, Cmd Msg), this creates initial state
11:54:58 <Cheery> update : Msg -> Model -> (Model, Cmd Msg), this is response to an event
11:56:01 <Cheery> make Msg = Model -> (Model, Cmd Msg)
11:56:33 <Cheery> now init would be: (Model, Cmd (Model -> (Model, Cmd Msg))
11:56:53 <Cheery> wavemode: see how it starts to correspond?
11:57:17 <Cheery> the subscriptions is bit "hmm" though.
11:58:00 <Cheery> oh right. it doesn't happen between updates. It's just an SDL-style event loop
11:58:19 <Cheery> there you go
12:08:32 <wavemode> hm that makes sense
12:26:41 <__monty__> Any recommended library to work with timestamps? 20200516T212530Z style timestamps. I want an easy way to get the separate parts, like hours and minutes.
12:29:02 <phadej> `time`
12:29:29 <phadej> parseTimeM True "%Y%m..."
12:30:43 <hpc> https://hackage.haskell.org/package/time-1.10/docs/Data-Time-Format.html
12:30:52 <hpc> ah, beat me to it
12:31:17 <hpc> you can usually get format strings for time formats out of the RFC, to make things easier as well
12:31:41 <hpc> and there are definitions included for iso 8601 and rfc 822
12:40:45 * hackage shakebook 0.3.0.1 - Shake-based technical documentation generator; HTML & PDF  https://hackage.haskell.org/package/shakebook-0.3.0.1 (locallycompact)
12:42:39 <johnw__> Date.Time.Format.ISO8601 is pretty easy to use
12:44:58 <__monty__> Ah great, thought I remembered seeing fairly frequent complaints about time.
12:45:49 <fog> phadej, int-e and merijn were talking before about performant haskell vs C, and unsafe direct memory access and high level safe API's over this
12:46:18 <fog> I have never written performant C code, and all mention of it seems mysterious 
12:46:57 <fog> am i right to understand that this last %10 of performance squeezed out of C is something to do with its ability to do things unsafely? 
12:47:00 <maerwald> You've never optimised the number of allocs in your C program? 
12:47:08 <fog> i never wrote a C program
12:47:12 <maerwald> Ok
12:47:16 <dsal> __monty__: Time is terrible, but it appears to exist so we have to interact with it.
12:47:42 <maerwald> Well, optimising allocations in haskell is a hard effort, because it's implicit and mostly related to laziness 
12:47:53 <fog> I had to read enough C when trying to understand some really massive industrial codes I was supposed to work with though
12:47:56 <wavemode> I've heard convincing arguments that time does not actually exist
12:48:57 <fog> but I didnt manage to glean from it how they were achieving some kind of difficult to achieve performance enhancement  
12:49:02 <__monty__> maerwald: Allocations are also far cheaper in haskell though.
12:49:08 <dsal> I've had to argue with people way too much that time is irrelevant to their concerns.  They always talk about things that sound like "happens before" but try to use things like timestamps to determine which things were related.
12:49:28 <maerwald> __monty__: not sure what that means 
12:50:00 <fog> reducing number of mallocs, well at least that a more tangible idea
12:50:13 <wavemode> data in C is "unboxed" as it were, which means you aren't dereferencing a pointer every time you read something. that's a significant performance boost on its own
12:50:33 <fog> so then, is it right to think that haskell somehow does some superfluous mallocs or something?
12:50:40 <__monty__> maerwald: Haskell programs often do huge amounts of allocation but the design of the GC makes that far less of an issue than in let's say java.
12:50:41 <maerwald> Yes
12:50:50 <fog> ah
12:51:01 <maerwald> __monty__: it is enough of an issue though 
12:51:27 <fog> ok, so that haskell is somehow then always going to be slower, by not reusing memory effeciently?
12:51:49 <maerwald> No, it means you put in more engineering time to fix your memory issues
12:52:24 <maerwald> If you look at how GHC uses memory, you'll see it isn't a trivial problem 
12:52:40 <Athas> You can get pretty significant performance improvements out of Haskell programs just by tweaking the GC flags.
12:52:40 <maerwald> Compilation in haskell can take huge amounts of memory 
12:52:48 <fog> so the high level objectives to reduce this interfacing - putting it all under the hood, which allows haskel to be more legible, is intrinsically expensive?
12:53:15 <Athas> fog: "intrinsically" probably but, but there are serious tradeoffs to be made with no clear answers.
12:53:16 <wavemode> in other words, there's no such thing as a free lunch
12:53:16 <maerwald> Laziness is expensive yes
12:53:47 <fog> but we can resort t MVectors and stuff in such cases
12:54:00 <Athas> fog: yes.
12:54:04 <wavemode> you can resort to inline-c :p
12:54:16 <Athas> Haskell is decently good at letting you write nasty code when you need the performance, and it'll run fast-ish.
12:54:16 <fog> i guess thats how MVector works
12:54:24 <maerwald> Often times, StrictData fixes half of your memory issues though 
12:54:52 <fog> like, Haskell does provide the ability to do everything C does right? but then is there an overhead from using haskell that cannot be worked around?
12:55:02 <maerwald> GC
12:55:24 <Athas> In the limit, probably not.
12:55:26 <dmj`> > sqrt (sqrt (2143 / 22))
12:55:30 <lambdabot>  3.141592652582646
12:55:37 <fog> ah! so you could write C that didnt use any GC, by just writing to the same addresses, essentially doing the GC for you
12:55:38 <Athas> You can essentially write C-in-Haskell by using the IO monad and some low-level operations.
12:55:47 <Athas> But it's going to be even more painful than writing it in C.
12:56:18 <fog> the question is more about the feasability of reducing the overhead of a high level api to 0
12:57:22 <fog> so there are advantages of "tweaking memory addresses" that abstracting away automated memory management either prevents, or at least means a custom interface to each such "trick" would be needed 
12:58:12 <fog> i think maybe I was thinking about something like this when trying to fold over a MVector 
12:58:26 <Athas> I judge it infeasible in general, mostly because no high-level languages have managed to do it.  The compilers may be theoretically possible to write, but nobody has done it.
12:58:33 <wavemode> back in the day, even C was considered "high level". ultimately, the ability to eliminate overhead (vs. just writing everything in asm) depends both on what exactly you're doing and how well the compiler can transform and optimize it
12:58:39 <Athas> Languages that are both high-level and very fast tend to make sacrifices in other areas.
12:58:47 <fog> you would need an MVar for the carry and by overwriting it, you would make some saving possibly 
12:58:55 <maerwald> Athas: rust is that, in a way 
12:58:58 <johnw__> It can be done if you open up the compilation process, rather than having a black-box compiler like GHC
12:59:21 <monochrom> This discussion could have been much more meaningful if you had, not just written in C and benchmarked it, but also studied the asm code generated by C compilers. And generally having taken a "computer organization" course.
12:59:23 <Athas> maerwald: kind of, but I don't think Rust is particularly high level.
12:59:44 <Athas> It's less high level than Standard ML, in the sense that it requires "attention to the irrelevant", and Standard ML is from the 1970s.
12:59:47 <maerwald> Athas: it has ADTs. That's high level imo
12:59:59 <johnw__> Rust isn't terribly high-level
13:00:00 <Athas> Pascal had ADTs.
13:00:07 <maerwald> Yes, also high level
13:00:12 <johnw__> I use both Haskell and Rust at work; we use Rust for the bits where operational behavior is king
13:00:22 <fog> monochrom: well that kind of suggests that the compiler could possibly even shuffle the machine code around to automatically find any exploitable memory reuse tricks
13:00:27 <Athas> Alright, they are high-level, but probably not in the sense that fog was asking about.
13:00:32 <maerwald> Java is low level
13:01:07 <wavemode> eh?
13:01:17 <monochrom> No, Pascal almost had ADTs. Here is what's missing: In Pascal, you manually check tags --- you are still allowed to make mistakes there.  In Haskell, the language check tags for you, you aren't allow to make mistakes.
13:01:17 <Athas> It's not a one-dimensional scale, and it's subjective to boot, but I'd classify Rust as about as high-level as C++.  (Although Rust is a much better language.)
13:01:23 <fog> right, so then the question is about human expertise vs learned automated graph refactoring of machine code
13:01:28 <Cheery> if a language describes what it runs on, it's low level
13:01:39 <fog> and the argument would be that it would never be possible to ensure no corner case exists
13:01:45 <Cheery> there's low level libraries in Haskell, but they're not crucial for writing haskell
13:01:49 <dsal> Cheery: like lisp on a lisp machine?
13:01:50 <johnw__> I count "low level" is being languages where you think more according to how the machine acts, rather than in terms of abstract concepts
13:01:54 <Athas> monochrom: eh, what's the 'A' here?  Normally an ADT in computer science is an Abstract Data Type.
13:01:55 <Cheery> dsal: yup
13:02:01 <Athas> Are we talking algebraic types?
13:02:10 <fog> and that while it is the compiler engineers job to classify common cases, they could never do so exhaustively 
13:02:22 <monochrom> Oh! I thought algebraic. Yeah, Pascal has abstract types alright!
13:02:39 <monochrom> Actually I have forgotten that part.
13:02:53 <maerwald> Low level is when you can't think abstract and have to run after compiler specifities all day and can't express anything meaningful without tons of useless chanting
13:02:55 <maerwald> So, java
13:03:08 <phadej> "everyone says `time` is terrible, but when they write (if) a time handling library themselves, it turns even worse"
13:03:32 <dsal> I can't seem to have a megaparsec grammar that lets me specify things that are line separated, but also have line comments.  The space consumer seems conflicted.
13:03:36 <Athas> fog: it's feasible to write a very high level language, that produces expert-level performance, if you restrict that language to a very specific domain (e.g. flat array processing).
13:03:52 <fog> and that the common pro-haskell argument is that by getting all of the most common patterns down, haskell produces more performant code automatically, but that since there is no way to ensure some specialist access pattern had not been built in, we say C is "faster" at the bleeding edge
13:03:55 <Athas> Because that constraints the problem the compiler has to solve, and makes it possible for mere mortals to actually *implement* the required compiler.
13:04:02 <Cheery> but my definition also means python is low level
13:04:04 <Cheery> and js
13:04:08 <monochrom> Part of time being terrible is because there are several conflicting meanings of "time".  Some want calendar time, some other want physics time.
13:04:09 <Athas> Haskell is way too flexible for a Sufficiently Smart Compiler to be written.
13:04:26 <Cheery> I still think it's right definition though.
13:04:28 <johnw__> Athas: If humans can be part of that smartness, I would disagree
13:04:54 <Athas> Automatic compiler, then.
13:04:59 <__monty__> Hmm, hourglass does look like a nicer API. Guess I'll stick to time until it bothers me though.
13:05:01 <monochrom> hahahah human being part of smartness
13:05:01 <phadej> monochrom: yes, so if you write physics time lib, it will suck as calendar time one.
13:05:08 <johnw__> 100% purely automatic, maybe, we'll see how far AI can take us on that frontier
13:05:28 <fog> well that sounds like a data scraping and classification task, you pour high performance C code in one end, and it learns all the tricks
13:05:30 <phadej> hourglass doesn't have anything about calendars e.g.
13:05:45 <phadej> or does it 
13:06:09 <johnw__> But I've worked on systems that go from straight up math to bit code, without sacrificing performance; but the automation has to be built and customized for each specific application.
13:06:10 <Athas> Sure, I don't think it's theoretically impossible to write a Haskell compiler that generates peak optimal code (except the usual Rice's Theorem cases), but currently it's science fiction.
13:06:23 <Athas> Although I don't think a sci-fi novel about a really good Haskell compiler would sell much.
13:06:36 <monochrom> Fortran compilers are known to have better code optimization than C compilers because pointer aliasing ruins a lot of things.
13:06:52 <Athas> johnw__: yes, things like FFTW and Helix and such, right?  They are basically languages/compilers for extremely specific problems.
13:07:03 <Athas> monochrom: yes, but they still can't parallelise worth shit.
13:07:07 <sheepfleece> I have two threads, they both work with the same socket (one reads, the other one writes), the thing is those two threads can both kill each other, how should I model it? Just throw an async exception?
13:07:14 <monochrom> Whenever I hear a millenial saying "C code is highly optimized" I'm like "you are so naive".
13:07:21 <dsal> sheepfleece: async has link.
13:07:28 <Athas> Expecting a compiler to reverse-engineer *intent* after an algorithm was mangled to fit in a FORTRAN-shaped box is naive.
13:08:02 <fog> i guess without having experience actually writing GHC, or any kind of graph refactoring of a bitcode emulator during compilation, it would be impossible to understad actually how likely a corner case would be to exist at all
13:08:03 <sheepfleece> dsal: Sorry, I don't follow.
13:08:12 <dsal> sheepfleece: Are you using the async library?
13:08:24 <sheepfleece> Right now I don't.
13:08:26 <dsal> It has conveniences such as `withAsync` and `link` that deal with such things.
13:08:32 <dsal> And `concurrently` and all that.
13:08:39 <dsal> Or even `race`
13:08:50 <sheepfleece> I see, I'll try them, thank you!
13:08:57 <dsal> Or `waitAnyCancel`
13:09:06 <dsal> (since in practice, I have several threads per connection)
13:09:20 <johnw__> Athas: I was thinking of MIT's Fiat library, that uses Coq to provably reduce mathematical specifications down to computational algorithms
13:09:59 <fog> maple is pretty good for simplifying equations 
13:11:16 <fog> i dont know aswell about machine precision and if error bounds for approximations could factor in
13:12:05 <fog> eg, do i use tanh in my net, or have a subnet approximating tanh from truncated taylor series etc
13:12:20 <fog> trying to reduce my atomic computations down to the Num interface
13:12:51 <fog> but I know there are like, trigonometric circuits on chips which have machine instructions for trig functions
13:13:29 <fog> but if I could refactor my net , by classifying it and deriving an approximator, some of the tanh precision might get discarded 
13:13:59 <fog> like if it was unnesacarliy precise to begin with and could be compesnated for more effeciently in the rest of the net
13:14:31 <fog> but then i end up with basically having logic opperations on bools for my net, when applying the same argument to (+) and (*)
13:15:48 <fog> and then im refactoring something like machine code anyway... might be a good stage to write a compiler over
13:16:26 <fog> as basically you could crush the machine code down with bounded impact on precision 
13:16:59 <fog> soft circuits!
13:18:44 <fog> and you could mine common diagrams, and do manifold learning to interpolate over this memoisation
13:19:15 <fog> probably ambitious...
13:22:01 <lxsameer> hey folks, I'm new to haskell's syntax. 'newtype State s a = State { runState :: s -> (s, a) }' means create new data type called State which has two type params. which the 's' one has a runState function with that signature. am i right ?
13:22:41 <dsal> runState is a field within the State record.
13:23:08 <dsal> State has only one field, and that's a function from  s to (s, a)
13:23:46 <lxsameer> dsal: ahhhh got it
13:24:11 <lxsameer> dsal: and one more question
13:25:05 <dmj`> lxsameer: the type of runState has 'State s a' as its first argument, it isn't obvious, and a big gotcha for people starting out
13:26:22 <lxsameer> in this expr (State x) >>= f = State $ \s -> let (v,s') = x s in runState (f v) s' , and from the 'let' forward means, destruct the return value of RunState (f v) s' and name the first value v and the second one s' right ?
13:27:09 <dmj`> lxsameer: yes, this goes back to what I just said, `f v` gives you back a type of State s a
13:27:18 <lxsameer> dmj`: i kinda figured that one out since it's a monad, but it is actually hard to read
13:27:26 <ski> no, lxsameer. the result of `x s' is matched on that pair pattern
13:27:36 <wavemode> no, in that expression, `x` is a function and you are destructuring the result of calling `x s`
13:28:07 <lxsameer> ok then what does `in` do ?
13:28:24 <wavemode> > let x = 5 in x + 10
13:28:25 <Cale> This is written in a needlessly hard to read way
13:28:26 <berndl> It's part of the let syntax
13:28:26 <ski> determines the scope of the locally bound variables
13:28:26 <lambdabot>  15
13:28:29 <dmj`> lxsameer: the fast the first arguments is State s a in runState is not specific to monads, but true of all haskell types defined in this way
13:28:33 <dmj`> the fact*
13:28:34 <Cale> It's easier to read if you write it like this:
13:28:36 <johnw__> let BINDINGS in EXPR
13:28:46 <ski> Cale : yea, it ought to be written with message-dispatching ..
13:29:16 <Cale> x >>= f = State $ \s -> let (v,s') = runState x s; (w,s'') = runState (f v) s' in (w,s'')
13:29:27 <lxsameer> johnw__: now it makes sense
13:30:01 <lxsameer> it's like (let ((v s') (x s) (runState (f v) s')) in a lisp
13:30:10 <ski> yes
13:30:12 <Cale> So then it's clear what's intended. When x >>= f is run on some initial state s, we first run x on the initial state s, getting some result v and new state s'
13:30:17 <ski> (missing a bracket)
13:30:49 <Cale> and then we run (f v) on the new state s', to get some final result w and final state s'', which are the result and final state of the combined computation
13:30:51 <ski> (hm, guess you'd need `let-values' or something)
13:31:09 <Cale> Does that make sense?
13:31:36 <Cale> Pattern matching the function out is equivalent, but less easy to read
13:31:49 <Cale> (in this case, anyway)
13:32:06 <lxsameer> Cale: yeah, but because i know about state monad, but the syntax in confusing, runState (f v) s' is like runState(f(v), s') right ?
13:32:26 <Cale> Yeah, though without the construction of a tuple
13:32:45 * hackage tz 0.1.3.4 - Efficient time zone handling  https://hackage.haskell.org/package/tz-0.1.3.4 (MihalyBarasz)
13:32:58 <ski> lxsameer : do you find `(runState (f v) s')' confusing ?
13:33:28 <Cale> In Haskell, rather than having functions of multiple arguments, we have only functions of a single argument, and when we want more, we just have them produce other functions
13:33:34 <lxsameer> ski: no, it's easy in lisp :)) but the question is 
13:33:47 <Cale> and so when you write f x y z it means ((f x) y) z
13:33:55 <lxsameer> runState signature is s -> (a, s)
13:34:02 <dmj`> lxsameer: NO
13:34:06 <Cale> and when you see the type A -> B -> C -> D, it really means A -> (B -> (C -> D))
13:34:08 <dmj`> lxsameer: scroll up to my messages
13:34:09 <lxsameer> but we passed two params to it
13:34:13 <ski> that's an unfortunate confusing part of Haskell
13:34:18 <monochrom> No, it's longer.  State s a -> s -> (a, s)
13:34:21 <dmj`> lxsameer: I specifically said this is what trips up new people
13:34:40 <lxsameer> dmj`: yeah :)) it tripped me as well then
13:34:43 <dmj`> lxsameer: and you said "It's a monad I got it", but the fact its a monad is irrelevant :P 
13:34:48 <Cale> lxsameer: The definition gives the type of the field, but that's not the same as the type of the function which is automatically generated for extracting that field
13:34:58 <Cale> Like, if we'd written
13:35:03 <dmj`> lxsameer: its just a detail of the type system when declaring records
13:35:14 <Cale> data Point = MkPoint { x :: Double, y :: Double }
13:35:19 <Cale> you'd automatically get functions
13:35:24 <Cale> x :: Point -> Double
13:35:28 <Cale> y :: Point -> Double
13:35:31 <ski> dmj` : SML and OCaml got this right
13:35:43 <johnw__> Cale: and MkPoint :: Double -> Double -> Point
13:35:48 <Cale> Indeed
13:36:00 <dmj`> it's always the "runState (f v) s' " that trips people 
13:36:16 <dmj`> this is why people always do flip runState
13:36:24 <ski> i don't
13:36:56 <ski>   act `runState` s
13:36:59 <monochrom> I never
13:37:05 <johnw__> you have to know that runState is just unwrapped the newtype to expose the function underneath, which takes a state; otherwise, I agree it's just confusing. I'd have preferred it if `unState` meant what runState now does, and runState had been provided flipped.
13:37:08 <ski>   (`runState` s) . runExceptT
13:37:23 <lxsameer> ok i think i'm getting there
13:37:36 <dmj`> people do flip runState because then you can hang a do block on the end of it
13:37:47 <dmj`> flip runState s $ do { .. }
13:37:53 <johnw__> yep
13:37:55 <ski>   (`runState` s) . runExceptT $ do ..
13:37:56 <dmj`> it's just more convenient
13:37:56 <berndl> I do that with folds too
13:37:57 <lxsameer> in newtype State s a = State { runState :: (s -> (a,s)) } , the paranthesis around s-> (a, s) is redundat right?
13:38:07 <ski> yes, lxsameer
13:38:07 <berndl> flip foldl' [] $ ...
13:38:08 <lxsameer> or does it have a specific meaning ?
13:38:19 <Cale> It's entirely redundant
13:38:21 <johnw__> dmg: I also do this often: (\f -> foldl' f X Y) $ \acc x -> ...
13:38:41 <Cale> lxsameer: It might help just to define runState separately
13:38:57 <fog> % type State s a = StateT s Identity a
13:38:57 <yahb> fog: 
13:39:11 <fog> % :t (\(StateT x) f -> x >>= f  . runIdentity) :: State s a -> ((a, s) -> s -> b) -> s -> b
13:39:11 <yahb> fog: State s a -> ((a, s) -> s -> b) -> s -> b
13:39:19 <Cale> newtype State s a = State (s -> (a,s))  -- now the parens aren't redundant any longer ;)
13:39:23 <lxsameer> coll and according to Cale, compiler creates  runState :: State -> s -> (a,s) as well right?
13:39:32 <Cale> and then define the runState function manually:
13:39:41 <Cale> runState :: State s a -> s -> (a,s)
13:39:46 <Cale> runState (State f) = f
13:39:58 <lxsameer> Cale: ah yeah, forgot the type params
13:40:00 * ski sighs
13:40:48 <berndl> It seems that newtype wrappers around function types always have runXXX destructors.
13:41:01 <lxsameer> Cale: State (s -> (a,s)) could you describe this please ?
13:41:05 <ski> @src Endo
13:41:05 <lambdabot> newtype Endo a = Endo { appEndo :: a -> a }
13:41:41 <Cale> lxsameer: In the newtype definition, that specifies that there will be a data constructor called State (same as the type, but it lives in a different namespace)
13:41:47 <berndl> I wonder why those chose appEndo instead of runEndo.
13:41:51 <Cale> and that it will have one argument whose type is (s -> (a,s))
13:41:54 <ski> sometimes i call the destructor `unXXX'
13:42:10 <berndl> I also don't understand why they chose runIdentity and runWriter - they don't wrap functins.
13:42:14 <monochrom> I never liked the "run" prefix.
13:42:37 <ski> why would "run" be associated with functions ?
13:42:37 <wavemode> it's misleading like "return" is misleading :p
13:42:40 <monochrom> And never liked aliasing type name with data constructor name either.
13:42:51 <lxsameer> Cale: ahhh, i see. Haskell's syntax is super confusing for me :))
13:42:55 <monochrom> I mean sure on my lazy days it saves typing.
13:42:56 <ski> amen to that, monochrom
13:43:10 <lxsameer> thanks folks, thanks for helping 
13:43:24 <Cale> lxsameer: The syntax of data types is meant to look a bit like BNF grammars if you've ever seen those
13:43:36 <Cale> But if not, probably GADT syntax is easier:
13:43:44 <Cale> newtype State s a where
13:43:49 <monochrom> I have promoted "data X = XOf { deX :: ... }" but no one cared.  Fortunately, they cared enough to "data X = MkX { unX :: ... }"
13:43:50 <Cale>   State :: (s -> (s,a)) -> State s a
13:44:05 <Cale> i.e. just give the type signature for the data constructors
13:44:16 <Cale> This is available in a language extension
13:44:22 <berndl> monochrom: Isn't the MkXXX convention from Idris?
13:44:26 <monochrom> But really, XOf makes better English sense, and deX makes better French sense.
13:44:28 <ski> no, berndl
13:44:34 <monochrom> I don't know.
13:44:39 <ski> pretty sure i've used it, before Idris existed
13:44:42 <lxsameer> Cale: cool, much easier to understand
13:45:13 <monochrom> <-- above average programmers in natural language diction.
13:45:32 <monochrom> not a very high bar at all, mind you :)
13:46:07 <monochrom> Like if you didn't flunk your highschool natural language classes you're already above average programmers.
13:46:10 * ski imagines a recurring bar
13:48:04 <monochrom> Hrm did I kill the conversation?
13:48:30 <berndl> I've noticed that in Purescript they use unwrap from Newtype instead of declaring explicit destructors.
13:48:40 <monochrom> "everyone is now intimidated by monochrom's elitist stance" :)
13:49:00 <fog> ski: were you taling about constraint continuations before? with this *> opperator for "exists" contexts...
13:49:22 <fog> i guess we can implement something like *> with reification right?
13:49:24 <monochrom> What does it look like in Purescript?
13:49:30 <ski> fog : i wouldn't call it "constraint continuations" .. i'm not sure what you mean by that term
13:49:58 <fog> (((C => a) -> a) -> a)
13:50:35 <ski> fog : `data cxt *> a = cxt => Provide a' approximates it
13:50:42 <fog> wait is that one too many nestings of  -> a?
13:50:46 <ski> yes
13:51:28 <fog> ok, so ((C => a) -> a)  says you can get an `a' from a (C => a) if you can reify the constraint implementation
13:52:53 <fog> there was a reifiable constraint post by thought police, ill find it...
13:53:01 <ski> `forall o. (C => o) -> o' is equivalent to `Dict C'. `forall o. (C => a -> o) -> o' is equivalent to `C *> a'
13:53:45 * hackage haskell-ci 0.10.1 - Cabal package script generator for Travis-CI  https://hackage.haskell.org/package/haskell-ci-0.10.1 (phadej)
13:53:54 <fog> https://www.schoolofhaskell.com/user/thoughtpolice/using-reflection
13:55:09 <fog> so you would say continuations can be used to encode exists, and then, is it right to say that "constraint continuations" are whats used to encode (*>)
13:56:10 <sheepfleece> When people use RIO Monad, do they usually have one big environment with type classes to deconstruct it? I now have a Reader with 15 fields or so, and it becomes more and more unmanageable. 
13:56:18 <fog> wait, why are you using continuation to hide the stored value `a' as well as the proof of the constraint?
13:56:39 <fog> wouldnt it be; `forall o. (C => a) -> a' is equivalent to `C *> a'
13:57:02 <ski> ´no
13:57:22 <fog> you *have* to have a continuation storing the value?
13:57:27 <monochrom> sheepfleece: I think they use lens to access individual fields, when there are a million fields and counting.
13:57:31 <ski> i don't understand the question
13:57:47 <maerwald> they use makeClassy etc
13:57:54 <maerwald> I don't like it
13:58:09 <ski> fog : anyway, you can also use an "existential data type"
13:58:16 <fog> why do you not just have to be able to prove the constraint holds in the continuation, not also that the continuation also holds the value which demands this constraint holds
13:58:20 <berndl> sheepfleece: RIO is meant to be used when you need ReaderT, EitherT and IO.
13:58:27 <maerwald> https://hackage.haskell.org/package/lens-4.19.2/docs/Control-Lens-Combinators.html#v:makeClassy
13:59:20 <maerwald> berndl: EitherT?
13:59:32 <maerwald> snoyman is against EitherT with IO
13:59:41 <maerwald> he promotes MonadThrow instead
14:00:25 <maerwald> Which is a terrible choice, because now you don't see the error types anymore
14:00:29 <fog>  (C => a -> o) -> o seems more like it needs the constraint to get the `o' from `a', aswell as holding an `a'.  
14:00:58 <maerwald> And you have to know that MondThrow + IO promotes to exceptions
14:01:10 <sheepfleece> Can I use generic-lens for this? I've never used any optics libraries, and I'm not sure which one should I choose for this.
14:01:10 <fog> (C => a) -> a, seems like it does not hold a stored value, and the only thing that requires the constraint holds is to get `a'
14:01:15 <maerwald> so in RIO, everything is an exception
14:01:26 <ski> fog : `C *> a' is equivalent to `forall o. ((C *> a) -> o) -> o' is equivalent to `forall o. (C => a -> o) -> o'
14:02:50 <fog> so in the constraint, you can swap *> for => ?
14:03:12 <ski> no
14:03:26 <ski> fog : `(exists a. ..a..) -> ...' is equivalent to `forall a. (..a.. -> ...)'
14:04:02 <ski> fog : `(Cxt *> ...) -> ...' is equivalent to `Cxt => (... -> ...)'
14:04:20 <ski> fog : `(...,...) -> ...' is equivalent to `... -> (... -> ...)'
14:04:25 <ski> (the last one is currying)
14:04:41 <ski> (the other two are "sortof currying", too)
14:12:39 <fog> so *> has nothing to do with ((C => a) -> a) ?
14:13:47 <ski> i'm not sure if you really mean `(C => a) -> a', or `forall a. (C => a) -> a' perhaps
14:14:06 <fog> heres the code from that thoughtpolice post; https://gist.github.com/dataN-hs/9c7e6106b2bbb992c1a2de25b2bdd930
14:14:06 <ski> the latter is equivalent to `C *> ()', which is `Dict C'
14:15:18 <fog> here is some ridiculous elaboration on that; https://gist.github.com/dataN-hs/e0a154cd485d34d8a1c0c35dc49bebd2
14:15:36 <fog> ski: im trying to find code where I made use of this "reificable constraints" thing
14:15:50 <fog> hopefully for a synonym defining which of those I mean
14:16:36 <ski> i wasn't talking about reification, fwiw
14:16:48 <fog> I think it was all done on lpaste which went down
14:17:07 <fog> ski: reification is nesacary for defining the "local instance"
14:17:29 <fog> ie, it would return a "constraint continuation", an environment in which the constraint holds
14:17:51 <fog> otherwise you can only do the instance at top level, and there is no notion of a restricted scope in which a constraint holds
14:21:19 <fog> recode :: forall p f i x proxy. (p f,Defined2 p,Newclass2 f p f) => proxy p -> (forall a. i -> f a -> f a) -> i -> (p f => x) -> x
14:22:12 <fog> there is a lot of code to make that work, and i have no idea what it does
14:22:50 <ski> i thought you meant you wrote the code in the second paste
14:23:12 <fog> yeah, i wrote all the code, doesnt mean i still no how to read it...
14:23:16 <fog> :: forall proxy p q. proxy p -> proxy q -> (forall a.    (p=>a)->a) -> (forall b. p=>(q=>b)->b) -> (forall c.    (q=>c)->c)
14:23:40 <fog> or what it does...
14:24:24 <fog> but yeah, im seeing a bunch of types now making reference to this (forall a.    (p=>a)->a)  shape
14:24:46 <ski> `forall a. (p=>a)->a' is clearly `Dict p'
14:25:23 <ski> hm, so that looks like a modus ponens rule
14:25:31 <fog> !?
14:25:36 <fog> awesome...
14:25:42 <ski> if `p' and `p => q', then `q'
14:26:11 <fog> sounds about right, i was trying to compose these things together
14:26:22 <fog> huh, i didnt know they were just Dicts...
14:27:48 <ski> you could say `forall proxy p q. proxy p -> proxy q -> Dict p -> (p :- q) -> Dict q'
14:29:17 <fog> its supposed to be, you have an environment that proves p is implemented, and a context that if p is implemented, proves q is implemented, then you have an environment that proves q is implemented
14:29:30 <ski> yes
14:29:44 <fog> so p "entails" q 
14:30:24 <fog> i think it was something to do with trying to reify superclasses
14:31:22 <ski> even thought of throwing in a stray comment that would help explain to yourself what the aim of the code is supposed to be ?
14:31:23 <fog> kind of disheartening to have evidently spent so long on something that I cant remember how it works or what it was for and can hardely read
14:31:58 <fog> some vague recollection that it was something to do with Traversable
14:32:44 <fog> i think because I couldnt override the Prelude implementation, and I wanted to add some superclasses or something
14:33:05 <fog> i just work with Convertable now...
14:33:13 <fog> a much easier workaround!
14:35:17 <fog> aha! a simpler example https://gist.github.com/fog-hs/c5ce3555142cac6e1d3b7e7c63c47e8e
14:36:23 <fog> seems to shortcut a bunch of the overhead by calling unsafeCoerce directly
14:36:53 <isene> New to Haskell. Programmed in 30+ other languages, but Haskell is very different. I have a program where I roll an "open ended dice". If a 6 is rolled, I roll again adding 1 every time 4 or more is rolled, stopping the sequence if 3 or less is rolled. If two consecutive 6s are rolled it is a "critical roll" and and I set "C=1". Usually I would set a variable "t=True" if one 6 is rolled and clear it if not.
14:36:56 <isene> If a 6 is rolled while "t=True", I set "C=1" marking the roll sequence as critical. Since variables in Haskell are immutable, the variable "t" cannot be changed. How do I keep track of possible consecutive 6s?
14:37:27 <merijn> isene: make the number of sixes so far an argument to the function and recurse?
14:37:36 <fog> here is convert; https://gist.github.com/fen-hs/9772c2ce27a355984add2e5b7d352fbb#file-fifo-hs-L147
14:37:59 <merijn> isene: In general any state updated during a loop is just "an extra function argument for a recursive call"
14:39:52 <fog> cant you just make a list of these and mapAccumL over them?
14:40:12 <fog> maybe there is a sequence like version of that...
14:41:39 <ski> isene : tail-calling a function is "goto-with-arguments to a label" (you can compare with `phi' nodes in SSA, if you want to)
14:42:09 <merijn> ski: I'm not sure referencing SSA is gonna help most people new to thinking recursively :p
14:42:30 * ski smiles
14:42:33 <merijn> Unless they've, like, implemented a compiler, in which case they've probably already done a bunch of functional thinking :p
14:43:21 <ski> it seems they're just writing an iterative loop, though, rather than doing a non-iterative recursion
14:44:42 <ski> isene : so .. the output of this would be (a) the sum of the first die with a bunch of `1's; and (b) the final value of `C' ?
14:45:55 <ski> isene : do you have some Haskell code that you're trying to make it do this task ? or perhaps you have some pseudo-code (in imperative style, say), for doing this ?
14:51:45 * hackage servant-wasm 0.1.0.0 - Servant support for delivering WebAssembly  https://hackage.haskell.org/package/servant-wasm-0.1.0.0 (DavidJohnson)
14:54:39 <isene> ski: I have three versions of this (Ruby, Nim and Fortran) here: http://dpaste.com/0NGD2QK
14:55:04 <isene> Explanation of what I want to accomplish: http://167.172.39.127/index.php/The_Character#Open_Ended_Rolls
14:55:44 <steven_> doing a problem on codewars, can anyone give a hint how we can have an isomorphism from Either [()] () to Either [()] Void? The first one has one more possible value than the second so don't we run out of values to use?
14:56:40 <steven_> i.e. define type ISO a b = (a -> b, b -> a), where the two functions are inverses of each other, then I need to write a definition for isoEU :: ISO (Either [()] ()) (Either [()] Void)
14:57:12 <isene> ski: Note that the Ruby example does not track criticals (two consecutive 6s) or fumbles (two consecutive 1s), but the Nim and Fortran versions do
14:57:42 <ski> steven_ : `[()]' is iso to `Maybe [()]'
14:58:53 <fog> you would just end up with a longer list of () in the version with Void right?
14:59:07 <steven_> hmmm maybe `to Nothing = [()..]`? Is that the right idea?
14:59:11 <steven_> ski: 
14:59:17 <isene> I have a hunch that implementing "Open ended dice rolls" in Haskell will be simpler than both Ruby, Nim and especially Fortran (!) - but it's a mind-bender without any footing in Haskell...
14:59:20 <ski> > [() ..]
14:59:22 <lambdabot>  [()]
14:59:31 <steven_> oh whoops meant infinite list
14:59:46 <fog> isene: can you describe what you mean by "open ended dice rolls" ?
14:59:48 <ski> steven_ : i'm assuming `[()]' means finite list
15:00:21 <steven_> I guess I need to think about it more then
15:00:37 <veverak> hmm
15:00:40 <fog> oh, i see your explanation above
15:00:49 <veverak> I need to use Reader/writer monad pattern
15:01:05 <dsal> I don't quite understand the explanation of "open ended dice rolls".  Does this terminate?
15:01:10 <veverak> but, there is one monad that is natively both of them at once
15:01:11 * dsal is slightly distracted by "one dice"
15:01:12 <veverak> which is it?
15:01:16 <veverak> (forgot the name)
15:01:48 <fog> % :t randomRs
15:01:48 <yahb> fog: (Random a, RandomGen g) => (a, a) -> g -> [a]
15:02:43 <dsal> Yeah, I'd start with an infinite list of die rolls, I just don't understand what "the answer" is supposed to be.  It looks like you'd have an infinite score.
15:03:25 <ski> isene : mhm, ok
15:03:32 <ski> isene : do you have any Haskell attempt ?
15:04:34 <fog> % :t \i -> randomRs (1,6) (mkStdGen i)
15:04:34 <yahb> fog: (Random a, Num a) => Int -> [a]
15:04:44 <ski> (and .. argh .. why compare with false and true ? ..)
15:04:50 <steven_> ski: ok I think I got it, in the iso between [()] and Maybe [()], we can map Nothing to [] and Just xs to ():xs
15:04:58 <isene> ski: No, not yet. I am attempting to learn Haskell by attacking this - as this is how I usually start learning a language (like I did with Fortran last summer). I am two days into Haskell...
15:05:02 <ski> steven_ : yep
15:05:03 <fog> % (\i -> randomRs (1,6) (mkStdGen i)) 0
15:05:08 <yahb> fog: [6,6,4,1,5,2,4,2,2,1,6,5,1,5,3,2,3,4,4,1,5,1,1,6,5,6,3,4,6,5,6,3,6,3,5,5,3,5,6,2,4,5,3,2,2,4,2,2,6,3,4,4,1,1,1,2,2,3,2,4,5,3,5,3,4,4,6,3,2,6,6,4,4,1,2,3,5,6,4,5,6,2,6,3,2,2,3,1,6,6,3,3,2,4,4,5,1,2,3,2,5,3,3,6,3,2,3,2,2,6,5,5,4,6,2,4,6,2,2,3,3,2,4,3,1,2,5,4,1,2,6,4,4,4,5,4,1,3,3,4,2,6,2,5,1,3,6,3,6,3,6,1,4,1,4,3,2,5,3,4,4,4,1,6,4,4,6,2,3,5,4,1,5,3,1,1,1,4,3,4,3,3,3,4,6,2,4,5,1,3,2,3,3,5,3,4,4,2,2,5
15:05:11 <ski> steven_ : note that `[()]' is basically `Nat'
15:05:52 <fog> :t mapAccumR
15:05:53 <lambdabot> Traversable t => (a -> b -> (a, c)) -> a -> t b -> (a, t c)
15:05:54 <steven_> ski: yes, I was stuck on one set having 'more' values but it's not true, Nat has the same cardinality as Nat | ()
15:05:55 <ski> isene : well, it could perhaps help to start with deciding on the interface of the main operation
15:06:27 <ski> steven_ : yea, an infinite set can have as many elements as a proper subset of it
15:06:29 <fog> hmm, actually just a fold would be easier 
15:06:45 <isene> I am looking at a simple cli call "O6" with an output in the terminal like "8 critical"
15:06:46 <ski> fog : that's too advanced for them, atm
15:07:12 <fog> % :t \i f a-> foldr f a $ randomRs (1,6) (mkStdGen i)
15:07:13 <yahb> fog: (Random a, Num a) => Int -> (a -> b -> b) -> b -> b
15:07:22 <ski> isene : ok, you could compile an executable that does that, too, if you want to
15:07:50 <fog> % :t \i f a n -> foldr f a $ take n $ randomRs (1,6) (mkStdGen i)
15:07:50 <ski> isene : however, for testing, i'd still suggest writing just a function that you can test in the interactor
15:07:50 <yahb> fog: (Random a, Num a) => Int -> (a -> b -> b) -> b -> Int -> b
15:08:18 <ski> isene : then you can define `main' to call that, and output the appropriate stuff on standard output
15:08:35 <fog> %  (\i f a n -> foldr f a $ take n $ randomRs (1,6) (mkStdGen i)) 0 (+) 0 10
15:08:35 <yahb> fog: 33
15:08:40 <fog> %  (\i f a n -> foldr f a $ take n $ randomRs (1,6) (mkStdGen i)) 1 (+) 0 10
15:08:41 <yahb> fog: 41
15:09:03 <fog> %  (\i f a n -> foldr f a $ take n $ randomRs (1,6) (mkStdGen i)) 1 (*) 1 10
15:09:03 <yahb> fog: 540000
15:09:40 <ski> isene : one complication, apart from how to deal with the update of the looping variables, is how to handle randomness
15:13:21 <isene> yes?
15:14:10 <ski> i'd say the most direct way to handle that is to just pass a PRNG state to your function, that can be used to generate random values
15:14:27 <ski> e.g. pass a value of type `StdGen'
15:15:04 <ski>   randomR :: (Int,Int) -> StdGen -> (Int,StdGen)
15:15:48 <ski> can be used to roll your d6, with a call `randomR (1,6) g0', giving back a result (d,g1)'
15:16:11 <ski> `g0' is the PRNG state before this random generation, `g1' is the state after
15:17:06 <ski> an alternative would be to use `randomRIO :: (Int,Int) -> IO Int', which hides the PRNG state for you .. but i think this would teach you less about how Haskell works (would be more similar to how you'd do it in other languages)
15:17:32 <ski> (`d' is the integer between one and six, of course)
15:17:42 <ski> isene : making any sense ?
15:18:06 <isene> I'm tracking you so far
15:18:36 <ski> so, you could define a funciton `o6', that takes an `StdGen' as input
15:19:16 <ski> as output, you want the accumulated result of the die throws, which is an `Int'
15:19:21 <ski> and also a "mark"
15:19:47 <ski> you could have your mark just be a `String'. or you could invent a new data type (an "enum", in C terms), for it, if you prefer
15:20:14 <isene> Right - but should I define a simple d6 first and use that in the o6 function (something like d6 = (randomRIO (1, 6) :: IO Int) ?
15:20:40 <ski> you might also want to return back the final `StdGen' state after your random generation. that would make the program more composable, so that you could easily call `o6' two times in a row
15:21:00 <ski> you can define a basic `d6' if you want to
15:21:56 <ski> however, as i suggested, i think it'd be nicer (FSVO "nicer") to not let it have `IO' in its interface/type signature/"prototype"
15:22:44 <ski> (if `d6' involves `IO', then anything invoking it would also have to involve `IO' ..)
15:23:36 <isene> OK, but how to track if two consecutive 6s are rolled? What I'm struggling with is that the variables are immutable...
15:24:12 <ski> <merijn> isene: make the number of sixes so far an argument to the function and recurse?
15:24:15 <ski> <merijn> isene: In general any state updated during a loop is just "an extra function argument for a recursive call"
15:24:40 <ski> define a "helper" function that `o6' calls, that maintains the local state it needs, as extra parameters
15:25:00 <isene> hmmm....
15:25:09 <ski> usually, such a "worker" would be defined locally to its "wrapper", so that it's "private", can't be accessed from outside
15:26:12 <ski> as i said, you can, if you want to, think of this local function as a "local label", that you're jumping to (in your loop), with updated values of the local "state variables" (being parameters of the helper function)
15:26:30 <ski> would you like to see an example of how this could be done ?
15:26:38 <ski> (for another problem, obviously)
15:34:24 * ski looks in isene's general direction
15:36:31 <isene> ski: sorry for the afk, yes please to an example
15:37:40 <ski> well, consider a function that, given `n', computes `1^2 + 2^2 + 3^2 + 4^2 + ... + (n-1)^2 + n^2', okay ?
15:38:41 <ski> `n' is assumed to be a non-negative integer (precondition)
15:38:53 <ski> consider the C code
15:39:01 <ski>   int sum_squares(int n)
15:39:03 <ski>     {
15:39:09 <ski>     int i,sum;
15:39:26 <ski>     for (i = 1,sum = 0; i++; i <= n)
15:39:34 <ski>       sum += i*i;
15:39:39 <ski>     return sum;
15:39:41 <ski>     }
15:40:13 <ski> now, consider the corresponding Haskell code :
15:40:27 <ski>   sumSquares :: Int -> Int
15:40:48 <ski>   sumSquares n = loop 1 0
15:40:50 <ski>     where
15:40:57 <ski>     loop :: Int -> Int -> Int
15:41:07 <ski>     loop i sum
15:41:40 <ski>       | i <= n    = loop (i + 1) (sum + i*i)
15:41:49 <ski>       | otherwise = sum
15:42:01 <ski> that's a fairly direct translation
15:42:12 <maerwald> pastebins not popular these days?
15:42:53 <ski> (in fact, this Haskell code can be considered to be a little bit more low-level, than the corresponding C above)
15:44:02 <ski> isene : parameters `i' and `sum' of the local helper/worker function named `loop' keep track of the current iteration index, and the current sum-so-far. initialization of these happens in the initial call, `loop 1 0'
15:45:18 <ski> isene : in the case the loop goes on, we (tail-)call the `loop' function from itself, with new values for the parameters, in place of the only, so incrementing `i' and adding to `sum'. in the termination case, we just "return" the current (final) value of `sum' as result
15:46:13 <ski> btw, another way to implement `sumSquares' would be to define
15:46:27 <ski>   sumSquares n = sum [i^2 | i <- [1 .. n]]
15:46:33 <ski> (using the library function `sum')
15:46:56 <ski> isene : making any sense ?
15:49:37 <eigenlicht> ski, isene : try to do "dynamic programming" in haskell and see were that brings you
15:50:08 <ski> eigenlicht : defining an array recursively in terms of itself can be a pleasant experience :)
15:50:35 <ski> (immutable array, i probably should clarify)
15:51:02 <isene> ski: OK, got that. But is there a really simple way to make almost a one-liner in Haskell to iterate the o6 function?
15:51:16 * Lycurgus was multiply triggered, first to say huzzar! for ignoring the small minded snipe about a snippet
15:51:39 <ski> that sounds a bit poetic, Lycurgus
15:52:19 <ski> isene : well, i'd start with getting a working (correct) implementation, and then perhaps try to refactor it, or think of alternative ways to do it
15:53:16 <ski> isene : i suppose one way might be to generate an infinite sequence of die throws, then write a function that "interprets" that, by munching off some initial number of die results
15:53:29 <eigenlicht> NA -> SML, EU -> OCaml, Brexit -> Haskell :)
15:53:41 * Lycurgus and secondly for the shibboleth "dynamic programming", the application based on the calc of variations due to bellman and the equivocation on static vs dynamic typing by the ignorant many
15:55:11 * ski . o O ( "Why “dynamic programming”?" in 2010-04-23 at <http://arcanesentiment.blogspot.com/2010/04/why-dynamic-programming.html> )
15:55:14 <Lycurgus> or the gladstone (iirc) quote, the hobgoblin of small minds is foolish consistency, which would have robbed the channel of highly relevant text
15:55:34 <isene> ski: OK, you got me moving hers. Thanks for that. I will move further tomorrow. This is what I was looking for.
15:56:10 * ski idly wonders whether "isene" is a reference to breer
15:56:47 <isene> ski: Isene is my last name :-) As in "Geir Isene" (see isene.org)
15:56:56 <ski> ah
15:57:02 <ski> norsk ?
15:57:06 <isene> Yup
15:57:23 <isene> You?
15:57:37 <ski> there's a #haskell.no and a #haskell.scandinavian
15:57:47 <isene> oh
15:57:48 <ski> svensk
15:57:53 <isene> ah
15:58:12 <ski> those channels (as well as #haskell.se) aren't that active, but it might be nice to know about
15:58:44 <isene> 5 others in #haskell.no :-)
15:59:08 * ski skulle vilja gå på tur i Sarek eller Jostedal igen ..
15:59:21 <isene> Etter Korona...
15:59:33 <ski> mm
16:03:06 * ski . o O ( Jogeir Liljedahl )
16:03:44 <solonarv> steven_: both have the same number of values, in fact (countable infinity)
16:04:55 <steven_> solonarv: yep, that's what I realized after
16:06:57 <solonarv> yeah I was scrolled up
16:10:05 <nil> aren't all "infinite" haskell types isomorphic anyway
16:10:45 <nil> data types, that is
16:11:45 <nil> just enumerate all binary strings and skip those that aren't valid representations for the type
16:12:47 <ski> how do you generate binary strings from `Integer -> Integer' ?
16:12:49 <solonarv> (Nat -> Bool) is uncountable if you include uncomputable functions in it
16:13:13 <ski> (i'd say "nonalgorithmic", rather than "uncomputable")
16:14:40 <nil> ski: no, the other way around: enumerate all binary strings (ε, 0, 1, 00, 01, ...) and look at the value they represent
16:14:54 <nil> but i have no idea whether functions actually have a fixed binary representation so i added "data types"
16:18:24 <nil> ski: what distinction do you make between (un)computable and (un)algorithmic?
16:18:33 <ski> hm, so sounds like you're thinking of the algorithmic values
16:18:53 <ski> well, consider a value of type `Stream Bool'
16:19:03 <nil> yes, i guess i mean practical real-world-computers haskell
16:19:23 <nil> ah, laziness enters the picture
16:19:46 <ski> it's (total and) computable iff youäll eventually reach each `Bool' in the stream
16:20:02 <ski> s/youäll/you'll/
16:20:29 <ski> it's algorithmic iff you can encode the stream by a finite program that generates it
16:20:45 <ski> algorithmic clearly implies computable
16:21:22 <ski> however, normally, to work with such values, you don't require knowing they're algorithmic, just that they're computable
16:21:30 <nil> hm, not sure i can think of an example of computable and unalgorithmic
16:21:43 <ski> that `Stream Bool' might come from a physical process, which you don't have reason to assume is algorithmic
16:22:00 <nil> ah
16:22:12 <monochrom> Then it's physical.
16:22:18 <ski> you may think of temperature measurements, stock markets, radioactive decay, &c.
16:23:18 <nil> but then why would you assume you'll eventually see each value? the physical process might stop (and will, eventually)
16:23:23 <ski> e.g., if you have two real numbers represented as infinite sequences of approximations (aka Cauchy sequences), you don't need to know they're algorithmic, to be able to do arithmetic with them. you just need to assume they're computable
16:23:30 <EvanR> physical processes eventually stop? interesting
16:23:42 <EvanR> when God stops paying the bills
16:24:18 <ski> yea, a more fine-grained analysis would tell you how much of the input you need to see, to be able to determine a certain amount of the output
16:24:31 <ski> (this is basically "epsilon-delta")
16:25:18 <ski> but it's a useful simplifying assumption, to assume that you'll eventually see each part of the input that you decide to explore
16:25:42 <EvanR> so algorithmic means you're producing the elements using a program. Computable means the defined sequence could possibly be generated with a program, as opposed to many sequences based on uncomputable problems
16:25:48 <freeman42x[m]1> I would like to play the AI writing game https://screeps.com/ using Haskell. To do that it would be idea if there was a way to generate a Haskell API from the JS API they provide. Is such a thing currently possible?
16:26:03 <ski> another word for "algorithmic" is "lawlike" (used by Brouwer)
16:26:14 <ski> @where topology
16:26:15 <lambdabot> "topology in Haskell" <http://www.haskell.org/pipermail/haskell/2004-June/014134.html> and "Synthetic topology of data types and classical spaces" <http://www.cs.bham.ac.uk/~mhe/papers/entcs87.(pdf|
16:26:15 <lambdabot> dvi|ps)> by Martn Escard
16:26:25 <freeman42x[m]1> If not, what about generating a Haskell API from TypeScript definition files? Since TypeScript definitions for Screeps are available also
16:26:29 <ski> talks a bit about this algorithmic vs. computable distinction, iirc
16:26:32 <solonarv> freeman42x[m]1: you can compile Haskell to JS vi GHCJS, so yes
16:26:48 <solonarv> (and of course GHCJS has a FFI to interact with JS APIs)
16:26:52 <wavemode> maybe look into PureScript? it's a language based on Haskell which compiles to JavaScript
16:27:00 <wavemode> GHCJS is an option though it's experimental
16:27:12 <solonarv> but the generated JS is not pretty and not super easy to debug, IIRC
16:27:20 <freeman42x[m]1> solonarv: I know I can compile Haskell to JS via GHCJS. That does not answer my question at all, which is about automatic generation of Haskell API
16:27:47 <solonarv> ah, apologies. I know there is an FFI, but I don't know if there is anything to help you generate the bindings.
16:28:22 <freeman42x[m]1> solonarv: I would generate the bindings myself manually if I knew how. But that would be more complicated than just using an automatic way to generate them.
16:28:54 <ski> EvanR : hm, i didn't follow the latter bit
16:29:20 <nil> ski: that's a big paper :) no results for ctrl+f "algorithmic" so i don't know what to look for
16:29:43 <solonarv> ah, if you're fine with writing the 'foreign import ...' declarations yourself then here is (some of) the ghcjs FFI docs: https://github.com/ghcjs/ghcjs/blob/master/doc/foreign-function-interface.md
16:30:32 <freeman42x[m]1> ideally I would like an isomorphism between this TypeScript definitions and Haskell APIs equivalent: https://github.com/screepers/typed-screeps/blob/master/src/spawn.ts
16:31:21 <ski> nil : section 2.6
16:31:59 <ski> nil : i may have gotten the "algorithmic" vs. "computable" terminology from a different place, though. perhaps Troelstra's "Constructivism in Mathematics"
16:32:04 <nil> thanks
16:32:10 <EvanR> ski: algorithmic indicates how something is being generated. Computable indicates your ability to do something
16:32:54 <freeman42x[m]1> someone did a bit of work on writing the Screeps API here I think: https://github.com/tourn/screeps-haskell
16:33:36 <EvanR> like a "already happened" vs "could happen" distinction
16:35:03 <freeman42x[m]1> solonarv: the thing is that I do not know yet what the equivalent Haskell constructs are for the respective TS ones
16:35:30 <freeman42x[m]1> I would need something like an article which explains how to write an API from TS definitions for dummies
16:35:57 <freeman42x[m]1> and with 1:1 mappings, stuff like: interface <-> typeclass ?!
16:36:14 <freeman42x[m]1> I do not even know which the 1:1 mappings are
16:36:20 <ski> EvanR : i suppose i'd add that a given computable sequence also possibly could not be generated by a program
16:36:25 <solonarv> yeah, I don't know that either (not really familiar with TS)
16:36:34 <EvanR> right
16:36:50 <EvanR> computable but doesn't mean it has to be
16:37:18 <hamishmack> Check out https://github.com/fpco/ghcjs-from-typescript and https://github.com/mgsloan/ghcjs-typescript
16:37:19 <EvanR> algorithmic seems to entail there exists a concrete program somewhere
16:37:53 <freeman42x[m]1> a better solution for me would be to use a TypeScript parser to analyze the TS code and automatically generate the Haskell API from it
16:38:05 <freeman42x[m]1> that would definitely be way more maintainable, and useful for other purposes also
16:38:33 <ski> the russian school of constructivists (of which Markov was a proponent), took as axiom "Church-Turing thesis", namely that all functions on the natural numbers are algorithmic
16:38:56 <ski> this leads to being able to refute the (universally quantified) excluded middle
16:39:45 <ski> (iiuc, the category `Eff' is related to this)
16:39:51 <EvanR> yeah so all-N-functions-algorithmic is incompatible with excluded middle)
16:40:54 <nil> why?
16:41:29 <ski> (for some reason Markov also took "Markov's principle" for evident : that, for an infinite sequence of bits, if there not not exists a natural number index whose corresponding bit is true, then there exists such an index -- just try them one after another, until you find the true/`1' bit !)
16:42:40 <EvanR> justification: how could it not
16:42:47 <ski> Brouwer's school, otoh, took "Bar Induction" as axiomatic. that also leads to forall-LEM being refuted
16:43:23 <EvanR> markov's principle is like LEM lite
16:44:04 <ski> yea, like a variant of the "Limited Principle of Omniscience" (each infinite sequence of bits either contains a `1', or else is all `0's)
16:46:40 <EvanR> Omni Science best science
16:51:50 <nil> what does the Church-Turing thesis have to do with LEM?
16:57:17 <ski> the proof is in Troelstra
16:57:38 <ski> (i don't recall details)
16:58:49 <nil> do you have an intuition?
17:01:16 <ski> not really
17:02:35 <ski> i only remember it talked some about the `T(p,m,n)' predicate expressing that the function encoded by number `p', given input `m', terminates with output `n'
17:31:55 <veverak> hmmm
17:32:18 <veverak> lest say I have M monad which is Reader monad for same type
17:32:26 <veverak> how to do: [M a] -> M [a] ?
17:32:38 <wavemode> :t sequence
17:32:39 <lambdabot> (Traversable t, Monad m) => t (m a) -> m (t a)
17:33:01 <veverak> thanks
17:51:07 <freeman42x[m]1> I need to find a library which can obtain AST of some TypeScript code but I do not know what are the right words to google for that. Anyone know what the process of obtaining AST of some code is called?
17:51:28 <Cale> A parser
17:51:37 <Cale> Probably the typescript implementation contains one
17:52:05 <Cale> Oh, it's written in Javascript?
17:52:45 <freeman42x[m]1> Cale: Are you sure it is just a parser? does obtaining the AST not include lexing also?
17:52:57 <xerox_> maybe whatever this uses https://astexplorer.net
17:53:10 <Cale> http://hackage.haskell.org/package/language-typescript-0.0.4 -- here's the start of a parser for typescript at least
17:53:54 <Cale> freeman42x[m]1: Often there will be a lexer before the parser, but it's possible to just bake that in anyway, and it's not a very interesting part of the process.
17:54:37 <Cale> Their "lexer" module here just consists of parsers for each of the lexemes that they then compose into the actual language parser.
17:55:45 * hackage static 0.1.0.0 - Type-safe and interoperable static values and closures  https://hackage.haskell.org/package/static-0.1.0.0 (infinity0)
17:56:53 <EvanR> a lexer is a kind of parser
17:57:57 <wikiemol> Hello, I am looking for a function with a signature like (Monad m) => m a -> T b m a, where T is a monad transformer. That is, it "lifts" a monad to a monad transformer.
17:58:13 <wikiemol> I can't find that on hoogle
17:58:27 <EvanR> :t lift
17:58:28 <lambdabot> (MonadTrans t, Monad m) => m a -> t m a
17:58:50 <EvanR> the b is likely part of the t
17:58:51 <infinity0> yeah it looks like your (T b) is the actual transformer, T would be a transformer-factory
17:59:08 <wikiemol> I see
17:59:51 <monochrom> yuck, "factory" nomenclature :)
17:59:53 <wikiemol> Thanks... I was trying lift, and it wasn't type checking, I must be doing something wrong, but at least I know what is right
18:01:41 <wikiemol> Oh yep, I was just doing something dumb :(
18:02:13 <EvanR> factories are cool
18:02:30 <infinity0> value-factorial-programming >:D
18:03:03 <EvanR> too bad we can't compute answers as efficiently as a real factory with parallel machines could
18:05:06 <freeman42x[m]1> Cale: ok, thank you, will have a look at that parser. Kind of sad that they did not provide any tests at all
18:07:29 <Cale> It looks like something that got written one-off for a specific purpose
18:16:19 <freeman42x[m]1> Cale: kind of like exactly what I need it for right now also. But I would write tests for it, cause why not
18:36:16 <hamishmack> freeman42x[m]1: Did you take a look at https://github.com/fpco/ghcjs-from-typescript and https://github.com/mgsloan/ghcjs-typescript ?
18:38:17 <hamishmack> They are likely to have some bitrot, but it might be better than starting from scratch.
18:46:15 * hackage hurl 1.4.1.1 - Haskell URL resolver  https://hackage.haskell.org/package/hurl-1.4.1.1 (alcinnz)
18:48:50 <johnw> hurl: great name
18:49:22 <DigitalKiwi> you dropped this /s
18:49:48 <Lycurgus> yeah, i'm sure it was all about being able to use the name
19:00:28 <Welkin> these badly named packages with puns are just too much sometimes
19:00:43 <Welkin> it's a common problem/complaint in most languages though
19:01:21 <Welkin> in a presentation on fable (fsharp) and elm, this was brought up as a difference. "Fsharp tends to have package names that are a pun on F or a greek god"
19:01:30 <Welkin> haskell does the same
19:01:48 <Welkin> in lua, it's sexual innuendos instead
19:49:30 <wavemode> I'm rather fond of lua's innuendos
19:56:32 <DigitalKiwi> like what?
19:59:38 <wavemode> they're not pervasive, really. mostly it's Love2D-related libraries that do that (the game engine)
19:59:53 <wavemode> hump, lust, GSpot...
19:59:58 <wavemode> SafeWord
20:00:37 <steven_> that's funny
20:00:42 <steven_> what is lua used for usually?
20:00:59 <steven_> I haven't seen it much
20:01:31 <wavemode> I think in practice, lua is usually used as a scripting language embedded within another application. Lots and lots of games are scripted/modded with lua
20:02:05 <DigitalKiwi> oh
20:02:14 <DigitalKiwi> i've never used love2d libraries
20:02:25 <DigitalKiwi> so that's why i couldn't think of any :)
20:15:26 <wavemode> maybe the love2d names are a bit much but I think lighthearted package names are a good thing in general
20:25:01 <crestfallen> > map (id^2 + id + 1) [-3..3]
20:25:03 <lambdabot>  [7,3,1,1,3,7,13]
20:25:26 <crestfallen> hi why doesn't this work in a file, with FlexibleContexts added?
20:26:04 <crestfallen> I have it as     f list = map (id^2 + id + 1) list
20:26:28 <crestfallen> it compiles
20:26:40 <Welkin> that's confusing anyway
20:26:58 <Welkin> the lambda has too uch implicit stuff going on
20:27:18 <Welkin> just write the lambda
20:27:19 <crestfallen> it's here   http://ix.io/2mhG
20:27:32 <wavemode> :t id
20:27:34 <lambdabot> a -> a
20:27:53 <Welkin> > map (\a -> a^2 + a + 1) [1..5]
20:27:55 <lambdabot>  [3,7,13,21,31]
20:27:56 <Welkin> is that so hard?
20:28:01 <Welkin> and it's readable too
20:28:37 <crestfallen> it works in lambdabot. not the code but why does it work in lambdabot and not a file loaded into ghci ?
20:28:38 <Welkin> I have found that people create problems for themselves by trying to make things too complicated when they don't need to be
20:29:05 <crestfallen> Welkin it's an example . just trying to understand why it would work here
20:31:16 <crestfallen> do you mean the lambda *bot 'has too much implicit stuff going on'  Welkin (above)
20:31:26 <crestfallen> ?
20:33:04 <wavemode> seems to be the case
20:33:15 <Welkin> your code does
20:33:36 <Welkin> there is an implicit lambda and you are using a function `id` in place of where a variable should be
20:33:37 <dolio> lambdabot has an instance of Num and such for functions that results in this behavior.
20:33:44 <Welkin> implicit is bad
20:34:01 <dolio> I'm not sure why this was treated as an opportunity to rant instead of just answering the question.
20:34:13 <Welkin> I don't know how it works
20:34:15 <Welkin> or why it works
20:34:15 <crestfallen> thanks and thanks dolio
20:34:20 <Welkin> so I couldn't answer that
20:34:24 <Welkin> that is my point
20:34:28 <jl> Hi guys, how is it going? Do you know if github haskell site for gentoo is out-dated?
20:34:29 <ski> crestfallen : i added the relevant instances, earlier, yesterday i think ?
20:34:36 <int-e> dolio: "lambdabot has" -- not by default it doesn't.
20:34:48 <crestfallen> sorry ski .. checking my notes :)
20:34:53 <int-e> (not anymore)
20:34:54 <Welkin> the code looks invalid
20:35:01 <Welkin> so I am very surprised it even works
20:35:23 <Welkin> rule #1 of progamming: never surprise the user
20:35:37 <ski> it's just a fun way to write various mathematical expressions, like polynomials
20:35:47 <int-e> dolio: but that's not stopping people from implementing it on the spot, apparently. (or maybe importing it? Doesn't make a huge difference.)
20:36:25 <crestfallen> ski what relevant instances are you referring to ski ?
20:36:42 <wavemode> it's dark magic: `instance Num b => Num (a -> b) where ...`
20:36:52 <ski> `Num a => Num (rho -> a)' and `Fractional a => Fractional (rho -> a)'
20:37:20 <crestfallen> oh yeah that went over my head 
20:37:30 <crestfallen> yesterday
20:37:51 <int-e> Nah, nothing dark about it. You just evaluate the operations pointwise. f + g = \x -> f x + g x, and so on.
20:38:08 <int-e> But it leads to confusing code.
20:38:09 <crestfallen> another one that surprised me:
20:38:16 <ski> it's sometimes common in math to use such a definition of addition, &c., on functions
20:38:40 <crestfallen> > (*) <*> 5 $ 10
20:38:42 <lambdabot>  error:
20:38:42 <lambdabot>      • No instance for (Num (Integer -> Integer))
20:38:42 <lambdabot>          arising from a use of ‘e_1510’
20:39:05 <wavemode> > (*) <*> (+5) $ 10
20:39:07 <lambdabot>  150
20:39:09 <crestfallen> oops
20:39:10 <crestfallen> thanks
20:39:31 <int-e> (As I said, those instances are not there by default.)
20:40:36 * ski 's a bit sad that `@define' is now a synonym of `@let' ..
20:40:47 <int-e> crestfallen: that 5 would become const 5.
20:40:59 <int-e> ski: huh, what would the difference be?
20:41:26 <ski> i can't type `@define' anymore to effect `@undefine'
20:41:42 <int-e> oh.
20:42:10 <int-e> that silent edit distance correction was a terrible idea :P
20:42:26 * ski grins
20:42:50 <crestfallen> int-e, not sure I follow.. that 5 was a mistype .. is that what you mean?
20:43:06 <ski> crestfallen : int-e was talking about the error
20:43:28 <crestfallen> > (*) <*> (const 5) $ 10
20:43:28 <ski> (and why it would have been accepted, with those instances in scope)
20:43:30 <lambdabot>  50
20:43:40 <int-e> crestfallen: the Num instance that makes  map (id^2 + id + 1) [-3..3]  work would also cause  (*) <*> 5 $ 10  to be accepted, but the 5 would become `const 5`.
20:44:05 <crestfallen> oh I meant to type (+5)
20:44:41 <int-e> crestfallen: And I suspect you were happier to get a type error than the answer 50 :)
20:45:25 <int-e> s/than/rather than/ sounds better.
20:48:11 <crestfallen> but I don't see how the first one is returning 150 int-e ski actually
20:48:11 <int-e> crestfallen: 10 * (10+5) = 150
20:48:11 <ski> crestfallen : it's using `Applicative (rho ->)'
20:48:16 <int-e> In the Reader applicative, the 10 becomes the first argument to both (*) and (+5).
20:48:46 <crestfallen> it nearly operates like a fold
20:49:10 <ski> > sequenceA [(+ 2),(* 2),(^ 2)] 10  -- another example of the same thing
20:49:12 <lambdabot>  [12,20,100]
20:49:44 <ski> that becomes `[10 + 2,10 * 2,10 ^ 2]'
20:49:44 <int-e> > runReader (reader (*) <*> reader (+5)) 10 -- hmm not sure that is helpful
20:49:46 <lambdabot>  150
20:50:58 <crestfallen> ski int-e thanks I'm update my little notebook from that.
20:51:15 <crestfallen> I'll
20:51:17 <ski> crestfallen : anyway, using `Functor',`Applicative',`Monad' instances of `(rho ->)' tend to confuse people. as does instances `C a => C (rho -> a)' for various classes (i had `C' being `Num', and being `Fractional')
20:52:00 <ski> crestfallen : but `(rho ->)' behaves the same here as `Reader rho', but the latter is a little bit easier to follow
20:52:03 <crestfallen> yeah I'm not there yet ski thanks
20:52:48 <ski> (and `Monoid a => Monoid (rho -> a)' can sometimes be quite handy and pretty ..)
20:52:56 <crestfallen> ski but is that why it doesn't run from a file with the FlexibleContexts added ski ? the rho business?
20:53:15 <freeman42x[m]1> hamishmack: thank you very much for those TS to HS link. They are exactly what I need it seems
20:53:24 <steven_> the num instance for (rho ->) is interesting. don't other languages (I think f# or scala) have support for syntax like (_*2) 5? it seems to be similar to that
20:53:26 <ski> `rho' is just another type variable, like `a',`b',`t',`k',`v',...
20:53:26 <crestfallen> not it, but your original id^2 example ?
20:53:58 <wavemode> :t (^)
20:53:59 <lambdabot> (Integral b, Num a) => a -> b -> a
20:54:07 <ski> crestfallen : the reason it didn't run was that you hadn't added those `Num' and `Fractional' instances to that file
20:54:20 <wavemode> if you write a Num instance for functions, then you can call (^) on a function
20:54:38 <int-e> steven_: I think the real confusion is over literals. You write 1 2 3 and it evaluates to 1... why :)
20:54:48 <crestfallen> excellent thanks
20:56:02 <steven_> int-e: hmm probably fromInteger = const I'm guessing?
20:56:11 <int-e> steven_: It wasn't a real question
20:56:40 <int-e> steven_: I know why but it just doesn't feel right.
20:57:02 <steven_> yeah agreed
20:57:14 <ski> crestfallen : i mostly did those examples, in here, to puzzle people, weirding them out, so that perhaps some'd be curious enough to try to figure out what was happening
20:58:08 <ski> (steven_ : almost)
20:58:20 <wavemode> you should add it to https://wiki.haskell.org/Blow_your_mind
20:58:34 <ski> @quote is.the.solution
20:58:35 <lambdabot> quicksilver says: head-explosion is the solution, not the problem.
20:59:54 <int-e> steven_: oh yes, almost: fromInteger = const . fromInteger
21:01:15 <steven_> int-e: right, I think that makes sense
21:01:27 <steven_> otherwise we could only get integers, and never ints
21:05:09 <crestfallen> ski your id^2 example needs an explicit type signature? I tried      (Integral b , Num a) => (a -> b) -> [a] -> [b]
21:05:09 <MarcelineVQ> the functional programmer: always the integer, never the int
21:05:41 <ski> crestfallen : for which (sub)expression ?
21:06:47 <crestfallen> > (id^2 + id + 1) `map` [-3..3]
21:06:49 <lambdabot>  error:
21:06:49 <lambdabot>      • No instance for (Num (Integer -> Integer))
21:06:49 <lambdabot>          arising from a use of ‘e_12133’
21:07:07 <crestfallen> wait it just worked here
21:07:08 <ski> the `Num' instance that's needed is no longer in lambdabot
21:07:24 <ski> (someone flushed it out)
21:07:47 <crestfallen> you mean just now?
21:08:14 <ski> no, about half an hour ago
21:08:49 <crestfallen> :)  dang!
21:09:06 <ski> if you really want to try, i could add them back
21:09:37 <crestfallen> no I'm good !! :)
21:12:56 <int-e> ski: sorry(but not really?), that was the quickest way to verify that they aren't there by default
21:13:33 <ski> it's fine :)
21:13:51 <ski> i'm sortof surprised they lasted a nychthemeron, anyway
21:15:36 <int-e> you could just write "day" you know
21:16:23 <MarcelineVQ> that's a really ingoprabiphteropodish thing to say
21:17:30 <ski> well, i didn't mean day
21:17:30 <ski> ever since i learned that word, i've been using it
21:17:54 <ski> there's much shorter equivalents in scandinavian languages, and, i'm told, also russian and ivrit
21:18:08 <MarcelineVQ> like half-day?
21:19:24 <ski> a nychthemeron is a full revolution of a celestial body .. in this case referring to the Earth. iiuc, it's mostly used by astronomers, and possibly also people dealing with calendars
21:19:43 <ski> (around its own axis, that is)
21:20:17 <MarcelineVQ> Ah that is quite different, since a day is a measure of how long it takes the sun to orbit the earth
21:20:33 <ski> (it's annoying to say "day and night" all the time, and often it would also be inaccurate or inappropriate)
21:22:14 <ski> (a day is, on average, half a nychthemeron)
21:22:39 <int-e> Nah, a day has 24 hours.
21:23:14 <MarcelineVQ> The moon is just the sun with the corset off and a night-dress on, that's why you never see the moon and the sun in the sky at the same time
21:23:25 <int-e> There's no room for ambiguity at all. None. Nada. I deny it. I'm not even listening. Lalalalala!
21:23:26 <ski> past the ploar circle, in the summer, yes
21:23:36 <ski> s/ploar/polar/
21:24:11 <MarcelineVQ> just wait until they gt around to adding leap days to the calendar, then this entire system breaks down
21:26:29 <int-e> ski: It's funny really. If somebody says that something will take 7 days, you won't go thinking that it's 84 hours, on average. It's just the single day where this ambiguity really materializes.
21:28:18 <ski> yea, to get past seven days, one also have to skip past the intervening nights
21:28:57 <MarcelineVQ> when you wait for 7 days are you on the 8th day or the 7th day when you finish?
21:30:13 <ski> seventh
21:30:21 <ski> (starting to count at zero)
21:31:46 <Welkin> at work, 7 days means "a week", which means 5 work days, which means... 5 works days of effort/time
21:31:54 <Welkin> actually, no one talks about days
21:31:59 <Welkin> we talk about sprints, which are two weeks
21:32:06 <Welkin> 1 sprint is the minimum length
21:32:29 <Welkin> nothing takes a day
21:32:31 <MarcelineVQ> and business days come in increments of 3 for some reason
21:33:39 <int-e> accounting muddles everything up
21:38:34 <Welkin> those muggles
21:39:45 <EvanR> day 1 goof off. day 2 consider doing it. day 3 forget about it until the last minute
21:40:07 <EvanR> take weekends off
21:40:40 <Welkin> no, it's more like: spend a week figuring out where to make the code change, then spend another week writing tests and making sure nothing broke, then another 2 week wait until it goes to production
21:41:40 <EvanR> that's so agile
21:45:46 <Welkin> no, that's so raven
21:53:14 <steven_> Welkin: that hit a little too close to home
23:01:52 <reallymemorable> where can i find the reviewEncoder fuunuction? https://github.com/obsidiansystems/obelisk/pull/733/files#diff-fe2dadb00af0583d3841e501760804eaR294
23:01:59 <reallymemorable> its not in Obelisk it seems
