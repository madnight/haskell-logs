00:25:05 <olavx200> Hello. I'm having a problem where I am getting ambigious type variable error. https://bpa.st/HIXQ
00:29:37 <Axman6> We're getting an ambiguous error error. can you zshow us what the error is, along with which line it's referring to in your code?
00:30:46 <Axman6> we also have no idea what the types of most of those functions is, so know eve n less than the compiler does
00:31:23 <olavx200> Ah. Sorry about the lack of information. Here is the error https://bpa.st/SZQA.
00:31:49 <olavx200> I kind of fixed it by replacing read with (read :: String -> Int) I think.
00:32:52 <Axman6> I can't see how that would fix the error you gave
00:33:27 <olavx200> I figured out the problem.
00:33:40 <olavx200> I misspelled the groupsOf function as groupOf two times :/
00:33:52 <Axman6> That'll do it...
00:34:48 <olavx200> :). Thank you. Goodbye
00:47:42 <koz_> Axman6: Ambiguous error error roft.
00:47:46 <koz_> ROFL*
00:47:49 <koz_> I can't type today argh.
01:14:46 * hackage shake-plus 0.1.3.0 - Re-export of Shake using well-typed paths and ReaderT.  https://hackage.haskell.org/package/shake-plus-0.1.3.0 (locallycompact)
01:55:59 <maerwald> phadej: wdyt about removing IsString ByteString, adding IsString [Word8] (which has a little less weird semantics, considering it's [Char] -> Word8] conversion)and then creating a GHC extension that can convert from [Word8] literals to ByteString. So the upgrade path would be less difficult
01:56:38 <maerwald> and still raise sufficient awareness
01:58:02 <phadej> that's not possible. We have  a ~ Char => IsString [a]
01:58:08 <maerwald> argh
01:58:14 <phadej> if we remove a ~ Char, then we potentially break a lot of type-inference
01:58:27 <phadej> i.e. relax  a ~ Char to some IsChar a
01:58:54 <phadej> (a ~ Char) context was introduced in 4.9.0.0 -- I don't remember why, see git log
01:59:16 <phadej> (I guess before it was just IsString [Char] which matched badly
02:14:15 * hackage aeson-with 0.0.1.0 - withXField combinators for aeson  https://hackage.haskell.org/package/aeson-with-0.0.1.0 (locallycompact)
02:22:10 <merijn> maerwald: I actually argued for better handling of OverloadedX back in 2013, but at the time it was deemed "unnecessary" and I should "prove demand by implementing it as a library"
02:22:29 <merijn> So probably I'll turn out to just be a visionary ahead of his time
02:23:02 <merijn> Because around the same time I argued GHC should support custom type error messages and that, too, was shot down as unnecessary and they're in GHC now :p
03:23:48 <maerwald> merijn: convenience > correctness is often a thing in haskell
03:38:16 <merijn> maerwald: To be fair, that's true in basically all programming languages
03:44:43 <tdammers> I'd argue that it's *more* of a thing in most languages that aren't haskell
03:45:17 <tdammers> I have yet to come across the equivalent of a newtype wrapper introduced for the sole purpose of telling the type checker that two types are different in, say, C++
03:45:51 <tdammers> even though you could - it'd be a lot of work, but you could do it. make a class with a single private field, and implement all the operators that make sense, and none of those that don't, for example
03:47:44 <martinmch> Is there a smarter way of writing \x -> (isPrefixOf "  " x) && (isSuffixOf "  " x)?
03:47:58 <merijn> martinmch: It depends...
03:48:18 <merijn> martinmch: For just 2 predicates...meh...it's all roughly the same
03:48:26 <merijn> If you expect many more predicates, then yes
03:48:38 <martinmch> I am potentially expecting up to eight predicates.
03:49:10 <merijn> martinmch: Basically, in Data.Monoid there's newtypes for Bool (Any / All), representing && and || respectively
03:49:38 <merijn> martinmch: Which becomes relevant when you know that the best Monoid instance exists "instance Monoid r => Monoid (a -> r)"
03:50:15 <merijn> martinmch: Which means that any function returning a monoidal value can be directly mappend'ed to create a function that applies all of them to the arguments and then mappend's the result
03:51:50 <merijn> martinmch: I use that for defining complex predicates in Cabal here: https://github.com/haskell/cabal/blob/master/Cabal/Distribution/Simple/Program/GHC.hs#L161-L210
03:52:14 <merijn> (Which incidentally has some uses of isPrefixOf in it)
03:52:34 <martinmch> Clever.
03:52:37 <martinmch> Thank you.
03:53:04 <merijn> So for your example it'd be like: getAny . mconcat [Any . isPrefixOf "  ", Any . isSuffixOf "  "]
03:53:30 <martinmch> Exactly.
03:54:21 <merijn> martinmch: Fun fact: That monoid instance for functions applies recursively (i.e. if 'a -> r' is a monoid, then so is 'b -> (a -> r)') so it generalises to predicates of arbitrary arity :)
04:18:28 <maerwald> merijn: rust trades some convenience for correctness
04:25:11 <mastarija> Hi there, does anyone know if there's some nice utility function for converting Words from one endian form into another?
04:26:08 <mastarija> I've found mention of endianness in GHC.ByteOrder but there are no utility functions for conversion.
04:28:30 <fendor> mastarija, does byteSwap work?
04:28:44 <fendor> > byteSwap16 257
04:28:47 <lambdabot>  257
04:29:10 <mastarija> not if I'm using word32
04:29:12 <solonarv> oh heh, they're already in base ;)
04:29:22 <mastarija> it just swaps the bytes
04:29:31 <mastarija> but I need byte level endianness
04:29:38 <solonarv> oh, I see
04:29:48 <mastarija> not bytes, bits :D
04:29:59 <mastarija> for my previous message
04:30:04 <solonarv> > bitReverse16 258
04:30:06 <lambdabot>  error:
04:30:06 <lambdabot>      Variable not in scope: bitReverse16 :: Integer -> t
04:30:16 <solonarv> @slap lambdabot 
04:30:16 <lambdabot> go slap lambdabot  yourself
04:30:28 <solonarv> anyway, those exist too
04:30:36 <solonarv> they're in Data.Word (which is in base)
04:30:36 <fendor> I thought endianness is on byte level? 
04:31:15 <mastarija> Yes, I need it on the byte level
04:31:28 <mastarija> When I tried byteSwap it just inverts the bits
04:31:41 <solonarv> that is why I am telling you about bitReverse
04:32:01 <mastarija> Oh
04:32:06 <mastarija> Lol, I didn't see that
04:32:13 <mastarija> Let me check
04:32:23 <solonarv> % Data.Word.biteReverse16 258
04:32:23 <yahb> solonarv: ; <interactive>:105:1: error:; Not in scope: `Data.Word.biteReverse16'; Perhaps you meant one of these: `Data.Word.bitReverse16' (imported from Data.Word), `Data.Word.bitReverse32' (imported from Data.Word), `Data.Word.bitReverse64' (imported from Data.Word)
04:32:29 <solonarv> % Data.Word.bitReverse16 258
04:32:30 <yahb> solonarv: 16512
04:32:39 <solonarv> % Data.Word.bitReverse8 258
04:32:39 <yahb> solonarv: ; <interactive>:107:23: warning: [-Woverflowed-literals] Literal 258 is out of the Word8 range 0..255; 64
04:32:57 <mastarija> Ok, I messed up
04:33:02 <mastarija> Thanks!
04:33:42 <mastarija> I thought I was using byteReverse, but I was using bitReverse instead, and I didn't even notice byteReverse functions
04:43:47 * hackage juicy-gcode 0.1.0.7 - SVG to G-Code converter  https://hackage.haskell.org/package/juicy-gcode-0.1.0.7 (dlacko)
04:46:35 <mkru> Is it allowed to have if clause in where block?
04:48:45 * hackage wai-middleware-auth 0.2.3.0 - Authentication middleware that secures WAI application  https://hackage.haskell.org/package/wai-middleware-auth-0.2.3.0 (JasperWoudenberg)
04:49:06 <merijn> mkru: No, but you can just use a guard?
04:50:11 <mkru> but with guards I have to repeat code in where clause
04:50:54 <mkru> oh no sorry
04:50:58 <mkru> it is pattern matching
05:20:49 <remexre> is there a strong reason for Functor to be in Data.*, but most of its subclasses are in Control.* ?
05:21:45 <merijn> remexre: I would say there's literally no reason whatsoever for Data.* and Control.* to exist
05:22:13 <merijn> People were just super trigger happy with the idea of hierarchical modules and went overboard at the start and now we're stuck with it
05:23:56 <remexre> so if I'm designing my own language that has them, it's not too illogical to put them in like Algebra.Monad, etc?
05:24:51 <remexre> though tbh I'm kinda leaning towards Burritos.Monad, where a burrito is any "hard" concept you need to (at least partially) grok to write "real-world" code
05:25:19 <phadej> Functor exttends into Traversable which is most likely data, but also into control structures
05:25:54 <phadej> agda-stdlib has it in Category.Functor
05:26:09 <phadej> (and they don't have Control)
05:26:13 <remexre> oh, yeah, forgot about that; I usually think of traversable as a subclass of foldable, tho I guess it's both, yeah
05:27:26 <remexre> oh hm, I should look at its organization; I like the burritos joke too much, but that's probably a better idea
05:29:34 <infinity0> in template haskell, how do i convert a Cxt = [Pred] = [Type] into a single [Type] ?
05:33:15 * hackage postgresql-syntax 0.3.0.2 - PostgreSQL AST parsing and rendering  https://hackage.haskell.org/package/postgresql-syntax-0.3.0.2 (NikitaVolkov)
05:35:15 * hackage hasql-pool 0.5.2 - A pool of connections for Hasql  https://hackage.haskell.org/package/hasql-pool-0.5.2 (NikitaVolkov)
05:42:21 <infinity0> ugh looks like i have to write my own function to convert [] into (TupleT n) bah
05:50:30 <merijn> bleh, sometimes I wish Haskell had named function arguments
05:50:38 <merijn> Or anonymous records, I suppose)
05:52:39 <olle___> you don't have named args?
05:52:49 <olle___> what about optional args?
05:52:58 <olle___> ocaml has both of those
05:53:04 <merijn> olle___: Optional args are just "Maybe a" :p
05:53:32 <merijn> olle___: Ocaml has the atrocity of +. and -. for floating point, so I wouldn't get too uppity ;)
05:54:01 <olle___> that sure sucks ass
05:54:42 <olle___> what's anonymous records?
05:55:00 <merijn> olle___: Records without explicitly defined/named types, which ocaml has too, afaik
06:03:00 <olle___> merijn: ocaml's object system you can do this, yes
06:03:07 <olle___> since objects are structurally typed
06:03:28 <olle___> but they are frowned upon, for whatever reason
06:04:17 <merijn> olle___: Because covariance/contravariance leads to confusing and weird behaviour when subtyping that way
06:04:25 <merijn> Rowtype polymorphism tries to fix that
06:05:03 <untseac> I don't think haskell needs any of that. It's so simple it doesn't need it. IMO.
06:05:45 <merijn> rowtype polymorphism would be nice!
06:07:19 <olle___> merijn: OCaml object is rowtype polymorphism, no?
06:07:25 <merijn> No
06:07:32 <merijn> Structural subtyping is different
06:07:43 <untseac> seems like java 14 is out. I don't like #java though. Loads of super snobs in that channel. Just ranting.
06:08:03 <olle___> very long answer... https://stackoverflow.com/questions/48092739/what-are-row-types-are-they-algebraic-data-types
06:09:09 <merijn> Oh, maybe it does now? When I first learned OCaml it didn't support them, anyway
06:10:28 <olle___> no idea if its object system has been touched since it was introduced.
06:11:54 <untseac> just another curiosity of java 14 (I know this is a haskell channel). It has records now but it's super limited. Works more like C struct.
06:12:04 <olle___> oh, they added it?
06:12:18 <untseac> finally if you ask me
06:12:24 <olle___> one has to wonder where the hell that language will end up 
06:12:31 <untseac> it's already a mess
06:12:35 <olle___> what's the fundamental guiding principle?
06:13:03 <untseac> if you're curious: https://www.techgeeknext.com/java/java14-features#rp
06:13:29 <untseac> what I actually wanted in standard haskell was raw strings
06:13:44 <olle___> bytes?
06:14:05 <untseac> there's a lib for that: https://hackage.haskell.org/package/raw-strings-qq
06:14:19 <untseac> it's so you don't have to escape characters
06:14:29 <yushyin> they added more of the stuff kotlin already has. Maybe as a reaction to not to fall so far behind
06:14:55 <untseac> y pretty much
06:15:02 <untseac> copying from scala and kotlin
06:15:18 <yushyin> same with 'sealed types' ^^
06:15:22 <untseac> which isn't bad in itself but optionals for example are poorly implemented
06:16:17 <untseac> e.g. optionals in java are kind of functors but not really because there's no functor type class. there's not even a None.
06:16:48 <untseac> and that limits the use of optionals
06:16:54 <olle___> untseac: why would you need it if the compiler does program flow analysis to avoid null exceptions?
06:17:59 <untseac> olle___, in some cases I would like to generically map as if it was a list of 1 element, but nop, you have to be explicit. I bumped into many limitations of Java functional implementation.
06:18:20 <untseac> there are more
06:19:12 <untseac> but java is one of those languages that does everything okayish, nothing great, nothing really bad
06:21:11 <remexre> not sure I'm understanding the last example in section 9.32.15 of the ghc user's guide (COMPLETE pragmas); shouldn't the kind of the type annotation have to be * ?
06:22:56 <merijn> remexre: Why?
06:23:56 <remexre> that's the way it is everywhere else in the language (and they're called /type/ annotations)
06:24:38 <merijn> remexre: Types are not requires to have kind *
06:24:55 <merijn> remexre: I certainly wouldn't say that has to be the case "everywhere else in the language"
06:25:11 <remexre> to be pedantic, and possibly tautological, those are kind annotations, not type annotations :P
06:25:15 <merijn> remexre: The types of *values* must always have kind *, but that doesn't apply to all types
06:25:57 <remexre> is the [] meant to directly fill in the f variable? or is it matching the outermost type constructor after reducing the type to some normal form?
06:26:27 <merijn> I do agree the example is a bit...under specified, because I'm not sure how it's supposed to work
06:37:42 <ggVGc> merijn: I sometimes find myself defining new data types just to pass named arguments to some functions...
06:37:49 <ggVGc> and feel like it's a bit too much boilerplate
06:37:58 <merijn> ggVGc: That's what I'm doing too
06:38:17 <merijn> ggVGc: But it sucks when I have a datatype like that and need to define a new version for another function :p
06:38:23 <ggVGc> since I also often define default constructors of those argument types, which leads to even more boilerplate
06:38:27 <ggVGc> and then it's nice to use
06:38:29 <ggVGc> but sucks to maintain
06:38:31 <ggVGc> and then I cry a little bit
06:38:43 <merijn> ggVGc: tbh, I find it's actually quite nice to maintain and use
06:38:53 <merijn> It's just the initial implementation that sucks
06:38:58 <ggVGc> merijn: what you just said is a major pain point though
06:39:21 <ggVGc> this is why I in many ways prefer purescript over haskell
06:39:25 <merijn> ggVGc: NoFieldSelectors extension is coming to GHC, that's good for this workflow :)
06:39:30 <ggVGc> but I still use haskell for the maturity of GHC and tool ecosystem
06:40:03 <ggVGc> great, another extension I have to read up on
06:40:10 <merijn> ggVGc: It's trivial
06:40:29 <merijn> ggVGc: You know how sum types suck in combination with record syntax because the accessors are partial?
06:40:55 <merijn> ggVGc: Galaxy brain solution: Let's not have field accessors!
06:41:49 <ggVGc> yeah, it's such a dumb part of haskel imo
06:41:58 <ggVGc> and one that I couldn't believe at first when I was learning the language
06:42:05 <ggVGc> it feels like a bug to me
06:42:08 <merijn> ggVGc: So record creation/update/pattern match syntax keeps working, there's just not accessor functions.
06:42:11 <merijn> Same
06:42:15 <ggVGc> that data declarations can generate partial functions
06:42:23 <ggVGc> how was that ever accepted as an okay thing
06:42:29 <merijn> Which is why I'm happy this proposal got accepted
06:42:36 <ggVGc> yeah sounds good
06:43:15 * hackage lsp-test 0.11.0.1 - Functional test framework for LSP servers.  https://hackage.haskell.org/package/lsp-test-0.11.0.1 (luke_)
06:44:15 * hackage with-utf8 1.0.2.0 - Get your IO right on the first try  https://hackage.haskell.org/package/with-utf8-1.0.2.0 (kirelagin)
07:18:50 <pie_> do you guys know any articles on xmonad style design for making things arbitrarily restartable?
07:19:01 <pie_> (im actually doing python right now though)
07:26:21 <frdg> what does `forall` do? Is it even important for a beginner? Why does it come up in error messages but not type signatures?
07:27:47 <wavemode> it introduces a type parameter. `id :: a -> a` is really `id :: forall a. a -> a`. it's implicit, most of the time, since anything lowercase is automatically a type variable
07:28:58 <frdg> wavemode: ok, that makes sense then why it would come up in error messages. 
07:29:17 <wavemode> it's implicit, but that doesn't mean it's not there :)
07:35:05 <sushi12312> Hello, could someone please give me a hint why if `f >@> g = \x -> (f x) >>= g` then this is true `return >@> f  = f`
07:38:12 <phadej> do you mwan >=> ?
07:38:26 <john20> Hi sushi12312, do you know the type signature for >@>
07:38:57 <sushi12312> john20: `(>@>) :: Monad m => (a -> m b) -> (b -> m c)-> (a -> m c)` here
07:40:20 <wavemode> :t return
07:40:21 <lambdabot> Monad m => a -> m a
07:40:26 <john20> doesn't `return` give you the identity value for a monad or something? Could that explain it
07:40:59 <sushi12312> yeah, it does, but i am a bit confused by the lambda inside
07:41:24 <john20> this bit `\x -> (f x) >>= g` ?
07:41:43 <sushi12312> yes
07:43:30 <john20> If you want to show that `return >@> f ` is the same as f then from the type signature, you can see that f has to have type of `a -> m b`
07:44:00 <infandum> What would you do in this scenario: a program that can be fully in haskell but has one function from upstream that is super slow compared to a command line program but you would need to output temporary files for the program to process, then read the results back in. Would you go full haskell or have haskell write files and call the command line program?
07:44:05 <john20> then you can put the values `return` and `f` into the definition of the `>@>` function and reduce it down
07:46:50 <sushi12312> if I put the values in I get `\x -> return x >>= f`, how would i continue to get the f?
07:47:31 <sushi12312> do I need to know about monad implementation for functions to understand this?
07:50:39 <wavemode> if `(>@>)` has a type signature of `(a -> m b) -> (b -> m c)-> (a -> m c)`, and return has a signatrure of `a -> m a`, then you could rewrite the signature of `>@>` to be `(a -> m a) -> (a -> m c)-> (a -> m c)`. which matches the assertion that `(>@>) return f = f`
07:51:23 <timCF> Hi guys) I have a noob question. Is it ok in general to use Lazy Text instead of Strict in application data types and Persistent storage? I'm just using gRPC which is always returns lazy text from network messages, just thinking is there any point to convert into strict, or I just can use text fields as they are (lazy)?
07:52:34 <wavemode> the key to understand is that `a -> m a` in return's signature necessarily means that return does not modify the value, it simply wraps it in a monad. so think of it as sequencing two functions, where the first one is doing nothing to the value anyway
07:55:32 <ski> sushi12312 : do you know the monad laws ?
07:55:45 <ski> sushi12312 : "do I need to know about monad implementation for functions to understand this?" -- no
07:56:19 <sushi12312> ski: i am reading just about them right now.
07:56:44 <ski> you can express them in terms of `do'-notation, and `return'
07:56:51 <ski> or in terms of `(>>=)' and `return'
07:58:24 <dmj`> TIL :set -DDEVELOPMENT 
07:58:31 <dmj`> can set CPP in .ghci
08:00:33 <ski> sushi12312 : a function of type `a -> m b' can be thought of as a computation that consumes an input of type `a', produces an output of type `b', and (possibly) has some effect of type `m'
08:00:56 <ski> this is also called a "Kleisli arrow/morphism"
08:01:36 <ski> @type readFile
08:01:38 <lambdabot> FilePath -> IO String
08:01:43 <ski> @type Kleisli readFile
08:01:44 <lambdabot> Kleisli IO FilePath String
08:02:46 <Cale> timCF: I'd avoid converting unnecessarily if possible. Converting to strict will suddenly allocate a single buffer for the entirety of the text.
08:03:25 <Cale> timCF: If it somehow happens to be infinite, you'll be having a bad day. If you know that it's short, it's probably safe to convert if that makes your life easier.
08:04:33 <merijn> "short" is relative :p
08:05:02 <merijn> Like, a few KB or even MB of strict Text is fine
08:05:35 <sushi12312> ski: thanks for explanation
08:06:23 <ski> sushi12312 : well, it wasn't really finished. i was just waiting for your next question about it
08:07:04 <ski> sushi12312 : did you manage to show that it holds ?
08:07:22 <sushi12312> ski: ah, i see. I think I kind of understand the monad. had hard time figuring out what was the difference between applicative functors and monads but I understand now
08:07:25 <ski> sushi12312 : do you understand the usual formulation (either of them) of the monad laws ?
08:08:02 <ski> oh, that's a separate topic
08:08:13 <ski> have you tried the Typeclassopedia, btw ?
08:08:37 <sushi12312> no, i am reading through some slides and Programming with Haskell only
08:08:53 <ski> ok
08:09:03 <ski> at some point, you may want to try it, as well
08:09:11 <ski> @where Typeclassopedia
08:09:11 <lambdabot> http://www.haskell.org/haskellwiki/Typeclassopedia
08:09:45 <ski> (doesn't have to be now, if you think you've already got your hands/head full with what you're doing)
08:10:42 <sushi12312> i'll check it right now, the slides are a bit confusing, just laws such as I sent with no explanation
08:10:53 <ski> sushi12312 : what would you say is the difference between applicative functors (aka "idioms") and monads ?
08:11:03 <ski> mhm
08:11:42 <ski> you know `do'-notation ?
08:11:42 <Cheery> I'd need something like MVar but it should be able to backtrack.
08:11:52 <Cheery> https://gist.github.com/cheery/4e1c6baa10e8dd002d47988154ce5e1e
08:12:13 <sushi12312> ski: from what I understood is that applicative has a little interaction with previous computations because of the signature (a -> b) compared to monad which has better flexibility with it's computation type (a -> m b)
08:12:58 <sushi12312> ski: yes, i've just read about it and tried few transformations from do-notations to monadic notations and back, to understand it better
08:13:09 <dsal> Cheery: it's easier to backtrack if you use immutable state
08:13:57 <Cheery> dsal: yup. uKanren -like variable buffer could be ok.
08:14:14 <ski> looks like something with linear logic, Cheery
08:15:26 <Cale> sushi12312: One way to put it is that with Applicative (alone), the results of subcomputations can't be used to determine which computations to run -- you basically have a fixed bunch of things in some sequence, and you're combining their results somehow. Monad's (>>=) gives you the power to decide what to do next based on the result of the previous action.
08:15:45 <ski> sushi12312 : yes, the difference is that with a monadic "computation", "what effects to perform later" may depend on intermediate results computed earlier. not so, for idiomatic computations
08:16:09 <Cheery> ski: I examined computability logic's semantics for "parallel" and "choice" connectives, and used it with linear logic as a guide
08:16:25 <ski> oh, Japarizde
08:16:43 <infandum> Could you have an IO action in a Semigroup instance? a -> a -> IO a, as IO would be needed to join the two. Is unsafePerformIO required?
08:17:04 <Cheery> I think these could be normalizable, but I have had difficulty building a normaliser.
08:17:04 <ski> Cheery : there's a paper about logic variables in Haskell, by Silvija Seres and Spivey, iirc
08:17:22 <ski> Cheery : and a follow-up paper about typed ditto, by Koen Claessen
08:17:42 <Cale> infandum: No, but you could have a semigroup which combined IO actions in some way
08:18:24 <ski> infandum : i'd recommend not lying to the implementation
08:18:48 <ski> sushi12312 : but have you seen the monad laws, in terms of `do' ?
08:19:07 <Cale> infandum: Why is IO required?
08:19:08 <sushi12312> ski: no, i don't think so
08:19:35 <Cheery> ok. If I stop the cut procedure and "branch", I should be able to reify the term.
08:19:51 <infandum> Cale: I tried Semigroup (IO T) with FlexibleInstances, but that conflicts with the Semigroup (IO a) instance.
08:19:54 <Cheery> ski: thanks
08:20:02 <Cale> infandum: Yeah, you'd have to make a newtype
08:20:54 <Cale> But... what is actually going on? :)
08:20:58 <infandum> Cale: I thought that might be the solution
08:21:25 <merijn> "Monoid a => Monoid (IO a)" already exists
08:21:41 <merijn> (and thus Semigroup, by transitivity)
08:21:45 <ski> Cheery : if you don't find links, i could dig up them
08:21:54 <infandum> Cale: Newtype for IO?
08:22:01 <ski> Cheery : there's also some papers on the implementation of lambdaProlog, which might be useful to you
08:22:26 <Cale> infandum: Well, could you describe what you're trying to do more broadly?
08:22:47 <Cale> infandum: I'm not sure this suggestion really makes sense, but yeah, it would be a newtype of IO T
08:23:27 <Cheery> ski: I found nice pictures of orchids, and Koen Claessen's paper
08:23:33 <infandum> newtype MyIO a = MyIO { unMyIO :: IO a }
08:23:50 <ski> Cheery : Claessen's paper should reference the other paper
08:24:06 <Cale> infandum: It probably shouldn't be a newtype with a parameter...
08:24:19 <Cale> infandum: What's your combining operation?
08:24:57 <infandum> Cale: I'm trying to join data. Through haskell, it's very slow (1 hour). Through a command line program, it would be 4 mins. So I want to try mconcat through IO.
08:26:10 <ski> sushi12312 : hm, perhaps you'd like to join #haskell-overflow ?
08:26:45 <sushi12312> ski: yes, ill join there
08:26:56 <sushi12312> thanks for help, i ll ask there
08:27:17 <infandum> Cale: I have ranges. I use Data.IntervalMap to join them (unionWith), but that's slow. Using the bedtools program for the ranges, it's much faster.
08:27:50 <Cale> infandum: Is the program definitely going to always produce the same result for the same inputs?
08:29:24 <Guest_68> https://pastebin.com/WAm9BsKG
08:29:30 <infandum> Cale: It should, but obviously if they have a bug there is no way to know.
08:29:36 <Cale> If so, it might be worth trying the unsafePerformIO thing, though in general, I'm not sure how I'd feel about lots of external processes getting created by a Semigroup instance :D
08:29:48 <Guest_68> I want to decrement my hitCounter everytime I call hit in the then portion of my loop
08:29:59 <sushi12312> ski: i can't seem to write to the channel 
08:30:02 <infandum> Cale: On top of that, it's all parallelized
08:30:07 <Guest_68> in c I would just hitCounter-- 
08:30:10 <ski> hm
08:30:11 <Cale> infandum: Do they have a library version?
08:30:48 <Cale> infandum: Perhaps doing FFI to it would be a bit nicer
08:31:15 <Cale> ah, it's written in C++, so probably not particularly easy to deal with via FFI
08:31:18 <infandum> Cale: I don't thinkso. It's in C++ though, but I have no idea how to do that
08:33:10 <infandum> Cale: According to my profiling, unionWith, unionWithKey, foldrWithKey, and fromDistinctAscList (all from Data.IntervalMap) are where the program is spending 80% or more of it's >1 hour runtime
08:34:56 <ski> sushi1234 : oh, okay. seems there's a quiet on unregistered users, in there, for some reason
08:35:28 <ski> sushi1234 : you have seen the monad laws, in terms of `return' and `(>>=)', yes ?
08:35:40 <timCF> thanks Cale
08:38:12 <sushi1234> ski: yes, i've seen them. I can type in overflow channel now
08:38:19 <Cale> infandum: To go back to the other idea, maybe something like  data IntervalWork = IntervalWork { runIntervalWork :: IO (IntervalMap something something) }
08:39:13 <Cale> infandum: Basically, you sort of build up a plan for running the external tool a bunch in order to construct your IntervalMap
08:39:29 <Cale> (or whatever sort of representation would be convenient)
08:40:02 <Cale> and then you actually execute the program at the very end, if that's possible
08:40:43 <infandum> Cale: I think the newtype idea is probably the simplest, although it pains me to leave haskell for this one process
08:42:08 <wavemode> infandum: is it possible for you to use a mutable data structure instead? I know there are various mutable hashmap implementations
08:43:18 <dsal> Guest_68: When you say `hitCounter = 4` that's what that means.  You can't later say it is something else.
08:43:56 <infandum> wavemode: I don't think it would be for interval data though
08:44:00 <Guest_68> https://pastebin.com/ZHuD3TWE dsal
08:44:02 <infandum> Thanks all!
08:44:33 <dsal> Guest_68: Another possibility:  Don't do that at all.
08:44:40 <dsal> BTW, you can say `hitCounter - 1`
08:45:12 <dsal> But first:  Get rid of all of the number things and go back to having proper types for your states.  Then you can just add up the states of a particular type.
08:45:29 <dsal> > sum . filter (== True) $ [False, True, True, False, True]
08:45:31 <lambdabot>  error:
08:45:32 <lambdabot>      • No instance for (Num Bool) arising from a use of ‘sum’
08:45:32 <lambdabot>      • In the first argument of ‘(.)’, namely ‘sum’
08:45:36 <dsal> *sigh*
08:45:40 <dsal> > length . filter (== True) $ [False, True, True, False, True]
08:45:41 <lambdabot>  3
08:45:52 * dsal also got up too early this morning and would rather still be asleep
08:46:04 <wavemode> Guest_68: you should just modify your if statement. the loop should end if the hitCounter is 0
08:46:56 <wavemode> so if it's 0, don't recurse any more
08:47:06 <Guest_68> if((mark==Just 1)&&(hitCounter/=0))
08:47:33 <dsal> Well, no.
08:48:02 <wavemode> no, more like `if hitCounter /= 0 then A else B`. A should be where you check for a hit and recurse, B should be where you end the game and don't recurse
08:48:22 <dsal> The `if mark == Just 1` thing doesn't make a lot of sense.
08:48:44 <dsal> You can place the mark and count the score separately.
08:48:57 <dsal> Because `1` is very misleading.
08:50:21 <dsal> let state' = guess state atInput   -- guess is firing at that position.  If there's Empty there, now it's Miss.  If there's Ship there, now it's Hit.  If there's Hit there, it's still Hit.
08:50:51 <dsal> Then you can loop when  `not . null . filter (== Ship) $ state`
08:51:20 <dsal> (or, if you'd prefer `(not . null . filter (== Ship)) state`
08:51:21 <dsal> )
08:52:06 <dsal> But that's a separate function.    `stillGoing :: Board -> Bool;   stillGoing = not . null. filter (== Ship)`
08:52:33 <dsal> Now you can say:   `when (stillGoing state')  $ loop state'`
08:53:44 <Guest_68> wavemode that was the trick thank you
08:54:22 <wavemode> i'm emotionally invested in you creating battleship at this point
08:54:28 <wavemode> don't let me down Guest_68
08:55:06 <Guest_68> dsal i have to submit a working prototype by this evening and its ~working now but ill polish it up to learn more after i submit
08:55:26 <dsal> Guest_68: Note that by having the board *and* the hitCounter, you have two separate representations of your state you have to keep in sync, and it's confusing with the numbers.
08:55:49 <Guest_68> haha ill send it my end result wavemode
08:56:15 <Guest_68> as ugly as it may be
08:57:48 <dsal> Note:  If you make `data State = Empty | Ship | Hit | Miss deriving (Eq, Show)` you can change the numbers immediately *and* you get rid of the `putString "Hit"` when you get a hit and just `maybe (pure ()) print mark`
08:58:18 <dsal> % maybe (pure ()) print (Just True) -- can I get a witness?
08:58:19 <yahb> dsal: True
08:58:47 <dsal> % let maybePrint = maybe (pure ()) print   in  maybePrint (Just True)
08:58:47 <yahb> dsal: True
09:03:20 <dsal> > let board = [("a1", Hit), ("a2", Ship), ("a3", Hit)]; hitCounter = length. filter (== Ship) . map snd in    hitCounter board
09:03:22 <lambdabot>  1
09:03:25 <dsal> > let board = [("a1", Hit), ("a2", Ship), ("a3", Ship)]; hitCounter = length. filter (== Ship) . map snd in    hitCounter board
09:03:27 <lambdabot>  2
09:03:30 <dsal> > let board = [("a1", Hit), ("a2", Hit), ("a3", Hit)]; hitCounter = length. filter (== Ship) . map snd in    hitCounter board
09:03:33 <lambdabot>  0
09:15:33 <isovector1> @pointful (uncurry (flip (flip maybe (Just . Left) . maybe Nothing (Just . Right))))
09:15:33 <lambdabot> (uncurry (\ x y -> maybe (maybe Nothing (\ x -> (Just) ((Right) x)) y) (\ x0 -> (Just) ((Left) x0)) x))
09:28:46 <olavx200> Did anyone else find the functors chapter in LYAH to be pretty poor. For me it didn't click before I read the summary in the next chapter (?) which for whatever reason was much mare understandable if you ask me.
09:29:19 <Cheery> how does LYAH explain functors?
09:29:24 <Cheery> can you link?
09:29:30 * Lycurgus checks if it's been updated
09:29:39 <wavemode> i find all of LYAH to be pretty poor. but that's just my opinion
09:29:53 <olavx200> http://learnyouahaskell.com/functors-applicative-functors-and-monoids
09:30:45 * hackage HTab 1.7.3 - Tableau based theorem prover for hybrid logics  https://hackage.haskell.org/package/HTab-1.7.3 (GuillaumeHoffmann)
09:31:10 <olavx200> Seems like popular opinon around here. You might be right, but I will finish it regardless. If nothing else just to increase my books read count :)
09:31:19 <ski> i've heard several people say they think LYAH is lacking a bit
09:31:25 <ski> (e.g. no exercises)
09:31:39 <Lycurgus> no and although I know it to be decade or more older, seems undated
09:31:46 <ski> someone likened it to a "four-hour long trailer"
09:32:02 <ski> iow, it isn't in-depth enough, although it has the pretty pictures
09:32:20 <ski> @where CIS194
09:32:21 <lambdabot> https://www.seas.upenn.edu/~cis194/spring13/lectures.html
09:32:31 <ski> olavx200 : if you're looking for exercises, you could try ^
09:32:40 <olavx200> There is no exercises that is true. I'm using some I found on github
09:32:44 <olavx200> Ah thank you :)
09:33:17 <olavx200> I might try them if I need some more after I finish the book.
09:33:29 <olavx200> I'm going back to studying now. Later
09:33:34 <ski> olavx200 : btw
09:34:05 <Lycurgus> LYAH is nice, we're mostly stuck up bitches
09:34:06 <ski> imho, it can also help, learning Haskell, to lurk in this channel
09:34:28 <ski> (and definitely ask, if there's something unclear)
09:34:29 <olavx200> ;)
09:35:53 <olavx200> Thanks. I appreciate that. I've always heard #haskell was a friendly place. You certainly live up to my expectations. :)
09:36:19 <ski> we can only try to keep it that way
09:36:53 <mastarija_> 'Sup people. I'm planning to explore conduit and how to do streaming in Haskell.
09:37:16 <mastarija_> I've tried to first read a binary file with my own approach.
09:37:28 <mastarija_> Just to see how I'd do it
09:37:41 <mastarija_> However, it's not really "streaming"
09:37:50 <mastarija_> As it needs to load the whole file first
09:37:55 <mastarija_> Here's my code
09:37:56 <mastarija_> https://pastebin.com/S4qXHRiu
09:38:08 <mastarija_> I was wondering if there's a better way to do what I intended to do.
09:38:32 <mastarija_> Basically, my file consists of some global header and an undefined number of "packets"
09:39:06 <mastarija_> And then I've made this readPackets function which checks if EOF is reached before continuing recursively.
09:39:32 <mastarija_> However, my recursion approach requires me to reach the end of the file first before I build up a list
09:42:25 <Lycurgus> conduit has poor rating on hackage, is it "production level" streaming?
09:42:35 <mastarija> Not really
09:42:43 <Lycurgus> ah
09:42:45 <mastarija> Just an exploration of streaming and stuff.
09:42:56 <wavemode> people pay attention to hackage ratings?
09:42:57 <mastarija> I've never done anything that would require it
09:43:30 <mastarija> Lycurgus, what would you recommend instead of conduit?
09:43:46 <Lycurgus> oh geez, in haskell?
09:43:52 <mastarija> Yep :D
09:44:10 <Lycurgus> i wouldn't recommend nuthin real time in haskell
09:44:29 <mastarija> I mean, I kind of want to score a haskell job so I'm thinking of covering streaming and concurrency (two things I never had to touch)
09:44:35 <Lycurgus> especially something subject to "the wild"
09:44:38 <[exa]> wavemode: these aren't random??
09:45:24 <Lycurgus> if my reasoning were correct you would score as having misunderstood it's domain of application
09:45:43 <wavemode> there's nothing wrong with conduit, and yes it's production ready
09:46:14 <Lycurgus> A Champion!
09:46:34 <mastarija> Is there some way in which I could improve my code from pastebin and make it stream?
09:46:44 <mastarija> I kind of have intuition that it's not possible
09:46:45 * Lycurgus does the "bring it" hand thing with the fingers
09:46:59 <mastarija> https://pastebin.com/S4qXHRiu
09:47:13 <[exa]> mastarija: well, do not output a list, output a stream :]
09:47:32 <[exa]> how are you planning to process the pcap log?
09:47:40 <mastarija> Just print out some data
09:47:50 <[exa]> cool, that's stream processing
09:48:05 * ski . o O ( `isRandom :: Eq a => (StdGen -> a) -> Bool' )
09:48:17 <mastarija> So stream is basically a list without an end, right?
09:48:21 <[exa]> ski: man
09:49:02 <[exa]> mastarija: with some bonuses, e.g. avoiding lazy IO
09:49:08 <dsal> mastarija: lists don't necessarily have ends, either.
09:49:10 <Cheery> there's another important thing
09:49:12 <Cheery> in stream
09:49:19 <mastarija> dsal, in Haskell
09:49:49 <dsal> In real life.  I've never seen the end of the list of all the ways I'm awesome.
09:50:21 <Cheery> if you define a stream as infinite list, then a subsequent value cannot depend on a value that is result of interacting with the said stream.
09:50:35 <mastarija> Although I'm not sure how you ever stop processing something without an end without just doing a violent quit
09:51:58 * ski notes mastarija is rediscovering the fan theorem
09:52:16 * hackage blake3 0.1 - BLAKE3 hashing algorithm  https://hackage.haskell.org/package/blake3-0.1 (RenzoCarbonara)
09:52:58 <dsal> conduit streams have ends just as lists do.
09:53:01 <mastarija> Ah.. I guess
09:53:58 <dsal> They also don't have ends the same way lists don't.  It just depends on what you're streaming.
09:54:41 <ski> it basically says that if you have `phi :: Stream Bool -> Bool' with `phi s0 = True' for some `s0 :: Stream Bool', then there's a finite prefix `l :: [Bool]' of `s0' such that for any `s1 :: Stream Bool' sharing the same prefix `l', also `phi s1 = True'
09:55:05 <ski> or, in other words, `phi s0' only looks at finitely many elements of `s0'
09:55:25 <Cheery> every Functor article should probably tell that they're structure preserving maps
09:56:10 <mastarija> dsal: so can I somehow use list in my case?
09:56:12 <ski> or, in other words, any such `phi :: Stream Bool -> Bool' is continuous
09:56:37 <dsal> mastarija: You can run a conduit stream into a list, or you can source a conduit stream from a list.
09:56:57 <mastarija> ski: basically, I have a tag in my stream?
09:57:04 <Cheery> and that they can be thought of as images of some category in an another category.
09:57:06 <ski> "tag" ?
09:57:07 <dsal> In your case, I'd probably just `yield` each packet.
09:57:28 <mastarija> dsal: yes, but what if I want to do it without conduit, as an exercise?
09:57:30 <ski> Cheery : i hope they tell about the `Functor' laws ..
09:57:44 <mastarija> ski: something that tells me "stop processing this stream"
09:57:49 <dsal> mastarija: Oh.  Well, it's just   getPacket : recurse
09:58:14 <ski> mastarija : well, you'll have to decide yourself, when to stop, i think ?
09:58:19 <Cheery> ski: that's bare minimum
09:58:35 <mastarija> dsal: am I not doing that in my example?
09:59:41 <ski> Cheery : functors can generalize actions, btw
09:59:42 <dsal> mastarija: Maybe.  I'm not entirely sure it plays with fusion.  I don't quite know what all the parts are or how they interact.
10:00:00 <Cheery> ski: LYAH tells about functor laws btw.
10:00:36 <mastarija> I guess, what I'm trying to figure out is why use streaming library instead of lists? Do I just get some extra handy utilities?
10:00:43 * ski goes to shut out the daystar
10:01:04 <Cheery> ski: generalize actions?
10:01:40 <ski> not "actions" in the idiom or monad sense
10:01:41 <mastarija> dsal, I was hoping that my example would work but it doesn't, because it's not really a tail recursion
10:01:48 <ski> but in the monoid and group sense
10:02:13 <wavemode> mastarija: the conduit readme answers that question. "It is an alternative to lazy I/O which guarantees deterministic resource handling."
10:03:31 <Cheery> ski: can you point a paper about that?
10:03:49 <mastarija> wavemode, ah sorry... I was thinking about more abstract differences for the lack of a better word
10:04:18 <mastarija> lazy I/O is what I'm doing (attempting to do) so I guess there's no in that aspect difference
10:04:24 <dsal> The problem is that it's hard to look at a bit of code like that and decide whether it's properly lazy.
10:04:36 <mastarija> Just a sec I'll make a new paste
10:04:46 * ski is trying to think of some example, in Haskell
10:05:25 <mastarija> dsal: Ok, this should be more obvious: https://pastebin.com/GGc71RP7
10:06:15 <ski> Cheery : let's define
10:06:22 <mastarija> So basically, I read some bytes with 'get @ Packet' but then I have to wait for the recursion to finish before I can build the list.
10:06:23 <dsal> mastarija: Are you verifying that that's not lazy?
10:06:29 <mastarija> I know it's not
10:06:37 <mastarija> But I can't think of a way to make it lazy
10:07:19 <mastarija> Or actually, I think I'm mixing tail recursion and lazyness here
10:07:26 <ski> @let concatReplicate :: Integral i => i -> [a] -> [a]; concatReplicate n xs = concat (genericReplicate n xs)
10:07:28 <lambdabot>  Defined.
10:07:43 <ski> > concatReplicate 3 "abc"
10:07:45 <lambdabot>  "abcabcabc"
10:07:48 <ski> > concatReplicate 0 "abc"
10:07:51 <lambdabot>  ""
10:07:57 <dsal> mastarija: Take the head from the list it produces and see if it even builds more than one packet.
10:08:02 <Lycurgus> i do see the conduit author is a reliable illuminary, if that could help
10:08:21 <dsal> Throw in some undefined or something.   `pure (p : undefined : ps)
10:08:22 <dsal> `
10:08:35 <ski> Cheery : let's say we're talking about natural numbers. we can state two laws for `concatReplicate'
10:08:37 <mastarija> dsal, ok just a sec
10:08:46 <ski>   concatReplicate 0 xs = xs
10:09:11 <ski> er, should be
10:09:15 <ski>   concatReplicate 1 xs = xs
10:09:45 <ski>   concatReplicate (m + n) xs = concatReplicate m xs ++ concatReplicate n xs
10:09:50 <Cheery> ski: concatReplicate 0 xs = [].. ok.
10:09:51 <mastarija> dsal, yep it's lazy for sure
10:09:55 <mastarija> I don't get an error
10:09:56 <dsal> Done!
10:10:17 <ski>   concatReplicate (m * n) xs = concatReplicate m (concatReplicate n xs)
10:10:28 <mastarija> hm.. but I get a big wait time when I run my function
10:10:31 * ski tries to make this example clear
10:10:40 <dsal> Well, we don't know it's lazy for sure at this point, really.
10:10:55 <mastarija> I mean, the list is lazy
10:10:58 <ski> ok, so we have two laws, regarding `0' (which you corrected) and `+'. and two regarding `1' and `*'
10:11:02 <Cheery> ski: oh ok.. you're not declaring a functino, but defining laws for it.
10:11:21 <dsal> mastarija: That was a bad test...
10:11:30 <ski> the first two ones (`0' and `+') are some kind of distributive laws
10:11:37 <mastarija> dsal: yep :D
10:11:49 <dsal> You want something more like `pure ([p] <> undefined <> ps)`
10:11:50 <Cheery> ski: is this a map from the laws of natural numbers to the laws of lists?
10:12:11 <dsal> I don't know...  Maybe just Debug.Trace. heh
10:12:42 <mastarija> No, I just want it to consume output on demand, right now it seems like it loads the whole file and constructs a full list.
10:13:03 <mastarija> Or actually, I know it does that.
10:13:12 <mastarija> I want to convert my recursion into tail recursion
10:13:33 <mastarija> But I don't see a way to do that when I need to unwrap a monadic result
10:13:33 <ski> Cheery : the two laws involving `0' and `+' state that `\n -> concatReplicate n xs' (for any particular `xs :: [a]') is a monoid homomorphism from the monoid of natural numbers, with `0' and `+', to the monoid of lists of type `[a]', with `[]' and `++'
10:13:53 <dsal> It's a little confusing because the list is inside your monad and you keep leaving it to get more data to put back inside.
10:13:56 <[exa]> mastarija: why don't you convert your loading function to loading and processing function?
10:14:50 <mastarija> I was thinking about that... but I thought it would be more elegant to get a stream of raw data and then be able to apply some function onto it.
10:14:57 <ski> Cheery : otoh, the two laws involving `1' and `*' state that `concatReplicate' is an action, having the monoid of natural numbers, with `1' and `*', act on the set/type `[a]'
10:15:25 <[exa]> mastarija: you cannot technically finish reading from the file without getting all of it in to memory (applies to all programming languages, not just haskell)
10:15:50 <mastarija> [exa], so how does conduit and similar streaming libraries approach this then?
10:16:07 <dsal> Well, you don't have to have it all in memory at once.
10:16:16 <mastarija> I mean, I know.
10:16:22 <mastarija> That's what I'm trying to achieve
10:16:24 * dmwit . o O ( concatReplicate is a monoid homomorphism from (N, 1, *) to (Endo [a], id, (.)) )
10:16:27 <ski> if `M' is any monoid, with neutral element `1' and combination `*', and `A' is any set, then `(#) : M * A >---> A' is an action of `M' on `A', iff :
10:16:28 <[exa]> mastarija: conduit is a great bunch of tools that allow you to not care about when the reading happens, you just describe the processing pipeline, done
10:16:36 <ski>   1 # a = a
10:16:48 <mastarija> yes, I get that
10:16:49 <ski>   (m * n) # a = m # (n # a)
10:17:21 <ski> Cheery : in our case, `#' corresponds to `concatReplicate', and `A' to `[a]'
10:18:07 <ski> Cheery : note how these laws look a bit like left neutral element law, and associativity law. but we have two different operations, `*' and `#'
10:18:10 <[exa]> mastarija: anyway you can keep it simple, instead of loadFile you can implement something like `foldPcap :: (Packet -> a -> a) -> a -> FileName -> a`
10:18:27 <mastarija> [exa], yes, I guess I'll do that
10:19:13 <mastarija> I'm assuming that this is what conduit toolchain does in the end?
10:19:21 <[exa]> or maybe better with Monoids (not sure if you want left or right fold)
10:19:27 <mastarija> right
10:19:28 <[exa]> mastarija: much more generically
10:20:35 <Cheery> ski: it makes sense, but how does this generalize actions?
10:20:38 <mastarija> [exa], I guess I've finally got the answer :D
10:20:44 <mastarija> [exa], thx
10:20:50 <ski> Cheery : oh, i haven't gotten to that, yet
10:21:19 <[exa]> mastarija: in particular, conduit allows you to insert the actions there and makes them run nicely and purely
10:21:54 <ski> Cheery : if we curry `(#) : M * A >---> A', we get say `act : M >---> Endo A', where `Endo A = A -> A'. note that `Endo A' is a monoid, for any set/type `A'
10:22:07 <ski> so, we can restate the action laws as :
10:22:15 <ski>   act 1 = id
10:22:23 <ski>   act (m * n) = act m . act n
10:22:46 * hackage ghc-byteorder 4.11.0.0.10 - "GHC.ByteOrder" API Compatibility Layer  https://hackage.haskell.org/package/ghc-byteorder-4.11.0.0.10 (HerbertValerioRiedel)
10:23:02 <ski> so, this just says that `act' is a monoid homomorphism, from the monoid `(M,1,(*))' to the monoid `(Endo A,id,(.))'
10:23:38 <[exa]> mastarija: like, a slightly more allowing (but different) version would become: `foldMPcap :: (Monad m) => (a -> Packet -> m a) -> a -> Filename -> m a`
10:23:45 <ski> so if you express actions in a curried way, they're just monoid homomorphisms into the endomorphism monoid on some type/set
10:24:15 <ski> Cheery : oh, and actions are quite common in math
10:25:55 <ski> (for any monoid, its binary operation is an action of the monoid, on its underlying set, is the most obvious general example)
10:25:57 <[exa]> mastarija: (btw note that this monadic version wouldn't allow you to easily terminate in the middle of the file, unlike the previous "foldr" one
10:26:03 <mastarija> [exa], yes that would be useful if I want to use state monad to do some processing that depends on previous results and such
10:26:22 <ski> Cheery : anyway, you know how a monoid can be considered to be a category, yes ?
10:26:30 <[exa]> mastarija: yeah, with State you don't even need the folding parameter because you can pass that through the monad
10:27:43 <[exa]> mastarija: say, `traversePcap :: Monad m => (Packet -> m a) -> Filename -> m a`
10:27:45 * hackage ghc-byteorder 4.11.0.0 - "GHC.ByteOrder" API Compatibility Layer  https://hackage.haskell.org/package/ghc-byteorder-4.11.0.0 (HerbertValerioRiedel)
10:28:03 <dsal> :t foldM
10:28:05 <lambdabot> (Foldable t, Monad m) => (b -> a -> m b) -> b -> t a -> m b
10:28:08 <Cheery> ski: Roughly. Aren't there several ways it can be considered a category?
10:28:26 <Cheery> but basically one way is to take the dot. and say that's the operator of your monoid
10:28:41 <ski> Cheery : well, two, if its not an abelian monoid
10:28:58 <mastarija> dsal, but foldM requires me to have 't a' which was my main pain point :D
10:28:58 <ski> yes
10:29:04 <[exa]> dsal: it would require a Foldable instance for a half-read file?
10:29:07 <dsal> mastarija: Yeah, I just saw that.
10:29:22 <ski> (the category of all monoids is a different thing)
10:29:50 <mastarija> Ok, thanks. Time to get to work :D
10:29:52 <ski> so, considering a monoid as a category, we get just one object, and (endo)morphisms on that object are the elements of the monoid
10:30:02 <[exa]> mastarija: btw the traversePcap would return `m [a]` if it would be correctest, I messed that one up. You probably want traversePcap_ that would return just `m ()`
10:30:14 <martinmch> If I do a takeWhile (/= ' ') "test       test", is there an easy way to get the remaining list, i.e. "       test"? 
10:30:26 <dsal> mastarija: I shouldn't've come to work. heh.   But as an alternative, if you're actually wanting to learn conduit, this is an interesting problem for it.
10:30:33 <[exa]> Is there a name for traverse that can decide to terminate in the middle? Preferably outside recursion-schemes.
10:30:38 <mastarija> [exa], I'll let the types guide me
10:30:44 <ski> Cheery : if we take two monoids, and consider them as categories, then functors between those two categories are nothing else than monoid homomorphisms between our original monoids
10:30:54 <[exa]> mastarija: take the right types then. :D
10:31:07 <mastarija> dsal, I'll first implement stuff manually and then reimplement it with conduit
10:31:15 <dsal> mastarija: That sounds correct.  :)
10:31:25 <mastarija> dsal, I kind of want to gain intuition of what's going on
10:31:37 <sheepfleece> Why does vector library stores data family in a type of Vector? As I understand Vector Bool "opens up" into Vector Vector Bool, where second Vector is a type family.
10:31:41 <sheepfleece> It seems confusing.
10:32:05 <dsal> Yeah, I kind of got a bit confused with your m [a] thing needing to go outside of the m to make the [a].  I don't have a good intuition as to how to make that lzy.
10:32:44 <sheepfleece> Here http://localhost:8080/file/nix/store/pkicdsxxvmxq4g28vxlhd9y9pbqpc1hi-vector-0.12.1.2-doc/share/doc/vector-0.12.1.2/html/Data-Vector-Unboxed.html#t:Vector
10:32:55 <sheepfleece> Oh, sorry, not that hoogle.
10:32:57 * ski looks at Cheery
10:33:16 <sheepfleece> https://hackage.haskell.org/package/vector-0.12.1.2/docs/Data-Vector-Unboxed.html#t:Vector
10:33:52 <Cheery> ski: I'm following, though..
10:34:42 <ski> Cheery : ok. so, instead of having `act : M >---> Endo A' be a monoid homomorphism between two monoids, we could have it be a functor, between those two monoids, considered as categories
10:35:43 <ski> Cheery : in fact, we can replace the codomain `Endo A' here by the category `Set', since the monoid `M', considered as a category, has just one object, and the functor `act' maps that to some object in the codomain, which is our `A'
10:38:17 <ski> Cheery : so, now we have a functor `act : M >---> Set'. next step now is to replace the one-object category `M' with any category, perhaps a small finite one. we could have a category with objects `Off',`On', and morphisms (apart from identities) `turnOn : Off >---> On',`turnOff : On >---> Off',`work : On >---> On' e.g.
10:38:57 <ski> where perhaps `turnOff . turnOn = id', and maybe even `work . work = work'
10:39:20 <ski> you can think of this as a state-diagram, with transitions that can take us from one state into another state
10:39:43 <ski> so, we can't "multiply" any two transitions together, but only if the "intermediate" state is the same
10:40:08 <Cheery> you introduce whole lot of constructs here, fortunately they're all fairly simple and similar.
10:40:51 <ski> and the functor `act' will now map the objects `Off' and `On' to actual sets (implementations / data types), and will map the specified transitions to actual functions that map from one data type to another, in a way which respects the laws of the state diagram
10:41:42 <ski> anyway, i'm basically done
10:42:16 <ski> the main point i wanted was the generalization from just one object in the monoid category, to multiple states
10:42:18 <Cheery> so functors in this case behave a bit like abstract datatypes.
10:42:35 <ski> well, the domain category rather, i'd say
10:42:53 <ski> while the functors/actions here describe possible realizations of them
10:43:39 <Cheery> hmm. yeah. functor in this case would be like.. description of implementing it.
10:44:36 <Cheery> it's interesting.
10:48:04 <Cheery> to me it'd seem like you could have just jumped to the last point about your category with On/Off/Work. I may miss the deeper ideas in the chain.
10:48:44 <ski> yea, perhaps. but i didn't recall how much background you had
10:49:36 <ski> (and, i suppose, with the intermediate steps, it could be more intelligible to onlookers/lurkers)
10:50:08 <ski> Cheery : btw, Lawvere has an interesting way to describe graphs, as actions
10:51:53 <Cheery> given a graph you may construct a category from it. then you got these actions you described as categories, and that whole thing looks a bit like finite state machine.
10:52:06 <Cheery> except that the focus is on transitions, like it perhaps often should be.
10:52:37 <ski> he starts with a monoid `<src,tgt | (forall x. x * src = src) /\ (forall x. x * tgt = tgt)>'
10:54:14 <ski> then we pick some set `A' whose elements are thought of as the nodes and the edges of the graph. to describe the source and target of each edge, we have an action `(#) : ST * A >---> A', where `ST' is the monoid just above (having three elements, `1',`src',`tgt')
10:55:54 <ski> we know `1 # a = a', and also `(x * y) # a = x # (y # a)'. in particular, we know x # (src # a) = (x * src) # a = src # a', and similarly with `tgt'
10:56:35 <WinchellsM> How to go from `[Just 1, Just 2, Just 3]` -> `[1,2,3]` and `[Just 1, Nothing, Just 3]` -> `[]`?  That is from, `[Maybe Integer]` to `[Integer]` such that we get `[]` in case any of the elements of the list are `Nothing`?
10:56:37 <ski> so, we call those elements `a' of `A', with `src # a = a' and `tgt # a = a', "nodes"
10:57:12 <Cheery> WinchellsM: :t mapM
10:57:18 <ski> WinchellsM : use `sequence', then go from there
10:57:29 <dsal> > sequence [Just 1, Just 2, Just 3] -- WinchellsM 
10:57:30 <lambdabot>  Just [1,2,3]
10:57:50 <ski> @type fromMaybe
10:57:51 <lambdabot> a -> Maybe a -> a
10:57:54 <Cheery> lmao.. I've been doing "mapM id" everywhere
10:58:07 <dsal> mapM is traverse.  traverse id is sequence.  :)
10:58:23 * ski . o O ( "War is peace." )
11:01:06 <ski> Cheery : anyway, i don't remember the details off-hand, but he's able to introduce several variants of graphs, e.g. allowing both bidirectional lanes between two nodes, and two separate unidirectional ones, in opposite directions
11:01:21 <monochrom> My freedom is your slavery. Your ignorance is my strength. (Parametric polymorphism and free theorems.)
11:01:40 <infandum> If I want to parallelize a Map.unionWith (each union takes a while), is it as simple as Map.unionWith (withStrategy rdeepseq . f)?
11:02:24 <Cheery> ski:  that graph presentation seems difficult. But I think I could look into it myself.
11:03:11 <ski> Cheery : "Sets for Mathematician" has a chapter on it
11:07:17 <WinchellsM> ski: (and everyone) thanks
11:12:15 <dsal> :t fromMaybe [] . sequence
11:12:17 <lambdabot> [Maybe a] -> [a]
11:12:37 <berndl> So I've read in a couple of places that monad transformers are pointed endofunctors on the category of monads. But, ContT doesn't satisfy this definition.
11:12:53 <ski> WinchellsM : do you know why `sequence' helps ?
11:15:15 <berndl> ContT always seems to defy attempts at categorizing it.
11:15:15 <ski> berndl : hm, i guess because it's invariant in the monad ?
11:15:45 * hackage calamity 0.1.8.1 - A library for writing discord bots  https://hackage.haskell.org/package/calamity-0.1.8.1 (nitros12)
11:15:48 <berndl> ski: Yes, it would end up being a pointed invariant endofunctor.
11:28:16 * hackage net-mqtt 0.7.0.0 - An MQTT Protocol Implementation.  https://hackage.haskell.org/package/net-mqtt-0.7.0.0 (dustin)
11:28:34 <dmwit> > [Just 1, Just 2, Just 3] >>= toList
11:28:37 <lambdabot>  error:
11:28:37 <lambdabot>      Ambiguous occurrence ‘toList’
11:28:37 <lambdabot>      It could refer to either ‘F.toList’,
11:28:40 <dmwit> > [Just 1, Just 2, Just 3] >>= F.toList
11:28:43 <lambdabot>  [1,2,3]
11:28:53 <dmwit> > [Just 1, Nothing, Just 3] >>= F.toList
11:28:55 <lambdabot>  [1,3]
11:29:11 <dmwit> whoops
11:29:20 <dmwit> > traverse F.toList [Just 1, Just 2, Just 3]
11:29:22 <lambdabot>  [[1,2,3]]
11:29:28 <dmwit> > traverse F.toList [Just 1, Nothing, Just 3]
11:29:31 <lambdabot>  []
11:30:20 <dsal> What is F ?
11:30:24 <dmwit> Data.Foldable
11:31:29 <berndl> I guess it would be more appropriate to say that monad transformers are pointed *endofunctions* on the category of monads.
11:32:08 <dmwit> What's an endofunction?
11:33:12 <berndl> A function whose domain and codomain are the same.
11:33:15 <monochrom> You can't just say "function" from a category to a category. Because there are objects and there are morphisms.
11:33:25 <dmwit> What is a function on the category of monads?
11:33:25 <monochrom> A category is not even a class.
11:33:54 <monochrom> Likewise you can't just say "function" from a graph to a graph.
11:34:18 <berndl> monochrom: True. I just say "on the objects of the category of monads".
11:34:26 <monochrom> There is much to say about how to map morphisms and edges.
11:34:38 <berndl> monochrom: whether a category is a class depends on my foundations.
11:35:58 <monochrom> sets :: mathematicians :: strings :: programmers
11:36:02 <monochrom> err
11:36:08 <monochrom> sets : mathematicians :: strings : programmers
11:36:30 <monochrom> completely unstructured things that no one should be using at all in the first place.
11:36:42 <monochrom> like why don't they just say "blob"
11:37:11 <berndl> Humans are lazy
11:37:19 <dmwit> ?unmtl ContT r m a
11:37:19 <lambdabot> (a -> m r) -> m r
11:37:32 <ski> @quote stark
11:37:32 <lambdabot> AlanPerlis says: The string is a stark data structure and everywhere it is passed there is much duplication of process. It is a perfect vehicle for hiding information.
11:37:39 <MarcelineVQ> monochrom: you've got blobs on the mind
11:38:06 <monochrom> Text.Attoparsec.Blob :)
11:38:07 <MarcelineVQ> I say binkey, blob's on the job
11:38:27 <dmwit> berndl: Why doesn't ContT satisfy the "pointed endofunctor" definition? Isn't `lift` the point?
11:38:45 <berndl> dmwit: It's the "functor" part that's the problem.
11:38:57 <berndl> mapContT doesn't cut it.
11:40:28 <ski> @hoogle hoist
11:40:28 <lambdabot> Pipes hoist :: (MFunctor t, Monad m) => (forall a . () => m a -> n a) -> t m b -> t n b
11:40:28 <lambdabot> Control.Monad.Morph hoist :: (MFunctor t, Monad m) => (forall a . m a -> n a) -> t m b -> t n b
11:40:28 <lambdabot> Streaming hoist :: (MFunctor t, Monad m) => forall a . () => m a -> n a -> t m b -> t n b
11:40:35 <ski> @hackage mmorph
11:40:35 <lambdabot> http://hackage.haskell.org/package/mmorph
11:40:35 <monochrom> Then either ContT is not a monad transformer or monad transformers are not pointed endofunctors on the monad category.
11:40:48 <ski> (note no `MFunctor (ContT o)' instance)
11:41:12 <berndl> Who here uses or has used ContT in production?
11:41:27 <monochrom> what about about 0? : numbers :: what about ContT? : monad transformers
11:42:24 <monochrom> Codensity may or may not enjoy/suffer the same considerations.
11:42:44 <monochrom> I think I know that people have used CodensityT in production.
11:43:15 <berndl> As a transformer?
11:43:19 <monochrom> Yes.
11:43:42 <remexre> do precompiled aarch64 cabal-install binaries exist? I've been chasing links in a circle for a few hours now...
11:43:45 * hackage net-mqtt-rpc 0.1.2.1 - Make RPC calls via an MQTT broker.  https://hackage.haskell.org/package/net-mqtt-rpc-0.1.2.1 (dustin)
11:43:55 <remexre> (outside of some distro's package manager, I mean)
11:43:59 * ski . o O ( "should we cite the crappy Gabor paper here?" <http://retractionwatch.com/2014/11/11/overly-honest-references-should-we-cite-the-crappy-gabor-paper-here/> )
11:44:30 <berndl> @hackage CodensityT
11:44:30 <lambdabot> http://hackage.haskell.org/package/CodensityT
11:44:56 <monochrom> remexre: what is aarch64 again? Is it arm? x86? arch linux?
11:45:17 <remexre> monochrom: the 64-bit version of arm; I mean for Linux
11:45:28 <monochrom> Ah OK, then I don't know.
11:48:46 * hackage net-mqtt-lens 0.1.0.0 - Optics for net-mqtt  https://hackage.haskell.org/package/net-mqtt-lens-0.1.0.0 (dustin)
11:56:06 <berndl> Hmm.. is there a type class with a maplike operation of the form (a -> a) -> f a -> f a?
11:56:21 <monochrom> Do you accept fmap?
11:56:45 <berndl> No, fmap uses two type variables
11:56:57 <monochrom> I think there is none.
11:57:18 <berndl> Maybe it's time to have one.
11:57:50 <monochrom> What are its laws?
11:57:51 <berndl> I'm thinking of calling the maplike function I mentioned endomap.
11:58:07 <berndl> monochrom: Same laws as a functor.
12:01:24 <mkru> I have a problem. Recursion leads to lack of memory. What might it mean?
12:03:45 <monochrom> Show actual code.
12:05:57 <mkru> monochrom: https://pastebin.com/vfyFsHaG
12:06:52 <monochrom> Could you point out which functions are recursive functions so I can save time?
12:07:29 <mkru> rozwiaz
12:07:46 <mkru> I mean there are more, but this is the one causing problems.
12:09:37 <Guest_68> do all elements in a list have to be the same type
12:09:50 <mkru> Yes
12:09:50 <monochrom> Yes
12:10:05 <mkru> use tuple :P
12:10:29 <Guest_68> thats what was confusing me, but the tuple is the element in the list right?
12:11:06 <remexre> tuples and lists are only related in that there's multiple things in one thing
12:11:48 <remexre> you can have a list of tuples, of course; but they're not intrinsically releated
12:16:09 * nil . o O ( is that what they meant by "Polish notation"? )
12:16:36 <monochrom> haha
12:18:44 <monochrom> mkru: It looks like roz is an infinite loop because sprawdz p ograniczenia is never true.
12:19:17 <mkru> No it is not true.
12:19:24 <mkru> It works for small examples.
12:19:40 <monochrom> I precisely tried small examples and got it to non-terminate.
12:19:50 <monochrom> You think I make claims without testing first?
12:19:55 <mkru> What do you mean by small?
12:19:58 <monochrom> 5
12:20:27 <monochrom> board size is 5x5.  Then I just keep entering 1,1,1 for my 5 trials.
12:20:44 <monochrom> or rather, lewa,1,1
12:20:49 <mkru> The algorithm computational complexity is really high because it is N^(N^2)
12:20:54 <mkru> try with 3x3
12:22:12 <monochrom> OK yes
12:22:35 <mkru> IN some cases it becomes infinite loop, but I have testing inputs, where I know it is not infinity.
12:22:45 <monochrom> That's time complexity. What space complexity do you expect?
12:23:04 <mkru> New, to Haskell, bit in C it would be fixed.
12:23:10 <mkru> but*
12:23:21 <merijn> nil: Fun fact, Polish notation is called that because colleagues of the programmer who invented it had trouble with his Polish name :p
12:23:22 <mkru> without recursion of course
12:24:01 <merijn> Oh wait, no, I'm thinking of Hungarian naming. Polish notation was apparently widely used in Poland :p
12:24:18 <remexre> hm, cabal's ./bootstrap.sh is using the host architecture when running under qemu; anyone know what it's using to detect it?
12:24:41 <nil> heh
12:26:52 <monochrom> OK it takes fixed space if compiled with -O
12:27:59 <mkru> any way to make it behaves this way in ghci?
12:28:28 <monochrom> No, ghci doesn't compile or optimize.
12:30:28 <merijn> ghci is a fun toy for testing/exploring, but it's not a production compiler :p
12:32:47 <mkru> Hmm, I get Could not find module ‘Prelude’ while trying to compile.
12:33:10 <merijn> Ooh! Is it Arch?
12:34:49 <mkru> Indeed.
12:35:10 <Guest83379> hi i'm trying to get ghcide to work with cabal, but it's not recognizing my dependencies. is there anywhere else i should put them other than the .cabal file at the root of the project?
12:35:32 <Ariakenom> narrator: The excited tone hid an unending despair. 
12:36:37 <mkru> Ok, -dynamic fixed the issue.
12:37:09 <merijn> mkru: Yeah, Arch's haskell packages are utterly broken
12:37:47 <mkru> I compiled, however: prj.exe: user error (Prelude.readIO: no parse)
12:37:50 <merijn> mkru: You wanna install ghc-static and avoid any of the libraries they package
12:39:37 <merijn> Ariakenom: I just like to brag about knowing the answer without even seeing the full error message :p
12:41:14 <mkru> With ghc-static I still get prj.exe: user error (Prelude.readIO: no parse) when I try to run.
12:42:09 <monochrom> mkru, you will have great fun figuring out and fighting output buffering. Oversimplified story: output isn't sent to screen until there is a newline.
12:42:10 <merijn> mkru: That's because you've got an error in your input
12:42:38 <monochrom> The consequence is your prompts are never displayed in time so you tend to enter wrong input.
12:43:30 <monochrom> What I did is since I already know how to enter valid input and when, I just enter it blindly without waiting for prompts.
12:43:53 <merijn> monochrom: Ever notice how technical people never mean fun when they talk about fun? ;)
12:44:22 <monochrom> I think accountants and lawyers do that to their colleagues too.
12:44:25 <mkru> Is it a joke, I use standard putStrLn and printf.
12:44:40 <monochrom> (Now let's fight over whether they count as technical :) )
12:45:01 <monochrom> putStr "Podaj rozmiar planszy: "   Tell me you know you did this.
12:45:41 <monochrom> putStr "Krawedz (1 - lewa, 2 - gorna, 3 - prawa, 4 - dolna): "   Tell me you know you did this.
12:46:08 <nil> are arch's haskell packages broken, or is GHC broken? dynamic linking is the standard almost everywhere else
12:47:04 <monochrom> arch's packages are broken.
12:47:07 <merijn> nil: Dynamic linking was added way later and is not the default usecase in Haskell, nor really even a sensible one
12:47:12 <mkru> monochrom: What is wrong with putStr?
12:47:26 <merijn> nil: GHC (and cabal) default to using static linking, because that's what's always been the default
12:47:33 <monochrom> I respect insisting on dynamic linking.  The arch packages are still implementing this mandate the wrong way.
12:47:44 <merijn> nil: Arch installs *only* dynamic libraries, but doesn't change/fix the defaults to match
12:47:45 <monochrom> No newline.
12:47:54 <nil> monochrom: what would be the right way?
12:48:22 <merijn> nil: Which means that if you use ghc with no special flags it will (as normal) try and link statically, and then barf, because they didn't install those
12:48:34 <nil> yeah, i've had that experience
12:48:41 <monochrom> See https://wiki.archlinux.org/index.php/Haskell#Problems_with_linking for what went wrong, I forgot the details but it's there.
12:48:50 <monochrom> But TL;DR incompetence.
12:48:53 <nil> is there a configuration flag to make -dynamic the default?
12:49:27 <merijn> nil: tbh, you probably shouldn't. There's really not much point to dynamic linking Haskell code
12:49:41 <monochrom> Or what merijn said.
12:50:10 <nil> why is haskell special in that regard?
12:50:12 <nshepperd> even if the default was changed or the static libraries were added too, there's still the problem that stuff installed in the global package db interferes with your build if you want different versions
12:50:16 <monochrom> I also take it back: I disrespect insisting on dynamic linking.  (I also disrespect insisting on static linking.)
12:50:34 <monochrom> I disrespect all inflexible dogmatic doctrinal ideologies.
12:50:36 <nil> i've read that GHC relies a lot on inlining, but that sounds like an implementation detail that could easily be worked around if dynamic linking was the goal
12:50:42 <monochrom> THERE ARE ALWAYS EXCEPTIONS
12:50:54 <merijn> nil: The problem is that GHC does cross package inlining
12:51:02 <monochrom> No, don't worry, inlining is orthogonal.
12:51:14 <merijn> nil: Therefore package A (depending on package B) can and *does* leak implementation details of B transitively
12:51:31 <monochrom> It doesn't stop you from dynamic linking, it just means most benefits of dynamic linking disappears.
12:51:31 <nil> would it hurt performance too much to stop doing that?
12:51:45 <monochrom> This is what's wrong with nflexible dogmatic doctrinal ideologies.
12:51:49 <merijn> nil: It's essentially never possible to upgrade library A without *also* recompiling everything depending on A, so that's one advantage of static linking out the window
12:52:00 <merijn> nil: Yes, tbh
12:52:04 <monochrom> I only respect cost-benefit analyses.
12:52:39 <monochrom> If you don't inline you lose all other optimizations.
12:52:47 <nil> i see
12:53:01 <monochrom> All those fusions so important for the last ounce of performance.
12:53:33 <monochrom> Because you always write code like "foo . bar" where foo and bar come from two different packages.
12:53:38 <nshepperd> ever since arch did the dynamic linking thing, installing any haskell binary means you get a bunch of dependent libraries installed in the global package db
12:53:52 <nshepperd> resulting in 100s of complaints about being unable to build things with cabal
12:54:03 <monochrom> If you leave "foo" and "bar" as blackboxes, there can be no fusion. You must open them up to see fusion opportunities.
12:54:32 <merijn> nshepperd: Worse, they all blame haskell, instead of Arch :(
12:54:55 <monochrom> This is what's wrong with religious people.
12:55:00 <nil> so i guess it's a tradeoff between performance on one side, and the benefits of dynamic linking on the other
12:55:01 <Uniaika> **triggered**
12:55:16 <monochrom> When there is a problem involving their religion and an external factor, their religion is always right.
12:55:26 <Uniaika> I have PTSD flashbacks from Arch
12:55:55 <oats> arch's haskell situation is awful, but if you just use stack-static you'll be alright :)
12:55:57 <monochrom> I do use dynamic linking in one context, mind you.
12:56:31 <[exa]> anyway
12:56:37 <monochrom> I compile a hundred student's haskell files for automarking by test cases.  This is when dynamic linking actually saves disk space.
12:56:53 <oats> monochrom: makes sense
12:56:55 <[exa]> is there any "right" practice of packaging haskell packages for binary distros?
12:57:00 <nshepperd> this wouldn't be such a problem if all the haskell library packages installed to a different location
12:57:27 <nshepperd> so that you would have to use 'cabal --arch-package-db' or something to have it see them
12:57:29 <monochrom> Just don't expect "I built my dynamic exe by ghc 8.6.3, I now expect that it will load ghc 8.6.5's libs when I switch over"
12:57:38 <[exa]> (debian is pretty good with that but still a lot to be desired)
12:57:52 <nil> monochrom: the main benefit of dynamic linking i have in mind is not having to recompile everything when openssl gets a security fix
12:58:01 <maerwald> [exa]: debian is usually the worst example for anything packaging related :P
12:58:02 <monochrom> haha
12:58:31 <[exa]> maerwald: ok wow, please elaborate
12:58:33 <monochrom> dynamic linking makes perfect sense for weak languages like C and weak compilers like gcc. :)
12:59:00 <maerwald> [exa]: just a general shot. But there's nothing particularly special about haskell binaries. They are treated like other pre-compiled binaries.
12:59:04 <monochrom> (Definition: If it doesn't do whole-program analyses and optimizations, it's weak :))
12:59:21 <maerwald> as for libraries: don't go there
12:59:39 <monochrom> (Definition: If a language doesn't enable you to talk about fusion, it's weak. :) )
12:59:42 <[exa]> maerwald: binaries are pretty straightforward, but what about precompiled libraries?
12:59:52 <[exa]> oh so
12:59:58 <maerwald> It's too hard
13:00:06 <maerwald> Gentoo tried it
13:00:09 <maerwald> it's still a mess
13:01:48 <merijn> nil: Right, but with Haskell libraries you have to recompile anyway, since they GHC doesn't have a stable ABI and due to inlining (also, note that GHC does link C libraries dynamically by default, so it's just Haskell libraries being linked statically)
13:02:01 <monochrom> I am interested in hearing the general-shot problem too.  I use Ubuntu and I don't feel a problem.  What is the problem?
13:02:22 <[exa]> maerwald: so, from packaging perspective, is something breaks&gets fixed in a library, all its revdep programs need to be repackaged to get the bump?
13:02:26 <nil> merijn: i see
13:02:48 <maerwald> [exa]: ABI is unstable, right?
13:02:55 <maerwald> So yeah
13:03:15 <merijn> maerwald: If you don't change your GHC version it should work
13:03:16 <[exa]> yes. kindof breaks the tangible modularity of the software
13:04:17 <maerwald> monochrom: not so much a user-facing problem, but debian likes to play upstream (see the OpenSSL debakle, but also less known things like messing with SONAMEs of libraries, adding files that don't exist upstream, breaking cross-distro compatibility, ...))
13:04:19 <[exa]> well even without ABI changes, code that gets inlined to the binary can be different
13:04:52 <monochrom> I think Debian solved that problem for Haskell libraries by choosing a very old version of GHC and libraries so there is nothing to fix because no one is fixing the old versions anyway!
13:05:19 <maerwald> that's a great approach that makes the point of dynamic libs moot :P
13:05:48 <[exa]> monochrom: 8.8.1/8.6.5 is unmaintained?
13:06:05 <monochrom> I have simply learned the very simple but true model that Debian defines "stable = outdated"
13:06:39 <monochrom> I don't think Debian has even caught up to 8.4
13:07:19 <maerwald> My favorite instance of debian messup was when they changed SONAME of some media library. Skype upstream built their binaries on a debian box and it broke on all other distros.
13:08:20 <maerwald> don't build your binaries on a debian box :P
13:09:05 <monochrom> Heh OK! No wonder your ghcup chose a built-on-fedora GHC for me.
13:09:09 <maerwald> yes
13:09:12 <merijn> [exa]: He's talking about the libraries, not the compiler
13:09:33 <[exa]> oh so
13:09:38 <[exa]> well, yes
13:10:17 <[exa]> the second problem is that the most important motivation for haskell in debian is currently pandoc, which isn't much shiny itself
13:11:04 <maerwald> I'm still procrastinating static GHC, which, according to ben should be possible: https://gitlab.haskell.org/ghc/ghc/issues/17878
13:11:13 <maerwald> Then maybe this should be the default
13:12:56 <maerwald> [exa]: is there no static binary of pandoc?
13:14:12 <maerwald> Well, it is statically linked it seems
13:14:16 <[exa]> the libraries are build deps
13:14:31 <[exa]> whoa, nice 118M binary
13:14:54 <monochrom> :)
13:14:57 <[exa]> not that far from go, docker binary has like 50MB too
13:15:04 <maerwald> I wonder if they do the split-sections thing
13:15:20 <[exa]> no idea
13:15:27 <[exa]> still I find this kind of binary size a bit....unnerving
13:15:40 <maerwald> pandoc binary is 68mb here
13:15:44 <monochrom> <roast> split-sections probably doesn't exist in the archaeological ghc version they use </roast>
13:16:55 <maerwald> The Outlaws game from 1997 was 30mb on disk
13:17:20 <[exa]> monochrom: 8.6.5 it seems :]
13:17:21 <nshepperd> my favourite system administration activity is symlinking libfoo.so.6 to libfoo.so.5 to make my applications keep working
13:17:44 <Guest_68> Can someone give a dumbed down definition of a monad? im still struggling 
13:18:00 <monochrom> 8.6.5 has split-sections
13:18:03 <maerwald> Guest_68: a programmable semicolon
13:18:19 <maerwald> lol
13:18:35 <monochrom> You ask for dumbed down, you get dumbed down.
13:18:39 <[exa]> maerwald: seems the explanation was satisfactory!
13:18:43 <maerwald> haha
13:18:45 <monochrom> You feel better but it's completely useless.
13:19:28 <monochrom> Why do people pursue useless information just to feel good.
13:19:40 <[exa]> Guest_89: how much "dumbed down" btw?
13:19:45 <maerwald> maybe it was actually an exercise "describe monads with your own words"
13:19:52 <monochrom> This is not a meditation group.
13:20:10 <dolio> Yeah, it's even easier to tell yourself that seeking information isn't worth it at all.
13:20:12 <EvanR> monochrom that question has its own answer embedded
13:20:27 <nshepperd> help i'm being dumbed down
13:20:35 <dsal> Guest_89: Simple explanations don't necessarily make sense.  I don't think you'd explain two phase commit to a three year old.
13:21:03 <monochrom> Yes "to feel good" would be a great reason for a meditation or mindfulness or yoga group.
13:21:21 <EvanR> Guest_89: wait. the normal definition of the monad is already pretty dumb
13:21:30 <Cheery> Guest_89: how are you struggling?
13:21:31 <monochrom> But you come to #haskell to write correct programs, not to feel good.
13:21:35 <maerwald> who are you guys talking to?
13:21:48 <nshepperd> I see that base-4.14.0.0 is now on hackage. i'm glad to see that impasse was seemingly resolved
13:21:54 <dsal> Writing correct programs makes me feel good.
13:21:57 <monochrom> So why would you pursue information that only makes you feel better but doesn't get any code written at all.
13:22:06 <EvanR> don't cross the Guests
13:22:09 <monochrom> Like, go to a yoga class instead.
13:22:12 <Guest_89> ill stop asking "useless" questions im just a beginner trying to learn haskell, and monads are a tricky concept for me to wrap my head around, no need to kick me
13:22:18 <dsal> I'm also a yoga teacher.
13:22:42 <dsal> Guest_89: Check out haskellbook.com
13:22:43 <EvanR> start with Functor
13:22:47 <maerwald> now this makes me thinking... a haskell meditation group might be an interesting thing
13:22:49 <EvanR> not Monad
13:23:06 <Qfwfq> Is 'elimSum :: (Functor f, Functor g, Functor h) => (Free f x -> Free h x) -> (Free g x -> Free h x) -> Free (Sum f g) x -> Free h x' inhabited?
13:23:18 <maerwald> You start with a question, go into deep meditation and discuss your insights in a group of hardcore nerds
13:23:34 <maerwald> Or maybe I'll go play some games instead
13:23:40 <monochrom> :)
13:24:03 <dolio> monochrom: Why are there hundreds of 'one trick for doing a handstand' videos that won't work?
13:24:54 <dsal> dolio: Here's my one trick for doing a handstand video:  https://www.youtube.com/watch?v=o8NCOszwe7o
13:25:02 <Cheery> Guest_89: monad is a structure where the subsequent values depend on prior values somehow.
13:25:04 <Qfwfq> Guest_89: Probably not a one-size-fits-all-thing, specific questions help.
13:25:10 <monochrom> I don't know, but at least they or their audience don't come to #haskell and ask about monads.
13:25:11 <dsal> Same reason I recommend haskellbook.com -- the slow path is often the quickest way there.  :)
13:25:15 <maerwald> Cheery: not just values, even effects
13:25:29 <maerwald> subsequent effects AND values depend on prior values
13:25:40 <Guest_89> Im sorry if I offended you monochrom
13:26:06 <monochrom> No no, I just don't understand what good "dumbed down" does.
13:26:27 <Cheery> Guest_89: did that clear it up?
13:26:58 <Guest_89> cheery yes thats what i was asking
13:27:15 <Guest_89> subsequent wasnt too complex of a word for me
13:27:51 <dsal> In reverse state, prior values depend on subsequent values.
13:30:15 <merijn> maerwald: I recommend Into the Breach ;)
13:30:28 <Cheery> Guest_89: it's an abstractly described structure that appears often. In I/O it forces you to schedule an event before you can access the value in the program.
13:30:33 <maerwald> merijn: I'm back to kotor
13:30:58 <ski> Guest_89 : i'd say monads are about expressing sequencing (in a particular sense)
13:31:11 <merijn> maerwald: Ah, never played that, and I already have a waiting list of "long RPGs" I need/want to finish first :p
13:31:18 <Qfwfq> [elimSum] I think it only when f and g are comonads, so, nah.
13:31:52 <maerwald> merijn: it's cooler when you're young, because the dialogues seem so deep. 
13:32:06 <ski> Guest_89 : also, i'd say that it's probably better to focus more on specific monads, see how they work, get some experience with that, and only then try to grasp what the general "monad" concept is about
13:32:36 <monochrom> EvanR's suggestion is the best so far.  Start with Functor.
13:33:17 <Cheery> There's operational understanding and then there's theoretical understanding
13:33:28 <Cheery> the latter is needed if you define your own monads
13:33:47 <rotaerk> in terms of abstraction order, do Functor, then Applicative, then Monad ... but within each abstraction, focus on specific examples/instances, understand each in isolation, and you'll start to intuit a common pattern
13:34:13 <Guest_89> Thank you, ski & cheery, I was just confused that everytime I saw monad it seemed to be representing something different, i understood there were different ones but i couldnt put an understanding to the theory
13:34:39 <Cheery> The point is to get representations of things that hide the details for a moment, so that structures are easier to understand.
13:34:45 <ski> Guest_89 : yes, it's a quite general concept, and specific instances of it tend to look wildly different, at least at first sight
13:34:56 <monochrom> We also need to ask more often "why do you ask?" and "what do you already know?"
13:35:42 <Cheery> You know.. for example, if you got numbers, you don't worry whether they're rocks or sticks, or you got paper.
13:36:09 <Cheery> you know you can shift piles of rocks around, etc.
13:36:10 <monochrom> In the same way when there is "how to fix syntax errors?" the correct respond is "show actual code" not answer the overgeneralized question.
13:36:24 <ski> Guest_89 : you know about different kinds of (abstract) data structures, which may admit multiple implementations, right ? e.g. different ways to implement a stack, or a queue, or a priority queue, or a heap
13:36:37 <Cheery> without changing the meaning of the expression.
13:37:51 <Guest_89> ski yeah ive done plenty of C/JS just never ran into Monad
13:38:05 <Cheery> Guest_89: if you remove the requirement of dependence, you just got a list. It's called a monoid
13:38:23 <ski> Guest_89 : well, think of "monad" as "just another abstract data structure, with specified operations", having multiple implementations
13:38:34 <Cheery> and since these are so simple constructs, they appear often
13:38:52 <maerwald> "Monads? They're just promises, right?" -- A Go developer
13:39:24 <ski> Guest_89 : only, to be able to do much useful with a monad, you general need to know more about it, than it just being a monad. while, for a priority queue, you'll know which implementation you've chosen, when you get the initial one, say, but from then, you don't have to care about which implementation you're using
13:40:18 <monochrom> It is possible that monads equals promises.
13:40:49 <monochrom> But I say it just because my idea of "promise" is vague and may be wrong.
13:41:04 <Cheery> Promises are aptly named.
13:41:21 <ski> (there are some useful operations, like `sequence :: Monad m => [m a] -> m [a]', `forever :: Monad m => m a -> m b', which applies to any monad, without knowing more specifics. but in any complete program using monads, these will only be part of working with the monad, you'll normally have a lot of operations that's specific to the particular monad you're using)
13:41:23 <rotaerk> do you promise?
13:42:29 <maerwald> monochrom: I just refuse to give an answer to that question.
13:42:42 <monochrom> :)
13:43:14 <rotaerk> generally the point of any abstraction is to write things in terms of it that automatically works for any instance of the abstraction; if there was no such thing as a function (or in haskell's case, a notation) that worked for all monads, then the monad abstraction wouldn't be particularly useful
13:43:44 <ski> yes
13:43:46 <rotaerk> but even without the abstraction, the type-specific implementations can still be useful
13:43:58 <rotaerk> the abstraction just ties them together under the same umbrella
13:46:54 <rotaerk> Guest_89, so perhaps one thing that might help you to understand the functor, applicative, and monad abstractions is ... first understand the fmap, <*>, pure/return, >>=, etc functions for specific types, then look at the functions defined generally for all functors, applicatives, and monads, and see how *those* work for the specific types
13:47:15 <rotaerk> e.g. see how sequence works for different types
13:47:47 <Guest_89> Thank you all for the help, I think ive got enough to ponder for now
13:47:53 <rotaerk> :P
13:48:22 <Guest_89> computerphile made a video on monads and the top comments all seem to follow 
13:48:26 <Guest_89> Haskell programmer here for the lols. You never understand monads, you just get used to them. Until you understand them. Then you realize you've fused with the machines.
13:48:54 <Guest_89> so it looks like i need to play with them more to grasp them
13:49:30 <dsal> Guest_89: Working up from function to functor to applicative to monad with a variety of each makes it all make sense.
13:49:35 <rotaerk> the big mistake people make is to try to understand the abstract concept of "monad" by analogy or something
13:49:40 <rotaerk> tto have the concept *explained* to them
13:49:56 <rotaerk> but understanding is best intuited through exposure to examples
13:50:24 <rotaerk> I don't agree with that comment though. you *do* come to understand monads
13:50:28 <monochrom> I get used to numbers and monads.  What does "understand" mean?
13:50:51 <maerwald> rotaerk: it's just over-advertised and hyped to the point that people think there must be this huge difficult to graph thing behind it
13:51:06 <maerwald> some hidden knowledge
13:51:09 <dolio> It's not very difficult to understand what monads are doing in Haskell, but it requires an applied-mathematics approach to programming that most people don't have.
13:51:16 <rotaerk> maerwald, yeah
13:51:22 <dolio> And you need to know the mathematics to apply.
13:51:29 <monochrom> I can only understand that "understand" is a subjective feeling that is prone to Dunning-Kruger and therefore wrong.
13:51:36 <rotaerk> another common misconception is that "monads" are what allow I/O in haskell
13:51:44 <Qfwfq> that's an unhealthily exclusionary meme :(
13:51:55 <maerwald> this maths-stuff is debunked by multiple researches already, proving that natural language skills are way more important for learning programming languages than maths is :)
13:52:00 <Guest_89> ive got plenty of math haha
13:52:11 <dsal> Obviously it's functors that allow IO in Haskell.
13:52:26 <ski> Guest_89 : in any case, before attempting to tackle `Functor',`Applicative',`Monad', you should first understand (to some degree) `data' types, with parameters; polymorphism; higher-order functions; type classes
13:53:22 <monochrom> As an example, I use this very simple but effective model of beginners. Their brain has a backend that guesses correctly >70% of the time, and a frontend that's a not-gate.
13:53:27 <dsal> Guest_89: haskellbook.com walks you from simple values, types, functions, functors, etc...  With cases of each, and the path is slow but very helpful if you want to understand all the things.
13:54:03 <ski> what is, Qfwfq ?
13:54:14 <monochrom> I don't know why this model works, but it so works, so I get used to it.  If you don't know that I'm using this model secretly, and can only observe that I make pretty good predictions about beginners, you would think that I "understand" them.
13:54:39 <rotaerk> monochrom, lol wtf
13:55:36 <ski> i "understand", monochrom
13:55:55 <rotaerk> I don't think understanding is about being correct
13:55:59 <maerwald> so it's 30%
13:56:10 <maerwald> at best
13:56:55 <monochrom> I have more models like this.  Simple cynical but good-enough models of various kinds of people.  E.g., for people with strong but irrational opinions, I model them as "memoizing random number generator".
13:57:10 <rotaerk> lol
13:57:34 * ski . o O ( simulated annealing )
13:57:50 <monochrom> And if I tell you more of these cynical models, I become a very controversial person, i.e., your opinions about me are very polarized.  One side will say that I'm too cynical, the other side "you have deep insight into human nature".
13:58:17 <dolio> monochrom: Oh, that's like Brouwer's creating subject arguments.
13:58:25 <maerwald> What's your model of a troll then?
13:58:44 <ski> monochrom : can one be on both sides ?
13:59:01 <monochrom> I think I'm on both sides! :)
13:59:14 <dsal> There are three types of people, but I'm afraid you're not one of them.
13:59:44 <ski> rotaerk : more about internal coherence ?
14:00:21 <monochrom> But ObTopic, I am thinking over the equivalence between monadic programming and callback-based programming.
14:00:58 <rotaerk> yeah, and intuition
14:01:13 <monochrom> I think we can take advantage of the fact that a lot of programmeers have gotten used to callback-based programming, and we can simply define monads for them by a simple transformation.
14:01:14 <ski> (don't get monochrom started on intuition .. :)
14:01:19 <rotaerk> but understandings, no matter how intuitive, are still just models, which can prove to be wrong
14:01:20 <monochrom> haha
14:02:02 <monochrom> a wrong model is still better than an irrefutable model ("not even wrong")
14:02:11 <rotaerk> heh
14:02:14 <dolio> Well, monads are about describing algebraic theories, and abstract algebra is actually about continuation passing style.
14:02:28 <dolio> A very limited form.
14:03:21 <ski> monochrom : well, "Web Programming" by Eli Barzilay at <http://tmp.barzilay.org/cont.txt> is an introduction to continuations ..
14:03:45 <ski> elaborate on the CPS, dolio ?
14:04:00 <dolio> The 'sort' is the answer type.
14:04:37 <ski> which sort ?
14:04:40 <dolio> And operations are described by arities `n -> m` that induce operations on continuations `a^m -> a^n`.
14:04:55 <ski> the carrier of the algebraic signature ?
14:04:57 <dolio> The sort of the algebra. The carrier.
14:05:26 * ski . o O ( abstract vs. concrete duality )
14:06:17 <ski> polynomials looks like nqCPS, to me
14:06:51 <dolio> When you do algebraic effects, you generalize to arities that aren't finite.
14:08:50 <dolio> If you don't fully translate to continuations, then the operation `n -> m` is `n * a^m -> a` So, you get the argument, and the continuation to provide the `m` for.
14:09:01 <ski> hm, i'm also reminded of "covariant exponentials", something like `R^(n)', which would be covariant in `n'
14:10:53 <Cheery> I'm probably getting to this later on the summer, but I could ask it now anyway.
14:11:28 <Cheery> If you were to use very abstract types, eg. "Int" refers to mathematical integer.
14:11:32 <ski> dolio : hm, so you're calling the "output index" (?) in `n' the "argument" ?
14:11:53 <Cheery> Is there some existing ideas about optimizing such programs?
14:11:56 <dolio> Oh, did I flip them accidentally?
14:12:30 <ski> (i have noticed the CPSy look of `n'-ary operations on bits, `2^n -> 2', before)
14:12:31 <dolio> No, I don't think I did.
14:12:42 <ski> no, you didn't flip accidentally
14:13:10 <ski> hm, i guess you call it "argument", since it's on the domain/input side in `n -> m'
14:14:10 <ski> i'm still not really following you that well though, i think, dolio
14:15:13 <Cheery> If you wanted to separate optimizations from program descriptions, would Haskell already have something for that?
14:15:22 <Cheery> except typeclasses.
14:15:30 * ski . o O ( matrices )
14:19:18 <dolio> Yeah. The effect signature is like `putChar : Char -> ()`. This induces an operation `a -> a^Char` on the model. In the free model it's a constructor `PutChar : Char -> Free -> Free`.
14:21:01 <dolio> The free model is like the tree version of IO.
14:21:11 <ski> hm, i see. interesting
14:21:17 <ski> where can i read about this ?
14:21:22 <EvanR> the tree version of IO
14:21:32 <EvanR> what's that
14:22:12 <dolio> ski: Algebraic effects papers by e.g. Plotkin and Power, but also other folks.
14:22:15 <ski>   data IO a = Return a | PutCharThen Char (IO a) | GetCharBind (Char -> IO a) | ...
14:22:21 <ski> presumably something along those lines
14:22:37 <dolio> Yeah, that one.
14:22:53 <EvanR> oh
14:24:09 <dolio> There are always two views of these things, too. `n -> m` is the 'generic effect' signature, where you think of it as an abstract 'function' from n to m. Then there's the 'operation' view, on the model which shows up more in mathematical algebra.
14:24:43 <dolio> Like, `mplus :: m -> m -> m` is an operation that corresponds to the effect `() -> Bool`.
14:24:55 <ski> yea, i see
14:25:34 <ski> still, the exponent in the codomain in `a^m -> a^n' surprised me, i guess
14:25:51 <dolio> Yeah, that confused me the first time I saw it, too.
14:26:29 <ski> what about polynomial functors, `F'-algebras ?
14:26:52 <ski> oh. it was mniip who i talked to, last time, about that
14:32:01 <dolio> I'm not sure.
14:33:57 <Guest_89> repeat = 2
14:34:32 <Guest_89> myList = take 10 ["hey" | i<-[1..repeat2]]
14:34:37 <ski> seems <http://tunes.org/~nef/logs/haskell/20.05.09> has that exchange
14:34:48 <dolio> ski: (Σ m_i * a^i) -> a  ==>  Π (a^i -> a^m_i), so maybe that translates into a bunch of effects.
14:35:34 <ski> ("Higher Inductive Types as Homotopy-Initial Algebras" by Kristina Sojakova in 2016-08 at <http://reports-archive.adm.cs.cmu.edu/anon/2016/CMU-CS-16-125.pdf> was referenced)
14:36:44 <ski> dolio : and the `m_i' are the constant sorts ?
14:37:16 <ski> Guest_89 : there is already a standard function named `repeat', btw
14:37:27 <dolio> No, a is the sort. m_i and i are arities.
14:37:57 <ski> > let repeat = 2 in take 10 ["hey" | i <- [1 .. repeat]]
14:37:59 <lambdabot>  ["hey","hey"]
14:38:34 <dolio> I.E. an algebra of that polynomial might be an algebra of the effects given by `m_i -> i`, if I had to guess.
14:38:38 <Guest_89> yeah it works in the terminal but wont compile
14:39:06 <ski> Guest_89 : in the interactor, you're likely shadowing the in-scope `repeat' (from `Prelude')
14:39:34 <dolio> I'm not certain if that actually works out, though.
14:39:56 <ski> dolio : could you describe what "arity" means, here ?
14:40:28 <Guest_89> my bad it was unrelated thanks ski
14:41:26 <dolio> ski: It comes from these being based on Lawvere theories, so the effect `1 -> n` induces an n-ary operation on the carrier.
14:42:03 <dolio> But generalized to infinite arities.
14:42:17 <ski> consider vector spaces over a ring `R'. we have one carrier `V'; operations `z : V',`a : V -> V -> V',`s : R -> V -> V', which we could summarize as `1 + V^2 + R*V -> V'. here `R' is a constant sort
14:42:43 <ski> (could have included additive inverse as well, i guess)
14:43:32 <dolio> Mathematicians go out of their way to not include R as a sort.
14:43:43 <dolio> (I think.)
14:43:43 <ski> so, i guess i was wondering, whether in the scaling case, you'd have `V -> V^R'
14:44:05 <dolio> Instead they have R-many unary operations and such, I think.
14:44:23 <ski> seems a bit clunky, to me ..
14:44:30 <dolio> Yeah, well, I agree. :)
14:45:22 <dolio> The algebraic effects stuff technically wouldn't do it like this, either, since they usually say they're doing 'countable' Lawvere theories. But maybe you could have ℝ as an arity, too.
14:45:40 <ski> hm, i was reading the other day about "stuff", structure, and properties
14:47:20 <ski> "Lectures on `n'-categories and cohomology" by John Baez (talks),Michael Shulman (notes) in 2006 - 2007 at <https://arxiv.org/abs/math/0608420>. see section 2.4 (which is what i jumped to)
14:47:52 <ski> hm, is there some particular reason for the countable ?
14:53:11 <dolio> I don't know. I mean, there's a reason that finite isn't good enough (you want signatures with non-finite types), but I don't know about the other end.
14:53:28 <ski> mm
14:54:41 <monochrom> You could weaken "real number scalars" to 'rational number scalars" if necessary.
14:55:10 <dolio> I think people are really using them with things that aren't countable internally, at least.
14:55:52 * ski imagines cauchy sequences of vector spaces
15:07:57 * ski . o O ( ".. Grothendieck dreamt of a much bigger generalization of Galois theory in his 593-page letter to Quillen, Pursuing Stacks." )
15:11:28 <monochrom> Did that result in adjunctions?
15:13:16 <ski> iirc, Kan introduced adjunctions. i dunno when that latter above was written
15:16:13 <dolio> Stacks are much more complex than adjunctions. :)
15:16:59 <dolio> Apparently it's more accurate to say something like, 'that led to univalence.' But I don't really understand how.
15:23:18 <dolio> ski: So, I think that translation above seems kosher. So, for instance, the effect algebra for lists of `a` is `write : a -> ()` and `done : Void`.
15:24:40 <ski> hm, okay
15:26:08 <dolio> P(x) = 1*x^0 + a*x^1 ==> (1 -> 0, a -> 1)
15:29:16 <ski> hm, `a^i -> a^m_i' would suggest each coefficient being determined by its corresponding exponent
15:29:52 <ski> (and, i guess, that should have finite support)
15:31:29 <ski> (now i'm wondering about some non-trivial monoid of exponents, without decidable equality ..)
15:31:31 <dolio> I mean, that's just how polynomials are specified, right?
15:32:27 <ski> yea, polynomials are just the monoid ring, where the monoid is the free monoid on the set of indeterminates
15:32:42 <ski> (well, i suppose we want commutativity in there)
15:33:53 <dolio> Exponents can be whatever you want in this setting, but you (obviously) need finitely many exponents to write it down in something with algebraic signatures as declarations.
15:35:01 <ski> yea. i'm thinking of rings, which don't have arbitrary sums
15:35:06 <dolio> So I guess it doesn't handle all 'polynomial functors' with initial algebras in e.g. Agda.
15:37:10 <dolio> I guess you could generalize my breakdown to Σ c_i * a^p_i.
15:37:40 <dolio> Where i ranges over a finite set.
15:38:33 <dolio> Unless you're generalizing away from a concrete syntax.
15:38:52 <ski> (that makes me think of some kind of coends ..)
15:59:27 <dsal> I started reading https://www.parsonsmatt.org/2020/05/07/on_pvp_restrictive_bounds.html -- but it's more of a discussion than what I'd consider an article.
15:59:37 <dsal> I ran into an annoyance with restrictive upper bounds today.
16:00:40 <dsal> I had to rev a version because I changed something rather obscure it's unlikely many people care about (of my millions of users).  Then I broke a build for something that upgraded my library, but not another library that had a restrictive upper bound on it.
16:54:11 <monochrom> I agree that we need more modal operators.
16:54:40 <monochrom> But whoever recommends semver over pvp misunderstands both.
16:55:54 <monochrom> because their only difference is the syntactic "how many bytes for the major version field".
16:57:44 <Guest_29> wavemode
16:58:00 <Guest_29> im done
18:37:49 <justsomeguy> Should I learn cabal in addition to stack?
18:39:15 <Welkin> yes
18:39:18 <Welkin> don't bother with stack
18:39:21 <Welkin> cabal is all you need
18:39:29 <Welkin> stack, in fact, uses cabal without you knowing
18:41:48 <justsomeguy> I've been a little confused as to when I should edit stack.yaml versus projectname.cabal ... I guess I'll just read up on both of them. If I wasn't following along with a book that uses stack in its examples I'd probably just ditch stack.
18:42:08 <Welkin> stack is just stupid at this point
18:42:14 <MarcelineVQ> the docs cover that sort of confusion https://docs.haskellstack.org/en/stable/stack_yaml_vs_cabal_package_file/
18:42:20 <Welkin> it's caused nothing but confusion, especially for new users
18:44:19 <monochrom> I haven't learned stack. But that's just because I haven't needed it as a teacher and hobbyist.
18:44:52 <monochrom> For some production purposes (though not all) it is still valuable to learn stack, but take your time.
18:45:28 <monochrom> A good heuristic is if you are doing fine then you don't need to learn a thing that you don't even know whether you need it.
18:45:56 <monochrom> In fact, likewise for monads and lens.
18:46:06 <monochrom> and many GHC language extensions.
18:46:35 <justsomeguy> Sure. It doesn't seem too much different from something like npm or poetry (python wrapper for venv + pytest). Right now the confusing part is how cabal and stack interact right now. But I'll take it slow.
18:46:54 <Welkin> cabal has a library and an executable. Stack uses the library
18:47:12 <Welkin> cabal is the only official build tool for haskell
18:47:17 <monochrom> Rather than spending days pouring yourself over thousands of blogs and getting into puzzling conversations in #haskell, why not take it easy and just accept "not ready for it = not need it for now"
18:47:34 <MarcelineVQ> calm down boys
18:48:20 <justsomeguy> I'm following along with the chapter of haskell programming from first principles that focuses on stack. For my everyday programming I'd be fine using cabal or my linux distros package manager, or whatever.
18:48:39 <monochrom> I am just still not quite over an earlier question from a beginner "what is monad, in dumbed down terms?"
18:48:57 <monochrom> If you need it dumbed down, perhaps you don't need to worry about it at all for now.
18:49:29 <monochrom> I don't understand why people work in a most-haste-less-speed mode.
18:49:34 <justsomeguy> Ok, that sounds like a different thing. I had a particular question, it's not the same as asking for dumbing down.
18:49:39 <Welkin> something I have learned from elm (and f#) is that it is completely stupid to even talk about monads, and it does nothing but confuse and intimidate newcomers
18:49:52 <Welkin> there was a great anology on the fsharpforfunandprofit website
18:49:54 <Welkin> let me find it
18:50:10 <MarcelineVQ> analogies are a lot like fruit
18:50:16 <monochrom> Ah if you're following a book that uses stack, I guess follow it through.
18:50:27 <Welkin> https://fsharpforfunandprofit.com/posts/why-i-wont-be-writing-a-monad-tutorial/
18:50:32 <justsomeguy> You know, i have the feeling that monads are easy, but people just won't stop talking about how hard they are. Apprehension.
18:50:41 <monochrom> Especially since it already says how to use stack. (At least sufficiently for the book's purpose.)
18:50:43 <Welkin> "Alice: No! A doggy is not a kitty. A horsie is not a kitty."
18:50:52 <Welkin> "Daddy: How about I explain for you? First, let us consider a set S which is strictly well-ordered with respect to set membership and where every element of S is also a subset of S. Does that give you a clue?"
18:50:57 <justsomeguy> monochrom: Yeah, that's pretty much the only reason I'm using it right now. I have no loyalty to particular tools.
18:51:15 <Welkin> "Alice: [Bursts into tears]"
18:51:27 <Welkin> that's what talking about monads is like
18:51:35 <MarcelineVQ> My first exposure to the word monad was a video called don't fear the monad and by the end I was more confused than I started. I wonder if I'd do better now
18:52:37 <justsomeguy> The only exposure I've to mondas so far is this video... which honestly didn't seem so bad. It's just an interface. https://www.youtube.com/watch?v=IBB7JpbClo8&list=PLe7Ei6viL6jGp1Rfu0dil1JH1SHk9bgDV&index=18&t=0s
18:52:53 <Welkin> it is an interface. But the category theory monad is a different beast
18:53:04 <Welkin> people confuse Monad the interface with monads from category theory
18:53:09 <justsomeguy> Shh, I'm not ready for that pain yet. :^p
18:53:11 <Welkin> as a programmer, you only need to know about the interface
18:53:36 <justsomeguy> lol, good
18:53:37 <MarcelineVQ> In the end it turns out it's just two functions and ~two laws, so that wasn't so bad
18:54:59 <MarcelineVQ> monads are 'hard' possibly because the people asking about them also are learning typeclasses still
18:55:29 <Welkin> if you deify something and talk about how hard it is, people have a mental block
18:55:37 <MarcelineVQ> So they dn't think to ask about some specific Monad, they don't know to
18:55:43 <Welkin> in my C programming class in uni, everyone talked about how hard/complicated pointers were
18:55:48 <Welkin> they are so basic!
18:55:56 <Welkin> but even I had issues at the time
18:56:01 <Welkin> C's crappy syntax doesn't help
18:56:12 <Welkin> multiple contexts for using * and then the & operator
18:56:16 <MarcelineVQ> they're super basic... wait was I tracking the memory offset size for my type or was the compiler?
18:56:25 <johnw> and every programmer has used things that share the monad interface, countless times, it's just not been called out "in the abstract" as its own concept before
18:56:51 <johnw> reminds me of when I tried to ask in Italian what the word for "food" was
18:57:00 <johnw> I just lacked the conceptual vocabulary to indicate that I was trying to be abstract
18:57:34 <MarcelineVQ> it's pasta yeah?
18:57:35 <Welkin> a monad is something something monoid something something endofunctor
18:57:40 <Welkin> that's all I remember
18:57:52 <johnw> Welkin: http://newartisans.com/2017/05/monads-are-monoids/ :)
18:57:54 <MarcelineVQ> pasta with a hard 'a'
18:58:27 <johnw> that article walks you through the entire stack of abstractions for category theory monads; you need know very little of it to use them in Haskell
18:58:59 <Welkin> I already put in my time to learn about some of these things years ago when I started haskell, like monoids and bifunctors and natural transformations, etc
18:59:04 <Welkin> maybe I'll go deeper at some point
18:59:14 <Welkin> I've got these category theory books laying around
18:59:17 <johnw> it's enlightening at a certain point, but mostly confusing until then
18:59:19 <Welkin> just for fun
18:59:35 <johnw> there are I think 4 different directions to get to the concept of a monad
18:59:48 <isovector1> what sort of performance penalty am i looking at to catch an exception?
19:00:01 <monochrom> I thought it was cibo.  I saw it in the libretto of Don Giovanni.
19:00:13 <isovector1> trying to detect if a function is `const` by passing undefined to it
19:00:25 <MarcelineVQ> and being hungry is called antipasta
19:00:29 <johnw> isovector1: I bet shachaf would know, since that's how Data.Data.Lens works
19:01:09 <monochrom> It's also where I learned that si = yes.  Completely handy when one day a student asked me questions, I answered, and it the middle of my answering, the student kept saying "si, si, si".
19:01:56 <johnw> si, è cibo
19:02:03 <isovector1> johnw: is it? cool. i've always wondered
19:02:36 <shachaf> I am out of the business of knowing things like that.
19:02:40 <johnw> now back to why privoxy isn't proxying my DNS requests...
19:02:56 <johnw> shachaf: on to bigger and better business?
19:02:58 <shachaf> If you're talking about upon, I don't recommend using it in "real" code.
19:03:39 <johnw> is the overhead alot, or is it just conceptually a bit too messy to be relied on?
19:03:50 <shachaf> Yes.
19:03:51 <isovector1> performance wise or trustworthiness-wise?
19:03:53 <johnw> :)
19:03:54 <isovector1> hahah
19:07:47 <isovector1> in that case maybe the hivemind can help me. i'm trying so solve the following system of denotational equations: `query (Pure a) = [a]`, `query other_things = a list with many things`, `fmap f (Pure a) = Pure (f a)`, `alt (refine (const False) q1) q2 = fmap Right q2`
19:09:04 <isovector1> the problem is that `fmap Right (Pure a)` has different "query properties" (first two eqns) than `alt (refine (const False) q1) (Pure a)` does
19:10:08 <isovector1> but `refine` is common in the algebra and it's hard to stomach an expensive check for `const`
19:11:22 <isovector1> alternatively i could get rid of that last equation and attempt to find some other way of describing the behavior of alt
19:13:53 <isovector1> maybe i just need an explicit failure node: `refine (const False) q = failure`, and then give `alt failure q2 = fmap Right q2`
19:15:47 <isovector1> nah that just punts the problem elsewhere
19:15:51 <isovector1> functions are the worst.
19:33:15 * hackage typed-encoding 0.2.2.0 - Type safe string transformations  https://hackage.haskell.org/package/typed-encoding-0.2.2.0 (rpeszek)
19:55:43 <crestfallen> hi I just started reading (<$) for functor, after having never seen it before. (reading haskellWiki and typeclassopedia).. what am I missing?
19:55:54 <crestfallen> vs (<$>)
19:55:59 <wavemode> :t (<$)
19:56:00 <lambdabot> Functor f => a -> f b -> f a
19:56:01 <wavemode> :t (<$>)
19:56:03 <lambdabot> Functor f => (a -> b) -> f a -> f b
19:56:22 <oats> crestfallen: you use <$  when you want to insert a value into a functor
19:56:29 <oats> <$> lets you map a function over it
19:56:40 <oats> but sometimes there's just a plain value you want to put in instead
19:56:54 <oats> % (+1) <$> Just 5
19:56:54 <yahb> oats: *** Parser [source]:; !!! Parser [source]: finished in 0.10 milliseconds, allocated 0.041 megabytes; *** Desugar:; *** Simplify [expr]:; !!! Simplify [expr]: finished in 0.43 milliseconds, allocated 0.232 megabytes; *** CorePrep [expr]:; !!! CorePrep [expr]: finished in 0.14 milliseconds, allocated 0.062 megabytes; *** ByteCodeGen [Ghci76]:; !!! ByteCodeGen [Ghci76]: finished in 0.31 milliseconds, allocat
19:57:01 <oats> uhhhhh
19:57:06 <oats> other bot I guess
19:57:07 <wavemode> > 5 <$ [1, 2, 3, 4]
19:57:08 <lambdabot>  [5,5,5,5]
19:57:22 <monochrom> Could you simply always expand <$ to its definition whenever you see it used?  After 10 times you will get it.
19:57:32 <oats> > 5 <$ Just "howdy"
19:57:34 <lambdabot>  Just 5
19:58:01 <monochrom> This practical experience is much better than any wordy explanation from 3rd parties or from yourself.
19:58:26 <MarcelineVQ> % :q
19:58:26 <yahb> MarcelineVQ: 
19:58:43 <crestfallen> what do you mean "expand it to its definition" monochrom ?
19:58:57 <wavemode> (<$) = fmap . const
19:59:29 <oats> or `value <$ functor = const value <$> functor`
19:59:39 <oats> params can add clarity :)
19:59:45 <wavemode> true x)
20:00:06 <crestfallen> ok thanks never saw it till now!
20:00:06 <monochrom> a <$ xs = fmap (const a) xs
20:00:32 <crestfallen> > fmap (const 10) [3,4,5]
20:00:34 <lambdabot>  [10,10,10]
20:00:39 <crestfallen> fair enough thanks
20:01:24 <oats> crestfallen: when in doubt, read the source and the types
20:01:37 <oats> if it still doesn't make sense, pull up a repo
20:01:40 <oats> *repl
20:01:46 <oats> rinse and repeat :)
20:01:50 <monochrom> the doc has "The default definition is fmap . const"
20:02:20 <crestfallen> yeah I just started on typeclassopedia as per suggestion of wavemode, that's the *first* thing they cover
20:03:30 <crestfallen> @let ff = fmap . const
20:03:31 <lambdabot>  Defined.
20:03:48 <crestfallen> > ff 4 [1,2,3]
20:03:50 <lambdabot>  [4,4,4]
20:04:52 <oats> we put the “Fun” in “Functor!”
20:05:45 <crestfallen> I wonder if I'll finally get haskell if I go through typeclassopedia
20:05:55 <MarcelineVQ> No
20:06:08 <MarcelineVQ> You get haskell by writing it, not reading it.
20:06:11 <oats> crestfallen: the best way to learn haskell is to write haskell
20:06:19 <oats> so pick a little problem and try to solve it :)
20:06:42 <wavemode> after the compiler has yelled at you enough times, you eventually learn how to get on its good side
20:06:46 <monochrom> generally all of computer science.
20:07:10 <monochrom> generally all of STEM
20:07:22 <MarcelineVQ> keep going
20:08:17 <crestfallen> monochrom you were talking about how some people cannot do formalism. I do like unifying types. I find that enriching. do you consider that formalism?
20:08:19 <monochrom> generally all of STEM and painting, sculping, music, dancing
20:08:36 <monochrom> Yes.
20:10:37 <monochrom> There are also people who can do it but they first need to decide that they must do it.
20:10:38 <Welkin> there is a tipping point with all programming languages (and all tools)
20:10:57 <Welkin> find a good project you can throw yourself into and you will learn very fast
20:11:31 <Welkin> I always use a project, like building an app I actually want to make
20:11:47 <Welkin> it will drive youto learn things you never considered
20:12:14 <Welkin> sometimes I do this with a new language, get some value from it, then never touch the language again
20:12:35 <oats> crestfallen: is there any bridge in particular you're having trouble crossing atm?
20:13:00 <crestfallen> thanks MarcelineVQ and Welkin thanks monochrom .. so I just did the unification for (>>= id) and (join (,)), and I enjoyed doing the  head . (filter first) some time ago.   some others also  what would be an instructive unification to go through/attempt?
20:13:20 <Welkin> crestfallen: flip const
20:13:24 <Welkin> and (.).(.)
20:13:37 <monochrom> (.).(.) is very mean.
20:13:52 <oats> :t (.).(.)
20:13:53 <lambdabot> (b -> c) -> (a1 -> a2 -> b) -> a1 -> a2 -> c
20:13:54 <crestfallen> oh yeah I think I looked at the owl eyes.
20:13:57 <monochrom> I reserve such mean problems to exams.
20:14:06 <crestfallen> ha!
20:14:25 <oats> oh, is that `over`?
20:14:40 <oats> @let over = (.).(.)
20:14:41 <lambdabot>  Defined.
20:15:11 <Welkin> I mean, const id and flip const
20:15:13 <oats> :t show `over` (+)
20:15:15 <lambdabot> error:
20:15:15 <lambdabot>     Ambiguous occurrence ‘over’
20:15:15 <lambdabot>     It could refer to either ‘Lens.over’,
20:15:21 <oats> bleh
20:15:26 <Welkin> never used over
20:15:31 <Welkin> I haven't touched lens really
20:15:38 <oats> > (show ((.).(.)) (+)) 1 2
20:15:39 <monochrom> but do it to every definition of polymorphic functions you care about. I think that's good enough. Plus you actually care about those definitions, not some contrived meant-to-be-mean puzzles like (.).(.).(.)
20:15:41 <lambdabot>  error:
20:15:41 <lambdabot>      • Couldn't match expected type ‘(Integer -> Integer -> Integer)
20:15:41 <lambdabot>                                      -> Integer -> Integer -> t’
20:15:44 <crestfallen> Welkin I wanted to do a project that actually teaches haskell basics (to intermediate?) .. is that a worthy project?
20:15:45 <oats> :<
20:15:51 <Welkin> (.).(.) isn't mean
20:16:03 <Welkin> it's my favorite exercise in haskell
20:16:08 <Welkin> it took me a day to do it
20:16:23 <Welkin> I finally realized I had to writ =e it all out step by step, lie a proof
20:16:28 <Welkin> like*
20:16:32 <Welkin> it was fun
20:16:46 <Welkin> there is a step-by-step way to do type unification by hand
20:16:52 <Welkin> as well as eta reduction and eta expansion
20:17:15 <ski> @let infixr 9 .:; (.:) :: (c0 -> c1) -> ((a -> b -> c0) -> (a -> b -> c1)); (.:) = (.) . (.)
20:17:17 <lambdabot>  Defined.
20:17:24 <ski> > (show .: (+)) 1 2
20:17:27 <lambdabot>  "3"
20:18:14 <crestfallen> well Welkin unification is sort of like proofs.. it has that feel anyway, right?
20:18:30 <oats> http://hackage.haskell.org/package/data-aviary-0.4.0/docs/Data-Aviary-Birds.html
20:18:34 <ski> a bit more like solving an equation system, i'd say
20:18:36 <oats> module of similar combinators
20:18:56 <oats> fun stuff
20:19:05 <ski> ah, nice module, oats :)
20:19:24 <oats> (.).(.) looks closest to the "blackbird"
20:19:47 <Welkin> another good one is const . const
20:19:58 <Welkin> and fmap fmap fmap
20:20:02 <Welkin> and fmap . fmap . fmap
20:20:06 <oats> lol
20:20:19 <Welkin> there are many surprises in there
20:20:23 <crestfallen> you always resolve the left hand side, but which function you plug into the lh operand, it's interchangeable right? you don't look at one and determine it is a better start than the other..
20:20:27 <Welkin> delightful surprises about how these things relate
20:20:47 <oats> interesting, (fmap fmap fmap) == (fmap . fmap)
20:20:58 <Welkin> guess why?
20:21:07 <Welkin> fmap is related to .
20:21:09 <ski> it used to be the case that in lambdabot, `(.) = fmap' and `flip f x = fmap ($ x) f'
20:21:34 <oats> (fmap fmap fmap) == (fmap <$> fmap) == (fmap . fmap)
20:21:36 <oats> I think
20:21:44 <Welkin> not what I'm going for, but sure
20:21:52 <oats> Welkin: what were you getting at?
20:21:59 <Welkin> it has to do with -> being a constructor for functions
20:22:02 <monochrom> Try this question: Which Functor instance is it using?
20:22:10 <monochrom> Darn. That, yes.
20:22:29 <Welkin> sorry I spilled the beans
20:22:35 <monochrom> It's OK.
20:22:46 <oats> Functor ((->) r)
20:22:55 <ski> crestfallen : hm, i didn't follow
20:22:58 <monochrom> This is why while (.) . (.) is mean, it is not mean enough.  I always say, let's up the game, consider fmap fmap fmap.
20:23:01 <Welkin> that blew my mind
20:23:07 <Welkin> haskell has blown my mind for years
20:23:12 <oats> https://hackage.haskell.org/package/base-4.14.0.0/docs/src/GHC.Base.html#line-969
20:23:17 <oats> fmap = (.) \o/
20:23:25 <ski> @quote is.the.solution
20:23:25 <lambdabot> quicksilver says: head-explosion is the solution, not the problem.
20:23:25 <oats> (celebration not included in function definition)
20:24:22 <wavemode> > (*) <*> (+5) $ 10
20:24:25 <lambdabot>  150
20:24:46 <crestfallen> ski well you unify the first parameter of the first two functions you start off with. so in the case of   head . (filter first)     ...
20:24:48 <crestfallen> working
20:26:12 <oats> wavemode: if I ever see that during a code review I will hunt down those responsible
20:26:16 <crestfallen> so you first unify (.) head  
20:26:39 <crestfallen> [a] -> a ~ (b -> c)
20:27:10 <crestfallen> you must start there, you can't start anywhere else right ski?
20:27:46 <ski> > (id^2 + id + 1) `map` [-3 .. 3]
20:27:48 <lambdabot>  [7,3,1,1,3,7,13]
20:27:50 <ski> > [[(fst^2 - fst*snd + snd^2) (x,y) | x <- [-1 .. 1]] | y <- [-1 .. 1]]
20:27:52 <lambdabot>  [[1,1,3],[1,0,1],[3,1,1]]
20:28:53 <oats> :t (.) <*> (.)
20:28:55 <lambdabot> ((a -> c) -> c) -> (a -> a -> c) -> c
20:29:06 <oats> I dub thee "goblin"
20:29:19 <ski> crestfallen : well, the type of `head' will need to be unified with the expected type of the left operand of `.', and the type of `filter first' with the expected type of the right operand of `.', in that example
20:29:36 <Welkin> you can use lambdabot in a private message
20:29:40 <Welkin> no need to spam the channel
20:31:27 <ski> @djinn ((a -> c) -> c) -> (a -> a -> c) -> c
20:31:27 <lambdabot> f a b = a (\ c -> b c c)
20:31:43 <oats> Welkin: but it's kinda quiet and we want to show off our anthropomorphic operators
20:31:59 <crestfallen> well I got lost up there
20:32:46 <crestfallen> I don't get that example at all
20:33:02 <crestfallen> 2 examples
20:33:41 <ski> crestfallen : i think it helps to first rename the type variables of the signatures of the identifiers one has to work with, so that no two different signatures share the same name of a type variable
20:33:55 <ski> in your case, since you have
20:33:59 <ski>   head :: [a] -> a
20:34:12 <ski>   (.) :: (b -> c) -> (a -> b) -> (a -> c)
20:34:13 <ski>   ...
20:34:36 <ski> you'd need to rename tyvars in at least one of those first two. specifically, rename `a' in one or the other of them
20:34:53 <ski> (or, you could simply rename every type variable, just in case)
20:35:33 <ski> the reason is that the `a' in the signature of `head' need have nothing to do with the `a' in the signature for `(.)'
20:38:44 <oats> “Using Data.Aviary as a library (i.e. depending on it for other packages) is not recommended: combinator-mania leads to inscrutable code” lol
20:41:05 <ski> (Backus might've disagreed)
20:42:29 <crestfallen> ski ok the way I (following the blog post) did it was actually doing the unification for (filter first) first. that gets rid of a
20:42:55 <crestfallen> gets rid of a in that part at least
20:43:13 <ski> yes, that is possibly a nice way to schedule it, in practice
20:43:51 <crestfallen> filter :: (a -> Bool) -> [a] -> [a]  ~  fst    :: (s, t) -> s
20:44:20 <crestfallen> [(Bool,t)] -> [(Bool,t)]
20:47:31 <crestfallen> so actually it's associative.. you can start with two of the four functions if they are adjacent , is that correct? or is it more flexible ski?
20:48:11 <ski> hm, what's associative ?
20:48:22 <crestfallen> I mean, does one always start in the same place, given x functions to be unified?
20:48:33 <ski> one doesn't have to, no
20:48:37 <crestfallen> hmm
20:48:59 <ski> as long as one considers all "positions" in the abstract syntax tree
20:49:44 <ski> (each identifier, each application, each other syntactical construct (like `if',`let',`case',..))
20:50:35 <crestfallen> not sure I follow .
20:50:40 <ski> one way is to visit each position, and have it generate some type equations, collecting them all. then, at the end, one can solve this equation system
20:51:00 <ski> or, you can start solving the equations you've seen, as you're traversing the expression
20:52:31 <ski> well, consider e.g. `map (map ord)'
20:52:38 <ski> @type ord
20:52:39 <lambdabot> Char -> Int
20:53:44 <ski> this expression is an application of the expression `map' to the expression `map ord'. the first of these two is an identifier. the second is again an application, this time of `map' to `ord'. and both these are identifiers
20:54:15 <crestfallen> the first being map in 'map ord' you mean?
20:54:26 <crestfallen> which is the identifier?
20:54:44 <ski> not, the first `map' i mentioned was the `map' to the left of `(map ord)', in `map (map ord)'
20:55:11 <ski> `map' is an identifier. `map ord' is not an identifier (it's an application of one identifier to another identifier)
20:55:12 <crestfallen> so the map in (map ord) is the identifier.
20:55:24 <ski> well, yes, that `map' occurance is also an identifier
20:55:39 <ski> if it helps, you could imagine a data type of expressions
20:55:41 <ski> something like
20:55:53 <ski>   data Expr = Ident String | App Expr Expr
20:56:19 <crestfallen> > ord 't'
20:56:21 <lambdabot>  116
20:56:34 <ski> then the expression `map (map ord)' could be represented as a data structure, as `App (Ident "map") (App (Ident "map") (Ident "ord"))'
20:57:20 <ski> so, when i'm saying you should "walk"/"traverse" the expression / abstract syntax tree `map (map ord)', i mean you need to visit both of the `App' nodes, and all three `Ident' nodes, in the data structure
20:57:59 <ski> however .. maybe this complication of representing a Haskell expression as a Haskell data structure is confusing you. in that case, you can ignore it
20:58:38 <crestfallen> yeah sorry I don't know what Ident is, or if "map" is a string or not
20:58:55 <ski> (i would draw a tree for you, at this point, with `map',`map',`ord' as its leaves, if i had a blackboard that you could see)
20:59:18 <ski> anyway, consider again the expression `map (map ord)'
20:59:34 <ski> this contains three identifier occurances, `map',`map',`ord'
20:59:46 <crestfallen> looking up identifier...
21:00:07 <ski> you can also call them "names", if you prefer, instead of "identifiers"
21:00:37 <ski> `map' and `ord' are names used to refer to values (in this case function values)
21:01:28 <ski> if we list the signatures for these three, we have
21:01:37 <ski>   map :: (a -> b) -> [a] -> [b]
21:01:40 <ski>   map :: (a -> b) -> [a] -> [b]
21:01:45 <ski>   ord :: Char -> Int
21:02:18 <crestfallen> ok could you show me how map (map ord) works in lambdabot?
21:03:03 <ski> > map (map ord) [['0','1','2','3'],['4','5','6'],['7','8'],['9'],[]]
21:03:04 <lambdabot>  [[48,49,50,51],[52,53,54],[55,56],[57],[]]
21:03:44 <ski> so, calls `ord' on each `Char'acter in a list of lists of `Char'acters, converting it to a corresponding `Int'
21:04:07 <ski> the first `map' deals with the outer list. the second `map' deals with each of the inner lists
21:04:29 <ski> ok ?
21:04:30 <crestfallen> ok got that thanks
21:05:20 <ski> anyway, the signature of `map' really includes `forall's, which usually are implicit (not spelled out). these `forall's are what's claiming that `map' is polymorphic. if we spell them out, we get
21:05:22 <crestfallen> there is nothing to flatten the list of lists
21:05:36 <ski>   map :: forall a b. (a -> b) -> [a] -> [b]
21:05:38 <ski>   map :: forall a b. (a -> b) -> [a] -> [b]
21:05:46 <ski>   ord :: Char -> Int
21:06:06 <ski> (still two `map's, since there's two of them, in the expression `map (map ord)')
21:06:13 <crestfallen> right
21:06:32 <ski> so, first thing we do now, is to remove `forall's, and simultaneously rename the corresponding tyvars
21:06:37 <ski> that will get us something like
21:06:57 <ski>   map :: (_a0 -> _b0) -> [_a0] -> [_b0]
21:07:04 <ski>   map :: (_a1 -> _b1) -> [_a1] -> [_b1]
21:07:06 <ski>   ord :: Char -> Int
21:07:38 <ski> so, we're making sure that no two different signatures here share a variable name
21:08:21 <ski> i've also prefixed them with `_' to highlight that they're "placeholders" (aka meta-variables, or logic variables), stands for yet-unknown actual types, that we're to figure out
21:08:34 <crestfallen> ok copy that. but...
21:08:43 <crestfallen> why the underscores?
21:09:09 <crestfallen> ok yeah I see that
21:09:22 <ski> these placeholders only occur during type checking/inference, never in actual type signatures that one writes in the program
21:09:35 <crestfallen> cool I like that
21:10:13 <crestfallen> so we are to unify the two maps first?
21:10:16 <ski> so, looking at `map (map ord)', we could focus first on the `map ord' part
21:10:27 <crestfallen> ok
21:10:50 <crestfallen> hold on, yeah its not possible to start with the two maps
21:11:10 <ski> that way, we'll figure out the type (possibly still containing placeholders) of that subexpression `map ord', which is to be an actual parameter of the first `map'
21:11:33 <ski> so, we're currently looking at just
21:11:36 <ski>   map :: (_a1 -> _b1) -> [_a1] -> [_b1]
21:11:39 <ski>   ord :: Char -> Int
21:11:47 <ski> (the second `map' signature from above)
21:11:49 <crestfallen> ok, you chose those first because.. you can't unify two identical functions
21:12:21 <ski> i'm doing a "bottom-up" traversal of the expression, starting at the identifiers, then working my way up to larger expressions
21:12:50 <crestfallen> but all three functions are identifiers right?
21:13:19 <ski> so i can't handle the expression `map (map ord)' before i've handled its two immediate subexpressions `map' and `map ord'. the first is already handled, since it's an identifier (we did those first). so `map ord' is next
21:13:36 <crestfallen> I mean , logically it makes sense to start with ord ~ map in the parens
21:13:40 <ski> well, `map ord' is also a function .. but that expression is not an identifier
21:13:51 <crestfallen> ok yeah
21:14:12 <crestfallen> but just so I'm certain..
21:14:26 <crestfallen> you can't unify the two maps, I mean, what would that look like/
21:14:27 <crestfallen> ?
21:14:31 <ski> anyway, the type of the formal parameter (the expected argument type), which is `_a1 -> _b1', has to match the type of the actual parameter (the actual argument type), which is `Char -> Int'
21:15:00 <ski> we're not unifying values (like `map'). we're unifying types of values
21:16:11 <ski> in an application `F X', if the type of `F' is `tau0 -> tau1', and the type of `X' is `tau2', then we must have `tau0 = tau2' (the formal and actual parameter types match), and then the type of `F X' is `tau1' (the return type of the function `F')
21:16:36 <ski> in this case, `F' would be `map', and `X' would be `ord'
21:16:37 <crestfallen> yes. but we cannot unify    (_a0 -> _b0) -> [_a0] -> [_b0] ~  map :: (_a1 -> _b1) -> [_a1] -> [_b1]
21:16:54 <crestfallen> sorry reading..
21:16:57 <ski> we shouldn't unify anything, except what the typing rules tells us to unify
21:17:16 <ski> the rule for applications tells us to unify formal parameter type with actual parameter type
21:18:27 <ski> so, in the case where `map :: (_a1 -> _b1) -> [_a1] -> [_b1]' and `ord :: Char -> Int', when checking `map ord', this rule tells us that we must have
21:18:36 <ski>   _a1 -> _b1  =  Char -> Int
21:18:40 <ski> and that
21:18:47 <ski>   map ord :: [_a1] -> [_b1]
21:19:07 <ski> crestfallen : does that make sense ?
21:19:27 <crestfallen> yes, because..
21:20:23 <ski> at this point, we could try to solve that type equation. but we can also just leave all generated equations until the end, and solve all of them in one go. let's do that here
21:20:26 <crestfallen> [_a1] -> [_b1] is the remainder after we've resolved the formal ~ actual parameter on the left
21:20:35 <ski> yes, crestfallen
21:20:50 <ski> so, recalling the signature of the first `map', we now know
21:20:56 <ski>   map :: (_a0 -> _b0) -> [_a0] -> [_b0]
21:21:02 <ski>   map ord :: [_a1] -> [_b1]
21:21:26 <ski> so, now we're considering applying `map' to `map ord', that is we're considering the application `map (map ord)'
21:21:37 <ski> again, formal and actual parameter types must match :
21:21:37 <crestfallen> ok
21:21:45 <ski>   _a0 -> _b0  =  [_a1] -> [_b1]
21:21:58 <ski> and the type of the application is the return type of the function :
21:22:10 <ski>   map (map ord) :: [_a0] -> [_b0]
21:22:21 <crestfallen> got that
21:22:43 <ski> so, now we're traversed the whole of this (small) expression. summarizing what we've concluded so far :
21:22:53 <ski>   _a1 -> _b1  =  Char -> Int
21:22:54 <ski>   _a0 -> _b0  =  [_a1] -> [_b1]
21:22:57 <ski>   map (map ord) :: [_a0] -> [_b0]
21:23:14 <ski> this should always be a bunch of type equations, and a signature for the whole expression
21:23:36 <crestfallen> then its just substitution
21:23:44 <ski> (in cases where we have type class constraints, we may also here have some constraints)
21:23:59 <ski> well, the first equation can be simplified into / replaced by
21:24:04 <crestfallen> oh yeah never considered constraints
21:24:07 <ski>   _a1  =  Char
21:24:15 <ski>   _b1  =  Int
21:24:22 <crestfallen> yeah break it down a bit further
21:24:26 <ski> and the second equation above can be reduced to
21:24:35 <ski>   _a0  =  [_a1]
21:24:39 <ski>   _b0  =  [_b1]
21:25:17 <ski> we can remove the first two of these four, by replacing every other occurance of the placeholder by the concrete type, and then remove that equation
21:25:20 <ski> that gives us
21:25:27 <ski>   _a0  =  [Char]
21:25:32 <ski>   _b0  =  [Int]
21:25:38 <ski>   map (map ord) :: [_a0] -> [_b0]
21:25:49 <ski> substituting again, we get just
21:25:58 <ski>   map (map ord) :: [[Char]] -> [[Int]]
21:26:03 <ski> which is the final answer
21:26:08 <crestfallen> that's sweet
21:26:29 <ski> in this case, we ended up with no placeholders left in the signature for the whole expression
21:26:55 <crestfallen> so it is type correct
21:27:08 <ski> if we do, we'd have to generalize the type, on the remaining placeholders, replacing them by (ordinary) type variables, and introducing `forall's for those, just after the `::'
21:27:44 <ski> if you try to do the "same", for `map (map reverse)', you should end up with something like
21:27:57 <ski>   map (map reverse) :: [[_a2]] -> [[_a2]]
21:28:07 <ski> and the final step then is to go from this to
21:28:17 <ski>   map (map reverse) :: forall a. [[a]] -> [[a]]
21:28:40 <ski> @type even
21:28:42 <lambdabot> Integral a => a -> Bool
21:29:01 <ski> if you try `map (map even)', you should end with
21:29:10 <ski>   Integral _a2
21:29:25 <ski>   map (map even) :: [[_a2]] -> [[Bool]]
21:29:34 <ski> and then the last step would be to replace this with
21:29:47 <ski>   map (map even) :: forall a. Integral a => [[a]] -> [[Bool]]
21:30:07 <ski> crestfallen : is this making any sense ?
21:30:18 <crestfallen> much , however..
21:30:25 <ski> btw, when starting with
21:30:34 <ski>   even :: forall a. Integral a => a -> Bool
21:30:40 <ski> the first step on this is to replace it with
21:30:46 <ski>   Integral _a2
21:30:54 <ski>   even :: _a2 -> Bool
21:30:57 <ski> (say)
21:31:37 <ski> so, that's where these items like `Integral _a2' come from, namely when you replace `forall's and type variables by placeholders
21:31:52 <crestfallen> so I can follow those unifications straight through, but I actually am foggy on forall still..
21:31:59 <ski> ok
21:32:00 <crestfallen> mathematically speaking
21:32:12 <ski> `forall' is what's expressing polymorphism
21:32:17 <ski> if you have
21:32:27 <ski>   take :: forall a. Int -> [a] -> [a]
21:32:31 <ski> then this is claiming
21:32:33 <ski>   forall a.
21:32:39 <ski>     take :: Int -> [a] -> [a]
21:33:03 <ski> that is, for every type which we can replace `a' with, `take' can be used as having type `Int -> [a] -> [a]'
21:33:37 <ski> e.g., `take' can be used as having type `Int -> [Bool] -> [Bool]', if we replace `a' with (instantiate `a' to) `Bool'
21:34:04 <crestfallen> right so how is that necessary,  or different from using Int -> [a] -> [b]  ?
21:34:34 <ski> if you say `Int -> [a] -> [a]', you're talking about a specific type `a'
21:34:38 <crestfallen> doesn't that also express polymorphism?
21:35:01 <ski> if you say `forall a. Int -> [a] -> [a]', you're not talking about a specific type `a'
21:35:35 <crestfallen> so forall is a keyword that says any instance of a can be polymorphic.
21:35:38 <EvanR> i propose notation for "specific `a'" ... A
21:35:39 <ski> it's just that, in a few cases, you don't actually have to spell out `forall'
21:35:46 * hackage hw-bits 0.7.2.1 - Bit manipulation  https://hackage.haskell.org/package/hw-bits-0.7.2.1 (haskellworks)
21:35:52 <EvanR> Int -> [A] -> [A]
21:36:17 <EvanR> obviously not polymorphic
21:36:24 <EvanR> (if you are used to haskell)
21:36:31 <ski> EvanR : doesn't work for e.g. `data Blah a = MkBlah (Int -> [a] -> [a])' ..
21:36:37 <crestfallen> is my last post correct?
21:37:21 <ski> crestfallen : if a value has a type like `forall a. ..a..', then it's a polymorphic value. and also, if it's a polymorphic value, its type looks like `forall a. ..a..'
21:37:35 <ski> (a different type variable than `a' may be used, of course)
21:38:28 <ski> anyway, usually (there are a few exceptions), if you say `foo :: Int -> [a] -> [a]', this really means `foo :: forall a. Int -> [a] -> [a]'
21:39:04 <ski> this is just a matter of convenience. we could still do the same things in the language, without this rule for leaving out `forall's
21:39:34 <ski> however, note that `Int -> [a] -> [a]' does not mean `forall a. Int -> [a] -> [a]' !
21:40:28 <ski> if `Int -> [a] -> [a]' always meant `forall a. Int -> [a] -> [a]', then `(Int -> [a] -> [a]) -> Bool' would mean `(forall a. Int -> [a] -> [a]) -> Bool' .. and it doesn't
21:41:38 <ski> crestfallen : btw, `a' is not polymorphic in `foo :: forall a. Int -> [a] -> [a]'. it's `foo' that is polymorphic
21:41:54 <ski> crestfallen : making any sense ?
21:42:15 <crestfallen> really trying to see this..
21:42:44 <crestfallen> when the result is Bool, that changed the meaning 
21:43:23 <ski> if `x's is equal to `y + 2', then `x^n' is equal to `(y + 2)^n'
21:43:57 <ski> two expressions being equal means that we can replace one expression by the other, anywhere it occurs
21:44:31 <ski> so if `Int -> [a] -> [a]' was equal to `forall a. Int -> [a] -> [a]', then `(Int -> [a] -> [a]) -> Bool' would be equal to `(forall a. Int -> [a] -> [a]) -> Bool' ..
21:44:53 <ski> .. but it definitely isn't (trust me, in case that's not clear), and so the first two aren't equal, either
21:46:44 <crestfallen> so if we are left with a [_a1] say...
21:46:44 <ski> (.. sometimes i think it would be easier to explain polymorphism, if this abbreviation rule didn't exist, in Haskell)
21:46:45 * hackage password 2.0.1.1 - Hashing and checking of passwords  https://hackage.haskell.org/package/password-2.0.1.1 (cdepillabout)
21:47:15 <crestfallen> everything is not resolved. but we can still..
21:47:37 <crestfallen> get that resolved by using forall  ?
21:47:50 <EvanR> it's like einstein summation convention. Before using it you need a paragraph explaining what's about to happen.
21:48:00 <EvanR> then you omit the paragraph
21:48:10 <crestfallen> interesting
21:48:24 * ski . o O ( Wittgenstein throwing away the ladder, after climbing up )
21:48:43 <crestfallen> if lions could talk we still wouldn't understand them
21:48:53 <ski> crestfallen : get what resolved ?
21:50:04 <crestfallen> so no worries, I haven't grasped forall quite yet :)
21:51:49 <ski> another complication with it is that there's no explicit syntax, for going from `map :: forall a b. (a -> b) -> [a] -> [b]' to `map :: (_a0 -> _b0) -> [_a0] -> [_b0]' .. we have the same `map', to the left of the `::', in both cases !
21:51:49 <crestfallen> so if `Int -> [a] -> [a]' was equal to `forall a. Int -> [a] -> [a]', then `(Int -> [a] -> [a]) -> Bool' would be equal to `(forall a. Int -> [a] -> [a]) -> Bool' .. but it definitely isn't
21:51:58 <crestfallen> this part I don't follow ^
21:52:11 <ski> which part of it ?
21:53:08 <crestfallen> well first:
21:53:33 <crestfallen> are these equal?    Int -> [a] -> [a] = forall a. Int -> [a] -> [a]
21:53:42 <ski> no
21:54:28 <crestfallen> sorry. well first to be clear, is the use of forall tied directly to type constraints?
21:55:01 <crestfallen> we were talking about constraints
21:55:52 <ski> well, `=>'
21:56:02 <ski> 's tends to be coupled with `forall'
21:56:13 <ski> (but `forall' without `=>' is also common)
21:56:39 <crestfallen> geez
21:56:41 <ski> if you want to, you could write a function
21:57:03 <ski>   sortStrings :: Ord String => [String] -> [String]
21:57:13 <ski> (with no `forall', implicit or otherwise)
21:57:28 <crestfallen> ok
21:57:30 <ski> however, there's no point to this, since we already know `String' is an instance of `Ord'
21:57:41 <ski> so therefore, we can simplify this to just
21:57:46 <ski>   sortStrings :: [String] -> [String]
21:58:30 <crestfallen> right, but the name of the function sheds some light on the purpose
21:58:49 <crestfallen> so does the constraint
21:59:36 <ski> in order to have a constraint that can't be simplified away like this, in a signature, you need to have it possibly stand for a constraint that isn't holding
21:59:36 <crestfallen> like if it was ff :: Ord String => [String] -> [String]
22:00:31 <ski> if you had
22:00:40 <ski>   blah :: Eq (Integer -> Integer) => ...
22:01:12 <ski> then noone should ever make `Integer -> Integer' an instance of `Eq'. because it's not possible to decide whether two such functions are equal
22:01:24 <ski> so, `blah' can never be called
22:01:32 <ski> (so, this is also a useless case)
22:01:44 <ski> but if you have
22:01:52 <ski>   blah :: forall a. Eq a => ...
22:02:44 <ski> then, depending on which type you use in place of `a', `Eq a' will either become a constraint that is known to hold (there is an instance for it), or a constraint that is not known to hold (like `Eq (Integer -> Integer)', if `a' is chosen to be `Integer -> Integer')
22:03:10 <ski> so, in this case, we can't simplify away the constraint `Eq a'
22:03:41 <crestfallen> ...
22:04:04 <ski> btw, you could have a constraint, without a `forall', usefully .. but it's rare
22:04:31 <c_wraith> other than 0-arg classes?
22:04:51 <ski> c_wraith : `Dict', e.g.
22:05:11 <crestfallen> so essentially my understanding of a type constraint will cover most of the meaning of forall I guess
22:05:46 <ski> crestfallen : you should understand plain polymorphism, before constrained polymorphism, not the other way around, i'd say
22:06:44 <ski> crestfallen : when considering the types, in relation to polymorphism, always start by inserting omitted `forall's, if there's any
22:07:25 <crestfallen> polymorphism just means that the function (a -> b) may return a b - a unique type - or still return whatever 'a' was
22:07:43 <ski> no
22:07:52 <Welkin> there are multiple kinds of polymorphism
22:07:56 <Welkin> they are all different
22:08:07 <Welkin> say what you mean instead of using buzzwords
22:08:29 <ski> yea, in a Haskell context, if one says "polymorphism", one intends "parametric polymorphism"
22:08:42 <Welkin> type variables/generics is one, function overloading is another
22:08:46 <ski> (i can link to a paper talking about different kinds as well ..)
22:08:50 <Welkin> then you have the OO-style polymorphism
22:09:05 <ski> subtyping
22:10:51 <crestfallen> monomorphism is when you have a type constraint. you can't interchange types, the function is designed for just one.
22:11:18 <ski>   ord :: Char -> Int
22:11:32 <ski> `ord' has just a single type. `ord' is monomorphic
22:11:43 <ski>   take :: Int -> [Bool] -> [Bool]
22:12:08 <ski>   take :: Int -> [(Int,[String])] -> [(Int,[String])]
22:12:09 <crestfallen> monomorphic
22:12:33 <ski>   take :: Int -> [[Int -> Int]] -> [[Int -> Int]]
22:12:36 <ski>   ...
22:12:56 <ski> `take' has many types, infinitely many, all following the shape
22:13:02 <ski>   take :: Int -> [a] -> [a]
22:13:11 <ski> `take' is (parametrically) polymorphic
22:13:49 <ski> "monomorphic" means "single shape", while "polymorphic" means "many shapes"
22:14:55 <crestfallen> but take :: Int -> [a] -> [a] is a single shape above right?
22:15:23 <crestfallen> ' ... all following the shape '
22:15:33 <ski> `a' is a type variable, not a specific type like `Bool',`(String,String)',&c.
22:15:54 <ski> `take :: Int -> [a] -> [a' can be called a "type signature schema"
22:16:58 <ski> consider
22:17:01 <ski> @src Eq
22:17:01 <lambdabot> class Eq a where
22:17:01 <lambdabot>     (==), (/=) :: a -> a -> Bool
22:17:10 <ski> the definition of the `Eq' type class
22:17:38 <ski> i claim the two methods, `(==)' and `(/=)', are not polymorphic, as members of this type class !
22:19:06 <ski> why ? .. well, take the specific case of `Eq Bool'. in that instance, the implementations of `(==)' and `(/=)' ought to have type `Bool -> Bool -> Bool' .. we have to have monomorphic implementations, not polymorphic ones, here
22:19:42 <ski> in this case, `(==), (/=) :: a -> a -> Bool's is not an abbreviation for `(==), (/=) :: forall a. a -> a -> Bool'
22:20:22 <ski> and the reason is because there's already a type variable `a' in scope, in the head of the class declaration, in `Eq a'
22:20:52 <ski> the `a' in the signature is talking about the same `a' as in `Eq a', hence we're not allowed to insert a `forall a.' there, in the signature
22:21:03 <ski> however, consider instead
22:21:10 <ski> @src RealFrac
22:21:11 <lambdabot> class (Real a, Fractional a) => RealFrac a where
22:21:11 <lambdabot>     properFraction                  :: (Integral b) => a -> (b, a)
22:21:11 <lambdabot>     truncate, round, ceiling, floor :: (Integral b) => a -> b
22:22:02 <ski> `properFraction' here is a polymorphic method. `properFraction :: (Integral b) => a -> (b, a)' here really is an abbreviation of `properFraction :: forall b. (Integral b) => a -> (b, a)'
22:22:33 <ski> (but we should only insert a `forall' for `b', not for `a', because `a' is mentioned in the class head)
22:23:04 <Welkin> but if you have nested type signature in a scope, and you want to talk about the same `a`, you can use ScopedTypeVariables with an explicit forall a. at the top level of that scope
22:23:28 <ski> crestfallen : i'm not sure whether these examples help dispel some confusion ?
22:24:02 <crestfallen> it's pretty heavy at this point. 
22:24:29 <Welkin> what is your question?
22:24:35 <Welkin> in plain language
22:33:29 <crestfallen> some functions , logically speaking , can only take a single type. it wouldn't make sense to write ord to accept a Bool. it can only return the numeric value of a character. it's monomorphic. other functions logically can operate on a number of types, making those polymorphic.  
22:34:11 <ski> i think it may be good to disentangle the concept of polymorphism for the concept of functions
22:34:19 <ski> not only functions can be polymorphic
22:34:28 <ski> `[]' (empty list) is polymorphic
22:34:36 <ski> `Nothing' is also polymorphic
22:35:14 <ski> @type System.Exit.exitSuccess
22:35:15 <lambdabot> IO a
22:35:17 <ski> is another example
22:36:23 <crestfallen> right, Nothing is polymorphic, because Maybe is designed to hold many types, and Nothing must be responsive to any of those types.
22:36:45 <ski> s/many types/any type/
22:36:51 <crestfallen> responsive just a word I made up
22:37:03 <ski> @type read
22:37:04 <lambdabot> Read a => String -> a
22:37:20 <ski> `read' is polymorphic, but not in any argument type (or part thereof)
22:37:59 <ski> so, `read' doesn't "operate on a number of types", but is still polymorphic
22:40:49 <fog> I have a GADT; https://pastebin.com/raw/rejSEAvP
22:41:12 <fog> where there is a type equality; SnocOne a ~ Snoc EmptySnoc a
22:41:15 * hackage github-webhooks 0.14.0 - Aeson instances for GitHub Webhook payloads.  https://hackage.haskell.org/package/github-webhooks-0.14.0 (onrock_eng)
22:41:21 <crestfallen> ski thanks could you give a quick example of read ?
22:41:23 <fog> how do i provide a proof of this globally?
22:41:36 <fog> % read @Int 0
22:41:37 <yahb> fog: ; <interactive>:1:11: error:; * No instance for (Num String) arising from the literal `0'; * In the second argument of `read', namely `0'; In the expression: read @Int 0; In an equation for `it': it = read @Int 0
22:41:40 <fog> % read @Int "0"
22:41:40 <yahb> fog: 0
22:41:46 <fog> % :t read @Int "0"
22:41:46 <yahb> fog: Int
22:41:50 <ski> > read "12.3" * 2.0
22:41:51 <lambdabot>  24.6
22:41:57 <ski> > read "12.3" * 2
22:41:59 <lambdabot>  *Exception: Prelude.read: no parse
22:43:43 <crestfallen> oh you threw an exception intentionally..
22:44:10 <ski> i let `read' do it
22:45:03 <ski> what `read' does depends on what type the context surrounding the `read' call expects to get
22:45:18 <crestfallen> right ok that's a good example. It won't take variable types like a float with a whole number
22:45:44 <fog> I can add (SnocOne a ~ Snoc EmptySnoc a) => as a constraint, which allows it to compile, but then when I go to run the function, there is no environement where I can actually prove this to be true. so it wont run... 
22:45:47 <ski> in this case, `2.0' has type `Double', and `2' has type `Integer'
22:45:50 <crestfallen> but it itself is polymorphic as longs as the operands are the same type
22:45:53 <ski> (those are by default)
22:46:09 <crestfallen> long*
22:47:01 <ski> > 12.3 * 2
22:47:03 <lambdabot>  24.6
22:47:11 <fog> right, it would be doing type inference to infer the polymorphic type of read, and failing to unify this Int with Double
22:47:15 <ski> (in that case, `2' has type `Double)
22:47:37 <fog> % 2 @Double
22:47:37 <yahb> fog: ; <interactive>:4:1: error:; * Cannot apply expression of type `p0'; to a visible type argument `Double'; * In the expression: 2 @Double; In an equation for `it': it = 2 @Double
22:48:00 <ski> hm, curious
22:48:45 <crestfallen> right so (*) is truly polymorphic... begging the question, by degree, even moreso than read?
22:49:08 <ski> nah, there's no degrees there
22:49:13 <fog> % :t (*) @Double
22:49:13 <yahb> fog: Double -> Double -> Double
22:51:01 <crestfallen> > :t read
22:51:03 <lambdabot>  <hint>:1:1: error: parse error on input ‘:’
22:51:12 <crestfallen> :t read
22:51:12 <ski> @type read
22:51:13 <lambdabot> Read a => String -> a
22:51:13 <lambdabot> Read a => String -> a
22:52:45 <fog> % :t Identity 2
22:52:45 <yahb> fog: Num a => Identity a
22:52:51 <fog> % :t Identity @Double 2
22:52:51 <yahb> fog: Identity Double
22:53:03 <maerwald> ski: tbf, the read "12.3" * 2 example should compile in my opinion. Because 2 is a literal. 
22:53:28 <fog> i cant seem to define instances of ~
22:53:35 <ski> > read "12.3" * 2 :: Double
22:53:37 <lambdabot>  24.6
22:53:48 <ski> > read "12.3"
22:53:51 <lambdabot>  *Exception: Prelude.read: no parse
22:53:52 <ski> > read "()"
22:53:54 <lambdabot>  ()
22:54:26 <fog> instance (SnocOne a) ~ (Snoc EmptySnoc a) 
22:54:42 <ski> maerwald : it did compile
22:55:22 <fog> if my program requires this constraint, how do I provide it?
22:55:24 <crestfallen> so read needs a second operand
22:55:40 <ski> no, crestfallen
22:56:12 <fog> argh, they are literally not equal...
22:56:15 <ski> (what made you think that)
22:56:48 <crestfallen> > read "()"
22:56:50 <fog> crestfallen: the @ is a type application, its the same as writing a specific and restricted type signature
22:56:50 <lambdabot>  ()
22:57:09 <fog> :t read @Double
22:57:10 <lambdabot> error:
22:57:10 <lambdabot>     Pattern syntax in expression context: read@Double
22:57:10 <lambdabot>     Did you mean to enable TypeApplications?
22:57:16 <fog> % :t read @Double
22:57:16 <yahb> fog: String -> Double
22:57:33 <fog> :t (read :: String -> Double)
22:57:34 <lambdabot> String -> Double
22:58:19 <fog> it does not need String to be provided, as its not polymorphic, the first polymorphic variable appearing in the type of read;
22:58:22 <fog> :t read
22:58:23 <lambdabot> Read a => String -> a
22:58:28 <fog> is `a'
22:58:50 <fog> "Read a => String -> a" is the same as "forall a. Read a => String -> a"
22:59:04 <ski> no
22:59:22 <ski> (it definitely isn't, as i was trying to explain, earlier)
22:59:26 <fog> the @Double fixes the `a' from being polymorphic, to specialising it to Double
22:59:53 <ski> (and `a' isn't polymorphic, `read' is :)
23:00:37 <fog> if we cant call `a' a polymorphic variable, then how do we call it?
23:00:40 <crestfallen> > read "23.4"
23:00:43 <lambdabot>  *Exception: Prelude.read: no parse
23:00:50 <ski> fog : "type variable"
23:00:54 <crestfallen> so that is different from:
23:00:58 <crestfallen> > read "()"
23:01:00 <lambdabot>  ()
23:01:14 <fog> right, () has an unambiguous type
23:01:15 * hackage minilight-lua 0.2.1.0 - A binding library of minilight for Lua langauge.  https://hackage.haskell.org/package/minilight-lua-0.2.1.0 (myuon)
23:01:28 <ski> crestfallen : because it doesn't know what type you want to `read' as, it just assumes `()'
23:01:38 <ski> that's is a defaulting case
23:02:27 <fog> it must have some way of discovering that there are several instances of Read which could be applied to that
23:02:31 <crestfallen> ok so () has no type
23:02:36 <ski> @type ()
23:02:38 <lambdabot> ()
23:02:44 <fog> since "12.3" has type Num a => a
23:03:03 <fog> it has exactly one type
23:03:11 <fog> (), that is
23:03:15 <ski> the type of `()' is also written `()' (somewhat confusingly)
23:03:32 <fog> whereas 12.3 has an ambiguous type 
23:03:48 <fog> actually, im not sure if thats the right way to call it
23:04:11 <ski> `12.3' is a polymorphic numeric literal / numeral
23:04:14 <ski> as is `2'
23:04:21 <ski> @type 12.3
23:04:22 <fog> it has a type signature with one free variable? 
23:04:22 <lambdabot> Fractional p => p
23:04:24 <ski> @type 2
23:04:26 <lambdabot> Num p => p
23:04:46 <fog> you cant say it has a polymorphic type signature?
23:05:14 <fog> oh, you cant say that `p' is polymorphic
23:05:16 <fog> ok..
23:05:32 <ski> signatures aren't really polymorphic. but i suppose one could use that as an abbreviation for "type signature of polymorphic value"
23:05:51 <fog> so 2 has a polymorphic type signature, which the type application restricts to be not polymorphic
23:06:43 <fog> ah, so we say; "2 is a polymorphic value, its type signature has a free variable" ?
23:07:21 <ski> i wouldn't really say it has a free type variable
23:07:38 <fog> or just, its type signature is variable?
23:07:47 <ski> the type of `2' is really `forall p. Num p => p', which has no free type variable
23:07:51 <fog> idk, im just confusing things at this point, sorry
23:08:21 <ski> (however, therefore it's surprising that the type application didn't work)
23:08:28 <fog> im just refusing to accept that I'm going to have to factor out all the mentions of SnocOne from my code
23:08:50 <fog> oh, unless I can promote a type synonym?
23:09:19 <fog> then i could write; type SnocOne a = Snoc EmptySnoc a
23:09:19 <ski> fog : well, from the `data' declaration, it follows that all the `data' constructors are disjoint
23:09:28 <fog> I want to write 'SnocOne
23:09:33 <fog> in a type
23:09:37 <ski> hm, that might work
23:09:43 <fog> it doesnt
23:09:57 <crestfallen> ok losing you. thanks ski so much I really appreciate it.. especially the map (map ord). I got a lot from that.  thanks fog!
23:10:23 <ski> crestfallen : mm .. can't chomp on too much at a time, i think
23:10:46 <crestfallen> yeah I'm just thinking about food right now :)
23:11:02 * ski . o O ( burrito )
23:11:20 <maerwald> They are not that great 
23:11:28 <crestfallen> . o 0 (medjool dates, a whole bag)
23:11:31 <maerwald> Too much advertising 
23:11:51 * ski was thinking about a certain category
23:12:31 * ski . o O ( "Burritos for the Hungry Mathematician" by Ed Morehouse in 2015-04-01 at <https://emorehouse.wescreates.wesleyan.edu/silliness/burrito_monads.pdf> )
23:12:50 <crestfallen> ski is a warrior.. or a saint? it must be like 4am where you're at isn't it?
23:12:59 <ski> nah, it's 08:12
23:13:27 <MarcelineVQ> 8:12 monday morning
23:13:49 <crestfallen> ha!
23:16:02 <maerwald> Why no one uses baozi as monad analogy, I cannot understand 
23:16:30 <MarcelineVQ> "<fog> it has a type signature with one free variable? "   iirc from ski's various talks the distinction goes like this, you would say the function 'read' is polymorphic as it can be instantiated to various types, whereas the type variable 'a' in read is not polymorphic, it can only be instaniated to one kind
23:16:33 <fog> i guess i cant promote a type synonym because it would resolve through to the rhs of the definition
23:17:01 <fog> MarcelineVQ: makes sense
23:17:07 <MarcelineVQ> In a similar manner to how  3 :: Int  4 :: Int  5 :: Int aren't polymorphic   Int :: *   Bool ::​ *   Char ::​ *  aren't polymorphic
23:17:21 <ski> yes, MarcelineVQ
23:17:44 <fog> ah, so its at type level, and we call polymorphic *values*
23:17:44 <ski> (and `p :: *', in that type)
23:18:20 <ski> if you define `data Const c a = MkConst c', then `Const' is polymorphic
23:18:38 <ski> we have `Const :: forall k. * -> k -> *'
23:18:46 <fog> aha! now i understand why its called PolyKinds
23:18:53 <fog> we need that to define Proxy
23:19:02 * ski dislikes the name `PolyKinds' .. :)
23:19:07 <fog> data Proxy (a :: k) = Proxy
23:19:23 <fog> here, `a' is a polymorphic *type*
23:19:28 <ski> no
23:19:33 <fog> oh
23:19:47 <ski> `Proxy' is a polymorphic type
23:20:00 <fog> isnt it a polymorphic value?
23:20:13 <ski> no, `a' doesn't have a kind of shape `forall k. ..k..'
23:20:28 <ski> `a' simply has kind `k, there's no `forall' hiding in there
23:21:13 <ski> but `Proxy' has a kind of shape `forall k. ..k..'. specifically, it has kind `forall k. k -> *'
23:21:16 <fog> Proxy :: forall k (a :: k). Proxy a
23:21:27 <crestfallen> I'm fairly certain forall hasn't been mentioned in my textbook, and I'm working on the state monad. does that make sense?
23:21:40 <ski> i'm talking about the type constructor `Proxy', btw, not the `data' constructor
23:21:55 <ski> crestfallen : yes
23:22:28 <fog> data Proxy2 (a :: forall k. k) = Proxy2
23:22:33 <fog> % data Proxy2 (a :: forall k. k) = Proxy2
23:22:34 <yahb> fog: 
23:22:37 <ski> crestfallen : `forall' needs to be mentioned when it's not only occuring right after a `::'
23:22:58 <fog> so whats Proxy2 ?
23:23:33 <ski> are you talking about the data constructor or the type constructor ?
23:23:47 <ski> (i don't like the convention of naming them the same .. you see why ?)
23:24:08 <fog> idk, im just confused about what the (a :: forall k . k) means
23:24:31 <ski> for the type constructor, we have `Proxy2 :: (forall k. k) -> *'
23:24:32 <fog> (making `a' a "polymorphic" type)
23:24:50 <fog> % :t Proxy2
23:24:50 <yahb> fog: forall (a :: forall k. k). Proxy2 a
23:24:53 <ski> this makes the type constructor not polymorphic, but rather rank-2
23:25:00 <fog> % :kind! 'Proxy2
23:25:00 <yahb> fog: forall (a :: forall k. k). Proxy2 a; = 'Proxy2
23:25:09 <ski> otoh, `a' there is polymorphic
23:26:01 <fog> is the 2 of rank2 referring to the levity?
23:26:10 <ski> no
23:26:27 <ski> if you define
23:26:52 <ski>   mystery :: (forall a. [a] -> [a]) -> [String] -> [String]
23:27:16 <ski> then `mystery' isn't polymorphic, but is rank-2
23:27:32 <ski> because it expects a polymorphic argument
23:27:51 <crestfallen> sorry ski, did you mean to write precisely this? : `forall' needs to be mentioned when it's not only occuring right after a `::'
23:28:28 <ski> crestfallen : yes, e.g. in `mystery' right above, it's not possible to omit `forall'
23:29:47 <fog> aha! i dont need to have 'SnocOne if SnocOne is a synonym
23:30:13 <fog> so i just replace all the 'SnocOne mentions with SnocOne and it works!
23:30:50 <fog> it cant be a type family though, because it appears in instances on recursive classes with that as a basecase
23:32:07 <fog> hmm, ski, sometimes when I write the forall within the brackets I get errors about QantifiedConstraints, and ImpredictivePolymorphism
23:32:23 <fog> I have never managed to use QuantifiedConstrants constructively
23:32:45 <fog> and whenever I see an error about ImpredictivePolymorphism, i give up immediately 
23:32:57 <fog> im worried about these Rank2 things...
23:33:11 <fog> commuting foralls into brackets usually breaks my code
23:33:30 <ski> apparently SPJ has a new implementation idea for `ImpredicativeTypes'
23:33:58 <fog> is it something to do with injective type families?
23:34:06 <ski> no
23:34:19 <fog> or -> appearing in kinds?
23:34:27 <ski> it's just about having `forall's to the left (inside) `->'s
23:34:37 <ski> as in `mystery' above
23:34:43 <ski> if you define
23:35:00 <ski>   mystery f ss = f (map f ss)
23:35:02 <fog> i saw the new ghc even allows you to write foralls all over the place
23:35:28 <ski> then you use `f' at two different types : `[String] -> [String]' and `[Char] -> [Char]'
23:35:41 <ski> this wouldn't work if the argument `f' wasn't itself polymorphic
23:36:08 <fog> \f ss = f (map f ss) :: (forall a. [a] -> [a]) -> [String] -> [String]
23:36:26 <ski> you can't infer higher-rank types
23:36:55 <ski> but if you know which type you intend, you can spell it out
23:37:22 <fog> ah, so its just about the type checker not being able to generalise
23:37:31 <fog> so it needs direction
23:37:51 <fog> otherwise it would probably have to enumerate an infinite number of possiblities or something
23:37:52 <ski> technically, it is possible to infer rank-2 (but GHC doesn't do it). but higher rank than that isn't possible to infer
23:38:14 <ski> @type callCC
23:38:16 <lambdabot> MonadCont m => ((a -> m b) -> m a) -> m a
23:38:24 <fog> so whats SPJ's idea?
23:38:24 <ski> an alternative type of `callCC' is
23:38:38 <fog> sorry, go on
23:38:40 <ski>   callCC :: forall m a. MonadCont m => ((forall b. a -> m b) -> m a) -> m a
23:38:50 <ski> this would be a rank-3 operation
23:39:06 <fog> because it takes a rank2 thing as an argument?
23:39:07 <ski> there are some advantages to this, over the `callCC' we have in `MonadCont'
23:39:10 <ski> yes
23:39:45 <ski> with this rank-3 `callCC', the captured continuation would itself be polymorphic in its monadic return type `b'
23:40:07 <ski> which means that it would be possible to call the same continuation in multiple places, each expecting a different return type
23:40:25 <ski> so, it would be more flexible than the present `callCC'
23:40:50 <fog> hmm, so as soon as you try to use something with a forall to the far left, in many places, its going to complain?
23:41:06 <fog> and commuting it into the bracket solves this
23:41:15 * hackage reanimate 0.3.2.0 - Animation library based on SVGs.  https://hackage.haskell.org/package/reanimate-0.3.2.0 (DavidHimmelstrup)
23:41:46 <fog> it must kind of prevent GHC from unifying the types
23:41:51 <ski> note that `forall a. (..a.. -> ...)' (where `a' doesn't occur (free) in `...') is basically the same as `(exists a. ..a..) -> ...'
23:43:32 <fog> thats existential quantification right?
23:43:32 <ski> if we were using classical logic, then also `exists a. (..a.. -> ...)' would be equivalent to `(forall a. ..a..) -> ...' -- so that `forall a. (..a.. -> ...) -> ...' would be equivalent to `((forall a. ..a..) -> ...) -> ...'
23:43:36 <ski> yes
23:43:51 <ski>   length :: forall a. ([a] -> Int)
23:43:55 <ski> expresses the same thing as
23:44:02 <ski>   length :: (exists a. [a]) -> Int
23:44:30 <ski> the first claims that for any type `a', if we call `length' with a list whose elements have type `a', the result has type `Int'
23:45:05 <ski> the second claims that calling `length' gives a result of type `Int', if there exists a type `a' such that the argument given to `length' is a list with elements of type `a'
23:45:38 <fog> error, fog no parse
23:45:53 <ski> heh
23:46:08 <fog> those are different?
23:46:28 <ski> no, those two different signatures for `length' expressess the same thing
23:46:36 <fog> ah, ok
23:47:03 <ski> (`exists a. [a]' is different from `[exists a. a]', btw)
23:47:50 <fog> i dont get why comuting through the parens flips between forall and exits
23:48:08 <fog> why not just length :: (forall a. [a]) -> Int
23:48:15 <ski> classically, `a -> b' is the same as `(Not a) \/ b'
23:48:36 <ski> moving the quantifier through a negation changes it from `forall' to `exists'
23:48:44 <fog> oh no, the curry howard isomorphism!
23:48:54 <ski> heh
23:48:57 <Rembane> ski: Is there an identity there somewhere? And how does it look? 
23:49:07 <Rembane> *what does it look like
23:49:07 <ski> identity ?
23:49:26 <fog> ahhhh
23:49:29 <Rembane> ski: Yeah, forall == <some operation> exists
23:50:00 <ski> fog : `blah :: forall a. ..a..' means that the caller/user/consumer of `blah' gets to pick `a'
23:50:03 <fog> its like instead of selecting one type from the set of all types, you are precluding all other types or something
23:50:29 <ski> fog : `bleh :: (forall a. ..a..) -> ..' means that the callee/implementation/producer `bleh' itself gets to pick `a'
23:51:07 <ski> fog : moving to the left of the `->' swaps the caller vs. callee (or consumer vs. producer) rôles
23:51:32 <fog> bleh :: exists a. ( ..a..) -> ..
23:51:43 <ski> Rembane : `Not (exists a. ..a..)' is the same as `forall a. Not (..a..)'
23:51:49 <Rembane> ski: Thank you! 
23:52:18 <ski> (if Djinn supported `exists', i'd show it with that)
23:52:24 <fog> i dont get what it means about this caller callee business
23:52:37 <Rembane> ski: In my head I replace a with cake, and I suddenly understand. 
23:53:01 <ski> Rembane : in classical logic, also `Not (forall a. ..a..)' is equivalent to `exists a. Not (..a..)' -- however, in intuitionistic logic, only the latter implies the former
23:53:33 * ski . o O ( "There is no cake." )
23:54:10 <Rembane> Bingo! 
23:54:24 <fog> can i take a harmonic section to quotient your cake / fibre bundle?
23:54:25 <ski> fog : "caller" is the piece of code that is referencing a defined identifier. if it refers to a function, then usually that piece of code would be calling that function
23:54:43 <ski> fog : "callee" is the piece of code that is implementing the defined identifier
23:55:22 <ski> elaborate on "harmonic section" ?
23:55:26 <fog> i dont know what does it mean "identifier" ?
23:55:40 <ski> a name that refers to some entity. in this case a value
23:56:10 <ski> `Bool' is an identifier that refers to a type
23:56:20 <fog> ski: its from the works of piere diligne and david mumford, also Hitchin and Donaldson - in the field of higgs bundles
23:56:32 <ski> `Maybe Bool' is not an identifier, is an application of the identifier `Maybe' to the identifier `Bool'
23:56:48 <ski> hm, i dunno anything about Higgs bundles
23:57:03 <fog> the notion of hierarchical background quantum fluctuations forms a "mumford stack"
23:57:25 <fog> i think ed witten had some stuff on it too. i was being absurd, sorry
23:57:33 * ski idly wonders whether that's related to the notion of "stack" mentioned previously
23:57:52 * ski 's heard of Witten, at least :)
23:57:58 <fog> im not sure which was first 
23:58:54 <fog> i was trying to develop a type theory for the expression of sections of function approximators
23:59:06 <fog> nvm.
23:59:17 <fog> im tired
23:59:52 <ski> (no worry about being absurd, i figured it was a joke. i was just curious about what that term referred to)
