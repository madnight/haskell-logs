00:56:48 <fog> Im trying to write fmap for hetrogenous functors
00:57:15 <fog> as well as needing an argument to cast the contents from one type to another, noramlly (a -> b) in fmap
00:57:49 <fog> the hetrogenous version needs a type family to be provided, to cast from the hetrogenous types of the input container, to the corresponding output
00:58:15 <fog> i guess I could provide this type family in defunctionalised form in a proxy as an argument to the hetrogenous fmap
00:58:45 <fog> but im having trouble understanding how to even write this type familiy
00:59:16 <fog> one idea is to have a constraint, which can be understood similarly to how the actual (a->b) stype value level function is provided
01:00:06 <fog> basically, by having the existence of the (a->b) like function as a constraint, a version of the hetrogenous container where all the values are constrained to satisfy this constraint can be used
01:00:32 <fog> then, instances can be reified locally as a way to pass the arguments in, in a way that allows for the constraint to be reused
01:01:06 <fog> the idea then would be to have something similar for passing in the type level function that is used to cast the input to output types
01:03:23 <fog> the reified constraint then seems to be something like; class Has a b | a -> b where to :: a -> b
01:04:16 <fog> or alternatly, anticipating that the returned hetrogenous functor needs to be able to calculate the actual result type b, that instead of a functional dependency, an associated type should be used;
01:05:30 <fog> class Cast a where type To a; to :: a -> To a
01:06:01 <fog> im not sure about having this poly kinded, where eg, we could have (To a :: k)
01:07:15 <fog> the problem thinking of this is something like how for regular functors the value level mapping function is (a -> b), but here, the type level mapping function is (* -> *)
01:07:32 <fog> maybe if they were polykinded it would be more like (ka -> kb)
01:08:14 <fog> depending on if the hetrogenous containers only store things of type *, which it seems like they must
01:08:51 <fog> im not sure if this is called a subtyping problem, or maybe if it is to do with not having type level classes, so not being able to refer to subsets of *
01:11:38 <fog> im not sure if it would be a worse idea instead to simply demand [*] -> [*], which seems less accurate, as really we want the length preserving law that mapping the ( * ~> * ) function over the list of types gives
01:14:01 <fog> it seems like trying to write this [*] -> [*] function in terms of the ( * ~> * ) provided on defunctionalising the associated type `To', requires some kind of pattern matching as the hetrogenous list is consumed, to retrive the input type stored at the current head of the hetrogenous list, and obtain the type family `To' by its defunctionalisation
01:14:01 <fog> symbol
01:15:14 <fog> the main implementation then is to proceed to "convert" over the hetrogenous container (like traverse, except using get and set, so allowing to reconstruct into a different container)
01:15:21 <fog> to cast it into the constrained version
01:15:48 <fog> within a Dictionary, which makes available the reified "Cast" implementations for the various types contained 
01:16:36 <fog> though, if doing this convert process anyway, it would be as easy to simply zip the datatype version of this class to each value
01:17:22 <fog> ie, the proxy defunctionalisation symbol of the type family `To' and the function to be used as the implementation of `to'
01:17:36 <fog> thus avoiding reification
01:17:53 <fog> and the conversion to a constrained version of the hetrogenous container
01:18:44 <fog> acutally this almost seems more natural, as this "fmap" does seem more like zipWith, since each type needs its own conversion function
01:19:30 <fog> though it is still supposed to capture functoriality somehow - maybe a more category theoretical treatment would be better here
01:21:05 <fog> ah, I guess thats the advantage of the reification and constraints way, as then, despite the values being hetrogenous, as each of them instantitates the same constraint, there is a kind of homoginaity about the function being applied
01:21:32 <fog> ie, all the different types contained share this common feature of having a mapping function defined over their value and type
01:22:16 <fog> just as all the values of type `a' should be covertable into `b' under the normall fmap argument (a -> b)
01:22:48 <fog> thinking of these values of type `a' as members of a set, in the same way that are the instances of the reified Cast constraint
01:23:03 <fog> im not sure if thats right though...
01:28:15 * hackage souffle-haskell 0.2.3 - Souffle Datalog bindings for Haskell  https://hackage.haskell.org/package/souffle-haskell-0.2.3 (luc_tielen)
01:50:16 * hackage unliftio 0.2.13 - The MonadUnliftIO typeclass for unlifting monads to IO (batteries included)  https://hackage.haskell.org/package/unliftio-0.2.13 (MichaelSnoyman)
02:02:45 * hackage elm-bridge 0.6.1 - Derive Elm types and Json code from Haskell types, using aeson's options  https://hackage.haskell.org/package/elm-bridge-0.6.1 (SimonMarechal)
03:17:15 * hackage monadic-recursion-schemes 0.1.11.0 - Recursion Schemes for Monadic version.  https://hackage.haskell.org/package/monadic-recursion-schemes-0.1.11.0 (KatsutoshiItoh)
03:38:30 <fendor> does in ghci -fno-omit-yields do anything?
03:48:44 <Shibby> jesus christ was a retarded who knows this ?
04:20:45 * hackage path 0.8.0 - Support for well-typed paths  https://hackage.haskell.org/package/path-0.8.0 (Norfair)
05:47:12 <fragamus_> what's the easiest way to decorate my AST with inferred tyoe information
05:47:23 <fragamus_> type^
05:51:19 <ski> one option is to add another constructor. another is DecoratingStructures
05:51:26 <ski> @where DecoratingStructures
05:51:27 <lambdabot> <http://web.archive.org/web/20051126143527/http://haskell.org/hawiki/DecoratingStructures>
05:51:41 <ski> a third would be to go full
05:51:46 <ski> @where IndirectComposite
05:51:47 <lambdabot> <http://web.archive.org/web/20051126141834/http://haskell.org/hawiki/IndirectComposite>
05:51:56 <ski> fragamus_ ^
05:53:09 <fragamus_> can I get GHC to fork over the type inference info without tearing into GHC
05:55:10 <ski> hm, how do you mean ?
05:55:22 <ski> are you talking about Haskell AST ?
05:56:08 <fragamus_> yes I am talking about a haskell AST
05:57:39 <ski> i haven't really looked into that
05:58:00 <ski> i guess you're either doing TH, or interfacing with GHC in some other way
05:58:32 <ski> (when you said "my AST", i was assuming it was a `data' type you had defined)
05:59:43 <fragamus_> well I was using Language.Haskell.Exts
06:00:33 <fragamus_> but I hear that I may have to switch to the GHC tool whatever it's called
06:00:36 <ski> well, seems there's not many around here, atm. you could try asking later. could also try asking in #ghc
06:00:57 <Heffalump> fragamus_: there's the GHC API, which IDEs use
06:13:35 <sushi1234> is Programming in Haskell by Graham Hutton worth reading for a beginner?
06:13:54 <ski> it's often suggested in here
06:16:12 <merijn> sushi1234: I've heard good things about it
06:19:03 <sushi1234> i just saw few videos with him in Computerphile, seems like a very good proff
06:20:18 <aveltras> i'd like to forward a wai request to somewhere else using http client, is there an existing library to translate between the different request types ?
06:23:31 <ski> sushi1234 : <https://www.youtube.com/watch?v=pcJHkWwjNl4>, about sorting, by Hutton, is (simple but) nice one
06:27:15 * hackage hw-kafka-client 3.1.1 - Kafka bindings for Haskell  https://hackage.haskell.org/package/hw-kafka-client-3.1.1 (alexeyraga)
07:10:58 <jumper149> Hi, I want to make an HTTP POST request from the JSM monad with GHCJS and I found these methods (https://hackage.haskell.org/package/jsaddle-dom-0.5.0.0/docs/JSDOM-Generated-XMLHttpRequest.html#v:send), but the send function doesn't let me specify a body. Anyone have an idea how to fix that?
07:15:57 <jumper149> Hi, I want to make an HTTP POST request from the JSM monad with GHCJS and I found these methods (https://hackage.haskell.org/package/jsaddle-dom-0.5.0.0/docs/JSDOM-Generated-XMLHttpRequest.html#v:send), but the send function doesn't let me specify a body. Anyone have an idea how to fix that? 
07:16:16 <jumper149> oups sorry
07:17:12 <infinisil> Um what, if you look at https://hackage.haskell.org/package/cabal-install-3.0.0.0, you can see `base (>=4.8 && <4.13)` and `Cabal (==3.0.*)` as requirements
07:17:21 <infinisil> But according to https://www.snoyman.com/base, there's no GHC version that satisfies both of these constraints!
07:17:36 <infinisil> Am I missing something?
07:18:35 <merijn> infinisil: Why do those conflict according to you?
07:19:29 <infinisil> The latest GHC version with base <4.13 is 8.6.5, but the Cabal version of it is 2.4.0.1
07:19:32 <merijn> infinisil: That table lists the version of Cabal the compiler ships with
07:19:44 <merijn> infinisil: You can just, you know, install a newer Cabal version
07:20:33 <infinisil> Hm yeah I'll have to do something like that
07:20:34 <merijn> infinisil: You can use newer Cabal versions with older GHCs just fine
07:21:02 <merijn> infinisil: cabal-install and Cabal, as far as I remember, support any GHC sinds 7.0
07:21:29 <infinisil> Hm okay so the library versions GHC ships with aren't really intended to be used?
07:21:51 <merijn> infinisil: Well, they're intended to be used in the sense that they're shipped so you can use them
07:22:03 <merijn> infinisil: However you're not required to use what ships with GHC
07:22:29 <veverak> hi
07:22:31 <veverak> https://paste.vpsfree.cz/pmoMMeip/
07:22:31 <merijn> infinisil: Basically Cabal/cabal-install are backwards compatible, but not forwards
07:22:34 <veverak> can somebdoy give me a tips?
07:22:41 <veverak> not sure why type system hates on this one :/
07:22:42 <infinisil> merijn: Hm, so I guess it's just that cabal-install doesn't work with the GHC-shipped libraries
07:22:44 <merijn> infinisil: So you should be able to use any *newer* cabal with an older GHC
07:22:58 <infinisil> But other packages might work
07:23:06 <merijn> infinisil: It's just that you can't (necessarily) use a newer GHC with an older Cabal
07:23:44 <merijn> veverak: Oh, that's easy, although slightly confusing :)
07:23:52 <infinisil> Still a bit confused, but I think I'll manage
07:24:01 <merijn> veverak: Type variable scope is (normally) limited to one specific signature
07:24:14 <merijn> veverak: So the 'a' in the top level signature and the sub signatures are independent
07:24:24 <veverak> ...
07:24:29 <veverak> but, wait, why is that a problem ?
07:24:55 <merijn> veverak: So the where bindings are claiming "I work with *any* type 'a'", which is bogus, because they can only work on the type passed in via the top-level
07:24:56 <veverak> I mean, independence does not mean a problem really no? (I assume that indepence allows for equality)
07:25:07 <veverak> ah
07:25:18 <merijn> veverak: You can use ScopedTypeVariables to fix that
07:25:25 <merijn> @where userguide
07:25:25 <lambdabot> https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/
07:25:46 <merijn> veverak: That extension lets you extend the scope of type variables to the bindings in where blocks, etc.
07:26:58 <veverak> for some reason it doesnt?
07:27:11 <veverak> {-# LANGUAGE ScopedTypeVariables #-}
07:27:13 <veverak> ?
07:27:21 <merijn> veverak: You need to use explicit forall to use that, hence why I linked the user guide for details ;)
07:27:41 <veverak> ah
07:28:15 * hackage mergeless 0.3.0.0 -   https://hackage.haskell.org/package/mergeless-0.3.0.0 (Norfair)
07:28:22 <veverak> yeah, it works
07:28:24 <veverak> merijn: thinks
07:28:30 <veverak> but it left my wonder why is this so complicated
07:28:32 <veverak> :/
07:29:16 * hackage mergeless-persistent 0.0.0.0, genvalidity-mergeless 0.2.0.0 (Norfair): https://qbin.io/clan-adsl-7ubn
07:29:47 <merijn> veverak: Because when things where defined most people assumed people would use inference more than it turns out we now do. And being able to reuse type variable in where blocks was considered convenient
07:30:08 <veverak> ah
07:30:22 <merijn> veverak: Changing such a design now would break lots of existing code (hence why you need the explicit forall to "opt in" to the extension, so it doesn't unintentionally break code in the same file)
07:30:24 <veverak> (that is reasoanble I suppose)
07:30:31 <veverak> yeah
07:31:25 <merijn> in other words "historical reasons"
07:31:37 <veverak> I live in C++ world normally
07:31:43 <veverak> so I can understand that
07:32:46 <shapr> @quote
07:32:46 <lambdabot> GuySteele says: Some people prefer not to commingle the functional, lambda-calculus part of a language with the parts that do side effects. It seems they believe in the separation of Church and
07:32:46 <lambdabot> state.
07:32:47 <merijn> veverak: Early Haskell everyone was like "yeah! inference! never annotate any types!", nowadays the consensus is more "without annotations everyone needs to mentally run their own typechecker to understand code, so that's a bad idea"
07:33:04 <shapr> I'm old school, I still don't want to annotate types unless it changes the behavior.
07:33:12 <shapr> I still want to write compile time python
07:33:28 <merijn> Heresy!
07:33:34 <shapr> I think it's silly to make explicit types if you don't really need them.
07:33:44 * shapr shrugs
07:34:09 <shapr> I also write Haskell to match my team when I'm at work. My personal Haskell code has very few explicit type signatures.
07:34:36 <veverak> I like type signatures
07:34:39 <merijn> I've reached the point where I basically annotate every binding, even where/let blocks
07:34:45 <Rembane> I prefer to write only type signatures.
07:34:47 <merijn> I find it much easier to read and follow
07:34:52 <veverak> (I do not overuse them, but they appear periodically)
07:34:54 <veverak> merijn: exactly
07:34:57 <merijn> Rembane: #idris is that way *point*
07:34:59 <veverak> this is 2 years old code
07:35:08 <veverak> thanks to type signatures I was able to understand it much quickly
07:35:09 <Rembane> merijn: :D
07:35:20 <veverak> (2 years as I did not saw it for 2 years)
07:35:24 <wavemode> I often need explicit signatures to grok _my own_ code, especially when the types become complex
07:35:43 <merijn> wavemode: Yeah, although I try and avoid letting them get that complex :p
07:36:42 <shapr> I will say that adding a type signature that's more specific than the most general type signature changes the code, so I'm okay with cases like that.
07:39:15 * hackage mergeful 0.2.0.0 -   https://hackage.haskell.org/package/mergeful-0.2.0.0 (Norfair)
07:40:00 <shapr> I wish I could specify laziness properties in the type signature, and have them checked.
07:40:16 * hackage mergeful-persistent 0.0.0.0, genvalidity-mergeful 0.2.0.0 (Norfair): https://qbin.io/debt-creek-wbfx
07:40:18 <merijn> shapr: Oh, I've been brainstorming how to do that
07:40:31 <merijn> shapr: All I need is funding to spend time to work it out! ;)
07:41:08 <shapr> I wish I had funding for my projects!
07:41:26 <merijn> I know, right
07:42:51 <shapr> yeah, I'm slowly digging through a spoken programming language, starting with kaldi + ucb logo
08:11:15 * hackage haskoin-store-data 0.30.0 - Data for Haskoin Store  https://hackage.haskell.org/package/haskoin-store-data-0.30.0 (jprupp)
08:12:16 * hackage haskoin-store 0.30.0 - Storage and index for Bitcoin and Bitcoin Cash  https://hackage.haskell.org/package/haskoin-store-0.30.0 (jprupp)
08:12:55 <hseg> hi. am trying to use a .ghcid file, unclear on what its contents are supposed to be
08:13:11 <hseg> bc just pasting in the commandline args doesn't work
08:13:26 <glguy> hseg: I have one like this: https://github.com/glguy/irc-core/blob/v2/.ghcid
08:17:00 <hseg> well, http://ix.io/2mUj gives this error http://ix.io/2mUk
08:17:09 <hseg> so seems to be a quoting issue
08:17:31 <hseg> but it's unclear what i'm expected to do exactly
08:20:31 <int-e> hseg: you probably have to quote the exclamation mark for the shell
08:21:43 <hseg> possibly, unclear how to do that
08:22:27 <hseg> frankly, feels like this should be more directly supported and that i'm abusing features
08:24:32 <int-e> sadly, it does look like a mess
08:44:57 <Mathnerd314> Is there a way to have a set of IORef's? They don't implement Ord for some reason
08:47:00 <frdg> Does anyone here have experience using XMonad, and if so is it a useful tool for learning Haskell? 
08:49:43 <ski> Mathnerd314 : i think that's to allow GC reordering them (like compacting GC)
08:49:55 <ski> maybe with `StablePtr' ?
08:50:21 <Mathnerd314> yeah. I think just generating StableName's might work, the only purpose is to traverse a pointer graph while avoiding cycles
08:50:31 <ski> frdg : i've heard some people started getting into Haskell, by using XMonad
08:51:36 <Mathnerd314> or not " Note in particular that mkStableName may return a different StableName after an object is evaluated." :-(
08:52:25 <frdg> ski: Ya im probably gonna try it either way but I see many mixed reviews over how much Haskell you learn by using it
08:52:36 <dmwit> frdg: xmonad (the core package) uses what I would consider very idiomatic Haskell, and is a great learning resource. However, there is a *lot* of example code and blog posts out there written by beginner Haskellers about xmonad. So it may take some taste to decide which advice to keep and which to ignore.
08:54:05 <Mathnerd314> ski: it looks like StablePtrs should work though. I just have to write an Ord instance that casts them to Ptr's
08:55:07 <ski> hm, no `Ord (StablePtr a)' in the lib ?
08:55:10 <dmwit> Mathnerd314: Why not just make sure it's evaluated before your first call to mkStableName?
08:55:11 * ski didn't check
08:55:48 <Mathnerd314> dmwit: that should work too. I guess it doesn't move after it's evaluated?
08:57:15 * hackage life-sync 1.1.1.0 - Synchronize personal configs across multiple machines.  https://hackage.haskell.org/package/life-sync-1.1.1.0 (shersh)
08:57:28 <Mathnerd314> doing DFS is basically memoization so I'm looking at https://www.microsoft.com/en-us/research/wp-content/uploads/1999/09/stretching.pdf
08:57:55 <dmwit> I dunno. The promises in the documentation make it seem like StableName is basically useless to me, TBH
08:58:54 <dmwit> MathNerd314: http://hackage.haskell.org/package/ioref-stable-0.1.1.0/docs/Data-IORefStable.html
08:59:37 <Mathnerd314> hmm, I guess. It's probably easier to use my own unique supply.
09:00:01 <c_wraith> StableName is just a hash table inside the RTS anyway
09:00:41 <c_wraith> In addition to all its caveats, it doesn't give you anything special
09:01:13 <c_wraith> It really should only be used for what it was designed for - passing opaque pointers to haskell values to the FFI
09:01:14 <dmwit> Mathnerd314: Really? IORefStable has like, exactly the same API as IORef, but also gives you Ord. Hard to imagine being much easier than that to migrate.
09:02:02 <dmwit> Just `sed s/IORef/IORefStable/g` and you're done.
09:02:30 <Mathnerd314> c_wraith: that's all I want, is a way to compare IORefs. I'm using them as pointers, so logically they should have addresses...
09:02:58 <dmwit> Well. They don't have addresses that stay the same over time.
09:03:11 <dmwit> GC moves them around.
09:04:06 <dmwit> You're definitely not the first person to wish for this. Here's a thread from 2004: https://mail.haskell.org/pipermail/haskell-cafe/2004-June/006260.html =P
09:04:28 <dmwit> I think IORefStable is probably about as good as it gets.
09:05:08 <Mathnerd314> yeah, I guess. thanks for the thread.
09:05:34 <wavemode_> that's the thing about haskell. almost every innovative idea you think you've had, someone thought of 15 years ago
09:06:02 <Mathnerd314> I'm reading that paper though, it looks like StableName's are basically unique's allocated on request
09:06:26 <c_wraith> with the extra overhead of a hash table indirection
09:07:34 <c_wraith> Did yolu look at the implementation of IORefStable?  It's literally an IORef + a Unique
09:08:16 <Mathnerd314> yeah. I'm just trying to figure out how StableName's work. They seem roughly equivalent to Unique, with more caveats
09:08:53 <c_wraith> all the caveats make sense when you remember that they were only designed to be passed to FFI functions that take a void* to pass to a callback.
09:09:14 <dmwit> Mathnerd314: Hah, in that thread is another idea.
09:09:25 <dmwit> Mathnerd314: https://mail.haskell.org/pipermail/haskell-cafe/2004-June/006259.html
09:10:41 <dmwit> Actually, on further consideration, that doesn't seem better. You still have to choose a unique collection identifier, and if you've already got a unique supply for collections, why not just use that for the IORefs themselves?
09:10:45 <dmwit> So never mind.
09:11:44 <Mathnerd314> that's what Jan Rochel did, it's interesting. (http://hackage.haskell.org/package/graph-rewriting-0.7.10/src/GraphRewriting/Graph/Internal.hs)
09:12:26 <Mathnerd314> but I was thinking direct IORef's would be better than an IntMap
09:17:06 <Mathnerd314> I guess the unique supply is the easiest.
09:26:22 <sushi1234> if I have this type `type Parse a b = [a] -> [(b,[a])]` and then `alt :: Parse a b -> Parse a b -> Parse a b` this function. how should i interpret this?
09:26:38 <sushi1234> `alt` takes two functions and returns a function?
09:27:09 <Mathnerd314> yep.
09:27:24 <sushi1234> `alt p1 p2 input = p1 input ++ p2 input` this is the definition, but i am a bit confused by the input, where did the input thing come from
09:27:43 <sushi1234> from my understanding there are only two arguments and suddenly alt definition is using three 
09:27:45 * hackage summoner 2.0.1.0 - Tool for scaffolding fully configured batteries-included production-level Haskell projects.  https://hackage.haskell.org/package/summoner-2.0.1.0 (vrom911)
09:28:15 <Mathnerd314> the extra parameter is because the last Parse a b is expanded.
09:28:49 <c_wraith> sushi1234: in a technical sense, all functions in Haskell have *exactly* one argument.  Writing out more at once is a convenient shorthand.  
09:28:57 <Mathnerd314> alt is at type `alt :: Parse a b -> Parse a b -> [a] -> [(b,[a])]`
09:29:44 * hackage summoner-tui 2.0.1.0 - Tool for scaffolding fully configured batteries-included production-level Haskell projects using TUI.  https://hackage.haskell.org/package/summoner-tui-2.0.1.0 (vrom911)
09:30:11 <c_wraith> sushi1234: it turns out that if your function returns a function, you can just pull it into function head.  there's no difference(*) between foo a b c = ...  and foo a b = \c -> ...
09:30:18 <Mathnerd314> c_wraith: nonsense, the core functions all use as many arguments as they can. Haskell has a special calling convention for partially applied functions ;-)
09:30:18 <sushi1234> so its `alt :: ([a] -> [(b, [a])] -> ([a] -> [(b, [a])]) -> [a] -> [(b, [a])]`
09:30:30 <sushi1234> ?
09:31:18 <c_wraith> sushi1234: * It's not quite true that argument count in the head doesn't matter.  Sometimes the optimizer takes advantage of that in GHC to determine when to inline.  But it doesn't change code meaning.
09:31:25 <c_wraith> sushi1234: yes, that's correct
09:31:44 <c_wraith> sushi1234: so is `alt :: ([a] -> [(b, [a])] -> ([a] -> [(b, [a])]) -> ([a] -> [(b, [a])])`
09:32:01 <c_wraith> sushi1234: those are two different ways of writing the same thing
09:32:15 * hackage lens-family-th 0.5.1.0 - Generate lens-family style lenses  https://hackage.haskell.org/package/lens-family-th-0.5.1.0 (DanBurton)
09:32:26 <merijn> Is there a literal for Infinity? No, right?
09:32:49 <c_wraith> sushi1234: the maximally-parenthesized version would be `alt :: ([a] -> [(b, [a])] -> (([a] -> [(b, [a])]) -> ([a] -> [(b, [a])]))`
09:33:21 <Mathnerd314> merijn: 1.0/0 ?
09:33:33 <c_wraith> merijn: like for floating point values?  No.  Could be made a pattern synonym I guess, but then someone would want a NaN pattern, and that is... stressful
09:34:03 <merijn> Mathnerd314: Yeah, I know that works, but not ideal :\
09:34:07 <sushi1234> c_wraith: I see, I was intepreting is as a function that takes two functions and returns a function since `Parse a b` is a function type
09:34:10 <sushi1234> c_wraith: thanks
09:34:32 <c_wraith> sushi1234: it is, in some sense.  Feel free to change viewpoints when it makes things easier.
09:34:50 <Ariakenom> 1/0 isnt a literal, but 1e1000 is
09:35:04 <Ariakenom> none of them are what you want though :p
09:35:22 <merijn> Ariakenom: 1e1000 isn't infinity, though, at least 1/0 is :p
09:35:34 <Ariakenom> > 1e1000
09:35:37 <lambdabot>  Infinity
09:36:01 <merijn> That's...questionable as hell
09:37:31 <Ariakenom> :D you are not in tune with hs' perfectly logical number system
09:38:03 <MarcelineVQ> > 1e1000
09:38:05 <lambdabot>  Infinity
09:38:27 <MarcelineVQ> lgtm, ship it, invest before IPO, dump after
09:38:52 <MarcelineVQ> hey, that's the wrong buffer you silly chat window you were supposed to > -1e1000
09:42:02 <solonarv> hey, don't blame haskell for this. this is entirely on the floating point standard.
09:42:08 <merijn> solonarv: It's not
09:42:23 <solonarv> okay, defaulting to 'Double' is haskell's fault.
09:42:39 <merijn> solonarv: Handling overflow in the conversion of literals is too
09:43:13 <solonarv> there's a warning for that, does it not work for fractional literals?
09:43:34 <c_wraith> Would you like to specify a better algorithm than "do an exponentiation and a multiplication?"
09:45:15 <ski> merijn : maybe one could make a pattern synonym
09:45:49 <c_wraith> ski: and then someone will ask for a NaN synonym
09:46:05 <merijn> c_wraith: Simple, just get rid of value NaN, problem gone!
09:46:19 <ski> there is that
09:46:21 <merijn> c_wraith: Also, NaN synonym is simple enough
09:46:34 <Ariakenom> c_wraith, exponentiation, multiplaction and a overflow (etc) check
09:46:38 <c_wraith> merijn: well, no.  It's not.  It has a massive semantic problem.
09:46:45 <merijn> c_wraith: Just do isNan
09:46:51 <c_wraith> merijn: either you violate IEEE754 semantics or Haskell semantics
09:46:52 <merijn> Next!
09:46:58 <merijn> c_wraith: How?
09:48:52 <c_wraith> Haskell says that pattern matching against numeric literals is done with (==), and IEEE754 says NaN == x is false for all x.  But if you provide a pattern, people will expect it to match NaN values, so it has to violate one of those three expectations.
09:49:05 <c_wraith> (or more!)
09:49:13 <merijn> c_wraith: Pattern synonyms aren't specified in Haskell at all
09:49:31 <merijn> c_wraith: They're certainly required to follow the pattern matching rules
09:49:44 <merijn> In fact, that's kinda their entire point
09:49:55 <merijn> So that's a bogus argument, imo
09:50:06 <c_wraith> I think you missed my point, because that doesn't address it.
09:50:24 <merijn> c_wraith: You argue that "matching against numeric literals is done with (==)"
09:50:32 <merijn> c_wraith: But ski was talking about pattern synonyms
09:50:49 <c_wraith> and?
09:50:56 <c_wraith> that doesn't invalidate anything.
09:51:03 <merijn> Pattern synonyms don't have any rules or specification at all
09:51:07 <c_wraith> I'm talking about user expectations, not rules.
09:51:17 <c_wraith> Users will expect both behaviors, because both are consistent
09:51:26 <c_wraith> except with each other
09:51:27 <merijn> Not a single user expects NaN to behave the way it does
09:51:39 <c_wraith> Except users who know floating point
09:51:42 <merijn> I honestly doubt more than a handful of people would be able to notice
09:53:34 <merijn> c_wraith: You think the intersection of "users who know FP well enough to know details of how IEEE-754 specifies NaN comparison" and "the set of people who know Haskell's pattern matching for numerical literal rules well enough to know it's done via ==" to *not* be smart enough to infer that a "NaN" pattern would use another method of matching to do the thing it logically obviously does?
09:54:04 <c_wraith> I'm saying I would absolutely not expect a NaN pattern to actually match NaN values.
09:54:40 <c_wraith> It would be both inconsistent with IEEE-754 and potentially throw information away.
09:55:22 <wavemode_> if someone wants to violate IEEE, they can newtype over Double themselves...
09:55:37 <c_wraith> (because as long as you're doing IEEE-754, you should be aware that different NaN values can signal different errors)
09:55:46 <merijn> We should just get rid of value NaN entirely in Haskell
09:55:49 <merijn> It's bogus
09:55:59 <wavemode_> that's impractical
09:56:05 <merijn> wavemode_: It's not
09:56:11 <c_wraith> If you want to use something other than Double... Great!  Double is garbage in a lot of ways.
09:56:22 <merijn> c_wraith: No, I want Double without value NaN
09:56:32 * ski . o O ( signalling `NaN's ? )
09:56:36 <merijn> ski: Yes
09:58:11 <wavemode_> there is no such thing as Double without nan and inf. it would be something different from Double. it would be Decimal (which already exists).
09:58:39 <merijn> wavemode_: There's no such thing as IEEE-754 double without NaN. There *is* such a thing as IEEE-754 double without value NaN
09:59:15 <merijn> Which would also fix and make lawful the Eq and Ord classes for Double
10:00:46 <c_wraith> isn't that a significant performance hit on existing hardware?
10:00:59 <merijn> c_wraith: Why?
10:01:16 <merijn> c_wraith: Any CPU since the early nineties supports trapping on floating points
10:01:35 <c_wraith> Yes, but if you have to install a handler for every FP operation...
10:01:37 <merijn> c_wraith: So the only overhead is when you actually hit a signalling NaN
10:01:46 <merijn> c_wraith: Why?
10:01:47 <hyperisco> What about our machine from the 70s that runs payroll?
10:02:00 <merijn> c_wraith: You can just install one handler and leave it
10:02:37 <merijn> c_wraith: You need to fiddle a bit around FFI calls, sure. But why would you reinstall a handler around every individual operation.
10:04:25 <MarcelineVQ> Does anyone have this?  http://www.cse.unsw.edu.au/~dons/tmp/chunksize_v_cache.png  https://hackage.haskell.org/package/bytestring-0.10.10.0/docs/src/Data.ByteString.Lazy.Internal.html#smallChunkSize 
10:04:52 <hyperisco> ghcjs is left in the cold on this I think
10:05:23 <MarcelineVQ> ^ dcoutts
10:06:01 <hyperisco> merijn, is it worth talking about NaN? if you don't construct it then it doesn't exist :)
10:06:23 <c_wraith> merijn: I was assuming you wanted accurate exception info.  But I guess Int 1/0 doesn't vie you accurate exception info, either.
10:06:29 <merijn> hyperisco: That assumes it's only ever constructed intentionally
10:06:42 <merijn> c_wraith: Why would you get inaccurate info, though?
10:06:46 <hyperisco> If it is constructed unintentionally then that is an error. It is undefined behaviour. Why not?
10:07:09 <merijn> c_wraith: You know the exact spot you trapped, with GHC's new DWARF stuff you could even create a stack trace!
10:07:09 <c_wraith> hyperisco: because C's conception of "undefined behavior" is far worse than anything NaN does
10:07:14 <merijn> hyperisco: What
10:07:24 <merijn> hyperisco: NaN isn't undefined behaviour
10:07:32 <merijn> hyperisco: In fact, it's pretty strictly and rigidly defined
10:07:34 <hyperisco> We're not talking about NaN anymore :)
10:07:48 <hyperisco> It doesn't exist. Now 1/0 in Double is just undefined.
10:08:06 <c_wraith> "the program did something invalid, so I'm free to pretend it didn't happen" is a terrible policy choice and easily the worst mistake C ever allowed.
10:08:07 <merijn> hyperisco: 1/0 isn't NaN
10:08:17 <hyperisco> 0/0
10:08:18 <monochrom> NaCl (not a closure) can cause segfaults :)
10:08:28 <hyperisco> The whatever expression that reduces to NaN
10:08:51 <merijn> hyperisco: It's not undefined either, it's bottom
10:09:10 <merijn> And the semantics of bottom in Haskell are well established
10:09:28 <hyperisco> The runtime tests for zero divisor?
10:09:33 <hyperisco> > 0/0 :: Double
10:09:35 <lambdabot>  NaN
10:09:50 <hyperisco> Looks like not a number to me
10:09:52 <merijn> hyperisco: The entire point of trapping NaN is that it creates an exception
10:10:24 <hyperisco> Which is represented how?
10:10:42 <monochrom> Bah this is a pointless discussion.
10:10:50 <merijn> hyperisco: The entire point of trapping NaN (as opposed to value NaN) is that it doesn't *have* a representation
10:11:02 <hyperisco> You're suggesting bottom?
10:11:06 <merijn> Anyway, we're now starting to rehash the starting point
10:11:18 <merijn> hyperisco: I'm suggesting an exception, so yes, bottom
10:11:40 <hyperisco> Alright
10:11:50 <hyperisco> I'm happy saying bottom is as good as undefined
10:12:31 <merijn> Entirely unrelated, more interesting question
10:12:59 <merijn> Does the FFI have a convenient combinator for allocating memory, copying a Storable value into it and returning the Ptr?
10:13:36 <solonarv> % :t Foreign.new
10:13:36 <yahb> solonarv: Foreign.Storable.Storable a => a -> IO (Ptr a)
10:13:50 <Mathnerd314> hyperisco: but exceptions aren't actually undefined. `undefined` is in the Prelude. So it's really about perception, of what's 'good practice' vs bad
10:14:02 <merijn> solonarv: \o/
10:14:03 <solonarv> % :t Foreign.with -- see also this
10:14:03 <yahb> solonarv: Foreign.Storable.Storable a => a -> (Ptr a -> IO b) -> IO b
10:14:19 <merijn> solonarv: Yeah, but that's no good for pointers I need to pass to C :)
10:14:44 <hyperisco> Mathnerd314, I have no qualms with defining what it means to be undefined.
10:14:45 <solonarv> yeah, of course - I didn't know what exactly you needed it for
10:14:54 <monochrom> It could be good if the C side doesn't hold on to the pointer for long.
10:15:18 <solonarv> I also defined 'allocaPeek f = alloca \p -> f p >> peek p' for out parameters
10:15:47 <merijn> monochrom: Iny my case I need to pass control of the lifetime to C :)
10:15:48 <hyperisco> Yes, C-style is to not define undefined, but that's just C's opinion.
10:16:26 <merijn> I was gonna go with: bracketOnError (new x) free
10:16:38 <wavemode_> MarcelineVQ: I did some digging. It looks like that file was added in 2006 by Don Stewart (donsbot.wordpress.com). I do wonder whether he still has it and, also, whether the numbers are still relevant...
10:18:16 <MarcelineVQ> yeah it wasn't on the wayback (that I could find)  they'd be relevant enough to be interesting at least, insofar as cache's are still cache's even if they're bigger or there's more in the heirarchy by now
10:18:56 <MarcelineVQ> hmm I should ask in ghc since I don't know everyone's handles to ping
10:19:17 <wavemode_> he also has contact info on his website
10:19:59 <MarcelineVQ> contacting people is scary :>
10:22:57 <hyperisco> So what is  main = putStrLn "Hello Sailor!" *> main  ?
10:23:29 <wavemode> :t (*>)
10:23:30 <lambdabot> Applicative f => f a -> f b -> f b
10:23:45 * hackage mighty-metropolis 2.0.0 - The Metropolis algorithm.  https://hackage.haskell.org/package/mighty-metropolis-2.0.0 (JaredTobin)
10:23:50 <monochrom> *> is the Applicative version of >>
10:23:50 <wavemode> :t (>>)
10:23:52 <lambdabot> Monad m => m a -> m b -> m b
10:24:11 <c_wraith> it's an IO value that represents an infinite loop that continually causes output but never produces a value that can be chained with (>>=)
10:24:14 <hyperisco> I guess I should use more words. Is it bottom or non-bottom?
10:24:15 <c_wraith> nothing undefined there at all
10:24:19 <c_wraith> non-bottom, of course
10:24:24 <c_wraith> you can evaluate it.
10:24:46 <c_wraith> You can even execute it.
10:25:05 <ski> it's similar to `ones = 1 : ones'
10:25:24 <monochrom> This is where the simple model "infinite loop = bottom" breaks. Productive infinite loop ≠ bottom
10:25:48 <merijn> monochrom: It's just the Halting Problem-problem :)
10:25:48 <hyperisco> My question could be phrased as asking what it is producing
10:25:51 <monochrom> This is also where you need to replace termination by liveness.
10:26:05 <ski> it's producing Input/Output interactions
10:26:12 <hyperisco> I'm not sure how far under the IO bonnet we should be looking to justify an answer
10:26:17 <monochrom> It produces a lot of output.
10:26:22 <merijn> monochrom: "I have vaguely heard something explained in the past, so I'm just going to redefine it to mean what I think it logically should mean with my understanding"
10:26:35 <merijn> hyperisco: We don't have to look under IO at all
10:26:50 <monochrom> You may need a formal model for IO, sure.  There are plentiful in formal methods and automata theory.
10:27:21 <c_wraith> If you want something that applies easily, you can look to the model of IO edwardk built for ermine
10:27:31 <monochrom> "models of talking to the outside world" is a solved problem.
10:28:19 <c_wraith> that's actually one of the examples he used to justify why the model ermine uses is a good way of thinking of things.
10:29:28 <wavemode> by contrast, `f = f` is bottom. f could be any type and the binding would still be valid
10:29:47 <mniip> if it's a top level binding then only lifted types
10:30:15 <monochrom> FWIW, "need to look under the hood for IO" : IO semantics :: "need to look under the hood for lazy evaluation" :: denotational semantics.
10:30:17 <mniip> MarcelineVQ, just wait till you have to email phd people about stuff they're experts in
10:30:21 <monochrom> IOW, you don't need them.
10:31:00 <monochrom> darn, missed a pun opportunity
10:31:08 <dmwit> hyperisco: For normal data structures, constructor applications are productive (and nothing else is). For IO, the data type is abstract; but (>>=) and (<*>) are productive.
10:31:21 <monochrom> "need to get to the bottom of lazy evaluation" : denotational bottom.  There!
10:32:01 <hyperisco> dmwit, >>= and <*> are productive for IO, you are claiming?
10:32:09 <dmwit> hyperisco: So IO definitions where the recursive call is not guarded by (>>=) or (<*>) are going to be a problem. Definitions where the recursion is guarded by those will be fine.
10:32:14 <dmwit> hyperisco: Correct.
10:32:30 <dmwit> hyperisco: (And (*>) calls (<*>).)
10:32:45 <monochrom> No dmwit, I think you want to cover your six by only saying ">>= and <*> preserve productiveness"
10:33:11 <dmwit> Do I? I don't think I do.
10:33:13 <monochrom> because if foo is not productive then foo >> foo is not productive either
10:33:26 <monochrom> for example foo = foo >> foo >> foo
10:33:27 <dmwit> It is not `repeat`'s fault if you pass it `undefined`.
10:33:34 <dmwit> Similarly it is not `forever`'s fault if you pass it undefined.
10:34:00 <dmwit> monochrom: The recursion there is not guarded by (>>=).
10:34:11 <dmwit> Ah, okay: now we must say what "guarded" means.
10:34:27 <hyperisco> Don't waste it on me
10:34:28 <dmwit> The second arguments to (>>=) and (<*>) are guarded. The first are not.
10:35:08 <monochrom> guarded by X means when written in prefix notation the head is X. For example (>>) foo foo is guarded by (>>)
10:35:22 <dmwit> Okay. Then I must use a different term than "guarded". I am okay with that.
10:35:28 <dmwit> Pick one for me. Or use "blargle by".
10:36:01 <monochrom> I should tell you how I came to this.
10:36:31 <hyperisco> Probably not related: how do we justify throwing exceptions as an effect of executing bottom?
10:36:57 <monochrom> I want to reserve the adjective "productive" for terms of type "IO X".
10:36:59 <hyperisco> Is it just because we stop caring what the effects are at that point?
10:37:04 <mniip> does that really need justification?
10:37:38 <wavemode> how do we justify it? via moral relativism. i.e. the alternative is worse
10:37:44 <monochrom> Like for example in topology I don't say "union is open", I say instead "union preserves openness", because "open" is for the subsets.
10:37:45 <mniip> I mean it's really just that `undefined >>=@IO f` = `undefined`
10:38:35 <monochrom> This is unlike strictness where, e.g., a function f itself has a certain strictness, and then f x has another strictness.
10:38:51 <mniip> now the question is what should `catch undefined` do
10:39:00 <hyperisco> Really, I could run any program as an effect of bottom
10:39:25 <dmwit> You can run any program as an effect of any IO action.
10:39:30 <mniip> unfortunately `catch` has to be strict in its first argument
10:39:38 <mniip> errr
10:39:39 <mniip> wait
10:39:43 <mniip> does that make sense
10:39:45 <dmwit> How do we justify printing to the screen as an effect of executing `print 0`?
10:39:58 <monochrom> Yes catch is strict :)
10:40:03 <mniip> could we have `catch undefined = undefined`
10:40:07 <hyperisco> So in some sense,  main = main  can be made equivalent to any other program, in terms of effects
10:40:19 <c_wraith> hyperisco: http://comonad.com/reader/2011/free-monads-for-less-3/
10:40:29 <monochrom> What is the type of catch?
10:40:37 <mniip> :t Control.Exception.catch
10:40:38 <lambdabot> Exception e => IO a -> (e -> IO a) -> IO a
10:40:47 <mniip> in particular @SomeException
10:40:48 <dmwit> hyperisco: Their our know lawz. Any program can be made equivalent to any other program if you're just making up a new semantics.
10:41:12 <merijn> dmwit: Whoo!
10:41:15 <dmwit> hyperisco: So: you must exercise some taste. It is better to say that `print 0` prints, and that `undefined` throws an exception, because that's the obvious thing to do.
10:41:18 <mniip> hyperisco, formalize what it means for effectful programs to be equivalent
10:41:34 <merijn> mniip: Intensional equality, done!
10:41:40 <merijn> Next! ;)
10:41:41 <hyperisco> mniip, I don't have IRC room for that
10:41:45 <monochrom> consider catch (let foo = foo >> foo in foo) (\e -> ...)
10:41:45 <mniip> no extensionality at all?
10:41:59 <merijn> mniip: I wanna be done before dinner :(
10:42:07 <monochrom> Hrm, may be not a good example.
10:42:50 <monochrom> consider catch (let ps = repeat (print 0) in last ps) (\e -> ...)
10:43:09 <dmwit> % catch undefined (\e -> putStr "catch is not strict" >> print (e :: SomeException))
10:43:09 <yahb> dmwit: catch is not strictPrelude.undefined; CallStack (from HasCallStack):; error, called at libraries/base/GHC/Err.hs:79:14 in base:GHC.Err; undefined, called at <interactive>:26:7 in interactive:Ghci12
10:45:16 <monochrom> mniip: I use obervational equality
10:45:34 <mniip> which is maximally extensional
10:45:36 <mniip> :P
10:45:48 <monochrom> for example "forever (print 0 >> print 0)" and "forever (print 0)" are equivalent.
10:46:05 <mniip> how to formalize this though
10:46:15 <monochrom> Bisimulation etc?
10:46:45 <monochrom> But I have also specialized "effect" to "I/O effect".
10:46:53 <mniip> equality in a free monad interpretation of IO?
10:47:01 <monochrom> So, again, any of the I/O models from formal methods and automata theory
10:47:06 <mniip> but I think we're getting outside of where we can apply fast+loose comfortably
10:47:57 <monochrom> Oh free I/O is easy. The monad type is an infinite-tree type. Just equality of infinite trees.
10:48:10 <monochrom> (which is then bisimulation again)
10:48:56 <dolio> forever (print 0) = print 0 >> forever (print 0) = print 0 >> print 0 >> forever (print 0) = (print 0 >> print 0) >> forever (print 0)
10:49:09 <dolio> Ergo, forever (print 0) = forever (print 0 >> print 0).
10:49:19 <monochrom> Bisimulation is just a lengthy mathy way of saying a very intuitive fast loose thing of "the user cannot make these two machines behave differently"
10:49:21 <mniip> did you just do coinduction
10:49:28 <dmwit> Bisimulation seems tricky in the presence of concurrency.
10:49:29 <monochrom> yeah
10:49:46 <dolio> No, I did equational reasoning.
10:50:34 <dolio> `forever (print 0)` satisfies the same equation as the defining equation of `forever (print 0 >> print 0)`.
10:50:36 <mniip> you used the terminal-coalgebra-unique property of "forever"
10:50:56 <mniip> that if "x = (print 0 >> print 0) >> x" then "x = forever (print 0 >> print 0)"
10:51:21 <mniip> right
10:51:26 <monochrom> Yeah coinduction justifies Haskell's use of "=" for these recursive definitions.
10:51:36 <mniip> that is not exactly coinduction but it's somewhere close
10:55:01 <dolio> It was actually the uniqueness property of least fixed points of domain equations, I think.
10:55:34 <monochrom> You need both.
10:56:17 <monochrom> When you write "foo = ... foo ...", yes, regardless of type (provided type-checked), it's a least fixed point and induction thing.
10:56:27 <monochrom> But when the type is IO X, what then?
10:57:08 <monochrom> f :: IO () could be a program that produces an infinite stream. This is where you need greatest fixed point and coinduction.
10:58:16 <monochrom> You're doing both.  You're doing lfp at the overarching level.  For a few types like IO, you're doing coalgebra to define IO itself before you can call it a domain for your outer lfp level.
10:59:42 <dolio> Every type is both least and greatest in this setting. IO isn't any different.
10:59:46 <monochrom> For example what does "f = g" even mean when f, g :: IO ()
11:00:45 <dolio> That doesn't matter.
11:01:07 <monochrom> It doesn't matter after someone else has worked it out.
11:01:31 <monochrom> or at least has proved that equality exists
11:01:36 <dolio> I didn't use the definition of equality. I used the hypothesized associativity of monadic stuff, regardless of what equality actually means, and deduced that they satisfy the same recursive domain equation.
11:02:02 <monochrom> "equation" means you took for granted that equality exists.
11:02:22 <mniip> actually that's not coinductive either
11:02:42 <mniip> I don't think we can consistently consider >>= as a constructor  "guarding" corecursion
11:03:16 <mniip> `f = f >>= ...` doesn't actually produce any effects
11:03:24 <dolio> Yes, of course I took for granted that it exists, and satisfies known rules. It doesn't matter what the details of its specification is beyond that, though.
11:03:35 <mniip> it is guarded on the right hand side however
11:03:50 <mniip> except `f = return () >>= const f`
11:09:56 <lyxia> 1 = id 1 = id 0 = 0   #EquationalReasoning
11:10:21 <monochrom> Wait how do you get id 1 = id 0?
11:10:23 <dolio> For instance, my proof doesn't care about IO, it is just as good for `forever x = forever (x >> x)`
11:11:09 <lyxia> by the same process you get print 0 >> print 0 >> forever (print 0) = print 0 >> print 0 >> forever (print 0 >> print 0)
11:11:31 <mniip> lyxia, that's not the step that was used
11:11:40 <monochrom> How do you prove cycle [False, True] = map even [0..] ?  This represents the gist of what I'm getting at, and it extends to IO.
11:12:52 <lyxia> mniip: ok yeah you're right
11:13:31 <mniip> generalize to forall k, cycle [False, True] = map even [2*k..]
11:13:46 <monochrom> (My answer is the "take-n theorem". I forgot who stated and proved it in a paper, will look for it soon.  TL;DR xs=ys iff for all n, take n xs = take n ys.  The take-n theorem has the feel of coinduction or bisimulation, and its proof is exactly that.)
11:13:49 <mniip> cofixpoint. cycle [False, True] = False:True:cycle [False, True] = {by coinductive hypothesis} = False:True:map even [2*(k+1)..] = map even [2*k..], qed by coinduction
11:27:28 <hseg> ok, i'm back.
11:27:46 <hseg> testing, the ghcid issue doesn't seem to be a matter of escaping the !
11:28:01 <hseg> eg --test='print "hello"' has the same issue
11:51:56 <monochrom> It's the "take lemma" initially from Bird and Wadler.  Andrew Gordon gave a coinduction proof of the take lemma.  Probably Bird and Wadler started from lfp.
11:54:04 <monochrom> the Andrew Gordon paper is "A Tutorial on Co-induction and Functional Programming"
11:55:07 <monochrom> Haha, Bird and Wadler's is their old FP/Haskell textbook.  So I guess it just states the lemma without proof.
11:55:42 <hseg> monochrom: ?
11:56:53 <syd52> How do I join the functional programming slack?
11:56:59 <monochrom> No, wait, I think it has a proof in their setting.  They used this principle: to prove "for all list xs" (there are restrictions), prove it for bottom, for [], and for x:xs inductively
11:57:26 <monochrom> hseg: It's a continuation from an earlier discussion.
11:57:45 <hseg> ah, ok
12:15:20 <hseg> ok, ghcid problem solved. this is a bug in cmdargs, which splits words too aggressively
12:21:07 <berndl> Is there a popular library for working with probability distributions and sampling from them?
12:22:38 <nil> mniip: how does that coinduction work? more generally, how does a "coinductive hypothesis" work and where can i read about this?
12:23:31 <nil> i'm used to proofs by induction where you have to make sure something is strictly decreasing, so i assume the dual of that is that something should be strictly increasing, i.e. productivity?
12:23:45 <berndl> Yes, that's right.
12:24:17 <berndl> e.g. ones = 1 : ones is a coinductive (or corecursive) definition
12:26:13 <nil> i'm interested in the logic side, as in how you formalise a coinduction principle
12:26:44 <nil> maybe i should look at the general induction principle and trying flipping things around
12:26:46 <monochrom> nil: Perhaps look for Bart Jacob and Jan Rutten's "a tutorial on (co)algebras and (co)induction"
12:26:52 <nil> that sounds good
12:34:33 <enthropy> the old haskellmode-vim had bindings for adding pragmas (specifically https://github.com/lukerandall/haskellmode-vim/blob/cd852bdaa85f52854782434926a6e752f6a61c89/compiler/ghc.vim#L568 ). What do people that use other vim modes do?
12:34:50 <berndl> nil: If you have Pierce's book "Types and Programming Languages", he talks about the formal side in Chapter 21.
12:35:43 <nil> thanks
12:48:38 <turion> I have a cabal package, and I'm doing cabal repl with a .ghci file. The .ghci file contains :m + MyModule, and that module is listed in my library under exposed-modules. Still, I'm getting: attempting to use module `bladibladibla’ which is not loaded
12:49:28 <turion> Would you expect this to work?
12:50:30 <turion> I forgot to add, I also did :set -package mypackage as the first line
12:52:34 <wavemode> There have been so many complaints about .ghci files in the past couple days. It makes me wonder was there a recent update which broke them?
12:53:35 <turion> Oh, this is ghc 8.6.5, so it wasn't very recently broken ;)
12:54:04 <turion> But I will play around with different ghcs, that's maybe a good start
12:57:49 <turion> The funny thing is, after the .ghci file is loaded, it compiles and loads both modules.
12:57:54 <monochrom> I don't think ":set -package mypackage" mixes well with "cabal repl"
12:58:04 <turion> I mean it loads that module
12:58:19 <monochrom> Gosh, no, it means nothing like that.
12:58:56 <monochrom> cabal repl has its own suite of "-package this", "-package that". I don't think you should muck with it.
12:59:15 * hackage haskoin-store-data 0.30.1 - Data for Haskoin Store  https://hackage.haskell.org/package/haskoin-store-data-0.30.1 (jprupp)
12:59:17 <turion> monochrom: If I leave it out, it says Could not load module, It is a member of the hidden package bladibla, even suggesting I should add the package to the dependencies
12:59:21 <monochrom> Especially not when you haven't carefully studied what "-package" really means from the GHC user guide.
13:00:15 * hackage haskoin-store 0.30.1 - Storage and index for Bitcoin and Bitcoin Cash  https://hackage.haskell.org/package/haskoin-store-0.30.1 (jprupp)
13:01:31 <turion> monochrom: What makes you assume I haven't? It says it loads the package. I was hoping I might make it load the package soon enough for my purposes
13:02:24 <turion> It tells me the package is hidden, so I try -package. The strange thing is maybe that it's hidden at all
13:02:58 <wavemode> well, cabal repl is getting its package list from the .cabal file, right?
13:04:48 <turion> Yes
13:05:12 <wavemode> I believe that is where you have to add packages
13:05:19 <turion> Should I maybe specify a target on the command line?
13:05:46 <turion> wavemode: How would I specify the package itself?
13:06:02 <wavemode> build-depends
13:06:20 <turion> I should add the library as its own build-depends?
13:06:40 <wavemode> uh maybe im misunderstanding your use case
13:06:45 <turion> That gives a dependency cycle :/
13:07:28 <turion> wavemode: Sorry, I'll explain better:
13:07:59 <turion> I have a .ghci file that uses some definitions from the package I'm developing
13:08:43 <turion> Basically in my module MyModule, I have a definition foo, and I want to get :set foo foo working in my .ghci file
13:08:59 <turion> But it tries to execute the :set directive before MyModule is loaded
13:09:16 <turion> I thought the correct solution is to manually load that module first then
13:09:31 <turion> But I can't figure out how. It works for other packages, though
13:09:53 <turion> I mean it works for packages that aren't the one I'm currently developing
13:11:43 <monochrom> exe targets can depend on the lib target. This is not circular.
13:11:57 <wavemode> in a .cabal file, you can specify both a library and an executable. so that the library has a list of module in its `exposed-modules` and the executable has those modules it needs in its `other-modules`
13:13:08 <turion> I don't have an exe
13:13:21 <turion> I could add one if that helps somehow
13:13:53 <monochrom> Then I don't think I've ever reproduced this problem.
13:14:56 <turion> Hmmm If I add an exe and I do cabal repl exe:myexe, and add my library as a dependency to the exe, it works
13:16:09 <turion> I guess that's a good enough workaround for now. Thanks monochrom, wavemode!
13:16:42 <monochrom> "-package ⟨pkg⟩   This option causes the installed package ⟨pkg⟩ to be exposed."  So if you say "load" not "expose" I know you haven't read that.
13:18:23 <turion> It's funny you think that when I have the manual page right on my screen
13:19:20 <monochrom> default ghci behaviour is expose everyone and then you can hide some packages explicitly.  cabal does the opposite, issues a -hide-all-packages and then issues individual "-package foo" instructions to expose just the ones listed on build-depends.
13:20:51 <turion> Yes
13:21:07 <turion> And I wanted the package itself exposed
13:31:15 * hackage conduit-zstd 0.0.2.0 - Conduit-based ZStd Compression  https://hackage.haskell.org/package/conduit-zstd-0.0.2.0 (luispedro)
13:32:28 <koz_> I submitted a package to Stackage, which blew up because of an unrelated issue (or rather, package) to mine. This has now been fixed, but the CI still shows broken. Who needs to notice me, senpai?
13:34:10 <wavemode> what package?
13:34:34 <koz_> wavemode: Medea: https://github.com/commercialhaskell/stackage/pull/5377
13:36:59 <hexagoxel> koz_: just rebase the PR on top of current master, force-push?
13:37:41 <koz_> hexagoxel: Yeah, can do.
13:37:55 <Cheery> Why go through the trouble of Haskell's syntax if you going to make it still incompatible with Haskell?
13:37:56 <koz_> How would I rebase my fork?
13:38:10 <Cheery> This purescript thing..
13:38:52 <berndl> Cheery: because JS
13:39:00 <jumper149> Cheery: That's also my experience. I like the design choices of purescript though
13:39:18 <jumper149> berndl: GHCJS is compatible with GHC :p
13:40:22 <berndl> jumper149: record types are more compatible with Javascript objects
13:41:32 <wavemode> there are projects like Haste, which are more directly "compile haskell to javascript"
13:41:43 <wavemode> purescript had a slightly different goal
13:42:17 <berndl> I like the fact that Purescript libraries are "cleaner" than in Haskell.
13:44:10 <berndl> The JS FFI is pretty nice too.
13:44:21 <Uniaika> jumper149: GHCJS is not compatible with ADSL people :P
13:45:41 <Cheery> where's "undefined" in purescript?
13:45:54 <Cheery> it didn't replicate Elm's design flags, did it?
13:46:05 <Cheery> flaws*
13:46:59 <jumper149> Cheery: btw #purescript exists on freenode
13:48:13 <Rembane> Cheery: And they have a Slack channel if that's more of your game. 
13:48:26 <hseg> trying to generate a local hoogle index, it complains it can't find docs for boot packages (array, base, binary, ...)
13:48:30 <berndl> Cheery: It's defined in a library.
13:49:56 <hseg> any danger in doing cabal install --reinstall on the lot?
14:06:29 <hseg> hrm. that did nothing
14:07:20 <hseg> so i neither can get local docs for base nor can my local hoogle instance support it
14:09:17 <xd1le> purescript is more about js interop rather than Haskell reuse. That said, I don't know how good gchjs js interop is, maybe it's also good.
14:10:09 <xd1le> (also I don't know what undefined is in purescript)
14:10:17 <xd1le> lol
14:11:41 <Cheery> it's a symbol you can use if you happen to know some state in the program is unreachable and you don't need to worry about it.
14:12:27 <xd1le> I know js just not how purescript handles it
14:18:15 <hseg> hrm. ok, so this is because of my half-assed relocation of the hoogle database
14:18:54 <hseg> i thought hoogle generate -d some/path would suffice for all queries of form hoogle -d some/path
14:36:48 <Guest_79> hi everyone.
14:37:49 <Guest_79> how do i fully uninstall ghcup and cabal?
14:38:04 <Guest_79> can't find the instructions anywhere
14:38:09 <solonarv> 'rm -rf ~/.cabal ~/.ghcup'
14:38:17 <solonarv> there are no instructions because that's all you need to do
14:38:23 <Guest_79> thanks!
14:39:17 <solonarv> oh, you may want to delete the part of your ~/.bashrc (or whatever) that adds cabal/ghcup stuff to $PATH
14:40:48 <Guest_79> yes. just did that
14:40:52 <Guest_79> thank you again
14:53:32 <theelous3> hi
14:54:15 * hackage zeolite-lang 0.7.0.2 - Zeolite is a statically-typed, general-purpose programming language.  https://hackage.haskell.org/package/zeolite-lang-0.7.0.2 (ta0kira)
14:56:15 <theelous3> so I'm doing beta reduction, doing one from the hffp book, the last exercise is (λxyz.xz(yz))(λx.z)(λx.a), which at some point in evaluation leads you to have the z bound from the head of the first lambda and the z from the body of the second one
14:57:00 <theelous3> the whole thing reduces to λz.za, where the z of the head is from the head in the beginning, and the z in the body is from the body of that second lambda from the beginning
14:57:30 <theelous3> if I had (λz.za)(2), would that be 2a?
14:57:33 <theelous3> or za?
14:58:13 <solonarv> it would be 2a
14:58:29 <solonarv> when you are doing beta reduction, make sure you don't get any name clashes!
14:59:20 <solonarv> the 'z' in (\x y z. ...) and the 'z' in (\x. z) are *not* the same
15:00:58 <dwt> right, that second z is free in the original term
15:01:24 <dwt> just like the a in \x.a
15:01:34 <tromp> so result is λ_.za
15:02:19 <solonarv> the easiest way to avoid this issue is to re-name variables before doing substitution
15:03:19 <solonarv> so the whole thing becomes: (\x1 y1 z1. x1 y1 (y1 z1)) (\x2. z) (\x3. a)
15:11:15 * hackage morpheus-graphql-core 0.12.0 - Morpheus GraphQL Core  https://hackage.haskell.org/package/morpheus-graphql-core-0.12.0 (nalchevanidze)
15:12:16 * hackage morpheus-graphql 0.12.0, morpheus-graphql-client 0.12.0 (nalchevanidze): https://qbin.io/went-faced-wbxb
15:23:51 <theelous3> solonarv: that's what I mean by would it be za, because the z in the head is not the z in the body, because of clash
15:24:03 <theelous3> why is it 2a?
15:25:46 <theelous3> like, is it not really (λz'.za)(2) -> za, where the two is bound to z' and dropped?
15:34:03 <LevelChart8> where is OAuth imported from? Getting "Not in scope: type constructor or class ‘OAuth’" while trying to install https://github.com/obsidiansystems/obelisk-oauth
15:41:01 <solonarv> theelous3: well, no. if you start with (\z. z a) and want to rename z to z', you have to also change it in the lambda's body!
15:41:21 <solonarv> so it turns into (\z'. z' a)
15:45:36 <koz_> solonarv: Ah, bound naming. That thing tripping up logicians since 1930 or so.
15:49:23 <dwt> this is what makes de Bruijn indices so attractive even if it is a "Cylon detector": (\z . z a) = (\.a), (\xyz.xz(yz))(\x.z)(\x.a) = (\\\.2 0 (1 0))(\.z)(\.a)
15:49:35 <koz_> dwt: Lol.
15:50:13 <oats> lol, never heard that before
15:50:59 <koz_> oats: I think it was a Conor McBride-ism. Someone in Academic Haskell mentioned that De Bruijn indices are a Cylon detector, because no human would want to work with them voluntarily.
15:52:54 <monochrom> wait, why is de bruijn indexing a cyclon detector?
15:53:12 <koz_> monochrom: Cylon, not cyclon.
15:53:16 <koz_> (BSG reference)
15:53:41 <monochrom> typo. cylon detector.
15:54:03 <monochrom> oh, that, haha
15:54:16 <koz_> I forget who said that though.
15:55:15 * hackage trek 0.0.1.0 -   https://hackage.haskell.org/package/trek-0.0.1.0 (ChrisPenner)
15:55:31 <monochrom> If machine learning results in a thing that's as bad as humans at lambda calculus, does that make the thing intelligent?
15:56:26 <monochrom> To make it more interesting and controversial and dilemmatic, let's say that thing is also as good as humans at classifying cat pics.
15:56:31 <oats> https://twitter.com/edwinbrady/status/857585751684501504
15:56:33 <oats> ah, found it :D
15:56:39 <monochrom> (the holy grail of machine learning, I guess?)
15:56:53 <koz_> Yep, called it, it is a McBride-ism.
15:56:59 <koz_> (Conor has a _very_ particular way with words)
15:58:16 * hackage trek-lens 0.0.1.0 -   https://hackage.haskell.org/package/trek-lens-0.0.1.0 (ChrisPenner)
16:02:45 <monochrom> In bash, is there a way to print a message after you enter a command but before the command is run?  Just so that it says "by your command" :)
16:03:09 <koz_> monochrom: So you mean, whenever you do anything, do that first?
16:03:14 <koz_> So it would go like
16:03:16 <koz_> ls
16:03:19 <koz_> by your command
16:03:21 <koz_> [list of dir]
16:03:24 <monochrom> yeah!
16:06:26 <Uniaika> hmm, bash is fairly rudimental, you'll have to alias `ls` to `echo "by your command" && ls`
16:07:49 <edwardk> koz_: when i asked him, IIRC, mcbride attributed the original cylon reference to bob atkey
16:10:10 <mlugg> How do Haskell compilers do dependency analysis for identifying binding groups (at top-level or in a let)? I cannot figure out a nice algorithm to do it :p
16:10:12 <justsomeguy> koz_: "trap 'echo by your command' DEBUG"
16:10:36 <justsomeguy> koz_: Unfortunately it also runs when PROMPT_COMMAND is executed.
16:10:54 <koz_> edwardk: Lol, figures.
16:10:59 <koz_> Thanks for the extra bit of history though!
16:11:47 <monochrom> mlugg: build a dependency graph (I hope you know this much), then run a strongly-connected-component algorithm
16:12:09 <monochrom> "binding group" = strongly-connected component
16:12:10 <koz_> Sharir-Kosaraju is the name of one I happen to know about.
16:12:26 <koz_> (assuming I'm not horribly mis-spelling one of those names)
16:17:42 <theelous3> solonarv sorry for the weirdly long breaks in this convo 
16:17:52 <theelous3> but I'm not starting with \z.za am I?
16:18:04 * justsomeguy tries tab completion and gets four pages of "by your command" displayed to his terminal.
16:18:08 <theelous3> because the z in the head is not the z in the body
16:18:19 <theelous3> which is what I was trying to get at with z' vs z
16:20:16 <theelous3> so at the end of the reduction we have z1 which came from some lambda head, and z which came from some body
16:20:50 <theelous3> book says we end with \z1.za, which is fine and makes sense, I'm just wondering if z1.za is the same as z.za
16:21:59 <theelous3> if so, why do we bother marking a difference?
16:22:12 <theelous3> I get that you probably already answered this but I'm not understanding :)
16:24:45 * hackage calamity 0.1.9.0 - A library for writing discord bots  https://hackage.haskell.org/package/calamity-0.1.9.0 (nitros12)
16:35:17 <justsomeguy> theelous3: Are you talking about the last exercise of ch 1 in Haskell Programming From First Principles?
16:41:05 <justsomeguy> theelous3: Try doing the reduction again, but use alpha equivalence to change the letters, so that (λxyz.xz(yz))(λx.z)(λx.a) becomes (λxym.xm(ym))(λo.z)(λp.a), first.
16:41:53 <wavemode> theelous3: no, z1.za is not the same as z.za . z gets renamed to z1 to disambiguate. they're not the same variable.
16:42:11 <wavemode> z1.za is equivalent to a.za or b.za, but not (the ambiguous) z.za
16:42:27 <wavemode> not a.za lol. also ambiguous
16:43:03 <justsomeguy> theelous3: The z¹ can be changed to a different letter, but the z within the body can't, because it's a free variable.
16:43:54 <justsomeguy> ...if you feel like cheating, I can link to my notes, which has a different reduction.
16:44:54 <justsomeguy> Or, err, the same reduction, with different steps.
16:45:44 <theelous3> justsomeguy: https://i.gyazo.com/1a1c570677260dec2a14469fa60e824b.png
16:45:47 <theelous3> was my work
16:46:57 <theelous3> (previous to reading the answer I didn't have z1 renamed, I just ended up with \z.za)
16:47:14 <justsomeguy> Heh, I did that the first time, too.
16:47:21 <theelous3> :)
16:47:24 <theelous3> show me your thing
16:47:29 <theelous3> am interested in different reduction
16:47:37 <justsomeguy> https://github.com/kingparra/hpfp/blob/master/01_-_anything_from_almost_nothing/exercises.rst
16:47:54 <theelous3> I also tried just looking at the ones with irrelevant heads
16:48:02 <theelous3> and just replacing them with their free var off the bat
16:50:46 <justsomeguy> Since it's probably confusing... In my notes there, I uses spaces to separate lambda terms instead of parenthesis, and don't write the lambda symbol.
16:51:16 <theelous3> yeah no that's fine
16:51:29 <zfnmxt> binders are important c:
16:51:48 <fog> still working of function nets - found that nets as neurons fits into the MCS framework
16:54:27 <justsomeguy> theelous3: Was that helpful at all?
16:58:15 <theelous3> justsomeguy: I'm not sure lol
16:58:33 <theelous3> I understood it alright, but I'm getting a little lost in your renaming
16:59:13 <theelous3> as in, I understood what I had done, and it was all correct barring the z1 != z in the final reduction
16:59:23 <theelous3> and I'm not seeing how your naming strategy makes things easier
16:59:43 <justsomeguy> theelous3: The main point is that the only part that I couldn't rename is the z within the function body, since it's a free variable. (Meaning it doesn't have a corresponding parameter in the head of the function.)
17:00:24 <theelous3> well, nor the a
17:00:42 * justsomeguy closes his reddit tab and double checks
17:00:43 <theelous3> but I see your point
17:01:41 <zfnmxt> theelous3: You should try reducing \f. (\x . f (x x)) (\x . f (x x)) 
17:01:45 <zfnmxt> :)
17:01:48 <theelous3> ok :D
17:01:57 <monochrom> That one has nothing to reduce.
17:02:02 <theelous3> awh
17:02:04 <theelous3> you ruined it
17:02:14 <zfnmxt> Well, apply it to something.
17:02:33 <monochrom> There is nothing to ruin either.
17:02:54 <zfnmxt> What about my fun?
17:03:02 <theelous3> honestly what about my fun
17:03:09 <theelous3> we both would have enjoyed that
17:03:12 <justsomeguy> You could have done "\y.(\x.y(xx) \x.y(xx)) \i.i" for an infinite loop.
17:03:41 <zfnmxt> theelous3: You can reduce (\f. (\x . f (x x)) (\x . f (x x))) f for some free variable f
17:03:41 <theelous3> gonna do it anyway out of spite
17:03:55 <monochrom> Like if someone gives you a ball of clay, and say "re-shape it until it's a sphere", but the ball of clay is already a sphere, you just reply "done", there is nothing to do.
17:04:37 <theelous3> cool, but if I understood the method of creating a sphere but didn't know how to recognise one, as is the case here
17:04:42 <theelous3> I would still have to try
17:04:50 <theelous3> therein lies the fun for both of us
17:05:02 <justsomeguy> theelous3: If you read the paper by Raul Rojas that the first chapter links to it provides an explanation of that function (the Y combinator). I had fun reading it. :^)
17:05:08 <zfnmxt> monochrom: You can just define a calculus that allows reductions under abstractions
17:05:33 <monochrom> But at this stage you're supposed to already know how to spot a sphere, and how to spot "it can't be further reduced".
17:06:05 <theelous3> monochrom: I literally started today
17:06:08 <theelous3> get real
17:06:21 <monochrom> be rational
17:06:34 <koz_> I guess that if you have 'data Foo = Bar { baz :: String } | Quux { baz :: Int }', there is no combination of GHC extensions that permits it?
17:06:46 <theelous3> if I could rolly my eyes so hard you could somehow see them, I would
17:06:50 <zfnmxt> theelous3: Try reducing the thing I gave you. So, to make it clear, reduce (\x . f (x x)) (\x . f (x x)) where f is some free variable that's in scope from "outside"
17:06:58 <theelous3> ok
17:07:03 <justsomeguy> theelous3: I think that monochrom was saying that to zfnmxt, though.
17:07:28 <theelous3> but the point was to get me to do a silly thing
17:07:34 <zfnmxt> It's silly
17:07:37 <zfnmxt> But try it!
17:07:38 <theelous3> like telling a new labourer to go buy a glass hammer
17:07:53 <zfnmxt> Oh. But my task to you is also silly as you'll soon find out :) 
17:08:00 <theelous3> yes I am hoping it is
17:10:24 <theelous3> justsomeguy: I have that paper open for reading btw, read a little bit earlier, seems interesting
17:10:34 <theelous3> I'll make sure to finish
17:12:35 <justsomeguy> It, uhh, took me a long time to finish. So don't be discouraged if it takes a while. Just sayin'.
17:12:50 <theelous3> I can tell it will take me some time too :D
17:16:17 <zfnmxt> justsomeguy: Which paper?
17:16:26 <theelous3> http://www.inf.fu-berlin.de/lehre/WS03/alpi/lambda.pdf
17:17:03 <justsomeguy> Also there's a new version of it here: https://arxiv.org/abs/1503.09060
17:17:21 <justsomeguy> Nothing revolutionary, basic lambda calculus stuff, but I had fun learning it.
17:18:10 <zfnmxt> Pierce's book is really good if you want something more pedagogical/in-depth.
17:18:37 <zfnmxt> (Types and Programming Languages)
17:19:33 <justsomeguy> I hope to read it someday. Right now I'm pretty busy trying to get through the 1200 page behemoth of a book that is HPFP, though.  
17:20:01 <theelous3> zfnmxt: f)f)f)f)f)f)f)f)
17:20:03 <theelous3> ?
17:20:04 <theelous3> :D
17:20:04 <zfnmxt> :D
17:20:06 <theelous3> lol
17:20:23 <zfnmxt> It's the Y-combinator. It's how you make recursive functions in the lambda calculus.
17:20:31 <theelous3> awesome
17:21:07 <theelous3> how do you...stop it?
17:21:22 <zfnmxt> Good question!
17:21:41 <justsomeguy> You have just begun evaluating an infinite loop, my friend.
17:21:54 <theelous3> this I can see
17:21:58 <theelous3> I am a very slow computer
17:24:48 <zfnmxt> If you want to stop it, you just have to define f in a clever way so that it "throws away" its argument.
17:25:33 <zfnmxt> So, you could define f like this: f := \fact n -> if n == 0 then 1 else fact (n - 1)
17:26:05 <theelous3> oh, right yeah sorry
17:26:07 <zfnmxt> So if you tried it with that definition of f, you'd see that you can bottom out.
17:26:21 <theelous3> forgot f here is some out of scope thing, I was being tunnel visioned
17:26:35 <theelous3> well, in scope thing
17:26:40 <theelous3> but...in the ether
17:27:02 <theelous3> cool
17:27:03 <theelous3> ty
17:27:03 <zfnmxt> Well that just means in some sense there's another outer binding that you can't see
17:27:24 <zfnmxt> Like  \f <---ether---> (\x . f (x x)) (\x . f (x x)) 
17:27:31 <theelous3> yes
17:27:38 <theelous3> I gettcha
17:27:39 <theelous3> :)
17:27:40 <zfnmxt> :)
17:28:30 <theelous3> off to bed, is late, and much to late to continue this
17:28:37 <zfnmxt> Good luck!
17:28:39 <theelous3> thanks for all the help peeps o/
17:31:38 <ezzieyguywuf> I'm pretty new to haskell. I feel like I've heard/read that arrays are typically not used and are usually avoided in haskell. I think it was because there ar ebetter alternatives, or because it is just inefficient or something
17:31:42 <ezzieyguywuf> does any of this ring true?
17:31:48 <ezzieyguywuf> can anyone educate me on this or point me to any resources?
17:39:56 <justsomeguy> I've read similar things. Check out page 7, section 1.6 of "Introduction to Functional Programming Through The Lambda Cauclus" by Greg Michealson. (It's free on the authors website.) I'm not sure it applies to Haskell, though.
17:43:15 <ezzieyguywuf> justsomeguy: I'll take a look, thank you
17:43:43 <wavemode> ezzieyguywuf: that's not accurate. if the job can be done with an immutable data structure like a list or Data.Sequence, then that's certainly the way to go. But regular mutable arrays do exist in haskell and are commonly used
17:44:52 <ezzieyguywuf> wavemode: a hah. I must be mistaken thin.
17:44:53 <ezzieyguywuf> *then.
17:44:58 <justsomeguy> I'm glad you mentioned it, wavemode. I've seen arrays used before, but wasn't really sure if it's idomatic or not.
17:45:13 <koz_> justsomeguy: It depends what you want done.
17:45:23 <koz_> Usually, starting off immutable is the way to go.
17:45:29 <koz_> (mutation is a performance hack)
17:45:34 <ezzieyguywuf> I am trying to write a CAD kernel, in which a topology of Vertex, Edge, and Face will be manipulated by the user. I was going to store the list ef Vertex etc. in an array so that I could easily access any particular Vertex to mutate as the user requests
17:45:59 <justsomeguy> I thought the book I mentioned had an interesting take on it from a conceptual point of view, but I can see how it would get inefficient quickly.
17:46:19 <koz_> ezzieyguywuf: You want a Map.
17:46:22 <koz_> Of some description.
17:46:36 <koz_> justsomeguy: You'd be surprised, honestly.
17:46:47 <ezzieyguywuf> koz_: can you point me to a reference?
17:47:05 <koz_> ezzieyguywuf: https://hackage.haskell.org/package/containers-0.6.2.1/docs/Data-Map.html
17:47:32 <ezzieyguywuf> koz_: thank you, I'll get to reading.
17:47:36 <koz_> justsomeguy: One example I discovered (fairly) recently is that HashMap from unordered-containers (which is immutable) out-performs anything in hashtable.
17:47:51 <koz_> Even though hashtables contains _mutable_ ... well, hash tables.
17:52:09 <dmwit> Map? IntMap? Seq? Which of these you want depends a lot on what operations you will do the most often.
17:54:42 <koz_> HashMap should be mentioned there too.
17:56:45 <dmj`> :t concatMap (intercalate "\n")
17:56:46 <lambdabot> Foldable t => t [[Char]] -> [Char]
17:59:40 <justsomeguy> Damn, well it's been really interesting learning about FP but I have to admit that after 7 months I still can't write a single useful thing in Haskell.
18:00:10 <justsomeguy> Maybe I should sleep...
18:00:21 <koz_> justsomeguy: You haven't slept in 7 months?
18:00:35 <justsomeguy> lol, no just 48 hours or so
18:01:01 <koz_> Yeah, go sleep.
18:01:28 <justsomeguy> Yep. Thanks for all the help, everyone. o/
18:06:28 <ezzieyguywuf> koz_: why do you think I want a Data.Map rather than an association list?
18:06:43 <ezzieyguywuf> I'm reading up on some of this stuff here: http://book.realworldhaskell.org/read/data-structures.html
18:06:58 <koz_> ezzieyguywuf: Do you mean something like [(k, v)]>
18:07:00 <koz_> ?*
18:07:00 <lambdabot> Maybe you meant: v @ ? .
18:07:05 <koz_> (when you say 'association list', that is)
18:07:33 <ezzieyguywuf> koz_: yes.
18:07:54 <koz_> Basically, Map has a much richer interface, and is more conveniently set up for doing things you'd want from a dictionary structure.
18:08:03 <koz_> (it's also more efficient when the number of assocs is large)
18:08:19 <koz_> It does require the keys to have an Ord instance, but given that you can autoderive that, it's not a big problem.
18:08:20 <ezzieyguywuf> *thumbs up* sound good, thank you for your thoughts
18:08:44 <koz_> Like, you _can_ use [(k, v)], it's just a lot more annoying once you want anything more complex than 'look up this thing'.
18:24:37 <dmwit> lmao [(k,v)] is so, so bad
18:28:08 <dmwit> Map is orders of magnitude faster for even modest numbers of keys.
18:28:36 <dmwit> With 128 entries, looking up the last one in an association list has to dereference like 384 pointers. With Map the worst-case is more like 16.
18:32:21 <shachaf> "struct { int k, v; } arr[128];" is a pretty good data structure, on the other hand.
18:33:00 <shachaf> Maybe a little big but pretty much just fine for key-value things. Zero dereferences, fits in a few cache lines.
18:34:34 <dmwit> Surely it would be 128 dereferences.
18:35:10 <dmwit> Hm. Maybe not. Depends what exactly you mean by "dereference", I guess.
18:35:29 <dmwit> But yes, the cache locality is also a very very big difference between the C array and the Haskell list.
18:36:47 <dmwit> (And you say "maybe a little big", but I think another big drawback is "maybe a little small". And if it turns out to be a little small... it's really, really hard to fix correctly.)
19:12:10 <awpr> I'm running into a case of GeneralizedNewtypeDeriving [and DerivingVia] falling over in simplifyInstanceContexts when it seems like they shouldn't need to: https://repl.it/repls/LimpingEmptyCore
19:12:55 <awpr> is this a known limitation and/or hard to solve, or just something nobody's run into much yet?
19:22:15 <awpr> ah, this is exactly the situation in "Note [Exotic derived instance contexts]"
19:24:18 <dmwit> awpr++ for putting in a ton of debugging effort
19:24:53 <dmwit> I wonder if http://hackage.haskell.org/package/ghc-typelits-knownnat would help here.
19:25:11 <dmwit> (Since with it, KnownNat n implies KnownNat (1+n).)
19:26:29 <awpr> I may have picked a bad instance of the problem for the repro -- elsewhere we have this popping up with miscellaneous non-arithmetic type families returning Nats and with other MultiParamTypeClass situations
19:27:33 <awpr> possibly the Nat solver plugins would dispatch this particular case
19:28:58 * dmwit nods
19:29:08 <awpr> actually, it may be safe simply to drop that restriction for contexts coming from GND / DerivingVia
19:29:36 <awpr> ("that restriction" = that the simplified constraints must constrain only type variables)
19:30:04 <ezzieyguywuf> if I have `data MyData = Empty | HasOne Int | HasTwo Int Int`, how can I write a function `isHasOne :: MyData -> Bool`. 
19:30:45 <ezzieyguywuf> the intent is to create a Data.Map Int MyData and user Data.Map.Filter to get all values that are a HasOne
19:31:49 <awpr> for GND / DerivingVia the instance context you end up with from `inferConstraintsCoerceBased` will be the same as (an instantiation of) an existing instance head, so maybe it's okay to exempt them
19:31:54 <Welkin> you don't need a function, just use a case expression and match on it
19:34:43 <MarcelineVQ> Or do make a function, but in the same way: pattern matching on MyData.  https://en.wikibooks.org/wiki/Haskell/Pattern_matching
19:35:45 <ezzieyguywuf> Welkin: if I have a Data.Map.fromList [(0,MyData Empty), (1, MyData HasOne 1), (2, MyData HaseTwo 2 3)], how would I extract _just_ the HasOne?
19:36:09 <koz_> Welkin: What if you have more than one?
19:36:12 <koz_> Or none?
19:36:36 <koz_> Sorry, ezzieyguywuf.
19:36:41 <koz_> I should type more carefully.
19:37:54 <ezzieyguywuf> koz_: if I have more than one HasOne? well that's the point - I'd like to, at any point, extract all of the HasOne from my Data.Map
19:38:24 <koz_> ezzieyguywuf: So what do you wanna get back? A Map full of only keyvals which happen to be HasOnes?
19:38:35 <koz_> [MyData] all of which are HasOnes?
19:38:38 <koz_> Some other thing?
19:53:36 <Welkin> ezzieyguywuf: it is literally just `Data.Map.filter (a -> case a of HasOne _ -> True; _ -> False)`
19:53:48 <Welkin> \a -> ...
19:54:10 <Welkin> a basic filter and a pattern match
19:54:41 <ezzieyguywuf> koz_: a Map full of only keyvals which happen to be HasOnes
19:54:49 <koz_> Then what Welkin said.
19:54:54 <ezzieyguywuf> Welkin: yes, you are right. it is as simple as that.
19:55:16 <ezzieyguywuf> I'm just still pretty new to haskell, so was unable to produce that idiom when thinking through the problem.
19:55:19 <ezzieyguywuf> thanks :)
19:55:34 <koz_> ezzieyguywuf: My advice? Read the functions in Data.Map.
19:55:35 <koz_> Many times.
19:55:39 <koz_> You'll find a lot of gems.
19:56:14 <Welkin> it's difficult to know your level of knowledge when reading your question, too
19:56:18 <ezzieyguywuf> koz_: yup, just got through my first read-through
19:56:37 <ezzieyguywuf> because I sound like I know so much!?
19:56:37 <ezzieyguywuf> lol
19:56:39 <ezzieyguywuf> jk
20:15:46 <dsal> ezzieyguywuf: There are many levels of answers.  One, e.g., is   `v ^.. folded . _HasOne`
20:16:27 <Welkin> that is for code golf
20:16:41 <dsal> But `isHasOne` writes itself.    `isHasOne (HasOne _) = True; isHasOne _ = False`
20:16:44 <Welkin> the best answer for a beginner is the same as the best answer for production code
20:17:22 <Welkin> it reminds me of "The Evolution of a Haskell Programmer"
20:17:35 <dsal> Welkin: OK, then my way is probably best, but it wouldn't be the easiest to understand without knowing a bit more.
20:18:16 <Welkin> simplest is best
20:18:28 <Welkin> simplicity is powerful
20:18:46 <MarcelineVQ> simplicity is chopped liver
20:19:18 <dsal> > [Left 3, Right 1, Left 4, Right 1, Left 5, Right 9] ^.. folded . _Right  -- being able to do the same kind of thing with all your types is pretty nice
20:19:21 <lambdabot>  [1,1,9]
20:20:41 <dsal> > [Left 3, Right (Just 1), Left 4, Right (Just 1), Left 5, Right (Just 9), Right Nothing ] ^.. folded . _Right . _Just -- especially in real world code where stuff gets complicated.
20:20:43 <lambdabot>  [1,1,9]
20:21:35 <Welkin> if you data is too complicated, simplfy your data
20:21:41 <dsal> One of my sum types has a quite a lot of variants (from a protocol definition).  I want the bits of a packet that match a certain type.  There *could* be duplicates, but not likely.
20:21:47 <Welkin> this reminds me of the clusterfuck redis client library
20:22:03 <dsal> I don't know that all of us are writing quicksort.
20:22:36 <Welkin> Maybes nested in Eithers nested in Maybes nested in Eithers ...
20:22:56 <dsal> Well, lambdabot doesn't have my actual data types, obviously.
20:23:16 <Welkin> one of my lowest points with haskell in the 6 years I've been writing it was the redis library
20:24:09 <dsal> Which is a packet sum type that has type-specific packet data which has a collection of zero or more properties from a well-defined list that each have property-specific data.
20:25:11 <Welkin> I don't see what that has to do with generic Either and Maybe
20:25:19 <dsal> Well, I dealt with antirez a while back and between him and is code written as a single-treaded server with only global state and features just thrown at it constantly, I'm not super surprised other parts of the ecosystem would also be bad.
20:25:22 <Welkin> making a custom type is the right solution, not being generic
20:25:45 <dsal> Uh yeah.  I was just describing the custom types I just said lambdabot doesn't know about.
20:25:54 <Welkin> it's not redis that was bad, it's the haskell client library. The erlang client library is brilliant
20:26:25 <Welkin> haskell has some of the best sql libraries, though
20:26:33 <dsal> I do like sqlite-simple.
20:26:36 <ezzieyguywuf> I have two data types, `data Vertex = LoopVertex Edge`, and `data Edge = LoopEdge Vertex`. Neither the Vertex nor the Edge can exist without the other, and they both reference each other. Haskell handles this easily, I guess b/c of lazy evaluation (despite the circular dependency), however, if I `show aVertex`, this understandably results in a never-ending stream of output.
20:27:11 <Welkin> ezzieyguywuf: don't use circularly defined data like that
20:27:14 <dsal> ezzieyguywuf: What do you want it to do?
20:27:26 <Welkin> represent your graph as a set of nodes and edges as adjacency lists
20:27:57 <ezzieyguywuf> well, I have a `data Topology = Topology (Data.Map Int Vertex) (Data.Map Int Edge)` that is used to store a list of Vertex and Edge
20:28:03 <dsal> % print (cycle "!")
20:28:09 <yahb> dsal: "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
20:28:26 <ski> > fix error
20:28:28 <lambdabot>  "*Exception: *Exception: *Exception: *Exception: *Exception: *Exception: *Ex...
20:28:44 <ezzieyguywuf> wat I want it to "do" is store an adjacency relationship between a given Vertex and Edge (and also Face, but I'm trying to keep my example simple)
20:29:12 <ezzieyguywuf> therefore, for any given Vertex, I'd like to know "which Edge are adjacent to it?"
20:29:17 <ezzieyguywuf> and vice-versa
20:29:35 <dsal> I mean, if you make an infinitely looping structure and then print it, why should it stop?
20:29:43 <ezzieyguywuf> it shouldn't
20:30:05 <ezzieyguywuf> I'm just wondering if this is a typical use-case in haskell
20:30:07 <dsal> Oh.  All's well, then.
20:30:12 <ezzieyguywuf> and if the problem has been solved before.
20:30:40 <awpr> typically these kinds of cyclic issues are dealt with by indirection: refer to Edges and Vertices by an Int ID or something, instead of embedding them directly into each other
20:30:59 <ezzieyguywuf> I considered adding `data Vertex = LoopVertex Int Edge` and the same for Edge, where the Int would be the key from Data.Map that is stored in Topology
20:31:03 <awpr> there's not an extremely satisfying solution that I know of, but IDs work okay enough
20:31:05 <dsal> There are a bunch of graph types.  http://hackage.haskell.org/package/containers-0.6.2.1/docs/Data-Graph.html is pretty minimal.
20:31:11 <ezzieyguywuf> then I could write my own Show for Vertex that just prints its index
20:31:25 <ezzieyguywuf> but I wasn't sure if this was somehow poor form
20:31:57 <awpr> you can take that one step further and omit the Edge from that, and if you need it, use (edges M.! edgeID)
20:32:53 <ezzieyguywuf> awpr: you lost me with that last comment.
20:33:17 <ezzieyguywuf> dsal: I will read up on Data-Graph
20:33:41 <dsal> It will look a little strange, but is the model described above.
20:33:53 <awpr> if you've got a `Map Int Edge` at hand, you can find `Edge`s explicitly by their key in that map, instead of storing (pointers to) them inside of `Vertex`es
20:34:21 <ezzieyguywuf> dsal: my model purposefully left out the higher order Face for the sake of simplicity, though I will need it.
20:35:23 <ezzieyguywuf> awpr: so you're suggesting that my (probably naive) Vertex would be better implemented as `data Vertex = LoopVertex Int` where the Int simply refers to a key in the Edge Data.Map?
20:36:27 <dsal> graphFromEdges :: Ord key => [(node, key, [key])] -> (Graph, Vertex -> (node, key, [key]), key -> Maybe Vertex) <-- that's the core of Data.Graph.  It just performs that abstraction for you.
20:36:37 <awpr> yeah, it's the same approach taken by most graph libraries -- Haskell doesn't give you explicit pointer equality (technically lying, but don't use it), so they use integer IDs instead of pointers
20:37:52 <dsal> I've implemented graphs with maps enough that I'd probably do that, though.  I've only occasionally used Data.Graph.
20:38:10 <ezzieyguywuf> dsal: I have a feeling that this Graph data structure may indeed be what I need/want, I just need to spend some time understanding it better.
20:38:26 <ezzieyguywuf> lol
20:38:41 <ezzieyguywuf> it'd probably still be helpful for me to understand these Graphs though
20:39:32 <dsal> I was going to say it's not very satisfying, but awpr said that already, heh.
20:41:21 <ezzieyguywuf> hrm, I originally moved away from the "store a key to an Edge 
20:41:32 <ezzieyguywuf> (for a vertex)" approach b/c it seemed error-prone
20:41:47 <ezzieyguywuf> i.e. what's to stop me from storing a key to a non-existent Edge?
20:42:05 <ezzieyguywuf> but perhaps that is better solved by controlling how my Vertex/Edge 'graph' is modified
20:42:33 <dsal> A good API would stop you.  :)
20:43:02 <ezzieyguywuf> indeed
20:43:38 <ezzieyguywuf> another reason - `data Vertex = LoopVertex Int`, `data Edge = LoopEdge Int` does not make it very clear that the LoopVertex refers to an Edge and vice-versa
20:43:58 <ezzieyguywuf> but perhaps I am overthinking things?
20:44:03 <ezzieyguywuf> or a well-placed comment would suffice?
20:44:34 <awpr> that's a good place for a `newtype VertexID = VertexID Int`, since there are multiple universes of IDs in the same area of the code
20:45:22 * ezzieyguywuf nods
20:46:34 <ezzieyguywuf> with the one caveat that something like `swapVertex :: VertexID -> VertexID -> Vertx` would require me to explicitly build the VertexID when I call it, such as `swapVertex (VertexID 0) (VertexID 1)`, but the additional verbosity here is not necessarily a bad thing
20:49:05 <awpr> note if the Maps' keys are `VertexID` too, you would probably already have them in `VertexID` form; it's just if you're pulling numbers out of thin air that you have to construct `VertexID` explicitly
20:51:33 <liiae`> IO can be a constructor in kotlin, that's really weird
20:52:15 <ezzieyguywuf> awpr: good point.
20:52:52 <ezzieyguywuf> and really, in that case (pulling numbers out of thin air), i kind of like that I must be explicit about what I'm doing.
20:56:37 <Welkin> liiae`: what's weird about it? IO is a class in Kotlin. Everything in java is a class.
21:01:01 <MarcelineVQ> now ski's gonna come along and tell you all about how IO is a constructor in haskell too :>
21:01:59 * awpr wonders if you can use `'IO` with `-XDataKinds`
21:12:35 <Welkin> IO is a type constructor, yes 
21:12:58 <Welkin> but you don't have access to it
21:14:02 <awpr> it's also a data constructor if you import the right very-internal modules
21:15:39 <ja> IIRC, something can not be both a type constructor and a data construtor, even if it has the same name. types are not data, yet. am I wrong?
21:16:19 <awpr> indeed, more precisely, something else that's also named `IO` (in a different namespace) is a data constructor
21:16:47 <awpr> same situation as `data Pair a = Pair a a`
21:20:19 <awpr> so apparently it's legal to pass around values of type `Type` at runtime, you just can't do anything with them or construct them with anything but bottom
21:22:23 <heatsink> Yes
21:22:37 <awpr> looks like GHC even knows that `Type` has no inhabitants at value level, since I can `EmptyCase` it without getting a warning
21:22:42 <heatsink> GHC's type system doesn't distinguish kinds and types, so you can use Type the same as any other type
21:23:28 <awpr> yeah, got that much, I just hadn't gotten around to trying to run such a program
21:24:32 <awpr> it's a bit odd that `Type` is `Void` at runtime and actual `Type` in the dependently-typed type-level evaluator
21:25:36 <awpr> but I guess it's probably a pragmatic thing: you need to be able to mention `Type` in data constructors because `DataKinds`, and it's not really gonna hurt anyone to have an extra name for `Void`
21:26:24 <awpr> now to see if `Coercible ('Just Int) ('Just (Sum Int))`
21:30:04 <awpr> answer: yes, promoted data constructors have representational role :)
21:50:15 * hackage declarative 0.5.3 - DIY Markov Chains.  https://hackage.haskell.org/package/declarative-0.5.3 (JaredTobin)
22:06:14 <liiae`> what's the benifit for other languages like kotlin to implement monads?
22:07:57 <liiae`> I did some exercise on codewars about haskell, I didn't saw some needs for monad yet...
22:08:07 <jle`> liiae`: do you mean implement a general/uniform interfaces for all monads, or dou you mean 'just have' individual monads?
22:08:15 <liiae`> the most is about list operate
22:08:21 <jle`> if kotlin has (homogeneous) lists, stuff like that, etc., then it already has monads
22:08:49 <jle`> the tricky thing for most languages that aren't haskell is being able to use all monads under a unified interface
22:09:02 <jle`> but most individual monads themselves are pretty useful in general
22:09:07 <jle`> each for different things
22:09:07 <liiae`> jle`: https://arrow-kt.io/
22:12:17 <Lycurgus> the benefit is glomming onto something that is "all the rage"
22:12:45 <Lycurgus> regardless of how it fits the lang in question
22:12:52 <Cale> I don't know if I'd agree that implementing specific examples of monads meets the bar of implementing monads as an abstraction
22:13:15 <Cale> You need to be able to write code which would work with an arbitrary choice of monad
22:13:22 <c_wraith> Lots of languages these days are throwing in extra syntax for specific monads, and just sort of pretending there isn't a unifying idea behind them.
22:13:36 <c_wraith> Things like null-coalescing operators or async/await
22:13:51 <liiae`> what's the benifit for higher kind ?
22:14:02 <c_wraith> it lets you think new thoughts
22:14:19 <liiae`> I actually wonder what kind is used for? 
22:14:27 <liiae`> except for descript type
22:14:37 <jle`> Cale: is that in response to me? because that was sort of the point i was trying to make
22:14:38 <Lycurgus> higher level type generalizations in hs
22:15:07 <jle`> liiae`: 'monad' is a higher order abstraction.  it abstracts over abstractions
22:15:28 <liiae`> jle`: for an instance?
22:15:44 <jle`> 'list-of', 'future-of', 'maybe-of'
22:16:01 <monochrom> monad and functor are generalizing from Vector<Int> to T<Int>, if you know to imagine such a generalization.
22:16:02 <jle`> etc,. are all united by a monadic interface
22:16:20 <Cale> liiae`: How much Haskell do you know already?
22:16:20 <monochrom> (Most people have only thought of generalizing from Vector<Int> to Vector<T>)
22:16:22 <jle`> yeah, a non-higher order abstraction would be like Vector<T>
22:16:30 <monochrom> (Another instance of Dunning-Kruger.)
22:16:31 <jle`> and a higher-order abstraction wouild be like M<T>   <- abstracting over the first part
22:16:43 <liiae`> Cale: a little, no math backgroud
22:16:44 <monochrom> (Err, not Dunning-Kruger.  Sapir-Worf)
22:17:08 <monochrom> But certainly start with functor.
22:17:16 <liiae`> Cale: just read learn yoursefl a haskell for good, that kind
22:20:10 <Cale> liiae`: Okay, so I suppose one way to put it is that there's a general approach to designing libraries, where we implement certain primitive components, and then ways of combining those primitives together into larger and more interesting programs or things.
22:20:30 <Cale> Monad is an abstraction of a general pattern which often appears when doing this
22:21:28 <liiae`> did Leibniz discover monad?
22:21:29 <Cale> Often we'll have some special sort of programs which produce results of a given type, which could be any type at all.
22:21:37 <Cale> No, that's a different monad
22:21:49 <Cale> Our monads come from category theory
22:22:30 <Cale> But learning category theory would be an extreme detour, so I think it's better just to understand them in terms of why they'd come up when developing software unless you already have a strong interest in mathematics
22:23:02 <liiae`> I search that on wikipedia, it said CT is non-sense abstract
22:24:02 <Cale> The "abstract nonsense" term is a bit of a joke -- it is abstract, but not necessarily any more abstract than most other areas of mathematics. It's just that other areas of mathematics tend to produce examples of categories.
22:26:10 <Cale> When people succeed in using results from category theory to prove results in some other specific area, because its objects of study and the mappings between them form a category, it can feel quite abstract.
22:27:08 <liiae`> Cale: why not just do itself in the specific area?
22:27:28 <liiae`> why prove that on CT?
22:27:36 <liiae`> what's the point?
22:27:48 <Cale> Category theory can really help when we approach a new area of mathematics
22:28:18 <Cale> We usually are not content to study a single thing on its own. Mathematicians are always studying related collections of objects
22:28:28 <Cale> and the structure-preserving mappings between them
22:28:51 <liiae`> CT can be related to the most area of math?
22:29:25 <liiae`> or just particular area
22:29:29 <Cale> A category abstracts this pattern: it consists of a collection of "objects" (which can be anything at all), with "arrows" between them, along with some rule for how arrows compose (similar to how functions compose)
22:30:30 <Cale> There are many definitions which will work in an arbitrary (or almost arbitrary) category, and so when we come to a new object of study, it can be helpful to look at how definitions from category theory specialise to our new objects and mappings.
22:30:41 <liiae`> I heard there's Kleisli stuff, it's related to CT?
22:30:49 <liiae`> :t >=>
22:30:50 <lambdabot> error: parse error on input ‘>=>’
22:30:58 <liiae`> the fish operator
22:31:20 <liiae`> the arrow -> is called Kleisli arrow?
22:31:20 <Cale> Yeah, that's one way to construct a new category from a monad.
22:32:52 <Cale> Given a monad M, the maps A -> M B for various types A and B are the arrows of the Kleisli category for M
22:33:04 <dmj`> > mempty []
22:33:06 <lambdabot>  ()
22:33:49 <Cale> The Kleisli category is defined to have the same objects as our original category, and its arrows A -> B are the arrows A -> M B in the original
22:33:54 <Cale> (to be more precise)
22:34:34 <Cale> What we call  return :: A -> M A  in Haskell gives the identity arrow in the Kleisli category
22:35:02 <Cale> and indeed (<=<) is the composition of arrows in the Kleisli category
22:35:16 <Cale> Compare:
22:35:19 <Cale> :t (.)
22:35:20 <lambdabot> (b -> c) -> (a -> b) -> a -> c
22:35:24 <Cale> :t (<=<)
22:35:26 <lambdabot> Monad m => (b -> m c) -> (a -> m b) -> a -> m c
22:35:36 <Cale> It's similar, but there are some m's
22:36:12 <liiae`> Cale: what about switch monads? that's natural trans?
22:37:01 <liiae`> :t (~>)
22:37:02 <lambdabot> error:
22:37:03 <lambdabot>     • Variable not in scope: ~>
22:37:03 <lambdabot>     • Perhaps you meant one of these:
22:37:10 <Cale> Polymorphic functions give us natural transformations (though really natural transformations in general are a little less restrictive than polymorphic functions are)
22:37:42 <Cale> But yeah, if M and N are monads, then polymorphic functions M a -> N a will give natural transformations M -> N
22:38:06 <liiae`> Cale: if that M is IO, that's possible?
22:38:11 <Cale> It can be
22:38:18 <Cale> depending on what N is
22:38:27 <liiae`> what N could be?
22:38:33 <awpr> IO :)
22:38:47 <liiae`> of course, IO a -> IO a is ok...
22:38:48 <Cale> N will need to be something which is capable of representing arbitrary IO actions, so in practice, it'll have to be something built up from IO in some way
22:39:16 <liiae`> wait a sec, I heard there's a stuff called MonadIO?
22:39:17 <liiae`> it's related?
22:39:24 <Cale> Yeah
22:39:27 <Cale> :t liftIO
22:39:29 <lambdabot> MonadIO m => IO a -> m a
22:39:54 <awpr> N can also be some other (degenerate-ish) things: `\_ -> Const () :: forall a. IO a -> Const () a`; `\_ -> [] :: forall a. IO a -> [a]`
22:39:55 <liiae`> Cale: an example ?
22:40:02 <liiae`> for value level
22:40:04 <Cale> MonadIO m is a constraint that says m must be a monad which has such an interpretation of IO actions
22:40:54 <liiae`> Cale: like IO Maybe a?
22:41:04 <Cale> More like ReaderT r IO
22:41:42 <liiae`> it's ReaderT IO r a
22:41:45 <Cale> ReaderT is called a monad transformer -- it's a way of constructing more monads from existing ones
22:41:55 <Cale> If you understand this syntax:
22:42:18 <Cale> newtype ReaderT r m a = MkReaderT (r -> m a)
22:42:36 <Cale> runReaderT :: ReaderT r m a -> r -> m a
22:42:50 <liiae`> oh, Reader...
22:43:04 <Cale> runReaderT (ReaderT f) r = f r
22:43:26 <Cale> We can define an instance:
22:43:37 <Cale> instance Monad m => Monad (ReaderT r m) where
22:43:53 <Cale>   return v = MkReaderT (\r -> return v)
22:44:29 <Cale>   x >>= f = MkReaderT (\r -> let v = runReaderT x r in runReaderT (f v) r)
22:44:55 <Cale> (sorry I'm not explaining that better, I don't know how much detail you want right away)
22:45:37 <Cale> ask :: ReaderT r m r
22:45:38 <liiae`> it doesn't matter, monad transformers are too fancy to me now :)
22:45:53 <Cale> ask = MkReaderT (\r -> return r)
22:46:31 <Cale> ^^ this is an operation we have in any ReaderT monad, we can ask for the "environment" of type r
22:46:40 <Cale> and we can also write:
22:46:40 <liiae`> that Reader, haha, an unary function contain a Reader, right?
22:46:49 <Cale> lift :: m a -> ReaderT r m a
22:47:04 <Cale> lift x = MkReaderT (\r -> x)
22:47:38 <Cale> i.e. we can always turn m-actions into (ReaderT r m)-actions
22:48:04 <Cale> This is kind of boring, all we've done is added an operation which gets a globally-available value
22:48:26 <Cale> But as a basic building block for building more interesting monads, it's pretty useful
22:48:46 <Cale> For example, maybe you're making a monad whose actions represent database transactions
22:48:58 <Cale> You might need to pass a database connection around everywhere
22:49:18 <Cale> and this gives you a quick way to get a monad which does that
22:49:57 <Cale> You might start with ReaderT DbConnection IO, and then restrict the use of IO, by wrapping that up in a newtype and not exporting the constructor
22:50:23 <liiae`> Cale: is there an actually exampe for this Reader?
22:50:54 <Cale> hmm, probably actually
22:51:12 <Cale> But off the top of my head, I'm not sure what libraries might do this one in particular
22:51:41 <wavemode> https://hackage.haskell.org/package/mtl-2.2.2/docs/Control-Monad-Reader.html
22:51:43 <liiae`> Cale: "a globally-available value", this is related to IORef?
22:51:44 <wavemode> has examples
22:51:57 <Cale> liiae`: It's orthogonal to IORef
22:52:15 <Cale> IORef isn't globally available, but it's a mutable reference to a value
22:52:16 <liiae`> sometimes without globla variable is really hard to do something like in threads
22:52:44 <Cale> You can make as many IORefs as you like, you have to pass them around explicitly, and you can update what values they contain
22:53:25 <Cale> ReaderT gives you effectively a global constant which is passed around silently between the ReaderT computations as they run
22:53:50 <Cale> You can get it from anywhere, but don't have to explicitly pass it, and it's immutable
22:53:58 <Cale> (but it could be an IORef)
22:54:27 <liiae`> Cale: but can ReaderT handle communicate between threads?
22:54:33 <Cale> Nope
22:54:54 <Cale> You could fork a new thread and then run a new ReaderT on it though
22:55:01 <Cale> :t forkIO
22:55:02 <lambdabot> error: Variable not in scope: forkIO
22:55:10 <Cale> :t Control.Concurrent.forkIO
22:55:11 <lambdabot> IO () -> IO GHC.Conc.Sync.ThreadId
22:55:18 <liiae`> Cale: yeah, and async
22:55:20 <Cale> forkIO wants a proper IO action
22:55:47 <Cale> But you can easily turn an action of type ReaderT r IO a into one of type IO a by supplying a value of type r
22:55:58 <liiae`> I don't know that STM stuff, but I heard that a lot
22:56:00 <Cale> ReaderT r IO a is after all just a fancy name for r -> IO a
22:56:26 <Cale> (the main difference being a shift in perspective)
22:57:01 <Cale> You usually wouldn't ReaderT transform IO if that was all you were doing -- it's usually nicer just to pass things as arguments, but it's a good building block
22:57:22 <liiae`> Cale: sometimes, I just need IO a -> [a]
22:57:30 <liiae`> or IO a -> Maybe a
22:57:35 <Cale> There aren't many useful functions of those types
22:57:50 <Cale> You probably really just want to execute your IO action
22:57:58 <Cale> inside another IO action
22:58:13 <liiae`> Cale: like read data from files,
22:58:31 <Cale> do x <- readFile "foo"; putStrLn (reverse x)
22:58:45 <Cale> Note how x :: String
22:58:47 <liiae`> Cale: and send them to socket?
22:58:57 <liiae`> socket is IO too?
22:58:58 <Cale> and reverse :: [a] -> [a] didn't need to care about IO here
22:59:02 <Cale> Yeah
22:59:21 <Cale> Stuff that involves input or output is almost certainly going to be in IO
22:59:46 <liiae`> ok
22:59:57 <Cale> The actual effects that your program has on the outside world, and how it's affected by the outside world
23:00:09 <Cale> those go in IO
23:00:37 <Cale> and inside an IO action, you're allowed to execute IO actions to get plain old values, like x in the above program was just an ordinary String
23:00:51 <Cale> the only catch being that the entire do-block was itself an IO action again
23:00:58 <liiae`> :t sequenceA
23:00:59 <lambdabot> (Traversable t, Applicative f) => t (f a) -> f (t a)
23:01:12 <liiae`> :t sequenceA_
23:01:14 <lambdabot> (Foldable t, Applicative f) => t (f a) -> f ()
23:01:36 <liiae`> print every element in a list 
23:01:41 <Cale> Those are very polymorphic, it might help to look at a more specific one, just for lists
23:01:57 <Cale> I might write:
23:02:07 <Cale> forM_ xs $ \x -> do
23:02:10 <Cale>   print x
23:02:28 <Cale> Or in this very specific case, since print is so easy
23:02:31 <Cale> mapM print xs
23:02:37 <Cale> mapM_ print xs
23:02:45 <Cale> (since I don't care about the results of printing)
23:03:12 <Cale> forM/mapM are defined in terms of sequence
23:03:27 <Cale> Let's write a special case:
23:03:36 <Cale> sequence :: [IO a] -> IO [a]
23:04:12 <Cale> sequence is going to glue together a list of IO actions of the same type into a single IO action, which produces a list of results
23:04:26 <liiae`> the intuitive give me `fmap print xs`
23:04:32 <liiae`> but that's not gonna work
23:04:42 <Cale> That'll get us a list of IO actions :D
23:04:53 <Cale> map print xs :: [IO ()]
23:05:07 <liiae`> yeah
23:05:14 <Cale> and so we just need to glue those together end to end
23:05:25 <Cale> sequence [] = ... -- in the case where the list is empty...
23:05:53 <Cale> sequence [] = return [] -- we'll produce the action which does nothing when executed, but return an empty list
23:06:13 <Cale> sequence (x:xs) = ... -- if the list is not empty, and starts with x, followed by another list xs...
23:06:29 <Cale> sequence (x:xs) = do v <- x; ... -- first we'll execute x, getting some result v
23:06:54 <Cale> sequence (x:xs) = do v <- x; vs <- sequence xs; ... -- then we'll execute the rest of the actions in the list, getting some results vs
23:07:20 <Cale> sequence (x:xs) = do v <- x; vs <- sequence xs; return (v:vs) -- and we'll have our combined action return a complete list
23:07:33 <Cale> make sense?
23:07:51 <Cale> There was actually nothing specific to IO in this code, though it was specific to lists
23:08:13 <liiae`> ok
23:08:16 <Cale> All we needed was  return
23:08:18 <Cale> :t return
23:08:20 <lambdabot> Monad m => a -> m a
23:08:23 <Cale> and do-notation
23:08:36 <Cale> which is implemented using the other basic Monad operation
23:08:46 <Cale> @undo do v <- x; vs <- sequence xs; return (v:vs) 
23:08:46 <lambdabot> x >>= \ v -> sequence xs >>= \ vs -> return (v : vs)
23:09:12 <Cale> So this code makes sense for any monad, we could say:
23:09:20 <Cale> sequence :: (Monad m) => [m a] -> m [a]
23:09:35 <Cale> and here's where having the idea of Monads starts to pay off
23:09:54 <Cale> We can define operations like this which work with any monad at all
23:09:58 <Cale> and reuse them
23:10:30 <Cale> Not just IO, but also parsers, and lists, and Maybe, and STM transactions, and all kinds of other things
23:10:42 <liiae`> Cale: does IO a <> IO b? 
23:10:54 <Cale> You mean they're not equal?
23:11:11 <Cale> Or what is that diamond?
23:11:17 <liiae`> Cale: [a] <> [b] == [a,b]
23:11:24 <Cale> oh
23:11:35 <Cale> I think there's an instance of Monoid for IO...
23:11:42 <liiae`> IO a <> IO b == IO a b ?
23:11:48 <Cale> Well, if there isn't we can define one:
23:12:00 <Cale> instance Monoid m => Monoid (IO m) where
23:12:15 <Cale>   x <> y = do m1 <- x; m2 <- y; return (m1 <> m2)
23:12:41 <liiae`> like `print 1` is a IO action, `print 2` is another IO action, can we combind those two actions make it print 1 then print 2?
23:13:08 <Cale> Ah, well, haha, (<>) would work for that, but usually isn't what we'd use
23:13:14 <Cale> There's an operation:
23:13:24 <Cale> (>>) :: (Monad m) => m a -> m b -> m b
23:13:40 <Cale> x >> y = do x; y
23:13:47 <Cale> Or to put it another way:
23:13:53 <liiae`> I thought that >> is used for not fail case
23:14:00 <Cale> x >> y = x >>= (\k -> y)
23:14:49 <Cale> i.e. x >> y is the action which first runs x, and then no matter what result k it gives, it runs y after
23:14:51 <liiae`> :t const
23:14:52 <lambdabot> a -> b -> a
23:14:58 <Cale> and the result of the combined action is the result of y
23:15:09 <Cale> Yeah, we could have written x >> y = x >>= const y
23:15:15 * hackage sixel 0.1.2.2 - Sixel library to show images in a terminal emulator  https://hackage.haskell.org/package/sixel-0.1.2.2 (junjihashimoto)
23:15:25 <Cale> const u v = u
23:15:25 <liiae`> ok
23:15:35 <Cale> Or  const u = (\v -> u) if you like
23:15:41 <Cale> (same thing)
23:15:56 <Cale> So, this sequence function
23:16:03 <Cale> Lists are a monad, right?
23:16:05 <liiae`> what if we fmap <> (fmap print [1,2])?
23:16:19 <Cale> So what might sequence :: [[a]] -> [[a]]  do?
23:16:42 <Cale> In order to know what to expect, we need to be able to interpret "executing" a list in that monad
23:16:45 <liiae`> fmap print [1,2] :: [IO a]
23:16:45 <johntalent> Cale: it returns the argument. it's an id.
23:16:52 <Cale> johntalent: nope!
23:17:09 <Cale> When you "run" a list, it means to pick one element from it (in all possible ways)
23:17:10 <johntalent> Cale: it returns the same type of the argument. 
23:17:22 <Cale> > do x <- [1,2,3]; y <- [4,5]; return (x,y)
23:17:24 <lambdabot>  [(1,4),(1,5),(2,4),(2,5),(3,4),(3,5)]
23:17:41 <Cale> So sequence is going to take a list of lists, and pick one element from each, in all possible ways
23:17:48 <Cale> giving each possible list of results
23:17:57 <Cale> > sequence [[1,2,3],[4,5],[6,7,8]]
23:17:58 <lambdabot>  [[1,4,6],[1,4,7],[1,4,8],[1,5,6],[1,5,7],[1,5,8],[2,4,6],[2,4,7],[2,4,8],[2,...
23:18:05 <Cale> i.e. it's a Cartesian product
23:18:17 <Cale> and we didn't have to write this explicitly
23:18:25 <Cale> We got it for free from the Monad instance on lists
23:18:39 <Cale> and from sequence
23:19:05 <Cale> We might also consider what sequence will do in a Parser monad
23:19:12 <Cale> sequence :: [Parser a] -> Parser [a]
23:19:27 <Cale> It takes a list of parsers, runs each of them, and produces a list of the results
23:19:57 <Cale> So what's going to happen is that each parser may leave some remaining portion of the string which the next one will begin to consume
23:20:07 <Cale> and so this is like concatenation of parsers
23:20:35 <Cale> (and if our parsing monad supports backtracking, that may happen of course)
23:21:17 <Cale> liiae`: It's important to remember that fmap just applies a function to the results of an action
23:21:29 <Cale> It can't be used to combine multiple actions
23:21:57 <Cale> Just for getting an action which is similar to an existing one, but with a modified result
23:22:00 <liiae`> > fmap print [1,2]
23:22:02 <lambdabot>  [<IO ()>,<IO ()>]
23:22:26 <Cale> lambdabot has a funny instance for printing IO actions which isn't very informative, but yeah, that gets you a list of two IO actions
23:23:21 <Cale> There's no way to inspect IO actions at runtime to tell what they might do before you run them -- this isn't essential, but it's just how IO happens to be implemented in Haskell
23:23:45 <Cale> So the thing which prints them out is powerless to give you any real detail
23:24:11 <Cale> We could invent our own miniature IO monad with actions that were more possible to inspect though
23:24:23 <liiae`> Cale: combind that two IO actions to one, and run it
23:24:28 <liiae`> is what I like
23:25:08 <Cale> liiae`: Often we'd just use do-notation
23:25:18 <liiae`> like `fmap print [1,]` is [IO ()], can I use `fmap >> ` on it to combind it to [IO ()] ?
23:25:24 <Cale> But yeah, you can apply sequence to that list of actions
23:25:25 <liiae`> just one IO action in that list
23:25:49 <Cale> sequence (map print [1..]) :: IO [()]
23:25:50 <liiae`> that get that IO action out of the list with head?
23:26:16 <liiae`> operate IO actions just like the other monad actions
23:26:35 <Cale> sequence is kind of like a primordial loop: if you can decide ahead of time what will happen on each iteration, it will glue the iterations together
23:26:49 <Cale> So we can define  mapM f xs = sequence (map f xs)
23:27:02 <Cale> mapM :: (a -> m b) -> [a] -> m [b]
23:27:16 <liiae`> .hoogle sequence
23:27:18 <Cale> (that should have a Monad m => constraint)
23:27:30 <Cale> :t sequence
23:27:32 <lambdabot> (Traversable t, Monad m) => t (m a) -> m (t a)
23:27:34 <liiae`> 'hoogle sequence
23:27:44 <Cale> ah, its real type involves Traversable now
23:27:53 <Cale> but all you need to know is that lists are Traversable
23:28:35 <Cale> (Kind of annoying pedagogically -- it used to just be  (Monad m) => [m a] -> m [a]  which was easier to introduce to beginners)
23:28:50 <Cale> :t mapM
23:28:52 <lambdabot> (Traversable t, Monad m) => (a -> m b) -> t a -> m (t b)
23:29:09 <liiae`> ok
23:29:09 <Cale> (a -> m b) -> [a] -> m [b]
23:29:23 <Cale> this is kind of like a for-each loop
23:29:33 <Cale> The function (a -> m b) is the "loop body"
23:29:44 <Cale> which determines what to do with each value of type a
23:29:45 * hackage lumberjack 0.1.0.2 - Trek through your code forest and make logs  https://hackage.haskell.org/package/lumberjack-0.1.0.2 (KevinQuick)
23:29:58 <Cale> producing an action whose result will have type b
23:30:11 <Cale> and then it takes a list of values of type a
23:30:25 <Cale> and the result is an action which produces a list of values of type b
23:30:32 <Cale> So you can write
23:30:38 <Cale> mapM print [1..10]
23:30:49 <liiae`> aha
23:31:19 <Cale> If you try that in ghci, you'll see that it also prints [(),(),(),(),(),(),(),(),(),()] at the end, because ghci always prints the results of IO actions that it runs, if it can
23:31:34 <Cale> Of course, collecting up a list of empty tuples in memory is kind of pointless
23:31:39 <Cale> which is why mapM_ exists
23:32:02 <Cale> which is similar to mapM, but discards the results of each iteration
23:32:13 <liiae`> > print "a" <> print "b"
23:32:15 <lambdabot>  <IO ()>
23:32:36 <Cale> That will work, but it does a funny extra step apart from just running both actions
23:32:51 <Cale> It uses the Monoid instance for () to combine the two ()'s which are the results of the prints
23:33:07 <Cale> which is kind of a boring waste of time...
23:33:19 <Cale> But it might be more interesting to try something like  getLine <> getLine
23:33:33 <Cale> which will read two lines of input, and produce the result of concatenating them
23:34:00 <liiae`> right!
23:35:39 <Cale> mapM is so much like a for-each loop that we couldn't help but write a version which takes the arguments in the opposite order, to look even a little more like one
23:35:48 <Cale> forM xs f = mapM f xs
23:36:34 <Cale> The list is first, so that it's more comfortable to write a whole do-block inside the function argument
23:36:46 <Cale> forM [1..3] $ \n -> do
23:36:49 <Cale>   print n
23:36:52 <Cale>   getLine
23:37:17 <Cale> This will, for each n in [1..3], print the number n, and then get a line of text from the user
23:37:32 <Cale> and it will return the list of three lines of text
23:37:57 <Cale> So we didn't need to build for-each loops into the language, we just defined that as a function
23:38:04 <Cale> and it doesn't only work with IO actions
23:39:18 <Cale> but also with parsers, and STM transactions, and interactive widgets that control part of the DOM in a web application, and all kinds of other things that people think up
23:40:53 <Cale> So this is the power of abstracting over monads, that when we go about defining libraries that have computation-like bits and pieces, often we'll have some boring sort of computation which "does nothing, except to produce the result v"
23:41:14 <Cale> and if we're implementing a Monad instance, that'll be  return v
23:41:48 <Cale> and then we'll often have a way to take one computation, and a function which, given the result of that first computation, decides what to do next
23:41:53 <Cale> and that'll be (>>=)
23:42:09 <Cale> and if we have those two things
23:42:21 <Cale> then we get all the stuff that people have written to work with any monad
23:42:35 <Cale> which is mostly control-structure-like things
23:42:50 <Cale> But can get more interesting
23:43:45 <Cale> Like, with monad transformers (which operate on arbitrary monads), I can take a parsing monad, and add state, or first class continuations to it after the fact
23:44:26 <Cale> Hopefully that kind of answers your original question :D
23:58:27 <liiae`> Cale: thanks :)
