00:00:22 <Pseudonym> It's useful in higher-order programming.
00:00:29 <Pseudonym> For example, consider this function:
00:00:39 <Pseudonym> mapFilter :: (a -> Maybe b) -> [a] -> [b]
00:00:43 <Pseudonym> mapFilter f [] = []
00:01:11 <Pseudonym> mapFilter f (x:xs) = case f x of { Just b -> [b] ; Nothing -> [] } : mapFilter f xs
00:01:20 <Pseudonym> (though it could be implemented better than this)
00:01:26 <Pseudonym> Actually, not a good example.
00:01:39 <Pseudonym> mapFilter :: (a -> Bool) -> (a -> b) -> [a] -> [b]
00:01:46 <Pseudonym> Which does the obvious thing.
00:01:54 <andersca> shouldn't it be called filterMap? :)
00:01:57 <Pseudonym> If you only had that, you could make it into filter by supplying id as one argum,ent.
00:02:04 <Pseudonym> Probably, yes.
00:02:06 <desrt> i think you overestimate my haskell skillz
00:02:13 <Pseudonym> Ah. :-)
00:02:20 <Pseudonym> Then id is pretty useless, isn't it? :-)
00:02:26 <desrt> ya.  i hate id
00:02:27 <desrt> :P
00:02:33 <andersca> mapFilter :: (a -> b) -> (b -> Bool) -> [a] -> [b]
00:02:34 <desrt> i see what you mean though
00:02:37 <andersca> seems somewhat more sensible
00:02:42 <Pseudonym> Shame.  It has such nice things to say about you.
00:02:53 <desrt> Pseudonym; really?  you think it likes me?
00:02:55 <Pseudonym> I suppose you're going to tell me you don't like () either.
00:03:07 <desrt> () frickin sucks
00:03:13 <desrt> i hate monads
00:03:14 <Pseudonym> id will actually accept anyone and anything.
00:03:29 <desrt> > id "I love you"
00:03:33 <desrt> "I love you"
00:03:33 <desrt> aww
00:03:43 <Pseudonym> id ()
00:04:14 <desrt> it strikes me as a bit funny that lcm/gcd are in prelude
00:05:11 <Pseudonym> Oh, it's bizarre what's in the prelude.
00:11:08 <desrt> hmm
00:11:14 <desrt> in a really strange world...
00:11:19 <desrt> id might make a good first argument to break
00:11:45 <ozone> id _|_?
00:12:04 <desrt> what is this _|_ thing.. i've seen it a few times now
00:13:06 <ozone> uh oh, now i've done it
00:13:10 <Pseudonym> :-)
00:13:17 <Pseudonym> It's pronounced "bottom".
00:13:21 <desrt> oh
00:13:27 <desrt> haskell has bottom?
00:13:30 <Pseudonym> If you haven't done any lattice theory, it probably won't make sense to you.
00:13:45 <desrt> p and not p
00:13:47 <ozone> desrt: from a pragmatic point of view, bottom == error
00:13:52 <desrt> what's lattice theory?
00:13:53 <Pseudonym> Yes, every type in Haskell also contains bottom.
00:14:05 <desrt> huh.
00:14:13 <Pseudonym> Bottom is anything which doesn't return, such as "error", "undefined" or an infinite loop.
00:14:25 <desrt> interesting.
00:15:04 <desrt> so is bottom the 'undefined' result that people talk about when they discuss strict vs non-strict?
00:15:48 <Pseudonym> Yes.
00:16:08 <desrt> anyway.  i love bottom
00:16:12 <desrt> it rules
00:16:43 <Pseudonym> So you are impersonal to id, you hate unit but you love bottom?
00:16:48 <Pseudonym> Sicko.
00:16:58 <desrt> bottom isn't a haskellism
00:17:43 <Pseudonym> No, it's a denotational semantics-ism.
00:17:55 <desrt> more fancy buzzwords
00:18:07 <desrt> i met bottom in a formal verification class
00:18:29 <Pseudonym> Well technically, bottom is valid in any set with a complete partial order.
00:18:55 <desrt> complete partial order
00:19:00 <Pseudonym> Yes.
00:19:01 <desrt> i get the feeling i'll soon know what that is
00:19:07 <Pseudonym> Very possibly.
00:19:20 <Pseudonym> You know what a partial order is?
00:19:26 <desrt> nope
00:19:45 <Pseudonym> A partial order over some set X is a relation which is reflexive and transitive.
00:19:46 <Pseudonym> x <= x
00:19:57 <Pseudonym> x <= y and y <= z implies x <= z
00:20:05 <desrt> uhm
00:20:08 <desrt> sounds like equality
00:20:25 <Pseudonym> No.  Equality also has the axiom that x = y implies y = x.
00:20:35 <desrt> and your second line was the definition of transitivity
00:20:41 <Pseudonym> Right.
00:20:53 <Pseudonym> I said "reflextive and transitive", and I just repeated the axioms for clarity.
00:21:07 <desrt> ohh
00:21:08 <ozone> sup kosmikus 
00:21:10 <desrt> gotcha
00:21:15 <Pseudonym> Right.
00:21:23 <kosmikus> hi ozone 
00:21:26 <desrt> i think my understanding of reflexive property was a bit off
00:22:40 <Pseudonym> A complete lattice is a set X, plus a partial ordering <=, such that any subset of X has a greatest lower bound and a least upper bound.
00:22:47 <Pseudonym> You know what is meant by those?
00:23:15 <desrt> yes
00:23:35 <desrt> ie: the real numbers are not a complete lattice because they go to infinity
00:23:49 <Pseudonym> They don't go to infinity.
00:24:06 <Pseudonym> But there is no real number which is greater than or equal to all other real numbers.
00:24:10 <Pseudonym> Anyway.
00:24:15 <desrt> question
00:24:18 <desrt> must the set be finite?
00:24:26 <Pseudonym> If you have a complete lattice, then the entire set itself has a greatest lower bound.
00:24:30 <Pseudonym> That is called "bottom".
00:24:33 <Pseudonym> desrt: No.
00:24:42 <desrt> ok.  i'm still on the same page, then
00:24:51 <Pseudonym> The subsets of the natural numbers, for example, is a complete lattice.
00:25:31 <desrt> how do you define a partial order operator on sets?
00:27:28 <kosmikus> desrt: "subset of"
00:28:09 <desrt> oh
00:28:17 <desrt> and the upper bound is the set of natural numbers themselves
00:28:52 <kosmikus> :)
00:29:04 <desrt> that seems like cheating :)
00:29:27 <desrt> from this example i assume that the lower/upper bounds must be contained in the set
00:29:47 <desrt> ie: all numbers from 0 to 1 (inclusive) are a complete lattice
00:29:57 <desrt> but the numbers between 0 and 1 (exclusive) are not
00:30:12 <Pseudonym> Right.
00:30:23 <kosmikus> all real numbers, yes
00:30:23 <Pseudonym> The rationals are not a complete lattice, either.
00:30:55 <desrt> hmm
00:31:00 <Pseudonym> Of course, it's possible to concoct an ordering such that the lattice is complete.
00:31:16 <Pseudonym> But using the standard ordering, they're not.
00:31:16 <desrt> ok.  so where does bottom come in?
00:31:28 <Pseudonym> Bottom is the greatest lower bound of the whole lattice.
00:31:54 <desrt> ie: 0
00:32:01 <desrt> or null set
00:32:03 <desrt> or .. whatever
00:32:17 <Pseudonym> Depending on the partial order.
00:32:27 <Pseudonym> Now if you take a Haskell domain, such as Bool...
00:32:34 <desrt> false
00:32:36 <Pseudonym> It nominally has two elements: True and False.
00:32:42 <Pseudonym> No!
00:32:42 <desrt> because succ false is true
00:32:57 <Pseudonym> The partial ordering in domain theory is "amount of information".
00:33:05 <Pseudonym> True and False have the same amount of information.
00:33:19 <desrt> haskell disagrees with you :)
00:33:24 <Pseudonym> They are terminating computations that return a value.
00:33:28 <Pseudonym> No, we're not using Ord.
00:33:34 <Pseudonym> It's a different partial ordering.
00:33:40 <desrt> ok
00:34:02 <desrt> bottom contains an infinite amount of information
00:34:17 <desrt> it has to, because top contains no information
00:34:25 <Pseudonym> Uhm... kind of.
00:34:39 <desrt> well.. top is tautology
00:34:43 <desrt> like "p or not p"
00:34:46 <Pseudonym> See, we actually use Scott domains, which are "consistently complete", which is weaker than "complete".
00:34:53 <desrt> which is like ... "duh... thanks for the tip"
00:35:15 <Pseudonym> In domain theory, sets must have a glb, but not necessary a lub.
00:35:23 <desrt> hmm
00:35:44 <desrt> so as far as partial ordering goes
00:36:04 <desrt> it's always seen as a "less than" sort of situation?
00:36:16 <Pseudonym> Not always.
00:36:24 <Pseudonym> Consider the subsets of the natural numbers.
00:36:29 <Pseudonym> Where <= means "subset".
00:36:38 <Pseudonym> It may be that you have two sets which are not comparable.
00:36:47 <Pseudonym> Neither x <= y nor y <= x.
00:37:18 <Pseudonym> This is important, for example, when considering the semantics of functions.
00:37:31 <desrt> but null <= x <= universe
00:37:33 <desrt> for all x, right?
00:37:34 <Pseudonym> A function f :: A -> B is a subset of AxB (Cartesian product).
00:37:53 <Pseudonym> Where f <= g if f is a subset of g.
00:38:11 <Pseudonym> Uhm... kind of.
00:38:15 <desrt> these definitions apply to relations as well as functions, right?
00:38:27 <desrt> ie: not-determinism is ok
00:38:30 <Pseudonym> Actually f <= g if for all a in A, f a <= g a
00:38:40 <Pseudonym> Sure, if you're analysing nondeterministic languages.
00:38:56 <Pseudonym> Anyway.
00:38:59 <desrt> stop
00:39:06 <desrt> just for a second
00:39:09 <Pseudonym> OK
00:39:21 <desrt> f a <= g a
00:39:27 <desrt> you mean <= as defined on the set B?
00:39:34 <Pseudonym> Right.
00:39:39 <desrt> ok
00:39:41 <desrt> continue :)
00:39:47 <Pseudonym> But <= isn't Ord.
00:39:57 <Pseudonym> It's the partial order of the Scott domain.
00:40:03 <desrt> Ord requires < and > and == as well
00:40:13 <Pseudonym> Most data types, say, Bool, have:
00:40:20 <Pseudonym> _|_ <= True
00:40:22 <Pseudonym> _|_ <= False
00:40:25 <Pseudonym> And that's it.
00:40:27 <desrt> huh
00:40:49 <Pseudonym> So _|_ is the glb of Bool.
00:40:50 <heatsink> Not all data types?
00:41:03 <Pseudonym> heatsink: No.
00:41:27 <Pseudonym> Not if you include function types.
00:41:28 <desrt> i don't understand why bool has a partial order defined
00:41:36 <desrt> if True <= False and False <= True
00:41:42 <desrt> why even bother
00:41:55 <desrt> true and false are both glb and lub
00:41:57 <Pseudonym> Who said True <= False and False <= True?
00:42:03 <Pseudonym> We're not talking about Ord.
00:42:05 <desrt> you said they were equivilent
00:42:14 <Pseudonym> They're not comparable.
00:42:16 <desrt> in terms of the ordering you declared
00:42:19 <desrt> oh.
00:42:21 <Pseudonym> Neither True <= False, nor False <= True.
00:42:21 <desrt> *oh*
00:42:22 <desrt> ok
00:42:42 <Pseudonym> heatsink: An example, just for the record, is:
00:42:44 <ozone> desrt: i think you are confused about <=: it's just a symbol here meant to indicate partial ordering.  nothing to do with Ord.
00:42:47 <Pseudonym> f :: String -> String
00:42:51 <desrt> ozone; i know
00:42:55 <Pseudonym> f = error
00:42:58 <Pseudonym> g :: String -> String
00:42:59 <Pseudonym> g = id
00:43:03 <Pseudonym> Then f <= g
00:43:11 <desrt> ok
00:43:36 <Pseudonym> desrt What x <= y means here is that x has less information than y.
00:43:52 <Pseudonym> That's a vague definition, and it's not very rigorous, but bear with me.
00:43:57 <desrt> say.. for A and B { 0, 1, 2, 3, 4 }
00:44:01 <Pseudonym> So True and False have the same amount of information.
00:44:01 <desrt> and f and g :: A -> B
00:44:08 <desrt> f(x) = 2
00:44:11 <desrt> g(x) = 3
00:44:15 <desrt> then f <= g?
00:44:28 <Pseudonym> Not in this sense.
00:44:36 <Pseudonym> 2 and 3 have the same amount of information.
00:44:43 <heatsink> Pseudonym: but is f the glb of all functions in String -> String?
00:44:46 <desrt> assuming <= is defined on B in the normal way
00:44:56 <heatsink> Pseudonym: but is (f = error) the glb of all functions in String -> String?
00:45:06 <desrt> i just don't understand how that's the same as subset
00:45:07 <Pseudonym> heatsink: Yes.
00:45:20 <Pseudonym> heatsink: OK, try this on for size:
00:45:26 <Pseudonym> h :: String -> String
00:45:29 <Pseudonym> h "" = undefined
00:45:31 <Pseudonym> h x = x
00:45:37 <Pseudonym> Now, f < x and x < g
00:45:44 <Pseudonym> s/x/h
00:45:52 <Pseudonym> Happy?
00:46:00 <heatsink> okay...
00:46:06 <heatsink> I htink so
00:46:12 <Pseudonym> Cool.
00:46:30 <desrt> Pseudonym; from what i understand of relations...
00:46:33 <Pseudonym> desrt: The reason I brought up subset is that it's an example of a partial order where there are two elements which are not comparable.
00:46:39 <Pseudonym> Neither x <= y nor y <= x
00:46:42 <Pseudonym> For some sets x, y.
00:46:47 <desrt> you can say that a relation is a subset if it contains a subset of the edges
00:46:53 <[dan]> Pseudonym: Do there exist examples of functions f,g in Haskell such that f <= g, where f is not _|_?
00:47:06 <Pseudonym> [dan]: Yes, I just gave one.
00:47:22 <Pseudonym> h <= g, but g is not _|_
00:47:24 <desrt> wow
00:47:27 <desrt> i have to be away in 3 hours
00:47:30 <desrt> *awake
00:47:30 <Pseudonym> Sorry, h is not _|_
00:47:33 <desrt> i should really go to bed
00:47:37 <Pseudonym> Ajh.  Well, I ned to go home.
00:47:41 <Pseudonym> So you sleep and I'll commute.
00:47:43 <[dan]> Ahh. I think I see.
00:47:44 <desrt> Pseudonym; thanks, i think :)
00:47:57 <desrt> nite.
00:48:00 <Pseudonym> Night.
00:48:01 * [dan] learns more from sitting on irc for a week in summer than a year in college classes.
00:48:02 <heatsink> night
00:48:07 <heatsink> :)
00:48:25 <heatsink> I had a question, too
00:48:29 <Pseudonym> OK.
00:48:37 <heatsink> The way I would write the fibonacci function is terribly inefficient: fib n = fib (n-1) + fib (n-2)
00:48:43 <Pseudonym> Yes.
00:48:47 <heatsink> Because it reevaluates smaller values of fib
00:48:51 <Pseudonym> Right.
00:48:58 <heatsink> What's a better way to write it?
00:49:07 <Pseudonym> OK, two possibilities.
00:49:37 <Pseudonym> 1. Do it the way you'd do it in an imperative language, only functionally.
00:49:39 <Pseudonym> 2. Memo.
00:49:49 <Pseudonym> In your case:
00:49:55 <heatsink> Haskell does memoization?
00:50:02 <Pseudonym> No, but you can do it manually.
00:50:18 <Pseudonym> http://www.haskell.org/hawiki/MemoisingCafs
00:51:00 <Pseudonym> fib n = fib' 0 1 n
00:51:04 <Pseudonym> fib' a b 0 = a
00:51:22 <Pseudonym> fib' a b n = fib' b (a+b) (n-1)
00:51:30 <Pseudonym> That's the way you'd do it in an imperative language.
00:51:44 <heatsink> I see
00:54:26 <ozone> i always liked this definition:
00:54:27 <ozone> fibs = 0 : 1 : (zipWith (+) fibs (tail fibs))
00:54:27 <ozone> fib n = fibs !! n
00:55:04 <Pseudonym> Also works.
00:55:18 <ozone> still sends my brains in knots trying to contemplate the recursion, mind you
00:57:24 <heatsink> It looks like the memoizing CAFs also use an array for memoization, and there's some trickier tree as well
00:58:01 <Pseudonym> Yes.
00:58:09 <Pseudonym> The tree works over an infinite domain.,
00:58:52 <heatsink> But they use the same trick of a lazy data structure that contains all answers
00:58:57 <Pseudonym> Right.
00:59:07 <Pseudonym> And you only compute as much of it as you need.
00:59:20 <Pseudonym> You can combine the techniques if you want.
01:00:11 <Pseudonym> Use an array for the more commonly used parts of the domain, use the tree for the rest of it.
01:00:12 <heatsink> I'm trying to understand how this locally defined array is saved across function calls
01:00:44 <Pseudonym> OK, you're falling into the imperative programmer trap.
01:00:53 <Pseudonym> Think of the array as static.
01:01:00 <Pseudonym> Also think of it as filled out in advance.
01:01:16 <Pseudonym> Except in a lazy language, of course, it can be filled out but not evaluated.
01:02:07 <polli> 2
01:02:09 <heatsink> That doesn't help me
01:02:12 <polli> oops
01:02:16 <Pseudonym> Hmmm.
01:02:20 <Pseudonym> OK, think of it this way.
01:02:31 <Pseudonym> The values in the array are never changed, right?
01:03:07 <heatsink> I know that the contents of memoizeArray !! 10 will not be recomputed the second time it gets evaluated to it, but fib 10 in my earlier function definition will be recomputed every time it's evalutated
01:03:15 <Pseudonym> Right.
01:09:38 <Pseudonym> Gotta go.  Nytol!
01:09:43 <heatsink> ok
01:50:01 <heatsink> This is interesting... Haskell reduces constructors into WHNF like function calls except that it doesn't perform the call
01:50:20 <heatsink> That makes them look like Lisp data
02:10:04 <shapr> good morning #haskell!
02:10:12 <Lunar^> good morning shapr !
02:10:16 <[dan]|away> evenin :)
02:10:26 <shapr> what's going on?
02:10:53 <JaffaCake> morning!
02:11:14 <bring> good morning all
02:11:34 <bring> oh, and:
02:11:41 <bring> @eurohaskell
02:11:42 <lambdabot> less talks, more code!
02:11:42 <lambdabot> http://www.haskell.org/hawiki/EuroHaskell
02:11:42 <lambdabot> EuroHaskell - Haskell Hackfest - June 10-12 - Gothenburg, Sweden
02:11:55 <bring> just thought I'd mention that
02:12:38 * bring gets kicked off da intarweb for spamming
02:14:29 * shapr grins
02:16:21 * Jerub waves
02:16:23 <Jerub> hi shapr!
02:16:52 <shapr> hi Jerub 
02:18:10 <shapr> wassup?
02:18:36 * shapr boings
02:20:24 <shapr> juhp: any more work on GtkMozEmbed?
02:24:29 <Jerub> shapr: I'm sick.
02:24:41 <Jerub> trying to stay awake long enough for dinner to be ready, so I can go to bed and sleep
02:24:47 <shapr> oh
02:24:52 <shapr> that sucks
02:41:33 <shapr> so, anything new and exciting in the world of haskell this morning?
02:41:46 <shapr> any have a source copy of programatica?
02:42:54 <shapr> or a tgz or zip of nomaware's monad tutorial?
02:42:56 <Lunar^> shapr: I think sebc got one
02:43:06 <Lunar^> shapr: But it's under NDA
02:43:13 <shapr> ah, ok
02:43:24 <Lunar^> shapr: He found it very promising, but painly slow
02:45:12 <Jerub> shapr: did you see the pygame psyco slideshow?
02:45:23 <Jerub> shapr: I'm considering adapting it for usage in teaching programming :)
02:46:10 <shapr> oh, for those that haven't seen it check out björn's cool EuroHaskell tshirt: http://www.dtek.chalmers.se/~d00bring/misc/eh-tshirt-bjorn.jpg
02:46:48 <shapr> desrt mentioned a project to graphically show procedural evaluation
02:47:44 <shapr> oh, I forgot to add tshirt info to the EuroHaskell page
02:50:24 <Lunar^> shapr: It's cool
02:51:03 <shapr> I'm pretty sure I've seen that notation in Types and Programming Languaces
02:52:00 <vegai> shapr: this? ftp://ftp.cs.utwente.nl/pub/doc/Parlevink/fokkinga/mmf92b.ps.Z
02:53:56 <shapr> hey vegai, did you try lambdabot?
02:56:12 <vegai> yep
02:56:23 <shapr> what do you think?
02:56:30 <shapr> any user feedback? :-)
02:56:34 <vegai> code is excellent, but my requirements are bit different
02:56:45 <shapr> like what?
02:56:45 <vegai> 10MB runtime is too much for my poor little box
02:56:59 <shapr> you could strip it
02:57:04 <vegai> hmm, perhaps I could try nhc98?
02:57:08 <shapr> it gets dow to 2mb I think
02:57:17 <vegai> hmm
02:57:23 <shapr> I don't know if nhc98 has Network
02:58:24 <vegai> stripping won't change its runtime memory footprint, or will it?
02:58:45 <shapr> I don't know
02:59:34 <vegai> the code was nice. Plugins/Modules especially
03:00:12 <shapr> the simple plugin interface was primarily designed by Pseudonym
03:00:47 <shapr> polli added the more detailed IRC typeclass
03:01:52 <vegai> also, I require channelholding abilities
03:01:57 <shapr> what's that?
03:02:45 <vegai> circumventing IRCNet's faults
03:03:12 <shapr> oh, auto-op certain hostmasks, etc?
03:03:20 <vegai> yes, that sort of things
03:03:36 <vegai> I think it would be wrong to force poor lambdabot to do such lowly tasks
03:04:00 <shapr> well, new code is nice
03:04:39 <vegai> lambdabot _would_ be more interesting, since I'd have chance of doing custom things
03:05:13 <shapr> auto-op wouldn't be very hard to write I think
03:05:45 <shapr> just add a join hook
03:06:25 <vegai> oh! also, there was a problem with the compilation on my freebsd's ghc-6.01
03:06:36 <vegai> let's see...
03:07:05 <shapr> ah, what sort of problem?
03:07:14 <vegai> seems I don't have parsec
03:07:39 <vegai> is it included in newer ghc?
03:07:51 <shapr> I think it is
03:08:11 <vegai> so, 6.01 should have it
03:08:12 <shapr> it may be separate in the freebsd package, I'm not sure
03:09:39 <vegai> let's see if the latest ghc fixes that
03:12:02 <kosmikus> vegai: I think parsec switches packages at some point; used to be in "text", and is now in "parsec" ...
03:13:24 <vegai> hmm, make clean insists on compiling everything before cleaning
03:13:48 <shapr> oh, good point, try adding -package text to the makefile
03:14:04 <shapr> in GHCOPTS I think
03:14:33 <vegai> I'll rather update my ghc
03:16:34 <vegai> *tsk*
03:17:16 <vegai> freebsd thinks I have ghc installed, so I can't upgrade it. But it doesn't show on any of the package databases
03:17:22 <vegai> ...so I can't remove it either
03:18:37 <vegai> ah, there we go. Now...
03:21:06 <vegai> shapr: lambdabot trusts nicks pretty much, doesn't it?
03:49:34 <shapr> yes, but hostname support would be easy
03:50:03 <shapr> I started on that at some point, don't remember if it works
04:24:40 <desrt> uggghhh
04:24:43 * desrt moans
06:16:48 <juhp> shapr: sorry for the long latency ;)  I would really like to etc GtkMozEmbed working with gtk2hs properly - I haven't tried the gtk+hs version (nor gtk+hs) in ages, it may be better
06:17:04 <juhp> then again who runs gtk1 moz these days...
07:03:45 <urtie> whee!
07:04:43 <urtie> only 47 topics not covered yet.
07:05:03 <JaffaCake> ouch
07:05:34 <urtie> that's about 10 people, about 5 of which have agreed to send it in `soon' or even `today'
07:05:52 <urtie> and there's a couple of topics I only added over the weekend that I *hope* to get submissions on.
07:06:39 <JaffaCake> I don't envy your job :)
07:06:41 <urtie> there isn't any real work being done on the language report anymore, is there? :)
07:06:47 <JaffaCake> nope
07:07:15 <urtie> oh, the job isn't much different from bugfixing.
07:07:46 <urtie> it's just that you have to use diplomacy to get your results, as opposed to coding skill. :)
07:08:15 <Lunar^> hOp is featured :) cool
07:08:25 * JaffaCake thinks he is considerably better at coding :)
07:08:31 <Lunar^> With a new meaning for hOp, cool :)
07:08:43 <urtie> lunar^: like it? :)
07:09:47 <Lunar^> urtie: I don't know if sebc thought of that meaning for hOp
07:11:04 <urtie> the webpage didn't have an explanation of the name, so I just made up a description for the topics list
07:11:53 <Lunar^> urtie: You did well, but hOp is just a cool name, without a meaning before yours :)
07:18:43 <jesse> LtU just broke, right in the middle of my first cup of coffee
07:19:09 <urtie> that sucsk
07:19:12 <urtie> sucks, even.
07:19:17 <jesse> yep
07:35:19 <Eglin> Hi, folks
07:35:47 <JaffaCake> hi there
07:36:56 <Eglin> Is there a haskell module with a predicate logic / 1st ord. logic solver?
07:39:51 <ibid> what do you mean by a logic solver?
07:39:57 <ibid> an inference engine?
07:40:06 <Eglin> like something that I can feed Horn clauses to
07:40:14 <ibid> ah :)
07:40:35 <ibid> there is a prolog implementation in the hugs distribution (at least was)
07:40:47 <ibid> note that horn clauses 
07:40:51 <Eglin> I have seen the abstract for "embedding prolog in haskel" all over, but can't get it off campus
07:40:56 <ibid> are a restricted form of FOL
07:40:59 <Lunar^> I think there's something in nofib about that
07:41:24 <Eglin> yeah... I've seen references to "mini-prolog" in hugs, but don't see where to d/l it w/o the entire dist.
07:41:34 <Eglin> Lunar^: What is nofib?
07:42:37 <Eglin> n/m.   benchmarks
07:51:21 <Lunar^> Eglin: It is the fptools benchmark suite
07:51:29 <Eglin> I see.  Thank you
07:52:01 <Lunar^> Eglin: It's named 'nofib' because it's meant to benchmark quite real apps, not the fibonacci suite
07:52:10 <Eglin> clever
07:52:24 <Lunar^> There's a paper about it somewhere
07:52:42 <JaffaCake> ... and also no "fib", as in no lying :)
07:52:59 <ibid> i would have guessed norwegian fibonacci or something :)
07:53:01 <JaffaCake> good ol' Will likes his puns
07:53:21 <Lunar^> JaffaCake: "fib" means lie ?
07:53:26 <Eglin> funny that fptools.com takes you to "a manufacturer of fine 'reamers'"
07:53:29 <JaffaCake> yes
07:53:29 <Eglin> Lunar^: Yes
07:53:40 <Lunar^> Thanks, I did not get the pun :)
07:55:46 <jvee> whats the difference between linear logic and intuitionistic logic ?
07:56:06 <jvee> (and natural deduction logic)
07:56:12 <ibid> isn't intuitionistic logic constructive logic?
07:56:27 <ibid> natural deduction logic is probably standard logic with natural deduction
07:56:40 <jvee> like sequent calculus ?
07:56:42 <ibid> linear logic i don't know
07:57:01 <ibid> natural deduction and sequent calculus are related but not identical
07:57:09 <jvee> im reading something where they say that sequent calculus is part of intuitionistic logic 
07:57:48 <jvee> its all confusing me, i dont know who is who ;)
07:57:59 <Lunar^> I think it is related to the "tiers exclus" (in french), excluded tier maybe ?
07:58:25 <Lunar^> You can not deduce that something is right when you prooved that it is not false
07:58:50 <Lunar^> But I might be all wrong
07:59:22 <ibid> jvee: they are probably talking about a sequent calculus for intuitionistic logic
07:59:38 <ibid> Lunar^: that's intuitionistic yes
08:00:13 <jvee> Lunar^: ok ! thanks a lot ;)
08:04:28 <Eglin> farewell, folks
08:04:31 <Eglin> thanks
08:06:10 <kosmikus> Lunar^: excluded middle, I think
08:09:37 <Lunar^> kosmikus: Thanks, it's always hard to translate such specific terms
11:59:36 --- topic: '["We put the Funk in Funktion","See logs @ http://tunes.org/~nef/logs/haskell/", "Learning Haskell - http://www.haskell.org/learning.html","deb http://www.syntaxpolice.org/haskell-experimental unstable/","Donate your brain! - hawiki/UsingHaskellWikiMaterial","haskelldb 0.8 released","related channels #haskell.se #haskelldb #darcs","http://www.haskell.org/hawiki/EuroHaskell"]'
11:59:36 --- topic: set by bring on [Tue May 04 12:41:39 2004]
11:59:36 --- names: list (clog spenatmannen monotonom jak l^rchkrn moomlyn_ SamB_irssi opet ibid Fractal mattam forester Segora flaw Spark Matt-W shrimpx mwotton Pinnen tumm skew Marvin-- stepcut tic harsha123 cptchaos cmeme Lemmih themaximus_ esap shapr bringert smkl urtie viblo Jerub JaffaCake elmex liiwi seafood shawn Etaoin Cale asmodai Smerdyakov Leimy ludde Lunar^ earthy _rubix Hipo jvee desrt tea isomer dennisb Taaus Riastradh kosmikus Lor wagle jagular Jon)
11:59:36 --- names: list (emu polli edwinb jasonw _Codex otsuka vegai norpan eivuokko Jad zas saz simon- flori gdsx ozone Igloo andersca juhp [dan]|away lambdabot Maddas chucky Lurc ksandstr skylan neologism keverets)
12:00:24 <stepcut> jak: it should work, hold on
12:02:05 <stepcut> http://www.mail-archive.com/haskell-cafe%40haskell.org/msg04117.html
12:02:18 <stepcut> the deser.tgz attached to that message has some code for parsing binary data 
12:02:31 <stepcut> one of the parsers uses parsec
12:02:40 <jak> fantastic, thanks stepcut!
12:03:28 <stepcut> If you need to parse things smaller than bytes, it can get a bit annoying however
12:04:03 <stepcut> nhc has some nice additions for doing this, but no one has ported the Binary.hs to ghc yet.
12:04:17 <stepcut> (ghc's version of Binary.hs does not get have the bit code in it)
12:04:56 <stepcut> which isn't to say that bit-level parsing can't be done, just that it's not a clean as it should be
12:05:22 <jak> yeah
12:05:45 <jak> what about reading in the file in the first place. how to get an array of word8
12:05:57 <jak> or a list of word8 for that matter
12:06:35 <jak> hGetContents get s a String which probably not what I want
12:08:31 <stepcut> i think its okay to use hGetContents
12:08:48 <stepcut> but you might want to use openBinaryFile or hSetBinaryMode 
12:08:54 <spenatmannen> I get this error :
12:09:05 <spenatmannen> TreeMap.hs:6: The last statement in a 'do' construct must be an expressi
12:09:08 <stepcut> (which are ghc specific, I think)
12:09:45 <spenatmannen> whats the big idea?
12:09:57 <stepcut> spenatmannen: one moment
12:10:29 <Igloo> spenatmannen: You'll have to show us the code...
12:10:39 <spenatmannen> ok
12:10:50 <spenatmannen> main :: IO ()
12:10:50 <spenatmannen> main = do a <- getArgs
12:10:50 <spenatmannen> 		  c <- readFile (head a)
12:10:50 <spenatmannen> 		  putStr (map toLower c)
12:11:00 <Igloo> Don't use tabs
12:11:07 <spenatmannen> ok
12:11:52 <stepcut> spenatmannen: the 'c' and 'putStr' aren't lined up under the 'a' on my screen, if that is actually the case in the code, then that would be a problem
12:11:55 <Igloo> And best to set your editor to make them align to the 8n columns when viewing Haskell
12:12:25 <jak> thanks stepcut
12:12:25 <Igloo> (or better still show them in flashing bright red  :-)  )
12:12:27 <spenatmannen> thank you! now it seem to work..
12:12:33 <Jon> perhaps also best to strip tab chars
12:14:36 <Marvin--> tabs suck
12:27:27 <monotonom> Hmm so #haskell does grow over the 80 mark.
12:28:21 <Leimy> ?
12:31:54 <Jon> 90 nicks
12:47:15 <l^rchkrn> Is here anyone familiar with Ruby?
12:47:20 <l^rchkrn> #ruby is dead...
13:31:47 <desrt> Cale; yo.  what up?
13:32:34 <desrt> idle loser.  bah.
13:39:40 <andersca> time to hack some haskell!
15:10:06 <SamB> hmm. this seems like a place where people care about indentation, so... how would you check indentation in a c++ program?
15:15:22 <monotonom> Check? I don't check. When in doubt, I tell emacs to re-indent. (There is also the "indent" unix program.)
15:59:36 * desrt jabs Cale
16:00:12 <desrt> i met Cale on last friday (before i came here) and when he saw me logging into my laptop today he was like "#haskell!!"
16:00:25 <desrt> irc is odd
16:04:59 <andersca> desrt: it is, yeah :)
16:16:39 <desrt> !!
16:16:46 <desrt> my new favourite operator
16:22:21 <andersca> mine is >>=
16:22:34 <desrt> monads suck
16:22:50 <Riastradh> Mine is qopa.
16:22:58 <desrt> qopa is nice
16:23:04 <Pseudonym> qopa sucks
16:23:09 <Pseudonym> No idea what it is, but it sucks.
16:23:51 <Riastradh> Qopa is roughly >=>, but imagine that it's solid and the right greater-than sign is smaller than the left one.
16:24:40 <Pseudonym> Yes, I can envisage that.
16:25:01 * desrt wants complex math
16:25:25 <Pseudonym> I want Clifford algebra.  Complex numbers are for wimps.
16:25:40 <Pseudonym> Or, if necessary, non-Euclidean metrics will do.
16:25:43 * desrt writes a fourier transform that's not dft
16:26:01 <desrt> dtft, i think
16:26:19 <desrt> yes
16:27:17 <desrt> complex numbers are so odd
16:27:34 <desrt> because in just about every way you can think of they're more natural than real numbers
16:27:49 <Riastradh> Is oddness defined on complex numbers?
16:28:11 <desrt> oddness isn't defined on real numbers
16:28:13 <desrt> so i'd imagine not
16:28:17 <Pseudonym> I couldn't disagree more.
16:28:37 <desrt> oddness defined on real?
16:28:39 <Riastradh> Oh, I'm sure you're capable of disagreement beyond that, Pseudonym.
16:28:46 <Pseudonym> I think complex numbers are highly unnatural compared with, say, metric tensors.
16:28:50 <Pseudonym> Or geometric algebras.
16:28:58 <desrt> oh
16:29:20 <Pseudonym> Complex numbers are almost always something else in disguise.
16:30:54 <desrt> why must you always rain on my parade? :)
16:31:23 <Jerub> o/~ I'm only happy when it rains! o/~
16:34:04 <Pseudonym> :-)
16:34:13 <Pseudonym> Complex numbers are useful, no doubt about that.
16:34:24 <Pseudonym> But what gets me is why they're added to standard libraries.
16:34:51 <Pseudonym> Seriously.  Unless you're heavily into numeric analysis, when's the last time you've needed complex numbers?
16:36:55 * desrt wonders if exp is overloaded for complex
16:37:21 <Pseudonym> @type exp
16:37:23 <lambdabot> exp :: forall a. (Floating a) => a -> a
16:37:25 <Pseudonym> No.
16:37:29 <Pseudonym> Complex isn't Floating.
16:37:34 <desrt> nod.
16:37:39 <Pseudonym> Floating needs to support:
16:37:43 <Pseudonym> @type toRational
16:37:45 <desrt> i figured maybe exp was a member function of a class that complex was from
16:37:45 <lambdabot> toRational :: forall a. (Real a) => a -> Rational
16:37:53 <Pseudonym> Oh, maybe nopt.
16:38:03 <Pseudonym> I thought toRational was in Floating.
16:38:28 <desrt> hugs is nice and small
16:39:29 <Pseudonym> @type exp (1 :+ 2)
16:39:30 <Cale> Hi desrt
16:39:30 <desrt> heh.  one of my profs today told me how to do io without monads :)
16:39:30 <lambdabot> bzzt
16:39:35 <desrt> yo.
16:39:41 <Pseudonym> exp is indeed defined on Complex.
16:39:46 <desrt> rad.
16:39:54 <Jerub> desrt: and now you will discover why monads are useful!
16:40:09 <desrt> Jerub; i didn't say i plan on doing it :)
16:40:19 <Jerub> desrt: no! please! go ahead!
16:40:25 <Jerub> you will discover the PAIN of non-monadic behaviour.
16:40:33 <desrt> i understand
16:40:52 <desrt> cale; i just got an email from laurie about your talk :)
16:41:11 <Cale> Yep
16:41:14 <desrt> btw: do you know when we get paid?
16:41:32 <Pseudonym> We get paid?!
16:41:41 <desrt> i have almost no money :P
16:41:43 <Cale> I don't know when I get paid - I figure it won't be for a little while, as I haven't given them anything in that regard yet.
16:41:55 <desrt> me neither
16:42:01 <desrt> but aparantly i've been working since last monday
16:42:02 <Cale> I'm living with my parents, so it's not so urgent for me.
16:42:23 <desrt> .... i can't think of anything i've produced in that time
16:42:31 <desrt> but uh... i've spent a lot of time at school talking to people...
16:43:28 <desrt> do you know where anand keeps the code he was talking about?
16:43:43 <desrt> other than on his laptop :)
16:44:11 <Cale> nope
16:44:20 <Cale> you could send him an e-mail
16:44:29 <desrt> too lazy
16:44:34 <desrt> <-- good haskell interpreter
16:45:10 <desrt> in fact, i'm gonna take a nap :)
16:45:12 <desrt> cheers
16:59:40 * jadrian wonders when will he stop mistyping >>= as >=
17:10:39 <jvee> is linear logic a subset of deductive logic ?
17:21:44 <jadrian> jvee: define deductive logic
17:25:17 <jvee> logic where rules of natural deduction applies 
17:27:28 <jadrian> you mean classical (prop) logic right?
17:27:39 <jvee> yeah, applied to sequent calculus for instance 
17:28:16 <jvee> when you have multiples formulas and you deduct 1 
17:28:36 <jvee> thats natural deduction logic I think
17:29:03 <jadrian> :-/
17:29:21 <jvee> but linear logic is slighly different, but I dont know the subtle semantic difference 
17:29:39 <jadrian> you're talking about deduction systems
17:29:52 <jvee> i'm talking about proof theory
17:29:54 <Smerdyakov> Linear logic limits you to using each hypothesis at most once.
17:29:55 <jadrian> yes
17:31:27 <jadrian> jvee: I'm saying that Hilbert systems, Natural Deduction, Gentzen systems, are kinds of deduction systems that can be used for many logics
17:31:30 <Smerdyakov> It is what's called a "substructural logic," because it makes some deductions that are legal in classical logic become illegal.
17:31:33 <jvee> Smerdyakov: k, thats what peoples told me, does it mean that linear logic systems is a factorisatio of deductive logic systems ?
17:31:41 <jadrian> jvee: not logic systems themselves
17:32:52 <Smerdyakov> jvee, it's probably best for you just to read something like http://www-2.cs.cmu.edu/~fp/courses/linear/handouts/linear.pdf
17:39:53 <jadrian> By the way, I always mess up the letters
17:39:58 <jvee> Smerdyakov: I'm having a course very near that one, its a nice topic, thx for the url
17:39:59 <jadrian> LK = sequent calculus
17:40:09 <jadrian> LJ = intuitionistic sequent calculus
17:40:18 <jadrian> G = ?
17:40:22 <jadrian> Natural deduction?
18:39:16 <flippo> Hmm.  www.haskell.org won't talk to me.
18:41:22 <SamB> flippo: you may need to brush up on your http skills
18:41:37 <l^rchkrn> :-)
18:41:47 <l^rchkrn> Its down sometimes
18:43:07 <flippo> GET SamB
18:43:31 <SamB> flippo: thats HTTP/0.9!
18:43:43 <flippo> Oops.
18:43:55 <SamB> also, you probably need a /
18:44:50 <flippo> Geek-o-rama
18:45:37 <flippo> Does Haskell have anything I could point to and say "That's a continuation"?
18:46:11 <flippo> I can't recall anything that qualifies.
18:46:36 <flippo> But I have no actual experience using "continuations," even in modest little scheme
18:47:24 <flippo> Maybe they are redundant with lazy evaluation
18:47:32 <SamB> flippo: point to a stack frame!
18:48:57 <flippo> Hmm.  I have no idea what that would look like.
18:51:08 <SamB> flippo: much like a heap object, only on the stack.
18:51:58 <SamB> read papers about stuff like the STG machine and the GHC runtime ;-)
18:52:40 <flippo> Okie, dokie.
18:53:15 <flippo> google found a discussion, but all examples are on the refractory haskell.org
18:53:41 <heatsink> G-machine uses a stack of stacks... could stacks on the dump qualify as cntinuations?
18:54:21 <heatsink> are you asking after first-class continuations?
18:54:35 <flippo> Yes, the first-class kind are most interesting
18:54:50 <flippo> But a clever use of them would be stimulating as well
18:55:07 <SamB> oh. the thing most like a first-class continuation is a function.
18:55:24 <flippo> Most uses I've seen can be avoided by lazy evaluation
18:55:44 <flippo> I guess lexical scoping requires some use
18:56:44 <SamB> well, I haven't felt any particular desire for continuations anyway
18:56:57 <SamB> what are they used for?
18:58:14 <flippo> I feel absolutely no need for them, but occasionally I hear someone praise them
18:59:45 <SamB> the only thing I know about them is that multi-shot continuations are a good way to confuse yourself.
18:59:58 <heatsink> It would be an interesting way to write a loop :)
19:00:44 <flippo> Hmm, monads may qualify.
19:01:52 <flippo> Appel says monads "generalize the notion of continuation-based interaction"
19:02:23 <shrimpx> some compilers use closure-converted continuation passing style as an intermediate form before code generation
19:02:26 <heatsink> i don't think monads have manipulatable continuations, but you could make one with a returnCurrentContinuation operator...
19:02:27 <SamB> flippo: they do seem to do some interesting things that might qualify them
19:04:12 <shrimpx> i've seen code written in CPS "for clarity"
19:04:17 <shrimpx> :)
19:04:27 <flippo> with no irony at all?
19:04:31 <shrimpx> no
19:04:59 <SamB> hmm, I guess the reason monads are so fun is that, for monadic functions, the return value *is* the effect, and you can use it more than once.
19:05:41 <jasonw> I've seen code written in CPS "for clarity" that really did add clarity.
19:06:28 <shrimpx> yeah, i think this was a translation phase in a compiler, and i remember it making sense
19:06:38 <shrimpx> if i had my laptop i could even look it up
19:06:40 <shrimpx> :(
19:06:59 <SamB> shrimpx: are you webless?
19:07:04 <SamB> or is it on the laptop?
19:07:08 <shrimpx> it's on the laptop
19:07:15 <SamB> what is it?
19:07:39 <shrimpx> a toy compiler for a FL
19:11:07 <shrimpx> here it is: ftp://ftp.cs.pdx.edu/pub/faculty/apt/94.cfl/interp/transl3.sml
19:20:39 <Leimy> hmm
19:27:54 <wagle> www.haskell.org is down?
19:28:17 <desrt> Leimy; did you see words?
19:28:40 <desrt> string -> [string]
19:29:11 <heatsink> wagle: down and dirty
19:29:18 <wagle> life sux when the manual is down
19:29:23 * desrt decides to go through his stuff and type it all
19:30:03 <Leimy> desrt: ?  Don't think so
19:30:13 <Leimy> what do you mean by words?
19:30:19 <SamB> wagle: which manual?
19:30:19 <desrt> Prelude> words "foo bar baz"
19:30:20 <desrt> ["foo","bar","baz"]
19:30:31 <Leimy> oh the Prelude function :)
19:30:44 <desrt> you already knew?
19:30:44 <Leimy> yeah that's pretty nice I spose
19:30:44 <wagle> if i have "data Foo = A Int Char", then do i get a accessor function for the Int part (and the Char part) for free?  how?
19:30:58 <desrt> just so i remember right
19:31:04 <Leimy> I've read through the Prelude index :)
19:31:08 <desrt> you had the text-justify problem, right? :)
19:31:11 <heatsink> wagle: no, you have to pay me
19:31:12 <Leimy> yeah
19:31:25 <wagle> heatsink: the check's in the mail
19:31:29 <Leimy> desrt: it was an exercise, and a fairly good one, from that book I was referring to
19:31:49 <heatsink> wagle: I don't think it makes an accessor function. Why do you want one?
19:32:00 <Leimy> desrt: I can use (word "Hello there") as input to the Justificationator
19:32:09 <Leimy> er words ...
19:32:15 * Leimy is trying a new keyboard
19:32:44 <wagle> i coulda sworn there was a struct format..  ohhh i think i know where to find an example
19:33:13 <heatsink> Yeah, there was a way to make data with named fields
19:33:21 <juhp> IWBNI lambdabot didn't require a `@' in private msgs...
19:34:06 <Leimy> Wouldn't a Haskell IDE rock?
19:34:33 <Leimy> something like Emacs for Haskell
19:34:41 <Leimy> is anyone working on anything like that?
19:34:51 <desrt> i'm getting better with types
19:35:03 <desrt> i can look at a function that i wrote and write down a :: type declaration for it
19:35:21 <SamB> wagle: errm, for free?
19:35:48 <SamB> shrimpx: hmm. evaluating reals in a compiler seems like a bad idea to me.
19:36:12 <heatsink> Leimy: there is a haskell-mode for emacs, though it has a few bugs
19:36:21 <Leimy> I've been using that
19:36:25 <wagle> ahh..  what i was thinking of was:
19:36:31 <Leimy> It's not been as good as vim's mode
19:36:32 <SamB> desrt: I bet you can't do it without knowing the types of the functions you call!
19:36:49 <desrt> samb; what kind of a statement is that? :)
19:37:14 <SamB> desrt: oh, a rather irrelevant one.
19:37:16 <wagle> newtype Env = Env { unEnv :: Name -> Maybe (InterpM Value) }
19:37:18 <Leimy> desrt: my next goal is to get Justify to add a newline
19:37:36 <Leimy> so it can justify large blocks of text :)
19:37:38 <desrt> i rule!
19:37:39 <SamB> but I don't always remember the types of things, even though I remember how to use them ;-)
19:37:40 <wagle> where unEnv retreives the tagged value
19:37:48 <desrt> i just got my factal function right first try
19:37:56 <Leimy> fractal?
19:37:57 <desrt> and it has a fucked up type
19:38:09 <SamB> desrt: what type does it have?
19:38:14 <heatsink> fractal?
19:38:20 <desrt> fractal :: [Colour] -> Float -> (Float, Float) -> [(Colour, [(Float, Float)])]
19:38:47 <Leimy> desrt: the neat thing about functional languages is supposed to be, once you understand them, being able to get a lot of stuff right the first try :)
19:38:53 <heatsink> what does it do?
19:39:10 <desrt> heatsink; generates a list of triangles in a fractal aranagement
19:39:26 <Leimy> triangles?
19:39:31 <desrt> well
19:39:32 <desrt> stars of david
19:39:34 <shrimpx> SamB: evaluating reals?
19:39:41 <desrt> (which are made out of 2 triangleS)
19:39:44 <Leimy> yeah
19:39:51 <Leimy> superimposed and inverted :)
19:39:52 <SamB> shrimpx: well, maybe it isn't. 
19:39:57 <shrimpx> SamB: that compiler doesn't support reals. the interpreters do tho
19:39:57 <SamB> but it sounds like it is.
19:39:58 <desrt> do you have gtk2hs?
19:40:48 <SamB> shrimpx: oh, okay. because the floating point representation might be different on the host and target machines ;-)
19:40:55 <shrimpx> SamB: yah
19:41:26 <SamB> then again, on x86 it depends on whether you use registers or memory, so...
19:41:34 <Pseudonym> By "reals", I assume you mean "floating point numbers".
19:41:48 <Pseudonym> Otherwise you'd have to include uncomputable reals.
19:41:50 <SamB> Pseudonym: yes, I know they aren't really reals
19:41:59 <Pseudonym> OK, just checking. :-)
19:42:04 <SamB> they are fake reals
19:42:16 <Pseudonym> No, they're IEEE-754 floating point numbers.
19:42:28 <Pseudonym> Which have a fairly well-defined semantics.  Which x86 breaks.
19:42:39 <Pseudonym> :-)
19:42:41 <SamB> Pseudonym: where does it say they are IEEE floats?
19:43:04 <Pseudonym> It doesn't, of course, but it is on all platforms I'm aware of.
19:43:16 <SamB> certainly in most cases floating point numbers are that...
19:43:17 <Pseudonym> (That GHC is ported to.)
19:43:45 <Pseudonym> Lunch.  BBIAB
19:43:48 <SamB> Pseudonym: the code in question is written in SML
19:43:59 <SamB> what a strange time to have lunch
19:44:09 <heatsink> lunch? where are you?
19:44:25 <heatsink> Hawaii?
19:45:27 <heatsink> Can ghc do common subexpression elimination?
19:46:09 <SamB> heatsink: do you think it would be called the Glorious Glasgow Haskell Compiler if it couldn't?
19:46:27 <wagle> ghc at -O2 reduced a 80 second computation to a 1.4 second one..  its pretty aggressive
19:46:50 <heatsink> I tested it, and it doesn't seem to
19:46:54 <heatsink> bar x = foo x + foo x
19:46:58 <heatsink> It evaluates foo x twice
19:47:04 <wagle> how do you know?
19:47:17 <heatsink> I used Debug.Trace.trace in foo
19:47:44 <wagle> the trace might force it to evaluate it twice
19:48:54 <wagle> doesnt trace do unsafePerformIO?
19:49:46 <SamB> heatsink: did you compile that?
19:49:57 <heatsink> I just realized, it doesn't recompile just because I change the flags
19:50:12 <heatsink> if I do gcc test.hs, then gcc -O2 test.hs without modifying test.hs, it won't recompile
19:50:17 <SamB> oh, yes, that is a pain.
19:50:30 <SamB> I think you must mean ghc?
19:50:40 <heatsink> oh, yea :)
19:50:53 <SamB> gcc probably doesn't do a very good job of compiling Haskell code ;-)
19:50:53 <heatsink> Now I can see it does CSE
19:51:14 <SamB> I know I've seen it in the output of -fext-core
19:51:44 <wagle> gcc == Glorious glasCow haskell Compiler
19:52:52 <Leimy> well you never know
19:53:01 <Leimy> gcc is a compiler collection
19:53:20 <wagle> you cannot write a compiler in C..
19:53:31 <SamB> Leimy: I suppose they could have gcc invoke ghc...
19:53:32 <wagle> gcc is proof
19:53:36 <Leimy> :)
19:54:07 <SamB> Leimy: but it would not be nice if it insisted on doing any of the work.
19:54:20 <Leimy> heh
19:54:26 <Jerub> hold on.
19:54:31 <Riastradh> To what?
19:54:34 <Jerub> I thought a change to a Makefile forced recompilation...
19:54:42 * wagle slips
19:55:06 <SamB> Jerub: well, you might need to add some rms to the makefile?
19:55:08 * Riastradh watches as wagle falls into a deep fog below the cliffs, his echoing screams diminishing rapidly.
19:56:28 <SamB> Leimy: because apparantly GHC does better with its own code generation than with gcc
19:56:54 <SamB> although I don't remember when that isn't true
19:57:45 <Leimy> that's neat
19:58:29 <Riastradh> gcc generates code?  I thought it just looked through /dev/urandom for something that resembles code, especially with -O3 on...
19:59:08 <SamB> hmm. what is a fun set of combinators?
19:59:20 <Leimy> I've seen bad things happen with -O3 also
19:59:56 <Riastradh> join, mu, and compose
19:59:56 <Riastradh> ...oh, er, oops.
20:00:46 <Riastradh> OK, before trying to confuse you with random combinators overusing Greek letters and ending up confusing myself instead, why don't you specify your request further, Samb?
20:00:49 <Riastradh> SamB, even.
20:01:47 <wagle> s k i
20:02:05 <Riastradh> i is unnecessary, varlet.
20:02:08 <heatsink> can where definitions be recursive?
20:02:14 <Riastradh> Yes.
20:02:17 <heatsink> ok
20:02:24 <Smerdyakov> Yes. Riastradh is unnecessary.
20:02:31 <heatsink> :)
20:02:46 <Riastradh> And Smerdyakov is a varlet.
20:02:55 <wagle> Riastradh: not if you use a snowboard
20:03:00 * Smerdyakov screams a blood-curdling varlet mating call.
20:03:17 * Riastradh sends Smerdyakov to the dungeons.
20:03:27 <Smerdyakov> No dungeon can hold me.
20:03:35 <Riastradh> That one just did.  ->
20:07:11 <wagle> if the dungeon is over there ->, and Smerdyakov is up there ^, it looks like he got ouy
20:07:15 <wagle> if the dungeon is over there ->, and Smerdyakov is up there ^, it looks like he got out
20:07:26 <Smerdyakov> I got out.
20:07:31 <Riastradh> That's only an illusion, wagle, burned into your retinas.
20:07:35 <Smerdyakov> The Devil gave me wings.
20:07:43 <SamB> Riastradh: well, two combinator libraries that I like are QuickCheck and Parsec
20:09:21 <SamB> wagle: did I mention I like combinators with actual names or at least somewhat suggestive symbols?
20:09:44 <Riastradh> Nope.
20:10:47 <SamB> for instance, <|> has the pipe symbol, which often has something to do with the word "or".
20:11:14 <SamB> and <?> has a question mark, which is often associated with help
20:12:07 <wagle> whoa.  an infinite loop is an illegal instruction in hugs..  8) ;)
20:12:25 <SamB> wagle: only if it is detectable.
20:12:58 <SamB> the halting problem prevents hugs from detecting all possible infinite loops
20:14:10 <heatsink> Here's a suggestive operator name: ~.^ I can't figure out what it should mean, though...
20:14:45 <SamB> heatsink: hmm, some kind of damaged smile?
20:14:55 <heatsink> I think it looks like a wink
20:15:03 <SamB> yeah, it has a black eye I think.
20:15:05 <Riastradh> It draws a winking Squeak logo to a Fudgets stream.
20:15:20 <SamB> Riastradh: squeak?
20:15:26 <heatsink> What?
20:15:28 <SamB> as in Squeak Smalltalk?
20:15:29 <Riastradh> http://www.squeak.org/
20:15:57 <SamB> yes, Squeak Smalltalk.
20:16:02 <Riastradh> Is Fudgets dead, by the way?
20:17:03 <Smerdyakov> Poke it and see
20:17:32 <SamB> why would you want to draw a Squeak logo to a Fudgets stream?
20:17:38 <Riastradh> I can't poke it; arrows weren't invented yet.
20:17:51 <Riastradh> SamB, I don't know!  That's just what that operator does.
20:18:00 <SamB> Riastradh: seriously?
20:18:11 <Riastradh> No, of course not.
20:18:22 <SamB> its hard to tell sometimes.
20:18:33 <Riastradh> I have succeeded, then.
20:19:28 <SamB> like in #nsrt, which is for some reason also used for ZSNES development chat now (I don't think anybody knows why), I suggested writing an SNES emulator in Haskell, one of them thought I might be serious.
20:19:52 <Riastradh> How long did it take for you to finish it?
20:20:09 <SamB> what?
20:20:18 <SamB> finish what?
20:20:19 <Riastradh> To finish an SNES emulator in Haskell.
20:20:40 <Jerub> reasonable.
20:20:41 <Smerdyakov> <Riastradh> I am confused.
20:20:49 <SamB> since it was only a joking suggestion, I neither took any time nor finished it.
20:20:51 <l^rchkrn> Whats NSRT? ZSNES? and SNES?
20:21:10 <Smerdyakov> CRT!
20:21:19 <l^rchkrn> Cathode Ray Tube
20:21:22 <wagle> UTGL
20:21:26 <Riastradh> EFMR
20:21:28 <l^rchkrn> ?
20:21:33 <heatsink> unreal tournament something something?
20:21:39 <l^rchkrn> OSPFLAB
20:21:55 <Riastradh> It's working!
20:22:12 <l^rchkrn> 8-?
20:22:31 <SamB> ZSNES is an SNES emulator, SNES is a video game machine, and NSRT is a rom tool for SNES roms.
20:22:34 <SamB> seeing as I don't even know how the 65816 works, I'm not exactly in a position to even play at writing an SNES emulator in anything.
20:22:54 <l^rchkrn> :-)
20:23:06 <Riastradh> Hail Eris!
20:23:12 <SamB> what is all this spouting of acronyms?
20:23:18 <l^rchkrn> O I C. Thanks SamB. SNES ~= Nintendo
20:23:18 <Riastradh> No.
20:23:48 <Pseudonym> Back.
20:23:48 <Pseudonym> SamB: I'm in Melbourne, Australia.  So it's not an odd time to have lunch.
20:23:49 <SamB> SNES is a product from nintendo, yes.
20:24:01 <SamB> Pseudonym: oh.
20:24:16 <l^rchkrn> Pseudonym: Its like 16:00 there nope?
20:24:25 <Pseudonym> No.
20:24:34 <l^rchkrn> 13:24
20:24:38 <l^rchkrn> :-)
20:24:41 <SamB> l^rchkrn: wouldn't that be an odd time to eat lunch?
20:24:43 <l^rchkrn> I cheated!
20:24:57 <SamB> l^rchkrn: not that I don't eat lunch then ;-)
20:25:25 <Pseudonym> While I don't clock on and off, I eat lunch when others do because that's when the card game is.
20:27:04 <l^rchkrn> I am set to GMT or BST or whatever...
20:31:29 <Jerub> bah.
20:31:33 <Jerub> its @188 everywhere :)
20:31:34 <l^rchkrn> Hab!
20:31:49 <l^rchkrn> Jerub: Yup! The OTBT!
20:32:04 <l^rchkrn> (One True Biel Time)
20:33:31 <Jerub> "_
20:33:32 <Jerub> er 
20:33:33 <Jerub> :)
20:33:58 <l^rchkrn> :-D English keyboard.
20:37:11 <Jerub> qwerty even.
20:38:57 <heatsink> I'm trying to define a list where the nth list item is the sum of the first n list items
20:39:17 <heatsink> Ghc notices that the list definition is self-referent and complains
20:39:20 <Smerdyakov> 0, 0, 0, 0, ...
20:39:21 <Smerdyakov> :D
20:39:39 * heatsink rolls eyes
20:39:45 <Jerub> a 2!
20:39:46 <heatsink> except for the 0th list item, which is 1
20:41:30 <heatsink> How do I get ghc to let me do it?
20:42:10 <Jerub> whats your currently code look like?
20:42:31 <heatsink> pow2 = 1 : nextPow2 1
20:42:55 <heatsink> nextPow2 n = foldl (+) 1 $ take n pow2 : next (n + 1)
20:43:14 <heatsink> so it takes the first n powers of 2 from the list, adds them, adds 1, and puts that in the next element
20:43:54 <heatsink> Actually, I didn't need to do that
20:44:25 <heatsink> oh wait, yes i did because I needed to pass n around, nevermind
20:45:23 <heatsink> oh, replace next with nextPow2
20:46:33 <heatsink> d'oh, I made a mistake
20:47:21 <Smerdyakov> Run ghc with --mistakes next time to find it automatically.
20:47:56 <heatsink> :p
20:51:19 <Leimy> ghc --fix-mah-shizzle
20:51:22 <shrimpx> heatsink: so you want a list of powers of 2?
20:51:27 <Pseudonym> Isn't it -fglasgow-mistakes?
20:52:09 <shrimpx> 1,1,2,4,8,... ?
20:53:00 <shrimpx> cuz that would be not so complicated =)
20:53:22 <Pseudonym> It's a bit more complicated if you want to allow an arbitrary first number.
20:53:28 <Pseudonym> But it's still a one-liner.
20:53:47 <Pseudonym> Oh, actually, no it isn't.
20:53:56 <Pseudonym> For a different first number, map (*n) to the list.
20:54:02 <Pseudonym> But it
20:54:07 <Pseudonym> 's _still_ a one-liner.
20:55:46 <heatsink> I got it working now
20:55:51 <Pseudonym> Cool.
20:55:55 <heatsink> I really wanted it to test something else
20:56:15 <Pseudonym> pow2 = 1 : tail (scanl (+) 0 pow2)
20:56:16 <Pseudonym> Quite short.
20:56:32 <heatsink> what is scanl?
20:57:11 <Pseudonym> It's a bit hard to explain.
20:57:20 <Pseudonym> Imagine you have a state machine which takes inputs.
20:57:29 <Pseudonym> So you have a state transition function:
20:57:42 <Pseudonym> f :: State -> Input -> State
20:58:06 <Pseudonym> To run this state machine, you use something like:
20:58:22 <Pseudonym> runMachine :: (State -> Input -> State) -> State -> [Input] -> [State]
20:58:37 <Pseudonym> So you give the transition function, an initial state and a list of inputs.
20:58:44 <Pseudonym> And it outputs the list of states.
20:58:48 <Pseudonym> With me?
20:58:59 <heatsink> I think so
20:59:04 <Pseudonym> @type scanl
20:59:05 <lambdabot> scanl :: forall a b. (a -> b -> a) -> a -> [b] -> [a]
20:59:14 <Pseudonym> That's what scanl does.
20:59:20 <heatsink> okay
20:59:32 <Pseudonym> The reason the tail needs to be there is that scanl returns the initial state as the first element in the output  list.
20:59:42 <Pseudonym> @eval scanl (+) 0 [1,2,3,4]
20:59:42 <lambdabot> (line 1, column 8):
20:59:42 <lambdabot> unexpected "+"
20:59:42 <lambdabot> expecting simple term
20:59:46 <Pseudonym> Oh.
20:59:52 <Pseudonym> Well, you can try that yourself.
21:00:08 <heatsink> @eval let plus a b = a + b in scanl plus 0 [1,2,3,4]
21:00:09 <lambdabot> (line 1, column 14):
21:00:09 <lambdabot> unexpected "="
21:00:09 <lambdabot> expecting var, "head", "tail", "null", bool, num, character, "[", string
21:00:09 <lambdabot>  "(", operator, simple term or end of input
21:00:21 <Riastradh> @eval scanl (\x y. x + y) 0 [1,2,3,4]
21:00:21 <lambdabot> [0, 1, 3, 6, 10]
21:00:29 <Pseudonym> There you go.
21:00:30 <Riastradh> @eval scanl (\x y. x * y) 0 [1,2,3,4]
21:00:31 <lambdabot> [0, 0, 0, 0, 0]
21:00:38 <Riastradh> @eval scanl (\x y. x * y) 1 [1,2,3,4]
21:00:39 <lambdabot> [1, 1, 2, 6, 24]
21:00:56 <heatsink> what happens if I say @eval (\x. x x)(\x. x x)
21:01:01 <shrimpx> heh
21:01:02 <Pseudonym> Try it.
21:01:10 <Pseudonym> Go ahead.  Really.
21:01:11 <heatsink> @eval (\x. x x)(\x. x x)
21:01:30 <Riastradh> @eval 4
21:01:30 <Pseudonym> lambdabot <- smart
21:01:35 <Pseudonym> Give it a moment.
21:01:42 <lambdabot> out of fuel - use @resume to continue
21:01:42 <lambdabot> 4
21:01:47 <heatsink> nice
21:01:53 <Riastradh> lambdabot ought to have one thread per inputted expression to evaluate, like sarahbot!
21:01:59 <monotonom> @resume
21:02:08 <Pseudonym> What's sarahbot?
21:02:16 * Riastradh points at #scheme & #schemerepl
21:02:29 <lambdabot> out of fuel - use @resume to continue
21:02:57 <Pseudonym> Can I /msg sarahbot?
21:03:05 * Riastradh prods Pseudonym into #schemerepl to demonstrate.
21:03:25 <Riastradh> Yes, I believe so.
21:06:15 <heatsink> Okay, I'm noticing the same property with both my longer version of the definition and the newer shorter version
21:06:25 <heatsink> I define foo x = pow2 !! x
21:07:02 <heatsink> When I compile without optimization, it will recompute all of pow2 up to the index every time foo is evaluated
21:07:19 <heatsink> When I compile with optimization, it will save the computed values of pow2 and not reevaluate them
21:07:29 <heatsink> Essentially, memoization in haskell only works when optimizatio is turned on
21:08:00 <heatsink> Oh, actually I did foo x = pow2 !! x where pow2 = ....
21:09:09 <heatsink> Pseudonym: yesterday I was asking you about memoization, I didn't understand why the memo array would save its values
21:09:33 <Pseudonym> OK.  Do you still not unerstand?
21:09:37 * Riastradh wanders off to bed.
21:09:43 <Pseudonym> Night.
21:09:47 <heatsink> night ri
21:10:41 <heatsink> Pseudonym: Yes, I still don't understand. Can we discuss it in the context of the foo x I described above?
21:12:27 * Pseudonym scrolls up
21:12:53 <Pseudonym> Can you repeat the example please?
21:13:01 <Pseudonym> It got interspersed with another conversation.
21:13:05 <heatsink> ok
21:13:17 <heatsink> foo x = pow2 !! x
21:13:41 <heatsink>      where pow2 = 1 : tail (scanl (+) 0 pow2)
21:13:52 <Pseudonym> OK.
21:14:01 <Pseudonym> pow is a memoising CAF
21:14:04 <heatsink> right
21:14:24 <Pseudonym> The idea with a memoising CAF is that you make a CAF which contains all answers.
21:14:29 <Pseudonym> BUT, you make it lazy.
21:14:37 <Pseudonym> So you only compute it when you need the value.
21:14:42 <desrt> is there a shortform of [minBound .. maxBound]?
21:14:53 <heatsink> yes, I understand that
21:15:00 <heatsink> I would understand how this works if pow2 were global
21:15:05 <Pseudonym> desrt: Not that I'm aware of, but [minBound..] is a little shorter.
21:15:13 <Pseudonym> Ah.
21:15:33 <Pseudonym> Well, there's a little transformation which happens to be valid in Haskell.
21:15:40 <Pseudonym> Called "let floating".
21:15:54 <Pseudonym> Hang on.
21:16:15 * heatsink puts on japanese water wings with "let floating" printed on them
21:16:50 <Pseudonym> Sorry, networm is slow today.
21:17:01 <Pseudonym> Blerg.  Can't get out.
21:17:06 <Pseudonym> Try this: @wiki LetFloating
21:17:12 <Pseudonym> @wiki LetFloating
21:17:12 <lambdabot> http://www.haskell.org/hawiki/LetFloating
21:17:15 <Pseudonym> Thankyou!
21:17:15 <desrt> mm
21:17:24 <desrt> colours = cycle [Red ..]
21:17:25 <desrt> i like!
21:17:27 <heatsink> let floating! it is heartening and gives peace to make splash in pool... we make splash in pool everyday!
21:18:04 <heatsink> haskell.org has been unreachable for me today
21:18:29 <heatsink> I still can't get to haskell
21:19:04 <Pseudonym> http://computing-dictionary.thefreedictionary.com/let%20floating
21:19:26 <Pseudonym> http://burks.brighton.ac.uk/burks/foldoc/6/66.htm
21:19:32 <Pseudonym> The second one is better formatted.
21:20:43 <heatsink> I see
21:20:58 <Pseudonym> So actually, it's as if it was at the top level.
21:21:31 <heatsink> Unfortunately, ghc does not do let floating by default, so memoization with local CAFs doesn't work unless optimization is turned on
21:21:48 <Pseudonym> Really?
21:22:02 <heatsink> Yes, you can test it
21:22:03 <Pseudonym> I believ eyou about let floating, but I think GHC implements full laziness.
21:22:11 <Pseudonym> Ah.
21:22:11 <Pseudonym> OK.
21:22:18 <Pseudonym> Yes, this is a defect in the Haskell standard.
21:22:34 <Pseudonym> The language standard does not mandate full laziness.
21:23:10 <Pseudonym> I think it should.
21:23:16 <Pseudonym> For reasons precisely like this.
21:23:31 <l^rchkrn> Haskell4?
21:23:32 <heatsink> interesting...
21:23:36 <heatsink> It's good to know
21:23:38 <Pseudonym> Unless the compiler can prove that it makes no difference, of course.
21:24:04 <heatsink> what I did to test it, BTW, was to replace (scanl (+) 0 pow2) with (scanl (\a b -> trace "Compute" a + b) 0 pow2) so I could see how many times it was computing pow2 indices
21:24:13 <Pseudonym> Gotcha.
21:25:22 <heatsink> This is the kind of thing that makes me uncomfortable about programming in Haskell
21:25:33 <heatsink> I'm learning how a program gets evaluated, but there are still surprises
21:25:37 * Pseudonym nods
21:25:50 <Pseudonym> Well, in this case, you can do it with modules and defining the CAF at the top-level.
21:26:06 <Pseudonym> But it's not encouraging, no.
21:29:10 <Leimy> desrt: did you catch the type of justify?
21:30:47 <desrt> justify?
21:30:56 <desrt> it would just be [string] -> string
21:30:58 <Leimy> the function you wrote yesterday :)
21:31:03 <Leimy> well
21:31:10 <Leimy> [[Char]] -> [Char]
21:31:13 <Leimy> but yeah
21:31:27 <desrt> i think [String] -> String is more accurate :)
21:31:40 <Leimy> that's not what ghci reports :)
21:31:47 <desrt> well, they're the same
21:31:48 <Leimy> I think String is just
21:31:54 <desrt> but in this case we're dealing with actual strings
21:32:00 <Leimy> yeah
21:32:04 <desrt> not sequences of unrelated characters
21:32:14 <Leimy> anyway I am writing a function around justify to add the "\n"
21:32:18 <Leimy> at least I think I am :)
21:32:22 <Pseudonym> You should put in a type declaration.
21:32:28 <desrt> that's an easy one
21:32:33 <Pseudonym> Then ghci will report the more accurate type.
21:34:08 <heatsink> This is interesting
21:34:18 <Leimy> desrt: did you get it?
21:34:57 <desrt> ya
21:35:04 <Leimy> I am now getting an error after specifying the type :)
21:35:17 <Leimy> but I've been tweaking it
21:35:20 <desrt> you want foldr1 (\x -> \y -> x ++ "\n" ++ y)
21:35:22 <Pseudonym> That's good.  It means there's a bug in your code.
21:35:40 <Leimy> desrt: something like that :)
21:35:51 <Leimy> I changed justify to take an int
21:35:52 <desrt> Prelude> foldr1 (\x -> \y -> x ++ "\n" ++ y) ["this", "is", "a", "test"]
21:35:52 <desrt> "this\nis\na\ntest"
21:35:58 <heatsink> Pseudonym: it's good that his code is buggy?
21:35:59 <desrt> ya.  good call
21:36:01 <desrt> it needed that :)
21:36:04 <Leimy> desrt: not quite what I waned :)
21:36:06 <Leimy> er wanted :)
21:36:08 <Pseudonym> heatsink: No, it's good that the compiler found it.
21:36:14 <heatsink> oh. yes.
21:36:18 <desrt> Leimy; what's wrong with it?
21:36:27 <Leimy> desrt: where you call spaceify numSpaces
21:36:32 <Leimy> spaceify should have 2 parameters
21:36:40 <Leimy> numSpaces and list
21:36:43 <Leimy> where's the other param?
21:36:49 * desrt yanks it up
21:37:01 <desrt> spaceify spaces list = alternate list (map (flip replicate ' ') spaces)
21:37:06 <desrt> this is what i have for spaceify
21:37:15 <desrt> looks fine to me
21:37:18 <Leimy> I may have hosed it
21:37:21 <Leimy> can you paste i?
21:37:23 <desrt> i like you did =)
21:37:24 <Leimy> I think I blew something
21:37:28 <desrt> i think, rather
21:37:39 <heatsink> Pseudonym: I wanted to see what would happen if I changed the list computation a little bit, to make the nth element a function of the first (n+1) elements... I thought it would go into an infinite loop or stack overflow... but instead it printed Fail: <<loop>>, how does that work?
21:37:49 <desrt> anyway. paste away
21:38:03 <Pseudonym> Ah, ineresting.
21:38:03 <Leimy> justify linelength list = spaceify numSpaces
21:38:03 <Leimy> 	where
21:38:03 <Leimy> 		needspaces = linelength - (sum (map length list))
21:38:03 <Leimy> 		numSpaces = distribute needspaces (length list - 1)
21:38:11 <Pseudonym> There are some infinite loops which the run-time system can detect.
21:38:18 <desrt> ya
21:38:21 <desrt> you definitely nuked that
21:38:24 <Leimy> heh
21:38:26 <desrt> i have
21:38:26 <Pseudonym> In particular, if a CAF depends on a CAF.
21:38:28 <desrt> justify list = spaceify spaces list
21:38:32 <heatsink> hmm...
21:38:47 <heatsink> okay
21:38:48 <Leimy> hmmm list fell off :)
21:38:52 <desrt> heh
21:38:53 <Pseudonym> It's referred to as "black hole", because that's what the Miranda interpreter called it.
21:38:57 <Leimy> doh!
21:39:00 * Leimy is tired
21:39:12 <Pseudonym> let bottom = bottom in bottom
21:39:19 <Pseudonym> That's the classic way to generate it.
21:39:36 <desrt> oh
21:39:38 <desrt> that reminds me
21:39:39 <heatsink> what? I don't understand that line of code
21:39:42 <Pseudonym> let bottom () = bottom () in bottom ()
21:39:53 <Pseudonym> That, on the other hand, infinitely loops because bottom isn't a CAF./
21:40:00 <desrt> i wanted to test multiplying 0 times an infinitely recursive function
21:40:21 <Leimy> ones = 1 : ones
21:40:28 <desrt> did not work.
21:40:28 <Pseudonym> heatsink: What don't you understand?
21:40:28 <Leimy> ?
21:40:30 <Leimy> hehe
21:40:31 <Pseudonym> The bottom = bottom part?
21:40:36 <desrt> ERROR - Control stack overflow
21:41:03 <heatsink> So it's saying bottom evaluates to bottom?
21:41:08 <Pseudonym> Yes.
21:41:10 <heatsink> okay
21:41:16 <Pseudonym> Which should, in theory, infinitely loop.
21:41:25 <Pseudonym> But because bottom is a CAF, it is detected at run-time.
21:41:41 <heatsink> okay
21:42:06 <desrt> heh
21:42:10 * desrt finds his evil justify :)
21:42:17 <Leimy> heh I hanged the thing
21:42:18 <Leimy> hung it?
21:42:22 <desrt> hung
21:42:28 <Leimy> justify2 :: Int -> [String] -> String
21:42:28 <Leimy> justify2 linelength list 
21:42:28 <Leimy> 	 | totalLen <= linelength = (justify linelength list) ++ "\n"
21:42:28 <Leimy> 	 | otherwise = justify2 linelength (take (totalLen - linelength + 1) list) ++ "\n" ++ 
21:42:28 <Leimy> 		       justify2 linelength (drop (totalLen - linelength + 1) list)
21:42:29 <Leimy> 	where totalLen = (sum (map length list)) + (length list - 1)
21:42:31 <Leimy> it's well hung
21:42:37 <heatsink> And bottom () is not a CAF because it takes an argument?
21:42:43 <Pseudonym> Right.
21:42:56 <desrt> what the hell are you doing?
21:43:35 <desrt> oh.  gotcha.
21:43:39 <Leimy> breaking into lines of linelen
21:43:39 <heatsink> interesting. So how does it detect CAF loops?
21:43:41 <Leimy> or trying :)
21:43:55 <desrt> i didn't know you could stack where clauses like that
21:43:56 <desrt> that's neat
21:44:14 <Leimy> the  | is a "guard"
21:44:19 <desrt> nod
21:44:20 <Pseudonym> heatsink: Well, it's based on how the run-time system works.
21:44:28 <desrt> i use it in my fractal program in a slightly differnt way
21:44:45 <Pseudonym> Basically, when it evaluates something, it overwrites the tag with a special tag which means "being evaluated".
21:44:48 <desrt> fractal size _ _ | size < 2 = []
21:44:50 <desrt> fractal size (c : d : colours) (x, y) = ..etc..
21:45:05 <Pseudonym> And then when it's completed, it rewrites with the result of the evalution.
21:45:26 <heatsink> Does the tag have a purpose besides detection of loops in the eval graph?
21:45:26 <Pseudonym> If, while it's evaluating, it finds one of these tags, then it's found an infinite loop.
21:45:32 <Pseudonym> Sure.
21:46:08 <Pseudonym> Conceptually, the tag is a word which gives the address of code to call if you want to evaluate something.
21:46:19 <Pseudonym> It's also used for garbage collection.
21:46:23 <desrt> i think i'm gonna program merge sort
21:46:32 <desrt> yes
21:47:46 <heatsink> okay, so it's a virtual pointer and reference count ;D
21:48:01 <Pseudonym> Except that GHC doesn't use reference counting.
21:48:10 <Pseudonym> It's actually more like run-time type information.
21:48:23 <heatsink> okay
21:48:54 <heatsink> I've only been reading the G-machine, the STG machine must work a little different
21:48:59 <Pseudonym> Yes.
21:49:14 <Pseudonym> I think the paper is called "implementation of functional languages on stock hardware".
21:49:26 <Pseudonym> The STG machine doesn't need lambda-lifting, either.
21:49:31 <Pseudonym> It implements environments directly.
21:51:04 <Pseudonym> One other nice thing about the STG machine is that because it doesn't abstract inner lambdas, there's more information about their environment available.
21:51:11 <Leimy> I see my error
21:51:20 <Pseudonym> For example, you can avoid quite a few updates by analysing the code.
21:52:57 <heatsink> I'd need to see an example to understand, I think.
21:53:02 <heatsink> I'm going to bed now
21:53:20 <Pseudonym> OK, night.
21:53:38 <heatsink> Thanks for explaning functional arcana to me :)
21:53:44 <Pseudonym> No problem. :-)
21:54:19 <SamB> I thought black holes were called black holes because that is what CAFs which are being evaluated are turned into?
21:54:32 <SamB> and because it is hazerdous to wander into them
21:55:32 <Pseudonym> Miranda used an SK combinator machine for evaluation.
21:56:15 <Pseudonym> Y f got turned not into f (Y f), but rather a graph with a cycle, of the form: let x = f x in x
21:56:46 <Pseudonym> I believe that the problem was that evaluating Y I would create a "graph" which was not representable.
21:56:53 <Pseudonym> So it's a "black hole".
21:57:09 <Pseudonym> It would kind of be a self-pointing indirection node.
21:58:03 <Pseudonym> But I think the garbage collector removed indirection nodes.
21:58:19 <Pseudonym> The details are a bit hazy. :-)
22:00:03 <SamB> Pseudonym: hmm. that sounds like the garbage collector would go into a loop trying to get rid of it.
22:00:09 <Pseudonym> Right.
22:03:53 <desrt> mergesort done
22:03:55 <desrt> that was fun
22:04:50 <Leimy> is it stable?
22:05:00 <desrt> good question
22:05:29 * Leimy often needs a good stable sort
22:05:32 <desrt> no.  it's not
22:05:37 <Leimy> hmm
22:05:40 * desrt changes a < to a <=
22:05:43 <desrt> now it is :)
22:05:47 <Leimy> :)
22:05:55 <Leimy> does it prefer the left in the == case?
22:05:55 <desrt> bedtime
22:06:05 <desrt> ya.  now it does
22:06:09 <Leimy> stable! :)
22:06:11 <desrt> you know how mergesort works?
22:06:28 <Leimy> merge left and right with the middle IIRC
22:06:34 <desrt> no
22:06:36 <Leimy> or the middle into left and right
22:06:40 <Leimy> or is that quicksort?
22:06:40 <desrt> no
22:06:41 <Leimy> :)
22:06:49 <desrt> sounds a bit more like quicksort but still not exactly
22:06:53 <desrt> mergesort splits the list in half
22:06:56 <desrt> sorts both halfs
22:07:02 <Leimy> and then merges
22:07:04 <Leimy> oh yeah
22:07:08 <desrt> then "merges" the sorted halves with an O(n) algorithm
22:07:22 <desrt> stable mergesorts will favour elements from the left list
22:07:31 <desrt> (in the merge function)
22:07:36 <Leimy> yeah
22:07:44 <desrt> now bedtime.  goodnight :)
22:07:55 * Leimy hasn't written mergesort since college
22:07:58 <Leimy> have had the need
22:08:29 <Leimy> er haven't
22:09:58 * Pseudonym was paid to write quick sort last year
22:10:53 <Leimy> cool
22:10:59 <Leimy> I've got justify2 done
22:11:01 <Pseudonym> It wasn't a standard quick sort.
22:11:18 * Leimy had to do in-place merge
22:11:25 <Leimy> i wasn't allowed to use N/2 scratch space
22:11:36 <Pseudonym> I need to write in-place radix sort in a couple of weeks.
22:11:47 <Leimy> radix sort is neat
22:11:58 <Pseudonym> It's actually the best sort algorithm around these days.
22:12:10 <Leimy> only works on some kinds of data though
22:12:13 <Pseudonym> Unless you are doing it off-line or compressed, in which case merge sort is.
22:12:20 <Pseudonym> Leimy: Pretty much all kinds, actualy.
22:12:23 <Leimy> or data you have a-priori knowledge of
22:12:30 <Leimy> well you have to know what you are going to get :)
22:12:34 <Leimy> and how to handle it :)
22:12:38 <Pseudonym> Sure.
22:12:46 <Leimy> it's not a "generic" sort
22:12:50 <Pseudonym> This is for a database server.  Field types are well-known ahead of time.
22:12:54 <Leimy> but it's really fast :)
22:13:11 <Pseudonym> It's as generic as quick sort.
22:13:16 <Pseudonym> It's just not a comparison-based sort.,
22:13:30 <Leimy> if I have a large amount of data I normally would do something like a single pass of bubble sort followed by qsort
22:13:56 <Leimy> the first pass of bubble can determine if the data is already sorted
22:14:04 <Leimy> and then qsort won't get O(n^2)
22:14:18 <Leimy> supposedly :)
22:17:30 <ozone> Pseudonym: Sounds rather similar to the first chapter of Programming Pearls ...
22:17:43 <Leimy> I have that book somewhere :)
22:17:50 <Leimy> that's a good book :)
22:18:32 <Leimy> I don't know if that book had the answer or if it gave me the idea for how to find all the anagrams in /usr/dict/words :)
22:18:41 <Leimy> and sort them into sets or something
22:18:46 <Leimy> it was like 15 lines of C++ :)
22:18:50 <Leimy> using STL 
22:19:07 <Leimy> oh it was a map
22:19:14 <Leimy> map <string, list<string> >
22:19:38 <SamB> Pseudonym: a REAL sort, eh?
22:21:05 <Leimy> that would be fun to write in haskell I reckon :)
22:21:59 <Pseudonym> The quick sort I had to write was actually a multi-key sort.
22:22:18 <Pseudonym> Oh, and I used pseudo-median-of-9 for the partition element, of course.
22:22:34 <Pseudonym> The idea is that instead of the usual two partitions, this algorithm created three.
22:22:41 <Pseudonym> < pivot, == pivot and > pivot
22:22:50 <Pseudonym> Then for the middle partition, it recursed onto the next key.
22:23:07 <ozone> Pseudonym: what language do you use for work, out of interest?
22:23:11 <Pseudonym> C++
22:23:46 <Pseudonym> Yes, I'm actually doing R&D on sorting right now.
22:23:50 <Pseudonym> Very interesting.
22:24:08 <Pseudonym> Our problem is that we want to sort, but accessing a key is expensive.
22:24:33 <Leimy> that's cool :)
22:24:46 <ozone> i figured it out, you're andrew tridgell in disguise
22:24:50 <Pseudonym> Now consider searching in a database.
22:24:58 <Pseudonym> No, I don't live in Canberra.  Shudder.
22:25:25 <Pseudonym> A simple way to search is simply to grep every record.
22:25:33 <ozone> that's a nice definition for hardcore CS: doing sorting and searching Ph.Ds in 2004
22:25:36 <Pseudonym> But we know that's slow for reasonable data sets.
22:25:46 <Pseudonym> So we build indexes.
22:25:49 <Pseudonym> Right?
22:25:56 <Pseudonym> That saves us from trolling over everything.
22:26:12 <Pseudonym> An index is a data structure which lets us avoid all that work.
22:26:28 <Pseudonym> Well, we've defined a data structure (stored on disk) which lets us avoid a lot of work in sorting, too.
22:26:48 <Pseudonym> And we only have to retrieve keys from records sparingly.
23:07:39 <Leimy_zzzz> night
23:35:24 <shapr> good morning #haskell!
23:36:10 <Maddas> Good morning, shapr 
23:36:13 <urtie> moin shapr
23:36:23 <shapr> what's going on?
23:36:33 <urtie> collating
23:36:42 <shapr> urtie: how's the report?
23:36:43 <shapr> oh
23:36:49 <shapr> Maddas: how's code?
23:36:55 <Maddas> It isn't :-)
23:37:15 <shapr> oh, no time lately?
23:37:33 <Maddas> Indeed
23:37:50 <Maddas> Enough time to not do anything useful, not enough for more
23:37:52 <shapr> urtie: any short missing entries I could write?
23:38:12 <urtie> I'll look
23:38:18 <urtie> just a sec.
23:38:45 <shapr> Maddas: work is busy? or just all of life?
23:39:03 <shapr> oh, I could check the status page
23:39:26 <Maddas> shapr: Busy studying and doing homework :-)
23:39:56 <shapr> ah, I can understand that
23:39:58 <urtie> shapr: anything that hasn't got a contact is fair game. :)
23:40:08 <Pseudonym> G'day.
23:40:16 <Maddas> Hello, Pseudonym 
23:40:17 <shapr> I should study more swedish
23:40:22 <shapr> g'day Pseudonym 
23:40:33 <Maddas> I should study more Japanese
23:40:41 <urtie> I should study more.
23:40:48 <shapr> Pseudonym: hey, did you see JaffaCake is on the channel?
23:41:30 <Pseudonym> No, I didn't.  Greetings!
23:42:10 <shapr> urtie: what's the status url again?
23:42:23 <Pseudonym> Do you suppose he's the left projection or the right projection morphism of Simon^2?
23:43:32 <shapr> I dunno, I think you should ask him if he awakens before you sleep
23:44:21 <urtie> shapr: http://www.haskell.org/communities/topics.html
23:44:22 <shapr> is haskell.org down?
23:45:33 <Pseudonym> We haven't been able to get to it all day.
23:45:47 <shapr> oh
23:45:51 <urtie> but, um, e.g.  the hierarchical libs, HXml, QuickCheck, haskell@haskell.org, haskell-cafe@haskell.org... they need text, and don't have a listed contact
23:47:25 <shapr> I can write about QuickCheck, but it'll be hard to keep it short
23:47:37 <shapr> hello mhfan 
23:50:07 <urtie> ;)
23:53:05 <shapr> oh, I really gotta put up an IOHCC page before the report goes up
23:53:36 <urtie> ozone also asked `when is the report going up' to get stuff out on the net before ;)
23:54:05 <shapr> Pseudonym: hey, any ideas for inline lambdabot command syntax?
23:54:13 <Pseudonym> Not offhand.
23:54:42 <shapr> I was just thinking how nice it would be to do read this: @wiki NewbieHelp or somethin
23:55:08 <shapr> oh, I have an almost working haddockindex plugin
23:55:52 <shapr> and @type does hierarchical libs, and I added @info
23:56:20 <shapr> how could one do a type based search?
23:56:49 <Pseudonym> Only way I can think is pre-compute the types and search that.
23:58:27 <shapr> is there already a Type datatype with useful Eq instance?
23:58:30 <ozone> shapr: i think arthur replied that it won't be up until at _least_ the 14th
23:58:38 <ozone> he's going to try to get it out by the 20th, i think
23:58:39 <shapr> ah, ok
23:59:02 <shapr> hey, did you develop your Data.Generics demo any further?
23:59:21 <ozone> oh, that thing?  nope
23:59:23 <ozone> i wouldn't even call it a demo
23:59:41 <ozone> more like ... a foray ... into ... the jungle, with lots of lions and cute cuddly kodiaks
23:59:48 <shapr> heh
