00:20:02 <shammah> Pseudonym: You mentioned PD
00:20:09 <shammah> lets try that again...
00:20:27 <Pseudonym> I did?
00:20:47 <shammah> You mentioned PDA's wrt context-free grammars.  I'm unfamiliar with that acronym, would you mind expanding it?
00:20:59 <Pseudonym> Push-down automaton.
00:21:13 <Pseudonym> It's basically a DFA with a stack.
00:21:59 <shammah> ahh I've heard of push-down automata.  the acronym was unfamiliar that's all.  Thanks.
00:22:07 <Pseudonym> No problem.
00:31:16 <Pseudonym> Must away.  Nytol!
00:43:39 <shapr> good morning #haskell!
00:43:55 <skew> hi shapr
00:44:29 <shapr> hey skew, what's happenin?
00:44:44 <skew> doing some math
00:45:20 <skew> you missed some interesting parsing stuff Pseudonym was talking about
00:45:24 <skew> http://compilers.iecc.com/compsearch.phtml/
00:45:28 <skew> search for quantum
00:47:06 <shapr> interesting
00:47:16 <andersca> morning
00:47:47 <skew> they use a spinor algebra of stack operations to do things with parsers
00:48:06 <skew> <s| for push s, |s> for pop s
00:48:23 <skew> you should see where this is going if you've seen dirac notation before
00:49:19 <skew> extend regular expressions with these
00:49:44 <skew> so (a <1|)* (b |1>)* is the language of a^n b^n
00:51:14 <skew> he explained it soon before you left, if you want to check the logs
00:52:22 <shapr> that is interesting
00:52:53 <det> shapr: g'morning
00:52:59 <skew> have you used the Utrecht parser combinators?
00:55:07 <shapr> nope
00:55:16 <shapr> though it's on my list
00:55:30 <skew> they are pretty nifty
00:55:39 <skew> but I'm having trouble trying to use them with a lexer
00:55:57 <skew> well, I haven't figured out how to keep position information nicely
00:59:45 <skew> I should figure out what they do when you are parsing characters (positions are reported fine there)
01:19:30 <kosmikus> skew: I don't understand. If you use a lexer, why don't you let the lexer keep position information?
01:19:47 <skew> yeah, the lexer puts the position information in the tokens
01:20:32 <kosmikus> skew: then you have it available during parsing, or not?
01:20:41 <skew> yeah
01:20:57 <skew> the issue is defining all the instances that the combinators want for the token type
01:21:20 <kosmikus> ah, ok
01:21:37 <kosmikus> I should look at a current version once :)
01:21:42 <skew> I can't derive Eq and Ord because I need to ignore the location
01:22:11 <skew> The most unatural part is defining the predecessor and sucessor functions
01:22:23 <skew> that doesn't make much sense for value bearing tokens
01:24:11 <earthy> btw, the branch of maths you were doing, was that perchance differential geometry?
01:24:31 <skew> I suppose so
01:25:01 <kosmikus> hmm, do you need those two functions if you don't use the range combinator?
01:25:06 <skew> yeah, that's probably what it is
01:25:24 <skew> kosmikus: you need to define an instance at least
01:25:46 <kosmikus> instance Symbol MyToken <return>
01:25:50 <skew> I should check. I would be nice if I could skip that
01:26:18 <kosmikus> they have default methods, defined as  "error something"
01:27:07 <shapr> is there a tutorial for the UUAG?
01:28:48 <kosmikus> shapr: start from http://www.cs.uu.nl/groups/ST/twiki/bin/view/Center/AttributeGrammarSystem
01:29:02 <kosmikus> there is a manual, and there is a talk by Doaitse from a while ago
01:29:43 <kosmikus> the AFP paper that is linked is good to get an idea of what AGs are about, but it describes are very old version of the system, so there are significant syntactic differences ...
01:30:50 <shapr> thanks
03:03:45 <skew> kosmikus: it looks like those functions are never used if the range operator and the except function are not used
03:06:02 <skew> or rather, as long as distinct ranges you create are disjoint
03:09:35 <kosmikus> I think so, yes
03:32:09 <kosmikus> is there a good english translation for the german word "gleichnamig"?
03:36:12 <Igloo> I assume you want a different meaning than homonym?
03:36:36 <Igloo> (I'm working from babelfish's translation of "of the same name", I don't know what the word really means)
03:37:32 <kosmikus> yeah, "of the same name" is what I came up with, too, but I wondered if there is a one-word solution
03:37:48 <kosmikus> homonym might do ;)
03:38:09 <Igloo> Can you give an English sentence with that word where you want an English word?
03:38:16 <kosmikus> ah no
03:38:21 <kosmikus> it really means something different
03:39:07 <Shammah> kosmikus: is it one name to represent two meanings, or two names for the same meaning?
03:39:08 <kosmikus> basically: The Chapter "Type-indexed datatypes" is based on the ... paper.
03:39:34 <Igloo> I'd say "on the paper of the same name"
03:39:41 <kosmikus> ok
03:39:47 <shapr> eponym
03:40:01 <shapr> @wn eponym
03:40:03 <lambdabot> *** "eponym" wn "WordNet (r) 2.0"
03:40:03 <lambdabot> eponym
03:40:03 <lambdabot>      n 1: the name of a person for whom something is supposedly named;
03:40:03 <lambdabot>           "Constantine I is the eponym for Constantinople"
03:40:04 <lambdabot>      2: a name derived from the name of person (real or imaginary)
03:40:05 <lambdabot>         as the name of Alexandria is derived from the name of its
03:40:07 <lambdabot>         founder: Alexander the Great
03:40:31 <kosmikus> should be more like isonym, probably, but that doesn't seem to exist
03:40:39 <shapr> so you could say "the eponymous paper" maybe?
03:40:59 <kosmikus> i'll go with "of the same name"
03:45:41 <Shammah> shapr: reading the definitions in dictionary.com I don't think it quite fits.
03:47:05 <Shammah> shapr: possibly (coining) a coeponym "The name of a thing supposedly named after a person" :)
03:48:08 <shapr> heh
04:26:39 <earthy> of the same name *really* is the best choice
04:29:29 <Shammah> earthy: but apparently german can do it in one word, and we can't be letting the germans get away with a shorter phrase than us for the same concept!!! ;)
04:30:16 <earthy> `Das Kapittel `Type-indexed data types' ist auf dem gleichnamigen Artikel basiert'
04:30:30 <earthy> `The chapter `Type-indexed data types' is based on the article of the same name'
04:31:05 <earthy> you count. :)
04:31:10 <Shammah> :)
04:31:57 <earthy> `Het hoofdstuk `Type-indexed data types' is op het gelijknamige artikel gebaseerd'
04:33:01 <shapr> Det kapitel `Type-indexed data types' ц╓r grunded av det artikel med samma namn.
04:33:30 <earthy> `Le chapitre `Type-indexed data types' est bas'e sur l'article du m^eme nom'
04:33:44 <shapr> bah, beat me to that one
04:33:47 <earthy> ;)
04:34:24 <adept> what are you doing? :)
04:34:47 * shapr tries to figure out the lojban translation of that sentence
04:34:52 <earthy> comparing expressions in different languages :)
04:35:06 * Jerub is reminded of "Hans, Poland, Ja?"
04:35:23 <earthy> with an eye towards expressivity and compactness ;)
04:35:40 <Jerub> German: The German word for "hello" is "Echsteinlefahrtengruber". The German translation for "Hey Hans, what say tomorrow morning we climb into our tanks and roll over Poland?" is "Hans, Poland, ja?"
04:36:08 <Cale> heh
04:36:59 <earthy> that ref does not click...
04:37:20 <earthy> wher
04:37:24 <earthy> where's it from
04:37:35 * earthy should know not to try typing with just one hand
04:37:38 <adept> Here's in russian: Раздел "Индексированные типами типы данных" основан на однименной статье
04:37:48 <shapr> earthy: works for me
04:38:07 <shapr> I can't see that :-/ can you put it on the wiki?
04:39:16 <Cale> what character encoding is that?
04:39:31 <shapr> koi8?
04:39:36 <shapr> guess not
04:39:45 <Jerub> irc doesn't have content-type encoding unfortunately.
04:39:52 <Cale> It's not utf-8 :)
04:40:22 <Cale> I'd like to see IRC with content-type encoding, and latex support.
04:41:04 <shapr> aha
04:41:04 <Jerub> Cale: no, latex support would suck.
04:41:14 <Jerub> see, the best irc client, bar none, is irssi
04:41:20 <shapr> http://www.haskell.org/hawiki/SandBox - view with kio8 encoding
04:41:27 <Cale> why would LaTeX support suck?
04:41:31 <shapr> looks very nifty
04:41:31 <det> Jerub: why do you say
04:41:39 <Jerub> irssi is the best irc client!
04:41:46 <shapr> I have a better idea
04:41:56 <shapr> let's find a non-sucky protocol
04:42:05 <Jerub> shapr: (that isn't based on xml)
04:42:10 <Cale> Or design a non-sucky protocol.
04:42:11 <shapr> exactly
04:42:44 <shapr> ok, ipv6 multicast
04:44:35 <kosmikus> Cale: what should LaTeX support be?
04:44:50 <shapr> would each message need to embed the content type?
04:45:23 <shapr> would be nicer if you could only embed it when it changes from what you've used before
04:45:24 <Cale> You could type equations (presumably between dollar-signs) and have them processed by LaTeX and show up in the text.
04:45:33 <shapr> implicit params :-)
04:46:07 <Cale> The other solution is to only use unicode.
04:46:21 <Cale> wrt the encoding problem :)
04:46:46 <Philippa> which encoding?
04:46:59 <Cale> encoding of IRC messages
04:47:00 <Jerub> utf-8 or utf-16 cale?
04:47:08 <Cale> hmmm
04:47:11 <Philippa> or UC-32, or...
04:47:28 <Philippa> utf-8 makes most sense for backwards compatability over IRC, mind
04:47:49 <shapr> can the client always tell the difference between utf flavors?
04:48:08 <Philippa> don't know off-hand. utf-8 doesn't break older IRC clients though
04:48:10 <Cale> well, restricting yourself to (possibly various kinds of) unicode means you don't have to send more than a byte to determine which flavour in any case.
04:50:19 <Jerub> utf-8 really already works.
04:50:24 <Jerub> its just client breakage.
04:54:50 <shapr> does utf-8 handle cyrillic, hangul, etc?
04:55:26 <bringert> yes
04:55:28 <bringert> afaik
04:55:45 <bringert> utf-8 can code all unicode characters
04:55:56 <Cale> Ф≈╔Ф°╛Х╙· К║╠Ц┘░Ц┘┌К▌▄ п╟п╠пЁп╢
04:55:59 <det> irssi-text is pretty nice
04:56:00 <shapr> are there fonts that display theme all?
04:56:24 <shapr> Cale: I didn't see that
04:56:27 <Cale> There's some Japanese, Hangul and Cyrillic
04:56:29 <shapr> just tildes
04:56:32 <Cale> hmm...
04:57:00 <Cale> well, I think you probably ought to have :) UTF-8 usually works okay for me.
04:59:25 <shapr> are you using xchat?
04:59:29 <Cale> Yeah
05:00:05 <Cale> and it's set on UTF-8
05:03:22 <keverets> -Misc-Fixed-Medium-R-SemiCondensed--13-120-75-75-C-60-ISO10646-1 should show most of them
05:04:51 <Cale> You really only need to make sure that you have good coverage across multiple fonts. FreeType (at least I'm pretty sure it's freetype doing it) will overlay different fonts to get the characters you need.
05:05:37 <keverets> unless you're working in an xterm, and using ssh to connect to a screen session using irssi
05:05:57 <keverets> might work still for gnome-terminal or something, but I don't use that.
05:15:14 <Shammah> I'm on OSX and didn't install the international font-packs so I don't get the option 
05:15:41 <Maddas> I saw everything right :)
05:15:48 <Maddas> (Using irssi)
05:15:56 <Maddas> Although I can't read any of them yet.
05:17:34 <Maddas> I find it very hard to even distinguish the lines of those pictographic things with normal font sizes
05:18:43 <Cale> Only the Japanese was actual Japanese.
05:19:17 <Maddas> Hum?
05:19:44 <Cale> well, the Hangul and Cyrillic characters were just random.
05:19:50 <Maddas> oh, ok :-)
05:20:08 <Maddas> Those were Kanji, right?
05:20:11 <Cale> yeah
05:20:24 <Cale> Ф╪╒Е╜≈
05:20:27 <Maddas> Yay, I think I know the middle one.
05:20:32 <Maddas> "Root"?
05:20:56 <Maddas> I guess they don't really have English names
05:21:10 <Maddas> Japanese is so much easier to read with font size 96 :-)
05:21:20 <Cale> book, main, head, this, our...
05:21:28 <Maddas> Bummer.
05:21:34 <Cale> it's part of
05:21:38 <Cale> Ф≈╔Ф°╛
05:21:46 <Cale> Which is Japan
05:21:47 <Maddas> I'll stick to learning Katakana better and Hiragana for now :-)
05:22:03 <Cale> Х╙· <-- language
05:22:09 <Maddas> Isn't there also a Kanji for "Root?" (As in the root of a tree)
05:22:39 <Cale> hmm...
05:22:51 <Cale> that might be used for root as well
05:23:09 <Cale> let me get more detailed info on it :)
05:23:11 <Hyp3rion> Ф═╧
05:23:17 <Hyp3rion> ^^^ root
05:23:40 <shapr> other than the "do my homework for me" people, this channel has exceptionally interesting content on a regular basis
05:23:43 <Cale> Hyp3rion: which counter would you use for roots?
05:23:46 * shapr hOps happily
05:24:00 <Cale> would that be Ф°╛?
05:24:40 <Maddas> I thought that was "Root"
05:24:45 <Maddas> but I don't know much :-)
05:24:58 <Maddas> (Probably ~10 Kanji)
05:25:00 <Cale> wwwjdic is nice :)
05:25:09 <Hyp3rion> Cale, Ц│╘Ц┌⌠Ц│╙Ф°╛Ц│▀
05:25:18 <Hyp3rion> 8-o
05:25:37 <Maddas> Woo, I can actually read those =)
05:26:39 <Cale> Well, it says that it's a counter for long things.
05:26:47 <Hyp3rion> wwwjdic?
05:26:53 <Cale> http://www.csse.monash.edu.au/~jwb/wwwjdic.html
05:26:56 <Hyp3rion> ?
05:27:15 <Hyp3rion> :-D I used http://world.altavista.com
05:27:39 <Hyp3rion> Je ne parle pas japonais :-/
05:27:52 <Cale> ah
05:28:01 <Maddas> seems like I was wrong.
05:30:22 <shapr> hiya maihem, wassup?
05:30:56 <maihem> hi, not a lot... but,
05:31:45 <Maddas> typeclasses rock
05:31:50 <maihem> how best should I get a list of all 1Cx, 2Cx, 3Cx, 4Cx, ... xCx from a list of x elements?
05:32:00 <Maddas> (in case somebody didn't notice yet :-))
05:33:00 <maihem> ie, combinations [a,b,c,d,e,f] = [[a],[b],[c],[d],[e],[f],[a,b],[a,c],[a,d],[a,e],[a,f],[b,c],[b,d],...]
05:33:18 <shapr> perms
05:33:24 <shapr> in PreludeExts
05:33:41 <shapr> or maybe that's a powerset, I forget which
05:34:00 <maihem> I don't want permutations, just combinations
05:34:17 <Cale> you want powerset
05:34:24 <shapr> right, powerset
05:34:31 <shapr> its on PreludeExts
05:34:40 <shapr> @wiki PreludeExts
05:34:40 <lambdabot> http://www.haskell.org/hawiki/PreludeExts
05:34:41 <maihem> iie [a,e] is the same as [e,a] and only one should occur
05:34:44 <Cale> or ranked powerset, if you want them grouped by size
05:34:59 <Cale> ah
05:35:28 <Cale> hmm - I think that's right still.
05:35:28 <maihem> heh, thanks!
05:57:57 <shapr> smellsLikePez: I like Pez. They smell nice.
05:58:00 <shapr> dang
06:03:01 <shapr> Si\: how's HAIFA?
06:32:39 <Si\> shapr: Currently being reshaped so that SOAP uses lazy references instead of IORefs
06:32:45 <Si\> I think it works now...
06:33:18 <Si\> well I say instead of, you can set it with the "lazy-refs" option in the HAIFA Environment
06:33:38 <Si\> if some die-hard IORef really wants to use them...
06:33:44 <Si\>                ^ fab
06:33:51 <Si\> s/fab/fan
06:44:58 <Igloo> Aaarggh. How should this sentence end? [| $c ++ $s |] is the piece of code which represents the concatenation of ...
06:46:08 * Igloo has "the values represented by c and s", but I'm not sure that sounds right
06:47:02 <shapr> why not just represents concatenation of c and s ?
06:47:14 <shapr> oh, because that's wrong
06:47:16 <Igloo> Because c and s are ASTs, not values
06:47:18 <Igloo> Yeah
06:47:19 <shapr> and you're right
06:47:37 <shapr> I think your version is great
06:47:43 <Igloo> Heh  :-)
06:47:54 * shapr grins
06:49:18 <kosmikus> I have another suggestoin: [| $c ++ $s |] is an example of a trivial TH expression.
06:49:23 <kosmikus> :)
06:55:20 <Igloo> I need to talk about what it does, though  :-)
06:58:18 <kosmikus> I can imagine :) well, seriously, I think your sentence is okay, too
07:04:36 <ozone> holy crap
07:04:47 <ozone> the runtime loader is second on google's hits if you do a search for "haskell ghc"
07:05:03 <ozone> i really should design a non-shitty webpage for it
07:05:37 <Igloo> :-)
07:06:51 <ozone> ooo, hey, igloo, good friend, good buddy ... :)
07:07:07 <ozone> Igloo: would it be much work to add support for implicit parameters to TH.Syntax?
07:08:13 * Igloo adds it to the list
07:08:26 <ozone> Igloo: schweet
07:08:27 <Igloo> I should be doing a spurt of TH hacking RSN
07:08:40 <ozone> looks like my "subversion" source control system is working quite well!
07:08:48 <ozone> ah, always wanted to say that
07:35:41 <jesse> does anyone know where i might find a network server written in haskell, aside from the http server? more along the lines of a mud or a chat server. something that makes good use of concurrent haskell channels and mvars, i guess not nessesarily a network server
07:37:09 <shapr> http://www.scannedinavian.org/~shae/src/haskell/Echo2.hs
07:39:46 <reffie> is there something like select(2) in haskell?
07:39:59 <JaffaCake> reffie: yup
07:40:08 <JaffaCake> Concurrent Haskell
07:40:20 <reffie> well other than creating new threads/processes?
07:40:52 <Igloo> Oh, that reminds me; it there a replacement for hSelect frmo the old libraries in the new libraries, JaffaCake?
07:40:55 <JaffaCake> there's an old Select library, but I think it was removed
07:41:07 <reffie> removed!
07:41:18 <JaffaCake> well, Conc Hask is the way to do it these days
07:41:41 <JaffaCake> hSelect didn't play well with CH, it blocked all the other threads
07:42:00 <Igloo> Hmm, OK
07:42:21 <reffie> well, it's the same in C
07:42:36 <reffie> or any other language, if you don't have kernel threads.
07:42:46 <JaffaCake> what do you want to do, exactly?
07:43:00 * Igloo can't quite visualise how that's going to work - would the other threads have to read the data and pass it back in MVars or something?
07:43:43 <reffie> JaffaCake: read from several sockets..
07:44:15 <JaffaCake> so what's wrong with spawning threads to read from the sockets?
07:44:45 <reffie> nothing :P
07:44:57 <JaffaCake> there you go then :P
07:45:16 <jesse> i myself am more interested in the clients being about to talk to eachother, which in my mind pushes r.t., id like to see how others have handled it
07:45:47 <JaffaCake> r.t.?
07:45:55 <jesse> referential transparency
07:45:58 <JaffaCake> ah
07:46:35 <JaffaCake> MVars, or Chans to communicate between threads usually
07:47:27 <jesse> yeah, im not saying its hard to do, id just like to see how exactly others have done it
07:47:53 <jesse> ive not run into too much concurrent haskell code that uses channels and mvars
07:51:13 <shapr> http://www.haskell.org/hawiki/ConcurrentTutorial?action=highlight&value=mvar
07:51:55 <JaffaCake> There isn't much on that page :)
07:52:27 <shapr> better than nothing :-)
07:52:55 <shapr> would be nice to have demo code for each lib
07:54:35 <Igloo> Do MVars guarantee fairness?
07:56:24 <JaffaCake> Igloo: no
07:56:38 <JaffaCake> what kind of fairness would you like?
07:58:31 <Igloo> I'f I'm reading from the keyboard and the output of a program I've run I want the keyboard to be handled reasonably quickly even if the program is forever generating output
08:00:12 <shapr> yes, Lunar^ has mentioned that hOp needs thread priority
08:01:05 <JaffaCake> yes, you want priority rather than fairness really
08:01:07 <Igloo> In fact, I want to use curses' getch to read the input so I'm not even sure how I do that without having one thread poll stdin?
08:01:38 <JaffaCake> you can use the threaded RTS to do that
08:02:11 <Igloo> Without polling?
08:02:14 <JaffaCake> compile with '-threaded', and invoke getch with foreign import safe
08:02:34 <JaffaCake> yes, I think so
08:04:47 <Igloo> But I need to make other curses calls based on the output of the other fd, so I don't want to have to call getch until there's something waiting there
08:05:16 <JaffaCake> calling getch won't block the other threads
08:05:19 * Igloo doesn't know if it would actually work in the curses case, but it doesn't look to me as if it will always be possible to DTRT
08:05:27 * Maddas whistles
08:06:01 <Igloo> But there's potentially a thread-local-memory issue isn't there?
08:06:18 <JaffaCake> ah, I see
08:06:35 <JaffaCake> yes, the curses library would have to be thread-safe
08:07:31 <JaffaCake> ok, so just to clarify: you want to read from some fd, but simultaneously wait for input on stdin and react when some input arrives?
08:07:41 <Igloo> Yes
08:08:15 <Igloo> It seems to me that the concurrency stuff doesn't offer a superset of the functionality of hSelect, so perhaps hSelect should be migrated to the HLs?
08:08:19 <JaffaCake> you can use threadWaitRead to wait for data on stdin
08:08:46 <JaffaCake> well, hSelect is ok in the threaded RTS
08:08:59 <JaffaCake> also it needs someone to port it (I couldn't be bothered :))
08:09:23 <Igloo> Ah, threadWaitRead looks like it would solve my problems
08:09:58 <Igloo> Cool, thanks
08:10:04 <JaffaCake> no probs
08:51:24 <phubuh> hi hi
08:51:34 <kosmikus> hi there
09:04:49 <systems> hello shapr
09:04:53 <systems> how ya been
09:31:37 <ozone> aww man
09:31:39 <ozone> this totally rules
09:31:50 <ozone> a 68-line haskell program compiles to a 21480k application
09:32:35 <ozone> eat your heart out, david parsons
09:36:30 <vegai> ?
09:39:20 <ozone> vegai: playing around with a language binding i'm about to release
09:41:09 <pesco> ozone: What's the reason for such size?
09:41:46 <Lunar^> pesco: There's no system libhaskell
09:42:08 <Lunar^> pesco: But every C program would be quite large with C library statically linked in
09:42:09 <ozone> pesco: that's a good question
09:42:11 * earthy laughs
09:42:24 <earthy> ozone's extreme objectiveness
09:42:28 <earthy> ;P
09:42:42 <ozone> earthy: hooray, i beat your deadline :)
09:42:50 <ozone> release due in about an hour
09:43:07 <earthy> by two days ;P
09:43:09 <pesco> ozone: Do you have that much boilerplate/marshalling code?|
09:43:30 <ozone> pesco: see, the great thing about this binding is that i didn't write it
09:43:33 <ozone> i'm just releasing it
09:43:44 <ozone> so, i will delegate your questions to the codemonkey :)
09:43:48 <pesco> ozone: oic. Which binding is it,?
09:43:54 <pesco> LISP?
09:43:58 <ozone> HOC
09:44:02 <ozone> haskell to objective-c
09:44:09 <pesco> Ah, good.
09:44:37 <ozone> earthy: HC&A not due out til friday now?
09:44:37 <pesco> Why isn't there an FFI to LISP!?
09:44:52 <pesco> Er, nevermind.
09:46:42 <earthy> nope, an appointment to look at a house came up
09:46:47 <pesco> Still, I'd like one. I could just tell everyone at work, look this great stuff I'm implementing for your humungous LISP machinery! When all the while I'd just been coding Haskell safely at home...
09:46:58 <earthy> so that took some time away
09:47:07 <earthy> and tomorrow is a national holiday
09:47:20 <earthy> and I've got plans to spend time with the gf
09:48:49 <ozone> earthy: aww, where's your sense of priorities
09:49:21 <earthy> with spending time and living together with the woman of my life. :P
09:49:38 <ozone> that's very sweet
09:49:53 <ozone> you should put that quote into the HC&A report as an explanation for why it's been delayed. *runs away*
09:50:00 * earthy laughs
09:50:05 <earthy> it hasn't been. :)
09:50:20 <earthy> I'm still on the original published schedule ;)
09:50:28 <ozone> very true
09:52:26 <earthy> damn that syntaxpolice though
09:55:25 <ozone> ?
10:14:19 * SamBv4 wonders where you talk about APL
10:18:14 * SamB wonders why a+ is written in C++
10:19:30 <ski> a+ ?
10:22:47 * SamB looks for a blurb
10:24:54 <SamB> it is a derivative of APL, anyway
10:25:50 <ski> mhmm
10:25:54 <SamB> how do you spell A in Wiki?
10:31:21 <SamB> hmm, I might need a windows key for this...
10:33:37 <SamB> well, at least it seems to be building okay, even if I got some ominous warnings from GCC. the same cannot be said of sisal
10:35:41 <SamB> hmm, was C++ around in the late '80s already?
10:35:52 <SamB> http://c2.com/cgi/wiki?AplusLanguage
10:43:22 <earthy> samb: yes.
10:43:40 <earthy> not as it is now, ofcourse
10:47:40 <SamB> earthy: I knew that much! it has changed in the quite recent past!
10:48:16 <earthy> but, yeah, I think the earliest developments are from about 1984 or thereabouts
10:48:19 <pesco> Which compilers supported partial template specialization back then?
10:48:38 <earthy> 1983 even.
10:49:32 <earthy> there was only one compiler at that point, and it defined the language. :P
10:49:53 <earthy> anyway, time to go dancing.
10:50:05 <pesco> Dance Dance Revolution?
10:50:19 <pesco> Yeah, that's an awesome game.
10:50:50 <earthy> nope, ballroom dancing. you know, in a room, with other people, without computers?
10:51:10 * pesco gives earthy a blank stare
10:51:45 <pesco> People? Peeeeeople.
10:51:53 <earthy> women even
10:51:54 * pesco closely listens to the word as he says it.
10:53:40 <shapr> man I gotta try that sometime
10:54:02 <pesco> shapr: DDR?
10:54:17 <shapr> nah, meeting people
10:54:25 <pesco> earthy: Oh, sweet, you seldomly see women at the arcade.
10:54:32 <shapr> like, someplace other than IRC
10:55:33 <shapr> pesco: speaking of which, you coming to EuroHaskell? I think I already asked you this maybe.
10:55:53 <ozone> HOC is out!
10:55:54 <pesco> shapr: Yes you did, I'd love to, but I'm hesitant about the long trip.
10:55:57 <ozone> http://hoc.sourceforge.net/
10:56:02 <ozone> and now, i'm going to get a freaking glass of water
10:57:00 <shapr> sweden has the highest concentration of gorgeous babes that I've ever seen, and I've traveled all over the US.
10:57:26 <tic> heh
10:57:42 <tic> then the US gurlz must be hideous =)
10:57:50 <shapr> pesco: don't just do it for the code ;-)
10:57:56 <ozone> sweden's pretty good
10:58:02 <ozone> certainly if you like blondes, sweden is rather good
10:58:15 <ozone> but uppsala, oh man, that place is just nuts
10:58:22 <shapr> tic: actually, I think it's the social importance of Sweden's national health program
10:58:24 <tic> ozone, heh, what about it?
10:58:28 <ozone> i think australia generally beats sweden
10:58:36 <tic> shapr, "social importance" ?
10:58:47 <ozone> but uppsala is an order of magnitude over any other european, asian or american city i've visited
10:58:57 <tic> over?
10:58:59 <shapr> in the USA there's no 'social priority' on being in good shape.
10:59:02 <tic> you mean for girls?
10:59:09 <tic> shapr, ahh.  
10:59:31 <shapr> I read that exercise gyms get federal subsidies
10:59:35 <pesco> shapr: I'm not sure I have the money. What's the date again?
10:59:37 <ozone> s/over/better than/
10:59:41 <tic> shapr, uhm, not that I've heard.
10:59:53 <shapr> @eurohaskell
10:59:54 <lambdabot> less talks, more code!
10:59:54 <lambdabot> http://www.haskell.org/hawiki/EuroHaskell
10:59:54 <lambdabot> EuroHaskell - Haskell Hackfest - June 10-12 - Gothenburg, Sweden
11:00:02 <ozone> hey, stop talking about babes and download hoc already :)
11:00:30 <tic> shapr, but generally we might be a bit healthier, yeah. Although we're quickly adopting the american life style which really sucks.
11:00:58 <shapr> tic: american eating and exercise habits (or lack thereof) truly do suck
11:01:33 <tic> shapr, so what's a typical day's food intake for the average american?
11:02:53 <tic> shapr, hey!
11:03:01 <tic> I demand answers in < 1 minute!
11:03:19 <ozone> tic: burger, fries, burger, fries, burger, fries
11:03:21 <tic> *fetching egg*
11:03:23 <tic> hehe. really? :)
11:03:41 <darius-> you left out the pork rinds
11:03:56 <pesco> and bacon for breakfast.
11:05:21 <tic> actually, my day started with a burger..
11:06:20 <tic> 09.40-10.40 - bicycle ride, 10.50 - breakfast: 150g burger+bread (no ketchup, mayo or whatever), and then situps, pushups, and then I had dinner just a few hours ago.  Now having a boiled egg.  BLah blah blah.
11:22:50 <Lunar^> Waow, HOC seems promising !
11:25:29 <ozone> excellent, my propaganda is working
11:26:08 <Lunar^> ozone :)
11:26:19 <Lunar^> ozone: I would like to spend more time on it... are you coming to EuroPython ?
11:26:25 <Lunar^> s/EuroPython/EuroHaskell/
11:26:26 <Lunar^> damn
11:27:34 <ozone> Lunar^: if i lived in europe, i probably would
11:27:46 <ozone> but i live approximately on the other side of the earth from europe, so that's a bit hard
11:35:48 <Lunar^> A live demo of the bindings would be cool IMHO
11:36:39 <ozone> yes, it would be
11:36:51 <ozone> i wanted to write more samples and more info for the webpages, but i'm going to collapse soon
11:36:55 <ozone> will have to do it in a few days
11:37:06 <ozone> ditto for a demonstration of how to write a haskell web browser, with Apple's WebKit :)
11:37:25 <ozone> (then again, you can already write a web browser with 0 lines of code with Cocoa, so maybe that's not such a great example)
11:37:53 <Lunar^> ozone: Mhh depends
11:38:07 <Lunar^> ozone: Good example would be HaXmL + WebKit maybe
11:38:39 <ozone> yes, true
11:39:03 <Lunar^> another killer app would be a GHC profiling analyzer
11:39:43 <ozone> indeed, like a frontend to valgrind
11:39:51 <Lunar^> I know ! A Darcs front-end !!
11:40:06 <ozone> that too :)
11:40:45 <Lunar^> Ok, please, I need to stop dreaming now, or I'm going to start coding, which would be very bad for hOp
11:41:16 <ozone> heheh
11:49:09 <jadrian> so I have:
11:49:16 <jadrian> MyProgram
11:49:26 <jadrian> MyProgram/Aux
11:50:01 <jadrian> modules in MyProgram import Modules in Aux
11:50:24 <jadrian> so I named the modules:
11:50:30 <jadrian> Aux.Module
11:50:51 <jadrian> But this means this modules cannot be imported by other modules in Aux :-/
11:51:02 <jadrian> how do you deal with namespaces?
11:51:17 <jadrian> simples example:
11:51:31 <jadrian> MyProgram 
11:51:36 <jadrian> MyProgram/Aux
11:52:08 <jadrian> MyProgram/A.hs  imports  MyProgram/Aux/C.hs
11:52:15 <jadrian> MyProgram/Aux/B.hs  imports  MyProgram/Aux/C.hs
11:52:50 <jadrian> how do you name/import this modules using namespaces?
11:53:58 <ozone> jadrian: you can write 'import Aux.C' in Aux/B.hs, if that's what you're asking ...
11:54:36 <jadrian> ozone: and what is the name of Aux/B.hs?
11:54:45 <ozone> module Aux.B where ...
11:54:46 <jadrian> ozone: Aux.B  or B 
11:54:56 <jadrian> didn't seem to work here...
11:54:59 <jadrian> let me try again
11:55:38 <jadrian> ozone: nope, doesn't work
11:55:44 <jadrian> "file name does not match module name"
11:55:58 <jadrian> (ghci)
11:56:09 <ozone> hmm
11:56:15 <ozone> try ghci -i..
11:56:25 <ozone> dunno if that'll fix it, but try it ...
11:56:38 <jadrian> yeah that will do, but it's a different approach...
11:56:57 <ozone> well, it seems to work OK for me
11:57:00 <ozone> not sure what's going wrong for you
11:57:07 <jadrian> with .. ? or without ..?
11:57:12 <ozone> without
11:57:26 <ozone> what version of GHC?
11:57:33 <jadrian> 6.2.1
11:57:35 <jadrian> latest stable
11:57:41 <ozone> same here
11:58:13 <ozone> post to haskell@haskell.org and ask, i think
11:58:23 <ozone> since not many are on irc right now
11:58:52 <ozone> but i know it works for me, i've been doing that for ages
11:58:53 <jadrian> let me just try a few more things
12:00:52 <jadrian> ok let me just confirm:
12:01:37 <jadrian> MyProgram/A.hs   name: A.hs    import Aux.C
12:01:55 <jadrian> opss
12:02:58 <jadrian> ok
12:03:06 <jadrian> so you're telling me this works for you:
12:03:09 <jadrian> MyProgram/A.hs        name: A        import Aux.C
12:03:09 <jadrian> MyProgram/Aux/B.hs    name: Aux.B    import C
12:03:09 <jadrian> MyProgram/Aux/C.hs    name: Aux.C    
12:03:29 <ozone> Aux.B should import Aux.C
12:03:43 <ozone> otherwise, yes, i've done that before
12:03:59 <ozone> you may need to specify -i.. with GHC(i)
12:05:01 <jadrian> yes but that I know
12:05:19 <jadrian> I was looking for a way to do it *without* specifying -i..
12:06:19 <ozone> hmm
12:06:31 <ozone> email haskell mailing list, i guess, sorry i can't of more help
12:06:39 <jadrian> k thanks ozone
12:15:42 <Lunar^> jadrian: Module Aux.B should import Aux.C 
12:22:14 <jadrian> Lunar^: when I do that it looks for C.hs under MyProgram/Aux/Aux/C.hs
12:22:32 <jadrian> Lunar^: that is, it expects it to be under a subdir Aux
12:22:42 <jadrian> Lunar^: But C and B are in the same dir
12:22:58 <jadrian> Lunar^: so that will only work if I add a -i.. flag
12:23:50 <Lunar^> jadrian: If you start your compilation in MyProgram, then C with your layout is Aux.Aux.C
12:24:19 <Lunar^> oops sorry
12:24:27 <Lunar^> I did not read you well
12:24:41 <Lunar^> jadrian: But you need to launch GHC in MyProgram
12:25:03 <jadrian> Lunar^: good point
12:25:07 <jadrian> let me try
12:25:35 <Lunar^> jadrian: If you ever worked with Java package, it is really the same
12:26:13 <jadrian> Lunar^: I don't really know Java
12:26:23 <jadrian> Lunar^: worked thanks, and it even makes sense ;)
12:27:02 <Lunar^> jadrian: Ok, so know that you know how hierachical modules works in Haskell, you know how java package works :)
12:28:53 <jadrian> :)
12:30:25 <Lunar^> Does David Rondy ever comes here ?
12:31:07 <jadrian> never heard of him...
12:31:11 <jadrian> dinner!
12:31:31 <SamB> Lunar^: are you sure you spelled that name properly?
12:32:11 <bringert> Lunar^: how complete is hOp's readline implementation?
12:32:50 <Lunar^> SamB: thanks, it's Roundy
12:33:07 <Lunar^> bringert: very simple but already useful
12:33:28 <SamB> Lunar^: him, I've heard of. but I don't think he comes here :-(
12:33:30 <Lunar^> bringert: It's laking completion though
12:34:30 <Lunar^> My english is as low as my last night sleep hours count :(
12:34:46 <SamB> hmm, what should I use for APL?
12:35:00 <bringert> I was talking to Aarne Ranta about EuroHaskell yesterday, he suggested that a (reasonably) complete readline replacement could be a good sprint
12:35:13 <bringert> to avoid having to link against libreadline
12:35:28 <bringert> which apparantely is a big headache at least on Solaris
12:35:32 <Lunar^> bringert: Depends how far do you go, and what would be really interesting for an Haskell binding
12:36:03 <Lunar^> bringert: hOp uses dark's haSDL key datatypes
12:36:06 <opet> bringert: I remember having linking issues when getting HTk going on solaris. it could have been my fault, though
12:36:06 <SamB> A+ is taking forever to compile, and it must have big binaries, because the debian package is around 5 MB...
12:36:47 <Lunar^> bringert: The harder part is terminal handling which is not a problem (or not that much due to full control) in Hop
12:38:05 <bringert> isn't there some library for that
12:38:15 <bringert> termcap or something like that
12:39:17 <Lunar^> bringert: There's no Haskell binding for termcap AFAIK
12:39:30 <bringert> btw, Aarne also suggested a library for hidden markov models
12:39:31 <Lunar^> bringert: And it's really really all dirty stateful code
12:39:39 <bringert> hmm, ok
12:39:43 <Lunar^> AFAIK
12:40:02 <Lunar^> There's also no termcap on Windows
12:40:10 <bringert> it seems like all you need is to be able to move the cursor and to delete characters
12:40:13 <Lunar^> Which is a major requirement for an independant Haskell libreadline clone
12:40:17 <bringert> yeah
12:40:35 <Lunar^> You'll see it in hOp code, I hOpe to finish it tomorrow night
12:40:40 <Lunar^> (finish the packaging)
12:42:09 <bringert> does the windows terminal (or whatever it is called) support any escape sequences?
12:42:37 <eivuokko> Depends.  It's not good to expect that for portable software.
12:43:01 <bringert> so the only solution is something like termcap?
12:43:01 <Lunar^> Unfortunately, my knowledge of Windows is really.. mhh.. inexistant
12:43:13 <bringert> mine too
12:43:26 <Lunar^> bringert: But for hOp implementation, I took example from a simple code for Windows that was posted on hasekll-cafe
12:44:03 <bringert> how about a low-level module that handles the cursor movement and such, and then we just write one for each platform?
12:44:57 <bringert> Lunar^: why does hOp do windows stuff? or is the windows way the same as talking directly to the hardware?
12:46:25 <Lunar^> http://shapr.homelinux.net:80/cgi-bin/wash/ShowMessage?%3C%2BRIAAMb%2F4zriNAEA%40cs.york.ac.uk%3E
12:46:32 <Lunar^> Malcolm Wallace again
12:46:43 <Lunar^> Did not notice at first sight
12:47:17 <Lunar^> bringert: That is a lot of hassle, I don't think that is good for a sprint
12:51:43 <bringert> ok
13:06:00 <ski> hmm, DSEL = Domain-Specific ?Extension? Language ?
13:06:39 <bringert> I normally read the E as Embedded
13:15:20 <d3z> I believe the windows terminal understands a subset of the vt100/ansi escapes.
13:18:54 <bringert> as long as they can move the cursor left/right and erase characters, it should be enough for readline, right?
13:20:58 <Lunar^> bringert: Unfortunately, not if you want to have real readline features
13:26:35 * bringert has only used line editing and history
13:26:41 <bringert> what other cool stuff is there?
13:27:28 <Lunar^> bringert: search in history, cut/paste feature
13:27:38 <Marvin--> tab expansion?
13:27:42 <d3z> Looking at the terminfo for 'cygwin' it looks fairly full fledged.
13:27:56 <Marvin--> oh crud
13:27:59 <Lunar^> sure, but GHC does not depend on cygwin (fortunately)
13:28:07 <Marvin--> the deadline for submissions to HW is June 4th
13:28:33 <d3z> I don't think the cygwin terminal is different than the regular windows terminal.
13:28:47 <Lunar^> d3z: it is ! It is a separate application
13:29:04 <Lunar^> or is it not ?
13:29:17 <d3z> It just uses the "normal" windows terminal window.
13:29:31 <d3z> I just tried it, you can actually run it in a normal terminal window.
13:30:24 <SamB> d3z: yeah, I would have thought you would have noticed that was *exactly* the same as a normal terminal, including settings...
13:30:52 <Lunar^> d3z: Still, it is not interesting because the idea of having an Haskell readline reimplentation is portability, I think
13:30:58 <d3z> I don't use windows very much.
13:31:11 <d3z> But, if we stuck to the ANSI terminal subset, it should work on most terminals.
13:31:34 <d3z> I was just saying that the windows terminal handles all of the escapes from the ANSI subset.
13:32:35 <d3z> The definition http://www.ecma-international.org/publications/standards/Ecma-048.htm describes the escapes.
13:33:08 <Lunar^> I take this link
13:34:18 <Marvin--> damn damn damn
15:56:20 * SamB wonders why the llnl cancelled sisal's web/ftpspace
18:40:15 <SamB> what idiot decided that sisal didn't need webspace or ftpspace anymore, just because it lost funding, I wonder?
18:40:35 <Pseudonym> Isn't it on sourceforge?
18:41:20 <SamB> well, I don't imagine that is the whole FTP tree on sourceforge...
18:41:23 <SamB> or am I blind?
18:41:33 <Pseudonym> I don't know.  Haven't used it in years.
19:50:19 <desrt> *nggggg*
19:50:24 <desrt> my screensaver is eating my brain
19:50:28 <desrt> it's such total eyecandy
19:52:10 <SamB> desrt: don't allow it to kick in!
19:52:53 <desrt> i just installed it on my desktop so that i could use my laptop while having it running beside me :)
19:53:02 <Cale> desrt: you should check out the rest of the xscreensaver collection - I'd say there's a better than 25% brain-eating potential rate.
19:53:06 <desrt> before it was running on my laptop while i was using my desktop
19:53:33 <desrt> Cale; i've gone through the whole thing.  this one is something i actually installed separately
19:53:44 <desrt> i used to use "Swirl" for everything
19:53:55 <desrt> fireflies is quite cool, though
19:54:00 <desrt> (emerge fireflies)
19:54:04 <desrt> how was ghazi's?
19:54:13 <SamB> desrt: that tends not to work on debian
19:54:39 <desrt> SamB; that's not my problem =)
19:55:34 <desrt> Cale; btw.  i wrote and ran my program to check against the libc sin/cosine
19:55:43 <desrt> remember how i thought it would end up taking the entire weekend to run it?
19:56:10 <desrt> it turns out that calling sin() and cos() in a tight loop is only about 4-5 times slower than dr. anand's implimentation
19:56:37 <desrt> results: for all positive numbers the maximum error of our values is something like 1e-7
19:57:00 <desrt> unfortunately, we get errors at -pi/28, -3pi/28 -5pi/28, ...
19:58:05 <Cale> ghazi's was good as usual :)
19:58:29 <Cale> ah, so it's for negative values that the problem occurs
19:58:39 <desrt> ya....
19:58:52 <Cale> odd - how long does it take to shift to [0,2pi) ?
19:58:53 <desrt> the real big disappointment here is that sin() and cos() are so bloody fast
19:59:06 <SamB> desrt: that should be a nice thing
19:59:07 <desrt> we get the shifting implicitly..... sort of
19:59:27 <desrt> SamB; not really.  it would be really nice to say "our implimentation is 100 times faster than libc sin()"
19:59:31 <desrt> but really it's only 4-5
19:59:51 <Cale> desrt: this is with the pipelining?
19:59:55 <desrt> no.
20:00:13 <desrt> but remember... we're at 12 clocks per value already
20:00:28 <desrt> pipelining will buy us a 2-3 times increase, *tops*
20:00:28 <Cale> well, it should be significantly faster when it's down to 2.5 clocks/value.
20:00:35 <desrt> i don't think 2.5 is possible
20:00:43 <desrt> in fact, i know it's impossible
20:01:02 <Cale> what did Dr.Anand say he had it at then?
20:01:07 <desrt> 2.5
20:01:12 <desrt> i'm sure he was lying
20:01:15 <Cale> heh
20:01:19 <desrt> seriously
20:01:34 <Cale> You should probably talk to him about that.
20:01:47 <desrt> *one part* of his algorithm (the polynomial approximation) does like 6 vector fma's in a row
20:01:53 <desrt> which takes exactly 6 clocks
20:01:55 <desrt> pipeline or not
20:02:09 <desrt> there's only one vector multiplication unit so you can only ever do one fma per clock
20:02:33 <desrt> anyway.. we do 4 numbers at once
20:02:34 <Cale> are there ops on the powerpc processor going on at the same time?
20:02:43 <desrt> which means that's 1.5 clocks per number
20:02:49 <desrt> and it's just a tiny part of the algorithm
20:02:57 <desrt> i refuse to believe the rest is going to pipeline into 1 clock :)
20:03:10 <desrt> ya
20:03:17 <SamB> desrt: that is quite reasonable, if it is worthy of the name algorithm
20:03:22 <Cale> well, we'll see. Fix the bug and let him shuffle the lines up again :)
20:03:33 <desrt> altivec can do 3(different operations at once
20:03:37 <desrt> emphasis on different
20:03:42 <desrt> because it can't do 3 of the same at once
20:04:07 <desrt> (well... i mean.. it explicitly always operates on vectors... so it *always* does 4/8/16 of the same thing at once)
20:04:37 <desrt> (but you can't do 3*4/8/16 of the same thing at once.... but you can do 4/8/16 of one thing, 4/8/16 of another and 4/8/16 of a 3rd different thing)
20:04:53 <desrt> get what i mean?
20:04:56 <Cale> yep
20:05:14 <desrt> *takes a look at the code*
20:05:46 <Cale> Which means that it starts to seem quite reasonable that it amortises to 2.5 clocks/value.
20:06:10 <desrt> 31 vector operations per loop cycle
20:06:28 <desrt> 3 vector memory operations
20:06:40 <desrt> 3 scalar operations, 1 branch
20:06:58 <Cale> these are vectors of 4 values?
20:07:03 <desrt> yes
20:07:06 <desrt> almost always
20:07:13 <desrt> ok
20:07:17 <desrt> it's starting to look possible
20:07:22 <desrt> assuming you can saturate the pipeline
20:07:44 <desrt> ie: 3 ops per clock
20:08:08 <Cale> I think the whole idea is to saturate the pipeline and approach/attain peak computation.
20:08:12 <desrt> means we have 10 clocks per loop (assuming the memory operations and scalar ops are free, which they probably come close to being)
20:08:27 <SamB> Cale: it is not easy to do that, though
20:08:27 <desrt> so say, even... 12 clocks per loop
20:08:38 <Cale> SamB: right.
20:08:38 <desrt> but.. remember.. each loop produces 8 values
20:08:52 <desrt> which means we get 1.5 clocks per value at pipeline saturation
20:08:59 <desrt> which means it's quite possible that he wasn't lying
20:09:06 <desrt> i forgot that we got 4 results at a time
20:09:19 <Cale> But I think this might be one of the "contrived examples" that Dr.Anand was talking about.
20:09:29 <desrt> well...
20:09:31 <desrt> here's the thing
20:09:33 <SamB> it is also quite possible that it can't be done unbuggily, isn't it?
20:09:34 <desrt> anand is smart
20:09:51 <desrt> he uses a good mix of vector instructions here
20:09:55 <desrt> that use different parts of the altivec
20:10:11 <desrt> 6 instructions are permutations
20:10:16 <ozone> 13:09 < desrt> which means it's quite possible that he wasn't lying
20:10:20 <ozone> ^ great quote
20:10:57 <SamB> you should start a cookie jar for #haskell
20:11:15 <desrt> ideally we have 25 vector ops to split in half now
20:11:25 <desrt> which gets us 12 clocks
20:11:30 <desrt> or more like 15 in reality
20:11:45 <desrt> 15 over 8 is still less than 2
20:12:14 <desrt> i'm going to venture to say that assuming the fix to the -pi/28 problem doesn't involve significant changes that we'll be able to get within a clock of 2.5
20:13:47 <desrt> right now it does 12 per value which is 24 per pair which is 96 per loop which is ... bad
20:14:07 <Cale> hmm - how are negative floating point values represented? Perhaps there are some bitwise/integer ops getting performed somewhere that assume that the representation is positive?
20:14:11 <desrt> 38 instructions in 96 clocks?!
20:14:34 <desrt> a negative float is a float with the highorder bit set
20:14:40 <Cale> okay
20:14:51 <desrt> i'm concerned
20:14:53 <Cale> how far off are the values are -pi/28 etc.
20:15:01 <Cale> at*
20:15:07 <desrt> for sine, 0.1
20:15:11 <desrt> for cosine 0.99
20:15:17 <Cale> hm..
20:15:26 <desrt> (ish)
20:15:48 <Cale> is it happening in a discrete fashion, or are multiple values around that point bad?
20:16:09 <desrt> couldn't tell you :)
20:16:17 <desrt> interesting fact, though:
20:16:23 <Cale> you might want to do a short sweep of 100 or so values and see
20:16:29 <desrt> the first value that triggers the problem for sine doesn't trigger it for cosine
20:16:30 <Cale> (since you know where to look)
20:16:34 <SamB> desrt: did you make graphs?
20:16:52 <desrt> samb; no
20:17:02 <desrt> once i got to what i know now i put the problem down
20:17:24 <desrt> it was after an hour or three of solid hacking
20:17:33 <desrt> seemed like a good place to stop :)
20:18:44 <desrt> i wonder how expensive a cache miss is on a G4
20:19:20 <desrt> i'm back to thinking that 2.5 is impossible except under unrealistically favourable conditions
20:21:00 <Cale> Unrealistically favourable conditions is the sort of thing Rebecca is working on.
20:22:06 <Cale> well, not quite the same there, but still :)
20:22:16 <SamB> maybe he wasn't counting those
20:23:21 * Cale rolls 5/8 on his fraction dice.
20:26:16 <desrt> 256000000
20:28:25 <Cale> that's 2^14 5^6
20:28:35 <desrt> :)
20:28:55 <desrt> i hope you were able to do that in your head
20:28:55 * SamB thinks somebody ought to dig the sisal webpages out of the web archive
20:29:57 <desrt> 4096000000
20:29:58 <Cale> yep, 256 = 2^8, 1000000 = 10^6.
20:29:58 <desrt> ok
20:29:59 <desrt> here goes
20:30:14 <Cale> where are these numbers coming from?
20:30:33 <Cale> are they loop sizes for your testing?
20:33:59 <desrt> Finished in 80.569390 seconds
20:35:00 <desrt> hmm.  how disappointing
20:36:05 <Cale> perhaps do a test of values within 100 epsilon of -pi/28?
20:36:21 <Cale> (and plot)
20:36:29 <desrt> wait
20:36:55 <desrt> wtf
20:36:55 <desrt> ok
20:36:59 <desrt> *gets out some paper*
20:37:03 <desrt> i'm messing something up here
20:37:05 <Cale> hehehe
20:37:18 <Cale> going to draw another one of those bloody circles?
20:37:22 <desrt> no :)
20:42:10 <desrt> ok
20:42:22 <desrt> i'm confident that the answer is 15.7 :)
20:42:38 <Cale> which answer is that?
20:42:54 <desrt> clocks per result
20:43:04 <desrt> where result is defined as a single sine term
20:43:12 <desrt> ie: 31 clocks per sin/cosine pair
20:43:28 <desrt> this is real time though... not user cpu time
20:43:34 <desrt> and my test environment wasn't really that great
20:43:42 <desrt> (ie: running on my laptop along side X and ssh to my irc client)
20:43:53 <Cale> ah, okay
20:44:06 <Cale> I was going to say that seems a bit high
20:44:27 <desrt> it's quite high
20:44:41 <desrt> it means that it takes about 125 clocks for one jaunt through the loop
20:44:47 <desrt> which is very high indeed
20:46:32 <desrt> ok.  i'm going to stop think about this by saying: if i see 2.5 i'll be impressed
20:46:44 <desrt> and if i see 2.5 in a real-world applicable situation i'll be *damned* impressed
20:48:17 <Cale> I want to know more about the nature of the failure at -pi/28
20:48:33 <desrt> tomorrow, young grasshopper
20:49:07 <Cale> haha
20:57:18 <desrt> it doesn't seem possible to properly determine how much cpu time i've actually used
20:59:19 <Cale> well, I'll be in a little later tomorrow - my dad got his hours changed a bit, which should make the mornings a bit calmer.
21:00:24 <Cale> however, it also means I get to be in the optlab until 7:30 - 8:00
21:01:58 <desrt> at night?
21:02:54 <desrt> you know
21:02:59 <desrt> we really have sweet jobs :)
21:03:45 <Cale> Yeah, it's pretty nice. If only I could get more sleep.
21:04:00 <desrt> the itb has really nice couches
21:04:06 <Cale> heh
21:04:07 <desrt> i'm sure you've noticed them by now
21:04:24 <Cale> that just doesn't seem right...
21:04:32 <Cale> heh
21:05:08 <desrt> my end of the school year was so fucked
21:05:10 <desrt> i slept so little at home
21:05:28 <Cale> I slept so little
21:05:41 <desrt> i'd pull an allnighter
21:05:44 <desrt> so i was up nice and early
21:06:24 <desrt> then because i was up so early i'd catch the 8am bus that takes me all the way from my house to school (there is exactly 1 bus like this per day.. at 8am)
21:06:30 <desrt> and i'd get there and crash
21:06:41 <desrt> i did this about 5 times in a little over 2 weeks :)
21:07:18 <desrt> and i've never slept so well as on those couches, listening to cat power while skipping my calculus class (which is in the lecture hall right beside the couches)
21:07:49 <desrt> something about that particular combination of conditions led to perfect sleep
21:09:06 <desrt> ok.. so.. tents
21:10:18 <Cale> there's something oddly satisfying about counting a specific set of approximately 3*10^1160 permutations within a minute.
21:10:45 <Cale> (this is a restriction, so it's counting only permutations matching a specific pattern)
21:11:05 <desrt> i was quite impressed by how fast my ibook was able to wrap a 32bit int
21:11:17 <Cale> I'd paste the result, but it's 1160 digits long :)
21:11:41 <desrt> here
21:11:44 <desrt> i have a problem for you
21:11:53 <desrt> factor this:
21:11:54 <desrt> 204786850751295361967761958294816772263373446530533330842310010227593460926573721616243574574938610317768838480295661764641373189675684598132126107868869100680403961034161531269875823113747307064306162361594184793353844591199934178691311093234277090051524523423020937643173802689510451078924760206401664344577855444555080209878653178613300670646276185802258412358218745698179218186281499918488117248474208839648731441658723181507007127
21:12:13 <desrt> in your head is prefered
21:12:23 <desrt> but if you want to use mathmatica i won't complain
21:12:23 <Cale> hmm... that number seems familiar
21:12:29 <Cale> :)
21:12:41 <desrt> it shouldn't
21:13:29 <desrt> it's the product of 2 very large random primes
21:13:46 <Cale> for a sufficient definition of "very"
21:14:02 <Cale> Is it one of the rsa challenges?
21:14:12 <desrt> it's my ssh key :)
21:14:18 <Cale> ah, okay
21:14:19 <desrt> or, rather, the modulus of my old ssh key
21:15:46 <Cale> Oh, right, I was thinking of 25195908475657893494027183240048398571429282126204032027777137836043662020707595556264018525880784406918290641249515082189298559149176184502808489120072844992687392807287776735971418347270261896375014971824691165077613379859095700097330459748808428401797429100642458691817195118746121515172654632282216869987549182422433637259085141865462043576798423387184774447920739934236584823824281198163815010674810451660377
21:15:46 <Cale> 306056201619676256133844143603833904414952634432190114657544454178424020924616515723350778707749817125772467962926386356373289912154831438167899885040445364023527381951378636564391212010397122822120720357
21:15:53 <Cale> which is much larger
21:16:05 <desrt> what is this one?
21:16:30 <Cale> RSA-2048
21:17:12 <desrt> uhm
21:17:14 <desrt> mine is 2048 bits
21:17:21 <desrt> irc probably truncated it
21:17:30 <Cale> yeah, probably
21:17:36 <Cale> it had to break my line
21:18:25 <Cale> I'll FactorIntegerECM your possibly truncated value anyway, and see if anything turns up
21:18:31 <Cale> right, 2963843 pops out
21:18:39 <desrt> definitely truncated
21:19:39 <desrt> i wonder if it's possible to find some pattern of number within a certain base that's always a prime
21:19:58 <desrt> something like saying 1, 11, 111, 1111, 111111 for any number of digits is always prime
21:20:09 <desrt> or maybe 123123123123 for as many repetitions of 123 as you want
21:20:11 <Cale> well, not that simple of a pattern :)
21:20:21 <desrt> something like that
21:20:31 <Cale> because there will be obvious factors
21:20:39 <desrt> if you could find a pattern like that and prove it....
21:20:57 <desrt> then you could instantly break all records (past and future) for the largest known prime
21:20:57 <iehon> ... then please make me a co-author of the paper.
21:22:03 <desrt> this is one of those things that it actually seems like there might be a proof floating around that proves it's not possible :)
21:22:08 <Cale> 123123123123 = 1001001001 * 123
21:22:15 <Cale> :)
21:22:33 <desrt> so there you go
21:22:35 <Cale> well, I'd be happy to try to prove it's impossible if you give me an admissible set of patterns
21:22:42 <desrt> for any pattern that has a period of more than 1
21:23:42 <desrt> now all you have to do to close the proof is find counterexamples for all the others
21:23:45 <desrt> which is absolutely trivial
21:23:54 <desrt> since 22, 33, 44, 55, 66, 77, 88, 99 all divide by 11
21:24:10 <desrt> and 111 = 3, 37
21:24:44 <np_hard> there is no pattern
21:24:49 <np_hard> it has been proved
21:24:54 <Cale> np_hard: huh?
21:25:01 <np_hard> there is a distribution though
21:25:02 <Cale> there is no pattern in what sense?
21:25:03 <desrt> we're not looking for a pattern of the primes
21:25:05 <np_hard> that has been proved
21:25:12 <np_hard> oh, sorry, I skmmed
21:25:15 <np_hard> skimmed
21:25:26 <Cale> Also, it always really bugs me that nobody ever says what they mean by pattern
21:25:59 <Cale> Of course there's a pattern to where the primes occur - they're a computable sequence.
21:26:23 <np_hard> that's not a pattern
21:26:28 <ski> it is
21:26:35 <Cale> Well, you didn't say what a pattern was
21:26:50 <np_hard> a satisfiable equation
21:26:53 <desrt> i think when people talk about patterns and primes they mean something more than the definition of what a prime is :P
21:26:58 <Cale> So I defined it to mean "anything for which an algorithm exists to generate it"
21:27:05 <np_hard> fair enough
21:27:21 <SamB> well, nothing other than their primeness...
21:27:35 <Cale> and if you stretch "equation" into "system of diophantine equations", then I'll be happy again. :)
21:27:52 <np_hard> yes, that works well in this case :)
21:28:54 <np_hard> there are lots of patterns in prime numbers actually
21:29:33 <np_hard> it's just computationally difficult to construct the sequence
21:29:40 <desrt> prime prime notprime prime notprime prime notprime notprime notprime prime
21:29:41 <desrt> ...
21:29:50 <SamB> np_hard: do tell
21:30:03 <desrt> sounds like a trippy drumbeat pattern to me
21:30:22 <SamB> np_hard: do they make curves with the commas or something?
21:30:30 <np_hard> well, for all primes, p=2n+1 for some n ;)
21:30:54 <np_hard> except 2 I suppose
21:31:03 <SamB> np_hard: that isn't a pattern, really...
21:31:12 <SamB> because most n don't have primes
21:31:13 <np_hard> well, what's a pattern then
21:31:14 <np_hard> :)
21:31:26 <desrt> hm
21:31:31 <SamB> and there isn't a pattern to which n do
21:31:34 <desrt> given a prime you can find the next prime
21:31:50 <Cale> When people say "there's no pattern to the digits of pi" without qualifying it in any way, I always grate my teeth. There's an algorithm to give the nth one in base 16 quickly, out of context. What do you want?
21:32:21 <desrt> Cale; is that algorithm O(1)?
21:32:27 <desrt> well
21:32:31 <Cale> heh
21:32:33 <desrt> i suppose, O(lgn) ..
21:32:38 <desrt> would be the best possible
21:32:54 <Cale> It's pretty fast. Let me look it up.
21:33:18 <desrt> because once n got big enough the sheer act of doing math on it would become difficult
21:33:22 <SamB> do you have O(1) arithmatic?
21:33:36 <desrt> SamB; this is what i'm saying
21:33:45 <Cale> It's done in polynomially logarithmic space and time.
21:33:53 <Cale> no
21:34:00 <Cale> and polynomial time
21:34:03 <desrt> if you're on a computer that has 32bits, for n>2^32 then arithmetic stops being constant-time
21:34:33 <desrt> what kind of polynomial?  n^2?
21:34:55 <SamB> desrt: well, sometimes it is 2^31
21:35:21 <desrt> doesn't matter
21:35:42 <desrt> when evaluating running times you always get blips and discontinuities at certain points when n is realatively small
21:35:58 <desrt> what matters is how running time is as n goes to infinity
21:36:27 <desrt> well, i guess i should probably say n > N
21:37:30 <Cale> Well, actually, the one I'm referring to is asymptotically slower (by a factor of log log log n) than the fastest known algorithms for computing up to the nth digit, but requires remarkably little space.
21:38:02 <Cale> It's O(n log(n) M(log(n))) where M is the complexity of multiplication.
21:38:14 <Cale> (that's in time)
21:38:40 <SamB> Cale: what about just the nth bit or nibble or whatever?
21:38:53 <desrt> SamB; doesn't matter
21:39:09 <Cale> I don't think it's any better - there's a 1/16^i in the nice formula for pi that they're using :)
21:39:09 <desrt> extracting 1 bit is the same in terms of O notation as extracting C bits (for constant C)
21:40:10 <Cale> they can also do logs of various integers, and powers thereof with essentially the same algorithm
21:40:14 <desrt> so even if your formula was optimised for extracting bits...
21:40:18 <SamB> desrt: yeah, I know...
21:40:32 <desrt> heh
21:40:39 <desrt> we were joking today
21:40:47 <desrt> that all problems have running time theta(1)
21:40:51 <desrt> for significantly large values of 1 :)
21:41:15 <Cale> or should that be sufficiently? I suppose it would be both.
21:41:26 <desrt> i meant to say sufficiently
21:41:37 <desrt> <- tired
21:43:02 <Cale> the neat thing is that they can use ordinary quad-precision floating point numbers to get digits that are way out there (like position 10^10)
21:43:27 * SamB installs g77, but isn't sure why
21:43:45 <Cale> google for "polylogarithmic constants" if you'd like to read the paper
21:44:00 * desrt found a book today "fortran 95" and boggled
21:44:27 <desrt> cale; you're a learning junkie
21:44:32 <desrt> i mean... i am too
21:44:40 <desrt> but .. not to such a level of excess :)
21:44:48 <SamB> hmm, does g77 support fortran 95?
21:45:02 <SamB> hmm, I am a learning junkie too. I think its this homeschooling ;-)
21:45:49 <desrt> g77 manpage doesn't contain the string "95"
21:46:40 <desrt>   However, we strongly expect that there will never be a version 0.6
21:46:40 <desrt> of `g77'.  Work on this compiler has stopped as of the release of GCC
21:46:40 <desrt> 3.1, except for bug fixing.  `g77' will be succeeded by `g95' - see
21:46:40 <desrt> `http://g95.sourceforge.net'.
21:49:03 <SamB> oh
21:50:07 <SamB> I have no clue as to the extent of the changes, but it does make sense to have an updated name too
21:51:36 <desrt> ok
21:51:40 <desrt> bedbedbed
21:51:43 <desrt> nite guys
21:51:49 <SamB> hmm, yes. bed.
21:58:01 <SamB> hmm, for some reason I was able to build sisal from CVS.
22:05:08 <SamB> how odd. sisal-mode doesn't do font-lock!
22:06:55 * SamB notices that xemacs supposedly supports HTCPCP
22:29:49 * ozone wonders when Fortran XP Media Center edition will come out
