01:35:35 <ih8ufkr> is haskell.org down
01:39:16 <Shammah> I haven't been able to get to it all day.
01:39:30 <Shammah> (1830 here)
01:51:02 <eivuokko> There's mirror at http://www.mirror.ac.uk/sites/www.haskell.org/
02:24:31 * iolotusbobo is away: Got Some Work... AFK...
03:35:25 <wolfman8k> morning
03:41:54 <wolfman8k> ghc finally finished installing, but when i try to run this OpenGL sample i get a ton of undefined references to things like, __stginit_GraphicsziUIziGLUT_
03:42:37 <neologism> do you have glut installed?
03:42:47 <wolfman8k> yes
03:43:54 <hashwolf> what do two colons on BOTH sides of an infix constructor (like :+: ) mean? 
03:45:23 <Jerub> hashwolf: thats probably the operator being defined...
03:45:25 <dennisb> hashwolf: the last : is just to make the constructor look nicer
03:45:37 <Jerub> oh, probably not then.
03:45:37 <Jerub> :)
03:46:24 <hashwolf> tought so but wasn't sure, 10x
05:21:56 <shapr> yeehaa
05:24:07 <shapr> man, I'm close to mirroring haskell.org on ScannedInAvian
05:24:37 <shapr> oh, I want a new DNS pointer type
05:25:09 <shapr> you can have multiple MX entries, why not multiple WWW entries?
05:30:45 <Lunar^> ?
05:31:34 <Lunar^> www IN A 127.0.0.1 \n www IN A 127.0.0.2  means that www is the round-bin between the two IPs in bind
05:31:40 <Lunar^> round-robin
05:38:27 <shapr> does that fallback to the other if the first ip doesn't respond?
05:42:53 <Lunar^> shapr: Nope, it's only one a DNS level
05:42:56 <Lunar^> -e
05:53:16 <shapr> MX is more sensible there
06:22:00 * iolotusbobo is back (gone 03:57:34)
06:22:16 <childe> Hello world!
06:22:33 <childe> Haskell is much better than Scheme, right?
06:23:16 <Taaus> Mu.
06:25:06 <norpan> programming languages are not better, programmers are
06:26:05 <andersca> morning norpan
06:26:55 <norpan> hej anders
06:37:20 <Philippa> norpan: this is why we're all writing machine code
06:43:21 <Maddas> Philippa: quite a few people do.
06:44:27 <Philippa> hmm. I don't know that many who write machine code rather than assembly these days
06:44:41 <Maddas> Oh, sorry, I thought you meant assembly :-)
06:46:00 <Philippa> there's no unique ordering on programming languages defining which're "better", but there're plenty of worthwhile ones
06:49:22 <XTL> And in practice, language implementation and libraries can matter in very significant ways
06:49:48 <Lunar^> He wins, troll started
06:50:03 <Maddas> :-)
06:50:31 <childe> Is it very difficult do write a Haskell interpreter, or compiler?
06:50:55 <childe> Is there some specific difficulties to write a H compiler?
06:51:56 <cm> you mean besides getting it correct and fast? :)
06:52:50 <saz> those aren't really speicific to a haskell compiler tho :P
06:53:02 <cm> the latter is :)
06:53:11 <childe> Several weeks ago a friend said to me, why not make a shell use Haskell as it's language.
06:53:14 <eivuokko> I'd guess that Haskell is relatively easy to implement as far as generic purpose languages are considered.
06:53:30 <saz> cm: you don't want your c compiler to be fast?
06:53:46 <cm> saz: it's much easier to write a fast c compiler, no?
06:53:47 <childe> He thinks that Haskell can be used as a shell language.
06:54:04 <saz> cm: i suppose so
06:54:18 <cm> :)
06:54:27 <saz> cm: but then again.. g++ is super slow
06:54:36 <saz> so it's not just haskell :)
06:54:37 <Maddas> That's C++, not C :)
06:54:37 <eivuokko> So are most other C++ compilers.
06:54:41 <saz> i know
06:54:57 <childe> C++ is much compicate than C.
06:55:03 <cm> saz: i was referring to that it should better generate fast code, sorry
06:55:11 <saz> ah
06:55:14 <cm> and msvc is pretty fast :)
06:55:28 <saz> never used it
06:55:30 <eivuokko> cm, how far you've gone with templates?
06:55:35 <childe> cm: You mean compile time or run time
06:55:44 <cm> compile time
06:55:47 <eivuokko> It slows down on templtes quite a lot in certain point.
06:55:48 <cm> eivuokko: very far
06:55:54 <childe> I don't think so.
06:56:20 <Maddas> "it should generate fast code" means _run-time_, doesn't it?
06:56:36 <cm> yes
06:56:45 <childe> cm: You've compiled the same program in both GCC and VC?
06:56:47 <cm> "[15:55] <cm> and msvc is pretty fast :)" was referring to compile-time, tho
06:56:55 <cm> childe: yes, vc was much faster
06:57:06 <childe> What program them?
06:57:14 <eivuokko> Fast runtime is a problem with every compiler implementing a general purpose language, I'd say.
06:57:25 <eivuokko> Some user always finds a thing that's "too slow".
06:57:46 <cm> eivuokko: i think it's harder to get it fast without strict evaluation, but then i've not implemented a haskell compiler yet
06:57:56 <eivuokko> Oh, yes.  There's no point comparing compile times of g++ and msvc :)
06:58:05 <eivuokko> *for
06:58:22 <Maddas> I think that the difficulty of making a compiler that generates "fast code" varies strongly across languages.
06:58:34 <childe> Anyway, do you think it's a good idea to make a Haskell shell?
06:58:49 <Lunar^> Maddas: and across code types
06:58:52 <cm> Maddas: yeah indeed
06:59:12 <Philippa> childe: 'sworth a shot. Won't be as quick as eg bash, but that's not the point
06:59:49 <blackdog_> THere's already a Clean shell, I think. "Esther", I believe.
07:00:19 <childe> blackdog_: Does that "Esther" use Haskell as it's language?
07:00:34 <blackdog_> Nope, Clean. The other lazy FPL. :)
07:00:50 <blackdog_> but last time i checked, htey were close enough that the Clean compiler can accept code in Haskell syntax.
07:01:02 <andersca> hmm, what's the identity monad called?
07:01:59 <Philippa> if you mean the implementation in Control.Monad.Identity, it's called, uh, Identity
07:02:03 <blackdog_> oh, and Olin "lock-and-load" Shivers wrote a scheme shell.
07:02:07 <childe> blackdog_: Thank you. I've found their web site
07:02:31 <Philippa> would've thought a lisp-like shell's pretty easy to do?
07:02:50 <blackdog_> in a sense, it's just a REPL.
07:02:53 <childe> Philippa: I don't think a shell full of ()s will be easy to use
07:03:11 <blackdog_> you could use ghci as a shell... some syntactic sugar would probably be nice, though.
07:03:45 <Philippa> childe: didn't say it would :-)
07:03:50 <childe> One of the major reasons make me like Haskell is that I don't need to write too many ()s
07:03:55 <blackdog_> I think most of the FPL shells are inteded more as shell scripting rather than as an interactive shell.
07:04:04 <Philippa> though if you add an equivalent of the layout rule with parens it could work well
07:04:14 <childe> Although I need to write a few []s.
07:04:23 <cm> Philippa: and there is an SRFI for i-expressions
07:04:42 <Philippa> SRFI?
07:04:56 <cm> Scheme Request for Implementation
07:04:59 <cm> http://srfi.schemers.org/
07:05:10 <Philippa> ah. Guess who doesn't scheme :-)
07:05:24 <Maddas> I guess jagular.
07:05:38 <cm> Philippa: http://srfi.schemers.org/srfi-49/srfi-49.txt
07:06:24 <childe> Maybe in the future someone will even make an OS in Haskell :-)
07:06:34 <Maddas> l0p
07:06:35 <eivuokko> h0p ;)
07:06:38 <Maddas> err, h0p.
07:06:39 <childe> The ITS for the 21st century
07:06:50 <childe> Hopes
07:06:56 <Maddas> No, h0p.
07:07:01 <Maddas> The OS is called h0p.
07:07:02 <childe> Or, a better name, Hip-Hop.
07:07:13 <Marvin--> I thought it was hOp?
07:07:21 <childe> Hip-Hop would be a really cool name.
07:07:21 <Maddas> hOp, yes, sorry.
07:07:30 <Maddas> That's why google didn't yield any results besides IRC logs :-)
07:07:38 * Philippa will play with that as soon as somebody explains an easyish way to build it from win32...
07:07:49 <Maddas> childe: http://www.macs.hw.ac.uk/~sebc/hOp/
07:07:58 <eivuokko> Philippa, should that be possible?
07:08:04 * eivuokko wants too
07:08:29 <eivuokko> Actually.  Hmmm.  Why not.
07:08:35 <childe> Maybe Google just Data Mining IRC logs.
07:10:41 <childe> I think hOp is a kernel mode Haskell interpreter.
07:11:08 <childe> Not a kernel mostly written in Haskell
07:14:02 <Philippa> yeah, that's why you need the linux kernel code handy to build it
07:14:25 <Philippa> oh, wait...
07:14:27 <Marvin--> childe: sure, but it's still pretty nifty :)
07:14:59 <childe> Yes.
07:15:24 <Philippa> I do like the idea of all the apps sitting within a bigger GCed system, which hOp kinda suggests
07:15:26 <childe> I've always think about rapid prototyping in kernel development.
07:16:03 <childe> Too bad they have implemented this idea before me
07:16:06 <childe> Bastard
07:16:10 <Marvin--> heh
07:16:40 <childe> They may got a Turing Award for that.
07:17:29 <childe> OK, go to sleep. Have a nice day. Bye.
07:19:31 * Philippa loves the way so many win32 compression utils handle tar.gz but not single gzipped files
07:20:36 <Marvin--> er, that's odd
07:21:27 <Marvin--> ISTR winzip spouting something like "This archive contains only a single file" and asking where you wanted to unpack it
07:22:15 <Philippa> the version I've got tries to add it to an archive
07:22:47 <Marvin--> evil
07:37:44 <Lunar^> mhh
07:38:08 <Lunar^> I'm quite afraid with how the Haskell community is believing in Hop
07:38:27 <Lunar^> (FYI, I'm currently working on making a new source release)
07:39:19 <blackdog_> i don't mean to ask dumb questions, but what's the motivation for Hop?
07:41:40 <Lukhas> improve your personal Haskell skills, understanding how things work
07:41:49 <Lukhas> that's a good start point for many projects
07:42:14 * Marvin-- wanders off to improve his coffee drinking skills
07:42:37 <Lukhas> Marvin--: use a French Press, roast your beans yourself ...
07:44:07 <blackdog_> Sure. I'm just wondering what it's meant to provide that's superior to other approaches. no-one sets out to write something that's worse than the status quo... I'm just wondering what leverage (ugh, horrible word) having the OS in Haskell gives you.
07:44:32 <Lunar^> blackdog_: sebc and I are deeply convinced that there can't be an innovative operating system without an innovative language underneath
07:45:04 <Lunar^> blackdog_: Haskell at kernel level means typechecked kernel code, easy to proove
07:45:22 <Marvin--> note to self: it might've been a good idea to start thinking about whether to have slides - and if so, how to make them - somewhat earlier than two days before the presentation
07:45:24 * Marvin-- sighs
07:45:37 <Lunar^> Marvin--: which presentation ?
07:45:55 <Marvin--> Lunar^: for my degree project
07:45:56 <blackdog_> easy to prove some properties... time propoerties are much trickier, especially if you have to worry about machine level issues like caches
07:46:29 <Marvin--> right now, I'm trying to be a device that turns coffee into a presentation
07:46:40 <Lunar^> Marvin--: lol
07:47:05 <Lukhas> hehe
07:47:37 <Lunar^> blackdog_: Sure. But anyway, there not has been many kernel done in high-level language
07:47:41 <blackdog_> Lunar^: i don't mean to be negative. i just want to know if you've got any concrete ideas about possible applications.
07:47:49 <Marvin--> Does anybody have any experience with using prosper?
07:48:14 <blackdog_> Lunar^: you hear good things about the lisp machines, but i haven't met anyone who's used one firsthand...
07:48:48 <Lunar^> blackdog_: I would be glad to have an OS running an application webserver
07:49:00 <Lunar^> blackdog_: hOp + HWS +HAIFA + HaskellDB
07:49:48 <Lunar^> blackdog_: Galois Connection people are interested by hOp, also. I don't know what exactly they have in mind, by I think the proof aspect interest their clients
07:49:53 <blackdog_> forgive me, i'm not much of an OS guy. WHat does having hOp at the bottom of that pile rather than a unix give you?
07:50:24 <Lunar^> blackdog_: The reason to say "Haskell rocks" ;)
07:50:33 <blackdog_> Lunar^: that's a point. You could get safeness properties at least.
07:51:12 <blackdog_> sh, we're trying to maintain the facade that we use Haskell out of sober engineering reason. we can't let it get out that it's fun, people will stop paying us for it. :)
07:51:25 <Lunar^> lol
07:52:10 <blackdog_> So how big's the kernel itself? what sort of design?
07:52:12 <Lunar^> To be honest, I really think the way OS are built are deeply influenced by the languaged used
07:52:27 <Lunar^> There's not much design by now unfortunately
07:53:36 <blackdog_> yeah, i'll buy that. I'm falling into the habit of writing very strange C these days - i prototype in haskell, then try to translate as faithfully as i can. lots of function pointers. :)
07:53:46 <Lunar^> It's just the GHC RTS hacked to run without an underlying OS and a simple interrupt handling model
07:54:06 <Lunar^> But it's enough to start writing device drivers
07:55:03 <blackdog_> hm. that's ... interesting. i was about to ask about kernel/userland divides, but i guess if you're only accepting source code rather than arbitrary binaries you've already got a pretty strong safety guarantee.
07:55:12 <Lunar^> The keyboard driver is currently very naive, but it wouldn't be hard to compile the keymap to a DFA, as an example
07:55:29 <Lunar^> blackdog_: Currently, there's no security at all
07:56:05 <blackdog_> although.. actually, what am i talking about, there's still IO () and the FFI. maybe not that safe. :)
07:56:36 <blackdog_> could it be put in later without significant rewriting?
07:57:00 <Lunar^> blackdog_: good point. I have papers from EROS waiting...
07:57:12 <blackdog_> one of the big things a lot of people at my uni are working on at the moment is userland device drivers. nobody wants to stay in the kernel.
07:57:37 <Lunar^> blackdog_: There's also this one, which seems relevant http://citeseer.ist.psu.edu/rees96security.html
07:58:00 <Lunar^> blackdog_: the RTS is actually our micro-kernel
07:58:43 <Lunar^> blackdog_: and with the current design, each drivers has its on thread, communicating with others by Chan
07:59:11 <blackdog_> hm, htat looks interesting (at least from the abstract). a more decentralised approach to security, i guess?
07:59:35 <blackdog_> one of my big beefs with the unix security model is that it's very hard to delegate trust.
07:59:46 <Lunar^> blackdog_: I think so. Buffer overflow attacks are really unlikely with a copying garbage collector anyway :)
08:00:15 <blackdog_> security-by-"where the hell is that buffer now anyway", hm? :)
08:00:42 <Lunar^> blackdog_: EROS capability based security model seems a really good way to delgate trust
08:01:16 <Lunar^> blackdog_: Aside from StablePtr, yes
08:01:53 <blackdog_> EROS vaguely rings a bell, but it's been a while...
08:09:46 <blackdog_> on another topic entirely, pizza rocks. i didn't think it could happen, but i'm actually enjoying programming in javaland.
08:11:18 <Lunar^> hehe
08:14:38 <blackdog_> just needs some FPL-oriented libraries. a parser combinator library, for instance...
08:15:29 <blackdog_> ugh, way past my bedtime. g'night all
09:22:10 <tyl3r> anyone knows which type system is using C++ ?
09:22:50 <Smerdyakov> What?
09:25:05 <bluejay> do you mean, "what type system is C++ using"?
09:25:33 <bluejay> I have no idea; I don't think they designed it that way
09:27:25 <vegai> the C++ type system =P
09:27:30 <eivuokko> As far as I know, C++ type system has just grown "as needed" fashion, not leaning too much on theories.  Hence only true source for understanding it is reading the C++ standard.
09:38:19 <tyl3r> ok, funny
09:40:11 <eivuokko> How come?  And why are you asking here, anyway? :)
09:43:16 <tyl3r> do you know a channel specialized in type systems ? :>
09:44:02 <eivuokko> I guess that's a point.
10:02:06 <SamB> C++ uses a weak static type system, doesn't it?
10:02:41 <Smerdyakov> I'm not aware of any issues with the C++ type system that are not clear to anyone who can write C++ programs.
10:06:12 <Hyp3rion> SamB, "weak"?
10:06:40 <Maddas> Hyp3rion: As opposed to a strong type system
10:06:43 <Maddas> (Probably not much help)
10:07:00 <Hyp3rion> But whaddaya mean by weak and strong type systems?
10:07:26 <Smerdyakov> You are not forced to follow it.
10:07:35 <Hyp3rion> Oh.
10:07:42 <Hyp3rion> C?
10:07:45 <eivuokko> Huh?
10:08:17 <SamB> Hyp3rion: you can do whatever you want with memory in C++!
10:08:52 <Hyp3rion> Oh really.
10:09:03 <SamB> C too, of course, but everyone already knew that ;-)
10:09:11 <SamB> well, if they know C, they must
10:09:35 <eivuokko> Typically well written C++ programs do not use "weak" typing.  And compilers usually help on that almost as much as f.ex. Haskell.
10:09:40 * SamB remembers he is lagged
10:11:59 <SamB> well, yeah. but the type system is weak, all the same.
10:12:32 <Hyp3rion> C type system kinda resembles native machine types...
10:13:00 <SamB> Hyp3rion: you know, there is a good reason for that!
10:13:50 <SamB> I have said it before, and I will say it again: C is just portable ASM
10:14:11 <Hyp3rion> Well yeah
10:14:18 <cm> portable?
10:14:19 <cm> :)
10:14:21 <eivuokko> Quite lacking at it, too.
10:14:36 <Hyp3rion> No C is good
10:14:47 <SamB> cm: compared to native ASM, yes!
10:15:02 <Hyp3rion> Better than all other "portable ASM"s at least...
10:15:42 <vegai> wasn't someone here working on a strongly typed ASM or something to that effect?
10:15:52 <SamB> eivuokko: what area do you find it lacking in?
10:16:05 <eivuokko> Carry flags, floating point operations.
10:16:29 * Maddas looks at Smerdyakov 
10:16:31 <eivuokko> The common stuff people bitch about not included in C.
10:16:56 <SamB> vegai: I'm not sure that is even a good idea. But I won't comment until someone tries to talk me into it.
10:17:04 <Smerdyakov> vegai, yes
10:17:06 <Riastradh> Hyp3rion, uh, what about C--?
10:17:12 <Hyp3rion> C--?
10:17:17 <Smerdyakov> SamB, what? It's a great idea.
10:17:18 <Riastradh> http://www.cminusminus.org/
10:17:23 <Hyp3rion> :-D
10:17:28 <SamB> eivuokko: well, carry flags are not exactly consistant between arches
10:17:41 <eivuokko> vegai, do you mean the same one someone thought incorporating into gcc?  Fxx whatever?
10:17:46 <SamB> Smerdyakov: are you volunteering to attempt to talk me into it?
10:17:56 <Smerdyakov> SamB, if you so desire.
10:18:07 <eivuokko> SamB, Yes, does that mean operations using them couldn't be portably expressed?  Dunno...
10:18:16 <SamB> Riastradh: how widely ported is C--?
10:18:24 <SamB> it may not be ready yet
10:18:33 <eivuokko> SamB, Happily I don't code C nor so lowlevel stuff almost ever :)
10:18:36 <Riastradh> I dunno.  I haven't kept up with it in the past six months, due to its prior lack of readiness.
10:19:06 <Smerdyakov> I think C-- and Typed Assembly Language have very different purposes.
10:19:28 <Smerdyakov> C-- is meant to be compiled, while TAL is not. It's already approximately the final machine code, expressed in a more convenient form.
10:19:32 * Hyp3rion tought C-- was a joke like C+-...
10:19:48 <Riastradh> Hyp3rion, no, it's a serious portable assembly language.
10:19:57 <Smerdyakov> And, of course, each individual TAL is far from portable.
10:19:58 <SamB> eivuokko: I don't know, but not including them at all is better than including them in a nonportable fashion ;-)
10:20:12 <eivuokko> That depends.
10:22:22 <SamB> Smerdyakov: I don't think there is much point to a typed assembly language without a typed portable assembly language...
10:23:13 <Smerdyakov> SamB, why not? You don't want to know that programs that you run are memory safe?
10:25:05 <SamB> Smerdyakov: well, if other people want to write code in it, fine. but why would I want to write in that?
10:25:42 <Riastradh> You could use it to check that the code your compiler generated was valid, I presume...
10:27:22 <SamB> Riastradh: only if your compiler generates nativish assembler...
10:27:27 <Smerdyakov> SamB, I don't understand. Do you write code in assembly now? Do view the value of an assembly language as being related to how easy it is for you to write programs directly in it?
10:28:51 <SamB> Smerdyakov: not programs. well, maybe I tried to do a tiny true.
10:29:27 <Smerdyakov> SamB, so then why did you say "but why would I want to write in that?"?
10:30:23 <SamB> these days, ASM typically gets used for a few routines in a C program, right?
10:31:44 <Smerdyakov> No.
10:31:55 <Smerdyakov> These days, assembly is generated by compilers as their final output.
10:32:18 <Philippa> small shreds of OS code, getting at CPU-specific features that can't be efficiently represented in C or C++
10:32:31 <Philippa> it's still quite common to see asm for SIMD code
10:33:10 <SamB> Smerdyakov: well, yes. but compilers don't have human failings ;-)
10:33:42 <Smerdyakov> SamB, how is that relevant?
10:34:02 <Smerdyakov> SamB, no one is proposing TAL as a language to be written by humans.
10:35:11 <SamB> Smerdyakov: ok.
10:36:41 <SamB> well, why would anyone want to target TAL before PTAL?
10:38:39 <SamB> and what good is it if your speed critical routines are still written in plain old C or ASM?
10:39:04 <Smerdyakov> What is PTAL?
10:39:15 <SamB> Portable Typed Assembly Language.
10:39:17 <cm> portable ..
10:39:26 <eivuokko> Validation, optimisations.
10:39:29 <Smerdyakov> A portable TAL is still a TAL.
10:39:46 <Smerdyakov> And you can write speed-critical routines in a native TAL just fine.
10:40:00 <SamB> Smerdyakov: you said "no one is proposing TAL as a language to be written by humans."!
10:40:53 <Smerdyakov> It's not the main purpose. Typically inline assembly is small enough that the benefits of typechecking are irrelevant. However, it is perfectly possible to use a TAL.
10:43:11 <SamB> Smerdyakov: what are you proposing to inline this assembly in?
10:45:42 <SamB> and, how do you inline assembly written in a different assembly language amongst the PAL?
10:45:46 <Smerdyakov> Wherever you feel the need. I don't really support inline assembly much, though.
10:45:48 <SamB> err, TAL.
10:46:16 <Smerdyakov> If the final output is TAL, then most likely you will not be permitted to mix untyped code of any kind.
10:47:19 <SamB> is this supposed to involve a whole new OS at some point?
10:48:11 <Smerdyakov> That would be nice, but not necessary.
10:49:09 <SamB> than what do you do at the kernelspace/userspace boundary?
10:49:25 <SamB> s/than/then/
10:52:17 <Smerdyakov> Use whatever assurance mechanism the user requires.
10:56:11 <SamB> and why are we going to all the work of targetting a compiler at this again?
10:57:58 <Smerdyakov> So you can verify that the programs you write and run are memory safe.
10:59:19 <ozone> SamB: TAL is also the basis for much proof-carrying code research, which is a pretty nice idea
10:59:42 <Smerdyakov> ozone, that is really a subset of what I just said. :-)
11:00:06 <ozone> Smerdyakov: sure, but i said it explicitly.  nyer :D
11:00:10 <SamB> I still don't see good reason to expect people to use it without a good PTAL.
11:00:37 <SamB> s/see/see a/
11:01:00 <Riastradh> SamB, say...for the C-- compiler to emit, perhaps.
11:01:08 <ozone> well, depends what you mean by PTAL
11:01:09 <SamB> I think we might need a bit more D with that R.
11:01:20 <ozone> java bytecode is targeted for one thing only, after all: JVM
11:01:28 <ozone> but i think i'd classify that as portable. :)
11:01:49 <ozone> ditto for .NET IL, which is actually TAL
11:01:52 <SamB> Riastradh: if C-- is not a PTAL, than it couldn't be expected to magically transform code into TAL, could it?
11:02:07 <Smerdyakov> SamB, if you're going to run native machine code programs, why don't you think it is good to verify that they won't crash?
11:02:16 <Lukhas> ah, glad to see Riastradh trolling here too :)
11:02:37 <vegai> perhaps he is worried that all that stuff hurts run-time performance?
11:02:37 <Smerdyakov> ozone, I take offense to calling JVM or MSIL assembly languages. They're too high level. :P
11:02:56 <ozone> Smerdyakov: i take it you're a big parrot supporter then, too ;)
11:03:17 <Smerdyakov> ozone, I don't know enough about Parrot to determine whether that was sarcasm.
11:03:17 <ozone> Smerdyakov: well, s/assembly/bytecode/, and all is well
11:03:24 <SamB> Smerdyakov: I just think that it is a waste of time to be targetting a bunch of TALs just because there isn't a PTAL.
11:03:37 <Smerdyakov> SamB, so you think no one should run native code programs?
11:04:09 <SamB> Smerdyakov: no. I just think that many-to-many is a bad architecture ;-)
11:04:24 <Riastradh> SamB, did you say previously that you preferred the idea of compilers emitting various assembly languages or that you preferred having one PAL such as C--?
11:04:35 <ozone> SamB: i think the point is moot anyway ... i don't know of any TALs which aren't P
11:04:38 <SamB> at least, not optimal for beginnings
11:05:30 <SamB> ozone: Smerdyakov should have said so right away, than.
11:05:41 <ozone> Smerdyakov may know otherwise, though
11:06:04 <ozone> (and at any rate, i think his point still stands)
11:06:19 <Smerdyakov> SamB, I think you are missing the point.
11:06:26 <ozone> ja, agreed
11:06:27 <Smerdyakov> SamB, it is trivial to have a portable TAL.
11:06:37 <Smerdyakov> SamB, you choose which machine language you want to use.
11:06:44 <Smerdyakov> SamB, I can give you a TAL that runs over it.
11:06:55 <ozone> but it's 4am here, so i think i might go to bed about now
11:06:56 <Smerdyakov> SamB, "machine language" includes "bytecode" languages.
11:07:10 <SamB> Smerdyakov: why didn't you say so earlier, than!
11:07:19 <Smerdyakov> SamB, why didn't _you_ say so earlier.
11:07:53 <Smerdyakov> SamB, it is ridiculous if you thought there was an idea that worked on real, complex architectures but not on simplified virtual machines designed to be portable.
11:08:07 <ne1> This exchange reminds me of the following. There are people who consider C high-level, and there are people who don't.
11:10:47 <Smerdyakov> ne1, and there generally isn't much ground for debate, since these people also don't agree on what "high level" means
11:11:13 <SamB> Smerdyakov: you should have told me my premises were wrong! you can't have missed that I was arguing that TAL without PTAL was silly!
11:14:18 <Smerdyakov> SamB, I saw that as an orthogonal issue, and I didn't know that you didn't realize that.
11:14:19 <SamB> okay. I withdraw my case because it was totally unneccesary and everything that I thought was silly was not in fact being attempted.
11:15:52 <jadrian> hello
11:17:16 <Smerdyakov> And despite the fact that the issue is orthogonal, I still disagree with you about it. :P
11:18:15 <jadrian> what's the syntax for exporting instances on modules
11:18:34 <jadrian> module MyInstances(?) where
11:19:30 <jadrian> for functions and value constr. you just have to add them to the (?)
11:20:46 <jadrian> wait
11:20:55 <jadrian> I downloaded the report!
11:20:59 <jadrian> brb
11:21:01 <jesse> MyInstances(function,type(constructors)) i think
11:21:49 <jadrian> never mind
11:21:53 <jadrian> they are always exported
11:22:06 <jadrian> jesse: I meant instance declarations, that I know ;)
11:22:24 <jesse> oh pfft, sorry
11:22:34 <jadrian> but thanks!
11:24:04 <jesse> all of this conflicting terminology floating around in my head, oop vs haskell ad hoc polymorphism
11:24:13 <SamB> oh, does TAL support parametric polymorphism and type classes?
11:24:37 <jadrian> what's TAL ?
11:25:29 <SamB> jadrian: any Typed Assembly Language
11:25:49 <jadrian> SamB: hmm never heard of it
11:28:04 <SamB> jadrian: I've heard of such things but not really looked closely at them.
11:28:18 <ne1> http://www.cs.cornell.edu/talc/  <---  hahaha
11:28:49 <jadrian> lol
11:29:58 <Smerdyakov> SamB, yes, it does.
11:30:40 <Smerdyakov> ne1, why is it funny?
11:31:06 <ne1> The logo and slogan at the end.
11:31:32 <SamB> Smerdyakov: "Types inside"? "What do you want to type check today?"
11:33:22 <SamB> hmm, Popcorn sounds like a PTAL to me.
11:34:36 <Smerdyakov> It's not an assembly language....
11:36:04 <SamB> Smerdyakov: it said C-like!
11:36:22 <ne1> There we go again.
11:37:14 <ne1> Perhaps we should first debate on whether it type-checks. What is type checking? How much type checking is needed to qualify as type checking?
11:39:25 <SamB> nel: well, apparantly it can guarentee memory safety, so no SIGSEGVs.
11:40:25 <SamB> nel: to do that without being horribly restrictive (and therefore not qualifying as an assembler) would take a lot, don't you think?
11:42:20 <Smerdyakov> Popcorn guarantees no segfaults.
11:42:34 <Marvin--> mm, popcorn
11:44:11 <SamB> Smerdyakov: well, in an informal sense, yes. in a formal sense, a segfault would occur whenever a page needed to be swapped back in ;-)
11:44:43 <SamB> er. no.
11:45:09 <SamB> I just remembered thats a pagefault...
11:45:16 * SamB hides under a rock
11:47:25 <SamB> hmm, why is a pagefault not bad but a segfault bad?
11:49:07 <Lukhas> a segfault is bad for your program, it just dies. A pagefault just takes some time to be unfaulted, iirc.
11:49:38 <SamB> Lukhas: unless the kernel has a problem with its swapspace, yeah ;-)
11:49:45 <Lukhas> SamB: hehe, yeah
11:50:11 <Lukhas> then it starts to trash the disk, which renders the computer kinda unusable until it's done.
11:50:56 <SamB> Lukhas: well, I was thinking more along the lines of what might happen if you used networked swap
11:51:23 <ne1> There are people --- prankers and virus writers --- who demand some language, say machine language, to be capable of crashing a computer, and that is only because their sole purpose of life is to crash people's computers.
11:51:24 <Lukhas> just tell your employees not to walk on cables :)
11:51:29 <ne1> I am not one of them.
11:53:08 * jadrian crashed his computer using haskell once...
11:53:33 <Lukhas> wow
11:53:34 <jadrian> and all it took was a space leak...
11:53:44 <jadrian> kernel 2.2 back then...
12:01:35 <SamB> for some reason, I do not think many BF compilers will target TALs
12:03:06 <SamB> even though I don't think I've seen shootfoot written in BF. (of course, it is dead easy ;-)
12:16:45 <Smerdyakov> Is BF not memory safe?
12:18:01 <SamB> Smerdyakov: it would take a lot more work to make it so, either from the CPU or from the compiler
12:20:42 <gintas> does Haskell have the XOR operator?
12:21:47 <Smerdyakov> It's pretty trivial to make Brainfuck memory safe if you check pointer bounds for each dereference.
12:22:19 <SamB> Smerdyakov: seeing as most of the work is dereferences...
12:24:08 <Cale> gintas: What sort of xor operator?
12:26:30 <gintas> Cale: never mind
12:26:39 <gintas> I thought that xor would be defined in Prelude
12:28:13 <ne1> It is not in standard Haskell (Haskell 98).
12:28:22 <ne1> But ghc has it.
12:30:08 <SamB> gintas: you want bitwise or logical? I guess bitwise...
12:30:11 <Cale> well, at least, there's a bitwise xor in Data.Bits
12:30:21 <Cale> (that's why I asked what kind)
12:31:49 <SamB> and of course, logical is quite easy to do ;-)
12:32:02 <Cale> True %% x  = not x
12:32:02 <Cale> False %% x = x
12:32:26 <SamB> Cale: not explicit enough ;-)
12:34:02 <Cale> Or of course, you could write  x %% y  = if x then not y else y
12:34:22 <SamB> Cale: hehe.
12:34:24 <Cale> and numerous other ways
12:35:50 <Cale> x %% y  = (x || y) && not (x && y)
12:35:58 <gintas> well, I wrote xor a b    = (not a && b) || (a && not b)
12:36:34 <Cale> i.e. (x or y) and not both :)
12:44:26 <Cale> %% is actually a pretty good symbol for xor, given what the truth table looks like :)
13:29:50 <tea> good morning, room 
13:30:37 <tea> I got an error while compile ghc-6.2.1, anyone can help me
13:32:07 <tea> the error messages are : types/Type.lhs:82: Module `DataCon' (hi-boot interface) does not export `dataConInstOrigArgTys'
13:36:44 <tea> the environment is debian(woody), the version of /usr/bin/ghc is 5.02.2. I dont know if there are program required
13:48:05 <Igloo> That doesn't rung a bell
13:48:13 <Igloo> You should be able to get stable debs frmo http://www.syntaxpolice.org/haskell-experimental/haskell-experimental.html though
13:52:16 <tea> Igloo: oh there was the deb. thank u infomation. I will try it now
14:00:53 <jadrian> Cale, gintas: /=  ;)
14:01:15 <jadrian> Cale, gintas: most programing languages do have the Xor operator and it is simply   /=  
14:01:23 <Cale> heh - that's a decent option :)
14:01:35 <jadrian> just like == is <=>
14:01:45 <jadrian> ;)
14:03:41 <Cale> That's a really good point - almost makes me wonder why they ever bother to define it separately.
14:04:29 <jadrian> yeap...
14:04:45 <jadrian> but do they?
14:04:53 <jadrian> is there an Xor in C for instance?
14:05:02 <Cale> yes, I'm fairly sure there is
14:05:12 <Lukhas> yeah, there's one
14:05:16 <jadrian> I don't mean the bitwise one
14:05:36 <jadrian> what is it?
14:05:40 <Lukhas> it's ^, iirc
14:05:49 <jadrian> hmm let me check
14:05:52 <Cale> ^^ ?
14:05:57 <jadrian> oh yeah
14:06:11 <jadrian> but in C  != wouldn't work obviousliy :)
14:06:14 <jadrian> eh
14:06:26 <Cale> ah, right, there's no bool type in C
14:06:28 <Smerdyakov> But !!a != !!b would.
14:06:37 <jadrian> lol
14:06:38 <Smerdyakov> (For logical a xor b)
14:06:44 <jadrian> yeap :)
14:06:48 <Lukhas> thanks god, there's no Bool in C
14:06:48 <Cale> or just !a != !b
14:06:53 <Lukhas> but in C99, there is one
14:07:09 <Smerdyakov> Lukhas, why "thanks god"?
14:07:46 <Lukhas> because C lived well without Bool type, for the last 25 years
14:07:59 <Cale> that doesn't mean that it's good that it doesn't have it
14:08:03 <Lukhas> and in C, i don't like the new Bool type
14:08:16 <jadrian> C lived well without lots of stuff
14:08:33 <Cale> It's nice to know when something is intended as a boolean value.
14:08:40 <jadrian> what is your favourite imperative/procedural language by the way?
14:09:15 <SamB> C is assembly!
14:09:25 <eivuokko> Asked on this channel, that seems either troll or a trick question ;)
14:09:34 <Cale> For imperative programming, mine is probably python. I also like ruby.
14:09:46 <SamB> jadrian: Python.
14:09:49 <Lukhas> python, C
14:10:01 <SamB> well, C goes with python ;-)
14:10:15 <jadrian> I've thought about pyhton but it's not strong typed :-/
14:10:28 <jadrian> I'd like something like Pascal but with Haskellish classes...
14:10:45 <SamB> jadrian: no, it isn't. well, probably isn't.
14:10:46 <jadrian> I thought about looking at Modula2/Oberon
14:11:05 <jadrian> but I thing their kind of dead
14:11:22 <Cale> Are there any strongly typed imperative languages with type inference?
14:11:26 <jadrian> s/thing/think
14:11:28 <SamB> oberon runs, doesn't it?
14:11:51 <jadrian> SamB: even if it does, I'd like something beeing activly developed...
14:12:08 <SamB> didn't that have a gui even?
14:12:14 <jadrian> good compiler, libraries, documentation, etc
14:12:28 <Cale> I also like Haskell's IO monad for imperative programming.
14:12:33 <jadrian> it even had a whole Operative System 
14:12:50 <SamB> jadrian: why do you use the past tense?
14:13:20 <jadrian> SamB: Ok, there probably is an Oberon Operative system out there :)
14:14:08 <jadrian> Cale: until you need to mix lots of monads, and then you got Monad Transformers Hell :-/
14:14:25 <SamB> jadrian: the first hit on google mentions bare hardware, even!
14:14:30 <jadrian> wow
14:14:46 <Cale> jadrian: yes, that needs to be solved somehow
14:15:30 <jadrian> I like haskell, but sometimes I'd really like to use imperative languages...
14:16:25 <jadrian> I'd be happy with Pascal + Haskell classes...
14:16:32 <Smerdyakov> :O
14:16:38 <Smerdyakov> You'd be happy without closures?
14:17:06 <jadrian> ok
14:17:10 <jadrian> I take it back...
14:17:15 <jadrian> :P
14:18:08 <jadrian> I was trying not to make it OOP
14:18:20 <jadrian> how can I have closures without OOP
14:19:07 <jadrian> I'd like to avoid the OOPish classes
14:19:17 <Cale> I think O'Haskell / Timber looks pretty neat.
14:19:31 <jadrian> is it still under development?
14:19:40 <SamB> jadrian: CL without the the object stuff? I think the object stuff is in a library anyway.
14:20:04 <jadrian> SamB: CL = common lisp?
14:20:12 <SamB> jadrian: what else?
14:20:14 <Smerdyakov> jadrian, "how can I have closures without OOP" ... this describes most FP languages....
14:20:34 <SamB> Smerdyakov: he is talking about imperative languages, though
14:20:41 <jadrian> Smerdyakov: yes but I was thinking about imperative languages ;)
14:20:55 <Smerdyakov> jadrian, I think it's fair to consider Standard ML an imperative language that fits the bill.
14:20:57 <Cale> I think Timber is still being worked on - at least, I haven't seen anything to the contrary.
14:21:40 <jadrian> Smerdyakov: the idea was, get Pascal, add haskellish classes (seems to me like they fit really well), now how to get closures?
14:21:43 <jadrian> Smerdyakov: maybe
14:22:40 <jadrian> (phone brb)
14:23:34 <Cale> Well, it shouldn't be too hard to have something like Haskell with Pascal embdedded as a monad.
14:24:08 <Cale> the parsing might be a bit funky though :)
14:25:41 <Cale> not to mention type conversion between the two
14:25:51 <Cale> :)
14:27:55 <Cale> but basically, for a little extra gluing work, you can pair up most any language with Haskell using ffi.
14:32:30 <gintas> how is Int different from Integer and Num?
14:32:45 <Cale> Int is 32 bits
14:32:51 <gintas> I suppose Int is fixed precision, Integer is arbitrary precision?
14:32:52 <Cale> Integer is of arbitrary size
14:32:58 <gintas> and Num includes floats too?
14:33:02 <Cale> Num is a general class of numeric types
14:33:06 <Cale> yes
14:33:13 <gintas> heh
14:33:24 <SamB> Num is not a type
14:33:35 <Cale> anything where +,*, negate and a couple other things are defined belongs to Num
14:33:45 <gintas> ok
14:34:28 <gintas> how do I stop Haskell from complaining about Integers instead of Int's?
14:34:44 <Cale> use fromIntegral
14:35:26 <jadrian> gintas: you should give us more details though
14:35:27 <Cale> that lifts the type context of an integral type (Int, Integer) to a general numeric type
14:36:12 <jadrian> that would sovlve it, but maybe he's just using Integers when Ints would be more appropriate...
14:36:25 <Cale> that's true
14:36:46 <gintas> well, point is when I use a list predefined in a program, I get a type error
14:36:53 <gintas> if I just paste the list in, all works fine
14:37:02 <gintas> (I'm working in hugs)
14:37:54 <Cale> this is with length, or something?
14:37:56 <jadrian> what are you doing to that list in your program=
14:37:57 <jadrian> ?
14:38:21 <gintas> I'm passing it to a function that is declared to expect [Int]
14:38:34 <jadrian> and how do you define the list?
14:38:44 <Cale> Why are the definitions for the generic* functions not the ones used in the prelude?
14:39:07 <jadrian> Cale: there was some discussion about it in the mailing list some time ago
14:39:09 <Cale> (i.e. genericLength etc. in List)
14:39:18 <jadrian> Cale: making Integer the default
14:39:29 <wolfman8k> i've been reading some tutorials and stuff but i still don't get it
14:39:33 <Cale> You don't even need to make Integer the default
14:39:37 <gintas> well, I don't define the list
14:39:44 <gintas> it appears that Integer is already the default
14:39:54 <Cale> just make length :: Integral a => [b] -> a
14:40:16 <SamB> Cale: you forgot the specialize pragma
14:40:31 <gintas> btw, what's Integral
14:40:35 <gintas> I'm a bit lost here :)
14:40:40 <Cale> Integral is another class of types
14:40:43 <jadrian> Integral is also a type Class
14:41:01 <jadrian> wich includes both Integers and Ints
14:41:13 <gintas> ah
14:41:49 <gintas> so I suppose that when I write functions for integer numbers, I should use the Integral type to avoid type problems, right?
14:42:45 <Cale> you could
14:44:12 <Cale> in general, you can make things fairly generic - often you might only need Ord or Enum
14:44:25 <gintas> well, now I put 'Int' everywhere, which is now causing some problems as you can see
14:44:54 <gintas> s/put/have put/
14:45:14 <jadrian> gintas: my guess is that you could actually stick with Int for most stuff, and just use Integer when you know numbers will be big
14:45:23 <gintas> can I get a overview of these type classes?
14:45:25 <Cale> how is this list defined? to re-ask jadrian's question
14:45:40 <gintas> jadrian: I think it's a good idea to define things as generically as possible
14:45:42 <jadrian> gintas: If you're starting with haskell that's probably a sensible approach
14:45:50 <jadrian> gintas: yes it is ;)
14:45:51 <Cale> gintas: sure - section 6 of the report
14:46:38 <gintas> Cale: thanks, that was very useful
14:46:45 <Cale> http://www.haskell.org/onlinereport/basic.html
14:47:20 <Cale> there's a nice diagram there that has them
14:47:27 <gintas> I know, I'm looking at it now
14:47:43 <Cale> to see what they actually involve, you'll have to have a look at the prelude
14:47:45 <gintas> I don't see natural numbers mentioned
14:48:01 <Cale> There's no Nat type by default
14:48:23 <Cale> I think this was also a source of argument at some point :)
14:48:45 <jadrian> some days ago I spent quite some time to make an average function with type:
14:48:50 <jadrian> average :: (Real a, Fractional b) => [a] -> b
14:48:50 <gintas> I think it would be nice to have, but then it's rather easy to define
14:49:53 <Smerdyakov> jadrian, you know that's not possible, right?
14:49:59 <jadrian> Smerdyakov: ?
14:50:02 <jadrian> Smerdyakov: I did it...
14:50:26 <jadrian> Smerdyakov: but I think I know what you mean
14:50:27 <Smerdyakov> jadrian, that's weird, because, in the way I understand the type classes, it would let you prove that the average of a list of real numbers is a rational number!
14:50:46 <Cale> class  (Num a, Ord a) => Real a  where
14:50:46 <Cale>     toRational       ::  a -> Rational
14:51:23 <jadrian> Smerdyakov: well there is a realToFrac function
14:51:43 <Smerdyakov> Cale, how awful! :D
14:52:44 <gintas> I suppose you just map realToFrac xs and pass it to average (Haskell, does have `average`, doesn't it?)
14:53:08 <jadrian> Smerdyakov: aren't you confusing Fractional with Rational?
14:53:25 <jadrian> Smerdyakov: Doubles are Fractionals
14:53:39 <Cale> average xs = fromRational $ sum (map toRational xs) / fromIntegral (length xs)
14:53:43 <Smerdyakov> jadrian, I don't know much about the structure of standard Haskell type classes. From the usual meanings of the terms in math, I'd think that a rational number is Fractional.
14:53:54 <Cale> average :: forall a a1. (Real a1, Fractional a) => [a1] -> a
14:53:58 <jadrian> Smerdyakov: I don't like the names either :)
14:54:07 <jadrian> Smerdyakov: but no in haskell they are not the same
14:54:47 <jadrian> Smerdyakov: Rational is a type  (Q in Math)
14:55:17 <jadrian> Smerdyakov: Fractional is a class 
14:55:37 <Maddas> Wow, Smerdyakov used ":D". Cale must have said something really special :-)
14:55:46 <jadrian> class (Num a) => Fractional a where {
14:55:46 <jadrian>     (/) :: a -> a -> a {- has default method -};
14:55:46 <jadrian>     recip :: a -> a {- has default method -};
14:55:46 <jadrian>     fromRational :: Rational -> a;
14:55:46 <jadrian>     }
14:56:20 <jadrian> Cale: I did
14:56:22 <jadrian> average :: (Real a, Fractional b) => [a] -> b
14:56:23 <jadrian> average xs = realToFrac (sum xs) / fromIntegral(length xs)
14:56:32 <gintas> a couple of stupid questions: what does '$' do and what is '=>' used for?
14:56:33 <jadrian> realToFrac simplifies things a little bit
14:56:45 <jadrian> $ is function application
14:57:41 <jadrian> f (g ( h x)  
14:57:55 <jadrian> (f . g . h ) x
14:58:06 <jadrian> f . g . h $ x
14:58:10 <gintas> I know '.'
14:58:26 <jadrian> or maybe better example
14:58:27 <gintas> ah, so it's just syntactic sugar
14:58:34 <jadrian> no 
14:58:39 <jadrian> it's actually a function...
14:59:05 <gintas> well, it just saves a couple parentheses, right?
15:00:43 <jadrian> not really
15:00:55 <jadrian> you can do some cool stuff with it since you can use it as an argument
15:01:05 <gintas> ah
15:01:11 <gintas> that's interesting
15:01:30 <jadrian> map ($4) [f,g,h]
15:01:43 <jadrian> there are better examples
15:02:01 <jadrian> like using ($) with folds
15:02:24 <Hyp3rion> Will GHC work on an Alpha Tsunami?
15:03:19 <gintas> jadrian: OK. And what about =>; is it a Haskell syntax element?
15:03:24 <jadrian> yeap
15:03:40 <jadrian> it is used to separate context from signatures
15:03:48 <jadrian> (or from the rest of the signature)
15:03:51 <gintas> it appears that you write (Num a) => [a] whereas I would write [Num]
15:04:02 <jadrian> (does context counts as signature?)
15:04:35 <gintas> I don't see the point
15:05:21 <jadrian> (Num a, Ord b, Num b) => a -> b -> (a,b)
15:05:23 <gintas> ah, OK, now I see the point
15:05:27 <jadrian> how would you type that
15:05:56 <jadrian> brb
15:07:07 <gintas> (I had thought of a simpler example, (Integer a) => a -> a -> a -> a, where there's no big advantage, but the result is shorter)
15:07:43 <gintas> by the way, what exactly does '(Ord a, Num a) => a' mean?
15:10:55 <jadrian> gintas: a is both an instance of Ord and Num
15:14:32 <gintas> jadrian: in this case it only matters if the type in question is custom, as members of Num defined in prelude are all in Ord too, right?
15:19:00 <gintas> gotta go
15:19:07 <gintas> thanks for your help everybody
15:19:16 <gintas> jadrian: you especially :)
15:19:52 <gintas> I'm sorry about my slightly erratic babbling -- it's 1 AM here and I think I've taken in quite enough Haskell for today...
15:20:32 <Hyp3rion> So anyone knows? Will GHC work on an Alpha Tsunami?
19:39:53 <pimpbot5000> quick latex question: does anyone know how to force latex into taking away italics within \begin{theorem} \end{theorem}
19:42:24 <skew> you can make the text non-italicized manually. I don't know how to change it globally
19:42:50 <pimpbot5000> oh, yea just locally
19:43:00 <pimpbot5000> i tried \textrm{blah}
19:43:08 <pimpbot5000> but that didn't help
19:43:20 <skew> didn't it?
19:43:36 <skew> inside the theorem?
19:43:39 <pimpbot5000> yea im surprised
19:44:36 <pimpbot5000> im using the sig-alternate style
19:44:45 <pimpbot5000> although i doubt that matters
19:46:39 <bluejay> shouldn't that be \mathrm{blah}?
19:46:51 <pimpbot5000> hmm, let me try
19:46:57 <Pseudonym> You might want to us ethe amsthm package.
19:47:10 <Pseudonym> You can change the style with \theoremstyle{}
19:48:16 <Pseudonym> http://www.stat.umn.edu/~charlie/amslatex.html <- take a look
19:48:28 <pimpbot5000> ok cool,
19:48:30 <pimpbot5000> thanks
19:48:34 <Pseudonym> np
20:18:12 <Cale> man, this must be the least trivial Haskell function I've yet written. 39 lines counting all lets and wheres.
20:18:47 <Cale> there's some pattern in it - I should look at figuring out how to factor it.
20:19:47 <stepcut> :p
20:20:17 <Cale> not a whole lot of pattern, mind you
20:21:24 <Cale> just a lot of cases to handle
20:21:36 <Cale> and they're all subtly different
20:21:43 <Cale> in different ways
20:24:43 <desrt> phd comprehensives tomorrow
20:30:47 <Smerdyakov> desrt, which uni?
20:32:25 <desrt> mcmaster
20:33:28 <desrt> not for me :)
20:38:14 <skew> Cale: what does it do?
20:41:20 * shapr yawns
20:41:27 <Pseudonym> G'day shapr.
20:41:36 <shapr> g'mornin Pseudonym 
20:41:51 <Pseudonym> You just getting up or just planning to sleep?
20:41:59 <shapr> nearing sleep
20:42:05 <Pseudonym> Fairy nuff.
20:42:45 <shapr> have you seen Pete Gammie's PLog?
20:42:53 <Pseudonym> No.
20:42:57 <shapr> haskell blogging tool
20:43:06 <Pseudonym> Oh, very cool.
20:43:11 <shapr> http://gungnir.csbnet.se/~peteg/blog/
20:43:35 <shapr> oh, here's the download page: http://gungnir.csbnet.se/~peteg/blog/plog.html
20:46:00 <shapr> Pseudonym: written any neat code lately?
20:46:24 <Pseudonym> Disturbingly close to a w*rk deadline, so no, unfortunately.
20:46:43 <Pseudonym> I have been sketching out some stack-free graph algorithms that I'm going to need in a personal project soon, though.
20:46:52 <Pseudonym> I need to manipulate a huge dataflow graph.
20:46:57 <shapr> what for?
20:47:03 <Pseudonym> Personal project. :-)
20:47:08 <Pseudonym> You'll find out if it goes anywhere.
20:47:10 <shapr> ok :-)
20:47:18 <shapr> souns good to me
20:47:41 <Pseudonym> Anyway, I need to analyse it (e.g. detect cycles) without using the stack because I expect paths to get very long.
20:48:12 <Pseudonym> And also, I may be able to use multi-threading to scale these algorithms.
20:48:53 <skew> I'm wondering about stuff somewhat related to finding cycles, or perhaps abstract interpretation
20:49:03 <Pseudonym> Oh?
20:49:13 <skew> could your project have anything to do with the typeclass system>
20:49:26 <Pseudonym> It's not in Haskell, but I am using it for prototyping.
20:49:34 <Pseudonym> And it's not for Haskell either.
20:49:56 <Pseudonym> It's for an interactive GUI-type application with nontrivial dynamic dependencies.
20:50:10 <skew> I would like to be able to determine whether an instance exists, allowing infinite irregular derivations
20:50:11 <Pseudonym> Kind of like a spreadsheet, except it's not a spreadsheet.
20:50:24 <shapr> that sounds interesting
20:50:25 <Pseudonym> You modify this value here, and all these values change.
20:50:47 <skew> you care about cycles, beyond rejecting cycles without a delay along them?
20:51:50 <Pseudonym> I care about cycles, yes.
20:51:58 <Pseudonym> Cycles actually make sense in my application.
20:52:14 <Pseudonym> Because the nodes of the graph are highly nontrivial.
20:52:19 <Pseudonym> Some inputs affect some outputs.
20:52:30 <Pseudonym> So nodes themselves might be cyclic but the actual dataflow dependencies may not be.
20:52:58 <Pseudonym> The complicating factor is that the nodes do quite complex computation in general.
20:53:09 <skew> that's vaugely related to what I'm trying to sort out
20:53:33 <Pseudonym> Going back to the spreadsheet analogy, if only a small amount of the spreadsheet is visible, you only want the bits you can see to be updated for it to run at interactive speeds.
20:54:00 <Pseudonym> So you need to find all paths between the input being modified and the visible outputs to work out exactly what you need to recompute.
20:54:13 <Pseudonym> It's quite tricky.
20:54:21 <skew> expanding the nodes of the graph to track separate bits of the data independantly might help
20:54:39 <Pseudonym> Well, not quite.
20:54:52 <Pseudonym> In general, a node uses all of its inputs to compute all of its outputs.
20:55:02 <Pseudonym> But if you only change THESE inputs, only THESE outputs change.
20:55:12 <skew> a graph tracking that, I mean
20:55:21 <Pseudonym> Actually I'm storing a bit matrix at each node.
20:55:45 <Pseudonym> Well, actually I'm storing it statically for each node class.
20:55:52 <Pseudonym> Not for each instance. :-)
20:56:10 <Pseudonym> So that's kind of a graph tracking that information.
20:57:06 <skew> given a set of types of kind *->*->...->* you can determine whether the types are regular by making a node for each input of each argument of each type, and connecting them up, and looking for positive weight cycles
20:57:41 <Pseudonym> skew: I think I know what you're doing.  It's similar to Mercury's mode analysis.
20:58:01 <shapr> are you making a sensible make replacement?
20:58:09 <Pseudonym> shapr: No.
20:58:15 <skew> what is this mode analysis for?
20:58:19 <Pseudonym> This is an interactive GUI application, which rules out make.
20:58:26 <Pseudonym> skew: Do you know prolog at all?
20:58:31 <skew> not much
20:58:40 <shapr> sometimes I think make is just a clunky DAG language
20:59:02 <Pseudonym> Prolog has free variables.
20:59:24 <Pseudonym> You can model this by considering a Prolog term as a type tree where each node is annotated by either "bound" or "free".
20:59:27 <skew> ACM is being a bit slow about giving me the paper
20:59:35 <stepcut> @type drawTree
20:59:36 <Pseudonym> With the constraint that if a node is free, all subtrees are free.
20:59:37 <lambdabot> bzzt
20:59:58 <stepcut> @type Data.Tree.drawTree
21:00:00 <lambdabot> Data.Tree.drawTree :: forall a.
21:00:00 <lambdabot> 		      (Show a) =>
21:00:00 <lambdabot> 		      Data.Tree.Tree a -> String
21:00:01 <Pseudonym> skew: You want Zoltan's PhD thesis.
21:00:17 <Pseudonym> http://www.cs.mu.oz.au/~zs/papers/papers.html
21:00:27 <Pseudonym> Go down near the bottom: "A system of precise modes for logic programs".
21:00:33 <stepcut> gah, the version of draw tree on *my* system is type: Tree String -> String
21:00:36 <skew> I just got Zoltan's "Constraint-based mode analysis of mercury"
21:00:38 <Pseudonym> That's actually not his thesis, but it's got all the ideas in it.
21:00:47 <Pseudonym> That's a good paper.
21:00:55 <skew> does it handle the higher order case?
21:00:56 <Pseudonym> But I think you need to read the other one to understand it. :-)
21:01:10 <skew> which paper?
21:01:14 <Pseudonym> No.  In Mercury, higher-order modes have to be declared by the programmer.
21:01:20 <Pseudonym> "A system of precise modes for logic
21:01:24 <Pseudonym>            programs"
21:02:11 <Pseudonym> Actually: http://www.cs.mu.oz.au/research/mercury/information/papers.html
21:02:20 <Pseudonym> Look at David Overton's PhD thesis.
21:02:21 <Pseudonym> That might be good.
21:03:28 <Pseudonym> But the thing is, the analysis seems very similar to what you're doing.
21:04:09 <skew> Basically, I want to be able to decide whether a particular instance is in the *greatest* fixedpoint of a set of instance declarations
21:04:29 <Pseudonym> Is there a greatest fixpoint?
21:04:59 <Pseudonym> And can you find it in finite time?
21:05:12 <skew> no to the latter, certainly
21:05:33 <Pseudonym> I have a suspicion that it may require induction over transfinite ordinals.
21:05:51 <Pseudonym> Unless you can only consider a finite set of candidates, I suppose.
21:05:51 <skew> the full problem is uncomputable, of course
21:06:02 <Pseudonym> Right.
21:06:03 <skew> so I'm really looking for a conservative approximation
21:06:50 <Pseudonym> It seems to me that you may be able to reduce it to a finite number of candidates with appropriate skolem types.
21:07:33 <skew> the ultimate goal is understanding the logic, with a probably side effect of allowing polymorphic recursion between instance declarations, at a sizable runtime cost
21:07:47 <Pseudonym> Is the greatest/optimal fixpoint going to be related to the least fixpoint?
21:07:58 <Pseudonym> Like, will one be an instance of the other?
21:08:04 <skew> huh?
21:08:09 <skew> I'm talking about sets of instances
21:08:20 <Pseudonym> Oh, yes.
21:08:26 <Pseudonym> Duh.
21:08:32 <skew> the least fixedpoint consists of instance claims that can be reduced to axioms by finite trees
21:08:47 <skew> the greatest is instances that can be reduced by infinite trees
21:08:47 <Pseudonym> Is there a unique greatest fixpoint?
21:08:59 <skew> greatest ordered under inclusion
21:09:03 <skew> of course there is
21:09:12 <Pseudonym> In some monotonic functionals there isn't.
21:09:20 <skew> no?
21:09:22 <Pseudonym> Oh, hang on.  Duh, yes.
21:09:29 <Pseudonym> In this case of course there is.
21:09:40 <skew> instance claims are finite trees
21:09:56 <Pseudonym> Because if X is a fixpoint and Y is a fixpoint then X \union Y is a fixpoint.
21:10:03 <skew> how to you fail to have a greatest fixedpoint?
21:10:11 <Pseudonym> It's possible.
21:10:17 <Pseudonym> I can't remember the precise examples.
21:10:29 <Pseudonym> The first requirement is that the lattice doesn't have a top.
21:10:31 <skew> the union of all self-justifying sets is the greatest fixedpoint
21:10:58 <Pseudonym> In THIS example, there's a greatest fixpoint.
21:11:22 <skew> maybe if your function is montonic under some ordering other than inclusion
21:11:30 <Pseudonym> But there isn't over all interesting domain lattices.
21:11:32 <skew> within a fixed set
21:11:33 <Pseudonym> Yes.
21:12:02 <Pseudonym> However, there's a nice theorem that the greatest lower bound of all maximal fixpoints is a fixpoint.
21:12:31 <Pseudonym> That's called the optimal fixpoint.
21:39:56 <Cale> skew: generates constraints on and adds variables for physical unit types in an abstract syntax tree.
21:41:21 <skew> Cale: what does that?
21:41:32 <Cale> the function that I just wrote
21:41:54 <Cale> It needs a bit of cleaning up, perhaps. :)
21:42:00 <skew> paste the code somewhere
21:42:18 <Cale> well, okay - but I'm going to sleep momentarily
21:44:09 <Cale> http://vx.hn.org/autoshare/AST.lhs -- it's a bit crufty, and pretty much everything in there is work-in-progress :)
21:44:35 <Cale> inferUnits is the big one at the moment :)
21:45:29 <Cale> I'm thinking that there might be some obvious transformations on that code which would help, but I'm a bit tired at the moment.
21:45:29 <skew> that case over the operator looks suspicious to me
21:45:39 <Cale> yeah
21:45:47 <ganymede> Cale: what are you building ?
21:46:03 <Cale> there ought to be a nice parametrisation of that
21:46:19 <Cale> the newCs is really the thing that changes in each case
21:46:41 <Cale> hmm -- spacing goes all wonky in my web browser
21:46:44 <Cale> meh
21:47:11 <Cale> ganymede: What will eventually be a compiler for a new language.
21:47:46 <ganymede> Cale: oh ! kewl
21:49:48 <stepcut> @type fmapM
21:49:49 <lambdabot> bzzt
21:49:50 <stepcut> :(
21:50:10 <skew> what type were you hoping for?
21:50:36 <stepcut> something like fmap + mapM
21:51:08 <stepcut> I want to fmap an function with return type 'IO a' over a Data.Tree
21:51:27 <stepcut> 'Data.Tree.Tree a' more specifically
21:52:05 <stepcut> so I would want: fmapM f mytree :: IO Data.Tree.Tree a
21:52:50 <stepcut> with fmap, i think I would get: Data.Tree.Tree (IO a)
21:52:52 <stepcut> :p
21:55:25 <Cale> hmm... that's a little cleaner
21:56:04 <skew> I think you should put the operator information in a table somewhere, maybe the context
21:57:00 <skew> stepcut: Tree doesn't even derive Data. I think you need to write that function yourself
21:57:35 <Cale> yes, that would possibly be nicer - or a finite map from symbols to functions that decide how the context gets updated.
21:57:50 <Cale> (which would basically be the same)
21:59:23 <Cale> hmm... anyone happen to know offhand an option to vim to always generate spaces?
21:59:38 <Cale> (rather than tabs)
21:59:47 <Pseudonym> :set expandtab
22:00:09 <Pseudonym> I have it on by default.
22:00:18 <Cale> I do too now :)
22:00:28 <skew> you probably want to set tabstop and shiftwidth
22:00:45 <Pseudonym> And softtabstop
22:00:55 <Cale> everything else is fine - it treats multiple spaces as tabs and all that
22:02:12 <skew> what is the use of softtabstop if you don't ever use tabs?
22:02:38 <Pseudonym> Useful if you're importingfiles with tabs.
22:04:11 <Cale> ah, much better
22:05:53 <skew> it sounds from the help like the effect is inserting tabs occasionally
22:06:00 <skew> how does that help importing files with tabs?
22:06:47 <Pseudonym> Hmmm.
22:06:51 <Pseudonym> I'll have to check.
22:07:04 <Pseudonym> Sorry, memory is a bit hazy on this.  I last looked at this years ago.
22:07:17 <Pseudonym> You might be right, and this might be useless.
22:15:19 <Cale> I think I'll brush up on some module theory tomorrow. Need to be able to actually solve the system of constraints I get :)  Shouldn't be too hard.
23:25:02 <Pseudonym> Grrrr.
23:25:42 * Pseudonym sighs
23:25:46 <Pseudonym> OK, need some advice.
23:25:53 <ayrnieu> Don't get married.
23:25:54 <Pseudonym> Nothing at all to do with Haskell.
23:25:59 <Pseudonym> Too late.  Already married.
23:26:23 <Pseudonym> Our wonderful database server has facilities to abort operations.
23:26:27 <Pseudonym> Say, if they're taking too long.
23:26:32 <Pseudonym> Or the connection drops.
23:26:51 <Pseudonym> I'm trying to test these against my wonderful new fast sort code.
23:27:11 <Pseudonym> Trouble is, the sorting is going _too_ fast.  I can't get them to time out.
23:27:22 <Pseudonym> Hence I can't test aborting the operations.
23:27:29 <Pseudonym> Hmmm.
23:27:50 <Pseudonym> The easiest approach would be to put in the inner loop:
23:27:52 <ibid> add an artificial delay to your code?
23:27:56 <Pseudonym> Yes.
23:28:10 <Pseudonym> However, that would slow down normal operations.
23:28:15 <ayrnieu> or have your code stop wherever you'd like to see an abortion.
23:28:16 <Pseudonym> Even if you didn't turn it on.
23:28:33 <Pseudonym> You'd still have to test a boolean somewhere in an inner loop.
23:28:37 <ibid> Pseudonym: don't use it in production builds
23:28:44 <ibid> Pseudonym: conditional compilation
23:28:56 <ibid> but i have to run to the bus, bbl
23:28:57 <Pseudonym> The system tests pass fine in non-production builds.
23:29:02 <Pseudonym> OK, bye.
23:29:17 <Pseudonym> We only have two compilation models: -O0 and -O2
23:29:29 <Pseudonym> In -O0 it runs slow enough that the tests pass.
23:29:34 <Pseudonym> In -O2 it doesn't.
23:29:59 <ayrnieu> -O2 -DINTENTIONALLY_SLOW
23:30:01 <skew> is there any reason to use the sorting process, rather than a process that just sleeps?
23:30:11 <Pseudonym> skew: Sorry?
23:30:17 <Pseudonym> Ah, yes, there is.
23:30:43 <Pseudonym> You have to understand how the code is structured to see why.
23:30:49 <skew> or, a process that sorts then sleeps
23:31:09 <Pseudonym> It's a whole infrastructure based on using different sorting methods and algorithms depending on what keys you give it.
23:31:22 <Pseudonym> ANd I want to test one subsystem.
23:32:11 <skew> it seems to me that aborting transactions that take too long would be unrelated to the details of what the transations are doing
23:32:28 <skew> except for a bit somewhere that picks the timeout to set on the new transactions
23:32:39 <Pseudonym> Ah, you have to understand how we abort operations for that.
23:32:46 <Pseudonym> We don't just kill a thread.
23:33:17 <Pseudonym> Operations which can be aborted have to periodically check an abort object, and if you need to abort, you throw an exception which is handled at a higher level.
23:34:37 <Pseudonym> Very annoying.
23:35:00 <Pseudonym> I _think_ what I'm going to have to do is just give it a larger dataset.
23:35:26 <Pseudonym> Trouble is, it takes something like 3000 seconds to load the databases during system tests as it is.
23:35:51 <Pseudonym> I don't want to increase peoples' pain unnecessarily.
