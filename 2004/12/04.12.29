00:31:11 <tintin> is there an mp3 player written in haskell ?
00:32:13 <Cale> not to the best of my knowledge
00:32:23 <Cale> why?
00:32:28 <Cale> thinking of writing one?
00:33:14 <tintin> yes hopefully if i can get at the algos ... it will be an excellent way to learn haskell ... 
00:33:26 <tintin> tutorials can get me only so far ... 
00:34:10 <humasect> . .. . .
00:34:19 <tintin> hello humasect 
00:34:26 <humasect> hi
00:36:28 <musasabi> morning
00:36:59 <musasabi> Has anyone worked on getting Haskell talk with XPCOM?
00:50:41 * wli comes up with another use for hopengl
00:59:03 <wli> 3D surface plotters (basically gnuplot but in 3D)
01:07:07 <wli> hopengl is stumping me
01:35:18 <xkb> how do you write a \ in latex? \\ doesnt work
01:45:33 <tintin> ,flip
01:50:08 <mornfall> xkb: \backslash
01:50:16 <mornfall> xkb: \\ is a newline :)
01:50:17 <xkb> really?
01:50:19 <xkb> ah
01:50:24 <xkb> tries.. :D
01:50:48 <mornfall> sorry for late reply, there was a dcc flood turmoil in #c++ :p
01:50:54 <xkb> lol
01:51:22 <xkb> cool.. thanks
01:51:29 <mornfall> no prob
01:51:50 <mornfall> as for #c++, some fuckwit was trying out a years-old mirc 5.something exploit :)
01:52:26 <xkb> its the holidays eh.. people got 2 much time on their hands
01:53:09 <mornfall> which reminds me i should be writing T&S... *sniff*
02:14:36 <tintin> hello shapr
02:40:01 <lyceen> hello
02:40:23 <tintin> hello lyceen 
02:42:06 <lyceen> how are you?
02:47:14 <lyceen> hello lordmetroid_
02:58:31 <musasabi> What is the best way to parse haskell source files?
02:59:31 <basti_> fileting an existing haskell parser?
02:59:51 <tintin> fileting ? what does that mean ?
03:00:07 <basti_> cutting it up to little pieces ready to be eaten ;)
03:00:46 <tintin> i thought there for a second that there is a fileting command in haskell ... 
03:00:54 <basti_> uhm no.
03:01:02 <basti_> but really i would use an existing parser
03:11:07 <basti_> musasabi: you want to do that in haskell dont you?
03:20:08 <wli> hssource is there
03:20:14 <wli> there's a haskell parser etc.
03:23:08 <musasabi> basti_: yes.
03:23:26 <musasabi> basti_: reusing TH could be kind of nice.
03:23:39 <musasabi> as I want GHC extensions too..
03:33:14 <sam_> vincenz, lo
03:57:33 <bierbaer> hi !
03:59:16 <bierbaer> i am a haskell nb. Could anyone tell me how to produce an output 10 times without using "if" and "else", so that i get smaller code ?
04:00:07 <musasabi> @type replicateM
04:00:08 <lambdabot> bzzt
04:00:22 <bierbaer> ??
04:00:27 <musasabi> bierbaer: import Control.Monad
04:00:39 <musasabi> bierbaer: replicateM 10 action
04:00:52 <musasabi> or if you don't need the result replicateM_
04:01:13 <musasabi> (of course if we are talking about a pure computation replicate is enough)
04:01:18 <bierbaer> i'll try..
04:02:41 <musasabi> e.g. 
04:02:53 <wilx> @type replicate
04:02:54 <lambdabot> replicate :: forall a. Int -> a -> [a]
04:03:01 <musasabi> main = replicateM_ 10 (putStrLn "hello world")
04:03:15 <wilx> @type replicateM
04:03:16 <lambdabot> bzzt
04:03:55 <bierbaer> ok. it works. thx :)
04:04:09 <redhatPT> hi everyone
04:05:36 <bierbaer> import Control.Monad is nearly as much code as when I do it recurseively with "if" and "else"...
04:05:57 <samc_> bierbaer: you wouldn't have had to use (explicit) 'if' and 'else' to define replicateM
04:06:30 <bierbaer> i understood that; i was using if and else before using replicateM
04:07:07 <bierbaer> But if and else were too many code characters. i was looking for some smaller solutions... but "import Control.Monad" is much text.
04:08:29 <samc_> why are you looking for little text?
04:09:42 <bierbaer> for some contest.
04:10:53 <musasabi> f 1 a = a ; f n a = a >> f (n-1) a
04:11:22 <bierbaer> thats not possible with "do", which i need for producing output..
04:11:36 <bierbaer> at least, i did not make it work :(
04:11:41 <musasabi> mapM_ action [1..10]
04:12:06 <musasabi> but you need action to accept/discard one dummy parameter (the n)
04:12:14 <bierbaer> what is that ?
04:12:39 <bierbaer> what is mapM ?
04:13:22 <bierbaer> what stands ">>" for ?
04:14:02 <samc_> a1 a2 = a1 >>= (\x -> a2)
04:14:23 <samc_> but I bet that didn't help ;)
04:14:32 <bierbaer> :)
04:15:19 <bierbaer> oh, jesus...
04:15:31 <bierbaer> could you explain that line ?
04:15:52 <samc_> try this: http://research.microsoft.com/Users/simonpj/papers/marktoberdorf/
04:16:06 <samc_> the beginning of
04:16:32 <musasabi> www.nomaware.com/monads/html/ is a quite good introduction to monads.
04:17:52 <samc_> I prefer peyton jones' presentation
04:17:54 <basti_> can anyone explain to me the correspondence between a monad and a funktor?
04:18:29 <musasabi> math or CS?
04:18:57 <basti_> what you like more
04:19:06 <basti_> I'll probably understand both.
04:19:19 <musasabi> well both monad and functor have very different meanings depending upon context.
04:20:17 <basti_> but as i understand what in Haskell is a Monad can be expressed as a Coalgebra
04:20:33 <basti_> and a Coalgebra has some relations to funktors.
04:20:43 <basti_> as in, "there is a funktor that belongs to some algebra"
04:20:57 <basti_> or am i off track there?
04:22:57 <musasabi> a functor is a morphism of categories.
04:23:02 <musasabi> (in category theory)
04:23:11 * basti_ nods
04:24:23 <musasabi> basti_: given two categories C and D the functor F maps all objects of C to D and all morphisms of C to morphisms of D such that the identity and composition of morphisms are preserved. 
04:24:36 <basti_> yup
04:24:45 <basti_> thats the "Funktor Properties"
04:25:18 <basti_> and if we have a coalgebra, we can see it as a Base Set and some Funktor.
04:25:53 <basti_> that maps the Base to (yes where?) and all the operations on Base.
04:26:34 <basti_> and since we have the funktor properties that make life so easy and the general categorical properties of all the functions in our base sets, we can make up some nice shorthands
04:26:53 <basti_> as in (do x<-this;that x)
04:28:18 <musasabi> sorry, I cannot really help with that. My bridge between math and CS is very lacking in those aspects.
04:28:26 * basti_ nods
04:28:35 <basti_> i'll have to ask my prof
04:28:44 <basti_> I'll write down some things and go ask him
04:28:54 <samc_> basti, I'm interested in that last bit, refs?
04:29:12 <basti_> samc_: i have no ref beside my own brain.
04:29:21 <samc_> oh well
04:29:31 <basti_> samc_: but i think i can go to great lengths about that
04:30:16 <musasabi> "Categories types and structures" is a freely? available book on the subject.
04:30:17 <basti_> basically you can ignore the "funktored" layer as long as you dont talk about the explicit construction of the sequence points
04:31:15 <basti_> samc_: are you interested in some techspeak about this?
04:33:24 <TheHunter> basti_, the basic relation between monads and functors is, that every monad is a functor, which unfortunately isn't reflected by the prelude's type class hierarchie.
04:33:41 <TheHunter> in haskell terms, you can always do instance Functor m where fmap = liftM
04:33:49 <basti_> =)
04:33:54 <basti_> now this is a clear response
04:34:32 <TheHunter> in categorical terms, a monad is a funtor with two natural transformations mu (join in haskell) and eta (return) which satisfy some laws.
04:34:43 <basti_> join?
04:34:51 <TheHunter> @type join
04:34:52 <lambdabot> bzzt
04:34:58 <TheHunter> @type Control.Monad.join
04:35:00 <lambdabot> Control.Monad.join :: forall a m. (Monad m) => m (m a) -> m a
04:35:00 <basti_> bind?
04:35:14 <basti_> k
04:35:17 <TheHunter> bind is crap, in any case.
04:35:26 <basti_> how does the do sequence point relate?
04:35:28 <basti_> forgot its name
04:35:29 <TheHunter> @type (=<<)
04:35:31 <lambdabot> (=<<) :: forall b m a. (Monad m) => (a -> m b) -> m a -> m b
04:35:53 <TheHunter> f =<< x = join $ f `fmap` x
04:36:16 <TheHunter> do sequence point?
04:36:25 <basti_> its a "sequence point"
04:36:34 <basti_> that is used in the "do" notation
04:36:53 <basti_> C ; is a sequence point. OCaml ; is, too.
04:37:14 <TheHunter> do x <- mx
04:37:18 <TheHunter>    y <- my
04:37:20 <TheHunter>    z
04:37:30 <basti_> means that "everything right of this can be done if everything left of this is done."
04:37:39 <basti_> yup theres sequence points
04:37:43 <basti_> you just dont see them ;)
04:37:43 <TheHunter> is translated to mx >>= \x -> my >>= \y -> z
04:37:57 * basti_ nods
04:38:27 <TheHunter> which has a very imperative motivation and I guess no really satisfying categorical interpretation.
04:38:39 <basti_> not strictly no.
04:38:54 * TheHunter prefers =<< to >>=, anyway.
04:38:54 <basti_> but you can see tiny splinters of categories in there.
04:39:02 <basti_> severely disrupted by \'s ;)
04:39:56 <TheHunter> to define new monads, join is usually the simplest operation to implement, that's about why mathematicians decided to define monads in terms of mu.
04:40:27 <basti_> thanks for the tip.
04:40:29 <basti_> wb samc_ 
04:40:52 * samc__ goes to read logs
04:41:22 <basti_> TheHunter: how does the source code of liftM look like?
04:41:30 <basti_> or is this done internally?
04:42:04 * basti_ .o° ( what i find cool is, i can now TALK about the things i used to only THINK about when i was younger)
04:42:21 <TheHunter> iirc, it's defined using do notation, which is usually much less efficient than using fmap directly.
04:42:45 <basti_> but it can be expressed in haskell yes?
04:43:05 <TheHunter> f `liftM` x = f =<< return x
04:43:19 <basti_> hm okay.
04:43:22 <basti_> i see.
04:43:33 <basti_> yes of course since "return" is the "make me monad!" transform isnt it?
04:43:44 <TheHunter> yep
04:44:01 <basti_> i think i'm slowly understanding this stuff.
04:44:12 <basti_> i mean as in really.
04:44:20 <TheHunter> from the libs: liftM f m1              = do { x1 <- m1; return (f x1) }
04:45:40 <TheHunter> umm, sorry, f `liftM` x = (return . f) =<< x
04:45:56 <TheHunter> the thing above is just the identity
04:46:06 <basti_> uh.
04:46:14 <basti_> okay.
04:48:09 <TheHunter> one thing that annoyed me, is that the monad laws are often stated in a weird way.
04:48:16 <TheHunter> (=<<) return === id
04:48:22 <TheHunter> (=<<) f . return === f
04:48:28 <TheHunter> (=<<) ((=<<) f . g) === (=<<) f . (=<<) g
04:48:30 <basti_> lol
04:48:34 <TheHunter> seems much more straightforward
04:48:42 <basti_> indeed
04:48:57 <basti_> probably theres just disjunct sets of weirdnesses ;)
04:49:19 <TheHunter> you have to interpret (=<<) as "lift a function of type a -> m b to a function of type m a -> m b"
04:49:21 <samc__> basti, re discussion; I'm afraid I'd be too slow, as I'd have to do too much parallel reading
04:49:29 <basti_> samc__: okay.
04:49:45 <TheHunter> in many text, (=<<) is denoted as a subscripted star.
04:49:58 <TheHunter> which makes the notation really concise.
04:50:04 <basti_> hmm i see
04:50:19 <TheHunter> (f_* . g)_* = f_* . g_*
04:50:43 <basti_> in lists, =<< should be concat . map shouldnt it?
04:51:04 <TheHunter> it's concatMap
04:51:09 <TheHunter> @type concatMap
04:51:10 <lambdabot> concatMap :: forall b a. (a -> [b]) -> [a] -> [b]
04:51:16 <basti_> =)
04:51:41 <TheHunter> but we already had that: concat is join and map is fmap aka. liftM
04:52:05 <basti_> i see
04:52:23 <TheHunter> list monads are nice!
04:52:29 <basti_> yes i know
04:52:30 <basti_> ;)
04:52:36 <basti_> and they make an intuitive example
04:53:19 <bierbaer> i tries putStrLn(show(getLine >>= f))
04:53:36 <bierbaer> it does not work, because f expects a String as argument.
04:53:42 <samc__> "if we have a coalgebra, we can see it as a Base Set and some Funktor", this is true then of algebras also right?
04:53:58 <basti_> samc__: coalgebras are the dual of algebras.
04:53:58 <bierbaer> how do i tell haskell to get a String from getLine ?
04:54:10 <basti_> samc__: therefore treated differently
04:54:39 <basti_> samc__: in some respects they are similar, in some they're opposite, and in some they're different.
04:54:59 <basti_> lol
04:55:08 <basti_> this is why i didnt see you leave
04:56:12 <basti_> for one instance, algebras in cs make only sense when they're finite
04:56:26 <basti_> coalgebras can be infinite in a way.
04:58:02 <basti_> for example the unix program "yes" gives you infinitely many "y"
04:58:25 <samc_> I know of the duality, but I can't see how the difference between coalgebras and algebras would allow coaglbras to be 'seen' as a base set and a functor but not an algebra
04:58:37 <basti_> well you can see algebras like that indeed.
04:58:42 <basti_> but it won't help you any
04:59:01 <basti_> i mean an algebra is maybe GxG -> G
04:59:05 <arjanb> bierbaer: http://haskell.org/hawiki/ThatAnnoyingIoType
04:59:17 <basti_> and another one FxF -> F
04:59:30 <basti_> now these two are homomorph
04:59:38 <basti_> via an homomorphism f
05:00:00 <basti_> now if you have 2 G, you can do f and get two F, and then you can apply the operation and get one F.
05:00:21 <basti_> or do the operation in G and then appply f.
05:01:04 <basti_> thats great now and then but it doesnt rock the chair
05:01:27 <basti_> since an algebra represented in your computer would be some variables of a finite type and operations between them
05:02:26 <basti_> sure you can think up a functor that makes the map (Int->Double) (Int->Int->Int) -> (Double->Double->Double)
05:03:04 <basti_> uhm actually not.
05:03:32 <basti_> (Int->Double) (Double->Double->Double) -> (Int->Int->Double) is what you could do
05:03:48 <basti_> thats what C calls typecast.
05:03:57 <basti_> in other words, its there but its no fun.
05:04:14 <arauko> Morning.
05:04:49 <arauko> A function always has to return the same value when it receives the same argument right?, if it doesn't do it then it isn't a function
05:05:01 <samc_> y
05:05:04 <basti_> on the other hand, lists cant be expressed as a native C type, since C's type system is too weak
05:05:04 <basti_> yup..
05:05:04 <basti_> if you want to split hairs that is.
05:05:12 <basti_> ;)
05:05:17 <arauko> Ok.
05:05:29 <basti_> what's "gettime()" if not a function? =)
05:05:43 <arauko> that is that , referencial transparency thingy 
05:05:53 <basti_> yes.
05:06:43 <samc_> variables or values?
05:07:00 <basti_> ?
05:07:37 <arauko> same values.
05:07:49 <arauko> so in that case, what gettime() is?
05:07:57 <basti_> i dont know ;)
05:08:01 <basti_> black magic
05:08:04 <arauko> :-P
05:08:11 <basti_> it always tells the time
05:08:16 <basti_> in a time-less environment
05:08:28 <samc_> a relation?
05:08:36 <samc_> ;)
05:08:52 <basti_> hmm actually yes.
05:08:59 <basti_> its a 1-relation.
05:09:05 <basti_> but not a useful one as this ;)
05:09:07 <arauko> what is that?
05:09:11 <basti_> every time value happened.
05:09:17 <basti_> an unary predicate
05:09:25 <basti_> or will happen
05:09:47 <samc_> what are the morphisms in the category of the base set?
05:09:58 <basti_> hm?
05:10:07 <basti_> "functions"
05:10:09 <basti_> =)
05:10:15 <samc_> all of em
05:10:30 <basti_> well yes
05:10:47 <basti_> maybe you have Int as your base set, then all operations "Int->..." would be interesting
05:11:12 <basti_> (all functions with codomain = "base set")
05:11:12 <samc_> and what is the target category of the functor?
05:11:41 <basti_> you usually write "FG" for an object G for example
05:12:03 <basti_> then FG is whatever the funktor does to G
05:12:51 <basti_> in Lists of course its [G], and the function funktor is map
05:14:38 <basti_> (haskell has problems with naming the funktor)
05:15:43 <samc_> arauko, gettime() can be considered a function with an implicit 'world' arg
05:15:57 <basti_> indeed but what would world be?
05:16:06 <basti_> that is as explaining conciousness as a little man inside your head
05:18:41 <arauko> isn't it an action?
05:20:49 <basti_> i think time would maybe have some relation to temporal logic
05:21:05 <musasabi> actions are just functions passing a world.
05:21:06 <samc_> arauko, yes
05:21:20 <basti_> which is a little obscure to me
05:21:57 <samc_> basti_, a great quote considered out of context :P
05:22:01 <musasabi> the problem in functional languages is to avoid cloning the world.
05:23:30 <samc_> whats [G] exactly?
05:23:38 <basti_> the type "List of many G's"
05:24:28 <samc_> in terms of the functor
05:24:33 <basti_> well uhm
05:24:49 <basti_> We're talking about Types, not about the Objects.
05:25:12 * basti_ orders his tongue
05:25:28 <samc_> you said in lists [G] is what the functor does to G
05:25:29 <basti_> lets say our base type is Integers.
05:25:44 <basti_> then we apply, say, "The List Funktor" (whatever this might be)
05:25:54 <samc_> which seems backwards
05:26:04 <basti_> it gives us a "List" for every Integer.
05:26:18 <basti_> and a function for every "Integer->X" function.
05:26:43 <basti_> that would be of type "Integer->X -> [Integer]->[X]"
05:27:05 <basti_> sadly these two notions of the Funktor are buried in different Haskell terms
05:27:19 <basti_> the first is (a::nil) or [a], and the second is map f
05:30:34 <samc_> you seem to be associating the functor with but one operation, how then can a multioperation algebra be viewed this way, or am I too confused :)
05:30:45 <samc_> coalgebra
05:31:03 <basti_> well map is a higher order function.
05:31:14 <basti_> it will treat any "Integer->X" function
05:31:25 <basti_> be it "Integer->Double" "Integer->Integer->Integer" or anything
05:31:38 <basti_> @eval map (\x->x+1) [1,2,3,4,5]
05:31:38 <lambdabot> [2, 3, 4, 5, 6]
05:31:50 <basti_> @eval map (+) [1,2,3,4,5]
05:31:50 <lambdabot> (line 1, column 6):
05:31:50 <lambdabot> unexpected "+"
05:31:50 <lambdabot> expecting simple term
05:31:52 <basti_> hm
05:31:57 <basti_> lambdabot doesn't.
05:31:58 <basti_> ;)
05:40:59 <samc_> can you give me an example of a (trivial) coalgebra and its functorial representation?
05:41:39 <basti_> hmm well okay
05:41:52 <basti_> The Coalgebra of Power Sets:
05:43:01 <basti_> if you can do one thing with all the Objects from X (function), then you can do it with all the Objects in a Set of these Objects.
05:43:32 <basti_> trivially by the join of the singletons of the results of the function applications.
05:44:22 <basti_> now i mentioned everything thats in that coalgebra.
05:53:42 <vincenz> samc_: hi
05:54:57 * esap just added lots of info to http://haskell.org/hawiki/ControlOperation.
05:59:10 <bierbaer> hello. i have a further question...
05:59:44 <bierbaer> is it possible to define a function like: "f 1 or 2 or 3=10"
05:59:46 <samc_> vincenz, I'll could send you CCT if you like (I only have .pdf)
06:00:03 <bierbaer> instead of "f 1 = 10; f 2= 10 etc"
06:00:10 <vincenz> samc_: sure
06:00:18 <bierbaer> how can i do ?
06:00:29 <esap> bierbaer: f x = case x of { 1 -> 10 ; 2 -> 10 ; 3 -> 10 }
06:00:56 <bierbaer> thats more to write that "f 1 = 10" etc..
06:01:09 <esap> bierbaer: yes :-)
06:01:18 <bringert> or f x | x `elem` [1,2,3] = 10
06:01:18 <bierbaer> is there a shorter way ?
06:01:26 <bierbaer> ah.
06:01:41 <bringert> or f x | x >= 1 && x <= 3 = 10
06:02:01 <bringert> or f x | x `elem` [1..3] = 10
06:02:05 <bringert> to save one character
06:02:09 <bierbaer> :)
06:02:14 <bierbaer> ok. thx.
06:02:16 <bringert>  or f x | elem x [1,2,3] = 10
06:02:25 <bringert> to save another
06:02:45 <bierbaer> i also need an else...
06:02:56 <bringert> f x | elem x [1..3] = 10
06:03:02 <bringert>    | otherwise = 20
06:03:04 <vincenz> samc_: how do you suggest? and pdf is perfect I always save everything as pdf
06:03:45 <bierbaer> elem is a list function ?
06:03:50 <bringert> @type elem
06:03:52 <lambdabot> elem :: forall a. (Eq a) => a -> [a] -> Bool
06:04:17 <bringert> checks if an element is in a list
06:04:29 <bierbaer> ok.
06:05:15 <bringert> f x = if elem x [1..3] then 10 else 20
06:05:23 <bringert> for another way to rite it
06:05:26 <bringert> write
06:05:28 <samc__> ah murphy's law
06:10:06 <bierbaer> is there no shorter way for "otherwise" ?
06:11:30 <sam_> now I'm pissed
06:12:29 <vincenz> sam_ == samc_ ?
06:12:36 <sam_> yes
06:13:08 <vincenz> anywho, how do you suggest sending it?
06:13:32 <sam_> this irc thingy has a send and recieve file facility
06:13:44 <vincenz> alright
06:13:48 <vincenz> let me unblock dcc
06:15:34 <vincenz> ok, done
06:19:57 <vincenz> sam_: ping
06:21:50 * vincenz aways as he has to go to
06:30:30 <bierbaer> is there any shorter way for "head" and "tail" of lists ?
06:31:53 <bierbaer> btw. i've found that you do not have to use "otherwise"; you can redefine the function for other cases. that is much shorter.
06:32:26 <bringert> you can also use any other True value instead of otherwise
06:33:16 <bierbaer> are there any shorter ?
06:34:44 <bierbaer> there is no shorter way, than redefinition
06:35:19 <samc_> lets see how long I can last this time
06:35:21 <bierbaer> but i need some shorter function for "head" and "tail"
06:35:58 <samc_> if you use them alot define a single letter as 'em
06:36:17 * samc_ holds his breathe
06:36:56 <bierbaer> no, i just use them one time, each.
06:37:20 <bierbaer> the best solution in haskell has half codesize of mine.. i cannot understand..
06:37:31 <arjanb> bierbaer: use pattern matching instead head and tail
06:38:18 <samc_> what do you have to write btw
06:38:21 <bierbaer> the function is "f a=m(head a)*f(tail a)"
06:38:40 <bierbaer> https://spoj.sphere.pl/problems/KAMIL/
06:39:19 <arjanb> f (x:xs) = m x * f xs
06:41:43 <samc_> so far, so good
06:42:24 <bierbaer> ok. that works. but why ?
06:43:52 <samc_> http://www.haskell.org/tutorial/patterns.html
06:45:35 <samc_> head (x:xs) =  x
06:45:52 <samc_> tail (x:xs)  =  xs
06:47:33 <bierbaer> ok. i think, i have understood :)
06:47:51 <samc_> bierbaer, ':' is an operator which adds an element to the front of a list
06:48:31 <bierbaer> i knew that, but i did not knew, that it can be used that way...
06:48:43 <samc_> so [a,b] = a:[b] = a:b:[]
06:48:59 <samc_> ok
06:49:00 <Cale> bierbaer: it's special in that way because it is a data constructor
06:49:11 <basti_> !r
06:49:23 <Cale> Infix operators which begin with : are data constructors.
06:49:31 <bierbaer> ah
06:49:35 <bierbaer> ok
06:49:41 <Cale> and are defined either by the language, or in data declarations
06:49:46 <xerox> Are there order operator that begins with : ?
06:50:41 <Cale> :+ in the case of Complex types
06:50:53 <Cale> to separate real and imaginary parts
06:50:56 <Cale> for example
06:51:15 <Cale> xerox: or was order not a typo? :)
06:51:28 <Cale> but in that case I'm not sure what you mean
06:51:38 <xerox> *other operators* sorry
06:51:55 <Cale> I thought so :)
06:53:10 <samc_> bierbaer, you probably better off looking earlier in the tut actually
07:00:19 <bourbaki> moin
07:00:43 <basti_> bourbon+raki!
07:00:52 <bourbaki> :)
07:00:58 <basti_> yuck
07:13:32 <bourbaki> who was it again who wrote a lisp interpreter in haskell?
07:18:31 <bierbaer> hmm. is there any shorter way for "w=getLine>>= \c->print(f c)" ?
07:19:29 <aleator> getLine>>=print.f
07:19:30 <aleator> ?
07:20:19 <bierbaer> wow. thx.
07:20:36 <aleator> what is it that you are working at?
07:21:39 <bierbaer> https://spoj.sphere.pl/problems/KAMIL/
07:22:16 <bierbaer> just a little contest...
07:26:43 <MegaMonad> Greetings si2, have any questions about haskell io and unsafeperformio ?
07:27:14 <ac_mac> hello MegaMonad 
07:34:16 <aleator> bierbaer: foldl.
07:37:57 <Cale> MegaMonad: Hello MegaMonad, have any questions about ponies?
07:38:02 <MegaMonad> Cale: Megamonad, how do i have questions about ponies?
07:38:18 <vegai> MegaMonad: would you like to do some of my work? I'm quite tired
07:38:23 <MegaMonad> vegai: Man these 'ghasts' keep getting me to work a little tired.
07:38:35 <vegai> stupid ghasts...
07:38:39 <Cale> MegaMonad: You know, the whole moving the smoke thing...
07:38:47 <MegaMonad> Cale: It sounds to me that they let you smoke the first one is moving.
07:39:37 <Cale> MegaMonad: Is moving universal?
07:39:42 <MegaMonad> Cale: But, haskell can have a universal one.
07:40:55 <CosmicRay> MegaMonad: did you get any Christmas presents?
07:41:00 <MegaMonad> CosmicRay: _Joey_: i you want me to write a monadic logger might make good christmas presents.
07:41:07 <xerox> A question, why is factorial n = return (fact n) of the type factorial :: Int -> IO Int ?
07:41:26 <CosmicRay> MegaMonad: I already wrote that, I think.
07:41:28 <xerox> (where fact :: Int -> Int)
07:41:32 <MegaMonad> CosmicRay: You think a lot easier to do this for you.
07:41:36 <CosmicRay> xerox: because of "return"
07:41:47 <CosmicRay> @type return
07:41:47 <lambdabot> return :: forall m a. (Monad m) => a -> m a
07:42:09 <CosmicRay> oh no, lambdabot is gone!
07:42:13 <CosmicRay> ah. phew.
07:42:14 <xerox> What's the purpose of that?
07:42:24 <CosmicRay> xerox: let me give you an example:
07:42:29 <CosmicRay> do c <- getChar
07:42:40 <CosmicRay>    return ([c] ++ ", foo")
07:42:56 <CosmicRay> a "do" block that is relating to IO must return an IO something.
07:43:05 <CosmicRay> that last expression would be a String
07:43:12 <CosmicRay> the "return" makes it into an IO String
07:43:28 <CosmicRay> in other words, "return" takes something that is outside a monad and promotes it to being inside the monad
07:43:35 <Cale> return takes a value, and produces a monadic container which has just that value in it, or if you think of them as computations, produces the constant computation returning that value
07:43:39 <CosmicRay> Here's an example where you don't need it:
07:43:43 <CosmicRay> do c <- getChar
07:43:52 <CosmicRay>    putStrLn ([c] ++ ", foo")
07:44:04 <CosmicRay> you don't need return there because putStrLn already returns IO ()
07:44:17 <CosmicRay> and the do block takes the value of the last expression when it "returns"
07:44:36 <xerox> I see
07:44:48 <CosmicRay> in your case, you're not using monads at all, so you have no need for return
07:44:56 <CosmicRay> take it out and you'll solve that problem
07:45:00 <Cale> Well, he could be
07:45:02 <xerox> O_o
07:45:05 <xerox> It's not a problem
07:45:24 <xerox> I was trying to understand that code: http://www.python.org/cgi-bin/moinmoin/PythonVsHaskell
07:46:29 <xerox> I was asking myself "why return explicitly in Haskell"
07:46:40 <xerox> thanks for the explanation
07:47:28 <CosmicRay> xerox: that code is not really idiomatic Haskell
07:47:43 <xerox> What does idiomatic Haskell.
07:47:48 <Cale> That's actually really odd
07:47:49 <CosmicRay> xerox: Usually in Haskell, one would not make a function return an IO unless you really need to
07:47:55 <xerox> umpf, What's idiomatic Haskell, I meant.
07:48:00 <CosmicRay> instead, one would use return when working in the IO monad itself
07:48:05 <Cale> does "foreign export stdcall fact :: Int -> Int" not work?
07:48:26 <CosmicRay> the reason is that, once a function returns an "IO something", every function that calls it must also return an IO something
07:48:36 <CosmicRay> so it limits where you could use the function
07:48:57 <CosmicRay> ah, I missed that bit.
07:49:14 <CosmicRay> cale: no, I think all foreign calls must (or at the very least, SHOULD) be in the IO monad
07:49:21 <CosmicRay> Cale: because C has side-effects
07:49:33 <Cale> right, that's a foreign export though
07:49:56 <CosmicRay> cale: hmm, I don't know.  I am not well-versed enough with the foreign stuff in Haskell
07:51:32 <Cale> I think it really should work, and they're just being a bit silly.
07:51:43 <xerox> :)
07:51:46 <Cale> There might be some subtlety to it that I'm missing
07:52:41 <wli> I'd love to hear how to do a wrapper for sys_epoll()
07:53:01 <CosmicRay> wli: what is that?
07:53:28 <wli> a Linux-specific system call in 2.6.x versions of Linux
07:53:48 <CosmicRay> huh, I don't have a manpage entry for it
07:53:58 <wli> try man epoll
07:54:14 <wli> there is epoll(4)
07:54:23 <wli> epoll_create(2)
07:54:26 <wli> epoll_ctl(2)
07:54:28 <CosmicRay> ah yes.
07:54:30 <wli> epoll_wait(2)
07:55:40 <CosmicRay> wli: is that really necessary in Haskell, though, given that forkIO already does asynchronous IO for us for free?
07:55:58 <wli> resource scalability
07:56:13 <CosmicRay> epoll scales better than poll?
07:56:19 <Cale> I suppose something like: foreign import ccall "static sys/epoll.h" epoll_create :: Int -> IO Int
07:56:25 <wli> asymptotically faster
07:56:31 <wli> epoll_wait() is the one I was worried about
07:56:58 <CosmicRay> wli: you might be able to see what ghc is doing with select or poll, whatever it uses now
07:57:08 <vincenz> re
07:57:10 <CosmicRay> wli: even better, patch ghc to use epoll if it's available
07:57:22 <Cale> you'll need to wrap up the struct, possibly writing an instance of Storable for some Haskell type
07:57:36 <wli> is Storable needed to get real arrays?
07:58:15 <vincenz> !seen sam
07:58:19 <vincenz> !seen sam_
07:58:23 <Cale> It's needed for marshalling data into a specified form in general
07:58:29 <vincenz> Cale: hi
07:58:32 <Cale> hi
08:17:45 <yeti> yay! my huffmanTree function produces trees... unforunately they're not correct yet =)
08:45:50 <ultramagnus> m00
08:47:04 <ultramagnus> I'd like some downloadable haskell texts/tutorials, need to study off-line.. recommendations?
08:47:55 <vincenz> check www.haskell.org
08:47:59 <vincenz> plenty thre
08:48:00 <vincenz> there
08:50:48 <arjanb> ultramagnus: http://www.isi.edu/~hdaume/htut/
08:53:17 <ultramagnus> ok
08:56:18 <bierbaer> does anyone know, how to write the shortest Code to count occurencies of characters from one String in another ?
08:57:00 <ultramagnus> why does the shortness matter?
08:57:22 <bierbaer> i like to have short code for a contest.
08:57:41 <bierbaer> https://spoj.sphere.pl/problems/KAMIL/
08:57:51 <TheHunter> bierbaer, how many lines have you got?
08:57:58 <TheHunter> s/lines/chars/
08:58:03 <bierbaer> 4
08:58:21 <bierbaer> 5
08:58:23 <bierbaer> 88 Byte
08:58:43 <wli> whoa
08:58:44 <bierbaer> the one with 4 lines has 89 Bytes
08:58:49 <wli> hdaume's style files rock
08:58:56 <wli> I wonder how he's doing a bunch of this stuff
08:59:00 <wli> like the purple and green boxes
08:59:03 <wli> and the margin notes
08:59:32 <TheHunter> my first attempt has 91 Byte
08:59:40 <bierbaer> oh.
08:59:42 <bierbaer> wow.
08:59:55 <TheHunter> not sure that i got it correctly though
09:00:20 <bierbaer> correctness is not so difficult for that problem.
09:00:32 <bierbaer> Well, that is my first Haskell programm :)
09:00:49 <TheHunter> how is the input terminated?
09:00:53 <TheHunter> first line or Ctrl+D
09:01:03 <wli> I'm not sure what my first Haskell program was. I wonder what it was.
09:01:07 <bierbaer> its not terminated. there are 10 testcases.
09:01:23 <bierbaer> after the last line, the program should terminate
09:01:34 <bierbaer> -> after 10 lines
09:03:00 <TheHunter> this discription is highly ambigous.
09:03:21 <TheHunter> The way I read it, it sould read some words and then count how many words can be built from these words.
09:03:22 <bierbaer> its describes on that page, how it should look like...
09:04:01 <bierbaer> yes, for each line you read, you should output the number of possibilities, then read the next line
09:04:11 <TheHunter> ok, then my program solves a slightly more difficult problem
09:04:34 <bierbaer> you read all lines first ? :)
09:04:43 <TheHunter> yep
09:04:53 <TheHunter> so tt\nkk returns 4
09:05:29 <wli> hmm, are there lambdatex debs?
09:06:55 <bierbaer> after the newine, you should restart the function...
09:07:06 <TheHunter> no, after eof.
09:07:13 <bierbaer> NKK returns 4, yes.
09:07:35 <bierbaer> capitals should be used.
09:08:12 <TheHunter> I see
09:08:59 <TheHunter> boring.
09:09:26 <bierbaer> how many Charactres do you need ?
09:09:38 <TheHunter> I was pretty impressed you could do that in 25 chars of perl, but this problem is really easier.
09:09:52 <TheHunter> for the right problem? didn't do that.
09:10:19 <bierbaer> can you beat the best haskell solution ?
09:10:25 <TheHunter> let's see
09:13:54 * shapr yawns
09:15:56 <xerox> Hm, can somebody help me giving more significative names to this function arguments? let me paste three lines:
09:16:02 <xerox> cfold' f z [] = z
09:16:02 <xerox> cfold' f z (x:xs) = f x z (\y -> cfold' f y xs)
09:16:02 <xerox> cfold f z l = cfold' (\x t g -> f x (g t)) z l
09:16:56 <vincenz> shapr: hi!, merry christmas and happy new year
09:17:14 <shapr> vincenz: merry christmas and happy new year to you too
09:17:27 <wli> hmm, pdftex can't find it
09:19:42 <wli> $ echo $TEXINPUTS 
09:19:42 <wli> /home/wli/tex/styles//:
09:19:57 <wli> $ ls -ld ~/tex/styles/lambdaTeX.tex 
09:19:57 <wli> -rw-r--r--  1 wli wli 41895 Jul 24  2003 /home/wli/tex/styles/lambdaTeX.tex
09:20:07 <wli> $ head -1 Main.lhs 
09:20:07 <wli> \input{lambdaTeX.tex}
09:20:09 <xerox> the f in cfold' arguments is the continuation, right?
09:20:13 <wli> okay, what did I do wrong?
09:20:31 <ne1> ah, continuation, no wonder I can't read it.
09:20:35 <bierbaer> TheHunter: what about your code size ?
09:20:45 <wli> any hints as to what I flubbed there?
09:22:09 <ne1> sometimes k is the dummy variable for a continuation.
09:23:14 <xerox> Resolved this I have to understand the continuation.
09:23:29 <xerox> what are 'x', 't' and 'g' ? :-\
09:23:53 <ne1> g is yet another continuation.
09:24:40 <TheHunter> bierbaer, 82 chars.
09:24:48 <xerox> Is t the value of the computation of f with the element?
09:25:13 <ne1> it begins to look bizzare. I don't know.
09:25:28 <xerox> Thanks btw
09:26:07 <wli> vaguely works with pdflatex except it errors out on \begin{code}
09:27:12 <bierbaer> what about that "print.xxx"? what does that mean ?
09:27:37 <bierbaer> 82? does it work fine ?
09:27:38 <TheHunter> compose the functions print and xxx
09:27:59 <TheHunter> main=interact$unlines.map(show.product.map f).lines
09:28:21 <TheHunter> f 'K'=2;f 'G'=2;f 'R'=3;f x=1
09:29:00 <bierbaer> wow. that is all ?
09:29:38 <TheHunter> i guess. It keeps on looping forever, though.
09:29:53 <bierbaer> hm. it should terminate after 10 times.
09:30:14 <bierbaer> have these "  ' " in "f' " special meanings ?
09:30:42 <TheHunter> @type 'k'
09:30:43 <lambdabot> 'k' :: Char
09:31:10 <bierbaer> ah. i was sleeping, i think :)
09:33:37 <bierbaer> hm. fuction composition is done with ".", you said. But why does it not work, when i give the result from one function to the other ? i think, thats also kind of composition ?
09:33:57 <TheHunter> (f . g) x === f (g x)
09:34:49 <wli> hmm, even lambdaTeX doesn't really do things justice
09:34:58 <bierbaer> it s the same ? ok.
09:35:16 <TheHunter> 89: main=sequence.replicate 10$(print.product.map f)=<<getLine
09:36:35 <TheHunter> 85: main=sequence[print.product.map f=<<getLine|_<-[0..9]]
09:37:45 <bierbaer> hm. the best one has 70..
09:38:14 <bierbaer> nevertheless, i am impressed...
09:39:39 <bierbaer> can i ask a further question ? why does "w=print (m (getLine))" not work, but "w=getLine>>=print.m" does ?
09:40:45 <TheHunter> (m getLine) has a monadic type, so you can't use the function print directly which does not expect a monadic type.
09:41:25 <ne1> I don't understand w=print (m (getLine)).  I guess that's why it doesn't work.
09:41:48 <bierbaer> when i use ">>=", a adaption is done ?
09:42:04 <TheHunter> @type (>>=)
09:42:05 <lambdabot> (>>=) :: forall m b a. (Monad m) => m a -> (a -> m b) -> m b
09:42:15 <TheHunter> @type (>>= print)
09:42:17 <lambdabot> (>>= print) :: forall a. (Show a) => IO a -> IO ()
09:43:18 <MegaMonad> Hi shapr. Good afternoon.
09:43:31 <ibid> MegaMonad: hello :)
09:43:37 <MegaMonad> ibid: What's the "fix" in "putstr $ fix("hello\n"++)" ?
09:43:38 <ne1> w=print (m (getLine))  would be valid Pascal but not valid Haskell.
09:43:56 <ibid> MegaMonad: it's the fixpoint combinator
09:43:58 <bierbaer> hm. but with >>= it works.
09:44:02 <MegaMonad> ibid: (I think we need to read about lazy fixpoint computation to an adress out of your haskell representation of a combinator is the try combinator.
09:44:20 <bierbaer> and as i understood the manual, that also gives the result to the next fct.
09:45:23 <bierbaer> could anyone explain the difference ?
09:45:38 <ne1> there is an IO monad tutorial. I forgot the url.
09:47:22 <wli> hmm, well, whatever hdaume did to get the code typesetting done was slick
09:47:59 <ne1> http://www.nomaware.com/monads/html/index.html  may be too much to read.
09:50:33 <wli> not enough according to me
09:51:30 <yeti> ne1: seems to be a good tutorial, i tried reading it, but it's still complicated for a newbie
09:51:34 <yeti> like me ;)
09:52:54 <bierbaer> i m a little obfuscated by those tutorials..
09:53:13 <ne1> Pascal does not distinguish "pure function that returns String" and "possibly side-effecting, I/O performing function that returns String".
09:53:41 <ne1> Haskell makes a big distinction.  First of all, the former has type String and the second has type IO String.
09:53:48 <bierbaer> Those Monads are equal to functions, but having side-effects? Did i understand right ?
09:53:58 <bierbaer> and Monads can be executed iterative.
09:54:09 <ne1> s/equal/like/  since the point is they are no longer equal.
09:54:25 <bierbaer> and can have non-deterministic results.
09:54:36 <bierbaer> hm.
09:54:42 <Lemmih> bierbaer: Only with the IO monad.
09:55:18 <yeti> http://dfy.dyndns.org/Huffman.hs <= could anyone please have a look at this code and tell me whats wrong? (i'm trying to implement a simple huffman tree)
09:55:21 <bierbaer> what could be Monad, excpet IO and Random ?
09:55:21 <ne1> To "call" a "function" (more like a procedure/command now) of the latter type and obtain its return value, you have to use >>=, or the do notation.
09:55:38 <Lemmih> bierbaer: Maybe and Either for example.
09:56:02 <Lemmih> Plus Error, lists and many more.
09:56:14 <ne1> I prefer the do notation.
09:56:23 <xerox> Is CPS widely used?
09:56:32 <bierbaer> i did not get the do notation work.
09:56:37 <ne1> do { s <- getLine; print (m s) }
09:57:01 <ne1> "s <- getLine" says: call getLine, store return value in s
09:57:04 <bierbaer> The Problem was with that "m".
09:57:16 <ne1> "print (m s)" is obvious, assuming m is a pure function.
09:57:24 <bierbaer> The Problem was with that "m".error
09:57:30 <bierbaer> because of that IO Type.
09:57:50 <bierbaer> oops; one line is gone.
09:57:52 <ne1> Then you have to add another line y <- m s
09:58:07 <ne1> do { s <- getLine; y <- m s; print y }
09:59:31 <ne1> Any time you use something of a type like a -> b -> c -> IO whatever, the "IO whatever" part means it is an I/O command.  You have to use the do notation and use <- to get its return value.
10:00:28 <bierbaer> hm. it worked with >>= ...
10:00:53 <bierbaer> i did not really understand, what that means, but it works fine..
10:01:08 <bierbaer> that must be similar to "do .. <- "
10:01:22 <bierbaer> but that with do, I did not get working.
10:01:24 <ne1> I trust that m has type like String -> IO whatever.
10:02:18 <ibid> bierbaer: do is just syntactic sugar for >>=
10:02:20 <ne1> I trust that I have made all kinds of correct assumptions.
10:02:21 <bierbaer> that's another thing, i do not really understand... Types are String->IO" ?
10:02:25 <bierbaer> for example ?
10:02:31 <ne1> You don't know types?
10:02:38 <bierbaer> there can be types concatenated with -> ?
10:02:46 <bierbaer> not really, i think ?
10:03:04 <ibid> bierbaer: a -> b is just the type of functions from a to b
10:03:55 <bierbaer> ok. but i have seen a->b->c
10:04:07 <ibid> bierbaer: that's the type of functions from a and b to c
10:04:19 <bierbaer> ok.
10:04:20 <ibid> bierbaer: the last type is the return value type, the rest are parameter types
10:04:21 <yrlnry> bierbaker: a >>= b    is the same as   do x <- a; b x
10:04:30 <ibid> yrlnry: more or less :)
10:05:18 <ne1> It is very hard to explain without knowing certain things on your side.  (What is m?  Why would "getLine >>= print . m" work while "do {s<-getLine; print (m s)}" not?  They are equivalent...)
10:06:09 <bierbaer> m is a pure function, that i have understood. getLine is not a pure function.
10:06:58 <bierbaer> that is why the use of getLine causes lots of problems :)
10:07:01 <ne1>    do {s<-getLine; print (m s)}
10:07:11 <ibid> what's the type of m?
10:07:20 <ne1> =  getLine >>= \s -> print (m s)
10:07:31 <bierbaer> m::[Char]->Int
10:07:33 <Lemmih> (Show a) => String -> a
10:07:37 <bierbaer> I hope :)
10:07:40 <ne1> =  getLine >>= \s -> (print . m) s
10:07:55 <ne1> =  getLine >>= (print . m)
10:08:06 <ne1> That is proof of their equivalence.
10:08:23 <ne1> I forgot the precedences of >>= and .
10:08:41 <bierbaer> ok.
10:08:50 <ibid> well, there is a corner case that makes your first step fail, but it's not an issue here
10:09:07 <ibid> actually, in this particular case i think the corner case doesn't matter at all
10:09:46 <bierbaer> "do {s <- getLine; print.m s}" is the same ?
10:10:08 <ne1> (print.m) s  mind the precedences
10:11:40 <bierbaer> ok. i _slowly_ understand...
10:12:16 <xerox> ne1, are you interested in map and filter by CPS?
10:12:40 <wli> okay, if I want sexy typeset Haskell code I may need to resort to trickery.
10:22:06 <ne1> I am not interested in all CPS.
10:22:34 <ne1> http://www.cs.toronto.edu/~trebla/fp/lecture-11.pdf  is my own I/O tutorial.
10:22:49 <ne1> (Of all the world's IO tutorials, I forgot mine. :)
10:23:52 <ne1> You don't have to fully understand the part "the magin of IO explained"
10:24:00 <ne1> s/magin/magic/
10:27:05 <shapr> hej noj
10:30:26 <noj> hej hej
10:37:53 * wli gets things looking like he wants after large amounts of pain and diverging wildly from anything interpretable by Haskell interpreters/compilers/etc.
10:37:58 * Lemmih is greatly annoyed by GHC's "urk" error message.
10:39:14 <wli> any recommendations on how to get Haskell code looking sexy in LaTeX
10:39:23 <wli> lambdaTeX isn't quite doing it for me
10:40:06 <Igloo> I think lhs2tex is the one best maintained (I think that's what it's called - whichever kosmikus works on)
10:42:36 <wli> *** Error in file Main.lhs line 5: 
10:42:36 <wli> `code' is not defined;
10:44:25 <wli> not in debian either
10:57:15 <wli> where is the tabbing environment defined...
11:00:15 <bierbaer> i do not really understand... why des that not work: "main=replicate (10 (print.product.map.f =<< getLine))"
11:01:38 <wli> argh
11:01:49 <wli> the tabbing environment is missing
11:02:43 <ne1> That is very confused bierbaer.
11:03:01 <bierbaer> f is a pure function...
11:03:05 <ne1> You bloody never write (10 (stuff))
11:03:25 <bierbaer> i want that code to be executed 10 times..
11:03:50 <arjanb> remove the outer parentheses
11:04:00 <ne1> main = sequence (replicate 10 (print.product.map.f =<< getLine))
11:04:50 <bierbaer> what does seuqence mean ?
11:04:54 <ne1> whatever you want, (10 (stuff)) makes no sense.  10 is not a function!
11:05:19 <Nioate> the problem might be the map.f
11:05:23 <Nioate> where did it come from?
11:05:26 <ne1> @type sequence
11:05:27 <lambdabot> sequence :: forall a m. (Monad m) => [m a] -> m [a]
11:05:41 <ne1> i.e., [IO a] -> IO [a]
11:05:57 <ne1> You give it a list of commands, it executes the commands one after another.
11:06:05 <ne1> You can also use sequence_
11:06:10 <ne1> @type sequence_
11:06:11 <lambdabot> sequence_ :: forall m a. (Monad m) => [m a] -> m ()
11:06:29 <ne1> [IO a] -> IO ()   this is good if you don't care about the return values.
11:06:57 <ne1> main is required to be of type IO whatever but not [IO whatever]
11:07:19 <ne1> You need to learn type-oriented programming.
11:09:20 <wli> okay, thus far, nothing can process the lambdatex stuff
11:09:26 <wli> er
11:09:28 <wli> lhs2tex
11:09:47 <arauko> actions are like single programs that are executed when the compiled program runs?
11:10:12 <ne1> Yes (without knowing what you really mean).
11:11:05 <arauko> i mean, you can't run an action right?, the compiled program runs it for you?
11:11:15 <ne1> Aha, right.
11:11:42 <arauko> So, the main fuction is an action?
11:12:02 <ne1> Yes, and the compiled program runs main and starts from there.
11:12:21 <arauko> Ah, thanks
11:13:47 <bierbaer> ne1: i lookes up "sequence" in a reference. The Type is "Monad a =>[ab]->a[b]"
11:13:51 <bierbaer> what does that mean ?
11:14:42 <wli> any hints?
11:14:45 <ne1> I prefer to rename the variables and call it Monad m => [m a] -> m [a]
11:15:20 <ne1> assume m is a monad (eg IO).  the parameter has type [m a], the result has type m [a].
11:15:32 <wli> I can't find the tabbing environment anywhere
11:16:03 <ne1> eg. parameter has type [IO a] (list of IO commands), result has type IO [a] (it is an IO command, and its return value has type [a])
11:16:49 <bierbaer> ok. thx.
11:16:51 <ne1> Example.  sequence [getChar, getChar, getChar] >>= print
11:17:05 <ne1> this will read 3 characters, then print them.
11:22:33 <wli> looks like %include directives
11:23:29 <bierbaer> if main has to be "IO" then the function at top must be print or something like that.
11:23:46 <ne1> Not necessarily.
11:23:49 <bierbaer> In my prog, sequence is the most upper function... and it works
11:23:58 <bierbaer> but sequence does not return IO
11:24:04 <ne1> IO [a]
11:24:05 <Cale> main simply has to be an IO action
11:24:11 <Cale> yeah
11:24:18 <Cale> m specialises to IO
11:24:22 <ne1> IO whatever will do. [a] is just as good as whatever
11:24:49 <ne1> main = getChar  this will also work.  IO Char
11:26:04 <ne1> of course by adjusting the meaning of "or something like that" you can be right.
11:26:44 <wli> okay, now I want exponents to show up like exponents instead of up arrows
11:27:00 <ne1> print 10, getChar, sequence [getChar, getChar] --- these are all examples of "print or something like that" under a suitable definition.
11:27:45 <jadrian> "Maybe *is* an instance of class Monad" or "Maybe *has* an instance of class Monad" ?
11:27:56 <ne1> is
11:28:05 <jadrian> ne1: thanks!
11:36:27 <wli> %format ^ = "^"
11:40:23 <wli> now to override the italic stuff which is very annoying
11:51:39 <Lemmih> GHC makes the impossible happen far to often.
11:55:04 <wli> lhs2TeX is really really close
11:55:29 <wli> basically a few %format's and some font cleanups fix it
11:56:56 <wli> not quite
11:57:05 <wli> the ^ hack doesn't work
12:05:26 <Lemmih> I think I found a bug in GHCs source...
12:07:36 <Lemmih> ghc/compiler/simplCore/Simplify.lhs, line 1504: "coreRefineTys tvs' (error "urk") ..."
12:08:59 <wli> piping through sed can handle the fonts
12:09:08 <Lemmih> but ghc/compiler/types/Unify.lhs, line 209: "coreRefineTys" performs a strict pattern match on its second argument.
12:09:21 <wli> some {-"{"-} and {-"}"-} comments can handle the rest
12:13:26 <wli> if there's a better way to deal with the Conid and Varid definitions in lhs2TeX that would help a bit.
12:26:23 <shapr> hiya Darius 
12:26:39 <Darius> heya shapr
12:30:34 <shapr> how's code?
12:31:43 <Darius> I still haven't gotten around to writing any, but with any luck I'll have persistence for the Joy implementation today.
12:50:38 <kosmikus> wli: mail me your questions re lhs2tex; I don't have time to look at it today, but I'll answer as soon as possible
12:53:58 <wli> kosmikus: what email addr?
12:57:02 <Philippa_> is there a working, sane SDL binding that's known to build under a win32 GHC installation using the default binary distro?
12:57:18 <Philippa_> IOW, something that I can just install without having to sacrifice things to satan and close friends?
13:59:06 <wli> I wonder if STArray and/or IOArray will get O(1) indexing semantics.
13:59:15 <wli> And similar for updates.
14:00:16 <Darius> will get?  They should have them.
14:00:29 <wli> then I'm happy
14:29:41 <Lemmih> O(1) updates for STArray?
14:31:45 <Darius> Lemmih: Are you asking if they have it? If so, yes.
14:43:30 <jadrian> are there any news on Manuel Chakravarty fast arrays for haskell?
14:43:47 <jadrian> he was working on them a few years ago
15:22:30 <Darius> Why is having a catch statement for an unthrown exception and error and not a warning in Java?
15:23:39 <vincenz> most likely cause it's dead code
15:23:47 <vincenz> though it could be a warning, you're right
15:24:04 <ibid> java has the tendency of making dead code warnings errors
15:24:47 <arjanb> it isn't dead code in bytecode
15:25:13 <ibid> arjanb: how so?
15:26:00 <arjanb> checked exceptions don't exist in bytecode
15:26:28 <ibid> that's true
15:26:46 <vincenz> how so?
15:26:56 <vincenz> and wouldn't the compiler not even make bytecode for the deadcode
15:27:44 <ibid> i suppose it's an error to avoid the situation where the compiler removes it as dead code and then the exception is thrown anyway
15:27:53 <Darius> vincenz: bytecode doesn't need to be the output of a compiler.
15:28:03 <ibid> or a java compiler
15:28:11 <Darius> ibid: Then the compiler can simpy not remove the dead code.
15:28:26 <ibid> Darius: that's beside the point
15:28:56 <vincenz> ibid: it was just a given that the exception will not be thrown
15:29:41 <ibid> Darius: if it were just a warning, then the compiler would probably still be allowed to remove it; if it took the code out, the programmer would be surprised
15:30:08 <ibid> vincenz: that assumes that all methods called by the code actually honor the exception contract
15:30:27 <ibid> anyway, i'm just guessing here. i'm not privy to what the java designers thought
15:31:33 <vincenz> ibid: it was just mentioned that making a catch statement for an unthrown exception is an error, hence such catch statement can not be there, hence such exception can not be thrown or it would be a warning but not an error
15:31:38 <vincenz> or they would be really stupid
15:31:51 <Darius> ibid: If "surprising" the developer is not acceptable, then it can just not eliminate the "dead code".
15:32:11 <ibid> vincenz: as was just mentioned, not all bytecode need not be produced by a conforming java compiler
15:32:33 <vincenz> well we were talking about a conformin gcompiler giving an error.
15:32:37 <ibid> Darius: i'm talking about the language designer's choices and possible motivations, not the compiler writer's
15:33:01 <ibid> vincenz: yes, but the code can still call code that has not been created by a conforming compiler
15:33:09 <vincenz> assuming less than standard compliancy does not allow us to talk about the language designer's intention
15:33:16 <ibid> vincenz: you're missing the point
15:33:26 <vincenz> how so?
15:33:37 <vincenz> though honestly I believe it's the other way around
15:33:43 <Darius> ibid: My statement still holds for the language designer, and depending on how stringently the errors a compiler is supposed to produce are defined, the compiler writer can change that (or at least add a flag to change it).
15:34:10 <ibid> vincenz: i don't think i can do much better than repeating what i've written above
15:34:34 <ibid> Darius: sure, the language designer could have ruled that dead code must not be eliminated
15:36:08 <ibid> vincenz: the point you seem to miss is that not all code in a jvm application need to be compiled by a java compiler; compilers for other languages are not bound to the java language specification
15:36:36 <vincenz> hmm
15:36:47 <vincenz> I assume however that it can be deduced what exceptions can be thrown by a simple scan
15:37:00 <ibid> vincenz: by who?
15:37:01 <vincenz> and such being the case, it can be known what exceptions to possibly expect
15:37:09 <vincenz> the compiler compiling the current catch statement
15:37:23 <ibid> vincenz: the compiler knows only what has been declared
15:37:34 <Darius> vincenz: Scan what? when?  The only time all the code is necessarily in one place is at run-time, it's too late to add a catch statement then.
15:37:41 <vincenz> hmm
15:37:54 <vincenz> ibid: the declared exceptions are written in the bytecode?
15:38:09 <vincenz> if so then I retract my statement and join Darius in his question, why make it an error
15:38:10 <ibid> vincenz: there is nothing in the jvm platform that enforces throws clauses, afaik
15:38:40 <ibid> why make it an error? as i said, i don't know, i offered one possible explanation
15:39:23 <vincenz> yes but doesn't that mean that if bytecode throws an unexpected error, you can not catch it anywhere?
15:39:46 <ibid> vincenz: yes it does
15:40:06 <ibid> vincenz: there is the other issue that the throwing code would be in breach of its contract in such a case
15:40:21 <ibid> vincenz: assuming that the java-side declaration isn't the one in error
15:41:12 <ibid> vincenz: i'm just saying that *if* removing dead code is allowed, then it is probably better to flag dead catch clauses as errors, given that java is supposed to run the same way everywhere
15:41:53 <ibid> now, we can debate whether it is allowed or a good idea to allow removing dead catches, but that's another matter ;)
15:42:36 <esap> There are two kinds of exceptions in Java, run-time checked and compile-time checked exceptions. I suppose dead catches can be detected only for the compile-time checked ones?
15:43:04 <ibid> what do you mean by run-time checked exceptions?
15:43:37 <esap> ibid: there is no need to propagate throws declarations for them.
15:44:00 <Darius> esap: checked and unchecked would be better terminology.
15:44:04 <ibid> esap: i wasn't aware they were checked
15:44:26 <esap> darius: you're right, it's not really checked :-)
15:44:50 <ibid> and i just tend to think that there's an implicit throws Error, RuntimeException in every method :)
15:44:58 <ibid> unifies the concept nicely
15:45:26 <esap> heh, probably it's implemented like that :-)
15:46:56 <ibid> certainly would make sense
15:47:08 <ibid> ... which doesn't mean it's actually done that way :)
15:50:06 <esap> Anyway, catching something when the code cannot raise the exception should IMO not be an error [you might be just preparing for the future].
15:50:32 <ibid> well, there is a simple way to work around it :)
15:50:43 <Darius> ibid: Yes. Don't use Java.
15:50:45 <ibid> though it's not very pretty
15:50:49 <ibid> Darius: that too
15:50:51 <esap> Yea, declare it in the interface.
15:51:21 <ibid> esap: add a private method that declares a throws for your method but doesn't actually throw it
15:51:34 <ibid> (in fact, it should be an empty method)
15:51:42 <ibid> then call it inside the try block :)
15:52:28 <esap> that's a strange workaround. Very interesting actually.
15:53:32 <ibid> if you're lucky, the compiler will inline the call
15:55:02 <esap> To me, that sounds like Java is trying to force people to write a layer for separating aspects specified in the interface from the actual implementation. Doesn't sound like a good idea.
15:56:28 <esap> I mean like wrapper layer that just forwards all methods, just for being independent of what exceptions are raised by the interface.
15:57:38 <ibid> hmm, i just had a disturbing thought
15:57:47 <ibid> i may have to add mutexes to activation records
15:58:38 <Darius> ibid: Why and what are you talking about?
15:58:50 <ibid> Darius: about ketchup, my lang design
15:59:34 <esap> ibid: ketchup? Nice name. :-)
16:00:01 <ibid> Darius: if two threads both call the same closure, there's a potential for concurrent access of a local variable
16:00:06 <Darius> ibid: Now you have to make it a successful language so that at one point someone will design Catsup.
16:00:12 <ibid> heh
16:00:32 <ibid> though i'm not sure why anybody would call a language catsup
16:00:55 <Riastradh> ibid, how does concurrent access necessitate mutexes?
16:00:59 <ibid> then again, i could forbid mutable local variables
16:01:11 <Darius> Yeah, we still have like 13 letters of the English alphabet remaining, and that's just sticking to the English alphabet.
16:01:30 <ibid> Riastradh: well, if at least one of the access is a non-atomic write
16:02:07 <esap> ibid: I think if you need lots of mutexes, there is already something wrong with the design.
16:02:17 <Riastradh> Oh, writes, not reads.
16:02:50 <ibid> esap: well, lots of mutexes is often better than a single mutex
16:03:07 <esap> ibid: yes, but both are worse than having no mutexes.
16:03:25 <ibid> esap: yeah, but that's not really possible in a shared-memory concurrency scenario
16:03:34 <Riastradh> Why not have the programmer manage his own synchronization?
16:03:36 <ibid> i'm actually using monitors
16:03:50 <ibid> but mutexes are the implementation mechanism
16:04:02 <Riastradh> You could provide mutexes if you like; you could also provide optimistic concurrency & logging variable readers/writers.
16:04:12 <esap> ibid: you could have a single-access policy on your shared memory.
16:04:21 <ibid> Riastradh: and abortable transactions...?
16:04:25 <ibid> esap: which means?
16:04:45 <esap> ibid: I mean, you have a token that you will pass between the parties, and only if you have the token, you can read/write.
16:05:00 <ibid> ketchup does provide for message-passing too
16:05:16 <ibid> (the rendezvous kind)
16:05:26 <ibid> esap: that amounts to having a global mutex
16:05:28 <Riastradh> ibid, sure, why not?
16:05:49 <ibid> Riastradh: that's an idea for some other language :)
16:06:02 <ibid> would work beautifully in a persistent language, actually
16:06:13 <Riastradh> What prevents it from being offered in your language?
16:06:21 <ibid> (i have one in preparation, swapped out currently - called celery)
16:06:23 <Riastradh> It's not a fundamental language design change or anything.
16:06:40 <ibid> Riastradh: if it can be offered by a library, nothing
16:06:46 <esap> ibid: not quite, though perhaps it means you need to combine message passing and shared memory.
16:06:59 <Riastradh> Well, it can't be offered by a library if it can manage closure slots.
16:07:01 <esap> ibid: which might be worse :-)
16:07:10 <ibid> Riastradh: hmm?
16:07:27 <Riastradh> Unless you have low-level access to the representation of closures.
16:07:40 <ibid> Riastradh: i mean, if the interface can be offered as a library. i have no problems with libraries tapping into compiler magic
16:07:45 <Riastradh> It's also very hard to implement efficiently & effectively if not at the lowest level.
16:08:00 <Riastradh> Oh, OK.
16:08:22 <ibid> oh well, let's show this here too: http://antti-juhani.kaijanaho.info/ketchup/
16:09:04 <ibid> (i'm drafting in my head a change in the type system, not reflected there yet)
16:09:30 <esap> nice "a module is a sequence of characters" :-) I would call that a 'string' :-)
16:09:56 <ibid> that is what i said, is it not? </data>
16:13:17 <esap> what's this 'async' thing in data type declarations?
16:13:57 <esap> interesting hmm..
16:14:18 <esap> to me it sounds like an implementation detail.
16:14:29 <ibid> the data type declarations thing will be redesigned
16:14:34 <Darius> ibid: Is there any example showing Ketchup doing something well that most languages don't?
16:14:51 <ibid> there aren't much any examples :)
16:15:02 <ibid> what there are are in the boot/test directory
16:15:29 * esap should write a specification for my language [other than the parse tree structure].
16:15:43 <ibid> esap: async is in the category of inline and register (as in C)
16:16:23 <ibid> esap: hints to the compiler that it can ignore but which in some situations may increase performance, or at least make the programmer feel being in control ;)
16:17:22 <esap> ibid: ok; I would separate those things from data type declarations [because you need to separate interface and implementation details].
16:17:42 <Darius> ibid: Are the type rules for switch in the "specification"?
16:18:57 <ibid> esap: i'm going to gut the data type declarations into two parts: a proper immutable algebraic data type package along the style of haskell records and a separate monitor concept that allows making altys mutable in actuality
16:19:05 <ibid> Darius: not in any formal sense, no
16:19:56 <ibid> however, there isn't that much to specify about it, and there is an informal type rule set
16:23:00 * ibid just now dicted catsup and now gets it
16:23:25 <Darius> ibid: Okay, I'm wondering how (or if) it typechecks uses of a case-analyzed variable.  I.e. what happens if you do: switch(e) { case nothing: e.datum; }?
16:24:31 <ibid> if you rewrite that into ({ switch(e) { case nothing: value e.datum; } }) it'll make sense, first of all :)
16:25:25 <ibid> the type of that expression is the type of e.datum, but you'll get a run-time error (and, if the compiler is smart enough, compile-time error)
16:36:53 <esap> what's the category theory notion that corresponds to type class constraints?
16:37:33 <Darius> esap: There isn't an immediate one.  It depends on how you formalize them.
16:38:21 <esap> darius: ok, I suppose I need just one that can be used to formalize it.
16:39:12 <ibid> Darius: i'm curious. what made the above question interesting to you?
16:39:25 <Darius> Well that depends on how you formalize terms and types?
16:39:46 <Darius> ibid: The one related to typechecking switches?
16:40:33 <ibid> yeah
16:40:52 <esap> darius: types map to objects. Terms map to arrows.
16:41:31 <Darius> ibid: My impression (for some reason) was that you didn't type check it (after looking at the maybe example) and I think it is not very difficult to do.
16:42:24 <Darius> esap: Simple typing then?
16:42:29 <ibid> Darius: hmm.  what did you have in mind?
16:43:26 <esap> darius: what do you mean?
16:43:30 <Darius> ibid: I'm not sure whether the seemingly obvious approach of changing the type of the analyzed expression in the scope of the case would work.
16:44:00 <Darius> esap: If types are objects, you don't (immediately) have polymorphic types.
16:44:29 <ibid> Darius: you mean something like making e stand for e.datum in case just:?
16:44:31 <Darius> ibid: Looking at the pattern calculi may also help.
16:44:45 <esap> darius: ok, true. I'm doing polymorphic types also, but they're not mapped to objects.
16:44:46 <ibid> Darius: ref?
16:44:48 <Darius> ibid: No, just having e have a different type in the cases.
16:45:06 <ibid> Darius: ah, ok
16:45:35 <ibid> Darius: yeah, that's the "if the compiler is smart enough" part. i'll consider making it mandatory, but not now
16:46:50 <Darius> http://www-staff.it.uts.edu.au/~cbj/patterns/ is one approach, Googling "pattern calculus" or some such will likely turn up others.
16:47:48 <ibid> however, ketchup is expressedly not an experimental language :)
16:48:50 <Darius> ibid: Well, Java 1.5 also has a feature along those lines and I'm wondering how they handle type checking.
16:49:25 <ibid> Darius: feature along those lines?
16:50:58 <arauko> Can i write to a file opened with ReadMode?
16:51:13 <ibid> arauko: why would you want to?
16:51:33 <arauko> ibid, i mean, im just reading an exmaple, and im confused, i don't know if it is wrong.
16:51:34 <ibid> arauko: presumably you opened it in ReadMode to read, not to write stuff from it?
16:51:39 <arauko> let me paste it somewhere
16:51:50 <arauko> yes, thats what i think
16:51:56 <Darius> ibid: http://java.sun.com/j2se/1.5.0/docs/guide/language/enums.html
16:52:39 <arauko> http://paste.lisp.org/display/4638
16:52:43 <arauko> that is it
16:52:48 <Darius> esap: Well, what are you thinking so far?  I haven't yet given it too much (uninterrupted) thought.
16:53:17 <ibid> Darius: i don't see anything out of the ordinary wrt standard enums in there in a quick look?
16:53:54 <esap> darius: My current thoughs is that type class constraints would map to constraints in  universal and existential quantification. But the details are not easy, because that would mean I would need to find something similar from substitution, and I don't see it.
16:55:58 <arauko> Anyone knows?
16:57:21 <ibid> arauko: that looks like a simple thinko on the part of the writer
16:57:36 <ibid> arauko: probably should be WriteMode
16:57:53 <Darius> ibid: Consider the Planet example and the 'constant-specific methods'.  Though it's not clear how flexible Java is here.
16:58:35 <arauko> ibid, yes, thats what i think either
16:58:35 <ibid> oh, missed that completely
16:58:40 <ibid> yes, that looks like interesting :)
17:00:01 <ibid> but i'm not exactly sure if that has any interesting typing problems :)
17:00:37 <Darius> ibid: From the examples it shows, it doesn't look like it.  If it's more flexible it may (assuming Java actually tries to solve them).
17:01:39 <esap> darius: The link to substitution comes from the adjunction connecting substitution and universal and existential quantification. I think the missing part is somehow related to the propagation of the constraints and how the constraints bind the names declared in the type class [dictionaries], but the details are not clear to me.
17:01:49 <ibid> Darius: anyway, i'm going to revamp the data type stuff, as specified it doesn't allow me to do stuff i wanted to do with it
17:02:39 <Darius> esap: My current thoughts are along treating constrained terms as type-indexed families of functions.
17:03:02 <ibid> Darius: trying to unify monitors and algebraic types into some kind of amalgam between pascal variant records and oo classes just doesn't cut it
17:03:10 <esap> darius: natural transformations?
17:04:08 <Darius> esap: Methods of type classes are immediately type indexed families, and I think even functions that use type-class methods can be viewed as type-indexed families, but that might require constraints to form a lattice.
17:04:39 <Darius> esap: I don't think (raw) natural transformations would work, the overall transformation is likely not natural.
17:05:16 <Darius> I'm thinking indexed-categories/fibrations may be more appropriate.
17:05:25 <Darius> But those seem too global.
17:07:46 <esap> darius: I need to think about that, it seems reasonable, but then I'm not any more sure how duality works there.
17:07:48 <Darius> ibid: What is something you want to do?
17:08:41 * shapr boings tiredly
17:09:07 <Darius> shapr: I do now have first-pass not very space-efficient persistence for the Joy imp.
17:09:54 <ibid> Darius: first of all, it's a nasty thing that the case labels can only be used in friend functions
17:10:22 <ibid> Darius: it makes ordering be a magical type
17:14:26 * vincenz boings shapr around the roo
17:14:30 <vincenz> ..m
17:18:38 <esap> darius: Another thought that I had about type class constraints is that they might be related to the common object of a pullback. But how the constraint applies to it is not at all clear.
17:20:34 <vincenz> the pullback is the maximal typing info that is shared by all constraints
17:20:50 <vincenz> ?
17:22:27 <Darius> esap: If the arrows are terms and objects types, there is no way the pullback diagram is going to commute, nor is it clear which arrows you are going to pullback.
17:23:21 <Darius> If you mean pullbacks of the constraints to make compound constraints, then that's a different issue.
17:25:17 <esap> darius: the arrows to pullback would be coercions from the type class variables to the dictionary type.
17:26:23 <esap> darius: but actually, then my description would be wrong, it would be that type class variables are domains of those arrows, not codomains :-(
17:27:20 <esap> darius: so the common object of the pullback would be the dictionary. But which one is the constraint actually associated with?
17:28:12 <arauko> in this example, http://paste.lisp.org/display/4638 , what are the values of 'h' and 'c' in the lambda function?, how do they get their values?
17:28:38 <esap> darius: well the details are not very clear in my mind.
17:28:43 <arauko> the 'h' is supposed to be a file handler and 'c' a char, but i don't see how they get those values.
17:30:14 <Darius> arauko: Are you familiar with higher-order functions?
17:30:44 <arauko> no... actually im still trying to grasp at that idea.
17:30:54 <arauko> is it what it is happening there?
17:32:17 <Darius> That and lexical scoping.  The c comes from the argument to writeChar, the h will be passed a handle by bracket, the expression (\h -> hPutChar h c) is a function that is being passed to bracket.
17:33:13 <arauko> Ok, i see now that 'c' comes from lexical scoping. 
17:33:20 <arauko> it is true.
17:33:53 <arauko> how is that 'h' will be passed a handle by bracket?
17:36:37 <esap> arauko: because openFile returns a handle and bracket just passes that to both functions?
17:37:38 <arauko> yes, good, i wanted to be sure it worked that way.
17:37:56 <esap> arauko: bracket :: forall a b c. IO a -> (a -> IO b) -> (a -> IO c) -> IO c, it's actually obvious from the signature.
17:40:50 <arauko> esap, hah, really not so obvius for me.
17:41:47 <esap> arauko: ok, the first argument to bracket, e.g. 'openFile fp ReadMode' must have type 'IO a' for some choice of 'a' due to the type of bracket.
17:42:33 <arauko> Ok.
17:42:45 <esap> arauko: and since openFile :: FilePath -> IOMode -> IO Handle, then 'openFile fp ReadMode' must have type 'IO Handle'.
17:43:23 <esap> arauko: where you can see that 'a = Handle'. So in this situation, bracket must have type  IO Handle -> (Handle -> IO b) -> (Handle -> IO c) -> IO c
17:44:04 <arauko> yes
17:45:11 <arauko> Oh, i get it
17:45:12 <esap> arauko: The second argument, therefore, has type 'Handle -> IO b' [e.g. hClose has this type]. And third argument "\h -> hPutChar h c" has type 'Handle -> IO c', directly from the signature. Right?
17:45:27 <arauko> yes
17:45:49 <arauko> nice explanation
17:45:56 <arauko> Thanks esap
17:50:17 <Darius> esap: You could always just identify constrained functions with their dictionary passing counterparts.
17:50:53 <Darius> esap: You'd only need to explicate the dictionary passing, which you may be able to handle in a Kleisli category.
17:52:41 <TheHunter> good evening, everybody
17:53:06 <esap> darius: Good idea. I think that was the approach actually used in one of the papers I read.
17:53:59 <esap> darius: But somehow it would be better if I didn't have to do a translation from explicit dictionaries to implicit dictionaries. I think the translation is not very simple.
17:55:27 <esap> darius: And I need to read about the Kleisli category more [I've seen it mentioned, but never actually read details about it, unless it means the kleisli arrow stuff?]
17:56:50 <Darius> esap: Being "in a monad" (in Haskell programming) so to speak, is roughly the same as working in the Kleisli category of the monad.
17:57:47 <Darius> esap: It would seem that you would need the translation from implicit to explicit more, of which the most complicated part would be the actual plumbing of the dictionaries.
17:58:30 <Darius> esap: Going the other way, (assuming we got where we are currently from some translation) should be pretty simple.
17:58:36 <esap> darius: of course, true. I wrote those in wrong way, obviously the conversion is from implicit to explicit.
18:02:29 <esap> darius: it might actually be possible to think of the constraints as syntactic sugar. But the structure of the constraint still needs to be understood there.
18:03:41 <Darius> esap: I was thinking, if you want to use something like the environment monad, you would still need some understanding of the constraint types because the type of the environment (looks like it) will be constantly changing.
18:04:16 <Darius> esap: I think you'd need a class-indexed product perhaps.
18:05:07 <Darius> No, even that's too coarse, as you may need multiple dictionaries for a single class.
18:17:05 <esap> darius: I think the semantics has to consider the fact that type class constraints are constraints on type variables, not on types. Maybe you can think of it as a 'type' of a type variable [as opposed to the value of the type variable, which is also a type]
18:19:38 <Darius> esap: Yes, I was thinking about that.  Though also, you only need one, Ord_Int dictionary no matter how many type variables resolve to Int.
18:20:00 <Darius> I was thinking a class/type indexed product would do it.
18:21:14 <Darius> I'm also wondering what type of product it should be as the order it's components are used is irrelevant.
18:22:49 <esap> darius: what would be the components of the product. I just realized there might be more than one choice for that :-)
18:23:02 <Darius> esap: The dictionaries.
18:24:28 <bourbaki> moin
18:26:04 <esap> darius: ok. The other alternative I was thinking about involved products where the operations of the class were components.
18:26:31 <bourbaki> hey esap
18:26:39 <esap> bourbaki: hi
18:26:55 <bourbaki> didnt anyone in here had a colelction of algebra classes?
18:27:33 <bourbaki> esap: i think i need something like macros in lisp for the classes i want to generate where i can dynamicly define classes
18:27:48 * esap has more than one collection of classes that could be called 'algebra classes' :-)
18:27:48 <Darius> esap: Dictionaries are products indexed by the operations of the class.
18:28:50 <bourbaki> esap: i need the basics and such like group and so
18:29:09 <bourbaki> or maybe a little help on things like the assoc law in groupd and such what would be the right way to wrap that in a class?
18:29:22 <Darius> esap: I was also thinking, since I'm sure you'd like this, the translation from constrained types to explicit dictionary passing should be an adjoint.
18:30:16 <Darius> Or rather, there should be an isomorphism of hom-sets, I'm not sure about the naturality of the translation going the other direction.
18:30:49 <bourbaki> Darius: what are you talking about?
18:31:06 <Darius> bourbaki: Categorical semantics to type classes.
18:31:49 <bourbaki> i see id like to get an introduction to the type class things where can i get a quick read on it with math?
18:33:54 <Darius> bourbaki: I don't think I've ever read it, but Wadler's early paper on type classes might be best, "How to Make Ad-hoc Overloading less Ad-hoc" I think the title is (pretty sure it's wadler too).
18:34:38 <esap> Also Jones: A system of constructor classes: overloading and implicit higher-order polymorphism has some additions.
18:34:46 <bourbaki> so how can i do something like associativity?
18:35:00 <Darius> bourbaki: With type classes?
18:35:15 <esap> bourbaki: You can't do it with type classes really, at least not currently.
18:35:38 <bourbaki> hm
18:35:41 <bourbaki> a pitty
18:35:54 <bourbaki> so i just added a function that takes up all the functions and so
18:35:58 <esap> bourbaki: I've written lots of those constraints in comments because there is no way to be explicit about it.
18:36:14 <Darius> esap: Have you ever looked at OBJ3?
18:36:17 <bourbaki> i just thought to use something like a function for it
18:36:24 <bourbaki> like assoc_mul or so
18:36:24 <Darius> Actually I'm pretty sure you have.
18:36:24 <esap> darius: no, what is it?
18:36:46 <Darius> esap: Google might pop it out, adding Goguen might help if it doesn't.
18:38:11 <esap> ah yea, I've read something about it.
18:38:18 <esap> I didn't realize it was that :-9
18:38:53 <bourbaki> so esaphow do you model assoc and such in your cat stuff?
18:39:22 <bourbaki> maybe i should write something that interprets functions to build a slight mod to the classes
18:39:24 <esap> bourbaki: with diagrams that commute.
18:40:11 <bourbaki> esap: but you cant use it on an expression can you?
18:41:13 <bourbaki> i would need something like that for derivation and integration of functions also
18:41:32 <esap> bourbaki: well I've not designed that part of the language yet, but I've been thinking about ways to control in a commuting diagram which representation would be normal form. But It's at concept level, no details done.
18:43:07 <bourbaki> id really like to have something like this enhanced classes and interpreted functions for derivation
18:43:50 <bourbaki> theres this french guys paper on the derivation thingy it would be so cool to do this differential manifold thing from scratch with the class system
18:44:08 <esap> bourbaki: which paper?
18:45:30 <bourbaki> esc
18:45:32 <bourbaki> sec
18:47:15 <bourbaki> esap: http://users.info.unicaen.fr/~karczma/arpap/
18:47:19 <bourbaki> Functional Differentiation of Computer Programs,
18:49:11 <Darius> Ah, good 'ole Jerzy Karczmarczuk.
18:50:54 <bourbaki> why isnt there a lib for that kind of stuff?
18:54:03 <esap> there was some algebra library I read about a long time ago that was supposed to replace prelude Num stuff, I don't know what happened to it.
18:54:17 <esap> Maybe it had derivates etc.
18:54:44 <bourbaki> someone in here once gave me an algebra lib with rings and fields and things alike
18:54:56 <esap> yea, sounds like it.
18:55:28 <Darius> esap: There was the Basic Algebra something or other proposal, which wasn't very well received and there's Docon which is that general vicinity.
18:55:44 <bourbaki> dang who was it?
18:56:18 <bourbaki> it would be so cool to build anything from scratch for my meshes and such
18:56:23 <esap> darius: yea, I think I remember the Basic algebra proposal
18:57:09 <bourbaki> cause all you would need to do is define a vector space and you could do some nice things with tologlogical algebras
18:57:25 <Darius> http://www.haskell.org/docon/
19:00:52 * esap has to get some sleep [it's 5am :-) ]
19:01:07 <bourbaki> nighto
19:01:32 <Darius> esap: I'll think of how to make that adjunction (though I'd have to define a category of constrained types to do it).
19:02:09 <esap> darius: category of constrained types? hmm..
19:02:44 <Darius> esap: The thing we were trying to define at the beginning.
19:02:57 <esap> darius: Actually, at one point I was thinking of using a separate category for each type class.'
19:03:51 <Darius> esap: Yes, indexed categories would also produce multiple categories.  Though in the end you'd want to be able to put the into one coherent thing.
19:04:05 <Darius> esap: Though perhaps enriched categories might be the way to go.
19:04:50 <Darius> Anyways, I had some ideas about making the back translation from explicit to implicit natural by separating dictionary parameters from other parameters.
19:06:11 <esap> you could also give dictionaries a distinct type to make them easy to distinguish from other parameters [supposedly those are not used elsewhere than for passing the dictionaries]
19:07:43 <esap> but ok, I need to sleep, I'm so tired I can hardly think this stuff :-)
19:29:53 <wagle> is there still a "ski" in this channel?
19:31:26 <wagle> anyone know anything about anarchic algebras?
19:32:01 <wagle> i google, and get mostly nothing, except some excerpts from a #haskell log..  8)
19:34:31 <Darius> wagle: Yeah, ski still seems to be here, though it seems less than he was a long time ago (or perhaps I'm on a different schedule than I was then).
19:35:08 <wagle> the log was from last february..  thought he might go by a new name
19:36:52 <Darius> wagle: As far anarchic algebras, he likely meant lawless ones (i.e. ones satisfying no equations).
19:39:31 <Darius> wagle: The mathematical term should be "free".
19:39:50 <wagle> yeah..  Pierce's little category theory book (1992?) makes a brief remark about F-algebras only being studied with no equalities..  i wonder'ed if anything had changed since then..  (he referred to them as anarchic algebras) 
19:40:06 <Darius> Well, somewaht (re my last remark).
19:40:13 <wagle> yeah..  i wondered why not just called free
19:40:51 <wagle> hence thought the word anarchic might be different than free
19:41:08 <wli> "free" == relation-free
19:41:14 <Darius> The issue might be that you can speak of a free monoid which means something that satisfies only the monoid laws.
19:41:34 <Darius> But a monoid is not anarchic.
19:43:12 <wagle> where is this use of anarchic defined?
19:43:49 <wagle> .. the word "anarchic"...  [that is]
19:45:26 <Darius> I've never really seen it used much for this.  I think lawless or equationally-free is more common, but even they don't seem to turn up many hits from google.
20:00:23 <CosmicRay> well.  I've finally read "Hitchhiker's Guide to the Universe".
20:00:24 <CosmicRay> great book.
20:00:39 <CosmicRay> seems rather haskellish in a way.
20:01:09 <CosmicRay> an infinite improbability drive that can visit every point in the universe seems somewhat like a haskell function that can operate on an infinite list :-)
20:01:14 <Darius> Yeah, I read the series a bit back.  However, I was underwhelmed.  
20:01:53 <wagle> CosmicRay: the original radio show was the best version
20:02:00 <Darius> They were good, but not as good as I was expecting. (Though, I did have very high expectations).
20:02:19 <CosmicRay> wagle: hmmm, is that available for downloading anywhere?
20:03:27 <wagle> dunno..  i was very surprised to find it on casette tape about 8-10 years ago, but not sure the dvd is the same
20:03:41 <Darius> I do have to agree with my friend though, that the author writes similarly to how I talk.
20:04:05 <wagle> getting kicked out of the coffee shop (8pm)..
20:05:11 <wagle> there was also a book of the original scripts..
20:05:23 * wagle is gone
20:05:53 <Darius> 8pm?  My friends and I usually got kicked out of Starbuckses around 9-11pm.
20:09:08 <Lemmih> GHC only supports Cabal packages now?
20:11:41 <Lemmih> That's so cool.
23:52:51 * boegel waves
