02:32:33 <shapr> d00d
02:35:15 <tintin> haskell has gone dead for new year day ...
03:14:24 <shapr> I thought new year's day is two days from now?
03:15:46 <arauko> Tue Dec 28 07:14:16 VET 2004
03:15:57 <arauko> 3 days here
03:15:58 <arauko> :-)
03:16:03 <arauko> hello shapr
03:17:36 <shapr> greetings
03:17:47 <ac_mac> la la la
03:20:20 <arauko> shapr, got some free time?
03:20:37 * arauko needs somebody with good datatypes knowledge
03:21:36 <Cale> arauko: what do you need to know?
03:24:06 <arauko> Cale, trying to understand data types.
03:24:27 <arauko> i mean, i got something like: data Pair a b = Pair a b
03:24:36 <Cale> okay
03:25:16 <Cale> The "Pair" on the left is the name of the type, and a and b the parameters to the type.
03:25:19 <arauko> The name of the datatype is Pair with two parameters, and the constructor of the datatype has the same name, specifying the same two parameters.
03:25:26 <Cale> right
03:25:30 <Cale> in the same order
03:25:32 <arauko> But i don't see how that datatype can be used?
03:25:38 <Cale> hm?
03:25:53 <Cale> (Pair 3 "Hello") :: Pair Int String
03:26:47 <Cale> Pair is actually a type constructor -- you might think of it as a function which builds types based on parameters which are types.
03:27:44 <arauko> Ok, for example, if i do this: let y = Pair 5 6
03:27:54 <arauko> How do i use those two values?
03:28:02 <Cale> hm
03:28:05 <wilx> Hm.
03:28:08 <wilx> Pattern matching.
03:28:11 <Cale> f (Pair a b) = a
03:28:18 <Cale> g (Pair a b) = b
03:28:27 <Cale> you can pull them back out
03:28:30 <arauko> Ah.
03:28:55 <arauko> hah, i see now
03:28:58 <arauko> Thanks.
03:31:39 <arauko> And if, i have a function which return Pair a b, i can assign the return value like this: x :: Pair a b = f (Pair a b) 
03:31:40 <arauko> ?
03:33:09 <Cale> hmm... I'm not sure I understand that syntax
03:33:33 <Cale> You can return a Pair simply by defining the result as one
03:33:53 <arauko> in the type signature right?
03:34:24 <Cale> i.e.
03:34:39 <Cale> dup :: a -> Pair a a
03:34:45 <Cale> dup x = Pair x x
03:34:54 <Cale> er, e.g. rather :)
03:35:08 <arauko> ah, ok thanks
05:37:14 <zamez> I want to improve the error handling in my parser to show the line number of the error
05:37:28 <basti_> hmm
05:37:35 <zamez> but since I'm lazy, I don't want to modify the tokeniser & parser to record the line numbers
05:37:44 <basti_> you would need to attach that line number info to the tokenizer output.
05:37:44 <zamez> at the moment I have code like this:
05:37:53 <zamez> (print . process . parser . alexScanTokens) s
05:38:10 <zamez> ok
05:38:17 <basti_> doesnt have alex an option for that?
05:38:51 <zamez> or would it be possible to put some kind of "flowmeter" between alexScanTokens and s, which would keep count?
05:39:19 <basti_> hmm just let alex catch newlines and output then
05:39:37 <basti_> and then?
05:40:03 <vincenz> the best way is to make your tokens include that info
05:40:11 <vincenz> ormally it's the lexer passing this info
05:40:15 <vincenz> +n
05:40:26 <basti_> i guess too that this would be the standard way
05:40:35 <basti_> thats what i learned in compiler theory
05:40:49 <vincenz> just ... well this is haskell so I don't know, but in general you keep a letter and line counter
05:40:58 <vincenz> on newline x=0, y=y+1
05:41:08 <vincenz> on reading, x += tokenlength
05:41:25 <basti_> yup
05:41:37 <basti_> and then attach current x and y values to every token munched
05:41:46 <vincenz> yip
05:41:54 <zamez> looks like alex does have support
05:42:04 <zamez> but I'll have to modify the tokens
05:42:14 <basti_> just their interpretation
05:42:23 <basti_> sounds like a call for map
05:42:27 <vincenz> zamez: not much, just keep your tokens and make tuples
05:42:33 <vincenz> (token, x, y)
05:43:03 <zamez> yep
05:43:49 <vincenz> then of course the info between parser and process might need the same sort of annotation
05:43:55 <vincenz> so your parser will need some work
05:44:32 <zamez> yeah
05:50:26 <vincenz> Question about category theory.  How does one represent multi-parameter functions in category theory?
05:52:26 <tuomov> depends on how you model things?
05:52:44 <vincenz> well if you want to consider a group G as a category
05:52:50 <vincenz> and want to look at *
05:52:59 <vincenz> a*b -> c
05:53:29 <tuomov> and G is an object of that category?
05:54:05 <tuomov> in that case you would require the existence of GxG as well and so on
05:54:20 <vincenz> no I want to look inside G
05:54:22 <vincenz> G is the category
05:54:33 <vincenz> s the elements are the objects
05:54:41 <vincenz> -s
05:55:18 <vincenz> but in any case, let's say we do as you say
05:55:20 <vincenz> but we generalize
05:55:26 <tuomov> well, I'm not familiar with such a model of groups, but perhaps you would also need to products of each elements
05:55:29 <vincenz> A*B-> 
05:55:31 <vincenz> C
05:55:42 <tuomov> s/to/the
05:55:55 <vincenz> and you have X->A and Y->B
05:56:03 <vincenz> how would you couple these arrows?
05:56:10 <vincenz> you can't go from A and B to AxB
05:56:18 <vincenz> cause arrows take one input
05:58:26 <basti_> i would model multiparameter functions as curries btw.
05:58:46 <vincenz> ok
05:58:55 <vincenz> I'm readig the pierce book on categorical theory
05:58:58 <vincenz> but I find it a bit terse
05:59:03 <basti_> :)
05:59:15 <vincenz> (especially given the fact that my background is EE ad we never had set theory and the lieks)
05:59:37 <vincenz> any suggestions as to other reading material?
05:59:39 <basti_> hmm
05:59:58 <basti_> i have a book in german.
06:01:02 <TheHunter> vincenz, if you interpret a group as a category, you usuall have one object and the morphisms are the group elements.
06:01:28 <vincenz> yes I read that, though I was not quite sure what exactly the element wuld be 
06:01:38 <vincenz> "int" for Z?
06:01:48 <TheHunter> vincenz, doesn't matter
06:01:53 <vincenz> oki
06:02:41 <TheHunter> Z has one object a and for each integer a morphism f_i : a -> a
06:02:54 <TheHunter> where f_i . f_j = j_(i+j)
06:03:16 <vincenz> yeah, he mentioned that, consider * or + as concatenation
06:06:23 <TheHunter> your question is about how f: C -> A and g: C -> B form a function <f,g>: C -> A * B ?
06:07:05 <vincenz> hmm
06:07:14 <vincenz> that makes it clearer
06:07:46 <TheHunter> it's pretty much the definition of the product.
06:08:23 <basti_> hm
06:08:25 <vincenz> however, itnos C->A*B
06:08:47 <vincenz> it's X->A and Y->B
06:08:58 <vincenz> itnos = its not
06:08:59 <basti_> i'd rather say he has f: G -> G -> G
06:09:02 <vincenz> anyways, I gotta run, people are waiting for me
06:09:13 <vincenz> I shall be back later and read backlogs 
06:09:16 <basti_> you could see it as G x G -> G too, though
06:09:25 <vincenz> later and thx
06:10:05 <tuomov> iirc some yoneda lemma corollary says that this can always be done
06:10:18 <tuomov> or at least when some things are small
06:11:29 <tuomov> in a sense, of course; you don't have "g -> g -> g" in the category itself
06:12:52 <zamez> ok, I've got it giving the line number
06:13:07 <zamez> I replaced Token with (Token, AlexPosn)
06:13:40 <zamez> how about getting it to print the line with the error?
06:13:54 <zamez> I won't bother if it's too complex
06:15:46 <tintin> @type (zipwith)
06:15:51 <lambdabot> bzzt
06:16:20 <TheHunter> @type zipWith
06:16:22 <lambdabot> zipWith :: forall c b a. (a -> b -> c) -> [a] -> [b] -> [c]
06:17:06 <tintin> tnx TheHunter 
07:07:38 <Lemmih> Stupid indecisive overloading!
07:09:09 <Lemmih> shapr: Ping.
07:11:06 <esap> indecisive?
07:12:20 <Lemmih> C++ style overloading is a bitch in Haskell.
07:12:39 <esap> Haskell doesn't have C++ style overloading.
07:12:55 <Lemmih> Exactly.
07:12:59 * esap thinks Haskell doesn't need it either.
07:14:06 * Lemmih is working on a framework for automatic generation of bindins to C++ libraries.
07:14:09 <esap> C++ style overloading relies too much on the notion that return types are always dependent on just the parameter types.
07:17:26 <ozone> Lemmih: fundeps?
07:19:17 <Lemmih> ozone: class OverloadNew args result | args -> result where new :: args -> result <-- that is not gonna work.
07:19:57 <ozone> i use it frequently.  what's bugging you about it?
07:20:50 <Lemmih> How would you implement new for e.g. (Int -> IO Int)?
07:21:02 <Lemmih> return . id
07:23:12 <Lemmih> I'm pretty sure SPJ would be interested if you have a working model.
07:23:13 <ozone> instance OverloadNew Int (IO Int) where ...
07:25:07 <Lemmih> And (Int -> Int -> IO Int)?
07:25:18 <ozone> instance OverloadNew (Int -> Int) (IO Int) where ...
07:25:38 <esap> ozone: the last one doesn't work for sure.
07:25:49 <Lemmih> That would be :: (Int -> Int) -> IO Int and not :: Int -> Int -> IO Int
07:25:53 <ozone> grumble, where's oleg's message ...
07:25:55 <esap> ozone: should be pair of ints
07:28:11 <esap> C++ style overloading is very hard to simulate, because it interacts in very strange ways with C++ conversion rules, templates and name lookup. These are in total pretty complex beasts.
07:28:20 <ozone> there:
07:28:21 <ozone> http://www.haskell.org/pipermail/haskell/2004-February/013710.html
07:28:53 <ozone> also has some commentary on C++
07:28:56 <ozone> (for good measure :)
07:30:23 <ozone> note: i don't advocate oleg's solution -- if you read the entire thread, you'll see why. nevertheless, it can be done ...
07:32:47 <ozone> in particular, http://www.haskell.org/pipermail/haskell/2004-February/013697.html
07:33:14 <ozone> of course, lots of people disagree with me, on the usual "OO is baaaaaad" reason
07:34:26 * esap doesn't think OO is bad. It's just different.
07:35:01 <esap> But the module system already provides qualified name support.
07:35:52 <ozone> indeed, which is bloody useful
07:36:10 <esap> true, what we don't have is first-class modules.
07:37:13 <esap> existential types are almost it already, but not quite.
07:38:07 <ozone> esap: did you see oleg's post on first-class modules in haskell via existentials? :)
07:38:10 <ibid> OO is not bad, but it's misused more often than not :)
07:38:36 <esap> ozone: when was that? It's possible I've seen it, but can't remember now.
07:39:08 <ozone> 2http://www.haskell.org/pipermail/haskell/2004-August/014463.html
07:39:12 <ozone> http://www.haskell.org/pipermail/haskell/2004-August/014463.html
07:39:31 <ozone> my brain melted about 3 sentences into that post
07:39:40 <Lemmih> Igloo: Ping.
07:39:57 <Igloo> pong
07:40:55 <Lemmih> Igloo: TH can't desuger type classes with functional dependencies?
07:41:13 <Igloo> I thought it could, in the head at least
07:41:34 <ozone> i'm fairly sure it could
07:41:38 <ozone> (even in 6.0)
07:43:06 <Lemmih> I'm having problems with GHC 6.2.2.
07:46:08 <esap> ozone: ok, I remember that translation of ML style first-class modules into Haskell. I was horrified with all the type annotations and casting in it :-)
07:47:02 <esap> ozone: At minimum, it would need some syntactic sugar to work.
07:49:20 <Lemmih> So what would the Dec look like for a class with functional dependencies?
07:52:24 <ozone> Lemmih: i usually just put the type into ghci and dump it
07:52:29 <ozone> let a = [t| ... |]
07:52:49 <ozone> and use ... i forget, runQ/show/pretty-printing functions to view it
07:59:36 <shapr> Lemmih: pong
08:02:49 <Lemmih> shapr: I would like you to host yet another Haskell project.
08:04:59 <ac_mac> shaprforge.net
08:05:13 <ozone> ac_mac++
08:05:46 <Lemmih> ozone: Yes but (runQ [d| class Test a b | a -> b |]) => "Warning: Cannot desuger this Template Haskell declaration".
08:06:36 <ozone> just double-checking: you're using -fglasgow-exts, right?
08:06:44 <ozone> otherwise, sorry, don't know.  (points to igloo)
08:07:32 <sam_> what's this Fw?
08:08:52 <Igloo> Works in -cvs but not 6.2.2
08:09:01 <Lemmih> Oh.
08:11:30 <Lemmih> shapr: darcs repo at http://212.242.49.100/repo/haskell/wincrem/ if you feel like hosting more Haskell code.
08:12:00 <ac_mac> Lemmih: what project is it?
08:14:10 <arjanb> sam_: Fw stands for F omega which is a type system
08:14:31 <Lemmih> Hopefully paying Haskell work.
08:17:55 <wli> type inference is unhappy for F^{\omega} 
08:18:24 <sam_> great that'll be easy to search for
08:22:01 <MegaMonad> Sds is on record for largest hello, world binary.   18042912 (17Mb.
08:22:40 <wli> feh, you can get close to that in C on ia64
08:22:46 <wli> what's Sds anyway?
08:24:12 <ski> MegaMonad: Whis is Sds ?
08:24:17 <basti_> that type paper drives me nuts.
08:24:17 <MegaMonad> ski: Sds is on x86 ...
08:25:07 <ski> MegaMonad: Ok. But you still haven't told me what it is.
08:25:13 <MegaMonad> ski: I heard andersca is a new arrow to correct me, is it ok to me.
08:25:24 <basti_> MegaMonad: what do you think about F omega things?
08:25:30 <MegaMonad> basti_: I cant find an f and the omega.
08:28:38 <sam_> arjanb: 'Girard's System F-omega' do you know which Girard?
08:30:05 <wli> look for polylambda.ps
08:30:37 <sam_> did not match any documents
08:30:45 <wli> according to what?
08:31:05 <sam_> google
08:31:17 <wli> there, try that
08:32:30 <sam_> cheers
08:39:00 <wli> sam: enjoy
08:39:48 * jadrian just got "the fun of programming" delivered :)
08:40:56 <sam_> wli; looks good
08:41:31 <wli> the SEL-HPC functional programming archive used to have a lot of this stuff
08:42:14 <wli> it appears to have been cleaned out and/or shut down
08:47:36 <sam_> http://liinwww.ira.uka.de/bibliography/Misc/SEL-HPC.html
08:47:58 <sam_> ftp://progftp.vub.ac.be/ftp/1994/vub-tinf-tr-94-01.ps.Z
08:48:09 <sam_> still available :)
08:49:56 <yeti> http://dfy.dyndns.org/Tree.hs <= could anyone please take a look at this, especially the leafdepth function - I'm a haskell newbie, and while that code works like it's supposed to, I don't think it's a good implementation
08:50:52 <Heffalump> there's no point in making the first parameter to leafdepth be of type Tree
08:50:58 <Heffalump> might as well just make it be of type a
08:51:17 <Heffalump> you repeat the subcomputation of leafdepth - use a where clause instead
08:51:20 <ibid> is it really a good idea to define the Tree type in such a way that there can be no empty tree?
08:51:36 <Heffalump> ibid: depends what kind of tree you want
08:51:46 <ibid> Heffalump: yes, that's what i'm asking
08:51:50 <Heffalump> it would be better style to use a 'Maybe' type to signal failure, rather than the 0 value.
08:52:06 <Heffalump> ibid: well, it doesn't seem unreasonable, given that it's probably just an exercise.
08:52:14 <Heffalump> anyway, I'm off shopping
08:52:18 * Heffalump disappears
08:53:15 <ibid> Heffalump: if it were an exercise and i was the teacher, i'd say some stern words about not allowing for an empty tree ;)
08:53:26 <yeti> oh :( i don't understand what he meant by "using a where clause" - how can i use a where clause in that code?
08:54:10 <ibid> yeti: put a where clause after the last line, the names you define in it can be used in the guards
08:54:47 <ibid> Heffalump: but in a real world situation, there may be good reason to not allow an empty tree
08:56:05 <Darius> ibid: In an "exercise" situation there may be good reason to not allow an empty tree, it depends on the text of the problem.
08:57:28 <Darius> ibid: Anyways, one could trivially implement a possibly empty tree from the current data type.
08:58:15 <ibid> Darius: yeah, i suppose i was talking about an exercise of the type "define a binary search tree and define the following functions to it..."
08:58:23 <ibid> Darius: my original question stands :)
09:00:31 <yeti> ibid: you're right, an empty tree would be good. i'm only doing this for learning purposes though, and no, i'm not studying at an university or something like that, i'm trying to learn it all by myself :)
09:00:48 <ibid> yeti: you are excused ;)
09:00:59 <yeti> http://dfy.dyndns.org/Tree.hs <= is this what you meant by 'where clause'?
09:01:01 <Darius> yeti: Are you using any book/tutorial/...?
09:01:36 <wli> well, static majors and minors should die, but it sucks that nfsroot should have to be a casualty
09:02:13 <ibid> yeti: yeah. i'd also add depthLeft and depthRight and use that, so that the function doesn't have to be called more than once
09:02:38 <yeti> Darius: well - i've read some pages of "yet another haskell tutorial", i downloaded "two dozen question papers on haskell&answers", and i have paul hudak's book, but i don't like it
09:03:11 * ibid liked bird when i learned this stuff :)
09:03:19 <yeti> bird?
09:04:05 <ibid> richard bird's book
09:04:08 <sam_> what's the quote "It's a great improvement on many of its succesors"?
09:04:29 <yeti> ibid: i've never heard of that one - can you give me an amazon link?
09:04:36 <Darius> sam_: What do you mean?
09:04:44 <Darius> sam_: Which book?
09:04:46 <ibid> yeti: it's listed in haskell.org
09:04:57 <ibid> sam_: it's about algol 60, by hoare iirc
09:05:14 <ibid> i'm not sure of the exact reference
09:05:22 <sam_> Dijkstra I thought
09:05:40 <ibid> http://vig.prenhall.com/catalog/academic/product/0,1144,0134843460.html,00.html
09:05:59 <ibid> sam_: attributed to both, but my information is that hoare is correct
09:06:19 <sam_> ok
09:06:38 <sam_> Darius, I was saying it applies to Bird's book
09:08:08 <ibid> i learned haskell from the first edition, which was in miranda :)
09:08:22 <Darius> sam_: Adding a '?' after "quote" would have made the reading clearer.
09:08:25 <yeti> about using Nothing instead of 0 to indicate failure in my code - i fear that's not possible because i recursively use the function and there's no instance for (Num (Maybe a)) to make the comparison depthLeft /= Nothing
09:08:31 <yeti> or is there a way to do this?
09:09:04 <Darius> yeti: You simply ignore information from Nothing branches.
09:09:07 <ibid> yeti: you need to pattern-match to remove the Just
09:09:28 <Darius> There's a function, mplus, that will do the right thing.
09:09:50 <yeti> <interactive>:1: Variable not in scope: `mplus'
09:09:52 <yeti> :(
09:09:55 <ibid> it cannot replace +
09:10:09 <sam_> yes I see
09:10:13 <ibid> yeti: it's in module Monad, but you don't want it
09:10:23 <ibid> yeti: not in this case
09:12:01 <Darius> ibid: The branch case of leafdepth can be written, leafdepth a (Branch l r) = fmap (1+) $ leafdepth a l `mplus` leafdepth a r
09:12:28 <yeti> and that is where it gets too complicated for a newbie like me =)
09:12:31 <shapr> ac_mac: re: shaprforge.net --> much entertainment
09:12:43 <ibid> Darius: yes, but i'd say you're moving much too fast :)
09:12:53 <shapr> Lemmih: did you record wincrem? it appears empty.
09:13:03 <Darius> yeti: On a bit of a side issue, camelCase seems to be the most prevalent naming convention in Haskell.
09:13:50 * yeti googles for camelCase
09:14:23 <Lemmih> shapr: Yeah. I only did 'darcs initialize'
09:14:23 <shapr> alsoKnownAsBumpyCaps
09:14:35 <Darius> ibid: A bit, especially when one looks at the type and finds that this (truly) trivially generalizes to handle the non-pair-wise distinct case.
09:14:45 <shapr> ok, time to unicycle, I'll check back later for wincrem
09:16:16 <shapr> Lemmih: btw, I'm having the same darcs problem with the haskore repo, it just never comes back.
09:17:24 <sam_> wow ircing and unicycling at the same time :P
09:17:55 <Lemmih> shapr: eh?
09:18:32 <Darius> Yeah shapr, strap a PDA to your unicycle!
09:32:08 <Lemmih> Greetings, bringert.
09:33:12 <bringert> merry christmas
09:33:26 <bringert> happy holidays is the more pc version I guess
09:34:18 <ibid> season's greetings :)
09:35:02 <yeti> quicksort [x:xs]  = quicksort [n | n <- xs, n < x] ++ [x] ++ quicksort [n | n <- xs, n >= x] <= what's wrong with that :( ? ghci says 'cannot construct infinite type'
09:35:44 <bringert> yeti: did you mean "quicksort (x:xs) = ..." ?
09:35:59 <yeti> oh, yeah...
09:36:18 <yeti> thanks
09:36:28 <bringert> [x:xs] means "the list which contains one element, which is a non-empty list"
09:36:39 <bringert> I guess you probably knew that
09:36:45 <bringert> easy typo to make
09:36:57 <yeti> yep, thx :)
09:37:14 <ibid> thank $DEITY for the occurs check
09:37:53 <Darius> if $DEITY didn't give us the natural numbers, it'd be a non-issue.
09:38:24 <ibid> hmm?
09:40:56 <wli> Die ganze Zahlen hat der liebe Gott gemacht; alles andere ist Menschenwerk.
09:41:16 <ibid> i know the quote
09:41:27 <ibid> i just have no idea how it affects the occurs check :)
09:41:46 <wli> there are different interpretations of the occurs check.
09:41:52 <wli> One is of a recursive type.
09:42:13 <sam_> I've only seen it translated as 'integers' zahlen includes negatibes?
09:42:19 <Darius> ibid: Axiom of Infinity
09:42:42 <wli> sam: ganze Zahlen == "whole numbers", refers to positive, negative, and zero integers.
09:43:11 <sam_> thanks
09:43:12 <ibid> occurs check is in general a way to avoid looping forever in a unification algorithm
09:43:31 <wli> like I said
09:43:43 <ibid> you didn't
09:43:45 <wli> in various contexts the occurs check can be interpreted via recursion
09:44:05 <wli> in Haskell it already is in various instances
09:44:16 <wli> xs = 1:xs for instance
09:44:27 <ibid> Darius: you can have natural numbers without AoI, you just cannot prove the existence of the *set* of natural numbers
09:44:38 <ibid> there is no occurs check there :)
09:44:46 <wli> it can be applied to a number of less typical instances
09:44:52 <wli> ibid: there is of a kind
09:45:04 <wli> ibid: it's used to generate the recursion
09:45:47 <wli> similar may be done with types
09:46:00 <wli> instead of following an infinite chain of inference carrying out unfolding
09:46:19 <wli> you notice recursion and generate a recursive type
09:46:20 <ibid> yes, you could allow infinite types
09:46:38 <ibid> but if you do, you then don't have an occurs check in the typecheck algorithm
09:46:38 <wli> I think this gets undecidable rather quickly.
09:47:00 <ibid> wli: type reconstruction is undecidable, but not type checking, iirc
09:47:11 <wli> Okay, then you're calling something different the "occurs check".
09:48:01 <wli> ibid: type inference isn't *always* undecidable in the present of it, it is just undecidable in the presence of numerous other useful constructs
09:48:05 <ibid> the occurs check is a part of the standard unification algorithm, when you are adding x -> t to your unifier, you first check if x occurs in t
09:48:32 <wli> ibid: the conclusion of x occurring in t need not always be failure
09:48:43 <ibid> wli: in standard unification it is
09:49:03 <wli> ibid: it's most typically interpreted as failure yes
09:49:41 <wli> ibid: the other conclusion that's possible from it is of a recursive type
09:50:22 <ibid> a recursive whatever :)
09:50:30 <wli> or data structure, eys
09:50:32 <ibid> unification is used not only in typechecking M;)
09:50:53 <ibid> i suppose you could have an infinite term in some logics
09:51:24 <wli> you get the analogue of Haskell structures like xs = 1:xs from this procedure being used in logic programming
09:52:23 <ibid> hm, if x occurs in t, you would add x -> mu x . t to the unifier?
09:52:30 <wli> ibid: yes
09:52:41 <ibid> ok, i'll buy that as an occurs check :)
09:52:58 <wli> ibid: well, I have no further claim than this
09:53:03 <ibid> :)
09:53:14 <ibid> (i just capitulated, congratulate yourself;)
09:53:17 <wli> ibid: in type systems lacking polymorphism I believe this can be decidable
09:53:31 <wli> ibid: well, I don't think of it as capitulation
09:56:52 <wli> it's described by some sources as being a method for doing robust typechecking and/or more advanced error reporting in explicitly-typed languages (specifically C)
09:58:49 <ibid> i just got a notification of a new number of 'annals of pure and applied logic' to my mailbox, and i noticed the following authors for a paper:
09:58:52 <ibid> Benedetto Intrigila and Richard Statman
09:58:59 <ibid> and i thought, wtf, rms is doing logic?
09:59:02 <ibid> :)
09:59:05 <wli> Stallman?
09:59:06 <Heffalump> :-)
09:59:24 <Heffalump> isn't that the Statman of Plotkin-Statman?
09:59:33 <ibid> no idea
10:00:26 <Heffalump> yes, it is
10:00:49 <Heffalump> they have a famous conjecture, but I can't remember what it's about :-)
10:06:39 * Darius thinks he'll try this sleep thing that seems to be all the rage.
10:06:48 <wli> speaking of logic programming semantics, I actually need those for a specific command language I'm wanting for something.
10:53:37 <TheHunter> oh no, http://haskell.org/ghc/docs/latest/html/libraries/base/Control.Monad.html#v%3AfoldM
10:53:41 <TheHunter> "If right-to-left evaluation is required, the input list should be reversed."
10:54:15 <TheHunter> They deliberately put no foldrM there!
10:57:21 <shapr> I think there's a good reason for that.
10:58:36 <TheHunter> i don't think so, the choice of which functions are included in Control.Monad seems pretty arbitrary to me.
10:59:00 <shapr> I'd love to hear about a better reasoned set of choices.
10:59:24 <shapr> Sometimes I think there's too many arbitrary choices, but I don't understand enough to be sure enough to argue.
11:01:40 <TheHunter> i've at least missed foldrM, repeatM and iterateM sometime.
11:02:33 <Heffalump> I would have thought that M equivalents of standard prelude stuff would be an obvious thing to include
11:02:44 <TheHunter> yep.
12:12:26 <basti_> http://www.students.uni-marburg.de/~Zapf/wtf.jpg
12:12:54 <desrt> what is that?
12:13:14 <sorje> took me a while to see what's wrong ;-)
12:13:52 <sorje> desrt, a tetrapack
12:14:07 <desrt> interesting.  ours don't have lids like that
12:14:19 <basti_> well these are new to ours
12:14:19 <Heffalump> what is wrong?
12:14:23 <basti_> pretty new that is
12:14:26 <basti_> only some years
12:14:37 <Heffalump> the only thing that looks odd is that white thing at the front of the spout thingy
12:15:00 <sorje> the lid opens in the wrong direction?
12:15:04 <basti_> yup
12:15:11 <desrt> oh.  i see
12:15:12 <basti_> Heffalump: thats the "clip" thingy of the lid
12:15:24 <desrt> that thing flips up and it's like a straw?
12:15:29 <Heffalump> ahh :-)
12:15:40 <Heffalump> desrt: no, it's a sort of hole you can pour through
12:15:41 <sorje> desrt, not at all ;-)
12:15:46 <desrt> ok.  good
12:15:49 <desrt> that would be sort of gross
12:15:51 <basti_> not really
12:16:09 <basti_> the round little thing in the hole of the orange whatever is just a "clip"
12:16:13 <basti_> it will hold the lid in place
12:16:31 <desrt> i think i now understand teh nature of the problem
12:16:32 <basti_> the hole to pour through will be in the back
12:16:42 <basti_> where it's somewhat wrong
12:16:59 <desrt> when you move the orange thing out of the way you can pour, but you'll be poruing toward the centre of the box ratehr than the edge
12:17:09 <basti_> yup
12:19:02 <tuomov> ours have much simpler lids..
13:07:50 <shapr> I do so love unicycling. It's such a rush.
13:07:50 <desrt> :)
13:07:50 <shapr> Today I met a fifty year old guy from Mongolia who wants to learn to unicycle.
13:11:24 <goron_> Shouldn't we call this channel #unicycling_bot ? ;)
13:11:27 * Lemmih wonders why GHC panics and only prints out "urk".
13:11:59 <Lemmih> Now I see why some people complain about GHC error messages.
13:14:03 <ibid> :)
13:14:51 * _Codex made a haskell program that is extreamly slow :)
13:15:11 <yeti> "cool".
13:15:13 <yeti> ;)
13:16:55 <yeti> i think the "haskell way of thinking" is quite complicated for a newbie - i'm trying to implement a huffmann tree but i don't have the right idea yet... but learning haskell is an interesting challenge :D
13:17:46 <Lemmih> GHC from CVS doesn't build with GHC 6.2.2?
13:19:12 <goron_> Lemmih: [Evil MS mode]Maybe it's windows only there days.[/]
13:19:22 <goron_> there->these
13:33:52 <_Codex> http://sivut.koti.soon.fi/terop/sphere.png <- this one took over 20 seconds to render.
13:35:36 <Aglarion> lol
13:35:43 <arjanb> heh, is raytracer the favorite first haskell program?
13:37:19 <_Codex> that's not really a raytracer though.
13:37:52 <_Codex> I tried to implement equalizers.
13:39:37 <Lemmih> Yay. Tricked GHC to die another day.
13:40:59 <yeti> what does "const :: forall a b. a -> b -> a" do?
13:41:51 <cptchaos> @index const
13:41:51 <lambdabot> GHC.Base,Prelude
13:42:09 <ibid> creates a constant function
13:42:22 <yeti> ahhh okay
13:42:24 <yeti> thx
13:42:25 <ibid> const 7 is a function that returns 7 regardless of its argument
13:42:41 <ibid> let f = const 7
13:42:47 <ibid> now f 12 == 7 etc :)
13:42:59 <cptchaos> @listcommands
13:43:00 <lambdabot> I react to the following commands: ["all-dicts","arr","cmafihe","define
13:43:00 <lambdabot> ,"definitions","del-definition","devils","dict","dict-help","dummy","dump
13:43:00 <lambdabot> ,"dynamic-load","dynamic-reload","dynamic-unload","easton","echo","elements
13:43:00 <lambdabot> ,"eurohaskell","eval","foldoc","fortune","gazetteer","get-definition","goodbye
13:43:00 <lambdabot> ,"hello","hitchcock","index","info","jargon","join","karma","karma+","karma
13:43:01 <lambdabot> ","learn","leave","listchans","listcommands","listmodules","lojban","moo
13:43:02 <lambdabot> ,"msg","part","prelude","quit","reconnect","resume","seen","set-fuel","state
13:43:05 <lambdabot> ,"topic-cons","topic-init","topic-snoc","topic-tail","topic-tell","type
13:43:07 <lambdabot> ,"vera","web1913","wiki","wn","world02","yow"]
13:43:16 <ibid> @hello
13:43:17 <lambdabot> Hello world. 
13:43:27 <ibid> a useful command :)
13:43:40 <ibid> @hitchcock
13:43:52 <cptchaos> there was a command do display prelude definitions?
13:44:05 <ibid> @prelude const
13:44:06 <lambdabot> ERROR: connect: does not exist (Connection refused)
13:44:24 <cptchaos> hm, ok
13:44:26 <arjanb> @get-definition const
13:44:26 <lambdabot> const = \x y.x
13:44:35 <cptchaos> ah
13:44:43 <cptchaos> thats it!
14:03:08 <bourbaki> moin
14:05:11 <ski> e'ning
14:09:09 <bourbaki> http://www.pouet.net/prod.php?which=4805
14:09:56 <ski> pouet is nice
14:10:48 <bourbaki> thats the coolest wild compo ive ever seen
14:11:37 * ski doesn't know what the 'wild' platform is ..
14:12:24 <bourbaki> its just without limitiation avi files for example like this
14:18:01 <ski> Ya Hya Chouhada
14:24:11 <_Codex> http://sivut.koti.soon.fi/terop/equ.png <-- yet another pic, took 30 secs.
14:41:57 <vincenz> re
14:42:58 <xerox> @info sortBy
14:43:06 <xerox> @get-definition sortBy
14:47:54 <lambdabot> sortBy not defined
14:47:54 <xerox> @index sortBy
14:47:54 <lambdabot> Data.List,List
14:47:54 <xerox> @index List.sortBy
14:47:54 <lambdabot> bzzt
14:47:54 <joao> Hello
14:49:21 <ski> hi joao
14:51:23 <ski> joao : looking for haskell info ?
14:56:19 <joao> Yes
14:56:33 <joao> How would you build an heterogeneous list?
14:57:00 <vincenz> disjoit uion
14:57:01 <vincenz> unin
14:57:15 <vincenz> ack, sorry this laptop is really bugging me, disjoint union
15:00:26 <ski> joao : why do you think you need a heteogenous list ?
15:01:08 <joao> ski, because I need a heterogeneous list :-) I need a variable length structure that can hold different objects from different types
15:01:43 <yeti> and haskell tuples don't work for you?
15:01:46 <ski> you could use a disjoint union, as suggested, if you already know all the possible variant that you'll need
15:02:00 <ski> yeti : note the word "variable" :)
15:02:04 <joao> yeti, nope. I need variable size at run-time...
15:02:44 <joao> ski, basically, I'd like to have a FiniteMap String (anytype) :-D
15:02:46 <tuomov> how would you use the elements?
15:03:14 <tuomov> in some cases dynamics might do it, in others existentials
15:03:18 <joao> There is HList, but it's very complicated for the thing I need (I think).
15:03:42 <ski> for what purpose do you need all these different types ?
15:05:18 <joao> I need to simulate state, with different objects. For instance, I create two stacks and can manipulate them with no problem (pushing to a stack the top of the other, etc). Now I'd like to have 2 stacks and other object, from a different type..
15:06:29 <ski> hm
15:07:16 <joao> Btw, right now I use a FiniteMap String Stack, where String is the Stack identifier
15:07:28 <tuomov> can all the operations performed on the objects by turned into type classes?
15:07:39 <tuomov> s/by/be/
15:07:56 <joao> tuomov, I don't think so... the operations are simple functions...
15:10:11 <tuomov> existentials work quite nicely with a type class after you write a wrapper instance
15:10:34 <tuomov> but if you need to know the type of the object at run-time, then you should probably use dynamics
15:12:38 * ski still fail to picture how joao want to use the stacks and "objects"
15:13:16 <xerox> Is there some Haskell reference online?
15:13:55 <arjanb> http://www.haskell.org/onlinereport/
15:14:00 <xerox> thank you
15:18:19 <ski> <MegaMonad> Shapr watches the spam on the right?
15:21:54 <xerox> sort.hs:5: Variable not in scope: `toLower'
15:22:02 <xerox> What can be the cause of that error?
15:22:56 <arjanb> @index toLower
15:22:57 <lambdabot> Data.Char,GHC.Unicode,Char
15:23:28 <xerox> Oh!
15:23:36 <xerox> I was referring to: http://www.cs.uu.nl/~afie/haskell/tourofprelude.html#toLower
15:23:48 <xerox> It says it was in the prelude, I'll check for other functions too, thanks
15:24:48 <joao> Thank you.
15:24:50 <joao> Bye
15:26:01 <ski> <MegaMonad> Product, coproduct, pullback and pushout.
15:26:05 <arjanb> xerox: i think that one refers to the Helium implementation of haskell
15:26:12 <xerox> Ah
15:32:26 <ski> MegaMonad: MON OH IR RA
15:32:32 <MegaMonad> ski: Oh is that you cant do ir.
15:33:00 <xerox> Can someone give me an example of an (a -> a -> Ordering) function?
15:33:56 <Cale> @type compare
15:33:57 <lambdabot> compare :: forall a. (Ord a) => a -> a -> Ordering
15:34:06 <xerox> @get-definition compare
15:34:06 <lambdabot> compare not defined
15:34:11 <xerox> :-\
15:34:23 <Cale> @info compare
15:34:25 <lambdabot> -- compare is a method in class Ord
15:34:25 <lambdabot> compare :: forall a. (Ord a) => a -> a -> Ordering
15:34:27 <xerox> In fact i need to compare the first two element of a tuple
15:34:30 <Cale> er, hmm
15:34:38 <Cale> @define compare
15:34:38 <lambdabot> (line 1, column 1):
15:34:38 <lambdabot> unexpected end of input
15:34:38 <lambdabot> expecting white space or simple term
15:34:41 <Cale> oh
15:34:49 <Cale> is there @prelude?
15:34:54 <Cale> @prelude compare
15:34:55 <lambdabot> ERROR: connect: does not exist (Connection refused)
15:34:56 <xerox> (\x y -> (fst . head) x < (fst . head) y)
15:35:39 <xerox> But it's [(a, b)] -> [(a, b1)] -> Bool
15:35:42 <Cale> (\x y -> compare (fst $ head x)  (fst $ head y))
15:36:14 <Cale> @type (\x y -> compare (fst $ head x)  (fst $ head y))
15:36:16 <lambdabot> (\x y -> compare (fst $ head x)  (fst $ head y)) :: forall b a b1.
15:36:16 <lambdabot> 						    (Ord a) =>
15:36:16 <lambdabot> 						    [(a, b)] -> [(a, b1)] -> Ordering
15:37:30 <xerox> Uh
15:37:35 <xerox> I don't need head in fact..
15:37:46 <Cale> I suppose that a natural thing to define would be compareWith p x y = compare (p x) (p y)
15:38:21 <xerox> @info compareWith
15:38:47 <Cale> I don't think that's defined in the standard libraries
15:38:53 <xerox> Thank you.
15:39:05 <Cale> but I should probably add it to PreludeExts
15:45:05 <ski> <MegaMonad> I think a language more than programming it.
15:45:50 <shapr> Cale: tom moertel wrote the Dict plugin, and cut the prelude into a bunch of neat bits.
15:45:56 <shapr> I have the @prelude archive around here somewhere.
15:46:16 <ski> <MegaMonad> Shapr fights the evil idea.
15:46:26 <shapr> truly!
15:48:39 <ski> <MegaMonad> I know (imperative languages after all.
15:49:07 <yeti> umh
15:49:23 <yeti> who's that ski guy and why is he quoting crazy stuff all the time :D ?
15:49:45 <ibid> ski: why *are* you quoting MegaMonad and not making him make up new quotes?
15:49:56 <ski> eh
15:50:01 <ibid> MegaMonad: so, how's business?
15:50:05 * yeti is listening to Track 12
15:50:08 <yeti> oh
15:50:08 <MegaMonad> ibid: How's your study of emiting machine code/etc from a business case to the real business?
15:50:09 <yeti> sorry
15:50:26 <ski> ibid : wouldn't want to bore channel with all our conversation
15:50:40 <ibid> ok, why do you paste snippets? :)
15:50:49 <ski> yeti : i just think MegaMonad is funny sometimes
15:50:51 <ibid> well, i think i get it
15:51:40 <ski> yeti : ski are combinators
15:52:10 <xerox> @info zip
15:52:11 <lambdabot> -- zip is a variable
15:52:11 <lambdabot> zip :: forall a b. [a] -> [b] -> [(a, b)]
15:52:16 <xerox> @get-definition zip
15:52:17 <lambdabot> zip = zipWith Pair
15:53:21 <ski> xerox : @get-definition doesn't give haskell code back
15:53:44 <xerox> Uh, why?
15:55:00 <ski> because currently lambdabot doesn't interpret @eval commands as executing haskell
15:55:16 <ski> (and that's because of current security issues)
15:55:46 <CosmicRay> ski: wouldn't the security issues be completely eliminated by simply not executing any IO actions?
15:55:59 <CosmicRay> (if that can, indeed, be done simply...)
15:56:09 <xerox> I see
15:56:19 * ski haven't coded any part of lambdabot, so he doesn't know very much about the details
15:57:37 <ski> previously @prelude would get a haskell definition though, but that hasn't worked for some time .. :(
16:14:48 <jadrian> hello
16:15:00 <arjanb> hey
16:15:27 <jadrian> I have a module with A algorithms, and a module B with Show instances for the data structures I use
16:15:38 <jadrian> now I wanted to use Debug.Trace
16:15:58 <jadrian> but I need to import B from a to get the show instances
16:16:05 <jadrian> and it complains about cyclic imports
16:16:12 <jadrian> is there anyway to allow them?
16:16:29 <reffie> do haskell threads use the systems libpthread?
16:16:35 <reffie> system's
16:16:43 <jadrian> hi arjanb  
16:17:25 <reffie> [ie, do they take advantage of an operating system's implementation of user threads?]
16:22:11 <Nioate> reffie: I would think that's probably implementation-dependent. ghc doesn't by default.
16:23:15 <reffie> but is there a switch to make it use them?
16:23:38 <Nioate> reffie: you could investigate bound threads in Control.Concurrent. I've never used them, but from what I've read in the ghc docs, it might allow you to use them
16:23:47 <Nioate> I suppose you're doing something where it matters?
16:24:30 <reffie> i'm just curious :)
16:24:40 <shapr> I wanna do something that matters.
16:24:47 <reffie> don't we all
16:25:53 <shapr> Actually, we're all doing things that matter.
16:26:06 <shapr> All the time that you are alive, you are affecting the lives of those around you.
16:26:13 <shapr> And that really matters.
16:26:44 <reffie> heh
16:28:08 * xerox affects the current state of the universe going to sleep ^__^
16:30:47 <reffie> :(
16:42:30 <jadrian> hmm now that I look at it
16:42:56 <jadrian> I have no idea wht it complains 
16:43:01 <jadrian> "Module imports form a cycle for modules:
16:43:01 <jadrian>         Terms.PrintTerms2 Formulas.Sequents Terms.UniRob"
16:43:21 <jadrian> none of these imports the other
16:43:27 <jadrian> the are unrelated...
16:43:48 <jadrian> so how can they form a cycle...?
16:44:47 <jadrian> hmm nevermind :-/
16:45:25 <jadrian> argh
16:45:33 <jadrian> can't we allow cycles somehow?
16:48:53 <dons> you need to use .hi-boot files to resolve mutually recursive imports
16:49:46 <dons> http://www.haskell.org/ghc/docs/latest/html/users_guide/separate-compilation.html#MUTUAL-RECURSION
16:51:44 <wli> mutual recursion should be solvable without all that
16:53:34 <dons> it is complicated by separate compilation, and unfolding of definitions in .hi files, I think.
16:55:06 <Philippa> it should still be "mostly" solvable without
16:55:07 <wli> well, some compilers (gcc) deal with similar issues (wrt. unfolding) by passing the mutual recursive files etc. into the same invocation of the compiler
16:56:02 <wli> multiple passes also work
16:56:38 <dons> anyway, .hi-boots are pretty easy. usually they just consist of: 'data Foo', for example
16:57:56 <dons> but I'm all for a transparent implementation of mutually recursive modules
16:59:17 <dons> ah, I see a comment in the ghc src that .hi-boots mean they need to inspect far less .hi files to compute recursiveness. hence faster.
16:59:24 <Philippa> the auto-generated .hi-boot approach works for me
16:59:37 <dons> with your own script?
16:59:44 <Philippa> no, I mean the idea
16:59:51 <Philippa> if I had a script, I'd release it
17:00:12 <dons> :)
17:39:14 <jadrian> dons: thanks
17:39:29 <jadrian> but I'm not compiling, just loading in ghci
17:41:41 <jadrian> if the problem is separate compilation, shouldn't loading in ghci be possible anyway?
17:47:36 <ski> "Since every value in a purely functional computation is built up out of existing values, it is impossible to create a cycle of references. The result is that the reference graph, where there are edges from objects to the objects they reference, is a directed acyclic graph."
17:49:14 <ski> that must be incorrect
17:50:03 <ski> seen on http://en.wikipedia.org/wiki/Purely_functional
17:53:47 <jadrian> this reminds me I still don't know an elegant way to implement and use cyclic structures in an elegant way
17:54:46 <jadrian> implementing something like a double linked list seemed easy to do 
17:54:53 <ibid> is anyone editing that already? if not, i'll do it
17:55:18 <jadrian> but using it in the sense of adding and removing elements doesn't seem easy to do... :-/
17:56:08 <ibid> anybody?
17:56:11 <ski> ibid : i'm not editing
17:56:14 <ibid> :)
17:56:37 <ski> ibid : i'll thought i'll leave that to someone else (who can formulate better)
17:56:38 <ski> :)
17:56:46 <ibid> heh
17:57:00 <ibid> it seems to me that the claim is true in an eagerly evaluating system
17:57:40 <ski> jadrian : maybe something like pointer-reversal traversal could be used .. ?
17:57:50 <ski> ibid : not for functions
17:58:11 <ski> ibid : functions can be "circular" (recursive)
17:59:26 <ibid> hmm, true
18:00:11 <ski> (because function bodies are delayed, of course)
18:00:44 <ski> one could mayhap say that functions are a lazy feature in an eager system
18:00:58 <ski> or something like that ..
18:01:45 <ibid> not really
18:01:55 <ski> (the same would e.g. for methods in O'Caml objects)
18:02:05 <ski> hm ?
18:02:27 <ski> hmm
18:03:15 <ibid> saved
18:03:41 <ibid> i wouldn't call lambda's effect of delaying evaluation *lazy* evaluation :)
18:03:49 <ski> nice
18:03:55 <ski> hm
18:04:11 <ski> what would you call a record with lazy fields ?
18:04:21 <jadrian> ski:  "pointer-reversal traversal" you mean for building it, right?
18:04:31 <ibid> a record with lazy fields :)
18:04:34 <ski> jadrian : not sure, just a wild thought
18:04:54 <jadrian> ski: http://www.haskell.org/hawiki/TyingTheKnot  <-- there is a description of something like it in here
18:05:09 <ski> if both fields have type 'a', then this is essentially the same as  Bool -> a
18:06:14 <ibid> only if you can control field selection at runtime
18:06:25 <ibid> (which you can, but not directly, in most languages)
18:06:51 <ibid> besides, even though you can emulate many concepts using other concepts doesn't mean that they're all the same concept
18:07:31 <ski> i'm thinking of the analogy of records with dependent functions from a "label" type
18:07:32 <ski> hm
18:07:58 <ski> (if thinking linearily, the record should be additive)
18:08:37 <ski> (and additive records seem to me to be naturally lazy)
18:08:47 <ski> whatever ..
18:09:06 <ski> jadrian : that constructs a directly cyclic structure
18:09:33 <ski> jadrian : i was prolly thinking of something alike the Zipper
18:09:57 <wli> data Tree t = Branch t (Tree t) (Tree t) | Leaf ; x = Branch 1 x x?
18:10:45 <ski> wli : that would be cyclic, yes
18:10:49 <jadrian> ski: I know I heard of the zipper (generic programming?) but don't remmember what it is
18:11:03 <dons> jadrian: ghci uses the same frontend as ghc, and afaik uses the same .hi / .hi-boot mechanism.
18:11:23 <dons> my .hi-boot stuff in Yi certainly works under ghci
18:11:29 <jadrian> dons: but I thought that just loading doesn't create .hi files...
18:12:07 <ski> jadrian : iirc it was something about "walking around" in a datastructure, and remembering the context (above), as well as current subpart (below). this would make local editing and stuff easier ..
18:12:25 <jadrian> wli: exactly I can create them to, just not "use it", that is, if you map it, all the sharing goes away
18:13:10 <dons> no, it doesn't, but it constructs a .hi structure internally. and if the module uses other modules cyclically, it stilll needs the .hi-boot to tie the knot 
18:13:23 <jadrian> ski: but if it is cyclic what is the difference between above and below?
18:13:31 <jadrian> dons: right
18:13:50 <wli> instanec Functor Tree where { fmap _ Leaf = Leaf; fmap f (Branch x y z) = Branch (f x) (fmap f y) (fmap f z) }
18:14:17 <ski> jadrian : if what is cyclic ?
18:14:30 <wli> looks vaguely like it needs to be memoized or some such
18:14:50 <jadrian> ski: the data structure you're walking on
18:15:30 <jadrian> ski: maybe I didn't understand what you meant by context and subpart...
18:15:36 <ski> jadrian : oh, well there's still a direction of the "links/pointers", right ?
18:16:40 <ski> jadrian : so if we have a (sub)node, things that link to that are above (but we might maybe not take all such into consideration), while the things that are linked to from the node are below
18:16:55 <ski> jadrian : sorry, but haven't read very much about the zipper
18:17:08 <jadrian> ski: yes sure,  I just don't see how we can't use that in the update...
18:18:07 <ski> i was thinking of a (indended doubly-linked list), of inserting new cells into it ..
18:18:37 <wli> maybe something like instance Functor Tree where { fmap _ Leaf = Leaf; fmap f (Branch x y z) = let { w = f x ; g u = if u == x then w else f x } in Branch w (fmap g y) (fmap g z) } would do
18:18:39 <ski> if we have a non-cyclic such we can represent it (+ a current position in it) by a pair of normal lists
18:18:43 <jadrian> ski:  (below) -> a -> (above)   now if you want to change the a into a b
18:18:50 <wli> except, of course
18:18:59 <wli> Eq can't get in there
18:19:13 <jadrian> ski:  it is not enough to say that you have  (below) -> b -> (above)
18:19:51 <ski> jadrian : don't you have the worng directoin of those arrows ?
18:19:51 <jadrian> ski:  because above still leads all the way around to your "a"
18:20:24 <ski> yep
18:20:51 <ski> that's the problem with the cycles and updating
18:21:46 <jadrian> ski:  yes I think they are in the wrong direction...
18:21:47 <ski> the losing of sharing is another, more operational problem
18:22:43 <jadrian> ski: yeap, I hadn't even thought about that one
18:23:10 <ski> could maybe be solved by some kind of caheing/memoing (possibly only active over recursive call ?)
18:24:09 <jadrian> dunno...
18:24:10 <jadrian> brb
18:24:56 <ski> (seems maybe related to "minimal model tabling" in logic programming ..)
18:25:11 <ski> jadrian : anyway
18:25:23 <wli> minimal model tabling sounds interesting
18:25:39 <ski> the problems are in "updating" the above to point to the updated version, so to speak
18:26:06 <ski> and if the structure is cyclic, then the below can refer to the above also !
18:28:05 <ski> wli : that can be used for ending recursion that calls with exactly same arguments in logic prog. e.g. trying to find paths in a cyclic graph without looping algo.
18:28:49 <wli> ski: sounds useful
18:29:41 <ski> jadrian : anyway, iiuc the zipper is (at least partly) about representing the above in a sorta upside down way (methinks similar to pointer reversal on main path to "here") so that we can easily construct a new version with the updated subnode in place of the old one
18:30:07 * ski must however leave now
18:30:23 <ski> you'll have to continue wthout me !
18:32:24 <jdrake> woohoo, new machine
19:01:06 <Cale> hehe, it's more fun to read if you name it "comparing" actually:
19:01:11 <Cale> comparing :: (Ord a) => (b -> a) -> b -> b -> Ordering
19:01:11 <Cale> comparing p x y = compare (p x) (p y)
19:01:32 <Cale> so that you can say "sortBy (comparing snd)", for instance :)
19:03:32 <jadrian> back
19:04:32 <jadrian> is there a not-so-theoretical name for coproduct of types?
19:04:43 <jadrian> type Foo = A | B
19:04:54 <jadrian> Foo is the (?) of A and B
19:05:04 <wli> jadrian: sum, variants, discriminated union
19:06:21 <jadrian> still a bit to theoretical
19:06:35 <jadrian> maybe discriminated union is fine
19:07:19 <jadrian> sum I wouldn't dare, because sum as we all know is just an arithmetic operation :)
19:09:48 <Darius> jadrian: Actually sum is used quite a bit, and there is more than just a coincidence of names for it, but variant or disjoint/discriminated union would be the more recognized for Java/C/C++/VB programmers.
19:10:30 * Philippa likes sum, or if you're talking down to C types it's a "tagged union"
20:18:37 <Ryanhart> hi guys
20:18:44 <Lemmih> Hey
20:18:59 <Ryanhart> does anyone here know pseudocode?
20:22:51 <Ryanhart> it's an easy question in pseudocode but scince I am a german, I did not understand it well
20:23:07 <Lemmih> I don't think pseudocode is a real language.
20:23:11 <Ryanhart> so I thought maybe an american can give me a help
20:23:33 <Ryanhart> no it's only about tracing an output
20:23:53 <aj> everything's easy in pseudocode: you just write   solve(the_problem)
20:23:58 <Ryanhart> but I have 10 examples and I need to understand one og them
20:24:13 <Ryanhart> to understan the others for the final exam
20:24:24 <Ryanhart> and I am short on time
20:24:50 <Ryanhart> so can anyone here help
20:24:53 <Ryanhart> please
20:25:22 <Ryanhart> <aj> I just write then solve?
20:25:31 <Ryanhart> how can I do that
20:26:51 <Ryanhart> can I paste the question here? is't ok according to the rules of the chanel
20:27:00 <Lemmih> Sure.
20:27:00 <Ryanhart> or maybe in private?
20:27:15 <Ryanhart> thanks then here is the question
20:27:33 <Ryanhart> int i = 2;
20:27:34 <Ryanhart> int j = 3;
20:27:34 <Ryanhart> void multiply(int m, int n) {
20:27:34 <Ryanhart> m = m * n;
20:27:34 <Ryanhart> print(m);
20:27:34 <Ryanhart> print(n);
20:27:35 <Ryanhart> }
20:27:37 <Ryanhart> int main(int argc, char * argv[]) {
20:27:39 <Ryanhart> multiply(i,j); //multiply(i,i);
20:27:41 <Ryanhart> print(i);
20:27:43 <Ryanhart> print(j);
20:27:45 <Ryanhart> }
20:27:47 <Ryanhart> Study the behavior of the above program for each of the indicated calls of multiply() inside
20:27:49 <Ryanhart> main(). Write down the program output for each of the following parameter passing method:
20:27:55 <Lemmih> Eeek.
20:28:03 <Lemmih> Anything over three lines should go on the wiki
20:28:05 <Ryanhart> how can I find it if I want
20:28:13 <Ryanhart> pass-by value.
20:28:19 <Lemmih> I should probably have told you about that earlier.
20:28:33 <Ryanhart> or let's say reference.
20:28:46 <Ryanhart> ah sorry about that
20:29:14 <Ryanhart> I don't need to paste anything else
20:29:17 <Lemmih> It looks more like C than pseudocode to me...
20:29:35 <Ryanhart> I need only to understand one question and I can solve the others
20:30:27 <Ryanhart> yeah but the prof told us to consider it as pseudocode
20:32:04 <Ryanhart> so if I want to find the output pass-by value, how I am going to find it?
20:32:05 <Lemmih> So are you familiar with C?
20:32:17 <Ryanhart> not really
20:32:25 <Lemmih> i = 2 and j = 3, OK
20:32:29 <Ryanhart> ok
20:33:14 <Lemmih> m = i * j, what's the value of m now?
20:33:21 <Ryanhart> 6
20:34:08 <Lemmih> You call multiply with i and j and multiply prints out the result and its second argument.
20:34:56 <Lemmih> And main prints out i and j.
20:35:02 <Ryanhart> humm, could you explain that a little bit more
20:35:23 <Ryanhart> from where did you get m = i * j?
20:35:49 <Lemmih> First line in the function 'multiply': m = m * n;
20:36:40 <Ryanhart> humm but that's m = m * n ( is it the same as m = i * j)?
20:37:22 <Lemmih> The function 'multiply' calls its arguments m and n.
20:37:47 <Lemmih> So when you call 'multiply(i,j);' then m=i and n=j.
20:37:58 <Ryanhart> aha ok
20:38:07 <Ryanhart> that's new to me
20:38:26 <Ryanhart> great what about int main(int argc, char * argv[]) 
20:38:51 <Lemmih> You can probably just ignore that for now.
20:38:56 <Ryanhart> ok
20:39:26 <Lemmih> It's for calling the problem itself with arguments.
20:39:39 <Ryanhart> ok
20:41:05 <Ryanhart> so now m=i and n=j, so print(m); will give us 2=i OR m=i*j = 6 ?
20:42:03 <Lemmih> 'multiply' binds m to new value, which is m*n.
20:42:41 <Ryanhart> aha but n remain the same 3
20:42:46 <Lemmih> Yes.
20:43:17 <Ryanhart> great up to that line now become clear
20:45:32 <Lemmih> So what's the output of the program?
20:45:46 <Ryanhart> for the first part
20:46:05 <Ryanhart> print(m); 6
20:46:22 <Ryanhart> print(n); 3
20:46:46 <Lemmih> Good. And the rest?
20:46:51 <Ryanhart> so the output for the first part 6,3
20:46:57 <Ryanhart> umm I think
20:47:30 <Ryanhart> multiply(i,j); 2*3 = 6
20:47:39 <Ryanhart> multiply(i,j); 2*2 = 4
20:48:07 <Ryanhart>  print(i); = 2
20:48:13 <Ryanhart> print(j); 3
20:48:58 <Ryanhart> so the program output 6,3,2,3
20:48:58 <Lemmih> Indeed.
20:49:03 <Lemmih> Correct.
20:49:26 <Ryanhart> or maybe the program output 6,3,6,4 
20:49:33 <Ryanhart> I am not sure
20:49:58 <Lemmih> Nope. i and j are not changed.
20:50:26 <Ryanhart> umm the n waht's the point of multiply(i,j)?
20:51:47 <Lemmih> It just prints out (i*j) and j...
20:52:58 <Ryanhart> humm so (i*j) isn't an output?
20:54:07 <Lemmih> 'multiply' _does_ print out (i*j).
20:54:56 <Ryanhart> but when we get the output of the program  6,3,2,3
20:55:27 <Ryanhart> we didn't multiply i*j or i*i 
20:55:31 <Ryanhart> right?
20:55:54 <Lemmih> '6' is i*j.
20:56:26 <Ryanhart> oh yeah that's for the the first part m*n which is basicaly i*j
20:56:35 <Ryanhart> what about i*i
20:56:52 <Lemmih> You've commented it out.
20:58:05 <Ryanhart> "commented it out" sorry didn't understand quite well ^_^
20:58:55 <Lemmih> It's a comment. It means that it wont be evaluated.
20:59:03 <Ryanhart> ah ok
20:59:30 <Ryanhart> great so now the output 6,3,2,3
20:59:48 <Lemmih> Yes.
20:59:57 <Ryanhart> now pass-by value
21:00:12 <Ryanhart> is in-mode according to my note right?
21:02:10 <Ryanhart> so does that "pass-by value output for this program" will give me the same output 6,3,2,3
21:02:38 <Ryanhart> please correct me if I am wrong
21:10:27 <Ryanhart> Lemmih, you there
21:14:47 <Lemmih> Ryanhart: Was out to get some food and now I'll go to bed. Cya later.
21:18:10 <Ryanhart> ok thanks Lemmih, really appreciate your help ^_^
21:18:59 <Ryanhart> so guys anyone here can help mere to find pass-by value output I can find how but I need to know the output
21:24:03 <Ryanhart> so guys anyone here can help mere to find pass-by value output I can find how but I need to know the output
21:32:35 <Cale> Ryanhart: I can't parse what you just said.
22:47:56 <shapr> What's the take 1 equivalent in postgresql? limit 1?
22:47:57 <shapr> top 1?
22:48:27 <Lemmih> Good morning, shapr.
22:49:04 <shapr> I've had three hours sleep in the last forty eight hours. I think morning no longer applies.
22:49:17 <shapr> In any case, greetings :-)
22:52:55 <shapr> I'm trying to add threading to curryspondence.
22:53:02 <shapr> Seems like it'll be easier than I expect.d
22:53:47 <Lemmih> A threaded WASH application?
22:53:50 <shapr> Lemmih: did you record wincrem?
22:54:07 <Lemmih> Not yet. I've been kinda busy.
22:54:09 <shapr> Lemmih: nah, conversational threading of emails.
22:54:21 <Lemmih> Oh. (-:
22:54:32 <Lemmih> Neat.
22:54:53 <shapr> I'd rather get rid of WASH entirely, but I don't know if there are any decent replacements for html generation.
22:54:55 <shapr> Do you know of any?
22:55:33 <Lemmih> I'm reading a thesis about proxima. Trying to figure out how to implement structual editing in Yi.
22:55:46 <shapr> nifty =)
22:55:49 <Lemmih> shapr: Well you can use Hemplate but it's a little rusty.
22:56:20 <shapr> Structual editing could be as simple as walking the visualization of an algebraic datatype.
22:56:51 <shapr> I think the Grammatical Framework has a structure editor written in Java.
22:57:30 <Lemmih> Well I don't understand Java so I'm gonna stick with Proxima (-:
22:58:10 <shapr> oh btw, I left the haskore pull running for a bunch of hours and it did exit.
22:58:33 <shapr> it could have been running for more than eight hours, I don't know.
22:59:01 <Lemmih> Haskore?
22:59:08 <Lemmih> The music thingy?
22:59:15 <shapr> yup, it has a darcs repo
