00:06:22 <reltuk> I always wondered about how professors like that work
00:06:49 <reltuk> I mean...there's professors on our faculty list who's addreses are at the Microsoft campus...why are they our professors and not Microsoft's employee?
00:07:34 <saz> there's a microsoft campus?
00:07:42 <reltuk> that's what they call it
00:07:54 <saz> heh
01:16:06 <shapr> good morning #haskell!
01:16:40 <adept> shapr: 
01:16:40 <Jerub> morning shae!
01:17:53 <shapr> how's code?
01:18:05 <Jerub> good
01:18:30 <Jerub> I wrote an rss aggregator to sharf a livejournal feed and pipe it to pyblosxom format, making the html validatable on the way.
01:18:37 <Jerub> also, I found a bug in twisted.web.microdom
01:19:34 <shapr> cool, I want an rss aggregator in haskell
01:20:00 <shapr> now I know who to ask for rss advice
01:22:52 <Jerub> rss is more trivial than people realise.
01:23:05 <Jerub> the most complex thing was grabbing the date and converting formats.
02:46:35 * shapr reads docs in the nightly HaskellDB snapshot
02:50:52 <shapr> yay, ilike
02:52:38 <shapr> oh cool! we can define CustomSql ops now
03:11:32 <mycroftxxx> good evening
03:12:38 <mycroftxxx> can someone tell me what Just does?
03:13:01 <ibid> it creates a value of type Maybe a
03:14:25 <mycroftxxx> hmm... maybe I'm missing something important in the semantics of haskell... but "data Maybe a = Nothing | Maybe a" doesn't work as well as "... = Nothing | Just a"?
03:14:56 <ibid> there is no semantic difference between them
03:15:14 <ibid> the difference is in the name of the tag of the second alternative
03:16:02 <mycroftxxx> I don't follow...
03:17:35 <ibid> data Maybe a = Nothing | Maybe a is a valid type definition and the resulting type is structurally similar to the result of data Maybe a = Nothing | Just a
03:17:36 <mycroftxxx> are you saying haskell doesn't like recursive references in data definitions, so you have to proxy Maybe through Just?
03:17:47 <ibid> no, that's not what i am saying
03:17:48 <vegai> mycroftxxx: if it was "data Maybe a = Nothing | HowDoYouDo a" then HowDoYouDo would create a value of type Maybe a
03:18:04 <vegai> it's just a definition
03:18:06 <shapr> can someone point me to a tutorial on writng your own tcp/ip stack? does such a thing exist?
03:18:08 <ibid> mycroftxxx: you seem to think that the two Maybes in data Maybe a = Nothing  | 
03:18:15 <mycroftxxx> wega: ahh... like an alias
03:18:17 <ibid> mycroftxxx: you seem to think that the two Maybes in data Maybe a = Nothing | Maybe a are the same thing 
03:18:31 <vegai> more like a constructor, perhaps
03:18:42 <vegai> in fact, it might be called exactly that ;P
03:18:45 <ibid> mycroftxxx: they are not; the first is a type constructor, and the second is a data constructor
03:18:50 <ibid> mycroftxxx: they live in different namespaces
03:18:55 <mycroftxxx> I see
03:19:28 <mycroftxxx> wow... I've not seen a language that divides namespaces by _type_ of definition... that's quite novel...
03:19:34 <ibid> mycroftxxx: the first word after | is the name of a new data constructor; the stuff following it, before the next | (or the end) are type expressions
03:19:54 <ibid> "type of definition"?
03:20:08 <mycroftxxx> ibid: ok... I was reading | to be like the | in language specs... like an OR
03:20:14 <ibid> mycroftxxx: so, you could say data Maybe a = Nothing | Maybe (Maybe a)
03:20:18 <ibid> mycroftxxx: you read it correctly
03:20:43 <ibid> in that declaration, Maybe appears twice as a type constructor and once as a data constructor
03:21:13 <mycroftxxx> ok, the second maybe is the odd-one out?
03:21:27 <ibid> yes
03:22:02 <ibid> mycroftxxx: you could read a data declaration as an abstract grammar for normal forms of expressions of the type being defined
03:22:04 <mycroftxxx> is Nothing a data constructor?
03:22:07 <ibid> yes
03:23:13 <mycroftxxx> ok, so: "data" Type x "=" data-constructor ["|" data-constructor]...
03:23:15 <mycroftxxx> something like that?
03:23:26 <ibid> yes, and the data constructor can have parameters
03:23:31 <ibid> which are type expressions
03:24:07 <ibid> "data" Type x "=" data-constructor-decl ["|" data-constructor-decl] ...
03:24:28 <mycroftxxx> ok
03:24:41 <ibid> data-constructor-decl ::= data-constructor [type-expression [type-expression ...]]
03:24:54 <mycroftxxx> I see
03:25:35 <mycroftxxx> I'm mostly just trying to figure out the basic syntax of haskell so that I can understand all of the Monad examples written in it
03:25:55 <ibid> monad examples?
03:26:12 <mycroftxxx> all the papers on monads use haskell as an example language
03:26:22 <ibid> yes
03:27:04 <ibid> what's your background?
03:27:10 <mycroftxxx> and monads have me baffled because I can't find a straight explanation of what one -is- and how it -operates-
03:27:16 <shapr> be careful, haskell is addictive...
03:27:24 <shapr> the first monad is free
03:27:37 <mycroftxxx> shapr: I can see that, lexically it's very smooth!
03:28:19 <shapr> monads are just a stepping stone drug to arrows
03:28:25 <ibid> what's your background? knowing it helps in tuning the level of explanations ;)
03:28:50 <mycroftxxx> ibid: Python has been my pet language for a long time... but I have some C/Perl/Java/etc exp... Just recently discovered Scheme and am scared to death of lisp
03:29:07 <ibid> mycroftxxx: any academic background?
03:29:09 <mycroftxxx> shapr: yeah... I see mention of arrows :)
03:29:18 <ibid> assume yes, since you are reading papers :)
03:29:34 <mycroftxxx> ibid: umm... community college classes on C/C++ and what they call "advanced C" which is crap :P
03:29:40 <ibid> ok
03:29:44 <ibid> computer science theory?
03:30:21 <mycroftxxx> The vast majority of what I know I've taught myself
03:30:42 <musasabi> I don't really like all of haskell's ideas
03:30:51 <musasabi> it is better than the majority of languages...
03:31:30 <mycroftxxx> I'm actually seriously digging into Dylan, haskell is just a tangent to learn monads and other "purist crap" :)
03:32:04 <mycroftxxx> (don't get me wrong, I'm all about purism...) :P
03:32:16 <musasabi> what I really want is a light weight scripting language with functional features and static typing
03:33:00 <Jerub> why static typing?
03:33:18 <ibid> an incomplete description of a monad is that it is a type-systematic way to separate pure (applicative) and impure (sequential) code
03:33:37 <ibid> a monadic value is essentially a program
03:33:38 <musasabi> Jerub: makes reasoning and automated testing/code generation easier and kills of stupid errors
03:33:48 <ibid> the monadic operators are program combinators
03:34:45 <ibid> each monad is usually associated also with some specific functions; their role is to be the primitive programs from which larger programs are composed of
03:36:21 <musasabi> something like erlang but with static typing...
03:37:09 <mycroftxxx> musasabi: Dylan has optional static typing
03:38:52 <mycroftxxx> my understanding of monad is that a monad is intialized with -something-, and that something is extended recursively with functions such that when the monad is calls, the functions collapse on the -something- in the order that they were added
03:38:58 <musasabi> mycroftxxx: did it have inference?
03:39:07 <mycroftxxx> musasabi: define inference
03:39:17 <musasabi> mycroftxxx: iirc it has optional type attributes which are checked.
03:39:17 <ibid> mycroftxxx: not all monads use functions that way
03:39:32 <ibid> mycroftxxx: the simplest monad, Id, does not :)
03:39:42 <ibid> newtype Id a = Id a
03:39:49 <ibid> instance Monad Id where
03:39:53 <ibid>   return a = Id a
03:40:05 <ibid>   (Id a) >>= f = Id (f a)
03:40:12 <ibid> (iirc)
03:40:25 <mycroftxxx> can you translate that into, say, scheme?
03:40:41 <ibid> what features of that should i translate?
03:40:49 <mycroftxxx> something like: (define (Id x) (lambda () x)?
03:40:52 <ibid> scheme is not a typed language, and much of that is in types
03:42:16 <mycroftxxx> musasabi: yeah, pretty much
03:43:02 <mycroftxxx> ok... (Id a) in the last line evaluates to a new Id with a value of a?
03:43:24 <ibid> mycroftxxx: (define (Id x) (cons 'Id x)) or something
03:43:46 <ibid> mycroftxxx: no, last line is an example of pattern matching
03:44:02 <mycroftxxx> pattern >>= replacement?
03:44:08 <ibid> mycroftxxx: no
03:44:31 <ibid> mycroftxxx: it is a definition of (>>=) with two parameters, the first being of form Id a the second being f
03:45:19 <ibid> (>>=) is a binary function, and since it is a symbol, it is most often used as an infix operator
03:45:21 <mycroftxxx> "of form"... is that like "of type" or "of class"? is form some funky haskell thinger?
03:45:32 <ibid> mycroftxxx: no
03:46:24 <ibid> mycroftxxx: "a is of form b" means that the value of a can be unified with b, where b may contain unifiable variables
03:47:14 <musasabi> What I don't like about haskell is that it forces one to make separate code for monadic things.
03:47:18 <mycroftxxx> did anyone get the license plate of the idea that just flew over my head?
03:47:57 <musasabi> why not just "if a block contains an expression with a monadic type it is evaluated like a do block"
03:48:48 <ibid> what do you mean "separate code for monadic things"
03:48:57 <ibid> and what do you mean by "a block"?
03:49:22 <atom-z> monad's take a while to click
03:49:58 <ibid> mycroftxxx: consider this: every value of type Id a has ultimately been created by an expression where the data constructor Id is applied to an expression of type a
03:50:15 <mycroftxxx> from my understanding, haskell simply has "one really long expression" and "blocks" are just ways of formatting text with newlines and indentation... Ruby has actual _blocks_
03:50:29 <musasabi> why "do a <- foo \n b <- bar \n return baz foo bar" instead of "a = foo \n b = bar \n baz foo bar"
03:50:44 <mycroftxxx> atom-z: I had it a second ago... then realized it was just a special case of them that I understood :P
03:51:10 * shapr swears at paypal
03:51:19 <musasabi> kill do and mdo and just use let and let rec!
03:51:34 <shapr> may they inherit bedridden camels!
03:52:30 <ibid> mycroftxxx: a function definition like "f (Id a) = something" then defines a function that a) takes a value of type Id a as parameter b) the argument must have been constructed by applying Id to an expression c) the value of the expression that Id was applied to is then bound to a, which is a variable visible in the "something"
03:53:07 <atom-z> mycroftxxx: which is that? (to check that i'm not making the same mistake)
03:53:36 <ibid> musasabi: one problem is that you'd have to work out types in order to see the structure of a program
03:53:46 <ibid> musasabi: with do blocks, the structure is evident from the syntax
03:53:52 <mycroftxxx> ibid: ahh! so pretty much you can disect the syntactical construct the created something by using similar notation?
03:54:17 <ibid> mycroftxxx: more or less, yes
03:54:33 <ibid> mycroftxxx: the nice thing is when the parameter type has multiple constructors
03:55:02 <shapr> I can't purely pay by credit rard becase I have a paypal account, I can't create a new paypal account because I already have one, but I can't use that one because I've changed countries, but I can't transfer an existing account to a new country, and I don't know how to cancel an existing account!
03:55:12 <mycroftxxx> it would be like ((lambda something ((cons x y)) (something-else)) (cons 3 4))...
03:55:15 <shapr> I don't think they really want my money.
03:55:17 <musasabi> ibid: no. with an implicit return the system would complain if you had monadic computations inside a function and were forgetting them.
03:55:39 <ibid> mycroftxxx: then you can mostly do away with iffing and just define a function by cases
03:56:08 <mycroftxxx> ibid: it's like an introspecting multi-dispach method
03:56:15 <ibid> musasabi: my point was not about the author of the code but about the poor soul trying to read the code after the fact
03:56:18 <ibid> mycroftxxx: exactly
03:56:21 <mycroftxxx> sweet
03:56:47 <musasabi> ibid: If the return type contains a monad then order is significant. Why is that too hard?
03:57:10 <ibid> musasabi: as i said, you'll have to figure out the types before you can understand the code
03:57:36 <musasabi> with haskell one generally first looks at the signature and then the code.
03:58:01 <musasabi> and in any case one has to look at the signature in monadic code to understand what the monadic operations do.
03:58:05 <mycroftxxx> ibid: so by "of the form" you meant the syntactical form... (Id a) is of the form Id?
03:58:18 <ibid> musasabi: haskell does not require type declarations for most cases
03:58:32 <ibid> musasabi: yes, except that (Id a) is of the form (Id a) :)
03:58:44 <mycroftxxx> ibid: right, right... I see
03:59:06 <ibid> sorry, s/musasabi/mycroftxxx/ for the last :)
03:59:08 <musasabi> btw are there automated tools to add type declaritions to haskell programs?
03:59:26 <musasabi> ibid: that all can be solved with a clever editor ;)
03:59:28 <mycroftxxx> the _expression_ "(Id a)" is of the form consisting of the _tokens_ "(" "Id" <something> ")"
03:59:54 <ibid> mycroftxxx: do you know any lambda calculus, or normal form theory, rewrite theory?
04:00:13 <mycroftxxx> ibid: I'm getting some idea of rewrite theory from Dylan
04:00:24 <mycroftxxx> ibid: familiar with dylan?
04:00:29 <ibid> mycroftxxx: no
04:00:46 <musasabi> currently if I write (non)monadic code and then want to switch to the other "useless" refactoring is needed.
04:01:10 <musasabi> and sometimes I don't know whether the code will be monadic when writing it.
04:01:57 <mycroftxxx> dylan has a hygenic token-based syntactical macro system... looks like: define macro { token ?variable:type-or-wildcard <etc> } => { new-token ?variable <etc>}
04:02:13 <ibid> musasabi: you will have to rewrite it in any case, if you go from non-monadic to monadic, regardless of whether you have do or not
04:02:26 <ibid> mycroftxxx: similar to scheme syntax-rules?
04:02:58 <musasabi> ibid: why?
04:03:16 <mycroftxxx> the things in the {} can be in any order or whatever... like { define mything ?thing-name:name ?anything-else:* } => { this ?thing-name make no sense with ?anything-else }
04:03:18 <musasabi> (a normal order of execution could be easily defined)
04:03:23 <ibid> musasabi: because monadic and non-monadic code are inherently different
04:03:30 <mycroftxxx> mycroftxxx: I never grokked schemes macros until I did dylan's
04:03:52 <mycroftxxx> er :P
04:03:55 <musasabi> ibid: not in all instances.
04:03:58 <mycroftxxx> musasabi: ^
04:06:00 <ibid> mycroftxxx: in a very real sense, haskell programs are expressions and execution is calculation (rewriting of expressions)
04:06:19 <ibid> mycroftxxx: the result of execution is a normal form of that expression, if one exists
04:06:52 <mycroftxxx> ibid: similar to how scheme is just an expression simplifier? evaluating the largest expression it can left-to-right?
04:07:05 <ibid> basically yes
04:07:21 <musasabi> leftmoust-outermoust reduction...
04:07:48 <musasabi> blackholes complicate things a little bit
04:08:22 <mycroftxxx> musasabi: I assume you mean leftmost-outermost
04:08:39 <musasabi> yes, just typoing
04:09:01 <ibid> mycroftxxx: remember when i earlier described a type definition as an abstract grammar for the normal forms of expressions of that type?
04:09:13 <mycroftxxx> yeah
04:09:28 <ibid> mycroftxxx: do you understand it?
04:09:37 <mycroftxxx> I think I know what you're saying
04:09:58 <mycroftxxx> type definitions are like macros... they just define a syntactical form
04:10:27 <ibid> not really macros
04:10:37 <mycroftxxx> and when something constructed with a constructor-thing, it's identified by it's signature....
04:10:59 <mycroftxxx> when something ... is passed around, it's ident....
04:11:17 <ibid> mycroftxxx: pattern matching basically tries a pattern to the normal form of a expression
04:12:30 <mycroftxxx> ok... so your code: (Id a) >>= f = Id (f a)
04:13:33 <mycroftxxx> the first "(Id a)" is the pattern for the lhs of >>= and "f" is the pattern for the rhs... the whole expression evaluates to what's after the =
04:14:26 <mycroftxxx> replacing f and a in "Id (f a)" with the corresponding match cases in the "... >>= ..." pattern
04:14:31 <mycroftxxx> am I close?
04:15:09 <ibid> yes
04:15:22 <mycroftxxx> ok... so how does that line relate to the stuff above  it?
04:16:04 <mycroftxxx> newtype Id a = Id a
04:16:04 <mycroftxxx> instance Monad Id where
04:16:04 <mycroftxxx>   return a = Id a
04:16:04 <mycroftxxx>   (Id a) >>= f = Id (f a)
04:16:55 <ibid> those two lines define two different functions, which are methods of the Monad class
04:17:11 <mycroftxxx> ok the first line defines a new type whose signature (form?) is "Id a" (the first part) and the constructor is "Id a" (the second part)?
04:17:47 <ibid> essentially yes
04:18:05 <mycroftxxx> and "instance" is a keyword to define a class?
04:18:16 <ibid> no, it defines an instance of the class
04:18:23 <ibid> the class has been defined elsewhere
04:18:32 <mycroftxxx> ok, good... that would just be confusing
04:18:35 <mycroftxxx> :P
04:18:49 <ibid> (remember, these are not oop classes)
04:18:49 <mycroftxxx> so we have a Monad instance named Id?
04:18:57 <ibid> yes
04:19:10 <mycroftxxx> how exactly do these classes work?
04:19:27 <mycroftxxx> (afk: beverage)
04:20:59 <mycroftxxx> back
04:21:23 * ibid is not :)
04:23:09 <mycroftxxx> heh
04:23:18 <ibid> watching tv, should end soon
04:24:18 <mycroftxxx> right on... in that case I'm gonna hit the store and get some smokes...
04:36:18 <mycroftxxx> back, again
04:42:03 <ibid> haskell classes are somewhat related to java interfaces
04:42:18 <ibid> except that there is no subtype relation implied by classes
04:42:44 <ibid> haskell type classes are essentially a way to group types by common functionality
04:42:56 <cm> shapr: hey
04:44:05 <mycroftxxx> ok... so no inheritance
04:44:29 <mycroftxxx> and by "interfaces" you mean they have no actual implementation...?
04:44:55 <ibid> mycroftxxx: instance declarations give the actual implementations
04:45:09 <ibid> there is inheritance (between classes) but not subtyping
04:46:06 <ibid> ok. let's rephrase. there is subclassing, but since classes are not types, that does not create subtyping
04:46:14 <mycroftxxx> ok
04:46:22 <mycroftxxx> class vs. type?
04:46:39 <ibid> classes are essentially sets of types
04:46:51 <mycroftxxx> ok
04:46:56 <ibid> that allow overloading of functions within that set of types
04:47:35 <ibid> class methods are overloadable functions, each class instance defines the overload instance for each method
04:47:43 <mycroftxxx> ok... so a class can define a set of functions, and a type in that class can overload those functions?
04:48:09 <ibid> yes (if i understand you correctly)
04:48:45 <ibid> you know that haskell functions can be generic (polymorphic in fp speak)?
04:49:00 <mycroftxxx> yeah... like multimethods
04:49:05 <ibid> no
04:49:11 <ibid> like c++ templates, more
04:49:34 <mycroftxxx> ok
04:49:46 <ibid> essentially, a function type may contain type variables
04:50:02 <ibid> classes allow you to restrict the types that a type variable can assume
04:50:13 <mycroftxxx> ok
04:50:42 <ibid> so, a type Ord a => a -> a is a function type that maps a value of a type to a value of the same type, but the function is only defined for types in the Ord class
04:51:05 <mycroftxxx> kind of like defining a function that accepts "a thing _x_ that is of type _t_ where t is any time"
04:51:30 <shapr> cm: y0
04:51:31 <ibid> because of that, you can use the (<) and other comparison function with the "a" type
04:51:39 <ibid> mycroftxxx: i'm not sure i get that
04:52:06 <ibid> (the comparison functions are methods of the Ord class)
04:52:13 <mycroftxxx> (define (f thing type) (...))
04:52:28 <ibid> what's that?
04:52:34 <ibid> looks like scheme but ...
04:52:51 <mycroftxxx> it's psuedo-scheme :P
04:53:05 <ibid> ok, what is its semantics?
04:53:27 <mycroftxxx> you said "type variables"... I interpret that as saying that a function can accept the type of something as an argument (of sorts)...
04:54:00 <ibid> mycroftxxx: that's not really what it means
04:54:12 <ibid> mycroftxxx: you are thinking too operationally :) think calculation
04:54:13 <cm> shapr: hiya :)
04:54:27 <cm> shapr: say, you got that one moinmoin wiki running, with latex support, right?
04:54:42 <ibid> a -> a is a type expression; a is a type variable, that is, a variable that can appear in type expressions
04:54:53 <mycroftxxx> I was raised on turboC and MSDOS batch files :P
04:55:04 <cm> mycroftxxx: there still is hope!
04:55:08 <shapr> cm: yup
04:55:11 <mycroftxxx> heheh
04:55:40 <cm> shapr: how do you install the latex processor? :) simply copying it into data/plugin/processor/ didn't seem to work for me :/
04:55:41 <ibid> mycroftxxx: operationally, a generic function without class constraints just gets a pointer as a generic parameter; it does not care what the pointer points to
04:55:56 <mycroftxxx> k
04:56:01 <shapr> cm: what didn't work?
04:56:14 <ibid> mycroftxxx: if a type variable is constrained by a class, then the function gets a hidden parameter that essentially works like a vtable
04:56:32 <mycroftxxx> vtable?
04:56:48 <cm> shapr: didn't seem to get loaded. when i put #!latex blablabla on a wiki page, it didn't get processed.
04:57:04 <ibid> mycroftxxx: ie. maps the methods of that class to the actual functions that implements the methods for the particular type of the parameter at this call
04:57:13 <cm> shapr: there's no .pyc file either in the same directory, hence i suspect it didn't get loaded at all
04:57:15 <mycroftxxx> cm: doesn't moinmoin require whitespace after #! ?
04:57:23 <ibid> mycroftxxx: vtable is an oo implementation technique, i just hoped you knew it :)
04:57:42 <cm> mycroftxxx: not that i know
04:58:35 <mycroftxxx> ibid: I'm -vaguely- familiar with LALR parsing, which I know produces tables for LR parsers... but not much else in those terms ;P
04:58:52 <ibid> mycroftxxx: vtables have nothing to do with parsing
04:59:00 <mycroftxxx> k, n/m :P
04:59:12 <ibid> mycroftxxx: it is the mechanism how single-dispatch methods are commonly implemented
04:59:21 <mycroftxxx> k
04:59:22 <cm> it's basically like. object.method(); -> object.__vtable[METHOD_INDEX]();
04:59:53 <ibid> mycroftxxx: in oo, that is: each object contains a pointer to a table that contains function pointers to the appropriate methods of the class of this object
04:59:56 <ibid> what cm said :)
05:00:09 <mycroftxxx> cm: yay, translation code :)
05:00:58 <mycroftxxx> so, this all sounds like multimethods to me (maybe I have a bad definition of them though)
05:01:14 <cm> multimethods do the dispatch on "multi"ple arguments' types
05:01:25 <ibid> mycroftxxx: multimethods are afaik closest to ordinary haskell functions and definition by cases
05:01:52 <ibid> mycroftxxx: generic functions and type classes are a totally separate set of concepts
05:02:01 <cm> instead of dispatching on the first parameter's type only (i.e. on the type of "object" in object.method()), you dispatch on multiple types
05:02:25 <mycroftxxx> hmm... Dylan's literature (seems to) use multimethods and generic functions interchangably...
05:02:38 <cm> it's the same
05:02:41 <ibid> mycroftxxx: ahh, that's common lisp special terminology ;)
05:02:56 <ibid> seems to have carried over to dylan
05:02:59 <ibid> (clos, that is)
05:03:11 <mycroftxxx> yeah... dylan takes a lot of CLOS concepts
05:03:19 <cm> -OS, too :)
05:03:30 <mycroftxxx> infact dylan is scheme + clos + pascal - ()(())()()))
05:03:52 <ibid> what i'm calling generic functions here are properly called parametrically polymorphic functions by fp folk
05:04:36 <ibid> the concept does not exist in lisp derivatives as parametric polymorphism is a static typing feature
05:04:47 <mycroftxxx> I see
05:05:00 <cm> you know you make me wanna.. shout
05:05:06 <ibid> who? :)
05:05:25 <ibid> (i know i'm simplifying here:)
05:06:12 <cm> just listening to ooold music :p
05:06:37 * ibid too :)
05:07:02 <ibid> bach's mattheus passion, to be precise :)
05:07:38 <cm> oh.. okay, you won ;) i'm twisting again :p
05:08:12 <ibid> mattheus passion and some requiems are traditional listening at easter :)
05:08:26 <mycroftxxx> here's what I think of when I hear "generic function"... in Dylan, when you define a method "define method a-method (foo :: <foo>, bar :: <bar>) => (<foobar>) ..." dylan creates a function called a-method which has a lookup table, and it adds [(<foo>, <bar>) -> a-method]...
05:08:40 <cm> ibid: i don't have an mp3 of those ;)
05:08:42 <ibid> yeah, that is multiple dispatch
05:08:46 <ibid> cm: i have oggs
05:09:04 <ibid> cm: ripped from my or my parents' cd's
05:09:05 <cm> oh :)
05:09:23 <mycroftxxx> mmmmm... ogg.....
05:09:54 <ibid> gerne will ich mich bequemen ... ;)
05:10:04 <mycroftxxx> so, what you're describing is not miltiple dispach?
05:10:06 <cm> hrhr
05:11:08 <ibid> mycroftxxx: no, multiple dispatch is closest to pattern matching functions in haskell, but parametric polymorphism and type classes are a separate set of concepts
05:11:23 <mycroftxxx> I see
05:11:45 <mycroftxxx> I think I just need to read these papers and mediated on example code
05:11:59 <mycroftxxx> s/mediated/meditate/
05:12:21 <ibid> as i said, the issues that type classes and polymorphic functions solve are not really issues for dynamically typed languages
05:12:41 <ibid> and so the concepts are not really present in such languages
05:14:33 <mycroftxxx> so a type class is just a way to be-able to accept more than one type... instead of func(int x) you can have func({int, float, double} x) or something
05:15:21 <ibid> no
05:15:33 <ibid> that's the function of polymorphism
05:15:43 <cm> well, in a certain way "yes", no?
05:16:26 <cm> class Funcable a where func :: a -> IO () // instance Funcable Integer where func n = print "meep" // ..
05:16:27 <ibid> cm: far-fetchedly, but yes :)
05:16:42 <ibid> ah, yes, in that sense
05:16:50 <cm> come on baby, let's do the twist
05:17:15 <ibid> type classes is a way to make function overloading civilized :)
05:17:49 <mycroftxxx> it's starting to make sense
05:18:08 <mycroftxxx> although, the fact that I'm still awake is making less sense...
05:18:22 <ibid> or rather, to make it interact well with hindley-milner type systems
05:18:36 <ibid> 15:18 here :)
05:19:57 <cm> 1418 :/
05:20:10 <ibid> 1520
05:21:00 <ibid> argh, too many planets, can't see intersting stuff in the logs anymore
05:21:38 <mycroftxxx> bleh 5:45am... haven't been up this late in a long time... Zzzzzz
05:21:41 <mycroftxxx> night guys
05:22:10 <ibid> good day :)
05:22:30 <ibid> 5:45? what timezone is that=
05:29:23 <vegai> west coast?
05:30:20 <skew> yep
05:30:39 <skew> well, my clock says 5:30
05:32:11 <skew> also getting wierd spam over IRC asking me to download and run executables
05:32:29 <ibid> vegai: has to be some -+XX30 timezone
05:32:51 <ibid> but i don't think there are many of those
05:33:22 <ibid> -0730, perhaps?
05:34:41 <cm> rank 1's sensation 2003 anthem is a cheap mozart ripoff :)
05:34:51 <skew> ibid: typeclass stuff isn't quite useless in dynamically typed languages. the python protocol stuff is a similar idea if not quite as developed
05:35:56 <cm> "milestone releases are being named alphabetically after pok√©mon". duh.
05:36:24 <skew> cm: what's doing that?
05:37:07 <cm> http://www.lag.net/~robey/paramiko/
05:40:12 <skew> I like the note on libtai about the format: "Under many cosmological theories, the integers under 2^63 are adequate to cover the entire expected lifetime of the universe; in this case no extensions will be necessary."
05:41:59 <skew> also, "TAI also specifies a frame of reference. Further discussion of special relativity is outside the scope of this document."
05:43:02 <cm> :)
06:08:40 <shapr> @yow !
06:08:41 <lambdabot> By MEER biz doo SCHOIN..
06:12:32 <andersca> @arr
06:12:32 <lambdabot> I heard andersca is a pirate
06:12:37 <shapr> cm: what version of moin? did you try the LaTeX examples on AvianWiki or HaWiki? are you using the latex.py plugin that I hacked on?
06:12:59 <shapr> andersca: you planned that didn't you?
06:13:12 <andersca> yes
06:13:20 * shapr grins
06:13:47 <Jerub> http://thorne.id.au/users/stephen/pirate_keyboard.jpg
06:15:11 <shapr> I feel like Captain Hook with this left hand layout
06:15:37 <shapr> er, right hand layout
06:15:57 <shapr> why do I always get that confused?
06:16:16 <Jerub> there's a left-handed maltron on ebay at the moment ;)
06:16:39 <shapr> I'm not so thrilled with maltron's 2-hand
06:16:55 <shapr> haven't looked at their 1-hand stuff much
06:17:15 <Jerub> its extremely similar to the kinesis isn't it?
06:18:16 <shapr> the angles on maltron are weird
06:18:28 <Jerub> ahh
06:18:45 <Jerub> I'm looking at trying to get a kinesis off ebay cheap
06:19:11 <cm> shapr: not quite sure which version it is :)
06:19:45 <shapr> lemme get it
06:20:49 <cm> shapr: oh, it's 1.2.1
06:21:24 <cm> i'm seeing an error message now that i pasted your #!latex example.. didn't put {{{ before #!latex and didn't close with }}]
06:22:29 <shapr> http://shapr.homelinux.net/~shae/latex.py
06:22:54 <cm> ta
06:23:03 <shapr> what's the error?
06:23:19 <cm> config_vartmp_dir not defined, i was using an old version i guess
06:23:22 <cm> let me try it now..
06:24:35 <shapr> means you need to edit your config
06:24:42 <shapr> probably
06:25:56 <shapr> I can put up my config if you want
06:26:30 <shapr> y0w ppls
06:26:54 <cm> sec :)
06:28:27 <shapr> suddenly I hear my unicycle calling me
06:30:14 <Jerub> sigh.
06:30:24 <Jerub> why is this so easy for some people.
06:30:29 <shapr> what?
06:30:30 <Jerub> 23:24 < marv> i don't really know haskell, but i'm looking to find the time to learn
06:30:33 <Jerub> 23:25 < Jerub> monads are the way you perform things in sequence - they're really quite simple once you remove the syntatic sugar.
06:30:40 <Jerub> 23:26 < marv> yeah sound like simply a function that generates a new function with the new state
06:31:03 <shapr> because we are stuck in our ways :-)
06:31:39 <cm> shapr: ah, /usr/bin/convert fails now
06:32:04 <skew> I don't understand what you are trying to say, Jerub
06:32:10 <shapr> which can be good sometimes
06:32:41 <cm> "/usr/bin/convert: DPS library is not available (..)"
06:33:01 <shapr> debian?
06:33:29 <cm> gentoo
06:34:03 <cm> and something about "sh: line 1: gs: command not found". /me emerging ghostscript now
06:34:27 <Jerub> skew: this dude already understands the monad, while it took me about 12 months to pick it up.
06:34:43 <skew> the stuff he said sounds pretty vauge
06:34:51 <skew> I couldn't make anything of it
06:37:05 <skew> I hope the people I'm teaching get the stuff about monads. I'm presenting IO next weeks, and monads in full generality the week after that
06:40:42 <cm> shapr: works :)
06:40:46 <cm> ghostscript was missing
06:50:25 <Shammah> hey jerub :)
06:51:00 <skew> I'm planning on the usual handwaving about actions for IO, but I might go for a full formal approach the week after next
06:51:57 <Jerub> Shammah: hello!
06:52:11 <Shammah> heh, I still don't understand monad's in full generality.
06:52:12 <Shammah> :(
06:52:35 <Shammah> Although the Parser Combinator's paper came closest to inspiring understanding.
06:52:50 <skew> Shammah: just stare at the commutativity diagram for a while :)
06:52:59 <Shammah> :)
06:53:32 <Shammah> Fortunately I need to pick up some category theory for work, which will probably help.
06:53:32 <skew> ooh. what sort of work?
06:54:12 <Shammah> sop-statement store db.
06:54:30 <Shammah> basically scalable rdf-database.
06:54:44 <Shammah> and the fun part is; we really do scale :)
06:55:38 <skew> what's a sop-statement, and where does the category theory come in?
06:56:32 <Shammah> subject-predicate-object.
06:57:24 <skew> like statements to be used in inference?
06:57:28 <Shammah> and the category theory comes in, because we are needing to introduce typing; and we would like to get the semantics right.
06:57:51 <Shammah> yeah.
06:59:06 <skew> I think there's some interesting analytic work in linguistics that might be relevant, depending on the scope of the system
06:59:35 <Shammah> oh?
06:59:40 <Shammah> I'm not surprised.
07:00:16 <skew> at least, I remember a paper treating tenses or subjunctive tense or something with continuations.
07:00:49 <skew> So there's probably other stuff at the edge of computer science more directly relevant
07:01:00 <Shammah> alot of the theory derives from the early prolog work, and prolog/mercury/constraint-prog remains popular in the NLP world.
07:01:12 <Shammah> that would be interesting.
07:01:36 <Shammah> do you have a cite?  Or enough for me to find it myself on citeseer? :)
07:01:52 <skew> hmm. it was years ago. I can try looking a bit
07:03:16 <Shammah> thanks.  I seem to spend a huge amount of time with my browser open to citeseer these days :P)
07:04:01 <skew> www.eecs.harvard.edu/~ccshan/cw2004/cw.pdf is roughly like what I remember
07:05:31 <Shammah> great. thanks.
07:07:08 <Shammah> mmm looks interesting.
07:10:13 <skew> there is plenty of other stuff like that out there, apparently. google could find plenty more. That was just one hit for (linguistics continuations)
07:14:53 <Shammah> skew: ah.  yeah. I never seem to have any trouble finding interesting papers to read.   I currently have ~200
07:15:07 <Shammah> Mb of unread pdf's on my to-read list :)
07:38:09 <_Codex> There exists piles of papers; but only few of them are really worth a read.
07:39:15 <Shammah> true. :)
07:41:26 <_Codex> What's the best papers you've read?
07:42:04 <Shammah> Combinatory Parsers was very good.
07:42:28 <Shammah> As is Milner's tutorial on the PI calculus.
07:43:14 <_Codex> I liked the one called "Curry-Howard isomorphism". That must still be the best one I've read.
07:43:30 <Shammah> Guy Steele wrote a fun paper on teaching language semantics.
07:43:54 <_Codex> err, its called "Lectures on the Curry-Howard isomorphism".
07:44:39 <Shammah> Barendregt's introduction to the lambda calculus is the most approachable discussion on the topic I've come across.
07:48:15 <Shammah> Daniel Friedman's "The role of the study of programming languages in the education of a programmer" is probably the best paper I've read.
07:52:26 <Shammah> Morten Heine B. Sorensen, Pawel Urzyczyn:
07:52:28 <Shammah> Lectures on the Curry-Howard Isomorphism.
07:52:29 <Shammah> DIKU report 98/14.
07:52:31 <Shammah> Is this the one?
07:52:50 <_Codex> yes, that's it.
07:54:22 <Shammah> wow, 273 pages.  I don't normally consider anything longer than 50 to retain the designation 'paper' ;)
07:54:51 <_Codex> maybe its a book.
07:56:00 <_Codex> I think "paper" means that it uses formal, exact way of presentation.
07:56:41 <Shammah> thanks for the pointer anyway.
07:59:03 <shapr> @yow !
07:59:03 <lambdabot> Prelude.(!!): index too large
07:59:21 <shapr> oh thanks a lot
07:59:55 * shapr smacks lambdabot 
08:52:47 <SyntaxNinja> are there any facilities in TH for creating a set of unique variable names?
08:52:56 <skew> a set of them>
08:52:59 <skew> ?
08:53:19 <skew> I'm pretty sure the Q monad provides some sort of gensym facility
08:53:41 <SyntaxNinja> hm. not quite what I want, I think.
08:53:53 <skew> what are you trying to do then?
08:55:01 <Igloo> replicateM n newName  (or maybe newName "foo", I forget)
08:55:36 <skew> that's the sort of thing I was talking about. It makes new names like "foo0","foo1","foo2",etc
08:55:37 <SyntaxNinja> hm. I don't see newName... i'll look around
08:56:30 <SyntaxNinja> actually, I thought I wasn't int he Q monad, but I am...
08:57:03 <monotonom> I am Q.
08:58:09 <skew> cool. I'd like an exploding pen and an umbrella concealing a sword. To go, please
08:58:50 <skew> SyntaxNinja: how much has Template Haskell changed recently?
08:59:11 <skew> I messed around with it a bit a while ago, and just ran into something else it might be useful for
09:01:05 <SyntaxNinja> ask Igloo :) It's not too different from last time i played with it
09:01:08 <SyntaxNinja> but getting more serious now :)
09:01:10 * SyntaxNinja lunch &
09:01:54 <Igloo> There's been a bunch of name changing depending on what you mean by recently. Also, new features are dripping in from SPJ
09:02:41 <skew> glancing over the module documentation shows support for foriegn declarations
09:02:54 <skew> so I'm just wondering if there are type brackets now
09:04:02 <Igloo> There have always been type brackets, just not type slices, I thought
09:04:59 <Igloo> Prelude Language.Haskell.TH> do x <- runQ [t| Int -> Bool |]; print (pprint x)
09:05:00 <Igloo> "GHC.Base.Int -> GHC.Base.Bool"
09:05:08 <skew> hmm. I guess I never used them.
09:05:26 <skew> I want to generate some ffi declarations plus a bit of marshalling
09:05:57 <skew> I think it will work out quite nicely
09:07:12 <Igloo> What for, OOI?
09:07:24 <skew> OOI?
09:07:32 <Igloo> Out Of Interest
09:07:51 <skew> I've been hacking a bit on a Python binding thing
09:08:38 <skew> well, I hacked on it two nights for a while ago, then my system went flaky for a while and I got schoolwork, but I want to fix it up a bit more eventually
09:09:06 <skew> as it stands I don't do any garbage collection, so you need to manage references on objects yourself
09:09:49 <skew> I'm just looking for the most degenerate case of marshalling, a little wrapper than unwraps ForeignPtr arguments, and wraps some results
09:10:14 <skew> but it would be incredibly tedious to do by hand, especially as I add more functions. So, macros
09:11:29 <skew> the binding does some cool stuff as it stands, if I haven't mentioned it to you
11:21:11 <SamB> anyone care to critique my resume?
11:21:56 <SamB> http://64.0.112.124:8080/resume/resume.{html,pdf}
11:26:24 <themaximus> sure
11:27:43 <themaximus> I'd get rid of the funny stuff. Managers don't like that for some stupid reason
11:27:50 <themaximus> I wish they did.....
11:29:44 <SamB> rats
11:31:04 <themaximus> Yeah, I know.
11:34:56 <Lemmih> Yay Haskell (-:
11:36:38 * Lemmih realizes which channel he's in and the error he just made.
11:37:06 <skew> Lemmih: error?
11:37:31 <bring> @type error
11:37:32 <lambdabot> error :: String -> a
11:37:36 <Lemmih> haha
11:37:51 <monotonom> @type just
11:37:55 <monotonom> @type and
11:37:57 <lambdabot> and :: [Bool] -> Bool
11:38:02 <skew> @type Just
11:38:03 <lambdabot> Just :: a -> Maybe a
11:38:48 * SamB comments out the Emacs entry under operating systems
11:38:59 <monotonom> Hahahahahah
11:39:27 <monotonom> Do put it under virtual machines though :)
11:39:50 <andersca> @type (!!)
11:39:51 <lambdabot> (!!) :: [a] -> Int -> a
11:39:55 <andersca> @type id
11:39:56 <lambdabot> id :: a -> a
11:39:58 <andersca> lambdabot is cool
11:43:18 <bring> SamB: how about something about your education?
11:44:47 <SamB> bring: okay
11:51:00 <SamB> should I include my SAT scores? AMC-12 score?
11:54:40 <Smerdyakov> If you get a programming job before college, it will be through personal connections.
11:54:44 <Smerdyakov> I'm not sure a resume matters at all.
11:54:56 <SamB> hmm.
11:55:13 <bring> hehe, I did, but that was in 2000 :)
11:55:29 <Smerdyakov> I got a programming job in 1998 because I knew somebody who worked at the place.
11:55:34 <skew> It's probably useful. The forms must be observed.
11:55:35 <Smerdyakov> I don't know how HE got the job. :)
11:56:05 <Smerdyakov> SamB, do you live near any universities?
11:56:49 <SamB> Smerdyakov: I live in Upper Darby, right outside of Philadelphia, and a pretty short train ride from Villanova too
11:57:28 <skew> That's probably a good place to work.
11:57:44 <andersca> @arr
11:57:44 <lambdabot> Avast!
11:57:46 <SamB> skew: which?
11:57:49 <skew> I got a job the summer before I went to college doing any sort of odd tasks around the CS department
11:58:21 <Smerdyakov> SamB, sweet jesus. You got to get your ass in to UPenn and bug the PL group.
11:58:59 <Smerdyakov> SamB, do you realize that Penn is one of maybe around 5 universities in the country with anyone doing functional programming research? :D
11:59:30 <skew> what are the others?
11:59:40 <SamB> Smerdyakov: oh, cool
12:00:36 <Smerdyakov> skew, CMU, Yale, OGI, ..., uhh... maybe that's it. :)
12:00:44 <monotonom> Harvard (Hudak)
12:00:57 <Smerdyakov> monotonom, he moved to Harvard?!
12:01:00 <monotonom> Where is Okasaki?
12:01:20 <Smerdyakov> monotonom, Naval Academy
12:01:29 <monotonom> Ah damn, Hudak is at Yale.
12:02:00 <monotonom> Alright, we've got 5 now.
12:02:15 <Smerdyakov> The Naval Academy isn't a university. :P
12:02:59 <Smerdyakov> From a potential student's point of view, it's no good to count it, since you must join the Navy to get a degree from there....
12:03:54 <monotonom> David MacQueen at U of Chicago
12:04:32 <monotonom> Actually http://www.smlnj.org/people.html speaks for itself :)
12:05:45 <Smerdyakov> I don't know if MacQueen does functional programming research these days.
12:05:58 <Smerdyakov> Blume is the real head of the SML/NJ project.
12:06:51 <Smerdyakov> Looking at past research projects is a bad way to tell what's going on now, since functional programming was the "in thing" in academia from mid 80's to mid 90's.
12:07:23 <SamB> what is the "in thing" now?
12:07:57 <monotonom> MacQueen does administration now http://www.cs.uchicago.edu/people/dbm
12:08:17 <Smerdyakov> The people who did functional programming either do security, non-functional language stuff that sneaks in features from functional languages, or other less common things.
12:08:28 <Smerdyakov> I'm only talking about America, by the way. Europe still loves FP. :)
12:08:42 <SamB> stupid americans
12:09:17 <Smerdyakov> I think it's actually a good change. There's only so much that can be done to advance the fundamental tools for functional programming at a time.
12:09:26 <SamB> true.
12:10:38 <Smerdyakov> More even geographic distribution would be preferable, though. :)
12:11:28 <skew> I think there is plenty of room for useful work
12:11:53 <skew> maybe not all in theory, but more work on implementations, libraries, selling to big corporations, etc.
12:12:25 <SamB> what about frameworks?
12:12:55 <Smerdyakov> skew, ah, but none of that is much in the realm of academic research.
12:13:16 <SamB> Smerdyakov: that is the fault of who?
12:13:35 <Smerdyakov> SamB, why is it a "fault"?
12:14:00 <SamB> well, academics should be more interested in usefull things
12:14:24 <Smerdyakov> They are interested in useful things, but the things should also pose fundamentally new questions.
12:14:25 <skew> there are still plenty of open theoretical questions anyway
12:14:33 <Smerdyakov> The implementation and social work skew describes does not fit this description.
12:15:08 <SamB> is this ivory tower mentality necessary?
12:16:01 <skew> it's more a question of how schools are organized
12:16:11 <skew> at the root, what research can recieve funding
12:16:23 <Smerdyakov> SamB, think about what you're saying. The very definition of academic research is as I said. If you don't like it, you don't work in academia.
12:16:42 <skew> if you want to do other stuff you do it on your own, starting a buisness or something
12:16:51 * earthy illustrates by mentioning Clean
12:17:17 <skew> but I think a lot of library sort of work could probably fall under publishable research
12:17:22 * earthy heard rumours that the group developing Clean has been put on academic probation, as the stuff they've been doing isn't academically interesting
12:17:26 <SamB> clean? clean is dirty. that is, I can't figure out how to build it.
12:17:46 <earthy> (their goal for the past 10 or so years has been to popularize functional programming)
12:19:20 <monotonom> Certain academic research projects are funded by companies. These projects can very well work on things the company can use.
12:19:34 <earthy> that is rare though
12:19:44 <Smerdyakov> I'm funded by the US government to do whatever I want as long as I "make reasonable progress towards my degree." :D
12:20:16 <monotonom> Yes, you need to convince a company to pay you for writing a Haskell socket library to begin with.
12:20:31 <Smerdyakov> Well, you see, I have the next 5 years to do things like that.
12:20:52 <Smerdyakov> I don't need to justify particular projects on an individual basis to anyone.
12:20:52 <Smerdyakov> Just my overall progress.
12:21:37 <vegai> I really do envy the academic world of the US
12:22:09 <Smerdyakov> vegai, no need to envy. Come on over. :)
12:22:35 <vegai> if my life was a bit different, I probably would at least try to
12:22:41 <Smerdyakov> What's stopping you?
12:22:45 <vegai> family
12:23:15 <Smerdyakov> Blood relations or one you have started?
12:23:24 <vegai> also, I think almost everything else is better here ;)
12:23:32 <vegai> one I have started, yes
12:24:04 <stepcut> you can always start another one in the US
12:24:37 <vegai>  if I did that, I wouldn't be me
12:24:38 <stepcut> you might even need to, to get in, in the first place
12:24:57 <vegai> yeah ;P
12:25:20 <stepcut> hrm, look at all the repeated works
12:26:14 <Smerdyakov> I think students admitted to universities have ways of getting in to the USA.
12:34:14 <musasabi> but USAs society is not something one wants to get into... of course there are better areas there too
12:35:21 <vegai> one can get a nice compromise between peaceful surroundings and relatively high standards here
12:35:43 <vegai> perhaps there are places like that out in the US too, I can't tell
12:35:49 <musasabi> hum can one live there without an auto and credit card?
12:35:55 <vegai> easily
12:35:56 <vegai> as I do
12:36:10 <vegai> well, ok, I live quite near to a small city
12:36:19 <musasabi> I meant in the US
12:36:24 <musasabi> in Finland it is easy
12:36:35 * musasabi has neither
12:36:37 <vegai> oh, should've whoissed ya ;/
12:36:52 <monotonom> If you have a credit card, you may get by without an auto. Shop online. :)
12:37:24 <SamB> well, my mom is going to make me learn to drive soon.
12:37:27 <skew> if you are living at a university you will be fine, at least as an undergrad
12:38:51 <musasabi> vegai: btw where are you from more exactly?
12:38:58 <vegai> musasabi: Jyv‰skyl‰
12:39:18 <earthy> `To implement Algol 68 on an arbitrary machine one should have to do nothing but provide translators for two-level grammars and for the special subset of natural language, and then simply "run" the Report. \\ Unfortunately this is a bit difficult.' -- Hanno Wupper, AB 44.4.1
12:39:30 * earthy laughs out loud
12:39:39 <bring> haha
12:39:59 <musasabi> going to visit there in summer because of Finncon (scifi convention)
12:41:00 <bring> musasabi, vegai: is functional programming big in finland?
12:41:11 <musasabi> not very much :-(
12:41:43 <monotonom> At Turku, imperative programming (refinement calculus) is big. Ralph Back is there.
12:42:07 <musasabi> at univ. of helsinki there are separate people doing fp but nothing organized afaik
12:42:58 <vegai> ibid's here doing most of the FP-related stuff
12:43:31 <vegai> I guess I am too, but that doesn't mean much ;)
12:43:36 <Smerdyakov> musasabi, you mentioned living without an auto. This is easy in a city with good public transportation.
12:43:40 <monotonom> Imperative programming by way of refinement calculus can be thought of as functional programming. All you do is compose and pass around weakest preconditions :)
12:43:51 <musasabi> yes
12:44:01 <bring> Smerdyakov: too bad there aren't too many of those in the US :)
12:44:25 <Smerdyakov> I think most of them have quite adequate public transportation.
12:44:57 <Smerdyakov> Where I mean "big cities" by "them."
12:45:14 <bring> not LA 
12:45:40 <bring> but yeah, SF and NY are alright
12:47:09 <bring> I think the main problem with US cities is that most people live in suburban single-family houses
12:47:36 <bring> which creates huge suburbs, in which it is impossible to create decent public transportation
12:49:19 <bring> I lived for year in San Luis Obispo, a city of about 40000 ppl, which was claimed to have very good public transporartion
12:49:35 <bring> i.e. a bus every 40 minutes, stops running at 6 pm
12:49:47 <SyntaxNinja> is there a way to get GHC to stop after the template pass and show me what it produced?
12:49:51 <monotonom> LA is better than that.
12:49:54 <musasabi> "what are you talking about on irc?" "living in the US" "please don't scare me before bedtime!" (a conversation with my gf)
12:50:04 <bring> haha
12:50:17 <SyntaxNinja> musasabi: are you a foreigner?!?!?!?
12:50:33 <musasabi> SyntaxNinja: nope. 
12:50:33 <skew> SyntaxNinja: do you live in the USA?
12:50:34 <monotonom> Everyone is a foreigner to someone
12:50:38 <SyntaxNinja> whew
12:50:41 <SyntaxNinja> skew: yeah
12:50:47 <SyntaxNinja> I mean... doesn't everyone?
12:50:47 <SamB> SyntaxNinja: this channel is not located in the US.
12:50:50 <bring> hehe, getting from LAX to downtown LA with public transportation requires 2-3 transfers and takes about 2 hours
12:50:51 <musasabi> SyntaxNinja: I am not a foreigner as to compared to myself.
12:51:08 <skew> I thought you were with the Chalmers crew for some reason
12:51:10 * SyntaxNinja is suspicious
12:51:19 <SyntaxNinja> skew: not me
12:51:37 <musasabi> getting to the centre of Helsinki takes ~25 minutes by bus which runs every 15 minutes... and this is the neighbouring town.
12:51:57 <monotonom> Well airport is another story.  But when I was in LA (for the ACM programming contest world finals last year) we could go between hotel, beach, and the starry street by bus.
12:52:53 <monotonom> I am a foreigner to exactly those who are not foreigners to themselves.
12:53:18 <SyntaxNinja> Oo
12:53:40 <musasabi> to the airport it is 51min by bus (but would take ~40min by car)
12:53:55 <skew> monotonom: sorry, but that's a proof by contradiction of your nonexistence. Bye!
12:54:06 <earthy> time for beer ;)
12:54:12 <bring> LAX - downtown LA is about 20 km :)
12:54:28 <bring> and it still takes hours
12:54:31 <bring> but bus
12:54:36 <bring> s/but/by/
12:54:50 <skew> the traffic is much lighter around 4AM
12:54:53 <monotonom> Yeah even on taxi, it took us forever between hotel and airport.
12:58:08 <bring> getting by in the US if you live close to the university is possible, but if you want to go anywhere else, you pretty much need a car
12:58:53 <bring> unless you live in a major city with good public transport
12:59:23 <bring> hmm, that's slightly obvious, isn't it
12:59:57 * SyntaxNinja figured out the TH question
13:00:02 <SamB> hmm, wouldn't a bicycle also work for some things?
13:00:21 <skew> I guess the non-obvious part is that there are big cities with bad transportation, but univiersities are always set up so you can get by
13:00:24 <monotonom> Go to Beijing!  Everyone goes everywhere on bicycle. :)
13:01:15 <bring> yeah
13:01:53 <bring> it's when you wanna do more than getting by that it gets harder
13:01:58 <andersca> boom
13:02:26 <bring> like to going shopping
13:02:35 <monotonom> Alright I don't know about fp research in Beijing, but filtering (censorship) research is big there, which is technically just as cool (but of course morally I denounce it).
13:02:35 <bring> yeah yeah, online, I know
13:02:47 <bring> haha
13:03:05 <bring> I thought they bought their filtering gear from the US
13:04:39 <bring> andersca: how's public transportation out there in the woods?
13:04:56 * bring is not being nice tonight
13:05:33 <andersca> bring: you can fly to stockholm for SEK 360
13:05:50 <bring> bah, who wants to got to Stockholm?
13:05:59 <andersca> that's a good question
13:06:07 <bring> Sweden's back side as it were
13:06:17 <andersca> :)
13:08:07 <SamB> how about spam filtering instead?
13:09:15 <bring> what if everyone starts sending dissident spam to China, surely they would figure out a solution to spam in no time
13:10:37 <musasabi> swedes...
13:12:45 <stepcut> bring: yeah, outlaw email
13:12:51 <skew> install a swede on every perimiter router? Now THAT's a creative solution to spam
13:13:07 <bring> haha
13:13:47 <bring> btw, native english speakers, do you use "swede" or "rutabaga"?
13:14:14 <skew> no
13:14:23 <skew> at least, not often
13:14:46 <skew> why?
13:14:46 <bring> hehe, I mean what do you call it?
13:14:54 <skew> call what?
13:15:01 <bring> the plant
13:15:15 <bring> similar to a turnip
13:15:32 <skew> I don't know of that usage for "swede"
13:15:38 <bring> http://dictionary.reference.com/search?db=*&q=rutabaga
13:16:00 <skew> a rutabaga is a sort of plant, but I wouldn't know which just from that name
13:16:11 <bring> http://en.wikipedia.org/wiki/Swede
13:16:45 <musasabi> is that nauris ?
13:16:48 <skew> interesting. it could be a regional thing as well
13:17:11 <bring> musasabi: Brassica napus var. napobrassica
13:18:04 <bring> what's a nauris?
13:18:13 <musasabi> no, that is lanttu then.
13:18:17 * musasabi looks up nauris
13:18:28 <wagle> anyone know any good/cool/clever ways to simulate (?) subtypes in haskell?
13:18:42 <skew> wagle: phantom types, or typeclass stuff
13:19:09 <skew> at least if you want to simulate inheritance or something like that
13:19:14 <musasabi> nauris == Brassica rapa, smaller and sweeter than rutabaka
13:20:09 <wagle> Liang has a OR class that can get close to subtypes, but the checks are actually dynamic.. i want fully static ones
13:20:42 <musasabi> wagle: typeclasses?
13:20:50 <bring> wagle: is it for a particular problem?
13:21:33 <wagle> cheney and hinze's phantom types?
13:22:03 <musasabi> class ParenInterface ... instance ParentInterface Parent instance ParentInterface Child and so on ? 
13:22:24 <wagle> trying to understand monad transformers and moduler interpreters
13:22:46 <skew> I don't see how subclasses come in at all
13:23:02 <skew> what you probably want there are typeclasses of monads supporting certain operations
13:23:10 <wagle> musasabi: yeah..  
13:23:10 <skew> like the ones in Control.Monad.*
13:25:18 <monotonom> phantom type is like this iirc. For example data MyType a = MyCon String.  So now you can have: x = MyCon "hello" :: MyType Int; y = MyCon "hi" :: MyType Bool.  x and y are now considered to have different types.
13:26:16 <wagle> hmm..  Sheard's playing around with something like that
13:26:57 <monotonom> If you now hide MyCon from the user and only expose MyType and a few restrictive utility functions you write, you can enforce a certain type discipline.
13:27:22 <skew> next step is to make data ChildCon a, and expose type ChildType a = MyCon (ChildCon a)
13:27:38 <skew> then functions with types like MyCon a -> result will work on any subtype of MyType
13:28:04 <monotonom> (For example expose only x and y.  Then you are guaranteed that "hello" is associated with Int and "hi" is associated with Bool.)
13:28:39 <skew> (the phantom types are stuff like the Bool or Int, my stuff was about simulating inheritance with them)
13:32:43 <wagle> i havent gotten around to really understanding existential types.  what do you mean my expose?
13:33:28 <monotonom> module MyModule(MyType, x, y) where ...
13:33:43 <monotonom> you do not export MyCon, that's all
13:38:53 <wagle> Liang (1995) uses "data OR a b = L a | R b" to define a "class SubType sub sup" class with inj and prj functions..  it depends on overlapping instances 
13:39:20 <wagle> (hmm..  make that Liang, Hudak, and Jones (1995))
13:40:33 <wagle> unfortunately, some of its type checks are dynamic
13:40:46 <wagle> i was hoping for something like that that was fully static
13:40:59 <stepcut> so, under linux, is there a command to extract the contents of an ISO without mounting it on a loopback device?
13:41:18 <skew> maybe, but why not mount it?
13:41:24 <stepcut> speeeeede
13:41:30 <stepcut> in theory
13:41:43 <musasabi> stepcut: I don't think so.
13:41:44 <skew> I doubt it would make much difference
13:42:01 <musasabi> stepcut: if you have loop you can mount it as a loop back device
13:42:14 <musasabi> stepcut: but without root, I don't think so.
13:42:23 <musasabi> stepcut: if you find a way please tell me to
13:42:26 <musasabi> too even
13:42:34 <wagle> mount -o loop iso-image-file /mnt/pt
13:43:04 <stepcut> skew: well the .iso is on a CD, so the seek times are huge, in theory, a tar like program for .iso's might be access the .iso in a more linear fashion, resulting in faster extraction time
13:43:31 <skew> why didn't you burn the iso as a CD?
13:43:45 <skew> if you have space you could put it on disc
13:44:06 <wagle> well, if you let it be a first class file system (by mounting it), it will start using the buffer cache
13:45:06 <skew> a ramdisk even, if it's small enough
13:45:52 <stepcut> its a complicated setup with a bootable compressed live cd that installs to a hard drive
13:48:04 <stepcut> when the image to be installed to the harddrive was in a tarball, the install was very fast, but the install CD was big, because it had a bootable live file system, and a whole bootable system (which contained everything in the live image) in the tarball
13:50:25 <stepcut> so, instead, we made the install image also be bootable as a live cd, so you can boot the cd, and copy the contents to the hard drive. So the ISO is much smaller, but also installs much slower
13:50:56 <wagle> what disk operations are you thinking to avoid by not mounting the iso image as a file system.  you are going to have to read from the slow host cdrom no matter what you do
13:51:06 <stepcut> wagle: seeking
13:52:31 <wagle> an iso is a filesystem..  why wouldnt a real tuned, maintained, etc file system driver in a kernel be better than some adhoc thing running in user space?
13:52:51 <wagle> .. better at prefetching..
13:53:07 <stepcut> apparently not
13:53:16 <bring> stepcut: what filesystem does the target system use?
13:53:17 <wagle> ?
13:53:24 <stepcut> reiserfs 3
13:53:56 <wagle> you dont have a user space thing..  how can you say "apparently not"?
13:54:50 <stepcut> all I can say is that extracting the tarball was faster
13:54:57 <bring> would it be possible to burn a reiserfs image to the cd, then just have the kernel that boots from the CD mount that as its root fs, then copy the image bit by bit to the target
13:55:11 <bring> ah, maybe I misunderstood
13:55:32 <bring> are you installing en entire filesystem in the target, or just some files
13:55:41 <wagle> sure..  a tarball is optimized to sequential access.  a filesystem for random access
13:57:19 <wagle> a filesystem image is probably not a good format for a cache
13:57:20 <bring> or you could just make the whole CD have a reiserfs instead of iso9660, would probably be hard to boot from it though
13:57:38 <stepcut> i think the cd has ext2 right now
13:58:26 <stepcut> which might also be part of the problem
13:59:34 <bring> what size in the hard drive / flash / whatever that you are installing to?
13:59:39 <bring> s/in/is/
13:59:56 <stepcut> unknown
14:00:11 <stepcut> its a general purpose install cd
14:00:20 <bring> do you partition it during the installation?
14:00:23 <stepcut> yes
14:01:08 <bring> then can't you make a partition the size of the CD, then dd if=/dev/cdrom of=/dev/hda1 (or whatever it is)
14:02:03 <stepcut> bring: then mount it on loopback and copy the contents out?
14:02:47 <bring> well, either that, or even faster, just have the CD filesystem be the final filesystem that you want on the target
14:03:11 <bring> or keep a filesystem image on the CD that you dd straigt into the partition
14:03:46 <bring> and which the kernel booting from the CD can mount as loopback when booting itself
14:04:14 <bring> could be a compressed image even, you you need more space
14:04:21 <stepcut> we have talked about trying things like that
14:04:22 <bring> s/you you/if you/
14:04:49 <stepcut> one issue is that in order to get the max speed, the filesystem on the cd should be compressed
14:05:35 <bring> not quite sure I see how that makes it faster
14:05:50 <stepcut> because the CPU is faster than an ISO
14:06:00 <stepcut> err, faster than a CD
14:06:00 <bring> ah, ok
14:06:31 <bring> so you mean you copy a compressed image to the HD, then mount that and copy to the right place
14:06:34 <bring> ?
14:07:11 <bring> that would seem to be the fastest, if you have enough space on the hd
14:07:25 <stepcut> no, copy the compressed image, then reboot
14:07:26 <wagle> any leads on subtypes-in-haskell besides the phantom types one?
14:08:12 <bring> then what?
14:08:28 <stepcut> resize the partion and be done
14:08:42 <stepcut> leave the user with a compressed reiser 4 fs
14:08:54 <bring> ah
14:09:10 <bring> you want it compressed in the end?
14:09:15 <stepcut> possibly
14:09:54 <stepcut> hans reiser indicated that they actually get better performance in reiser 4 by enabling compression, because it allows them to exceed the bandwidth of the hard drive
14:09:56 <bring> wagle: what was it you wanted to use it for?
14:10:10 <bring> hmm, that's interesting
14:10:25 <stepcut> plus, you save space (unless you are just filling up the drive with mp3s ...)
14:10:39 <bring> makes sense though, seeing how CPU speed grows so much fast than IO and memort bandwidth
14:10:50 <stepcut> yeah
14:11:48 <stepcut> the CPU overhead was pretty low too
14:13:01 <bring> plus if you have lots of ram, most of the stuff you use will be in the block cache anyway
14:13:04 <stepcut> its an interesting concept that on-the-fly hard drive compression could actually improve overall speed and response
14:13:17 <stepcut> not just save space
14:13:50 * stepcut gets back to work
14:14:22 <bring> sort of like how sacrificing 'speed' for smaller code size in compiler optimizations can make your code run faster
14:14:48 <bring> that memory vs cpu, not io vs cpu, but still
14:14:58 <bring> stepcut: it sounds like you are working
14:15:40 <stepcut> well, i have to get back to work on something less exciting
18:35:37 <eixei> l
18:38:10 <reltuk> excellant...
21:03:50 <stepcut> mmm, tax law
21:09:32 <reltuk> indeed
21:09:40 <reltuk> have you written a haskell program to do your taxes yet?
21:10:00 <stepcut> no, but I might write a program to do my bookkeeping
21:10:33 <reltuk> see, an ai program that reads the irs documents and does your taxes would be much cooler :-p
21:11:29 <stepcut> Q: oh no, I underpaid my estimated taxes by $55,000, what should I do?  A: Buy an H2 hummer
21:11:53 <reltuk> lol
21:12:22 <stepcut> for 2 years only, the limit on section 179 deductions has been raised to $100,000 instead of $25,000
21:12:50 <stepcut> which means you can deduct the entire cost of equipment in 1 year istead of depreciating it over several
21:12:51 <reltuk> what are 179 deductions?
21:13:51 <stepcut> A passenger car would not qualify as a business deduction, but a light duty industrial truck would
21:14:21 <stepcut> the distinction between car and industrial truck is by weight, namely above or below 6000lbs.
21:14:45 <stepcut> Since the H2 weighs 8600lbs, it qualifies as a light-duty industrial truck
21:15:56 <stepcut> meaning, that with the increased limit on 179 deductions, you could write-off the entire cost of an H2 (~$55,000), this year and as a result, lower your taxable income
21:16:11 <stepcut> aren't taxes fun?
21:31:59 <reltuk> umm...b: no
23:08:00 <stepcut> sweet! I don't have to complete item J on Schedule K-1 because I answered Yes to question 5 on schedule B
