00:35:12 <dons> ?uptime
00:35:12 <lambdabot> uptime: 2 days, 6 hours, 17 minutes and 53 seconds
00:36:41 <dreamEye> @fortune
00:36:41 <lambdabot> Hackathon Moose (or other Ex-Magnificent-Forest-Creature) Barbecue
00:36:41 <lambdabot>  
00:36:41 <lambdabot> 30 cups oil
00:36:41 <lambdabot> 15 cups Soy sauce
00:36:41 <lambdabot> 5 cups Worcestershire Sauce
00:36:43 <lambdabot> [18 @more lines]
00:37:16 <dreamEye> @quote
00:37:17 <lambdabot> Pseudonym says: Lazy evalution is really, really trippy.
00:37:19 <dons> dreamEye: learning haskell?
00:37:29 <dreamEye> yes
00:37:53 <dons> how's the experience been so far? 
00:38:05 <dreamEye> wonderful
00:38:15 <dreamEye> I like Haskell
00:38:17 <dons> oh, great :) that's what i like to hear.
00:38:32 <dons> lambdabot's written in haskell, btw.
00:38:39 <dreamEye> I know
00:39:40 <dons> ?source
00:39:41 <lambdabot> lambdabot 3.1p35, GHC 6.4.1 (Linux i686 3.20GHz)
00:39:41 <lambdabot> darcs get http://www.cse.unsw.edu.au/~dons/lambdabot
00:40:13 <dreamEye> I discovered haskell 5 months ago
00:40:46 <dreamEye> and I have to say that I´m fascinated
00:40:49 <dons> how've you been learning it? just self-taught, reading tutorials, hanging out here? or do you have a course or a text book?
00:41:11 <dons> its a very addictive language, i feel.
00:41:12 <dreamEye> self taught by readin internet resources
00:41:24 <dons> you've seen the tutorials page on haskell.org?
00:41:25 <dreamEye> yes indeed
00:41:35 <dons> had any projects to hack on?
00:41:42 <dreamEye> I read "A gentle introduction to Haskell
00:41:52 <dons> any thoughts on a lambdabot plugin you'd like to write?
00:42:04 <dreamEye> I´m working on a Internet mini-portal
00:42:09 <dons> (quite a few beginners have written lambdabot plugins..)
00:42:16 <dons> ah, very interesting
00:42:28 <dreamEye> I did´nt care about lambdabot until yesterday
00:42:31 <dreamEye> is funny
00:42:40 <dons> what happened yesterday?
00:43:20 <dons> its useful for group discussion and interactive learning of haskell. also, just as a tool for looking up functions, searching for names and so on.
00:43:21 <dreamEye> I saw haskeel evaluation of expressions by lambdabot
00:43:25 <dons> ?hoogle a -> b -> (a,b)
00:43:26 <lambdabot> Control.Monad.RWS.execRWS :: RWS r w s a -> r -> s -> (s, w)
00:43:26 <lambdabot> Control.Monad.RWS.evalRWS :: RWS r w s a -> r -> s -> (a, w)
00:43:31 <dons> ?djinn a -> (a,a)
00:43:31 <lambdabot> f a = (a, a)
00:43:37 <dreamEye> I din't had notive begore about this functionality
00:43:38 <dons> > map (+1) [1..1-]
00:43:38 <lambdabot>  Parse error
00:43:41 <dons> > map (+1) [1..10]
00:43:42 <lambdabot>  [2,3,4,5,6,7,8,9,10,11]
00:43:43 <goltrpoat> i keep forgetting about djinn
00:43:51 <dons> ?type map
00:43:52 <lambdabot> forall b a. (a -> b) -> [a] -> [b]
00:43:54 <dreamEye> I din't had notice before about this functionality
00:43:59 <dons> ?kind Either
00:44:00 <lambdabot> * -> * -> *
00:44:17 <dons> ?pl \x y -> f x y
00:44:17 <lambdabot> f
00:44:38 <dons> ?pl \x y -> (f x, f y)
00:44:38 <lambdabot> (. f) . (,) . f
00:44:53 <dons> the 'pointless' plugin is i think, my favourite.
00:45:05 <goltrpoat> oh, reminds me.
00:45:16 <goltrpoat> @pl \a b c d -> (a b) . (c d)
00:45:16 <lambdabot> (((.) . (.)) .)
00:45:23 <goltrpoat> jesus.
00:45:28 <goltrpoat> nevermind
00:45:35 <dons> hehe
00:46:10 <dreamEye> it´s a very good idea
00:47:01 <dreamEye> I'll think about a new module
00:47:30 <dreamEye> where is the developer's info about lambdabot?
00:47:33 <dons> often good ones to start are plugins that lookup some data on the web, or run a program.
00:47:39 <dons> well, in the source mostly
00:47:53 <dons> grab the darcs src, and start hacking in Plugins/ looking at the other plugins for examples
00:48:14 <xerox> @karma-all
00:48:14 <lambdabot>  dons                   35
00:48:14 <lambdabot>  Lemmih                 17
00:48:14 <lambdabot>  shapr                  17
00:48:14 <lambdabot>  xerox                  15
00:48:14 <lambdabot>  dcoutts                14
00:48:16 <lambdabot> [160 @more lines]
00:48:23 <xerox> Ah-ha, here's who screamt.
00:48:29 <vincenz> Are you allowed to have overlapping names for tycons and class names?
00:48:35 <goltrpoat> ive been sort of thinking of trying a symbolic integration program.  i mean, i know that's a ton of work, just figured it'd be sort of fun to do, and haskell seems like the perfect language for it
00:48:42 <xerox> Ohayou!
00:48:59 <goltrpoat> be cool to bundle that some simpler symbolic stuff and turn it into a plugin
00:48:59 <vincenz> ?
00:49:10 <dons> goltrpoat: hmm, yeah, that'd be kinda fun
00:49:44 <xerox> Calculus in \bot?
00:50:06 <dreamEye> it would be very nice
00:51:32 <goltrpoat> i actually don't have the slightest clue about how, say, mathematica, does symbolic differentiation.  i remember reading something from wolfram that said that it's nothing like what humans do, i.e. you're not trying to pattern match against integration by parts, or finding substitutions, etc
00:51:40 <goltrpoat> er.  symbolic integration, i mean
00:51:47 <goltrpoat> i'm pretty sure i know how it does symbolic differentiation, haha
00:52:41 <dreamEye> you can take a look at Maxima, a open source mathematical package made in Lisp
00:52:52 <dreamEye> it does symbolic integration and more
00:52:52 <goltrpoat> yeah, ive heard a lot about maxima, been meaning to take a look at it
00:53:05 <dreamEye> but Lisp is very hard to reverse enginer
00:53:29 <dreamEye> I say it by experience. It´s like assembler!
00:54:39 <dreamEye> I also had Musimp, that did SI and the code was much more readable, in a sort of evolved lisp
00:54:57 <goltrpoat> haven't heard of musimp
00:55:27 <goltrpoat> oh that's the mumath language
00:55:43 <dreamEye> it was amusing. a little progran that ran in MSDOS machines with 200Kbytes of memory
00:55:49 <dreamEye> yes, mumath
00:56:20 <goltrpoat> 'evolved lisp' ?  doesn't lisp self-evolve? :)
00:57:07 <goltrpoat> project-wide i mean
00:57:30 <dreamEye> hehe, mumath is very readable. it´s easily portable to haskell I guess
00:58:54 <dreamEye> Unfortunately I lost the progran and I don´t find any download location
00:59:42 <dreamEye> I think the authors would be proud if someone port musimp to a haskell library
01:01:44 <dreamEye> It had fourier series , matrix operations and a lot more
01:01:46 <goltrpoat> speaking of.  say we have two ASTs that give an expression, that we're trying to manipulation somehow.  it'd be hugely beneficial to ask whether or not two ASTs are equivalent
01:02:09 <dons> goltrpoat: equivalent in what sense?
01:02:20 <goltrpoat> is there some sort of a trick, like showing an isomorphism on the fixed points of the reduction rules, or some such
01:02:25 <dons> under reduction, identical, alpha-equivalent?
01:02:31 <goltrpoat> identical
01:02:37 <dons> deriving Eq then.
01:02:44 <goltrpoat> x*2 = 2*x, sin(x)^2 + cos(x)^2 = 1
01:03:08 <goltrpoat> well yeah, but, implementation-side.
01:03:17 <dons> ok, so that's not identical, that's identical modulo, what, hmm, beta reduction and what's the first case? 
01:03:22 <goltrpoat> i mean i can sort the AST in the first case, and i can apply redexes in the second and hope for the best.
01:03:25 <dons> so what happens in the case your program loops?
01:03:44 <goltrpoat> loops?
01:03:45 <dons> you wont know it loops till you attempt to reduce it, then bang
01:03:51 <dons> diverges
01:04:11 <audreyt> well, set an alarm() ;)
01:04:16 <dons> heh
01:04:45 <dons> goltrpoat: alpha-equivalence is fairly useful. I used alpha-equivalence to check for cheating in an assignement once
01:05:04 <goltrpoat> sec, i should look this up.
01:05:05 <dons> so, compare to people's programs, after parsing (so whitespace and comments don't help), and modulo variable names
01:05:43 <goltrpoat> oh
01:05:45 <dons> and all I had to do was derive Read on the AST, and do an alpha-equivalence equality function
01:05:58 <goltrpoat> so \x -> x * 2 is equivalent to \y->(y*2)
01:06:15 <goltrpoat> in that sense?
01:06:22 <dons> but in general, equivalence of two programs under reduction == halting problem, it would seem.
01:06:26 <dons> goltrpoat: yeah.
01:06:27 <goltrpoat> but \x -> x * 2 is not alpha-equivalent to \y -> 2 * y?
01:06:40 <Cale> right
01:06:41 <dons> nope. that's some extra transform you've applied
01:06:42 <goltrpoat> yeah i had various vague non-decidability alarms going off in my head
01:06:54 <Cale> You used the commutativity of multiplication there
01:07:02 <Cale> (which may not always hold in Haskell!)
01:07:10 <goltrpoat> right, assume y's typed
01:07:26 <goltrpoat> or.. both expressions are typed, rather.
01:07:34 <dons> hmm. with rewrite rules you might just be able to get away with alpha equivalence..
01:07:41 <goltrpoat> actually..  hell, let's just assume commutativity of +, - and * to make the examples make sense
01:07:45 <dons> as long as you provide extra rewrite rules for all the cases you want to handle
01:07:49 <Cale> not of -
01:07:55 <goltrpoat> pardon.  + and * :)
01:07:55 <dons> then deriving Eq would handle the result after rewriting.
01:08:05 <dons> Cale, don't you think that woule be a neat idea? :)
01:08:28 <goltrpoat> yeah, i was doing something similar while simplifying expressions a little while ago, i would sort the stuff on the same level of AST by type constructor
01:08:47 <goltrpoat> so all variables end up at the left, say, and are lexically sorted
01:08:57 <Cale> dons: perhaps if there's a way to make it safe :)
01:08:58 <goltrpoat> and then comparisons sort of make sense
01:09:03 <goltrpoat> it seemed like a kludge though.
01:09:25 <dons> so you'd have, \x -> x * 2 `alpha` \y -> y * 2 , with {-# RULES forall x . x * 2 = 2 * x #-} -- you'd need a case for all lits you're interested in
01:09:32 <dons> so you'd have to generate that list of rules
01:10:02 <Cale> I sort of think that we need a better, safer way to handle rules
01:10:13 <Cale> in particular, it should be typed
01:10:19 <dons> oh, they are typed.
01:10:32 <Cale> does GHC even check that both sides of a rule are equally typed?
01:10:34 <dons> but they're not checked for termination, or equivalence
01:10:47 <dons> yeah. they have the same type.
01:11:01 <goltrpoat> sorry.. what are rules? :)
01:11:07 <Cale> well, that much is good
01:11:15 <goltrpoat> i get the feeling i was asking for something similar a little while ago while writing some algebra types
01:11:15 <xerox> Cellular automatas :-P
01:11:37 <Cale> It still feels really low-level
01:11:39 <dons> but they're not checked for confluence or termination.
01:11:58 <xerox> ...pardon, confluence?
01:12:00 <goltrpoat> eg, * is a binary operation on F, which commutes and distributes wrt +
01:12:00 <dons> confluence seems too hard. termination is fairly easy to spot.
01:12:00 <Cale> Well, you can't really check that too easily, without the programmer supplying a proof...
01:12:17 <dons> xerox: that both sides reduce to the same canonical form (iirc)
01:12:17 <Cale> It would be cool to have a language where proof could be provided and compiler checked.
01:12:34 <Cale> is it?
01:12:35 <xerox> Coq? (:
01:13:05 <dons> yes, you certainly want some proof (or at least QC property) for your rule.
01:13:21 <dons> luckily, there's at least a trivial transformation for every rule into a QC property
01:13:39 <dons> turning that into a proof .. well, i hope to find out on tuesday from an Isabelle guy
01:13:46 <Cale> The only problem I have with machine provers/proof checkers is that people start to get the idea that mathematics should be done that way.
01:14:07 <dons> hehe. it shouldn't be??
01:14:10 <goltrpoat> i don't think there is any danger of that :)
01:14:22 <cpatrick> Cale: only people who haven't actually _used_ them, I think.
01:14:44 <dons> well... i'm not sure. i know a few CS theory guys who laught at math proofs for their lack of rigour
01:15:03 <dons> the assumptions that are , hmm, assumed.
01:15:10 * xerox . o O (interesting discussion!!!)
01:15:10 <Cale> Mathematics proofs *are* rigourous, to quite an amazing extent
01:15:21 <Cale> It's just that we don't write down everything which is boring.
01:15:31 <xerox> Random though: maybe it is because of the notation that the CS guy think so?
01:15:34 <dons> yeah. that's the difference that cs theory people point out
01:15:37 * cpatrick nods
01:16:02 <goltrpoat> dons:  that's an .. odd stance :)
01:16:03 <Cale> Computers are stupid, so they need to have their hands held through everything, whereas humans easily recreate all the "missing" steps from the important ones.
01:16:12 <cpatrick> People didn't realise quite how much boring stuff there was to assume in maths until they tried to make it completely rigorous, though.
01:16:21 <Cale> Right
01:16:27 <dons> yep
01:16:28 <cpatrick> e.g. principia mathematica and its ilk
01:16:55 <Cale> But then GÃ¶del came along and showed them that it didn't really matter.
01:17:01 <Cale> hehe :)
01:17:03 <xerox> Unfortunately the `rigor hypothesis' makes me fall in the case analysis every every every time I want to prove something.
01:17:06 <goltrpoat> and then there was much laughter and frolicking.
01:17:17 <xerox> ...and I feel that it isn't a good thing in general.
01:17:43 <dons> hands up if you knew specialisation in ghc was done with dynamically generated rewrite rules?
01:17:44 <Cale> The thing is, starting from Peano's axioms can be just as rigourous as Russel and Whitehead's (if you're talking about first order number theory)
01:17:51 * dons just finds this out
01:18:07 <audreyt> strangely, I know that :)
01:18:56 <goltrpoat> but that doesn't make sense.  you don't start a paper on CS by introducing the UTM and going from there.
01:19:05 <Cale> One thing I really want to know is the reasoning behind the removal of Laws
01:19:06 <xerox> IIRC Dijkstra didn't like case analysis.
01:19:14 <Cale> (a.k.a. non-free types)
01:19:48 <Cale> xerox: it's not always case analysis
01:20:17 <xerox> Cale - Every time there's an absolute value, you are done ):  Well, I am.
01:20:40 <Cale> Usually what I do is treat absolute values as distances
01:20:47 <Cale> and use the properties of distance functions
01:20:55 <Cale> (at least, when it's possible)
01:21:06 <xerox> I wonder if there are explanations of other general means of proving, like this one, somewhere?
01:21:07 <Cale> i.e. |a-b| is the distance from a to b
01:21:21 <Cale> and |a| = |a - 0| is the distance from a to 0
01:21:27 <xerox> Right.
01:21:39 <Cale> the only case where that doesn't work is when you use the rule that |ax| = |a| |x|
01:22:45 <xerox> http://en.wikipedia.org/wiki/Distance_function
01:22:46 <goltrpoat> |ax| = |ax-0| = |(a-0)(x-0)| = |a-0| |x-0| = |a| |x|, no?
01:22:48 <Cale> but really, all you need to work with absolute values are a few inequalities and some other properties like that one
01:23:09 <Cale> goltrpoat: well, you used the multiplicative rule in the middle there
01:23:10 <goltrpoat> or was there some specific property that you were losing
01:23:35 <Cale> Really, what I'm saying is to treat |a-b| as d(a,b) from a metric space
01:23:45 <goltrpoat> oh you're saying it's a metric on R^1, x is a vector, and a is a scalar
01:24:09 <Cale> yeah, |a||x| is sort of the "normed vector space" property
01:24:15 <goltrpoat> right
01:24:38 <Cale> whereas basically all the other interesting properties come from the fact that it's a metric space
01:24:57 <Cale> and metric spaces are nice and easy to work with because there are so few rules to think about
01:25:05 <goltrpoat> -nod-
01:25:25 <Cale> (hehe, that's not quite true, but half true anyway)
01:25:34 <goltrpoat> hehe
01:25:35 <xerox> Any pointers on those metric spaces?  Wikipedia is a bit dry.
01:26:04 <Cale> A metric space is a set X with a function d: X x X -> X with three properties:
01:26:11 <Cale> d(x,x) = 0
01:26:15 <Cale> d(x,y) = d(y,x)
01:26:17 <goltrpoat> well, in E^1 it gets a little silly.. what's the gradient of my uh.. scalar field |x|?  oh it's the gradient of |x|, eh.  oh, what's that now?  oh it's uh..  it's not quite there at zero, we're working on it.
01:26:19 <xerox> Okay, that's wikipedia :)
01:26:26 <Cale> d(x,z) <= d(x,y) + d(y,z)
01:26:39 <Cale> (I'm going to talk about them)
01:26:50 <Cale> The first one says that the distance from a point to itself is 0
01:27:14 <Cale> the second says that the distance between two points is the same no matter which one you start at
01:27:26 <Cale> (there are no hills to climb)
01:27:50 <Cale> and the third is called the triangle inequality
01:28:20 <Cale> It says that the distance between two points is no more than the sum of the distances going through a third point
01:28:41 <Cale> You can't get some magical shortcut by going via a third point.
01:29:00 <Cale> There are plenty of interesting metric spaces.
01:29:18 <Cale> One of my favourites is the discrete metric space.
01:29:22 <xerox> If there were hills or climbs, I see that this third wouldn't hold, but I am not sure about the second.
01:29:27 <Cale> Let X be any set
01:30:12 <Cale> Well, by the hill climbing thing, I was referring to the idea that it's not as easy to go up a hill than to go down
01:30:25 <xerox> ..speed?
01:30:43 <Cale> yeah, if you measured distances between points with time taken or something :)
01:31:04 <xerox> Ah well, I see.
01:31:19 <Cale> It was a bit of a weak metaphor :)
01:31:28 <xerox> If x is on the Everest, and y on a boat... (:
01:31:51 <xerox> But it makes sense for the third case, doesn't it? It really says "it's flat".
01:31:52 <goltrpoat> cale:  this would be a good time to bring in grad d :)
01:32:14 <goltrpoat> with x fixed or whatever.
01:32:20 <Cale> well, sort of
01:32:31 <Cale> but even distances on a sphere satisfy that
01:32:33 <goltrpoat> (re the hill climbing)
01:32:39 <Cale> so we can't take it too far :)
01:32:43 <xerox> Right :D
01:33:02 <Cale> what we mean by "flat" is sort of nebulous here, so it could get us into trouble :)
01:33:20 <Cale> goltrpoat: grad d?
01:33:46 <dreamEye> gradient I suppose
01:33:58 <xerox> How is written on the wikipedia page that ``it works on a sphere'' ?
01:33:59 <Cale> Here's a good example metric space which will proably challenge the picture you have in your head :)
01:34:08 <xerox> Okay (:
01:34:16 <Cale> Pick a set X, any set you like
01:34:29 <Cale> could be infinite, doesn't matter
01:34:48 <Cale> define d(x,x) = 0 for x in X, and d(x,y) = 1 when x /= y
01:35:00 <Cale> then (X,d) is a metric space
01:35:53 <xerox> Eek. I feel like Achilles now. I picked R^2.
01:35:55 <Cale> (Called the discrete metric space on X)
01:36:06 <Cale> sure
01:36:11 <Cale> R^2 is fine
01:36:38 <Cale> just that this really doesn't correspond to the usual metric or topology on R^2
01:36:41 <xerox> So the distance between (0,0) and (1,1) is 1, and the distance between (0,0) and (2,2) is one?
01:36:47 <Cale> yep
01:37:14 <dreamEye> if you consider mass distortion you can test the CPU performance by using the relativistic tensor metrics
01:37:16 <Cale> If you're standing at any point in the space, every other point is at distance 1 from you.
01:37:33 <xerox> I was thinking what sense does that make.
01:37:51 <Cale> It's really easy to check that it's a metric space too :)
01:38:13 <xerox> The first two properties are given, the third says 1 < 2.
01:38:16 <Cale> But even with such strange examples, it's amazing how much can be proved about metric spaces.
01:38:19 <Cale> yeah
01:39:10 <dreamEye> but one metric space is a bit special: our own
01:39:34 <cpatrick> dreamEye: the only problem is, we're not sure _which_ metric space we live in :-P
01:39:39 <xerox> Where you define d(x,y) as |a-x| !
01:39:42 <xerox> Err.
01:39:48 <xerox> You see what I mean (:
01:39:56 <cpatrick> It looks a bit like R^3, only Einstein showed it wasn't really
01:40:21 <Cale> Here's another one... take R^2, and define the distance between (x1,y1) and (x2,y2) as |x1-x2| + |y1-y2|
01:40:30 <Cale> this is called the taxicab metric
01:40:44 <goltrpoat> or manhattan metric
01:40:49 <Cale> right
01:40:50 <dreamEye> cpatrick well, it does't matter if you need to measure the sufrace of the cubicle where I work
01:41:09 <xerox> No squares and roots?
01:41:11 <Cale> The idea being that you get between two points by travelling parallel to the coordinate axes
01:41:19 <Cale> not in this case
01:41:37 <xerox> Right, I see what you mean.
01:41:45 <goltrpoat> the "manhattan" bit comes from the idea that if you walk two blocks south and two blocks north, you are "four blocks away" from where you started from
01:42:03 <Cale> goltrpoat: s/north/east/
01:42:05 <xerox> heh!
01:42:08 <goltrpoat> haha
01:42:11 <goltrpoat> goddamn.
01:42:19 <goltrpoat> yes, replace one of those with east or west
01:42:31 <xerox> That was okay too, silly manhattians!
01:42:33 <dreamEye> a amusing task is to find te geodesic between two points in a given metric space
01:42:36 <xerox> Just kidding (:
01:42:57 <Cale> dreamEye: it's not always well-defined of course
01:43:31 <xerox> ``the generalization of the notion of "straight line" to "curved space"''
01:43:48 <dreamEye> you mean that there may be many geodesic lines ?
01:44:08 <Cale> with the taxicab metric, there are uncountably many geodesics between any two distinct points
01:44:09 <xerox> ``In mathematics, a geodesic is a generalization of the notion of "straight line" to "curved spaces".''
01:44:15 <Cale> er
01:44:18 <xerox> That's what wikipedia states, dreamEye.
01:44:19 <Cale> er
01:44:22 <Cale> hehe
01:44:23 <dreamEye> for example the geodesic between opposite points in a sphere
01:44:36 <Cale> any two points both of whose coordinates differ :)
01:44:51 <dreamEye> there are infinite geodesic lines there
01:44:55 <Cale> yeah
01:44:56 <xerox> Do that geodesic go inside the sphere or on the surface?
01:45:17 <dreamEye> in the metric defined in the sphere surface of course
01:45:29 <Cale> It's a little strange to even define "geodesic"
01:45:36 <Cale> but I suppose it's doable
01:45:46 <xerox> ``If the space carreis a natural metric then the geodesics are defined to be (locally) the shortest path between points on the space.''
01:45:56 <goltrpoat> dreameye:  take a chess board, and use the manhattan metric.  what's the shortest path from a1 to c8?
01:45:59 <xerox> I like the `natural' part :)
01:46:20 <dreamEye> it is supposed tha a mass in the real space follows a geodesic. Satelites describe geodesic lines in the relativistic metric
01:46:22 <xerox> goltrpoat - Distance 8 ?
01:46:25 <Cale> I suppose that we can easily enough talk about paths in the usual topological way as continuous images of [0,1]
01:46:51 <dreamEye> goltrpoat : I can´t even imagine....
01:47:05 <cpatrick> goltrpoat/xerox: 9, surely
01:47:13 <xerox> Nine you say...
01:47:30 <goltrpoat> dreameye:  well, there's two across, eight up, or there's one up, two across, seven up, or two up, two across, six up, etc.
01:47:31 <cpatrick> two squares right, seven squares up
01:47:35 <goltrpoat> all are geodesics.
01:47:56 <xerox> goltrpoat - Right, then I didn't misunderstand the question ! :)
01:47:58 <dreamEye> all are the shortest path?
01:48:00 <goltrpoat> er.  7, 6, 5, not 8, 6, 7.
01:48:02 <goltrpoat> yes
01:48:03 <cpatrick> dreamEye: yep
01:48:22 <Cale> Better to say that there is no minimum path, but that there are minimal ones.
01:49:12 <xerox> (To quote shapr, I wonder what are they talking now on, say #drupal -- <grin>)
01:49:26 <Cale> of course, if you want to get stupidly picky, by using a discrete chessboard, there are no geodesics, because it's totally disconnected :)
01:49:39 <xerox> (That is to say that the discussion was illuminating so far!)
01:50:28 <Cale> (but we might be able to redefine "path" so that it makes sense :)
01:50:32 <xerox> Cale, it is because discrete =/= natural ?
01:50:55 <dreamEye> not, according with quantum mechanics
01:50:59 <Cale> xerox: Well, let me give the usual definition of path
01:51:21 <Cale> for which I'll need a definition of a continuous function
01:51:37 <goltrpoat> uh oh.
01:51:41 <Cale> If (X,d) and (Y,d') are metric spaces, and f: X -> Y
01:52:06 <dreamEye> If God exist, why there are discontinuous functions?
01:52:35 <dreamEye> (joking)
01:53:11 <cpatrick> Sounds like Euler (Gauss?) with "e^pi*i + 1 = 0, therefore god exists", only backwards.
01:53:27 <goltrpoat> i remember reading that that never happened
01:53:28 <xerox> (Euler)
01:53:36 <Cale> then f is continuous at a point x in X if for every epsilon > 0, there exists delta > 0 such that if d(x,y) < epsilon, then d(f(x), f(y)) < delta.
01:53:52 <xerox> Cale, do it non-standardly! :D
01:54:01 <Cale> we can do better
01:54:01 <goltrpoat> dear god please don't do it non-standardly.
01:54:08 <goltrpoat> that's palomer's domain.
01:54:10 <Cale> Let's define one more thing :)
01:54:14 <xerox> Okay (:
01:54:36 <dreamEye> what is I in e^pi*i + 1 = 0  ??
01:54:53 * xerox gets a cup of green tea
01:54:56 <cpatrick> Cale: no no, define it in terms of open balls so that you can generalise to topological spaces :-P
01:54:58 <goltrpoat> dreameye:  i^2 = -1.
01:54:59 <cpatrick> dreamEye: sqrt(-1)
01:55:00 <Cale> If x is in X, and r is a real number, define B(x,r) = {y in X, d(x,y) < r}
01:55:13 <dreamEye> ok, i supposed that
01:55:16 <Cale> That's what I'm doing :)
01:55:20 <goltrpoat> cale:  oh you rock.
01:55:32 * cpatrick grins
01:55:32 <xerox> What is B ?
01:55:46 <xerox> The Ball!
01:55:47 <Cale> B(x,r) is called the (open) ball of radius r at x
01:55:53 <cpatrick> xerox: Think of a volume enclosed inside sphere, not including the surface of it
01:56:06 <Cale> Then what does f being continuous say?
01:56:19 <cpatrick> (only it might not actually be 'spherical-looking' depending on your metric)
01:56:20 <xerox> That the balls are tangent at every point?
01:57:42 <dreamEye> there is a web site on discontinuous universes and the possibility that our universe is a simulation in a turing machine
01:57:55 <goltrpoat> the question still open?  balls of radius epsilon have things inside them, no matter what the epsilon.
01:58:32 <goltrpoat> (this must be what dons was talking about when he said that CS people say that mathematics lacks rigour)
01:58:48 <xerox> May you explain the continuous hypothesis per-e?
01:58:51 <xerox> *per-se
01:58:59 <goltrpoat> ("things" is, in fact, the technical term)
01:59:00 <xerox> (In this specific case)
01:59:38 <vincenz> CHECK IT OUT
01:59:39 <vincenz> my compiler works
01:59:40 <vincenz> http://rafb.net/paste/results/o2jZeS51.html
01:59:45 <vincenz> \\\\o////
02:00:14 <Cale> We can actually say that it means that for any epsilon > 0, there exists a delta > 0 such that the image of the ball of radius delta around x under the function f is mapped inside the ball of radius epsilon around f(x).
02:00:33 <Cale> vincenz: good god, you have a lot of arms
02:00:56 <vincenz> :)
02:00:57 <xerox> He's tricking human vision ;)
02:01:00 * cpatrick laughs
02:01:02 <vincenz> check out the link
02:01:05 <vincenz> I only print the toplevel stuff
02:01:13 <vincenz> cause I haven't made a pretty printer for my AST ye
02:01:16 <Cale> yeah, your language is looking good :)
02:01:22 <xerox> Cale, and that works in the other way around, if you pick the latter ball as the starting one?
02:01:28 <dreamEye> what compiles your compiler vincenz?
02:01:33 <vincenz> dreamEye: haskell
02:01:37 <cpatrick> vincenz: it looks very much like Haskell
02:01:38 <vincenz> 70 hours
02:01:47 <vincenz> cpatrick: yeah except it has refs, is strict and lacks monads
02:01:56 <cpatrick> ahh righty
02:01:58 <xerox> So, scheme48, we'll have haskell70 :D
02:02:00 <dreamEye> wow
02:02:07 <vincenz> cpatrick: but possibly I could reuse part of it to create a haskell compiler
02:02:08 <Cale> xerox: not quite...
02:02:13 <vincenz> cpatrick: shouldn't be too hard
02:02:32 <vincenz> module system works nearly like the haskell module system (with a few small limitations I added cause I felt like it)
02:02:59 <xerox> G'day davidhouse.
02:02:59 <cpatrick> vincenz: so it's kind of the offspring resulting from that night when OCaml got Haskell really really drunk ...
02:03:07 <vincenz> cpatrick: yeah
02:03:14 <vincenz> I prefer haskell module sysetm
02:03:15 <goltrpoat> cale:  do go on.
02:03:16 <Cale> xerox: but we define an open set as a set U such that for any x in U, there is some epsilon such that B(x,epsilon) is a subset of U
02:03:16 <vincenz> ocaml shadows
02:03:20 <vincenz> and is lexically scoped
02:03:30 <vincenz> I prefer place func anywhere and have recursive defs at toplevel by default
02:03:50 <Cale> And it turns out that it's just as good to define continuity by saying that the preimages of open sets are open.
02:03:52 <vincenz> I don't have data constructors yet
02:03:55 <vincenz> or tycons
02:03:57 <vincenz> that's the next part
02:04:12 <vincenz> only tuples, tuple patterns
02:04:16 <xerox> Cale, I think I see what you mean by that, it is "unbounded" or "infinite"
02:04:34 <Cale> not necessarily
02:04:43 <Cale> remember that discrete metric space?
02:04:51 <vincenz> hmm
02:04:51 <xerox> YEs
02:04:51 <Cale> Every subset of that space is an open set
02:04:52 <cpatrick> xerox: the empty set is open ;-)
02:04:57 <vincenz> is it possible to define an FFI data type?
02:05:08 <vincenz> data X  (no def)
02:05:10 <Cale> also the empty set is always open, and the whole metric space too
02:05:17 <xerox> Cale, but then you "cut" the Balls on the bounds?
02:05:32 <xerox> I think I am tied to the wrong picture of the metric space.
02:05:45 <xerox> There are no such things as bounds on the discret metric space, maybe.
02:06:04 <cpatrick> xerox: nah, you only get the hang of this by asking lots of questions, which the mathematicians then make you feel daft for asking
02:06:18 <Cale> hehe
02:06:29 <xerox> Cale is a great guy (:
02:06:38 <vincenz> How do I define data types whose implementation is hidden (bolted into the compiler) in haskell
02:06:44 <goltrpoat> keep in mind the idea of an open ball as everything whose distance, under whatever metric we care about, to something or other, is less than some constant
02:06:48 * vincenz wants to keep the same syntax
02:07:17 <goltrpoat> and then don't concentrate on the particular metric
02:07:22 <xerox> goltrpoat - so balls are empty on our discrete metric space, if we pick radius 1 ?
02:07:43 <eivuokko> vincenz, Isn't that obviously up to the compiler?  You can always hide names from a module by not exporting them.
02:07:48 <goltrpoat> which discrete metric space?  the (x,x) = 0, and 1 otherwise one?
02:07:50 <xerox> I wonder how one is going to make sense of this without concentrating on something, sorry! :)
02:07:51 <Stinger_> ball will contain the point its centered on
02:08:00 <xerox> goltrpoat - Yes, that one we previously defined.
02:08:46 <goltrpoat> xerox:  the open ball at x contains x and nothing else
02:08:54 <xerox> Okay.
02:09:10 <vincenz> out of curiousity...
02:09:13 <vincenz> n
02:09:14 <vincenz> nm
02:10:07 <xerox> So our continuous function F is mapping all the points inside the ball to another ball?
02:10:52 <xerox> I am not sure about what does it imply that no matter how we choose epsilon, there exist a delta, here.
02:15:17 <davidhouse> hi xerox, sorry, i was a little distracted
02:15:43 <xerox> Today's topic is metric spaces (:
02:15:48 <goltrpoat> the cauchy definition that cale started out with, modified a little, says that we can do this.  pick a ball around a point, x, say, with radius epsilon.  epsilon is up to you.  once you pick a particular epsilon, i say that i can pick a vector delta, such that for any y in d(x, x+delta), the value of the (supposedly continuous) function f(x) will be between f(x-delta) and f(x+delta).
02:15:50 <davidhouse> aha. they're good fun
02:16:19 <davidhouse> goltrpoat: you missed that epsilon and delta are > 0, which is vitally important
02:16:30 <Cale> goltrpoat: that's assuming that there's addition :)
02:16:34 <goltrpoat> delta is a vector, but yes for epsilon
02:16:37 <goltrpoat> and that.
02:16:43 * xerox scratches head
02:17:03 <goltrpoat> cale should keep doing what he was doing, i'm getting really rather remarkably drunk here.
02:17:10 <davidhouse> what are we defining? continuous functions?
02:17:15 <xerox> Thank you goltrpoat!
02:18:09 <xerox> A clarification, in general f(x) isn't in the ball B(x,epsilon) right?
02:18:28 <goltrpoat> no, but x obviously is.
02:18:36 <Stinger_> f(x) doesnt even have to be in the same space
02:18:44 <goltrpoat> f could be a scalar function of bananas for all you care.
02:18:49 <davidhouse> :)
02:19:01 <xerox> Oh, that's helpful! *grumble*
02:19:04 <davidhouse> f : R^3 -> Bananas
02:19:08 <goltrpoat> hehe
02:19:28 <Cale> hehe
02:19:37 * davidhouse goes off to church
02:19:40 <goltrpoat> (in which case, if you pick a scalar epsilon, i can pick a banana delta, such that yada yada)
02:19:48 <Cale> What's yellow and complete under the induced metric?
02:19:54 <davidhouse> (nothing to do with lambda calculus, for all you pun fans out there)
02:20:06 <Stinger_> haha
02:20:12 <Cale> A: A banananach space :)
02:20:25 * xerox sighs
02:20:46 <goltrpoat> that has got to be at least fifty years old
02:20:50 <goltrpoat> hehe
02:21:42 <goltrpoat> cale:  you should go back to the whole cts functions take open sets to open sets bit.
02:22:13 * xerox hops up and down furiously
02:22:31 <Cale> They don't necessarily take open sets to open sets
02:22:41 <Cale> The preimages of open sets are open sets
02:22:55 <Stinger_> preimage = inverse image?
02:23:10 <xerox> Is there a wordy explanation of what the point is?
02:23:16 <Cale> yes
02:24:01 <Cale> That is, if f: X -> Y is continuous, and U is open in Y, then f^-1(U) = {x in X: f(x) is in U} is open in X.
02:24:54 <Stinger_> I vaguely remember that :)
02:25:11 <Cale> and in fact, the converse is also true, that if for every open set U in Y, the function f: X -> Y has the property that f^-1(U) is open, then f is continuous.
02:25:26 <xerox> Cale - Do you usually grasp new concept via definitions?
02:25:49 <Cale> This is, in fact, how continuity gets generalised to topological spaces, where all you define is which sets are open, and you don't even talk about distances.
02:26:15 <Cale> xerox: definitions and propositions, and then some theorems and I'm starting to get a good handle on it :)
02:26:42 <Cale> The definition is a good starting point here.
02:27:02 <xerox> Okay, then it's my fault I am not exactly following what continuity is here.
02:27:41 <Cale> Okay, well, it's good to see how it lines up with the usual idea of continuity
02:28:26 <Cale> Do you understand the original definition I gave?
02:28:31 <Cale> (With deltas and epsilons?)
02:28:52 <xerox> Nope.
02:29:12 <Cale> okay
02:29:38 <Cale> Perhaps it would help to put it in words a little better...
02:29:50 <xerox> I thought f mapped Balls to Balls, but then you told me that it didn't work if you used the end set as the starting one.
02:29:51 <Stinger_> give an example
02:29:55 <goltrpoat> someone should slap me for even saying this, but iirc, descartes' "definition" was that a continuous function R->R was one that you could draw without lifting your pen off the paper.  terrible definition, but try to make that mesh with the epsilon-delta one.
02:30:56 <Cale> A function f: X -> Y is continuous if and only if for every point x in X, and every real number e > 0, there is a real number d > 0 so that whenever a point z in X has distance less than d to x, the point f(z) in Y has distance less than e to f(x).
02:31:25 <Cale> That is, we can play a game
02:31:41 <Cale> Suppose I claim that f is continuous.
02:31:56 <Cale> and you're challenging me
02:32:18 <Cale> I have to have a plan, so that whenever you give me a real number e
02:32:35 <Cale> e > 0
02:32:46 <Cale> Then to win, I have to come up with a real number d > 0
02:33:01 <xerox> (I think I understood a little bit, now, you are generalizing the usual definition of continuous function, where the distance is the absolute value of the difference, to use our distance function?)
02:33:09 <Stinger_> damn internet today >:(
02:33:11 <Cale> oops :)
02:33:18 <Cale> I have to have a plan, so that whenever you give me a real number e > 0, *and* a point x in X.
02:34:25 <Cale> I can give you a real number d > 0 so that no matter which point z in X you choose with distance less than d from x,
02:34:41 <Cale> f(z) will be within e of f(x)
02:35:43 <Cale> To sum that up, it's like there's a guarantee that points which are "close" in the domain are "close" in the image.
02:35:55 <xerox> Right.
02:36:00 <xerox> I understand this.
02:37:18 <xerox> (One could ask the question what is the relation with e and d)
02:38:11 <Cale> (e,x) and d
02:38:17 <Cale> that's sort of important
02:38:29 <Cale> (I messed that up at first)
02:38:32 <xerox> oops, again.  Right!
02:38:38 <Stinger_> don't know there really is one
02:39:13 <Cale> If you move the choice of x past the choice of d, then it becomes something called uniform continuity
02:39:46 <goltrpoat> it's typical, when proving continuity of a particular function, to have to come up with a specific d in terms of e and x that happens to work
02:39:58 <Cale> Stinger_: well, there is one, but it's different for every continuous function
02:40:12 <Stinger_> yeah I think he was talking generally
02:40:41 <Cale> With uniform continuity, for each epsilon, you have to be able to choose delta so that *for all* x, the thing holds
02:40:41 <xerox> Cale, I see what you mean, in some intervals xÂ±e the values of f could change more rapidly than in other intervals.
02:42:56 <Cale> yeah
02:43:11 <xerox> Without uniform continuity you could get some f(x)Â±d which x fall outside of xÂ±e.
02:43:14 <Cale> I was talking generally, but with a specific function, that's what you do
02:43:56 <xerox> Hmm, maybe I got d and e on the wrong axes.
02:44:11 <Cale> Without uniform continuity, you can get functions which oscillate faster and faster, and things like that
02:44:19 <xerox> Well, okay.
02:44:28 <xerox> Writing it formall is painful, shoot me (:
02:44:31 <xerox> *formally
02:44:46 <goltrpoat> it makes a bit more sense on a graph of f(x).  pick an x, pick an epsilon.  draw horizontal bars at f(x)+e and f(x)-e.  the bit of the function enclosed between the bars is what we care about.  now pick a delta, draw vertical bars at x+delta and x-delta.  your job, given some particular epsilon, is to find a delta such that f goes over or under the horizontal bars, within the square created by the two pairs
02:45:02 <Cale> consider cos(x^2)
02:45:21 <xerox> You are saying you are talking more generally than `the graph of some f', what is more general than that?
02:45:35 <goltrpoat> if you can't do that no matter what epsilon i pick, then f is continuous.  if you figure out a way to do it with some particular choice of epsilon, then you win and f is discontinuous.
02:45:47 <goltrpoat> cale is taking it to far nicer pastures.
02:47:26 <goltrpoat> there is no "graph of some f" when f takes six-dimensional goats to polynomials with fruity-valued coefficients.
02:48:36 <Cale> hehe
02:48:41 <goltrpoat> sorry, i keep interrupting.
02:48:44 <Cale> well, there is, but it's a purely formal graph
02:49:31 <Cale> no, it's fine, I'm actually talking to someone else too, and it gives me time :)
02:49:36 <goltrpoat> ah ok
02:49:59 <goltrpoat> well, my point was that at this point we don't care about what any of the geometry of what we're dealing with looks like
02:50:11 <Cale> graph f = {(x,f(x)) : x in domain of f}
02:50:36 <Cale> (that is, it's the actual set of pairs behind the scenes in f, if you use that definition of function)
02:52:49 <mahogny> hm. has there been any CAS libs written with haskell?
02:53:18 <Cale> mahogny: the closest thing I can think of is DoCon
02:53:22 * vincenz is off to crash
02:53:57 <goltrpoat> cale:  yeah, but when do you ever use that :)
02:54:40 <goltrpoat> i mean, you'll say this stuff in the domain of this is doing stuff to this stuff in the range of this.
02:54:42 <mahogny> hrm... this looks like some academic mess
02:54:47 <Cale> I haven't really even looked too closely at DoCon
02:55:25 <Cale> mahogny: what else is a CAS, really? :)
02:55:40 <mahogny> Cale, engineering stuff? :)
02:56:14 <mahogny> I'm quite unhappy with Maxima and other free CAS. wouldn't hurt to give it a try
02:56:56 <Cale> I rather like GAP, but for engineering stuff, it would be useless.
02:57:15 <Cale> It's more for group theoretic and combinatorial stuff.
02:57:39 <mahogny> hm, yes, way too many such CAS' lol
02:59:24 <Cale> I wish GAP was written over Haskell rather than its own rather awkward language.
02:59:26 <goltrpoat> i still wish i could say "this is the typeclass called field.  anything that instances it must provide commutative addition and distributitivity of addition under multiplication and blah blah" and have the typechecker at least make an effort at verifying it, possibly with some (or a lot) of (forced?) help from the programmer
03:00:13 <goltrpoat> multiplication.  over addition.
03:00:23 <mahogny> goltrpoat, well, I don't think that would be terribly hard to add to one of the provers we have now
03:00:58 <goltrpoat> that'd be very cool.
03:01:16 <mahogny> for now, I'm happy just being able to specify it for each function
03:02:00 <goltrpoat> you could say, this is a vector space V over F.  oh oops, F is a ring, this is a module.
03:02:31 <Cale> goltrpoat: with fundeps you already can do something sort of like that
03:02:48 <Cale> (well, not the properties checking)
03:04:02 <goltrpoat> reading.  haven't seen it before, but the second sentence says "used to constraint the parameters of type classes", which is A Good Thing.
03:04:03 <goltrpoat> thanks
03:04:08 <goltrpoat> constraint=constrain
03:05:20 * mahogny figures some summer vacation would be nice
03:05:22 <goltrpoat> ooh.
03:06:04 <goltrpoat> what's the scope of the type variables in the fundep?  the type definition?
03:07:21 <goltrpoat> this is damn cool.  thanks
03:09:57 <xerox> How did you get around those fluffy term you use all the time talking about abstractions? (:
03:10:15 <goltrpoat> ?
03:10:48 <xerox> That's a floaty question, I know...
03:11:40 <goltrpoat> you mean how do you work with things that are patently abstract?
03:11:46 <goltrpoat> or reason about them, etc?
03:14:24 <audreyt> those fluffy terms show things to people, they don't define things, and that's patently fine...
03:19:56 <Cale> It's good and important to have some fuzzy terms around your formal systems, since if it turns out the formal system is broken (inconsistent), they'll be useful in determining how you'd like to fix it.
03:21:00 <audreyt> also, without fluffy terms it's extremely hard to move from levels to levels
03:22:04 <xerox> Haskell can be taught in an IRC channel. Can math be taught there too?
03:22:38 <Cale> of course, that's what #math does :)
03:22:38 <mahogny> uh. there are already math channels? o_O
03:22:51 <Cale> But mathematics is much larger than Haskell.
03:23:14 <goltrpoat> it's much larger than haskell, and it's a lot harder to grok without doing a ton of exercises
03:23:14 <mahogny> there's also a physics channel
03:23:18 <Cale> So it's pretty tough to learn math only using IRC
03:23:20 <goltrpoat> or.. that's my take anyway.
03:23:34 <xerox> Exercises you say.
03:23:40 <mahogny> goltrpoat, nah. you can get away without exercises
03:23:44 <goltrpoat> you can pick up a programming language, do one project, and be reasonably comfortable with it.  with math, uh.
03:24:06 <goltrpoat> mahogny:  that's an odd take on it.
03:24:10 <audreyt> isn't math just the programming language for mathematica? </troll>
03:24:12 <mahogny> goltrpoat, works here
03:24:46 <Cale> audreyt: haha
03:24:48 <xerox> Cale - But it feels like that if on one side #haskell can teach Haskell newbies as we know, #math can't do that in a way comparable to the former
03:24:59 <goron> Can I make () an instance of Real?
03:25:00 <goltrpoat> mahogny:  f(0) = c, f(x+1) = f(x), f is cts.  what can you say about f?
03:25:20 <mahogny> goltrpoat, pretty much constant?
03:25:30 <goltrpoat> show it?
03:25:32 <Cale> xerox: right
03:26:01 <mahogny> goltrpoat, hang on. need to look up definitions :P
03:26:15 <Cale> xerox: Haskell is really quite easy to master compared to the range of topics one picks up in a mathematics degree.
03:26:47 <xerox> Cale, is that because the aims are different? Or there aren't as many people who are willing to help a math newbie as there are for haskell? Or what?
03:27:00 <goltrpoat> it's the scope.
03:27:00 <cpatrick> Cale: true. Although some maths degrees are better than others (at least at my university, it's _really_ watered down stuff until 3rd year and honours)
03:27:15 <Cale> You can become reasonably competent with it in a matter of months.
03:27:19 <cpatrick> xerox: there are a lot of different areas of maths.  You could consider CS as being comparable to perhaps one of them
03:27:27 <xerox> cpatrick - Point.
03:27:29 <mahogny> goltrpoat, well, duh, the function is almost arbitrary. no proof there
03:27:36 <mahogny> goltrpoat, depending on x
03:27:47 <mahogny> goltrpoat, what's the range of x?
03:27:57 <goltrpoat> mahogny:  x is in R.
03:28:07 <cpatrick> mahogny: well, it must be some kind of periodic function
03:28:20 <mahogny> cpatrick, yup
03:28:31 <Cale> and the set of topics relevant to programming in Haskell as a fragment of CS topics
03:28:33 <cpatrick> (which doesn't tell you much because what you were given is roughly the definition of a periodic function)
03:28:36 <mahogny> and that's pretty much what you can say
03:28:43 <dons> maybe we should have Haskell degrees
03:28:46 <Cale> (I'm very lagged, btw)
03:28:47 <xerox> So what is #math really for?
03:28:55 <mahogny> xerox, questions really
03:28:57 <dons> there's a few phds worth of topics to study, at least
03:28:58 <goltrpoat> ok well, that took you four minutes :)
03:29:07 <mahogny> goltrpoat, calculus isn't my thing
03:29:07 <goltrpoat> i say my claim holds.
03:29:08 <Cale> xerox: help with learning math
03:29:27 <Cale> xerox: It's not really used for complete courses
03:29:34 <mahogny> goltrpoat, if you want a game when it comes to sparse matrices and functional analysis, I'm game ;)
03:29:41 <xerox> Mumble.
03:30:21 <xerox> Cale, then were should one do the proper learning?
03:30:21 <goltrpoat> mahogny:  oh, that's much more of a..  either you have an answer right there, or you're going to be digging up books you haven't touched in a year, type thing
03:30:31 <goltrpoat> mahogny:  that's what i do, basically, so i'm right with ya.
03:30:46 <Cale> xerox: though occasionally I can be tricked into giving a mini-lecture :)
03:30:53 <Cale> xerox: a university is good :)
03:30:53 <Cale> xerox: and/or books
03:30:54 <xerox> Right.
03:31:11 <mahogny> goltrpoat, yes. practice might make you faster at solving things but for general mathematical understanding, you can come a far way without them
03:31:16 <xerox> Mumble.
03:31:53 <goltrpoat> mahogny:  i remember spending two months doing one hundred analysis problems a day.
03:32:01 <mahogny> goltrpoat, eew
03:32:05 <goltrpoat> it didn't do me any good in the long run, but i'll get back to it faster these days if i have to.
03:32:06 <goltrpoat> i dunno.
03:32:14 <xerox> It bothers me that you can learn programming languages by using open source mediums on internet, but you can't learn math this way!
03:32:16 <Cale> mahogny: Well, you eventually have to prove things to actually get anything but the shallowest mathematical understanding :)
03:32:23 <Maddas> xerox: Who says you can't?
03:32:31 <mahogny> Cale, true there. but that's why you read proofs :)
03:32:38 <xerox> Maddas - Everybody, as now.
03:32:44 <Maddas> I didn't see anybody say that.
03:32:50 <Maddas> There are plenty of books on the internet.
03:32:52 <Cale> goltrpoat: I remember spending 14 hours on a single problem in first year :)
03:33:01 <Cale> (with a whole group of people, no less :)
03:33:04 <goltrpoat> cale:  oh, plenty of that, too
03:33:07 * mahogny hates analysis
03:33:15 <Cale> mahogny: writing is important too :)
03:33:23 <Maddas> That doesn't change the fact that learning hard things is often a solitary activity, at least in my mind learning math often is :-)
03:33:37 <mahogny> Cale, to some extent, but one can learn to live without it
03:33:39 <goltrpoat> yah, maddas sort of summed it up there.
03:34:25 <mahogny> Cale, of course, it's more challenging without doing excercises. but I usually get good grades on exams anyway :)
03:34:53 <Maddas> I'd certainly never have learned a reasonable amount of maths without any exercises :-)
03:34:54 <mahogny> btw are there many mathematicians in here?
03:35:17 <cpatrick> mahogny: seems to be.
03:35:25 <Cale> mahogny: me, sort of :)
03:35:26 <cpatrick> I'm a maths student, e.g.
03:35:27 <goron> fromInteger is not defined for (), I only want to associate 1 with () by making it an instance of Real. Any idea on how I can solve that?
03:35:47 <Maddas> For me, being at a university is probably the only thing that kept me steadily going through the boring parts, it's way too easy to gloss over boring (but important) parts only to get stuck later on. Especially getting practice :)
03:35:51 <goltrpoat> here's the argument for cramming, in the programming scenario.  let's say bob has been coding for five years.  let's say alice has been coding for twenty.  we put bob and alice in adjacent rooms, hand them a language they have never seen before, and ask them to write a big ass program in it.
03:35:52 * mahogny bets at least 1/5 of us are into math
03:36:24 <goltrpoat> i don't think anyone would disagree that alice will win the vast majority of the time.
03:36:32 <Maddas> Uh, I would...
03:36:38 <goron> Or is putting fromInteger = undefined also ok?
03:36:47 <Maddas> goltrpoat: Has alice been using COBOL for twenty years? ;-)
03:37:01 <mahogny> I consider coding to be much more of a practical craft than most other subject. you obviously have to code a lot to become good at it
03:37:08 <goltrpoat> no, both bob and alice have been working in the same sector of the industry for the past however many years each.
03:37:22 <Maddas> Oh, okay.
03:37:22 <Beelsebob> I have
03:37:25 <Beelsebob> who's alice?
03:37:26 <Beelsebob> :P
03:37:26 <goltrpoat> now, i've been both bob and alice, and i've worked under bobs, and i've worked under alices, and yeah it's a tossup
03:37:44 <goltrpoat> (i'm more of an alice, these days)
03:37:55 * mahogny feels old in the business too
03:37:58 <Maddas> After twenty years of doing it, any bob is an alice, by your definition.
03:38:05 <goltrpoat> but picking an average problem, alice will win, in general.  chances are, she's done it before, and if she hasn't, chances are, she'll hit subproblems she knows about.
03:38:29 <xerox> I am not sure solitary activity is the right thing in general.
03:38:35 <goron> Hmm, that seems to work :)
03:38:38 <mahogny> not only that; alice probably has better coding quality in overall
03:38:46 <Razor-X> How can you generate multiple random numbers?
03:38:49 <Maddas> xerox: I'm sure it's often essential to learning.
03:38:52 <goltrpoat> mahogny:  right.
03:39:12 <xerox> Maddas - I didn't learn Haskell by reading on my own, neither I learnt Scheme that way.
03:39:25 <goron> Razor-X: Are you sure they even exist?
03:39:31 <Maddas> xerox: Other people can't learn it for you.
03:40:03 <Maddas> xerox: But I wasn't precise enough, I meant essential to learning certain things, and I'd say maths is one of them.
03:40:03 <xerox> Maddas - Where's the fun if you don't talk about what you like?
03:40:08 <Razor-X> goron: Pseudo-random numbers, then :).
03:40:11 <Maddas> xerox: Talking is essential to learning.
03:40:17 <goron> Razor-X: StdGen in docs
03:40:25 <Razor-X> goron: Thanks.
03:40:27 <goron> Razor-X: that's the type IIRC.
03:40:41 <Maddas> xerox: All I'm saying is that you also need to study and work on things by yourself too (yes, a quite trivial statement :-)
03:40:59 <Cale> I learned Haskell by lurking around here and doing other people's homework problems secretly
03:41:07 <mahogny> lol
03:41:13 <xerox> I am more interested in the community part. But I agree.
03:41:20 <Maddas> Cale: Right, that's what I mean.
03:41:23 <goron> "I want to learn how to hotwire a motorcycle. " - Trinity ... oh Matrix....
03:41:38 <mahogny> someone code the matrix
03:42:46 <xerox> Random thought: may #math be a too general name for a channel, but it is needed because there aren't enough people to cover individual matters?
03:43:01 <goltrpoat> mahogny:  oh, i remember what you do now
03:43:15 <goltrpoat> we had that conversation about CFD, you and uh.. korollary, i think
03:43:29 <mahogny> xerox, on efnet, we have #math and #physics, and I recently started #statistics. harder to do more fine grained than that
03:43:30 <goltrpoat> that sound about right?
03:43:33 <mahogny> yup :)
03:43:34 <Razor-X> My favorite way to learn a programming language is always to tackle some hopelessly difficult problem (for a beginner).
03:44:03 <Maddas> xerox: I really doubt that I'd even _want_ to learn math (from ground-up) from an IRC channel. The most interesting things for me were finding and working out things on my own, and being able to trace theorems and stuff in books whenever I want to, not just whenever someone talks about it
03:44:18 <goltrpoat> ah ok.  yah, i definitely hear what you're saying about not needing to do a huge amount of work then, it's just sort of experience that comes with doing this or that
03:44:47 <goltrpoat> and then you go, oh, yah, this is banded triangular, i remember that.  oh and also, i do the LU in my head.
03:45:05 <goltrpoat> (because you had to do that while working on some random crap ten years ago)
03:45:14 <mahogny> yeah. sooner or later you end up doing the "excercises" anyway, be it if it is the exam or a real life problem :)
03:45:17 <goron> Any idea for a sensible value of instance Num () fromInteger n (with n!=1)?
03:45:35 <goron> I don't understand why the graph algorithm even uses it....
03:46:17 <mahogny> goltrpoat, hm. we don't use banded trimatrices though. but that's something else ;)
03:46:17 <Cale> hm?
03:46:57 <Cale> goron: isn't there only one possible definition of fromInteger?
03:47:09 <pejo> Maddas, I don't think any irc channels will teach you math from the ground up. Answer a few specific questions - sure, but not too much.
03:47:11 <Cale> (up to leaving it undefined)
03:47:15 <goron> Cale: being?
03:47:16 <Maddas> pejo: I agree.
03:47:21 <goron> Cale: No
03:47:25 <Cale> fromInteger _ = ()
03:47:30 <goron> Cale: For 1 it's ()
03:47:39 <goron> Cale: For n!=1 it's undefined
03:47:48 <goron> Cale: (in my application)
03:47:55 <Cale> You're defining an instance of Num for empty tuples?
03:47:59 <goltrpoat> mahogny:  i had a doubly bordered *symmetric* diagonal matrix recently in a problem.  recognizing that made the difference between O(n) and O(n^3) with a substantial n.
03:48:05 <goron> Cale: I need an instance for real
03:48:12 <goron> Cale: Real
03:48:43 <goltrpoat> banded diagonal matrices tend to pop up in implicit ODE schemes though, no?
03:48:57 <mahogny> goltrpoat, indeed. the worst thing is that the LAPACK/BLAS support for such situations is bad though
03:49:13 <mahogny> yes, BC ODEs
03:49:18 <goltrpoat> yeah
03:49:30 <mahogny> but one shouldn't use matrices in those cases. that just consumes a lot of memory
03:49:32 <Maddas> xerox: I believe that the transient and often informal nature of discussions make them a bad match to learn many things. I'm not saying you can't learn that way, just that I think it's a terrible way to learn certain things :-) I think that discussions are crucial to learning, but complementary to studying things on your own.
03:49:43 <goltrpoat> banded diagonal matrices consume a lot of memory? :)
03:49:48 <mahogny> goltrpoat, yes
03:50:05 <mahogny> goltrpoat, you don't need to store the matrix at all
03:50:18 <xerox> mahogny - Is it really *difficult* to have fine-grained distinction?
03:50:19 <goron> Cale: I think I will just turn my beautiful graph into a implementation imposed graph... (e.g. adding explicit weights):(
03:50:21 <goltrpoat> oh you mean in the BC case specifically?
03:50:27 <Maddas> xerox: Also, there are simply too few good teachers to give everyone private lessons ;-)
03:50:43 <xerox> Maddas - Right, you download the compiler to learn Haskell. But you can understand the value of #haskell
03:50:45 <Maddas> xerox: I think you'll end up with tons of empty channels once the distinctions get too fine-grained.
03:50:52 <mahogny> xerox, well, I guess you can split up #math into number theory and calculus camps, but there's still a lot that doesn't fall into any of those
03:51:03 <goltrpoat> you mean just inverting it implicitely.  sorry, lost track there.
03:51:24 <mahogny> goltrpoat, you write a solver specifically for the problem, and insert the constants there
03:51:29 <Maddas> xerox: Absolutely. I learned an amazing proportion of what I know about programming from IRC channels, but I don't think everything is suitable to be learned this way. I also don't think everyone learns the way I do :]
03:51:50 <xerox> mahogny, Maddas - Does that mean it isn't worth trying?
03:52:00 <xerox> Also, if you have better ideas, I'd love to hear (:
03:52:05 <mahogny> xerox, what would the point in splitting the channel be?
03:52:06 <Maddas> No, I was just pointing out a problem with the idea.
03:52:16 <goltrpoat> mahogny:  yeah but that's fairly standard, you write a half-assed implementation just to get it working, and then optimize
03:52:21 <Maddas> Personally, I'm not interested in too fine-grained channels. I'm in enough channels as is :-)
03:52:25 <xerox> mahogny - Make an #haskell for #whatever.
03:52:48 <goltrpoat> mahogny:  that algorithm i was talking about with the bordered diagonal matrix, my first prototype used an SVD solver just because i had written one two weeks before i came up with the idea
03:52:57 <mahogny> goltrpoat, actually, I find it easier to write the special solver right away than to assemble a matrix :) the codes aren't similar at all so it's not like you optimize afterwards
03:53:08 <Maddas> xerox: Imagine having #haskell-monads, #haskell-gadts, #haskell-parsec, etc. May sound like a good idea at first, but surely the overhead of managing and tracking discussions would overweigh the advantages pretty soon :-)
03:53:10 <goron> Putting the same type everywhere is annoying...
03:53:24 <mahogny> xerox, I don't follow :o
03:53:35 <goltrpoat> mahogny:  depends on the problem, i'm sure.
03:53:39 <mahogny> goltrpoat, yes
03:53:39 <xerox> Maddas - Parsec isn't a subset of Haskell in the proportion Number Theory is to Mathematics, I think.
03:53:43 <Maddas> Also, it's hard to guess channel names for newbies
03:54:04 <xerox> Maddas - You can fix that with a list in the topic of the most general ones.
03:54:05 <Maddas> xerox: Oh, you're right. It certainly was an exaggeration.
03:55:04 <mahogny> xerox, I think a good thing with large channels like that is that you get some exchange between communities
03:55:10 * Maddas doesn't know enough about maths and about the (number of) people talking about maths on IRC to comment on that :]
03:55:21 <Maddas> mahogny: Yeah, it's often a great way to learn about new things.
03:55:39 <goltrpoat> [05:50] <mahogny> xerox, well, I guess you can split up #math into number theory and calculus camps, but there's still a lot that doesn't fall into any of those
03:55:40 <xerox> But first you have to join a community!
03:55:50 <goltrpoat> last i checked, you could split up #math into algebra and NT camps
03:56:00 <goltrpoat> the algebra camp being about 95% of the channel
03:56:01 <goltrpoat> hehe
03:56:04 * Maddas laughs
03:56:12 <xerox> What I am saying is that I don't understand how to do it.
03:56:15 <mahogny> goltrpoat, I'm only in the efnet #math so it might be a bit different here
03:56:24 <goltrpoat> yeah i'm talking about efnet #math
03:56:33 <goltrpoat> i don't think i've ever been to freenode #math
03:57:01 <goltrpoat> all the ops on #math are algebraists.  90% of the regulars are algebraists.  it's nuts.
03:57:18 <mahogny> goltrpoat, there are lots of calculus and fourier stuff that belong in neither channel
03:57:21 <goltrpoat> hell, most of the people who left years ago, were algebraists.
03:57:25 <xerox> #haskell is like what the other #language would ever want to become.  It feels like to me that #math is like one of the latter ones atm.
03:58:27 <xerox> Maybe it is derived from the fact that my understanding of the matter is very little.
03:58:59 <xerox> Thank you for your ideas.
03:59:07 <mahogny> well. I would be glad if we could fork off the bloody number theorists from efnet #math so I won't have to see their discussions. but that's another thing ;)
03:59:14 * Maddas doesn't understand the 'what the other #language would ever want to become' :)
03:59:16 <goltrpoat> no, this is one of the best channels there is.  lots of bright folk with no egos.  sort of rare on irc.
03:59:41 <goltrpoat> mahogny:  the only one i can think of is landen
03:59:53 <mahogny> goltrpoat, *cough*#java*cough*
03:59:57 <xerox> Maddas - More or less what goltrpoat says.
04:00:05 <mahogny> goltrpoat, he seems to be into more than NT
04:00:06 <xerox> Maddas - #scheme is awesome too (:
04:00:06 <johnnowak> goltrpoat: i second that. #c nearly made me want to gouge my eyes out before.
04:00:22 <johnnowak> xerox: i second that as well :)
04:00:47 <Maddas> xerox: Dunno, I know plenty of channels where the members are happy the way it is. Many that I don't like, but I'm not to judge what they want it to become :)
04:00:53 <goltrpoat> mahogny:  landen is a mathematical-physicist-in-the-field-cum-hobbyist-number-theorist
04:01:03 <goltrpoat> or that's what i've gathered anyway
04:01:04 <mahogny> goltrpoat, right :)
04:01:21 <johnnowak> Maddas: you have more patience than me
04:01:27 <xerox> Maddas - I don't know better ways to explain what I mean, sorry.
04:01:33 <Maddas> No worries :)
04:01:35 <mahogny> goltrpoat, apparently he's into one of my subject as well; biophysics :o
04:01:51 <goltrpoat> oh, didn't know that.
04:02:00 <mahogny> his phd was related to it
04:02:02 <Maddas> For example, I know of #language channels that are explicitly /not/ about helping newbies, and that are still interesting to be in. 
04:02:05 <goltrpoat> my father used to be a biochemist, i picked up absolutely zero from that.
04:02:07 <Maddas> (At least in my opinion)
04:02:10 <mahogny> goltrpoat, lol
04:02:29 <xerox> Maddas - This channel falls in both categories, doesn't it?
04:02:41 <goltrpoat> maddas:  #c++ on efnet?
04:02:50 <mahogny> goltrpoat, if one wants to get into that field, then one has to work there me thinks. they have so bloody much to memorize
04:02:51 <Maddas> No, I wasn't thinking of that, goltrpoat, but I don't know it.
04:02:54 <goltrpoat> ah ok.
04:02:55 <Maddas> xerox: Huh? I always thought people here were pretty friendly :-)
04:03:15 <xerox> Maddas - Right. But at times there are over-the-clouds discussions, no?
04:03:17 <goltrpoat> maddas:  care to name some?  just curious, i don't know of too many language-related channels.
04:03:22 <Maddas> xerox: Absolutely
04:03:25 <goltrpoat> #ocaml is dead most of the time, it seems.
04:04:15 <Maddas> goltrpoat: efnet #perl for example. There's a #perlhelp for the newbie helping or more directly code-related questions in general :)
04:04:21 <goltrpoat> mahogny:  yeah, it always struck me as too much effort.
04:04:33 <goltrpoat> maddas:  oh, perl and i don't like each other
04:04:33 <mahogny> goltrpoat, it's a fun subject. try it ^_^
04:04:34 * xerox -> lunch
04:04:42 <Maddas> xerox: I just meant to say that different channels have different focuses. Some channels I hate due to their unfriendlyness might be just what the members there like.
04:04:59 <goltrpoat> mahogny:  i can hold a conversation in it :)  can't really see spending my time on learning more, though.
04:05:01 <Maddas> (I guess I was just irked by the idea of declaring something as an 'ideal' channel, sorry for the ranting ;-))
04:05:14 <goltrpoat> heheh
04:05:21 <xerox> Maddas - Feelings (:
04:05:23 <goltrpoat> hey i didn't say ideal, i said one of the best.
04:05:28 <mahogny> goltrpoat, there's a lot of nice mathematical problems there *hinthint* :)
04:05:35 <Maddas> goltrpoat: Sure, I didn't mean to attack anyone, just the idea itself.
04:06:12 <Maddas> xerox: I guess (:
04:06:18 <goltrpoat> mahogny:  i'll stick to CM and CFD :)
04:06:39 <xerox> Maddas - I mean my own ones too! Well, lunch, ttyl (:
04:07:03 <goron> Why did nobody come up with the bright idea of supplying an _undirected_ graph in the libraries? :(
04:07:32 <goltrpoat> actually i should probably not pigeonhole myself that way.  i'm in a somewhat weird situation, i've been doing computational physics for a long time, in the context of game development.  so i end up going in and out of computational geometry and rendering, and you end up stumbling onto a fair bit of language work here and there
04:07:37 <goltrpoat> so i'm somewhat all over the place.
04:07:55 <goron> I had this cool convention for representing undirected graphs with the directed one from the libraries, but of course that doesn't work when I use the other algorithms from the library....
04:08:08 <goron> Nothing unsolvable, just annoying.
04:08:11 <mahogny> goltrpoat, heck. tell me about it; as soon as you get into any form of "computational" you find yourself working in all fields
04:08:22 <goltrpoat> yep
04:08:38 <Maddas> xerox: Have a nice meal.
04:09:37 <goltrpoat> i don't particularly mind, but when people ask me what it is that i do, i generally cough, mumble something about game development, and ask them a leading question, such as, "dear god, is that gary busey behind you?"
04:10:11 <Maddas> Haha.
04:10:15 <goltrpoat> at which point they proceed to disseminate, amongst their friends and family, the information that i do "website design".
04:10:27 * Maddas laughs. 
04:10:37 <Maddas> goltrpoat: Can you fix my computer? Pleeeeease!
04:10:41 <goltrpoat> hehe
04:10:44 <mahogny> goltrpoat, I tell people what I currently work with. that has caused major confusion. some consider me a biophysicist, some think I am a nuclear physicist, another bunch considers me a game coder etc etc :P
04:11:02 * mahogny hates when a book gives multiple meanings to a variable. there are three variables like that so far :(
04:11:23 <goltrpoat> mahogny:  clear, i need to hang out around people who can spell "nuclear physicist".  i'll be popular.
04:11:36 <mahogny> goltrpoat, lol
04:11:56 <goltrpoat> clearly, rather.  for some reason, i lose the ability to type whenever i join this channel.
04:12:26 <mahogny> goltrpoat, if you are into nuclear reactors, then you can come a far way just by being able to solve boltzmann or the laplace equation :)
04:12:50 <goltrpoat> lemme guess, on a thin rod.
04:13:24 <mahogny> in that case you do it analytically if possible. but even for that simple case you need numerics at times
04:13:31 <mahogny> especially if it is a fast breeder
04:13:43 <goltrpoat> why is it that every fucking book talks about thin rods, thin plates, and if you hit FEM/BEM, *gasp* rods with circumference of 
04:13:44 <goltrpoat> n.
04:14:00 <goltrpoat> (that's a rhetorical question)
04:14:32 <goltrpoat> anyway, i think they did do it analytically for quite some time
04:14:34 <mahogny> goltrpoat, yes. this book does so as well :)
04:15:12 <goltrpoat> oh, tell ya what..  lemme see if i can dig up some titles for you, in case you're interested.
04:15:29 <goltrpoat> my books are somewhat scattered all over the place.
04:15:53 <mahogny> goltrpoat, I think I have read enough about rods by now lol
04:20:14 <goltrpoat> ok i don't think i can get to any of them without waking up my girlfriend
04:20:24 <mahogny> ah
04:20:47 <mahogny> what kind of books did you have in mind? fourier stuff or nuclear theory books?
04:20:57 <goltrpoat> 'classical and computational solid mechanics' by y.c.fung and pin tong is a must-have though.
04:21:03 <mahogny> hmmm
04:21:46 <goltrpoat> it's pricy, and it's a good 1000 pages, but it's like..  what numerical recipes is to the NA community
04:21:47 <mahogny> I think I have something equivalent. I have something like an msc in solid mechanics
04:21:50 <mahogny> wow
04:22:29 <mahogny> if you know good books on mean field theory however, I'm all ears :)
04:23:15 <goltrpoat> is that the multibody thing?
04:23:49 <mahogny> it is a way to consider large spatial ensembles in solid state physics by approximating over local interactions
04:24:03 <goltrpoat> i think i passed it by because my primary focus is rigid dynamics, where it fails spectacularly
04:24:15 <mahogny> the ising model is an example where mean field theory is used to get analytical expressions
04:25:36 <mahogny> hm! maybe you know about how to best handle multiple collision points? that question arise quite often in efnet physics
04:25:54 <mahogny> I like the lagrangian approach but what is the state of the art?
04:26:02 <goltrpoat> oh that's been an ongoing problem for the past 30 years or so
04:26:15 <goltrpoat> with rigid collisions, there is a number of approaches, let me enumerate
04:26:57 <goltrpoat> first, we can set this up as an LP.  we say that relative velocities (accelerations) are greater than zero along the contact planes, and find something that minimizes the energy potential.
04:27:40 <goltrpoat> this approach is due to baraff, dates back to 88 or so, and the two big name realtime packages still use that approach unmodified.
04:28:11 <psi> xerox: did you code Clock.hs?
04:28:15 <mahogny> LP. I guess that's rather efficient
04:28:29 <goltrpoat> the main issue here is that we have to differentiate between resting contact (where normal forces kick in), and colliding contact (where restitution impulses kick in).
04:28:57 <mahogny> hm. right, I can see the problem there
04:28:58 <goltrpoat> it's also rather inefficient, compared to the next couple of approaches -- but a lot more stable, so we have fewer iterations, ideally.
04:29:33 <goltrpoat> the second approach is what's called the impulse approach, or microcollision approach.  we model resting contact as microcollisions, and apply restitution impulses to everything (while solving a tiny closed-form linear system for each body)
04:29:57 <goltrpoat> this can be shown to be physically broken, in certain ways.
04:30:16 <goltrpoat> the third approach, which had been abandoned for a good 20 years until novodex used it recently, is the penalty force approach.
04:30:59 <goltrpoat> you apply forces to keep things from penetrating.  it results in a fucking mess of an ODE system, and i don't know what they're doing in particualr to fix the stiff ODEs.
04:31:16 <psi> xerox: ah, I see that duncan did it. I just wondering if it required a development version of gtk2hs - there a bunch of functions missing when I try to compile it. 
04:31:42 <goltrpoat> the second approach has received the most attention in the recent past.
04:31:50 <psi> dcoutts: does it? :)
04:31:54 <dcoutts> psi, what?
04:31:55 <mahogny> goltrpoat, ah, the third is the lagrangian approach
04:32:22 <mahogny> goltrpoat, lots of theory but yes, you get quite a system to solve
04:32:26 <goltrpoat> well, you can write it as a lagrangian that you want to minimize, but you want to constrain it, right?  i think that was baraff's original thesis, he wrote it as a QP as a result
04:32:33 <psi> dcoutts: I'm trying to compile Clock.hs, but it can't find certain functions, such as: windowSetGeometryHints
04:32:37 <goltrpoat> later work reduced it to a LP, and that gave the first approach i cited.
04:33:01 <mahogny> hmm. ok
04:33:25 <mahogny> which approach do you think is best?
04:33:52 <dcoutts> psi, right, you need the dev version
04:34:03 <psi> ok
04:34:13 <goltrpoat> well, there's a whole host of other issues.  all three approaches i've cited sound easy, and they are on paper, but none of them are numerically stable.
04:34:32 <goltrpoat> you get a ton of floating-point drift problems, and the whole racket is about who's the best at fixing those.
04:34:43 <mahogny> eew
04:35:51 <goltrpoat> my personal preference is towards the LP approach, because it's elegant, and i don't think that any of the people who have tried doing it this way have really tried anything other than simplex or seidel
04:36:05 <psi> @where nymphaea
04:36:05 <lambdabot> http://haskell.galois.com/~paolo/nymphaea
04:36:10 <goltrpoat> i think the approach will benefit from the past 30 years of development in LP theory.
04:36:40 <goltrpoat> if someone told me "you have to write a physics engine by august", i would pick the second approach, by all means.
04:37:01 <mahogny> hm. ok. yes, it sounds rather easy
04:37:10 <mahogny> unphysical, but ok for the task
04:37:18 <mahogny> how would it be with an approach that tries to do things less numerically? ie add the physical model and compute precise times of impact etc
04:37:34 <goltrpoat> it's physically plausible in most situations you'll hit -- i don't think it was shown to be inplausible until the mid 90s.
04:37:44 <mahogny> more complex indeed, but maybe that could get rid of a few numerical problems
04:37:45 <mahogny> oh
04:37:48 <goltrpoat> it's still not an easy thing to write.
04:37:54 <mahogny> right
04:42:04 <goltrpoat> if someone said "what happens in a multibody collision", i'd show them the LP formulation.
04:42:29 <goltrpoat> it's easy to grok, and it really leaves nothing to the imagination
04:42:36 <mahogny> yeah, it's nice to have a compact formula that one can just toss at a standard solver
04:42:40 <goltrpoat> but in practical scenarios, you have to work with a lot more than that.
04:42:58 <goltrpoat> -nod-
04:43:13 <goltrpoat> check out baraff and witkin's course notes.
04:43:17 <mahogny> and then it's quite easy to know how to improve if needed; just write a better solver
04:43:26 <goltrpoat> heheh
04:43:31 <goltrpoat> yeah, therein lies the problem :)
04:44:37 <goltrpoat> it's not that the solver is bad, it's that what it returns is up to this precision, and then your collision detection hits this instead of that, and your next timestep happens to decide that this collision is separating instead of colliding, because the point is behind the triangle's plane, etc.
04:44:48 <goltrpoat> it's fascinating, but it's a goddamn nightmare in places.
04:47:10 <goltrpoat> actually.  i think baraff's notes arrive at the QP formulation, come to think of it.  it's probably illustrative to read that stuff before you read his later papers though.
04:47:57 <mahogny> hm. maybe relaxation can be mixed with the LP stuff. I'll have to look it up. thanks anyway :)
04:48:04 <goltrpoat> hehe
04:49:15 <goltrpoat> right now i'm having to work on a triangle soup coming out of an implicit solver i came up with for a particular problem, and having to a) come up with a method to avoid self-intersections on that, b) come up with a method to dynamically remesh the result
04:50:19 <goltrpoat> this is like..  floating point drift times ten, because you can't assume that a triangle is always in front of something -- this is a boundary-element problem with a thin-shell interface.
04:50:35 <mahogny> isn't it possible to avoid triangles entirelly?
04:50:55 <goltrpoat> no, not analytically.
04:51:05 <goltrpoat> you can't write "avoid this triangle while trying to minimize this function".
04:51:28 <mahogny> well, I mean, can't you try to use different nicer primitives?
04:51:37 <goltrpoat> i guess you can, but that's a dynamic programming problem, and that's where i'm at
04:51:41 <goltrpoat> well
04:51:47 <goltrpoat> triangles are the perfect primitive for the solver
04:51:53 <goltrpoat> you can integrate over them willy nilly
04:52:14 <goltrpoat> int_0^1 int_0^{1-t} crap ds dt
04:52:25 <mahogny> I guess. but triangles usually come in hundreds or thousands :)
04:52:49 <goltrpoat> but we're always working with triangles or tetrahedra in BEM or FEM respectively
04:52:52 <goltrpoat> there's a reason for that.
04:53:13 <mahogny> aha. FEM as well. then I see
04:56:01 <goltrpoat> also, triangles are what you usually get out of a modelling package, right.  so assume your problem is to take a mesh and do something or other with it.
04:56:19 <goltrpoat> we can certainly remesh it, but then the surface integrals get ugly -- and we need them here, say.
04:57:29 <goltrpoat> i think most of these methods call for primitives we can easily reason about
04:57:44 <goltrpoat> i.e. boxes, tetrahedra, triangles, spheres, etc.
04:58:30 <goltrpoat> out of those, triangles are the only thing that makes sense for BEM :)
04:58:57 <mahogny> hm. yes
04:59:14 <mahogny> well, I guess it ain't that bad after all if you want to use the model for other stuff as well
04:59:29 <goltrpoat> oh, well, yah it goes right over to the renderer
04:59:42 <goltrpoat> which likes triangles as well, although probably not quite as much as the solver does
05:00:15 <goltrpoat> incidentally, i came up with a free-boundary 2d CFD algorithm based on this thing.
05:00:22 <goltrpoat> that runs entirely on the gpu :)
05:01:05 <goltrpoat> that's probably my only contribution -- it's the only algorithm i know of that has use in both volumetric and heightfield applications
05:01:45 <mahogny> hm. 2d cfd. what do you use it for? water?
05:04:41 <goltrpoat> it will handle anything that's incompressible and reciprocal
05:04:47 <goltrpoat> so.. linear solids.  water'll work.
05:05:05 <mahogny> what has it been used for so far?
05:05:20 <goltrpoat> there's a hack for compressibility, but i can't show that it's makes sense physically.
05:05:31 <goltrpoat> we have an xbox live title in development that's centered around it.
05:05:37 <mahogny> ooh
05:06:13 <mahogny> hm. I missed that course on compressible CFD but OTOH that usually means turbulence as well and there are only hacks for turbulence :)
05:06:28 <apfelmus> what's difference between types  muX. 1+YxX   and  nuX. 1+YxX  ?
05:07:06 <goltrpoat> i basically say, this mesh is incompressible.  i then do some handwaving and minimize a lagrangian.
05:07:12 <apfelmus> and how is mu (least fixpoint) interpreted anyway? some kind of _|_ on the type level?
05:07:39 <goltrpoat> i get per-vertex velocities.  i feed those into an integrator of my choice.
05:07:39 <mahogny> goltrpoat, whatever looks nice is the rule of thumb anyway 
05:07:47 <goltrpoat> i get an implicit something or other integrator.
05:08:44 <goltrpoat> yeah, it looks very nice on the screen.  it was one of those..  two months on paper, 2 days of code, type deals.
05:09:13 <mahogny> lol. love those
05:10:13 <goltrpoat> of course then i found myself having to do collision response.
05:10:59 <goltrpoat> can you imagine what has to be done in order to make a physical simulation grok the fact that i'm remeshing shit that's topologically ambiguous to begin with, not even counting all the numerical error crap?
05:11:06 <goltrpoat> the solver is *unconditionally stable*
05:11:11 <goltrpoat> the collision detection is eh.
05:11:29 <goltrpoat> stable, if you feed it stuff that doesn't hit it too hard.
05:11:56 <mahogny> bah. just give the Game Over screen if it ever destabilizes. the user probably fucked up anyway :)
05:11:59 <goltrpoat> actually i guess that's my second contribution.  an unconditionally stable cfd solver.
05:12:14 <goltrpoat> stam had one, but it wasn't energy-conserving.
05:12:33 <goltrpoat> mine has an error-correction mechanism that basically guarantees it to be energy conserving.
05:13:11 <goltrpoat> (up to a frame or two, but whatever)
05:13:22 <mahogny> hm. is it that hard to make unconditionally stable cfd solvers for your application?
05:13:36 <goltrpoat> it's very hard.
05:14:07 <goltrpoat> i mean, try to do a navier-stokes solver on a lattice with numerical methods
05:14:34 <mahogny> well. we barely even have equations to solve it so unconditionally stable isn't really the problem yet
05:14:35 <goltrpoat> you'll end up with a 3rd or 4th order integrator just to make it look reasonable if you go with the naive approach
05:15:05 <goltrpoat> eh?  no, we don't have any equations to "solve" it, but we have a vector field, right, we can move crap along it.
05:15:11 <mahogny> yes
05:15:15 <goltrpoat> that's what numerical integration does.
05:16:05 <mahogny> hm. I wonder how easy it would be to implement lbe on a gpu
05:16:42 <goltrpoat> ive seen lattice-boltzman solvers on the gpu, yah
05:17:11 <goltrpoat> sec, lemme see if i can find links
05:17:24 <mahogny> is there any physical model that aren't in use in games yet, except QM? :)
05:17:29 <goltrpoat> oh, gpu gems 2 had one.
05:17:49 <goltrpoat> yes, optics is largely untapped at runtime.
05:17:51 <goltrpoat> hehe
05:17:55 <mahogny> :D
05:18:06 <goltrpoat> i think as far as classical physics goes, we've hit most of the areas
05:18:32 <goltrpoat> i remember working with some guy back in 1996 on pencil tracing sound emitters for multi-tap echo
05:18:43 <mahogny> o_O
05:19:21 <goltrpoat> i also remember doing the hough transform on some random crap that came up, and my father asked me what i was doing, so i explained it, and he said, uh, they used that to trace the paths of elementary particles back at the beginning of the 20th century.
05:19:44 <mahogny> hm. the hough transform is quite expensive :/
05:19:46 <goltrpoat> and i said, great, but unlike that method, this one will get me paid.
05:20:16 <goltrpoat> i thought that was funny though, because hough patented his method in the 60s
05:20:23 <mahogny> ugh
05:20:24 <goltrpoat> oh fuck yeah it's expensive.  it's mostly useless.
05:20:24 <mahogny> :D
05:20:43 <goltrpoat> i mean, if you have more than 2 variables, you're more or less SOL.
05:20:56 <goltrpoat> (ooh, spheres).
05:21:18 <mahogny> well, useful as long as you are willing to wait :)
05:21:22 <goltrpoat> haha
05:21:29 <goltrpoat> and swap a TON of stuff to disk.
05:22:33 <mahogny> dunno if there are many better alternatives. of course, you can do multilevel hough's, that saves a factor 10^6 :P
05:23:34 <goltrpoat> yah, there's the obvious multilevel extension, and then radon transform applies when you can write what you're looking for in a reasonable manner, and then PCA applies, and then ... etc.
05:23:47 <mahogny> yup
05:24:26 <goltrpoat> feature extraction is a pretty mature field now
05:24:40 <goltrpoat> they've been doing a lot with that.
05:24:49 <mahogny> quite. there's still a lot of shit left
05:26:18 <goltrpoat> i had a bid on a contract for a cosmetics company, back in 2001 i think, that basically revolved around the fact that they wanted to take a photo of a person in a particular metrized setting, turn that photo into a set of numbers that parametrized their skin health based on whatever metric (that's where i would've come in), and compared before and after photos based on that
05:26:50 <mahogny> hmmmmm
05:27:09 <mahogny> that industry has grown too big lol
05:27:47 <goltrpoat> now, the way they do this is fairly specific, iirc.  they have this set of parameters that basically revolve around, how many wrinkles around the nose, how many around the eyes, where around the nose, where around the eyes, what's the median direction, what's the mean direction, blah blah, then they take the spreadsheet and i guess they've been doing this for a good century, hand it off to a beancounter.
05:28:25 <mahogny> what a waste of time anyhow :)
05:28:30 <goltrpoat> so the program had to say, this is the nose, and, uh, these are the particular skin features pertinent to the nose, with, what i estimate, is this amount of pores per square inch, whatever.
05:28:47 <goltrpoat> amazing waste of time, yes, but i was sort of desperate for a contract.
05:29:00 <mahogny> as long as they pay up ^_^
05:29:23 <mahogny> how long have been into this?
05:29:27 <goltrpoat> this was five years ago, right.  i estimate i have 20 papers on my hard drive (ive switched computers twice since then) on feature recognition
05:30:06 <goltrpoat> and it goes from.. hough transform.. to radon transform.. to doing crap you can barely follow.. to DEAR GOD WHAT IS THIS.
05:30:14 <mahogny> lol
05:31:17 <goltrpoat> those folks have sort of veered off into their own universe, and they're all referencing papers by each other, and it's goddamn impossible to read any of it
05:31:46 <goltrpoat> and you're sitting there going.. this could not, possibly, be difficult, in any, sense, of the word.
05:31:50 <mahogny> it's no different from other disciplines really. it's always hard to pick up the first set of papers
05:32:29 <goltrpoat> well, i'm used to that though :)
05:32:41 <goltrpoat> this was like.. a country club of proctor and gamble flunkies.
05:32:49 <mahogny> :D
05:33:09 <mahogny> had the same problem when I started out with LBE
05:34:17 <mahogny> I love especially what they do to get a lattice that is invariant over certain transformations... they solve the equation in four dimensions and then project it down :P
05:34:27 <mahogny> some papers assume you know that :P
05:36:51 <goltrpoat> i've done stuff with taking 4d systems to 2d, under a transformation that makes sense
05:37:01 <goltrpoat> in particular, this makes sense for lighting
05:37:29 <goltrpoat> briefly -- you have a function that takes incoming radiance and turns it into outgoing irradiance.
05:38:17 <goltrpoat> you can say f(w) = i.  we can say radiance is a 2d vector (unit sphere), takes it to a 2d vector (unit sphere)
05:38:49 <goltrpoat> so per point, we want to say f(w,i) = stuff.  this is a 4d dataset, they measure it physically with fairly intelligent devices.
05:39:09 <goltrpoat> so given a dataset from a goniometer, you want to put it into something that can run in realtime.
05:39:31 <goltrpoat> obviously, you don't want a 4 gig dataset per material, so eh.  then we get to factorize it.
05:40:06 <goltrpoat> i think i mentioned chebyshev polynomials last time that the conversation "degenerated" into cfd, so that was the idea.
05:40:30 <goltrpoat> you factor things as p*q, and fit a lattice of polynomials over the resulting 2d dataset.
05:40:49 <goltrpoat> i think they do "clever" projections like that in a lot of fields.
05:41:13 <mahogny> hmmm. I think it's a bit different here, but yeah, it probably comes up in other places as well
05:41:32 <goltrpoat> i guess my point was that reducing dimensionality is a common trend in everything, more or less.
05:41:47 <goltrpoat> you get a big ass dataset that's a function of these ten parameters, and you want to reduce it to two.
05:42:11 <mahogny> what they do here is to say that your gas is homogenous in the fourth dimension and hence it can be removed. but you do so by a projection
05:42:11 <goltrpoat> so you do PCA or whatever or you notice a trend and say, these things factor homomorphically as this.
05:43:08 <goltrpoat> yeah but any reduction in dimensionality is a projection, right.  linear in the simplest case, but it makes sense to project things nonlinearly so we can reconstruct them in a reasonable manner.
05:43:41 <mahogny> right. it's just that you don't lose anything in this projection :)
05:44:14 <goltrpoat> oh.  i guess i shouldve asked what the hell the field looks like :)
05:44:30 <mahogny> well, it's only a theoretical tool in this case to be able to manage things
05:45:59 <goltrpoat> i mean it doesn't make sense that in x (+) y = z, we have three-dimensional x and y placed on something or other in four dimensions, and z is on a horizontal plane so we can drop the fourth component
05:46:08 <goltrpoat> why not just drop it to begin with and rewrite (+) to make sense in 3d
05:46:15 <goltrpoat> or am i missing something.
05:47:04 <mahogny> it's apparently messy to do something like that. you want to be able to work with something that has nice properties and those are lost when you squash it down to 3d
05:47:30 <mahogny> mathematicians you know :)
05:47:32 <goltrpoat> like x and y are on something that's not easily parametrizable
05:47:35 <goltrpoat> makes sense i guess.
05:47:43 <goron> You do know #haskell/=#math, right?
05:47:54 <mahogny> it has to do with some invariance
05:48:01 <mahogny> goron, hey. it's numerics. we use haskell ;)
05:48:48 <goltrpoat> goron:  it's not like anyone else is talking :)
05:49:27 * mahogny should go back reading about "the narrow resonance approximation for neutron moderation with absorption and fission" >_<
05:49:47 <goltrpoat> plus, if anyone ever decides to write a computational mechanics library in haskell, this is probably a good start.  or a really bad start, depending on how you look at it.
05:50:12 <goltrpoat> mahogny:  dear god.
05:50:14 <mahogny> I might end up doing something like that. we'll see
05:50:44 <goltrpoat> well, let me know if you do
05:51:08 <goltrpoat> a lot of this stuff is nicer in fp.
05:51:14 <mahogny> LBE first. if I ever manage to make a nice CAS, then I can extend it to computational mechanics as well
05:51:43 <goltrpoat> did you see my question about symbolic integration earlier?
05:51:57 <mahogny> hmmmmm
05:51:59 <mahogny> maybe not
05:52:04 <goltrpoat> actually i guess it wasn't much of a question
05:52:41 <goltrpoat> basically, i said that i had been thinking about what it would take to write a symbolic integration package in haskell.  it seems to be the hardest part of anything involved in that type of a thing, right.
05:53:03 <goltrpoat> so then i said that i remember reading something by wolfram where he said that mathematica doesn't really work on integrals the same way that people do
05:53:13 <mahogny> yes, there seems to be no package like that and I'm also tempted to write one
05:53:59 <goltrpoat> i.e. it doesn't go ok this kind of looks like i might be able to use substitution here.  try this, try that, oh no, i guess let's try integration by parts.  we have five factors, let's try this one as the differential.  nope.  how about this one.  oh that works.  ok let's solve the reduced integral now.
05:53:59 <goltrpoat> etc.
05:54:33 <apfelmus> goltrpoat,mahogny: #haskell is encouraging scientific discussions! yet, in case you don't know, IRC offers /query and /msg for completely undisturbed two-eyes communication.
05:54:35 <mahogny> I have considered some use of CPS
05:54:36 <goltrpoat> i have a somewhat of a vague idea of where i'd start with something like that, but i don't even know where to look for details.
05:54:53 <mahogny> apfelmus, you're encouraged to join ;)
05:55:08 <mahogny> anyhow, we could go PM :P
05:55:20 <goltrpoat> apfelmus:  the CFD discussion was OT, i'll admit, but what the hell is wrong with talking about a haskell CAS package?
05:56:32 <goltrpoat> this *is* #haskell, right?
05:56:56 <mahogny> goltrpoat, my CPS idea: you explore the tree of all substitutions but at the same time try to minimize the complexity. as some paths might not terminate, you would have to search it level by level and that's where CPS butts in
05:57:15 <mahogny> goltrpoat, as for the rest, you just enumerate a lot of functions that can do various transforms
05:57:17 <apfelmus> mahogny: if would, but i have yet to finish the lab courses ...
05:58:09 <goltrpoat> i played around with the idea of using the "dfs all substitutions and minimize complexity" idea a little while ago
05:58:14 <mahogny> goltrpoat, ok, it's a bit more difficult than this; you need to have "goals" in a sense, which I guess would come in form of subtasks
05:58:54 <goltrpoat> the main problem is that equivalent substitution paths don't end up with the same expressions.
05:59:10 <goltrpoat> you have to go, is x*2 equivalent to 2*x.
05:59:32 <apfelmus> goltrpoat: it's as you say and i tried to mean it that way
05:59:39 <goltrpoat> (i figured i'd try the balls-out normalization approach to expression simplification)
06:00:13 <mahogny> goltrpoat, this is only a problem if you don't keep track of your goal as I see it
06:00:31 <goltrpoat> apfelmus:  oh.  sorry if i misinterpreted what you said.  it seemed like you were saying "dear god please take this to msg" :)
06:00:56 <goltrpoat> what's the goal?
06:01:45 <mahogny> goltrpoat, half the problem is making a formal definition of it. the goal of the goal (heh) is to make sure you don't enumerate all possibilities but only the ones that are relevant
06:02:11 <apfelmus> goltrpoat: text is a lot different than voice :-)
06:02:41 <goltrpoat> well, in that case i'd drop the brute force approach, and just sort stuff on the same levels of the ast and merge things that want to, like Mul (Num, Num)
06:03:44 <goltrpoat> i found that going from Add,Sub,Mul,Div to Add,Mul,Neg,Recip, made dumber algorithms producer better results, as well
06:03:54 <davidhouse> grr
06:04:02 <goltrpoat> but i'm sort of stumbling in the dark here.
06:04:06 <davidhouse> i want to code something, but i don't have any idas
06:04:07 <mahogny> I haven't tried implementing one so I can't tell
06:04:09 <davidhouse> *ideas
06:04:36 * davidhouse considers trying to add source code support to haddock
06:04:37 <mahogny> davidhouse, recently someone asked for a compresser of .djvu files that output pdf's with all letters turned into text
06:04:48 <mahogny> davidhouse, then I want a 3d graphing tool :)
06:04:58 <goltrpoat> ok so.  it's 8am, and i should go to bed.
06:05:02 <goltrpoat> adios.
06:05:09 <mahogny> later
06:17:34 <apfelmus> davidhouse: still searching ideas? i suggest making HaXML work on large files (goal: 20MB with hugs)
06:17:50 <davidhouse> i found an old project that needs finishing :)
06:17:55 <mahogny> davidhouse, for many ideas, check the SoC projects that got rejected :)
06:17:58 <mahogny> ah :)
06:26:46 <davidhouse> @pl \f g -> liftIO . f >>= liftIO . g {- something like (>>=) . liftM2 (liftIO .), perhaps? -}
06:26:46 <lambdabot> (. (liftIO .)) . (>>=) . (liftIO .)
06:27:07 <davidhouse> @type \f g -> liftIO . f >>= liftIO . g
06:27:08 <lambdabot> forall (m :: * -> *) a a1 a2. (MonadIO m, MonadIO ((->) a1)) => (a1 -> IO a) -> (m a -> IO a2) -> a1 -> a2
06:27:25 <davidhouse> ah
06:27:30 <davidhouse> @type \x f g -> x >>= liftIO . f >>= liftIO . g
06:27:31 <lambdabot> forall a a1 (m :: * -> *) a2. (MonadIO m) => m a -> (a -> IO a1) -> (a1 -> IO a2) -> m a2
06:27:39 <davidhouse> @pl \x f g -> x >>= liftIO . f >>= liftIO . g
06:27:39 <lambdabot> flip flip (liftIO .) . (((.) . (>>=)) .) . (. (liftIO .)) . (>>=)
06:27:59 <davidhouse> @pl \f g x -> x >>= liftIO . f >>= liftIO . g
06:28:00 <lambdabot> (. (liftIO .)) . flip . ((>>=) .) . (=<<) . (liftIO .)
06:28:05 <davidhouse> bah. never mind.
06:28:09 <mahogny> the pointless thingy looks like something taken from hell. what do you use it for anyway?
06:28:16 <davidhouse> it can be pretty sometimes
06:28:22 <mahogny> ....pretty -_-
06:28:35 <davidhouse> @pl \f g h x -> g x `f` h x
06:28:35 <lambdabot> liftM2
06:29:16 <davidhouse> > liftM2 (++) (map toUpper) (map toLower) "hElLo WoRlD"
06:29:17 <lambdabot>  "HELLO WORLDhello world"
06:41:06 <LordBrain> is there a shortcut, given a tupple like (a,b,c,d) to producing a list like [show a,show b,show c,show d] ?
06:41:31 <mahogny> none that I am aware of
06:41:37 <LordBrain> besides writing it out explicitely with all those shows i mean
06:41:54 <mahogny> you can of course show the entire tuple if that works for you
06:42:13 <dons> f (a,b,c,d) = map show [a,b,c,d] -- 
06:42:15 <dons> ?
06:42:27 <LordBrain> they're not homogenious types
06:42:31 <mahogny> right
06:42:39 <dons> ah, i see what you're doing.
06:42:40 <LordBrain> they're all members of the show class of course
06:42:44 <mahogny> so... no "nice" way. you can of course try template haskell but that sounds overkill ;)
06:42:47 <davidhouse> perhaps an HLIst
06:42:52 <davidhouse> @where HList
06:42:52 <lambdabot> http://homepages.cwi.nl/~ralf/hlist/
06:42:59 <dons> it's a list of [forall a . Show a => a]
06:43:06 <dons> just use existentials :)
06:43:11 <davidhouse> i _think_ that internally uses tuples for hetrogenerous lists
06:43:23 <davidhouse> but i've never actually checked it out
06:43:30 <mahogny> davidhouse, at least the paper I read used something likes tuples yes
06:44:11 <LordBrain> Daveman: i get a 404
06:44:17 <LordBrain> davidhouse:
06:44:23 <LordBrain> sorry too many dav's
06:44:38 <LordBrain> the page is not found...
06:44:39 <davidhouse> @where+ HList http://homepages.cwi.nl/~ralf/HList/
06:44:40 <lambdabot> Done.
06:44:50 <davidhouse> try that one instead
06:44:58 <mahogny> kick the most useless dav? :) hate when nicks are too similar
06:45:00 <davidhouse> Daveman: you've got to change your nick :)
06:45:30 <davidhouse> or, actually
06:45:42 <dmhouse> i'll use my efnet nickl
06:45:43 <dmhouse> *nick
06:46:05 <LordBrain> that one works
06:46:38 <dons> data Showable = forall a. Show a => S a
06:46:38 <dons> f :: (Show a, Show b, Show c, Show d) => (a,b,c,d) -> [Showable]
06:46:39 <dons> f (a,b,c,d) = [S a, S b, S c, S d]
06:46:44 <dons> a solution using existentials
06:46:51 <dons> *Main> let s = f (1,"foo",'x',())
06:46:51 <dons> *Main> :t s
06:46:51 <dons> s :: [Showable]
06:46:51 <dons> *Main> map (\(S x) -> show x) s
06:46:52 <dons> ["1","\"foo\"","'x'","()"]
06:46:59 <LordBrain> is HList distributed with ghc?
06:47:09 <dons> no need for heavy HList stuff.
06:47:16 <dons> of course, another option would be dynamics
06:47:19 <LordBrain> oh
06:47:33 <dmhouse> i hate using existentials like that
06:47:35 <LordBrain> i'm entirely unfamiliar with the concept of an existential
06:47:44 <dmhouse> LordBrain: then learn :)
06:47:49 <dmhouse> @wiki Existential types
06:47:50 <lambdabot> http://www.haskell.org/haskellwiki/Existential types
06:47:53 <LordBrain> thanks
06:48:02 <dons> > let f (a,b,c,d) = [toDyn a, toDyn b, toDyn c, toDyn d] in f ('x',(),"xt",'z')
06:48:03 <lambdabot>  [<<Char>>,<<()>>,<<[Char]>>,<<Char>>]
06:48:19 <LordBrain> (There is currently no text in this page)
06:48:19 <mahogny> dynamic types are just evil :/
06:48:45 <dons> > let f (a,b,c,d) = [toDyn a, toDyn b, toDyn c, toDyn d] in map (show.fromJust.fromDynamic) $ f ('x',(),"xt",'z')
06:48:46 <lambdabot>  Add a type signature
06:48:49 <dmhouse> LordBrain: did you paste the whole thing?
06:48:58 <LordBrain> oh with the space?
06:49:03 <dmhouse> yeah.
06:49:24 <dmhouse> sorry, i figured @wiki would automatically spaces underscoreds
06:49:28 <dmhouse> *underscores
06:49:29 <dons> dmhouse: what's wrong with using existentials for hlists? that's a great use, imo
06:49:38 <dons> lists of things that share the same api.
06:49:55 <dmhouse> dons, no, nothing, it's just that every solution to the homonogeneity of lists seems like a hack
06:50:05 <dmhouse> and never seems to work everywhere i try it.
06:50:20 <dmhouse> the laws governing, say, pattern bindings on existentials are just beyond me
06:50:21 <dons> hmm. existentials don't seem very hacky to me.
06:50:37 <dons> at least, for heterogeneous lists
06:50:44 <dons> makes perfect sense
06:50:49 <goron> Is there also a concatMapM?
06:50:56 <dons> ?type concatMap
06:50:57 <lambdabot> forall b a. (a -> [b]) -> [a] -> [b]
06:51:03 <dons> ?type liftM2 concatMap
06:51:04 <lambdabot> forall a b (m :: * -> *). (Monad m) => m (a -> [b]) -> m [a] -> m [b]
06:51:11 <dons> not quite.
06:51:23 <dmhouse> @type (sequence .) . concatMap
06:51:23 <lambdabot> forall (m :: * -> *) a a1. (Monad m) => (a1 -> [m a]) -> [a1] -> m [a]
06:51:36 <dons> ?djinn (a -> b) -> [a] -> m [b]
06:51:37 <lambdabot> -- f cannot be realized.
06:52:02 <dons> ?djinn (a -> m b) -> [a] -> m [b]
06:52:02 <lambdabot> -- f cannot be realized.
06:52:04 <dons> bah
06:52:32 <dmhouse> dons, well, you're defining a type whose sole purpose is to ignore the type of its argument. i don't know, perhaps i'm just not very used to it
06:53:08 <dons> a type that represents some value, with a specific set of operations on it
06:53:12 <dmhouse> it's analoguous to monads. you can use do-blocks to write (bad) imperative code, but if you're doing that, why not just use an imperative language? similarly with dynamic/static types
06:53:55 <dons> the nice property is that the particular type you wrap is hidden, on the api is exposed. that's a nice property
06:54:02 <dons> s/on/only/
06:54:15 <dmhouse> hmm
06:54:20 <mahogny> hm. can it be retrieved again?
06:54:24 <dons> and its all statically typed.
06:54:50 <dons> much better than leaving it till runtime to find out you can't apply 'show' to some value in your list
06:55:06 <mahogny> hm
06:55:08 <dons> mahogny: yeah, see above.
06:55:09 * mahogny likes this
06:55:21 <dmhouse> i suppose one of my uncomforts about it is that you have to define your own existentials
06:55:36 <dmhouse> it'd be nice if every typeclass also defined a hiding existential
06:55:42 <dmhouse> with some standard was of combining them
06:55:56 <dons> yeah, perhaps there could be some sugar, but its not too bad
06:55:57 <kosmikus> defined a hiding existential?
06:56:00 <dmhouse> (so things like [forall s. (Show s, HTML s) => s]
06:56:19 <dmhouse> kosmikus: yeah, as in data ShowHider = forall s. Show s => S s
06:56:42 <dmhouse> mmm... perhaps we just need sugar, then.
06:57:02 <dmhouse> and more comprehensible pattern matching :)
06:57:12 <kosmikus> in my experience, these things are usually not really required. but anyway, with impredicativity, you will be able to write that directly.
06:58:01 <LordBrain> is capital S just a synonym for String?
06:58:15 <dmhouse> no
06:58:24 <dmhouse> it's dons existential
06:58:39 <dmhouse> data Showable = forall a. Show a => S a
06:59:02 <kosmikus> LordBrain: it's a data constructor
06:59:03 <LordBrain> ok
06:59:29 <dmhouse> is there a standard parsec combinator for something in brackets?
06:59:44 <dons> yeah, these are rarely used. I have one program that uses them once. :)
07:00:15 <dmhouse> bracketed = between (char '(') (char ')') (many $ noneOf "()")
07:00:21 <dmhouse> something like that
07:00:38 <dmhouse> err
07:00:38 * dons `fmap` sleep
07:00:48 <dmhouse> many $ noneOf ")"
07:00:49 <kosmikus> well, forget what I said, it will not be possible to write this directly with impredicativity, because [forall a. (Show a) => a] and [Showable] are quite different things
07:01:01 <dmhouse> kosmikus: they are?
07:01:28 <dmhouse> oh, yeah, they are
07:01:29 <dmhouse> constructors.
07:01:34 <kosmikus> sure, [Showable] is like [exists a. (Show a) => a]
07:01:42 <dmhouse> err, no it's not.
07:01:57 <dmhouse> that would make it homogenous
07:02:16 <kosmikus> huh?
07:02:35 <kosmikus> good night dons
07:03:12 <dmhouse> hmm
07:03:22 <dmhouse> it depends at what level you take the type to mean
07:03:42 <dmhouse> i suppose you're right, really
07:04:10 <LordBrain> hmmmm ghc seems not to be liking the forall
07:04:15 <dmhouse> [forall a. Show a => a] would be _very_ weird :) it'd have to be [undefined, undefined, undefined ...] :)
07:04:19 <dmhouse> LordBrain: -fglasgow-exts
07:04:31 <LordBrain> ok
07:04:58 <kosmikus> LordBrain: you'll have to use a recent ghc-6.5 version for something like [forall a. Show a => a] ...
07:06:07 <kosmikus> dmhouse: yes, that type is not very useful
07:06:33 <dmhouse> in fact, it could only appear in dynamically-typed languages
07:06:44 <dmhouse> where things can have multiple types at once
07:06:56 <LordBrain> heh.. my program hung
07:07:05 <LordBrain> oh
07:07:28 <dmhouse> [forall a. Show a => a] means that no matter which type (call it a) you pick, if it instantiates Show, then your list is of type [a]
07:07:35 <LordBrain> i'm only on ghc 6.2.2
07:07:52 <int-e> dmhouse: no, that's Show a => [a]
07:08:15 <int-e> dmhouse: [forall a.Show a => a] means the list can contain anything that has a show instance.
07:08:47 <goron> I have a value of m [a] how do I filter some elements from [a]?
07:09:17 <LordBrain> can goron do liftM filter ?
07:09:19 <dmhouse> int-e, oh, hmm
07:09:34 <dmhouse> then kosmikus is wrong?
07:09:36 <xerox> goron, Just do { xs <- monadicList; return filter ... xs }
07:09:39 <dmhouse> LordBrain: yes, or just filterM
07:09:45 <dmhouse> @type filterM
07:09:46 <lambdabot> forall a (m :: * -> *). (Monad m) => (a -> m Bool) -> [a] -> m [a]
07:09:50 <dmhouse> err, not filterM.
07:09:57 <dmhouse> hey xerox
07:10:01 <goron> filterM does not work indeed,
07:10:04 <goron> thanks
07:10:12 <xerox> Howdy dm.
07:10:29 * dmhouse changed his nick to stop it clashing with Daveman
07:13:10 <kosmikus> dmhouse: I'm not wrong, int-e is :)
07:15:24 <goron>  Couldn't match kind `(* -> *) -> * -> *' against `?? -> ? -> *'
07:15:24 <goron>     When matching the kinds of `t :: (* -> *) -> * -> *' and `(->) :: ?? -> ? -> *'
07:15:30 <goron> Oh, that's easy :P
07:15:33 <int-e> hmm. maybe we both are. [forall a.Show a => a] is just wrong. 
07:15:38 <xerox> @ghc
07:15:39 <lambdabot>  All the type patterns for a generic type constructor must be identical
07:15:53 <kosmikus> int-e: define "wrong"
07:16:13 <int-e> kosmikus: == a syntax error.
07:16:48 <kosmikus> int-e: that doesn't mean it's not possible to attach a sensible meaning to it. also, ghc-6.5 supports it.
07:18:03 <int-e> kosmikus: hmm. that's right, thanks. but why?
07:18:57 <kosmikus> because while [forall a. Show a => a] is rather useless, there are useful examples of lists containing polymorphic values
07:19:11 <int-e> kosmikus: it certainly doesn't do what it suggests to me. But yes, I was wrong.
07:19:53 <LordBrain> hmm its not completely useless.. i thought it was handy for doing map show over a heterogenous list
07:19:56 <kosmikus> you can, as a still rather useless example, define [fst, snd] :: [forall a. (a,a) -> a]
07:20:54 * johnnowak hates irc ads
07:21:06 <LordBrain> i think i need a existential type specific tutorial
07:21:11 <int-e> but how is that different from forall a.[(a,a) -> a]? (is there a discussion about this on a mailing list somewhere that I could read?)
07:21:14 <LordBrain> its not clicking yet..
07:21:29 <reppie> i used to work at burger king, a king taking orders
07:22:03 <kosmikus> it's not that different from (forall a. [(a,a) -> a]) in the case of lists. I think the two are isomorphic for lists, but not for general type constructors.
07:22:14 <LordBrain> oh
07:22:25 <LordBrain> so for lists.. if the later notation is more standard ..?
07:23:17 <goron> Should this happen? Urk! Inventing strangely-kinded void TyCon:
07:23:18 <goron>     ZCt{tc adIa}
07:23:18 <goron>     (* -> *) -> * -> *
07:23:35 <int-e> kosmikus: Hmm, although I imagine it's still useful for lists for dealing with type synonyms. I'll have to think about it some more.
07:24:04 <kosmikus> LordBrain: hard to say what's more standard. the latter notation is allowed in ghc-6.4.X already ...
07:24:36 <LordBrain> would i be wrong to say ghc is like a defacto standard?
07:24:50 <mahogny> not really
07:24:52 <kosmikus> for Haskell?
07:25:03 <mahogny> but hugs is common. way too common
07:25:24 <LordBrain> yes for haskell.. of course... 
07:25:31 <Saulzar> Hmm, I think yes
07:25:35 <kosmikus> That's a philosophical question. Not all things in ghc are cleary defined, though.
07:25:45 <LordBrain> yeah hmmm
07:25:56 <kosmikus> s/cleary/clearly/
07:26:12 <kosmikus> that's why there's the Haskell' effort ...
07:26:32 <Saulzar> There is a common subset of extensions between ghc/hugs which is most used probably
07:26:40 <goron> kosmikus: I am sure it's precisely defined. I don't know whether that is "clear". 
07:28:09 <kosmikus> goron: no, I'm not sure it's precisely defined. you can of course argue that the implementation clearly defines a language, but I'm convinced that even the GHC developers agree that there are quite a few corner cases where the current implementation does not reflect their "intuition" of how it should behave, and where there isn't any clear spec of how it should behave at all ...
07:28:34 <kosmikus> say, interaction of GADTs with functional dependencies ...
07:28:50 <LordBrain> yeah
07:28:54 <goron> kosmikus: We agree, I was referring to the implementation. 
07:28:54 <LordBrain> that makes sense
07:30:14 <LordBrain> so if you were to rely on that corner case behavior.. your program will be more likely to become broken in later versions of ghc 
07:31:20 <goron> Isn't that exciting? ;)
07:32:38 <LordBrain> my window manager has a bug...
07:32:59 <LordBrain> every once in a while when i close a window, the whole thing shuts down
07:33:32 <kosmikus> what window manager?
07:33:42 <LordBrain> well its like a fresh checkout of fluxbox
07:33:54 <LordBrain> perhaps a little bit of a stale one actually
07:37:51 <LordBrain> lets see if i can reproduce it...
07:38:02 <LordBrain> nope
07:38:47 <LordBrain> its happened to me many times tho
07:39:49 <kosmikus> strange
07:40:46 <LordBrain> it appears to actually close the windows politely.. because otherwise there would be a stale ghost here on freenode when i reconnected
07:55:59 <dmhouse> xerox, pign
07:56:13 <xerox> Pong.
07:56:20 <dmhouse> trying out nymphathingy
07:56:29 <dmhouse> is the syntax documented anywhere?
07:56:38 <xerox> Err, I don't think so.
07:56:58 <dmhouse> hm
08:00:28 <dmhouse> i can pretty much guess at what everything means
08:01:22 <xerox> F does a straight line, + and - rotate, G hops without drawing the line, [ branches, ] closes the branch
08:01:22 <dmhouse> 90-degree rotation?
08:01:22 <xerox> You can specify the degrees
08:01:22 <xerox> At runtime IIRC
08:01:22 <dmhouse> oh, that's what angle is for. okay, thanks.
08:01:22 <xerox> :D
08:01:22 <xerox> Then you can click on the rendering window...
08:01:22 <xerox> ...and if you hold the mouse, and move it around the point you have first clicked on, you select the angle of the rendering
08:01:22 <xerox> (The point and the angle)
08:01:22 <xerox> With a slick animation Cale did (:
08:01:45 <LordBrain> what program is this?
08:03:15 <xerox> @where nymphaea
08:03:15 <lambdabot> http://haskell.galois.com/~paolo/nymphaea
08:03:15 <dmhouse> hehe, nice
08:03:15 <xerox> Yeah!
08:03:15 <dmhouse> xerox, got any examples other than the one that loads with the program?
08:03:15 <xerox> dmhouse - Maybe there is a directory containing them. If you are lucky.
08:03:15 <dmhouse> ooh, yeah there is
08:03:19 * xerox bounces
08:03:19 <xerox> I never got around finishing the GUI properly.
08:03:19 <xerox> It misses load/save of L-systems and image saving.
08:03:19 <xerox> (Patches are welcome! :)
08:03:19 <dmhouse> the fractions handle non-determinism?
08:03:19 <xerox> Yep.
08:03:33 <dmhouse> and represent probabilities, i guess
08:03:33 <xerox> They are the probabilities.
08:03:58 <dmhouse> xerox: can you open those .l files?
08:03:58 <xerox> http://haskell.galois.com/~paolo/darcs/nymphaea/lsystems/branchyTree.l
08:04:07 <xerox> Id you do mean via the GUI, nope. Load/Save is missing.
08:04:27 <dmhouse> how else can you do it, other than the GUI?
08:04:52 <xerox> Via the text editor :)
08:05:15 <dmhouse> huh?
08:05:22 <robajs> hello
08:05:58 <dmhouse> can they be rendered apart from through the GUI, is what i mean
08:06:32 <ADEpt> there is a single haskell-mode for emacs out there, isn't it?
08:06:43 <dmhouse> ADEpt: yep
08:07:00 <ADEpt> dmhouse: which is currently slightly broken, right?
08:07:04 <dmhouse> err
08:07:08 <dmhouse> not that i know of?
08:07:23 <Stinger_> damn paren highlighting is slow in it :P
08:07:39 <xerox> dmhouse - nope, but that is a good idea I think.
08:08:04 <dmhouse> xerox, so there's no way to render those .l files?
08:08:17 <xerox> No direct means as now.
08:08:47 <dmhouse> okay.
08:10:52 <goron> I have a [State FooState [Foo]], I would like to define msum on this, to get State FooState [Foo], but I need a little help. Do I first have to run all those states and then extract the result the [Foo]'s, and then combine them with e.g. concat and then build a new State by using a constructor explicitly?
08:10:55 <int-e> kosmikus: re: [forall a.Show a => a] ... the boxy typing paper is about this, right?
08:18:38 <goron> Nm
08:26:41 <ADEpt> dmhouse: i'm consistently getting "Invalid sytax designator ?\t" when trying to align code. Does not happen always, though
08:27:07 <dmhouse> ADEpt: you're probably not using it right. you know about the tab cycle, yeah?
08:27:30 <ADEpt> dmhouse: yes
08:27:55 <ADEpt> dmhouse: try writing this: 
08:27:55 <ADEpt> "main =
08:27:55 <ADEpt>    do
08:27:55 <ADEpt>       let x =y"
08:28:04 <ADEpt> and press tab on "let x =y" line
08:28:34 <kpreid_> is it possible to write a function like (Data.Maybe.fromJust . Data.Dynamic.fromDynamic) except that the error includes the type for which it would have succeeded?
08:29:34 <dmhouse> ADEpt: main = do let x = y :) all on one line
08:29:39 <dmhouse> that's how i'd do it
08:30:18 <Cale> putting do on a line of its own is a bit ugly
08:30:47 <Cale> I'd either do what dmhouse said, or at least include the do in the let x = y line.
08:31:22 <dmhouse> yeah, if the lines get too long, then do main = \n do let x = y, or main = do \n let x = y
08:31:43 <ADEpt> dmhouse: the point is not about code style, it is about haskell-mode refusing to layout it with errors.
08:32:25 <dmhouse> haskell-mode refuses to lay it out with errors?!
08:32:28 <dmhouse> that's good, right?
08:32:36 <Stinger_> ADEpt press tab a few times
08:33:21 <dmhouse> Stinger_: nah, this is one of those "Sole indentation" times
08:33:28 <dmhouse> but anyway, i <3 haskell-mode
08:33:34 <dmhouse> haskell-mode is the reason i switched to emacs
08:33:48 <dmhouse> gah, i hate ##php.
08:33:50 <ADEpt> dmhouse: ok. Shorter example:
08:33:50 <ADEpt> "main = do 
08:33:50 <ADEpt> let abc = foo"
08:34:15 <dmhouse> ADEpt: what's your point there?
08:34:32 <ADEpt> dmhouse: the second line wouldn't move. Signal "Invalid sytax designator ?\t" will be raised when you try to indent it
08:34:37 <dmhouse> not for me
08:34:42 <dmhouse> you have a broken emacs, methinks.
08:34:55 <ADEpt> dmhouse: what's yours?
08:35:02 <dmhouse> my emacs?
08:35:14 <ADEpt> yep. brand and version?
08:35:37 <goron> instance  MonadPlus (State a)  where
08:35:38 <goron>     s `mplus` t = ...
08:35:40 <dmhouse> "normal" brand (no XEmacs, thankyou), GTK engine with XFT support.
08:35:46 <dmhouse> but i've never come across that
08:35:53 <goron> I need a hint of what to place on the ...
08:36:30 <dmhouse> and i've ran 1) emacs with X support, CVS version, 2) emacs in the terminal, CVS version, 3) emacs with X version, 21, 4) this current one
08:36:33 <dmhouse> which is CVS, by the way
08:36:45 <dmhouse> goron, that depends
08:36:57 <goron> dmhouse: I know what I want to do. 
08:37:06 <dmhouse> goron: no-one else does. :)
08:37:24 <goron> dmhouse: extract answer components, concat them, build a new State out of it.
08:37:32 <dmhouse> ah
08:37:55 <dmhouse> what if the results are () and ()?
08:38:00 <dmhouse> you can't concat ().
08:38:02 <dmhouse> or numbers?
08:38:13 <goron> dmhouse: The result should be a list. 
08:38:33 <goron> dmhouse: I wanted to define an instance MonadPlus (State a [Foo])
08:38:38 <goron> dmhouse: But that didn't comile
08:38:42 <goron> dmhouse: er compile
08:38:49 <dmhouse> no, you can't do that.
08:39:08 <dmhouse> because a MonadPlus _has_ to take a type parameter which is its return value
08:39:14 <dmhouse> (otherwise it wouldn't be a monad)
08:39:24 <dmhouse> you'd be better of instantiating Monoid.
08:39:40 <goron> How would that go?
08:40:29 <goron> dmhouse: E.g. mappend?
08:40:35 <dmhouse> instance Monad (State a [b]) where mempty = return []; x `mappend` y = ...
08:41:08 <ADEpt> dmhouse: aha. found the culprit : (skip-syntax-backward " \t"). '\t' is not a valid syntax code in my emacs
08:41:19 <goron> And how do I extract the answer components from x and y?
08:41:24 <dmhouse> runState
08:42:16 <goron> dmhouse: Ok, so extract current state from x, then runState using that state?
08:42:36 <dmhouse> goron, try something like this:
08:42:38 <goron> dmhouse: Don't you mean instance Monoid?
08:42:44 <dmhouse> err, yeah
08:43:23 <dmhouse> x `mappend` y = State (\s -> let (s', v) = runState x; (s'', v') = runState y in (s'', v ++ v'))
08:43:52 <dmhouse> make sense?
08:44:07 <dmhouse> oh, oops
08:44:17 <dmhouse> x `mappend` y = State (\s -> let (s', v) = runState x s; (s'', v') = runState y s' in (s'', v ++ v'))
08:45:11 <dmhouse> or, more generically:
08:45:19 <dmhouse> x `mappend` y = State (\s -> let (s', v) = runState x s; (s'', v') = runState y s' in (s'', v `mappend` v'))
08:45:29 <goron> dmhouse: I don't really see why this would work, because x and y are of type State Foo [Foo]
08:45:31 <dmhouse> then the result need only be a Monoid, not necessarily a list
08:45:52 <dmhouse> @type runState
08:45:53 <lambdabot> forall s a. State s a -> s -> (a, s)
08:45:57 <dmhouse> og
08:45:58 <dmhouse> *oh
08:46:02 <dmhouse> i got it backwards then
08:46:18 <dmhouse> x `mappend` y = State (\s -> let (v, s') = runState x s; (v', s'') = runState y s' in (s'', v ++ v'))
08:47:38 <dmhouse> this is going to be difficult to understand if you don't fully grok the State monad
08:48:17 <goron> Illegal instance declaration for `Monoid (State a [b])
08:48:32 <dmhouse> hmm
08:48:45 <goron> Apparently, the compiler also thinks it's too difficult.
08:48:52 <dmhouse> oh
08:48:56 <dmhouse> hmm
08:48:59 <dmhouse> no, that should work
08:49:09 <dmhouse> right? /me appeals to the channel
08:49:29 <goron> dmhouse: I think you need overlapping instances for that....
08:50:02 <goron> dmhouse: It's not Haskell 98, in any case.
08:51:45 <dmhouse> goron, it works for me
08:51:53 <dmhouse> i got it still wrong in the last version, though
08:52:05 <dmhouse> x `mappend` y = State (\s -> let (v, s') = runState x s; (v', s'') = runState y s' in (v ++ v', s''))
08:52:08 <dmhouse> that works fine for me
08:52:17 <goron> dmhouse: What instance declaration?
08:52:24 <dmhouse> hold on
08:52:57 <goron> I am pretty sure this is not in Haskell 98: instance  Monoid (State a [b]) where
08:53:58 <dmhouse> just pastebinning.
08:54:35 <lisppaste2> davidhouse pasted "monoidal instance for State" at http://paste.lisp.org/display/20840
08:57:38 <goron> dmhouse: thank you for your time, what mempty is called in the definition of mempty?
08:57:56 <dmhouse> i'll reformulate it just using lists if you'd prefer
08:58:03 <dmhouse> then you can compare the two
08:58:39 <lisppaste2> davidhouse annotated #20840 with "just using lists" at http://paste.lisp.org/display/20840#1
09:05:00 <dmhouse> anyone read the "Arrows, like Monad, are Monoids" paper?
09:05:18 <dmhouse> they use a notation like C^{op}, where C is a category
09:05:24 <dmhouse> anyone know what that might mean?
09:08:30 <goron> dmhouse: What's monoidal (:) ?
09:08:47 <dmhouse> goron, sorry?
09:08:49 <dmhouse> oh
09:08:53 <dmhouse> hmm
09:08:55 <dmhouse> there isn
09:08:59 <dmhouse> *there isn't one, really
09:09:06 <goron> dmhouse: Oh, I need that. 
09:09:15 <dmhouse> because in general a monoid isn't necessarily a conatiner
09:09:20 <dmhouse> *container
09:09:27 <dmhouse> e.g. the reals under multiplication form a monoid
09:09:41 <dmhouse> goron, where?
09:10:11 <goron> dmhouse: Well, in your annotated implementation I need : in place of ++
09:10:25 <goron> dmhouse: I didn't specify the problem correctly.
09:10:27 <dmhouse> ah.
09:10:38 <dmhouse> one of them returns a list, and the other returns an element?
09:10:49 <goron> dmhouse: both lists
09:10:55 <dmhouse> then you can't (:) them
09:11:03 <goron> No, I know...
09:11:52 <goron> This is what I need: a function::[State Foo [Foo]]->State HState [[Foo]]
09:12:07 <goron> er :[State Foo [Foo]]->State Foo [[Foo]
09:12:14 <dmhouse> ah
09:12:44 <dmhouse> right
09:12:45 <goron> another er [State Foo [Foo]]->State Foo [[Foo]]
09:13:27 <dmhouse> let me have a whack at writing that
09:14:25 <goron> msum had the right type, so that's why I wanted an instance for msum
09:14:44 <dmhouse> do you want a result type of [[Foo]], or [Foo]?
09:15:10 <goron> Oh, no msum does not have the right type
09:15:15 <goron> dmhouse: the former
09:15:32 <dmhouse> okay, so you're not (++)ing the lists.
09:15:43 <goron> dmhouse: no, that should not happen.
09:15:48 <dmhouse> sure
09:16:06 <dmhouse> @type runState
09:16:07 <lambdabot> forall s a. State s a -> s -> (a, s)
09:16:34 <goron> Looks like a fold
09:16:45 <goron> (what I need)
09:17:21 <dmhouse> almost
09:17:23 <dmhouse> a scan, i think
09:18:45 <dmhouse> hmm, no, maybe it is a fold
09:20:47 <dmhouse> goron, i think i've got it
09:20:50 <dmhouse> i'll just test it
09:25:23 <lisppaste2> davidhouse pasted "sequenceStates" at http://paste.lisp.org/display/20843
09:25:47 <dmhouse> got it. :)
09:31:25 <dmhouse> anyone know how to get hold of the paste.lisp.org guy?
09:31:32 <dmhouse> paste.lisp.org/email seems to be broken
09:31:51 <int-e> hmm, ask on #lisppaste?
09:32:22 <dmhouse> huh, that channel is just me, the bot, and some guy called 'chandler'
09:34:55 <int-e> it sends a Location: mailto:lisppaste-requests@common-lisp.net
09:35:20 <dmhouse> ah
09:35:24 <dmhouse> thanks, int-e
09:36:20 * int-e isn't sure if that redirect should actually work or not ...
09:39:22 <Maddas> (dmhouse: Chandler is it)
09:58:58 <apfelmus> dows anybody know the difference between  muX.1+YxX  and  nuX.1+YxX  i.e. the fixed point operators on type level?
10:02:56 <sachu> hi. I installed the shooting game 'Frag' written in Haskell, but it's way too slow. What might be the reason? I have 512MB of RAM, and a lot of that is free when the game runs. I couldn't find a mailing list or some such forum at http://www.haskell.org/haskellwiki/Frag, hence asking for help here.
10:03:53 <int-e> apfelmus: muX.1+YxX are finite lists;  nuX.1+YxX includes sequences, i.e. infinite lists.
10:04:21 <apfelmus> sachu: perhpas optimisation on when compiling with ghc helps?
10:05:13 <apfelmus> int-e: ok, how does the general construction go?
10:05:32 <sachu> I compiled with -O2 as specified in the readme.txt
10:06:39 <apfelmus> sachu: you have hardware 3d acceleration?
10:06:46 <sachu> Is there something like -O3, -O4 etc that I can try?
10:07:14 <sachu> apfelmus: I'm not sure. How do I find out? I am running Fedora Core 4 
10:08:33 <JKnecht> sachu: go to system menu, select display, hardware tab
10:08:58 <JKnecht> video card section will tell what kind of adapter you have.
10:10:13 <int-e> apfelmus: hmm, I'm trying to remember that, I only remember a category theoretic version. You can consider the category of functions y: Y -> 1+YxT; morphisms are functions f: Y->X, such that y o f = (1+f x id_T) o g; then call the initial object muX.1+YxX and the final object nuX.1+YxX.
10:10:13 <sachu> OK. I guess I'll try to find the equivalent for Linux. Thanks for the help
10:10:58 <psi> sachu: you could try running glxgears. if your fps is > 1000 you probably have hardware acceleration.
10:11:03 <stepcut> sachu: run 'glxinfo | grep direct' and see if direct rendering is enabled
10:12:00 <int-e> apfelmus: I think I've seen a constructive version of that that basically builds trees; this is similar to how ADTs are implemented in Haskell. (Note that ADTs in Haskell correspond to nu; the mu version would restrict the corresponding trees to finite ones)
10:12:43 <sachu> psi, stepcut: fps is ~ 300, and direct rendering is not enabled. Is it possible to enable this?
10:12:55 <stepcut> sachu: what video card ?
10:14:21 <JKnecht> glxinfo -v worked for me
10:14:36 <sachu> stepcut: I have an NVIDIA nForce2 chipset
10:15:33 <stepcut> sachu: you will need to install the drivers from nvidia's site then -- not sure how to do it under fedora, but there is certainly a webpage that will tell you home
10:15:36 <stepcut> s/home/how/
10:16:04 <sachu> stepcut: thanks for the help, i will try that.
10:17:03 * apfelmus thinks &
10:17:13 * apfelmus eats
10:22:38 <apfelmus> int-e: eh, let's let out the parameter and consider  m/nuX. 1+Int x X. this should replace the function category (* -> *) by a kind * one?
10:25:46 <int-e> yes
10:25:51 <ForgeAus> hey all :)
10:26:28 <apfelmus> int-e: much nicer. can you state it for this case?
10:26:36 <ForgeAus> wow the topic is kinda long
10:29:12 <int-e> apfelmus: woops. I messed up the variables. just replace T by Int in what I wrote.
10:30:51 <int-e> apfelmus: hah. I found what I remembered, a PhD thesis that (among other things) proves that the initial and final models that I used above exist - using trees: http://hsss.slub-dresden.de/pub2/dissertation/2002/mathematik_und_naturwissenschaften/993474604234-7596/993474604234-7596.pdf
10:31:10 <ForgeAus> its also strange I been coming here for a while now and I still don't understand Haskell syntax...
10:31:21 <apfelmus> int-e: so the category to work in remains (* -> *)? but the outcome is a normal type * ?? :O 
10:31:24 <ForgeAus> well mostly the operators more than the syntax
10:34:23 <int-e> apfelmus: you take a Functor F (kind * -> *; F(X) = 1 + TxX in the example) and consider morphisms f: X -> F(X) - that's the meaning of 1 now you build a category out of these morphisms; this category has (hopefully) an initial object i : I -> F(I) and a final (terminal) object t : T -> F(T). you define mu X.F(X) = I and nu X.F(X) = T.
10:34:33 <int-e> apfelmus: I and T are of kind *
10:35:09 <int-e> apfelmus: (of course they're only determined up to isomorphism, so you need to pick one of the many isomorphic objects)
10:36:39 <int-e> apfelmus: (the initial and final objects do not exist in general; they do, however, exist for a large class of interesting functors)
10:37:01 <apfelmus> int-e: ah, the category is neither * nor (*->*)
10:37:09 <int-e> apfelmus: right
10:45:41 <apfelmus> int-e: how do i get I back from i? i mean, the objects are (computable) function X->F(X), and I is a bit buried, right?
10:45:54 <int-e> apfelmus: basically the category consists of types with a required structure (a function that either returns 1 for an empty list or head:tail for a non-empty list in the example)
10:46:58 <apfelmus> int-e: ah, some kind of (X, X -> F(X)).
10:47:12 <int-e> apfelmus: yes.
10:48:16 <apfelmus> int-e: ah, now i got it. these are just the F-algebras (anything with either 0 or an binary op)
10:48:52 <int-e> Yes. Why didn't I write that :)
10:50:07 <apfelmus> int-e: because it's not so short ;-)
10:51:48 <int-e> apfelmus: anyway, yes we work in the category of F-algebras; the morphisms are F-homomorphisms.
10:53:22 <apfelmus> int-e: so the inital object is the free algebra (0 and anything i can do with it like succ(0)) finitely many times.
10:53:28 <apfelmus> and the terminal object is not () but much more interesting?
10:58:33 <int-e> apfelmus: yes. I'm struggling with the explanation.
11:01:35 <int-e> apfelmus: let (A,a) be an F-algebra and b in a, and c=u(b) the corresponding element (by the unique morphism u to T) of T. Then we either have a(b) = 1, which implies t(c) = 1 or a(b) = (x,b) which implies t(c) = (x,c') where u(b')=u(c')
11:02:39 <int-e> apfelmus: now there's an F-algebra A which contains all finite lists and also infinite ones; they are all distinguishable by applications of a, and therefore have different corresponding elements in T.
11:03:41 <int-e> I meant to write a(b) = (x,b') two lines above.
11:05:59 <int-e> and also u(b')=c'.
11:11:47 <apfelmus> int-e: mh, wait don't we have  a : F(A) -> A?
11:12:14 <apfelmus> int-e: and the category goes F(X) -> X?
11:14:17 <psi> when using c2hs, shouldn't you be able to put '#include <foo.h>' in the .chs file, just as well as specifying foo.h on the command line?
11:14:31 <int-e> apfelmus: then the final object would be ().
11:14:38 <psi> only the latter works for me
11:14:41 <apfelmus> int-e: the other way round is pattern matching.
11:16:20 <psi> the documentation says exactly this... I can't see what I'm doing wrong.
11:16:26 * vincenz does the boogie
11:16:49 <vincenz> int-e: it works!!!! (it did 8 hours ago but I crashed after having finished it
11:17:05 <apfelmus> int-e: so maybe we use F(X)->X and inital for mu (free F-algebra)   and  X->F(X) and terminal for nu (free "pattern match" thingy)
11:21:42 <int-e> apfelmus: yes, you're right.
11:25:08 <apfelmus> int-e: enlightening! despite the fact that the pdf from the link cannot flip pages backward (!?), it calls such things coalgebra.
11:25:34 <int-e> apfelmus: yes. my memory played me a few tricks.
11:26:17 <int-e> apfelmus: so, for mu we work with F-algebras; for nu we work with F-coalgebras. We pick a initial objec in the first case and a terminal model in the latter case.
11:26:36 <vincenz> the initial model in one is the terminal in the other?
11:26:55 <apfelmus> int-e: never mind. as long as your memory is coded in Haskell ;-)
11:27:07 <vincenz> apfelmus: lazily?
11:27:10 <int-e> apfelmus: in the first case, terminal objects are boring ( () ) and in the second case they usually don't exist (even for something simple like F(X)=X+1)
11:28:01 <int-e> apfelmus: err in the second case *initial* objects usually don't exist.
11:28:18 <apfelmus> vincenz: no no, i mean of only the purest thoughts :-)
11:28:20 <vincenz> int-e: my compiler works
11:28:24 <int-e> vincenz: cool
11:29:29 <apfelmus> int-e: but now, T should be an algebra and I a coalgebra, too? at least that's how i use in Haskell?
11:30:25 <int-e> apfelmus: well, for the inital and final objects the algebra respectively coalgebra are isomorphism so you can freely choose between the two.
11:31:42 <int-e> apfelmus: that's part of the reason why I didn't remember the need to distinguish between the two in the construction.
11:33:51 <apfelmus> int-e: so there isomorphic because T and I are both co- and algebras at the same time?
11:36:37 <reppie> does GHC work on ARM cpus?
11:37:05 <reppie> well, is it able to produce ARM binaries
11:37:25 <int-e> apfelmus: let t : T -> F(T) the final F-coalgebra; then F(t) : F(T) -> F(F(T)) is also a F-coalgebra. t : T -> F(T) is a coalgebra-morhism from t to F(t). there's a unique F-morphism u : F(t) -> t, because t is final. u o t is a morphism from t to t, therefore u o t = id (because id is a morphism from t to t and that morphism is unique)
11:41:18 <apfelmus> int-e: right! pattern matching constructors is the identity.
11:41:50 <apfelmus> int-e: the morphism F(t)->t means also that T is an ordinary algebra
11:42:05 <int-e> apfelmus: yep.
11:42:46 <apfelmus> int-e: by duality, the same argument goes for I
11:45:43 <apfelmus> int-e: since T is an algebra, there is a unique it : I -> T. same for ti: T -> I as I is also a coalgebra. so ti o it = id : I -> I again unique for inital I.
11:46:57 <apfelmus> int-e: and WHY do the haskell-comonad-guys Uustalu and Vene differentiate between mu and nu?
11:47:15 <int-e> but ti doesn't exist.
11:47:52 <apfelmus> int-e: oops...
11:47:56 <int-e> wait. ti isn't unique.
11:48:20 <int-e> and as a right inverse it doesn't exist.
11:49:22 * int-e is actually still missing why  t o u = id.
11:50:00 <apfelmus> int-e: right, T eats and I gives. both do in it, but i thought, one does in it and the other in ti...
11:51:25 <japple> I'm having trouble with haddock
11:51:43 <japple> it chockes on the first character of a line containing #ifndef HADDOCK
11:51:48 <japple> *chokes
11:52:06 <japple> I'm using 0.7
12:01:41 <apfelmus> int-e:  t o u  does is not unique if there is a coalgebra A with a,a' : A -> F(A) and a /= a'
12:03:37 <apfelmus> int-e: but we can have f,g :: Int -> F(Int) = 1 + Int x Int = Maybe (Int,Int)
12:03:50 <apfelmus> inte-e: f n = Nothing, g n = Just (n,n)
12:03:50 <japple> nevermind, found answer at http://www.haskell.org/haddock/haddock-html-0.7/invoking.html#cpp
12:05:58 <apfelmus> int-e: it seem that there are quite many really useless coalgebras
12:09:20 <Lokadin> @where home
12:09:21 <lambdabot> I know nothing about home.
12:13:40 <Lokadin> Could not find module `Data.ByteString.Base':
12:13:41 <Lokadin> :(
12:13:47 <Lokadin> hmmm
12:13:49 <xerox> -package fps ?
12:13:53 <xerox> (Or --make ?)
12:14:04 <xerox> Or even, does it exist? (:
12:14:06 <vincenz> @where+ home Where my stella stands.
12:14:06 <lambdabot> Done.
12:14:13 <xerox> o_O
12:14:39 <vincenz> never seen that commercial
12:14:45 <Lokadin> hmmm one sec let my try one of those
12:14:48 <vincenz> "Casa e dove sta la mia stella artois"
12:14:56 <xerox> Commercial? Oh, dunno.
12:15:06 <vincenz> you know stella artois?
12:15:16 <xerox> I think it is a beer.
12:15:20 <vincenz> erm yes
12:15:31 <Lokadin> bah, it's lambabot, and they don't have a Setup.hs
12:15:51 <Lokadin> fps 0.6 is installed though
12:15:54 <vincenz> dons: ?
12:15:58 <vincenz> erm
12:15:59 <vincenz> Lokadin: ?
12:16:04 <vincenz> Lokadin: having problems with lambdabot?
12:16:11 <vincenz> Lokadin: I have my own version running
12:16:27 <Lokadin> yea
12:16:49 <Lokadin> it' complains that it can't find Data.ByteString.Base
12:16:58 <xerox> G'evening Cale.
12:17:07 <Cale> hi
12:17:18 <Lokadin> maybe i didn't configure it properly though so i'll brb 
12:17:35 <goron> Code is nice, when it's working :)
12:18:37 <vincenz> Lokadin: install fps
12:18:56 <Lokadin> vincenz: it is installed
12:19:28 <Lokadin> fps-0.2, fps-0.6,
12:20:47 * Korollary steals Cale's axioms
12:22:14 <vincenz> Lokadin: did you do autoconf / .configure ...
12:22:26 <vincenz> make disclean
12:22:28 <vincenz> autoconf
12:22:31 <vincenz> ./configure
12:22:34 <vincenz> erm
12:22:36 <vincenz> distclean
12:23:00 <Lokadin> yea i did
12:23:03 <Lokadin>  i tried it again
12:23:08 <Lokadin> gave me same error
12:23:17 <vincenz> hmm
12:23:40 <vincenz> doesn't it complain about the fact you have two fps' installed?
12:23:55 <vincenz> it did for me when I had 0.1 and 0.7
12:24:00 <vincenz> adn then I couldn't compile lambdabot
12:24:35 <Lokadin> Could not find module `Data.FastPackedString': use -v to see a list of the files searched for (imported from Lambdabot.hs)
12:25:40 <Lokadin> i have no idea how to give it -v though, cause it's run through make
12:25:59 <Lokadin> and yi compiles fine on my system
12:26:01 <vincenz> run the command manually
12:26:25 <Lokadin> which command?
12:27:50 <vincenz> the ghc command invoked by make
12:28:05 <vincenz> alter the makefile to add in -v?
12:29:03 <Lokadin> kk i got it
12:29:06 <Lokadin> :)
12:29:53 <vincenz> ?
12:29:56 <Lokadin> Could not find module `Data.FastPackedString':
12:29:56 <Lokadin>   locations searched:
12:29:56 <Lokadin>     Data/FastPackedString.hs
12:29:56 <Lokadin>     Data/FastPackedString.lhs
12:30:08 <vincenz> o.O
12:30:11 <Lokadin> yea
12:31:29 <Lokadin> s/yea/.ie
12:33:01 <Lokadin> well it still compiles one file or attempts to after that error message and then exits with /tmp/ghc14659.hspp:14:0:
12:33:02 <vincenz> you sure you installed fps properly?
12:33:04 <Lokadin>     Failed to load interface for `Lambdabot':
12:33:06 <Lokadin>         Could not find module `Lambdabot':
12:33:13 <Lokadin> well like i said, my yi compiles fine
12:33:55 <bringert> Lokadin: Data.FastPackedString is Data.ByteString these days
12:34:06 <Lokadin> yea, i know i have both installed
12:34:07 <bringert> could that be the problem?
12:34:41 <Lokadin> i can modify the files in lamdabot to just use ByteString instead of FastPackedString
12:35:43 <mathewm> > map ((,) 'x') [ 'a', 'b', 'c']
12:35:44 <lambdabot>  [('x','a'),('x','b'),('x','c')]
12:35:52 <mathewm> are sections flipped?
12:36:06 <mathewm> > map ('x' (,)) [ 'a', 'b', 'c']
12:36:06 <lambdabot>  Couldn't match `Char' against `t -> t1'
12:36:29 <mathewm> @type ('x' (,))
12:36:30 <lambdabot>   Couldn't match `Char' against `t -> t1'
12:36:30 <lambdabot>   Expected type: Char
12:36:50 <mathewm> @type ('x' ,)
12:36:51 <lambdabot> parse error on input `)'
12:36:53 <bringert> mathewm: ((,) 'x') is not a section
12:37:05 <bringert> since (,) is not an operator, it is a function
12:37:07 <ihope> > map (flip (,) 'x') ['a','b','c']
12:37:08 <lambdabot>  [('a','x'),('b','x'),('c','x')]
12:37:17 <mathewm> oh - partially applied function gotcha
12:37:22 <ihope> > map (,'x') ['a','b','c']
12:37:22 <lambdabot>  Parse error
12:37:25 <ihope> Sigh.
12:38:27 <bringert> , is not really an operator
12:39:09 <mathewm> @type ,
12:39:10 <lambdabot> parse error on input `,'
12:39:13 <mathewm> @type (,)
12:39:14 <lambdabot> forall b a. a -> b -> (a, b)
12:39:30 <mathewm> @type (+)
12:39:31 <lambdabot> forall a. (Num a) => a -> a -> a
12:39:52 <mathewm> what makes (,) different from (+) ?
12:40:10 <bringert> + is an operator, , isn't really an operator in itself
12:40:52 <bringert> 4 , 5 isn't a valid expression
12:40:58 <bringert> bout (4, 5) is
12:41:21 <mathewm> so is the '(,)' special?
12:41:34 <bringert> (x, y) is a separate syntactic construct from infix operators
12:41:36 <mathewm> mix-fix sytax?
12:41:39 <bringert> I'd says so, yes
12:41:56 <mathewm> @type ('a',)
12:41:57 <lambdabot> parse error on input `)'
12:42:05 <mathewm> hmm
12:42:07 <mathewm> ok
12:42:09 <bringert> exactly
12:42:24 <mathewm> thanks
12:42:43 <bringert> I think the reason is that the comma is used for other stuff as well
12:43:28 <mathewm> are there other special constructs like (,) ?
12:43:43 <mathewm> '[]' seems well-behaved
12:43:43 <bringert> [], [x,y,...]
12:43:53 <mathewm> > [] 1 2
12:43:53 <lambdabot>  Couldn't match `[a]' against `t -> t1 -> t2'
12:43:58 <mathewm> > ([]) 1 2
12:43:58 <lambdabot>  Couldn't match `[a]' against `t -> t1 -> t2'
12:44:10 <mathewm> > (:) 1  []
12:44:11 <bringert> [] is a nullary constructor
12:44:11 <lambdabot>  [1]
12:44:22 <bringert> yeah, [] is not very special
12:44:26 <mathewm> > 1 : []
12:44:26 <lambdabot>  [1]
12:44:36 <bringert> but [x,y,..] is
12:44:40 <mathewm> I saw some interesting stuff with '[]' in type-classes
12:44:58 <mathewm>  m [a] == m [] a
12:45:03 <mathewm> or something like that
12:45:38 <Korollary> [] is a type constructor as well
12:46:59 <mathewm> > (1 :) [ 2, 3]
12:47:00 <lambdabot>  [1,2,3]
12:47:39 <Korollary> ?pl \x -> (x,1)
12:47:40 <lambdabot> flip (,) 1
12:47:46 <mathewm> > map (1 :) [ [2, 3], [4,5] ]
12:47:47 <lambdabot>  [[1,2,3],[1,4,5]]
12:48:35 <mathewm> what does pl do?
12:48:53 <mathewm> @pl \x -> x + 1
12:48:53 <lambdabot> (1 +)
12:49:16 <mathewm> point-less oh yes I remember that
12:50:43 <Lokadin> lol
12:50:50 <Lokadin> .ui
13:05:32 <atilaromero> How can I capture packets from my eth0 in haskell?
13:07:41 <ADEpt> atilaromero: you need bindings to libpcap. Google for qforeign, if I am not mistaken
13:07:47 <waern> :q
13:07:50 <waern> oops :)
13:08:34 <atilaromero> Ok.
13:08:36 <mathewm> you can have a 'let' without an 'in' ?
13:09:07 <int-e> in list comrehensions and in 'do' blocks, yes.
13:09:28 <mathewm> yeah, I am looking at a do block
13:09:54 <int-e> do let a=b; <operations here can use a>
13:09:56 <mathewm> I guess its scope is anything after the decl's in the do-block, ay?
13:10:08 <int-e> yep
13:10:09 <mathewm> yup, thanks :)
13:13:03 * int-e finds the blindingly obvious argument that shows t o u = id (regarding a discussion of an hour ago).
13:14:26 <int-e> (Namely: u is a coalgebra-morphism from F(t) to t; therefore t o u = F(u) o F(t) = F(u o t) = F(id) = id.)
13:14:49 <int-e> you know something is blindingly obvious when it takes an hour to find and fits comfortably on a single line. :P
13:19:55 <psi> I cannot figure this out.
13:20:01 <psi> Compiling Element          ( ./Element.hs, ./Element.o )
13:20:02 <psi> Element.chs:22:8: parse error on input `import'
13:20:14 <psi> why is it looking in the .chs file?
13:20:39 <psi> and there is not a single import statement in either file. :)
13:20:44 <int-e> you probably have some #line lines in the .hs file?
13:21:56 <int-e> hmm. {-# LINE <line number> <file> #-}
13:22:04 <int-e> close, but the wrong language :)
13:22:21 <psi> yes... what do they mean?
13:23:00 <int-e> they tell the compiler to adjust its error messages; the following code is assumed to come from the specified file, starting with the specified line.
13:23:09 <mathewm> :type mapM
13:23:17 <mathewm> @type mapM
13:23:17 <lambdabot> forall b (m :: * -> *) a. (Monad m) => (a -> m b) -> [a] -> m [b]
13:23:20 <mathewm> @type mapM_
13:23:21 <lambdabot> forall (m :: * -> *) a b. (Monad m) => (a -> m b) -> [a] -> m ()
13:23:22 <int-e> hence the error message refers to the chs file.
13:23:42 <mathewm> @type mapM >>
13:23:43 <lambdabot> parse error (possibly incorrect indentation)
13:23:49 <mathewm> @type  >>
13:23:50 <lambdabot> parse error on input `>>'
13:23:57 <psi> int-e: oh. it confused me. 
13:24:01 <int-e> (>>), (mapM >>)
13:24:15 <psi> especially since the import statement (it was actually foreign import) isn't in the .chs file
13:24:32 <int-e> psi: heh :)
13:26:15 <psi> and what I forgot was the -fffi switch.
13:26:42 <int-e> thought so :)
13:30:15 <Korollary> Why does GHC write m's kind out explicitly in the forall? Doesn't (Monad m) in the context already restrict the kind of m?
13:31:13 <SamB> Korollary: sure!
13:32:12 <scsibug> Does anyone have an idea how much registration for the 2006 ICFP will be?  I'm trying to decide if I should plan on going.
13:32:15 <Korollary> I suppose it's being extra helpful
13:32:50 <Lokadin> @localtime
13:32:56 <Lokadin> @localtime lokadin
13:33:03 <Korollary> ?time Lokadin
13:33:04 <lambdabot> Local time for Lokadin is Sun Jun  4 16:31:41 2006
13:33:10 <Lokadin> really?
13:33:15 <Lokadin> bah!
13:33:35 <Lokadin> my cellphone says the wrong time on it
13:34:13 <Korollary> every cellphone needs a lambdabot
13:34:20 <Lokadin> that's right :)
13:34:26 <Lokadin> and linux to boot
13:37:44 * dmhouse jumps into view
13:39:43 <dmhouse> mm... not the chattiest of channels
13:40:16 <SamB> Lokadin: but linux takes so *long* to boot
13:40:20 <ADEpt> i wonder, could i say to newbie that monad is a nice way to generalize the function composition ?
13:40:28 <SamB> ?
13:40:40 <dmhouse> ADEpt: generalise in what context?
13:40:44 <dmhouse> arrows might be better
13:40:45 <Lokadin> SamB: not with initng
13:40:53 <piggybox> decorator pattern
13:41:08 <dmhouse> there's a direct analogue of (.) with arrows, (>>>)
13:41:24 <dmhouse> although i suppose (>>=) is analoguous for monads
13:41:36 <Lokadin> SamB: 17s full non-X boot
13:41:51 <Lokadin> not inculding bios/grub
13:41:59 * SamB wonders how in the world to implement a board game with GTK
13:42:07 <ADEpt> dmhouse: like, function composition "sequences" function application in straightforward way. Next function is applied to the result of previous, directly. There is no way to handle errors in between, etc
13:42:32 <SamB> ADEpt: well, that still sounds like arrows ;-)
13:42:41 <dmhouse> SamB: it's monads too
13:42:48 <dmhouse> monads allow the concept of order of execution
13:42:50 <ADEpt> SamB: but context is "explaining monads to newbie"
13:42:55 <SamB> yeah, yeah
13:42:59 <SamB> but that sounds a bit confusing
13:43:01 <dmhouse> ADEpt: ah, then don't use that
13:43:07 <ADEpt> dmhouse: why not?
13:43:17 <dmhouse> it's not the main point of monads
13:43:18 <SamB> maybe we should just replace monads with arrows, and then we could use that explanation ;-)
13:43:28 <ADEpt> dmhouse: i know. I just wonder from where to begin
13:43:57 <dmhouse> either start from Maybe/[] to get the structure sorted out
13:43:58 <SamB> only arrows aren't really appropriate for everything, and sometimes too hard...
13:44:07 <goltrpoat> if they have an OOP background, then saying "decorator", like piggybox said, should set off a lightbulb
13:44:26 <SamB> but how are monads decorators?
13:44:37 <dmhouse> and say Maybe represents computations that can fail, and the Maybe monad is used to propogate failure.
13:44:43 <dmhouse> (see the Sheep program from all about monads)
13:45:12 <dmhouse> similarly [] is used for computations with multiple possible results (like parsing ambiguous grammars, or solving something like Sudoku which could have multiple solutions)
13:45:13 <SamB> anyone know how to do a board game in GTK?
13:46:02 * int-e wonders what SamB's hoping for. Make a drawing area, hook up a few events, mouse clicks and expose, draw, handle events, done.
13:46:15 <SamB> oh, that sounds hard!
13:46:23 <SamB> you want me to draw it myself?
13:46:25 <dmhouse> and the []-monad is used both to propogate failures (but with [], failures are the empty list) and to kind of "fan out" solutions
13:46:46 * int-e hands SamB a pencil and a sheet of paper.
13:46:50 <goltrpoat> sam:  they package up a type and add operations to it?  i guess decorator is not the right pattern, since decorators are supposed to be transparent with respect to the type
13:47:07 * SamB wants a higher-level interface
13:47:41 <dmhouse> and to implement backtracking
13:48:04 <goltrpoat> but it makes sense to talk about monads as decorators when you're expecting a monad but don't care which.  sort of.  maybe this isn't a good analogy after all.
13:48:11 <ADEpt> dmhouse: but that is quite the long way, and it's already a trodden path with "all about mondas"
13:48:29 <ADEpt> dmhouse: i'm looking for something which will make a "bulb" light earlier.
13:48:33 <dmhouse> okay
13:48:44 <dmhouse> try explaining the _structure_ of monads first
13:48:51 <dmhouse> then explain why they're useful
13:49:02 <dmhouse> in other words, start with monads as containers, then move on to monads as computations
13:49:13 <dmhouse> for the former, there's a wonderful wikibook somewhere, hold on
13:49:32 <dmhouse> http://en.wikibooks.org/wiki/Programming:Haskell_monads
13:49:34 <SamB> int-e: isn't there some kind of canvas with a persistant object model?
13:51:33 <int-e> SamB: I suppose you can build something on top of GtkFixed and GtkImage ...
13:52:25 <int-e> SamB: there's a gtkcanvas project based on cairo. it's not part of gtk, and I don't know if it has progressed far enough to be useful.
13:53:00 <int-e> SamB: (btw, I'm *not* a gtk expert, I've just played around with it a bit. take what I say with a grain of salt.)
13:53:25 <SamB> yeah, well I'm just looking at the palette in Glade
13:55:53 <SamB> Does it work to have overlapping widgets in GTK?
13:58:36 <int-e> hmm. I was just wondering the same - GtkFixed has no z component for its children, making overlapping children useless, even if they work.
13:58:56 <ADEpt> dmhouse: thanks for the link. Haven't seen that before. Is it mentioned on haskellwiki?
13:59:05 <dmhouse> not sure
13:59:43 <SamB> yeah, GtkTable seems to have the same problem. At least, I see nothing in Glade...
14:01:05 <int-e> oh, they have an invisible widget :)
14:01:30 <int-e> "The GtkInvisible widget is used internally in GTK+, and is probably not very useful for application developers."
14:01:38 <SamB> heh
14:03:11 <SamB> is it toplevel?
14:03:17 <int-e> SamB: on the other hand, overlapping widgets are possible in principle; redrawing is done back-to-front (well, apparently that just means parent-to-children for the existing containers) and double-buffered.
14:03:18 <dan2> hi there guys
14:03:23 <Cale> hello dan2
14:03:43 <ADEpt> question about arros then: I have in my todo a scrapnote "read: article on arrows, chris, 2006, pdf". It is about a link I seen here. Any idea what this might be?
14:04:02 <int-e> it's a subclass of Window ... and associated to a screen. I think that's as 'top-level' as an invisible widget can be.
14:05:28 <shapr> dmhouse: whoa, nick change?
14:05:52 <dmhouse> shapr: kept clashing with Daveman. Plus i wanted a shorter one anyway
14:06:04 <shapr> Makes sense to me.
14:06:11 <dmhouse> :)
14:06:46 <shapr> bringert: ping?
14:06:47 <dmhouse> now, if i can remember how to change my default nick in irssi...
14:06:57 <bringert> shapr: pong!
14:07:03 <shapr> dmhouse: What about export IRC_NICK=
14:07:12 <bringert> shapr: we went to see the bronze pig yesterday
14:07:15 <dmhouse> there's a setting in irssi, though, i'm sure.
14:07:16 <SamB> Glade is too unstable...
14:07:19 <shapr> bringert: whoa cool :-)
14:07:20 <bringert> shapr: wazzup
14:07:32 <shapr> bringert: What's your opinion on your email to jun mukai?
14:07:52 <dan2> does anyone know how to create a nonarbitrary moving average
14:07:55 <shapr> I'm mentor for HaskellNet, and the goal is just to make it easier for users to have 'batteries included'.
14:08:16 <bringert> shapr: you mean how I think it should be run? or if I think I wrote something stupid?
14:08:42 <shapr> I mean what's your suggestion for how to answer "What does this mean in practise?"
14:08:48 <dmhouse> shapr, that project sounds great.
14:08:51 <bringert> ah
14:08:55 <bringert> not sure
14:08:56 <shapr> I don't think forking is a good idea.
14:09:04 <bringert> that's why I didn't suggest anything
14:09:16 <bringert> I guess it depends on the current status of the lib
14:09:18 <shapr> Distributed together sounds nice and easy, and so does a common repo. I still would prefer separate packages though.
14:09:33 <bringert> some probably don't have maintainers
14:09:36 <bringert> others do
14:09:41 <shapr> Maybe distributed together but separate repos and separate packages is best?
14:09:57 <bringert> wouldn't cabal-get solve the distribution issue
14:10:06 <shapr> Yeah, it would.
14:10:33 <bringert> ok, so he could set up official repos for the unmaintained projects at darcs.haskell.org
14:10:44 <shapr> Yeah, that would work.
14:10:50 <shapr> dmhouse: How would you want to use HaskellNet?
14:10:53 <bringert> and the others he could have private repos for and send patches to the maintainers
14:11:25 <dmhouse> shapr, how do you mean?
14:11:26 <bringert> and then he would make sure that all packages work with cabal-get, however that will work
14:11:38 <shapr> Yeah, I like it :-)
14:12:00 <shapr> dmhouse: Just wondering what you thought about separate packages, repos, etc.
14:12:10 <dmhouse> ah.
14:12:18 <shapr> bringert: btw, any cool Seattle stories?
14:12:24 <shapr> Seen anything especially nifty?
14:12:36 <ADEpt> shapr, bringert:  is the haskell-soc-mentors ml still alive?
14:12:45 <dmhouse> well I probably wouldn't want to require the users of my app to install a POP3, MIME, FTP lib if all I need is HTTP transfer.
14:13:04 <bringert> I think that we should try to get to the point where normal library users shouldn't have to care about repos and packages too much. Just depend on packages, and use cabal-et to install stuff
14:13:16 <dmhouse> so +1 for seperate packages, at least.
14:13:22 <Lemmih> ADEpt: I believe so, yes.
14:13:59 <bringert> Rheiny: I've sen that movie. funny stuff
14:14:02 <bringert> seen
14:14:05 <ADEpt> dmhouse: I have better example. I recently looked for DNS implementation. And found it inside HAppS. Quite heavy dependency if all I need is DNS lookup
14:14:15 <dmhouse> yep, exactly.
14:14:39 <ADEpt> Lemmih: i take it that only active mentors have been left on the list, right?
14:14:47 <shapr> musasabi wrote a dns implementation. Peter Simons did also.
14:15:24 <ADEpt> shapr: and I haven't even found those on google...
14:15:30 * shapr gets urls
14:15:46 <Lemmih> ADEpt: Really?
14:15:58 <ADEpt> shapr: I would say that even collecting the full list of existing things in one place would be a huge payback from HaskellNet
14:16:22 <ADEpt> Lemmih: i haven't got a mail from there since 20th of May. Hence to conclusion.
14:16:24 <bringert> shapr: hmm, cool stories. the area net to pike place market seems a bit dodgy. scary looking guys dealing drugs right next to us on the street. outside a jewlery/pawn shop whose logo is a shot gun.
14:16:40 <ADEpt> Lemmih: from 25th
14:16:43 <bringert> shapr> micrsoft 
14:16:47 <bringert> damm enter key
14:17:18 <shapr> ADEpt: I think collecting packages to distribute via cabal-get is best!
14:17:18 <bringert> shapr: microsoft research is like a day care center in terms of spreading virii (the kind that affects people)
14:17:23 <shapr> haha
14:17:34 <Lemmih> ADEpt: I don't think anyone has used it since then.
14:17:34 <shapr> Did you hang out with the Simons?
14:17:49 <bringert> simons? aren't they in Cambridge?
14:17:51 <ADEpt> Lemmih: ah
14:17:52 <mathewm> where would one use 'evaluate'?
14:17:53 <shapr> Er, yeah
14:18:14 <shapr> Sorry, my brain is actually writing Python code to do SQL queries.
14:18:21 <bringert> yikes
14:18:28 <shapr> Hey, it's what I get paid to do.
14:18:36 <bringert> sorry
14:18:38 <shapr> Me too.
14:18:51 <bringert> shapr: I've got a new version of Blob
14:18:56 <shapr> Oh?
14:19:06 <shapr> in the repo?
14:19:08 <dmhouse> @hoogle evaluatio
14:19:09 <lambdabot> No matches found
14:19:11 <dmhouse> @hoogle evaluate
14:19:11 <lambdabot> Control.Exception.evaluate :: a -> IO a
14:19:11 <lambdabot> Test.QuickCheck.evaluate :: Testable a => a -> Gen Result
14:19:16 <shapr> I'm way tired of PLog.
14:19:19 <bringert> shapr: as a module in the beginnings of some sort of web application framework
14:19:27 <shapr> It was great for years, but... I want something with an RSS feed.
14:19:29 <shapr> oh neat!
14:19:35 <bringert> there is also a photo album module
14:19:40 <shapr> Ok, gimme url!
14:19:43 * SamB_XP decides he is too tired to program
14:19:51 <bringert> oh, yeah, I haven't gotten around to adding RSS feeds yet
14:19:54 <dmhouse> shapr, WordPress! :)
14:19:54 <shapr> Wargh
14:19:57 <bringert> but it should be easy enough
14:20:01 <shapr> dmhouse: Is that written in Haskell?
14:20:06 <dmhouse> err
14:20:21 <shapr> I want something I can hack on...
14:20:29 <shapr> For fun too
14:20:30 <dmhouse> if my 'haskell' you mean 'PHP, and bad PHP at that, and yes, there is such a thing', then yes! :)
14:20:40 <SamB_XP> haha
14:20:46 <bringert> shapr: the dependencies are a bit crazy, 10-ish packages
14:20:52 <bringert> mostly written by me
14:20:55 <shapr> bringert: That's fine with me.
14:21:00 <shapr> darcs repo?
14:21:06 <bringert> feedback would be great
14:21:11 <bringert> coming
14:21:18 <shapr> My first feedback is ... I want RSS! :-)
14:21:28 <bringert> http://www.cs.chalmers.se/~bringert/darcs/hope/
14:21:29 <dmhouse> what you _really_ want is Atom.
14:21:33 <bringert> for the framework
14:21:34 <SamB_XP> shapr: I must ask you -- what *is* RSS?
14:21:40 <shapr> Really Simple Syndication
14:21:44 <dmhouse> SamB_XP: it's an XML version of the site, basically
14:22:08 <dmhouse> if you read a lot of blogs, you get all their RSS feeds, plug them into a feed reader, then this program tells you when there's a new entry on one of your blogs
14:22:10 <SamB_XP> I ask this because "RSS" has been used for many incompatible specs...
14:22:16 <bringert> http://www.cs.chalmers.se/~bringert/darcs/blob2/ for the blog module (check it out into the modules/ dir of hope
14:22:27 <dmhouse> he probably means RSS2.
14:22:36 <bringert> http://www.cs.chalmers.se/~bringert/darcs/halbum2/ for the photo album module, same drill with the checkout
14:22:37 <dmhouse> RSS0.92 is obsolete, RSS1 is something completely different
14:22:43 * SamB_XP kinda likes RSS3
14:22:49 * dmhouse kinda likes Atom
14:23:05 * shapr likes GData
14:23:14 <SamB_XP> now, Atom, that is a name ;-)
14:23:29 <SamB_XP> though it is probably a bit harder to google
14:23:34 <dmhouse> :)
14:23:38 <bringert> shapr: I should probably add a list of requirements before you try to build it
14:23:57 <shapr> Jun Mukai said he might have time to get a Haskell GData implementation working.
14:24:00 <shapr> That would rock :-)
14:24:09 <SamB_XP> what is GData?
14:24:18 <shapr> bringert: Or I can iterate build -> oops -> install
14:24:38 <shapr> bringert: Plus make shows the packages.
14:24:39 <bringert> yeah, well, that'll take a while
14:24:54 <bringert> except the ones I forgot to add package flags for
14:25:06 <shapr> I wish darcs had meta-repos that got a bunch of other repos into subdirs.
14:25:20 <SamB_XP> mmmm
14:25:43 <SamB_XP> would be good for JHC ;-)
14:25:51 <shapr> And I'd want it to work so that darcs pull in a meta-repo would update all subrepos.
14:26:33 <shapr> bringert: haskell-cgi (NewCGI?) is quite nifty.
14:26:40 <shapr> I've used it for my Flash coding a bit.
14:26:50 <bringert> cool
14:26:53 <bringert> flash?
14:26:59 <shapr> http://www.scannedinavian.com/~shae/flash/ProtoExternalData.swf
14:27:08 <shapr> I'm learning Flash in hopes of making money with it.
14:28:17 <dmhouse> shapr, you can call Haskell from Flash?
14:28:31 <shapr> Sure, Flash has getURL
14:28:40 <dmhouse> aha. cool. :)
14:28:42 <shapr> And that can call a CGI program.
14:28:46 <shapr> You can also do xmlrpc
14:28:51 <dmhouse> seems a rather round-about way of doing things, if it's on the same server
14:29:19 <shapr> It's easy though. I've not tried setting up a streaming xmlrpc connection yet.
14:29:25 <shapr> Ya know, that whole ajax bit.
14:29:33 <shapr> bringert: Where do I get xhtml?
14:29:37 <dmhouse> a serverside shell connection would be better
14:29:54 <bringert> shapr: I'm writing up a list of urls for the deps right now
14:33:21 <shapr> bringert: cool
14:33:55 <bringert> shapr: updated hope/INSTALL with deps. let me know If I missed any.
14:34:02 <bringert> maybe I should use cabal to build it
14:34:14 <shapr> yes!
14:34:16 <bringert> you really need to read INSTALL btw
14:34:24 <bringert> you need to edit some files
14:34:50 <sam_> yay.. just got my first 'real' program working that is using error monads for error handling.. coding it was a pain for every single line :-)
14:35:13 <dmhouse> SamB_XP: cool! what does it do?
14:35:16 <dmhouse> err
14:35:23 <bringert> shapr: did you know that NewCGI uses lazy bytestrings now? you can serve huge files really quickly with constant memory
14:35:24 <dmhouse> sam_: cool! what does it do?
14:35:31 <shapr> bringert: awesome!
14:35:41 <Razor-X> If a compiled program takes command-line parameters, can you specify them in ghci too?
14:35:50 <sam_> dmhouse, parses historial stock quote data from flat files and displays them on a graph
14:36:26 <dmhouse> sam_, nice
14:36:38 <dmhouse> sam_, what graphing lib did you use?
14:37:01 <sam_> dmhouse, integrating with gnuplot
14:37:10 <dmhouse> right
14:37:21 <bringert> shapr: the whole thing is still kinda rough, but I think the code is nice to work with
14:37:32 <shapr> btw, I wish I could use ParseDate as a combinator in Parsec
14:37:59 <bringert> shapr: you can't?
14:38:09 <shapr> Maybe I can, but I couldn't figure out how.
14:38:13 <bringert> ah, you're right, silly me
14:38:17 <bringert> I should expose that
14:38:34 <shapr> I wanted to do parsedate format inputstring
14:38:51 <shapr> or: calTime <- parsedate format inputstring
14:39:18 <bringert> shapr: you'll have it in a few minutes
14:39:19 <shapr> I forget what sort of time value is returned, but it would be nice to use directly inside parsec.
14:39:21 <shapr> w00!
14:40:46 <shapr> bringert: Hey, I'll be living in Stockholm end of the month, and I have more unicycles...
14:40:55 <shapr> And this time I have the right tools to adjust the seat height.
14:41:01 <vincenz> shapr: !
14:41:07 <bringert> shapr: for how long?
14:41:22 <shapr> Until migrationsverket throws me out of the country I guess. Which I hope won't happen.
14:41:58 <bringert> great. I'll come visit some time
14:42:00 <shapr> yay!
14:42:11 <shapr> Or I'll come visit you and we can have another EuroHaskell
14:42:35 <shapr> Anyway, if you need a place to sleep in Stockholm now you have one!
14:43:19 <bringert> sapr: I'll add it to my list :-P
14:43:20 <shapr> Hm, I get an error with Hawl...
14:43:23 <bringert> eh shapr
14:43:29 <bringert> shapr: what?
14:43:51 <shapr> ./Hawl/Util/CGI.hs:55:22: \n Couldn't match `ByteString' against `Data.ByteString.ByteString' \n Expected type: m ByteString \n Inferred type: m Data.ByteString.ByteString
14:43:58 <shapr> I may need to update my ByteString version
14:44:01 <bringert> huh
14:44:03 <bringert> probably
14:44:15 <bringert> you need the darcs version from less than two days ago
14:44:20 <shapr> Yargh, we need a european mirror, dons repo is slow!
14:44:23 <bringert> this thing is very bleeding edge
14:44:25 <shapr> cool!
14:45:32 <shapr> What did you think of Pike Place Market?
14:46:09 <bringert> shapr: exposed pCalendarTime is in parsedate darcs now. the docs on the home are not updated yet, I'm working on my homepage generation program.
14:46:55 <bringert> shapr: we got there a bit late, so they were closing up. Saw lots of stalls selling batik shirts, crystals, statues made from Mount St Helens ash etc
14:47:12 <bringert> I'm a bit ill atm, so we took it really easy
14:47:21 <bringert> need to go there again
14:47:29 <bringert> do you have any tips for good stuff?
14:48:31 <bringert> hmm, I probably exposed the wrong thing in parsedate, hold on
14:53:15 <kpreid_> shapr!
14:53:21 <kpreid_> I have something you will find interesting!
14:55:21 <kpreid_> I also have a question: is there a monad (transformer) which provides something like IORefs except not in the IO monad? That is, like a state monad with the state being a map and a counter for fresh names.
14:55:30 <dmhouse> ST
14:55:48 <dmhouse> IO is just ST with an environment of RealWorld.
14:56:22 <SamB> dmhouse: virtual-implementation-detail
14:56:42 <dmhouse> SamB: ?
14:56:50 <SamB> virtual-non-implementation detail
14:56:51 <kpreid_> dmhouse: I thought that might be, but what do I use for new/read/write?
14:56:52 <SamB> actually
14:57:15 <SamB> since you may notice that IO actually is not a newtype of ST
14:57:26 <dmhouse> kpreid_: try browsing the Control.Monad.ST module. it's things like newSTRef, modifySTRef and writeSTRef
14:57:35 <dmhouse> just like the *IORef functions
14:57:51 <kpreid_> I've been looking at http://haskell.org/ghc/docs/latest/html/libraries/base/Control-Monad-ST.html and it doesn't have anything about STRef
14:58:01 <kpreid_> but I now see Data.STRef
14:58:14 <kpreid_> I didn't look hard enough, but the documentation isn't particularly helpful either :)
14:58:28 <vincenz> ihope: ping
14:58:43 <ihope> Pong.
14:59:16 <vincenz> hmm
14:59:17 <vincenz> nm
14:59:56 <vincenz> how does your drain only support one faucet?
15:01:37 <ihope> I run one drain and two faucets, but only one faucet spews anything.
15:01:41 <vincenz> and don't you get memory blow up when you do
15:01:44 <vincenz> faucet | drain
15:01:58 <vincenz> ihope: how do you do that?
15:02:03 <vincenz> run two faucets
15:02:17 <vincenz> what's the cmdline?
15:02:38 <ihope> drain 389 sets up a drain on port 389, and faucet 389 connects to that drain.
15:02:46 <vincenz> yep
15:03:02 <vincenz> I don't see how you can do circularl stuff
15:03:10 <vincenz> faucet 400 | drain 400
15:03:20 <ihope> faucet 485 | dosomething | drain 485
15:03:20 <vincenz> faucet will fail to connect to drain cause drain hasn't started yet
15:03:35 <ihope> What if all the things in the pipe are run at the same time?
15:03:39 <vincenz> hmm
15:03:45 <bringert> I want a parsec function with type: st -> GenParser tok st a -> GenParser tok () st
15:03:46 <vincenz> ihope: doesn't that generate infinite input?
15:03:58 <vincenz> ihope: and what's the cmdline for multiple faucets?
15:04:14 <bringert> i.e. run a stateful parser with an initial state, and get the state
15:04:17 <ihope> vincenz: drain 295, faucet 295, faucet 295...
15:04:24 <vincenz> ihope: , ?
15:04:50 <ihope> vincenz: just have two faucets with the same number.
15:05:00 <vincenz> yeah but how do you invoke em
15:05:05 <ihope> Invoke?
15:05:07 <vincenz> show me an exact cmdline
15:05:36 <ihope> drain 295 on one term, faucet 295 on each of two others.
15:05:53 <vincenz> ah
15:06:09 * vincenz was thinking single term
15:06:37 <vincenz> btw
15:06:41 <vincenz> I think your naming is confusing
15:06:44 <vincenz> first time I read your mail
15:06:45 <bringert> shapr: it was harder than I thought
15:06:47 <vincenz> and when I pinged you
15:06:58 <vincenz> I was gonna suggest calling faucet drain and viceversa
15:07:02 <vincenz> cause drain faucets on the tcpip
15:07:03 <bringert> shapr: I can't figure out how to run a stateful parser in side a stateless one
15:07:04 <CosmicRay> can somebody help me figure out the problem with my class instances at http://darcs.complete.org/hsh/HSH/Command.hs ?
15:07:45 <vincenz> ihope: pipetoSock and socktoPipe?
15:07:56 <bringert> CosmicRay: what happens?
15:07:59 <ihope> What to what?
15:08:20 <vincenz> ihope: drain and faucet are confusing names... cause drain pours stuff into the tcpip
15:08:23 <vincenz> into the socket
15:08:30 <vincenz> pipetosocket sockettopie
15:08:32 <vincenz> pipe
15:08:36 <ihope> Ah.
15:08:56 <CosmicRay> when compiled without -fglasgow-exts, I get a bunch of HSH/Command.hs:109:0:
15:08:56 <CosmicRay>     Illegal instance declaration for `ShellCommand (String, [String])'
15:08:56 <CosmicRay>         (The instance type must be of form (T a b c)
15:08:56 <CosmicRay>          where T is not a synonym, and a,b,c are distinct type variables)
15:08:56 <CosmicRay>     In the instance declaration for `ShellCommand (String, [String])'
15:08:57 <CosmicRay> Failed, modules loaded: none.
15:09:04 <wilx> Confusing? I think it sounds nice.
15:09:05 <CosmicRay> when I use -fglasgow-exts, it compiles but trying to use it fails with *HSH.Command System.Posix.IO> fdInvoke ("ls", []) stdInput stdOutput (\_ -> return ()) (return ())
15:09:10 <CosmicRay> <interactive>:1:0:
15:09:12 <CosmicRay>     No instance for (ShellCommand ([Char], [a]))
15:09:14 <CosmicRay>       arising from use of `fdInvoke' at <interactive>:1:0-7
15:09:16 <CosmicRay>     Probable fix: add an instance declaration for (ShellCommand ([Char], [a]))
15:09:18 <CosmicRay>     In the definition of `it':
15:09:20 <CosmicRay>         it = fdInvoke ("ls", []) stdInput stdOutput (\ _ -> return ()) (return ())
15:09:21 <ihope> But faucet pours data into the pipe, which flows into the drain.
15:09:22 <CosmicRay> *HSH.Command System.Posix.IO>
15:09:24 <CosmicRay> bringert: does that answer your question?
15:09:31 <ihope> CosmicRay: mind using a pastebin for that stuff?
15:09:32 <dmhouse> CosmicRay: you can't use String in instance declarations
15:09:36 <dmhouse> use [Char] instead
15:09:49 <dmhouse> the reason is what is says, "T is not a synonym"
15:10:21 <ihope> Of course, in "real" plumbing, the drain's where stuff flows into the pipe, and the faucet's where it comes out... oh well.
15:10:25 <bringert> CosmicRay: you have a [] in your command, this is polymorphic
15:10:42 <bringert> try giving it an explicit type
15:11:10 <bringert> "No instance for (ShellCommand ([Char], [a]))", the [a] is the type of the []
15:12:18 <CosmicRay> dmhouse: oh, hmm!  I had no idea.  that seems brain-dead for some reason.
15:12:18 <CosmicRay> ihope: sorry
15:12:20 <CosmicRay> dmhouse: that did not fix the compilation problem
15:12:24 <CosmicRay> hmm.
15:12:30 <CosmicRay> if I invoke it with []::[[Char]], that helps.
15:12:32 <CosmicRay> bringert: why can't it infer, since there is a class that would match?
15:12:41 <vincenz> ihope: aha!!!
15:12:44 <vincenz> ihope: I think I know
15:12:45 <bringert> CosmicRay: it doesn't work that way :-)
15:12:53 <CosmicRay> also I still don't understand why I get the compilation error without -fglasgow-exts
15:13:07 <dmhouse> anyone familiar with ST internals?
15:13:10 <vincenz> ihope: see it works fine for me if I modify just slightly
15:13:43 <bringert> CosmicRay: you need glasgow-exts for this stuff, otherwise you can't declare instances for T T' (e.g. [Char], that is String). I think so anyway
15:13:54 <dmhouse> i'm wondering where realWorld# and State# are defined. They are used in GHC.ST, but neither seem to be in any of the modules imported from there
15:14:15 <ihope> They're defined in the same place as [] :-P
15:14:26 <dmhouse> ihope, where's that?
15:15:02 <ihope> Eh, I don't actually know...
15:15:05 <vincenz> ihope: works for me
15:15:20 <ihope> vincenz: so what's the slight modification?
15:15:38 <vincenz> ihope:  but I still fail to see how you would use this... cause it's just catting whatever comes in from the drain to the two faucets
15:15:42 <vincenz> ihope: I don't filter localhost
15:15:48 <bringert> CosmicRay: from the Haskell 98 report, section 4.3.2: The general form of the corresponding instance declaration is: instance cx' => C (T u1 ... uk) where { d } where k>=0. The type (T u1 ... uk) must take the form of a type constructor T applied to simple type variables u1, ... uk; furthermore, T must not be a type synonym, and the ui must all be distinct.
15:15:54 <vincenz> ihope: before neither of my faucets would print
15:16:03 <ihope> Hmm, I'll try that.
15:16:20 <vincenz> but
15:16:22 <vincenz> if I do
15:16:28 <vincenz> tail -f log | ./drain 1234
15:16:32 <vincenz> and then sepearte term
15:16:37 <vincenz> ./faucet 1234 >> log
15:16:38 <vincenz> and another term
15:16:41 <vincenz> ./ faucet 1234
15:16:42 <vincenz> I get nothing
15:16:55 <ihope> What's tail do?
15:17:01 <vincenz> follows a file's end
15:17:12 <vincenz> it's like an endless catb
15:17:15 <vincenz> but starts at the end
15:17:26 <vincenz> I bet it's got to do with buffering
15:20:17 <vincenz> yeah I think it has to do with tail's buffering
15:20:21 <vincenz> btw
15:20:27 <vincenz> I changed faucet and drain to BOTH use linebuffering
15:20:43 <ihope> Maybe the localhost thing was some platform thing.
15:21:29 <vincenz> odd
15:21:31 <vincenz> now I get zilch
15:22:02 <vincenz> cat xx | ./drain 1234
15:22:04 <vincenz> faucet 1234
15:22:05 <vincenz> nada
15:23:41 <vincenz> odd
15:23:46 <vincenz> now I get no input again
15:24:00 <vincenz> on second faucet
15:24:33 <vincenz> oh!
15:24:34 <vincenz> I know
15:24:35 <vincenz> duh!
15:24:36 <vincenz> duh!
15:24:41 <vincenz> ihope: I see what it is
15:24:45 <vincenz> ihope: it's rather trivial
15:25:02 <vincenz> ihope: if you run multiple faucets in parallel, you'll need threading in drain
15:25:16 <ihope> Don't I have that?
15:25:28 <ihope> ...Whoops.
15:28:53 <vincenz> ihope: http://rafb.net/paste/results/nkSuFp52.html
15:29:54 <ihope> Thanks.
15:30:21 <vincenz> still can't get the endless thing to work tho
15:30:32 <vincenz> I suspect that's a tail issue
15:31:17 <ihope> @karma+ vincenz
15:31:17 <lambdabot> vincenz's karma raised to 6.
15:31:22 <vincenz> aha!
15:31:26 <vincenz> figured out why it doesn't work for me :D
15:33:41 <vincenz> yep
15:33:47 <vincenz> setNoBuffering on stdout
15:33:49 <vincenz> in faucet
15:34:56 <vincenz> ihope: I'm adding these to my darcs, how do I quote you?
15:35:09 <ihope> Darcs?
15:35:15 <vincenz> yeah I have a random haskell darcs
15:35:18 <vincenz> which is also online
15:35:25 <vincenz> just small snippets of haskell stuff
15:35:29 <vincenz> how do I refer to you?
15:35:35 <ihope> I don't know Darcs.
15:35:39 <vincenz> ...
15:35:41 <vincenz> it's a repository
15:35:45 <ihope> Um...
15:35:46 <vincenz> how do I refer to you in the files
15:35:52 <vincenz> since these might be accessed by others
15:35:53 <ihope> Oh, you mean...
15:35:55 <dmhouse> ihope, he wants a name
15:36:01 <vincenz> I want a license
15:36:16 <vincenz> - Initially written by ihope?
15:36:17 <vincenz> will do?
15:36:19 <ihope> Make it public domain, and "ihope".
15:36:34 <vincenz> - Public domain software originally implemented by ihope
15:36:37 <vincenz> like that?
15:36:39 <ihope> Yeah.
15:36:43 <dmhouse> mmm, more mystery on ihope's part ;)
15:37:03 <vincenz> what's with the no name sharing
15:37:28 <jer> under "Moral Rights" under copyright law (at least in north america) you can hold a copyright with an alias on literary works (including computer software)
15:37:36 <vincenz> anyone know lhs?
15:37:48 <vincenz> if I ad a line without >
15:37:52 <vincenz> ghc complains
15:38:00 <vincenz> unlit: Program line next to comment
15:38:10 <scsibug> you need blank lines between code and comments with lhs
15:38:28 <vincenz> what a random requirement
15:38:42 <int-e> "public domain, use at your own risk. please ignore the ticking sounds inside."
15:38:42 <scsibug> indeed, supposedly to prevent accidentally writing code without the preceding >
15:38:56 <scsibug> it seems to cause more trouble than it's worth, imo
15:40:03 <vincenz> is there a global environment variable that you can set so darcs doesn't ask email for each new repo?
15:40:40 <scsibug> there is a file inside _darcs/prefs
15:41:05 <vincenz> ihope: http://oasis.yi.org:8080/repos/haskell/random/
15:41:14 <vincenz> scsibug: yeah but that's repo/dependent
15:41:22 <scsibug> ah, sorry, true
15:41:38 <scsibug> DARCS_EMAIL, environmment variable
15:42:28 <int-e> vincenz: also ~/.darcs/author , /email, etc.
15:42:32 <scsibug> fyi, I don't think that overrides what is in _darcs/prefs/author however
15:42:33 <vincenz> ah thx
15:43:02 <vincenz> ~/.darcs seems to be it
15:43:49 <scsibug> looking through darcs source code trying to fix a problem was what got me interested in haskell ;)
15:44:29 <vincenz> :)
15:44:33 <vincenz> evince is the worst software ever
15:44:35 * vincenz mutters
15:46:15 <dmhouse> this is why dynamic typing sucks:
15:46:18 <dmhouse> if ( false === strpos($rewrite, 'index.php/') )
15:46:40 <dmhouse> here $rewrite is an array. an array! jeez. wonder how long that bug has been sitting in the WordPress core.
15:47:16 <dmhouse> for those interested, the reason PHP doesn't complain is because it can handle array -> string coercions. It just changes anything to the string 'Array'.
15:47:42 <int-e> ah I can see how that is useful in preventing software bugs
15:49:25 <jer> dmhouse, and that statement is why broad generalizations suck =]
15:49:53 <bjornbm> Hello all.
15:50:56 <dmhouse> jer, why?
15:51:33 <jer> dmhouse, condemning dynamic typing because of one lousy example in one language is just as ridiculous if i said ocaml's +/+., -/-., etc operations is why static typing sucks =]
15:52:06 <dmhouse> hehe, yeah i know.
15:53:24 <bjornbm> Do you people know of a good "package" for general work with dates/times? System.Time seems pretty bare to me.
16:01:06 <vincenz> > let as = 1 in a
16:01:06 <lambdabot>  Not in scope: `a'
16:01:44 <vincenz> > let as = 1 in as
16:01:45 <lambdabot>  1
16:02:58 <bringert> bjornbm: I think the System.Time stuff in ghc 6.6 will have more stuff
16:03:25 <vincenz> odd
16:03:34 <vincenz> > let qualified = 1 in qualified
16:03:35 <lambdabot>  1
16:03:38 <bringert> if you want to parse dates, there's also http://www.cs.chalmers.se/~bringert/darcs/parsedate/doc/
16:03:45 <vincenz> > let import = 1 in import
16:03:46 <lambdabot>  Parse error
16:04:08 <vincenz> > let module = 1 in module
16:04:08 <lambdabot>  Parse error
16:04:26 <Igloo> as and a few others aren't keywords as they were added to the language later and didn't want to break existing programs
16:04:33 <bringert> vincenz: qualified and as only have special meanings in import clauses. 
16:04:47 <Igloo> as, qualified and hiding I think. The report will tell you if you really care
16:06:20 <bjornbm> Ok, thanks bringert, I'll check your parsedate stuff
16:22:04 <bjornbm> bringert: looks like your code will help a little at least. Had hoped for more stuff to be around. Thanks anyway!
16:31:52 <AtnNn> hi
16:32:49 <AtnNn> in this message (http://www.haskell.org/pipermail/haskell/2001-May/007262.html) someone (Jerzy K.) talks about a "time-machine monad [...]proposed once by hadler
16:33:21 <AtnNn> *wadler. does anyone know where i can find an example of this?
16:34:05 <Pseudonym> @google phil wadler
16:34:07 <lambdabot> http://homepages.inf.ed.ac.uk/wadler/
16:34:55 <SamB> AtnNn: it might have been a joke, or maybe something to do with:
16:34:55 <SamB> @hoogle mfix
16:34:56 <lambdabot> Control.Monad.Fix.mfix :: MonadFix m => (a -> m a) -> m a
16:35:07 <Pseudonym> http://homepages.inf.ed.ac.uk/wadler/topics/monads.html
16:35:12 <Pseudonym> That should narrow your search a bit.
16:35:45 <AtnNn> thank you
16:36:38 <SamB> (or perhaps a mixture of the two ;-)
16:41:35 <_frederik_> how do i code strongly iterative algorithms in haskell? like where i need to be sure that stuff is garbage collected between one iteration and the next, where it would really be better for things to be strict?
16:41:51 <Pseudonym> That's a big question.
16:42:04 <Pseudonym> Do you have a specific example?
16:42:11 <SamB> you don't try to get it GC'd between iterations
16:42:27 <SamB> you could try FastMutInt, though, whatever that may be
16:42:50 <Pseudonym> Without knowing specifics, if it's really that important to you, perhaps you should be looking at a monadic data structure with guaranteed destructive update.
16:43:01 <Pseudonym> FastMutInt is one example, IOArray is another.
16:43:03 <_frederik_> no that's not what i want
16:43:09 <lscd> newbie question: i'm trying to parse some command line arguments, and i want to verify that one of them is a number; i can use read, but then if it's not it blows up - what's the simplest way to check if the contents of a string are parseable as a number?
16:43:25 <_frederik_> i have a linear algebra library
16:43:32 <Pseudonym> _frederik_: OK
16:43:33 <_frederik_> it's based on alberto's GSLHaskell
16:43:39 <SamB> anyways, you really don't want to GC every iteration, it would be *really really slow*, and O(n) in live data...
16:43:45 <_frederik_> it's as fast / faster than octave for large matrix computations
16:43:55 <_frederik_> because they both use ATLAS / LAPACK i think
16:43:58 <Pseudonym> Cool.
16:44:10 <_frederik_> but haskell suffers from laziness of course
16:44:19 <_frederik_> and most algorithms are expressed iteratively
16:45:01 <_frederik_> haskell's much faster than octave (and probably matlab) when it comes to executing instructions, looping, etc.
16:45:22 <_frederik_> but what is needed is a good way to express iterative computations without worrying about dangling thunks
16:45:31 <Pseudonym> Do you have an example use case?
16:45:49 <_frederik_> well i'm writing a paper and i want to code up an example which is from one of my classes
16:46:01 <_frederik_> it's just a random machine learning task
16:46:05 <Pseudonym> Ah, OK.
16:46:33 <Pseudonym> My first comment is that the easiest way to avoid dangling thunks is to use strict containers.
16:46:44 <Pseudonym> IOUArray is one example.
16:46:59 <_frederik_> http://www.gatsby.ucl.ac.uk/~zoubin/course05/asst5var.pdf
16:47:12 <_frederik_> ok
16:47:20 <_frederik_> i was thinking about 'DeepSeq'
16:47:34 <Pseudonym> DeepSeq is a sledgehammer, but sometimes that's what you need.
16:47:40 <_frederik_> it seems one could just define it in terms of Data
16:47:46 <_frederik_> why isn't every haskell object an instance of Data?
16:48:02 <Pseudonym> Long story.
16:48:06 <_frederik_> it could have a default instance which would be overridden
16:48:14 <Pseudonym> But the short answer is that there are still some Haskell types for which it doesn't make sense.
16:48:18 <Pseudonym> Functions, for example.
16:48:33 <_frederik_> so what?
16:48:46 <_frederik_> i'd rather have it defined automatically for the ones which do make sense
16:48:52 <_frederik_> which is almost everything
16:48:53 <Pseudonym> If you deepSeq a function, you might expect that it evaluates all of the thunks inside the function body.
16:48:58 <Pseudonym> Ah, not true!
16:49:03 <Pseudonym> In fact, it's less than you think.
16:49:25 <_frederik_> i don't understand the argument though
16:49:47 <Pseudonym> If there is even one type for which deepSeq doesn't make sense, then all of a sudden it's a bit dubious for any polymorphic type.
16:50:05 <_frederik_> why?
16:50:35 <_frederik_> it's pretty clear to me. if I define something with 'data ... = ...' then it should have a data instance that reflects that
16:50:57 <Pseudonym> I'm talking about deeqSeq specifically.
16:51:09 <_frederik_> ok
16:51:16 <Pseudonym> I do take your point, though.
16:51:21 <_frederik_> i'm guessing this is on the mailing list
16:51:46 <Pseudonym> Any type that you declare with "data" would make sense to be a member of Data.
16:51:52 <Pseudonym> However.
16:51:57 <Pseudonym> This is actually a current research topic.
16:52:07 <Pseudonym> The "deriving" declaration isn't extensible.
16:52:18 <Pseudonym> There are a few auto-derivable typeclasses built in.
16:52:29 <_frederik_> lscd: there are a lot of parsers which will return [] for a failure
16:52:35 <Pseudonym> But it'd be even more useful if you could define your own.
16:53:21 <_frederik_> but if everything had a Data instance, then you could also give everything a DeepSeq instance, etc.
16:53:36 <_frederik_> i think Data is all you really need
16:53:43 <lscd> _frederik_: sure - i mean, worst-case, i could haul out parsec or something - but i'm wondering about the simplest / most typical haskell-style way to do something like this
16:54:28 <_frederik_> lscd: Text.ParserCombinators.ReadP is good
16:54:35 <Pseudonym> @type reads
16:54:37 <lambdabot> forall a. (Read a) => ReadS a
16:54:46 <Pseudonym> reads "1" :: ReadS Int
16:54:51 <Pseudonym> > reads "1" :: ReadS Int
16:54:51 <lambdabot>  Couldn't match `[(a, String)]' against `t -> t1'
16:55:10 <Pseudonym> > reads "1" :: [Int]
16:55:10 <lambdabot>  Couldn't match `Int' against `(a, String)'
16:55:13 <_frederik_> > reads "1" ""
16:55:13 <lambdabot>  Couldn't match `[(a, String)]' against `t -> t1'
16:55:18 <Pseudonym> > reads "1" :: [(Int,String)]
16:55:19 <lambdabot>  [(1,"")]
16:55:21 <Pseudonym> That's it.
16:55:28 <Pseudonym> > reads "Hello" :: [(Int,String)]
16:55:29 <lambdabot>  []
16:55:32 <Pseudonym> Bingo.
16:55:48 <lscd> hm; that seems like overkill, but thanks
16:56:01 <Pseudonym> It is overkill, but it has one advantage.
16:56:20 <lscd> which is?
16:56:21 <Pseudonym> It uses the standard Haskell "Read".
16:56:31 <lscd> ahhh; how?
16:56:32 <Pseudonym> Which means it's an inverse for "Show".
16:56:45 <palomer> read isn't really an inverse for show
16:56:51 <Pseudonym> More or less.
16:57:03 <Pseudonym> No, it's a retract for "Show".
16:57:06 <Pseudonym> Happy now?
16:57:11 <palomer> even then
16:57:19 <AtnNn> @pl (\a -> (a,a))
16:57:19 <lambdabot> join (,)
16:57:26 <_frederik_> anyway, so i was thinking about sending auxiliary information about the computation to a channel, it will either be thrown away or used for debugging. that way you don't have unevaluated thunks leaking out, like you would for instance if you collected a list of values describing the progress of the computation. has anyone done that before?
16:57:30 <palomer> you're claiming that show . read = id, right?
16:57:39 <Pseudonym> No, read . show = id
16:57:51 <Pseudonym> For any non-bottom value.
16:58:02 <SamB> _frederik_: well, some people are liking to use trace levels
16:58:03 <lscd> what's a retract?
16:58:09 <palomer> and any value which does not contain bottom somewhere?
16:58:18 <_frederik_> SamB: what's a trace level?
16:58:23 <Pseudonym> lcsd: If r . s = id, then r is a retract for s.
16:58:28 <Pseudonym> And s is a section for r.
16:59:12 <lscd> hm... how does this differ from the concept of inverse?  by r .s = id not implying s . r = id, or something else?
16:59:23 <Pseudonym> Correct.
16:59:27 <lscd> and what branch of math is this from?
16:59:31 <Pseudonym> Category theory.
16:59:33 <lscd> ah-hah
16:59:47 <lscd> i've got to start learning that; everything in haskell seems to keep leading back to it
16:59:48 <Pseudonym> This is a classic example of how r . s = id does not imply that s . r = id
16:59:48 <shapr> slashdot is sort of like intellectual anesthesia.
16:59:54 <lscd> shapr: yep
17:00:14 <Pseudonym> For example, serialising a data structure makes one String for every data structure.
17:00:21 <Pseudonym> But many Strings may map to the same data structure.
17:00:27 <Pseudonym> Given differing whitespace, for example.
17:00:28 <_frederik_> but i think the name "retract" comes from algebraic topology, right?
17:00:40 <Pseudonym> Many things in category theory come from algebraic topology.
17:01:01 <lscd> any recommendations for books / websites to learn the basics of category theory and algebraic topology?
17:01:11 <shapr> bringert: Hey, problems with hawl
17:01:18 <mlh> wikpedia
17:01:25 <bringert> shapr: ok, what?
17:01:25 <shapr> bringert: Compiling Hawl.User.DBDesc ( ./Hawl/User/DBDesc.hs, dist/build/Hawl/User/DBDesc.o ) \n ./Hawl/User/DBDesc.hs:16:58: Not in scope: data constructor `IntT'
17:01:28 <Pseudonym> lcsd: First book you should try to borrow is "Conceptual mathematics".
17:01:35 <_frederik_> lscd: mac lane
17:01:36 <Pseudonym> It's extremely gentle.
17:01:51 <Pseudonym> Mac Lane is good, so is Barr and Wells.
17:01:53 <bringert> shapr: is your HaskellDB up to date?
17:01:55 <shapr> um
17:02:03 <shapr> Probably not, I'm using the debs.
17:02:14 <bringert> shapr: there is a parsecCalendarTime is parsedate now
17:02:16 <shapr> Is HaskellDB in a darcs repo these days?
17:02:20 <shapr> bringert: thanks!
17:02:24 <Pseudonym> http://www.let.uu.nl/esslli/Courses/barr-wells.html <- Barr & Wells
17:02:31 <bringert> shapr: you wouldn't believe what a hack I needed to do it
17:02:39 <shapr> I'm afraid to ask.. what did you do?
17:03:04 <_frederik_> so if anyone else has advice about iterative algorithms...
17:03:04 <bringert> shapr: yes, http://darcs.haskell.org/haskelldb/
17:03:54 <bringert> shapr: parsec does not provide a way to use a stateful parser in a stateless one, or one with a different state type, afaict
17:04:06 <shapr> Hm, that could be better.
17:04:20 <shapr> It'd seem like a commonly needed feature.
17:04:32 <shapr> But maybe I've worked with ASN.1 too much.
17:04:49 <Pseudonym> Any working with ASN.1 is too much. :-)
17:04:49 <lscd> mind expanding on 'mac lane' a bit?  googling is turning up a lot of irrelevant stuff, and i'm not sure enough on what it is to be able to narrow it down effectively
17:04:58 <bringert> so I use runParser inside a parser with a different state type, shuffling the positions and inputs around to to make it work
17:05:00 <Pseudonym> @google "saunders mac lane"
17:05:01 <lambdabot> http://www-history.mcs.st-andrews.ac.uk/history/Mathematicians/MacLane.html
17:05:08 <Pseudonym> Oooh, nice link.
17:05:38 <Pseudonym> http://en.wikipedia.org/wiki/Categories_for_the_Working_Mathematician
17:05:38 <shapr> bringert: Sounds creative
17:05:42 <Pseudonym> That's the book we're talking about.
17:05:59 <lscd> ahh, thanks; i found the person, but i had no idea what book was meant
17:06:17 * _frederik_ goes back to writing
17:06:36 <bringert> anyway, it seems to work now
17:06:36 <Pseudonym> One central problem with most category theory texts is that they are "category theory for the person who's already an expert in field X".
17:06:51 <Pseudonym> Which rules out most of the world, despite category theory being quite simple when you get down to it.
17:07:09 <Pseudonym> Barr & Wells is one of the few exceptions.
17:07:33 <Pseudonym> And "Conceptual Mathematics" even makes it accessible to a smart high school student.
17:07:39 <Pseudonym> Though it doesn't go into great depth.
17:08:17 <lscd> i'd probably better start with conceptual mathematics
17:08:24 <lscd> math-wise, i'm in the high school student category, unfortunately
17:08:29 <Pseudonym> :-)
17:08:36 <Pseudonym> A useful thing about that book is it's very gentle.
17:08:37 <lscd> i'm doing a very low-on-math degree in CS atm
17:08:54 <Pseudonym> So it'll drum the basic ideas into your brain without overloading it.
17:09:09 <lscd> overloading is ok; haskell overloads my brain frequently
17:09:22 <Pseudonym> Then you'll actually REMEMBER what half these terms mean when you get to a more advanced book.
17:09:59 <lscd> but having no idea what's going on because i have no idea about 3 levels of prerequisites is more of a pain (i'm happy to learn; but unfortunately, my knowledge is still pretty limited)
17:10:06 <lscd> yeah; that can help a lot
17:11:51 <lscd> any knowledge of "'Arrows, Structures and Functors: The Categorical Imperative'" ? someone on amazon suggested it instead of 'categories for the working mathematician' for people who knew less math already
17:12:11 <Pseudonym> No idea, but I like the title.
17:12:33 <ihope> "IInterInterInterInterInterInterInterInter...InterInterInterrupted."
17:12:38 <ihope> GHCi shouldn't do that.
17:12:45 <SamB> indeed not
17:13:06 <SamB> unless it is experiencing recursive interruptions
17:13:11 <shapr> bringert: Truly, cabal-get will make Hope easier to build.
17:13:19 <bringert> it sure will
17:14:12 <bringert> shapr: do you have any build instruction updates?
17:15:18 <shapr> Nah, just iterate darcs get and install
17:16:02 <shapr> Where's the HSQL repo?
17:16:37 <bringert> SourceForge CVS: cvs -z3 -d:ext:developername@htoolkit.cvs.sourceforge.net:/cvsroot/htoolkit co -P HSQL
17:16:42 <shapr> oh yeah
17:16:54 <bringert> or anonymous
17:18:39 <shapr> Hm, no route to host cvs.sourceforge.net
17:18:44 <shapr> That's frustrating.
17:19:01 <shapr> Does HaskellDB work with CosmicRay's HDBC?
17:19:03 <ihope> unsafeCoerce# (unsafeCoerce# "foo") -- heh heh
17:19:12 <bringert> shapr: yes, it should
17:19:42 <bringert> I think that the HDBC SQLite3 backend has problems with date types
17:19:45 <Pseudonym> Has anyone read "Sheaves in Geometry and Logic"?
17:21:12 <shapr> It's 2:30am, I've run out of steam. I'll finish building Blob & Hope tomorrow.
17:21:22 <Pseudonym> Night.
17:21:22 <bringert> :-)
17:21:26 <bringert> good night
17:21:38 <bringert> we need cabal-get
17:26:22 <dons> moin
18:02:58 <bringert> morning dons
18:12:35 <lscd> how do I wrap a function in an IO monad?  I'm trying to write a function that returns something of type  IO StdGen; getStdGen returns this type, but mkStdGen yields something of type StdGen; I'd like to be able to return IO StdGen in either case
18:13:29 <dons> return mkStdGen ?
18:13:48 <dons> ?type return
18:13:49 <lambdabot> forall (m :: * -> *) a. (Monad m) => a -> m a
18:14:26 <lscd>  Ambiguous type variable `m' in the constraint:
18:14:27 <lscd>       `Monad m' arising from use of `return'
18:14:40 <dons> you want to constraint it to IO
18:14:43 <lscd> trying to make it be an IO monad, not just some monad, is what's confusing me
18:14:50 <Igloo> In a real program it should infer it
18:15:45 <dons> Prelude System.Random> :t return (mkStdGen 99) :: IO StdGen
18:15:46 <dons> return (mkStdGen 99) :: IO StdGen :: IO StdGen
18:16:25 <dons> lscd: is that what you're looking for? (and Igloo correctly points out that you wouldn't need the type annotation in a real program, ghci needs it though)
18:16:51 <lscd> that's what I'm looking for; thanks -- now I just need to get it working in my 'real program'
18:22:56 <lscd> hm. i should probably be using a maybe monad - i'm trying to conditionally either use getStdGen or mkStdGen, depending on whether or not the program arguments included a seed
18:23:34 <Igloo> I doubt you want to use Maybe as a monad
18:24:04 <Lemmih> fn (Just num) = return (mkStdGen num); fn (Just seed) = getStdGen?
18:24:06 <Igloo> You might want to have a Maybe Seed, depending on whether the argument parsing and generator creation are far apart or not
18:24:24 <lscd> Igloo: ah... oops. yep, i was confused there
18:24:25 <Igloo> YM Nothing in the second case, presumably?
18:24:41 <Igloo> But yes, that's just using Maybe as a datatype, not as a monad
18:25:01 <lscd> yeah... most recent uses of Maybe I've seen have been as a monad (don't ask....) and it's 3am
18:25:15 <Igloo> :-)
18:26:17 <Lemmih> @type maybe getStdGen (return.mkStdGen)
18:26:18 <lambdabot> Maybe Int -> IO StdGen
18:31:57 <bolrod> :)
18:33:07 <lscd> when in doubt, stop fighting haskell
18:33:51 <lscd> i just managed to write an apparently-working getSeed function, which returns Maybe Int; i think things'll be a lot cleaner now
18:34:34 <lscd> trying to read on aListOfStrings[0] was giving me really bogus type inferences; i was probably trying to do it wrong
18:36:18 <Igloo> You probably meant aListOfStrings !! 0, or equivalently, head aListOfStrings
18:36:59 <lscd> ah-hah; yes, you're right
18:37:14 <lscd> i keep falling into c-style syntax in a few languages which don't use it at all
18:37:17 <mauke> <+GumbyBRAIN> id :: forall a. (A) -> a; id(x) = { x } <- the problem with people making typos, or people in parliament.
18:37:30 <lscd> i puzzled out why != wasn't working for about 5 minutes a couple of hours ago before i remembered it was /=
18:38:00 <lscd> oh well; the approach i'm using now is a lot cleaner anyhow, so using the wrong syntax with the wrong approach wasn't a total loss
18:43:36 <bolrod> OmG
18:43:41 <bolrod> it's getting light again!
18:43:49 <bolrod> I can see light on the horizon
18:45:06 <bolrod> it's only 3:44 ffs!
18:46:12 <palomer> sage looks cool
18:47:41 <lscd> bolrod: well, you're pretty far north; in switzerland, it's still dark
18:47:49 <bolrod> yeah
18:47:54 <bolrod> you have mountains
18:47:55 <bolrod> tooo
18:47:57 <bolrod> ;)
18:47:59 <lscd> that too, yeah
18:48:00 <bolrod> I'm in the netherlands
18:48:05 <lscd> i know, i /whois'd you
18:48:12 <bolrod> ah :)
18:48:36 <bolrod> it's getting light REALLY REALLY ! fast
18:48:36 <lscd> goedemorgen :)
18:48:40 <bolrod> hehe :)
18:48:49 <bolrod> I mean...  just 4 minutes ago.. it was much darker
18:48:53 <lscd> yeah
18:49:07 <lscd> it's amazing how it does that
18:49:11 <bolrod> yeah :)
18:49:18 <bolrod> man... I hope it gets warmer at night
18:49:25 <lscd> hmm?
18:49:28 <bolrod> so I can go cycling in the night :P
18:49:34 <bolrod> it's so nice :)
18:49:36 <lscd> ahhh; yeah, that'd be cool
18:49:44 <bolrod> last year I went cycling ..
18:49:50 <lscd> i've pretty much quit cycling - it's too mountainous here
18:49:52 <bolrod> and I got to the sea when the sun was rising
18:49:54 <bolrod> so nice :)
18:50:00 <mauke> data DL a = E | N a (DL a) (DL a); manyDL p = do {x <- p; f <- manyDL p; return (\prev -> let this = N x prev (f this) in this)} <||> return (const E)
18:50:03 <lscd> yeah; the seaside at sunrise is beautiful
18:50:13 <bolrod> and the colors are so different in the mornting then during the day
18:50:14 <bringert> bolrod: hate to rain on your parade, but it's normally cooler at night :-P
18:50:23 <bolrod> it's like there is more contrast... or warmer colors
18:50:25 <lscd> yeah
18:50:42 <lscd> bringert: so, we need a temperature monad?
18:50:52 <bolrod> ;)
18:51:07 <bringert> make it a monad transformer and I'm in
18:51:13 <lscd> okdokie
18:51:20 <bolrod> hmm... last few days I didn't have alot of sleep ... I think
18:51:34 <bolrod> well.. I slept a bit during the day
18:51:38 <bolrod> which is yesterday already
18:52:47 <bolrod> seriously... some days ago.. it wasn't getting light until 4:15 or something
18:55:27 <lscd> yeah; it was a bit like that when i lived in canada
18:55:55 <bolrod> :)  this is why I like summer :P
18:55:59 <bolrod> long days
18:56:23 <bolrod> I like it when it gets dark after 22:30 or something
18:57:40 <lscd> hmm. how can I find out what the seed of a random number generator is, when I just have the random number generator?
18:58:06 <dons> lscd, do you have the System.Random docs in front of you?
18:58:12 <dons> ?docs System.Random
18:58:12 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/System-Random.html
18:58:25 <bolrod> yo dons 
18:58:33 <lscd> I do; none of the functions there look obviously like what I'm looking for
18:58:33 <dons> hey bolrod 
18:58:44 <lscd> i'm still quite poor at reading the Haskell docs though, so I might just be missing it
18:58:46 <bolrod> do you know about some weird error during the test of ByteString on OSX?
18:58:54 <dons> lscd: it may not make sense to find the seed, after constructing the random gen.
18:59:01 <dons> bolrod: no. do tell..
18:59:11 <lscd> dons: yes; I suppose that's what I should have asked
18:59:24 <lscd> if it doesn't, I need to rethink the whole approach I'm taking fairly drastically
18:59:31 <bolrod> dons: in the tests dir I do  `make`  right?
18:59:39 <dons> bolrod: yep. 
18:59:46 <dons> as long as you have 'runhaskell' installed
19:00:18 <bolrod> yes.. it runs fine for quite a while
19:00:32 <bolrod> and then stops and gives an error about some file or library being out of datye
19:00:33 <bolrod> date*
19:00:45 <dons> what's the exact error?
19:00:49 <bolrod> I'm running the test now...  lets see what it says
19:00:57 <bolrod> I don't know exactly ;)   I'll have to see in a moment
19:01:25 <bolrod> I didn't have it on my linux box
19:01:41 <bolrod> it's the darcs pull... I already hat this error with a previous version
19:02:53 <bolrod> I wouldn't need root to run the tests by chance?
19:03:02 <dons> what do you mean 'its the darcs pull'?
19:03:02 <bolrod> though I think it wouldn't make any difference
19:03:05 <bolrod> yes
19:03:12 <dons> no need to run as root
19:03:18 <bolrod> I pulled the source with darcs
19:03:21 <bolrod> from you ;)
19:03:29 <dons> you can run the tests yourself, with 'ghci Properties.hs" then type 'main'
19:03:44 <bolrod> I just ran  make
19:04:08 <bolrod> and it runs the first tests quite well
19:04:44 <dons> ok. i'll need the precise error, to move forward on this.
19:05:46 <bolrod> I'm stil waiting on it :D
19:06:44 <bolrod> ah.. now it started compiling some things after alot of tests
19:06:52 <bolrod> it 'should' pop up any moment now
19:08:14 <bolrod> @where paste
19:08:15 <lambdabot> http://paste.lisp.org/new/haskell
19:08:57 <lisppaste2> bolrod pasted "error" at http://paste.lisp.org/display/20852
19:09:12 <bolrod> that's it
19:09:38 * dons looks
19:10:38 <dons> run ranlib on /f/g/lib/fps-0.7/libHSfps-0.7.a
19:10:42 <dons> its a mac os isue
19:10:44 <dons> issue.
19:11:53 <bolrod> hmm..
19:12:15 <bolrod> if it knows what to do.. why doesn't it just do it itself :p  
19:12:30 <dons> you just need to build the symbol table (i think newer cbals might do this for you)
19:29:53 <dons> bolrod: did that clear things up?
19:30:10 <mnvl> hi there, does anyone know what haskell library a module Data.Graph.Automorphism came from?
19:30:20 <bolrod> yep
19:30:21 <bolrod> :)
19:32:33 <dons> mnvl: from the new graph automorphism library?
19:32:45 <dons> I think its mentioned on the haskell.org front page (or recent news)
19:34:14 <bringert> has anyone gotten parallel programs compiled with ghc 6.5 to actually use more than one core?
19:34:24 <dons> bringert: simon m has.
19:34:27 <mnvl> great thanx i think that's the one dons 
19:34:31 <bringert> :-)
19:34:36 <bringert> anyone mortal?
19:34:46 <dons> i should try this one day.
19:34:59 <dons> bringert: have you looked at the smC pwiki page?
19:35:01 <dons> smp
19:35:13 <bringert> I've only seen this: http://www.haskell.org/haskellwiki/GHC/Concurrency
19:35:44 <dons> i think there's another one. let me see...
19:36:04 <dons> oh, that's the one
19:36:17 <dons> so, you've got a ghc that support smp?
19:36:25 <dons> and compiled with -thredaed
19:36:29 <bringert> darcs from yesterday
19:36:31 <bringert> yep
19:36:35 <bringert> and I use -N2
19:36:36 <dons> and using  +RTS -N2 
19:36:38 <dons> for e.g. two threads
19:36:52 <dons> and using forkIO
19:36:59 <bringert> yep. I'm on OS X though
19:36:59 <dons> what does  +RTS -sstderr  say?
19:37:04 <dons> oh. hmm.
19:37:48 <bringert> it lists 4 tasks, 3 of which seem to use CPU time
19:38:14 <bringert> maybe I should boot to linux
19:38:34 <dons> might be worth checking
19:38:38 <bringert> that's one thing my ubuntu-in-a-VM can't do, use both cores
19:40:27 <bringert> see you on the other side
19:46:35 <bringert> I forgot that I've never actually used the real Linux installation on this machine
19:46:46 <bringert> it's in a pretty sad state
19:52:14 <mnvl> sorry to repeatedly ask this kind of question, but making that library choked when it couldn't find Data.Trie - which is in the hierarchical list as haskell.org..
19:52:22 <mnvl> isn't* in
19:54:34 <mnvl> can anyone tell me what i'm missing now?
19:58:23 <dons> i'm not sure where Data.Trie lives. Edison perhaps?
19:58:26 <dons> ?google Data.Trie
19:58:28 <lambdabot> http://backpan.perl.org/authors/id/H/HA/HAMMOND/data-trie-0.01.readme
19:58:36 <dons> ?google Data.Trie Haskell
19:58:38 <lambdabot> http://cvs.haskell.org/trac/ghc/ticket/721
19:58:47 <dons> ?google Data.Trie .hs
19:58:49 <lambdabot> http://homepages.cwi.nl/~jve/demo/DPLL.hs
19:59:04 <dons> mnvl: does the code you're using list its dependencies somewhere?
19:59:19 <mnvl> no
19:59:32 <dons> can you ask the author?
19:59:40 <mnvl> possibly..
19:59:53 <mnvl> i did google for this file as well :)
20:00:00 <dons> :)
20:00:02 <mnvl> thx anyway
20:00:55 <Cale> http://darcs.haskell.org/packages/collections/
20:01:03 <dons> ah, yes, collectoins
20:01:14 <dons> morning Cale.
20:01:53 <Cale> hehe
20:01:58 <Cale> morning dons :)
20:02:06 <mnvl> hi Cale 
20:02:26 <Cale> hello
20:05:54 <goltrpoat> #ocaml is dead again.  anyone know if it has forward declarations?
20:06:29 <goltrpoat> i mean 'it' as in ocaml
20:06:31 <dons> #ocaml is dead, long live #haskell!
20:06:46 <goltrpoat> hehe
20:07:41 <palomer> ocaml had potential; too bad it's french
20:07:50 <Cale> goltrpoat: what do you mean by forward declarations?
20:08:07 <goltrpoat> actually, if anyone here knows any ocaml, how do i declare a bunch of functions that ultimately form one big recursive function?  eg f = g, g = h, h = i, i = f
20:08:43 <Cale> letrec?
20:08:46 <goltrpoat> nah
20:09:06 <Cale> no?
20:09:06 <goltrpoat> let rec f = g followed by let rec g = f doesn't typecheck (g is undeclared in the first definition)
20:09:29 <Cale> can you put both declarations in the same letrec?
20:09:59 <Cale> (I really should look at O'Caml more closely at some point :)
20:10:00 <goltrpoat> yes, using the 'and' syntax.  but then it complains about the fact that i defined a recursive function using the 'and' syntax
20:10:07 <Cale> ugh
20:10:09 <goltrpoat> this is F#, not ocaml proper, so i'm not fully sure what i'm doing
20:10:47 <goltrpoat> i mean, i'd be quite unsure what i'm doing even if it were ocaml proper, but i can't tell what's F#-specific and what isn't
20:11:25 <goltrpoat> i get.. "This value will be eventually evaluated as part of its own definition. You may need to make the value lazy or a function. Value 'expr' will evaluate 'term' will evaluate 'expterm' will evaluate 'factor' will evaluate 'expr'"
20:11:28 <goltrpoat> heh
20:11:39 <goltrpoat> and i'm like.. yeah, that's the point
20:12:13 <cmarcelo> if i create "class Enum a => MyClass a", every type which derives Enum will "have instance"? Or is it necessary to do a "instance MyClass x" for each type x (which derives Enum)?
20:13:04 <lispy> cmarcelo: if you type that you are requiring that all instances of MyClass are also instances of Enum
20:13:51 <lispy> but it's still up to the programmer to make sure that they are in fact instances of Enum, otherwise the type checker will complain
20:14:39 <cmarcelo> i understand. but once being a Enum it will be a MyClass automatically too?
20:15:01 <lispy> no
20:15:29 <Cale> goltrpoat: hmm, everything I'm seeing seems to support the case that mutual recursion with 'and' ought to work
20:16:14 <cmarcelo> hmm.. is it possible then to "class MyClass" and then create an "default" instance for Enum types... like: "instance Enum a => MyClass a"...? if yes, this instance could be overloaded by specific implementations?
20:16:15 <palomer> let rec f () = g () and g () = f () ;;
20:16:32 <palomer> in fact, rec isn't needed
20:17:29 <lispy> cmarcelo: you can provide default implementations of the functions in a class, then for someone to create an instance of a type class they only need to provide a definition for functions which don't have a default
20:17:56 <palomer> let rec f () = g () and g () = h () and h () = f ();;
20:18:07 * palomer wonders why people still use ocaml
20:18:18 <palomer> then again, the alternatives aren't so pretty
20:20:29 <cmarcelo> lispy: well. I have default implementation only for Enum classes, but wanted MyClass not to be restricted to Enum types. I think this isn't possible then?
20:23:25 <lispy> cmarcelo: well, by your definition any 'a' which satisfies MyClass a is an Enum a also
20:23:35 <lispy> cmarcelo: so you should be okay to assume properties of Enum
20:24:36 <goltrpoat> palomer:  it's F#..  i don't know of any other fp language that plays nice with .net
20:24:43 <goltrpoat> or well.. *that* nice anyway
20:27:05 <cmarcelo> lispy: consider my last question again, but ignoring that definition where MyClass \subset Enum. think of a "class MyClass" only.
20:27:10 <lispy> i wouldn't mind the lack of FP .NET langs if haskell supported COM
20:27:15 <palomer> more like F#&%
20:27:47 <Korollary> com & .net are quite separate afaik
20:27:48 <goltrpoat> palomer:  that worked, thanks..  combined it with smerdyakov's suggestion from #ocaml and added a unit argument to the relevant functions
20:28:08 <palomer> right
20:28:11 <palomer> values can't be recursive in ocaml
20:28:24 <palomer> it doesn't make any sense in a strict language to have recursive values, you see
20:28:31 <lispy> Korollary: yeah, but for me at work the terms of interchangable because the COM aspect of .NET is all we make use of
20:28:52 <Korollary> argh
20:28:57 <lispy> terms of/terms are
20:28:58 <goltrpoat> palomer:  yeah, that's what the #ocaml guy said as well :)
20:29:01 <palomer> http://www.lfcs.inf.ed.ac.uk/research/dotnetlab/talks.html <--- sml.net
20:29:25 <palomer> though F# is probably just as good
20:29:47 * palomer has had the most unproductive weekend, ever
20:29:55 <goltrpoat> palomer:  oh cool, thanks.. i'll check that out
20:30:21 <palomer> and H# might come out; some day.
20:30:33 * palomer feels .net too real world for haskell
20:31:05 <Korollary> Hejlsberg says .net is too real world for F# as well
20:31:43 <goltrpoat> korollary:  in what sense?
20:32:07 <Korollary> goltrpoat: I asked him whether there was a possibility that f# could become an official part of visual studio...
20:32:46 <Korollary> "No."
20:32:53 <palomer> don't blame'em
20:33:08 <Korollary> blame da playa
20:33:26 <goltrpoat> what does hejlsberg have to do with f#?  i thought he was the c# lead
20:34:12 <Korollary> He doesn't have anything to do with it.
20:34:20 <goltrpoat> oh
20:34:26 <goltrpoat> why is he being so authoritative on that then
20:34:27 <goltrpoat> hehe
20:34:45 <Korollary> he is in an authoritative position in general
20:34:51 <goltrpoat> ah
20:35:03 * palomer sounds the word non-existence alarm
20:35:20 <Korollary> which word?
20:35:42 <palomer> authoritative
20:35:50 <goltrpoat> i can authoritatively say that authoritative is a word.
20:36:00 <Korollary> http://m-w.com/cgi-bin/dictionary?va=authoritative
20:36:17 <palomer> oh, you're right
20:36:34 <palomer> that's nuts!
20:36:43 <palomer> it defies logic!
20:36:47 <palomer> @palomer
20:36:47 <Korollary> drives a Quebecois nuts, eh?
20:36:47 <lambdabot> Pfft
20:37:02 <palomer> I'm quebecois only by birth
20:37:26 <palomer> I'm actually kryptonian
20:37:48 <palomer> and I was fathered by three different people
20:37:58 <palomer> one of which female
20:39:38 <Korollary> I see. So sex is determined by an Int32 in the kryptonian DNA?
20:43:47 <lscd> Int128 actually
20:45:19 <lscd> is anyone here willing to critique a short (139 line, including comments / whitespace) haskell program? it's the first one i write, and i'd be happy to hear any feedback on how i could write it more cleanly/better
20:45:48 <Lemmih> lscd: post it.
20:47:16 <goltrpoat> cool.  my first take at a parser combinator library in F# throws a stack overflow.
20:47:40 <lscd> http://pastebin.com/759050
20:47:47 <palomer> you're doing it wrong!
20:48:05 <lispy> goltrpoat: in my experience that means you need a base case
20:48:12 <lispy> *somewhere* :)
20:48:23 <goltrpoat> all valid suggestions, guys.
20:48:33 <goltrpoat> i'll try to add a base case and do the rest of it right.
20:49:01 <palomer> ok, if haskell.net can't release anything in 2.5 years, I think it's safe to assume that it's dead
20:49:38 <palomer> and why is everyone throwing their weight behind the visual studio.net plugin? what about the linux users? we have most of the brains, damnit!
20:49:56 <lispy> palomer: there are some real technical problems with truely supporting an FP langin the CLR.  I bet you could revive the project by using the F# specific CLR extensions
20:50:28 <Lemmih> haskell.org is way better than haskell.net, IMHO.
20:50:43 <goltrpoat> palomer:  we have brains too
20:50:45 <palomer> har har har
20:50:48 <goltrpoat> we keep them in jars
20:50:51 <lispy> palomer: who is throwing their weight behind it?  and since i want to use haskell at work and we use VS + windows it would be really nice for me :)
20:51:05 <goltrpoat> microsoft research is/was
20:51:24 <goltrpoat> i don't think there's a 2005 version though
20:51:28 <goltrpoat> 2003 is the latest it went
20:51:33 <lispy> yeah
20:51:42 <palomer> well, it seems to be the only thing that's being worked on in the haskell integrated development area
20:51:46 <lispy> but we haven't switched to 2005 yet so i didn't mind that yet either :)
20:51:57 <lispy> palomer: certainly not true
20:52:03 <lispy> palomer: eclipse fp is active
20:52:06 <goltrpoat> lispy:  http://www.haskell.org/visualhaskell/
20:52:08 <lispy> palomer: and hIDE is active
20:52:20 <goltrpoat> oh.. you said didn't mind, as in, you're aware of it
20:52:21 <goltrpoat> nevermind :)
20:52:23 <palomer> I thought hIDE was dead!
20:52:26 <lispy> goltrpoat: yeah, i know, i have it installed on two computers and was emailing simonm with bug reports last week :)
20:52:34 <goltrpoat> ah cool
20:52:51 <lispy> palomer: hIDE is infantile, but i doubt it's dead
20:53:21 <palomer> infantile in which sense?
20:53:25 <palomer> just-born?
20:53:27 <palomer> childish?
20:53:33 <goltrpoat> i remember hating eclipse with a passion while using it for java a while back
20:53:39 <palomer> inadequate?
20:53:40 <lispy> i couldn't do really simple COM examples using it...like staring an instance of MS Access gave me errors
20:53:52 <lispy> palomer: very new
20:53:59 <lispy> palomer: not yet to the alpha stage
20:54:17 <lispy> it's not really meant to non-devs yet.  iirc it's a real pain to build
20:54:20 <palomer> who took it back up?
20:54:32 <Lemmih> hIDE had a collision with some anti-time and has reversed to a state of pre-birth.
20:54:32 <lispy> Lemmih and dcoutts were working on it last i knew
20:54:32 <cmarcelo> lispy: (sorry, I didn't mean to be rude before =| ).. with "MyClass a" only (without supposing Enum), is possible to declare a default implementation only for Enum types? Or default implementation is only set in class declarations?
20:55:24 <lispy> cmarcelo: oh, i didn't notice any rudeness.  Um...I think we need to see examples of your code before we can help.  I'm basically confused at this point :)
20:55:50 * palomer isn't tolerating this rudeness!
20:56:08 <lscd> goltrpoat: same.... eclipse is pretty painful
20:56:58 <scsibug> lscd: I'm pretty new to haskell, so I don't have any critiques.  But your code did help me understand a couple things about handling command line arguments.. so thank you for that.
20:57:04 <cmarcelo> @paste
20:57:05 <lambdabot> http://www.haskell.org/hawiki/HaskellIrcPastePage
20:57:21 <lscd> scsibug: cool; i only learned how to deal with them about 6 hours ago :)
20:57:52 <lispy> lscd: my personal style would be to combine lines 14 & 15
20:58:37 <lscd> ah, my indentation was a bit different there; i put the do's on new lines so i wouldn't have to indent everything really far (at least everywhere else)
20:59:29 <scsibug> when I put the "do" on the same line as the function declaration, I only indent 2 spaces over on the next line...
20:59:44 <scsibug> you don't have to indent all the way to the "do"
21:00:03 <lscd> ahh, ok; i'm still getting the hang of haskell's indent rules; thanks
21:00:23 <lispy> lscd: in getYN you might want to return a 'canonical' representation of what the user typed
21:00:34 <lispy> lscd: for example, you could lowercase it everytime
21:00:36 <lscd> mm. good point. 
21:00:37 <lscd> yeah
21:00:45 <lscd> i generally do that; i guess i just wasn't thinking when i wrote that part
21:01:11 <lispy> lscd: also instead of `elem` ['Y', 'y', 'N', 'n'] you could say, `elem` "YyNn"
21:01:26 <lispy> lscd: obvisouly i'm picking nits, but i think that's what you wanted :)
21:01:30 <lispy> it looks really good so far
21:01:43 <lscd> yes, it's what i wanted; thanks ^-^
21:01:52 <SamB> yeah, when I find myself not thinking, I tend to stop trying to program, and read webcomics or play games instead ;-)
21:02:16 <lscd> SamB: yeah, yeah ... ;)
21:02:22 <sam_> lscd, looked pretty good to me.. i wish there were more 'real' small progs, like yours, to look & learn from..
21:02:35 <lscd> i was struggling with the haskell side of it and let good design slip by a couple of times :)
21:02:41 <lispy> lscd: you could also generalize what you're doing in getYN to be getYN :: String -> IO Response, and then data Response = Affirmative | Negative
21:02:43 <lscd> sam_: yeah.... i wished for the same for ages
21:03:07 <sam_> ..that is, programs that actually need to deal with errors, io, etc real world concerns, instead of just doing simple functional stuff
21:03:12 <SamB> lispy: wouldn't it make more sense to use Bool?
21:03:12 <lispy> lscd: then you could cehck for "yes", "no", "oh yeah!", "sure"
21:03:43 <SamB> lispy: okay, that is just plain ridiculous
21:03:44 <lscd> hmm... i'd tend to say that that's overgeneralization, but i see your point
21:03:56 <lispy> SamB: bool would work fine and you could just use the result in an if statement...OTOH, having it return Yes or No or something like that might help self document
21:04:34 <SamB_XP> lispy: Am thinking that True is close enough to Affirmative that it would not be a problem!
21:04:41 <lispy> yeah
21:04:55 <goltrpoat> i'd merge guessWrong and guessCorrect into checkGuess
21:05:50 <lispy> i was thinking about that too
21:05:55 <lispy> i'm not sold on it though
21:06:00 <lscd> goltrpoat: my personal tendency is to make functions _really_ small; for guessCorrect, i'd almost agree, but by the time you're merging in guessWrong it starts to seem a bit unbalanced
21:06:03 <cmarcelo> lispy: http://rafb.net/paste/results/mB61F025.html
21:07:40 <lispy> cmarcelo: mm...are lines 13&14 invalid?  i actually can't remember if i've tried that
21:07:46 <Cale> cmarcelo: how does it decide which instance to use?
21:08:00 <Cale> yeah, they're invalid without undecidable instances
21:08:44 * SamB_XP thinks it is funny that someone would want to pay $300 to get a rat treated for cancer
21:08:55 <Cale> You might even need more than that, I'm not completely sure
21:10:16 <lispy> SamB_XP: yeah
21:12:07 <cmarcelo> Cale: The GHC flag doesnt seem to be enough. It could choose the most specific, or the problem (decide instance to use) is bigger than I'm seeing?
21:13:00 <Cale> It's quite complicated.
21:13:12 * SamB_XP wonders what would be a really really low overhead interface to notify the kernel of pages which you don't want back (because they are consumed portions of buffers, or have been evacuated, or whatever)
21:14:36 <stepcut> SamB_XP: free()
21:14:38 <stepcut> ;)
21:14:50 <lispy> free is actually kinda costly :)
21:14:56 <SamB_XP> stepcut: silly!
21:15:08 <stepcut> lispy: i know :(
21:15:20 <Cale> cmarcelo: Typeclasses can have multiple type parameters
21:15:23 <SamB_XP> stepcut: that would actually touch memory!
21:16:01 <Cale> and getting a good definition of "most specific" is quite hard.
21:16:15 * SamB_XP is thinking maybe some kind of bitmap stuck somewhere that the kernel would look at whenever it got the chance
21:16:19 <Cale> You also have the problem that what if a future module comes along with a more specific instance?
21:16:32 * SamB_XP is *not* serious about this
21:16:40 <Cale> Then you might have compiled code against the more general instance already.
21:16:49 <goltrpoat> you know.. i just realized something.  perhaps constructing an infinite tree of parsers in an eager language isn't the best idea.
21:17:12 <Cale> So you could end up with unexpected semantics there
21:17:18 <SamB_XP> (Meaning, I'm not going to *do* anything about it. Not that I am joking ;-)
21:17:27 <Cale> goltrpoat: hehe
21:17:30 <SamB_XP> goltrpoat: perhaps not!
21:18:07 * SamB_XP isn't even sure that is a good idea in a lazy language!
21:18:55 <cmarcelo> Cale: thanks.
21:19:01 <lispy> SamB_XP: a stream or the lazy module :)
21:19:14 <lispy> er
21:19:29 <lispy> goltrpoat: use a stream or the lazy module
21:20:16 <lispy> goltrpoat: why did you choose ocaml?
21:20:24 <SamB_XP> what language are you talkin 'bout, anyways?
21:21:05 <goltrpoat> yeah i'm going to sprinkle lazy all over the place and see how that works out
21:21:15 <goltrpoat> it's F#.. been playing around with it for a couple of days
21:21:23 <goltrpoat> decided that porting hutton's paper to it would be a good first project
21:22:16 <goltrpoat> in retrospect, that was a pretty dumb idea, but it's basically ported, minus the whole not running bit
21:22:26 <lispy> goltrpoat: i think someone once told me that lazy code in ghc is optimized much better than ocaml (which probably applies for the F# compiler too)
21:22:32 <stepcut> SamB_XP: perhaps what you want is for the kernel to let each application do its own memory managemet ?
21:22:51 <goltrpoat> lispy:  yeah, it seems to be a bit of an afterthought in ocaml
21:22:55 <SamB_XP> stepcut: nah.
21:23:10 <SamB_XP> you don't want to actually write the swapper, after all!
21:23:29 <stepcut> SamB_XP: well, that could just be a library 
21:24:01 <SamB_XP> anyway, the point of my idea is to avoid having to do a syscall ;-)
21:24:28 <stepcut> SamB_XP: well, if it's in user-space -- no syscall needed ;)
21:24:54 <SamB_XP> well, how are you supposed to actually do memory management without syscalls?
21:25:35 * SamB_XP does not want to think that hard
21:25:39 <stepcut> heh
21:25:49 <SamB_XP> and I doubt Linux would permit that sort of thing
21:25:59 <goltrpoat> cool.  Lazy.force_val( (Lazy.lazy_from_fun (*)) 2 3 );; seems to confuse the interactive shell to no end.
21:28:54 <SamB_XP> > 2^32 / 4096 / 32
21:28:55 <lambdabot>  32768.0
21:29:31 <wimp> hmm
21:29:33 <wimp> linspire using haskell
21:29:35 <wimp> is this for real?
21:29:37 <wimp> or some sick joke?
21:29:42 <stepcut> wimp: both?
21:29:55 <wimp> how is it a sick joke?
21:29:56 * SamB_XP remembers that there are 8 bits in a byte
21:30:03 <skew> well, they're talking about it across the street from me this thursday
21:30:05 <SamB_XP> > 2^32 / 4096 / 8
21:30:06 <lambdabot>  131072.0
21:30:14 <stepcut> wimp: dunno, you started it...
21:30:28 <wimp> I was hoping someone here could enlighten me on this random article I read
21:30:36 <dons> wimp, hehe. well, pick a language safer, more maintainable, and faster, than sh or perl scripts..
21:30:45 <stepcut> wimp: what would you like to know ?
21:30:55 <goltrpoat> skew:  there was a link to the announcement on LtU
21:31:19 <wimp> stepcut, is P == NP?
21:31:35 <skew> see also here http://www.sgvlug.org/
21:31:43 <SamB_XP> dons: well, Python might be at least more maintainable ;-)
21:32:20 <dons> ok, it gets 1 out of 3 then. commendable ;)
21:32:21 <skew> SamB_XP: but we all know you get to pick two out of three! Like faster, better, cheaper.
21:32:48 <stepcut> SamB_XP: maybe the Linspire programmers don't know Python ?
21:33:01 <dons> oh this is too funny. bad stepcut
21:33:12 <SamB_XP> stepcut: I really expect they do know python ;-)
21:33:30 <SamB_XP> and PYthon might be safer than shell, at least
21:34:42 <skew> or perl, for that matter
21:35:49 <stepcut> skew: do you mean python is safer than perl ? or that perl is safer than shell ? (or perhaps both...)
21:36:04 <SamB_XP> well, yes, I suppose you can do a lot more implicit coertion in Perl than in Python...
21:36:21 <lisppaste2> sam_ pasted "mapping exceptions" at http://paste.lisp.org/display/20860
21:36:25 <sam_> Could someone take a look at the paste, and tell how I could make the 'outerFun' act the way I want in a simpler manner.
21:36:25 <Cale> wimp: what would you like to know?
21:36:36 <Cale> wimp: Haskell is a perfectly reasonable programming language
21:36:55 <stepcut> it is the finest imperative language today, after all
21:37:01 <Cale> hehe
21:37:04 <dons> quite so!
21:37:09 <Cale> wimp: I see no reason why they couldn't use it.
21:37:31 <SamB_XP> it is certainly the only language I know which treats imperatives as first-class entities!
21:38:07 <SamB_XP> and as an added bonus, you can have higher-order, overloaded imperatives!
21:38:32 <goltrpoat> with cheese!
21:38:54 <SamB_XP> yes, with cheese!
21:39:09 <SamB_XP> wait, wait, how do you put cheese on a monadic computation?
21:39:21 <stepcut> what's python got? Run-time type errors -- who needs that ?
21:39:26 <goltrpoat> with CheeseT.
21:39:57 <SamB_XP> stepcut: I know! even worse! run time name errors! (for attribute access)
21:40:10 <goltrpoat> which, needless to say, transforms the result of a computation into cheese.
21:40:14 <SamB_XP> but it Perl has the same, hasn't it?
21:40:20 <stepcut> plus if you want to put a python script in the initial ram disk, you gotta stick a whole interpreter in there
21:40:24 <SamB_XP> and Shell hasn't even types!
21:40:36 <stepcut> shell has no modules either -- sucks for code reuse
21:40:51 <jer> SamB_XP, the shell isn't a real programming language
21:41:26 * stepcut has seen a webserver written in shell...
21:41:48 <jer> stepcut, i doubt it.. gnu awk, perhaps; sh, no
21:42:29 <SamB_XP> jer: oh really?
21:42:55 <SamB_XP> jer: I can easily imagine a VERY INSECURE webserver written in shell
21:43:05 <jer> SamB_XP, please, demonstrate
21:43:36 <stepcut> http://home.eol.ca/~parkw/httpd.sh
21:43:37 <jer> i'd be particularly curious how you handle sockets without resorting to a third party tool like netcat
21:43:51 <SamB_XP> well, it would add a directory containing some things called GET, HEAD, POST, etc. to the PATH...
21:43:55 <stepcut> SamB_XP: probably wouldn't have a bunch of buffer overflows :)
21:44:04 <stepcut> jer: inetd
21:44:29 <jer> stepcut, again, that's a third party tool.
21:44:41 <SamB_XP> jer: so?
21:44:44 <stepcut> jer: well, I'd like to see apache handle tcp/ip without the kernel
21:44:46 <SamB_XP> so is true, for all you know!
21:45:16 <jer> stepcut, that's not a third party tool though; apache exists as a child process under the kernel
21:45:29 <SamB_XP> sure it is!
21:45:45 <stepcut> jer: whatever. running things from inetd is a time-tested method of invoking servers
21:46:09 <jer> stepcut, i know, it's also a time tested way of getting yourself lots of security headaches
21:46:15 <stepcut> jer: ;p
21:46:17 <jer> that wasn't what i was talking about however
21:46:18 <SamB_XP> Intel made the CPU, and ASF made Apache, and Linus, as we all know, wrote the kernel single-handedly!
21:46:42 <lispy> heh
21:46:55 <lispy> no way, i reported a bug once so i helped!
21:47:01 <stepcut> jer: http://thesmithfam.org/blog/?p=21
21:47:10 <lispy> ...although it turned out the bug was with my power supply not the kernel...
21:47:24 <SamB_XP> lispy: I am clearly not even lying, that last statement was so far from the truth ;-)
21:47:25 <goltrpoat> http://www.dbforums.com/archive/index.php/t-722892.html
21:47:33 <jer> stepcut, that's not portable
21:47:36 <jer> stepcut, but okay
21:48:25 <Cale> goltrpoat: mbot used to be written in bash :)
21:48:40 <goltrpoat> why do people do that to themselves
21:48:41 <goltrpoat> hehe
21:48:50 <SamB_XP> Cale: but you rewrote it in SED, right?
21:49:00 <Cale> SamB_XP: no, it's a lambdabot now
21:49:27 <SamB_XP> well, somebody tried to do a bot in sed the other day ;-)
21:49:27 <goltrpoat> it's like.. here, i know, i'm going to write a paint program in APL
21:49:36 <Cale> though I did actually use sed in the bash version
21:50:03 <Cale> It was basically one long pipeline with the ends tied together by a fifo
21:50:40 <SamB_XP> oh, that sounds remarkably similar to what this IRC bot was supposed to do
21:50:43 <Cale> wimp_: er, welcome back?
21:50:48 * SamB_XP didn't understand it, however
21:51:11 <Cale> bash can be quite nice if you don't use any of its imperative features
21:51:27 <stepcut> and if you enable, pipefail
21:51:42 <jer> Cale, it's even nicer if you ignore it completely =]
21:51:53 <Cale> jer: hehe
21:52:35 <sam_> Need help with Errors. Please :-)  http://paste.lisp.org/display/20860
21:53:07 <Cale> It's sort of like writing a lazy list processor using other programs in your chain of compositions
21:53:41 <Cale> sam_: use catchError?
21:54:06 <SamB_XP> Cale: oh, don't tease so!
21:54:37 <sam_> cale, i don't see how catchError would help here
21:54:38 <SamB_XP> @localtime sam_ 
21:54:39 <lambdabot> Local time for sam_ is Mon Jun  5 00:58:52
21:54:49 <stepcut> and then, of course, you can use h4sh to make bash even more functional ;)
21:55:34 <Cale> yeah, it would have been nice to have h4sh handy when writing it :)
21:55:53 <SamB_XP> sam_: same time zone as me!
21:56:07 <sam_> samb, where abouts are you?
21:56:16 <jer> EDT by the looks of it
21:56:27 <SamB_XP> sam_: right west of Philadelphia
21:56:38 <Cale> sam_: you're catching the innerError and rethrowing outerError?
21:56:38 <sam_> long island, ny, here
21:56:48 <stepcut> in my experience, given enough time, any useful shell script will grow large enough that you wish you had written it in a real language :)
21:56:57 <Cale> stepcut: true :)
21:57:04 <dons> stepcut: yeah, that's my experience too.
21:57:05 <lscd> stepcut: unless it's something so short you may as well have used alias, ya
21:57:11 <Cale> well, almost true, yeah
21:57:29 <Cale> there's sleeptil, which is a shellscript I still use
21:57:30 <dons> and the OS boot script writer's experience too, I suspect.
21:57:39 <SamB_XP> stepcut: so I guess you have to catch it before then, eh?
21:58:03 <dons> did I see a mentoin recently of a talk on improving the speed of the sh boot scripts in debian?
21:58:11 <SamB_XP> lscd: but aliases aren't spacial enough!
21:59:16 <stepcut> dons: yes -- various things like, using dash instead of bash, and stuf
21:59:30 <bringert> stepcut: are you guys going to start writing boot scripts in Haskell now?
21:59:43 <lispy> if i need an 8bit int what type should i use?
21:59:52 <dons> lispy: Word8 ?
21:59:55 <dons> there's no signed Word8
22:00:03 <dons> oh, maybe there is
22:00:04 <lscd> SamB_XP: true, true
22:00:09 <bringert> stepcut: I gave the hask-home program some source clean-up today, so if you are going to look at it, get the latest version
22:00:09 <dons> ?kind Data.Int.Int8
22:00:10 <lambdabot> *
22:00:13 <stepcut> bringert: probably not -- we use debian's for the most part.
22:00:13 <lispy> hmm...not sure if signed matters, but word8 should work, thanks
22:00:15 <SamB_XP> lispy: signed or not?
22:00:22 <stepcut> bringert: cool
22:00:25 <dons> so take your pick, Int8 or Word8
22:00:27 <SamB_XP> Either Int8 or Word8
22:00:37 <lispy> i think just byte is all, so i'll use Word8
22:00:46 <lispy> this is for a bf interpreter
22:00:53 <sam_> cale, yes..  in the 'real code', MyError and innerFun would be in a separate module. So, for better abstraction, outerFun would not want to throw Exceptions defined in another module, but it would still fail in the same cases as innerFun..
22:01:27 <SamB_XP> lispy: I've already written one of those, you know!
22:01:41 <SamB_XP> lispy: also, no, it does not matter which you use for a BF interp
22:01:43 <lispy> SamB_XP: but i haven't!
22:01:50 <lispy> @hoogle Word8
22:01:51 <lambdabot> Data.Word.Word8 :: data Word8
22:01:58 <stepcut> bringert: in general, our goal is to *not* diverge from debian when possible -- and we are attempting to submit more changes/tools back to help with that
22:02:05 <SamB_XP> well, unless the program tries to use high ascii, maybe ;-)
22:02:07 <lispy> Could not find module `Data.Word.Word8':
22:02:15 <bringert> stepcut: good plan
22:02:23 <lispy> why am i not finding Word8
22:02:42 <dons> Data.Word
22:02:53 <dons> oh. hmm. very old compiler??
22:03:23 <lispy> 6.4
22:03:23 <SamB_XP> import Data.Word, not import Data.Word.Word8
22:03:42 <lispy> oh hm...works now
22:04:42 <lisppaste2> stepcut pasted "bytestring compile error" at http://paste.lisp.org/display/20863
22:04:55 <stepcut> dons: have you ever seen that error ?
22:05:26 <stepcut> dons: using ghc6 6.4.1 on i386 -- same code works fine for me on a different machine
22:06:33 <SamB_XP> stepcut: is it possible that that you have different ByteString installs between the machines?
22:06:36 <dons> stepcut, looking
22:06:52 <dons> yes, i've seen that.
22:06:55 <dons> patched in the darcs repo
22:07:02 <stepcut> SamB_XP: the machine with that error has never had bytestream installed
22:07:02 <dons> its due to using -optc-O2
22:07:12 <stepcut> dons: this was fixed in the last week or so ?
22:07:17 <dons> which some gcc's end up using to produce C that the mangler can't handle
22:07:20 <dons> fixed 2 days ago
22:07:30 <SamB_XP> oh
22:07:41 <dons> and thus, you get a mangler error, "Prologue junk"
22:07:50 <dons> the solutoin is to compile with -optc-O1 or less
22:07:53 <stepcut> yeah, I have worked a bit with the mangler for the arm port
22:08:20 <dons> gcc 4.0.4 ? 
22:08:42 <stepcut> works with gcc 4.0.3, failed with an older version of gcc (3.4 maybe?)
22:08:55 <dons> its easy to fix, just change the fps.cabal optc-O2 to -optc-O
22:09:04 <dons> and rebuild fps on that offending machine
22:09:19 <stepcut> ok, thanks
22:09:39 <dons> be happy that fps is pushing hard on gcc ;)
22:09:45 <stepcut> indeed :)
22:10:12 <sam_> cale, I guess what I'm looking for is something like: "mapError e f = case e of { Right x -> return x | Left x -> f x }"
22:10:36 <Cale> hmm
22:11:04 <SamB_XP> dons: isn't that actually a GHC mangler problem?
22:11:08 <sam_> which would allow me to do: "outerFun x = mapError (innerFun x) (\e -> Error.throwError $ MyOtherError "foo")"
22:11:30 <dons> SamB_XP: yes, it is.
22:12:17 <SamB_XP> dons: it does not happen almost whenever you compile with -optc-O2 ?
22:12:55 <dons> SamB_XP: no, only a few odd compilers produce it.
22:12:57 <dons> odd gccs
22:13:16 <SamB_XP> dons: I meant, with those GCCs
22:13:19 <dons> we've hadd -optc-O2 as the default for 6 months, only now i've had two reports in 3 days.
22:13:39 <dons> its deterministic, do you mean?
22:14:23 <SamB_XP> well, I mean, maybe the code isn't responsible as much as the Cabal file ;-)
22:15:25 <SamB_XP> also, you have to admit that it isn't GCCs fault if the mangler can't mangle its output
22:15:46 <dons> no, its not gcc's fault. its the mangler
22:16:16 <dons> but the code's also responsible. since most code you can use -optc-O2 fine (everything else i compile)
22:16:26 <stepcut> it is the *evil* mangler after all..
22:16:30 <SamB_XP> okay, I should go to bed now, instead of incoherently defending programs at random
22:16:30 <dons> just fps, and a Binary instance I wrote once, break under -optc-O2
22:16:36 <dons> SamB_XP: :)
22:17:32 * stepcut goes to bed
22:17:37 <stepcut> dons: thanks for the help
22:18:13 <dons> no worries.
22:18:25 <stepcut> @karma+ dons
22:18:25 <lambdabot> dons's karma raised to 36.
22:18:45 <SamB_XP> yes, I know, the mangler is at fault. so I'm not quite incoherent. maybe I just don't like you seeming to claim mangler failure as meaning that you are pushing the envelope ;-)
22:19:18 <dons> oh, well, it does mean we're generating code that the mangler hasn't seen before. so we're at least doing something new, right?
22:19:46 <dons> if it wasn't new, the mangler would know about the code pattern already.
22:19:57 <SamB_XP> but, GCC is the one confusing the mangler!
22:20:04 <dons> or, alternately, gcc is doing something entirely new with the same old code.
22:20:21 <SamB_XP> all you are doing is passing -O2 to GCC ;-)
22:20:32 <stepcut> dons: should I log a bug with ghc about that error ? or did you already log a suitable one?
22:20:42 <dons> hmm. yes, we should feed it back to ghc.
22:20:57 <dons> better log the gcc version, and the fps versoin. also arch/os etc.
22:21:14 <stepcut> ok, I will try to get that info tomorrow -- it was someone elses machine
22:21:24 <SamB_XP> I've heard of mangler issues connected with GCC 4 already...
22:22:07 <lispy> @hoogle Char -> Word8
22:22:08 <lambdabot> No matches, try a more general search
22:22:16 <lispy> @hoogle Ord -> Word8
22:22:16 <lambdabot> No matches, try a more general search
22:22:27 <lispy> @hoogle Num a -> Word8
22:22:28 <lambdabot> No matches, try a more general search
22:22:35 <lispy> hmm...
22:22:54 <Pseudonym> > ord 'A'
22:22:54 <lambdabot>  65
22:22:56 <stepcut> lispy: ord and fromIntegral are probably what you want (or were you just testing hoogle?)
22:23:01 <Pseudonym> @type ord
22:23:02 <lambdabot> Char -> Int
22:23:10 <Pseudonym> @type enum
22:23:11 <lambdabot> Not in scope: `enum'
22:23:16 <lispy> i tried fromIntegral, perhaps I should use (fromIntegral . ord)
22:23:16 <SamB_XP> try fromIntegral . fromEnum 
22:23:18 <Pseudonym> @type fromEnum
22:23:19 <lambdabot> forall a. (Enum a) => a -> Int
22:23:24 <Pseudonym> > fromEnum 'A'
22:23:25 <lambdabot>  65
22:23:28 <dons> c2w :: Char -> Word8
22:23:28 <Pseudonym> That also works.
22:23:28 <dons> c2w = fromIntegral . ord
22:23:30 <lispy> okay cool
22:23:31 <SamB_XP> @type fromIntegral . fromEnum :: Char -> Word8
22:23:32 <lambdabot> Char -> Word8 :: Char -> Word8
22:23:34 <dons> w2c :: Word8 -> Char
22:23:34 <dons> w2c = chr . fromIntegral
22:23:36 <lispy> thanks guys
22:24:04 <lispy> @index ord
22:24:04 <lambdabot> Data.Char
22:26:45 <dons> ?karma+ frederik_eaton -- ghc-6.4.2: panic! (the `impossible' happened: linkBCO: >= 64k insns in BCO
22:26:45 <lambdabot> frederik_eaton's karma raised to 1.
22:26:48 <dons> excellent bug
