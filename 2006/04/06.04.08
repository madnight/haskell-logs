00:02:51 <MarcWeber> newsham: Haven't thought of a typo.. I want to try out fudgets lib.. But know I get another error don't know why..
00:03:46 <dons> sethk, I've posted a little tweak to the Server class to avoid the need for explict 'S' parameters. you just use a type annotation now to select the server type. http://www.cse.unsw.edu.au/~dons/tmp/ClientServer.hs
00:04:01 <sethk> dons, thanks
00:04:15 <dons> the key is to just include the server type as a dummy return from runServer:
00:04:16 <dons> runServer :: Handle -> IO (S a b)
00:04:19 <dons> then you can write:
00:04:30 <dons> type TestServer = S LoadtestRequest LoadtestResponse
00:04:30 <dons> main = runServer stdin :: IO TestServer
00:05:20 <sethk> definitely cleaner
00:05:23 <dons> it also makes runServer a class method for the Server class
00:05:26 <dons> which seems reasonable.
00:05:42 <dons> since any Server will have a runServer anyway, this makes that clearer
00:05:51 <sethk> yes.  in fact I originally thought it should be, but then I couldn't see how to do it that way
00:05:58 <sethk> with runServer a class method, that is
00:06:55 <sethk> so it's the same up to the server class definition?
00:07:49 <sethk> then runServer is within the Server class
00:07:51 <dons> its all the same
00:07:52 <dons> yep
00:07:58 <dons> and with a different type. that's all
00:08:30 <dons> and the extra sugar of a type synonym instead of S LoadtestRequest LoadtestResponse
00:09:37 <magiUserL1> can haskell do concurrent programming?
00:09:53 <magiUserL1> things like running jobs in parallell
00:09:53 <magiUserL1> ?
00:10:24 <newsham> yes.  the ghc system has concurrency support
00:10:36 <sethk> dons, hm, you don't need to define the type until just before the runServer invocation
00:10:39 <dons> its possibly the best mainstream language for concurrent programming
00:11:01 <sethk> dons, we'll have a type statement for each server type
00:11:02 <dons> you can define the type synonym anywhere
00:11:05 <dons> yep
00:11:25 <dons> or you can do without, then you need to say: runServer stdin :: IO (S LoadtestRequest LoadtestResponse)
00:11:55 <dons> magiUserL1: check haskell.org, and look at Libraries and tools, under concurrency
00:12:18 <newsham> also see "tackling the awkward squad" paper
00:12:36 <newsham> err.. wait.. the haskell web server paper?  I think thats the one
00:12:56 <sethk> dons, I'm getting "ambigous type variables request, response in the constraing:  Server request response
00:13:00 <sethk> did I miss a change?
00:13:16 <newsham> ahh, awkward squad talks about concurrency
00:13:50 <dons> sethk, hmm. do you have -fglasgow-exts on?
00:13:58 <sethk> dons, yws
00:14:00 <sethk> O
00:14:24 <dons> otherwise, what line?
00:14:53 <sethk> wait, I think I see it
00:15:25 <dons> you'd put something like: type ServerT = S FinalizeRequest FinalizeResponse  in your Finalizer module, and then write catch (runServer hclient :: IO ServerT)
00:15:38 <sethk> yes.  the type variables in (request :: ... ) and (response:: ...) now have to match the ones in the class definition
00:15:58 <sethk> I had a and b on those two lines, but a different name in the class header
00:16:02 <dons> ah
00:16:31 <dons> yes, they have to match the class now, rather than locally. good point
00:16:40 <sethk> hmm, now I'm getting an error on the runServer call.  Let me make sure I don't have another typo
00:16:41 <dons> (bad dons for renaming types all over the place)
00:17:13 <magiUserL1> I am reading about TOP and SQL
00:17:22 <magiUserL1> haskell seesm to generalize the principles
00:17:34 <magiUserL1> I loe the idea of putting the biz logic in tables
00:17:36 <sethk> dons, ok, I fixed that one.  Now it doesn't like the exception part of my thing
00:17:39 <magiUserL1> brilliant
00:17:46 <sethk> dons, I have catch (runServer ...) (\e -> ...)
00:17:58 <sethk> dons, the exception part has to return something of the same type?
00:18:00 <dons> maybe you'll have to return () after runServer?
00:18:10 <sethk> I'll try ...
00:18:22 <dons> because both arms of the catch have to return the same type
00:18:27 <dons> and now runServer returns (S a b)
00:18:30 <dons> not ()
00:18:41 <dons> (its a dummy S a b, but still not the same as ())
00:18:45 <sethk> right, but I can't return (), because of the type
00:19:06 <dons> hmm, you'd have to write: runServer stdin :: IO TestServer >> return ()
00:19:21 <sethk> tried that, doesn't like it
00:19:48 <dons> what's the error?
00:20:10 <magiUserL1> wat is a decent linux?
00:20:15 <magiUserL1> redhat sux
00:20:26 <sethk> dons, couldn't match ...  but this worked:  catch ( do { runServer ... ; return () }  )
00:20:38 <dons> this works for me: 
00:20:39 <dons> main = catch ((runServer stdin :: IO TestServer) >> return ())
00:20:40 <sethk> dons, that's not the same as  runServer ... >> return ()   ?
00:20:40 <dons>              (\e -> return ())
00:20:56 <sethk> maybe I need another set of parents
00:21:55 <dons> you can be a bit fancy, import Foreign, and write: void (runServer stdin :: IO TestServer)
00:22:09 <sethk> yes, it's happy with an extra set of () around (runServer ...) >> return ...
00:23:11 <newsham> magi: if you're a RH person, FedoraCore is a natural progression.
00:23:19 <newsham> I think lots of people are on ubuntu these days
00:23:37 <dons> main = handle (\e -> return ()) $ void 
00:23:37 <dons>         (runServer stdin :: IO TestServer) even
00:23:59 <dons> its all fun, and like newsham says, maybe I will spend 3 days writing the best 3 lines that was ever written
00:24:05 <dons> ;)
00:24:06 <newsham> :)
00:24:31 <newsham> 21st century haiku
00:25:20 <dons> this would be the most standard, though:
00:25:21 <dons> main = catch ((runServer stdin :: IO TestServer) >> return ())
00:25:22 <dons>              (\e -> return ())
00:25:27 <dons> as we said
00:26:13 <newsham> so haskell has strong formal underpinnings, strong type checking, lots of smart people who are interested in it.  why is there only 1 web server, 5 years old, unused hiding away in cobwebbed corner of a cvs repository
00:26:23 <dons> there's 5 or 6
00:26:27 <dons> did you look at hsp?
00:26:28 <newsham> (with security vulns, I might add :)
00:26:30 <dons> hws-wp
00:26:33 <dons> hasp
00:26:35 <dons> wash has a server.
00:26:39 <dons> mod_haskell
00:26:46 <newsham> hws-wp is hws.  i cant get a copy though.   i havent looked at hsp.
00:26:51 <xX[ReP]Xx> http://people.freebsd.org/~ssouhlal/stuff/httpd.hs
00:26:51 <newsham> i didnt know wash had a server.
00:26:55 <dons> hmm. probably others
00:27:11 <dons> yeah, even lambdabot talks http.
00:27:12 <newsham> do people use any of these?
00:27:21 <dons> hsp gets used
00:27:27 <dons> but don't most people just use apache...
00:27:56 <dons> pivot or vital or something. 
00:27:58 <dons> must have a server in it somewhere.
00:28:03 <newsham> apache doesnt use strong type checking or language with strong formal underpinnings
00:28:08 <dons> ok
00:28:20 <newsham> (it does have ssl, on the otherhand)
00:28:35 <dons> I think galois might have a very secure, top secret commeriical web server
00:28:39 <dons> built on top of house.
00:28:52 <dons> but not open source, I'd suggest.
00:28:57 <newsham> galois?
00:29:06 <dons> halfs was part of that in some way. so you could ask SyntaxNinja
00:29:18 <dons> ?google galois connections oregon
00:29:19 <lambdabot> http://www.galois.com/
00:31:36 <newsham> galois uses house as an OS?
00:32:33 <dons> or ghc on bare metal or something. 
00:32:44 <dons> check the halfs page. let me find it
00:33:55 <dons> I guess one point is that there's money to be made in highly secure, verified software, so you don't see it being given away.
00:34:22 <dons> http://www.haskell.org/halfs/
00:34:57 <dons> about the "in the course of developing a web server for an embedded operating system...."
00:36:07 <newsham> thanks
00:38:59 <magiUserL1> so when moving the biz logic into tables
00:39:05 <magiUserL1> you end up with meta tables
00:39:18 <magiUserL1> is this abstraction?
00:42:20 <sethk> magiUserL1, it's a type of abstraction, I suppose, but not the most common type
00:44:15 <magiUserL1> is it practical to use haskell without a database?
00:44:23 <magiUserL1> it seems once you have a db
00:44:31 <magiUserL1> u want the operations to happen in the db
00:45:12 <magiUserL1> but if you leaveout a db
00:45:24 <magiUserL1> then you can really program against the data and abstract thigns
00:45:29 <magiUserL1> to get whatever u want
00:45:46 <magiUserL1> Im envisioning a slaes and prospecting database
00:45:50 <magiUserL1> sales
00:45:57 <newsham> Galois, in partnership with the Navy and security agencies and in accordance with the DoD NetCentric vision, is working on critical cross-domain components which minimize required infrastructure and support a composeable framework where data sources and ap
00:51:01 <dons> there's also http://www.aetion.com/
00:51:55 <boy> dons: hi
00:51:57 <newsham> that looks like decision stuff.  
00:56:40 <magiUserL1> interesting
00:56:44 <magiUserL1> hard to say wht they have
00:57:03 <magiUserL1> so is it better to place most processing into the database
00:57:03 <newsham> decision software *yawn*
00:57:09 <magiUserL1> or keep it out in the programming language?
00:57:21 <magiUserL1> haskell has concurrency
00:57:30 <newsham> ghc has concurrency
00:57:31 <magiUserL1> this means what? things can happen at the same time?
00:57:40 <newsham> multiple threads can run independantly
00:57:55 <magiUserL1> or you have liek 10 jobs solving the problem at same time?
00:58:07 <newsham> they can communicate with each other
00:58:12 <magiUserL1> where would you use it?
00:58:20 <magiUserL1> sounds hi tek
00:58:23 <newsham> web server, for example.
00:58:37 <magiUserL1> o
00:58:44 <magiUserL1> ok how different from normal way?
00:58:47 <newsham> so that each client can progress at its own speed without affecting the other clients
00:58:59 <magiUserL1> hmm
00:59:12 <magiUserL1> ever hear of event drien programming?
00:59:13 <tennin> aren't HaskellDB and LINQ supposed to soften the distinction between programming language & database?
00:59:31 <magiUserL1> whats linq?
00:59:32 <newsham> heard of it.
01:01:10 <boy> is there something like a resizing array, like c++ std::vector in haskell?
01:02:51 <tennin> wow, I'm impressed with HXT... it looks like it might just allow me to deal with XML without ever feeling the urge to gouge my eyes out and write turgid poetry about my pain
01:04:49 <magiUserL1> in business I have to deal with text and xml file transfers from prisons noting prisoner purchases of phone time
01:04:54 <magiUserL1> its a heellish ftp fest
01:05:04 <magiUserL1> can haskell help?
01:05:19 <magiUserL1> hxt?
01:05:28 <tennin> Haskell XML Toolkit
01:05:48 <ski> (dons : yes, instances (and record constructions) should provide all (non-default, in case of instance,) parts, imo (possibly with flag to turn this into a warning, instead, for fast prototyping))
01:06:02 <ski> (Cale : yes, 'fail' should be kicked or moved)
01:06:11 <tennin> what programming experience do you have?
01:07:06 <tennin> and are you interested at all in learning about programming/computer science for its own sake or are you strictly interested in the tasks at hand?
01:08:41 <boy> ski: please man... you gotta help me
01:09:31 <ski> hm ?
01:10:18 <boy> ski: i can't figure out what types i need for an assembly language. my goal right now is to get a working dissasembler
01:10:40 <sethk> boy, find a disassembler and read the source
01:10:41 <boy> ski: my general idea is to have a data Instruction = Push Register | Pop Register | Ld Register Register | Nop | ...
01:10:50 <boy> sethk: my problem is with the types
01:11:01 <ski> yes, i'd prolly start with somethin glike that
01:11:03 <sethk> boy, so?  my advise still stands
01:11:29 <ski> boy : can you more specifically say what is the type problem ?
01:11:32 <boy> ski: my problem though is that the types get really complicated since there are dozens of variations of Ld
01:11:44 <tennin> btw, LINQ as I understand it is a planned feature of Microsoft .NET languages like C# and Visual Basic, that incorporates a unified SQL-like syntax for querying databases, XML documents and other formats into the programming language itself
01:12:40 <tennin> it's designed by one of the creators of Haskell and is apparently heavily influenced by features of Haskell and HaskellDB
01:12:47 <ski> boy : can you enumerate some of these variantions ? (i assume you want to be able to express all of them)
01:12:53 <boy> ski: i'm almost tempted to to have seperate Ld constructors for each register
01:13:10 <ski> (s/variantions/variations/)
01:13:22 <boy> ski: you can see a compact summary here: http://www.semis.demon.co.uk/Gameboy/images/Opcodes.htm
01:15:31 <skew> tennin: have you read the Comega papers?
01:16:42 <wilx> Hmm, maybe you should have more indirect representation of the instructions.
01:16:44 <tennin> no
01:17:00 <boy> wilx: what do you mean?
01:17:02 <wilx> Like, Ld [Operand]
01:17:18 <wilx> And Operand being Register/Memory etc.
01:17:49 <tennin> still struggling with basic stuff like Hughes' and Paterson's arrow papers
01:18:28 <skew> tennin: well, those describe this LINQ stuff
01:18:47 <skew> pretty close to what's coming out in new versions of C#, I think.
01:19:52 <tennin> thanks
01:21:27 <ski> boy : what is 'r','s','d','n','A','C','ss','dd' ?
01:22:05 <ski> is 'A' always the 'A' register, or can other registers be used there, too (which ?) ?  (same for 'C' ?)
01:22:09 <neologism> by a chance.. anyone here who knows PM2 languag?
01:22:15 <boy> ski: at the bottom there is a terminology table
01:22:30 <boy> ski: 'A' is always the 'A' register
01:23:17 <ski> does 'C' in 'LD A,(C)' really mean "carry flag" ?
01:23:53 <newsham> 8 bit cpu?  fun
01:23:58 <tennin> Z80?
01:23:58 <boy> ski: hm... in that case 'C' probably means C register
01:24:12 <boy> i think this might work: http://rafb.net/paste/results/3aKiDi70.html
01:24:20 <magiUserL1> sounds liek ITOP
01:24:32 <magiUserL1> http://www.geocities.com/tablizer/top.htm
01:24:33 <ski> so 'n' and 'nn' is immediate operands, then, i take it ?
01:24:38 <ski> s/is/are/
01:24:43 <newsham> C is a flag.  it says so in the box that says "Flags"
01:25:01 <boy> newsham: yeah, but it doesn't make sense for it to be a flag in those LD instructions
01:25:04 <wilx> Hmm, that looks odd to me.
01:25:09 <boy> tennin: Z80-like
01:25:20 <ski> (newsham : "Terminology .... C	Carry flag....")
01:25:27 <newsham> sure it does.   A <- ($FF00 + C)
01:25:39 <newsham> wait, no it doesnt.  you're right
01:25:48 <newsham> nice of them to use the same name for register and flag
01:26:01 <ski> well, it could .. but it'd be a quite restricted operation, in that case
01:26:51 <newsham> nice to know that video games are still being written for 8-bit cpus 20 years later
01:28:02 <ski> what is a 'destination register' ?
01:28:17 <newsham> where the results go?
01:29:20 <newsham> LD C, 25     c = destination register
01:29:38 <ski> hm .. i wondered which registers were "destination registers"
01:29:55 <ski> but now i see that it's prolly just a description of the intended use
01:30:29 <ski> (thesy should have used something like 'ea = effective address' instead, for both 's' and 'd', i think)
01:31:12 <boy> well, these cover all of the 8-bit loads, but it doesn't look good: http://rafb.net/paste/results/pwfZxd76.html
01:32:18 * shapr yodels
01:32:31 <dons> shapr, http://www.haskell.org/haskellwiki/Research_papers :)
01:32:45 <ski> what does e.g. 's=r,n,(HL)' mean ?
01:32:52 <dons> who needs publishers...
01:33:00 <ski> (at top in the diagram)
01:33:02 <tennin> I used to be into 8-bit Nintendo ASM hacking
01:33:15 <tennin> there's a pretty big "scene"
01:33:48 <boy> ski: it means that the 's' in LD r,s can be either r,n, or (HL)
01:33:55 <newsham> ski: probably the opcode encoding subfields
01:33:58 <ski> boy : i think i'd make one datatype of 8-bit registers, and one for 16-bit registers
01:34:11 <tennin> hardware hacking too
01:34:52 <boy> ski: maybe.... i am thinking i should do what wilx said and have also an Operand type, so i can have only a few LD constructors instead of 20 of them
01:34:54 <ski> boy : and prolly i'd make two variants for "effective address" being either a register or a memory location
01:35:16 <shapr> dons: Speaking of research papers, my brain is stretching in a whole new direction, I'm reading Charles Stewart's thesis.
01:35:27 <ski> boy : and then, since 'LD' seems to be symmetric, i'd add a direction flag to (almost) all 'LD' constructors
01:35:37 <shapr> Oh man, I could point out a zillion papers.
01:35:45 <boy> ski: hm....
01:36:02 <ski> shapr : what's it about ?
01:36:25 <dons> shapr, yeah. there is so so much Haskell stuff out there. it's scary once you try to enumerate it
01:36:43 <shapr> ski: "On the formulae-as-types correspondence for classical logic"
01:36:50 <dons> and we need to connect all that written stuff with the net. it's all dispersed at them moment.
01:36:50 <skew> classical logic?
01:36:51 <shapr> by Charles Alexander Stewart
01:37:05 <ski> boy : hm, i think wilx' 'Operand' is the same as my 'effective address'
01:37:20 <shapr> He appears to have extended the Curry-Howard correspondence to classical logic as used in philosophy.
01:37:24 <skew> hey, I just grabbed his paper on port grammars the other day
01:37:45 <ski> shapr : wasn't there a paper by Timothy(?) Griffin about that ?
01:38:01 <shapr> ski: No clue, tell me about it?
01:38:09 <ski> shapr : i guess it talks about continuations, then ?
01:38:22 <boy> ski: hm....... /me cries this was supposed to be the easy part, i still have the task of doing a complete gameboy emulator ahead of me :'(
01:38:34 <shapr> I got to this paper by following Hamming's advice "What's the most important research topic in your field right now?" "Are you researching it?"
01:38:48 <shapr> boy: No worries, you'll do fine.
01:38:53 <ski> shapr : hm .. i think i was thinking of http://citeseer.ist.psu.edu/griffin90formulaeastypes.html
01:39:33 <shapr> ski: http://www.linearity.org/cas/
01:39:52 <ski> boy : when you've got the data structures pinned, i think many things will fall out more or less by themselves
01:40:00 <ski> shapr : danke
01:40:12 <shapr> skew: Yeah, port grammars is his most recent publication.
01:40:51 <shapr> skew: This PhD thesis is hard going for me. I never read Wittengenstein or Kant, and my readings of older philosophy like Aristotle was not focussed around systems of meaning.
01:40:55 <boy> ski: yeah.... i guess i'll work on this some more
01:41:51 <shapr> On the other hand, I'm thoroughly entertained by any on-topic for #haskell PhD thesis that can realistically have references in the bibliography to all these guys!
01:42:09 <ski> boy : e.g. i'd say 'data Reg8 = RegA | RegB | ... | RegL' 'data Reg16 = RegAB | ...'
01:42:11 <magiUserL1> anyone here ever hear of table oriented programming?
01:42:15 <magiUserL1> top
01:42:26 <shapr> magiUserL1: Sure, I've heard of it. Do you know TopMind?
01:42:30 <magiUserL1> no
01:42:39 <magiUserL1> Im reading his geocities site again after years
01:42:44 <magiUserL1> he might be on to something
01:42:55 <shapr> magiUserL1: I really tried to give his stuff a chance, but I think he's just a nut.
01:42:58 <magiUserL1> tables are more info dense than objects
01:43:03 <magiUserL1> really?
01:43:13 <magiUserL1> his ITOP ideas are theoretical
01:43:16 <magiUserL1> unfortunatly
01:43:17 <skew> certainly obtuse, anyway
01:43:35 <skew> if you go to w2 you can see many k of people trying to explain stuff like higher order functions to him
01:43:37 <magiUserL1> but putting programming logic into tables and data dictionaries tables about tables seem liek smart abstractions?
01:43:50 <shapr> Yeah, if you read Ward's Wiki, you'll see what I mean.
01:43:57 <magiUserL1> w2?
01:44:01 <skew> er, c2?
01:44:12 <skew> what shapr says
01:44:21 <magiUserL1> wards wiki?
01:44:46 <shapr> It appears to me that TopMind totally fails to understands the basics of functional programming enough to compare and contrast table oriented programming to FP.
01:45:06 <shapr> In my opinion, table oriented programming is more limited than functional programming.
01:45:08 <tennin> personally, I think he does a good job laying out the problems with mainstream OOP in practice, though
01:45:22 <shapr> Yeah, but his solution looks like snake oil.
01:45:29 <skew> c2.com/cgi/wiki
01:46:08 <skew> shapr: I'll have to read that thesis more carefully. Philosophers say intersting things, but they tend to abuse math too.
01:46:56 <magiUserL1> http://www.c2.com/cgi/wiki?TableOrientedProgramming
01:47:07 <skew> there's stuff scattered all about
01:47:12 <shapr> skew: Everything I've seen so far implies that he made a real connection between CH and a subset of the sort of proofs used in philosophy.
01:47:15 <magiUserL1> who owns c2?
01:47:19 <shapr> magiUserL1: Ward
01:47:29 <magiUserL1> oh
01:47:36 <shapr> Ward Cunningham that is. He invented the idea of Wikis and made the first one.
01:47:37 <shapr> That's it.
01:47:47 <skew> shapr: stewart? and a connection between CH and something else?
01:48:08 <skew> or a CH-style connection between classical logic and a language?
01:48:12 <tennin> well, he seems to be unwilling to put any effort into understanding FP so it's no surprise his comments on it aren't worth much
01:48:22 <shapr> tennin: Yeah, that's pretty much what I think.
01:48:37 <skew> he seems to have put quite a bit more effort in to dismissing it than it would take to understand it.
01:48:38 <shapr> Well, that and his solutions don't seem that great to me.
01:48:51 <shapr> He sounds like someone who's trying to fit the facts to his solution.
01:49:10 <magiUserL1> the ward guy is an extreme programming inventor?
01:49:23 <magiUserL1> xp sounds like marjeting madness
01:49:30 <magiUserL1> marketing
01:49:31 <shapr> magiUserL1: Sort of .. Extreme Programming came out of discussions on the wiki.
01:49:45 <magiUserL1> but the TOP idea of tables with info about tabels sems brilliant
01:49:52 <shapr> magiUserL1: XP isn't marketing madness, but it has been advertised strangely.
01:49:56 <shapr> magiUserL1: Well, prove it.
01:50:01 <magiUserL1> oh so ward is like a ground 0 invetor of xp?
01:50:14 <shapr> magiUserL1: Are you TopMind?
01:50:19 <magiUserL1> no
01:50:23 <shapr> Ok...
01:50:31 <magiUserL1> My real name is Gavin
01:50:37 <shapr> Hi Gavin, my real name is Shae.
01:50:41 <shapr> Nice to meet you :-)
01:50:42 <magiUserL1> 33 year old guy in Los angeles working as linux admin
01:50:48 <ulfdoz> xp is just a concept. Whether it works or not depends on task and execution.
01:50:59 <shapr> I'm a 34 year old guy working in Sweden doing Zope dev.
01:51:03 <magiUserL1> dreaming of learning to develop programs taht are super fast
01:51:06 <magiUserL1> unlie the www.suagrcrm.com thing I have to support
01:51:16 <magiUserL1> zope?
01:51:19 <magiUserL1> python?
01:51:26 <shapr> Yeah, Python is how I make most of my money.
01:51:37 <magiUserL1> sweden?
01:51:44 <magiUserL1> I hear the girls are pretty there
01:51:47 <shapr> Yup, I moved from Alabama to Europe six years ago.
01:51:56 <magiUserL1> ha!
01:51:56 <shapr> Truly, the women here are fine.
01:52:00 <magiUserL1> adventure!
01:52:08 <shapr> World Tour!
01:52:18 <magiUserL1> so why hanging in haskell if the snake is yur thing?
01:52:28 <shapr> The Snake is how I make money.
01:52:35 <shapr> The Lambda is the way and the light =)
01:52:44 <magiUserL1> do you reccomend I learn that as 1st lang?
01:52:50 <shapr> Ok, I'm teasing about Haskell being the one true way.
01:52:50 <skew> strangely, Python is what I'm working on for money too.
01:52:52 <magiUserL1> lambda meaning?
01:52:56 <magiUserL1> oh
01:53:00 <shapr> But Haskell is the best tool I've found so far.
01:53:11 <magiUserL1> wow
01:53:19 <astrolabe> and haskell is fun
01:53:24 <shapr> Thing is, you gotta realize that everything we have now is crap compared to programming languages that will exist in five hundred years, right?
01:53:29 <magiUserL1> I hear big things about smalltalk and clisp, and evn scheme whre i am unfortunatly banned
01:53:48 <shapr> Well, if you're nice here on #haskell, you won't get banned.
01:54:02 <skew> mostly C at work, decided to make a tool to make C. I was going to use Haskell, but darius suggested Python as a compromise
01:54:05 <shapr> g'day blackdog 
01:54:09 <magiUserL1> c seems very powerful and i have the book stting here kernighan
01:54:12 <blackdog> hej shapr
01:54:12 <shapr> Darius is a smart guy.
01:54:21 <shapr> magiUserL1: it is! C is very much worth learning and knowing.
01:54:25 <magiUserL1> I dream of maybe learnign c and then ic an crank out awesoem programs
01:54:33 <magiUserL1> and all the naysayers are tricking me
01:54:53 <shapr> magiUserL1: If you want a good first programming language that'll let you make money once you know it, learn Python!
01:54:57 <ulfdoz> In my opinion, C is unusable. At least I make too much mistakes, which need a lot of time to correct.
01:54:59 <blackdog> C is pretty rarely the right tool for the job.
01:55:02 <skew> shapr : ... avoiding actually using.
01:55:09 <tennin> you want to write programs that are super fast as in performance?
01:55:15 <tennin> or super fast as in speed of development?
01:55:26 <shapr> skew: Yes, I did not say using :-)
01:55:30 * ski remembers learning C and understanding the possibility of uniform syntax for function calling (as opposed to old Basic)
01:55:30 <boy> C might not be a good tool for a lot of jobs, but i think that every serious programmer should know C very well
01:55:41 <magiUserL1> why
01:55:41 <boy> ski: i think i am making some progress :)
01:55:42 <blackdog> Decently sized programs in C aren't that fast anyway. Look at the gnome object system.
01:55:44 <astrolabe> boy: agreed
01:55:45 <magiUserL1> why know c if nt use
01:55:55 <magiUserL1> i also lately saw something called objectiv c
01:55:56 <blackdog> boy: every programmer should know about pointers, at least.
01:55:59 <shapr> magiUserL1: Because C is a portable assembly language.
01:56:08 <skew> it's not very convenient for actually using, but learning it teaches you a lot about how the hardware works
01:56:13 <shapr> Yes, object oriented programming is worth knowing also.
01:56:19 <skew> or used to work back in the 70s, or something like that
01:56:26 <astrolabe> If you learn C, you really appreciate haskell.
01:56:26 <ulfdoz> skew: That does assembler, too. ;)
01:56:31 <shapr> skew: ooh, truth in advertising :-)
01:56:32 <magiUserL1> I like the idea of tables with programming logic in them
01:56:35 <magiUserL1> data dictionaries
01:56:40 <blackdog> shapr: I'm going to take these quotes of yours and save them up for the witch trials. :P
01:56:44 <magiUserL1> it sudsn liek you can use tables as abstractions
01:56:54 <shapr> blackdog: What, that each of these is worth knowing?
01:57:16 <astrolabe> magiUserL1: What's good about tables?
01:57:17 <blackdog> Yep. don't worry, I'll take them totally out of context.
01:57:22 <magiUserL1> can you use tables instead of objects to abstract away programming tasks?
01:57:39 <shapr> magiUserL1: You could, yes.
01:57:54 <magiUserL1> is that not a cool technique
01:57:58 <magiUserL1> ?
01:58:09 <tennin> my current "development methodology" is pretty much the antithesis of XP (or anything sane)
01:58:10 <Saulzar> What do you mean by that statement?
01:58:20 <shapr> Well, I want abstractions that are simple, regular and powerful.
01:58:31 <Saulzar> "tables instead of objects"  "abstract away programming tasks" ?
01:58:34 <magiUserL1> I hate www.sugarcrm.com
01:58:39 <astrolabe> Are you talking about modularisation, because that is an ability of most languages?
01:58:42 <magiUserL1> its php and mysql apache
01:58:51 <shapr> A pure lookup table is simple and regular, but what's powerful about it?
01:58:51 <magiUserL1> pre cut pages CRM
01:58:58 <boy> ski: argh, i almost had something worked out but now there is this bit operand that is used sometimes
01:59:14 <magiUserL1> yes modularization
01:59:21 <magiUserL1> say I wanted to build a sales database
01:59:29 <boy> ski: hm.... actually i guess i can just use Word8 for bit
01:59:32 <tennin> volunteer to write program in Python -> come up with ambitious concepts -> realize that neither Python nor my level of CS knowledge are cutting it -> hole up in my room for a year learning Haskell and studying theoretical CS
01:59:34 <magiUserL1> and make it avaialble over the network, notice i didnt say web page
01:59:37 <shapr> magiUserL1: Whoa hang on, why do you want a database?
01:59:38 <tennin> -> ??? -> Profit!
01:59:54 <magiUserL1> I dont neccerily
02:00:08 <shapr> What's the real business goal?
02:00:12 <shapr> tennin: Oh, I like it!
02:00:16 <magiUserL1> I just want to have a sales list of clients the sales reps can update and then do reports on
02:00:38 <magiUserL1> i dont care if it doesnt use a relational db
02:00:56 <magiUserL1> information sharing in a business is a real need in my current job
02:01:07 <astrolabe> magiUserL1: How did you get to #haskell?
02:01:07 <magiUserL1> If I could learn to produce something I could start my own biz.
02:01:19 <shapr> magiUserL1: Start with Python.
02:01:26 <magiUserL1> well I started reading about TOP and functional programming
02:01:59 <magiUserL1> well let me ask this what does haskell offer over python?
02:02:12 <magiUserL1> why start with python is haskell is better?
02:02:31 <shapr> Haskell has more power, more regularity, more theory, and a smarter community.
02:02:44 <shapr> Python has acceptance in business.
02:02:45 <astrolabe> The world is too much influenced by buzzwords and advertising.  I'd listen to shapr :)
02:03:02 <magiUserL1> but if haskell is more productive......
02:03:09 <wilx> Bah, Python is overrated. Perl is the way to go.
02:03:11 <magiUserL1> wont i get richer with haskell?
02:03:18 <skew> shapr: About languages, McCarthy said lisp is a local optimum in the space of programming languges. Haskell makes me think of constrained optimization and lagrange multipliers - we have some ideas where to improve, but that takes us out of the realm of well-developed languages
02:03:18 <blackdog> HAHAHAHA
02:03:20 <astrolabe> I think haskell is more difficult (not knowing python).
02:03:32 <blackdog> sorry. has anyone made a motza with haskell yet?
02:04:00 <shapr> magiUserL1: For whatever stupid reason, business people who have no clue about programming tend to make technical decisions. Thus Python is more likely to end up getting you a job writing software.
02:04:02 <magiUserL1> paul graham said clisp and true macroes are just the best way to go
02:04:07 <skew> Python is pretty simple to learn, and makes it quite easy to make little gui things and other toys.
02:04:23 <blackdog> i think libraries play a much bigger part than we like to admit. a lot of programmers are really CPAN programmers, perl just happens to be tho language CPAN is written in.
02:04:26 <skew> which is pretty nice for a starting point, although the language isn't really totally simple to understand
02:04:45 <magiUserL1> hmm
02:04:58 <magiUserL1> I read about a lot of stuff like POE for perl
02:05:13 <tennin> if you're interested in writing high-performance programs, you should probably get a book on algorithms
02:05:17 <magiUserL1> but gosh  im a bit intimidated to jump in and get feet wet but i know i must
02:05:35 <shapr> skew: I agree, I've been searching for local minima like lisp. I've found a few. Python, monads, and joy are the others.
02:05:40 <shapr> magiUserL1: Nah, the other way around jump in!
02:05:50 <magiUserL1> the problem with our cms is our network is so clogged and their laptops so clogged with crap that everything is slw adn then they bitch
02:06:00 <magiUserL1> ok goodnight all
02:06:02 <skew> Scheme is maybe the most simple language (if you don't count macros and continuations), but I don't know much about libraries and stuff, and getting banned from #scheme kinda interferes with finding out.
02:06:07 <shapr> magiUserL1: If you want to be a really good programmer, go learn Python and make money for a few years, then come back and learn Haskell.
02:06:08 <magiUserL1> Im jumping in in morninn lol
02:06:11 <astrolabe> Languages like clisp, scheme and haskell will do the job, and in cool and interesting ways, but they take more effort and thought I think.
02:06:20 <magiUserL1> oh
02:06:41 <musasabi> What was the correct way to trace why a Haskell program segfaults? (compiled with ghc)
02:06:42 <magiUserL1> hmm
02:06:49 <magiUserL1> night all
02:06:53 <shapr> g'nite magiUserL1
02:07:42 <shapr> I do think Haskell is the best thing going, but until we get some consultancy pools organized, businesses can say "We won't be able to support it!"
02:07:44 <astrolabe> I wonder why he got banned from #scheme.
02:08:05 <astrolabe> Seemed amiable enough.
02:08:12 <shapr> I think it's because he's a newbie to the world of irc, and he tends to ramble.
02:08:46 <dons> musasabi: compile with -debug? use gdb
02:09:03 <dons> catch SIGSEGVs around foreign calls.
02:09:13 <Korollary> skew: how did you get banned from #scheme?
02:09:24 <dons> skew got banned from #scheme?
02:09:27 <dons> bizarre
02:09:28 <skew> I didn't, but that magiUserL1 guy did
02:09:33 <Korollary> ah, sorry
02:09:35 <dons> oh yes.
02:09:42 <dons> Korollary confuses the situation...
02:09:43 <dons> ;)
02:09:52 <Korollary> I am barely awake.
02:09:54 <astrolabe> lets all go to #scheme an experiment ;)
02:09:58 <dons> hehe
02:09:59 <astrolabe> *and
02:10:05 <dons> whoever gets banned first wins!
02:10:08 <dons> :P
02:10:59 <tennin> if #scheme is anything like comp.lang.lisp...
02:11:03 <skew> shapr: local maxima, vs. point along a potentially unbounded trajectory :)
02:11:42 <Maddas> tennin: It's not.
02:12:27 <skew> I need some help thinking of a test case - can somebody suggest a simple example of a program with a test suite and some edits to it?
02:12:53 <dons> ?
02:12:58 <dons> more info 
02:13:19 <dons> if hhave examples of programs with testsuites, if you want those..
02:13:22 <shapr> Yeah, elucidate
02:13:26 <skew> I'm hacking up an interpreter in an incremental computation monad, with the idea that this might be useful for "rerunning" a test suite after changing your program
02:13:34 <shapr> oh!
02:13:42 <shapr> Like Smalltalk's debug and rerun?
02:14:04 <skew> but it's been a while since I've done test-driven development in the pure lambda calculus :)
02:14:09 * shapr grins
02:14:36 <skew> debug and rerun? maybe if you crossed it with the guts of a time-travel debugger
02:14:49 <astrolabe> I'd be interested to hear about peoples methodologies for tdd in haskell.
02:15:06 <shapr> It's like 'restart from thrown exception'
02:15:11 <shapr> after you changed the code to fix the problem.
02:15:44 <musasabi> hmm, the crash happens just sometimes :-(
02:15:48 <shapr> If you could associate tests with particular increments you'd only ever need to rerun the tests for the code that has changed.
02:15:55 <shapr> Test suite memoization :-)
02:16:17 <skew> I'm thinking more the other way, worrying that your edit broke something
02:16:37 <skew> after reading about how long the full Pugs tests tage
02:16:41 <shapr> Hm, hey, what about putting tests into the module and having ghc run them during compilation via TH?
02:17:06 <shapr> Oh, why not just have a few end-to-end tests?
02:17:59 <skew> I'm speculating that some kinds of long-running tests might be only locally affected by some edits
02:18:27 <shapr> locally affected?
02:18:50 <skew> so maybe explicitly building up the complete execution trace of a program as an incrementally updated structure could help performance
02:19:25 <skew> fun, anyway
02:19:43 <shapr> Or you could have top level tests that call lower level test suites when those top level tests fail.
02:19:58 <shapr> But incrementally executed test suites would be much niftier.
02:20:46 <shapr> But if you're writing a webserver a simple end-to-end test could serve a known file from the filesystem, and if that test fails you could run the top level tests for each major chunk of the server.
02:21:29 <skew> for one, that probably doesn't give very good coverage
02:21:48 <tennin> btw, could someone recommend good modern books on algorithms to supplement Knuth, which I'm slowly struggling through and love but am afraid isn't quite adequate by itself anymore...?
02:22:02 <skew> or, gives good coverage and takes a long time
02:22:14 <shapr> Yeah, but coverage isn't so important until you're about to run darcs record.
02:22:32 <dons> tennin, Cormen is standard these days
02:22:43 <dons> ?google Cormen algorithms
02:22:45 <lambdabot> http://theory.lcs.mit.edu/~clr/
02:23:09 <shapr> Anyway, you (or your company) should choose your own balance between speed of dev and time of tests.
02:23:24 <shapr> Darius once suggested zero button testing to me.
02:23:53 <shapr> He said that a filesystem change notification process should kick off the tests everytime you save the file, and the programmer should keep on coding until an error is thrown.
02:24:33 <flux__> really what should happen is that the editor would closely converse with the compiler and send updates to its parse tree
02:24:36 <shapr> I like that, but don't really know how to implement it.
02:24:46 <flux__> and whenever it would parse, it would be compiled
02:25:03 <flux__> or maybe even only the parts that were changed (with dependency tracking) would be recompiled
02:25:11 <flux__> and tested ;)
02:25:27 <skew> the excuse here is that a test suite comprehensive enough to actually convince you the program is correct probably takes a long time to re-run (naively, anyway) on those edits
02:25:33 <tennin> e.g. Knuth's reasons for not using a specific high-level language make sense, but using a specific concrete machine model and assembly language doesn't seem much better, even if it weren't from the 60s
02:26:16 <flux__> a smart dependency analysis could tell which tests are relevant for testing the most recent changes
02:26:44 <skew> flux__: I'm trying to go one step better, seeing which bits of the execution of the test are relevant for seeing the effects of the change
02:27:13 <flux__> yeah, well you could split the tests into smaller tests
02:27:41 <ski> this sounds a bit related to declarative debugging, i think
02:27:49 <flux__> and store the results of the tests so that you can evaluate the larger test by using one actually performed test and n other cached tests ;)
02:27:58 <ski> (divide-and-query, etc)
02:28:09 <flux__> hm, what is declarative debugging?
02:28:09 <skew> I'm reminded of a proof from a complexity class, that some kind of automata on 5 booleans could be implemented in parallel in log of the execution time, by computing the n-fold composition of the update function by repeated squaring
02:28:15 <tennin> esp. with the rise of multi-core and distributed systems...  seems like the best thing would be to use some kind of abstract machine model for analysis, or, better, introduce multiple machine models and compare and contrast where appropriate
02:29:49 <ski> flux__ : you start by telling declarative debugger that a certain call returned incorrect result .. it then starts asking you about various subcalls, asking whether they returned correct values, in the particular cases, so the decl. debugger narrows down the possible source(s) of the bug for you
02:31:02 <skew> have you all seen Manuel Chakravarty's new paper? System F with coercions, for implementing all kinds of things
02:31:45 <skew> I wonder how it relates to Daan's stuff about implementing MLF with evidence functions
02:32:21 <flux__> ski, how does that work with imperative languages, that is, when you have mutable data?
02:32:48 <skew> flux__: in principle, you can remember all the values of the data
02:32:50 <flux__> ski, it would need to store a history of changes with variables or iterate runs?
02:33:10 <flux__> right. are the examples of such debuggers?-o
02:33:32 <skew> I think OCaml has one
02:33:37 <tennin> how about Distributed Algorithms by Nancy Lynch?
02:33:39 <ski> flux__ : yes, with I/O it's more complicated .. Mercury has one though
02:33:42 <skew> the phrase is "time travel debugger"
02:33:54 <numerodix> anyone know how to UPDATE a statusbar in wxhaskell? seems I can create it, but not change it later. setting the frame's statusbar anew (as in to a new object) gives an error...
02:33:57 <skew> at least, for debuggers that keep the whole execution history so you can jump around
02:34:08 <skew> OCaml has one, for example
02:34:20 <skew> I haven't heard of mixing that with declarative debugging
02:34:53 <ski> flux__ : in case of I/O the mercury one generates unique ids for I/O actions, memoizing what arguments and results each such call had .. then instead of recalling I/O actions, it just returned the cached results
02:37:06 <ski> (Mercury is a pure language, with an I/O system similar to Clean's, also it supports mutable references similar to 'STRef's, those are relative to a 'store' state that is linearly passed around (similar to the world for I/O))
02:37:56 <boy> if performance is really important, should i instead of very small lists use a tuple where the first item that contains the length?
02:38:23 <boy> like instead of [5, 5, 6] i do: (3, 5, 5, 6, 0, 0, 0, 0, 0)
02:39:11 <skew> boy: that's going to be hard to impossible to do, because different size tuples are different types
02:39:37 <boy> skew: yeah, that's why i have the "padding" at the end. i know the maximum length
02:39:49 <skew> is performance a problem?
02:40:13 <boy> skew: it might not be, or it might be a big big problem
02:40:36 <boy> but from my experience lists can be very slow
02:41:05 <ski> i'd say, optimize it later, if it proves to be too slow
02:41:33 <boy> yeah
02:41:46 <skew> boy: http://shootout.alioth.debian.org/debian/benchmark.php?test=all&lang=all
02:42:12 <skew> if it's really necessary, you can stomp on your Haskell program until it is tiny and fast
02:42:19 <boy> skew: yeah
02:42:37 <boy> skew: problem is that i will have hundreds of lines
02:42:39 <skew> tiny lists are probably not such a big deal anyway
02:42:51 <skew> if they are really that short and don't last too long
02:43:14 <boy> skew: haskell needs some sort of system where you can transform programs
02:43:21 <skew> deforestation might eat some of them, and they'll live in cache anyway
02:43:43 <genneth> boy: if you think it's going to be a likely point to optimize for, make a new typeclass that contains the operations you want to do on that data type
02:43:53 <skew> or, just don't worry
02:43:58 <skew> then it's easy now
02:44:11 <genneth> boy: then changing it from a list based one to a tuple based one is localized to just one point...
02:44:15 <skew> and if you are really lucky, you might get to learn how to use the profiler. Oh boy!
02:44:22 <boy> hm....
02:44:37 <Saulzar> Premature optimisation is evil, right? :)
02:44:49 <Maddas> Is it full moon tonight?
02:44:50 <Maddas> ;-)
02:44:56 <skew> I'm assuming you are wanting to write some program, rather than learn how to optimize Haskell
02:45:08 <skew> learning about optimizing Haskell is fun too.
02:45:13 <int-e> Saulzar: hmm, is the root of all evil evil?
02:45:29 <skew> what's the cube root of all evil?
02:45:45 * Saulzar thinks there is a type error
02:46:05 <int-e> skew: negative ;)
02:46:42 <tennin> (evil)**(evil) = ?
02:46:44 <dons> skew, oh, I hadn't realised Manuel's actually written the paper up.
02:47:05 <dons> goo.d bring on the associated types
02:47:10 <skew> perhaps it just went up today
02:47:36 <dons> must have been recent. since he didn't mention it at our meetings :} (he's my supervisor)
02:47:54 <skew> the whole of cse.unsw.edu.au was down for a while earlier this week, maybe I'm just imagining seeing his page without that paper
02:47:59 <boy> this is the code i'm working on:
02:48:11 <dons> no, the paper is there, at ~chak/papers/SCP06.html
02:48:19 <boy> http://rafb.net/paste/results/OwsRF396.html
02:48:22 <dons> but also, the uni did go down last weekend..
02:48:33 <dons> they removed some thing, and replaaced some other thing
02:48:59 <skew> thwi was thursday afternoon when I was looking for papers on data parallel programming
02:49:31 <skew> I think that link wasn't on the version of the page from search engine caches
02:49:41 <skew> which put it at a few weeks, I guess
02:49:47 <skew> anyway, nice paper
02:49:54 <skew> especially if he's your advisor :)
02:50:19 <skew> Daan did vaguely similar things with actualy typecasting functions in his MLF paper
02:50:50 <skew> boy: don't worry much about that
02:51:51 <boy> skew: hm... actually i don't think i will ever have more then 2 elements. so maybe i should use a Either Word8 (Word8, Word8) ?
02:52:13 <skew> nah, this looks like the most direct way, for easily translating lots of instructions
02:52:55 <skew> concatMap instructionToMachineCode :: [Instruction] -> [Word8]
02:54:02 <boy> skew: won't that be slow as hell though for large programs?
02:54:19 <skew> I suspect actually getting the words out of that either type and onto disk could be slower
02:56:03 <boy> well, i mean having a very large [Word8] result from the concatMap. wouldn't something that puts the result into an array be better?
02:56:11 <skew> not necessarily
02:56:27 <skew> say, if you are lazily producing those words as they are written off to disk
02:56:51 <skew> especially if the compiler gets smart and avoids actually making the list in the first place, just handing the words straight into IO buffers
02:57:27 <boy> hm... that is indeed very interesting
03:04:33 <flux__> I wonder what ghc will look like in ten years or so
03:04:45 <flux__> assuming it won't be replaced by something even greater, that is ;)
03:05:41 <flux__> like yhc or jhc ;)
03:40:43 * boy whistles for ski 
04:11:50 <bolrod> wheee   just created a very basic sudoku solver
04:11:51 <bolrod> :]
04:12:50 <astrolabe> cool
04:34:20 <bolrod> lets see if it can solve this simple sudoku :]
04:34:41 * boy wrote a sudoku solver in microsoft word visual basic :P
04:35:07 <boy> @seen ski 
04:35:07 <lambdabot> ski is in #haskell-overflow, #haskell-blah and #haskell. Last spoke 1 hour, 54 minutes and 1 second ago.
04:35:15 <boy> @seen skew
04:35:15 <lambdabot> I saw skew leaving #haskell 18 minutes and 39 seconds ago.
04:35:28 <boy> @seen wilx 
04:35:29 <lambdabot> wilx is in #haskell. Last spoke 2 hours, 32 minutes and 19 seconds ago.
04:35:44 <norpan> i wrote a sudoku solver in prolog using fdsolve
04:50:35 <wilx> Hm?
04:51:23 <bolrod> muahaha >:)
04:51:42 <bolrod> simple sudoku solver in about 60 lines
04:56:38 <bolrod> hahahha
04:56:46 <bolrod> it just solved an average sudoku
05:00:30 <bolrod> ok.. id can't do hard ones yet
05:00:33 <bolrod> hehe
05:22:47 <boy> wilx: hello!
05:30:47 <boy> wilx: do you think that i should have really strong typing in my Instruction type, so that it's imposisble to have an invalid Instruction value?
05:31:46 <wilx> Type safety is always nice.
05:32:02 <norpan> as much as you can
05:32:49 <boy> there is a BIT instruction that takes an argument 0-7, so should i have a have a data BitIndex = Bit0 | Bit1 | ... | Bit7?
05:33:02 <boy> or should i just use Int?
05:35:35 <wilx> Hmm, I think that in this case it depends on your taste. It might looks like a bit of an overkill to enumerate all the bits.
05:36:49 <wilx> On the other hand, 8 enumerators is not that much either.
05:38:29 <boy> wilx: how about the RST instruction that can as argument only specific addresses: $00 $08 $10 $18 $20 $28 $30 $38, should i have a data RestartAddress = RST_00H | RST_08H | RST_10H ... ?
05:40:48 <wilx> Hm, dunno, same case.
05:41:17 <wilx> I guess I would first try to enumerate the possibilities if there weren't too many of them.
05:42:25 <boy> wilx: ok, but the killer is the LD instruction, which has a large amount of very specific combinations of registers, pointers, and numbers. getting perfect type safety for this will be a pain in the ass
05:46:53 <wilx> Not everything can be taken care of using the type system.
05:47:36 <wilx> You will have to make some function that construct only sane instruction/data.
05:49:14 <boy> wilx: hm...
05:53:47 <boy> anyone happen to know the best way to combine 2 Data.Word8 into a Data.Word16?
05:55:09 <wilx> Extend to Word16 and then shift and or.
05:56:30 <boy> how do i extend to Word16?
05:57:38 <musasabi> fromIntegral
05:58:39 <musasabi> Is there a pragma to tell GHC to float a function with constant argument outwards to the top-level?
05:58:40 <boy> musasabi: is that fast?
06:00:12 <musasabi> boy: It should be compiled to something fast if you are using an optimizing compiler.
06:06:55 <loonatic> hiho everybody, i'm currently learning haskell and for practice I try to implement a library for 3d vector calculations (including addition, cross product, and all the stuff). i got the addition working via operators but i have no idea how i can change the member type of the vector (currently Double) into a more general form linke Num or Fractional or so. do you have any ideas?
06:07:05 <loonatic> my type declaration looks like this:
06:07:21 <loonatic> data Vec3 = Vec3 Double Double Double
06:08:20 <boy> musasabi: does such an optimizing compiler exist today? :D
06:11:21 <musasabi> GHC with -O2 does a quite good job.
06:11:29 <musasabi> jhc too.
06:12:06 <shapr> JHC does amazing things.
06:14:46 <Lemmih> In theory, at least.
06:15:08 <astrolabe> loonatic: maybe something like 'Num a => data Vec3 = Vec3 a a a'
06:15:31 <shapr> I've been able to produce a test binary for my Nokia 770, so JHC has something good for :-)
06:24:39 <boy> Data.Word8 is unsigned, right? is there a signed version?
06:25:14 <Lemmih> Int8
06:26:16 <boy> Lemmih: where is that?
06:26:48 <Lemmih> boy: Data.Int
06:27:19 <davidhouse> @hoogle Int8
06:27:20 <lambdabot> Data.Int.Int8 :: data Int8
06:41:47 <boy> > (3 :: Data.Int.Int8)
06:41:48 <lambdabot> 3
06:42:01 <boy> > ((-5) :: Data.Int.Int8) + 2
06:42:02 <lambdabot> -3
06:42:11 <boy> > ((-129) :: Data.Int.Int8)
06:42:12 <lambdabot> 127
06:42:17 <boy> > ((-128) :: Data.Int.Int8)
06:42:18 <lambdabot> -128
06:42:23 <boy> > ((-130) :: Data.Int.Int8)
06:42:24 <lambdabot> 126
07:07:32 <boy> f x = ...
07:07:34 <boy> g = f
07:08:12 <boy> when i call g, it will be optimized to directly call f? and possibly even inline everything so there is no JUMP?
07:11:15 <Lemmih> boy: Test it.
07:13:23 <boy> don't you mean: "test it, boy" :P
07:17:07 <jyp> I got a couple of questions for you Lemmih... 
07:17:24 <jyp> 1. How is hide doing ?
07:18:05 <jyp> 2. Should it work with ghc head, or does it require your own version?
07:20:31 <Lemmih> jyp: The HIDE project is active and should build with recent versions of GHC-head.
07:21:30 <jyp> Lemmih, ok, I'll try again then (last time I got segmentation fault upon running it-
07:21:57 <jyp> I guess it should make no difference if I'm using amd64?
07:22:50 * Beelsebob licks bethan
07:22:53 <Beelsebob> bah
07:22:56 <Beelsebob> *confused*
07:23:05 * Beelsebob licks Philippa while I'm on that line of thought
07:23:32 <Lemmih> jyp: We've previously experienced problems with amd64 but if you can load the 'ghc' package in GHCi then you should be fine.
07:24:02 <jyp> Lemmih: ok, I will try that. Thanks :)
07:34:32 <JohnnyL> anyone here know how much resources haskell takes up as a web server/cgi?
07:34:50 <boy> cgi might be really slow
07:35:08 <Lemmih> I'd use fastcgi.
07:35:30 <shapr> JohnnyL: You can also check out Peter Thiemann's haskell web server with hs-plugins ability.
07:35:34 <boy> fastcgi would be fun :)
07:35:37 <Lemmih> @where fastcgi
07:35:37 <lambdabot> http://www.cs.chalmers.se/~bringert/darcs/haskell-fastcgi/
07:41:23 <JohnnyL> shapr, url?
07:41:35 <JohnnyL> i am trying to get my internet provider to use haskell.
07:41:45 <shapr> Wow
07:42:08 <shapr> Wouldn't it make more sense to rent a virtual server and just install it?
07:42:22 <shapr> I pay $15usd a month for root on my own virtual server.
07:42:46 <bolrod> ;o!
07:43:05 <JohnnyL> i pay $4 a month.
07:43:33 <Beelsebob> :o what do you get that cheap????
07:43:43 <JohnnyL> alot.
07:43:47 <JohnnyL> interadvantage.com
07:44:02 <Beelsebob> how's their support?
07:44:28 <Beelsebob> oh - they don't give you a virtual server
07:44:30 <Beelsebob> just hosting
07:44:48 <Beelsebob> and bugger all space and bandwidth
07:45:21 <shapr> I get unlimited bandwidth and 10gb of space.
07:45:37 <Beelsebob> that's about what I pay, for the same shapr 
07:45:57 <astrolabe> How can they offer unlimited bandwidth?
07:46:16 <Beelsebob> they offer as much bandwidth as the connection can support
07:46:24 <shapr> I think it's because they have their servers hosted at one of the massive NOCs in Atlanta.
07:46:36 <vincenz> NOC?
07:46:37 <astrolabe> Ah I see.
07:46:42 <Beelsebob> mine's in london somewhere
07:46:45 <shapr> Network Operating Center
07:46:49 <vincenz> oh
07:46:55 <vincenz> I was thinking of something else
07:47:05 <vincenz> like in the movie "recruit"
07:47:11 <shapr> Bandwidth is cheap when you're sitting on one of the biggest international network points.
07:47:25 <Beelsebob> heh
07:47:36 <Beelsebob> indeed - this is why being at uni of Kent is fun
07:48:38 <astrolabe> I wonder where the most dense information flow is.
07:48:56 <shapr> So, I'm thinking about what I'd need to build a general purpose Haskell framework thingy. I started thinking about a webapp server, but I have something more general in mind.
07:49:35 <shapr> The design is simple, write an hs-plugins dynloading server, then plugins for various protocols.
07:49:40 <boy> data Foo = Bar | N Int
07:49:48 <boy> how do i make this showable?
07:49:54 <shapr> deriving Show
07:50:17 <shapr> Sounds too simple even.
07:50:21 <bolrod> yeah
07:50:33 <boy> how do i do that? :)
07:50:37 <bolrod> erh
07:50:39 <shapr> But I realize this would be good for a bunch of things.
07:50:48 <bolrod> write deriving Show beneath the data. ....
07:50:54 <shapr> Lots of people have wished for cron-like functionality in lambdabot
07:51:05 <boy> i want to write my own show function though
07:51:12 <shapr> I've wished for an easy way to index data and search through it.
07:51:37 <bolrod> instance Show Foo  where
07:51:49 <bolrod> then implement the show function
07:52:28 <bolrod> shapr: call google and ask how they do it
07:52:35 <bolrod> ^.^
07:52:54 <shapr> Actually, it'd be easy enough to steal kimbly's inverted index code.
07:53:04 <bolrod> just search the patents for methods  *cough* *cough*
07:53:05 <shapr> Thing is, it sounds too good to be true.
07:53:18 <bolrod> whats that method?
07:53:43 <shapr> No, I mean a server that loads stuff via hs-plugins.. it sounds too good to be true.
07:53:51 <shapr> Am I missing something obvious?
07:54:16 <bolrod> I dont know how it works .. so.. 
07:54:20 <Saulzar> You might ask the hIDE people :)
07:54:24 <astrolabe> There is no simple way to index all large datasets.
07:55:13 <bolrod> or nobody has thought of it yet
07:55:33 <astrolabe> I think there are too many possible queries.
07:55:43 <shapr> I'm just thinking of ways to build a general purpose app server.
07:56:06 <astrolabe> So what is the general use case for this thing?
07:56:15 <shapr> A cron service is pretty obvious and simple.
07:56:33 * astrolabe googles cron
07:56:43 * shapr thinks
07:57:28 <shapr> I'd like to be able to easily access services like data indexing,timed callbacks events, etc from any Haskell program.
07:57:52 <sieni> data indexing? what's that?
07:57:57 <shapr> and I'd like to write new services
07:58:14 <boy> f 1 x y = 5
07:58:16 <boy> f 2 x y = 6
07:58:30 <shapr> sieni: I want a database backend, and I don't want to have to care what backend is being used.
07:59:01 <boy> can i have a common where clause in the definition of both of these?
07:59:11 <boy> like where foo = x + y
07:59:14 <shapr> boy: yup
07:59:15 <bolrod> > let f a _ _ = a +4 in f 5 4 2
07:59:16 <lambdabot> 9
08:00:06 <shapr> astrolabe: I want to write CGI programs that access databases and don't have to reload all the HaskellDB code for each program invocation.
08:00:40 <astrolabe> That's sensible.
08:01:20 <shapr> I'd also like to be able to access all of lambdabot's cool Haskell developer tools the same way.
08:01:42 <astrolabe> I can imagine a server that had some specific code-base loaded continually that would evaluate expressions for clients to save them loading the code-base.
08:02:08 <shapr> And I'd like to be able to write new plugins/services for this system.
08:02:08 <shapr> Right, that's where I'm heading.
08:02:29 <shapr> Philippa suggested that I run a daemon that does nothing more than load code via hs-plugins.
08:02:34 <astrolabe> Yeah.  Sounds good.  That's how I use lambdabot now for @type, @eval etc.
08:03:05 <shapr> dons recently modified lambdabot to run on the command line without irc for just those tools.
08:03:36 <shapr> So I see a convergence waiting to happen...
08:04:21 <astrolabe> A web page that accessed lambdabot would be useful.
08:05:17 <astrolabe> particularly if it could see various databases.
08:07:39 <JohnnyL> can anyone help with ghc install? ohn@linux:/dl/ghc-6.4.2.20060406> ghc
08:07:39 <JohnnyL> /usr/local/lib/ghc-6.4.2.20060406/ghc-6.4.2.20060406: error while loading shared libraries: libreadline.so.4: cannot open shared object file: No such file or directory
08:08:20 <pejo> JohnnyL, you need to set your LD_LIBRARY_PATH to point to a place where libreadline.so.4 is.
08:08:28 <shapr> JohnnyL: what does "locate libreadline.so.4" give you?
08:09:17 <mathrick> data Tree a = Leaf a | Branch (Tree a) (Tree a)
08:09:17 <mathrick> (>>=) :: Tree a -> (a -> Tree a) -> Tree a
08:09:17 <mathrick> (>>=) (Leaf a) f = (Leaf (f a))
08:09:17 <mathrick> (>>=) (Branch (Tree a) (Tree b)) f = (Branch (f a) (f b))
08:09:23 <bolrod> JohnnyL: you tried to compile the ghc?
08:09:23 <mathrick> does this look correct?
08:09:44 <JohnnyL> locate not found.
08:09:45 <JohnnyL> lol.
08:09:49 <bolrod> seriously
08:09:51 <mathrick> hmm
08:09:52 <bolrod> thats not cool
08:09:54 <JohnnyL> boldrod, yes.
08:10:01 <bolrod> you should have locate!
08:10:03 <mathrick> (>>=) (Leaf a) f = f a
08:10:05 <mathrick> I guess
08:10:08 <bolrod> what distro do you have?
08:10:14 <Lemmih> mathrick: Shouldn't it be '(Branch a b) >>= f = Branch (f a) (f b)'?
08:10:32 <shapr> mathrick: Isn't that more of a Functor instance?
08:10:48 <JohnnyL> suse
08:10:51 <mathrick> Lemmih: infix vs. prefix? that shouldn't matter
08:10:56 <mathrick> shapr: uh?
08:11:04 <bolrod> ic...  isn't the ghc in the repository?!
08:11:09 <Lemmih> mathrick: I also removed the 'Tree's.
08:11:10 <bolrod> its much easier to just install an rpm
08:11:34 <mathrick> Lemmih: well, but I need to unpack the args for my function
08:11:43 <Lemmih> mathrick: Oh, and the type of (>>=) should be 'Tree a -> (a -> Tree b) -> Tree b'.
08:12:07 <Lemmih> mathrick: data Tree a = Leaf a | Branch (Tree a) (Tree b), right?
08:12:35 <bolrod> JohnnyL: well?
08:12:49 <mathrick> Lemmih: well, the starting point as given above was data Tree a = Leaf a | Branch (Tree a) (Tree a)
08:12:59 <mathrick> so it's for homogenous trees
08:13:26 <Lemmih> mathrick: Right, I missed that. But you still don't need to unpack the args.
08:13:43 <mathrick> Lemmih: you're right about 'Tree a -> (a -> Tree b) -> Tree b' tho, I think
08:13:45 <JohnnyL> `bolrod, that all depepends on what you mean by repository.
08:13:49 <mathrick> Lemmih: I do
08:14:01 <bolrod> look in the Yast2 or something.. what is it now
08:14:03 <Lemmih> mathrick: No, you don't.
08:14:03 <mathrick> Lemmih: look at (>>=) type signature
08:14:30 <bolrod> or with rpm...  I dont really know how suse works
08:14:30 <mathrick> (a -> Tree b)
08:14:40 <Lemmih> mathrick: Right, so: Branch a b >>= f = Branch (a >>= f) (b >>= f)
08:15:12 <mathrick> Lemmih: I gues that's equivalent, yeah
08:15:54 <mathrick> but if I read it correctly, it shouldn't yield different results, right?
08:16:26 <Lemmih> mathrick: Well, 'Branch (Tree a) (Tree b)' isn't valid Haskell.
08:16:51 <mathrick> it isn't?
08:17:03 <mathrick> well, I guess it's not
08:17:05 <mathrick> right
08:18:26 <mathrick> now, I wonder how one'd monadify a (more useful) tree type like this:
08:18:26 <mathrick> data Tree a = Leaf a | Branch (Tree a) a (Tree a)
08:18:33 <boy> what should i call an operator that concatenates strings while putting a space between them?
08:18:49 <mathrick> boy: :+ perhaps?
08:19:08 <JohnnyL> boldrod, nothing in the suse 'repository'.
08:19:28 <boy> mathrick: ok thanks :)
08:19:37 <Lemmih> mathrick: That's pretty much the same. You just do for the Branch case what you did in the Leaf case.
08:19:45 <JohnnyL> well i have hugs, thats a start.
08:19:47 <boy> how can i show a number in base hex?
08:20:04 <JohnnyL> installing on linux requires a degree in insanity.
08:20:25 <Lemmih> mathrick: Oh, and 'Leaf a >>= f = f a'.
08:20:44 <mathrick> Lemmih: I corrected that
08:21:00 <mathrick> Lemmih: however, what do you mean by "do for the Branch case what you did in the Leaf case"?
08:21:09 <bolrod> JohnnyL: installing SuSE does
08:21:10 <bolrod> ;)
08:21:12 <mathrick> the problem with f is that it returns a tree
08:21:28 <mathrick> and I need a value to put in a branch
08:21:59 <Lemmih> mathrick: Right, and how to you get a value of the a Tree?
08:22:20 <boy> mathrick: actually i think that (:+) is an invalid operator! :O
08:22:29 <bolrod> why?
08:22:43 <boy> > let x (:+) y = x + y in 3 :+ 6
08:22:43 <mathrick> boy: I thought all :* ops were reserved for the user?
08:22:44 <lambdabot>  Not in scope: data constructor `:+'
08:22:52 <bolrod> indeed
08:22:55 <Muad_Dib> installing on gentoo is very simple :)
08:22:56 <boy> > let x (&+) y = x + y in 3 &+ 6
08:22:57 <lambdabot>  Not in scope: `&+'
08:22:57 <bolrod> its a data constructor
08:23:27 <mathrick> Lemmih: well, I'd need to create a helper to extract it for me, I guess
08:23:28 <bolrod> data Foo = Bar :+ Bar   might be perfectly fine I guess
08:23:38 <mathrick> boy: ()
08:23:46 <mathrick> boy: it makes it prefix
08:23:56 <Lemmih> mathrick: fn val >>= \extractedVal -> ...
08:23:56 <mathrick> > let x :+ y = x + y in 3 :+ 6
08:23:57 <lambdabot>  Not in scope: data constructor `:+'
08:24:18 <bolrod> an operator that starts with : is a constructor operator
08:24:22 <mathrick> Lemmih: yeah, that's what I mean
08:24:31 <boy> > let x &+ y = x + y in 3 &+ 6
08:24:32 <mathrick> bolrod: oh
08:24:32 <lambdabot> 9
08:24:44 <mathrick> bolrod: what's a constructor operator?
08:24:56 <bolrod> data Foo = Bar :+ Bar
08:25:03 <mathrick> and that means what?
08:25:24 <bolrod> data Foo = (:+) Bar Bar   ?
08:25:31 <bolrod> data Foo = Constructor Bar Bar   ?
08:26:09 <bolrod> > let  data Foo = Bar :+ Bar in Bar :+ Bar 
08:26:10 <lambdabot>  parse error on input `data'
08:26:16 <bolrod> ok..
08:30:52 <mathrick> what I still don't get, however, is how does using IO monad make it in any way deterministic
08:33:33 <bolrod> http://www.scriptol.org/choose.php   << O_o?
08:34:22 <boy> what's better style: fooFromBar or barToFoo?
08:36:31 <Saulzar> In the standard library they use fromBar exclusively (but that's with typeclasses)
08:37:09 <Saulzar> bolrod, They don't make haskell sound very inspiring...
08:37:24 <boy> > isSigned (3::Word8)
08:37:25 <lambdabot> False
08:37:26 <Saulzar> "Functional programming. Slow and memory consuming.  To try programming in another way"
08:37:33 <bolrod> indeed :/
08:37:35 <boy> > bitSize (3::Word8)
08:37:36 <lambdabot> 8
08:37:41 <boy> > isSigned (3::Int8)
08:37:42 <lambdabot> True
08:37:48 <boy> > bitSize (3::Int8)
08:37:49 <lambdabot> 8
08:38:12 <bolrod> > bitSize (2134444444444444444444444444444444444444444444444444444444444444444234234444444444444443222222222222222222222222444444444 ::Integer)
08:38:13 <lambdabot> Exception: Data.Bits.bitSize(Integer)
08:38:18 <bolrod> :o?!
08:38:23 <Saulzar> Well they give somewhat random coments for half the languages...
08:38:34 <bolrod> yeah 
08:38:42 <Lemmih> bolrod: bitSize ignores the value of its argument.
08:38:43 <Saulzar> C, C++ "Suffering slow programming to make fast programs. For system programming."
08:39:17 <bolrod> it does ? -,-
08:39:24 <Lemmih> > bitSize (undefined :: Int)
08:39:25 <lambdabot> 32
08:39:30 <bolrod> bah
08:39:31 <bolrod> :)
08:39:38 <bolrod> @hoogle size
08:39:38 <lambdabot> Data.IntMap.size :: IntMap a -> Int
08:39:38 <lambdabot> Data.IntSet.size :: IntSet -> Int
08:39:38 <lambdabot> Data.Map.size :: Map k a -> Int
08:39:46 <bolrod> bwah
08:39:50 <mathrick> Assembler
08:39:50 <mathrick> 	This is near the machine language and the fastest. You should never use it, as older programmers did.
08:39:53 <mathrick> ...
08:40:04 <bolrod> wel you shouldn't use it...
08:40:04 <araujo> morning
08:40:15 <bolrod> unless you know every cpu optimisation 
08:40:16 <bolrod> ;)
08:40:28 <bolrod> in which case... probably fiddle with the compiler flags
08:41:40 <astrolabe> I bet it's still quicker than compiled C, even if you aren't an expert.
08:41:49 <mathrick> bolrod: that's not true
08:42:09 <bolrod> what use does it have...    C is fast enough
08:42:13 <bolrod> probably easier to debug
08:42:17 <mathrick> astrolabe: depends. It's hard to make big programs that are quicker than what compiler does
08:42:19 <bolrod> and portable
08:42:21 <astrolabe> fast enough for what?
08:42:28 <mathrick> however, for a local, small optimisations, assembly is very handy
08:42:28 <bolrod> say you fidle with the ASM code..
08:42:30 <Saulzar> Can't always get the special opcodes from C, bit search functions for example :)
08:42:35 <bolrod> and then you screw up 10 other optimisations
08:42:38 <bolrod> thats NOT good
08:42:50 <astrolabe> mathrick: right, it is only worthwhile on the time consuming bits.
08:43:08 <mathrick> however, seeing asm as something that's "omg fast" is silly
08:43:16 <boy> is there a builtin way to convert a Word8 that contains a signed value to an Int8? this should just be a really fast internal cast...
08:43:17 <mathrick> there are many other reasons to use assembly
08:43:35 <bolrod> its probably easier to think of a better algorythm in some cases then fiddle with the ASM to get it a tiny bit faster
08:43:40 <astrolabe> I see asm as OMG fast.
08:44:24 <Lemmih> bolrod: fromIntegral.
08:44:30 <astrolabe> borod: Some algorithms are hard to improve.
08:44:41 <mathrick> bolrod: *bzzzt*
08:44:44 <bolrod> yes..
08:45:03 <bolrod> so then you can fiddle with the ASM... if you know what you're doing
08:45:09 <bolrod> (I don't anyway )
08:45:10 <bolrod> :)
08:45:11 <astrolabe> Also it isn't an either/or choice.
08:45:17 <mathrick> bolrod: let go of your "fiddling"
08:45:23 <mathrick> astrolabe: exactly
08:45:27 <Lemmih> boy: fromIntegral.
08:45:42 <bolrod> so when would you need ASM for your normal programs
08:45:43 * Lemmih stabs his tab-completion.
08:45:45 <boy> Lemmih: but that doesn't work
08:45:58 <bolrod> when comes the point.. Hey! lets program this in ASM :)
08:45:59 <Lemmih> boy: Sure it does (:
08:46:43 <boy> > (fromIntegral (129::Word8)) :: Int8
08:46:44 <lambdabot> -127
08:47:00 <boy> whoah you are right
08:47:06 <mathrick> bolrod: you're very welcome to learn assembly, you'll see it then
08:47:07 <boy> duh!
08:47:10 <boy> :)
08:47:15 <bolrod> ok :)
08:47:22 <boy> > (fromIntegral (255::Word8)) :: Int8
08:47:23 <lambdabot> -1
08:47:38 <bolrod> duh...   it flips around ;)
08:47:39 <astrolabe> One of the best go programs from a few years ago was written entirely in assembly.  I don't know why, but it was very fast.
08:47:44 <boy> Lemmih: actually it's not correct
08:47:58 <bolrod> 11111111  (bits )= -1
08:48:26 <boy> bolrod: yeah, but 11111111 should be -127
08:48:32 <bolrod> no
08:48:34 <bolrod> it isn't
08:48:48 <bolrod> 11111110 = -2
08:48:51 <bolrod> etc.
08:49:00 <boy> bolrod: hm.... you are sure about this?
08:49:08 <bolrod> you just wrote it yourself ;)
08:53:21 <Saulzar> twos compliment
08:54:41 <bolrod> yep
08:57:27 <pierre-> hello.
09:06:00 <Saulzar> astrolabe, A lot of the better chess programs are not particually hard wired with assembler... some are, of course
09:16:15 <astrolabe> Yeah, I think a contain assembler.
09:16:26 <astrolabe> I think a lot contain assembler.
09:17:44 <Descolada|Work> no memos!
09:17:59 <vincenz> astrolabe: yeah especially when compiled
09:20:58 <Pegazus> [x ++ y, x <- xs, y <- ys] == head([ [x ++ y, y <- ys], x <- xs] ]) == how to do this with maps, without using lists?
09:21:24 <JohnnyL> are most of the #haskell er's students?
09:22:33 <vincenz> Pegazus: that' is wrong
09:22:36 <vincenz> oh nm
09:23:09 <vincenz> Pegazus: ys and xs are lists of lists
09:23:18 <vincenz> and it's
09:23:22 <Pegazus> i mean comprenhensive lists
09:23:24 <Pegazus> the [] ones
09:23:28 <vincenz> [x++y| x<xs, y<-ys]
09:23:39 <vincenz> Pegazus: but for that to work, x and y  must be lists
09:23:44 <vincenz> so xs and ys must be lists of lists
09:23:58 <Pegazus> they are
09:25:18 <Pegazus> so how to do it?
09:25:26 <vincenz> map (\x -> map (\y -> x++y) ys) xs
09:26:21 <araujo> JohnnyL, and hobbist programmers too
09:26:38 <araujo> i think there was data about it somewhere
09:27:51 <Pegazus> thanks
09:30:01 <JohnnyL> how do I run a file from within hugs?
09:42:44 <JohnnyL> how can I list my function (such as main) from within the hugs interpreter/
09:42:45 <JohnnyL> ?
09:43:12 <flux__> I don't actually know, but I doubt it
09:44:31 <Saulzar> Not sure about hugs, but ghci you can do :browse <module> to see the names/types inside
09:44:54 <Lemmih> JohnnyL: :?
09:45:33 <JohnnyL> :borwse is in the help list, but If I type :browse main, i get unknown module.
09:45:42 <Lemmih> JohnnyL: Try Main.
09:48:08 <JohnnyL> that works but only slightful helpful. doesn't list it's contents, only the type, the declaration.
09:48:22 <JohnnyL> :browse Main
09:48:22 <JohnnyL> module Main where
09:48:22 <JohnnyL> main :: IO ()
09:48:22 <JohnnyL> Main>                
09:49:21 <Saulzar> Yep, go look at the file if you want the actual definition
09:49:31 <Lemmih> JohnnyL: Try :!cat module.hs
09:51:53 <JohnnyL> !:cat "hello.hs"
09:51:53 <JohnnyL> sh: :cat: command not found
09:51:53 <JohnnyL> Warning: Shell escape terminated abnormally
09:52:10 <JohnnyL> i can't believe that hugs doesn't have a way to inspect functions
09:52:39 <Lemmih> You usually use an editor for that.
09:53:49 <JohnnyL> no, the hugs interpreter needs that as a function.
09:53:59 <Cale> why?
09:54:24 <Cale> I suppose it's more plausible that hugs could do it than ghci
09:57:40 <JohnnyL> Cale because even with Commodore basic you can list the contents in the interpreter, and that was made in 1980!
09:58:11 <Cale> There's :e
09:58:30 <Lemmih> Even in C you can mutate variable, and that was made in 1970!
09:58:43 <JohnnyL> thats a compiler.
09:58:59 <Cale> why just list, when you can load a proper editor with syntax highlighting and folding and such :)
09:59:24 <JohnnyL> Cale, thats the sort of response I expect from an opensource programmer. :)
09:59:41 <JohnnyL> but i hear ya.
10:00:06 <Cale> I mean, sure, it's a feature which is missing, but I've never really felt like I needed it
10:01:00 <jyp> Maybe in ndm's WinHugs ?
10:01:21 <Lemmih> Doesn't WinHugs include an editor?
10:03:11 <jyp> I wouldn't know.
10:07:05 <RyanT5000> what's the haskell equivalent of "merge"?
10:07:17 <Cale> what merge?
10:07:34 <RyanT5000> merge :: (a -> b -> c) -> [a] -> [b] -> [c]
10:07:34 <Cale> merge [] ys = ys
10:07:35 <Cale> merge xs [] = xs
10:07:35 <Cale> merge (x:xs) (y:ys) = case compare x y of
10:07:35 <Cale>     LT -> x : merge xs (y:ys)
10:07:35 <Cale>     EQ -> x : y : merge xs ys
10:07:36 <Cale>     GT -> y : merge (x:xs) ys
10:07:40 <Cale> oh
10:07:47 <Cale> that's zipWith
10:07:48 <RyanT5000> no not as in merge sort
10:07:54 <RyanT5000> alright thanks
10:07:58 <Cale> @type zipWith
10:07:59 <lambdabot> forall c b a. (a -> b -> c) -> [a] -> [b] -> [c]
10:08:15 <jyp> @hoogle (a -> b -> c) -> [a] -> [b] -> [c]
10:08:16 <lambdabot> Prelude.zipWith :: (a -> b -> c) -> [a] -> [b] -> [c]
10:08:16 <lambdabot> Control.Parallel.Strategies.parZipWith :: Strategy c -> (a -> b -> c) -> [a] -> [b] -> [c]
10:08:28 <jyp> just great :)
10:09:33 <RyanT5000> ** is "to the power of" right?
10:09:51 <Igloo> RyanT5000: You might want ^ depending on what you are doing
10:10:45 <jcreigh> Igloo: What's the difference?
10:11:28 <Igloo> The type, primarily (and different implementation follows from that)
10:12:11 <Igloo> There's also ^^, but ISTR that is rarely wanted
10:12:27 <JohnnyL> i'm a haskell newbie, i get Main> length                  :: [a] -> Integer
10:12:27 <JohnnyL> ERROR - Type error in type annotation
10:12:27 <JohnnyL> *** Term           : length
10:12:27 <JohnnyL> *** Type           : [b] -> Int
10:12:27 <JohnnyL> *** Does not match : [a] -> Integer
10:12:28 <JohnnyL>  when I cut and paste into hugs interpreter. does it need to be in a file?
10:12:46 <Igloo> Yes
10:13:24 <Igloo> Well, you could say   let length :: [a] -> Integer; length = ... in ..., but it's probably easier to stick it in a file
10:14:19 <flux__> johnnyl, btw, ghc/hugs are also compilers (latter being a byte-code compiler I believe?) and they don't keep the function definition around because it isn't required
10:14:50 <Igloo> hugs isn't a compiler
10:15:04 <flux__> not even bytecode?-o
10:15:44 <flux__> I suppose just generating parsetrees can't be counted as compiling though, so you're probably right
10:15:57 <flux__> (that is, if it does only use parse trees)
10:16:56 <flux__> well, hugs could in that case output the parse tree, although it wouldn't look like the original (atleast comments would be gone)
10:18:22 <flux__> as the haskell web, faq nor the documentation mention compiling in this context, I'm willing to accept that ;)
10:20:56 <JohnnyL> et length::[a]->Integer; length (x:xs)           =  1 + length xs
10:20:56 <JohnnyL> ERROR - Syntax error in expression (unexpected end of input)
10:21:02 <JohnnyL> sorry
10:21:08 <JohnnyL> let length *
10:25:41 <Saulzar> JohnnyL, the local let syntax only works in ghci as far as I know (not hugs)
10:27:39 <JohnnyL> ah
10:27:40 <JohnnyL> k
10:27:40 <palomer> <:o
10:27:41 <JohnnyL> i see.
10:27:45 <palomer> Hello World!
10:44:00 <heatsink> I'm having trouble with higher kinds... http://www.nomorepasting.com/paste.php?pasteID=60511
10:44:26 <heatsink> The definition of runErrST doesn't pass typecheck.
10:47:45 <pierre-> can you help me? I want to build a binary tree from a list such as "Node Node Leaf 1 Leaf 2 Node Leaf3 Node Leaf4 Leaf5" -- but i have no idea how can i functionally implement it...
10:47:48 <KirinDave> Excuse me. Could someone give me some pointers on possibly getting GHC to run on an intel mac?
10:48:05 <xerox> KirinDave, the DMG on the site works, under Rosetta, but works.
10:48:16 <KirinDave> xerox: I am trying to set up darcs.
10:48:22 <KirinDave> xerox: It's too slow under rosetta
10:48:54 <KirinDave> xerox: If I installed the rosetta variant, do you think that'd make a suitable base for recompiling ghc under macintel?
10:48:59 <xerox> They were saying that people is working on porting it atm.  I personally didn't check the mailing lists, tho.
10:49:19 <ircleuser> Hello.
10:49:25 <xerox> KirinDave, I think so.  At least I suspect it could work.
10:49:36 <KirinDave> I hope it will.
10:49:40 <mathrick> pierre-: depends on what complexity you want to have
10:49:43 <xerox> KirinDave, which mac did you get? :-)
10:49:50 <KirinDave> The macbook pro.
10:50:05 <Seraph_> I've got a question, I keep trying to compile my code in GHC but I get this error:sudokuopt.hs:12:0:
10:50:05 <Seraph_>     Couldn't match `IO a' against `t -> t1'
10:50:05 <Seraph_>       Expected type: IO a
10:50:05 <Seraph_>       Inferred type: t -> t1
10:50:06 <Seraph_>       Expected type: IO a
10:50:08 <Seraph_>       Inferred type: Int -> [Int] -> [[Int]]
10:50:11 <Seraph_>     In the first argument of `GHC.TopHandler.runMainIO', namely `main'
10:50:30 <mathrick> pierre-: if O(n logn) is enough for you, then simple divide and conquer is trivial, you just need drop and take functions.
10:51:00 <Lemmih> Seraph_: 'main' should be of type IO ().
10:51:15 <Seraph_> k
10:51:21 <mathrick> pierre-: however, if you want O(n), then it's more complex... like, I'm just working on it :)
10:51:26 <Seraph_> so should i just make main a function that prints out the result?
10:51:53 <mathrick> @type lookup
10:51:54 <lambdabot> forall b a. (Eq a) => a -> [(a, b)] -> Maybe b
10:52:31 <Seraph_> how do i read input from the console?
10:52:46 <heatsink> Seraph_: getLine
10:53:28 <mathrick> @type fromJust
10:53:29 <lambdabot> Not in scope: `fromJust'
10:53:35 <mathrick> @index fromJust
10:53:35 <lambdabot> Data.Maybe
10:53:42 <mathrick> @type Data.Maybe.fromJust
10:53:42 <lambdabot> forall a. Maybe a -> a
10:53:43 <Seraph_> @getLine
10:53:43 <lambdabot> Unknown command, try @list
10:53:58 <mathrick> @docs Var
10:53:58 <lambdabot> Var not available
10:54:03 <mathrick> @index Var
10:54:03 <lambdabot> bzzt
10:54:09 <mathrick> @hoogle Var
10:54:09 <lambdabot> Language.Haskell.TH.VarE :: Name -> Exp
10:54:09 <lambdabot> Language.Haskell.TH.VarI :: Name -> Type -> Maybe Dec -> Fixity -> Info
10:54:09 <lambdabot> Language.Haskell.TH.VarP :: Name -> Pat
10:55:04 <KirinDave> xerox: Do you know how to build ghc from scratch?
10:55:15 <KirinDave> I'd much appreciate some advice about how to go about this.
10:57:11 <xerox> KirinDave, I heard that it would be as simple as doing sh configure && make && make install.
10:57:35 <KirinDave> xerox: So I'll keep the existing haskell that runs under rosetta in my path.
10:57:36 <KirinDave> Okay.
10:57:58 <xerox> I don't know how one does create the DMG, tho.
10:58:07 <xerox> But that's probably the least important problem as now.
10:58:13 <KirinDave> Ahh
10:58:15 <KirinDave> I know all that.
10:58:20 <KirinDave> I just need binaries. :)
10:58:42 <KirinDave> Then I will share them with the world, and use them to finish my RubyOnRails+Darcs plugin. :)
10:59:02 <heatsink> These two definitions of "run" look equivalent to me, but the first definition doesn't typecheck... what's going on? http://www.nomorepasting.com/paste.php?pasteID=60513
10:59:54 <davidhouse> heatsink: "  data X a b = X (a -> a)" you parametrising over three variables, but only using two
11:00:13 <heatsink> davidhouse, I'm parametrizing over two variables, but only using one
11:00:22 <davidhouse> err, yeah, that one
11:00:29 <heatsink> That's not a problem.
11:01:27 <davidhouse> parameter order?
11:01:53 <xerox> No the problem is really about higher-rank polymorphism it seems.
11:02:02 <davidhouse> with the second, you'd supply the parameters like run x (X a b), but with the first it's the other way around
11:02:17 <xerox> davidhouse, I don't think so.
11:02:29 <heatsink> davidhouse: the X constructor only has one parameter, of type (a -> a)
11:02:31 <xerox> davidhouse, eta-reduce it?
11:02:50 <xerox> f x = (...) x    f = (...)
11:02:59 <davidhouse> xerox, eta-reduce which one?
11:03:09 <KirinDave> Argh
11:03:26 <palomer> is the typed KS calculus turing complete?
11:03:49 <xerox> KirinDave?
11:04:02 <palomer> actually, it can't be
11:04:09 <KirinDave> Whoever built the macosx version of ghc, not the .pkg version, linked to their own home directory.
11:04:21 <davidhouse> heatsink: ah yeah, sorry, so in the first one you'd call it like run (X f) x, but with the second it'd be run x (X f)
11:04:25 <xerox> KirinDave, urgh.
11:04:27 <KirinDave> I'm gonna have to use the .pkg and hope. 
11:06:55 <heatsink> davidhouse: the first one is [| run (X f) y = f y |]; the second one is [| run (X f) y = f y |]
11:07:20 <heatsink> davidhouse, the difference is where the X data gets deconstructed
11:07:35 <xerox> KirinDave, http://hackage.haskell.org/trac/ghc/wiki/Contributors  Maybe you could mail that guy.
11:07:56 <KirinDave> xerox: Thanks.
11:08:16 <nemostultae> KirinDave: huh? What do you mean linked to their own home directory?
11:08:34 <KirinDave> nemostultae: It expects libraries to be in /Users/wolfgang/
11:08:52 <davidhouse> @type let run x = \f -> f x in run
11:08:53 <lambdabot> forall t t1. t -> (t -> t1) -> t1
11:09:06 <davidhouse> hmm, okay, i'm wrong.
11:09:25 <davidhouse> > let run x = \f -> f x in run 'c' toUpper
11:09:26 <lambdabot> 'C'
11:09:40 <davidhouse> wait, no.
11:09:51 <davidhouse> i'm right. you provide the argument first.
11:10:09 <lightstep> does ocaml have higher-ranked types in its class system? i mean, methods with an internal quantifier
11:10:56 <davidhouse> or am i... perhaps the issue is more complicated, your pattern matching isn't the same as mine
11:10:57 <nemostultae> KirinDave: Do a otool -L /usr/local/lib/ghc-6.4.1/ghc-6.4.1. Looks fine to me.
11:11:08 <KirinDave> nemostultae: But running it fails.
11:11:18 <KirinDave> However, the .pkg version works fine
11:11:25 <davidhouse> @type let run x = (\f -> f) x in run
11:11:26 <lambdabot> forall t. t -> t
11:11:33 <KirinDave> I may be able to just build it without issue.
11:11:36 <KirinDave> Which would be funny. :)
11:12:14 <xerox> KirinDave, I'm very interested in the result too.
11:12:16 <heatsink> davidhouse: that's id
11:12:21 <davidhouse> clearly.
11:12:22 <newsham> hi
11:12:29 <KirinDave> If that's the case, I'll make sure to make it available.
11:12:35 <KirinDave> I read the ars writeup on these core processors.
11:12:43 <KirinDave> The're pretty neat.
11:13:07 <davidhouse> heatsink: it's a weird use of lambda
11:13:10 <xerox> I'm enjoying them too :-)
11:13:27 <heatsink> davidhouse: It's just deconstructing x.
11:13:41 <bolrod> sjanssen: Yo
11:13:44 <KirinDave> Shit.
11:13:49 <bolrod> you read that last post on the libraries mailing list
11:13:49 <xerox> Oww.
11:13:50 <KirinDave> Didn't work. :(
11:13:59 <bolrod> ?
11:14:01 <KirinDave> error: invalid register name for 'R1'
11:14:16 <KirinDave> It's using the binary images from ppc, not intel.
11:14:18 <lightstep> run (X f) y = f y -- also doesn't check
11:14:32 <xerox> KirinDave, oh-uhm.
11:14:37 <KirinDave> Oh well. :(
11:14:50 <KirinDave> Anyways, thanks for your advice, xeros.
11:14:56 <KirinDave> Err, xerox 
11:14:58 <xerox> You're welcome.
11:15:43 <davidhouse> lightstep: does it work without the type annotation?
11:16:30 <lightstep> yes, and says run :: X a b -> a -> a
11:17:55 <davidhouse> what about if you make it data X a = a -> a and remove the inner forall?
11:18:11 <davidhouse> err, data X a = X (a -> a)
11:19:03 <heatsink> davidhouse, that would work.  But I couldn't apply that to my code that calls runST.
11:19:05 <heatsink> @index runST
11:19:06 <lambdabot> Control.Monad.ST.Lazy, Control.Monad.ST, Control.Monad.ST.Strict
11:19:09 <heatsink> @type runST
11:19:10 <lambdabot> Not in scope: `runST'
11:19:36 <lightstep> i could check all the possibilities, but it would just work, since run's type is like the ones inferable by HM
11:19:38 <davidhouse> @type Control.Monad.ST.runST
11:19:39 <lambdabot> forall a. (forall s. GHC.ST.ST s a) -> a
11:19:58 <JohnnyL> Anyone here think that haskell will become a worldy used language, such as java?
11:21:14 <heatsink> JohnnyL, perhaps if it gets used as the development platform for an end-user project that is both popular and visible.
11:21:59 <lightstep> haskell has a problem with syntax
11:23:39 <heatsink> Haskell has significant whitespace.  You can't see significant whitespace! How can it possibly be significant if you can't see it?? I'm not using this dopey language!!!
11:24:20 <Descolada|Work> thank you
11:24:35 <Saulzar> I think Haskell syntax is great (admittedly arrays and records are slightly awkward)
11:24:58 <Descolada|Work> records are very awkward
11:25:37 <lightstep> Saulzar, i was thinking about the `do' syntax. i really miss mif, mcase, and loops
11:25:42 <Descolada|Work> other then that, i like it
11:25:54 <Saulzar> lightstep, You can easily add such features yourself...
11:26:16 <lightstep> how?
11:26:28 <lightstep> my maching isn't strong enough to compile ghc
11:27:00 <Saulzar> > let forM = flip mapM  in forM [1..10] $ (\x -> Just 3)
11:27:01 <lambdabot> Just [3,3,3,3,3,3,3,3,3,3]
11:27:40 <Saulzar> Substitute Just 3 for "print", but lambdabot won't do IO :)
11:27:53 <lightstep> but what about break? and continue? and easy indexing (zip isn't pretty)?
11:28:52 <lightstep> i know i could use Control.Monad.Fix.fix to get the general case, but i prefer some sugar on top of that
11:28:57 <Saulzar> You can define sub-routines with "let" very easily in a do block, and exceptions do well enough
11:29:36 <lightstep> (or, as you said, create the recursion with let)
11:29:43 <Lemmih> Thinking of a less imperative way of solving problems might also help.
11:29:50 <Saulzar> I don't think you need recursion 99% of the time
11:30:17 <Saulzar> After a while you get used to just mixing and matching and it's not so bad
11:31:07 <vincenz>  let forM = flip mapM  in forM [1..10] $ (\x -> x)
11:31:10 <vincenz> > let forM = flip mapM  in forM [1..10] $ (\x -> x)
11:31:11 <lambdabot>  add an instance declaration for (Show (m [b]))
11:31:16 <lightstep> i know, and using haskell is usually fun. but i still wish for a syntax extension mechanism that would allow me to use these idioms
11:31:41 <wchogg> Although, one thing I kindof miss in Haskell is not having the ability for "optional" arguments, i.e. overloading of function names with different variables.
11:31:51 <Saulzar> lightstep, Usually you can make the functionality you need 
11:32:27 <Saulzar> I just keep a file full of "handy functions" which get used over and over...
11:34:44 <heatsink> Saulzar, prelude?
11:34:48 <heatsink> :)
11:34:49 <wchogg> lightstep:  Well, as Template Haskell matures it might be possible to add syntactic extensions easily, but until then we'll never really have true macros.
11:35:03 <Saulzar> heatsink, Well, I have found some of them already in prelude from time to time :)
11:44:09 <Seraph_> whats a really efficient way to get an item from a list, given an index?
11:44:26 <boy> l !! i
11:44:29 <Seraph_> list !! index is bad, and i need to change it.
11:44:40 <mathrick> combM :: (a -> IO b) -> (b -> IO y) -> (a -> IO y)
11:44:40 <mathrick> combM f g x = return x >>= f >>= g
11:44:40 <mathrick> /tmp/foo.hs:24:8: Not in scope: data constructor `IO'
11:44:48 <mathrick> what's wrong with that declaration?
11:44:51 <Saulzar> Seraph_, Lists don't index fast, for that you need an array or map
11:44:54 <heatsink> Seraph_ : that's the fastest way to get a list item.  Perhpas you want an array?
11:45:20 <heatsink> mathrick: IO is not defined.  maybe import System.IO
11:45:20 <Seraph_> it is?
11:45:26 <mathrick> heatsink: ok
11:45:41 <Seraph_> so something like:
11:45:51 <mathrick> @index IO
11:45:51 <lambdabot> System.IO, Prelude
11:46:01 <mathrick> heatsink: still the same
11:46:56 <Seraph_> getItem (x:xs) index counter | index == count = x | otherwise = getItem xs index (counter+1) isn't better?
11:47:14 <Seraph_> index == counter, that is.
11:47:59 <heatsink> mathrick: It compiles for me.
11:48:15 <mathrick> heatsink: oh, I'll retry then, I might have broken my environment
11:48:49 <mathrick> heatsink: right, it was another line, sorry :)
11:48:51 <Lemmih> Seraph_: That's pretty much what (!!) does.
11:49:18 <mathrick> btw, how is combM called in standard haskell?
11:49:20 <Seraph_> Ah, weird. I profiled my code and apparently it says the functions where I'm using !! are taking the longest.
11:51:01 <Lemmih> Seraph_: Well, that might be right. If you're trying to use a list as an array then your code will be slow.
11:51:52 <heatsink> Seraph_: Do you know how often (!!) gets called?  For example, might it get called once for each list item?
11:52:07 <Seraph_> Ah.
11:52:13 <Seraph_> I don't think I can use arrays.
11:52:19 <Seraph_> I'd have to import a module, right?
11:52:29 <Seraph_> It gets called a lot.
11:52:36 <mathrick> @index combM
11:52:37 <lambdabot> bzzt
11:52:38 <boy> how i use hGetBuf? it needs a Ptr a, how can i convert a Word8 to Ptr a?
11:52:45 <mathrick> @index <>
11:52:45 <lambdabot> Language.Haskell.TH.PprLib, Text.PrettyPrint.HughesPJ, Text.PrettyPrint
11:52:48 <Seraph_> I retrieve a column a lot, and i retrieve rows a lot, i build each row and column by accessing the list at the correct index
11:53:42 <Seraph_> im given a long list of Ints as input, and i have to figure out how to get colums and rows from it
11:53:46 <Seraph_> basically the list is a matrix
11:54:26 <Lemmih> boy: You have a pointer in a Word8?
11:55:01 <boy> Lemmih: no... i mean how can i create a Ptr a value?
11:55:23 <Seraph_> Are there more efficient ways to extract colums and rows from a "matrix" that is actually a list?
11:55:47 <boy> Seraph_: i think you should use an array
11:56:07 <Lemmih> boy: You can allocate some memory and point to it.
11:56:25 <heatsink> Seraph_: If you want to extract a sub-list, then there are more efficient ways than using (!!) for each element of the sub-list.
11:56:30 <Seraph_> are there native arrays in haskell?
11:56:44 <Seraph_> heatsink, yes thats what i want to do
11:56:51 <boy> Lemmih: hm.... do you remember how one does this?
11:56:55 <heatsink> Seraph_, try using take and drop
11:56:57 <bolrod> anybody reading the libraries mailing list?
11:57:09 <Seraph_> heatsink: what is take and drop?
11:57:17 <heatsink> > take 3 $ drop 1 $ [1,5,4,3,8]
11:57:18 <lambdabot> [5,4,3]
11:57:22 <bolrod> take 10 takes first 10 of the list
11:57:33 <bolrod> if there are only 4 elements
11:57:34 <bolrod> it takes 4
11:57:43 <Lemmih> @docs Foreign.Marshal.Alloc
11:57:43 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Foreign-Marshal-Alloc.html
11:57:44 <bolrod> > take 10 [1,2,3,4]
11:57:44 <Seraph_> and drop?
11:57:45 <lambdabot> [1,2,3,4]
11:57:53 <bolrod> drops the first of the list
11:57:59 <bolrod> > drop 2 [1,2,3,4,5,6]
11:58:00 <lambdabot> [3,4,5,6]
11:58:01 <Seraph_> isnt that like tail?
11:58:03 <bolrod> > drop 10 [1,2,3,4,5,6]
11:58:04 <lambdabot> []
11:58:08 <bolrod> no
11:58:14 <bolrod> tail just drops the first
11:58:23 <boy> Lemmih: thanks
11:58:24 <bolrod> oh
11:58:25 <bolrod> andd
11:58:29 <bolrod> tail fails on empty list
11:58:31 <bolrod> > tail []
11:58:32 <lambdabot> Add a type signature
11:58:32 <Seraph_> so take and drop would be a hell of a lot more efficient? :)
11:58:38 <bolrod> eh
11:58:43 <bolrod> > tail [1,2]
11:58:44 <lambdabot> [2]
11:58:47 <bolrod> > tail []
11:58:48 <lambdabot> Add a type signature
11:58:52 <bolrod> > drop 1 []
11:58:53 <lambdabot> Add a type signature
11:59:04 <bolrod> guess not then
11:59:25 <bolrod> try in the ghci
11:59:28 <bolrod> tail fails
11:59:31 <Muad_Dib> > tail [] :: Int
11:59:32 <lambdabot> Couldn't match `Int' against `[a]'
11:59:33 <bolrod> drop returns empty list
11:59:41 <Muad_Dib> > tail [] :: [Int]
11:59:42 <lambdabot> Exception: Prelude.tail: empty list
11:59:43 <Muad_Dib> do'h
11:59:52 <bolrod> > drop 1 [] :: [Int]
11:59:53 <Muad_Dib> @ Int instead of [Int]
11:59:53 <lambdabot> []
12:00:01 <bolrod> there you have it
12:00:34 <bolrod> Muad_Dib: you following the libraries mailing list?
12:00:48 <Muad_Dib> nope
12:00:52 <bolrod> aye
12:01:08 <bolrod> ok.. dont execute the inits function .. just reason with your mind ;)
12:01:11 <Seraph_> would i have to import a module to use an array?
12:01:14 <bolrod> what is   'inits []'
12:01:23 <bolrod> import Array
12:01:28 <bolrod> Muad_Dib: well?
12:01:45 <bolrod> what would logically be   inits []
12:02:24 <lightstep> bolrod, just the empty list
12:02:25 <Muad_Dib> the opposite of tail i think
12:02:42 <bolrod> hrm
12:02:44 <Muad_Dib> I'd say an Exception: inits: empty list
12:02:45 <bolrod> its [[]]
12:02:59 <Muad_Dib> > inits [1,2,3]
12:03:00 <bolrod> empty list is a subset of the empty list
12:03:00 <lambdabot> [[],[1],[1,2],[1,2,3]]
12:03:04 <Muad_Dib> aah
12:03:07 <Muad_Dib> forget what i said
12:03:08 <bolrod> NOWWw
12:03:10 <Muad_Dib> I was thinking about init
12:03:15 <bolrod> hehe
12:03:19 <bolrod> what is  inits undefined
12:03:20 <Seraph_> is there a quick way to turn a list into an array?
12:03:38 <bolrod> array = listArray (bounds) [list]
12:03:43 <bolrod> erh..   just a list
12:03:46 <bolrod> not list in list
12:04:05 <Muad_Dib> bolrod: undefined
12:04:24 <bolrod> well...   my version of inits also returns [[]]
12:04:27 <bolrod> but I wonder what it really is
12:04:31 <bolrod> since [] is basically nothing
12:04:34 <Muad_Dib> > inits undefined
12:04:34 <lambdabot> Add a type signature
12:04:37 <bolrod> but what is undefined 
12:04:38 <Muad_Dib> > inits undefined :: a
12:04:39 <lambdabot>  a
12:04:39 <lambdabot>   Inferred type: [[a1]]
12:04:39 <lambdabot>   In the application `inits undefined'
12:04:46 <Muad_Dib> > inits undefined :: [[Int]]
12:04:47 <lambdabot> Undefined
12:04:53 <bolrod> > inits []
12:04:54 <lambdabot> Add a type signature
12:04:59 <bolrod> > inits [] :: [[Int]]
12:04:59 <lambdabot> [[]]
12:05:14 <Muad_Dib> undefined is not defined in any way
12:05:21 <bolrod> hmm.. true
12:05:36 <bolrod> still.. you couls ask yourself
12:05:41 <Muad_Dib> so the outcome of any function applied on undefined is also undefined
12:05:43 <bolrod> is nothing.. a subset of undefined
12:06:00 <palomer> is it possible to make copies of an ST store?
12:06:02 <bolrod> or should the subset of undefined be  [undefined]
12:06:33 <bolrod> it would make sense in a way to make   'inits undefined'  result in  [undefined] 
12:06:36 <bolrod> right?
12:06:47 <Muad_Dib> no
12:06:49 <bolrod> ok
12:06:52 <heatsink> palomer: It's not possible.
12:07:03 <Muad_Dib> cause that would rule out [undefined,[undefined, undefined],etc]
12:07:15 <bolrod> that is not even possible
12:07:16 <Muad_Dib> infact
12:07:20 <Muad_Dib> it would be
12:07:29 <bolrod> but lets say
12:07:30 <Muad_Dib> cycle [undefined]
12:07:35 <palomer> aww man
12:07:38 <bolrod> > cycle [undefined]
12:07:38 <lambdabot> Add a type signature
12:07:42 <palomer> so I'll have to write my own copyable ST monad
12:07:45 <bolrod> > cycle [undefined] :: [undefined]
12:07:45 <lambdabot> Add a type signature
12:07:48 <bolrod> > cycle [undefined] :: [a]
12:07:49 <lambdabot> Add a type signature
12:07:50 <Muad_Dib> (and infinite list of undefind]
12:07:52 <bolrod> > cycle [undefined] :: [Int]
12:07:52 <heatsink> palomer, what state do you want to copy?
12:07:53 <lambdabot> Undefined
12:07:56 <bolrod> hm
12:08:02 <palomer> heatsink: the current state, all of it
12:08:08 <palomer> heatsink: I'd like my state to branch
12:08:14 <Muad_Dib> or rather
12:08:25 <bolrod> > map inits [[1,2,3],[1,2],undefined,[2,3]]
12:08:26 <lambdabot> Undefined
12:08:28 <Muad_Dib> it would not be an infinite list, but a list of an undefined lenght
12:08:29 <bolrod> SEE!
12:08:31 <Seraph_> so is an array just a list of tuples?
12:08:33 <bolrod> thats incorrect!
12:08:41 <bolrod> > map inits [[1,2,3],[1,2],[],[2,3]]
12:08:42 <lambdabot> [[[],[1],[1,2],[1,2,3]],[[],[1],[1,2]],[[]],[[],[2],[2,3]]]
12:08:43 <Seraph_> the first element of the tuple is the index and the 2nd element is the value
12:08:43 <Seraph_> ?
12:08:45 <bolrod> instead of undefined
12:08:57 <heatsink> palomer, There is nothing in the normal ST implementation that knows what data constitutes the current state.  You'll have to write something that remembers what the state is.
12:09:17 <palomer> sucks
12:09:19 <bolrod> but this doesn't make sense.. why would the WHOLE expression result in undefined.. when just 1 list is undefined
12:09:32 <heatsink> palomer, once you've done that, you can just make a function to copy that state.
12:09:42 <bolrod> > [undefined]
12:09:43 <lambdabot> Add a type signature
12:09:47 <bolrod> > [undefined] :: [Int]
12:09:49 <lambdabot> Undefined
12:09:50 <palomer> wait, if I have an ST s bool, can't I simply copy it?
12:10:07 <Muad_Dib> because whenever an undefined is evaluate, haskell gives Undefined as result.
12:10:26 <Seraph_> how do you get a value from an array with an index?
12:10:37 <heatsink> palomer, you can copy it, but the copies aren't guaranteed to behave the same.
12:11:05 <boy> how can i get the size of a file?
12:11:30 <bolrod> ok...   [undefined] is basically the same as undefined
12:11:40 <heatsink> If you run (do x <- readSTRef r; writeSTRef (not x) r; return x) twice in a row, one of them will return True and the other will return False.
12:11:42 <palomer> heatsink: well, that's the thing, I don't want changes to one to affect changes to the other
12:11:46 <bolrod> > map inits [[1,2,3,4],undefined,[1,2]] !! 2
12:11:47 <lambdabot> [[],[1],[1,2]]
12:11:57 <bolrod> > map inits [[1,2,3,4],undefined,[1,2]] !! 1
12:11:58 <lambdabot> Undefined
12:12:00 <bolrod> > map inits [[1,2,3,4],undefined,[1,2]] !! 0
12:12:01 <lambdabot> [[],[1],[1,2],[1,2,3],[1,2,3,4]]
12:12:02 <bolrod> works fine
12:12:03 <heatsink> palomer, That's not what ST monads are for.
12:12:15 <Seraph_> bolrod: how do i get an array element?
12:12:48 <bolrod> > Array (0,10) (repeat 1)
12:12:48 <lambdabot>  Not in scope: data constructor `Array'
12:12:53 <bolrod> > array (0,10) (repeat 1)
12:12:53 <lambdabot>  add an instance declaration for (Num (i, e))
12:12:58 <bolrod> > arrayList (0,10) (repeat 1)
12:12:59 <lambdabot>  Not in scope: `arrayList'
12:13:03 <bolrod> eh?
12:13:09 <bolrod> it should be!
12:13:12 <bolrod> bah
12:13:34 <boy> > Array.arrayList (0,10) (repeat 1)
12:13:34 <lambdabot>  Not in scope: `Array.arrayList'
12:13:43 <boy> > Data.Array.arrayList (0,10) (repeat 1)
12:13:44 <lambdabot>  Not in scope: `Data.Array.arrayList'
12:13:45 <bolrod> oh
12:13:54 <bolrod> > listArray (0,10) (repeat 1)
12:13:55 <Muad_Dib> bolrod: of course that works, undefined is never evaluated :)
12:13:55 <lambdabot> array (0,10) [(0,1),(1,1),(2,1),(3,1),(4,1),(5,1),(6,1),(7,1),(8,1),(9,1),(10,1)]
12:14:00 <bolrod> :)
12:14:07 <bolrod> Muad_Dib: indeed
12:14:09 * boy wacks bolrod 
12:14:17 * bolrod whacks boy
12:14:41 * boy throws a coconut at bolrod and asks him how to get the size of a file
12:14:52 <bolrod> urh
12:14:54 <bolrod> dunno
12:14:56 <bolrod> xD
12:15:45 <bolrod> why are you so violent? :p
12:16:14 * boy violently drowns bolrod's head in toilet bowl
12:16:33 <heatsink> bolrod: Get back at him by giving him a correct but inefficient answer, e.g. return . length =<< hGetContents =<< openFile fname
12:16:47 <bolrod> :)
12:16:54 <boy> heatsink: thanks, that might work!
12:17:01 <bolrod> -.-
12:17:06 <heatsink> um, yes. >_>
12:17:12 <bolrod> I think you'd better search a better function
12:17:30 <bolrod> you dont need to read a whole file to get the size of it I guess
12:17:38 <bolrod> imagine windows would do that each time you'd ask the size of a file
12:17:45 <bolrod> (especially a file of size 600MB)
12:18:02 <heatsink> That explains why it takes so long to open "my computer"...
12:18:09 <Muad_Dib> Thats how windows does it anyway ;) ;)
12:18:30 * Muad_Dib suggest boy to look at the library documentation anyway ;)
12:18:34 <boy> well, i imagine there is an interface to the stat system command in the standard haskell libraries but i can't find it
12:19:01 <Korollary> MissingH has stat
12:19:16 <newsham> System.Posix ?
12:19:20 <Lemmih> And so does System.Posix, iirc.
12:20:04 <bolrod> heatsink: exactly
12:20:21 <boy> actually, what i really need is to make a function f :: FilePath -> IO (Array Int Word8)
12:20:23 <Lemmih> Has anyone suggested System.IO.hFileSize yet?
12:20:29 <boy> Lemmih: :)
12:20:43 <boy> f should read the entire binary contents of the file into the array
12:20:44 <bolrod> windows will 'actually' open your computer
12:20:46 <bolrod> :)
12:20:54 <Korollary> my System.Posix seems to be lacking the function sigs
12:20:58 <Korollary> the docs I mean
12:21:03 <Muad_Dib> System.IO?
12:21:14 <Muad_Dib> @hoogle hFileSize
12:21:14 <lambdabot> IO.hFileSize :: Handle -> IO Integer
12:21:22 <Lemmih> boy: There's an 'slurpFile :: FilePath -> IO (Ptr (), Int)' if you're using GHC.
12:21:32 <boy> Lemmih: hm.... i'll look at that
12:21:32 <Muad_Dib> Lemmih: pfft
12:21:38 <Muad_Dib> I should read what others say before typing
12:21:39 <boy> @hoogle slurpFile
12:21:39 <lambdabot> No matches found
12:21:41 <Muad_Dib> so excuse me.
12:21:42 <newsham> hGetContents ?
12:21:59 <Lemmih> boy: But using FPS would be easier, I think.
12:22:12 <Lemmih> @where fps
12:22:12 <lambdabot> http://www.cse.unsw.edu.au/~dons/fps.html
12:22:50 <mathrick> newtype State s a = State { runState ::  (s -> (a,s)) }   <--  how do I read that syntax?
12:22:57 <newsham> http://haskell.org/ghc/docs/latest/html/libraries/base/System-IO.html#v%3AhGetContents
12:23:20 <heatsink> mathrick, it's a function of type (s -> (a, s))
12:23:29 <newsham> mathrick: there's a type  "State s a"  with a constructor "State" which makes a record with one field called "runState"
12:23:40 <newsham> the runState field is a function mapping an s to a (a,s)
12:23:58 <norpan> take a state, return a value and a new state
12:24:22 <mathrick> oh, so values of type state are records?
12:24:23 <mathrick> noted
12:24:31 * mathrick wasn't familiar with records
12:24:31 <newsham> (they named the field runState because there will be a field accessor called "runState", and its a function, so it will turn out that you can use the accessor to run the state)
12:25:57 <newsham> data Foo = Foo { a :: Int, b :: [Char] }  ;     f = Foo 3 "hi" ;   a f ---> 3    b f --> "hi"
12:26:10 <newsham> its like a named tuple
12:26:48 <mathrick> oh
12:26:56 <mathrick> I see
12:27:16 <newsham> it also allows easy "updates"     f' = f { b = "blah" }
12:30:26 <mathrick> instance Monad (State s) where
12:30:26 <mathrick>     return a = State $ \s -> (a,s)
12:30:37 <mathrick> why does (State s) omit 'a' param?
12:30:55 <Cale> A monad is a type constructor
12:31:17 <mathrick> uh?
12:31:18 <newsham> (State s a) is a (Monad a)
12:31:20 <Cale> State s is partially applied
12:31:24 <newsham> so (State s) is a Monad
12:31:27 <Cale> hm?
12:31:29 <mathrick> aha
12:31:48 <Cale> I wouldn't say that State s a is a Monad a
12:32:07 <newsham> err.. yah, oops. 
12:32:32 <newsham> *rethinks*
12:33:01 <Cale> State s a is the image of the type a under the monad State s
12:33:19 <Cale> A monad is a function from types to types. (It's a functor)
12:34:06 <sjanssen> bolrod: are you around?
12:34:13 <Korollary> how do I dump the contents of an .hi file?
12:34:41 <bolrod> sjanssen: yes
12:35:07 <sjanssen> anyway, I'm up to date on the mailing list conversaton, you mentioned it earlier?
12:36:36 <Lemmih> Korollary: ghc --show-iface 
12:36:36 <bolrod> yes
12:36:47 <bolrod> what do they mean with the original version being strict..
12:36:59 <Cale> mathrick: does that make some sense?
12:36:59 <bolrod> which function is strict in the original function?
12:37:14 <Cale> (and have you read MonadsAsContainers? :)
12:37:58 <sjanssen> they're talking about how it reacts to things like "inits undefined", and such
12:38:16 <bolrod> well
12:38:21 <Cale> I'm all for the new definition of inits :)
12:38:22 <sjanssen> I'm of the opinion that it's bad style to depend on the exact behavior of things like that
12:38:22 <bolrod> for me it reacts exactly the same now
12:38:33 <bolrod> that too
12:38:33 <Cale> sjanssen: I agree
12:38:45 <bolrod> plus... it reacts EXACTLY ! the same if you use xn@(_:_)  
12:38:53 <bolrod> since it then has to evaluate the undefined
12:39:19 <sjanssen> perhaps it's a good idea to include that, just in case some crazy person depended on that behavior
12:39:28 <bolrod> I did post the change
12:39:31 <bolrod> ;)
12:39:32 <sjanssen> that is how it's defined in the report, after all
12:40:03 <mathrick> Cale: makes some, and I'm reading it right now
12:40:21 <Korollary> Lemmih: I've built fps using cabal, but ghc can't find Data.FastPackedString even tho ghc-pkg lists fps-0.1 and ghci shows the hi file was searched.
12:40:22 <bolrod> ahyeah.. did profiling on the output of inits .. and the old version isn't as crazilly slower as asking the length
12:40:31 <bolrod> but it does use alot more memory
12:40:45 <bolrod> and the characteristic graph showed again
12:40:55 <sjanssen> I did find one case where old inits is better
12:41:09 <bolrod> this defenition seems to be making junk all the time while it only needs it for a tiny moment
12:41:14 <bolrod> sjanssen: well :D? 
12:41:21 <sjanssen> if you try to run this program: "main = print $ last $ inits [1..]"
12:41:22 <bolrod> on the junkyard?
12:41:32 <bolrod> dude
12:41:35 <mathrick> bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbgbhbgbhbhgghghhggggghgh
12:41:43 <bolrod> thats not going to work ? ;/
12:41:47 <mathrick> oops, sorry
12:41:52 <mathrick> was cleaning the kbd :)
12:41:54 <sjanssen> old inits runs in constant space, new one allocates a bunch of memory
12:42:03 <bolrod> yeah!
12:42:03 <bolrod> true
12:42:10 <sjanssen> bolrod: right, it won't terminate, so it's just a silly example
12:42:12 <bolrod> but if you're going to calculate that
12:42:22 <bolrod> you're not very wise ;)
12:42:30 <bolrod> with VERY large lists
12:42:37 <bolrod> the new inits will take up a HUGE amount of space
12:42:40 <bolrod> but hey
12:42:51 <bolrod> if you're asking the length of inits [1..1000000000]   
12:42:55 <bolrod> you might as well use a better function
12:42:56 <bolrod> ;)
12:43:06 <bolrod> since the original vresion wont even get there in your lifetime I guess
12:43:21 <bolrod> at least on a normal computer
12:44:51 <bolrod> what I dont get.. is why that typical graph shows with the original inits
12:45:01 <bolrod> what exactly is it creating that it doesn't need again .1 of a second later
12:48:56 <Korollary> hmm. Setup.hs says it saved the lib but it didnt.
12:51:21 <bolrod> then there is possibly something wrong?
12:51:22 <bolrod> ;)
12:52:23 <Korollary> argh
12:53:07 <JohnnyL> the keyword data is wierd , it sorta defines things backwards.
12:54:13 <JohnnyL> :type Pt     data Point a = Pt :: a-> a-> Point a
12:54:21 <JohnnyL> and Point a is not defined.
12:55:23 <sjanssen> JohnnyL: the type constructor Point is defined
12:56:02 <sjanssen> you could write "data Point a = Point a a"
12:57:57 <JohnnyL> data Bool = True | False      What's on the right hand side extracts the type which is on the left hand side. My next step is to test to see If I can define Bool with something else.
12:58:56 <Korollary> I'd rather read that as "Bool is a type which is inhabited by two values, True and False."
12:59:37 <sjanssen> JohnnyL: if I'm catching your drift, this is valid: "data Bool = True | False; data SomethingElse = Bool"
12:59:50 <JohnnyL> it appears that you can not mix tuple types and disjoint types in the same declaration, is this true?
13:00:05 <JohnnyL> sjanssen, yeah, thats it.
13:00:39 <JohnnyL> i can't for some reason declare data Bool    = True | False
13:00:39 <JohnnyL> data MoreBool = Bool | Point a
13:00:43 <JohnnyL> it pukes on the Point a.
13:00:46 <sjanssen> the way the Haskell syntax is defined, it is never ambiguous whether a type or expression will appear, so we can reuse their names
13:00:48 <JohnnyL> Point works fine though.
13:01:12 <Korollary> read "MoreBool is a type whose values are either Bool, or Point a". What the heck is "a"?
13:01:19 <sjanssen> JohnnyL: the bool problem is because the Prelude exports the constructors True and False
13:03:41 <JohnnyL> Korollary, well you can define data Point a = Pt a a. Oh, I see, you need a corresponding cartesian value on the left hand side.
13:04:56 <xerox> Man I turned around so much today that I thought I wouldn't be able to immerge in R^3 anymore.
13:06:54 <JohnnyL> sjanssen, what's a prelude? the haskell default lib?
13:07:18 <newsham> the standard prelude.. stuff in the lib you get for free
13:07:23 <sjanssen> JohnnyL: yes, the library that's implicitly imported for every Haskell file
13:10:30 <JohnnyL> MoreBool a is the type of which Bool or Point a is.
13:17:19 <JohnnyL> hey dudes, do I need a function in order to explicilty state 'Pt 2.0 2.0' give the above definition of data Point a = Pt a a ?
13:17:32 <JohnnyL> that is 'given'.
13:19:46 <mathrick> numberST :: Tree a -> State Int (Tree (a,Int))
13:19:47 <mathrick> numberST (Leaf a) = do
13:19:47 <mathrick>                         next <- get
13:19:47 <mathrick>                         put (next + 1)
13:19:47 <mathrick>                         return Leaf (a,next)
13:19:52 <mathrick> where does the state come from?
13:19:58 <mathrick> because it's never named
13:20:12 <mathrick> and thus appears to come out of nowehere
13:20:22 <heatsink> mathrick, the functions "get", "put", and "return" have State types
13:20:37 <mathrick> heatsink: yeah, but what do they start with?
13:20:40 <heatsink> and then "do" combines them into a bigger function that also has a State type
13:21:01 <heatsink> mathrick, what do you mean, "start with"?
13:21:14 <mathrick> heatsink: the goal is to number tree nodes
13:21:35 <mathrick> thus those integers you associate with them have to have some concrete value
13:21:44 <mathrick> and that value is never initialised
13:21:49 <heatsink> mathrick, are you asking about what invisible data `get' and `put' are accessing?
13:21:50 <shapr> mathrick: Look at http://www.scannedinavian.com/~shae/steve_atkins_monads/Eval6.hs
13:21:58 <mathrick> heatsink: pretty much, yeah
13:22:16 <heatsink> mathrick, it's hidden in the do syntax
13:22:31 <mathrick> heatsink: uhh, but there is some data at some point
13:22:41 <mathrick> otherwise those numbers could be completely random
13:22:43 <sjanssen> mathrick: State s a == s -> (s, a)
13:22:45 <shapr> mathrick: Look at the very last character of Eval6.hs
13:22:51 <mathrick> shapr: okay
13:23:16 <shapr> The state monad works like the M+ button on those weenie solar powered calculators.
13:23:25 <heatsink> hahaha
13:23:34 * pesco giggles.
13:23:41 <mathrick> heh
13:24:01 <shapr> You could emulate that one bucket of state in a purely functional manner by explicitly passing around whatever value you have saved, yeah?
13:24:39 <mathrick> sure
13:25:01 <mathrick> shapr: so in case of numberST, how do I pass in the starting state/value ?
13:26:13 <shapr> State monad code (well, all monads) usually starts with something like \m ->
13:26:50 * shapr digs up the url for the state monad on nomaware
13:27:09 <heatsink> Geh, I thought the nomaware tutorial was confusing as heck
13:27:17 <shapr> http://www.nomaware.com/monads/html/statemonad.html
13:27:35 <shapr> I liked it, that and Cale's monads as containers wiki page made it crystal clear for me.
13:27:52 <mathrick> okay
13:27:55 * mathrick reads
13:28:02 <heatsink> Does Happy work with ST monads?  Can I say: %monad forall s. ST s
13:29:15 <shapr> mathrick: Did you see the way the starting value is explicitly passed in for the Eval6.hs file?
13:34:28 <mathrick> shapr: yes, but I don't understand that
13:36:10 <xerox> calculator :: Key -> State Number Number
13:37:53 <shapr> mathrick: Look at Eval5.hs
13:39:25 <heatsink> Eval5 looks like an Error monad, not a State monad
13:39:49 <shapr> oops
13:42:37 <mathrick> so what should I be looking at?
13:42:50 <shapr> If you used that explicitly passed around state as earlier, you could write your code to represent some use of the calculator so that the only unfilled argument would be that state.
13:45:46 <shapr> Man, my brain is all fuzzy today :-(
13:46:14 <shapr> mathrick: Are you going through a tutorial, or just trying to number the leaves in a tree?
13:50:06 <shapr> mathrick: My earlier comment about Functor was for data structure traversal. http://www.scannedinavian.com/~shae/ProtoFunctor.hs http://www.haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html#t%3AFunctor
13:51:38 <mathrick> shapr: I'm going through, and right now I'm trying to understand why numbering leaves with State monad works like it does in order to understand the State monad
13:52:23 <shapr> It's just the hand-calculator-explicit-passing-of-state idea.
13:52:47 <shapr> I was confused the first time looking at State because you have to pass it through both computations.
13:53:04 <Descolada|Work> is it possible to pull a value from a tuple inside a function?
13:53:20 <JohnnyL> why does 'and1 a b = if a == b then a else False'  and1 True False equates to False?
13:53:34 <shapr> Descolada|Work: Sure, fst and snd work for two tuples, and \(a b c d) -> d works for anything else.
13:54:05 <Lemmih> JohnnyL: Because 'True' /= 'False'?
13:54:11 <xerox> Counting leaves with State sounds like moving in the structure pressing 'M+1' every time one touches a leaf.
13:54:36 <shapr> mathrick: In fact, Eval9.hs does almost exactly what you asked for.
13:54:45 <shapr> http://www.scannedinavian.com/~shae/steve_atkins_monads/Eval9.hs
13:54:50 <shapr> Though it counts 'operations' instead.
13:55:34 <JohnnyL> Lemmih, ok, i get it looks weird though.
13:55:47 <mathrick> I can understand that
13:56:17 <mathrick> I just don't understand why appending 0 at the end of Eval6.hs magically makes it the initial value
13:56:49 <shapr> mathrick: What's the type of unwind?
13:57:34 <xerox> In fact it's hideous.
13:58:25 <mathrick> unwind :: M a -> State -> (a, State)
13:58:52 <shapr> What's the real type of "M a" ?
13:59:06 <mathrick> M Int
13:59:13 <mathrick> aha, I was reading it wrong I guess
13:59:24 <mathrick> associativity strikes again
13:59:24 <shapr> Ok, what's the *value* of "M a" in that type?
13:59:40 <shapr> This threw me off for days when I was first learning monads.
14:00:05 <shapr> It just never occured to me that I'd need to mentally expand the "m a" in type signatures into a bunch of other stuff.
14:00:10 <mathrick> shapr: ummm, the initial state + whatever eval does on it
14:00:29 <shapr> (State -> (a, State))
14:00:30 <xerox> Once you have a substitution model, you're done.
14:03:03 <mathrick> shapr: so was it right or not?
14:03:03 <shapr> mathrick: So you see why zero has to be passed in explicitly?
14:03:14 <shapr> Er, was what right?
14:04:39 <shapr> The entire type signature is unwind ::  (State -> (a, State)) -> State -> (a, State)
14:05:33 <mathrick> <mathrick> shapr: ummm, the initial state + whatever eval does on it
14:06:10 <shapr> If you mean what I think you mean, then you're right...
14:11:55 <mathrick> shapr: okay, reading a bit above (namely, type M a = State -> (a, State)), then applying that to eval :: Term -> M Int makes it clear
14:12:21 <xerox> That's right.
14:15:12 <mathrick> type Reader e = (->) e -- our monad
14:15:12 <mathrick> I think I asked about that last time too, but how the hell do I read that?
14:15:29 <mathrick> (->) is an operator?
14:16:30 <heatsink> It's an operator, of sorts, but on types
14:16:50 <heatsink> Just like "Either" is an operator on types... you have Either Int Int, Either Int (), and so forth
14:16:52 <mauke> a -> b == (->) a b
14:17:32 <heatsink> mathrick, You also have alternative syntax for list and tuple types.  (a,b,c) === (,,) a b c
14:18:13 <mathrick> okay, so how should I read the above?
14:18:23 <xerox> mathrick, (->) is the type constructor for functions.
14:18:40 <shapr> It's like (a -> b) but you don't have that b yet.
14:18:41 <heatsink> mathrick, (->) e is the type of a function (e -> f) for any type f.
14:18:43 <xerox> As mauke stated, your "(->) a" is really 'a ->'.
14:19:17 <mathrick> okay, so then I go to define some Reader e a
14:19:28 <mathrick> and that means it's really (e -> a) ?
14:19:36 <xerox> Yup.
14:19:38 <mathrick> so Reader is really a function?
14:19:49 <xerox> Isn't State one too?
14:19:53 <mathrick> okay, lemme read the rest now I know that
14:20:11 <mathrick> xerox: yes, but Reader is earlier in the MonadsAsContainers
14:20:17 <xerox> Indeed.
14:20:24 <goltrpoat> so i got SOE in the mail the other day, and went a bit overboard with an exercise.. can someone take a look at http://rafb.net/paste/results/LOsVLO21.html and tell me if i'm doing anything particularly stupid/inefficient/inelegant?
14:20:24 <mathrick> I just skipped it because I couldn't read that syntax
14:25:17 <bolrod> I have the feeling I got another function that is feeling slow :D
14:25:37 <sjanssen> bolrod: what is that?
14:25:42 <bolrod> isSuffixOf
14:25:55 <bolrod> is reversing the two whole lists it gets
14:26:00 <bolrod> then passes it on to isPrefixOf
14:26:03 <bolrod> I find that stupid
14:27:06 <bolrod> lets see if I can make a faster one 'gain! :D
14:27:11 <bolrod> this is funny
14:27:37 <sjanssen> with lazy evaluation, the performance should be okay
14:27:57 <bolrod> what is lazy about reversing a whole list!?
14:28:29 <sjanssen> well, you have to navigate to the tail, so reverse is okay there
14:28:41 <bolrod> indeed you have to navigate to the tail
14:28:46 <bolrod> but you dont need reversing for that
14:28:56 <bolrod> I'm not sure if this is going to work
14:29:04 <bolrod> but I think I'll see within the next 30 minutes
14:30:40 <bolrod> hrm.. maybe I'm wrong ;)
14:31:43 <goltrpoat> actually, i was wondering about something similar a while back.  is the compiler going to be smart enough about something like (unwords . reverse . words) to eliminate the temporary storage?  (this should run in linear time with a single char of storage, ideally)
14:32:34 <xerox> I think that's called deforestation.
14:33:38 <goltrpoat> oh ive heard about that..  that's just a general optimization technique for removing intermediate lists, right
14:35:26 <sjanssen> I don't think the compiler can get rid of the temporary storage in that case
14:36:47 <goltrpoat> yah the optimization is nontrivial..  ideally, you'd reverse the string, then reverse each word in place
14:38:36 <goltrpoat> crap.  gotta run
14:38:40 <goltrpoat> later
14:39:49 <bolrod> blah...  this IS going to work
14:40:00 <bolrod> but I doubt if this will be pretty and/or usefull
14:42:33 <sjanssen> bolrod: I just wrote one that does "drop (length y - length x) y == x"
14:42:40 <sjanssen> I'm not sure how to test it though . . .
14:45:10 <bolrod> hrm... sounds more reasonable then what I have
14:45:11 <bolrod> :D
14:45:24 <bolrod> dang
14:45:48 <bolrod> > isSuffixOf [100..1000] [1..1000]
14:45:49 <lambdabot> True
14:45:51 <bolrod> > isSuffixOf [100..1000] [1..1002]
14:45:52 <lambdabot> False
14:45:55 <bolrod> ;)
14:46:41 <bolrod> its so simple! why did I think so difficult :D
14:47:18 <bolrod> > isSuffixOf [100..1000000] [1..1000000]
14:47:19 <lambdabot> True
14:47:24 <bolrod> > isSuffixOf [100..10000-00] [1..10000000]
14:47:27 <lambdabot> Terminated
14:47:29 <bolrod> > isSuffixOf [100..10000000] [1..10000000]
14:47:34 <lambdabot> Terminated
14:48:18 <bolrod> > let isSuffixOf' x y = drop (length y - length x) y == x in    isSuffixOf' [100..10000000] [1..10000000]
14:48:22 <lambdabot> Terminated
14:49:53 <bolrod> sjanssen: yours is about twice as fast ;)
14:49:58 <bolrod> then the one in the libs
14:50:04 <bolrod> dang.. No wonder haskell is slow!!
14:50:16 <bolrod> ;)
14:50:29 <bolrod> ofcourse I need to test my version still
14:50:30 <bolrod> >:)
14:50:43 <bolrod> hrm
14:50:55 <Descolada|Work> isSuffixOf?
14:51:04 <bolrod> the 2nd time it wasn't faster
14:51:05 <bolrod> lets see
14:51:23 <bolrod> nope
14:51:29 <bolrod> slower :/
14:51:30 <bolrod> weird
14:52:51 <bolrod> hmmm
14:53:36 <bolrod> ok!
14:53:39 <bolrod> seriously
14:53:44 <bolrod> yours is faster with a False result
14:54:07 <bolrod> wayyyyyyyy faster 
14:54:13 <bolrod> I think isPrefix could be done just that way
14:54:16 <bolrod> just with the take
14:54:30 <bolrod> *Suffix> isSuffixOf' [500..9000000] [1..10000000]
14:54:30 <bolrod> *Suffix> isSuffixOf' [500..9000000] [1..False
14:54:30 <bolrod> (11.71 secs, 686359512 bytes)
14:54:30 <bolrod> *Suffix> isSuffixOf [500..9000000] [1..10000000]
14:54:30 <bolrod> False
14:54:33 <bolrod> (13.16 secs, 915887084 bytes)
14:54:46 <bolrod> Descolada|Work: looks if the first list is the end of the 2nd list
14:54:53 <bolrod> > isSuffixOf [1,2,3] [1,2,3,4,5]
14:54:55 <lambdabot> False
14:54:57 <Descolada|Work> ahh
14:54:58 <bolrod> > isSuffixOf [1,2,3] [1,2,3]
14:54:59 <lambdabot> True
14:55:02 <bolrod> > isSuffixOf [2,3] [1,2,3]
14:55:03 <lambdabot> True
15:03:05 <bolrod> sjanssen: in some cases my version outperforms yours.. and some cases it doesn't
15:04:23 <bolrod> noe[
15:04:29 <bolrod> the one in the libs is VERY bad
15:04:51 <bolrod> why did nobody notice these things before :/
15:04:55 <bolrod> this is bad!
15:05:08 <boy> ghci needs a built-in pager :\
15:05:20 <bolrod> seriously
15:05:29 <bolrod> > isSuffixOf [500..1000000] [1..1000000000]
15:05:33 <lambdabot> Terminated
15:05:34 <bolrod> it terminates
15:05:35 <bolrod> see
15:05:41 <bolrod> *IsSuffixOf> isSuffixOf' [500..1000000] [1..1000000000]
15:05:41 <bolrod> False
15:05:42 <bolrod> (1.20 secs, 109156944 bytes)
15:05:47 <bolrod> can be done in a matter of seconds
15:05:51 <boy> my z80-like asm disassembler seems to be working :D
15:06:27 <bolrod> sjanssen: guess we have the next candidate pending before the first is even adopted
15:09:06 <bolrod> sjanssen: sorry mate... my version is super ugly... but uses way less memory and is a tad faster then your very cool function  ;)
15:09:09 <bolrod> haha
15:10:30 <bolrod> in some cases
15:10:31 <bolrod> :x
15:12:01 <JohnnyL> hey there boy, cool. what's it for?
15:12:14 <boy> JohnnyL: haskell gameboy emulator :D
15:12:25 <xerox> hah, nice one.
15:12:43 <xerox> Do you have a site, a repository, or something about it?
15:12:45 <boy> this is gonna be much harder then i thought it would be though
15:12:47 <JohnnyL> neat stuff man.
15:12:52 <boy> xerox: nope, just started it today
15:12:54 <bolrod> I'm dissapointed at List libs so far :(!
15:13:13 <bolrod> disappointed*
15:13:26 <xerox> boy, keep it up, I'd love to see it :-)
15:13:58 <boy> xerox: wanna see the code i have so far?
15:14:04 <xerox> Yes, sure.
15:14:31 <bolrod> does anybody make haskell libs here anyway? :)
15:15:27 <boy> xerox: http://rafb.net/paste/results/EBuqOK90.html
15:15:49 <boy> xerox: it's not much yet... but it took quite a long time getting a good (and totally type-safe) Instruction type
15:18:00 <xerox> Yay.
15:18:55 <bolrod> my gawd I did it again
15:22:22 <boy> now i'm trying to figure out what kind of type i need to express the execution of an instruction
15:22:37 <boy> i think i'm supposed to use some kind of monad :\
15:24:38 <bolrod> sjanssen: you still there?
15:31:22 <xerox> 'night-o.
15:33:55 <palomer> hrmph, what's the problem of solving type equalities and type inequalities?
15:34:10 <palomer> like a -> b = c -> d and d <= e
15:44:41 * palomer pokes ski
15:44:45 <palomer> @seen ski
15:44:45 <lambdabot> ski is in #haskell-overflow, #haskell-blah and #haskell. Last spoke 13 hours, 3 minutes and 34 seconds ago.
15:47:27 <palomer> shucks, semi-unification isn't decidable
15:48:54 <bolrod> > isSuffixOf [1..] [2]
15:48:55 <bolrod> :D
15:48:58 <lambdabot> Terminated
16:11:17 * araujo hacks a bit on himerge
16:13:25 * shapr yawns
16:17:25 * araujo had a hot discussion about "Why Haskell got no state" today
16:22:28 * araujo loves HOT
16:22:33 * araujo loves it HOT
16:25:44 <mathrick> @type lookup
16:25:45 <lambdabot> forall b a. (Eq a) => a -> [(a, b)] -> Maybe b
16:27:30 <palomer> @type \n \f \x f (n f x)
16:27:31 <lambdabot> parse error on input `\'
16:27:36 <palomer> @type \n \f \x -> f (n f x)
16:27:36 <lambdabot> parse error on input `\'
16:27:42 <palomer> @type \n f x -> f (n f x)
16:27:43 <Korollar1> just one slash
16:27:43 <lambdabot> forall t t1 t2.
16:27:43 <lambdabot>         ((t -> t1) -> t2 -> t) -> (t -> t1) -> t2 -> t1
16:27:49 <palomer> the successor is typable?
16:28:17 <palomer> I'm shocked.
16:28:34 <palomer> wasn't there  a combinator on the church numerals which was not typable?
16:28:52 <Korollar1> I dont remember
16:29:15 * Korollar1 grabs tapl
16:29:20 <falconair> I'm curious about Haskell's performance, with all the type information Haskell has, shouldn't the compiler be able to do crazy optimizations and spit out one of the fastest binaries?
16:29:42 <boy> falconair: that's the goal :)
16:30:37 <boy> falconair: also, haskell not only has lots of type information, it also has referential transparency, so even more crazy optimizations can be theoretically done
16:30:45 <falconair> i haven't been able to understand if the current performance is due to something fundamental in the language (keeping all the lazy expression around) or just that speed hasn't been a priority yet
16:31:14 <palomer> haskell shows the discrepency between "theoretically" and "in practical terms"
16:31:17 <boy> falconair: i think a lot more research of optimization strategies is needed
16:31:52 <Korollar1> falconair: that's a question on ghc, not haskell.
16:32:12 <Korollar1> jhc for instance has speed as a priority
16:32:57 <falconair> Korollar1: I guess that was implicit in my question, could someone realistically build a compiler to make haskell compete with C (in terms of speed)?
16:33:21 <Korollar1> falconair: there's no reason why the imperative subset of haskell should be any slower than C.
16:34:18 <falconair> Korollar1: what do you mean by imperative subset, i thought there was no state in haskell (other than monads)
16:34:49 <Korollar1> that's the imperative subset
16:35:33 <falconair> so what keeps rest of haskell from being as fast?  garbage collection, unevaluated expression graphs?
16:36:07 <flux__> korollary, no theoretical reason maybe, but I doubt the current implementations are quite there yet?
16:36:29 <boy> i think a lot more research is needed in things like deforestation
16:36:46 <flux__> anyway, who wants to compete with the imperative implementation: it's the functional code that shouldn't be any slower (and preferable be faster), and it can just as well be (theoretically) just as fast as imperative C
16:37:02 <Korollary> flux__: ghc has indeed some issues with some programs that should be quite faster
16:37:03 <flux__> copying data could be optimized into mutating it
16:37:31 <Korollary> flux__: but ghc has very few people working on it and they are doing their best with a long todo list.
16:37:37 <flux__> yes
16:38:02 <flux__> but it'll still take very bright minds and lots of time.
16:38:17 <Korollary> and solid theory
16:38:56 <boy> and i think some killer AI techniques :P
16:40:39 <flux__> yeah, I guess the idea behind these kinds of optimizations is "if human can do it, so should the computer"
16:40:39 <Korollary> it doesn't matter all that much if ghc never gets that fast anyway. There are a lot of other languages that don't.
16:41:15 <flux__> I think more interesting is the potential with using multiple cpu's with ease
16:41:22 <falconair> as far as I can tell, much of the optimization focuses on turning out fast C code, perhaps more could be done if some compiler would spit out assembly...
16:41:33 <flux__> as in future that's where the performance is coming from
16:41:47 <flux__> didn't ghc target c-- also?
16:41:49 <Korollary> ghc wants to target c--
16:41:51 <falconair> i was actually thinking how cool it would be to start a haskell based company
16:42:23 <flux__> I think founding a company needs something more than just the idea of using a certain language ;)
16:42:39 <Korollary> companies are founded on business ideas, not just technology
16:42:46 <newsham> flux: if the language is outstanding, it might be a good start
16:42:54 <newsham> given the languages most pepole are developing in these days :)
16:43:07 <falconair> hahaha, i want to build a specific kind of database for a very specific industry
16:43:15 <Korollary> that may work
16:43:47 <flux__> newsham, so it's equally great idea to have a company that uses porsches, some way, some how?-)
16:43:54 <falconair> i came to haskell after trying to figure out how to best implement my idea, so the business idea is indeed what started it all for me
16:44:18 <falconair> shoot, i started this conversation at the wrong time, i gotta run
16:44:29 <flux__> I guess everyone's read Paul Graham's Why Functional Programming Matter
16:44:37 <Korollary> I have not
16:44:44 <falconair> i dont' think paul graham wrote it
16:44:52 <flux__> oh
16:44:55 <flux__> right
16:45:07 <flux__> paul graham was some bayesian filter guy
16:45:23 <falconair> he's is the lisp guy (the essayist)
16:45:23 <Korollary> not exactly, altho he wrote an essay on bayesian filters
16:45:58 <mathrick> hrmpf
16:46:00 <mathrick> (Reader r) >>= f = \x -> f (r x)
16:46:08 <flux__> actually my mistake was probably also with the document name
16:46:22 <mathrick> why does every other definition suggest that it should actually be (Reader r) >>= f = \x -> f (r x) x ?
16:46:33 <flux__> I'm just thinking the writeup where the secret weapon of the company was Lisp
16:47:18 <flux__> so right guy, wrong name of essay
16:47:36 <flux__> and looking at the list, I can't remember which one I meant ;)
16:47:48 <falconair> you are thinking of John Hughes
16:47:50 <falconair> http://www.cs.chalmers.se/~rjmh/Papers/whyfp.html
16:47:52 <shapr> I'm pretty sure John Hughes wrote "Why Functional Programming Matters"
16:48:02 <flux__> yes, google agrees with you
16:48:22 <falconair> google is my brain :)
16:49:19 <mathrick> nvm, I'm silly
16:49:47 * shapr enjoys silliness.
16:50:10 <Korollary> @silly+ shapr
16:50:11 <lambdabot> Unknown command, try @list
16:50:37 <araujo> @yay!
16:50:37 <lambdabot> Unknown command, try @list
16:56:44 <araujo> I am kind of impressed
16:57:03 <araujo> i met somebody today who never ever had heard about Haskell
16:57:32 <araujo> A brief explanation and he was able to write valid expressiones in about 5 minutes
16:57:50 <shapr> wow
16:57:53 <newsham> in 3 mos he might be able to use the IO monad :)
16:57:59 <araujo> Indeed
16:58:22 <araujo> I think i should do my children test someday
16:58:37 <araujo> I know some professors who could give me the opportunity
16:59:51 <newsham> got a turtle interface?
17:00:05 <araujo> uh?
17:03:17 <SuperTails92> by "turtle interface" you mean...
17:03:33 <newsham> http://wxhaskell.sourceforge.net/assignment.html
17:04:19 <SuperTails92> logo : lisp :: haskell : ?????
17:04:28 <SuperTails92> err
17:04:35 <SuperTails92> lisp : logo :: haskell : ?????
17:04:47 <newsham> python?  *shrug*
17:05:00 <newsham> (list comprehesions)
17:07:01 <SuperTails92> logo is lisp with a turtle and without parentheses
17:07:14 <SuperTails92> python is...not haskell at all
17:07:45 <newsham> yah, well, i didnt really have much to ick from.
17:08:15 <tic> isn't a Turtle module in Haskell something of a standard assignment.
17:09:15 <newsham> (python has list comprehensions and some limited forms of lazy evaluation)
17:25:44 <int80_h> does someone have a server available for me to play with haskell on. I want to do web applications, but I have to install a bunch of stuff. And my admin doesn't loike doing it
17:26:11 <int80_h> I'd like to eventually have a MEWA framework...but one step at a time here.
17:26:22 <int80_h> getting basic libraries installed would be fantastic
17:26:40 <newsham> simon's HWS, but it has security bug in it.  might not be a good way to impress your admin
17:27:05 <int80_h> yeah I figured someone here might let me have an accoutn somewhere
17:27:10 <newsham> http://lava.net/~newsham/x/hws.tgz
17:27:12 <Lemmih> You don't need a server written in Haskell, do you?
17:27:26 <int80_h> well, no. That would be cool. But don't need one no
17:27:30 <newsham> oh, i misread.. heh. blah, i'm dumb.
17:27:47 <newsham> why dont you just install hugs or ghc yourself?
17:27:51 <newsham> you dont need an admin to do it
17:28:04 <int80_h> I've got those. I need some libraries with a bunch of dependencies
17:28:19 <int80_h> unless you know how a guy with no root provilieges can use apt-get
17:28:29 <int80_h> because, I don't
17:28:37 <newsham> download src, build.
17:28:40 <newsham> no need for apt-get
17:28:46 <int80_h> yes newsham, thank you
17:28:58 <JohnnyL> what's the difference between a type and a data declaration?
17:29:06 <int80_h> if it were that simple and obvious, I wouldn't be here asking for an accoutn somewhere
17:29:06 <newsham> configure --prefix=$HOME
17:29:14 <int80_h> yes newsham, I know how to read the docs
17:29:24 <int80_h> thanks you though
17:29:45 <boy> JohnnyL: i think that type just creates a type synonym
17:29:50 <newsham> sorry.  just trying to be helpful  to answer your direction question, no I dont have an account for you (but you shouldnt need one)
17:30:13 <int80_h> well, darcs is complaining it can't find the zlib libraries. That's what lead me to desperate measures ;)
17:30:30 <newsham> get zlib, compile it in ~/lib
17:30:34 <int80_h> admin is running debian sarg, and as far as I can tell zlib is a kernel module
17:30:47 <newsham> no, zlib is nto a kernel module
17:30:51 <int80_h> hmm
17:30:56 <int80_h> that was the problem then
17:31:04 <int80_h> but I expect more problems in the future
17:31:10 <goltrpoat> heh.. come to think of it, it'd be somewhat cool to add a telnet interface to lambdabot, and a ghci shell to go with it
17:31:14 <newsham> http://www.zlib.net/
17:31:22 <int80_h> hopefully he won't mind altering his apache conf file
17:31:40 <newsham> i would be suprised if your admin let you edit his apache conf
17:31:53 <int80_h> well no, I will give him specifics, and hope he will do it
17:31:57 <newsham> but you may be able to run your own instance of apache
17:32:00 <int80_h> but I ask alot of him
17:32:09 <goltrpoat> <rh:mit> maybe if you got him drunk.  very... drunk.  </rh:mit>
17:32:11 <int80_h> ah!
17:32:28 <newsham> httpd -d $HOME
17:32:30 <int80_h> run my own apache
17:32:47 <newsham> (you'd have to make your own web root, config file, log file dir, etc)
17:32:51 <goltrpoat> damn, that was quite possibly the funniest movie reference ive ever made.
17:33:07 <int80_h> yeah and I could just send it a nohup signal to keep it running right?
17:33:08 <goltrpoat> although clearly i'm the only one laughing.
17:33:53 <int80_h> I'd want it to be persistant
17:33:58 <newsham> nohup's not a signal, but basically, yah, you can run it nohup (or in most shell's, just run it in the background)
17:34:17 <newsham> actually the server backgroudns itself automatically so you dont have to do anything special
17:34:40 <dons> goltrpoat, actually lambdabot already has a ghci-ish shelll. but not telnet
17:34:41 <int80_h> ah so even if the parent process exits, it still persists?
17:34:47 <newsham> yes
17:35:06 <int80_h> okay hopefully he won't crap about that
17:35:15 <int80_h> I'll do that is I absolutely need to
17:35:36 <int80_h> so, is the a haskell web server?
17:35:37 <goltrpoat> dons:  yah i guess the telnet bit would be the major change.  i remember wanting it in the past, mostly just to use @pl without getting on irc and flooding the channel
17:35:37 <newsham> if you configure it nicely (not fork off too many processes, dont make any big security holes, etc) he might not care
17:36:30 <int80_h> I mean, is there a haskell web server?
17:36:39 <int80_h> because, that would be a cool project
17:36:46 <newsham> yah, the url i pasted earlier, but i wouldnt recommend it right now
17:36:48 <int80_h> lisp has one, for crying out loud.
17:36:54 <int80_h> oooh
17:36:58 <int80_h> very alpha eh
17:37:01 <newsham> and this one too http://www.informatik.uni-freiburg.de/~thiemann/WASH/
17:37:11 <int80_h> ah I learned about WASH today
17:37:15 <newsham> (someone says it has a web server built in, i havent looked at it)
17:37:34 <newsham> int: its not that its alpha, its that it has a sec vuln.
17:37:54 <int80_h> oooh
17:38:31 <int80_h> once I get my blog built, I would like to take on a library project of some kind
17:38:34 <goltrpoat> ive been toying with the idea of writing a MUD in haskell (apropos the web server bit)
17:38:50 <int80_h> golt, I want to write a mud engine! better than a mud
17:39:03 <goltrpoat> well yeah, i mean a MUD engine, not a specific MUD
17:39:06 <int80_h> make haskell the embedded language for the mud
17:39:14 <int80_h> promote it as an educational tool
17:39:15 <newsham> ugh, mudders.
17:39:17 <int80_h> very worthy
17:39:58 <int80_h> hey kids play mud. and if they get on a mud with haskell, eventually they will want to be wizards. Then they will have to learn haskell
17:40:15 <araujo> hah
17:40:16 <int80_h> it's an ecedllent way to promote haskell among the kids
17:40:19 <araujo> nice reasoning
17:40:30 <int80_h> am I being naive?
17:40:33 <dons> goltrpoat, so for that i currently say: just instal lambdabot locally, and use the shell or vim bindings. that's what I do.  
17:41:17 <goltrpoat> dons:  too much effort, since i'm running windows
17:41:29 <goltrpoat> although i heard there's a free version of vmware now
17:41:52 <dons> $ ./lambdabot 
17:41:53 <dons> lambdabot> pl \f x y -> f x (f y)
17:41:53 <dons> flip =<< ((.) .)
17:41:53 <dons> lambdabot> quit
17:42:09 <dons> it builds on windows...
17:42:12 <dons> why wouldn't it?
17:42:13 <newsham> golt: whats wrong w/ windows?
17:42:17 <goltrpoat> there's also virtual server, but it wants to install IIS, and IIS scares me
17:42:32 <int80_h> it should scare you. that means you are a rational being
17:42:57 <goltrpoat> newsham:  nothing.  would just make it hard to install lambdabot locally, unless i'm missing something major.
17:43:20 <goltrpoat> i guess i could install cygwin and do it that way.
17:44:41 <newsham> C:\Documents and Settings\newsham>\ghc\ghc-6.4.1\bin\ghci.exe
17:44:41 <newsham>    ___         ___ _
17:44:41 <newsham>   / _ \ /\  /\/ __(_)
17:44:42 <newsham>  / /_\// /_/ / /  | |      GHC Interactive, version 6.4.1, for Haskell 98.
17:44:54 <int80_h> ouch
17:45:24 <int80_h> golt are you serious about building a mud engine?
17:45:24 <newsham> (you should still ahve cygwin installed :)
17:45:34 <int80_h> I'm a newbie so I need to collaborate
17:46:10 <goltrpoat> newsham:  ?  no, i can run ghci fine.  there's a minimal mingw install that comes with the visual haskell distro, i'm running off that
17:46:16 <int80_h> I'm still working through my tutorial book
17:48:45 <goltrpoat> int80:  somewhat.  it seems like a fun semi-easy project, i've been trying to find one.  i'm not sure how much time i'll be able to dedicate to it though, i already have a haskell project that's actually going into production (a compiler for a domain-specific language), but i wanted to diversify a bit
17:49:47 <goltrpoat> since i'm still feeling green as all hell.
17:49:58 <dons> goltrpoat, I thnk mingw should build in mingw.  like a normal haskell app.
17:50:05 <dons> its not a magic posix app, afaik.
17:50:11 <goltrpoat> you mean lambdabot should build in mingw?
17:50:21 <dons> yep. me brain slow morning
17:51:11 <goltrpoat> sweet..  i'll try that then
17:51:32 <int80_h> hm to you it seems semi easy. There must be things I don't know yet
17:51:35 <dons> and re. web servers. you've seen hws?
17:51:38 <int80_h> that would make it seem easy to me
17:52:02 <int80_h> well at least from you I would ask for a framework, like where to start. could you do that for me?
17:52:12 <int80_h> when I'm finished with my tutorial I'll use that
17:52:34 <dons>  [http://www.haskell.org/~simonmar/papers/web-server-jfp.pdf Developing a high-performance web server in Concurrent Haskell
17:53:00 <int80_h> ooooh sweet
17:54:11 <goltrpoat> i seriously need to look into concurrency in haskell.  someone was asking me if it was basically occam or CSP style par/seq and channel constructs, and the only thing i could say was "this makes sense, but i haven't the mildest clue as to the specifics"
17:55:28 <dechunker> I wonder what percent of this room is atheist.
17:55:56 <araujo> i am araujist
17:56:40 <int80_h> I shift my beliefe system as it's convinient
17:57:01 <int80_h> athiesm is often convienient and useful
17:57:27 <int80_h> I haven't tried being a born again christian yet though
17:57:31 <goltrpoat> i'm a rabid dontcareist.
17:57:39 <int80_h> he
17:57:40 <int80_h> heh
17:57:58 <int80_h> doesn't-apply-to-me-iology
17:58:41 <int80_h> oooh is dechunker a ... troll?
17:58:49 <araujo> Though i read a nice sentence from Leibniz i think a few days ago
17:58:55 <dechunker> I'm a Haskell newbie with a basic problem.  I want to build a shapes library, similar to Monadius (Haskell game), but it doesn't seem to quite work to do "data Shape = Circle {...} | LineSegment {...} | ..." because, although the shapes are usually treated in a generic way, there will sometime be a method that only works on one shape.  My standard answer in C++ would be to come up with the obvious object oriented scheme...  what's th
17:58:58 <araujo> God is the monad of monads 
17:59:00 <araujo> :-]
17:59:04 <int80_h> heh
17:59:08 <int80_h> see you guys later
17:59:38 <JohnnyL> boy, while data does what?
17:59:40 <malig> blech, spinoza
17:59:56 <goltrpoat> araujo:  congratulations, you just broke my brain.
18:00:20 <goltrpoat> dechunker:  you got cut off after "what's the"
18:00:46 <dechunker> Pasted: "My standard answer in C++ would be to come up with the obvious object oriented scheme...  what's the standard answer in Haskell?"
18:01:34 <JKnecht> "It is evident from this that if we were to have nothing distinctive, or so to speak prominent, and of a higher flavor in our perceptions, we should be in a continual state of stupor. This is the condition of Monads whe are wholly bare." - Monadology 24
18:01:34 <goltrpoat> specialize a function on the shapes you care about, and throw an exception otherwise?  to use c++ speak.
18:01:45 <araujo> goltrpoat, :-]
18:02:52 <boy> JohnnyL: data defines a new type
18:03:44 <JohnnyL> boy, ok
18:07:07 <goltrpoat> anyone here know much about the curry language?  looks like a logic language with haskellish syntax and constraint programming built in
18:08:12 <goltrpoat> and ive always wondered about generalizations of constraint programming, since there's so many different types.. LP, QP, NLP, non-convex programming, etc, in addition to your standard logic constraint programs
18:10:45 <goltrpoat> i mean, if i say minimize c^T x subject to x > 0, M x <= b, is this a logic problem or an LP problem?  if the former, it won't terminate any time soon, if the latter, what am i using, simplex, dual methods, kandarkar, seidel, what
18:11:01 <goltrpoat> er karmarkar rather.  kandarkar is a city in afghanistan, heh.
18:14:48 <goltrpoat> smokey
18:17:19 <Smokey`> goltrpoat.
18:19:29 * araujo pushes some changes to himerge
18:29:39 * goltrpoat drops a pin
18:40:15 <dons> ?brain
18:40:15 <lambdabot> Narf!
18:40:16 <JohnnyL> what wrong with:       nTh 1 1 = head 1
18:40:28 <dons> you can't take the head of 1
18:40:31 <dons> ?type head
18:40:31 <lambdabot> forall a. [a] -> a
18:40:35 <dons> it takes a list
18:40:38 <dons> > head [1..10]
18:40:39 <lambdabot> 1
18:40:43 <dons> > head []
18:40:43 <lambdabot> Add a type signature
18:40:48 <dons> > head [] :: [Int]
18:40:49 <lambdabot> Exception: Prelude.head: empty list
18:40:55 <dons> > head 1 -- is a type error
18:40:56 <lambdabot>  add an instance declaration for (Num [a])
18:41:22 <dons> make sense, JohnnyL ?
18:42:18 <Smokey`> that's the most elongated and complicated way of saying "head takes a list", I've ever seen :)
18:42:41 <dons> complicated? examples are useful, no?
18:42:46 <int-e> uh. but it's true.
18:43:04 <Smokey`> yes, examples are useful.  but all you really showed was head takes a list...
18:43:10 <int-e> in some old code of mine I had such an instance for polynomials: *Main> head 1 --> 1
18:43:25 <dons> especially, since I said "you can't take the head of 1. it takes a list"
18:43:33 <dons> bad int-e
18:44:01 <Smokey`> dons: ahh, my bad... didn't see you say "it takes a list"
18:44:11 <JohnnyL> i am typing it from example in a tutorial, thought it looked weird.
18:44:21 <int-e> the newer version is 'newtype Poly a = Poly [a] deriving (Show, Eq)' because it ended up being too confusing.
18:44:56 <dons> yeah, I reckon ;)
18:44:59 <dons> though karam+ for fun
18:56:06 <goltrpoat> heh.. polynomials would make a good first chapter for an "FP for mathematicians" type book
18:56:20 <goltrpoat> all kinds of recursion for root finding
18:57:33 <goltrpoat> along with P(x) -> dP/dx and vice versa being nicely defined
18:58:11 <dons> hmm. I wonder if there's any mention in "The Haskell Road to Maths and logic"?
18:58:33 <dons> ?google the haskell road
18:58:35 <lambdabot> http://www.cwi.nl/~jve/HR/
18:58:35 <goltrpoat> as luck would have it, i brought it with me to the cafe
18:58:37 <goltrpoat> sec
18:58:50 <dons> seriously?
18:59:21 <goltrpoat> chapter 9 covers polynomials.. haven't gotten there yet, but it doesn't seem to cover root finding and differentiation/integration (judging by TOC)
19:01:29 <goltrpoat> the second subsection is "gaussian elimination", which i assumes covers polynomial fitting.  third one is on the binomial theorem, fourth one is called "polynomials for combinatorial reasoning".  seems very sparse.
19:01:34 <dons> ?karma+ goltrpoat -- reading Haskell books :)
19:01:34 <lambdabot> goltrpoat's karma raised to 2.
19:01:40 <goltrpoat> hehe
19:04:46 <goltrpoat> one thing that would be really cool is if someone undertook yet another translation of numerical recipes, to a functional language this time
19:07:51 <goltrpoat> there are tons of numerical analysis books in imperative languages, but like.. more or less none in FP languages.  which is rather weird, since that type of thing is a fair bit easier to write in FP
19:08:06 <goltrpoat> or.. well, i shouldn't say none, but i looked around a fair bit.
19:13:50 <dons> have you seen the numerical stuff and maths page on haskell.org, btw?
19:13:53 <dons> lots of fun libraries
19:14:02 <dons> lets see if lambdabot can find it
19:14:08 <dons> ?gwiki Numerical
19:14:10 <lambdabot> No Result Found.
19:14:15 <dons> ?gwiki math
19:14:17 <lambdabot> No Result Found.
19:14:18 <goltrpoat> yah ive been slowly wading through that
19:14:20 <dons> bah
19:16:22 <goltrpoat> i should qualify that what i mean by NA doesn't really encompass CA type stuff..  i've come across a lot on the former
19:19:05 <goltrpoat> er.  the latter, rather.
19:19:19 <goltrpoat> rewrote the sentence a couple of times, and i guess that didn't work out very well.
19:19:57 <goltrpoat> but you were talking about http://www.haskell.org/haskellwiki/Libraries_and_tools/Mathematics right
19:20:33 <dons> yup
19:20:38 <dons> ?gwiki Mathematics
19:20:40 <lambdabot> No Result Found.
19:20:43 <dons> google blows
19:20:49 <dons> ?wiki Libraries_and_tools/Mathematics
19:20:49 <lambdabot> http://www.haskell.org/haskellwiki/Libraries_and_tools/Mathematics
19:20:55 <dons> lambdabot rules!
19:21:11 <goltrpoat> i briefly checked out the GSLHaskell stuff, and jerzy karczmarczuk really rings a bell
19:23:11 <goltrpoat> http://www.dinkla.net/fp/cglib.html is very much in line with my interests, haven't looked at it much yet
19:27:19 <Korollary> a lot of the people who are interested in NA use imperative languages like fortran, c, etc. so it's not a surprise.
19:29:26 <goltrpoat> well..  yes, that's why, i assume, it's so entrenched in imperative languages.  certain things seem easier in FP though.  certain things seem easier in IP -- in particular, many operations are naturally sequenced with state threading.  i think there's more than enough of a tradeoff though to at least consider it in detail.
19:32:22 <goltrpoat> like here's one example.  shewchuk's exact arithmetic stuff (he basically generalized some of knuth's thoughts on the matter, it comes in very very handy in numerically unstable algorithms like most geometric stuff) .. in C++, this is probably less up front work than in haskell -- just by virtue of it being not nearly as type safe
19:33:11 <goltrpoat> but something like crout's method in LU, that makes a ton more sense in a pure FP language
19:33:53 <Korollary> in any case the reader probably wants to use arrays, turn recursion into loops, etc.
19:34:18 <goltrpoat> only if they learned it in an imperative setting to begin with
19:34:55 <goltrpoat> alrighty.. i gotta head home
19:34:57 <goltrpoat> bbiab
19:35:16 <kazzmir> stupid question, how do I comment a line in haskell?
19:38:03 <Korollary> -- for a single line comment
19:38:15 <Korollary> {- -} for blocks
19:38:51 <kazzmir> thanks
19:39:05 <Korollary> np
19:56:30 <dons> ?brain
19:56:31 <lambdabot> Well, I think so, Brain, but first you'd have to take that whole bridge apart, wouldn't you?
20:02:07 <araujo> @keal
20:02:07 <lambdabot> how do i search for someone saying 'Keal' in mirc
20:02:16 <araujo> hah
20:09:46 <heatsink> :)
20:24:19 <jlenor1_> >:o
20:24:24 <jlenor1_> anyone ever heard of semi-unification?
20:28:09 <palomer_> whoa, there are most general semi-unifiers
20:28:12 <palomer_> that's nuts!
20:42:21 <goltrpoat> is there any provision for dynamic scoping in haskell'?
20:43:36 <goltrpoat> in a restricted sense, it seems like it'd be useful.  would result in a lot less lifting of random crap that nothing except for two or three functions needs to have access to
20:45:06 <dons> its possible with TH, but generally frowned upon.
20:46:10 <goltrpoat> frowned upon because it breaks encapsulation to an extent?  or some other reason?
20:47:02 <dons> makes the code harder to reason about, in general. in any language
20:48:05 <goltrpoat> even if you have to fully qualify anything that's dynamically scoped?  i mean, that's no different than just lifting it
20:48:28 <goltrpoat> other than the added access restriction
20:49:06 <sethk> I don't like it because the meaning of code is changed by syntax potentially nowhere near the code
20:50:40 <goltrpoat> but that's inevitable in any large project
20:50:47 <palomer_> with power comes responsibility
20:51:58 <dons> sethk, how's the code coming along?
20:52:20 <goltrpoat> i mean, i don't have to export helper definitions that had to be lifted in order to accomodate the two other functions that happen to need it, but it just seems dirty to declare those in global scope.
20:52:39 <Korollary> why do they have to be in global scope?
20:52:50 <goltrpoat> module scope i guess.
20:53:03 <Korollary> I still don't see it
20:53:09 <dons> i don't really understand what the restriction is here.
20:53:16 <palomer_> ok, if inria is down I'm going to scream
20:53:17 <dons> code example, perhaps?
20:53:37 * palomer_ screams
20:53:43 <palomer_> darn those french!
20:53:56 <palomer_> now I'm going to have to scavenge through my room to find the paper
20:54:03 <goltrpoat> say i write f = g.  i write g in a where block.  then i write h = map g.  i lift g to module scope to accomodate that.
20:55:03 <Korollary> you can choose to not export g
20:55:10 <goltrpoat> right, i just said that
20:55:33 <palomer_> I think you have the freedom to not export g
20:55:44 <goltrpoat> [22:51] <goltrpoat> i mean, i don't have to export helper definitions ...
20:55:54 <Korollary> yes, you dont have to. I am confused.
20:56:09 <goltrpoat> it pollutes the namespace
20:57:40 <Korollary> Not if you do "module Stuff (f) where"
20:57:53 <Korollary> "module Stuff (f,h) where" I mean
20:58:32 <palomer_> I think this is getting out of hand
20:58:35 <palomer_> and I'm going nuts!
20:58:52 <Korollary> palomer_: maybe citeseer has it?
20:59:08 <palomer_> oh, right, it does
20:59:11 <palomer_> I'm being silly
20:59:44 <goltrpoat> i guess it just seems dirty to define a function that everything else in the module has access to, whether it needs to or not
21:00:14 <Korollary> You can split the module
21:00:32 <goltrpoat> and if i'm feeling strongly about a particular function existing purely for the benefit of two or three other functions, it'd be nice to be able to define it locally and scope it
21:00:36 <goltrpoat> yeah that's true.
21:00:39 <palomer_> Stratified type inference for generalized algebraic data types <--this is what I want
21:02:56 <goltrpoat> http://cristal.inria.fr/~fpottier/publis/pottier-regis-gianas-05.pdf ?
21:03:05 <goltrpoat> and/or acm subscription
21:03:06 <dons> Ralf Lammel wrote a paper called: "Dealing with Large Bananas" !
21:03:19 <goltrpoat> oh cept that link is broken
21:03:25 <dons> is that the GADT paper?
21:03:33 <dons> ah, but inria is down?
21:03:43 <dons> 404
21:03:43 <dons> :(
21:03:46 <goltrpoat> looks like it
21:04:25 <dons> citeseer cache?/
21:06:05 <goltrpoat> it looks like every page that mentions pottier is down
21:06:14 <goltrpoat> that's a fairly useful skill.
21:06:16 <heatsink> must be a conspiracy.
21:06:37 <palomer_> acm has it
21:06:40 <palomer_> citeseer doesn't
21:06:46 <palomer_> strange
21:06:54 <palomer_> anyways, I think that's the best GADT paper so far
21:06:57 * palomer_ is off
21:07:25 <goltrpoat> an acm subscription is worth it though.  if only for the random $100k credit line offers that they used to send out
21:07:54 <goltrpoat> the amusement factor more than compensates for the subscription fee.
21:11:20 <Korollary> heh, view as html works quite well
21:11:24 <Korollary> http://scholar.google.com/scholar?hl=en&lr=&safe=off&q=cache:d40FHXUm2EcJ:cristal.inria.fr/~regisgia/publis/prg-long.pdf+
21:11:46 <Korollary> except for page 10
21:11:48 <Korollary> heh
21:14:42 <dons> palomer_, you might want to add some of the GADT papers you've been reading to : http://haskell.org/haskellwiki/Research_papers ... please :)
21:14:56 <dons> and anyone else who reads or writes haskell papers.
21:15:09 <goltrpoat> he's gone btw
21:15:18 <dons> oh. oops
21:15:41 <heatsink> happy is fun.
21:16:16 <goltrpoat> ive been playing with ultra a little bit.. hours of amusement, that.
21:16:20 <goltrpoat> too bad it's gofer
21:16:43 <dons> how gofer is it?
21:17:10 <goltrpoat> i haven't broken it yet, but it very explicitely says it's gofer
21:17:15 <goltrpoat> so i figure it's only a matter of time
21:17:51 <goltrpoat> (my only 'real' exposure to gofer is the hutton paper)
21:18:37 <goltrpoat> and actually.. the only real incompatibility i ran into with that was having to translate monad comprenehsion syntax over to haskell
21:19:11 <dons> yeah, but foer is basically early haskell.
21:19:11 <dons> pre-98
21:19:25 <dons> so it might still be valid haskell98 too.
21:19:28 <dons> s/foer/gofer/
21:19:39 <dons> ah right
21:19:42 <goltrpoat> yah but miranda is mostly valid haskell98 too, no?
21:19:51 <dons> hmm. less so.
21:19:59 <dons> but there are tools to do the translatoin from miranda
21:20:01 <goltrpoat> i meant i figure i can expect to write stuff and not have it compile
21:20:19 <dons> I used gofer for a haskell course a long time ago, with no problems
21:20:28 <dons> and it was a haskell implementation.
21:20:33 <dons> it was never a standalone language.
21:20:38 <dons> it's like ghc/haskell
21:20:42 <dons> its haskell98+extras
21:20:50 <goltrpoat> ah ok.. i was under the impression it was a subset of haskell
21:21:02 <dons> no. let me find the initial release notes
21:21:22 <goltrpoat> in particular, ultra uses a standalone gofer compiler that ive never heard of
21:22:07 <dons> a gofer compiler!?
21:22:11 <dons> huh
21:23:00 <dons> oh, they do actually say that Gofer is a "language very similar to Haskell"
21:23:17 <goltrpoat> yeah
21:23:17 <dons> but really, its an interpreter that implements most of haskell, plus some other bits, for Haskell 1.3 and earlier
21:23:33 <dons> http://ww.cse.unsw.edu.au/~dons/haskell-1990-2000/msg00866.html
21:23:44 <dons> and gofer is counted in the lists of Haskell implementations
21:24:07 <dons> "It extends Haskell in some ways, and subsets it in
21:24:14 <dons> others."
21:24:50 <goltrpoat> ah ok, so it's not strictly a subset, it has extensions
21:25:18 <goltrpoat> but i can expect to not be able to compile anything in the complement of one in the other, so to speak
21:29:26 <goltrpoat> i mean, sort of in the same vein i mentioned earlier -- some miranda code will be valid haskell, some haskell will be valid miranda, doesn't mean ghc is a miranda compiler
21:29:57 <dons> yup. but with gofer the gap is much smaller, and the conversion is less work
21:30:12 <goltrpoat> -nod-
21:30:27 <dons> so you could practically expect to be able to compile gofer code in ghc, with a bit of practice
21:33:23 <goltrpoat> ah ok, that makes sense.  with ultra, it sort of kept working, and i was wondering when the uh.. working.. would stop.
21:34:24 <dons> well, as long as ultras written in the subset of haskell, and no extensions, then it should keep working as long as there's an h98 compiler in existence?
21:34:42 <dons> or a haskell' compiler, if it uses the union of h98 and haskell'
21:34:57 <dons> intersectoin of
21:34:57 <pierre-> hello.
21:35:01 <goltrpoat> well, it works with tkgofer.  it was written in haskell, iirc, but it uses gofer for theorem definitions etc.
21:35:35 <dons> hey pierre- 
21:35:51 <dons> new to haskell? or just #haskell?
21:36:27 <goltrpoat> the docs say "gofer 2.30a".  i really have no clue what that means or what it's based on or why it's gofer to begin with.
21:37:20 <palomer> dons: I haven't forgotten about the GADT section
21:37:33 <palomer> however, whatever I want to add isn't supported by gcc 6.4:/
21:37:33 <pierre-> dons: me?
21:38:02 <palomer> oh my, you have the 2 peyton papers for GADTs
21:42:07 <palomer> hhhmph, I hate deadlines
21:42:27 <palomer> and I'm clueless as to how I'm going to do type inference for my system
21:42:39 <Saulzar> They make you do stuff though, so you quickly gain motivation :)
21:43:00 <dons> oh my? why are you surprised about what papers are up there? I don't understand.
21:43:37 <palomer> I'm not a big fan of those papers
21:43:56 <palomer> (one reason being the typos)
21:44:20 <dons> ah, but they're in ghc. so that increases the value.
21:44:42 <palomer> true, true
21:44:51 <palomer> I think it was a huge mistake to jump the gun
21:45:05 <palomer> (they should have waited until I come out with MY system)
21:45:09 <dons> ah.
21:45:10 <pierre-> is ghc-cvs (20050331) stable enough? can it compile anything that ghc6 can?
21:45:14 <dons> :)
21:45:20 <palomer> pierre-: that's old news
21:45:28 <palomer> seriously, the current system is too cumbersome
21:45:32 <dons> pierre-: hmm. why not 20060409?
21:45:54 <dons> palomer, have you read the new FD, GADT and Associ types paper?
21:46:06 <palomer> nope, got a link?
21:46:13 <dons> (look under assciated types on the same page)
21:46:16 <pierre-> dons: 20050331 is one from my Ubuntu repository
21:46:41 <dons> it won't compile everything pierre- . there must have been some new extensions in the last year. but probably you won't notice any thing
21:47:18 <pierre-> yeah, this seems to be quite old...
21:47:28 <palomer> dons: which paper?
21:47:36 <palomer> can't find anything about GADT in the associated paper section
21:48:02 <dons> the one about System F
21:48:29 <dons> its a new GHC Core for type checking all 3 systems.
21:48:46 <palomer> another type equality paper
21:48:55 * palomer thinks type equality is not the way to go
21:49:01 <pierre-> dons: can i compile hIDE with ghc6? 
21:49:13 <palomer> type checking or infering?
21:49:30 <dons> palomer, you need to show the community your code ... :)
21:49:41 <palomer> code for...?
21:50:13 <dons> your GADT type inference algo ;)
21:50:39 <palomer> I still haven't figured out how to do it
21:50:49 <palomer> though my system is vastly simpler than anything out there
21:51:03 <dons> i know. i'm teasing.
21:51:05 <palomer> well, I have one way in mind, but it's so ugly I dare not do it
21:52:07 <palomer> someone give me an example where functional dependencies are a must
21:52:27 <palomer> I have a feeling that most functional dependency examples can be handled with generalized algebraic datatypes
21:56:00 <Saulzar> How about Vector/Matrix overloading for multiplication  matrix -> matrix -> matrix,  matrix -> vector -> vector, matrix -> scalar -> matrix
21:56:57 <Saulzar> For the typical example...
21:59:27 <heatsink> Saulzar, it depends on how much typechecking you want the typechecker to do.
22:00:55 <goltrpoat> plus the matrix bit can be abstracted a bit further by saying that a vector is an nx1 matrix, giving matrix -> matrix -> matrix, matrix -> vector -> vector, vector -> vector -> scalar, vector -> vector -> scalar, and all kinds of other crap, with a single function
22:01:37 <goltrpoat> er.  second vector -> vector -> a should be vector -> vector -> matrix for outer product
22:01:47 <heatsink> Saulzar, I would look at the problem differently depending on whether you'd like the compiler to typecheck (matrix -> matrix -> matrix) or not
22:04:44 * heatsink quit Connection reset by sleep
22:04:50 <heatsink> I mean
22:05:00 <Saulzar> Well, sure - maybe it's not an absolute requirement, but I was hoping to see how that translates to GADTs? C++ style overloading is just the most obvious application of FDs to me.
22:05:34 <palomer> ok, so how would FD help us in this case?
22:06:09 <palomer> actually, this is easily done with GADTs
22:06:20 <palomer> hrm, maybe not
22:06:22 <palomer> I'll mull it over
22:06:29 <Saulzar> Return type is depedant on the parameters 
22:06:43 <palomer> well, that's the whole point of GADTs, really
22:06:50 <palomer> got any other example?
22:08:06 <Saulzar> Hmm, but using GADs ties them all together in one data type right? If you want to tack-on something type classes are not easier?
22:08:11 <palomer> I have to agree with heatsink, a vector is simply a matrix
22:08:22 <palomer> well, yes, type classes are easier
22:08:32 <Cale> A matrix is simply a vector :)
22:08:35 <palomer> but it's always good to have the right tool for the job
22:09:18 <palomer> right cale?
22:09:43 <Cale> hm?
22:10:19 <palomer> right.
22:10:28 <Cale> well, the right tool for the job, of course
22:10:54 <goltrpoat> careful, this is how people become physicists.
22:11:14 <Cale> A matrix is really a linear map.
22:11:21 <palomer> I mean typeclasses solve all our problems
22:11:28 <palomer> but it's a _huge_ hammer
22:11:54 <palomer> and sometimes, it misses the nail completely
22:12:08 <Cale> I think typeclasses can do some nice things with linear algebra, though I'm not sure I'd represent matrix multiplication with one.
22:12:30 <Cale> I'd certainly abstract vector operations.
22:13:01 <Cale> Actually, a class for linear algebras wouldn't be such a bad plan
22:13:19 <Cale> though Num sort of handles that already
22:13:37 <falconair> i am looking for a haskell compiler/interpreter/AST builder as an excercise in learning haskell by reading code that (sort of) implements haskeel...any suggestions?
22:13:59 <falconair> i'm mainly looking for simplicity
22:14:00 <goltrpoat> a field class would be more or less a prerequisite, no?  unless you want to limit yourself to matrix algebra on reals
22:14:15 <Cale> goltrpoat: a ring class
22:14:27 <Cale> (matrix algebras don't tend to be fields)
22:14:29 <Cale> er
22:14:29 <goltrpoat> i mean the underlying field
22:14:37 <Cale> ah, yes
22:14:53 <goltrpoat> as in, what are we working with, reals, polynomials, what
22:15:14 <Cale> falconair: Haskell is a fairly complicated language to implement. You might look up "Typing Haskell in Haskell"
22:15:17 <falconair> ...even better if it uses parsec parser
22:15:43 <Cale> There are a good deal of smaller interpreters and such written in Haskell
22:15:44 <Saulzar> @google scheme 48 hours haskell
22:15:45 <lambdabot> http://halogen.note.amherst.edu/~jdtang/scheme_in_48/tutorial/overview.html
22:16:30 <falconair> actually i started working on scheme in 48 hours, i couldn't even compile the first example (I think my indentation is messed up)...it is a great article
22:16:42 <dons> you could probably build a Haskell 1.0 interpreter in haskell with only a little effort.
22:17:09 <falconair> other than that, are there other source code examples that might be instructive for someone starting in haskell?
22:17:10 <goltrpoat> haskell is LL(k), right
22:17:17 <palomer> scheme in 48 is the best approach, ever
22:17:18 <Cale> falconair: what was the error?
22:17:26 <goltrpoat> and type inference looks unpleasant to write
22:17:42 <Cale> goltrpoat: it's really context sensitive
22:17:57 <falconair> it was last week, i'll sit down with it again (with this irc channel open next to my editor :) )
22:18:05 <Cale> goltrpoat: though there are ways to avoid that, by repairing broken parse trees after the fact
22:18:18 <palomer> quick, someone remind me what the latex symbol for < is
22:18:25 <Cale> It's <
22:18:26 <Cale> :)
22:18:35 <falconair> i would eventually like to build a prototype sql database in haskell, something very simple
22:18:35 <Cale> <= is \leq
22:20:18 <palomer> that should be the only way programming languages are learnt
22:20:24 <palomer> really
22:20:33 <goltrpoat> by writing a sql server?
22:20:35 <palomer> all programming language books
22:20:41 <Cale> hm?
22:20:44 <palomer> no, by writing something tangible
22:20:47 <palomer> like scheme
22:20:48 <dons> (not using eval, that is ;)
22:21:08 <Cale> I suppose that it's important to eventually do so
22:21:09 <falconair> yeah, an sql server, based on Grust's "Comprehending Queries"
22:21:16 <Cale> (well, of course it is)
22:21:59 <Cale> but I rather like doing a large number of toy programs and snippets before writing anything the least bit serious
22:23:17 <falconair> Cale, I've written the fold function a million times in haskell, ml, scheme, javascript..., sometimes a large but interesting program is more motivating
22:23:50 <Cale> :)
22:23:56 <falconair> for lazy bums like me, the 'sink or swim' approach is better
22:24:13 <palomer> yes!
22:24:15 <palomer> sink or swim!
22:24:56 <Cale> I don't suppose I could swindle you into writing a generator for one of my favourite puzzles? :)
22:25:39 <Cale> There seems to be a definitive lack of generators for nurikabe puzzles.
22:25:58 <dons> I rather like doing a  small number of large programs before writing any toy programs and snippets. I'm not sure why.
22:26:07 <falconair> you write a database for me, i'll write little puzzles :)
22:26:13 <Cale> hehe
22:26:15 <dons> I'm writing many more snippets these days.
22:26:37 <Cale> Well, I'm going to be working on a code generator for DFTs.
22:26:49 <palomer> nurikabe looks awesome
22:26:54 <Cale> It is :)
22:27:01 <palomer> discrete fourrier transforms? again?
22:27:08 <palomer> hasn't that been done a gizillion times?
22:27:20 <falconair> i find that i read little snippets in a book and convince my self that i don't have to actually type it out since it is so 'simple,' then when i have to write a hello world program without a book, i'm lost
22:27:36 <dons> falconair, maybe you'd like to write a lambdabot plugin?
22:27:41 <Cale> Not in anything close to a provably optimal way
22:27:47 <falconair> what's that?
22:27:48 <Cale> FFTW does very well
22:28:01 <dons> some people have got their start in haskell that way.
22:28:06 <dons> ?type map
22:28:06 <lambdabot> forall b a. (a -> b) -> [a] -> [b]
22:28:07 <dons> ?hooogle map
22:28:08 <lambdabot> Prelude.map :: (a -> b) -> [a] -> [b]
22:28:08 <lambdabot> Data.IntMap.map :: (a -> b) -> IntMap a -> IntMap b
22:28:08 <lambdabot> Data.IntSet.map :: (Int -> Int) -> IntSet -> IntSet
22:28:12 <palomer> provably ultimate?
22:28:17 <palomer> err, optimal
22:28:28 <palomer> you just work in some multiplicative group and you're done, no?
22:28:29 <dons> ?version
22:28:29 <lambdabot> lambdabot 3p400, GHC 6.4.1 (Linux i686 3.20GHz)
22:28:29 <lambdabot> darcs get http://www.cse.unsw.edu.au/~dons/lambdabot
22:28:55 <Cale> palomer: there are lots of ways to do CSE
22:29:38 <Cale> and optimality of code is ultimately dependent on machine architecture
22:30:06 <Cale> Since I'll be generating code for the Cell, which is very predictable, it's a little easier to reason about.
22:30:30 <palomer> isn't that the PS2 chip?
22:31:00 <Cale> I think so, if not the next generation after that
22:31:12 <Cale> It's an IBM chip really.
22:32:14 <palomer> you'll be doing this in haskell?
22:32:36 <goltrpoat> no, the ps2 had a bunch of mips chips in it.  they're using cell processors (multiple cores) in ps3 and xbox2 though.
22:32:39 <falconair> lambdabot looks cool, is there a website?
22:32:45 <dons> ?where lambdabot
22:32:46 <lambdabot> http://www.cse.unsw.edu.au/~dons/lambdabot.html
22:32:49 <dons> :)0
22:33:08 <dons> ?wiki lambdabot
22:33:08 <falconair> :)
22:33:08 <lambdabot> http://www.haskell.org/haskellwiki/lambdabot
22:33:38 <palomer> well, I'm off to bed
22:33:39 <palomer> night
22:36:19 <Saulzar> Hmm, what's a good way of dealing with source positions in a simple AST? Chuck them in every node?
22:37:06 <dons> paramaterise the AST type with the ident type, whiich can then be a simple String, or a pair of String and locationns
22:37:38 <Cale> The Cell is actually really nice for code generation. It has 8 SPEs which do floating point and integer computations each with a 128x16 byte register file, and a local store of 256KB, which it controls.
22:37:50 <dons> and then when you instantiate your AST type, you get all nodes located for free
22:38:48 <gizban> is anyone familiar with SOEGraphics?
22:38:55 <Cale> and the length of time that instructions take is really predictable
22:39:11 <Saulzar> Hmm, I started out with different types for each source part, Statement Expression etc.
22:39:18 <Cale> (which is a lot more than I could say for an Intel chip :)
22:39:46 <Cale> gizban: depends how familiar you need :)
22:40:05 <gizban> I need to make colored squares.
22:40:14 <gizban> like this:   http://www.cosc.brocku.ca/Offerings/4V81/Assignment4.html
22:40:28 <goltrpoat> cale:  i'm not sure if the no branch prediction brand of predictable is necessarily a good thing.
22:40:59 <Cale> goltrpoat: It is for us
22:41:14 <Saulzar> Easier to merge the lot of them into one type, Ast = Expression | Statement etc. ?
22:41:55 <Cale> well, it does do branch prediction, but the better guarantees we have, the easier it is to get scheduling to be optimal
22:42:13 <goltrpoat> hmm?  there's no branch prediction on the SPEs
22:42:15 <dons> Saulzar, you can keep them separate, but paramaterise the type on the Ident type.
22:42:17 <Saulzar> Ah I see, I suppose you can have all the types as parameterised, Expression a Statement a etc.
22:42:29 <Saulzar> dons, Thanks :)
22:42:53 <dons> data GenCmmTop d i
22:42:53 <dons>   = CmmProc
22:42:53 <dons>      [d]           -- Info table, may be empty
22:42:54 <dons>      CLabel
22:43:04 <dons> for example. 
22:43:15 <dons> and then: type Cmm = GenCmm CmmStatic CmmStmt
22:43:32 <dons> so you have a 'generic' data type decl. and all parts are paramaterised.
22:43:49 <Cale> Currently, another student (Wolfgang Thaller) has written a modulo scheduler for it, which is able to optimally schedule a rather large piece of code. (~5000 instructions) Every cycle is packed :)
22:44:11 <palomer> that's nuts
22:44:29 <dons> oh, Cale, you're at uni with Wolfgang now? I didn't know that.
22:44:36 <gizban> I can't seem to find examples of SOEGraphics or tutorials
22:44:47 <dons> or did I?
22:44:49 <Cale> dons: Well, he's finishing up now.
22:45:15 <palomer> so you're writing this code in assembly?
22:45:33 <Cale> palomer: I'm writing Haskell which writes abstract assembly.
22:45:46 <Cale> (pre-scheduling, pre-register-allocation)
22:47:42 <Cale> Basically, I'm generating a codegraph.
22:48:05 <palomer> so you're writing a compiler which only compiles your one program, right?
22:48:46 <Cale> palomer: essentially. We'll eventually probably generalise it to other linear transformations.
22:49:19 <goltrpoat> cale:  is this for a compiler backend, or something more generic?
22:49:28 <Cale> I have to finish this bit in the next couple weeks such that it at least works on some smallish examples, so that we have something nice to show IBM and hopefully get some funding.
22:49:30 <goltrpoat> oh sorry, didn't see your answer to palomer's question
22:49:39 <Cale> goltrpoat: It's part of a larger compiler
22:50:04 <goltrpoat> you're hoping to sell the idea to the octopiler team?
22:50:21 <goltrpoat> i mean sell = get funding from
22:50:22 <Cale> Not sure which team exactly.
22:50:40 <goltrpoat> ah.  cause the octopiler folk are basically working on a vectorizing compiler in the cell setting
22:51:13 <palomer> that's a wicked idea, though
22:52:10 <Cale> Coconut is sort of a stack of different level languages (equational, declarative at the top) which compile into one another, using directed searches at each stage to try to optimise.
22:52:34 <Cale> Well, directed searches and more specific techniques
22:52:44 <goltrpoat> ah nice
22:53:38 <Cale> There's also work going into automatically proving that generated code is correct in various ways.
22:53:55 <palomer> that's *&(*%&$ nuts
22:53:55 <Cale> Like that parallel code behaves reasonably
22:53:59 <goltrpoat> oh i was just talking about that the other day.
22:54:10 <palomer> night all
22:54:14 <goltrpoat> more on a "wouldn't it be nice" type level though.
22:54:14 <Cale> night palomer 
22:55:09 <Cale> gizban: did you have a more specific question?
22:56:10 <Cale> gizban: I recommend using the 'polygon' primitive to define a square first
22:56:34 <Cale> or createRectangle and drawRegion
22:57:25 <Cale> gizban: Oh, I must have missed it -- you're looking for examples?
22:57:40 <gizban> yeah, it's easier to learn by example
22:57:54 <Cale> gizban: If you have access to a library, there's a decent book which uses SOEGraphics to teach Haskell
22:58:11 <Cale> (the library is named after the book)
22:58:14 <Cale> http://www.haskell.org/soe/
22:58:34 <gizban> I found the lecture slides for that book online.  I wish I could get that book, but it's on 3 hours reserve at my school library.
22:58:41 <Cale> ah
22:59:45 <Cale> You've seen the GHC documentation? It doesn't have examples, but the library is pretty small and simple
23:00:16 <gizban> I think I can hack something together with these slides.  I'm required to use hugs.
23:00:31 <Cale> yes, but it's the same library :)
23:00:49 <Cale> http://www.haskell.org/ghc/docs/latest/html/libraries/HGL/Graphics-SOE.html
23:01:43 <gizban> that's very helpful.  Thanks
23:02:13 <Cale> no problem
23:03:20 <goltrpoat> cale:  btw, by directed search you mean control flow graph based analysis, right?  or is this something different
23:09:33 <Cale> goltrpoat: Well, various combinatorial optimisation techniques operating on the code, and determining execution cost.
23:13:30 <goltrpoat> so directed search here refers to dynamic programming type algorithms on the flow graph?
23:13:55 <Pegazus> hi
23:14:00 <Pegazus> does anyone knows how to solve the recurrency
23:14:12 <Pegazus> T(n) = 2 * T(n - 1) + n + k with k constant?
23:14:22 <Pegazus> (it's the time of an algorithm)
23:15:04 <Cale> goltrpoat: yeah, basically
23:15:18 <Cale> mbot knows :)
23:16:08 <Cale> T[n] -> -2 + 2^(1 + n) - k + 2^n*k - n + 2^(-1 + n)*C[1]
23:16:20 <Cale> where C[1] is an arbitrary constant
23:16:45 <Pegazus> emmm
23:16:47 <Cale> T[n] -> -2 - k - n + 2^(-1 + n)*(4 + 2*k + C[1]
23:16:48 <Pegazus> what?
23:16:50 <Cale> simplifies
23:16:52 <Pegazus> and how do i prove that?
23:17:59 <Cale> Well, you could use induction, but that's cheap
23:18:09 <Pegazus> cheap means easy or what?
23:18:09 <Cale> There are methods for solving recurrences like that
23:18:16 <Pegazus> and how do you know that's the result?
23:18:22 <Cale> exactly
23:18:32 <Cale> (that's why it's cheap)
23:19:11 <Pegazus> what?
23:19:15 <Cale> Let me recall what I learned about recurrences, that was quite a while ago
23:19:28 <Pegazus> i've just been trying 12 hours
23:19:32 <Pegazus> to solve that recurrsion
23:19:32 <Cale> There are methods for solving them just like those for differential equations
23:19:33 <Pegazus> O_o
23:20:13 <mwc> Difference equations?
23:20:17 <mwc> I have a good book on that upstairs
23:20:35 <mwc> I've got tons of Springer-Verlag books I've been hoping to dive into this summer
23:21:07 <Cale> http://en.wikipedia.org/wiki/Recurrence_relation -- look here
23:21:07 <tennin> is it = to \sum_{0<=i<=n} 2^(n-i) (i+k) ?
23:21:20 <Cale> It describes a method suitable for your case
23:22:21 <Pegazus> what method
23:22:41 <Cale> "Solving linear recurrence relations"
23:22:52 <Cale> and down
23:23:42 <Pegazus> :/
23:23:54 <Pegazus> i hate maths
23:25:35 <Pegazus> does anyone of you knows how to make a "formal proof" that a top down dynamic programming algorithm takes the complexity it takes?
23:26:32 <Cale> Pegazus: if you only need the order complexity, there are theorems you can use for recurrences like that
23:26:57 <Cale> I believe one of them at least is called the "master theorem"
23:27:14 <Cale> http://en.wikipedia.org/wiki/Master_theorem -- yep, here it is
23:27:57 <Cale> ah, unfortunately it doesn't quite apply here
23:28:10 <Pegazus> it doesn't work
23:28:21 <Pegazus> master theorem is for T(n) = T(a/b) things
23:28:26 <Cale> right
23:28:35 <Cale> How about the Akra-Bazzi theorem?
23:28:42 <Pegazus> i don't know that one
23:28:44 <Cale> It looks significantly more general
23:28:46 <Cale> http://en.wikipedia.org/wiki/Akra-Bazzi_method
23:29:27 <Pegazus> it don't think it suits there
23:31:03 <Cale> seems to
23:31:17 <Cale> It's extreme overkill though
23:31:28 <Cale> g(x) = x - k
23:31:30 <Pegazus> check the form of h
23:31:33 <Cale> a_1 = 2
23:31:37 <Cale> b_1 = 1
23:31:42 <Cale> h_i(x) = -1
23:32:19 <Pegazus> it can't be -1}
23:32:49 <Cale> hm?
23:33:05 <Cale> oh, there is one concern
23:33:23 <Cale> that page gives a bound saying 0 < b_i < 1
23:34:31 <Cale> there's nothing which says that h_1(x) = -1 isn't possible
23:34:55 <Pegazus> that's too much complexy anyway
23:34:58 <Pegazus> i want something simple
23:35:28 <Cale> oh, it doesn't work, since b_1 = 1 kills the next step
23:35:42 <Cale> which is finding a value of p for which 2 * 1^p = 1
23:35:48 <Cale> which is obviously impossible :)
23:38:08 <int-e> Cale: That's no surprise, really, because there's no p such that 2^n = O(x^p).
23:38:16 <int-e> err, n^p
23:39:44 <Cale> int-e: of course -- I hadn't looked carefully at the remaining part yet
23:40:16 <Pegazus> that algorithm is worst than O(n*2^n) i think
23:41:02 <Cale> It's O(2^n)
23:41:11 <Pegazus> good
23:41:13 <Pegazus> how do you prove it?
23:41:25 <Cale> Well, using that result from mathematica
23:41:30 <Pegazus> good
23:41:37 <Pegazus> and if i don't have matehamtica?
23:41:59 <Cale> Well, it is a linear recurrence equation which you can solve exactly
23:42:07 <Pegazus> what?
23:43:14 <Cale> The recurrence relation page I originally pointed you at
23:43:40 <Cale> gives the general method for finding closed forms for things like T(n)
23:44:02 <Pegazus> but T(n) isn't exactly 2^n
23:44:36 <Cale> oh, sure
23:45:10 <Cale> but the other stuff is asymptotically insignificant
23:45:19 <tennin> hmm, why is it  -2 + 2^(1 + n) - k + 2^n*k...  and not ... + 2^(n+1)*k... ?
23:45:19 <Pegazus> i need to prove it formally
23:49:06 <int-e> tennin: it's -n-2-k + C*2^k for some constant C.
23:50:32 <int-e> -n-2-k + C*2^n (I keep mixing up variables. Sorry.)
23:51:27 <Cale> int-e: ah, you absorbed a bunch of stuff into the constant -- I wonder why mathematica doesn't do that :)
23:53:30 <tennin> oh, ok
23:55:34 <Cale> anyway, it's fairly easy to show that -n-2-k + C * 2^n is in O(2^n), just take your constant factor to be something like C+1
23:55:49 <Cale> (or even just C, given that you have that -n there)
23:56:32 <Cale> If k might be negative, then you'll need to take it into account too, but using C+1 would take care of that.
23:59:36 <int-e> A sketch of a solution of that recurrence would be: We want to solve the inhomogenous linear recurrence: T(n) = 2 * T(n - 1) + n + k
23:59:36 <int-e> 1. solve the homogenous recurrence: T'(n) = 2*T'(n-1) --> T'(n) = C*2^n
23:59:36 <int-e> 2. find a particular solution: t(n) = 2*t(n-1) + n + k. (n+k) is a linear polynomial in n, so let t(n) be a linear polynomial: set t(n) = n*a + b. This gives t(n) = - n - 2 - k
23:59:36 <int-e> 3. The general solution is T(n) = T'(n) + t(n) = C*2^k - n - 2 - k.
