00:00:13 <edwardk> (simon pjs old papers on Henk are really about it as a pure type system)
00:02:04 <edwardk> My options at this point are to explode my set of sorts (making it a powerset of another set), make my pure type system 'non-functional' or 'non-simply sorted', or to adopt the pretype machinery.
00:03:31 <edwardk> Exploring the first option I get sorts of types that have some subset of the features: weakenable, contractable, exchangable (which actually is a function of the cross product of sorts), pointed, and whether or not its a polytype.
00:04:32 <edwardk> Taken all together (ignoring the fact that some combinations are illogical) thats 32 'sorts'. And possibly another 32 sorts for the associated kinds. Meaning instead of 'star' and 'box' like haskell i'd have 64 of the things to deal with =/
00:04:53 <edwardk> which starts to sound patently absurd
00:04:54 <Korollary> that is gnarly
00:05:35 <Korollary> what does your advyz0r say?
00:05:38 <edwardk> on the other hand, the features ARE almost entirely orthogonal to one another, and they do allow for lots of optimization, and it would be an intermediate language.
00:06:07 <edwardk> Heh, my college isn't very big on functional programming, so I'm flying without a net. My advisor will rubberstamp whatever I want to do.
00:06:58 <Korollary> I think my advisor hasn't even read my thesis. God bless him.
00:07:02 <edwardk> I had the same situation with my first thesis. They don't have anyone into computational geometry. So I grabbed a geometer and an algebraist and a computer scientist and called it a committee. =)
00:07:52 <Syzygy-> Are these PhD-theses or masters'?
00:07:57 <edwardk> of course, in the first case it was also that i wanted to do my masters in math entirely within one semester, so I pretty much took whoever I could find and wrote on the first topic that came to mind that I had something to say about.
00:08:05 <edwardk> syz: for me, masters.
00:09:24 <Korollary> I need a small-sized project
00:09:32 * edwardk 's bankaccount is still recovering from paying for that class-binge.
00:10:07 * Syzygy- took his master in a part of the world with free public education and generic grants to support students... :)
00:10:16 <edwardk> syz: heh
00:10:42 <edwardk> syz: i alas, did not, so I've paid for my entire education out of pocket.
00:10:59 <edwardk> and because I pretty much went and did it at my own pace the loans couldn't keep up with my course load.
00:11:26 <Syzygy-> Ouch.
00:11:47 <edwardk> On the other hand, I also now know that I have officially taken twice as many graduate credits in a single semester as the previous record holder ;)
00:11:59 <edwardk> well, not quite twice.
00:12:20 <edwardk> 28 over 15.
00:12:48 <edwardk> which was a lot of fun, but left my fiancee wondering who I was =)
00:13:09 <edwardk> given that she basically saw me for a couple of hours on the weekends
00:13:54 <edwardk> whoa.
00:14:05 <edwardk> just finished running a sandmark comparing vms.
00:14:26 <edwardk> the vector implementation is 8x slower than the calloc/free one.
00:14:35 <edwardk> didn't expect quite that much of a speed hit.
00:14:59 <zarvok> @tell vincenz Wow, nice UM!
00:15:00 <lambdabot> Consider it noted.
00:17:14 <dons> zarvok: where's vincen'z UM?
00:19:39 <zarvok> dons: it was posted on the icfpcontest-discuss list.  If you don't want to go through all that I'm happy to mail it to you - what's you're address?
00:20:19 <zarvok> your address rather
00:20:22 <zarvok> man I need some sleep
00:20:23 <dons> oh, its not hosted somewhere?
00:20:32 <zarvok> it may be, but I wouldn't know
00:20:33 * dons didn't bother with the discuss list this year
00:20:39 <dons> ok, dons @ cse.unsw.edu.au
00:21:10 <zarvok> A wise decision, I'm in the middle of going through like 300 messages posted in the last 10 hours
00:21:17 <dons> heh
00:21:37 <Korollary> viagra ads and entries from Nigeria?
00:21:43 <lisppaste2> edwardk pasted "ICFP UM" at http://paste.lisp.org/display/23124
00:21:50 <edwardk> that one is mine
00:22:07 <edwardk> pretty minimal c thing.
00:22:10 <zarvok> dons: I've forwarded the message, you should have it
00:22:20 <dons> looks good edwardk
00:22:38 <Korollary> It looks quite minimal.
00:22:43 <zarvok> vincenz is impressive because he used complicatedish C++ STL stuff to ensure 64-bit compatibility, but it is lightening fast
00:22:47 <dons> here's a haskell one, http://www.cse.unsw.edu.au/~dons/code/icfp06/machine/Machine.hs
00:22:51 <edwardk> runs about 8x faster than the vector one on my machine
00:23:00 <dons> but i think we could improve it, thinking some more about it
00:23:19 <dons> still, it was fast enough for everything
00:23:37 * edwardk nods
00:23:58 <Korollary> edwardk: That doesn't sound right.
00:24:02 <zarvok> I tried to write a haskell reference solution pre-contest and wasn't able to get it quite fast enough.  I'm looking forward to going through all the haskell ones people have posted tomorrow - should learn quite a bit
00:24:53 <edwardk> kor: struck me as odd, i wasn't expecting a huge speed difference
00:25:00 <zarvok> edwardk: you're referring to vincenz machine?  Did you compile it -O3?
00:25:13 <edwardk> let me make sure i used the same optimizations as mine
00:25:32 <zarvok> his makes huge use of some O3 specific optimizations
00:25:58 <zarvok> though it wouldn't be surprising if your C one is a fair bit faster
00:26:01 <dons> i think there's a fairly straight forward translation of some of these C ones into Haskell now, but it would be slighly odd IO/unboxed Haskell
00:26:41 <edwardk> -O3 -fomit-frame-pointer helped it a bit, going to retime it
00:26:49 <dons> another idea would have been to write a Hsakell one that dumps out actual C code for the input program,compile that and run it natively
00:26:58 <dons> i'm a bit tempted to do that actually
00:27:03 <edwardk> yeah
00:27:10 <zarvok> yeah, I tried to write a haskell one in the style of the C ones, and it didn't go so well
00:27:14 <edwardk> i just implemented it in C, because of the direct translation benefit
00:27:24 <zarvok> But I've never tried to write haskell for speed before, so who knows
00:27:26 <edwardk> the vm really did seem geared for it.
00:27:33 <dons> edwardk: right
00:27:45 <dons> zarvok: yeah, it was a bit hard if you didn't know the unboxed array interface, i suppose.
00:27:50 <dons> and Data.Bits
00:27:56 <dons> oh, and some low level io games
00:28:15 <zarvok> yeah, I tried to learn a bit about them as I did it, but I'm sure a more experienced hand would have done better
00:28:28 <edwardk> wow, your haskell version is a lot more verbose
00:28:36 <dons> it is.
00:28:43 <dons> i think it could be massively simplified now
00:29:05 <dons> one problem is no good syntactic support for mutable read/write and array indexing
00:29:09 <dons> some combinators would help there
00:29:52 <edwardk> yeah
00:30:41 <edwardk> my c version is probably the least 'safe' thing i've written in a long time. =/
00:30:42 <dons> edwardk: but your reference C immpl looks like a good candidate to translate to a simple haskell one
00:30:47 <dons> i might try that, in fact
00:31:02 <dons> based over a bytestring io/buffer code, should have reasonable speed
00:31:34 <dons> zarvok: the UM spec is a good benchmark for haskell in fact, since it has proved fairly hard to get near C
00:31:57 <dons> which is always interesting to find out.
00:32:02 <zarvok> dons: yeah, we were very interested in which functional languages would be able to do well
00:32:46 <zarvok> though we were hoping people wouldn't spend too much time on trying to get their higher-level language versions to work during the contest and just go to C if they were having trouble
00:33:15 <dons> i think at least in this channel, people got the haskell ones out pretty quickly
00:33:19 <dons> i know we did
00:33:19 <zarvok> yes
00:33:24 <zarvok> I was impressed
00:33:26 <zarvok> very impressed
00:34:08 <zarvok> I've only been coding seriously in haskell for about a year, and never for anything where high speed was very important, so it was neat to see that other people could do it so well
00:34:41 <gaal> hah, go to google and enter ghc manual. hit "I'm feeling lucky".
00:34:46 <dons> yeah, check the Great Language Shootout. The body of knowledge for writing fast haskell has grown a lot in the last 3 or so years
00:35:07 <dons> so people knew about mutable arrays, unsafeRead/Write, and how to use Data.Bits, I suspect
00:35:08 <astrolabe> Is that knowledge written up anywhere?
00:35:14 <dons> ?wiki Performance
00:35:15 <lambdabot> http://www.haskell.org/haskellwiki/Performance
00:35:18 <dons> :)
00:35:24 <astrolabe> Thanks!
00:35:25 <lisppaste2> edwardk annotated #23124 with "cut&paste error" at http://paste.lisp.org/display/23124#1
00:35:44 <edwardk> when i stitched it together from my vi buffer I omitted a line
00:35:56 <edwardk> would have prevented you from running the codec.umz through it
00:35:59 <zarvok> dons: well, thanks for the pointers, I'll be sure to check some of this stuff out tomorrow.  I'm going back to bed now though - later
00:36:06 <dons> night!
00:37:22 <dons> edwardk: i think i'll have a go at writing yours in haskell, after dinner. looks like a good place to start from.
00:37:29 <edwardk> k
00:37:45 <edwardk> glad to hear someone getting use out of it
00:38:00 <edwardk> I slapped it together while taking a break from theory this weekend
00:38:04 <edwardk> but didn't have time to compete
00:38:12 <edwardk> enjoying playing with the um now though
00:45:53 <edwardk> well, the -O3 sped up the vector implementation by a factor of 4. so the speed difference is only a factor of 2 to the 'bare bones' c implementation now.
00:46:02 <edwardk> that makes me feel better =)
00:48:14 <dons> hmm? what's the bare bones one? is that the one you posted?
00:48:27 <edwardk> yeah
00:49:10 <edwardk> a factor of two is about right because every cell reference in the vector imp has to go through two pointers.
00:49:50 <erider_>  /join ##c
00:50:21 <edwardk> sorry erider_  =/
00:50:50 <erider_> oops :)
00:50:55 <edwardk> heh
01:00:07 <gaal> is quickCheck supposed to work inside ghci? I'm getting an error about No instance for (Arbitrary Char)
01:00:39 <gaal> my property function has type String -> Bool
01:08:28 <dons> gaal: you're missing the Arbitrary Char instance
01:08:36 <dons> I can lend you such an instance, if you wish?
01:08:41 <gaal> please do :)
01:08:46 <dons> but you have to promise to return it, because I'll need it later
01:09:29 <gaal> I can promise now, but I have to warn you I can get quite arbitrary.
01:09:31 <dons> instance Arbitrary Char where
01:09:31 <dons>   arbitrary = choose ('\0', '\255') -- since we have to test words, unlines too
01:09:32 <dons>   coarbitrary c = variant (ord c `rem` 16)
01:09:41 <dons> that tests ascii
01:10:06 <dons> you probably want, arbitrary = choose (minBound, maxBound)
01:10:42 <gaal> wow, I sortof expected the library to provide a default for this...
01:11:26 <dons> yeah, its an often heard complaint
01:11:32 <gaal> though now I realize it probably couldn't have (you can't lexically override instances, can you?)
01:12:20 <gaal> @index ord
01:12:21 <lambdabot> Data.Char
01:13:48 <gaal> okay, it works now, thanks dons :)
01:16:44 <edwardk> hahaha, i just found a reference to a buch of articles i wrote way back when in a siggraph paper =)
02:03:13 <shapr> Good morning #haskell!
02:03:58 <psnl> good morning
02:06:24 <ValarQ> hello shapr
02:14:50 <u221e> Is there a way to stop getChar from showing the character on the screen when it's pressed?
02:15:06 <ValarQ> u221e: yes
02:15:32 <ValarQ> u221e: you have to turn off local echo
02:17:33 <ValarQ> u221e: System.Posix.Terminal might be of help here
02:17:38 <ValarQ> u221e: http://www.haskell.org/ghc/docs/latest/html/libraries/unix/System-Posix-Terminal.html
02:17:45 <u221e> :\
02:18:34 <musasabi> There are functions in System.IO too
02:18:45 <musasabi> @index hSetEcho
02:18:45 <lambdabot> System.IO
02:18:50 <musasabi> @index hGetEcho
02:18:51 <lambdabot> System.IO
02:23:56 <dcoutts> dons, ping
02:25:00 <dons> hey
02:25:05 <dons> time to write a paper?
02:26:07 <u221e> You two and your papers...
02:26:29 <dons> :)
02:27:22 <ValarQ> dmhouse is back!
02:27:26 <dmhouse> Morning channel :)
02:27:38 <dmhouse> ValarQ: Err, yes I am :)
02:28:29 <dons> time to make some noise!
02:28:41 <dons> look what the contest did to the channel, http://www.cse.unsw.edu.au/~dons/irc/haskell-06.html
02:28:41 <lambdabot> Title: #haskell @ freenode.org stats by dons
02:28:44 <dons> see the last 4 days
02:30:58 <u221e> Is there a version of getLine that can handle backspaces, or will I have to do it myself?
02:31:35 <dons> depends on your terminal settings
02:31:41 <dons> if you need full editing , use readline
02:31:45 <dons> ?hoogle readline
02:31:46 <lambdabot> System.Console.Readline.readline :: String -> IO (Maybe String)
02:31:46 <lambdabot> System.Console.Readline :: module
02:31:46 <lambdabot> System.Console.Readline.setReadlineName :: String -> IO ()
02:31:50 <dmhouse> u221e: I had some success by setting the buffering
02:31:57 <dmhouse> ?hoogle setBuffering
02:31:57 <dons> i.e. ms <- readline ""
02:31:57 <lambdabot> IO.hSetBuffering :: Handle -> BufferMode -> IO ()
02:32:15 <dmhouse> hSetBuffering stdout LineBuffering or something like that.
02:33:11 <dmhouse> dons: Nice page! We can conclude the vincenz is the most verbose #haskeller :)
02:33:38 <dons> well , except for the magic bot that never sleeps
02:33:56 <dons> the full stats are here, http://www.cse.unsw.edu.au/~dons/irc/
02:33:57 <lambdabot> Title: Haskell IRC Activity
02:34:07 <u221e> Hm, the hoogle logo is different
02:34:18 <dmhouse> "lambdabot is a very aggressive person. He/She attacked others 34 times." :)
02:34:31 <dmhouse> "Poor lambdabot, nobody likes him/her. He/She was attacked 20 times."
02:34:37 <dons> @slap lambdabot
02:34:37 * lambdabot beats up lambdabot
02:34:40 <dons> hehe
02:41:57 <Itkovian> I'm thinking about changing the approach I'm taking to parse my trace files, to get better performance, though I've no idea what approach to try, other than what I did. I think, though that, if a better approach can be found, I might get performance that equals ocamls performance.
02:42:51 <Itkovian> so, if you were to build a tree based on information in a trace, how would you proceed?
02:43:17 <dmhouse> @tell kowey it looks like we might be stepping on each other's toes a little on the Lists and tuples chapter :) I've put up what I've written, hopefully you hadn't started that section yet. Feel free to flesh out the rest, I'll knock something else off the todo.
02:43:18 <lambdabot> Consider it noted.
02:48:38 <u221e> I'm having trouble remembering what the bind functions do on various Monads...
02:48:52 <dons> ?hoogle Ptr
02:48:52 <lambdabot> Foreign.Ptr :: module
02:48:53 <lambdabot> Foreign.Ptr.Ptr :: data Ptr a
02:48:53 <lambdabot> GHC.Exts.Ptr :: Addr# -> Ptr a
02:49:09 <u221e> About the only one I can remember is IO ;P
02:49:17 <dons> ah well. same for many of us :)
02:49:34 <dmhouse> How can you remember IO?
02:49:49 <dmhouse> I don't even _know_ how IO works.
02:50:04 <dmhouse> I might be able to work it out, based on scraps of knowledge of ST, but I doubt it.
02:51:15 <u221e> IO bind is easy... it just extracts the thing in the IO monad.
02:51:32 <u221e> The other ones though...arg.
02:51:47 <dmhouse> Oh, I see.
02:52:01 <dmhouse> Well, if you're thinking about it that way, then Maybe's easy too.
02:52:18 <dmhouse> It extracts the thing out of the Just, or if it was a Nothing, it bypasses the function and becomes Nothing overall.
02:53:41 <dmhouse> [] is easy-ish, too. It extracts each element from the list, in turn, runs each through the function, then concats the resulting lists of lists.
02:54:06 <u221e> But when it's used in the do notation it looks confusing
02:54:18 <dmhouse> Right, but you hardly ever see [] or Maybe do-blocks.
02:57:14 <u221e> Hm, why does readline return a Maybe String?
03:00:54 <kosmikus> I use Maybe in do-blocks regularly, [] is rarely used in a do-construct because list-comprehension syntax is more beautiful
03:01:32 <dmhouse> I've used Maybe in a do-block only once.
03:01:45 <dmhouse> It was three commands strung together.
03:03:07 <dons> kosmikus: and as Cale always says, we should be using monad comprehensions anyway.. ;)
03:03:16 <kosmikus> +1
03:03:53 <dmhouse> Monad comprehensions? Isn't that just a do-block anyway?
03:04:07 <dmhouse> Or do you mean the generalised list-comprehensions thing that was scrapped for H98?
03:04:15 <dons> yep, that.
03:04:49 <edwardk> yeah
03:04:53 <u221e> I have no idea what your talking about ;)
03:05:02 <edwardk> i admit i loved the idea of a monad comprehension
03:05:11 <edwardk> i was bummed when i didn't find them in the modern language
03:05:25 <dons> maybe we should add them back in as a -fglasgow-exts
03:05:29 <dmhouse> u221e: You know list comprehensions?
03:05:29 <kosmikus> Haskell 1.4 isn't modern? ;)
03:05:30 <edwardk> ooooh
03:05:41 <dmhouse> [ (x, y) | x <- [1..], y <- [1..]] -- those things
03:05:42 <u221e> dmhouse: Yeah...
03:05:46 <dons> kosmikus: yeah, we could all install gofer!
03:05:59 <dmhouse> They were once generalised to arbitrary monads, but this was decided to be too confusing and scrapped for Haskell 98.
03:06:01 <edwardk> we did. its called 'hugs' =)
03:06:18 <edwardk> the problem supposedly had to do withthe error messages confusing newbies.
03:06:25 <u221e> ...
03:06:27 <edwardk> but then, since when is haaskell friendly to newbies? =)
03:06:33 <edwardk> i say add em in =)
03:07:42 <ProfTeggy> Same here.  Want to have them back
03:07:46 <u221e> What is with the ghc error messages anyway?
03:07:47 <edwardk> a nice set monad comprehension would make me happy
03:08:13 <edwardk> would be kinda like coming full circle
03:08:35 <dons> maybe we should add them back in, and see if the opinions have changed
03:08:43 <edwardk> yeah
03:08:46 <dons> considering the type errors we get with GADTs and FDs and so on now
03:08:51 <edwardk> heh
03:08:59 <dmhouse> What was the syntax like for monad comprehensions?
03:09:01 <dons> monad comprehenions seem like nothing
03:09:01 <kosmikus> I can see what I can do when we discuss such "details" for Haskell', but I don't think the chances are high ...
03:09:10 <dons> no, i agree
03:09:25 <dons> i think the best would be to get it into ghc in the first place..
03:09:58 <dmhouse> To be honest, there are cooler things lacking an implementation right not.
03:09:59 <dmhouse> *now
03:10:14 <dmhouse> kosmikus: Are you still hoping to implement your Open Datatypes stuff at the hackathon?
03:10:17 <edwardk> dmhouse: yeah but its a fairly painless-to-implement sugar
03:10:18 <kosmikus> for teaching, and approach such as "Helium" is probably preferable -- a subset of the Haskell language with better error messages
03:10:36 <dons> rather than crippling the main language branch, yes.
03:11:10 <kosmikus> dmhouse: I talked to SPJ at PPDP. We discussed what would have to be done. It's all not difficult, but quite a lot (at least for someone like me not being experiences with ghc). I'd still like to do it though ...
03:11:11 <dons> I think we're more comfortable with hard type errors than 8 years ago, too
03:11:52 <dmhouse> kosmikus: I see.
03:11:54 <edwardk> dons: wrt monad comprehensions or kosmikus's stuff? =)
03:12:01 <dons> heh
03:12:09 <kosmikus> dons: not really. I think the type errors for some advanced constructs are far too difficult, and I'd encourage more research on good error messages
03:12:29 <dmhouse> Wow, Haskell 98 is 8 years old. That's weird to think about.
03:12:59 <dmhouse> kosmikus: Especially when you get presented with an error message that begins 'My brain just exploded!'.
03:13:00 <edwardk> Heh considering the one time I tried haskell prior to a month ago was around then, yeah =)
03:13:01 <kosmikus> but if error messages are bad, I'd generally suggest to improve them rather than to give up on the language (feature)
03:13:14 <dons> yes, that's my opinion too.
03:13:27 <kosmikus> dmhouse: does that still exist? I got that quite often a few years ago, but haven't encountered it recently.
03:13:38 <kosmikus> maybe that's because I don't write that sort of programs anymore, though ...
03:13:44 <dons> yeah, its still there
03:13:50 <dons> when you try to pattern match an existential
03:13:58 <dons> ?ghc
03:13:59 <lambdabot>  A lazy (~) pattern connot bind existential type variables
03:14:03 <dons> oh, almost!
03:14:06 <dons> ?ghc
03:14:06 <lambdabot>  panic! (the `impossible' happened, GHC version 6.4)
03:14:11 <dons> ?ghc
03:14:11 <lambdabot>  For basic information, try the `--help' option.
03:14:14 <dons> ah
03:14:16 <dmhouse> The impossible does still happen too much.
03:14:18 <dmhouse> ?ghc
03:14:19 <lambdabot>  Info table already?
03:14:22 <dmhouse> ?ghc
03:14:23 <lambdabot>  the eta-reduction property does not hold
03:14:29 <dmhouse> ?ghc
03:14:29 <dons> take that!
03:14:29 <lambdabot>  All of the type variables in the constraint are already in scope (at least one must be universally quantified here)
03:14:30 <kosmikus> hehe
03:14:44 <kosmikus> that's a good newbie error message "the eta-reduction property does not hold"
03:14:50 <dons> hehe
03:14:59 <dmhouse> Where would it not?!
03:15:05 <dmhouse> Oh, is that newtype deriving stuff?
03:15:46 <dons> yeah, its in the deriving code
03:16:07 <dons> next to the error message about "cuning newtype deriving"
03:16:18 <dons> ?ghc
03:16:19 <lambdabot>  Illegal deriving item
03:16:53 <dmhouse> Hehe. I did always love the 'Cunning newtype deriving' messages.
03:16:54 <dmhouse> ?ghc
03:16:55 <lambdabot>  lexical error in string/character literal
03:17:01 <dmhouse> ?ghc
03:17:01 <u221e> How do I remove ghc-6.5?
03:17:02 <lambdabot>  Ambiguous constraint
03:17:14 <dmhouse> ?ghc
03:17:15 <lambdabot>  Malformed constructor signature
03:26:40 <edwardk> hrmm.  the code to tweak the desugaring of lists would have to be tweaked kind of carefully not to remove all the work that goes into its foldr/build fusion stuff
03:31:05 <shapr> edwardk: Seen unfold/destroy?
03:38:02 <edwardk> shapr: yeaah
03:38:30 <shapr> edwardk: Know of any other fusion rules?
03:38:34 <shapr> @seen bringert
03:38:34 <lambdabot> I saw bringert leaving #haskell.se and #haskell 1 day, 15 hours, 35 minutes and 17 seconds ago, and .
03:38:49 <edwardk> shapr: been spending a lot of time on pointedness and when that sort of fusion is correct, while i play with these substructural logics
03:39:03 <shapr> What's a substructural logic?
03:39:12 <edwardk> shapr: linear, affine, relevant, etc.
03:39:19 <shapr> ok...
03:39:46 <edwardk> basically been trying to see if i can shoehorn them into a pure type system so they come out less adhoc than the versions i've found so far.
03:40:00 <edwardk> a PTS has nice clean lines.
03:40:12 <edwardk> the substructural lambda calculi I have seen do not =)
03:42:31 <edwardk> as for other shortcut fusion rules, well, you might look at the boost matrix library they use a form of expression template that is analogous
03:45:08 <shapr> I just thought of array fusion. It's used in nested data parallel stuff.
03:45:21 * edwardk nods.
03:45:29 <edwardk> thats basically what the boost library stuff does
03:45:54 <edwardk> they just have a lot less theory than the haskell folks
03:46:08 <edwardk> coz of side effects, etc.
03:51:28 <shapr> More theory means more optimizations possible.
03:51:38 <shapr> As per Oleg's Principled FFT paper.
03:51:41 <edwardk> yeah
04:04:46 <lorne> > 1 `div` 0
04:04:47 <lambdabot>  Exception: divide by zero
04:04:55 * lorne goes to see how lambdabot does that
04:05:28 <dmhouse> lorne: regexes on GHCi's output, I think.
04:05:45 <dmhouse> Prelude> 1 `div` 0
04:05:46 <dmhouse> *** Exception: divide by zero
04:10:40 <pejo> I just read Simon Peyton Jones mail on ghc-users. Does anyone happen to know if there is more information on what is wrong somewhere?
04:11:00 <pejo> (Ups, regarding GHC 6.4.3 being stalled).
04:11:08 <shapr> JaffaCak1: Hey, I think I see what you meant in our original discussion. I think that hasStub isn't being passed somewhere.
04:12:10 <JaffaCak1> shapr: yes, or stored anywhere
04:13:01 <shapr> Right, so a Bool in the interface file would be enough.
04:14:19 <sylvan> shapr, google fails me, I can't find that paper (Principled FFT)
04:16:27 * lorne discovers Control.Exception.evaluate and continues on his merry way
04:19:34 <shapr> sylvan: google for oleg shapr fft, it's a post on LtU
04:30:56 * joelr1 waves
04:31:05 * shapr particles
04:31:16 <joelr1> you shapr
04:32:01 <joelr1> did you guys know that #ocaml has 37 members and #erlang has 34 vs. 202 on #haskell?
04:32:48 <johnnowak> yes.
04:33:25 <joelr1> haskell is no longer a niche language? :D
04:33:54 * joelr1 will be back in a few to bug JaffaCak1 about mac threading issues
04:34:04 <johnnowak> joelr1: maybe the niche is just getting bigger :)
04:45:49 <shapr> joelr1: The secret is simple... #haskell is friendly and we keep it that way.
04:46:21 <shapr> joelr1: If a particular user threatens that friendliness, they are removed from the channel.
04:51:46 <postman> What does \Pi mean in denotional semantics? SPJ uses it in "Lazy Functional State Threads" in Env = \Pi_\tau (var_\tau \rightarrow D_\tau).
04:51:58 <postman> denotational, even
05:07:30 <lorne> @paste
05:07:30 <lambdabot> http://paste.lisp.org/new/haskell
05:09:59 <lisppaste2> lorne pasted "Control.Exception.catch confusion" at http://paste.lisp.org/display/23130
05:10:37 <shapr> Where is a HomModInfo turned into ModDetails?
05:11:40 <lorne> I'm missing the way to catch the last case of my paste
05:12:50 <joelr1> gents, why is ghc so slow when compiling?
05:13:07 <dons> it's doing a lot of thinking?
05:13:46 <shapr> yeah
05:14:04 <joelr1> no, seriously. the ocaml compiler is quite fast, for example
05:14:28 <joelr1> is there anything to point a finger to?
05:14:33 <dons> i'm not sure where the bottlenecks in the compiler are, actually
05:14:42 <shapr> dons: Profiling time?
05:14:46 <dons> i know its faster if you don't invoke gcc
05:14:51 <dons> i.e. -fasm
05:15:08 <joelr1> shapr: you mean to profile the compiler?
05:15:13 <dons> also, using -Onot makes a big difference
05:15:19 <joelr1> dons: but it builds with gcc by default, no?
05:15:27 <dons> right
05:15:41 <dons> those optimisations do a lot of work, which takes a while
05:15:43 <shapr> joelr1: You could try JHC. That'll give you a positive appreciation of GHC.
05:15:50 <dons> so for top speed try -Onot -fasm
05:16:01 <shapr> Heard the story about the sage and the villagers who wanted more space in their house?
05:16:06 <joelr1> dons: there's gonna be a drawback to that for sure
05:16:13 <dons> well, its ok if you're just testing
05:16:13 <joelr1> shapr: no, why?
05:16:30 <dons> then crank on -O3 -lots-of-magic-flags for production use
05:16:32 <shapr> Each time they visited, the sage told 'em to move more of their animals into the house.
05:16:45 <shapr> The last time, when they were about to scream, he told 'em to move all the animals out of their house.
05:16:57 <shapr> After that, their house felt huge!
05:17:02 <dons> hehe
05:17:05 <joelr1> shapr: haha :) yes, you learn by comparison
05:17:07 <shapr> So like I said, try compiling stuff with JHC for awhile...
05:17:30 <dons> joelr1: also, if you can do an initial build with ghc, then use ghci to reload any changes
05:17:32 <joelr1> the advantag of jhc is whole-program optimization, right? i thought jhc wasn't ready for prime-time
05:17:35 <dons> that'll improve turn around
05:17:37 <dons> times
05:18:01 <joelr1> right
05:18:06 <joelr1> regardless, i can't fight the urge :-(
05:18:38 <joelr1> i was gonna use ocaml (something new! fast!) until i saw spj's plea for help with threading
05:19:15 <joelr1> so i'm gonna be a guinea pig again :D
05:19:21 <dons> cool :)
05:19:22 <dons> ?karma
05:19:23 <lambdabot> You have a karma of 45
05:19:23 <shapr> Where's that? ghc-users?
05:19:29 * joelr1 is waiting for cheers
05:19:29 <joelr1> hehe
05:19:32 <Syzygy-> ?karma
05:19:32 <joelr1> shapr: yes
05:19:33 <lambdabot> You have a karma of 0
05:19:35 <dons> ?karma+ joelr1
05:19:36 <lambdabot> joelr1's karma raised to 3.
05:19:38 <dons> i mean :)
05:19:46 <joelr1> thank you dons
05:19:51 <sylvan> I'm trying to learn ReadP, how would I do something like (parsec): do { r <- regex; char '*'; return (Many r)}
05:19:59 <Syzygy-> How do you gain karma / what is it for?
05:20:04 <joelr1> guinea pig cause i want to do time series computations
05:20:34 <dmhouse> sylvan: I guess you mean many r. And you probably don't need to use return, many is already monadic.
05:20:56 <sylvan> no Many is a type constructor for my Regex type
05:21:02 <dmhouse> Oh, I see.
05:21:04 <sylvan> I'm just parsing regex-expressions
05:21:11 <sylvan> (as a learning example)
05:21:24 <sylvan> but I want to do the Parsec example I gave using ReadP
05:21:32 <sylvan> (i.e. non-monadic)
05:22:40 <sylvan> I can't find any sort of "parse this, than this" operator in ReadP
05:22:47 <sylvan> (then
05:22:48 <sylvan> )
05:26:24 <sylvan> ah, I suppose you use the monadic interface for the sequencing stuff
05:26:26 <joelr1> see you guys in a while /no, can't work with #haskell running/
06:09:45 <mahogny> anyone tried building wxhaskell on the latest Ubuntu?
06:09:50 <mahogny> got some errors
06:12:49 <mahogny> ah fuck it. gtk2hs next
06:13:56 * dcoutts runs gtk2hs on his new laptop with Ubuntu 6.06
06:14:14 <postman> In the spirit of "If it doesn't compile, let it die".
06:15:15 <xs> mahogny, i built wxhaskell under debian testing just now.. it worked fine..
06:16:11 <mahogny> hm. weird. oh well
06:16:19 <mahogny> postman: right :P
06:17:09 <roconnor> Is there any reason to use a series of IORef's vs StateT MyData IO
06:17:12 <xs> what was the error?
06:18:09 <dcoutts> mahogny, I've fixed the wxHaskell for gentoo several times, it is indeed very sensitive to the way the wxGTK package was built
06:18:33 <mahogny> xs: PM
06:18:39 <dcoutts> eg with/without odbc support, Unicode, blah, blah
06:19:44 <mahogny> well, I've had some other problems with wx so this was the perfect excuse to let it go :)
06:19:54 <mahogny> the performance of wx is utterly bad
06:19:56 <dcoutts> mahogny, from looking at the Gentoo wxHaskell ebuild it seems that the only combination that works is wxGTK built for Gtk+-2.x without unicode and without odbc
06:20:06 <mahogny> :/
06:21:20 <dcoutts> the latest released version of Gtk2Hs builds from source fine on everything I've tried it on (even win32 if you follow the instructions carefully)
06:22:21 <mahogny> sounds promising
06:24:19 <dons> roconnor: hmm. the IORefs might be slower?
06:25:34 <roconnor> dons: I'm trying to figure out if IORefs would be slower or faster.
06:25:41 <mahogny> I would assume slower
06:26:14 <dons> compared to just accessing a normal value threaded in the monad, the IORef has extra machinery
06:26:24 <dons> but numbers would be good. its an interesting puzzle :)
06:26:37 <dons> and then you could consider an MVar too
06:26:52 <tato> does haskell have a macro facility like lisp or ocaml?
06:26:55 * roconnor can't stop thinking about his UM.
06:27:04 <roconnor> MVar?
06:27:21 <Philippa> +
06:27:42 <roconnor> So I'm wondering if it is better to make a strict data structure of 8 Word32's to pass around as state
06:27:59 <roconnor> or use an IOUArray in the state.
06:28:14 <mahogny> tato: if you think of what I think of, then no, not really. but with high order function application etc you shouldn't be needing macros
06:32:16 <dons> tato , yeah, as mahogny says, we just use higher order functions, and laziness, to add new "syntax"
06:33:25 <tato> hmm.. i wonder why then caml and lisp programmers (both have higher order functions) don't do the same thing
06:34:28 <dons> perhaps the laziness becomes the key issue.
06:34:34 <dons> you need it for writing new control structures
06:34:53 <nattfodd> tato: there aren't really any macros in ocaml
06:34:59 <nattfodd> at least not in the core of the language
06:35:19 <nattfodd> you need to use either metaocaml or ocamlp4 to have something that looks like the lisp things
06:35:42 <dons> haskell does though have Template Haskell, for when you need to generate code at compile time
06:35:51 <dons> which sometimes is needed for really tricky problems
06:36:21 <mahogny> really tricky is the word
06:36:37 <mahogny> the macro system as is is usually way too powerful for most problems
06:36:48 <tato> (what I'm actually doing is exploring lisp and trying to determine exactly whats so exciting about its macro system...)
06:37:03 <dons> well, is it exciting?
06:37:17 <tato> the author makes it out to be..
06:37:20 <mahogny> at the time it was exciting. then we figured the problems with it :)
06:37:37 <nattfodd> they really are exciting
06:37:50 <nattfodd> they give you a lot of power, which means a huge bug potential
06:37:53 <mahogny> well, they still are. if you can live with the problems
06:38:46 <tato> any specific problems you're refering to?
06:39:05 <shapr> I agree with joelr1, I can't work when I'm on #haskell
06:39:08 <mahogny> I feel sorry for the compiler coder, and it's easy to mess up
06:39:34 <postman> Scheme macros are nice. Also Scheme does not limit one as much as the Haskell character set. In Haskell you can't have foo-is-a-cool-name.
06:39:58 <dons> but you can have .... is a cool name ;)
06:40:42 <mahogny> if you think that is a good feature, go for Algol :)
06:41:06 <ozone> dons: you're up late these days
06:41:09 <dons> > let x .!#$%^&*<> y = x ++ y in "oh " .!#$%^&*<> "my"
06:41:10 <lambdabot>  "oh my"
06:41:19 <postman> It's not like they didn't think about what features to go in the language.
06:41:29 * dons thinks there should be more operators that look like !#%^
06:41:37 <Failure02> in haskell you can have korean smilies as variables! like (^-^)
06:41:41 <dons> heh
06:41:47 <mux> Intercal!
06:42:01 <dons> ?remember Failure02 in haskell you can have korean smilies as variables! like (^-^)
06:42:01 <lambdabot> Done.
06:42:06 <dons> ozone: yeah, a bit
06:42:38 <postman> > (define ^-^ 2)
06:42:38 <postman> ; no values returned
06:42:38 <postman> > ^-^
06:42:38 <postman> 2
06:42:38 <postman> >
06:42:38 <lambdabot>  Parse error
06:42:39 <lambdabot>  Not in scope: `^-^'
06:42:50 <postman> Failure02: see?
06:43:28 <postman> The only thing bad about Scheme is that it seems less work has gone into its implementations.
06:43:28 <ikegami--> Perl6 has the Neko operator ^..^
06:43:55 <mahogny> perl... omg, keep it away
06:44:23 <Failure02> i don't know scheme... but can you have the parantheses around it still?
06:44:32 <dons> > let (^-^) = ":)" in cycle (^-^)
06:44:33 <lambdabot>  ":):):):):):):):):):):):):):):):):):):):):):):):):):):):):):):):):):):):):):...
06:44:46 <ikegami--> hehe
06:45:13 <postman> Failure02: how do you mean? (exp) is call exp
06:45:39 <Failure02> okay. so you could just make it a function then
06:45:40 <dons> > let (^-^) = map in (^-^) (:[]) ":)"
06:45:41 <lambdabot>  [":",")"]
06:45:53 <dons> I do like :[]
06:45:57 <dons> it should have a name
06:46:10 <dons> oh, I think we had a name actually
06:46:12 <ndm> box
06:46:15 <Failure02> but isn't ' a reserved char in scheme? i love using primes in haskell
06:46:21 <dons> the "I-just-swallowed-TaPL"
06:46:22 <dons> operator
06:46:41 <ski> return
06:47:09 <dons> ndm, yeah, now where have I see 'box'?
06:47:13 <dons> in an old version of List.hs?
06:47:15 <postman> Failure02: yes
06:47:18 <ndm> dons, PreludeExts
06:47:24 <ndm> @oldwiki PreludeExts
06:47:24 <lambdabot> http://www.haskell.org/hawiki/PreludeExts
06:47:28 <dons> ah!
06:47:51 <ndm> http://www.haskell.org/hawiki/LicensedPreludeExts
06:47:52 <postman> Also the concept of "reserved character" is void in most Scheme implementations, since you can always use read-sytax, or something like that.
06:47:52 <lambdabot> Title: LicensedPreludeExts - The Haskell Wiki
06:48:08 <postman> In R5RS there is no such facility, though.
06:48:17 * ndm has been working with box all morning
06:51:04 <postman> I think that not be able to put - in a name, damages readability. NobodyLikeThis, orThat, or_this, so instead they all use x xs, n i, and all other meaningless names.
06:51:12 <postman> being able, even
06:52:39 <postman> A good example is MkState, instead of make-state
06:53:04 <postman> Haskell is filled with this "shorthand". Does it help readability?
06:53:33 <psi> I also like '-' in names.
06:54:03 <ndm> postman: imagine parsec, but with proper names intead of operator symbols
06:54:11 <ndm> or monads, without >> and >>=
06:54:15 <postman> Good Lisp code (e.g. see code in base Emacs), is easily readable.
06:54:26 <postman> ndm: I am not saying one should dump operators.
06:54:41 <Failure02> in haskell there's the alternative of writing'identifiers'like'this. ;) hopefully no one does that though.
06:55:32 <Failure02> but i agree that - is a tad more readable than _. and camel casing isn't pretty
06:55:39 <postman> ndm: well, in fact "many", and "many1" don't use + and *.
06:55:51 <postman> ndm: breaking EBNF tradition.
06:56:34 <ndm> postman: thats only beacuse you can't have prefix/postfix operators in Haskell
06:57:31 <dons> > let maybe'we'should'do'this'more'often = error "or maybe not" in maybe'we'should'do'this'more'often
06:57:32 <lambdabot>  Add a type signature
06:57:36 <dons> boo
06:57:49 <Failure02> you can sort of have prefix.
06:57:51 <postman> ndm: true, but things like this you can do in Scheme (with e.g. macros)
06:58:03 <ndm> postman: Yhc supports prefix operators, i think
06:58:30 <Failure02> > let (!!!) x = x in (!!!) 666
06:58:31 <lambdabot>  666
06:58:57 <dons> ndm, really? prefix operators? that would be nice.
06:59:02 <ndm> Failure02: as soon as you put a prefix operator in brackets, you've lost the beauty of a prefix operator
06:59:09 <dons> i've often wished for them
06:59:11 <ndm> dons, I think so, nhc98 did and we haven't tweaked that bit
06:59:17 <roconnor> are IOArrays strict?
06:59:24 <ndm> dons: i think -12 is done using prefix operators, but i may be wrong
06:59:33 <dons> hmm, don't think so
06:59:33 <dons> try IOUArrays?
06:59:42 <dons> ndm, also I'd like `expr in here` syntax
06:59:53 <dons> for point-free hacking, like x `flip (.)` y
07:00:01 <postman> ndm: yes, that's the only prefix operator, and I believe the implementors don't like it.
07:00:04 <ndm> dons: if you can patch the parser in the copmiler, go for it!
07:00:19 <ndm> postman: nhc generalised it, has general prefix operators, and then - is no longer a special case
07:00:23 <ndm> (i think, might be wrong)
07:00:28 <roconnor> dons: no I want unstrict arrays ;)
07:00:44 <ndm> dons, and you probably can't patch the copmiler, i spent 3 hours yesterday and couldn't hack PRAGMA's in
07:00:46 <dons> oh. i'm biased, it seems, roconnor
07:00:56 <postman> ndm: Any system can do anything, but than it's not Haskell anymore. Then it's Haskell + anything.
07:01:22 <dons> yeah, i like ghc -fanything-goes
07:01:32 <ndm> postman: Yhc is not haskell, its ~= haskell
07:01:52 <postman> There are lots of tools for generating code (e.g. for Binary, Xml (HaXml)), that shown weaknesses in the language.
07:02:02 <postman> "But wait we have TH".
07:02:07 <postman> See, my point?
07:02:16 <dons> DrIFT is common too
07:02:22 <dons> maybe even the preferred tool?
07:02:23 <postman> dons: I know.
07:02:40 <dons> its a strong point that many tools exist for generating haskell
07:03:23 <postman> show, even
07:07:51 <postman> Another example is "RULES". "RULES" is basically a rather weak language for doing something that can be done better with macros.
07:08:56 <postman> The sequence >> foo => sequence_ >> foo is a nice example (from the mailing lists)
07:09:39 <kosmikus> that should be done with a macro in your opinion? within the language?
07:09:51 <ndm> postman: in fact, i think its a weak way of doing proper function matching on the LHS
07:10:16 <ndm> i.e. you could add: not ($not x) = x
07:10:29 <ndm> as a rule, which is both at runtime and compile time
07:10:38 <ndm> and then you can just treat rules as inlining
07:10:58 <ndm> postman: if you think macros == RULES, you haven't understood the power of rules :)
07:11:44 <edwardk> you can play with advise in the icfp thing, theres a rules engine in there, its just perverse =)
07:12:11 <postman> kosmikus: Why not? It seems a better approach then making up a new language as a hack. IIRC SPJ wants people to do domain specific optimizations (TH paper) done by _users_.
07:12:13 <dcoutts> postman, that's not true. RULES are much more powerful than macros
07:12:31 <dcoutts> try doing list fusion with macros
07:12:44 <dons> yeah, they're more like a scripting language for the optimiser
07:13:01 <joelr1> dcoutts: how do you do list fusion with rules? is that described anywhere?
07:13:12 <ndm> @google foldr build fusion haskell
07:13:15 <lambdabot> http://www.haskell.org/haskellwiki/Correctness_of_short_cut_fusion
07:13:15 <lambdabot> Title: Correctness of short cut fusion - HaskellWiki
07:13:18 <dons> that's the main use of rules, joelr :)
07:13:21 <dcoutts> joelr1, in various papers and in ghc libs itself
07:13:33 <joelr1> thanks
07:13:41 <kosmikus> also, if you'd turn optimisations into macros, you might get error messages in terms of optimised code ...
07:13:46 <dons> check out Playing by the rules: rewriting as a practical optimisation technique in {GHC}
07:13:50 <dcoutts> joelr1, look for build/fold fusion
07:13:57 <postman> dcoutts: macros are turing complete. I don't see your point.
07:14:28 <dcoutts> postman, so what can they match? they're jsut arbirtary code that has access to the whole AST and can do anything to it?
07:14:38 <ndm> postman: are you talking LISP macros or C macros?
07:14:52 <kosmikus> TeX macros?
07:14:53 <postman> ndm: Scheme macros.
07:15:10 <dcoutts> I thought that a macro could only expand into code, not modify other code in the same module
07:15:11 <joelr1> ugh, i must be dumb but i don't see ay rule pragmas on that page. i thought rules was a pragma
07:15:14 <postman> ndm: LISP died a long time ago. It's Lisp.
07:15:32 <kosmikus> aren't Scheme macros only there as an excuse for not having lazy evaluation? ;)
07:15:33 <ndm> postman: thats a bit like writing your own compiler extensions, which RULES is too, so yes, in that sense they are more powerful than RULES
07:15:34 <joelr1> @google Playing by the rules: rewriting as a practical optimisation technique
07:15:37 <lambdabot> http://citeseer.ist.psu.edu/peytonjones01playing.html
07:15:53 <ndm> postman: I write ADA just to piss people off :)
07:16:01 <joelr1> dcoutts: you can do anything you want in macros
07:16:02 <postman> ndm: Indeed, that's the point of the exercise.
07:16:08 <joelr1> dcoutts: they are eval-d
07:16:23 <edwardk> rules get applied in multiple passes though, do scheme macros?
07:16:24 <joelr1> dcoutts: at least Common Lisp macros
07:16:36 <dcoutts> joelr1, but can they modify other parts of the same program, non-local stuff
07:16:49 <ndm> edwardk: Macros have recursion, so they can apply themselves on their own
07:17:05 <dcoutts> the crucial question is where they apply
07:17:09 <joelr1> dcoutts: sure, why not, macros are just programs
07:17:23 <dcoutts> do I have to write a named macro to use it?
07:17:26 <joelr1> dcoutts: you can set variables, re-define functions, classes, etc. and then just return some code
07:17:41 <edwardk> ndm: yeah but the whole point of the rule thing is they can apply, then others can apply and you just throw all the rules into a pot and they can work themselves out coalescing things towards a reasonably efficient representation. with macros you wind up being a llot more specific it seems
07:17:42 <ndm> dcoutts, have you seen Perl's features for rewriting the language that you type?
07:17:44 <postman> kosmikus: Why would Scheme not have lazyness? You can easily implement the primitives such that they give lazy semantics. Although, I admit not as efficiently as Haskell does.
07:18:02 <joelr1> dcoutts: mmm... no, you don't have to. `(foo ,bar) can be anywhere
07:18:08 <kosmikus> postman: I was joking
07:18:11 <ndm> edwardk: if only, th problem is Rules are non-terminating and non-confluent and a tad fragile
07:18:19 <joelr1> dcoutts: that would be a shortcut for (list 'foo bar) or something like that
07:18:21 <ndm> so you end up hacking a control structure in, btu without the proper tools
07:18:31 <edwardk> i didn't say they worked out that well in practice =)
07:18:37 <postman> kosmikus: oh, hard to tell on IRC. (I missed your smiley)
07:18:38 <edwardk> but that it seemed like the idea
07:18:39 <jgrimes_> how would you map a function of two arguments across a list if the second argument is static?
07:18:50 <dcoutts> joelr1, and running that macro can change any other code in the same module?
07:19:04 <ndm> dcoutts, macro :: ParseTree -> ParseTree
07:19:19 <dcoutts> ndm, but that's not good endough
07:19:24 <joelr1> dcoutts: of course. if you redefine a function you are changing the code. there's no concept of modules in lisp, not the same way as in haskell so you are changing stuff in the same program
07:19:26 <dcoutts> not to do what RULES do
07:19:45 <ndm> dcoutts, but you could imoplement a rule engine in Scheme macros
07:19:55 <dcoutts> joelr1, ok, so if a macro is defined in one module and then that module is imported into another module then does the macro still run and change my client module?
07:20:44 <joelr1> dcoutts: when you use a macro you are running eval so whatever is in the macro gets executed. there's no concept of modules, it's one large body of code. there's the concept of "namespaces" (packages) but that's still the same body of code as everything else and you can change it
07:20:45 <dcoutts> ndm,  macro :: ParseTree -> ParseTree is not good enough if it's pure, you need to globally re-write the program, not just generate an AST
07:20:53 <postman> joelr1: You are talking about CL?
07:21:04 <joelr1> dcoutts: and there's no importing of modules
07:21:15 <joelr1> dcoutts, postman: yep, i'm talking common lisp macros
07:22:13 <dcoutts> joelr1, so I just use some function someone else supplied, eg fold and by using that function it can cause a macro to run at compile time and globally modify the program being compiled?
07:23:01 <joelr1> dcoutts: positively so
07:23:17 <dcoutts> right then, ok that's more powerful than RULES
07:23:35 <postman> :)
07:23:49 <joelr1> dcoutts: i quasi-finished the cocoa bridge for common lisp, for example. i would inspect the objective-c runtime and generate classes on the fly
07:24:46 <joelr1> dcoutts: or let you define those (in a macro). when you use the define-objc-class macro it defines a new class and a bunch of methods, etc. so it modifies your program to include those in the compiled binary
07:25:09 <dcoutts> so what mechanism invokes a macro?
07:25:16 <dcoutts> I don't have to call it myself?
07:25:40 <joelr1> dcoutts: it looks like a function call so you need to invoke it
07:25:55 <dcoutts> so you'd embed it in some function that I did want to call
07:26:18 <joelr1> dcoutts: yes, or just tell you that one is available
07:26:23 <joelr1> so that you can call it
07:26:34 <dcoutts> eg if I ever used any function from the module of list utils then it'd run this macro over the whole program
07:26:40 <dcoutts> so it can be transprent
07:26:47 <dcoutts> transprent/transparent
07:26:52 <postman> joelr1: I think you could even catch some "non-existent function" exception and let the macro automatically generate the bindings at that moment.
07:26:55 <joelr1> yes, the beauty of lisp is that you can modify your runtime as you wish
07:27:23 <joelr1> dcoutts: sorry, modify your program, not the lisp runtime. although you could redefine the runtime functions too.
07:27:44 <dcoutts> so would I need to have this macro called by every function in the module to make sure it got invoked on client's code?
07:27:45 <postman> joelr1: (and then call it), ok?
07:27:50 <joelr1> postman: you would need to provide a handler for that
07:28:08 <postman> joelr1: yes, that's what I meant.
07:28:17 <joelr1> dcoutts: i'm not sure what you are asking about. you can modify something once and then it will be used by everyone
07:29:06 <roconnor> I wishmapArray had type (MArray a' e' m, MArray a e m, Ix i) => (e' -> e) -> a' i e' -> m (a i e)
07:29:12 <dcoutts> joelr1, well I mean, suppose you've got a module of list functions, I want to rewrite the user's code if they ever use even a signle function from this list module.
07:29:48 <joelr1> dcoutts: for example, the jpeg library i used once would run performance tests at runtime to choose what implementation suited your platform the most. it would then "tell the rest of the code" to use that implementation. so every time i would load the (compiled) jpeg library i would use the optimized implementation
07:30:04 <sjanssen> @hoogle mapArray
07:30:05 <lambdabot> Data.Array.MArray.mapArray :: (MArray a e' m, MArray a e m, Ix i) => (e' -> e) -> a i e' -> m (a i e)
07:30:07 <joelr1> dcoutts: yes, every function would need to invoke your macro then
07:30:32 <sjanssen> norpan: you're right, that is annoying
07:30:44 <sjanssen> I'
07:30:49 <sjanssen> d consider that a bug
07:30:58 <dcoutts> joelr1, well it sounds like macros are indeed very powerful, if a bit inconvenient for the problem that RULES tackle.
07:31:53 <dcoutts> ChilliX, hia. So now that it's over, can you tell us what insider info did you have on the ICFP programming contest? :-)
07:31:57 <joelr1> i have a lot to learn. i could not understand that cuts page
07:32:08 <dcoutts> cuts?
07:32:09 <joelr1> is the icfp contest over?
07:32:13 <dcoutts> yep
07:32:48 * asbeta thinks about porting rewrite rules to ocaml :)
07:32:53 <joelr1> dcoutts: correctness of short cut fusion, could not understand it
07:32:55 <joelr1> asbeta: hiya!
07:33:04 <joelr1> who won the icfp contest?
07:33:07 <joelr1> ocaml again? :D
07:33:12 <dcoutts> we don't know yet
07:33:16 <joelr1> oh
07:33:24 <asbeta> joelr1, hi, don't know :)
07:34:08 <joelr1> asbeta: i still don't know if i want to use ocaml or haskell. the fact that the lexifi people had to fix up the compiler to get x `plus` y gives me pause
07:34:32 <dcoutts> joelr1, that correctness of short cut fusion page on the wiki assumes a lot of previous knowledge of fold/build fusion, theorems for free and strictness
07:34:45 <joelr1> dcoutts: right
07:34:49 <_Codex> joel: http://www.icfpcontest.org/scoreboard.shtml has a pretty good list of who might win :)
07:34:50 <dcoutts> joelr1, you want the original paper by spj on short cut fusion
07:34:51 <lambdabot> Title: ICFP Programming Contest, 2006 : Scoreboard
07:34:51 <kosmikus> joelr1: the last time ocaml won was 2002, not?
07:34:52 <asbeta> joelr1, there is a way to make "plus" a keyword
07:35:30 <joelr1> asbeta: yes, with camplp4
07:35:59 <joelr1> dcoutts: ugh... sure. my brain hurts just thinking about it
07:36:19 <joelr1> haskell: beats brain age for nintendo ds!
07:36:33 <joelr1> as far as exercising your brain goes
07:37:04 <ChilliX> dcoutts: Hi!
07:37:12 <dcoutts> joelr1, it's not that hard actually, it just says that if you've got a list producer and a list consumer then you can fuse those two together and never have to allocate an intermediate list. so each time the producer produces a list element then the consumer consumes it directly. So no list cells are allocated.
07:37:19 <joelr1> _Codex: i wish there was a way to find out what team is using what language
07:37:20 <ChilliX> Well, I knew about the um and some of the puzzles.
07:37:37 <dcoutts> ChilliX, ah right :-) they're were fun.
07:37:41 <joelr1> dcoutts: is ghc using this technique right now?
07:37:45 <_Codex> joel: yeah, that's pretty bad that teams cannot indicate their fafourite language.
07:37:45 <dcoutts> joelr1, yes
07:37:59 <joelr1> dcoutts: and how is that triggered?
07:37:59 <ChilliX> I kind of followed some of the online trace of the event.
07:38:04 <ChilliX> Seemed like lots of fun.
07:38:15 <dcoutts> joelr1, simply by using lit functions, it's all automatic
07:38:28 <ChilliX> And the amount of work Tom7 et al put in must have been insane.
07:38:43 <joelr1> dcoutts: where's the original paper?
07:38:54 <ChilliX> I guess, a significant number of the research students of POP will now finish their degree half a year later ;)
07:39:06 <dcoutts> ChilliX, I bet. We were all suprised when the codex spat out another file which turned out to be a whole mini-unix system.
07:39:36 <dcoutts> joelr1, in spj's list of papers, on his homepage
07:39:55 <ChilliX> They actually got a compiler for a small ML-ish language, which they used to develop the um code.
07:40:08 <pejo> joelr1, I think bug 751 is related to the infromation you wanted. And some thread on ghc-users, subject MacOS X / PowerPC
07:40:08 <ChilliX> (I mean the programs running on the um)
07:40:19 <dcoutts> joelr1, http://research.microsoft.com/~simonpj/Papers/deforestation-short-cut.ps.Z
07:40:37 <dcoutts> ChilliX, right
07:41:02 <joelr1> dcoutts: thanks
07:41:11 <joelr1> pejo: thanks
07:41:33 <ChilliX> And they put so much effort into the background story.
07:41:33 <joelr1> pejo: got links?
07:41:45 <ChilliX> Like a full scale adventure game.
07:42:03 <dcoutts> yeah, there was lots of funny stuff in there
07:42:21 <pejo> joelr1, hm, no, it's in my mailbox, sorry. I can give you the message id, if thats of any help?
07:42:22 <dcoutts> in the various READMEs and spam emails
07:42:47 <joelr1> pejo: i'll look at track and wait for JaffaCak1
07:43:04 <ChilliX> It also seemed like many more people than in previous years participated.
07:43:49 <Igloo> The fact the true task was hidden may have enticed onlookers to actually start
07:44:06 <dcoutts> good point
07:44:15 <asbeta> hmm.. are those rewrite rules applied in compile-time or run-time?
07:44:21 <dcoutts> asbeta, compile time
07:44:23 <ChilliX> Igloo: true
07:45:07 <JaffaCak1> ChilliX: hi there ;)
07:45:33 <postman> dcoutts: Someone said earlier thatn not(not $x) was rewritten to x also at run-time.
07:45:37 <ChilliX> JaffaCak1: Hi! :)
07:45:56 <JaffaCak1> how goes it?
07:46:00 <postman> dcoutts: Not that I believed that.
07:46:05 <dcoutts> postman, not at runtime, it can be done at compile time
07:46:40 <dcoutts> joelr1, the nice thing about RULES is that they're applied automatically by the compiler so you don't have to write any code to transform abstract syntax trees and they can be type checked etc.
07:47:09 <dcoutts> joelr1, you can match against values by name and/or by type
07:47:20 <ChilliX> JaffaCak1: Quite well actually.  We had a nice 2.8 last week.  Otherwise, NY is a nice place to be for a while.
07:47:23 <joelr1> dcoutts: there's a rules pragma, right?
07:47:29 <ChilliX> JaffaCak1: How about you guys?
07:47:52 <JaffaCak1> not bad, kids just had chickenpox :(
07:47:55 <dcoutts> joelr1, yes, written {-# RULES ... #-}, hence people call them RULES.
07:48:02 <ChilliX> JaffaCak1: oh - ok again?
07:48:05 <sjanssen> I think we need all kinds of crazy RULES.  sum [1..n] can rewrite to n*(n+1)/2
07:48:09 <joelr1> dcoutts: he
07:48:13 <JaffaCak1> yeah, survived
07:48:30 <joelr1> dcoutts: but it sort of requires you to know when to apply what rules pragma, right? why not do it automatically
07:48:31 <dcoutts> joelr1, joelr1, eg not (not a) => a, or (a :: Foo) `seq` b => b
07:48:31 <ChilliX> JaffaCak1: Leon had to get a vaccination against that actually before he was allowed to day care in NY.
07:49:08 <dcoutts> joelr1, because you as library author know what rules are true, the compiler doesn't.
07:49:23 <joelr1> ChilliX = manue t.c.?
07:49:30 <joelr1> manuel, sorry :-)
07:49:38 <ChilliX> JaffaCak1: What's the plan w/ ICFP btw.  Sine was thinking to come, too, at some point...
07:49:52 <joelr1> dcoutts: hmm... right
07:50:00 <joelr1> so much to learn, so little time
07:50:02 <JaffaCak1> ChilliX: yeah, but we decided against it in the end..
07:50:04 <dcoutts> joelr1, so for example, dons and I know what RULES apply for the ByteString library. When you import and use functions from that library you are benefiting from the domain-specific knowledge that dons and I have embeded in it.
07:50:05 * ChilliX cover is gone - oh no!
07:50:05 <postman> joelr1: Did you ever blogged on this global transforming macros? I know it's possible, I just never did anything with it.
07:50:18 <JaffaCak1> ChilliX: just too much of a logistical nightmare
07:50:27 <dcoutts> joelr1, or rather the knowledge of the domain-specific optimisations
07:50:32 <joelr1> ChilliX: are you on wall st. as well?
07:50:32 <ChilliX> JaffaCak1: hmm, yeah, I understand - but it's a pity
07:50:46 <dcoutts> joelr1, so you write clear code and we transform that into fast code.
07:50:51 <joelr1> postman: never
07:50:51 <JaffaCak1> I know :(
07:51:01 <ChilliX> JaffaCak1: Stephanie and Steve are coming with Elli.  We thought about getting joint care.  So it's more fun for the kids.
07:51:11 <joelr1> dcoutts: so much to learn!
07:51:18 <ChilliX> If you guys would come, we'd book a kindergarten ;)
07:51:40 <ChilliX> joelr1: nope, just Gabi and Lennart
07:51:42 <JaffaCak1> ChilliX: hehe, the ICFP creche
07:52:13 <dcoutts> joelr1, you don't need to learn unless you want to write cunning haskell libs with domain-specific optimisations.
07:52:46 <joelr1> ChilliX: funny, my daughter's name is gabriela and i always spell it gaby :) i guess i gotta change that to gabi since you are the second person i see using that
07:52:51 <ChilliX> joelr1: and they are not working on Wall St, but Madison Ave ;)
07:53:09 <joelr1> dcoutts: i see cunning haskell ahead of me
07:53:19 <dcoutts> good good :-)
07:54:13 <joelr1> ChilliX: well, yeah, but how come you are not on "wall st"? if not a secret :) investment banks love brainy ph.d-s :D
07:54:24 <joelr1> i wish i could return to wall st myself
07:54:47 <joelr1> as it is, i just keep thinking of how to milk it :D
07:55:18 <ChilliX> joelr1: Well, somebody has to look after our research students and research projects.
07:55:56 <joelr1> ChilliX: ah!
07:56:52 <ChilliX> joelr1: besides, I quite like the intellectual freedom of research, as opposed to production
07:56:53 <joelr1> i think wall st. should use haskell more. just imagine the possibilities: haskell and program trading, for example
07:57:12 <ChilliX> :)
07:57:28 <joelr1> ChilliX: i'm with you. i left my last job out of ... boredom
07:57:33 <ChilliX> Well, we'll see how this all pans out at CS
07:57:48 <ChilliX> joelr1: Yeah, I can understand that
07:58:34 <joelr1> ChilliX: i want to apply haskell to similarity search in time series. i hear data parallel haskell is not ready for prime time so i'll just stick to the regular stuff, try to learn, optimize, etc. hopefully it will all be fast enough
07:59:21 <ozone> hey joel, chillix
07:59:32 <ozone> i presume you're joel reymont?
07:59:33 <joelr1> ChilliX: i'm always looking for data points as far as haskell and number crunching goes ... but my understanding is that lennart (not sure about gabi) is not doing anything high-performance
07:59:40 <joelr1> ozone: yes, why? hi :)
07:59:58 <joelr1> ozone: reveal your true self, please!
08:00:00 <ChilliX> joelr1: We have a fairly complete API for sequential exec of DPH without automatic flattening in the ghc-ndp branch
08:00:09 <joelr1> cause it doesn't seem like i know you :D
08:00:11 <ozone> joelr1: hey, i was the guy who gave you a small erlang/xmpp discussion when you emailed me about hoc the other week :)
08:00:24 <ChilliX> The user-visible portion of that will stay the same when we parallelise (which we just started to)
08:00:40 <ChilliX> ozone: Hi!
08:00:40 <joelr1> ozone: oh! yes, yes, the movie guys in australia :D
08:00:48 <ChilliX> lol - movie guy
08:00:58 <ozone> joelr1: i'm a movie guy!  ha
08:01:02 <ozone> i like this image
08:01:07 <ChilliX> I bet you do!
08:01:21 <ozone> hey man, you doubting my charisma
08:01:34 <joelr1> hehe
08:01:52 <ozone> don't make me whip your ass in cs
08:02:05 <ChilliX> you wish
08:02:11 <joelr1> i gotta poke lennart from time to time, i guess. i don't know of anyone else using haskell on wall st
08:02:14 <joelr1> ozone: cs
08:02:16 <ozone> joelr1: yeah, actually giving a talk about erlang this friday
08:02:17 * ChilliX puts on a mean face.
08:02:20 <joelr1> ozone: computer science?
08:02:33 <ozone> joelr1: uhh, that's probably one area where i won't be whipping ChilliX's ass in...
08:02:37 <joelr1> ozone: cool!
08:03:14 <joelr1> my haskell vs erlang blog post is like the all-time favorite ever
08:03:27 <ozone> joelr1: it's a good objective analysis
08:03:38 <joelr1> ozone: nah, highly skewed, actually
08:03:58 <ozone> oh, well, in that case...
08:04:06 <joelr1> haskell and erlang have their niches as someone pointed out
08:04:08 <ozone> (cs == counter-strike, btw)
08:04:11 <joelr1> they are just... different
08:04:17 <joelr1> ozone: ah, counter-strike
08:04:27 <ozone> right
08:04:39 <ozone> i'm still threatening to use haskell into our work project
08:04:49 <ozone> C++, haskell, erlang and objective-c all on the same project
08:04:54 <joelr1> i'm going through the animal crossing craze myself. well, the whole family is :D 3 nintendo ds-s, 3 cartriges, all weekend type of thing :D
08:04:55 <ozone> could life be any more fun?
08:04:56 <ChilliX> hehe
08:05:03 <ChilliX> Just chuck out C++
08:05:20 <ozone> ChilliX: neh, now i know how to do type-level hackery with templates, it's too much fun :)
08:05:24 <joelr1> i wish i had known just erlang, for example
08:05:38 <joelr1> my biggest problem is worrying about making the right choice.
08:05:39 <ChilliX> ozone: Twisted sens eof fun :P
08:05:42 <ChilliX> sense
08:06:01 <ChilliX> I actually had a C++ template program on my first slide of my 2.8 talk :)
08:06:06 <joelr1> erlang vs. haskell? haskell vs. ocaml? lisp?
08:06:09 <ozone> 2.8?
08:06:14 <ChilliX> IFIP WG2.8
08:06:18 <joelr1> yeah, what's 2.8? second time i hear that
08:06:25 <ChilliX> the thing we had at COffs
08:06:27 <ozone> joelr1: well, if you're doing a serious project, you have to pick a choice sooner or later
08:06:31 <ozone> you ended up with ruby, right?
08:06:36 <ozone> ChilliX: ah, fun
08:06:45 <ChilliX> joelr1: crazy FP people meeting once a year
08:06:46 <vincenz> zarvok: thx!
08:06:47 <ozone> i'm slightly sad i'll be missing haskell workshop again this year
08:07:44 <joelr1> JaffaCak1: ping
08:07:50 <JaffaCak1> pong
08:08:00 <joelr1> JaffaCak1: so... how about them threading bugs?
08:08:08 <zarvok> vincenz: I'm impressed with the speed you got while maintaing 64 bit compatibility
08:08:09 <lambdabot> zarvok: You have 1 new message. '/msg lambdabot @messages' to read it.
08:08:23 <JaffaCak1> joelr1: in relation to what?
08:08:37 <joelr1> JaffaCak1: i doubt i'll be anywhere near wolfgang's level anytime soon but i do have both a G4 and a MBP
08:08:41 <joelr1> JaffaCak1: mac osx of course
08:08:49 <joelr1> JaffaCak1: spj asked for help today
08:09:04 <JaffaCak1> yes, sorry .. are you offering?
08:09:10 <JaffaCak1> that'd be great
08:09:44 <joelr1> JaffaCak1: yes, i have both ppc32 and mac intel. i don't want to let you in via ssh like last time but i do want you to teach me stuff :D
08:10:19 <joelr1> and of course i'm offering to help. i've been mindlessly recompiling ghc 6.5 time and again so i might as well investigate something
08:10:51 <JaffaCak1> the first problem we want to find is with 6.4.2
08:11:26 <JaffaCak1> http://hackage.haskell.org/trac/ghc/ticket/751
08:11:28 <lambdabot> Title: #751 (ghc 6.4.2 on OS X 10.4.6 fails a compiler error building Crypto-3.0.3.) -  ...
08:11:37 <JaffaCak1> there's a rather long log on that bug
08:11:49 <joelr1> JaffaCak1: wouldn't it be the same in 6.5? i recompiled 6.4.2 a few times but never had a problem. then again, i never compiled crypto 3.0.3
08:12:06 <joelr1> JaffaCak1: yes, i have that bug open
08:12:44 <JaffaCak1> AFAIK it isn't specific to crypto
08:12:58 <vincenz> zarvok: it's not particularly complicated ;)
08:12:59 <joelr1> JaffaCak1: would it work to try to compile crypto with 6.5 on mac intel to see what happens?
08:13:02 <JaffaCak1> people have reported randoim crashes when compiling other stuff
08:13:20 <JaffaCak1> joelr1: maybe, yes
08:13:39 <joelr1> JaffaCak1: i used 6.4.2 last year, you probably remember that. i used it quite heavily and never had the problem described in 751
08:13:49 <JaffaCak1> yes, odd
08:13:56 <ozone> joelr1: binary search? :}
08:14:04 <joelr1> ozone: what?
08:14:10 <ozone> (for the bug)
08:14:23 <JaffaCak1> joelr1: we did switch to building stage2 with -threaded at one point, that may have been after you were playing with it
08:14:23 <ozone> sorry, too obscure.  binary search the changesets...
08:15:15 <joelr1> JaffaCak1: i'll try to look into it tonight then. first on 6.5/mac intel since it's ... faster. i'll fallback to the ppc if i don't see crashes
08:15:52 <JaffaCak1> joelr1: great, thanks
08:16:24 <joelr1> JaffaCak1: 6.5 is being built with -threaded via -smp, right? stage2 included? i did report a problem with running tests and you said it was something thread-related, i believe. suggested i run the test driver 100 times in a loop until i catch the bug
08:17:04 <JaffaCak1> -threaded is the same as -smp now
08:17:19 <JaffaCak1> oh yes, you have some random hang problem
08:17:38 <joelr1> JaffaCak1: right, random hang problem when running tests. i haven't looked into it yet.
08:18:03 <JaffaCak1> that might be the same thing as #751, but probably isn't
08:18:56 <joelr1> JaffaCak1: i'll try 751 first since it's an easier test. i think. easier to see if something pops up
08:19:20 <JaffaCak1> right
08:20:07 <joelr1> why is haskell so irresistable?!
08:20:08 <pejo> joelr1/JaffaCak1, is the theory here to provoke it to crash, and run gdb on it?
08:20:52 <JaffaCak1> pejo: yes, that would be a good start
08:21:58 <ozone> joelr1: our C++ guru at work is getting a bit sick of saying "ah, so that's like <x> in haskell, but not quite as elegant..."
08:22:11 <ozone> getting a bit sick of me saying that, rather
08:23:07 <ozone> though it's nice when he talks about using a null object as a better way of the error code vs exception argument, and the response is "ah, right, like a maybe monad"
08:26:32 <joelr1> ozone: he
08:26:47 <ChilliX> ozone: Well that's what he gets for using a language in which the words "elegance" and "principled approach" were banned during language design...
08:26:47 <joelr1> i want a haskell job!
08:27:01 <pejo> JaffaCak1, any qualified guess what one might be looking for?
08:27:26 <JaffaCak1> actually no
08:27:33 <ozone> joelr1: you could just do that i do and try to get haskell in via the back door :)
08:27:37 <joelr1> i have a _very_ well paying job where we switched from mostly lisp to mostly ruby (i take some credit) but i'm still not content
08:27:49 <joelr1> ozone: maybe later :)
08:28:04 <ozone> JaffaCak1: oh, can you compile a static library with ghc and link it with msvc++ on windows?
08:28:04 <joelr1> ozone: although i doubt it. i tried pushing erlang from the beginning but it did not work
08:28:25 <JaffaCak1> joelr1:  I fixed one thing on Solaris which had to do with defining _REENTRANT when including system headers to get the thread-safe version of errno, it might be related to that... maybe
08:28:32 <ozone> joelr1: yeah, i'm just surprised that i wasn't the one pushing erlang at our place.  sometimes it's good to have an ex-prolog fanatic :)
08:28:41 <JaffaCak1> ozone: don't think so
08:29:17 <yaxu> we're still on perl here
08:29:17 <JaffaCak1> joelr1: the REENTRANT fix is in the ghc-6-4-branch, so actually it would be good if you could use that
08:30:02 <JaffaCak1> joelr1: grab the sources with CVS, that is
08:31:00 <joelr1> oops
08:31:11 <pejo> JaffaCak1, would 0724 source snapshot have that included?
08:31:12 <joelr1> JaffaCak1: i'm installing the latest darwinports version
08:31:30 <joelr1> JaffaCak1: i can use it to bootstrap cvs, though, right?
08:31:41 <ozone> joelr1: does that work on ICBMs now?
08:31:50 <ozone> (Intel-Chip-Based-Macs)
08:31:50 <JaffaCak1> pejo: yes, a snapshot is fine too (probably better)
08:31:57 <JaffaCak1> joelr1: yes
08:32:07 <vincenz> JaffaCak1: the internships at MSR are mostly aimed at master students?
08:32:28 <joelr1> ozone: no, does not. i have a ppc powerbook too
08:32:33 <JaffaCak1> vincenz: mostly phd students actually, sometimes they take masters students
08:32:38 <vincenz> ah cool :)
08:32:42 <joelr1> well, enough of basking in the warm haskell glory :D gotta go do what i'm paid for. back later
08:32:48 <vincenz> let's see if I can convince my supervisor
08:32:57 <ozone> joelr1: later
08:36:24 <dcoutts> JaffaCak1, would you accept a patch to remove -s from SRC_INSTALL_BIN_OPTS by default? The install-strip makefile target already does $(MAKE) EXTRA_INSTALL_OPTS='-s' install
08:37:12 <JaffaCak1> dcoutts: what's accepted practice these days?  to install unstripped?
08:37:20 <dcoutts> JaffaCak1, we get complaints from our gentoo QA people that ghc's build system strips binaries when it shouldn't
08:37:42 <dcoutts> JaffaCak1, well most distros strip themselves, or strip and put the debug info elsewhere
08:37:50 <dcoutts> but pre-stripping removes those possabilites
08:38:12 <dcoutts> so actually, most end users want it striped and distros want to have control over that themselves
08:38:35 <dcoutts> but apparently the autotools default is to install unstriped
08:38:55 <dcoutts> at least I assume that must be the case since we don't have to patch most things to not pre-strip
08:40:00 <JaffaCak1> ok, then we'll probably have to change various other things to cope with the change, like the RPM script, FreeBSD port, etc.
08:40:47 <dcoutts> eg I believe Fedora strips off debug stuff and optionally installes it in a seperate dir for when one needs to use gdb
08:41:16 <JaffaCak1> I guess I'm not against the change, as long as we can do it without imposing lossage elsewhere
08:41:48 <dcoutts> JaffaCak1, or the quick hack is to keep the current default and add install-nostrip :-) just like there is currently a (redundant) install-strip
08:42:21 <JaffaCak1> yes, that would be easier
08:42:43 <dcoutts> ok, we'll send a patch for that
08:43:25 <JaffaCak1> righto
09:16:08 <sjanssen> @quote
09:16:08 <lambdabot> Philippa says: hey, if the guy wants a monadectomy that's his choice
09:16:26 <sjanssen> ull
09:18:11 <roconnor> hmmm, the behaviour of IOArray and IOUArray is quite different for arrays of 500 000 elements.
09:18:24 <roconnor> why are IOArrays so slow.
09:18:34 <roconnor> or am I just accessing them wrongly.
09:18:50 <monochrom> IOU is very fast.
09:18:57 <sjanssen> IOUArray uses significantly less memory?
09:19:09 <dcoutts> yes because they're unboxed
09:19:32 <dcoutts> which accounts for the speed and memory usage differences
09:19:37 <monochrom> less memory, one fewer dereference, and also more strict.
09:19:56 <roconnor> but why wouel IOArrays be unusably slow
09:20:28 <roconnor> I mean IOArray (in my case) isn't twice as slow.  It isn't even 10x slower.
09:20:28 <dcoutts> they're not that slow, so unusably depends on what you're using them for :-)
09:20:39 <roconnor> it is slow slow that I gave up.
09:20:52 <dcoutts> perhaps it's the extra strictness
09:21:17 <roconnor> how does strictness make things faster?
09:21:39 <sjanssen> roconnor: how are you using your arrays?
09:21:52 <dcoutts> every time you add a value into an IOUArray, that value gets forced, when you use an IOArray it doesn't get forced
09:21:59 <roconnor> I read 4 Chars from a file handle
09:22:04 <roconnor> assemble them into a Word32
09:22:09 <roconnor> write it into the array
09:22:15 <roconnor> repeat 500 000 times
09:22:19 <dcoutts> then use an IOUArray Int Word32
09:22:24 <sjanssen> oh, sounds like you're writing a Universal Machine
09:22:29 <roconnor> sjanssen: ;)
09:22:37 <roconnor> I can't stop tinkering with it.
09:22:53 <sjanssen> you definitely want a IOUArray here
09:22:56 <dcoutts> probably what's happening is that you're allocating 500,000 thunks for the Word32 byte swapping stuff
09:23:15 <roconnor> dcoutts: I was trying to admend it to assemble a Word32, x, and then store (decode x) into an IOArray.
09:23:45 <dcoutts> then what's getting stored is not the result of (decode x), but the thunk (decode x)
09:24:03 <roconnor> is that a problem?
09:24:05 <dcoutts> by forcing it you make sure that byte swizzling happends before writing to the array and so there is no allocation for the thunk
09:24:24 <dcoutts> it's not a problem, it's just unnecessay in your case and makes it slower
09:24:36 <dcoutts> due to the extra allocations to create the thunk
09:24:49 <dcoutts> as the result of decode x is much smaller than the thunk
09:25:23 <dcoutts> 4 bytes and no additional allocation vs dozens of newly allocated bytes
09:25:28 <monochrom> It is the exactly same reason foldl is less efficient than foldl'
09:26:50 <monochrom> I thought by the 21st Century everyone knew thunking.
09:26:56 <roconnor> so you think if I use seq to eval x before storing it, the IOArray would run reasonably close to the IOUArray speed?
09:27:24 <dcoutts> roconnor, yes
09:28:05 <erider_> hi all
09:28:35 <dcoutts> roconnor, careful how you use seq in IO code, it doesn't always behave the way you might think
09:28:46 <Cale> I'm missing context here, but wouldn't allocating all the cells at once (as in the case of using an IOUArray) usually be faster than allocating them all separately?
09:29:06 <dcoutts> roconnor, use evaluate
09:29:11 <dcoutts> @hoogle evaluate
09:29:12 <lambdabot> Control.Exception.evaluate :: a -> IO a
09:29:13 <lambdabot> Test.QuickCheck.evaluate :: Testable a => a -> Gen Result
09:29:26 <dcoutts> Cale, yes
09:29:27 <Cale> If you're going to seq all the cells on the array creation anyway, and they're of a type such that you can use IOUArray, you probably should use that
09:29:33 <dcoutts> Cale, indeed
09:29:45 <dcoutts> the Q was are IOArrays always unusably slow
09:29:51 <Cale> oh
09:30:04 <Cale> Right then, the answer is no, they aren't :)
09:30:05 <dcoutts> and the answer was no, but in this case the lazyness is the performance problem
09:30:19 <roconnor> Cale, I'm testing replacing the IOUArray Word32 Word32 with IOArray Word32 (Machine ())
09:30:28 <roconnor> so far the results are very disappointing.
09:30:45 <monochrom> IOArrays are unusably fast if you use them for dynamic programming and you end up not using many of the elements.
09:30:59 <dcoutts> IOUArray Word32 Word32 is going to be faster for a UM than a decoded instruction value
09:31:14 <roconnor> dcoutts why is that?
09:31:28 <dcoutts> because the IOUArray Word32 Word32 has much lower overhead
09:31:38 <dcoutts> and decoding the Word32 is cheap
09:31:51 <dcoutts> just a few shifts, logical ands etc
09:32:22 <roconnor> Why is it so hard to store a pointer to a function?
09:32:22 <dcoutts> compared to all the extra memory accesses for a decoded structure
09:32:48 <dcoutts> there's no such thing as a pointer to a function (unless you mean a pointer to a C function)
09:32:55 <monochrom> That is not hard.  Building the function is hard.
09:33:00 <roconnor> isn't a thunk a pointer to a closure?
09:33:16 <monochrom> A thunk is the closure.
09:33:17 <dcoutts> it's also the value with which that function is called
09:34:17 <dcoutts> so the runtime has to allocate a record containing the function to call and all the arguments to the function
09:34:27 <dcoutts> now that's not terribly expensive
09:34:52 <roconnor> presumably it has to do that sort of thing after decoding anyways?
09:35:08 <dcoutts> but compared to doing a write/lookup in an IOUArray Int Word32, it's quite an overhead
09:35:39 <dcoutts> roconnor, no, probably not because the result is used right away, so it never needs to allocate heap space for the result of decoding
09:35:50 <monochrom> Each lazy entry is necessarily a tagged union of at least two cases: value (perhaps even pointer to) or pointer to thunk.  When dereferencing, a conditional branch is made.  This is one slowdown.
09:36:16 <roconnor> dcoutts and the heap allocation is slow?
09:36:41 <dcoutts> roconnor, not very, but if you're allocating 500,000 things comapred to allocating 0 things then yes.
09:37:19 <dcoutts> monochrom, actually there's no tagging in ghc' impl. it just changes the pointer
09:37:28 <roconnor> so it does an alloc for each entry
09:37:39 <roconnor> where as the IOU array is one alloc
09:37:43 <dcoutts> right
09:38:05 <dmhouse> Mmm... cold shower.
09:38:05 <monochrom> If you have an array of those, you start with lots of thunks in the heap, which are much larger than the wanted data.  This puts extra pressure on the cache in two ways: first, there is more stuff; second, there is less locality.
09:38:07 <roconnor> and IOArrays are fast, so long as you don't use it all.
09:38:24 <dcoutts> and what's more, it's one contiguous alloc so if you access the array in sequence then you get good cache utilisation.
09:39:11 <monochrom> These days cache locality can explain a 100x difference.
09:39:30 <dcoutts> roconnor, IOArrays just have a bit more of an overhead. Your example shows that up.
09:39:50 <dcoutts> roconnor, there are many other cases where IOArrays are a good choice
09:40:12 <monochrom> On a 1980 cacheless computer you would see the expected 2x difference between IOArray and IOUArray!
09:40:23 <dcoutts> but if your data is simple enough for it to be possible to use an unboxed array then that's usually the better performing choice
09:42:01 <dcoutts> roconnor, for one of this years ICPF problems I used an array and relied on the fact that it uses boxed values, since I filled in undefined for many entries. That's quite a useful luxury.
09:42:23 <vincenz> dcoutts: memoisation?
09:42:29 <dcoutts> it was for looking things up in a mostly 2-d grid
09:42:35 <dcoutts> the adventure game
09:42:47 <dcoutts> it was a 4x4 grid, with 3 missing locations
09:42:52 <vincenz> ah
09:59:32 <exarkun> Hi.  What is the general approach to implementing IDL-less RPC protocols in statically typed languages like Haskell?
10:03:07 <ndm> exarkun: IDL-less?
10:03:53 <exarkun> An RPC system where you don't necessarily know the types of all arguments at compile time
10:09:11 <ndm> exarkun: data AnyType = String String | Bool Bool | ... for all the types you need to support
10:09:55 <exarkun> Oooh.  A union type, basically?
10:10:02 * exarkun starts remembering things.
10:10:17 <ndm> exarkun: an Algebraic Data Type, its the norm in Haskell
10:10:36 <ndm> data Bool = True | False
10:10:51 <ndm> data [] a = [] | (:) a ([] a)
10:10:53 <ndm> etc.
10:11:00 <exarkun> Huh, okay
10:11:29 <ndm> but yeah, a tagged union in C terms
10:12:09 <exarkun> Thanks, that makes sense.
10:12:44 <xerox> exarkun: there is an XmlRpc implementation if you are interested in such a thing (I am not sure.)
10:13:10 <vincenz> ndm: did you particpate in the end?
10:13:17 <ndm> vincenz: no
10:13:25 <exarkun> Yes, that would probably make a good example to look at.  Thanks for mentioning it.
10:13:27 <vincenz> ndm: next year you're on my team?
10:13:29 <vincenz> :)
10:13:43 <ndm> vincenz: we'll see :)
10:13:47 <ndm> but perhaps, yeah
10:14:15 <xerox> exarkun: you can find it here <http://www.haskell.org/haxr/>.
10:14:24 <ndm> i want to see the challenges
10:14:43 <ndm> i am wondering if a non-deterministic graph programming language would have been good for any?
10:15:04 <vincenz> ndm: I can give you my vm.cpp
10:15:19 <ndm> vincenz: not at the mo, but probably this weekend
10:15:28 <ndm> vincenz: don't want to get distracted :)
10:15:34 <vincenz> ah right :D
10:15:49 <ndm> anyway, have to go now
10:15:51 <ndm> bye
10:15:54 <vincenz> bbye
10:16:01 <edwardk> i threw my vm up on http://slipwave.info
10:16:23 <edwardk> its pretty minimal (ad outruns vincenz's by a factor of two on my machine) ;)
10:16:45 <edwardk> but i assume a 32 bit architecture
10:19:12 <dcoutts_> edwardk, oh your UM, yeah I noticed that cheat ;-)
10:19:16 <roconnor> what's the point of a functional programming language if I can't allocate 500 000 closures.
10:19:19 <roconnor> :P
10:19:25 <edwardk> cheat?
10:19:36 <dcoutts_> the casting pointers to 32bit ints :-)
10:20:07 <edwardk> heh
10:20:42 <edwardk> it met the specification =)
10:21:05 <dcoutts_> indeed
10:21:12 <dcoutts_> and saves an indirection
10:21:24 <dcoutts_> and saves managing an array of allocations
10:21:47 <edwardk> if i had to do a 32 bit clean version i would probably just mmap/mprotect a 4 gig region, and allocate/free from there, etc. since you can only have 4billion distinct 'arrays' anyways
10:21:55 <edwardk> and i don't have more than 4 gigs of ram =)
10:22:11 <edwardk> then it would be simple base pointer plus offset
10:22:18 <dcoutts_> though then you'd need your own allocater
10:22:20 <edwardk> but it could fragment
10:22:22 <edwardk> yeah
10:22:30 <sylvan> edwardk, hey you're harmless! I remember reading those articles ages ago...
10:22:32 <roconnor> I've been toying with making a JITC for the UM.
10:22:35 <edwardk> well, i've got one of those lying around
10:22:35 <edwardk> heh
10:22:37 <edwardk> yeah
10:22:38 <edwardk> thats me
10:22:44 <edwardk> i started transcribing them up onto my wiki
10:22:49 <dcoutts_> roconnor, yes dons and I were taking about that eariler
10:22:51 <vincenz> dcoutts_: the nice thing is that you could move data around as you see all the memory accesses so you can easily translate pointers
10:23:16 <roconnor> dcoutts_: The self modifying code make it a little tricky
10:23:31 <dcoutts_> roconnor, just re-translate when doing a load 0
10:23:46 <edwardk> thats what i was afraid of and why i didn't play with a jit. i remember it making my old apple iigs emulator a nightmare
10:23:47 <roconnor> dcoutts_: sometimes they write to array 0
10:23:59 <dcoutts_> ah, that'd be slow
10:24:36 <vincenz> edwardk: how fast is yours on sandmark?
10:24:46 <roconnor> I was considering dropping down to interpreted mode when they write to array 0
10:24:51 <dcoutts_> roconnor, right
10:25:04 <roconnor> And pray the load a new program soon
10:25:05 <edwardk> vincenz: on my web server it runs in about a minute 40 seconds, yours takes about 4 minutes. both -O3 -fomitfp'd
10:25:07 <vincenz> edwardk: holy cow, how does that zooming work???
10:25:08 <dcoutts_> vincenz, where is sandmark described?
10:25:22 <vincenz> dcoutts_: icfpcontest
10:25:24 <edwardk> vincenz: javascript. look at jquery for the basic idea =)
10:25:26 <vincenz> dcoutts_: where the original um is
10:25:33 <vincenz> edwardk: nice :)
10:25:46 <vincenz> edwardk: made my browser crash first time through tho
10:25:51 <ProfTeggy> Bye all
10:25:54 <edwardk> i'm planning on throwing my continuation based version of those things onto the site eventually. i just have 9 directions to go in right now
10:26:13 <edwardk> yeah, the site really only works in firefox right now.. you can disable the zoom effect on the right hand control panel i think
10:26:31 <edwardk> click down to options
10:26:51 <vincenz> edwardk: I just thought of another cool hack to make mine go faster
10:26:57 <vincenz> edwardk: make my code vector<value>&
10:27:16 <vincenz> oh wait..nm..that wouldn't work
10:27:18 <vincenz> :/
10:27:22 <edwardk> was going to say =)
10:27:58 <edwardk> i wa greatly amused when i saw yours coz we follow the same basic structure.
10:28:09 <vincenz> :)
10:28:51 <vincenz> edwardk: how fast is your webserver?
10:28:57 <edwardk> i need to take the stuff thats up on slipwave and dump the tiddlywiki underbelly and make it something more reliable.
10:29:10 <edwardk> not sure. i actually don't own the box. lemme see if i can figure it out real fast
10:29:20 <edwardk> and keep in mind its pretty loaded down
10:29:20 <vincenz> cause 4m seems excessive
10:29:28 <edwardk> its a rather slow box
10:29:36 <vincenz> then 40s seems excessive
10:29:40 <edwardk> heh
10:29:50 <edwardk> what do you take to run the sandmark on yours?
10:30:17 <edwardk> also note i only have gcc 3.3.3 on it
10:30:19 <vincenz> 1m5
10:30:20 <vincenz> 1m50
10:30:32 <vincenz> ah
10:30:35 <vincenz> yeah
10:30:37 <vincenz> mine takes 12m
10:30:40 <vincenz> when not -O3
10:30:54 <vincenz> cause vector is bad unless you can make it smart in not duplicating itself when not necessary (aka when resizing environment)
10:30:55 <edwardk> i used -O3 but that just took it from 16minutes to 4
10:30:58 <edwardk> yeah
10:31:39 <edwardk> model name      : Intel(R) Pentium(R) 4 CPU 1.80GHz
10:31:39 <edwardk> stepping        : 2
10:31:39 <edwardk> cpu MHz         : 1793.479
10:32:17 <vincenz> might be compiler related
10:32:39 <edwardk> feel free to download and sandmark mine to compare
10:32:45 <vincenz> doin so :)
10:33:00 <edwardk> i was using -O3 -fomit-frame-pointer
10:33:02 <vincenz> yours is faster
10:33:06 <vincenz> I did -O3
10:33:11 <vincenz> 1m16 vs 1m50 for mine
10:33:16 <vincenz> faster but not by as muchc
10:33:22 <edwardk> ah not so bad once you throw gcc4 at it then
10:33:32 <edwardk> that makes me feel a lot better actually
10:34:09 <vincenz> model name      : Intel(R) Pentium(R) M processor 1.60GHz
10:34:10 <vincenz> stepping        : 8
10:34:10 <vincenz> cpu MHz         : 1596.203
10:34:18 <edwardk> heh
10:34:31 <vincenz> so yeah
10:34:40 <vincenz> your version seems to scale comparably
10:34:42 <vincenz> it must be the gc
10:34:44 <vincenz> cgc
10:34:46 <vincenz> grr
10:34:46 <vincenz> gcc
10:34:58 * vincenz has dyslexci fingers
10:35:14 <edwardk> sylvan: so somebody actually read those articles? =)
10:36:24 <edwardk> btw- my first implementation was all vectors as i was reading the spec, then i saw how arrays were actually defined and i threw that out and swapped in this ;)
10:36:29 * vincenz ponders
10:36:38 <vincenz> is it ime or is it imposssible to jump in um?
10:36:50 <edwardk> they do it all the time.
10:37:00 <vincenz> except by copying the remaining code to an array and loading that
10:37:03 <edwardk> use load where you load from array 0
10:37:13 <edwardk> in my case i don't copy any code there
10:37:14 <vincenz> oh right
10:37:21 * vincenz forgot about the C
10:37:27 <edwardk> yeah
10:37:31 <edwardk> i forgot it entirely my first time
10:37:32 <edwardk> gotta run
10:38:32 * dmhouse yawns
10:43:32 <roconnor> Hmmm the IOArray Word32 (Machine ()) seems to be only 20x slower
10:43:46 <roconnor> I guess I'm just really impatient
10:44:22 <roconnor> sadly 20x slower is pretty bad for an optimization.
10:44:53 <edwardk> back
10:46:16 <dmhouse> Wb, edwardk. :)
10:46:34 <edwardk> heh
10:47:16 <sylvan> yep, I actually browsed through them quite recently when I was writing a software rasterizer in C# - ended up going for straight sorted spans though
10:47:53 * edwardk nods.
10:48:25 <edwardk> I basically slapped them together to document the stuff I had done about 3 years prior to the first article, so they were pretty dated by the time I got around to writing them ;)
10:48:39 <roconnor> ugh, who would have thought looking up a closure would be slower than just calling a function with the same parameters.
10:49:22 <edwardk> I did a bunch of Plucker visibility stuff later, now I'd probably never use any of those algorithms. sad eh? =)
10:50:09 <sylvan> yeah, damn hardware
10:50:13 <edwardk> hh
10:50:17 <edwardk> actually i like hardware
10:50:28 <edwardk> it makes like a lot easier. you just have to change with it
10:50:49 <sylvan> yeah me too, but I run into quite a few cases where I do something cool on the CPU only to find out when benchmarking that it's faster to just stop being clever and let the GPU be dumb
10:50:58 <edwardk> i only have two or three toy algorithms from that era that hardware directly improved though
10:50:59 <sylvan> which is annoying
10:51:37 <edwardk> the beamtree stuff became a lot more useful, the volumetric isometric renderer i wrote can now build textures with depth info, and a couple of lighting algorithms don't have their old defects.
10:51:47 <edwardk> everything else went to the wayside =)
10:52:22 <edwardk> oh, and the machines have sped up so i can do visibility calculations in Pluckerspace now rather than in 3-space.
10:52:37 <edwardk> but the visibility skeleton is impossible to explain to someone without a math background
10:52:44 <vincenz> pluckerspace?
10:52:45 <edwardk> so its hard to build a team around a project using it =)
10:53:07 <edwardk> http://slipwave.info/~harmless/thesis.pdf is an old draft of my thesis
10:53:13 <edwardk> (er my first one)
10:53:29 <roconnor> edwardk: have you heard of geometric algebra?
10:53:33 <edwardk> covers that and an alternative basis for it from about 130 years ago that when adapted to oriented projective geometry is useful for 3d
10:54:06 <edwardk> yeah played with it quite a bit. you can find a lot of analogies between the plucker quadric and bivectors with a certain meet and join.
10:54:42 <roconnor> edwardk: I've been meaning to write a raytracer using Clifford Algebras.
10:55:05 <roconnor> Actually, I was planning to teach a CG course using geometric algebra.
10:55:12 <roconnor> sadly it didn't pan out
10:55:13 <edwardk> i used it when i was trying to work out visibility in a piecewise quadratic space of implicit surfaces
10:55:30 <edwardk> so you could have smooth curves for all of your geometry, etc.
10:55:46 <edwardk> but the math isn't quiiite up to dragging that into realtime without hackery so i stopped.
10:56:00 <roconnor> quadratic surfaces?
10:56:10 <roconnor> so this is the fancy doubly homogenous stuff I read about?
10:56:25 <edwardk> well, visibility in a system with implicit surfaces is kind of a net goal.
10:56:52 <roconnor> :)
10:57:05 <edwardk> ad you can approximate an implicit surface with a piecewise quadratic one (where each tetrahedron contains a patch and sidedness constraints)
10:57:32 <roconnor> ... my life lesson from today: 1 closure is nice, 500 000 closures suck.
10:57:35 <edwardk> so if you can perform visibility checks agaainst the faces of th tetrahedron and the side of the quadratic curve you're all set.
10:58:04 <edwardk> but once you drag in all the convex polytope theory you need to do it, you find that you get degenerate faces that are poonems, not faces, etc.
10:58:20 <edwardk> and it all goes to crap, unless you are willing to approximate a solution
10:58:38 <edwardk> i spent about a month on it earlier this summer
10:59:08 <edwardk> learned a lot of polytope theory, etc though, so i guess it was worth it
10:59:12 <roconnor> :)
10:59:32 <edwardk> after that i decided i wanted to do something else and started slapping together javascript engines.
10:59:47 <edwardk> now i'm drifting towards pure type systems and substructural logics because i still need a second thesis.
11:00:34 <edwardk> of course nowhere in that do i get to apply any of the geometry stuff, but hey
11:01:20 <Philippa> presumably the trick is in seeing what extra properties you can prove, as if you've broken any existing (useful) ones something's really wrong?
11:01:23 <edwardk> anyways vincenz: that paper describes everything you'd need to know about plucker-space. its basically a 5 dimensional projective space in which all points on a particular quadratic surface describe lines in 3 dimensional projective space.
11:01:50 <edwardk> phillipa: mostly interested in cleaning up the mess that is the substructural papers i've read. =)
11:01:53 <Philippa> I was trying to remember where I'd seen "harmless" before - I should probably wander back into #flipcode sometime, too
11:03:18 <edwardk> vincenz: it has some nice properties. notably you can project lines to become hyperplanes in that space. so if you are looking for whether or not there exists a line that satisfies a number of contraints. you are looking for whether or not the quadric intersects the convex polygonal cone that results from the projection.
11:03:25 <Lemmih> greenrd: ping.
11:04:16 <edwardk> that can nicely be shown to only happen if the quadric intersects one of the 1-faces (er lines that make up the side of the cone), and then you can compute the set of one faces in quadratic time to the number of constraints.
11:04:17 <vincenz> edwardk: wrong person
11:04:34 <edwardk> vincenz: heh, was answering 'pluckerspace?' =)
11:04:45 <vincenz> :)
11:04:48 <edwardk> somewhat belatedly
11:04:59 <vincenz> yeah but I quicly backced out
11:05:01 <vincenz> tooo much math
11:05:06 <edwardk> heh
11:05:07 <sylvan> That's impossible!
11:05:08 <vincenz> :P
11:05:21 <edwardk> the paper up there starts with just assuming you know linear algebra
11:05:27 <edwardk> then i build up what geometry is over that
11:05:37 <vincenz> yeah but I'm not in a mental state atm to undergo that
11:05:38 <edwardk> its a little backwards but i find it to be a more intuitive exposition for most people.
11:05:38 <sylvan> "Not enough math" I've heard of, but the other one doesn't seem to make sense :-)
11:05:49 <vincenz> malnourishment and sleepdepr over the last 3 days
11:07:05 <edwardk> i need to get a final copy of my thesis back from the university so i can post that one up online, it has the last chapter corrected.
11:07:07 <edwardk> =/
11:07:44 <mnislaih_> Lemmih: have you had time to work on breakpoints?
11:08:01 <edwardk> (the laptop my draft was on was stolen)
11:08:41 <sylvan> I remember reading about plucker space way back, but that was before university so I think I didn't have the math basics down cold yet, because I can't for the life of me remember any of it. Maybe I should go back and look at that now when I'm wiser...
11:08:50 <edwardk> heh
11:08:51 <edwardk> yeah
11:09:03 <vincenz> @seen adept
11:09:03 <lambdabot> I saw adept leaving #oasis 3 hours, 35 minutes and 37 seconds ago, and .
11:09:10 <edwardk> i basically started back up in school. got to my masters program, cracked my fingers and dove back into the literature
11:09:15 <edwardk> its not so bad in retrospect
11:09:34 <edwardk> though to make sense of it, i would recommend trying to find an old copy of coxeter's 1950 'noneuclidean geometry'
11:09:48 <Lemmih> mnislaih_: Nope, but I will. It's on my TODO list right under getting things ready for my interview at MSR.
11:09:55 <sylvan> sounds like far too much work :-)
11:10:02 <edwardk> its about the only way i think anyone could wade through it without a formal introduction to the subject
11:10:17 <Lemmih> mnislaih_: I gotta fix it before 6.6 comes out.
11:10:27 <mnislaih_> Lemmih: let me know if I can help you
11:10:51 <edwardk> the nice part about coxeter is that his notation parallels that of the modern oriented projective geometry follks in a lot of ways (sometimes by accident)
11:10:56 <edwardk> so it works well as a primer =)
11:11:05 <sylvan> Besides, I'm busy re-learning C++...  Have hardly touched it since I started University 4 years ago and now I'm starting at a company using C/C++ exclusively... :-)
11:11:21 <edwardk> another place to start would be the papers by Jorge Stolfi
11:11:43 <edwardk> he uses a different formalism for oriented projective geometry than I do, but the systems are largely interchangeable
11:12:06 <edwardk> and mine is simplified for expository purposes, and lacks some of the hypersphere connectives as a result.
11:13:11 <edwardk> i have c/c++ etched into my mind, so deeply I fear I may never recover.
11:13:18 <edwardk> Its a bit of a curse when playing in haskell =)
11:13:56 <SamB> has anyone here implemented O'Cult in Haskell yet?
11:14:00 <sylvan> :-) I had trouble learning Haskell for that very reason, but once I "got it" I've avoided C++ for all my pet projects, and only used C/C++ in 3-4 courses
11:14:22 <edwardk> sam: thought about it, but that damn least heeded rule is obnoxious =)
11:14:39 <sylvan> So now I'm suffering to re-learn C++, hating much of it.. Though i suppose once I get stuck in with a project I'll enjoy the extra challenges posed by the language as much as the challenges posed by the problem
11:15:01 <monochrom> har
11:15:11 <SamB> I have only just got around to copy/pasting the whole README into a real file
11:15:19 <edwardk> that is something i don't tend to have happen for me
11:15:33 <edwardk> if i get stuck with a crappy language, i rarely enjoy the constraints it imposes ;)
11:15:36 <edwardk> heh
11:15:40 <edwardk> well, qvickbasic was fun
11:15:55 <edwardk> in a perverse sort of way
11:15:56 <SamB> I didn't like qvickbasic much
11:16:00 <sylvan> but it's satisfying to get something that looks clean and works without memory leaks etc. if it is indeed a feat to do so :-)
11:16:06 <roconnor> O'Cult is a terrible terrible language.
11:16:26 <sylvan> though I prefer to spend my problem-solving on the actual problem if possible (hence using other languages than C++ as much as possible)
11:16:27 <edwardk> i never checked any operator or function that wasn't used. was there a CHR() function and did < work?
11:16:28 <SamB> line numbers are a pain, moreso if not in a proper radix-based number system
11:17:14 * edwardk wrote a 5 line perl program to replace his line numbers with roman numerals and generated his code that way =)
11:17:22 <mikael> hey sylvan
11:17:30 <mikael> your friend wanted that apartment, eh? :-)
11:17:34 <edwardk> amazing what s///eg can do for you
11:17:43 <SamB> is umodem a real program, btw?
11:17:50 <SamB> or is it made up for the contest?
11:17:56 <sylvan> It's interesting to read books like "exceptional c++"etc.. IMO it implies something deeply wrong with the language if you can publish whole books (with sequels) containing programming puzzles (where the language is the puzzle)
11:18:06 <sylvan> mikael: Yep
11:18:13 <sylvan> sorry!
11:18:14 <edwardk> its pretty much based on xmodem/zmodem/ymodem and kermit as a joke
11:18:24 <SamB> yeah, I wasn't sure
11:19:15 * SamB wonders if anyone did anything in qvickbasic besides fixing hack.bas
11:19:55 <edwardk> heh well, i generated a larger scale hacking tool that i let run over the users for a little bit that ran in the background
11:20:13 <edwardk> but it basically just piped into my vm and loaded little snippets and ran them
11:21:07 <SamB> hmm, so how many passwords can you find with a fixed hack.bas?
11:21:21 <edwardk> i think just ftd's
11:21:26 <edwardk> lemme go look
11:21:42 <edwardk> yeah just ftd
11:21:54 <SamB> well, it would also find the ones that you'd find if you just take off the last line...
11:21:55 <edwardk> unless one of the account names you get later can be hacked
11:22:02 <edwardk> yeah
11:22:21 <edwardk> so howie guest ohmega
11:22:30 <edwardk> and getting ftd gets you hmonk
11:22:31 <SamB> guest hardly counts
11:22:34 <edwardk> heh
11:22:39 <edwardk> well it finds a password for him =)
11:22:43 <SamB> I am thinking that *any* password would match for guest
11:22:44 <edwardk> if you run it it says 'airplane' =)
11:22:50 <SamB> since the first password tried did...
11:22:53 <edwardk> yeah
11:22:55 <edwardk> good point
11:24:32 <SamB> hmm, yeah, O'Cult *is* awful...
11:24:49 <edwardk> heh
11:25:00 <edwardk> if it didn't have that rule perverse rule it would be fine
11:25:05 <SamB> well...
11:25:16 <edwardk> i haven't found a good  way to do it other than to march 'compute' around as a cursor =/
11:25:33 <SamB> oh, moving that around is effective?
11:25:49 <edwardk> worked for me, gave me only one place i COULD apply a rule at any time
11:26:09 <edwardk> but its still ugly and not likely to give a good 'score' if the score is based on how small the rules are
11:26:44 <Failure02> is o'cult something real or do you mean o'caml?
11:26:55 <edwardk> o'cult is from icfp this year
11:26:56 <SamB> Failure02: it is a real fictional programming language
11:27:03 <SamB> that actually works
11:27:13 <edwardk> it works, you can write code in it and have to for part of the contest.
11:27:16 <Failure02> ah
11:27:55 <SamB> basically you are running around in this computer trying to hack into as many accounts as you can and solve any programming problems you run into
11:28:32 <edwardk> ...reminds me of my first semester of college... =)
11:30:07 <roconnor> >last [0..]::Word8
11:30:13 <roconnor> > last [0..]::Word8
11:30:19 <lambdabot>  255
11:30:20 <jgrimes_> for an interpreter would it be best to return a new environment after evaluating a complete statement or to use (ST|IO)Ref and have state taken care of that way?
11:30:51 <roconnor> jgrimes_: excellet question
11:31:05 <edwardk> jgrimes: depends, environments tend to be slow to update
11:31:05 <roconnor> I'm sort of testing that right now
11:31:19 <edwardk> jgrimes: i've been using STM and IO monads for the most part
11:31:42 <edwardk> interpreting with STM is pretty neat imho =)
11:32:02 <roconnor> ?
11:32:04 <sylvan> It's probably nice to have some sort of monadic interface anyway to hide the plumbing, even if it's just a State monad
11:32:41 <edwardk> roconnor: ? to me?
11:32:58 <jgrimes_> I haven't looked at STM at all
11:33:16 <edwardk> roconnor: lets me have an interpreter that can run on multiple machines and where none of them ever notice any side effects from any of the others except at dedicated 'safe points'
11:33:37 <jgrimes_> that sounds pretty neat
11:33:41 <roconnor> edwardk: for check pointing.
11:33:44 <edwardk> yeah
11:33:58 <edwardk> playing with it for the new javascript thingy i'm doing
11:34:03 <roconnor> how do you fork the state?
11:34:09 <roconnor> you write a copy state function?
11:34:13 <dmhouse> Why would you need a threaded interpreter?
11:34:26 <edwardk> i have a native object type that splits off a new 'Thread'
11:34:44 <sylvan> is O'Cult pure?
11:34:47 <edwardk> dmhouse: well, in the end mine is getting compiled. and i need it for the same reason i have to emulate threads in the browser.
11:34:52 <edwardk> sylvan: yeah
11:35:02 <SamB> sylvan: o'cult is just rewriting rules
11:35:06 <sylvan> Then you could have an interpreter with implicit parallellism =)
11:35:14 <sjanssen> anybody have pointers to literature on views as a Haskell extension?
11:35:35 <dmhouse> sjanssen: citeseer?
11:35:40 <edwardk> sjannsen: i have some in a pile of papers around here somewhere if i trip over them i'll let you know
11:35:57 <sylvan> @google views haskell
11:36:00 <lambdabot> http://hackage.haskell.org/trac/haskell-prime/wiki/Views
11:36:01 <lambdabot> Title: Views - Haskell Prime - Trac
11:36:16 <edwardk> weren't views _removed_ from the language spec? =)
11:36:19 <sylvan> links to a bunch of stuff
11:36:44 <SamB> I like the password on hmonk's account
11:36:52 <edwardk> heh
11:36:52 <edwardk> yeah
11:37:01 <edwardk> did you ever read the paper on that topic?
11:37:02 <sjanssen> edwardk: they were proposed but didn't make the cut
11:37:13 <edwardk> er on the topic of hmonk's password, not views
11:37:15 <edwardk> =)
11:37:28 <emertens> @pl (\a f -> f (a f))
11:37:28 <lambdabot> ap id
11:37:33 <SamB> no, but INTERCAL has a COMEFROM or COME FROM construct
11:38:13 <sjanssen> so far I've seen a proposal by Wadler, a proposal for SML by Okasaki, and Okasaki's design is mentioned in a paper by Hinze
11:38:35 <SamB> UMIX seems leaky
11:38:42 <sjanssen> Simon PJ mentioned "a number of alternative designs", wondering if there are more
11:38:49 <sylvan> I think Scala has (or had) views
11:39:03 <SamB> you think they might have got rid of them?
11:39:14 <dmhouse> Transformational patterns are meant to be favourable to views.
11:39:22 <edwardk> intercal adds it just to be perverse
11:39:34 <SamB> edwardk: I know ;-)
11:39:36 <edwardk> in the context of an if guarded come from, its actually somewhat useful as an idea =)
11:39:43 <dmhouse> At least, that's what Philippa said. :)
11:39:50 <edwardk> at leaasat in the horrible warrens of basic syntax.
11:39:55 <edwardk> er least
11:40:14 <sylvan> I always liked views, it would be interesting to see the arguments against them... Maybe it's just a "language complexity" issue and the fact that you could probably get much of the same by calling a function returning a pattern-matchable construct (like viewl and viewr in some of the collections)
11:40:56 <roconnor> jgrimes_: my initial test results are in...
11:41:02 <sylvan> SamB I remember either views getting removed or something else getting removed in favour of views :-)
11:41:15 <shapr> sylvan: Did you find that paper?
11:41:29 <greenrd> Lemmih: pong
11:41:30 <lambdabot> greenrd: You have 1 new message. '/msg lambdabot @messages' to read it.
11:41:34 <sjanssen> views seem very nice in the context of String and ByteString
11:41:43 <roconnor> using IORefs seems a litlle better than state record with strict fields
11:41:52 <sylvan> nope :-) I looked briefly at the LTU post but was busy with a bunch of stuff so I forgot :-)
11:41:58 <roconnor> more testing is need
11:42:05 <jgrimes_> roconnor: interesting
11:42:06 <sjanssen> the only annoying part of using ByteString's is losing the handy pattern matching
11:42:32 <sylvan> sjanssen: Indeed. Pattern matching is really neat, but I find that the more pragmatic you get (i.e. use fairly opaque libraries) the less you get to use them.. Views could help
11:42:33 <jgrimes_> roconnor: I was considering just using IORefs since I am eventually going to have to do IO with interpreter anyway
11:43:36 <jgrimes_> roconnor: and it'd be nice to already have things in the IO monad
11:43:45 <sylvan> jgrimes_: I don't know much about how that interpreter works, but I wrote an interpreter ones that just worked with lazy lists in a state monad. It's somewhat limited though, but if you just want some output it works
11:44:04 <shapr> I'm beginning to understand how GHC does linking, yay!
11:44:08 <sylvan> (I assume you're talking about ICFP, and I know nothing about it)
11:44:56 <emertens> @instances (->)
11:44:57 <lambdabot> Not a class! Perhaps you need to import the  module that defines it? Try @help instances-importing.
11:45:02 <shapr> Can the tags file also tell me where a function is called?
11:45:02 <jgrimes_> sylvan: no, I am working through "essentials of programming languages" and it instructs by having you write interpreters
11:45:15 * edwardk changed the /etc/issue at work to reflect the UMIX login. one person got the joke
11:46:16 <greenrd> Lemmih: I replied in the bug report
11:46:24 <sylvan> jgrimes_: Ah.. Anyway, an easy way is to just work with lazy lists, but it's somewhat liming. However if you have a monad which hides the IO (and symbol tables etc.) you can easily change it out for something else...
11:46:24 <Lemmih> greenrd: Great.
11:46:39 <sylvan> liming = limiting
11:46:54 <shapr> Lemmih: I'm trying to figure out how GHC decides what to link for a file when HscNoRecomp is in effect.
11:46:58 <edwardk> jgrimes: probably wrap the io monad into your evaluation monad, then use that and lift to get IO when you need it
11:47:22 <jgrimes_> edwardk: yeah, I think thats probably along the lines of what I'm going to end up doing
11:47:30 <sylvan> right, that's what I ended up doing when I bumped up against the lazy-list approach
11:47:42 <sylvan> (like interleaving input/output etc.)
11:48:00 <edwardk> jgrimes: it seems to be a popular approach. pugs uses more or less that as well.
11:48:12 <shapr> I'm pretty sure I found at least one culprit for #706, Finder.findObjectLinkable automatically appends $MODULE_stub.o to the list of Linkables without checking if that module even uses ForeignStubs.
11:48:39 <edwardk> well, then make it check =)
11:48:57 <shapr> How exactly?
11:48:58 <edwardk> that was that if you copy A_stub to B_stub thing and then link it gives you duplicate symbols bug right?
11:49:01 <edwardk> no idea =)
11:49:03 <shapr> Yup, that's it.
11:49:58 <edwardk> can you interrogate the interface for the module somehow?
11:50:57 <shapr> I added a mi_foreign :: Bool to the ModIface record, so now I can...
11:51:44 <shapr> Just trying to figure out exactly where I should interrogate the ModIface (or HomeModInfo) value.
11:52:13 <edwardk> maybe in Finder.findObjectLinkable?
11:52:27 <shapr> Lemmih: line 232 of HscTypes says "When re-linking a module (hscNoRecomp), we construct the HomeModInfo by building a new ModDetails from the old ModIface (only)." Do you know where that happens?
11:53:03 <shapr> edwardk: The iface values aren't available there, so I'm tracing up the call tree to see where the info is available.
11:53:13 * edwardk poked around in the ghc internals the other day, put up a sign saying 'here be demons' and walked away for now =)
11:53:36 <shapr> GHC isn't scary, imho. It's just that you need to know what all the types do.
11:53:43 <edwardk> i wanted to see how hard it would be to add back in monad comprehensions
11:54:07 <shapr> If I could only remember exactly what info is in HscEnv, etc.
11:54:08 <edwardk> coz they were one of the language features i'd read about before using the language in practice and i was bumed to see them gone.
11:54:16 <Lemmih> shapr: Hm, no.
11:55:55 <shapr> HscEnv has a HomePackageTable among other things, maybe the iface info is available there?
11:56:27 <shapr> ah yes!
11:57:36 <saccade> is there a type class for periodic structures that has eq and successor but not ord?
11:57:58 <shapr> I think succ is part of ord.
11:58:16 <shapr> But you could check the alternative Num hierarchy in the Numeric Haskell libs.
11:58:27 <saccade> hm, ok
11:58:44 <sjanssen> succ is part of Enum
11:58:50 <shapr> oops
12:00:19 <shapr> M-. and M-* in emacs really makes my life easier.
12:00:43 * edwardk rather likes the BAL proposal from the russian guy who built docon, but i think its got the standard problem with such things. If you haven't had a course or two in abstract algebra you don't see its value. =(
12:01:31 <edwardk> the num hierarchy in the prelude makes me wince.
12:02:18 <sjanssen> it's practical
12:02:38 <edwardk> Succ is in enum, not ord.
12:02:43 <edwardk> oh
12:02:43 <edwardk> heh
12:02:48 <edwardk> didn't see your answer above =)
12:03:14 <dmhouse> sjanssen: No, it's not.
12:03:17 <shapr> Lemmih: I've found linking code in DriverPipeline.hs and in Linker.lhs, is there anywhere else I should look?
12:03:32 <sjanssen> dmhouse: please elaborate
12:03:34 <dmhouse> Every time I've used a fromIntegral, that's an imperfection of the numeric class hierarchy.
12:03:45 <dmhouse> Specifically, having to use fromIntegral with (/) is annoying.
12:04:36 <sjanssen> so you want silent conversion to some sort of floating point number?
12:05:03 <edwardk> that i don't want
12:05:17 <dmhouse> No, I want to be able to divide two integrals and get a floating point number.
12:05:23 <edwardk> i just want to be able to make a function that works on a Ring or Field.
12:05:24 <edwardk> =)
12:05:44 <dmhouse> > (length [1..3]) / (length [1..9]) -- for example
12:05:45 <lambdabot>  add an instance declaration for (Fractional Int)
12:05:46 <lambdabot>   In the definition of `...
12:05:54 * edwardk finds those to be a lot more natural to talk about.
12:06:02 <SamB> dmhouse: how do you know your integrals fit in the floating point representation
12:06:19 <dmhouse> SamB: ?
12:06:20 <SamB> also, have you any idea how annoying it would be if / was polymorphic in its result type?
12:06:29 <dmhouse> It doesn't have to be :)
12:06:38 <sjanssen> wouldn't it?
12:06:49 <dmhouse> No! I don't care if it returns floats. That's fine.
12:06:59 <SamB> we can't hardcode it
12:07:03 <sjanssen> right, but should it return Float or Double?
12:07:04 <edwardk> it would have to be in case you cared about better precision and wanted to use a multiprecision real library or something
12:07:06 <SamB> that woudl be just wrong!
12:07:12 <sjanssen> or maybe even a Ratio
12:07:19 <edwardk> yeah
12:07:19 <dmhouse> sjanssen: I don't care, that's totally orthagonal to my problem.
12:07:30 <SamB> dmhouse: you don't own /
12:07:46 <shapr> Lemmih: I haven't found any description of GHC's linking in the Commentary, anywhere else I can look for a high level overview?
12:07:53 <dmhouse> SamB: err... what?
12:07:55 * edwardk votes that the library shouldn't even define /. there then everyone can be happy =)
12:08:15 <dmhouse> Okay. Here's my argument:
12:08:20 <edwardk> no numbers, no /. you want em, you write em =)
12:08:24 <dmhouse> 1) Things like my example involving lengths above should work.
12:08:56 <dmhouse> 2) I shouldn't have to use fromIntegral to hop around the class hierarchy. It should be somehow automatically coerced.
12:09:11 <edwardk> i would tend to agree that in general the division of two integers should return a rational though unless explicitly chosen otherwise, but i don't think there is a good way to express that
12:09:13 <dmhouse> 3) Obviously we can't instantiate Fractional Int (recipricals, anyone?)
12:09:35 <dmhouse> 4) Therefore, the class hierarchy isn't practical.
12:09:44 <Lemmih> shapr: I'm not sure there exist a high level description. /-:
12:09:44 <ChilliX> shapr: Hi!  You hacking GHC?
12:09:53 <sjanssen> I think point 2 is rather controversial.  At least I disagree with it
12:10:09 <ChilliX> Lemmih: Do you want to say the Haskell source is not a high-level description?  ;)
12:10:15 <dmhouse> Note that nowhere did I mention the type of what (/) _returns_. Whether 3/2 = 1.5 or 3%2, I don't care.
12:10:39 <dmhouse> sjanssen: If I used a less evocative word in place of 'coerced', so you didn't start thinking about unsafeCoerce
12:10:47 <dmhouse> # and type hackery, would you agree?
12:11:29 <dmhouse> E.g., I can do (length [1..6]) + 5, because (+) is sufficiently polymorphic to allow me to add integrals.
12:11:30 <shapr> ChilliX: Yes!
12:11:46 <shapr> ChilliX: I'm trying to fix bug #706 - http://hackage.haskell.org/trac/ghc/ticket/706
12:11:47 <lambdabot> Title: #706 (GHC links _stub.o files regardless of whether any 'foreign import' decls r ...
12:11:48 <sjanssen> dmhouse: it isn't the language that bothers me, it's the idea
12:12:07 <ChilliX> dmhouse: I agree w/ sjanssen.
12:12:20 <ChilliX> shapr: ic
12:12:26 <dmhouse> sjanssen: how does this differ from the (+) case, then?
12:13:05 <shapr> ChilliX: Finder.findObjectLinkable seems to be the culprit. Not sure if that's the only broken code though.
12:13:18 <ChilliX> dmhouse: Numeric argument promotion is not semantics preserving.  That's the problem.
12:13:27 <sylvan> at the very least the Num hierarchy could be more flexible so that dmhouse could just import a module which has "instance Div d n r | d n -> r where"
12:13:51 <dmhouse> ChilliX: what do you mean by 'Numeric argument promotion'?
12:14:10 <ChilliX> Converting int to float for example.
12:14:19 <ChilliX> 2 and 2.0 are not the same.
12:14:27 <dmhouse> Right. Which semantics doesn't it preserve?
12:15:39 <shapr> Does hasktags include information on where a function is referenced?
12:15:48 <edwardk> dmhouse: floats are kind of a collossal hack mathematically speaking =)
12:15:49 <ChilliX> > maxBound::Int
12:15:50 <lambdabot>  2147483647
12:15:58 <ChilliX> fromIntegral (maxBound::Int) :: Float
12:16:00 <sylvan> But if a user wants it to be in *his* application, I don't see why the Num hierarchy should insist on not allowing you to add that instance (instance Div Int Int Double where). It would require MPTC and fundeps though, but I think it should have that just so that anyone who wants to be able to scale a vector by a scalar (for example) should be allowed to do so
12:16:01 <ChilliX> > fromIntegral (maxBound::Int) :: Float
12:16:03 <lambdabot>  2.1474837e9
12:16:07 <ChilliX> That!
12:16:44 <shapr> iirc, fromIntegral has caused serious bugs in SyntaxNinja's commercial code.
12:17:09 <ChilliX> Well, fromIntegral has destroyed a mars lander or something, wasn't it?
12:17:11 <dmhouse> ChilliX: That doesn't seem like a particularly important semantics, but okay, I see the general point.
12:17:49 <sylvan> ChilliX: Right, so you argue that "invisible" fromIntegral's are bad, and in most cases i agree, but what if there are no instances in the Prelude which does this, but they're defined in some other module that you have to explicitly import to allow that type of stuff?
12:18:00 <sylvan> Like a Div class with three parameters
12:18:07 <sylvan> (and Mul, and Add, etc.)
12:18:43 <Igloo> sylvan: Nothing stops you from writing such a module and putting it in a sylvanmaths package
12:18:56 <shapr> Maybe the Numeric Prelude does this sort of thing already?
12:18:57 <ChilliX> ah, no, the mars lander got caught by priority inversion
12:18:58 <dmhouse> I just think that there's no reason why Int -> Int -> Whatever shouldn't be an instance of (/)'s type.
12:19:12 <ChilliX> It was Ariane 5 that exploded due to wrong float->int conversion
12:19:16 <dmhouse> @type (/)
12:19:17 <sylvan> Igloo, well if Num hogs all the good symbols in inflexible classes it's a problem :-)
12:19:18 <lambdabot> forall a. (Fractional a) => a -> a -> a
12:19:36 <Igloo> sylvan: You can import the prelude hiding them and then import them frmo your module
12:20:08 <ChilliX> dmhouse: So, the short answer is, because we want space rockets programmed with Haskell to be safe :)
12:20:16 <dmhouse> ;)
12:20:28 <sjanssen> perhaps fromIntegral just needs a shorter name?
12:20:36 <sylvan> Sure, but the question is why isn't the standard numeric hierarchy flexible enough to just let you add those instances without requiring the user to hide the default?
12:20:39 <dmhouse> My high-level point is that you should be able to divide Ints.
12:20:40 <ChilliX> It's a bit verbose, I admit that!
12:20:50 <ChilliX> div?
12:21:10 <dmhouse> If you don't want the rounding semantics, though...
12:21:43 <shapr> ChilliX: Is the ModIface available in one-shot mode? Do you know where I can find one-shot mode in the source?
12:21:47 <ChilliX> rounding?  What's wront about
12:21:51 <ChilliX> @type div
12:21:51 <ChilliX> ?
12:21:52 <lambdabot> forall a. (Integral a) => a -> a -> a
12:22:11 <sylvan> So I'd want the Haskell-prime num hierarchy to use MPTC etc. to allow you to easily have Vector * Scalar = Vector etc.
12:22:19 <dmhouse> ChilliX: say I want 3/2 to be 1.5 instead of 1 (or 2, can't remember which way div goes).
12:22:31 <ChilliX> shapr: Sorry, but I am not very familiar with that part of GHC.
12:22:32 <Igloo> sylvan: Well for one things Haskell98 doesn't have MPTCs
12:22:36 <shapr> ChilliX: Ok, thanks.
12:22:48 <dmhouse> (I don't see why dividing two Ints and getting something that isn't an Int is a philosophical issue.)
12:23:00 <Igloo> You'd also get less inference from such a class (I'm not sure if that matters) and potentially worse error messages. Usability for newbies is important too
12:23:58 <ChilliX> dmhouse: How about defining:
12:24:01 <ChilliX> divToFloat x y = fromIntegral x / fromIntegral y
12:24:04 <sylvan> Igloo, right. I realise the reasons for it. But if we're talking in the ideal world where we can do that sort of stuff. Is it the way it is due to restrictions in H98 or because people in general think it's a good thing to have a very restrictive class the numerics...
12:24:15 <ChilliX> Well use an infix op if you like
12:24:20 <dmhouse> ChilliX: that may indeed be the best solution.
12:24:43 <ChilliX> (Now you may say that should be in the Prelude, and yes, it may be useful to have stuff like that in a lib.)
12:26:12 <ChilliX> shapr: Which ModIFace are you talking about, btw?
12:26:26 <sylvan> Maybe the class alias proposal would solve this. People want their restrictive class can use that, and if you want flexible math operators (for linear algebra for instance) you'd import a class alias which breaks up Num...
12:26:43 <shapr> Wow cool, the GHC sources have a hidden message written in Klingon!
12:26:51 <sylvan> haha
12:26:56 <sjanssen> shapr: really?
12:27:03 <sylvan> shapr: Are you looking at the perl code?
12:27:04 <shapr> sjanssen: Yes seriously. But I won't tell you where =)
12:27:07 <sylvan> :-=
12:27:09 <sjanssen> blast
12:27:27 <dmhouse> @karma+ shapr -- for finding it
12:27:28 <lambdabot> shapr's karma raised to 21.
12:27:36 <dmhouse> @karma- shapr -- for not telling us where it is
12:27:36 <lambdabot> shapr's karma lowered to 20.
12:27:37 <shapr> ChilliX: ModIface is the ADT for a .hi file.
12:27:40 <shapr> dmhouse: haha
12:27:49 <sjanssen> shapr: perhaps that will be a question in your MSR interview?
12:27:58 <shapr> sjanssen: Doubt it, but it's possible.
12:28:05 <ChilliX> shapr: Yes, I know, but which IFace do you want to get at?
12:28:11 <dmhouse> You could at least mention it. :)
12:28:14 <dmhouse> Put it on your CV.
12:28:22 * shapr grins
12:28:34 <ChilliX> dmhouse: lol
12:28:43 <vincenz> what's the operator for bitnot?
12:29:14 <sjanssen> @hoogle complement
12:29:15 <lambdabot> Data.Bits.complement :: Bits a => a -> a
12:29:15 <lambdabot> Data.Bits.complementBit :: Bits a => a -> Int -> a
12:29:18 <shapr> ChilliX: I added a new field ModIface.mi_foreign :: Bool. Now I'm trying to figure out how linking is done is HscNoRecomp. GHC is automatically picking up the _stub.o files somewhere there.
12:29:25 <xerox> shapr: your M-. gets you to the right functions and data definitions?
12:29:33 <shapr> xerox: Sure
12:29:50 <shapr> xerox: I used dons' tag builder script and changed htags to hasktags.
12:30:10 <xerox> shapr: ctags and hasktags guess wrongly `foo' if there are occurences like `fooBar' :-(
12:30:29 <xerox> shapr: may you put the tools somewhere online? It really makes life easier if it works properly.
12:30:44 <shapr> tools?
12:31:06 <xerox> Hmmm.
12:31:13 <xerox> How do you do tags? :-)
12:31:21 <shapr> xerox: http://www.cse.unsw.edu.au/~dons/tmp/tag-fptools
12:31:36 <xerox> Danke!
12:31:57 <greenrd> shapr: liyang writes on the AngloHaskell page: [I'm coming] (provided there's some sort of concrete plan...)
12:32:09 <greenrd> shapr: maybe we oughtta think up some sort of concrete plan...
12:32:39 <shapr> greenrd: Sounds good to me.
12:32:55 <xerox> Oh, I think it's time to book tickets for the train for some of us, is the date 100% sure?
12:33:44 <shapr> Yup, 100%
12:33:52 <shapr> I'll be there until Sunday.
12:33:57 <greenrd> cool
12:34:39 <Lemmih> greenrd: Join #anglohaskell?
12:37:41 <liyang> plan!
12:38:11 <cinema> @seen dons
12:38:11 <lambdabot> dons is in #haskell-overflow and #haskell. I last heard dons speak 5 hours, 24 minutes and 26 seconds ago.
12:38:11 <ChilliX> shapr: I guess, you looked at staticLink.
12:40:29 <shapr> ChilliX: btw, thanks for coming up with the #haskell motto :-)
12:41:47 * shapr reads staticLink
12:42:27 <shapr> One-shot mode doesn't read the .hi file, so it has to pick up any stubs it finds... could that be the entirety of the bug?
12:42:52 <shapr> The bug says "rename A_stub.o to B_stub.o and relink" would that invoke one-shot mode?
12:43:09 <SamB> I really don't get this O'Cult thing...
12:43:36 <shapr> Pun on object and occult?
12:43:49 <ChilliX> on O'Caml, I'd say
12:43:59 <SamB> no, I meant how to write code that works
12:44:11 <dmhouse> Hah, 'occult', I can't believe I missed that :)
12:46:30 <ChilliX> shapr: Did I come up with it?
12:46:44 <ChilliX> shapr: re the bug, sounds plausible
12:47:13 <shapr> ChilliX: Yeah, "We put the funk in funktion"
12:48:08 <shapr> I'll email JaffaCake and ask him.
12:50:37 <ChilliX> shapr: It seems to me that the list of the stub file is computed by Main.main and put into v_Ld_inputs, where staticLink picks them up
12:51:03 <ChilliX> (BTW, I guess, I know where the Klingon comes from...)
12:51:11 <shapr> Did you write it?
12:51:17 <ChilliX> no, I didn't
12:51:22 <shapr> Ok, just curious.
12:51:45 * shapr looks at Main.main
12:51:58 <dmhouse> You know what? More languages need typeclasses.
12:52:03 <shapr> Heck yeah!
12:52:10 <shapr> dmhouse: But they already have them, somewhat.
12:52:15 <dmhouse> I read http://cavlec.yarinareth.net/archives/2006/07/20/nope-javas-still-evil/ and it makes me want to scream 'typeclasses!'.
12:52:19 <shapr> Python's 'honor system' now called Duck Typing, yeah?
12:52:32 <ChilliX> shapr: He may have: http://www.tcs.informatik.uni-muenchen.de/~hwloidl/
12:52:35 <lambdabot> Title: Hans-Wolfgang Loidl's Home Page
12:56:02 <shapr> ChilliX: Still, with HscNoRecomp, whether a module has ForeignStubs cannot be found from the .hi file alone.
12:56:18 <syntaxfree> GAH AGH AGH GAH GAH GAH.
12:56:32 <syntaxfree> Who was the sadistic soul that came up with OOP?
12:56:37 <syntaxfree> I can't get anything done.
12:56:51 <syntaxfree> I can't return functions from functions. How the heck am I supposed to get something to work in PHP?
12:56:56 <ChilliX> shapr: yes, I guess, that's true.
12:57:15 <shapr> ChilliX: So I wonder how the list of Linkables is calculated in that case. That's the code I want to find.
12:57:17 <roconnor> jgrimes_: um, I forgot to turn on unbox-strict-fields
12:57:36 <shapr> syntaxfree: Use Hope.
12:57:41 <daniel_larsson> OOP and PHP in the same sentence.... interesting
12:57:49 <jgrimes_> roconnor: so now how is it?
12:57:51 <roconnor> jgrimes_: now both IORefs and State strict records take about the same time in my one test
12:57:54 <syntaxfree> Hope?
12:58:04 <shapr> syntaxfree: http://hope.bringert.net/
12:58:04 <roconnor> IORefs still slightly faster
12:58:21 <syntaxfree> oh. that's really cool.
12:58:26 <syntaxfree> I'm supposed to fix existing PHP code, though.
12:58:26 <dcoutts_> roconnor, I'm writing a fast Haskell UM too...
12:58:43 <syntaxfree> it runs as CGI?
12:58:50 <roconnor> dcoutts_: you say `too' as if I have written one :P
12:59:18 <roconnor> dcoutts_: I *want* to write a fast UM, but I can't.
12:59:22 <dcoutts_> heh
12:59:28 <roconnor> I can only write slow and very slow UMs
12:59:33 <shapr> dcoutts_: Hey, can you come to #anglohaskell?
12:59:57 <sjanssen> roconnor: how slow is your slow UM?
13:00:01 <dmhouse> syntaxfree: PHP isn't very object orientated...
13:00:03 * dcoutts_ is debugging his UM
13:00:09 <dmhouse> syntaxfree: what code do you need to fix?
13:00:10 <syntaxfree> I went to PHP with a problem.
13:00:12 <Igloo> dcoutts_: The Haskell one?
13:00:17 <jgrimes_> dcoutts_: what are you using for the environment state?
13:00:17 <syntaxfree> And they said, "there are OOP patterns that can do that".
13:00:23 <dcoutts_> Igloo, no, I've written another Haskell one
13:00:31 <Igloo> Heh, fair enough
13:00:33 <dmhouse> I hate ##php.
13:00:36 <roconnor> sjanssen: it take 13 seconds to get to the login prompt on the extracted umix system.
13:00:44 <syntaxfree> But they're just very roundabout ways to avoid needing to return a function.
13:00:51 <dcoutts_> jgrimes_, program counter, memory and regs
13:01:06 <jgrimes_> dcoutts_: oh, this is for the icfp stuff.
13:01:09 <syntaxfree> it's that simple. Jesus. You don't need to make it purely-functional lazily-evaluated rooted-in-academia.
13:01:15 <dcoutts_> jgrimes_, yeah
13:01:19 <ChilliX> shapr: Well, the code in Main.main suggest to me that it just uses all the files that are specified on the command line.
13:01:22 <syntaxfree> I just need functions that can receive and output functions.
13:01:32 <ChilliX> Which would explain the bug.
13:01:36 <syntaxfree> why can't mainstream languages do that? :'(
13:01:42 <dmhouse> syntaxfree: what, at a higher level, do you want to do?
13:01:49 <jgrimes_> I'm working on a non-icfp related interpreter
13:02:11 <dmhouse> syntaxfree: doing thing the Haskell way obviouslly isn't going to work in PHP. OOP can still be elegant, but you just do things differently.
13:02:12 <syntaxfree> I'm trying to rewrite this bizarre db-like code for a client.
13:02:28 <syntaxfree> It doesn't use DBs, it reads from/writes to CSV files.
13:02:56 <syntaxfree> The way it's done is simply a lot of copy-paste programming with small alterations.
13:03:24 <syntaxfree> but it broke down for reasons I can't pin down, and I thought it'd be easy to rewrite stuff.
13:04:50 <ptolomy> If anyone gets bored, I'd love to see a hello world-level example of STM that integrates STM and IO.
13:04:59 <shapr> ChilliX: I don't understand? I'd guess that this guy had a foreign stub in his source, then commented it out, and the old _stub.o was still linked. Anyway, I think I need more info about this bug.
13:05:17 <Philippa> evenin'
13:06:08 <sjanssen> my Haskell UM takes 20s to login as guest and logout, how slow is that?
13:06:20 <ChilliX> shapr: The way it seems to me, he renamed the A_stub.o to B_stub.o and GHC picked B_stub.o up w/o there every having been a need for a B_stub.
13:07:24 <shapr> ChilliX: I can see that happening in one-shot mode. I can't figure out where GHCi does linking, so I can't tell if it's there too.
13:07:42 <roconnor> sjanssen: sounds similar to mine
13:08:51 <SamB> O'Cult starts at the top of the entire term every time, right?
13:09:52 <shapr> ChilliX: one-shot mode doesn't have access to a HomePackageTable, so it just grabs any _stub.o file. That happens in the Finder.findObjectLinkable function.
13:10:53 <dmhouse> I need a project. Still.
13:10:57 <shapr> GHC?
13:11:04 <ChilliX> shapr: ah, yes
13:11:26 <dmhouse> shapr: is it easy to start hacking on? Are there a good list of things I could do?
13:11:36 <SamB> Final Term:      (Compute (Mult ((S (S (S (S (S Z))))) ((Mult (S (S Z))) (S (S (S Z)))))))
13:11:37 <ChilliX> Yeah, so it does that unconditionally with every module spec'ed on the comman dline in absence of any other inf, right?
13:11:42 <dmhouse> Is there a document which describes the general layout of the repo?
13:11:46 <SamB> why isn't it using this rule:
13:11:55 <dmhouse> Including roles of the various files, etc.
13:11:55 <SamB> Compute (Mult (S x) y) => Compute (Add y (Mult x y));
13:12:20 <shapr> dmhouse: Yeah, it's pretty simple to get started with. I've learned much the last coupla days, feel free to ask me.
13:12:23 <roconnor> SamB if a rule applies equally to two places, then it isn't applied at all
13:12:45 <SamB> roconnor: but I only have one compute in this
13:12:51 <ChilliX> shapr: The question is how to do any better...
13:12:53 <shapr> dmhouse: Look for a simple bug her - http://hackage.haskell.org/trac/ghc/report
13:12:55 <lambdabot> Title: Available Reports - GHC - Trac
13:13:17 <roconnor> SamB ah yes
13:13:21 <shapr> ChilliX: I don't think GHC can do any better in one-shot mode. There's no available info.
13:13:43 <roconnor> SamB why are you apply (S (S...Z) to (Mult ...)
13:13:58 <shapr> ChilliX: Or does it have access to the .hi file?
13:14:02 <roconnor> your brackets make me suspicous
13:14:09 <SamB> those aren't my brackets
13:14:16 <SamB> those are O'Cults brackets
13:14:23 <roconnor> yes
13:14:25 <SamB> er, O'Cult's brackets
13:14:30 <ptolomy> How practically useful and convenient is GHC STM without unsafeIO stuff?
13:14:32 <roconnor> SamB but you made that turm
13:14:36 <roconnor> term
13:14:38 <roconnor> ugh!!
13:14:44 * roconnor can't type
13:14:47 <SamB> well.
13:14:55 <SamB> I didn't write it by hand...
13:15:04 <stepcut> is there a ghci :command that will show all the modules that start with Text.* ?
13:15:10 <roconnor> So one of your rules ended up making a number apply to an expression
13:15:21 <roconnor> O'Cult is untyped
13:15:32 <ChilliX> shapr: hmm, here an evil idea: You could look at the symbols of the stub file and see whether they match the module name
13:15:59 <ChilliX> This plus the check of the modification time would rule out must mix-ups, I guess.
13:16:39 <SamB> roconnor: oh, I see
13:16:51 <shapr> ChilliX: That is evil, but it would likely work.
13:17:39 <dmhouse> shapr: I'll darcs pull GHC and give it a go..
13:19:29 <ChilliX> shapr: Main problem is probably that it is easy to get at symbols in *nix, but I am not sure about windoes.
13:20:10 <ChilliX> shapr: re .hi file, would that help?  Does it list function for which stubs were generated?
13:20:22 <shapr> Yeah, I notice that findObjectLinkable explicitly uses "_stub.o", it doesn't even try to do win32.
13:20:55 <shapr> ChilliX: No, but it could. I added only the ModIface.mi_foreign :: Bool in hopes that would be enough.
13:23:37 <shapr> Does a debug build automatically enable debugTraceMsg ?
13:23:57 <ChilliX> I think, you got the iface.
13:24:12 <ChilliX> Look at end of DriverPipeline.compile
13:24:26 <ChilliX> handleBatch gets an iface
13:25:44 <shapr> But the HscNoRecomp case of handleBatch returns the maybe_old_linkable, right?
13:26:08 <ChilliX> Oh, is it Maybe ModIFace?
13:26:08 <shapr> And the HscRecomp case explicitly checks hasStub already, yes?
13:26:12 <ChilliX> grr, no signatures
13:26:26 <shapr> ChilliX: dons' tag building script and M-. :-)
13:26:57 <sylvan> ptolomy: I think it's very practical. Basically anytime you want a mutable reference (for design reasons, not performance reasons) start out using TVars. It's just very conveneient. If you end up in some obscure situation where an IORef (or MVar) would cause threading-releated problems, your TVars will just work. If you get exceptions in your actions your STM actions will just work. At some point
13:26:57 <sylvan> you may want to switch to an MVar or something for performance and be "very careful" when using it, but STM is a very good default IMO
13:27:35 <shapr> ChilliX: So the HscNoRecomp case of handleBatch doesn't change the linkables value, yes?
13:27:52 <shapr> Same for the InteractiveNoRecomp case of handleInterpreted.
13:28:45 <sylvan> (plus the new "check" in STM is good stuff)
13:29:07 <shapr> If I understand this correctly, only one-shot mode will flagrantly link  _stub.o files.
13:30:03 <syntaxfree> Browser caching is a bitch when you're debugging web apps.
13:30:23 <shapr> syntaxfree: You can explicitly turn off all caching in firefox, iirc
13:30:35 <ChilliX> shapr: It depends on the "compiler" functions in HscMain
13:30:48 <ChilliX> eg, hscCompileBatch
13:31:26 <ChilliX> or hscCompileOneShot
13:32:37 * shapr reads those functions
13:33:37 <shapr> What exactly depends on those functions?
13:33:50 <ChilliX> After all the recomp check still needs to read the iface, so it should be avilable, right?
13:34:21 <ChilliX> The runCompiler calls at the end of DriverPipeline.compile
13:34:38 <shapr> Where does the recomp check happen?
13:34:43 <syntaxfree> jesus.
13:34:51 <syntaxfree> in PHP, sort isn't a function.
13:34:57 <syntaxfree> you don't do $a = sort($b).
13:35:02 <syntaxfree> $a returns "True".
13:35:05 <syntaxfree> and $b is changed.
13:35:16 <syntaxfree> I was breaking my head looking at a heisenbug.
13:35:19 <shapr> syntaxfree: C'mon man, take that sort of chat to ##php or #haskell-blah
13:35:20 <dmhouse> Yeah. PHP is, bluntly, awful.
13:35:25 <ChilliX> I would say also in these functions of HscMain
13:35:34 <ChilliX> (well, maybe indirectky in them)
13:35:38 <syntaxfree> yeah, I wan't even looking where I was ranting.
13:35:43 <syntaxfree> Sorry :)
13:35:52 <dmhouse> At least Ruby has the decency to place exclamation marks in edit-in-place functions.
13:36:29 <ChilliX> shapr: sorry, need to go now - pick Leon up from child care.
13:36:36 <ChilliX> cu around
13:36:36 <shapr> ChilliX: Ok, thanks for your help!
13:36:51 <mnislaih_> looks like there are ghc hackers around. Anyone can give me a hand with some basic typechecker related doubts ?
13:36:59 <ChilliX> well, more like half-informed ramblings...
13:38:00 <shapr> mnislaih_: You can ask, I dunno if you'll get a response.
13:39:06 <shapr> ChilliX: Still helpful, I've only been hacking on GHC for two days.
13:39:07 <mnislaih_> basically I have the Type of a polymorphic function (coming from a DataCon), and I have the type of its arguments. I want to get to the type of the result
13:39:15 <ChilliX> shapr: :)
13:39:39 <ChilliX> shapr: btw, if you figure it out, please consider adding your insights to the Commentary.  Futre generations will be thankful ;)
13:39:42 <ChilliX> ok, bye now
13:39:49 <roconnor> @hoogle [a] -> (a -> m b) -> m [b]
13:39:49 <mnislaih_> ..the idea being to retrieve the tyvars instantiated  by the concrete types of the arguments
13:39:50 <shapr> ChilliX: will do :-)
13:39:50 <lambdabot> No matches, try a more general search
13:40:12 <roconnor> @hoogle [m b] -> m [b]
13:40:13 <lambdabot> Prelude.head :: [a] -> a
13:40:13 <lambdabot> Prelude.last :: [a] -> a
13:40:13 <lambdabot> List.maximumBy :: (a -> a -> a) -> [a] -> a
13:41:00 <dmhouse> roconnor: sequence.
13:41:07 <mnislaih_> a simpler question that would also help is, can anyone explain the difference between an AppTy and a FunTy ?
13:41:18 * SamB wonders if you can do better than
13:41:21 <SamB>     ADVIS.ARH=166@2312|1750c91bd2478a6dcdf5b11a0ff0b95
13:41:24 <roconnor> yeah, I want sequence . map
13:41:29 <dmhouse> roconnor: mapM.
13:41:35 <roconnor> of course!
13:41:50 <roconnor> SamB yes
13:41:54 <roconnor> 169
13:41:55 <vincenz> SamB: I got 168
13:41:56 <SamB> @pl sequence.map
13:41:57 <lambdabot> sequence . map
13:42:04 <dmhouse> Hrm. I'm failing GHC hacking at the first hurdle. I can't compile it :)
13:42:05 <vincenz> roconnor: I heard 169 was not valid
13:42:09 <roconnor> oh
13:42:13 <SamB> really?
13:42:18 <SamB> how is it not valid?
13:42:18 <vincenz> well not hte one on the ML
13:42:21 <vincenz> according to another pooster
13:42:23 <shapr> dmhouse: Did you run the darcs-all shell script?
13:42:29 <roconnor> are the test cases random?
13:42:30 <dmhouse> shapr: Yes
13:42:39 <shapr> dmhouse: What error(s) did you get?
13:42:39 <mnislaih_> dmhouse: do you have alex and happy ?
13:42:44 <dmhouse> shapr: autoreconf fails with autoreconf: `configure.ac' or `configure.in' is required
13:42:52 <dmhouse> mnislaih_: I'm not even at that stage yet.
13:43:01 <shapr> dmhouse: Are you in the ghc repo dir?
13:43:11 <mnislaih_> yep, but anyway you need to have them before running autoreconf
13:43:19 <SamB> well, having gotten that twice, I guess I'll move on
13:43:55 <shapr> dmhouse: darcs get --partial http://darcs.haskell.org/ghc && cd ghc && sh darcs-all --partial && autoreconf
13:43:57 <lambdabot> Title: Index of /ghc
13:43:58 <shapr> I think that'll work...
13:44:17 <dmhouse> shapr: Yeah. find -name 'configure.in' shows that the only one's in rts/gmp/.
13:45:10 <shapr> dmhouse: Since I can directly see http://darcs.haskell.org/ghc/configure.ac I know it should be working.
13:45:49 <SamB> hmm, do I want to even try the XML one?
13:45:49 <dmhouse> Okay, _weird_.
13:46:05 <dmhouse> configure.ac exists. But autoreconf still fails.
13:47:33 <SamB> I guess I'l save it for later...
13:48:28 * SamB groans at stupid pun re: gardener's account
13:48:30 <sylvan> Is there any good intro on what Hope is and what you can use it for and how? I've gone to that site like 4 times, went "but what does it do?", didn't find any easily accessible info, and went somewhere else.
13:48:50 <dmhouse> Shapr's writing an article, IIRC :)
13:49:02 <sylvan> But then again, maybe it's not Hope, I may just have a very short attention spa... oh look a new Lazy Town video...
13:49:15 <sylvan> dmhouse: sweet
13:49:24 <sylvan> shapr, you don't happen to have a draft somewhere?
13:49:51 * dmhouse skips autoreconf and goes straight onto configuring and hopes nothing breaks.
13:50:10 <shapr> I am?
13:50:12 <shapr> um...
13:50:13 <mnislaih_> dmhouse:  what is the error with autoreconf ?
13:50:19 <mnislaih_> did you put
13:50:27 <mnislaih_> make sure you put alex and happy in the path
13:50:27 <shapr> sylvan: Hope is a webapplication server.
13:50:55 <shapr> sylvan: It integrates HaskellDB, xhtml, newcgi, and a bunch of other modules.
13:51:02 <dmhouse> mnislaih_: it claims configure.ac or configure.in are missing. Nothing about happy and alex.
13:51:18 <shapr> sylvan: At the moment plugins are the most interesting part of Hope.
13:51:34 <sylvan> hmm... okay... is it comparable to something else? Is it HSP stuff or just a library?
13:51:47 <shapr> Some plugins are the blog, the photo album, the static pages, the settings UI for each module, etc
13:52:00 <shapr> Nah, hope doesn't have any templating yet.
13:52:31 <sylvan> So it's like CGI.hs++
13:52:32 <sylvan> ?
13:53:12 <shapr> Hope includes support for authentication and sessions too.
13:53:28 <shapr> It's really a webapp platform.
13:53:40 <SamB> hmm, antomaton cheats
13:54:00 <sylvan> Okay cool... so this could be used for pretty much anything people use PHP for?
13:54:16 <SamB> it goes back to the top-left of the terminal, which is not portable...
13:54:19 <shapr> Yeah, though I really want templating.
13:54:28 <sylvan> what do you mean by templating?
13:54:34 <SamB> also it wipes out the command I entered to start it :-(
13:56:53 <shapr> sylvan: Hope is a single cgi or fast-cgi binary that access your database.
13:57:16 <shapr> Pages are created purely in Haskell.
13:57:41 <shapr> I'd like to have pages that are a mix of static html and Haskell code.
13:57:48 <sylvan> ah, so like HSP
13:58:23 <shapr> I'm actually building a commercial website with Hope as part of my contribution. I'm trying to figure out what Hope needs to be used for serious webapps.
13:59:03 <sylvan> Microsoft-backing would be good :-)
13:59:30 <shapr> Have you used ZPT?
14:00:00 <sylvan> ZPT?
14:00:42 <shapr> Zope page templates.
14:00:55 <sylvan> Nope
14:00:55 <shapr> Halipeto is pretty much a reimplementation of ZPT in Haskell.
14:01:24 <sylvan> Halipeto is a Hope plugin?
14:01:32 <shapr> Anyway, the big problem with ZPTs is that you can't nest 'em, meaning all sub-bits must to be explicitly included in the toplevel of each html file.
14:01:42 <shapr> Nah, Halipeto was written by andrew cooke.
14:01:50 <shapr> But probably could be a Hope plugin
14:01:57 <sieni> Halipeto :-D
14:02:17 <sieni> halipeto == hug beast in Finnish
14:02:38 <shapr> I had the idea to use sub-DTD type checking to do nested templates. Malcolm Wallace said that HaXml was planned to have that sort of checking from the beginning.
14:03:11 <shapr> Most of the pain of Zope/Plone comes from the fact that bugs are not found until that part of the code is executed.
14:03:29 <shapr> Many times I've found released code that never could have worked in the first place.
14:04:15 <sylvan> Maybe the Haskell web site should be Hope at some point. It would be neat to have something written in Haskell running it, if only for the cool factor
14:04:17 <shapr> In any case, a Haskell templating module could be amazing and pleasant :-)
14:04:48 <wolverian> sieni, yeah, greatest project name ever probably :)
14:05:28 <sylvan> maybe some of the HSP stuff could be used for that...
14:05:53 <shapr> sylvan: imho, the biggest reason to use Hope is author support...
14:07:03 <sylvan> Right...
14:07:06 <shapr> Bjorn Bringert started writing Hope in May I think.
14:08:22 <sylvan> Hmm.. I may be misremembering but I think he tutored the D3-project with HSP here at Chalmers.. so there seems to be a bit of in-breeding in those two projects (in the sense that they at the very least work in the same corridor)...
14:09:28 <shapr> He maintains (and authored most of) haskell-xmlrpc, haskell-http, haskell-newcgi, haskell-parsedate, haskell-gd, haskell-exif, haskell-xhtml, etc
14:09:53 <shapr> Oh, and he maintains HaskellDB as well.
14:11:00 <shapr> sylvan: Anyway, grab Hope and install it.
14:11:06 <shapr> You'll quickly wish for cabal-get =)
14:11:15 * SamB gets past the first ant puzzle and freaks out ... until he notices the program limits
14:11:24 <shapr> On the other hand, I think that means Haskell is hitting the real world now.
14:11:30 <sylvan> hehe... Maybe I should check if it's installed somwhere on the chalmers system...
14:13:17 <SamB> these ant problems look fascinating
14:14:14 <shapr> sylvan: Still, grab it and start using it. We'll have a *real* webapp system soon if we can get people using Hope.
14:15:37 <sylvan> I don't really have anything to do with it though :-)
14:16:00 <shapr> Build a personal website?
14:16:10 <sylvan> bah, I have nothing to say :-)
14:16:22 <sylvan> "Here's my email, phonenr"
14:16:30 <shapr> You could write a blog.
14:17:14 <sylvan> hmm.. yeah I have nothing to say :-)
14:17:28 <shapr> Talk about research papers you read?
14:17:28 <sylvan> "today I played some video games for several hours, it was good"
14:17:29 <shapr> That's what I do.
14:18:12 <sylvan> I'd still need a server somewhere... Maybe I'll try to get it running on the CTH system and put it on my personal web space there...
14:18:51 <shapr> I have a virtual server in Atlanta. It costs me $15 a month.
14:21:15 <sylvan> Yeah I've been meaning to get some webspace and a domain somewhere at some point. It'll have to wait until I start making money, though. :-)
14:22:11 <dmhouse> sylvan: try ithium.net. Webspace from $15 a year. It's a not-for-profit host; the guy that runs it is a great bloke.
14:22:36 <dmhouse> The main site isn't complete, so try forums.ithium.net.
14:23:24 <sylvan> "if you run a worthwhile, non-profit project, then you may qualify for free hosting." hmm.. now for a worthwhile project!
14:25:23 <sylvan> dmhouse, any chance to get him to install Hope? :-)
14:25:34 <dmhouse> Ah, now that's less likely.
14:26:01 <dmhouse> I'd recommend a VPS if you want to do that.
14:26:13 <dmhouse> As you'll need to install a whole load.
14:27:50 <astrolabe> What are these 'ant problems'?
14:28:47 <vincenz> astrolabe: they need raid or a debugger
14:29:54 <SamB> astrolabe: in the ICFP 2006 thing
14:30:14 <astrolabe> Ah
14:30:22 <SamB> astrolabe: under the gardener account
14:33:26 <sjanssen> @hoogle Int32
14:33:27 <lambdabot> Data.Int.Int32 :: data Int32
14:33:37 <SamB> I've managed to complete the first one ;-)
14:33:44 <SamB> sjanssen: see also Data.Word and Data.Bits
14:34:34 <ptolomy> I'd like to get a VPS for darcs, and I'd be delighted to let other haskellers use it for their projects.
14:35:50 <SamB> hey, is this 5.3 thing with the publications a reference to filenames on some pathetic OS?
14:37:57 <SamB> hmm, you know, I'd really like an antomaton that ran on my real OS...
14:47:11 * shapr translates the secret Klingon message.
14:47:41 <nnunley> ?
14:48:44 <dmhouse> shapr: So what would you recommend as reading for getting into GHC?
14:49:00 <dmhouse> I'm reading that commentary, but everywhere just says it's out of date.
14:51:09 <kosmikus> Hi everyone. I finally put the list of accepted papers online at haskell.org/haskell-workshop/2006/ ... Please consider to participate in the workshop! I will send an announcement to the mailing list soon.
14:52:09 <shapr> dmhouse: Pick a simple bug from the GHC bug list and jump on it.
14:52:23 <shapr> dmhouse: Every time you're stuck for more than ten minutes, ask here on #haskell :-)
14:52:57 <dmhouse> shapr, well, yeah, but staring at a directory full of .hs files isn't very helpful. I'd need to know how the pieces fit together before I could really fix something.
14:53:18 <shapr> dmhouse: Okay, DriverPipeline is the real meat, imho
14:53:41 <shapr> It has compile and link, for example.
14:54:06 <kosmikus> dmhouse: will you be at the hackathon?
14:54:11 <dmhouse> kosmikus: No, sadly not.
14:54:20 <dmhouse> (Nor ICFP itself.)
14:54:29 <dmhouse> (Nor AngloHaskell.) :(
14:54:32 <shapr> freshhawk: Hi, learning Haskell?
14:54:51 <kosmikus> dmhouse: I probably won't make AngloHaskell myself. Too much travelling already ...
14:54:56 <freshhawk> shapr: yup
14:54:57 <kosmikus> Is the date for AngloHaskell fixed yet?
14:55:02 <shapr> freshhawk: Have any questions?
14:55:03 <dmhouse> kosmikus: This Friday.
14:55:04 <shapr> kosmikus: Yup
14:55:16 <dmhouse> freshhawk: How are you finding it?
14:55:18 <kosmikus> ok, then it's definitely "no" ...
14:55:28 <sylvan> @where AngloHaskell
14:55:28 <lambdabot> http://haskell.org/haskellwiki/AngloHaskell
14:55:36 <dmhouse> kosmikus: those papers will be released at ICFP?
14:55:39 <freshhawk> shapr: not right now.
14:55:40 <dmhouse> (Haskell Workshop)
14:56:10 <freshhawk> dmhouse, actually i love it. in the process of doing some simple stuff in order to go from knowing the language to actually feeling comfortable programming in it
14:56:13 <sylvan> dmhouse, you mean the next friday? The 4th of August?
14:56:46 <dmhouse> sylvan: Apparently so. :
14:56:48 <dmhouse> *:)
14:56:55 <dmhouse> freshhawk: Great :)
14:57:11 <dmhouse> freshhawk: Let us know if you come up with anything cool, or if you have any questions.
14:57:28 <dmhouse> freshhawk: Did you have any previous functional programming experience?
14:57:34 <freshhawk> dmhouse, sure thing.
14:57:58 <freshhawk> dmhouse, learned scheme way back when, liked that a lot but had trouble using it in the real world
14:58:19 <kosmikus> dmhouse: at HW, yes
14:58:35 <dmhouse> kosmikus: Okay, fun. And I'll be able to download them?
14:58:49 <freshhawk> dmhouse, i'm really happy to be back in FP. When i found out there was a purely functional lazy programming language that had a growing community i was pretty happy
14:58:50 <shapr> nnunley: I found a secret message in the GHC sources written in Klingon, and then succeeded in translating it.
14:59:05 <dmhouse> shapr: what did it say?
14:59:16 <dmhouse> freshhawk: Yeah, the Haskell community is wonderful. :)
14:59:23 <nnunley> shapr: Nice.
14:59:32 <kosmikus> dmhouse: if the authors choose to make them available on their homepages, which is likely
14:59:56 <dmhouse> kosmikus: Great. :) Some real cool looking papers there.
15:00:26 <dmhouse> kosmikus: But nothing by yourself? :) Or did you forfeit that by being on the committee?
15:00:59 <roconnor> Anyone know how we are supposed to get a script generate the solutions to the adventure problem?
15:01:04 <ndm> oh, Extended Static Checking for Haskell, that looks cool :)
15:01:06 <kosmikus> by being the chair. committee members may submit (but are held to a higher standard), the chair must not ...
15:01:42 <dmhouse> I see.
15:03:31 <kosmikus> but I probably wouldn't have managed anyway. I have to admit that I have not submitted anything to ICFP this year, neither to the GP workshop. I had a number of papers at earlier conferences (FLOPS, MPC, PPDP), and simply didn't manage to finish anything new until now, although I'm working on it ...
15:04:30 <dmhouse> Yeah.
15:05:34 <roconnor> ``UMIX scripts that generate all publications that you have submitted''
15:05:44 <roconnor> how are we supposed to do that for Adventure?
15:06:11 <Pete_I> what module do you use for long decimals?
15:06:23 <ndm> Pete_l, Integer
15:06:24 <vincenz> roconnor: didn't log?
15:06:29 <Pete_I> ndm, thanks.
15:06:48 <ndm> Int is 32  bit (at least), Integer is infinitely big
15:07:08 <roconnor> vincenz: I didn't play the game.  I'm just assembling the solutions from the team
15:07:12 <dmhouse> ndm: Int is only guarenteed to be 29 bits.
15:07:23 <roconnor> I have a ``startup script'' that generates 9 or 10 items we have
15:07:26 <ndm> dmhouse: true
15:07:36 <roconnor> but then the uploader is run and wooosh, I'm somewhere
15:07:49 <dmhouse> > logBase 2 (maxBound + 1 :: Int)
15:07:50 <lambdabot>  add an instance declaration for (Floating Int)
15:07:50 <lambdabot>   In the definition of `sh...
15:07:54 <shapr> dmhouse: If you find the klingon in the GHC sources, I'll tell you the translation :-)
15:08:01 <dmhouse> shapr: hah :)
15:08:09 <dmhouse> @type logBase
15:08:10 <lambdabot> forall a. (Floating a) => a -> a -> a
15:08:28 <dmhouse> > logBase 2 $ fromIntegral (maxBound + 1 :: Int)
15:08:29 <lambdabot>  -Infinity
15:08:35 <dmhouse> Riiight.
15:08:45 <dmhouse> Oh. Hehe. :)
15:09:31 <dmhouse> > logBase 2 $ fromIntegral (fromIntegral (maxBound :: Int) + 1 :: Integer)
15:09:32 <lambdabot>  31.000000000000004
15:23:10 <shapr> dmhouse: Did you find a small GHC bug to hack on?
15:23:42 <dmhouse> shapr: For now I'm going to do some reading, get my head around how GHC works. Then I might try http://hackage.haskell.org/trac/ghc/ticket/719
15:23:44 <lambdabot> Title: #719 (error messages are too long sometimes) - GHC - Trac
15:24:17 * dmhouse discovers that the # in type names refers to primitiveness rather than boxedness
15:25:02 <dmhouse> And ByteArray# is a boxed, unlifted type. Weird.
15:30:52 <dmhouse> What's a FunTyCon?
15:30:57 <mnislaih_> GHC hackers: I really need some clues about GHC Type datatype
15:31:04 <mnislaih_> ah, I know that one dmhouse
15:31:16 <mnislaih_> a FunTyCon is (->)
15:31:25 <dmhouse> Aha.
15:31:43 <mnislaih_> a Data Constructor denoting functions
15:31:53 <mnislaih_> _the_ data constructor denoting functions
15:32:16 <mnislaih_> now, what is an AppTy ?
15:32:36 <dmhouse> Function is *not* a TyConApp :)
15:32:48 <mnislaih_> yes
15:33:01 <mnislaih_> a gloriously helpful commentary
15:33:17 <SamB> probably a tycon applied to something?
15:33:19 <ndm> the simplest thing when i figured them out was to look at their show/output instances
15:33:21 <SamB> or the other way round
15:33:23 <dmhouse> Does 'saturated' mean 'has the right number of type parameters'?
15:33:29 <SamB> probably
15:33:31 <mnislaih_> dmhouse: yes
15:34:11 <dmhouse> "for example unsaturated type synonyms can appear as the RHS of a type synonym." Woah, really?
15:34:16 <dmhouse> So we can do type List = []?
15:34:26 <dmhouse> Type-level eta-reduction?
15:34:54 <mnislaih_> hmm yes, you can do that in haskell, cant you ?
15:35:07 <dmhouse> I didn't think so
15:35:30 <ndm> mnislaih_: no, you can't - would require type level lambda's, which ghc lacks
15:35:50 <dmhouse> So what does the comment mean?
15:36:33 <dmhouse> Wait, no, you can!
15:36:38 <dmhouse> At least, GHC accepts it.
15:37:04 <dmhouse> type List = []
15:37:05 <dmhouse> type Maybe2 = Maybe
15:37:08 <dmhouse> They both work
15:37:32 <mnislaih_> AppTy seems to stand for function application. But, does it make sense at type level ?
15:38:01 <mnislaih_> If I apply a function ([a]->a)
15:38:10 <mnislaih_> to an object of type Int
15:38:37 <mnislaih_> Do I get something like (AppTy ([a]->a) Int) ?
15:38:58 <mnislaih_> Can I simplify it to (TyConApp Int []) ?
15:39:13 <dmhouse> mnislaih_: if FunTyCon is _the_ data constructor denoting functions, why is a record with slots, for, say, kind and arity?
15:39:20 <dmhouse> And name?
15:39:21 <mnislaih_> err.. I mean to an object of type [Int] of course..
15:39:54 <dmhouse> mnislaih_: I think you mean (TyConApp [] Int) as well.
15:40:12 <mnislaih_> no, that one was right
15:40:14 <dmhouse> Or, even, TyConApp [] [Int].
15:40:35 <mnislaih_> I mean the DataCon Int applied to no parameters, as it has arity 0
15:40:42 <dmhouse> Oh, I see.
15:41:27 <mnislaih_> dmhouse: I am not sure about FunTyCon
15:46:05 <dmhouse> Ah, the stuff on predicates makes a lot of sense. :)
15:46:40 <ndm> how come everyone decided to hack on GHC?
15:46:45 <ndm> why not Yhc :)
15:46:59 <DeeJay> Hi all. I have a quick question about StablePtr's. I asked last night but no one who could help was around (so sorry to those who are hearing it again)... what would be an example use of the function castStablePtrToPtr?
15:47:24 <DeeJay> I found the docs somewhat cryptic... so wondered if #haskell could help.
15:47:33 <urz> anybody use HAIFA?
15:47:37 <ndm> ask on the mailing list haskell-cafe
15:47:40 <dmhouse> DeeJay: if you can't find anyone, the mailing lists are always good
15:48:08 <DeeJay> thanks for the tip
15:48:23 <ndm> a quick poll, who would use WinHugs if it support GHCi as well as Hugs and ran on all operating systems?
15:49:35 <mnislaih_> hmm, I am happy with ghci :)
15:49:54 <mnislaih_> and more with the upcoming breakpoint stuff :=)
15:49:58 <ndm> mnislaih_: is there any killer feature a GUI might add that would tempt you away?
15:50:16 <ndm> mnislaih_: it'll have full hat support, which makes breakpoint debugging look like the difference between Haskell and ASM
15:50:30 <mnislaih_> When I was using EclipseFP I loved the integration with ghci
15:50:37 <mnislaih_> In Visual Haskell I love the type information
15:50:52 <ndm> Apparently someone is porting EclipseFP to use Yhc
15:50:54 <mnislaih_> getting types for functions withouth type annotations for instance
15:51:09 <mnislaih_> and also, 'go to definition'
15:51:16 <ndm> yeah, Hugs has both those
15:51:52 <mnislaih_> What I don't like about hugs, or didn't when I used it last time, was the inability of defining local things
15:51:56 <mnislaih_> as you can do in ghci
15:52:14 <ndm> my program will allow you to use GHCi or Hugs as a base end
15:52:32 <mnislaih_> what are you working on exactly ?
15:52:36 <ndm> and you'll be able to have a  multiline input, so less need to define local things
15:52:38 <mnislaih_> a new WinHugs version or an IDE ?
15:52:39 <ndm> @where winhaskell
15:52:40 <lambdabot> http://www-users.cs.york.ac.uk/~ndm/projects/winhaskell.php
15:53:00 <ndm> like that, but I'm thinking of writing it in Haskell, using Gtk
15:53:19 <ndm> so it will be (Win|Linux|Mac)(Hugs|GHCi|Yhc...)
15:53:23 <mnislaih_> the problem with Hat is/was the lack of full Haskell extensions, plus libraries, support
15:53:36 <ndm> i am well aware of that
15:53:44 <ndm> haskekll extensions is a pain
15:53:49 <ndm> and likely to take a while
15:53:52 <ndm> libraries should be possible
15:54:03 <ndm> I have half written a GUI
15:54:29 <mnislaih_> and wait, integrate Hoogle with local Cabal packages
15:54:43 <mnislaih_> although it has nothing to do with WinHaskell it'd be cool too :)
15:54:47 <ndm> add integration in a WinHugs style environment, and thats pretty everything in hat's favour
15:54:55 <ndm> thats a separate task altogether
15:55:14 <ndm> but should be doable, although I'd wait for Hoogle 4 first
15:56:11 <mnislaih_> coming back to WinHaskell, having Hat integrated would be  a big plus
15:56:28 <ndm> yeah, I think so too
15:56:35 <ndm> at hte moment Hat is unuseable, basically
15:56:53 <ndm> my idea is that when your program crashes, it will just go "would you like to know why it crashed"?
15:57:03 <ndm> if you click yes, it builds, runs with Hat, and reports the error
15:57:06 <ndm> all at one click
15:58:13 <ndm> although it probably makes sense to integrate Hat with Cabal first
15:59:43 <dmhouse> mnislaih_: Ah, I know why FunTyCon is a record.
16:00:17 <mnislaih_> dmhouse: what have you found
16:01:08 <dmhouse> mnislaih_: it can only be created through mkFunTyCon, which gives it an arity of 2, so that's built-in. It's a record so you can apply, say, tyConArity to arbitrary TyCon values without worrying whether they're FunTyCons or not.
16:01:27 <dmhouse> If you notice, tyConArity and friends are shared among the other data constructors in TyCon.
16:01:42 <mnislaih_> ah, I get it
16:02:04 <mnislaih_> it'd be nice if there was a comment about that there though
16:02:56 <mnislaih_> ndm: how would Hat integrate with Cabal? In the same way as ghc profiling does right now ?
16:13:41 <lispy> can cabal be used to turn my whole project into a single dll?
16:14:12 <lispy> i see that a multi-dll project is not possible and i'm okay with that
16:14:51 <lispy> to the linker i added --mk-dll but that doesn't seem make a difference
16:16:01 <lispy> oh wait a sec
16:16:15 <lispy> i think it created it but in a different directory than expected
16:16:37 <mahogny> anyone with gtk2hs and concurrency experience here?
16:16:52 <mahogny> in particular, if they know the details about the yield hack
16:17:56 <lispy> you probably want dcoutts
16:30:54 <joelr1> folks, where does NewBinary live these days?
16:31:00 <joelr1> i need it to build crypto
16:31:24 <joelr1> still at http://www.n-heptane.com/nhlab/repos/NewBinary?
16:31:27 <lambdabot> Title: Index of /nhlab/repos/NewBinary
16:33:18 <lispy> @where NewBinary
16:33:19 <lambdabot> darcs get http://www.n-heptane.com/nhlab/repos/NewBinary
16:33:19 <joelr1> grrr... what's the lang package? does not seem to be part of ghc 6.5
16:33:35 <lispy> joelr1: what does ghc-pkg list say?
16:33:42 <joelr1> NewBinar cannot satisfy the lang-any dependency
16:33:44 <lispy> but lang package sounds fishy
16:33:46 <joelr1> lispy: it's not there
16:33:52 <lispy> @index lang
16:33:53 <lambdabot> Text.Html
16:34:02 <lispy> er...that's not what you want
16:34:26 <lispy> joelr1: how goes haskell in industry (I'm a win32 dev trying out haskell on a project ;)
16:34:26 <joelr1> sounds like something that should be part of ghc
16:34:43 <lispy> yeah, i bet it's been replaced by base
16:34:52 <joelr1> lispy: dunno :) not for me it does not go
16:35:04 <lispy> aww :(
16:35:29 <lispy> i find that i get stuck on stupid stuff for a while but otherwise it's been good
16:35:37 <joelr1> yup
16:35:41 <lispy> like right now i want cabal to build a dll and i can't seem to get it working
16:35:49 <joelr1> i think it's an experience that we all share when we start
16:36:07 <hellish> Does (,) mean something other that tuples in a heap profile? If I look at only the function which uses tuples, (,) dissapears off my graph.
16:36:19 <lispy> does it work if you replace lang with base -any?
16:36:32 <SamB> maybe something got inlined?
16:36:46 <SamB> (such as the tuples)
16:37:05 <joelr1> i;m removing it, lang, from the list of deps
16:37:19 <joelr1> gotta install c2hs, cpphs and greencard
16:37:23 <hellish> SamB: should I turn -O and look again?
16:37:24 <joelr1> or maybe not
16:37:33 <hellish> off^
16:37:36 <joelr1> i guess not
16:37:41 <lispy> joelr1: greencard won't be easy, but cpphs and c2hs should be easy
16:37:59 <lispy> i think i installed them just in case
16:38:09 <joelr1> grrr
16:38:16 <joelr1> Registering NewBinary-0.1...
16:38:16 <joelr1> Reading package info from ".installed-pkg-config" ... done.
16:38:16 <joelr1> ghc-pkg: invalid package identifier:
16:40:30 <lispy> how do i tell cabal i want a library instead of an executable?
16:41:02 <joelr1> ugh, i forgot
16:41:07 <joelr1> let me see
16:41:25 <SamB> heh, I just love this:
16:41:35 <SamB>         Your CV's weight is 521.
16:41:36 <SamB>         Your current rank is Lecture Administrator.
16:41:36 <SamB>         To use your administrative privileges:
16:41:36 <SamB>                 login:          guest
16:41:36 <SamB>                 password:
16:41:50 <joelr1> lispy: dunnoo. try looking at some existing libraries
16:47:54 <lispy> apparently whitespace is significant in cabal files
17:00:52 <lispy> is it just not possible to build a dll with cabal?
17:07:21 <lispy> is there a way to get cabal to run a custom ghc line after the build?
17:11:43 * edwardk sighs.
17:12:05 <edwardk> > fromIntegral (maxBound +1 :: Int)
17:12:06 <lambdabot>  -2147483648
17:12:08 <edwardk> I get
17:12:25 <edwardk> > log (-2147483648)
17:12:26 <lambdabot>  -Infinity
17:12:37 <edwardk> is weird =)
17:13:05 <lispy> @type log
17:13:06 <lambdabot> forall a. (Floating a) => a -> a
17:13:17 <edwardk> yeah, but its wrong =)
17:13:27 <lispy> > -2147483648 :: Double
17:13:29 <lambdabot>  -2.147483648e9
17:13:44 <lispy> > log (-2.147483648e9)
17:13:46 <lambdabot>  -Infinity
17:14:02 <edwardk> the result should be complex
17:14:18 <lispy> well...technically it is complex
17:14:42 <lispy> > log (1 +: 1)
17:14:43 <lambdabot>  Not in scope: `+:'
17:14:51 <lispy> @hoogle +:
17:14:52 <lambdabot> Hoogle Error: Parse Error: Unexpected character '+:'
17:14:57 <lispy> @hoogle (+:)
17:14:58 <lambdabot> Did you mean: (+:)
17:14:58 <lambdabot> Prelude.undefined :: a
17:14:58 <lambdabot> Control.Monad.Reader.ask :: MonadReader r m => m r
17:15:05 <lispy> hmm...
17:15:16 <lispy> @hoogle (:+)
17:15:18 <lambdabot> Did you mean: (:+)
17:15:18 <lambdabot> Prelude.undefined :: a
17:15:18 <lambdabot> Control.Monad.Reader.ask :: MonadReader r m => m r
17:15:25 <lispy> @type (:+)
17:15:26 <lambdabot> Not in scope: data constructor `:+'
17:15:40 <lispy> > 1 Complex.:+ 2
17:15:41 <lambdabot>  Not in scope: data constructor `Complex.:+'
17:15:41 <edwardk> but lets take the easier:
17:15:44 <edwardk> > log (-1)
17:15:45 <SamB> hmm, how to deal with Seq's in the XML problem...
17:15:45 <lambdabot>  -Infinity
17:16:44 <edwardk> I realize they probably just don't want to say 'Maybe a' as the reply
17:16:46 <edwardk> but still
17:17:00 <edwardk> NaN seems a more reasonable reply
17:17:42 <SamB> > log (-1) < 0
17:17:43 <lambdabot>  True
17:17:52 <monochrom> Eh?  At my own ghci prompt I get NaN for log(-1)
17:17:53 <SamB> > 1 / 0 < 1 / 0
17:17:54 <lambdabot>  False
17:18:07 <lispy> > log ( 1 :+ 2)
17:18:09 <lambdabot>  0.8047189562170503 :+ 1.1071487177940904
17:18:09 <SamB> must be a platform-dependant thing too ;-)
17:18:16 <edwardk> monochrom: i think its lambdabot
17:18:30 <SamB> monochrom: what CPU do you have?
17:18:30 <monochrom> > log (-1) :: Double
17:18:31 <lambdabot>  -Infinity
17:18:44 <edwardk> > log ((-1) :+ 0)
17:18:45 <monochrom> Ha!  You're right.  Celeron.
17:18:46 <lambdabot>  0.0 :+ 3.141592653589793
17:18:50 <edwardk> thats better
17:19:08 <SamB> ooooooooooooooooooo
17:19:19 <lispy> > log (-2147483648) :: Complex
17:19:19 <lambdabot>    `Complex' is not applied to enough type arguments
17:19:20 <SamB> for it is almost pi!
17:19:20 <lambdabot>   Expected kind `?',...
17:19:34 <lispy> > log ((-2147483648) :+ 0)
17:19:35 <lambdabot>  21.487562597358306 :+ 3.141592653589793
17:19:36 <SamB> > log (-2147483648) :: Complex Double
17:19:38 <lambdabot>  21.487562597358306 :+ (-3.141592653589793)
17:19:38 <edwardk> samb; it actually IS pi.
17:19:46 <edwardk> its one of euler's identities read backwards
17:19:55 <lispy> oh, it is
17:19:57 <SamB> edwardk: is it not pi times i?
17:20:04 <monochrom> So this is *the* dispute and competition between Intel and AMD?  That log(-1) should be NaN vs -oo ?
17:20:05 <edwardk> yeh
17:20:14 <edwardk> but the pi in question i was just referring to the imaginary part =)
17:20:14 <SamB> which is not quite the same as pi
17:20:27 <lispy> SamB: tell me the secret of building a dll with cabal!  you must know it, right?...
17:20:33 <SamB> hahaha
17:20:57 <SamB> for I do not know how to use Haskell on windows
17:21:05 <lispy> :(
17:21:12 <SamB> except that it probably involves starting with free disk space
17:21:35 <edwardk> that i think this is the first non-integer case for dependant typing i've seen =)
17:21:40 <lispy> how about this, can i get cabal to run a command of my choosing after building the .o files?
17:21:53 <monochrom> These days you can use free flash space instead of free disk space.
17:22:35 <lispy> i need someone like dons that uses cabal often
17:22:37 <finlay> Hello
17:22:42 <lispy> hi
17:22:49 <lispy> welcome to #haskell
17:23:00 <monochrom> Yay
17:23:15 <finlay> Im looking for some advice on getting haskells HDBC packages to run on debian sarge
17:23:32 <finlay> they are packaged for etch, but not sarge (current stable dist)
17:26:56 <lispy> finlay: they are not that hard to build by hand
17:27:07 <lispy> finlay: i built them by hand on windows
17:27:48 <lispy> finlay: iirc, it was just runghc Setup.lhs configure; runghc Setup.lhs build; runghc Setup.lhs install
17:28:44 <finlay> lispy: I'll give that a go thanks
17:31:12 <SamB> I not get how to write the CNF transformation for XML...
17:31:38 <lispy> SamB: there are at least three haskell xml libraries, none of them will do?
17:31:51 <SamB> not *that* XML
17:32:07 <SamB> the excessively mallable language
17:32:14 <lispy> heh
17:32:43 * hellish hopes UM implementation becomes a shootout benchmark.
17:32:45 <lispy> i could really use a postBuild example
17:32:56 <SamB> indeed
17:33:03 <monochrom> Hmmm what is XML then?
17:33:29 <SamB>   The Cult-Wide-Web Consortium (CW2C) has settled on the eXcessively
17:33:29 <SamB>   Malleable Language (XML) as the format for CW2 pages.  The abstract
17:33:29 <SamB>   syntax of this language is represented as O'Cult terms as follows:
17:33:29 <SamB>   quality ::= Bold | Emph | Maj
17:33:29 <SamB>   doc ::= A | B | Seq doc doc | Tag quality doc
17:34:02 <SamB> (from advise.man in /home/hmonk)
17:34:06 <monochrom> Oh man, this ICFPC contains too many parodies!
17:35:42 <SamB>   Given the granularity of our current sand, CW2 browsers are too slow
17:35:42 <SamB>   to display CW2 documents unless they are in _short normal form_ (SNF).
17:35:42 <SamB>   An XML document is in SNF iff
17:35:51 <SamB>   (1) No piece of the document matches any of the following three patterns:
17:35:51 <SamB>      
17:35:51 <SamB>       Seq (Seq d1 d2) d3
17:35:51 <SamB>       Tag q (Tag q d)
17:35:51 <SamB>       Seq (Tag q d1) (Tag q d2)
17:36:06 <SamB>   (2) For all nested Tag expressions (Tag q1 (Tag q2 d)) in the document,
17:36:06 <SamB>       q1 is less than q2, where Bold is less than Emph is less than Maj.
17:37:29 <SamB> I hate this part of O'Cult:
17:37:31 <SamB>          * if the rule matches the same number of subterms in both
17:37:31 <SamB>            positions, the rule is not applied.
17:39:30 <int-e> well, where'd be the challenge otherwise?
17:39:50 <SamB> point...
17:39:54 <SamB> but this is just... gah!
17:40:03 <SamB> I'd have to be insane to figure this out.
17:41:26 <SamB> I really don't think the least heeded/most needed part is very annoying compared to this part
17:43:11 <SamB> does anyone know about how many points this is worth anyway?
17:43:51 <int-e> depends. 334 is the top score we know of.
17:44:08 <int-e> about 160-170 for both. I think.
17:44:20 <SamB> mmm
17:44:27 <int-e> I had 166 (for arith) and 163 (for xml)
17:44:35 <SamB> got 166 for arith
17:44:58 <SamB> how do you deal with Seq?
17:45:10 <int-e> I know of a 168 arith solution.
17:45:44 <SamB> I heard tell of two 169 solutions, one of which was supposedly even valid
17:45:50 <int-e> http://paste.lisp.org/display/23096 were my solutions
17:50:02 <int-e> but the idea is the same for both, introduce two markers - one for going up, one for going down - and traverse the tree.
17:50:44 <int-e> every rule involves a marker, and there is only one marker in the tree at any given time, so no tie between rules can happen.
17:53:28 <SamB> int-e: your arith is much different from mine
17:53:32 <SamB> I wonder if mine is valid
17:54:11 <dons> good morning!
17:54:12 <lambdabot> dons: You have 2 new messages. '/msg lambdabot @messages' to read them.
17:54:24 <dons> thankyou Ms. Bot.
17:54:53 <int-e> SamB: the other obvious approach is to make a system of rules that only need to be applied at the top of the tree.
17:55:02 <int-e> SamB: but that seemed harder to do to me.
17:56:16 <dons> hellish: I agree. We should get the UM as a shootout benchmark
17:56:26 <dons> though it would damage pure fp languages....
17:56:41 <dons> Ptr (Ptr Word32) anyone?
17:56:46 <SamB> heh
17:56:54 <sjanssen> dons: did you write a fast UM in Haskell?
17:56:56 <shapr> Compile UM to native code?
17:57:02 <edwardk> heh
17:57:12 <dons> sjanssen: yeah, it's ok. but its probably 10x slower than C.
17:57:14 <edwardk> sandmark a UM in each?
17:57:17 <dons> i.e. it was usable
17:57:25 <SamB> shapr: I was thinking of a direct-threaded (I think thats what you call it) implementation...
17:57:26 <dons> edwardk: that's exactly what I'd do, yes.
17:57:29 <edwardk> shapr: hard, because they selfmodify
17:57:33 <sjanssen> dons: how long does sandmark take?
17:57:38 <dons> about 25 mins.
17:57:50 <edwardk> shapr: means even a jit is of limited usefulness
17:57:55 <edwardk> dons: ouch
17:58:03 <dons> right!
17:58:10 <dons> but that was usable, nonetheless
17:58:10 <shapr> oh
17:58:23 <edwardk> wonder if an hsplugin based jit could work =)
17:58:24 <SamB> I bet sandmark takes that long for me with my C UM
17:58:25 <sjanssen> my sandmark isn't quite finished, but I'm guessing 5 min. for my version
17:58:32 <dons> ah. good
17:58:50 <sjanssen> the secret is avoiding reallocating arrays
17:58:51 <edwardk> the c/c++ versions seem to average 1min 16 or 1min 30 here
17:58:54 <SamB> not that there is anything wrong with my C UM -- just that I have a slow CPU
17:59:02 <dons> sjanssen: I was going to translate edwardk's C version, here, http://www.cse.unsw.edu.au/~dons/tmp/edwardk.c
17:59:28 <dons> sjanssen: but if you want to see what we actually ended up using, its here http://www.cse.unsw.edu.au/~dons/code/icfp06/machine/Machine.hs
17:59:30 <edwardk> i hve that posted up on http://slipwave/info as well
17:59:38 <dons> its all very nice and State-monady and HUit-checkabke
17:59:40 <SamB> dons: I felt the need to use C to get reasonable load times for my UM.
17:59:42 <dons> but just too slow
17:59:50 <dons> SamB: oh, _load_ times?
17:59:52 <SamB> well.
18:00:11 <dons> you mean, just the part of sucking in the codex?
18:00:14 <dons> or the load operator
18:00:17 <SamB> I first tried the only way I could think of to do it in FPS
18:00:22 <SamB> just sucking in the codex
18:00:30 <SamB> where by FPS I mean Data.ByteString
18:00:38 <sjanssen> I was right, 4:55 for me
18:00:44 <dons> sjanssen: code somewhere?
18:00:56 <dons> I'd like to try to get out an optimal Haskell version
18:01:17 <dons> sjanssen: do you have some kind of mutable Ptr Addr# ?
18:01:41 <dons> I was thinking of something like,
18:01:43 <dons> data Array = Array !Int !(Ptr Word32)
18:01:43 <dons> data State =
18:01:43 <dons>     State {
18:01:43 <dons>         text :: !(Ptr Array),
18:01:45 <dons>         reg  :: !(Ptr Word32),
18:01:47 <dons>         pc   :: !Word32
18:01:50 <dons>     }
18:01:55 <dons> for the machine state. much like the mutable Yi buffers.
18:02:21 <dons> then we can directly use things like mmemove and other C ops from bytestring's base module.
18:02:48 <ChilliX> Hi dons!
18:02:52 <ndm> whats this for (has a sneaking suspicion it might be ICFP in Haskell)
18:02:57 <dons> morning ChilliX !
18:03:00 <SamB> that looks almost like my C version. except that I used global variables, and the regs were an array...
18:03:03 <SamB> ndm: indeed
18:03:05 <ChilliX> What you describe is exactly what I thought would be worthwhile trying.
18:03:08 <edwardk> hrmm. i wonder how bad just transforming each call to 'loadprog' into a compilation step via hsplugins would be. just compile the sequence of bytes up til the next loadprog and handle writes to array 0 as some sort of terminating event for the monad.
18:03:13 <SamB> ndm: only it is only an outline
18:03:28 <SamB> edwardk: how do you handle writes to the 0 array?
18:03:32 <sjanssen> dons: http://cse.unl.edu/~sjanssen/UM32.hs
18:03:35 <SamB> oh, right...
18:03:44 <sjanssen> be warned, the code is very ugly
18:03:51 <dons> ChilliX: in the end team Freiburg/UNSW used just normal IOUArrays, and that was ok. but real speed needs some lower level hackery
18:03:57 <edwardk> samb: anything that writes to array 0 past the current ip stops the monad, and you recompile
18:04:18 <edwardk> since you have to loadprog to loop that should be valid.
18:04:19 <ndm> isn't this just a task for where maybe C is better than Haskell?
18:04:20 <SamB> edwardk: that sounds slow
18:04:22 <edwardk> cache them by range
18:04:25 <dons> ndm, yes maybe.
18:04:31 <dons> but that's not satisfactory :)
18:04:40 <edwardk> well, it seems that loadprog isn't used very often except to call the same addresses in loops.
18:04:41 <ChilliX> ndm: That's beside the point :)
18:04:44 <dons> and its instructive finding problems that are hard to solve in haskell
18:04:52 <ndm> yeah, I kind of thought that might be the response :)
18:04:53 <SamB> if you consider the fact that you are supposed to support loadprogs of the 0 array with the utmost swiftness
18:04:59 <edwardk> and the only thing i saw that abused self modifying code was the code in the .umz stuff
18:05:18 <ndm> if we put Language.Interpretter.UM in the base, it could be written in C internally
18:05:20 <edwardk> yeah well, loadprogging array 0 can be fast. just any time you write to array 0 you have to invalidate the entire cache.
18:05:23 <dons> load on the 0 arrays is just a branch, so it should only set the pc.
18:05:28 <edwardk> or rather any cache item that overlaps the address written to
18:05:29 <SamB> edwardk: what, you actually looked at what it does?
18:05:38 <edwardk> yeah =)
18:05:43 <edwardk> i threw in some debug code to test it
18:05:56 <edwardk> so hrmm
18:06:01 <SamB> oh, I guess you were doing this before sandmark eh?
18:06:10 <SamB> I was not actually on time fot the contest
18:06:17 <SamB> s/fot/for/
18:06:43 <dons> sjanssen: very nice. i think we can make it a lot shorter, looking at edwardk's C code.
18:06:45 <edwardk> i didn't do anything during the contest other than slap together the version of the code you guys see there and an earlier version that dumped and let me use TeX's undump to restore the core from a current state
18:06:54 <edwardk> that way i could keep a logged in copy of the program
18:06:56 <edwardk> and just resume it
18:07:06 <SamB> why would you want to do that?
18:07:12 <edwardk> useful if you do lots of umodem crap
18:07:17 <SamB> well...
18:07:22 <SamB> you must have a lot of RAM or something
18:07:24 <edwardk> or want to keep 'compiled qvickbasic' code around without umodeming
18:07:27 <SamB> or maybe my UM is leaky
18:07:46 <dons> that's not a bad idea, edwardk
18:07:47 <SamB> is the "compiled qvickbasic" code compiled?
18:07:50 <dons> a persistent UM :)
18:07:54 <edwardk> exactly =)
18:08:13 <edwardk> i admit i'm half tempted to slap together a java one and leave it up as an applet
18:08:14 <SamB> how real is the filesystem?
18:08:28 <edwardk> you can make files on it, rm them, etc.
18:08:30 <dons> i suppose the next thing is to add a lambdabot plugin ;)
18:08:34 <edwardk> but it only has single user permissions
18:08:36 <edwardk> heh
18:08:50 <ChilliX> lol @ dons
18:08:50 <dons> @umix run adventure;go north;take foo
18:08:50 <lambdabot> Unknown command, try @list
18:08:55 <SamB> edwardk: I noticed that it only has 3 bits of permissions, and no groups
18:08:58 <edwardk> i almost want to write a qvickbasic target for a real programming language.
18:09:04 <SamB> or only claims 3 bits rather
18:09:08 <SamB> when you do ls -l
18:09:13 <edwardk> yeah
18:09:21 <edwardk> thats why i said, single user permissions. =)
18:09:33 <SamB> but it is not DOS
18:09:36 <edwardk> yeah
18:09:45 <edwardk> sad thing is its better than dos nonetheless =)
18:09:49 <SamB> it at least claims that files have owners
18:09:51 <dons> edwardk: or perhaps work on a C-- to UM machine backend to ghc..
18:10:00 <SamB> well, at least DOS comes with an assembler
18:10:12 <SamB> though I suppose a UM assembler wouldn't be of much use
18:10:17 <edwardk> well, the only reason why i'd like to dump qvickbasic is then you can run it IN UMIX =)
18:10:27 <sjanssen> dons: perhaps the organizers already have?
18:10:39 <dons> I think they must have, for an SML compiler
18:10:52 <ChilliX> plus, I doubt they coded um.um in hex
18:11:04 <int-e> using DEBUG as an assembler was painful though.
18:11:16 <SamB> int-e: but it does grant ULTIMATE POWER
18:11:19 <edwardk> hrmm what sort of speed impact is there for running sandmark.umz through um.um?
18:11:21 <ChilliX> thought, getting it to be 1024 surely required some acrobatics
18:11:23 <edwardk> i haven't tried yet
18:11:26 <SamB> such as the ability to perform arbitrary system calls
18:12:08 <SamB> edwardk: I would hope um.um did more than copy your program to an array and loadprog 0 it...
18:12:14 <int-e> Heh. I did use it, occasionally.
18:12:46 <SamB> well, especially considering it doesn't know how long your program is and has no way to find out
18:12:54 <edwardk> heh, well, its supposed to be an implementation, so it might so some real legwork of about the same complexity as the c implementation
18:13:00 <SamB> hmm
18:13:02 <SamB> ./um/um sandmark.umz  467.34s user 0.92s system 75% cpu 10:19.89 total
18:13:25 <edwardk> was that with their um on yours or just yours?
18:13:33 <SamB> just mine
18:13:36 <SamB> my C one
18:13:52 <SamB> my Haskell one would probably take hours
18:14:04 <SamB> I shouldn't have used an IntMap for the heap
18:14:30 <edwardk> sandmarking the emulated version
18:14:30 <dons> we used an IntMap, and run about 2.5x slower than your C one
18:14:34 <edwardk> whoa. slow
18:14:47 <int-e> is there any way to get a reasonable switch statement from ghc?
18:14:48 <SamB> how did you allocate though?
18:14:57 <dons> int-e case on Word32?
18:15:04 <edwardk> heh well, it just finished the first time tick =)
18:15:13 <dons> SamB, newArray
18:15:23 <SamB> dons: how did you pick new numbers, I meant
18:15:30 <edwardk> tick
18:15:36 <dons> a unique supply ... i.e. an Int sitting in the state.
18:15:46 <dons> we didn't reuse
18:15:49 <SamB> ah, see, I bet that is part of why mine is so slow
18:15:54 <SamB> but is that safe?
18:15:58 <int-e> I didn't look at the C code, but the core code didn't look good - case a==0 of False -> { case a==1 of False -> ... True -> stuff } True -> stuff.
18:16:01 <dons> hasn't crashes yet..
18:16:03 <SamB> what if it does more than 2^32 allocations
18:16:11 <edwardk> it would have to use 4 billion newarrays or so
18:16:12 <dons> right. what if ;) then it crashes
18:16:15 <int-e> hmm. stg. sorry.
18:16:18 <edwardk> =)
18:16:22 <edwardk> might take a while
18:16:43 <edwardk> its a barrier to persistent umix. but thats about it =)
18:16:43 <SamB> I guess these things don't use nearly as many arrays as I would expect...
18:17:07 <SamB> if it were to wrap around, you'd need to check against the IntMap
18:17:45 <SamB> did I mention I had to resort to C for reading scrolls? (or did, in any case?)
18:17:57 <dons> SamB: you could always have an infinite list of Ints, and then just push back any you deallocate
18:18:06 <dons> so a stack of unique idents
18:18:08 <SamB> donshuh
18:18:09 <edwardk> reading scrolls from the output stream?
18:18:24 <SamB> edwardk: no, for booting
18:18:29 <sjanssen> dons: that's a neat application of lazy evaluation
18:18:30 <edwardk> ah
18:18:57 <sjanssen> I want a chance to use that now
18:18:57 <int-e> dons: I did that actually
18:19:14 <SamB> so like [1..maxBound] ++ [minBound..-1]?
18:19:25 <dons> yeah, we were going to, then decided we probably wouldn't run out of unqiues
18:19:44 <dons> [minBound ..] ?
18:19:58 <dons> but yeah, something like that
18:20:09 <SamB> well, in case you run out of positive ones!
18:20:19 <SamB> well. not on a 32-bit machine like mine, but ;-)
18:20:54 <SamB> my C version cheats and just stores the pointers as uint32_ts
18:21:28 <int-e> sigh. Stack space overflow: current size 8388608 bytes. :(
18:21:29 <SamB> (offset a bit to make room for the length at the beginning)
18:22:56 <SamB> int-e: oh, I annotated your paste with my version of arith...
18:23:36 <SamB> I'm not at all sure it really does what it is supposed to do, but it passes the test at least
18:24:46 <int-e> SamB: neat
18:26:18 <SamB> hmm, yours is interesting too...
18:26:47 <SamB> what does the R accomplish?
18:27:00 <int-e> 'Return'
18:27:27 <int-e> a Computation, when done turns into a Return <some value>
18:28:10 <SamB> hmm...
18:28:25 <SamB> that is a nice idiom ;-)
18:28:31 <int-e> note the   a (R x) y => a x (Compute y);  rule -> when the left argument is evaluated, use the right one
18:28:36 <SamB> I wonder if it can be used for other things?
18:28:39 <int-e> err, compute
18:29:00 <int-e> the XML one uses the same idea. it's called 'U' there, for 'Up'.
18:29:04 <SamB> ah
18:29:18 <SamB> I think R makes more sense
18:29:36 <SamB> I was thinking it might mean "Result"
18:29:59 <int-e> Up comes from a tree traversal point of view
18:30:02 <SamB> I'm pretty sure length is counted in terms of the number of name tokens, not characters, btw
18:30:27 <int-e> if everything is already evaluated (no changes need to be made), SNF/Up follow the path of an in-order tree traversal
18:30:37 <int-e> I know.
18:30:49 <int-e> But I tried that change and never changed it back :)
18:30:55 <SamB> oh
18:31:31 <int-e> oh, post-order in XML (for no particular reason. I think it simplified the Seq/Seq handling a bit)
18:31:33 <SamB> I never bothered because it was giving these figures for size that looked like they might be the number of name tokens
18:31:43 <SamB> certainly too small to be the number of characters
18:31:47 <edwardk> theh, sandmark is still running in the reference implementation
18:31:54 <edwardk> we're at 69.
18:32:05 <edwardk> looks like it'll take the better part of an hour in total
18:33:54 <edwardk> ok, extrapolated from current progress to 52 minutes on a machine that takes a minute 30. So its a 34:1 speed hit
18:34:23 <SamB> only three times as bad as naive Haskell?
18:34:34 <edwardk> dons: how are the c plugins coming?
18:35:27 <dons> the generated C plugins? prototype is written
18:35:31 * edwardk tries to figure out a good set of assembly opcodes for the bulk of umix to jit it
18:35:41 <dons> yeah..!
18:35:54 <SamB> o.O
18:35:57 <SamB> er.
18:36:02 <SamB> o_O
18:36:03 <edwardk> too bad i don't have a nice set of registers on this machine
18:36:33 <dons> I think generating C would be ok, and let gcc handle the register allocation
18:36:37 <edwardk> and i don't run 64 bit linux any more so i can't use the extended set.
18:36:58 <edwardk> well, the reason i wanted to use real registers is that way i can avoid going out to memory for all 8.
18:37:01 <SamB> dons: how would that handle trans-snippet stuff?
18:37:13 <SamB> you'd need to do like QEMU...
18:37:15 <dons> trans-snippet?
18:37:24 <SamB> well. you know how JIT works?
18:37:33 <SamB> you glue pieces of code together
18:37:55 <dons> oh, not really. I wasn't thinking of JITing it, more of generating a C src in one pass, then exec . gcc the result
18:37:59 <SamB> usually keeping somet things in registers between pieces
18:38:19 <SamB> QEMU does this by associating global variables with registers
18:38:40 <SamB> (it also does magic with relocations to parameterize the snippets)
18:38:51 <edwardk> hrmm
18:39:03 * edwardk starts taking apart an old apple  iigs emulator to build a jit =)
18:39:22 * int-e wonders how heavily the UM programs rely on self-modifying code.
18:39:22 <edwardk> gah
18:39:27 <edwardk> i don't have the old one
18:39:39 <dons> int-e, well there's a mixture of data and code in the input program, iirc
18:39:42 <edwardk> i have the pre-jit version on my harddrive
18:39:43 <dons> so you'd have to handle that.
18:39:51 <dons> but i'm not sure if we know if there's any self-modiyfing code in there
18:40:05 <edwardk> there is SMC in the codex.umz
18:40:14 <edwardk> not sure about the decrypted one though
18:40:20 <dons> oh, there you go :)
18:41:02 <dons> so you'd have to dump the instrs into a RWX segment, like we do with adjustor thunks
18:41:55 <edwardk> well. actually a R-X and catch write faults.
18:44:55 <edwardk> 1630890 self-modifying code operations in running just UMIX long enough to log in and logout
18:45:11 <edwardk> so a naive jit will be a nightmare
18:45:28 * lispy fights his cabal demons head on
18:45:35 <edwardk> not sure if any of those are in the same data range as any executed bytes though.
18:45:42 <dons> hmm
18:45:43 <edwardk> no good way to test. hrmm
18:45:45 <int-e> edwardk: hmm, how many of them are just generated by some unpacker?
18:45:48 <edwardk> yeah
18:46:00 <edwardk> well, the decoded um i don't think is packed
18:46:07 <edwardk> codex.umz is compressed to hell
18:46:26 <edwardk> and it might just be that the bulk of what it does is entirely ON array 0
18:46:33 <edwardk> so that could be all data accesses, etc.
18:47:22 <int-e> data in the middle of code, right
18:47:45 <edwardk> yeah, if they compile their data segment at the end of array 0 and just access it there, etc.
18:47:50 <int-e> if we catch a signal every 10 operations then it'll be hard to beat an interpreter
18:48:02 <edwardk> heh, interesting
18:48:22 <edwardk> i'm catching loads to array 0 right now and i haven't seen any since starting the decoded um
18:49:56 <int-e> interesting.
18:50:24 <edwardk> likewise i only get 2 such loads in the sandmark
18:50:28 <dons> yeah, i didn't see any either, when testing my LOAD handling a few days ago
18:50:31 <edwardk> when i run the sandmark IN the emulator
18:50:35 <edwardk> =)
18:50:51 <int-e> maybe they do subroutine calls by modifying the 'return' instruction? (a orthography followed by a load, that would be - the orthography would be patched)
18:50:53 <edwardk> so its llikely that most jitted instructions can be cached.
18:51:52 <edwardk> well, its possible to do SMC tricks like that. I used to use them for some really bad loop optimization stuff in the early pentium days, but its not a popular notion, and it seems unlikely that they'd do something that backwards
18:52:16 <int-e> does it?
18:52:37 <edwardk> well, if i catch and invalidate any write to a memory region in advance of the current cursor
18:52:44 <int-e> I mean, it *is* an old cult we're dealing with. :)
18:52:52 <edwardk> and i define jit runs as running until the next loadprog
18:53:00 <edwardk> i think it might work
18:53:18 <edwardk> now the dilemma is c vs. haskell =)
18:54:10 <edwardk> the haskell jit would suffer from the fact that it has to go through a fairly monolithic process to start up plugins, the c jit would be non-portable
18:54:16 * int-e wonders why that little haskell um of his allocates memory :/
18:54:32 <int-e> thunks that is
19:00:21 <int-e> are things like using  StateT Machine IO  inherently bad?
19:00:47 <edwardk> doesn't seem too bad to me
19:00:58 <sjanssen> http://cse.unl.edu/~sjanssen/UM32Taint.hs -- there's a UM that prints a message every time it executes an instruction that has been amended
19:00:59 <edwardk> or do you mean performance wise?
19:01:05 <int-e> performance wise
19:01:17 <edwardk> sjannsen: does it yell at you much?
19:01:24 <sjanssen> int-e: I got a speed up when I switched to explicit paramater passing
19:01:52 <int-e> the StateT stuff gets inlined but strictness could be a problem ... maybe other things, too
19:02:11 <sjanssen> edwardk: I poked around a little in Umix and I didn't seem to get any
19:02:21 <sjanssen> it was not an exhaustive search by any means
19:02:27 <lisppaste2> edwardk pasted "counting um" at http://paste.lisp.org/display/23175
19:02:42 <edwardk> i slapped in some signal handling code to llet it print out statistics at the end
19:02:59 <edwardk> but i haven't annotated to check for SMC cases at all yet
19:03:17 <edwardk> just so i could try to figure out how often program loads were being done
19:03:21 <edwardk> i haven't found any in UMIX
19:03:27 <dons> int-e, sometimes you have to watch out for strictness on the state value
19:03:29 <edwardk> just the test one or so in the sandmark
19:03:32 <dons> when using StateT
19:04:07 <edwardk> codex.umz does about 5 during its startup selfcheck.
19:04:32 <xahlee> do we have a Mathematica expert here?
19:05:19 <edwardk> xahlee: why not just ask the question and we'll see what we can do =)
19:05:30 <dons> there's a mathematica channel, I think
19:05:43 <edwardk> 91245787 self-modifying code operations
19:05:43 <edwardk> 2 program loads
19:05:43 <edwardk> 9 arrays loaded
19:05:43 <edwardk> 5 arrays freed getting to the menu prompt in codex
19:05:52 <edwardk> so it is safe to assume that program loads are fairly rare
19:06:10 <edwardk> though the SMC count is just 'writes to array 0'
19:06:40 <xahlee> dons: i'm the only one there.
19:07:01 <xahlee> edwardk: i'm one of the world's top mathematica expert, so, unless there are expert here, chances are, nothing you can do.
19:07:18 <xahlee> but here's my Q: http://rafb.net/paste/results/dXkz0074.html
19:08:36 <dons> sjanssen: very nice. your UM32 really zips along
19:10:46 <dons> sjanssen:btw, I've had some success with tthe -optc-march=pentium4 flag
19:13:09 <edwardk> hrmm.
19:13:29 <edwardk> i haven't seen a single SMC call in your nnotated version yet
19:13:32 <edwardk> there might be hope =)
19:14:30 <edwardk> in fact now that i think about it the one from the self-test may have been a bug from my first attempt to load. when i er.. forgot to read the characters unsigned =)
19:14:52 <edwardk> i haven't looked at it since then
19:18:17 <sjanssen> man, why do I get confused when tab completion doesn't work in UMIX?
19:18:28 <edwardk> heh
19:18:30 <xahlee> edwardk: do you have Mathematica?
19:18:55 <edwardk> xahlee: yeah, but unfortunately at the moment, they don't believe i own it, and i need to send them a letter to get it moved to this machine =)
19:19:14 <xahlee> edwardk: ah, the perils of student version. :D
19:19:40 <edwardk> xahlee: i did a lot of work in it, and my advisor wrote a book on it, hence why i figured i might be able to help
19:19:57 <edwardk> but without access to DO anything with it right now i can't find a way to answer your question
19:20:13 <xahlee> edwardk: i probably need something like ErrorQ[f[x,y]]
19:20:24 <edwardk> i suppose i could crack it
19:20:34 <edwardk> but that seems counter to my purposes.
19:20:35 <xahlee> but as far as i know up to version 3, there's no such function
19:21:13 <dons> sjanssen: want to stick your UM32.hs into a darcs repo?
19:21:26 <dons> i'd like to see if we can really crank it, when I have some spare time
19:21:52 <dons> using a Ptr Word32 would be one thing I'd like to try
19:22:36 <edwardk> so how bad is haskell at handling the optimization of code thats just one gigantic stream of monadic ops?
19:22:55 <dons> not sure..
19:23:02 <dons> I've not heard of anything
19:23:15 <edwardk> hrmm
19:23:32 <dons> i mean, i'm not aware of any reports
19:23:53 <dons> depends on the monad..
19:24:41 <Cufisz> is there a way to interupt a GHCi computation?
19:24:48 <edwardk> xahlee: can you get there with HoldPattern?
19:24:48 <dons> ^C ?
19:24:52 <Cufisz> hmm
19:24:55 <Cufisz> doesn't seem to work on windows
19:25:15 <dons> can you send signals some how?
19:25:30 * dons is windows clueless
19:25:35 <Cufisz> i'm not sure...
19:25:37 <Cufisz> =|
19:25:56 <xahlee> edwardk: no...
19:26:00 <edwardk> dons: the monad would basically track 8 values for registers (though i might just make them IOrefs) and the current jit-list.
19:26:10 <dons> oh, I think you should pass those as arguments
19:26:17 <xahlee> edwardk: you have a function f, and you want to know what argument it takes
19:26:21 <dons> we got really really good code for a shootout program that way, we beat gcc
19:26:40 <edwardk> yeah i can't seem to find any good way to introspect f.
19:26:45 <dons> so pass 8 register, non-mutable arguments, and then just change the argument in the recursive call
19:26:55 <dons> then there's no IORef cost either
19:26:59 <edwardk> hrmm so
19:27:18 <dons> i.e. eval a b c ... = case op of .... -> eval a' b' c'
19:27:34 <edwardk> generate a function like foo a b c d e f g h = do and then <- to mask them?
19:27:35 <int-e> but that makes register lookup hard
19:27:37 <edwardk> this is for the jit =)
19:27:40 <dons> those args will end up on the stack, unboxed, if you're lucky
19:27:44 <int-e> oh
19:27:48 <SamB> I used an IOUArray for the registers...
19:28:01 <dons> yeah, or do that. same as sjanssen's code
19:28:42 <SamB> I kept the finger in there too, though maybe it would be better not to
19:29:00 <dons> yeah, no need for it to be in there
19:29:15 <edwardk> the only reason i would need it is if the jit can SMC
19:29:21 <edwardk> otherwise i can be finger-free.
19:29:21 <dons> the lesson of partial-sums: http://shootout.alioth.debian.org/gp4/benchmark.php?test=partialsums&lang=ghc&id=2
19:29:22 <lambdabot> Title: partial-sums Haskell GHC #2 program | Gentoo : Intel&#174; Pentium&#174;&nbsp;4  ...
19:29:45 <SamB> yeah, but even with no JIT it might be slower to keep it in there...
19:29:46 <dons> is that passing arguments is a better way to emulate mutable variables :)
19:30:09 <dons> oh, gcc beats us by 0.04s now :/
19:30:11 <edwardk> thats somewhat horrifying to me dons =)
19:30:14 <SamB> dons: so StateT is teh best
19:30:27 <SamB> edwardk: which?
19:30:31 <dons> not necessarily, SamB
19:30:40 <dons> since you've got too many indirectoins, and a lazy state type
19:30:53 <SamB> hmm?
19:30:53 <dons> and the monadic plumbing
19:30:54 <edwardk> the fact that they get their best results by recursing with 13 variables in that case
19:30:57 <SamB> lazy state type?
19:31:05 <SamB> what monadic plumbing?
19:31:17 <SamB> StateT doesn't have monadic plumbing to speak of
19:31:22 <SamB> just the bare minimum
19:31:46 <SamB> well... maybe it should use (# , #) instead of (,)
19:32:12 <sjanssen> dons: darcs get http://cse.unl.edu/~sjanssen/UM32
19:32:23 <SamB> 32 only?
19:32:39 <lisppaste2> int-e pasted "slow UM :/" at http://paste.lisp.org/display/23176
19:33:42 <dons> cheers sjanssen
19:33:45 <int-e> does anyone want to have a look? I'm lost (I tried a strictified state transformer but that didn't change the figures. STG code shows some allocations of Machine though, which is a bad sign)
19:34:03 <SamB> int-e: yours is more concise than mine I think
19:34:03 <sjanssen> int-e: you can make the IOUArray strict too
19:34:23 <int-e>     Unexpected strictness annotation: !IOUArray
19:34:42 <dons> oh, no ghc 6.5
19:34:54 <dons> int-e, sjanssen's using bang patterns :)
19:35:03 <dons> oh, actually
19:35:11 <dons> you mean !(IOUArray ..)
19:35:16 <int-e> ohh
19:35:41 <int-e> let's see if that changes anything
19:36:23 <SamB> sjanssen: fix it?
19:37:04 <sjanssen> SamB: fix what?
19:37:10 <dons> hey, we regained the lead http://shootout.alioth.debian.org/gp4/benchmark.php?test=nsieve&lang=all
19:37:16 <lambdabot> Title: nsieve benchmark | Gentoo : Intel&#174; Pentium&#174;&nbsp;4 Computer Language S ...
19:37:45 <int-e> dons: heh, that made things worse :/
19:38:38 <int-e> sjanssen's UM is 6-7 times faster here
19:38:49 <SamB> oh, what the hell are these bangs everywhere?
19:38:59 <dons> seqs
19:39:20 <sjanssen> SamB: I'll remove those momentarily
19:39:23 <SamB> I should have known
19:39:53 <SamB> and these only work if you don't put a space after them, I suppose?
19:39:57 <int-e> ah I like them :)
19:40:08 <SamB> I don't because I get
19:40:17 <SamB> Chasing modules from: UM32.hs
19:40:17 <SamB> Compiling Main             ( UM32.hs, UM32.o )
19:40:17 <SamB> UM32.hs:120:4: Parse error in pattern
19:40:37 <int-e> I know. Finally having a ghc 6.5 around is sorta useful ;)
19:40:57 <dons> that and you get Data.ByteString installed for free ;)
19:41:03 <int-e> err no
19:41:16 <int-e> I went through the trouble of removing it from ghc's sources ;)
19:41:17 <SamB> I thought it was "for killing"
19:41:25 <dons> bad int-e
19:41:31 <dons> we all _need_ Data.ByteString
19:41:33 <dons> ;
19:41:35 <dons> ;)
19:41:36 <SamB> at least, that was the impression I got from audreyt
19:41:37 <int-e> I still have it
19:41:42 <SamB> because it did not *WORK*
19:41:45 <int-e> in its own shiny fps package
19:41:54 <edwardk> samb: that sjannsen's code? works for me with 6.5 doesn't compile in 6.4 for me
19:42:06 <dons> int-e, why remove it? did it break something?
19:42:13 <SamB> dons: yes!
19:42:15 <SamB> FPS!
19:42:16 <int-e> dons: no, wasn't up-to-date enough
19:42:24 <dons> oh. ok. its up to date now
19:42:25 <SamB> it broke FPS
19:42:28 <int-e> dons: and yes, it broke building bytestring
19:42:31 <dons> thanks SamB :)
19:42:33 <int-e> :)
19:42:47 <dons> well, better we sort this all out now, than when 6.6 is reesaed
19:42:57 <dons> yes. reesaed. that's right
19:47:28 <int-e> Oh, btw I was quite proud of this use for join: join (liftM3 wmem (rreg a) (rreg b) (rreg c))
19:47:53 <dons> :)
19:48:12 <SamB> yeah, I somehow decided to do that too
19:48:17 <dons> we should have a little competition to get the fastest UM in haskell
19:48:28 <dons> I'll host some sandmark times, if people like
19:48:35 <SamB> sandmark times?
19:48:48 <dons> yeah, the runtime of the sandmark on the UM
19:48:57 <dons> a bit of competition should be good to get the best result
19:49:06 <SamB> but mine would be slower than yours because my CPU has only got four hundred and fifty mega-hurts
19:49:16 <int-e>  right now I'm timing (echo 'guest'; echo 'logout') | ./um UMIX
19:49:20 <int-e> that's slow enough ;)
19:49:21 <dons> no no, you submit them to me, and i run them on a 3G P4
19:49:26 <SamB> oh oh
19:49:40 <dons> i.e. just make the link available, i run them, and update the rankings
19:49:43 <SamB> you should have said you'd sandmark them and host the results
19:49:49 <dons> ah :)
19:50:10 <dons> then we can consider a parallel implementation..
19:50:18 <SamB> ???
19:50:25 <dons> since i have this 20 box cluster sitting idle..
19:50:38 <SamB> to be sure, a decent sand-based computer would have paralism
19:50:40 <dons> and there's some sort of uber-karma to someone who works out how to run the UM on that
19:50:41 <int-e> what do you want to parallelize?
19:50:44 <SamB> if only to look cool
19:50:47 <int-e> :)
19:50:53 <dons> not sure, int-e.  hence uber-karma.
19:51:07 <int-e> massive speculative execution
19:51:08 <int-e> ?
19:51:11 <dons> yeah, perhaps?
19:51:15 <dons> pipelining at least
19:51:26 <SamB> how do you speculatively execute?
19:51:27 <dons> but spec eval would be the start
19:51:47 <dons> SamB, start accumulating a log of changes, and only flush them if theeir needed
19:51:52 <dons> hmm. can anyone say STM?
19:51:54 <int-e> SamB: don't know. Everything I can imagine has a huge communication overhead :)
19:51:58 <edwardk> dons: heh
19:52:12 <edwardk> with some sort of checkpoint whenever it would write to the terminal? =)
19:52:16 <int-e> or would require 2^$bignum CPUs :)
19:52:16 <SamB> I suppose you'd need to identify conditional branches from their CMOV and LOADPROG?
19:52:28 <int-e> (yes, big number in the exponent. no I'm not serious)
19:52:43 <dons> int-e, at least it wasn't maxBound
19:52:58 <SamB> > 2^maxBound
19:52:59 <lambdabot>  Add a type signature
19:53:02 <SamB> > 2^maxBound :: Integer
19:53:03 <int-e> dons: that would've fixed the value. maybe maxBound is too small ;)
19:53:03 <lambdabot>  Add a type signature
19:53:12 <SamB> > 2^maxBound :: Int
19:53:13 <lambdabot>  Add a type signature
19:53:17 <SamB> @type (^)
19:53:19 <lambdabot> forall a b. (Integral b, Num a) => a -> b -> a
19:53:22 <SamB> oh
19:53:25 <int-e> > 2^(maxBound::Int) :: Integer
19:53:29 <lambdabot> Terminated
19:53:33 <SamB> hah
19:53:38 <int-e> @botsnack
19:53:38 <lambdabot> :)
19:53:46 <SamB> > 2^(maxBound::Int16)
19:53:48 <lambdabot>  7077305155224773945007765138724758006740653557361940836171928741361833171204...
19:54:10 <int-e> > product [1..10000]
19:54:14 <lambdabot>  2846259680917054518906413212119868890148051401702799230794179994274411340003...
19:54:29 <SamB> it should say how many digits were left out
19:54:33 <int-e> probably the most useful thing I did for Haskell :) (making number output fast)
19:54:36 <dons> its moments like this that i really love lambdabot
19:54:38 <SamB> that is kind of important
19:54:44 <int-e> > length $ show (product [1..10000])
19:54:47 <lambdabot>  35660
19:54:53 <SamB> dons: you listening?
19:55:04 <dons> SamB, I hear you
19:55:06 <dons> good idea
19:55:18 <SamB> > length $ show $ 2^(maxBound::Int16)
19:55:19 <lambdabot>  9864
19:55:25 <dons> right
19:55:36 <int-e> > log 65535 / log 2
19:55:37 <lambdabot>  15.999977986052738
19:55:46 <int-e> stupid.
19:55:54 <int-e> > 65535 * log 2 / log 10
19:55:55 <lambdabot>  19728.000765839006
19:56:03 <SamB> @type log 65535 / log 2
19:56:05 <lambdabot> forall a. (Floating a) => a
19:56:10 <int-e> > 32767 * log 2 / log 10
19:56:12 <lambdabot>  9863.849867921672
19:56:25 <SamB> > log 65535 / log 2 :: Quadruple
19:56:26 <lambdabot>  Not in scope: type constructor or class `Quadruple'
19:56:30 <SamB> > log 65535 / log 2 :: Double
19:56:32 <lambdabot>  15.999977986052738
19:56:40 <SamB> > log 65535 / log 2 :: LongDouble
19:56:41 <lambdabot>  Not in scope: type constructor or class `LongDouble'
19:56:46 <SamB> why not LongDouble?
19:57:35 <SamB> hmm, does @eval compile with evil optimizations or not?
19:57:45 <SamB> such as -fallow-excess-precision?
19:57:51 <SamB> (Which is a GCC flag)
19:58:39 <dons> no
19:58:46 <dons> oh, hang on. maybe..
19:59:00 <dons> no, "-fth"
19:59:02 <dons> is all
19:59:06 <dons> but that's broken
19:59:09 <SamB> why not }->?
19:59:17 <dons> since we want the turn around to be fast
19:59:26 <dons> but perhaps the delay in irc is enough that we could try it
19:59:37 <dons> -fexcess-precision is the flag, iirc
19:59:43 <SamB> that one likely doesn't slow down GCC too much... or are we not using GCC?
19:59:51 <dons> we're not currently
19:59:51 <SamB> oh, am I confused by the GHC -fallow flags?
20:00:02 <dons> do we have allow flags?
20:00:17 <dons> oh, like -fallow-overlapping-instances
20:00:30 <SamB> or -fallow-undecidable-instances
20:00:35 <dons> -fallow-undecidable-instances, -fallow-incoherent-instances
20:00:44 <dons> yeah. that's it though
20:00:51 <SamB> what are incoherent instances?
20:01:00 <dons> ones that don't make sense
20:01:10 <SamB> why would anyone want those?
20:01:19 <dons> you can do some type hackery
20:01:21 <SamB> (and how can GHC tell if they make sense anyway?)
20:01:38 <SamB> (does GHC have sense?)
20:01:42 <dons> check the type extensions page of the ghc manual ? ;)
20:02:00 <SamB> @google ghc docs -fallow-incoherent-instances
20:02:02 <lambdabot> http://haskell.cs.yale.edu/ghc/documentation.html
20:02:02 <lambdabot> Title: The Glasgow Haskell Compiler
20:04:21 * dons compiles with -O2 -optc-O3 -fexcess-precision -funbox-strict-fields -optc-march=pentium4 -optc-ffast-math just in case..
20:06:15 <edwardk> haskell doesn't have any sort of built in interval tree does it?
20:06:30 <dons> now, but there's a 3rd party lib out there
20:06:37 <dons> on haskell.org's libraries page, iirc
20:06:37 * edwardk arches an eyebrow
20:07:05 <dons> under 'data structures'?
20:07:16 <edwardk> ahh. i see the diet impl
20:07:22 <dons> http://web.engr.oregonstate.edu/~erwig/diet/
20:07:22 <lambdabot> Title: Diets for Fat Sets
20:07:28 <dons> ?where+ diet http://web.engr.oregonstate.edu/~erwig/diet/
20:07:28 <lambdabot> Done.
20:08:01 <edwardk> not quite the kind of interval tree i had in mind, but it might work
20:08:05 <edwardk> would be a bit jump heavy
20:08:54 <edwardk> i basically want a 1d R-tree so i can quickly check to see all ranges in a set that contain a given point.
20:09:00 <edwardk> where the set can grow pretty big pretty fast
20:09:09 <edwardk> hrmm
20:09:14 <edwardk> but i guess i can share endpoints
20:09:22 <edwardk> so i can optimize that anyways
20:10:25 <edwardk> basically i'll have a set of intervals of the form [x,y] where if any two intervals overlap then they each share a common y value.
20:11:15 <edwardk> so i suppose i can probably make a pair of data.maps work
20:14:06 <dons> sjanssen: all, http://www.cse.unsw.edu.au/~dons/um.html
20:14:06 <lambdabot> Title: Haskell UM
20:14:19 <edwardk> hrmm
20:14:21 <edwardk> gah.
20:14:45 <edwardk> is there anyway to extract the smallest key larger than a given value from a data.map other than partitioning it and taking the min value of the right half?
20:16:56 <petekaz> @hoogle Int -> IO a -> IO ()
20:16:57 <lambdabot> No matches, try a more general search
20:17:13 <sjanssen> petekaz: replicateM_?
20:17:17 <petekaz> Is there a builtin in function that runs an action 'n' times?
20:17:22 <sjanssen> @hoogle replicateM_
20:17:22 <lambdabot> Control.Monad.replicateM_ :: Monad m => Int -> m a -> m ()
20:17:31 <petekaz> ah .. thanks.
20:17:59 <petekaz> so much for my version, my name was dumb anyways ... myrepeat
20:19:09 * edwardk notes that in haskell, it seems that you asymptotically approach writing no code over time as you learn your way around whats already there. =)
20:19:39 <dons> hehe
20:20:04 <dons> ?remember edwardk notes that in haskell, it seems that you asymptotically approach writing no code over time as you learn your way around whats already there
20:20:04 <lambdabot> Done.
20:21:31 <edwardk> whether thats from analysis-paralysis or actual higher-order thought is another matter entirely =)
20:30:58 <dibblego> is there a de facto convention agreed upon between using spacing layout or explicit parentheses and semi-colons?
20:31:22 <dons> sjanssen: so updated slightly, compared to C, http://www.cse.unsw.edu.au/~dons/um.html
20:31:22 <lambdabot> Title: Haskell UM
20:31:40 <dons> dibblego: use layout :)
20:31:48 <dons> that's the convention
20:31:53 <dibblego> dons, is that a general agreement?
20:31:55 <dibblego> ok
20:32:09 <dons> yeah, no one uses semi colons, except newbies coming from java ;)
20:32:15 <dibblego> righto
20:32:25 <dons> there's the rare case, such as mechanically generated code, where we care
20:32:56 <dons> SamB: got a haskell um somewhere?
20:33:00 <dons> int-e, where's yours?
20:34:35 <monochrom> I use semicolons.  I am not a newbie.
20:34:46 <dons> for all code?
20:35:13 <monochrom> I use both semicolons and layout.
20:35:22 <dons> ah well, so do I.
20:35:29 <dons> but in general, it would be 90% layout
20:35:40 <int-e> http://int-e.home.tlink.de/haskell/um4.hs (um3.hs is much slower. I followed sjanssen's advice and got rid of the Machine struct)
20:35:45 <monochrom> In all code written after a certain time.  I have become fond of the semicolons.
20:36:01 <edwardk> hrmm i wonder what percentage of register reads come from regs that had just been written to by orthography
20:36:02 <int-e> 4 times less allocation, 4 times faster :)
20:36:06 <dons> cheers int-e
20:36:14 <edwardk> coz those could be jitted away entirely
20:36:31 <int-e> and I think it's shortand 41 lines shorter
20:36:33 <edwardk> but then i either need to update the register ANYWAYS, or prove that its never used and the write can be discarded or to it lazily
20:36:34 <monochrom> A reason for my switch is that the semicolons and {}'s help the emacs haskell mode indent.
20:36:50 <edwardk> er or do
20:37:04 <monochrom> Examples: http://www.vex.net/~trebla/annotate-STArray.html
20:37:09 <monochrom> err wrong url
20:37:14 <monochrom> Examples: http://www.vex.net/~trebla/haskell/annotate-STArray.html
20:37:19 <dibblego> monochrom, I am using jedit - I am not a emacs fan
20:37:42 <monochrom> dibblego: I am using emacs - I am not a jedit fan
20:38:18 <monochrom> ha, still wrong url.  Here is the right one: http://www.vex.net/~trebla/haskell/annote-STArray.html
20:38:20 <lambdabot> Title: How to annotate STArray types?
20:38:34 <monochrom> lambdabot is a nice URL debugger.
20:40:23 <dons> heh
20:42:57 <monochrom> I think I should bring this preceding-semicolon convention to my Java code in the future and freak the hell out of Java programmers :)
20:43:01 <dibblego> http://rafb.net/paste/results/HtsEeQ17.html whenever I attempt to rewrite the function f as shown, it fails
20:43:23 <dons> monochrom: heh!
20:43:30 <monochrom> Please put a space between f and x.
20:43:32 <Korollary> need a space
20:43:57 <dibblego> ah
20:44:00 <dons> anyone else got a UM?
20:44:04 <dons> written in Haskell?
20:44:07 <dons> Philippa: your UM?
20:44:17 <dons> @seen vincenz
20:44:17 <lambdabot> I saw vincenz leaving #oasis and #haskell 5 hours, 12 minutes and 4 seconds ago, and .
20:44:25 <monochrom> I am not fluent enough with the layout fine-prints to comment on the layout.
20:45:26 <dibblego> if I write a function f _ = 7 does the underscore stand for numbers only?
20:45:43 <monochrom> Not a priori.
20:46:01 <SamB> dons: you want mine?
20:46:09 <sjanssen> dibblego: underscore matches anything
20:46:14 <hellish> @type f _ = 7
20:46:16 <lambdabot> parse error on input `='
20:46:31 <dons> SamB, yes.
20:46:32 <hellish> @type (\_ -> 7)
20:46:33 <lambdabot> forall t t1. (Num t) => t1 -> t
20:46:34 <dons> updated , http://www.cse.unsw.edu.au/~dons/um.html
20:46:35 <lambdabot> Title: Haskell UM
20:46:40 <dibblego> sjanssen, I declare f _ = 7 then f '5' and it fails
20:46:44 <dons> still the best we have is 4.5x C -- too slow :/
20:46:51 <dons> SamB, I just need a url
20:47:03 <monochrom> That is because of other f equations, dibblego
20:47:10 <dibblego> monochrom, I deleted them
20:47:15 <dons> funnily, sadly, the UM we actually used in competition is still running
20:47:17 <monochrom> > let { f _ = 7 } in f '5'
20:47:18 <lambdabot>  7
20:47:24 <monochrom> works for me
20:47:26 <dibblego> gah, maybe I forgot to :reload
20:47:28 <dibblego> my bad
20:48:01 <SamB> dons: I'm testing the repo before giving the URL, thank you ;-)
20:48:06 <petekaz> Do all FFI calls marked as 'safe' get executed in a separate OS worker thread in the threaded RTS?  I.e. the safety attribute of a FFI call only affects how the call interacts with the threaded RTS?  Or are there other effects as well?
20:48:14 <sjanssen> dons: is there a quicker way to fill an array with zeroes?
20:48:19 <dons> calloc?
20:48:34 <dons> have a look in ByteString, we've got code for that somewhere
20:48:49 <sjanssen> @hoogle calloc
20:48:50 <lambdabot> No matches found
20:48:50 <dons> but you'll need a Ptr, I think
20:48:57 <dons> oh, maybe Foreign.newArray_ ?
20:48:59 <dibblego> so if I have other declarations for f, then does that restrict the types for _?
20:49:01 <sjanssen> yeah, if I was in ByteString I'd use memset
20:49:05 <dons> right
20:49:06 <monochrom> YES!
20:49:15 <dons> maybe you can get into the MutableByteArr# and memset it?
20:49:25 <dons> down inside the array?
20:50:03 <sjanssen> is there a MutableByteArr# -> Ptr a function?
20:50:13 <Korollary> 4.5x is better than I expected
20:50:24 <dons> no, but a MutableByteArr#  is just an Addr#, so you can coerce and then apply Ptr
20:50:29 <dons> _I think_
20:50:43 <dons> there's some code in Yi's FastBuffer.hs that does this, iirc
20:50:55 <dons> Korollary: I think we can do much better
20:51:02 <dons> no one's actually tried a Ptr Word32 design yet
20:51:05 <sjanssen> Korollary: I do some allocation caching tricks that the C code doesn't do
20:51:17 <dons> Korollary: and we average 1.2x C in the shootout, so I'm fairly sure we can get there
20:51:47 <dons> I should try -fliberate-case-threshold, that's supposed to help with array code
20:51:51 <sjanssen> I imagine there is a faster C implementation
20:52:03 <dons> certainly
20:53:49 <SamB> darcs get http://naesten.dyndns.org:8080/repos/um
20:53:56 <edwardk_> dons: i have vincenz implementation here as well
20:53:56 <lambdabot> Title: Directory listing for /repos/um/
20:54:03 <SamB> oh good, got it right
20:54:07 <dons> edwardk_: his haskell one?
20:54:16 <edwardk_> nah, his c++ one
20:54:17 <SamB> dons: that has my C one too
20:54:27 <edwardk_> if you are adding a definitive collection of them =)
20:54:28 <dons> ok.
20:54:32 <dons> yeah, ok.
20:54:33 <dons> url?
20:55:07 <edwardk_> http://slipwave.info/icfp/vincenz-um.cpp
20:55:10 <dons> cheers
20:55:31 <edwardk_> heh
20:55:32 <dons> SamB, missing flag, what is it? undefined reference to `read_scroll'
20:55:44 <edwardk_> half considering using your plugins interface for c to write the jit
20:55:54 <SamB> dons: you need to build readscroll.c and pass in readscroll.o
20:56:02 <dons> ok
20:56:26 <SamB> I wish you could stick that in {-# OPTIONS_GHC #-}
20:56:39 <SamB> (and have it build the .o for you too)
20:57:41 <edwardk_> using ntohl is a pretty good idea
20:58:19 <SamB> it is fortunate that they used big-endian encoding for their 8-bit scrolls ;-)
20:58:24 <edwardk_> heh
20:59:31 <Korollary> Well, the point is that most of the shootout entries also required days and days of fiddling. Time is up for this one.
20:59:48 <edwardk_> kor: ?
20:59:59 <SamB> heh. I didn't get mine working before the contest ended ;-)
21:00:30 <int-e> hah. time to optimize the initialisation a bit
21:00:42 <dons> someone familiar with C++ knows what flags I should use to compile vincenz UM?
21:00:44 <dons> edwardk_: ?
21:01:16 <SamB> dons: what are you asking about?
21:01:16 <edwardk_> -O3
21:01:21 <SamB> oh.
21:01:30 <SamB> -O3 isn't a C++ flag
21:01:35 <SamB> it is a normal flag
21:01:59 <edwardk_> well, thats what he said
21:02:00 <edwardk_> =)
21:02:07 <dons> ok, got it.
21:02:08 <edwardk_> and it makes a pretty big difference for him on gcc4.
21:03:13 <Korollary> specifying arch type and cpu type helps. omit-frame-pointer, etc.
21:03:17 <edwardk_>  -O3 Optimize yet more.  -O3 turns on all optimizations specified by -O2 and also turns on the -finline-functions and
21:03:17 <edwardk_>            -frename-registers options.
21:03:36 <edwardk_> yeah
21:03:46 <edwardk_> i compiled with -fomit-frame-pointer on mine
21:03:53 <Korollary> profile based optimization helps quite a lot sometimes.
21:04:36 <lispy> often -O3 has some negative impact
21:04:55 <edwardk_>  well, in this case it speeds him up by a factor of 4
21:04:56 <edwardk_> =)
21:04:59 <lispy> unless you're really profiling the hell out of your build options it's a good idea to use -O2 at the most
21:05:09 <dons> ok, updated http://www.cse.unsw.edu.au/~dons/um.html
21:05:10 <lambdabot> Title: Haskell UM
21:05:11 <lispy> ah, cool
21:05:37 <dons> SamB, am I right in thinking your um will take quite a while to run the sandmark?
21:05:55 <SamB> well.
21:05:58 <SamB> probably!
21:06:06 <dons> have you run the sandmark?
21:06:16 <dons> ok, it just seems to be going slowly :)
21:06:21 <SamB> on this 450 MHz machine? no.
21:06:26 <dons> ah, right.
21:06:37 <int-e> oops. ghc-6.5: unknown package: fps
21:06:42 <SamB> well, I mean, I started it but killed it in the 90s probably
21:07:53 <lispy> ah, the 90s
21:08:04 <Korollary> lousy decade
21:08:12 <lispy> back when the internet was safe
21:08:17 <dons> now, do we have any other UMS?
21:08:48 <lispy> Korollary: have the 00s been better?  last i checked bush has been our leader the whole time :)
21:09:10 <dons> I think lispy, you should say "our fearless leader"
21:09:21 <dons> it has a better ring to it
21:09:21 <Korollary> the decider
21:09:41 <lispy> that guy that likes pork...
21:09:46 <dons> heh
21:10:30 <int-e> and, due to some ghc hacking, ghc-6.5: not built for interactive use. hehe. no runhaskell.
21:10:34 <SamB> @hoogle unsafeCoerce#
21:10:34 <lambdabot> Hoogle Error: Parse Error: Unexpected character '>'
21:10:35 <SamB> @hoogle unsafeCoerce
21:10:36 <lambdabot> No matches found
21:10:44 <dons> its in GHC.Base, or Prim
21:10:48 <dons> i can never remember which
21:11:18 <lispy> did joelr get his problem fixed?
21:12:05 <lispy> @hoogle foo#
21:12:05 <lambdabot> Hoogle Error: Parse Error: Unexpected character '>'
21:12:16 <lispy> interesting, i never typed '>' ;)
21:12:17 <dons> i might solicit for some UM implementatoins on the haskell-cafe
21:12:31 <dons> ndm: ^^ more weirdness
21:13:18 <lispy> dons: friend of mine didn't want to irc so he tried to build lambdabot on windows and got a bunch of errors.  Is that a know bug?
21:13:42 <lispy> dons: and no...i don't have more details than that :(
21:14:22 <dons> its a known bug that windows and lambdabot aren't friendly, or even sociable
21:14:33 <dons> ndm was looking at it, it seems fixable
21:14:52 <lispy> dons: ah, okay, i'll let my friend know
21:14:57 <dons> but really i need a windows person to sit down and solve it
21:15:00 <edwardk_> hrmm. how does the haskell garbage collector work?
21:15:03 <dons> i can guide, if needed
21:15:10 <Korollary> "My friend..." Hah! Admit it, it was you!!
21:15:13 <lispy> edwardk_: depends on the implementation
21:15:14 <edwardk_> is it safe for me to use my cheesy c trick?
21:15:17 <edwardk_> in ghc
21:15:18 <dons> Korollary: heh
21:15:26 <lispy> Korollary: ssshhh
21:15:29 <edwardk_> (the int->pointer hack)
21:15:44 <SamB> oh, you can do that
21:15:45 <edwardk_> or will it collect on me
21:15:52 <lispy> edwardk_: are you the one that just emaild haskell-cafe about stable ptr?
21:15:57 <edwardk_> nope
21:15:58 <SamB> as long as you make sure the pointer in question is supposed to be a C Ptr
21:16:04 <SamB> or a stable pointer
21:16:11 <SamB> a stable pointer is just an int anyway
21:16:17 <monochrom> friends
21:16:19 <edwardk_> hrmm
21:16:20 <sjanssen> edwardk_: that isn't 64 bit safe though
21:16:24 <SamB> (but you better make sure it isn't 0)
21:16:31 <lispy> just use jhc, last i heard JohnMeacham hadn't implemented the gc yet :)
21:16:32 <SamB> sjanssen: true enough
21:16:36 <SamB> hahaha
21:16:39 <edwardk_> sjanssen: yeah i know, thats ok, i only have a 32 bit cpu =)
21:16:54 <edwardk_> and while i normally code 64-bit clean. i'm having fun
21:16:58 <SamB> edwardk_: and how is that your cheesy C trick?
21:16:59 <lispy> famous last words...
21:17:04 <SamB> my C also uses that trick
21:17:25 <lispy> sit C, sit.  Good C.
21:17:34 <edwardk_> samb: ok, well i don't claim to own 'ancient c coding bad habits' =)
21:17:50 <SamB> that is an ancient habit?
21:17:58 <SamB> is it usually used for VMs?
21:18:12 <swiert> \quit leaving
21:18:18 <swiert> whatever
21:18:23 <SamB> swiert: you've been using too much windows...
21:18:33 <edwardk_> why do you think so much code has problems with porting to 64 bit environments?
21:18:37 <monochrom> haha using too much windows
21:18:40 <Korollary> what's the point of "leaving" anyways.
21:18:50 <SamB> @tell swiert you've been using too much windows... (re: \quit leaving)
21:18:50 <lambdabot> Consider it noted.
21:19:01 <edwardk_> he wants to quit leaving, but can't
21:19:23 <monochrom> /quit leaving #haskell
21:19:55 <edwardk_> you tell him mono! =)
21:20:10 <SamB> heh
21:20:32 <SamB> mine is really bad, huh?
21:20:53 <SamB> dons: are you going to include the C one as well, or are you running on 64-bit?
21:21:01 <dons> SamB, I haven't got passed 100 yet.
21:21:28 <dons> ah, yes, i forgot about that one.
21:21:30 <edwardk_> dons: you should throw um.um on there =)
21:21:36 <SamB> the C one is entirely contained in um.c
21:21:38 <dons> oh that too!
21:21:56 <edwardk_> and um.um um.um, and um.um um.um um.um,...
21:22:05 <dons> also, were any of these used in the competition?
21:22:09 <dons> besides mine and vincenz?
21:22:32 <edwardk_> heh well i registered, but never actually submitted any journals so as to keep my nname off the bottom of the list =)
21:22:44 <dons> heh
21:22:44 * int-e got the codex unpacked with his, then grew impatient and wrote one in C
21:22:46 <SamB> I would have used mine in a half-hearted way if it was done and able to get anwhere in time
21:22:56 <int-e> (the codex took 41 minutes, argl)
21:22:58 <dons> edwardk_: if you need a team next year, just ping me ;)
21:23:05 <edwardk_> dons: will do
21:23:11 <SamB> edwardk_: do you even hit the list if you don't get points?
21:23:14 <SamB> I hope not
21:23:15 <edwardk_> i hadn't actually competed in any of these prioer to this
21:23:16 <edwardk_> samb: nope
21:23:31 <dons> we should try to ensure we group up more #haskell people in future
21:23:41 <edwardk_> and this time i just wanted a break from working on my thesis
21:23:49 <SamB> because it would be lame to have "SamB" at the bottom of the list with no points
21:23:57 <edwardk_> heh
21:24:04 <edwardk_> i chose the name "Eager Bottoms"
21:24:09 <edwardk_> so even if i showed up i'd be safe
21:24:14 <edwardk_> =)
21:24:14 <SamB> I only registered to get the key, really
21:24:17 <edwardk_> yeah
21:24:18 <edwardk_> me too
21:24:26 <edwardk_> coz i'm not sure you can get one now
21:24:27 <int-e> I did that
21:24:29 <SamB> they should let you grab keys now
21:24:39 <int-e> ended up with not quite 2000 points :)
21:24:42 <SamB> post a keygen or something
21:24:53 <int-e> (and I started on Sunday)
21:25:03 <dons> cool int-e!
21:25:31 <edwardk_> int-e: i basically took about an hour, got a working vm, decoded the codex, logged in, and hacked out the qvickbasic thing and got back to work on real-world stuff
21:25:35 <int-e> (well, it was still saturday in EDT)
21:25:35 <SamB> I was away too much on saturday and sunday, I think.
21:25:52 <SamB> also I am not that fast
21:26:02 <int-e> aaaargh, it still does it
21:26:07 <int-e> LOADING: 9876543210
21:26:07 <int-e> Stack space overflow: current size 8388608 bytes.
21:26:07 <int-e> Use `+RTS -Ksize' to increase it.
21:26:14 <monochrom> hahaha
21:26:22 <edwardk_> int-e: ouch
21:26:34 <lispy> yeah, i went rafting (which killed my whole saturday) then slept in on sunday...so i would have only had a few hours had i actually worked on it
21:26:39 <int-e> edwardk_: ironically this is quite fast now
21:27:21 <lispy> my body is still tired from the rafting :)
21:27:59 <int-e> but I'd still like to know why it does that :(
21:28:22 <dons> SamB, so your C version was the one you used in the contest?
21:28:35 <SamB> dons: I did not get either of them working in time
21:28:39 <dons> ah, ok
21:28:49 <dons> now, how do i use this um.um
21:28:49 <hellish> What performance problems is (
21:28:49 <hellish> http://haskell.org/haskellwiki/Performance/Arrays) talking about w.r.t. Data.Array.Diff? I'm still tracking that space leak.
21:28:51 <lambdabot> Title: Performance/Arrays - HaskellWiki
21:29:07 <SamB> but obviously I wasn't going to let that stop me from having a crack at the problems
21:29:12 <int-e> Data.Array.Diff is a compromise
21:29:14 <dons> hellish: oh, did you have a haskell UM?
21:29:42 <hellish> dons: I have one with a magnificant space leak. I might have one capable of running UMIX in the next few days...
21:29:45 <int-e> it's slow if you want mutable arrays, it's fast if you want arrays you modify occasionally with only one copy in use at a time
21:30:12 <dons> hellish: ok. cool
21:30:16 <SamB> it is probably good enough if you are just implementing Z-machine
21:31:06 <SamB> (though perhaps I ought to try plain-old UArrays instead?
21:31:16 <hellish> It looks like it's retaining the [(idx,value)] pairs used in (//) longer than it should.
21:31:38 <SamB> well... do you hold onto old copies?
21:31:43 <dons> ok, now I run um on um
21:31:44 <SamB> it probably sticks them in those
21:31:50 <hellish> SamB: hopefully not.
21:32:48 <SamB> can you do a retainers profile?
21:33:05 <hellish> SamB: somewhere.
21:33:09 <SamB> or maybe check the MVar count?
21:33:10 <int-e> 2m10 for decoding the codex 4x slower than C
21:33:11 <Korollary> Damn. Coffee tables must have been invented to accumulate junk.
21:33:16 <int-e> that's decent
21:33:21 <dons> Korollary: I agree!
21:33:24 * dons looks at his coffee table
21:33:49 <SamB> I haven't got one
21:34:07 <SamB> the junk still accumulates though...
21:34:07 <int-e> dons: http://int-e.home.tlink.de/haskell/um4.hs uses Data.ByteString for loading now
21:34:28 <int-e> and there's still a stack space leak apparently
21:34:36 <dons> int-e, ok. trying
21:36:31 <int-e> dons: mind the march flag
21:36:47 <dons> i'm using -optc-march=pentium4, is that ok?
21:36:53 <int-e> ok
21:37:16 <int-e> I have an -optc-march=athlon-xp in the hs file, but you're overriding that then :)
21:37:31 <int-e> which is what you should be doing
21:37:35 <dons> int-e, well its faster than um.um running on edwardk
21:41:09 <edwardk_> heh well i think everything is =)
21:41:17 <edwardk_> that one took me almost an hour =/
21:41:38 <int-e> uh, then my initial haskell UM was way slower than that
21:42:11 <int-e> extrapolating that would run sandmark in 2 hours, maybe.
21:42:49 <dons> int-e, the updated um4 was no faster than the earlier one
21:42:56 <dons> is that right?
21:43:13 <int-e> probably a second or two. :)
21:43:26 <dons> yeah, i got 1s slower
21:44:00 <int-e> the optimization was for logging in faster (read the input faster), not for running faster.
21:44:11 <dons> yep
21:44:13 <int-e> it did that quite well.
21:44:44 <dons> SamB, updated to add your C one, http://www.cse.unsw.edu.au/~dons/um.html
21:44:45 <lambdabot> Title: Haskell UM
21:46:39 <int-e> oh. the loading thing has a countdown.
21:48:21 <edwardk_> samb: i'd guess your speed loss would come from looping over the function call
21:48:36 <edwardk_> rather than doing a while
21:51:23 <dons> int-e, I wonder if stepping inside the IO constructor would help..
22:16:49 <tessier__> Are most haskell implementations self-hosting?
22:16:53 <tessier__> Or are they C underneath still?
22:17:24 <dons> underneath?
22:17:46 <dons> the tool chain is written all in haskell, in all the compilers, i think
22:18:03 <dons> hugs is written in C, but its an exception. also, its an interpreter
22:18:31 <tessier__> Interesting.
22:18:34 <tessier__> That's pretty cool.
22:18:50 <dons> it would be kind of insane to not use haskell to write a haskell compiler
22:19:07 <dons> i just don't want to think about pattern matching on an AST without pattern matching ;)
22:19:16 <tessier__> But someone had to write the first haskell compiler in something other than haskell...
22:19:29 <dons> yep. sure. a long time ago
22:20:08 <dons> and on new architectures, you just take the partially compiled haskell source for your compile, to the new machine, and then finish the compile there with gcc
22:20:21 <dons> so bootstrapping itself only uses gcc right at the end
22:20:31 <tessier__> Partially compiled? So it compiles to C or something?
22:20:36 <dons> right
22:20:48 <dons> you compile your ghc, and dump out the backend as C
22:20:49 <tessier__> Why compile to C?
22:21:02 <dons> those files can then be moved to a new machine, and compiled with gcc
22:21:08 <dons> giving you a functional ghc
22:21:11 <dons> and away you go
22:21:13 <tessier__> Is that how it normally works even when you are not cross compiling?
22:21:18 <dons> why C? its a good portable target
22:21:32 <dons> no, you can also just generate asm directly out the back end
22:21:40 <tessier__> Ah, I see.
22:21:59 <tessier__> But don't you at some point have to write code to generate asm directly for your haskell compiler?
22:22:17 <dons> why/
22:22:25 <dons> the fact that we do, isn't important to bootstrapping
22:22:29 <Pseudonym> You don't _have_ to.
22:22:51 <Pseudonym> No more than a C compiler has to generate machine code, when there are perfectly good assemblers.
22:22:51 <dons> you could always just translate to C, and then finish the compile with gcc. that works fine
22:23:10 <dons> exactly. its an identical situation to bootstrapping C on a new machine
22:23:27 <dons> to compile gcc you umm need a gcc. oh no! fix point!
22:24:17 <dons> there's a really great bug message we got on the ghc mailing list once, from a guy whose brain-stack overflowed trying to work out the recursion involved in bootstrapping a haskell compiler
22:24:45 <tessier__> I know the feeling
22:25:00 <dons> recursion comes naturally to fp hackers though :)
22:25:13 <tessier__> It takes some time to become an fp hacker. :)
22:25:30 <dons> ?google haskell ghc "fully nerd" bootstrap
22:25:33 <lambdabot> http://www.haskell.org/pipermail/glasgow-haskell-bugs/2006-March/006286.html
22:25:33 <lambdabot> Title: ghc needing ghc is the biggest bug in ghc
22:25:34 <tessier__> I read "The Little Schemer" and I understand the basics of cdr'ing down a list using recursion. Still a lot more to learn. :)
22:25:41 <dons> ah ha, that's the mail
22:26:04 * tessier__ is fully nerd
22:26:19 <dons> that's the original,
22:26:21 <dons> http://www.haskell.org/pipermail/glasgow-haskell-bugs/2006-March/006285.html
22:26:22 <lambdabot> Title: ghc needing ghc is the biggest bug in ghc
22:26:35 <dons> and a response, http://www.haskell.org/pipermail/glasgow-haskell-bugs/2006-March/006294.html :)
22:26:36 <lambdabot> Title: ghc needing ghc is the biggest bug in ghc
22:28:31 <zarvok> dons: priceless
22:28:34 <zarvok> I can't stop laughing
22:28:51 <dons> its like you can really see the guy's brain melting
22:28:53 <sjanssen> I can't believe that this is real
22:29:10 <dons> zarvok: fyi, http://www.cse.unsw.edu.au/~dons/um.html
22:29:11 <lambdabot> Title: Haskell UM
22:29:33 <dons> we're seeing if we can get a decent one written. lots of ideas to improve yet.
22:29:39 <zarvok> @quote dons  its like you can really see the guy's brain melting
22:29:40 <lambdabot> dons  its like you can really see the guy's brain melting hasn't said anything memorable
22:29:51 <dons> heh
22:29:51 <zarvok> @remember dons  its like you can really see the guy's brain melting
22:29:52 <lambdabot> Done.
22:29:56 <zarvok> heh, got it wrong
22:30:01 <zarvok> dons: thanks
22:30:04 <zarvok> will check it out tomorrow
22:30:30 <dons> just a table of competing times for the sandmark
22:30:35 <dons> for the various haskell ums
22:30:35 <tessier__> What is an AST?
22:30:44 <int-e> ah. size 0 arrays. I forgot.
22:30:48 <zarvok> abstract syntax tree
22:30:52 <tessier__> When you say "pattern matching" do you mean like regex is pattern matching?
22:31:07 <dons> no, like 'case Plus x y of x + y' :)
22:31:13 <Pseudonym> Incidentally, you may now ponder the question of how GHC was written.
22:31:21 <zarvok> heh
22:31:23 * Pseudonym happens to know the answer to this one
22:31:35 <tessier__> ah, that AST
22:31:54 <tessier__> Pseudonym: Fairy dust purchased from IBM?
22:31:58 <int-e> [0..sz-1] on unsigned types wasn't so clever.
22:32:07 <Pseudonym> Nope, IBM wasn't selling fairy dust at the time.
22:32:10 <sjanssen> tessier_: actually, time travel was involved
22:32:15 <dons> heh
22:33:09 <Pseudonym> Haskell was an attempt to consolidate research in lazy FPs.
22:33:18 <Pseudonym> That is, it was based on a bunch of existing languages.
22:33:22 <Pseudonym> So it was bootstrapped from one of them.
22:33:38 <tessier__> Far out, man.
22:33:49 <Pseudonym> That's a common approach.
22:34:02 <dibblego> Pseudonym, all IBM sells is fairy dust
22:34:08 <dons> so we're vulnerable to the "all haskell compilers get deleted by accident" exploit?
22:34:13 <dons> leaving us without a language
22:34:13 <Pseudonym> Actually, one common approach is to write a parser first, then translate Haskell into another language with a similar typesystem.
22:34:22 <zarvok> hahaha
22:34:29 <Pseudonym> dons: Well, yes.  But that's true of C too.
22:34:39 <tessier__> I understand compiling to C and movign that C to another machine and compiling with gcc over there...but where does the final haskell learn how to generate asm code for this new system? Does it somehow inherit that knowledge by virtue of the fact that it was compiled with GCC on that new system?
22:34:49 <sjanssen> perhaps we should all memorize a bit of the GHC source code, like Fahrenheit 451
22:34:57 <Pseudonym> Good idea!
22:35:03 <Pseudonym> I'll memorise the evil mangler.
22:35:07 <zarvok> dibs on the parser
22:35:27 <dons> doh, i get stuck with either the type system or the code gen :/
22:35:29 <Pseudonym> Oh!  I want to memorise the bit that prints "the impossible just happened".
22:35:33 <dibblego> with pretty glossy brochures containing an assortment of euphemisms attached of course
22:35:40 <zarvok> heh
22:35:43 <dons> ?ghc
22:35:43 <lambdabot>  GHC internal error
22:35:46 <dons> that one!
22:36:13 <Pseudonym> I would offer to memorise "my brain just exploded", but that doesn't sound safe to memories.
22:36:15 <dibblego> everything oughtta be a referentially transparent function - including databases
22:36:16 <Pseudonym> memorise
22:36:41 <dons> dibblego: ah, you should join the cult of the bound variable.
22:36:54 <dibblego> I have long believed that
22:37:02 <dibblego> I am pleased to hear other share my belief
22:37:02 <dibblego> s
22:37:03 * tessier__ will memorize the README
22:45:35 * edwardk_ kicks his network provideer, and waits patiently for them to figure out the routing problem between him and half the internet.
22:46:03 <edwardk_> The JIT is coming along, slowly but surely
22:46:24 <tessier__> So when can we expect an OS in haskell? :)
22:46:31 <edwardk_> tess: there is one
22:46:32 <newsham> you meanse House?
22:46:45 <edwardk_> http://www.cse.ogi.edu/~hallgren/House/
22:46:47 <lambdabot> Title: House
22:47:24 <tessier__> Wow, that's sweet!
22:47:49 <tessier__> Does it turn out to be very stable by virtue of being written in haskell>
22:47:50 <tessier__> ?
22:48:02 <edwardk_> haven't tried it
22:48:08 <dons> that's the idea.
22:48:20 <dons> its used for high-assurance embedded systems
22:48:31 <tessier__> I mean, obviously it is very young wouldn't have many features but I would expect anything written in haskell to be able to avoid segfaults and buffer overflows etc. typical of C code.
22:48:37 <newsham> its probably fairly stable by virtue of not doing a whole lot :)
22:48:41 <dons> there's also an L4 kernel written in Haskell, able to be checked via isabelle
22:48:41 <edwardk_> heh
22:49:03 <edwardk_> that is pretty cool. i'd like to take a peek did a lot of work with l4ka
22:49:05 <dibblego> what's isabelle?
22:49:12 <dons> newsham: the talk about House was presented using slides running on a thinkpad running house :)
22:49:20 <edwardk_> proof system
22:49:20 <tessier__> newsham: I am sure you are well aware of how even a tiny bit of C code which doesn't do much can crash easily. :)
22:49:31 <dons> dibblego: a theorem prover. so they could mechanically verify the kernel
22:49:42 <newsham> thats pretty typical.  the microsoft .net research kernel group did the same thing with their OS
22:49:45 <tessier__> Linspire using Haskell really impressed me. I had lunch with those guys a couple months ago.
22:49:47 <newsham> compiling the slides into the kernel
22:50:05 <newsham> you can get the House floppy and boot it in vmware
22:50:31 <dibblego> newsham, what OS do you tell vmware to use?
22:50:43 <edwardk_> my problem with most toy os projects is they never get around to building themselves a filesystem. thats usually the point at which joe-on-the-street is willing to play with your OS and bring it up to critical mass.
22:50:55 <newsham> Other?  I dont think those OS settings matter for much other than tips for installing vmware tools
22:51:11 <dibblego> newsham, I wasn't sure what they do, but you're probably right
22:51:16 <newsham> edward: most toy os's arent really concerned with joe on the street :)
22:51:25 <edwardk_> well, they used to use them for various boot hacks, because there is some issues with the jump from 16 to 32 bit
22:52:30 <edwardk_> heh, well, what i mean by that is trying to get someone to actually extend and develop on it. house will probably die because no one cares. add a file system, and the ability to compile haskell IN it, and i'd probably spend more than 2 minutes going 'oh, look another toy os' =)
22:53:25 <dibblego> I'm not sure that noone will care if it can prove to have gained the benefits of Haskell
22:55:54 <tessier__> Haskell needs a killer app IMHO
22:56:40 <dons> please write us one, tessier__ :) since apparently the world is happy to put up with verbosity and bugs forever
22:56:44 <tessier__> Python has zope, bittorrent, Anaconda, various things that boost python. Ruby has Rails. Lisp has emacs and a very long history of other things...
22:56:55 <tessier__> dons: Verbosity and bugs forever?
22:56:56 <dons> well, there's pugs and darcs
22:57:09 <tessier__> pugs is perl6 in haskell right? Did I read that right?
22:57:15 <edwardk_> the closest thing we have is, yeah... pugs and darcs =)
22:57:17 <dons> tessier__: since just having a better language isn't enough to make people switch, is the implication.
22:57:30 <dons> hence the need for a killer ap.
22:57:40 <tessier__> dons: Right. And just having a better language isn't enough. You are right, if that is what you are saying.
22:57:40 <lambdabot> Don't I count? Hmm?
22:57:51 <lambdabot> I've never actually killed anybody. Yet.
22:57:54 <dibblego> "the world is happy to put up with verbosity and bugs forever" -- I agree, except for the forever part
22:57:55 <dons> i.e. the arguments about productivity, bugs and verbosity aren't enough
22:57:56 <edwardk_> oh, and a cool bot
22:58:05 <tessier__> lambdabot: No offense but bots are even more trivial and worthless than toy OS's. :)
22:58:19 <edwardk_> @slap tessier__
22:58:19 <lambdabot> why on earth would I slap tessier__
22:58:22 <lambdabot> I resemble that remark.
22:58:22 <edwardk_> aww
22:58:24 <dibblego> the demand from industry is increasing, even if ever so slowly
22:58:28 <edwardk_> lambdabot doesn't like me =)
22:58:29 * tessier__ wonders what a good filesystem for House would look like
22:58:36 <edwardk_> heh
22:58:37 <dibblego> if Haskell had a migration path of the existing filth, it might move faster
22:58:39 <dibblego> *off
22:58:44 <dons> tessier__: we have one. its called Halfs
22:58:46 <edwardk_> zipperFS or whatever that oleg wrote sounds like a good start =)
22:58:46 <dons> ?where halfs
22:58:47 <lambdabot> http://www.haskell.org/halfs
22:59:12 <tessier__> I liked Erlang's approach to reliability but haskell seems more modern and has a lot more popular support. Anything like Erlang's threading model for haskell?
22:59:34 <dons> threads in haskell tend to be around the same, or better than erlang
22:59:42 <dons> at least from the language benchmarks
22:59:53 <int-e> dons: another thing to try, http://int-e.home.tlink.de/haskell/um5.hs
22:59:55 <Pseudonym> Haskell doesn't exactly have a Linda-like IPC mechanism, though.
22:59:59 <dons> concurrency has been a strong aspect of haskell since the early days
23:00:02 <Pseudonym> If that's what you really want.
23:01:01 <Pseudonym> Concurrent.Chan doesn't _quite_ work.
23:01:19 <tessier__> I don't know what Linda-like is. But I have always expected a purely functional language to be good at concurrency due to lack of side effects complicating things.
23:01:20 <Pseudonym> To be Linda-like, you'd have to pull out the first element from the channel that matches some pattern.
23:01:21 <dons> int-e, um5.hs:95:10: The last statement in a 'do' construct must be an expression
23:01:42 <int-e> woops
23:01:49 <dons> Pseudonym: is that a filter?
23:02:27 <int-e> code cleanup mistake. fixing.
23:03:07 <int-e> should work now
23:04:07 <dons> nope, still um5.hs:95:10: The last statement in a 'do' construct must be an expression
23:04:34 <Pseudonym> Kind of.
23:04:42 <Pseudonym> It's known as "tuple space".
23:04:59 <Pseudonym> Basically, transmitters dump tuples onto a shared space, and receivers pick up any that look interesting.
23:05:03 <int-e> dons: download again?
23:05:20 <Pseudonym> The Erlang model was partly based on Linda.
23:06:00 <tessier__> Pseudonym: That is basically message passing right?
23:06:07 <Pseudonym> Yeah, more or less.
23:06:10 <Pseudonym> It's one form of it.
23:06:28 <dons> int-e no?
23:06:39 <dons> still fails
23:06:42 <tessier__> I see. No need to synchronize. Nice.
23:06:53 <int-e> dons: using wget and got a um5.hs.1 file?
23:07:01 <dons> there's a return missing there
23:07:06 <dons> oh, could be the proxy...
23:07:20 <Pseudonym> It also fits nicely with the "pool of workers" style of coding.
23:07:22 <llama32> GHC seems to have a module imitating/wrapping dlopen and such... can this be used to open compiled haskell programs - does this cause havock with the garbage collector, or is it hard to find symbols or anything?
23:07:31 <Pseudonym> You add CPUs, put listeners on them, and everything (in theory) scales.
23:07:43 <dons> HTTP request sent, awaiting response... 403 Forbidden ?
23:07:45 <Pseudonym> (In practice, of course, the tuplespace itself may be the bottleneck.)
23:08:04 <Pseudonym> Erlang is particularly nice about this.  Threads don't even share a heap.
23:08:14 <Pseudonym> They communicate only by tuples, which actually _copies_ data between threads.
23:08:23 <Pseudonym> So threads can garbage collect separately.
23:08:25 <tessier__> Isn't all that copying inefficient?
23:08:39 <tessier__> I guess not if it isn't much data.
23:08:47 <Pseudonym> It buys you responsiveness.
23:09:09 <int-e> dons: not my fault. it's my ISP's server. try http://fuchur.t-link.de/~bf3/um5.hs (temporary link)
23:09:29 <dons> 16:09:01 ERROR 403: Forbidden :/
23:09:44 <int-e> funny.
23:09:49 <Pseudonym> Once again, this just shows that there's no one metric for "efficient".
23:10:04 <dons> hmm :/
23:10:17 <dons> oh. my fault
23:10:23 <dons> wrong flag to wget
23:10:32 <Pseudonym> You lose a little bit of performance in copying, but you gain the fact that you can transparently migrate threads across CPUs _and_ garbage collect them independently.
23:10:36 <int-e>  echo 'GET /~bf3/um5.hs' | nc fuchur.t-link.de 80 > um5.hs ;-)
23:10:47 <Pseudonym> Which is actually more important in a real-time environment.
23:10:52 <tessier__> So does anyone actually mathematically prove the correctness of haskell programs?
23:11:02 <Pseudonym> Sure.
23:11:06 <dons> --cache=off not --proxy=off
23:11:08 <Pseudonym> Read any "functional pearl" article.
23:11:22 <Pseudonym> It's more common to mathematically derive programs than prove them, though.
23:11:26 <dons> got it, int-e
23:11:43 <Pseudonym> It's also more common to prove properties of programs.
23:13:01 <tessier__> Due to the purely functional nature you should also (at least theoretically) be able to change code on the fly with haskell like you can with erlang right? No downtime?
23:13:14 <dons> lambdabot does this
23:13:25 <dons> there's a paper on it.
23:13:48 <tessier__> Wow. Which haskell implementation does lambdabot use?
23:13:51 <dons> ghc
23:15:01 <edwardk_> dons is sneaky and lambdabot kinda brings itself up from its bootstraps with this arcane plugin architecture
23:15:10 <edwardk_> its a neat idea, so i'm ripping it off =)
23:15:23 <dons> arcane, eh?
23:15:36 <tessier__> Very impressive.
23:15:36 <edwardk_> yep
23:15:37 <dons> you start with the dynamic loader, and go from there
23:15:45 <edwardk_> actually its not so bad
23:15:48 <int-e> dons: did you ever run into problem with coexisting tls/non-tls glibcs?
23:15:58 <dons> i don't use glibc
23:16:04 <dons> bsd ;)
23:16:17 <mwc> tls = transport level security (SSL successor)
23:16:18 <mwc> ?\
23:16:19 <lambdabot> Maybe you meant: . v
23:16:22 <dons> so as such, no, i've never had a problem.
23:16:30 <int-e> mwc: tls = thread local storage
23:16:36 <edwardk_> just kinda wish the c interface could readily grab haskell functions and pass them values rather than just eval strings
23:17:01 <dons> edwardk_: oh, that's just the normal ffi mechanism, isn't it?
23:17:04 <dons> foreign export?
23:17:10 <Pete_I> is there a built in function for converting numbers to hexidecimal/octal/whatever?
23:17:11 <int-e> I need an LD_PRELOAD for lambdabot to work ... I'd like to know why but maybe I'll find that out myself.
23:17:12 <dons> its fancier to do an eval
23:17:13 <edwardk_> hrmm.
23:17:23 <mwc> int-e, ah, I've never seen that acronymed before
23:17:30 <edwardk_> haven't played with foreign export yet
23:17:31 <dons> > printf "%x\n" (255::Int)
23:17:32 <lambdabot>  Add a type signature
23:17:44 <dons> > printf "%x\n" (255::Int) :: String
23:17:45 <Pete_I> ah, printf. thanks.
23:17:45 <lambdabot>  "ff\n"
23:17:51 <dons> > printf "0x%x\n" (255::Int) :: String
23:17:52 <lambdabot>  "0xff\n"
23:18:14 <edwardk_> dons: what i mean is to call the haskell code from the c side.
23:18:17 * tessier__ wonders when we will see Learning Haskell from O'Reilly
23:18:28 <int-e> mwc: I think the official acronym is nptl
23:18:35 <Korollary> probably never
23:18:45 <int-e> mwc: or even nptl/tls. I don't really know.
23:18:46 <edwardk_> mostsly because i was about 10 minutes away slapping together a franken-jit using perl5 to call c to call haskell to compile the jit fragments =)
23:18:46 <dons> edwardk_: right, foreign export
23:19:02 <edwardk_> coz i prototype quickly in perl
23:19:10 <int-e> sandmark in under 10 mintes, yay.
23:19:15 <edwardk_> nice int-e
23:19:35 <dons> edwardk_: hs_init(&argc, &argv); p = hs_some_function(i); hs_exit();
23:19:49 <dons> where hs_some_function is foreign exported
23:19:57 <edwardk_> ah neat =)
23:20:08 <dons> int-e, i think this new um5 is slower/
23:20:09 <dons> ?
23:20:19 <int-e> dons: it's faster here.
23:20:43 <dons> seems about two times slower here. hmm
23:20:46 <dons> let me try again
23:21:19 <dons> any special flags?
23:21:22 <int-e> using ghc 6.5 here. I wonder if that makes a difference
23:21:30 <dons> i'll try
23:21:33 <int-e> -package fps and what's at the top of the file
23:22:34 <dons> ok, maybe its running faster now.
23:22:38 <dons> i must have missed something
23:22:44 <dons> or 6.5 really does matter
23:23:46 <int-e> let me install bytestring for my 6.4.2 :)
23:28:32 <int-e> it's definitely slower with 6.4.2.
23:30:39 <int-e> by a factor of 2.4 or so.
23:32:17 <int-e> 2.2. but that's impressive enough.
23:33:05 <dons> yep
23:33:14 <dons> its faster under 6.5, for sure
23:33:37 <dons> but still came in a tad slower than the first version
23:33:43 <dons> 405 vs 426s
23:34:04 <dons> how much faster do you expect it to be?
23:34:47 <int-e> hmm. here it's 130s vs. 110s for the thing that I measure (unpacking the codex)
23:35:05 <dons> ok, its possible the sandmark does different things
23:36:02 <int-e> true.
23:36:08 <lispy> hmm...
23:36:15 <lispy> why are the haskell versions so slow?
23:36:18 <lispy> any theories?
23:36:47 <lispy> the arrays?
23:36:48 <int-e> bad flow control for switch and loop (and IO, too, to some extend)
23:37:02 <dons> arrays, mutable everything
23:37:11 <dons> i think we can do ok with Ptr versions, though
23:37:27 <tessier__> Is haskell a suitable language scripting/RAD language for replacing perl/python for sysadmin tasks?
23:37:34 <int-e> look at that um5.hs - it tries to do it with foreignptrs
23:37:43 <tessier__> one two many uses of the word language in there
23:37:54 <dons> tessier__: Linspire uses haskell for its system scripts
23:38:27 <dons> anything more than 10 lines I switch from sh to haskell, since its faster and safer
23:39:32 <lispy> would be nice if there was an efficient and idomatic haskell way
23:39:42 <lispy> seeing all the seqs makes me sad
23:39:49 <lispy> lot of extra work
23:40:08 <int-e> seqs are barely ok ... stepping inside IO is defeating the purpose in my opinion
23:40:18 <int-e> unless you're a library writer :)
23:40:58 <dons> yes.
23:41:20 <int-e> (stepping inside IO meaning to treat IO as ... what's it, IO# (RealWord# -> (RealWord#, result))? or just IO?
23:41:45 <int-e> bang patterns look nice, too
23:41:54 <dons> IO $ \s -> ....
23:42:01 <int-e> ok
23:42:04 <dons> you can use strict primops .. ;)
23:42:13 <dons> which is bad for your health
23:42:17 <int-e> yes, at the cost of unreadable code
23:42:22 <hellish> What do RULES pragmas (pragmae?) do?
23:42:40 <dons> they let you perform arbitrary transformations of your code
23:42:50 <dons> i.e. user-defined optimisations, based on term rewriting
23:42:58 <hellish> dons: Documentation?
23:43:05 <int-e> ghc manual
23:43:07 <dons> there's a paper, and a website
23:44:37 * hellish examines the manual.
23:46:30 <tessier__> Do most haskell coders use emacs?
23:48:28 <Cale> emacs and vim are rather popular
23:48:29 <dons> its about half and half with vim, I think
23:48:38 <int-e> dons: some fps unstable patches are not world-readable, is that intentional?
23:48:38 <dons> Cale, did you write a UM ?
23:48:44 <dons> hmm no.
23:49:09 <int-e> (the three most recent ones I think)
23:49:11 <dons> but be warned that it is _really_ unstable and not for human consumption
23:49:18 <int-e> I know
23:49:25 <dons> there's no real reason to use it, unless you're writing a paper
23:49:26 <int-e> I'm merely curious :)
23:50:00 <dons> :) ok. fixed, I think
23:50:37 <int-e> looks better now, thanks
23:50:42 <Cale> what's unfit for human consumption?
23:51:18 <dons> the unstable branch of fps. we provide no guarntees that anything works
23:51:29 <int-e> a new fusion idea dons and dcoutts, I think, are working on.
23:52:09 <dons> yep
23:52:16 <Cale> ah, that looks really cool, btw
23:52:28 <Cale> I hope it goes into 6.6
23:55:05 <cybercobra> could someone recommend a book on haskell for the experienced (non-functional) programmer?
23:55:25 <tessier__> cybercobra: I just ordered one....
23:55:43 <tessier__>  "Haskell: The Craft of Functional Programming (2nd Edition)"
23:55:49 <tessier__> I hear it's good.
23:56:23 <tessier__> Books are so damn expensive. I have spent thousands by now at amazon I bet
23:56:55 <cybercobra> yes, the cost doth suck, but having something tangible is just so damn useful
23:56:56 <lispy> i wonder if a haskell UM implementation could do memoizing, caching or pipe lining to get better performance
23:57:11 <cybercobra> tessier__: thanks!
23:57:26 <tessier__> I had never heard of memoizing before a couple of days ago and now it's everywhere. That happens so often to me. Weird.
23:58:06 <int-e> dons: btw I know where the xTransformerBi1 name comes from, but it's completely unenlightening for me: the desugar pass rewrites top-level bindings as xxx = xxx_internal; xxx_internal = the code for xxx here (xxx_internal being one of these strange internal ids, like xxx_ak2p).  In the end, the unexported symbol xxx got optimized away and the compiler choose a new name for xxx_internal. If xxx is still referenced at that point (by one of the R
23:58:06 <int-e> ULES, I think), that name is xxx1.
23:58:09 <dons> lispy, yes, I wonder about pipelining
23:58:38 <dons> ah, thanks int-e
23:59:14 <lispy> seems like a little non-determinism ala Monad [] could go a long ways...
23:59:19 <int-e> dons: it gives me no idea at all how this should be fixed so rules for unexported symbols will work. interestingly, the right hand sides of the rules are rewritten to use the internal symbol.
23:59:47 <lispy> well, that and a good array library
