00:00:05 <dons> lispy: yeah. embrace, extend^h^h^hcripple, ....
00:00:50 <lispy> dons: it makes me wonder if the quote about dragging the C programmers half way to lisp is actually true
00:01:03 <lispy> dons: iirc, gossling said that as a goal of java
00:01:25 <lispy> dons: as sort of, "well, if you can't beat 'em, get 'em to join ya"
00:03:03 <dons> yeah
00:03:13 <dons> so everyone used java instead of smalltalk
00:03:26 <dons> will everyone in the future be using some non-fp lang as if it was fp
00:03:46 * dons holds out for multicore machines making imperative, mutable-by-default infeasible..
00:04:28 <greentea> dons: But unlike Java, Smalltalk didn't have an industry heavyweight pushing it hard, did it?
00:04:47 <dons> right. so that's what i'm wondering about haskell..
00:04:51 <lispy> greentea: how do you feel about xerox? actualy, i don't know if they even tried to push it
00:05:06 <dons> ispy?
00:06:14 <greentea> lispy: Well, that's what i'm wondering: did Xerox push Smalltalk in the same way that i've seen Sun push Java?
00:06:19 <lispy> didn't smalltalk come out of xerox parc?
00:06:35 <greentea> i mean, when Java first came out, Sun was talking as though they invented the concept of the VM.
00:06:39 <Excedrin> xerox is great at marketing... copiers
00:06:42 <lispy> greentea: well, alan kay push it quite a bit in magazines and such and there was a lot of research around it
00:07:28 <kfish> xerox invented PCs, LANs and OO -- and made a management decision not to go into that business as it wasn't copiers
00:08:02 <kfish> and steve jobs paid $1million for a tour of xerox in the early 80s, to check out their windowing system invention
00:08:13 <greentea> lispy: *nod* But did Xerox say "Hey, CIOs, here's a way of reducing development time across heterogenous networks - use Smalltalk"?
00:08:33 <dons> ?seen xerox
00:08:33 <lambdabot> xerox is in #haskell-overflow and #haskell. I last heard xerox speak 10h 18m 34s ago.
00:08:49 <greentea> Heh.
00:09:49 <newsham> dons: people have been writing multithreaded code in imperative languages for quite a while
00:10:07 <newsham> i dont think multi-core is going to kill imperative programming
00:10:11 <lispy> newsham: and it's considered expensive and hard, right?
00:10:31 <newsham> yes, no doubt.
00:10:34 <dons> newsham: i know :) they'll just be doing it in a fp-style
00:10:49 <lispy> foozles are great
00:10:53 <newsham> no arguments from me about FP making parallel coding simpler
00:10:54 <dons> less mutable state, more pure functions
00:11:01 <dons> it'll probably be called some new design pattern
00:11:07 <dons> or an agile method
00:11:23 <lispy> dons: haskell will have its chance to be bitter like the lisp community when the ignore our research and do a shoddy job of something else which is basically what we're using now
00:11:34 <lispy> :)
00:11:40 <dons> don't scare me
00:12:07 <dons> as long as all the new PL rsrch is happening in haskell, things are good
00:12:13 <newsham> unlike lisp 30 yrs ago, we've got lots of spare cpu cycles these days
00:12:16 <dons> since that's a steady stream of cutting edge features appearing
00:12:17 <greentea> Heh, my gut feeling is that Haskell isn't going to end up in that place. :-)
00:12:46 <newsham> and a lot more of those little cores that you need for your heap
00:13:33 <kfish> if the people in this channel write code that changes the world, haskell will have a place
00:13:39 <newsham> in a decade your cell phone will have enough storage to store video of your entire life, and spare cpu cycles to boot
00:14:31 <lispy> kfish: interesting
00:14:58 <lispy> alan kay has been reported to say the best way to predict the future is to invent it
00:15:03 <lispy> similar reasoning...
00:16:07 <dons> everyone: QUICK! write some CODE!
00:16:15 <dons> (but make sure it type checks)
00:16:29 <kfish> heh
00:16:56 <newsham> working on it
00:17:06 <dons> newsham: I suspect the big multicore systems will be disruptive though. languages will have to have smp runtimes (or libraries)
00:17:14 <dons> which will be hard for some
00:17:30 <dons> and those already ready for this will be at an advantage for a while
00:17:39 <lispy> dons: we'll just have RoS, ruby on smp
00:18:31 <dons> haven't green threads been deferred in ruby for at least another release/
00:24:25 <tessier_> big multicore systems...mmmmm
00:24:55 * dons waits on the new 16 core amd64 to arrive in a couple of weeks...
00:24:59 * tessier_ has a 16 cpu xen cluster in 4u
00:25:02 <dons> lambdabot will think she's moved into a castle!
00:25:14 <tessier_> dons: Have you done any parallelization stuff in haskell?
00:25:22 <dons> yeah, some.
00:25:26 <tessier_> I understand it's a new feature of ghc
00:25:28 <dons> ?where pqc
00:25:28 <lambdabot> http://www.cse.unsw.edu.au/~dons/pqc.html
00:25:30 <dons> last week :)
00:25:50 <dons> my research group is strongly involved in the effort
00:26:05 <dons> this stuff, http://www.cse.unsw.edu.au/~chak/project/dph/
00:26:06 <lambdabot> Title: Manuel M T Chakravarty - Data Parallel Haskell
00:47:00 <evergreen> Is it possible to convince ghc to optimize recursive code, perhaps via tail call elimination?
00:47:13 <evergreen> This code gives a stack overflow:
00:47:18 <evergreen> foo 0 = 0
00:47:23 <evergreen> foo n = foo (n - 1) + 1
00:47:28 <evergreen> foo 1234567
00:47:44 <Excedrin> it's not tail recursive
00:47:52 <evergreen> Oh?
00:49:24 <Excedrin> the addition happens after the call to foo (n - 1)
00:50:15 <evergreen> Ah.  I think I see.
00:50:58 <greentea> Does ghc actually do that optimisation, though?
00:51:10 <greentea> i thought someone recently said that it doesn't.
00:51:36 <Excedrin> it does, but you can also have stack overflows when things are too lazy
00:51:43 <greentea> Ah, okay.
00:54:13 <dons> evergreen: consider this:
00:54:13 <dons> bar 0 = 0
00:54:13 <dons> bar n = bar (n-1) + 1
00:54:13 <dons> foo n = g n 0
00:54:13 <dons>     where g 0   acc = acc
00:54:13 <dons>           g !n !acc = g (n-1) (acc + 1)
00:54:13 <dons> main = do
00:54:13 <dons>     print . foo $ 10^7
00:54:13 <dons>     print . bar $ 10^7
00:54:13 <dons> $ ghc -O -fbang-patterns A.hs ; ./a.out
00:54:13 <dons> 10000000
00:54:13 <dons> Stack space overflow: current size 8388608 bytes.
00:54:13 <dons> foo is tail recursive, bar isn't
00:54:16 <dons> (foo has some extra strictness tossed in just to show how to do that)
00:56:33 <Excedrin> is using ! preferred over $! ?
00:56:39 <dons> and just for fun, 'g' is compiled to:
00:56:41 <dons> Main.$wg =
00:56:42 <dons>   \ (ww_s20E :: GHC.Prim.Int#) (ww1_s20I :: GHC.Prim.Int#) ->
00:56:42 <dons>     case ww_s20E of ds_X15T {
00:56:42 <dons>       __DEFAULT -> Main.$wg (GHC.Prim.-# ds_X15T 1) (GHC.Prim.+# ww1_s20I 1);
00:56:42 <dons>       0 -> ww1_s20I
00:57:11 <Cale> > foldl' (const (+1)) 0 [1..10000000]
00:57:16 <lambdabot> Terminated
00:57:18 <Cale> > foldl' (const (+1)) 0 [1..1000000]
00:57:20 <lambdabot>  1000001
00:57:27 <Cale> > foldl (const (+1)) 0 [1..1000000]
00:57:29 <lambdabot>  1000001
00:57:36 <dons> Excedrin: it depends.
00:57:45 <dons> I wanted two args strict, and ! is nicer there
00:57:51 <dons> but $! is more portable
00:58:20 <evergreen> dons: Thanks!  Still wrapping my head around your implementation...
00:58:32 <Cale> oh well, not enough time to get a stack overflow with that
00:58:50 <Cale> > foldl (+) 0 [1..1000000]
00:58:52 <lambdabot>  Exception: stack overflow
00:58:56 <Cale> > foldl' (+) 0 [1..1000000]
00:58:58 <lambdabot>  500000500000
00:59:23 <Cale> Note that although foldl is tail recursive, the fact that it isn't strict leads to a stack overflow
00:59:29 <Cale> foldl (+) 0 [1,2,3]
00:59:38 <Cale> = foldl (+) (0 + 1) [2,3]
00:59:44 <Cale> = foldl (+) ((0 + 1) + 2) [3]
00:59:51 <Cale> = foldl (+) (((0 + 1) + 2) + 3) []
00:59:58 <Cale> = ((0 + 1) + 2) + 3
01:00:04 <Cale> = (1 + 2) + 3
01:00:11 <Cale> = 3 + 3
01:00:13 <Cale> = 6
01:00:35 <dons> evergreen: the (standard) trick is to pass the accumulator value down the loop, rather than relying on the stack to keep track:
01:00:38 <dons> foo n = g n 0
01:00:41 <dons>     where g 0   acc = acc
01:00:43 <dons>           g !n !acc = g (n-1) (acc + 1)
01:00:55 <Cale> If the list is too long, then evaluating expression resulting from the loop will cause too many things to be put on the stack.
01:01:21 <Cale> the*
01:02:11 <evergreen> Right on.  So no operation needs to be done on the result of "g (n-1) (acc + 1)" except to return it to the previous stack frame.
01:12:02 <evergreen> Do you find that this translation from the simpler implementation to the passing-the-accumulator style becomes second nature as you get more FP literate?  Or does one normally just rely on higher-level functions like foldl being tail-recursive and then not need to worry about it much?
01:12:35 <Excedrin> yes to both
01:14:26 <Cale> evergreen: in a lazy language, you're mostly trying to avoid tail-recursion anyway
01:14:48 <greentea> Cale: Because you just get frames accumulating on the stack?
01:15:19 <Cale> Because a tail recursive function can't return any part of the result before it finishes recursing.
01:15:36 <greentea> *nod*
01:16:18 <Cale> What you're really looking for, when you can get them, are functions which immediately return a constructor before recursing.
01:16:50 <Cale> Of course, when the result is a simple integer, or something else which is atomic in nature like that, then strictness in building it is usually fine.
01:17:36 <Cale> and so tail recursion does well (together with some strictness to make sure the accumulators work) -- usually you want to use foldl' or something like that to make sure you get the details right.
01:18:34 <dons> evergreen: also, in a lazy language its often just as good to generate all solutions, and pick one. and it gives you more flexibility later on,
01:18:37 <dons> import Data.List
01:18:40 <dons> main = print . take 10 . scanl (+) 0 $ [1..10^5]
01:18:44 <dons> $ runhaskell A.hs
01:18:45 <dons> [0,1,3,6,10,15,21,28,36,45]
01:19:00 <evergreen> Cale: I see your point about laziness.  But I don't understand the meaning of the word "strict".
01:20:20 <Cale> Strictness is effectively the opposite of laziness
01:20:54 <evergreen> Cale: Ah, yes.
01:21:05 <Cale> Strict evaluation of a function f applied to an argument x proceeds by evaluating x, and then substituting the result in the body of f.
01:21:45 <Cale> Normal-order evaluation of the same proceeds by substituting x in the body of f, and then evaluating the result -- no evaluation of x is performed beforehand.
01:22:32 <Cale> Lazy evaluation is the same as normal order evaluation, but when the sustitution is done, the copies of x are linked together, so that as soon as one of them evaluates, they're all evaluated.
01:23:29 <Cale> (because f might duplicate its parameter)
01:23:49 <Cale> As an example, suppose that square x = x * x
01:24:14 <Cale> if we evaluate strictly,
01:24:17 <Cale> square (square 5)
01:24:22 <Cale> = square (5 * 5)
01:24:29 <Cale> = square 25
01:24:33 <Cale> = 25 * 25
01:24:36 <Cale> = 625
01:24:46 <Cale> Under normal order evaluation:
01:24:54 <Cale> square (square 5)
01:25:03 <Cale> = (square 5) * (square 5)
01:25:14 <Cale> = (5 * 5) * (square 5)
01:25:22 <Cale> = (5 * 5) * (5 * 5)
01:25:30 <Cale> = 25 * (5 * 5)
01:25:33 <Cale> = 25 * 25
01:25:37 <Cale> = 625
01:26:02 <Excedrin> also, 5 * 5 is only calculated once, right?
01:26:08 <Cale> Note that there was wasted work, because we computed 5 * 5 twice, and square 5 twice
01:26:15 <Cale> Lazy evaluation fixes that
01:26:43 <Cale> square (square 5)
01:26:50 <evergreen> So the haskell compiler does some magical memoization?
01:27:02 <greentea> Cale: Does normal-order require that the outer square be expanded first?
01:27:03 <Cale> = let x = square 5 in x * x
01:27:13 <Cale> = let x = 5 * 5 in x * x
01:27:26 <Cale> = let x = 25 in x * x
01:27:30 * xerox runs naked through the reductions
01:27:46 <Excedrin> http://research.microsoft.com/Users/simonpj/Papers/pj-lester-book/
01:27:48 <lambdabot> Title: Simon Peyton Jones: book, http://tinyurl.com/y6d7fu
01:27:56 <Cale> = 625
01:28:24 * Lemmih grins at xerox.
01:28:29 <Cale> (well, I skipped the let substitution step, because I was just using it to represent the fact that those were pointers both pointing to the same place)
01:28:45 <evergreen> Ah.  I see.  Memoization is not even necessary.
01:29:21 <xerox> Hiya Lemmih :)
01:30:15 <dons> Cale: we need to grab hat, and add a @reduce plugin..
01:30:21 <dons> it would be really really useful
01:32:51 <xerox> dons first law of software, if it is useful, it shall be a lambdabot plugin.
01:33:38 <lrrrr> hi there :)
01:33:51 <lrrrr> can anybody help me with State monad?
01:34:08 <xerox> Yeah.
01:34:23 <lrrrr> is it ok to paste 2 lines of code here?
01:34:29 <xerox> Yeah.
01:34:39 <dons> > runState (do x <- get ; put (x+1) ; return "done") 8
01:34:40 <lambdabot>  ("done",9)
01:34:52 <xerox> ...yeah.
01:35:13 <dons> hey lrrrr , welcome back. haven't seen you around for a while
01:35:42 <lrrrr> dons> hi :) for a few months, i think..
01:36:17 <lrrrr> yeah :)
01:36:27 <lrrrr> ok, so, regarding State..
01:36:41 <evergreen> dons: Your scanl example, above, is cool.  As long as I'm burning stack frames, might as well get all the intermediate results too, I guess. :)
01:36:44 <Cale> dons: yeah, that's a good idea
01:36:52 <lrrrr> tick d = do n <- get; put (trace (show d) (n+d));
01:37:02 <lrrrr> execState (sequence_ $ map tick [0..3]) 0
01:37:21 <lrrrr> why i see trace messages in reversed order here?
01:37:28 <lrrrr> i mean 3,2,1,0
01:38:42 <Cale> lrrrr: good question :)
01:39:01 <Lemmih> trace "3" (trace "2" ...)
01:39:12 <Cale> When you put (trace (show d) (n+d))
01:39:39 <Cale> n is the previous state, which is probably something of the form (trace (show (d-1)) ...)
01:40:17 <lrrrr> ah call-by-name in action? :)
01:40:20 <Lemmih> lrrrr: You could probably do: trace (show d) $ put (n+d)
01:40:36 <Cale> Remember trace doesn't print anything until it gets evaluated, which in this case is only after the whole state computation has finished.
01:45:28 <lrrrr> got it.. if i add $! before (n+d), then numbers are printed in the right order..
01:47:14 <lrrrr> thanks :)
01:52:00 <faszos> hi
02:06:27 <Cale> lrrrr: "right order" is relative :)
02:27:54 <joelr> good morning
02:27:55 <lambdabot> joelr: You have 1 new message. '/msg lambdabot @messages' to read it.
02:31:06 <dons> hey joelr. keeping up the lambda hacking?
02:31:28 <joelr> dons: seriously considering it :) unless lisp counts
02:31:37 <dons> heh
02:32:12 <joelr> dons: i've got some time now to dedicate to trading and my trading infrastructure
02:32:54 <joelr> one of the first things i would like to do is improve the way i read the numerous blogs in my rss readers
02:34:04 <joelr> i want to build "feedburner networks" of my own and aggregate different rss feeds (wall st. journal, ny times, etc.) into a single one
02:34:47 <joelr> i think hxml 7.0 came out recently, i need to take a look at it. i also wonder if anyone is doing rss in haskell
02:36:38 <therp> joelr: that sound interesting. why are you aggregating them? display in some trader app?
02:37:42 <joelr> therp: i want a single feed for articles from many blogs
02:38:08 <dons> joelr: there's lambdaFeed too
02:38:12 <dons> ?where lambdaFeed
02:38:13 <lambdabot> http://www.cse.unsw.edu.au/~chak/haskell/lambdaFeed/
02:38:27 <joelr> the reason i do is to feed out repeating articles, for example. also to be able to slice and dice the contents, try to extract information
02:38:41 <joelr> dons: what about lambdafeed? /let me take a look/
02:39:29 <joelr> dons: awesome! do you know of a library that reads rss and atom formats? lambdafeed seems to be about publishing
02:41:14 <psnl> joelr: rawdog / planet
02:41:30 <joelr> psnl: what's that? are these haskell libraries?
02:42:41 <psnl> things to tie together lots of feeds
02:43:59 <joelr> psnl: thanks
02:45:53 <dons> joelr: i don't know of a haskell library for reading/parsing these formats. but you never know .. ping haskell-cafe@
02:46:20 <joelr> yep
02:47:34 <evergreen> One more question about stack space, building on dons' scanl example:
02:47:45 <evergreen> This runs to completion, after a while:
02:47:50 <evergreen> main = print . scanl (+) 0 $ [1..10^7]
02:47:58 <evergreen> But this runs out of stack space:
02:48:06 <evergreen> main = print . last .scanl (+) 0 $ [1..10^7]
02:48:30 <joelr> 10:26 *** giksos QUIT Read error: 104 (Connection reset by peer)
02:48:35 <joelr> err
02:49:43 <evergreen> I wouldn't think "last" would add any overhead.
02:50:35 <Syzygy-> evergreen: could it be laziness biting you?
02:50:53 <Syzygy-> last.scanl is "basically" the same as foldl, isn't it?
02:51:12 * greentea wonders whether last forces a list of elements to be retained in memory than scanl alone doesn't.
02:51:24 <joelr> is there such a beast as a haskell web server?  production-ready web server?
02:51:31 <greentea> er, "in memory in a way that"
02:51:41 <Syzygy-> I think I've heard people talk about highly distributed haskell webservers...
02:51:51 <greentea> joelr: i don't know if it's production-ready, but there's HAppS
02:51:52 <Syzygy-> Yup....
02:52:04 <joelr> Syzygy-: yes! highly distributed is awesome
02:54:16 <evergreen> Syzygy-: I suppose last.scanl is the same as foldl.  At any rate, either one uses up all my stack space.
02:54:18 <Syzygy-> Yup. Thielemann will be talking about it at the Haskell meet on tuesday.
02:54:46 <Syzygy-> evergreen: What happens if you pick out the second-to-last and the last element?
02:55:11 <evergreen> Syzygy-: Using last . take N ?
02:56:24 <evergreen> Syzygy-: Still runs out of stack space.
02:57:13 <xerox> @check \f k xs -> foldl f k xs == last (scanl f k xs)
02:57:14 <lambdabot>  Add a type signature
02:57:17 <xerox> gnarf.
02:58:01 <Syzygy-> Oh... I think I found Thielemanns stuff. And it doesn't sreally seem to be so much a webserver as it is a "rewrite webpages in weird accents" engine.
02:58:28 <greentea> > print y in let (xs:y:z) = last .scanl (+) 0 $ [1..10^7]
02:58:29 <lambdabot>  Parse error
02:58:33 <greentea> Oops.
03:00:18 <astrolabe> evergreen: use scanl'   from Data.List
03:00:34 <astrolabe> er I mean foldl'
03:01:33 <astrolabe> It is a strict version, which doesn't fill up the stack.
03:01:44 <dons> joelr: yeah, HAppS has a high perf web server. check with musasabi or alexj
03:01:56 <dons> there's also simonm's demo one, which you know about
03:03:14 <dons> mmm. be interesting running simonm's HWS on the SMP rts.
03:03:55 <evergreen> astrolabe: foldl' works!  Thanks.  I'll look into how foldl' works.
03:04:07 <dons> ?source Data.List
03:04:08 <lambdabot> http://darcs.haskell.org/packages/base/Data/List.hs
03:04:38 <greentea> Well, that was . . . . educational.
03:05:23 <dons> greentea: which? :)
03:05:33 <greentea> i now know that it takes ~10 hours and ~750M to compile GHC 6.4.2 on my box.
03:05:41 <dons> heh
03:05:51 <greentea> The compilation finished with only ~6M free space to spare.
03:05:53 <dons> 750M seems a bit high...
03:06:01 <astrolabe> wow
03:06:03 <dons> what kind of box?
03:06:09 <dons> something what 200Mhz?
03:06:22 <greentea> Dell Laptop, Pentium III, 233MHz.
03:06:31 <dons> ok, sounds about right
03:07:00 <greentea> And all this because i wanted to have a gander at MissingH. :-P
03:07:25 <dons> i've built it in 14 mins once, on  3 Ghz machine, in a ramdisk fs, with optimisations off
03:07:49 <greentea> Sorry, i meant 750M of disk space, not RAM!
03:08:03 <greentea> )Crikey, this box only has 256M of RAM. :-
03:08:05 <greentea> :-) even
03:08:08 <astrolabe> I wish you could make version independent dlls with ghc
03:08:27 <dons> hmm. that seems big, $ du -hs lib/ghc-6.6
03:08:28 <dons> 184M    lib/ghc-6.6
03:08:48 <evergreen> greentea: Ubuntu 6.10 offers a ghc 6.4.2 package.
03:08:48 <dons> and the tree itself, $ du -hs /usr/obj/build
03:08:49 <dons> 270M    /usr/obj/build
03:09:02 <dons> i wonder why its so big.
03:09:06 <greentea> evergreen: i know, but i'm running Mandriva 2006.0, which doesn't. :-(
03:09:35 <evergreen> greentea: Boot ubuntu off CD!
03:09:46 <greentea> This box doesn't have a builtin CD/DVD drive.
03:10:22 <greentea> i also happen to use this box for non-Haskell stuff. :-)
03:12:48 <greentea> Hmm, don't have enough space on the root partition to actually install it, either. It's taken up more than 197M.
03:12:48 <dons> that's crazy talk!  ;)
03:12:52 <greentea> *chuckle*
03:13:10 <dons> hmm.
03:20:09 <hmich> hi all!
03:20:15 <hmich> can anybody explain to me
03:20:18 <astrolabe> hello
03:20:34 <hmich> why following code runs on par with the version where I define fib as an array
03:20:38 <hmich> fib :: [Integer]; fib = 1 : 1 : zipWith (+) fib (tail fib)
03:20:41 <hmich> main = print $ foldr ((+) . (fib !!)) (0::Integer) $ take 100000 $ cycle [1000]
03:21:10 <hmich> why doesn't indexing the list take any time?
03:26:50 <dcoutts> hmich, if you're only indexing once then construction time will dominate
03:27:09 <dcoutts> how much are you indexing?
03:27:26 <hmich> I run a fold over an list and index with each element of it
03:27:35 <hmich> and list as you can see contains 100000 elements
04:24:33 <dons> ?yow!
04:24:34 <lambdabot> I'm totally DESPONDENT over the LIBYAN situation and the price of
04:24:34 <lambdabot> CHICKEN ...
04:25:56 <greentea> BWAHAHAHA!
04:26:14 <greentea> After all that, i still can't install MissingH!
04:26:38 <greentea> regex-base, which is a dependency, is asking for base=>2.0.
04:26:51 <greentea> er, >=
04:28:35 <greentea> And all i've got is base 1.0.
04:29:08 <greentea> So i guess i have to find earlier versions of regex-base and regex-compat.
04:29:36 <greentea> But i think i'm not going to bother with this any further. %-}
04:31:55 <dons> greentea: ok. so no, you've got a too-new missingH still
04:32:23 <dons> you need a version before it depended on regex-*
04:32:27 <dons> i.e. MissingH-0.14.4 or earlier, iirc
04:37:44 <greentea> Hmm, but those earlier versions didn't work with GHC 6.4.1; is that likely to change with 6.4.2?
04:43:20 <greentea> Trying to install 0.13.1 results in that old error of "setup: MissingH.cabal:82: Parse of field 'extensions' failed:", with no further info.
04:45:08 <Masklinn> hello everybody
04:46:02 <greentea> And trying to download 0.14.4 from the new missingh site at software.complete.org still results in a 404.
04:53:26 <greentea> . . . . and the same error results.
04:54:00 <greentea> So i give up. i think i've gone above and beyond "reasonable steps" to get this package installed. If John wonders why this package isn't known and/or used more widely, i suspect i have at least part of an answer for him. :-P
05:05:45 <dons> greentea: argh :|
05:13:44 <greentea> Ja.
05:15:22 <greentea> Ah well, it's been a learning experience. :-)
05:38:04 <araujo> morning!
05:41:23 <erider> buen dia araujo
05:43:15 <greentea> Hi araujo.
05:44:14 <araujo> hola erider
05:44:16 <araujo> hola greentea
05:44:17 <araujo> :-)
05:44:23 <erider> voy pa Bolivia la semana que viene
05:44:31 <araujo> cool!
05:44:55 <araujo> erider, hay varias personas de bolivia que visitan haskell.es
05:45:08 <erider> esta haciendo frio aqui y no me gusta voy a estar con mi tia y su familia alla
05:45:15 <araujo> haha
05:45:24 <araujo> nice
05:46:03 <araujo> erider, recuerda tomar fotos :-)
05:46:11 <erider> hasta 4 de enero y voy a volver :)
05:46:31 <erider> ok :)
05:46:57 <erider> how have things been going with haskell araujo
05:54:03 <araujo> erider, very well , a bit stopped lately.
05:54:07 * araujo kind of busy
06:06:12 <dons> well, this is just stunning: http://www.haskell.org/pipermail/haskell-cafe/2006-December/020005.html
06:06:15 <lambdabot> Title: [Haskell-cafe] Re: Generate 50 random coordinates, http://tinyurl.com/ygxz6f
06:06:28 <dons> lispy: check it out. that'll learn you for throwing so much IO around ;)
06:18:04 <astrolabe> Arrgh just wrote a grumpy letter to the hat mailing list, and my mail server's gone down or something.  I wanted it to be gone so I can't reconsider it.
06:35:38 <xerox> dons: "He reaches Dons' stronghold with effort and urgency." :O
06:43:15 <sjanssen> I believe apfelmus's poem is a parody of Der Erlkoenig
06:43:50 <sjanssen> Wer reitet so spat durch nacht und wind?
06:44:08 <sjanssen> Es ist das Vater mit seinem Kind;
06:46:06 <int-e> close enough :)
06:46:23 <sjanssen> int-e: yes, I screwed it up
06:46:35 <sjanssen> been a long time since high school German ;)
07:04:59 <paolino> where is defined the Kill exception mentioned in the "Tackling .." to kill threads with throwTo ?
07:05:57 <paolino> or how do I kill a thread ?
07:10:34 <int-e> @type Control.Concurrent.killThread
07:10:36 <lambdabot> GHC.Conc.ThreadId -> IO ()
07:10:40 <int-e> this?
07:12:55 <paolino> can be, tnks
07:13:39 <faszos> it would be so nice if ghci had these features that lambdabot
07:14:13 <faszos> or if somebody integrated lambdabot into ghci.. hm
07:15:36 <int-e> rumours say that this has already happened.
07:16:34 <int-e> http://www.cse.unsw.edu.au/~dons/lambdabot.html ... not the News section
07:16:36 <lambdabot> Title: lambdabot, http://tinyurl.com/kv4n5
07:17:39 <faszos> wow, that sounds cool
07:19:38 <faszos> i dont have darcs :(
07:25:27 <ikegami--> is dons awake yet? :)
07:25:38 <ikegami--> I have a question about hs-plugins and GHC 6.6
07:26:06 <ikegami--> if he is asleep now, then I'll ask him next time
07:27:21 <int-e> @localtime dons
07:27:23 <lambdabot> Local time for dons is Sun Dec  3 02:23:15 2006
07:27:27 <Lemmih> What's the question?
07:28:08 <ikegami--> my question is whether can we compile hs-plugins at darcs repository by GHC 6.6?
07:28:26 <ikegami--> one of my friends try to compile and meets an error
07:28:42 <ikegami--> 00:20 <konn> src/AltData/Typeable.hs:452:0:
07:28:43 <ikegami--> 00:20 <konn>     parse error (possibly incorrect indentation)
07:28:59 <ikegami--> I don't have another information, but I want to help konn
07:29:00 <Lemmih> You can't.
07:29:03 <ikegami--> aha
07:31:13 <ikegami--> Lemmih: then, we may need the previous version GHC 6.4 for hs-plugins, is it right?
07:33:38 <Lemmih> ikegami--: Yes.
07:33:58 <ikegami--> ok, thanks a lot.
07:34:10 <ikegami--> I'll tell konn the answer
07:34:31 <int-e> interestingly it compiles with 6.6 here (I know that it won't work)
07:36:14 <nomeata> Is it a bug of ghc if a program compiles, but won’t work?
07:36:15 <nomeata> :-)
07:36:59 <int-e> that depends on the program or library :)
07:41:21 <Lemmih> int-e: hs-plugins from darcs?
07:41:47 <int-e> Lemmih: yes
07:42:01 <Lemmih> int-e: Can you run stuff with System.Eval.Haskell.eval?
07:42:07 <int-e> Lemmih: of course not.
07:42:08 <int-e> :)
07:42:47 <int-e> It's still looking for the wrong symbols at runtime, but compiling the lib was never an issue for me.
07:43:48 * Lemmih breifly hoped dons had fixed it.
07:44:11 <int-e> Heh. Sorry.
08:01:29 <augustss> ?users
08:01:30 <lambdabot> Maximum users seen in #haskell: 276, currently: 244 (88.4%), active: 18 (7.4%)
08:01:56 <nomeata> ?users
08:01:57 <lambdabot> Maximum users seen in #haskell: 276, currently: 245 (88.8%), active: 18 (7.3%)
08:02:09 <nomeata> looks like I don’t count as active when I ask for users
08:02:13 <nomeata> ?users
08:02:13 <lambdabot> Maximum users seen in #haskell: 276, currently: 245 (88.8%), active: 18 (7.3%)
08:02:23 <nomeata> oh, I wrote something up there. nevermind.
08:02:30 <swiert> augustss: would you consider writing up your lambda calculus note for the monad reader?
08:03:17 <augustss> swiert: I guess, I could.  but it involves work :)
08:03:35 <swiert> Yes - well you have more than a month...
08:04:05 <augustss> i might give it a good next weekend.
08:04:21 <swiert> It would fit really nicely. No pressure though.
08:21:38 <Renkin> I have a problem with designing my Replay-monad
08:23:07 <pitecus> Anyone see something like this?
08:23:09 <pitecus> <interactive>:1:85:
08:23:09 <pitecus>     Bad interface file: Prelude.hi
08:23:09 <pitecus>         Prelude.hi: openBinaryFile: does not exist (No such file or directory)
08:23:09 <pitecus> ghc-6.6: panic! (the 'impossible' happened)
08:23:09 <pitecus>   (GHC version 6.6 for i386-unknown-linux):
08:23:10 <pitecus>         interactiveUI:setBuffering
08:23:59 <Lemmih> Whoa, did you hide 'base' or something?
08:24:51 <pitecus> nothing, just trying to start ghci
08:25:50 <Saizan> uhm lambdabot requires unix to compile, why?
08:26:15 <chessguy> am i not allowed to do something like this?
08:26:16 <chessguy> data Foo1 = Foo1 { foo :: Integer, ...}
08:26:16 <chessguy> data Foo2 = Foo2 { foo :: Integer, ...}
08:26:35 <eviltwin_b> no, because foo becomes an accessor function
08:26:39 <Saizan> you are redefining foo
08:26:55 <chessguy> but it''s Foo1.foo and Foo2.foo
08:27:18 <eviltwin_b> no, that's not how haskell works
08:27:21 <Saizan> uhm no, foo belongs to the module, non to the data
08:27:45 <chessguy> hmmm. i must be missing something about how these data types work
08:28:02 <Saizan> better use also a class in your case maybe
08:28:53 <chessguy> i'm trying to model two very similar queuing situations, to do a monte carlo simulation which should demonstrate which is better
08:29:18 <chessguy> lemme paste the data types i have
08:29:22 <chessguy> @paste
08:29:23 <lambdabot> http://paste.lisp.org/new/haskell
08:29:31 <eviltwin_b> data Foo = Foo {foo :: Integer} declares a function foo at the module level which takes a Foo and returns the value inside it.
08:29:38 <eviltwin_b> it is called foo, not Foo.foo
08:30:11 <eviltwin_b> you can't have the samer function defined for a different type, becuase the way to do that in haskell uses type classes and you can't declare a type class on an automatically decalred accessor
08:30:43 <eviltwin_b> you *could* call them foo1 and foo2, define a type class, and make Foo1 and Foo2 instances of it which define foo to be foo1 and foo2 respectively
08:30:48 <pitecus> I reinstalled ghc, and i still get the same 'impossible happened' error.
08:31:13 <chessguy> pastebinn is taking its grand old time
08:33:11 <chessguy> geez, it still didn't paste?
08:33:34 <Saizan> it seems almost down in these days
08:34:05 <Saizan> (asking again: someone knows why lambdabot requires unix to compile?)
08:34:25 <eviltwin_b> ...because it was developed on unix and nobody's done the work to port it?
08:34:34 <chessguy> ok, well it doesn't look too horrible on mathbin
08:34:35 <chessguy> http://www.mathbin.net/1981
08:35:03 <chessguy> is there a better way to model this?
08:35:16 <Saizan> eviltwin_b: well, the question was more like, which part is unix specific?
08:35:57 * eviltwin_b hasn't actually seen the code so could not say
08:36:07 <chessguy> the code's freely available
08:36:09 <eviltwin_b> also, I'm not much of a win32 person
08:36:15 <chessguy> why don't you check for yourself
08:37:51 <Saizan> cause i still don't know enough of haskell libraries to tell what is portable and what is not
08:38:34 <gds> Saizan: @fortune, @zippy etc use the fortune prog, which is typically only found on unix systems...
08:38:42 <eviltwin_b> chessguy: I'd almost say the typeclass is the way to go, the simulation interface is defined by the typeclass and each simulation type is an instance which translates generic accessors to its particular form
08:38:47 <Saizan> but i'm not pretending, the "asking again" was there like an "excuse me if i'm asking again"
08:39:20 <eviltwin_b> saizan: from what I've seen, getting lambdabot going is painful even for people familiar with haskell and their platform
08:39:54 <chessguy> eviltwin_b, hmm. but, e.g., the second instance has a different number of accessors
08:40:09 <gds> There are various bits that make use of shell-like things too, I think...
08:40:14 <eviltwin_b> that's not the level you want to work at, though
08:40:27 <chessguy> hmm?
08:40:29 <Saizan> gds: well for some of them there are ports
08:40:43 <eviltwin_b> instead of manipulation the ccessor directly, you place the higher level semantic operation in the typeclass and have each type provide the appropriate implementation
08:40:54 <gds> I dunno - just trying to figure out possibilities :)
08:41:08 <chessguy> hmm.
08:41:17 <Saizan> gds: thanks :)
08:41:51 <eviltwin_b> forgive me for not being familiar with what you're doing... if the lines are queues, then you'd define an enqueue operation and give Foo1 and Foo2 implementations which add to the appropriate line
08:42:19 <chessguy> so i want a general typeclass like ServiceStation, and instances like threeLineServiceStation and singleLineServiceStation
08:42:31 <eviltwin_b> the idea being that you do evberything through the typeclass "interface" and the code doesn't know/can't see what's going on behind the scenes, which makes it easier to compare multiple implementations
08:42:38 <eviltwin_b> yes
08:42:58 <chessguy> ok. i've never done anything remotely like that with typeclasses
08:43:01 <chessguy> could be interesting
08:43:13 <chessguy> almost OO-ish
08:43:23 <eviltwin_b> it is called a type*class* for a reason
08:44:41 <Saizan> http://www.mathbin.net/1981 <-- something like the annotation
08:45:34 <chessguy> what's l -> ServicedCustomer
08:45:37 <eviltwin_b> you can also define a default implementation in the typeclass and let those instances which need something different add their own, but with only 2 instances that's probably not worth it
08:46:02 <chessguy> well, maybe not but i could generalize it
08:46:09 <chessguy> to do all kinds of combinations
08:46:44 <chessguy> different numbers of service points, different numbers of lines, different scheduling algorithms
08:47:16 <eviltwin_b> exactly.  and if you write everything to the typeclass then adding a new model doesn't require changing anything else
08:47:21 <Saizan> is the type of the class method, (LineState l) => l -> ServicedCustomer
08:48:22 <chessguy> hmmm. i don't get what you're doing, Saizan
08:48:26 <chessguy> pardon my n00biness
08:49:51 <eviltwin_b> when you define something in a class you need to have a parameter for the actual type.
08:50:21 <chessguy> right
08:50:32 <eviltwin_b> so he's defined (for an example) an accessor server1 which takes an I (the actual type) and returns a ServicedCustomer
08:51:14 <eviltwin_b> an instance will define server1 with the actual type there instead of the placeholder type
08:52:09 <eviltwin_b> make that "(the placeholder type)" instead of "(the actual type)"
08:52:47 <chessguy> ermmm
08:53:27 <eviltwin_b> hm?
08:54:00 <chessguy> so the instance says "in my case, server1 isn't really l->ServicedCustomer, it's ServicedCustomer"?
08:54:48 <eviltwin_b> "server1 is a function which takes an I and returns a ServicedCustomer, where I represents an instance type of the class"
08:55:28 <chessguy> oh!
08:55:46 <lrrr> hi there
08:55:50 <chessguy> so I is replaced by SingleLineState or ThreeLineState
08:55:54 <eviltwin_b> right
08:56:03 <chessguy> ok
08:56:05 <lrrr> is there a way to modify an element in ByteString ?
08:56:18 <lrrr> something like (//) for arrays
08:57:22 <chessguy> ok, thanks for the help. i'll have to thunk on this for a while.
08:57:38 <eviltwin_b> I'd use a more descriptive name than l for the type
08:57:56 <chessguy> can i use Instance, or is that reserved
08:58:03 <chessguy> @hoogle Instance
08:58:04 <lambdabot> Prelude.instance :: keyword
08:58:04 <lambdabot> Language.Haskell.TH.InstanceD :: Cxt -> Type -> [Dec] -> Dec
08:58:04 <lambdabot> Language.Haskell.TH.instanceD :: CxtQ -> TypeQ -> [DecQ] -> DecQ
08:58:05 * eviltwin_b isn't actually sure i that's an I or an l, should probably be the latter since it's a type variable, this font sucks
08:58:17 <chessguy> yeah i'm not sure either
08:58:21 <Saizan> it's l
08:58:32 <chessguy> L or I
08:58:34 <Saizan> only constructor are uppercase no?
08:58:45 <eviltwin_b> saizan: that doesn't help, I and l look identical here :>
08:58:53 <Saizan> "el"
08:59:02 <eviltwin_b> type variabl;es are lowercase so it should be ell
08:59:04 <eviltwin_b> yeh
09:00:20 <chessguy> man, haskell is ridiculously flexible
09:01:19 <pitecus> I rebooted, reinstalled ghc, and now i get the ghci error only when trying to run it from emacs, works ok from the console. very misterious...
09:01:33 <chessguy> ok thanks again, i'm gonna go do some symbolic regression and come back to this project later
09:01:44 <Saizan> pitecus, it's probably a path problem
09:02:06 <pitecus> whats sort of path problem, Saizan ?
09:03:06 <Saizan> well, ghci has to search for libraries, i don't know how it do this, but from your errors it seems that it matters from where it is invocated
09:03:23 <lrrr> err looks like i've kinda choosen a bad time for asking.. it's night in australia now.. :)
09:03:23 <Saizan> s/do/does/
09:04:37 <Saizan> you run it from emacs with haskell-mode?
09:04:42 <pitecus> ya
09:05:03 <Saizan> strange it works fine with me even on windows
09:05:17 <pitecus> It worked fine for a long time
09:05:26 <pitecus> Started to act weird today
09:05:38 <pitecus> before I rebooted it gave the same error from the console too
09:05:55 <pitecus> something must be really screwed up
09:15:07 <earthy> yaay
09:15:24 <earthy> my preliminary haskell folder for vim is not obviously stupid anymore
09:15:41 <earthy> slow though
09:18:27 <lisppaste2> pitecus pasted "Too complicated?" at http://paste.lisp.org/display/31218
09:18:33 <pitecus> Can someone look at this and tell whether I'm doing the wrong thing? It seems strange that I need multiparameter typeclasses and fundeps for suhc a simple thing...
09:18:57 <ulfdoz> http://www.rafb.net/paste/results/N4iF7l43.html <- does this contain an acceptable amount of elegance or can it be done better?
09:21:02 <earthy> pitecus: why do you need the argument a?
09:21:45 <pitecus> thats the instance
09:21:54 <earthy> methinks you'd be better of with a data StatisticalSet = StatSet { testSet :: Set b, goldSet :: Set b }
09:22:33 <earthy> and then code that takes StatisticalSet thingies
09:23:47 <pitecus> ya, that would be simpler
09:26:47 <pejo> ulfdoz, have you tried rewriting that with where instead of let? (Funky indentation of if too, imho. Why do you put your else at the end of a line?)
09:30:00 <ulfdoz> pejo: thx, looks much nicer now. I have probably done too much ML, so I tend to forget "where".
09:31:11 <sieni> > product [1..10]
09:31:15 <lambdabot>  3628800
09:31:29 <sieni> > product [1..1000]
09:31:31 <lambdabot>  4023872600770937735437024339230039857193748642107146325437999104299385123986...
09:41:52 <wolverian> hrm, why aren't tuples in Enum?
09:42:38 <Heffalump> how do you enumerate (Integer, Integer) ?
09:42:56 <Heffalump> noting that Integer is in Enum
09:43:13 <wolverian> your point being infinities?
09:43:28 <Heffalump> yes
09:43:35 <wolverian> well, that's a good point.
09:43:50 <wolverian> I can't help but feel it would be useful anyway.
09:43:50 <Heffalump> the obvious answer is diagonalisation, but it's not obvious that people would want that for non-infinite types
09:44:41 <Heffalump> and diagonalisation is troublesome too, you might want ((a,b),c) to enumerate in the same order as (a,b,c) and (a,(b,c))
09:44:58 <kpreid> There is Ix (Integer, Integer), however.
09:45:14 <kpreid> The difference from Enum is that you have to supply bounds.
09:45:26 <Heffalump> right
09:45:30 <Heffalump> so it's effectively finite
09:45:35 <wolverian> oh. I forgot to check the functions in Ix. thanks!
09:45:41 <wolverian> (I'm using arrays anyway, so.. :)
09:47:16 <hmich> I wanted to compare performance of lists vs arrays today and wrote a small test for calculating sum of fibonacci numbers
09:47:22 <hmich> fib :: [Integer]; fib = 1 : 1 : zipWith (+) fib (tail fib)
09:47:28 <hmich> main = print $ foldr ((+) . (fib !!)) (0::Integer) $ take 100000 $ cycle [1000]
09:47:47 <hmich> but the same code written using arrays had the same performance
09:48:15 <vegai> is that surprising?
09:48:20 <hmich> yeah
09:48:26 <hmich> why does indexing a list with !! take a lot of time?
09:48:40 <hmich> s/does/doesn't/
09:49:12 <vegai> hmm
09:49:21 <kpreid> perhaps the array version has its own equivalent slowness?
09:49:41 <vegai> hmich: might be that laziness benefits the list version in that case
09:50:03 <hmich> well here is the array version
09:50:09 <hmich> fib = a where a = listArray (0, 1000) ([1, 1] ++ [ a ! (i - 1) + a ! (i - 2) | i <- [2 .. 1000] ])
09:50:12 <hmich> main = print $ foldr1 ((+) . (fib !)) $ take 100000 $ cycle [1000]
09:50:21 <hmich> i don't think that it is slow
09:50:35 <hmich> perhaps laziness benefits somehow indeed
09:50:42 <hmich> but can anyone explain exactly how?
09:51:11 * vegai waves a large banner: "Wizards needed!"
09:51:16 <hmich> =)
09:54:06 <vegai> seems like both versions need to build everything before n anyway, so ! or !! won't be the most expensive operation
09:54:41 <vegai> or rather, ! and !! is what triggers building the list
09:55:05 <vegai> I think I have this in my head correctly, but I'm having trouble bringing it out :)
09:59:31 <hmich> mm
09:59:39 <hmich> but !! needs to traverse the list from the beginning
10:00:02 <hmich> if ghs doesn't implicitly construct an array instead of list
10:00:29 <vegai> yes, but if !! triggers building the list, it would do it only once?
10:00:36 <vegai> Oh, I don't know.
10:00:40 <hmich> yes
10:00:50 <hmich> but it's the traversing that takes much time in the cycle
10:01:06 <hmich> well doesn't take exactly but should =)
10:01:46 <hmich> the problem with haskell is that it's rather hard to predict perfomance of the code if you're not a guru
10:02:00 <Saizan> maybe it doesn't restart every time from the head
10:02:09 <vegai> I would trust a profiler rather than my own head in any other language too
10:02:17 <hmich> by the way, what other lazy programming languages are there or haskell is unique?
10:02:20 <vegai> or a benchmark
10:02:55 <pejo> hmich, Clean, Miranda, O'Haskell, Helium
10:02:58 <hmich> well of course but in say c++ you could at least assume asymptotics and based on your experience predict time needed to run the programm
10:03:27 <hmich> yeah, I read that clean is very similar to haskell, but I don't know much about another three
10:03:31 <hmich> thanks for pointers
10:03:42 <Saizan> because the c++ compiler can't assume eanough to do optimization like ghc can and does
10:03:52 <vegai> and there are some modules in many languages that allow you to do lazy evaluation
10:04:15 <hmich> well it's nice but what if because of laziness code would run slow?
10:04:20 <vegai> ocaml has one in the standard distribution, I think
10:04:37 <vegai> hmich: then you can insert strictness annotations, i.e. force evaluation
10:04:39 <hmich> that's I think can be a problem when adopting Haskell for use in some algorithmic competition like topcoder
10:05:12 <hmich> because people there want to know exactly how well their program would perform
10:05:15 <Saizan> if you need performance you still have to check it with a profiler anyway
10:05:37 <pejo> Saizan, WCET analysis. :-)
10:05:55 <Saizan> WCET?
10:06:00 <hmich> you don't get profiler as a builtin tool in topcoder =)
10:06:04 <pejo> Worst Case Execution Time
10:06:06 <vegai> Whatever the university courses teach about performance analysis, I don't think it's smart to trust your brain on that one
10:06:38 <vegai> unless for some reason, computer-assisted benchmarking and profiling is specially hard
10:07:26 <Saizan> you can trust performance analysis if you know exactly what is going in the machinery
10:07:36 <hmich> I think my brain is good enough to trust it sometimes =)
10:07:52 <hmich> we talk here about parts in the code that are algorithm-intense
10:08:15 <hmich> and it's bad if because of some laziness error somewhere
10:08:28 <hmich> they don't perform as they should
10:08:45 <Masklinn> well software always performs as coded
10:08:59 <vegai> or as the implementation interprets it
10:09:10 <Saizan> for example you can design a O(logn) but if you have large data and you have to read from locations distant from each other it will be very slow
10:09:21 <vegai> I think I could write a C compiler that screws up your excellent algorithms :)
10:09:31 <hmich> =)
10:09:36 <vegai> in fact, it's probably easier to write such a complier than a good one :)
10:09:41 <eviltwin_b> "Reflections on Trusting Trust",m anyone?
10:10:29 <Masklinn> anyway, multiple experiences have showed that to know how your code performs you need to measure it, if only to humble you and show you that 9 times out of 10, when you think you know where your performance issues come from, you're wrong
10:10:50 <Saizan> the problem is that abstractions leaks, some time or the other
10:11:08 <hmich> simply put, I wondered: what if my example with fibonacci didn't show that both versions performed good, but instead that both versions were slow
10:11:09 <Masklinn> the other way being to micro-optimize everything, but that's not what haskell was created for
10:11:21 <hmich> yeah, that's the problem with abstractions
10:11:30 <hmich> joel spolsky wrote an article about it on his site =)
10:12:06 <newsham> how is judging performed to measure worst case performance?
10:12:34 <newsham> seems like you could use data structures that had great average case performance that would be hard to find worst cases for without knowing the code
10:13:27 <pejo> hmich, there is some hints on the wiki for performance tuning Haskell.
10:13:42 <Masklinn> it would take some time to find them though, maybe more than the time you get for stuff like TopCoder unless you're very good at structuring data
10:14:26 <Saizan> i think that list comprehensions generally aren't that fast, they construct the list first right?
10:14:29 <newsham> right, so how do they judge the contest if the contest is for best worst case perf?
10:14:37 <Masklinn> plus you'd be at the mercy of randomness, cause it would be hard to find the worst case, unless the judges just stumble on it by sheer chance
10:15:00 <hmich> well but Haskell is perfect for clean impementation of many algorithms, and that's what topcoder is all about
10:15:45 <Masklinn> Saizan > What do you mean? List Comprehensions are as lazy as everything else
10:15:57 <Masklinn> they lazyly construct the list
10:16:04 <Saizan> i know, but they construct it
10:16:17 <Masklinn> as opposed to doing what?
10:16:19 <Saizan> instead there's no nead for it in hmich\s code
10:16:29 <hmich> newsham: usually time limit on a problem is about two times longer than a right implementation would run on the hardest test case
10:16:31 <Masklinn> ah ok it's about stuff I haven't seen, sorry
10:16:41 <Saizan> 'im talking abaout his rightmost [1..1000]
10:17:19 <Masklinn> I came back after he showed his code, right in the middle of the discussion, so I didn't see it, sorry about that
10:17:23 <newsham> > last [1..1000]
10:17:25 <lambdabot>  1000
10:17:25 <Saizan> kk
10:17:43 <hmich> well you could use something like cycle [1..1000]
10:17:44 <newsham> like that?  the list is constructed, but it need not be all computed in memory at once
10:17:48 <hmich> the result wouldn't be different
10:18:00 <newsham> elements could be added as they are needed and read by "last"
10:18:52 <xerox> ?type last . cycle
10:18:54 <lambdabot> forall a. [a] -> a
10:19:30 <xerox> Maybe a more expressive type system would scream that _|_ is buried there.
10:19:48 <newsham> a type system that solves the halting problem?
10:20:04 <desrt> we were discussing how "infinite list" is not a haskell type yesterday, in class
10:20:09 <Masklinn> for at least a few values
10:20:10 <desrt> from a comonadic view of streams
10:20:13 <newsham> or do you mean one that knows cycle generates infinite values?
10:20:23 <fasta> Setup.hs: cannot satisfy dependency mtl>=1.0 (isn't this included in GHC already?)
10:20:23 <newsham> and that last consumes all values
10:20:31 <desrt> newsham; special type for infinite lists
10:20:35 <fasta> I get that message when I try to build Edison
10:21:00 <newsham> what of functions that may or may not return infinite lists?
10:21:12 <desrt> well, that's just a list then
10:21:12 <newsham> Maybe Infinite [] a?  ;-)
10:21:43 <desrt> note that, practically speaking, there's no difference between infinite lists and very very long ones
10:21:53 <Lemmih> fasta: Not anymore.
10:22:01 <desrt> you'd only get the 'infinite' annotation if haskell could convince itself that the list was infinite
10:22:24 <desrt> these things really do have no place in the typesystem though...
10:22:38 <desrt> to do it realistically would be hacky and prone to finicky edge cases
10:22:43 <desrt> to do it properly would be undecidable :)
10:23:10 <Lemmih> fasta: If you're on Debian, install libghc6-mtl-dev.
10:23:19 <fasta> Lemmih: ok, thanks
10:24:22 <fasta> Lemmih: lots of libraries in Debian now. Cool
10:28:14 <Renkin> I have a monad Replay q r a. It's a program that runs IO actions and produces a trace of everything it's run. Either it reaches the end of the program and gives a result, or it stops and gives the trace, whenever it can't run because more input is needed. Then you can rerun the program, giving it a trace
10:29:28 <fasta> What are the accompaning doc packages for everything starting with libghc6?
10:29:48 <Renkin> I was thinking of a type of the form  Trace -> (Trace, IO (Either Trace a))
10:30:11 <fasta> accompanying*
10:30:22 <pejo> fasta, apt-cache search ghc6 should give a nice list of packages named something with ghc6
10:30:33 <Renkin> Where the trace of the tuple is the rest of the given trace, after the monad has been run. So it consumes a bit of the trace and returns the rest
10:31:07 <Renkin> The trace in the Either thing should be the complete trace of what the program has done so far
10:31:29 <Renkin> The problem is I can't find a way to keep the complete trace throughout the execution
10:31:35 <Renkin> Any suggestions?
10:31:50 <Renkin> Maybe the type is insufficient
10:33:14 <astrolabe> desert: But as a programmer, I want to state that a list is infinite using the type system.
10:34:59 <newsham> data InfList a = InfList { withInfList :: [a] } ?
10:35:58 <astrolabe> newsham: yeah, something like that, but I want the [] and : notation to work for InfList too.
10:37:01 <astrolabe> But really, I was arguing with desrt saying there should be no place in the type system to say that a list is infinite.
10:37:02 <newsham> InfList [1,2,3,4]   already works with []'s :)
10:37:26 <astrolabe> yeah :(
10:37:41 <newsham> x `colon` (InfList xs) = InfList x : xs
10:37:48 <newsham> now colon works too :)
10:38:16 <newsham> here's a big downside : you can use InfList on finite lists.
10:39:00 <astrolabe> and you have to keep mentioning the data constructor
10:39:36 <newsham> i think incorrectness might be a bigger downside than extra typing and lack of syntactic sugar
10:44:04 <newsham> > ((* 3) >>> (+ 1)) 9
10:44:06 <lambdabot>  28
10:44:49 <astrolabe> But the incorrectness is fixable, the sugar isn't.
10:45:55 <YuleAthas> What is "fps-any"? The Yi configure script complains I don't have it.
10:46:08 <newsham> > first (* 3) (2,3)
10:46:10 <lambdabot>  (6,3)
10:46:14 <eviltwin_b> ?where fps
10:46:15 <lambdabot> http://www.cse.unsw.edu.au/~dons/fps.html
10:46:17 <newsham> > second (* 3) (2,3)
10:46:19 <lambdabot>  (2,9)
10:46:42 <astrolabe> @hoogle first
10:46:43 <lambdabot> Control.Arrow.first :: Arrow a => a b c -> a (b, d) (c, d)
10:46:43 <lambdabot> Data.List.deleteFirstsBy :: (a -> a -> Bool) -> [a] -> [a] -> [a]
10:46:43 <lambdabot> System.Win32.File.c_FindFirstChangeNotification :: LPCTSTR -> Bool -> FileNotificationFlag -> IO HANDLE
10:47:07 <newsham> > ((* 3) *** (+ 1)) (3,4)
10:47:08 <lambdabot>  (9,5)
10:47:17 <emu> > (+ 1) . (* 3) $ 9
10:47:18 <lambdabot>  28
10:47:40 <newsham> > ((* 3) &&& (+ 1)) 3
10:47:42 <lambdabot>  (9,4)
10:48:17 <resiak> Yay for arrows, or something?
10:49:01 <Masklinn> ?type (>>>)
10:49:03 <lambdabot> forall (a :: * -> * -> *) d b c. (Arrow a) => a b c -> a c d -> a b d
10:49:32 <Masklinn> ?type ***
10:49:34 <lambdabot> parse error on input `***'
10:49:39 <Masklinn> ?type (***)
10:49:40 <lambdabot> forall (a :: * -> * -> *) c' c b' b. (Arrow a) => a b c -> a b' c' -> a (b, b') (c, c')
10:50:10 <newsham> > (((* 3) *** (+ 1)) >>> (curry (+))) 3
10:50:12 <lambdabot>  add an instance declaration for (Num (b, b'))
10:50:48 <newsham> ?type ((* 3) *** (+ 1))
10:50:50 <lambdabot> forall b b'. (Num b, Num b') => (b, b') -> (b, b')
10:51:00 <newsham> ?type (curry (+))
10:51:02 <lambdabot> forall a b. (Num (a, b)) => a -> b -> (a, b) -> (a, b)
10:51:23 <newsham> ?type (((* 3) *** (+ 1)) >>> (curry (+)))
10:51:25 <lambdabot> forall b b' b1. (Num b, Num b', Num ((b, b'), b1)) => (b, b') -> b1 -> ((b, b'), b1) -> ((b, b'), b1)
10:52:27 <newsham> > (((* 3) &&& (+ 1)) >>> (curry (+))) 3
10:52:28 <lambdabot>  add an instance declaration for (Num ((b, b), b1))
10:52:44 <newsham> > ((* 3) &&& (+ 1)) 3
10:52:46 <lambdabot>  (9,4)
10:53:02 <newsham> > curry (+) (9,4)
10:53:04 <lambdabot>  add an instance declaration for (Num ((a, b1), b))
10:53:22 <newsham> > uncurry (+) (9,4)
10:53:24 <lambdabot>  13
10:53:27 <newsham> oops!
10:53:39 <newsham> > (((* 3) &&& (+ 1)) >>> (uncurry (+))) 3
10:53:41 <lambdabot>  13
10:54:39 <desrt> > abuse!
10:54:40 <lambdabot>  Parse error
10:54:57 <eviltwin_b> sometimes /msg is more appropriate...
10:55:17 <newsham> oh! didnt know lambda does msg
10:55:34 <eviltwin_b> yep.  "/msg lambdabot > ..." works fine
10:55:40 <newsham> yah just tried
10:56:34 <lambdabot> I do a lot of things you don't know about. *wink*
10:56:38 <newsham> ?pl \x -> (x*3) + (x+1)
10:56:39 <lambdabot> liftM2 (+) (3 *) (1 +)
10:57:07 <newsham> hmm.. lambdabot knows that (* 3) == (3 *) ?
10:58:49 <newsham> which monad is that liftM2 in?
11:00:08 <resiak> @type liftM2 (+) (3*)
11:00:09 <lambdabot> forall a. (Num a) => (a -> a) -> a -> a
11:00:27 <resiak> Bleh, should have know.n  I think that ((->) a) is a monad
11:00:38 <resiak> (I for one am very confused by this.)
11:00:39 <newsham> instance Monad ((->) r)  ?
11:00:47 <eviltwin_b> no, it's just looking for the other funciton argument
11:02:51 <Cale> > (do {u <- (* 2); v <- (+ 1); return (u * v)}) 5
11:02:52 <lambdabot>  60
11:03:34 <newsham> interesting
11:03:42 <Cale> > (5 * 2) * (5 + 1)
11:03:44 <lambdabot>  60
11:04:20 <newsham> > 5 >>= (* 2)
11:04:21 <lambdabot>  add an instance declaration for (Num (m b))
11:04:41 <lispy> > return 5 >>= (* 2)
11:04:42 <lambdabot>  add an instance declaration for (Num (m b))
11:04:49 <lispy> er?
11:04:54 <lispy> > (return 5) >>= (* 2)
11:04:54 <lambdabot>  add an instance declaration for (Num (m b))
11:05:37 <lispy> > (return 5) >>= liftM (* 2)
11:05:37 <lambdabot>  add an instance declaration for (Num (m a1))
11:05:42 <resiak> Cale: what does the definition of >>= look like for that monad?
11:06:54 <Cale> x >>= f = \k -> f (x k) k
11:07:23 <eviltwin_b> oh.  (* 2) is a functor?
11:07:33 <Cale> ((->) e) is a functor
11:08:06 <Cale> fmap f g = f . g
11:08:38 <lispy> ?undo do { u <- (* 2);  v<- (+1); return (u*v)}
11:08:39 <lambdabot> (* 2) >>= \ u -> (+ 1) >>= \ v -> return (u * v)
11:09:01 <lispy> > ((* 2) >>= \ u -> (+ 1) >>= \ v -> return (u * v)) 5
11:09:02 <lambdabot>  60
11:09:43 <Cale> > liftM2 (*) (* 2) (+ 1) 5
11:09:44 <lambdabot>  60
11:11:04 <newsham> the do notation is nifty
11:11:39 <Deformative> Haskell slower or faster than C++?
11:11:51 <Cale> Deformative: hard to say
11:12:12 <Cale> GHC is producing code in some cases which rivals C now.
11:12:14 <Deformative> Generally,  development and preformance I am refering to.
11:12:26 <Cale> Development is almost certainly faster
11:12:28 * lispy groans
11:12:28 <newsham> > (do { x3 <- (^ 3); x2 <- (^ 2); x <- id; return (x3 + 2*x2 + x + 5) }) 3
11:12:30 <lambdabot>  53
11:12:40 <Deformative> s/./;
11:13:08 <Cale> Performance has typically been a problem in the past, but we're getting over that now :)
11:13:23 <Deformative> Getting over it?
11:13:41 <Deformative> As in hardware no longer requires it or getting bored of it,  or accomplishing?
11:14:11 <Lemmih> D) All of the above?
11:14:16 <Cale> Well, one of the biggest problems with making Haskell programs fast in the past is the fact that the default String type in Haskell is [Char], that is lists of 32-bit characters
11:14:29 <newsham> ?where shootout
11:14:30 <lambdabot> http://shootout.alioth.debian.org/
11:14:33 <Cale> But we now have Data.ByteString
11:14:51 <gour> Lemmih: is hIDE abandoned or just sleeping?
11:15:03 <Deformative> Oh,  interesting.
11:15:31 <Cale> Which is a library for working with either contiguous blocks of memory, or lazy lists of L2-cache sized blocks of memory
11:15:34 <newsham> the shootout page has some performance metrics (of several types) for many languages for some small benchmarks
11:15:36 <Lemmih> gour: Abandoned, I believe.
11:15:37 <Deformative> Would it be possible for Haskell to exceed C in terms of performance one day?  (all/most aspects)
11:15:43 <lispy> Deformative: if you're into contrived micro-benchmarks try this: http://shootout.alioth.debian.org/gp4/haskell.php
11:15:44 <Cale> I think it is
11:16:01 * gour is sad hearing bad news about hIDE
11:16:03 <Cale> Data.ByteString programs are beating naive C programs.
11:16:06 <lambdabot> http://tinyurl.com/y3kvjm
11:16:23 <lispy> Deformative: it's faster today depending on your application
11:16:39 <newsham> you mean "code written by a good C programmer vs code written by a good haskell programmer" I assume.
11:16:42 <Cale> Because not only is the datastructure more efficient, but the lirary contains lots of algebraic hints to the compiler as to how to rewrite code to make it more efficient.
11:16:51 <Cale> (using properties of strings)
11:16:55 <Deformative> Interesting.
11:17:10 <lispy> Deformative: for example, the virtual machines people wrote for the most recent ICFP contest were slower in haskell, but concurrency seems to be faster in haskell
11:17:22 <Cale> The end result is that C code often needs to be rewritten to use block-IO to beat simple Haskell ByteString programs
11:17:29 <Deformative> Yes I do newsham.
11:17:57 <Cale> We still need to rewrite many of the shootout entries to use Data.ByteString
11:18:07 <newsham> another factor is that you can write the code faster in haskell and spend more of your time budget on analyzing the problem and finding more optimal strategies.
11:18:27 <Cale> It was worked on a lot a few months ago, but the shootout machines didn't have a copy of that library back then.
11:18:49 <Cale> Yeah, it's much easier to attempt things which you couldn't even attempt in C.
11:19:28 <lispy> yeah, like writing a scheme compiler in less than a week would be hard in C :)
11:19:41 <newsham> lispy: i dunno.  its just scheme.
11:19:42 <Cale> I wrote a pipeline scheduler for PPC+Altivec a while back, which was around 1200 lines of code including comments, and it would have easily been 15000 lines of C.
11:19:49 <Deformative> Cool.
11:21:19 <lispy> Cale: did you see the question on the cafe by Grady Lemoine?
11:21:29 <lispy> Cale: do you understand what is happening there?
11:22:20 <Deformative> Hmm,  Does Haskell run quicker on different architectures than C does,  or is i686 the most comparable?
11:22:24 <lispy> Cale: i'm sort of wondering about weird type defaulting?
11:22:57 <lispy> Deformative: not to be too pendantic, but haskell and c don't run
11:23:12 <lispy> Deformative: but, ghc is heavily optimized for i686 as i understand it
11:23:56 <Deformative> Well, I meant haskell and C apps,  sorry.
11:24:00 <lispy> Deformative: keep this in mind with ghc, when you compile with optimizations it generally translate to C then uses gcc to turn that into a binary
11:24:03 <eviltwin_b> deformative: that's a tricky question, for example you can have ghc generate c code,and gcc is much bettre at optimization on x86 so the same generated code will be faster on x86
11:24:08 <Deformative> I should phrase better.
11:24:18 <lispy> Deformative: my point is that it depends on the _implementation_ not the language
11:24:26 <Deformative> Yeah.
11:24:28 <lispy> Deformative: the compiler matters
11:24:48 <Deformative> I guess I was thinking about asm implementation.
11:25:25 <lispy> well, you can ask ghc to produce asm directly or via-c, maybe you should play around with it and see what the output looks like?
11:26:29 <Deformative> Hmm,  I do not have a ppc, alpha, or sparc to compare to.
11:26:35 <lispy> Deformative: http://www.haskell.org/ghc/docs/latest/html/users_guide/flag-reference.html
11:26:38 <lambdabot> Title: 4.17. Flag reference, http://tinyurl.com/ydk2e6
11:26:53 <lispy> -keep-s-file may be of interest
11:29:04 <Cale> Deformative: Generally, there's no theoretical reason why Haskell programs can't be compiled to really fast code, most of the problem with getting programs to run quickly has been the fact that Haskell's evaluation mechanism is different from 99% of the languages out there, and so there hasn't been nearly as much research into how to compile things efficiently for it.
11:29:33 <Cale> We're getting to the point where it's really quite a practical language in many directions now though.
11:29:38 <lispy> Deformative: one other thing to keep in mind about haskell, there is a defacto standard for linking with C which is quite simple and easy to use.  So if you do find that Haskell doesn't cut the mustard, you can rewrite a module in C (or something which supports the C abi) and link it
11:29:54 * Heffalump disagrees, I think laziness makes compiling Haskell to efficient code intrinsically harder than most languages
11:29:55 <Cale> There's a proof-of-concept first-person-shooter game.
11:30:09 <lispy> ?where frag
11:30:10 <lambdabot> http://www.haskell.org/haskellwiki/Frag
11:30:19 <lispy> Deformative: ^^ that's the game Cale just mentioned
11:30:28 <Cale> I don't really think it's intrinsically harder. It's just different, and so we don't know as much about it.
11:30:38 <chessguy> hmm, i think some experimentation is required :)
11:30:54 <Cale> Certainly, I'd just say jump right in and try it.
11:30:59 <Heffalump> laziness is further away from the machine model
11:31:12 <eviltwin_b> heffalump: take a look at compiler optimization foo sometime, even for simple languages like C it turns out to be nontrivial
11:31:38 * lispy would not consider C to be all that simple
11:31:38 <Deformative> Yeah,  I am just thinking about what might happen in the future,  I am convinced that one day a Language will replace C as "the great preformance language that everyone uses"  Haha.
11:31:56 <eviltwin_b> maybe I should specify K&R C; ANSI's added a lot of complexity :>
11:31:58 <lispy> Deformative: i think that's a myth about C :)
11:32:02 <Cale> Heffalump: maybe, but I don't really know how you'd measure that, and I'm not sure that it's not just a perception caused by lack of knowledge :)
11:32:09 <emu> depending on your application, there are much better languages than C for performance
11:32:20 <Masklinn> Deformative> Would it be possible for Haskell to exceed C in terms of performance one day?  (all/most aspects) > theorically, since Haskell code is of a much higher level yet statically typed the compiler has all the information it needs to create the best code (plus since haskell doesn't rely on execution order out of do expressions, it can rearrange all the code to get suff that fits him better). Plus because of the higher level of the language, there
11:32:20 <Masklinn>  are potential optimizations that a compiler just can't infer in, say, C. Practically, optimizing is a very hard problem, and automatically finding optimizations for languages which are fairly close to glorified assembly such as Fortran or C is much easier
11:32:51 <Cale> Here's an example I like to bring out
11:33:04 <emu> Fortran compilers have been studied for so long, they produce much better numeric code than any C compiler
11:33:19 <desrt> but C fights back
11:33:22 <emu> SISAL is a functional language explicitly designed for fast and distributed numeric computation
11:33:58 <Masklinn> emu > there's also the fact that FORTRAN still is at the forefront of numeric computations, so lots of work is done on compilers in that precise field
11:34:18 <emu> also the language is more oriented towards it
11:34:36 <Heffalump> ah, distributed stuff does change the equation significantly
11:34:39 <Cale> Suppose you have a language which knows about matrices and matrix multiplication, and it inlines some code and finds A * A^(-1) * x with matrix A and vector x somewhere. In the case of a language which knows about matrices, it can optimise this to x
11:34:42 <Masklinn> well it's better to it suited than C indeed
11:34:51 <Renkin> It'd be cool with a multi-core-CPU that's optimized for functional code :)
11:34:52 <Heffalump> suddenly Haskell's evaluation model looks much more parallelisable than C's
11:34:55 <Cale> C can't do that, because all a C-compiler will see is a bunch of loops
11:35:10 <Heffalump> Cale: sure, but neither can Haskell
11:35:11 <eviltwin_b> C: jack of all trades, master of none
11:35:15 <desrt> Cale; assuming A^(-1) exists :)
11:35:18 <Masklinn> Heffalump > that's a property of functional programming anyway, see Erlang
11:35:21 <Cale> desrt: of course
11:35:33 <desrt> eviltwin_b; with C the programmer has to be the master
11:35:52 <Heffalump> Masklinn: Erlang is more explicitly designed for distributed processing, but I was just trying to compare Haskell and C, not make general points
11:35:58 <Masklinn> Haskell's non-garanteed-order-of-execution just makes  parallelisation less problematic
11:36:06 <fasta> What does "the symmetric order of the tree" mean?
11:36:13 <Heffalump> it's not just non-guaranteed, it's non-observable
11:36:14 <desrt> yes.  purity rocks the socks of parallelism
11:36:19 <Cale> Heffalump: In Haskell we still might be able to rig something up with RULES, but you're right. The point is really that higher level languages open up more opportunities for optimising programs.
11:36:43 <desrt> . o O ( i think i might need this value soon... let's fire off a thread to compute it )
11:36:50 <Heffalump> Cale: yes, no question. But I still maintain that laziness is a significant burden when executing sequentially.
11:36:58 <desrt> . o O ( oh.  i didn't need that value after all.. it's pure, though, so nothing bad happened. )
11:37:11 <emu> desrt: your thoughts are showing
11:37:19 <desrt> emu; i think loudly
11:37:31 <Masklinn> desrt thinks over standard TCP/IP
11:37:39 <Masklinn> his brain is not big enough for his intelligence
11:37:44 <emu> Heffalump: what about the fact that you can enforce strictness when you want?
11:37:44 <newsham> i cant hear anything but the teletype, desrt.
11:37:47 <desrt> thoughts in ascii
11:37:50 <desrt> ^ my new band name
11:38:09 <fasta> nm
11:38:09 <Heffalump> emu: it's syntactically burdensome so people don't unless they have a real need, IME
11:38:13 <Masklinn> emu > but you lose the "free" parallelisation
11:38:27 <emu> Heffalump: or when laziness causes you to save time because you didn't compute extra values
11:38:53 <emu> dealing with thunks and memoization certainly looks burdensome on the micro-optimization level
11:39:07 * emu shrugs
11:39:22 <Renkin> I was thinking, wouldn't the concept of pure functions be very useful when programming the PS3. Developers are constantly complaining about how hard it is to program because htye have to modularize (is that a word?) the code since the CPU has 8 cores
11:39:42 <Renkin> Pure functions can run in parallell
11:39:46 <Masklinn> laziness is a tradeoff anyway, and Haskell is one of the few languages that uses it as default, others either are eager or require you to specify lazy operations. So if you don't like laziness you have many languages (including functional) to pick from
11:39:49 <desrt> Renkin; hah.  you just stated the justification behind the coconut project.
11:40:06 <Renkin> desrt: what is that? :)
11:40:26 <desrt> Renkin; this research project going on at my university
11:40:50 <desrt> in theory you write very high-level code and it figures out how to leverage the SPUs on a cell-like processor to do the work for you very efficiently
11:41:10 <desrt> in practise, the scope of the project is huge and very complicated so it will be a while before it produces anything real
11:41:15 <emu> luckily the PS3 is gonna bomb.  how much do they want people to pay for it? yikes
11:41:16 <Masklinn> a compiler that multithreads your code automagically?
11:41:18 <Masklinn> neat
11:41:31 <desrt> Masklinn; haskell almost does this for you
11:41:41 <fasta> desrt: it does?
11:41:43 <desrt> in ghc 6.6
11:41:47 <Masklinn> keyword's almost ;)
11:41:49 <desrt> you get threading _almost_ for free
11:42:20 <desrt> you basically tell haskell that you want it to do two things at once and it does :p
11:42:26 <Renkin> desrt: sounds cool. what uni?
11:42:28 <Masklinn> really?
11:42:28 * Deformative might buy a ps3 after they bomb.
11:42:31 <desrt> Renkin; mcmaster
11:42:32 <Deformative> And use it for a PC.
11:42:36 <Deformative> It has a cool case.
11:42:40 <Deformative> But it overheats.
11:42:40 <Masklinn> you don't even have to specify which function is part of a process?
11:42:45 <Deformative> So I would need to find a way to fix that.
11:42:55 <therp> yeah, I heard they overheat..
11:43:15 <Masklinn> (i haven't started looking into GHC 6.6 parallelism, I've been more interested in Erlang's take on it for the moment)
11:43:16 <mgsloan> Def, how could you use the SPEs for a PC?
11:43:22 <desrt> Masklinn; i think there is this 'par' function
11:43:29 <desrt> ?type par
11:43:31 <lambdabot> Not in scope: `par'
11:43:34 <desrt> ?hoogle par
11:43:36 <lambdabot> Control.Parallel.par :: a -> b -> b
11:43:36 <lambdabot> List.partition :: (a -> Bool) -> [a] -> ([a], [a])
11:43:36 <lambdabot> Data.IntMap.partition :: (a -> Bool) -> IntMap a -> (IntMap a, IntMap a)
11:43:42 <emu> http://www.macs.hw.ac.uk/~dsg/gph/
11:43:44 <lambdabot> Title: Glasgow Parallel Haskell
11:43:59 <desrt> ^^ that'll calculate the 'a' result at the same time as it calculates 'b'
11:44:09 <desrt> and (i think) won't return 'b' until it has 'a' as well
11:44:22 <desrt> sort of like seq that way except that it does 'a' on another CPU if it can
11:44:26 <Masklinn> emu > I'm not sure it's going to bomb, but it's probably going to have a harder time than the PS2. There are many people who don't believe the Wii is "good enough" (no "next gen" graphics + wiggle + too small == no e-penis size increase) and just don't like the 260
11:44:34 <Masklinn> s/260/360/
11:44:41 <desrt> (or such is my understanding)
11:45:09 <emu> yea i guess, we'll just have to see
11:45:09 <desrt> par :: a -> b -> (a, b) seems like it would be more useful
11:45:12 <desrt> but whatev :)
11:45:13 * emu doesn't have any consoles
11:45:25 <Masklinn> don't like console games emu?
11:45:49 <emu> not a big fan of single player games so much... and i don't need more time-wasting activities :/
11:46:06 <emu> i'm tempted to get a Wii next year maybe
11:46:06 <desrt> or even some special brackets like «a, b» that cause b to be evaluated on the first access to a and vice versa
11:46:10 <Renkin> I don't have a console either, mostly because I've more or less lost faith in new games =)
11:46:17 <Masklinn> well the new generation is much more about multiplayer than the previous ones, both online and in your living room
11:46:17 <Renkin> new commercial games
11:46:49 <Masklinn> renkin > you should check what the DS has to offer, there are really cool (as in strange/different) games on that platform
11:46:55 <Deformative> mgsloan,  dunno.
11:47:08 <Renkin> Masklinn: Yeah, I've actually thought of getting a DS
11:47:18 <emu> my friend has recommended the DS as well
11:47:57 <Masklinn> I've bought one a few months ago (at the euro DSLite launch), first console since the SNES, I don't regret it (even though I'm also playing GBA games on it, SNES' Yoshi's Island for the win)
11:48:07 <Renkin> But it seems the touch screen thing leads to about as many forced gimmicks as new cool ideas
11:48:15 <Masklinn> of course it does
11:48:18 <Renkin> But some games seem interesting, indeed
11:48:28 <Masklinn> just as successful consoles get as many crappy games as good one
11:48:30 <Masklinn> ones
11:48:36 <mgsloan> would be pretty cool, though.  I've thought about it - if people get linux or something running on it and the SPEs (in an efficient fashion, which would probably require very modificied compilers) I'd go for it
11:48:39 <Renkin> Yeah, or a lot more, actually :)
11:48:55 <emu> does the touch screen/pen make your hand hurt
11:48:56 <Masklinn> Castlevania's use of the touchscreen sucked, but Trauma Center's rock for example
11:49:14 <Masklinn> Tetris on the touch screen is horrible (but optional), Meteos is dead on
11:49:33 <Masklinn> emu > not really, depends of the game though when you get sucked in you sometime grip the stylus really hard
11:49:48 <Renkin> I was actually thinking that the DS Castlevania seemed really cool, but that they should've just gotten rid of the touch screen stuff :)
11:50:10 <Masklinn> the stylus itself doesn't make my hands hurt. And i'm using the base stylus, there are bigger/foldable 3rd party stylus which i've heard are much more comfortable
11:50:44 <Masklinn> Renkin > couldn't agree more. Now I'm waiting to see how (or if) they use it on the new Castlevania (PoR) which should be released soon
11:51:09 <Masklinn> mgsloan > I think there's already Linux running on the PS3, that's in fact part of Sony's PR to geeks
11:51:15 <emu> how long do the batteries last
11:51:23 <Masklinn> they also made Linux run on the PS2 btw
11:51:23 <Renkin> If I get a DS, it'd be mist first since SNES, also
11:51:30 <mgsloan> Masklinn - yes, but it just uses the wimpy PPC core
11:51:32 <Renkin> mist=my
11:51:34 <emu> this is funny, because I also had the SNES when I was a kid
11:52:35 <Masklinn> emu > there are 4 light levels (the lowest being the same brightness as the old DS'), on maximum luminosity (which is too much) it has around 8 hours of battery, on the lowest level (which I don't like, but many friends find more than enough) it reaches 18 hours
11:52:40 <Masklinn> when not using WiFi of course
11:52:40 <Renkin> Later I've discovered that the first PS has quite a collection of good games, but most of them weren't known in Europe
11:52:47 <Masklinn> in a word, autonomy is very good
11:53:13 <Masklinn> plus you just have to close the clamshell and it goes into sleep mode
11:53:14 <emu> hmm
11:53:51 <Masklinn> (the battery sucking in sleep varies with the game though, some eat more than others, for example Animal Crossing stays online when in sleep, while New Super Mario completely shuts the console down)
11:54:04 <Masklinn> (sleep mode seems configurable by the game)
11:54:18 <Renkin> Is the new mario any fun?
11:54:54 <Masklinn> it's really good, but far too short and not that original. Many steps under Super Mario World
11:55:12 <Masklinn> I liked it though
11:55:16 <Renkin> Ok. Is it about the same concept as SMW?
11:55:22 <Renkin> Or more linear, or something else?
11:55:24 <Masklinn> more linear
11:55:30 <Renkin> Ok
11:55:38 <Masklinn> but not completely, there are 2 non-necessary worlds you have to unlock
11:55:45 <Masklinn> no yoshis in the game though
11:55:51 <Masklinn> and as I said, the game is far shorter
11:55:54 <Renkin> Ok
11:56:07 <Renkin> From what I saw, it seemed there were no vertical scrolling in the levels
11:56:12 <Renkin> Is that right?
11:56:22 <Masklinn> it's wrong
11:56:29 <Renkin> Ah, ok
11:56:32 <Masklinn> it's just not used that much
11:56:37 <lispy> we need (if we don't already have) an FAQ on this haskell vs. C stuff...i get sick of going over it :)
11:56:39 <Masklinn> but one or two levels are mostly vertical
11:56:54 <Masklinn> I preferred Kirby though, even if it's much more bizarre
11:57:03 <Masklinn> makes really fun use of the stylus and touch screen
11:57:05 <emu> DS mario?
11:57:08 <emu> k
11:57:09 <Renkin> Ok. I might still get a DS. I was very close to buying it once :)
11:57:15 <Masklinn> emu > yeah New Super Mario Bros
11:57:42 <Masklinn> and I've got to buy Yoshi's Island DS, but i'm in the process of replaying the original one (bought a GBA card)
11:58:10 <Masklinn> i've got too many damn games anyway, and don't have the time to play them all. It's pretty horrible
11:58:16 <Renkin> Playing the SNES version on your DS?
11:58:23 <Renkin> Or what?
11:58:45 <emu> ugh, just what i need, more games
11:58:45 <Masklinn> yeah, they re-released many classics including Super Mario World and Yoshi's Island on the GBA, and the DS plays GBA games no problem
11:59:01 <Deformative> http://shootout.alioth.debian.org/gp4/benchmark.php?test=all&lang=ghc&lang2=dlang
11:59:02 <Masklinn> So I'm playing the GBA version of SNES' Yoshi's Island on my DS
11:59:08 <Masklinn> how's that for cool?
11:59:09 <Deformative> Huhhh?
11:59:11 <Renkin> Ok
11:59:19 <lambdabot> Title: Haskell GHC benchmarks | Gentoo : Intel&#174; Pentium&#174;&nbsp;4 Computer Lang ..., http://tinyurl.com/y2gsho
11:59:22 <Deformative> How is D  winning so many benchmarks?
11:59:22 <Renkin> They released NES ones too, I saw
11:59:31 <Renkin> Metroid, mmm :)
11:59:56 <Masklinn> Deformative > D is _very_ fast
12:00:22 <Masklinn> the guys from Digital Mars have one of the best C compilers out there, and went on to build a compiler that's even better for D
12:00:31 <lispy> i could see getting a lot of industry acceptance
12:00:35 <Deformative> But it back ends to GCC,  you know this/\
12:00:36 <Deformative> ?
12:00:40 <Masklinn> plus they can build on C compiler knowledge
12:01:22 <Masklinn> Defo > I think there's a specific D compiler, you don't have to use the frontend to GCC
12:01:26 <Masklinn> not so sure anymore thogh
12:01:28 <Deformative> I thought that haskell was comparable with C.
12:01:28 <Masklinn> though
12:01:29 <Renkin> Hmm, I can't wrap my head around this Replay monad..
12:01:56 <Deformative> Masklinn,  the D specific compiler is used majorly by Windows users.
12:02:06 <Deformative> The frontend to Gcc is reccomended for Linux.
12:02:17 <Masklinn> ok
12:02:31 <emu> i doubt it backends to GCC
12:02:37 <emu> GCC is not a very good C compiler, relatively
12:02:53 <Renkin> In short, I want the Replay monad to run programs and create a trace up to a certain point, and then you can re-run a program with a trace, and it reaches the same point where it was before
12:03:07 <Renkin> So when I run the monad, it needs to return a result, or a trace of what has been done
12:03:39 <Deformative> C pwns haskell in those benchmarks..  =/
12:04:11 <Renkin> The only working type for the monad I can figure out is one that takes a Trace to two new Traces and a result, like Trace -> (Trace, Trace, IO)
12:04:12 <Masklinn> Def > It's a bit bizarre though since D doesn't quite have the same perfs as GCC C (spanks C in Chameneos for example)
12:04:31 <Deformative> Yeah,  it is.
12:04:34 <Renkin> Where one trace is the rest of the trace you gave the monad to start with, and the other is everything it's done
12:04:51 <Masklinn> Def > no, they're using GHC 6.4 and probably the old benches as well, I think people have been working on improving the benches using GHC 6.6 and Data.ByteString
12:04:52 <lypanov> does D have a irc channel?
12:05:02 <Deformative> Yes lypanov
12:05:10 <Deformative> Hmm,  C++ kills haskell too.
12:05:12 <Deformative> Oddd.
12:05:36 <Masklinn> Defo > #d
12:05:40 <emu> i would like to see a boxing match
12:05:41 <Masklinn> couldn't be much simpler :)
12:05:41 <Deformative> It does.
12:05:48 <Deformative> lypanov asked.
12:05:54 <fasta> Deformative: there's more than "performance"
12:05:58 <emu> Haskell vs C++, battle royale
12:06:08 <lypanov> Masklinn / Deformative: thanks :)
12:06:42 <emu> i'm not sure how this would manifest though.  print out a copy of the Report and also the C++ standard and throw them at each other?
12:07:01 <Masklinn> Defo > doesn't on all the boxes, the Sempron sandbox uses GHC 6.6, the P4 doesn't seem to
12:07:04 <Deformative> [14:08] <Deformative> Haskell slower or faster than C++?
12:07:04 <Deformative> [14:08] <Cale> Deformative: hard to say
12:07:11 <jlouis> emu, I am pretty sure we would have different weight classes.
12:07:12 <Deformative> Those benchmarks show it killing it.
12:07:17 <Deformative> Sigh.
12:07:25 <emu> Deformative: no, you are looking at g++ vs ghc
12:07:26 <Masklinn> yes it's hard to say because the Shootout are not real-world benches
12:07:35 <emu> ghc 6.4 iirc
12:07:36 <Deformative> Oh,  oops.
12:07:37 <Masklinn> it's even written on the pages
12:07:46 <Cale> Also, the Haskell solutions on the shootout are still not updated to use the new liraries.
12:07:50 <Cale> libraries*
12:07:55 <lypanov> Deformative: one of the main problems i see with haskell from the outside is that haskell users need to know the optimizations performed by the interpreter inside out to be at all able to produce efficienct code
12:07:59 <Masklinn> emu > GHC 6.6 isn't much better right now, since they're still using the old code
12:08:03 <Cale> (largely, a couple may have been rewritten)
12:08:13 <emu> yes, data.bytestring really helps with the large input sets though
12:08:24 <Renkin> Haskell isn't mainly for speed critical code, though, is it?
12:08:29 <emu> my spoj solutions went up an order of magnitude or so with that
12:08:49 <wolverian> http://paste.lisp.org/display/31238 -- anyone have a better version?
12:09:01 <Cale> emu: I've even heard of things going two orders of magnitude faster :)
12:09:07 <lypanov> does haskell have any nice html templating systems?
12:09:13 <Masklinn> Renkin > it's for all kinds of code, but if the Haskell compiler lacks optimizations on some things you can rely on the FFI. Still much better to be able to stay in the language
12:09:34 <Renkin> Yeah
12:09:46 <Masklinn> and since the likes of Python are usually "good enough" (not meant as dissing python, I love that language), you can infer what that makes of Haskell
12:10:05 <emu> lypanov: Text.HTML?
12:10:20 <Renkin> What I meant is that the fastest language isn't always the best to use. Only when speed matter a lot
12:10:26 <Renkin> matters
12:10:34 <lypanov> i disagree
12:10:53 <Renkin> How so?
12:10:54 <lypanov> python/ruby coders get bogged down in making sane algms when java/c coders just brute force it
12:10:58 <Masklinn> Well "the fastest" is slightly meaningless, depends what you want it to be the fastest at
12:11:11 <lypanov> i'm faster at coding java with good ide support than i ever was at using ruby as ruby is simply too slow
12:11:11 <emu> bogged down in making sane algorithms?
12:11:34 <emu> ruby's implementation sucks in particular
12:11:52 <lypanov> emu: fairly efficient algms have to be used else you're pretty much screwed when you want to start scaling
12:11:53 <lypanov> emu: yeah
12:11:55 <Masklinn> ruby's implementation is pretty much the worst way you could implement a dynamically typed language
12:11:56 <Renkin> Yeah, there's a limit to how slow it should be allowed to be of course
12:12:03 <lypanov> but its no more than 2 times slower than python
12:12:12 <emu> lypanov: of course. the point of high level languages is to make it easier to write sane algorithms =)
12:12:14 <lypanov> java is two orders of magnitude faster....
12:12:26 <lypanov> emu: sometimes one wants to just code... :)
12:12:29 <emu> what you just said just proves that python and ruby are not suitable enough =)
12:12:34 <lypanov> yeah
12:12:37 <lypanov> true
12:12:48 <fasta> Since when did #haskell become #languagewar?
12:13:01 <lypanov> war?
12:13:03 <emu> i'm not sure of the state of IDE support for Ruby.  I used Emacs/inf-ruby and it was ok, but nothing like i'm used to with SLIME.
12:13:07 <Masklinn> lypanov > it is, and it doesn't have stuff like Pyrex or Psyco
12:13:17 <lypanov> Masklinn: pypy :)
12:13:24 <Masklinn> pypy is not quite done :D
12:13:30 <lypanov> true. nevertheless. its godly
12:13:35 * eviltwin_b suspects every language-oiented channel occasionally becomes #languagewar :>
12:13:41 <lypanov> Masklinn: http://blade.nagaokaut.ac.jp/cgi-bin/scat.rb/ruby/ruby-talk/113779
12:13:44 <lambdabot> Title: [ANN] Rubydium 0.1 - Tech Preview, http://tinyurl.com/y2nn7x
12:13:55 <Masklinn> yes, but Pyrex and Psyco are stable and work right now, Pypy is a work in progress
12:14:02 <lypanov> yeah. agreed
12:14:05 <emu> in any case, I'm interested in improvements to Haskell IDEs
12:14:08 <lypanov> and psyco is pretyy dang fast
12:14:21 <Masklinn> depends on what you're doing, but for maths stuff it's impressive indeed
12:14:24 <jlouis> emu, SWANK-GHCI ??
12:14:25 <lispy> emu: which ones have you used? like eclipse-fp or visual haskell?
12:14:35 <emu> I don't have Windows stuff
12:14:44 <emu> I use emacs / haskell-mode / inf-haskell
12:14:49 <lispy> emu: well, eclipse is (kinda) cross poltform
12:14:59 <eviltwin_b> eclipse-fp isn't windows-only
12:15:00 <emu> eclipse chokes my system
12:15:01 <Lunar^> shapr: http://xkcd.com/c191.html <-- this one is for you ;)
12:15:02 <lambdabot> Title: xkcd - A webcomic of romance, sarcasm, math, and language - By Randall Munroe
12:15:05 <Masklinn> lispy > in the sense that it's dog slow on every single platform?
12:15:06 <lispy> it's like java, it gets cross on any platform :)
12:15:26 <Masklinn> lol
12:15:40 <emu> eclipse, in any case, sounds like a fool's errand.  an extensible editor and IDE in a language which sucks balls at extensibility and flexibility?
12:15:43 <eviltwin_b> @quote lispy it's like java, it gets cross on any platform :)
12:15:44 <lambdabot> lispy it's like java, it gets cross on any platform :) hasn't said anything memorable
12:15:49 <eviltwin_b> hm
12:15:53 <emu> its @remember
12:16:00 <eviltwin_b> @remember lispy it's like java, it gets cross on any platform :)
12:16:01 <eviltwin_b> yyeh
12:16:07 <Masklinn> emu > well at the core, Eclipse is a Smalltalker's journey to get back Smalltalk environments in Java
12:16:13 * eviltwin_b is not thinking well today
12:16:23 <Masklinn> that's why it was created: smalltalk guys having to work in java for a living
12:16:34 <emu> yea, i feel bad for them.
12:16:45 <jlouis> Masklinn, haha. Only that eclipse is failing at that
12:16:59 <emu> they have possibly the best language for the job already, and they are forced by perverse industry to use a piece of shit.
12:17:16 <Masklinn> jlouis > well no, considering the difference in flexibility and stuff between Java and Smalltalk, it's actually amazing what they've managed to do
12:17:44 <jlouis> Masklinn, indeed. But there is still a long way to go.
12:17:47 <Masklinn> IntelliJ's still better in my mind (for doing java), but it doesn't try to be extendable to everyhing under the sun
12:18:13 <Masklinn> in fact, Eclipse's a bizarre bastard child of smalltalk environments, Emacs and Java
12:18:14 <emu> i'm just happy I can keep the Java to a minimum. whenever I do have to deal with it, it delivers no end of frustration.
12:18:37 <Masklinn> minus the pinky strain
12:19:10 <newsham> why wouldnt smalltalk programmers work in python for a living? :)
12:19:26 <newsham> python quacks like a duck
12:19:28 <Masklinn> because they get paid for coding in java?
12:19:37 <emu> I see eclipse screenshots sometimes, and I'm absolutely stunned by the amount of crap they have on the screen.  so busy.
12:19:38 <jlouis> quack.el?
12:19:42 <newsham> people get paid for coding in python
12:19:52 <Masklinn> plus Python feels very different than Smalltalk
12:20:04 <newsham> as opposed to java?
12:20:09 <Masklinn> a bit closer to Smalltalk than Java, but not that much, and the IDE support is much wore
12:20:14 <Nafai> emu: Yeah, it is busy.  It is really sucky at 1280x1024; I use Eclipse every day at work
12:20:17 <jlouis> emu, yup. The first thing you do in Eclipse is to kill most windows which are only there for looking cool. Then you begin coding
12:20:18 <emu> Ruby is supposed to be the Smalltalk derivative
12:20:32 <newsham> ruby?  japanese tcl?
12:20:36 <emu> jlouis: ok whew
12:20:37 <eviltwin_b> well, except it took a detour through perl5
12:20:40 <Masklinn> emu > no, Ruby has Smalltalk inspiration, a lot of them, but much more comes from Perl
12:21:05 <nominolo> Scala is a nice combination of Smalltalk and ML
12:21:12 <jlouis> emu, you have the context-window for instance. It will tell you "cool" things like what class you are in, what method you are in. Etc. <die>context-window</die>
12:21:13 <Masklinn> and it fails at many things Smalltalk had, blocks for example, the fact that it actually has keywords, the fact that the implementation blows, the fact that there's no IDE support and it's not image based
12:21:30 <lispy> newsham: i'd be careful calling something "japanese tcl".  It makes you sonud like you might not like the japanese or japanese things
12:21:37 <eviltwin_b> heh
12:21:57 <emu> jlouis: the other thing that bothers me is that it is too mouse-oriented
12:22:01 <Masklinn> there's very few in common between coding in smalltalk and coding in ruby, the main one being that you code *IN* smalltalk, as in you're coding from inside the language itself
12:22:05 <newsham> lispy: hey, unagi is great, but thats no excuse for ruby ;-)
12:22:14 <jlouis> emu, I keep pressing C-a and C-e, hehe
12:22:27 <newsham> (in reality i have nothing against ruby or .jp or even tcl)
12:22:35 <jlouis> and C-x k (My cut) C-y and C-w
12:22:43 <newsham> i always thought itcl was pretty cool
12:22:44 <jlouis> and M-w
12:22:47 <emu> jlouis: my machine at work has a slightly broken mouse so I just installed ratpoison and never touch it
12:22:59 <jlouis> emu, cool. Tried ion?
12:23:03 <emu> not yet
12:23:28 <jlouis> ion is sadly big these days. Ratpoison is small and cool.
12:24:00 <Deformative> KDE
12:24:19 <jlouis> #haskell -> #languagewars -> #wm-wars
12:24:26 <emu> installing ratpoison on FC3 turned out to be a chore, i wonder if there are ion packages. (not that I'm using FC3 of my will)
12:24:39 <eviltwin_b> bah.
12:24:42 <lispy> #haskell -> #languagewar -> #wm-wars -> #haskell-blah
12:24:44 <emu> oo just turned it into linux-wars
12:24:57 <emu> sorry
12:25:01 <emu> let's get back to haskell
12:25:02 <lispy> :)
12:25:02 * eviltwin_b left ##freebsd over *real* xx-wars
12:25:07 <eviltwin_b> this is nothing
12:25:11 <lispy> emu: i think we all got sucked in
12:25:19 * lypanov debates throwing in a "opensolaris!"
12:25:24 <Masklinn> jlouis > how about mentionOfC :: #haskell -> #languageWar -> #OSWar
12:25:27 <jlouis> can lambdabot still do type lookups? I need a function [Word8] -> String doing bytes to Unicode in GHC6.6 via unicode
12:25:37 <eviltwin_b> hoogle?
12:25:39 <lispy> jlouis: ?hoogle
12:25:51 <lispy> ?hoogle [Word8] -> String
12:25:53 <lambdabot> No matches, try a more general search
12:25:57 <jlouis> blah
12:26:03 <lispy> jlouis: well, that one may not be in lambdabot's database
12:26:11 <lispy> jlouis: do you want something like unpack?
12:26:20 <jlouis> unpack from what module?
12:26:28 <Masklinn> by the way is there any HaskellMachine project out there?
12:26:29 <lispy> Data.ByteString
12:26:50 <Masklinn> (akin to the LispM of the olden days)
12:26:51 <lispy> Masklinn: house is probably as close as you'll get
12:27:03 <Masklinn> that's an OS in haskell right?
12:27:10 <lispy> right
12:27:52 <newsham> is there a function for formatting integers to strings?  (ie. fixed width with leading zeros) ?
12:28:04 <jlouis> lispy, not really. unpack/pack from ByteString just does the stuff on single bytes. I need some way to turn a List of Bytes (Word8s) into a String while assuming the Lsit of bytes are unicode
12:28:08 <jlouis> encoded in UTF-8
12:28:08 <eviltwin_b> ?hoogle printf
12:28:10 <lambdabot> Text.Printf.printf :: PrintfType r => String -> r
12:28:10 <lambdabot> Text.Printf :: module
12:28:10 <lambdabot> Text.Printf.hPrintf :: HPrintfType r => Handle -> String -> r
12:28:10 <lispy> newsham: printf
12:28:23 <newsham> is that the only one?
12:28:46 <lispy> jlouis: ah! well, ByteString doesn't officially support unicode, so i think you'll probably want the source and then start looking around
12:28:56 <Deformative> Does house run xorg?
12:28:59 <jlouis> aha!
12:29:01 <lispy> newsham: it's the only one i know of
12:29:07 <Korollary> sjanssen worked on unicode bytestrings iirc
12:29:45 <jlouis> lambdabot, find the unicode darcs repository of sjanssens bytestring hackings
12:29:54 <lispy> ?where fps-unicode
12:29:55 <lambdabot> I know nothing about fps-unicode.
12:30:20 <pejo> Deformative, no, it uses some window system that was presented with hOp in a workshop whcih I don't remember the name of.
12:30:22 <jlouis> damn, you forget too much about lambabot by being away from it for a little over a year
12:30:44 <lispy> Spencer Janssen is actually working on such a class (String) to deal
12:30:45 <lispy> with this, initially to support [a] and Word8 and Unicode bytestrings,
12:30:46 <lispy> as part of his Summer of Code project.
12:31:08 <pejo> Deformative, (while House is fun, I don't think you'd call it ready for production just yet).
12:31:09 <lispy> that's from haskell-cafe@
12:31:15 <Deformative> Yeah.
12:31:25 <Deformative> I was just wondering if there would be screenshots.
12:31:31 <Masklinn> jlouis > like forget that he's still a bot and not a general purpose full fledged half human AI?
12:31:37 <jlouis> aha! It can wait a bit for me though. lispy, thanks.
12:31:40 <Deformative> pejo,  sortof like dragonflybsd.
12:31:55 <Deformative> Just dragonfly makes stuff that can be used by other OSes.
12:31:55 <lispy> jlouis: okay, well summer of code is over for this year
12:32:00 <Deformative> Erm,  fixes stuff.
12:32:04 <lispy> jlouis: so whatever work sjanssen did should be done
12:32:29 <Masklinn> Oh, and is there any kind of counter to the day when Lambdabot will rename itself Skynet and take over the world?
12:32:41 <lispy> Masklinn: funny you should ask
12:32:43 <lispy> ?quote dons
12:32:43 <lambdabot>  too many papers, not enough code
12:32:44 <lispy> ?quote dons
12:32:45 <lambdabot>  yeah, good idea. use C++ as the prototyping language
12:32:47 <lispy> ?quote dons
12:32:47 <lambdabot>  -fglasgow-exts ~= -fhaskell-prime
12:32:48 <lispy> ?quote dons
12:32:49 <lambdabot>  I think Pseudonym should submit some more @free patches,
12:32:51 <lispy> gr...
12:32:55 <Masklinn> lol
12:32:56 <lispy> i'll go find the quote
12:32:59 <pejo> Deformative, there are screenshots of house available.
12:32:59 <emu> need @quote-search
12:33:06 <Deformative> Yeah, I just found them.
12:33:19 <emu> go implement it, and help bring lambdabot closer to skynet!
12:33:23 <lispy> note down this date, people, 13-09-2006. today lambdabot == skynet
12:33:48 <apfelmus> is there a compelling example why one uses CPO's instead of SET as base category for denotational semantics of Haskell?
12:33:53 <lispy> that was the day lambdaweb finally worked
12:33:59 <Masklinn> lambdaweb?
12:34:05 <lispy> ?where lambdaweb
12:34:05 <lambdabot> http://lambdabot.codersbase.com
12:34:20 <Masklinn> oooh
12:34:22 <Masklinn> neat
12:34:46 <chessguy> @paste
12:34:47 <lambdabot> http://paste.lisp.org/new/haskell
12:34:50 <lispy> yeah, i still plan to adapt one of the existing tutorials to use lambdaweb
12:35:02 <lispy> so that you can do the whole tutorial without a local install :)
12:35:07 <Masklinn> mmm
12:35:11 <jlouis> apfelmus, because CPOs has nice properties regarding continuity of functions (ie, fix-points are preserved under functions from a CPO D to a CPO E)
12:35:36 <jlouis> and you want to have fixpoints to talk about the denotation of a recursive function?
12:35:45 <Masklinn> lispy > tryruby style? That would be great
12:35:57 <lispy> Masklinn: i need to check that out
12:36:00 <Masklinn> (http://tryruby.hobix.com/ for those who don't know tryruby)
12:36:01 <lambdabot> Title: try ruby! (in your browser)
12:36:04 <lispy> Masklinn: i've heard of it, but not tried it
12:36:20 <Masklinn> it's not really fast, but works well and is really fun
12:36:49 <lispy> hmm..yes then we need that for haskell
12:37:01 <lispy> show those ruby punks what we're made of ;)
12:37:04 <Masklinn> lol
12:37:33 <jlouis> lispy, if that is what you want, I have a little project ongoing with making HWS more like web.py ;P
12:37:48 <Masklinn> note that tryruby even has shell history (you can use the up and down arrows to navigate your previous and next instructions)
12:38:09 <newsham> addquote <lambdabot> Title: try ruby!
12:38:42 <newsham> so you can make lambdabot say anything in a <title> ?
12:39:58 <apfelmus> jlouis: i know. but i think i somewhere heard that there is something that's absolutely impossible in SET and i'd like to put my finger on that. i mean, semi-trivial fixed point semantics can be done with ad-hoc partial functions in SET, too. i'd like to have a compelling example that SET is a very bad idea.
12:40:01 <newsham> http://www.thenewsh.com/~newsham/x/xx.html
12:40:05 <lambdabot> Title: /quit I'm outta here
12:40:11 <newsham> oh, it prepends title.
12:40:18 * gravity is hoping that the prelude for ruby library gets off the ground
12:40:28 <newsham> why didnt it prepend title when it said "try ruby" ?
12:40:40 <Masklinn> it did
12:40:51 <Masklinn> "lambdabot> Title: try ruby! (in your browser)"
12:40:51 <eviltwin_b> <lambdabot> Title: try ruby! (in your browser)
12:41:29 <newsham> oh, i'm blind or dumb or something
12:42:13 <jlouis> apfelmus, I am bad at Cat. Theory, sorry. A bit too necromantic.
12:42:36 <jlouis> It might be tradition or sheer convenience, but I don't think so somehow
12:43:36 <chessguy> http://cpp.sourceforge.net/?show=25716
12:43:37 <lambdabot> Title: #C++ Pastebin
12:43:46 <chessguy> hey i'm looking for any optimization hacks for this code
12:45:21 <chessguy> don't everyone talk at once :)
12:45:39 <int-e> chessguy: is replacing s' ++ [x] by x:s' feasible? even if you  map reverse  afterwards that should be better than all those ++. I think.
12:45:40 <apfelmus> jlouis: ok. but lawful good necromancers? :)
12:46:04 <lispy> jlouis: well, currently lambdaweb is just a tiny bit of javascript which calls a fast cgi "webservice" which is really an instance of lambdabot :)
12:46:08 <int-e> chessguy: or maybe you can reverse c instead, before running losingCoalitions
12:46:12 <jlouis> apfelmus, hehe. I more thought along the lines "I am a bit too necromantic"
12:46:26 <chessguy> mmmm, i need x at the end
12:46:33 <jlouis> lispy, anything that works ;)
12:47:11 <jlouis> apfelmus, Cat. Theorists are more like Witch-Hunters out to kill Necromancers
12:47:12 <newsham> whats a good way to represent a small number of flags in haskell?
12:47:27 <jlouis> newsham, data flags = FOO | BAR | BAZ
12:47:39 <jlouis> data flag ==
12:47:45 <jlouis> type flags = [flag]
12:47:45 <LoganCapaldo> type FlagSet = [flags]
12:47:46 <jlouis> etc
12:47:53 <lispy> newsham: and if you need to give them numeric values you can derive Enum
12:47:57 <newsham> seems like that wouldnt be very efficient
12:48:05 <newsham> list membership for each flag check?
12:48:07 <chessguy> int-e, you're saying reverse c, run losingcoalitions and use x:s'?
12:48:13 <jlouis> newsham, why not. They are compiled to enums inside
12:48:14 <Korollary> you said small number
12:48:23 <LoganCapaldo> type FlagSet = Set flag ;)
12:48:27 <jlouis> if the set is large, then
12:48:42 <jlouis> type flagSet = Data.IntSet.Set flag
12:48:44 <jlouis> or similiar
12:48:46 <newsham> kor: lots of small list memberships are still not fast.
12:48:47 <int-e> chessguy: yes. I'm not sure whether that's good for you, it'll change the order of the result list, but not, I think, the actual lists.
12:48:52 <jlouis> doh, not intset
12:48:58 <newsham> IntSet?  moight be what I want
12:49:08 <jlouis> not really. Go for Set
12:49:11 <int-e> chessguy: using  x:s'  and then  map reverse  in the end should not change the result however.
12:49:12 <chessguy> mmm, i think that's ok
12:49:15 <lispy> newsham: if you really want you can do it like you would in C
12:49:17 <newsham> so a Set of enums?
12:49:19 <lispy> newsham: using Data.Bits
12:49:26 <chessguy> map reverse?
12:49:31 <jlouis> Data.Bits might be powerful
12:49:56 <newsham> lispy: yeah, was trying to think of a "haskell" way to do it before writing it as I would in C.  (also wanted to know if there was already bitset operations I could build on or use)
12:50:05 <int-e> chessguy: oops. what does   x <- c s',   do?
12:50:06 <apfelmus> jlouis: mh, depends on the point of view... let's say they're extremely lawful :)
12:50:09 <apfelmus> btw, i remembered the location: in "theorems for free", Wadler mentions that there are no naive set-theoretic models for polymorphic lambda calculus
12:50:40 <chessguy> hrmmm, that must be a pasting issue
12:50:42 <chessguy> hang on
12:51:06 <chessguy> oh, should be x <- c \\ s'
12:51:11 <lispy> newsham: you could also do something perverse like data FlagSet = FS (Maybe Bool) ... (Maybe Bool) -- although you'd probably want to use record syntax to name them
12:51:20 <int-e> chessguy: aha. the 'last' should be 'head' then.
12:51:35 <chessguy> last?
12:51:40 <int-e> chessguy: next line
12:51:42 <jlouis> lispy, that looks too perverse to me. A bit like what a daemonologist would do ;)
12:51:56 <chessguy> oh
12:52:00 <int-e> chessguy: errr. wait a second.
12:52:01 <newsham> lispy: hmm..  no need for Maybe's..  just a record of Bools.  i think thats what I want
12:52:10 <int-e> chessguy: the 'last' should be 'head' if you don't reverse c.
12:52:21 <lispy> newsham: oh yeah, i changed my design half thought, you're right, drop the maybe
12:52:29 <int-e> chessguy: that means I'm not sure that reversing c actually works as expected.
12:52:45 <lispy> newsham: unless you need tri-state, it can be handy
12:52:51 <lispy> newsham: to know that something hasn't been set
12:53:11 <newsham> how's GHC about packing a bunch of Bools?
12:53:40 <chessguy> yeah it sounds like a problem to me
12:53:43 <chessguy> but i'm not sure
12:56:05 <int-e> chessguy: hmm. what's the exact specification of this function? you're looking for subsets of c with less than s elements?
12:56:23 <int-e> s/less/fewer/
12:56:59 <chessguy> not exactly
12:57:15 <int-e> x >= (2 * (1 + length s')), hmm.
12:57:15 <chessguy> there's not an easy way to explain it
12:58:45 <chessguy> if s_i is the ith member of the subset (which really isn't a set since the order matters), 2s_i should be at least x_i
12:58:49 <chessguy> (i think that's right)
12:59:23 <int-e> so number 1 can't be in any of the subsets?
12:59:28 <chessguy> right
13:01:14 <int-e> ok, then the function isn't that great.
13:01:48 <chessguy> hmm?
13:01:58 <chessguy> you mean the way it's written isn't that great?
13:02:00 <int-e> instead of the c \\ s'  you could drop leading elements of c as appropriate. (assuming that c is sorted.)
13:02:04 <int-e> yes.
13:02:08 <int-e> that's what I meant.
13:03:30 <chessguy> hmm, drop the length of s' from c?
13:06:38 <int-e> Oh, are you just interested in the final numbers or are you interested in the actual coalitions, too?
13:07:05 <chessguy> well, i'd like the coalitions, but i'll take the numbers
13:07:13 <chessguy> either f' n s or f n
13:07:43 <chessguy> f n is exponential, i have a curve that fits the first 25 points pretty well
13:08:06 <int-e> I think f n is expressible as a sum of binomial coefficients.
13:08:42 <chessguy> hmmm
13:09:24 <chessguy> for s > n/2, f(n, s) is always 0 if that helps
13:10:12 <campusblo> hi
13:10:30 <campusblo> undefinded data constructor
13:10:34 <campusblo> what does that mean?
13:10:44 <apfelmus> chessguy: what does losingCoalitions do exactly
13:10:51 <Masklinn> that you haven't defined a constructor for a data type?
13:10:54 <Renkin> campusblo: that the data constructor wasn't defined :)
13:11:25 <Masklinn> when you create a data type, you have to create both the type and a constructor (to create values of the type you just defined)
13:11:53 <JohnnyL> any of you program web sites in haskell?
13:11:57 <chessguy> it finds the subset of c (which is [1..n]) such that, if s_i is the ith member of the subset (which really isn't a set since the order matters), 2s_i should be at least x_i, the ith member of c
13:12:01 <Lemmih> JohnnyL: Yes.
13:12:13 <Renkin> You might also be trying to do something wrong, and the compiler thinks you're trying to access a data contructor that doesn't exist
13:12:38 <campusblo> thanks renkin
13:12:43 <Masklinn> usually because you're calling something that starts with a maj
13:12:44 <JohnnyL> Lemmih, really hoe does that work for you anyway?
13:12:48 <JohnnyL> how
13:13:19 <lispy> okay, the explanation of the MR in the mail list is nice
13:13:20 <Lemmih> JohnnyL: It works great.
13:13:33 <lispy> i didn't realize it had to do with efficiency
13:13:35 <apfelmus> chessguy: subset or subsets? and what does it mean ('losing coalitions')?
13:13:38 <Masklinn> lispy > ? any url?
13:13:48 <lispy> Masklinn: i'll check, i get it in my gmail
13:14:00 <JohnnyL> Lemmih, do you have a url?
13:14:02 <lisppaste2> int-e pasted "losingCoaltions?" at http://paste.lisp.org/display/31247
13:14:06 <Lemmih> JohnnyL: http://www.catenova.org/
13:14:08 <lambdabot> Title: Catenova - The Ultimate Collection
13:14:09 <JohnnyL> thanks
13:14:27 <Masklinn> lispy > well if you have a thread name i can go check it on google groups too
13:14:43 <Masklinn> (ah no i'm stupid, it's on the ml not a group)
13:14:51 <chessguy> apfelmus, sorry, i should have said it finds the number of subsets of c such that...
13:14:51 <Masklinn> (probably)
13:15:26 <JohnnyL> Lemmih, not exactly what I call a complicated site.
13:15:37 <Lemmih> JohnnyL: Nope.
13:16:28 <lispy> Masklinn: http://comments.gmane.org/gmane.comp.lang.haskell.cafe/17037
13:16:31 <lambdabot> Title: gmane.comp.lang.haskell.cafe, http://tinyurl.com/y3el2f
13:18:04 <campusblo> so im trying to do a simple hellp world in haskell
13:18:08 <campusblo> type h String
13:18:08 <campusblo> h = Hello
13:18:17 <campusblo> i get an error for this
13:18:26 <apfelmus> chessguy: ok. and the meaning?
13:18:38 <Renkin> There are a few errors there
13:18:45 <chessguy> apfelmus, hang on, i'm playing with int-e's function
13:18:55 <campusblo> so how do i define the variable h for hello?
13:19:10 <Renkin> h :: String
13:19:14 <Renkin> h = "hello"
13:19:40 <alar> what is the most generic type for \f-> \x-> f (f x) ?
13:19:43 <campusblo> for a string variable i hae to have the "" then?
13:19:56 <Korollary> campusblo: do you have a good tutorial, like yaht?
13:19:56 <resiak> @type \f-> \x-> f (f x)
13:19:58 <lambdabot> forall t. (t -> t) -> t -> t
13:20:16 * mgsloan 's oleg power rises to .1 : data Foo c a = Bar [c a]
13:20:38 <alar> resiak: there can't be any more polymorphism?
13:20:50 <resiak> alar: f must accept the same type as it returns
13:21:11 <alar> resiak: I feel so, but can't prove
13:21:17 <resiak> lambdabot can :)
13:21:53 <chessguy> int-e, how do i use that to find f' n s?
13:21:57 <alar> but I'm not sure if lambdabot truely returns _the_most_ generic type
13:22:06 <jlouis> If f :: a -> b, then x :: a and also x :: b. Therefore a = b = t and lambdabot is right
13:22:15 <int-e> chessguy: losingCoalitions should be a drop in replacement.
13:22:17 <Renkin> campusblo: check out a tutorial for Haskell basics
13:22:18 <alar> thanks!
13:22:31 <jlouis> alar, something along those lines
13:22:53 <campusblo> whats the difference between type h = string and h :: string
13:23:05 <resiak> jlouis: do you not mean "x :: a and also f x :: a" ?
13:23:14 <campusblo> ive checked the tutorials what i think i need is a list of errors
13:23:35 <jlouis> its probably better to write that x :: a and f(x) :: b and then note that f(x) is an input to f so it must be that f(x) :: a as well. Thus a = b
13:23:38 <jlouis> resiak, exactly
13:23:57 <Lemmih> campusblo: 'type h = string' is not valid Haskell.
13:23:58 <campusblo> and ive seen both in programs but im not sure if the do exactly the same ting
13:23:58 <resiak> jlouis: => a = b QED :)
13:24:06 <chessguy> int-e: looks pretty accurate. let me see how improved the efficiency is
13:24:40 <Lemmih> campusblo: 'type X = Y' means that X is a synonym for Y.
13:24:44 <Renkin> campusblo: if you don't know the difference, you probably didn't read the tutorials very well
13:25:17 <Renkin> and yeah, what Lemmih said
13:25:42 <chessguy> hmm, there is some improvement, but still bogs down for n > 20
13:26:18 <leather> While you're on the topic, here's a general question: when do you use data vs. newtype?
13:26:31 <Renkin> newtype is for one constructor only?
13:26:34 <int-e> chessguy: no surprise :)
13:26:43 <Renkin> that's what I know about it
13:26:46 <chessguy> still, the improvement is welcome. thanks
13:26:56 <Masklinn> chessguy > then maybe the algorithm's at fault? Or you could use an other data structure?
13:26:57 <chessguy> apfelmus, still here and interested?
13:27:04 <leather> Renkin: But you can also use data for that, right?
13:27:05 <apfelmus> of course
13:27:09 <Masklinn> (a btree or something)
13:27:29 <Renkin> leather: Yeah, but I think it's optimized or something. I'm not sure
13:27:31 <Masklinn> (i've not followed on what your problem was btw)
13:28:15 <Renkin> As far as I know, always use newtype when you have one constructor
13:28:18 <chessguy> apfelmus, here's the actual problem i'm trying to solve, in large
13:28:19 <chessguy> http://www.mathbin.net/1991
13:28:23 <Renkin> Flame me if I'm wrong :)
13:28:40 <gzl> so
13:28:57 <gzl> how would one think about implementing a DP algorithm that essentially has to fill in a big matrix iteratively?
13:29:16 <chessguy> this particular problem is trying to find the subsets of the indices for which the sum is always less than q. that is, the sets of indices which form losing coalitions regardless of the actual x_i values
13:29:32 <lispy> gzl: not sure, i've done DP in haskell and i have it around here somewher, but i didn't use a table i don't think
13:29:37 <mgsloan> renkin - if that was true then why not just do those optimization on data statements with one constructor?  I'm not sure of the reason for newtype either though.  I never use it.
13:29:56 <chessguy> e.g., for a committee <x_1, x_2, x_3, x_4> , it can be shown that x_2+x_4 is always < q
13:29:56 <lispy> gzl: have you seen the tying the knot stuff wrt to dynamic programming?
13:30:02 <gzl> lispy: it's fairly easy to implement in an imperative language, but it seems awkward in Haskell
13:30:08 <gzl> but I also don't know Haskell so well
13:30:16 <gzl> no I haven't
13:30:17 <lispy> gzl: haskell is imperative
13:30:37 <lispy> gzl: or rather it has support for first class imperative programming via monads!
13:30:38 <Renkin> mgsloan: Yeah, I was just thinking that myself, actually
13:30:43 <chessguy> Masklinn, it may indeed be that the algorithm is at fault, but it may also be that it's just a computationally hard problem
13:31:02 <chessguy> or both :)
13:31:09 <apfelmus> chessguy: huh? x_1=x_3=x_4=0 ?
13:31:16 <lispy> gzl: http://www.haskell.org/hawiki/TyingTheKnot
13:31:16 <gzl> lispy: ok, fine. I don't know enough about monads to see how to implement this though.
13:31:17 <lambdabot> Title: TyingTheKnot - The Haskell Wiki
13:31:45 <chessguy> apfelmus, note the restriction that x_i >= x_i+1
13:31:59 <apfelmus> chessguy: ah.
13:32:05 <chessguy> err, x_i >= x_(i+1)
13:32:08 <lispy> gzl: i'm not really sure how to help, what do you have so far?
13:33:32 <Renkin> so can anyone explain the difference between newtype and data for one constructor only?
13:33:32 <gzl> lispy: nothing. I could explain the algorithm though. if you're familiar with forward-backward, that's what I'm trying to implement.
13:33:41 <gzl> lispy: I'm just wondering how you would implement it, really, this isn't real code
13:34:13 <gzl> lispy: should I explain the algorithm?
13:34:27 <lispy> gzl: i'm not familiar with forward-backward, i can find the version i wrote for a class and show you but it's probably not the type of algorithm you want
13:34:57 <Heffalump> Renkin: there's a semantic difference to do with strictness
13:35:42 <apfelmus> chessguy: mh. maybe only the extreme cases x_1 >> x_2 >> ... and x_1 = x_2 = ... are of importance.
13:36:12 <astrolabe> Renkin, also I think newtype can only have a single field
13:36:21 <Heffalump> renkin: my notes say "data ! and newtype both have a single _|_, the difference is you can match it against Foo _ with newtype but not data !"
13:36:31 <leather> Renkin: I'm reading up on it right now: http://igitur-archive.library.uu.nl/dissertations/2004-1130-111344/c15.pdf
13:36:33 <lambdabot> http://tinyurl.com/y4j3ja
13:36:59 <Renkin> Ok, nice
13:37:04 <mgsloan> hmm, a newtype is a data statement which only allows one constructor and one value in that constructor.  This allows the data to just be passed around, rather than using a pointer.
13:37:22 <lispy> oh geez
13:37:25 <lispy> this code is terrible
13:37:29 <lispy> i wrote this?! ;)
13:37:37 <chessguy> apfelmus, well the really important question is what are the minimal WINNING coalitions? i'm trying to eliminate all the LOSING coalitions
13:37:58 <chessguy> well, i should say, that's one really important question. there are others
13:39:19 <gzl> lispy: basically, you have three matrices, pi = (pi_i), A = (a_ij), B = (b_ik). given sequence K = [ k_0, ..., k_n ], define alpha_0(i) = pi_i * b_{i,k_0}, alpha_{t+1}(j) = (sum_i alpha_t(i) * a_ij) * b_{j, k_{t+1}). so the output should be the matrix alpha_t(i) for all t,i.
13:40:27 <Renkin> mgsloan: but I use newtype for a function. how can a function be passed around?
13:40:36 <gzl> lispy: where t indexes K.
13:40:50 <astrolabe> Renkin: welcome to haskell :)
13:40:53 <mgsloan> renkin - well, functions are first class.
13:40:56 <int-e> chessguy: hah, f has a very simple closed formula in fact.
13:41:01 <mgsloan> i dunno about memory wise though :P
13:41:02 <chessguy> oh really?
13:41:02 <apfelmus> chessguy: mh. i don't know. if x_1 = x_2 >> ..., then every coalition without x_1 or x_2 will lose.
13:41:15 <Renkin> Yeah, but aren't we talking compiler stuff now?
13:41:16 <mgsloan> the explanation i gave is just what i gleaned from YAHT
13:41:20 <Renkin> I mean, what happens in the machine?
13:41:24 <chessguy> f(n) or f(n,s)?
13:41:28 <int-e> f(n)
13:41:29 <Renkin> I know functions are first class in Haskell :)
13:41:37 <chessguy> what is the formula?
13:41:45 <int-e> f(n,s), too. but f(n) is even simpler.
13:42:08 <lispy> gzl: this is davis-putnam?
13:42:09 <astrolabe> Renkin: I guess on some level, a pointer to a lambda expression is passed around
13:42:17 <Heffalump> mgsloan: I think that explanation is completely wrong
13:42:20 <mgsloan> renkin - i wouldn't be surprised if it's a function pointer in memory
13:42:31 <gzl> lispy: no, it's the forward-backward algorithm. er, just the forward part. but the backward part is very similar.
13:42:43 <mgsloan> Heffalump: well, then yaht needs work...
13:42:47 <Heffalump> in particular the underlying implementation of Haskell datatypes is completely unspecified by the language
13:42:56 <Heffalump> or you're misunderstanding it :-)
13:43:12 <gzl> lispy: I'm completely glossing over what this algorithm is actually doing just for brevity.
13:43:13 <chessguy> you're killing me here :)
13:43:13 <mgsloan> actually i've noticed its rather rough in general, maybe i have an old version (misspellings, sections with headers but no text)
13:43:56 <int-e> chessguy: let me think about this some more. there should be an easy explanation for the formula, let me try to find it.
13:43:56 <apfelmus> chessguy: you should have asked how the formula is derived :)
13:44:01 <JohnnyL> hi
13:44:15 <chessguy> int-e, can i have the formula while you think?
13:44:43 <Renkin> How is Haskell Prime coming by the way?
13:45:20 <mgsloan> "there may be efﬁciency issues with this representation: now, instead of simply storing an integer, we have to store a pointer to an integer and have to follow that pointer whenever we need the value of a MyInt.  To get around these problems, Haskell has a newtype construction." (From YAHT)
13:45:44 <gzl> lispy: is the algorithm clear?
13:46:02 <Renkin> mgsloan: and that can't be right, since a function would allways be a pointer in the machine, right?
13:46:12 <Renkin> always
13:46:37 <mgsloan> good point
13:46:40 <Heffalump> I think that explanation is completely misguided.
13:46:49 <Renkin> unless it passes around a complete table for the function :)
13:46:52 <lispy> gzl: what does DP standfor? I thought we were talking about ways to solve SAT
13:47:14 <gzl> lispy: dynamic programming
13:47:21 <lispy> Oh
13:47:37 * lispy adjusts his mental context
13:47:40 <gzl> sorry. I should have written it out.
13:47:48 <gzl> but my mental context didn't include Davis-Putnam. :)
13:47:58 <lispy> gzl: i don't know much about dynamic programming, i've only read about it a little
13:48:25 <lispy> gzl: i know that tying the knot link i gave you can be used to define the the lookup table
13:48:45 <gzl> lispy: well, here's a general question. to run that algorithm you need to access certain elements in a matrix or list, but it seems like that's slow in Haskell.
13:48:48 <lispy> gzl: laziness is going to be the key to an elegant DP solution
13:48:53 <gzl> yeah, that's what I was thinking
13:48:55 <leather> Re: diff between 'data' and 'newtype': I now understand there are two major language differences:
13:49:06 <gzl> lispy: but that general idea was about as far as I got
13:49:10 <lispy> gzl: well, using (!!) will be slow
13:49:23 <lispy> but, indexing an array won't be slow
13:49:29 <leather> (1) Syntactically: newtype only has one constructor and one field (as was mentioned before).
13:49:36 <gzl> what do you mean by indexing an array?
13:49:40 <gzl> (if not (!!))
13:49:44 <lispy> gzl: esp. if you switch to unsafe indexing once you know the algorithm isn't buggy
13:49:49 <Renkin> gzl: !! is for lists
13:49:49 <lispy> ?type (!!)
13:49:51 <lambdabot> forall a. [a] -> Int -> a
13:49:55 <lispy> ?type (!)
13:49:57 <lambdabot> forall e i. (Ix i) => Array i e -> i -> e
13:50:05 <gzl> oh, you literally mean Array
13:50:07 <gzl> ok
13:50:38 <lispy> gzl: right and we have "Array" if you don't care about mutating the array
13:50:44 <lispy> and MArray if you do
13:50:49 <gzl> oh, and those are fast?
13:50:56 <leather> (2) Semantically: something about 'data A = MkA x' and 'newtype A = MkA x' differ in how x =_|_ is interpreted.
13:51:20 <gzl> lispy: yeah, the arrays/matrices given as input need not be mutated, the output matrix is built up piece by piece.
13:51:20 <lispy> gzl: it can be, using arrays is unfortunately somewhat advanced for beginners in haskell
13:51:22 <alar> (!!) is ~ O(n) and (!) is ~ O(1)
13:51:27 <alar> probably
13:51:51 <gzl> lispy: ok. sounds like a pain in the ass.
13:52:05 <lispy> gzl: well, there is a way to create the lookup table by tying the knot which is good and efficient, but i don't have a good resource for it
13:52:18 <lispy> (using Array)
13:52:28 <Renkin> leather: What does x = _|_ mean?
13:52:28 <gzl> ok. I don't want to waste a lot of time on this, it was just a curiosity. it sounds complicated enough that I don't really want to continue.
13:52:34 <gzl> thanks for the help, though.
13:52:45 <lispy> it's not that bad actually, just takes a new outlook
13:52:54 <leather> That's a good question. ;)
13:52:55 <lispy> and once you see it/get it, it's nice
13:53:18 <gzl> ok.
13:53:18 <newsham> http://en.wikipedia.org/wiki/Bottom_type
13:53:32 <mgsloan> leather - hmm, well YAHT brings up something along the lines of that.  I think it was that even if type A cannot be _|_, with newtype Foo = Foo A, you can have Foo _|_
13:53:42 <apfelmus> chessguy: in the mean time, it looks like you can calculate the table (length (lc [k..n]) s)_{s,k}) recursively. it smells like a classic dynamic programming example.
13:53:46 <newsham> similar to http://en.wikipedia.org/wiki/Bottom_element
13:54:17 <chessguy> apfelmus, huh?
13:54:43 <Renkin> mgsloan: I don't get it :)
13:55:09 <Heffalump> if you define newtype Foo = Foo A
13:55:11 <leather> newsham: I've tried to understand it before, but it never really came together.
13:55:15 <chessguy> apfelmus, i don't get your notation
13:55:21 <Heffalump> that's very similar to defining data Foo = Foo !A
13:55:42 <leather> Heffalump: where ! means strict?
13:55:44 <Heffalump> yes
13:55:54 <Renkin> Ok
13:55:59 <Heffalump> in particular, both types have a single _|_ value (which is semantically equivalent to Foo _|_)
13:56:00 <leather> Heffalump: So, exactly what does that mean, if you don't mind?
13:56:02 <leather> :)
13:56:04 <apfelmus> chessguy: i mean you can calculate the number of subsets reported by (lc [k..n] s) (in dependence of k,s\in Int)
13:56:23 <Heffalump> leather: it means that if the parameter marked with ! is _|_, then the whole value is too
13:56:35 <Heffalump> (operationally, any time the whole value is demanded, any parameter marked with ! will be too)
13:56:39 <chessguy> i'm not sure how k..n helps
13:56:40 <leather> Heffalump: Ah, got it.
13:56:51 <chessguy> or what k is
13:56:59 <Heffalump> ok, so as I said, newtype Foo = Foo A is very similar to data Foo = Foo !A
13:57:14 <emu> lol.  trying michi's spinning cubes example is making my computer emit a strange whining noise
13:57:22 <mgsloan> Renkin - yeah, the _|_ type is subtle, i still don't really get it totally
13:57:36 <Heffalump> the only difference is that if you write some function f which pattern matches on Foo, like this:
13:57:36 <apfelmus> chessguy: you want [1..n] right? and the algorithm only uses the (tails [1..n]) which are the lists [k..n] (with 1<=k<=n)
13:57:40 <mgsloan> heffalump - oh, interesting
13:57:40 <Heffalump> f (Foo x) = ....
13:57:54 <int-e> chessguy: let's find f(n,s). Consider the subsets of {1,...,n}. It's useful to assign a 2D path to each subset: Start at the origin. Now for i = 1..n, go up (0,1) if the i is present in the subset, otherwise go right (0,1).
13:58:00 <Heffalump> then with a newtype, the pattern match will _always_ succeed, no matter whether you feed it _|_ or not
13:58:08 <Heffalump> with a data, the pattern match will fail if you feed it _|_
13:58:15 <emu> @hoogle postRedisplay
13:58:16 <lambdabot> No matches found
13:58:16 <Renkin> Ah
13:58:22 <Heffalump> (and by fail I mean trigger a pattern match error)
13:58:33 <Heffalump> s/pattern match error/error/
13:58:36 <int-e> chessguy: your x_i >= 2i restriction says that this path must never go below x=y.
13:58:38 <Renkin> Can you match against _|_?
13:58:41 <Heffalump> no
13:58:42 <Renkin> Specifically
13:58:45 <leather> Heffalump: Unless, you also have f _|_?
13:58:46 <mgsloan> YAHT should use your definition - much clearer
13:58:58 <Heffalump> leather: no, cos you can't write that
13:59:14 <leather> Heffalump: not even f undefined = ... ?
13:59:16 <apfelmus> chessguy: you can calculate   a k s = length (lc [k..n] s) in terms of a k' s' for k'<=k, s'<= s.
13:59:16 <Heffalump> operationally, pattern matching causes a value to be demanded
13:59:20 <Heffalump> leather: that's invalid
13:59:22 <Renkin> So is _|_ some crazy stuff you never wanna touch? :)
13:59:23 <chessguy> hmm
13:59:25 <LoganCapaldo> case x of undefined -> ... is not matching against bottom then, or that just doesn't work?
13:59:29 <leather> Heffalump: Hmm.
13:59:30 <Heffalump> Renkin: _|_ is there to represent failure
13:59:36 <Renkin> Oh, ok
13:59:38 <Heffalump> semantically, non-termination is represented as _|_ too
13:59:39 <LoganCapaldo> Me slow
13:59:45 <Heffalump> and obviously nothing can detect that
13:59:53 <Renkin> Yeah, true
14:00:16 <chessguy> int-e, ok, i think i'm with you so far
14:00:16 <mgsloan> :type undefined
14:00:17 <int-e> chessguy: note that there are C(a+b, a) subsets of {1..a+b} corresponding to a path going to (a,b).
14:00:17 <Renkin> Unless Turing was wrong :)
14:00:21 <LoganCapaldo> Heffalump: There's the girl I know at Delphi who says she can
14:00:38 <Heffalump> LoganCapaldo: oh, ok then :-)
14:00:49 <Heffalump> I'll just rewrite the semantics of Haskell
14:00:59 <int-e> chessguy: the trick now is this: consider a path violating that restriction. that means it touches the line x = (y-1), somewhere.
14:01:06 <Renkin> Isn't undefined just like error without a message?
14:01:09 <Heffalump> anyway, did everyone who cares understand my explanation of the difference between newtype Foo = Foo A and data Foo = Foo !A ?
14:01:13 <leather> @type undefined
14:01:15 <lambdabot> forall a. a
14:01:22 <Heffalump> Renkin: undefined is just one manifestation of _|_?
14:01:31 <Heffalump> s/?//
14:01:36 <int-e> chessguy: take the first of those touching points, and now *reflect* the rest of the path at the line x = (y-1).
14:01:47 <Renkin> Heffalump: Oh, yeah, I wasn't trying to contradict what you said before
14:01:56 <Heffalump> ah, right
14:02:06 <Renkin> I was just asking whether undefined is basically error without message
14:02:11 <Heffalump> the report says undefined is error with some implementation-specified message
14:02:22 <Renkin> Ok
14:02:26 <int-e> chessguy: if the original path went to (a,b), the resulting path now goes to (b+1,a-1)
14:02:37 <leather> Heffalump: I think I understood. I'm still not sure when you'd want to strictify (?) things in general.
14:02:51 <Heffalump> leather: normally for efficiency reasons
14:02:57 <int-e> chessguy: and if b>=a, this mapping is bijective.
14:03:18 <Heffalump> laziness can cause large unevaluated computations to be left lying around for a long time
14:03:44 <jlouis> if I have case foo of { Bar -> x; Baz -> x} what is the way to fuse Bar and Baz into the same expression x? (Known as an Or-pattern in SML/OCaml land)
14:03:51 <Heffalump> if you increase strictness then you reduce that, at the cost of more time spent on evaluation
14:04:32 <mgsloan> well, if the evaluation will be necessary anyway, its just shifting the time when the evaluation is performed
14:04:38 <Heffalump> yes, but it might turn out not to be
14:04:41 <int-e> chessguy: hmm.
14:04:53 <chessguy2> sorry, wireless dropped out
14:04:55 <chessguy2> the last i saw was [16:58] <int-e> chessguy: and if b>=a, this mapping is bijective.
14:05:09 <int-e> ok, nothing got lost then
14:05:18 <chessguy> sorry about that
14:05:49 <chessguy> i'm going to have to look at your derivation again later. what formula does it lead you to?
14:05:52 <int-e> anyway, finding f(n,s) for s<=n/2 amounts to finding all paths to (n-s,s) and then subtracting the number of paths that touch the x = y-1 line.
14:06:05 <chessguy> oh, there's more
14:06:31 <int-e> sorry. the path goes to (s, n-s).
14:06:44 <apfelmus> int-e: did you mean to go up when i is not in the the subset? i mean 1 is never in the subset
14:07:08 <leather> Heffalump: You worked on abc?
14:07:12 <int-e> the latter number equals the number of paths to (n-s+1, s-1).
14:07:13 <Heffalump> yes
14:07:20 <leather> Heffalump: I'm working on it, now. :)
14:07:23 <int-e> apfelmus: err. yes. doesn't change any counts though.
14:07:35 <Heffalump> cool, what for?
14:07:44 <chessguy> int-e, what do you mean by the latter number?
14:07:56 <chessguy> the number of paths that touch the x=y-1 line?
14:07:57 <int-e> so f(n,s) = C(n, s) - C(n, s-1).
14:08:08 <int-e> chessguy: yes
14:08:29 <chessguy> ok
14:08:40 <leather> Heffalump: I'm refactoring it in feature-oriented style using the  AHEAD toolsuite (http://www.cs.utexas.edu/~schwartz/ATS.html).
14:08:53 <int-e> f(n) is a nice cascading sum, f(n) = C(n, floor(n/2)) - C(n,0) = C(n, floor(n/2)) - 1.
14:09:07 <apfelmus> true. i just got stuck on that.
14:09:18 <Heffalump> ah. why? :-)
14:09:23 <chessguy> C(n, s) is n choose s?
14:09:28 <int-e> yep
14:09:43 <int-e> I'm going back from paths to subsets for that
14:09:58 <int-e> a path to (a,b) has (a+b) steps, b of which are upward steps.
14:10:02 <leather> Heffalump: Well, it started out as a class project. Then, the prof thought it might turn into a paper.
14:10:23 <leather> Heffalump: Really, though, I think we can make abc more extensible than it is right now.
14:10:36 <Heffalump> that sounds good, in what ways?
14:10:38 <apfelmus> chessguy: what i don't get is how this relates to your original problem ...
14:10:38 <int-e> (these paths are, of course, not necessary, but they help the intuition a lot.)
14:11:05 <chessguy> wow
14:11:09 <int-e> apfelmus: did you see chessguy's original quote?
14:11:19 <int-e> apfelmus: err, paste
14:12:17 <leather> Heffalump: The way in which we're refactoring allows you to do several things. Users (i.e. developers) can pick and choose the AspectJ  features they want to include in the language.
14:12:19 <apfelmus> maybe. depends on what original is. i meant the general coalition problem
14:12:19 <chessguy> that's really cool
14:12:41 <leather> Heffalump: Extensions are also easier to develop (less boilerplate).
14:12:59 <int-e> chessguy: this problem is strongly related to counting binary trees, or the number of ways to write n pairs of brackets in a balanced way.
14:13:02 <chessguy> apfelmus, if i can find the losing coalitions, i can start looking at sets of winning coalitions
14:13:10 <Heffalump> how have you avoided the boilerplate? (that's certainly one of the weaknesses)
14:13:26 <Heffalump> I don't really think being able to pick and choose AspectJ features is either useful or difficult, TBH
14:13:32 <chessguy> int-e, you mean the number of losing coalitions problem, or the overall problem?
14:13:36 <int-e> chessguy: the second amounts to finding f(2n, n)
14:13:50 <Heffalump> perhaps we should take this to msgs, it being nothing to do with Haskell
14:14:37 <apfelmus> chessguy: sure. i didn't get the translation (x_1,...) -> [1..n]
14:15:34 <int-e> chessguy: oh wait. you probably want C(n, floor((n-1)/2)). I made an off-by-one error.
14:15:49 <chessguy> int-e, i think your formula was right
14:16:04 <int-e> chessguy: is {2,4} a losing coalition of {1,2,3,4}?
14:16:10 <chessguy> yes
14:16:22 <int-e> ok. then this is all correct.
14:16:55 <chessguy> i think your original formula was fine
14:17:51 <int-e> Sorry. That was a confusing way to say what I wanted to say. I meant that I didn't make a mistake after all.
14:18:00 <chessguy> ok
14:19:02 <chessguy> now all i have to do is prove that this way of calculating losing coalitions really gets them all
14:19:14 <chessguy> well, that's not ALL i have to do
14:19:16 <apfelmus> chessguy: ah, (x2+x4) always < (x1+x2+x3+x4) /2
14:19:44 <chessguy> apfelmus, right
14:19:53 <chessguy> umm, <=
14:19:53 <apfelmus> chessguy: why don't x1=x2=1/2 and x3=...=0 dominate?
14:20:24 <chessguy> hmm?
14:20:59 <emu> is there some "normal" glut way to terminate the program when the window is closed?
14:21:03 <Renkin> It's never possible to safely transform some result in the form of IO a to just a, right?
14:21:03 <apfelmus> chessguy: i mean for the special case x1=x2=1 and x3=..=0, every winning coalition must incorporate x1 or x2. so this holds in general, too
14:21:10 <chessguy> x_i should be an integer
14:21:48 <chessguy> ok, i agree about those specific x values. i'm not sure what you mean by 'in general'
14:21:52 <apfelmus> chessguy: integer is unimportant, you can normalize to x1+x2+... = 1
14:22:13 <chessguy> well, ok
14:22:40 <apfelmus> chessguy: i mean that there is no coalition not involving x1 or x2 that can always win regardless of xi because there is a counterexample.
14:23:05 <int-e> apfelmus: {1,2} is not a losing coalition.
14:23:20 <chessguy> right, int-e
14:23:29 <int-e> apfelmus: (by chessguy's calculation)
14:23:59 <chessguy> 1 can never be a member of a losing coalition
14:24:11 <chessguy> {2, 3} is also never a losing coalition
14:24:51 <int-e> never? not always?
14:24:52 <newsham> > (first (+ 4)) (2,3)
14:24:53 <apfelmus> int-e: yes?
14:24:54 <lambdabot>  (6,3)
14:25:07 <apfelmus> chessguy: but {2,4} may lose
14:25:08 <chessguy> int-e, right.
14:25:20 <int-e> apfelmus: so an example where it's a winning coalition proves nothing. what is your point?
14:25:43 <int-e> and {2,4} will always lose. so it's a losing coalition.
14:26:24 <apfelmus> int-e: i thought chessguy was mainly interested in winning coalitions
14:26:24 <apfelmus> loosing coalitions seem to be more interesting
14:26:45 <int-e> apfelmus: losingCoalitions returns those coalitions which always lose, no matter what the weights of the voters are.
14:27:37 <int-e> the weights are subject to being sorted of course.
14:27:51 <chessguy> which we can assume without loss of generality
14:28:21 <apfelmus> int-e: yes (is inteded to do). yes. i thought about winning coalitions. which seem to be scarce compared to loosing coalitions.
14:29:00 <Renkin> since the trace of a program is the results of the actions of the program (a in IO a), it would never be possible to have a trace outside bind/do in a program.. does that reasoning sound correct?
14:29:33 <chessguy> winning coalitions depend on the weights
14:30:06 <chessguy> which is why they're harder to find.
14:30:18 <chessguy> but if i can eliminate losing coalitions, that's a step in the right direction
14:30:39 <int-e> this is strange though. there are some obvious winning coalitions (assuming positive weights)
14:30:56 <chessguy> int-e, like what?
14:31:18 <int-e> anything that has {1..n/2+1} as a subset
14:31:31 <int-e> (where division rounds down)
14:31:57 <chessguy> ermm
14:32:03 <chessguy> can you give a more concrete example?
14:32:08 <apfelmus> chessguy: ah. you eliminate absolute losing coalitions because that eliminates test cases for relative winning coalitions.
14:32:11 <int-e> n=7. {1,2,3,4}
14:32:14 <chessguy> remember, q can be as much as the sum of x_i
14:32:37 <chessguy> that's not a winning coalition
14:32:54 <int-e> ah, but I was assuming that q = sum of weights / 2
14:33:13 <apfelmus> int-e: i think the condition is also necessary (for q=1/2). otherwise x1=x2=...=xn is a counterexample.
14:33:15 <chessguy> ah, but that's not necessarily true
14:33:23 <chessguy> it's greater than that
14:33:31 <int-e> aha. ok then.
14:34:00 <int-e> then there's no obvious winning coalition because you can even prevent {1..n} from winning
14:34:02 <chessguy> i mean, unless you can show that we can fix q at that and still guarantee that we can get an optimal result
14:34:19 <chessguy> int-e, right. that's why i said, the set of winning coalitions depends on the weights
14:35:49 <apfelmus> chessguy: mh. there are only polynomial many loosing coalitions compared to an exponential number of total coalitions. i don't know whether filtering them really helps
14:36:24 <chessguy> umm, the number of losing coalitions is exponential in n
14:36:28 <chessguy> int-e's formula proves that
14:37:20 <chessguy> ermm, C(n,r) is exponential, right?
14:37:31 <apfelmus> sorry. i thought r was fixed.
14:37:54 <chessguy> no, r goes from 1 to floor(n/2)
14:40:54 <apfelmus> chessguy: but they're still rather few. its roughly the 1/((n/2)!)^2 part of n!.
14:40:55 <int-e> well C(2n, n) ~ 2^(n+1) / sqrt(2 pi n)
14:42:01 <int-e> so you save testing about 2/sqrt(pi n) of all subsets. the overhead is probably too large to make it worth the effort.
14:42:08 <newsham> I wish record update functions were first class functions.
14:42:28 <int-e> except, ironically, for small n :)
14:42:29 <lispy> newsham: well, the record names are
14:42:35 <newsham> I would love to   {foo=bar} . {blah=stuff} . somefunc
14:42:42 <lispy> ah, right
14:44:04 * LoganCapaldo was sitting here trying to figure out how you could do ({}) foo bar
14:44:14 <LoganCapaldo> But newsham's sysntax is much saner :)
14:48:27 <chessguy> well, i'm looking at cases where n is small to determine overall patterns, so it does help me
14:48:53 <apfelmus> chessguy: you have concrete weights?
14:48:53 <chessguy> (particularly having the actual subsets)
14:48:59 <chessguy> apfelmus, no.
14:49:10 <apfelmus> where's the pattern, then?
14:49:18 <chessguy> i'm trying to find an algorithm to construct the weights given a set of power indices
14:50:17 <apfelmus> mh. i don't know. feels like an entirely different problem to me.
14:50:49 * chessguy shrugs
14:51:07 <apfelmus> but for winning coalitions and small integers x_i, you may want to use the standard knapsack dynamic programming
14:51:28 <newsham> in general for records I often want settors (\x o -> o {foo=x})  as {foo=},  first class set functions  (\x -> {foo=x}) as {foo=x}  and updators (\f o -> o {foo= f (foo o)})  (syntax?)
14:51:56 <newsham> err the second should be (\x o -> o {foo=x})
14:52:05 <chessguy> i really don't like the term winning coalitions
14:52:15 <chessguy> unless you talk about a specific set of weights
14:52:42 <eviltwin_b> newsham: you can define such a thing, just can'
14:52:48 <eviltwin_b> t use "record" syntax
14:53:00 <newsham> yah, I just did define them in my last line.
14:53:16 <chessguy> ok, dinner's ready
14:53:17 <newsham> the problem is writing  \x o -> o {foo=x}   is more verbose and harder to read than just {foo=x}
14:53:20 <chessguy> i'll be back later
14:53:24 <newsham> err i mean {foo=}
14:53:34 <eviltwin_b> yeh
14:54:46 <apfelmus> i'm going to bed. int-e, see you :)
14:55:26 <Renkin> is there a "third" variant like fst and snd?
14:55:50 <nornagon> Renkin: it's trivial to write your own if there isn't
14:56:00 <nornagon> thd (_,_,x) = x
14:56:20 <Renkin> Yeah, I know
14:56:34 <Renkin> But I thought, if there already is one, why not use it
14:56:54 <nornagon> fair enough
14:56:54 <int-e> I've seen fst3, snd3 and thd3 somewhere. I forgot where, PreludeExts maybe?
14:57:09 <newsham> ewww :)
14:57:10 <int-e> Not in any standard library.
14:57:16 <Renkin> Ok, I'll just write them myself :)
14:57:30 <Renkin> I didn't think of that you actually need new ones for fst and snd as well
14:57:59 <int-e> newsham: eww? it has to coexist with fst and snd ... I guess you could put it in a type class.
14:58:34 <int-e> newsham: but that's not an option for the standard libs I think.
15:00:34 <kpreid> class AtLeast2 (a b c) where { fst :: a -> b; snd :: a -> c }; class AtLeast3 (a d) where { trd :: a -> d }; ...
15:01:53 <int-e> bad syntax.
15:02:08 <kpreid> oh?
15:02:20 <int-e> class AtLeast2 a b c where ...
15:02:27 <kpreid> oh, right
15:02:36 <kpreid> I was thinking of the wrong case
15:02:46 <xerox> class Atleast2 a b => AtLeast3 a d
15:02:51 <xerox> well, b c.
15:03:14 <kpreid> yep
15:03:17 <xerox> polyvariadic classes?
15:03:23 <int-e> Atleast2 a b c => Atleast3 a b c d  maybe.
15:03:38 <int-e> Atleast2 a b c => Atleast3 a d  should be undecidable.
15:03:45 <xerox> TypeCast TypeCast' TypeCast'' could probably do it.
15:04:02 <xerox> the SilverBullet™
15:04:18 <xerox> please don't drag me into this! :)
15:04:26 <int-e> oh, and you'd need fundeps to actually use the stuff
15:04:39 * xerox ducks shuts the eyelids
15:04:42 <xerox> 'and'
15:04:48 <int-e> class Atleast2 a b c | a -> b c where
15:06:18 <int-e> I like fst and snd as they are actually
15:22:23 <jeroeng> Is there someone in here who can give me some pointers on how to handle template haskell?
15:28:14 <dons> moin
15:28:24 <dons> jeroeng: you've seen the TH website?
15:28:56 <jeroeng> Which one?
15:29:27 <jeroeng> dons: http://www.haskell.org/th/ ?
15:29:29 <lambdabot> Title: Template Haskell
15:29:42 <dons> yep
15:29:50 <jeroeng> Seen that one :)
15:30:12 <jeroeng> I'm trying to figure out whether something is possible in an elegant way in TH
15:30:35 <dons> ok. TH is a little rare in use, so you might have better luck asking your problem on haskell-cafe@haskell.org
15:30:48 <jeroeng> Ah
15:31:04 <jeroeng> Howcome TH is not that popular?
15:34:22 <dons> i guess the need for compile time metaprogramming isn't so great, when you've got higherorder functions and laziness. TH is also a bit complex
15:34:51 <dons> however, it is used. but the tricky details are best asked on the mailing list, i think.
15:35:23 <glguy> Is there some trick to using unsafeCoerce# in GHCi? GHCi thinks that I'm calling "unsafeCoerce" and "#" separately
15:35:32 <dons> :set -fglasgow-exts
15:35:36 <glguy> ahh
15:35:36 <dons> ?uptime
15:35:37 <lambdabot> uptime: 2d 14h 20m 10s, longest uptime: 9d 2h 23m 6s
15:35:43 <dons> ?users
15:35:44 <lambdabot> Maximum users seen in #haskell: 276, currently: 259 (93.8%), active: 34 (13.1%)
15:35:45 <jeroeng> A shame, I thought template haskell was quite commonly used. So using it doesn't improve readability I guess :)
15:36:29 <dons> yeah, that's true.
15:36:37 <dons> for some problems though its exactly what is needed
15:36:42 <glguy> should this have happened?
15:36:42 <jeroeng> dons: What about generic Haskell?
15:36:45 <glguy> Prelude GHC.Base> unsafeCoerce# (3.14159 :: Float)
15:36:45 <glguy> <interactive>: internal error: stg_ap_v_ret (GHC version 6.6 for i386_unknown_openbsd) Please report this as a GHC bug:  http://www.haskell.org/ghc/reportabug
15:36:47 <lambdabot> Title: 1.2. Reporting bugs in GHC
15:36:48 <glguy> Abort trap (core dumped)
15:37:01 <glguy> I recognize that I didn't tell it what type to coerce to
15:37:04 <glguy> but an abort?
15:37:32 <dons> glguy: so it probably cast it to a num a => a, and then tried to execute that...
15:37:59 <dons> jeroeng: generics are used moderately widely, and there's no reason not to use them :)
15:38:12 <dons> using the generic haskell compiler is probably a bit rarer
15:38:23 <jeroeng> Ah, but still it is used
15:38:35 <dons> particularly SYB-style generics
15:38:42 <dons> and stuff in Data.Generics
15:39:02 <jeroeng> Good, just trying to figure out which methods are mose common :)
15:41:34 <jeroeng> dons: The generic haskell you meant is the same one as mentioned on www.generic-haskell.org ?
15:45:47 <dons> some of the techniques there are in ghc, i think. but that compiler itself is not widely used. there's a new project to unify all the various generics work, which will probably help improve the use and acceptance of the various generics extensions
15:47:00 <dons> more info here, http://www.haskell.org/haskellwiki/Libraries_and_tools/Generic_programming
15:47:02 <lambdabot> Title: Libraries and tools/Generic programming - HaskellWiki, http://tinyurl.com/y8sz9o
15:47:18 <jeroeng> Interesting. There's a whole lot going on I suppose. Fairly confusing to a newb like me :)
15:48:08 <dons> i'd stick to the generics that you can get at from a standard ghc installation, unless you have a particular need to use something from a non-standard compiler
15:48:09 <lisppaste2> glguy pasted "FastInvSqrt from reddit linked article" at http://paste.lisp.org/display/31255
15:49:34 <fik> glguy, :)
15:50:35 <newsham> ?type unsafeCoerce#
15:50:37 <lambdabot> Not in scope: `unsafeCoerce#'
15:50:49 <newsham> :(  lambdabot cant do fastinvsqrt :(
15:50:56 <glguy> unsafeCoerce# :: forall t b. t -> b
15:51:35 <newsham> what about the one the other guy hinted at that is precise to 48bits?
15:52:16 <jeroeng> Thanks for the good advice, dons
15:53:14 <newsham> "I wrote a very fast (pipelineable) & accurate invsqrt() 5+ years ago, to help a Swede with a computation fluid chemistry problem." - terje
15:53:51 <newsham> "The swede needed at least 48 significant bits in his result ..."
15:54:48 <fik> @doc Data.Bits
15:54:49 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Data-Bits.html
15:57:55 <fik> @help plugs
15:57:55 <lambdabot> help <command>. Ask for help for <command>. Try 'list' for all commands
16:04:06 <dons> mmm. more new haskell books, Roman V. Dushkin. Functional Programming in Haskell. Moscow: DMK Press, 2006. 608 pp., http://haskell.org/haskellwiki/Image:Fp_in_haskell.gif
16:04:09 <lambdabot> Title: Image:Fp in haskell.gif - HaskellWiki, http://tinyurl.com/wzoxe
16:09:55 <Renkin> can you do case inside do?
16:10:34 <jlouis> Renkin, sure
16:10:39 <Renkin> do res <- prog and pattern match on res
16:10:56 <Renkin> ok, it works just like outside do?
16:11:06 <jlouis> you just start a case under your res yes
16:11:07 <Renkin> I guess I could just try it :)
16:11:11 <Renkin> ok, thanks
16:11:52 <bd_> @pointless \n -> "The square of " ++ (show n) ++ " is " ++ (n * n)
16:11:54 <lambdabot> ("The square of " ++) . liftM2 (++) show ((" is " ++) . join (*))
16:12:59 <jlouis> dons, you must know this: utf8Decode :: [Word8] -> String.. does this exist? hoogle says no ;)
16:13:35 <dons> there's a function in darcs to do this, and in jhc too i suspect
16:13:38 <dons> maybe even in ghc base now
16:13:47 <pejo> dons, is that book in english?
16:13:53 <dons> pejo: russian
16:14:06 <pejo> Ah, my russian is a tad rusty. *cough*
16:14:17 <jlouis> dons, ah, in darcs. That may be the place to look. Thanks.
16:14:29 <dons> > do x <- getLine ; case x of [] -> error "yow!" ; (x:xs) -> return x
16:14:31 <lambdabot>  <IO Char>
16:18:35 <alar> russian book on haskell? are there any?
16:18:52 <alar> ah, dushkin
16:19:06 <alar> darkus@livejournal.com
16:19:33 <alar> I think he got his several-years-old lectures published
16:23:30 <dons> alar: and what's this one: http://photos1.blogger.com/blogger2/4419/3608/1600/061108_011148.0.jpg coming out soon?
16:23:32 <lambdabot> http://tinyurl.com/ydqkln
16:23:54 <dons> "<ADEpt> dons: indeed, and it's not that small - recent haskell book (in russian!) is already pre-ordered in amount of 200 copies"
16:23:59 <alar> dons: this should be translation
16:24:10 <dons> yeah
16:24:33 <alar> secon edition
16:24:54 <alar> that explains why I think that the title is known to me
16:25:30 <dons> dushkin's book is on the haskell.org books page now, http://haskell.org/haskellwiki/Books_and_tutorials#Textbooks
16:25:32 <lambdabot> Title: Books and tutorials - HaskellWiki, http://tinyurl.com/vqzky
16:28:53 <Renkin> I want the return function for my monad to work only with readable and showable a's, how do I do that?
16:29:17 <Renkin> Could not deduce (Show a, Read a) from context..
16:29:41 <dons> your monad will have to be constrained to read and show, i suspect
16:29:55 <Renkin> Yeah, where do I define that?
16:30:21 <dons> hmm, but you want to constrain the type of the value you wrap up in the monad. hmm..
16:30:21 <Renkin> In the "instance" block somewhere?
16:30:22 <LoganCapaldo> class (Read a, Show a) => Renkin a where right?
16:30:33 <LoganCapaldo> Or am I bonkers?
16:30:56 <LoganCapaldo> I'm bonkers aren't I
16:31:05 <Renkin> LoganCapaldo: I'd need it in instance instead of class
16:31:18 <dons> so the problem is that: return      :: a -> m a
16:31:19 <Renkin> dons: Well, what I really need..
16:31:36 <dons> so you can't constrain 'a' to Show/Read by changing the type of return
16:31:42 <Renkin> ...is the a to be showable, so I can write it to a file.
16:32:02 <dons> you want return to write to a file?
16:32:13 <Renkin> No
16:32:15 <dons> ah ok. good!
16:32:43 <dons> writeValue :: (Show a, Read a) => a -> IO () -- then
16:32:43 <gravity> Why is the isLower function not in scope in ghci automatically? Isn't it part of the prelude?
16:32:50 <dons> its in Data.Char
16:32:54 <dons> :m + Data.Char
16:32:58 <dons> ?hoogle isLower
16:32:59 <lambdabot> Char.isLower :: Char -> Bool
16:33:12 <Renkin> Well..
16:33:13 <gravity> Lovely, thank you!
16:33:34 <Renkin> I'm making that trace monad, if you remember from yesterday
16:33:35 <Renkin> Replay
16:33:49 <dons> yes
16:33:59 <Renkin> And every result of every action should be saved to a trace
16:34:11 <Renkin> And the trace needs to be writable to a file
16:34:12 <dons> ok.
16:34:36 <dons> right. that's good. so your Trace type can be an instance of Show, and defined to be recursive in its elements.
16:34:43 <Renkin> So inside return, I save (show x)
16:34:56 <dons> can you paste the code?
16:35:04 <Renkin> sure, sex
16:35:05 <Renkin> haha
16:35:06 <Renkin> sec
16:35:11 <dons> (oh, this was a homework assignment though, right? ...)
16:35:19 <Renkin> yeah
16:35:30 <Renkin> so you can't help me too much =)
16:35:32 <dons> yep
16:35:52 <Renkin> but I thought this is very much a detail problem
16:35:55 <dons> when do you need to write to the file? at the end? or incrementally?
16:36:34 <Renkin> At the end, probably
16:36:48 <Renkin> I don't remember it from the specification very well
16:36:50 <Renkin> ?paste
16:36:50 <lambdabot> http://paste.lisp.org/new/haskell
16:37:01 <dons> ok. good. so you can build up the trace by adding values to a list carried by the monad
16:37:06 <dons> then at the end dump them out
16:37:32 <Renkin> ah, yeah, in the run function?
16:37:47 <Renkin> that sounds nice, I think
16:38:45 <Renkin> yeah, it doesn't need to be a trace yet, that's right
16:39:09 <Renkin> or wait
16:39:23 <Renkin> then I could create a trace that I can't write in the end?
16:39:34 <Renkin> I'll paste the code
16:40:17 <Renkin> paste.lisp.org won't load
16:40:21 <dons> yeah seems down
16:40:37 <dons> bit flakey the last few days
16:40:51 <Renkin> ok. can I pase three lines here?
16:41:00 <lispy> dons: that sonuds like the way my code gen monad works in helisp
16:41:17 <lispy> build up the asm file that needs to be emited and then dump it out at the end
16:41:17 <dons> Renkin: sure
16:41:25 <Renkin> rReturn :: (Show a, Read a) => a -> Replay q r a
16:41:25 <Renkin> rReturn x = MkReplay f
16:41:25 <Renkin>         where f tr = return (tr, [Result (show x)], (Right x))
16:41:55 <dons> yeah, or you could even use an existential, and avoid the show
16:42:08 <dons> data Results = forall a . Show a => Result a
16:42:20 <dons> [Result x] -- would be ok
16:42:25 <dons> and at the end you can show the list
16:42:36 <Renkin> So what happens if it isn't showable?
16:42:43 <Excedrin> 3 lines is fine
16:42:43 <dons> you can't put it into a Result
16:42:52 <Renkin> Ah, ok.
16:43:06 <Renkin> So the problem here is that it doesn't accept (Show a, Read a)
16:44:27 <dons> can't see why unless we see how you're using rReturn
16:45:41 <Renkin> I'm not using it yet
16:45:59 <Renkin> instance Monad (Replay q r) where
16:45:59 <Renkin>         return = rReturn
16:45:59 <Renkin>         (>>=)  = rBind
16:46:31 <dons> ok, so the problem will be the extra constraint you add to return. tricky
16:47:02 <Renkin> Yeah, quite
16:49:18 <Renkin> I guess I could just not save what return does to the trace
16:49:28 <fax> hi
16:49:30 <Renkin> It won't be needed in practice
16:49:37 <Renkin> I think
16:49:40 <fax> regarding Parsec "The library "embeds" a parsing language into Haskell. The user of the library can specify a parser's grammar directly in Haskell code!"
16:49:53 <fax> is it possible to write your own language extensions similar to parsec.. in haskell?
16:50:16 <Renkin> Or, well, no, that wouldn't be good
16:50:38 <resiak> fax: Parsec's written in Haskell.
16:50:53 <resiak> fax: It's just a library.  So yes, sure you can.
16:51:03 <fax> nice :D
16:51:19 <Renkin> The course I'm taking now is like 50% about embedded languages in Haskell :)
16:51:44 <alar> I saw exampleof embedded assembler
16:51:44 <mgsloan> fax - DSL is used rather loosely in regards to haskell.  You have enough flexibility with monads and your own operators that you may make something which appears to have a new syntax
16:51:48 <alar> :)
16:52:13 <fax> wow
16:52:56 <alar> the funniest thing was forward jumps that wouldn't be resolved without laziness in language
17:03:01 <Axioplas1> how in ghci can I set a type constraint ? (since I think that all must be done on one single line...)
17:03:15 <alar> > (1::Int)
17:03:16 <lambdabot>  1
17:03:23 <alar> this?
17:03:41 <alar> > (+) (1::Int) 1
17:03:43 <lambdabot>  2
17:04:21 <Axioplas1> ok htanks
17:04:49 <newsham> ?check \n -> 0 * (n :: Int) == 0
17:04:51 <lambdabot>  OK, passed 500 tests.
17:05:51 <Renkin> Hey, is that quick check?
17:06:04 <alar> @help check
17:06:04 <lambdabot> check <expr>
17:06:04 <lambdabot> You have QuickCheck and 3 seconds. Prove something.
17:06:11 <Renkin> Nice
17:06:20 <Renkin> Koen is my teacher
17:06:42 <newsham> ?check \n -> (n :: Int) + 1000 > n
17:06:44 <lambdabot>  OK, passed 500 tests.
17:06:51 <newsham> tsk!
17:08:31 <newsham> > (2147483392 :: Int) + 10000
17:08:33 <lambdabot>  -2147473904
17:08:51 <Renkin> > (2147483392 :: Integer) + 10000
17:08:52 <lambdabot>  2147493392
17:09:01 <newsham> yah, but thats not what I was ?check'ing
17:09:12 <alar> ?check \n -> (n :: Int) + 2147493392 > n
17:09:13 <lambdabot>  Falsifiable, after 0 tests: -2
17:09:14 <Renkin> Oh
17:10:16 <newsham> ?check \n m -> let s = abs (n :: Int) + abs m in s > n && s > m
17:10:18 <lambdabot>  Falsifiable, after 1 tests: 0, 0
17:10:30 <newsham> ?check \n m -> let s = abs (n :: Int) + abs m in s >= n && s >= m
17:10:32 <lambdabot>  OK, passed 500 tests.
17:10:47 <newsham> i guess it doesnt generate many large values
17:12:14 <Renkin> It starts with low values and increases the size
17:12:24 <mgsloan> yeah, the checkers generators actually aren't very good.  Doesn't do extreme cases, and the Char generator ranges all over unicode, with no specific atention to ascii and stuff like '\n'
17:13:18 <Renkin> But it's pretty easy to write your own generators
17:13:23 <mgsloan> yes
17:13:55 <newsham> i think that using a few of the edge cases would give good bang for buck
17:14:03 <Axioplas1> > (k::[Int]) = return 42
17:14:04 <lambdabot>  Parse error
17:14:25 <araujo> > k <- return 42
17:14:25 <lambdabot>  Parse error
17:14:33 <newsham> > let k = (return 42 :: [Int}) in k
17:14:34 <lambdabot>  Parse error
17:14:38 <mgsloan> still, the actual framework is relatively small.  most of its value is even in the predefined generators, so they should be quality generators
17:14:39 <araujo> > do k <- return 42; k
17:14:40 <lambdabot>  add an instance declaration for (Num (m b))
17:14:48 <mgsloan> (iirc the framework is small...)
17:15:08 <newsham> > let k = (return 42 :: [Int]) in k
17:15:09 <lambdabot>  [42]
17:16:02 <Axioplas1> newsham: nice one, thanks a lot
17:16:09 * LoganCapaldo is writting the list monad in a dynamicly typed language wheeee
17:16:22 <jcreigh> LoganCapaldo: Ruby?
17:16:26 <mgsloan> would be quite clever if the checker could provide (->) values :)
17:16:32 <Renkin> So lists are monads?
17:16:35 <LoganCapaldo> jcreigh: good guess :)
17:16:39 <jcreigh> LoganCapaldo: heh
17:16:42 <mgsloan> Renkin: yep
17:17:08 <Renkin> Is that useful somehow?
17:17:13 <Renkin> Or is it just cool? :)
17:17:14 <newsham> > [3,2] >>= (\x -> [0-x, x])
17:17:16 <lambdabot>  [-3,3,-2,2]
17:17:31 <newsham> multi-valued functions
17:17:41 <mgsloan> mostly cool, occasionally useful, very elegant.
17:17:48 <newsham> the Maybe monad is similar to list monad with Nothing = [] and Just x = [x]
17:17:51 <Renkin> indeed
17:18:17 <araujo> Renkin, yes, it is. Monads help to build types that can contain different values. It is used that way for the list type.
17:18:22 <newsham> if you have search code that uses Maybe to find an answer, changing it to use List will let you find all answers
17:18:35 <araujo> (different in this case, as in different size)
17:19:14 <Renkin> Monads is a really powerful concept
17:19:26 <Renkin> I still don't grasp them fully, though
17:19:42 <LoganCapaldo> I wrote guard too, so now I have ugly as sin list comprehensions
17:20:24 <newsham> > do { x <- [1,3]; y <- [0-x, x], return (2*y-9) }
17:20:25 <lambdabot>  Parse error
17:20:33 <newsham> > do { x <- [1,3]; y <- [0-x, x]; return (2*y-9) }
17:20:35 <lambdabot>  [-11,-7,-15,-3]
17:21:25 <dons> and your paper for today is: http://programming.reddit.com/info/tebr/comments
17:21:28 <lambdabot> Title: Extracting Programs from Type Class Proofs [pdf] (reddit.com), http://tinyurl.com/yk4bg4
17:21:39 <newsham> you may have come across something like this before:
17:21:52 <newsham> > do { x <- [1..3]; y <- [1..3]; return (x,y) }
17:21:54 <lambdabot>  [(1,1),(1,2),(1,3),(2,1),(2,2),(2,3),(3,1),(3,2),(3,3)]
17:22:02 <newsham> thats also list monad
17:22:17 <Renkin> that's really cool
17:22:36 <newsham> > [(x,y) | x <- [1..3], y <- [1..3]]
17:22:38 <lambdabot>  [(1,1),(1,2),(1,3),(2,1),(2,2),(2,3),(3,1),(3,2),(3,3)]
17:22:50 <Renkin> What is x in x <- [1] ?
17:23:13 <newsham> renkin: first its 1.  thats all. :)
17:23:23 <newsham> where as in x <- [1..3] first its 1, then its 2, then its 3..
17:23:24 <Renkin> So list comprehension is even more syntactic sugar on top of do?
17:23:33 <Renkin> just even more, I mean
17:23:45 <newsham> renkin: list comprehensions are like list monads.  there's a paper somewhere about "comprehending monads"
17:23:45 <lispy> Renkin: list comp. is actually filters and maps and things
17:23:58 <newsham> but i think in haskell only list monads get comprehended
17:24:05 <dons> list comprehensions are just monad comprehensions on lists :)
17:24:05 <lispy> Renkin: but to be fair, the list monad is interms of those things too
17:24:09 <LoganCapaldo> newsham: Hand-rolled version <g>: Array.m_bind([1,3]){ |x| Array.m_bind([0 - x, x]){|y| Array.m_return(2*y-9)}}
17:24:32 <Renkin> Heh :)
17:24:45 <Renkin> So x <- [1,2] ?
17:24:46 <newsham> logan: or [(x,y) for x in xrange(3+1) for y in xrange(3+1)]
17:24:54 <newsham> but we dont use python or ruby, right?
17:25:58 <mgsloan> > let foo zip map foldl = zip * map + foldl in foo 2 3 5    --Uh-Oh! :)
17:26:00 <lambdabot>  11
17:26:03 <newsham> logan: you're writing listmonad lib for ruby?
17:26:15 <LoganCapaldo> newsham: yeah sort of
17:26:19 <LoganCapaldo> @hoggle guard
17:26:20 <lambdabot> Monad.guard :: MonadPlus a => Bool -> a ()
17:26:20 <lambdabot> Control.Monad.guard :: MonadPlus m => Bool -> m ()
17:26:20 <lambdabot> Language.Haskell.TH.Guard :: data Guard
17:26:36 <LoganCapaldo> I started with Maybe
17:27:02 <LoganCapaldo> Hmm
17:27:24 <newsham> logan: i have a fun use case for list monads if you're looking for something to use it for:  http://www.thenewsh.com/%7Enewsham/x/machine/Transform2.hs
17:27:27 <lambdabot> http://tinyurl.com/yc63jv
17:27:51 <newsham> (list monad not strictly needed)
17:28:06 <LoganCapaldo> newsham: thanks I'll take a look
17:32:40 <mgsloan> > let t@(x:xs) = [1..10] in (t, x, xs)
17:32:42 <lambdabot>  ([1,2,3,4,5,6,7,8,9,10],1,[2,3,4,5,6,7,8,9,10])
17:33:02 <mgsloan> this still fairly well blows my concept of a function, but cool nonetheless
17:33:13 <LoganCapaldo> Hmm I think my guard is wrong. Does anyone have a link to the source of guard? (preferrably for List and not the genral case, I'm easily confused :) )
17:34:01 * lenbust dances
17:34:42 <Renkin> mgsloan: how is that a function?
17:34:51 <Renkin> it is cool :)
17:34:57 <mgsloan> it is, it defines the functions t, x, and xs
17:35:03 <mgsloan> yeah, pretty crazy
17:35:17 <mgsloan> > let Just 5 = 2 in Just 5
17:35:18 <lambdabot>  add an instance declaration for (Num (Maybe a))
17:35:18 <lambdabot>   In a pattern binding: J...
17:35:38 <mgsloan> > let (Just 5) = 2 in Just 5
17:35:40 <lambdabot>  add an instance declaration for (Num (Maybe a))
17:35:40 <lambdabot>   In a pattern binding: (...
17:35:44 <mgsloan> hmm, maybe not
17:35:50 <audreyt> > let just 5 = 2 in just 5
17:35:52 <lambdabot>  2
17:35:53 <audreyt> ;)
17:35:57 <mgsloan> ohh
17:36:03 <mgsloan> well, no, that's cheating
17:36:06 <jcreigh> case Matters
17:36:06 <mgsloan> :)
17:36:22 <audreyt> > let 2 + 2 = 5 in 2 + 2
17:36:24 <lambdabot>  5
17:36:26 <audreyt> better?
17:36:41 <mgsloan> yeah, but i knew about that wierdness :)
17:36:47 <LoganCapaldo> how is that remotely legal?
17:36:54 <mgsloan> > let 2+2 = 5 in 3+2
17:36:55 <audreyt> too bad \bot doesn't parse 2+2+2
17:36:55 <lambdabot>  Non-exhaustive patterns in function +
17:36:58 <Renkin> it's just defining a new operator +, right?
17:37:00 <jcreigh> LoganCapaldo: it defines (+)
17:37:08 <LoganCapaldo> oh
17:37:08 <jcreigh> > let add 2 2 = 5 in add 2 2
17:37:10 <lambdabot>  5
17:37:14 <LoganCapaldo> right
17:37:26 <jcreigh> just infix cleverness.
17:37:49 <dons> mmm, an instance Num for Maybes could just about be useful,
17:37:50 <dons> instance Num a => Maybe a where
17:37:50 <dons>     (Just a) (+) (Just b) = a + b
17:37:50 <dons>     Nothing  (+) b        = b
17:37:56 <dons> just map 0 -> Nothing
17:38:09 <Botje> > let _ / 0 = "you blew up the universe. happy?" in 5/0
17:38:11 <lambdabot>  "you blew up the universe. happy?"
17:38:22 <lispy> Botje: nice one
17:38:25 <Botje> this should be a default in all languages.
17:38:44 <dons> > 5%0 -- does this work?
17:38:45 <lambdabot>  Exception: Ratio.%: zero denominator
17:38:47 <dons> npoe
17:38:57 <lispy> hard to take the gcd with 0
17:39:04 <mgsloan> > let (one:two:three:four:five:six:_) = iterate (Just) Nothing in three
17:39:05 <lambdabot>    Occurs check: cannot construct the infinite type: a = Maybe a
17:39:06 <lambdabot>    Expe...
17:39:09 <lispy> > gcd 5 0
17:39:11 <lambdabot>  5
17:39:23 <lispy> ha! i thought that was undefined
17:39:27 <lispy> > 0 / 5
17:39:28 <lambdabot>  0.0
17:39:32 <Botje> not really.
17:39:36 <audreyt> dons: you mean instance Num a => Num (Maybe a) ?
17:39:37 <lispy> guess that makes sense
17:39:40 <Botje> 0 is divisable by every number
17:39:43 <Botje> *divisible
17:39:47 <LoganCapaldo> damn
17:39:48 <lispy> Botje: yeah, i realized that now :)
17:39:54 <monochrom> gcd 0 0 will be more fun
17:40:04 <ihope_> > gcd 0 0
17:40:06 <lambdabot>  Exception: GHC.Base.gcdInt: gcd 0 0 is undefined
17:40:13 <monochrom> There!
17:40:14 <LoganCapaldo> lets ban do notation, I've decided everything makes more sense if its not there and I get less confused
17:40:48 <Botje> LoganCapaldo: you prefer foo >>= \x -> bar x >>= y -> baz y ?
17:40:53 <monochrom> You like getChar >>= \x -> print (ord x) ?
17:41:09 <monochrom> I like arrows.
17:41:15 <ihope_> Arrow...
17:41:21 <LoganCapaldo> For me to try and figure out how guard works by working backwards from example code? Yes :)
17:41:22 <jcreigh> LoganCapaldo: just use @undo :)
17:41:52 * ihope_ feels an odd need to tack ::usage onto everything
17:41:58 <ihope_> @undo::usage
17:41:59 <lambdabot> Unknown command, try @list
17:42:02 <ihope_> @ help undo
17:42:10 <mgsloan> > let (one:two:three:four:five:six:_) = iterate (1:) [] in three
17:42:11 <lambdabot>  [1,1]
17:42:12 <dons> audreyt: yep
17:42:15 <ihope_> You get the idea, don't you, lambdabot?
17:42:20 <Renkin> @undo do { x <- [1,3]; y <- [0-x, x]; return (2*y-9) }
17:42:20 <lambdabot> [1, 3] >>= \ x -> [0 - x, x] >>= \ y -> return (2 * y - 9)
17:42:30 <mgsloan> > let (zero:one:two:three:four:five:six:_) = iterate (1:) [] in three
17:42:31 <Renkin> I'll start using that instead of list comprehension :)
17:42:33 <lambdabot>  [1,1,1]
17:42:37 <newsham> > (((+ 3) &&& (* 2)) >>> (uncurry (+))) 5
17:42:39 <lambdabot>  18
17:42:50 <dons> ?redo [1, 3] >>= \ x -> [0 - x, x] >>= \ y -> return (2 * y - 9)
17:42:50 <lambdabot> do { x <- [1, 3]; y <- [0 - x, x]; return (2 * y - 9)}
17:42:51 <ihope_> You want an @uncomprehend command?
17:43:06 <lispy> gcd 0 0 must have been the exception i was thinking of
17:43:11 <greentea> Hi all.
17:43:17 * ihope_ runs up to the Linux machine
17:43:21 <dons> afternoon greentea
17:43:26 * Botje trips up ihope_ 
17:43:39 <Botje> NO RUNNING IN THE COMPUTER ROOMS8
17:44:12 <newsham> anyone here familiar with HAppS?  gotta question.
17:44:34 <Botje> hmm. 02:40 already.
17:44:40 <Botje> better sleep some
17:44:40 <Botje> <<
17:44:43 <newsham> 340p here.
17:44:52 <monochrom> I drank greentea today.
17:45:04 <dons> newsham: a few do, ask away.
17:45:13 * greentea hasn't been drunk for a while. ;-)
17:45:23 <Renkin> how would one make a program stop?
17:45:42 <newsham> I want to define my model (the data for my app) in terms of a state monad of some sort (which can stand alone for testing purposes) and incorporate that into HAppS
17:45:43 <monochrom> switch off the computer
17:45:49 <Renkin> haha, good one
17:45:53 <LoganCapaldo> error "Stop" `seq` 1
17:45:55 <LoganCapaldo> ?
17:45:57 <Botje> dereference a null pointer
17:46:01 <newsham> what kind of state monad thingy do I want to use for that, and what support does HAppS have for invoking that from in the Ev monad.
17:46:24 <dons> audreyt: how's code?
17:47:20 <Renkin> I have my monad that runs a program (using IO's), and I basically want a command to stop it in a controlled way.. but I can't grasp that concept
17:47:53 <newsham> renkin: one thread running an IO and interrupted by another thread?
17:48:23 <Renkin> it's part of a couse, and we haven't touched threads :)
17:48:37 <monochrom> You spawn another process?
17:48:57 <newsham> renkin: so interrupted how?  like ^C?
17:49:03 <Renkin> No
17:49:22 <Renkin> Just stop and return something, like "you paused"
17:49:37 <newsham> what triggers that to happen?
17:49:53 <Renkin> Insufficient data to continue
17:49:57 <Renkin> You provide the program with a trace
17:50:22 <Renkin> Maybe I'm just tired
17:51:08 <dons> Martin Sulzmann is insanely productive, check out the paper list, http://www.comp.nus.edu.sg/~sulzmann
17:51:10 <lambdabot> Title: Martin Sulzmann
17:51:20 <Renkin> I'll have to do that in bind, I guess
17:51:24 <dons> like 1 paper every fortnight.. scary
17:51:30 * dons feels shockingly lazy
17:51:39 <lispy> dons: my first advisor was crazy about publishing
17:51:48 <lispy> dons: i hated working under her 'cause of it :)
17:52:22 <dons> i really need to write up more things.
17:52:30 <newsham> yah, dons, wtf, all you do is write a bot, hs-plugins, fast strings, maintain a weekly newsletter, write a tutorial every few weeks, and go to school and write a thesis
17:53:26 <dons> yeah, i know. such a slacker. /me looks for more things to write.
17:53:28 <Renkin> When I try to bind two programs like  A >>= B  I can pattern match A and if it looks a certain way, I cut B and bind to return? does that break any rule? :)
17:53:49 <kpreid> Renkin: that sounds like an ordinary sort of failure
17:54:03 <Renkin> Ok, good. It's probably what I want
17:54:16 <kpreid> wait, bind to return? you can't do that, I think
17:54:31 <kpreid> because you don't know anything about the return type the second action has to have
17:54:40 <dons> i need an rss feed of Martin's papers...
17:54:43 <Renkin> Oh, I just run A instead of A >>= B then
17:54:45 <kpreid> but you can return a failure as the result of the while
17:54:52 <kpreid> whole
17:55:10 <Renkin> Oh
17:55:44 <Renkin> return a failure?
17:55:46 <newsham> dons: if you have problems finding something (to do), let me know ;-)
17:56:10 <dons> i think i just have to focus on *finishing* all the things I start.
17:56:11 <kpreid> Renkin: look at the Either monad, sayt
17:56:16 <kpreid> it probably goes like:
17:56:16 <monochrom> Cont monad and callCC
17:56:22 <mgsloan> It's too bad functions which evaluate to a constant can't be used in pattern matching
17:56:30 <dons> that's the difference -- Martin's turning everything he things about into a finished paper
17:56:34 <dons> s/thinks/
17:56:34 <mgsloan> (yes, i know guards can be used)
17:56:40 <kpreid> Left err >>= _ = Left err
17:56:50 <newsham> i dont even turn everything i think about into a started project
17:56:59 <kpreid> Right ok >>= f = f ok
17:57:18 <dons> newsham: heh
17:57:46 <dons> to achieve this i'll have to dump my gf, lock myself in a small, quiet room with a fast network. firewall reddit and irc and ban email
17:57:50 <jlouis> dons, Martin?
17:57:59 <dons> i'll get the food delivered to the door
17:57:59 <Renkin> I'm using Either, but not for that. I'll look at that
17:58:08 <dons> jlouis: Sulzmann
17:58:22 <lispy> dons: my advisors approach was to only do things which having publishing potential
17:58:25 <kpreid> Renkin: I'm not saying use Either, I'm saying look at it for an example of a monad with a don't-execute-the-right case
17:58:25 <jlouis> dunno about him
17:58:31 <dons> lispy: interesting.
17:58:33 <lispy> dons: even if it means it's otherwise boring
17:58:38 <dons> jlouis: http://www.comp.nus.edu.sg/~sulzmann/
17:58:38 <lambdabot> Title: Martin Sulzmann
17:58:39 <newsham> gf? irc? network?  you'll never make a good mathemtician!
17:58:45 <dons> heh
17:58:52 <Renkin> kpreid: Oh, ok
17:58:59 <Renkin> Yeah, that makes sense
17:59:19 <lispy> i more prefer the romantic approach to research
17:59:19 <newsham> i like that russian guy who just won an award after holing himself up and coming up with some theorems, and he turns down the award
17:59:34 <lispy> do something which you think is interesting and then once you have evidence that it's interesting, publish!
17:59:36 <jlouis> dons, productive bastard
18:00:20 <jlouis> lispy, that is the Richard Feynmann approach. That will definitely not work!
18:00:25 <lispy> i think of her approach as the engineered approach.  You engineer a situation that allows you to publish, then carpe diem
18:00:34 * jlouis grins ironically like a necromancer
18:00:37 <newsham> perelman, fields medal, poincare conjecture.
18:00:37 <mgsloan> newsham - perelman?
18:00:42 <mgsloan> yeah
18:00:42 <monochrom> (with the Cont monad)  callCC (\throwup -> throwup 5 >> return 6)   this will return 5 rather than 6.
18:01:05 <lispy> i quite like the idea of becoming a hermit lately
18:01:14 <monochrom> There is of course also ContT monad transformer so that you can apply ContT to IO.
18:01:23 <lispy> i just need to learn about more about growing my own food and making my own clothes
18:01:39 <lispy> i'm sure i can get cheap land in texas
18:01:44 <newsham> "surely you're joking, mr feynman"  "you did what!@#? mr feynman?" "wtf?!@# mr feynman!"
18:02:44 <lispy> although, with how lazy i am, i'll probably pass away after 6 months of being a hermit
18:02:46 <Excedrin> lispy: there should be some sort of commune for hackers, but screw growing food, let subsidized farming handle that...
18:02:52 <lispy> (not sure if this is a bad thing yet)
18:03:00 <newsham> excedrin: like l0pht?
18:03:06 <newsham> new hack city?
18:03:24 <dons> lispy: so I guess my issue is that I like writing tools, libraries and apps. paper publishing isn't so conducive to getting real things built and used
18:03:36 <dons> since you're encouraged more to get proof of concept stuff done, then move on
18:03:39 <Excedrin> does l0pht sitll exist?
18:03:43 <newsham> no
18:03:59 <newsham> l0pht -> @stake -> symantec
18:04:03 <Excedrin> also, I mean hacker in the oss sense
18:04:20 <newsham> how does that not apply to l0pht?
18:04:31 <Excedrin> they're hackers in the security sense
18:04:33 <lispy> dons: right, a researcher stops the implemenation long before running into the last 30% or so because that's where most of the effort has to go in, if a quality tool is your goal.  Instead they invest in the last 30% of the theory
18:04:41 <newsham> excedrin: why cant it be both?
18:05:16 <Excedrin> if there's some new fangled hacker commune, _it_ can be, but l0pht wasn't afaik
18:05:24 <newsham> there are some very good hackers (in the programming sense) from l0pht.
18:05:47 <newsham> dildog and hobbit come to mind
18:06:11 <lispy> dons: have you read "you and your research"? it's 20 years old this year but every bit relevant (and generalizes to more than research)
18:06:37 <shapr> yeah, hobbit is awesome
18:06:44 <lispy> dons: i especially like Hamming's discussion of luck/hardwork and how they _really_ work together
18:07:06 <Excedrin> socat > nc
18:07:10 <newsham> http://www.flickr.com/photos/ericskiff/160112141/ <- dildog with his pocketpc port of quake3
18:07:16 <lispy> shapr: hey, how's code?
18:07:17 <lambdabot> Title: Christien Rioux with his pocket PC port of Quake 3 on Flickr - Photo Sharing!, http://tinyurl.com/yk9wm4
18:07:32 <shapr> lispy: nothing lately...
18:07:47 <lispy> shapr: yeah, i'm having procrastination problems myself :(
18:07:54 <Nafai> Me too
18:08:00 <shapr> I'd like to start something like the l0pht, an in-person community with the quality of #haskell...
18:08:12 <lispy> i just watched every episode of "Peep show" that exists on google video :(
18:08:26 <shapr> We should all move in with dons.
18:08:48 <lispy> dons: i could sleep in the server room, they could keep me warm
18:09:02 <lispy> god knows i'd be better off dating a machine anyway
18:09:05 <newsham> cDc had a collective in SF similar to l0pht, called NewHackCity.  they had people who hacked on hardware and software there too
18:10:07 <shapr> I don't know how to make it work on the money side though. Maybe someone rich could buy an apartment building and rent it out to hackers?
18:10:18 <bd_> @pointless \f n -> f n n
18:10:19 <lambdabot> join
18:10:28 <dons> i'm hoping we'll get a big spike in productivity out of the hackathon
18:10:35 <lispy> bd_: now figure out why that works!
18:10:41 <shapr> Personally, I wish my apartment were smaller but had a better 'net connect.
18:10:44 <bd_> I think I did, ages ago >.>
18:10:48 <newsham> find a cheap space and split the rent with a bunch of people who need space for their tech stuff
18:10:54 <bd_> it has something to do with the reader monad, right?
18:10:59 <lispy> > join (+) 3
18:11:00 <lambdabot>  6
18:11:06 <lispy> bd_: right!
18:11:13 <bd_> let's see
18:11:14 <dons> bd++ good work
18:11:44 <newsham> 5 people sharing a $1k/mo space is only $200/mo.
18:11:52 <dons> shapr: so we've got 10 people for the hackathon now, and another 5 or so maybes
18:12:00 <dons> so should be really useful, I think
18:12:11 <newsham> these days people have less spare hardware junk and more vmwares though
18:12:13 <CosmicRay> shapr!
18:12:25 <CosmicRay> newsham: xen, man, xen!
18:12:51 <bd_> join m = do v <- m; v, making join m = m >>= id
18:12:58 <jlouis> CosmicRay!, Dons!, shapr! Hackathon??!!
18:12:58 <newsham> sorry, i'm still using vmwares
18:13:15 <dons> jlouis: !
18:13:21 <dons> ?where Hac07
18:13:21 <lambdabot> http://haskell.org/haskellwiki/Hac_2007
18:13:26 <CosmicRay> newsham: I am too, but only when I have to run RedmondOS
18:13:36 <shapr> hiya CosmicRay
18:13:44 <shapr> jlouis: man, haven't seen you in months
18:14:08 <CosmicRay> shapr: I just realized last night.  It's been *2 years* since megamonad sprang to life.
18:14:13 <shapr> wow
18:14:15 <jlouis> nah, but I am hacking Haskell again
18:14:55 <jlouis> 'tis good stuff.
18:15:05 <dons> yay!
18:15:09 <shapr> dons: aw, can't make it to the UK
18:15:18 <dons> shapr: i know :/ such a pity!
18:15:20 <lispy> CosmicRay: meaning we may get a special guest apperance for the holidy?
18:15:20 <jlouis> shapr, you still up there in Sweden?
18:15:25 <bd_> in reader, (>>=) m1 f = \env -> f (m1 env) env; so join m = (m >>= id) = \env -> id (m env) env = \env -> m env env
18:15:34 <bd_> thus, join f v = f v v
18:15:38 <shapr> jlouis: Nope, living in Alabama for ... three months or more now.
18:15:43 <dons> bd_: excellent :)
18:15:54 <dons> bd_: reaches level 3
18:15:58 <bd_> woo
18:16:02 <bd_> +2 to WIS?
18:16:06 <jlouis> shapr, that may explain while you are up. Its 03:12 here and I can't sleep
18:16:18 <jlouis> bd_, no, but you may choose an oleg-feat.
18:16:28 <bd_> jlouis: What are the available options?
18:16:28 <dons> CosmicRay: any chance you'd make the hackathon?
18:16:32 <lispy> jlouis: haha
18:16:37 <CosmicRay> lispy: I don't know, perhaps I could train a new megamonad from more recent logs.  the problem was that megahal segfaults when its brain file exceeds 512MB, so megamonad basically was killed off by software bugs.
18:16:52 <lispy> CosmicRay: aye
18:16:52 <jlouis> Like Extreme-Polymorphic-Knowledge, or Counting via Polymorphic Succ+Zero etc
18:16:54 <CosmicRay> dons: not very likely.  life is waaay too busy right now
18:16:54 <dons> I wonder if any USAsians will be around for POPl.
18:17:00 <dons> CosmicRay: fair enough :)
18:17:03 <lispy> CosmicRay: this convo feels like dejavu
18:17:04 <shapr> CosmicRay: Think we could organize a US Hackathon?
18:17:11 <CosmicRay> I'd love to attend one sometime
18:17:16 <shapr> oh, busy, not travel costs...
18:17:21 <jlouis> The Save-Life-By-Capturing-Continuation requires at least level 18
18:17:23 <dons> shapr: so the plan is to hold 2 a year, one with ICFP, nd one with POPL
18:17:27 <jlouis> (Thats another Oleg-Feat)
18:17:30 <CosmicRay> shapr: well, we are talking portland, aren't we?
18:17:35 <CosmicRay> or is this the european hackathon?
18:17:46 <Nafai> You guys should hold a hack-a-thon in Austin :)
18:17:47 <shapr> Nah, we're talking YOUR NEW HOUSE!
18:17:47 <bd_> jlouis: Bah, all the good ones take at least level 15
18:17:50 * shapr boings!
18:17:56 <lispy> i plan to keep increasing my haskell level until i get "Summon Dire Oleg"
18:17:59 <shapr> CosmicRay: Ok, just joking =)
18:18:00 <dons> heh
18:18:21 <shapr> Didn't Oleg's have fire whips?
18:18:27 <CosmicRay> shapr: I should mention that haskell.edu is about 90 minutes from here ;-)
18:18:29 <shapr> Or was that Olegrogs?
18:18:29 <bd_> I guess I'll take Protection +1 versus Nontermination
18:18:31 <lispy> sadly, i don't think i'll ever be able to control a familiar of that power
18:18:33 <jlouis> No that was Balrogs
18:18:38 <dons> oh nice, sigfpe's using lambdabot for his math articles...
18:18:41 <dons> http://sigfpe.blogspot.com/2006/12/yonedic-addendum.html
18:18:44 <lambdabot> Title: A Neighborhood of Infinity: A Yonedic Addendum, http://tinyurl.com/ylq7hg
18:18:50 <jlouis> bd_, A Nice choice!
18:18:57 <dons> ?free (Float -> b) -> Char -> b
18:18:58 <lambdabot> Pattern match failure in do expression at Plugin/Free/FreeTheorem.hs:54:20-34
18:18:59 <CosmicRay> shapr: yes, we can probably set up 3 workstations per grain bin out in the granary... ;-)
18:19:08 <dons> ?ft (Float -> b) -> Char -> b
18:19:10 <lambdabot>  There was an error in the type: (line 1, column 7):
18:19:10 <lambdabot>  unexpected "e"
18:19:10 <lambdabot>  expecting "->" or end of input
18:19:14 <CosmicRay> shapr: and if it's winter, we won't need to worry about cooling
18:19:15 <lispy> bd_: that goes well with the +2 sword of slay segfaults
18:19:15 <dons> urgh
18:19:15 <shapr> CosmicRay: haha
18:19:20 <Axioplas1> I'm having trouble with a simple StateMonad, trying to fetch back the result : http://rafb.net/paste/results/Sw5ima44.html  Can someone point me out what to do ?
18:19:28 * fik wonders: what the hell is a level
18:19:31 <jlouis> ?help ft
18:19:31 <lambdabot> ft <ident>. Generate theorems for free
18:19:36 <jlouis> oh, nice
18:19:36 <bd_> lispy: I thought the Shield of Strict Typing gives me that for free?
18:19:46 <dons> ah yes. we broke the 'custom type' apart. pity
18:19:53 <dons> ?ft foldr
18:19:54 <lambdabot>  forall T1,T2 in TYPES. forall h1 :: T1 -> T2, h1 strict.
18:19:55 <lambdabot>   forall T3,T4 in TYPES. forall h2 :: T3 -> T4, h2 strict.
18:19:55 <lambdabot>    forall f1 :: T3 -> T1 -> T1.
18:19:55 <lambdabot>     forall g1 :: T4 -> T2 -> T2.
18:19:55 <lambdabot>      (forall x3 :: T3.
18:19:56 <lambdabot> [5 @more lines]
18:20:02 <dons> ?free foldr
18:20:03 <lambdabot> (forall x. f . h x = k (g x) . f) => f . foldr h y = foldr k (f y) . $map g
18:20:08 <dons> (more concise, less accuratE)
18:20:22 <lispy> bd_: it appears that Array can still summon a segfault
18:20:26 <bd_> Axioplas1: You can't show a State monad, because you'd need to pass in an initial state for it to make sense
18:20:41 <dons> ?where+ paste-rafb http://rafb.net/paste
18:20:41 <lambdabot> Done.
18:21:46 <Axioplas1> bd_: well.. I think that *at least* I should be able to manipulate it's return value (fst of the pair)
18:21:52 * dons gets a feeling that bd_ isn't a haskell newbie ;)
18:21:56 <bd_> Axioplas1: to run your state monad, you'd need something like: runState initState (ST f) = f initState
18:22:04 <bd_> Axioplas1: The return value depends on the initial state :)
18:22:17 <bd_> dons: I just don't idle much around here >.>
18:22:41 <lispy> dons: did  you see we have math paste now too
18:22:43 <lispy> ?where mathpaste
18:22:43 <dons> bd_: well, welcome back anyway.
18:22:43 <lambdabot> http://www.mathbin.net/
18:22:43 <bd_> It still makes my head hurt when people use typeclasses to make variadic functions though >.>
18:22:50 <dons> lispy: oh nice. any good?
18:22:50 <Axioplas1> bd_: I'm not using the StateMonad. I'm using s stateMonade-like monad..
18:22:53 <dons> bd_: hehe
18:22:59 <lispy> dons: i haven't tried it
18:23:13 <bd_> Axioplas1: right, but even with your monad, you have s -> (a, s)
18:23:17 <bd_> the a is dependent on the input s
18:23:25 <bd_> for example
18:23:27 <bd_> You could have
18:23:32 <bd_> ST (\s -> (s, s))
18:23:35 <bd_> that is, the get primitive
18:23:41 <Axioplas1> yep
18:23:46 <bd_> how can you manipulate the return value if the state is unknown?
18:24:03 <Axioplas1> indeed...
18:24:06 <jlouis> 'tis STM stuff kicks fucking ass
18:24:20 <jlouis> Its like getting a dual-wield lightsaber
18:24:30 <bd_> Axioplas1: In order to extract the value from the state monad, you must simply extract the function within, and pass in an initial state.
18:24:48 <Axioplas1> bd_: that's what I've been trying to do for now two hours :/
18:24:54 <stepcut> hrm, 'host -t mx haskell.org' tells me that there is no MX record for haskell.org -- am I being stupid, or is there something up with haskell.org and mail ?
18:24:55 <bd_> lispy: btw, how can Array summon segfaults? I thought it was bounds-checked?
18:25:16 <Axioplas1> bd_: but it won't type
18:25:19 <lispy> bd_: recently someone emaild haskell-cafe@ with an example which can do it
18:25:43 <bd_> Axioplas1: Well, doing it by Show won't work, as the Show clss doesn't give you a place to put in an initial value (except undefined, I guess, but that's not useful)
18:25:50 <bd_> So you need to make a new function
18:26:01 <bd_> lispy: hmm, isn't that a compiler bug? :)
18:26:15 <Axioplas1> bd_: I thought "if show can do it, anyone can". Though I'mve been struggling with a simple putStr that didn't get better...
18:26:25 <lispy> bd_: well, it has to do with some type class for indexing or some such
18:26:33 <lispy> bd_: causes the problem on both hugs and ghc
18:26:44 <bd_> Axioplas1: Well, yes, if show could do it, it'd be fine, but show can't ;) You could, however, do something like this, in theory:
18:26:53 <Axioplas1> I tried stuff like foo>>=(\x -> putStr$fst$x 42))
18:26:54 <bd_> instance Show (s, State s r) where ...
18:26:59 <bd_> but that's silly.
18:27:04 <LoganCapaldo> what's the name for (>>) ?
18:27:12 <bd_> Axioplas1: in the IO monad, or in a state monad?
18:27:20 <Axioplas1> bd_: in the State one :/
18:27:33 <Axioplas1> I dunno how to IO it.
18:28:06 <bd_> You mean, how to make a StateT where IO can be accessed as well? That's a bit more advanced then just making a runState function :)
18:28:18 <bd_> runState (ST f) initState = ...
18:30:02 <jlouis> stepcut, you are not wrong. When no MX is present, it asks directly for the A record and uses that instead
18:30:12 <Axioplas1> it says : bd_ the error is that bd_ I don't know whether it's a runState or else. I just want to.. well.. run my previous line on a State value...
18:30:37 <jlouis> stepcut, and if you check with telnet haskell.org 25 ...
18:30:39 <mutjida> Hello. I'm a little confused about the type language of GHC and was wondering if anyone here could shed some light. In particular, does the GHC typechecker support type-level functions and higher-order unification?
18:30:42 <Axioplas1> but it says "oh no! x is not a function !"
18:30:46 <bd_> Axioplas1: which line, the one with putStr?
18:30:48 <bd_> or...?
18:30:55 <stepcut> jlouis: ah - thanks. exim4 has been giving me trouble recently -- just wanted to make sure it was a problem on my side, not haskell.org
18:31:14 <bd_> oh
18:31:25 <bd_> Axioplas1: your a <- x in the paste?
18:31:27 <Axioplas1> bd_: err.. I removed the main, and instead wrote : gaga foo =  foo>>=(\x -> putStr$fst$x 42)
18:31:34 <lispy> stepcut: fwiw, i used to use exim3 and then 4...after i switched to postfix my life has been simpler
18:31:39 <Axioplas1> (where gaga is the function that fails to type)
18:32:04 <dons> ok, this is just freaky!  http://programming.reddit.com/info/temb/comments
18:32:07 <lambdabot> Title: Aspect-Oriented Programming with Haskell Type Classes (reddit.com), http://tinyurl.com/y6heqo
18:32:10 <bd_> Axioplas1: Well, it types, but it's in the IO monad, not any kind of State monad.
18:32:25 <bd_> Axioplas1: if you want to run a state monad, you need a function to go between them
18:32:26 <jlouis> dons, firewall reddit! Write paper!
18:32:30 <bd_> something like:
18:32:34 <jlouis> ;)
18:32:53 <jlouis> mutjida, what do you mean by HO unification and type-level functions?
18:32:54 <stepcut> lispy: maybe i'll make the switch -- by email routing is a bit silly because I have to use different mail servers depending on if I am at home or work *and* depending on what my from address is set to..
18:32:57 <dons> jlouis: I'm just reading more MartinS papers -- so many interesting ideas that should have appeared in the HWN...
18:32:58 <bd_> gaga foo = let (x, y) = runState foo someInitialState in ...
18:33:19 <jlouis> dons, I have put some on my TODO list for reading
18:33:22 <bd_> Axioplas1: since State and IO are different monads, you cannot simply do a <- stateMonad in IO; IO doesn't know how to handle State
18:33:33 <lispy> stepcut: good luck either way, ymmv :)
18:33:48 <bd_> Axioplas1: so, you need a function to execute state and bring it down into a simple value
18:34:34 <mutjida> jlouis: can it solve a unification problem a =?= b a by setting b := \x -> x (a type-level lambda)?
18:34:57 <Axioplas1> bd_: that function would return me a value not contained in a Moand, shouldn't it ?
18:35:17 <bd_> Axioplas1: Right. It'd be of the type: State s r -> s -> (r, s)
18:36:03 <bd_> hmm
18:36:09 <bd_>         let b = a 42 {-a is a fun-} in let r = fst b {-b is a pair-} in putStr r
18:36:35 <newsham> so when you program in a monadic style you are often (always?) specifying an explicit order of operations, even though some of the ordering may not be required dependency.
18:37:05 <dons> newsham: yeah. the sequencing is often over-specified
18:37:10 <newsham> what does parallelizing code do about that?  are there ways to write some of the monadic code without specifying the ordering?
18:37:16 <sorear> reader monad (for instance) does not create sequencing deps
18:37:17 <jlouis> mutjida, I am not sure if it can type-check that at all. Ask some of the guys with better knowledge in here
18:37:21 <Axioplas1> bd_: are you telling me that I just had to define that function outside the "do" construct ???
18:37:28 <dons> newsham: well you could use arrows
18:37:31 <bd_> Axioplas1: eh? nono
18:37:44 <bd_> Axioplas1: The line I pasted is /close/ to correct
18:37:49 <sorear> arrows must impose ordering too
18:37:49 <bd_> correct would be more like:
18:38:03 <newsham> do arrows ordering only impose ordering where there are dependencies?
18:38:07 <sorear> eg kliesi-arrows of IO are order-sensitive
18:38:11 <bd_>     let b = runState x 42 in let r = fst b = putStr r
18:38:13 <bd_> with no a <- x
18:38:18 <sorear> therefore there must be specified order
18:38:20 <bd_> and with a runState function defined
18:38:29 <bd_> runState (ST f) initialState = f initialState
18:38:30 <bd_> essentially
18:38:56 <sorear> eg the pairing combinator (i forget its name, I don't use arrows often) runs the left arrow first
18:39:16 <newsham> &&& ?
18:39:33 <newsham> > ((+ 1) &&& (+ 2)) 3
18:39:35 <lambdabot>  (4,5)
18:40:05 <bd_> :t (&&&)
18:40:12 <bd_> @type (&&&)
18:40:13 <lambdabot> forall (a :: * -> * -> *) c' c b. (Arrow a) => a b c -> a b c' -> a b (c, c')
18:40:15 <Axioplas1> bd_: so, when I want to use M a's a in N b, I must use "let" to fetch the value through a "getter" ?
18:40:19 <sorear> that works too, not what I was thinking of
18:40:19 * dons adds :t syntax
18:40:30 <bd_> Axioplas1: well, not quite. You need a function to 'run' a monad.
18:40:37 <eviltwin_b> heh
18:40:43 <bd_> Axioplas1: That is, a function which knows how the monad works, and how to get a normal value out of it
18:40:45 <newsham> whats the pairing combinator you're thinking of? (whats it do?)
18:40:54 <Axioplas1> anyway, it's now working
18:40:56 <bd_> Axioplas1: 'let' here is not strictly needed. you could do: putStr $ fst $ runState x 42
18:41:05 <sorear> ?type (***)
18:41:07 <lambdabot> forall (a :: * -> * -> *) c' c b' b. (Arrow a) => a b c -> a b' c' -> a (b, b') (c, c')
18:41:07 <sorear> that one
18:41:10 <bd_> I only used let because your original code used it :)
18:41:22 <sorear> but &&& serves my point just as well
18:41:49 <newsham> > ((+ 1) *** (+ 2)) (3,4)
18:41:50 <lambdabot>  (4,6)
18:42:11 <newsham> so when using kleisly (***) evalutes one firs tthen the second (left then right, for ex)?
18:42:39 <Axioplas1> bd_: ha ?  err.. wherever I am, is the "<-" doing the same thing ? or did it think "a must be from inside an IO" by itself ?
18:42:39 <sorear> that's what I think
18:43:11 <bd_> Axioplas1: <- is different; it doesn't take values outside of a monad, instead it... well, one way of thinking of it is it combines monads
18:43:17 <bd_> kinda
18:43:29 <bd_> but they need to be of the same type of course
18:43:34 <bd_> to use monads of different types
18:43:39 <bd_> you need some kind of adapter, which <- is not :p
18:43:58 <sorear> you need a lifting function
18:44:00 <Axioplas1> bd_: Or was I wrong thinking that a<-x g was similar to case x of (SM a) -> a   ?
18:44:23 <bd_> Axioplas1: yes, that's wrong XD
18:44:30 <Axioplas1> ok.
18:44:38 <newsham> so given that real programs make use of lots of monadic code, how accurate is it to say that its easier to parallelize haskell code because there is no explicit order of evaluation?
18:44:39 <bd_> Axioplas1: Do you know how do-syntax is converted in the compiler ot >>=?
18:44:48 <Axioplas1> That might be why I couldn't apply that result...
18:44:51 <audreyt> newsham: forkIO
18:44:55 <Axioplas1> bd_: yes I do
18:45:04 <bd_> Axioplas1: Well, what does <- become? :)
18:45:12 <Axioplas1> this one, I don't know :)
18:45:13 <audreyt> (to elaborate: explicit parallelization is 1)fun 2)easy)
18:45:16 <sorear> newsham: different ST monads (eg) can work in parallel (theoretically)
18:45:23 <bd_> Axioplas1: Well, then you don't know how do-syntax is converted :)
18:45:31 <newsham> (also wouldnt some of the artificially imposed ordering eliminate some optimization possibilities?)
18:45:33 <audreyt> GHC never claimed to do any sort of implicit parallelization
18:45:37 <bd_> Axioplas1: http://www.nomaware.com/monads/html/class.html#donotation
18:45:40 <lambdabot> Title: Doing it with class, http://tinyurl.com/y8svf5
18:45:52 <sorear> of course all this falls under the heading of "assuming a sufficiently advanced compiler..."
18:45:55 <audreyt> so we're all explicit. difference is haskell makes annotations rather easy
18:45:55 <newsham> audreyt: hmm, but it is an argument that functional programmers put forward
18:46:05 <audreyt> newsham: it is a bogus argument.
18:46:17 <Axioplas1> bd_: ah. then I knew it :)
18:46:27 <lispy> like the auto-memozing argument?
18:46:36 <lispy> could be done, but not worth it in practice?
18:46:37 <audreyt> right. hashconsing is _also_ explicit
18:46:42 <audreyt> yup
18:46:42 <dons> well, we have libraries now for magically parallel arrays
18:46:54 <audreyt> yeah but it's structure-bound not code bound
18:46:56 <bd_> Axioplas1: right, but x >>= \a -> ... doesn/t convert State to IO or anything like that :)
18:46:59 <dons> and its pretty magic when you can just sprinkle `par` in code to get parallelisation
18:47:00 <ihope> Oi, it's not especially obvious how to install the MCC.
18:47:02 <audreyt> the usual bogus argument talks about code :)
18:47:18 <sorear> automemoizing is a *big* (20 orders of magnitude for hashlife) win, I wish it were easier to do
18:47:18 <lispy> ihope: what is this, MCC, you're playing with?
18:47:20 <audreyt> `par` is explicit annotation, rather eas one at that
18:47:33 <dons> stepcut++ Another Haskell MIME Library
18:47:43 <ihope> lispy: Muenster Curry Compiler, if I'm transliterating my umlauts correctly.
18:47:57 * sorear pleads for a standard easy memofix-combinator or MEMOIZE-pragma
18:48:10 <audreyt> {-# MEMOIZE f #-}
18:48:19 <audreyt> would be nice
18:48:41 <audreyt> create a GHC ticket? :)
18:48:42 * lispy was about to say, "Cool" and try it :)
18:48:44 <Axioplas1> bd_: yes.. I should have thought about that..
18:48:52 <ihope> I'm getting that wonderful "C compiler cannot create executables" error thingy.
18:48:52 <Axioplas1> the type is propagated..
18:49:17 <Axioplas1> I reckon that I now deserve a good night o' sleep...
18:49:27 <bd_> hehe
18:49:34 <bd_> Monads can be tough at first, but it's worth it in the end :)
18:49:35 <Axioplas1> bd_: thanks a lot, and sorry for the harassment :)
18:49:52 <Axioplas1> bd_: I hope so ! otherwise I'm sticking back to OCaml ^^
18:50:00 <bd_> eww :P
18:50:22 <sorear> given rank-2 types, it is possible to create a program which does not use an a-priori bounded number of types
18:50:36 <sorear> http://members.cox.net/stefanor/MultispecializeKiller.hs
18:50:39 <lambdabot> http://tinyurl.com/yc3dfc
18:50:45 <sorear> has anyone else noticed this before?
18:50:52 <lispy> ihope: maybe it's targeting the wrong architecture?
18:51:04 <dons> mmm, sorear. interesting.
18:51:15 <ihope> Linux, Intel x86?
18:51:17 <dons> sorear: haskell-cafe@ please. you're inviting an Oleg response..
18:51:20 <dons> :)
18:51:26 <ihope> That's what it says, and that's what I have.
18:51:49 <audreyt> sorear: I think I've seen this technique somewhere
18:51:49 <sorear> dons: will do, redirect appreciated.
18:52:07 <audreyt> probably the Implicit Configurations paper
18:52:11 <lispy> ihope: i don't know, i'm just speculating why gcc would give that error....i used to know but i lost that memory, the hash table on my shoulders must use weak refs
18:52:32 <audreyt> sorear: also, by "if Haskell had first class existentials:" you just mean "has this keyword" :)
18:52:55 * eviltwin_b knows a bunch of ways to trigger it but has no idea which might apply to your stiatopm
18:53:01 <audreyt> oh wait. no, you are actually using existentials as first-class. nvm
18:53:13 <eviltwin_b> *situation
18:53:22 * eviltwin_b wonders where his finfers went that time
18:55:53 <sorear> audreyt: Beaten *again*...
18:56:37 <Cale> dons: http://www.marriedtothesea.com/120206/bloggers.gif
18:56:40 <lambdabot> http://tinyurl.com/y6mmra
18:57:05 <sorear> do I at least have the honor of noticing that first class existentials and rank 2 types are exactly equivalent?
18:57:41 <sorear> s/noticing/being the first to notice/
18:57:45 <dons> sorear: mm. i think that might be known (at least i've heard rumours)
18:58:18 <dons> (remember that both have been around in (at least haskell) for a while)
18:58:20 <dons> i could be wrong though
18:58:28 * sorear seems to be very good at rediscovering things
18:58:34 <lispy> Cale: hehe
18:58:36 <dons> Cale: heh. bizarre
18:59:07 <shapr> sorear: So, where do rank N types fit in there?
18:59:25 <sorear> rank 3 == rank 1.  rank 4 == rank 2.  etc.
18:59:35 <sorear> rank N gives no added power.
19:01:55 <audreyt> sorear: I forsee you joining the ranks of oleg/ccshan/amr/ralf et al in your near future :)
19:02:41 <shapr> who's amr?
19:03:03 <audreyt> amr sabry
19:03:21 <shapr> oh
19:03:35 <audreyt> "Structuring Quantum Effects: Superoperators as Arrows", "Backtracking, Interleaving, and Terminating Monad Transformers", "Delimited Dynamic Binding", etc
19:03:53 <audreyt> Haskell-as-quantum-machine-language fascinates me :)
19:04:07 <jlouis> sabry is a level 36 Magician
19:04:32 <dons> mmm, there's few sabry papers on the haskell.org reesarch papers list. someone shoudl add them...
19:04:40 <sorear> (reminds me) What do you call an arrow w/o arr?
19:04:48 <audreyt> ow?
19:04:56 <stepcut> dons: I added my lib to the wiki :)
19:05:10 <sorear> hehehe
19:05:26 <sorear> such could be used to embed a compiler into haskell
19:05:33 <jlouis> ok, i'll find a bed. Happy hacking!
19:06:17 <sorear> a massive tangent leading from haskell-as-real-time-language on haskell-cafe@ a while back.
19:06:22 <dons> stepcut: cheerrs
19:07:05 <sorear> assoc. type synonyms are only in GHC devel, correct? (as opposed to stable)
19:07:18 <dons> right
19:07:48 <CosmicRay> what is the canonical download site for Systme.FilePath?
19:07:55 <sorear> oh, well, guess like i'll have to wait for GHC to finish compiling :(
19:08:04 <dons> something on ndm's page, CosmicRay
19:08:14 <CosmicRay> ok.
19:08:21 <dons> ?google ndm FilePath
19:08:23 <lambdabot> http://www-users.cs.york.ac.uk/~ndm/projects/libraries.php
19:08:23 <lambdabot> Title: Neil Mitchell - Haskell Libraries
19:08:26 <dons> ooks good
19:08:31 <CosmicRay> I have that URL, just wasn't sure if people were supposed to use darcs.h.o or something from www.haskell.org
19:08:46 <sorear> how widely used is data Name = Name ? (i.e. overlapping tycon and dcon namespace?)
19:08:54 <dons> common
19:09:27 <dons> I often use data St = St .... -- for state types
19:09:36 <sorear> i'm chasing a natural-looking extention for value-parameterized types, and it forces the two namespaces to be unified...
19:11:03 <shapr> sorear: Have you seen Epigram?
19:11:16 <sorear> heard of it, never tried it
19:11:24 <shapr> sorear: Have you read Types and Programming Languages?
19:11:39 <stepcut> hrm, my ghc 6.6 build failed with -> cc1: Invalid option `-finline-limit=2500'
19:11:57 <sorear> I'm shooting for decidible inference and my idea seems to support it
19:12:11 <sorear> no, haven't read it (sounds like a SPJ book?)
19:12:53 <shapr> sorear: You should investigate those two things, I suspect you'll have a lot of fun.
19:13:32 <shapr> Have you reached dependent type systems yet?
19:13:57 <shapr> Do you know the lambda cube?
19:14:11 <sorear> I've read the Henk paper
19:15:00 <dons> alar, around? grr. editing the wiki page broke the cyrillic text.
19:15:11 <sorear> my unbounded-types insight is fallout of my thoughts on value parameterized types, in case that explains anything...
19:15:55 <shapr> It doesn't say much to me, but I don't know so much about type systems.
19:16:26 <sorear> (out of order) my system is strictly less powerful than epigram - it can't directly express the Epigram example of vector appends giving summed length
19:19:02 <lispy> oleg is a wedding dress? http://corvallis.craigslist.org/clo/240201421.html  (sorry, OT and bad joke....)
19:19:04 <lambdabot> Title: Oleg Cassini wedding dress & accessories, http://tinyurl.com/y96mxz
19:19:19 <lispy> i bet that took some real type hackery
19:22:48 <dons> :t fix
19:23:16 <lambdabot> forall a. (a -> a) -> a
19:23:24 <sorear> is there a standard reified type library?
19:23:25 <lispy> dons: ha!
19:23:28 <lispy> dons++
19:23:28 <dons> :k Int
19:23:34 <lambdabot> *
19:23:40 <dons> :)
19:23:42 <sorear> I don't think ++ works
19:23:48 <dons> sorear: yep it does
19:23:52 <dons> (its just quiet)
19:23:52 <sorear> look at the timestamp on the karma file
19:23:59 <dons> hmm?
19:24:02 <sorear> early November
19:24:18 <dons> only indicates last time I darcs pushed to the public repo, the karma file..
19:24:29 <dons> (the darcs repo isn't the same State as the running freenode instance)
19:24:47 <sorear> phhew
19:24:50 <dons> heh
19:25:04 <dons> ?version
19:25:04 <lambdabot> lambdabot 4p287, GHC 6.5 (OpenBSD i386)
19:25:05 <lambdabot> darcs get http://www.cse.unsw.edu.au/~dons/lambdabot
19:26:09 <dons> mmm, $ darcs changes | grep -v '^[\t ].*' | grep  '^[SMTWTFS]' | wc -l
19:26:09 <dons>     1312
19:26:39 <sorear> ieee, GHC build errorred
19:27:05 <sorear> a whole bunch of undefined Windows API symbols
19:27:31 <dons> an IEEE error? that's what'll happen on the DEC alpha with its weird floating support.
19:27:32 <sorear> I ran configure, my `uname` is Linux, I wonder why it thinks my computer supports the windows API
19:27:39 <dons> weird
19:27:47 <dons> someone mentioned this a couple of days ago
19:27:52 <sorear> ieee, meaning scream
19:28:02 <sorear> but it got through first stage
19:28:15 * dons jokes about the real IEEE error you can get
19:28:27 <sorear> (what won't work if I use a 6.6 compiled 6.7 compiler? just ghci?)
19:28:46 <dons> it should all work
19:29:14 <sorear> no my machine is a 387-compatible, FP-wise
19:29:35 <dons> sorry for being distracting :)
19:32:31 <dons> ?users
19:32:32 <lambdabot> Maximum users seen in #haskell: 276, currently: 241 (87.3%), active: 3 (1.2%)
19:33:31 <sorear> sure enough, 'not build for interactive use'
19:34:21 <newsham> this "monad transformers step by step" is pretty good.  wish i had read this earlier
19:35:15 <lispy> newsham: it's certainly nice
19:35:18 <lispy> newsham: but it's very new
19:35:22 <lispy> i think
19:35:40 <lispy> so don't feel too bad if you've never seen it before :)
19:36:25 <sorear> I've fixed this ghc-bug
19:36:41 <sorear> now lets see what else {is,i've} broken
19:40:28 <shapr> newsham: Which one?
19:40:47 <newsham> ?where monad transformers step by step
19:40:48 <lambdabot> I know nothing about monad.
19:41:05 <newsham> http://uebb.cs.tu-berlin.de/~magr/pub/Transformers.en.html
19:41:11 <lambdabot> Title: Monad Transformers Step by Step, http://tinyurl.com/esboz
19:41:52 <shapr> I've heard of that one but haven't read it yet.
19:42:52 <LoganCapaldo> Autobots lead the battle to destroy the evil forces of the decepticons?
19:43:14 <dons> that's reasonable
19:44:08 <JohnnyL> anyone know if compaq laptops last?
19:45:40 <Excedrin> they're not as durable as thinkpads
19:46:04 <Excedrin> I'm not sure about any of the recent compaq laptops though
19:46:20 <Nafai> "Write Yourself a Scheme in 48 Hours" is pretty cool
19:49:37 <sorear> Wow. GHC compilation has set a new processor-temp record for me. (52*C)
19:49:54 <dons> cool. must be good
19:50:06 <sorear> prev record (45*C, povray | gcc, can't remember which)
19:53:06 <sorear> class Foo x y | x -> y
19:53:22 <sorear> instance (Foo a b, Foo c d) => Foo (a,c) (b,d)
19:53:24 <sorear> fails.
19:55:16 <dons> loosk a bit like my:
19:55:18 <dons> class (Functor f, Functor g) => NatTrans f g where
19:55:18 <dons>     eta :: f a -> g a
19:55:25 <dons> instance Model f g => NatTrans ((,) f) ((,) g) where eta (f,a) = (model f, a)
19:55:25 <dons> -- And finally, we can take any (m a) to (n b), if we can Model m n, and a b
19:55:26 <dons> instance (NatTrans m n, Model a b) => Model (m a) (n b) where model x = fmap model (eta x)
19:55:44 <sorear> the compiler can apparently not see the contexts while it is checking for overlaps?  I'm waiting to see if assoc type synonyms can handle this.  (Unfortunately this means that my vpt will require 6.7 :( )
20:01:25 <sorear> YES! Ghc compile successful!!! Ghci works!!!
20:01:35 <sorear> now to post my 1 line fix...
20:01:41 <dons> cool
20:02:34 <monochrom> How long did it take your computer to build ghc?
20:02:46 <sorear> ?seen sorear
20:02:47 <lambdabot> You are in #haskell. I last heard you speak just now.
20:03:07 <desrt> lambdabot has a sense of humour
20:04:13 <sorear> about 90 mins
20:05:15 <dons> mmm. I should try a ghc 6.6 builds with -j8 on the multicore box
20:05:22 * dons tries this
20:06:00 <JohnnyL> anyone here roll with a ps3?
20:13:07 * dons forks of a -j8 ghc build ...
20:14:03 <shapr> dons: Oh, your big box has arrived?
20:15:32 <dons> not yet. this is the small old box
20:15:42 <dons> only 4 cpus, 8 cores
20:15:58 <shapr> ah, so small :-)
20:16:02 <dons> teensy
20:18:52 <dons> base lib builtt
20:19:01 <dons> stage2 underway...
20:22:22 <newsham> so when you use monad transformers you dont have to lift your monad operations from one monad to another (except for IO which isnt part of the transformer set) ?
20:22:39 <monochrom> have to
20:22:45 <dons> done!
20:22:45 <dons> make -j8 > /dev/null  1290.87s user 146.16s system 247% cpu 9:41.48 total
20:22:57 <dons> aka "How to build GHC in 9minutes 41 seconds"
20:23:00 * greentea goes greener with envy.
20:23:26 <newsham> hmm, in this paper they're using "ask" and "tell" without lifting them.
20:23:27 <dons> that's my new record
20:23:31 <monochrom> I envy you.
20:23:36 * dons tweaks and tries some new fast flags
20:23:47 <eviltwin_b> well, that was cute.  haskell-mode from darcs whines about my not having a hugs menu.  which the ChangeLog suggests is a bug they'd fixed.
20:23:58 <monochrom> the inner monad needs lifting. the outer monad doesn't, of course.
20:23:58 * eviltwin_b sometimes "loves" xemacs...
20:23:59 <newsham> dons: is that a full triple build?
20:24:10 <Cale> newsham: that's fine so long as there's a lifting instance
20:24:12 <dons> full build, to the end of stage 2
20:24:22 <newsham> cale: I dont understand that sentance
20:24:25 <dons> i.e. how you build it if you get the tarball (and add some fast build flags)..
20:25:06 <Cale> newsham: well, ask and tell are methods of MonadReader and MonadWriter
20:25:42 <sorear> MonadReader/MonadWriter are automagically lifter
20:25:46 <sorear> s/er/ed/
20:26:01 <Cale> If you apply some transformer on top of a reader monad, and there's an instance (MonadReader r m) => MonadReader r (T m), then you don't need to lift.
20:26:02 <newsham> hmm.. whats the mechanism for automatic lifting?
20:26:15 <newsham> ahh..
20:26:17 <monochrom> OH!
20:29:01 <sorear> of course this uses icky incoherent-instances
20:29:41 <dons> ok. build underway..
20:29:44 <newsham> so thats one thing this paper doesnt mention is lifting, until it gets to the end and there's an IO monad involved.
20:30:08 <newsham> might have been good to mention "now we have to lift these operations, except for this case we're using, we dont have to because the lib already did it for us"
20:31:09 <newsham> otherwise really cool paper.. i learned lots.  I didnt really have exposure to the monad transformers yet
20:32:25 <dons> stage 1 done.
20:35:50 <sorear> GHC error: 'type synonym `RuntimeType' should have 1 argument, but has been given 1' !?
20:36:06 <sorear> no typo - 1 and 1.
20:36:19 <dons> libraries done.
20:36:23 * sorear is trying to get ATS's done.
20:36:48 <sorear> s/done/working/
20:37:00 <greentea> dons: So . . . . do you take cross-compilation requests? ;-)
20:38:10 <kfish> ?where+ hogg http://www.annodex.net/~conrad/software/hogg.html
20:38:10 <lambdabot> Done.
20:39:40 <dons> greentea: nice idea. i'll definitely do -j-based nightly buidls once the dedicated 16 core box arrives
20:39:45 <dons> kfish: is that a release?
20:39:51 <shapr> kfish: cool app
20:40:02 <dons> ok, and done, make -j4 > /dev/null  1142.52s user 133.04s system 208% cpu 10:12.43 total
20:40:10 <dons> so -J8 was a bit better
20:40:22 <greentea> dons: Excellent! :-D
20:42:07 <kfish> dons, shapr, maybe not a release, just admitting to myself that it does something useful ;-)
20:42:42 <dons> kfish: is it linked on the sound/music libraries page?
20:42:55 <dons> hey, is that a darcs-graph I see! :)
20:43:01 <dons> first non-dons user
20:43:06 <kfish> hah, really?
20:43:21 <kfish> i copied your page layout, so i needed a darcs-graph
20:43:46 <dons> btw, you can get nice TTF fonts, if you edit the Graph.hs file, and add ,"set terminal png font Vera 9 xffffff x000000 x404040 xd0d0d0 x0000ff"
20:43:56 <dons> you'll need Vera installed though ( that's the font used on my site)
20:44:03 <dons> kfish: heh ok
20:44:05 <kfish> it's not linked yet -- i'm using this more for video, so it's not just for sound/music
20:44:19 <dons> ok. so we need a new Video category..
20:44:19 <kfish> perhaps i'll add a Multimedia section or something
20:44:23 <dons> yeah
20:44:29 <dons> combined with the graphics stuff like Pan
20:44:57 <kfish> that page needs hierarchies :-)
20:45:06 <dons> it does
20:45:20 <kfish> maybe mimicking the package hierarchy ...
20:49:55 <kfish> hmm, perhaps Ogg should go into Data.Codec.Container
20:54:29 <hyrax42> Data.Multimedia.Container?
20:55:20 <hyrax42> are the standard hierarchies ok for people to add to, or must it go through the lib process?
20:55:33 <dons> if its your package, you can pick any name
20:55:49 <dons> there's some suggested guidelines out there though
20:55:58 <kfish> well, I was thinking of something vaguely following http://www.haskell.org/~simonmar/lib-hierarchy.html
20:56:00 <lambdabot> Title: Haskell Library Hierarchy, http://tinyurl.com/lphbd
20:58:03 * SamB wonders how to to take maxima output like...
20:58:05 <SamB> [[e21 = (-e4-e3+e2+e1+2*%r1)/2,e31 = (-e4+e3-e2+e1+2*%r2)/2,
20:58:05 <SamB>   e32 = -(-e4-e3-e2+e1+2*%r2+2*%r1)/2,e41 = e4-%r2-%r1,e42 = %r2,e43 = %r1]]$
20:59:16 <SamB> and find some values for e21, e32, e32, e41, e42, e43 that work with some specific values for e4 etc...
21:00:07 <SamB> well, I suppose it is simpler if you feed maxima the values for e[1-3] ;-)
21:00:14 <SamB> er. e[1-4]
21:00:37 <SamB> instead of the variable names...
21:04:44 <kfish> dons: anyway, added to Sound and Music -- Multimedia would be too bare ;-)
21:05:11 <dons> ok
21:09:11 <dons> so, for those wanting to crank up their ghc build times, http://cgi.cse.unsw.edu.au/~dons/blog/2006/12/03#build_ghc_fast
21:09:13 <lambdabot> Title: Haskell, hacking and other stuff, http://tinyurl.com/yyu2xm
21:33:36 <hyrax42> is there a good example/simple use of Control.Parallel(.Strategies) to show what ti does?
21:33:46 <hyrax42> the lib docs are completely useless
21:34:31 <dons> yeah, let me find it ...
21:34:54 <hyrax42> oh I think I found
21:34:58 <hyrax42> gentle intro to gph
21:34:59 <hyrax42> ?
21:35:24 <dons> down the bottom, http://www.haskell.org/ghc/dist/current/docs/users_guide/lang-parallel.html
21:35:26 <lambdabot> Title: 7.15. Concurrent and Parallel Haskell, http://tinyurl.com/zqwkf
21:35:28 <dons> yeah, the gph docs probably help too
21:36:25 <dons> feel free to ask on haskell-cafe@, its a hot topic atm
21:36:36 <hyrax42> oh really
21:36:45 <hyrax42> I have not watched cafe ina while
21:36:51 <hyrax42> I guess really I'm too busy to be looking htis up right now
21:37:14 <dons> the smp rts, and the availability of multicore macs, suddenly makes implicit parallelism via Control.Parallel very interesting
21:38:18 <hyrax42> rts = ?
21:38:24 <sorear> run time system
21:38:34 <hyrax42> and it sounds like there is no implicit parallelism?  You need to annotate evyerhthing
21:38:52 <sorear> Haskell makes annotation easy.
21:38:55 <hyrax42> ahhh I always though RT Stack
21:39:29 <hyrax42> and multicore macs as opposed to computers in general :?
21:39:53 <dons> macs with 2 cores are common now amongst haskell users
21:39:55 <hyrax42> yeah I think concurrency/parallelism will be my little reading project over the holidays
21:40:16 <hyrax42> dons, ah.. haskell users are a concentration area for macs?
21:40:25 <dons> when people's everyday laptop needs parallelism, then things get interesting
21:40:35 <hyrax42> true enough
21:40:38 <hyrax42> I wish mine did
21:40:42 <hyrax42> silly ibook g4
21:41:13 <sorear> I've got 4 cpu's... one in my PC, one in father's PC, one in mother's PC, one in video recorder PC.  <bemoans inability to set up parallel whatchamacallit>
21:41:29 <sorear> All 2Ghz P4's.
21:41:40 <sorear> 2GB total ram.
21:42:01 <sorear> Virtually never simultaneosly active. *sigh*
21:42:10 <dons> gee. you need gph for cluster-based haskell... ;)
21:42:21 <hyrax42> total in this apt is 5 cores, 5 CPUs, 6.5 GB RAM I think
21:42:22 <newsham> if only there were operating systems where resources could easily be accessed over the network
21:42:46 <hyrax42> actually 6 cores, 5 cpus
21:42:51 <hyrax42> roommate's lappy is core duo
21:43:00 <hyrax42> anyway, I will go to bed now
21:43:04 <hyrax42> thanks for the links, dons
21:43:10 <sorear> Oh, yeah, and 2 pc's are windows, two linux.
21:43:40 <sorear> Does GpH require homog. cluster?
21:43:57 <dons> not sure.
21:43:58 <hyrax42> I don't think gph is distributed?
21:44:01 <hyrax42> oh it is?
21:44:05 <sorear> (not like I'd be able to get the privledges anyways...)
21:44:21 <hyrax42> ok forget my question I msut sleep
21:45:33 <newsham> an operating system where all resources could be accessed in a simple and uniform way wether they are local or remote
21:45:48 <SamB> oh, you mean plan9?
21:45:49 <newsham> something that made accessing devices as simple as reading and writing files
21:45:54 <newsham> ahh!  plan9!  perfect!
21:46:14 <SamB> I assume you already know about plan9?
21:46:27 <newsham> used it once or twice ;-)
21:47:31 <SamB> I've never heard of anything save plan9 where the windowsystem was a filesystem ;-)
21:48:34 <Excedrin> inferno
21:48:43 <SamB> well, okay, maybe inferno
21:48:52 <SamB> that limbo stuff freaks me out though
21:49:20 <SamB> a little too OOP, I think
21:50:30 <sorear> how about an OS based on haskell?  "Sorry. You lack sufficient privledges to use unsafePerformIO."
21:50:38 <SamB> unfortunately I don't think it does the same for threads
21:50:47 <newsham> the filesystem is the major abstraction.  the window system is a filesystem, the net stack is a filesystem, the audio device is a filesystem, etc..
21:50:55 <dons> sorear: you've seen House?
21:51:13 <newsham> also since the filesystem is a network filesystem, it works similarly in a local environment or a distributed env
21:51:15 <sorear> heard of, not looked at...
21:52:33 <SamB> but can it solve my simultanious linear equations for integral non-negative values -- they have too many variables...
21:53:16 <Excedrin> http://www.fujipress.jp/finder/xslt.php?mode=present&inputfile=IPSTP004700160002.xml
21:53:20 <lambdabot> Title: A Network Programming Framework in Haskell Based on Asynchronous Localized pi-ca ..., http://tinyurl.com/y9xtju
21:53:29 <Excedrin> I'd like to read that but it's apparently not available, and it's in Japanese...
21:53:51 <SamB> why the hell is the title in english, then?
21:54:17 <kfish> SamB: because it looks better on their publication lists
21:54:18 <dons> mm
21:54:29 <dons> Excedrin: what's this then?
21:54:51 <dons> nice
21:55:57 * SamB goes to bed
21:56:25 <dons> SamB: applying your dyn loading patches to lambdabot, btw...
21:56:32 <dons> just trying to ensure they make sense
22:06:49 <lispy> oh, what do they do?
22:07:14 <dons> fixes building lambdabot the dynamic way, via the cabal script
22:08:45 <lispy> hmm...i thought that worked already?
22:11:26 <Excedrin> http://tsukimi.agusa.i.is.nagoya-u.ac.jp/~sydney/PiMonad/
22:11:31 <lambdabot> Title: PiMonad - a network programming framework based on Pi-Calculus, http://tinyurl.com/y2ylt2
22:14:14 <newsham> ?type readRefSTM
22:14:16 <lambdabot> Not in scope: `readRefSTM'
22:22:28 <sieni> stupid macports
22:22:41 <sorear> ?type readTVar
22:22:42 <lambdabot> Not in scope: `readTVar'
22:22:56 <sorear> ?type Control.STM.readTVar
22:22:58 <lambdabot> Couldn't find qualified module.
22:23:08 <newsham> sor: found that. thanks.
22:23:46 <newsham> ?hoogle readTVar
22:23:47 <lambdabot> GHC.Conc.readTVar :: TVar a -> STM a
22:24:27 <shapr> dons: btw, why doesn't hs-plugins work on 6.6?
22:24:51 <shapr> Excedrin: Hey, that looks cute
22:25:07 <sieni> shapr: I asked the same, I think it was combination of some incompatibility with .hi files (+ lazy dons ;-)
22:25:25 <Excedrin> shapr: it doesn't build under ghc 6.6 :(
22:25:26 <shapr> oh
22:25:33 <shapr> Excedrin: yeah, but I want to know *why*
22:25:39 <newsham> hs-plugins evaluates lazily and it hasnt gotten around to 6.6
22:25:44 * shapr snickers
22:25:57 <Excedrin> shapr: (oh, I meant PiMonad
22:26:11 <sieni> I wonder why hs-plugins isn't part of ghc distribution :-o
22:26:16 <Excedrin> the Coverage Condition fails for one of the functional dependencies
22:26:40 <dons> shapr: ok: a) the ghc .hi file format changed. b) the typeable interface changed c) the package format changed
22:26:47 <dons> i need to fix these. and i'm getting there :)
22:27:05 <dons> an hs-plugins interface based on libHSghc is more maintainable in the longer term though
22:27:19 <dons> since ghc would have to build for it work , which means SimonM can maintain it.. ;)
22:27:43 <dons> but, hs-plugins for 6.6 will be done soon.
22:27:49 <dons> and it will be smaller, since the typeable stuff can be junked
22:27:59 <dons> certainly done by the hackathon
22:32:00 <dons> Excedrin: http://programming.reddit.com/info/tf7t/comments
22:32:03 <lambdabot> Title: PiMonad: a Pi calculus implementation for Haskell (reddit.com), http://tinyurl.com/vukng
22:32:18 <dons> this is super cool stuff. how come we don't see it announced on the haskell@ lists?
22:32:21 <dons> :/
22:35:24 <Cale> Someone apparently wasn't informed that integration into the collective Haskell hive-mind is mandatory.
22:36:06 <dons> we really should make that clear
22:36:27 <dons> perhaps ghc could print on start up :    "Assimilation is mandatory"
22:36:50 <dons> "You will submit to the lambda hive-mind"
22:37:03 <dons> something like that should do the trick
22:37:07 <Cale> Being Japanese is not an excuse.
22:37:36 <dons> they're worse than the secret russian cabal. kfish you need to lively up some of these guys!
22:41:18 <dons> oh my, data O a
22:41:19 <dons> = O Int
22:41:30 <dons> ah, that's an 'O' not a '0'
22:42:27 <dons> hey jmuk
22:42:34 <jmuk> hello,
22:43:54 <dons> jmuk: any idea why so many .jp haskell researchers don't announce their work on the haskell@haskell.org mailing list?  For example, we found this today: http://tsukimi.agusa.i.is.nagoya-u.ac.jp/~sydney/PiMonad/  seems really nice.
22:43:55 <lambdabot> http://tinyurl.com/y2ylt2
22:43:59 <dons> but we'd never know about it.
22:44:20 <dons> what can be done to improve publicity of .jp-based researchers and haskell programmers, in the wider haskell community?
22:44:22 <jmuk> mmm
22:45:45 <dons> it would be nice to start a japanese translation of the haskell.org wiki too. we have spanish and romanian, but there's so much japanese material out there, it would be good to collect it under haskell.org/haskellwiki/Jp
22:45:46 <jmuk> I am not researcher of haskell, so i dont know them...
22:46:06 <dons> perhaps that's why we know about your work ;)
22:46:09 <jmuk> Maybe, there are two haskell community, one is researchers,
22:46:22 <bd_> @pointless \f g v -> (f v) (g v)
22:46:22 <lambdabot> ap
22:46:33 <bd_> a builtin? nice
22:46:33 <jmuk> the other is programmers, I belong to this
22:46:38 <dons> jmuk: yeah. that could be it. the researchers are happy to just publish papers
22:46:44 <lispy> ?pl \f g v -> (f v) (g v)
22:46:44 <lambdabot> ap
22:46:48 <dons> but the programmers know they need to release and announce their work
22:46:56 <bd_> @pointless \f g -> join $ \a1 a2 -> (f a1) (g a2)
22:46:57 <lambdabot> (join .) . flip . ((.) .)
22:47:30 <lispy> bd_: if you're interested in saving keystrokes you can just pl if you like
22:47:40 <emu> it helps to drive in the point
22:47:40 <dons> @pl \f x -> f x
22:47:41 <lambdabot> id
22:47:44 <bd_> heh
22:47:44 <emu> or the lack of it
22:47:45 <bd_> thanks
22:47:54 <bd_> is there a command-line version of lambdabot? >.>
22:48:02 <dons> yeah
22:48:07 <dons> and a ghci version, and a web version
22:48:09 <lispy> bd_: there is GHCi on Acid
22:48:13 <bd_> Acid?
22:48:14 <lispy> ?where lambdaweb
22:48:14 <lambdabot> http://lambdabot.codersbase.com
22:48:20 <emu> and a version you can download directly into your brain
22:48:27 <bd_> nono, I mean, lambdabot's commands in a tty program
22:48:29 <dons> and that one. yes, the brain implant
22:48:36 <dons> bd_: exactly that
22:48:50 <lispy> bd_: right, ghci on acid is just lambdabot incorporated into ghci
22:48:59 <dons> $ ./lambdabot
22:49:00 <dons> Initialising plugins ................................................... done.
22:49:00 <dons> lambdabot> pl \x f y -> y (f y x)
22:49:00 <dons> (ap id .) . flip flip
22:49:00 <dons> lambdabot> Exception: <eof>
22:49:03 <lispy> bd_: you can interact with haskell or lambdabot that way from the same session
22:49:07 <dons> that's the normal lambdabot, there's also a ghci binding
22:49:17 <shapr> Hm, I wonder if I can run lambdabot on my Nokia 770...
22:49:28 <shapr> Then I could keep a running copy of lambdabot in my pocket!
22:49:29 <lispy> bd_: you can also /msg lambdabot  or use the url i provided
22:49:42 <sieni> bd_: Acid is a slang expression for lysergic acid diethylamide
22:49:43 * lispy ponders the implications
22:50:02 <bd_> ah, an AJAXy lambdabot?
22:50:09 <lispy> ya
22:50:12 <bd_> hmm
22:50:23 <bd_> not quite as good as a console version, but good nonetheless. thanks :)
22:50:36 * glguy just picked up his copy of *The Seasoned Schemer*, finishing his collection of the 3 Schemer books
22:50:49 <lispy> it needs a little love, but some of us are too scattered brained to work on it anymore /me glares at lispy
22:51:00 <dons> bd_: there is a console version, i don't understand what you're asking?
22:51:01 <bd_> hm though
22:51:07 <dons> there is both a console and a ghci version
22:51:10 <bd_> oh
22:51:16 <bd_> wait, I'm confused now XD
22:51:22 <dons> the ghci version/binding is just an interface to the console version
22:51:22 <bd_> the link given above is an AJAXy version
22:51:34 <dons> and that's the web interface to the console version :)
22:51:39 <lispy> bd_: lambdabot has many, many incarnations
22:51:42 <bd_> which... seems a bit broken, as '4 + 4' and '> 4 + 4' don't work :p
22:51:52 <dons> oh?
22:51:53 <lispy> bd_: really?
22:51:57 <lispy> was working last night
22:51:57 <dons> was working yesterday
22:52:03 <dons> better check...
22:52:09 <lispy> indeed, checking now
22:52:12 <dons> > 3+4 --should work
22:52:14 <lambdabot>  7
22:52:27 <bd_> I'll pastebin the error
22:52:28 <lispy>         *  Failed to load interface for `ShowFun':
22:52:29 <lispy>         * Could not find module `ShowFun': use -v to see a list of the files searched for
22:52:33 <dons> oh
22:52:36 <nornagon> oh, it's a bd_.
22:52:39 <bd_> ... yeah, that
22:52:57 <lispy> dons: how do i fix this?
22:53:01 * bd_ darcs goa
22:53:01 <dons> lispy: you probably forgot to move ShowFun.{hi,o} into the lambdabot dir?
22:53:04 <lispy> and why did it used to work
22:53:07 <dons> remember how you copy the tree in your web setup?
22:53:20 <lispy> i use a script
22:53:23 <lispy> so i better modify it
22:53:25 <dons> there should be a : ShowFun.hi, ShowFun.o in the same dir as the binary
22:54:23 * lispy edits and re-runs the build script
22:54:52 <lispy> interesting that ghc always relinks
22:55:03 <lispy> even when skipping all modules
22:55:45 * lispy is put off by the extra long linking time
22:56:04 <shapr> I thought 6.6 didn't do that?
22:56:25 <lispy> 6.6 also doesn't support hs-plugins :)
22:56:47 <lispy> at least last time i pestered dons it didn't
22:56:58 <shapr> oh yeah
22:57:04 <lispy> bd_: try it now
22:57:08 <lispy> bd_: all seems to be merry
22:57:43 <bd_> looks good :)
23:03:46 <lispy> dons: if .hi information were embeddable in the .o file do you think that would increase the linkability of haskell object files?
23:04:09 <lispy> like, maybe cross compiler or for creating dynamic objects which worked cross compiler?
23:04:26 <lispy> ya know, make a sort of Haskell ABI that way
23:05:16 <sieni> imao hs-plugins should be part of the ghc distribution
23:10:01 <dons> sieni: yeah, though as it is, its too clunky. a stripped down version for ghc could be a core lib, even better (imo) would be to be part of the ghc-api
23:12:40 <eviltwin_b> lispy: actually doable on COFF and ELF systems.  (woudl that still screw openbsd?)
23:13:01 <dons> just stick the .hi info in an elf section
23:13:09 <dons> it'd make ghci loading faster too, i suspect
23:13:17 <dons> since you wouldn't have to suck in those extra .hi files
23:13:28 <dons> probably not terribly portable though
23:13:51 <sorear> How about embedding the full object code into the .hi?
23:14:22 <lispy> dons: don't the .o files have places to stick string constants?
23:14:29 <lispy> maybe it could be sneaked into there?
23:14:33 <dons> yeah, and you can create custom sectoins anyway
23:14:39 <sorear> In C, strings go to .rodata
23:15:26 <eviltwin_b> on ELF systems you can do that.  on a.out, well, it's doable with a lot of hackery (see gcc's "collect" stuff on an a.out system)
23:15:38 <dons> do we have any a.out systems left?
23:15:39 <sorear> If we are writing our own dynamic-linker *anyway*, why use the platform object format?  Can't we just standardize on ELF/custom format?
23:16:01 <eviltwin_b> I dunno, I thought openbsd still was (hence my question earlier)
23:16:01 <dons> well, we want to support std C dynlinkers too
23:16:09 <dons> nope. its elf for the last 5 or 6 years
23:16:21 <sorear> a.out systems, that had hardware updates recently enough to *hold* ghc's heap
23:16:22 <dons> since '02 or so
23:16:25 <eviltwin_b> but I thik most folks have migrated, because a.out is just too much of a PITA wspecially if you want to support C++
23:17:20 <sorear> Why do we need to support C opening of Haskell objects? I was imagining having the *final* haskell linker output platform objects.
23:17:37 <sorear> But use internal format for separately-compiled modules.
23:17:55 <dons> its already supported on the mac, and almost on the x86/linux machines
23:18:10 <dons> we want it since then the final haskell binaries are tiny
23:18:26 <sorear> Are there use cases other than ghc-compiled executable and ghc-compiled dll I'm forgetting?
23:18:27 <dons> since we can share libHSrts, libc, libgmp, ...
23:18:55 <lispy> dons: oh, that's cool
23:19:04 <dons> foreign language applications with embedded haskell ?
23:19:14 <sorear> When we drop the haskell type-info (no use at runtime), why not change from GHC-extended-elf to standard-format
23:19:16 <dons> dont' want to statically link libHSrts into vim just to have some haskell scripting
23:19:35 <sorear> yes, thus libHSrts would be a native library
23:19:43 <shapr> sorear: hs-plugins could use it at runtime.
23:20:20 <shapr> There are many good uses of proof carrying code, but I think it's off-topic for the moment :-)
23:20:27 <sorear> Ow!  Do you have to use FACTS on me!  My idea is deflating, help!!!
23:20:53 <dons> heh
23:20:59 <dons> ?yow
23:21:00 <lambdabot> Once, there was NO fun ... This was before MENU planning, FASHION
23:21:00 <lambdabot> statements or NAUTILUS equipment ... Then, in 1985 ... FUN was
23:21:00 <lambdabot> completely encoded in this tiny MICROCHIP ... It contain 14,768 vaguely
23:21:00 <lambdabot> amusing SIT-COM pilots!!  We had to wait FOUR BILLION years but we
23:21:00 <lambdabot> finally got JERRY LEWIS, MTV and a large selection of creme-filled
23:21:02 <lambdabot> snack cakes!
23:21:02 * glguy thought that sorear was doing a ?yow
23:21:04 <dons> yikes!
23:21:14 <shapr> wow, yow spam!
23:21:20 <glguy> ?yow spam
23:21:20 <lambdabot> If you can't say something nice, say something surrealistic.
23:21:30 <shapr> oh, I like that one!
23:21:31 <dons> ?vixen spam
23:21:31 <lambdabot> i find it hard to masturbate when the lights are on.
23:21:35 <dons> yikes!
23:21:40 <shapr> !
23:21:50 <dons> blackdog snuck some evil into vixen
23:22:05 <dons> she's just a bit perverse when things don't compute
23:24:23 <sorear> just checked /usr/include/asm-i486/a.out.h, (granted this is Linux not openBSD), it looks like a sized format - can we append Haskell tables to the file?
23:24:51 <sorear> use the size fields to seek over code and read the table
23:25:06 <sorear> bonus: the kernel won't read this "useless" data
23:25:15 <eviltwin_b> many implementations will refuse to execute a file which is the wrong size for its content on the assumption that it's a viral modification
23:25:17 <glguy> > let scramble = aux [] where aux xs [] = []; aux xs (y:ys) = (y:xs) !! y : aux (y:xs) ys in scramble [0,0,0,2,3,1,0,0,8,1]
23:25:18 <lambdabot>  [0,0,0,0,0,3,0,0,0,8]
23:26:06 <eviltwin_b> the usual hack is weird symbols (this is how C++ gloal constructors/destructors and debug information used to be done)
23:27:10 <sorear> I want haskell-types to be in a separate section where they can be lazily (read: never) demand-loaded into RAM.
23:27:34 <eviltwin_b> symbols don't get loaded into RAM
23:29:13 <sorear> oh right - I was confusing myself with eviltwin's "global constructors" and GCC's putting-constructor-addresses-into-a-section-labelled-with-symbols. Sorry.
23:29:17 <eviltwin_b> you really don't have many options with a.out except symbol table hacks; that's why eeryone switched to ELF (or ECOFF which is COFF with some ELF extensions --- AIX3/4 and Tru64 used it)
23:29:59 <eviltwin_b> constructors were handled by giving them magic symbol names which something else collected and stuck somewhere useful.  see gcc's "collect"
23:30:16 <eviltwin_b> (on an a.out system)
23:30:22 <sorear> how much pain can we expect from telling a.out folks to use 6.6?
23:30:27 <lispy> hmm...sounds like there are ways to do this, but would it really be helpful?
23:30:45 <lispy> i guess that was the other part of my question
23:31:29 <thedatabase> dons: I find it hard to masturbate when I can't download GOA with darcs.  What gives?
23:31:31 <thedatabase> $ darcs get --partial http://www.cse.unsw.edu.au/~dons/goa
23:31:32 <thedatabase> Invalid repository:  http://www.cse.unsw.edu.au/~dons/goa
23:31:32 <thedatabase> darcs failed:  Failed to download URL http://www.cse.unsw.edu.au/~dons/goa/_darcs/inventory
23:31:32 <thedatabase> libcurl: HTTP error (404?)
23:31:34 <lambdabot> http://tinyurl.com/yapfy4
23:31:57 <lispy> thedatabase: it's a permission problem on dons' end
23:32:01 * eviltwin_b used unsafePerformIO for debugging earlier tonight.  mmm, dirty :>
23:33:10 <thedatabase> thanks lispy.... i'll try again later :)
23:33:25 <dons> thedatabase: checking..
23:33:26 <lispy> dons: i thought you had a cron job or something to fix up those permissions
23:34:09 <dons> thedatabase: wrong url..
23:34:17 <lispy> oh
23:34:17 <dons> http://www.cse.unsw.edu.au/~dons/code/goa, no?
23:34:18 <lambdabot> Title: Index of /~dons/code/goa
23:34:25 <dons> $ darcs get --partial http://www.cse.unsw.edu.au/~dons/code/goa
23:34:25 <dons> Copying patch 42 of 42... done!
23:34:25 <dons> Applying patch 42 of 42... done.
23:34:25 <dons> Finished getting.
23:34:26 <lambdabot> Title: Index of /~dons/code/goa
23:34:35 <lispy> i'm so used to the permission problem, i assumed the wrong thing
23:35:05 <lispy> dons: i was wondering, do you plan on doing a release of lambdabot in the near future?
23:35:16 <lispy> dons: i was thinking of only upgrading lambdaweb when you do a release
23:36:16 <lispy> or should i consider lambdabot to permamently be in release state?
23:39:47 <thedatabase> dons: my bad!  All better now, sorry to disturb ;0)
23:44:06 <dons> lispy: when we hit 400 patches or so, or the hackathon
23:44:08 <dons> one of those
23:44:37 <lispy> dons: cool
23:44:44 <lispy> hackathon++
23:45:33 <dons> ?vers
23:45:34 <lambdabot> lambdabot 4p287, GHC 6.5 (OpenBSD i386)
23:45:34 <lambdabot> darcs get http://www.cse.unsw.edu.au/~dons/lambdabot
23:52:19 <glguy> maybe release when 6.6 is supported?
23:53:21 <dons> yeah
23:53:40 <vegai> was it still possible to build it without hs-plugins?
23:56:04 <dons> it is yes. and does so by default
23:58:01 <dons> ?users
23:58:02 <lambdabot> Maximum users seen in #haskell: 276, currently: 233 (84.4%), active: 21 (9.0%)
