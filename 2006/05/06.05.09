00:11:00 * dcoutts notes that after the final SoC application deadline we have 104 applications!
00:11:08 <dcoutts> !!!
00:12:04 <dcoutts> @karma+ xerox
00:12:04 <lambdabot> xerox's karma raised to 13.
00:12:53 <shapr> I think we have ten hours left.
00:13:23 <dcoutts> shapr, I thought applications closed
00:13:34 <zarvok> they extended the deadline
00:13:36 <zarvok> until 11 am tomorrow
00:13:42 <zarvok> Due to server trouble
00:13:46 <dcoutts> ah ok
00:13:48 <shapr> Hiya zarvok 
00:13:58 * dcoutts reads email and notices same
00:14:13 <zarvok> hi
00:14:17 <shapr> I'm still not on the mentors list...
00:14:37 <zarvok> the SoC channel was madness around the original submission deadline
00:14:43 <zarvok> since the servers were down
00:14:47 <shapr> Truly
00:15:49 <zarvok> so 104 and counting, pretty impressive
00:16:39 <shapr> Yeah, I was amazed at 50.
00:16:46 <shapr> Now I'm just overwhelmed.
00:17:21 <zarvok> heh, now I'm worried
00:17:26 <dcoutts> @seen syntaxninja
00:17:26 <lambdabot> I saw syntaxninja leaving #haskell 3 days, 6 hours, 26 minutes and 37 seconds ago, and .
00:17:27 * zarvok is a student
00:17:37 <zarvok> too much competition! :)
00:24:51 <shapr> zarvok: Hey, are you getting my private messages?
00:25:09 <shapr> g'day blackdog 
00:35:30 <Cale> http://www.haskell.org/haskellwiki/Monads_as_Containers
00:39:54 <shapr> Cale: Is that the normal code coloring critter?
00:41:05 <Cale> I painstakingly added some of the colours myself.
00:41:28 <Cale> but the code blocks are just using the standard one
00:42:08 <Cale> now, where should I link it
00:43:05 <Cale> I also think that it would be nice to move the HaskellNewbie section over, only that the licensing issues involved there are hideously complex unless ignored.
00:46:08 <Cale> http://www.haskell.org/hawiki/FirstSteps is also a really good intro, and should be moved across
00:48:08 <Cale> possibly merged with the Learning page on the new wiki
00:51:14 <shapr> zarvok: ping
00:57:40 * lispy thinks it would be really nice to not stay up overly late one night this week :)
00:57:48 <lispy> @localtime lispy
00:57:49 <lambdabot> Local time for lispy is Tue May  9 00:57:24 2006
00:57:58 <lispy> lambdabot: curse you!
00:58:05 * lispy runs to bed in a flury
01:00:48 <Captain_Fourier> run lispy!
01:43:07 <Cale> metaperl: you around?
01:50:00 <Cale> hmm, I think we should have a better index for wiki articles than just the automatic Categories listing.
02:18:09 <musasabi> Anyone have a nice way to make vim autoindent Haskell?
02:34:22 <kombinator> GHC 6.4.1 fails to parse string literals with utf-8 characters in them, is that normal?
02:34:38 <kombinator> utf-8 was supposed to be compatible with ascii
02:34:54 <kzm> That should work.
02:35:11 <kzm> how does it fail?  Error?
02:35:16 <kombinator> I'm getting "Test.hs:3:13: lexical error in string/character literal" from ghci
02:35:20 <kzm> Or just unexpected results?
02:35:27 <kzm> Ah, in source.
02:37:12 <kombinator> but codes for "high" characters should not conflict with ascii codes
02:37:17 <kombinator> so I dont
02:37:27 <kombinator> understand what's the problem
02:38:26 <Cale> GHC's lexer in 6.4.1 has trouble dealing with unicode characters outside of ASCII.
02:38:35 <dons> > '\12321'
02:38:36 <lambdabot> '\12321'
02:38:38 <dons> :)
02:38:49 <dons> but unicode chars in the head should be ok
02:38:59 <Cale> you can explicitly represent the characters you need with escapes too, though that's annoying
02:39:06 <kombinator> right
02:39:40 <kombinator> so it has also trouble with dealing with latin1/2 I guess
02:39:54 <Cale> I'm not sure, but I think so
02:40:00 <kombinator> as they contain 128-255 codes
02:40:03 <musasabi> 6.4.1 + Latin1 is fine.
02:40:15 <musasabi> For 128-255
02:40:24 <Cale> okay, I can't say I've ever tried it :)
02:41:12 <morans> I don't think a text processor can be simultaneously happy with both utf and latin1, though...
02:41:23 <Cale> (though I had tried Greek and Japanese, and those certainly don't work)
02:42:01 <Cale> hmm, I thought that Latin-1 was primarily a subset of UTF-8.
02:42:09 <musasabi> morans: I think it goes from "latin-1 works" to "utf-8 works"
02:42:36 <musasabi> Cale: but most latin1 text with octets >128 is invalid UTF8.
02:42:49 <Cale> oh, really?
02:42:50 <Cale> hmm
02:42:54 <musasabi> All valid UTF-8 is valid Latin1 + control characters.
02:42:59 <kombinator> ascii is a subset of UTF-8
02:43:36 <pesco> Cale: The top bit is used, in effect, to signal "multibyte".
02:43:38 <Cale> musasabi: that's sort of the opposite relationship than what I'd though
02:43:40 <Cale> t*
02:43:59 <Cale> ah
02:44:09 <kombinator> http://en.wikipedia.org/wiki/UTF-8
02:44:19 <pesco> musasabi: Which byte sequence is not valid Latin1 + control chars?
02:44:36 <musasabi> Cale: basically every octet is valid Latin1+control characters. Not all valid latin1 sequences are valid utf8.
02:45:18 <musasabi> pesco: I was saying the reverse.
02:45:40 <pesco> musasabi: Okay, misunderstanding.
02:46:53 <Cale> valid, but not necessarily meaningful, then
02:47:18 <Cale> (surely UTF-8 doesn't embed into Latin-1)
02:47:43 <kzm> This is Comp.Sci - we worry about "valid".  "meaning" is somebody else's problem :-)
02:48:07 <Cale> heh
02:48:33 <musasabi> Cale: All UTF8 byte sequences are valid Latin1 byte sequences (they have different meanings).
02:48:43 <musasabi> but the reverse is not true.
02:49:20 <kzm> Depends on what level you are "embedding".
02:49:44 <kzm> At the Char level, Latin1 is a subset of Unicode, while UTF-8 can represent the entire range.
02:50:03 <kzm> At the representation level, any octet stream is valid Latin1, but not UTF-8.
02:52:32 <dcoutts> kombinator, the problem is if your utf8 char needs more than one byte then when that's interpreted in altin1 then it's not a valid char because it's actualy two or three chars.
02:52:59 <dcoutts> and if you did it in a string you'd get a utf8 encoded string which is not what String is supposed to be
02:53:19 <dcoutts> what ghc should do is decode the utf8 into a Haskell String
02:53:49 <kombinator> dcoutts: well, encoding one char in many would also satisfy me
02:54:26 <kombinator> dcoutts: but GHC 6.4 refuses to parse my literals
02:54:34 <dcoutts> right
02:54:51 <dcoutts> because ghc 6.4.x treats the source as latin1, not as utf8
02:55:32 <dcoutts> the current 6.5 development branch does utf8
02:56:33 <kombinator> dcoutts: right, but isn't every byte sequence a proper latin1 sequence? I thought GHC will accept any sequence
02:57:12 <dcoutts> that's true, it's a proper latin1 sequence, but it isn't a valid character literal
02:57:25 <dcoutts> is this a valid char literal 'ab' ?
02:57:29 <dcoutts> > 'ab'
02:57:30 <lambdabot>  Not in scope: `ab''
02:57:42 <dcoutts> ?
02:57:46 <dcoutts> > 'a'
02:57:47 <kombinator> I'm trying to write string literals
02:57:47 <lambdabot> 'a'
02:57:55 <kombinator> > "a"
02:57:56 <lambdabot> "a"
02:57:59 <kombinator> > "Ä…"
02:58:00 <lambdabot>  lexical error in string/character literal
02:58:30 * dcoutts checks the lexer
02:58:43 <dcoutts> kombinator, but even if it worked it wouldn't be a proper String
02:58:49 <dcoutts> because it'd be in utf8
02:58:55 <dcoutts> which is not what String is
02:59:07 <kzm> > "blÃ¥bÃ¦r"
02:59:08 <lambdabot> "bl\195\165b\195\166r"
02:59:12 <morans> | <musasabi> All valid UTF-8 is valid Latin1 + control characters.
02:59:14 <kombinator> yes, but putStr would write what I want, right?
02:59:19 <kzm> UTF8, interpreted as raw bytes
02:59:23 <dcoutts> kombinator, only by accident
02:59:24 <morans> musabi: what does that mean?
02:59:51 <morans> oh oh
02:59:55 <morans> i see yeah fine
03:01:12 * kzm is puzzled. Why doesn't it work?  What's with the 'a' with the funny appendage?
03:04:40 <kombinator> kzm: for some reason its UTF-8 sequence isn't accepted by ghc 6.4, it is accepted by hugs, though
03:07:08 <dcoutts> kombinator, not all latin1 sequences are valid string literals of course. That'd explain why some utf8 sequeces are ok and others are not.
03:07:25 <kombinator> dcoutts: I see
03:07:57 <dcoutts> the basic point is that it wont work at the moment and if it does at the moment by accident then your prog will break when ghc does it correctly
03:08:26 <dcoutts> because putStr will continue to only output the low bytes
03:09:04 <xerox> Michael's \feed looks interesting!
03:09:06 <dcoutts> you'd need a putStr with a utf8 encoder
03:11:13 <resiak> dcoutts: May I /msg you regarding .ox.ac.uk things?
03:11:39 <dcoutts> resiak, aye
03:12:39 <morans> what space of characters can haskell represent in the spec?
03:13:12 <dcoutts> all of Unicode
03:13:47 <kombinator> > maxBound :: Char
03:13:48 <lambdabot> '\1114111'
03:13:58 <kombinator> not bad;)
03:15:30 <kzm> Any quick way to identify a runaway recursive function?  My stack blows up, and it would be nice if GHC could tell me what causes it :-)
03:15:55 <xerox> Profile your program
03:16:02 <xerox> Or read it carefully (-:
03:16:47 * kzm has tried the reading thing, but so far, has only achieved a headache.
03:17:32 <amiddelk> kzm: what about Hat (http://www.haskell.org/hat/)
03:18:10 <xerox> I think adding two options to GHC is straightforward - modulo imported libraries not being compiled for profiling problems.
03:19:12 <kzm> how is Hat support for advanced features these days?
03:19:42 <kzm> I looked at it a while ago, but ruled it out.  ISTR UArray as one culprit.
03:20:15 <amiddelk> kzm: latest release is a year ago, so it probably is still bad
03:20:41 <shapr> audreyt: Hey, did you get the info about user space STM on top of Peng Li and Steve Zdancewic's unified thread/event framework?
03:36:33 * Beelsebob__ checks
03:36:47 <Beelsebob__> Haskell can't have mutually dependant modules can it?
03:36:56 <dcoutts> it can
03:37:04 <Beelsebob__> in the standard or in a specific implementation?
03:37:11 <dcoutts> in the standard
03:37:23 <dcoutts> ghc needs boot files to do it
03:37:31 <Beelsebob__> okay, cool
03:41:02 <audreyt> shapr: no... where?
03:46:28 <shapr> audreyt: discussion on #haskell yesterday
03:46:45 <shapr> audreyt: I got started on it because of your question about the SoC project
03:47:27 <audreyt> ah. I missed the backlog
03:47:41 <audreyt> executive summary? :)
03:47:56 <shapr> userspace STM on top of Peng Li and Steve Zdancewic's's userspace Control.Concurrent
03:50:37 <shapr> audreyt: One nifty feature is that the SoC applicant wants to use resumption monads instead of CPS
03:51:56 <shapr> My only real question is how this will fit with GHC-SMP.
03:52:53 <audreyt> intriguing.
03:53:09 <musasabi> Basically it will look like "OS threads > haskell threads with RTS (+locking) > haskell threads in Haskell (+locking)" I think.
03:53:50 <dcoutts> I don't get that proposal, how is it different (better?) than ghc's current STM implementation?
03:54:03 <shapr> If this purely userspace STM & Control.Concurrent can still take advantage of ghc-smp, I am totally in favor.
03:54:39 <musasabi> shapr: It can take advantage of that, but how fast it will be on SMP is an another story.
03:54:41 <shapr> dcoutts: Well, consider that Li & Zdancewic's pure Haskell Control.Concurrent is not part of the RTS.
03:55:15 <shapr> You might be able to run it on Hugs, or any Haskell implementation.
03:55:18 <dcoutts> that's a concurrent based on CPS monads right?
03:55:25 <audreyt> Resumption Monad Transformers (ResT)
03:55:35 <dcoutts> so it's sort of cooperative concurrency
03:55:38 <shapr> The SoC applicant wants Resumption Monads, yeah.
03:55:39 <audreyt> I guess any good acronym deserves multiple expansions
03:56:07 <shapr> I haven't looked very hard, but ResT appears to be more 'tractable' than pure CPS.
03:56:41 <dcoutts> so we want to do cooperative concurrency in pure Haskell and use STM in that?
03:58:00 <shapr> It would move STM out of the RTS and into a space where we can hack on it as a library. I like that idea.
03:58:40 <musasabi> Of course if one does not need the concurrency then an IORef implementation is trivial.
03:59:09 <dcoutts> shapr, what does JaffaCake think of the idea?
03:59:27 * dcoutts isn't sold on it (mostly because he doesn't understand it)
04:00:00 <shapr> JaffaCake wants to mentor it.
04:00:09 <audreyt> shapr: ok, thanks, I think I grokked the idea. sounds good.
04:00:20 <shapr> I'm not totally sold on the idea because I don't clearly see its advantages.
04:00:30 <shapr> I wish JaffaCake would show up and tell us :-)
04:00:34 * dcoutts too
04:01:00 <audreyt> persumably it means the advantage is that people can hack in Hs instead of in C.
04:01:02 <shapr> I know this would be good for House.
04:01:16 <shapr> Yeah, the RTS is written in C and GHC-Haskell.
04:02:22 <shapr> It'll be a faster STM as well.
04:02:37 <shapr> What are the downsides? Will it still be pre-emptive?
04:03:19 <shapr> Li&Zdancewic's framework can only preempt when another continuation is called, right? The RTS can preempt at any allocation, iirc. Does that make a difference?
04:04:03 <musasabi> shapr: I don't think it will be pre-emptive, also will allocate more memory.
04:05:31 <dcoutts> shapr, why would it be a faster STM ?
04:05:54 <dcoutts> it can't be pre-emptive unless it's done at the rts level
04:06:04 <dcoutts> or at least has some rts support
04:06:46 <dcoutts> and it not being pre-emptive means you can't run time-consuming pure functions in their own thread and have them not block other things
04:06:47 <audreyt> but it builds on ConcHaskell
04:06:51 <audreyt> so it's already preemptive
04:07:06 <audreyt> on RTSs that implements preemptive ConcHaskell, that is.
04:07:16 <dcoutts> so what does it add then?
04:07:16 <audreyt> s/implements/allows/
04:07:31 <dcoutts> if we still need a underlying concurrency implementation?
04:07:34 <audreyt> portability of STM applications across Haskell implementations
04:07:44 <audreyt> implementors only has to implement forkIO
04:07:53 <dcoutts> hmm, ok
04:07:55 <audreyt> and get newTVar for free
04:11:38 <musasabi> except that STM is easy to implement for co-operative systems like JHC and Hugs and very fast.
04:13:27 <musasabi> -> lunch (will talk more when back)
04:14:54 <tic> Hello. Is there a DOM library for Haskell, i.e., that lets me read some random chunk of XML, and then process it?
04:15:20 <tic> (It's for a kind of templating language for XML)
04:16:06 <audreyt> HaXml surely?
04:17:20 <tic> Couldn't find any good examples though :/
04:20:41 <tic> Thing is.. I want to have an attribute for a tag, which is then called as a regular Haskell function. I.e., <h1 v:render="foo"/>, which should cause the function "foo" to be called. 
04:21:15 <tic> Problem is that it's not really possible to look up a random name and call it in Haskell, right? (typing)
04:25:41 <kolmodin> tic: 6211?
04:27:00 <shapr> You can 'preempt' by calling the scheduler instead of the next continuation?
04:29:45 <tic> kolmodin, jess.
04:29:58 <tic> kolmodin, kåmmeruhit?
04:31:53 <kolmodin> tic: yupp. överochut
04:41:26 <tic> kolmodin, bra!
04:49:24 <musasabi> back
04:50:19 <musasabi> There is a trivial implementation of STM on top of "IORef (IO ())" that is portable.
04:50:30 <musasabi> Various levels of locking can be added for that.
04:51:09 <musasabi> The fun things is how 1) mix blocking IO, 2) make more than one Haskell thread manipulate the same TVar concurrently.
04:51:50 <shapr> At this point, I'm intrigued, but don't really understand all the benefits & drawbacks of the SoC project.
04:52:50 <shapr> That is, the userspace STM on top of the unified thread/event framework.
04:58:11 <kombinator> shapr: perhaps the goal of that project is to enable porting STM to other haskell implementations, like YHC or hugs
05:01:33 <musasabi> kombinator: but there already exist at least two portable STM implementations.
05:01:49 <kombinator> musasabi: oh, didn't know
05:02:19 <musasabi> kombinator: the MVar one (was on the mailing lists as compatiblity with older GHC) and the IORef one.
05:31:02 <kolmodin> is there any way to pretty print the tree parsed by hsx?
05:37:16 <Beelsebob__> @hoogle maybe
05:37:17 <lambdabot> Prelude.maybe :: b -> (a -> b) -> Maybe a -> b
05:37:17 <lambdabot> Maybe :: module
05:37:17 <lambdabot> Prelude.Maybe :: data Maybe a
05:49:20 <shapr> Whoa this is great - "Characterizing People as Non-Linear, First-Order Components in Software Development" - http://alistair.cockburn.us/crystal/articles/cpanfocisd/characterizingpeopleasnonlinear.html
06:10:38 <Itkovian> @type (>>>)
06:10:39 <lambdabot> forall (a :: * -> * -> *) d b c.
06:10:39 <lambdabot>    (Arrow a) =>
06:10:39 <lambdabot>    a b c -> a c d -> a b d
06:12:30 <ndm> @seen dons
06:12:31 <lambdabot> dons is in #haskell-overflow and #haskell. I last heard dons speak 3 hours, 33 minutes and 1 second ago.
06:12:47 <ndm> anyone well know much about C and Linux?
06:12:59 <ndm> http://haskell.org/haskellwiki/Wc#Going_via_C
06:13:13 <ndm> is there any reason for the C code to import those two headers?
06:13:25 <ndm> on Windows neither are necessary, and one is fatallly bad (because it doesn't exist)
06:15:06 <dcoutts> ndm, I don't understand
06:15:18 <dcoutts> that page provides wc.c & wc.h
06:15:24 <ndm> dcoutts, if you look at the C code, it has as #include
06:15:32 <ndm> #include <sys/types.h>
06:15:34 <ndm> #include <unistd.h>
06:15:35 <dcoutts> ah ok
06:15:47 <ndm> are they really required on Linux?
06:15:56 <ndm> unistd doesn't exist on Windows
06:16:03 <ndm> and it compiles fine with neither of them
06:16:14 <hyrax42> > (1-) 2
06:16:15 <lambdabot> -1
06:16:18 <dcoutts> I wouldn't think so, the program isn't using anything from them it looks like
06:16:20 <hyrax42> > (-1) 2
06:16:21 <lambdabot>  add an instance declaration for (Num (t -> a))
06:16:23 <dcoutts> ndm, let me try it...
06:16:34 <ndm> cheers - i don't want to break linux users :)
06:16:41 <yaarg> probably because windows doesn't care about portability
06:16:57 <dcoutts> ndm, it's not needed.
06:17:20 <hyrax42> can't section - in that way at all?
06:17:26 <hyrax42> > ((-) 1) 2
06:17:27 <lambdabot> -1
06:17:29 <eivuokko> yaarg, If posix layer is not used, unistd.h is correct not to be on path.
06:17:31 <hyrax42> ah
06:18:12 <ndm> dcoutts, cheers, i managed to get it working with Hugs and WinHugs on Windows with the FFI - a first :)
06:18:23 <dcoutts> great
06:18:25 <eivuokko> Nice :)
06:22:08 <Itkovian> ndm: I can't see why you'd need unistd.h or types.h, as you are never calling a function as far as i can tell
06:22:21 <ndm> Itkovian: yep, i have removed them now
06:31:57 <ozone> shapr: that alistair cockburn article on people is an excellent read, cheers
06:34:18 <dons> dcoutts: thanks for the patches!
06:34:25 <dcoutts> np :-)
06:34:46 <dons> we're at the point that we should be looking for these micro-optimisations, as you say
06:34:48 <dcoutts> dons, was the unfoldrN limited for a reason? or just an oversight?
06:35:17 <dons> limited?
06:35:27 <dcoutts> dons, got my latest patch?
06:35:34 <dons> oh, haven't read that yet. let me see...
06:35:35 <dcoutts> about unfoldrN
06:35:57 <dons> ah, oops.
06:35:57 <dcoutts> dons, I wasn't particularly looking for micro-optimisation, just reading the code as I try and do the .Lazy version
06:36:20 <dons> yeah, as with fold, it shouldn't have the more specific type.
06:36:33 <dcoutts> ok, good
06:37:12 <dcoutts> for unfoldrN on lazy bytestrings I need a local version of P.unfoldrN that returns the 'seed'
06:37:19 <dcoutts> so I can carry on in the next chunk
06:37:37 <dons> ah, right.
06:37:55 <dcoutts> so the N parameter now means "chunk size"
06:38:03 <dcoutts> rather than total length
06:38:23 <dcoutts> so you never loose anything, just waste part of the end block
06:39:46 <dcoutts> perhaps it should be called something else though
06:39:55 <dcoutts> because it doesn't have the same meaning
06:40:36 <dons> hmm.
06:40:55 <dons> unfoldChunks :)
06:41:45 <dcoutts> I think I might have a few versions in the end with a tunable chunk size parameter
06:42:05 <dcoutts> because the chunk size is vaugely important for estimatng performance
06:42:12 <dons> yeah.
06:42:19 <dcoutts> the complexity of several other ops is O(n/c)
06:42:34 <dcoutts> ie total length / avg chunk size
06:42:47 <dcoutts> == # chunks
06:43:41 <dons> ok, time for bed. i'll apply the patches in the morning.
06:43:52 <dcoutts> g'night dons 
06:51:14 <shapr> ozone: Yeah it is, know of anything similar?
06:57:20 <shapr> I think the whole paper can be summarized with this one quote "The fit of a particular person's personality profile to the role given them has a large effect on the outcome of the project."
06:57:36 <shapr> The hard part is getting that right for a bunch of different people.
06:58:40 <cmarcelo> ozone / shapr: link for the article?
06:59:10 <kzm> http://alistair.cockburn.us/crystal/articles/cpanfocisd/characterizingpeopleasnonlinear.html
07:00:07 <cmarcelo> tks
07:00:21 <Magical1>  /join #os86x
07:04:54 <shapr> hey CosmicRay, ltns
07:06:26 <CosmicRay> hey shapr!
07:06:36 <shapr> Wassup?
07:06:40 <shapr> psnl: Cute hostname
07:07:07 <psnl> shapr: friend's box
07:09:00 <oNoX> hi
07:09:33 <oNoX> i'm trying to extract digits from a string, but groupBy doesn't really work
07:10:35 <oNoX> i have groupBy (isDigit) s, where s is a string
07:10:49 <SamB> oNoX: what do you want to do with them?
07:11:12 <musasabi> oNoX: how about filter?
07:11:28 <musasabi> > filter Char.isDigit "foo 215 bar"
07:11:29 <lambdabot> "215"
07:11:53 <oNoX> well, if need to get ["12", "34"] out of "ab12c34d"
07:14:38 <shapr> JaffaCake!
07:14:45 <JaffaCake> hiya
07:14:59 <shapr> Can you explain to me what's good about userspace STM on top of Li&Zdancewic's threads/events framework?
07:15:10 <JaffaCake> no :)
07:15:14 <shapr> oh
07:15:19 <sieni> stm?
07:15:26 <JaffaCake> as in, I'm not sure it's good
07:15:31 <shapr> oh!
07:16:20 <shapr> Your offer to sponsor that project motivated several bits of discussion about the merits.
07:16:41 <JaffaCake> I think it's an interesting experiment to try, certainly
07:16:50 <shapr> What do you think might be good or bad about it?
07:16:56 <sieni> url?
07:17:22 <JaffaCake> well, I still remain to be convinced about the whole user-space scheduling thing...
07:17:32 <shapr> The obvious advantages are user hackable STM/Concurrent, and STM/Concurrent for Hugs, JHC, etc.
07:17:54 <JaffaCake> sure
07:18:24 <shapr> musasabi pointed out that there are two portable STM implementations already.
07:18:33 <JaffaCake> there are, yes
07:18:44 <shapr> <musasabi> The fun things is how 1) mix blocking IO, 2) make more than one Haskell thread manipulate the same TVar concurrently.
07:19:30 <shapr> I guess I feel the same way, it'll be interesting, but I don't know where it's going.
07:20:00 <shapr> Do you think resumption monads are better than CPS for this?
07:20:19 <JaffaCake> I really don't know
07:20:27 <JaffaCake> sorry :)
07:20:32 <shapr> heh, ok
07:20:58 * JaffaCake has a head full of ICFP reviewing
07:21:02 * SamB walks around shapr, looking for a concealed tape recorder
07:21:07 <shapr> SamB: What?
07:21:23 <musasabi> evening
07:21:27 <shapr> JaffaCake: Sorry don't mean to distract you from real work :-)
07:21:44 <JaffaCake> hehe, well what am I doing on IRC?
07:21:47 <SamB> shapr: you almost sound like you are doing an interview
07:21:52 <shapr> ICFP reviewing?
07:22:10 <JaffaCake> yeah, ICFP prog committee
07:22:57 <shapr> SamB: Well, JaffaCake seemed to have a positive opinion about something that I did not understand. So I wished to understand it. First I read the papers, then I asked the awake #haskell people, and then JaffaCake showed up and I had the issues clearly set out in my head.
07:22:59 <dcoutts> JaffaCake, if you want distracting... :-) I'm unconvinced about the CInt/Int issue from the other day.
07:23:31 <JaffaCake> dcoutts: oh? what about it?
07:23:46 <shapr> Finding something that I do not understand makes me crazy. I must figure it out.
07:24:07 <JaffaCake> shapr: I don't have a deep understanding of it yet, but I plan to find out too
07:24:17 <dcoutts> JaffaCake, I don't understand how we'd get the results we see given the ways that we can munge 32 & 64 bit ints. Also I don't see why it'd be different for -fvia-C vs -fasm. And I'd expect gcc to warn in the -fvia-C case.
07:24:42 <dcoutts> JaffaCake, so on amd64 CInt is 32bit & Int is 64 bit
07:25:01 <oNoX> musasabi: how do I split to ["215", "2465"]?
07:25:05 <dcoutts> but that doesn't explain how we get the unsigned wrapping I think.
07:25:30 <oNoX> musasabi: how do I split to ["215", "2465"]?
07:25:34 * SamB wonders what dcoutts is talking about
07:25:36 <oNoX> oops, srry
07:25:39 <JaffaCake> dcoutts: it's to do with the way we compile C calls - gcc always adds the required promotion of the result type, but the NCG relies on GHC to add a promotion
07:25:55 <dcoutts> I'd expect we'd either get the sign-extend 32bits (ie all 1's) or the low 32bits which should be the answer we thought we were looking for
07:25:58 <JaffaCake> GHC adds a promotion in the desugarer if necessary
07:26:26 <JaffaCake> you are getting the low 32 bits, no?
07:27:23 * dcoutts tries to work it out
07:27:59 <dcoutts> it looks like we're getting the low 32bit but interpreted as unsigned
07:28:03 <JaffaCake> the fact that we add an explicit promotion is a bit of a hack, I can't remember why we did it that way but there's probably comments and/or commit logs
07:28:13 <JaffaCake> yes, that's right
07:28:31 <dcoutts> why would that be?
07:28:44 <JaffaCake> the C function returns the result as 32 bits, the caller interprets it as 64 bits 
07:29:10 <JaffaCake> the fact that the upper 32 bits are zero is probably a coincidence
07:29:29 <dcoutts> right, ok
07:29:48 <dcoutts> it's a shame we can't detect that kind of mistake when going via C
07:30:12 <dcoutts> gcc should complain that we're narrowing a 64bit value to 32bit
07:30:39 <JaffaCake> hmm, I wonder why it doesn't
07:30:39 <SamB> dcoutts: with or without a cast?
07:30:56 <dcoutts> SamB, dunno, it depens on what ghc is generating
07:31:04 * dcoutts looks at the .hc code...
07:31:50 <dcoutts> _s1EZ = (W_)c_id((I_)(R1.p[1]));
07:32:07 <SamB> ack!
07:32:11 <dcoutts> that's with: foreign import ccall unsafe "c_id" c_id :: Int -> IO Int
07:32:17 <SamB> that is *HORRIFIC*
07:32:59 <SamB> that (W_) does look like a cast, though
07:33:09 <JaffaCake> the result type is cast, yes
07:33:23 <JaffaCake> but the argument type is I_, which is a "long"
07:33:27 <SamB> oh
07:33:52 <dcoutts> let me try an ordinary C example...
07:34:04 <SamB> where were you thinking that GCC ought to warn?
07:34:33 <JaffaCake> for the argument type, I'd have thought
07:35:05 <SamB> isn't that cast too?
07:35:20 <JaffaCake> the function expects an int, the argument type is long
07:36:08 <dcoutts> isn't it long long
07:36:16 <dcoutts> long is 32bit in C on amd64
07:36:35 <JaffaCake> no, long is 64 on amd64
07:36:48 <dcoutts> really? oh ok
07:36:53 <dcoutts> void foo() {
07:36:53 <dcoutts>         long long n = 1;
07:36:53 <dcoutts>         n = c_id(n);
07:36:53 <dcoutts> }
07:36:58 <dcoutts> gcc -Wall -c cbit.c
07:37:03 <dcoutts> no complaints :-(
07:37:10 <JaffaCake> heh
07:37:16 <dcoutts> where: int c_id (int n) {
07:37:16 <dcoutts>  ... }
07:37:27 <dcoutts> no loss of precision warning :-(
07:38:54 <SamB> okay, you might be right
07:44:00 <eivuokko> What's the deal with ghc's "Rules.findBest: rule overlap (Rule 1 wins)" on head?  I get it and it seems from fromIntegral, is it a problem?
07:44:20 <SamB> why would it be a problem?
07:44:35 <SamB> what were the names of the rules, anyway?
07:44:37 <eivuokko> Because it's two screens of text that comes after that.
07:45:06 <SamB> at worst it would be a performance problem
07:45:26 <eivuokko> fromIntegral/CInt->a and fromIntegral/a->CInt as far as I see..
07:45:39 <SamB> oh, that should be just fine
07:45:45 <eivuokko> Well, it makes it hard to see warnings
07:46:08 <eivuokko> Oh, well, I can live with it.
07:46:17 <SamB> would be nice if there was a way to get GHC to stop telling you about fromIntegral rules...
07:46:24 <dcoutts> JaffaCake, -Wconversion might help, not quite sure
07:46:29 <SamB> ..because those do that a lot
07:46:30 <dcoutts> http://gcc.gnu.org/onlinedocs/gcc-4.1.0/gcc/Warning-Options.html#Warning-Options
07:46:55 <eivuokko> I guess I could also disable rules or optimisations :)
07:48:00 <JaffaCake> dcoutts: does -Wconversion cause a warning to be generated?
07:48:16 <dcoutts> JaffaCake, yeah, but not quite the one I'd hoped for
07:48:42 <Igloo> JaffaCake: Has there been a decision on whether or not to release a 6.4.3?
07:49:07 <JaffaCake> Igloo: I think we probably should
07:49:24 <dcoutts> JaffaCake, in which case what about the cabal version?
07:49:33 <JaffaCake> to get the MacOS X issues fixed, and the threading problem on Solaris/FreeBSD
07:49:38 * dcoutts puts his Cabal release manager hat on
07:49:47 <JaffaCake> dcoutts: you're the man, tell me what to do :)
07:50:14 <dcoutts> JaffaCake, well it depends on how strict you're feeling about ghc minor releases and APIs
07:50:17 <Igloo> OK, cool. I can probably skip 6.4.2 then  :-)
07:50:40 <dcoutts> Igloo, hah, so that's why you asked :-)
07:50:58 <JaffaCake> dcoutts: do you think we should go to 1.1.5 for 6.4.3?
07:51:10 <JaffaCake> I'm happy if you are
07:51:21 <dcoutts> JaffaCake, well we'd call it 1.1.6 but probably, yes.
07:51:35 <dcoutts> JaffaCake, what kind of time frame were you looking at?
07:51:53 <dcoutts> We'd want to do some more thourough testing for a release
07:51:58 <JaffaCake> well, ideally after the Haskell Workshop deadline
07:52:00 <JaffaCake> 2 June
07:52:06 <dcoutts> and perhaps branch
07:52:09 <dcoutts> right, ok
07:52:39 <JaffaCake> also we haven't found the problem with threading on Solaris/FreeBSD yet
07:52:53 <dcoutts> perhaps we could do cabalised happy & alex releases at the same time :-)
07:53:09 <dcoutts> or did I mean haddock
07:53:30 <JaffaCake> yes, possibly
07:54:30 <Igloo> There's no reason to release them all at once is there? So that would just mean holding up some things until the others were ready...
07:54:38 <eivuokko> Hey, that reminds me. Is http://darcs.haskell.org/alex broken?  I can't darcs (1.0.6) get it without getting darcs error on applying patch 18
07:54:57 <dcoutts> Igloo, well it'd be good to make sure that the cabal we use can build the other tools
07:55:59 <Igloo> True
07:57:10 <ndm> eivuokko: try --partial
07:57:18 <eivuokko> ndm, the repo has no checkpoints
07:57:34 <JaffaCake> eivuokko: you on windows?
07:57:40 <eivuokko> JaffaCake, Yeah
07:57:50 <eivuokko> JaffaCake, And yeah, I think it only happens in Windows..
07:57:58 <JaffaCake> problem with non-case-sensitive filesystem, probably
07:58:02 <eivuokko> Ah
07:58:17 <eivuokko> Could someone put checkpoint tag in sometime?
07:58:19 <JaffaCake> partial might help
07:58:32 <JaffaCake> ah, it needs a checkpoint ?
07:58:40 <eivuokko> Let me try once more
07:58:56 <eivuokko> Yeha, partial doesn't affect atm.  Needs a checkpoint
08:00:07 <musasabi> JaffaCake: are there concrete plans on with the idea of a smaller base package?
08:00:12 <musasabi> -on
08:00:39 <JaffaCake> musasabi: yeah, there's a ticket somewhere
08:00:46 <JaffaCake> look for "library reorganisation"
08:00:56 <Beelsebob__> o_O 
08:00:58 <Beelsebob__> Expecting a function type, but found `t_a6Jru'
08:02:39 <eivuokko> Why did ByteString go in base and not a stand-alone package?
08:03:28 <JaffaCake> eivuokko: we will probaby want to use it in other low-down libraries at some point
08:03:36 <eivuokko> JaffaCake, Ok.
08:04:09 <musasabi> http://hackage.haskell.org/trac/ghc/ticket/710 seems like the correct one.
08:04:31 <JaffaCake> yep
08:04:43 <hyrax42> @index LineBuffering
08:04:43 <lambdabot> System.IO
08:06:01 <musasabi> Control.Concurrent and System.Posix could also perhaps move from base.
08:08:44 <musasabi> Is the plan to make base = haskell-prime libraries + some extensions, or base = something completely separate from haskell-prime library spec ?
08:10:46 <JaffaCake> musasabi: system.posix is not in the base... only the signal handling
08:11:11 <musasabi> and Internals and Types.
08:11:30 * musasabi remembered more of it was in base.
08:11:35 <JaffaCake> musasabi: base == Prelude + bits required by Prelude, is my rule of thumb
08:12:43 <JaffaCake> musasabi: System.Posix.Signals can be moved, but internals and types are required by the IO library
08:13:46 <musasabi> My main worry is with Cabal and packages depending on base-package and that not telling whether they use GHC.LazestFeature or Data.Char (that other compilers will probably also have)
08:14:45 <JaffaCake> musasabi: yes, I had a vague plan for that... but we need an extension to the packaging system to support packages that re-expose modules
08:14:48 <musasabi> + the same version of base has a different API depending on the compiler used.
08:15:22 <musasabi> That sounds like a solution.
08:27:06 <eddyp> CosmicRay: got the lil' patch?
08:35:34 <hyrax42> can you map actions?
08:35:56 <Cale> hyrax42: yes, depending on exactly what you mean
08:36:11 <hyrax42> well can I map a "function" that prints stuff over a list?
08:36:21 <Cale> yeah, use mapM for that
08:36:29 <hyrax42> not regular map?
08:36:33 <hyrax42> @index mapM
08:36:33 <lambdabot> Control.Monad, Prelude, Control.Monad.Reader, Control.Monad.Writer, Control.Monad.State, Control.Monad.RWS, Control.Monad.Identity, Control.Monad.Cont, Control.Monad.Error, Control.Monad.List
08:36:42 <Cale> well, with regular map, you'll just get a list of actions
08:36:53 <hyrax42> ah ok
08:37:00 <hyrax42> hm
08:37:02 <Cale> which you could then apply sequence to, but mapM does that for you
08:37:19 <Cale> Control.Monad is the module you're looking for
08:37:49 <hyrax42> tutorial says I should use mapM_
08:37:52 <hyrax42> for printing
08:38:02 <hyrax42> so that return is IO ()
08:38:02 <hyrax42> ?
08:38:20 <Cale> mapM_ will throw away the results, yeah
08:38:47 <hyrax42> if I were to use mapM would I get type errors if nothing was down with results after
08:38:50 <hyrax42> or
08:38:52 * hyrax42 has idea
08:38:56 <hyrax42> try it
08:40:25 <hyrax42> thanks Cale
08:40:35 <Cale> largely no, it's just if it occurs as the last action in the block, it'll affect the type of the block. mapM is also likely to be ever so slightly more efficient
08:40:38 <Cale> er
08:40:41 <Cale> mapM_ rather
08:41:32 <hyrax42> ah yeah
08:41:39 <hyrax42> in this case changes it from IO [()] to IO ()
08:41:45 <Cale> mhm
08:41:57 * hyrax42 feels like he's slowly getting somewhere
08:42:25 <Cale> mapM/mapM_ are the primary way that you handle loops
08:42:44 <hyrax42> that is good to know, going in
08:46:16 <Cale> JaffaCake: what do you think of this idea: for each class constraint on a data type, record a pointer to the appropriate class dictionary in each value. This would ensure that functions who needed that class dictionary to work with values of that type would have it, even if it wasn't mentioned in the class context of their type.
08:47:17 <Cale> (of course, this has some pretty big typing implications)
08:49:43 <Cale> You probably wouldn't want to use it without an explicit type signature somewhere which lacked the necessary class context
08:58:45 <petekaz> newbie question on laziness: does laziness imply memoization of functions as well?  For example, in most languages this is a terrible implementation of fib, is that the case in haskell as well?  Or are the repeated calls to fib memoized?
08:58:49 <petekaz> fib 0 = 0
08:58:49 <petekaz> fib 1 = 1
08:58:50 <petekaz> fib n = fib (n-1) + fib (n-2)
08:59:06 <SamB> it is still terrible!
08:59:10 <Cale> petekaz: in that case, no, functions aren't memoized
08:59:21 <Cale> but constant values are
08:59:46 <Cale> fibs = map fib [0..]
08:59:49 <Cale> fib 0 = 0
08:59:52 <Cale> fib 1 = 1
09:00:04 <Cale> fib n = fibs !! (n-1) + fibs !! (n-2)
09:00:40 <Cale> now, (!!) isn't terribly efficient, and this would be better served by an array or tree of some kind, but here, you'll see some benefit at least
09:01:06 <hyrax42> but in that method, doing fib n would leave it uncomputed in fibs, right?
09:01:34 <Cale> yeah, but it would cause all the elements before the nth to be computed in fibs
09:01:40 <hyrax42> as in fib (n + 1) would end up recomputing fib n, though the lead-up work is done
09:01:46 <hyrax42> what's the zipWith solution again
09:02:01 * petekaz scratches head
09:02:09 <Cale> fibs = 0 : 1 : zipWith (+) fibs (tail fibs)
09:02:12 <petekaz> laziness takes a bit to get used to.
09:02:24 <hyrax42> oh!! I was putting the 0:1: in the second arguemtn to zipWith
09:03:01 <hyrax42> petekaz: yeah
09:03:13 <petekaz> In a purely functional language, couldn't all functions be memoized if they always return the same values?
09:03:32 <hyrax42> probably a feasibility issue
09:03:52 <Cale> petekaz: not all values can be compared for equality
09:03:54 <hyrax42> <- newbie as well, so grain of salt
09:03:59 <Cale> and not all equality tests are cheap
09:04:07 <petekaz> In my opinion, the fib def I pasted is definitely the easiest to understand and read.
09:04:09 <Cale> and sometimes you care about memory usage more than time
09:04:19 <petekaz> I see.
09:04:23 <petekaz> That makes sense.
09:04:24 <Cale> so it's really tough to automatically decide what to memoise
09:05:31 <Cale> you can strike a balance using a locally defined array
09:05:43 <SamB> I think C++ templates are a purely-functional language in which all functions are memoized.
09:06:36 <eivuokko> Not all implementation memoize, tho
09:06:36 <CosmicRay> eddyp: nope, no mail from you yet.
09:06:53 <eddyp> hmm, maybe is in the spam box?
09:07:06 <SamB> which implementations don't
09:07:06 <SamB> ?
09:07:22 <Cale> import Array
09:07:22 <Cale> fib n = 
09:07:22 <Cale>   let
09:07:22 <Cale>     fibs = array (0,n) [(i,fib' i) | i <- [0..n]]
09:07:22 <Cale>     fib' 0 = 0
09:07:25 <Cale>     fib' 1 = 1
09:07:26 <eivuokko> I am fairly sure that atleast Microsft's doesn't, as it takes typically much less memory
09:07:27 <Cale>     fib' n = fibs ! (n-1) + fibs ! (n-2)
09:07:29 <Cale>   in fib' n
09:08:11 <SamB> eivuokko: hmm.
09:08:20 * eddyp is just trying another build (for another package)
09:08:29 <Cale> there, the memoising array is constructed for each call to fib, but will be preserved for the whole computation
09:08:44 <SamB> in any case, I care little, for I do not write such code, and am far more concerned about the time/space for e.g. compiling Haskell programs with GCC...
09:08:50 <eddyp> CosmicRay: I get a lot of consecutive 
09:08:50 <eddyp> procThisDep: my arch is i386
09:09:08 <petekaz> On a different note (still related to laziness), someone the other day posted a link to the wiki book section on foldl, foldl', and foldr.  But this morning I was reading YAHT (at the gym, only nerd reading haskell I bet!), and it makes the claim that foldl is more efficient than foldr even though foldr can work on infinite lists.  If I understood the wiki book correctly, foldl is more or less pointless due to laziness, thus the YAHT
09:09:10 <petekaz> claim that foldl is more efficient than foldr, is not really true, unless referring to foldl' right?
09:09:29 <SamB> probably not
09:09:30 <CosmicRay> eddyp: right, I saw it, I will have to look at it later (hacking on Bacula right now)
09:09:32 <Cale> petekaz: yeah, usually
09:09:43 <SamB> I don't rembember if foldl is ever really more efficient
09:09:44 <petekaz> Because Haskell cannot take advantage of tail-recursion unless its strictly evaluated.
09:09:44 <hyrax42> petekaz: haha I was thinking of printing and taking for the hamster wheel as well
09:09:59 <eddyp> CosmicRay: probably is because of the recursive nature of haskell ;-)
09:10:02 <Cale> foldl will build up expressions really quickly, but then those expressions still have to be evaluated
09:10:30 <petekaz> More importantly, and really my point, is that foldl with blow the stack very fast.
09:10:38 <Cale> yes, that too
09:10:40 <SamB> yeah, that does seem to be true
09:10:50 <Cale> if you're using foldl, you probably really want foldl'
09:10:53 <petekaz> When other FL like erlang, foldl works great, due to strictness.
09:10:55 <SamB> we were playing with it in lambdabot a while back, and we blew the stack a *lot*
09:11:16 <Cale> > foldl (+) 0 [1..100000]
09:11:17 <lambdabot> 5000050000
09:11:17 <petekaz> So this all led me to ponder, why even have a foldl implementation?
09:11:24 <Cale> > foldl (+) 0 [1..1000000]
09:11:25 <SamB> (fortunately, it was not lambdabot's stack that we blew)
09:11:26 <lambdabot> Exception: stack overflow
09:11:29 <Cale> > foldl' (+) 0 [1..1000000]
09:11:31 <lambdabot> 500000500000
09:11:43 <SamB> I don't know why we have foldl!
09:11:53 <Cale> petekaz: sometimes you have to do a left fold, but you still want laziness
09:12:16 <petekaz> And on a related note, are there other functions that are tail-recursive in haskell that are waiting to bite my in the ass like this foldl?
09:12:31 <petekaz> Cale: example?
09:12:58 <petekaz> And one last question?  How is foldl' implemented?  Is there some strict operator or something?
09:13:00 <Cale> hmm :)
09:13:02 <Cale> oh
09:13:12 <mauke> seq, $!
09:13:16 <petekaz> That one could apply to his/her own tail-recursive algos?
09:13:22 <Cale> foldl' is implemented with seq or $!, yes
09:13:33 <osqulda> where can one learn about rank-2 polymorphsm and a comparison between System F and Haskell?
09:13:35 <SamB> hmm, what is director and why do I need a plugin for it to see the worked solutions to the problems in my calculus book...
09:13:50 <Cale> foldl' f z [] = z
09:13:54 <davidhouse_> $! is strict application, right? so anyFunction $! _|_ == _|_
09:14:21 <SamB> yes
09:14:27 <Cale> foldl' f z (x:xs) = (foldl' f $! f z x) xs
09:14:29 <Cale> iirc
09:14:54 <petekaz> I see.
09:15:11 <Cale> and
09:15:22 <Cale> f $! x = x `seq` f x
09:15:39 <SamB> hmm, is a haskell implementation allowed to not notice that the value of an expression was _|_, and instead act as if it has a value?
09:15:59 <Cale> > const 5 undefined
09:16:01 <lambdabot> 5
09:16:09 * SamB is aware that this would be idiotic
09:16:14 <petekaz> Cale: neat, thanks.  Are there any other foldl-like functions that I should be avoiding so as not to blow my stack?
09:16:27 <Cale> scanr
09:16:42 <SamB> I don't even know what scanr is supposed to do
09:16:54 <davidhouse_> @index seq
09:16:55 <Cale> scanr (+) 0 [1..5]
09:16:55 <lambdabot> Prelude, Control.Parallel
09:16:57 <Cale> > scanr (+) 0 [1..5]
09:16:58 <lambdabot> [15,14,12,9,5,0]
09:17:30 <Cale> actually, I'm not sure if it's tail-recursive, but it sure isn't lazy
09:17:37 <hyrax42> > scanl (+) [1..5]
09:17:38 <lambdabot>  add an instance declaration for (Num [a])
09:17:40 <Cale> > take 10 $ scanr (+) 0 [1..1000000]
09:17:43 <lambdabot> Exception: stack overflow
09:17:47 <hyrax42> I mean
09:17:55 <hyrax42> > scanl (+) 0 [1..5]
09:17:56 <Cale> > take 10 $ scanl (+) 0 [1..1000000]
09:17:56 <lambdabot> [0,1,3,6,10,15]
09:17:57 <lambdabot> [0,1,3,6,10,15,21,28,36,45]
09:18:14 <davidhouse_> > const 5 $! undefined
09:18:15 <lambdabot> Undefined
09:18:22 <davidhouse_> > const 5 $ undefined
09:18:23 <lambdabot> 5
09:18:54 <SamB> > scanr' (+) 0 [1..1000000]
09:18:55 <lambdabot>  Not in scope: `scanr''
09:18:58 <SamB> aww
09:19:09 <SamB> oh well, forgot to "take 10" anyway
09:19:50 <Cale> as for actual examples of where foldl is better than foldl', I'm not sure
09:20:01 <Cale> It makes sense that they'd exist :)
09:20:03 <petekaz> Well, I think I'm actually starting to understand some of this.
09:20:07 <davidhouse_> > take 20 $ scanl (+) 1 [1,1..]
09:20:08 <lambdabot> [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]
09:20:31 <petekaz> I can't wait for my Intro to FP by Bird arrives.
09:20:36 <Cale> well, I could come up with something really artificial
09:20:45 <petekaz> Does that talk about laziness in haskell as well?
09:20:54 <SamB> maybe we should rename it to foldl_lazy to discourage accidental use?
09:20:55 <petekaz> Cale: that's ok.
09:20:57 * davidhouse_ gets all the bottom stuff, he just does't understand how (f _|_ = _|_ => f is strict) has anything to do with laziness
09:21:00 <SamB> I mean, if the uses for it are so few...
09:21:04 <Cale> > foldl (\x y -> if x > 20 then x else y) 0 [1..1000000]
09:21:06 <lambdabot> Exception: stack overflow
09:21:12 <Cale> hmm, nope :)
09:21:35 <Cale> right, it would have to be a list of compound structures
09:21:43 <petekaz> SamB: foldl_tailrecursive_and_lazy
09:21:43 <SamB> ...it won't really matter if its name is five characters longer
09:21:43 <Cale> not single numbers
09:22:12 <petekaz> It's that combination in particular that seems disasterous.
09:22:21 <SamB> lazy is the opposite of strict
09:22:24 <davidhouse_> hey, making things ugly to discourage use works for unboxed types.
09:22:56 <Cale> Well, it somehow makes sense that foldl is the ordinary one, and foldl' is the one with the added strictness trick.
09:22:59 <SamB> davidhouse: that, and the fact that you need -fglasgow-exts to spell the names
09:23:11 <Cale> oh, has everyone seen my diagram of folds?
09:23:27 <SamB> Cale: how is "blows the stack in the majority of cases" considered "normal"?
09:23:28 <Cale> http://cale.yi.org/autoshare/folds.png
09:23:42 <Cale> SamB: not the majority of cases :)
09:23:54 <Cale> well, depending on how you measure
09:24:05 <Cale> sure, there are infinitely many cases in which it does :)
09:24:07 <SamB> well, maybe not the majority of playing-around-with-it cases
09:24:53 <Cale> but you have to get up around 1000000 elements in your list before you start to see that, and there are plenty of real-world applications which don't fold lists that long
09:25:06 <SamB> oh really?
09:25:16 <SamB> the stack is that big?
09:25:21 <Cale> well, yeah
09:25:30 <Cale> > foldl (+) 0 [1..100000]
09:25:31 <lambdabot> 5000050000
09:25:33 <SamB> how does that interact with threads?
09:25:35 <Cale> > foldl (+) 0 [1..500000]
09:25:36 <dcoutts> the stack size is not fixed
09:25:37 <lambdabot> 125000250000
09:25:40 <Cale> > foldl (+) 0 [1..700000]
09:25:41 <lambdabot> Exception: stack overflow
09:25:42 <dcoutts> it grows as necessary
09:25:48 <petekaz> It just seems to me that the purpose of writing a tail-recursive function is to avoid stack overflow, but in haskell, that happens anyways because of laziness.  Is there some prog guidelines for newbies that state things like "do not write tail-recursive functions unless you make them strict".
09:26:02 <SamB> dcoutts: I'm surprised that there is nothing impeding its growth ;-)
09:26:18 <Cale> > foldr (+) 0 [1..700000]
09:26:20 <lambdabot> Exception: stack overflow
09:26:22 <wchogg> Hrmm...if foldl isn't that useful in alot of cases, why is foldM a left fold?
09:26:37 <petekaz> Which is faster?  foldl or foldl'?  Assuming no stack overflow.
09:26:37 <SamB> well, it isn't really a problem if you don't try to foldl a strict function, is it?
09:26:57 <Cale> petekaz: foldl'
09:27:12 <SamB> wchogg: how do you do a right fold monadically?
09:27:15 <Cale> assuming that the additional strictness doesn't kill you
09:27:25 <dcoutts> wchogg, so that you perform the operations in the right order
09:27:54 <wchogg> Oh sure, the sequencing.
09:27:56 <davidhouse_> SamB, foldM . reverse
09:27:59 <dcoutts> oh, hmm, that's not actually true
09:28:06 <dcoutts> >> is associative
09:28:32 <SamB> I was thinking more about "how do you get the value before you compute it?"
09:28:58 <SamB> you'd either need a time machine or mfix
09:29:43 <Cale> I think I'd probably prefer foldM to be a right fold.
09:30:41 <Cale> hmm
09:30:50 <Cale> oh, perhaps I see
09:33:01 <SamB> amazing! a plugin finding service has actually found a plugin!
09:35:45 <davidhouse> Cale, planning to enlighten us?
09:36:00 <Cale> sorry, got distracted :)
09:36:53 <davidhouse> Cale, #haskell > #math :P
09:37:12 <Cale> I think the issue is that it's using the result of the computations in order to get the input to the rest
09:37:33 <Cale> it's not really combining them with >>
09:37:39 <Cale> it's combining with >>=
09:38:44 <Cale> foldM f a1 [x1, x2, ..., xm] = f a1 x1 >>= \a2 -> f a2 x2 >>= ... >>= \am -> f am xm
09:38:47 <SamB> a right fold would require it to take the value of the rest of the computation to pass to the piece that is supposed to be done before that
09:39:35 <davidhouse> hmm. does writeFile require that the file already exist?
09:40:29 <norpan> davidhouse: i don't think so
09:40:49 <SamB> davidhouse: no!
09:41:10 <SamB> in fact, it is discouraged for the file to exist. by me, at least...
09:46:04 <Cale> foldrM f z [] = return z; foldrM f z (x:xs) = mdo v <- foldrM f z xs; f x v
09:46:43 <Cale> actually, no need for mdo at all
09:47:09 <davidhouse> mdo is do with recursive bindings allowed, right?
09:47:24 <mauke> I think a parser for a data structure I have in mind requires a type of (Node -> Node) -> Parser (Node -> Node)
09:47:30 <Cale> davidhouse: yeah
09:47:32 <mauke> is there anything obviously wrong with that?
09:47:51 <davidhouse> Cale, that's a bad name. it should be rdo or something.
09:47:54 <Cale> mauke: nope
09:48:06 <Cale> davidhouse: it's really Î¼do
09:48:12 <Cale> (that is, mu-do)
09:48:50 <davidhouse> ah. then it should be mudo.
09:48:57 <Cale> yeah
09:49:11 <Cale> or dorec
09:49:41 <ibid> udo :)
09:50:11 <ibid> or just use the arrow variant: do ... rec { ... } ...
09:51:44 <davidhouse> wow. GHC's Data.Tuple allows up to 101-tuples :)
09:51:52 <work_metaperl> zowie
09:51:56 <petekaz> thats it?
09:52:11 <work_metaperl> zowie zowie zowie zowie zowie zowie zowie --- to quite Scary Movie IV
09:52:19 <norpan> 101-tuples ought to be enough for anybody!
09:52:20 <SamB> for autogenerated code, obviously
09:52:27 <Cale> petekaz: seeing as nobody sane uses anything more than triples, it's crazy :)
09:52:29 <SamB> petekaz: if you need more, you send something to libraries
09:52:41 <petekaz> sorry ... my comment was sarcastic.
09:52:51 <davidhouse> and to think NHC only provides up to 15. pfft.
09:52:53 <petekaz> I can imagine pattern matching that bad boy.
09:53:10 <SamB> I don't know *what* uses those huge tuples...
09:53:38 <Cale> hi metaperl -- did you get my response to the howManyEqual question?
09:53:39 <davidhouse> hmm. actually it only provides up to 63, because, and i quote Data.Tuple: {- Manuel says: Including one more declaration gives a segmentation fault.
09:53:52 <SamB> some people might use quadruples or quintuples on rare occasions
09:53:58 <shapr> SamB: HList can easily go over 15.
09:54:10 <shapr> I think I've seen it go over 41 before.
09:54:21 <SamB> shapr: how?
09:54:32 <davidhouse> shapr, that must use TH
09:55:25 <SamB> I thought HList was type-hackery?
09:56:27 <norpan> what should I use instead of List.sort
09:56:48 <ndm> davidhouse: but with NHC you can define more your self :)
09:57:23 <norpan> it uses insertion sort
09:57:40 <SamB> what is wrong with insertion sort?
09:57:44 <Philippa_> SamB: that doesn't stop it using tuples as part of that typing
09:57:59 <norpan> it has complexity O(n^2) right?
09:58:00 <SamB> Philippa_: yes, but how can it build big ones?
09:58:11 <Cale> List.sort is actually pretty well optimised
09:58:18 <Philippa_> 64 items in your type-level list?
09:58:20 <Cale> at least in ghc
09:58:46 <SamB> but... how can you build tuple types one type at a time?
09:59:21 <norpan> Cale: it is?
09:59:44 <norpan> ah, mergesort
10:00:00 <norpan> mergesort seems suited for lazy processing yes
10:00:09 <norpan> i imagine in my little brain
10:00:28 <SamB> I was pretty sure that whatever they used they picked for a good reason ;-)
10:00:45 <norpan> finding the k least elements should be O(k log n)
10:00:46 <davidhouse> i once saw a cool website which had several sets of thin vertical red bars of varying length, then applied a different sort to each set (sort by length). you could see visually how quick each sort was
10:01:00 <norpan> err no
10:01:28 <norpan> anyway
10:01:35 <norpan> i imagine it would work well lazily
10:01:45 <SamB> davidhouse: well, that works for array sorts I guess
10:02:04 <petekaz> http://cg.scs.carleton.ca/~morin/misc/sortalg/
10:02:11 <petekaz> davidhouse: is that the one?
10:02:28 <araujo> Hello!
10:02:50 <davidhouse> petekaz: hold on, let me install JRE
10:05:18 <petekaz> Is there a regexp library for haskell?
10:05:45 <work_metaperl> a library external to haskell for haskell is what attracted me to haskell... is that self-referential sentence?
10:05:55 <work_metaperl> and it was a regexp library... very attractive
10:06:02 <work_metaperl> my first post to comp.lang.functional... let me find it
10:06:39 <davidhouse> petekaz: JRegex is nice. there is one in the standard libs, but it's not PCREs.
10:06:58 <work_metaperl> petekaz: http://repetae.net/john/computer/haskell/hsregex/hsregex-0.2/docs/RRegex.Syntax.html
10:06:59 <norpan> there is Text.Regex
10:07:04 <petekaz> ahh ... ok, I'll search for JRegex, I prefer PCRE.
10:07:20 <work_metaperl> petekaz: also see the one that attracted me to haskell: http://repetae.net/john/computer/haskell/hsregex/hsregex-0.2/docs/RRegex.Syntax.html
10:07:36 <petekaz> work_metaperl: thanks.
10:07:44 <work_metaperl> sure. the thread was here: http://groups.google.com/group/comp.lang.functional/tree/browse_frm/month/2005-02/3b4415c386511815?rnum=161&_done=%2Fgroup%2Fcomp.lang.functional%2Fbrowse_frm%2Fmonth%2F2005-02%3F#doc_3b4415c386511815
10:08:02 <davidhouse> work_metaperl: that seems fairly similar to JRegex
10:08:33 <work_metaperl> davidhouse: I wouldnt know... I'm still working through "Craft" for the 2nd time... Haskell is one language you dont hack with . You either learn the fundamentals or you get ripped to shreds
10:08:56 <SyntaxNinja> dcoutts: aaaurgh too much spam
10:09:09 <dcoutts> SyntaxNinja, mm, quite
10:09:30 <dcoutts> SyntaxNinja, I can't get into the mailing list admin interface, we set the passwd right?
10:09:44 <dcoutts> SyntaxNinja, I have lots to deny and one to allow
10:10:00 <dcoutts> can we do some junk mail filtering before it gets to us?
10:11:01 <SyntaxNinja> dcoutts: I don't think you know the passwords.
10:11:07 <SyntaxNinja> dcoutts: I don't know.
10:11:31 <dcoutts> SyntaxNinja, you wanted me to admin the cabal-devel list
10:11:59 <dcoutts> SyntaxNinja, I get all the emails asking for approval
10:12:11 <dcoutts> SyntaxNinja, you asked me to make up a password to use
10:12:22 <dcoutts> to use here: http://www.haskell.org//mailman/admindb/cabal-devel
10:14:17 <dcoutts> SyntaxNinja, JaffaCake said he's pondering doing a 6.4.3 in early June. We need to decide if we want an updated cabal in that ghc release.
10:14:25 <dcoutts> eg with the recently updated API
10:16:01 <musasabi> An API that would stay the same with 6.6 would be nice.
10:17:15 <SyntaxNinja> dcoutts: right. I thought I asked you for a passwd and didn't get a reply.
10:17:22 <SyntaxNinja> (sorry, i was afk)
10:17:39 <dcoutts> SyntaxNinja, I thought I did reply :-) nm let me /msg you ..
10:17:45 <pitecus> Hi. Is it possible to compile a program with GHC so this program runs with a non-default RTS option?
10:18:25 <dcoutts> pitecus, yes, but not especially easily
10:18:30 <dcoutts> it's mentioned in the user guide
10:21:24 <SyntaxNinja> dcoutts: it would probably be good to get the "final" hooks interface into 6.4.3.
10:22:05 <dcoutts> SyntaxNinja, sounds good.
10:23:28 <SyntaxNinja> plus if we make a big deal about this version of cabal, maybe we can get more ppl to submit patches for stuff that's been bugging them ;)
10:23:48 <pitecus> dcoutts, whereabouts? I can't find it.
10:25:29 <shapr> SyntaxNinja: hiya!
10:25:30 <eivuokko> pitecus, http://haskell.org/ghc/docs/latest/html/users_guide/runtime-control.html#rts-hooks
10:25:33 <SyntaxNinja> hey shapr
10:25:54 <dcoutts> pitecus, http://www.haskell.org/ghc/docs/latest/html/users_guide/runtime-control.html#rts-hooks
10:27:28 <pitecus> thanks, dcoutts, eivuokko 
10:28:10 <SyntaxNinja> xerox: what's up w/ SoC. what are next steps?
10:31:20 <SyntaxNinja> hey, are other SoC mentors getting soc-mentors@syntaxpolice.org emails?
10:32:47 * dcoutts thinks he must not be
10:33:57 <xerox> Howdy.
10:34:02 <dcoutts> @yarr!
10:34:03 <lambdabot> Yeh scurvy dog...
10:34:07 <xerox> Just came back home -- oooof.
10:34:08 <bolrod> Aye!
10:34:53 <dcoutts> xerox, so, 114 applications
10:34:54 <xerox> SyntaxNinja: mentors got to rank before the 22nd
10:35:01 <xerox> Ah, did we reach thousands yet? :-D
10:36:03 <bolrod> 114 is nice :)
10:36:15 <bolrod> imagine every project has that or more :)
10:36:22 <xerox> And also applications sshould be assigned to mentors
10:36:33 <SyntaxNinja> xerox: OK
10:36:35 <xerox> But I think it is given by the ranking process
10:36:37 <bolrod> so... some projects probably get way more..
10:36:41 <bolrod> 150.000 applications? :)
10:37:24 <xerox> In the meanwhile mentors could contact applicants to discuss or just ask for more informations
10:38:04 <xerox> There will be a "Summer-Discuss Google Group" for discussions between administrators, mentors, applicants, and Google.
10:38:15 <ADEpt> SyntaxNinja: after initial invitational email, no more mails for me
10:38:28 <xerox> On the 23rd Google will publish the list
10:38:30 <musasabi> SyntaxNinja: if you can point to subjects of the relevant messages? I saw the initial "Welcome to the Haskell Mentors list", but nothing after that.
10:39:10 <xerox> Then work work work work until June 26.  At that time mentors will be asked to do a mid-program evaluation of the student progress.
10:39:11 <SyntaxNinja> musasabi: ADEpt: that's it.
10:39:22 <xerox> Etc, etc, etc.
10:40:11 <shapr> SyntaxNinja: I'm not getting soc-mentors@syntaxpolice.org emails.
10:40:19 <shapr> How do I susbscribe?
10:40:35 <SyntaxNinja> shapr: it's going to your gmail, do you want me to change addresses?
10:41:09 <SyntaxNinja> mentors: I used the addresses you gave google!
10:41:32 <xerox> Obviously mentors have set their clients to highlight on the keyword "mentors" :-D
10:41:49 <SyntaxNinja> holy crap there are a lot of applications
10:41:58 <nibro> indeed there are...
10:42:45 <nibro> 114 to be precise
10:43:37 <xerox> xerox: ,t8 ja en çŒ«
10:43:37 <xerox> fsbot: Cat
10:43:37 <xerox> ^- dcoutts I want that, it's GNOME libtranslate :-)
10:43:38 <palomer> the mcgill christian club is othercotting the da vinci code
10:44:25 <greenrd> othercotting?
10:45:19 <palomer> going to see other films on the opening night
10:45:51 <greenrd> that's just boycotting
10:46:15 <davidhouse> well, boycotting would perhaps be staying at home.
10:46:36 <davidhouse> i think the da vinci code is a good thing, from a christian's point of view. it emphasises that the story is fiction.
10:46:44 <greenrd> no, boycotting is when you don't buy a particular brand or product
10:47:00 <greenrd> just because you boycott a brand of shampoo, doesn't mean you can't wash your hair
10:47:31 <palomer> maybe othercotting subsumes boycotting
10:47:38 <palomer> ever thought of that, big boy?
10:47:51 <nibro> SyntaxNinja, xerox: do we know how many applications of ours that google will accept?
10:48:23 <xerox> I don't think so
10:48:49 <palomer> go #78!
10:49:09 <dcoutts> SyntaxNinja, so I am signed up? I've not seen any emails. I do get the google ones which is of course on the same email address?
10:49:10 <nibro> earlier the cutoff line was shown at 8 applications, now it's 40 (!)
10:49:45 <dcoutts> when will we know how many applications we can accept?
10:50:50 <sieni> how do you decide which ones to accept?
10:50:50 <xerox> dcoutts: the FreeBSD admins told me that last year mentor ranked, and then Google took all those greater than a certain 'n' value.
10:51:14 <dcoutts> xerox, hmm, but we can set arbitrarily hign 'n' values
10:51:36 <nibro> xerox: so if we just pump all applications arbitrarily high, we get all our applications in?
10:51:58 <dcoutts> the google chap says:
10:52:00 <dcoutts> We will automatically select the top N projects.   If there's a project
10:52:00 <dcoutts> that you'd like to see mentored that doesn't fall into your top N
10:52:00 <dcoutts> projects, you can score it higher and decrement the score of another
10:52:00 <dcoutts> application.
10:52:11 <dcoutts> but I assume that's per-priject
10:52:23 <dcoutts> err per-organisation
10:52:30 <dcoutts> not across all organisations
10:52:35 <SyntaxNinja> nibro: we don't know how many they'll accept.
10:53:32 <petekaz> So do any of these regexp libraries work with fps bytes?
10:54:04 <nibro> hmm, so I guess we should really just decide among ourselves the order of applications, and never mind what the actual numbers are then
10:54:43 <dcoutts> and then fix the numbers to reflect that ordering
10:55:01 <nibro> exactly
10:55:02 <dcoutts> mind you it might be a good thing to start by just going though each application and give it our score
10:55:09 <SyntaxNinja> right
10:55:19 <dcoutts> for which most would be 0 "feh, I don't care"
10:55:30 <nibro> yep
10:55:59 <dcoutts> sorry, wrong attitude. "nice, but not top 20%"
10:55:59 <nibro> that should at least bring the interesting ones towards the top, for an easier second pass
10:56:04 <dcoutts> right
10:56:23 <dcoutts> some people have marked several ones as "I'd mentor this"
10:56:42 <dcoutts> is that because they're prepared to mentor several
10:56:53 <dcoutts> or they would be prepared to mentor any of them?
10:56:57 <dcoutts> ie any vs all?
10:57:11 <Philippa_> unless told otherwise I'd assume any
10:57:13 <SyntaxNinja> "any" I think.
10:57:20 <dcoutts> right, ok
10:57:34 <Lemmih> I assumed all.
10:57:42 <SyntaxNinja> not sure.
10:57:45 <dcoutts> so I can say mark 5 of them as "I'd do it" but then only take one or 2 in the end?
10:57:49 <SyntaxNinja> I think you can only mentor one thing, but I'm not positive.
10:57:57 <SyntaxNinja> dcoutts: that's what I think, maybe xerox can find out?
10:58:02 <dcoutts> no, the nmap guy mentored 20 last year I think
10:58:15 <dcoutts> I don't think it's got to be 1:1
10:58:22 <SyntaxNinja> OK I just emailed the group again
10:58:23 <dcoutts> just what you think you've got time for
10:59:20 <SyntaxNinja> right.
10:59:38 <SyntaxNinja> thing is, if there are 20 really easy projects that anyone can mentor, then lots of folks might vote for that because they'd be willing to mentor it ;)
10:59:46 * audreyt is glad to see Haskell becoming a 3-hours tutorial in this year's OSCON
10:59:53 <audreyt> # http://conferences.oreillynet.com/cs/os2006/view/e_sess/8898
11:00:05 <audreyt> "doomed to succeed"
11:00:16 <nibro> I would mentor both of the projects I said I could, no problem
11:00:25 <nibro> so in my case it's "all" :-)
11:01:18 <nibro> SyntaxNinja: I'm sure we'd discover those projects manually in pass 2 though
11:01:24 <dcoutts> SyntaxNinja, true, but I think we just need a first pass
11:01:33 <dcoutts> we can then really rank the top 20 at the end
11:02:06 <dcoutts> are applications closed now?
11:02:35 <Philippa_> audreyt: heh, cool
11:03:01 <SyntaxNinja> audreyt: cool!
11:03:51 <nibro> "Monads, and how to use them "
11:04:14 <nibro> as one point out of many in a talk 3.5 hours long
11:04:22 <nibro> wonder how many will get it...
11:04:34 <davidhouse> i think the point is to give a taster, more than anything.
11:05:09 <nibro> yeah, I think it's a great idea, never a complaint :-)
11:05:17 <nibro> but I still wonder... ;-)
11:05:38 <SamB> dcoutts: should be!
11:05:47 <dcoutts> right, good
11:05:58 <shapr> SyntaxNinja: I got mail!
11:06:02 <SamB> however, the site does not indicate this very well...
11:06:18 <dcoutts> SamB, ok, so it's not that I just can't read :-)
11:07:12 <nibro> is it ok for us (wrt google) to accept projects that don't span the whole summer?
11:07:40 <SamB> I mean, for some reason I am still seeing a link to submit applications...
11:14:02 <davidhouse> heh. http://cg.scs.carleton.ca/~morin/misc/sortalg/ has a "PermSort" algorithm which is O(n!n) :)
11:15:39 <musasabi> SyntaxNinja: got the test mail.
11:19:23 <SyntaxNinja> musasabi: thanks.
11:21:06 <SamB> davidhouse: wow that is *BAD*
11:23:00 <davidhouse> SamB: it generates all possible permutations of the list, and checks all of them to see which one is sorted :)
11:23:09 <davidhouse> it's a joke, but still.
11:23:26 <SamB> hahahah
11:25:03 <xerox> dcoutts: what was the question?
11:25:32 <dcoutts> xerox, I forget
11:26:20 <SamB> something about whether SoC applications are still being accepted?
11:26:38 <dcoutts> xerox, we were wondering about how many projects we're likely to get and yeah, if applications are now closed.
11:28:00 <xerox> Yes, applications are closed.  I don't reallyt know a number to tell you, tho.
11:29:26 <SamB> they ought to take out the link to submit more!
11:30:20 <MarcWeber> Is something like this possible/desirable? http://rafb.net/paste/results/sFWImv12.html from 1 to 1'?
11:32:09 <davidhouse> MarcWeber, sure
11:32:27 <davidhouse> data MappingObj=forall f. (Typeable f, Mapping f) => MappingObj { unObj :: f }
11:32:34 * int-e wonders if newtype and newtype deriving would do the job.
11:32:49 <davidhouse> create/pattern match your values in exactly the same way as before, but you get the unObj accessor for free.
11:32:57 <davidhouse> int-e, i did wonder that.
11:41:49 <int-e> urg. ok, what's the type unObj is supposed to have?
11:46:09 <ruffneck> doesn't it say in it's declaration or something?
11:46:46 <davidhouse> int-e, (Typeable f, Mapping f) => MappingObj f -> f, surely?
11:47:08 <int-e> unObj :: MappingObj -> (exists f . (Typeable f, Mapping f) => f) ? but existential quantifications in types aren't supported, are they?
11:47:32 <int-e> davidhouse: MappingObj has no type parameter ...
11:47:43 <MarcWeber> davidhouse: he, wow it works..
11:48:02 <davidhouse> int-e, oh, true. eww.
11:48:29 <MarcWeber> int-e: Let me try
11:48:41 <davidhouse> MarcWeber, really? load it up in ghci -fglasgow-exts and do a :t unObj
11:51:45 <MarcWeber> Oh it says : Can't find interface-file declaration for TableObj ...
11:52:21 <MarcWeber> And my program compiles but says <<loop>> ;) But i don't think it's due to unObj? I'll see
11:55:21 <MarcWeber> How can I import Prelude.show ?
11:55:32 <int-e> import Prelude (show)
11:55:44 <MarcWeber> ah sure.
11:56:26 <mgoetze> i thought not importing it is harder than importing it....
11:56:44 <MarcWeber> Why doesn't ghc want to have a qualified name in the line show=show?
11:56:54 <MarcWeber> ;)
11:57:08 <int-e> because you might have done that intentionally?
11:58:29 <ndm> what name would you give a library for solving predicates?
11:58:33 <ndm> Data.Predicate ?
11:58:39 <ndm> or is there something better it could be called
11:58:53 <ndm> (well, more playing with, rather than just solving)
11:59:38 <MarcWeber> int-e: http://rafb.net/paste/results/JKMbjI93.html
12:00:04 <int-e> cute :)
12:00:31 <MarcWeber> Thats my <<loop>> failure ..
12:01:04 <MarcWeber> davidhouse ?
12:01:37 <MarcWeber> int-e: How would I have to rewrite my data line to use newtype and deriving?
12:01:38 <Cale> MarcWeber: it's not though.
12:01:59 <Cale> MarcWeber: the second show is the same one as the first since they're being applied to a value of the same type
12:02:02 <davidhouse> MarcWeber, :) you can't do that.
12:02:19 <Cale> maybe you want show = show . unObj
12:02:37 <davidhouse> when you do show 5, that works because somewhere someone's written instance Show Int where show = (some function for showing integers)
12:02:39 <int-e> MarcWeber: newtype TableObj = forall f. (Typeable f, Table f, Show f) => TableObj { unObj::f } deriving (Show, Table, Typeable). But I think it won't work.
12:02:44 <davidhouse> you have to write a showing method.
12:03:12 <int-e> actually ghc 6.4.1 doesn't like your code (or are there options besides -fglasgow-exts that I should add?)
12:03:12 <Cale> what is going on here anyway?
12:04:00 <MarcWeber> Cale : My first question:  quote  "Is something like this possible/desirable? http://rafb.net/paste/results/sFWImv12.html from 1 to 1'?"
12:05:16 <Cale> MarcWeber: it's certainly possible to switch from using pattern matching to applying a projection function
12:06:05 <Cale> er
12:06:18 <int-e> ...    Can't combine named fields with locally-quantified type variables or context
12:06:19 <Cale> hmm, is that an existential though?
12:06:22 <int-e> yes.
12:06:30 <Cale> then what's the type of unObj?
12:06:55 <MarcWeber> ghci can't show it ;))
12:07:59 <Cale> worse than that
12:08:04 <Cale> there is no such type
12:08:11 <int-e> MarcWeber: which ghc version are you using?
12:08:17 <Cale> (at least, in Haskell)
12:08:22 <MarcWeber> 6.5
12:08:31 <MarcWeber> It's of type <interactive>:1:0:
12:08:31 <MarcWeber>     Can't find interface-file declaration for TableObj
12:08:31 <MarcWeber>       Probable cause: bug in .hi-boot file, or inconsistent .hi file
12:08:46 <Cale> that's got to be a bug :)
12:08:51 <davidhouse> ah, so this is what is meant by "existential types"?
12:09:05 <MarcWeber> 6.5.20060117 yeah ;))))
12:09:20 <MarcWeber> Cale: ghc dev or cvs mailinglist?
12:09:41 <Cale> MarcWeber: I'm not sure where you should report it -- probably ghc dev
12:10:07 <Cale> It should outright reject that definition
12:10:14 <Cale> unObj (MappingObj obj) = obj
12:10:20 <Igloo> Assuming the .hi file was generated by the same GHC version you are using
12:10:32 <MarcWeber> Igloo: It was.
12:10:58 <MarcWeber> I've done a rm all .hi and .o files 3min ago.
12:11:02 <Cale> also, it's a good habit to put spaces around your composition operators :)
12:11:50 <MarcWeber> Cale: So I stick to my 1) ?
12:12:25 <Cale> yes, in this case you have to
12:13:30 <Cale> I think 6.5 has support for record labels in existential types, but I'm fairly sure they're not first class functions, and can only be used in certain contexts.
12:14:49 <MarcWeber> I'll post the bug to glasgow-haskell-bugs and ask for implementing deriving (Mapping) ;)
12:14:50 <Cale> http://www.haskell.org/hawiki/Existentially_20quantified_20record_20constructors
12:33:02 <osqulda> what is the difference between System F and Haskell?
12:33:10 <osqulda> e.g. rank-n types, higher-order features etc?
12:33:23 <osqulda> (forget all other things like data definitios)
12:33:51 <osqulda> and fixpoints
12:34:45 <kombinator> System-F is a 'mathematical' type system, it doesn't have named types
12:37:30 <kombinator> ok, you've mentioned it;)
12:38:53 <jlhamilton> is liftM just a special version of fmap for monads?
12:39:10 <isaacd> @type liftM
12:39:11 <lambdabot> forall r (m :: * -> *) a1.
12:39:11 <lambdabot>    (Monad m) =>
12:39:11 <lambdabot>    (a1 -> r) -> m a1 -> m r
12:39:14 <isaacd> @type fmap
12:39:15 <lambdabot> forall (f :: * -> *) b a.
12:39:15 <lambdabot>    (Functor f) =>
12:39:15 <lambdabot>    (a -> b) -> f a -> f b
12:39:41 <isaacd> looks like it
12:40:12 <osqulda> what is nominal type system?
12:40:37 <davidhouse> osqulda: i believe Haskell uses a restricted version of system F.
12:41:04 <glauber_sp> hi guys =)
12:41:07 <osqulda> List = List' <=== data List a = Nil |Â Cons  (List a) a  an data List' a = Null | Cuns (List' a) a
12:41:17 <osqulda> davidhouse, restricted but inconsistent
12:41:56 <osqulda> but HOW is it restricted, e.g. how far does the higher-order features go and how much nesting of type abstractions are allowed today?
12:42:33 <davidhouse> osqulda: http://en.wikipedia.org/wiki/System_F says haskell uses HM, http://en.wikipedia.org/wiki/Hindley-Milner
12:42:49 <osqulda> higher-order HM with lot's of extras
12:42:53 <osqulda> ?
12:43:01 <kombinator> osqulda: inconsistent meaning you can type forall a. a?
12:43:13 <osqulda> undefined
12:43:52 <kombinator> osqulda: right, this is caused by general recursion
12:44:03 <musasabi> Different Haskell implementations have different kinds of type systems under the hood.
12:44:16 <osqulda> no, by partial recursion
12:46:04 <Philippa_> System F does impredicative rank-n type - that is, you can quantify over types with foralls in 'em too
12:46:48 <Philippa_> it's essentially the simply-typed lambda calculus plus type lambdas, type applications and foralls in types (being the type corresponding to a type lambda)
12:47:28 <glauber_sp> guys, I need to write about lambda calculus. Should I use matematical definitions as Barendregth or is there other papers that explain the concepts without a lots of mathematical definitions? I want to implement my work in Haskell; I need an reference that links \-calculus with haskell (curry or church style, I guess) I'm starting reading about it yet
12:49:18 <osqulda> check Hankin's book, glauber_sp
12:49:22 <osqulda> or Ong's notes
12:49:32 <osqulda> what is rank-n for fix n?
12:49:49 <Philippa_> glauber_sp: data Term = Var Variable | App Term Term | Lam Variable Term, go from there
12:50:03 <Philippa_> basically, use haskell as metalanguage only
12:50:21 <glauber_sp> osqulda, are there eletronical verions of these texts? or only printed ones?
12:50:29 <osqulda> electronic for the second ref.
12:50:49 <glauber_sp> osqulda, thanks, I'll take a look
12:51:07 <osqulda> where are rank-n defined, Philippa_
12:52:20 <glauber_sp> osqulda, Ong's note, can you tell me the full name or other name to search for? the book I found as reference in a presentation I got here.
12:53:00 <osqulda> Luke Ong Oxford
12:53:05 <glauber_sp> osqulda, thanks =0
12:53:14 <osqulda> TAPLAS is good 
12:53:14 <osqulda> good night
13:04:52 <BCoppens> Itkovian: tomorrow it starts at 10.00, not 11.30, right (NPP)
13:13:26 <zarvok> @type reverse []
13:13:27 <lambdabot> forall a. [a]
13:14:34 <zarvok> @listcommands
13:14:34 <lambdabot> Unknown command, try @list
13:14:42 <zarvok> @list
13:14:43 <lambdabot> list [module|command]. Where modules is one of:
13:14:43 <lambdabot> babel base compose dice dict djinn drHylo dummy elite fact haddock help hoogle karma lambda localtime log more pl plugs poll pretty quote search seen slap spell state system todo topic type unlambda
13:14:43 <lambdabot> version vixen where
13:15:03 <zarvok> @list hoogle
13:15:03 <lambdabot> hoogle provides: hoogle hoogle+
13:15:17 <zarvok> @help hoogle
13:15:17 <lambdabot> hoogle <expr>. Haskell API Search for either names, or types.
13:15:56 <davidhouse> @hoogle map
13:15:56 <lambdabot> Prelude.map :: (a -> b) -> [a] -> [b]
13:15:57 <lambdabot> Data.IntMap.map :: (a -> b) -> IntMap a -> IntMap b
13:15:57 <lambdabot> Data.IntSet.map :: (Int -> Int) -> IntSet -> IntSet
13:16:10 <zarvok> lambdabot is hot
13:16:14 <zarvok> is my conclusion
13:16:25 <davidhouse> damn straight.
13:16:36 <davidhouse> zarvok: and you can download it! and run it locally!
13:16:49 <zarvok> heh, already darcs'd the source
13:18:20 <zarvok> hmm, nice, responds to private messages too, so I don't have to bother the whole channel with my messing around :)
13:19:37 <roconnor> Anyone want to help me translate 8 lines of SML/NJ to Haskell?
13:19:46 <norpan> shoot
13:19:48 <zarvok> sure
13:19:55 <roconnor> @lisp-past
13:19:56 <lambdabot> Unknown command, try @list
13:19:59 <roconnor> er
13:20:01 <roconnor> @lisp-paste
13:20:02 <lambdabot> Unknown command, try @list
13:20:09 <sieni> @paste
13:20:09 <lambdabot> http://www.haskell.org/hawiki/HaskellIrcPastePage
13:20:15 <sieni> hmm...
13:20:44 <roconnor> isn't there a better paste place?
13:21:22 <sieni> paste.lisp.org does not seem to support standard ml
13:21:48 <lisppaste2> roconnor pasted "SML/NJ continuation code" at http://paste.lisp.org/display/19836
13:22:13 <roconnor> I have just started looking at it.  I'm not so familiar with continuations
13:22:27 * zarvok fears callcc
13:23:09 <roconnor> @hoggle throw
13:23:10 <lambdabot> Control.Exception.throw :: Exception -> a
13:23:10 <lambdabot> Control.Concurrent.throwTo :: ThreadId -> Exception -> IO ()
13:23:10 <lambdabot> Control.Exception.throwDyn :: Typeable exception => exception -> b
13:26:06 <palomer> http://www.magnesium.net/~palomer/graphical/ <--nice little application, if anyone is interested
13:26:42 <zarvok> I don't know the coninuations monad, so I can't really help, I'm afraid
13:26:47 <zarvok> continuations, even
13:27:22 <roconnor> zarvok: yea me too.
13:27:24 <roconnor> ;)
13:27:46 <zarvok> heh, I was made to learn callcc in SML, but only code haskell for fun and never have use of them
13:28:14 <zarvok> write a lot of CPS, but first class continuations are no fun
13:29:28 <sieni> have fun translating that to haskell
13:29:49 <zarvok> I assume you want a haskell implementation that uses continuations?  It's easy enough to write a similar function without them
13:31:04 <work_metaperl> runCont runs a CPS computation: http://www.google.com/search?client=opera&rls=en&q=CPS+monad+haskell&sourceid=opera&ie=utf-8&oe=utf-8
13:32:02 <roconnor> zarvok: Well, this function ought to be undefineable in the pure lambda calculus
13:32:22 * zarvok has another look
13:32:24 <roconnor> which is why I'm interested in this.
13:33:43 <zarvok> yeah, I think I see that
13:33:51 <zarvok> looks like you'll have to learn the continuations monad
13:33:58 <zarvok> have fun :)
13:34:02 <shapr> hi zarvok 
13:34:08 <zarvok> hi shapr
13:34:16 <shapr> Wow, 224 clients.
13:34:17 <roconnor> what I don't get is that the continuations monad seems to implemented in the pure lambda calculus
13:34:20 <roconnor> so I am confused.
13:34:48 <zarvok> thanks for the heads up earlier, although I guess the other app I submitted was for one that looked popular as well, so we'll see how it goes 
13:35:09 <Philippa_> roconnor: it is, but programs in it aren't pure lambda calculus
13:35:21 <Philippa_> it's an intermediary to writing an interpreter for, say, \calc+callcc
13:35:29 <shapr> Sure, I didn't want you to build up your hopes and then have that sudden letdown :-)
13:36:21 <roconnor> http://www.haskell.org/hawiki/MonadCont gives an implementaiton
13:37:43 <shapr> Hm, that was 225 clients on #haskell with est, our new high water mark!
13:37:57 <norpan> i had better quit then
13:38:08 <Philippa_> roconnor: note the boxing and the existance of >>=. It's not a \calc implementation of classical call/CC
13:38:09 <stepcut> heh
13:38:16 <shapr> Hey stepcut, when did you get a 770?
13:38:45 <stepcut> last sunday (april 30)
13:38:52 <shapr> How do you like it so far?
13:39:01 <shapr> My gf is using mine to draw a ninja at this very instant.
13:39:18 <stepcut> shapr: having trouble with the bluetooth keyboard + the 770, but otherwise, it does what we need it to (aka, run emacs)
13:39:36 <shapr> You run emacs on the 770?? Do you have a deb for that?
13:40:09 <roconnor> Philippa_: boxing?  >>= seems to be defined in pure lambda calculus
13:40:19 <Philippa_> yes, but it's not defined /on/ pure lambda calculus
13:40:33 <Philippa_> boxing as in the Cont type
13:40:49 <Philippa_> classical call/CC doesn't need an equivalent of >>=
13:40:55 <Philippa_> or return, for that matter
13:41:16 <Philippa_> you're adding just enough framework to see enough of the 'interpreter' to be able to hack it and bolt call/CC on, essentially
13:41:43 <roconnor> but this is still all pure lambda calculus hidden by syntactic sugar?
13:41:46 <Philippa_> but the code you write using the Cont monad isn't the same you'd write in a \calc-with-call/CC
13:42:00 <Philippa_> the monad implementation is, yes
13:43:09 <Philippa_> in practice though, when you write something of type Cont Int it's not "an integer" any more
13:43:21 <roconnor> So are you saying I can't translate the SML/NJ code to Haskell?
13:43:23 <Philippa_> whereas in a lambda calculus directly extended with call/CC it would be
13:44:01 <Philippa_> no, I'm not. I've not looked at the SML/NJ code. I'm just telling you the theoretical "but you can't implement call/CC in \calc!" issue still holds - it's just being circumvented. Oh, and you might need ContT IO instead
13:45:57 <sieni> http://research.microsoft.com/~simonpj/papers/control/control.pdf
13:48:03 <roconnor> But what specific part of the implementation of Cont isn't definable in the pure lambda calculus? (still confused)
13:54:16 <Philippa_> roconnor: none of it is. But the resulting thing isn't call/CC
13:54:26 <Philippa_> (or rather, none of it isn't: it's all definable)
13:54:43 <Philippa_> classically, call/CC works on /everything/, not just stuff in a monad
13:55:01 <Philippa_> (it's much like "pure lambda calculus doesn't have state")
13:55:36 <falconair> i'm trying to learn haskell and would like to experiment with evaluating a small expression language (basic math, logical operators, variables, perhaps the ability to define functions) ... other than "Scheme in 48 Hours," is there a tutorial on the web, or even haskell code I can study?
13:56:14 <roconnor> Doesn't runCont get you out of the monad?
13:57:40 <roconnor> @type callCC
13:57:41 <lambdabot> Not in scope: `callCC'
13:57:46 <roconnor> @type Control.Monad.Cont.callCC
13:57:47 <lambdabot> forall (m :: * -> *) a b.
13:57:48 <lambdabot>           (Control.Monad.Cont.MonadCont m) =>
13:57:48 <lambdabot>           ((a -> m b) -> m a) -> m a
14:00:20 <Philippa_> roconnor: yes. It's not IO, you can write an interpreter for \calc-with-call/CC in \calc, too
14:01:19 <Philippa_> but you have to do that, you can't implement call/CC on any-and-all \calc code without an equivalent of return being involved too
14:01:32 <roconnor> ah, but this particular function ought to be impossible to write in \calc. 
14:01:59 <Philippa_> no. The version that operates on ordinary \calc should
14:02:12 <Philippa_> the any-and-all-\calc-code version's impossible to write, that function isn't
14:02:15 <roconnor> that is why I am confused.
14:02:22 <Philippa_> see "boxing"
14:02:42 <Philippa_> you've already got a function :: a -> ma
14:02:48 <Philippa_> a -> m a, even
14:04:52 <roconnor> I'm starting to think laziness will change the semantics from the SML/NJ function.
14:05:20 <Philippa_> possibly, yes
14:05:26 <Cale> falconair: hmm, I'm sure I've seen other tutorials with things like that in them
14:05:44 <falconair> Cale: do you happen to recall any? :)
14:06:05 <roconnor> The SML code does some computation with a throw in it that it then ignores.
14:06:19 <roconnor> so the call to throw won't be forced.
14:07:26 <falconair> i thought about trying some exercises from Pierce's book "Types and Programming Languages," his code is in ML, but it will help me immensely in learning both haskell and the concepts underlying it.
14:08:07 <Philippa_> falconair: good idea. audreyt did that and ended up with pugs
14:09:09 <falconair> yeah, i'm no wizard like audreyt, but i think it should be an instructive approach
14:09:17 <Cale> hmm, I can't seem to find one in the usual places, but I could probably at least dig up the monadic interpreters paper
14:09:58 <falconair> Cale: you mean the one by Wadler, in which he introduces Monads?
14:10:14 <Cale> ah, have you read that?
14:10:39 <falconair> I have skimmed it, I should go through that
14:11:02 <roconnor> Okay, I've got something that typechecks.
14:11:13 <Philippa_> always a good start :-)
14:11:31 <Cale> and if you know how datatypes work, it should be easy to get a good abstract syntax going
14:11:32 <zarvok> falconair:  TaPL is a great text
14:11:44 <lisppaste2> roconnor annotated #19836 with "This typechecks." at http://paste.lisp.org/display/19836#1
14:12:18 <Philippa_> TaPL is indeed cool, as is ATTaPL
14:12:40 <falconair> zarvok: i bought it when i first started learning functional programming...its not quite for that purpose, but now I appreciate it a great deal more
14:13:05 <falconair> ATTaPL has lots of cool stuff in it, unfortunately I can't understand anything besides chapter titles
14:13:12 <Philippa_> finish TaPL then :-)
14:13:22 <zarvok> If you're interested in an even more theoretical approach, check out the texts available on Bob Harper's page:
14:13:24 <Cale> Yeah, "The Essence of Functional Programming" -- the coding style is a little primitive (no monad typeclass, no do-notation) but it's fairly illustrative
14:13:27 <zarvok> http://www.cs.cmu.edu/~rwh/
14:13:30 <Philippa_> some chapters're harder work than others, admittedly
14:13:34 <Cale> http://homepages.inf.ed.ac.uk/wadler/papers/essence/essence.ps.gz
14:13:40 <Philippa_> I'm more interested in a wider range of stuff than a more theoretical approach per se
14:13:42 <roconnor> OMG it seems to work!
14:13:45 <zarvok> In particular "Programming Languages: Theory and Practice"
14:13:52 <roconnor> I'm am totally confused.
14:13:56 <Philippa_> I'm playing with Pure Type Systems because they look useful
14:14:13 <Philippa_> (and I suspect I can use them to prove a pile of intuitions I have)
14:14:28 <roconnor> Ahhhhh, this is impossible.
14:14:29 <zarvok> Harper's text have a firm anti-call-by-name bias though, so watch out
14:15:21 <roconnor> Unless, Control.Monad.Cont.Cont is implemented is some special way
14:15:34 <Cale> roconnor: hm?
14:15:44 <Cale> roconnor: what's going on?
14:16:12 <roconnor> Cale: http://paste.lisp.org/display/19836#1
14:16:43 <roconnor> m is a fucntion that takes a functional f, and a function x, and returns the largest value that f calls on x.
14:17:08 <roconnor> but m isn't extensional.
14:17:16 <roconnor> so m is impossible to write in the pure lambda calculus.
14:17:32 <roconnor> but Control.Monad.Cont.Cont is just a regular data type.
14:17:39 <falconair> zarvok: is "The Essence of Functional Programming" by Wadler?  I couldn't find it on harper's page, the ps link won't work, and google shows Wadler as the author?
14:17:49 <roconnor> so this program is writen in the pure part of Haskell.
14:17:57 <roconnor> so writing m is impossible.
14:18:01 <roconnor> but I just wrote it.
14:18:11 <Cale> roconnor: what's the type of m
14:18:23 <roconnor> m :: (Num a, Ord a) =>
14:18:24 <roconnor>      ((a -> Cont a b) -> Cont a t) -> (a -> b) -> a
14:18:30 <Cale> see?
14:18:34 <roconnor> oh
14:18:40 <Cale> f isn't an ordinary function at all
14:18:49 <zarvok> yes, that's wadler's, I think the ordering of the discussion was a little confused earlier, I was recommending harper's work unrelatedly
14:19:09 <jlhamilton> http://homepages.inf.ed.ac.uk/wadler/topics/monads.html
14:19:16 <roconnor> Cale, gimme a moment for that to sink in.
14:19:52 <falconair> i see the paper, i'll go through that as well, thanks
14:19:58 <Philippa_> whenever you use typeclasses and you're theorising about lambda calculus, apply the dictionary transformation by hand
14:20:01 <Cale> newtype Cont r a = Cont { runCont :: (a -> r) -> r }
14:20:04 <Philippa_> otherwise you'll confuse the hell out of yourself
14:20:20 <roconnor> dictionary transformation?
14:20:55 <roconnor> I can't belive I got it to type check without knowing the type of m.
14:20:56 <Philippa_> translate out the predicates by passing in dictionaries (records containing the methods for the appropriate types)
14:21:03 <Cale> roconnor: typeclasses are implemented by passing dictionaries of functions as extra parameters to the functions that need them
14:21:22 <Philippa_> Cale: "usually" implemented, I think you'll find :-)
14:21:27 <Cale> Philippa_: did you hear my newer idea about how to solve the Ord Monad problem?
14:21:31 <Philippa_> no?
14:22:20 <Cale> What do you think of having class contexts in data declarations actually mean that a dictionary pointer is stored in the values of the type
14:23:24 <Cale> Then for any function which takes a value with one of these dictionaries as a parameter, the class context is optional.
14:23:52 <Philippa_> sounds broken
14:24:01 <Philippa_> or rather, it leaves the type of return broken still
14:24:23 <roconnor> Yeah, but there are not typeclasses (that matter) in my case because I am specifically using Cont.  (maybe Philippa_'s comment wasn't for me)
14:24:47 <Cale> ah, right :/
14:24:54 <Cale> annoying :)
14:25:10 <Cale> you'd get Functor at least.
14:26:16 <roconnor> Cale, thanks for fixing the universe for me.
14:26:37 <Cale> I'm beginning to think that we have to get over this parameter passing implementation of typeclasses if this is to be solved.
14:27:50 <Philippa_> I don't think we do at all
14:28:03 <Philippa_> it seems to be you just need a second parm on Monad
14:28:10 <Philippa_> it seems to me, even
14:28:20 <Philippa_> namely the "source" category
14:29:41 <Cale> yeah, but we don't have a way to really talk about subcategories at all.
14:30:43 <Philippa_> seems to me that typeclasses and/or individual types're a way to start?
14:31:05 <Philippa_> oh, ick. No way to say "those /and/ functions on them"
14:31:28 <Philippa_> well, not currently. Could probably be written as a closed class, come to think of it
14:32:21 <Cale> there's the trick which adds two type parameters to the Monad class, but that's really ugly
14:32:34 <Philippa_> how does that go?
14:32:42 <Cale> class Monad m a b where
14:32:47 <Cale>   return :: a -> m a
14:33:03 <Cale>   (>>=) :: m a -> (a -> m b) -> m b
14:33:19 <Cale> instance (Ord a, Ord b) => Monad Set a b where
14:33:28 <Cale>   return = singleton
14:33:30 <Cale>    ...
14:33:59 <Cale> there's something conceptually broken about that :)
14:34:22 <Philippa_> I agree
14:34:39 <Cale> however, translating into that form wouldn't be so bad
14:34:49 <Philippa_> of course, being uber-correct, a would have to include m a anyway
14:35:05 <Cale> hm?
14:35:12 <Philippa_> but that's not generally a property of monads we're actually interested in
14:35:44 <Cale> Well, we do actually have Ord a => Ord (Set a)
14:35:46 <Philippa_> maybe I've misunderstood, but part of the point is that whatever we build, we can view it in the 'source' category
14:35:54 <Philippa_> in that example, yeah
14:36:17 <Cale> oh, well, yes
14:36:19 <Philippa_> do we need it "for what we're doing" in all other cases?
14:36:37 <Cale> we do need it if join is to be possible
14:37:11 <Cale> so yeah, you're riht
14:37:13 <Philippa_> hmm, I'm not convinced at first glance (because computations're still haskell-values)
14:37:14 <Cale> right*
14:37:30 <Philippa_> oh, wait, yes
14:37:38 <Philippa_> you can't have anything valid to pass into join otherwise :-)
14:37:43 <Cale> yeah
14:51:08 <roconnor> @dijnn ((a -> b) -> t) -> (a -> b) -> a
14:51:09 <lambdabot> -- f cannot be realized.
14:51:28 <roconnor> @dijnn (((a -> b) -> t) -> (a -> b) -> a)->Void)->Void
14:51:28 <lambdabot> Cannot parse command
14:51:36 <roconnor> @dijnn ((((a -> b) -> t) -> (a -> b) -> a)->Void)->Void
14:51:36 <lambdabot> -- f cannot be realized.
14:52:32 <roconnor> @dijnn ((((a -> b) -> Void) -> (a -> b) -> a)->Void)->Void
14:52:32 <lambdabot> f a =
14:52:32 <lambdabot>   void (a (\ _ b ->
14:52:32 <lambdabot>      void (a (\ c -> void (c (\ d -> void (c (\ _ -> b d))))))))
14:53:00 <roconnor> @dijnn ((((a -> b) -> Void) -> (a -> b) -> a)
14:53:01 <lambdabot> Cannot parse command
14:53:04 <roconnor> @dijnn ((((a -> b) -> Void) -> (a -> b) -> a))
14:53:05 <lambdabot> f a b = void (a (\ c -> void (a (\ _ -> b c))))
14:53:14 <psi> I always thought it was "djinn"
14:53:20 <roconnor> I can't spell
14:53:33 <roconnor> lambdabot is very understanding
14:53:37 <psi> :D
14:54:36 <psi> so, am I the only refreshing his student home on google several times a day?
14:57:16 <psi> I've been expermenting making some bindings manually with the FFI interface. converting types from haskell to C is not exactly difficult, but it is tedious. Do I understand correctly that C->Haskell helps you with that?
14:57:54 <psi> haskell to c, and vice versa
14:58:16 <Lemmih> psi: What projects did you propose?
14:58:54 <stepcut> psi: the built-in ffi is ok, until you need to access members of a structure -- the only way to do that is to specify the byte-offset
14:59:10 <psi> Lemmih: gstreamer bindings. (and my name is Simon Sandlund. I know at least one more has sent in an app.)
14:59:46 <stepcut> psi: I use hsc2hs which adds some helper functions for using #defines and getting/setting structure members
15:00:24 <psi> ah, ok.
15:00:43 <dcoutts> what is HOC?
15:00:53 <psi> so what do you do? write c code for it?
15:01:05 <psi> oh, wait
15:01:33 <psi> I'll take a look at hsc2hs
15:01:34 <dcoutts> oh, Haskell to Objective-C
15:01:53 <xerox> Yes!
15:02:07 <xerox> dcoutts: do you remember that monadic interface....
15:02:16 <dcoutts> not really
15:02:40 <xerox> dcoutts: yes I didn't go in much detail.  I'll be talking with Andre Pang ASAP.
15:03:08 <dcoutts> xerox, did you apply for that too? #65
15:03:14 <xerox> Nope.
15:03:57 * psi has the following program working: 'main = getArgs >>= gstInit >> gstVersion >>= print' :)
15:03:59 <xerox> But I think it could be a cool project.
15:04:33 <lesser> I want to play with Haskell a bit: anyone here want to help me convert my "game" from Python to Haskell (100 lines of Python code)?
15:04:43 <xerox> psi: cool, another friend of mine proposed to do that for C# (mono.)
15:06:13 <psi> xerox: aren't there .NET bindings already?
15:06:43 <psi> ah, they are apparently not ready yet.
15:11:06 * psi decides to watch the latest prison break
15:12:33 <Cale> lesser: sure
15:13:20 <Cale> lesser: what game?
15:14:50 <lesser> its a puzzle game
15:14:55 <lesser> not really*
15:19:33 <lesser> ill make a file to explain what im trying to code
15:25:32 <Cale> lesser: sure :)
15:25:59 <goltrpoat> anyone know of a good introduction to redex-based AST simplification?  i wrote a little symbolic differentiation deal a few days ago (lets you enter an expression, differentiates it, tries to simplify the result, dumps out the transformed AST in human-readable form).. but then the same topic came up on haskell-cafe, so that got me interested in coming up with something less silly than my current simplification scheme
15:27:17 <goltrpoat> i did something similar for a bytecode-level peephole optimizer a while back, but did it pretty much blindly
15:28:17 <jfoutz> i think it's just hard. simplifying (1 + x) + (x + 1) is about my limit.
15:28:48 <jfoutz> everything i've seen is based on optimizing specific cases
15:29:38 <lesser> i hope this works
15:29:52 <goltrpoat> right now it's having trouble simplifying stuff like Add (Add (Val 5) (Var x)) (Val 10), because neither 5+x nor x+10 can be reduced.. i thought of rewriting those as operators on lists and sorting them by atom type, but that seems hacky
15:31:23 <goltrpoat> i also thought of doing a normalization-style scheme where chains of operators are similarly put into lists, but then you do an exhaustive search on all permutations, and try to optimize some sort of a metric on the expression
15:31:30 <jfoutz> i think you want to do something like gather all vals at a specific precedence level, and unify them appropriately. then gather all vars at a specific precedence level and unify them
15:32:06 <goltrpoat> well yah, that's what i meant by sorting by atom type
15:32:36 <jfoutz> you don't need to build the list, you just need to traverse the tree.
15:33:07 <jfoutz> you need a function that will percolate vars up to the top...
15:34:08 <goltrpoat> oh right.  so Add (Add x y) (Add z w) -> unifyAdd (x y z w), and rewrite Sub in terms of Add and a new constructor Neg, or some such
15:34:17 <jfoutz> there you go.
15:34:41 <jfoutz> ensure that any variable is the (say) first left value of any tree
15:35:05 <goltrpoat> yah that's a fair bit nicer than the sorted list thing
15:35:11 <jfoutz> then you only have to look one deep (and you can pattern match against it)
15:36:25 <goltrpoat> cool, thanks.. i'll try that
15:36:35 <jfoutz> gcc is scary in that regard
15:36:59 <goltrpoat> gcc is compiling to some lisp-like RTL though, right
15:37:14 <jfoutz> yeah, they'll optimize through things like strlen
15:37:20 <goltrpoat> -nod-
15:37:49 <jfoutz> again (1+x) + (x +1) is about as far as i ever got
15:38:47 <lesser> http://bellsouthpwp.net/a/o/aoeu256/starsweep.7z
15:38:48 <goltrpoat> the differentiator takes 2^x to a 20-term expression, and then happily simplifies it down to 2^x log 2
15:38:59 <goltrpoat> so in some places, it works pretty well
15:39:03 <goltrpoat> in others.. not so much
15:40:09 <xerox> lesser: 7z ?! (-:
15:40:11 <jfoutz> paradigms of ai programming has a simplifier in it. i can't thing of another textbook cover of that though.
15:40:22 <lesser> http://prdownloads.sourceforge.net/ika/ika-dlls-0.61.zip
15:40:32 <lesser> for those interested in helping me play arround with haskell
15:40:45 <lesser> i am trying to convert a game i wrote in python to haskell
15:42:01 <falconair> is hugs known to have bad errors reporting or am I catching it on a bad day?
15:42:04 <jfoutz> actually paip has this cute program like eliza. it pattern matches word problems, then solves them
15:43:08 <wchogg> falconair:  I don't know if I'd call hugs bad, but ghci tends to be more helpful.
15:43:37 <falconair> wchogg, ghci is the same as ghc?
15:44:05 <wchogg> Yeah, it's just the interactive mode for ghc.  If you have ghc you have ghci.
15:44:18 <falconair> ok, thanks, i'll try it
15:45:25 <goltrpoat> jfoutz:  yah, bookmarked the amazon link.. seems pretty cool
15:45:31 <goltrpoat> gotta run, bar night.  later
15:45:36 <jfoutz> night
15:46:21 <wchogg> Some days I feel like c++ is the abusive father I never had.
15:46:39 <jfoutz> hehehe
15:47:42 <sidewinder> so Graphics.HGL is broken on windows?
15:48:15 <lesser> sidewinder: what do you mean?
15:48:28 <sidewinder> it's wierd.  I built and ran a little opengl demo from the docs and nothing came up.  I went outside and came back about a half hour later and the window was up
15:48:40 <sidewinder> lesser: I thought OpenGL on windows was busted
15:49:57 <lesser> which docs :)
15:50:42 <sidewinder> the sample on the first page of Graphics.HGL
15:53:44 <lesser> anyone got http://bellsouthpwp.net/a/o/aoeu256/starsweep.7z working?
16:08:17 <pirroh> hi
16:08:22 <pirroh> kudos to xerox
16:09:44 <xerox> Howdy :-D
16:11:28 <sethk> dons, are you around?
16:11:30 <pirroh> @karma+ xerox
16:11:30 <lambdabot> xerox's karma raised to 15.
16:12:02 * xerox hugs pirroh 
16:16:53 <ndm> sidewinder: i had OpenGL on windows with Hugs working earlier today :)
16:17:10 <ndm> with completely fresh builds from CVS of everything, mind you
16:18:54 <xerox> Goodnight folks.  Have a joyous time.
16:19:59 <psi> g'night xerox
16:23:14 <sidewinder> ndm: hmm. i'm using the gch from Visual Haskell
16:23:18 <sidewinder> gch
16:23:23 <ndm> ghc ?
16:23:24 <sidewinder> ghc
16:23:48 <sidewinder> ndm: do you have some sample code i can try?
16:24:04 <ndm> sidewinder: not at the mo, its in my office
16:24:15 <ndm> i can get you some in about 10 hours
16:24:21 <ndm> or you can try a recent release of WinHugs
16:24:23 <ndm> @where WinHugs
16:24:24 <lambdabot> http://www.cs.york.ac.uk/~ndm/projects/winhugs.php
16:24:31 <sidewinder> ndm: i've got winhugs
16:24:32 <ndm> that might work, although its slightly older libraries
16:24:41 <sidewinder> yeah, let me try that
16:24:43 <ndm> sidewinder: from that site, or from elsewhere?
16:24:54 <ndm> the other winhugs is about 3 years old, thats the new pre-release version
16:25:01 <sidewinder> yeah, i got the jan6 build
16:25:29 <ndm> does that work with OpenGL?
16:25:43 <sidewinder> no idea
16:25:57 <sidewinder> i'll try
16:26:07 <ndm> it used to work a bit, then crash out
16:26:12 <ndm> but sounds like better than GHC :)
16:26:40 <sidewinder> the libraries page of www.haskell.org says that opengl is broken on windows
16:27:10 <ndm> i had the demos running earlier today
16:27:12 <ndm> under winhugs
16:27:19 <ndm> but as i exited the demo, it crashed out winhugs
16:27:25 <ndm> but after it worked fine during hte demo
16:27:41 <sidewinder> what demos are you talking about?
16:28:38 <ndm> demos\HGL\GTest.hs
16:28:41 <ndm> it fires up 8 windows and plays with them
16:28:51 <ndm> under hugs it crashes with a signal quickly
16:28:57 <ndm> under winhugs, it crashes when you close the window
16:29:08 <ndm> but hte winhugs mode is probably just about useable
16:29:28 <ndm> and if you prod the GL maintainer in my direction, i;'m happy to do a b it of work for winhugs + GL
16:31:04 <sidewinder> ok, the Gltest opened up the windows and then promptly crashed winhugs
16:31:19 <ndm> after you exited the windows, or before?
16:31:23 <sidewinder> before
16:31:39 <ndm> the build i had going today crashed after i exited all 8 windows
16:31:46 <ndm> but did allow me to interact with them up until that point
16:31:58 <sidewinder> i'm gonna try that demo with ghc
16:39:05 <sidewinder> ndm: OpenGL HelloWorld did work in winhugs but not Visual Haskell
16:39:28 <ndm> sidewinder: it might work better in the newer winhugs
16:39:44 <ndm> and possibly better if i managed to get Visual Studio OpenGL and VS WinHugs
16:39:51 <ndm> at the moment its GCC OpenGL
16:40:02 <sidewinder> ndm: and Tests.hs crashed winhugs
16:40:31 <sidewinder> what's VS WinHugs?
16:40:38 <sidewinder> you mean compiled with VS?
16:40:39 <ndm> Visual Studio
16:40:41 <ndm> yep
16:40:53 <ndm> because of the way OpenGL is set up, getting a VS build is really hard
16:40:55 <sidewinder> is there a solution for it?
16:40:57 <ndm> so i have a GCC build
16:41:10 <ndm> it doesn't work like that, you need to run each C file thought ffihugs
16:41:16 <sidewinder> oh
16:41:21 <ndm> but the custom ffihugs i have, which builds with VS, rather than GCC
16:41:39 <sidewinder> this is a bummer
16:42:06 <ndm> indeed
16:42:20 <ndm> is OpenGL on windows officilly unsupported?
16:42:34 <ndm> if there is a maintainer who has windows and still cares, i'll happily work with them
16:42:36 <sidewinder> the vendors make the drivers
16:42:55 <ndm> the error is probably not at the driver level
16:43:04 <ndm> probably much higher up - a haskell maintainer i mean
16:43:09 <sidewinder> oh, you mean haskell supported
16:43:41 <sidewinder> i'm a newb so i'm not sure how useful i would be
16:43:58 <sidewinder> but i just run linux on servers
16:44:10 <ndm> i don't use opengl
16:44:28 <ndm> but i guess the haskell one is just a wrapper round a C one
16:44:43 <ndm> and i guess the bugs are in the C->Haskell phase, way above the drivers and OS dependant bits
16:44:49 <sidewinder> yeah
16:45:52 <Philippa_> given that OpenGL otherwise tends to work pretty well under windows...
16:46:07 <ndm> yeah, it segfaults under WinHugs
16:46:22 <ndm> which makes me think one of the calling conventions or argument signatures is wrongly declared
16:47:13 <ndm> although i've kind of given up caring - it took 2 weeks to build libraries on WinHugs
16:48:14 <Philippa_> I care, but can't be a maintainer
16:48:21 <ndm> but if someone else cares, i would begin to care more
16:48:44 <ndm> i just need someone to talk to about it, who has windows, and cares about OpenGL
16:48:57 <ndm> and can at least tell me where the C files are coming from, or what the bug might be
16:49:46 <sidewinder> isn't the ffi generation pretty much automated?
16:49:49 <ndm> Philippa_: do you have visual studio, and would you like to take a shot at fixing it?
16:49:52 <Philippa_> it's been too long since I messed around with it in C, sadly. It's worth checking for a calling convention clash though, especially on the code that sets up an OGL context
16:49:58 <ndm> sidewinder: automated, yes, broken, yes
16:50:02 <Philippa_> I don't have VS, and I'm pretty braindead at the mo
16:50:28 <ndm> sidewinder: the generation is automated, but based on teh signatures you supply - I suspect one of them is wrong somewhere
16:50:35 <sidewinder> hmm
16:50:44 <sidewinder> i've got vs2003 and v2005
16:51:04 <sidewinder> but gotta start making dinner right now:)
16:51:05 <sidewinder> bbiab
16:51:23 <ndm> sidewinder: if you want, send me an email, and i can get you pre-release copies of everything
16:51:30 <ndm> then maybe you can figure out whats going wrong :)
17:16:14 <ndm> sidewinder: if you do decide to take up the challenge, email me at ndmitchell       #####    gmail.com
17:19:09 <zarvok> user
17:26:43 <sethk> @seen dons
17:26:43 <lambdabot> dons is in #haskell-overflow and #haskell. I last heard dons speak 10 hours, 37 minutes and 48 seconds ago.
17:28:24 <jfoutz> @seen you
17:28:24 <lambdabot> I haven't seen you.
17:34:40 <Lemmih> khaladan: UNDERFLOW!
17:34:51 <khaladan> yikes!
17:46:39 <zer0`> > map (show.(^2))[1..10]
17:46:40 <lambdabot> ["1","4","9","16","25","36","49","64","81","100"]
17:48:30 <zer0`> > map (show.negate.(^2))[1..10]
17:48:31 <lambdabot> ["-1","-4","-9","-16","-25","-36","-49","-64","-81","-100"]
17:53:49 <zer0`> > map (^2) (reverse [1..10])
17:53:50 <lambdabot> [100,81,64,49,36,25,16,9,4,1]
18:27:18 <Lemmih> @seen SyntaxNinja
18:27:18 <lambdabot> I saw SyntaxNinja leaving #haskell 1 hour, 1 minute and 13 seconds ago, and .
18:37:48 <palomer> > 0 ^ 0
18:37:49 <lambdabot> 1
19:00:31 <ihope_> 0^0 = 0
19:00:34 <ihope_> It just does.
19:00:41 <ihope_> :-P
19:01:34 <lispy> nah, it's undefined since it's equivalent to 0^1/0^1 = 0/0, and we already know youc an't divide by zero
19:01:57 <lispy> > 0 ** 0
19:01:58 <lambdabot> 1.0
19:02:10 <palomer> hah, you've been beat
19:02:20 <palomer> sucker
19:02:28 <lispy> let 0 ** 0 = 0.0 in 0 ** 0
19:02:32 <lispy> > let 0 ** 0 = 0.0 in 0 ** 0
19:02:33 <lambdabot> 0.0
19:02:35 <lispy> hah!
19:02:45 <lispy> i just have to redefine it :)
19:02:56 <lispy> > let 0 ** 0 = 1/0 in 0 ** 0
19:02:57 <lambdabot> Infinity
19:03:13 <lispy> lambdabot: say NaN with me
19:03:34 <lispy> > 0 ** 0 = (-1)**(0.5) in 0 ** 0
19:03:35 <lambdabot>  parse error on input `='
19:03:41 <lispy> > let 0 ** 0 = (-1)**(0.5) in 0 ** 0
19:03:42 <lambdabot> Add a type signature
19:03:45 <lispy> dah!
19:03:48 <mlh> > NaN
19:03:49 <lambdabot>  Not in scope: data constructor `NaN'
19:03:49 * lispy gives up
19:04:01 <Lemmih> > 0/0
19:04:02 <lispy> > let 0 ** 0 = (-1)**(0.5) :: Double in 0 ** 0
19:04:03 <lambdabot> NaN
19:04:04 <lambdabot>  Non-exhaustive patterns in function **
19:04:13 <lispy> Lemmih: yah, there we go
19:04:22 <lispy> > let 0 ** 0 = 0/0 in 0 ** 0
19:04:23 <lambdabot> NaN
19:04:31 <mlh> > log(-1)
19:04:32 <lambdabot> NaN
19:07:33 <araujo> Hello
19:12:11 <palomer> > let 1 + 2 = 4 in 1 + 2
19:12:12 <lambdabot> 4
19:12:15 <palomer> > let 1 + 2 = 4 in 1 + 4
19:12:15 <lambdabot>  Non-exhaustive patterns in function +
19:12:43 <palomer> > let 0 ** 0 = "lisp is WRONG" in 0 ** 0
19:12:44 <lambdabot> "lisp is WRONG"
19:12:50 <palomer> s/lisp/lispy
19:14:37 <dons> @seen petekaz
19:14:38 <lambdabot> petekaz is in #haskell. I last heard petekaz speak 8 hours, 21 minutes and 1 second ago.
19:15:56 <palomer> dons: check out the prototype for the proposal: http://www.magnesium.net/~palomer/graphical/
19:16:49 <dons> cool!
19:17:27 <dons> btw, have you read the paper on graphical type analysisf from the 04 Haskell workshop?
19:17:41 <dons> let me find the ref..
19:19:59 <dons> ah, "Haskell type browswer"
19:20:26 <dons> neubauer and thiemann
19:20:27 <sethk> dons, do you have open office installed?  If I send you a .odt document, can you read it?
19:21:02 <dons> hmm. I have it on a linux box. I could probably decode it.
19:21:06 <dons> sending text would be better.. :)
19:21:19 <sethk> dons, ok, if you don't normally use it, I'll send it as text
19:21:28 <dons> cheers.
19:21:52 <dons> palomer: check out "Haskell type browser" paper. It was something roughly similar, I think. But you'll want to inspect the details.
19:22:18 <palomer> yeah, it's about the same
19:22:20 <dons> http://doi.acm.org/10.1145/1017472.1017474 if you have acm.
19:22:29 <palomer> http://www.informatik.uni-freiburg.de/~thiemann/haskell/HTB/
19:22:38 <palomer> though mine will have a nicer user interface
19:22:39 <dons> right
19:22:57 <dons> i don't mind. you can leverage the work. since its not in mainstream haskell use, there's definitely more to be done.
19:23:17 <palomer> yeah, and I don't think developers could use this one
19:23:40 <palomer> whereas mine is seamlessly usable by anyone using yi
19:23:51 <araujo> dons, hola!
19:25:04 <palomer> the point of the project is that anyone editing code with yi could simply point to where they need the type information and it would be displayed instantly
19:25:54 <palomer> (like in the prototype)
19:26:11 <dons> hey araujo 
19:26:21 <palomer> actually, they would need to be using yi/cabal
19:26:23 <dons> palomer: yep. that's what's needed in practice.
19:30:45 * palomer is really pumped about this
19:34:52 <ihope_> > let 0 ** 0 = (-1) Prelude.** (0.5) :: Double in 0 ** 0
19:34:53 <lambdabot> NaN
19:39:32 <hyrax42> hmmmm
19:39:39 <hyrax42> I'm working through yaht
19:39:46 <hyrax42> and reached exercise 4.10
19:39:50 <hyrax42> write a fold function for trees
19:40:04 <hyrax42> and I can't quite figure what it should do :/
19:40:12 <Cale> > let n^m = length . sequence $ replicate m [1..n] in 0^0
19:40:13 <lambdabot> 1
19:40:24 <ihope_> Well, you know how foldr replaces (:) and [] with given values?
19:40:38 <hyrax42> yeah
19:40:40 <ihope_> Do the same thing, but with the constructors you used for your tree.
19:40:49 <hyrax42> just now you have two types of "(:)"
19:40:51 <Cale> http://cale.yi.org/autoshare/folds.png
19:40:53 <hyrax42> left and right branches?
19:41:09 <Cale> You probably have a replacement for Branch and a replacement for Leaf
19:42:06 <Cale> so that foldTree l b (Branch (Branch (Leaf 1) (Leaf 2)) (Leaf 3)) = b (b (l 1) (l 2)) (l 3)
19:42:09 <Cale> for example
19:42:44 <hyrax42> ah, so now "inital value", rather a second function... I guess that makes sense
19:42:53 <hyrax42> *no
19:43:19 <Cale> basically, you're taking the types of the data constructors of your type, and generalising them a bit
19:44:02 <Cale> and the fold will replace those constructors in a value with the new functions
19:44:02 <ihope_> I like to call these foldy thingies recursive unions.
19:44:36 <Cale> in the diagram I pasted above, the diagram for foldr is the most typical
19:44:58 <Cale> that is, just straight across replacement, without restructuring
19:45:22 <Cale> > let n^m = length . sequence $ replicate m [1..n] in 2^10
19:45:23 <lambdabot> 1024
19:45:43 <Cale> > let n^m = length . sequence $ replicate m [1..n] in 3^2
19:45:44 <lambdabot> 9
19:45:58 <ihope_> > let n^m = length . sequence $ replicate m [1..n] in 0^0
19:45:59 <lambdabot> 1
19:46:03 <ihope_> !
19:46:06 <Cale> yes :)
19:46:33 <ihope_> Nice.
19:46:44 <ihope_> > let n^m = sequence $ replicate m [1..n] in 3^2
19:46:45 <lambdabot> [[1,1],[1,2],[1,3],[2,1],[2,2],[2,3],[3,1],[3,2],[3,3]]
19:47:46 <Cale> > let n^m = sequence $ replicate m [1..n] in 0^0
19:47:47 <lambdabot> [[]]
19:48:20 <Cale> there's one function from the empty set to itself -- the empty function :)
19:48:31 <ihope_> Void -> Void
19:48:46 <ihope_> \x -> case x of
19:49:02 <Cale> \x -> x
19:49:09 <ihope_> That'll work, too.
19:49:40 <ihope_> @type \x -> case x of
19:49:41 <lambdabot> parse error (possibly incorrect indentation)
19:49:44 <ihope_> @type \x -> case x of {}
19:49:45 <lambdabot> parse error on input `}'
19:52:08 <sethk> dons, I've been working on an interesting bug tonight, but it's somewhere deep in the O/S.  I have a server with three four-port ethernet cards, and when I use an interface from the second card, it crashes the o/s.  Completely locks up, no response from the keyboard, nothing in the logs.  
19:52:30 <sethk> dons, but our code works perfectly until the machine crashes.  :)
19:52:57 <sethk> dons, I told them not to use AMD 64, but somebody really wanted to play with it, I think
19:53:22 <dons> yikes. 
19:53:59 <sethk> dons, actually, given that I've been able to do this entire project in Haskell except for the device driver and about 200 lines of FFI, I am not going to complain
19:54:02 <Korollary> I wonder why they need so many ethernet cards
19:54:18 <sethk> Korollary, we're bulk testing 8 port firewalls
19:54:31 <sethk> we need to hit all the ports at once
19:54:31 <Korollary> ah
19:54:59 <sethk> the previous generation had 10, so they used 3 four port cards
19:55:21 <sethk> for the eight, I would have used two four-ports, plus a single, but we want to keep the hardware the same for testing the old and the new generation
20:03:14 <sethk> I think if I turn off ACPI this problem will go away.
20:13:36 <akemp> @seen dons
20:13:37 <lambdabot> dons is in #haskell-overflow and #haskell. I last heard dons speak 20 minutes and 14 seconds ago.
20:14:43 <akemp> dons: a trivial patch to Yi to get it to work with the latest FPS is in a darcs repo at http://alsonkemp.dyndns.org/yi.  
20:59:29 <machack666> what would I need to do to get a parsec parser to indicate either newline or eof?  when I try (newline <|> eof) I get a type error.
21:00:06 <dons> akemp: please darcs send me the patches, they're much easier for me to apply that way
21:00:07 <machack666> I want to read a possibly 0 number of characters up until newline or eof.
21:00:24 <dons> and i'm forced to look at it to get my mail inbox clear
21:00:38 <dons> ^^ good point for anyone else sending patches to people.
21:02:52 <Lemmih> machack666: (newline >> return ()) <|> eof
21:04:04 <machack666> Lemmih, thanks
21:09:14 <akemp> dons: I don't have a mail daemon set up on either of my Linux boxes.   ...  At least, I don't think that I do...  I did "darcs send" and it did something, so we'll see if you get an e-mail.  [I noodled with the daemon before, so maybe I set it up correctly.]
21:10:09 <dons> well, I got an email :)
21:10:18 <akemp> Really?!  Wow!  I rule!  ;)
21:10:23 <dons> so maybe your noodles are  ok
21:10:38 <dons> darcs patch: Update to latest version of FPS
21:10:49 <akemp> That's the one.
21:10:59 <dons> ?karma+ akemp -- yi patches!
21:11:00 <lambdabot> akemp's karma raised to 1.
21:11:27 <akemp> I can't believe that worked.  I spent about 5 minutes on postfix about 3 months ago and then realized I didn't care about it.
21:11:44 <dons> hehe
21:11:57 <dons> intercontinental communication rules.
21:13:28 <akemp> Absolutely.  Note: I'm still dancing around the room...
21:15:56 <akemp> @seen syntaxninja
21:15:57 <lambdabot> I saw syntaxninja leaving #haskell 3 hours, 49 minutes and 50 seconds ago, and .
22:05:33 <Oeje1> Lemmih: Good morning!
22:08:00 <Oeje1> And to other too.
22:08:05 <Lemmih> Oeje1: God morgen, god morgen.
22:08:56 <Oeje1> Lemmih: Allerede oppe? ;-)
22:10:37 <Lemmih> Haven't slept yet.
22:10:40 <kzm_> Bah.  Det er jo snart frokost.
22:10:46 <Lemmih> Why are you up?
22:10:59 <kzm_> (= morgenmad :-)
22:11:13 <sieni> == morning mad?
22:11:25 <Lemmih> kzm_: jeg vidste ikke at du var dansker.
22:11:47 <kzm_> det er jeg s'gu heller ikke. :-)
22:11:58 <Lemmih> Svensker?
22:12:02 * kzm_ is from .no
22:12:29 <Lemmih> Ah, the money country.
22:12:36 <Lemmih> sieni: breakfast.
22:12:54 <kzm_> Well. I suppose.  Of course, the money is...elsewhere, apparently.
22:14:17 <kzm_> ?localtime kzm_
22:14:18 <lambdabot> Local time for kzm_ is Wed May 10 07:13:26
22:14:32 <Lemmih> ?time Lemmih 
22:14:35 <lambdabot> Local time for Lemmih is Wed May 10 07:19:08 2006
22:14:49 <Lemmih> I think my clock is off.
22:14:57 <kzm_> At least one of us needs to run NTP
22:15:27 <Oeje1> ?time Oeje1
22:15:47 <Lemmih> ?time Lemmih 
22:15:51 <lambdabot> Local time for Lemmih is Wed May 10 07:15:26 2006
22:15:53 <Oeje1> ?localtime
22:16:02 <Korollary> Lemmih: What do you mean by lack of type system usage in ghc's sources?
22:16:02 <Oeje1> :'(
22:16:55 <kzm_> 10 May 07:16:15 ntpdate[15477]: step time server 192.36.143.150 offset 29.943928 sec
22:17:35 <Korollary> kzm_: are you a student?
22:18:07 <kzm_> Not anymore.  Do I ask too many dumb questions?
22:18:57 <Lemmih> Korollary: GHC likes to pass around data structures like this 'data X = X (Maybe Y) Z N' where Z and N are _|_ if some flags are set and (Maybe Y) must be a Just if some other flags are on.
22:18:59 <Korollary> No. I asked because of your reference to lack of money
22:19:51 <Korollary> Lemmih: Global flags?
22:20:30 <shapr> jo, det er nu frokost
22:21:06 <kzm_> Ah.  The lack of money is due to an abundance of children.  Fortunately, I guess - it's one of the better reasons to become poor.
22:21:11 <Oeje1> shapr: Nej, det er ikke frokosttid.
22:21:22 <Lemmih> Korollary: The static flags are global (with unsafePerformIO hacks and all), the dynamic flags are just passed around everywhere.
22:21:30 <shapr> When do you have breakfast?
22:22:03 * kzm_ thinks frokost means different things in .dk and .no/.se
22:22:10 <Oeje1> shapr: Today, at 0550.
22:22:27 * kzm_ was, apparenlty, wrong.
22:22:37 <Korollary> Lemmih: Are there any comments around that excuse themselves due to performance reasons or something?
22:22:41 <shapr> Hm, 7:30 is a good breakfast time for me.
22:24:09 <Lemmih> Korollary: In previous incarnations of GHC, the low level compile function returned a (Maybe CompiledByteCode) for when bytecode were the target and a ModIface which was _|_ when the compiler was in one-shot mode.
22:25:45 <Lemmih> Korollary: It's just what happens after 14 years of development. The code will run faster if/when we redesign it.
22:27:04 <Korollary> Blasphemy. Haskell code should have evolved into a swan in fourteen years.
22:43:14 <newsham> nifty http://users.info.unicaen.fr/~karczma/arpap/diffalg.pdf
22:53:04 <araujo> Hi
23:12:09 <roconnor> @djinn ((a -> ((b->a)->a)) -> ((t -> a)->a)) -> (a -> ((b->a)->a)) -> a
23:12:41 <roconnor> @yow
23:21:25 <Lemmih> @bot
23:22:00 <Lemmih> Weird. It responsive to PMs.
23:22:10 <dons> @botsnack
23:23:34 <dons> @bot
23:23:42 <dons> hmm
23:23:57 <dons> ?uptime
23:24:10 <dons> ?uptime
23:24:30 <lambdabot> uptime: 6 seconds
23:24:43 <dons> no idea what happened there.
23:24:47 <roconnor> @yow
23:24:48 <lambdabot> I brought my BOWLING BALL -- and some DRUGS!!
23:24:48 <dons> i blame the network
23:24:51 <roconnor> @djinn ((a -> ((b->a)->a)) -> ((t -> a)->a)) -> (a -> ((b->a)->a)) -> a
23:25:02 <roconnor> hmmm
23:25:14 <roconnor> I'm not sure lambda bot likes my question
23:26:51 <dons> hmm
23:26:57 <dons> bad roconner. that's what you did.
23:27:07 <dons> now, djinn should have a timeout ..
23:27:13 * dons checks the source
23:27:34 <dons> ah, no it doesn't :}
23:27:39 <roconnor> I didn't think my question was so hard.  I'll as Coq the same question
23:27:57 <lambdabot> djinn module failed: Prelude.init: empty list
23:28:04 <dons> had to kill it.
23:28:11 <dons> should add the timeout capibility
23:29:22 <xerox> Welcome to ``how a type theorist kills a bot'' part two.
23:29:46 <roconnor> Who made  djinn?  It's got a bug. ;)
23:29:56 <xerox> lennart
23:30:18 <dons> ?darcs version
23:30:18 <lambdabot> version not available
23:30:19 * roconnor wonders if ``it's'' is a contraction for it has
23:30:22 <dons> ?djinn version
23:30:22 <lambdabot> -- f cannot be realized.
23:30:27 <dons> ?djinn-version
23:30:27 <lambdabot> Unknown command, try @list
23:30:31 <dons> ?djinn-vers
23:30:31 <lambdabot> Djinn version 2005-12-15.
23:36:11 <ADEpt> morning
23:39:27 <dons> morning ADEpt 
23:40:05 <dons> btw, ADEpt == Dmitry A ?
23:40:26 <dons> I should know these things.
23:43:00 <ADEpt> dons: yep, indeed
23:43:08 <dons> :)
23:44:13 <ADEpt> dons: i plan to collect all links from SOC into table (link, student name, project) so that we could do some pivot tables and see it in different perspectives. What do you think, will it be useful?
23:44:21 <dons> ah yes very!
23:44:27 <dons> I was just doing the same thing 
23:44:44 <dons> sorting into libraries/haskell tools/extending projects/new projects
23:44:47 <dons> and then also collecting the duplicates
23:45:03 <dons> since removing the weaker of duplicate applications seems like an important task 
23:45:23 <dons> so , please, go ahead .
23:46:43 <ADEpt> dons: i think it would be important to ask all "strong" submittants about whether they submitted SOC applications to other organizations. Because succesfull application to other organization effectively "disables" applicant for haskell.org
23:47:17 <dons> hmm. yes. I'm not too sure how we deal with this. I guess we can mail them.
23:47:53 <sieni> why would they answer?
23:48:24 <ADEpt> sieni: why would they participate in the first place? :)
23:49:19 <dons> they're scared that if they don't we'll just reject them :)
23:49:58 <sieni> ADEpt: I mean that submitting applications to SOC projects improve their probability of getting a position and obviously answering "yes" to a question like "have you applied to another SOC project?" would diminish their chances of getting a position. 
23:50:48 <sieni> dons: and there's a risk that they answer "no" even if they have applied to another SOC project
23:52:11 <sieni> google might be of help as well, of course. maybe other projects put their lists of applicants as well on the web
23:52:32 <dons> yeah, i don't know if we need to do anything about it.
23:52:57 <dons> other than just make sure our list accurately reflects the importance of each project getting done.
23:54:56 <ADEpt> dons: google already published their stance on this matter
23:55:03 <ADEpt> dons: in the soc-admin list
23:55:13 <dons> ah, what was that position?
23:57:38 <ADEpt> dons: if the student A qualifies in organizations B and C then google 1)contacts B and C and asks them to resolve conflict; If they can't decide, google asks student to choose between B and C; If he cant decide, google has the final say. Organization, which "loses", have the relevant proposal stiked out from it's "top N" and and next biggest-scored proposal is added to "top N"
23:58:27 <dons> right.
23:58:40 <dons> so we just make sure we get a project order we all agree on.
23:58:50 <kzm> thanks for that point.
23:59:02 <kzm> I mailed the haskell mentors list with some suggestions.
23:59:12 <dons> kzm: how many bioinformatics projects do you think we should support.. :)
23:59:21 <kzm> Oh, I don't know.
23:59:27 <kzm> Probably no more than five or six.
23:59:33 <kzm> If we get, like six or seven slots.
23:59:45 <dons> hehe
