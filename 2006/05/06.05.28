00:32:09 <dons> ?uptime
00:32:10 <lambdabot> uptime: 1 day, 1 hour, 13 minutes and 27 seconds
01:38:37 <Stinger_> is there a way to get info about functions/objects/types in ghci?
01:38:46 <Stinger_> <- newbie
01:39:15 <wilx> Info?
01:40:07 <Stinger_> ooh, ta
01:41:17 <xerox> Stinger_ - Try :help.
01:47:10 <shapr> @yow !
01:47:10 <lambdabot> All of a sudden, I want to THROW OVER my promising ACTING CAREER, grow
01:47:10 <lambdabot> a LONG BLACK BEARD and wear a BASEBALL HAT!! ...  Although I don't know
01:47:10 <lambdabot> WHY!!
01:48:03 <shapr> d00d, wassup?
02:01:55 <shapr> It's so quiet!
02:03:38 <xerox> pssssssshhh!
02:04:17 <cptchaos> and I suddenly remember an old bjoerk song ...
02:15:59 <xahlee> hey, off topic... but may i ask if anyone familiar with Mathematica?
02:16:43 * xahlee love bj√∂rk
02:17:08 <Stinger_> Show is a class correct?
02:17:27 <xerox> Yes.
02:17:35 <xerox> xahlee - Yes, someone here are.
02:17:53 <xahlee> xerox: heh... yeah i remember you do
02:18:16 <xahlee> xerox: i wanted to know, is there some intergrated graphics system/lang similar to Mathematica that i can use?
02:18:57 <xahlee> i mean, i use mma to do a lot graphics programing... but when i don't have mma, or sometimes i want to write opensource programs so that others can use/see, what do i use?
02:19:05 <xerox> 2D cool graphics  ==  Cairo (-:
02:19:27 <xahlee> ,cairo
02:19:33 <xerox> @where gtk2hs
02:19:34 <lambdabot> http://haskell.org/gtk2hs/
02:19:37 <xahlee> xerox: does it not support 3d?
02:20:12 <xahlee> i don't want a GUI libraries though
02:20:28 <xerox> It is just a package that can be used without GTK
02:20:36 <xerox> For 3D I think OpenGL is the way to go
02:20:37 <xahlee> i want a high-level graphics system as in mathematica where i can produce geometric graphics
02:20:55 <xahlee> nah, those are too low level
02:21:03 <xerox> Yes, those aren't high-level.
02:21:21 <xerox> Maybe Cale knows something.
02:21:32 <ricebowl> a question... I'm writing in Haskell a program to analyze some x86 code and optimize it... I have a data structure that represents the machine state, and I want to define a function called rdcxt (read context) to read state out of the structure
02:21:38 <xahlee> for example, otherwise i might as well use Java's Swing or Awk or it's graphics lib
02:21:46 <ricebowl> but the catch is that I want it to be polymorphic
02:22:02 <ricebowl> I have several enumerators, e.g. Reg8 (AL, CL, ...) and Reg32 (EAX, ECX, ...)
02:22:15 <ricebowl> I made a class to try and do this, but I'm getting type errors
02:22:37 <ricebowl> the definition of rdcxt is rdcxt :: X86Cxt -> a -> Maybe b
02:22:46 <ricebowl> in the case of Reg32 it would be X86Cxt -> Reg32 -> Maybe Word32
02:23:03 <ricebowl> in the case of Reg8, well, just s/32/8/
02:23:20 <ricebowl> but GHC is complaining that it can't match the type variable b
02:23:48 <ricebowl>     Couldn't match the rigid variable `b' against `Word32'
02:23:48 <ricebowl>       `b' is bound by the type signature for `rdcxt'
02:23:48 <ricebowl>       Expected type: Mask b
02:23:48 <ricebowl>       Inferred type: Mask Word32
02:24:36 <xerox> ricebowl - Are you sure you want an a -> b function?
02:24:45 <xerox> (a and b being not constrained)
02:24:54 <ricebowl> they need to be constrained, but I don't know how to do that
02:25:02 <ricebowl> Reg32 always has to produce a Maybe Word32
02:25:07 <ricebowl> Reg8 always has to produce a Maybe Word8
02:26:03 <ricebowl> I just left it unconstrained in the class definition assuming that if it were used improperly, the function definition would simply not exist
02:26:04 <xerox> class Foo r w | r -> w where
02:26:04 <xerox>   rdcxt :: X86Cxt -> r -> Maybe w
02:26:04 <xerox> instance Foo Reg32 Word32 where
02:26:04 <xerox>   rdcxt ...
02:26:04 <xerox> instance Foo Reg8 Word8 where
02:26:05 <xerox>   ...
02:26:13 <ricebowl> ah
02:26:20 <ricebowl> let me try that, thanks
02:26:31 <xerox> The `| r -> w' part means ``r chooses w'' (uniquely.)
02:27:31 <ricebowl> I see
02:32:46 <ricebowl> awesome, many thanks
02:33:06 <ricebowl> that's going to greatly reduce the code size since now I don't have to specialize thrice *by hand*
02:42:02 <xerox> (-:
03:12:26 <ricebowl> @type Data.Map.insertWith
03:12:27 <lambdabot> forall a k.
03:12:27 <lambdabot>         (Ord k) =>
03:12:27 <lambdabot>         (a -> a -> a) -> k -> a -> Data.Map.Map k a -> Data.Map.Map k a
03:12:44 <ricebowl> how does that work... what if the key isn't in the map, what value would be supplied?
03:13:26 <resiak> I think that then the key and value you supply just get inserted directly.
03:14:48 <ricebowl> ah
03:25:54 <dcoutts> dons, so, what's the count? How many theorems do we not have to prove due to QuickCheck finding counter-examples?
03:26:58 * dcoutts reads his email
03:27:04 <dcoutts> dons, ah! nice bug.
03:27:25 <dcoutts> yeah, I'll take a look. Should just be fixing the wrapper
03:27:41 <dcoutts> oh, hmm.
03:28:02 <dcoutts> that makes it harder to have one wrapper, we'll have to generalise
03:28:32 <dcoutts> return rather than a length, a start and end pointer or length+offset
03:28:41 <dcoutts> that'll allow filtering up & down loops
03:29:25 <goron> Is there an undirected graph implementation somewhere? Or should I just wrap Data.Graph.Inductive?
03:36:35 <dcoutts> goron, yeah that's probably your best bet.
04:23:51 <goron> Ok, found yet another bug: (\n->map (\x->Data.IntSet.fromList [x,x+1,x+2,n]) [1..n-1]) 5
04:24:21 <goron> Is there any place on earth where I can find quality software? 
04:26:58 <Stinger_> whats wrong with that, just out of interest
04:27:21 <goron> Stinger_: Did you execute it? Count the number of elements.
04:27:33 <Stinger_> what about them
04:27:48 <goron> Stinger_: They are not equal.
04:28:02 <int-e> goron: of course not, it's a set
04:28:07 <Stinger_> some of the set elements get repeated
04:28:27 <int-e> goron: if n is one of x, x+1 or x+2, you'll get a 3-element set.
04:28:29 <Stinger_> as x gets higher it intersects with n-1
04:28:41 <Stinger_> sorry n rather
04:28:57 <goron> Makes sense, although in my case I thought I designed my algorithm that that case didn't occur. 
04:29:08 <goron> Probably my fault.
04:29:24 <int-e> > (\n->map (\x->[x,x+1,x+2,n]) [1..n-1]) 5
04:29:25 <lambdabot>  [[1,2,3,5],[2,3,4,5],[3,4,5,5],[4,5,6,5]]
04:30:47 <goron> Ok, there was a bug in my code. Sorry for bothering.
04:32:19 <goron> Off by one bug. 
04:36:56 <Lemmih> Bummer. (:
05:12:05 <Stinger_> how do you repeat a list a number of times?
05:12:30 <Lemmih> > replicate 10 [1,2,3]
05:12:31 <lambdabot>  [[1,2,3],[1,2,3],[1,2,3],[1,2,3],[1,2,3],[1,2,3],[1,2,3],[1,2,3],[1,2,3],[1,2,3]]
05:12:35 <jethr0> replicate 3 [1,2,3]
05:12:41 <Stinger_> ah thanks
05:14:36 <jethr0> > unfoldr (\i -> if i < 1 then Nothing else Just ([1,2,3], i-1)) 3
05:14:37 <lambdabot>  [[1,2,3],[1,2,3],[1,2,3]]
05:14:56 <Stinger_> I prefer the first ;)
05:15:04 <jethr0> hehe, just fooling around :)
05:15:31 <Stinger_> dont even know whats happening there :P
05:15:59 <jethr0> > iterate ([1,2,3]:) [] !! 3
05:16:00 <lambdabot>  [[1,2,3],[1,2,3],[1,2,3]]
05:16:44 <int-e> > join (map . const) [1,2,3]
05:16:45 <lambdabot>  [[1,2,3],[1,2,3],[1,2,3]]
05:17:07 <jethr0> that's cheating :)
05:17:35 <jethr0> plus, i don't understand it...
05:17:51 <int-e> map (const [1,2,3]) [1,2,3]
05:18:15 <int-e> that's what the join of the reader monad does: join f x -> f x x
05:18:58 <jethr0> hmm, i have little problems with sequence, but join sometimes still eludes me :)
05:19:50 <jethr0> i see huge potential for join in my quest for obfuscationH^H^H^H abstraction
05:19:53 <int-e> > join (>>) [1,2,3]
05:19:53 <lambdabot>  [1,2,3,1,2,3,1,2,3]
05:20:11 <jethr0> it's very similar to sequence, but different ^_^
05:20:51 <Stinger_> you people are evil
05:21:04 <jethr0> > [[1,2,3]] >> [[1,2,3]]
05:21:05 <lambdabot>  [[1,2,3]]
05:21:10 <int-e> > mapM (enumFrom 1) [1,2,3]
05:21:11 <lambdabot>  Couldn't match `[a]' against `t -> t1'
05:21:17 <int-e> > mapM (enumFromTo 1) [1,2,3]
05:21:18 <lambdabot>  [[1,1,1],[1,1,2],[1,1,3],[1,2,1],[1,2,2],[1,2,3]]
05:21:47 <Stinger_> its trinary
05:22:16 <int-e> it's a bit more subtle - first digit ranges from 1 to 1, second from 1 to 2, third from 1 to 3.
05:22:24 <int-e> and all 6 combinations of these are there.
05:23:17 <int-e> anyway, it's safe to ignore this stuff.
05:25:54 <seba> any ideas on how to calculate a list of all anagrams of a word?
05:26:08 <Stinger_> hmm actually what I wanted was the [1,2,3,1,2,3,..]
05:26:25 <int-e> > take 12 $ cycle [1..5]
05:26:26 <lambdabot>  [1,2,3,4,5,1,2,3,4,5,1,2]
05:26:38 <int-e> this one is handy, too.
05:27:01 <jethr0> > take 3 $ cycle [[1,2,3]]
05:27:02 <lambdabot>  [[1,2,3],[1,2,3],[1,2,3]]
05:27:49 <int-e> jethr0: cycle on a one-element list is sorta pointless though.
05:28:03 <jethr0> well, it's replicate if you take from it
05:28:11 <int-e> > take 3 $ repeat [1,2,3]
05:28:11 <lambdabot>  [[1,2,3],[1,2,3],[1,2,3]]
05:28:14 <jethr0> true
05:28:28 <int-e> hmm.
05:29:16 <int-e> > [1..4] >> [1,2,3]
05:29:17 <lambdabot>  [1,2,3,1,2,3,1,2,3,1,2,3]
05:29:21 <int-e> but that's obscure again.
05:30:08 <jethr0> doesn't work with non-multiples either
05:30:11 <jethr0> bbl
05:42:08 <dcoutts> dons, fixed the down loop fusion bug I think
05:49:21 <dcoutts> oh, hmm some QC tests still failing...
05:56:06 <seba> any ideas on how to calculate a list of all anagrams of a word?
05:56:59 <dcoutts> seba, calculate all permutations and filter that with a dictionary of words
05:58:13 <Stinger_> hmm, how do you pull something out of a tuple
05:58:43 <dcoutts> let (a,b,c,d) = foo in ...
05:58:43 <ricebowl> how do you extend "class Foo r w | r -> w where" to 2 implied types?
05:59:00 <dcoutts> Stinger_, or case foo of (a,b,c,d) -> ...
05:59:05 <ricebowl> can always use fst and snd on 2-tuples
05:59:08 <ricebowl> @type fst
05:59:09 <lambdabot> forall a b. (a, b) -> a
05:59:12 <Saulzar> ricebowl, r -> w, r -> x
05:59:17 <ricebowl> ah, ok, thanks
05:59:36 <Stinger_> ok cool I'll take a look at those
05:59:39 <malcolm> also r -> w x
06:00:35 <ricebowl> @eval fst (1, 2)
06:00:49 <ricebowl> > fst (1, 2)
06:00:50 <lambdabot>  1
06:00:52 <lambdabot>  1
06:01:05 <ricebowl> > map fst [(0, 'a'), (1, 'b'), (2, 'c')]
06:01:06 <lambdabot>  [0,1,2]
06:01:10 <ricebowl> > map snd [(0, 'a'), (1, 'b'), (2, 'c')]
06:01:11 <lambdabot>  "abc"
06:01:26 <seba> dcoutts, how can I calculate all permutations?
06:02:41 <dons> dcoutts: hey.
06:03:04 <dcoutts> dons, hia, I thought I had a fix
06:03:32 <dcoutts> now I'm still getting QC failures, though only when using prop-compiled
06:03:39 <jethr0> > sequence [[1,2,3], [3,4,5]]
06:03:40 <lambdabot>  [[1,3],[1,4],[1,5],[2,3],[2,4],[2,5],[3,3],[3,4],[3,5]]
06:03:43 <jethr0> that's combinations
06:03:44 <dcoutts> just checking again in case I'm just doing something silly
06:03:46 <dons> oh, dcoutts, perhaps make clean?
06:03:49 <dons> could just be an old binary.
06:04:00 <dcoutts> it did compile it
06:04:19 <dcoutts> you did add -no-recomp in the Makefile for just that reason :-)
06:04:28 <dons> ah, i did did i. sounds like a good idea.
06:05:08 <dcoutts> dons, have you noticed that concatMap is unreasonably slow?
06:05:15 <dons> do you have a solution that doessn't involve a memmove? or was the issue something else?
06:05:26 <dons> yeah, its slow. haven't chased it too closely
06:05:29 <dcoutts> yes, no memmove required
06:05:39 <dons> ok good.
06:05:55 <dcoutts> we just return the offset and length to the wrapper
06:06:01 <dons> ok. good.
06:06:21 <dcoutts> so when the wrapper reallocs it just does (destPtr `plusPtr` destOffset)
06:06:27 <dons> cool.
06:06:35 <dcoutts> and then in sequenceLoops we take the offsets into account too
06:06:44 <dcoutts> sequenceLoops loop1 loop2 src dest len0 = do
06:06:44 <dcoutts>   (acc1, off1, len1) <- loop1 src dest len0
06:06:44 <dcoutts>   (acc2, off2, len2) <- let src'  = dest `plusPtr` off1
06:06:44 <dcoutts>                             dest' = src' -- note that we are using dest == src
06:06:44 <dcoutts>                                          -- for the second loop as we are
06:06:46 <dcoutts>                                          -- mutating the dest array in-place!
06:06:48 <dcoutts>                          in loop2 src' dest' len1
06:06:50 <dcoutts>   return ((acc1  :*: acc2), off1 + off2, len2)
06:06:57 <dons> we should add some properties to also check the results of fusion, i think. not just the rewrite rules.
06:07:04 <dcoutts> yes
06:07:22 <dons> so that, say, map . filter {- fused -} == List.map . List.filter
06:07:35 <dcoutts> probably a seperate file so we can compile without -frules-off
06:07:40 <dons> it would have to be in another properties file though,. 
06:07:41 <dons> yes.
06:08:22 <dons> have you noticed that ghc takes an unreasonable time to compile Properties.hs ?
06:08:27 <dcoutts> yes
06:08:37 <dcoutts> especially since you use -O2 -optc-O2 :-)
06:08:49 <dons> inline wacky fun :)
06:08:53 <dcoutts> we've got very compact code there
06:09:08 <dcoutts> and it's a large file 1700 lines
06:09:19 <dons> yeah, that's a big static data list too.
06:09:45 <dcoutts> oh btw I'm splitting that into sections to make testing quicker
06:10:02 <dcoutts> I got tired of waiting for concatMap when all I want is the fusion rules :-)
06:10:22 <dcoutts> tests = misc_tests ++ bl_tests ++ ... etc
06:11:42 <dons> cool. can we provide an arg to switch between  them?
06:11:54 <dcoutts> I'm using ghci atm
06:12:02 <dons> wow. 3 mins later, Properties.hs i still compiling
06:12:04 <dcoutts> but with it compiled
06:12:07 <dons> /i/is/
06:12:11 <goron> Do you ever first implement something with a very wrong datastructure (e.g. list) and when it works convert it to something which use efficient data structures, or do you do the right thing from the start?
06:12:12 * dcoutts took off the -O2
06:12:18 <Taldor> I'm trying to install hsSDL, but I get an error: 'Could not find module `Distribution.Simple''. How do I get that module?
06:12:27 <dcoutts> goron, often start with simple
06:12:38 <dcoutts> goron, and then optimise later when the algorithm is right
06:12:43 <dons> dcoutts: I add the -O2, when I noticed some properties failed only with optimisation on.
06:12:53 <dons> i.e. like that inlining issue.
06:13:01 <dcoutts> dons, ah, -O should be enough though right?
06:13:08 <dcoutts> oh, hmm I see
06:13:14 <dcoutts> fair enough
06:13:26 <dcoutts> so we should use -O2 at least occasionally
06:13:28 <dons> you get -Onot with ghci anyway.
06:13:40 <dcoutts> not if you compile the thing first
06:13:45 <dons> yeah, 'gmake everything' should run the lot. good to do every couple of days.
06:13:47 <dons> ah, trrue..
06:13:53 <goron> dcoutts: I was just wondering whether I was the only one doing it that way. Thanks
06:14:05 <dons> huh, ghc-6.4.2: out of memory (requested 2097152 bytes)
06:14:06 <dcoutts> goron, I'm sure everyone does it :-)
06:14:13 <dcoutts> hah hah
06:14:17 <dons> dcoutts: i couldn't even get Properties.hs compiled that time..
06:14:36 <dcoutts> +RTS -Hhugem -RTS
06:14:40 <goron> dcoutts: Well, with something that's already known of how to do, I would guess it's possible to do it right from the start. 
06:14:48 <dcoutts> goron, sure
06:16:50 <jethr0> have you guys seen spirit [http://spirit.sourceforge.net/]? it's a parser combinator library for c++ :)
06:17:08 <dons> huh.
06:17:43 <Stinger_> whats a quick way to get an inf list of a single value? (that isnt ridiculously complicated ;) ) 
06:17:49 <goron> jethr0: Yep, but I don't think it does the same grammars as Parsec.
06:17:57 <dons> > repeat ()
06:18:06 <lambdabot>  [(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),()
06:18:06 <lambdabot> ,(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),
06:18:06 <lambdabot> (),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(
06:18:06 <lambdabot> ),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),()
06:18:09 <lambdabot> ,(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),(),
06:18:12 <lambdabot> [6 @more lines]
06:18:25 <jethr0> goron: i don't know. but i sure as hell will try to stay clear of c++ in the future anyhow
06:18:31 <dons> Stinger_: quick and not complicated enough?
06:18:46 <Stinger_> quite :)
06:19:00 <jethr0> > take 20 $ fix (3:)
06:19:02 <lambdabot>  [3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3]
06:19:16 <dons> jethr0 wins
06:19:23 <jethr0> *yeah*
06:19:28 <Stinger_> whats the $ do
06:19:30 <dons> in brevity, at least :)
06:19:38 <dons> ?type ($)
06:19:39 <lambdabot> forall b a. (a -> b) -> a -> b
06:20:03 <jethr0> > take 20 (fix (3:))
06:20:04 <lambdabot>  [3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3]
06:20:04 <dons> its an application operator, with lower precedence,, so you can avoid a lot of parens
06:20:35 <dons> > let f # x = f x in take 20 # fix (3:)
06:20:36 <lambdabot>  [3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3]
06:20:36 <Stinger_> oh, interesting
06:21:31 <dons> isn't haskell great fun?
06:22:04 <Stinger_> well, it might be when I figure out what the hell is going on heh
06:24:23 <resiak> Hmm, any examples of functions to apply fix to which will give a terminating expression?
06:24:53 <goron> I wish there was SLIME for Haskell.
06:25:07 <jethr0> > fix (\f x -> if x > 3 then 4 else f (x+1)) 1
06:25:08 <lambdabot>  4
06:25:30 <resiak> oh of course, you can apply `fix f' to something else
06:26:02 <goron> > :t fix
06:26:02 <lambdabot>  Parse error
06:26:04 <int-e> fix (const foo)
06:26:10 <resiak> @type fix
06:26:11 <lambdabot> forall a. (a -> a) -> a
06:26:11 <goron> @type fix
06:26:12 <lambdabot> forall a. (a -> a) -> a
06:28:50 <jethr0> > fix (\f n -> if n <= 0 then 1 else n * f (n-1)) 6
06:28:51 <lambdabot>  720
06:28:56 <goron> > (fix id) 1
06:28:57 <lambdabot>  Add a type signature
06:28:58 <int-e> fix (\ ~(a,b,c) -> (2,a*3,b+6)) -- look, a simple calculation with intermediate results :)
06:29:01 <int-e> > fix (\ ~(a,b,c) -> (2,a*3,b+6)) -- look, a simple calculation with intermediate results :)
06:29:02 <lambdabot>  Unterminated end-of-line comment
06:29:10 <dons> oh, that's interesting.
06:29:23 <jethr0> yup, that's occurred since the last patch
06:29:37 <dons> ah, that's the Language.Haskell parser being screwy
06:29:42 <dons> > 1+2 -- test
06:29:43 <lambdabot>  Unterminated end-of-line comment
06:29:46 <dons> bah
06:29:50 <xerox> > -- comment
06:29:50 <lambdabot>  Unterminated end-of-line comment
06:29:54 <dons> > 1+2 {- test -}
06:29:55 <lambdabot>  3
06:29:55 * int-e comforts dons
06:29:59 <jethr0> > take 20 $ fix (\ ~(a,b,c) -> (2,a*3,b+6))
06:30:00 <lambdabot>  Couldn't match `[a]' against `(a1, b, c)'
06:30:01 <int-e> > fix (\ ~(a,b,c) -> (2,a*3,b+6))
06:30:02 <lambdabot>  (2,6,12)
06:30:05 <Stinger_> hmm can only zip together 2 lists :(
06:30:06 <xerox> Uh.
06:30:09 <dons> stupid  Language.Haskell parser :/
06:30:19 * dcoutts starts compiling Properties.hs again and goes for a cuppa tea
06:30:32 <jethr0> Stinger_: there's higher-ary zips in data.list
06:30:36 <xerox> > fix (\(a,b,c) -> (2,a*3,b+6))
06:30:36 <int-e> dons: can you parse   expression++"\n"?
06:30:36 <ricebowl> @type zip3
06:30:37 <lambdabot>  Terminated
06:30:38 <lambdabot> forall c b a. [a] -> [b] -> [c] -> [(a, b, c)]
06:30:42 <dons> dcoutts: i managed to get it compiled with the works on a 16G machine.
06:30:47 <Stinger_> ah cool, tz
06:30:52 <Stinger_> ta*
06:30:52 <ricebowl> > zip3 [0, 1, 2] ['a', 'b', 'c'] [True, False, True]
06:30:53 <lambdabot>  [(0,'a',True),(1,'b',False),(2,'c',True)]
06:30:57 <dons> int-e, yeah, i should add a \n, you think?
06:31:01 <dcoutts> dons, hah ha
06:31:08 <dcoutts> dons, 16G !?
06:31:13 <int-e> dons: I'd try it. I don't know if it works.
06:31:19 <dons> but it just thrashes my laptop and heats up the room
06:31:28 <dons> dcoutts: yeah, big university server
06:31:46 * int-e ponders getting his own lambdabot but doesn't really feel like it.
06:31:56 <dons> int-e, i'll have a quick peep at the src.
06:32:22 <xerox> int-e - How does your fix (\~x -> x) work?^
06:32:27 <int-e> > 1 {- this works, I hope? -}
06:32:28 <lambdabot>  1
06:33:24 <int-e> xerox: it's equivalent to let (a,b,c) = (4,a*2,b+3) in (a,b,c) ... and that doesn't answer your question
06:34:18 <dons> adding \n doesn't help out the silly-billy parser
06:34:33 <dcoutts> dons, well I'm glad I added that extra 1Gb to my desktop box :-)
06:34:38 <dons> heh
06:35:06 <dons> ok, so you're on top of that down loop issue?
06:35:10 <dcoutts> if I had been feeling richer I'd have swapped for a dual core cpu too :-)
06:35:33 <dcoutts> dons, yeah, still tracking down some foo/down loop test failures
06:35:41 <dcoutts> though down/down seems to work now
06:35:53 <dons> ok. make sure to check down-fuse.hs in ghci
06:36:04 <dcoutts> that works
06:36:07 <dons> it produced clear, strange results when things didn't work.
06:36:12 <dcoutts> that was the first one I tried
06:36:17 <dons> ie. g k s returned different stuff each time
06:36:24 <dons> ok.
06:36:41 <int-e> xerox: let v = (4,a*2,b+3), a = (\(a,_,_) -> a) v; b = (\(_,b,_) -> b) v; c = (\(_,_,c) -> c) v  is close to how its actually implemented, as far as I understand it.
06:36:46 <dons> well, bedtime for me then. 
06:36:55 <dcoutts> ok, g'night dons 
06:36:55 <dons> night guys.
06:36:56 <xerox> int-e - ah-ha!  Neat.
06:37:01 <xerox> Goodnight donnie.
06:37:37 <dons> :S night paolini (slightly insulting?)
06:37:52 <dcoutts> heh
06:38:05 <dcoutts> little Paolo ;-)
06:38:16 <int-e> xerox: so a black hole is created for the tuple v, then the thunks for a, b and c are created; they aren't forced before the black hole for the tuple has been filled with the tuple (and black holes for its 3 values) so in the end everything works without running in cycles.
06:38:33 * dons tries to come up with a diminutive form of paolo
06:38:47 <int-e> xerox: For most purposes it's probably ok to treat it as black magic.
06:39:11 <dcoutts> dons, paoloisimi?
06:39:47 <xerox> "poli" is how they call me (-:
06:39:54 <dcoutts> nice :-)
06:39:56 <dons> ah, very nice.
06:40:03 <xerox> (They got it from ... The Godfather? Dunno.)
06:40:12 * dcoutts shan't share his diminutive nickname
06:40:24 <xerox> Duck ? (:
06:40:31 <xerox> Dookie
06:40:37 <dcoutts> heh
06:40:38 <xerox> Dun!
06:40:41 <xerox> Dunno :)
06:40:47 <dons> oh dear.
06:40:50 <xerox> (And that wasn't meant as nickname :P)
06:41:05 * dcoutts wonders what he's started
06:41:11 <int-e> Oh dear? now that's an interesting nick. How'd you end up being called that?
06:41:35 <xerox> Love.
06:41:41 <dcoutts> hah
06:42:10 <xerox> So so what's yours, dunky? (:
06:42:32 * dcoutts keeps quiet
06:42:41 <xerox> Pfft.
06:42:46 <dcoutts> :-)
06:43:04 <dcoutts> xerox, that's not the worst ;-)
06:44:26 <xerox> A linguist made an Haskell tutorial for a .it site (in Italian), it *doesn't*make*any*sense* ):
06:44:55 <ricebowl> grammatically, or?
06:45:05 <xerox> Do you believe me if I say: both.
06:45:55 <xerox> It's more a show-off of periphrases, than an introduction to Haskell.
06:45:58 <int-e> maybe he made up his own language?
06:46:07 <ricebowl> paraphrases, you mean?
06:46:21 <xerox> I tried do write the plural of periphrasis.
06:46:49 <xerox> int-e - http://www.siforge.org/articles/2006/03/22-hsintro.html
06:47:01 <ricebowl> paraphrase, paraphrases... at least I'm pretty sure that's what you mean
06:47:16 <ricebowl> is periphrasis the Italian word for it?
06:47:25 <xerox> ricebowl - It's not paraphrase what I mean, it's periphrase.  In italian they are distinct words too.
06:47:37 <ricebowl> never heard of a periphrase
06:48:03 <xerox> http://en.wikipedia.org/wiki/Periphrasis
06:48:30 <psi> @dict periphrasis
06:48:30 <lambdabot> Supported dictionary-lookup commands:
06:48:31 <lambdabot>  @all-dicts @devils @easton @elements @foldoc @gazetteer @hitchcock @jargon @lojban @vera @web1913 @wn @world02
06:48:31 <lambdabot> Use "@dict-help [cmd...]" for more.
06:48:40 <xerox> @wn periphrasis
06:48:42 <lambdabot> *** "periphrasis" wn "WordNet (r) 2.0"
06:48:42 <lambdabot> periphrasis
06:48:42 <lambdabot>   n : a style that involves indirect ways of expressing things
06:48:42 <lambdabot>    [syn: {circumlocution}, {ambage}]
06:48:42 <lambdabot>   [also: {periphrases} (pl)]
06:48:49 <xerox> That.
06:49:13 <ricebowl> I don't see the difference
06:49:20 <xerox> @wn paraphrasis
06:49:21 <lambdabot> *** "paraphrasis" wn "WordNet (r) 2.0"
06:49:22 <lambdabot> paraphrasis
06:49:22 <lambdabot>   n : rewording for the purpose of clarification [syn: {paraphrase}]
06:49:37 <ricebowl> ok, if paraphrase is a synonym, then they are the same
06:49:38 <xerox> The periphrasis doesn't clearify.
06:49:47 <xerox> Well, in this case.
06:50:11 <psi> they are the opposite of each other, I guess
06:50:20 <xerox> I think so too.
06:50:39 <xerox> Well, if not the opposite, they have opposite semantic flavour.
06:51:36 <ricebowl> a paraphrase is a rephrasing of a word or phrase to clarify meaning...Wikipedia seems to imply that for periphrasis, although it isn't entirely clear
06:52:00 <int-e> xerox: I only understand the code examples which make it hard to believe that people could code anything meaningful in Haskell after reading that text.
06:52:09 <psi> "The use of more words than are necessary to express the idea" - The Collaborative International Dictionary of English
06:52:23 <int-e> xerox: not to mention that there's a mistake in at least one of them.
06:52:35 <ricebowl> it appears to come from Latin "paraphrasis"
06:52:40 <xerox> Yes, int-e.  He doesn't make one damn point.
06:53:12 <xerox> int-e - The subtlety of exemplification of map with |map (...) [1]| explains it well.
06:53:27 <ricebowl> uh?
06:53:35 <ricebowl> only mapping over one element...?
06:53:59 <xerox> That's the mood of the article.
06:54:07 <ricebowl> I don't see why existing English tutorials wouldn't simply be translated
06:54:36 <xerox> I never saw an introduction to Haskell that tells you FIRST that "You sum with +, multiply with * and compare with <, >, ==, /=."
06:54:48 * int-e was surprised by that, too.
06:55:02 <ricebowl> maybe if it's aimed at people who have never programmed before *shrug*
06:55:04 <xerox> "Hereditariety operator: =>"
06:55:06 <xerox> o_O
06:55:07 <int-e> I mean, you can give a few examples but you don't really get far without mentioning some basic types.
06:55:10 <ricebowl> lol
06:55:23 <ricebowl> I've got another problem that I could use some help with, BTW
06:55:32 <xerox> Yes, I made a comment, I hope they'll read it so we can abolish it and put up some pertinet introduction.
06:55:36 <ricebowl> I have a type called Memory which...represents memory
06:55:44 <ricebowl> or more specifically an address computation
06:55:50 * int-e notes that the word 'Num' does not appear in the text.
06:55:53 <ricebowl> and I want to generalize it as I was doing the registers earlier
06:56:05 <int-e> xerox: oh, and the Test class is just great.
06:56:09 <ricebowl> the problem is that it lacks any associated size
06:56:24 <ricebowl> so I don't know whether I'm reading 8-bits, 16-bits, or 32-bits
06:56:35 <xerox> int-e - Hell yeah.  It is so simple to explain typeclass with (+), "you can't sum up everything, you sum up nums."
06:56:47 <ricebowl> to solve, I did newtype Mem8 = Mem8 Memory; newtype Mem16 = Mem16 Memory; etc.
06:56:51 <xerox> Why call it Test ?
06:57:16 <int-e> dunno. explaining Num would be a good idea. it does pop up in error messages.
06:57:31 <ricebowl> Memory has type Memory (Maybe Reg32) (Maybe (Reg32, Int)) (Maybe Int)
06:57:33 <xerox> Yes, that's what I start with firstly all the times.
06:57:40 <int-e> but of course beginners don't make mistakes. they look at the examples, gasp in awe and give up.
06:57:43 <ricebowl> it's actually 7 cases rather than the maybes, but it's easier to give it that way
06:58:23 <ricebowl> I don't want to dissect the Memory structure for each instance of my class, so I created a general function called readmem to do it
06:58:29 <xerox> In fact the very first thing I explain is the substitution model with ones = 1 : ones or evens = 0 : map (+1) odds; odds = map (+1) evens, depending on the public :-)
06:58:40 <ricebowl> but then I have no way to tell GHC which instance of the class I want because I've lost my type information
06:59:17 <ricebowl> help :S
06:59:45 <xerox> ricebowl - What's up with all those Maybes?
07:00:27 <ricebowl> well, x86 address computations take the general form of [base+index*scale+disp] where different fields can be omitted
07:00:38 <ricebowl> e.g. you can have [base] or [base+disp] or [index*scale] or ...
07:01:13 <ricebowl> I don't actually use Maybe for that, I a case for each, but it's easier to explain it with Maybe
07:01:18 <ricebowl> +use
07:01:50 <int-e> err, what do you want to *do*?
07:02:05 <ricebowl> hmm, let me paste some code and then try to explain
07:02:11 <ricebowl> the pastebin seems to be down though...?
07:04:55 <int-e> ricebowl: is the problem that neither the arguments nor the result type of the function depend on the class that you mentioned (whatver its purpose)?
07:06:07 <ricebowl> yes, exactly
07:07:47 <ricebowl> http://www.rafb.net/paste/results/PZu5r242.html <-- here's the paste, though it's a bit lengthy. With the X86Reg class, I can generalize reading and writing registers in my X86Cxt datatype
07:08:30 <ricebowl> I want to do the same thing with X86Mem. The thing is that I have to pull apart the structure (see rdmem32), and I don't want to keep rewriting that code
07:09:05 <ricebowl> as a result, neither the arguments nor the result depend on the class
07:15:28 <mnvl> hi there, does anyone know what the ubuntu package name for the haskell compiler is?
07:15:29 <int-e> ricebowl: ok, add a dummy argument then whose sole purpose is to determine the class. f :: Class x => x -> <rest of functions>
07:16:11 <int-e> ricebowl: in the function you can play with explicit type annotations or `asTypeOf`
07:16:30 <int-e> ricebowl: and then you can define convenience wrappers that pass in the correct dummy argument.
07:16:38 <ricebowl> *nods*
07:17:05 <ibid> mnvl: the debian package is ghc6, i suspect ubuntu uses the same name
07:17:23 <ricebowl> I was thinking that another possibility would be to do the dissection in another function and either return Maybe Int32 or pass it a function to invoke
07:17:34 <ibid> mnvl: of course, there is no *the* haskell compiler, this is one of the possibilities, the most popular one
07:17:57 <int-e> whatever invoke is :P
07:18:06 <ricebowl> apply or whatever, I'm tired...
07:18:13 <mnvl> thanx ibid. it's not working right now but i think i still need to add community repositories
07:18:44 <ibid> mnvl: i'd assume it's in universe
07:30:23 <jethr0> > [] `asTypeOf` "hello world"
07:30:24 <lambdabot>  ""
07:37:02 <vincenz> > "" `asTypeOf` "Jethr0"
07:37:03 <lambdabot>  ""
07:37:58 <int-e> asTypeof == id `asTypeOf` const ;-)
07:38:04 <int-e> err, sorry.
07:38:09 <int-e> const `asTypeOf` id
07:39:32 <Stinger_> is there a simple way to get make an Ord instance for a custom data type
07:39:52 <Stinger_> specifically data ATMMode = CBR | VBR | ABR | UBR
07:39:57 <vincenz> deriving (Ord)
07:39:57 <Lemmih> Stinger_: You can derive Ord.
07:40:01 <int-e> data ... deriving (Eq, Ord)
07:40:22 <Stinger_> will that just do it all automagically?
07:41:58 <int-e> yes. although the resulting order might be different from what you want
07:42:45 <Stinger_> I just want left greatest to right least
07:42:50 <vincenz> hiya Lemmih 
07:42:56 <vincenz> Lemmih: seen Oejet ?
07:43:06 <int-e> hmm it does left least to right greatest I believe.
07:43:23 <Lemmih> vincenz: Oejet is in #haskell_ru, #haskell-blah and #haskell. I don't know when Oejet last spoke.
07:43:24 <vincenz> int-e: yep
07:43:27 <Stinger_> actually I might even want it that way come to think of it
07:43:30 <vincenz> Lemmih: :D
07:43:33 <int-e> but you can just reorder the constructors to match that.
07:43:38 <vincenz> Lemmih: thank you lemmi'ngsbot
07:43:56 * vincenz palmslaps
07:52:16 <vincenz> anyone know what the < symbol with inward curved dashes means in typing papers
07:52:45 <hyrax42> hmm?
07:53:10 <Igloo> Subtype, possibly. Hard to say without context
07:53:28 <vincenz> Generalizing Hindley-Milner Type Inference Algorithms
07:53:32 <vincenz> that's the paper I'm reading
07:53:39 <vincenz> if you happen to know it
07:53:43 <dcoutts> vincenz, I think it's a instance of a type scheme
07:53:48 <vincenz> t < context(x)
07:53:50 <vincenz> --------
07:53:52 <vincenz> x:t
07:53:55 <dcoutts> yep
07:54:15 <dcoutts> oh, hmm
07:54:20 <vincenz> so why prefer the more specific thingy?
07:54:20 <dcoutts> what page?
07:54:22 <vincenz> 4
07:54:23 <vincenz> top
07:54:50 <Stinger_> cellcompare :: (Ord a) => (Ord c) => (a,b,c) -> (a,b,c) -> Ordering     whats the correct way of doing this? (if you can figure out what I'm trying to do)
07:54:52 <vincenz> I find it odd they choose a type that's in some sense smaller
07:54:54 <Igloo> "the more specific thingy"?
07:55:04 <vincenz> t < Context(x)
07:55:13 <dcoutts> œÑ < Œì(x)
07:55:32 <vincenz> tau < L_invert(x)
07:55:33 <Igloo> It means that if x :: forall a . a -> a in the env then you are allowed to derive x :: Int -> Int, say
07:55:33 <arjanb> Stinger_: (Ord a, Ord c) =>
07:55:44 <Stinger_> hmm I coulda sworn I tried that
07:55:44 <vincenz> ah
07:56:00 <Igloo> i.e. Int -> Int < forall a . a -> a
07:56:03 <vincenz> why can't they put their explanation on symbols in these papers
07:56:05 <dcoutts> that the type t is a instance of the type scheme
07:56:09 <vincenz> yep
07:56:15 <vincenz> thx
07:56:15 <dcoutts> yeah, I noticed that one was missing
07:56:33 <dcoutts> it explains al its other notation except for that one I think
07:56:46 <Stinger_> guess not, thanks arjanb 
07:58:40 <Igloo> Presumably just got overlooked
07:59:31 <vincenz> possibly
07:59:39 <vincenz> or assumed to be known
07:59:43 <vincenz> which is more typical
08:04:37 <vincenz> dcoutts: if I read it correctly, that table is meant purely bottom up from a syntactic point of view?
08:05:03 <dcoutts> vincenz, you mean Figure 1 ?
08:05:05 <vincenz> yep
08:05:28 <dcoutts> yes, it's can be done as a bottom up syntactic check
08:05:40 <dcoutts> but only if you've already got the type annoations!
08:05:50 <dcoutts> the inference process is more complex
08:06:18 <dcoutts> the inference can be done bottom up or top down
08:07:10 <vincenz> ah yep so it states about M_funky and W_funky
08:08:00 * vincenz wishes he had done CS
08:09:21 <vincenz> hmm funky
08:09:31 <vincenz> W_funky is supposed to be bottom_up
08:09:39 <vincenz> but rule 1 in figure 2 makes no sense if the context is empty
08:09:41 <dcoutts> they don't often teach HM type inference in CS, it's more graduate level
08:10:00 <vincenz> dcoutts: well I could've used a bit more courses using formal notation
08:10:12 <dcoutts> ah yeah, that helps
08:10:43 <dcoutts> typeing judgements are so nice :-)
08:10:58 <psnl> dcoutts: I learnt it as an UG, and a easy type inferance question was on the exam
08:11:01 <vincenz> dcoutts: mind explaining rule 1 on figure2?
08:11:05 <dcoutts> sometimes you can read an algorithm right off them
08:11:22 <vincenz> dcoutts: it's bottomup, so if you start with "x" wouldn't the context be empty?
08:11:24 <dcoutts> psnl, UG? 
08:11:31 <vincenz> under-grad?
08:11:43 <dcoutts> psnl, you don't mean a attribute grammar?
08:12:26 * vincenz had issues in the past as well reading books on formal semantics, it's one thing to read them, but the proofs are so finegrained you often don't see the point, and then you get completely stuck in the excercise section where they ask you to prove something
08:13:35 <vincenz> W(L,x) = ([], instantiate(tau)) where (x:tau) elof L    --- makes no sense in bottomup, the context will be empty
08:14:06 <dcoutts> vincenz, I'm not quite sure why they call it botom up, the substituion comes bottom up but the type env goes down
08:14:13 <vincenz> ah
08:14:16 <psnl> dcoutts: Undergrad, and the question read "infer the type of <long expression>"
08:14:18 <vincenz> that might explain something
08:14:23 <dcoutts> that's why it's an input not an abotput
08:14:30 <vincenz> so it's start at top, then go down and use the results bottomup
08:14:41 <dcoutts> psnl, ah ok, but that's not quite the same as a type inference algorithm
08:14:54 <dcoutts> psnl, figureing out the types of stuff by hand isn't so hard
08:15:00 <dcoutts> you do it all the time when coding
08:15:15 <vincenz> dcoutts: and yeah I agree, with the proper monad, you can pretty much literally copy these algorithms from paper into haskell
08:15:26 <psnl> dcoutts: yeah, writing code to do it is quite something
08:15:38 <vincenz> :D
08:15:43 <vincenz> now imagine doing it in c
08:15:46 <dcoutts> vincenz, or even without a monad
08:15:56 <vincenz> dcoutts: well you need "fresh"
08:15:57 <dcoutts> vincenz, that Figure 2 is almost Haskell already
08:16:01 <dcoutts> ah that's true
08:16:35 <dcoutts> it's certainly possible to write declarative typing judgements that have no obvious evaluation order however
08:16:48 * vincenz is a bit pissed off, I was making this tool to simulate a model of mine, but i'm nearly inventing a new language :
08:16:51 <vincenz> :/
08:17:11 <dcoutts> vincenz, eg the let rec rule can throw you at first
08:17:19 <vincenz> hmm
08:17:28 <vincenz> where
08:17:36 <dcoutts> not in that paper
08:17:39 <dcoutts> it only does let
08:17:44 * psnl wonders how hard it would be to write a simple type-inferer
08:18:05 <vincenz> dcoutts: cause it requires a recursive declaration in the type-inferrer?
08:18:26 <dcoutts> psnl, see the paper we're talking about
08:18:37 <dcoutts> psnl, it's quite easy once you see how
08:18:43 <vincenz> AHA!!!
08:18:47 <vincenz> they define <= on page 6
08:18:53 <vincenz> well the curly one
08:19:04 <vincenz> bit late but oh well
08:20:21 <vincenz> type inference rests on the fact that types form a bottom-bounded lattice, no?
08:20:47 <vincenz> erm, top and bottom bounded
08:20:53 <vincenz> with 'alpha' being the top
08:21:08 <dcoutts> hmm
08:21:12 <vincenz> well forall alpha.alpha
08:24:24 <vincenz> dcoutts: mind if I ask another question regarding Fig2?
08:24:31 <dcoutts> go on
08:24:34 <vincenz> it concerns the APP rule
08:24:37 <vincenz> well there's no name stated
08:24:39 <vincenz> but e1 e2
08:24:52 <vincenz> why does the substution defined in e1 have any influence on e2?
08:25:23 <dcoutts> hmm
08:26:03 <vincenz> I'd think that scope-wise they're independent
08:26:10 <dcoutts> I'm not sure if it could be done the other way around
08:26:18 <vincenz> well just not use S1 in doing e2
08:26:31 <vincenz> the substitutions of e1 and e2 should be disjoint
08:26:36 <vincenz> erm, nonoverlapping
08:26:39 <dcoutts> why?
08:27:06 <vincenz> well if you define variables in e1 with some let or whatever
08:27:09 <vincenz> that won't be in scope in e2
08:27:18 <Igloo> What about variables already in scope?
08:27:31 <vincenz> isn't that what the mgu is for?
08:27:37 <vincenz> after the two subparts?
08:28:14 <dcoutts> the sustituion gets threaded linearly through the computation
08:28:19 * Igloo doesn't have the paper - mgu of the substitutions from the recursive calls on e1 and e2?
08:28:33 <vincenz> dcoutts: it makes no sense tho
08:28:37 <vincenz> why prefer e1 over e2
08:28:40 <vincenz> theyre independent
08:28:47 <Igloo> Or mgu of t1 = t2 -> alpha?
08:28:55 <dcoutts> archive.cs.uu.nl/pub/RUU/CS/techreps/CS-2002/2002-031.pdf
08:28:58 <Stinger_> hmm does someone want to explain to me how Maybe works? cause I think I may need it :P 
08:29:19 <dcoutts> vincenz, as I said it might be possible to do them in the other order
08:29:27 * vincenz nods
08:29:33 <Igloo> Right, that's not what the mgu is for
08:29:34 <vincenz> or why not having an order
08:29:59 <vincenz> Igloo: well I'd think it's more sensible you collect both substitutions separately and then combine
08:30:03 <dcoutts> vincenz, the substitution must get threaded through
08:30:08 <Igloo> It's harder to reason about if you do that
08:30:14 <dcoutts> vincenz, for an unordered one see the constaint solving system
08:30:14 <vincenz> hmm
08:30:29 <dcoutts> vincenz, the constraint colving version is much less ordered
08:30:36 <vincenz> yep planning on reading further :)
08:30:51 <dcoutts> vincenz, in that version the algorithm W corresponds to one fixed order for solving the constraints
08:31:18 <dcoutts> vincenz, the constraint solving version just imposes a couple simple restrictions on the order in which you can solve the constraints
08:31:27 <vincenz> I guess I have a hard time visioning the S's
08:31:33 <dcoutts> so you're probably right that those two are independent and could be reversed
08:31:41 <Igloo> Yes, they could
08:32:03 <dcoutts> the main restriction is that the binder of a let must be solved before the body
08:32:18 <vincenz> seems intuitive
08:32:50 <vincenz> I guess I just have an issue representing the L's and S's 
08:33:01 <dcoutts> the algorithm W just does it in that order so it's not clear if it's essential or not
08:33:03 <vincenz> I mean I know the type, but what they would contain
08:33:24 <dcoutts> the constraint solving version makes the solving order restrictions explicit
08:33:29 * vincenz nods
08:33:41 * vincenz continues reading into section 4
08:34:02 <dcoutts> by L you mean \gamma right?
08:34:05 <vincenz> yeah
08:34:17 <dcoutts> so \gamma is easier to understand
08:34:27 <dcoutts> it just maps program vars to types
08:34:30 <vincenz> right
08:34:34 <vincenz> but does it start full?
08:34:34 <dcoutts> or rather type schemes
08:34:35 <Stinger_> ok figured out the Maybe thing
08:34:52 <dcoutts> vincenz, it starts with all the free vars of the expression
08:35:17 <vincenz> pointing to?
08:35:22 <dcoutts> vincenz, ie all your library functions. For a closed expression then \gamma can be empty
08:35:24 <Igloo> Well, if it doesn't then type inference will fail  :-)
08:35:34 <vincenz> dcoutts: well yes, let will introduce more stuff into L
08:35:43 <dcoutts> vincenz, as will \x -> 
08:35:47 * vincenz nods
08:36:05 <dcoutts> S is hader to get an intuition about
08:36:26 <vincenz> it's typevar -> specific type
08:36:46 <dcoutts> right
08:36:51 <vincenz> just that the way they wrote the rules, it's hard to figure out when they actually add something
08:37:00 <vincenz> cause they pipe modifications straight into arguments of W
08:37:04 <vincenz> instead of return values
08:37:07 <dcoutts> so as we discover more and more about the shapes of types we get more refined substitutions
08:37:32 <dcoutts> so they're adding stuff in let and app
08:37:37 <vincenz> yep
08:37:41 <dcoutts> S1 o S2
08:37:53 <dcoutts> or rather the other way around
08:39:27 <vincenz> well that's just a unioning with preference to S2
08:39:34 <vincenz> I'm trying to figure out when they add specific stuff
08:39:41 <dcoutts> mm, ok but in let they're definately adding things
08:39:56 <dcoutts> er no
08:39:58 <dcoutts> I mean app
08:39:59 <vincenz> they're piping it straight into gamma
08:40:06 <dcoutts> adding in S3
08:40:10 <vincenz> yep
08:40:36 <Igloo> substitution composition isn't really a union as the second substitution can modify the mappings of the first
08:41:15 <vincenz> Igloo: I don't think so
08:41:16 <dcoutts> mgu doesn't get defined in this paper sadly
08:41:20 <vincenz> they're supposed to be idempotent
08:41:28 <dcoutts> vincenz, no it really can
08:41:35 <vincenz> so you acn have variables in the codomain?
08:41:46 <Igloo> vincenz: (y |-> z) o (x |-> y) = (x |-> z, y |-> z)
08:42:00 <vincenz> ah, I thought you werent allowed to have tyvars in codomain
08:42:20 <dcoutts> -- composition of substitution
08:42:20 <dcoutts> infixr 4 @@
08:42:20 <dcoutts> (@@) :: Substitution -> Substitution -> Substitution
08:42:20 <dcoutts> s1 @@ s2 = [ (x, substitute s1 t) | (x, t) <- s2 ] ++ s1
08:42:28 <Igloo> idempotent means you can't have the /same/ type variable in both domain and codomain
08:42:34 * vincenz nods
08:42:35 <vincenz> okies
08:42:44 <vincenz> I just wasn't sure that rule was generalized to no tyvars in codomain
08:42:52 <vincenz> afaik, palomer does typechecking without tyvars in codomain
08:43:22 <Igloo> I think you're wrong
08:43:22 <vincenz> now if I read figure 2 correctly, let automatically makes a parametric polymorphic x?
08:43:41 <vincenz> by the fact it uses generalize
08:43:56 <dcoutts> vincenz, right
08:44:10 <dcoutts> that's where we get let polymorphism from
08:44:21 <dcoutts> and why lambdas are not polymorphic
08:44:21 <vincenz> Igloo: so what was the restriction that philippa didn't agree with if you prenormalize in his sysem
08:44:32 * vincenz nods at dcoutts 
08:44:48 <vincenz> what if you tried the same trick with lambas?
08:45:01 <Igloo> I can't remember
08:45:09 <dcoutts> then it becomes undecidable
08:45:19 <dcoutts> I mean type inference becomes impossible
08:45:28 <vincenz> just throw in a generalize(S1(\gamma), tau2 -> beta)
08:45:41 <vincenz> oh
08:45:44 <dcoutts> you can still have a consistent type system with polymorphic lambda
08:45:49 <dcoutts> but you can't infer it
08:45:51 * vincenz nods
08:46:08 <vincenz> but... isn't "not-inferrable in theory" still possibly inferrable in practice
08:46:16 <vincenz> if you consider toplevel annotations
08:46:19 <dcoutts> it's possible with type annoations
08:46:25 <Igloo> Well, it would be decidable, because you'd have an algorithm for it. It just wouldn't implement the type system you'd specified
08:46:31 <dcoutts> and local inference
08:46:35 <dcoutts> Igloo, right :-)
08:46:43 <vincenz> Igloo: not sure what that maneas
08:46:45 <dcoutts> vincenz, spj has a paper on that I think
08:46:46 <vincenz> s/maneans/means
08:47:03 <Igloo> vincenz: Which bit?
08:47:15 <vincenz> Igloo: the facti t wouldn't implement the typesystem you specified
08:47:22 <vincenz> I mean the types returned would still have to obey the rules
08:47:28 <vincenz> an Int wouldn't become a bool
08:47:33 <dcoutts> vincenz, the point is you can certainly make your algorithm do that but it will not match any sensible type system
08:47:34 <Igloo> No they wouldn't
08:47:49 <Igloo> \x -> x could have type a -> b, which is not allowed by the rules
08:47:49 <vincenz> do you have an example?
08:47:54 <dcoutts> and it certainly wouldn't match the type sysetm you wanted :-)
08:48:26 * vincenz ponders
08:48:29 <vincenz> I'll think on that some more
08:48:33 <dcoutts> vincenz, you have to be really very cerful with this stuff because it can easily become undecidable
08:48:34 <vincenz> plan to read TAPL this week
08:48:36 <vincenz> I left it at work :/
08:48:44 <dcoutts> that's why everyone wants proofs of this stuff
08:48:48 <vincenz> yep
08:48:59 <dcoutts> because it's very subtle
08:49:11 <dcoutts> HM is on the cusp of decidability
08:49:22 <vincenz> but... what if something is not proveable but pragmatically still feasible
08:49:30 <vincenz> I mean can someone prove that the whole of GHC is correct?
08:49:32 <vincenz> (typewise)
08:49:43 <dcoutts> let is a form of lambda that is rectricted just enough so that we can make it polymorphic and still have decidable type inference
08:50:04 <dcoutts> vincenz, there are papers and proofs for most of the extensions to the ghc type system
08:50:12 <dcoutts> but not all and they do find bugs
08:50:33 <vincenz> even the -fallow-undecideable and -fallow-overlappinng
08:50:51 <dcoutts> -fallow-undecideable is easy to specifyI think
08:51:03 <dcoutts> it just isn't decidable!
08:51:18 <vincenz> yeah but still useful
08:51:26 <dcoutts> aye, sometimes
08:51:57 <vincenz> I mean there's nuclear explosion undecideable, and small tidbits that rarely occur and are easily fixed
08:55:44 * vincenz ponders
08:55:56 <vincenz> Anyways, gotta finish reading this and then think on how I want to make my little programming language 
08:56:12 <vincenz> I want to keep it as small as possible
09:00:16 <vincenz> hmm
09:00:26 <vincenz> figure 3 which is literally bottom up also suffers the same issue with variables
09:00:46 <vincenz> Ie, it assumes there's an assumption about a variable in A_curly
09:01:32 <vincenz> oh wait, nm
09:01:35 <vincenz> there's no vertical br
09:01:36 <vincenz> bar
09:02:55 <vincenz> dcoutts: does the system presented in that paper extend to typeclasses?
09:03:10 <dcoutts> not so easily
09:03:16 <dcoutts> read THIH for that
09:03:19 * vincenz nods
09:03:29 <vincenz> I'll reread it :D
09:04:57 * vincenz presumes that all variables have a unique name in the system given by this paper
09:05:22 <dcoutts> ?
09:05:37 <vincenz> figure 3, page 6
09:05:40 <Igloo> You can choose a new name or a repeated name as you wish
09:06:03 <vincenz> cause in the end you will get a set of assumptions regarding variable names
09:06:11 <vincenz> let x = ... in let x = ... in ...
09:07:08 <dcoutts> no, look at the A1 ‚à™ A2 \x
09:07:28 <dcoutts> same for abs
09:08:02 <vincenz> hmm
09:08:06 <vincenz> which means that once you reach the top
09:08:11 <vincenz> you'll only have assumptions about freevars
09:08:26 <vincenz> would be nicer if you kept the assumptions regarding vars in program
09:08:38 <vincenz> so you know the types of the variables postcheck
09:13:34 <vincenz> mm
09:14:26 <vincenz> apparently to find the set M for <=_M  it's necessary to do a top-down analysis, while type-inference works bottom-up... how do you unify these two approaches such that the variables generated in the type-inference(fresh) and those generated in the top-down analysis match
09:15:30 <vincenz> I take it's another top-down context, bottom-up analysis system
09:15:32 <vincenz> like W-funky
09:16:05 <vincenz> with this time the context being the set M of monomorphic type-variables
09:16:09 <vincenz> ?
09:24:51 <vincenz> "These properties hold because the only generic instance of a
09:24:53 <vincenz> type is the type itself"
09:24:54 <vincenz> ??
09:24:55 <lambdabot> Maybe you meant: . v
09:25:35 <dvorak> hrm, anyone built ghc 6.4.2 under cygwin?
09:29:34 <SamB> why would anyone build a release version themselves on Windows?
09:29:47 <dvorak> because there isn't a cygwin binary
09:29:54 <SamB> oh
09:30:29 <SamB> is there a mingw binary?
09:30:38 <dvorak> I think so
09:30:58 <SamB> can you even build GHC two different ways on Windows?
09:31:47 <SamB> I mean, those two different ways?
09:32:07 <dvorak> well, from the docs, it appears that building it on cygwin is supposed to work
09:32:23 <dvorak> but it dies trying to do a huge link pretty early on because the unix package isn't available
09:32:36 <dvorak> I commented out the -package unix line for now
09:32:38 <SamB> maybe building on Cygwin gives you a MingW binary?
09:32:42 <dvorak> seems to be getter futher
09:33:05 <SamB> did configure detect all the things you need?
09:34:42 <dvorak> looks to
09:35:00 <dvorak> the problem I think is that the windows native binary doesn't provide a unix package, for obvious reasons
09:35:12 <dvorak> but configure thinks there should be one available
09:35:17 <SamB> huh.
09:36:09 <SamB> I have no clue about building on windows -- but I seem to remember something about the windows version being only available in MingW binaries, even if it *does* have to built with Cygwin...
09:36:19 <SamB> or was that MinGW
09:36:25 * SamB should just use lowercase
09:37:14 <dvorak> yeah, that's my understanding also
09:38:07 <Igloo> What's wrong with http://www.haskell.org/ghc/download_ghc_642.html#windows ?
09:38:25 <vincenz> Igloo: why the @?
09:38:31 <Igloo> Oh, that's mingw and you want cygwin?
09:38:32 <dvorak> I'd reather have a cygwin binary is all
09:38:35 <dvorak> right
09:38:36 <SamB> so, it stands to reason that you might as well use the mingw binary, since you'd pretty much end up with that anyway ;-)
09:38:39 <Igloo> Last I heard only one worked
09:39:14 <dvorak> well, the information I've found so far indicates that cygwin should work, it's just not provided since cygwin is a moving target
09:39:27 <dvorak> the problem seems to be how to bootstrap it
09:39:27 <Igloo> vincenz: I've left it on since people were saying they didn't know who were ops when there were troublemakers around
09:39:58 <SamB> Igloo: not a bad idea
09:40:08 <vincenz> :)
09:40:35 <vincenz> make lambdabot op and give him a spam-detection algo
09:40:40 <SamB> and its not like Igloo is very intimidating ;-)
09:40:58 <dcoutts> dons, all fixed now. It's all -O sharing issues.
09:41:38 <Igloo> dvorak: http://hackage.haskell.org/trac/ghc/wiki/Contributors says "port bitrotted"
09:43:35 <dvorak> ah well, good to know I guess
09:44:02 <SamB> they should at least build GHC for Cygwin at release time, if there is supposed to be a port, just to make sure it still works...
09:44:43 <Igloo> SamB: But they know it doesn't work...
09:47:44 <vincenz> Igloo, dcoutts: So are toplevel definitions in haskell lambda-defs or recursive letbindings?
09:47:46 <SamB> well, should have been building it, then!
09:47:56 <Igloo> Recursive let bindings
09:48:06 <vincenz> why the monomorphic restriction then?
09:48:33 <Igloo> The rationale for the MR is in the H98 report
09:48:47 <newsham> hi
09:48:52 * vincenz nods
09:50:21 <dcoutts> vincenz, the MR is independent of the letrec question
09:51:00 <Igloo> Well, if top level bindings were lambda-bound then they would already be monomorphic so there would be no need for a MR
09:51:14 <vincenz> right
09:58:21 <vincenz> dcoutts: which do you find more interesting in that paper?  SOLVE or the typegraph approach
09:59:10 <dcoutts> vincenz, the solve bits in the first half of the paper
09:59:26 <vincenz> dcoutts: for the constraint based system
09:59:36 * vincenz skipped the proof-sections
09:59:41 <vincenz> but section 6 is interesting
10:04:02 <dcoutts> vincenz, it's great for givign good type error messages
10:04:09 <vincenz> yep
10:04:20 <vincenz> could be neat if there was some heuristic to lay it out nicely
10:04:27 <vincenz> so you can literally visualize em
10:04:47 <vincenz> and then as you hover your mouse over it, show which part of an expression it's referring to
10:06:52 * vincenz whistles "2 hours to read that paper" after calculating out my breaks
10:08:06 <psnl> aah, but do you really understand it?
10:08:10 <vincenz> yp
10:08:11 <vincenz> yep
10:08:27 <psnl> tried to code it up?
10:08:32 <vincenz> no
10:08:34 <vincenz> but I got other todo's
10:08:40 <vincenz> but the implementation should be trivial
10:09:04 <psnl> I never feel I understand anything in CS until I write code to implement it
10:09:27 <vincenz> psnl: I have the strucutre of the code in my head
10:17:36 <ihope> Well, until you get used to it, vi's weird.
10:18:48 <vincenz> ihope: that statement can be generalized for any thing
10:18:55 <ihope> True.
10:19:15 <ihope> Until you get used to it, Haskell is weird. Until you get used to it, Spanish is weird...
10:19:23 <Stinger_> there a fn that will find me the index of an element in a list given a predicate?
10:19:40 <mauke> @hoogle (a -> Bool) -> [a] -> Int
10:19:41 <lambdabot> No matches, try a more general search
10:19:50 <jethr0_> english isn't weird *until* you get used to it :)
10:19:56 <mauke> @hoogle (a -> Bool) -> [a] -> b
10:19:57 <lambdabot> No matches, try a more general search
10:20:08 <ihope> Hmm.
10:20:11 <Stinger_> curses 
10:20:17 <ihope> I'll write you one.
10:20:50 <jethr0> @type findIndex
10:20:51 <lambdabot> forall a. (a -> Bool) -> [a] -> Maybe Int
10:20:52 <xerox> exist a. until you get used to a. a is weird.
10:21:20 <ihope> Ah, there's one.
10:21:29 <xerox> ?type findIndices
10:21:30 <lambdabot> forall a. (a -> Bool) -> [a] -> [Int]
10:21:36 <vincenz> xerox: i don't think that "exist a." is required
10:22:00 <vincenz> xerox: things that don't exist will always be weird as you can't get used to them
10:22:37 <jethr0> alternatively, one can do:
10:22:37 <ihope> What the...
10:22:45 <Stinger_> thx jethr0 
10:23:02 <ihope> Is that command supposed to do that?
10:23:18 * ihope retypes everything
10:23:37 <jethr0> > map fst . filter (even . snd) . zip [0..] $ [1..7]
10:23:38 <lambdabot>  [1,3,5]
10:23:57 <jethr0> with f = even
10:25:51 <vincenz> > map fst . filter (even . snd) . zip [0..] $ [1,2,4,6,8,9]
10:25:52 <lambdabot>  [1,2,3,4]
10:25:56 <xerox> vincenz - Mine is optimistic (-:
10:26:03 <vincenz> o.O
10:27:02 * vincenz thinks that software with a zillin requirements in buildtools and libraries should be abolished
10:27:05 * vincenz muttrs
10:28:50 * jethr0 is confused how different movie players can play different broken movie files even though they use the same codecs!?
10:32:34 <Guest57096> maybe they are secretly using *different* codecs?
10:34:56 <jethr0> i don't know. but it's really weird how one of mplayer,xine and vlc usually works. but never the same one :)
10:37:22 <davidhouse> @type (.) . (.)
10:37:23 <lambdabot> forall a b c a1.
10:37:23 <lambdabot>      (b -> c) -> (a -> a1 -> b) -> a -> a1 -> c
10:38:06 <davidhouse> > (.) . (.) $ show (+) 2 3
10:38:06 <lambdabot>  Couldn't match `[Char]' against `t -> t1 -> t2'
10:38:20 <davidhouse> > ((.) . (.)) show (+) 2 3
10:38:21 <lambdabot>  "5"
10:39:22 <SamB> maybe they are using different demuxers
10:39:40 <SamB> and I don't think they are necessarily using the same codecs
10:40:02 <xerox> davidhouse - When you compose compose like that, the numer of compose composed is the number of arguments of the funcion you are composing an unary function with.
10:40:29 <SamB> there are often multiple codec libraries that can handle a given format
10:42:41 <dsacode> Hello! What does a@(x:xs) notation mean?
10:43:16 <Pegazus> a@(x:xs) the parameter get's matched with both a and (x:xs)
10:43:18 <SamB> it means that a is being bound to a parameter
10:43:33 <Pegazus> so the list can be "used" as a, or the head of the list as x and the tail as xs...
10:43:40 <dsacode> Ahh, ok
10:43:47 <Pegazus> it's like where x = head a; xs = tail a;
10:43:54 <dsacode> I understand
10:43:56 <dsacode> Thanks!
10:44:14 <davidhouse> > let a@(x:xs) = [1..5] in (a, x, xs)
10:44:15 <lambdabot>  ([1,2,3,4,5],1,[2,3,4,5])
10:44:16 <SamB> > let f a@(x:xs) = a in f []
10:44:16 <lambdabot>  Add a type signature
10:44:29 <SamB> > let f a@(x:xs) = a in f [] :: String
10:44:30 <lambdabot>  Non-exhaustive patterns in function f
10:44:54 * SamB didn't remember whether the (x:xs) was matched strictly or not
10:45:00 <Pegazus> is it or not?
10:45:03 <SamB> > let f a@~(x:xs) = a in f [] :: String
10:45:03 <lambdabot>  Parse error in pattern
10:45:08 <SamB> Pegazus: it is
10:45:11 <Pegazus> k
10:45:12 <davidhouse> all pattern bindings are strict apart from case (IIRC).
10:45:25 <davidhouse> don't quote me on that.
10:45:50 <SamB> there is a way to do it the other way, but I forget what it is
10:45:54 <davidhouse> > let f (x:xs) = "hello world" in f undefined
10:45:55 <lambdabot>  Undefined
10:45:59 <davidhouse> > let f ~(x:xs) = "hello world" in f undefined
10:46:00 <SamB> something about "irrefutable" patterns
10:46:00 <lambdabot>  "hello world"
10:46:13 <SamB> > let f a~@(x:xs) = a in f [] :: String
10:46:13 <lambdabot>  Parse error in pattern
10:46:24 <SamB> > let f a @~(x:xs) = a in f [] :: String
10:46:24 <lambdabot>  Parse error in pattern
10:46:28 <SamB> > let f a @ ~(x:xs) = a in f [] :: String
10:46:29 <lambdabot>  ""
10:46:33 <davidhouse> the ~ asserts that the pattern will be matched. it turns strict patterns into lazy ones
10:46:48 <SamB> hmm, that looks ugly, doen't it
10:46:53 <xerox> Yes!
10:47:05 <SamB> there is probably a better way to say that?
10:47:16 <SamB> @report
10:47:17 <lambdabot> Unknown command, try @list
10:47:21 <davidhouse> > id [] :: String
10:47:22 <lambdabot>  ""
10:47:23 <SamB> @google haskell report
10:47:24 <davidhouse> :)
10:47:25 <lambdabot> http://www.haskell.org/onlinereport/
10:47:29 <davidhouse> @where report
10:47:29 <lambdabot> I know nothing about report.
10:47:41 <davidhouse> @where+ report http://www.haskell.org/onlinereport/
10:47:41 <lambdabot> Done.
10:47:44 <davidhouse> @where report
10:47:45 <lambdabot> http://www.haskell.org/onlinereport/
10:49:19 <davidhouse> of course, if you use a lazy pattern and try to do anything with what you match, it'll bork if you pass in _|_.
10:49:40 <davidhouse> > let f ~(x:xs) = x : "hello world" in f undefined
10:49:41 <lambdabot>  Undefined
10:54:35 <davidhouse> any type system experts aroud?
10:55:00 * davidhouse was wondering whether the Y combinator breaks the normalisation property
11:01:25 <dcoutts_> davidhouse, what do you think the answer is?
11:02:46 <davidhouse> dcoutts_: i would say 'yes it does'.
11:02:56 <dcoutts_> why?
11:03:03 <davidhouse> let me give an example.
11:03:20 <dcoutts_> you mean a counter-example :-)
11:04:42 <vincenz> re
11:04:44 <davidhouse> fix (\x -> 1 + x), say. this will be expanded to 1 + 1 + 1 + 1 + ..., which can't be beta-reduced.
11:04:55 <dcoutts_> davidhouse, right.
11:05:26 <davidhouse> so i would guess the existence of non-terminism (programs that don't halt; is that the right term?) is evidence against the normalisation property.
11:05:33 <dcoutts_> indeed
11:05:51 <dcoutts_> program that have no normal form
11:06:08 <ulfdoz_> Do you solve the Halt-Problem? :)
11:06:09 <davidhouse> but System F apparently _is_ strictly normalising, and i thought HM was just a restriction of System F?
11:06:32 <vincenz> davidhouse: but normalizing on the AST or on the semantics of the AST?
11:06:32 <dcoutts_> hmm
11:06:45 <vincenz> davidhouse: cause the ast of that fix (\x -> 1 + x) is finite
11:07:04 <vincenz> @where report
11:07:04 <lambdabot> http://www.haskell.org/onlinereport/
11:07:09 <palomer> davidhouse: System F doesn't have recursion
11:07:23 <palomer> HM does
11:07:34 <davidhouse> hmm?
11:07:47 <palomer> HM is not simply a restriction of System F
11:07:54 <davidhouse> right.
11:07:57 <palomer> HM is a restriction of System F + Y combinator
11:08:27 <davidhouse> system f has recursion at the type level, though, right?
11:08:37 <palomer>  nope
11:08:58 <dcoutts_> seems not as it's apparently equivalent to second-order logic.
11:09:47 <palomer> second order logic without  the first order
11:10:01 <davidhouse> "System F allows recursive constructions to be embedded in a natural manner, related to that in Martin-L√É¬∂f's type theory."
11:10:01 <palomer> AF_2 is second order logic
11:10:19 <palomer> davidhouse: sure, but that says nothing about recursive types
11:10:47 <davidhouse> palomer: so at what level is it recursive?
11:11:01 <palomer> it isn't
11:11:02 <dsacode> Is there some function reference for haskell (quick description, type) from Prelude and List? Not tutorial or something, just reference
11:11:08 <palomer> it's impredicative
11:11:36 <davidhouse> dsacode: either the hierarchial modules, or go into GHCi and hit :b Prelude, or :b Data.Oist
11:11:40 <davidhouse> s/Oist/List
11:11:57 <davidhouse> @docs Prelude
11:11:57 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Prelude.html
11:11:58 <dsacode> davidhouse: hmm.. isn't there PDF, HTML or something? :(
11:12:01 <mauke> dsacode: http://haskell.org/onlinereport/
11:12:07 <dsacode> thanks, guys
11:12:10 <dsacode> i'll check it
11:12:21 <davidhouse> dsacode: the hierarchial modules are HTML.
11:12:24 <mauke> http://haskell.org/haskellwiki/Language_and_library_specification
11:15:09 <mathewm1> Does anyone know the problem with gcc >= 3.3 on PPC?  Seems to produce a ghc that dies of Bus errors...
11:15:59 <dsacode> BTW, isn't there some predefined function in Prelude or List, so if we will have list of pairs (key, value), we can give key and this list and get value?
11:16:12 <davidhouse> dsacode: lookup.
11:16:30 <dsacode> thanks!
11:16:38 <davidhouse> > lookup 2 [(1, "hello"), (2, "world")]
11:16:39 <lambdabot>  Just "world"
11:16:42 <davidhouse> > lookup 2 [(1, "hello"), (3, "world")]
11:16:43 <lambdabot>  Nothing
11:17:31 <Pegazus> lookup 3 [(1, "hi")] ++  [(1, "hello"), (3, "world")]
11:17:37 <Pegazus> > lookup 3 [(1, "hi")] ++  [(1, "hello"), (3, "world")]
11:17:38 <lambdabot>  Couldn't match `[a]' against `Maybe b'
11:17:52 <palomer> ++ doesn't bind very tightly
11:17:57 <Pegazus> what?
11:18:01 <davidhouse> > lookup 3 ([(1, "hi")] ++  [(1, "hello"), (3, "world")])
11:18:02 <lambdabot>  Just "world"
11:18:07 <Pegazus> ah :p
11:18:12 <mathewm1> ++ is right assoc for performance sake, I think
11:18:23 <Pegazus> > lookup 3 ((repeat [(1, "hi")]) ++ [(1, "hello"), (3, "world")])
11:18:24 <lambdabot>  Couldn't match `[(a, [Char])]' against `(a1, b)'
11:18:43 <dcoutts_> mathewm1, really? we don't get that on Gentoo/ppc 
11:18:49 <palomer> > error "high"
11:18:50 <lambdabot>  Add a type signature
11:18:54 <palomer> > error "high" :: Int
11:18:55 <lambdabot>  Exception: high
11:19:09 <mathewm1> dcoutts_ maybe it is OSX specific then
11:19:16 <palomer> > error "high" ++ error "low" ++ error "bye"  :: [Int]
11:19:17 <lambdabot>  Exception: high
11:19:20 <dcoutts_> mathewm1, yeah, could well be.
11:19:23 <davidhouse> > lookup 3 (repeat (1, "hi") ++ [(1, "hello"), (3, "world")])
11:19:26 <lambdabot> Terminated
11:19:28 <palomer> looks left associative to me
11:19:42 * mathewm1 doesn't know what he is talking about...
11:20:20 <davidhouse> Pegazus: repeat takes one element, then repeats it to form a list. you gave it a list, so it would repeat that list to form a list of lists.
11:21:00 <davidhouse> and another thing worth knowing is that function application binds tightest of all, so you can drop some of your parentheses (as i did).
11:21:57 <Pegazus> > lookup 3 ((repeat (1, "hi")) ++ [(1, "hello"), (3, "world")])
11:22:00 <Pegazus> there? :)
11:22:01 <lambdabot> Terminated
11:22:08 <davidhouse> palomer, dcoutts_, thanks for your help. don't suppose either of you could recommend a textbook on this kind of thing? even better if its online so i don't have to buy it :)
11:22:36 <palomer> hrmph, types and programming languages isn't bad
11:22:56 <vincenz> davidhouse: tapl
11:22:58 <dcoutts_> davidhouse, I'd reccomend this book: http://www.cis.upenn.edu/~bcpierce/tapl/
11:23:10 <dcoutts_> well that's unanimous then :-)
11:23:18 <davidhouse> heh. :)
11:23:34 <palomer> a much better book could be written, though
11:23:49 <palomer> I'm not a huge fan of his approach
11:24:04 <norpan> palomer: how does that show that it's left associative?
11:24:56 <palomer> > error "1" $ error "2" $ error "3" :: Int
11:24:56 <lambdabot>  Exception: 1
11:24:57 <dcoutts_> palomer, would you reccomend any existing book?
11:25:19 <Pegazus> does anyone here knows how to do SLD algorithm by hand? (and also how to turn some first order logic sentences into horn clauses when possible...)
11:25:28 <palomer> > (error "1" $  error "2") error "3" :: Int
11:25:30 <lambdabot>  Exception: 1
11:25:32 <SamB> what is SLD?
11:25:38 <palomer> you're right, it doesn't show anything:/
11:25:59 <palomer> dcoutts_: no, all the other books are even worse
11:26:02 <Pegazus> it might be SDL
11:26:05 <palomer> (from my experience)
11:26:10 <dcoutts_> palomer, heh, ok.
11:26:11 <Pegazus> i always forget if it's SLD or SDL...
11:26:12 <palomer> LSD?
11:26:30 <Pegazus> it's an algorithm for deducing things from horn clauses...
11:26:50 <Pegazus> to test insatisfacibility...
11:26:58 <mathewm1> does lambabot have any command to show binding order and associativity of an operator?
11:27:10 <davidhouse> palomer: "infixr 5  ++, :", from http://darcs.haskell.org/packages/base/GHC/Base.lhs
11:27:14 <mauke> @fixity
11:27:21 <lambdabot> Unknown command, try @list
11:27:30 <davidhouse> mathewm1: feel like writing a plugin :)
11:27:34 <SamB> mathewm1: don't think so, but GHCi can show you
11:27:41 <davidhouse> SamB: it can?
11:27:41 <dcoutts_> :info ++
11:27:41 <dcoutts_> infixr 5 ++
11:27:41 <dcoutts_> (++) :: [a] -> [a] -> [a]
11:27:48 <davidhouse> wow, awesome :)
11:28:04 <dcoutts_> both ghc and hugs will tell you that
11:28:26 <dcoutts_> :info works on any functon, type, operator, class name
11:28:50 <davidhouse> so :info does: 1) class methods 2) class instances 3) gives the definition of type constructors 4) gives the type and fixity of a function
11:29:02 <davidhouse> and where it's defined.
11:29:19 <SamB> well, where it is "imported from", anyway
11:29:42 <davidhouse> true.
11:30:00 <SamB> if the module is a starred module, I guess it probably does say where it was defined
11:30:28 <SamB> maybe any interpreted module
11:32:16 <SamB> well, it certainly works for interactively bound variables ;-)
11:32:35 <SamB> I assume it works for other interpreted code, because it isn't really very useful for it to say:
11:32:41 <SamB> x :: Integer    -- Defined at <interactive>:1:4
11:33:34 <SamB> incidentally, I didn't know the MR applied to things bound interactively with let...
11:40:06 <robajs> hello
11:40:14 <davidhouse> hi robajs.
11:42:20 <robajs> can haskell take advantage of multiple cpus or multiple cores?
11:42:40 <integral> GHC 6.5 has exciting SMP features
11:42:58 <integral> robajs: there's "Parallel Haskell" and "Concurrent Haskell".
11:43:36 <mathewm> when is 6.5 to become 6.6 ( and "stable" )?
11:46:41 <davidhouse> mathewm: a couple of months.
11:48:33 <mathewm> davidhouse: that is a good answer
11:48:46 <davidhouse> mathewm: it is?
11:49:07 <mathewm> davidhouse: better than "dunno - a couple of years maybe..."
11:49:28 <davidhouse> hehe :)
11:49:32 <davidhouse> "When it's ready" ;)
11:50:06 <mathewm> :)
11:50:24 <norpan> when it is good and ready
11:50:33 <newsham> its not good yet?
11:50:41 <jethr0> @google a -> a -> a -> [a]
11:50:42 <lambdabot> http://www.apple.com/
11:50:47 <jethr0> @hoogle a -> a -> a -> [a]
11:50:47 <lambdabot> No matches, try a more general search
11:50:51 <norpan> maybe, but not good and ready :)
11:51:17 <jethr0> @type enumFromThenTo
11:51:18 <lambdabot> forall a. (Enum a) => a -> a -> a -> [a]
11:51:30 <davidhouse> @karma- hoogle
11:51:31 <lambdabot> hoogle's karma lowered to 1.
11:51:35 <jethr0> somehow hoogle tends to miss cases...
11:51:44 <newsham> @karma- newsham
11:51:44 <lambdabot> You can't change your own karma, silly.
11:51:48 <mathewm> the 'forall' stuff isn't standard Haskell '98, right
11:51:56 <jethr0> @karma- newsham
11:51:56 <lambdabot> newsham's karma lowered to -1.
11:51:58 <newsham> lies.  you can change your own karma
11:52:01 <jethr0> at your service :)
11:52:08 <newsham> thats how karma works
11:52:18 <jethr0> @karma+ newsham
11:52:18 <lambdabot> newsham's karma raised to 0.
11:52:44 <newsham> +2health +20coding -5social
11:52:49 <davidhouse> mathewm: nope. they're called existentials, and are a type extension in -fglasgow-exts.
11:52:52 * jethr0 thinks there should be a compulsory reason attached (as with darcs) when you change someones karma ^_^
11:52:58 <norpan> the bad thing about karma is that you don't get to use it until you die
11:53:18 <jethr0> the thought alone of using up your karma sets it to zero
11:53:21 <newsham> +8 dharma
11:53:30 <norpan> jethr0: darn
11:53:54 <davidhouse> @echo @karma+ davidhouse
11:53:54 <lambdabot> echo; msg:Message {msgPrefix = "davidhouse!n=david@host86-143-53-67.range86-143.btcentralplus.com", msgCommand = "PRIVMSG", msgParams = ["#haskell",":@echo @karma+ davidhouse"]} rest:"@karma+
11:53:55 <lambdabot> davidhouse"
11:54:01 <davidhouse> argh!?
11:54:15 <jethr0> is there a table somewhere associating #haskell karma with what you'll be in your next/real life?
11:54:30 <davidhouse> @echo ping ping ping
11:54:30 <lambdabot> echo; msg:Message {msgPrefix = "davidhouse!n=david@host86-143-53-67.range86-143.btcentralplus.com", msgCommand = "PRIVMSG", msgParams = ["#haskell",":@echo ping ping ping"]} rest:"ping ping ping"
11:54:34 <bolrod> ?
11:54:38 * davidhouse thinks that @echo has bugs
11:54:47 <jethr0> @echo "hello world"
11:54:47 <bolrod> @echo test
11:54:47 <lambdabot> echo; msg:Message {msgPrefix = "jethr0!i=foobar@p54A36039.dip.t-dialin.net", msgCommand = "PRIVMSG", msgParams = ["#haskell",":@echo \"hello world\""]} rest:"\"hello world\""
11:54:47 <lambdabot> echo; msg:Message {msgPrefix = "bolrod!n=bolrod@84-104-179-208.cable.quicknet.nl", msgCommand = "PRIVMSG", msgParams = ["#haskell",":@echo test"]} rest:"test"
11:54:56 <jethr0> hmm, very useful module!
11:55:07 <davidhouse> it normally just echoes out what you just said.
11:55:11 <ithika> yeah, these logs were too small :)
11:55:21 <davidhouse> i.e. <davidhouse> @echo hello <lambdabot> hello
11:55:21 <newsham> +5 = you will have your questioned answered in your next #channel
11:55:40 <bolrod> @. elite echo test
11:55:52 <bolrod> @elite "test"
11:56:00 <bolrod> ?
11:56:06 <bolrod> @test
11:56:11 <bolrod> @echo hello
11:56:26 <bolrod> :/
11:56:29 <davidhouse> someone's tying up lambdabot in a PM.
11:56:32 <lambdabot> 3(ho; MS9:M3$SAgE {/\/\sgpREphix = "b0LRoD!n=bO|R0D@84-104-179-208.(A8|e.QUi(xne+.Nl", m5Gc0M/\/\And = "pRI\/Mz9", m$GpArA/\/\z0rz = ["#h4$KE11",":@. 1337 EchO t3zt"]} Rezt:"73$+"
11:56:33 <davidhouse> he'll be back soon.
11:56:35 <lambdabot> "tEz+"
11:56:35 <jethr0> the @list feature is somewhat broken. i seem to be hogging all of lambdabots processing power in private channel just to list all commands. and it takes dozens of seconds, too
11:56:39 <lambdabot> Maybe you meant: last list
11:56:41 <lambdabot> echo; msg:Message {msgPrefix = "bolrod!n=bolrod@84-104-179-208.cable.quicknet.nl", msgCommand = "PRIVMSG", msgParams = ["#haskell",":@echo hello"]} rest:"hello"
11:56:46 <mathewm> PM?
11:57:00 <jethr0>  /msg lambdabot hello
11:57:05 <davidhouse> private message; /msg (or /query, depending on your client)
11:57:29 <mathewm> so lambdabot isn't multi-"threaded"?
11:57:35 <Pegazus> <mathewm> so lambdabot isn't multi-"threaded"? O_o
11:57:50 <jethr0> @slap Pegazus 
11:57:51 * lambdabot beats up Pegazus
11:58:36 <jethr0> wasn't me, it was Emily!
12:02:09 <bolrod> Prelude> :t (+1).(+) $ 2    
12:02:09 <bolrod> (+1).(+) $ 2 :: (Num (a -> a), Num a) => a -> a
12:02:11 <bolrod> ^.0
12:02:30 <bolrod> :]
12:10:13 <ithika> are there any good beginners' guides for XML in haskell?
12:10:27 <ithika> i'm trying to wrap my head round HaXml but I can't
12:12:52 * vincenz kicks c++ typing system
12:13:59 <Eelis> now what? ;)
12:14:04 <vincenz> templates
12:14:13 <vincenz> templates aren't that hard to type really, why all the stupid restrictions
12:14:23 <vincenz> liek partial specialization for friends
12:14:35 <Eelis> i'll have a look in D&E, perhaps it's mentioned
12:14:56 <vincenz> D&E?
12:15:49 <Eelis> stroustrup's "The Design & Evolution Of C++"
12:16:02 <vincenz> ah
12:16:16 <Eelis> can't seem to find my copy though
12:29:28 * SamB thinks HXT is better
12:29:45 <int-e> All the small little syntax details of templates. For example, what's wrong with foo<bar<xyzzy>>; ... *grr* (>> is a single lexeme)
12:31:09 <SamB> yeah, shouldn't try to use brackets for other purposes, really...
12:31:18 <SamB> of course, ASCII hasn't enough kinds of brackets
12:31:27 <int-e> > [t| t <- [1..3]]
12:31:27 <lambdabot>  parse error on input `<-'
12:32:21 <Eelis> for what it's worth, the >> "problem" will be fixed in 2009 :)
12:33:47 <int-e> Yes I've seen that actually. concepts look neat, too. (and despite everything that Stroustrup wrote I'd still say they're basically type classes)
12:33:57 <tennin> that's allowed in C# isn't it?  how do you declare second-order templates in C++?
12:34:12 <int-e> tennin: put a space between > and >.
12:34:55 <tennin> ugh
12:34:58 <int-e> tennin: my second thought was 'oh, maybe this doesn't seem so bad - Haskell does the same.' My third, 'but not for characters used in a bracket-like fashion.'
12:36:04 <int-e> But actually it only affects . in Haskell.
12:36:56 <tennin> I found HXT pretty easy to understand from the thesis included with the source distribution
12:38:38 <int-e> > [x| x <- [1..3]]
12:38:38 <lambdabot>  [1,2,3]
12:38:38 <tennin> though I'd just finished reading the Hughes and Paterson arrow papers at the time (and found them very rough going) so it may have been momentum
12:41:39 <goron> @pointless (\x-> take  (length x).map id x)
12:41:39 <lambdabot> (.) =<< take . length
12:41:45 <goron> This makes my head hurt.
12:41:57 <davidhouse> goron, it's the (a->) monad.
12:42:43 <davidhouse> goron, although you and i know that that's == id, lambdabot's not quite so clever
12:42:53 <goron> davidhouse: ? I know what the individual operators are.  What do you mean?
12:43:06 * jethr0 is annoyed with the incompatibility of STL and OO. inheriting iterators and similar ideas fail at some point because it's not "supposed to go along" *arg*
12:43:18 <jethr0> in c++ that is
12:43:18 <goron> davidhouse: What is (a->)?
12:43:45 <davidhouse> goron, all functions Bool -> something form a monad. so do Int -> something, or any type in that place of the first.
12:43:59 <davidhouse> that's how you can use >>= and stuff with just function.
12:44:09 <davidhouse> *funcions
12:44:19 <goron> Why is Int->Int a monad?
12:44:30 <davidhouse> okay.
12:44:40 <norpan> Int->Int is not a monad (Int->) is :)
12:44:50 <davidhouse> newtype IntDocmain a = ID (Int -> a)
12:45:01 <goron> What is the Int-> notation?
12:45:38 <davidhouse> instance Monad IntDomain where return = id; m >>= f = f . m; (iirc)
12:45:48 <norpan> goron: it's a partial type
12:46:59 <goron> norpan: And a partial type is exactly?
12:47:14 <davidhouse> goron, like i said.
12:47:18 <davidhouse> newtype IntDocmain a = ID (Int -> a)
12:47:31 <davidhouse> (Int->) is like (2*).
12:47:32 <int-e> it is not correct Haskell syntax anyway.
12:47:51 <davidhouse> but it's a section of a type constructor (->) instead of a function (*).
12:47:54 <int-e> you write (->) Int there.
12:48:46 <int-e> davidhouse: your >>= is wrong btw. >>= has to duplicate the reader value.
12:49:00 <davidhouse> i had a feeling :)
12:49:05 <davidhouse> int-e, what's correct?
12:49:08 <goron> So, this trick works because someone wrote an instance for Monad?
12:49:15 <int-e> davidhouse: (m >>= f) x = f (m x) x
12:49:20 <goron> I will look it up.
12:49:21 <norpan> goron: exactly
12:49:46 <goron> norpan: is it a real monad anyway?
12:49:51 <goron> norpan: Or just a hack?
12:49:59 <davidhouse> it's a real monad.
12:49:59 <norpan> of course it is a real monad
12:50:02 <int-e> davidhouse: but really  join f x = f x x  is more natural for that monad.
12:50:23 <goron> Thought, so, ugly hacks are not Haskell :)
12:50:26 <norpan> join is more natural for some monads
12:50:34 <norpan> the list monad for instance
12:50:41 <davidhouse> > not >>= (&&)
12:50:42 <lambdabot>  <Bool -> Bool>
12:50:52 <davidhouse> > (not >>= (&&)) True
12:50:53 <lambdabot>  False
12:51:23 <davidhouse> it goes to not True && not True
12:51:43 <xerox> > (not >>= (&&)) False
12:51:44 <lambdabot>  False
12:51:49 <xerox> Doesn't seem so.
12:52:14 <goron> Where is that instance listed in the documentation?
12:52:20 <davidhouse> err, (not >>= (&&)) x   ==   not x && x
12:52:23 <xerox> goron - under Reader.
12:52:24 <davidhouse> i.e. const False :)
12:52:39 <xerox> So that's the dual of ap :D
12:52:41 <goron> Why isn't it listed under Control.Monad?
12:52:51 <davidhouse> goron: import Control.Monad.Reader.
12:52:59 <davidhouse> it's actually equivalent to the Reader monad.
12:53:12 <goron> I meant in the Haddock documentation.
12:53:47 <goron> I thought the idea of Haddock was that it lists *all* the instances (known at documentation generation time)
12:54:02 <jethr0> > map (+1) >>= (++) $ [1,2,3]
12:54:03 <lambdabot>  [2,3,4,1,2,3]
12:54:05 <davidhouse> yeah, but it doesn't know to import Control.Monad.
12:54:25 <davidhouse> *Control.Monad.Reader
12:54:31 <davidhouse> sorry, i'm a little distracted :)
12:54:33 <xerox> jethr0 - O_O
12:55:16 * jethr0 is still thinking of nice applications. but my brain tilts at the idea of "(f x) `g` x"
12:55:36 <xerox> Yeah.
12:55:41 <goron> Oh, I see it doesn't list the refexive transisitve closure. 
12:56:04 <goron> (of the subclass relation)
12:56:29 <xerox> @pl (\f g x -> g (f x) x,\f g x -> f x (g x))
12:56:29 <goron> For some sensible interpretation of subclass ;)
12:56:30 <lambdabot> (flip flip id . (ap .) . flip (.), ap)
12:56:36 <xerox> UH.
12:56:39 <jethr0> > length >>= (\x -> map (+x)) $ [1,2,3]
12:56:40 <lambdabot>  [4,5,6]
12:56:50 <jethr0> @pl \x -> map (+x)
12:56:50 <lambdabot> map . (+)
12:57:03 <jethr0> > length >>= map . (x) $ [1,2,3]
12:57:03 <lambdabot>  Not in scope: `x'
12:57:04 <xerox> jethr0: haha, that's obfuscated code.
12:57:10 <jethr0> > length >>= map . (+) $ [1,2,3]
12:57:11 <goron> How would a reader of code ever know that for other things?
12:57:11 <lambdabot>  [4,5,6]
12:57:22 <jethr0> i call it "concise" ^_^
12:57:30 <goron> Assuming we don't have an IDE showing the types.
12:57:45 <xerox> jethr0 - let's find a better name, >>= is confusing :D
12:58:13 <int-e> hmm. how about we move that Monad and its MonadReader instance into Control.Monad.Reader.Obscure ?
12:58:18 <jethr0> i agree, but so are many haskell features. it's all a question of getting used to them and annoying people who haven't bothered to spend hours comprehending them :)
12:58:38 <jethr0> no, monad reader can be really helpful!
12:59:05 <int-e> yes, but there's a nicely newtyped one which doesn't lead to such abuse of the fact that ask = id
12:59:09 <jethr0> > sequence [(+1), (*2), (`div` 4)] 5
12:59:10 <lambdabot>  [6,10,1]
13:00:17 <int-e> > (ask >>= \x -> x+x) 42
13:00:18 <lambdabot>   Occurs check: cannot construct the infinite type: t = t -> b
13:00:18 <lambdabot>   Expected type: t
13:00:18 <lambdabot>   Inferred type: t -> b
13:00:21 <int-e> hmm.
13:00:35 <int-e> > (ask >>= \x -> return (x+x)) 42
13:00:36 <lambdabot>  84
13:00:54 <jethr0> > liftM2 (&&) even odd $ 4
13:00:56 <lambdabot>  False
13:01:06 <int-e> > runReader (ask >>= \x -> return (x+x)) 42
13:01:07 <lambdabot>  84
13:01:15 <int-e> now that's actually readable.
13:01:26 <jethr0> it's also trivial :)
13:01:41 <davidhouse> > runReader (liftM (*2) . ask) 42
13:01:41 <lambdabot>  Couldn't match `Reader r a' against `t -> t1'
13:01:52 <davidhouse> > runReader (liftM (*2) ask) 42
13:01:54 <lambdabot>  84
13:02:13 <davidhouse> > runReader (liftM (join (+)) ask) 42
13:02:14 <lambdabot>  84
13:02:16 <davidhouse> :)
13:02:31 * jethr0 is still *very* confused by join
13:02:48 <jethr0> does . not . compute
13:02:59 <jethr0> k, gotta go. got my crypto exam tomorrow :(
13:03:04 <int-e> why? it's just 'given a computation that returns a computation, run that computation and then the returned computation'
13:03:05 <davidhouse> good luck!
13:03:22 <davidhouse> jethr0: in Reader, join f = \x -> f x x
13:03:28 <jethr0> thx
13:05:11 <jethr0> > join const 4
13:05:12 <lambdabot>  4
13:05:14 <jethr0> :)
13:05:17 <jethr0> g'night
13:05:34 <davidhouse> right, join const = id.
13:05:41 <int-e> const = return
13:05:59 <int-e> and then that's actually a monad law
13:08:42 <goron> Is (->) r the same as r->a ?
13:08:54 <davidhouse> (->) r a == r -> a.
13:09:15 <davidhouse> just like (+) r a == r + a
13:14:30 <vincenz> dons: ping
13:15:07 <vincenz> dcoutts_: ping as well I guess
13:15:45 <vincenz> davidhouse: bad example, one is at typelevel, the other at valuelevel
13:16:00 <davidhouse> vincenz: right. but it's analoguous.
13:16:41 <vincenz> true
13:17:19 * vincenz grrs
13:18:38 <goron> @hoogle sort
13:18:38 <lambdabot> List.sort :: Ord a => [a] -> [a]
13:18:39 <lambdabot> List.sortBy :: (a -> a -> Ordering) -> [a] -> [a]
13:18:39 <lambdabot> System.Win32.NLS.sORTIDFROMLCID :: LCID -> SortID
13:22:52 <lennart> howdy
13:24:52 <kosmikus> hi lennart 
13:33:18 <BeyondDeath> if anyone wants to hack my box, i'm testing it for security; 70.247.165.123
13:33:47 <vincenz> @pl \f g a b -> f (g a b)
13:33:48 <lambdabot> (.) . (.)
13:35:46 <sjanssen> BeyondDeath: when we say "Haskell is still the language of choice for discriminating hackers", we mean hacking as in programming, not breaking into computers
13:35:48 <vincenz> @type (.)
13:35:49 <lambdabot> forall c a b. (b -> c) -> (a -> b) -> a -> c
13:43:21 <vincenz> 10:42 pm
13:43:23 <vincenz> time for dinner
13:44:42 <goron> vincenz: pizza? 
13:44:59 <vincenz> nah
13:45:06 * vincenz has some food inhouse
13:45:08 <vincenz> I'd better cook that
13:45:12 <vincenz> just finished working on something :/
13:45:34 <goron> vincenz: Me too, it seems I am more productive with Haskell than with Lisp.
13:46:03 <goron> Mostly a documentation issue and lack of Lisp experience I think.
13:46:06 <vincenz> it was c++
13:46:30 <vincenz> after dinner I have to work on a haskell thing tho
13:46:47 <goron> vincenz: I read The C++ Programming Language (except for the appendix)
13:46:57 <goron> vincenz: all 780 pages of them.
13:47:24 <davidhouse> goron, why not the appendix?! ;)
13:47:25 <goron> er 789
13:49:34 <vincenz> goron: so you're very familiar with c++?
13:49:58 <goron> vincenz: low on experience, but I think I am.
13:50:02 <mathewm> I thought I saw a "buildList" function - varargs.  I cannot find it now, though
13:50:05 * vincenz snaps his finger
13:50:15 <marc_vw> the appendix is available as its own book
13:50:18 <davidhouse> mathewm: to do what?
13:50:21 <vincenz> I'm trying to find a testsuite for STL
13:50:25 <marc_vw> annotated c++ reference, very cool
13:50:27 <vincenz> cause I have my own implementation of vector
13:50:36 <mathewm> take variable numbers of args and create a list from them
13:50:57 <mathewm> a -> a -> a ... -> a -> [a]
13:51:19 <davidhouse> doesn't sound like a haskell function.
13:51:23 <vincenz> nope
13:51:27 <vincenz> unpossible
13:51:28 <davidhouse> why not just [x, y, z, ...]?
13:51:36 <davidhouse> vincenz: without clever typeclass hackery.
13:51:36 <goron> Main reason for learning it was the Boost Graph Library, but I feel it's either overly complicated, or just not good documented.
13:51:40 <davidhouse> vincenz: and/or TH.
13:51:42 <vincenz> davidhouse: yep
13:51:46 <mathewm> I saw it somewhere , I swear it...
13:52:11 <davidhouse> mathewm: perhaps on the mailing list, where someone was discussing either clever typeclass hackery or TH? :)
13:52:16 <davidhouse> mathewm: why would you want one?
13:52:30 <mathewm> because I am learning...
13:52:44 <mathewm> I want to know the boundaries of the language
13:54:17 <davidhouse> in general, variable number of arguments aren't possible.
13:54:30 <goron> vincenz: Probably gcc contains tests for vector. 
13:54:36 <mathewm> ah - this is what I saw http://okmij.org/ftp/Haskell/types.html#polyvar-fn
13:54:42 <davidhouse> mathewm: the reason is because things have to have a fixed type.
13:54:49 <goron> Oleg
13:54:55 <goron> 's articles are interesting.
13:55:03 <davidhouse> yes, like i said, clever typeclass hackery.
13:55:07 <goron> I read his monad in Scheme things.
13:55:50 <SamB> yes, this must have been one of olegs ideas...
13:56:18 <SamB> I've seen something like that somewhere too...
13:57:20 <goron> "requires only the most common extension of multiparameter classes with functional dependencies. "
13:57:26 <SamB> @type Text.Printf.printf
13:57:27 <lambdabot> forall r. (PrintfType r) => String -> r
13:57:46 <SamB> > printf "Hello, %s!" "World"
13:57:47 <lambdabot>  Add a type signature
13:57:53 <SamB> > printf "Hello, %s!" "World" :: String
13:57:54 <lambdabot>  "Hello, World!"
13:58:16 <goron> I think Lisp languages do have one advantage: it's stable. 
13:58:42 <davidhouse> haskell is stable too.
13:58:42 <SamB> but the typesystem is very little help
13:59:01 <davidhouse> there have been very few backward-incompatible changes... ever.
13:59:22 <mathewm> several libraries seem to have been renamed/modified
13:59:23 <goron> davidhouse: that's true, but if one looks at Perl.... 
13:59:24 * SamB wishes mame didn't need to be compiled strictly
13:59:45 <SamB> well, Lisp has no namespaces even...
14:00:08 <goron> SamB: It has packages, which serve that purpose.
14:00:08 <SamB> well, not in the standard library, to speak of
14:00:18 <goron> SamB: true
14:00:23 <SamB> and they aren't even safe!
14:00:27 <goron> also true
14:00:42 <goron> I don't think that is a problem though. 
14:01:23 <SamB> also, I can't get it to parse lisp sources with C/C++ style comments in...
14:01:40 <goron> SamB: ?
14:01:56 <goron> SamB: You mean a reader macro?
14:02:10 <SamB> oh, I had been trying to reimplement Abuse in it. Abuse seemed to want to be written in Lisp...
14:02:34 <goron> SamB: Abuse? 
14:02:44 <SamB> a game
14:03:49 <goron> SamB: and where did the C/C++ comments come from?
14:04:07 <SamB> well, for some reason the dialect of Lisp it implements allows them
14:04:24 <goron> SamB: oh, now I understand.
14:04:46 <goron> SamB: You could load it in other Lisps if you would write a reader macro.
14:05:17 <SamB> well, I couldn't figure out how, I guess...
14:05:34 <SamB> at least, I looked at them, but didn't seem to be able to figure it out...
14:06:20 <goron> Changed libraries should come with code that automatically transforms code using that library.
14:06:28 <SamB> maybe because the start char was /, and I didn't want to alter the reading of (/ 2 1)
14:06:42 <SamB> would be nice1
14:06:49 <SamB> s/1/!/
14:07:02 <shapr> @yow !
14:07:02 <lambdabot> Should I get locked in the PRINCICAL'S OFFICE today -- or have a
14:07:02 <lambdabot> VASECTOMY??
14:07:17 <SamB> is that where they take a vase out of you?
14:07:58 <goron> SamB: FYI you can do that in Common Lisp.
14:08:12 <shapr> Take the vase out?
14:08:42 <mathewm> Why is Data.FiniteMap deprecated?  What is the alternative?
14:08:48 <SamB> Data.Map?
14:08:53 <int-e> doesn't it tell you?
14:08:57 <goron> mathewm: It tells you
14:09:07 * mathewm doesn't bother reading...
14:09:08 <int-e>   {-# DEPRECATED "Please use Data.Map instead." #-}
14:11:08 <mathewm> so why would FiniteMap be deprecated?  Was it just namimg or something functional?
14:14:02 <ndm> mathewm: names and an interface change
14:14:32 <ndm> not that fundamentally different concept, just a new version with more consistent names compared to Data.Set and Data.List
14:15:15 <int-e> @index _tagCmp
14:15:16 <lambdabot> bzzt
14:17:01 <Revision17> If I'm using an immutable array, use // to change a couple elements in it, and never use the previous versions of the array, does haskell (or at least GHC) make a complete copy of the array with the changes (I want to know for preformance reasons as I may be using an 8KB array that is changed alot)?
14:17:49 <ndm> Revision17: see diff arrays
14:18:16 <int-e> or you can play around with unsafeThawArray / unsafeFreezeArray if you really know what you're doing.
14:18:16 <ndm> that way the newest version is always in a proper array, and the old ones are as a difference list
14:18:27 <ndm> hence the new version is always fast, and the old one gets GC'd
14:18:34 <int-e> diffarrays on the other hand are safe.
14:18:52 <SamB> apparantly an 8KB array is not necessarily anything to worry about that with...
14:19:19 <Revision17> ndm: so with diff arrays, I can get O(1) access and write times?
14:19:21 <int-e> oh, copying 8 kb a million times takes some time.
14:19:35 <ndm> Revision17: maybe, try it and find out :)
14:19:43 <SamB> yes, but so does doing a million takeMVars
14:19:49 <Revision17> this is for an emulator, so I'm going to be doing lots of random reads and writes
14:19:51 <int-e> Revision17: if you never use old copies, yes.
14:19:51 <ndm> but my guess is "maybe"
14:20:15 <Revision17> int-e: cool; I'll look into them, thanks
14:21:04 <SamB> and actually, you have to takeMVar whenever you read from a DiffArray, don't you?
14:21:13 <SamB> or something like that?
14:21:35 <SamB> er, I guess you just have to peek at the value inside, so you don't need to actually take it...
14:22:44 <int-e> SamB: but MVar has no peek operation (readMVar is implemented in terms of takeMVar and putMVar)
14:25:09 <Maddas> SamB: Doesn't Abuse use a home-grown language/dialect?
14:25:24 <SamB> apparantly a home-grown Lisp dialect
14:28:21 <dcoutts> vincenz, pong
14:29:10 <Maddas> SamB: Right. So you are trying to re-implement it in CL? (Just wondering whether I understood the situation)
14:29:24 <SamB> not at the moment
14:29:26 <SamB> I was
14:29:28 <SamB> a while back
14:29:57 <Maddas> okay
14:38:49 <vincenz> dcoutts: do you use anything for planning?
14:39:01 <dcoutts> what do you mean?
14:39:07 <vincenz> like stuff you still have to do
14:39:20 <vincenz> except.. I don't think this was my question when I pinged
14:45:27 <ForgeAus> just out of curiousity (I think I'm going retro here) how different is haskell to clean?
14:45:41 <vincenz> ForgeAus: I don't think it's very different, I think it's in the details
14:46:50 <ForgeAus> ahh but if you seen lost (damn forgot which one - about a theif anyhow..) anyway, Sawyer says its all in the details
14:48:12 <ForgeAus> also details are important to some people
14:48:34 <vincenz> I'm not quite certain what the differences are
14:48:37 <vincenz> but I know they're minor
14:48:55 <ForgeAus> good to know... so if I get the hang of Clean Haskell won't be so bad :)
14:49:09 <int-e> hmm, monadic IO vs. linear types? (disclaimer: I've never actually looked at Clean)
14:49:13 <vincenz> or if you get the hang of haskell, clean won't be so bad ;)
14:49:21 <ForgeAus> rofl
14:49:27 <ForgeAus> how did I know you'd say that
14:50:42 <ForgeAus> well IronPython is basically built into VS.NET (2006) now, at least they have versions with it built in and also theres Boo (python-like) for SharpDevelop.... still its weird Haskell isn't in it...
14:50:43 <int-e> clean Haskell sounds good.
14:50:56 <vincenz> int-e: he meant to attach a ","
14:51:15 <ForgeAus> yeah my grammar sux
14:51:16 <int-e> vincenz: oh really? ]:->
14:51:21 <vincenz> :D
14:51:40 <ForgeAus> then agian I kinda like the idea of clean haskell too :)
14:52:05 <vincenz> well we will soon have "haskell clean"
14:52:08 <vincenz> also known as haskell'
14:52:21 <ForgeAus> specially considering Charlie the Duck that I just played was compiled in it
14:52:24 <vincenz> which will supposedly allow us to write clean haskell
14:52:25 <ForgeAus> very Mario-like game
14:53:01 <davidhouse> hey, vincenz, did you get your class aliases proposal in?
14:53:15 <vincenz> davidhouse: it's not my proposal, it's some other guy that invented it
14:53:22 <vincenz> and by the looks of it it'll be no
14:53:32 <vincenz> haskell' is supposed to be a consolidatin of what's developed
14:53:41 <vincenz> noone has ever done class aliases for real
14:53:43 <SamB> oh, well, maybe it will make the next Haskell'
14:53:49 <vincenz> SamB: haskell''?
14:53:54 <ForgeAus> Haskell 2?
14:53:59 <vincenz> haskell 95?
14:54:07 <SamB> well, I was assuming they would come up with an actual name at some point for haskell'
14:54:11 <davidhouse> vincenz: does it have an implementation?
14:54:11 <ForgeAus> Haskell 2006.NET ++?
14:54:14 <poetix> http://lambda-the-ultimate.org/node/1507 <- I take it everyone has seen this, or something else on the same subject, by now...?
14:54:18 <vincenz> davidhouse: I'm afraid not
14:54:23 <vincenz> davidhouse: someone would have to do it for instance for ghc
14:54:28 <davidhouse> poetix: i didn't click it, but is it the linspire thing?
14:54:34 <poetix> Yup...
14:54:40 <SamB> linspire thing?
14:54:41 <davidhouse> hehe 'fraid so.
14:54:42 <vincenz> davidhouse: it's not a major modif, but it's a deep one, requiring knoweldge of ghc internals at all levels
14:54:53 <davidhouse> vincenz: going to the hackathon? :)
14:54:56 <ForgeAus> linspire? isn't that lindows successor?
14:55:01 <vincenz> davidhouse: wish I could :/
14:55:08 <davidhouse> oh wait, no, you were the one asking for a podcast
14:55:08 <SamB> it *is* lindows
14:55:13 <SamB> but they had to change the name
14:55:14 <vincenz> davidhouse: yep
14:55:18 <davidhouse> ForgeAus: right. they're rewriting it in haskell! :D
14:55:19 <vincenz> vincenz == poucet
14:55:24 <ForgeAus> rofl Davidhouse
14:55:25 <poetix> Not the first place I'd look for cutting-edge Haskell development...
14:55:33 <davidhouse> ForgeAus: no, seriously. they are!
14:55:46 * vincenz oughta get a more obvious nickname
14:55:49 <ForgeAus> davidhouse... ok then.. KEWL!... but still rofl :)
14:55:51 <davidhouse> this is real.
14:55:55 <poetix> A whole bunch of deep-set prejudices just keeled over and died of shock.
14:56:08 <davidhouse> everyone thought it was a badly timed April 1st joke to begin with, but now... :D
14:56:18 <SamB> *what* are they rewriting in Haskell?
14:56:21 <vincenz> davidhouse: got a better nickname suggestion?
14:56:25 <ForgeAus> I'm too Pascal Oriented, I need to see the links to transform what I know into what I don't know
14:56:31 <SamB> linspire is a Linux distribution, isn't it?
14:56:39 <ForgeAus> SamB basically yeah
14:56:42 <poetix> I'm delighted, because it means Haskell will be used in anger for a range of quite high-profile real-world tasks
14:56:46 <SamB> you don't rewrite the entire OS in Haskell!
14:56:51 <ForgeAus> I got Sarge recently, now I just need another HDD to install it on :)
14:56:59 <SamB> "in anger"?
14:57:15 <davidhouse> vincenz: cpoucet? chrisp? hehe i like the latter.
14:57:20 <vincenz> ooh
14:57:22 <vincenz> chrispy
14:57:27 <vincenz> nice one
14:57:28 <poetix> "for real", "seriously", "not just kidding around on some hobby project"
14:57:29 <davidhouse> nice.
14:57:35 * vincenz didn't come to that one cause noone ever calls him "chris"
14:57:42 <davidhouse> vincenz: it'd spoil your domain name, but...
14:57:48 <vincenz> davidhouse: touche
14:57:54 <vincenz> notchrispy
14:57:55 <vincenz> :D
14:58:07 <ForgeAus> Ubuntu has a kewl desktop feature I heard, about its vwm being a cubelike thing... you drag and drop ur desktop or something to get another facet = another virtual desktop... from what I heard it sounded groovy anyhow... (not to be confused with the Java-language groovy of course)
14:58:12 <vincenz> sounds like a bad chips commercial
14:58:26 * xerox has got an headache
14:58:32 <xerox> Math over skype... aww.
14:58:39 <vincenz> xerox: typed?
14:58:40 <davidhouse> vincenz: what's your nationality? your name sounds french, but i though i'd ask
14:58:41 <ForgeAus> skype! lol
14:58:43 <vincenz> xerox: or audio?
14:58:45 <ForgeAus> its got webcam now!
14:58:51 <xerox> Audio.
14:58:51 <vincenz> davidhouse: belgian, flemish, but yeah french name
14:59:07 <vincenz> xerox: ah k, cause typing equations in skype is horrible with the autosmileys
14:59:11 <xerox> ForgeAus: windows only.
14:59:15 <SamB> what was our animal going to be again?
14:59:16 <xerox> vincenz: haha yes.
14:59:18 <davidhouse> xerox: what math?
14:59:23 <ForgeAus> xerox, luckily I got windows
14:59:34 <xerox> davidhouse - Integral integrals integrals...
14:59:37 <xerox> (With a schoolmate.
14:59:46 <davidhouse> ForgeAus: i wouldn't call that lucky... ;)
14:59:47 <vincenz> xerox: single?
14:59:57 <xerox> Yes
15:00:02 <ForgeAus> its quite integral that integrals are integral :)
15:00:03 <xerox> Exercises
15:00:04 <vincenz> infinite ones?
15:00:09 * poetix heads off for bed
15:00:13 <xerox> Both definite and indefinite
15:00:17 <poetix> Night all
15:00:20 <xerox> But I want to talk about something else now, or sleep :)
15:00:31 <vincenz> xerox: what do you think as "chrispy" for my new nick
15:01:05 <ForgeAus> is indefine something like indefine what has been defined, or "unlearn what you have learnt"?
15:01:18 <davidhouse> indefinite integrals.
15:01:22 <xerox> vincenz - o_O
15:01:24 <vincenz> indefinite... without start and end
15:01:37 <vincenz> xerox: my first name is christophe, last name poucet, trying to get a more to the point nick
15:01:45 <davidhouse> as in, given some curve f'(x), find the function f(x) such that f's derivative is f'(x).
15:02:00 <vincenz> davidhouse: you mean f(x)+C
15:02:15 <davidhouse> sure, there's a family of solutions.
15:02:25 <davidhouse> hi ihope
15:02:31 <ihope> Hello.
15:02:54 <vincenz> hi ihope ...high hope
15:02:54 <ForgeAus> like infinites, but I had a big argument over them with a #philosophy channel
15:02:54 <ForgeAus> like.. they were trying to tell me infinity - 1 = infinity...
15:02:58 <ForgeAus> I was sticking up for the little guy - literally... -1 means there is one missing... therefore its not quite infinity anymore.... but they didn't wish to acknowledge the infinitessimal subtraction...
15:03:02 <lennart> lo ihope
15:03:12 <ihope> Hello.
15:03:15 <davidhouse> ForgeAus: mathematically, infty - 1 = infty.
15:03:19 <ForgeAus> imho infinity - 1 cannot be approximated or boiled back down to infinity...
15:03:22 <vincenz> lennart: that a play on high hope?
15:03:28 <vincenz> ForgeAus: it is 
15:03:35 <xerox> \int_{-\inf}^{\inf} e^(-x^2) = ?  (-:
15:03:35 <ForgeAus> davidhouse, perhaps mathematically is wrong?
15:03:40 <vincenz> unless you use the math that allows to work with infinities
15:03:52 * vincenz actually read a math that allowed one to calculate with omegas
15:04:00 <vincenz> but the notation was rather ... odd
15:04:05 <ForgeAus> heheh
15:04:09 <davidhouse> ForgeAus: would you agree to this? two sets of objects are the same size if you can match up every item from the first with an item from the second?
15:04:10 <xerox> ForgeAus - There is no approximation or boiling, it's definitions.
15:04:11 <lennart> vincenz: of course :)
15:04:13 <vincenz> it was with arrows
15:04:19 <ihope> ForgeAus: define infinity.
15:04:37 <ForgeAus> davidhouse, yes but I think your argument wont be matching 1 to 1 each element
15:04:44 <xerox> davidhouse - And then zip [1..] [0..] :-D
15:04:45 <ForgeAus> because you can never reach infinity
15:04:57 <vincenz> ForgeAus: it's provable
15:05:00 <ForgeAus> ie.. whats stored in the "infinitieth" element?
15:05:10 <ihope> ForgeAus: infinity!
15:05:11 <davidhouse> xerox, hehe
15:05:17 <xerox> ForgeAus - It depends on the construction.
15:05:24 <ForgeAus> ihope... not in davidhouses example that he hasn't put forth yet
15:05:33 <davidhouse> ForgeAus: nope, you can match every number in the set {1, 2, 3, ...} with the set {0, 1, 2, ...}.
15:05:35 * xerox is in the mood of Non-Standard Analysis these days.
15:05:55 <ForgeAus> um davidhouse the 0th element? um scrap that its too confusing..
15:06:06 <ForgeAus> plus ppl think your trying to add them and adding 0 is non-consequential
15:06:10 <davidhouse> no, the set containing the items "0", "1", "2",...
15:06:18 <davidhouse> i'm not adding anything.
15:06:18 <vincenz> has as many items as the set containing
15:06:21 <vincenz> "5" ... 
15:06:24 <ForgeAus> I know your not
15:06:29 <vincenz> in fact
15:06:31 <vincenz> for any number N
15:06:39 <ForgeAus> but start from 1 it makes more sense.... and in ur second set start from 2 if you want
15:06:42 <vincenz> {N, N+1, ...} has the same amount of elements as {0,1,...}
15:06:48 <vincenz> erm, any bounded number
15:06:48 <Cufisz> I'm trying to figure out the performance differences between arrays, tuples and lists and there appears to be none. Is this correct?
15:07:01 <Cufisz> My test code can be viewed here: http://www.rafb.net/paste/results/Wme7ej92.html
15:07:02 <vincenz> Cufisz: depends on usage
15:07:03 <davidhouse> vincenz: and the same number as there are in {2, 4, 6, 8, } or {3, 6, 9, 12...} or in general any infinite subset of the rationals.
15:07:10 <vincenz> davidhouse: yep
15:07:10 <xerox> > concat [init $ show $ take 10 $ zip [1..] [0..], ".."]
15:07:11 <lambdabot>  "[(1,0),(2,1),(3,2),(4,3),(5,4),(6,5),(7,6),(8,7),(9,8),(10,9).."
15:07:30 <ForgeAus> lambdabot what happens when you reach the infinitieth element, your one less...
15:07:34 <ForgeAus> ie infinity -1
15:07:43 <Cufisz> from my experience with non-functional languages it seems that accessing the 6th element of a list should be much slower than accessing the 6th element of an array or tuple
15:07:43 <xerox> (n,n-1)
15:07:47 <ForgeAus> therefore infinity - 1 = infinity - 1, no less no more...
15:07:52 <ForgeAus> xerox is right
15:07:53 <ihope> ForgeAus: but you never reach the infinitieth element, so that doesn't matter.
15:08:02 <ForgeAus> ihope how lazy
15:08:06 <vincenz> Cufisz: tuples are kinda pointless cause they can't grow
15:08:14 <ForgeAus> your approximating and ignoring the significant digit 1 here
15:08:19 <xerox> ForgeAus - Each pair is defined as (n,n-1) so it really depends on how you define infinites.
15:08:23 <ihope> Aah.
15:08:31 <davidhouse> ForgeAus: would you agree that if one could prove that there were as many even numbers as (whole) numbers themselves themselves, that infty - 1 = infty? i.e. if infty/2 = infty then certainly infty - 1= infty?
15:08:35 <Cufisz> vincenz: sometimes you don't need growth, like for example 3 dimensional vectors
15:08:44 <vincenz> Cufisz: correct, just pointing it out
15:08:53 <ForgeAus> davidhouse, can you prove that?
15:09:01 <vincenz> Cufisz: in that case tuples are preferred
15:09:02 <xerox> ForgeAus - Yes he can by the same argument.
15:09:04 <ihope> ForgeAus: well, you can't prove anything about infinity until you define infinity. You haven't done that.
15:09:07 <davidhouse> ForgeAus: uep.
15:09:14 <Cufisz> vincenz: care to elaborate? =)
15:09:14 <ForgeAus> xerox, that argument didn't prove anything to me... sofar
15:09:33 <xerox> ForgeAus - Read about Cantor (-:
15:09:34 <Cufisz> and especially what are the advantages of tuples over arrays?
15:09:36 <vincenz> Cufisz: well theh reason being tat you know it'll always have 3 elements, can't suddenly get something with 2 or 4 elements, typecheck ensures it
15:09:50 <ForgeAus> xerox... why, doesn't it support my position?
15:09:58 <vincenz> Cufisz: arrays grow afaik
15:10:05 <ForgeAus> tuples are kewleer
15:10:06 <xerox> ForgeAus - I don't understand your position.
15:10:08 <ForgeAus> grr kewler
15:10:09 <davidhouse> ForgeAus: we construct a function that halves its input. i.e., in haskell, halve x = x/2. Then we feed in, one by one, the even numbers. if we amalgamate its results, we get, completely and wholly, the integers.
15:10:17 <vincenz> Cufisz: and then it's mostly tradeoff between arrays and lists....
15:10:26 <vincenz> Cufisz: which I think would be the same tradeoff as in any language
15:10:34 <xerox> (davidhouse, the naturals.)
15:10:44 <ForgeAus> naturals vs integers now?
15:10:46 <davidhouse> ForgeAus: therefore each even number matches up with one and exactly one integer, and every integer matches up with exactly one even number
15:10:52 <davidhouse> xerox: taking -2 to be even.
15:10:54 <davidhouse> etc.
15:11:06 <vincenz> there must be made a point
15:11:09 <vincenz> this is all true in the math system we use
15:11:14 * ihope whimpers
15:11:17 <vincenz> I have seen a math system that allows working with infinities
15:11:21 <davidhouse> ForgeAus: and therefore, we conclude that, because of that matching-up-property i mentioned ^^ up there, there are as many even numbers as whole numbers.
15:11:22 <xerox> ForgeAus - What is the problem exactly?
15:11:22 <ForgeAus> davidhouse, whats that got to do with infinity?
15:11:24 <vincenz> and even differentiates between omega and omega-1
15:11:40 <ForgeAus> vincenz? omega and omega -1?... whats that?
15:11:40 <Cufisz> vincenz: well with tuples being able to store different types i'd think they would have one extra level of indirection. But as i've said I could not find any performance difference between accessing the 6th element of a list/tuple/array many times.
15:11:45 <xerox> vincenz - Sure there are!
15:11:48 <vincenz> ForgeAus: omega is typically used for infinite
15:11:50 <vincenz> infinity
15:11:50 <ForgeAus> and is this something to do with the transfinite?
15:11:52 <ihope> ForgeAus: the number of whole numbers is infinity...
15:11:56 <ihope> Well...
15:12:04 <ihope> We still haven't defined infinity yet!
15:12:08 <ForgeAus> hehe ihope thats self-referential
15:12:16 <ForgeAus> try the count of whole numbers is infinity???
15:12:18 <xerox> vincenz - Non-standard extension of the reals, the hyperreals, define more-than-everything and less-than-nothing formally.
15:12:22 <vincenz> Cufisz: well perhaps because of all the function call indirectio
15:12:22 <ForgeAus> thats probably also circular uh?...
15:12:27 <SamB> Cufisz: maybe you didn't access it many times?
15:12:34 <ihope> ForgeAus: hmm?
15:12:40 <davidhouse> ForgeAus: if you would prefer a less mathematical proof, then picture a hotel with an infinite number of rooms. suddenly, an infinite number of people turn up and they all want a room! no problem, we just move every guest in room number n to room number 2n.
15:12:41 <vincenz> xerox: less-than-nothing?
15:12:50 <vincenz> xerox: nothing being -omega?
15:12:50 <xerox> vincenz - Yes, aka infinitesimals.
15:12:58 <vincenz> xerox: you mean more than nothing
15:12:58 <davidhouse> so the guy in 4 goes to 8, etc. now we have an infinite amount of free rooms for everyone to fit in!
15:12:59 <ForgeAus> davidhouse I can't picture a hotel with an infinite number of rooms
15:13:05 <Cufisz> vincenz: hmm, possibly
15:13:08 <ForgeAus> its not possible for you too either
15:13:10 <vincenz> xerox: a very small number bigger than 0
15:13:16 <davidhouse> ForgeAus: use your imagination.
15:13:23 <xerox> vincenz - No, that's a real number.
15:13:25 <ihope> ForgeAus: well, but do you see anything wrong with his argument?
15:13:34 <ForgeAus> I can use my imagination all I like but I'd never be able to fit an infinite number of rooms in there
15:13:41 <mahogny> hilberts hotel is one bitch
15:13:46 * mahogny hates infinity
15:13:46 <vincenz> xerox: not if it's smaller than 10^(-omega)
15:13:46 <ForgeAus> perhaps you don't understand the concept of infinity?....
15:13:54 <vincenz> xerox: or 1/omega
15:13:56 * ihope sighs.
15:14:00 <davidhouse> all right then, the gloves areoff.
15:14:00 <ihope> What's infinity?
15:14:08 <xerox> vincenz - I don't know this omega you are talking about.
15:14:10 <vincenz> either way
15:14:10 <SamB> > 1 / 0
15:14:11 <lambdabot>  Infinity
15:14:12 <vincenz> the point is moot
15:14:15 <ForgeAus> ihope infinity never ends....
15:14:15 <mahogny> infinity doesn't exist
15:14:16 <vincenz> our whole universe is based on finities
15:14:21 <ihope> ForgeAus: but what is it?
15:14:26 <xerox> vincenz - I think the ``almost nothing'' is what I wanted to say really.
15:14:26 <ihope> Many things never ends.
15:14:28 <ForgeAus> exactly vincenz :)
15:14:28 <vincenz> and our whole universe is discrete
15:14:35 <vincenz> even lengths
15:14:39 <ForgeAus> almost nothing you mean infinitessimal?
15:14:39 <vincenz> the base unit being a planck length
15:14:40 <davidhouse> ForgeAus: right! infinity never ends! but then nor does infinity - 1!
15:14:41 <ihope> s/ends./end./
15:14:45 <lennart> > let infinity = infinity + 1 in infinity
15:14:46 <lambdabot>  Terminated
15:14:55 <vincenz> xerox: ah ;)
15:15:11 <SamB> > let infinity - 1 = infinity in infinity
15:15:12 <lambdabot>  Not in scope: `infinity'
15:15:15 <vincenz> did you know that if you take sizes smaller than a planck length they actually get bigger again?
15:15:16 <int-e> > let infinity = 1/0 in infinity + 1
15:15:16 <ForgeAus> davidhouse, hmmm that I'm not sure of.. but even if it doesn't end, its imaginary endpoint would be one less than the endpoint of infinity...
15:15:17 <lambdabot>  Infinity
15:15:21 <SamB> > let (infinity - 1) = infinity in infinity
15:15:21 <lambdabot>  Parse error in pattern
15:15:29 <ForgeAus> lol SamB :)
15:15:31 <SamB> > let (infinity + (-1)) = infinity in infinity
15:15:31 <lambdabot>  Parse error in pattern
15:15:38 * xerox shakes SamB 
15:15:38 <vincenz> aka the inverse point of the universe lies at a planck length... go smaller and everything behaves like plancklength/length
15:15:55 <davidhouse> ForgeAus: but there is no end point. that's the entire point (no pun intended)! so there is precisely nothing to distinguish infinity and infinity - 1.
15:16:06 <SamB> does dons's parser not do n+k patterns?
15:16:07 <ihope> Yeah!
15:16:11 <vincenz> floating point numbers are useless
15:16:17 <SamB> or do you actually need a positive k?
15:16:23 <int-e> > (\(1+n) -> n) 0
15:16:23 <lambdabot>  Parse error in pattern
15:16:31 <int-e> > (\(n+1) -> n) 0
15:16:32 <lambdabot>  Parse error in pattern
15:16:36 <ihope> What's the *difference* between infinity and infinity-1?
15:16:36 <int-e> good :)
15:16:37 <vincenz> int-e: I think that's a hack that only works for toplevels
15:16:39 <int-e> I hate those.
15:16:43 <davidhouse> > let (n+1) = 5 in n
15:16:43 <lambdabot>  Parse error in pattern
15:16:45 <xerox> > let f (n+1) = n in f 1
15:16:46 <lambdabot>  Parse error in pattern
15:16:49 <davidhouse> > let (n + 1) = 5 in n
15:16:50 <lambdabot>  Parse error in pattern
15:16:55 <davidhouse> huh. used to work.
15:16:56 <vincenz> > let f n+1 = 5 in f 4
15:16:57 <lambdabot>  Parse error in pattern
15:16:58 <SamB> still, it *is* standard Haskell!
15:17:02 <xerox> davidhouse - Really?!
15:17:02 <vincenz> > let f (n+1) = 5 in f 4
15:17:02 <lambdabot>  Parse error in pattern
15:17:05 <ihope> > let f (x+1) = x in f 3
15:17:05 <lambdabot>  Parse error in pattern
15:17:09 <davidhouse> xerox, yeah, i was shocked too.
15:17:10 <vincenz> I think only for toplevels!
15:17:12 <ihope> Okay, it doesn't work!
15:17:15 <xerox> Geez.
15:17:18 <SamB> davidhouse: I bet he broke it when he put in that parser to make sure the given code was actually an expression...
15:17:27 <davidhouse> oooh! but check this out:
15:17:29 <davidhouse> > not
15:17:29 <SamB> and not something involving ) ( in the middle somewhere
15:17:30 <lambdabot>  <Bool -> Bool>
15:17:32 <davidhouse> !!!
15:17:34 <vincenz> davidhouse: :)
15:17:39 <vincenz> > (:)
15:17:40 <lambdabot>  Add a type signature
15:17:51 <davidhouse> only works if it doesn't involve type variables
15:17:52 <vincenz> > (:) :: (Char -> [Char] -> [Char])
15:17:53 <lambdabot>  <Char -> [Char] -> [Char]>
15:17:59 <davidhouse> (i.e. monomorphic functions)
15:18:08 <vincenz> davidhouse: yeah cause it needs to call a specific show
15:18:09 <int-e> > let x = (:); y = x 'a' undefined in x
15:18:10 <lambdabot>  Add a type signature
15:18:27 <xerox> vincenz - <http://mathforum.org/dr.math/faq/analysis_hyperreals.html>
15:18:29 <vincenz> int-e: let bindings are polymorphic
15:18:43 <vincenz> xerox: now regarding my new nick
15:18:45 <davidhouse> ooh, hyperreals :)
15:18:46 <int-e> vincenz: even monomorphic ones?
15:18:47 <lennart> Oh, has showing functions reached what hbc did in 1989 now :)
15:18:48 <vincenz> who votes for chrispy
15:18:55 <davidhouse> vincenz: me! :)
15:19:01 <vincenz> int-e: huh...(:) is polymorphic, hence so is x
15:19:11 <xerox> vincenz, it sounds like chris-py.
15:19:17 <vincenz> no like crispy
15:19:22 <vincenz> hi
15:19:23 <SamB> lennart: presumably it is a special feature of @eval
15:19:28 <vincenz> whoops, wrong window
15:19:31 <int-e> vincenz: err, wrong wording. I was trying to ask if the MR doesn't apply to let bindings.
15:19:53 <vincenz> int-e: things bound by let are polymorphic unless they directly bind to a monomorphic function
15:19:55 <ihope> Monomorphism restriction?
15:19:57 <vincenz> like this
15:19:58 <ihope> Hmm...
15:20:01 <Forgacius> back
15:20:06 <int-e> ihope: yes
15:20:08 <ihope> > asTypeOf True
15:20:09 <lambdabot>  <Bool -> Bool>
15:20:10 <vincenz> > let x = \a -> a in (x 'a', x 1)
15:20:12 <lambdabot>  ('a',1)
15:20:14 <davidhouse> MR does apply to lets.
15:20:14 <vincenz> hmm
15:20:20 <davidhouse> annoyingly. grr.
15:20:23 <int-e> > let x = 0 in ([1]!!x, x/2)
15:20:23 <lambdabot>  add an instance declaration for (Fractional Int)
15:20:24 <lambdabot>   In the definition of `tld': tld = let x = 0 in ([1] !! x, x / 2)
15:20:24 <lambdabot>   In the definition of `qoz':
15:20:24 <xerox> Goodnight.
15:20:25 * davidhouse stabs the MR
15:20:31 <davidhouse> bye, xerox
15:20:36 <ihope> What *is* the MR?
15:20:37 <int-e> looks monomorphic to me, even though 0 is polymorphic
15:21:01 <int-e> > let x = (:); y = x 'a' undefined in (x,y)
15:21:02 <lambdabot>  Add a type signature
15:21:16 <int-e> > let x = (:); y = x 'a' undefined in x 'a'
15:21:17 <lambdabot>  <[Char] -> [Char]>
15:21:20 * int-e shrugs
15:21:27 <davidhouse> ihope: you can't have polymorphism in some places :) i.e. see what int-e did with the tuple.
15:22:44 <vincenz> so
15:22:45 <vincenz> chrispy?
15:22:46 <ihope> davidhouse: judging by the "Add a type signature", there was some polymorphism in there...
15:22:47 <vincenz> vincenz?
15:22:51 <vincenz> chris-p
15:22:55 <int-e> > 1+1 where x=32
15:22:55 <lambdabot>  Parse error
15:23:08 <ihope> > let x = 32 in 1+!
15:23:08 <lambdabot>  Parse error
15:23:11 <ihope> > let x = 32 in 1+1
15:23:12 <lambdabot>  2
15:23:19 <ihope> vincenz: ?
15:23:28 <vincenz> ihope: a new more relevant nickname
15:23:34 <vincenz> ihope: my full name is "christophe poucet"
15:23:54 <davidhouse> ihope:
15:24:03 <davidhouse> > let x = 0 in ([1]!!x, x/2) -- this one
15:24:03 <lambdabot>  Unterminated end-of-line comment
15:24:33 <ihope> > let x = 0 in ([1]!!x, x/2)
15:24:34 <lambdabot>  add an instance declaration for (Fractional Int)
15:24:34 <lambdabot>   In the definition of `mas': mas = let x = 0 in ([1] !! x, x / 2)
15:24:34 <lambdabot>   In the definition of `aak':
15:24:38 <ihope> I see.
15:25:22 <ihope> Yep, that's pretty evil.
15:25:38 <int-e> davidhouse: so what's the significant difference between  let x = (:); y = x 'a' in x  and  let x = 0 in ([1]!!x, x/2) ?
15:26:10 <davidhouse> does the former work?
15:26:14 <ihope> > let foo = ([1]!!x, x/2) where x = 0 in foo
15:26:15 <lambdabot>  add an instance declaration for (Fractional Int)
15:26:15 <lambdabot>   In the definition of `foo':
15:26:15 <lambdabot>    foo = ([1] !! x, x / 2)
15:26:33 <davidhouse> wait.
15:26:40 <int-e> @type (let x = (:); y = x 'a', let x = 0 in ([1]!!x, x/2))
15:26:41 <lambdabot> parse error on input `,'
15:26:46 <davidhouse> why would the former not work?
15:26:49 <ihope> > let x = 0; foo = [1] !! x in x/2
15:26:50 <lambdabot>  add an instance declaration for (Fractional Int)
15:26:50 <lambdabot>   In the definition of `zgn':
15:26:50 <lambdabot>    zgn = let
15:26:51 <int-e> @type (let x = (:); y = x 'a' in x, let x = 0 in ([1]!!x, x/2))
15:26:52 <lambdabot>   No instance for (Fractional Int)
15:26:52 <lambdabot>   arising from use of `/' at <interactive>:1:53
15:27:21 <int-e> ah dangit. the first type ends up being polymorphic, a -> [a] -> [a].
15:27:27 <vincenz> > let x = \a -> a in (x 'a', x 1)
15:27:28 <lambdabot>  ('a',1)
15:27:30 <vincenz> why does this work
15:27:34 <vincenz> lambdas are monomorphic
15:27:51 <ihope> vincenz: they are?
15:27:55 <vincenz> I guess it optimizes it to
15:27:56 <vincenz> x a = a
15:27:57 <int-e> @type let x = 0; y = []!!0; z = 0/1 in x
15:27:58 <lambdabot> forall t. (Num t) => t
15:28:00 <vincenz> ihope: yes
15:28:04 <int-e> @type let x = 0; y = []!!x; z = x/1 in x
15:28:05 <lambdabot>   No instance for (Fractional Int)
15:28:05 <lambdabot>   arising from use of `/' at <interactive>:1:27
15:28:08 <ihope> @type let x = 0; foo = [1] !! x in x
15:28:09 <lambdabot> Int
15:28:19 <ihope> Dang...
15:28:50 <vincenz> so nickname suggestions?
15:30:06 <ihope> @vincenz
15:30:06 <lambdabot> Unknown command, try @list
15:30:23 <ihope> That would make a nice nickname. :-P
15:30:28 <vincenz> @vincenz?
15:30:29 <lambdabot> Unknown command, try @list
15:30:32 <int-e> @type (let x = succ; y = x (1::Int) in x, (let x = id; y = x (1::Int) in x)
15:30:33 <lambdabot> parse error (possibly incorrect indentation)
15:30:41 <vincenz> already have that in #oasis 
15:30:49 <ihope> @type (let x = succ; y = x (1::Int) in x, (let x = id; y = x (1::Int) in x))
15:30:50 <lambdabot> forall a.
15:30:50 <lambdabot>                          (Int -> Int, a -> a)
15:31:13 <int-e> I think that's strange.
15:31:43 <ihope> vincenz: I don't see a guy named "list" there.
15:32:33 <ihope> Now, this probably won't work:
15:33:01 <int-e> @type (let x = succ in x, let x = id in x)
15:33:02 <lambdabot> forall a a1.
15:33:02 <lambdabot>               (Enum a) =>
15:33:02 <lambdabot>               (a -> a, a1 -> a1)
15:33:21 <davidhouse> > let in ()
15:33:21 <lambdabot>  ()
15:33:24 <davidhouse> :)
15:33:34 <ihope> @type {-# OPTIONS=-fno-monomorphism-restriction #-} (let x = succ; y = x (1::Int) in x, (let x = id; y = x (1::Int) in x))
15:33:35 <lambdabot> forall a.
15:33:35 <lambdabot>                          (Int -> Int, a -> a)
15:33:42 <ihope> Tee hee.
15:33:46 <int-e> nah, that's just a comment
15:34:00 <davidhouse> besides, the syntax was wrong ;)
15:34:13 <ihope> So what is it?
15:34:16 <davidhouse> {-# OPTIONS_GHC -fno-monomorphism-restriction #-}
15:34:19 <davidhouse> no equals, _GHC.
15:34:44 <ihope> @type {-# OPTIONS_GHC -fno-monomorphism-restriction #-} (let x = succ; y = x (1::Int) in x, (let x = id; y = x (1::Int) in x))
15:34:45 <lambdabot> forall a.
15:34:45 <lambdabot>                          (Int -> Int, a -> a)
15:34:56 <ihope> Okay, enough of that.
15:36:22 <SamB> it ought to complain that the pragma is too far down...
15:37:15 <davidhouse> it's only a @type, it probably doesn't analyse pragmas.
15:42:08 <int-e> @version
15:42:09 <lambdabot> lambdabot 3.1p18, GHC 6.4.1 (Linux i686 3.20GHz)
15:42:09 <lambdabot> darcs get http://www.cse.unsw.edu.au/~dons/lambdabot
15:43:16 <int-e> I think it's not recognized as a pragma without -fglasgow-exts. (the first line for OPTIONS_GHC being the sole exception).
15:43:32 <int-e> and -fglasgow-exts is (luckily) not used by plugs.
15:45:35 <davidhouse> int-e: it's not?
15:45:39 <davidhouse> @type map
15:45:40 <lambdabot> forall b a. (a -> b) -> [a] -> [b]
15:45:55 <davidhouse> it uses existensitials. that's glasgow-exts.
15:46:28 <int-e> @type is implemented differently
15:46:29 <lambdabot> Not in scope: `is'
15:46:29 <lambdabot>  
15:46:29 <lambdabot> <interactive>:1:3: Not in scope: `implemented'
15:46:42 <int-e> @type putStrLn
15:46:43 <lambdabot> String -> IO ()
15:46:49 <int-e> it knows IO, for example.
15:47:09 <davidhouse> ah.
15:48:56 <ihope> > putStrLn
15:48:57 <lambdabot>  <[Char] -> IO ()>
15:50:51 <ihope> Why [Char] and not String?
15:51:36 <int-e> look at http://www.cse.unsw.edu.au/~dons/lambdabot/scripts/ShowQ.hs
15:52:14 <int-e> well, I guess you should look at Data.Dynamic
15:58:07 <davidhouse> argh.
15:58:18 <davidhouse> it annoys me when i see m >>= return . f
15:58:28 <davidhouse> it's like, "liftM is there for a reason! :)"
15:58:45 <mauke> I use >>+ for that
15:58:53 <int-e> @index >>+
15:58:53 <lambdabot> bzzt
15:58:57 <int-e> @index (>>+)
15:58:57 <lambdabot> bzzt
15:59:01 <davidhouse> @hoogle (>>+)
15:59:01 <lambdabot> Did you mean: (>>+)
15:59:02 <lambdabot> Prelude.undefined :: a
15:59:02 <lambdabot> Control.Monad.Reader.ask :: MonadReader r m => m r
15:59:08 <mauke> no, I mean I defined it first
15:59:20 <davidhouse> ah. :)
15:59:31 <davidhouse> why not use one of the two functions that already do it?
15:59:52 <mauke> token '-' >> ((noneOf "\\]" <||> (token '\\' >> anyToken)) >>+ flip enumFromTo) looks better
16:00:02 <int-e> davidhouse: actually I disagree. I tend to dislike liftM for the reason that I tend to dislike =<< - the operations show up in the code in the wrong order.
16:00:45 <ndm> hoogle seems to go off the wall for that last query...
16:00:50 <davidhouse> int-e, okay, but >>= return is still a waste.
16:01:04 <ndm> i do that all the time, what is the equivalent with liftM?
16:01:13 <ndm> (i'm still new to the whole monad thingy...)
16:01:17 <mauke> liftM f m
16:01:18 <davidhouse> hehe
16:01:28 <int-e> liftM f m1              = do { x1 <- m1; return (f x1) }
16:01:37 <int-e> straight from Control.Monad :P
16:02:30 <davidhouse> @type (ask >>= return . toUpper, liftM toUpper ask, fmap toUpper ask, asks toUpper)
16:02:31 <lambdabot> forall (m :: *
16:02:31 <lambdabot>                                 -> *)
16:02:31 <lambdabot>                               (m1 :: *
16:02:31 <lambdabot>                                 -> *)
16:02:31 <lambdabot>                               (m2 :: *
16:02:33 <lambdabot> [16 @more lines]
16:02:38 <davidhouse> eurgh.
16:02:41 <davidhouse> they're equivalent.
16:02:53 <ihope> @hoogle asks
16:02:54 <lambdabot> Control.Monad.Reader.asks :: MonadReader r m => (r -> a) -> m a
16:03:04 <davidhouse> normally used with a selector function
16:03:21 <int-e> wee, another name for id
16:03:25 <ihope> So what's with all these monads having classes to go with them?
16:03:28 <davidhouse> e.g. if your environment is R { a :: Bool, b :: String }, then asks a is a nice idiom.
16:03:39 <int-e> > asks (:) 'a' "bcd"
16:03:39 <lambdabot>  "abcd"
16:04:01 <davidhouse> ihope: so you can write your own, say, Reader, and swap it in with little or no impact
16:04:06 <int-e> > ask (:) 'a' "bcd"
16:04:07 <lambdabot>  "abcd"
16:04:31 <ihope> @hoogle ask
16:04:31 <davidhouse> huh? i'm sure that's not true in general.
16:04:32 <lambdabot> Control.Monad.Reader.ask :: MonadReader r m => m r
16:04:32 <lambdabot> Control.Monad.Reader.asks :: MonadReader r m => (r -> a) -> m a
16:04:32 <lambdabot> Distribution.Extension.TemplateHaskell :: Extension
16:04:51 <ihope> davidhouse: so is MonadReader just Monad with ask tossed in as a class value?
16:05:12 <davidhouse> ihope, right. it's also got a slightly different kind requirement.
16:05:24 <davidhouse> it requires that your monad be parametrised over its environment.
16:05:28 <int-e> davidhouse: well, ask = id, asks = ($) if you like. and of course that's just the version for the (->) r monad.
16:05:35 <ihope> It requires what now?
16:05:58 <davidhouse> int-e, yeah.
16:06:10 <davidhouse> ihope, you say instance Monad (Reader env), but instance MonadReader Reader
16:06:26 <davidhouse> instance of Monad need to be * -> *, but for MonadReader, it needs to be * -> * -> *
16:06:39 <davidhouse> i.e. it requires that the type of your environment be a type parameter
16:06:54 <ihope> Ah.
16:06:55 <davidhouse> i.e. it requires you to be parametrised over the type of your environment :)
16:07:21 <ihope> @hoogle State
16:07:22 <lambdabot> Control.Monad.State :: module
16:07:22 <lambdabot> Control.Monad.State.State :: (s -> (a, s)) -> State s a
16:07:22 <lambdabot> Control.Monad.State.State :: newtype State s a
16:07:29 <ihope> @hoogle StateMonad
16:07:30 <lambdabot> No matches found
16:07:31 <davidhouse> MonadStat's the same.
16:07:40 <ihope> Ah, right.
16:08:09 <davidhouse> but with get and put as its class methods.
16:08:28 <davidhouse> there's a MonadCont too, i think, but i wouldn't go near that if i were you :)
16:08:47 * ihope goes near it
16:08:51 * ihope screams and runs away
16:09:11 <davidhouse> hehe.
16:09:43 <mux> The MonadCont hits! The MonadCont hits! You die..--More--
16:10:25 <ihope> ihope (Cav Dwa Mal Law), 332 points, killed by callCC
16:10:31 <davidhouse> i can see the spotty 12 year olds at it now:
16:11:22 <davidhouse> "Nooo, the MonadCont!" "Quick, deploy the lambda troops!" "Argh, no good, it's got us with its first-class callbacks."
16:11:39 <davidhouse> s/callbacks/continuations
16:12:18 <lennart> The continuation beast is harmless.  You just have to stare it down.  Show nofear, or it will eat you.
16:13:04 <ihope> @djinn (((a -> Cont r b) -> Cont r a) ->  a)
16:13:04 <lambdabot> -- f cannot be realized.
16:13:18 * ihope kills his keyboard
16:13:27 <lennart> @djinn-env
16:13:28 <lambdabot> data () = ()
16:13:28 <lambdabot> data Either a b = Left a | Right b
16:13:28 <lambdabot> data Maybe a = Nothing | Just a
16:13:28 <lambdabot> data Bool = False | True
16:13:28 <lambdabot> data Void
16:13:30 <lambdabot> type Not x = x -> Void
16:14:16 <ihope> @djinn-add callCC :: (((a -> Cont r b) -> Cont r a) -> Cont r a)
16:14:29 <ihope> @djinn ((a -> r) -> r) -> Cont r a
16:14:30 <lambdabot> -- f cannot be realized.
16:14:50 <ihope> @djinn Cont r a -> (a -> r) -> r
16:14:50 <lambdabot> -- f cannot be realized.
16:14:56 <ihope> I still don't get it.
16:14:59 <lennart> why add callCC?  it's perfectly happy to find that for you.
16:15:12 <ihope> lennart: not without a definition of Cont!
16:15:22 <lennart> very true :)
16:15:48 <ihope> I just plain don't get callCC.
16:15:53 <ihope> Well...
16:16:20 <ihope> I get what it does, but I don't get its implementation, nor how it could be so useful.
16:16:28 <lennart> @djinn-del callCC
16:16:36 * davidhouse likes to pretend continuations don't exist
16:16:41 <davidhouse> lennart: heh, it's for the best. :)
16:16:51 <lennart> @djinn-add Cont r a = Cont ((a -> r) -> r)
16:16:52 <lambdabot> Cannot parse command
16:17:08 <lennart> @djinn-add data Cont r a = Cont ((a -> r) -> r)
16:17:19 <lennart> what about callCC don't you get?
16:17:29 <mux> I read somewhere in the wiki that people often use a Reader monad with a record of IORefs to simulate global variables efficiently
16:17:49 <ihope> Well, there doesn't seem to be much to differentiate its type from ((a -> b) -> a) -> a.
16:17:51 <mux> is there a reason not to have just one IORefs poiting on a record instead?
16:18:16 <Cale> mux: not much of one
16:18:28 <lennart> ihope: you can think of the implementation as taking a copy of the whole machine state at the point you call callCC so that it can be reused later
16:18:53 <ihope> Eh, I'm tires.
16:18:57 <ihope> I'm tired, too.
16:18:58 <Cale> mux: you can do it either way, but having a record of IORefs will involve slightly less work when doing updates.
16:19:08 <lennart> ihope: it would have type ((a->b)->a)->a if it were first class in Haskell
16:19:21 <davidhouse> @djinn-add data Ihope = Tires
16:19:25 <mux> Cale: ok, thanks
16:19:27 <lennart> or a type similar to that
16:19:48 <mux> Cale: is that due to the strictness of the records?
16:19:58 <davidhouse> > undefined `seq` "blargh"
16:20:01 <lennart> @djinn Ihope
16:20:06 <ihope> Maybe after a while I'll be able to grok and parse.
16:20:07 <lambdabot>  Undefined
16:20:07 <lambdabot> f = Tires
16:20:07 <Cale> mux: If you have an IORef pointing at a record, when you want to update one of the record fields, you'll end up creating a new record value, which means copying a bunch of pointers.
16:20:27 <mux> Cale: *nods* ok
16:20:39 <lennart> btw, hi Cale :)
16:20:41 <davidhouse> > (undefined $) `seq` "blargh"
16:20:42 <lambdabot>  "blargh"
16:20:43 <Cale> hello
16:21:18 <mux> @version
16:21:18 <lambdabot> lambdabot 3.1p18, GHC 6.4.1 (Linux i686 3.20GHz)
16:21:18 <lambdabot> darcs get http://www.cse.unsw.edu.au/~dons/lambdabot
16:22:07 <davidhouse> is ($ x), x /= _|_ strict?
16:22:49 <lennart> yes
16:23:13 <davidhouse> i.e. is it true that, for all x /= _|_, _|_ x = _|_?
16:23:16 <davidhouse> righ.t
16:23:29 <ihope> Okay.
16:23:29 <lennart> yes
16:23:34 <ihope> @hoogle callCC
16:23:35 <lambdabot> Control.Monad.Cont.callCC :: MonadCont m => ((a -> m b) -> m a) -> m a
16:24:08 <lennart> to evaluate a function call you need to use the function, so application is strict in the function
16:24:29 <ihope> So, again, that's ((a -> Cont r b) -> Cont r a) -> Cont r a, which is the same as Cont (Cont r a) (a -> Cont r b).
16:24:54 <lennart> @djinn ((a -> Cont r b) -> Cont r a) -> Cont r a
16:24:54 <lambdabot> f a =
16:24:55 <lambdabot>   Cont (\ b ->
16:24:55 <lambdabot>     case a (\ c -> Cont (\ _ -> b c)) of
16:24:55 <lambdabot>     Cont d -> d b)
16:25:17 <Cale> @djinn Cont (Cont r a) (a -> Cont r b)
16:25:17 <lambdabot> f = Cont (\ a ->
16:25:18 <lambdabot>     Cont (\ b ->
16:25:18 <lambdabot>       case a (\ c -> Cont (\ _ -> b c)) of
16:25:18 <lambdabot>       Cont d -> d b))
16:25:45 <lennart> ihope: yes they are the same.  I've never thought of that.  I wonder if it means something? :)
16:25:59 <ihope> Now, the thingies.
16:26:01 <davidhouse> night all.
16:26:43 <ihope> Reader a (Reader b c) = Reader (a, b) c.
16:26:53 <ihope> Can we do something similar with that thing above?
16:28:21 <aFlag> Is there any way to access a arbitrary element inside a data structure in O(1) time?
16:28:35 <Cale> in any data structure?
16:28:43 <lennart> aFlag: depends on what the data structure is
16:28:52 <Cale> In an array
16:28:55 <mux> it's possible with an array
16:29:13 <ihope> Oh, right.
16:29:27 <ihope> (((a -> r) -> r) -> s) -> s
16:29:34 <ihope> What's that?
16:29:35 <aFlag> hum, are they defined using only haskell?
16:29:52 <aFlag> or are those array primitives?
16:29:53 <lennart> aFlag: no
16:29:59 <Cale> aFlag: they're defined as a part of Haskell.
16:30:02 <lennart> aFlag: primitives
16:30:24 * ihope thinks
16:30:26 <mux> aFlag: haskell has many kinds of arrays, with two distinct interfaces for purely functional arrays and for mutable arrays
16:30:47 <Cale> http://www.haskell.org/haskellwiki/Arrays
16:31:18 <mux> yeah, that pages is a very good read
16:31:32 <ihope> ((a -> Cont r b) -> Cont r a) -> Cont r a... nope, that type's meaningless to me.
16:31:58 <lennart> It's hard to say anything about complexity for Haskell since the Haskell definition doesn't mention complexity (except for O(1) indexing in arrays)
16:32:10 <lennart> ihope: me too :)
16:32:26 <ihope> Going the other way: ((a -> (b -> r) -> r) -> (a -> r) -> r) -> (a -> r) -> r.
16:32:33 <ihope> That's pretty durn big.
16:32:34 <Cale> It actually doesn't even say that it needs to be O(1)
16:32:46 <Cale> iirc, it says something like "in a timely fashion"
16:32:55 <lennart> I thought it did (at least it used to) for arrays
16:32:58 <lennart> ah
16:33:18 <Cale> "a programmer may reasonably expect rapid access to the components"
16:33:19 <mux> aFlag: btw, grabbing the head element of a list is O(1)
16:33:28 <ihope> Well, okay. Enough of the type. What does callCC *do*?
16:33:28 <lennart> ihope: I get my best understaing of callCC purely operationally
16:33:34 <mux> aFlag: so, depending on how you need to access the data, sometimes lists are just enough
16:33:50 <lennart> ihope: it takes a copy of the machine state so you can use it again later
16:34:33 <Pseudonym> ihope: It's like setjmp() in C.
16:34:37 <Pseudonym> Operationally speaking.
16:34:42 <lennart> ihope: give me 5 minutes at a whiteboard and you'll understand it fine :)
16:34:56 * ihope gives lennart a whiteboard
16:35:18 <lennart> Pseudonym: except that callCC can be used even when you have exited the "scope" of the call
16:35:19 <aFlag> yeah, I didn't have any specific problem in mind. I was just thinking about if I'd be able to write a data structure which I could make an arbitrary access at O(1) time
16:35:50 <Pseudonym> http://www.haskell.org/hawiki/MonadicContinuationPassingStyle
16:35:58 <Pseudonym> That has a good example.
16:36:00 <mux> I've never used the hastable module so I don't know if it's good, but it's there
16:36:27 <mux> it only gives O(1) when there are no collisions of course
16:36:36 <ihope> lennart: http://i4.tinypic.com/10znts7.png <- here's your whiteboard. Now write!
16:37:03 <lennart> ihope: nono, it's the whole animation and talking that goes with it
16:37:04 <Pseudonym> mux: Hashtables give O(1) access times if you keep the loading constant.
16:37:10 <Pseudonym> i.e. if you expand them as they grow
16:37:21 <mux> that's another way of saying what I said :)
16:37:33 <Pseudonym> No, you said "when there are no collisions".
16:37:47 <lennart> mux: well, but you can get O(1) amortized complexity if you grow as needed
16:38:09 <mux> yeah yeah.
16:38:14 <Pseudonym> The conditions for O(1) amortised complexity are that you need to grow geometrically (at least) and the hash function needs to be good.
16:38:17 <Pseudonym> But we knew that, of course.
16:38:35 <aFlag> so it's not possible to implement a data structure that has a O(1) arbitrary acess, such as an array, using only pure functions?
16:38:52 <lennart> aFlag: not as far as we know :)
16:38:54 <ihope> @type Control.Monad.Cont.Cont const
16:38:55 <lambdabot>   Occurs check: cannot construct the infinite type: t = a -> b -> t
16:38:55 <lambdabot>   Expected type: (a -> b -> t) -> b -> t
16:38:59 <ihope> Ack!
16:39:09 <ihope> @type Control.Monad.Cont.Cont . const
16:39:11 <lambdabot> forall a a1.
16:39:11 <lambdabot>             a1 -> Control.Monad.Cont.Cont a1 a
16:39:30 <Cale> aFlag: not and which has an arbitrary size
16:39:35 <Pseudonym> aFlag: No, but it's possible to make the constant factor arbitrary low.
16:39:53 <Pseudonym> You could, in theory, implement arbitrary-ply B-trees, for example.
16:40:03 <lennart> aFlag: but O(log n), and log_2 n is (as we know) < 64 :)
16:40:16 <Cale> data ArrayTen a = A10 a a a a a a a a a a
16:40:21 <ihope> Nope, I still don't get it.
16:40:50 <Cale> You get the same access time to all the components there, but there are obviously problems with that :)
16:41:03 <mux> Cale: would be interesting to see how many components the runtime can handle before collapsing
16:41:36 <Pseudonym> \
16:42:06 <Cale> O(log n) is usually good enough if the constant isn't so bad anyway.
16:42:54 <Pseudonym> And 640kb ought to be enough for anybody.
16:42:56 <aFlag> Pseudonym, what's arbitrary-ply?
16:43:09 <Pseudonym> The kicker, of course, is that updates require O(log n) _allocations_.
16:43:18 <Pseudonym> Which may not be desirable.
16:43:30 <Pseudonym> aFlag: A binary tree is 2-ply.
16:43:32 <lennart> When I was younger we said "log n < 32", but the bound grows ;)
16:43:33 <Pseudonym> Two children per node.
16:43:46 <Pseudonym> When I was younger, log n < 16.
16:43:47 <aFlag> lennart, what's that 64 magic number? I've seen other people saying that some algorithm never takes more than 64 itarations in practice, and stuf like that
16:43:56 <Pseudonym> Unless you swapped to the floppy drive.
16:44:05 <lennart> Pseudonym: did you have to eat poison as a child too?
16:44:09 <aFlag> oh, i see your point
16:44:37 <Pseudonym> No, just freezing cold gravel.
16:44:47 <lennart> Lucky you!
16:44:53 <Pseudonym> Luxury!
16:45:24 <Pseudonym> Our mercury tube RAM got useless if it was a hot day.
16:45:50 <Pseudonym> And we'd have to enter the boot loader by hand using the switch panel!
16:46:04 <lennart> well, me too :)
16:46:17 <lennart> though I never had any mercury tube RAMs
16:46:17 <ihope> Okay. callCC provides a way to exit from a computation, right?
16:46:35 <Pseudonym> That's one use for it, yes.
16:46:40 <Pseudonym> Probably the most common, in fact.
16:46:42 <lennart> ihope: exiting is one way of using it.  that's like setjmp()/longjmp()
16:46:54 <ihope> Okay... what's another use?
16:47:11 <lennart> "exiting" again after you have already exited the first time
16:48:38 <ihope> Wouldn't you have to enter it again for that to work?
16:48:55 <lennart> if you have the expression "callCC foo" and foo save the continuation somewhere and never uses it then you come back from callCC.  if at some later point you use the saved continuation you will return from callCC.  Again!
16:49:20 <lennart> And you can do it over and over.
16:49:42 <ihope> Could I do "cc <- callCC id" to get the currect continuation?
16:51:00 <ihope> Hmm... but then applying cc would have to produce something of the same type as cc, and GHC doesn't like that.
16:51:59 <lennart> You need to use some types to do it.
16:53:55 <lennart> http://www.cs.chalmers.se/Cs/Grundutb/Kurser/afp/lec-20051118.html
16:58:03 <lennart> ihope?
16:58:18 <ihope> I'm here.
16:58:39 <lennart> did you look at the link i sent?
17:00:02 <ihope> Yeah.
17:00:46 <lennart> did it explain anything?  (it really goes with 90 minutes of lecturing :) )
17:01:37 <ihope> Well, I know what Unlambda's c combinator does, so this can't be too different.
17:21:46 <dons> moin
17:24:33 <dons> dcoutts: the sharing issue sounds reasonable. 
17:31:36 <mathewm> > newtype CPSMonad a = CPSMonad ( (a -> Trace ) -> Trace )
17:31:36 <lambdabot>  Parse error
17:37:58 <SamB> hmm, I can't get MAME to build with debug symbols :-(
17:42:03 <palomer> @palomer
17:42:04 <lambdabot> I think you're all nuts
17:42:08 <palomer> @palomer
17:42:08 <lambdabot> Brump!
17:42:13 <Pseudonym> @keal
17:42:13 <lambdabot> Cale etc already pointed out Haskell is puny to nothing to emulate using my barrage of mathematic theories
17:43:05 <mathewm> can you partially apply constrctors?
17:45:06 <mauke> who is keal?
17:45:14 <mauke> mathewm: yes
17:45:34 <mauke> (: []) is relatively common
17:46:01 <mathewm> :type []
17:46:05 <mathewm> @type []
17:46:06 <lambdabot> forall a. [a]
17:46:22 <mathewm> > ([]) 1
17:46:22 <lambdabot>  Couldn't match `[a]' against `t -> t1'
17:46:52 <mauke> > (: []) 1
17:46:53 <lambdabot>  [1]
17:47:31 <mathewm> > (: []) 1
17:47:32 <lambdabot>  [1]
17:47:40 <mathewm> (: []) is a section, right?
17:47:55 <mathewm> partially applied ':' - I see
17:49:30 <mathewm> recursive newtype def'n are giving me a headache 
17:52:35 <Philippa> yes, it's a section
17:54:11 <palomer> @palomer
17:54:12 <lambdabot> They're telling you lies!
17:55:03 * Philippa wonders if they've got one for her yet then remembers she's not really talked about kink in chan since #haskell-blah was founded
17:55:17 <SamB> mathewm: partially applied *flipped* (:)
17:55:44 <SamB> @pl (: [])
17:55:44 <lambdabot> return
17:55:47 <mathewm> > ([] ++ ) 1
17:55:48 <lambdabot>  add an instance declaration for (Num [a])
17:55:48 <SamB> hmm.
17:55:52 <mathewm> > ([] ++ ) [1]
17:55:53 <lambdabot>  [1]
17:56:07 <mathewm> but then ++ isn't a constructor, is it
17:56:14 <SamB> of course not
17:56:59 <mathewm> > ( flip (:) 'a' ) ['b'] 
17:56:59 <lambdabot>  Couldn't match `[a]' against `Char'
17:57:17 <mathewm> @haddoc flip
17:57:17 <lambdabot> Unknown command, try @list
17:57:19 <SamB> > let [] ++ ys = ys; (x:xs) ++ ys = x:xs ++ ys in "Hello," ++ " World!"
17:57:20 <lambdabot>  "Hello, World!"
17:57:24 <SamB> whoo!
17:57:54 <SamB> definately *not* a constructor
17:58:33 <mathewm> why not?  Because you can override it?
17:58:33 <SamB> @type flip
17:58:34 <lambdabot> forall c a b. (a -> b -> c) -> b -> a -> c
17:58:58 <SamB> because if it were a constructor, I couldn't implement it using the others ;-)
17:59:05 <mathewm> > ( flip (:) [] ) 'b' 
17:59:06 <lambdabot>  "b"
17:59:17 <SamB> also, try ":info []" in GHC, maybe
17:59:20 <SamB> GHCi, that is
17:59:26 * mathewm claps wildly with his toung stretched out
18:02:33 <Korollary> hallelujah
18:04:08 <mathewm> Feeling happy there, Korollary?
18:04:29 <Korollary> I just had too much chololate.
18:04:36 <Korollary> it'll pass.
18:04:39 <mathewm> :)
18:05:10 <mathewm> Korollary: how are you with recursive newtype's?
18:05:43 <mathewm> newtype CPSMonad a = CPSMonad ((a -> Trace) -> Trace)
18:06:17 <mathewm> I am not quite sure what that is telling me - reading the haskell98 report...
18:07:35 <mathewm> hmm, I guess it isn't recursive after all
18:08:05 <SamB> no, the CPSMonad on the right is the constructor
18:08:16 <SamB> the non-existant data constructor
18:08:21 <mathewm> so why use newtype instead of data here?
18:08:34 <SamB> newtype has no overhead, and is strict
18:08:44 <SamB> it uses the same representation as the underlying type
18:08:55 <samx> Could use some help: I'm trying to export a data type from a module, and import it to another module.. but when trying to use it, ghc is complaining.. it's just couple of lines, so please excuse me for the c&p:
18:09:01 <samx> module Date (Date (..)) where (data Date = Date { dayOfMonth :: Int, monthOfYear :: Int, year :: Int })
18:09:06 <samx> module A where (import qualified Date as Date; getDay d = Date.dayOfMonth d)
18:09:25 <dons> where { } ?
18:09:26 <SamB> but gives you a new type, so you can make different instances, enforce abstractions, just generally avoid confusing type errors...
18:09:45 <dons> samx, why do you have aprens after where, instead of braces?
18:09:50 <dons> s/aprens/parens/
18:09:54 <SamB> haha
18:10:08 <mathewm> SamB: thanks
18:10:11 <samx> dons, oh, that's just what i put in there for a smaller copy & paste. i'm having them on separate lines
18:10:37 <dons> the above looks ok then.
18:10:39 <dons> what's the error?
18:11:14 <samx> Expecting a function type, but found `Int'      Expected type: b -> c      Inferred type: Int,     for the use of Date.dayOfMonth
18:11:46 <dons> day of Months is an Int,
18:11:51 <dons> you're using it as a function applied to 'd'
18:12:09 <dons> getDay d = Date.dayOfMonth d -- is wrong
18:12:44 <dons> should you be using the Time library, or do you need to do this by hand for some reason?
18:13:23 <samx> I seemed to remember, that for accessing a member in a data type, you'd use the name of the member as an accessor. Am I totally confused here?
18:14:01 <dons> ah no. i am. no coffee yet.
18:15:26 <dons> no, it works for me. your code is ok.
18:15:29 <dons> perhaps save?
18:15:41 * Korollary screams
18:15:41 <dons> *A> :t getDay
18:15:42 <dons> getDay :: Date.Date -> Int
18:15:51 <xah> !! just realized that there's a Mathematica bot at #math
18:15:54 <Korollary> @keal
18:15:55 <lambdabot> b*(Floor[v/b^p]/b-Floor[Floor[v/b^p]/b])
18:16:14 <dons> unless there is code you're not showing us, that is using getDay in the wrong way
18:16:15 <samx> oops.. I realized my mistake.. and actually the c&pd version doesn't have the problem
18:16:19 <Korollary> I believe Cale set that bot up.
18:16:30 <mathewm> is 'module Date (Date (..)) where ' actuall sytax?  -looking at the (..)
18:16:30 <dons> Korollary: ?
18:16:46 <dons> no. it was some weird convention samx adopted :)
18:16:52 <Korollary> dons: the bot in #math I mean.
18:17:03 <samx> dons, got it to work. thanks for taking a look at it, though :-)
18:17:08 <dons> samx, it's best to use explicit lazyout when pasting. so you'd use Data where { .. } :)
18:17:19 <dons> layout. man i need some coffee
18:17:22 * dons gets coffee
18:17:27 <Korollary> hah lazyout
18:17:38 <dons> lazy io on the brain
18:17:44 <Korollary> don't lay it out unless absolutely necessary!
18:18:58 <xah> i can do a Mathematica-teaching session with the bot
18:23:03 <xahlee> has anyone read my article ‚ÄúThe Concepts and Confusions of Pre-fix, In-fix, Post-fix and Fully Functional Notations‚Äù?
18:25:52 <SamB> no. nobody at all has read it.
18:25:59 <Cale> hehe
18:28:06 <xahlee> Cale: i have your mbot!
18:28:11 <xahlee> have -> love.
18:28:17 <Korollary> lol
18:28:46 <xahlee> Cale: can it be set to run in #Mathematica?
18:29:40 <Cale> sure
18:30:25 <xahlee> super. :) thanks.
18:38:14 <aFlag> what's the name of that article that there's bananas, flees, stuff like that on the title?
18:38:48 <Korollary> bananas lenses and barbed wire?
18:39:01 <aFlag> yes, i think that's the one
18:39:39 <Korollary> http://research.microsoft.com/~emeijer/
18:42:28 <aFlag> thanks
18:46:15 <SamB> flees?
18:47:11 <Pseudonym> Yes, that's a siphomorphism.
18:47:48 <Korollary> flees are the arrows between the bananas.
18:48:38 <hyrax42> an if/then/else is not an expression?
18:48:50 <SamB> have they released a LaTeX package to typeset all those symbols?
18:48:56 <Korollary> no. it's syntax.
18:48:58 <SamB> hyrax42: course it is
18:49:15 <hyrax42> well I'm being complained at over last statemnt in a do must be an expression
18:49:22 <hyrax42> oh
18:49:23 <hyrax42> nm
18:49:26 <hyrax42> I need another do
18:49:31 <SamB> > if True then 1 else 2
18:49:32 <lambdabot>  1
18:52:14 <Korollary> do wah <- dee dee
18:52:48 <hyrax42> or worse
18:52:50 <hyrax42> *sigh*
18:52:54 <hyrax42> I was looking at the wrong line
18:54:26 <SamB> > do wah <- dee dee
18:54:26 <lambdabot>  Parse error
18:54:38 <Korollary> bot needs some culture
18:55:20 <aFlag> me too :(
18:55:25 <SamB> parse error! bah!
18:55:48 <SamB> oh, right.
18:56:14 <SamB> > do wah <- dee dee; return wah
18:56:15 <lambdabot>  Not in scope: `dee'
18:57:04 <hyrax42> what is the correct way to indent an if/else
18:57:11 <hyrax42> if/then/else rather
18:57:21 <Korollary> There is none.
18:57:31 <Korollary> are you in a do block?
18:57:35 <hyrax42> yeah
18:58:05 <Korollary> that's confusing you. you want that line to continue, so you will make sure that if you split the line, the second line is indented more.
18:58:31 <hyrax42> kk
19:39:02 <dons> ?karma+ QuickCheck -- knows all
19:39:02 <lambdabot> QuickCheck's karma raised to 9.
20:11:43 <smoofra> i have what im sure is a stupid question for you all, but i can't find it on google:  how do you write a top level loop in haskell?
20:12:51 <psnl> smoofra: recursion
20:13:38 <psnl> main = do foo >>= main, if you get the syntax mangling
20:14:00 <smoofra> oh.  heh. i guess that makes sense
20:14:06 <smoofra> didn't realise that was legal
20:15:53 <AtnNn> you can also use sequence.repeat
20:21:09 <Razor-X`> Is there any nice tutorial on network code in Haskell?
20:22:18 <dons> i don't know of one. but check haskell.org's tutorials page
20:22:28 <dons> there's always the Network docs
20:22:49 <dons> ?docs Network
20:22:50 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/network/Network.html
20:24:45 <AtnNn> i coudlnt find any tut when i looked last week, those docs are what i used and if you've done networking before its quite easy to figure out. just use PortNumber instead of htonl iirc
20:24:59 <Cale> That should be "main = do foo; main" or "main = foo >> main"
20:25:17 <hyrax42> I like how haddock docs are more or less enough to get going
20:25:23 <hyrax42> because of type signatures
20:25:33 <Razor-X`> Thanks.
20:26:05 <dons> ?karma+ QuickCheck -- two more bugos spotted
20:26:05 <lambdabot> QuickCheck's karma raised to 10.
20:38:01 <stepcut> @echo use your cloaking device
20:38:02 <lambdabot> echo; msg:Message {msgPrefix = "stepcut!n=user@ip68-107-68-183.sd.sd.cox.net", msgCommand = "PRIVMSG", msgParams = ["#haskell",":@echo use your cloaking device"]} rest:"use your cloaking device"
20:38:05 <stepcut> :p
20:44:41 <dons> ?
20:53:47 <audreyt> dons: how do we get \bot to #perl6?
20:55:37 <dons> you want an instance of this one?
20:55:59 <dons> @join #perl6
20:56:09 <dons> audreyt, would you like it there permanently?
20:56:28 <audreyt> yes
20:56:41 <dons> ok, i'll add perl6 to the config file. it shoudl autojoin in future.
20:57:44 <audreyt> bad thing is that our evalbot also uses ?eval
20:57:48 * audreyt ponders what to do
20:58:03 <dons> hmm.
20:59:15 <dons> ?eval 1+2
20:59:16 <lambdabot>  3
21:00:20 <dons> audreyt: i think one or the other has to change their command name :/
21:00:30 <audreyt> @eval 1+2
21:00:31 <lambdabot>  3
21:00:33 <audreyt> > 1+2
21:00:34 <lambdabot>  3
21:00:45 <audreyt> I think it's \bot if that's okay with you :)
21:00:50 <dons> yeah, ok.
21:00:51 <audreyt> is the ?eval form often used here?
21:00:55 <dons> no. 
21:00:59 <dons> it is almost just an internal name
21:01:04 <dons> so give me 5 mins...
21:01:11 <audreyt> danke
21:01:13 <dons> is "run" ok?
21:01:20 <audreyt> sure
21:04:44 <Revision17> how do I write that an argument must implement multiple typeclasses (like this foo :: (Integral,Read) a => a -> Bool except...correct)?
21:06:48 <stepcut> (Integral a, Read a) => a -> Bool
21:07:24 <Revision17> stepcut: thanks
21:07:50 <stepcut> np.
21:12:37 <dons> @quit use @run internally, avoids unnec. use of the valuable `eval' identifier
21:12:49 <dons> ?bot
21:13:14 <lambdabot> :)
21:13:21 <dons> ?run 1+2
21:13:22 <stepcut> dons: is @echo supposed to have so much output ?
21:13:30 <lambdabot>  3
21:13:32 <dons> i'm not sure. its a very old command.
21:13:36 <Cale> @echo
21:13:36 <lambdabot> echo; msg:Message {msgPrefix = "Cale!i=foobar@bas4-kitchener06-1167891324.dsl.bell.ca", msgCommand = "PRIVMSG", msgParams = ["#haskell",":@echo"]} rest:""
21:13:51 <dons> its for debugging the irc protocol impl, iirc.
21:14:09 <dons> what's your concern, stepcut?
21:14:15 <dons> @id foo
21:14:15 <lambdabot> foo
21:14:19 <dons> is myabe what you're after?
21:14:31 <dons> @id \1ACTION man\1
21:14:31 <lambdabot> \1ACTION man\1
21:14:41 <stepcut> I just didn't know if it was a feature or a bug :)
21:14:50 <dons> > 1+2
21:14:50 <lambdabot>  3
21:15:00 <dons> @eval should be keal
21:15:00 <lambdabot> where can i find opensource schematics of Linus Torvalds' x86 clone?
21:15:04 <dons> audreyt: done.
21:22:40 <audreyt> dons++
22:13:37 <Stinger_> in ghci, when it says use -v to see a list of dependencies, where do you use that exactly?
22:14:54 <Stinger_> -v to show a list of files searched rather (when using :load, :add etc)
22:17:48 <dons> ghci -v4 ?
22:17:55 <dons> try, :set -v4
22:19:02 <Stinger_> oh its an option
22:19:14 <dons> yeah, normal ghc command line flag
22:20:04 <Stinger_> I thought they wanted it in the :add command somewhere
22:22:20 <palomer> @palomer
22:22:20 <lambdabot> That's a lie
22:28:03 <palomer> oomph, I'm bored
22:28:07 <palomer> this isn't a state I'm used to
22:30:30 <Stinger_> hmm how do you create a Rational?
22:30:47 <Stinger_> 2 % 3 ?
22:30:55 <Cale> yeah
22:31:21 <palomer> > 2/3
22:31:22 <lambdabot>  0.6666666666666666
22:31:22 <Stinger_> ok so I'm assuming I need Data.Rational imported then, cause that doesnt seem to work by default in ghci
22:31:24 <Cale> Or even 2/3 will do, if the type context is there to say that you want a rational.
22:31:27 <palomer> @type 2/3
22:31:28 <lambdabot> forall a. (Fractional a) => a
22:31:29 <Cale> yeah
22:31:44 <Cale> > numerator (2/3)
22:31:45 <lambdabot>  2
22:32:10 <Stinger_> next question then, how do you get Data.Rational imported into the interpretter, I tried :add Data.Rational
22:32:21 <dons> :m + 
22:32:26 <Cale> :m + Data.Ratio
22:32:37 <dons> as :h will tell you ;)
22:32:42 <dons> or :?
22:32:52 <Stinger_> hmm doesnt that switch the context?
22:33:05 <palomer> it adds to the context
22:33:21 <palomer> though I don't like using the word context
22:33:26 <palomer> it adds to the environment
22:33:47 <Cale> This is ghci right?
22:34:02 <Stinger_> yeah, hmm my prompt could get largish
22:34:27 <Cale> You can also create a module which imports whatever modules you want to use, and then load that.
22:34:49 <dons> or just use the compiler. its all good.
22:35:28 <Stinger_> well I've just got a .hs file that imports things atm, doesnt explicitly define a module though
22:36:01 <Cale> that's fine too
22:36:09 <Cale> It defines the module Main by defauly
22:36:11 <Cale> t*
22:36:26 <shapr> stepcut: @echo just runs show on the datatype that represents an irc message.
22:52:17 <shapr> palomer: If you're bored, check out the lambda cube?
22:53:04 <Razor-X`> How can you tell an IO function to wait?
22:54:11 <dons> threadDelay, perhaps?
22:54:16 <shapr> Timeout code was discussed last month on the mailing list.
22:54:22 <dons> or do you want to wait on a handle?
22:54:31 <Razor-X`> Yeah, I want to wait on a handle :P.
22:56:25 <dons> ?
22:56:50 <dons> that wasn't a joke. maybe you want your thread to sleep, waiting on input from a file handle?
22:56:54 <dons> but i guess not.
22:57:32 <Razor-X`> Nevermind the smilie then.
22:58:01 <Razor-X`> That is what I want, dons.
22:59:44 <dons> have a look at threadWait then
22:59:50 <dons> ?hoogle threadWait
22:59:50 <lambdabot> Control.Concurrent.threadWaitRead :: Fd -> IO ()
22:59:51 <lambdabot> Control.Concurrent.threadWaitWrite :: Fd -> IO ()
23:00:13 <dons> if you want to wait on a file, threadDelay if you want to just sleep for a while
23:00:25 <dons> not that to get an Fd from a Handle you'll need
23:00:28 <dons> ?hoogle Handle -> Fd
23:00:29 <lambdabot> No matches, try a more general search
23:00:35 <dons> ?hoogle Handle -> IO Fd
23:00:35 <lambdabot> No matches, try a more general search
23:00:40 <dons> ?hoogle handleToFd
23:00:40 <lambdabot> No matches found
23:00:58 <Razor-X`> Hmmm.
23:01:01 <dons> ?index handelToFd
23:01:01 <lambdabot> bzzt
23:01:05 <dons> ?index handleToFd
23:01:05 <lambdabot> System.Posix.IO, System.Posix
23:01:13 <dons> ?type System.Posix.handleToFd
23:01:14 <lambdabot> GHC.IOBase.Handle
23:01:14 <lambdabot>          -> IO System.Posix.Types.Fd
23:01:32 <dons> unix only
23:01:48 <dons> lots of other games you could play. like yielding and sleeping.
23:01:54 <dons> ?docs Control.Concurrent
23:01:54 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Control-Concurrent.html
23:01:56 <dons> is worth reading.
23:02:01 <Razor-X`> Unix only is fine.
23:02:48 <Razor-X`> I'll read that too.
23:03:04 <Razor-X`> Mmmm. Haskell is fun.
23:03:27 <dons> good :)
23:03:30 <dons> i think so too.
23:04:38 <Razor-X`> I just got into Haskell after looking at Lisp and OCaML, and I like Haskell the most.
23:05:13 <dons> yeah, its the more advanced for these languages (by a lot these days, i think)
23:06:17 <Korollary> dons: (H98) In a context, what kind of a type variable is considered free? (since in h98 there's the implicit forall)
23:07:16 <dons> in a typeclass context?
23:07:31 <Korollary> yes
23:07:37 <dons> hmm. none?
23:07:50 <Korollary> I'm trying to decipher a sentence from the report.
23:07:50 <dons> as unbound types wouldn't help things much.
23:08:06 <Korollary> "In any such type, any of the universally-quantified type variables ui that are free in cx must also be free in t."
23:08:40 <dons> oh, talking about sub-expressions..
23:08:53 <dons> imagine in a subexpression, there can be tyvars free in that expression that are bound further out
23:09:34 <Korollary> further out where?
23:09:52 <dons> in an outer expression
23:10:21 <dons> so they might be bound at the toplevel with an implicit forall, but they'll be free in some subexression that refers to them (in the context of  that subexpression).
23:10:42 <dons> the subexpression considered in isolation might have free tyvars, yeah?
23:11:35 <Korollary> Oh I get it
23:11:57 <Korollary> I was thinking of all toplevel
23:12:26 <Korollary> thanks
23:15:34 <dons> no probs.
23:23:27 <Razor-X`> How do regexps work in Haskell?
23:24:30 <Korollary> @index mkRegex
23:24:31 <lambdabot> Text.Regex
23:26:27 <cmarcelo> Razor-X`: people here are always talking about JRegex too, http://repetae.net/john/computer/haskell/JRegex/
23:28:25 <Razor-X`> Oh. JRegex sounds like just what I need.
23:41:24 <Itkovian> meuning
23:41:40 <Itkovian> boegel.
23:44:24 <boegel> yo Itkovian 
23:47:20 <shemale_magic> hi
23:47:41 <shemale_magic> If I do not know programming at all can I learn haskell?
23:47:55 <mauke> probably yes
23:48:00 <palomer> Cale claims not
23:48:03 <palomer> err
23:48:05 <palomer> cale claims so
23:48:15 <palomer> I'm thinking maybe
23:48:17 <dons> yeah, haskell is often taught as a first programming language.
23:48:19 <palomer> though not real programming
23:48:26 <palomer> since that's not what  haskell is meant for
23:48:29 <Cale> heh
23:48:38 <dons> thanks palomer. keep up the good work
23:48:38 <Cale> Haskell is fine for real programming
23:48:57 <palomer> just doing my job
23:49:01 * dons goes back to his unreal array fusioning
23:50:21 <aleator> Sorry, but should this be valid c from c2hs point of view: "return (__m128){ 0.0f, 0.0f, 0.0f, 0.0f };" ?
23:54:11 <neologism> shemale_magic: definitely yes but you will have hard time learning other (imperative) languages :)
23:57:12 <shemale_magic> wil I need to learn imperative langs?
23:57:58 <ValarQ> shemale_magic: short answer: no
23:58:31 <tennin> what attracted you to Haskell?
