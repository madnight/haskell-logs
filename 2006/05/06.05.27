00:55:54 <neologism> by a chance - anyone skilled with AgentSpeak here?
01:15:34 <jethr0> could anyone here please help me with irreducible polynomials? i've been trying to understand them for days now and have gotten nowhere :((
01:17:57 <dcoutts> dons, ping
02:08:28 <cmarcelo> i'm having "kind errors" when trying to layer a ReaderT transformer on top of a State monad (doing this is a bad idea?). well i'm trying something like this (simplified): fun :: Program -> ReaderT [String] (State String Int) ...  GHCi says that (State String Int) is '*' but it wants '* -> *'... =|
02:12:12 <eivuokko> You want ReaderT [String] (State String) Int
02:12:48 <cmarcelo> hmm
02:13:23 <eivuokko> The second parameter to transformer is the inner monad, and the last parameter type the monadic action returns
02:13:54 <eivuokko> That is, IO has kind * -> * and is monad.  IO Int is monadic value
02:14:01 <eivuokko> (and has kind *)
02:14:56 <cmarcelo> kind * -> * is like "a type that takes a type as 'argument' and returns a type" ?
02:15:00 <eivuokko> Yes.
02:15:06 <eivuokko> Kinds are types of types.
02:15:24 <eivuokko> In haskell they are much simpler than actual types
02:15:29 <jethr0> @kind maybe
02:15:31 <lambdabot> Not in scope: type variable `maybe'
02:15:35 <jethr0> @kind Maybe
02:15:36 <lambdabot> * -> *
02:15:50 <eivuokko> There's just one basic type * and application ->
02:15:54 <eivuokko> Err, kind
02:15:56 <eivuokko> ;)
02:16:10 <eivuokko> (GHC has few of it's own for unboxed stuff)
02:17:26 <Muad_Dib> @kind String
02:17:27 <lambdabot> *
02:17:50 <cmarcelo> thanks. looks like it worked (even layering ErrorT on top of everything): "Program -> ErrorT String (ReaderT Names (State SymbolTable)) Int"
02:38:43 <davidhouse> so here's a crazy idea
02:38:47 <davidhouse> a wiki based on darcs.
02:39:33 <davidhouse> it seems a perfect back end; you get diffing, revision control all free.
02:39:39 <kep> davidhouse: why not ? 
02:39:51 <davidhouse> you'd need to write a wiki syntax module, but other than that, you're done! :)
02:40:16 <kep> davidhouse: here is a wiki is based on subversiob, as I remember 
02:40:29 <cmarcelo> http://ikiwiki.kitenet.net/ is a wiki based on svn...
02:42:05 <davidhouse> RCSs are basically just wikis for files
02:42:39 <isaacd> davidhouse: and you get patch commutation so that reverts could be easier somehow, perhaps
02:42:56 <isaacd> things like that anyway
02:42:59 <cmarcelo> davidhouse: that smatiny(?) compiler/interpreter that you were working on, did you release it?
02:43:09 <davidhouse> cmarcelo, version one has been, yeah.
02:43:24 <davidhouse> version two's almost ready, which features an extensible instruction set and input.
02:43:50 <davidhouse> i need to solve about one more problem then it's finished.
02:44:00 <davidhouse> plus test it.
02:44:32 <davidhouse> cmarcelo: the first version is linked to from the esolang wiki
02:47:44 <cmarcelo> davidhouse: hmm.. that extensible instruction set is what called my attention.. =) but i'll take a look in v1.
02:48:36 <davidhouse> v1's nothing particularly special.
02:48:45 <davidhouse> cmarcelo: are you interested in the language itself?
02:50:46 <cmarcelo> nope. is the extensible instr. set thing... PLUS i'm learning Haskell so any code is a way to learn something =)
02:52:06 <davidhouse> hehe, sure.
02:52:17 <davidhouse> well the way it'll work isn't that elegant.
02:52:46 <davidhouse> i found a paper that outlines an extension that would perfectly solve the problem, but it's without implementation, so i'm having to hack myself together something.
02:53:45 <cmarcelo> davidhouse: which paper?
02:55:11 <davidhouse> http://www.informatik.uni-bonn.de/~loeh/OpenDatatypes.html "Open Data type and Open Functions", Andres LÃ¶h and Ralf Hinze
02:56:31 <cmarcelo> tks
02:58:25 <dcoutts> dons, you about?
03:07:41 <davidhouse> @hoogle (a -> Maybe b) -> [a] -> [b]
03:07:42 <lambdabot> Maybe.mapMaybe :: (a -> Maybe b) -> [a] -> [b]
03:31:59 <dcoutts> first results of new fps fusion system: take 51% of the time of previous system.
03:32:40 <dcoutts> benchmark time down from 3.86 seconds to 1.97
03:32:52 <kolmodin> dcoutts: OMG!
03:33:14 <dcoutts> :-)
03:33:18 <kolmodin> great news :)
03:33:22 <wilx> Fusion?
03:33:31 <kolmodin> other great news: I just did my final exam for this period
03:33:37 <dcoutts> yay!
03:33:41 <isaacd> what is this (amazing) fps fusion system?
03:33:55 <kolmodin> not that great news: I'll probably have to do it again after the summer :/
03:34:11 <dcoutts> kolmodin, na, you'll pass first time
03:34:21 <kolmodin> dcoutts: very unlikely :D
03:34:29 <Stinger_> what subject?
03:34:31 <dcoutts> have faith man
03:34:31 <davidhouse> kolmodin: what's the exam on?
03:34:40 <kolmodin> object oriented programming. crap! :D
03:35:20 <dcoutts> wilx, isaacd, fusion: it does for ByteStrings what is already done for lists, things like: map f . map g ~> map (f . g)
03:35:46 <wilx> Ah, rewrite ruleS?
03:35:52 <dcoutts> wilx, isaacd, it means that you don't need to construct an intermeidate list/array and you can do it in one pass rather than two.
03:35:55 <kolmodin> I actually knew one question about OCL, which I leart in another course. on the other 3 questions I just made up something :)
03:36:00 * davidhouse wishes parsec's nmodule name was shorter
03:36:01 <wilx> I see.
03:36:12 <dcoutts> yes we use ghc's RULES to do it, just like ghc uses RULES for list fusion
03:36:22 <dcoutts> but the array fusion is cooler :-)
03:36:31 <kolmodin> dcoutts: is it commited yet?
03:36:41 <dcoutts> kolmodin, yep
03:36:48 <dcoutts> and I'm now just testing it
03:37:33 <dcoutts> because we can combine things that are not directly fusable, eg you can't fuse an up loop with a down loop, but you can still combine them such that the second loop happens in-place rather than needing to allocate an additional buffer
03:39:05 <isaacd> wow, things that would be ugly hacks become transparent optimizations
03:39:21 <dcoutts> isaacd, right
03:39:27 <isaacd> Haskell is great :)
03:39:54 <dcoutts> so you can have long piplines of array functions fused into one effecient operation
03:40:21 <dcoutts> (or at least reusing the same memory block if they're not fusable into a single pass)
03:41:08 <dcoutts> so that includes all maps, filters, folds and similar things like scans, mapAccum etc
03:41:29 <davidhouse> dcoutts: is there much left on the ByteString todo? it seems you guys are always coming up with new ways of optimising it
03:41:57 <dcoutts> davidhouse, still some work on the .Lazy version and .Char8 modules
03:42:18 <dcoutts> and we're still tidying, documenting and benchmarking
03:42:33 <dcoutts> we've been working on cleaning up the api
03:42:39 <dcoutts> so still a bit to do
03:42:40 <davidhouse> @hoogle filterM
03:42:41 <lambdabot> Monad.filterM :: Monad a => (b -> a Bool) -> [b] -> a [b]
03:42:41 <lambdabot> Control.Monad.filterM :: Monad m => (a -> m Bool) -> [a] -> m [a]
03:42:41 <lambdabot> Data.Graph.Inductive.Query.Monad.graphFilterM :: GraphM m gr => (Context a b -> Bool) -> GT m (gr a b) [Context a b]
03:42:41 <davidhouse> cool.
03:43:57 <dcoutts> yay, the difference between map and map' is now just 10% rather than 50%
03:44:41 <davidhouse> is parsec's many just sequence . repeat?
03:49:21 <isaacd> davidhouse: it's a version optimised to avoid stack overflow, according to its comments, but it can't be equivalent to sequence . repeat, because that would always fail?
03:49:37 <davidhouse> hmm, true.
03:50:12 <davidhouse> never mind, sepBy does what i want without using the generic monadic combinators.
04:06:37 <xerox> mnislaih__ - Good luck with your GHCi debugger SoC project!
04:06:49 <mnislaih__> thanks xerox, I'm gonna need it
04:06:53 <dcoutts> mm, 50 times faster in another corner case...
04:07:04 <dcoutts> well 48.5 times faster
04:07:46 <dcoutts> for: foldr (+) 0 . map f . filter p . map f . map f . map f
04:08:01 <dcoutts> for some reason the existing foldr is very slow and not fusable
04:08:06 <dcoutts> the new one is fusable
04:08:59 <dcoutts> I think it's mainly because the old one was using a lot of stack space
04:13:07 <davidhouse> mnislaih__: i've got a long list of things that GHCi Should Do :)
04:14:18 <mnislaih__> hah David, that sounds interesting but ...
04:14:31 <mnislaih__> really, I've got an even longer list of things GHCi does and I need to know how it does them :)
04:14:39 <davidhouse> like there should be an option to load all the locally-bound things; i.e. all the lets and wheres.
04:14:48 <davidhouse> mnislaih__: heh :) what's the eventual project aim?
04:15:03 <davidhouse> is it to implement something specific or just to make GHCi into the ultimate debugger?
04:15:12 <mnislaih__> to provide all the bells & whistles needed for the breakpoint support Lemmih created
04:15:38 <mnislaih__> there are some specific things that need to be done
04:16:05 <mnislaih__> support for displaying closures, for keeping track of stack traces, and a few other
04:16:40 <davidhouse> lambdabot can display closures.
04:16:49 <mnislaih__> hmm that's interesting !
04:16:50 <davidhouse> non-polymorhpic ones, at least.
04:16:51 <davidhouse> > not
04:16:52 <lambdabot>  <Bool -> Bool>
04:17:06 <mnislaih__> > length
04:17:07 <lambdabot>  Add a type signature
04:17:10 <mnislaih__> :S
04:17:18 <davidhouse> yeah, it borks on anything that's approaching polymorphism ;)
04:17:34 <davidhouse> it probably just doesn't understand type variables.
04:17:36 <mnislaih__> we want to display polymorphic ones too, but I'll give a look at lambdabot darcs and see how it does it
04:18:38 <davidhouse> mnislaih__: well, this is probably the most exciting project, so good luck! :)
04:19:01 <mnislaih__> I don't think so davidhouse, all the other projects are very interesting too
04:19:13 <davidhouse> that and Waern's haddock project. and cabal-get. ah, they all rock.
04:19:32 <davidhouse> language.c will be _very_ useful to some people.
04:21:35 <jethr0> davidhouse: to do what?
04:22:47 <davidhouse> jethr0: well, out of all the languages you could parse, C's going to be the one that comes up most frequently. also it will probably have some application within GHC
04:23:02 <jethr0> hmm
04:36:02 <xerox> jethr0 - Parse & Conquer yarr!
04:36:51 <davidhouse> what's wrong with the following module decl?
04:37:13 <davidhouse> module StepDefs (module A (handler), module B (handler), module C (handler)) where
04:37:31 <davidhouse> i get "parse error on input `('"
04:39:58 <kosmikus> I don't think you can have nested export lists for modules
04:40:34 <davidhouse> sure you can. i'm just reexporting modules.
04:40:42 <Lemmih> No, you can't.
04:40:57 <Lemmih> davidhouse: module StepDefs (module A) where import A (handler)
04:41:12 <davidhouse> Lemmih: ah.
04:42:12 <mux> morning
04:59:58 <davidhouse> argh. i wish GHC had proper mutually recursive modules support.
05:00:12 <jethr0> isn't it possible to export functions that one has imported?
05:00:13 <davidhouse> perhaps i'm just a terrible module designer, but my modules _always_ end up being mutually dependant
05:00:32 <jethr0> "module X (func) where import Y (func)"?
05:00:45 <davidhouse> module X (module Y) where import Y (func)
05:01:07 <davidhouse> i would have thought your method would be supported too, though
05:01:18 <davidhouse> because sometimes you might want to import more functions than you export
05:16:20 <tibbetts> Stupid question, but one that I'm having no luck googling. On ghc 6.4, as installed by Ubuntu, using ghci, I do "import Test.HUnit". The file /usr/lib/ghc-6.4/imports/Test/HUnit.hi exists, but strace shows that ghci is only looking for imports in my current directory. How do I make it find Test.HUnit in the system library dir?
05:16:58 <Lemmih> tibbetts: :m Test.HUnit?
05:17:34 <dons> dcoutts: results, eh?
05:17:41 <tibbetts> Seems to have the same problem: Could not find module `Test.HUnit': it is not a module in the current program, or in any known package.
05:18:13 <dons> is that 50% speedup due to down loop fusion kicking in? or is it to do with better map/map fusion?
05:18:15 <tibbetts> I also get the same error from regular ghc, non-interactive.
05:19:10 <tibbetts> The compiler is however loading Prelude.hi out of that directory.
05:19:11 <Lemmih> tibbetts: Does `ghc-pkg` show parentheses around HUnit?
05:19:30 <Lemmih> `ghc-pkg list`
05:19:37 <tibbetts> It actually doesn't show hunit at all.
05:20:15 <tibbetts> And something I did earlier while installing packages might have actually messed up ghc-pkg's view of the world. Maybe I'll try re-installing the ghc package.
05:25:54 <dons> dcoutts: some very exciting results there!
05:27:35 <tibbetts> Thanks for the tip about ghc-pkg. Reinstalling makes HUnit appear in the list.
05:37:23 <jethr0> hey dons
05:37:27 <dons> hey
05:37:36 <jethr0> dons: any chance that you could help me with an algebra question?
05:37:55 <dons> oh, possibly. but its been about 5 years since i've done any algebra...
05:38:39 <jethr0> i'm at a bit of a less concerning my crypto exam on monday. much of it is about irreducible polynomials and their "zeros" and i just don't understand how an irreducible poly. can have any zeros...
05:38:51 * jethr0 can be real stupid sometimes
05:39:59 <dons> oh, perhaps try Cale? there are some other math guys around here. 
05:40:55 <jethr0> hehe, i'll try asking cale whenever he shows up...
05:41:15 <wilx> Learning math on IRC is not the best way :)
05:41:36 <dons> i'd first have to find my math textbooks, and given its 11pm on a saturday, this would take a while
05:41:46 <dons> wilx: you think? maybe it could be taught like haskell via irc.
05:41:54 <dons> we'd need an @eval and @type though.
05:42:00 <wilx> :)
05:42:02 <dons> or , even better, just teach haskell in math courses...
05:42:46 <wilx> I think that it is so complicated subject that people slowly typing on IRC cannot pass the information fast enough.
05:42:51 <wilx> Reading books is much better.
05:43:07 <dons> yeah, fair enough. only the simple haskell stuff gets taught via irc too.
05:43:38 <jethr0> wilx: i've gone through all my books and searched the internet but haven't found an answer to my question :(
05:44:05 <dons> have you tried #math? I don't know their culture though. maybe asking questions is a faux pas..
05:44:12 <wilx> Heh.
05:44:28 <dons> well, some languages aren't as welcoming to beginners ;)
05:45:34 <jethr0> dons: yes, i have, but with cale not being there yet, they don't seem to be the sharpest knives in the drawer :)
05:45:50 <dons> ah, there you go. didn't know that.
05:46:08 <dons> and they run a lambdabot in #math too, yes?
05:46:45 <jethr0> i don't want to be disrespectful to them, but until know there wasn't anyone who'd have reacted to me asking about irreducible poly's...
05:46:54 <int-e> Cale does, it's mbot.
05:47:12 <davidhouse> jethr0, it depends what field they're irreducible over, i would assume.
05:47:22 <dons> int-e, i find this funny. maybe the math guys should just admit they're becoming a branch of theoretical computer scince ;)
05:47:53 <wilx> I ain't no mathematican, in fact I am rather weak in it. But I don't see why irreducible polynoms couldn't have a point where its value is zero.
05:47:57 <int-e> Hmm. I'd put it the other way around, but yes. The fields have a large overlap.
05:48:02 <davidhouse> obviously every polynomial is reduciable over C.
05:48:12 <jethr0> davidhouse: yes, and i admit i'm a bit unclear in that respect.
05:48:13 <dons> int-e, yeah, joke ;) 
05:48:34 <jethr0> davidhouse: but when a poly is irreducible over a specific field, can it then still have zeros in that field??
05:48:52 * dons `fmap` sleep
05:49:05 <mux> nite dons 
05:49:32 <davidhouse> wilx, because to find the zeroes of, say, x^2 - 2x -3 you'd write it as (x-3)(x+1) = 0; x = 3 or x = -1. But the very fact you can factorise it means it's reducible.
05:49:53 <jethr0> davidhouse: i'm doing this in cryptography and there you have GF(p) `mod` f(x) with f(x) irreducible over GF(p).
05:50:27 <jethr0> davidhouse: so you agree that an irreducible poly under a field can't have a zero in that field?
05:50:47 <davidhouse> i think so.
05:51:00 <Taldor> and what about X = 0 ?
05:51:26 <int-e> dons: I might add that I've studied CS ;)
05:51:26 <jethr0> i think irreducible is defined as deg > 0
05:51:56 <Taldor> the degree of X is 1...
05:52:28 <jethr0> sry, i think i meant deg>1, but as you can see i'm not quite comfortable with this yet :((
05:53:37 <int-e> jethr0: f(a) = 0 implies f(x) = (x-a)*g(x). if f has degree > 1 then g has degree >0 and f is reducible.
05:53:41 <jethr0> nm, gotta get back to my maths *grumbles*
05:53:47 <davidhouse> wikipedia: "Hence, all irreducible polynomials are of degree 1. This is the Fundamental theorem of algebra."
05:54:13 * jethr0 doesn't think that's correct. i think that's in N or Z or sth
05:54:15 <davidhouse> yeah, what int-e said explains it nicely.
05:54:28 <davidhouse> jethr0: that's in C.
05:54:46 <davidhouse> in N, for example, x^2 + 2 is irreducible.
05:55:04 <davidhouse> (that's even irreducible in Q)
05:55:12 <int-e> Oh, please, use something that's a ring - Z or Q :)
05:55:25 <marc_vw_> now i missed the interessting bits ..
05:55:31 <marc_vw_> bloody timeouts
05:55:45 <int-e> marc_vw: see http://meme.b9.com/
05:55:50 <davidhouse> yeah, Z then :)
05:56:32 <jethr0> they've got a nice polynomial plugin for lambdabot over at #math
05:56:44 <davidhouse> N could be a ring, but it'd have some weird operation
05:56:46 <dcoutts> hi dons, so did you mean that I should just enable it replacing the current system?
05:56:55 <davidhouse> jethr0: mbot has a mathematica interface.
05:57:00 <dcoutts> dons, because in a sense it's already enabled, they're currently both enabled
05:57:09 <jethr0> ahh
05:57:13 <int-e> davidhouse: hmm, well you can use any bijection between Z and N for constructing such a beast.
05:57:36 <dcoutts> dons, it's just that only the old system is currently used
05:57:39 <int-e> davidhouse: but people will likely want to kill you for calling the resulting structure N ;)
05:57:57 <davidhouse> hehe. well it'd be (N, +, *) or whatever, but the base set would still be N.
05:58:00 <dcoutts> dons, so I've been benchmarking by importing the Fusion module directly
05:58:25 <davidhouse> or (N, +, *, 0, 1) depending on how you define your operations.
05:59:14 <davidhouse> jethr0: the guys in #math aren't that scary. they'd warm to a well-phrased question, even if it's not a "how do you complete this exercise" type question.
05:59:23 <davidhouse> efnet's math is also a great source of knowledge.
05:59:27 <davidhouse> *#math
05:59:51 <jethr0> davidhouse: i guess the "main" people weren't around when i asked
06:00:25 <davidhouse> jethr0: perhaps not.
06:20:44 <redblades> Hello!
06:21:58 <int-e> > let bin 0 _ = 1; bin n k = bin (n-1) (k-1) * n `div` k in bin 6 2
06:21:59 <lambdabot>  Exception: divide by zero
06:22:07 <int-e> > let bin _ 0 = 1; bin n k = bin (n-1) (k-1) * n `div` k in bin 6 2
06:22:08 <lambdabot>  15
06:22:19 <jethr0> > let pascal = iterate (\row -> [1] ++ [x | x <- zipWith (+) row (tail row)] ++ [1]) [1] in pascal !! 6 !! 2
06:22:20 <lambdabot>  15
06:22:41 <jethr0> > let pascal = iterate (\row -> [1] ++ zipWith (+) row (tail row) ++ [1]) [1] in pascal !! 6 !! 2
06:22:42 <lambdabot>  15
06:47:55 <MarcWeber> Is there some kind of power function beyond exp ? something like pow 2 3 = 2^3 ?
06:48:16 <mauke> pow = (^)
06:48:55 <isaacd> > 2^3
06:48:56 <lambdabot>  8
06:49:02 <isaacd> > 2^^3
06:49:03 <lambdabot>  8.0
06:49:05 <isaacd> > 2**3
06:49:06 <lambdabot>  8.0
06:49:14 <isaacd> > 2^(-3)
06:49:15 <lambdabot>  Exception: Prelude.^: negative exponent
06:49:18 <isaacd> > 2^^(-3)
06:49:19 <lambdabot>  0.125
06:49:27 <isaacd> > 2^(3.5)
06:49:28 <lambdabot>  Add a type signature
06:49:32 <isaacd> > 2^^(3.5)
06:49:33 <lambdabot>  Add a type signature
06:49:44 <isaacd> > 2^(3.5) :: Double
06:49:44 <lambdabot>  Add a type signature
06:49:49 <MarcWeber> > 2^^(3.5::Double)
06:49:50 <lambdabot>  add an instance declaration for (Integral Double)
06:49:50 <lambdabot>   In the definition of `zxs': zxs = 2 ^^ (3.5 :: Double)
06:49:50 <lambdabot>   In the definition of `wju':
06:49:53 <sieni> > (fromIntegral 2)^(3.5)
06:49:54 <lambdabot>  Add a type signature
06:49:57 <sieni> oops
06:50:04 <MarcWeber> > 2**(3.5::Double)
06:50:05 <lambdabot>  11.313708498984761
06:50:09 <isaacd> Only ** works for doubles anyway
06:50:15 <MarcWeber> ^^ is for ints ** for floats
06:50:17 <isaacd> 2**3.5
06:50:21 <sieni> MarcWeber: ahh :-)
06:50:22 <MarcWeber> thx
06:50:25 <isaacd> > 2**3.5
06:50:26 <lambdabot>  11.313708498984761
06:50:37 <sieni> > 2^43
06:50:38 <lambdabot>  8796093022208
06:50:45 <sieni> > 2**43
06:50:46 <lambdabot>  8.796093022208e12
06:51:07 <sieni> ok, makes sort of sense
06:53:14 <int-e> > (-2)^^(-3)
06:53:15 <lambdabot>  -0.125
06:53:29 <int-e> > (-2)**(-3)
06:53:30 <lambdabot>  -0.125
06:53:38 <int-e> (I hate Posix for this)
06:54:01 <sieni> how is posix related to this?
06:54:18 <sieni> (-2)**(-2.4)
06:54:23 <sieni> oops
06:54:27 <sieni> > (-2)**(-2.4)
06:54:28 <lambdabot>  NaN
06:54:28 <int-e> sieni: Posix requires pow() to work for negative integer exponents.
06:54:50 <davidhouse> how is (-2)**(1/2)
06:54:53 <bolrod> > (2)^^(0.5)
06:54:53 <davidhouse> oops
06:54:53 <lambdabot>  Add a type signature
06:54:57 <davidhouse> (-2)**(1/2)
06:55:02 <davidhouse> > (-2)**(1/2)
06:55:03 <lambdabot>  NaN
06:55:06 <sieni> int-e: well, that's semi-sucky, although not that bad
06:55:17 <bolrod> > (2)^^(0.5) :: Double
06:55:17 <lambdabot>  Add a type signature
06:55:20 <sieni> int-e: I'd rather have different function for that behaviour
06:55:25 <bolrod> > (2)^^(1/2) 
06:55:25 <lambdabot>  Add a type signature
06:55:36 <int-e> sieni: me too
06:55:40 <davidhouse> > (-2)^(1/2)
06:55:41 <lambdabot>  Add a type signature
06:55:58 <davidhouse> there's no exponeniation which can result in complex numbers?
06:56:00 <davidhouse> > sqrt(-2)
06:56:01 <lambdabot>  NaN
06:56:46 <bolrod> @index Complex
06:56:47 <lambdabot> Data.Complex
06:57:34 <bolrod> > 1:+4
06:57:35 <lambdabot>  1.0 :+ 4.0
06:57:43 <bolrod> > sqrt(1:+0)
06:57:44 <lambdabot>  1.0 :+ 0.0
06:57:52 <bolrod> > sqrt(-1:+0)
06:57:53 <lambdabot>   precedence parsing error
06:57:53 <lambdabot>    cannot mix prefix `-' [infixl 6] and `(:+)' [infix 6] in the same infix expression
06:57:57 <sieni> int-e: what does c99 say?
06:57:58 <bolrod> > sqrt((-1):+0)
06:57:59 <lambdabot>  0.0 :+ 1.0
06:58:01 <bolrod> :]
06:58:07 <MarcWeber> > sqrt(0 :+ 1)
06:58:09 <lambdabot>  0.7071067811865476 :+ 0.7071067811865475
06:58:20 <MarcWeber> yep
06:58:46 <sieni> davidhouse: which branch were you going to take for negative numbers?
06:59:04 <int-e> sieni: hmm, the same
06:59:06 <int-e>        [#2]  The  pow functions compute x raised to the power y.  A
06:59:06 <int-e>        domain error occurs if x is negative and y is finite and not
06:59:06 <int-e>        an  integer  value.   A  domain  error  occurs if the result
06:59:06 <int-e>        cannot be represented when x is zero and y is less  than  or
06:59:06 <int-e>        equal to zero.  A range error may occur.
06:59:06 <davidhouse> sieni, sorry?
06:59:38 <sieni> davidhouse: is sqrt(-1) supposed to be i or -i and how are you planning to decide that without arbitrariness?
07:00:59 <sieni> davidhouse: square root naturally yields two numbers (which are additive inverses to each other) except for 0 (which is, of course the additive inverse of itself)
07:01:01 <davidhouse> you define it anologously to sqrt on R^+.
07:01:14 <sieni> davidhouse: the analogy being?
07:01:14 <davidhouse> you say it's the one with the positive imaginary coefficient, by "defaul".
07:01:17 <davidhouse> *default
07:01:24 <davidhouse> e.g.
07:01:26 <davidhouse> > sqrt 4
07:01:27 <lambdabot>  2.0
07:01:37 <MarcWeber> sqrt :: Complex -> [Complex] ;-))) infinite lists? *smile* result : [i,-i,2*i,-2*i,3*i,-3*i,...] ;-))
07:01:39 <sieni> ok, what would then be the square root of i and what would be the square root of -i?
07:01:58 <int-e> MarcWeber: huh?
07:02:10 <davidhouse> notice lack of -2. that's because in mathematics, the square root function returns the positive number whose square is the argument.
07:02:16 <sieni> MarcWeber: certainly not. Only if the root you are taking is not an integer
07:02:17 <int-e> MarcWeber: sqrt has only two values.
07:03:01 <MarcWeber> int-e: Sorry, I did mix up e notation with x+iy notation..
07:03:07 <davidhouse> square root of i: (a + bi)^2 = i; a^2 - b^2 + 2abi = i; a^2 - b^2 = 0 and 2ab = 1.
07:03:19 <davidhouse> solve those simultaneously to obtain a complex root of i.
07:04:44 <sieni> davidhouse: I can solve them without even looking at the solution for the second order equation, they are 1/(sqrt 2)(1 + i) and it's negative and for -i they are 1/(sqrt 2)(1 - i) and its negative inverse.
07:05:05 <davidhouse> right, so why do you ask?
07:05:22 <sieni> davidhouse: which one were you planning of choosing?
07:05:34 <davidhouse> the one with the positive imaginary coefficient...
07:05:48 <int-e> MarcWeber: and you forgot the 2*pi*...
07:05:56 <MarcWeber> I know...
07:06:33 <MarcWeber> I shouldn't cook, try chatting and try to program at the same time ?
07:06:41 <isaacd> equivalently, choose the one with polar angle < pi?
07:06:55 <isaacd> and >= 0
07:09:00 <sieni> ok, let me put it this way: assuming that you know that x^2 + 1 == 0 has two complex solutions and you decide to call one of them i and the other one -i, how can you distinguish between them only by resorting to real numbers?
07:09:09 <davidhouse> does it matter?
07:09:13 <neologism> http://lambda-the-ultimate.org/node/1506
07:09:15 <neologism> have you read this?
07:09:41 <davidhouse> neologism: it was on the mailing lists a couple of weeks back
07:14:11 <neologism> ok
07:16:19 <petekaz> I find that post interesting as that means there is hope I can use haskell for practical things.
07:16:33 <davidhouse> petekaz: seen pugs?
07:16:50 <davidhouse> it's _the_ perl 6 interpreter. written in haskell,.
07:16:52 <integral> pugs has to be some of the ugliest haskell in the world
07:17:29 <petekaz> And I thought it was only going to be a prototype, they aren't really going to implement perl 6 in haskell are they?
07:17:59 <xerox> Pugs is like Hugs (-:
07:18:06 <integral> it's *a* perl6 implementation.  there will be several.  afaik none's officially blessed by TPF as a main one yet
07:18:19 <petekaz> I do lots of sysadmin and tool building for unix boxes, so the linspire announcement was of interest to me.
07:18:43 <petekaz> There is such a lack of examples of haskell being used in this domain.
07:18:53 <xerox> Anybody up for a Go game?
07:19:07 <dcoutts> petekaz, there's a gentoo package manager implemented in Haskell
07:19:16 <davidhouse> hey, xerox, shouldn't you be working on cabal-get? :)
07:19:45 <xerox> davidhouse - I must relax a bit, those two last week of school are tough )-:
07:19:45 <davidhouse> how's that going, by the way?
07:20:09 <petekaz> xerox: did you get my question about tagging the projects that were accepted in the SOC in trac so I can see them all at once?
07:20:12 <xerox> Final exams in short time, argh.
07:20:18 <petekaz> dcoutts: I'll take a look at it.
07:20:45 <xerox> petekaz - Yes, will link to the sensible tickets in short time.
07:20:47 <davidhouse> none of the trac projects seem to exactly line up with the final project proposals.
07:20:53 <dcoutts> petekaz, not *the* gentoo package manager (that's in python) but *a* gentoo package manger
07:20:56 <petekaz> Any examples of people using haskell for more "down to earth" things interest me :-)
07:21:05 <petekaz> dcoutts: ok, I'll find it.
07:21:25 <dcoutts> petekaz, well at the moment we're hacking on a fast string library
07:21:44 <dcoutts> so that should make all kinds of file processing tasks quicker
07:21:58 <petekaz> Well, I've been following that, and that will be important for my use of haskell.
07:22:12 <petekaz> I do tons of log processing.
07:22:31 <dcoutts> eg someone poped up on one of the haskell lists the other day with a log processing example that was running very slowly using ordinary String
07:22:40 <dcoutts> petekaz, that wansn't you was it?
07:22:43 <petekaz> I manage a global VoIP network of about 3000+ Cisco devices.
07:22:51 <petekaz> dcoutts: not me.
07:23:00 <petekaz> dcoutts: haven't gotten that far yet.
07:23:31 <dcoutts> petekaz, anyway he had an example which simply printed the top 1000 most frequently occuring lines in a log file
07:24:20 <dcoutts> his initial version was too strict and was usign linear heap space
07:24:22 <petekaz> And those Cisco boxes all "syslog" and "trap" back to about 7 collectors around the globe.  I have python agents on those boxes that sit on the logs, look for events, then fire actions (emails, alarms to the NetOps Center, etc ...)
07:24:58 <petekaz> dcoutts: I haven't read the mailing list for 2 days or so, I'll look for that.
07:25:11 <MarcWeber> Yeah... haskell for os! .. Mmhh Would be a reason to switch from gentoo to debian?? ;-)
07:25:27 <dcoutts> petekaz, anyway, dons wrote a version using Data.ByteString which was much faster and ran in constant space
07:25:34 <petekaz> I want to port my logwrap framework to haskell: http://www.kazmier.com/computer/logwrap/
07:26:00 <dcoutts> MarcWeber, well if you like that then you can already switch your gentoo package manager to a Haskell reimplemtation of portage
07:26:06 <petekaz> dcoutts: Any regexp engines work with fps yet?
07:26:11 <dcoutts> MarcWeber, no need to switch to debian
07:26:13 <MarcWeber> What?
07:26:17 <dcoutts> petekaz, not yet, it's on the TODO list
07:26:36 <MarcWeber> Can't believe it..
07:26:54 <petekaz> I'll eagerly await that .. probably by then I may actually be able to write some haskell :-)
07:26:54 <dcoutts> MarcWeber, it's not an official project of course
07:28:12 <MarcWeber> dcoutts: Would you be so kind and reimplement the  "masked by ~x86" to "masked by ~x86 would you like to add it to /etc/portage/package.keywords [y/n]".. ;-)
07:28:31 <dcoutts> MarcWeber, send in a patch
07:28:33 <dcoutts> http://www.iai.uni-bonn.de/~loeh/exi/
07:29:20 <dcoutts> MarcWeber, or  "masked by ~x86" to "masked by ~x86, use ACCEPT_KEYWORDS="~x86" emerge ..."
07:30:01 <MarcWeber> But what to do on a emerge -world / -system?
07:30:10 <dcoutts> petekaz, what kind of regexps do you normall use? POSIX or PCRE ?
07:30:28 <dcoutts> MarcWeber, true true
07:30:41 <MarcWeber> are vim regexpr POSIX or PCRE? Which type is pythons re?
07:31:10 <mauke> vim regexes are vim
07:31:22 <MarcWeber> dcoutts: One thing to change would also be : save the whole dependency tree in some kind of database and use that for emerge.. would be much faster.
07:31:25 <MarcWeber> ;-)
07:31:58 <dcoutts> MarcWeber, the ebuilds are already cached
07:32:05 <petekaz> dcoutts: PCRE
07:32:14 <dcoutts> I was looking about for a good POSIX regexp lib and couldn't really find any. Am I just blind?
07:32:29 <davidhouse> dcoutts: other than Text.Regex?
07:32:55 <dcoutts> davidhouse, it's based on the glibc one I beleive which has too limited an interface to be useful for what I wanted
07:33:00 <sieni> pcre are teh only allowable regexen. the others are blashphemy
07:33:05 <davidhouse> JRegex?
07:33:12 <dcoutts> eg it only works on null terminated char*, I want to work on streams
07:33:18 <petekaz> I use python regexps the most which are pcre compatible.
07:33:40 <sieni> petekaz: perl compatible regular expressions compatible?
07:33:47 <dcoutts> one can't implement regexps for lazy bytestrings using the POSIX regexp api
07:34:06 <petekaz> sieni: yes.
07:34:17 <petekaz> similar.
07:34:17 <dcoutts> it's not even clear that it can be done with the PCRE api
07:34:39 <davidhouse> dcoutts: JRegex does both POSIX and PCRE.
07:34:45 <davidhouse> iirc.
07:34:55 <dcoutts> davidhouse, ok, but we can't bind to that if it's in Java
07:35:08 <davidhouse> @where JRegex
07:35:08 <lambdabot> http://repetae.net/john/computer/haskell/JRegex/
07:35:10 <petekaz> it's their own implementation, but similar to Perl's.  From the python doc "This module provides regular expression matching operations similar to those found in Perl."
07:35:11 <davidhouse> it's a haskell lib.
07:35:18 <MarcWeber> \url
07:35:50 <dcoutts> davidhouse, oh I see!
07:38:32 <MarcWeber> So there is nothing missing for a haskell expect .. ;-)
07:39:15 <dcoutts> petekaz, doesn't perl allow regexp matching on an input stream without having to chop up the input into strings first?
07:39:34 <mauke> no
07:40:00 <petekaz> MarcWeber: a haskell expect would be nice.  I wrote an erlang telnet client to do that the other week.
07:47:07 <dcoutts> so libpcre allows stream matching but with restructions and only using its slower dfa matcher
07:48:08 <dcoutts> and it makes the matcher non-deterministic (in the sense that differences in the underlying stream segmentation can affect the result)
07:48:21 <dcoutts> so two equal streams may match differently
07:48:46 <petekaz> blasphemy! 
07:48:51 * petekaz pretends to be a haskeller
07:48:53 <dcoutts> quite
07:48:56 <dcoutts> :-)
07:51:03 <petekaz> I wonder why the linspire team choose haskell over ocaml?  It sounds as though that they already had some stuff written in ocaml.  And I always thought, perhaps naively, that ocaml was more practical than haskell.
07:51:05 <Igloo> How does it behave differently?
07:51:55 <dcoutts> Igloo, http://www.ugcs.caltech.edu/manuals/libs/pcre-6.4/pcrepartial.html#SEC4
07:52:09 <dcoutts> the bit starting:
07:52:09 <dcoutts> 3. Matching a subject string that is split into multiple segments does not always produce exactly the same result as matching over one single long string.
07:52:49 <sieni> petekaz: well, ocaml compiler has a sucky licence (qpl) and should not be supported. A good question, of course, is to ask why haskell was chosen instead of standard ml.
07:52:58 <dcoutts> so it looks like we can only provide regexps for Data.ByteString and not Data.ByteString.Lazy
07:53:16 <Igloo> Euch
07:53:21 * petekaz googles for qpl
07:53:28 <dcoutts> Igloo, quite
07:53:45 <dcoutts> I had no idea the state of C regexp libs was so poor
07:53:46 <Igloo> You could always finish my Haskell regexp library  :-)
07:54:08 <dcoutts> Igloo, can we make it fast! ;-)
07:54:29 <Igloo> You can certainly try  :-)
07:54:34 <dcoutts> heh
07:54:45 <dcoutts> Igloo, is it a DFA matcher?
07:55:30 <sieni> petekaz: I would say that Haskell has probably the largest community behind it and a really good implementation of the language (ghc), although mlton is really good standard ml implementation as well.
07:55:59 <Igloo> Can't remember. Can you do proper DFA when you have capturing parentheses?
07:56:06 <petekaz> This is a dumb question I'm sure, but when would a lazy bytestring be good vs a non-lazy one?  If I'm processing a log file, I'll read it one line at a time.  In this case, what's the big deal with lazy bytestrings?  (remember, I'm a newbie)
07:56:15 <dcoutts> Igloo, no, I believe not
07:57:00 <Igloo> It's at http://urchin.earth.li/darcs/ian/regexp/ if you're interested. I think the POSIX REs are complete (apart from things like the combining character stuff), but the PCRE stuff isn't
07:57:05 <dcoutts> petekaz, because it allows you to express it as a pure computation rather than reading line by line
07:57:43 <petekaz> But all IO in haskell is faked in the IO monad right?  So how is that pure?
07:57:51 <dcoutts> petekaz, for just that special case of line by line one can lazily get a list of lines from a file
07:58:09 <petekaz> isn't that called buffering?
07:58:20 <dcoutts> petekaz, the operations on the lazy byte string really are pure
07:58:31 <dcoutts> petekaz, getting one from a file involves lazy IO
07:58:52 <Igloo> petekaz: You can say xs <- get_all_the_lines; mapM_ process_line xs rather than having to explicitly loop yourself
07:59:33 <petekaz> Is that it?
07:59:41 <petekaz> I mean ... in python I do:
07:59:43 <dcoutts> so declaratively you do all the IO upfront and then process it, but the implementation interleaves the IO and the processing
07:59:47 <petekaz> for line in sys.stdio:
07:59:57 <dcoutts> lazy IO is implemented using unsafeInterleaveIO
08:00:07 <petekaz>   check regexp and do something if a match
08:00:17 <petekaz> Hmmm ...
08:01:01 <dcoutts> petekaz, for just your special case of lines dons added hGetLines :: IO [ByteString]
08:01:22 <dcoutts> the ByteString.Lazy module generalises that idea
08:01:23 <petekaz> Still trying to wrap my head around the real benefits vs just a difference in implementations.  Is my code going to be shorter?  
08:01:26 <dcoutts> so it's not just line based
08:01:36 <dcoutts> yes, it should be shorter
08:01:57 <petekaz> right, I'm just using the lines example as thats what I used most often.
08:01:58 <dcoutts> though as I saidm your line by line is a neat special case
08:02:29 <dcoutts> eg think of stream processors like tr
08:02:41 <dcoutts> we can write that as a one liner and it'll be fast
08:03:02 <dcoutts> interact (filter (/='e'))
08:03:39 <dcoutts> if you do that with out using lazy byte strings then you need to write a loop that reads bit by bit
08:04:23 <petekaz> I see.
08:04:51 <dcoutts> which is easy for line by line, but gets harder for more complex pipelines
08:05:13 <dcoutts> oh, and it allows us to do fusion
08:05:24 <petekaz> cold?
08:05:27 <petekaz> :-)
08:05:28 <dcoutts> heh
08:05:36 <dcoutts> list/array fusion
08:05:46 <dcoutts> which is not pleasent to do by hand
08:05:57 <dcoutts> (too hot)
08:06:10 <dcoutts> (unless it's cold fusion)
08:06:38 <petekaz> I don't understand, from the little I know about fusion, isn't that how multiple calls to map and filter are combined automatically into on to avoid interediate lists?
08:06:47 <dcoutts> right
08:06:54 <dcoutts> and we can do the same for ByteStrings
08:07:06 <dcoutts> and indeed for lazy ByteStrings
08:07:06 <petekaz> oh!
08:07:12 <int-e> interact for bytestrings?
08:07:23 <dcoutts> int-e, yep, for lazy ByteString
08:07:27 <int-e> wee.
08:07:54 <dcoutts> int-e, it's easy: interact transformer = putStr . transformer =<< getContents
08:08:18 <dcoutts> ok, so the magic is in getContents & putStr
08:23:40 <SamB> is that how it is really implemented?
08:24:11 <dcoutts> SamB, yes.
08:24:36 <dcoutts> both getContents & putStr are lazy so it's fine.
08:25:49 <dcoutts> SamB, what did you imagine?
08:26:46 <int-e> unsafeInterleaveIO is powerful ...
08:27:04 <SamB> oh, yeah, come to think of it, putStr does show as many chars as it can...
08:27:43 <dcoutts> SamB, though remember that this is Data.ByteString.Lazy.putStr not Prelude.putStr
08:27:54 <int-e> getContents is more lazy than putStr.
08:28:06 <int-e> oh
08:28:07 <SamB> oh, you are talking about a different interact?
08:28:14 <int-e> dcoutts: is that a good idea?
08:28:40 <dcoutts> int-e, is what a good idea?
08:28:46 <int-e> dcoutts: what if the program terminates? does interact id suddenly stop copying input from output then?
08:28:59 <dcoutts> SamB, I'm talking about Data.ByteString.Lazy.interact
08:29:42 <dcoutts> int-e, huh? if the program terminates then the program terminates. I don' think I understant what you mean.
08:30:30 <int-e> dcoutts: Let me rephrase that. if getContents and putStr are both lazy in the same sense, shouldn't interact return immediately, terminating the program (if no other stuff follows)?
08:30:47 <int-e> dcoutts: I'm confused by the claim that putStr is lazy.
08:31:14 <dcoutts> int-e, oh I see
08:31:48 <dcoutts> well putStr does consume the whole string but it produces output while consuming te string
08:32:01 <dcoutts> just like the ordinary Prelude.putStr
08:32:04 <int-e> okay, I'd call that strict.
08:32:16 <dcoutts> ok, I guess so
08:32:30 <dcoutts> but it is different from something like:
08:32:42 <int-e> length l `seq` putStr l
08:32:47 <dcoutts> length s `seq` Prelude.putStr s
08:32:49 <dcoutts> right
08:33:03 <dcoutts> which is what Data.ByteString.putStr is
08:33:19 <petekaz> what's the diff in the above two?
08:33:29 <int-e> ok, it'd be nice to have a term for 'consumes its input as it processes it' vs. 'keeps the input alive while it processes it'
08:33:33 <dcoutts> petekaz, it's when the output happens
08:33:41 <int-e> 'good list consumer' maybe.
08:33:50 <xerox> `streamy'
08:33:50 <int-e> (or as it may be, lazy bytestrings)
08:33:57 <dcoutts> int-e, needs some description of the IO
08:34:13 <dcoutts> int-e, it can be described with prefixes etc
08:34:14 <int-e> dcoutts: well the idea applies to pure functions as well
08:34:16 <petekaz> dcoutts: oh, so as it's computing the length, it's also printing?
08:34:24 <int-e> dcoutts: say, sort vs. concat.
08:34:28 <dcoutts> petekaz, no
08:34:33 <dcoutts> int-e, right, using prefixes
08:35:01 <dcoutts> petekaz, length s `seq` Prelude.putStr s  will not produce any output 'til the whole input s has been evaluated
08:35:30 <dcoutts> petekaz, where was Prelude.putStr s will produce output while evaluating s
08:35:40 <dcoutts> so you can use Prelude.putStr with an infinite string
08:36:21 <petekaz> That is the result of seq right?
08:36:33 <petekaz> strict evaluation of length s?
08:36:40 <dcoutts> yes
08:36:59 <petekaz> so how is the lazy byte string version different?
08:37:11 <petekaz> doesn't seq force the same behavior?
08:37:43 <dcoutts> petekaz, sure, we were simulating a strict version of Prelude.putStr by adding in seq
08:38:20 <petekaz> oh, so there is no diff between those two examples?
08:38:25 <dcoutts> the point we were making is that the lazy bytestring putStr behaves like normal putStr, not the version we made up there with seq
08:39:06 <dcoutts> there is certainly a difference between putStr s and length s `seq` Prelude.putStr s
08:39:17 <petekaz> I understand now ...
08:39:47 <petekaz> Thanks for taking the time to explain.
08:39:52 <dcoutts> np
08:48:28 <petekaz> dcoutts: do you recall the list that log processing example was in you referred to?
08:48:53 <dcoutts> petekaz, [Haskell-cafe] [newbie] processing large logs
08:48:58 <dcoutts> May 13th
08:49:16 <petekaz> thanks!
08:52:53 <cb_> hi. are there any good sdl bindings? i've tried a few places but they either lead to dead links, or stuff that doesn't look very finished?
08:53:50 <xerox> Yes!  Lemmih's ones.
08:54:01 <xerox> ?where hsSDL
08:54:02 <lambdabot> http://darcs.haskell.org/~lemmih/hsSDL
08:54:25 <cb_> ahh. the same as the scannedinavian.org stuff? scannedinavian.org seems dead
08:54:28 <cb_> ta muchly! :)
08:54:36 <xerox> You're welcome!
08:55:03 <SamB> hooray, I found the problem with my XPCOM type library parsing code!
08:55:15 <SamB> it was inherited from the spec
08:55:41 <SamB> I sent an email to 
08:55:54 <SamB> er, well, I tried to send an email to the spec authors...
08:56:03 <xerox> What is XPCOM?
08:56:05 <SamB> but it seems to have bounced from both addressis
08:56:12 <SamB> Mozilla's component object model
08:58:41 <SamB> well, it doesn't look to have been the only problem
09:52:45 <davidhouse> soo...
09:53:15 <davidhouse> what's the difference between f :: Monad m => a -> m b and f :: Arrow m => m a b?
09:54:25 <edeefelt> PHP?
09:54:53 <davidhouse> edeefelt: sorry?
09:55:49 <JKnecht> good decision if e thought that was PHP.
09:56:39 <JKnecht> Arrows and Monads are different and competing encapsulations of computations in Haskell.
09:57:03 <xerox> davidhouse - the second type is more general.
09:57:58 <davidhouse> conceptually, though, they both represent the same thing: a black box with side effects.
09:58:09 <JKnecht> arrows seem (to me at least) to have a more category theortic flavor and are thus more consonant with the Haskell design intent I think, but Monads seem a lot more worked out.
09:58:14 <davidhouse> xerox, but how is it more general?
09:58:21 <xerox> davidhouse - No *side* effect, just effect.
09:58:48 <davidhouse> JKnecht: well, monads are pulled directly from CT, but arrows are a CS invention. they do have close CT correspondant, though (Freyd-categories).
09:59:00 <xerox> davidhouse - All Monads are Arrows, but not all Arrows are Monads.
09:59:38 <davidhouse> hmm, yes.
10:00:53 <JKnecht> arrows as function mapping are CT too.
10:01:09 <davidhouse> so the arrowic axioms are weaker than the monadic ones?
10:05:55 <xerox> Arrows require a larger collection of laws.
10:06:37 <xerox> (f >>> g) >>> h  =  f >>> (g >>> h)
10:06:48 <xerox> arr (f >>> g)  =  arr f >>> arr g
10:07:21 <davidhouse> you mean arr (f . g) = arr f >>> arr g
10:07:50 <davidhouse> and that's analoguous to fmap (f . g) = fmap f . fmap g (as Monad is a subclass of Functor that's required)
10:08:07 <xerox> arr h >>> f = arr h >>> g (h is surjective)  =>  f = g
10:08:18 <davidhouse> and there's a law of associativity for >>= too
10:08:39 <xerox> f >>> arr h  =  g >>> arr h  (h is bijective)  =>  f = g
10:08:57 <xerox> (So, arr id >>> f = f = f >>> arr id)
10:09:43 <xerox> There are more... Arrows have a number of combinators.
10:10:07 <xerox> first (arr f) = arr (fist f)
10:10:26 <davidhouse> fist?
10:10:29 <xerox> first (f >>> g)  =  first f >>> first g
10:10:39 <xerox> Sorry, typo.  I mean `first.'
10:10:47 <davidhouse> well, first f doesn't make sense as f is pure
10:10:57 <davidhouse> probably f * id
10:11:08 <davidhouse> where f * g (x, y) = (f x, g y)
10:11:18 <xerox> Right, we shall require that all combinators behave for pure arrows as they do for functions.
10:11:44 <xerox> first f >>> arr fst  =  arr fst >>> f
10:12:00 <xerox> (That is, `first f' depends only on the first components of pairs)
10:12:54 <davidhouse> so another difference between a -> m b and m a b is that arrows have this concept of only acting on part of their input.
10:13:27 <xerox> Swap those to get the laws for second.
10:14:48 <xerox> (For ArrowZero and ArrowPlus, we just require that the operation is associative and zeroArrow is its unit.  Requiring more would be overly restrictive for parsers, for example.)
10:24:07 <Revision17> @kind MonadState
10:24:08 <lambdabot> Class `MonadState' used as a type
10:25:28 <davidhouse> Revision17: instances of MonadState are required to be monads, so they have kind * -> *.
10:25:40 <Revision17> ah
10:25:58 <Revision17> I'm still trying to figure out this whole monad thing
10:27:30 <davidhouse> read http://en.wikibooks.org/wiki/Programming:Haskell_monads
10:27:52 <davidhouse> then read http://www.nomaware.com/monads/html/index.html
10:28:53 <mauke> I just fixed an annoying bug in my code
10:29:22 <mauke> somehow nondeterminism crept in in the middle of a do block
10:29:55 <mauke> I tried to Debug.Trace.trace it but failed because of laziness
10:30:49 <davidhouse> ah, that can suck.
10:30:58 <davidhouse> a nice idiom is to do something like:
10:31:16 <mauke> turns out I had defined optionalS as optionalM and vice versa
10:31:22 <davidhouse> f a b c | trace (show a ++ show b ++ show c) False = undefined
10:31:49 <davidhouse> put that at the top of your function, then you'll get a dump whenever that function is called.
10:32:29 <mauke> how do I add that to f <- optionalS' (: []) (token '-' >> ((noneOf "\\]" <||> (token '\\' >> anyToken)) >>+ flip enumFromTo))? :-)
10:33:29 <davidhouse> put it at the top of your function def; just below your type signiture.
10:34:23 <mauke> the function containing that line?
10:35:20 <davidhouse> sure.
10:35:45 <davidhouse> is that a parsing monad? doesn't look like Parsec.
10:35:58 <mauke> that function doesn't take any arguments :-)
10:36:03 <mauke> it's my own parser
10:36:33 <davidhouse> ah, cool.
10:38:00 <davidhouse> wow: http://en.wikipedia.org/wiki/Banach-Tarski_paradox "In other words, a marble could be cut up into finitely many pieces and reassembled into a planet" :)
10:38:15 <Revision17> so, I've been trying to get my Cpu data structure working with a StateMonad for awhile, and I haven't figured it out; could someone point me in the right direction with the MonadState instance (yes I've read the monad book and all about monads, but they don't seem to have monadstate instance examples)? http://pastebin.com/741437
10:39:18 <davidhouse> Revision17: your Cpu monad looks equivalent to Reader.
10:40:27 <Revision17> so I should read up on that? I'm trying to eventually get a "language" where I can do stuff like writeReg that appear to have side effects
10:41:04 <davidhouse> and i believe the syntax you're looking for is instance MonadState Cpu where...
10:41:55 <Revision17> that fails with "Kind error: `Cpu' is not applied to enough type arguments"
10:42:14 <Revision17> so I was trying stuff closer to what was in the error messages
10:43:08 <davidhouse> ah, of course.
10:43:30 <davidhouse> instances of MonadState should actually be kind * -> * -> *. they need to be parametrised over the type of their environment.
10:43:50 <davidhouse> is RegisterModel your environment?
10:44:05 <Revision17> I suppose so; it will be were all the data is stored
10:44:11 <davidhouse> i.e., do you want to get and put RegisterModels?
10:44:14 <Revision17> yes
10:44:17 <davidhouse> cool.
10:44:26 <davidhouse> then try type Cpu a = State RegisterModel a
10:44:40 * Revision17 tries
10:44:53 <davidhouse> a direct synonym will do here. what's more, you get all State's functions like get and put for free, as well as the monadic instances.
10:45:14 <davidhouse> then i'd define your own combinators like writeRef in your Cpu monad.
10:53:47 <davidhouse> is \x. x x impossible in typed lambda calculi?
10:53:55 <dcoutts> yep
10:54:04 <dcoutts> try finding the type for it
10:54:11 <davidhouse> that's what i thought; but isn't that exactly what fix does?
10:54:39 <dcoutts> no
10:55:12 <dcoutts> though fix also can't be written in simply typed lambda calculus
10:56:47 <davidhouse> @type \x -> x x
10:56:48 <lambdabot>   Occurs check: cannot construct the infinite type: t = t -> t1
10:56:48 <lambdabot>   Expected type: t
10:56:52 <Revision17> davidhouse: sorry to be a bother, but I'm having a bit of difficulty with declaring an instance of the Cpu type you gave me http://pastebin.com/741463
10:57:19 <davidhouse> dcoutts: it has type a -> a -> a -> a...?
10:57:21 <int-e> fix would have type (a->a)->a ... that's no problem at all.
10:57:44 <dcoutts> davidhouse, yeah
10:57:52 <davidhouse> Revision17: you get the monadic instance for free with type synonyms, you don't need to declare it.
10:57:56 <int-e> but typed lambda calculus is strongly normalizing and doesn't have any infinite calculations; hence, no fix.
10:58:00 <Revision17> oh wow
10:58:08 <int-e> (I hope I remembered that correctly)
10:58:09 <dcoutts> int-e, right, which is why we can introduce it as a constant, even though we can't write code for it.
10:59:04 <davidhouse> dcoutts: we can introduce fix as a constant? what does that mean?
10:59:15 <dcoutts> fix is an axiom that allows you to assume what you're trying to prove and rely on that in your proof.
10:59:34 <davidhouse> Revision17: when you say type A = B, that means A is _entirely equivalent_ to B. the compiler can and does interchange that at will.
10:59:38 <davidhouse> hence if B is a monad, then A is.
10:59:53 <Revision17> alright, that makes sense
11:00:06 <davidhouse> dcoutts: sounds useful :)
11:00:34 <Cale> Revision17: You're running into the problem that type synonyms are required to be fully applied
11:01:03 <dcoutts> davidhouse, it means you can take typed lambda calculus and add a function fix that behaves as we require, so it's adding 'fix' as constant to the language just like we might add 3 as a constant to simply type lambda calculus.
11:01:34 <dcoutts> davidhouse, it's common to take simply typed lambda calculus and extend it with various constants
11:01:42 <Cale> Revision17: If you want to create a new type to have a separate Monad instance, use newtype rather than type
11:01:47 <dcoutts> ie named functions etc
11:01:58 <davidhouse> Cale, he doesn't, he basically wants State with a specific env.
11:03:03 <davidhouse> dcoutts: hmm... i don't quite see. what precisely do you mean by 'constant' here?
11:04:09 <xerox> davidhouse - Cale is right.  Newtype deriving does what Revision17 is aiming for.
11:04:12 <dcoutts> davidhouse, a constant like 0,1, (+), (-), map, etc etc
11:04:56 <dcoutts> davidhouse, any named value
11:05:05 <davidhouse> dcoutts: oh, so functions are constants too. what's not a constant?
11:05:21 <xerox> IORefs (-:
11:05:24 <davidhouse> xerox, why?
11:05:34 <davidhouse> not the IORef comment, your previous one.
11:05:35 <int-e> davidhouse: variables introduced by lambda abstraction
11:05:40 <dcoutts> something which is expressed using the constructs of lambda calculus
11:05:41 <xerox> Because they do mutate, but there could be objections.
11:06:14 <davidhouse> odd.
11:06:26 <int-e> xerox: but the Ref is constant
11:06:29 <davidhouse> so (+) is a constant, but \x y. x + y isn't?
11:06:33 <dcoutts> davidhouse, so we add in as constants things which we can't express directly in lambda calculus
11:06:42 <int-e> xerox: (well, GC aside)
11:07:28 <dcoutts> Daveman, \x y. x + y contains a constant
11:08:12 <davidhouse> assume you're talking to me :)
11:08:26 <int-e> davidhouse: you extend the language. \x y. (+) x y  wouldn't be a lambda term if + weren't a constant (unless you want to make (+) a valid variable name in which case it'd be an unbound variable)
11:09:02 <davidhouse> right, i think i get it. so constants are like "built-ins"?
11:09:14 <int-e> davidhouse: now in Haskell (+) actually isn't magic - it's the primops that are.
11:09:21 <int-e> yes.
11:09:39 <davidhouse> primops, as well as things like if, case?
11:09:47 <int-e> constants get their own reduction rules in the calculus.  like,  2 + 2 --> 4
11:09:53 <davidhouse> although if could be lambda'd.
11:09:54 <int-e> or  fix a -> a (fix a)
11:10:19 <dcoutts> davidhouse, er yeah I did mean you, oops :-)
11:12:16 <xerox> int-e - Is it really needed for the Ref to be constant?
11:13:01 <dcoutts> davidhouse, things like if & case are extra language constructs, rather than just constants
11:13:13 <dcoutts> adding constants to a language is easier
11:13:21 <dcoutts> so yes, they're like primops
11:13:31 <SamB> yeah, you can add constants to the library instead ;-)
11:13:49 <SamB> not many languages have keyword libraries
11:13:57 <int-e> xerox: everything else would break referential transparency, and in Haskell that should require unsafe stuff or working in IO.
11:14:55 <int-e> xerox: the contents of the memory referenced by the IORef can't be accessed by those means and thus don't matter.
11:15:03 <xerox> int-e - IORefs require working in IO.
11:15:22 <int-e> xerox: head :: [IORef a] -> IORef a  is pure
11:15:30 <xerox> Ah-ha!  So their constantness doesn't exactly matter.
11:15:59 <int-e> you can do a lot of stuff with references without dereferencing them.
11:16:22 <xerox> That's right.
11:17:28 <xerox> There is no IORef# right?
11:17:40 <int-e> @index IORef
11:17:41 <lambdabot> Data.IORef
11:18:11 <xerox> @docs Data.IORef
11:18:11 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Data-IORef.html
11:18:22 <int-e> newtype IORef a = IORef (STRef RealWorld a)
11:18:29 <int-e> (ghc)
11:19:01 <int-e> and data STRef s a = STRef (MutVar# s a)
11:19:20 <xerox> ....and MutVar# ?
11:19:21 <SamB> lambdabot still uses compiled-in configurations, right?
11:19:26 <int-e> is builtin
11:19:28 <int-e> hence the #
11:20:22 <xerox> The levels of indirection makes IORef fit your description, imo.
11:21:31 <xerox> Do you think it is possible for the pointer address (not the address the pointer points to) to change at runtime in compiled code?
11:22:15 <SamB> strange question...
11:22:22 <int-e> I'm not sure. With cooperation of the GC it might be possible.
11:22:28 <SamB> doesn't really matter, if you aren't allowed to read it
11:22:36 <SamB> because it will still be different from all the others
11:22:41 <SamB> and the same as itself
11:23:02 <int-e> I mean, this is not a foreign pointer where non-haskell code could have references to the stuff.
11:23:15 <xerox> That's what I think when I say that the ref itself is mutable.  At language level it doesn't break referential transparency, but nothing forces this behaviour in compiled code...
11:23:22 <SamB> you don't really need to know what the address is.
11:23:48 <xerox> Well, there is a reason if we do Higher Level programming.
11:23:59 <int-e> you can't tell
11:24:23 <xerox> int-e - But it is possible in principle, so you can't tell either that it is constant.
11:25:23 <int-e> right.
11:25:34 * xerox hops up and down furiously
11:26:39 <int-e> of course I might just adopt the right definition for 'constant' :P
11:27:08 <xerox> Making a point with int-e ... /me scribbles on the calendar.
11:28:05 <int-e> heck, I'd think I'm wrong often enough :)
11:28:15 * xerox hugs int-e 
11:40:01 <int-e> @karma- @karma
11:40:01 <lambdabot>  @karma's karma lowered to -1.
11:40:55 <davidhouse> hah. :)
11:54:20 <vincenz> :)
11:57:38 <davidhouse> what does the B-combinator do?
11:58:22 <SamB> @karma
11:58:22 <lambdabot> You have a karma of 9
11:58:33 <SamB> @karma lambdabot
11:58:33 <lambdabot> lambdabot has a karma of 12
11:58:37 <SamB> ooh
11:58:47 <int-e> (B a b c) = (a (b c))
11:59:35 <xerox> (((Bf) g) x) → (f (gx))
11:59:43 <davidhouse> thanks, int-e.
12:00:24 <int-e> so, B = (.)
12:01:23 <davidhouse> @pl b f g x = f (g x)
12:01:24 <lambdabot> b = (.)
12:06:28 <SamB> hmm, there seem to be a lot of problems with lambdabot and latest Data.ByteString...
12:18:47 <vincenz> @karma
12:18:48 <lambdabot> You have a karma of 4
12:18:58 <davidhouse> http://www.willamette.edu/~fruehr/haskell/evolution.html#listencoding i really like this definition of fac.
12:27:13 <davidhouse> wow. according to my laptop battery manager, i've got 5% of my battery left, and that equates to 1.5 hours! :)
12:27:39 * davidhouse longs for a 30-hour battery
12:29:47 <lispy> davidhouse: heh, i'd hate to have a 30-hour battery on my laptop with current technology.  I'd never be able to take it anywhere :)
12:31:14 <davidhouse> hehe
12:38:43 <davidhouse> err, now it's gone up to 9 hours.
12:38:47 <davidhouse> still on 5%
12:48:18 <int-e> @pl \(a,b,c)->a b c
12:48:18 <lambdabot> (line 1, column 6):
12:48:18 <lambdabot> unexpected ","
12:48:18 <lambdabot> expecting letter or digit, operator or ")"
12:48:18 <lambdabot> ambiguous use of a non associative operator
12:48:24 <int-e> @pl \(a,b)->a b
12:48:25 <lambdabot> ap fst snd
12:48:51 <xerox> So true.
13:01:29 <Razor-X> Does Yet Another Haskell Tutorial go into more depth than A Gentle Introduction to Haskell?
13:06:29 <int-e> > let x=[9,3,7,6,9,9];m q(a,o,b)n=(a,o,q b n);a q v n=(u v,q,n);u(a,o,b)=o a b;(y:z)=map(%1)x in [(zip t x>>= \((_,o),n)->show n++o)++show(last x)|t<-mapM(\_->[(a(+),"+"),(a(-),"-"),(m(/),"/"),(m(*),"*")])z,u(foldl(\v(n,(f,_))->f v n)(0,(+),y)$zip z t)==100]
13:06:30 <lambdabot>  Couldn't match `t -> t1 -> (a1, a1 -> c -> a, c)' against `(a2, b, c1)'
13:07:07 <int-e> aww.
13:09:57 <int-e> works in ghci so. *mumbles*
13:20:47 <int-e> (I found out why: $zip is a template haskell construct)
13:51:42 <int-e> @karma
13:51:43 <lambdabot> You have a karma of 5
13:59:05 <int-e> @version
13:59:05 <lambdabot> lambdabot 3.1p18, GHC 6.4.1 (Linux i686 3.20GHz)
13:59:06 <lambdabot> darcs get http://www.cse.unsw.edu.au/~dons/lambdabot
14:13:27 <SamB> hmm, interesting, Relax NG's compact syntax appears to be specified using a simple functional programming language...
14:16:05 <dcoutts> I hope it doesn't take a turing complete language to specify
14:16:18 <dcoutts> one might hope a CFG or something might be sufficient
14:16:31 <SamB> oh, well, I meant pure actually ;-)
14:16:52 <SamB> and it is really more of an expression language
14:17:54 <SamB> you know how most language specs have grammars but leave out the part that normally goes in the curly brackets?
14:18:14 <SamB> this one doesn't ;-)
14:21:30 <davidhouse> anyone recommend a nice online textbook for learning about the various lambda calculi/type systems in general?
14:23:43 <hyrax42> was the max projects given to a mentoring org 10?
14:23:53 <davidhouse> hyrax42: look at KDE.
14:23:55 <hyrax42> oh nm
14:23:59 <hyrax42> mozilla has 13
14:24:14 <hyrax42> just was surprised to see that haskell got more than rubycentral
14:24:30 <Lemmih> We'll be more organized next year.
14:25:02 <hyrax42> hopefully I'll be able to participate then
14:25:28 <SamB> is it *really* that surprising?
14:25:44 <SamB> I mean, which is easier to read -- Haskell or Ruby?
14:25:51 <petekaz> ruby is not bad.
14:26:01 <davidhouse> SamB: compared to the ruby community, us haskellers are small fry.
14:26:14 <JKnecht> it's a smalttalk patois aint it?
14:26:23 <SamB> well, Google is not impressed so much by popularity
14:26:34 <davidhouse> evidently not.
14:26:44 <davidhouse> but Ruby has rails and gems and a lot of cool things.
14:26:45 <SamB> and I heard one of the SoC people liked Haskell a lot, too ;-)
14:27:14 <SamB> well, apparantly a lot of people don't like Ruby on Rails. In fact, I would avoid mentioning it if I were you.
14:27:29 <petekaz> Personally, I'm not sure why Ruby has received so much hype when Python is so much more mature.
14:27:31 <SamB> not as many as think they like it, maybe
14:27:57 <SamB> and Google is more interested in Python than Ruby, aren't they?
14:28:11 <petekaz> I believe so ... Norvig likes Python.
14:29:37 <davidhouse> someone remind me... A |- B in logic means that B follows from A, right? in other words, A implies B?
14:29:53 <xerox> If A, then B.
14:29:58 <petekaz> I think the Ruby phenomenom is due to two things: 1) RoR and 2) some Java pundits "discovered" it and started blogging about it (the same that were pushing various agile methodologies).
14:30:10 <davidhouse> xerox, right. so A => B.
14:30:36 <davidhouse> petekaz: yeah, RoR caught on to the ajax thing really quickly and soon became synonymous with Web 2.
14:30:39 <davidhouse> *2.0
14:31:36 * SamB just really likes the fact that the RELAX NG Compact Syntax specification tells you what you need to put in your AST datastructures
14:31:39 <Razor-X> I like Ruby, but I've never used/don't intend to use Rails.
14:31:59 <xerox> SamB - What is Relax NG?
14:32:39 <SamB> xerox: XML schemas done right
14:36:48 <Cale> I really don't understand why people consider rails to be such a big deal. Perhaps I'm missing something, but it just looks like a bunch of ordinary network and database libraries.
14:37:54 <ValarQ> Cale: ordinary network and database libraries isn't a big deal?
14:37:55 <davidhouse> it's a lot of boilerplate code.
14:38:22 <davidhouse> you can create a standard DB-based web app really quickly.
14:38:44 <vincenz> yeah
14:38:48 <vincenz> it's mostly the seamlessness
14:39:04 <petekaz> I think it's really just that one can define some objects, and then have the data model is persisted automatcially and the web page is auto generated that lets you edit it.
14:39:28 <davidhouse> plus all the nice ajaxy stuff it features.
14:39:40 <davidhouse> plus a lot of the people migrating to it came from PHP... 'nuff said :)
14:39:56 <davidhouse> doesn't take much to impress someone that's used to that poor excuse of a language.
14:40:43 <davidhouse> but no; i've used RoR and liked it.
14:40:51 * davidhouse makes a mental note to relearn ruby
14:40:59 <davidhouse> it's on the list after C++ and perl :)
14:42:57 <vincenz> perl???
14:43:39 <davidhouse> whatever set of languages i choose i'm going to get people saying exactly that, so why not choose a language who's compiler i can hack? :)
14:44:08 <xerox> pugs> [+] 1..10
14:44:09 <xerox> 55
14:44:55 <xerox> pugs> (1..10) >>*<< (1..10)
14:45:22 <davidhouse> *whose
14:45:27 <xerox> 1,4,9,16,25,36,...
14:45:38 <xerox> Fun language :)
14:45:47 <davidhouse> yeah, perl6 has got some nice haskell-like operators.
14:47:07 <davidhouse> does the Y-combinator break the normalisation property?
14:47:45 <davidhouse> does HM even have the normalisation property?
14:48:46 <hyrax42> oh
14:48:58 <hyrax42> SamB: I guess not so surprising
14:50:37 <petekaz> How does the list monad relate to logic programming?
14:51:10 <xerox> It can be used to represent nondeteremism and doing backtracking.
14:51:14 <xerox> I.e. prolog.
14:51:20 <petekaz> I'm reading this: http://en.wikibooks.org/wiki/Programming:Haskell_monads#Introduction
14:51:24 <xerox> nondeterminism, even.
14:51:33 <petekaz> Do you have an example?
14:51:56 <davidhouse> petekaz: seen Cale's sudoku solver?
14:51:59 <xerox> The idea, since Haskell is lazy, is to provide all the possible result as a list of result.
14:52:16 <davidhouse> it uses NonDet, which is a drop-in replacement for []. it's used for backtracking.
14:52:34 <petekaz> I really like what this paragraph states:
14:52:44 <petekaz> "Most languages are "imperative": they have no problem with side effects. Part of their programmer model is a "flow of control". A statement which has a side effect can change the result of something that happens further along in the flow of control. But because Haskell has no side effects it has no concept of flow of control either."
14:53:23 <petekaz> davidhouse: I'll look at it, was hoping for a simple example here though.
14:53:32 <Cale> http://www.haskell.org/haskellwiki/Sudoku
14:53:41 <dcoutts> @localtime dons
14:53:42 <lambdabot> Local time for dons is Sun May 28 07:46:54 2006
14:53:55 <dcoutts> too early yet
14:54:02 <Cale> petekaz: as a simple example...
14:54:10 <petekaz> xerox: if all the results are stored in a list, how does that relate to backtracking?
14:54:12 <xerox> I think @eval should provide a pre-seeded randoms.
14:55:10 <Cale> > do { x <- [1..20]; y <- [x..20]; z <- [y..20]; guard $ x^2 + y^2 == z^2; return (x,y,z) }
14:55:11 <lambdabot>  [(3,4,5),(5,12,13),(6,8,10),(8,15,17),(9,12,15),(12,16,20)]
14:55:23 <xerox> Right, backtracking is usually expressed with guards.
14:55:30 <Cale> that does a backtracking search for pythagorean triples
14:56:06 <petekaz> can I not do that same thing using python's list comprehensions?
14:56:15 <petekaz> Or is laziness required.
14:56:30 <Cale> List comprehensions essentially are the list monad.
14:56:44 <Cale> Though it helps if things are lazy.
14:57:17 <Cale> It's hard to solve really large problems if the lists are strict.
14:57:29 <davidhouse> [ f x | x <- xs, predicate ]   ==   do x <- xs; guard predicate; return (f x)
14:57:30 <petekaz> I see.
14:57:31 <xerox> It would be like using loops.
15:01:12 <vincenz> woo
15:01:21 <vincenz> downloading something at 540 Kb/s
15:02:14 <davidhouse> simply-typed lambda calculus: what does the following mean in normal english>
15:02:17 <davidhouse> http://upload.wikimedia.org/math/e/0/0/e0061f3d6c7c0868d6d4ea2f7f7133ac.png
15:02:31 <psi> I download my ubuntu updates at ~4000 kB/s :)
15:03:28 <xerox> The upper-left greek letter is the axioms given.
15:03:42 <davidhouse> i get it to be something like "given the type context Lambda, if x has type sigma and y is not equal to x, then we can infer from the same type context and the fact that y has type tau that x has type sigma.
15:03:46 <xerox> I am not sure about the ':'
15:03:53 <xerox> Oh, types.
15:03:53 <davidhouse> xerox, "has type"
15:03:54 <Cale> davidhouse: If, based on the context Gamma, x gets type sigma, and x is not equal to y, then Gamma with the added rule that y gets type tau will prove that x gets type sigma.
15:04:02 <davidhouse> oops, it's a gamma.
15:04:21 <dcoutts> davidhouse, it says that if y :: t and x :: a and x/=y then x :: a
15:04:49 <davidhouse> Cale, so that's saying that you can add new bits of data to type contexts without changing existing values, basically?
15:04:49 <Cale> It's just saying that if you add equations having nothing to do with a term to a context which already proves that a term has some type will not affect this.
15:04:54 <Cale> yes
15:05:01 <davidhouse> right
15:05:07 <Cale> It's just saying that in an irritatingly formal way.
15:05:13 <dcoutts> heh
15:05:18 <davidhouse> :)
15:05:31 * davidhouse wishes people would use quantifiers and implication signs more often.
15:06:15 <Cale> I actually like an even less symbolic form.
15:06:30 * dcoutts likes typing judgements
15:06:39 <Cale> I'll tend to write down how the symbols would be read anyway, unless I'm doing something computation-like with the symbols themselves.
15:06:55 <Cale> (i.e. use English)
15:07:35 <Cale> Or, I suppose, if I'm trying to save space.
15:07:53 <xerox> Or write strange novels (;
15:07:55 * davidhouse spends a few minutes editing the wikipedia page so that everyone else can understand the irritating formalism too :)
15:07:55 <Cale> But if I'm writing something for a human to read, I try to be as sparing as possible with symbols.
15:08:26 <Cale> The use of period for context extension seems silly too.
15:09:16 <Cale> I'd probably have chosen set theoretic notation.
15:09:20 * dcoutts would use \gamma[x |-> t]
15:09:50 <Cale> I'd use \Gamma \cup \{y : \tau\}
15:09:50 <dcoutts> using ':' on either side of the |- is confusing
15:12:00 <davidhouse> that came from http://en.wikipedia.org/wiki/Simply_typed_lambda_calculus. what would be the best way to give each of those four equations a number?
15:12:17 <vincenz> psi: 4 MB???
15:12:23 <vincenz> psi: what kinda connection you got
15:14:57 <vincenz> out of curiousity regaring typed lambda calculus
15:15:03 <vincenz> isn't it typically ',' and not '.'
15:15:05 <vincenz> or possibly ';'
15:15:17 <davidhouse> vincenz: where?
15:15:32 <vincenz> davidhouse: the page you referred to use
15:15:36 <vincenz> Context.x:tau
15:15:47 <vincenz> not Context;x:tau      or Context,x:tau
15:16:32 <davidhouse> dunno.
15:17:37 <jethr0> holla vincenz
15:23:03 <psi> vincenz: 100 Mbit
15:23:32 <hyrax42> ah the good old days
15:23:39 * hyrax42 misses having 100 mbit connection
15:28:20 <vincenz> psi: me too but straight to internet/?
15:28:34 <vincenz> damn... no s-video cable
15:28:44 <vincenz> I guess I'll watch the movie on my lappy :/
15:29:01 <xerox> Goodnight.
15:31:45 <vincenz> night
15:32:12 <davidhouse> @type let s x y z = x z (y z); k x _ = x; i x = x in (\x y -> y x, s (k (s i)) (s (k k) i))
15:32:13 <lambdabot> forall t
15:32:14 <lambdabot>                                 t1
15:32:14 <lambdabot>                                 t2
15:32:14 <lambdabot>                                 t3.
15:32:14 <lambdabot>                               (t1
15:32:15 <lambdabot> [7 @more lines]
15:32:19 <davidhouse> @more
15:32:19 <lambdabot>                               -> (t1
15:32:19 <lambdabot>                                 -> t)
15:32:21 <lambdabot>                               -> t,
15:32:23 <lambdabot>                               t2
15:32:25 <lambdabot>                               -> (t2
15:32:27 <lambdabot>                                 -> t3)
15:32:29 <lambdabot>                               -> t3)
15:32:35 <davidhouse> great.
15:34:17 <Cale> @type let f x = (x,x); f1 x = f (f x); f2 x = f1 (f1 x); f3 x = f2 (f2 x); f4 x = f3 (f3 x) in f4
15:35:12 <SamB> someone really ought to hack @type to at least dedent the lines after the first to match it...
15:35:13 <lambdabot> forall a.
15:35:13 <lambdabot>                                 a
15:35:13 <lambdabot>                                 -> ((((((((((((((((a,
15:35:13 <lambdabot>                                       a),
15:35:13 <lambdabot>                                       (a,
15:35:21 <lambdabot> [65533 @more lines]
15:35:49 <SamB> would be better if GHC could be coaxed to not display the expression in the first place...
15:36:43 <davidhouse> > let s x y z = x z (y z); k x _ = x; i x = x in ((\x y -> y x) 4 show, (s (k (s i)) (s (k k) i)) 4 show)
15:36:44 <lambdabot>  ("4","4")
15:36:56 <davidhouse> lambda -> combinatorics :)
15:40:40 <davidhouse> > let s x y z = x z (y z); k x _ = x; i x = x in ((\x y -> y x) 4 show, (s (k (s i)) k) 4 show)
15:40:41 <lambdabot>  ("4","4")
15:41:16 * SamB laughs at the people who have to type a long java command to run trang
15:41:30 <Cale> trang?
15:41:52 <Cale> oh, some XML thing
15:49:37 <SamB> yes.
15:50:09 <SamB> the one in debian is built with GCJ, so runs natively with no jar or JVM
16:14:42 <dcoutts> @localtime dons
16:14:44 <lambdabot> Local time for dons is Sun May 28 09:07:55 2006
16:14:58 * dcoutts has more array fusion news
16:38:20 <mauke> yay, it works!
16:38:37 <mauke> if anyone wants to see my latest perversion, it's at http://mauke.ath.cx/stuff/perl/add.pl
16:39:31 <wolverian> ugh, nice
16:39:42 <basti_> LOL
16:39:58 <basti_> deimos.dynalias.org/kommutativdistributiv.pl < in a similar vein
16:41:46 <mauke> this what happens when you implement addition with binary operators, convert the loop to recursion, convert the whole thing to lambda calculus, then use CPS in Perl
16:53:05 <LordBrain> Hey.. i think someone in here once recommended a book on category theory for haskell programmers.. anyone know the one?
16:53:26 <dcoutts> category theory for the working programmer perhaps?
16:53:36 <dcoutts> I don't know if it's any good
16:53:38 <LordBrain> hmm i dont know.. how many are there
16:53:51 <dcoutts> not too sure myself
17:22:56 <SamB> what about the playing programmer?
17:29:54 * SamB wonders how to implement monopd protocol
17:33:20 <aFlag> does anyone know about some application written in haskell using opengl?
17:39:27 <Cale> there's Frag
17:56:40 <dons> moin
17:56:56 <dons> dcoutts: ?
17:57:04 <dcoutts> hia dons 
17:57:12 <dcoutts> lots of RULES hacking
17:57:30 <dons> good stuff!
17:57:50 <dcoutts> do you have some patches from me or did I foget to send them?
17:58:01 <dons> no patches
17:58:08 <dons> just an email saying there are patches
17:58:11 <dcoutts> ok, sent
17:58:32 <palomer> @palomer
17:58:33 <lambdabot> Brump!
17:58:34 <dcoutts> dons, so I was looking at the list versions
17:58:36 <dons> so, today i'll compare the old and the new, and try to steal the ndp fusion test code.
17:58:41 <dons> ok, yeah?
17:58:42 <dcoutts> ah good
17:59:03 <dcoutts> yeah, and the list stuff doesn't work in quite the same way as the current array stuff
17:59:23 <dcoutts> it can't because we can't combine up & down loops into a single wraper like we do with arrays
17:59:51 <dcoutts> so we can't do the neat trick of unwrapping and then fusing adjacent loops
17:59:57 <dcoutts> but we can do something similar
18:00:08 <dons> oh really?
18:00:24 <dcoutts> basically we fuse between the 'wrapped' versions rather than the unwrapped versions 
18:00:34 <dcoutts> ie no wrapper/mutator split
18:00:42 <dcoutts> just fuse at the top level
18:01:08 <dcoutts> so we still get 23 cases :-)
18:01:18 <dons> oh good .. I think.
18:01:44 <dcoutts> but that also means we can use more specific 'wrappers'
18:02:03 <dons> ok. good, that's a win
18:02:05 <dcoutts> eg the one for map doesn't need to carry the accumulator
18:02:46 <dcoutts> so it rather begs the question of if we could do that technique for the array style
18:02:52 <dcoutts> so we're more consistent
18:02:57 <dcoutts> and the answer is yes
18:03:19 <dcoutts> though I guess we'd then need an extra rule to combine and up loop with a down loop
18:03:31 <dcoutts> ie the previous unwrapping rule
18:03:46 <dons> so we can avoid the unwrappeing split and rules?
18:03:58 <dcoutts> yes
18:04:06 <dcoutts> so we still have 23 rules
18:04:12 <dons> ok. that'll look better on paper.. ;)
18:04:24 <dcoutts> but they'd operate at the loop wrapper level
18:04:32 <dons> and float out the wrappers?
18:04:42 <dcoutts> well the wrappers are directly combined
18:04:44 <dcoutts> eg:
18:04:46 <dons> yeah.
18:04:49 <dcoutts> instead of:
18:05:06 <dcoutts> "loop/loop wrapper elimination"  and "up/up loop fusion"
18:05:27 <dcoutts> we directly do:
18:05:27 <dcoutts> "up/up list fusion" forall f1 f2 acc1 acc2 arr.
18:05:28 <dcoutts>   loopUp f2 acc2 (loopArr (loopUp f1 acc1 arr)) =
18:05:28 <dcoutts>     loopSndAcc (loopUp (f1 `fuseAccAccEFL` f2) (acc1 :*: acc2) arr)
18:05:42 <dcoutts> which looks much like the old loopU rule
18:05:51 <dons> yep.
18:05:55 <dons> good
18:05:58 <dcoutts> but instead of one loopU rule there are 23 special cases :-)
18:06:59 <dcoutts> but that also means we eliminate NoAcc type entirely
18:07:05 <dons> oh?
18:07:18 <dons> oh you eliminate it from the loops for map and filter?
18:07:29 <dcoutts> because we're covering all the holes that NoAcc used to fill by special case loops
18:07:33 <dons> yeah.
18:07:40 <dons> so we should be able to approach map'
18:07:45 <dcoutts> right
18:07:47 <dons> any numbers on that?
18:07:51 <palomer> grr
18:08:00 * palomer kicks latex
18:08:21 <dcoutts> on the current stuff I've sent you we're still down slightly using ghc 6.5
18:08:49 <dcoutts> I've not benchmarked this newer stuff much yet
18:08:52 <dons> but what about 6.4.x ?
18:09:09 <dcoutts> I've not been testing with 6.4
18:09:34 <dcoutts> with 6.5 the difference between map and map' is about 15%
18:09:40 <dons> ok. not too bad. 
18:09:41 <dcoutts> rather than 40% previously
18:09:58 <dcoutts> and this stuff I'm looking at now might get that even lower
18:10:32 <dcoutts> in fact it's almost exactly the same code as map'
18:10:38 <dcoutts> so it really should do
18:10:45 <dons> ok. good.
18:11:35 <dcoutts> dons, I worry that we're being too strict in places
18:11:51 <dcoutts> eg foldEFL and foldEFL' seem to be exactly the same
18:11:56 <dons> hmm.
18:12:11 <dcoutts> foldEFL' f = \a e -> let a' = f a e in a' `seq` (a' :*: NothingS)
18:12:18 <dcoutts> that seq is doing nothing
18:12:34 <dons> yeah, maybe. but does anyone care i wonder?
18:12:50 <dcoutts> well foldr will be strict so no lazy unpacking
18:13:12 <dcoutts> and I worry about what it does for the .Lazy versions
18:13:14 <dons> i wonder why they do this in the ndp branch too, then.
18:13:40 <dcoutts> I wonder if (# , #) wouldn't be better than (  :*:  )
18:13:53 <dons> oh, that's an interesting idea.
18:13:59 <dons> ah, no good for hugs though
18:14:06 <dcoutts> #ifdef
18:14:08 <dons> we'd need to type alias it.
18:14:10 <dons> or that.
18:14:19 <dcoutts> type alias using #ifdef
18:14:32 <dons> yeah, interesting. we know the strict pairs are needed for some rules to work though
18:14:36 <dons> we found that the other day
18:14:43 <dons> but it may be that they're not needed everywhere
18:14:54 <dcoutts> I've eliminated most of the strict pairs anyway
18:14:54 <dons> so if , for semantics, we need to remove some, then that'd be ok.
18:15:00 <dons> yeah?
18:15:08 <dcoutts> by eliminating the NoAcc
18:15:12 <dons> ah. right.
18:15:24 <dcoutts> so the only place we use the Pair is where it's actually needed
18:15:34 <dons> cool
18:15:40 * dons gets coffee. back in 10
18:15:40 <dcoutts> which is when combining up/up down/down loops
18:15:44 <dcoutts> ok
18:15:52 * dcoutts gets a cup 'o tea
18:27:40 <dcoutts> dons, phew!
18:27:59 <dcoutts> dons, for a moment there I thought this was running slower, but it's ok
18:28:19 <dcoutts> it's very marginally faster than the curent code
18:28:49 <dcoutts> so being more extreme on the special cases doesn't seem to be hurting and is even a slight bonus
18:28:54 * SamB wonders if xmame really needs to build the blit files differently... stupid C and its lack of .hi files...
18:29:07 <SamB> (I enabled DEBUG...)
18:29:17 <dcoutts> but mostly it means we can take the same approach for both ByteString and [ByteString]
18:29:39 <dcoutts> in particular we can share the fuseFooBarEFL snippets
18:31:01 * SamB shuts down the running MAME to speed compilation, anyways...
18:37:27 <dons> dcoutts: ok. good. so i'll just apply your patches, and do some benchmarking across compilers
18:37:45 <dcoutts> dons, I've not sent the latest bits yet
18:38:00 <dcoutts> we've actually got 3 versions :-)
18:38:22 <dcoutts> we might want to compare all 3
18:38:45 <dcoutts> I don't know for sure that this latest stuff is faster than what I've already sent
18:39:03 <dcoutts> hmm, we need names for these versions/styles/techniques
18:39:08 * dcoutts ponders
18:39:16 <dcoutts> otherwise we'll get horribly confused
18:40:14 <dcoutts> there's the old loopU stuff, nice and simple just 3 RULES, use noAcc
18:41:10 <dcoutts> there's the new loopUp/Down/NoAcc/Map/Filter stuff, uses a wrapper/looping split , 3 + 23 RULES, uses noAcc
18:42:14 <dcoutts> there's the even newer loopUp/Down/NoAcc/Map/Filter stuff, doesn't split into wrapper+loop, 1 + 23 RULES, eliminates noAcc
18:42:36 <dcoutts> the third version also works for [ByteString]
18:43:14 <audreyt> dons: ping
18:43:25 <SamB> you could call them loopU, wrapped wonkaloop, and unwrapped wonkaloop...
18:43:25 <dcoutts> the frist version works for [ByteString], the second doesn't, at least not in the same style since with lists we can't do the wrapper+loop split
18:43:32 <dcoutts> SamB, nice!
18:43:39 <dcoutts> wonkaloop
18:43:41 <audreyt> dons: I'm building Pugs with ghc-6.5.20060526-i686-apple-darwin8 -- two problems
18:43:53 <SamB> refers to the glass elevator, which goes everywhichway
18:44:02 <dcoutts> hah
18:44:25 <audreyt> 1. fps's packCString vs packCStringLen is incompat API vs. GHC trunk; your darcs repo has it as CString->ByteString, but the GHC core has CString->IO ByteString
18:44:35 <audreyt> that is rather bad to #ifdef against.
18:44:52 <dcoutts> audreyt, use the CString->IO ByteString as that is correct
18:45:08 <audreyt> 2. GHC core has it in the "base" ackage; so I can't easily just hide that package when I want to use the bundled fps instead of core one
18:45:23 <dcoutts> the fps darcs repo now uses CString->IO ByteString (I think)
18:45:33 <audreyt> dcoutts: I don't doubt that, but it's confusing to see API breakage from upstream
18:45:36 <audreyt> no. I just did  get
18:45:42 <audreyt> it's ->ByteString
18:45:43 <dcoutts> audreyt, true, 2 is a problem
18:45:47 <dcoutts> really, hmm
18:45:50 * dcoutts looks
18:46:22 <dcoutts> ah true, thanks for pointing it out
18:46:25 <audreyt> it'd be better if we create a fps package in GHC core
18:46:30 * dcoutts makes a patch
18:46:42 <audreyt> I had used breakFirst and packByte
18:46:47 <audreyt> neither of which arei nthe GHC ore version
18:46:56 <dcoutts> audreyt, not really, long term fps is going into base, there won't be an fps package in the end
18:47:01 <audreyt> and I had to copy the implementations in my user code, as it stands
18:47:12 <dcoutts> audreyt, packByte -> singleton
18:47:20 <audreyt> ah thanks
18:47:24 <audreyt> breakFirst?
18:47:40 <dcoutts> I think we removed it
18:47:40 <SamB> major churn in the API right now ;-)
18:47:44 <dcoutts> what did it do exactly?
18:47:53 <dcoutts> we though it wasn't important
18:48:10 <dcoutts> how is it different from break and breakEnd ?
18:48:44 <dcoutts> SamB, aye, we're tring to make it nice before it gets frozen
18:49:06 <audreyt> It behaves like 'break', except the delimiter is
18:49:06 <audreyt> -- not returned, and @Nothing@ is returned if the delimiter is not in
18:49:08 <audreyt> -- the ByteString. I.e.
18:49:34 <audreyt> -- > breakFirst c xs ==
18:49:34 <audreyt> -- > let (x,y) = break (== c) xs 
18:49:34 <audreyt> -- > in if null y then Nothing else Just (x, drop 1 y))
18:49:39 <audreyt> I can inline that implementation here
18:49:41 <SamB> dcoutts: yes, is good ;-)
18:49:43 <audreyt> not really a problem
18:49:46 <dcoutts> so you can do the same with case break foo of (a,b) | blah blah ->
18:49:47 <SamB> hence smiley
18:50:05 <audreyt> yeah.
18:50:20 <dcoutts> audreyt, yeah we figured it wasn't that crucial and could be defined quickly if anyone really needed it
18:50:26 <audreyt> btw, I just made a OSX-Intel bindist 
18:50:30 <SamB> oh, the package should perhaps not be called fps anymore?
18:50:35 <audreyt> http://perlcabal.org/~audreyt/tmp/ghc-6.5.20060526-i686-apple-darwin8.tar.bz2
18:50:58 <audreyt> the annoying "disappearing ghc-" bug in Wolfgang's earlier build is apparently gone
18:51:07 <dcoutts> SamB, well it doesn't matter too much since it's not going to be around that long
18:51:14 <audreyt> and readline5 is working happily, as is cabal
18:52:11 <audreyt> dcoutts: let me know when I can pull the fixed fps code?
18:52:19 <dcoutts> ok
18:52:39 <SamB> dcoutts: I meant that when/if you make it a seperate package in the GHC libs, you should not call that package fps
18:52:53 <dcoutts> SamB, it's in the base lib
18:53:40 <SamB> dcoutts: yes, but audreyt is complaining that it should not be in "base" but in a seperate package
18:53:53 <dcoutts> SamB, that's only a transitional issue
18:53:55 <audreyt> having it in base kinda promises API compat
18:54:01 <SamB> hmm.
18:54:11 <audreyt> but otoh, until GHC 6.6.0, that promise doesn't need to be kept
18:54:25 <dcoutts> audreyt, right, which why we're hacking on the API before 6.6 freezes it
18:54:30 <SamB> so maybe you should keep it out of base just for convenience sake until you are happy with the API?
18:54:34 <audreyt> I wouldn't have problem, if not for the fact that GHC 6.4-STABLE branch doesn't build on macbook here 
18:54:45 <audreyt> even after I fixed the rts and mangler
18:55:08 <dcoutts> SamB, we've got enough time to fix the api, we have been looking at that recently
18:55:28 <audreyt> any timeframe as re: api freeze time?
18:55:36 <SamB> I realize it is to be fixed by 6.6 ;-)
18:55:39 <dcoutts> audreyt, the release of ghc 6.6
18:55:54 <audreyt> ok.
18:56:11 <dcoutts> though we'd obviously like to do as much of that as possible as early as possible
18:56:20 <SamB> the API should perhaps be frozen a bit before that in case there is the slight possibility of bugs?
18:56:24 <dcoutts> but no promises before 6.6
18:56:38 <dcoutts> SamB, right, that's why we should try and do it asap
18:56:48 <dcoutts> so we get time for feedback before 6.6
18:56:56 <SamB> dcoutts: yeah, me am lagged
18:57:03 <SamB> me saw:
18:57:09 <SamB> <SamB> the API should perhaps be frozen a bit before that in case there is the slight possibility of bugs?
18:57:09 <SamB> <dcoutts> though we'd obviously like to do as much of that as possible as early as possible
18:57:37 <dcoutts> heh, ok, I saw it the other way around :-)
18:57:57 <SamB> dcoutts: yes, I realize ;-)
19:01:47 <dcoutts> audreyt, actually the copyCString is already in the fps repo
19:02:28 <audreyt> oh 
19:02:36 <audreyt> it's just the line 188
19:02:42 <audreyt> and 189
19:02:47 <dcoutts> right, that bit was wrong :-)
19:02:47 <audreyt> needs updating to reflect reality
19:02:52 <dcoutts> it didn't get updated
19:02:54 <dcoutts> right
19:03:00 <audreyt> k thanks :)
19:03:07 * dcoutts fixes docs
19:06:05 <dons> audreyt: oh, did I forget to merge the IO copy functions back to fps?
19:06:16 <audreyt> dons: turns out only the docs was mismerged
19:06:22 <audreyt> the actual funcs are fine
19:07:20 <audreyt> http://hackage.haskell.org/trac/ghc/wiki/X86OSXGhc updated with the new osx86 build
19:07:33 <dons> ah. ok. good.
19:07:45 <dons> so yes, I'll probably merge fps into base/ less often then. 
19:07:48 <dcoutts> dons, I've got a patch for that, I'll send it with my nex batch
19:07:55 <rainman> hi im getting Instance of Num [Char] required for definition of substitute
19:07:56 <dons> but, like Cabal, we'll keep hacking until the 6.6 freeze
19:08:00 <rainman> Why?
19:08:07 <dons> hopefully very few things change now though.
19:08:07 <dcoutts> dons, so what do you want me to send now?
19:08:25 <dons> now. i can wait 30 mins . 
19:08:37 <dons> oh, maybe i misunderstand, just send everything, its easier
19:08:39 <audreyt> rainman: you did something like "123" + "456"
19:08:47 <audreyt> and mistook haskell for Tcl or Perl, maybe
19:08:48 <dcoutts> dons, I was thinking, do you want the changes to ByteString to make it use fusion version 2
19:09:03 <dcoutts> dons, and then seperatly I can send the fusion version 3
19:09:32 <rainman> impossible... where can I paste the code?
19:09:43 <rainman> its just 4 short lines...
19:10:00 <dons> dcoutts: does version 3 (this is the no -wrapper code?) override version 2?
19:10:07 <dcoutts> dons, yes
19:10:40 <dons> so why not send version 3, and we'll work on that? or is it too experimental?
19:11:08 <dcoutts> well at first it didn't seem to be working as well
19:11:16 <dcoutts> it looks ok now though
19:11:22 <rainman> http://pastebin.com/742205
19:11:28 <rainman> on line 4.
19:11:29 <dcoutts> mind you I've not tested this latest stuff nearly as much
19:11:53 <dcoutts> dons, I'd be inclined to benchmark v1 against v2
19:12:05 <dcoutts> and then do v3 next using the same framework
19:12:12 <dons> ok. hang on to v3 then, i'll look at v2 and try to check it thoroughly.
19:12:17 <dcoutts> ok
19:12:34 <dcoutts> I'll send the patch to actually use v2
19:13:53 <dcoutts> dons, yeah and v3 doesn't combine up & down loops yet
19:15:00 <dons> ok.
19:15:04 <dons> SamB, around?
19:15:43 <SamB_XP> playing street-fighter style sailor moon game... but yes.
19:16:00 <dons> you asked about lambdabot building with fps?
19:16:09 <SamB_XP> did I?
19:16:10 <dons> latest repo should need latest fps. i ported it yesterday
19:16:46 <SamB_XP> yeah, I had my friend pull the latest patches and eventually he managed to build it ;-)
19:17:02 <dons> 12:06:28 <SamB> hmm, there seem to be a lot of problems with lambdabot and latest Data.ByteString...
19:17:07 <dons> ok.
19:17:17 * SamB_XP goes back to game
19:17:20 <rainman> What the hell is wrong here? I'm going nuts: substitute [] b = []
19:17:20 <rainman> substitute (x:xs) b | x == fst b = [snd b] + substitute xs b
19:17:20 <rainman> 		    | otherwise = [x] + substitute xs b
19:17:48 <rainman> where b (Char, Char
19:17:56 <rainman> (x:xs) String
19:18:06 <rainman> (Char, Char)*
19:18:14 <rainman> the function returns a string.
19:18:16 <Cale> ++
19:18:18 <Cale> not +
19:18:21 <rainman> oh.
19:18:27 <Cale> or use snd b : ...
19:18:41 <rainman> its 4:15 in the night ^^
19:18:59 <rainman> thanks.
19:19:03 <Cale> no problem
19:20:12 <Cale> subst xs (a,b) = [if x == a then b else x | x <- xs]
19:22:00 <dcoutts> dons, ok sent
19:22:28 <dcoutts> dons, so in one test I've got ghc-6.5 is running about twice as fast a 6.4.2
19:22:36 <dons> ok. great!
19:23:00 <dcoutts> the test is a pipleine of 40 maps & filters and a foldl
19:24:20 <dcoutts> dons, so how do you plan to benchmark it? especially since you'd really have to be using ghc-6.5
19:24:54 <dons> well, i have both compilers here. and i can dump our fps into ghc's base/ dir.
19:25:13 <dons> then, i'll adapt the bench code to test the various pipeliens we want to fuse
19:25:23 <dons> and check they do so, versus unfused version with -frules-off
19:25:28 <dcoutts> ok, and for the V1 fusion vs V2 ?
19:25:48 <dons> before and after applying the patches, I suppose. easy to unpull
19:25:53 <dcoutts> ok
19:25:59 <dons> and then quickcheck the rules themselves
19:26:11 <dcoutts> I'm not sure the 6.4.2 test will be very interesting
19:26:20 <dons> ok.
19:26:24 <dcoutts> except to show how much better the rules work with 6.5
19:26:32 <dons> is the stuff you sent me good to apply to the main repo?
19:26:33 <dcoutts> but we knew that
19:26:49 <dcoutts> the main fps repo yes
19:26:51 <dons> yeah, true. 6.4.x is uninteresting.
19:26:54 <dons> ok. good. applying
19:27:07 <dons> ?karma+ dcoutts -- fusion engineer!
19:27:07 <lambdabot> dcoutts's karma raised to 13.
19:27:15 <dcoutts> it does actually use the new stuff now, but I did check the QCs eariler today
19:27:21 <dcoutts> so it should be ok...
19:28:02 <dcoutts> dons, fusion enginees eh? shall I tell you about the next iteration after V3 ? ;-)
19:28:24 <dcoutts> mmm, yet more special cases...
19:28:36 <dons> ah, ok. so we can further refine more cases?
19:28:40 <dcoutts> dons, so what's the special case we havn't covered yet?
19:28:44 <dons> or should we work out how to fuse more loops?
19:28:56 <dons> some other things: length . filter 
19:29:05 <dcoutts> right, folds
19:29:21 <dcoutts> folds at the end of a pipleine can be optimised more that we do now
19:29:29 <dcoutts> because a fold throws away the array
19:29:36 <dons> yep
19:29:40 <dcoutts> so we never need to allocate it or wirite into it
19:30:31 <dcoutts> so we've got the NoAcc case, next up is the AccOnly case
19:30:45 <dons> yeah.
19:30:55 <dcoutts> but I'll leave that for the moment :-)
19:31:09 <dcoutts> or we'll all get terribly confused
19:31:28 <dons> NoArr case, it would be :)
19:31:45 <dcoutts> I guess so :-)
19:31:52 <dcoutts> I want to be careful about not introdcing stuff on a hunch without benchmarks to support it
19:32:05 <dons> yes. this is very tricky stuff to get right;
19:32:10 <dcoutts> and if I change stuff to fast we won't get the chance to benchmark it properly
19:32:33 <dons> yep. i'm happy to have what we've got, get it understood and sorted properly.
19:32:56 <dcoutts> so I'll go try an extend V3 to combine up & down loops whoch got lost since V2
19:33:05 <dcoutts> this one might be tricky
19:33:12 <dons> ok. that's a good step.
19:33:17 <dcoutts> we want to combine up/down and down/up
19:33:40 <dcoutts> but I worry that doing so too early might prevent the normal up/up fusion
19:33:59 <dcoutts> we only want to combine up/down when no other fusions apply
19:34:09 <dcoutts> that happened automatically with V2
19:34:22 <dcoutts> because we combined and then fused within the wrapper
19:34:54 <dcoutts> so up/down combinations was just the residue of all the other fusion
19:35:08 <dcoutts> but now we need to do it explicitly
19:35:17 <dons> yeah. that was a nice property. hmm.
19:35:47 <dcoutts> I don't think we can delay it by a phase can we?
19:36:22 <dcoutts> imagine: up . up . down
19:36:45 <dcoutts> or rather: up f . up g  . down k
19:37:01 <dcoutts> we want to do the up/up first to get
19:37:15 <dcoutts> up (f `fuse` g)  . down k
19:37:20 <dcoutts> and then:
19:37:28 <audreyt> so, as it stands, if I'm to build pugs with ghc 6.6-trunk and I'd like to use .Lazy
19:37:35 <dcoutts> up (f `fuse` g)  `combine` down k
19:37:41 <audreyt> seems there's no easier way than rename Data.ByteString privately :/
19:38:01 <dcoutts> audreyt, or make a copy of Data.ByteString.Lazy privately
19:38:09 <audreyt> yeah
19:38:21 <dcoutts> audreyt, or suggest on the libraries list that we include .Lazy in base too
19:38:27 <dcoutts> we've not proposed it yet
19:38:36 <dcoutts> but we probably will at some point
19:38:37 <audreyt> but then the build system for <6.6 is hard to maintain here
19:38:48 <audreyt> as <6.6 will need its own fps too
19:39:05 <dcoutts> sorry :-(
19:39:06 <SamB_XP> why would you not include the whole package in base?
19:39:10 <audreyt> I wonder if it's sane to have a package that partially overlaps base.
19:39:19 <SamB_XP> it is not
19:39:20 <audreyt> (thats a polite way to say it's probably insane)
19:39:24 <dons> soon enough, hopefully, the whole thing will be in base.
19:39:34 * SamB_XP isn't especially polite ;-)
19:39:36 <dcoutts> SamB_XP, oh we just started on .Lazy after the rest was already in base
19:40:01 <dcoutts> audreyt, yeah, sadly that will not work
19:40:08 <dcoutts> you'll get module namespace clashes
19:40:25 <audreyt> which is what fps is currently at :)
19:40:30 <dcoutts> we get that problem when trying to test with ghc-6.5 too :-)
19:40:39 <audreyt> dons: yeah, entire-thing-into-base makes more sense
19:40:50 <audreyt> the nonbase parts should probably not be listed inthe same cabal package
19:40:52 <dons> when i test with 6.5, i just copy the lot into base/
19:42:01 <dons> dcoutts: if we can get this thing stablilised soonish, we should then look at pushing into base. if we can show a few users of .Lazy, then it shouldn't be too much of a problem i hope, since it seems a logical extension of the current Data.ByteString.
19:42:13 <dcoutts> dons, yeah
19:42:20 <SamB_XP> you don't need to show users!
19:42:28 <dcoutts> dons, JaffaCake worries about lazy IO 
19:42:32 <SamB_XP> users will appear out of woodwork
19:42:42 <dcoutts> I think it's something we should think about, ie exceptions
19:42:53 <dons> dcoutts: yes, i saw his comment.
19:43:09 <dons> i'll add a todo
19:43:25 <dons> oh, you've already done so.
19:43:26 <Revision17> is there a way I can access a part of a records without pattern matching, like the . operator in O'Caml (like someRecord.name) in haskell?
19:43:30 <dcoutts> dons, oh and we should make Lazy.hGetContents use non-blocking gets
19:43:44 <dons> Revision17: yeah, use the record name as a selector function
19:43:47 <Cale> Revision17: the field names are functions
19:44:08 <Revision17> oh wow; neat
19:44:12 <Revision17> thanks :)
19:44:20 <dcoutts> dons, that's in the TODO too, does it make any sense to you?
19:44:25 <dons> it does.
19:44:33 <dcoutts> ok good
19:44:54 <dons> the question of exception handling . hmm. it is hard.
19:45:06 <dcoutts> I think, just throw an exception
19:45:27 <dcoutts> we could try and be clever about what info goes into the exception
19:45:29 <dons> yeah. just have to be careful to clean up correctly
19:45:39 <dons> not much more we can do, i think
19:46:07 <dcoutts> what is a user going to want to do when an IO exception happens?
19:46:20 <dcoutts> it might be nice to know where we were when it happened
19:46:42 <dcoutts> eg to have some ability to restart in the same place
19:47:01 <dons> yeah. but how?
19:47:07 <dcoutts> not sure :-)
19:47:14 <dcoutts> stuff more info into the exception
19:47:53 <dcoutts> but it gets harder if you're lazily building some more complex structure, eg parsing deserialising, whatever
19:48:11 <dons> we should look into how the existing lazy io scheme handles exceptoins
19:48:21 <dcoutts> it jsut cuts off the string
19:48:27 <dcoutts> ... :[]
19:48:44 <dons> getContents and friends?
19:48:46 <dcoutts> rather than ... :(error "")
19:48:50 <dcoutts> dons, yep
19:49:00 <dons> oh, well, what's the problem then :) we can surely do that.
19:49:04 <dcoutts> apparently that's what it does
19:49:13 <dcoutts> I've not double checked
19:49:25 <dons> oh, i misunderstood simon's comment. i thought he meant that _ours_ cuts off, and that was bad.
19:49:28 <dcoutts> dons, but that's exactly what JaffaCake was compplaining about
19:49:48 <dcoutts> that you can't do sensible error handling
19:49:57 <dons> but if its a general problem with lazy io, then well, its a bigger issue, unless we try to push lazy io onto everyone (which i'm not inclined to do).
19:50:13 <dcoutts> so at least by throwing an exception we're doing better
19:50:22 <dons> yeah. that's reasonable.
19:50:24 <dons> we should do that.
19:50:35 <dcoutts> though there's still the problem of exceptions burried inside otherstructures
19:50:52 <dcoutts> so you don't know there there unless you're careful with strictness
19:51:01 <dcoutts> or do a deepSeq or something
19:51:08 <dons> yep. laziness is evil, apparently
19:51:41 <dcoutts> laziness is great for elegant IO
19:51:48 <dcoutts> and low heap usage
19:52:24 <dcoutts> but yeah, it does become harder when we want do deal precisely with errors
19:52:37 <dons> anyway, we can just keep hacking. and i think .Lazy can go into base without solving once and for all the lazy io issue. but we can do a better job with exceptions
19:52:46 <dcoutts> ok
19:53:24 <dcoutts> we could integrate with a future Streams lib
19:53:28 <dons> and we can drop map' i think. i'll look at that today.
19:53:35 <dcoutts> so giving you either lazy IO or strict
19:53:53 <dons> yeah, i already got an email from Bulat asking me to give him a private, modified version of fps (!)
19:54:04 <dons> so he can hack on it with his streams stuff
19:54:06 <dcoutts> streamTransformer :: (ByteString -> ByteString) -> Stream -> Stream
19:54:18 <dcoutts> what modifications does he want?
19:54:36 <dcoutts> I have to say I'm ever so slightly suspicious of Bulat's design
19:54:47 <dons> it looks pretty hairy, i must say.
19:55:12 <dons> anyway, he keeps asking me to back port the 6.5 ForeignPtr to 6.4.x
19:55:21 <dcoutts> aaarh1! no.
19:55:30 <dcoutts> is what I keep thinking when I see that :-)
19:55:31 <dons> i think he should just install 6.5..
19:55:36 <dcoutts> yeah
19:55:59 <dons> oh, you added scanr, and friends. good-o
19:56:13 <dcoutts> or just use it with 6.4, it does work afterall
19:56:36 <dcoutts> and actualy the performance doesn't seem that much different for most stuff
19:56:51 <dcoutts> it's only with these RULES bits that it's really different
19:57:08 <dons> yeah, you've seen the graphs. for lots and lots of strings, it makes a difference. but we haven't pursued the many-small-strings angle closely
19:57:16 <dcoutts> withForeignPtr is quicker right?
19:57:26 <dcoutts> one less de-reference right?
19:57:37 <dons> much simpler representation, and the Addr# is cached, so it less indirection, right.
19:57:48 <dons> its like unwrapping a Ptr
19:58:25 <dcoutts> so some things which we curently have as strict recursions inside a withForeignPtr could be tunred into lazy versions using tail perhaps without a performance loss
19:58:53 <dons> possibly.
19:59:20 <dcoutts> eg unpack
19:59:27 <dcoutts> I'm sure unpack should be lazy
19:59:49 <dcoutts> it'd be better use of memory
20:00:19 <dons> sounds reasonable.
20:00:39 <dons> yeah, we could look at that.
20:01:08 <dcoutts> I worry especially about foldr being too strict for the .Lazy module
20:01:53 <dcoutts> ie that it'd force the whole stream before producing anything
20:02:04 <dcoutts> even if you did foldr (:) []
20:02:21 <dons> ok. feel free to take action on that.
20:02:24 <dcoutts> because currentBulat
20:02:26 <dcoutts> oops
20:02:34 <dcoutts> right, ok I'll take a look
20:02:34 <dons> now i'm worried 
20:02:44 <dcoutts> :-)
20:03:09 <dcoutts> accidental ctl+v paste :-)
20:03:59 <dcoutts> it's quiet round here at this hour
20:04:23 <SamB_XP_> I told you, I'm playing that sailor moon game
20:17:42 <rainman> how can i express an empty char?
20:17:55 <hyrax42> there's no such thing?
20:18:15 <rainman> ?
20:18:21 <hyrax42> how can you express an empty Int
20:18:40 <rainman> stupid question ^^
20:18:49 <Cale> You could use a Maybe Char
20:19:00 <Cale> @type Just 'c'
20:19:01 <lambdabot> Maybe Char
20:19:11 <Cale> @type Nothing :: Maybe Char
20:19:11 <SamB_XP_> 0 -- there is a hole in the middle ;-P
20:19:12 <lambdabot> Maybe Char :: Maybe Char
20:19:53 * hyrax42 tried to think of a non-number "primitive" type
20:20:20 <rainman> i have a function in which in the beginning i should assign a char to a variable then call the function again recursively with the assigned char as an argument. I was trying to figure out a way how to notice when the function is called for the first time or not.
20:20:23 <Cale> Bool
20:20:32 <hyrax42> Cale: d'oh!
20:20:43 <rainman> not a variable :D
20:20:45 <rainman> oh god.
20:21:08 <hyrax42> recursive helper?
20:24:15 <rainman> http://pastebin.com/742270
20:24:24 <rainman> second line...
20:24:34 <rainman> im not very sure about that.
20:26:03 <Cale> comparing never returns any value other than its first parameter (or error)
20:27:08 <rainman> improved it.
20:28:22 <Cale> now  comparing = const
20:28:43 <Cale> (which makes it seem unlikely that you want it to do that)
20:29:13 <Cale> that is, I could optimise comparing by writing it like comparing a b = a
20:29:46 <SamB_XP_> isn't it supposed to go: comparing f a b = f a `compare` f b
20:30:07 <Cale> SamB_XP_: yeah, that's my comparing, this is a function in his code
20:32:05 <Cale> rainman: what do you want it to do?
20:32:19 <Cale> (what should substituteAll do, also?)
20:33:39 <rainman> eg: substituteAll "chatroom" [('c', 'q'), ('o', 'k'), (
20:33:58 <rainman> eg: substituteAll "chatroom" [('c', 'q'), ('o', 'k'), ('m', 'f')] = ghatrkkf
20:34:13 <rainman> qhatrkkf*
20:34:28 <Cale> well, you have substitute written already, right?
20:34:32 <rainman> yes
20:34:38 <Cale> This looks an awful lot like a fold to me :)
20:34:46 <SamB_XP_> you mean "qhatrkkf"?
20:34:57 <rainman> yes.
20:35:01 <palomer> @v
20:35:01 <lambdabot> "\"\\\"\\\\\\\"\\\\\\\\\\\\\\\"\\\\\\\\\\"
20:35:46 <Cale> I can't remember, does substitute take the pair first or second?
20:36:44 <mauke> > (\k r -> map (\x -> maybe x id (lookup x r)) k) "chatroom" [('c', 'q'), ('o', 'k'), ('m', 'f')]
20:36:45 <lambdabot>  "qhatrkkf"
20:37:03 <rainman> hehe
20:37:15 <hyrax42> @hoogle (a->Bool) -> [a] -> Bool
20:37:15 <lambdabot> Prelude.all :: (a -> Bool) -> [a] -> Bool
20:37:16 <lambdabot> Prelude.any :: (a -> Bool) -> [a] -> Bool
20:37:22 <hyrax42> gah I keep forgetting those
20:37:36 <rainman> nice...
20:37:55 <palomer> all and any are goodness
20:38:06 <hyrax42> I always forget what they're called
20:38:24 <Cale> rainman: what order does substitute take its arguments in?
20:38:33 <hyrax42> and *almost* write somethng using case (find ...) of
20:38:43 <Cale> substituteAll is probably just foldr substitute
20:38:44 <hyrax42> then think to check
20:39:07 <rainman> substitute :: String -> (Char, Char) -> String
20:39:15 <mauke> you can't just iterate over the substitutes
20:39:23 <mauke> consider [('a', 'b'), ('b', 'x')]
20:39:24 <Cale> yeah, flip the args on it, and that'll work, or use foldl
20:40:04 <Cale> good point
20:40:09 <hyrax42> use a Map or array
20:40:12 <hyrax42> ?
20:40:13 <dons> you can really push on QuickCheck as a poor man's theorem prover, in some ways.
20:40:23 <dons> if only we had a real theorem prover as convenient as QuickCheck
20:40:41 <dons> maybe i should read more agda papers
20:40:50 <hyrax42> agda?
20:40:56 <palomer> real theorem provers can't prove very much
20:40:57 <SamB_XP_> quickcheck is a theorem disprover ;-)
20:41:06 <dons> yep :)
20:41:16 <dons> palomer: ok. thanks for that. it goes in the quotes list ;)
20:41:25 <Cale> Negations of theorems are theorems too :)
20:41:41 <Cale> (well, potential theorems)
20:41:49 <palomer> a theorem is a provable closed formula
20:41:54 <dons> well, i want to prove associativity of a binary function i have rewrite rules for.
20:41:57 <SamB_XP_> yes, and QuickCheck potentially proves them
20:42:15 <Cale> Yeah, I should have said that negations of statements are statements too.
20:42:44 <dons> so i can nicely write that in quickcheck, but i get no guarantees about coverage for arbitrary functions (at least, the coverage guarantees are hard to devine from the coarbitrary method)
20:43:16 <dons> so, while i can actually prove via exhaustive search, properties on some types, properties on functions is a harder problem
20:43:41 <dons> however, being able to write this and get it checked with a reasonable set of things is comforting:
20:43:44 <dons> prop_sequenceloops_assoc x y z = (x * y) * z == x * (y * z)
20:43:46 <dons>     where (*) = sequenceLoops
20:43:54 <dons> i.e. being able to use haskell to code up my properties. big win.
20:44:39 <palomer> you guys make it sound so easy
20:44:49 <dons> we may just have to prove some things by hand though, for a paper. urgh!
20:44:53 <palomer> might as well wish for a computer to write the programs for you
20:45:34 <palomer> dons: once LF gets automation features, you could probably use it to prove whatever you want to prove seamlessly
20:45:38 <SamB_XP_> palomer: doesn't it?
20:45:50 <palomer> doesn't i what?
20:45:58 <dons> palomer: well, we'd have to write an instance of haskell in lf first..
20:46:10 <dons> we've only got system f + some sugar, atm.
20:46:11 <palomer> haskell-core has been formalised, I believe
20:46:21 <palomer> whatever that means
20:46:22 <SamB_XP_> write the programs
20:46:48 <dons> palomer: yeah, the guy who sits next to me did lf encoding of ghc core.
20:46:48 <palomer> usability > provability, in my books
20:47:10 <palomer> what bothers me about LF is that nothing says that the encode is accurate
20:47:17 <palomer> s/encoding/encode
20:47:35 <palomer> and sometimes that requires a proof in itself
20:47:35 <dons> right. you need to establish other things to ensure correctness of the encoding. no way around that.
20:47:42 <dons> same problem in isabelle or anything else
20:47:57 <dons> there's no magic embedding
20:48:13 <palomer> I'm a much bigger fan of making the theory obvious to everyone so a proof isn't needed
20:48:24 * dons gets back to actually checking things
20:49:00 <Cale> palomer: or at least, the proof is trivial
20:50:05 <aFlag> what's lf?
20:50:27 <palomer> something people at CMU orgasm over
20:50:35 <dons> LF, logical framework, a metatheory for proving properties of logics and languages
20:50:41 <dons> used in the ELF and Twelf systems.
20:50:56 <dons> yeah, and for what palomer said 
20:51:14 <aFlag> oh
20:51:24 <palomer> I don't think it's such hot stuff, though
20:51:43 <dons> palomer doesn't think anything is good for anything though.
20:51:58 <dons> forall anythings
20:52:06 <palomer> that's a lie
20:52:12 <palomer> I think vim is good for the rubbish bin
20:52:19 <dons> hehe
20:52:25 <dons> i knew i get something good out of that.
20:52:32 * dons hacks lambdabot's quote file
20:53:05 <SamB_XP> if only quickcheck came up with such amusing counterexamples
20:53:45 <dons> Test failed with: function f :: Int -> Bool, counterexample: fits in rubbish bin after 3 attempts
20:54:02 <dons> yeah, that'd rock
21:01:34 <rainman> should anyone be interested, here's my solution ^^: http://pastebin.com/742292
21:14:27 <petekaz> With all this lazy IO talk, I'm having a hard time understanding why lazy IO is more efficient.  In C, if I use the stdio library, and I use fgetc() in a loop, underneath the stdio library will read chunks.  How does lazy IO work?  Underneath, doesn't essentially the same thing happen?
21:15:02 <SamB_XP> lazy IO isn't necessarily any faster
21:15:19 <SamB_XP> but it does save memory over reading an entire file into memory!
21:15:24 <petekaz> Yet in various benchmarks (by dons) and some posts on the thread in the haskell library list, people keep saying lazy IO performs better.
21:15:42 <mwc> indeed, it gives you the programming simplicity of the naive approach
21:15:48 <mwc> with the performance of a more thought out approach
21:16:16 <petekaz> Without using lazy IO, is it possible in haskell to read chunks at a time similar to the C example I mention?  Or is that not possible?
21:16:17 <SamB_XP> well, this lazy ByteString approach does, anyway
21:16:33 <SamB_XP> the other one doesn't necessarily, because there might be a bit much overhead...
21:17:15 <SamB_XP> and Haskell has always been about making the naive approach practical, hasn't it?
21:18:51 <petekaz> I'm a newbie, but all this talk on the list about lazy IO has my head spinning as I just can't understand what the big deal is aside from letting the programmer write his/her program in a potentially clearer manner (although, writing the loop described above doesn't seem that hard at all).
21:18:52 <dons> petekaz, it'll handle the reading of chunks, and deallocating of chunks, in a single line. also, with fusion, we can perform optimisations not practical in gcc.
21:19:21 <dons> of course its possible to read chunks explicilty, without lazy io. its just easier with lazy io.
21:19:42 <petekaz> But what is all this hoopla wrt exceptions?
21:19:47 <SamB_XP> letting people write the easy to read program but run the fast program is a major goal of Haskell ;-)
21:20:15 <dons> yeah. we want to write our one liners that perform as well as 20 lines of C (or more). 
21:20:44 <dons> exceptions can't be caught in pure code. 
21:20:59 <dons> so if you write: f .g .h .i =<< Lazy.getContents
21:21:25 <dons> and you care about handling exceptions, well, you need to catch either at the top level, or wrap getContents.
21:21:40 <petekaz> so what's the big deal?
21:21:47 <dons> ?
21:22:07 <petekaz> seems easy enough, but people on the mailing list are still complaining about imprecise exceptions?
21:22:12 <dons> also, we don't say lazy chunked bytestrigns outperform C. they approach C to within a few percent. with fusion, we beat C t hough.
21:22:28 <dons> petekaz: i'm not sure there's complaints. just bulat didn't understand them.
21:22:31 <petekaz> I meant, what's the big deal on the mailing list that folks are complaining about.
21:22:51 <mauke> what's fusion and how does it beat C? :-)
21:22:52 <petekaz> meacham and simon's comments, perhaps I don't understand.
21:22:57 <dons> i don't think there's a big deal. some people didn't understand exceptions in pure code.
21:23:53 <petekaz> well, as I was talking about earlier today, I am looking forward to a regexp library for fps!
21:24:04 <dons> well, we have one in the works. you want the url?
21:24:14 * stepcut wants it
21:24:27 <dcoutts> dons, though it looks like it won't extend to .Lazy very well.
21:24:42 <dons> here's a Ptr binding to C (though C's regexes suck), http://www.cse.unsw.edu.au/~dons/code/hmp3/Regex.hsc
21:24:52 <dons> at least it'll avoid pack/unpack on each regex call
21:25:00 <petekaz> not yet ... I figure I have some time to learn how to write a useful haskell program before that is ready.  Still trying to learn haskell.
21:25:12 <dcoutts> dons, most regexp libs can't handle stream style, ie to continue in a following chunk if you get a partial match in the first chunk
21:25:20 <dons> dcoutts: hmm. QCing the rules. down/down loop fusion    : Falsifiable after 3 tests:
21:25:24 <dons> <function>
21:25:26 <dons> <function>
21:25:29 <dons> 1
21:25:31 <dons> 0
21:25:34 <dons> dcoutts: yeah. we should just use a pure haskell regex lib
21:25:36 <dons> "ife"
21:25:48 <dcoutts> hmm
21:26:07 <dons> oh, maybe there's no guarantee i'm getting random down loops..
21:26:25 <dcoutts> shouldn't matter
21:26:31 <dcoutts> (I think)
21:26:34 <dons> ah, no. you're right.
21:26:39 <dons> they're random functions of type (Int -> Word8 -> PairS Int (MaybeS Word8))
21:27:06 * dons investigates
21:27:15 * dcoutts should go to bed
21:27:20 <dons> @localtime dcoutts
21:27:22 <lambdabot> Local time for dcoutts is Sun May 28 05:26:11
21:27:26 <dons> bed time!
21:27:33 <dcoutts> :-)
21:28:52 <dcoutts> if down/down is falcifiable then up/up should be too
21:28:59 <dcoutts> they should be symmetric
21:29:12 <dcoutts> anyway, I'm not looking into that now
21:29:24 * dcoutts <- bed
21:29:38 <dons> now. i'll look into it.
21:29:43 <dons> s/w//
22:04:48 <hyrax42> @hoogle (a -> Bool) -> Map a -> Bool
22:04:49 <lambdabot> No matches, try a more general search
22:05:08 <mauke> what's Map a?
22:05:25 <hyrax42> @index Data.Map
22:05:25 <lambdabot> bzzt
22:05:29 <hyrax42> @index Map
22:05:29 <lambdabot> Data.Map
22:05:36 <hyrax42> balanced tree
22:05:47 <mauke> last I looked it was Map k a
22:05:55 <hyrax42> ohhh!
22:06:01 * hyrax42 stupid
22:06:13 <hyrax42> @hoogle (a -> Bool) -> Map k a -> Bool
22:06:13 <lambdabot> No matches, try a more general search
22:06:18 <hyrax42> :/
22:06:26 <mauke> what do you want to do?
22:06:42 <hyrax42> oh just looking for equivalent of List.any
22:07:05 <hyrax42> not doing anything with it now, but I might switch from lists to Maps for this
22:07:58 <mauke> any f (elems m)
22:08:11 <hyrax42> of course
22:08:23 <hyrax42> laziness is hard to get used to
22:08:46 <hyrax42> is it lazy?
22:08:50 <hyrax42> elems, that is
22:09:11 <mauke> fold (\x z -> z || f x) False m
22:10:20 <hyrax42> hm
22:10:44 <hyrax42> thanks
23:07:26 <mcnster> greetings
23:08:35 <mcnster> hs-boot files causing great puzzlement
23:10:26 <mcnster> if i have Module A where 'var' is of instance Foo Int and instance Foo String, what would be the type of 'var' in A.hs-boot?
23:11:45 <mcnster> going once...
23:12:24 <mcnster> argh
23:13:00 <dons> ?karma+ QuickCheck -- spotted another logical error
23:13:00 <lambdabot> QuickCheck's karma raised to 8.
23:59:30 <xerox> @arr
23:59:30 <lambdabot> Aye
