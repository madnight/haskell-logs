00:07:04 <hyrax42> ugh
00:07:10 <hyrax42> circularity is hard
00:12:48 <dons> dcoutts_: there's still a bug in groupBy when chunk size is set to 1 byte :/ i can't see where it is though.
00:14:48 <hyrax42> well that puts a real damper in my first "real" program
00:14:57 <ADEpt> morning
00:14:58 <dons> hyrax42: yeah?
00:15:07 <hyrax42> well
00:15:08 <dons> morning ADEpt 
00:15:30 <hyrax42> I wanted to make a Diplomacy (boardgame) order resolver
00:15:38 <hyrax42> but I can't represent the map
00:15:45 <hyrax42> because circularity makes my head hurt
00:16:08 <dons> ciras in you go off one side and come back on the other?
00:16:24 <dons> circularity. (/me hits tab too often now)
00:16:30 <hyrax42> well basically I need a graph with cycles
00:16:33 <hyrax42> for the map/board
00:16:35 <dons> ah
00:16:42 <hyrax42> which provinces are adjacent to which
00:16:45 <dons> and you're using on of our fine graph libraries?
00:17:03 <hyrax42> that didn't occur to me
00:17:15 * hyrax42 googles
00:17:26 <dons> I use and recommend Data.Graph.Inductive, in package fgl
00:17:33 <dons> it comes with the standard ghc system.
00:17:50 <dons> for some applications, Data.Graph in the base package is also suitable
00:17:57 <dons> ?docs Data.Graph
00:17:57 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Data-Graph.html
00:18:03 <dons> ?docs Data.Graph.Inductive
00:18:03 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/fgl/Data-Graph-Inductive.html
00:23:07 <hyrax42> any intro/tutorials, other than the ~2000 user guide?
00:24:02 <dons> not really, unfortunately. just follow the api.
00:24:14 <dons> Data.Graph might be a bit simpler to get started with
00:24:19 <dons> than *.Inductive
00:25:24 <ADEpt> hyrax42: you could google up code samples. I could provide you some, if needed
00:25:39 <hyrax42> ADEpt: I might take you up on that
00:25:46 <hyrax42> for now I'll just look at the api
00:25:51 <hyrax42> and go to bed
00:27:25 <hyrax42> how do you make the modules names in ghci prompt to not take up the whole line
00:33:09 <ADEpt> hyrax42: you can't imo
00:33:50 <dons> hyrax42: unload some perhaps? :m - Foo ?
00:34:03 <hyrax42> nm
00:34:17 <hyrax42> I wanted to hae Data.Graph, and ~.Inductive at same time
00:34:20 <hyrax42> but better not to anyway
00:42:57 <hyrax42> sweet
00:43:19 <hyrax42> well now I'll go to bed, but this will be nice I think
00:43:41 <hyrax42> thanks dons, ADEpt 
00:45:43 <hyrax42> and good night all
01:10:50 <dcoutts> dons, hmm
01:11:56 <dcoutts> dons, heh, 10x spedup from a well placed INLINE, nice
01:12:26 <shapr> Yow!
01:13:13 <dcoutts> dons, as for groupBy, do the QCs find that? or do you have another failiing case?
01:15:29 <dons> QCs catch it, only when I manually set the chunk size to 1 in ByteString/Lazy.hs
01:15:43 <dcoutts> dons, right
01:15:57 <shapr> Can the QC tests test with different chunk sizes too?
01:16:25 <dons> they test random chunk sizes, but apparently don't quite generate this pattern
01:16:35 <dons> dcoutts: you saw the new graph?
01:16:44 <dcoutts> nope
01:16:48 <dcoutts> where?
01:17:12 <dons> http://www.cse.unsw.edu.au/~dons/tmp/lazystrict.png
01:17:17 <dons> green line is Lazy.hs
01:17:51 <dcoutts> dons, so each point is a test?
01:17:59 <dons> yep, each poin on the x axis
01:18:02 <dons> y is time in seconds
01:18:10 <dcoutts> should be a bar graph :-)
01:18:19 <dons> yeah. but i like the lines.
01:18:24 <dons> sort of easier on the eye
01:18:30 <dcoutts> heh, it's not continuous
01:18:41 <dcoutts> yeah, I guess so
01:18:51 <dons> shoudln't be, Lazy doesn't implement everything normal ByteStrings do.
01:18:57 <dons> so there's gaps at the end
01:19:15 <dons> but for the part that's done Lazy.hs now does very well, often beating the strict form
01:19:49 <dcoutts> :-)
01:19:51 <dcoutts> yay
01:20:32 <dcoutts> what's the huge spike?
01:20:50 <dcoutts> around the 45 mark
01:21:04 <dons> group and groupBy
01:21:12 <dcoutts> ah ok
01:21:17 <dcoutts> heh
01:21:29 * dcoutts wonders why they're so slow
01:21:40 <dons> yeah, probably could be worked on.
01:22:03 <norpan> hi
01:22:04 <dons> since they're just a bit more complex version of split.
01:22:12 <dcoutts> right
01:22:39 <dcoutts> the Lazy group/groupBy is not much slower so speeding up the underlying op is probably the way
01:22:49 <dons> yeah. 
01:23:17 <shapr> Where's ByteStringPrelude?
01:23:36 <dcoutts> heh
01:23:47 <norpan> how would you implement (x:xs) matching?
01:23:51 <shapr> That is, something that replace the Prelude and associated libraries with functions that look the same but use ByteString under the hood.
01:24:01 <dcoutts> norpan, views?
01:24:17 <norpan> is that available?
01:24:24 <dcoutts> no
01:24:26 <dcoutts> ;-)
01:24:35 <norpan> oh
01:24:42 <norpan> then it'll be hard
01:25:03 <dcoutts> someone proposed the idea but it's never been implemented
01:25:51 <norpan> replacing the default String is maybe not a bad idea, but I'm not sure bytestring's the way to go
01:26:25 <dcoutts> what would you use?
01:26:38 <norpan> lazy bytestring is better
01:27:08 <norpan> but of course it would have to handle some kind of unicode
01:27:20 <dcoutts> yeah
01:27:47 <norpan> we talked about having the bytestring chunks of different word size in the same lazy bytestring
01:27:58 <norpan> so that ascii would still be stored effiently
01:28:12 * dcoutts is sceptical of that idea
01:28:59 <norpan> why is that?
01:29:19 <dcoutts> I think it'd be slow
01:29:36 <norpan> how so?
01:30:08 <norpan> if the chunks are big enough, the extra overhead would not be noticable
01:30:10 <dcoutts> the overhead of doing the grouping, I doubt it'd pay off
01:30:50 <norpan> you'd not group differently, you'd just store the groups more efficiently if they are all ascii or all 16-bit unicode
01:31:53 <norpan> which costs almost nothing to check since you need to traverse the input String anyway to find it's length
01:33:10 <dcoutts> why do we need its length? or you mean the length of each packed chunk?
01:33:11 <dcoutts> dons, btw, when we're happy with the api and perf, what should be looking at next? gzip'ing, re-encoding, regex matching...
01:33:42 <dcoutts> dons, there's lots of stream style operations we could do
01:33:51 <norpan> dcoutts: yes because you need to allocate space for it
01:34:09 <dcoutts> norpan, I'll await the benchmarks with interest
01:34:35 <norpan> yeah
01:34:40 <norpan> of course it needs to be benchmarked
01:35:25 <norpan> but for a String replacement we need some way of handling Unicode
01:35:31 <norpan> and that is one way
01:35:47 <dcoutts> dons, and then there's binary serialising, parsing...
01:36:43 <dcoutts> dons, who needs a StreamIO library eh? pure lazy bytestreams for emperor!
01:38:46 <norpan> err, and by ascii i mean latin1 of course
01:38:56 <norpan> unicode 8 bits
01:42:24 <dons> i was thinking regexes
01:42:56 <dons> i agree. who needs stream IO? not me :)
02:01:11 <davidhouse> i think this is the quietest time i've ever seen IRC
02:11:06 <goltrpoat> i'd like to take the opportunity to pledge my first-born to macallan distillers, and, in particular, to whoever came up with their 1987 vintage 18yr single malt.
02:14:10 <wilx> Spirits are no good.
02:18:13 <goltrpoat> them's fightin words.
02:20:38 <goltrpoat> :)
02:47:33 <norpan> goltrpoat: i'm sad to say i haven't tasted that one
02:48:33 <norpan> i've had macallan 18yr, but not that vintage
02:58:58 <goltrpoat> norpan:  i've been working my way up from my usual 10yr oban and 15 and 10 yr aberlour (don't remember what years, fairly recent)..  and i can't really complain about those, but this is really rather amazing in comparison
03:02:18 <goltrpoat> although at some point i should probably venture out of my little speyside bubble.
03:02:30 <norpan> there are plenty of fine spirits
03:04:03 <goltrpoat> i guess oban isn't speyside, come to think of it.
03:04:24 <norpan> no, oban is highlands
03:04:27 <goltrpoat> -nod-
03:05:50 <norpan> err, speyside is technically highlands too :)
03:07:45 <goltrpoat> yah, but a lot of people put it in a separate category
03:08:02 <goltrpoat> or so it seems
03:08:45 <norpan> actually oban seems to be "western highlands"
03:08:48 <norpan> but nm
03:10:33 <xerox> @yow
03:10:34 <lambdabot> These PRESERVES should be FORCE-FED to PENTAGON OFFICIALS!!
03:11:51 <dozer> ping SizUni
03:11:58 <dozer> ping Si\Uni
03:16:24 <goltrpoat> Two with FLUFFO, hold th' BEETS..side of SOYETTES!
03:29:40 <goltrpoat> bedtime.
03:35:56 <dcoutts_> @yarr!
03:35:57 <lambdabot> Shiver me timbers!
03:36:05 * dcoutts_ has had a good supervision
03:39:29 <dcoutts_> JaffaCake, so these various ideas about a new IO system based on a traditional imperitive notion of streams.. dons and I were wondering if we couldn't do that more elegantly (and with nearly the same effeciency) using lazy bytestrings.
03:40:27 <dcoutts_> IO streams give you great explicit buffer management, while lazy bytestrings leave it up to the GC rather more
03:41:32 <dcoutts_> interact ( etc . lines . fromUTF8 . gunzip )
03:42:02 <dcoutts_> so we get nice purely functional composition for "stream transformers"
03:43:37 <swiert> dcoutts_: That sounds really cool. Do you have any pointers?
03:43:50 <dcoutts_> swiert, Data.ByteString.Lazy
03:44:03 <dcoutts_> and ideas comming out of that
03:44:22 <swiert> dcoutts_: More generally about stream based IO?
03:44:55 <dcoutts_> well JaffaCake and people on the libs list have been discussing a new IO streams library for some time
03:45:25 <dcoutts_> I'm wondering if it's necessary, if we couldn't do better with a system based on lazy bytestrings
03:45:59 <dcoutts_> swiert, the streams concept is basically imperitive, much like C++ or Java streams
03:46:37 <dcoutts_> they compose/layer quite well, eg stacking encoders/decoders and transport layers (files, sockets etc)
03:46:50 <xerox> Err?
03:47:11 <xerox> Wasn't stream-based-IO abolished in favor of the Monadic framework we use nowadays?
03:47:46 <dcoutts_> slightly different terminology
03:48:04 <swiert> dcoutts_: I've been thinking about something related, but a bit weird.
03:48:14 <dcoutts_> a bit wierd?
03:48:25 <swiert> dcoutts_: more in the trend of John Hughes's stream based arrow stuff.
03:48:57 <swiert> dcoutts_: but at the moment it's more a bunch of half baked ideas than anything tangible.
03:49:35 <dcoutts_> swiert, so those kind of things can do "real" IO, our lazy bytestrings can only operate on data got lazily from an IO source, eg using hGetContents
03:50:11 <swiert> aha - that makes sense.
03:50:12 <dcoutts_> swiert, ie we can do all the transformation bits appart from doing the actual moving of data to/from an IO data source
03:50:40 <swiert> which transformation bits?
03:50:43 <dcoutts_> so eg we can do encoding/decoding, buffering for free, but not actually moving blocks to a file
03:51:12 <dcoutts_> so for IO we've got hGetContents, readfile, writeFile which work on whole lazy bytestrings at once
03:51:49 <dcoutts_> so they work the same as the traditional String-based versions, but in large packed chunks of bytes, so it's very fast.
03:51:59 <dcoutts_> but still lazy
03:53:18 <dcoutts_> so one way to go is to move the encoding/decoding/buffering into your stream abstraction, another is to keep them in the pure code
03:53:36 <dcoutts_> and by operating in large chunks we can make the pure code almost as fast
03:54:04 <dcoutts_> see dons's benchmarks
03:54:55 <swiert> ok. Thanks for the explanation.
03:56:05 <swiert> summing it up, you're trying to get faster IO by writing combinators for really low-level stuff manipulating the streams of bytes.
03:56:15 <dozer> we had a talk at work a couple of weeks ago by Malcolm Dowse
03:56:17 <dcoutts_> right
03:56:18 <dozer> "Modelling State, Concurrency and I/O in Functional Languages"
03:56:56 <swiert> sounds pretty cool. How are the benchmarks?
03:57:04 <dcoutts_> fast :-)
03:57:35 <dcoutts_> swiert, and we can process multi-gigabyte files with constant heap
03:58:21 <swiert> wow!
03:58:37 <dozer> dcoutts_ using a "can from the beginning to the end, doing something with contiguous blocks of bytes on the way" model?
03:58:45 <dozer> s/can/scan/
03:58:52 <dcoutts_> yes
03:58:57 <dozer> sweet
04:00:03 <dozer> with effort, using java NIO, channels and buffers, I can get java code to be entirely hardware/os IO bound for that kind of app, but you pay for it in code maintainability
04:02:18 <dcoutts_> http://www.haskell.org//pipermail/libraries/2006-May/005366.html
04:02:52 <dcoutts_> here's one of dons's posts about the stuff, we're getting within 6% of C for a filter test on a 10GB file
04:03:29 <dcoutts_> in both cases it's mostly IO bound
04:04:13 <dcoutts_> looking at cpu usage we're at 2x the C version
04:05:02 <swiert> dcoutts: thanks for the info, I'm off to lunch.
04:05:23 <dcoutts_> so both IO bound, but tr is at 26% cpu and our lazy thing is 53% cpu.
04:05:33 <dcoutts_> but our lazy code is a one-liner
04:05:58 <dozer> at what point do you add optimizations to the compiler rather than writing better library code?
04:06:33 <dcoutts_> we probably don't really, not much
04:07:05 <dcoutts_> though JaffaCake has already changed the representation of ForeignPtr in ghc 6.6 to make this stuff faster
04:07:28 <dcoutts_> it gives one fewer indirection
04:08:04 <davidhouse> hi all. when haddocking my modules, i get a load of warnings like "Warning: FooModule: the following names could not be resolved: CharParser String"
04:08:55 <dcoutts_> dozer, dons has also looked at what you might call compiler optimisations, ghc RULES. transformation rules to optimise compositions of bytestring operations
04:09:07 <davidhouse> should i be doing something about that?
04:10:02 <dcoutts_> davidhouse, things from the Prelude shouldn't worry you, you could use --use-package=base --use-package=haskell98
04:10:29 <dcoutts_> davidhouse, not being able to resolve things defined in your own module might be slightly more worrying
04:10:49 <dcoutts_> davidhouse, it means you're not getting cross-links where you might expect them
04:11:07 <davidhouse> hmm.
04:11:12 * dcoutts_ goes out shopping
04:11:21 <davidhouse> well, those two options had little affect, as far as i can tell
04:11:48 <davidhouse> if i want them crosslinked to the hierarchial modules, can haddock link to haskell.org's copy, or do i need to keep one locally?
04:39:04 <tennin> I think it's really disappointing I'm still limited to 24 hours per day even while programming in Haskell
04:39:18 <tennin> I thought modern tools and system software had gotten past such arbitrary limitations
04:40:23 <lisppaste2> Free Ringtones pasted "Free Ringtones" at http://paste.lisp.org/display/20111
04:44:30 <davidhouse> @hoogle print
04:44:31 <lambdabot> Prelude.print :: Show a => a -> IO ()
04:44:31 <lambdabot> Text.Printf.Print :: class Print
04:44:31 <lambdabot> Text.Printf.printf :: PrintfType r => String -> r
05:58:02 <msph> Can anyone tell me how to 1: get the Cabal build system and 2: get the runghc script that Cabal depends on?
05:58:46 <eivuokko> You need to install recent ghc.  It becomes with both.
05:59:05 <msph> Ah.  Darn.
05:59:17 <eivuokko> Cabal should work with hugs and nhc, too.  Not sure if your package does.
06:00:06 <norpan> there are a lot of people here in the channel
06:00:08 <norpan> 202 nicks
06:01:18 <shapr> norpan: We had 225 a few days back.
06:01:19 <msph> It's the HSQL package that I want to install, and it seems to only have Cabal install instructions.
06:01:51 <eivuokko> It's haskell lib, right?
06:01:59 <norpan> someone did Seq ByteString, who was it now
06:02:11 <msph> Yes.
06:02:20 <eivuokko> So, don't you have a compiler already?
06:02:31 <msph> I have GHC 6.2.
06:02:36 <eivuokko> Then you can get cabal from haskell.org/cabal
06:02:42 <dcoutts> cabal works with ghc-6.2
06:02:46 <msph> Oh...
06:03:04 <dcoutts> at least it's supposed to, it doesn't get tested much
06:03:04 <eivuokko> dcoutts, Does it get much testing?
06:03:11 <eivuokko> Ah :)
06:03:31 <dcoutts> I know of some packages that work with 6.2.2 anc cabal-1.1.3
06:03:32 <msph> I can try anyway.  In a low-memory system, installing a new version of GHC is not an attractive idea.
06:03:59 <shapr> msph: Binary packages?
06:04:13 <eivuokko> And you don't need runghc, you can just compile the setup.(l)hs
06:04:31 <msph> shapr: There aren't any for OS X, yet.
06:04:39 <dcoutts> ghc Setup.lhs -o setup; ./setup configure; ...
06:05:03 <norpan> i looked at Data.Sequence and compared it to the paper. does anyone know why the FingerTree is wrapped in a newtype Seq and why it's not exported. Also, why is there a newtype Elem?
06:05:27 <dcoutts> msph, there are ghc binary packages for OSX
06:06:00 <msph> So, I just need to search better?
06:06:10 <dcoutts> it's on the ghc download page
06:12:29 <norpan> nm, i'll mail ross and ask instead
06:37:30 <shapr> Yow! Wazzup?
06:37:44 <shapr> It's so quiet...
06:38:15 <vincenz> > unwords . take 3 . repeat $ "ping"
06:38:17 <lambdabot> "ping ping ping"
06:43:14 <dcoutts> > groupBy (<) [97,104,100]
06:43:15 <lambdabot> [[97,104,100]]
06:44:06 <vincenz> seems wrong
06:44:14 <dcoutts> yeah, I don't understand it
06:44:16 <vincenz> unless it's always compared with the first element
06:44:19 <vincenz> I think that would be it
06:44:23 <vincenz> it assumes an equivalence class
06:44:26 <dcoutts> seems to be
06:44:53 <vincenz> aka it assumes transitive && commutative
06:44:56 * dcoutts changes his algorithm for ByteString.Lazy.groupBy to match List.groupBy
06:46:22 * SamB wonders if there is a groupBy/group RULE
06:46:37 <dcoutts> SamB, what would that look like?
06:47:36 <SamB> well, what does group do again? groupBy (==)?
06:47:46 <dcoutts> yep
06:48:27 <SamB> so, that RULE would be: {-# RULES "groupBy/group" groupBy (==) = group #-}
06:48:54 <vincenz> what is {-# RULES}
06:48:56 <dcoutts> isn't that higher order matching?
06:49:06 <SamB> higher-order matching?
06:49:42 <dcoutts> hmm, I have the feeling that that rule is a bit more tricky to get working than it looks
06:49:52 <SamB> actually, I dunno if there would be any point in it anyway.
06:49:53 <dcoutts> ask dons, I don't fully understand
06:49:54 <vincenz> how are RULEs used?
06:50:30 <SamB> well, I know the one I wrote for not unpacking literals didn't work as well as I had hoped
06:50:54 <SamB> string literals, that is
06:51:07 <vincenz> @hoogle trace
06:51:08 <lambdabot> Debug.Trace.trace :: String -> a -> a
06:51:08 <lambdabot> Debug.Trace :: module
06:51:08 <lambdabot> Debug.Trace.putTraceMsg :: String -> IO ()
06:51:35 <SamB> anyway, RULEs are used for stuff like list fusion...
06:51:45 <vincenz> dcoutts: I traced it
06:51:49 <SamB> also to avoid unneeded conversions to Integer
06:52:04 <Lemmih> Isn't 'group = groupBy (==)'?
06:52:15 <petekaz> vincenz: http://www.haskell.org/ghc/docs/6.4.1/html/users_guide/rewrite-rules.html
06:52:17 <vincenz> dcoutts: http://rafb.net/paste/results/RH7w9999.html
06:52:18 <dcoutts> Lemmih, actually, no
06:52:35 <Lemmih> dcoutts: It's specialized by hand?
06:52:49 <vincenz> SamB: you mean deforestation
06:53:04 <dcoutts> Lemmih, the ByteString.group uses a faster span test than groupBy
06:53:18 <dcoutts> Lemmih, and then the lazy version builds on both underlying versions seperately
06:53:22 <SamB> vincenz: yeah, list fusion is a kind of deforestation
06:53:40 <vincenz> dcoutts: as we suspected
06:54:06 <dcoutts> vincenz, yes, and swithcing my code about makes it match the results for list now
06:54:14 <vincenz> ;0
06:54:15 <vincenz> :)
06:54:42 <vincenz> so we should prolly have some other function that matches our original idea about groupBy
06:54:43 <Lemmih> dcoutts: Ah, OK.
06:54:49 <SamB> I remember someone said something about whether the lazy group should be in terms of groupBy
06:54:52 * vincenz codes one
06:55:05 <sjanssen_> vincenz: original idea?
06:55:26 <vincenz> sjanssen_: groupBy' (<) [97, 104, 100] => [[97, 104], [100]]
06:56:31 <dcoutts> SamB, and we found that it's faster to use the underlying PackedString.group
06:56:31 <sjanssen_> > groupBy (<) [97, 104, 100]
06:56:31 <lambdabot> [[97,104,100]]
06:56:31 <vincenz> sjanssen_: http://rafb.net/paste/results/RH7w9999.html
06:56:31 <sjanssen_> vincenz: it negates the operator?
06:56:31 <vincenz> no
06:56:31 <vincenz> check that post
06:56:31 <vincenz> it shows the tracing
06:56:31 <vincenz> it always refers back to first elem in grouping
06:56:31 <SamB> well, I thought maybe a RULE like that would give the best of both worlds
06:56:35 <dcoutts> sjanssen, first element in the group rather than the adjacent element
06:57:06 <sjanssen_> @fptools groupBy
06:57:06 <lambdabot> groupBy not available
06:57:06 <vincenz> dcoutts: it probably does a takeWhile always using first elem
06:57:10 <sjanssen_> @fptools Data.List
06:57:11 <lambdabot> http://darcs.haskell.org/packages/base/Data/List.hs
06:57:20 <dcoutts> vincenz, yeah, probably
06:57:56 <sjanssen_> vincenz: that's how Data.List.groupBy works if I catch your meaning
06:58:11 <vincenz> it uses span
06:58:55 <sjanssen_> so you're saying adjacent element instead of first element then?
06:59:03 <vincenz> would be more interesting
06:59:11 * vincenz is coding one
06:59:19 <sjanssen_> okay, I was thinking backwards
06:59:25 <sjanssen_> yeah, could be interesting
06:59:41 <sjanssen_> should be easy with foldr
07:03:05 <sjanssen_> > let f eq z (x@(y:_):xs) | z `eq` y = (z:x) : xs; f eq z xs = [z] : xs in foldr (f (<)) [] [97, 104, 100]
07:03:06 <lambdabot> [[97,104],[100]]
07:03:30 <sjanssen_> not sure how strict that is . . .
07:03:47 <sjanssen_> > let f eq z (x@(y:_):xs) | z `eq` y = (z:x) : xs; f eq z xs = [z] : xs in take 10 $ foldr (f (<)) [] [1..]
07:03:48 <lambdabot> Exception: stack overflow
07:04:28 <sjanssen_> > let f eq z (x@(y:_):xs) | z `eq` y = (z:x) : xs; f eq z xs = [z] : xs in take 10 $ foldr (f (>)) [] [1..]
07:04:30 <lambdabot> Exception: stack overflow
07:04:35 <sjanssen_> yep, not so good
07:04:58 <vincenz> here you go
07:04:59 <vincenz> http://rafb.net/paste/results/fC2ZoF92.html
07:05:03 <vincenz> feel free to golf it
07:06:50 <sjanssen_> vincenz: does it work on infinite lists?
07:06:55 <vincenz> dunno
07:06:59 <vincenz> lemme test
07:07:49 <vincenz> yep
07:08:15 <vincenz> http://rafb.net/paste/results/qFaOaB47.html
07:10:42 * vincenz tests on the internal infinte of the third element
07:10:49 <vincenz> > drop 2 [1..3]
07:10:50 <lambdabot> [3]
07:11:17 <vincenz> woo
07:11:29 <vincenz> it's even lazy on the sublists
07:11:42 <vincenz> take 11 $ head $ drop 2
07:11:48 <vincenz> -> [1,2,..,11]
07:12:17 <vincenz> > take 3 $ head $ groupBy (<) [1..]
07:12:17 <lambdabot> [1,2,3]
07:41:31 <ADEpt> @index unsafeAt
07:41:31 <lambdabot> bzzt
07:42:37 <ndm> @hoogle unsafe
07:42:38 <lambdabot> Language.Haskell.TH.unsafe :: Safety
07:42:38 <lambdabot> System.IO.Unsafe :: module
07:42:38 <lambdabot> Language.Haskell.TH.Unsafe :: Safety
07:42:50 <ndm> @hoogle unsafeAt
07:42:50 <lambdabot> No matches found
07:43:17 <Lemmih> @type Data.Array.Base.unsafeAt
07:43:18 <lambdabot> forall e (a :: * -> * -> *) i.
07:43:18 <lambdabot>           (Data.Array.Base.IArray a e, Ix i) =>
07:43:18 <lambdabot>           a i e -> Int -> e
07:52:16 <norpan> re your groupBy discussion, i made the same mistake in the UTF-8 code
07:52:35 <norpan> but QuickCheck found it
07:53:02 <Beelsebob> @where Haskell Report
07:53:02 <lambdabot> http://haskell.org/
07:53:21 <dcoutts> norpan, where is your code?
07:53:29 <norpan> http://norpan.org/~martin/fps-i18n/Data/ByteString/UTF8.hs
07:53:40 <norpan> kzm has it in the big repo too
07:53:50 <dcoutts> right
07:55:32 <dcoutts> norpan, you don't think it's a good idea for the UTF8 version to be a newtype?
07:56:08 <norpan> we discussed both using newtype and using ghost type argument to ByteString
07:57:53 <norpan> but i don't know
07:58:04 <davidhouse> norpan, the type annotation for snoc in the module export disagrees with that in the module body
07:58:30 <norpan> indeed it does
07:58:38 <int-e> hmm, the STRICT6 macro won't work I think (f is used as an argument there)
07:59:11 <norpan> int-e: you don't think?
07:59:20 <norpan> won't the inner f hide the function symbol
07:59:31 <davidhouse> norpan, and also the definition for STRICT1 is off
07:59:48 <davidhouse> should be "f a" not "f a b c" before the guard
07:59:49 <norpan> hey, i didn't write those
07:59:55 <norpan> kzm is to blame :)
08:00:02 <int-e> hm. I guess it will. It's still a problem for STRICT6(a) .. STRICT6(e).
08:00:16 <norpan> fortunately those are not used
08:00:35 <norpan> they are wrong just to confuse the casual reader
08:00:50 <norpan> int-e: yeah, i suppose STRICT6 will be wrong
08:01:06 <int-e> but it's not as bad as I thought, that's right
08:01:40 <norpan> int-e: exactly :)
08:01:41 <int-e> and STRICT1 is just weird.
08:01:57 <norpan> i'll have to change those then
08:02:27 <norpan> actually http://norpan.org/~martin/fps/Data/ByteString/UTF8.hs is the one you should see
08:03:27 <int-e> yes, that's the one I'm looking at.
08:03:47 <norpan> ok, fixed :)
08:04:23 <norpan> and the snoc thing is just copied from ByteString.hs
08:05:25 <kolmodin> @where paste
08:05:25 <lambdabot> http://paste.lisp.org/new/haskell
08:11:53 <dcoutts> dons, elemIndexLast could use memrchr
08:12:26 <dcoutts> dons, oh, only if it's available (as it's a glibc extension)
08:41:37 <hyrax42> @pl \(a,b) -> (b,a)
08:41:38 <lambdabot> uncurry (flip (,))
08:43:02 <davidhouse> that should be a standard combinator too.
08:43:09 <davidhouse> i think i might write a combinator wishlist
08:43:38 <hyrax42> isn't there a movement to reduce the size of the prelude?
08:44:06 <hyrax42> I think I read something like that maybe in a weekly haskell news posting thigny
08:44:29 <eivuokko> Yeah, I thin kthere is a proposal for haskell-prime to split Prelude
08:44:35 <xerox> ?type (snd &&& fst)
08:44:35 <hyrax42> @index rev
08:44:36 <lambdabot> forall a b. (a, b) -> (b, a)
08:44:36 <lambdabot> Text.Html
08:44:54 <hyrax42> not all of us understand arrows
08:44:55 <hyrax42> :(
08:45:05 <davidhouse> xerox, ooh :)
08:45:15 <hyrax42> @type &&&
08:45:15 <davidhouse> @type rev
08:45:16 <lambdabot> Not in scope: `rev'
08:45:17 <lambdabot> parse error on input `&&&'
08:45:23 <hyrax42> @type (&&&)
08:45:23 <davidhouse> @type (&&&)
08:45:24 <lambdabot> forall (a :: * -> * -> *) c' c b.
08:45:24 <lambdabot>    (Arrow a) =>
08:45:24 <lambdabot>    a b c -> a b c' -> a b (c, c')
08:45:25 <lambdabot> forall (a :: * -> * -> *) c' c b.
08:45:25 <lambdabot>    (Arrow a) =>
08:45:26 <lambdabot>    a b c -> a b c' -> a b (c, c')
08:45:40 <hyrax42> well anyway, I wanted this:
08:45:43 <davidhouse> we're working in the (->) monad.
08:45:50 <int-e> arrow :)
08:45:55 <davidhouse> err, yeah
08:45:59 <xerox> hyrax42 - instance Arrow (->) where
08:45:59 <xerox>  (f *** g) (x,y) = (f x,g y)
08:45:59 <xerox>  (f &&& g) x     = (f x,g x)
08:46:00 <xerox>  first f (x,y)   = (f x,y)
08:46:00 <xerox>  second ...
08:46:00 <xerox>  (>>>) = flip (.)
08:46:05 <hyrax42> let rev = (snd &&& fst) in [id, rev] `ap` [(1,2),(2,3)]
08:46:14 <hyrax42> >let rev = (snd &&& fst) in [id, rev] `ap` [(1,2),(2,3)]
08:46:18 <hyrax42> > let rev = (snd &&& fst) in [id, rev] `ap` [(1,2),(2,3)]
08:46:19 <lambdabot> [(1,2),(2,3),(2,1),(3,2)]
08:47:11 <davidhouse> anyone come up with a good name for my \f g x y -> g x `f` g y combinator?
08:47:58 <vincenz> @pl \f g x y -> g x `f` g y
08:47:58 <lambdabot> join . ((flip . ((.) .)) .) . (.)
08:48:05 <xerox> "mess"
08:48:05 <hyrax42> oww
08:48:18 <vincenz> davidhouse: :
08:48:21 <vincenz> f `over` g
08:48:22 <int-e> hmm. it's a generalization of comparing f a b = compare (f a) (f b) ...
08:48:24 <davidhouse> xerox, i'm compiling a combinator wishlist
08:48:32 <xerox> davidhouse - good idea.
08:48:38 <vincenz> f `over` g?
08:48:50 <davidhouse> sure.
08:49:05 <davidhouse> i was thinking "attach".
08:49:18 <vincenz> combineWith
08:49:27 <davidhouse> too long.
08:49:47 <vincenz> should prolly typeclass it
08:49:51 <vincenz> for f : a->a-.b
08:49:57 <vincenz> f a -> a -> a- >b
08:49:58 <hyrax42> what makes a function worthy of being referred to as a combinator
08:49:58 <vincenz> ..
08:50:08 <vincenz> hyrax42: personal preference
08:50:15 <davidhouse> hyrax42: generically useful
08:50:22 <hyrax42> ok
08:50:23 <davidhouse> most combinators are also HOFs
08:50:28 <vincenz> davidhouse: that's isomorphic to what I said
08:50:47 <hyrax42> I though more to do with HOFness
08:50:59 <hyrax42> e.g. the (snd &&& fst) guy up there (or however you want to spell it)
08:51:04 <hyrax42> I wouldn't have called a combinator
08:52:27 <hyrax42> gah
08:52:39 <hyrax42> I hate sitting waiting for parcels
08:52:44 <shapr> @foldoc combinator
08:52:46 <lambdabot> *** "combinator" foldoc "The Free On-line Dictionary of Computing (27 SEP 03)"
08:52:46 <lambdabot> combinator
08:52:46 <lambdabot>  
08:52:46 <lambdabot>    <theory> A function with no {free variables}.  A term is
08:52:46 <lambdabot>    either a constant, a variable or of the form A B denoting the
08:52:48 <lambdabot> [28 @more lines]
08:52:53 <xerox> swap = (snd &&& fst)
08:52:59 <xerox> dup = (id &&& id)
08:53:07 <vincenz> xerox: or just id?
08:53:16 <xerox> Sorry?
08:53:21 <vincenz> > id (1,2)
08:53:22 <lambdabot> (1,2)
08:53:28 <vincenz> > (id &&& id) (1,2)
08:53:29 <lambdabot> ((1,2),(1,2))
08:53:33 <vincenz> whoops
08:53:34 <vincenz> nm
08:53:39 <hyrax42> hm
08:53:43 <davidhouse> > let dup a = (a, a) in dup "hello"
08:53:44 <lambdabot> ("hello","hello")
08:53:50 <vincenz> > let dup = join (,) in dup "hello"
08:53:51 <lambdabot> ("hello","hello")
08:54:09 <vincenz> @type join (join (,))
08:54:10 <lambdabot>   Couldn't match `(a, a)' against `t -> t1'
08:54:10 <lambdabot>   Expected type: (a, a)
08:54:17 <davidhouse> > let dup a = (a, a) in dup "hello" >>> (toLower *** toUpper) -- /me heart arrowic combinators
08:54:18 <xerox> (.)
08:54:18 <lambdabot> Couldn't match `(,)' against `(->)'
08:54:33 <davidhouse> > let dup a = (a, a) in dup "hello" >>> (map toLower *** map toUpper) -- /me heart arrowic combinators
08:54:34 <lambdabot> Couldn't match `(,)' against `(->)'
08:54:35 <int-e> it's also a generalization of function composition ... compose f g x = f (g x); compose2 f g x y = f (g x) (g y); compose3 f g x y z = f (g x) (g y) (g z) etc.?
08:54:42 <xerox> > join (,) . join (,) $ "hello"
08:54:43 <lambdabot> (("hello","hello"),("hello","hello"))
08:54:45 <davidhouse> huh.
08:55:07 <davidhouse> @type (***)
08:55:08 <lambdabot> forall (a :: * -> * -> *) c' c b' b.
08:55:08 <lambdabot>    (Arrow a) =>
08:55:08 <lambdabot>    a b c -> a b' c' -> a (b, b') (c, c')
08:55:15 <davidhouse> @type (>>>)
08:55:16 <lambdabot> forall (a :: * -> * -> *) d b c.
08:55:17 <lambdabot>    (Arrow a) =>
08:55:17 <lambdabot>    a b c -> a c d -> a b d
08:55:43 <xerox> davidhouse, since (>.>) = flip (.), maybe something using '>', '<', and '.' ?
08:56:10 <davidhouse> xerox, for what?
08:56:20 <davidhouse> @type let dup a = (a, a) in (dup "hello" >>>)
08:56:21 <lambdabot>   No instance for (Arrow (,))
08:56:21 <lambdabot>   arising from use of `>>>' at <interactive>:1:35-37
08:56:32 <xerox> davidhouse - composition
08:56:54 <davidhouse> > let dup a = (a, a) in arr (dup "hello") >>> (map toLower *** map toUpper) -- /me heart arrowic combinators
08:56:54 <lambdabot> Couldn't match `(a, a)' against `t -> t1'
08:57:06 <davidhouse> i can't remember how this works.
08:57:15 <davidhouse> oh, wait.
08:57:33 <davidhouse> > let dup a = (a, a) in (map toLower *** map toUpper) $ dup "hello"
08:57:34 <lambdabot> ("hello","HELLO")
08:57:38 <davidhouse> heh.
08:58:20 <vincenz> erm
08:58:30 <vincenz> > join (map toLower *** map toUpper) $ "hello"
08:58:30 <lambdabot> Couldn't match `(->) ([Char], [Char])' against `(,) [Char]'
08:58:35 <davidhouse> oops, gotta go.
08:58:51 <vincenz> > join ((,) . map toLower *** map toUpper) $ "hello"
08:58:52 <lambdabot> Couldn't match `(->) ([Char], [Char])' against `(,) (b -> ([Char], b))'
08:58:58 * vincenz gives up
08:59:00 <int-e> > (map toLower &&& map toUpper) "hello"
08:59:01 <lambdabot> ("hello","HELLO")
09:00:08 <xerox> > (dup >>> first (+1) >>> second (*2) >>> swap) 1
09:00:09 <lambdabot>  Not in scope: `swap'
09:00:24 <xerox> > let dup x = (x,x); swap (x,y) = (y,x) in (dup >>> first (+1) >>> second (*2) >>> swap) 1
09:00:25 <lambdabot> (2,2)
09:06:38 <vincenz> wtf
09:06:45 <vincenz> this is such bs
09:07:12 <vincenz> there is this app on sourceforge... if you go to download files, it only provides an html, so you take thhat, it redirectos you to the homepage, where only binaries can be ound "If you want the source, go to sourceforge"
09:07:29 * vincenz draws a little circle
09:07:36 <dcoutts> perhaps in cvs?
09:08:48 <vincenz> nope
09:08:51 <vincenz> I tried, no access
09:09:36 <shapr> Sourceforge is pretty painful to use lately.
09:10:01 <shapr> anon cvs is dead, bandwidth is overloaded, mailing lists are flaking out
09:10:12 <vincenz> not to mention how much you have to click to download a file
09:10:16 <shapr> Yeah, that really bites.
09:10:40 <shapr> On the good side, Sun/IBM/etc should donate their hardware on the condition their load and uptime stats are recorded.
09:10:52 <int-e> are there ternary variants of curry and uncurry anywhere?
09:11:07 <shapr> I bet 100% load and 99.9% uptimes would persuade many a business.
09:11:24 <vincenz> @type curry3
09:11:26 <lambdabot> Not in scope: `curry3'
09:11:46 <dcoutts> @hoogle curry3
09:11:47 <lambdabot> No matches found
09:11:50 <dcoutts> @hoogle curry
09:11:51 <lambdabot> Prelude.curry :: ((a, b) -> c) -> a -> b -> c
09:11:51 <lambdabot> Prelude.uncurry :: (a -> b -> c) -> (a, b) -> c
09:11:51 <vincenz> int-e: sounds like something good for th
09:14:50 <vincenz> shapr: wanna see something even MORE shocking?
09:15:01 <vincenz> you haven't used your Skype Credit for a long time now. Unless you take some action, your Skype Credit balance will expire in 30 days and you cannot use it any longer.
09:15:23 <dcoutts> how rude!
09:15:25 <vincenz> pure theft!
09:15:41 <vincenz> skype credit is whta you pay for, I use skype daily, just haven't caled a phone in a long time
09:15:56 <vincenz> so I just called my friend for a second
09:16:09 <shapr> That's a ripoff
09:16:10 * vincenz mutters
09:16:22 <tennin> just asked this on #scheme but
09:16:36 <tennin> is there a usable Scheme analog of Haskell's QuickCheck?
09:16:48 <tennin> I saw references to something called Scheme-Check but no working links
09:16:53 <vincenz> "Skype Credit expires 180 days after your last purchase or SkypeOut call. If you're not using your balance we need to expire the credit sooner or later to comply with normal business accounting rules. Not very exciting, but true."
09:17:29 <dcoutts> vincenz, sounds like BS to me. Note how most other vouchers don't expire.
09:18:10 <vincenz> "Just make another Skype Credit purchase to add to your credit, or make a SkypeOut call to anywhere you want (we suggest you call your Mum). Alternatively, you could Personalise Skype, by purchasing a new image or ringtone. It's up to you how you spend your Skype Credit, you just need to keep your account active. After you do any one of these, all of your Skype Credit is again available for the next 180 days."
09:18:32 <vincenz> . o O (spend money, or we'll steal yours)
09:19:01 <vincenz> dcoutts: I find it very shocking
09:19:05 <vincenz> and a slap in the face
09:19:12 <xerox> What does `BS' mean?
09:19:33 <vincenz> merda
09:19:35 <dcoutts> xerox, it's what comes out the back end of a male bovine
09:19:45 <xerox> Woops.
09:20:24 <vincenz> Lemmih: ping
09:21:04 <vincenz> it's funny, cause I made a 1 sec call to someone in spain, and apparently it was so short that it was 0 euro, yet sitll it says "expiry in 30 days" in my skype page, it didn't refresh
09:21:10 <vincenz> so it's not administration but money leaching
09:23:23 <dozer> I'm having trouble writing a cabal file
09:23:45 <dozer> it seems to be OK when building libraries
09:23:57 <hyrax42> I wish I could just do
09:24:02 <dozer> but when building an executable, I can't see how to attach libraries the executable uses to it
09:24:19 <RyanT5000> ld-options?
09:24:52 * alar found strange thing
09:25:00 <hyrax42> map order $ take 10 $ sortBy preference amazonbooklist
09:25:00 <dozer> that is for os-specific .so isn/t it?
09:25:04 <alar> ghc-6.4 does not exist for BSD 4
09:25:28 <alar> although 6.2.2 is there
09:25:51 <alar> is there so big difference?
09:25:55 <dozer> I just want to get the app to bind to other haskell packages that have already been built - like build-depends in package building
09:25:58 <int-e> @pl (\f g x h y -> f (g x) (h y))
09:25:59 <lambdabot> (((.) .) .) . (.)
09:26:03 <alar> that one builds and the other does not
09:29:04 <dozer> ah - it was user error .... again
09:29:26 <dozer> ls
09:32:46 <resiak> int-e: Eew!
09:33:41 <xerox> ?. djinn type ((((.) .) .) .)
09:33:42 <lambdabot> -- f cannot be realized.
09:33:42 <lambdabot> Cannot parse command
09:34:03 <vincenz> xerox: djinn takes types
09:34:16 <vincenz> @type  ((((.) .) .) .)
09:34:16 <lambdabot> forall b c a a1 a2 a3.
09:34:17 <lambdabot>        (a3 -> a2 -> a1 -> b -> c) -> a3 -> a2 -> a1 -> (a -> b) -> a -> c
09:34:19 <vincenz> ah forall
09:34:38 <vincenz> @djinn (a3 -> a2 -> a1 -> b -> c) -> a3 -> a2 -> a1 -> ( a -> b) -> a -> c
09:34:38 <lambdabot> f a b c d e f = a b c d (e f)
09:34:44 <int-e> @djinn (b -> b -> b2) -> (b1 -> b) -> b1 -> b1 -> b2
09:34:45 <lambdabot> f a b c _ = a (b c) (b c)
09:34:46 <vincenz> funky
09:34:50 <vincenz> djinn reuses the name 'f'
09:34:52 <vincenz> which is incorrect
09:35:00 <xerox> Is it?
09:35:12 <xerox> @type let f a b c d e f = a b c d (e f) in f
09:35:13 <lambdabot> forall t t1 t2 t3 t4 t5.
09:35:13 <lambdabot>               (t -> t1 -> t2 -> t3 -> t4)
09:35:13 <lambdabot>               -> t
09:35:13 <lambdabot>               -> t1
09:35:13 <vincenz> > let f f = 1 - f in f 3
09:35:14 <lambdabot>               -> t2
09:35:16 <lambdabot> [3 @more lines]
09:35:18 <lambdabot> -2
09:35:22 <vincenz> hmm
09:35:22 <xerox> Err, that's the type anyway.
09:35:49 <int-e> let f f f = undefined in f
09:35:52 <int-e> > let f f f = undefined in f
09:35:53 <lambdabot>   Conflicting definitions for `f'
09:35:55 <lambdabot>   In the definition of `f'
09:36:25 <vincenz> > let f f = f undefined in f
09:36:25 <lambdabot> Add a type signature
09:36:26 <araujo> Hi!
09:36:30 <vincenz> hello
09:36:50 <int-e> > let f f = f where f = 42 in f 23
09:36:52 <lambdabot> 42
09:37:13 <xerox> hah.
09:38:09 <vincenz> that's three f's
09:38:36 <vincenz> > let f f = f f where f f = 42 in f 23
09:38:36 <lambdabot> 42
09:39:03 <vincenz> nasty
09:40:13 <vincenz> http://developers.slashdot.org/article.pl?sid=06/05/17/127214&from=rss
09:51:06 <lscd> I found the following code in a tutorial - http://pastebin.com/722888 -- but it fails to load, saying "parse error on input `;" -- why?  I don't see what's syntactically incorrect about it, and attempts to get rid of the ;'s and use layout rules haven't helped
09:51:35 <vincenz> Lemmih: ; not ,
09:51:37 <vincenz> err
09:51:40 <vincenz> lscd: ; not n
09:51:47 * vincenz mutters you need to use , 
09:52:00 <lscd> vincenz: not my code; ah... ok, thanks.. that makes a lot more sense
09:54:08 <lscd> hm. i probably shouldn't rely on this tutorial - the 4th line is also pretty messed up
09:54:49 <Cale> and the 3rd, where not is being applied to 3 args.
09:54:54 <Cale> 4
09:55:23 <lscd> yeah; i've parenthesized that, and i'm trying to get the 4th working
09:55:51 <lscd> ah well, this is good practice for when i start really writing haskell and have to find braindead errors i'll make :p
09:56:11 <vincenz> http://pastebin.com/722908
09:56:14 <vincenz> lscd: that's fixed
09:58:03 <lscd> thank you
10:04:57 <lscd> heh. that's by far the best solution to n-queens i've ever seen
10:05:10 <vincenz> don't think it's very efficient
10:05:12 <vincenz> using !! is bad
10:05:22 <lscd> sure; it's probably not optimal
10:05:27 <lscd> but in terms of readability and lines of code
10:05:35 <lscd> that beats the hell out of every scheme implementation of n-queens i've seen
10:05:38 <lscd> much less the java ones
10:05:51 <mwc> link for the latecomers?
10:06:00 <lscd> http://pastebin.com/72290
10:06:24 <lscd> and !! probably isn't that bad when the lists have <= 8 elements, i'd guess
10:06:47 <mwc> lscd, bad link?
10:06:51 <mwc> Empty pastebin
10:06:55 <lscd> http://pastebin.com/722908
10:06:59 <lscd> oops... sorry about that
10:07:05 <vincenz> http://oasis.yi.org:8080/repos/haskell/Queens.hs
10:07:05 <lscd> somehow managed to avoid getting the last character
10:09:23 <mwc> beauty that
10:10:11 <lscd> seriously
10:10:27 <lscd> the next question is why schemers usually try to bring backtracking and search into it
10:11:11 <mwc> without a good type system, they probably feel like they have do so something "spectacular."
10:12:43 <lscd> hm... it's just become the classic example to illustrate backtracking
10:13:06 <lscd> which is.. stupid, since it can be solved better without search, and there are other problems you can illustrate backtracking with
10:14:35 <vincenz> ah the beauty of lazy functional programming
10:14:57 <vincenz> bfs tree = traverse (++) tree
10:14:57 <vincenz> dfs tree = traverse (flip (++)) tree
10:15:13 <lscd> gaaaah. that's just painful, vincenz 
10:15:28 <lscd> i had to sit through more than an hour of stepping through bfs and dfs last friday
10:15:52 <vincenz> http://oasis.yi.org:8080/repos/haskell/Tree.hs
10:16:27 <vincenz> bfs will prolly work for infinite trees too
10:16:38 * vincenz generalizes a bit
10:17:59 <vincenz> ghc-6.4: panic! (the `impossible' happened, GHC version 6.4): ds_app_type Tree.Tree{tc r151} [a{tv a16Z}]
10:19:56 <xerox> Eek!
10:21:38 <dozer> I'm behind a web-proxy at work. how can I convince Network.HTTP to use it?
10:22:26 <vincenz> refresh your browser
10:22:32 * vincenz updated Tree
10:22:53 * dozer is |..| this close to getting stuff working
10:23:15 <lscd> same md5sum here
10:25:19 * davidhouse returns
10:25:21 <vincenz> lscd: huh?
10:25:38 <lscd> i grabbed http://oasis.yi.org:8080/repos/haskell/Tree.hs a second time
10:25:50 <vincenz> odd
10:25:55 <lscd> ah, hm
10:25:58 <lscd> now it's different
10:26:11 <lscd> i grabbed it through wget this time
10:26:17 <vincenz> it's serving old content
10:26:27 <davidhouse> okay, what would be a good symbol for the combinator \f g (x, y) -> (f x, g y)?
10:26:46 <vincenz> how do I turn off caching?
10:26:46 <davidhouse> it's called <multiplication sign> in academia but that's obviously not an option here.
10:26:48 <vincenz> of apache
10:27:27 <vincenz> n, was firefox
10:27:44 <vincenz> davidhouse: that exists
10:28:07 <vincenz> > ((*3) *** (+2)) (2,3)
10:28:08 <lambdabot> (6,5)
10:28:18 <lscd> i'm getting the correct version through firefox now
10:28:29 <davidhouse> oh yeah, the arrowic one.
10:28:34 * davidhouse forgot about that.
10:28:36 <davidhouse> never mind then.
10:28:52 <davidhouse> what other combinators should i include in my wishlist then?
10:29:30 <xerox> What do you think about ACM?
10:29:53 <davidhouse> so far, i've got dup :: a -> (a, a), swap :: (a, b) -> (b, a), splitEithers :: [Either a b] -> ([a], [b])
10:30:05 <lscd> are you a forth programmer, by any chance?
10:30:14 <davidhouse> and f `over` g = \x y -> g x `f` g y
10:30:39 <xerox> `over' ?
10:30:53 <davidhouse> vincenz named it. i quite like "attach". name's aren't fixed
10:31:19 <vincenz> xerox: g `under` f?
10:31:41 <vincenz> davidhouse: TBH....dup and swap are hardly combinators
10:31:50 <davidhouse> vincenz: i'd call them so.
10:31:55 <vincenz> they're just functions
10:31:59 <xerox> I like int-e's `compose' idea.
10:32:04 <vincenz> combinators combine fucntions
10:32:15 <davidhouse> xerox, [a -> b] -> [a] -> [b]?
10:32:26 <davidhouse> i.e. (+) is to sum as (.) is to compose
10:32:41 <vincenz> > zipWith ($) [+1, +2] [1,2]
10:32:42 <lambdabot>  parse error on input `+'
10:32:48 <vincenz> > zipWith ($) [(+1), (+2)] [1,2]
10:32:49 <lambdabot> [2,4]
10:33:04 <davidhouse> err, [a -> b] -> a -> b, i meant.
10:33:10 <xerox> davidhouse - didn't that combinator come up in sortBy/groupBy/etc functions?
10:33:15 <vincenz> davidhouse: that's not feasible
10:33:16 <davidhouse> put a value in the top and get it out at the bottom.
10:33:24 <davidhouse> vincenz: sure it is
10:33:24 <vincenz> unless it's a->a
10:33:26 <vincenz> no it's not
10:33:38 <davidhouse> oh, wait, yeah, a -> a.
10:33:56 <davidhouse> @type let compose = foldl (flip (.)) id in compose
10:33:57 <lambdabot> forall a.
10:33:57 <lambdabot>                 [a -> a] -> a -> a
10:34:00 <vincenz> > foldr1 (.) [(*3), (+2)] 1
10:34:01 <lambdabot> 9
10:34:21 <xerox> ?type foldr (.) id
10:34:22 <lambdabot> forall a. [a -> a] -> a -> a
10:34:35 <davidhouse> don't use the fold*1 functions generically, they break on empty lists
10:34:40 <vincenz> davidhouse: you're making special cases of things that can be done with HOF combinators
10:34:45 <davidhouse> especially as we have an easy identity here
10:34:51 <davidhouse> vincenz: this is a HOF combinator.
10:35:01 <vincenz> [a->a] -> a -> a??
10:35:04 <xerox> Yep.
10:35:06 <vincenz> hardly
10:35:08 <davidhouse> ?
10:35:11 <vincenz> as it can be done with foldr1 and id
10:35:12 <xerox> It takes functions as argument.
10:35:14 <vincenz> and (.)
10:35:23 <davidhouse> HOF = function that takes functions as its arguments
10:35:31 <xerox> (And returns functions.)
10:35:41 <xerox> (But that's how Haskell work generally, heh.)
10:35:45 <vincenz> not every HOF is really a valid combinator if it's a specialization of a more generic thing
10:35:55 <davidhouse> what is this a specialisation of?
10:36:13 <vincenz> davidhouse: the fact that you can deconstruct your function into foldr (.) and id
10:36:14 <davidhouse> i'd call map a combinator even though it's a special case of fmap
10:36:20 <vincenz> no it's not
10:36:22 <vincenz> fmap is based on map
10:36:25 <vincenz> not viceversa
10:36:28 <davidhouse> err...
10:36:29 <xerox> vincenz - you can deconstruct all of Haskell to lambda calculus.
10:36:32 <davidhouse> fmap is more general.
10:36:40 <vincenz> davidhouse: fmap is not implementable without map
10:36:44 <xerox> Sure it is.
10:36:52 <vincenz> well ok.. if you paste the code of map in
10:37:08 * vincenz shrugs
10:37:08 <davidhouse> vincenz: give an example of a real combinator then
10:37:12 <vincenz> foldr
10:37:36 <davidhouse> but foldr can be defined in terms of function application
10:37:43 <xerox> I like davidhouse's idea of listing commodity functions for future applications.
10:37:52 <vincenz> xerox: yeah but I wouldn't put em in the prelude
10:37:52 <davidhouse> (or lambda calculus, for that matter. as can anything)
10:38:00 <davidhouse> (or indeed, the K and S combinators)
10:38:08 <xerox> vincenz - no one want to put anything in the Prelude at this stage.
10:38:17 <davidhouse> vincenz: sure. let's have a cabalised package Combinators which people can cabal-get
10:38:34 <davidhouse> vincenz: but i still argue that your definition of combinator is not useful enough
10:39:12 <vincenz> to me a combinator is something generic that does one thing
10:39:23 <vincenz> and you combine it with other combinatros to make functions that do plural things
10:39:27 <davidhouse> like, duplicate a value into a pair?
10:39:28 <vincenz> foldr: apply something to a list
10:39:33 <vincenz> (.) : compose functions
10:39:40 <vincenz> -> foldr (.) id
10:40:01 <xerox> foldr folds.
10:41:21 <davidhouse> any more recommendations then?
10:41:50 <xerox> davidhouse - Found anything interesting in the PreludeExts on the wiki?
10:42:23 <davidhouse> i think i did
10:43:04 <shapr> There are other collections of source code on the old wiki too.
10:43:50 <davidhouse> Cale's swing looks quite useful
10:43:55 <xerox> Yes!
10:44:02 <davidhouse> i don't understand it, but it looks nice :)
10:44:07 <xerox> I couldn't came up with its name, but I wanted to suggest it.
10:47:40 <vincenz> is there anything to halve a list?
10:48:08 <shapr> davidhouse: swing swaps function and data
10:48:17 <ibid> vincenz: there are a lot of ways that you could do that. which one do you want?
10:48:55 <int-e> map (/2) ?
10:49:09 <davidhouse> take (length l / 2)?
10:49:12 <davidhouse> depends on what you mean
10:49:22 <ibid> i think there is a partition somewhere
10:49:25 <ibid> too
10:49:34 <davidhouse> nah, i don't think so
10:49:44 <ibid> @index partition
10:49:45 <lambdabot> Data.IntMap, Data.IntSet, Data.List, Data.Map, Data.Set
10:49:56 <ibid> @type Data.List.partition
10:49:57 <lambdabot> forall a. (a -> Bool) -> [a] -> ([a], [a])
10:50:00 <davidhouse> the predicate for partition needs to be based on the elements in the list, i.e. not how far along the list you are
10:50:01 <ibid> yeah
10:50:02 <xerox> splitAt =<< (`div` 2) . length
10:50:09 <davidhouse> pfft.
10:50:13 <xerox> (-:
10:50:21 <ibid> davidhouse: vincenz didn't specify that it has to be based on how far along you are
10:50:26 <davidhouse> why =<<?
10:50:32 <ibid> davidhouse: just that it should be halved
10:50:35 <xerox> davidhouse - ((->) e)
10:50:36 <int-e> reader monad
10:50:40 <ibid> davidhouse: ... which could mean a lot of things
10:50:45 * xerox blinks
10:50:51 <davidhouse> xerox, don't tell me that was off the top of your head
10:50:57 * xerox giggles....
10:51:31 <davidhouse> besides which, (>>=) is (.) for (a->)
10:52:04 <int-e> hmm. ap (flip splitAt) (flip div 2 . length)
10:52:21 <davidhouse> ooh, yeah, that was on the tip of my tongue, :|
10:52:22 <xerox> int-e - initially I tought the same.
10:52:24 <int-e> davidhouse: wrong
10:52:31 <xerox> But...
10:52:37 <davidhouse> @fptools Control.Monad.Reader
10:52:37 <lambdabot> http://darcs.haskell.org/packages/mtl/Control/Monad/Reader.hs
10:52:45 <int-e> davidhouse: >>= duplicates an argument, . doesn't.
10:53:29 <vincenz> ibid: got it
10:54:00 <vincenz> http://oasis.yi.org:8080/repos/haskell/Tree.hs
10:55:09 <davidhouse> @type splitAt
10:55:10 <lambdabot> forall a. Int -> [a] -> ([a], [a])
10:55:21 <davidhouse> @type (splitAt =<<)
10:55:22 <lambdabot> forall a. ([a] -> Int) -> [a] -> ([a], [a])
10:55:36 <davidhouse> @type (splitAt .)
10:55:37 <lambdabot> forall a a1. (a1 -> Int) -> a1 -> [a] -> ([a], [a])
10:55:55 <vincenz> > splitAt =<< (\l -> length div 2) [1..10]
10:55:55 <lambdabot> Couldn't match `Int' against `t -> t1'
10:56:01 <vincenz> > splitAt =<< (\l -> length l `div` 2) [1..10]
10:56:02 <lambdabot> Couldn't match `[a] -> Int' against `Int'
10:56:18 <davidhouse> > splitAt =<< (\l -> length l `div` 2) $ [1..10]
10:56:19 <lambdabot> ([1,2,3,4,5],[6,7,8,9,10])
10:57:48 <alar> vincenz: why Leaf and not Leaf a ?
10:58:40 <alar> Data.Tree seems better IMHO :)
10:58:59 <davidhouse> @hoogle Tree
10:58:59 <lambdabot> Data.Graph.Inductive.Tree :: module
10:58:59 <lambdabot> Data.Tree :: module
10:58:59 <lambdabot> Data.Tree.Tree :: data Tree a
10:59:11 <davidhouse> wow. and i always include my own definitions of Tree.
10:59:37 <davidhouse> oh, it's not a binary tree.
10:59:40 <davidhouse> anyway, gotta dash.
11:00:08 <vincenz> alar: lookk how therei's a instance Tree T.Tree
11:00:48 <vincenz> the actual immplementation is less of interest than the generic travesal
11:01:02 <vincenz> > uncurry (:0
11:01:02 <lambdabot>  parse error on input `}'
11:01:03 <vincenz> > uncurry (:0
11:01:03 <lambdabot>  parse error on input `}'
11:01:05 <vincenz> gr
11:04:18 <vincenz> @type (=<<)
11:04:19 <lambdabot> forall b (m :: * -> *) a.
11:04:19 <lambdabot>    (Monad m) =>
11:04:19 <lambdabot>    (a -> m b) -> m a -> m b
11:05:57 <vincenz> No instance for (Monad ((->) [Int]))
11:06:29 * vincenz import's Control.Monad.Reader
11:09:00 <vincenz> alar: Leaf a disallows empty trees
11:10:32 <alar> I thought leafs contain elements
11:10:48 <vincenz> depends whom you talk to
11:10:57 <vincenz> RedBlack Trees for instance assume valueless leafs
11:11:03 <alar> ah
11:11:13 <alar> ok
11:11:29 <alar> maybe valueless leafs are better in some areas
11:14:48 <vincenz> any easy way of doing
11:14:55 <vincenz> splitN :: Int -> [a] -> [[a]]
11:15:07 <vincenz> where it splits them into n segments of about equal size?
11:23:23 <vincenz> done
11:25:40 <hyrax42> what do dyou do if there's remainder
11:26:08 <vincenz> hyrax42: well there isn't
11:26:11 <hyrax42> e.g. splitN 4 [1..10]
11:26:38 <vincenz> [1..3] [4..6] [7..9] [10] 
11:26:44 <vincenz> I round up
11:26:50 <hyrax42> ok
11:27:16 <hyrax42> a splitting say [1..3] [4..6] [7,8] [9.10] would get them more "roughly same"
11:27:29 <hyrax42> obvioulsy worse say in splitN 11 [1..101]
11:27:58 <vincenz> http://rafb.net/paste/results/rDqdhe55.html
11:28:43 <hyrax42> @type iterate
11:28:44 <lambdabot> forall a. (a -> a) -> a -> [a]
11:29:08 <vincenz> > take 3 $ iterate (+1) 1
11:29:09 <lambdabot> [1,2,3]
11:29:16 <hyrax42> ah ok
11:29:26 <hyrax42> it's the fun one for fixed point iterations
11:29:27 <vincenz> generates an infinite list
11:29:28 <hyrax42> and so on
11:32:44 <hyrax42> is nub O(n^2) on (finite) lists?
11:33:18 <vincenz> yes
11:33:39 <vincenz> if it required Ord instead of Eq
11:33:41 <vincenz> it could be n log n
11:36:39 <dcoutts> dons, takeWhile gets a stack overflow with a large file when it has to go a long way down, eg try 50mb worth of /dev/zero
11:40:50 <palomer> oh no, it looks like I might be using the continuation monad
11:40:52 * palomer hopes not
11:41:58 <stepcut> palomer: :p
11:48:21 <palomer> whew, this is going to be a wicked monad
11:48:33 <hyrax42> palomer: what's it do
11:55:46 <sjanssen_> @. elite quote
11:55:46 <lambdabot> JJug91e S4yS: i wAz0rz RIdIng aR0uND 70wn aND 7HiS CoP ON pa7Ro| 0N A 8IxE Rode UP nEX+ +0 ME 4nD zAID, "T|-|ERe'z ALwayz0rz A z|-|Ow 0fph." I OphfeR3D 7o +3aCH HiM +O RidE 4ND hE|p 5E7 UP A UNi(Y(
11:55:46 <lambdabot> l3 paTR0l SQUAD, BU+ H3 DEclINed.
11:56:34 <sjanssen_> @v
11:56:35 <lambdabot> "\"\\\"\\\\\\\"\\\\\\"
12:04:43 <palomer> hyrax42: let's you iterate through a tree twice
12:04:57 <palomer> using the global state accumulated the first time to compute something the second time
12:06:17 <palomer> I'll need Cale's help to build it
12:06:19 <palomer> @seen Cale
12:06:19 <lambdabot> Cale is in #haskell. I last heard Cale speak 2 hours, 11 minutes and 24 seconds ago.
12:06:44 <Cale> hi
12:06:59 <palomer> yo
12:07:21 <palomer> Cale: I want to build a monad which let's me iterate through a tree, using the state accumulated in the first pass to serve for the second pass
12:07:53 <Cale> that's possible using the state monad
12:07:57 <palomer> so you'd have something like do {x <- foo; y <- bar; postcondition (lookup x globalTable)}
12:08:28 <palomer> the post condition being run only once everything is done
12:08:43 <palomer> s/post/postcondition
12:09:06 <Cale> what would the postcondition do?
12:09:12 <Cale> (if it failed, say)
12:09:36 <palomer> sorry, I meant post
12:09:50 <Cale> hm?
12:09:53 <palomer> make that:
12:10:07 <palomer> do{x <- foo; y <- bar; return (x,y); post (lookup x globalTable)}
12:10:17 <Cale> okay, and what does post do?
12:10:23 <Cale> er
12:10:25 <Cale> what?
12:10:31 <Cale> why the no-op?
12:10:33 <palomer> it's what's run after the first iteration
12:10:44 <palomer> there's a no-op?
12:10:50 <Cale> do{x <- foo; y <- bar; return (x,y); post (lookup x globalTable)} = do{x <- foo; y <- bar; post (lookup x globalTable)}
12:11:01 <palomer> you sure?
12:11:05 <Cale> yes
12:11:11 <Cale> the monad laws ensure it
12:11:18 <palomer> darn
12:11:25 <palomer> so it'll have to be something like this:
12:11:59 <palomer> do {pre (do  x <- foo; y <- bar, return (x,y)); post (lookup x globalTable}
12:12:10 <palomer> s/;/,
12:12:21 <Cale> you mean s/,/;/
12:12:40 <Cale> okay
12:12:53 <Cale> hmm, so what's the type of pre?
12:13:05 <Cale> it seems to be turning one monad into another
12:13:23 <palomer> m a   would be the monad
12:13:26 <Cale> I'm also really unclear on what pre and post do
12:13:54 <palomer> ok, here's why I need it
12:14:05 <palomer> I'm doing type inference
12:14:08 <palomer> this requires unification
12:14:14 <palomer> I'm also annotating my nodes with types
12:14:18 <palomer> which are later refined
12:14:28 <palomer> so my first pass will refine all the types
12:14:37 <palomer> and my second pass will lookup the refinement in the table
12:14:56 <palomer> (refining=unifying)
12:15:16 <shapr> Is lists.debian.org dead?
12:15:18 <Cale> any reason you can't use a plain State monad for that?
12:15:32 <palomer> how would that work?
12:16:48 <Cale> well, you'd probably do something like storing the current type context in the state, and then you'd have access to it from anywhere
12:17:11 <palomer> http://www.rafb.net/paste/results/F4Iz1I56.html
12:17:28 <palomer> s/annotation/annotating
12:17:32 <palomer> er
12:17:36 <palomer> s/annotating/annotation
12:19:13 <Cale> hmm
12:20:16 <Cale> I'm not sure if I really see the problem
12:21:15 <Cale> maybe you're looking to annotate the code with functions from gamma to types?
12:21:40 <palomer> now you're getting into higher order abstract syntax
12:22:11 <palomer> even then, I'm refining elements in gamma
12:22:18 <Cale> I'm just not certain about what the problem is. You're annotating things with type variables and collecting equations on those variables, right?
12:22:21 <palomer> ok, here's how type inference works:
12:22:30 <palomer> say you have the term \x -> x + 1
12:22:45 <palomer> Cale: I'm solving the equations in place
12:23:25 <palomer> so then you'd try to find types satisfying the sequent x : A |- (x + 1) : (?)
12:23:33 <Cale> but how can you do that if you don't actually have all the equations yet?
12:23:45 <palomer> Cale: you unify as you harvest them
12:23:54 <palomer> and you store the temporary results in a global table
12:24:07 <Cale> yeah, but then you have to go back and reapply things
12:24:15 <Cale> no?
12:24:21 <palomer> if I'm not annotating?
12:24:26 <palomer> no
12:24:31 <palomer> If I'm annotating, yes
12:24:35 <Cale> yeah
12:24:43 <palomer> and this is what bothers me
12:25:07 <palomer> so I want to wrap this "going back and reapplying" into a monad
12:25:20 <Cale> hmm
12:26:45 <palomer> (or maybe we need something more powerful than a monad?)
12:27:42 <Cale> I'd probably just wrap it into a function :)
12:27:56 <palomer> the reapplying?
12:28:18 <palomer> so you'd simply iterate over the annotated tree?
12:28:41 <Cale> annotate the tree with variables and collect equations, then solve the equations, then apply final types according to the solutions
12:29:12 <palomer> oy ve
12:29:29 <palomer> that's 3 steps!
12:29:33 <Cale> so?
12:29:42 <Cale> they're sane steps to take
12:29:49 <palomer> would be nice if I could combine them into 1
12:30:25 <Cale> let laziness combine them into one
12:30:26 <vincenz> new version of Tree
12:30:58 <palomer> I'm not sure what kind of job laziness would do
12:31:21 <palomer> and, anyways, it's standard practice to solve in place so you can get better error messages
12:31:28 <Cale> really?
12:31:44 <palomer> really
12:31:48 <palomer> heck, usually you do it with ST
12:32:18 <Cale> It seems conceptually bizarre to me to try to do all that at once.
12:32:30 <palomer> solve in place?
12:32:33 <Cale> yeah
12:32:44 <palomer> well, if you store your partial solutions in a global table
12:32:50 <Cale> since you'll perpetually be going back and correcting your solutions
12:32:50 <palomer> all you need to do is normalize your returns
12:33:04 <palomer> you'll be refining your solutions
12:33:28 <palomer> if you're the least bit careful, you'll never correct something twice
12:33:38 <vincenz> http://oasis.yi.org:8080/repos/haskell/Tree.hs
12:34:44 <palomer> and it's probably much faster, too
12:34:44 <Cale> I suppose you could do something like recording a continuation from each point that you have a type which could possibly get refined
12:34:51 <Cale> this is going to get crazy though
12:35:03 <palomer> here's some pretty standard code:
12:35:08 <vincenz> @type (\d l -> map ($ d) l
12:35:10 <lambdabot> parse error (possibly incorrect indentation)
12:35:10 <vincenz> @type (\d l -> map ($ d) l)
12:35:10 <Cale> and I don't think it'll be any faster
12:35:11 <lambdabot> forall a b. a -> [a -> b] -> [b]
12:35:28 <Cale> the same data structure transformation is going to occur in the end
12:35:44 <palomer> http://www.rafb.net/paste/results/TdFEAa36.html
12:35:57 <Cale> note that if you're just annotating a tree with tyvars, you can do that quite lazily
12:36:00 <palomer> ignore Mu
12:36:04 <palomer> (it's incorrect, anyways)
12:36:05 <vincenz> yeah
12:36:09 <vincenz> why nt annotate with TyVars
12:36:15 <vincenz> and then have a lookup table of what is unified so far
12:36:28 <palomer> annotate what with tyvars?
12:36:32 <vincenz> your exps
12:36:34 <vincenz> and funcs
12:36:47 <vincenz> err... all variables basically
12:37:00 <palomer> annotate variables with tyvars?
12:37:02 <vincenz> yep
12:37:03 <palomer> that's what the context does
12:37:23 <palomer> so yes, what you're proposing is what we do
12:37:31 <Cale> We're assuming that you have some kind of tree of code
12:37:42 <vincenz> AST
12:37:59 <palomer> you want to annotate the variables, and only the variables, in the AST?
12:38:03 <vincenz> no
12:38:05 <palomer> or you want to annotate the whole AST
12:38:08 <vincenz> you annotate your entire AST
12:38:11 <vincenz> every single element
12:38:15 <palomer> well, that's what I'm doing
12:38:28 <palomer> but it requires you to have 2 passes
12:38:35 <Cale> You start out by (lazily) annotating the tree with type variables, all distinct. This is trivial.
12:39:02 <vincenz> well the second pass is only to annoate your AST with the stuff your tyvars are mapped to in your context
12:39:06 <vincenz> that's rather trivia
12:39:18 <palomer> trivial but tedious
12:39:48 <Cale> more tedious than storing continuations, and working with code with non-obvious control flow?
12:39:59 <vincenz> second option
12:40:04 <vincenz> have a types be IORefs
12:40:06 <palomer> Cale: I'd say so
12:40:14 <palomer> vincenz: you only need STRefs, really
12:40:16 <vincenz> have your context be (tyvar -> [IORef where used])
12:40:16 <Cale> that's really strange
12:40:20 <vincenz> right, refs of some form
12:40:29 <vincenz> whenever you force a tyvar to a specific type
12:40:29 <palomer> this is what's usually done
12:40:30 <Cale> or not even refs
12:40:31 <palomer> since refs are faster
12:40:34 <vincenz> update all locations your refs are
12:40:39 <Cale> really all you need are functions from gamma to types
12:41:03 * vincenz checks his own typechecker
12:41:19 <palomer> Cale: so you'd have a function sequent :: [(String,Type)] -> Type ?
12:41:37 <Cale> something like that, yeah
12:41:49 <vincenz> typeCheck :: AST () -> (Ast Type, Type)
12:42:42 <palomer> Cale: and how would you use this function?
12:43:50 <Cale> Well, when you're finished constructing gamma, pass it back to all such functions in the tree. Or if you need to see what the current type of some term is, you can pass gamma to it right then.
12:44:04 <vincenz> what is sequent?
12:44:59 <palomer> a sequent is a mapping from context to type
12:45:15 <vincenz> don't you need an input?
12:45:27 <vincenz> String -> [(String, Type)] -> Type
12:46:00 <palomer> Cale: so your tree would be a tree of functions?
12:46:05 <vincenz> ah like that
12:46:07 <Cale> vincenz: I'm saying that he might annotate his AST with such functions
12:46:11 <Cale> yes
12:46:20 <vincenz> yeah would make sense
12:46:35 <palomer> the problem is that a variable in one gamma might not be the same as a variable in another gamma
12:46:36 <vincenz> and if you want to save some work, then define generic traversal methods for your AST
12:46:48 <palomer> (for example, when you shadow a variable)
12:47:07 <Cale> don't reuse variables
12:47:10 <palomer> \x -> (\x -> x) (x+1)
12:47:26 <palomer> don't have much of a choice, it's the user which decides which variables to use
12:47:31 <Cale> these are type variables we're talking about, aren't they?
12:47:37 <vincenz> palomer: your parser should generate unique ids
12:47:44 <vincenz> for each variable name
12:47:49 <palomer> vincenz: but then it needs to get redisplayed to the user
12:47:52 <vincenz> no
12:48:00 <palomer> Cale: term variables, which are mapped to types
12:48:02 <vincenz> type varname = (originalname, uniqueID)
12:48:18 <palomer> I still don't see the advantage of cale's method
12:48:20 <vincenz> that's how I did it... I decorated my variable names with a unique id
12:48:36 <palomer> the uniqueID could even be the ref
12:48:39 <Cale> Gamma should consist of some set of equations on types
12:48:46 <Cale> it shouldn't refer to terms
12:48:59 <palomer> the context mapps term variables to types
12:49:04 <vincenz> Cale: erm the term defines the equation on types
12:49:48 <palomer> s/mapps/maps
12:50:32 <Cale> Every term is already annotated with a globally unique type variable, so you shouldn't need to refer to the term directly in Gamma anyway.
12:50:48 <vincenz> Cale: you mean every variable
12:51:11 <palomer> Cale has a different approach
12:51:13 <Cale> every node of the AST which has a type, basically
12:51:19 <palomer> a little strange to me, admittedly
12:51:26 <vincenz> Cale: yes but the equation at each node is dependent on the kind of node
12:51:44 <Cale> sure
12:54:20 <palomer> cale's method makes sense
12:54:20 <vincenz> is it feasible to have recursively defined classes?
12:54:26 <palomer> it's quite cool, actually
12:54:29 <vincenz> class (Foo a) => Bar b where
12:54:37 <vincenz> class (Bar b) => Foo a where
12:55:00 <Cale> vincenz: I believe you can do that
12:55:10 <palomer> sounds pretty nuts
12:55:13 <palomer> is that haskell98?
12:55:13 <vincenz> (notice the different letters a and b)
12:55:21 <Cale> oh
12:55:29 <xerox> It doesn't work
12:55:41 <Cale> no, that's not going to work, since what's b then?
12:55:41 <xerox> Constrained typevars have to compare in the type
12:55:55 <lisppaste2> syntaxfree pasted "I'd like to overload "and", "or" and "not" for this new type" at http://paste.lisp.org/display/20123
12:56:18 <palomer> yes, I like cale's method
12:56:29 <vincenz> class (Foo f) => Bar b where foo :: b a -> f a
12:56:29 <vincenz> class (Bar b) => Foo f where bar :: f a -> b a
12:56:30 <palomer> (though annotating every term with a tyvar is needless)
12:56:41 <syntaxfree> has my lisppaste gotten here?
12:56:44 <sjanssen_> syntaxfree: yes
12:57:01 <sjanssen_> syntaxfree: you can't overload and/or, they're not in a typeclass
12:57:02 <Cale> vincenz: class (Foo f) => Bar b f where foo :: b a -> f a
12:57:03 <Cale> er
12:57:05 <syntaxfree> (if anyone has a better name than "Trool", I'm  also in)
12:57:09 <Cale> vincenz: class (Foo b f) => Bar b f where foo :: b a -> f a
12:57:23 <Cale> class (Bar b f) => Foo b f where bar :: f a -> b a
12:57:27 <syntaxfree> so I basically have to create a class "Logic", and make Bool an instance of it?
12:57:35 <sjanssen_> yes
12:57:37 <vincenz> Cale: I see
12:57:52 <vincenz> syntaxfree: there's another option
12:57:56 <syntaxfree> but, but, can I just go around overruling the Prelude like that?
12:57:56 <vincenz> syntaxfree: instead of using and or and not
12:58:04 <Cale> actually, rather than that, just do
12:58:05 <vincenz> syntaxfree: use +, * and unary minus
12:58:16 <vincenz> syntaxfree: and define your thing an instance of Num
12:58:25 <vincenz> or some proper subclass of Num
12:58:26 <syntaxfree> that's messy. Num needs /
12:58:32 <xerox> syntaxfree - import Prelude hiding (and, or, not) and then define yours.  But it's not as clean as typeclassing.
12:58:33 <Cale> class FooBar b f | b -> f, f -> b where foo :: b a -> f a; bar :: f a -> b a
12:58:35 <sjanssen_> syntaxfree: use an exlicit prelude import "import Prelude hiding (and)"
12:58:41 <vincenz> the num classes really oughta be extended
12:58:56 <syntaxfree> there really should be something somewhat like my Trool type.
12:58:57 <xerox> @yow SyntaxNinja 
12:58:57 <lambdabot> INSIDE, I have the same personality disorder as LUCY RICARDO!!
12:59:03 <syntaxfree> I( need a better name than Trool too!
12:59:11 <vincenz> Cale: erm... can I then do (FooBar _ f) => f x ...
12:59:12 <Cale> Trool?
12:59:19 <SyntaxNinja> yo xerox
12:59:20 <syntaxfree> Cale: http://paste.lisp.org/display/20123
12:59:21 <Cale> vincenz: no
12:59:29 <vincenz> Cale: but b won't be used on the left side
12:59:29 <sjanssen_> syntaxfree: have you considered type Trool = Maybe Bool ?
12:59:33 <vincenz> for some function using f
12:59:38 <vincenz> (right side)
12:59:44 <Cale> vincenz: well, you can leave it a variable
12:59:45 <sjanssen_> syntaxfree: then you could use liftM and the like to get your operations easily
12:59:47 <syntaxfree> Umm. 
12:59:57 <vincenz> Cale: then you have more variables on constraint than are being used which is illegal
13:00:00 <syntaxfree> if Trool = Maybe Bool, then what does Undefined look like?
13:00:05 <vincenz> syntaxfree: Nothing
13:00:18 <sjanssen_> > liftM (not) Nothing
13:00:19 <syntaxfree> hmm. Why would I need liftM, then?
13:00:19 <lambdabot> Nothing
13:00:28 <sjanssen_> > liftM not (Just True)
13:00:29 <lambdabot> Just False
13:00:32 <syntaxfree> ahhh.
13:00:33 <syntaxfree> I see.
13:00:41 <xerox> syntaxfree - liftM = \f xs -> xs >>= return . f
13:00:47 <syntaxfree> Just and Nothing behaves something like []
13:00:49 <vincenz> > [minBound..maxBound] :: [Maybe Bool]
13:00:49 <lambdabot>  add an instance declaration for (Bounded (Maybe Bool))
13:00:49 <lambdabot>   In an arithmetic sequence: [minBound .. maxBound]
13:00:49 <lambdabot>   In the expression: [minBound .. maxBound] :: [Maybe Bool]
13:00:58 <sjanssen_> I suppose it won't work for all operations
13:00:59 <vincenz> how lame
13:01:20 <sjanssen_> > liftM (||) Nothing (Just True)
13:01:21 <syntaxfree> so. is it possible to create a type composed of a list of same-sized lists?
13:01:21 <lambdabot> Couldn't match `(->) t' against `Maybe'
13:01:36 <sjanssen_> > liftM2 (||) Nothing (Just True)
13:01:36 <vincenz> why is Maybe not Bounded?
13:01:37 <lambdabot> Nothing
13:01:47 <Cale> syntaxfree: I believe so, awkwardly.
13:01:48 <vincenz> instance (Bounded a) => Bounded (Maybe a)
13:02:10 <moonlite> in a relational database i have a one to many relationship between the table "authors" and the table "posts", would one say that it is posts that references authors or the other way around? sorry for being ab it offtopic :)
13:02:20 <vincenz> minBounded = Nothing, maxBound = Just maxBound
13:02:24 <syntaxfree> I think I'm gonna go with my definition of Trool.
13:02:30 <syntaxfree> Any ideas for a better name?
13:02:51 <vincenz> Troll
13:02:57 <Cale> Maybe Bool :)
13:03:21 <Cale> If you use Maybe, you get lots of functions for free
13:03:48 <Cale> btw, isTrue that you wrote there is a type error
13:04:19 <vincenz> (instance (Bounded a) => Bounded (Maybe a)) and (instance (Enum a) => Enum (Maybe a)) should exist imho
13:04:40 <sjanssen_> vincenz: I concur
13:04:48 <vincenz> with Nothing as least value
13:05:02 <sjanssen_> > compare Nothing (Just 2)
13:05:03 <lambdabot> LT
13:05:12 <vincenz> [minBound .. maxBound] :: (Maybe Bool) => [Nothing, Just False, Just True]
13:05:12 <sjanssen_> yeah, especially since Ord is defined
13:05:37 <xerox> > [minBound..maxBound] :: [Maybe Bool]
13:05:37 <lambdabot>  add an instance declaration for (Bounded (Maybe Bool))
13:05:37 <lambdabot>   In an arithmetic sequence: [minBound .. maxBound]
13:05:37 <lambdabot>   In the expression: [minBound .. maxBound] :: [Maybe Bool]
13:05:43 <xerox> (-:
13:05:43 <sjanssen_> > compare (Left 2) (Right 2)
13:05:44 <lambdabot> LT
13:05:45 <vincenz> xerox: and Maybe is not an instance of Enum 
13:06:03 <xerox> Then your ordering is arbitrary?
13:06:07 <vincenz> no
13:06:11 <vincenz> cause it IS instance of Ord
13:06:45 <vincenz> another thing which I think should hold
13:06:49 <Cale> syntaxfree: seriously though, using Maybe is way cooler, since you get a monad instance with it that lets you write lots of things far more conveniently
13:06:57 <vincenz> (Ord a, Bounded a) => Enum a
13:07:51 <Cale> vincenz: I don't think I agree about that.
13:07:56 <vincenz> why not
13:08:02 <vincenz> ifi you can impose an ordering you can number them
13:08:13 <Cale> because something can be ordered and bounded but not enumerable
13:08:32 <Cale> there may be no "next" one
13:08:48 <Cale> consider rational numbers in the intervl [0,1]
13:08:57 <vincenz> hmm
13:09:02 <vincenz> good touche
13:09:14 <vincenz> alright
13:09:17 <Cale> (sure they're enumerable, but not in a way that the ordering makes obvious)
13:09:18 <vincenz> Enum a => Ord a
13:09:35 <Cale> that might be doable
13:09:49 <Cale> though any automatic instance will likely be very expensive
13:10:02 <vincenz> compare x y = fromEnum x `compare` fromEnum y
13:10:09 <Cale> (think about Integer)
13:10:22 <Cale> oh, right, fromEnum
13:10:30 <vincenz> Integer is not part of Enum
13:10:55 <Cale> ah, right, because fromEnum :: (Enum a) => a -> Int
13:10:59 <Cale> @type fromEnum
13:11:00 <lambdabot> forall a. (Enum a) => a -> Int
13:11:02 <Cale> yes
13:11:18 <vincenz> besides
13:11:19 <sjanssen_> > fromEnum (12 :: Integer)
13:11:19 <lambdabot> 12
13:11:23 <vincenz> any Enum must be lowerbounded by definition
13:11:37 <sjanssen_> > fromEnum (2 ^ 33 :: Integer)
13:11:38 <lambdabot> 0
13:11:41 <vincenz> namely element 0
13:11:49 <Cale> hm?
13:11:58 <Cale> > pred (0 :: Int)
13:11:59 <lambdabot> -1
13:12:01 <vincenz> > take 3 $ [minBound .. maxBound] :: [Integer]
13:12:02 <lambdabot>  add an instance declaration for (Bounded Integer)
13:12:02 <lambdabot>   In an arithmetic sequence: [minBound .. maxBound]
13:12:31 <vincenz> n
13:12:32 <vincenz> nm
13:12:34 <Cale> > take 3 $ [minBound .. maxBound] :: [Int]
13:12:35 <lambdabot> [-2147483648,-2147483647,-2147483646]
13:12:35 <xerox> Heh.
13:12:53 <vincenz> fromEnum is flawed for Integer
13:13:10 <Cale> it's not defined for Integer
13:13:17 <vincenz> then what did sjanssen do
13:13:22 <vincenz>  > fromEnum (12 :: Integer)
13:13:25 <vincenz> > fromEnum (12 :: Integer)
13:13:26 <lambdabot> 12
13:13:50 <Cale> oh, I see
13:13:53 * vincenz votes for a redefinition
13:13:58 <sjanssen_> > [1.1 .. 10]
13:13:59 <lambdabot> [1.1,2.1,3.1,4.1,5.1,6.1,7.1,8.1,9.1,10.1]
13:14:00 <vincenz> fromEnum :: (Enum a) => a -> Integer
13:14:10 <Cale> yeah
13:14:23 <vincenz> > fromEnum (1.1)
13:14:24 <lambdabot> 1
13:14:26 <vincenz> > fromEnum (1.2)
13:14:27 <lambdabot> 1
13:14:29 <vincenz> hmm
13:14:41 <sjanssen_> > fromEnum (1/0)
13:14:41 <lambdabot> 0
13:14:43 <vincenz> > map fromEnum $ [1.1 .. 10]
13:14:44 <lambdabot> [1,2,3,4,5,6,7,8,9,10]
13:14:56 <vincenz> > map fromEnum $ [1.1, 1.2 .. 1.9]
13:14:57 <lambdabot> [1,1,1,1,1,1,1,1,1]
13:15:02 <vincenz> lol
13:15:07 <Cale> It really bothers me that Int is used so much in the Prelude
13:15:08 <vincenz> > [1.1, 1.2 .. 1.9]
13:15:09 <lambdabot> [1.1,1.2,1.2999999999999998,1.3999999999999997,1.4999999999999996,1.5999999999999994,1.6999999999999993,1.7999999999999992,1.899999999999999]
13:15:15 <vincenz> fromEnum is seriously flawed
13:15:16 <Cale> it should really be in a separate library
13:15:21 <vincenz> you'd expect succ numbers to be different
13:15:34 <vincenz> > succ 1.1
13:15:35 <lambdabot> 2.1
13:15:43 <Cale> fromEnum :: a -> Int
13:15:43 <Cale> Convert to an Int. It is implementation-dependent what fromEnum returns when applied to a value that is too large to fit in an Int.
13:15:52 <vincenz> how about succ then
13:15:56 <vincenz> > succ 1.1
13:15:57 <lambdabot> 2.1
13:16:04 <vincenz> > [1.1, 1.2, .. 1.5]
13:16:04 <lambdabot>  parse error on input `..'
13:16:07 <Cale> succ :: a -> a
13:16:07 <Cale> the successor of a value. For numeric types, succ adds 1.
13:16:08 <vincenz> > [1.1, 1.2 .. 1.5]
13:16:09 <lambdabot> [1.1,1.2,1.2999999999999998,1.3999999999999997,1.4999999999999996]
13:16:29 <vincenz> Cale: yeah and I can imagine doing multiple succs for enumFromThenTo
13:16:36 <vincenz> but these are less than one succ
13:16:52 <Cale> sure
13:17:28 <vincenz> > succ . head $ [1..5]
13:17:29 <lambdabot> 2
13:17:39 <vincenz> > succ . head $ [1.1, 1.2 .. 1.5]
13:17:40 <lambdabot> 2.1
13:17:49 * vincenz tsks
13:17:57 <Cale> so
13:18:23 <vincenz> so there are obviously no laws tying together the different functions of Enum
13:18:26 <vincenz> making it completely arbitrary
13:18:56 <Cale> numericEnumFromThenTo n n' m = takeWhile p (numericEnumFromThen n n')
13:18:56 <Cale>                              where
13:18:56 <Cale>                                p | n' >= n   = (<= m + (n'-n)/2)
13:18:56 <Cale>                                  | otherwise = (>= m + (n'-n)/2)
13:19:14 <Cale> numericEnumFromThen n m =  iterate (+(m-n)) n
13:20:33 <vincenz> why the /2
13:20:50 <vincenz> (<= (m
13:20:57 <vincenz> <= m
13:20:59 <vincenz> that's enough
13:21:08 <vincenz> and >= m
13:21:24 <Cale> > [1.0,1.2..1.5]
13:21:25 <lambdabot> [1.0,1.2,1.4,1.5999999999999999]
13:21:32 <vincenz> hmm
13:21:37 <vincenz> funky
13:22:00 * vincenz would think the top value to be the maximum
13:22:05 <Cale> > [1.0,1.21..1.5]
13:22:06 <lambdabot> [1.0,1.21,1.42]
13:22:23 * vincenz shrugs
13:22:33 <Cale> it is a little strange
13:23:03 <vincenz> yeah
13:23:23 <Cale> they made it so that the last value is closer to the specified endpoint than any other value in the arithmetic sequence
13:23:31 <vincenz> so it would seem yes
13:23:39 <eivuokko> Ergh
13:23:43 <eivuokko> Is that in spec?
13:23:46 <Cale> yes
13:23:50 * vincenz proposes removing numbers altogeter and going back to functions
13:23:59 <eivuokko> Heh
13:24:04 <vincenz> :D
13:24:14 <sjanssen_> that makes sense, because you can't reliably compare floats for equality
13:24:24 <Cale> a lambda-calculus implementation of floats
13:24:26 <vincenz> sjanssen_: yes you can
13:24:51 <vincenz> you just can't reliably add em and such
13:24:54 <zacch> hi, stylistic question about IO monads: I wrote an interpreter for a simple programming language with a "print" statement, all other statements perform no I/O. now what's preferable: making interpretation of all other statements monadic too, or handle the "print" separately and keep the IO monad away from the rest?
13:25:10 <vincenz> zacch: second
13:25:15 <sjanssen_> vincenz: okay, you can't reliably compare them for equality after you've done operations on them
13:25:28 <vincenz> sjanssen_: that's why we should have as ONLY instance (Eq Float)
13:25:30 <vincenz> and not Num
13:25:45 <vincenz> and Ord 
13:25:46 <vincenz> possibly
13:25:48 <sjanssen_> vincenz: that's pretty impractical
13:25:49 <zacch> vincenz: that's what I currently have. strong reasons for it?
13:25:49 <vincenz> tho that fails with nan
13:25:58 <vincenz> zacch: haskell works that way?
13:26:13 <vincenz> sjanssen_: it's a joke
13:26:16 <zacch> vincenz: what way?
13:26:24 <eivuokko> zacch, Keeping state as restricted as possible is often considered good style in haskell.  IO is monster of state.
13:26:32 <Cale> zacch: it really depends, though it's nice to have the types of things give you as many guarantees as possible
13:27:06 <zacch> Cale: types do that either way
13:27:19 <sjanssen_> zacch: perhaps you should just add a type system with monads to your language ;-)
13:27:34 <Cale> Working with IO computations is far more dangerous than working with plain values.
13:28:16 <Cale> IO computations are harder to debug, and harder to reason about, so it's usually a good policy to keep them to a minimum.
13:28:17 <zacch> it's not dangerous - performing one step of the interpreter is step :: Instruction -> State -> State
13:28:27 <zacch> otherwise, it would be: Instruction -> State -> IO State
13:28:36 <zacch> so same guarantees from the type system
13:28:57 <Cale> right, and the IO that's produced, does it access the network?
13:28:58 <vincenz> zacch: except not all things touch the state
13:29:10 <vincenz> so only those that touch the state should be typed as `IO` monad
13:29:11 <sjanssen_> zacch: what about step :: Instruction -> State -> Either State (IO State)
13:29:19 <zacch> I currently have the first way, the problem with it is this:
13:29:27 <xerox> sjanssen - that sounds inpractical
13:29:33 <xerox> s/in/un/
13:29:35 <Cale> You know that the State value can't cause your program to access the network or the disk at any point
13:29:37 <zacch> 1) not all instructions are handled uniformely (via "step" function")
13:29:41 <Cale> but the IO computation might
13:29:50 <zacch> 2) I have to inspect the current instruction in two different functions
13:30:22 <Cale> but yeah, it may be more natural to simply convert your language into the IO monad
13:30:25 <xerox> I think...
13:30:43 <xerox> I think one could write a pure interpreting function and plug it into a REPLoop.
13:30:55 <Cale> though I'd probably still leave things like expression evaluation pure
13:31:00 <xerox> Yeah!
13:31:23 <zacch> what do you mean by "pure" - it's pure with monads too
13:31:39 <Cale> It might not be.
13:31:44 <zacch> what?
13:31:47 <xerox> Err no, hmm.  I was thinking about having the interpreter spitting out the series of action to run and the external code running it.
13:31:55 <Cale> by 'pure' in this case, I mean not having an IO type
13:32:18 <xerox> Cale: interpreter :: AST -> ... ?
13:32:21 <Cale> xerox: that's also really quite possible
13:32:30 <sjanssen_> perhaps State can contain a lazy stream of input, and the evaluation loop yield a lazy stream of output
13:32:44 <zacch> actually, it's an interpreter for a virtual machine code. State captures the state of the machine (stack, program counter etc.)
13:32:52 <Cale> zacch: do the programs you're interpreting take any input?
13:32:55 <sjanssen_> if all your language has is simple IO from stdin/stdout
13:32:59 <zacch> Cale: no
13:33:26 <xerox> parser :: String -> AST, interpreter :: AST -> Program, (R)EPL :: Program -> IO ()
13:33:45 <zacch> so since it's concise VM code, the "step" function is very simple: it's only one case statement branching on the integer code
13:33:55 <zacch> (I need no parser)
13:34:13 <xerox> The Program could wrap any kind of IO actions, for one.
13:34:30 <zacch> the trouble with the current approach is is that the code for "print" is missing - handled elsewhere. that makes it somewhat not nice
13:34:56 <Cale> you could add some mechanism to the state to keep track of what's being printed
13:35:06 <Cale> (in the simplest case, just a String)
13:35:20 <zacch> xerox: I understand that. The question is only whether one VM instruction performing I/O warrants pulling the IO monad in even into the "step" function
13:35:40 <Cale> 'print' is a pretty limited form of IO
13:36:00 <zacch> Cale: yes, that's very true, though not worky: I want "print" to perform I/O right away - the program might not terminate!
13:36:12 <Cale> laziness is your friend
13:36:38 <zacch> yes, also true.
13:37:00 <xerox> Cale - maybe the interpreting works in a Writer, and one `tell's out the strings to be printed.
13:37:08 <palomer> I also thought laziness was my friend, until he ran off with my wife
13:37:10 <palomer> bastard
13:37:11 <Cale> xerox: that's an idea
13:37:33 <xerox> ?palomer
13:37:34 <lambdabot> Hrmph
13:38:00 <sjanssen_> palomer: he probably didn't run off until you tried to evaluate your wife
13:38:45 <Cale> zacch: do you know about the Writer monad?
13:38:55 <xerox> Cale - that would work for a calculator :-)
13:38:57 <Cale> it would be much more appropriate than IO
13:39:09 <xerox> (For example, I mean.)
13:39:19 * xerox tries something
13:39:48 <zacch> Cale: no!
13:39:55 <zacch> (I didn't know it)
13:40:06 <Cale> step :: Instruction -> State -> Writer String State
13:40:24 <zacch> now what's the advantage over IO monad?
13:40:33 <Cale> you can't accidentally do IO
13:40:33 <zacch> ah I see, write to string?
13:40:36 <Cale> yes
13:40:47 <Cale> tell "hello" will append "hello" to the current string
13:42:14 <zacch> and how to combine this with lazy evaluation to work around the termination problem?
13:42:23 <Cale> that's automatic
13:42:25 <davidmccabe> ! and // seem really fitting for some reason. I'm always curious about how arbitrary symbols are chosen.
13:42:29 <Cale> you don't even need to worry about it
13:43:00 <Cale> just execWriter (myWholeHonkingComputation), and you'll get a lazy string of all the output
13:44:16 <Cale> (don't do this on each step -- combine all the steps before applying execWriter)
13:46:05 <zacch> what do you mean with "combine the steps"? I have one "print" VM instruction, and want to see output as soon as it's encountered. I suppose you also would use "putStr" in "main" to print the writer monad's string?
13:46:27 <Cale> okay, assuming that you have all the instructions in some list
13:46:38 <zacch> yes, I have that (or an array)
13:47:06 <xerox> Cale - infix data constructors: :+: :*: etc.. ?
13:47:19 <Cale> you're going to be mapping those instructions onto functions of type State -> Writer String State (we could also use a state monad here, but let's go easy on it for now :)
13:47:27 <Cale> xerox: yep
13:47:32 <xerox> Thanks.
13:47:56 <zacch> do you mean fold instead of map?
13:48:12 <Cale> well, it is a sort of fold, in the end
13:48:24 <Cale> (might be a fold and a map, but we can fuse them)
13:48:39 <zacch> I think it only takes fold
13:48:54 <Cale> @type foldM
13:48:55 <lambdabot> forall a (m :: * -> *) b.
13:48:55 <lambdabot>    (Monad m) =>
13:48:55 <lambdabot>    (a -> b -> m a) -> a -> [b] -> m a
13:49:20 <Cale> this is exactly what you need
13:49:35 <zacch> yeah
13:49:47 <Cale> well, there may be at least one issue with it
13:50:00 <Cale> does your language have a jump instruction?
13:50:09 <zacch> yes
13:50:28 <Cale> ah, okay, so the State also has a code pointer
13:50:37 <zacch> yes, I mentioned that
13:50:42 <Cale> yeah, you did :)
13:50:45 <Cale> okay
13:50:54 <Cale> so you can't really get hold of the list you'll need
13:51:28 <Cale> (well, maybe you can, but it would be complicated)
13:51:36 <zacch> yes, very complicated
13:52:02 <zacch> besides, the fold may not terminate
13:52:17 <Cale> hmm, but this is not a real problem, it's not a fold, it's more of an iteration then
13:52:30 <zacch> ture
13:52:31 <zacch> true
13:53:07 <xerox> I want `permutations' in Prelude (:
13:53:08 <zacch> OK, I can easily code an analogous function
13:53:16 <zacch> (to foldM)
13:53:24 <Cale> http://www.haskell.org/ghc/docs/latest/html/libraries/mtl/Control-Monad-RWS.html -- this monad seems ideal, actually
13:53:43 <xerox> Indeed!
13:54:02 <xerox> `RWST t w s m a' yay.
13:54:07 <Cale> not T
13:54:09 <xerox> s/t/r/
13:54:14 <xerox> Just looking around.
13:54:43 <Cale> You could work in the monad RWS Instructions String MachineState
13:55:05 <xerox> Very nice.
13:55:50 <Cale> 'ask' will be an action which gives you the Instructions, 'tell' will append a string to the output, and get/put/modify will act on the machine state.
13:56:10 <Cale> and you'll be assured that no actual IO will occur
13:56:13 <xerox> That's a dream monad.
13:56:25 <xerox> 6.6 only?
13:56:29 <Cale> no
13:56:36 <xerox> Good.
13:56:39 <sjanssen_> One Monad to bring them all, and in the darkness (>>=) them.
13:56:45 <Cale> hahaha
13:56:53 * xerox laughs
13:56:57 <Cale> aaaaaauuuuggghh...
13:57:06 <zacch> where do you get the "ask" from?
13:57:14 <Cale> from Reader
13:57:14 <xerox> From the Reader part.
13:57:23 <zacch> yes, where do you get the reader from?
13:57:37 <Cale> http://www.haskell.org/ghc/docs/latest/html/libraries/mtl/Control-Monad-Reader.html#t%3AMonadReader -- this documents it
13:57:54 <xerox> evalRWST :: Monad m => RWST r w s m a -> r -> s -> m (a, w)
13:57:55 <xerox> execRWST :: Monad m => RWST r w s m a -> r -> s -> m (s, w)
13:58:13 <Cale> we're not using the transformer version
13:58:13 <xerox> In each case you feed the action with a Reader environment `r' and a State state `s'.
13:58:19 <xerox> Err, again, sorry.
13:58:25 <Cale> evalRWS :: RWS r w s a -> r -> s -> (a, w)
13:58:25 <Cale> execRWS :: RWS r w s a -> r -> s -> (s, w)
13:58:29 * xerox 's eye falls on that every time.
13:58:41 <xerox> That's the same anyway.
13:59:00 * xerox suggests to use w = IO :-P
13:59:10 <Cale> you could, but there's no need
13:59:14 <Cale> String will do
13:59:21 <xerox> davidhouse - ohi!  You must see this one <http://www.haskell.org/ghc/docs/latest/html/libraries/mtl/Control-Monad-RWS.html>
13:59:24 <Cale> and we're using this to avoid IO
13:59:31 <xerox> Yes, I was kidding :-)
13:59:44 <davidhouse> xerox, what's that?
13:59:59 <Cale> RWS is nothing too special, you can get it by applying those three transformers to the identity monad
14:00:05 <xerox> davidhouse - Reader + Writer + State!
14:00:11 <davidhouse> heh, nice.
14:00:20 <zacch> OK, thank you, that certainly helps me a lot. Only one thing: why are you so keen on avoiding I/O - after all, that's what the print statement is meant to do no? I mean, what's the additional advantage of the writer?
14:00:27 <xerox> Cale - what else _is_ special, conversely?
14:00:29 <davidhouse> surely Reader + State = State?
14:00:40 <davidhouse> Reader is a special case of State - one with a non-mutable environment
14:00:41 <monochrom> haha sjanssen.  But consider join instead of bring.
14:00:56 <xerox> davidhouse - nope, as Cale says, stacked.
14:01:06 <Cale> zacch: well, it means that the compiler is going to ensure that various things simply can't happen
14:01:19 <zacch> such as?
14:01:22 <Cale> IO is a real big bag of tricks
14:01:25 <davidmccabe> eeek! ghc ate all my memory!
14:01:39 <Cale> If all you know about a value is that it's of type IO ()
14:01:41 <xerox> davidhouse - so you feed a RWS action with a Reader environment, a State state, and get out a value and a Writer log (or the State state.)
14:01:45 <Cale> then you don't really know much
14:01:50 <Cale> it could do anything
14:02:00 <monochrom> Such as you cannot have a function of type IO a -> a   *duck*
14:02:02 <zacch> yes, that's true - but contrast this to IO State
14:02:07 <zacch> (which is what I would have had)
14:02:13 <Cale> or IO State even
14:02:15 <Cale> that's no better
14:02:23 <zacch> this I don't get - why?
14:02:28 <davidhouse> by the looks of things, you get a value, Writer output and the new State
14:02:29 <Cale> It could do anything, before returning a new State
14:02:48 * davidmccabe tries to figure out why this simple program is taking huuuuuge amounts of RAM as soon as it starts up.
14:02:53 <davidhouse> heh, "newtype RWST r w s m a"
14:03:02 <xerox> davidhouse - haha, I said the same thing.
14:03:17 <wolverian> sometimes single-character names are annoying.
14:03:19 <Cale> you're guaranteed that it returns a value of type State when executed, but that's about it. You don't know if it reads or writes the network, disk, or does any number of other things
14:03:33 <Cale> Whereas a String can do no such things
14:03:45 <Cale> it's just a value, you can observe its contents
14:03:55 <davidhouse> @kind Control.Monad.RWS.RWST
14:03:57 <lambdabot> * -> * -> * -> (* -> *) -> * -> *
14:04:12 <Cale> and it's completely defined by its contents
14:04:56 <Cale> Or perhaps a better comparison would compare it with a State, which is probably a tuple of some Ints and miscellaneous other pure values -- the same argument applies
14:05:44 <Cale> Now, RWS, you know that it might read and write its local state, write to its writer stream, and look at its environment, but that's all it can do
14:05:58 <Cale> it can't access files on disk, for example
14:06:48 <Cale> and it could be translated into a non-monadic representation which just uses a bunch of functions which pass tuples around
14:07:34 <Cale> It's generally good to use the "smallest" monad which you can get away with.
14:07:52 <Cale> That is, the one with just the features you need, and nothing extra.
14:07:56 <vincenz> is it possible to have lambdabot give multiline quotes?
14:07:57 <zacch> OK, these seem convincing points to me. Though in particular the reader feels like overkill, doesn't it? The set of instructions is fixed, so I don't need to ask it.
14:08:12 <Cale> That's what Reader is for
14:08:13 <monochrom> For example, a large part of a program consists of pure functions, no need to IO.
14:08:25 <Cale> (computations which read from a fixed environment)
14:08:50 <Cale> Reader e a is basically the same as e -> a
14:09:31 <xerox> Basically the same as an implicit parameter <grin>
14:09:46 <Cale> or an explicit one even
14:09:58 <xerox> Add linear!
14:10:07 <Cale> not linear
14:10:26 <Cale> linear implicit parameters are closer in nature to the state monad
14:10:37 <xerox> Is the same linearity enforced by Clean?
14:10:40 <davidhouse> what does linear mean in this context?
14:12:03 <Cale> http://www.haskell.org/ghc/docs/latest/html/users_guide/type-extensions.html#linear-implicit-parameters
14:12:22 <monochrom> Imperative programming is degenerate functional programming, in that each statement is a function with domain "all state and environment" and co-domain "all state and environment".  Functional programming relaxes that to fine-grained domains and co-domains - you have the full spectrum.
14:13:00 <xerox> Well posed.
14:13:11 <monochrom> Oh, and imperative programming imposes linearity too.
14:13:49 <vincenz> @karma+ monochrom 
14:13:49 <lambdabot> monochrom's karma raised to 2.
14:14:19 <vincenz> monochrom: that also explains why going from CFG to something looser is such a b*tch in imperative language compilers
14:14:26 <vincenz> for instance VFG
14:14:43 <monochrom> In this postmodern new-age world, you have to phrase something as "inclusive", "love, not war", "empowerment", ... in order to sell it.
14:14:59 <vincenz> monochrom: and completely biological
14:15:11 <davidhouse> not to mention organic.
14:15:22 <vincenz> assembly! the language with a completely biological compiler
14:15:40 <monochrom> (Fortunately, no matter what you sell, you can always do that, by definition of postmodernism.  (I can do the same to imperative programming.))
14:15:48 <Cale> hehe, functional programming empowers you with the ability to restrict yourself into not doing things you don't mean to.
14:16:02 <vincenz> Cale: like a recent google talk "less is more"'
14:16:21 <vincenz> vidoegoogle for "Paradox of Choice Why less is more"
14:16:37 <davidhouse> hey, it's true on unix.
14:16:49 <zacch> uhm, I just realized that I don't need the "step" function at all in the interpreter - now I simply have iter :: State -> IO ()
14:16:49 <vincenz> nope
14:16:53 <vincenz> less != more
14:17:00 <zacch> ah, there was another point I wanted to mention:
14:17:08 <davidhouse> well, they fulfill the same role.
14:17:17 <zacch> the step function had the advantage that its signature was :: instr -> State -> State
14:17:59 <davidhouse> hmm... anyone feel like explaining some type theory to me?
14:18:09 <zacch> while if I pull in a monad in, each of the conditional branches must have a "return" - any clean way to get read of it? I suppose I should transform it to "return $ case ...."
14:19:29 <monochrom> I heard that the two subjects "type systems" and "type theory" are different.  I also heard that you probably have the former in mind.
14:19:30 <davidhouse> "In particular, while HM polymorphism allows the denition of functions that behave uniformly over all types, it does not permit...". what does "behave uniformly" here mean? i thought the entire point of polymorphism was that a function's behaviour could be dependant on the type of its argument; i.e. not uniform?
14:20:16 <dcoutts> dons, I'm suspicious of the reliability of the benchmark, be reordering them I get quite different timings, eg from 0.2 to 0.26 seconds for findIndexOrEnd
14:20:20 <monochrom> subtype polymorphism allows behaviour dependent on types
14:20:34 <dcoutts> dons, and what's odd is that it's not repeatabilty from one run to the next
14:21:00 <dcoutts> dons, with one order, running several times gives the same results, but changing the order makes a big difference
14:21:23 <monochrom> parametric polymorphism is the one described in the quoted text.  it does not.  f :: a->a  implies (forall x. f x diverges) or (forall x. f x = x)
14:22:15 <monochrom> The word "polymorphism" bears opposite meanings in opposing communities (OOP vs FP)
14:22:37 <monochrom> But so does the word "elegant". :)
14:22:50 <davidhouse> you're saying there's no function other than id and functions returning _|_ that has all types as its domain?
14:23:30 <monochrom> (Viz. if you introduce a lot of states, it's elegant in OOP; if you eliminate a lot of states, it's elegant in FP)
14:23:39 <monochrom> Yes I'm saying that.
14:24:07 <monochrom> I don't have a proof.  Too hard for me.  But I can point you to one.
14:24:36 <monochrom> But the gist is that parametric polymorphism means you are denied of type reflection.
14:24:40 <davidhouse> i was under the impression that polymorphism meant doing different things depending on the type. e.g. show :: Show s => s -> String can have different behaviours depending on whether its argument is, say, an Int or a Bool.
14:25:25 <monochrom> That is some kind of subtype polymorphism.
14:25:40 <monochrom> Did I say that "polymorphism" bears opposite meanings?
14:25:56 <davidhouse> yes
14:26:02 <davidhouse> you didn't really explain.
14:26:31 <monochrom> parametric polymorphism denies you reflection, subtyping, overloading, ...
14:26:39 <davidhouse> polymorphism in OOP is where a function can have more than one definition, distinguishable by their type signitures. the compiler decides which one to use based on the type of arguments you're trying to pass in.
14:26:40 <xerox> davidhouse - maybe in that case, behaviour = returning String?
14:26:59 <davidhouse> xerox, okay, then consider something like (+).
14:27:14 <davidhouse> or Read, that's a better example.
14:27:41 <xerox> 'return a value of that type' heh :)
14:27:57 <monochrom> I have explained why "elegant" bears opposite meanings.  I would think upon hearing that your world is unmade and you no longer carry concepts from OOP over to FP.
14:28:38 <davidhouse> ;)
14:28:38 <norpan> what is happening
14:28:44 <monochrom> (+), read, ... those are subtype polymorphisms too.
14:28:59 <davidhouse> perhaps i need to read up on polymorphism from the start. any paper/textbook references?
14:29:14 <davidhouse> you can explain the whole thing to me if you prefer, if you have the patience ;)
14:29:16 <monochrom> You have to pretty much think of SML in order to know what parametric polymorphism and HM is about.
14:29:40 <monochrom> Haskell has too many nice features and is no longer pure parametric or HM.
14:30:30 <monochrom> Hell, even the word "programming" means very different things, almost opposite things, to different people.
14:31:47 <monochrom> You should notice that I never use "polymorphism" as an isolated noun without adjective.  I always add an adjective before it.
14:32:36 <davidhouse> yes. subtype and parametric are very different?
14:32:44 <davidhouse> @oldwiki Polymorphism
14:32:45 <lambdabot> http://www.haskell.org/hawiki/Polymorphism
14:33:53 <monochrom> Java 1.4 is an example of subtype polymorphism.  SML is an example of parametric polymorphism.  Java 1.5, Haskell, OCaml, C++, ... these mix the two (in different ways).
14:35:19 <davidhouse> wikipedia says parametric polymorphism is things like (++) :: [a] -> [a] -> [a], it doesn't care about the type of the list. it's parametrised over the type of the list, in other words
14:36:02 <davidhouse> i suppose C++ templates would fall into this category.
14:36:20 <mwc_> "what is "scary voodoo""
14:36:34 <mwc_> oh, this isn't jeopardy.
14:38:49 <davidhouse> but when you impose class restrictions, it suddenly jumps to subtype polymorphism?
14:38:55 <monochrom> C++ templates interact with the subclassing mechanism and the operator overloading mechanism too much.
14:39:40 <Dibrom> C++ templates are different than parametric polymorphism in Haskell (based on System-F), although they can seem superficially similar.  In C++, a specialized instance of code is created at compile time for each type one uses for a given template in C++ (also you can do partial specialization, which you can't do in Haskell).  In Haskell, a polymorphic function (like the list concatenation) is really more like: \\ a -> \ (h
14:39:48 <monochrom> So I still think it is best to look at SML.
14:39:52 <mwc_> monochrom, I've always thought the opposite: that CPP templates were a (slightly) better macro system that had a token interaction with the type system
14:40:18 <monochrom> "too much" ==> broken, there we agree :)
14:40:26 <mwc_> yes
14:40:30 <davidhouse> Dibrom, that was cut off after \\ a -> \ (h
14:40:46 <Dibrom> \\ a -> \ (head :: a) (tail :: [a]) -> ...
14:40:46 <davidhouse> okay, well lets forget C++ then.
14:40:48 <Dibrom> :)
14:41:25 <Dibrom> in Haskell you just aren't exposed to the fact that are functions that really take a type parameter first
14:42:15 <davidhouse> unless you -fglasgow-exts and forall. your types.
14:42:49 <mwc_> anybody have a good practical introduction to Rank-2 poly?
14:42:51 <Dibrom> well I mean you don't see, in Haskell syntax, that the underlying polymorphic functions work that way.  But if you write a pure system-f evaluator, you can see it
14:43:35 <Dibrom> but C++ polymorphism is still sort of interesting, it's powerful enough to do stuff like what you see in boost
14:43:53 <Dibrom> but it's sort of funny, because I don't think it was meant to be that way
14:44:11 <mwc_> No, I've read that somebody at a conference showed they could print out primes using the template system
14:44:14 <davidhouse> i'm sitll not quite grokking the difference between parametric and subtype polymorphism.
14:44:25 <mwc_> and it came as quite a surprise to the language designers
14:44:35 <monochrom> f :: (forall b. b -> b) -> Int -> String -> (Int,String)   is an example of rank-2 polymorphism
14:44:44 <Dibrom> mwc_: yes, it's turing complete.  You can write a lambda calculus evaluator with templates, where the result is inserted into the code at compile time 
14:45:03 <monochrom> An example of f is: f g n s = (g n, g s)
14:45:09 <Dibrom> *shrug*... guess that's what happens when you don't respect the theory when implementing new features
14:45:14 <Dibrom> all too common with languages like that
14:45:43 <monochrom> Note that it won't type-check with the rank-1 signature (b -> b) -> Int -> String -> (Int,String)
14:46:35 <Dibrom> davidhouse: if you are interested in the difference, you could check out the book Types and Programming Languages
14:46:44 <monochrom> I have shown a dumb use of rank-2 polymorphism.  But there are better uses.  Also, if you also add typeclasses or subtypes, you can do big things.
14:46:52 <Dibrom> probably a lot to read if you're just curious, but it's a very nice book anyway.. I learned a lot from it
14:47:18 <the_lord> Hi, I want to read a file and return something after processing the file, how should I do?
14:47:44 <Dibrom> the_lord: do you understand the IO monad?
14:48:01 <dcoutts> @type readFile
14:48:03 <lambdabot> FilePath -> IO String
14:48:09 <xerox> the_lord: main = do { contents <- readFile filename; return (doStuff contents) }; doStuff :: String -> ...
14:48:09 <monochrom> do { s <- readFile "abc"; return (length s) }   This is an example.
14:48:26 <Dibrom> yeah
14:48:40 <the_lord> @type do { s <- readFile "abc"; return (length s) }
14:48:41 <lambdabot> IO Int
14:48:51 <the_lord> IO, how do I remove it?
14:48:56 <dcoutts> you can't
14:49:02 <xerox> It could be the title of a book :-)
14:49:04 <dcoutts> that's the point
14:49:20 <the_lord> and if I want to pass the result to another function?
14:49:23 <Dibrom> the_lord: you have to do your calculation with the input inside of the IO monad
14:49:27 <xerox> ``IO, how do I remove it? -- The Monad Problem''
14:49:31 <monochrom> I think davidhouse has never seen SML, and so he doesn't understand what I was talking about.  Unfortunately, SML is still the most lightweight and interactive introduction to HM.
14:49:45 <davidhouse> the_lord, if you're in a do block and you go var <- somethingThatReturnsAnIOSomething, then var won't have the IO wrapper.
14:50:01 <monochrom> (Hacking with SML certainly beats reading a thick Greek book under a tree. :) )
14:50:05 <davidhouse> monochrom: no, sadly i haven't. i've got no academic grounding in these things.
14:50:18 <mwc_> monochrom, what's an HM>
14:50:24 <dcoutts> the_lord: main = do { contents <- readFile filename; intermediateResult <- doStuff contents; return (makeFinalResult intermediateResult) };
14:50:25 <monochrom> Hindley-Milner
14:50:28 <mwc_> ah
14:50:32 <Dibrom> isn't there a good guide on IO somewhere by now?
14:50:45 <monochrom> There are too many. :)
14:51:14 <mwc_> I think that teaching do notation before you can write the expression using >>= is a mistake
14:51:28 <thelsdj> i've totally ignored the whole monad thing in my foray into haskell so far, i should probably just get it over with, might even get me more interested
14:51:34 <dcoutts> the_lord, so the point is that you can move a pure computation into the IO monad but you can't get a non-IO result out
14:51:43 <davidmccabe> If I have a type that is simply a set of constructors used as identifiers -- I forget the name for that -- such as 'data Foo = Bar | Baz', can I store those in an unboxed array?
14:51:49 <xerox> the_lord: try this:
14:51:50 <mwc_> thelsdj, oh yes, you can't have any fun without monads
14:52:01 <xerox> @oldwiki MonadsAsContainers
14:52:01 <lambdabot> http://www.haskell.org/hawiki/MonadsAsContainers
14:52:06 <monochrom> Oh, I know!  Hudak's book is an excellent introduction to IO.
14:52:07 <xerox> Maybe it was singular :-)
14:52:11 <dcoutts> the_lord, so it's not restrictive like it sounds, you can always just do your pure computation inside the do block
14:52:48 <Dibrom> monochrom: yeah that's a good book for Haskell
14:52:51 <monochrom> It is, like, completely concrete and "why don't you try these".  Relevant, not abstract.
14:53:16 <mwc_> agreeds
14:53:43 <Dibrom> I would like to see a new version, covering more recent developments though
14:53:50 <Dibrom> maybe for haskell prime :)
14:54:15 <dcoutts> the_lord, do { content <- readFile; ... X ...   }  -- so at point X here, content has type String, so you can do what you like with it there, you just can't get it outside the do {...} block.
14:54:53 <monochrom> I suppose it's now too late to advice the_lord to go get Hudak's book and read.
14:55:07 <dcoutts> or rather if you return it to the outside of the do { ... } block then it'll end up with type IO String. See?
14:55:17 <dcoutts> the_lord, get it?
14:55:56 <the_lord> dcoutts, It doesnt work for me
14:56:01 <mwc_> the_lord, I like to think of a monad as a special boxed-off chunk of the universe, with some special rules. 
14:56:09 <the_lord> it's still IO String
14:56:46 <dcoutts> the_lord, show us your example
14:56:50 <davidhouse> typeclasses are an extension to HM?
14:56:55 <dcoutts> davidhouse, yep
14:57:03 <davidhouse> right.
14:57:11 <the_lord> mtd :: String -> [Token]
14:57:11 <the_lord> mtd f = do { s <- readFile f; return (alexScanTokens s) }
14:57:31 <dcoutts> the_lord, and what is the type of alexScanTokens?
14:57:53 <dcoutts> the_lord, for starters, mtd :: String -> IO [Token]
14:58:22 <the_lord> the thing is I don't want the IO
14:58:37 <mwc_> the_lord, then you can't read a file in there
14:58:37 <dcoutts> the_lord, then you can't read files because that is doing IO
14:58:55 <dcoutts> the_lord, for the reason we said eariler, the result of a do block in the IO monad has type IO something
14:59:17 <xerox> the_lord: what's the purpose of the whole program?
14:59:22 <the_lord> and how do I do something like print, for instance
14:59:27 <the_lord> return a [Token]
14:59:36 <xerox> the_lord: print them?
14:59:41 <dcoutts> do { s <- readFile f; print (alexScanTokens s) }
15:00:08 <xerox> (or mapM_ putStrLn (alexScanTokens s))
15:00:10 <the_lord> no, I want to return [Token]
15:00:16 <xerox> the_lord: to the user?
15:00:27 <the_lord> to another module
15:00:49 <xerox> Then take in input a String, and return [Token], not a filename.
15:01:27 <discoloda> anyone know of a guide to speed up haskell?
15:01:32 <the_lord> in some point I have to read the file
15:01:37 <dcoutts> the_lord, yep, try what xerox suggests, then the top level part of your prog can read the file and pass it to your function
15:01:40 <discoloda> strictness and all that
15:01:42 <xerox> the_lord: outermost you can.
15:02:02 <xerox> the_lord: so that the inner part works purely with all its advantages.
15:02:17 <dcoutts> the_lord, it's best to keep IO in as small a part of the program as possible
15:06:04 <monochrom> "s <- readFile whatever"  this will not read the whole file immediately.
15:06:56 <monochrom> Things will be read on-demand as the rest of the program proceeds.  You can even write your program to not read everything.
15:08:47 <monochrom> Try this, if you're on some kind of *nix.  (Who isn't?)  main = do { s <- readFile "/dev/stdin"; putStrLn (take 10 s) }
15:09:26 <monochrom> Now at the shell prompt, enter: yes | runghc <name of the .hs file containing that code>
15:09:42 <monochrom> "yes" is a program that outputs infinitely many y's.
15:09:57 <monochrom> See that the Haskell program will not take infinite time.
15:11:11 <discoloda> so, no article on optimizations?
15:11:28 <monochrom> I haven't heard of one.
15:13:04 <the_lord> IO a -> a
15:13:20 <monochrom> Please please please forget IO a -> a
15:13:26 <the_lord> isn't there a function that does this?
15:13:35 <monochrom> Yes it's a backdoor.
15:13:35 <vincenz> nope
15:13:42 <monochrom> It's also called cheating.
15:13:44 <vincenz> ... into hell
15:13:58 <the_lord> why?
15:14:11 <Dibrom> because it's not safe
15:14:20 <monochrom> Because if you needed that, why wouldn't you just go write C++ or Java.
15:15:02 <the_lord> but I need to do it in haskell
15:15:11 <the_lord> It's not about choice
15:15:29 <monochrom> Yes, and the point is you also need to learn how to do it in Haskell without IO a -> a.
15:15:31 <davidhouse> it almost certainly can be done without.
15:15:35 <Dibrom> you don't have to do it, you can do your computation in the IO monad
15:16:24 <the_lord> just to try, can't you point me to the function?
15:16:44 <monochrom> Let me put it this way.  IO a -> a is available in ghc but not standard.  You are asked to do the job using just the standard things.
15:16:49 <Dibrom> it's really better to do it the right way :/
15:17:04 <monochrom> You were already given the name of that function two days ago.
15:17:28 <vincenz> the_lord: IO a -> a is bad
15:17:34 <vincenz> the_lord: we'd rather you learn the proper way
15:17:44 <vincenz> the_lord: do you know c++?
15:17:46 <davidhouse> we like to call it It That Shall Not Be Named.
15:17:55 <the_lord> little
15:17:55 <monochrom> Dibrom: Yes.  Moreover it is homework and the homework is (implicitly) asking the student to do it the right way.
15:18:00 <vincenz> the_lord: imagine someone recommending you to use goto
15:18:08 <vincenz> and tentuplle that 
15:18:30 <Dibrom> ah, didn't know it was homework... in that case it's esp important to do it right, yeah
15:18:48 <vincenz> Dibrom: even if it's not it is important
15:18:57 <vincenz> Dibrom: only VERY rare cases should use IO a -> a
15:19:03 <Dibrom> right
15:19:17 <Dibrom> I've never used the function myself, although I know which one it is :)
15:19:23 <monochrom> I have no real morality when it comes to programming.  I can certain show how to cheat.  But this also means 0 marks if you hand that in for homework.
15:19:25 <vincenz> and if your last name is in the set {Peyton, Marlow}
15:19:40 <Dibrom> although I've used the coerce one a bit for some type level arithmetic kind of stuff :)
15:19:43 <davidhouse> Peyton-Jones, that is.
15:20:46 <the_lord> I've found the function for myself
15:20:50 <the_lord> now I can cheat
15:21:09 * vincenz palmslaps
15:21:18 <monochrom> Though I have no morality on programming, I do have some morality on homework.  Namely, I would not advice you how to get 0 marks.
15:21:30 <vincenz> the_lord: while you're at it, why don't you start accessing arrays atthe wrong place so you can mess up the stack
15:21:42 <Dibrom> I agree with monochrom
15:22:12 <psnl> we were told that unsafeIO led to wierd bugs and deadlock, so you might want to be careful
15:22:29 <Dibrom> the_lord: it's really better to just learn the right way.  you won't really understand the point of Haskell if you use functions like this one
15:23:15 <the_lord> I have a week asking what's the right way
15:23:25 <vincenz> you bind the computation
15:23:46 <vincenz> the_lord: and we're not joking this isn't something lihgt "oh the wrong way is just unpreferred"
15:23:48 <the_lord> and all you do is tell me a different solution
15:24:01 <vincenz> the_lord: this is akin to overwriting your stack in the hope that your compiler (gcc) does exactly what you want it to
15:24:04 <Dibrom> the_lord: if you read this: http://www.nomaware.com/monads/html/index.html
15:24:08 <Dibrom> then you will understand the right way
15:24:16 <the_lord> a solution that doesn't work for me
15:24:32 <Dibrom> just go through some of the first few examples
15:24:35 <Dibrom> you will start to understand it
15:24:47 <psnl> the_lord: for IO? can you explain your problem in more depth?
15:24:50 <vincenz> Dibrom: tbh, I personally felt that that site was confusing, I much preferred YAHT
15:25:00 <Cale> Unless you actually understand how GHC works, unsafePerformIO is a terrible idea.
15:25:03 <davidhouse> YAHT isn't much better.
15:25:19 <vincenz> Cale: yeah, it's like overwriting your stack in a c program, in the hope you know the exact layout of a stackframe
15:25:20 <davidhouse> the wikibook, then all about monads, that's the way to go.
15:25:26 <Dibrom> vincenz: ah... well this was the one I really first started understanding monads from.  I guess YMMV :)
15:25:34 <Dibrom> but I liked this tutorial since it went all the way to monad transformers
15:25:40 <Dibrom> which I needed
15:25:47 <Cale> the_lord: what is your program doing?
15:25:58 <Cale> heh
15:26:12 <vincenz> disconnect?
15:26:13 <davidhouse> the wikibook explains well the structure of monads. aam explains well monads as computations, and gives invaluable lessons of each of the major monads
15:26:19 <tennin> parts I and II of the nomaware tutorial I found very clear
15:26:34 <vincenz> Dibrom: my issue with nomaware was that there was a lot of code in the examples, making it more difficult
15:26:42 <davidhouse> the stuff on monad transformers is fine once you realise that they're disgustingly easy.
15:26:48 <Dibrom> really?
15:26:54 <Cale> The only problem with "All About Monads" is the examples... it uses the continuation monad too much.
15:26:54 <Dibrom> I liked that part actually
15:26:57 <tennin> part III was a little murkier due to what I thought were unnecessarily difficult examples
15:26:59 <tennin> cale: exactly
15:27:18 <vincenz> Dibrom: i mean part 2
15:27:20 <the_lord> ok I'm implementing a language definition
15:27:21 <Dibrom> well the continuation stuff is tricky, that's true
15:27:24 <vincenz> and Part 3
15:27:29 <Dibrom> vincenz: oh, I see
15:27:38 <the_lord> so I have to parse it with alex
15:27:46 <the_lord> that returns a [Token]
15:27:59 <the_lord> that I have to pass it through Happy
15:28:05 <vincenz> Dibrom: and for some reason part 1 wasn't enough
15:28:08 <the_lord> and then interpret
15:28:28 <vincenz> so you mean
15:28:30 <vincenz> main =
15:28:31 <Dibrom> vincenz: well I definitely think monads could be explained better than how they are in that tutorial.  It's just the one I saw that sort of worked when I read it
15:28:34 <vincenz>   s <- readFile f
15:28:38 <vincenz>    tokenList <- parse s
15:28:43 <Dibrom> I started writing my own tutorial once, but only got part of the way through
15:28:46 <vincenz>   code <- happy tokenList
15:28:47 <Dibrom> wasn't motivated to finish
15:28:52 <vincenz>   output <- interpret code
15:29:06 * vincenz nods at Dibrom 
15:29:10 <monochrom> You probably mean "tokenList <- alexwhatever s" there.
15:29:38 <vincenz> monochrom: oh right
15:29:38 <vincenz> lex
15:29:40 * vincenz cough
15:29:51 <the_lord> vincenz, yes but I need a function that gets a String and do two things, print and then return a Token
15:30:07 <Cale> the_lord: then it's not a function, but an IO action
15:30:09 <vincenz> function x = do
15:30:11 <vincenz>   print x
15:30:13 <vincenz>   return x
15:30:19 <psnl> gets a String? from IO or as an argument?
15:30:22 <monochrom> the_lord wants the tokenization stage to emit tokenization error messages on-the-fly.
15:30:25 <the_lord> and returns IO a
15:30:33 <vincenz> monochrom: that's not necessary
15:30:35 <the_lord> monochrom remembers
15:30:37 <vincenz> monochrom: alex can happily run into a monad
15:30:42 <vincenz> and then you can use io
15:30:46 <shapr> Sounds like a crash :-)
15:30:55 * shapr accidentally runs into a monad
15:31:03 <vincenz> there's a monadic option for alex
15:31:15 <vincenz> shapr: hehe :)
15:31:16 <Guest15207> return alex?
15:31:25 <xerox> run alex, run!
15:31:29 <shapr> Guest15207: You'll get your money back!
15:31:44 <vincenz> blegh
15:31:45 <the_lord> vincenz, I have to use posn
15:31:46 <vincenz> functions are called
15:31:48 <vincenz> actions are run
15:32:04 <Muad_Dibber> monads actually return money? cool.
15:32:08 <vincenz> the_lord: tell your teacher he's a moron to make lowlevel technical decisions
15:32:20 <vincenz> like that
15:32:54 <the_lord> tomorrow I'll have his solution, and then we'll discuss it here
15:33:00 * vincenz doesn't get it
15:33:04 <vincenz> he gives a highlevel task
15:33:07 <shapr> or maybe just laugh at it?
15:33:08 <vincenz> and then makes lowlevel decisions?
15:33:15 <vincenz> that makes no sense
15:33:18 <shapr> vincenz: Sound like every boss I've had.
15:33:19 <psnl> if you want to hand optimize your code, one normally starts with a lower-level solution, like in C
15:33:27 <vincenz> shapr: yeah but you'd expect more from a professor
15:33:32 <psnl> bet you its ghc -O99 
15:33:35 <shapr> well, true
15:33:44 <Cale> the_lord: is a copy of the assignment online?
15:33:50 <the_lord> in spanish
15:33:53 <Cale> sure
15:33:57 <vincenz> bring it on
15:34:03 <vincenz> the_lord: which university?
15:34:13 <shapr> no habla espanol!
15:34:14 <the_lord> and the thing I want it's not a requirement, it's a challenge
15:34:22 <the_lord> Universidad Simon Bolivar
15:34:26 <vincenz> a
15:34:39 <vincenz> the_lord: use the monadic version of alex
15:34:41 <the_lord> Venezuela
15:34:50 <vincenz> the_lord: you can always use positions in your own alex mnad
15:34:54 <vincenz> that's how I did it
15:34:59 <psnl> the_lord: did he suggest that it was doable?
15:35:05 <vincenz> posn is basically a specific monad
15:35:12 <vincenz> psnl: it's not a requirement
15:35:20 <the_lord> vincenz, nope, I have to use posn
15:35:31 <the_lord> that is in the specification
15:35:35 <vincenz> o.O
15:35:40 <vincenz> the_lord: can I see the assignment
15:35:45 <the_lord> wait
15:35:51 <the_lord> http://www.ldc.usb.ve/~emhn/AbrJul2006/Proyecto/parte1.pdf
15:36:02 <monochrom> The challenge part may be more relaxed.
15:36:07 <psnl> at least a couple of my professors were in for "here is an intractable problem, solve it"
15:36:28 <vincenz> where is the part about the posn
15:36:34 <vincenz> my spanish is too shabby to do diagonal reading 
15:36:50 <shapr> mmmm, fiskpinnar
15:36:52 * vincenz did a search for posn
15:36:54 <vincenz> nothing was mentioned
15:37:47 <vincenz> the_lord: where is the part about posn in that?
15:37:58 <psnl> the_lord: nice to see you use the same MC textbook
15:38:04 <monochrom> Perhaps it's all a dream.
15:38:04 <the_lord> vincenz, that was directly told to us
15:38:09 <vincenz> oh
15:38:17 <monochrom> For the challenge?
15:38:18 <vincenz> hmm
15:38:26 <vincenz> generate posn monad code...take it...modify it
15:38:29 <vincenz> and name it posn'
15:38:44 <the_lord> monochrom, perhaps I'm in the matrix and tomorrow I get out of this twisted world
15:38:54 <the_lord> vincenz, yeah right
15:39:14 <vincenz> the_lord: second option
15:39:19 <vincenz> the_lord: put the position into your token
15:39:23 <vincenz> the_lord: and then do printing after
15:39:37 <vincenz> that's what's typically done
15:39:42 <the_lord> I'll give him two solutions, the right one, and the cheating one with the challenge fulfilled
15:40:09 <the_lord> vincenz, that was my original solution, and monochrom's one
15:40:10 <vincenz> the_lord: are you using happy for parsing/
15:40:19 <the_lord> but that's not on the fly
15:40:21 <monochrom> What is "challenge" in spanish?
15:40:49 <monochrom> And I claim that the_lord is uninformed when he/she says it is not on-the-fly.
15:40:55 <vincenz> he's disco
15:41:00 <vincenz> monochrom: I agree
15:41:03 <vincenz> was just gonna tell him that
15:41:11 <vincenz> that 'on the fly' is very ambiguous in haskell
15:41:13 <vincenz> given lazy consumption
15:41:36 <vincenz> haskell is 'bug' free :D
15:41:43 <monochrom> haha
15:43:02 * shapr steps 'on the fly'
15:43:02 <monochrom> Though I have no business in it, I am also unconvinced that the challenge part specifies posn.
15:43:24 <the_lord> monochrom, the challenge is personal
15:43:26 <vincenz> monochrom: I find that a very odd requirement
15:43:38 <vincenz> the_lord: on the fly is very ambiguous in haskell
15:43:40 * shapr buzzes
15:43:46 <vincenz> the_lord: even if you do it after callinig the lexer, it's still on the fly
15:43:48 <monochrom> I am sure posn is specified for the original assignment.
15:43:49 * dcoutts swats shapr 
15:43:55 <vincenz> cause haskell generates the token list lazily
15:43:56 <the_lord> vincenz, I already discussed that
15:43:59 * shapr make tiny little screams as he crashes and burns
15:44:11 <shapr> I'm obviously bored.
15:44:18 <vincenz> 00:39 < the_lord> but that's not on the fly
15:44:19 <dcoutts> clearly :-)
15:44:32 <the_lord> ask monochrom
15:44:43 <monochrom> ask me what?
15:44:45 <vincenz> the_lord: then why are you still claiming it is
15:44:48 <vincenz> erm
15:44:49 <vincenz> it is not
15:44:52 * dcoutts wonders when dons will get here
15:44:56 <dcoutts> @localtime dons
15:44:58 <lambdabot> Local time for dons is Thu May 18 08:39:46 2006
15:45:07 * dcoutts has patches & questions for dons 
15:45:19 * shapr has nicotine patches...
15:45:27 <shapr> Actually, I gave up smoking many years ago.
15:46:13 <dcoutts> and took up unicycling instead!
15:46:17 <shapr> yeah!
15:46:43 <monochrom> ok I know what you're asking me.  here it is.  No, the_lord did not discuss or argue why in his professional opinion the thing will not be on the fly.  instead, he just made the claim, and when pressed, explicitly stated "I won't argue with you".  So much for "I already discussed that".
15:46:52 * dcoutts did his shopping today with the aid of his unicycle
15:47:38 <xerox> What's your opinion on ACM and alikes?
15:47:54 <shapr> I like to shop with unicycle. It requires a backpack that tightens imho.
15:48:06 <shapr> The load has to stay balanced. Shifting around sucks.
15:48:36 <monochrom> As long as I don't have to code, I like ACM and alikes. :)
15:49:08 <xerox> monochrom - do you think the fees are justified?
15:49:45 <dcoutts> shapr, I use a backpack and I can carry two other bags, one each side
15:50:25 <xerox> I don't understand why many authors publish under such organizations, giving up on copyright.  I mean, what do they earn in exchange, in this internet age?
15:50:37 <davidhouse> woah, the paper i'm reading is talking about least fixed points of type constructors.
15:50:43 <monochrom> Oh, joining the ACM. (I thought the programming contest.)  The student fee for ACM is perfectly reasonable for the benefit of its digital library.  The fee for IEEE or IEEE-CS is way too high for the benefit of its digital library.
15:51:33 <monochrom> I only know student fees
15:51:54 <davidhouse> shapr, is it easy to actually _go_ places on a unicycle? rather than just stay in roughly the same spot?
15:51:57 <edwinb> Getting something in an ACM publication makes it more likely to be read than just sticking it on your website...
15:52:23 <vincenz> does anyone know how to get metadata out of a pdf
15:52:36 <shapr> davidhouse: Yeah, staying in one place is hard.
15:52:43 <vincenz> monochrom: IEEE fee is 12.5 euro
15:52:46 <xerox> edwinb: you read more paying or free things?
15:52:57 <monochrom> interesting
15:53:05 <vincenz> student that is
15:53:12 <vincenz> which is valid even for grad students
15:53:16 <davidhouse> vincenz: per what unit of time?
15:53:19 <vincenz> year
15:53:20 <monochrom> IEEE-CS is way too high (student fee, like US$50)
15:53:27 <edwinb> I read more peer reviewed things.
15:53:39 <xerox> monochrom: isn't $50/year for ACM?
15:53:46 <vincenz> monochrom: there's a separate IEEE-CS???
15:53:58 <vincenz> edwinb: what do you do?
15:54:00 <edwinb> Also, I read more articles that the authors also publish free.
15:54:03 <monochrom> Nah, thirty-something
15:54:06 <vincenz> and on the note of papers
15:54:18 <vincenz> anyone know how to extract metadata from PDFS?
15:54:22 <xerox> Well, 'nighto.
15:54:25 <edwinb> vincenz: CS research
15:54:30 <vincenz> edwinb: what kind
15:54:30 <monochrom> But anyway IEEE has little functional programming, whereas ACM has POPL at least :)
15:54:46 <vincenz> monochrom: true, but ten my research domain falls more into IEEE
15:54:52 <vincenz> s/ten/then
15:54:54 <edwinb> AFAIK, authors can still put articles on the web even after ACM publication.
15:54:56 <edwinb> Certainly many do.
15:55:00 <monochrom> oh wait, POPL is ACM and IEEE joint, ...
15:55:08 <vincenz> monochrom: most good ones are joint
15:55:17 <monochrom> Ha, interesting.
15:55:27 <monochrom> Anyway, theoretically you could write a pdf parser... XD
15:55:30 <vincenz> even in IEEE field
15:55:36 <vincenz> monochrom: yeah but... when you write latex
15:55:40 <vincenz> you have \begin{abstract}
15:55:42 <vincenz> and \title..
15:55:43 <vincenz> and \date
15:55:44 <vincenz> \author
15:55:48 <vincenz> why can't put this crap in metadat
15:55:52 <shapr> yeah, I agree
15:55:56 * vincenz has a huge library
15:56:00 <shapr> It'd make FLM easier.
15:56:19 <vincenz> I want to get my library more organized
15:56:39 <vincenz> but without metadata, writing a tool for that is gonna require serious data inputting
15:57:00 <davidhouse> dude, regexes.
15:57:06 <davidhouse> unless you mean starting from the binary pdf.
15:57:08 <vincenz> not good enough
15:57:20 <vincenz> and yes, I don't have the latex source of stuff not written by me
15:57:26 <shapr> Right, that's my problem.
15:57:36 <shapr> How to go from PDF & PS to metadata?
15:57:57 <vincenz> a good tool would allow partitioning stuff by the listed keywords, grepping on abstract only, creating a citation graph
15:58:03 <davidhouse> people should just distribute .texs and then PDF viewers should convert them to pdfs on the fly.
15:58:08 <shapr> yup
15:58:12 <edwinb> It'd be nice if more authors provided bibtex really.
15:58:46 <vincenz> even bibtex isn't sufficient
15:58:53 <vincenz> most bibtex's don't include keywords
15:59:01 <edwinb> Most PDFs don't...
15:59:13 <vincenz> plus it would be nice to grep on content
15:59:15 <edwinb> The trouble with provided .tex is that there could be lots of source files.
15:59:25 <vincenz> yep
15:59:28 <vincenz> as well as images
15:59:32 <shapr> Metadata as text would be enough.
15:59:34 <edwinb> and obscure packages
15:59:40 <vincenz> and sty's
16:00:12 <shapr> I'd rather have something like lhs2TeX where you get any executable source code and metadata as text.
16:00:38 <vincenz> PDF -> MetaData
16:00:52 <vincenz> or possibly
16:00:56 <vincenz> PDf -> Maybe MetaData
16:00:58 <vincenz> for those scanned pdfs
16:01:02 <shapr> For example, wtf can't we get proof assistant source for proofs done for a paper?
16:01:18 <edwinb> Because authors are scared of providing them ;)
16:01:20 <shapr> Why isn't there a Comprehensive Proof Archive Network?
16:01:21 <vincenz> shapr: I read on lambda-the-ultimate they had something for that
16:01:23 <ndm> shapr, because proofs in a paper are sometimes wrong
16:01:36 <shapr> ndm: And Science is dedicated to covering up that sort of thing?
16:01:37 <edwinb> and they're often done by hand rather than in a theorem prover
16:01:48 * vincenz points to his statement
16:01:53 <ndm> shapr, when an undergrad, i submitted proofs i knew to be wrong
16:01:56 <ndm> its part of life...
16:01:59 <shapr> yow
16:02:09 <vincenz> ndm: testing the review process?
16:02:15 <shapr> I dunno, I'd lose jobs if I did that.
16:02:25 <ndm> vincenz: i was pretty certain they'd pass undetected, or i wouldn't have done it
16:02:30 * edwinb makes a note of that in case he ever reviews an ndm paper...
16:02:45 <ndm> edwinb: my proofs now are 100% safe
16:02:46 <vincenz> edwinb: so what kind of cs research
16:02:50 <edwinb> good, good.
16:02:51 <vincenz> kinda broad, given how I do i too
16:03:01 <edwinb> vincenz: Dependent types, meta programming, resource bounded programming.
16:03:05 <vincenz> ndm: 100% safe, understandable and fundamentally wrong/
16:03:07 <ndm> althought my last paper contained none, and some of the axioms were wrong...
16:03:27 <davidmccabe> So, I added an extra argument to the list of arguments of a function, and haskell doesn't seem to be acknowledging it. It complains that I apply the function to too many arguments now.
16:03:37 <davidmccabe> Any ideas what might be causing that?
16:03:46 <ndm> shapr, but how do you formalise every type of proof? thats an interesting challenge
16:03:46 <vincenz> davidmccabe: not without a paste of code
16:03:47 <vincenz> @paste
16:03:47 <lambdabot> http://www.haskell.org/hawiki/HaskellIrcPastePage
16:03:53 <ndm> @where paste
16:03:53 <lambdabot> http://paste.lisp.org/new/haskell
16:03:58 <ndm> that paste is easier to use
16:03:59 <davidmccabe> ok. one second.
16:04:01 <davidhouse> use the latter.
16:04:03 <vincenz> ndm: again, lambda-the-iltimate has something for that
16:04:08 <vincenz> ndm: yeah, tho I prefer rafb.net
16:04:20 <shapr> ndm: I'm just talking about Coq, NuPRL, etc
16:04:22 <ndm> vincenz: a system for formalising every type of proof?
16:04:25 <vincenz> no
16:04:37 <vincenz> a system for more generic proofs tan the very itty nitty ones required by coq and suc
16:04:42 <vincenz> and a nearly automated process to go to the nitty ones
16:04:51 <ndm> i have my own system for generating haskell proofs
16:05:02 <ndm> and rules for automatic generation
16:05:05 <vincenz> http://lambda-the-ultimate.org/node/1465
16:05:11 <ndm> which is why i'm quite interested in this stuff :)
16:05:21 <vincenz> ndm: gpl'd?
16:05:35 <ndm> vincenz: no, just available and license not yet decided
16:05:40 <vincenz> link?
16:05:42 <ndm> probably GPL though in the end
16:05:45 <ndm> @where catch
16:05:45 <lambdabot> http://www.cs.york.ac.uk/~ndm/projects/catch.php
16:06:13 <ndm> the code is available, but wrong (as of this morning), and incomplete (as of forever), so I don't recommend anyone tries the code bit
16:06:23 <shapr> whoa, mathlang looks way cool
16:06:32 <ndm> but http://www.cs.york.ac.uk/fp/darcs/catch/ if anyone does care
16:07:05 <ndm> mathlang is timing out for me :(
16:07:35 <davidmccabe> oh, I bet I know what my problem is. one second.
16:07:36 <shapr> me too
16:08:09 <shapr> I'd like to have a firefox plugin that retries every half hour until it gets a copy of that thing.
16:08:16 <ndm> http://216.239.59.104/search?q=cache:WbF9tuBnYPAJ:www.macs.hw.ac.uk/~paulvt/mathlang/+&hl=en&lr=&strip=1
16:08:22 <ndm> thats the google cache
16:08:52 <davidmccabe> aha!
16:08:57 <shapr> neat
16:09:26 <davidmccabe> Haskell ascertains the argument list from, I guess, the first time I call the function. Since that one hadn't been updated to the new number of arguments yet, instead of saying it had too few, it said everything else had too many.
16:09:32 <davidmccabe> Despite the new function definition. How strange.
16:10:03 <tennin> will the Pierce book clue me in about rank-n impredicative types and all that?
16:10:23 <ndm> davidmccabe: often different haskell compilers check types in different orders, so some will go one way round, others another way round
16:10:44 <ndm> for example, Hugs always decides the last equation is valid, and the ones before are wrong
16:11:02 <davidmccabe> Hmmm. It seems odd to me that the function definition is not definitive wheni in comes to number of arguments. But, ok.
16:11:05 <monochrom> davidmccabe: in the presence of higher-order functions, it is a subjective matter whether one place is too many or the other place is too few.
16:11:09 <davidmccabe> Haskell has done weirder things to me :)
16:11:23 <shapr> tennin: impredicative just means being able to instantiate polymorphic types, I think.
16:11:30 <davidmccabe> monochrom: ah, this probably has to do with currying?
16:11:37 <monochrom> Yes absolutely.
16:11:43 <davidmccabe> Makes sense, come to think of it.
16:11:50 <edwinb> The function could return a function. Adding a type signature could help.
16:12:17 <davidmccabe> I'll add one, then.
16:12:17 <shapr> tennin: iirc, you can have polymorphic types, but only monomorphic values.
16:12:34 <vincenz> yep
16:12:55 <vincenz> dynamic languages polymorph on values, static languages on types
16:13:04 <shapr> tennin: Anyway, TaPL has all sorts of nifty stuff.
16:13:07 <shapr> It's great fun.
16:13:20 <shapr> It's just flat out amazing :-)
16:13:22 <vincenz> typeclasses are like object classes but raised by one level :)
16:13:29 <monochrom> heh
16:13:43 <vincenz> maybe some day we'll have kindclasses
16:13:58 * edwinb decides that is a scary thought
16:14:10 * ndm agrees with edwinb
16:14:32 <vincenz> be cool if someone could completely parallellize the thoughts about typeclasses and object classes
16:14:51 <shapr> It's amusing to have discussions like this in #haskell while #drupal talks about user friendly PHP front ends to CVS.
16:15:14 <vincenz> shapr: while ##C++ is mostly about trolling
16:15:20 <shapr> heh
16:16:20 <davidmccabe> Sorry for the silly questions, but how do I convert a Graphic into an IO Graphic?
16:16:29 <Cale> davidmccabe: return
16:16:29 <ndm> davidmccabe: return
16:16:33 <davidmccabe> ohh, yes. thanks.
16:16:36 <ndm> @hoogle return
16:16:36 <lambdabot> Prelude.return :: Monad m => a -> m a
16:16:36 <lambdabot> Control.Arrow.returnA :: Arrow a => a b b
16:16:36 <lambdabot> Language.Haskell.TH.Syntax.returnQ :: a -> Q a
16:16:40 <davidmccabe> I knew it was something like that :)
16:16:48 <davidmccabe> but monad things are still hard to keep track of here.
16:17:59 * vincenz is off to sleep
16:21:33 <ndm> shapr, I emailed Martin Sjgren about his thesis, but never got any response :(
16:21:48 <shapr> I have a copy around here somewhere...
16:21:55 <ndm> in digital form?
16:22:08 <shapr> yup
16:22:22 <ndm> oh, would be grateful if you could send it over :)
16:22:27 <Muad_Dibber> send it to ndm!
16:22:38 <shapr> Somewhere in my 400mb of Haskell papers & source code.
16:22:57 <ndm> just put all your code and papers on haskell.org, a community service :)
16:23:05 <shapr> Er, I can't
16:23:31 <shapr> I have a significant number of unpublished, never-to-be-published, confidential, and other sort of papers and source code.
16:23:38 <ndm> thats a shame
16:23:56 <shapr> All acquired through personal correspondence of course.
16:24:16 <ndm> if its interesting, then i would say that takes precedence, but obviously thats something for the individual author to decide...
16:24:24 <shapr> I do wish I'd kept the two collections separate.
16:24:51 <shapr> There's an amazing amount of interesting unpublished work out there.
16:25:20 <ndm> i know, its amazing how much there is just sitting around my office
16:25:28 <shapr> Where someone just got interested and pursued a thought or idea, and came up with totally new stuff.
16:27:51 <shapr> ndm: if I can find it, I'll send it to you.
16:28:16 <ndm> shapr, cheers, i have a friend going to chalmers soon, so if you can't, i'll get my friend to track down the guy in person...
16:28:42 <ndm> i hope the haskell wiki will become a repo of all good haskell papers and stuff
16:28:54 <ndm> dons seems to be making progress towards that
16:29:04 <shapr> I'd rather finish Fermat's Last Margin...
16:29:17 <ndm> but until then...
16:29:31 <ndm> how long til fermats last margin?
16:29:47 <shapr> Well, it's been nearly done for more than a year
16:29:55 <shapr> Just needs some darcs integration
16:30:04 <shapr> I got distracted...
16:30:36 <ndm> yeah, i know the feeling
16:30:45 <ndm> hoogle is now 2 years old, and has never been released...
16:30:53 <ndm> despite hitting version 3
16:30:53 <Muad_Dibber> I want some bot
16:31:00 <Muad_Dibber> which helps me in finding out what the topic is about
16:31:08 <Muad_Dibber> Fermat's Last Margin??
16:31:35 <shapr> I like to write in the margin of my papers.
16:31:38 <ndm> Muad_Dibber: wikipedia?
16:31:39 <shapr> And in my books
16:31:50 <shapr> I write questions, answers, ideas, thoughts, connections, everything
16:32:05 <shapr> Books & papers are a continuing conversation to me.
16:32:20 <shapr> But I can't grep those margins, nor can I share them with more than one other person at a time.
16:32:48 <shapr> Fermat had a greater problem, he came up with a cool proof, and could not fit it into the margin of the book.
16:33:07 <shapr> So I figured I'd write software that would be the last margin Fermat would ever have needed.
16:33:24 <JKnecht> the link of the same name on the top ranking google page is broken
16:33:27 * dcoutts darcs sends patches to dons and heads for bed
16:33:55 <JKnecht> (i.e. Fermat's Last Margin/Comonads)
16:34:11 * ndm sends some patches to ndm and heads for bed
16:34:17 <shapr> The FLM idea is simple, convert the document pages to images, stuff them into a wiki page, and save the wiki page text into a darcs repo.
16:34:43 <Muad_Dibber> ah
16:34:46 <JKnecht> that's a comonad?
16:34:56 <shapr> Then other people can write their own text in the margins and we can all share it.
16:35:05 <shapr> It'd solve the bibtex problem as well.
16:35:33 <JKnecht> comonad = collaborative monad?
16:36:15 <shapr> What's the top ranking google page for fermat's last margin?
16:36:31 * shapr finds http://www.scannedinavian.com/~shae/blog/2004-12-01.html
16:37:19 <JKnecht> right, it's .../AnnotationMockup that is b0rken.
16:37:34 <shapr> Yeah, that server hasn't come back from the ISP :-|
16:37:55 <shapr> I wish he'd give me back my server.
16:38:14 <Muad_Dibber> hmm.
16:38:17 <Muad_Dibber> anyway, night all
16:39:03 <shapr> Anyway, the code for turning pdf & ps into page images has been working fine for months.
16:39:18 <shapr> and automatically generating wiki pages for documents, etc
16:39:43 <shapr> I modified Philippa's Flippi wiki (written in Haskell)
16:40:38 <shapr> I just never finished the darcs annotation saving code.
16:40:46 * JKnecht locates the wiki comonad page.
16:52:22 * shapr gets C-M-S-H-Sh-f13 not defined.
16:53:02 <shapr> And it only requires two fingers to press that key combination.
16:54:47 <syntaxfree> ohhh grrrrr @ JMKeynes
16:56:01 <syntaxfree> can  I suggest an insane feature for lambdabot?
17:11:24 <shapr> syntaxfree: suggest away
17:35:18 <davidmccabe> My first semi-real haskell program:
17:35:25 <davidmccabe> http://dmccabe.org/WireWorld.lhs
17:35:31 <davidmccabe> (also my first literate program)
17:35:35 <davidmccabe> comments would be most welcome :)
17:37:03 <davidmccabe> uhhhhh, Version 2.0 is now at the same location ;)
17:38:31 <ihope> Ah, WireWorld!
17:40:46 <davidmccabe> You are familiar with it?
17:41:30 <davidmccabe> Once again, updated version available.
17:41:36 <Cale> needs a way to blacken cells
17:41:48 <davidmccabe> (these are all documentation fixes; I added the documentation just now, and emacs is being screwy on me)
17:42:26 <ihope> Just a second...
17:42:32 <davidmccabe> Cale: you're right. unfortunately, HGL only lets you see two mouse buttons, and I don't really want to get into discriminating between key presses this afternoon.
17:43:28 <davidmccabe> brb.
18:08:07 <ihope> Screenful of junk, screenful of junk...
18:08:32 <davidmccabe> back.
18:12:46 <Spark> neurogeek == b&
18:15:03 <davidmccabe> When I run my program from ghci, it works. But when I try to compile it with ghc, it gives a bunch of errors like this one:
18:15:18 <davidmccabe>  undefined reference to `GraphicsziHGLziInternalsziTypes_RGB_con_info'
18:15:22 <davidmccabe> any ideas? thanks!
18:15:34 <davidmccabe> (google doesn't know about this error, and the man page isn't enlightening either)
18:15:35 <stepcut> did you use --make ?
18:15:55 <davidmccabe> thank you.
18:18:31 <ihope> neurogeek must have a pretty good connection.
18:21:33 <dons> dcoutts: regarding the benchmarks, i'm pretty certain its the garbage collector changing things.
18:24:31 <davidmccabe> oh dear, oh dear.
18:24:41 <davidmccabe> it behaves differently when compiled than when run interactively. 
18:25:09 <davidmccabe> does anybody else experience this? When compiled, it pauses about a second into execution until an event is received.
18:26:48 <davidmccabe> no wait
18:27:21 <dons> there are differences, usually due to timing of various runtime system events. also, interactive is unoptimized
18:27:25 <davidmccabe> it doesn't do anything unless it receives events... and this is even before it starts listening for events! and only when compiled!
18:27:46 <davidmccabe> lemme try turning of optimization and see if that fixes it, then.
18:28:45 <davidmccabe> ok, it isn't that.
18:31:02 <davidmccabe> http://dmccabe.org/WireWorld.lhs
18:31:07 <davidmccabe> does it do that to anybody else?
18:34:39 <Cale> It works fine for me when compiled
18:34:47 <Cale> ghc -O --make WireWorld.lhs -o wire
18:35:13 <davidmccabe> ok, thanks for that datum. Any pointers how to get to the bottom of this? I don't know where to start.
18:40:01 <Cale> It pauses?
18:40:25 <davidmccabe> It doesn't do anything unless the mouse is moving over its window.
18:40:38 <Cale> what platform are you running it on?
18:40:41 <davidmccabe> This is before it even starts asking GHL for events.
18:40:43 <davidmccabe> X11.
18:40:48 <Cale> hmm
18:40:56 <Cale> Yeah, I am too
18:41:15 <davidmccabe> GHC 6.4.
18:41:18 <Cale> well, what it does for me, is when it's started, it draws a grid
18:41:31 <Cale> is it supposed to do more?
18:41:39 <davidmccabe> no, that's all it's supposed to do.
18:41:57 <Cale> I'm using GHC 6.4.1
18:42:28 <davidmccabe> me too.
18:42:41 <davidmccabe> what it does is, it draws the first few cells of the grid and then stops.
18:42:48 <Cale> odd
18:42:54 <davidmccabe> if you move the mouse into its window, it starts again... until the mouse stops moving.
18:43:00 <hyrax42_> haxml, hxt or other
18:43:13 <davidmccabe> when it finishes drawing the grid, it should start listening for mouse and keyboard events.
18:43:33 <davidmccabe> it responds to the keyboard events, *but the window is only redrawn after the mouse moves across it*
18:43:41 <davidmccabe> the events are appearently queued up until then.
18:43:48 <davidmccabe> again, it works as expected when run from ghci.
18:46:01 <Cale> that sounds rather like the problem that people get with HGL under Win32
18:46:36 <Cale> I wonder if the Gtk2Hs variant of HGL would work better for you. I think someone wrote one, anyway
18:47:16 <Cale> oh, it was an SOE port
18:47:55 <Cale> http://haskell.org/~duncan/soe/Graphics/SOE/Gtk.hs
18:49:11 <Cale> probably not quite compatible
18:53:47 <davidmccabe> My computer crashed.
18:54:01 <davidmccabe> Cale: last I heard was that it had to do with SOE. were you saying anything else?
18:58:06 <Cale> oh, I gave a link to the library, and mentoned that it was probably not quite compatible with HGL
18:58:35 <Cale> but other than that, I'm not sure what's wrong -- at least, it works fine for me here
19:19:17 <davidmccabe> well, it works on somebody else's system, too, and he's on the same distro as me.
19:48:27 <dons> ?karma+ hugs -spotted a bug for me
19:48:27 <lambdabot> hugs's karma raised to 1.
19:49:05 <davidmccabe> http://dmccabe.org/foo.html
19:49:06 <davidmccabe> screencast.
19:49:26 <Lemmih> dons: How many slots did we get?
19:49:29 <Lemmih> (for SoC)
19:49:30 <davidmccabe> the curser is all jumpy and it doesn't show keypresses, so it's a little hard to see what's going on. but still, I guess that may shed some light for those who have any idea what the problem could be.
19:49:34 <dons> haven't heard yet Lemmih.
19:50:16 <dons> possibly they contacted SyntaxNinja, or maybe they're just not done yet.
19:50:47 <thelsdj> ?karma hugs
19:50:47 <lambdabot> hugs has a karma of 1
19:51:05 <thelsdj> ?karma ghc
19:51:06 <lambdabot> ghc has a karma of 0
19:51:23 <dons> ?karma QuickCheck
19:51:23 <lambdabot> QuickCheck has a karma of 7
19:51:37 <Lemmih> @karma dons 
19:51:38 <lambdabot> dons has a karma of 35
19:53:02 <Lemmih> Who's on second and third place?
19:53:22 <dons> we need @karma-rank or something
19:53:33 * dons hacks it up
20:09:05 <syntaxfree> is "type Bundle = [Num a]" correct?
20:09:22 <Lemmih> No.
20:09:47 <syntaxfree> type Bundle = (Num a)=>[a]?
20:10:10 <Lemmih> Nope.
20:10:36 <syntaxfree> It can't be a typeclass?
20:10:41 <syntaxfree> Or you just mean my syntax is wrong?
20:11:00 <syntaxfree> type Bundle = [Double] would be ok?
20:11:15 <dons> you could have, data Bundle = forall a . Num a => Bundle [a], but probably that's not what you're looking for.
20:11:28 <akemp> I've got a "last statement in 'do' construct must be an expression" error that I *cannot* find and fix!
20:11:43 <akemp> Anyone got any magic suggestions?
20:11:43 <dons> akemp: check the indenting around that line?
20:12:33 <akemp> dons: looks kosher...
20:12:41 <syntaxfree> can I define infix functions just by saying "(>>) = and . map (>=)"?
20:14:25 <akemp> argh!  This is driving me batty
20:15:57 <mauke> akemp: what's the line with the error?
20:17:56 <lisppaste2> akemp pasted "do construct problem" at http://paste.lisp.org/display/20137
20:18:54 <akemp> mauke: check out the paste.  I'm not sure if the line numbers reported by GHC are perfect, but it looks to be at "as <-..."
20:20:11 <mauke> unbalanced parentheses
20:21:35 <thelsdj> ah yep, one too many on the end?
20:21:41 <akemp> Thanks.  I've been looking at this screen too long to see something so obvious!  Frustrating.
20:22:57 <mauke> ?karma+ vim7
20:23:58 <akemp> ;)
20:24:28 <lambdabot> vim7's karma raised to 1.
20:25:15 <akemp> Right then.  All's fixed.  Thanks y'all.
20:25:55 <thelsdj> hrm my vim7 doesn't catch it by default
20:26:02 <akemp> Incidentally, how do you get vim to check parens?  (:set sm!)
20:28:49 <mauke> the matchparen plugin highlights paren pairs when the cursor is over them
21:06:49 <davidmccabe> So, concerning the bizarre HGL problems, should I probably escalate to the GHC mailing list at this point?
21:35:43 <Cale> haha, this paper defines the term ``\{0,+,\sum_{i \in \N},1,\cross,\prod_{i \in \N},\to\}-like''
21:36:02 <Bobstopper> Anyone have .debs for gtk2hs? the "carwash" server where they're meant to be seems to be down.
21:42:22 <davidmccabe> Cale: ...
22:02:14 <sjanssen> it'd be nice if Haskell could export functions to certain 'trusted' modules, but not to others
22:03:46 <sjanssen> @hoogle CSize
22:03:46 <lambdabot> Foreign.C.Types.CSize :: data CSize
22:10:20 <sjanssen> dons: I'm going to write a counting sort for .Lazy, suppose I need to keep my counters as 64 bit values?
22:11:26 <dons> yeah, I reckon. Though we're a bit sloppy with the use of Int64 around that code (i.e some of the fooIndex functions don't use  Int64)
22:15:15 <sjanssen> too bad I can't access memset from Lazy
22:15:43 * sjanssen wishes for internal exports again
22:18:26 <dons> sjanssen:  yeah :(
22:18:38 <dons> we really need a .Internal module
22:18:43 <dons> like the Arrays library has
22:18:50 <dons> and then Data.ByteString is a wrapper over the Internals
22:18:56 <dons> hiding anything not safe
22:21:42 <sjanssen> does Cabal have a concept of hidden packages?
22:32:22 <sjanssen> dons: should unsafeTake be exported?
22:32:30 <Lemmih> sjanssen: Yes, I think so.
22:37:09 <dons> yeah, its just as usable as unsafeHead,unsafeTail. But it should probably be also in an .Internals module. That's something you might want to do if google picks your SoC project.
22:38:56 <sjanssen> if I run Quick.hs, does it test Lazy also?
22:40:05 <dons> nope. use 'gmake' to run both.
22:40:24 <dons> though I've started on Properties.hs to run both, it doesn't do all tests yet.
22:40:42 <dons> the idae is Peroperties.hs tests Lazy==Byte, Byte==List, LAzy==List.
22:41:00 <dons> and it has some nice boilerplate stuff that makes writing tests a bit more methodical
22:41:41 <dons> the default makefile target will run both QC sets interpreted and the compiled with -O. sometimes its possibly to get different results, so its important to check both ways.
22:41:50 <dons> s/and then compiled/
22:43:55 <sjanssen> concatMap takes a ridiculously long time to test over here, is that weird?
22:44:13 <dons> here too. needs looking at.
22:44:30 <dons> also, you might want to install hugs, and test with hugs as well, sometimes. 
22:44:39 <dons> setup.hs configure --hugs w
22:44:50 <dons> and then runhugs Quick.hs, can be useful to spot strange things missed by ghc
22:45:02 <dons> also, runhugs -98 Properties.hs
22:45:40 <dons> i.e. I'd forgotten that 'assert' is turned off by ghc -O, but an aassertion failure was spotted by hugs this morning.
22:46:47 <joelk> Wow, ByteString is awesome! One problem, the wc.hs on the web page gives me "wc: realloc: resource exhausted (out of memory)" on a ~3e6 line file.
22:47:37 <dons> joelk: oh, I think you're using an older version of fps?
22:47:49 <joelk> darcs pulled yesterday
22:48:24 <joelk> or was that on a different machine... hang on a sec
22:48:33 <dons> hmm. doesn't sound right. I don't use realloc any more.
22:50:17 <joelk> hmm. a darcs pull now pulls 10 patches from the 17th and 18th only. So, I was right about pulling on this machine yesterday.
22:50:33 <dons> ok. i'm investigating. you just using wc -l from tests/ ?
22:51:45 <joelk> yes
22:53:33 <joelk> But, I have avery similar program that reads in the lines, filters out a lot of them and then prints the length of the remaining list. It has no problems.
22:53:41 <dons> oh, for big files you should use Lazy.hs by the way, as in:
22:53:50 <dons> $ time ./wc < /home/dons/tmp/tests/256M
22:53:50 <dons> 8753152
22:53:50 <dons> ./wc < /home/dons/tmp/tests/256M  0.97s user 0.47s system 11% cpu 12.535 total
22:53:50 <dons> $ time wc -l /home/dons/tmp/tests/256M 
22:53:50 <dons>  8753152 /home/dons/tmp/tests/256M
22:53:53 <dons> wc -l /home/dons/tmp/tests/256M  0.65s user 0.34s system 8% cpu 12.198 total
22:54:03 <dons> with
22:54:03 <dons> import qualified Data.ByteString.Lazy as L
22:54:03 <dons> main = print . L.count 10 =<< L.getContents
22:55:06 <joelk> what about "print . length . L.Lines =<< L.getContents" ?
22:55:16 <dons> there's no Lazy lines yet.
22:55:19 <joelk> ah
22:56:04 <dons> ah, I get a realloc issue too :)
22:56:09 <dons> $ time ./wc < /home/dons/tmp/tests/256M 
22:56:09 <dons> wc: realloc: resource exhausted (out of memory)
22:56:28 <dons> but since this about the size of memory, not much I can do about it.
22:56:54 <joelk> yeah, I was impressed that it was faster than normal wc until I realized why.
22:57:17 <dons> is the file you're using > half of your ram?
22:57:18 <joelk> But its doesn't even come close to exhausting memory.
22:57:22 <joelk> yes
22:57:43 <joelk> well, close
22:57:54 <joelk> 826M / 2G
22:57:58 <dons> one thing to remember is that normal bytestrings are strict, so it has to suck the whole file into a buffer.
22:58:11 <dons> however, i'd expect 826M to be ok.
22:58:37 <dons> oh, its the getcontents, it needs to do a realloc
22:58:40 <dons> try readFile instead
22:58:48 <joelk> ok
22:59:42 <dons> now, for me, it dies immediately, since I can't get a 256M buffer.
22:59:49 <dons> main = print . length . B.lines =<< B.readFile "/home/dons/tmp/tests/256M"
22:59:55 <dons> but for you, it may just suceed
23:00:17 <joelk> one way to find out.
23:00:33 <dons> of course, once you're above half your ram, its best to use the lazy version of bytestrings, which just allocate a lazy list of cache-sized chunks.
23:00:59 <joelk> aha, that's cool.
23:02:39 <joelk> ok. readFile is good. I'll start using the lazy version though.
23:05:09 <joelk> Ah, but if there's no lazy lines, it's not so useful for me.
23:05:37 <dons> use split on 10
23:06:10 <dons> i.e. split (fromIntegral . ord $ '\n') 
23:06:49 <joelk> thanks
23:07:35 <dons> there's a bit of a performance hit there, since it'll try to refragment the chunks. Not sure if that matters too much to you. I should perhaps add a native Lazy lines.
23:08:44 <dons> you could always use getLine in the strict bytestring to generate a stream of line chunks. that would be even more efficient than split of a lazy bytestring.
23:11:23 <joelk> why is Data.ByteString.Lazy.pack :: [GHC.Word.Word8] -> ByteString and not String -> ByteString?
23:11:32 <dons> this guy:
23:11:32 <dons> getLines :: Handle -> IO [B.ByteString]
23:11:32 <dons> getLines h = unsafeInterleaveIO $ do
23:11:32 <dons>     s  <- hGetLine h
23:11:32 <dons>     ss <- getLines h
23:11:34 <dons>     return (s : ss)
23:12:07 <dons> oh, because String is a [Char]. Chars are 32 bits. its more accurate to use Word8 and provide a wrapper Char layer, that truncates or decodes Char values > 255
23:12:24 <dons> as Data.ByteString.Char8 does for strict bytestrings
23:12:31 <joelk> oh right... 32 bits
23:13:10 <dons> its easy enough to write your own wrapper, and we'll do it eventually. check Char8.hs for the details
23:13:20 <joelk> ok, thanks.
23:16:13 <joelk> darn. my filtering program works for 826M but fails on 1.5G :-) Time to use getLines from above!
23:30:29 <dons> i'll add it to Lazy.hs
23:36:43 <kowey> hey haskellers, could somebody help me with a little profiling, please? http://www.loria.fr/~kow/tmp/
23:37:22 <ADEpt> @seen SyntaxPolice
23:37:22 <lambdabot> I haven't seen SyntaxPolice.
23:37:35 <dons> @seen SyntaxNinja 
23:37:35 <lambdabot> I saw SyntaxNinja leaving #haskell 9 hours, 19 minutes and 19 seconds ago, and .
23:37:37 <dons> you mean.
23:39:02 <thelsdj> whats with the ', and.' at the end there?
23:39:45 <thelsdj> bug i guess
23:39:50 <dons> buglet
23:40:42 <dons> joelk, this runs in constant heap space:
23:40:44 <dons> $ ./a.out < /home/dons/tmp/tests/256M 
23:40:44 <dons> 6283264
23:40:44 <dons> $ cat lazylines.hs
23:40:44 <dons> import qualified Data.ByteString as B
23:40:44 <dons> import System.IO
23:40:47 <dons> main = print . length . filter (\l -> B.length l >= 10) =<< B.hGetLines stdin
23:40:51 <dons> is that roughly what you're looking for?
23:41:18 <ADEpt> dons: probably. You haven't experienced bounces from soc-mentors@s.o lately?
23:41:28 <dons> nope.
23:42:04 <dons> joelk, I've pushed a version of hGetLines into the fps darcs repo now. 
23:42:10 <dons> let me know how it goes.
23:45:58 <dons> hey hey, hGetLines is useful... : 
23:45:59 <dons> $ /usr/bin/time ./lazylines < /home/dons/tmp/tests/256M 
23:45:59 <dons> 8753152
23:45:59 <dons>        11.89 real         4.98 user         0.67 sys
23:46:10 <dons> $ /usr/bin/time wc -l /home/dons/tmp/tests/256M
23:46:10 <dons>  8753152 /home/dons/tmp/tests/256M
23:46:11 <dons>        11.81 real         0.61 user         0.31 sys
23:47:43 <dons> for big files hGetLines is the way to go for the wc -l problem, it seems
23:48:07 <kzm> how does it compare to mmap?
23:48:32 <dons> don't know. interesting question though.
23:48:43 <dons> mmap never gave me too much help
23:49:45 <kzm> wc seems to read sequentially in 16K chunks.
23:50:22 <kzm> unsurprisingly, I might add. :-)
23:50:43 <dons> yeah, so that's why its about the same as our count . getContents, using Lazy chunks of 128k
23:52:23 <thelsdj> is there something like pythons urllib for haskell?
23:53:34 <kzm> about SoC, have we set a number of desired slots yet?  I see Google is asking for that.
23:53:46 <dons> we set it to 35, yes.
23:54:59 <dons> looks like they haven't frozen the number yet though.
23:55:17 <joelk> oh, thanks dons. I'll pull anew.
23:56:11 <joelk> I was writing my own getlines but an't seem to catch the eof IOError...
23:56:24 <dons> just wrap getLine in a catch, no?
23:57:05 <joelk> well, I was using B.getLine, which is the same as B.hGetLine stdin, no?
23:57:19 <joelk> ... and the catch... didn't
23:57:34 <dons> hmm.
23:57:45 <joelk> I must be doing something foolish
23:58:16 <dons> seems to work here.
23:58:32 <dons>                 ms <- catch (hGetLine h >>= return . Just)
23:58:33 <dons>                             (\_ -> return Nothing)
