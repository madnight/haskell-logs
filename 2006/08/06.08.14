00:00:22 <ibid> the appropriate comparison pairs are strict - nonstrict and earger - lazy
00:00:26 <Cale> but it uses sharing, so that things which came from the same parameter won't be recomputed
00:00:43 <Cale> ibid: It's also called strict evaluation
00:00:49 <ibid> the difference being that the first are semantics, the latter are implementation techniques
00:00:59 <satan> i see
00:01:09 <ibid> Cale: yes, but it confuses things to mix the pairs :)
00:01:22 <Cale> point taken :)
00:01:30 <Cale> So let's call it eager evaluation
00:01:46 <Cale> in eager evaluation, you evaluate innermost first
00:01:48 <satan> so lazy evaluates the outermost function first, while strict(non lazy) doesnt? it evaluates inner operands first?
00:01:51 <satan> ah ok
00:02:14 <astrolabe> So what is strict?
00:02:26 <Cale> Most of the programming languages out there use eager evaluation
00:02:30 <ibid> satan: a useful operational intuition for lazy evaluation is that function parameters get evaluated only when used, and the value is remembered if it is used again
00:02:32 <satan> right
00:02:47 <satan> ibid: gotcha, thanks
00:03:03 <ibid> satan: eager evaluation uses the more 'standard' technique of evaluating the argument at the call
00:03:03 <Cale> Of course, you have to be careful about how long exactly things will be remembered :)
00:03:13 <satan> ah ok
00:03:52 <satan> and thats dependent on the compiler, be it ghc or hugs or whatever
00:04:19 <ibid> satan: the formal definition of strictness is (more or less) that if an argument evaluation diverges (ie. either aborts or never terminates), then the whole call diverges
00:04:26 <Cale> Well, Haskell is defined to have nonstrict semantics, so you can't evaluate things eagerly.
00:04:44 <xerox> ``The STG machine has its roots in lazy graph reduction.''
00:04:44 <ibid> Cale: well ...  :)
00:04:48 <xerox> (G'day.)
00:04:52 <Cale> You can do tricky things where you mix innermost and outermost calls
00:04:56 <satan> ah i see
00:05:16 <Cale> Or try to evaluate eagerly for a while, and possibly give up after a time limit
00:05:37 <Cale> But generally, lazy evaluation is how people tend to implement nonstrict semantics.
00:05:49 <astrolabe> Ah.  Thanks
00:06:21 <satan> nonstrict semantics??
00:06:28 <satan> what does that mean? :S
00:06:55 <ibid> Cale: haskell programs can be thought about as if all calls were lazy; but an important optimization performed by haskell compilers try to find as many places where it can 'cheat' by using eager evaluation without changing what the program does
00:07:00 <Cale> Right, there's a distinction here between semantics, that is, the end results you get, and implementation of those.
00:07:01 <ibid> gah, that was meant for satan
00:07:37 <satan> ah i see
00:07:46 <Cale> For example, in Haskell, the expression  let ones = 1 : ones in take 10 ones
00:07:57 <Cale> has to evaluate to [1,1,1,1,1,1,1,1,1,1]
00:08:04 <satan> right
00:08:09 <Cale> and not spin forever
00:08:19 <Cale> but how it gets there is up to the implementation
00:08:21 <satan> this is because it evaluates take 10 first
00:08:38 <Cale> in lazy evaluation, that's what happens
00:08:41 <ibid> satan: nonstrictness means 1) for single function calls that even if a function argument diverges, the function call will not unless it returns that argument and 2) for programming languages that nonstrict function calls are used
00:08:48 <Pseudonym> I love this.  In the history of Haskell paper.
00:08:52 <Cale> in eager evaluation, it would try to evaluate ones first
00:09:06 <satan> so the implementation specific details are the non strict semantics you were talking about, Cale ?
00:09:20 <Pseudonym> In 1989, Eugenio Moggi published [...] a paper on the use of monads [...] which immediately attracted a great deal of attention (Moggi, 1989; Moggi, 1991).
00:09:22 <Cale> ibid: 2) for programming languages that nonstrict function calls are used <-- got cut off here?
00:09:33 <ibid> Cale: nope
00:09:35 <Pseudonym> Eugenio Moggi likes paying attention to his own papers.
00:10:01 <norpan> he sure does
00:10:03 <xerox> haha
00:10:07 <Cale> ibid: Oh, just had trouble parsing that somehow :)
00:10:10 <ibid> satan: nonstrictness is what haskell promises; lazy evaluation is the implementation technique most often used
00:10:36 <ibid> satan: in practice, everyone assumes haskell also promises lazy evaluation even if it really doesn't
00:10:49 <satan> ibid: ah ok, so what are non strict semantics then?
00:10:55 <satan> what are semantics anyway?
00:11:00 <Cale> satan: for example, another evaluation strategy would be to evaluate an innermost thing, then an outermost thing, and back and forth like that
00:11:08 <satan> right ok
00:11:19 <Cale> and that would also work and give nonstrict semantics
00:11:30 <Cale> though it might evaluate lots of stuff you don't need :)
00:11:45 <ibid> satan: semantics is the study of meaning, but in this case semantics refers to "what programs are supposed to do"
00:12:02 <satan> ibid: ah ok, gotcha
00:12:10 <ibid> satan: also see my note above a few minutes ago
00:12:26 <satan> ibid: yep saw it
00:12:47 <satan> cool, all a bit clearer now, thanks guys :)
00:14:17 <ibid> satan: i found when i was newer to haskell that the practical operational intuition of "function arguments are evaluated only when needed, and at most once" is the most useful one at the beginning. it's not quite as precise as one would like, but you'll eventually learn where it breaks :)
00:14:37 <Cale> It's actually possible to see roughly the space performance of Haskell code with lazy evaluation by writing out derivations of how it runs on paper, and keeping in mind what things will be computed together (which you can do by drawing your code as a graph rather than a tree)
00:14:47 <Cale> and looking at the size of the graphs :)
00:14:55 <satan> ah ok
00:15:42 <Cale> because really what the STG machine is doing is manipulating what are essentially graphs
00:15:56 <satan> ok
00:16:32 <ibid> yes, it is also useful to familiarise oneself with basic graph reduction :)
00:17:02 <ibid> (which is why i drilled my students on it a year ago the last time i taught fp :)
00:17:41 <Cale> One way to implement things which isn't exactly how STG does it, but is easier to explain is that every variable is a combination of a pointer and a boolean flag. If the flag is unset, then the pointer points to code, and if it is set, then the pointer points to the final value. When the value of the variable is demanded, the flag is tested,
00:17:46 <dons> 1st birthday issue of HWN out now http://sequence.complete.org/hwn/20060814
00:18:13 <satan> cool
00:18:14 <kosmikus> congratulations, dons
00:18:15 <Cale> and if the flag is unset, the code runs, and the pointer is updated to point at the value the code builds, and the computed value is returned
00:18:30 <Cale> if the flag is set, then the pointer is looked up, and that value is returned immediately
00:18:52 <Cale> STG does away with the tag (that's why it's tagless)
00:19:00 <ibid> (the way STG does this is rather clever:)
00:19:12 <dons> kosmikus: congrats on the HW lineup, btw. looks good!
00:19:49 * ibid is writing a vm-compiler for a lazy language using the STG model. i had a lot of fun when i realized how STG works here :)
00:20:15 <Cale> oh, forgot to mention that of course, the flag gets set when the pointer is updated to point at the computed value :)
00:20:25 <ibid> originally i assumed that the "tagless" refers to gc tags, which it sort of does too
00:20:40 <kosmikus> dons: thanks to the authors :)
00:21:00 <dons> yes, that too :)
00:21:30 <kosmikus> will you be there?
00:21:54 <Cale> satan: It's an amazingly cool thing that one can write decent Haskell programs without being completely aware of how it all works :)
00:22:20 <Cale> satan: (though it certainly helps if you run into performance problems)
00:22:48 <dons> kosmikus: I don't think so :/ My international travel money is running out. Must write more papers!
00:22:49 <satan> true, that certainly works for me heh
00:23:48 <kosmikus> dons: oh, that's sad, but I can understand that. I'm short on travel money all the time.
00:23:55 <kosmikus> dons: no hackathon either then ...
00:24:05 <dons> :( I hope to hack on GHC at that time anyway, though
00:24:09 <dons> get the stream fusion stuff in
00:25:05 <norpan> you are mean, now i must read that stg article
00:25:10 <norpan> i have to work you know
00:26:40 <ibid> norpan: be sure to read the newer one:)
00:27:02 <norpan> version 2.5
00:27:48 <ibid> i mean, not the conference version
00:28:05 <ibid> if it says it's a rewrite of the conference version, it's probably fine
00:28:32 * ibid hasn't been able to find the JFP version, my university doesn't subscribe to JFP :)
00:29:11 <Cale> the one on CiteSeer says that it's to appear in JFP
00:29:19 <norpan> that's the one i read
00:29:29 <ibid> that's the one i've read
00:29:36 <Cale> I could probably get the JFP one by using my friend's library account :)
00:29:53 <ibid> but i prefer to read publisher's versions when i can
00:33:25 <ibid> reading the RTS document afterward will also be a good idea
00:33:43 <ibid> dunno how much out of date it is, but probably less than the STG paper :)
00:45:01 <MarcWeber> I'm trying to unnderstand the paper (PDF) abouut Implicit Configurations which can be found here: http://okmij.org/ftp/Haskell/types.html#Prepose. There is one type definition used I can't cope with (page 4):
00:45:02 <lambdabot> Title: Haskell Programming: Types
00:45:07 <MarcWeber> newtype Modulus s a = Modulus a
00:45:07 <MarcWeber> data AnyModulus = forall a. AnyModulus (Modulus s a)
00:45:24 <Pseudonym> That's a trick.
00:45:33 <MarcWeber> GHC is complaining about s which isn't defined.
00:45:45 <Pseudonym> Errr...
00:45:51 <Pseudonym> I think that should be forall s.
00:46:10 <MarcWeber> Oh I did make a typo
00:46:25 <MarcWeber> data AnyModulus a =  forall...
00:46:32 <Pseudonym> Right.
00:46:38 <Pseudonym> And forall s.
00:51:00 <MarcWeber> I still don't understand why it doesn't have to data AnyModulus s a = .. ? Time will tell. Now I can try the examples given in the paper.
00:57:05 <satan> does anyone know category theory well here?
00:58:17 <satan> Prove that in a category with products, and for any two objects A and B in that category, A x B is isomorphic to B x A
00:59:09 <satan> more questions found online :P
01:00:37 <Cale> Well, BxA is also a product of AxB.
01:00:55 <sieni> the isomorphism is given by swapping the associated projections?
01:01:00 <Cale> So it comes down to showing that if P and Q are both products of A and B, then they are isomorphic.
01:01:06 <satan> ok...
01:01:24 <Cale> yeah, by swapping the projections
01:01:47 <satan> so how would i go about doing that? by drawing one of those diagrams?
01:02:27 <Cale> Yeah, you know how you have that universal property?
01:02:40 <Cale> for both P and Q, you can construct that unique arrow, right?
01:02:48 <satan> the dashed one with the !
01:02:54 <Cale> mhm
01:03:02 <satan> -------!
01:03:08 <satan> ok
01:03:20 <Cale> okay, let's give things some names :)
01:03:33 <satan> ok heh
01:03:39 <Cale> A <-- pi_1 -- P -- pi_2 --> B
01:03:49 <Cale> A <-- lambda_1 -- Q -- lambda_2 --> B
01:04:17 <satan> ok with you so far
01:04:19 <Cale> okay
01:04:21 <satan> btw
01:04:27 <satan> those dashed arrow or regular?
01:04:30 <satan> arrows*
01:04:31 <Cale> regular
01:04:33 <satan> ok
01:04:40 <Cale> those are the projections
01:04:44 <Cale> now
01:04:44 <satan> right
01:05:25 <Cale> You know that for any X and any f_1: X -> A, f_2: X -> B, there's a unique arrow X -> P making the product diagram commute.
01:05:42 <Cale> Take X = Q, f_1 = lambda_1, f_2 = lambda_2
01:05:57 <satan> right, i have a q about that too
01:06:15 <satan> what does making the diagram commute mean? why do we need to make it commute?
01:06:28 <Cale> Okay, someone should have told you that right off :)
01:06:51 <satan> heh yeah i guess
01:07:08 <Cale> A diagram commutes when the composition of every path of arrows through it which start and end at the same nodes are equal.
01:07:20 <satan> ok got it
01:07:52 <satan> ok, so back to what you said above that
01:08:06 <satan> for any X and any f_1....
01:08:25 <Cale> So just to be clear, in this case, if we call our uniquely constructed function F, then pi_1 . F = f_1, and pi_2 . F = f_2
01:08:50 <satan> ok
01:09:02 <Cale> That's what the diagram is encoding :)
01:09:16 <satan> so how would i draw it then?
01:09:25 <satan> with the A <-- pi_1 -- P -- pi_2 --> B at the bottom
01:09:29 <Cale> yeah
01:09:30 <satan> X at the top, say
01:09:40 <satan> unique arrow straight down to P
01:09:45 <Cale> right
01:09:53 <satan> and f_1 from X to A
01:09:58 <Cale> right
01:09:59 <satan> and f_2 from X to B
01:10:13 <Cale> mhm
01:10:18 <satan> that way, f_1 = F.pi_1
01:10:29 <satan> i mean, pi_1.F
01:10:46 <satan> ok then what about Q?
01:11:10 <satan> do the same for that and say, since they come to mean the same thing, they must be isomorphs
01:11:47 <Cale> What does it mean for P to be isomorphic to Q?
01:12:05 <satan> there's a function from P to Q and another from Q to P ?
01:12:13 <Cale> more than that
01:12:17 <satan> or is that homomorphic?
01:12:24 <satan> the structure is preserved
01:12:33 <Cale> homomorphic
01:12:53 <Cale> But that's rarely very interesting
01:13:26 <satan> ok
01:13:28 <Cale> (though yeah, in some categories it's a rather interesting thing to consider, like the category of graphs, where it's a generalisation of graph colourability)
01:13:49 <satan> alright
01:14:16 <Cale> A is isomorphic to B if there are arrows u: A -> B and v: B -> A such that v . u = id_A, and u . v = id_B.
01:14:27 <satan> ohh ok, alright
01:15:14 <satan> so to show that P is isomorphic to Q, i gotta show that
01:15:26 <Cale> In our case, the only way we're going to get such u and v is by using our universal property
01:15:40 <satan> which is?
01:15:46 <Cale> It's the only tool we have for constructing arrows, so we'd better use it
01:15:55 <Cale> The product property
01:16:01 <Cale> is the one I'm talking about
01:16:07 <satan> ah ok, sorry
01:17:08 <Cale> okay, so in order to get arrows between P and Q, we'll set X to Q in the P diagram, and set X to P in the Q diagram.
01:17:29 <satan> alright
01:18:00 <Cale> so we end up with a diagram that looks like, well, shall I draw it?
01:19:30 <satan> ok will it be a square balanced on one corner
01:19:58 <Cale> cale.yi.org/autoshare/product.png
01:20:32 <satan> ah ok
01:20:36 <satan> thanks :)
01:21:27 <satan> right, so to state it formally
01:21:30 <Cale> now, we just need to somehow show that these are isomorphisms
01:22:16 <Cale> It's the uniqueness that will help in this
01:22:22 <satan> right
01:22:55 <satan> so u.v = idQ
01:23:12 <Cale> yeah, we need to get that that's true
01:23:17 <satan> and v.u = idP
01:23:21 <satan> ok i see
01:24:33 <Cale> Okay, so let's go by contradiction.
01:24:48 <satan> alright
01:25:08 <Cale> Suppose that u . v = f, some other map.
01:25:33 <satan> ok
01:25:45 <Cale> Then v . f should also make the diagram commute.
01:25:59 <Cale> in place of v
01:26:20 <Cale> but v was the unique arrow with that property
01:26:28 <Cale> So they can't be different
01:26:33 <Cale> v . f = v
01:26:35 <satan> ah i see
01:26:41 <satan> neat
01:28:14 <satan> where is the f on the diagram, though?
01:28:25 <satan> since it went down as the unique commuting diagram
01:28:30 <satan> arrow, not diagram
01:28:37 <Cale> f is u . v
01:28:47 <Cale> so it's an arrow Q -> Q
01:28:51 <satan> ahh ok
01:29:00 <Cale> we need to show that it's id
01:29:10 <satan> alright, thats much better now :)
01:29:58 <Cale> hmm
01:30:55 <marc_vw> can you recommend a good on category theory? to me, so far it sucks. :-)
01:31:11 <marc_vw> book
01:31:26 <Cale> marc_vw: Categories for the Working Mathematician is decent if you know a bunch of mathematics already
01:31:42 <Cale> I learned what I know from that book, and a bunch of random web sources.
01:31:49 <marc_vw> i would love a schaum's outline on category theory as i learn by example best it seems
01:31:56 <satan> yeah same here
01:32:10 <Cale> Algebraic Topology is really where category theory shines, I think
01:32:28 <marc_vw> and for monads it seems :-)
01:32:28 <satan> so, cale, i guess i'd have to use a similar trick to prove (AxB)xC is isomorphic to Ax(BxC)
01:32:46 <Cale> wait wait, I'm not yet 100% convinced we're done :)
01:32:54 <satan> heh ok
01:33:54 <Cale> we know that v . u . v = v and that u . v . u = u
01:34:23 <satan> right
01:38:46 <satan> so what do we do next? sorry its late here, i should sleep soon :S gotta be up at 6
01:38:50 <satan> where are you, cale?
01:39:04 <Cale> Ontario
01:39:12 <satan> no way, where, toronto?
01:39:23 <satan> i'm flying to toronto on tuesday
01:39:27 <satan> i'm in van, bc
01:39:40 <Cale> Brantford
01:39:45 <satan> cool
01:39:55 <Cale> It's 4am :)
01:39:59 <Cale> 4:30
01:40:02 <satan> haha wow
01:40:06 <satan> its 1.40 here
01:41:20 <Cale> hmm, there's a good reason why if you have two unique arrows going between a pair of objects, then their composition is exactly the identity in either direction, but I seem to be forgetting some little point in the proof :)
01:42:08 <satan> hmmm
01:43:43 <Cale> oh
01:44:29 <Cale> right
01:44:30 <Cale> hehe
01:44:41 <Cale> We use the universal property again!
01:44:50 <satan> because there can be one and only one id function?
01:45:02 <Cale> let me draw :)
01:45:04 <satan> oh, ok
01:46:01 <satan> ok cool :)
01:46:30 <MarcWeber> Cale: Are you a polyphasic sleeper? ;-)
01:46:34 <Cale> cale.yi.org/autoshare/product2.png
01:46:47 <Cale> MarcWeber: no, my hours are just f'd up :)
01:46:58 <Cale> satan: see that?
01:47:01 <satan> yes
01:47:09 <Cale> v . u is unique there, by the product property
01:47:19 <Cale> but id_P works to make that diagram commute
01:47:24 <Cale> so v . u = id_P
01:47:36 <satan> ok
01:47:41 <Cale> doing the same thing with Q, we get that u . v = id_Q
01:47:48 <Cale> and so they're isomorphic :)
01:47:54 <satan> wow awesome
01:47:57 <satan> thanks dude
01:48:08 <Cale> no problem :)
01:48:23 <Cale> good for me to keep this stuff remembered :)
01:48:33 <satan> haha and good for me to pick it up :P
01:48:47 <satan> ok i should sleep, 4 hrs is just enough
01:48:51 <Cale> :)
01:49:08 <satan> gotta restart anyway, cya in the morning
01:49:21 <Cale> 'night
01:49:27 <satan> night
02:06:29 <foxy> dons, when you have time can you compile yi+gtk and do "C-x C-f <filename>"?
03:11:07 <shapr> @users
03:11:09 <lambdabot> Maximum users seen in #haskell: 235, currently: 199
03:11:18 <ValarQ> hello formarn
03:11:32 <shapr> Si\: Hey, what's up with HAIFA? Does it do xml-schema and/or SOAP?
03:11:34 <shapr> hej ValarQ
03:51:06 <syntaxfree> if I say type Row = [String], does the Row type inherit all the functions that are valid on [String]?
03:53:07 <vegai> perhaps not 'inherit'. Row is then a synonym for [String]
03:53:52 <syntaxfree> oh. so all functions defined on Row are also valid for [String[?
03:57:01 <shapr> You're just saying 'Row is a nickname for [String]'
03:57:10 <shapr> That's what "type" does.
03:57:22 <shapr> Unlike type, "data" declares an entirely new type.
03:57:40 <syntaxfree> I see.
03:57:44 <vegai> a bit unfortunate naming, perhaps
03:57:53 * shapr doesn't remember exactly what newtype does
03:58:25 <syntaxfree> the syntax would  be data Row = Row [String] though, right?
03:58:34 <vegai> at least it (newtype) needs a constructor
03:58:51 <syntaxfree> if shapr doesn't remember what it does, I prolly don't need it ;)
03:58:53 <shapr> More explicitly, data RowType = RowConstructor [String]
03:59:08 <syntaxfree> yes, I know.
03:59:15 <syntaxfree> is it okay to nest type synonyms?
03:59:17 <shapr> I am not the expert on all Haskell, sadly.
03:59:21 <syntaxfree> type Row = [String]
03:59:24 <shapr> I just do this for fun.
03:59:27 <syntaxfree> type Tabular = [Row]
04:02:05 <ibid> syntaxfree: yes, but not recursion
04:03:02 <ibid> newtype Foo = Foo A is almost like data Foo = Foo !A, but more efficient. i forget what the semantic differences were
04:03:13 <musasabi> How undefined works.
04:03:28 <syntaxfree> what is data Foo  = Foo !A ?
04:03:31 <musasabi> data D = D Bool; newtype N = N Bool
04:03:47 <musasabi> D undefined /= undefined
04:03:52 <musasabi> N undefined == undefined
04:04:17 <ibid> musasabi: note the ! in my data
04:04:38 <ibid> musasabi: i'm fairly sure undefined behaves the same
04:05:22 <ibid> syntaxfree: it's like data Foo = Foo A, except that the A is a strict parameter (ie if a diverges, then Foo a diverges too)
04:05:36 <syntaxfree> diverges?
04:05:59 <ibid> syntaxfree: either aborts or fails to return
04:07:50 <syntaxfree> Hm.
04:07:57 <syntaxfree> Ok!
04:07:59 <syntaxfree> Thanks.
04:11:34 <shapr> hiya ndm
04:12:01 <ndm> hiya shapr
04:16:53 <syntaxfree> Text.Html  Stability	experimental
04:17:00 <syntaxfree> has anyone here used it?
04:20:55 <musasabi> syntaxfree: yes.
04:21:12 <syntaxfree> recommended?
04:21:16 <musasabi> syntaxfree: works for quick hacks, but I wouldn't use it for a large project.
04:21:24 <syntaxfree> I see.
04:21:31 <syntaxfree> Thanks :)
04:21:44 <musasabi> if I want something quick, I use that. But if I want something proper one of the XML libraries
04:23:10 <ndm> i never saw any need to use it, when you can easily squirt out html directly
04:23:53 <benja_> ibid: hmm, what was the status of HacksML :)
04:24:36 <benja_> (not really related but the discussion reminded me)
04:24:54 <syntaxfree> @hoogle [Int]->String->[String]
04:24:55 <lambdabot> No matches, try a more general search
04:25:13 <syntaxfree> @hoogle [Int]->[a]->[[a]]
04:25:14 <lambdabot> No matches, try a more general search
04:25:33 <syntaxfree> @hoogle (Integral b)=>[b]->[a]->[[a]]
04:25:34 <lambdabot> No matches, try a more general search
04:25:44 <ndm> syntaxfree: spaces!
04:25:50 <syntaxfree> ?
04:25:53 <ndm> @hoogle [Int] -> String -> [String]
04:25:54 <lambdabot> No matches, try a more general search
04:26:00 <syntaxfree> ah!
04:26:05 * syntaxfree goes flood lambdabot by privmsg.
04:26:09 <ndm> http://haskell.org/hoogle/?q=%5BInt%5D+-%3E+String+-%3E+%5BString%5D
04:26:11 <lambdabot> Title: [Int] -> String -> [String] - Hoogle
04:26:18 <ndm> just use the normal hoogle, much more reliable
04:26:33 <syntaxfree> oh, there's a web hoogle.
04:26:34 <syntaxfree> cool!
04:26:52 <benja_> syntaxfree, map . replicate? :)
04:26:58 <syntaxfree> nope.
04:27:04 <ndm> the web hoogle is the hoogle, the lamdabot one isn't as powerful
04:27:08 <syntaxfree> I have a list of integers and a string.
04:27:23 <syntaxfree> I want to produce a list of substrings.
04:27:44 <syntaxfree> (The string is "cut" at the positions indicated by the integers)
04:27:50 <ibid> benja_: like most of my projects, dormant :)
04:27:51 <benja_> ah
04:28:01 <benja_> ibid: :)
04:28:07 <ndm> syntaxfree: there is no function to do that
04:28:14 <ndm> but splitAt will probably help
04:28:15 <syntaxfree> I can easily write a recursive function that does that..
04:28:54 <musasabi> drops [] s = s; drops (x:xs) s = take x s : drops xs (drop x s)
04:29:51 <syntaxfree> splitBy (x:xs) string = take x string : splitBy  xs ((drop x+1) s)
04:30:12 <syntaxfree> oh.
04:30:20 <syntaxfree> "drops" is such a weird name.
04:30:35 <ndm> rather than do both take and drop, splitAt is more efficient
04:30:39 <ndm> you'll only do it once
04:35:20 <musasabi> ndm: if you care about performance you wouldn't use Strings in the first place.
04:37:02 <syntaxfree> I might care about performance in the nearby (i.e. in about a week) future.
04:37:10 <syntaxfree> I'm trying to hack up an interface to code against right now.
04:37:15 <musasabi> syntaxfree: then you would swith to ByteStrings
04:37:40 <syntaxfree> Later I might rewrite the boilerplate code with careful attention t o performance.
04:37:54 <syntaxfree> hmm. What restrictions do ByteStrings have, as compared to Strings?
04:38:36 <musasabi> no infinite strings
04:39:10 <ibid> no pattern matching either, i expect
04:39:33 <Cale> There's lazy bytestrings now though
04:39:41 <Cale> which allow for infinite length :)
04:40:12 <syntaxfree> um. I don't need infinite strings, but I've come to expect some degree of laziness.
04:40:14 <Cale> (they're really lists of approximately-cache-sized ordinary ByteStrings)
04:40:26 <Cale> well, yeah
04:41:01 <ibid> Cale: does it allow for divergence within a bs-block?
04:41:03 <syntaxfree> I'm writing code to deal with large numeric databases in various annoying text formats and outputting a format that can be imported into GNU R.
04:41:35 <Cale> ibid: I'm not 100% sure about the behaviour there. That'd be good to test.
04:42:19 <syntaxfree> (I'm also doing a lot of pre-selection in Haskell code, selecting subsets. These datasets are humongous for the machines I have access to)
05:00:52 <shapr`> Anyone know how I can fix this error? "/home/shae/download/tmp/fiasco-1.3/lib/error.c:202: undefined reference to `errno'"
05:02:33 <musasabi> fiasco = L4?
05:02:51 <musasabi> if it is a normal program then #include <errno.h>, but if L4 that is the wrong way
05:02:58 <shapr> L4?
05:03:12 <musasabi> L4 = a microkernel family
05:03:16 <shapr> I'm building on debian/unstable
05:03:28 <shapr> I don't think it's L4.
05:03:40 <musasabi> try the errno.h then
05:04:29 <sieni> #include <errno.h> should work, yes.
05:05:49 <shapr> thanks
05:09:51 <RobHu> Hi - I've just started the Gentle introduction to Haskell and I was wondering what I should use to try it out as I go through (or is that covered later on?) I've installed ghc
05:10:14 <sieni> Maybe :-)
05:10:51 <sieni> although the gentleness is maybe slightly relative in this case...
05:10:57 <RobHu> :-)
05:11:07 <RobHu> My Haskell-ing friend at Galois recommended it
05:11:11 <shapr> "Yet Another Haskell Tutorial" is also nice.
05:11:25 <shapr> RobHu: Oh, who's that? John Launchbury? Isaac Jones?
05:12:05 <sieni> If you have some experience with e.g. lisp or ml, then it's quite ok.
05:12:05 <RobHu> He is an intern there
05:12:12 <shapr> Ah ok
05:12:26 <RobHu> He works for Isaac Jones I think
05:13:02 <RobHu> So am I best using emacs and ghc?
05:14:14 <shapr> That's a well supported config
05:15:00 <musasabi> emacs + ghc is what most people here use.
05:15:07 <RobHu> ok
05:15:38 <sieni> although it would be cool to be able to dump emacs in favor of yi ;-)
05:15:49 <RobHu> heh
05:16:07 <musasabi> sieni: maybe you could hack yi ;-)
05:25:27 <sieni> maybe :-)
05:28:30 <scc> hello shapr I drew it
05:41:26 <beelsebob> hmm, naughty yhc
05:41:30 <beelsebob> doesn't work on ppc any more!
05:44:43 <beelsebob> on the plus side... x86-macosx works, which is one trick ghc doesn't do well
05:48:02 <cmarcelo> i get this error when compiling GHC-trunk: ghc-6.5: unknown package: html
05:48:16 <cmarcelo> did I miss download something?
05:54:31 <musasabi> cmarcelo: update libraries
05:54:42 <musasabi> html package was split a short time ago
05:55:24 <shapr> scc: Where is it?
05:55:24 <cmarcelo> i usually update via ./darcs-all pull, this get libraries for me, dont ?
05:55:41 <int-e> cmarcelo: html is new. run ./darcs-all get again
05:55:49 * int-e had the same problem a day or two ago.
05:56:15 <int-e> cmarcelo: oh, and after that, remove all the stamp files in driver/ so the package config gets rebuilt.
05:57:02 <cmarcelo> tks
05:57:33 <cmarcelo> need to purge libraries/ before darcs get?
05:57:38 <int-e> no
05:57:47 <int-e> darcs-all get skips existing packages
05:58:33 <scc> shapr I tried to send via irc, it isn't working?
05:59:06 <shapr> I can't receive via irc
05:59:15 <shapr> You can send by email or other approach though.
05:59:20 <shapr> I'm shae at scannedinavian dot com
05:59:27 <scc> ok I'll email it
06:01:56 <scc> sent
06:02:36 <scc> brb
06:03:07 <chris2> anyone know libraries for haskell (or other functional languages) that provide efficient array programming (think APL)?
06:04:15 <musasabi> There is work in that direction
06:04:44 <chris2> any links?
06:04:45 <syntaxfree> http://www.regdeveloper.co.uk/2006/08/12/floating_point_approximation/
06:05:05 <syntaxfree> chris2: GNU R is functional and provides good matrix algebra.
06:05:21 <chris2> hmm, R. yeah...
06:05:30 <scc> hmm it's not really cursive perhaps flowing
06:05:37 <syntaxfree> R blows me away with numerical speed.
06:05:51 <syntaxfree> What bothers me is its inability to load large datasets from disk as needed.
06:05:55 * chris2 'd prefer haskell syntax and semantics :P
06:06:04 <musasabi> chris2: e.g. the ndp stuff
06:06:40 <syntaxfree> but anyway, "large datasets" in our department means 3 million observation, 1.5Gb stuff.
06:07:00 <chris2> musasabi: looks good, i'll investigate
06:07:14 <syntaxfree> R works with 100 thousand-ish obs. datasets as if it was working with scalars. Blazing fast stuff.
06:08:03 <chris2> yeah, i've played with R a bit already
06:08:45 <Pupeno> GHC errors sound like me when talking 'precisely' to someone when I want him/her to think a bit and deduce the answer... although GHC is in another higher level of course.
06:10:06 <syntaxfree> the trick is to be able to not talk to people like GHC talks to you.
06:10:41 <SamB> yeah, at least use more variety
06:10:51 <SamB> and be wrong sometimes ;-)
06:11:18 <Pupeno> One of the things I dislike about common lisp is the mix of functions and methods, that is, built-in functions can't be overloaded because the are not method (or generic functions), I can't overload the operator + to apply it to... whatever, I don't know, chairs. Since in Haskell there are also methods and functions on the same namespace do you find that problem ? how often ?
06:11:46 <SamB> well, it doesn't help for something to just *be* a method
06:11:55 <SamB> it has to be a method of the right typeclass
06:12:26 <SamB> it would be nice if there were collection classes, but nobody seems to have figured out what those should be, afaik...
06:12:38 <SamB> I tried once, and it was interesting but discouraging...
06:13:26 <SamB> we might need more extensions than I had available to come up with something I would really like ;-)
06:15:39 <SamB> really, though, a lot of things are in classes, and you could always write your own class that has members with the same shortnames as functions in a library, and an instance that uses those functions...
06:17:05 <SamB> + is okay
06:17:50 <dons> ?ghc say something!
06:17:50 <lambdabot>  Simplifier reached fixed point
06:18:01 <dons> ah, wonderful. i'll ponder this
06:18:05 * dons reaches fixed point
06:18:08 <dons> night!
06:18:30 <SamB> * is okay as long as you aren't trying to do matrix/vector arithmatic (where the arguments might have different types and, furthermore, does * mean dot or cross?)
06:19:23 <syntaxfree> "If your programming language requires you to use functors, you're not getting all the benefits of a modern programming environment."
06:19:28 <syntaxfree> http://www.joelonsoftware.com/items/2006/08/01.html
06:19:31 <lambdabot> Title: Joel on Software
06:23:26 <psi> what's that supposed to mean? I've only heard of functors in the context of haskell.
06:23:40 <shapr> scc: You're right, that is far niftier than the logic alphabet.
06:23:59 <MarcWeber> I'm currently trying to compile hope. I'm gettnig this error: http://rafb.net/paste/results/JQk31630.html "ope/Session.hs|1| unknown package: fps-0.7" I don't understand why  ghc requires version 0.7. Where might this version come from? Thes requirement remains after adding -package fps-0.8
06:24:06 <shapr> scc: Do you mind if I post that on my blog?
06:24:12 <scc> no
06:25:16 <gds> psi: In that context it means first class functions are good, and wrapping functions in objects is bad.
06:25:24 <scc> I just hope it there are no blatant errors
06:25:57 <syntaxfree> http://steve-yegge.blogspot.com/2006/03/execution-in-kingdom-of-nouns.html
06:25:59 <lambdabot> Title: Stevey's Blog Rants: Execution in the Kingdom of Nouns
06:26:08 <syntaxfree> "On the other side of the world is a sparsely inhabited region in whose kingdoms Verbs are the citizens of eminence. These are the Functional Kingdoms, including Haskellia, Ocamlica, Schemeria, and several others. Their citizens rarely cross paths with the kingdoms near Javaland. "
06:26:18 <int-e> @where hope
06:26:19 <lambdabot> http://hope.bringert.net/
06:26:55 <shapr> scc: it sure looks nice to me.
06:27:04 <MarcWeber> int-e: Any idea?
06:27:04 <musasabi> Is there a paper related to the "[Haskell] Smash your boiler-plate without class and Typeable" ?
06:27:38 <shapr> I haven't seen anything about it.
06:27:55 <psi> gds: I see. Object with a function = functor?
06:28:07 <shapr> MarcWeber: When did fps-0.8 come out?
06:28:22 <shapr> MarcWeber: afaik, hope works with 0.7 and I would have updated it if I knew 0.8 was released.
06:28:28 <SamB> which language has something called a "functor" that is pretty much like a Python object with a __call__ method?
06:28:34 <int-e> MarcWeber: maybe you have to recompile one of the required packages?
06:28:42 <int-e> hmm
06:28:43 <shapr> MarcWeber: Try hacking the cabal file to say fps-0.8 instead?
06:28:43 <SamB> probably C++...
06:28:48 <scc> thanks shapr
06:28:50 <dylan> SamB: C++
06:29:20 <psi> is this totally unrelated to the haskell functor?
06:29:22 <SamB> python people use the more sensible term "callable object"
06:29:27 <dylan> and Functor means something different in ML, too... at least, I'm not sure how ML functors relate to haskell functors...
06:29:30 <SamB> or just "callable"
06:29:50 <SamB> dylan: something to do with parameterized modules, isn't it?
06:30:00 <int-e> requirements in the cabal file are  fps >= 0.7, ... if your ghc is too new, you should remove that dependency, because Data.ByteString is in the base package there. But I can't explain where the 0.8 comes from.
06:30:17 <SamB> anyway, I believe Haskell's functors are the only ones that use the term correctly...
06:30:24 <SamB> @all-dict functor
06:30:25 <int-e> oh, the 0.8 was invented by you.
06:30:26 <dylan> SamB: a function that works on modules
06:30:26 <lambdabot> *** "functor" foldoc "The Free On-line Dictionary of Computing (27 SEP 03)"
06:30:26 <lambdabot> functor
06:30:26 <lambdabot>  
06:30:26 <lambdabot>     In {category theory}, a functor F is an operator on types.  F
06:30:26 <lambdabot>     is also considered to be a {polymorphic} operator on functions
06:30:28 <lambdabot> [11 @more lines]
06:30:35 <shapr> hiya dylan, how's code?
06:30:41 <SamB> @more
06:30:42 <lambdabot>     with the type
06:30:42 <lambdabot>  
06:30:42 <lambdabot>     	F : (a -> b) -> (F a -> F b).
06:30:42 <lambdabot>  
06:30:42 <lambdabot>     Functors are a generalisation of the function "{map}".  The
06:30:44 <lambdabot> [6 @more lines]
06:30:48 <gds> psi: "Java required you to create a whole object with a single method called a functor if you wanted to treat a function like a first class object."
06:30:52 <dylan> shapr: No more stack overflows, how about you?
06:30:54 <SamB> hmm, or not
06:30:55 <gds> psi: so basically, yes.
06:31:02 <SamB> I don't understand that
06:31:10 <shapr> hah
06:31:14 * dylan was doing something stupid with a FilePath -> IO [FilePath] function. XD
06:31:16 <shapr> dylan: pure and functional!
06:31:21 <SamB> @more
06:31:22 <lambdabot>     type operator in this case takes a type T and returns type
06:31:22 <lambdabot>     "list of T".  The map function takes a function and applies it
06:31:22 <lambdabot>     to each element of a list.
06:31:22 <lambdabot>  
06:31:22 <lambdabot>     (1995-02-07)
06:31:24 <lambdabot>  
06:31:28 <shapr> dylan: Sound familiar, how'd you beat it?
06:31:40 <musasabi> dcoutts_: any ideas what to do about the configurations stuff?
06:31:44 <SamB> dylan: what did it do? "return"?
06:31:53 <SamB> oh, wait, thats a list
06:31:56 <scc> btw do you know of any names for the ones I didn't name?
06:32:03 <psi> gds: thanks. I actually read that sentence, but somehow I missed the word functor :)
06:32:09 <SamB> was it supposed to read a directory?
06:32:17 <dylan> SamB: Recursively, yes.
06:32:20 <dcoutts_> musasabi, have there been more emails? If so I've not read them yet.
06:32:26 <gds> psi: Cool :)
06:32:31 <SamB> dylan: I think dons has code for that...
06:32:34 <SamB> in hmp3
06:32:35 <musasabi> dcoutts_: no
06:32:37 <dylan> Works fine now, it was a wrapper around it that was somehow making it use a lot of stack. XD
06:32:45 <shapr> scc: No, but I'll ask in my blog entry.
06:32:52 <musasabi> dcoutts_: and Marlow is on holiday
06:32:54 <scc> cool
06:32:54 <dylan> SamB: yes, but this is for learning
06:32:58 <dcoutts_> musasabi, a bugger.
06:32:59 <SamB> oh
06:33:02 <dcoutts_> a/ah
06:33:19 <SamB> well, then I guess you care more about writing it yourself than about its being the best code ;-)
06:33:27 <dcoutts_> musasabi, we can ask SyntaxNinja and Igloo for their opinions
06:34:07 <dylan> SamB: Yep. using the IO and List monads a lot. I also have a good feeling for how to seperate "pure" code out of the IO monad.
06:34:18 <musasabi> ok
06:34:45 * musasabi will be away from all Haskell stuff from thursday till sunday
06:34:50 <dcoutts_> musasabi, ok
06:34:53 * SamB should go take a shower...
06:35:04 <dcoutts_> musasabi, or we could risk it and start implementing bits
06:35:07 <SamB> maybe should finish my water first
06:35:13 <dcoutts_> musasabi, for example, we can start without the flags
06:35:14 <SamB> I don't like water :-(
06:35:40 <SamB> unforunately I'm about to go for bloodwork so I can't have anything else :-(
06:35:43 <dcoutts_> musasabi, and have the bits where you're allowed to ask about versions of packages we aleady dep on
06:36:20 <dcoutts_> musasabi, eg configuration: using(base<=1.0); build-depends: fps>=0.8
06:36:37 <dcoutts_> that's a relatively small modification of the current system
06:36:45 <dcoutts_> just chaning the semantics of package/using
06:37:08 <dcoutts_> to mean which one have we decided to depend on, rather than what's available in the environment
06:37:18 <shapr> scc: btw, neat last name, never seen that one before.
06:37:47 <dylan> sweeet.
06:37:50 <musasabi> dcoutts_: true. Just not sure how to make the decision process not relevant on the order
06:37:56 <dylan> I just got out of writing a requirements document at work
06:38:10 <shapr> SamB: What do you usually drink?
06:38:21 * shapr drinks more liquids than anyone he's ever met.
06:38:21 <SamB> milk
06:38:23 <scc> unfortunately it's always misspelt
06:38:40 <shapr> scc: Still, it's way nifty. Where'd it come from?
06:38:56 <dcoutts_> musasabi, my suggestions were: 1. just let it be ordered top to bottom. 2. process in dep order and ban cycles. 3. iterate until fixpoint (which I think should be terminating).
06:39:00 <boegel> shapr: you're the local beer champion?
06:39:15 <shapr> Nah, I don't drink alcohol more than twice a year or so.
06:39:16 <dcoutts_> musasabi, 1. is obviously easist
06:39:29 <shapr> boegel: Though I did once drink 28 beers in an evening.
06:39:29 <dcoutts_> musasabi, and we could change it to 2. or 3. if necessary
06:39:56 <boegel> shapr: 33cl? or 25?
06:39:57 <dylan> shapr: spake my girlfriend: "How did you... drink... 3 gallons of water in a day!?"
06:40:28 <musasabi> dcoutts_: the problem is that there can be two good configurations.
06:40:31 <boegel> shapr: a friend of my gf told her her back is painfull because she doesn't drink enough water
06:40:34 <boegel> and I think he's right
06:40:38 <shapr> dylan: Hm, I've drunk more than 4 gallons in a day easily.
06:40:45 <musasabi> dcoutts_: e.g. should be prefer base-1.0+fps-0.8 or base-2.0
06:40:52 <boegel> translate that to liters please :)
06:40:52 <shapr> dylan: You drink 3 gallons yourself?
06:40:59 <dcoutts_> musasabi, that gets decided first
06:40:59 <shapr> boegel: More than 15 liters.
06:41:09 <musasabi> dcoutts_: based on what?
06:41:12 <boegel> shapr: :|
06:41:16 <dylan> shapr: I know! and it's hot here. She's like a desert creature or something, only drinks about 1 gal of liquid a day, and calls me strange for needing more. :P
06:41:16 <boegel> shapr: you're mad!
06:41:18 <scc> my father :p I don't really know, all I know is that my father's side has cornish roots
06:41:25 <boegel> shapr: then you're drinking _all_ the time?
06:41:28 <dylan> shapr: yes, it was hot and I was outside most of the time.
06:41:28 <dcoutts_> musasabi, the same method cabal uses now to resolve versions
06:41:30 <shapr> boegel: I'm not dehydrated at least.
06:41:34 <shapr> boegel: Well, yes.
06:41:43 <boegel> damn
06:41:45 <shapr> dylan: Insane..
06:41:46 <dcoutts_> musasabi, if I say: build-depends: base. then cabal decides on a version.
06:41:58 <boegel> how much is 1 gallon?
06:42:01 <dcoutts_> musasabi, then the configuration decisions are based on that decision
06:42:15 <musasabi> so it would be impossible to build a base-1.0+fps-0.8 version if base-2.0 was installed?
06:42:33 <dcoutts_> musasabi, if cabal decided to use base-2.0 then yes
06:42:38 <shapr> dylan: Where are you? How hot?
06:42:54 <dcoutts_> musasabi, at the moment cabal always picks the latest installed version matching the constraints
06:43:01 <dylan> shapr: Florida, between 80-90 and high humidity.
06:43:07 <dcoutts_> musasabi, having more control over that is a seprate issue
06:43:14 <musasabi> true. But currently there are no alternative configurations usually
06:43:37 <dylan> sorry, I don't have a fahrenheit to celcius converter handy.
06:43:43 <scc> 3.7854118 litre for US, 4.54609 for imperial
06:44:01 <shapr> @google 90 degrees fahrenheit in celsius
06:44:02 <dcoutts_> musasabi, well true, now it makes more difference than just which version of a single package we use as it can pull in different deps
06:44:02 <lambdabot> 90 degrees Fahrenheit = 32.2222222 degrees Celsius
06:44:17 <shapr> @google 1 gallon in liters
06:44:19 <lambdabot> 1 US gallon = 3.7854118 liters
06:44:24 <dylan> shapr: Even without doing anything outside, it's possible to sweat.
06:44:31 <dcoutts_> musasabi, but I think it's still a seprate issue, if people care we may allow more influence over the dep picking policy
06:44:37 <musasabi> ok
06:44:38 <boegel> shapr: no way my gf drinks 1 gallon a day
06:44:41 <boegel> more like half a gallon
06:44:49 <shapr> I agree. I lived in Birmingham Alabama, where it gets to 110 in the summers.
06:45:06 <dylan> shapr: Yikes. it never gets that hot here. :)
06:45:12 <Pupeno> SamB: according to what you said, then, can I define a length function/method for my own data type/class ?
06:45:16 <dylan> but might be more humid. :(
06:45:21 <shapr> It only gets that hot inside the city during rush hour.
06:45:42 <shapr> Still no fun to be without an air conditioner though.
06:45:54 <dylan> shapr: Until the last year, I've never had AC. :)
06:45:58 <Pupeno> @google 1 uk gallon in liters
06:45:59 <lambdabot> 1 Imperial gallon = 4.54609188 liters
06:46:04 <Pupeno> ha!
06:46:06 <dylan> 20 years in FL without A/C...
06:46:13 <MarcWeber>  Now I did compile nicely... ;-)
06:46:17 <Adamant> now that stinks
06:46:25 <Adamant> FL gets freakin' hot.
06:46:31 <boegel> Pupeno: tssk, they really always want something else, don't they?
06:46:37 <dylan> Adamant: Nono, I always used to take at least 2 showers a day
06:46:45 <dylan> So, no stinky. ;)
06:47:05 <Adamant> dylan, not heat/sweat stink, just that it is a ungood situation
06:47:08 <dylan> As a result of this, I'm like the only person on the bikeway in the summer.
06:47:11 <shapr> It's not bad if you stay thin.
06:47:23 <dylan> (I'm used to the heat, most people arn't, it seems.)
06:47:23 <shapr> It's way too hot if you don't work off that programmer's belly.
06:48:22 * Pupeno had a thermodinamics teacher that thought that unit conversions were basic to normal life so he would give us the values in many different kinds of units (imperial, metrics and others), we would have to do many conversions to use the different tables and then convert back because he wanted the result in some other esotheric unit.... the tests were hard only because of the conversion units.
06:48:46 <dylan> shapr: the biggest problem is the salt deposits in one's shirts, really.
06:49:03 <shapr> I got used to the opposite while living in Boden, now I can unicycle when it's down to zero degrees F.
06:49:21 <Adamant> fun fact - living without AC causes you to burn more calories via your body thermoregulating.
06:49:28 <shapr> Neat
06:49:32 <dylan> shapr: It's nice to know one can get cold-adapted after being hot-adapted.
06:50:58 <scc> I'm going to put another log on the fire
06:52:07 <dylan> I think I'm severly deprived of knowledge of cold here...
06:53:07 <shapr> Cold is nice in many ways. There are nearly zero bugs, snakes, etc.
06:53:16 <dylan> I like snakes, though.
06:54:13 <dylan> and it's thrilling to know there's a 2.2-meter aligator in the lake just down the street. ;)
07:00:51 <scc> you sound like a C programmer
07:01:08 <shapr> scc: Your logic alphabet is way nifty
07:01:24 * dylan doesn't really know C.
07:01:51 <shapr> I met C once. Didn't get along with him.
07:02:02 <dylan> looking at irssi's source code made me never want to use C for anything.
07:02:08 * Pupeno will experience real cold and snow for the first time this winter (living in Berlin).
07:04:05 <shapr> scc: That's really cool that commutativity is explicit.
07:04:19 * shapr is meditating on the whole logic alphabet thing...
07:04:47 <scc> yes, that was the main thing i didn't like about the original
07:06:52 <shapr> scc: That says something nifty about DSLs, I think...
07:07:37 <shapr> Domain Specific Languages are where you set up the basic chunks to encode certain properties and follow certain laws so that problems phrased in those languages can be easily solved in a certain way.
07:07:55 <syntaxfree> is Prolog a DSL then?
07:08:04 <shapr> At some level it is.
07:08:13 <syntaxfree> I have to learn Prolog at some point.
07:08:35 <shapr> Haskell is a DSL for a certain definition of domain.
07:08:56 <shapr> Thing is, most people define their domain in terms of a specific application, like Haskore for music.
07:09:48 <syntaxfree> Prolog sounds more DSL-ish than Haskell.
07:10:05 <scc> I bet if students were taught it first they would get into trouble trying to treat all symmetrical operators as commutative :)
07:10:05 <syntaxfree> the automatic solving stuff.
07:10:32 <syntaxfree> My last attempt to learn Prolog was thwarted by the incompatibility between the interpreters I found and the tutorials available.
07:10:35 <shapr> You can get the same sort of automatic solving from the list monad in Haskell.
07:10:40 <shapr> It just walks a solution tree.
07:11:04 <shapr> At least, I think so.. I don't know Prolog, maybe I shouldn't say anything.
07:11:26 <syntaxfree> @wikipedia Prolog
07:11:27 <lambdabot> No Result Found.
07:11:52 <Stinger_> ok just mucking around with gtk2hs, is it possible to store some state in an event handler.. if this question even makes sense
07:11:57 <syntaxfree> Prolog does some sort of logical backtracing.
07:12:25 <shapr> Backtracking does happen with the list monad.
07:12:31 <sieni> then there's LogicT for Haskell, of course.
07:12:34 <dcoutts_> Stinger_, you can create IORefs/MVars of course and then modify them in an event handler
07:12:59 <Stinger_> would that be a sensible thing to do?
07:13:07 <dcoutts_> probably
07:13:13 <dcoutts_> what are you trying to do?
07:14:04 <Stinger_> just say trying to have a button that toggles colour; wondering if you can do it by storing state rather than querying something else
07:17:31 <dcoutts_> colour <- newIORef blue; onClicked button $ do current <- readIORef colour; ...
07:19:40 <Stinger_> is this how most interactive programs operate? with most of the state in IORefs?
07:22:04 <dcoutts_> Stinger_, well people prefer to minimise the number of state components
07:22:12 <dcoutts_> Stinger_, there's a few techniques..
07:23:28 <dcoutts_> one is to make a data type holding all the bits of state you need and then just use one IORef/MVar to hold that. The ref can often be hidden in get/set functions
07:23:38 <dcoutts_> or similarly use a state monad
07:23:49 <dcoutts_> another is to use a thread
07:23:54 <dcoutts_> or several
07:24:39 <Stinger_> well I originally thought of the state monad, but that wouldn't fit into this specific framework/application would it?
07:24:45 <shapr> Or you can do everything by hand and melt into a puddle of despair trying to find typos.
07:24:45 <dcoutts_> and have the thread read commands out of a queue, the thread can hold any state it needs without using any refs, but just by the normal technique of a recursive function passing parameters to itself
07:24:55 <shapr> hiya jtoy, learning Haskell?
07:25:06 <jtoy> yes
07:25:17 <dcoutts_> Stinger_, then other event handlers post commands to the thread(s)'s queues
07:25:49 <eivuokko> Anyone here used ObjectIO package?
07:25:52 <shapr> jtoy: Any questions?
07:26:14 <shapr> eivuokko: Only works on windows, linux port was abandoned by author.
07:26:15 <Stinger_> so you'd have a state monad in a seperate thread and delegate to that from say user interface code?
07:26:37 <shapr> eivuokko: Other than that, I've heard it's neat, and extremely windows specific.
07:26:51 <dcoutts_> Stinger_, that's possible, then the event handlers do not need any state themselves
07:27:03 <dcoutts_> and you can make gui calls from any thread
07:27:15 <dcoutts_> though do read the FAQ on Gtk2Hs and threads first.
07:27:50 <dcoutts_> Stinger_, otherwise you'll think it's broken at first
07:27:55 <eivuokko> shapr, Sounds cool.  It just seems unmaintained, and I am converting it to use Data.Map instead of FiniteMap (so that nightly builds might work again)
07:27:56 <Stinger_> hmm interesting, dont think I'm quite up to threads in haskell yet :) thanks for the ideas though
07:29:24 <dcoutts_> Stinger_, then the common thing to do is have a little abstraction where you run an action in your state monad by getting the state from the IORef, running the action and then putting the state back.
07:29:58 <dcoutts_> Stinger_, so your event handlers would do: runAction (blah)
07:30:53 <dcoutts_> and runAction would have been defined eariler as something like: runAction action = readIORef s >>= runState action >>= writeIORef s
07:31:18 <dcoutts_> Stinger_, then all your actions work in your state monad
07:31:45 <dcoutts_> so it's just: extract the saved state, run the action, resave the state
07:36:34 <Stinger_> hehe all this imperitive stuff, doesn't seem quite right with all the stuff I've been reading in hsoe :)
07:41:12 <dcoutts_> Stinger_, yeah, I know. :-(  Functional guis are still a area under development. Doing purely functional drawing is ok, the reactive gui stuff is more tricky. There are some approaches based on FRAN.
07:41:44 <shapr> Check out Fruit
07:42:20 <scc> under develepment but extremely cool
07:45:00 <shapr> hiya liyang
07:46:16 <liyang> hullo. The university seems to have fallen off the network there.
07:47:25 <dcoutts_> shapr, perhaps you can give me some advice, I'm tring to book a youth hostel in Stockholm for one night...
07:49:11 <sieni> naah, just go tenting to danderyd. cheaper and more interesting ;-)
07:49:32 <dcoutts_> I was looking on one website, but despite all of the site being available in english, the booking bit is only in swedish and then I get lost :-)
07:49:41 <shapr> What's the url?
07:49:50 <dcoutts_> shapr, I started here: http://www.stockholmtown.com/templates/page____7793.aspx
07:49:56 <shapr> Any specific words you want translated?
07:50:06 <dcoutts_> shapr, but I don't even know if that's the best place to be looking
07:50:40 <dcoutts_> I'm just looking for a simple one night youth hostel type thing
07:50:45 <shapr> Looks right to me.
07:51:07 <shapr> When I don't know a word, I use http://www-lexikon.nada.kth.se/skolverket/sve-eng.shtml
07:51:10 <dcoutts_> as we arrive in the evening and then take off the next day for the Inlandsbanan :-)
07:51:22 <shapr> Vandrarhem means youth hostel.
07:51:27 <dcoutts_> right
07:52:01 <dcoutts_> shapr, it also seems to be mentioning regions of the city
07:52:25 <dcoutts_> I presume I want "stockholm city"
07:52:30 <shapr> Yup, and there are 66 hits.
07:52:47 <Stinger_> not really complaining about the imperitiveness, its what I'm used to. Some of the functional whackiness they pull in soe does my head in :)
07:52:50 <shapr> You take off from the airport?
07:53:52 <shapr> dcoutts_: Arlanda is the name of the airport, so you could limit it to that.
07:54:10 * edwardk waves ello.
07:54:17 <dcoutts_> shapr, no, we're going from Gotenberg to Stockholm by train, then by train to Mora
07:55:27 * edwardk tries very hard to wake up and be a good employee... and fails.
07:55:52 <shapr> dcoutts_: In that case, stockholm city probably is better.
07:57:05 <dcoutts_> shapr, right
08:02:16 <greenrd> Has anyone experienced runghc being really, really, really slow when it redirects to a file?
08:02:26 <greenrd> But not when it's just outputting to the console?
08:03:01 <greenrd> this is on Linux with the file being on NFS
08:04:01 <edwardk> greenrd: are you sure the problem isn't just that nfs is dog slow? =)
08:09:35 <greenrd> edwardk: well... normally it doesn't take that long to write a file :)
08:10:01 <greenrd> maybe it needs to write buffer more... still, it does seem excessively slow
08:10:12 <greenrd> perhaps it is actually making one write() call per character?
08:10:19 <greenrd> I should use strace to find out
08:14:52 <edwardk> greenrd: does runghc setvbuf to turn off buffering on its standard output? nfs doesn't respond well to no buffering, as you say, one write per character.
08:15:15 * edwardk brought a server to its knees once by similar means =0
08:28:25 <ookk> what does the *** operator do?
08:28:36 <basti_> that depends.
08:28:45 <ookk> and what module is it in?
08:28:46 <edwardk> @type (***)
08:28:47 <lambdabot> forall (a :: * -> * -> *) c' c b' b. (Arrow a) => a b c -> a b' c' -> a (b, b') (c, c')
08:28:52 <edwardk> its in Control.Arrow
08:28:55 <ookk> i have seen it int the Mind Blowing Examples
08:29:00 <ookk> ok
08:29:24 <edwardk> it lets you combine two arrows to make one that works on a pair
08:29:55 <ookk> ok can you give an example?
08:29:59 <edwardk> sure
08:30:15 <edwardk> > (fst *** snd) ((1,2),(3,4))
08:30:16 <lambdabot>  (1,4)
08:30:35 <edwardk> note that function application is an arrow
08:30:43 <edwardk> so you can use it to combine functions
08:31:08 <ookk> ahh so it makes a function that takes two tuples as an argument?
08:31:24 <basti_> btw. edwardk could you enlighten what the connection between arrows and pairs is? I often see both constructions at the same time, but I don't understand at all why.
08:31:25 <edwardk> well, in that case, because fst and snd each expect tuples
08:31:42 <ibid> basti_: arrows use pairs for plumbing
08:32:01 <edwardk> > (head *** tail) ([1..10],[1..10])
08:32:08 <lambdabot>  (1,[2,3,4,5,6,7,8,9,10])
08:32:21 <ookk> so it parameters is a tuple with the arguments?
08:32:22 <xerox> Yuck.
08:32:26 <edwardk> heh
08:32:29 <xerox> > (head &&& tail) [1..10]
08:32:30 <lambdabot>  (1,[2,3,4,5,6,7,8,9,10])
08:32:38 <basti_> ibid: yea i have understood this far. Is there no other way to do this?
08:32:41 <xerox> instance Arrow (->) where
08:32:42 <basti_> (combine arrows)
08:32:47 <edwardk> well, i was trying to give an example of *** =)
08:32:50 <xerox>   (f &&& g) x = (f x,g x)
08:33:00 <xerox>   (f *** g) (x,y) = (f x,g y)
08:33:07 <xerox> first f (x,y) = (f x,y)
08:33:13 <xerox>   second f (x,y) = (x,f y)
08:33:19 <edwardk> basti: well, the connection has to do with monads. the idea is that arrows generalize function application and connecting functions.
08:33:20 <xerox>   (>>>) = flip (.)
08:33:25 <xerox> That's it.
08:33:26 <ibid> basti_: probably is, but why bother?
08:33:39 <basti_> hmm
08:33:39 <edwardk> unfortunately, an arrow itelf isn't all that useful coz you have no place to carry a state unless you add more structure
08:33:44 <ookk> xerox, ahh thx, that was a clear definition :)
08:33:46 <basti_> ibid: yes i see that point
08:33:51 <edwardk> well, what better place to carry that than as one of two elements in a pair
08:34:19 <edwardk> so you typically see arrows used in which the first element of the pair represents state and the second is used for whatever you would bundle in a monad.
08:34:27 <ibid> not state per se but local variables in a proc/do
08:34:33 <edwardk> yeah
08:34:51 <ibid> i mean, when you say "state" i think of the state monad, and it's nothing like that
08:35:09 <ibid> you can do a state arrow in that sense, but it works differently
08:35:14 <edwardk> then you can use 'first' and 'second' to set up functions that only work with the state or the value.
08:35:15 <ibid> (from the tuple stuff)
08:35:20 * edwardk nods.
08:36:03 <edwardk> it just seemed to be a common recurring usage pattern for them
08:37:25 <edwardk> anyways, the nice thing about arrows is they can be things other than function application, and the pair stuff basically just gives you a limited form of cartesian product you can play with.
08:43:46 <edwardk> xerox: how goes your investigation into category theory?
08:44:28 * dmhouse pokes his head round the door
08:45:10 <edwardk> heya dm
08:46:21 <dmhouse> Hi edwardk.
08:50:24 <shapr> stepcut: Do you have an emacs for os2006?
08:50:57 <edwardk> there needs to be a typeclass level seq =)
08:51:09 <edwardk> or fewer ghc bugs
08:51:09 <dmhouse> Hi shapr, any progress on an AngloHaskell report?
08:51:17 <int-e> heh, types are strict, aren't they?
08:51:50 <edwardk> int-e: yeah. unfortunately ghc seems to have a bug that causes it to evaluate dependencies in the wrong order and blow up occasionally
08:51:51 <shapr> dmhouse: I've been distracted...
08:52:16 <edwardk> int-e: with something that could force the evaluation order i woudn't have that problem
08:52:47 <edwardk> int-e: seems to only show up in the face of complicated fundeps
08:53:01 <edwardk> and lots of dependencies
08:54:32 <edwardk> i was revisiting some of the type arithmetic code trying to understand why ghc pitched a fit about an unrelated instance declaration when i changed the type annotation on one of the witness functions
08:54:40 <ookk> if i write let f n = \x -> (expensive_function n)*x is expensive_function calculated everytime i use the function returned by f n ?
08:55:35 <edwardk> ookk: shoudn't be, welcome to lazy evaluation.
08:56:15 <edwardk> it'll resolve that the first time its needed, and rewrite the memothunk with its new value.
08:56:23 <ookk> so if i type let p = (f n) and then use p expensive_function n is already calculated as a constant?
08:56:50 <edwardk> it will be after first use
08:57:01 <ookk> okay
08:57:26 <ookk> good
08:57:46 <edwardk> its haskell's greatest strength (and weakness) coz you can wind up with a lot of those things beind held onto that you don't need, and leak space.
08:58:33 <ookk> its a very nice feature
08:59:01 <LordBrain> what's the feature?
08:59:06 <LordBrain> memoization?
08:59:13 <edwardk> lord: yeah
08:59:20 <ookk> lazy evaluation
08:59:36 <LordBrain> ah yeah i like it
08:59:43 <ookk> what is memoization?
08:59:48 <edwardk> more specifically graph reduction
09:00:20 <edwardk> memoization refers to saving the result of a function in a map from the function arguments to the result, used to cache expensive calculations
09:00:37 <edwardk> its common usage refers to a more heavyweight process than the one defined.
09:00:39 <ookk> the only thing discomforting about haskell is that ghc is maintained by microsoft research ;)
09:00:47 <LordBrain> ookk: it simply means remembering, the last time you called f with 4 as a parameter it gave you 8, next time you dont have to actually compute it, you know its 8
09:00:55 <edwardk> see, nothing stops you from calling f n in another place, getting a different thunk, and having to evaluate that
09:01:13 <edwardk> so graph reduction != memoization in the traditional sense.
09:01:15 <ookk> yeah i thought that was lazy evaluation
09:01:57 <ookk> i like being able to define infinite lists
09:01:58 <edwardk> lazy just says you don't evaluate til you need it. it doesn't necessarily entail that you update the node with its result.
09:02:20 <ookk> yeah that makes sense
09:02:26 <edwardk> call-by-name vs. call-by-need and all that
09:03:34 <shapr> hiya pediddle, ltns
09:04:00 <LordBrain> although, some computations are probably faster than table look ups.... like if its just an increment
09:04:10 <edwardk> yeah
09:04:19 <pediddle> mornin'
09:04:26 <edwardk> and the table lookups mean you have to keep the values a lot longer, etc.
09:04:33 <shapr> ookk: Microsoft Research is paying the Simons to develop and release BSD3 licensed code. I'm not worried. If they go closed source with it, we can just fork and continue development.
09:04:35 <edwardk> time/space tradeoff
09:05:54 <shapr> @users
09:05:56 <lambdabot> Maximum users seen in #haskell: 235, currently: 211
09:06:10 <SamB> they'd rather quit anyway, methinks
09:06:46 <edwardk> yeah, the opensource thing seems pretty hardwired into the community
09:07:00 <mux> mmm, how can I define a type, or type synonim that encompasses several constraints?
09:07:11 <SamB> of course, MS is free to develop a closed-source version which tracks the open source code
09:07:23 <SamB> but they'd probably have to deal with that LGPL issue
09:07:40 <LordBrain> i thought it was bsd licensed
09:07:40 <edwardk> mux: constraints as in fundeps or constraints as in multiple type variables?
09:07:53 <mux> like, I don't want to have (Integral a, Fractional a, Random a) => ... for all of my functions
09:08:05 <SamB> LordBrain: one of the libraries it uses is not
09:08:08 <edwardk> mux: you're screwed =)
09:08:14 <edwardk> mux: you CAN cheat a little though
09:08:14 <LordBrain> which one?
09:08:15 <mux> fsck!
09:08:22 <SamB> LordBrain: libgmp
09:08:29 <ibid> mux: you can create a new class that inherits from them
09:08:36 <edwardk> mux: class Integral a, Fractional a, Random a => MyClass a
09:08:47 <SamB> libreadline isn't, either, actually...
09:08:47 <mux> ah.
09:08:49 <edwardk> instance (Integral a, Fractional a, Random a) => MyClass a
09:08:49 <mux> that's good enough
09:09:08 <LordBrain> hypothetically, if we did have to fork it, would we continue a bsd style fork? or would we lgpl it?
09:09:08 <SamB> in fact I think that one is GPL...
09:09:08 <edwardk> then you define a subclass of all of them and that every instance of all of them is an instance of your subclass
09:09:14 <ibid> basti_: but libreadline is not linked with compiled executables by default
09:09:19 <SamB> but that is not a dependency but rather a convenience feature
09:09:26 <mux> a bit uneasy though
09:09:35 <basti_> ibid?
09:09:37 <ibid> gah, s/basti_/SamB/
09:09:41 <basti_> ^^
09:09:46 <edwardk> samb: gmp is the big lgpl requirement that i recall
09:09:53 <edwardk> oh
09:09:57 <edwardk> saw you mentioned that =)
09:10:07 <LordBrain> it would depend on how competetive or cooperative we want to be with microsoft i guess.
09:10:09 <SamB> edwardk: yeah, readline probably doesn't even work on Windows ;-)
09:10:09 <shapr> LordBrain: I think it depends on who was in the team that decided to continue developing it.
09:10:16 <SamB> and MS wouldn't care about it most likely
09:10:23 <ibid> basti_: sorry :)
09:11:44 <edwardk> its a shame that gmp is so much faster than most of its competition
09:13:15 <LordBrain> hmmm
09:13:22 <shapr> Whoa, my irc nick is in the History of Haskell paper!!
09:13:36 <LordBrain> it's a shame because you would rather a bsd license on it?
09:13:46 <mux> edwardk: looks to me as if only the class line is necessary?
09:13:49 <gzl> shapr: I would have expected that. but I'll be impressed if your unicycle is there too. :)
09:13:54 * shapr laughs
09:16:35 <mux> erm, or not
09:17:25 <SamB> ack, I just cutmy left index finger on the tip and it hurts!
09:17:53 <SamB> makes typing much harder
09:18:04 <mux> surprisingly :)
09:18:07 <edwardk> haskell needs a native big number library. doing fusion on that would be cool. =)
09:18:17 <SamB> (yes, I put bandaid on it ;-)
09:18:19 <beelsebob> um... Integer
09:18:30 <SamB> beelsebob: yes, exactly
09:18:31 <edwardk> beelsebob: Integer == gmp its not native
09:18:57 <edwardk> beelsebob: hence why i think it would be cool to do one natively, that could exploit the various fusion techniques.
09:19:05 <shapr> @remember VirginiaCurry "You know, Haskell actually never liked the name Haskell." -- Virgina Curry (Haskell B. Curry's widow)
09:19:06 <lambdabot> Done.
09:19:07 <edwardk> each multiplication, etc is a black box and can't be interconnected.
09:19:09 <beelsebob> Integer is entirely defined by the compiler
09:19:20 <beelsebob> it just so happens that the compilers all use gmp
09:19:27 <SamB> well, yes.
09:19:43 <edwardk> beelsebob: *nods* ok, well, ghc et al. need a natively implemented Integer then =)
09:19:51 <beelsebob> why?
09:19:52 <SamB> but a portable implementation would not hurt
09:20:05 <edwardk> i realize it would likely never exceed the gmp's implementation speed
09:20:18 <mux> edwardk: I don't get this subclass thing entirely
09:20:25 <SamB> not for single operations, no...
09:20:53 <edwardk> beelsebob: well, aside from the licensing issue with the fact that using gmp the way haskell does may make gmp etc's licensing illegal, it exposs more opportunities for optimization
09:21:04 <SamB> huh?
09:21:18 <shapr> Honestly, Thomas Jaeger and Derek Elkins should be hired by Microsoft Research and installed in the Cambridge building.
09:21:22 <edwardk> er may make ghc, etc.
09:21:31 <musasabi> A pure Haskell big num library would be fun.
09:21:48 <ibid> edwardk: uh, why?
09:21:48 <SamB> GHC binaries may be covered by the LGPL
09:22:04 <SamB> but that isn't illegal
09:22:17 <beelsebob> it wouldn't make sense though... Integer is part of the language spec, so to implement something in the spec in the language would just make no sense at all
09:22:19 <edwardk> ibid: there are some issues with using the LGPL, because ghc then re-exports the functions as haskell functions through the ghc-api, etc.
09:22:35 <SamB> edwardk: eh?
09:22:50 <edwardk> beelsebob: well, the prelude is written in haskell =)
09:23:03 <SamB> does it export them as-is?
09:23:04 <beelsebob> the very basics of it are not
09:23:07 <beelsebob> + is not
09:23:10 <edwardk> beelsebob: there is nothing saying it can't be implemented in terms of more fundamental primops
09:23:17 <SamB> beelsebob: sure it is!
09:23:36 <ibid> edwardk: uh, what?
09:23:52 <beelsebob> SamB: every compiler I've ever seen just uses the implementation language's plus
09:23:54 <edwardk> ibid: which part?
09:24:05 <SamB> beelsebob: "just"?
09:24:09 <LordBrain> if ghc is covered by the lgpl, then thats good... unless you're microsoft, right?
09:24:16 <beelsebob> SamB: ?
09:24:20 <edwardk> beelsebob: ghc definitely doesn't just use c's + operator =)
09:24:35 <beelsebob> edwardk: what does it use then?
09:24:38 <musasabi> LGPL is not very nice for Haskell
09:24:39 <SamB> LordBrain: anyway it only affects binaries
09:24:55 <SamB> but, that is still not good
09:24:58 <LordBrain> it wouldn't effect the programs you compile tho
09:25:04 <SamB> it would
09:25:08 <LordBrain> oh?
09:25:12 <edwardk> beelsebob: it use it when appropriate for unboxed ints, etc. but how many of the integers in your program are unboxed?
09:25:23 <SamB> because the base library uses GMP
09:25:26 <SamB> for Integer
09:25:31 <ibid> edwardk: there wasn't more than one part :)
09:25:34 <musasabi> Minimal licensing fuss is optimal
09:25:47 <edwardk> musasabi: yeah considering it then devolves to the gpl when its used as an application =/
09:26:15 <SamB> edwardk: fortunately the GMP library isn't an application...
09:26:29 <edwardk> ibid: well, lgpl, Integer, fusion, etc. =)
09:26:40 <musasabi> SamB: yes. Of course static linking causes problems
09:26:47 <ibid> edwardk: i was referring to your last line addressed to me
09:26:50 <edwardk> samb: no, but ghc is.
09:26:52 <edwardk> ibid: ah
09:27:04 <SamB> musasabi: GHC is just another program built with GHC, though
09:27:19 <SamB> so it isn't any worse for GHC than for other programs
09:27:22 <edwardk> anyways
09:27:25 <musasabi> True.
09:27:25 <edwardk> its not so bad
09:27:37 <musasabi> But I don't like the situation for other programs either.
09:27:42 <SamB> sure
09:27:50 <edwardk> it just means that to maintain separation the code should be modified so that libgmp can be swapped out for an equivalent library
09:27:55 <SamB> I guess my point is that the *source* is unaffected
09:27:57 <musasabi> Free is dynamically linking, but LGPL hell if statically linked.
09:28:04 <lispy> so i can or cannot staticly link a closed source haskell program compiled by ghc?
09:28:06 <edwardk> you don't need to actually us the other library, just put another one in on equal footing
09:28:13 <edwardk> that plugs the licensing gap.
09:28:16 <SamB> lispy: you can
09:28:21 <SamB> just don't give it to anyone
09:28:24 <SamB> ;-P
09:28:50 <musasabi> lispy: you can. It involves creating lump .o files, stripping them etc. And of course it will have zero help for anyone else and lots of work for you.
09:29:07 <dcoutts_> the usual thing to do is compile your app but just dynamically link with libgmp
09:29:10 <dcoutts_> it's not hard
09:29:19 <dcoutts_> and that's what happens by default
09:29:27 <lispy> well, i know ghc will build it, but i meant legally. this licensing discussion is confusing to me :)
09:29:34 <dcoutts_> I've never seen the fuss
09:29:36 <musasabi> dcoutts_: on windows having a single exe without external dependencies is very nice.
09:29:51 <SamB> lispy: the GPL and LGPL don't cover building anyway
09:29:54 <dcoutts_> musasabi, just bung the .dll in the same directory, like every other app does
09:29:54 <SamB> only distribution
09:30:02 <beelsebob> on the Mac side, having a single app but with deps in it is very nice
09:30:04 <tibbe> if I want to release something I made under the BSD license, what the heck do I put as organization, there's no organisation, just me :)
09:30:10 <edwardk> the lgpl allows static linkage as long as you also distribute the object and source files so that the end user can link against a new version of the library.
09:30:15 <ibid> lispy: the main thing is, an user must be able to switch libgmp to any library implementing the same interface
09:30:17 <SamB> so, if you gave your closed-source program to people in source form, it would be fine...
09:30:21 <musasabi> dcoutts_: and write an installer etc. Having a single exe-file that does not need to be installed is much nicer.
09:30:28 <mux> tibbe: you don't need to put an organization
09:30:34 <SamB> (presumably the license would forbid further redistribution)
09:30:44 <musasabi> SamB: that is usually not possible due to legal complications.
09:30:46 <dcoutts_> musasabi, sure, though in practice most windows apps are more than a .exe too
09:30:53 <dcoutts_> and need an installer etc
09:30:53 <edwardk> but of course, this tightens the more liberal terms of the BSD license.
09:30:57 <SamB> musasabi: what complications?
09:31:01 <tibbe> mux, but the template has a slot for it ;) and besides I don't know what I can remove
09:31:14 <mux> tibbe: show me the template you're using
09:31:16 <tibbe> http://www.opensource.org/licenses/bsd-license.php
09:31:16 <lispy> so, then my closed source program has to dynamically link in libgmp to be truely closed source?
09:31:18 <lambdabot> Title: Open Source Initiative OSI - The BSD License:Licensing
09:31:23 <musasabi> SamB: like legal agreements "Our company will not distribute this further in source form"
09:31:35 <dcoutts_> lispy, that's the simplest thing to do, yes.
09:31:42 <edwardk> lispy: in a nutshell, yes
09:31:49 <musasabi> lispy: yes. Or you have to provide object files that in theory make relinking possible.
09:31:54 <SamB> musasabi: you can't just put that in the EULA?
09:31:56 <mux> tibbe: ok, then you can replace <ORGANIZATION> by author
09:32:02 <edwardk> its why i dislike the gpl, it makes a legal issue into a technology issue.
09:32:08 <dcoutts_> if you want to statically link libgmp then the requirements a more tricky.
09:32:09 <mux> ie Neither the name of the author nor the names of its contribuitors blabla
09:32:13 <edwardk> er (l)gpl
09:32:14 <dcoutts_> so don't bother
09:32:16 <lispy> musasabi: but only upon request?  and we don't have to advertise that we'll provide them?
09:32:30 <mux> tibbe: in FreeBSD we don't even use this clause anymore
09:32:40 <musasabi> SamB: no. If the company agrees not to distribute foo source that does not mean they can distribute foo source and just say in EULA "please don't copy this".
09:32:47 <dcoutts_> lispy, no, you must note that the offer is available
09:32:50 <SamB> lispy: not if you don't count the GPL as advertisement...
09:32:52 <tibbe> mux, ok thanks
09:33:18 <musasabi> But for licensing things consult your lawyer.
09:33:22 <tibbe> mux, what license does GHC use?
09:33:27 <dcoutts_> BSD3
09:33:37 <lispy> huh, this is all interesting...i had been building with -static turned on, so i guess i'll make sure the dynamic build works too since that's probably what we'll want to distribute
09:33:46 <mux> tibbe: http://www.freebsd.org/cgi/cvsweb.cgi/~checkout~/src/share/examples/etc/bsd-style-copyright?rev=1.10&content-type=text/plain
09:33:53 <mux> GHC still uses t he non-advertising clause
09:34:09 <edwardk> lispy: i suppose if you distribute both static and dynamic builds you should be safe
09:34:20 <edwardk> since you will then be allowing the end-user to link against the new version of the library
09:34:35 <edwardk> and it avoids the whole open/closed mess.
09:35:11 <musasabi> edwardk: that should be fine in theory. But by legal interpretation that can be illegal
09:35:22 * mux bbl &
09:35:33 <edwardk> musasabi: checking the license again.
09:35:39 <shapr> I really really wish that software would always be released as open source when everyone is finished using it, or when the company goes out of business.
09:35:44 <SamB> musasabi: why?
09:35:51 <musasabi> edwardk: static and dynamically linked versions are different versions.
09:36:02 <lispy> i doubt any user of our software would ever notice if we violated this libgmp licensingthing, but it's good to stay honest
09:36:14 <edwardk> musasabi: i'm afraid you're probably right =/
09:36:14 <SamB> shapr: obviously that would be useless if everyone was *really* finished using it
09:36:16 <lispy> shapr: yeah
09:36:28 * musasabi just wants to share code with the least legal mess possible
09:36:44 <lispy> shapr: or anything that's orthoganol to the company's business
09:36:59 <SamB> how about "if nobody was selling it"
09:37:02 <tibbe> I just want a simple license that allows anyone to use my web server and protects me from any mishaps they might have
09:37:03 <shapr> Fair enough
09:37:07 <edwardk> yeah.
09:37:18 <lispy> i can see why some businesses would want to keep certain compontents closed source for competetive advantage, but it would be nice if they had the thought to open the source to the rest of their code
09:37:20 <edwardk> and everyone wonders why I am anti-GPL =)
09:37:28 <shapr> I just get irritated when I see how many good chunks of code will forever be closed source.
09:37:29 <edwardk> but pro F/OSS =)
09:37:34 <SamB> shapr: yes
09:37:36 <shapr> We're losing our culture.
09:37:52 <edwardk> tibbe: check out the apache public license
09:37:58 <edwardk> or bsd3
09:38:00 * lispy should run to work
09:38:00 <shapr> Where's the source for all the PDP-11 programs? Or the KPRO?
09:38:22 * lispy nods
09:38:27 <shapr> At least an older version of the LispM source was found and released recently.
09:38:44 <edwardk> shapr: heh get a tape reader. =-)
09:38:46 <SamB> sources should be held by the government for safe-keeping, and released in the event that the company died or stopped selling the product for some reason or other...
09:39:40 <lispy> business in the US would never trust the government to hold it
09:39:40 <shapr> Truly. At the moment we're in the middle ages where everything is a trade secret, and the discoveries are lost when the source is gone.
09:40:23 <musasabi> shapr: actually that might not help as much as one might think.
09:40:34 <shapr> No one knows how the Stradivarius violins were made. I hope we don't lose our best discoveries as well.
09:40:37 <musasabi> shapr: we would have lots of old code that would be hard to integrate.
09:40:38 <SamB> (which would also prevent the loss of code that might otherwise have been released as open-source at some point to hard-drive failure, such as the source to ZZT)
09:40:39 * tibbe thinks licensing issues are really, really boring
09:41:00 <SamB> ZZT being the first product of Epic Megagames
09:41:02 <edwardk> my biggest problem with licensing is that GPL becomes the default for anyone deciding to 'give away the code'
09:41:03 <shapr> musasabi: But having the code would teach us lessons, imho.
09:41:03 <scc> supposedly the macpaint source is going to be released
09:41:21 <edwardk> heh
09:41:30 <musasabi> shapr: to a limited extent. I think that creating code that is open from the beginning has more merit.
09:41:36 <SamB> it was written in Turbo Pascal
09:41:45 <edwardk> i've probably lost 3/4ths of the code i've written in my lifetime to accumulatd hardware failures.
09:41:49 <edwardk> sad
09:41:50 <SamB> shapr: at least stradivarious violins are still compatible with Earth
09:41:59 <shapr> musasabi: I've recently decided that culture is just collective insanity, it shapes and warps us more than we think. I'd like to see the code people wrote before there was a programmer culture, when they had to come up with entirely new solutions.
09:42:16 <shapr> musasabi: True, open from the start is best.
09:42:25 <edwardk> heh i tripped over some ancient turbo pascal battletech mech editor i slapped together back in the day the other day. i was appalled. =)
09:42:36 <edwardk> don't have the source to that any more =/
09:43:06 <SamB> ZZT's internals aren't that great either ;-)
09:43:16 <edwardk> heh
09:43:19 <shapr> If proofs were closed source...
09:43:24 <edwardk> but it was neat for its day.
09:43:25 <SamB> they wouldn't be proofs
09:43:47 <SamB> the proof is the source, after all
09:43:52 <shapr> I wonder how long it'll be until some judge has to deal with the CH correspondence.
09:44:23 <edwardk> samb: yeah, besides who needs to close the source on one of them when you can just patent it (RSA comes to mind) =)
09:44:26 <SamB> oh, you talking about proof-carrying code?
09:44:26 <shapr> SamB: Not exactly, iirc many of the top mathematicians (especially number theorists) in the world disappear into the NSA.
09:44:56 <shapr> How many brilliant proofs are classified?
09:45:03 <SamB> well...
09:45:17 <SamB> how would the C/H isomorphism come into it?
09:46:10 <shapr> If I generate a program from a proof, and patent the program, is that legal?
09:46:30 <madpickle> you can't patent software code
09:46:38 <madpickle> you patent a concept or an algorithm
09:46:45 <madpickle> your code is copyrighted, though
09:47:03 <shapr> Ok, can I patent a proof?
09:47:07 <beelsebob> not in this country you can't
09:47:17 <beelsebob> the EU didn't approve software patents
09:47:20 <SamB> and anyone who uses the algorithm is violating the patent whether or not they knew about it?
09:47:21 <madpickle> patent a proof? doubtful.
09:47:33 <edwardk> you would have better luck patenting the logic behind the proof. you then make a number of absurdly general claims that support your proof and the patent office has to knock down all of your  arguments or you get a patent =)
09:47:36 <SamB> madpickle: perhaps if it was in the form of a program...
09:47:41 <SamB> er, algorithm.
09:47:49 <madpickle> sure. unless people show prior art
09:47:51 <SamB> the difference being not a whole lot...
09:47:52 <shapr> So what about writing a proof of a program and then generating a program from the proof. And what if this is a proof of an already patented algorithm?
09:48:13 <madpickle> if you infringe on a patent, you infringe on a patent.
09:48:17 <lisppaste2> asbeta pasted "is there a way to export prelude?" at http://paste.lisp.org/display/24118
09:48:38 <ibid> shapr: patent protects even against independent reinvention
09:48:41 <SamB> put "module Prelude" in the export list, but why would you want to?
09:48:44 <edwardk> shapr: well, patents are about general ideas. you wnt your patent to be as broad as possible, and to make as many claims as you can think of about potential future applications to maximize the splash effect.
09:48:49 <SamB> everything imports Prelude by default anyway
09:48:51 <asbeta> SamB: hiding something
09:49:00 <SamB> hmm
09:49:07 <shapr> Sure, but at some point someone will derive an obvious proof and the result will be patented.
09:49:08 <madpickle> and just because you have a patent it does not meanit would stand up in court
09:49:08 <SamB> maybe if you import it hiding those things, you can...
09:49:18 <madpickle> prior art, shapr
09:49:19 <edwardk> madpickle: doesn't have to
09:49:22 <madpickle> if it's obvious it's probably done before.
09:49:29 <asbeta> SamB: i tried it that way, don't work yet
09:49:32 <edwardk> madpickle: because anyone who tries to tear it down winds up paying the court costs.
09:49:34 <madpickle> edwardk: perhaps not. but if someone were to challenge it, it would
09:49:36 <shapr> Some things are only obvious from the right viewpoint.
09:49:40 <edwardk> you can bludgeon people with junk patents
09:49:41 <SamB> did you also "import Prelude ()"
09:49:42 <madpickle> yeah. so you go up against microsoft
09:49:42 <SamB> ?
09:49:43 <madpickle> or IBM
09:49:48 <madpickle> have fun clinging to your parent
09:49:50 <ibid> even if it has never been done, obviousness is a criterion for not being patentable
09:49:59 <edwardk> madpickle: i've fought the good fight against a patent before, and ran out of money.
09:50:02 <asbeta> SamB: hmm.. no, just import Bootstrap
09:50:05 <ibid> (but this only applies to a priori obviousness)
09:50:10 <shapr> The legal system is the bludgeon.
09:50:13 <edwardk> madpickle: despite 20 years of well documented prior art
09:50:18 <shapr> It is its own punishment.
09:50:19 <madpickle> edwardk: such is life
09:50:23 <madpickle> (unfortunately)
09:50:33 <ibid> shapr: there is no "the" legal system in an international context :)
09:50:40 <madpickle> move to china
09:50:40 <ibid> shapr: which is one of the problems
09:50:46 <edwardk> madpickle: the patent doesn;t have to be good. it just has to exist. the $50k legal hurdle is a sufficient deterrent.
09:50:47 <madpickle> they don't seem to care about anything over there.
09:50:52 <asbeta> SamB: import Prelude () worked, but i'd prefer to go with just import Bootstrap :)
09:51:00 <edwardk> madpickle: that you can stomp all over the little fish
09:51:04 <madpickle> edwardk: of course it doesn't have to be good
09:51:06 <LordBrain> well we do have a semi-pretense of interantional law based on treaties
09:51:10 <madpickle> BT patented the hyperlink, but look whereit got them
09:51:15 <madpickle> some guy in Australia patented the wheel
09:51:23 <SamB> $50k!!!!
09:51:26 <SamB> that is far too much
09:51:39 <SamB> they should be fined!
09:51:48 <edwardk> samb: that was the final estimate of what it wou;d have cost me to win the lawsuit
09:51:49 <ibid> LordBrain: that doesn't create a legal system, which includes courts of law and traditions of law interpretation by courts
09:52:00 <edwardk> samb: i stood to possibly gain about 100k in licensing fees from my software
09:52:15 <edwardk> but i couldn't because someone had effectively patented looking up a vector in a table. =)
09:52:22 <LordBrain> hmmm well there are international courts, they jsut aren't universally recognized
09:52:25 <SamB> what in the ...?
09:52:29 <edwardk> and it was in a directly competing product.
09:52:37 <ibid> LordBrain: and do not have general jurisdiction
09:52:47 <SamB> indexed by vector or by something else?
09:52:50 <edwardk> if you do a patent search on animatek, you'll find the patent
09:52:57 <tibbe> oh, cabal doesn't have MIT as one of it's "supported" licenses
09:52:58 <ibid> LordBrain: all international courts are special courts
09:53:00 <edwardk> indexed by a simple integer. an array of 27 vectors =)
09:53:09 <SamB> you should have found the other patents of this process
09:53:24 <edwardk> just the lookup of a vector in a table is covered by their patent as one of their baseless claims
09:53:51 <SamB> hmm
09:53:57 <edwardk> you can go back 20 years into the demoscene on the c64 for lots of prior art.
09:54:06 <asbeta> looks like you have nothing to do but submit patents yourself :)
09:54:07 <shapr> Hm, so I could sell the proof of a patented algorithm along with Coq so people could generate the code on their own computer.
09:54:15 <shapr> Then I wouldn't be breaking the law, and neither would they.
09:54:31 <ibid> shapr: you probably would be
09:54:36 <SamB> they shouldn't be allowed to have judges that don't know how to program try these cases
09:54:47 <madpickle> SamB: unreasonable demand
09:54:56 <madpickle> what about quantum physics, biology, medicine
09:55:04 <madpickle> they are arbitrators of the law
09:55:07 <madpickle> not scientists
09:55:18 <madpickle> YOU are the scientist who has to defend your claim
09:55:28 <edwardk> samb: actually its more the opposite, knowledge of how to program is actually detrimental in some cases to the judge's legal arguments, because the aggrieved party can claim bias. =)
09:55:33 <SamB> well, they don't seem to get how obvious looking up something in a table is
09:55:38 <SamB> no matter what it is
09:55:39 <ibid> shapr: courts don't interpret law as a program, you can't survive using a legal fiction unless it is backed by the state
09:55:49 <shapr> hmm
09:56:15 <Stinger_> who decides the technical merits of the case if the judge can't?
09:56:16 <int-e> oh. that gives a whole new meaning to 'unbiased' "We want a clueless person judging our case."
09:56:20 <basti_> are you debating post-modernism here?
09:56:25 <SamB> but if it is just a proof and a tool that can program, what is the problem?
09:56:29 <basti_> like in "solipsism" or "relativism"?
09:56:36 <SyntaxNinja> hi shapr
09:56:37 <eivuokko> int-e, lol :D
09:56:40 <edwardk> stinger: well, that has been used as an appellate argument in the past successfully.
09:56:46 <shapr> hi SyntaxNinja!
09:56:50 <edwardk> it came up when i brought up the issue to my lawyer =/
09:56:53 <ibid> Stinger_: the judge does based on the evidence presented by both parties
09:56:55 <madpickle> judges are rarely clueless. but you cannot expect them to have knowledge in any- and everything
09:57:05 <SamB> it is impossible to present a reasonable argument to someone who is clueless
09:57:05 <madpickle> and if it really is so simple it should be a simple point to argue. but legal cases cost $$$
09:57:13 <basti_> -> #haskell-blah maybe?
09:57:18 <madpickle> SamB: i dare you to argue law with a supreme court judge
09:57:20 <ibid> Stinger_: which means getting expert witnesses to your side
09:57:36 <SamB> madpickle: I'm not saying they are clueless about law
09:57:40 <shapr> Sorry, I shouldn't have started a legal system flamewar :-(
09:57:42 <madpickle> SamB: you are.
09:57:53 <shapr> Hey, I have a thoroughly academic question.
09:57:55 <madpickle> if judges are clueless about IT and physics and whatnot
09:57:55 <SamB> but how in the world are they going to understand the concept of "obvious"?
09:58:02 <shapr> Is there a way to measure change?
09:58:05 <madpickle> but are required to know it
09:58:09 <madpickle> hen you ought to know law, right?
09:58:09 <SamB> if they don't have a basic understanding of the subject?
09:58:10 <tibbe> I need a regex library, which one should I use, the one in the GHC libraries or the Text.Regex.Lazy one?
09:58:11 <edwardk> im kinda with basti on moving this discussion to #haskell-blah
09:58:18 <SamB> well, not the concept
09:58:21 <madpickle> anywho, i digress.
09:58:21 <SamB> but the application...
09:58:24 <ibid> SamB: you throw an expert witness at it
09:58:39 <Stinger_> madpickle ignorance of the law is no excuse. :P
09:58:44 <SamB> how about random 12-year-olds?
09:59:05 <SamB> that know a thing or two about programming
09:59:05 <shapr> Ok, no more legal system and/or patent discussion!
09:59:08 <Stinger_> granted I'm not sure how that applies to civil :)
09:59:09 <madpickle> so how about dem knicks?
09:59:12 <basti_> -> #haskell-blah
09:59:25 <SyntaxNinja> have the ICFP 2006 pages been down?
09:59:29 * ibid notes idly that he has sat behind the bench for a year and a half now as a lay judge (criminal cases only, and always part of a four-judge panel, including one legally trained president)
09:59:30 * shapr doesn't know
09:59:49 <edwardk> ibid: my condolences =)
10:00:08 <ibid> edwardk: it is actually one of the best experiences i've had
10:00:09 <shapr> Anyway, I'm trying to find a way to *exactly* measure the change complexity of a particular abstraction.
10:00:12 <madpickle> let's not be condescending.
10:00:16 <edwardk> ibid: fair enough
10:00:22 <madpickle> i am sure ibid did it because he wanted to, and thoroughly enjoyed it
10:00:39 <edwardk> i thought about going into patent law, but then basically discovered that learning patent law would be about the worst thing i could do to myself as a programmer
10:00:42 <ibid> well. i was asked to
10:00:54 <ibid> but the idea intrigued me
10:01:24 <madpickle> anywho - thanks for the discussion, guys.
10:01:31 * ibid sometimes thinks about switching to law :)
10:02:10 <shapr> I have this idea that the parts of the code you need to think about when changing stuff inside an abstraction is important.
10:02:27 <shapr> For example, each object can affect all others, but monad transformers only need to know what's in their stack.
10:02:46 <shapr> This seems obviously simpler, but I want to figure out how to directly measure the complexity of change.
10:04:06 <shapr> Does anyone know of any references that describe ways to measure change?
10:04:18 <shapr> I can't directly apply computational complexity, but it is the right measurement...
10:07:31 <scc> I don't understand, if the change is inside an abstraction isn't the change limited to this 'inside' by definition of abstraction?
10:08:04 <SamB> shapr: what is this about monad transformers needing to know what is in their stack?
10:08:10 <scc> in general too vague for me :(
10:10:54 <shapr> SamB: Your customers ask for a new feature.
10:11:01 <shapr> You need to change your program.
10:11:19 <shapr> Which would require less mental effort, a program written with monads or one with objects?
10:11:46 <SamB> probably depends on the feature
10:12:03 <ibid> i don't think those are opposites
10:12:03 <shapr> I think the complexity of change can be directly measure.
10:12:18 <SamB> well, maybe
10:12:30 <shapr> The simplest approach is, in the code I need to change, what else is at the same abstractional level? What else might I break?
10:12:45 <SamB> but who cares about the complexity of change? isn't the complexity of figuring out what to change more important?
10:13:02 <shapr> Not necessarily.
10:13:11 <SamB> anyway...
10:13:28 <shapr> http://c2.com/cgi-bin/wiki?ScreechinglyObviousCode says that maintenance programmers tend to have a very vague idea of the rest of the code.
10:13:29 <SamB> I suppose people are more likely to ask for the sorts of features monads tend to help with...
10:13:33 <lambdabot> Title: Screechingly Obvious Code
10:13:34 <SamB> allpervading ones
10:14:16 <SamB> shapr: I am puzzled as to how that contradicts what I said
10:14:19 <shapr> scc: Yeah, a change inside an abstraction is limited to this 'inside', so maybe the question is, how to measure the insides that an abstraction can delimit?
10:15:39 <SamB> well, anything that uses the constructors and functions that are not part of the external interface of the abstraction?
10:15:49 <shapr> SamB: The simpler it is to make a change, the less likely it is to break something else.
10:16:00 <SamB> yeah
10:16:27 <shapr> So I think that complexity of change overlaps with complexity of figuring out what to change.
10:16:33 <SamB> hmm
10:16:39 <SamB> yes, probably
10:16:45 <SamB> because they are interwoven
10:16:56 <SamB> but I think this makes it hard to measure...
10:17:25 <SamB> (how do you measure thinking? especially how do you measure thinking about a given problem?)
10:18:13 <shapr> I don't know. But if I can measure changes to code, I can measure that on both object and monad abstractions.
10:18:48 <scc> so you want to measure the the difficulty of changing various concrete implementations of the same abstract specification when that specification changes?
10:19:07 <shapr> Yeah, that's the only approach I can come up so far.
10:19:19 <SamB> yes, but the complexity of *making* the changes is not evident in the delta
10:19:42 <scc> sounds very tricky
10:19:45 <shapr> In some ways it is.. I can compare the changes to the ASTs.
10:20:49 <SamB> you would need to track the walk through the code as the programmer decided what to do...
10:21:23 <scc> the more I think about it the trickier it gets
10:21:57 <shapr> Test driven development has step zero as "refactor the code in the direction of the feature you're about to write." then you write the test and the code that solves that test.
10:22:31 <shapr> I want to see if I can measure whether various abstractions make that refactoring simpler.
10:22:41 <shapr> For example, subroutines obviously do that.
10:23:12 <shapr> That is, in the case of zero abstractions vs subroutines, subroutines obviously make a specified refactoring simpler.
10:24:30 <scc> I would think you would first need a good definition of a qualifying abstraction
10:24:50 <shapr> I guess jump/goto is the first abstraction, yeah?
10:24:55 <shapr> Otherwise *everything* is inline.
10:25:48 <Cale> Well, you won't have Turing completeness without the ability to repeat code.
10:26:16 <scc> so part of the definition is no change in power
10:26:46 <shapr> Can turing machines repeat code?
10:27:15 <Cale> yeah
10:27:17 <beelsebob> yes
10:27:49 <Cale> They're essentially fancily labelled graphs, and cycles in those graphs will lead to repeated code.
10:28:01 <SamB> fancilly labeled graphs?
10:28:12 <ookk> is there a function that tests values in a list for some condition that stops and returns true if the condition is true or false if all values of the list failed the condition?
10:28:16 <Cale> Do you know what a DFA looks like?
10:28:32 <SamB> ookk: you mean like any?
10:28:36 <psnl> http://www.hermann-uwe.de/node/1062 can we have haskell programmers above Lisp prgrammers?
10:28:39 <lambdabot> Title: Programmer Hierarchy | Uwe Hermann
10:28:47 <SamB> > any id [False, False, True]
10:28:48 <lambdabot>  True
10:28:57 <SamB> > any id [False, False]
10:28:57 <ookk> ahh thx :)
10:28:58 <lambdabot>  False
10:29:03 <ookk> that was what i was looking for
10:29:24 <SamB> there is a similar function called all
10:30:09 <SamB> which returns True only if all the items meet the condition
10:30:29 <Cale> A Turing machine is a directed graph, with some vertex marked as a start state, and edges marked with possible values on the tape, together with optionally a movement of the tape head and optionally a symbol to write.
10:30:31 <ookk> okay but that is not what i want
10:30:43 <ookk> any is perfect .)
10:30:46 <SamB> ookk: I just thought you might want it later
10:31:04 <ookk> im using it for a prime check
10:31:05 <ookk> prime n = not $ any ((0==).(mod n)) (takeWhile ( < int_sqrt n ) primes)
10:31:05 <ookk> primes = 2 : [n | n <- [3..], prime n]
10:31:58 <SamB> of course, many if not most of the library functions would be easy to write yourself
10:32:26 <SamB> but maybe not so easy to name ;-)
10:32:34 <ookk> hehe
10:32:44 <ookk> but i guess those functions are implemented in C or?
10:32:50 <SamB> nope
10:33:06 <ookk> okay so then i should be able to write an equally fast function myself?
10:33:15 <SamB> well, I mean, if the Haskell implementor was crazy it could be in C if they wanted
10:33:25 <SamB> but they'd have to, um, be crazy ;-)
10:33:51 <ookk> heh
10:34:53 <scc> shapr, you would also need a notion of change at the specification level first no?
10:35:11 <scc> or could after all completely change
10:35:16 <scc> it
10:36:38 <SamB> well... it wouldn't be needed but it might be of interest...
10:36:39 <shapr> Yeah, that's true.
10:36:58 <SamB> at least, not absolutely needed...
10:37:24 <SamB> I suppose it helps to weight the complexities of the changes in implementations
10:38:03 <SamB> or unweight or whatever
10:38:54 <SamB> ookk: now, a few library functions must of course use things not written in Haskell...
10:39:09 <shapr> scc: I'd like to find out any prior research focussed on measuring change or abstraction.
10:39:10 <SamB> such as the I/O and arithmatic stuff
10:39:23 <shapr> I found a cool paper by the 'pigs in blankets' guy, but it's not very detailed.
10:40:02 <scc> pigs from sausages?
10:40:14 <shapr> You mentioned him yesterday.
10:40:21 <scc> yea
10:40:22 <shapr> yes, that's it :-)
10:44:49 <shapr> Anyway, I'll be back later.
10:46:59 <dmhouse> Anyone read Bulat's 'class []' proposal on [Haskell-cafe]?
10:48:08 <ValarQ> dmhouse: i did
10:49:23 <dmhouse> ValarQ: thoughts?
10:49:39 <dmhouse> I'd personally oppose strongly his syntax ideas.
10:49:57 <dmhouse> I think it's inelegant, unclear and it breaks backward compatability.
10:50:03 * ValarQ to
10:50:25 <ValarQ> either do it to everything, tuples, records etc, or nothing
10:52:49 <ValarQ> and i don't like classes named exactly as types
10:55:24 <dmhouse> No, those were my comments.
10:56:18 <dmhouse> It's very unclear: does 'Num' mean a type or a class? And therefore it's also backward incompatible.
11:15:17 <dmhouse> ?where report
11:15:17 <lambdabot> I know nothing about report.
11:15:24 <dmhouse> ?google haskell report
11:15:27 <lambdabot> http://www.haskell.org/onlinereport/
11:15:27 <lambdabot> Title: The Haskell 98 Language Report
11:15:38 <dmhouse> ?where+ report http://www.haskell.org/onlinereport/
11:15:38 <lambdabot> Done.
11:20:10 <edwardk> class []?
11:20:14 * edwardk goes off to read
11:25:06 <Klauso> @pl \x -> x
11:25:06 <lambdabot> id
11:25:26 <Klauso> \n m -> rem n m == 0
11:25:39 <Klauso> @pl  \n m -> rem n m == 0
11:25:39 <lambdabot> flip flip 0 . ((==) .) . rem
11:27:21 <monochrom> "flip flip" reminds me of the Swedish Chef in the Muppets Show.
11:27:36 <Klauso> hi there
11:27:54 <Klauso> I just wanted to make some experiments in pointless style :-)
11:28:31 <edwardk> @type flip flip
11:28:32 <lambdabot> forall a c b. b -> (a -> b -> c) -> a -> c
11:29:05 <dmhouse> Klauso: that's a classic example of when _not_ to use pointsfree :)
11:29:14 <edwardk> heh
11:29:19 <dmhouse> It's a simple, readable lambda expression and the PF version is horrific.
11:29:38 <Klauso> I was thinking about how it would look like in PF style and I could'nt come up with a solution
11:29:39 <dmhouse> (Although for optimum readability I'd prefer to use rem infix.)
11:29:53 <dmhouse> xerox: your services are required!
11:29:55 <edwardk> most of the time that ponts free starts using (foo.) .  etc it just goes off the deep end
11:29:59 <int-e> @type flip flip 0 . ((==) .) . rem
11:30:01 <lambdabot> forall a. (Integral a) => a -> a -> Bool
11:30:16 <Cale> It's more common to want mod than rem
11:30:34 <Klauso> does @pl produce "optimal" code in some sense or can I expect that "hand optimization" would yield better PF code?
11:30:34 <Cale> (-12) `rem` 5
11:30:37 <Cale> >(-12) `rem` 5
11:30:39 <Cale> > (-12) `rem` 5
11:30:41 <lambdabot>  -2
11:30:42 <dmhouse> Klauso: depends.
11:30:50 <dmhouse> Sometimes the former, sometimes the latter.
11:31:00 <dmhouse> For example, in situation, I can tell you that @pl was a little inefficient.
11:31:06 <int-e> for comparing with 0, rem is probably better
11:31:14 <dmhouse> \n m -> n `rem` m == 0
11:31:26 <dmhouse> \n m -> (==0) (rem n m)
11:31:34 <flux__> there should be @pointy, or @unpl, too ;-)
11:31:55 <dmhouse> \n m -> ((==0) . rem n) m
11:31:59 <edwardk> flux: i'm sure dons would welcome it if you wrote it =)
11:32:06 <Cale> int-e: really?
11:32:06 <flux__> that sounds like work ;)
11:32:11 <int-e> Cale: slightly faster
11:32:16 <dmhouse> \n m -> (((==0) .) . rem) n m -- I think. Not too sure.
11:32:24 <dmhouse> ?type (((==0) .) . rem)
11:32:26 <lambdabot> forall a. (Integral a) => a -> a -> Bool
11:32:38 <Cale> int-e: They should be the same, except I'd expect mod to have better low-level support.
11:32:41 <edwardk> its div/mod vs quot/rem in haskell right?
11:32:47 <Cale> yeah
11:32:51 <dmhouse> But \n m -> n `rem` m == 0 is way nicer :)
11:32:54 <edwardk> for rounding towards neg infinity vs. zero?
11:33:15 <int-e> Cale: rem has better low-level support for ints on x86. I'd have to check gmp but I believe it's the same there.
11:33:30 <Cale> edwardk: quot/rem allow negative remainders, div/mod don't
11:33:37 <int-e> Cale: the reason being that programmers are lazy and treat the sign separately.
11:33:37 <Cale> int-e: bizarre
11:33:42 <edwardk> yeah
11:34:04 <Cale> > (-12) `rem` 5
11:34:05 <lambdabot>  -2
11:34:08 <Cale> > (-12) `mod` 5
11:34:10 <lambdabot>  3
11:34:22 <dmhouse> (Of course, -2 and 3 are identical mod 5 anyway.)
11:34:42 <Cale> Well, yes, that'll always be true of them :)
11:34:43 <SamB> hmm, apparantly the problem with my code is in the logic for reading a string...
11:35:06 <Cale> int-e: so the hardware actually produces signed results for integer remainder?
11:35:08 <edwardk> dmhouse: sure, but mathematically i'm used to the div/mod formalism. coz then you know that div yields the classical division algorithm answer for q.
11:35:09 <int-e> Cale: but in general if the difference really matters you probably don't want to use haskell :)
11:35:14 <int-e> Cale: yes
11:35:27 <Cale> interesting
11:35:40 <int-e> Cale: for signed operands anyway, and my knowledge is limited to x86 here.
11:36:14 <tibbe> :t unlines
11:36:23 <tibbe> @type unlines
11:36:25 <lambdabot> [String] -> String
11:37:41 <wolverian> negative remainders are nice with date calculations
11:37:42 <edwardk> yeah idiv truncates towards zero, so has quot/rem semantics.
11:37:53 <int-e> Cale: the C standard allows some degree of freedom here, if I remember correctly. % can be mod or rem, and / is the matching counterpart, div or quot.
11:38:10 <Cale> Oh, that's also interesting, and broken.
11:38:19 <edwardk> yep
11:38:39 <edwardk> and perl, and python and ruby all do it one way or the other, etc.
11:38:53 <edwardk> its generally a known clusterfuck =)
11:39:24 <edwardk> i like haskell's answer of offer it both ways clearly
11:39:51 <wolverian> all of ruby, perl and python seem to do it the same way
11:40:06 <edwardk> perl's behavior changes with some compiler flags, be careful
11:40:12 <int-e> hmm, what's java's take on this?
11:40:21 <int-e> or C#?
11:40:23 <wolverian> edwardk, wow. :)
11:40:29 <wolverian> what flag is that, do you remember?
11:40:33 <wolverian> (is it in perl -V?)
11:40:34 <edwardk> if it uses native ints it drops back to c behavior which alters its behavior.
11:40:56 <edwardk> i don't recall, look for something that speeds up ints =)
11:41:11 <wolverian> well my use64bitints is undef
11:41:21 <wolverian> mm. and I get negative remainders.
11:42:32 <wolverian> C gives negatives too.
11:42:47 <wolverian> (gcc)
11:42:48 <edwardk> http://www.davidflanagan.com/mt/mt-comments.cgi?entry_id=101
11:42:51 <lambdabot> Title: davidflanagan.com: Comment on Integer division and negative numbers
11:42:58 <edwardk> i knew i had it bookarked somewhere =)
11:43:02 <Cale> There must be bugs in C code where people were trying to address an array cyclically :)
11:43:35 <edwardk> heh thank you google desktop
11:43:41 <Cale> It seems like a stupid default for programming purposes to allow negative moduli.
11:43:46 <edwardk> i agree
11:44:01 <edwardk> but that may be the math geek in me talking
11:44:12 <edwardk> div/mod seem cleaner than quot/rem
11:44:17 <Cale> much
11:44:48 <edwardk> on the other hand the average joe blanks when he tries to think about why -1 returns n-1.
11:44:49 <Patterner> I vote for div/mod
11:45:02 <Cale> In fact, I have a hard time believing that the hardware really does it that way, but it seems to be the case.
11:45:18 <Klauso> @pl \x y -> - (rem x y)
11:45:18 <lambdabot> (line 1, column 9):
11:45:18 <lambdabot> unexpected "-"
11:45:18 <lambdabot> expecting lambda abstraction or expression
11:45:28 <Patterner> How many average joes use haskell?
11:45:31 <edwardk> cale: has to do with how standard 2s complement binary division works
11:45:35 <int-e> they really treat the sign separately so they only have to deal with positive numbers.
11:45:37 <edwardk> cale: they get it that way for free
11:45:49 <int-e> hmm
11:46:06 <Klauso>  @pl \x y -> 0 -(rem x y)
11:46:07 * edwardk will probably wind up with quot/rem semantics in his binary divider for the type leve arithmetic stuff too
11:46:20 <wolverian> ah. that's not a compiler flag, edwardk :)
11:46:39 <edwardk> wolverian: couldn't remember where it was coming from. yeah its a use declaration
11:46:53 <Klauso> @pl \x y ->42 - (rem x y)
11:46:53 <lambdabot> ((-) 42 .) . rem
11:47:08 <wolverian> yeah, and date calculations are mentioned there too
11:47:17 <edwardk> perl kinda muddies the waters with all the use pragmas
11:47:18 <wolverian> (where perl's behaviour is useful)
11:47:25 * edwardk nods.
11:47:45 <wolverian> thanks for the link.
11:48:13 <wolverian> and, yeah, perl is more of a set of behaviours out from which you construct your language, than a definite language
11:48:23 <wolverian> some people hate that.. :-)
11:48:38 <wolverian> (I make fun of them)
11:48:44 * edwardk is rather fond of that. =)
11:49:18 <wolverian> is has problems, mainly how it doesn't provide a sensible default to certain things (OO).
11:49:25 <int-e> hmm, there's also the possibility to use ssh ... ssh ..., but I suspect that doesn't combine well with scp.
11:49:26 <Cale> s/construct/choose/?
11:49:34 <edwardk> haskell sometimes reminds me of that with its surfeit of operators though.
11:49:35 <int-e> wrong channel
11:49:38 <wolverian> Cale, right.
11:49:41 <edwardk> wolverian: yeah
11:49:55 <wolverian> Cale, where you choose n behaviours, where n >= 1
11:50:25 <edwardk> wolverian: they are trying to fix that though
11:50:36 <edwardk> wolverian: javascript is even trying the same trick
11:50:48 <edwardk> wolverian: and haskell lacks sensible OO too, so thats not saying much =)
11:51:09 <work_metaperl> CosmicRay, check it out: http://antwrp.gsfc.nasa.gov/apod/astropix.html
11:51:11 <lambdabot> Title: Astronomy Picture of the Day
11:51:37 <wolverian> edwardk, right. perl6 is a lot saner than perl5.
11:51:51 <wolverian> and js2 looks pretty similar.
11:51:56 <Cale> Well, I think sensible OO is coming (or is here, depending on how you define sensible), though it's not going to look quite like OO in other languages.
11:52:09 <wolverian> Cale, in _any_ other language? :)
11:52:20 <Cale> I don't know about that
11:52:34 <Cale> But any other popular language, sure.
11:52:37 <monochrom> @pl \(n,m) -> f(n,m) == 0
11:52:37 <lambdabot> uncurry (flip flip 0 . (((==) . f) .) . (,))
11:52:51 <monochrom> @pl \(n,m) -> f n m == 0
11:52:51 <lambdabot> uncurry (flip flip 0 . ((==) .) . f)
11:52:54 <wolverian> Cale, ah. where can I read about the OO?
11:53:00 <Cale> Existential types give you the core functionality of OO, as far as I'm concerned.
11:53:20 <wolverian> right
11:53:22 <edwardk> cale: they aren't extensible though. so you still have to do crappy little tail chaining of records =(
11:53:32 <edwardk> cale: they lack a critical feature for actual use
11:54:13 <Cale> hm?
11:54:52 <edwardk> cale: did you read the OOHaskell paper?
11:54:58 <Cale> yeah
11:55:18 <edwardk> the same arguments there haven't really been addressed. they just made finnding th fixpoint easier.
11:55:22 <edwardk> that wasn't a problem =)
11:56:37 <Cale> Well, existentials allow you to "encapsulate", by throwing away information about implementation and giving you values which you can only interact with through a specified set of interfaces.
11:57:05 <edwardk> cale: but i can't subclass and just extend an interface without building a new record completely.
11:57:12 <edwardk> or exposing a delta interface of some sort
11:57:19 <edwardk> its pretty broken OO
11:57:35 <int-e> you scrambled some words there *ducks*
11:57:49 <Cale> hm?
11:57:53 <int-e> . o O ( OO is pretty broken. )
11:57:57 <edwardk> heh
11:58:28 <Cale> You can just extend an interface by having a second class which implements the extension.
11:58:59 <edwardk> all of the problems from section 3 of the OOHaskell paper with using haskell records still hold with the fairly minor extension granted.
11:59:25 <edwardk> cale: you have to admit that yields a pretty crappy interface =)
11:59:42 <SamB> Cale: well... but then you need whole new existentials
11:59:45 <Cale> I don't know. I think it could be quite usable.
12:00:29 <Cale> Well, either you're making a guarantee of a particular interface, or you aren't, so I don't see having separate existentials as a problem.
12:00:38 <edwardk> i find it about as bad as the carrying of all of the type parameters around because we don't have class associated types. its USABLE, but it actively gets in my way of doing anything productive
12:00:55 <Cale> what?
12:01:03 <Cale> What are you referring to there?
12:01:17 <SamB> it seems like it would lead to a lot of boilerplate...
12:02:14 <edwardk> well, the other example comes from the fact that if i want a flexible enough type for say, a type that uses a different reference and array type depending on the monad its instantiated in i need something like data VHash m a r k v for the type, even if a and r are dependant on m or some typeclass.
12:02:56 <edwardk> the signature of the type depends too much on the internals. using the interfaces the way you propose actively gets in the way of refactoring code
12:03:10 <edwardk> it makes it harder to break apart interfaces, refactor to add a superclass, etc.
12:04:05 <CosmicRay> work_metaperl: nifty, thanks!
12:04:06 <edwardk> all things that people in java have done painlessly for years.
12:04:33 <xerox> dmhouse: sorry? :)
12:04:37 <edwardk> there is something to be said for not just going your own way because you can, but looking for a clean abstraction that doesn't throw the baby out with the bathwater =)
12:04:52 <dmhouse> xerox: Ah, sorry, someone wanted a pointsfree derivation explaining.
12:04:53 <edwardk> not to painfully mix metaphors or anything =)
12:05:01 <xerox> dmhouse: oh cool!
12:05:02 <int-e> how about this, http://int-e.home.tlink.de/haskell/ArrayM.hs - it chooses appropriate array types for IO or ST.
12:05:12 <xerox> dmhouse: which where what how? :)
12:05:32 <Cale> Well, I don't really see exactly why it should make things any harder to work with than they are in Java, but okay. :)
12:05:59 <dmhouse> ?pl \n m -> n `rem` m == 0 -- I pl'd this to (((==0) .) . rem), which also works, and is simpler.
12:05:59 <lambdabot> flip flip 0 . ((==) .) . rem
12:06:14 <edwardk> int-e: been there, wrote that as well, but it doesn't make the types simpler =)
12:06:17 <xerox> Oh I see.
12:06:20 <Cale> (I also don't see how anything could be done painlessly in Java, but that's something else ;)
12:06:33 <xerox> dmhouse: right, I'd do that too.
12:06:45 <SamB> perhaps Java wasn't the best example ;-)
12:07:02 <edwardk> int-e: regardlesss of what classes i have floating around a TYPE that depends on that array and monad has to lug around another parameter.
12:07:14 <xerox> dmhouse: also, I am using the section (x==) more than (==x), duncan et all were complaining that the latter one difficultier to optimize, for some reason.
12:07:38 <SamB> xerox: huh?
12:07:43 <dcoutts> xerox, no, that was only our problem with RULES matching
12:07:45 <work_metaperl> CosmicRay, sure
12:07:47 <work_metaperl> :)
12:07:52 <xerox> Right, in a very specific context
12:07:58 <SamB> oh
12:08:01 <syntaxfree> it's amazing how much you can learn just by browsing the GHC docs.
12:08:02 <Cale> xerox: the latter uses flip
12:08:03 <dcoutts> xerox, we can't match operator sections with ghc RULES
12:08:10 <xerox> Right.
12:08:17 <SamB> dcoutts: you can't?
12:08:20 <xerox> Cale, that's true too.
12:08:23 <dcoutts> Cale, except it doesn't, it uses a lambda, and we can't match lambdas
12:08:24 * syntaxfree do notation considered harmful.
12:08:30 <SamB> it uses a lambda?
12:08:32 <SamB> why!!!
12:08:50 <dcoutts> because that's how the desugaring is defined in Haskell98
12:08:52 <edwardk> syn: heh
12:09:04 <Cale> Really? I thought it was defined using flip
12:09:05 <dcoutts> and actually it's not necessarily the same as using flip
12:09:05 <SamB> dcoutts: why!!!!
12:09:11 <SamB> oh?
12:09:13 <dcoutts> eg runST $ do ...
12:09:24 <SamB> runST?
12:09:30 <edwardk> because of strictness?
12:09:31 <xerox> You see, in the end is better to do x== sections. :)
12:09:33 <SamB> hmm...
12:09:36 <xerox> Because of the forall.
12:09:37 <dcoutts> no, because of the type
12:09:40 <edwardk> ah
12:09:40 <dcoutts> right
12:09:47 <Cale> oh, it is
12:09:52 <int-e> dcoutts: something like that works with the new boxy types.
12:09:57 <Pupeno> Is some distributed haskell working ?
12:10:01 <dcoutts> int-e, cool
12:10:10 <Cale> (op e) 	 = 	 \ x -> x op e
12:10:10 <Cale> (e op) 	= 	\ x -> e op x
12:11:03 <syntaxfree> I postponed learning about monads forever because do notation enabled me to do basic IO.
12:11:05 <int-e> the second can be matched by  e op  in rules; the first can't be matched.
12:11:10 <xerox> ^_^
12:11:23 <int-e> that's dcoutts' and dons' problem, as I understand it.
12:11:57 <monochrom> Evil!
12:12:03 <xerox> (!)
12:12:18 <monochrom> This hurts my heart
12:13:50 <musasabi> Pupeno: for what values of working?
12:13:58 <SamB> syntaxfree: well... at least you didn't feel that you couldn't use Haskell because you did not understand monads
12:14:17 <Pupeno> musasabi: up to be able to replace Erlang.
12:14:23 <musasabi> no
12:14:23 <dcoutts> int-e, no, neither can be matched
12:14:28 <dcoutts> because both are lambdas
12:14:42 <int-e> dcoutts: I though eta-expansion is done when matching?
12:14:44 <musasabi> Pupeno: I think erlang is one of the best distributed things out there.
12:14:46 <int-e> *thought
12:14:52 <syntaxfree> SamB: OTOH, I felt that working with random numbers was impossible because I didn't know monads.
12:14:53 <dcoutts> int-e, hm, maybe
12:14:53 <Pupeno> musasabi: me too.
12:14:56 <SamB> why are they both lambdas?
12:15:08 <dcoutts> SamB, that's how they are desigared
12:15:11 <SamB> syntaxfree: oh, well, even without monads you can sort of do it
12:15:11 <syntaxfree> And if there was a do notation, it must have meant that monads are really abstract over the wall stuff.
12:15:21 * dcoutts -> shops
12:15:28 <syntaxfree> They're not, they're just functors with some sort of structure.
12:15:29 <SamB> its just that monads enable you to abstract them, I guess...
12:15:33 <musasabi> Pupeno: distributed haskell things miss the enteprise parts, even if they are very nice from an academic pov
12:15:43 <int-e> 'The pattern (rule), but not the expression, is eta-expanded if necessary. (Eta-expanding the expression can lead to laziness bugs.)'
12:16:13 <monochrom> You can use "randoms"
12:16:21 <Pupeno> musasabi: at work we are re-doing half Erlang in Python because the people who started the project didn't know about Erlang, so, I am going to seriously propose using Erlang... but I like Haskell better, so, if Haskell can do what Erlang can do, I'd give it a try.
12:16:25 <syntaxfree> I should have known that GHC docs were very detailed before. I'm finding out just now that Data.Bits has all the bitwise operations I needed for classical GAs.
12:16:43 <syntaxfree> Now I just need to learn how to do random stuff. But since figuring out monads, now I'm confident to go :)
12:16:45 <SamB> Pupeno: I wouldn't suggest it
12:16:46 <int-e> dcoutts: I don't know if it applies to subpatterns of rules, too.
12:16:47 <xerox> int-e: eta-reduction is \x.Mx -> M, I believe, what is eta-expansion, the dual?
12:16:54 <int-e> xerox: yes
12:16:55 <SamB> if you want erlang, you want erlang
12:17:01 <Pupeno> SamB: what part ?
12:17:05 <Pupeno> SamB: oh, ok.
12:17:14 <int-e> dcoutts: which is what you'd need.
12:17:16 * Pupeno really prefeers Haskell... if only for the syntax.
12:17:16 <SamB> Haskell is not up to being erlang
12:17:17 <Cale> syntaxfree: you can use the Random module even just knowing how to do IO
12:17:24 <Pupeno> and the community.
12:17:31 <xerox> int-e: why is it performed, I mean, when is it necessary?
12:17:45 <Cale> @type randomRIO
12:17:46 <lambdabot> forall a. (Random a) => (a, a) -> IO a
12:18:02 <monochrom> hee hee hee.  http://www.vex.net/~trebla/haskell/random.xhtml   (shameless plug)
12:18:02 <int-e> xerox: to be able to match f and \x -> f x
12:18:05 <SamB> I suppose it works better if you don't need hundreds of interrelated record types
12:18:31 <SamB> Haskell, I mean...
12:18:31 <musasabi> Pupeno: if you want something ready just use Erlang.
12:18:35 <monochrom> http://www.vex.net/~trebla/haskell/random.xhtml   (testing lambdabot)
12:18:41 <musasabi> It is quite nice once you are accustomed to it.
12:18:42 <xerox> int-e: i.e. if one provides a rule with arguments ghc will try to match them?
12:18:48 <Pupeno> musasabi: yes, it seems like I'd do that.
12:18:50 <int-e> xerox: eta-reduction and eta-expansion are more or less equivalent in that context, I suspect the actual implementation does eta-reduction.
12:19:00 <Cale> http://haskell.org/hawiki/HaskellNewbie_2fWorkingWithRandomNumbers
12:19:01 <lambdabot> Title: HaskellNewbie/WorkingWithRandomNumbers - The Haskell Wiki
12:19:09 <xerox> I would have thought that too, int-e, that's why I am asking in fact :)
12:19:18 <int-e> xerox: I wish I knew. the description isn't quite clear.
12:19:19 <xerox> int-e: sounds more... decidable? :)
12:19:27 <int-e> xerox: and I don't know the code.
12:20:35 <int-e> the rough description is here: http://www.haskell.org/ghc/docs/latest/html/users_guide/rewrite-rules.html#id3152963
12:20:36 <lambdabot> Title: 7.10. Rewrite rules
12:21:26 <xerox> If more than one rule matches a call, GHC will choose one arbitrarily to apply.
12:21:27 <xerox> Wow.
12:21:35 <int-e> xerox: I'd expect a rule that says f x = x^2 to expand f to \x -> x^2.
12:21:42 <int-e> xerox: I think that's what it means.
12:22:13 <xerox> `It seeks a substitution which makes the LHS and expression syntactically equal modulo alpha conversion.'
12:22:22 <int-e> xerox: i.e. eta-expand f to \x -> f x, then apply the rule.
12:22:40 <xerox> How do you know how many eta expansions you need?
12:23:51 <xerox> Well, there's the type information...
12:24:05 <int-e> the pattern is an application ((a b) c) ... - you just eta-expand often enough to have a value or variable for b, c, and so on.
12:24:14 <xerox> But the Spineless Tagless G-machine paper says that you can't depend on type information for the number of parameters because we have polymorphic typing.
12:24:18 <int-e> it can be done purely syntactically
12:24:29 <xerox> Okay, I see.
12:26:04 <dmhouse> ?where report
12:26:05 <lambdabot> http://www.haskell.org/onlinereport/
12:26:43 <int-e> dcoutts: but if that's how it works, you're right, and \x -> e op x cannot be matched.
12:26:52 <int-e> dcoutts: as a subpattern.
12:27:00 <edwardk> xerox: the STG just saturates constructors, right?
12:27:36 <xerox> edwardk: I am not sure. I think it uses a good number of techniques for everything it does.
12:30:39 <ookk> if i want to calculate an inexpensive function for lets say 1000000 values does haskell cache the results of all those calculations?
12:30:50 <SamB> heh
12:31:02 <xerox> Depends on many things, first of all how do you program it to calculate them :)
12:31:03 <SamB> you expect the compiler to figure out whether your function is expensive?
12:31:32 <ookk> i dont want to get stack overflow because i calculate 1000000 values of a function
12:31:48 <SamB> stack overflow?
12:31:52 <xerox> That's reasonable
12:32:29 <ookk> i get stack overfol when i calculate the sum of 1000000 values of a function
12:32:47 <xerox> > foldl (+) 0 [1..999999]
12:32:49 <lambdabot>  Exception: stack overflow
12:32:52 <xerox> > foldr (+) 0 [1..999999]
12:32:54 <lambdabot>  Exception: stack overflow
12:33:00 <xerox> > foldl' (+) 0 [1..999999]
12:33:00 <int-e> > foldl' (+) 0 [1..999999]
12:33:01 <ookk> i did that first
12:33:02 <lambdabot>  499999500000
12:33:02 <lambdabot>  499999500000
12:33:08 <ookk> then i made a recursive function
12:33:18 <ookk> but that gave overflow to
12:33:19 <int-e> @type seq
12:33:21 <lambdabot> forall b a. a -> b -> b
12:33:23 <xerox> > sum [1..999999]
12:33:25 <lambdabot>  Exception: stack overflow
12:33:31 <xerox> > sum $! [1..999999]
12:33:33 <lambdabot>  Exception: stack overflow
12:33:36 <xerox> Yuck :)
12:33:38 <ookk> what does ' do ?
12:33:39 <dmhouse> > foldl' (+) 0 [1..9999999]
12:33:41 <Cale> ookk: the problem is not in forming the expression -- it's evaluating it
12:33:43 <lambdabot> Terminated
12:33:49 <SamB> ookk: well... you have to use proper tail recursion for strict stuff like this...
12:33:50 <dmhouse> ookk: nothing, it's part of the name.
12:33:54 <xerox> That's the strict counterpart of fold.
12:34:05 <dmhouse> ookk: foo' is a valid identifier in Haskell.
12:34:09 <ookk> Cale, well i want it to calculate it without stack overflow :)
12:34:10 <newsham> doesnt haskell konw that 1+99999999 == 2 + 9999998 == 3 + 9999997 == ... ?
12:34:15 <Cale> ookk: You're essentially building an expression like ((((((((((....(0 + 1) + 1) + 1) + ... + 1)
12:34:18 <xerox> ?fptools Data.List
12:34:19 <lambdabot> http://darcs.haskell.org/packages/base/Data/List.hs
12:34:26 <int-e> newsham: no, why would it know that?
12:34:29 <xerox> See there the implementaiton
12:34:32 <xerox> *implementation
12:34:38 <int-e> newsham: a smart programmer will know that himself.
12:34:40 <SamB> newsham: haskell is not some smart kid
12:34:44 <Cale> ookk: so you need some extra strictness thrown in to make sure that the expression is evaluated as it is built
12:34:49 <ookk> so how should i calculate the sum of 1..1000000 then?
12:35:02 <Cale> ookk: use foldl' like was shown
12:35:03 <newsham> :(
12:35:04 <dmhouse> sum' = foldl' (+) 0
12:35:11 <Cale> which is the strict version of foldl
12:35:23 <dmhouse> (Why isn't sum strict by default?) (Why isn't foldl strict by default?)
12:35:27 <tibbe> @hoogle [a -> a] -> a -> a
12:35:29 <lambdabot> No matches, try a more general search
12:35:38 <int-e> > let sumFromTo n m = (n+m)*(m-n+1)`div`2 in sumFromTo 1 10000000000
12:35:39 <lambdabot>  50000000005000000000
12:35:43 <ookk> is there more functions in haskell which have a strict version?
12:35:46 <Cale> sum isn't strict by default because there are cases where you want it to be lazy
12:35:49 <xerox> tibbe: that's compose :)
12:35:55 <monochrom> sum should use fold' or equivalent in all implementations, I agree.
12:36:02 <tibbe> xerorx, aha!
12:36:03 <dmhouse> Cale: such as?
12:36:09 <tibbe> xerox, just what I needed
12:36:11 <newsham> it would be cool if i could codify knowledge, like the sum of n over a range, and have a programming system that could apply my knowledge to come up with various algorithms to solve a problem.
12:36:11 <xerox> ?type let swing f c a = f ($ c) a in swing
12:36:13 <lambdabot> forall a b t t1. (((a -> b) -> b) -> t -> t1) -> a -> t -> t1
12:36:16 <xerox> No wait
12:36:22 <xerox> ?wiki LicensedPreludeExts
12:36:23 <lambdabot> http://www.haskell.org/haskellwiki/LicensedPreludeExts
12:36:27 <newsham> sorta like an intern that you gradually teach how to program
12:36:33 <Cale> dmhouse: when your numeric type is something more complicated than the types offered in the Prelude and libraries
12:36:56 <Cale> dmhouse: though I admit it's actually pretty rare
12:37:02 <int-e> > foldl (flip const) undefined [undefined,2]
12:37:03 <lambdabot>  2
12:37:05 <dmhouse> Cale: well if you're summing a list you're going to have to evaluate the members most of the time anyway.
12:37:06 <int-e> > foldl' (flip const) undefined [undefined,2]
12:37:07 <lambdabot>  Undefined
12:37:14 <xerox> Oh well.
12:37:26 <xerox> ?type[3~> fold (.) id
12:37:27 <lambdabot> Unknown command, try @list
12:37:35 <xerox> ?type foldl (.) id
12:37:36 <lambdabot> forall b. [b -> b] -> b -> b
12:37:46 <xerox> Damn lag :(
12:37:53 <Cale> dmhouse: maybe you're summing a bunch of power series, and you just want to extract the coefficient of x^5 after
12:37:59 <xerox> ?wiki Compose
12:38:00 <lambdabot> http://www.haskell.org/haskellwiki/Compose
12:38:05 <int-e> Arguably, you could have Num instances with similar properties, so making sum strict is an incompatible change, too.
12:38:07 <monochrom> <rant>I hear no one complaining, about eager languages, that "map f (x:xs) = f x : map f xs" overflows the stack and takes forever before returning the first obvious item.</rant>
12:38:29 <Cale> monochrom:  good point :)
12:38:33 <dmhouse> Cale: true.
12:38:47 <int-e> haha
12:38:51 <dmhouse> Cale: although it's trivial to do that the other way around, although that could break composability.
12:39:16 <SamB> does it overflow the stack?
12:39:29 <Cale> Though it's true, sum probably ought to be strict by default
12:39:30 <int-e> we take lazyness for granted and complain when it bites us. :)
12:39:31 <monochrom> Try it in SML or OCaml, SamB.
12:39:42 <int-e> laziness?
12:40:10 <SamB> oh, right, that implementation
12:40:14 <Cale> laziness
12:40:24 <int-e> Laziness is Haskell's biggest problem and its biggest virtue at the same time.
12:40:34 <SamB> personally I'd say that people who want to have lazy sum or product can get their own, or complain!
12:40:43 <syntaxfree> why problem?
12:40:58 <monochrom> Eagerness is ML's biggest problem and biggest virtue at the same time.
12:41:05 <SamB> I don't believe they exist
12:41:08 <newsham> lazy programmer
12:41:14 <int-e> syntaxfree: because it's hard to control, say, in a state monad where the state is used for accumulating some sum.
12:41:38 <syntaxfree> ah. I haven~t got there yet.
12:41:45 <norpan> i would expect sum [1..n] to run in constant space
12:41:46 <monochrom> Well eagerness is hard to control too.
12:41:59 <flux__> eager haskell had a fun solution for that, which would handle both of the cases
12:42:10 <zarvok> monochrom: I'm not sure.  It's pretty easy to simulate laziness in an eager language
12:42:11 <flux__> (I think it was that project)
12:42:27 <int-e> syntaxfree: seq is all nice, but you'd want it in the monad operations ... get >>= \s -> s `seq` ...  for forcing the state to be evaluated is ugly.
12:42:30 <SamB> monochrom: but if you need an eager sum, you can write your own easily enough, or send a complaint to the libraries list
12:42:38 <zarvok> don't get me wrong, I love haskell, but I can certainly see the argument
12:43:03 <monochrom> Eagerness is hard to control.  It makes you wrangle the compiler: "why do I have to tell you the exact order of interleaving things? why is it not obvious to you and you just do the obvious?"
12:43:04 <Cale> zarvok: It's really not
12:43:23 <Cale> zarvok: Not easy enough to get any reasonable benefits anyway
12:43:47 <zarvok> Cale: well, I guess it depends where you want the laziness.  Certainly lazy data structures (like in monochrome's example) are easy
12:43:51 <syntaxfree> what _is_ the Typeable class?
12:43:58 <Cale> It sort of has to be pervasive before you start getting benefits in terms of compositionality
12:44:01 <SamB> is it also easy to insert this simulated laziness into the library of said eager language ?
12:44:05 <SamB> without recompiling?
12:44:05 <dmhouse> syntaxfree: runtime representation of various types.
12:44:07 <monochrom> I think most people complain about laziness surprises simply because they are brought up eagerly and don't see the eagerness surprises.
12:44:08 <zarvok> Cale: You're certainly right though if we want to completely simulate it everywhere
12:44:30 <SamB> that is, so that the library functions will operate in an appropriately lazy manner?
12:44:56 <Cale> zarvok: Like, consider the function   isSubstringOf s xs = any (isPrefixOf s) (tails xs)
12:45:05 <Cale> zarvok: Would you write that in a strict language?
12:45:12 <SamB> no.
12:45:18 <SamB> I'd wait for somebody else to do it.
12:45:19 <syntaxfree> dmhouse: oh. okie. thanks.
12:45:27 <Cale> It would be an unreasonable implementation
12:45:33 <ookk> anyone know a wiki or text where i can read a litte abot how to code strict with haskell?
12:45:47 <dmhouse> syntaxfree: a very simplified explanation would be you have data Type = Int | Bool | String | ...
12:45:49 <int-e> Cale: oh, but it's obvious that that translates to two nested while loops ;)
12:45:49 <zarvok> Cale: well, that's a good point, though I bet I could through together a relatively straightforward CPS implementation
12:45:53 <SamB> that is, I'd wait for someone else to implement that function correctly
12:46:11 <zarvok> I really was just talking in terms of lazy data structures though, and spoke to generally
12:46:15 <zarvok> *too
12:46:19 <Cale> zarvok: yeah, but you'd destroy your ability to use those library functions
12:46:25 <int-e> Cale: until you get to the point that the strings are lazy too. and then it becomes hairy :)
12:46:44 <SamB> zarvok: but you can't "simulate" a lazy list type
12:46:54 <zarvok> SamB: why not?
12:46:57 <SamB> because part of having a lazy list type is using it for everything under the sun?
12:47:08 <zarvok> ?
12:47:19 <zarvok> You are certainly welcome to implement streams in ML and just use them for everything
12:47:39 <SamB> but the LIBRARY!
12:47:42 <SamB> it will not.
12:47:51 <Cale> but because nobody else uses them, you can't use other people's libraries with them effectively
12:48:13 <zarvok> Well, it's true.  I think haskell's libraries are a large part of the reason I love it (to respond to both SamB and Cale)
12:48:37 <zarvok> And I do think that the laziness plays a big part there
12:49:02 <zarvok> But I'm not sure it's fair to compare languages on the basis of their libraries
12:49:10 <zarvok> Certainly I could implement extensive libraries in ML
12:49:11 <Cale> the thing about lazy evaluation is that it turns data structures into control structures, but in such a way that you don't have to think about it that way
12:49:33 <zarvok> I like that analogy
12:49:37 <SamB> heh
12:49:55 <int-e> with very funny effects
12:49:55 <SamB> not fair to compare languages on the basis of their libraries?
12:50:07 <zarvok> well, I'm talking about language design choices
12:50:17 <zarvok> extensive libraries have nothing to do withthe core language features
12:50:17 <int-e> the list monad lets you write a breadth first search that is executed as a depth first search.
12:50:19 <zarvok> (like laziness)
12:50:35 <Cale> int-e: yes, exactly :)
12:50:44 <SamB> I am talking about *using* languages
12:51:07 <zarvok> Well, fine.  I've already agreed that Haskell's libraries are far superior, and that's the reason I code in it
12:51:18 <SamB> I didn't even say that
12:51:31 <Cale> and a breadth first search that it really tangible, because you're really just thinking about how to construct your possibilities, and that's it.
12:51:40 <SamB> I just said that simulating laziness doesn't get you the benefits of laziness, because the libraries need to be there too
12:51:50 <zarvok> I'm just saying it may not be fair to insult ML on the basis that you can't program certain things efficiently because you don't have lazy lists.  Because, in fact, they are trivial to implement
12:52:11 <SamB> oh, but who cares about efficient programming if it is work?
12:52:16 <int-e> SamB: and the environment will not support such libraries because they're so obviously inefficient
12:52:38 <Cale> zarvok: It's not really efficiency, it's compositionality
12:52:43 <zarvok> fair enough
12:52:48 <int-e> SamB: with Haskell you just accept the inefficiencies, trust the compiler to do a good job and implement your stuff lazily.
12:52:49 <SamB> hmm
12:52:57 <Cale> zarvok: You can get efficiency, but you're sort of back to square one all the time
12:53:10 <int-e> SamB: or at least that's the case for me.
12:53:13 <Cale> (by comparison)
12:53:13 <SamB> well.
12:53:43 <SamB> depends on the program
12:53:51 <monochrom> OK, I weaken my position. If you are dumbly simulating a program in your head, eagerness is a piece of cake because the execution order is written. Given that you always develop code by trial-and-error --- conjure code, simulate to see if you like it, rinse and repeat --- it is therefore also easier to develop in.
12:53:51 <zarvok> Cale: Sure.  I'm not saying it's easy to turn ML into a lazy language.  I'm just saying it wouldn't be difficult to build libraries that do the same things as the list libraries in haskell.
12:54:02 <Cale> int-e: I agree for the greater part, but there are of course cases where you have to work out what's really going on :)
12:54:11 <Cale> zarvok: all right :)
12:54:11 <SamB> I have written a Haskell program that beat a C progrma with a nearly identical structure...
12:54:24 <zarvok> :)
12:54:36 <SamB> dunno how lazy it was though
12:54:37 <monochrom> It is also the same reason you find looping to be easier to use than recursion.  Looping is easier to simulate in head.
12:54:38 <int-e> Cale: oh of course :) and there are cases where you resort to the ST monad or some variant thereof, which usually makes me wish I was coding in C.
12:55:03 <SamB> monochrom: but...
12:55:11 <monochrom> But if you derive programs rathen than simulate programs, you will unanimously find that laziness and recursion are the obvious things to do.
12:55:15 <Cale> higher-order functions (well, the nice ones) are easier than loops though
12:55:36 <SamB> it is harder to write more complicated programs that way without being too inefficient
12:55:39 <Cale> 'all', for example, is easier to think about than a loop which computes it
12:55:57 <int-e> Cale: unless what you want is a loop. (I'm talking about rather boring array manipulation there. everything else is fun again in Haskell)
12:56:27 <Cale> yes, okay, though I'm still not completely convinced that we can't have efficient higher-order array manipulation :)
12:56:31 <monochrom> Observe that a real eager program contains all sorts of coding tricks to regain lazy or postponed evaluation.
12:56:33 <SamB> int-e: extremely boring array manipulation could be done with one of the functions in the array library...
12:56:43 <SamB> monochrom: exactly
12:56:48 <int-e> SamB: ok, show me a matrix multiplication
12:56:53 <int-e> :-P
12:57:04 <SamB> int-e: oh, is that what you meant by boring?
12:57:39 <int-e> SamB: Just the basic O(n*m*k) algorithm, nothing fancy
12:57:56 <SamB> I don't recall it ;-)
12:58:06 <SamB> it doesn't come up that often for me
12:58:07 <int-e> SamB: in fact I think I should just do it in C and use FFI.
12:58:14 <int-e> SamB: yes, that's basic
12:58:34 <monochrom> The coding tricks required in a eager programs can fill up a whole book.  The coding trick required in a lazy program to save some space/time is one and simple: just put a "seq" at the hotspots.
12:58:38 <SamB> I'd probably steal someone else's C ;-P
12:59:01 <int-e> then again, haskell should be fun for optimizing chains of matrix multiplications to achieve minimum cost.
12:59:03 <SamB> monochrom: and use good algorithms and fusion ;-)
12:59:18 <monochrom> Of course, as always in this field of software development, it is the method that fills up a whole book that is preferred.  Programmers love to read and write whole books!
12:59:28 <SamB> int-e: only if it knows what size the matrices are going to be
12:59:50 <monochrom> (Can't complain about the latter.  Beats those illiterate comic fans altogether!)
13:00:03 <SamB> oooh
13:00:07 <int-e> SamB: it was meant as an example, so just pretend I know that :)
13:00:18 <SamB> weshould publish algorithms in comic books to reach a wider audience ;-)
13:01:04 <int-e> . o O ( and here is how we do a radix sort ... then three panels with heaps of cards of varying size, final panel: "There, it's sorted, wasn'
13:01:09 <int-e> t that easy? )
13:01:12 <SamB> and I guess you'd need to do the optimization in actual Haskell code, and not RULES or the typesystem...
13:01:43 <int-e> but I think that's more an idea for a comic for a limited audience.
13:03:56 <SamB> hmm, I wish adventure would finish parsing my program... it doesn't seem to have started yet...
13:16:30 <d-bug> Q: I'm using Hugs and try to do "import Network" but it says "ERROR Network - Unable to open file "Network"". What am I missing?
13:19:11 <monochrom> Does Hugs have the Network module?
13:19:31 <d-bug> Doesn't look like it from the message, but I don't know for sure
13:21:32 <beelsebob> gyargh
13:21:38 <beelsebob> who has a clue how I can debug libffi
13:21:52 <monochrom> Hugs has Network.  But I wonder if you need "hugs -98" to get it.
13:22:32 <Klauso> Hi there, does anyone here know whether the type checker from "Typing Haskell in Haskell" is still available somewhere?
13:24:01 <musasabi> yes it is.
13:24:22 <musasabi> or was some months ago. I don't remember the URL
13:25:05 <d-bug> nvm, i changed to ghci and got new exciting messages :)
13:25:54 <Klauso> I tried to google it (Typing Haskell in Haskell) but I only found a dead link
13:27:25 <eivuokko> Klauso, I have it downloaded, if you want it in email.
13:27:56 <Klauso> that would be nice
13:30:00 <eivuokko> Sure, what's your email?  Pm or mangle it, as this channel is logged on net.
13:30:20 <Klauso> I have sent it via pm
13:30:57 <Klauso> @pl \f x -> (f x, g x)
13:30:58 <lambdabot> (`ap` g) . ((,) .)
13:31:22 <eivuokko> Uhm, I think the pm got lost because of some freenode non-regged nick protection.
13:31:36 <xerox> > ((+1) &&& (*2)) 2
13:31:38 <lambdabot>  (3,4)
13:32:21 <Klauso> my email is ostermann@informatik
13:32:27 <Klauso> .tu-darmstadt.de
13:32:55 <Klauso> @pl \f g x -> (f x, g x)
13:32:55 <lambdabot> liftM2 (,)
13:33:58 <xerox> That's (&&&) :)
13:34:08 <eivuokko> Sent.
13:34:20 <Klauso> thanks
13:40:13 <Klauso> @pl \x -> (x,x)
13:40:14 <lambdabot> join (,)
13:42:54 <svref> How can I convert a float to a string without all 17 decimal places being displayed?  1 decimal place would be great.
13:43:05 <emertens> I'm at 30% genius on mathschallenge.net , representing Haskell :)
13:43:05 <xerox> > showFFloat pi (Just 1) ""
13:43:06 <lambdabot>  add an instance declaration for (Floating (Maybe Int))
13:43:14 <xerox> > showFFloat (Just 1) pi ""
13:43:16 <lambdabot>  "3.1"
13:43:43 <svref> Thanks.
13:43:48 <xerox> You're welcome.
13:44:54 <svref> what package is showFFloat in?
13:45:01 <xerox> ?index showFFloat
13:45:02 <lambdabot> Numeric
13:47:00 <Klauso> can someone explain to me why @pl \x -> (x,x) is "join (,)" ?
13:47:07 <emertens> Klauso: sure
13:47:22 <Klauso> it does not seem to be equivalent
13:47:28 <xerox> You can get many different explanations of that single line of code :)
13:47:28 <emertens> Klauso: this is using the (->) Monad, which is like a reader monad
13:47:46 <xerox> It is the ((->) a) Monad. Monads have kind * -> *.
13:47:53 <emertens> Klauso: join look like this: join x = do { a <- x; a }
13:48:15 <monochrom> emertens: how to submit solutions?
13:48:15 <xerox> I'd suggest join f x = f x x :)
13:48:25 <emertens> in the reader monad, a <- x means "a is the result of calling x on the "environment"
13:48:39 <emertens> xerox: that doesn't explain why it works
13:48:45 <Klauso> but if I try, say, "(join (,)) 42 " I don't get (42,42) as expected but an error
13:48:55 <xerox> You need to import the needed instance.
13:49:03 <emertens> Klauso: import Control.Monad.Reader
13:49:17 <Klauso> I'll try
13:49:26 <emertens> > (do { a <- (,) ; a }) 1
13:49:27 <lambdabot>  (1,1)
13:50:44 <Klauso> this looks interesting but I think I need a few seconds to understand it ... :-)
13:51:42 <svref> > putStrLn (showFFloat pi (Just 2) "")
13:51:42 <lambdabot>  No IO allowed
13:51:50 <svref> > showFFloat pi (Just 2) ""
13:51:51 <lambdabot>  add an instance declaration for (Floating (Maybe Int))
13:51:51 <Klauso> Is this really the simplest (or only?) way to make "\x -> (x,x)" point free ?
13:52:10 <monochrom> Simplest
13:52:22 <LordBrain> @pl \x -> (x,x)
13:52:22 <lambdabot> join (,)
13:52:26 <emertens> Klauso: it's about the only way
13:52:30 <emertens> > ((,) =<< (+1)) 3
13:52:31 <lambdabot>  (4,3)
13:52:31 <Klauso> I am sure it is the *shortest*, but simplest?
13:52:54 <LordBrain> join (,) 3
13:52:55 <emertens> > ((,) =<< chr) 67
13:52:57 <lambdabot>  ('C',67)
13:52:58 <LordBrain> > join (,) 3
13:52:59 <lambdabot>  (3,3)
13:53:23 <emertens> > ap (,) chr 67
13:53:25 <lambdabot>  (67,'C')
13:53:42 <xerox> ?where stg
13:53:42 <lambdabot> http://citeseer.ist.psu.edu/peytonjones92implementing.html
13:53:47 <LordBrain> ap i need to get more usage from that guy
13:56:49 <emertens> > (do { a <- (,); b <- chr; return (a b) }) 67 -- ap expanded
13:56:51 <lambdabot>  (67,'C')
13:58:16 <xerox> > ((,) >>= \a -> chr >>= \b -> return (a b)) 67 -- ap desugared
13:58:17 <lambdabot>  (67,'C')
13:59:30 <LordBrain> when you write a <- (,) what is the monad?
13:59:33 <Klauso> ?type \x -> ((,) =<< x)
13:59:35 <lambdabot> forall a b. (b -> a) -> b -> (a, b)
13:59:39 <emertens> that is still the (->) Monad
14:00:18 <emertens> I am making a mild attempt at illustrating a little better why (->) works
14:00:51 <LordBrain> how does (->) define bind?
14:01:02 <LordBrain> or return
14:01:02 <xerox> ?fptools Control.Monad.Reader
14:01:03 <lambdabot> http://darcs.haskell.org/packages/mtl/Control/Monad/Reader.hs
14:01:28 <xerox> return x = \_ -> x -- :)
14:01:57 <emertens> flip const
14:02:04 <emertens> err
14:02:06 <emertens> const
14:02:11 <Klauso> as far as I understand "return" and "bind" in this monad are just the K and S combinators
14:02:17 <emertens> bingo :)
14:02:29 <emertens> actually
14:02:30 <Klauso> but I don't quite get what kind of type constructor "r ->" is
14:02:35 <emertens> I think that =<< is
14:02:39 <SamB> Klauso: it isn't
14:02:48 <SamB> "(->) r" is
14:03:07 <SamB> @kind (->) ()
14:03:08 <lambdabot> ? -> *
14:03:13 <SamB> oho!
14:03:17 <SamB> it works!
14:03:22 <SamB> I didn't think that was going to work
14:03:26 <emertens> ? means unboxed type or some jazz
14:03:33 <emertens> @kind (->)
14:03:34 <lambdabot> ?? -> ? -> *
14:03:35 <Klauso> I am just taking a look at the 1995 paper from Jones. He says "instance Monad (r->) where ..."
14:03:45 <SamB> I forget what ? means
14:03:57 <ptolomy> @pl compare ((length . fst) x) ((length . fst) y)
14:03:58 <lambdabot> compare (length (fst x)) (length (fst y))
14:04:03 <ptolomy> aww.
14:04:13 <ptolomy> What is the less gross way of doing that?
14:04:14 <LordBrain> you mean http://www.cse.ogi.edu/~mpj/ ?
14:04:15 <lambdabot> Title: Redirect: Web resource has moved
14:04:16 <emertens> ptolomy: that's not how @pl works :)
14:04:25 <Klauso> http://web.cecs.pdx.edu/~mpj/pubs/springschool95.pdf
14:04:44 <xerox> ptolomy: with comparing
14:04:53 <xerox> ?oldwiki LicensedPreludeExts
14:04:53 <lambdabot> http://www.haskell.org/hawiki/LicensedPreludeExts
14:04:59 <SamB> where   *    [LiftedTypeKind]   means boxed type
14:04:59 <SamB>         #    [UnliftedTypeKind] means unboxed type
14:04:59 <SamB>         (#)  [UbxTupleKind]     means unboxed tuple
14:04:59 <SamB>         ??   [ArgTypeKind]      is the lub of *,#
14:05:01 <SamB>         ?    [OpenTypeKind]     means any type at all
14:05:10 <SamB> that was from fptools/ghc/compiler/types/Kind.lhs
14:05:19 <xerox> ?kind (->)
14:05:21 <lambdabot> ?? -> ? -> *
14:05:29 <monochrom> Klauso: do you understand it?
14:05:54 <ptolomy> Ah. of course.
14:05:59 <ptolomy> xerox: Thanks. :)
14:06:02 <xerox> You're welcome.
14:06:13 <SamB> of course, that use of @kind was a bad pun...
14:06:18 <emertens> ptolomy: for reference, the way to ask lambdabot a @pl question is:
14:06:20 <Klauso> ok, so " ->" takes two types and produces a type, right?
14:06:31 <Klauso> so it would have kind * -> * -> *, no?
14:06:31 <emertens> @pl \x y -> comparing (g x) (g y)
14:06:31 <SamB> lets call it (->)
14:06:31 <lambdabot> (. g) . comparing . g
14:06:37 <emertens> @pl \x y -> compare (g x) (g y)
14:06:38 <lambdabot> (. g) . compare . g
14:06:41 <ptolomy> emertens: Ah, good to know. Thanks.
14:06:45 <SamB> Klauso: well, in standard Haskell it would
14:06:55 <SamB> GHC extends things a little
14:06:58 <SamB> it needs to
14:07:07 <SamB> or unboxed stuff wouldn't work at all at all
14:07:14 <xerox> liftM2 I suspect
14:07:15 <Klauso> unboxed?
14:07:26 <xerox> ?type \f x y -> compare (f x) (f y)
14:07:28 <lambdabot> forall a t. (Ord a) => (t -> a) -> t -> t -> Ordering
14:07:32 <xerox> ?pl \f x y -> compare (f x) (f y)
14:07:33 <lambdabot> flip =<< (((.) . compare) .)
14:07:36 <xerox> Oh cool.
14:07:44 <SamB> it uses an unboxed type to implement Int, for instance
14:07:54 <SamB> (Int is not one)
14:08:02 <Klauso> what does "unboxed" mean?
14:08:16 <monochrom> Do we need to go into that now?
14:08:31 <LordBrain> it basicly means you have a value instead of a pointer to a value
14:08:37 <Klauso> a reference would be sufficient, then I can look it up myself
14:08:55 <SamB> Klauso: it means it is stored in-place
14:09:02 <SamB> no pointer
14:09:24 <SamB> so you can't use it in a polymorphic datastructure
14:09:28 <Klauso> is it a GHC implementation detail or something that is visible to the programmer?
14:09:37 <LordBrain> translation to c would be like int i instead of int *i
14:09:43 <SamB> it is visible to the programmer
14:09:54 <emertens> Klauso: the programmer can use them to speed things up, at the cost of features
14:10:03 <SamB> if desired, it can be used by the programmer, but that requires -fglasgow-exts
14:10:34 <Klauso> OK, but this looks like a sidetrack. So why is "->" not of kind * -> * -> * ?
14:10:54 <norpan> isn't it?
14:11:00 <SamB> @kind (->)
14:11:01 <LordBrain> i need to study the Reader Monad myself
14:11:01 <emertens> ?? -> ? -> *
14:11:03 <lambdabot> ?? -> ? -> *
14:11:16 <Klauso> what do all these question marks mean?
14:11:22 <emertens> scroll up
14:11:24 <norpan> ?? and ? are more generic than *, right?
14:11:31 <emertens> ?? is argument type
14:11:31 <LordBrain> the questions refer to the boxing thing
14:11:32 <SamB> yeah
14:11:34 <emertens> ? is any type
14:11:45 <emertens> * is boxed type
14:12:02 <norpan> so ?? is a non-function type and ? is any type
14:12:03 <SamB> where   *    [LiftedTypeKind]   means boxed type
14:12:03 <SamB>         #    [UnliftedTypeKind] means unboxed type
14:12:03 <SamB>         (#)  [UbxTupleKind]     means unboxed tuple
14:12:03 <SamB>         ??   [ArgTypeKind]      is the lub of *,#
14:12:07 <SamB>         ?    [OpenTypeKind]     means any type at all
14:12:12 <norpan> no
14:12:19 <norpan> what is argument type
14:12:28 <monochrom> This whole exercise is like how you describe numbers to newbies.
14:12:29 <Klauso> ok, but is the difference between ?? and * relevant to the "-> r" Monad?
14:12:30 <emertens> the lub or *,#, duh
14:12:30 <SamB> argument type is apparantly anything but unboxed tuples
14:12:42 <LordBrain> numbers to newbies?
14:13:01 <SamB> Klauso: not really
14:13:03 <norpan> Klauso: i don't think so
14:13:07 <monochrom> Yes. For simplicity at the very beginning, you lie: "10::Int".  Of course, we all know...
14:13:11 <monochrom> @type 10
14:13:12 <lambdabot> forall t. (Num t) => t
14:13:17 <SamB> @type return
14:13:19 <lambdabot> forall (m :: * -> *) a. (Monad m) => a -> m a
14:13:20 <LordBrain> oh i see
14:13:24 <monochrom> But you can't say that to a newbie just yet.
14:13:40 <SamB> see, the Monad class constrains the kind to * -> * anyway
14:13:46 <LordBrain> it might depend on how brave a newbie you have
14:13:51 <LordBrain> hehe
14:14:03 <monochrom> You want to get the newbie to comfortably write functions for Ints before you say it can be generalized to Num t.
14:14:06 <LordBrain> if you think it will scare him, you hold back ;)
14:14:18 <LordBrain> yeah
14:14:20 <LordBrain> that makes sense
14:14:22 <SamB> Klauso: anyway... to answer your question more seriously...
14:14:50 <SamB> ((->) a) is a partially applied type constructor
14:15:12 <xerox> ?quote Cale
14:15:13 <lambdabot>  The perfect programming language is mathematics, but that only runs on mathematicians.
14:15:14 <xerox> ?quote Cale
14:15:15 <lambdabot>  ... if sections were allowed at the type level ...
14:15:23 <xerox> ...then you could write (a ->)
14:15:34 <Klauso> so ((->) a) is a type constructor that, for any type t, returns a -> t, right?
14:15:43 <monochrom> Yes.
14:15:44 <SamB> yeah
14:15:45 <norpan> @karma+ (a->)
14:15:45 <lambdabot> (a->)'s karma raised to 1.
14:15:56 <emertens> quoting Cale through lambdabot seems like a roundabout way of explaining something ;)
14:16:08 <monochrom> or explaining everything
14:16:21 <xerox> Yuck.
14:16:22 <SamB> @quote me
14:16:23 <lambdabot> me hasn't said anything memorable
14:16:27 <SamB> @remember me
14:16:28 <lambdabot> Incorrect arguments to quote
14:16:31 <SamB> aww
14:16:44 <SamB> @quote SamB
14:16:45 <lambdabot>  C is a good language. If what you want is an assembly language where you can't be sure what anything does
14:17:13 * emertens hits SamB with the grammar stick ;)
14:17:44 <SamB> I can't fix it now!
14:18:06 <emertens> oh man. you're screwed!
14:18:37 <SamB> I don't think I get graded on lambdabot's quote file...
14:18:48 <emertens> oh
14:18:49 <emertens> ..
14:18:58 <emertens> well, in that case, I guess you're fine
14:19:01 <SamB> hehe
14:19:13 <Klauso> @type (+) <<=
14:19:14 <lambdabot> parse error (possibly incorrect indentation)
14:19:30 <Klauso> @type (<<=) (+)
14:19:31 <lambdabot> Not in scope: `<<='
14:19:35 <emertens> =<< ?
14:19:41 <Klauso> @type (=<<) (+)
14:19:42 <lambdabot> forall a. (Num a) => (a -> a) -> a -> a
14:19:42 <emertens> >>= ?
14:20:16 <emertens> > (+) =<< (+1) 2 -- is 5
14:20:17 <lambdabot>  add an instance declaration for (Num (a -> a))
14:20:21 <emertens> > ((+) =<< (+1)) 2 -- is 5
14:20:23 <lambdabot>  5
14:20:37 <xerox> > 5 -- is 5 and easier to write
14:20:38 <lambdabot>  5
14:20:52 <emertens> @slap xerox
14:20:52 * lambdabot smacks xerox about with a large trout
14:20:57 <xerox> Yuck.
14:21:07 <Klauso> haha, this bot seems to have many features
14:21:18 <emertens> we aren't even scratching the surface :-D
14:21:24 <SamB> Klauso: you are welcome to write one
14:21:44 <emertens> @karma- java
14:21:44 <lambdabot> emertens's karma lowered to 1.
14:22:01 <SamB> @remember Klauso haha, this bot seems to have many features
14:22:01 <lambdabot> Done.
14:22:07 <beelsebob> @karma+ emertens
14:22:07 <lambdabot> emertens's karma raised to 2.
14:22:29 <emertens> thnx :)
14:22:36 <emertens> lambdabot: has special java karma logic
14:22:39 <Klauso> for today, I am busy enough internalizing the ((->) a) Monad :-)
14:23:27 <xerox> > ap (,) (+1) 1
14:23:28 <lambdabot>  (1,2)
14:23:44 <Klauso> @type return (+)
14:23:46 <lambdabot> forall (m :: * -> *) a. (Monad m, Num a) => m (a -> a -> a)
14:25:22 <SamB> emertens: shouldn't it *raise* your karma if you lower java's?
14:25:30 <emertens> SamB: I think that it did
14:25:37 <SamB> <emertens> @karma- java
14:25:37 <SamB> <lambdabot> emertens's karma lowered to 1.
14:25:51 <emertens> SamB: I think that the "lowered" is just because you are in @karma- mode
14:25:55 <emertens> not because it's lowering it
14:25:56 <SamB> oh
14:25:59 <SamB> how stupid
14:26:03 <emertens> I'm guessing it's a bug
14:26:12 <emertens> but also not an oft used feature
14:26:19 <SamB> you'd think someone would have noticed it testing the feature!
14:26:42 <emertens> I'll try again to verify my guess
14:26:45 <emertens> @karma- java
14:26:46 <lambdabot> emertens's karma lowered to 1.
14:26:49 <emertens> nope
14:26:52 <emertens> its just broke
14:27:01 <emertens> @karma+ java
14:27:02 <lambdabot> emertens's karma lowered to 0.
14:27:07 <monochrom> Haha!
14:27:09 <emertens> don't touch java, apparently
14:27:17 <xerox> haha
14:27:20 <emertens> maybe it was being abused?
14:27:31 <Klauso> > (return (+)) 1 2 3
14:27:32 <lambdabot>  5
14:27:33 <monochrom> Have you tried: @karma- haskell, @karma+ haskell ?
14:27:39 <emertens> @karma java
14:27:39 <lambdabot> java has a karma of 0
14:28:06 <Klauso> :type (return (+) ) 1 2 3 4 5
14:28:15 <Klauso> @type (return (+)) 1 2 3 4 5
14:28:15 <java> @karma- java
14:28:16 <lambdabot> forall t t1 t2. (Num (t -> t1 -> t2), Num t, Num t1) => t2
14:28:16 <lambdabot> You can't change your own karma, silly.
14:28:44 <monochrom> Have you tried: @karma- haskell, @karma+ haskell ?
14:28:46 <Pupeno_> @karma+ haskell
14:28:46 <lambdabot> haskell's karma raised to 3.
14:28:56 <monochrom> OK!
14:29:04 <Pupeno_> @karma Pupeno
14:29:05 <lambdabot> Pupeno has a karma of 2
14:34:50 <Klauso>  > ((+) =<< (+1)) 2
14:34:57 <Klauso> > ((+) =<< (+1)) 2
14:34:58 <lambdabot>  5
14:35:42 <LordBrain> @karma LordBrain
14:35:43 <lambdabot> You have a karma of 3
14:35:52 <LordBrain> lol
14:37:30 <Klauso> is it true that (x =<< y) z  =  y ((x z) z) ? (in the ((->) a) Monad)
14:38:06 <Jormunder> @karma Jormunder
14:38:06 <lambdabot> You have a karma of 0
14:39:19 <haskell> how was this nick not registered already?
14:40:37 <haskell> hey Cale, you know anything about @karma- java attacking the person typing it?
14:40:47 <Cale> hehe
14:41:01 <Cale> karma- ?
14:41:06 <haskell> yeah, both + and - now
14:41:11 <Cale> hmm
14:41:13 <Cale> odd :)
14:41:17 <haskell> no joke
14:41:22 <Cale> probably a bug
14:41:32 <emertens> I think it was intentional
14:41:39 <emertens> since it *used* to work correctly :)
14:42:13 <emertens> and now I'm out 2 karma ;)
14:42:22 <SamB> you don't think it could have been badly refactored?
14:42:29 <SamB> @karma+ emertens
14:42:30 <lambdabot> emertens's karma raised to 1.
14:42:31 <SamB> @karma+ emertens
14:42:32 <lambdabot> emertens's karma raised to 2.
14:42:49 <emertens> heh, which when you only had 2 is a lot :)
14:44:03 <Cale> whee, mostly have my system up and working correctly with ubuntu, which was a slight pain due to my need for reiser4 support
14:44:10 <xerox> Cale - hehe, it is not a bug, dons hacked it in.
14:44:31 <Cale> xerox: I knew about the attack on karma+ java
14:44:45 <Cale> xerox: I didn't think it applied to karma- as well
14:45:09 <SamB> I say @karma- java should give karma ;-)
14:45:27 <SamB> or at least lower java's karma
14:47:24 <xerox> patch it.
14:48:23 <int-e> SamB: @karma- java gave karma for a short while, but dons didn't like it.
14:49:34 <int-e> SamB: yes, I agree with that
14:52:40 <Failure02> how do i read an int from stdin?
14:52:46 <Failure02> readLn takes a whole line, i don't want that
14:53:20 <stepcut> Failure02: do you want just a single digit?
14:53:40 <Failure02> no, an integer. if "123 45" is in input, i want "123"
14:53:55 <Failure02> i guess i could readLn, then do words on it
14:54:01 <stepcut> yeah
14:59:37 <emertens> is there a better way to find the digits of a number than: unfoldr (\b -> if b == 0 then Nothing else Just (b `mod` 10, b `div` 10))
15:00:01 <SamB> how about "show n"
15:00:26 <emertens> would that be faster or slower?
15:00:59 <SamB> dunno
15:01:05 <SamB> but it is much easier to read
15:01:12 <emertens> I don't really care about that
15:01:21 <emertens> this is for mathschallenge.net
15:01:32 <emertens> i just figured I see if anyone knew a better way than what I'd been using
15:01:40 <Failure02> emertens: then it shouldn't matter, with the 1 minute rule
15:01:51 <madpickle> that's only a guideline
15:02:13 <madpickle> the dude who wrote it said *he* did it under a minute with his knowledge of the questions
15:02:38 <madpickle> he also said that it was unlikely that most quesitons could be done in <1 given that different languages, platforms and types of languages
15:02:48 <Failure02> i mean that since it won't take so long anyway, such an optimization would be silly. i don't think show is going to be what kills your performance
15:03:14 <emertens> show n doesn't do the same thing
15:03:21 <emertens> map (read . return) . show
15:03:33 <emertens> or
15:04:07 <emertens> map (- ord '0') . show
15:04:09 <emertens> something like that
15:04:38 <emertens> map ((- ord '0') . ord) . show
15:30:23 <syntaxfree> is System.readFile lazy, in some loose sense?
15:30:41 <Cale> yes
15:30:50 <Cale> It cheats a bit :)
15:31:01 <syntaxfree> Like the unix "cat" is lazy?
15:31:06 <dcoutts> yes
15:31:12 <Cale> The string that it gives you will do IO when observed.
15:31:21 <Cale> and close the file when at EOF.
15:31:34 <dcoutts> foxy, looks like our notebook bug will be fixed in the next Gtk+ release, 2.10.2
15:31:47 <syntaxfree> it will only read as observed, and therefore if treated with lazy functions it's lazy.
15:32:06 <dcoutts> foxy, one of the main Gtk+ devs has set a target of 2.10.2
15:32:08 <dcoutts> http://bugzilla.gnome.org/show_bug.cgi?id=351112
15:32:12 <lambdabot> Title: Bug 351112 - gtk_notebook_set_current_page fails when the notebook has not yet b ...
15:35:22 <syntaxfree> Cale: so it's okay to readFile some very large file,as long as the string it gives me is dealt with lazy functions?
15:37:35 <ndm> anyone used Haskell Source Extensions - http://www.cs.chalmers.se/~d00nibro/haskell-src-exts/
15:37:41 <lambdabot> Title: Haskell-Source with eXtensions
15:37:48 <ndm> someone suggested it for hoogle
15:37:55 <Lemmih> I did once.
15:37:59 <ndm> but the documentation (ahem) has absolutely no examples
15:38:15 <ndm> i just want to see a chunk of source code and see what it looks like
15:38:25 <ndm> Lemmih: thoughts? would you use it again?
15:38:41 <japple> So, I was asking a CS prof at a US university for advice about graduate school. When he asked what I wanted to study, I mentioned types and typed programming, and he asked if I was thinking of Ada or Pascal, and stated that both of these are dead ends. Our exchange went as follows:
15:38:41 <japple> > > I am more interested in languages like Haskell and SML, or even
15:38:41 <japple> > > programming systems based on more expressive type theories like the
15:38:41 <japple> > > Calculus of Constructions or Martin-Lof's theory of types.
15:38:41 <japple> >
15:38:42 <lambdabot>  Parse error
15:38:42 <lambdabot>  Parse error
15:38:42 <lambdabot>  Parse error
15:38:43 <japple> > All of the work that you mention is based on the fundamental
15:38:44 <lambdabot>  Parse error
15:38:45 <japple> > assumption made by Pascal and Ada -- that it ought to be a syntax
15:38:46 <lambdabot>  Not in scope: data constructor `Ada'
15:38:47 <japple> > error if quantities of different types are combined -- and this is
15:38:48 <lambdabot>  Parse error
15:38:49 <japple> > just not believed any more, for the reasons I mentioned. You need to
15:38:49 <lambdabot>  Parse error
15:38:51 <japple> > start over again on some other theoretical line.
15:38:52 <lambdabot>  Parse error
15:38:59 <japple> Sorry lambdabot :-(
15:39:54 <syntaxfree> easiest non-explicitly recursive way of getting a list with 54 ones?
15:40:09 <Lemmih> ndm: The API is pretty similar to haskell-src, iirc.
15:40:11 <japple> Anyway, I thought you all might enjoy this nugget of wisdom that we're all barking up the wrong tree.
15:40:15 <syntaxfree> ntimes 0 w = w; ntimes n w = w : ntimes (n-1) w
15:40:29 <syntaxfree> there's a function that does that?
15:40:32 <japple> replicate 54 1
15:40:35 <ihope> > (sum . map ord) "Life, the universe and everything" `mod` 76
15:40:36 <ndm> Lemmih: i was lead to believe it was more a transofrmational thingy?
15:40:36 <lambdabot>  42
15:40:36 <syntaxfree> ok!
15:40:38 <syntaxfree> thanks.
15:40:45 <ndm> to embed XML/HTML in Haskell source code?
15:40:48 <ihope> That means 76 is the Question.
15:40:57 <ihope> > (sum . map ord) "Life, the universe and everything" `mod` 82
15:40:58 <lambdabot>  42
15:41:06 <ihope> 82 must be the other Question.
15:44:02 <Lemmih> ndm: Yeah, it can parse a few more extensions (including regular patterns and embedded XML) than haskell-src.
15:44:31 <ndm> Lemmih: i really was just hoping to see an example of what the embedded XML stuff looked like
15:44:50 <ndm> hmm, i thought haskell-src  was just a parser for Haskell, must be thinking of the wrong one
15:44:51 <musasabi> ndm: look at HSP
15:45:07 <ndm> musasabi: didn';t find any good examples of that either :)
15:45:28 <Lemmih> x = <p>hello world</p>
15:46:05 <ndm> in that example x ends up being a string?
15:46:23 <musasabi> foo t b = <html><head><title><% t %></title></head><body><% b %></html>
15:46:27 <ndm> any way to do f name = <p>hello <%= name %></p>
15:46:33 <ndm> ah, sounds cool
15:47:01 <Lemmih> Haskell-src parses Haskell'98, haskell-src-exts parses Haskell'98 + GADTS + FFI + a few more.
15:47:06 <musasabi> ndm: it ends up being something like "HSP XML"
15:47:31 <ndm> musasabi: thats somewhat what i'm looking for
15:48:04 <beschmi> ndm: there is a preprocessor built with haskell-src-ext for xml embedding in haskell
15:48:05 <lambdabot> beschmi: You have 1 new message. '/msg lambdabot @messages' to read it.
15:48:22 <ndm> beschmi: yes, thats what i think i'm looking at
15:48:31 <musasabi> the preprocessor is called trhsx or something similar
15:48:43 <beschmi> http://www.cs.chalmers.se/~d00nibro/hsp/ it's described in the thesis
15:48:44 <lambdabot> Title: HSP - Haskell Server Pages
15:52:23 <syntaxfree> Why can't they ship datasets in reasonable formats? :'(
15:52:45 <syntaxfree> I'm toiling over this dataset shipped in what supposedly are fixed-width columns.
15:52:51 <syntaxfree> Except they're not fixed-width.
15:55:52 <monochrom> Unreasonable people produce unreasonable formats.
15:56:20 <Cale> syntaxfree: yes
15:56:31 <Cale> syntaxfree: (sorry for the late answer, I was in the shower)
15:57:50 <lispy> why is, "instance Show a => Foo a where..." valid but "instance Num a => Foo a where..." not valid?  it tells me, "There must be at least one non-type-variable in the instance head"
15:59:02 <monochrom> Is Foo a data type?
15:59:22 <monochrom> Err sorry.  Is Foo a type class?
15:59:32 <lispy> Foo is a type class, i think i just realized the "Show a" version is not an instance but in the class declaration
15:59:58 <lispy> buti still thought i could add constraints like that to instances
16:00:11 <Cale> what's your actual instance?
16:00:26 <lispy> what do you mean?
16:00:41 <lispy> it really is "instance Num a => Foo a where..."
16:00:47 <Cale> okay
16:00:47 <monochrom> "class Show a => Foo a " you have this instead?
16:00:49 <lispy> well, Foo == ExcelValue
16:01:09 <lispy> monochrom: i have that as the class
16:01:23 <lispy> it's the instance declaration that's making ghc unhappy
16:01:48 <Cale> yeah, you have to have at least one type constructor in there
16:02:14 <lispy> oh, i can't make it work for all instances of Num in one declaration?
16:02:29 <int-e> -fundecidable-instances lifts that restriction, right?
16:02:34 <Cale> Or else turn on options like undecidable instances and friends until it's happy :)
16:02:40 <lispy> covering Integer and Double should be 90% of my cases...
16:03:02 <lispy> yeah, it says that will make it happy, but i like to only use ghc extensions when i know i need them :)
16:03:09 <lispy> so...maybe in this case i'll try it out
16:04:01 <lispy> hmm...how do you do that as a comment again?
16:04:14 <lispy> {- GHC_OPTION -fundecidable-instances -} doesn't seem right
16:04:38 <monochrom> {-# OPTIONS_GHC -fundecidable-instances #-}
16:05:53 <lispy> {-# OPTIONS -fallow-undecidable-instances #-}
16:06:18 * lispy wonders what the difference means
16:06:20 <int-e> oh my bad
16:06:40 <monochrom> I have never heard of the latter.
16:06:48 <lispy> what is the difference between OPTIONS_GHC and OPTIONS?
16:07:05 <lispy> oh, i got it off the wiki :)
16:07:15 <lispy> http://www.haskell.org/hawiki/TipsAndTricks
16:07:16 <lambdabot> Title: TipsAndTricks - The Haskell Wiki
16:07:46 <monochrom> Turns out I never read the wiki. I derive everything from first principles.
16:08:39 <lispy> heh
16:08:46 <lispy> thanks for the help, btw
16:12:42 <LordBrain> Is this considered abuse of the show function? http://www.nomaware.com/monads/examples/example16.hs
16:13:20 <LordBrain> I'm referreng specifically to the Instance declaration of Show Template
16:14:09 <LordBrain> basicly, its converting things to strings.. that would/could not be readable...
16:14:17 <LordBrain> i mean the type info is lost
16:14:25 <LordBrain> that's not how i normally think of show
16:14:49 <monochrom> I think it's fine.
16:16:24 <LordBrain> hmm
16:16:32 <LordBrain> i guess i prefer to reserve show for debugging
16:18:55 <LordBrain> in the case of numbers its the same tho...
16:18:58 <LordBrain> hmm
16:19:20 <LordBrain> so show has overlapping usages...
16:24:19 <LordBrain> i guess we can preserve both things by making a Render type class and have a default instance for everything in the Show class... so if something has a render function it uses that, otherwise it uses show
16:24:55 <LordBrain> something like that
17:09:35 <Klauso> > (\n -> foldM (\b _ -> [ x : b |  x <- [1..n], and $ [ x /= c &&  x /= c+i && x /= c-i | (c,i) <- zip b [1..(length b)]] ]) [] [1..n]) 5
17:09:36 <lambdabot>  [[4,2,5,3,1],[3,5,2,4,1],[5,3,1,4,2],[4,1,3,5,2],[5,2,4,1,3],[1,4,2,5,3],[2,...
17:10:17 <Klauso> take 1 $  (\n -> foldM (\b _ -> [ x : b |  x <- [1..n], and $ [ x /= c &&  x /= c+i && x /= c-i | (c,i) <- zip b [1..(length b)]] ]) [] [1..n]) 10
17:10:32 <Klauso> > take 1 $  (\n -> foldM (\b _ -> [ x : b |  x <- [1..n], and $ [ x /= c &&  x /= c+i && x /= c-i | (c,i) <- zip b [1..(length b)]] ]) [] [1..n]) 8
17:10:33 <lambdabot>  [[4,2,7,3,6,8,5,1]]
17:11:28 <Klauso> @pl \n -> foldM (\b _ -> [ x : b |  x <- [1..n], and $ [ x /= c &&  x /= c+i && x /= c-i | (c,i) <- zip b [1..(length b)]] ]) [] [1..n]
17:11:36 <lambdabot> ap (flip foldM [] . (const .) . (`ap` (return . and . return . ((x /= c && x /= c + i) &&) . (x /=) . (-) c . ((i | (c, i)) <-) . ap zip (enumFromTo 1 . length))) . (((:) . (x :)) .) . flip ((<-) . (
17:11:37 <lambdabot> | x)) . enumFromTo 1) (enumFromTo 1)
17:12:57 <Klauso> > take 1 $  (\n -> foldM (\b _ -> [ x : b |  x <- [1..n], and $ [ x /= c &&  x /= c+i && x /= c-i | (c,i) <- zip b [1..(length b)]] ]) [] [1..n]) 12
17:12:57 <lambdabot>  [[4,9,7,2,11,6,12,10,8,5,3,1]]
17:13:16 <Lemmih> Klauso: lambdabot also respond to private messages.
17:13:23 <Klauso> ah, ok
17:13:39 <Klauso> thanks, then I won't bother the whole channel anymore
17:42:44 <foxy> dcoutts, when with Gtk+ 2.10.2 come out?
18:13:16 <LordBrain> i think we should make interfaces customizable after the fact... like we just specify a bunch of variables and maybe tag them to help with organization, and maybe one of the tags could indicate whether its a submit style input or if it's just instant
18:13:57 <LordBrain> kind of the opposite of those RAD approaches
18:14:15 <LordBrain> which seem to make the program an after thought
18:14:36 <LordBrain> the interface could be a configurable after thought...
18:14:50 <LordBrain> i'm sure someone has been working on something like this somewhere
18:17:11 <LordBrain> maybe we can have a Fetchable type class, with member fetch :: IO a
18:17:26 <LordBrain> then we just say x <- fetch
18:17:34 <LordBrain> hmmm
18:17:44 <LordBrain> we'd have to specify the type with a signature if we did that tho
18:19:31 <LordBrain> x <- fetch::IO MyType
18:21:29 <LordBrain> or get and put
18:28:07 <SamB> hmm hmm hmm
18:28:24 <SamB> why does everything come out zero...
18:29:10 * SamB is trying to figure out why his RML program sets all his objects to have the condition matching the number 0 in his encoding of the naturals... or doesn't set them at all...
18:30:45 <SamB> oh, no wonder... forgot to call write' from write...
18:30:56 <SamB> should work much better now ;-)
18:30:59 * SamB lints it first
18:32:52 <emertens> woot, I'm in 10th place among Haskell users on mathschallenge. (I encourage all of you to participate to get the haskell numbers up ;) )
18:33:59 <Failure02> i'm #1 :)
18:35:09 <emertens> I imagine it'll be a while before I'm able to tie you, but I'll continue ot work on it :)
18:35:25 <emertens> how many days did it take ot get there
18:35:54 <Failure02> dunno. i've been on there for more than two years... so i've just solved the new problems once they've come up
18:36:59 <emertens> Did you use Haskell for all of them?
18:37:55 <Failure02> no, python and c++. for the new problems, i most often use haskell
18:38:25 <emertens> How awkward is it to work with the bignum classes in c++?
18:38:28 <stepcut> hrm, is there something like the Reader monad where each call to 'ask' gets the next value from a list ?
18:38:38 <nostromo> does haskell support ipv6?
18:38:52 <SamB> stepcut: you mean a unique supply monad
18:38:52 <SamB> ?
18:39:02 <SamB> stepcut: you can do that, sure
18:39:05 <Failure02> emertens: I used NTL for the bignum problems
18:39:16 <Failure02> icky syntax, but it works alright
18:39:21 <SamB> doubt if there is a nice one
18:39:28 <stepcut> SamB: sort of. More like a parser monad where it is parsing a list of input tokens
18:39:51 <SamB> stepcut: see Parsec ;-)
18:39:55 <emertens> Failure02: i've never solved problem requiring bignums in c++, it seems like on a lot of the problems you get a huge advantage using haskell
18:40:11 <emertens> or any other language
18:40:18 <emertens> with built in support for such numbers
18:40:23 <stepcut> SamB: sadly Parsec does not seem to work to well for parsing things besides strings :-/
18:40:36 <SamB> stepcut: such as?
18:40:43 <Failure02> yeah, like python. :)
18:41:07 <stepcut> SamB: dunno, I just know that I have tried to use it for a number of other things in the past and always get stuck
18:41:25 <Failure02> i just resort to c++ when i'm not good enough to do it fast enough in the other languages
18:41:28 <SamB> stepcut: it works best for lists of Chars, sure
18:42:02 <Failure02> it's kind of unfair. on a lot of the problems, you need some very clever algo to do it in a dynamic language, but brute force in c++ is still faster
18:42:03 <stepcut> SamB: maybe it was a problem when I was trying to use it on non-list things, like ByteString
18:42:12 <SamB> stepcut: ah, that ;-)
18:42:21 <SamB> yeah, it doesn't yet support those, afaik.
18:42:34 <SamB> iirc there was a SoC project dealing with that?
18:43:24 <SamB> in any case it won't be in the release version
18:43:47 <stepcut> SamB: ah yes, in this case, Parsec will not work, because I need to intermix I/O :(
18:44:09 <SamB> oh, that sounds like a job for ParsecT!
18:44:25 <SamB> which unfortnately was not picked as an SoC project this year :-(
18:44:30 <stepcut> :(
18:44:35 <SamB> I should have done better applications
18:44:58 <SamB> I'm not sure it would work anyway, actually...
18:45:20 <stepcut> oh well, I can make my own monad transformer -- something simple should do the trick
18:45:54 <SamB> good luck!
18:47:04 <SamB> I suppose you'd be able to work something out with ParsecT, anyhow
18:47:18 <SamB> not sure how well it would do with nested parsing
18:47:47 <SamB> it would depend on how clever I was, I suppose...
18:54:33 <svref> I'm trying to print i for i from 1..10.  This isn't working at all, and I don't understand the error msg: map (putStrLn . show) [1..10]
18:55:29 <svref> To put it another way: how do I "map for side effect?"
18:55:47 <SamB> mapM
18:56:04 <SamB> or mapM_ if you don't need the results
18:56:21 <SamB> as in mapM_ print [1..10]
18:56:32 <svref> results are for woosies.  I just want side effects.  :]
18:56:40 <svref> Thanks.
18:56:57 <SamB> not woosies, just people who are doing something for more than side-effects
18:57:22 <svref> he he...sure sure.
18:58:10 <SamB> like, mapM queryUserAbout ["foo", "bar", "baz"] ;-)
18:58:24 <SamB> well, those are probably not good examples, but you know what I mean
18:58:35 <svref> yes
18:59:04 <SamB> things that need to be run in a monad that you want the results of
18:59:42 <SamB> or rather, one thing that you want to do in a monad for various things
18:59:54 <SamB> and get the results
19:00:02 <SamB> it need not be the IO monad
19:00:06 <SamB> any monad will work
19:08:31 <svref> is there a function that takes an int and shows it, with zero-padding at the front up to N characters?
19:09:21 <lispy> @index printf
19:09:21 <lambdabot> Text.Printf
19:09:41 <svref> sweet!
19:09:58 <lispy> not sure if it does what you want, but it might help
19:10:11 <lispy> it's also pretty easy to write a function to do it
19:10:30 <lispy> use show, length, take and an infinite list of zeros
19:11:10 <emertens> Failure02: you there?
19:12:24 <emertens> replicate n 0 == take n (repeat 0)
19:12:25 <lispy> > let showN n v = concatap show take (n - (length (show v))) (repeat 0)) ++
19:12:25 <lambdabot>  Parse error
19:12:32 <lispy> eer...
19:12:32 <lispy>  
19:12:38 <lispy> emertens: true
19:12:43 <lispy> stupid keyboard
19:13:02 <emertens> concatap... is that some super cool version of ap?
19:13:05 <emertens> ;)
19:13:37 <lispy> > let showN n v = concatMap show (replicate (n - (length (show v)))) ++ show v in showN 5 3
19:13:37 <lambdabot>    Expecting a function type, but found `[a]'
19:13:38 <lambdabot>    Expected type: [a]
19:13:38 <lambdabot>   ...
19:14:01 <lispy> emertens: my keyboard freaked out in the middle...i didn't mean to hit enter there :)
19:14:21 <lispy> > let showN n v = (concatMap show (replicate (n - (length (show v))))) ++ show v in showN 5 3
19:14:22 <lambdabot>    Expecting a function type, but found `[a]'
19:14:22 <lambdabot>    Expected type: [a]
19:14:22 <lambdabot>   ...
19:14:25 <lispy> hmm...
19:14:46 <SamB> if only it would give one more line of error!
19:14:58 <lispy> > let showN n v = replicate (n - (length (show v))) in showN 5 3
19:14:59 <lambdabot>  Add a type signature
19:15:03 <emertens> > let showN n v = replicate (n - length (show v)) 0 ++ show v in showN 5 3
19:15:04 <lambdabot>  add an instance declaration for (Num Char)
19:15:07 <emertens> heh
19:15:15 <lispy> oh
19:15:15 <emertens> > let showN n v = replicate (n - length (show v)) '0' ++ show v in showN 5 3
19:15:16 <lambdabot>  "00003"
19:15:25 <lispy> oh good call
19:15:32 <lispy> then you don't need concatMap
19:19:11 <syntaxfree> compiler-wise, is "map" more efficient than "fmap" over lists?
19:19:30 <lispy> the compiler should inline it all away
19:19:42 <syntaxfree> inline = turn it into loops?
19:19:55 <lispy> well, fmap = map for lists
19:19:58 <lispy> quite literally
19:20:08 <lispy> so it should just call map inplace of fmap
19:20:13 <syntaxfree> I thought fmap = map for monads.
19:20:16 <lispy> (or which ever one is more primitive)
19:20:24 <emertens> fmap is for Functors
19:20:27 <syntaxfree> yeah.
19:20:28 <syntaxfree> mapM.
19:20:37 <syntaxfree> brain slip.
19:20:38 <emertens> but he said that "fmap is map on lists"
19:21:07 <emertens> mapM binds a monad through a list
19:21:17 <syntaxfree> yes, yes.
19:21:20 <syntaxfree> I meant a functor.
19:21:21 <lispy> @type mapM
19:21:22 <lambdabot> forall b (m :: * -> *) a. (Monad m) => (a -> m b) -> [a] -> m [b]
19:21:41 <syntaxfree> I'm not getting enough sleep lately.
19:21:55 <syntaxfree> I am an economist and I'm okay; I hack all night and I work all day.
19:22:04 <lispy> syntaxfree: for any reasonable compiler i would expect fmap to have the same exact efficiency as map for lists... :)
19:23:13 <cmarcelo> @paste
19:23:13 <lambdabot> http://paste.lisp.org/new/haskell
19:23:27 <emertens> in the functor instance for [], there should be a line: fmap = map
19:24:09 <emertens> and since Haskell is strongly typed and all... the compiler knows which function is being used at compile time
19:24:32 <SamB> emertens: maybe
19:24:36 <SamB> sometimes it does
19:24:47 <SamB> if it did full program optimization it could
19:24:55 <syntaxfree> the GHC docs should have more information on the time efficiency of functions.
19:25:02 <syntaxfree> Some libraries have that info.
19:25:14 <lisppaste2> cmarcelo pasted "compilation error, undef reference to "__stginit_ZCMain" and to "ZCMain_main_closure"" at http://paste.lisp.org/display/24155
19:25:16 <lispy> and eta reduction/expansion is free in purely functional code so no excuse not to inline as needed
19:25:51 <cmarcelo> anyone is familiar with this error? was using GHC 6.5-trunk, and have a src/Main.hs with a function "main"...
19:25:52 <syntaxfree> cmarcelo: I get that error when I have no main function.
19:26:01 <syntaxfree> oh.
19:26:27 <lispy> using cabal?
19:26:35 <syntaxfree> "Build failed: 256 at util/build_pugs.pl line 319."
19:26:41 <syntaxfree> he's using some Perl-based installer.
19:26:45 <lispy> ah
19:26:47 <syntaxfree> it's Pugs.
19:26:56 <cmarcelo> yep
19:26:57 <syntaxfree> "Build failed: 256 at util/build_pugs.pl line 319."
19:26:58 <lispy> i have no clue then :(
19:27:05 <syntaxfree> Autrijus often comes here.
19:27:29 <syntaxfree> Autrijus = Audrey Tang :)
19:27:33 <syntaxfree> @seen autrijus
19:27:33 <lambdabot> I haven't seen autrijus.
19:27:51 <emertens> we all make mistake
19:27:52 <emertens> s
19:27:55 <emertens> see :)
19:28:05 <cmarcelo> well, usually this message means it's not finding a proper Main... right?
19:28:24 <syntaxfree> usually that message happens (to me) when it's not finding a proper main.
19:28:34 <SamB> lambdabot doesn't remember that "autrijus is now known as audreyt"?
19:28:45 <SamB> shame on her!
19:29:01 <lispy> @seen audreyt
19:29:01 <lambdabot> audreyt is in #haskell and #perl6. I last heard audreyt speak 1 hour, 1 minute and 47 seconds ago.
19:29:11 <SamB> her being lambdabot, not audreyt
19:29:19 <syntaxfree> GHC-generated C code looks a lot like mzscheme-generated C code.
19:29:42 <syntaxfree> @seen boo
19:29:42 <lambdabot> boo has changed nick to samb.
19:29:43 <lambdabot> samb is in #perl6 and #haskell. I last heard samb speak 31 seconds ago.
19:29:45 <lispy> i'm pretty good at reading C code, and ghc generated C tends to give me a headache :)
19:30:02 <emertens> leave the computer programming to the compilers please ;)
19:30:15 <stepcut> :p
19:30:22 <SamB> well, GHC is very bad at writing C
19:30:33 <SamB> it uses gotos for its looping and doesn't indent a thing
19:30:49 <syntaxfree> I have a friend in compsci who is obsessed over algorithmic efficiency, is opposed to garbage collection as a matter of principle, etc. etc.
19:30:51 <emertens> gotos are only bad if you expect to be able to reason about the code :)
19:30:51 <lispy> otoh, it's C programs tend to have less bugs than mine
19:30:52 <stepcut> at least it does not use setjump/longjump ;)
19:31:05 <syntaxfree> I like to tease him telling he's the stonemason, and I'm the architect ;)
19:31:22 <SamB> emertens: it makes it more difficult for GCC to reason about the code, though
19:31:27 <SamB> where reason about == optimize
19:31:30 <lispy> syntaxfree: GC can improve performance in many cases
19:32:37 <lispy> although, i've heard of this other thing call, algorithm design that supposedly improves performance even more than duff's device...*gasp*
19:32:38 <SamB> especially when things allocated are for the most part forgotten quite quickly
19:32:59 <LordBrain> is it possible to have an HList as a member of a record?
19:33:31 <lispy> you want something like? data Foo = Foo { bar :: HList }
19:33:36 <LordBrain> yeah
19:33:41 * lispy has never used HList
19:33:43 <lispy> is it weird?
19:33:56 <LordBrain> i've not used it either
19:34:00 <SamB> it is wierd
19:34:19 <SamB> the lists are in the types, iirc
19:34:41 <LordBrain> thats why its not possible right, what i said?
19:35:54 <LordBrain> the type signature would specify what types are stored in the HList....
19:36:24 <lispy> from a type point of view, what is different about records?
19:36:43 <lispy> i'm sort of lost...if you can normally use HList somewhere, why would a record prevent it?
19:36:56 <LordBrain> i'm lost too
19:37:01 <LordBrain> hence my question
19:37:02 <LordBrain> hehe
19:37:18 <lispy> @slap LordBrain -- ;)
19:37:18 * lambdabot smacks LordBrain -- ;) about with a large trout
19:37:22 <lispy> er...
19:37:27 <lispy> @slap lispy
19:37:27 * lambdabot smacks lispy about with a large trout
19:37:32 <LordBrain> i'm thinking of an approach to IO with a separate interface
19:37:37 <LordBrain> like
19:37:52 <LordBrain> main = withInterface Interface $ do
19:38:58 <LordBrain> interface should be lower case there
19:39:52 <LordBrain> tho...
19:40:11 <LordBrain> basicly i could just forget the withInterface part.. and have interfaces defined as functions themselves
19:41:12 <LordBrain> i'm not very good with making new monads yet tho
19:43:43 <lispy> LordBrain: maybe you could use that trick where you newtype the state monadand extend it with your application's state
19:44:28 <LordBrain> hmmm thats interesting
19:44:50 <LordBrain> i want to have tags tho, like all the io is tagged
19:45:00 <LordBrain> you specify a bunch of tags when you run a get
19:45:09 <LordBrain> and also when you run a put
19:45:45 <lispy> what are tags?
19:45:45 <LordBrain> then the interface figures out how to organize the actual inputting and outputting based on the tags
19:45:48 <lispy> what do they do?
19:45:49 <LordBrain> just strings
19:46:01 <lispy> mapReduce?
19:46:13 <LordBrain> @type mapReduce
19:46:14 <lambdabot> Not in scope: `mapReduce'
19:46:18 <LordBrain> never heard of it
19:46:34 <LordBrain> for example
19:47:00 <lispy> mapReduce is what google uses to run search queries and other things
19:47:09 <LordBrain> google uses haskell?
19:47:11 <lispy> @google mapReduce
19:47:12 <lispy> no
19:47:13 <lambdabot> http://labs.google.com/papers/mapreduce.html
19:47:13 <lambdabot> Title: Google Research Publications
19:47:14 <lispy> well, maybe
19:47:19 <lispy> but they implemented it in C++
19:47:23 <dons> they like haskell, they say
19:47:30 <dons> but whether they use it. hmm.
19:47:43 <dons> they certainly gave us a good chunk of SoC slots
19:50:15 <lispy> with as many bright researchers as they have, you know *someone* there is using it
19:50:27 <lispy> who knows if it's widespread or applied to application development tho
19:53:25 <LordBrain> hmmmm i'm not thinking in terms of key value pairs so much
19:53:30 <LordBrain> rather
19:53:37 <LordBrain> you have a particular input item say
19:53:57 <LordBrain> that item is tagged in many ways...
19:54:14 <LordBrain> which basicly means
19:54:28 <LordBrain> for each tag there is a set, and when you tag an item, it belongs to that set
19:54:34 <LordBrain> then later on
19:54:37 <LordBrain> say the gui maker
19:54:41 <LordBrain> comes along
19:54:49 <LordBrain> and he says fetch me all the items with such and such tag
19:55:09 <LordBrain> and creates an input widget for each
19:56:35 <LordBrain> hmmmm ideally in fact, the items could be tagged after the fact..
19:59:01 <LordBrain> programmer writes program which creates a sort of database of inputs and outputs, then as a separate phase someone tags those ins and outs so that a nice looking ui can be generated.
19:59:25 <LordBrain> using a UI generator that someone wrote.
19:59:36 <lispy> LordBrain: you've started down a rabbit hole so deep it should perhaps be expressed used an eDSL...i say this because it sounds more like a paradigm of expression than anything else
19:59:57 <LordBrain> eDSL?
20:00:00 <LordBrain> what's the e?
20:00:03 <LordBrain> embeded?
20:00:16 <lispy> yeah
20:02:07 <LordBrain> well... i'm just talking about having UI's generated basicly. I want to write a program without worrying about the UI at all... i certainly dont want a langauge for creating UI's for that...
20:03:09 <LordBrain> like x <- userInput >> userOutput y
20:03:14 <lispy> LordBrain: i know the feeling...and for me it usually means i haven't thought it out enough
20:04:22 <LordBrain> maybe put a name on each thing
20:05:03 <LordBrain> so x <- userInput "FileToProcess"
20:05:09 <LordBrain> something like that
20:06:03 <LordBrain> and have a program which takes my program, and displays basicly a bunch of Inputs and outputs, which are then tagged appropriately in order for them to be plugged into a sort of gui template.
20:07:45 <LordBrain> so the template says, here put all these things at the top of the window, using such and such widgets, and put this down at the bottom, and throw in some graphics here and there which are nothing but decorations.
20:08:38 <dons> yay, hs-plugins works on the Mac again
20:09:19 <LordBrain> the "template" would be the DSL
20:09:39 <dons> ?users
20:09:43 <lambdabot> Maximum users seen in #haskell: 235, currently: 191
20:09:45 <syntaxfree> dons: you mean, on OS X.
20:09:59 <dons> syntaxfree: I do.
20:10:21 <dons> they're not called macintoshes, anymore, I take it? ;)
20:11:13 <LordBrain> or it could just be something like an XSSLT
20:15:29 <LordBrain> hmmmm
20:22:29 <syntaxfree> dons: Macintoshes can run a number of OSes.
20:22:55 <syntaxfree> PPC-based Macs can run most of the Linuces, the [Free|Open|Net]BSDs  and PegasOS, a PowerPC-specific OS.
20:23:21 <syntaxfree> x86 Macs can run most of the Linuces, the [Free|Open|Net]BSDs and various versions of Microsoft Windows.
20:25:01 <dons> oh, interesting, http://www.seas.upenn.edu/~lipeng/homepage/unify.html
20:25:02 <lambdabot> Title: Unifying events and threads
20:25:13 <dons> syntaxfree: yes, I know. I run netbsd on my mac.
20:25:26 <dons> on my 68k mac, in fact.
20:25:39 <syntaxfree> oh, I even forgot about 68k macs.
20:25:54 <syntaxfree> Now that PPC Macs are out of the market, I officially own a Low-End Mac :)
20:25:59 <dons> heh
20:26:30 <dons> my 68k box is now approaching 15 years, without hardware failure
20:26:44 <syntaxfree> wow, I wonder if my Mini is that well-built.
20:27:41 <foxy> dons, Hi, could you try compiling yi+gtk and doing 'C-x C-f <filename>'  for me?
20:28:02 <dons> foxy: hmm, i need a gtk2hs installed, yes?
20:28:14 <dons> what happens? badness?
20:28:40 <dons> (/me isn't sure he can build yi+gtk atm)
20:28:44 * syntaxfree attracts attention to his talking on #haskell-blah
20:29:17 <foxy> dons, some sort of deadlock with window focussing...
20:29:25 <foxy> s/ss/s/
20:29:49 <dons> hmm
20:30:04 <dons> focusing. eh? a gtk issue? or a yi issue?
20:30:34 <syntaxfree> what is concurrent programming?
20:30:36 <foxy> dons, methinks a yi issue
20:30:36 <dons> I suppose its possible the code could be trying to take the state MVar from inside a withEditor block. that's usually the cause of deadlocks
20:30:58 <dons> syntaxfree: programs written using multiple threads of control
20:31:08 <syntaxfree> also known as multi-threading?
20:31:19 <foxy> dons, I think that what happens is that  a GUI generated focus calls 'focus' which calls widgetGrabFocus
20:31:44 <dons> ok
20:32:06 <foxy> dons, BTW I have a suggestion for your next assault after fps...
20:32:17 <dons> @tell joelr maybe you're interested, http://www.seas.upenn.edu/~lipeng/homepage/unify.html
20:32:18 <lambdabot> Consider it noted.
20:32:20 <foxy> lapack - compatible fast pack matrices :D
20:32:20 <dons> foxy: oh, yes?
20:32:26 <dons> oh hmm.
20:32:39 <dons> not bad, not a bad idea at all
20:32:53 <LordBrain> syntaxfree: can you point me to some information about this pegasos
20:33:02 <LordBrain> google just shows hardware called pegasos
20:33:05 <dons> i was also planning on writing my dissertation
20:33:50 <LordBrain> the pegasos hardware ships with Debian as the OS, or Ubuntu or Gentoo
20:35:13 <foxy> dons, heh
20:47:57 <SamB> what, and save you the enjoyment of installing it yourself?
20:48:51 <johnnowak> it is so easy nowadays anyway...
20:49:14 <johnnowak> probably faster than booting an older installed copy and recompiling half the world with gentoo.
20:49:14 <SamB> and how do they know how you want it partitioned?
20:49:28 <johnnowak> right.
20:50:24 <SamB> it should just come with ubuntu preinstalled and a rescue disk, and maybe a disk each to kick of debian and gentoo installation
20:50:47 <SamB> or they could leave out the gentoo one, because if you can figure out how to install it you can figure out how to get it too
20:51:49 <SamB> a friend of mine once bought gentoo by mistake and I couldn't get it to work :-(
20:51:55 <SamB> it wouldn't boot right
20:52:06 <SamB> something was wrong with the initrd
20:53:09 <syntaxfree> I just came up with a better syntax for Ordering functions like sortBy
20:53:28 <syntaxfree> criteria func = (\x y->compare (func x) (func y))
20:53:37 <SamB> uh
20:53:40 <SamB> comparing?
20:53:46 <SamB> the name is comparing?
20:53:58 <syntaxfree> there's "comparing".
20:54:06 <syntaxfree> Dang, these Haskell people sure are smart ;)
20:54:10 <SamB> ... it does need to go in the library, though...
20:54:34 <SamB> the names are harder than the functions, it seems ;-)
20:54:55 <lispy> @hoogle comparing
20:54:56 <lambdabot> No matches found
20:54:58 <syntaxfree> > let criteria func = (\x y->compare (func x) (func y)) in sortBy (criteria (**2)) [-1, 0, 0.25]
20:54:59 <lambdabot>  [0.0,0.25,-1.0]
20:55:02 <SamB> lisppaste2: as I said...
20:55:04 <SamB> er.
20:55:07 <SamB> lispy:
20:55:10 <SamB> as I said...
20:55:15 <SamB> it needs to go in the library
20:55:31 <syntaxfree> SamB: Lisppaste is not Eliza. (L.I.N.E.)
20:55:32 <lispy> hmm...i read that but i don't think i understood it
20:55:45 <lispy> which library?
20:55:54 <SamB> @oldwiki LicensedPreludeExts
20:55:54 <lispy> so i thought...hey, maybe it's in hoogle and i haven't heard of it
20:55:55 <lambdabot> http://www.haskell.org/hawiki/LicensedPreludeExts
20:56:20 <SamB> it should be added to Prelude, IMO
20:56:43 <dons> ?pl \x y->compare (func x) (func y)
20:56:43 <lambdabot> (. func) . compare . func
20:56:56 <syntaxfree> SamB: ah, it's not in Haskell yet, it's an user contribution.
20:57:02 <syntaxfree> I was sound asleep and I dreamt of thar.
20:57:02 <dons> sortBy ((. f) . compare . f) -- ;)
20:57:18 <dons> but usually you'd write : \x y -> f x `compare` f y
20:57:18 <lispy> ?pl \x y -> (func x) `compare` (func y)
20:57:19 <lambdabot> (. func) . compare . func
20:57:28 <SamB> syntaxfree: you say you came up with this in your sleep?
20:57:31 <SamB> impressive ;-)
20:57:41 <dons> hmm. seems there should be a join f in there somewhere
20:57:42 <syntaxfree> I once invented relational databases in my sleep.
20:57:46 <SamB> hahahaha
20:57:55 <lispy> @quote lispy
20:57:55 <lambdabot>  I just remembered this dream i had the other morning.  I was trying to tell my alarm clock how to snooze by using a list comprehension
20:58:07 <lispy> ^^^ that's what i've dreamed up ;)
20:58:09 <dons> ?pl \x y -> (f x, f y)
20:58:09 <lambdabot> (. f) . (,) . f
20:58:13 <syntaxfree> I was thinking of some way to solve this problem I had, short of having to learn relational databases.
20:58:18 <dons> ?pl \f x y -> (f x, f y)
20:58:18 <lambdabot> flip =<< (((.) . (,)) .)
20:58:26 <dons> ?pl \f (x,y) -> (f x, f y)
20:58:27 <lambdabot> (`ap` snd) . (. fst) . (flip =<< (((.) . (,)) .))
20:58:29 <SamB> I need to get better at Haskell
20:58:35 <syntaxfree> So I woke up and started hacking away, and then I showed it to my buddy who is in comp sci.
20:58:42 <SamB> I can hardly think in it without a writing implement or keyboard
20:58:47 <dons> ?type (f *** f)
20:58:49 <lambdabot> Not in scope: `f'
20:58:49 <lambdabot>  
20:58:49 <lambdabot> <interactive>:1:7: Not in scope: `f'
20:58:54 <dons> ?type \f -> (f *** f)
20:58:55 <lambdabot> forall (a :: * -> * -> *) b c. (Arrow a) => a b c -> a (b, b) (c, c)
20:59:00 <syntaxfree> Only to be told that _was_ a relational database.
20:59:05 <SamB> syntaxfree: well
20:59:16 <SamB> that saved you the trouble of having to learn them on purpose ;-)
20:59:26 <SamB> enduring some horrible textbook or the like
21:00:26 <syntaxfree> SamB: I'm lazy about learning.
21:00:40 <syntaxfree> Years before the relational database incident, I was refusing to learn SQL.
21:01:00 <syntaxfree> Instead, I wrote a humongous, horrible, inefficient CSV-handling library to solve this database problem.
21:01:06 <SamB> ouch
21:01:19 <syntaxfree> That stuff was for my father's company.
21:01:21 <SamB> maybe it *would* have saved trouble to learn relational databases
21:01:31 <syntaxfree> Once in a while the humongous CSV library comes back  to bite me.
21:01:33 <SamB> not to advocate SQL itself
21:01:57 <syntaxfree> every once in a while PHP will actually break syntax in upgrade cycles.
21:02:09 <lispy> i've been using FP longer than SQL...recently i was using SQL thinking it's really just the list monad + filter functions
21:02:11 <syntaxfree> Then I'm forced to go back and revise the humongous CSV library.
21:02:12 <SamB> I don't remember it very well, honestly...
21:02:15 <dons> syntax is hard ;)
21:02:28 <SamB> lispy: that does sound likely
21:02:38 <SamB> I don't think I've looked at it lately though
21:03:06 <SamB> lispy: so basically just fancy list comprehensions
21:03:14 <lispy> SamB: yeah
21:03:25 <SamB> with nicer records
21:03:31 <lispy> i'm sure i'm over simplifying...but i don't use the full power of SQL
21:03:33 <syntaxfree> records are cool.
21:03:39 <syntaxfree> records are pervasive in  GNU R.
21:03:47 <SamB> ... hence the name?
21:03:57 <SamB> or does it stand for the 3 Rs?
21:03:58 <lispy> no, R is a clone of S
21:04:01 <SamB> oh.
21:04:12 <SamB> shouldn't the clone of S be called T?
21:04:29 <syntaxfree> I keep going back to GNU R as an example of a good, not too high-brow "pragmatic" language.
21:04:33 <SamB> > ['R'..]
21:04:35 <lambdabot>  "RSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\DEL\128\129\130\131\132\133\...
21:04:56 <lispy> SamB: yeah, funny that
21:04:56 <syntaxfree> It supports full higher-order functions. Including functions returning functions.
21:05:20 <syntaxfree> Some problems in statistics require nontrivial transformations of vectors into functions.
21:05:22 <lispy> R is internally based on something similar to lisp
21:06:02 <lispy> i'm not an R programmer, but i built a gui in java that featured an R interpreter
21:06:10 <lispy> (for work)
21:06:20 <lispy> fun project
21:07:12 <SamB> ouch ack
21:07:17 <SamB> my code still doesn't work
21:08:11 <SamB> it takes a lot longer than it used to, though, which might be a good sign
21:08:58 <SamB> hmm, I think it is time to restart the UM again
21:09:04 <dons> heh
21:09:27 <SamB> dons: I'm having trouble with adventure still ;-)
21:10:03 <SamB> okay, I will leave it to get the uploader over night
21:10:05 <lispy> SamB: do you hack on zsnes ore something like that?
21:10:58 <SamB> lispy: a bit
21:11:04 <lispy> cool
21:11:22 <SamB> I've ported the debugger mostly to C
21:11:32 <emertens> "teacha told me ta go out side and have recess, I didn't go, 'cause I don play)
21:11:57 <SamB> I need to gather up the motivation to fix a couple of things still...
21:12:21 <lispy> cool
21:12:30 <SamB> like a couple of ASM routines that take parameters on the stack from C code... Nach says that that is a big no-no
21:12:44 <SamB> oh, and they tell me that this debugger isn't that great
21:12:55 <lispy> hmm
21:12:57 <lispy> i hate that
21:13:09 <SamB> I gather that it is mostly useful for debugging ZSNES
21:13:15 <lispy> working on something and then the maintainers are like, "Oh, doing it that way sucks...we can't accept your hard work"
21:13:30 <LordBrain> big no-no because it hardwires the calling convention?
21:13:39 <SamB> LordBrain: something like that
21:13:47 <LordBrain> hmmm
21:13:50 <SamB> he also mumbled something about OS X
21:14:05 <SamB> anyway, he didn't reject my work
21:14:28 <SamB> he's just left me with the nagging feeling that ought to fix it but don't realy care yet
21:14:37 <LordBrain> i thought the C calling convention was standardized...
21:14:40 <SamB> er, that *I* ought to fix it
21:14:43 <SamB> LordBrain: me too!
21:14:58 <SamB> but he didn't seem to think either MS or apple followed the convention, at least not always
21:15:04 <lispy> whatif the C function changes?
21:15:16 <SamB> lispy: changes?
21:15:20 <lispy> and what if the function was inlined?
21:15:24 <SamB> that is what the C++ convention is for!
21:15:30 <LordBrain> thats true, MS has something weird i think i recall... function calls are wrapped in macros always..
21:15:46 <SamB> and you can't inline a function written in NASM into C!
21:15:53 <SamB> LordBrain: not always
21:16:09 <lispy> i thought MS provided stdcall macro to convince their compile to behave
21:16:10 <SamB> just the ones with the A/W variants, mostly
21:16:21 <LordBrain> hmm i dont know
21:16:24 <SamB> lispy: they have that
21:16:29 <SamB> I thought it was the default though
21:16:33 <LordBrain> it's beena  long time since i programmed windows.. and i didnt do very much of it then
21:16:37 <lispy> SamB: okaky, i was just trying to find sometihng that might change and screw up the code ;)
21:16:46 <SamB> oh wait, stdcall is the wierd way
21:16:56 <SamB> cdecl is the normal one
21:17:08 <SamB> anyway, I am supposed to be going to bed
21:17:10 <lispy> stdcall is what you need for dlls...i think stdcall is the pascal way
21:17:15 <SamB> ;-)
21:17:25 <LordBrain> yes, i think thats right
21:17:25 <SamB> lispy: maybe it is, or maybe it just was...
21:17:38 <SamB> who knows what Pascal uses these days?
21:17:40 <LordBrain> for some strange reason... they use pascal calling convention on dlls
21:18:20 <SamB> I think they used to be written in Haskell, in the distant past
21:18:30 <LordBrain> the dlls?
21:18:32 <SamB> heh
21:18:35 <SamB> I mean PASCAL
21:18:37 <SamB> I'm sleepy
21:18:40 <LordBrain> haha
21:18:41 <SamB> they sound so similar!
21:18:50 <lispy> but not as sleep as you're gonna be if you stay up ;)
21:18:55 <lispy> Hascal
21:19:00 <lispy> Paskell
21:19:28 <SamB> anyway, quit distracting me!
21:19:36 <lispy> yeah!
21:19:47 <SamB> ;-)
21:19:47 <lispy> i was going to go to the store...but i'm dozing off just now
21:19:49 <LordBrain> so what is the proper way to write your asm function?
21:19:52 <lispy> maybe i'll sleep instead
21:20:17 <SamB> LordBrain: pass parameters in global variables, of course!
21:20:29 <lispy> lol
21:20:35 <lispy> write it out to a file
21:20:40 <lispy> then read it back in
21:20:45 <SamB> lispy: haha
21:20:46 <SamB> no
21:20:50 <lispy> this is why people use asm or performance
21:20:51 <LordBrain> that would be crazy..
21:20:56 <LordBrain> lol
21:21:02 <lispy> asm gives you the really fast IO for free
21:21:03 <SamB> I don't think ZSNES is even allowed to access files from ASM anymore
21:21:24 <lispy> why does it even need asm?
21:21:32 <lispy> does it do some JIT?
21:21:39 <SamB> well, because it is mostly written in ASM ?
21:21:54 <LordBrain> never ported...
21:21:59 <LordBrain> hmm
21:22:15 <SamB> at one point, I hear, it was completely written in ASM
21:22:40 <lispy> you should port it to UM
21:22:49 <SamB> apparantly now it is more like 77%
21:22:52 <LordBrain> i didnt participate in the whole UM thing
21:22:53 <SamB> by some metric or other
21:23:02 <SamB> anyway, bed bed bed!
21:23:10 <lispy> good night
21:23:37 <LordBrain> passing things on the stack is more efficient than using global variables
21:23:51 <LordBrain> and i would think if you're using asm...
21:24:01 <LordBrain> oh well
21:24:51 <SamB> I probably never will get around to fixing it until someone complains that my code is crashing on them ;-)
21:25:12 <SamB> it is the lazy way...
21:25:18 <SamB> now for real...
21:25:23 <lispy> just rewrite zsnes to haskell
21:25:34 <LordBrain> hmmm
21:26:03 <LordBrain> i've not yet seen really fast animation in haskell... yampa is slow
21:26:37 <lispy> recently i found that generating haskell code programmatically is kind of nice because the haskell compiler is so picky...it lets you know when you have a typo
21:26:46 <dons> LordBrain: how about Frag?
21:26:52 <lispy> fran and the like are fast
21:26:57 <lispy> oh, frag is cool too
21:27:02 <LordBrain> frag uses yampa..
21:27:07 <dons> seems pretty quick (and its even unoptimised)
21:27:09 <LordBrain> what machines do you have?
21:27:22 <lispy> i ran it on a G4 1.2 Ghz
21:28:02 <dons> Frag uses some fast texture gpu extensions, iirc
21:28:13 <LordBrain> gpu?
21:28:23 <dons> the graphics processor
21:28:25 <lispy> LordBrain: the processor inside modern graphics cards
21:28:28 <LordBrain> oh
21:28:41 <dons> yampa isn't the rendering engine anyway
21:28:46 <dons> its using OpenGL, iirc
21:29:31 <LordBrain> i havent tested it
21:30:04 <LordBrain> i probably dont have the libraries necessary to make use of my gpu
21:30:12 <LordBrain> on debian
21:30:32 <dylan> LordBrain: it's easy if you use ati or nvidia, and don't use 64bit.
21:30:51 <dylan> (nvidia is still easy in amd64, actually)
21:30:53 <LordBrain> i havhe an Intel Graphics card
21:30:59 <dylan> hmm
21:31:01 <LordBrain> hmmm
21:31:03 <dylan> dunno about that
21:31:18 <LordBrain> i had trouble with nvidia once
21:31:27 <dons> heya dylan
21:31:31 * lispy prefers nvidia
21:31:32 <dons> how's the haskell hacking coming along?
21:31:51 <LordBrain> it depends on the particular nvidia card... some have different chipsets
21:32:02 <dylan> dons: I have a getDirectoryContentsRec function that has no problem with working on / :-)
21:32:24 <LordBrain> i usually prefer whatever i get on the cheap...
21:32:29 <dylan> (although, I sort of bugged my local haskell expert to make it work. ;))
21:32:39 <dons> dylan: heh. there's code in hmp3 to do that :)
21:32:58 <dylan> it was a good lesson in the IO and List monads.
21:33:00 <dons> since hmp3 has to reads directory trees of hmp3 files quickly
21:33:01 <dons> yeah, cool
21:33:09 <LordBrain> i've heard good things about nvidia support on linux tho... but when i finally encountered a computer with an nvidia card, it didnt work.
21:33:37 <dylan> the connection between list comprehensions and the list monad was enlightening.
21:33:39 <dons> a bit of stuff here, http://www.cse.unsw.edu.au/~dons/code/hmp3/FastIO.hs and http://www.cse.unsw.edu.au/~dons/code/hmp3/Tree.hs
21:33:43 <dons> dylan: ah, yes.
21:33:50 <dons> we used to have generic monad comprehensions
21:34:02 <dylan> But that is not decidable, yes?
21:34:09 <dons> hmm?
21:34:12 <LordBrain> why'd they get rid of the generic comprehensions?
21:34:28 <dons> every list comprehension error would mention monads
21:34:36 <dylan> I remember reading generic monad comprehensions had some termination problem in the type checker, or some such?
21:34:54 <dons> I'm not aware of that. they were certainly part of haskell for several years
21:34:58 <dylan> Only because of error messages?
21:35:11 <dons> there's some examples here ,http://www.cse.unsw.edu.au/~dons/data/cc.prelude
21:35:15 <dons> dylan: i think so, yes.
21:35:21 <dylan> I have a habit for remembering bits and pieces of everything. :-/
21:35:33 <dylan> not always correctly.
21:35:42 <dons> filter           :: Monad0 m => (a -> Bool) -> m a -> m a
21:35:43 <dons> filter p xs       = [ x | x<-xs, p x ]
21:35:45 <dons> is a nice example
21:36:15 <dons> or mapl             :: Monad m => (a -> m b) -> ([a] -> m [b])
21:36:15 <dons> mapl f []         = [ [] ]
21:36:15 <dons> mapl f (x:xs)     = [ y:ys | y <- f x, ys <- mapl f xs ]
21:36:45 <lispy> Monad0?
21:37:10 <dylan> Monad0 would be a cool name for a haskell-powered... robot or something.
21:37:34 <lispy> Monad5000
21:37:44 <dylan> Monad0 -- perhaps an old name for MonadPlus?
21:37:46 <lispy> johny5 is alive!
21:38:03 <lispy> perhaps, i do see something about monad zero
21:38:17 <dylan> Monad0 -- mzero, MonadPlus -- mplus?
21:38:21 <lispy> instance Monad0    [] where zero         = []
21:38:49 <dylan> That looks like the defintion of mzero?
21:38:57 <dylan> (for lists)
21:39:18 <lispy> @hoogle copy
21:39:18 <lambdabot> Distribution.InstalledPackageInfo.copyright :: InstalledPackageInfo -> String
21:39:18 <lambdabot> Distribution.PackageDescription.copyright :: PackageDescription -> String
21:39:18 <lambdabot> System.Directory.copyFile :: FilePath -> FilePath -> IO ()
21:39:41 <lispy> this prelude has a lot of things which seem to have been removed
21:40:27 <LordBrain> some were pushed to the List monad it seems
21:40:29 <LordBrain> er
21:40:31 <LordBrain> module
21:40:33 <LordBrain> the list module
21:40:51 <lispy> @hoogle asTypeOf
21:40:52 <lambdabot> Prelude.asTypeOf :: a -> a -> a
21:41:20 <lispy> > 1 `asTypeOf` "hi"
21:41:21 <lambdabot>  add an instance declaration for (Num [Char])
21:41:31 <lispy> > 1 `asTypeOf` 2
21:41:31 <lambdabot>  1
21:41:41 <lispy> what is this functon for?
21:42:06 <dons> its useful in the days before we had type signatures you could place anywhere
21:42:08 <LordBrain> > 1 `asTypeOf` 1.03
21:42:09 <lambdabot>  1.0
21:42:11 <dons> you'd just write:
21:42:14 <lispy> asTypeOf               :: a -> a -> a
21:42:15 <dons> > 1 :: Float -- now
21:42:15 <lispy> x `asTypeOf` _          = x
21:42:17 <lambdabot>  1.0
21:42:30 <dons> > 1 `asTypeOf` pi
21:42:31 <lambdabot>  1.0
21:42:36 <lispy> huh
21:42:54 <lispy> i think i get it
21:43:00 <dons> -- | 'asTypeOf' is a type-restricted version of 'const'.  It is usually
21:43:01 <dons> -- used as an infix operator, and its typing forces its first argument
21:43:01 <dons> -- (which is usually overloaded) to have the same type as the second.
21:43:01 <dons> asTypeOf        :: a -> a -> a
21:43:01 <dons> asTypeOf        =  const
21:43:33 <LordBrain> hmmm
21:43:35 <Korollary> It's meant to be used like polymorphic type annotations
21:43:36 <lispy> @type const
21:43:37 <lambdabot> forall a b. a -> b -> a
21:43:39 <dons> which is what we use lexically scoped type variables, pattern signatures, or just more type annotations, for
21:44:14 <dons> so you get this constraint : f x (y :: a) = x :: a
21:44:31 <dons> but its valid haskell 1.0 :)
21:45:52 <foxy> does dependent typing imply run-time type-checking?
21:46:05 <foxy> (necessarily)
21:46:37 <dons> nope.
21:46:38 <LordBrain> i'm not sure what you mean by dependent typing.
21:46:50 <foxy> @where epigram
21:46:51 <lambdabot> http://www.e-pig.org/
21:47:00 <dons> foxy: if you just lift values into the type level, you may need to evaluate during type checking
21:47:14 <dons> but if you have types as values, then you might need to typecheck at runtime
21:47:30 <dons> (i.e. like Data.Typeable)
21:48:47 <foxy> It seems to me that there is some sort strong equivalence going on, like dependent typing (types as values) _requires_ run-time type checking
21:49:07 <dons> types as values, maybe yes.
21:49:17 <dons> values as types, which is more usual, no.
21:49:32 <dons> usually you want dependent types to express things like: Array 0 9 Int
21:50:16 <dons> a good reference for thinking about this kind of stuff, is the pure type  systems work. the SPJet al paper 'Henk' is a good introduction from a haskellers point of view
21:50:40 <dons> here, http://haskell.org/haskellwiki/Research_papers/Type_systems#Pure_type_systems
21:50:42 <lambdabot> Title: Research papers/Type systems - HaskellWiki
21:50:57 <foxy> I'm thinking about something like doing a case on type i.e. case typeOf foo ; Char -> doChar foo ; Int -> doInt foo
21:52:50 <foxy> and also, if dependent typing is merely the addition of run-time type-checking you could turn theorem prover - Epigram type code into Haskell + RT typing
21:57:54 <syntaxfree> http://haskell.org/haskellwiki/Research_papers
21:57:55 <lambdabot> Title: Research papers - HaskellWiki
21:58:08 <syntaxfree> that recent "History of Haskell" paper should be in the overview section of that site.
21:59:02 <LordBrain> Is there something like a "making your own monads" tutorial? which maybe has some exercises to help you get some ideas about when you can roll your own and how to go about it?
21:59:25 <stepcut> http://www.cs.chalmers.se/~augustss/AFP/monads.html
21:59:27 <lambdabot> Title: Systematic Design of Monads
21:59:31 <LordBrain> ah thankyou
21:59:49 <stepcut> I have not actually read that, but shapr recommended it on his blog
21:59:52 <LordBrain> :)
21:59:53 <dons> syntaxfree: good idea.
22:00:03 <dons> i'll add it now.
22:00:35 <syntaxfree> :)
22:00:42 <stepcut> LordBrain: is from '95 for the syntax may be a bit different
22:01:39 <foxy> I think all this MPTC type-level programming could be more elegant, since we've already got a language for doing computations (\-calculus) why reinvent the wheel at the type level?  (I do think that being able to prove properties at the type level is a _good_ thing)
22:02:03 <dons> indeed, foxy, with the new associated types/System Fc work, we do have proper type level functions now
22:02:55 <foxy> Are associated types going to be incorporated into Haskell?
22:03:18 <foxy> also, I reckon a mechanism for verifying algebraic rules in classes would be good.
22:03:36 <LordBrain> yeah
22:03:41 <LordBrain> that does sound nice
22:03:51 <foxy> @google "System F_c"
22:03:52 <lambdabot> No Result Found.
22:04:07 <lispy> foxy: but how can you really verify algebraic laws in general?
22:04:11 <sieni> foxy: how do you do that and avoid problems with e.g. the halting problem?
22:04:17 <lispy> foxy: you'd have to test all values right?
22:05:21 <dons> avoid general recursion?
22:05:29 <foxy> lispy, well the type-checker is turing complete
22:05:42 <dons> http://haskell.org/haskellwiki/Haskell_Equational_Reasoning_Assistant
22:05:44 <lambdabot> Title: Haskell Equational Reasoning Assistant - HaskellWiki
22:06:11 <lispy> foxy: yes, but i want the compile to complete in finite time
22:06:59 <foxy> data Function a = Function { complexity :: BigOh, documentation :: Documentation, function :: a }
22:07:26 <syntaxfree> lispy: I want this, I want that, spoiled wah wah wah ;)
22:07:50 <lispy> i know, lispers can't be choosers...
22:09:07 <syntaxfree> @type unfoldl
22:09:09 <lambdabot> Not in scope: `unfoldl'
22:09:12 <syntaxfree> @type unfold
22:09:14 <lambdabot> Not in scope: `unfold'
22:09:18 <syntaxfree> @type unfoldr
22:09:20 <lambdabot> forall a b. (b -> Maybe (a, b)) -> b -> [a]
22:09:26 <lispy> syntaxfree: hoogle is faster
22:09:32 <lispy> @hoogle unfold
22:09:32 <lambdabot> List.unfoldr :: (a -> Maybe (b, a)) -> a -> [b]
22:09:33 <lambdabot> Data.List.unfoldr :: (b -> Maybe (a, b)) -> b -> [a]
22:09:33 <lambdabot> Data.Tree.unfoldForest :: (b -> (a, [b])) -> [b] -> Forest a
22:10:02 <syntaxfree> > unfold (\x->(x+1, x-1)) 3
22:10:03 <lambdabot>  Not in scope: `unfold'
22:10:18 <syntaxfree> > unfoldr (\x->(x+1, x-1)) 3
22:10:18 <lambdabot>  Couldn't match `Maybe (a, b)' against `(a1, b1)'
22:10:35 <lispy> > unfolder (\x -> Just (x+1, x-1)) 3
22:10:35 <lambdabot>  Not in scope: `unfolder'
22:10:41 <lispy> > unfoldr (\x -> Just (x+1, x-1)) 3
22:10:42 <lambdabot>  [4,3,2,1,0,-1,-2,-3,-4,-5,-6,-7,-8,-9,-10,-11,-12,-13,-14,-15,-16,-17,-18,-1...
22:12:48 <lispy> > unfoldl (\x -> Just (x+1, x-1)) 3
22:12:48 <lambdabot>  Not in scope: `unfoldl'
22:12:58 <lispy> why is there no unfoldl?
22:12:58 * syntaxfree tries to attract attention to #haskell-blah again
22:13:09 <syntaxfree> because it's an infinite list, I reckon.
22:13:36 <lispy> > unfoldr (\x -> Nothing) 3
22:13:37 <lambdabot>  Add a type signature
22:13:49 <dons> heh, theRegister talks more and more static typing every week, "Use a programming language with unambiguous static and dynamicsemantics to "write it right" in the first place. No, probably not C++" but still not quite ready to mention Haskell :/ http://www.regdeveloper.co.uk/2006/08/14/math_managing_defects/
22:13:51 <lispy> > unfoldr (\x -> Nothing:: Maybe (Int, Int)) 3
22:13:52 <lambdabot>  []
22:14:13 <dons> is it the dawning of the age of haskell?
22:14:55 <syntaxfree> Haskell impresses me by being both a hot academic research area and a ready-to-deploy commercial-level language.
22:14:56 <dons> or, more likely, are other languages just going to adopt haskellish features in ad hoc ways (such as external static checkers)
22:15:18 <syntaxfree> In my field (the economics of contracts), things either are in common use in the business world, or are hot research areas.
22:15:42 <dons> in software though, there's no real reason you're research can't be published and useable
22:15:51 <dons> and we see this in haskell
22:16:20 <dons> just takes a bit more effort to polish things, and write reasonable build systems
22:16:27 <dons> ;)
22:16:29 <lispy> honestly, i don't see a lot of 'enterprise' solution in haskell tho ;)
22:16:36 <sieni> dons: s/you're/your/ ;-)
22:17:01 <Pseudonym> You should read The Daily WTF.  I'm glad Haskell isn't "enterprisey".
22:17:07 <dons> hehe
22:17:20 * lispy was teasing in a dailywtf sense :)
22:17:26 <Pseudonym> :-)
22:17:29 <piggybox> don't need enterprise stuffs, just need killer application
22:17:34 <dons> i'd be happy if the demand for haskell hackers just managed to balance the supply...
22:17:49 <lispy> yeah, we need to write the AssassinMonad
22:17:50 <Pseudonym> "Enterprise" is one of those things that nobody can agree what it means.
22:17:59 <Pseudonym> lispy: Ask syntaxninja.
22:18:40 <syntaxfree> @google The Daily WTF
22:18:42 <lambdabot> http://thedailywtf.com/
22:20:39 <Tela> I'm trying to learn Haskell and so I'm looking for some smaller pieces of practical code. Is there anything like that around? A Haskell Cookbook, for instance?
22:21:17 <lispy> Tela: have you looked at the wiki?
22:21:18 <Pseudonym> @google site:haskell.org CodeSnippets
22:21:20 <lambdabot> http://www.haskell.org/hawiki/CodeSnippets
22:21:20 <lambdabot> Title: CodeSnippets - The Haskell Wiki
22:21:27 <Pseudonym> There you go.
22:21:33 <Tela> Thanks
22:21:36 <Pseudonym> However, it would be nice to organise this stuff a bit better.
22:22:54 <dons> also
22:22:56 <dons> ?wiki ExampleCode
22:22:56 <lambdabot> http://www.haskell.org/haskellwiki/ExampleCode
22:23:10 <dons> CodeSnippets should probably migrate to ExampleCode
22:23:15 <Pseudonym> Right.
22:24:11 <Tela> There are two wikis on the site? hawiki and haskellwiki?
22:24:23 <lispy> yeah
22:24:29 <dons> the old and the new
22:24:30 <lispy> the mediawiki instance is the new one
22:25:08 <Tela> good to know
22:25:29 <lispy> yeah, it's too bad we have two :(
22:26:00 <lispy> apparently it's not trivial to just move them because the content has no license on the old wiki, but is licensed on the new wiki
22:28:02 <Tela> At least there's just one site. Lisp is all over the place.
22:28:35 <lispy> they have a wiki that pulls it all together pretty well tho
22:28:43 <lispy> commonlisp.net iirc
22:30:31 <Tela> But then some things will be there, others on Cliki
22:30:52 <syntaxfree> I liked the moinmoinwiki style.
22:30:54 <syntaxfree> it's cozier.
22:30:55 <lispy> yeah, safer to just use haskell ;)
22:31:31 <Tela> I'd love to once I can wrap my head around all this typing ;)
22:31:58 <lispy> the first time you write a significant chunk of codeand it just type checks you'll be happy :)
22:32:01 <dons> well, just ask. we're here to help
22:32:36 <syntaxfree> Tela: don't declare explicit types when beginning, and then ask the interpreter what type it guessed.
22:32:39 <syntaxfree> That helped me.
22:32:55 <Tela> It's not so much I don't get the concept, I just can't see how you'd use it. That's why I'm looking through some example code
22:32:59 <syntaxfree> (these days I tend to write type declarations first)
22:33:25 <dons> you use it to more accurately specify what your code does
22:33:34 <dons> its machine checkable documentation, in that sense
22:33:45 <Tela> One of the tutorial-things I read said declarations first was the best way, but then I end up with all sorts of Type errors, heh heh
22:34:00 * Tela nods
22:34:02 <dons> declaratoins first is how its usually taught.
22:34:15 <dons> since this encourages you to think about the design a bit, I suppose
22:34:31 <dons> after a while, you always write types first.
22:34:47 <dons> and maybe just leave the function bodies undefined, while you get all the types right
22:34:51 <Tela> Well, for some simpler functions, I've found that the type declaration is a great way to outline the function before actually writing
22:34:54 <dons> then the code itself just falls out
22:35:03 <dons> Tela: exactly
22:35:19 <Tela> When I get to more complex ones though... Things tend to explode in messes of type errors :)
22:35:19 <dons> for some functions, the type uniquely specifies the function, in fact
22:35:25 <dons> write something of type: a -> a
22:35:26 <lispy> dons: yeah, i fonud myself coding like that just today...
22:35:32 <LordBrain> it helps error messages too, the compiler better knows what you are trying to do.
22:35:42 <dons> > f x = x -- one solution
22:35:43 <lambdabot>  Parse error
22:35:52 <dons> ?type let f x = x in f
22:35:54 <lambdabot> forall t. t -> t
22:36:02 <Tela> Oh yeah! The GHCi error messages constantly astound me with being so verbose and precise. It's a relief.
22:36:05 <dons> Tela: can you think of any other function of type :: a -> a
22:36:24 <dons> actually, we have a tool to find the code for some types:
22:36:27 <dons> ?djinn a -> a
22:36:27 <lambdabot> f a = a
22:36:28 <LordBrain> yeah i love the error checking too
22:36:30 <dons> that's it.
22:36:31 <LordBrain> :)
22:36:37 <Tela> Nifty
22:36:48 <Pseudonym> (forall f_1 :: (A_2 -> A_3). forall v1_4 :: A_2. f_1 (id (| A_2 |) v1_4) = id (|
22:36:49 <Pseudonym>  A_3 |) (f_1 v1_4))
22:36:49 <emertens> dons: \a -> undefined `asTypeOf` a
22:36:50 <emertens> ?
22:36:51 <dons> which just goes to show that once you find the types, you're a long way towards finishing
22:37:01 <Pseudonym> Sorry, I use banana brackets for type application here.
22:37:05 <Tela> I like how Haskell just feels so much more mathematically complete. The type system being a big part of that :)
22:37:24 <syntaxfree> ?djinn [[String]]->Int
22:37:25 <lambdabot> -- f cannot be realized.
22:37:25 <dons> emertens, then there's a bunch of bottoms that have a -> a too.
22:37:34 <dons> djinn only works on polymorphic types
22:37:40 <dons> ?djinn a -> b -> Maybe (a,b)
22:37:41 <lambdabot> f a b = Just (a, b)
22:37:58 <dons> ?djinn (a,b,c) -> (c,b,a)
22:37:58 <lambdabot> f (a, b, c) = (c, b, a)
22:37:59 <emertens> dons: I didn't expect ?djinn to come up with that
22:38:17 <dons> ?djinn (b -> c) -> (a -> b) -> a -> c
22:38:17 <lambdabot> f a b c = a (b c)
22:38:24 <Pseudonym> For all functions f :: a -> a, then for all g, f . g = g . f
22:38:33 <dons> ?djinn (a -> b) -> (c -> b) -> Either a c -> b
22:38:34 <lambdabot> f a b c =
22:38:34 <lambdabot>   case c of
22:38:34 <lambdabot>   Left d -> a d
22:38:34 <lambdabot>   Right e -> b e
22:39:09 <dons> emertens: http://www.cse.unsw.edu.au/~dons/code/lambdabot/scripts/Djinn/examples
22:39:12 <Pseudonym> I haven't yet modified my free theorem generator to handle data declarations.
22:39:15 <Pseudonym> That's gonna be fun.
22:39:24 <dons> Pseudonym: we need a plugin...
22:39:37 <syntaxfree> http://thedailywtf.com/forums/thread/31455.aspx
22:39:47 <Pseudonym> dons: We need it finished first.
22:39:48 <dons> its been at least 3 days since we got a new lambdabot feature
22:39:59 <dons> finished is good too
22:40:10 <emertens> dons: we can't karma- java anymore
22:40:16 <emertens> even when we really just want ot karma- java
22:40:18 <Pseudonym> The main missing feature is I don't parse types yet.
22:40:32 <Pseudonym> Which is an impediment to lambdabot-ifying it.
22:40:37 <dons> emertens: ok. i'll fix that. i was too tired the other day
22:40:50 <dons> Pseudonym: hmm. ok. well let me know and i'll whip up a binding, when you're done
22:40:58 <Pseudonym> No problem.
22:41:05 <dons> emertens:   | map toLower nick == "java" = changeKarma (-1) "lambdabot" sender
22:41:08 <dons> is the bug, you see.
22:41:23 <Pseudonym> The other problem is that the theorems are infuriatingly pedantic.
22:41:31 <emertens> Oh, I knew it wasn't a "bug", you did it on purpose
22:41:36 <Pseudonym> Which isn't a huge surprise, of course.
22:41:37 <emertens> ;)
22:41:40 <emertens> you love java
22:42:01 <dons> well, its a bug that karma- java lowers your own karma. clearly that's wrong! karma just doesn't work like that
22:42:39 <emertens> Hmm... I'd swear that there was a @quote dons that said "I love java"
22:42:40 <emertens> weird
22:42:50 <dons> that seems unlikely ;)
22:50:17 <LordBrain> wow, its been so long since i did basic i didnt even recognize the language syntaxfree
22:52:20 <Tela> Here's a question: I was looking at the Darcs source and saw lots of .lhs files. I'd thought lhs meant that everything was a comment unless the line started with >. These files looked like Latex. What's up there?
22:53:03 <lispy> there are two types of lhs
22:53:08 <lispy> it was indeed, latex
22:53:31 <lispy> the darcs source code is hard to read for beginnerrs
22:54:08 <Tela> Yep. Heh. It was more for curiosity than actual hope of productivity :)
22:54:23 <lispy> ah, too bad, darcs could use more hackers
22:55:15 <dons> yeah. here in irc we use bird-style literate haskell
22:55:18 <dons> > 1 + 1
22:55:19 <lambdabot>  2
22:55:39 <dons> but in darcs they use the latex style, developed by Will Partain, I think, in the early 90s, to document ghc
22:56:13 <dons> \end{history_lesson}
22:56:24 <Tela> heh
23:00:40 <LordBrain> hmmm i'd choose java over visual basic
23:00:48 <LordBrain> hehe
23:09:11 * sm looks at darcs source again
23:51:24 <cschneid> (newb here) thinking of attempting to implement a bloom filter in haskell, would I use an Integer as the bitfield, using the bit class as the interface into it? (testbit and such)
23:53:06 <Korollary> @index testbit
23:53:06 <lambdabot> bzzt
23:53:23 <cschneid> @index testBit
23:53:23 <lambdabot> Data.Bits, Foreign
23:53:49 <Korollary> ah
23:55:01 <cschneid> would that be the appropriate data structure for a bit field? or is there a better way of representing it
23:55:28 <Korollary> That looks like it would work
23:56:36 <cschneid> ok, thanks, off to bed for now, think about it later :)
23:56:58 <Korollary> np.
