00:00:25 <Cale> monomorphism restriction
00:00:36 <palomer> grr
00:00:49 <Cale> > let (==*) a b = liftM2 (==) a b in 5::Int
00:00:51 <lambdabot> 5
00:01:11 <palomer> @hoogle liftM2
00:01:12 <lambdabot> Control.Monad.liftM2 :: Monad m => (a1 -> a2 -> r) -> m a1 -> m a2 -> m
00:01:12 <lambdabot> r
00:01:27 <Cale> > let (==*) a b = liftM2 (==) a b in [1,3,4] ==* [1,2,4]
00:01:29 <lambdabot> [True,False,False,False,False,False,False,False,True]
00:02:16 <palomer> hrmph
00:02:22 <palomer> I'm going to have to study this more carefully
00:03:05 <palomer> mapM (\x -> return (x,image x u)) newDomain <--this would be better done with liftM, right?
00:03:18 <Cale> liftM2 f x y = do { v <- x; w <- y; return (f x y) }
00:03:30 <Cale> um...
00:03:44 <palomer> liftM2 is exactly what I need
00:03:57 <palomer> too bad it only works for 2 arguments
00:03:58 <Cale> that's better done with an ordinary map
00:04:05 <Cale> since you're just applying return
00:04:15 <Cale> liftM3
00:04:17 <Cale> liftM4, and liftM5
00:04:20 <Cale> are defined
00:04:24 <Cale> If you need more,
00:04:39 <Cale> return f `ap` x1 `ap` ... `ap` xn
00:04:47 <Cale> is the same as
00:04:51 <Cale> liftMn f x1 ... xn
00:08:17 <palomer> liftM f x = y <- x; return f x ?
00:08:24 <palomer> put a do in there
00:08:24 <Cale> yeah
00:08:32 <Cale> yep
00:08:53 <Cale> er
00:08:58 <Cale> and swap the x and y
00:09:06 <Cale> and put some parens :)
00:09:40 <palomer> righto
00:09:42 <palomer> it's late
00:09:46 <Cale> liftM f x = return . f =<< x
00:09:47 <palomer> and I'm euphoric
00:09:55 <Cale> :)
00:10:15 <palomer> I've needed liftM so many times in my life!
00:10:26 <palomer> are there any other useful combinators I should be knowing about?
00:10:40 <lispy> i've never needed liftM, but fmap is handy ;)
00:10:51 <Cale> heh
00:11:00 <Cale> fmap is just liftM with a more general type
00:11:29 <Cale> sequence?
00:11:34 <lispy> > fmap (+) [1..3]
00:11:35 <lambdabot>  add an instance declaration for (Show (a -> a))
00:11:42 <Cale> sequence is the basis of a lot of monadic goodness
00:11:47 <Cale> @type sequence
00:11:47 <lispy> > fmap (+1) [1..3]
00:11:48 <lambdabot> forall a (m :: * -> *). (Monad m) => [m a] -> m [a]
00:11:49 <lambdabot> [2,3,4]
00:11:57 <palomer> @type fmap
00:11:57 <lambdabot> forall (f :: * -> *) b a. (Functor f) => (a -> b) -> f a -> f b
00:12:00 <palomer> @type liftM
00:12:01 <lambdabot> Not in scope: `liftM'
00:12:10 <lispy> > liftM (+1) [1..3]
00:12:11 <lambdabot> [2,3,4]
00:12:20 <Cale> mapM f x = sequence (map f x)
00:12:38 <lispy> > mapM (+1) [1..3]
00:12:39 <lambdabot>  add an instance declaration for (Show (m [b]))
00:12:48 <lispy> oh right
00:12:49 <Cale> join is cool
00:12:52 <Cale> @type join
00:12:54 <lambdabot> Not in scope: `join'
00:13:02 <Cale> @type Control.Monad.join
00:13:03 <lambdabot> forall a (m :: * -> *). (Monad m) => m (m a) -> m a
00:13:24 <Cale> It's obvious in the container view, but a little esoteric in the computation view
00:13:26 <lispy> > join [[1]]
00:13:27 <lambdabot> [1]
00:13:41 <palomer> Cale: right on
00:13:43 <lispy> > join [[1,2]]
00:13:44 <lambdabot> [1,2]
00:13:50 <lispy> > join [[1,2],[3,4]]
00:13:51 <lambdabot> [1,2,3,4]
00:13:53 <palomer> well, actually no
00:14:00 <Cale> There are things like foldM and zipWithM
00:14:02 <palomer> if you have a computation which returns a computation which computes a
00:14:07 <palomer> then you have a computation which computes a
00:14:09 <Cale> replicateM is particularly handy
00:14:19 <palomer> @hoogle zipWithM
00:14:19 <lambdabot> Control.Monad.zipWithM :: Monad m => (a -> b -> m c) -> [a] -> [b] -> m [
00:14:19 <lambdabot> c]
00:14:19 <lambdabot> Control.Monad.zipWithM_ :: Monad m => (a -> b -> m c) -> [a] -> [b] -> m (
00:14:19 <lambdabot> )
00:14:19 <lambdabot> Data.Generics.Twins.gzipWithM :: Monad m => GenericQ (GenericM m) ->
00:14:22 <lambdabot> GenericQ (GenericM m)
00:14:26 <Cale> palomer: right, it computes the computation, then runs it
00:14:59 <palomer> which computation?
00:15:02 <palomer> inner or outer?
00:16:01 <Cale> join x = do { y <- x; y }
00:16:37 <palomer> oh, righto, the outer computation
00:16:47 <palomer> well, I'm out
00:16:47 <palomer> cyas!
00:16:54 <Cale> I wish there was a repeatM, but it's not there
00:17:01 <palomer> and thx!
00:17:06 <Cale> repeatM = sequence . repeat
00:17:11 <Cale> np :)
00:17:17 <Cale> see you
00:17:19 <lome> Cale, sorry had you received my private message?
00:17:36 <Cale> lome: not at all :)
00:17:54 <lome> oops... ok, could you give me your mail?
00:18:27 <Cale> lome: you need to identify with services to send private messages
00:18:39 <Cale> cgibbard@gmail.com -- what's it about?
00:18:43 <lome> oh! just a moment!
00:19:46 <lome> Cale: and now?
00:37:50 <araujo> jethr0_, there?
00:37:55 <jethr0_> yup
00:38:00 <araujo> :-)
00:38:11 <araujo> jethr0_, wanted to ask you, what is the best way to kill a process? 
00:38:28 <araujo> jethr0_, in this case, one crated by rIP, terminateProcess doesn't seem very safe
00:38:51 <jethr0_> never've done it. how 'bout terminateProcess
00:38:59 <jethr0_> why?
00:39:16 <araujo> "This function should not be used under normal circumstances - no guarantees are given regarding how cleanly the process is terminated"
00:40:05 * araujo thinking taht he probably could use the kill command
00:42:42 <jethr0_> how do you propose to kill it?
00:42:54 <jethr0_> you can only do: SIGINT, SIGKILL
00:43:05 <jethr0_> and maybe one i've forgotten
00:46:12 <araujo> jethr0_, well, with the kill command, i get the process id and kill that
00:46:17 <ski> good morning, #haskell
00:46:25 <araujo> morning ski 
00:46:33 <ski> (.. 'set terrorists' hehe ;)
00:48:55 <jethr0_> ah, ok
00:49:12 <araujo> ski, :-)
00:49:22 <araujo> ski, suggest a more lovely way!!
00:49:36 <jethr0_> araujo: as i said, i've never done it before
00:49:48 <ski> araujo : way for what ?
00:51:23 <araujo> ski, to kill a process
00:52:03 <ski> oh
00:52:14 * ski was reacting to a comment by tic, above
01:08:46 <essiene> moin
01:09:56 <ski> morning, essiene
01:25:38 <Cale> heh, I read one Haskell' post, and another is made while I'm reading.
01:28:04 <araujo> ?
01:28:07 * jethr0_ is mystified how this parsec stuff can possibly work
01:28:12 <Cale> oh, I guess it's not just Haskell'
01:28:24 * jethr0_ now parses regular expressions and build parsec parsers for them...
01:28:32 <araujo> parsec 0wnz y0u!
01:28:33 <jethr0_> and it just works !?!!!
01:28:41 <Cale> seems there are Haskell Libraries posts in there :)
01:28:51 <jethr0_> regExer (PAnd xs) = foldl1 (>>) $ map regExer xs
01:28:54 <jethr0_> hehe
01:29:06 <Cale> jethr0_: of course -- it compiles, right? :)
01:29:10 <jethr0_> sure
01:29:20 <Cale> so obviously it's going to work :)
01:29:23 * araujo thinks he got this working too
01:29:28 <Cale> hehe
01:29:32 <jethr0_> i mean i'm still in the process of converting my AST into parsec, but that goes really quick!
01:29:37 <araujo> Let's celebrate!!
01:29:44 * jethr0_ dances on the table
01:29:52 <ski> @arr
01:29:52 <lambdabot> I'll crush ye barnacles!
01:29:53 <araujo> haha
01:30:02 <jethr0_> i've even got weird features like "a{,3}" working
01:30:06 <Cale> working on the gene-splicing shootout programs?
01:30:26 <Cale> or a better Regex library for Haskell? :)
01:30:40 <jethr0_> don't know. it just seemed like a fun project
01:30:57 <jethr0_> and if it's short enough, maybe it'll go into the regexp shootout entry :)
01:30:58 <Cale> did you see the recent results in the shootout entry?
01:31:08 <jethr0_> yup
01:32:02 <ProfTeggy> Moin
01:32:15 <jethr0_> but unfortunately it's pretty hard to debug because parsec actions are not showable (i think)
01:33:25 <Cale> jethr0_: you can still break them up and test them separately fairly well though
01:34:01 <jethr0_> hm, not when they're sufficiently complex. but i'll cope :)
01:34:21 <Cale> I like the fact that the fastest RegexDna entry uses lots of laziness.
01:35:11 <jethr0_> it's impressive how fast the regexp libraries for such otherwise slow languages as python and ruby are
01:35:49 <Cale> well, that's especially important for them
01:37:02 <psi> python is using C for regex I think
01:37:08 <jethr0_> you think accepting in itself is worth something, or should i go for matching?
01:37:24 <jethr0_> i think i'll be happy with accepting for today ^_^
01:37:47 <Cale> matching is probably not too hard an extension
01:38:01 <jethr0_> nah, i don't think so either
01:44:57 <jethr0_> i can't keep myself writing unit tests. i always fall back on writing functionality first *argh*
01:45:06 <Cale> heh
01:45:43 <jethr0_> i'm starting to force myself by actually deleting good code, i've started in the wrong order :)
01:45:49 <jethr0_> desperate measurees
01:46:50 <Cale> I have the opposite problem. I tend to write typeclasses and then libraries using them when I still have no instances, or one stupid trivial instance :)
01:46:52 <jethr0_> hmm, the lookahead/greedy features might get hard
01:47:02 <jethr0_> like "a?b?a*b"
01:47:23 <jethr0_> i'm not even sure they're actually "regular"
01:47:45 <Cale> ? is nothing special
01:48:21 <Cale> but I think I know what you're talking about
01:48:22 <jethr0_> i guess you can just try and put back several times
01:48:41 <jethr0_> you can say (try a >> try b >>= try a) or sth like that
01:48:44 <ProfTeggy> This is related to (one-)unambiguity, jethro
01:48:45 <jethr0_> i'll se
01:48:49 <Cale> a? = (a | epsilon)
01:48:52 <jethr0_> yup
01:49:07 <ProfTeggy> Papers by Anne Brueggemann-Klein are highly recommend in this context
01:49:13 <jethr0_> :)
01:49:20 <Cale> @hoogle option
01:49:21 <lambdabot> System.Console.GetOpt.Option :: [Char] -> [String] -> ArgDescr a ->
01:49:21 <lambdabot> String -> OptDescr a
01:49:21 <lambdabot> Text.Html.option :: Html -> Html
01:49:21 <lambdabot> Text.ParserCombinators.ReadP.option :: a -> ReadP a -> ReadP a
01:49:23 <ProfTeggy> They also contain rewritings to get rid of such unambiguity
01:49:32 <jethr0_> ProfTeggy: but i know that perl uses lookahead and some greedy methods
01:49:49 <jethr0_> whereas a finite automaton shouldn't need either
01:49:49 * ProfTeggy nods.
01:50:08 <jethr0_> is it a question of speed or of calculability
01:50:10 <ProfTeggy> I just wanted to put this interesting dicussion of yours into an academic perspective. ;-)
01:50:19 * jethr0_ should know this, he's just had his compiler construction exam...
01:50:37 <jethr0_> s/bility/bility?/
01:51:05 <ProfTeggy> jethro, it is a question of efficiency
01:51:15 <jethr0_> k, then i'm not worried :)
01:51:34 <jethr0_> i guess reading 100s of chars and then having to put them back can be kind of costly :)
01:51:36 <ProfTeggy> The reg language if, of course, not ambiguous
01:51:41 <ProfTeggy> s/if/is/
01:52:09 <jethr0_> and, even more obviously, it's "regular" :)
01:52:26 <Cale> @hoogle optional
01:52:27 <lambdabot> Text.ParserCombinators.ReadP.optional :: ReadP a -> ReadP ()
01:52:27 <lambdabot> Text.ParserCombinators.Parsec.Combinator.optional :: GenParser tok st a ->
01:52:27 <lambdabot> GenParser tok st ()
01:52:30 <jethr0_> cale, you think it's theoretically possible to use "try" everywhere?
01:52:49 <jethr0_> otherwise i'd have to look for common prefixes
01:52:52 <Cale> you can use it everywhere, but it hurts efficiency
01:53:15 <jethr0_> Cale: i know about optional, i was just wondering about feasibility. but some compiler construction material from the lecture even stuck with me...
01:53:20 <jethr0_> k
01:53:58 <jethr0_> *damn*. once again forgot the unit test $%$)(*@$$@W
01:56:14 <jethr0_> the "only" feature of "try" is that it puts consumed input back on failing, right?
01:56:53 <jethr0_> so, writing "try (option (char 'c'; char 'd'))" should make sense (in a perverted kinda way), right?
01:57:17 <Cale> yeah
01:57:42 <Si\Uni> are unsafePerformIO global variables available to all modules during compilation if TH splices are used which use them, or is their use localised on a per-module basis?
01:57:42 <Cale> option succeeds on the empty input though
01:57:47 <Cale> so the try will never matter
01:57:53 <jethr0_> d'oh
01:58:03 <jethr0_> well, that makes sense
01:58:16 <jethr0_> hmm, or not
01:58:24 <Si\Uni> I mean their content rather
01:58:26 <jethr0_> i guess, i'm gonna wrap everything in "try"s
01:58:53 <Cale> jethr0_: or you could switch to a library with fair <|>
01:58:59 <jethr0_> hmm, true
01:59:13 <Cale> Parsek, for example
01:59:23 <jethr0_> :)
02:00:50 <Cale> Parsek also gives you lots of options as to which match you want in the cases where a parse is ambiguous. (longest, shortest, all, etc.)
02:02:04 <jethr0_> i'll have a look. but i really just wanna play a little around with parsec :)
02:02:32 <Cale> Parsek looks almost exactly the same as Parsec
02:02:56 <jethr0_> i know
02:03:20 <Cale> I should get a little sleep
02:03:32 <jethr0_> that's overrated to no end!
02:03:41 <Cale> yeah
02:03:51 <Cale> but I'm waiting on a download :)
02:04:13 <jethr0_> i haven't slept for real in days... waiting for download is _so_ 90s *g*
02:04:35 <Cale> yeah, this internet connection pretty much sucks
02:04:57 <Cale> It's supposed to be DSL, but I get 42 KiB/s out of it at max.
02:05:46 <Cale> and this torrent won't even give me that
02:06:29 <jethr0_> cale, where're you at?
02:06:46 <Cale> Brantford, Ontario
02:07:11 <jethr0_> didn't know that dsl was so popular in the states. i though everyone had cable or satellite connection, or sth
02:07:22 <Cale> When I was in Waterloo, I had 3mbit DSL for just under $30/mo. I think we're paying more for it here and getting less.
02:07:29 <Cale> I'm in Canada :)
02:07:40 <jethr0_> sorry, my geography has been better
02:07:49 <Cale> Canada generally has much better internet access than the US.
02:07:49 <jethr0_> not sleeping doesn't help in _all_respects
02:08:32 <Cale> (but on this part of this street, it sucks -- we should probably switch to cable)
02:09:41 <jethr0_> must be might cold right now, no? it's been a minimum of -37C here in germany
02:09:52 <jethr0_> i've never heard of anything this cold in these regions
02:10:36 <Cale> It's actually been quite warm the last couple of weeks. The temperature is falling.
02:10:41 <Cale> We had freezing rain today.
02:10:48 <jethr0_> yeah
02:11:05 <jethr0_> that's different from hail in what respect? still somewhat wet?
02:11:30 <Cale> It's not hail at all. It's rain that freezes on contact with the ground.
02:12:02 <Cale> terrible if you have to drive anywhere
02:12:26 <flux__> especially PIA on the windshield, before you've managed to warm it enough
02:12:38 <Cale> http://www.cita.utoronto.ca/~rjh/toronto/toronto-weather-l.html
02:13:51 <Cale> http://www.cita.utoronto.ca/~rjh/toronto/toronto-weather-ll.html -- this has normal average lines on it -- you can see that it's been 5-10 degrees warmer than usual
02:16:34 * jethr0_ thinks it was a bad idea to make "$" more binding than ">>="    *grr*
02:20:42 <dons> jethr0_, yeah, that bugs me too :)
02:21:21 <jethr0_> dons: should you be so sarcastic so early in the morning? or whatever time it is on your end :)
02:22:05 <dons> no  no, I'm serious. foo $ x y >>= bar catches me out too often. but then again, I love $ \p -> ....
02:22:30 <jethr0_> true
02:22:38 <dons> @localtime dons
02:22:41 <lambdabot> Local time for dons is Mon Feb  6 21:22:04 2006
02:22:42 <jethr0_> i think it should be a dwim feature
02:23:00 <jethr0_> and whoever edited it last gave it the implicit dwim-effect
02:23:34 <flux__> @localtime flux__
02:23:37 <lambdabot> Local time for flux__ is Mon Feb  6 12:23:13 2006
02:24:10 <oxygene> rehi
02:24:28 <essiene> still doing my studying on types and something is confusing me... when passing types to functions... what is *really* passed? the type or the constructor? and why?
02:24:52 <essiene> say i have: data Mtype a b = Mtype1 a | Mtype2 b
02:25:14 <oxygene> seems like I managed to build ghc on solaris/x86 now.. just one issue, how can I persuade it to use a certain gcc (with full path)? there are usually several installed, and on some revisions, the default one is broken wrt -fomit-frame-pointer, confusing the mangler script
02:25:24 <essiene> to define a function that takes Mtype... what will it look like?
02:25:31 <dons> Results of haskell in higher ed. survey: http://www.cs.chalmers.se/~rjmh/Wash/Survey/teaching.htm
02:28:08 <jethr0_> 4% each of students start with pascal and ada... *weird*
02:28:30 <Saulzar> 26% Functional programming 5% Advanced functional programming ??
02:28:53 <essiene> or better still... it seems my functions will only take: func (Mtype1 a) = [], why do i have to pass the Mtype1 a constructor... and not Mtype a b or something? its a bit confusing right now
02:29:05 <Saulzar> Ah, they ask for 1 course
02:30:04 <jethr0_> "eof  = notFollowedBy anyToken"
02:30:13 <jethr0_> that's what i call literal style
02:30:23 <jethr0_> literary?
02:34:18 <ski> essiene : your 'Mtype' is the type (constructor), and your 'Mtype1' and 'MType2' are the data constructors
02:35:45 <dons> essiene : f :: Mtype Int Int -> Int ; f x = case x of Mtype1 x -> x ; Mtype y -> y -- is that ok?
02:37:25 <essiene> ski, hmmm...
02:38:25 <ski> or
02:38:28 <dons> calling the two constructors Mtype1 and Mtype2 is confusinng, since they're data, not types, as ski says
02:38:33 <ski> f (Mtype1 x) = x
02:38:37 <ski> f (Mtype2 y) = y
02:38:50 <essiene> hmmm....
02:38:56 <dons> yup.
02:39:04 <ski> essiene : do you know how 'Maybe' works ?
02:39:20 <jethr0_> dons: does parsec use stateful backtracking you think? how does it resolve things like (many a, many b, many a, many b)?
02:39:26 <essiene> lemme try to paraphrase in a poor mans language
02:39:59 <dons> jethr0_, don't know. i'm sure it's in one of the papers somewhere.
02:40:18 <essiene> when defining a type... the left hand side is the 'type' contructor... and the right hand side is the 'data' constructor for data of the type on the left hand side...
02:40:20 <jethr0_> i tought maybe you'd know. since you're one of the gurus in here :)
02:40:48 <essiene> ski, this all sttarted from Maybe :)
02:41:22 <essiene> ski, Maybe was easy to understand... also Either, but when i had to solve some examples... i didn't understand my solution.. even tho they worked :)
02:42:09 <Saulzar> Hmm, you're not actually passing the constructor either. You're matching against it.
02:42:18 <essiene> ski, i think right now... my confustion still came from tying the 'type' and the 'data' constructed from the type too closely together...
02:43:12 <essiene> Saulzar, ohhh... yeah... that's right... i'm 'matching' hmmm... that may be my problem... i'm still thinking of 'passing' ....
02:44:36 <dons> jethr_, ah, sure, but I don't use parsec much (ever?), usually just use happy and alex for parsing
02:44:47 <Saulzar> The syntax for constructing some data eg. (Just foo) is the same as matching against it, depending where you use it
02:44:48 <essiene> i also noticed that after a definition of Mtype as above... in hugs, i can do, :t Mtype1 , and it will say its of type Mtype, but :t Mtype gives an error... undefined type or something...
02:44:51 <essiene> lemme confirm
02:44:56 <ski> hm
02:45:14 <ski> yes, since 'Mtype' is a type, but 'Mtype1
02:45:18 <ski> ' is not a type
02:45:37 <Saulzar> Constructors are like a function to create some data of a type
02:45:53 <dons> essiene, you can ask the type of a value, but not the type of a type. types don't have types :)
02:46:06 <Saulzar> Hmm, whoops. Value is a better term :)
02:46:13 * ski refrains from mentioning kinds
02:46:22 <dons> so :t Constructor --works, but :t Int -- doesn't make sense.
02:46:44 <dons> @kind Int -- types are classified into kinds, as values are classified into types
02:46:46 <lambdabot> *
02:47:29 <ski> essiene : you do know that you can sortof think of integers as defined by 'data Integer = ... | -3 | -2 | -1 | 0 | 1 | 2 | 3 | ...', right ?
02:48:21 <essiene> my head is spinning :-s
02:48:28 <ski> so, your data constructor 'Mytype1' is a bit analogous to '3', and your type constructor 'Mytype' is a bit analogous to 'Integer'
02:50:14 <essiene> hmmm... ok...
02:50:31 <essiene> oh... i c
02:50:44 <essiene> hmmmm....
02:51:06 <Saulzar> Hmm, which is why Mytype1 is an especially bad label given that it isn't a type at all... :)
02:51:51 <essiene> wow... its all coming together now... slowly... hmmmm...
02:52:24 <essiene> dons, totally understand what you're saying now.
02:52:35 <ProfTeggy> let { int = 2.34; bool = 42; double = True } in .... ;-)
02:52:41 <essiene> ski, i get that part to now...
02:53:26 <ski> OK
02:53:44 * ski curses a certain keyboard button
02:53:49 <araujo> Good morning!
02:53:52 <essiene> Saulzar, i think i get that too... prolly the naming is part of my confusion... would this be better? Mtype a b = MData1 a | MData2 b ?
02:54:10 <ski> essiene : yes
02:54:33 <essiene> ahhh... i c, i c, i c :)
02:54:58 <jethr0_> ProfTeggy: i was using quickcheck and hunit in the same file once (with global import), and it took me half an hour or so to understand they exported "oneof" and "oneOf" respectively *argh*
02:55:07 <ski> essiene : now .. you datatype declaration here is of course somewhat more complicated, since it declares a parametric data type
02:55:19 <Saulzar> ProfTeggy, Wouldn't that be an excellent in a beginners tutorial? :)
02:55:32 <ProfTeggy> Saulzar, :-)
02:55:36 <ski> so, e.g.   MData1 "foo" :: Mtype String Bool
02:55:59 <ski> and also,  MData1 "foo" :: Mtype String [Int]
02:56:13 <essiene> ski, parametric? one that takes a parameter? what's the *other* options?
02:56:26 <ski> data Bool = False | True
02:56:31 <ski> that is non-parametric
02:56:40 <essiene> hmmm....
02:57:10 <ski> data Maybe_Bool = No_Bool | Just_A_Bool Bool
02:57:11 <ProfTeggy> data Weekday = Sun | Mon | Tue | ... | Sat
02:57:43 <ski> the type 'Maybe_Bool' is also non-parametric, but the data constructor 'Just_A_Bool' takes a parameter (of type 'Bool')
02:57:54 <jethr0_> ski, how about: "data Bool = False | True Bool"
02:58:01 <essiene> why is that?
02:58:05 <essiene> i don't *see* it
02:58:21 <ProfTeggy> jethro, and then use True (True (True False)) ?
02:58:29 <jethr0_> exactly!
02:58:30 <ski> look at what's left of the '=' .. only one thing, no type arguments/parameters
02:58:50 <ski> No_Bool :: Maybe_Bool
02:58:50 <jethr0_> it's pure genius
02:59:00 <ski> Just_A_Bool :: Bool -> Maybe_Bool
02:59:31 <essiene> ok..
02:59:58 <ski> we can't put values of any type we'd like inside a value of type 'Maybe_Bool', only booleans (and only inside the 'Just_A_Bool' constructor)
03:00:01 <ski> otoh
03:00:14 <ski> data Maybe a = Nothing | Just a
03:00:28 <ski> Nothing :: forall a. Maybe a
03:00:34 <ski> Just :: forall a. a -> Maybe a
03:00:52 <ski> this means that we can use any type we want, in place of the type variable 'a'
03:00:59 <ski> so, e.g.
03:01:06 <ski> Nothing :: Maybe Bool
03:01:14 <ski> Just :: Bool -> Maybe Bool
03:01:19 <ski> Just False :: Maybe Bool
03:01:21 <ski> but also
03:01:29 <ski> Just "hello" :: Maybe String
03:01:38 <ski> Nothing :: Maybe (Int -> Bool)
03:01:38 <essiene> ok...
03:02:06 <ski> maybe it'd be good to compare with lists
03:02:57 <ski> you don't have a value of type "list", you have a value of type "list of something", e.g. "list of Char", writtten '[Char]'
03:03:22 <essiene> yeah... true.
03:03:22 <ski> "list of" is a parametric type, just as 'Maybe' is
03:04:01 <ski> (i.e. you often read it aloud as 'list of' .. but it's written like '[Char]' or '[] Char' if you have a list of chars)
03:04:53 <ski> so, in a way 'list of' is a *type-level* "function", that turns types into types, e.g. if it's given the type of characters, it returns the type of lists of characters
03:04:59 <essiene> ok... i see what the parametric types are now
03:05:04 <ski> fine
03:05:36 <ski> @kind Int
03:05:37 <lambdabot> *
03:05:42 <ski> @kind (Int,[Bool])
03:05:43 <lambdabot> *
03:05:47 <ski> @kind Maybe
03:05:47 <lambdabot> * -> *
03:05:50 <essiene> phew...
03:05:51 <ski> @kind Maybe Int
03:05:52 <lambdabot> *
03:06:15 <ski> (ignore that for now, if you want .. :)
03:06:47 * SimonRC goes
03:07:04 <essiene> i will :)
03:07:54 <essiene> hmmm....
03:08:05 * essiene is swirling all that in his head for a moment
03:09:30 <ski> (disclaimer : the learning of haskell can expand your mind)
03:20:08 <Si\Un1> is there anyway of stopping a class constraint of the form Class Type a => being undecidable?
03:29:42 <dons> @kind Control.Monad.RWS.RWST  -- ;)
03:29:43 <lambdabot> * -> * -> * -> (* -> *) -> * -> *
03:31:00 <olliej> dons: wow... pain...
03:42:32 <jethr0_> jup, i use that one _all_ the time
03:42:57 <jethr0_> it takes something from the left and transforms it to the right
04:07:39 <nibro> @seen dons
04:07:39 <lambdabot> dons is in #haskell. Last spoke 37 minutes and 57 seconds ago.
04:11:43 * araujo wonders why when he kills the child process, the parent also is killed.
04:12:01 <araujo> anybody knows any situation in which that _might_ happen?
04:25:11 <lisppaste2> jethr0 pasted "regular expressions" at http://paste.lisp.org/display/16507
04:25:38 <jethr0_> man, do i love parsec!
05:03:56 * araujo can't believe it
05:04:09 <SimonRC> what?
05:04:41 <SimonRC> on nao?
05:04:46 <araujo> YEAH!!!!
05:04:52 <araujo> I solved it!!!
05:05:01 <tromp_> gratz
05:05:07 * araujo takes his t-shirt off and dance
05:06:19 <araujo> geez... signals problems are sweet
05:06:40 <rep> so what was the problem
05:07:21 <araujo> For some *weird-unknown-heavenly-obscure* reason whenever i sent terminateProcess to the children, the parent process was getting the softwareTermination signal too.
05:08:03 <araujo> Is it normal, or it is just in my little world that i believe _that_ shouldn't happen?
05:08:06 <gour> anyone uses yi editor?
05:10:12 <JKnecht> hIDE developers?
05:10:48 <gour> JKnecht: dcoutts uses nedit. don't know about dons..
05:13:19 <oxygene> yay.. apart from some small issues, ghc/solaris/x86 works :) so, how do I teach ghc to use /path/to/good/gcc when a bad gcc (as in not suitable for ghc) is in $PATH? the other thing is, how do I teach ghc to pass -R to gcc/the linker, so the search path for libraries ends up in the executable, too?
05:15:44 <SimonRC> hi
05:16:38 <earthy> oxygen: -pgmc /path/to/good/gcc
05:18:14 <oxygene> earthy: I changed PATH for now.. any way to make this the default?
05:23:59 <edwinb> Hi. Any GHC wizards about?
05:24:45 <JKnecht> you the wizard now, dog:)
05:25:23 * edwinb dons his pointy hat and waves a wand about
05:25:36 <edwinb> Hmm, no, didn't help ;)
05:27:11 <olliej> Saulzar: you there?
05:40:01 <kzm> Hi.  I've turned a program into a server, basically just using "interact".  Quick and dirty.
05:40:31 <kzm> However, I would like to print a prompt.  Is there anything ready made, or must I write my own "interact"? 
05:40:42 <kzm> I don't what to do without buffering, thank you.
05:40:46 <kzm> :-)
05:41:17 <kzm> @seen
05:41:18 <lambdabot> Lately, I have seen kzm.
05:41:21 <kzm> @heard?
05:41:21 <lambdabot> Unknown command, try @listcommands.
05:41:39 <kzm> bots should be @seen but not @heard?
05:43:27 <ski> @seen
05:43:27 <lambdabot> Lately, I have seen kzm and ski.
05:46:20 <ski> hm, i seem to recall some stuff like that in the old Interact module in hugs
05:47:03 <ski> (old = pre-hieracical, dunno if it's carried over)
05:47:17 <ski> readLine                 :: String -> (String -> Interact) -> Interact
05:47:54 <MarcWeber> Is gcc.exe from ghc-6.4.1 from Win Installer meant to compile C files? I get the error cc1 is missing..
05:48:26 <dcoutts> MarcWeber, you need to set various flags and/or env vars to get it to work. ghc.exe does all that itself.
05:49:40 <MarcWeber> dcoutts: I tried specify it at ./configure of fptools (--with-gcc=ghc-6.4.1/gcc.exe) and configure complaint it can't produce executables (same error) I'm currently checking wether configure uses this gcc by default..
05:50:12 <MarcWeber> No it does use cygwin gcc compiler then. ;-(e
06:04:07 <Saulzar> Hmm, I notice Yi uses the UnsafePerformIO-Singleton "idom" - seems to make for clean code. It is jolly tempting with gui code.
06:05:21 <xerox> What is it?
06:06:41 <Saulzar> state = unsafePerformIO newIORef
06:07:01 <xerox> Uh-o.
06:07:03 <Saulzar> Combined with IO accesors
06:07:20 <xerox> seems baaaaaaad :)
06:09:01 <Saulzar> He has several functions which wrap it (ie. state is not public), withEditor, withBuffer etc.   It seems remarkably nice to use.
06:09:04 <ski> @hoogle oldIORef
06:09:05 <lambdabot> No matches found
06:10:55 <Saulzar> The alternative is pass the IORef everywhere, or use StateT.  StateT seems awkward with a gui (gtk2hs) IO actions... and the Singleton seems to mean 1 less parameter passed everywhere
06:11:25 <xerox> Yeah.
06:13:15 <Saulzar> It seems evil, but this seems nice :)
06:14:04 <xerox> I see.
06:18:39 <kzm> how do I (i.e. \bot) search by type signature again?
06:20:28 <Saulzar> kzm, Think you can just give it a signature .. ie. a -> Int
06:21:06 <kzm> Huh?  No command?
06:21:34 <kzm> or @djinn?
06:21:59 <Saulzar> Ah, @hoogle you mean?
06:22:46 <kzm> Yes, of course. Thank you.
06:23:17 <kzm> Anyway - didn't find any prompting interact, so I guess I'll have to write my own. :-(
06:52:42 <Pupeno> [OT] Is a finite state machine the same thing as a finite state automaton ?
06:52:57 <earthy> um. yeah?
06:54:50 <ulfdoz> depends on the machine I'd say. :)
06:58:31 <tromp_> anyone likes a programming puzzle?
06:59:44 <jethr0_> tromp_: always
07:01:07 <wilx> Hmm. I would say that automaton is well known and defined ordered 5-tuple while machine can be more than that.
07:01:16 <tromp_> given an array with bounds (a,b) and elements in range (a+1,b), find a duplicate
07:01:45 <tromp_> using only linear time and no mutable arrays
07:02:08 <jethr0_> that one's old :)
07:02:42 <jethr0_> but i forget the solution every time...
07:02:59 <Saulzar> Hmm... 
07:03:10 <jethr0_> something about the sum
07:03:11 <kosmikus> "given *an* array" seems to contradict "no mutable arrays"
07:03:28 <Saulzar> Ah, the array itself is mutable?
07:03:31 <tromp_> the given array  is immutable
07:03:45 <kosmikus> so it's constant, because you're only given one?
07:04:31 <jethr0_> it was like summing every snd and every third and deducing from the difference or some such :)
07:05:26 <jethr0_> tromp_: so it's definitely the lowest element that's missing?
07:05:30 <Saulzar> Ah, an array of integers?
07:06:03 <Saulzar> Oh, elements in the range (a+1, b), I see...
07:07:25 <tromp_> example is array (0,3) with elements in [1..3]
07:07:46 <tromp_> you only have Equality on the elements
07:07:52 <tromp_> uhm, wait
07:07:59 <tromp_> the elements must be Ints
07:08:21 <jethr0_> but if it's always the smallest element missing it's a simple sum game
07:08:36 <jethr0_> sum(a1) - sum([0..n]) = missing-1
07:08:46 <tromp_> atually it doesn't matter
07:08:48 <jethr0_> s/missing/double/
07:09:55 <tromp_> that doesn't work, jethr0
07:10:09 <tromp_> the elements are arbitrary
07:10:10 <kosmikus> I still don't even understand the question
07:10:22 <kosmikus> are the elements *in* the array? what's the array for?
07:10:23 <jethr0_> neither do i! and i already know the riddle :)
07:10:36 <tromp_> given n numbers in range [1..n-1]
07:10:52 <kosmikus> ah, so there's nothing about an array in the problem.
07:10:52 <tromp_> find a duplicate in linear time
07:10:54 <Saulzar> Er, could be more than 1 duplicate? 
07:11:03 <tromp_> yes, the numbers are given in an array
07:11:12 <tromp_> so you can do constant time lookup
07:11:18 <kosmikus> meaning nothing more than that you can do O(1) lookup
07:11:20 <kosmikus> ok
07:11:24 <tromp_> there can be many dupes
07:11:43 <kosmikus> you want to find the *indices* of a duplicate, or the identity?
07:11:45 <jethr0_> tromp_: stop changing the spec :))
07:11:50 <jethr0_> http://www.ocf.berkeley.edu/%7Ewwu/riddles/intro.shtml
07:12:02 <jethr0_> is a _great_ site for riddles! best i've ever seen by far
07:14:07 <tromp_> you want to find the duped element
07:14:19 <tromp_> well, one of them
07:15:01 <kosmikus> all arithmetic operations on integers are considered O(1)?
07:15:53 <jethr0_> tromp_: i'm not sure your specs are working
07:15:58 <Saulzar> Hmm
07:16:50 <tromp_> ok, write a linear time function dupe :: (Eq e, Ix e) => Array e e -> e
07:16:59 <jethr0_> i know the solution was sth with building differences of sums or so. but with your specs, discerning [2,3,2,3,...] and [1,4,1,4,1,4,...] might be hard
07:17:35 <tromp_> on input listArray (0,5) [1,3,2,3,5,4], it should return 3
07:18:07 <jethr0_> but now you've restricted it to a single dupe again
07:18:21 <tromp_> and  on input listArray (0,5) [3,2,3,2,2,4] it can return either 2 or 3
07:18:30 <jethr0_> uhu
07:18:41 <tromp_> no, i just gave an example with a unique answer
07:18:48 <jethr0_> :)
07:19:25 <kosmikus> tromp_: am I allowed to precompute prime numbers?
07:19:41 <jethr0_> kosmikus: hehe, building an orthonormal base? :)
07:19:57 <jethr0_> kosmikus: all of them?
07:20:19 <kosmikus> no, the first (b-a)
07:20:27 <tromp_> as long as it's linear time in length of input:)
07:20:45 <jethr0_> paul graham: "an algorithm for lazy evaluation of research papers. Just write whatever you want and don't cite any previous work, and indignant readers will send you references to all the papers you should have cited"
07:20:54 <jethr0_> :)
07:21:01 <Saulzar> Haha
07:21:05 <kosmikus> computing the nth prime number isn't constant, so this won't work then
07:21:58 <jethr0_> well linear means going through each element a fixed number of times. and as i can't see how increasing this number helps, it will likely be 1 or 2
07:22:44 <jethr0_> sub-linear won't work because then we might miss the element (unless the array is sorted)
07:23:45 <tibbe> > putStrLn "I'm a haskler"
07:23:46 <lambdabot> No IO allowed
07:23:47 <Saulzar> Hehe, prime number solution is sneaky...
07:24:21 <tibbe> > words "I am le tired"
07:24:22 <lambdabot> ["I","am","le","tired"]
07:25:32 <kosmikus> Saulzar: but obviously not good enough. the point is most likely that you have to use the fact that you know there will be at least one duplicate
07:25:47 <jethr0_> Saulzar: how's it work. some kind of base transform?
07:26:49 <kosmikus> jethr0_: just keep a running product. when you encounter n, you check if your current number is divisble by n. if yes, you found a dup, otherwise you multiply your running number by p(n) ...
07:27:29 <kosmikus> sorry, should be p(n) both times
07:28:04 <jethr0_> :)
07:29:05 <jethr0_> yup that's a bit like what i had in mind
07:29:57 <tromp_> the function should be dupe :: (Eq e, Ix e) => Array e e -> e
07:30:09 <tromp_> so you only use equality testing
07:31:56 <Saulzar> Erg..
07:32:48 <jethr0_> tricky
07:35:01 <Saulzar> Prime number solution exploits the fact that integers can be arbitrarily big and treats 'em like a bool array :)
07:35:29 <kosmikus> I know it's cheating.
07:35:32 <Saulzar> Just equality seems to be a fair bit more restrictive, though I'm guessing the answer is extremely simple
07:35:35 <carp> swiert: hi ;)
07:36:00 <kosmikus> tromp_: Ix implies Ord
07:36:04 <edwinb> hello sneezy people
07:36:06 <swiert> hi carp - I think I've managed to get things working
07:36:16 <carp> cool
07:36:31 <swiert> hi kosmikus
07:36:39 <kosmikus> tromp_: so, can we assume a total order on the elements, or only equality?
07:36:45 <kosmikus> hi swiert 
07:36:50 <tromp_> well, ok, you can use Ord, but it isn't needed:)
07:37:00 <swiert> are you coming to Nottingham for DGP?
07:37:05 <kosmikus> swiert: no
07:37:12 <kosmikus> tromp_: ok:)
07:37:26 <swiert> kosmikus: too bad :-(
07:37:42 <kosmikus> swiert: collision with FLOPS, not my fault that you placed it in the same week ;)
07:37:45 <jethr0_> Saulzar: you know the algo for finding loops in a graph in linear time?
07:38:14 <swiert> kosmikus: well I'm not in the position that I plan all these things.
07:38:22 <Saulzar> jethr0_, Nope..
07:38:36 <kosmikus> swiert: it was an "all you Nottingham guys" aggregated sort of "you" ;)
07:39:17 <jethr0_> one "iterator" takes every next node and another skips every second node. at 2*loop length at the latest they are on top of each other :)
07:39:39 <musasabi> Are the changes to hdirect from the visual haskell project integrated to the cvs/darcs version?
07:39:42 <swiert> kosmikus: no problem. How's Bonn?
07:42:30 <Saulzar> jethr0_, What kind of iterator ? I don't see what you mean by every next/second node 
07:43:56 <jethr0_> Saulzar: both start at a start node and then take every right turn. if the graph has no loops they arrive at the start point eventually (undirected graph).
07:44:47 <jethr0_> by letting one go in steps of 1 and the other in steps of two, when they are caught in a loop they will meet each other, thus proving that they were in a loop
07:47:44 <Saulzar> Ah, undirected ..
07:48:19 <jethr0_> still, i like the simplicity :)
07:49:31 <kosmikus> swiert: nice
07:50:52 <swiert> kosmikus: I take it you won't be around for TFP/TYPES either?
07:52:28 <edwinb> Hmm, I should see if I can get to TYPES.
07:54:05 <kosmikus> swiert: sorry, no
07:54:57 <swiert> kosmikus: 'schade'.
07:54:58 <carp> edwinb: hi
07:55:07 <kosmikus> swiert: I'll be at IFIP 2.1, FLOPS, MPC (including MSFP), ICFP (including HW). No more travel plans for this year yet.
07:55:27 <edwinb> hi carp. How's the hacking going?
07:55:38 <swiert> kosmikus: I have about a month of nonstop conferences in April.
07:56:01 <carp> haven't done that much lately, everyones busy writing papers
07:56:07 <edwinb> fun funf
07:56:11 <kosmikus> swiert: yes, I can see that it's quite crowded with conferences there
07:56:21 <swiert> kosmikus: and possibly LICS in August. I'd like to go to MPC etc. but I'm not sure...
07:56:29 <Saulzar> This applies directly to tromp_'s problem somehow I take it, can't figure it out yet... :)
07:57:44 <carp> edwinb: when are you heading down to talk to us?
07:57:48 <lispy> haskell-cafe is higher volume that i would have expected
07:57:52 <edwinb> carp: March 10th
07:57:58 <edwinb> Might see if I can hang around a bit.
07:58:04 <carp> that'd be cool
07:58:31 <swiert> kosmikus: the thing is - during the Easter break, rooms and accomodation are available, so everything seems to be planned round then.
07:58:44 <carp> dcoutts and axel are coming on the 3rd to talk to us about gtk2hs which should be cool
07:58:47 <swiert> edwinb: it would be good to meet you IRL.
07:59:07 <edwinb> I notice the Nottingham group has grown enormously since I was last there...
07:59:28 <carp> there are quite a few phd students now
07:59:36 <liyang> :)
07:59:42 * edwinb spots another one
07:59:48 <carp> :)
08:00:12 * edwinb suddenly remembers he promised Neil an abstract last week
08:00:35 <carp> what are you going to talk about?
08:01:41 <edwinb> Something along the lines of proving resource bounds with dependent types
08:03:15 <Philippa> carp: will there be any objection if I want to show up to the gtk2hs talk?
08:04:23 <carp> Phillippa: better talk to Graham, fp-lunch is not open to everyone for reasons of space i think
08:04:39 <Philippa> ah, if it's fp-lunch I know the answer already
08:05:36 <Philippa_> re
08:06:30 * Philippa curses NTL
08:07:32 <edwinb> Last time I went to fp lunch it was a bit of a squeeze... how on earth do you manage now?
08:08:30 <carp> with difficulty!
08:08:34 <edwinb> heh
08:08:45 <liyang> Changing to a room (Thorsten's) without a desk in the middle...
08:09:02 <edwinb> I am jealous of your fp lunch.
08:09:11 <Philippa> too bad you can't change to the three wheatsheaves
08:09:11 <edwinb> I suppose we don't have enough people here to get it going though.
08:09:38 <Philippa> (unless the food there's gone downhill recently, 'sbeen a while since I ate there)
08:09:40 <liyang> and ocassionally (well, once since I got here) A01 downstairs.
08:11:31 <Spark> lunch as in one person gives a talk while the others eat?
08:15:13 <swiert> \part "Back to the grindstone..."
08:15:14 <carp> Spark: http://sneezy.cs.nott.ac.uk/fplunch
08:16:01 <Spark> why is suduko on that list :(
08:16:44 <Philippa> because it's potentially an amusing chat for the course of lunch?
08:17:22 <Spark> is it an injoke then
08:17:50 <edwinb> http://sneezy.cs.nott.ac.uk/fplunch/weblog/?p=18
08:18:10 <Philippa> Spark: they don't have room for undergrads there, unfortunately, so I wouldn't really know
08:18:33 <edwinb> it's on the list because it was discussed once...
08:18:48 <kosmikus> tromp_: ok, I have a solution, although I don't think it's optimal yet
08:18:49 <carp> a few other people have written programs to solve sudoku puzzles too
08:18:50 <Spark> ah, in the "can we write a sudoku solver in one line" context
08:26:13 <tromp_> want to paste it?
08:30:18 <Spark> is it a more tractable problem than 8 queens then?
08:34:10 <lispy> sudoku is O(1)  in the board size :)
08:34:45 * lispy is just teasing since the board size doesn't change of course...
08:35:21 * Igloo has seen 1..25 sudoku problems
08:35:49 <tromp_> my dupe solution is 5 lines of haskell, longer than the c version, but also less error-prone;)
08:37:25 <earthy> less than 5 line sudoku-solver in C? that's small. :)
08:37:39 <vincenz> earthy: depends on the length of a line
08:37:46 <earthy> true enough.
08:37:53 <earthy> assuming 80 chars it's small
08:38:02 <earthy> in haskell it's doable. :P
08:40:39 <tromp_> now, a program for the duplicate problem i posed earlier
08:40:47 <tromp_> now->no
08:41:54 <tromp_> to write a linear time function dupe :: (Eq e, Ix e) => Array e e -> e
08:42:38 <tromp_> that outputs a duplicate on any array mapping (low, high) to (low+1, high)
08:43:46 <tromp_> eg. dupe $ listArray (0,5) [2,3,2,4,2,4]   can be 2 or 4
08:43:56 <earthy> ah
08:44:17 <tromp_> not using any mutable array....
08:47:12 <Philippa> is anyone here familiar with (hacking on) GHC's typechecker?
08:47:26 <Philippa> (and preferably the other bits and pieces needed to insert eg the relevant syntax for a new feature as well)
08:50:10 <dcoutts_> carp, so you're in the epigram group at Nottingham? I'm lookin forward to the visit. :-)
08:53:46 <kosmikus> tromp_: why should I give away the solution and spoil the fun for others?
08:54:16 <palomer> hrm, I have a function ==~::a -> b -> m Bool, how can I use nub with this?
08:55:59 <Philippa> what do you mean by "use nub with this"?
08:56:10 <vincenz> @type nub
08:56:11 <lambdabot> Not in scope: `nub'
08:56:15 <palomer> well, erm, I can't set ==~ as a member of an instance of Eq
08:56:17 <vincenz> @type Data.List.nub
08:56:18 <lambdabot> forall a. (Eq a) => [a] -> [a]
08:56:23 <palomer> it do esn't have the right type
08:56:23 <Philippa> (for example, I assume you intend to use it for values of m /= []?)
08:56:26 <palomer> but I still want to use nub
08:56:42 <palomer> Philippa: oh no, I'll be using it on [a]
08:56:49 <Philippa> you effectively want to nubBy the func?
08:56:50 <palomer> actually, make that ==~::a -> a -> m Bool
08:56:56 <Philippa> :-)
08:57:08 <Philippa> which happens to be monadic, thus screwing you over?
08:57:20 <palomer> exactly!
08:57:31 <palomer> or else I'd make a an instance of Eq
08:57:48 <Philippa> All of List needs monadic variants, which doesn't happen :-(
08:58:34 <tromp_> ok, kosmikus, you can email me at tromp@cwi.nl :)
08:58:52 <Philippa> unfortunately you'd get an m [a] out, not a [m a] - so it looks like you're left writing nubByM
08:59:06 <palomer> why does "nubByM" mean?
08:59:11 <palomer> s/why/what
08:59:23 <tromp_> off to dinner
08:59:29 <Philippa> RTFDocumentation for the Monad module. It's a monadic version of nubBy
08:59:38 <palomer> I meant linguistically
08:59:44 <palomer> why use "byM"
08:59:57 <palomer> passing be the monad?
09:00:00 <Philippa> It's (nubBy)M
09:00:00 <palomer> s/be/by
09:00:25 <Philippa> beyond that, read the Data.Monad docs for the significance of the M
09:00:38 <Philippa> er, Control.Monad even
09:00:43 <palomer> I know what a monad is!
09:00:46 * palomer slaps Philippa 
09:00:51 <palomer> it's the "by" that bothered me
09:01:17 <palomer> well, erm, I have knowledge of Monad
09:01:31 <Philippa> don't act like a brat
09:01:39 <palomer> I'm not!
09:01:41 <palomer> I apologize
09:01:42 <ski> nubMBy
09:01:48 <Philippa> nubBy is the function that takes another function for an equality predicate before acting like nub
09:01:55 <palomer> ahhhh
09:01:55 <Philippa> it's part of the standard List module
09:02:04 <Philippa> and *you should have looked that up*
09:02:07 <palomer> then I can just use it inside a do block
09:02:21 <Philippa> if you have a nubByM, yes
09:02:32 <palomer> oh, good point
09:02:36 <Philippa> nubBy isn't sufficient, sadly - the structure of the list's dependant on monadic ops
09:02:37 <kosmikus> tromp_: I'll msg you, but let me first write it down
09:02:52 <Philippa> (if it's just the individual items, rather than where they are and if they exist, you can always sequence it afterwards)
09:03:31 <palomer> oh, I don't care where they are
09:03:46 <Philippa> no, but whether you cons something on or not'll depend on the result of the equality predicate
09:03:59 <Philippa> IOW, the list structure's not independant of it, so the list structure's dependant on monadic code
09:04:10 <palomer> so I have to write it by hand?
09:04:30 <Philippa> yup
09:04:35 <Philippa> which sucks
09:04:39 * palomer agrees
09:05:14 <palomer> ditto for sort?
09:05:22 <palomer> sort would really suck:O!
09:05:56 <Philippa> ditto for sort :-(
09:06:09 <Philippa> (or rather, sortBy)
09:06:18 <Philippa> ('cos sort just uses ordinary equality)
09:06:59 <palomer> looks like I'm going to use that silly quicksort everyone has seen
09:07:18 <palomer> oh, but wait, I can't use list comprehensions
09:07:25 <palomer> ho my
09:07:33 <Philippa> there's definitely no way to use a non-monadic equality or ordering?
09:07:46 <palomer> I'm doing with STRefs
09:07:50 <palomer> s/doing/dealing
09:08:09 * Philippa nods
09:08:18 <Philippa> and at a point where the data in them could still be mutated?
09:08:29 <palomer> exactly
09:08:33 <Philippa> Or is the code doing the sorting read-only? (in which case you can yank all the structure out)
09:08:35 <Philippa> ouch
09:08:44 <palomer> well, not in them per say, but I need to stay in ST
09:09:13 <palomer> moving in and out of ST would be a pain
09:09:41 <Philippa> how big a one?
09:10:02 <palomer> I would need to convert back and forth between string representations
09:10:02 <Philippa> I'm happy doing queries on a bunch of extracted-from-ST data so it's pure code that'll eventually be returned back into ST code
09:10:06 <Philippa> ouch
09:10:15 <palomer> I'm doing constraints solving
09:10:21 <palomer> s/constraints/constraint
09:13:06 <ski> the monadic versions expose more of evaluation order
09:13:24 <palomer> and noone has written a monadified version of Data.List?
09:13:28 <ski> so, potentially, there could be several monadic variants, only differing in order
09:13:55 <palomer> Philippa: btw, have you thought of putting GADTs into your implementation?
09:14:14 <Philippa> palomer: not really. It's been a long time since I was doing any real hacking on it anyway
09:14:25 * ski wonders what extension Philippa had in mind
09:14:44 <Philippa> ski: partial type annotations. Just the wildcard for now, no variables
09:15:05 <palomer> Philippa: existentials in your annotations?
09:15:18 <Philippa> AIUI that should be reasonably easy to implement, though I haven't thought about interactions with (linear) implicit variables
09:15:22 <Philippa> palomer: no
09:15:33 <palomer> foo::Int -> * ?
09:15:47 <palomer> rather, foo::Int -> ? 
09:15:48 <Philippa> was going to use _ rather than *
09:16:00 <palomer> right, that's like foo:: exists x. Int -> x
09:16:02 <Philippa> (by analogy to pattern-matching, again)
09:16:06 <Philippa> no, it's not
09:16:19 <ski> foo = id
09:16:36 <ski> with 'exists' ther result can't be used, effectively
09:16:37 <palomer> oh, so Int -> _ means Int goes to something, but we don't know what
09:16:39 <Philippa> there's no mechanism for getting rid of the existential quantifier once you've got it, plus it interacts badly in a predicative type system
09:16:42 <ski> with '_', it can
09:16:43 <Philippa> right
09:16:52 <palomer> ski: for the second one?
09:17:03 <Philippa> it's "I can't be arsed to write this part of the type, please infer it for me"
09:17:05 <ski> it's like a free logic variable, i think
09:17:09 * Philippa nods
09:17:18 <palomer> Philippa: the wildcare or the existential?
09:17:23 <palomer> s/wildcare/wildcard
09:17:24 <Philippa> the extension to named variables I tend to think of as 'metavariables'
09:17:26 <Philippa> the wildcard
09:17:33 <ski> (whereas 'exists' restricts to a scope)
09:17:38 <palomer> ditto for the existential
09:17:49 * ski wouldn't think of it as 'meta'
09:17:49 <palomer> ski: yeah, the scope of the type
09:17:56 <Philippa> no. The existential *can't collect further constraints*
09:18:03 <Philippa> because you've just annotated that there aren't any
09:18:21 <palomer> I'm pretty sure it can
09:18:32 <palomer> >= :: exists x. Int -> x
09:18:37 <Philippa> ski: they occupy the same sort of role as the metavariables in discussions of type systems themselves. I agree they're not meta once they're in the system itself
09:18:38 <palomer> err, rather
09:18:41 <ski> well, one could maybe get rid of existential by introducing a skolem
09:18:46 <palomer> isZero:: exists x. Int -> x
09:18:56 <Philippa> ski: maybe. Better to just not introduce it in the first place, no?
09:19:37 <palomer> http://cristal.inria.fr/attapl/ <-- at least, I think my interpretation of existentials follows theirs
09:19:51 <ski> Philippa : hmm .. aren't they similar to tyvars bound in a pattern further out ?
09:20:06 <ski> (or must those be general ?)
09:20:17 <palomer> oh, but I see your point
09:20:21 <Philippa> ski: the intention's to pull the same kind of tricks, but those've got all the constraints fixed
09:20:27 <palomer> you can do that with existential tyvar annotations
09:20:43 <palomer> err, parameter annotations
09:21:12 <ski> Philippa : mercury has existentials, they use it for their ST-substitute
09:21:25 <Philippa> cool
09:21:51 <Philippa> feel free to comment on the ticket I posted on the haskell' wiki, btw
09:21:52 <ski> so, new_store returns a new store of type store(S), for some type S
09:22:03 <ski> (of course the store is unique, then)
09:22:38 <ski> this serves a similar purepose as the inner 'forall' in 'runST'
09:22:46 <ski> s/purepose/purpose/
09:23:00 <ski> (only it's exposed)
09:23:03 <palomer> why doesn't anyone use mercury?
09:23:17 <ski> ppl do
09:23:26 <ski> just not so many
09:23:29 <Philippa> because it's confusing in the way haskell is to people who've only coded in C relatives
09:23:41 <palomer> confusing to us?
09:23:55 <ski> palomer : are you familiar with logic programming ?
09:24:02 <Philippa> to me, at least. I could decipher it, but it'd take more time than I want to put in at the moment
09:24:25 <ski> ('it' being ?)
09:24:42 <Philippa> Mercury
09:24:45 <ski> k
09:25:16 * ski hasn't yet written very much in it, but has read most of the papers on the site
09:25:17 <Philippa> I've met prolog before, and I know I /could/ grok Mercury. I probably should and will sometime, but not in an "I'm going to start seriously coding in this language" kinda way
09:25:26 <palomer> ski: isn't it like haskell, except you have to pattern match all the time?
09:25:32 <Philippa> which is the kind of attitude a lot of people have to haskell
09:25:34 <Philippa> palomer: er, no
09:25:42 <ski> well
09:25:47 <ski> it's a pure language
09:25:53 <ski> with declarative IO
09:26:06 <ski> and, the type-system is quite similar to haskells
09:26:11 <ski> e.g. they have type-classes
09:26:17 <palomer> what kind of problems does it solve better than haskell?
09:26:31 <ski> backtracking search
09:26:46 <ski> also, sometimes several functions can be merged into a single predicate
09:27:01 <ski> (this is also true of prolog, but to a lesser degree)
09:27:06 <Philippa> it's a relative of prolog, which is essentially backtracking search + unification
09:27:32 <palomer> hrm
09:27:33 <ski> it can also handle partially instantiated data
09:27:37 <ski> which is cool
09:27:43 <palomer> I'm going to have to try logic programming one of these days
09:27:56 <ski> ok
09:28:01 <Philippa> ski: I assume it's less painful to code in than prolog?
09:28:16 <ski> (note though that prolog has many flaws still .. mercury tries to improve upon that)
09:28:19 <ski> yes
09:28:29 <ski> the evil "cut" doesn't exist in mercury
09:28:49 <Philippa> that's a good start :-)
09:28:51 <ski> (and the usual uses for it are handled in better ways)
09:29:03 <Philippa> (palomer: cut is 'commit to this path so far along the DFS')
09:29:24 <ski> or, maybe i shoudl say .. red cuts doesn't exist
09:29:36 <ski> you can get behaviour of green cut, with other means
09:29:38 <palomer> that sounds like sml
09:29:44 <Philippa> I didn't do enough prolog to understand what that means
09:29:47 <ski> how so ?
09:30:10 <ski> red cuts are the evil ones, they change the semantics to the operational doesn't match the declarative
09:30:13 <Philippa> door
09:30:20 <ski> green cuts just improve efficiency
09:30:56 <ski> of course, in prolog, the difference is only conceptual .. the implementation can't tell which is which (at least generally)
09:31:59 * ski has a comparision of permutation in haskell, prolog, mercury lying around
09:32:13 <ski> i should probably continue extending that
09:32:36 <ski> (i could send a copy, if you're interested)
09:33:20 <palomer> ski: post it on the wiki!
09:33:46 <ski> well, it's not very polished
09:34:06 <ski> maybe when i feel more "done" with it
09:34:39 <ski> (the haskell version of course uses the list monad, to get closest correspondance)
09:36:08 <palomer> hrm
09:36:30 * palomer needs to find someone who wants to add palomer's GADT extension to their type system implementation
09:36:43 <palomer> bbl
09:37:15 <ski> palomer : which is ?
09:42:47 <frederik> so there's no optimistic evaluation in the default ghc branch?
09:43:24 <Cale> frederik: not that I'm aware of
09:43:26 <kosmikus> frederik: no. I'm not even sure it's in any current branch.
09:44:20 <edwinb> It is, I gather, somewhat tricky to maintain...
09:44:34 <frederik> was it part of any branch?
09:44:36 <edwinb> unsurprisingly
09:45:00 <kosmikus> frederik: yes, it was. but robert ennals stopped to work on it, and I think no one else knew the code well enough to keep it maintained.
09:45:11 <frederik> it seems like the only thing that would make haskell usable for non-toy applications
09:45:19 <frederik> now i have to put 'seq' everywhere
09:45:24 <kosmikus> frederik: ?
09:45:32 <kosmikus> it *is* used for non toy applications
09:45:34 <Cale> frederik: ?
09:45:37 <frederik> hehe
09:45:47 <Cale> You shouldn't have to put seq everywhere
09:45:51 <frederik> really
09:46:10 <frederik> doSteps cp mp 0 i pop stats = return stats
09:46:10 <frederik> doSteps cp mp n i pop stats = do
09:46:10 <frederik>     putErrLn ("Step "++show i)
09:46:10 <frederik>     pop' <- stepPop cp mp pop
09:46:10 <frederik>     let s = (snd $ best pop', ave $ vmap fitness pop')
09:46:12 <frederik>     seq (fst s) $ seq (snd s) $ doSteps cp mp (n-1) (i+1) pop' (s:stats) 
09:46:15 <mauke> he just loves the seqs
09:46:19 <frederik> what am i doing wrong?
09:46:38 <frederik> if i don't have the 'seq's then it takes all my memory
09:46:46 <Cale> what does that do?
09:46:47 <palomer> Cale: do you have any solutions for using sortBy with a (a -> a -> m Bool) ?
09:47:18 <frederik> it's a genetic algorithms example problem
09:47:40 <frederik> 'pop' is big, and needs to be garbage collected at each iteration
09:47:43 <ski> (palomer : monadic reflection would probably work .. but it's possibly unsafe :)
09:47:57 <frederik> so...
09:48:02 <palomer> ski: sounds evil, how does that work?
09:48:04 <Cale> palomer: don't :) Run the computations and pair the results with the originals
09:48:15 <Cale> then use sortBy (comparing fst)
09:48:22 <ski> palomer : TheHunter had a TMR article about it
09:48:52 <Cale> frederik: that looks quite a lot like it might be a mapM, or possibly foldM.
09:49:12 <Cale> But you shouldn't try to mix your computation up too much with the IO monad.
09:49:25 <ski> palomer : (the possible unsafeness would come from compiler thinking it can optimise in ways that's not sound with side-effects .. but i don't know if this's actually the case)
09:49:31 <Cale> It's better to separate it out, and let it be lazily evaluated.
09:49:36 <frederik> well it uses random numbers so it has to be in IO
09:49:45 <Cale> that's not true
09:49:50 <palomer> Cale: I can't run the computations, since I'll have to get back into ST afterwards?
09:50:16 <frederik> so you're saying i'm on my own if i use the IO monad...
09:50:31 <frederik> or would foldM solve my problem?
09:50:43 <Cale> palomer: you can run them for their current values -- I don't know how else you want two m Bool's to be compared
09:50:56 <Cale> frederik: well foldM optimises better
09:51:04 <Cale> (or I'd expect it to :)
09:51:07 <frederik> how does that work?
09:51:19 <frederik> are there special rules that say "recursively evaluate the output of foldM"?
09:51:41 <Cale> Most of the nice structural functions have lots of nice compiler support
09:51:50 <frederik> (because i think it's also sad that i have to use 'seq' twice, rather than being able to call 'seq s')
09:51:54 <Cale> mapM tends to turn into a tight loop, for example
09:52:14 <SyntaxNinja> w00t
09:52:37 <palomer> Cale: m bools to be compared?
09:52:44 <palomer> well, it's actually a->a-> ST s Bool
09:53:37 <Lemmih> Hiya SyntaxNinja.
09:53:46 <Cale> frederik: Well, there's two ways to save memory: make sure your value is GC'd sooner by applying seq, or by making sure that it's evaluated later.
09:54:18 <Cale> palomer: sure -- two values of type (ST s Bool) are just computations -- they're normally incomparable.
09:54:59 <Cale> of course, you can run them, if you're in ST
09:55:48 <palomer> oh, righto
09:55:52 <palomer> isn't that excessively slow?
09:56:11 <Cale> not any slower than it has to be?
09:57:06 <SyntaxNinja> Lemmih: how's it going?
09:57:10 <Cale> You'd have to evaluate them all anyway.
09:58:41 <Lemmih> SyntaxNinja: It's going great. Got back from Tunisia some days ago and I have plenty of new books to read (:
09:59:39 <palomer> Cale: even when i'm in ST?
09:59:40 <frederik> Cale: as I expected, a foldM version shows the same problem
09:59:46 <dcoutts_> SyntaxNinja, dons said he'll consider the cabal-get de-bloat idea. He suggested "mini http as used by lambdabot"
09:59:46 <Cale> frederik: sure, for some aspects of genetic algorithms, I can imagine some strictness being needed, but even doing most things in the IO monad mostly won't give you the right sort of strictness (many of your values will still be lazy), but some things will be stricter than you'd want.
10:00:54 <frederik> so now you're saying that I need 'seq' after all?
10:00:59 <Cale> The 'right way' is to write the algorithm in such a way that it uses as little data from the previous step as necessary in order to construct each part of the current result.
10:01:34 <frederik> i think my implementation is indeed minimal
10:02:04 <Cale> If the issue is that fundamentally, you're collapsing a lot of data into a single value by observing everything, then you need something like foldl' or seqs.
10:02:17 <Cale> But in any other case, laziness is your friend.
10:02:18 <palomer> someone give me a symbol for the unsound operator, in the sense "constraints a combined with constraints b would be unsound"
10:02:27 <frederik> where is seqs documented?
10:02:42 <Cale> palomer: ah, I see now.
10:02:49 * ski wonders if strictness patterns would be nicer
10:02:53 <palomer> Cale: see what?
10:02:55 <Cale> frederik: that was plural of seq :)
10:03:04 <frederik> oh
10:03:13 <Cale> palomer: you want to avoid computing all pairs.
10:03:14 <Cale> okay
10:03:38 <palomer> err, no
10:04:15 <palomer> Cale: I could write a sort algorithm in ST that wouldn't need me to run runST
10:04:48 <frederik> so what non-toy applications is haskell used for? i'm thinking of things that actually do a lot of data processing within the run time system, not things like 'darcs' that just move files around
10:04:49 <Cale> oh, I wasn't quite even suggesting that
10:05:01 <Cale> frederik: GHC
10:05:08 <Cale> Pugs
10:05:30 <frederik> anything numerical?
10:05:31 <Cale> I wrote a pipeline scheduler and register allocator in it
10:05:38 <Cale> There's a project for a bittorrent client
10:05:54 <Cale> I don't know about too many numerical apps.
10:06:08 <frederik> i don't think any of those things are as data-intensive as what people typically use say matlab for
10:06:33 <Cale> well, there's still Matlab :)
10:06:45 <frederik> yes there is
10:06:53 * ski shudders
10:07:11 <frederik> it just boggles my mind that they took out optimistic evaluation
10:07:32 <frederik> that would have made all my problems go away
10:07:34 <Saulzar> I think darcs does a lot more than 'just move files around' :)
10:07:44 <Cale> I expect optimistic evaluation would probably annoy me more often than it would help.
10:07:51 <frederik> really?
10:07:53 <Cale> It does.
10:08:05 <palomer> why?
10:08:10 <Cale> (Saulzar)
10:08:54 <Cale> A lot of the things I do / have done with Haskell involve lots of nondeterministic computation
10:09:06 <Saulzar> Hm, what is optimistic evaluation?
10:09:13 <Saulzar> Not the same as strict?
10:09:17 <frederik> no
10:09:34 <ski> opt. evals things before they are forced
10:09:44 <Cale> You do your computation in the list monad, in such a way that reading off the head of the list gives the same result as the greedy algorithm.
10:09:44 <frederik> it's something that Rob Ennals added to GHC which evaluates thunks "optimistically"
10:09:59 <Cale> and you *really* don't want any extra evaluation at any step
10:09:59 <palomer> frederik: wasn't very popular?
10:10:00 <frederik> so that objects they reference can be freed
10:10:29 <Saulzar> What does that mean exactly?
10:10:35 <frederik> Cale: the greedy algorithm?
10:10:38 <Cale> because the final list is trillions of elements long (or possibly longer)
10:11:06 <Cale> frederik: you're producing every possible "something" based on some constraints
10:11:09 <Saulzar> I use haskell for writing toys which use numerics :)
10:11:38 <palomer>     Couldn't match `ST s (Unifier s, [HornClause s])' against `t -> t1' <--this is the error I _hate_ the most!
10:11:48 <frederik> Cale: oh, well that's different from what i'm doing
10:11:57 <palomer> it doesn't tell you anything!
10:12:02 <Cale> For example, scheduling assembly code -- there are lots of possible ways to order the instructions.
10:12:19 <frederik> Cale: so you're saying that these are reasons not to use optimistic evaluation?
10:12:35 <frederik> Cale: i mean places where it would get in the way?
10:12:54 <Cale> frederik: optimistic evaluation, unless it was incredibly clever, would totally choke on my register allocator
10:13:03 <Cale> it would end up consuming way more memory and time
10:13:05 <frederik> did you read the paper?
10:13:11 <Saulzar> palomer, It means you're using a value where it wants a function, or the other way?
10:13:19 <palomer> Saulzar: yes, but where??
10:13:21 <palomer> gah!
10:13:33 <frederik> Cale: i thought it sort of does the evaluation in the background and then stops if it ends up taking too much memory
10:13:41 <Saulzar> Are you using type signatures yet? That always helps me :)
10:13:53 <Cale> frederik: Right, it would do that over and over and over again
10:13:58 <Cale> and never get anywhere
10:14:28 <palomer> Saulzar: of course
10:14:34 <frederik> Cale: did you read the paper? i thought it kept statistics on those things
10:14:52 <edwinb> I think it is clever about remembering which functions *don't* get fully evaluated.
10:14:53 <Cale> I read it at one point
10:15:03 <frederik> Cale: ... and avoided doing the evaluation if it wasn't helping
10:15:03 <edwinb> So if you're using laziness heavily, you'll get a slight performance hit.
10:15:09 <edwinb> But otherwise, you'll get a big gain.
10:15:32 <frederik> Cale: how would going out of the IO monad help me? i'm reluctant because i'll have to rewrite a lot of stuff
10:15:54 * davidhouse gets on to the monads chapter of his book
10:16:08 <gour> Lemmih: is yi supposed to be the only editor embeddable into hiDE?
10:17:11 <Lemmih> gour: No.
10:17:23 <gour> Lemmih: ??
10:17:47 <Lemmih> I'm not using yi with hIDE.
10:17:49 <Cale> frederik: You'll likely be able to reclaim some laziness, and the code will be much easier to reason about anyway. Though if you think strict evaluation is the only thing you can do, then go ahead with what you have.
10:17:58 <gour> Lemmih: ????
10:18:05 <Lemmih> gour: !
10:18:30 <gour> Lemmih: :-) what do you use?
10:18:31 <Cale> You don't really need the IO monad to generate random numbers, though you do need it to get hold of a random generator.
10:18:32 <frederik> Cale: obviously i can use the non-IO random interface. or unsafePerformIO around the random number stuff. but i don't see how anything will change
10:19:00 <Lemmih> gour: A normal SourceView.
10:19:06 <Saulzar> frederik, What's the issue?
10:19:12 <Cale> @type System.Random.randomsIO
10:19:13 <lambdabot> Not in scope: `System.Random.randomsIO'
10:19:21 <Cale> @type System.Random.randoms
10:19:22 <lambdabot> forall a g.
10:19:22 <lambdabot> (System.Random.Random a, System.Random.RandomGen g) =>
10:19:22 <lambdabot> g -> [a]
10:19:31 <Cale> that's the one :)
10:19:42 <frederik> Saulzar: i posted some code way up there. it's looping and holding on to some large values across iterations, unless i force things with 'seq'
10:20:10 <SyntaxNinja> dcoutts: OK. 
10:20:19 <Cale> It's hard to say what to do with that without knowing more about how it fits in with the rest of your program
10:20:19 <SyntaxNinja> Lemmih: how was tunisia?
10:20:25 <palomer> Cale: w.r.t. sortBy, I'd expect it returns an ST s [a]
10:20:33 <palomer> sortByM, that is
10:21:01 <frederik> Cale: for instance, i'm returning a list of (average fitness, max fitness) values. if i went through the list and printed only the average values, then the max values would still hold on to the population objects and it would eat up all my memory...
10:21:03 <Cale> palomer: hmm, okay
10:21:10 <SyntaxNinja> hurray!  /me just linked /home/darcs/cabal to /home/darcs/packages/Cabal, so there's only one repo now! and my time of manually syncing two cabal repos has come to an end!
10:21:16 <Cale> palomer: nothing like that exists in the current libraries
10:21:29 <palomer> Cale: but it would be faster than using runST, right?
10:21:47 <Cale> frederik: not if they were just completely unevaluated thunks
10:22:06 <Saulzar> frederik, Space leaks have plagued me too, though it seems that once you've got some of the techniques figured out they're not so daunting
10:22:13 <frederik> Cale: hmm? the problem is that they reference large objects in their unevaluated states
10:22:27 <gour> Lemmih: is hIDE usable? what about other editors, e.g. Scribes (http://scribes.sourceforge.net/). atm I use pida - http://pida.vm.bytemark.co.uk/projects/pida/wiki) but would rather start using hIDE and not switching all the time :-)
10:22:42 <Cale> frederik: allocation for those large objects doesn't happen until they get forced
10:23:01 <Saulzar> If they're already allocated though...
10:23:03 <Cale> normally anyway
10:23:05 <frederik> Cale: right. i said "if i went through the list and printed only the average values". that's where they are allocated
10:23:09 <Cale> if you apply seq too early it might
10:23:16 <Cale> no
10:23:34 <Cale> (well, it shouldn't)
10:23:47 <Cale> Oh, I see
10:23:57 <frederik> Cale: the result is a list of [(Double,Double)]. doing "print $ map fst l" will eat up my memory
10:24:27 <Cale> You're referring to all the various allocations done by the algorithm -- yeah, that might be true.
10:24:27 <frederik> Cale: if for instance i wanted to produce two graphs, i would start with "map fst l" and then do "map snd l"
10:24:43 <tibbe> anyone has personal experience of phone interview(s) with google or know of a good source of info?
10:24:48 <Lemmih> SyntaxNinja: It was pretty nice. And it was quite funny to get back home and realize that the Muhammed issue has escaladed so far (:
10:25:07 <palomer> I'm surprised it took so long to escalate
10:25:17 <Cale> frederik: could you produce them separately?
10:25:17 <Lemmih> gour: Well, it can't save files yet.
10:25:20 <Cale> (in the first place)
10:25:47 <frederik> Cale: well that would be twice as slow as it should be
10:26:12 <frederik> Cale: do you see why optimistic evaluation is a good idea?
10:26:36 <Cale> I'm not sure why it would be -- you're doing two different summarisations.
10:26:58 <Cale> Unless you mean that you'd re-evaluate some other large structure.
10:27:06 <frederik> right
10:27:16 <Cale> which ought to be the input anyway, and be shared.
10:27:49 <frederik> no, because it can't all fit in memory at once
10:28:02 <frederik> that's why it's a simulation in *time*
10:29:00 <Cale> well, if you don't want to share it, then produce your two graphs separately, and reevaluate it
10:29:35 <frederik> which would take twice as long as necessary, as i said
10:29:47 <frederik> right?
10:30:00 <SyntaxNinja> Lemmih: yeah, it's big news!
10:30:03 <frederik> maybe i should use python...?
10:30:07 <Cale> I don't see how that's twice as long as necessary.
10:30:20 <Cale> You can either keep the thing in memory, or you can't.
10:31:11 <Cale> It's just the usual memory/space tradeoff.
10:31:44 <frederik> ok i have a list of big values "bs :: [B]" and a function "f :: B -> (S,S)". i want to print out the result of "map (fst.f) bs" and "map (snd.f) bs"
10:32:12 <frederik> how do i do this without "seq", without re-evaluating 'bs', and without running out of memory (which will happen if all of 'bs' is in memory at once)
10:32:14 <Saulzar> I don't see what the problem with evaluating it once, forcing it (with seq) or however you require. Is a big issue?
10:32:40 <gour> Lemmih: any eta when it will be save-files-ready?
10:32:42 <frederik> Cale was saying that i don't need to put 'seq' everywhere. 
10:33:05 <Cale> frederik: not everywhere -- you may occasionally need one or two
10:33:13 <Saulzar> You don't have to put it everywhere, but it is certainly useful in some cases
10:33:25 <frederik> well that depends on the kind of program doesn't it?
10:33:34 <frederik> i'm doing this kind of thing a lot
10:33:34 <Cale> Usually there's just one point in an algorithm where a seq would be needed.
10:34:26 <Cale> If computing f's result uses all of B, then yes, put a seq in it which forces the parameter.
10:34:40 <frederik> what if S is a medium-sized nested data structure?
10:34:51 <Saulzar> You could also compute the list lazily then force it afterward 
10:34:59 <Cale> As S gets larger, it becomes less and less worthwhile
10:35:31 <frederik> it could be a 100-tuple and still be quite worthwhile
10:35:41 <frederik> then i'd need 100 'seq's
10:35:42 <frederik> right?
10:35:51 <Cale> frederik: no
10:35:56 <frederik> 99
10:36:07 <frederik> at least
10:36:12 <Cale> You'd use Control.Parallel.Strategies or DeepSeq
10:36:28 <frederik> what is DeepSeq?
10:36:36 <Saulzar> You could use a strict data type potentially too
10:36:59 <Cale> yeah, or strict data, if you didn't need the laziness anywhere else
10:37:26 <Saulzar> For things like vectors where it usually doesn't make sense to evaluate x without y...
10:37:44 <frederik> sigh. ok well i still think that optimistic evaluation is the best solution
10:37:56 <Cale> http://www.cse.unsw.edu.au/~dons/lambdabot/DeepSeq.hs
10:38:09 <frederik> but obviously you guys aren't going to be convinced
10:38:10 <Saulzar> I wouldn't get too hung up on it... it's not such a huge barrier in the end I think :)
10:38:26 <palomer> well, erm, I don't care that much about performance
10:38:49 <frederik> this seems like quite a lot of work for something which is a non-issue in any other language
10:38:50 <Cale> Optimistic evaluation might be good sometimes, but I'm not so sure that it could really be smart enough in all cases where you really want laziness.
10:39:02 <Cale> Maybe if there was a compiler pragma to turn it on.
10:39:22 <Cale> Well, it's the same issue as you have in any other language
10:39:50 <frederik> why? because i could just declare my data types strict?
10:39:56 <frederik> how do i make a strict tuple by the way?
10:39:58 <Lemmih> gour: No, not really.
10:40:03 <Saulzar> frederik, I think mainly it takes a little effort to figure out strategies to deal with it. Then it is not such an effort
10:40:12 <Cale> Tuples are lazy
10:40:27 <frederik> i thought there was a way to make them strict
10:40:40 <Saulzar> frederik, You use the ! annotation on data types
10:40:42 <Cale> data MyType = MyConstructor !Integer !Integer !Double
10:41:05 <Cale> That will make MyConstructor strict in each of its parameters.
10:41:16 <Cale> So forcing evaluation of one will force them all.
10:42:09 <palomer> is there a reason to use strictness other than performance?
10:42:26 <Cale> palomer: no
10:42:46 <Cale> If you have infinite memory, laziness is always better.
10:43:13 <Saulzar> Debugging maybe ... trace "Oh no" `seq` 
10:43:40 <xerox> Saulzar: does that typecheck?
10:43:41 <Cale> I suppose
10:43:44 <xerox> (Howdy!)
10:43:48 <Saulzar> No idea :)
10:43:51 * palomer goes and buys infinite memory
10:44:03 <xerox> I need some more finite memory in fact :-)
10:44:04 <Cale> xerox: yeah, you can put anything as the first parameter of seq and it'll typecheck
10:44:36 <Saulzar> Well, also using too much memory can/will  hurt your time performance too .. 
10:44:38 <Cale> I have 1GB of memory on my desktop machine now :)
10:44:53 <Cale> Saulzar: well, that can be true
10:45:01 <xerox> @type (Debug.Trace.trace "" `seq`)
10:45:02 <lambdabot> forall b. b -> b
10:45:05 <Cale> certainly if you start swapping
10:45:25 <xerox> Cale: ah, right.
10:45:33 <Cale> also, if your code spends most of its time in the GC
10:45:46 <Saulzar> Also the GC and whatnot, and allocation is not free either
10:45:58 <Cale> yeah
10:46:26 <frederik> well thanks for the advice. i'm still disappointed with the decision to remove OE
10:46:34 <Cale> laziness can be quite good at keeping allocation to a minimum though
10:46:54 <Cale> frederik: yeah, it would be nice to have it, but these things need maintainers :)
10:47:09 <frederik> is the runtime changing a lot?
10:47:17 <Cale> yeah
10:47:38 <Saulzar> How many people work on GHC anywhere near fulltime?
10:47:39 <Cale> the whole language is changing a lot
10:47:52 <frederik> hrm. still, i can't imagine any changes which would be more important to me than OE
10:48:06 <frederik> and it was Rob's whole thesis wasn't it?
10:48:22 <Cale> frederik: perhaps you'd like to maintain OE in GHC then? :)
10:48:58 <frederik> no, i would like you to maintain it :)
10:49:08 <Cale> heh
10:58:09 <palomer> is it possible to insert some performUnsafeIO in my code to simulate the printf debugging style?
10:58:26 <Cale> palomer: see Debug.Trace
10:59:02 <wilx> Beware it won't print every time you would expect.
10:59:08 <wilx> At least such is my experience.
10:59:09 <palomer> :/
10:59:32 <frederik> so ... Control.Parallel.Strategies isn't really documented
10:59:32 <palomer> wilx: for Trace or performUnsafeIO?
10:59:39 <wilx> Trace.
10:59:42 <Cale> Well, it will print whenever evaluation is forced, which might not be when you expect :)
10:59:43 <Saulzar> See 3 lines up for the `seq` example :)
11:00:28 <Cale> trace uses unsafePerformIO, but it includes a bunch of compiler pragmas to make sure that it isn't simply discarded by the compiler
11:01:28 <Cale> also beware that if you print out structures from inside your algorithm, it can change performance behaviour by forcing things early.
11:01:42 <Cale> (which can be really bad sometimes)
11:02:11 <palomer> oh, I don't rely on laziness anywhere
11:02:14 <palomer> maybe ST does though
11:02:35 <Cale> not unless you're using lazy ST
11:05:55 <palomer> nope
11:14:46 <palomer> @hoogle (a->b) -> [a] -> [(a,b)]
11:14:47 <lambdabot> No matches, try a more general search
11:14:51 <palomer> @hoogle zipwith
11:14:52 <lambdabot> Data.List.zipWith :: (a -> b -> c) -> [a] -> [b] -> [c]
11:14:52 <lambdabot> Prelude.zipWith :: (a -> b -> c) -> [a] -> [b] -> [c]
11:14:52 <lambdabot> Control.Monad.zipWithM :: Monad m => (a -> b -> m c) -> [a] -> [b] -> m [
11:14:52 <lambdabot> c]
11:15:23 <Cale> zip xs (map f xs)
11:16:05 <palomer> good one
11:16:08 <palomer> @hoogle zipM
11:16:09 <lambdabot> Control.Monad.mapAndUnzipM :: Monad m => (a -> m (b, c)) -> [a] -> m ([b],
11:16:09 <lambdabot> [c])
11:18:38 <palomer> doesn't it suck when you write a beautiful algorithm and it doesn't work?
11:18:48 <palomer> you even named your variables with intuitive names!
11:19:42 <Saulzar> Oh yes...
11:20:37 <palomer> time to play "let's shorten palomer's code" game:
11:20:41 <palomer> varAndImages u = mapM (\x -> do {y <- image x u;return (x,y)}) (domain u)
11:23:44 <palomer> don't everyone speak at once:P
11:24:46 <vincenz> @hoogle image
11:24:47 <lambdabot> Text.Html.image :: Html
11:24:47 <lambdabot> Graphics.Rendering.OpenGL.GL.PixelRectangles.PixelStorage.imageHeight ::
11:24:47 <lambdabot> PixelStoreDirection -> StateVar GLint
11:24:47 <lambdabot> Graphics.Rendering.OpenGL.GL.Texturing.Specification.getTexImage ::
11:24:47 <lambdabot> Either TextureTarget CubeMapTarget -> Level -> PixelData a -> IO ()
11:34:53 <liyang> I need a word.
11:36:32 <liyang> Say I had a POSet X = { a < b < c, a < d } and I had a function f which took a to { c, d }. What's that called? It's not the closure as I don't include b or a.
11:37:13 <Philippa> the "greatest upper bounds"?
11:37:44 <liyang> ah. Thanks. But a bit more succinctly? ^_^;;
11:49:28 <palomer> Cale: how do we call the set representation of a function?
11:49:59 <Cale> The graph of f
11:50:11 <Cale> er...
11:50:25 <Cale> or are you referring to my variety construction above?
11:50:31 <palomer> no, the set of pairs
11:50:32 <Cale> er, not above
11:50:39 <Cale> sorry, wrong channel :)
11:50:40 <Cale> hehe
11:51:00 <Cale> yeah, the set of pairs is commonly called the graph
11:51:22 <Lemmih> Whee. HIDE now does correct syntax-highlighting for unicode files: http://scannedinavian.com/~lemmih/HideUnicodePretty.png
11:52:03 <xerox> Lemmih: and it does really work as Haskell source?
11:52:20 <Lemmih> xerox: Yes.
11:52:31 * xerox blinks
11:52:48 <Cale> There's some new code in GHC for handling unicode apparently
11:53:36 <xerox> That rocks!
11:54:31 <palomer> Cale: remind me what a complete lattice is
11:54:49 <xerox> A wikipedia entry?  <grin>
11:56:17 <palomer> :O!
11:56:25 <davidhouse> right, back to learning about monads.
11:56:30 <palomer> has anyone ever heard "this relation is coarser"?
11:56:37 <palomer> (like, the opposite of finer)
11:57:08 <Cale> palomer: every subset has a least upper bound and greatest lower bound
11:57:12 <Cale> + poset
11:58:32 <palomer> do lattices must have tops and bottoms?
11:58:43 <Cale> yeah
11:58:55 <Cale> since you can take that subset to be the entire set
11:59:14 <palomer> oh, righto
11:59:14 <Cale> so the entire poset has a lub and glb
11:59:26 <liyang> @hoogle (a -> m a) -> a -> m a
11:59:27 <lambdabot> Data.Generics.Schemes.everywhere :: (a -> a) -> a -> a
11:59:27 <lambdabot> Data.Generics.Schemes.everywhere' :: (a -> a) -> a -> a
11:59:27 <lambdabot> Prelude.($) :: (a -> b) -> a -> b
12:00:25 <Lemmih> dcoutts_: ping.
12:07:48 <palomer> @djinn a -> (c->d,e->f) -> (a -> c -> d, a -> e -> f)
12:07:48 <lambdabot> f _ (a, b) = (\ _ c -> a c, \ _ d -> b d)
12:07:49 <gour> Lemmih: that's new haskell syntax (on the shot)?
12:09:15 <Lemmih> gour: Yeah, GHC recently begun to support unicode in Haskell sources.
12:09:29 <gour> Lemmih: wonderful!
12:11:20 <Lemmih> I should've used 'began' instead of 'begun', right?
12:12:12 <Cale> yeah, I think so
12:20:10 <davidhouse> how can i read a file in gchi?
12:20:26 <Cale> read in which sense?
12:20:46 <davidhouse> print it to stdout
12:20:57 <davidhouse> so i type "read this file" and it prints it
12:21:18 <Lemmih> :!cat file (:
12:21:22 <Cale> readFile "/etc/services" >>= putStrLn
12:21:51 <davidhouse> thanks Cale, Lemmih (although your solution was cheating ;) )
12:36:06 <vincenz> main = getArgs >>= mapM_ (\x -> catch (readFile x) (\y -> return "") >>= putStr)
12:36:12 <Mitar> can anybody point me to an algorithm for constructing deterministic finite state machine from regular expression without going through nondeterministic?
12:36:32 <vincenz> Mitar: look for literature on transforming NFA to DFA
12:36:41 <vincenz> oh... without
12:36:45 <Mitar> :-)
12:36:49 <vincenz> why?
12:37:11 <Mitar> we have to do it on exam
12:37:27 <Mitar> and i was wondering if there is easier way than to go through all this steps od nka
12:37:33 <Mitar> of nfa
12:38:01 <vincenz> regexp is directly translated to an nfa, tho
12:38:12 <vincenz> I would think any attempt to do what you ask would just roll that with nfa->dfa into one
12:38:18 <vincenz> but conceputally you're doing nfa->dfa
12:38:27 <Mitar> ok
12:38:31 <Mitar> i was just checking
12:38:43 <Mitar> i read somewhere that there is some way with a tree
12:38:51 <Cale> you could try to do it in an ad-hoc fashion, but it gets hard for some regexps
12:39:01 <Mitar> http://www2.toki.or.id/book/AlgDesignManual/BOOK/BOOK5/NODE207.HTM
12:39:09 <Mitar> "The deterministic construction starts with the parse tree for the regular expression, observing that each leaf represents one of the alphabet symbols in the pattern."
12:39:35 <Mitar> i will try it ad-hoc, but i would like to have a algorithm in case it is not obvious
12:40:17 <Cale> of course
12:40:45 <Mitar> so it is still the best to go through nfa
12:40:47 <Mitar> thanks
12:41:01 <Cale> I think so
12:41:42 <Mitar> ok
12:41:48 <Mitar> i have one more question ...
12:43:03 <Mitar> what is correct sequence of actions when converting to greibach normal form: removing useless productions, removing lambda productions, removing unit production OR removing lambda productions, removing unit productions, removing useless productions
12:43:23 <Mitar> i have read that you start with removing useless productions and then move to lambda and so on
12:43:43 <Mitar> but i found out that when you remove lambda productions you can get some useless productions
12:43:48 <davidhouse> @type getArgs
12:43:49 <lambdabot> Not in scope: `getArgs'
12:44:58 <Mitar> like when you have: S -> ABABA; A -> a; B -> lambda and you remove lambda, then you get a lot of useless productions with B in it, that can be then easily removed but everywhere i read they first remove useless productions
12:51:43 <SamK> what is the reason that the pre-defined functions, like + and * are not lazy with respect to their arguments in haskell?
12:52:18 <vincenz> SamK: who says they're not?
12:52:26 <Cale> they are
12:53:36 <SamK> oh ok, I am working my way through the lectures here: http://video.s-inf.de/#FP.2005-SS-Giesl.(COt).HD_Videoaufzeichnung
12:54:01 <Cale> For types like Int, of course they can't be too lazy.
12:54:09 <SamK> and he mentions that things like + and * are exceptions to the lazy evaluation rule
12:54:53 <Cale> Only if you specifically add code to make them stricter for your type.
12:55:40 <Taral> grr, snap, snakr.
12:55:43 <Taral> *snark
12:55:54 <Taral> I'm about ready to abandon haskell-prime :<
12:56:06 <Cale> Taral: hm?
12:56:09 <Cale> There's a lot of annoying posts on it
12:56:12 <SamK> for example he says: 0 * infinity (where infinity = infinity + 1) does not terminate
12:56:19 <Taral> Well, the original purpose was a "conservative" extension.
12:56:32 <Taral> But almost everything proposed is not conservative.
12:56:54 <Cale> Taral: I expect that most of these suggestions will be thrown out.
12:57:00 <Taral> I hope so.
12:57:23 <Taral> Even ! patterns are not conservative, considering that they're not available in any release of any haskell compiler. (They're in GHC cvs.)
12:57:38 <dcoutts> Lemmih, pong
12:58:16 <Cale> SamK: usually not, though you could make it do so
12:58:25 <dcoutts> Lemmih, hey that pic looks nice!
12:58:30 <Cale> Taral: well, they're trivial
12:59:02 <Taral> trivial, but of unproven use/validity.
12:59:02 <Cale> Brian Hulley's suggestions always seem insane to me.
12:59:03 <flux__> I guess if condition then a else a also evaluates condition?
12:59:18 <flux__> although there could be a rewrite rule to remove that..
12:59:40 <Taral> flux__: if condition then a else a ==> condition `seq` a
12:59:47 <Cale> Taral: their use is reasonably obvious, and they provide a nice counterpoint to ~ patterns
12:59:55 <jethr0_> ls
13:00:04 <Lemmih> dcoutts: I've been thinking about starting a screenshot gallery for HIDE.
13:00:07 <Taral> Cale: I agree completely. I'm just wondering where the line will be drawn on "conservative".
13:00:21 <dcoutts> Lemmih, good idea
13:00:32 <dcoutts> Lemmih, for gtk2hs we use gallery
13:00:34 <Cale> Taral: I'd also like to see a lot of the things which were removed going from 1.4 to 98 to come back.
13:01:01 <kosmikus> monad comprehensions, yay
13:01:02 <dcoutts> Lemmih, or just the haskell.org wiki
13:01:03 <Taral> Cale: Like monad comprehensions and the Monad hierarchy?
13:01:03 <SamK> cale: is that because * does not pattern match against (0,x) = 0 for efficiency?
13:01:20 <Cale> SamK: yeah
13:01:24 <Cale> Taral: yeah
13:01:57 <Taral> I really liked the Functor/Fixpoint/Applicative/Monad/Arrow hierarchy
13:01:59 <Cale> Taral: it usually uses a machine implementation of *, which means that you have to evaluate both args.
13:02:11 <Taral> :D
13:02:25 <Cale> Taral: yeah, if it was that fine though, I'd really really want some extension to classes
13:02:28 <SamK> right, makes sense, cheers
13:03:01 <Cale> Something like default instances.
13:03:02 <Taral> Well, there's the whole FD problem too.
13:03:31 <Taral> Did anyone else notice that boxy types == proof reconstructioN?
13:03:41 <Taral> (sorry, complete change of subject there.)
13:04:22 <Cale> I'm afraid I didn't really look all that closely at boxy types, though I did notice that they'd be a cool thing to have every once in a while.
13:05:14 <Taral> Hm.
13:05:37 <Taral> I recently ran across proof compaction/reconstruction and thought it looked a lot like what boxy types does.
13:07:46 <dcoutts> Lemmih, did I tell you I'm going to cs.nott.ac.uk to talk about gtk2hs and possibly a little about hIDE? I'd be cool to do a live demo of it and/or some interesting screenshots.
13:08:09 <Lemmih> Neat!
13:08:35 <Taral> I also really like the idea of [a,b,c] ==> (return a) `mplus` (return b) `mplus` (return c)
13:08:48 <dcoutts> Lemmih, the epigram people are interested in gtk2hs for the new version of epigram and our IDE stuff
13:09:00 <xerox> Hola dcoutts!
13:09:03 <dcoutts> hia xerox 
13:09:31 <dcoutts> xerox, I was sketching out some stuff for a pure cairo layer yesterday.
13:09:47 <dcoutts> data types, function types etc
13:09:51 <Cale> Taral: yeah, I'm actually a little afraid of unresolved overloading issues in plain lists like that, but it would have to be tried.
13:10:02 <dcoutts> xerox, some bits are obvious, others I'm not sure about
13:10:30 <Cale> Restricted data types are cool, and I really want something like that, but I think the whole wft thing is ugly.
13:10:33 <xerox> Oh that, yeah.
13:10:45 <xerox> @wtf wft
13:10:46 <lambdabot> No match for "wft".
13:10:51 <Taral> well-formed type
13:10:57 <dcoutts> xerox, the more I think about it, the more I like it. It makes a lot of things that are implicit in the current api more explict. Eg the fact that paths must be stroked or filled to be actually drawn.
13:11:05 <Taral> I didn't like any of the approaches that the RDT paper took.
13:11:09 <xerox> dcoutts: that's right.
13:11:10 <Taral> I like the idea, I find it very intuitive.
13:11:30 <Taral> But with the type/class namespace split, you could just as easily define:
13:11:55 <dcoutts> xerox, so it means people can't make that mistake, or other mistakes like mismatched numbers of save/restore.
13:12:34 <xerox> dcoutts: I did it often, I'm with you.
13:12:51 <Taral> data Eq a => Set a = Set [a] ==> class Eq a => Set a
13:12:52 <Taral> or something
13:13:03 <Taral> so that people can use "Set a" to mean "the context required by Set"
13:13:07 <Taral> and then you don't have any surprises.
13:13:24 <Taral> in fact, you could make any use of the type "Set a" imply the context "Set a".
13:13:44 <Cale> We really just need a general solution to the problem of making Set an instance of Monad and Functor :)
13:13:57 <Taral> ha
13:14:02 <xerox> Functor seem doable, is it really a problem?
13:14:23 <Cale> Yeah, it is
13:14:27 <Cale> try it :)
13:14:41 <Taral> You'd have a problem if the mapping function wasn't one-to-one.
13:14:45 <xerox> ...is it because of the internal representation?
13:14:52 <xerox> Oh-uhm.
13:14:57 <xerox> Right.
13:14:58 <Cale> It's because it requires Ord
13:15:14 <Cale> has nothing to do with the mapping function -- there's already a Set.map
13:15:18 <Taral> What about an existential type? The only problem there are the constructor functions "empty" and "singleton"
13:15:18 <Cale> @type Data.Set.map
13:15:19 <lambdabot> forall b a.
13:15:19 <lambdabot> (Ord b, Ord a) =>
13:15:19 <lambdabot> (a -> b) -> Data.Set.Set a -> Data.Set.Set b
13:15:30 <xerox> Cale: why does it?
13:15:38 <Taral> data Set a = forall a. Eq a => Set [a]
13:15:52 <Taral> or whatever
13:16:06 <Cale> xerox: efficiency -- even if not Ord, you'd need Eq
13:16:26 <Cale> Set uses a balanced tree representation
13:16:31 <Taral> What about type-holes?
13:16:43 <Taral> This all comes up because type specifications have to be complete.
13:16:52 <Taral> With incomplete type specifications, you don't have this problem
13:16:57 <Taral> well, not as badly.
13:17:03 <Cale> hm?
13:17:04 <Taral> hm
13:17:08 * xerox will observe for Hawking Radiation out of type holes
13:17:17 <Taral> type holes
13:17:21 <Taral> f :: _ -> Set a
13:17:25 <Taral> where _ is a hole
13:17:30 <Taral> for the type inference engine to fill in
13:17:47 <Taral> could have context holes too
13:17:52 <Taral> f :: _ => a -> Set a
13:17:58 <Cale> Well, there are very practical issues with that
13:18:11 <kosmikus> Taral: this is proposed (PartialTypeSignatures)
13:18:22 <Taral> kosmikus: Yes, I know. I like it a lot.
13:18:26 <Taral> Boxy types makes it much easier.
13:18:39 <Taral> Since then _ (and its parents) are just an unboxed part of the type
13:18:43 <Cale> If it's the proposed type holes, then I don't think it solves anything here
13:18:52 <kosmikus> Taral: I don't think that boxy types have any realistic chance of getting into Haskell', though.
13:18:53 <Cale> such things would never be allowed in class declarations
13:19:01 <Cale> For example, how is that going to work with separate compilation?
13:19:07 <Taral> boxy types are an implementation issue, not a syntactic issue
13:19:13 <Taral> so they don't have anything to do with haskell'
13:19:26 <Taral> partial type signatures, however, are not likely to make it into haskell', I agree
13:19:27 <kosmikus> er, no
13:19:34 <Cale> Taral: Suppose I have a module A in which f :: _ => a -> Set a
13:19:40 <kosmikus> boxy types are a semantic issue
13:19:54 <Cale> er
13:20:10 <Taral> kosmikus: I see what you mean. Yes, they're not going to be required for haskell', I agree there too.
13:20:27 <Cale> Taral: Suppose I have a module A in which map :: (Functor f, _) => (a -> b) -> (f a -> f b)
13:20:43 <Cale> that _ still has to be resolved by the top of the module
13:20:50 <Taral> Yes.
13:20:51 <Cale> or else I can't compile it
13:21:08 <Taral> Still working on it.
13:21:10 <Cale> and it can't be nondeterministic
13:21:30 <kosmikus> Cale: yes. it'd be resolved to () with the standard definition of map ...
13:22:01 <Cale> kosmikus: right -- which means that an instance for Set still can't be defined
13:22:07 <kosmikus> oh, well. forget what I said. standard definition for functors doesn't exist.
13:22:15 <Cale> even if you put both in the same module, it'd have to compile to something
13:22:35 <kosmikus> yes, sure, it wouldn't help for the Set/Ord thing
13:23:02 <Taral> Is a polymorphic assignment considered a CAF?
13:23:13 <Taral> is_this_a_caf :: [a]
13:23:20 <Taral> is_this_a_caf = []
13:23:41 <kosmikus> I think so, but I'm not entirely sure.
13:23:47 <Taral> er, top-level assignment, sorry
13:24:18 <Taral> what about...
13:24:23 <Taral> is_this_a_caf :: Eq a => [a]
13:24:32 <Cale> no
13:24:34 <Cale> that's not
13:24:36 <Taral> ok, good
13:24:44 <Taral> so...
13:24:47 <Taral> empty :: Set a
13:24:57 <Taral> would not be a CAF if the compler knew that Set was an existential type?
13:25:00 <Cale> though without the type sig, the bloody MR will catch you :)
13:25:10 <Taral> Cale: I know, that's why I gave it. :P
13:25:34 <Taral> I dislike top-level MR. But that's a totally different discussion.
13:25:35 <Cale> yeah, I'll have to try that
13:25:51 <Taral> aha
13:26:06 <Taral> empty :: Set a doesn't work if Set is existential unless you add the constraint too.
13:26:17 <Cale> I dislike the MR altogether. I really don't think it should be in the language spec. Let compilers implement it if they have to.
13:26:23 <Taral> See, Haskell doesn't allow any implied context right now, and RDT pretty much mandates implied context.
13:26:25 <kosmikus> what do you mean: "Set is existential"?
13:26:45 <Taral> kosmikus: data Set a = forall a. Eq a => Set [a]
13:27:03 <Taral> It carries the necessary type dictionary with it.
13:27:28 <kosmikus> ah, bad name in this case. because in current Haskell semantics, that just changes the type of the constructor "Set".
13:27:31 <Taral> this solves the RDT problem for all except "constructor" functions like empty and singleton.
13:28:12 <Taral> kosmikus: But it also states that (Set a -> exists a. Eq a), so it is existential, no?
13:28:24 <Taral> er, oops
13:28:27 <kosmikus> furthermore, your definition doesn't make sense, or at least I don't get it.
13:28:31 <kosmikus> Set a = forall a ... ?
13:28:52 <kosmikus> either you bind "a" inside, or you have an argument of "Set" ...
13:28:56 <Taral> http://www.haskell.org/ghc/docs/latest/html/users_guide/type-extensions.html#existential-quantification
13:29:07 <kosmikus> I know existential types.
13:29:31 <Taral> I'm trying to use that to capture the type dictionary
13:29:38 <Taral> perhaps the forall is not required?
13:29:41 <kosmikus> I was confused by your "Set a = forall a. Eq a =>" shadowing of "a"
13:29:56 <Taral> so data Set a = Eq a => Set a?
13:29:59 <Taral> so data Set a = Eq a => Set [a]?
13:30:25 <Taral> Or this is not supported. :(
13:31:41 <kosmikus> you can do "data Set a where { Set :: forall a. (Eq a) => [a] -> Set a }" in GADT syntax. That's the closest you can get, but I think it's somewhat unspecified how it behaves.
13:32:01 <Taral> ah, good
13:32:26 <Taral> anyway, something like that is pretty much required for RDT in a dictionary-passing system
13:32:50 <Taral> now jhc can do RDT without blinking, because it uses type lambda instead of dictionaries.
13:33:16 <cathper> uhm, started reading my haskell book and one exercise is to create a 'blowup :: String -> String' such that ['a', 'b', 'c', etc.] becomes ['a', 'b', 'b', 'c', 'c', 'c', etc.]. I have a solution, but it's definitely not even nearly elegant. Can you give me a short neat solution?
13:34:34 <Cale> > let blowup xs = concat (zipWith replicate [1..] xs)
13:34:34 <lambdabot>  parse error on input `}'
13:34:40 <Cale> > let blowup xs = concat (zipWith replicate [1..] xs) in blowup "abc"
13:34:41 <lambdabot> "abbccc"
13:34:53 <xerox> whoa.
13:35:00 <Taral> *snicker*
13:35:06 <Taral> I was thinking of using something clever with fold and zip
13:35:12 <Taral> try to get interleave
13:35:48 <Taral> blowup = concat . zipWith replicate [1..]
13:35:56 <Taral> MR evil!
13:36:12 <cathper> err, I can read and understand the code, but I think I'm supposed to do it with just ++ and simple recursion ... :-)
13:36:29 <Taral> ha
13:36:45 <Taral> that makes it much bigger
13:36:51 <Cale> simple recursion has a tendency to be inelegant :)
13:36:57 <cathper> hehe
13:37:10 <Cale> however...
13:37:24 <cathper> I made a blowup_helper :: Integer -> String -> String and a repeat' :: Integer -> Char -> String ...
13:37:51 <Taral> repeat' = replicate
13:38:00 <cathper> oh, thanks
13:39:39 <Taral> in that case you're just expanding concat.zipWith
13:39:57 <Taral> (being loose with my dots here)
13:40:07 <Taral> and expanding zipWith is usually not pretty
13:40:31 <xerox> Howdy Pseudonym.
13:40:36 <Pseudonym> G'day.
13:40:43 <Cale> > let blowup' [] = []; blowup' (xs:xss) = xs : map (\(x:xs) -> (x:x:xs)) (blowup' xss); blowup xs = blowup' (map (:[]) xs) in blowup "abc"
13:40:44 <Pseudonym> FINALLY, someone has opened up a firewall port.
13:40:45 <lambdabot> ["a","bb","ccc"]
13:40:46 <Pseudonym> So here I am. :-)
13:41:16 <Taral> Cale: need a concat there :)
13:41:16 <Cale> > let blowup' [] = []; blowup' (xs:xss) = xs : map (\(x:xs) -> (x:x:xs)) (blowup' xss); blowup xs = concat (blowup' (map (:[]) xs)) in blowup "abc"
13:41:17 <lambdabot> "abbccc"
13:41:21 <Cale> yes
13:41:25 <shapr> g'day Pseudonym 
13:41:29 <Pseudonym> G'day.
13:41:34 <shapr> How's nano?
13:41:34 <Cale> that's reasonably elegant
13:41:35 * Pseudonym went to a talk by Phil Wadler last week
13:41:41 <shapr> cool!
13:41:50 <Pseudonym> As cool as nanotech is, Phil Wadler seminars are cooler.
13:42:03 <Cale> cathper: what do you think of that version?
13:42:12 <cathper> Cale: reading ... :-)
13:42:49 <Cale> of course, that can be rewritten as a foldr
13:43:05 <Pseudonym> He was talking about the Curry-Howard isomorphism, and how this proves that lambda calculus is the programming language given to us by God.
13:43:14 <Pseudonym> Of course, he's an atheist, so he had to qualify that remark.
13:43:54 <Cale> > let blowup' = foldr (\xs xss -> xs : map (\(x:xs) -> (x:x:xs)) xss) []; blowup xs = concat (blowup' (map (:[]) xs)) in blowup "abc"
13:43:56 <lambdabot> "abbccc"
13:44:01 <shapr> Pseudonym: You could have irc'd over DNS...
13:44:09 <cathper> Cale: I see; It's quite elegant.
13:44:21 <Pseudonym> Not if your DNS servers are properly configured.
13:44:29 <Pseudonym> But thanks for the thought!
13:44:59 <d0c|h> hey
13:45:08 <d0c|h> wondering if anyone could help me in here
13:45:34 <d0c|h> i found a chatlog from this channel that was about my problem.. but still no solution
13:45:36 <Cale> d0c|h: If it's about Haskell, that's what the channel is for :)
13:45:51 <Cale> what's your problem?
13:45:54 <d0c|h> Fail: Error in array index
13:45:59 <Pseudonym> One of the cool things he noted is that the Curry-Howard equivalent of the law of the excluded middle is call/cc.
13:46:02 * Taral laughs.
13:46:10 <Pseudonym> Well, its type, anyway.
13:46:14 <d0c|h> and the -xc gives just GHC.Arr.CAF
13:46:19 <d0c|h> which isn't helpful
13:46:20 <Taral> Pseudonym: I thought call/cc was whatsit's law?
13:46:29 <d0c|h> is the Debug.Trace my only option?
13:46:34 <Taral> Peirce's law
13:47:02 <Cale> d0c|h: well, how heavily are you using arrays? :)
13:47:10 <Cale> d0c|h: are they 2D arrays?
13:47:19 <d0c|h> most of them
13:47:25 <Pseudonym> Hmmm.
13:47:26 <Cale> a common mistake is specifying the bounds incorrectly
13:47:40 <Cale> ((xmin, ymin), (xmax, ymax))
13:47:47 <Taral> Pseudonym: Now I think Peirce's law <-> excluded middle
13:47:53 <Pseudonym> That's possible, yes.
13:48:24 <Cale> *not* ((xmin, xmax), (ymin, ymax))
13:48:31 <d0c|h> probably.. but it's darn hard to figure out where.. because it doesn't occur too frequently
13:49:09 <Pseudonym> @type \a b -> a (\c _ -> b c) (\d -> b d)
13:49:14 <lambdabot> forall t t1 t2 t3.
13:49:16 <lambdabot> ((t1 -> t -> t2) -> (t1 -> t2) -> t3) -> (t1 -> t2) -> t3
13:50:52 <d0c|h> i guess i just have to debug it.. but actually there's another problem i can't figure out
13:51:06 <Cale> d0c|h: Debug.Trace might help. You might also paste the code somewhere, and we could look at it
13:51:38 <Taral> @djinn Eq (EM a) (((a -> b) -> a) -> a)
13:51:38 <lambdabot> -- f cannot be realized.
13:51:40 <Taral> hm
13:51:57 <Taral> @djinn EM a -> (((a -> b) -> a) -> a)
13:51:58 <lambdabot> f a b =
13:51:58 <lambdabot>   case a of
13:51:58 <lambdabot>   Left c -> c
13:51:58 <lambdabot>   Right d -> b (\ e -> void (d e))
13:52:03 <Taral> @djinn (((a -> b) -> a) -> a) -> EM a
13:52:04 <lambdabot> -- f cannot be realized.
13:52:07 <Taral> ha, not equivalent
13:53:11 <d0c|h> i'm using mutable arrays.. is it possible that size of the array affects program performance? it seems to affect it so that profiling doesn't show where extra computing goes
13:53:32 <d0c|h> i'm using those arrays to cache some results.. more result i cache the better
13:53:39 <ihope> You know what?
13:53:54 <ihope> Haskell may well be a more-or-less perfect programming language.
13:54:05 <d0c|h> i'm talking about changing array size from 50000 500000 for example
13:54:13 <Cale> ihope: it's not perfect, but it's pretty good
13:54:17 <Pseudonym> Right.
13:54:17 <_Codex> ihope: far from perfect :)
13:54:34 <Pseudonym> It definitely comes closest to a certain sweet spot.
13:54:55 <Cale> The perfect programming language is mathematics, but that only runs on mathematicians.
13:54:56 <ihope> Yep. It comes closer to perfect than everything else.
13:55:02 <Pseudonym> If it was perfect, we could close down haskell-prime now.
13:55:08 <ihope> @help quote
13:55:09 <lambdabot>  @quote <nick>/@quote-add <nick> <quote>
13:55:09 <lambdabot> Quote somebody, or a random person, or save a memorable quote
13:55:34 <Pseudonym> I wouldn't call it close to perfect, though.  There are some things it does woefully.
13:55:41 <ihope> Like what?
13:55:45 <Pseudonym> Concurrency.
13:55:53 <Pseudonym> That's a matter of getting the right model, though.
13:56:02 <Pseudonym> I don't think that we've got there yet.
13:56:06 <ihope> ...Just what is concurrency?
13:56:31 <Pseudonym> @hoogle forkIO
13:56:31 <lambdabot> Control.Concurrent.forkIO :: IO () -> IO ThreadId
13:56:33 <Cale> ihope: multiple threads, usually running on the same processor
13:56:47 <Pseudonym> I dispute the "running on the same processor" part.
13:56:57 <Pseudonym> Actually, this is one of the things that Phil Wadler pointed out.
13:57:08 <Cale> parallelism is the 'running on different processors' part
13:57:09 <ihope> Multiple threads whose execution... thingy is undefined?
13:57:34 <Pseudonym> The only Curry-Howard-like logic that we DON'T have is one for is concurrency.
13:57:49 <Pseudonym> This suggests to me that the pi calculus was not given to us by God.
13:57:56 <Pseudonym> Unlike the lambda calculus.
13:57:57 <d0c|h> Cale, is it possible that accessing 50000 element array takes 10 times less time that accessing 500 000 element array?
13:58:28 <d0c|h> or am i stumbling accross the cost of just creating 500 000 element array?
13:58:39 <Cale> d0c|h: if the 500000 element array ends up causing you to swap memory out to disk, perhaps :)
13:58:48 <d0c|h> no.. memory is fine
13:58:51 <ihope> Pi calculus?
13:58:53 <Pseudonym> Haskell doesn't do mutable objects with identity very well, either.
13:58:54 <Cale> is the array boxed or unboxed?
13:58:58 <Taral> @djinn Not ((((a -> b) -> a) -> a) -> EM a)
13:58:59 <lambdabot> -- f cannot be realized.
13:59:05 <Pseudonym> Though that's nothing that a program redesign can't fix.
13:59:05 <Taral> @djinn Not (Not ((((a -> b) -> a) -> a) -> EM a))
13:59:06 <lambdabot> f a = void (a (\ _ -> Right (\ b -> a (\ _ -> Left b))))
13:59:18 <d0c|h> unboxed.. unfortunately
13:59:26 <Pseudonym> My main beef is the Haskell module system.  THAT is truly woeful.
13:59:30 <Cale> Mutable objects with identity are a design flaw in and of themselves :)
13:59:36 <ihope> @kind Not
13:59:37 <lambdabot> Not in scope: type constructor or class `Not'
13:59:38 <Pseudonym> No, I disagree with that.
13:59:51 <Pseudonym> Mutable objects with identity are tailor-made for writing Smalltalk-like GUIs.
13:59:52 <d0c|h> sry.. boxed still.. i guess
13:59:54 <Saulzar> d0c|h, Locality in memory also affects performance, cache misses and whatnot
14:00:07 <Pseudonym> That's OO's "killer app".
14:00:22 <Cale> d0c|h: so each is computed separately when it's accessed
14:00:24 <Saulzar> Pseudonym, In the way that the module system is not the ML module system or?
14:00:33 <d0c|h> ok.. but why isn't it showing in profiles?
14:00:41 <Pseudonym> The Haskell module system doesn't even support separate compilation.
14:00:53 <Pseudonym> That's the LEAST you'd expect of a module system, don't you think?
14:01:08 <Cale> It mostly does
14:01:18 <Taral> @djinn (Not (Not a) -> a) -> EM a
14:01:18 <lambdabot> -- f cannot be realized.
14:01:25 <Taral> @djinn EM a -> (Not (Not a) -> a)
14:01:25 <lambdabot> f a b =
14:01:25 <lambdabot>   case a of
14:01:25 <lambdabot>   Left c -> c
14:01:25 <lambdabot>   Right d -> void (b d)
14:01:26 <Pseudonym> "Mostly does" is a euphemism for "doesn't". :-)
14:01:31 <Cale> Separate compilation up to module interdependency is okay with me
14:01:37 <d0c|h> CAF calls don't shot in profile.. might it be the case?
14:01:39 <Pseudonym> It's not okay with me.
14:01:42 <d0c|h> *show*
14:01:45 <Cale> why?
14:01:46 <Pseudonym> And it's so easily fixed.
14:01:50 <Cale> who cares anyway?
14:01:57 <Taral> @djinn (Not (Not a) -> a) -> (((a -> b) -> a) -> a)
14:01:57 <lambdabot> f a b = a (\ c -> void (c (b (\ d -> void (c d)))))
14:02:01 <Pseudonym> Because it's important for Large Applications(tm).
14:02:04 <Taral> @djinn Eq (Not (Not a) -> a) (((a -> b) -> a) -> a)
14:02:04 <lambdabot> -- f cannot be realized.
14:02:07 <Taral> hm
14:02:17 <Pseudonym> Builds should be as parallelisable as possible.
14:02:29 <Taral> Pseudonym: So EM is strictly more powerful than call/cc
14:02:45 <Cale> Large applications will use a module design which is parallelisable.
14:02:54 <dcoutts> Pseudonym, I thought that if you supplied interface files then you do get seperate compilation
14:03:03 <Pseudonym> dcoutts: Yes, but that's not Haskell.
14:03:03 <Saulzar> Does it not depend more on the compiler than the language?
14:03:06 <dcoutts> even for mutually recursive modules
14:03:11 <Pseudonym> It's the related language of Haskell plus .hi-boot files.
14:03:27 <dcoutts> .hi-boot files are just Haskell type sigs.
14:03:27 <Taral> @djinn Eq (EM a) ((Not a -> a) -> a)
14:03:28 <lambdabot> -- f cannot be realized.
14:03:33 <Taral> @djinn (EM a) -> ((Not a -> a) -> a)
14:03:34 <lambdabot> f a b =
14:03:34 <lambdabot>   case a of
14:03:34 <lambdabot>   Left c -> c
14:03:34 <lambdabot>   Right d -> b d
14:03:37 <Pseudonym> .hi-boot files are not mentioned in the Haskell specification.
14:03:42 <Pseudonym> Ergo, they are not part of Haskell.
14:03:50 <Taral> @djinn ((Not a -> a) -> a)
14:03:51 <lambdabot> -- f cannot be realized.
14:03:58 <Pseudonym> If they're that important, you should be able to generate them automatically.
14:04:01 <Cale> What do .hi-boot files actually have in them? Is it plausible to have the compiler or another tool write them?
14:04:28 <Pseudonym> It's plausible to do that, IF you are willing to live with cross-module analysis.
14:04:32 <ihope> What's EM?
14:04:34 <Cale> I think this is more a compiler issue than a language spec issue.
14:04:43 <Pseudonym> No, it's a language spec issue.
14:04:46 <Cale> Pseudonym: sure, that seems fine
14:04:50 <Cale> why?
14:04:57 <d0c|h> Thanks for the time, Cale. Off to debug now ;)
14:04:58 <Pseudonym> The problem is that exported symbols don't have to have type declarations.
14:05:13 <Pseudonym> So type checking a module might require type checking modules in the import SCC at the same time.
14:05:14 <dcoutts> Pseudonym, I think originally they considered standardising the hand written .hi files but decided against for some reason.
14:05:31 <Cale> Pseudonym: that seems okay to me
14:05:35 <Pseudonym> I don't.
14:05:48 <Pseudonym> Requiring a SCC to be analysed at a time is not "separate compilation".
14:06:06 <Pseudonym> By any stretch of the term.
14:06:51 <dcoutts> Pseudonym, so you want seperate compilation to be mandated?
14:06:59 <Pseudonym> I want it to be possible.
14:07:25 <Pseudonym> The rule that I want is that it should be possible to generate a .hi file from the .hs file alone.
14:07:30 <dcoutts> and without writing any non-h98 code or using special build tols
14:07:49 <Cale> I think it's close enough to possible. You can design your app so that it does compile separately.
14:08:00 <Pseudonym> You can, and any good programmer does.
14:08:07 <Pseudonym> So why not make it mandatory?
14:08:10 <Cale> So what's the problem?
14:08:30 <dcoutts> you cuold build a .hi file generator that considered SCCs, then on normal builds that didn't change the interfaces you'd get ordinary per-module separate compilation
14:08:42 <Pseudonym> BTW, this is only one of my concerns about the module system, but it's the biggest.
14:08:43 <Cale> Because hardly anyone cares about separate compilation enough to put up with the restrictions it gives?
14:09:14 <dcoutts> or if you'd given types then it could do it without considering SCCs
14:09:15 <Cale> I don't care if anything I write compiles separately. I have a single processor machine.
14:09:16 <Pseudonym> Oh, don't ever say that in a crowd of C++ programmers.  They'd eat you alive.
14:09:25 <Pseudonym> I can see it now.
14:09:37 <Pseudonym> "Oh, Haskell... it's kinda pretty, but it's not _practical_."
14:09:44 <Cale> Separate compilation is a red herring.
14:09:50 <Pseudonym> No, I disagree.
14:09:55 <dcoutts> well, only somewhat
14:09:57 <Pseudonym> It's what makes some kinds of large build possible.
14:10:04 <Saulzar> What do you mean, C++ doesn't even come close especially these days with >50% of code ending up in header files
14:10:07 <Pseudonym> The bigger the program, the more important it is.
14:10:19 <dcoutts> jhc doesn't do too well on large mulit-module progs because it doesn't fit in memory even on a 1GB machine.
14:10:26 <Pseudonym> Saulzar: Not true!
14:10:34 <Pseudonym> I know why you say that, but it's not true.
14:10:47 <Cale> Why? Why do you think that programmers with a single-processor build environment should be forced to obey arbitrary restrictions to write their code such that modules can compile separately when they'll be compiled sequentially anyway?
14:10:56 <Pseudonym> Any sufficiently large C++ application relies on components more than templates.
14:11:01 <integral> ghc uses lots of memory 10k source file
14:11:16 <Pseudonym> Why is my suggested restriction arbitrary?
14:11:30 <Saulzar> Yeah, but it's heading more and more that way
14:11:48 <Philippa> separate compilation also matters if you've got a dynamic app architecture ala hs-plugins+yi
14:11:51 <dcoutts> Pseudonym, but requiring all top level things to have types would be a pain, especially for beginners.
14:11:57 <Cale> I really really don't care about separate compilation. I can see that for some applications and in some environments, it's a good property, but let those people write their code in a restricted fashion so as to get those benefits.
14:12:03 <Pseudonym> Not all top-level things.  Just exported things.
14:12:05 <Saulzar> I would rather have fully mutually recursive modules than seperate compilation
14:12:10 <dcoutts> since beginners start by not knowing what a module is and so everything is exported
14:12:16 <Pseudonym> Saulzar: I'd rather have both.
14:12:27 <dcoutts> because they don't add "module Foo (...) where "
14:12:29 <Cale> Pseudonym: which, unless you have an explicit export list, is everything
14:12:41 <dcoutts> or they don't specify an export list and so everything is exported
14:12:42 <Pseudonym> dcoutts: And that's my second complaint about the module system.
14:12:57 <dcoutts> Pseudonym, that it's easy for beginners?
14:12:58 <Cale> Pseudonym: you already have both - you can add the required type signatures.
14:13:27 <dcoutts> and that for full seperate compilation you have to have slightly more disipline
14:13:37 <Pseudonym> The export list design is wrong.
14:13:37 <Philippa> I'd simply require all exported things to be s.t. you can assign them types looking at the module and the types of things it imports only
14:13:38 <Cale> It's just that the language won't force you to, and I don't think it should.
14:14:08 <dcoutts> -fwarn-exports-without-type-sigs
14:14:09 <Saulzar> Pseudonym, Why? What would you rather have? Default nothing exported?
14:14:14 <Cale> Philippa: I'm not sure if I'd even want that.
14:14:32 <Pseudonym> Saulzar: I'd rather have the programmer say what's exported and what's not.
14:14:47 <Philippa> Cale: the alternative's having the types of things in the module dependant on things that import that module, no?
14:14:48 <Saulzar> What do you mean by that? They do already 
14:15:02 <Pseudonym> No they don't.  Not really.
14:15:10 <Cale> Why not just allow the programmer to specify the types if they want separate compilation, and compile things together if they don't?
14:15:10 <Pseudonym> You can't control whether or not a typeclass instance is exported.
14:15:14 <Philippa> I only do the first time it causes me a name clash usually
14:15:21 <Saulzar> Ah.
14:15:37 <Cale> A warning flag in the compiler could be enabled to note the potential for breaking separate compilation.
14:15:44 <Philippa> Cale: because all of a sudden the semantics of a module're implementation-specific
14:16:01 <Cale> what?
14:16:13 <Pseudonym> Well, they are now, in the sense that some modules in GHC don't make sense without .hi-boot files.
14:16:17 <Philippa> 'compiling things together'
14:16:31 <Philippa> Pseudonym: GHC in non-H98-compliance shocker ;-)
14:17:08 <Pseudonym> :-)
14:18:05 <Pseudonym> I don't know what a decent Haskell-like module system would look like, BTW.
14:18:08 <Philippa> if you really, really have to 'compile it together', stick it in the same damn module?
14:18:15 <Cale> I'd like to be able to take a program which is all in one file with arbitrary definitions, maybe lacking type signatures, split it into modules however I see fit with appropriate imports (maybe just import all other modules from every one of them) and still have it work.
14:18:22 <Pseudonym> I like Mercury's module system, which is based on Modula-like languages, I think.
14:18:29 <Pseudonym> Separate interface and implementation sections.
14:19:01 <Taral> Cale: That's whole-program processing.
14:19:02 <Saulzar> I'm not fussed by modules... quite happy to have a simple module system which doesn't get in the way and isn't some kind of funky meta-programming system
14:19:05 <Pseudonym> Cale: I'd argue that if your program is big enough that it needs to be split, it's big enough that it should have type signatures.
14:19:07 <Cale> Taral: sure
14:19:07 <Philippa> Cale: I don't think that's always reasonable. I also don't see having to find out some of the inferred types for the single-module version and annotate them if they're no longer clear when looking at modules as stand-alone entities as that big a burden
14:19:08 <Taral> On a per-file compilation system, that doesn't work.
14:19:13 <Taral> GHC is a per-file compliation system.
14:19:32 <Cale> Pseudonym: It might not always be a good idea, but it's a property that I'd like to preserve.
14:19:34 <Philippa> I'm finding myself doing things with a first-class-module flavour
14:19:51 <Philippa> but record<->module transformations cover all of those atm
14:19:56 <Cale> Taral: maybe it shouldn't be
14:20:15 <Philippa> Cale: it'd be preservable for a large variety of typable stuff
14:20:24 <Taral> If jhc had the memory management bits worked out, I might use it.
14:20:25 <Taral> it's wpa
14:20:37 <Philippa> in the cases where it's not, I don't think the individual modules actually make sense as 'modules' rather than namespaces...
14:20:58 <Pseudonym> Oh, one other small-if-controversial point.
14:21:11 <Philippa> and I *definitely* don't want to kill the possibility of dynamic apps without recompiling the entire app each time something's loaded
14:21:15 <Pseudonym> I'm willing to live with it, but I'm not 100% happy that module == file.
14:21:38 <Cale> Pseudonym: yeah, I'd like to be able to put multiple modules in a single file as well.
14:21:42 <Philippa> I'm willing to live with it in the current system, but I would like lexically scoped modules
14:21:48 <Pseudonym> If that restriction were lifted, Cale's problem could be trivially solved by splitting the file without splitting the module.
14:22:03 <Pseudonym> C programmers are used to this. :-)
14:22:09 <Cale> Pseudonym: oh, the other way -- how is that supposed to work?
14:22:14 <Cale> textual includes are ugly.
14:22:16 <Pseudonym> I don't know.
14:22:28 <Pseudonym> As I said, C programmers do it all the time.
14:22:34 <Pseudonym> A module is, more or less, a header file.
14:22:36 <Philippa> I tend to think it should be done by stripping the module into submodules anyway
14:22:47 <Pseudonym> And header files do not need to be in 1:1 correspondence with source files.
14:23:04 <Saulzar> Erg, header files
14:23:10 <Pseudonym> Yeah, I don't like it either.
14:23:22 <Pseudonym> I think there's a module system waiting to be invented which does it without header files.
14:23:32 <Saulzar> Maintinence, maintinence..
14:23:34 <Pseudonym> And without textual macro processing.
14:23:57 <Philippa> Pseudonym: one which also handles platform-case type stuff?
14:24:08 <Pseudonym> Presumably.
14:24:19 <tony2> can you rename stuff in imports anymore? (import ModuleA renaming (A to A_)
14:24:59 <Pseudonym> I say I'm willing to live with it, but that's mostly because I can't think of a clean way to do it any other way/
14:25:19 <Philippa> I find it mostly makes sense for me. If I want to split things up, I split them into submodules
14:25:32 <Philippa> a notion of 'private submodule' might be nice
14:25:37 <Pseudonym> Sure.
14:25:45 <dcoutts> Philippa, packages can give you that
14:26:02 <Philippa> packages're extra-linguistic atm though
14:26:22 <dcoutts> yeah, it's interesting that modules are not enough, that we aquire packages too
14:26:23 <Pseudonym> The main situation where I find myself wanting mode than one source file per module is when I need to pull out platform-specificisms.
14:26:31 <Philippa> they're beyond what I generally want to screw around with. And they don't seem to help much while I'm developing the package
14:26:35 <Pseudonym> And I couldn't be bothered making a lower-level hardware abstraction.
14:27:12 <Philippa> private Module.<platform>isms modules plus a reasonable form of platformcase'd do?
14:27:40 <Pseudonym> Probably, though again I don't know what a reasonable form of platformcase would look like.
14:28:34 <Philippa> some idiot'll suggest doing it with TH ;-)
14:28:52 <Pseudonym> :-)
14:29:17 <Philippa> which wouldn't be such a stupid idea, I guess
14:29:33 <Pseudonym> TH still looks very beta to me.
14:29:45 <Pseudonym> But that might just be me,.
14:29:47 <Philippa> import PlatformSpecificity; $(case platform of {Foo -> [|import ...|]})
14:29:51 <Philippa> same here
14:30:24 <tony2> I won't touch it (TH) because generally I require profiling.
14:30:24 <Philippa> 'sa shame, I see it and hs-plugins becoming really important parts of the haskell ecosystem in the long run
14:30:45 <Pseudonym> It's not the implementation.  I find the syntax clumsy.
14:30:57 <Philippa> AOL
14:31:04 * Pseudonym nods
14:31:17 <Philippa> it seems to be mostly a lack-of-sugar thing, but still
14:31:30 <Pseudonym> C++ templates, for all of their semantic ugliness, seem to really fit into the language in a deep way.
14:31:57 <Philippa> yeah. Much as I'm tempted to say "fuck the language hard" ;-)
14:32:15 <Pseudonym> If it wasn't for all of the horrible concessions that had to be made to C backwards compatibility, I'd even be tempted to call the C++ template syntax "nice".
14:32:22 <Pseudonym> Not "beautiful", but "nice".
14:32:47 <Pseudonym> (And, once again, NOT the semantic ugliness.)
14:32:53 <Philippa> I wouldn't go that far, but only because I'm resistant to typing. Not actively unpleasant beyond that though
14:33:04 <Saulzar> How can you say the syntax is nice? It generates the most hideously verbose code I've ever seen...
14:33:05 <Pseudonym> (Any time you say anything positive around C++ in here you have to qualify it!)
14:34:11 <Pseudonym> Template code itself tends to be verbose, but that's because it's highly configurable.
14:34:21 <Pseudonym> Code that USES templated code tends to be not very verbose at all.
14:34:32 <Pseudonym> Though the error messages in current compilers can be a bit horrible
14:35:18 <dcoutts> pair<int, int> foo = mk_pair<int,int>(1,2);
14:35:20 <Saulzar> Blargh, give me type parameterised types and type classes any day. I'm sick of templates
14:35:20 <Pseudonym> "Generative Programming" makes the point that you don't often write single programs these days.
14:35:36 <Pseudonym> dcoutts: typedef pair<int,int> intpair;
14:35:41 <Pseudonym> intpair foo(1, 2);
14:35:55 <Pseudonym> Or even:
14:36:03 <Pseudonym> pair<intint> foo(1,2);
14:36:03 <Philippa> sure, but it still sucks compared to (1,2) or Pair 1 2
14:36:06 <Pseudonym> pair<int,int> foo(1,2);
14:36:09 <Saulzar> Code which uses templates end up with typedef typename rubish everywhere
14:36:10 <Pseudonym> Well, yes.
14:36:18 <Pseudonym> But the problem here is that it doesn't use a Milner type system.
14:36:31 <Pseudonym> Haskell programmers don't like it when you have to declare the types of internal variables.
14:36:45 <dcoutts> indeed
14:36:48 <Philippa> -internal :-)
14:37:01 <Saulzar> Pseudonym, Thank god for that :)
14:37:09 <Philippa> I tend to type annotate afterwards unless I'm having trouble thinking things through
14:37:25 <Pseudonym> Philippa: Except we REALLY like declaring the types of exported symbols, DON'T WE!
14:37:43 <Pseudonym> ;-)
14:37:46 <Philippa> bah, somebody else can type :t and cut'n'paste lots :-)
14:38:01 <Pseudonym> Because otherwise we don't get separate compilation, do we.
14:38:05 <Philippa> I don't like it. I just know it needs doing once I need mutually recursive modules
14:38:24 <Philippa> often I'll still only declare the minimal set while I'm working 'internally'
14:38:58 <Saulzar> I use type signatures on everything because I usually get it wrong 9/10 times, and then I put more signatures on when I'm having trouble with internal types.
14:39:24 <Philippa> I do declare types and provide a fair amount of info to the typechecker through that, constructor use etc
14:39:54 <Philippa> I could use something to auto-generate annotations for me once code's got through the checker though
14:40:07 <Pseudonym> When I was marking Haskell programs, I could always tell which students copied-and-pasted inferred type signatures.
14:40:19 <Philippa> because they stank? :-)
14:40:26 <Saulzar> Heh, because some of them used a2-> b1 -> d3 ?
14:40:27 <Pseudonym> That too. :-)
14:40:30 <Philippa> (and... yeah, sucks, doesn't it?)
14:40:48 <Philippa> I do tend to give the type variables in datatype declarations meaningful names
14:41:05 <Pseudonym> There were two giveaways: 1) Type synonyms were expanded, 2) Declarations were more polymorphic than intended.
14:41:24 <Pseudonym> getIdField :: (a, b, c) -> a
14:41:26 <Pseudonym> As opposed to:
14:41:31 <Pseudonym> getIdField :: Record -> Id
14:42:19 <Saulzar> I guess they required type signatures for marks?
14:42:31 <Philippa> that's what you get for using tuples instead of named datatypes
14:42:37 <Pseudonym> Well, that's true.
14:43:03 <Philippa> I do it occasionally, I'd probably do so a lot less given an appropriate flavour of lightweight record
14:43:11 <Saulzar> Or even... using a record instead of type Record =  ..  :)
14:43:36 <Pseudonym> I would never teach H98 records to first-semester students.
14:43:57 <Pseudonym> For the same reason why I'd never teach first-semester students C.
14:44:01 <Cale> why? It only takes about 20 seconds
14:44:10 <Philippa> Saulzar: nah. A record (IMO) would include the field names, and if it's not declared with a data statement those names're part of its type
14:44:19 <Cale> There's nothing to the current record system
14:44:21 <Pseudonym> It'd fill their head with Haskell-specific syntax instead of computer science.
14:44:21 <Saulzar> Why not? I just about never use non records for the simple reason they can be used exactly the same way except one gives you selectors...
14:44:26 <Philippa> I'd rather know about H98 records than not if I'm working in it
14:44:44 <Philippa> it's a good opportunity to cover ideas like 'room for expansion' (records have it, constructors don't)
14:44:47 <Pseudonym> I was thinking more of the record update syntax.
14:45:06 <Philippa> fair enough, that's "just sugar"
14:45:10 * Pseudonym nods
14:45:11 <Philippa> 'look it up'
14:45:34 <Pseudonym> Using tuples or tradition algebraic data types makes it more obvious what's going on.
14:45:40 <Pseudonym> Less error-prone if you're new to the language
14:45:58 * Saulzar wishes he'd learned Haskell as a "first semester student"
14:46:07 <Philippa> I learnt it in the second semester here
14:46:13 <Philippa> mind you, I was never the average CS student
14:46:19 <Pseudonym> So do I, but there weren't decent Haskell implementations at the time.
14:46:19 * vincenz learned it three wekends ago
14:46:27 <Pseudonym> We had to learn Orwell instead.
14:46:46 <Pseudonym> Only in second semester did we upgrade to Miranda.
14:47:16 <Pseudonym> Orwell is, without any dramatic irony at all, a fairly oppressive language.
14:47:47 <Saulzar> Haha, what does that mean? :)
14:48:03 <Pseudonym> Pattern matching in Orwell was fully parallel, not top-to-bottom.
14:48:07 <Pseudonym> Here's an example:
14:48:10 <Saulzar> We learned Java, Java is all that matters
14:48:27 <Pseudonym> merge [] ys = ys
14:48:30 <Pseudonym> merge xs [] = xs
14:48:42 <Pseudonym> merge (x:xs) (y:ys) = ...
14:48:47 <Pseudonym> We'd be happy to write that in Haskell.
14:49:06 <Pseudonym> But you can't in Orwell, because merge [] [] would match two left hand sides.
14:49:15 <Pseudonym> And it couldn't decide which one to pick, so that's an error.
14:49:29 <Pseudonym> Instead, you'd have to write something like this:
14:49:34 <Pseudonym> merge [] ys = ys
14:49:36 <Pseudonym> %else
14:49:38 <Pseudonym> merge xs [] = xs
14:49:44 <Pseudonym> merge (x:xs) (y:ys) = ...
14:49:48 <Saulzar> Lovely :)
14:49:58 <Pseudonym> This is okay because the second two definitions don't overlap.
14:50:33 <Pseudonym> Pretty infuritating.
14:50:38 <Pseudonym> infuriating
14:51:38 <Pseudonym> Orwell was one of those languages which was made because Miranda was proprietary.
14:52:14 <dcoutts> whatever happened to the company that started Miranda?
14:52:24 <Pseudonym> No clue.
14:52:38 <Mitar> is there a "match ... with" construct in Haskell?
14:52:45 <dcoutts> Mitar, case ... of
14:52:58 <Mitar> thanks
14:53:02 <Pseudonym> David Turner isn't at Kent any more.
14:54:14 <Pseudonym> Oh, according to his bio at his new university, one of his research interests is: "open systems and the free software movement".
14:54:18 <Pseudonym> I guess he saw the light.
14:54:59 <glauber_sp> guys, sort in math means class?
14:55:20 <gzl> glauber_sp: what?
14:55:23 <Pseudonym> IIRC, "sort" in mathematics means "type".
14:55:37 <Pseudonym> But I have a suspicion that "sort" is an overloaded term.
14:55:43 <gzl> what's the context?
14:55:49 <Philippa> in pure type systems, 'term', 'type' and 'kind' are sorts
14:56:00 <Pseudonym> I interpreted it in the sense of "many-sorted algebra".
14:56:25 <gzl> ah. I haven't heard that term.
14:56:38 <glauber_sp> a set of sorts
14:56:57 <glauber_sp> Pseudonym, yes, it's about algebra
14:57:14 <glauber_sp> a signature is a set of sorts with some operations defined over them
14:57:15 <Saulzar> a sort of type...
14:57:25 <Saulzar> a type of sorts 
14:57:57 <heya> is there a way to check if a list contains of only empty lists?
14:58:21 <Pseudonym> all null xs
14:58:22 <glauber_sp> I need to translate sorts to pt_BR. and I don't remember how =/ eheh
14:58:31 <Pseudonym> @eval all null [[],[]]
14:58:32 <lambdabot> True
14:58:34 <Pseudonym> @eval all null [[],[1]]
14:58:35 <lambdabot> False
14:59:06 <heya> thanks
14:59:26 <Pseudonym> You'll often find statements of the form: A determinist finite automaton is a quintuple (K, Sigma, delta, s, F) where...
14:59:34 <Pseudonym> That's a many-sorted algebra.
14:59:45 <Pseudonym> Each "sort" would be a type if you were implementing DFAs in Haskell.
14:59:52 <Pseudonym> Kind of.
15:00:03 <Pseudonym> It'd be a field in a record or something.
15:00:48 <Pseudonym> So I guess Philippa is right.  It could be a term, could be a type and could be a kind.
15:01:02 <glauber_sp> Pseudonym, hum, ok. I got the meaning. thanks you both =)
15:16:52 <vincenz> How do I easily build a lexer in haskell?
15:17:49 <shapr> alex?
15:17:59 <vincenz> @where alex
15:18:00 <lambdabot> http://www.haskell.org/alex/
15:18:04 <vincenz> thx
15:25:32 <ihope> What about lex? :-P
15:25:56 <ihope> > iterate (fst . lex) "2 + 2 = 5"
15:25:57 <lambdabot> Couldn't match `(a, b)' against `[(String, String)]'
15:26:08 <ihope> > iterate (fst . head . lex) "2 + 2 = 5"
15:26:09 <lambdabot> ["2 + 2 = 5","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","
15:26:09 <lambdabot> 2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2"
15:26:09 <lambdabot> ,"2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","
15:26:09 <lambdabot> 2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2"
15:26:09 <lambdabot> ,"2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","2","
15:26:11 <lambdabot> [23 @more lines]
15:26:16 <ihope> That's not good.
15:26:21 <ihope> > iterate (snd . head . lex) "2 + 2 = 5"
15:26:22 <lambdabot> ["2 + 2 = 5"," + 2 = 5"," 2 = 5"," = 5"," 5","","","","","","","","","",""
15:26:22 <lambdabot> ,"","","","","","","","","","","","","","","","","","","","","","","","","
15:26:22 <lambdabot> ","","","","","","","","","","","","","","","","","","","","","","","","",
15:26:22 <lambdabot> "","","","","","","","","","","","","","","","","","","","","","","","",""
15:26:22 <lambdabot> ,"","","","","","","","","","","","","","","","","","","","","","","","","
15:26:24 <lambdabot> [23 @more lines]
15:26:47 <vincenz> ihope: can I use lex in the context of haskell?
15:26:56 <vincenz> I have to say, the doc of alex is...lacking
15:27:10 <ihope> I dunno just how lex works, really.
15:27:35 * vincenz is trying to port a lex file to alex
15:27:59 <TuringTest> > lex "I am 2 + 2"
15:28:00 <lambdabot> [("I"," am 2 + 2")]
15:28:18 <TuringTest> It pulls of the first token
15:28:22 <vincenz> o.O
15:28:27 <vincenz> TuringTest: obviously you'r lacking context
15:28:27 <dcoutts> vincenz, still parsing C?
15:28:30 <vincenz> dcoutts: c++
15:28:31 <ihope> > (fst . head . lex . take while (/= "") . iterate (snd . head . lex)) "2 + 2 = 5"
15:28:32 <lambdabot>  Not in scope: `while'
15:28:36 <dcoutts> vincenz, ah
15:28:37 <vincenz> dcoutts: I found a lec and yacc file, and I'm trying to port to alex and happy
15:28:38 <ihope> > (fst . head . lex . takeWhile (/= "") . iterate (snd . head . lex)) "2 + 2 = 5"
15:28:39 <lambdabot> Couldn't match `Char' against `[Char]'
15:28:44 <ihope> Meh.
15:28:50 <vincenz> dcoutts: but alex is not evident to use given the sparse docs
15:28:51 <ihope> > (map fst . map head . map lex . takeWhile (/= "") . iterate (snd . head . lex)) "2 + 2 = 5"
15:28:52 <lambdabot> ["2","+","2","=","5"]
15:28:57 <ihope> Yay!
15:29:12 <dcoutts> vincenz, I found that studying GHC's alex lexer was helpful.
15:29:19 <vincenz> dcoutts: where might I find this?
15:29:29 <ihope> This won't work:
15:29:30 <dcoutts> vincenz, in the ghc source :-)
15:29:35 <int80_h> hmmm
15:29:40 <vincenz> dcoutts: ah...cool
15:29:43 <ihope> > let readsPrec = lex in read "Hello, world!"
15:29:43 <lambdabot> Add a type signature
15:29:46 <vincenz> dcoutts: might I aske you for some assistance in porting the .l file to alex format?
15:30:03 <dcoutts> vincenz, not now, sorry. I'm busy with other stuff.
15:30:15 <vincenz> dcoutts: but specific questions
15:30:23 <dcoutts> vincenz, http://darcs.haskell.org/ghc/ghc/compiler/parser/Lexer.x
15:30:28 <vincenz> thx
15:35:57 <Mitar> how to get next char in ASCII from a char?
15:36:05 <Mitar> so from a to get b?
15:36:17 <vincenz> is there a vim hilight file for alex files?
15:36:27 <vincenz> > succ 'a'
15:36:28 <lambdabot> 'b'
15:36:35 <Mitar> thanks
15:37:40 <ihope> > succ 2
15:37:41 <lambdabot> 3
15:37:46 <ihope> @type succ
15:37:47 <lambdabot> forall a. (Enum a) => a -> a
15:38:54 <ihope> Say... if I have something of type Num a => a, how does show know how to show it?
15:39:08 <Taral> @type show
15:39:09 <lambdabot> forall a. (Show a) => a -> String
15:39:12 <Mitar> and how to check if it is before Z?
15:39:18 <Taral> You'll need something of type Show a => a
15:39:23 <Mitar> < 'Z'?
15:39:26 <int-e> > show 2
15:39:27 <lambdabot> "2"
15:39:31 <ihope> Taral: Num is a subclass of Show
15:39:34 <Taral> Mitar: Yes, but that's part of the Ord class.
15:39:36 <Taral> ihope: Ah.
15:39:39 <Taral> It is?
15:39:44 <ihope> Yep.
15:39:46 <ihope> And Eq.
15:39:52 <int-e> ihope: by using some defaulting rule I suppose
15:40:17 <ihope> Classes are confusing. /me checks the Report
15:40:32 <Taral> hm, that's illy
15:40:34 <Taral> er, silly
15:40:36 <mauke> class  (Eq a, Show a) => Num a  where
15:40:55 <vincenz> dcoutts: the tokens :- can be any name?
15:41:26 <dcoutts> vincenz, not sure what you mean
15:41:36 <vincenz> dcoutts: well in alex you have regexp definitions
15:41:42 <vincenz> then tokens :- for the lex rules
15:41:51 <vincenz> the file you gave me a linke to uses "haskell :-"
15:41:52 <ihope> Well, I suppose every Num a => a is a call of fromInteger.
15:41:54 <vincenz> iso tokens :-
15:42:26 <Mitar> how can i catch an exception from head if the list is emtpy?
15:42:38 <mauke> you can't
15:42:43 <Taral> Mitar: check the list first
15:43:02 <Taral> and while you're at it, do the head op in the same case statement
15:43:03 <vincenz> seems so
15:43:16 <Taral> case l of { [] -> ...; h:t -> ... }
15:43:23 <mauke> headM (x : xs) = x
15:43:29 <mauke> headM [] = fail "error"
15:43:37 <Taral> mauke: you need a return there
15:43:47 <Taral> catching exceptions is rarely the right answer anyway
15:43:57 <mauke> d'oh, I even _thought_ return, I just failed to type it
15:45:58 <ihope> Okay.
15:45:59 * ihope tests
15:46:02 <Mitar> possiblem = ['A'..'Z'] \\ v
15:46:02 <Mitar> newm = if null possiblem then error "grammar too complex" else head possiblema
15:46:25 <int-e> ihope: the default declaration is described here: http://haskell.org/onlinereport/decls.html#sect4.3.4
15:46:48 <int-e> ihope: and it defaults to (Integer, Double) - so show 1 prints an Integer
15:46:59 <Mitar> is this OK?
15:47:56 <dcoutts> vincenz, http://haskell.org/alex/doc/html/alex-files.html
15:48:57 <dcoutts> vincenz, that "haskell" bit before the ":-" is described in the alex manual:
15:48:58 <dcoutts>  It doesn't matter what you use for the identifer, it is just there for documentation purposes. In fact, it can be omitted, but the :- must be left in.
15:50:03 <vincenz> dcoutts: yeah I found it
15:50:10 <vincenz> thx
15:51:02 <ihope> int-e: thanks
15:56:05 <vincenz> what's the most efficient way to take all the elements besides the last from a list?
15:56:10 <vincenz> (or more specifically string)
15:56:12 <vincenz> @hoogle dropL
15:56:13 <lambdabot> No matches found
15:56:14 <vincenz> @hoogle dropLast
15:56:15 <lambdabot> No matches found
15:56:25 <tromp_> init
15:56:30 <vincenz> @hoogle init
15:56:31 <lambdabot> Data.List.init :: [a] -> [a]
15:56:31 <lambdabot> Prelude.init :: [a] -> [a]
15:56:31 <lambdabot> Data.List.inits :: [a] -> [[a]]
15:56:38 <vincenz> >init "abc" 2
15:56:46 <vincenz> > init "abc" 
15:56:47 <lambdabot> "ab"
15:56:50 <vincenz> thx
15:58:09 <ihope> > init []
15:58:10 <lambdabot> Add a type signature
15:58:14 <ihope> Wow!
15:58:33 <ihope> > show []
15:58:34 <lambdabot> Add a type signature
15:58:38 <ihope> Um
15:58:42 <ihope> > show [] :: String
15:58:43 <lambdabot> Add a type signature
15:58:55 <tromp_> > show ([]::[Int])
15:58:56 <lambdabot> "[]"
15:59:02 <ihope> Ah.
15:59:33 <ihope> So where does a default declaration go?
16:00:39 <int-e> ihope: it's a toplevel declaration in a module, I think
16:02:13 <ihope> Does it even say which class it's for?
16:02:57 <ihope> @djinn Integer -> Int
16:02:58 <lambdabot> -- f cannot be realized.
16:03:46 <vincenz> dcoutts: so if I use alex and happy in conjunction, do I need to define the tokens in the happygrammar filie and then use thos efrom the alex-lexer?
16:04:11 <vincenz> @type const
16:04:12 <lambdabot> forall a b. a -> b -> a
16:06:16 <ihope> > compare 3 2
16:06:18 <lambdabot> GT
16:10:52 <Taral> @type fromIntegral :: Integer -> Int
16:10:53 <lambdabot> Integer -> Int :: Integer -> Int
16:11:34 <mauke> @type undefined :: eh
16:11:35 <lambdabot> eh :: forall eh. eh
16:11:49 <ihope> @type undefined :: forall
16:11:50 <lambdabot> parse error (possibly incorrect indentation)
16:11:58 <ihope> @type undefined :: Eh
16:11:59 <lambdabot> Not in scope: type constructor or class `Eh'
16:12:03 <ihope> @kind Void
16:12:04 <lambdabot> Not in scope: type constructor or class `Void'
16:12:07 <ihope> @index Void
16:12:08 <lambdabot> bzzt
16:12:11 <ihope> @hoogle Void
16:12:12 <lambdabot> Foreign.Marshal.Error.void :: IO a -> IO ()
16:12:14 <mauke> @kind ()
16:12:15 <lambdabot> *
16:23:32 <Taral> @type fromIntegral :: String
16:23:33 <lambdabot>   Expecting a function type, but found `[Char]'
16:23:33 <lambdabot>   Expected type: String
16:23:35 <Taral> oh, good
16:27:38 <vincenz> Taral: fromIntegral is not for strings but for moving to nonintegrals (like flating)
16:27:43 <vincenz> > show 2
16:27:44 <lambdabot> "2"
16:27:49 <vincenz> @type show
16:27:50 <lambdabot> forall a. (Show a) => a -> String
16:27:53 <vincenz> ;)
16:28:23 <Taral> vincenz: I know.
16:28:38 <Taral> I was making sure that @type actually tested type compatibility when given an annotation
16:28:47 <vincenz> ah k
16:34:58 <ihope> @type iterate
16:34:59 <lambdabot> forall a. (a -> a) -> a -> [a]
16:35:06 <ihope> @djinn (a -> a) -> a -> [a]
16:35:07 <lambdabot> -- f cannot be realized.
16:35:15 <ihope> So I suppose this won't work:
16:35:22 <ihope> @djinn (a -> a -> a) -> a -> a -> [a]
16:35:23 <lambdabot> -- f cannot be realized.
16:35:46 <ihope> Let's see...
16:36:59 <ihope> iterate2 f a b = a : b : zipWith f iterate2 (tail iterate2)
16:37:06 <ihope> Is that right?
16:37:26 <ihope> > let iterate2 f a b = a : b : zipWith f iterate2 (tail iterate2) in iterate2 (+) 1 1
16:37:27 <lambdabot> Couldn't match `[a]' against `(a -> b -> c) -> a1 -> c -> t'
16:37:43 <ihope> ...Oops!
16:38:16 <ihope> > let iterate2 f a b = a : b : zipWith f (iterate2 f a b) (tail (iterate2 f a b)) in iterate2 (+) 1 1
16:38:21 <lambdabot> Terminated
16:38:33 <ihope> That clearly didn't work.
16:39:43 <ihope> Okay. It *did* work; lambdabot just didn't get enough to show it.
16:40:52 <ihope> Hmm. Why's it so slow, though?
16:43:32 <ihope> @kind 1
16:43:33 <lambdabot> *
16:43:46 <ihope> @djinn 1 -> 1
16:43:46 <lambdabot> Cannot parse command
16:44:35 <ihope> @pl iterate2 f a b = a : b : zipWith f (iterate2 f a b) (tail (iterate2 f a b))
16:44:37 <lambdabot> iterate2 = fix (((liftM2 (.) (:) . (ap (:) .)) .) . ap (ap . (liftM2 ap .)
16:44:37 <lambdabot> . ap ((.) . (.) . zipWith)) (((tail .) .) .))
16:46:54 <int-e> @pl \(a,b) -> a:b:[]
16:46:55 <lambdabot> uncurry ((. return) . (:))
16:47:39 <ihope> pl is good at obfuscations.
16:49:09 <Taral> @type uncurry
16:49:10 <lambdabot> forall c b a. (a -> b -> c) -> (a, b) -> c
16:49:33 <Taral> @pl \(a,b) -> b:a:[]
16:49:34 <lambdabot> uncurry (flip (:) . return)
16:50:39 <Taral> @pl \(a,b) -> (b,a)
16:50:40 <lambdabot> uncurry (flip (,))
16:52:41 <ihope> @pl \a (b,c) -> a c b
16:52:42 <lambdabot> (`ap` snd) . (. fst) . flip
16:52:47 <ihope> Whoa!
16:58:17 <mauke> next time you don't know if you're running gcc, perl or a haskell compiler, try http://home.cs.tum.edu/~mai/poly.sh.pl.tcl.cpp.bf.py.c.lhs.txt !
16:59:18 <ihope> Whoa.
16:59:25 <palomer> Cale: you around?
16:59:35 <Igloo> Bah, get .hs in there and maybe I'll be impressed  :-)
16:59:40 <ihope> .bf? Um...
16:59:48 <ihope> Oh. Lexical ;-)
17:01:24 <mauke> Igloo: that's probably impossible :/
17:02:14 <vincenz> > toEnum 0 :: Char
17:02:22 <lambdabot> '\NUL'
17:02:28 <vincenz> > map toEnum [0..255] :: [Char]
17:02:30 <lambdabot> "\NUL\SOH\STX\ETX\EOT\ENQ\ACK\a\b\t\n\v\f\r\SO\SI\DLE\DC1\DC2\DC3\DC4\NAK\
17:02:32 <lambdabot> SYN\ETB\CAN\EM\SUB\ESC\FS\GS\RS\US !\"#$%&'()*+,-./0123456789:;<=>?@
17:02:34 <lambdabot> ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\DEL\128\
17:02:36 <lambdabot> 129\130\131\132\133\134\135\136\137\138\139\140\141\142\143\144\145\146\
17:02:38 <lambdabot> 147\148\149\150\151\152\153\154\155\156\157\158\159\160\161\162\163\164\
17:02:40 <lambdabot> [6 @more lines]
17:02:58 <palomer> @hoogle toEnum
17:02:59 <lambdabot> Prelude.toEnum :: Enum a => Int -> a
17:03:26 <ihope> I propose that the word "wednesday" be pronounced as spelled. The day of the week would be "wendsday".
17:03:26 * palomer pokes cale
17:03:28 <vincenz> > fromEnum '\NUL'
17:03:29 <lambdabot> 0
17:03:42 <ihope> @type fromEnum '\NUL'
17:03:43 <lambdabot> Int
17:04:14 <palomer> I've always spelled wednesday as wendnesday
17:05:40 <TuringTest> WWOD ?
17:06:35 <ihope> Hoe murk thyme...
17:06:49 <Mitar> is there a way to get this into one line:
17:06:50 <Mitar> p' = foldl substitute [] p
17:06:50 <Mitar> (v',p'') = foldl leftrec (v,[]) p'
17:06:50 <Mitar> p''' = foldr (flip substitute) [] p''
17:07:07 <TuringTest> hmmm
17:07:30 <TuringTest> p to p' to p'' to p'''
17:07:34 <Mitar> ok, first two are not problem
17:07:45 <TuringTest> The answer is yes
17:07:50 <Mitar> how?
17:07:53 <mauke> foldr (flip substitute) [] (snd (foldl leftrec (v, []) (foldl substitute [] p)))
17:08:27 <Mitar> but i lost v' this way?
17:08:31 <TuringTest> p''' = ( foldr (flip substitute) [] ) . snd . (foldl leftrec (v,[])  ) . ( foldl substitute []  ) $ p
17:08:50 <TuringTest> Mitar: a bit lost
17:09:06 <Mitar> i need p''' and v' at the end
17:09:22 <TuringTest> (v',p''') = (\(f,s) -> (f, ( foldr (flip substitute) [] ) s) .  (foldl leftrec (v,[])  ) . ( foldl substitute []  ) $ p
17:09:33 <vincenz> CxxLexer.x:149:9: Not in scope: `alexScanTokens'
17:09:49 <TuringTest> Untested, of course.  But that is what a typechecker can help with
17:09:55 <Mitar> :-)
17:10:03 <Mitar> ok, i will probably leave ti this way then
17:10:09 <TuringTest> :)
17:10:25 <TuringTest> Yeah...do NOT put that code where anyone else will need to read it
17:10:35 <TuringTest> Not even the shootout code looks like that
17:10:42 <Mitar> like what?
17:10:47 <Mitar> like my first code
17:10:51 <Mitar> or the second ...
17:10:51 <TuringTest> the second
17:10:55 <Mitar> aha
17:11:07 <Mitar> so it is normal to have such p''''... variables?
17:11:38 <TuringTest> Well... it is better to have intelligible names, but everyone uses x x' x''
17:11:46 <Mitar> ok
17:11:49 <Mitar> :-)
17:11:53 <Mitar> it is eaasiest
17:12:07 <TuringTest> Though Monads are a good way to thread such a value through code
17:12:26 <Mitar> but i would like to have it clean functional
17:13:18 <TuringTest> The unclean Monad is IO.   Other monads are function outside the runMonadName function
17:13:19 <Cale> palomer: hi
17:13:33 <TuringTest> funciton -> functional
17:14:45 <vincenz> anyone using alex?
17:15:07 <palomer> Cale: I have a hard problem:o
17:15:23 * vincenz uses alex, and seems to get a lot of not in scopes for alex functions and types
17:15:24 <SyntaxNinja> I think you should give up after 2 '' 
17:15:43 <SyntaxNinja> vincenz: I used alex a while back.
17:16:01 <vincenz> ah, it seems I needed to ad "wrapper"
17:16:09 <SyntaxNinja> btw, simonmar says that if he had written it, it would be calld "Lexstatic" which would be funny (since the yacc-thing is happy)
17:18:48 <vincenz> hehe
17:19:11 <TuringTest> Oh...by way of the shootout we have a new front runner for "Weakest GHC 6.4.1 Library" : Text.Regex
17:19:58 <SyntaxNinja> weak in what sense?
17:20:14 <TuringTest> It runs almost exactly 100 times too slow due to marshalling.
17:20:25 <TuringTest> That is not a typo.
17:20:36 <Cale> parsec runs circles around it
17:20:44 * TuringTest nods
17:21:09 <vincenz> crud
17:21:34 <dons> TuringTest, I've written a new entry using lazy regexes, it runs faster than perl... :)
17:21:47 <TuringTest> dons: I do not believe you
17:22:04 <dons> I had a dream about it at2am this morning 
17:22:35 <TuringTest> I rescind that. OCaml #2 is beating perl
17:22:38 <dons> give me a few mnutes to benchmark and post it.
17:23:51 <TuringTest> dons: My parsec parser for regex strings is even better than the wiki -- I added {n} {n,m} {n}? {n,m}? modifiers.
17:24:25 <TuringTest> dons: It can act as a front end for your lazy processor
17:25:19 <SyntaxNinja> dons!
17:25:41 <TuringTest> Cale: Yeah, I wrote an all-parsec version for the http://haskell.org/hawiki/RegexDna entry, and it is okay, but not the fastest.
17:26:37 <TuringTest> Cale: It uses Parsec to parse a regex into a tree and then turns that into a GenParser
17:28:14 <TuringTest> Hmmm... I should go to sleep, but dons has the snappy entry that he is posting.   Must stay awake.
17:29:04 <dons> TuringTest, it runs in 6s (so what 5x faster ?)
17:29:20 <TuringTest> That smokes.
17:30:10 <TuringTest> How much of the regex spec can it handle at the moment?
17:32:04 <palomer> Cale: ok back
17:33:36 <dons> oh, just * + | [] and ()  (but that's enough) 
17:33:41 <palomer> Cale: do you remember the order we talked about yesterday?
17:34:03 <dons> they're combinators, you just combine them with normal haskell functions (replicate, for example)
17:34:40 <dons> hey SyntaxNinja
17:34:43 <Cale> palomer: yeah
17:35:09 <palomer> Cale: well, let me explain where they pop up
17:35:34 <palomer> Cale: if you have a set of type equality constraints, you can get a unifier
17:36:11 <palomer> Cale: the set of maximally general unifiers of a set of constraints forms an equivalence class
17:36:16 <palomer> under my equality
17:36:25 * TuringTest reconnects
17:36:29 <palomer> (the equivalence relation induced by the order)
17:36:41 <palomer> Cale: do you follow me?
17:36:47 <Cale> I think so
17:37:04 <palomer> Cale: so these equivalence classes of unifiers forms a lattice
17:37:32 <palomer> Cale: the top element is the unsound unifier, the bottom element is the identity unifier
17:37:49 <Cale> okay
17:38:12 <palomer> Cale: the lub of two equivalence classes represents the union of the constraints
17:38:21 <palomer> Cale: I'm trying to figure out what the glb is
17:38:52 <palomer> Cale: got any clues?
17:39:04 <Cale> let me think about it :)
17:39:34 <palomer> Cale: though I'm pretty sure that the lub of two equivalence classes is the union of the constraints, I haven't proved it
17:39:37 <palomer> more formally:
17:39:51 <palomer> let phi be the function which maps sets of constraints to equivalence classes of unifiers
17:40:07 <palomer> phi(e U e') = lub (phi e, phi e')
17:40:18 <SyntaxNinja> gotta go
17:41:07 <Cale> Well, let's write the definition out and see if anything useful appears...
17:41:53 <palomer> certainly phi( e intersection e') is not glb (phi e, phi e')
17:42:47 <palomer> Cale: maybe we should take this to #math?
17:42:48 <Cale> The glb, z of two unifiers x and y is a unifier which is less than or equal to both x and y, and if any unifier w is also less than or equal to both x and y, then w is less than or equal to z.
17:43:16 <palomer> sure
17:43:25 <Cale> The relation was such that finer partitions were lower?
17:43:32 <palomer> yes
17:43:42 <palomer> it's called the "information order"
17:43:48 <Cale> So it's the coarsest partition which is a refinement of both x and y
17:43:49 <palomer> the higher you go, the more information you have
17:44:10 <palomer> refinement?
17:44:14 <palomer> oh,righto
17:44:43 <Cale> Just like in Riemann integration :)
17:45:31 <Cale> I'm not entirely sure how to express that in terms of the equations.
17:45:48 <Cale> You have only equality relations?
17:45:48 <palomer> well, at least a way to compute it
17:46:05 <Cale> oh, that's easy if you're working with the partitions
17:46:05 <palomer> Cale: yup
17:46:24 <palomer> ok, what is it?
17:47:19 <vincenz> anyone ever used happy
17:48:03 <Cale> Basically, for each point, you'd find the largest set of points which are equivalent to it under both x and y, and make that an equivalence class of the GLB.
17:48:24 <palomer> what's a point?
17:49:02 <Cale> Your partitions are partitioning points.
17:49:37 <palomer> ok, sure
17:49:45 <Cale> I suppose it's a type variable before unification
17:50:03 <palomer> this sounds like anti-unification
17:50:17 <Cale> yeah, probably could call it something like that
17:50:46 <palomer> the glb of {int->int,bool->int} is {a->int} ?
17:50:56 <palomer> the glb of {int->int} and {bool->int} is {a->int} ?
17:51:23 <Cale> that seems plausible
17:52:30 <palomer> err, that doesn't make any sense
17:53:42 <palomer> those aren't even type equalities
17:54:36 <palomer> Cale: and what would negation be?
17:55:52 <dons> TuringTest, entry posted, now i'll benchmark the others that are new.
17:56:02 * TuringTest goes to look
17:56:36 <dons> well, almost posted. just waiting on the net connection to finish uploading...
17:56:43 <dons> flakey wifi
17:57:06 <TuringTest> dons: I see it
17:57:11 <dons> a corrected version is on its way... there was a bug in that one.
17:57:19 <dons> (it prints out the lines in the wrong order)
17:57:47 <dons> the key is that it does a sinngle pass in the count-matches phase
17:57:55 <TuringTest> dons: clearly.
17:58:31 <TuringTest> dons: Now we just need to use regex for cleaning header/newline and converting Iubs
17:58:37 <dons> ok, the fixed version is up.
17:58:51 <dons> yep, and I already have a version of that. i'll post it ..
17:59:11 <dons> the single-pass count matches shows the expressive power of combinator-based approaches, I think.
17:59:29 <dons>  we didnn't have to modify the regex library (unlike, say perl)
17:59:45 * TuringTest is compiling
18:01:14 <TuringTest> dons: compile flags?
18:02:04 <TuringTest> dons: It ran in 16 seconds.  My other code runs in 34 seconds.  Well done.
18:02:13 <dons> -O2 should be all.
18:02:46 <dons> code that appears in dreams should not be discounted :)
18:03:38 <TuringTest> I have not read the code itself yet...I must go dream first.  It seems you delete my code block that connected by front end regex parser to your back end lexer.
18:04:13 <dons> oh, i didn't look at that till today.
18:04:39 <TuringTest> Wow...my fingers keep missing
18:04:46 <dons> i don't know. i think it should be legal to construct the regexes "natively" and not via ".*foo.*" strings.
18:04:49 <palomer> missing whom?
18:05:13 <dons> so: string "xyz" +> char \n' `star` epsilon, should be legal.
18:05:14 <TuringTest> It connected my front end to the combinators in your code.
18:05:45 <dons> anyway, as I say, i didn't delete it -- i didn't know about it  :)
18:06:12 <dons> or did I really delete some code off the wiki? is that what you mean?
18:08:16 <TuringTest> On the wiki
18:08:20 <TuringTest> I just resurrected it.
18:08:45 <dons> oh. sorry! my fingers must have played games.
18:09:08 <TuringTest> Can you see section 4.1 of the page?
18:09:20 <TuringTest> Called "Front End"
18:10:16 <TuringTest> dons: I did not see a quick way to encode [^baz] atoms or . wildcard atoms.
18:11:02 <TuringTest> dons: Is the matching always greedy?
18:11:14 <dons> you specify an alt [0..255] \\ "baz". just normal list stuff.
18:11:39 <dons> most of the higher level regex ops are done using lists, maps, folds etc, and parens.
18:11:52 <dons> I think it is always greedy, check the comment on greediness
18:12:01 <dons> i can't remember the details.
18:12:44 <TuringTest> It says " we implement the "principle of the longest match" "
18:12:55 <TuringTest> So it seems to be always greedy.
18:13:45 <dons> hmm. what's up with the wiki? did we lose all the bottom? no hsc2hs entry? :/ hmm...
18:13:53 <dons> it got munged somehow.
18:13:54 <TuringTest> The "fast..G4" entry works differently and it handles both greedy and non-greedy modifiers.
18:14:07 <TuringTest> dons: I though you *wanted* to clean it up.  Ooops
18:14:23 <dons> shrug. not important I guess.
18:14:36 <dons> we only care about the fast ones in the end.
18:14:46 <dons> and its either going to be parsec or lazy regexes.
18:15:20 <TuringTest> dons:  Well, not the "all parsec" entry -- it is too slow
18:15:21 <dons> so it''s ok to leave it as is.
18:15:26 <TuringTest> I agree
18:15:26 <dons> ok.
18:15:56 <dons> ok, i timed your 'fastest-on-g4 entry'. it clocks in at 19.6s on x86.
18:16:16 <dons> i'll add that. then make the lazy regex entry 100% legal
18:16:19 <TuringTest> Hmmm...that is why I called it G4, since it likes my machine better
18:17:20 <TuringTest> dons: That is mainly why I wanted to be able to parse standard regular expressions on the front end.  So it would be more acceptable for the shootout.
18:17:50 <TuringTest> dons: I have read "man re_format" too many times now.  I fear that I may dream about it.
18:17:52 <dons> yeah. but I think itis a philosophical thing. we should be able to submit combinator-based regexes.
18:18:31 <TuringTest> dons: Go ahead and try.  I don't want to waste lines of code on my front end if they will take it without it.
18:18:38 <dons> it doesn't even say: must implement all of regex(3). so basic *, +, ?, etc should be legal, imo.
18:18:58 <TuringTest> And [abc] of course.  (and maybe [^abc])
18:19:17 <dons> well, [abc] is supported via `alt`
18:19:37 <dons> and [^abc] == alt $  [0..255] \\ [ac]
18:19:52 <dons> \\ [abc], of course.
18:20:02 <TuringTest> ...and toEnum
18:20:17 <TuringTest> oh..fromInteger
18:20:49 <TuringTest> err..nope
18:21:08 <dons> maybe you can change the title of "Fastest entry (on g4)" to something?
18:21:15 <TuringTest> right-o
18:21:17 <dons> I mean ['\0'.. '\255']
18:21:25 <dons> but i'm lazy :)
18:22:58 * TuringTest has changed the headings
18:26:18 <TuringTest> dons: The `meta` is interesting...
18:26:58 <dons> yeah, it's really powerful, being able to thread arbitrary state around
18:27:19 <dons> see my paper on Yi, section 5, iirc, talks all about this.
18:33:57 * TuringTest waves goodnight
19:40:43 <SamK> hi, i can understand why its bad for a function to modify global state, that another function might depend upon (side effect).. but can anyone explain the reason why its necessary for a function to always return the same value given the same inputs?
19:41:43 <mauke> how do you return different values without modifying global state?
19:42:26 <araujo> Hello.
19:42:45 <palomer>  SamK: well, say you've computed (head f), where f is a list, this is only computed once
19:42:57 <palomer> SamK: so if this value changes, you're screwed
19:43:24 <SyntaxNinja> ha!
19:43:30 <palomer> or something like that
19:44:00 <palomer> and that's why communism didn't work
19:44:23 <Pseudonym> Ah, I always wondered that.
19:44:31 <SamK> I guess I was wondering whats so bad about say, reading the "system time", and using it in some calculation, then returning the result
19:44:31 <Pseudonym> Communism didn't work because it broke referential transparency.
19:44:43 <araujo> hah
19:44:46 <mauke> reading the system time modifies global state
19:45:06 <mauke> also it doesn't "work" with lazy evaluation
19:45:27 <Pseudonym> It's not obvious what "reading the system time" means when it may not be evaluated straight away.
19:45:37 <mauke> or evaluated more than once
19:45:40 <Pseudonym> Right.
19:45:59 <Pseudonym> What you're missing, SamK, is that doing something like that requires a notion of "sequence".
19:46:17 <Pseudonym> What you want to do is read the system time, THEN do something, then read the system time again.
19:46:35 <palomer> lazy + not referential transparent = weird stuff happening
19:46:39 <skew> "they system time" isn' a value
19:46:53 <SamK> I see, so if you had two call to that function that read the time, you may get two answers based on an arbitrary execution order?
19:47:01 <Pseudonym> Right.
19:47:04 <mauke> there are no calls
19:47:07 <SyntaxNinja> hm. I want to get help from freenode, but the /stats p command doesn't work on my client, and I can't talk on the #freenode channel. so... what's a guy to do?
19:47:10 <palomer> there is no spoon
19:47:19 <mauke> functions are applied, not called
19:47:25 <SamK> right, yeah
19:47:25 <Pseudonym> If you want to do that, you have to do it in such a way that the sequence is enforced.
19:47:43 <skew> mauke: or maybe just composed, depending how you want to think of values
19:47:44 <palomer> I'll go as far as to say that there are no functions, really, just equations
19:48:16 <mauke> main = const (putStrLn "hello") (putStrLn "world")
19:49:27 <SamK> "called" = my filthy imperatism training ;)
19:50:14 <SamK> think I get it now, cheers
19:51:27 * palomer needs to start to use quickcheck more extensively
19:51:33 <palomer> it means I have to get knee deep into monads, though
19:51:53 <skew> you are testing monadic code?
19:52:08 <skew> quickcheck doesn't use monads very deeply for testing functional code
19:52:30 <mauke> SamK: do you get fibs = 0 : 1 : zipWith (+) fibs (tail fibs)? :-)
19:54:43 <palomer> I remember the very first time I tried haskell, I was put off by the @ operator
19:54:47 <SamK> not got much experience with zipWith, but yeah, fibonacci sequence
19:56:24 <SamK> >fibs = 0 : 1 : zipWith (+) fibs (tail fibs)
19:56:32 <SamK> bah
19:56:36 <palomer> put a space
19:56:40 <SamK> > fibs = 0 : 1 : zipWith (+) fibs (tail fibs)
19:56:40 <lambdabot>  parse error on input `='
19:56:57 <skew> then duck
19:57:10 <mauke> > let fibs = 0 : 1 : zipWith (+) fibs (tail fibs) in fibs  -- to turn it into an expression
19:57:11 <lambdabot> [0,1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,
19:57:11 <lambdabot> 10946,17711,28657,46368,75025,121393,196418,317811,514229,832040,1346269,
19:57:11 <lambdabot> 2178309,3524578,5702887,9227465,14930352,24157817,39088169,63245986,
19:57:11 <lambdabot> 102334155,165580141,267914296,433494437,701408733,1134903170,1836311903,
19:57:11 <lambdabot> 2971215073,4807526976,7778742049,12586269025,20365011074,32951280099,
19:57:13 <lambdabot> [23 @more lines]
19:57:19 <skew> you want "let fibs = ..."
19:57:24 <palomer> SamK: only one liners can be interpreted
19:57:47 <SamK> does lambdabot abort infinite list answers? ;)
19:57:57 <palomer> @more lines
19:57:58 <lambdabot> 53316291173,86267571272,139583862445,225851433717,365435296162,591286729879
19:57:58 <lambdabot> ,956722026041,1548008755920,2504730781961,4052739537881,6557470319842,
19:57:58 <lambdabot> 10610209857723,17167680177565,27777890035288,44945570212853,72723460248141,
19:57:58 <lambdabot> 117669030460994,190392490709135,308061521170129,498454011879264,80651553304
19:57:58 <lambdabot> 9393,1304969544928657,2111485077978050,3416454622906707,5527939700884757,
19:58:00 <lambdabot> [18 @more lines]
19:58:08 <palomer> SamK: of course
19:58:10 <SamK> > let fibs = 0 : 1 : zipWith (+) fibs (tail fibs)
19:58:11 <lambdabot>  parse error on input `}'
19:58:30 <SamK> > let fibs = 0 : 1 : zipWith (+) fibs (tail fibs) in fibs
19:58:31 <lambdabot> [0,1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,
19:58:31 <lambdabot> 10946,17711,28657,46368,75025,121393,196418,317811,514229,832040,1346269,
19:58:31 <lambdabot> 2178309,3524578,5702887,9227465,14930352,24157817,39088169,63245986,
19:58:31 <lambdabot> 102334155,165580141,267914296,433494437,701408733,1134903170,1836311903,
19:58:31 <lambdabot> 2971215073,4807526976,7778742049,12586269025,20365011074,32951280099,
19:58:33 <lambdabot> [23 @more lines]
19:58:35 <SamK> gotya
19:59:09 <palomer> why doesn't ghci accept top level bindings?
19:59:25 * palomer has always wondered
19:59:48 <skew> I think it was slightly tricky to implement
20:01:02 <skew> I think you could hack up a full toplevel with ghc-api, maybe with some trickiness for mutual recursion
20:01:20 * skew adds the idea to his montone increasing todo file
20:01:36 <dibblego> am I right that Monads exist to replicate the notion of state without requiring the notion of identity in a functional language?
20:01:40 <palomer> monotonically
20:01:46 <skew> dibblego: not exactly
20:01:47 <dons> Prelude> let x = 7
20:01:47 <dons> Prelude> x
20:01:59 <dibblego> skew: am I close? (I am guessing after reading for 2 minutes)
20:02:12 <palomer> identity?
20:02:38 <skew> dibblego: they are more general
20:02:38 <dibblego> yes, identity is the fundamental definition of an OO language
20:02:57 <dibblego> this is my guess
20:03:03 <palomer> object identity?
20:03:03 <dibblego> you may have an operation setX
20:03:05 <skew> palomer: you know, the thing that you use as an index into the store?
20:03:07 <palomer> .equals()?
20:03:16 <dibblego> and you can observe a side-effect of it through another operation called getX()
20:03:25 <palomer> skew: memory location?
20:03:26 <dibblego> but since this requires the notion of identity, Monads exist
20:03:46 <dibblego> so you invoke the setX operation, and you are returned some contract through which the getX operation can be invoked
20:03:48 <skew> palomer: have you ever seen a store-passing translation of state?
20:04:10 <dibblego> I should probably read more
20:04:13 <skew> dibblego: monads cover a bit more than state, and it's not so much about identity
20:04:14 <palomer> skew: yes
20:04:15 <dibblego> I just haven't used Haskell before
20:04:34 <skew> True and False are the same as themselves and different from each other
20:04:46 <SyntaxNinja> dibblego: OOI, if you've never used Haskell before, why are you looking at monads?
20:04:54 <dibblego> I didn't expect identity to have anything to do with monads
20:04:58 <skew> SyntaxNinja: because they are awesome?
20:05:09 <palomer> I don't find monads that awesome
20:05:13 <palomer> they fit awkwardly into the language
20:05:20 <dibblego> SyntaxNinja: because I am writing my own language, and I like to understand how other languages have solved similar problems to what I am solving
20:05:31 <skew> palomer: maybe I just like math
20:05:57 <SyntaxNinja> dibblego: good reason :)
20:06:12 <palomer> dibblego: will your language have lazy evaluation?
20:06:20 <SyntaxNinja> skew: they are indeed, and yet I find that many newcommers stumble over them right away for no apparent reason, and get turned off from the language.
20:06:20 <skew> dibblego: anyway, monads are more about reconcilling referential transparency with state (and other stuff), rather than lack of identity
20:06:32 <dibblego> palomer: I don't understand what you mean by that
20:06:40 <palomer> > and []
20:06:42 <lambdabot> True
20:06:42 <skew> SyntaxNinja: with any luck they will eventually get some good press too
20:07:00 <palomer> dibblego: will things only be evaluated when they are needed?
20:07:00 <dibblego> palomer: syntax means nothing so far - we are solving a major problem with existing languages
20:07:13 <skew> palomer: I don't know what that's supposed to demonstrate
20:07:23 <dibblego> palomer: I can only guess what you mean by that - in which case, the answer is no
20:07:44 <mauke> > const 42 (1 / 0)
20:07:45 <lambdabot> 42
20:07:58 <palomer> I don't see why any language  without lazy evaluation would want monads
20:08:09 <mauke> because they're awesome
20:08:18 <dibblego> palomer: can you please expand on what you mean by lazy evaluation?
20:08:36 <mauke> see above, the 1/0 is not evaluated because it's not needed
20:08:37 <SyntaxNinja> dons: I msg'd you ;)
20:08:39 <dibblego> evaluation of what exactly?
20:08:39 <skew> palomer: well, you can express any monad with continuations and mutable state, if you want to
20:08:42 <palomer> dibblego: const is a function which takes 2 argumetnts and returns the first
20:08:44 <Pseudonym> Why wouldn't a strict pure language want monads?
20:09:00 <palomer> skew: yes, but language wise they are ugly
20:09:06 <dibblego> oh right - we haven't even bothered to look at that yet
20:09:09 <palomer> I think we should have 2 levels of syntax, one monadic and one pure
20:09:25 <skew> palomer: isn't that what do is about?
20:10:07 <skew> dibblego: so, referential transparency means you can always replace a thing with it's definition
20:10:48 <skew> saying p.getX() at two different times and getting two different values out means that p.getX() isn't referentially transparent
20:11:01 <dibblego> ok gotchya
20:11:30 <skew> referential transparency is nice mostly for being able to think about a program and prove stuff about it easily
20:12:15 <skew> one thing that monads do is build back up explicit sequencing in a language that
20:12:23 <skew> that is mostly referentially transparent
20:13:05 <palomer> yes! I've hunted the last bug
20:13:05 <skew> and then because there is this order, "p.getX() earlier in the chain" is different from "p.getX() later in the chain"
20:13:07 <palomer> w00t
20:13:14 <palomer> skew: do only takes it so far
20:13:17 <palomer> we need to take it further
20:13:20 <palomer> longer
20:13:20 <palomer> better!
20:13:37 <skew> which is about how things are all the time in a language like e.g. Java
20:14:01 <dibblego> skew: what do you mean it is like Java? what is exactly?
20:14:17 <dibblego> you mean that p.getX() may or may not return the same thing consistently?
20:14:28 <skew> if it's sequenced into a monad
20:14:44 <dibblego> so a monad allows you to somehow formally express that?
20:15:43 <skew> > do v <- newIORef 0; x <- readIORef v; writeIORef v 1; y <- readIORef v; print (x,y)
20:15:44 <lambdabot>  Not in scope: `readIORef'
20:15:47 <skew> aww
20:15:55 <SamK> mmm.. whats wrong with: take 5 integers where integers x = 0:(integers x+1)
20:16:24 <skew> SamK: integers is a function from a number to a list, not a list
20:16:37 <SamK> ah right
20:16:39 <dibblego> skew: I'm very unfamiliar with that syntax
20:16:54 <skew> dibblego: sort of, it's more like it lets you do that only where you want to
20:17:04 <dibblego> skew: ok cool - makes sense
20:17:09 <skew> It would have printed (0,1) if lambdabot loaded the right modules
20:17:32 <palomer> just use ST
20:17:56 <dibblego> ok, I have some thinking to do - thanks
20:17:58 <skew> it's something like v = 0; x = v; v = 1; y = v; print x,y in Python
20:18:00 <palomer> change IO for ST and party like it's 1942
20:18:05 <skew> ok
20:18:25 <skew> anyway, it's nice to be able to write with stuff like IO sometimes
20:18:42 <skew> but other times, it's nice to know that using f 1 here and f 1 there will give the same answer
20:19:30 <skew> that's one motivation for having a pure language with monads
20:22:43 <palomer> @hoogle all
20:22:43 <lambdabot> Data.List.all :: (a -> Bool) -> [a] -> Bool
20:22:43 <lambdabot> Prelude.all :: (a -> Bool) -> [a] -> Bool
20:22:43 <lambdabot> Foreign.Marshal.Alloc.alloca :: Storable a => (Ptr a -> IO b) -> IO
20:22:43 <lambdabot> b
20:23:22 <palomer> @hoogle Eq a => a -> Bool
20:23:23 <lambdabot> Test.QuickCheck.Batch.isBottom :: a -> Bool
20:23:23 <lambdabot> Control.Concurrent.rtsSupportsBoundThreads :: Bool
20:23:23 <lambdabot> Data.Bool.False :: Bool
20:24:39 <palomer> oh lordy
20:26:17 <skew> ok, I guess it's not a general solution to the Halting Problem
20:27:04 * palomer inserts error all over his code for error checking
20:27:36 <palomer> is it possible to get ghc to detect infinite loops?
20:27:51 <skew> sometimes
20:27:59 <skew> only if a value directly depends on itself, I think
20:27:59 <SamK> > (integers 0) where integers x = x:(integers x+1)
20:28:00 <lambdabot>  add an instance declaration for (Num [a])
20:28:00 <lambdabot>   In the definition of `sfk':
20:28:00 <lambdabot>    sfk = (integers 0)
20:28:19 <SamK> hrm
20:28:26 <skew> that's parsed as (integers x) + 1 inside the parens
20:28:47 <SamK> > (integers 0) where integers x = x:((integers x)+1)
20:28:47 <lambdabot>  add an instance declaration for (Num [a])
20:28:47 <lambdabot>   In the definition of `njm':
20:28:47 <lambdabot>    njm = (integers 0)
20:29:14 <skew> you probably wanted integers (x + 1)
20:29:22 <SamK> whoops ;)
20:29:33 <SamK> > (integers 0) where integers x = x:(integers (x+1))
20:29:34 <lambdabot> [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,
20:29:34 <lambdabot> 27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,
20:29:34 <lambdabot> 51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,
20:29:34 <lambdabot> 75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,
20:29:34 <lambdabot> 99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,
20:29:36 <lambdabot> [24 @more lines]
20:29:41 <SamK> aha
20:30:24 <SamK> how can I "take 5" of them?
20:30:45 <skew> if them is (integers 0), take 5 them
20:30:57 <skew> referential transparency, you know
20:30:58 <palomer> is it possible to find the location of infinite loops with a profiler?
20:31:12 <SamK> > take 5 (integers 0) where integers x = x:(integers x+1)
20:31:12 <lambdabot>  add an instance declaration for (Num [a])
20:31:36 <SamK> > take 5 (integers 0) where integers x = x:(integers (x+1))
20:31:37 <lambdabot> [0,1,2,3,4]
20:31:40 <SamK> cool
20:32:01 <palomer> > take 42 [1..]
20:32:03 <lambdabot> [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,
20:32:03 <lambdabot> 28,29,30,31,32,33,34,35,36,37,38,39,40,41,42]
20:32:16 <palomer> > take 42 [1..(-1)]
20:32:17 <lambdabot> []
20:33:10 <SamK> suprised [1..(-1)] didnt give an error, I noticed some prelude function give errors on -ve numbers
20:34:07 <SamK> > reverse take 20 (integers 0) where integers x = x:(integers (x+1))
20:34:08 <lambdabot>   The function `reverse' is applied to three arguments,
20:34:08 <lambdabot>   but its type `[a] -> [a]' has only one
20:34:08 <lambdabot>   In the definition of `ekj':
20:34:13 <Lemmih> > [1,0.. -1]
20:34:14 <lambdabot> [1,0,-1]
20:34:16 <skew> the parens there are sometimes important
20:34:23 <SamK> > reverse (take 20 (integers 0) where integers x = x:(integers (x+1)))
20:34:24 <lambdabot>  parse error on input `where'
20:34:36 <skew> otherwise, it might look like you are trying to subtract 1 from a function if you use -1
20:35:02 <palomer> hrmph
20:35:11 <palomer> compiling with -prof just doesn't work
20:35:18 <palomer> Could not find module `Control.Monad.State':
20:35:30 <palomer> ghc -fno-monomorphism-restriction --make -o silly types.hs ReaderStateT  lambda2.hs monadsupply.hs stype.hs constraints.hs infer.hs unifier.hs parse.hs solvehorns.hs main.hs -prof
20:35:51 <Lemmih> palomer: You probably don't have the profiling libraries.
20:36:43 <palomer> oh my, have to install from source again
20:36:45 <palomer> :O!
20:37:38 <Lemmih> Or just 'apt-get install ghc-prof'
20:37:55 <palomer> no can do
20:37:59 <palomer> it requires ghc 6.2
20:39:16 <skew> which?
20:39:42 <Lemmih> Really? ghc-prof in unstable is for ghc-6.4.1
20:39:47 <skew> there's certainly a ghc-prof for 6.2, and the Haskell-unsafe repository had packages for 6.4
21:02:20 <palomer> checking again
21:02:47 <palomer> oh, righto
21:02:51 <palomer> it's because of ghc-hat
21:03:30 <palomer> why isn't ghc-hat in the haskell-unsafe repository?
21:08:20 <palomer> how do you profile for the functions which are the biggest time hogs?
21:08:49 <palomer> (I'm trying to find an infinite loop)
21:09:23 <dons> interrupt the program, and the infinite loop should be on top of the call stack (usually)
21:10:05 <palomer> how do I check for this?
21:10:21 <palomer> like, how do I interrupt and check the call stack?
21:11:14 <dons> ^c, compile the program with -prof -auto-all, run it with +RTS -p, check foo.prof afterwards.
21:13:44 <palomer> I'm using hp2ps
21:13:56 <palomer> and the ps file doesn't have any information on the call stack
21:14:38 <palomer> oh, just check the .prof file
21:14:56 <palomer>  CAF                     Main                                                 238           4 100.0  100.0   100.0  100.0
21:15:01 <palomer> the rest are all 0
21:15:28 <palomer> I'm pretty sure it's not my main though
21:15:40 <palomer> my main is like 4 lines
21:15:42 <palomer> nothing recursive
21:15:52 <dons> did you compile with -prof -auto-all ? 
21:16:33 <palomer> yup
21:21:04 <palomer> then again, I don't think what it gives me is the call stack
21:30:00 <dons> @seen musasabi
21:30:01 <lambdabot> musasabi is in #haskell-blah and #haskell. Last spoke 13 hours, 42
21:30:01 <lambdabot> minutes and 35 seconds ago.
21:32:46 <palomer> hrm
21:32:54 <palomer> when should one do the occurs check when unifying?
21:33:20 <Pseudonym> Yes, when unifying.
21:33:26 <Pseudonym> That's the customary time.
21:33:28 <Pseudonym> :-)
21:34:12 <palomer> but, exactly when?
21:34:24 <Pseudonym> Basically, when you unify a variable with a term, first check to see if the variable is in the term.
21:34:52 <Pseudonym> When you unify a variable with a variable, if they are the same you can just throw the constraint away.
21:35:21 <Pseudonym> And unifying a term with a term results in sub-unifications which fall under one of these cases.
21:36:21 <palomer> oh, righto
21:36:43 <palomer> that was my blunder
21:36:50 <palomer> whew, I think my unifying library is finished
21:36:52 <palomer> tough stuff
21:36:58 <Pseudonym> Cool.
21:37:26 <palomer> oh, it's extra cool
21:38:55 <skew> what are you unifying?
21:39:27 <Pseudonym> And why aren't you allowing regular tree unification, hmmm?
21:40:05 <palomer> oh, type equalities
21:40:10 <palomer> tyes, rather
21:40:15 <palomer> s/tyes/types
21:40:22 <palomer> Pseudonym: what's regular tree unification?
21:42:43 <Pseudonym> That's where you don't bother with the occurs check.
21:43:05 <Pseudonym> The term "trees" in that case can contain cycles.
21:43:23 <Pseudonym> So if it's types... makes sense.
21:45:01 <palomer> oh, righto
21:45:04 <palomer> infinite types
21:45:07 <palomer> and what are they good for?
21:45:12 <palomer> wait...trees don't have cycles!
21:45:15 <Pseudonym> Infinite types are useless.
21:45:24 <Pseudonym> But infinite terms in general might be useful.
21:45:34 <Pseudonym> OK, not completely useless.
21:45:46 <Pseudonym> data List a = Nil | Cons a (List a)
21:46:04 <palomer> that's an infinite type?
21:46:07 <Pseudonym> With infinite types you wouldn't have to give that a name.
21:46:11 <Pseudonym> You could say this instead:
21:46:17 <Pseudonym> type List a = Either () (a, List a)
21:46:39 <Pseudonym> As it is, you need at least newtype.
21:46:57 <palomer> how could you replace List with an infinite type?
21:47:12 <Pseudonym> type List a = Either () (a, List a)
21:47:15 <Pseudonym> Like that.
21:47:23 <skew> Either () (a, Either () (a, Either () a, ...
21:47:48 <Pseudonym> Unfortunately, allowing this also makes a lot of obviously incorrect programs correct.
21:48:04 <palomer> for example?
21:48:56 <skew> map f (x:xs) = f xs: map f xs
21:49:16 <Pseudonym> Well that's not obviously wrong.
21:50:14 <skew> I guess filter works better
21:50:22 <skew> that's like some compositon of map and tails
21:50:37 <skew> filter p (x:xs) = if p x then xs:filter p xs else filter p xs
21:51:04 <skew> hmm, that doesn't quite unify a and [a] either, does it?
21:52:15 <Pseudonym> Trying to find the canonical example.
21:55:51 <Pseudonym> Hmmm.  Can't find it here.
21:56:28 <palomer> don't you guys hate it when you make your program work, and then you screw it up again?
21:56:50 <palomer> =me likes the fact that <= looks like an arrow
21:57:10 <dons> darcs revert 
21:57:37 <palomer> I don't use source control
21:57:47 <palomer> I mean, I just got the hand of using a makefile
21:57:54 <palomer> (that's after 4 years of CS)
21:58:29 <dons> ah well, darcs record ; darcs revert aren't that hard to learn :)
21:58:54 <palomer> If I'm going to use source control, I want to use a remote server
21:59:02 <palomer> sadly, I have none
21:59:14 <joelk> bah. Anyone know of an example of using strictToLazyST? I just get " Couldn't match `ST s a' against `Control.Monad.ST.Lazy.ST s a'", but, isn't that the point?
22:07:57 <joelk> ah, the ImperativeHaskell wiki page ha a section on that. My guess to the answer was confirmed...
22:19:59 <Pseudonym> Gotta go.  Nytol!
22:24:40 <joelk> hmm... got strictToLazyST working as desired, but it sure seems like there should be a more aesthetically pleasing way to do it.
22:25:13 <palomer> is there a function for partial ordering?
22:25:34 <palomer> or does sortBy work with partial orders?
22:26:23 <palomer> oh, shucks, my order is monadic
22:29:14 <joelk> not monastic?
22:34:42 <gour> @hIDE
22:34:43 <lambdabot> Unknown command, try @listcommands.
22:34:47 <gour> @where hIDE
22:34:49 <lambdabot> http://haskell.org/haskellwiki/HIDE
22:48:57 <aleator> Anyone have decent queue-set implementation they'd like to share?
22:49:32 <dibblego> I wrote one of those in Java just two days ago
22:49:40 <dibblego> it was for someone's homework
22:51:34 <aleator> Well.. That doesn't help much, since that I'm trying to be too lazy to write one so I'll be too lazy to port it :)
22:51:56 <dibblego> I've never used Haskell so I wouldn't have a clue how to write it
22:52:08 <dibblego> I'd need to start at the beginning
22:52:22 <dibblego> on that note, where is "Haskell for noobs" document?
22:52:41 <Korollary> there are so many. Check the wiki.
22:53:17 <dibblego> when there are so many, the problem is the potential for misleading - I am too naive to know better
22:53:44 <dibblego> monkeys are dominant
22:53:50 <dibblego> I'll figure it out anyway
22:54:08 <Korollary> You can start with Yet Another Haskell Tutorial. If you had previous FP experience, even the Gentle Introduction would do.
22:54:16 <dibblego> ok thanks
22:54:25 <dibblego> you're referring to http://www.haskell.org/hawiki/ right?
22:54:29 <Korollary> Yes
22:57:01 <dons> or is it on haskell.org/haskellwiki/ now ?
22:57:30 <Korollary> That looks new.
22:58:59 <dons> I'm so happy, I finally got to use 'interact' in a shootout entry :)
22:59:18 <Korollary> ahah
22:59:37 <dons> interact is a bit like unfoldr (though not as obscure). it's misunderstood, or forgotten. like scanl too.
22:59:49 <Korollary> I usually forget about it heh
23:00:38 <dons> yeah, I'd written: getContents >>= putStr . f , before I slapped myself for being silly
23:01:01 <dons> @karma+ interact
23:01:01 <lambdabot> interact's karma raised to 1.
23:01:14 <Korollary> @karma foldl
23:01:15 <lambdabot> foldl has a karma of 0
23:01:40 <dons> @karma unfoldr
23:01:41 <lambdabot> unfoldr has a karma of 2
23:02:02 <Saulzar> Seems something fairly specific to be in a standard library
23:02:18 <dons> what's that?
23:02:25 <Korollary> so is putStr heh
23:02:55 <dons> `interact' is nice old skool, since you can use it to wrap pure programs., and forget about monads all together.
23:03:39 <vincenz> anyone here a happy fan?
23:03:46 <Saulzar> Ah, it does it lazily. Was trying to figure out what it did in ghci.
23:03:52 <vincenz> err....expert
23:06:29 <vincenz> @hoogle interact
23:06:30 <lambdabot> Prelude.interact :: (String -> String) -> IO ()
23:06:30 <lambdabot> System.IO.interact :: (String -> String) -> IO ()
23:06:30 <lambdabot> System.Process.runInteractiveCommand :: String -> IO (Handle, Handle,
23:06:30 <lambdabot> Handle, ProcessHandle)
23:13:17 <gour> @where hs-plugins
23:13:18 <lambdabot> http://www.cse.unsw.edu.au/~dons/hs-plugins/
23:15:12 <gour> @where yi
23:15:13 <lambdabot> http://www.cse.unsw.edu.au/~dons/yi.html
23:16:06 <ncalexan> gour: there's also a gtk branch of yi; look for the yi wiki for the url.
23:16:18 <ncalexan> (It's close to the hide repo, IIRC.)
23:16:59 * shapr boings
23:17:10 * Korollary deboings shapr
23:17:44 <gour> ncalexan: thanks. i'm just preaching about hIDE technology :-)
23:18:53 <gour> @where hIDE
23:18:54 <lambdabot> http://haskell.org/haskellwiki/HIDE
23:21:08 <vincenz> shapr: I'm now a haskell-convert :)
23:29:05 * gour considers shapr saved another soul. long live shapr!
23:29:35 <ncalexan> Is there a standard priority queue implementation?
23:32:25 <xerox> @docs Data.Queue
23:32:26 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Data-Queue.
23:32:26 <lambdabot> html
23:32:27 <xerox> Maybe.
23:33:22 <Cale> Data.Set
23:33:23 <ncalexan> Urgh, should have seen that one.
23:33:41 <ncalexan> Cale: really?
23:33:44 <ncalexan> @docs Data.Set
23:33:44 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/base/Data-Set.html
23:33:45 <Cale> deleteFindMin
23:34:19 <Cale> er, hmm
23:34:30 <Cale> I suppose that requires a total order, doesn't it?
23:34:38 <Cale> might be annoying
23:34:47 <ncalexan> Well, it'll work, and it's full featured.  (In this case, total order is probably... oh wait, I see.)
23:35:08 <ncalexan> You do get O(log n) for both insert and deleteMin, which is sub-optimal.
23:35:22 <Cale> that's also true
23:35:40 <ncalexan> This should really be in the standard libs.
23:35:41 <Cale> hang on
23:35:48 <ncalexan> Data.Queue is not a priority queue.
23:35:52 <Cale> right
23:36:23 <Cale> http://www.dtek.chalmers.se/~sylvan/PriorityQueue/
23:36:26 <Cale> there you go
23:36:53 <Cale> Thank GMail for being so nicely searchable :)
23:37:11 <ncalexan> Cheers.  I saw that one, but I was wondering if there was an implementation blessed by the community :)
23:38:27 <Cale> nothing official afaik
23:38:27 <ncalexan> g'night, all.
23:39:08 <ncalexan> I wonder why there's no standard impl in the Data hierarchy?  Anyway, not tonight's issue.  Cioa.
23:50:44 <pierre-> hello
23:51:20 <pierre-> i'm trying to write a simple win32 app, and i've got big problem...
23:51:41 <pierre-> where can i get HINSTANCE? 
23:57:18 <Korollary> It seems it is in System.Win32.Types
23:58:29 <pierre-> Korollary: i didn't found anything there...
23:59:15 <dons> it's in System.Win32.Types:
23:59:16 <dons> type   HINSTANCE   = Ptr ()
23:59:17 <dons> type MbHINSTANCE   = Maybe HINSTANCE
23:59:46 <dons> @hoogle HINSTANCE
23:59:46 <lambdabot> No matches found
23:59:59 <Korollary> @docs System.Win32.Types
