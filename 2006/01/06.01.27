00:05:14 <Cale> "It seems this benchmark clearly shows that Haskell, which was never designed to handle numerics, is slow at numerics." -- ChrisKuklewicz
00:05:50 <Korollary> mandelbrot?
00:06:01 <Cale> n-body
00:08:06 <Korollary> well, ghc is doing pretty miserably there.
00:10:12 <Cale> The wiki entry is as fast as unoptimised C
00:10:47 <Cale> but that is after a lot of work
00:10:55 <Cale> and the code looks like a mess
00:11:29 <Cale> there really ought to be a good purely functional way to solve that problem.
00:12:02 <Cale> I think perhaps that integrator just doesn't translate to Haskell too well.
00:12:35 <Korollary> the n-body problem is a stateful problem
00:13:28 <Korollary> somehow ghc needs to compile any pure code into something that looks like the C entry
00:14:09 <dons> the code is a mess, but maybe a rewrite of that idea would clean it up.
00:14:13 <jonkri> @doc Add
00:14:14 <lambdabot> Add not available
00:14:35 <Korollary> I dont think you can lose the unsafeReads, tho. array bound checks cost too much.
00:15:49 <dons> no, they're critical.
00:16:22 <dons> the C one doesn't check arraybounds on every a[x], so it would be silly for us to ;)
00:17:15 <Korollary> A while ago I wrote a fibonacci module. even something simple as that was nowhere near C speed.
00:17:29 <shapr> Could the nbody be turned into parallel array ops?
00:17:32 <dons> btw, Chris wrote this comment about numerics before we sped it up. I think sometimes we jump to conclusions about how fast haskell can go ;)
00:17:57 <dons> Korollary, the current fib (the recursive spec) is around C speed.
00:17:59 <Cale> Has anyone tried the 'leaning on lazy evaluation' way?
00:18:14 <shapr> Yeah, amortized complexity?
00:18:41 <Cale> you can often represent iterative algorithms as infinite lists
00:18:52 <dons> yeah, we do that in pidigits
00:18:57 <dons> and kick butt
00:19:12 <dons> (with the help of good Integers)
00:19:34 <dons> but nbody, we've only done it the way the spec says: i.e. follow the Java prog
00:19:40 <shapr> Jeremy Gibbons' paper that introduced pidigits talks about spigot algorithms in general, maybe nbody could be a spigot algorithm?
00:19:41 <Korollary> dons: I went for a nonrecursive implementation
00:20:39 <Cale> perhaps a program which did it the FP way could be included -- though it's likely you wouldn't get quite the right floating point result unless you took a tremendous amount of care
00:21:17 <shapr> I haven't seen any benchmarks that say "Do it like this Haskell program." :-)
00:21:24 <Cale> yeah
00:21:32 <dons> very true
00:21:43 <Cale> I want to see a nice Haskell implementation with coroutine-like use of lazy evaluation
00:21:57 <Cale> and a request for the C programmers to "do it just like Haskell" :)
00:22:06 <Korollary> that's absurd
00:22:10 <Cale> hehe
00:22:45 <dons> well, a dynamic programing or lazy eval test would be fun.
00:23:07 <Cale> well, it's almost as absurd to require that this incredibly imperative algorithm be used in functional languages
00:23:33 <Korollary> well, whatever runs the fastest is what matters. not the style.
00:23:51 <Cale> I think style counts just as much
00:23:52 <shapr> The task itself does matter.
00:24:02 <Korollary> not for things like n-body
00:24:20 <Cale> but it is affecting our score
00:24:27 <Korollary> heh that's too bad :)
00:24:39 <Cale> Well, that's the point.
00:24:59 <shapr> I proposed a 'scales to multiple CPUs' test that wasn't picked up, sadly.
00:26:03 <Korollary> shapr: that's a good quality. but it doesn't apply to everything.
00:26:05 <Cale> If we had some task which used a lot of lazy evaluation, and the imperative programmers were required to write it "the same way", we'd see some different scores altogether :)
00:26:37 <shapr> I know a single GHC-SMP program will get at least 1.6x scaling from one to two CPUs. I know OCaml would require a rewrite of the implementation to scale at all.
00:26:46 <Korollary> Cale: They cannot do lazy eval without emulating it somehow, and if they have to, then they'd beat us again (but their code would be a total mess)
00:27:13 <Cale> Korollary: sure, they *might* beat us, but it would be tough, and again, the code would be a mess.
00:27:20 <shapr> Korollary: I think any forward looking benchmark would be testing the benefit of multicore systems.
00:27:38 <Cale> but it would make the inclusion of things like n-body fair, since there'd be a test which went the other way
00:27:45 <Korollary> shapr: some benchmarks definitely. Not sum-file, tho.
00:28:18 <shapr> Sum file would work nicely with multicores.
00:28:22 <ncalexan> shapr: what about embedded devices?  I think ghc would be pretty much finished in that arena.
00:28:32 <Korollary> shapr: btw, the way ghc performs, a single threaded C version can beat an SMP ghc version heh.
00:28:40 <dons> Korollary, have you seen the rankings? 3rd fastest cputime, 7th on memory, 1st on loc. that's pretty great i think. and we beat all other fp langs by those metrics
00:28:45 <shapr> ncalexan: I agree, I want to run gtk2hs on my nokia770, and ghc just won't cut it there.
00:29:02 <dons> we beat C in 4 or 5 tests
00:29:09 <dons> on speed alone
00:29:10 <Korollary> dons: I think the current standings are great. But you do realize that there are a lot of do-blocks out there.
00:29:29 <ncalexan> I think the 'whole multiple CPUs is the future' meme is given too much credence.
00:29:35 <Cale> do-blocks aren't bad, it's the unsafeReads being necessary :)
00:29:37 <dons> doesn't have much to do with it. it's still functional
00:29:51 <dons> yeah, that kind of stuff, unsafeReads, Ptr Word8, they're annoying
00:29:56 <shapr> Korollary: Sure, hand tuned C will often beat Haskell. But I can write a rough but working Haskell version in a small fraction of the time it takes to write a rough but working C version.
00:30:14 <Korollary> dons: It is, but we *had* to resort to those knowing that the idiomatic versions somehow don't perform. It's a sad thing really.
00:30:15 <shapr> The point I see is that Haskell lets me get working code soonest, and can still scale to being fast.
00:30:40 <shapr> That's partially because CPUs have been tuned for decades for idiomatic C.
00:30:48 <shapr> Multicore systems will change that.
00:31:21 <Cale> I think there's a lot of room for compilers to take advantage of higher level code structure in optimisation
00:31:47 <Cale> If you know that something is a 'map', and not just a loop, that opens up a lot of possibilities.
00:31:54 <ncalexan> Mmm, and I think GHC's rewrite rules pragmas are underutilized.
00:32:03 <shapr> Ever since the eight core Cell cpu was announced for the playstation 3 there has been a continuous background whine from C programmers not wishing to learn about concurrency.
00:32:06 <pejo> Tim Sweeney's slides from POPL this year mentions all this multicore stuff. But they're .ppt, unfortunately.
00:32:14 <Korollary> shapr: today people can get anything working faster in Perl than in C++ too. That doesn't make them pick perl, tho. Somethings got to be damn fast.
00:32:25 <ncalexan> shapr: without the haskell primitives, why would you want to use concurrency :)
00:32:36 <Cale> Korollary: that's what the FFI is for :)
00:32:53 <Korollary> Cale: that argument goes for JNI too?
00:33:10 <Cale> hm?
00:33:19 <shapr> Korollary: Yes, but no one knows what has to be fast until after the first profiling run, and I can get to the first profiling run fastest with Haskell. Only the inner loop has to be fast.
00:33:20 <Korollary> java native interface
00:34:01 <Cale> I take it that's Java's FFI?
00:34:05 <Korollary> yeah
00:34:07 <Cale> sure
00:34:34 <Cale> though with Java, you'll probably lose that cross-platformy goodness you never had anyway
00:34:52 <Korollary> shapr: It depends on what application you're talking about. For many of them, people know from the get-go.
00:35:01 <shapr> In the business world, lots of people do pick Perl over C++ because you can write it quickly and it's fast enough.
00:35:17 <Cale> though there's not too much benefit to Java over, say C++
00:35:49 <shapr> Korollary: I've never been in an environment that was so clueful.
00:36:11 <ncalexan> Has anyone here been following the Perl6 birthing pains?
00:36:13 <shapr> I've heard that the SAN networks is such an industry.
00:36:18 <Cale> ncalexan: pains?
00:36:41 <dons> i know there was no implementation till they tried it in haskell ;)
00:36:48 <Cale> ncalexan: I take it you must know about pugs :)
00:36:58 <ncalexan> From the outside, the process looks laborious.
00:36:59 <pejo> Cale, wouldn't you say the garbage collection helps for atleast a rather large class of common errors?
00:37:00 <shapr> Korollary: Can you give some examples of apps where people already know the inner loop?
00:37:15 <ncalexan> Of course, atang's blog is fascinating stuff.
00:37:19 <Cale> pejo: okay, yeah, that's one point
00:37:29 <Korollary> shapr: What inner loop are you talking about? You're writing, say, an mp3 encoder. Do you really wonder if it needs to be as fast as possible?
00:37:39 <Cale> pejo: Java is a nicer language than C++, but only by a little, compared with say, Haskell
00:38:04 <dons> anyway, i think we should all celebrate that haskell is the 3rd _fastest_ language. i wonder how many hits google turns up for 'haskell too slow' ;)
00:38:21 <dons> and on the part-time budget we have, as well
00:38:25 <shapr> Korollary: I think the same pattern applies there. The encoding loop obviously needs to be as fast as possible, but all the code around that doesn't.
00:38:26 <pejo> Cale, I'm not defending Java, just saying that GC is "necessary" for all of us that are bad programmers.
00:38:28 <Cale> ncalexan: Perhaps from my distant perspective, everything appears to be going much more smoothly than it actually is
00:38:30 <Korollary> dons: I don't think ghc is slow.
00:39:43 <shapr> Korollary: In my opinion, http://c2.com/cgi-bin/wiki?AlternateHardAndSoftLayers says that I can write the code first in Haskell, Python, or whatever, and then optimize the inner loop with a chunk of C or hand tuned asm.
00:39:53 <Cale> pejo: yeah, garbage collection is pretty important
00:40:59 <shapr> Korollary: Anyway, I know that the BBC's  Dirac video codec was prototyped for correctness in Haskell first, and then rewritten.
00:41:11 <Cale> I think that if you *really* want speed, what you do is write a combinatorial optimiser in Haskell which writes/rewrites assembler for you.
00:41:35 <shapr> Cale: Right, Oleg's optimal code generator in Scheme is an example of that.
00:41:43 <Cale> Or FFTW
00:41:51 <shapr> Singel pass optimal code generation is the way of the future.
00:41:53 <Cale> which is in O'Caml
00:42:44 <Korollary> shapr: That turns the project into a multilingual one. I haven't seen many of those, probably because management & HR hate it.
00:42:53 <pejo> shapr, what does Oleg generate optimal code for, or is it just optimal in general? And optimal wrt to what?
00:43:22 <Cale> obviously you can't generate optimal code for anything
00:43:27 <shapr> pejo: http://lambda-the-ultimate.org/node/652
00:43:38 <earthy> 1. single pass optimal code generation may not always be possible
00:43:50 <earthy> 2. single pass code generation is a concern of the past
00:44:10 <shapr> I disagree, but I could easily be wrong :-)
00:44:23 <Korollary> why would I care if it's single pass or not?
00:44:26 <earthy> okay, what do you consider a single pass? :)
00:44:56 <shapr> I think a single pass allows the most optimization because you have all the original information available.
00:45:07 <earthy> korollary: a single pass only requires going through the input once, and *not* constructing any intermediate values representing the entire input that you then traverse
00:45:44 <earthy> as soon as you generate an AST that you then traverse, you're already doing multipass compilation
00:45:53 <Korollary> earthy: so why do I care?
00:46:07 <earthy> korollary: as I said, you don't. :)
00:46:30 <earthy> but for very small machines, back in the day, where going through the input was costly, and you couldn't always keep all the input in memory
00:46:34 <shapr> Oleg's says the point of his paper is that once you know the important axioms, you can generate optimum code.
00:46:37 <Korollary> yes, I remember that
00:47:25 <Korollary> the small machines thingy, that is
00:47:30 <shapr> Actually, he says that in this case they found all the axioms, and that let them generate optimal code.
00:48:34 <earthy> was it http://okmij.org/ftp/Scheme/PostL-paper.html, shapr?
00:54:26 <jonkri> thanks all
00:54:26 <jonkri> cya
00:54:45 <shapr> earthy: nay - http://lambda-the-ultimate.org/node/652
00:56:06 <shapr> Korollary: Well, I think all projects should be multilingual, and I wonder whether SQL counts as another language already.
00:56:50 <shapr> Anyway, I am distracting myself from paying work, and so shall leave the field of discussion.
00:57:06 <earthy> point. :)
01:32:04 <lispy> @pl \x -> x + x
01:32:04 <lambdabot> join (+)
01:32:17 <lispy> @type Control.Monad.join
01:32:18 <lambdabot> forall a (m :: * -> *). (Monad m) => m (m a) -> m a
01:32:51 <lispy> > Control.Monad.join (+) 1
01:32:52 <lambdabot> 2
01:33:03 <lispy> hmm...that's very odd to me
01:33:23 <lispy> @type Control.Monad.join (+)
01:33:24 <lambdabot> forall a. (Monad ((->) a), Num a) => a -> a
01:33:56 <lispy> what monad does it use? the identity monad?
01:33:59 <nibro> function application is a reader monad
01:34:19 <nibro> it will treat the 1 as both the environment and the value
01:34:51 <nibro> > (do { x <- (+1); return x}) 1
01:34:53 <lambdabot> 2
01:35:25 <lispy> interestingly it does not work when i try it in ghci
01:35:34 <lispy>     No instance for (Monad ((->) a))
01:35:34 <lispy>       arising from use of `join' at <interactive>:1:0-3
01:35:34 <lispy>     Probable fix: add an instance declaration for (Monad ((->) a))
01:35:34 <lispy>     In the definition of `it': it = join (+) 1
01:36:09 <nibro> aye, the instance lives in Control.Monad.Reader IIRC
01:36:30 <nibro> yep, just checked
01:37:46 <lispy> okay, interesting
01:38:19 <nibro> hmm
01:38:21 <lispy> i had actually expected @pl to fail
01:38:36 <nibro> @type Control.Monad.join filter
01:38:38 <lambdabot>   Couldn't match `[a]' against `a -> Bool'
01:38:38 <lambdabot>   Expected type: (a -> Bool) -> (a -> Bool) -> a1
01:38:57 <nibro> @type Control.Monad.join (filter id)
01:38:58 <lambdabot>   Couldn't match `[a1] -> a' against `[a1]'
01:38:58 <lambdabot>   Expected type: [a1] -> [a1] -> a
01:39:13 <nibro> @type Control.Monad.join concat
01:39:14 <lambdabot>   Couldn't match `[[a1]] -> a' against `[a1]'
01:39:14 <lambdabot>   Expected type: [[a1]] -> [[a1]] -> a
01:39:18 <tromp_> of course it never fails
01:39:19 <lispy> @pl \x -> x + x + x
01:39:19 <lambdabot> (+) =<< join (+)
01:39:24 <xerox> Yay.
01:39:45 <nibro> @type Control.Monad.join (++)
01:39:46 <lispy> @pl \x -> x + x + x + x + x + x
01:39:46 <lambdabot> forall a. (Monad ((->) [a])) => [a] -> [a]
01:39:46 <lambdabot> (+) =<< (+) =<< (+) =<< (+) =<< join (+)
01:39:52 <lispy> hehe
01:39:56 <xerox> sounds like
01:40:14 <xerox> foldr (=<<) (join) (replicate (+))
01:40:18 <xerox> @type foldr (=<<) (join) (replicate (+))
01:40:19 <lambdabot> Not in scope: `join'
01:40:22 <xerox> @type foldr (=<<) (Monad.join) (replicate (+))
01:40:22 <lambdabot>   Expecting a function type, but found `[a]'
01:40:22 <lambdabot>   Expected type: [m a -> m (m a) -> m a]
01:40:26 <xerox> Yey.
01:40:39 <xerox> @type foldr (=<<) (Monad.join (+)) (replicate (+))
01:40:40 <lambdabot>   Expecting a function type, but found `[a]'
01:40:40 <lambdabot>   Expected type: [a -> a -> a]
01:40:56 <xerox> @type Monad.foldM_
01:40:57 <lambdabot> Not in scope: `Monad.foldM_'
01:40:59 <xerox> @type Monad.foldrM
01:41:00 <lambdabot> Not in scope: `Monad.foldrM'
01:41:02 <xerox> @type Monad.foldM
01:41:03 <lambdabot> forall a (m :: * -> *) b.
01:41:03 <lambdabot> (Monad m) =>
01:41:03 <lambdabot> (a -> b -> m a) -> a -> [b] -> m a
01:41:09 <xerox> @type foldM (=<<) (Monad.join (+)) (replicate (+))
01:41:10 <lambdabot> Not in scope: `foldM'
01:41:14 <xerox> @type Monad.foldM (=<<) (Monad.join (+)) (replicate (+))
01:41:15 <lambdabot>   Occurs check: cannot construct the infinite type: b = a -> m b
01:41:15 <lambdabot>   Expected type: (a -> m b) -> m a -> m (a -> m b)
01:41:21 * xerox sits in his angle now.
01:41:38 <tromp_> it could even express any function in just ap and const
01:41:46 <tromp_> aka S and K
01:42:08 <lispy> ah, i have seen it resort to ap and const before
01:42:11 <tromp_> although they prolly wouldn't type properly:(
01:43:30 <tromp_> @pl (\x y->x y x)(\y x-> y(x y x))
01:43:30 <lambdabot> join flip (ap (.) (join . flip id))
01:44:17 <lispy> @pl (\x -> y)(\y -> x)
01:44:17 <lambdabot> y
01:45:25 <xerox> heh.
01:46:18 <lispy> i think that's wrong, but my brain keeps going haywire trying to explain it to me
01:46:47 <xerox> y is a free var in the left function.
01:47:01 <xerox> and it ignores its argument
01:47:22 <xerox> so should it be const y?
01:47:36 <xerox> No, y is right.
01:47:37 <lispy> @pl \x -> y
01:47:37 <lambdabot> const y
01:47:42 <xerox> Because it is applied to a function
01:47:50 <xerox> Whatever is it, it's ignored.
01:47:52 <xerox> Yep, that's right.
01:47:56 <lispy> @pl \y -> x
01:47:56 <lambdabot> const x
01:48:19 <lispy> @pl \x y -> (const y) (const x)
01:48:20 <lambdabot> const id
01:48:22 <xerox> @pl (\_ -> f) (whatever you would ever think of)
01:48:22 <lambdabot> f
01:48:35 <xerox> @pl (\_ -> f) -- without, it's const f.
01:48:36 <lambdabot> const f
01:48:53 <lispy> neat
01:49:35 <lispy> @pl (\_ -> f) (say "f" if you like lispy)
01:49:36 <lambdabot> (line 1, column 20):
01:49:36 <lambdabot> unexpected reserved word "if"
01:49:36 <lambdabot> expecting variable, "(", operator or ")"
01:49:40 <lispy> darn....
01:49:44 <xerox> heh.
01:49:47 <lispy> @pl (\_ -> f) (say f if you like lispy)
01:49:47 <lambdabot> (line 1, column 18):
01:49:47 <lambdabot> unexpected reserved word "if"
01:49:47 <lambdabot> expecting variable, "(", operator or ")"
01:49:56 <xerox> 'if' it's a reserved keyword.
01:50:00 <lispy> oh
01:50:01 <xerox> is, even
01:50:08 <lispy> yeah, you're right
01:50:57 <lispy> @pl \x -> if True then x else x + x
01:50:58 <lambdabot> if' True `ap` join (+)
01:51:09 <lispy> ah, i hopped it would be more creative :)
01:51:19 <lispy> well, i should probably go to bed
01:52:53 <xerox> > let if' p t f = if p then t else f; lispy = if' True `ap` join (+) in lispy 1
01:52:54 <lambdabot> 1
02:00:42 <Cale> 'night
02:01:21 <xerox> Yay I didn't know this was possible: http://rafb.net/paste/results/1G3ktP63.html
02:10:19 <shapr> Anyone know Esa Pulkkinen's email address?
02:10:42 <shapr> ah, found it
02:11:06 <xerox> shapr: this is IRC!  How do you expect us to know realnames?  <blink>
02:12:16 <shapr> Well, I do.
02:12:39 <xerox> Dull Eris boy.
02:12:56 <shapr> But then again, I also remember most of the people I've conversed with on IRC since 1992 or so.
02:13:27 <xerox> Same here, at least for the nicks, and sometime the names, yea.
02:14:54 <shapr> pesco: Want to publish your "he" program as a TMR article demonstrating how to combine yampa and opengl to get cool effects?
02:18:54 <dcoutts> JohnMeacham, don't you rely on class instances being global to be able to do some of your class system optimisations? Would you cope with local instances as just suggested on the haskell-prime list?
02:19:46 <dcoutts> JohnMeacham, local instances might be no great burden for a dictionaly passing scheme but it'd be much worse for your system right?
02:20:27 * xerox hugs dcoutts 
02:20:40 * dcoutts is slightly suprised!
02:20:40 <xerox> dcoutts: those are NEAT graphics!  Woooo!
02:20:47 <dcoutts> oh that :-)
02:20:57 <dcoutts> http://haskell.org/gtk2hs/archives/2006/01/26/cairo-eye-candy/
02:20:57 <xerox> Weee :-)
02:21:03 <xerox> Yes, that.
02:21:18 <dcoutts> xerox, you've run it then?
02:21:31 <dcoutts> or still just looking at the screenshots? :-)
02:21:43 <xerox> The latter, gtk2hs wasn't building here.
02:21:53 <dcoutts> oh really? a build problem?
02:21:55 <xerox> I'm doing a compilation from a fresh repo now.
02:21:58 <dcoutts> ok
02:22:20 <dcoutts> we do try to keep the dev repo buildable
02:22:20 <shapr> dcoutts: I've always wanted a time-setting widget that let me drag the arms of the clock around, can this do that?
02:22:35 <dcoutts> shapr, it doesn't but you could extend it!
02:22:41 <xerox> Unfortunately the ubuntu cairo package doesn't install libsvg-cairo :-|
02:22:52 <shapr> In my copious free time.
02:22:57 <dcoutts> xerox, doesn't matter, we don't need it for anything
02:23:21 <xerox> I've got some code that behave on the cairo rendered surface from Cale, for nymphaea, if it helps.
02:23:24 <dcoutts> there arn't any really special svg demos in the gtk2hs collection yet
02:23:50 <xerox> Do you remember the bubble popping up where you click, with a little arrow pointing at the pointer, when you turn around holding the mouse button?
02:24:17 <dcoutts> oh yes, shapr, that'd do for your time setting widget
02:24:19 <xerox> You've got compliments ;-)  <+_llll_> the clock.hs is very readable anyway
02:24:33 <xerox> (#math folks without deep Haskell knowledge)
02:24:38 <shapr> Could I write desktop kudzu with a compositing manager? That is, could some app figure out where the edges of the windows are sitting and slowly grow climbing vines up as long as you haven't moved the window?
02:24:42 <dcoutts> xerox, heh :-)
02:25:24 <dcoutts> shapr, the edges of other windows on the desktop? ones not owned by your app?
02:25:26 <shapr> Of course, with kudzu it wouldn't be that slow...
02:25:26 <xerox> @baben en it vines
02:25:28 <lambdabot>  viti
02:25:52 <dcoutts> shapr, this clock is suppsoed to have a transparent background if you've got a composit manager running
02:25:57 <shapr> dcoutts: I'm thinking about the funny roaches under windows demo, but instead using something pretty like vines.
02:26:07 <dcoutts> shapr, a right, fun
02:26:22 <shapr> A compositing manager sounds like the best way to do that.
02:26:33 <dcoutts> shapr, hmm, so you'd need to enumerate the windows on the desktop, I'll have alook in the docs...
02:27:03 <dcoutts> it might be beyond the scope of gdk, you might need some extra xlib stuff
02:27:13 <shapr> It would be especially fun to tear your window off of the vines and then watch them wither and fall off :-)
02:27:41 <shapr> Or come back after vacation and the vines are so thick you can't move your window at all!
02:27:42 * shapr laughs
02:27:52 <xerox> Haha.
02:28:14 <xerox> shapr: what i the demo you were talking about?
02:28:18 <shapr> The roaches?
02:28:28 <xerox> Yep.
02:29:48 <shapr> http://home.catv.ne.jp/pp/ginoue/software/groach/images/groach.png
02:29:57 <dcoutts> shapr, it might be easier to do that in a window manager
02:30:07 <shapr> Yeah, maybe so.
02:30:27 <dcoutts> otherwise it might be hard to track the movement of the top level windows
02:30:42 <shapr> Hm, makes sense.
02:30:45 <dcoutts> I'd look for a WM with plugins for themes
02:30:56 <xerox> Yay, people's still using unstyled fwvm... :-)
02:32:10 <dcoutts> shapr, or take a look at libwnck, it's used by the worskapce switcher applet and it can track window motion
02:32:39 <shapr> Ok, I'll look at it, thanks.
02:32:40 <dcoutts> shapr, so perhaps it'd be possible, but keeping a mostly transparent window on top of every other top level window
02:32:58 <shapr> Yeah, that would work.
02:33:08 <dcoutts> though that might intercept events
02:33:26 <shapr> Roaches are easier because they're always underneath other windows.
02:33:30 <aleator> Think plexiglass.. :)
02:33:37 <dcoutts> perhaps just two smaller windows on each side, partially overlapping the sides of each top level window
02:34:08 <shapr> I remember parking my car in a parking lot one day, and two days later kudzu was trying to grow into the engine.
02:34:22 <dcoutts> I think it is possible to allow clicks through to the windows below
02:34:35 <dcoutts> kudzu?
02:35:07 * dcoutts googles for kudzu
02:35:27 <dcoutts> "Kudzu is a vine that when left uncontrolled will eventually grow over almost any fixed object in its proximity including other vegetation."
02:36:31 <shapr> It grows about a foot per day.
02:37:18 <shapr> It was originally a small decorative japanese clinging vine that required careful upkeep. Then someone imported it to the southeast USA...
02:37:46 <aleator> http://www.science-house.org/kudzu/kudzu-car.jpg?
02:37:47 <shapr> Now it's - http://www.science-house.org/kudzu/
02:37:51 <shapr> aleator: Exactly
02:40:28 <dcoutts> is it much different to ivy?
02:40:49 <earthy> yes
02:41:02 <earthy> it grows a shitload faster
02:41:11 <dcoutts> right
02:42:11 <earthy> funny thing is kudzu was imported for its useful properties
02:42:20 <earthy> it just got out of control
02:42:35 <Saulzar> As goes for most random pests...
02:43:33 <earthy> such as rabbits in australia
02:43:55 <earthy> meddling with ecosystems is somewhat dangerous. :)
02:45:46 <lightstep> i have some questions about haskell i/o
02:46:10 <lightstep> first, why doesn't getLine use standard line-buffered i/o?
02:46:30 <lightstep> second, why isn't there a strict getContents?
02:47:24 <xerox> It's because of the conspiracy built in order to get more entropy on this channel.
02:47:58 <JohnMeacham> dcoutts: local dictionaries would horribly break a lot of haskells static semantics, independent of implementation issues they would be a bad idea. polymorphic components and newtype deriving pretty much obviate the need for them anyway.
02:48:12 <lightstep> i tried the exercises on THHGTTH, and they're really hard
02:48:24 <xerox> @wtf THHGTTH
02:48:25 <lambdabot> No match for "THHGTTH".
02:48:27 <lightstep> especially ex. 1 on chapter 1
02:48:27 <JohnMeacham> dcoutts: I think we had a discussion about this recently. I'll see if I can dig it up.
02:48:42 <lightstep> @wiki TheHitchHikersGuideToTheHaskell
02:48:42 <lambdabot> http://www.haskell.org/hawiki/TheHitchHikersGuideToTheHaskell
02:48:47 <xerox> Ah-ha.
02:48:56 <lightstep> err
02:49:04 <lightstep> @wiki HitchhikersGuideToTheHaskell
02:49:04 <lambdabot> http://www.haskell.org/hawiki/HitchhikersGuideToTheHaskell
02:49:46 <xerox> lightstep: what's hard abotu that?
02:49:50 <xerox> about, even
02:50:05 <lightstep> getContents is lazy
02:50:12 <lightstep> try solving it, and you'll see
02:50:25 <xerox> Maybe I'mreading the wrong exercise then.
02:50:35 <lightstep> the solution is sth like main = getContents >>= (putStrLn . ("hello "++))
02:50:40 <xerox> Try to write program that takes your name from the stdin and greets you (keywords: getContents, putStrLn);
02:50:57 <dcoutts> JohnMeacham, if you find that reference you could post it in reply on the haskell-prime list
02:51:20 <shapr> Anyone else want to write an article or finish an article for the last TMR?
02:51:25 <lightstep> the problem is, the program first prints "hello ", and then echoes back any character you type
02:52:00 <lightstep> another problem is that it doesn't recognize linefeed or eof
02:52:20 <kosmikus> dcoutts: I agree with JohnMeacham. Local dictionaries *might* be a useful addition, but I imagine it requires quite some research before it could be added to Haskell.
02:52:59 <dcoutts> kosmikus, I recall you had a bit about that in your thesis?
02:55:52 <kosmikus> Yes, you could say that.
02:56:38 <kosmikus> Although the reasoning worked like this: if you want to implement dependency style using type classes, then you'd like to have local instances. Local instances as required for that purposes, can, however, be simulated using existing Haskell features.
02:56:59 <xerox> lightstep: heh, it's not straightforward as it seems, yea...
02:57:04 <kosmikus> I haven't outlined how local instances would work for Haskell, and I'm not convinced they would at all.
02:57:13 <dcoutts> right
02:58:03 <xerox> lightstep: the proper solution seem to be:
02:58:04 <xerox> import IO
02:58:05 <xerox> main = hGetLine stdin >>= putStrLn . ("Hi, "++)
02:58:21 <xerox> lightstep: well, getLine should work too.
02:58:38 <xerox> main = getLine >>= putStrLn . ("Hi, "++)
02:58:42 <lightstep> which brings me to the second question
02:58:43 <xerox> Yes it does, without the import IO.
02:58:52 <xerox> Let's fix the wikipage.
02:58:59 <lightstep> why can't you use backspace?
02:59:18 <xerox> No readline support, I think.
03:00:08 <lightstep> this has nothing to do with readline
03:00:20 <lightstep> it's a standard unix terminal thing
03:00:20 <xerox> Bah, I don't remember my wikiaccount password, hmpf.
03:00:26 <lightstep> gets() also has this
03:00:36 <xerox> Maybe it doesn't setup the term properly?
03:01:21 <lightstep> probably it's still in character-mode
03:01:46 <lightstep> (unlike any other language environment, which starts up line-buffered
03:01:53 <lightstep> *start)
03:02:23 <xerox> ADEpt: ping
03:04:54 <JohnMeacham> kosmikus: a canonical bad thing would be a Set.Set made with one instance of Ord and then used with another. lots of invarients in code depend on the idea class instances are global. in any case, other extensions solve the problems local class instances are thought to solve.
03:05:38 <dblhelix> away
03:15:03 <ADEpt> xerox: pong
03:17:45 <MarcWeber> It's strange: in the file base.Control.Concurrent they mention a paper which describes the extension. But I can't find the function delay and the first echo char example contains an error ( echo = hGetChar stdin >>= \c hPutChar stdout [here is c missing, isn't it?] >> return c)
03:35:33 <phas> hello
03:35:49 <phas> i'm trying to use System.Network lib for a small app
03:36:25 <phas> but i need a lot of help
03:36:34 <TuringTest> @seen dons
03:36:35 <lambdabot> dons is in #haskell-blah and #haskell. Last spoke 2 hours, 58 minutes and
03:36:35 <lambdabot> 14 seconds ago.
03:38:07 <Lemmih> phas: What seems to be the problem?
03:38:38 <phas> well mainly i don't know how to do what i want :P i expain myself better
03:39:29 <phas> i have to write a simple client/server app that contains a server that wait for messagges from client and print them when they occours
03:39:55 <phas> the easy way to do that is using
03:39:55 <phas> sendTo :: HostName -> PortID -> String -> IO ()
03:39:56 <phas> recvFrom :: HostName -> PortID -> IO String
03:40:20 <phas> but it's wrote that these function are intended only for testing
03:41:06 <phas> so i think that for the server-side i need to use
03:41:06 <phas> listenOn
03:41:12 <phas> to create the socket
03:41:15 <Lemmih> Indeed.
03:41:29 <phas> and accept
03:41:43 <phas> to obtain a I/O hander on wich read on
03:42:02 <Lemmih> Exactly.
03:42:08 <phas> while the client uses
03:42:09 <phas> connectTo
03:42:20 <phas> to have an handler on wich write on
03:42:56 <Lemmih> Sounds like you have it all figured out.
03:43:05 <phas> now, while the client-side is somewath straightforward
03:43:12 <phas> i have some doubt on the server-side
03:44:00 <phas> the main one is how obtain that process block itself while it doesn't obtain a message
03:44:22 <phas> end wakeup himself when obtains one, fore reading it
03:45:32 <lightstep> threads?
03:45:43 <phas> uhm
03:45:45 <Lemmih> You don't need threads.
03:45:52 <phas> ah, ok
03:45:54 <phas> because
03:46:02 <Lemmih> phas: You know how to read and write the message?
03:46:09 <phas> uuuuuuuuh well
03:46:29 <phas> not very well have to say
03:46:59 <phas> i know that when i have han handler i have to use sone System.IO functions
03:47:13 <Lemmih> What is a message?
03:47:23 <phas> uh?
03:47:28 <phas> a String
03:47:58 <Lemmih> Is it a single line? Does it have some format?
03:48:18 <phas> uhm a single line-one could be fine for now
03:48:34 <phas> but wait a minute
03:49:02 <phas> i know that if you want to syncronize two processes this way using messagges
03:49:26 <phas> i need to have a stopping "receive" function
03:49:36 <phas> or something like that
03:49:56 <Lemmih> Have you tried just hacking a simple implementation with hGetLine and hPutStrLn?
03:50:16 <phas> mmh no, being earnest, i've tryng nothing
03:50:34 <phas> mainly because i don't know what to try
03:51:17 <Lemmih> You know how to start the server and you know how to connect the client to it. That gives you a Handle on each side.
03:51:25 <phas> ok
03:51:42 <Lemmih> Then you can use hPutStrLn and hGetLine to send messages.
03:51:54 <Lemmih> There's nothing more to it.
03:54:03 <phas> mmmh
03:54:24 <phas> yeah you are probably right
03:54:36 <phas> ok
03:55:11 <phas> next questionn
03:55:13 <phas> -> IO (Handle, HostName, PortNumber)
03:55:28 <phas> is a monad containing a touple?
03:58:11 <Lemmih> Yes.
03:58:46 <Lemmih> do sock <- listenOn ...; (handle, host, port) <- accept sock; ...
04:16:10 <phas> uuh i've a third question
04:16:54 <phas> (PortNumber 1300) gives me the related port ID
04:17:44 <phas> doesn't it's supposed to work the same way (PortNumber (read "1300"))
04:22:13 <Lemmih> (PortNumber (fromIntegral (read "1300"))). PortNumber isn't an instance of Read for some reason.
04:23:43 <phas> ah ok
04:28:39 <dcoutts> Lemmih, I see you've forked a gtk2hs branch for hIDE. Is that really necesary?
04:29:18 <dcoutts> Lemmih, is there anything I can do upstream to mean we don't need a branch?
04:31:47 <Lemmih> I'd like to guarantee that HIDE is buildable.
04:32:53 <Lemmih> Remember when you added the 'event' prefix to all events? It broke a lot of stuff and was a pain in the ass. (:
04:35:00 <phas> lol
04:43:59 <Lemmih> lisppaste2: url
04:44:00 <lisppaste2> To use the lisppaste bot, visit http://paste.lisp.org/new/haskell and enter your paste.
04:44:58 <lisppaste2> phas pasted "server.hs" at http://paste.lisp.org/display/16111
04:45:59 <dons> @seen musasabi
04:45:59 <lambdabot> I saw musasabi leaving #haskell-overflow, #haskell-blah and #haskell 1
04:45:59 <lambdabot> day, 32 minutes and 55 seconds ago.
04:46:16 <lisppaste2> phas pasted "client.hs" at http://paste.lisp.org/display/16113
04:51:59 <xerox> ADEpt: re-ping :-)
04:52:17 <xerox> Hi phas :-)
04:52:37 <ADEpt> xerox: packet loss - 50% :)
04:54:44 <xerox> ADEpt: heh.
04:55:37 <ADEpt> xerox: is that all? :)
04:55:38 <xerox> ADEpt: lightstep was suggesting to fix your tutorial's exercise about welcoming a user by changing the suggestion about 'getContents' with 'getLine', which is line buffered, and understand the end of the line, at lest.
04:55:42 <xerox> *least
04:57:11 <ADEpt> xerox: me bad. fixed. btw, have you read it? any feedback?
04:57:36 <xerox> I just skimmed it, I can't really say.  But seems good to me.
04:59:03 <TuringTest> dons: Hi again
05:07:24 <Itkovian> @type readFile
05:07:24 <lambdabot> FilePath -> IO String
05:07:33 <Itkovian> @type lines
05:07:34 <lambdabot> String -> [String]
05:30:59 <eckhart> hi
05:32:07 <Lemmih> Hiya eckhart.
05:32:45 <eckhart> are these expressions equivalent: [x | x <- xs, y<-ys] and [ x | y <- ys, x<-xs]
05:33:19 <eckhart> the only reason i can find those two are not equivalent are: ys depends on x / xs depends on y
05:34:08 <Lemmih> > [ x | x <- [1,2,3], y <- [4,5,6]]
05:34:09 <lambdabot> [1,1,1,2,2,2,3,3,3]
05:34:12 <Lemmih> > [ x | y <- [4,5,6], x <- [1,2,3]]
05:34:13 <lambdabot> [1,2,3,1,2,3,1,2,3]
05:34:40 <eckhart> ah
05:34:45 <eckhart> yeah, i can see now
05:34:47 <eckhart> my fault
05:35:00 <sieni> > [x^y | x <- [1,2,3], y <- [4,5,6]]
05:35:01 <lambdabot> [1,1,1,16,32,64,81,243,729]
05:35:45 <Lemmih> > [ x^y | y <- [4,5,6], x <- [1,2,3]]
05:35:46 <lambdabot> [1,16,81,1,32,243,1,64,729]
05:37:19 * jethr0_ wrote a naive entry for the shootout nbody entry. it's damned slow. and e.g. the scheme entry is damned fast and has remarkably simple code :(
05:38:27 <musasabi> dons: back from death, missed probably things.
05:39:54 <jethr0_> and the scheme version is even purely functional *huhuhu*
05:42:21 <Saulzar> Hmm, which scheme version are you looking at? Looking at the page they're a fair way down.
05:43:26 <jethr0_> Saulzar: yes, i was looking at n=50000. scheme is pretty slow, but it's still 30 times faster than my version :)
05:43:33 <jethr0_> wait, 8 times
05:43:50 <Saulzar> But the one I'm looking at doesn't look purely functional...
05:44:22 <jethr0_> http://shootout.alioth.debian.org/gp4/benchmark.php?test=nbody&lang=chicken&id=2
05:44:35 <Saulzar> Ah, I was looking at 1..
05:44:44 <jethr0_> i'd just like to know how to find / solve memory leaks
05:44:51 <Saulzar> Second one is almost right at the bottom of the tables.
05:44:59 <jethr0_> how do you differentiate between a leak and just huge mem usage?
05:45:00 <xerox> What is it?
05:45:25 <Saulzar> Well if you're doing some kind of iteration where you're not keeping prior results...
05:45:45 <Saulzar> Then you should be able to get it to use constant memory, otherwise it's leaking
05:46:13 <jethr0_> Saulzar: i know. i looked wrong. checking out the sml/nj version now
05:46:59 <jethr0_> so, i've got an iteration where i create lists/objects. and mem usage is proportional to n. how can i fix that?
05:47:01 <Saulzar> I'm trying to un-leak my program, finally managed to get the basics non-leaking and adding stuff slowly.
05:47:21 <xerox> jethr0_: keep sure to not keep references to things that needs to be collected?
05:47:44 <farre> ping nibro_
05:48:07 <Saulzar> Which may require forcefully evaluating stuff
05:48:47 <jethr0_> xerox: easier said than done :)
05:49:06 <xerox> jethr0_: would you mind to explain the whole problem?
05:49:31 <eckhart> could one say that [x | x <- xs, y<-ys] and [ x | y <- ys, x<-xs] are equivalent with either:
05:49:45 <eckhart> 1) length ys <= 1
05:49:55 <jethr0_> i don't want to bother you too much :). i didn't like how the code for the optimized nbody entry looked and wondered how fast a optimized, readable naive/pure version would be.
05:49:58 <eckhart> or 2) the number of different elements in xs <= 1
05:50:01 <Saulzar> jethr0_, You can say that again :)
05:50:16 <jethr0_> i've programmed that now, but it's so devilishly slow, that i'm annoyed
05:50:27 <xerox> Tried profiling?
05:50:31 <Saulzar> Hmm, the SML version, and the Clean version are both using mutable arrays (and are pretty fast)
05:51:06 <jethr0_> xerox: that's what i'm trying all the time. and i know which function causes most time and mem. but it's hard to pinpoint what _inside_ that function causes this
05:51:21 <jethr0_> my guess is creating lists/objects, but its just a guess
05:51:23 <xerox> 8-pages-long-functions?  :-)
05:51:48 <jethr0_> Saulzar: well, mutable arrays isn't that bad, but the fastest haskell version uses bit fiddling to no end.
05:51:51 <Saulzar> jethr0_, Tried heap profiling?
05:52:00 <jethr0_> i don't want to criticise, but it doesn't look pleasant to me
05:52:27 <jethr0_> http://haskell.org/hawiki/NbodyEntry
05:52:54 <Saulzar> Hmm, what's it using bit fiddling for? Calculating array indices?
05:52:59 <jethr0_> Saulzar: tried, yes. but found it hard to act on the results. it basically just said: "all you mem is expended in this function, and it's _a lot_"
05:53:01 <Saulzar> I'm just looking there
05:53:30 <jethr0_> sth like that. it's not the easiest code to read
05:53:35 <Saulzar> Have you had a look with hp2ps graphs?
05:53:53 <xerox> Yay, that's *unsafe* !
05:54:12 <jethr0_> yes, but again, they aren't very precise in pinpointing the offending expression
05:54:18 <Saulzar> Hmm
05:54:33 <Saulzar> I guess ideally one would need to test each individually.
05:54:41 <jethr0_> xerox: after reading in many times it doesn't look all that bad anymore, but at first glance *brrr*
05:54:57 <xerox> heh.
05:55:05 <Saulzar> I've been having no end of trouble figuring out how to un-leak this program, ended up commenting out 99% of the code and starting from ground up.
05:55:08 <xerox> Maybe with some ad-hoc monad...
05:55:17 <xerox> Boom-boom-cha.
05:56:10 <jethr0_> Saulzar: but i don't find that a good prospect if i want to program in haskell for real. especially for things where performance might count
05:56:20 <Saulzar> Right... 
05:58:43 <Saulzar> Seems like a tough kind of issue, I have a feeling that once one gets a feel of it it's not so bad.
05:59:07 <jethr0_> hmm, i was just wondering whether anyone on here had a process that i could follow :)
05:59:41 <Saulzar> Have you had a look at retainer profiling yet? That seems particually useful to get started
06:00:55 <jethr0_> i just did, but wasn't very happy about its results. it basically said that i'm visitim a fixed average number of objects per second
06:01:02 <jethr0_> whatever that is supposed to mean
06:02:26 <Saulzar> Hmm, but what is the top item of the list?
06:02:53 <lisppaste2> jethr0 pasted "nbody retainer profile" at http://paste.lisp.org/display/16115
06:03:18 <SamB> Saulzar: which program? your ray tracer?
06:03:37 <Saulzar> Robots 
06:03:40 <jethr0_> SamB: nah, i tried myself on the nbody problem. and haskell got me good
06:03:54 <jethr0_> Saulzar: it's planets, actually *g*
06:09:35 <JohnMeacham> oh yeah. haskell is lazy huh. I keep forgetting to take advantage of it in obvious places.
06:10:07 <SamB> robdockins: I guess the C-- spec needs to put minus signs in with the main grammar rather than the literal syntax, eh?
06:10:43 <JohnMeacham> like instead of passing flags to a complicated function telling it what to do, just return every possible result, and let the user choose what he wants. rather than have seperate functions to determine whether you can unbox something and to do the unboxing, return the result as a maybe, so you can use it for both without actually having to calculate the unboxing.... 
06:11:05 <MarcWeber> What does # mean in Conc(urrent).lhs ? It's used many times.
06:11:30 <Saulzar> Unboxed primitives?
06:11:33 <dcoutts> MarcWeber, how is it used? as part of function names?
06:11:37 <JohnMeacham> I can handle infinite data structures and tying the knot just fine.. but these little obvious things keep slipping past me...
06:11:40 <SamB> MarcWeber: where?
06:12:08 <SamB> JohnMeacham: and you, writing a compiler and all!
06:12:26 <robdockins> samb: well, the way I think about it is, the c-- defines one huge BNF, of which the literal BNFs are just a part.
06:13:03 <robdockins> samb:  unary '-' is always a bugger when writing parses
06:13:47 <SamB> robdockins: its easier if the spec is given in a more readily-implemented form, though
06:13:54 <MarcWeber> dcoutts: \ c# -> case newVar # s# of ... (from newEmptyMvar)
06:13:59 <robdockins> samb: very true
06:14:11 <MarcWeber> Is this specific to ghc?
06:14:21 <SamB> robdockins: I have seen some fairly horrible code to deal with this kind of thing
06:14:50 <SamB> MarcWeber: well, the c# is just a variable name (though not in standard syntax)
06:15:26 <robdockins> samb: I hope mine isn't in that category ;)
06:15:26 <dcoutts> MarcWeber, yes, it's a ghc extension. It allows '#' chars in value names. It uses such names for primitives that are unboxed.
06:15:38 <SamB> robdockins: no
06:15:49 <SamB> actually, it wasn't that bad. could have been worse.
06:16:09 <dcoutts> MarcWeber, eg: data Int = I# GHC.Prim.Int#
06:16:21 <dcoutts> Int# is the type of unboxed integers
06:16:32 <MarcWeber> dcoutts: boxing means putting it into a data type? (such like State Monad? (State and runState to unbox)?
06:16:47 <SamB> I think all it did was either glue "-" and numeric literal tokens together, or split negative literals apart, when one or the other interpretations was not appropriate
06:17:17 <dcoutts> MarcWeber, yeah, that's what boxing is, so that code is passing about unboxed values.
06:17:25 <SamB> the former is not hard even in Parsec
06:18:21 <SamB> there were worse things about this code, though, I think
06:18:56 <MarcWeber> dcoutts: But it doesn't matter anyway? Because the compiler does tree reduction (I don't remember the name exactly)..  I'll just try.. or grep for GHC.Prim.Int ;-)
06:19:40 <dcoutts> MarcWeber, yes ghc can often unbox things without you needing to do it explicitly. However some of ghc's internal libs use unboxed things explicitly.
06:21:39 <SamB> often enough, it can't unbox without changing semantics (or at least, can't prove that it can), so it doesn't
06:25:30 <SamB> robdockins: you may notice that it is conventional for packages in the Language tree to have three modules named "Syntax", "Parser", and "Pretty" next to eachother?
06:26:33 <SamB> (I use the term package loosely)
06:27:50 <robdockins> samb:  I hadn't noticed that.... I'm not opposed to changing to match.
06:28:16 <MarcWeber> SamB, dcoutts Which keyword to use to look it up in ghc documentation?
06:28:24 <SimonRC> You know you're writing Haskell when ... Your graphics library consists of an abstract arrow data type with associated primitives and combinators, and was developed for a PhD.  Your main data structure library consists of an abstract functor data type with associated primitives and combinators, and was developed for a PhD.  Your marshalling/demarshalling library consists of an abstract monadic data type with associated primitives and combinators, and was d
06:28:39 <SamB> I didn't think you would be. I guessed you might not have noticed. I might even be overgeneralizing!
06:28:47 <SimonRC> You know you're a Haskell programmer if ... you find the above perfectly normal.
06:28:56 <SamB> but it doesn't look bad.
06:29:11 <dcoutts> MarcWeber, I'm not sure what your talking about
06:29:16 <SimonRC> :-)
06:29:48 <SamB> SimonRC: well, either you are writing Haskell or you are a masochistic PhD student
06:30:33 <SimonRC> SamB: :-S
06:30:37 <SamB> and that sounds pretty normal to me ;-)
06:30:41 <shapr> SimonRC: Give it up man, you should have used a higher order function to make that sentence shorter.
06:30:41 <MarcWeber> dcoutts: ghc extionsion unboxing #
06:30:46 <robdockins> or both
06:31:06 <SimonRC> shapr: I considered doing so, but it would break the rhythm.
06:31:07 <SamB> though I might use a different graphics library
06:31:18 <MarcWeber> dcoutts: I've found it
06:31:21 <SamB> and what is a "data structure library"?
06:31:36 <MarcWeber> unboxed types and primitive operations ;)
06:31:43 <SimonRC> SamB: Like Data.Map, Data.Graph.*, etc
06:34:12 <SimonRC> but more advanced, maybe
06:35:51 <shapr> You know you're writing Haskell when (++) ( map (uncurry \x y -> Your x library consists of an abstract y type with associated primitives and combinators, and was developed for a PhD) [("graphics","arrow"),("data structure","functor data"),("marshalling/demarshalling","monadic data")])
06:35:54 <lightstep> #index gfold
06:35:57 <lightstep> @index gfold
06:35:57 <lambdabot> Data.Graph.Inductive.Basic, Data.Graph.Inductive
06:36:09 * shapr compulsively refactors...
06:36:50 <shapr> SimonRC: I admit, that's cute and quotable... are you doing your PhD? ;-)
06:37:22 <shapr> In any case, what are you writing? It sounds interesting.
06:38:06 <jethr0_> shapr: how's the TMR coming along?
06:38:42 <shapr> I won't be able to work on it before monday.
06:39:04 <dcoutts> hia gour
06:39:41 <Saulzar> Victory! No more leaks :)
06:40:11 <jethr0_> Saulzar: congrats
06:40:19 <jethr0_> now you only have to tell me how :)
06:40:19 <dcoutts> gour, btw I made a couple minor changes to the gtk2hs web site css theme. I changed the title description from 1.2em to 1.8 and the side bar text from 1em to 1.1em.
06:40:44 <dcoutts> gour, and of course I added those cool new screenshots :-)
06:41:09 <Saulzar> jethr0_, Well, I commented everything and went from the ground up... which as you pointed out, not very appealing way to go
06:41:13 <vincenz> Holy cow
06:41:25 <jethr0_> hmm
06:41:46 <jethr0_> until you saw some leaking, i guess. and then you knew what it was
06:41:57 <Saulzar> Yep, put it back slowly.
06:42:02 <jethr0_> there's an automatic debugger out there which will do interval debugging automatically
06:42:23 <jethr0_> sth like that would be nice for haskell. interval commenting-out until the leak is pinpointed
06:42:41 <jethr0_> w/o many data dependencies this should be easier in haskell than in imperative languages
06:42:46 <Saulzar> Hmm, what is meant by interval?
06:42:48 <kevind> how can I make emacs haskell-mode just use spaces and not tabs
06:43:06 <jethr0_> Saulzar: like testing first half of the program. if bug doesn't appear, test second half of the program
06:43:14 <jethr0_> repeat until bug location is pinpointed exactly
06:43:18 <Saulzar> Hmm..
06:43:49 <Saulzar> Trouble is that programs are mostly heirarchial.
06:44:02 <jethr0_> yup, i forgot how they did it, but it actually worked
06:44:16 <jethr0_> maybe it wasn't bugs, but some kind of defined misbehaviour
06:45:54 <Saulzar> In my case I just needed to make it consume all the inputs and all the outputs (ie. make it stricter)
06:46:09 <jethr0_> like adding `seq` everywhere?
06:46:53 <Saulzar> Yeah, well in some places
06:47:11 <xerox> or deepseq main (lol)
06:47:23 <Saulzar> But that was hard, because I've been using Dynamic... which doesn't seem like something which can be force evaluated easily (if you don't know the type)
06:48:58 <Lemmih> kevind: (setq-default indent-tabs-mode nil), I think.
06:49:13 <xerox> Lemmih is right.
06:49:32 <jethr0_> hmm
06:49:37 <kevind> thx
06:53:38 <gour> dcoutt: nice touch ;)
06:54:37 <gour> dcoutts: maybe menu tabs could be increased a bit?
06:54:49 <gour> dcoutts: now i have to go out. bbl
06:57:44 <Saulzar> Hmm, one thing I didn't realise is that if I use some stateful arrow, and it is never used then it leaks. Which seems to defeat laziness a little. If I return some graphic which is not drawn ... 
07:11:33 <jethr0_> can someone give me a hint wrt profiling
07:11:58 <jethr0_> i've got following profiles (with tons of cost centers): jethr0.dyndns.org/current/{a.out.ps, a.out.prof}
07:12:17 <jethr0_> and don't know what to do with them :)
07:13:44 <ADEpt> jethr0_: now you might want to see who is holding "advancemain". with "-hr -hcadvancemain", if I am not mistaken
07:13:45 <dcoutts> gour, done
07:13:54 <jethr0_> ok
07:14:08 <dcoutts> gour, see if you think it's ok
07:14:11 <jethr0_> what do you mean "holding"? it's function "advance" called from "main"
07:15:04 <Saulzar> Can we see the code? :)
07:15:19 <jethr0_> sure, but it ain't pretty :)
07:16:16 <lisppaste2> jethr0 pasted "stupid, slow nbody version" at http://paste.lisp.org/display/16119
07:16:34 <ADEpt> jethr0_: have you head "heap profiling for space efficiency" by Runciman and R\:oemo ?
07:16:51 <jethr0_> it's not a _real_ project. i just want to learn how to profile/optimize in haskell
07:17:09 <jethr0_> ADEpt: yes, but i might reread that :)
07:19:06 <araujo> Good morning.
07:20:17 <ADEpt> jethr0_: have you done producer profile?
07:20:41 <jethr0_> ADEpt: which flag is that?
07:21:05 <ADEpt> jethr0_: -p ?
07:21:11 <ADEpt> jethr0_: or -hp ?
07:21:17 <jethr0_> i've done "-hr -hcadvance" now, but that's only mildly readable
07:21:44 <jethr0_> yes
07:22:13 <jethr0_> http://jethr0.dyndns.org/current/a.out.ps   and   http://jethr0.dyndns.org/current/a.out.prof
07:22:34 <araujo> @index timeoutAddFulle
07:22:35 <lambdabot> bzzt
07:22:45 <araujo> @index timeoutAddFull
07:22:46 <lambdabot> bzzt
07:22:53 <xerox> @hoogle timeoutAdd
07:22:54 <lambdabot> No matches found
07:22:56 <xerox> @hoogle timeout
07:22:57 <lambdabot> Graphics.UI.GLUT.Callbacks.Global.Timeout :: Int
07:22:57 <lambdabot> Network.Socket.RecvTimeOut :: SocketOption
07:22:57 <lambdabot> Network.Socket.SendTimeOut :: SocketOption
07:23:34 <xerox> I think there is timeoutAdd in Gtk2Hs.
07:23:45 <araujo> yeah , i see
07:24:20 <ADEpt> jethr0_: http://jethr0.dyndns.org/current/a.out.ps is done with "-hc"
07:24:33 <jethr0_> yes
07:24:42 <jethr0_> ah, sorry. i'll try -hp
07:24:56 <vincenz> @fptools take
07:24:56 <lambdabot> take not available
07:25:58 <vincenz> @type foldr
07:25:58 <lambdabot> forall b a. (a -> b -> b) -> b -> [a] -> b
07:26:26 <jethr0_> ADEpt: -hp is not a valid switch
07:26:50 <dcoutts> how's it going araujo?
07:27:03 <araujo> Hello dcoutts !
07:27:08 <araujo> dcoutts, having a lot of fun :-)
07:27:12 <dcoutts> good good
07:27:16 <vincenz> > foldr (\x y -> if x < 10 then x:y else x:[]) [] [1..100]
07:27:17 <lambdabot> [1,2,3,4,5,6,7,8,9,10]
07:27:38 <araujo> dcoutts, i finally figured out the things about the progress bar, thanks for the help.
07:27:40 <ADEpt> jethr0_: ./a.out +RTS --help 
07:27:47 <dcoutts> araujo, great
07:28:04 <vincenz> how would I force a trace?
07:28:11 <vincenz> in that lambda
07:28:28 <vincenz> @index trace
07:28:28 <lambdabot> Debug.Trace
07:28:35 <jethr0_> ADEpt: http://jethr0.dyndns.org/current/help
07:30:23 * vincenz mutters
07:30:43 <ADEpt> jethr0_: ah. my knowledge is outdated. anyway ..
07:30:49 <jethr0_> hmm, thx anyways.
07:30:56 <vincenz> How do I use the trace function?
07:31:08 <jethr0_> ADEpt: the specifics aren't that important. i just don't know how to proceed in general!
07:31:22 <ADEpt> jethr0_: if I were you I'd started with -hb and found out that most of the memory "lags" - that is, it's allocated too early
07:31:38 <jethr0_> ok
07:31:57 <lightstep> @type trace
07:31:58 <lambdabot> Not in scope: `trace'
07:31:59 <vincenz> > (trace x) `seq` if x < 10 then return x:y else return x:[]
07:32:00 <lambdabot>  Not in scope: `x'
07:32:06 <vincenz> > \x y -> (trace x) `seq` if x < 10 then return x:y else return x:[]
07:32:07 <lambdabot>  Not in scope: `trace'
07:32:09 <vincenz> @type \x y -> (trace x) `seq` if x < 10 then return x:y else return x:[]
07:32:10 <lambdabot> Not in scope: `trace'
07:32:41 <jethr0_> ADEpt: most is "lag", 25% "inherent_use"
07:32:56 <lightstep> > \x y -> if Debug.Trace.trace x < 10 then return x:y else return [x]
07:32:57 <lambdabot>  Not in scope: `Debug.Trace.trace'
07:34:23 <lightstep> is it disallowed because of unsafePerformIO?
07:34:36 <vincenz> @type Debug.Trace.trace
07:34:36 <lambdabot> forall a. String -> a -> a
07:34:44 <ADEpt> jethr0_: "lag" is a state between creation and first usage, so as I said you allocate too early somewhere
07:35:00 <vincenz> oh, a string!
07:35:02 <lightstep> vincenz, usually you use trace (show x) x
07:35:17 <jethr0_> aha, and how would you procede?
07:35:20 <vincenz> won't work :(
07:35:27 <vincenz> aha!
07:35:56 <vincenz> o.O
07:35:57 <vincenz> wow
07:36:11 <vincenz> foldr -can- stop halfway down a list
07:36:17 <xerox> Yes.
07:36:38 <vincenz> myfunc x y = trace (show x) (if x < 10 then x:y else x:[])
07:36:43 <vincenz> main = do
07:36:48 <vincenz>   let l = foldr myfunc [] [1..100] in
07:36:48 <vincenz>     sequence_ $ map print $ l
07:36:55 <ADEpt> jethr0_: -hc already shown that you use up with applications of "advance"
07:37:06 <vincenz> hmm
07:37:30 <jethr0_> ADEpt: yes, my program is leaking (or at least using up memory) like crazy
07:37:38 <Saulzar> jethr0_, Hmm, by forcing it to evaluate bodies at each iteration I have it so it uses about 30k of memory, not quite sure why though.
07:38:00 <jethr0_> Saulzar: my code?
07:38:03 <Saulzar> Yeah
07:38:12 <jethr0_> you mean 30k alltogether?
07:38:24 <vincenz> xerox: even MORe interesting..it prints the items of trace WHILE it prints the final list :)
07:38:27 <jethr0_> could you annotate in the paste thingey
07:38:33 <Saulzar> Yep, I'll upload it and you can figure out why :)
07:38:39 <vincenz> jethr0_: what's the link?
07:38:39 <jethr0_> cool, thx
07:38:46 <vincenz> lambdabot: where is the paste site?
07:38:48 <vincenz> @paste
07:38:49 <lambdabot> http://www.haskell.org/hawiki/HaskellIrcPastePage
07:39:05 <ADEpt> jethr0_: so use -hd and see which closures this memory consists of
07:39:18 <jethr0_> http://paste.lisp.org/display/16119
07:39:28 <jethr0_> ADEpt: ah
07:40:28 <ADEpt> jethr0_: or do -hr -hcadvance to see who is retaining "advance" on heap. My profiler says that it's "added", then "dvels"
07:40:48 <ADEpt> jethr0_: even better, -hd -hcadvance
07:40:49 <xerox> vincenz: try some expensive computation?
07:41:08 <vincenz> xerox: like what
07:41:20 <ADEpt> jethr0_: btw, this small script could be of use:
07:41:20 <ADEpt> #!/bin/bash
07:41:20 <ADEpt> suffix=$(echo $@ | sed -e 's/ //g')
07:41:20 <ADEpt> ./a.out +RTS "$@"
07:41:20 <ADEpt> hp2ps a.out.hp 
07:41:20 <ADEpt> mv a.out.ps a.out_$suffix.ps
07:41:21 <lisppaste2> Saulzar annotated #16119 with "non leak (maybe)" at http://paste.lisp.org/display/16119#1
07:41:22 <lisppaste2> Saulzar annotated #16119 with "non leak (maybe)" at http://paste.lisp.org/display/16119#2
07:41:22 <ADEpt> gv a.out_$suffix.ps
07:41:30 <Saulzar> Whoops
07:41:52 <Saulzar> Somehow managed to double click the button and submit it twice
07:42:06 <jethr0_> never mind
07:42:36 <jethr0_> hehe
07:42:45 <jethr0_> ADEpt: thx, good idea
07:42:54 <lightstep> jethr0_, is there no way to avoid the O(n^2) complexity of energy?
07:43:01 <kevind> hrm, do default instances of Ord and Eq for datatypes (whose constituents are Ord and Eq) work?  They seem to just cause stack overflows for me
07:43:10 <vincenz> out of curiousity
07:43:12 <Saulzar> ADEpt, Ahh - so that's asking for the "second in line" retainer inside of advance?
07:43:21 <vincenz> if I wanted to use parsec to make a parser that is indentatio nsensitive...how would I do this?
07:43:25 <jethr0_> lightstep: energy is only called once. so i don't care. i just translated the java version in haskell...
07:43:40 <lightstep> oh
07:44:29 <lightstep> also, mapVector is only used once, for division by a scalar
07:44:44 <ADEpt> Saulzar: what are you talking about -hr  or -hd ?
07:45:02 <Saulzar> In this line "-hr -hcadvance"
07:45:16 <jethr0_> lightstep: it's not a great program :). just trying to learn how to profile. and "advance" uses 90% of runtime/heap!
07:45:55 <ADEpt> Saulzar: yep. "who holds that advance thingie that sits on top of the heap profile"
07:46:37 <ADEpt> so my guess is that "added" could you a bit of more strictness
07:47:01 <jethr0_> cool
07:47:24 <Saulzar> That's really useful. I was running into a brick wall because the top level function was not giving enough granularity.
07:50:02 <jethr0_> ADEpt: i still don't understand what it means. so in my case "dvels" and "added" 'hold' advance on the heap, right?
07:53:16 <TuringTest> @find turingtest
07:53:17 <lambdabot> Not in scope: type variable `turingtest'
07:55:38 <Saulzar> What's all the SCC pragma stuff about?
07:56:40 <jethr0_> Saulzar: that's me not knowing what i'm doing. adding cost centers.
07:56:46 <Saulzar> Oh, makes a cost centre
07:56:51 <Saulzar> I see
07:57:08 <jethr0_> Saulzar: but i guess you have to know what you're doing to use them properly
07:57:23 <jethr0_> Saulzar: i still don't understand what it means. so in my case "dvels" and "added" 'hold' advance on the heap, right?
08:00:13 <jethr0_> Saulzar: in your paste, what does the "--Here" mean?
08:00:37 <Saulzar> That's just where I messed with it
08:01:17 <Saulzar> Not entirely sure, apparently that's the interpretation, or I would have thought it meant advance "contains" those two sub elements
08:01:51 <Saulzar> It seems only this line "body1 `seq` loop bodies vecs" is enough 
08:01:52 <jethr0_> i guess i'll reread the heap profiling paper. BTW, your one change had an amazing effect!
08:02:27 <jethr0_> but what i _really_ want to know is how one could have methologically found that!
08:02:34 <Saulzar> Actually I changed a few, but only that one seems to matter
08:03:59 <Saulzar> In this case it seems to help that everything is strict, so if you force evaluate the Body structure then everything is
08:04:11 <Saulzar> (The data structure is strict, I mean)
08:05:54 <jethr0_> Saulzar: no, some of my own changes helped a lot too, i'm seeing
08:06:08 <jethr0_> but it's all so trial-and-error :'(
08:06:18 <Saulzar> Hmm, I tried removing all the $! and it seems to work the same
08:07:04 <gour> dcoutts: here it is too big, 'Development' hides in the next row. in any case too big. next attempt please :-) 
08:07:09 <gour> dcoutts: bbl
08:08:05 <jethr0_> Saulzar: forcing "body1" in the getDeltaVels line gives a speedup of 7
08:08:40 <Saulzar> Ah, seems to require this too
08:08:45 <Saulzar> loop (n-1) $! ...
08:08:50 <Saulzar> In the main body
08:09:19 <jethr0_> i just wish it weren't so "guessy"
08:10:58 <Saulzar> What I want to know is why forcing the top level elements didn't change anything, I tried getting it to evaluate at top level "advance"
08:11:20 <jethr0_> i wish i could deepseq "bodies". but it's not in the std libraries, is it?
08:12:37 <Saulzar> I tried that, and it didn't seem to help. In fact it was leaking with it, but not without...
08:20:13 <Saulzar> Hmm, I tried making a strict zipWith and that did the trick too
08:20:32 <jethr0_> nice
08:20:44 <jethr0_> maybe a strict "map" would help too
08:25:07 <Saulzar> ghc map seems faster than my attempt at strict map :)
08:25:57 <xerox> It is probably heavily optimized inside, since its not fmap.
08:28:21 <araujo> What is a good way to run parallel processe?
08:28:37 <Saulzar> If I use an accumulating parameter and then reverse it, it seems only a tiny bit slower
08:29:11 <Saulzar> Whoops. Much faster in fact..
08:29:13 <xerox> araujo: threads I'd say.
08:29:35 <jethr0_> accumulating parameter?
08:30:11 <Saulzar> Whoops again, I had a bug :)
08:31:29 <Saulzar> Instead of adding elements to the return value, eg. map xyz = abc : map ...    accumulate the return in a parameter
08:31:40 <jethr0_> i removed all optimizations and only use my strict zip and have the same performance!
08:32:03 <boozee> hello, can anyone suggest an app that prints all source code given a dir?
08:32:11 <Saulzar> Yep, here too, seems about the same.
08:32:17 <jethr0_> Saulzar: yes, that was on my (forgotten) TODO list
08:32:25 <jethr0_> boozee: cat?
08:32:45 <boozee> jethr0_, i was thinking about adding colors :)
08:32:55 <boozee> and maybe the dirs too... :)
08:34:18 <Saulzar> How does the un-leaked version compare with the shootout entries? 
08:34:37 <araujo> xerox, ?
08:34:43 <Saulzar> (I would guess it would still be much worse, but...)
08:35:12 <jethr0_> factor 7 to the latest version
08:36:46 <jethr0_> well factor 10
08:36:50 <jethr0_> but this version is pure :)
08:37:13 <jethr0_> no factor 7 was right. i enabled profiling :)
08:38:10 <Saulzar> Using optim flags?
08:38:23 <jethr0_> yes, but i'm not sure my version is leak-free :(
08:38:37 <jethr0_> yes it is
08:39:07 <Saulzar> Well, it might have leaks within the main loop I guess, but no global leak
08:39:10 <jethr0_> if my code weren't so bad. it could look as nice as the scheme #2 code and still be only 7 times slower :)
08:39:12 <tromp_> printing source in color sounds like a waste of ink
08:39:39 <jethr0_> adding some unpureness, should get me in the region of factor 2 or so (just guessing)
08:40:56 <jethr0_> but i still don't know how i could've found my leak :(
08:41:18 <jethr0_> in the end, deepSeq the bodies worked just fine!
08:41:31 <jethr0_> 'coz that's what my strict zip does, more or less
08:41:35 <Saulzar> Ah, really? How did you go about it?
08:41:59 <jethr0_> using a strict zip for "zip' [1..] bodies"
08:42:37 <Saulzar> Hm, you seem to make array for nullVels, then all you use it for is converting back to a list? 
08:43:34 <jethr0_> cool, with -fexcess-precision it's only factor 4
08:43:57 <jethr0_> Saulzar: yes, but i'm using it to do indexed adding
08:44:18 <Saulzar> Ah, maybe I'm blind but I can't see where?
08:44:32 <Saulzar> Ah, vecs ! n
08:44:39 <vincenz> @index Parsec
08:44:40 <lambdabot> bzzt
08:44:44 <vincenz> hmm
08:44:49 <vincenz> import Parsec won't owrk :/
08:44:51 <jethr0_> yup, maybe not the best way...
08:44:58 <vincenz> @index letter
08:44:58 <lambdabot> Text.ParserCombinators.Parsec.Char, Text.ParserCombinators.Parsec
08:45:00 <jethr0_> but in my raytracer, using arrays really paid off!
08:45:00 <vincenz> ah
08:45:06 <Saulzar> fexcess-precision seems to do nothing on this computer, in fact it seems to make it slower
08:45:12 <Saulzar> (For any program that I've tested)
08:46:02 <vincenz> jethr0_: ooh, can I see your raytracer (is it simple code?)
08:47:00 <Saulzar> What did you need arrays for in the raytracer?
08:48:17 <jethr0_> Saulzar: on my computer the code is "only" factor 12 slower than c. that would place it 20th in the current shootout. about in the middle of all entries!
08:48:25 <jethr0_> Saulzar: textures
08:48:46 <jethr0_> vincenz: it's simple, but terribly ugly. have you seen hray
08:48:47 <jethr0_> ?
08:48:53 <Saulzar> jethr0_, Congrats :)
08:49:17 <Saulzar> That's not too bad, it's faster than the purely functional scheme...
08:49:25 <jethr0_> http://www.haskell.org/tmrwiki/HRay
08:49:27 <vincenz> jethr0_: no, just hoping to see some haskell code to learn haskel
08:49:30 <jethr0_> http://scannedinavian.com/~boegel/HRay/
08:49:55 <jethr0_> Saulzar: and i'm sure there's plenty of opportunity to improve even the pure version.
08:50:02 <jethr0_> i just gotta get better at profiling!
08:50:32 <jethr0_> Saulzar: and factor 4 isn't that bad, considering how the optimized haskell code looks like
08:52:20 <Saulzar> Hehe, well the optimised code looks a lot like the SML array update code to me...
08:52:20 <jethr0_> i wonder if you can force the result of a function. like "let res = ... in res `seq` res" or sth
08:52:27 <jethr0_> *brr*
08:52:49 <boegel|home> jethr0_: I've seen HRay
08:52:58 <jethr0_> hehe
08:53:15 <jethr0_> but mine is only 250 lines :)
08:53:25 <boegel|home> can it do as much as mine can ?
08:53:37 <boegel|home> I mean, a lot of the code is for the Perlin related stuff and the GUI
08:53:52 <boegel|home> I believe the actual raytracing is somewhat like 250 lines too in mine
08:54:03 <Saulzar> Mine is bloated :)
08:54:12 <jethr0_> no, but i was still impressed at the brevity. http://jethr0.dyndns.org/phpwikihideindexphp/index.php/RayTracing. excuse the slow uplink!
08:54:56 <jethr0_> boegel|home: i was very much inspired by your TMR article
08:56:59 <boegel|home> jethr0_: cool, thanks
08:57:18 <jethr0_> bump mapping rulez :)
08:57:24 <boegel|home> jethr0_: feel free to add stuff to mine ;)
08:57:57 <boegel|home> you have some very cool stuff there... you have anti-aliasing working ?
08:58:08 <jethr0_> i'm gonna rewrite mine to make CSG easier. and i'll do it test-driven so that i have no excuse not to add features weeks after leaving it alone
08:58:09 <boegel|home> or did you just rescale the images as I did ? :p
08:58:37 <jethr0_> boegel|home: i am doing sub-sampling at points of big gradient
08:59:01 <Saulzar> boegel|home, That was my trick too :)
08:59:04 <jethr0_> some of the pics are just blurred. but the later one are adaptively subsampled
08:59:14 <boegel|home> hmm, I should add that to mine too... if I only had time
08:59:40 <jethr0_> but with my newly acquired strictness skills i can also speed my raytracer up to no end!
09:00:11 <Saulzar> It looks much nicer, edge jitter looks really ugly 
09:00:35 <vincenz> jethr0_: is your code lgpl'd?
09:00:37 <Saulzar> Hmm, I never checked to see if I had a leak at all... it just seemed to work.
09:00:38 <boegel|home> I know :(
09:00:53 <jethr0_> vincenz: no license, too ugly. but you can have it if you want
09:01:03 <boegel|home> maybe I should a some license to my code too... I'm just not too familiar with that stuff
09:01:04 <vincenz> jethr0_: just looking for some small code samples to tweak to learn haskell better :)
09:01:05 <jethr0_> http://jethr0.dyndns.org/repos/raytracer/
09:01:44 <vincenz> jethr0_: nice results :)
09:01:54 <jethr0_> vincenz: but it's really ugly! my first real haskell project and many wront starts, work in progress :)
09:02:10 <vincenz> jethr0_: well a good learning place :)
09:03:04 <boegel|home> jethr0_: heh, I could sue you for stealing my code, since no license = copyrighted (if I'm correct)
09:03:30 <vincenz> oy, talk about slow upload :/
09:04:00 <jethr0_> boegel|home: i really meant _inspired_, not copied. it's all my own code!
09:04:29 <jethr0_> vincenz: darcs getting it would be faster, because there's lots of crap in that directory
09:04:44 <vincenz> jethr0_: I'm still loading the first page, it hasn't loaded the directory yet :
09:04:45 <vincenz> :/
09:04:47 <jethr0_> "darcs get http://jethr0.dyndns.org/repos/raytracer/"
09:05:02 <jethr0_> weird
09:05:07 <vincenz> btw, how much space overhead does a darcs repo add?
09:05:09 <Saulzar> Hmm, seems I had no space leak despite doing no optimisation at all...
09:05:14 <jethr0_> the picture page has pretty big animated gifs on it
09:05:36 <jethr0_> space overhead where? i guess it duplicates the content plus some delta information
09:06:18 <vincenz> damn, darcs get is slow too
09:06:22 <vincenz> still coping patch 1
09:06:31 <jethr0_> i'm sorry
09:06:41 <jethr0_> don't wait for it, just let it happen :)
09:07:09 <jethr0_> ls
09:07:13 <vincenz> :P
09:07:25 <vincenz> jethr0_: and why does it keep loading your page, I have all the images, yet it just keeps on loading
09:07:34 <jethr0_> no idea
09:07:48 <boegel|home> jethr0_: I know dude, I was joking... there's no fun in copying. I'm glad someone is finding it usefull
09:07:49 <jethr0_> have you got the animated images at the bottom finished?
09:07:52 <vincenz> well under pseudotextures I only see one image
09:08:01 <vincenz> same for "antialiasing *yeah*"
09:08:15 <vincenz> jethr0_: the wall? yes
09:08:31 <vincenz> I get a lot of php errors however
09:08:40 <jethr0_> the bottom two walls are animated
09:08:49 <vincenz> okay, i switched from linked lists to arrays for my texture lookup and instead of 12 minutes the above bump mapped image now renders in 9 second
09:08:51 <jethr0_> vincenz: well, i could not have shown you, you know :)
09:08:53 <vincenz> wow
09:09:18 <vincenz> jethr0_: anyways, you mention different steps, are these traceable in your code to see how it goes along?
09:09:26 <jethr0_> vincenz: yes, wouldn't have thought so either
09:09:48 <Saulzar> I guess O(n) traversal is not going to be fun for 480000 element lists
09:09:49 <jethr0_> vincenz: hmm, not in the code, but to an extent in the darcs'ed patches
09:09:56 <vincenz> jethr0_: ah cool, thanks :)
09:10:10 <vincenz> if I did a darcs get, can I rewind patches without reconenting to your pc?
09:10:11 <jethr0_> although i don't remember when i actually started darcs'ing it
09:10:17 <jethr0_> yes
09:10:20 <vincenz> cool :)
09:10:35 <vincenz> anyways, gotta go get groceries before it closes
09:10:40 * vincenz needs food cause he' sgot the flue
09:10:49 <jethr0_> but as i said: don't take the code to be idiomatic, beautiful haskell. i'm gonna rewrite the whole thing
09:11:00 <jethr0_> that should tell you what i think about its code quality *g*
09:11:04 <vincenz> jethr0_: no worries, just that small code smaples are hard to find
09:11:13 <jethr0_> very true
09:11:21 <vincenz> so I take what I can get
09:11:26 <vincenz> anyways, bbl
09:12:16 <jethr0_> originally i wanted to do photon mapping, but that was too much of a challenge to do in pure haskell. so i'm gonna do that someday later...
09:13:59 * boegel|home leaves
09:14:03 <boegel|home> me gf will be here soon
09:14:04 <boegel|home> bye !
09:14:10 <jethr0_> bye
09:20:21 <palomer> @hoogle Error
09:20:22 <lambdabot> Prelude.error :: String -> a
09:20:22 <lambdabot> Control.Monad.Error.Error :: Error a
09:20:22 <lambdabot> Graphics.Rendering.OpenGL.GLU.Errors.Error :: Error
09:20:40 <xerox> Monad Error?  Uh.  Either?
09:21:31 <roconnor> In Haskell crazy world, monads have 3 functions: return, bind, and error.
09:21:54 <roconnor> mostly so that do blocks have something to call when pattern matches fail.
09:22:17 <palomer> oh, so that's why they do it
09:22:29 <roconnor> well, that's my understanding.
09:22:54 <eivuokko> Yeah, seemed so on the archives that got digged up when Cale brought monad stuff up on ml.
09:23:39 <Saulzar> Hmm. If you use return and bind 99% of the time, is that so crazy?
09:24:09 <palomer> as opposed to?
09:24:26 <xerox> Saulzar: it's nature!
09:24:28 <Saulzar> map and join
09:24:55 <roconnor> No, it's not crazy.
09:25:10 <xerox> Nature I say!
09:25:21 <palomer> weren't the SICP authors big map/join proponents?
09:25:48 <roconnor> bind, map, join; they are all good.
09:26:15 <palomer> @hoogle ST
09:26:16 <lambdabot> Control.Monad.ST.Lazy.ST :: ST s a
09:26:16 <lambdabot> Control.Monad.ST.ST :: ST s a
09:26:16 <lambdabot> Graphics.UI.ObjectIO.CommonDef.St :: s -> (a, s)
09:26:19 <franka> Hello.
09:26:21 <roconnor> even return is good once in a while ;)
09:26:40 <xerox> I should elaborate some more on The Evil Idea.
09:26:58 <palomer> @hoogle RealWorld
09:26:58 <lambdabot> Control.Monad.ST.Lazy.RealWorld :: RealWorld
09:26:58 <lambdabot> Control.Monad.ST.RealWorld :: RealWorld
09:27:12 <roconnor> oh my
09:27:30 <bosie> lambdabot did watch too much mtv
09:27:33 <roconnor> what is that used for?
09:27:40 <roconnor> please say FFI
09:27:53 <xerox> roconnor: IO.
09:28:01 <jethr0_> muhaha
09:28:23 <roconnor> what functions take the RealWorld as a parameter?
09:28:26 <xerox> roconnor: newtype IO a = IO { unIO :: ST RealWorld a }
09:28:31 <xerox> Somewhat...
09:29:02 <xerox> I do!  (taking RealWorld as a parameter)
09:29:07 <roconnor> franka: Hi.
09:29:32 <roconnor> put RealWorld peace
09:30:04 <palomer> can I put STRef s Int and STRef s bool in the same list?
09:30:28 <palomer> my intuition says says, and that it'll be an (Eq a) => List a
09:30:34 <palomer> s/says/yes
09:30:36 <palomer> but the compiler says no
09:30:38 <xerox> Nope...
09:30:39 <franka> Hello, roconnor 
09:30:44 <xerox> Lists are homogeneous.
09:31:05 <roconnor> palomer: How about List (Either (StRef s Int) (StRef s bool))
09:31:15 <xerox> Handy :-P
09:31:26 <palomer> oh my god my types are getting really really gross
09:31:30 <franka> If bool is indeed lowercase, you can.
09:31:40 <palomer> > [2,True]
09:31:40 <lambdabot>  add an instance declaration for (Num Bool)
09:31:40 <lambdabot>   In the list element: 2
09:31:40 <lambdabot>   In the definition of `kjg': kjg = [2, True]
09:31:43 <roconnor> palomer: How about List (Either (StRef s Int) (StRef s Bool))
09:32:01 <palomer> roconnor: yeah, that'll uglyfi my lists even more!
09:32:06 <palomer> err, my types
09:32:13 <palomer> @hoogle Left
09:32:13 <lambdabot> Control.Arrow.left :: ArrowChoice a => a b c -> a (Either b d) (Either c
09:32:13 <lambdabot> d)
09:32:13 <lambdabot> Data.Either.Left :: a -> Either a b
09:32:13 <lambdabot> Prelude.Left :: a -> Either a b
09:32:25 <roconnor> palomer: type thingy = Either (StRef s Int) (StRef s Bool)
09:32:35 <palomer> also means I have to change mucho code
09:32:38 <roconnor> palomer: type Thingy = Either (StRef s Int) (StRef s Bool)
09:32:39 <palomer> oh the things I do for science!
09:32:44 <roconnor> now it's List Thingy
09:33:13 <roconnor> palomer: data types need to be abstracted as well as functions ;)
09:33:25 <palomer> I still don't see why it can't be homogeneous in the typeclass
09:33:37 <roconnor> oh
09:33:42 <palomer> all I want is eq
09:33:44 <roconnor> well, you can use rank-2 polymorphism
09:33:58 <roconnor> It's a bit tricky, but if all you care about is Eq.
09:34:11 <palomer> actually, wait, I have an idea
09:34:16 <roconnor> if all you REALLY care about is Eq, then it can work.
09:35:02 <palomer> how would that work?
09:35:14 <Philippa_> Thingy = forall s.Either...
09:35:33 <roconnor> perhaps List (StRef s (Either Int Bool)) is what you really want.
09:35:55 <Philippa_> yeah, you only want the lists attached to specific heaps anyway
09:36:15 <roconnor> palomer: I need to look up some old code, hang on.
09:36:27 <palomer> so  (Eq e) => List e doesn't have any inhabitants?
09:37:42 <roconnor> data Thingy =forall a.(Eq a) => Thingy a
09:37:52 <roconnor> Now you can do List Thingy
09:38:07 <palomer> shouldn't taht be type?
09:38:30 <roconnor> Now you can use the type List Thingy as a list of things with the equality class.
09:38:57 <roconnor> But be warned, all you can do with items in the list is compare them with themselves for equality
09:39:03 <roconnor> Hmmm
09:39:15 <roconnor> Your probably can't even compare two different element with each other.
09:39:33 <roconnor> so.... I guess this will be pretty damned useless.
09:39:37 <roconnor> ... sorry.
09:39:42 <Philippa_> you can't, no
09:39:50 <Philippa_> the forall'd have to be on the list, not the individual elements
09:40:26 <roconnor> honestly, using Either (or making your own data type) is the way to go in this situation.
09:42:17 <palomer> you can't match on bottom, right...
09:42:28 <roconnor> Don't think so.
09:42:45 <eivuokko> You can't.  But explicit bottom tends to cause io exception
09:42:45 <roconnor> > undefined::Int == undefined::Int
09:42:46 <lambdabot>  parse error on input `::'
09:42:54 <roconnor> > (undefined::Int) == (undefined::Int)
09:42:55 <lambdabot> Undefined
09:43:24 <palomer> man, you guys are making my life a lot harder:P
09:43:49 <roconnor> In order to make your life easier, we will need more information on what you are trying to do.
09:44:10 <palomer> oh, I'm doing type inference
09:44:14 <palomer> with STRefs
09:44:16 <palomer> and I'm unifying
09:44:32 <eivuokko> Hmmm.
09:44:45 <palomer> and sometimes unification fails
09:44:47 <palomer> and I want to store it at the node
09:44:51 <palomer> looks like I'll have to tag again
09:45:00 * palomer gives up and starts learning template haskell
09:45:46 <palomer> TH let's you do stuff like taggedT = tag(T,Int) where T is a datatype, right?
09:46:02 * roconnor doesn't know TH
09:46:45 <franka> Why do you have refs to Bools in a type inference application?
09:46:45 <Philippa_> palomer: you want to store the fact unification failed at the node?
09:47:02 <Philippa_> Surely that just means you're doing references to some flavour of Either and life as normal?
09:47:24 <eivuokko> Wouldn't WriterT fit that?
09:47:39 <palomer> Philippa_: I would have to change a lot of code, an the Either would only apply to unification (which is only a small part of my program)
09:48:00 <Philippa_> how much is 'a lot'? IME type refactorings aren't too horrendous
09:48:30 <Philippa_> I guess you need an error handling strategy for whatever called your unify func, but you can always start by wrapping it with whatever failure looked like previously
09:49:10 <franka> If you are storing failed unifications, you probably want to use Maybe.  But probably what you want is to abort the whole computation outright, not to store them.
09:49:41 <Philippa_> I tend to recommend Either over Maybe, because it lets you store more context if/when you find a need
09:49:57 <roconnor> Just put it all in a monad and call error.
09:50:06 <roconnor> then you can decide later whether to use maybe or either ;)
09:50:09 <franka> You can use Either too, but Either X String not Either Int Bool.
09:50:25 <franka> X-->Int
09:51:10 <palomer> what about tagging with TH?
09:51:25 <palomer> @hoogle ExpQ
09:51:25 <lambdabot> Language.Haskell.TH.Lib.ExpQ :: Q Exp
09:51:25 <lambdabot> Language.Haskell.TH.ExpQ :: Q Exp
09:51:25 <lambdabot> Language.Haskell.TH.Lib.FieldExpQ :: Q FieldExp
09:51:28 <Philippa_> waaaaaaay OTT
09:51:32 <palomer> OTT?
09:51:36 <Philippa_> Over The Top
09:51:39 <palomer> @hoogle DataQ
09:51:39 <lambdabot> No matches found
09:51:46 <franka> Don't go using TH without a good reason.
09:51:47 <palomer> Philippa_: but it would also be useful elsewhere!
09:51:57 <palomer> it would also make my code simpler
09:52:06 <Philippa_> it feels a lot like using a tacnuke to cut your toenails
09:52:10 <Philippa_> how?
09:52:13 <Philippa_> what would you do with it?
09:52:26 <palomer> well, I have terms
09:52:34 <palomer> then I want to tag types ont my terms
09:52:40 <palomer> then I want to tag errors on to my types
09:52:49 <Philippa_> right. That's not a TH thing
09:53:01 <Philippa_> that's a "leave room for new fields" thing
09:53:27 <palomer> taggedTerms = tag(Term,Type) ; taggedType = tag(Type,Error)
09:53:27 <Philippa_> or even untagged and tagged types
09:53:34 <palomer> tagged types?
09:53:50 <Philippa_> data UntaggedTerm = ..., data TaggedTerm = ...
09:54:18 <franka> What is the point of tagging types with errors?  It will just propagate threw the entire term.
09:54:22 <franka> through
09:54:30 <palomer> Philippa_: but here's the deal, some parts of my program will use Term, and some parts TaggedTerm, and some parts TermsTaggedWithTaggedTypes
09:54:37 <Philippa_> franka: knowing where the error originated from?
09:54:44 <Philippa_> palomer: so what?
09:54:55 <Philippa_> the question is how far each bit needs to propagate and how you achieve that
09:55:05 <palomer> and some parts Type
09:55:08 <franka> But a type is not a place in a program.
09:55:17 <franka> A term is.
09:55:40 <palomer> franka: yeah, but the type is tagged onto the term
09:55:57 <palomer> Philippa_: propagate?
09:56:22 <Philippa_> palomer: spread from source to destinations, if you like
09:56:32 <franka> Then add a tag to the term, not the type.
09:56:45 <franka> Anyway, the type may be shared among terms.
09:56:54 <franka> Which has nothing to do with where the unification error occurs.
09:56:57 <palomer> franka: yeah, but unification acts on types, not terms
09:57:11 <franka> It acts on occurrences of types.
09:57:13 <franka> No on types.
09:57:16 <palomer> franka: yeah, these are type references
09:57:17 <franka> Not
09:57:40 <palomer> yeah, when I say types I mean typerefs
09:58:08 <franka> OK, perhaps that is sensible.
09:58:42 <palomer> how about this: datat Term = ... deriving (TagType)
09:58:48 <palomer> s/datat/data
09:58:53 <Philippa_> yerwhat?
09:59:01 <Philippa_> that doesn't make sense
09:59:09 <jdv79> is there a repository or directory or something for haskell libs/packages/frameworks/pick-your-favorite-flavor?
10:00:29 <palomer> yeah, guess not
10:00:48 <Philippa_> a HasTypeTag class might, admittedly
10:00:58 <Philippa_> but it looks like you're mostly just after records
10:02:01 <palomer> I don't want to end up with something like this: TLet (TParameter s,(TaggedTerm s)) (TaggedTerm s) (SType s)
10:02:15 <Philippa_> why not?
10:02:26 <Philippa_> you can always build accessors and constructors to make that easier to build
10:02:35 <Philippa_> large types aren't something to be scared of
10:02:49 <franka> I still think it is odd to store errors at type refs.  An error is not a property of a type occurrence.
10:03:37 <palomer> Philippa_: it doesn't make sense to have the part of my program which simply acts on simple terms have to deal with the tagging
10:03:43 <Philippa_> the nature of the error isn't perhaps, the fact there's no well-defined type occurrance at that position is
10:03:55 <palomer> Philippa_: the only other alternative is for me to write 5 different datatypes and the corresponding conversion functions
10:04:17 <Philippa_> which is the way to do it if you really really want to have it all as well-typed as you can manage
10:04:27 <Philippa_> failing that, use accessors to get just the terms
10:04:35 <palomer> franka: you have a point
10:05:16 <Philippa_> to rephrase that: terms hopefully have type occurrances but may not have a valid type
10:05:29 <palomer> righto
10:05:59 <palomer> yeah, I'll tag my errors onto my terms
10:06:41 <franka> Also the error depends on the algorithm.
10:06:52 <Philippa_> I'd suggest tagging the type|error onto the term
10:06:54 <palomer> Philippa_: so what you're suggesting is TaggedLet Term (Maybe TypeTag) (Maybe ErrorTag) ?
10:07:04 <Philippa_> franka: so you get a polymorphic Either, big deal?
10:07:29 <franka> No, I mean that the error depends on the order in which the algorithm does the inference.
10:07:31 <Philippa_> palomer: no, ditch the Maybes for (Either Type Error)
10:07:47 <Philippa_> franka: fair enough. Not sure how that affects the types used by the algorithm
10:08:17 <palomer> it would have to be (STRef s (Either Type Error)), since I'm doing the unification in ST
10:08:26 <Philippa_> palomer: no biggie :-)
10:08:48 <palomer> still, I don't like the Term parameter
10:08:57 <palomer> in fact, how does it propagate?
10:09:07 <franka> I would probably spit out a bunch of constraints, solve them separately, and then tag each constraint with an error.  That way at least the error involves both the types to be unified.
10:09:26 <Philippa_> franka: yeah, I'm leaning towards constraint-based approaches
10:09:45 <Philippa_> it'd be nice to have a better tutorial paper on them though
10:10:18 <palomer> TLet Term (STRef s (Either Type Error)) <---I'd want to tagging to propagate through Term, though
10:10:37 <Philippa_> palomer: one trick'd be to parameterise the Term type on any extra baggage being carried around
10:11:00 <palomer> oh, so this would be my toplevel Term, not my TaggedTerm
10:11:05 <palomer> so I'd have one datatype for everyone
10:11:23 <Philippa_> possibly, though if you actually parameterise it you actually get the entire family of possible tags out with a little hackery
10:11:29 <Philippa_> including the all-important "what tag?"
10:11:50 <Philippa_> the idea is that the child nodes're all of the parameter type rather than Term itself
10:11:51 <palomer> so toString :: Term -> String would call the function untag all the time, right?
10:11:58 <franka> I would change Term to Term a, and then define type inference on Term TermInfo where TermInfo = (SourceLoc, Maybe Type).
10:12:09 <franka> If you want to do it that way.
10:12:18 <Philippa_> exactly
10:12:32 <franka> And I would do it comonadically for fun.
10:12:42 <franka> :)
10:12:44 <palomer> franka: how does TermInfo work?
10:12:46 <Philippa_> sure, I like pain too :-)
10:12:54 <Philippa_> palomer: just a value
10:13:52 <palomer> so Term a = Let (Parameter a) (Term a) (Term a) a ?
10:14:52 <Philippa_> if Parameter needs to carry any info associated with terms as well, yeah
10:15:15 <Philippa_> (I assume that's intended to cover single-binding lets only?)
10:15:17 <franka> TermInfo is just all the extra "tags" you want for a term, like source info, types, strictness info, etc.
10:15:22 <palomer> Philippa_: yeah
10:15:29 <palomer> I'll add poly-binding lets later
10:15:44 <Philippa_> exactly. Which means you can forward- and back-propagate by adding or removing data to get different types as appropriate
10:16:05 <Philippa_> each stage only needs to see the info it understands
10:16:10 <palomer> but what would be the type of untag?
10:16:54 <franka> Or, actually, tyInfer :: Term a -> Maybe (Term (a,Type)) or something.
10:17:02 <Philippa_> you don't have untag, you have conversions between types you care about tagging with and you just ignore the tag outright if there isn't anything you care about
10:17:11 <vincenz> how do I get the first version of a darcs repo?
10:17:12 <Philippa_> (or use () or something)
10:18:28 <palomer> Philippa_: so my toString : Term -> String will simply ignore the extra parameter floating around
10:18:48 <robdockins> vincenz: darcs init ;)  All darcs repos start from the empty repository.
10:18:50 <franka> There is a library for type inference from UU, BTW.
10:19:04 <franka> Bastiaan Heeren
10:19:06 <palomer> UU?
10:19:11 <Philippa_> palomer: that, or attempt to show it or something, yeah
10:19:11 <franka> Utrecht University
10:19:13 <palomer> does it use STRefs or string substitutions?
10:19:24 <franka> I'm sure it uses refs.
10:19:45 <franka> It's focussed on producing good error messages.
10:19:51 <vincenz> robdockins: no I mena...I did a darcs get, I would like to look at the different versioins to see how it's changing, starting with version 1
10:19:58 <palomer> I've implemented inference twice before, I'm just trying to get a little funky at the moment
10:20:05 <palomer> what's UU btw?
10:20:30 <Philippa_> he said: Utrecht University
10:20:35 <palomer> oh, righto
10:21:11 <robdockins> vincenz: ah.  I'm not exactly sure.  I think the darcs cgi module supports this, but darcs itself doesnt.  Its a major wart in my opinon.
10:21:34 <palomer> franka: got a link?
10:21:39 <franka> http://www.cs.uu.nl/wiki/Top/WebHome
10:21:56 <robdockins> you might try rolling back patches one at a time (never done this so I'm not sure how to direct you)
10:23:35 <palomer> franka: are you talking about the helium type inference system?
10:24:02 <franka> It was used for implementing Helium, yeah.
10:24:20 <palomer> (since I don't see any other links on that page)
10:24:43 <franka> Look at the left-hand side bar.
10:25:40 <palomer> documentation?
10:25:53 * vincenz did "darcs init" "darcs add -r tests"
10:25:54 <vincenz> how do I now apply it?
10:26:19 <franka> Click the Software link.
10:27:00 <palomer> the cvs archive?
10:27:17 <franka> Do you see the link "Code documentation"?
10:27:22 <palomer> yeah
10:27:34 * SimonRC goes
10:27:37 <palomer> when I asked "documentation?", I meant "are you referring to the documentation?"
10:28:18 <franka> Oh, you mean because the CVS pages are empty...
10:29:48 <franka> Hm, I dunno.  I think it is just the web pages.  I have seen it in the CVS repository.
10:30:39 <franka> In fact, I have a local copy.
10:31:35 * palomer still thinks a solution which doesn't force me to change any existing code would be ideal
10:31:57 <franka> Life is tough. :)
10:32:22 <Philippa_> how many lines of existing code are there?
10:32:40 <Philippa_> usually it's not too bad if you can work out a simple transformation that does everything necessary
10:32:56 <Philippa_> I've done a fair amount of refactoring existing code
10:32:58 <franka> For these types of things you are usually better of in the long run shaping your code up anyway.
10:33:13 <Philippa_> yeah. The more you refactor the easier it gets, for one
10:33:27 <Philippa_> means you don't have to do as much complex stuff when you finally reach breaking point and have to
10:34:58 <palomer> but, like, what if I have refactor again in the future when I have a lot more code written
10:35:42 <Philippa_> then at least it's easier to do because there're fewer transformations to carry out
10:35:59 <Philippa_> also, the better-factored your code is, the less code needs refactoring to achieve an effect
10:36:25 <palomer> then again, using something like metaML or templateHaskell would mean that I would never have to refactor
10:36:40 <Philippa_> hah
10:36:45 <Philippa_> readability matters!
10:36:48 <palomer> or generic haskell
10:36:56 <Philippa_> GH doesn't do what TH does
10:37:04 <palomer> I'm sure I could hack it with GH
10:37:11 <franka> GH would not help you here.
10:37:19 <palomer> taggedTerm = Tag(Term,Type) seems quite reasonable to me
10:37:28 <Philippa_> you probably could if you were sufficiently determined. You'd be nucking futs to try it
10:37:38 <palomer> err, readable
10:37:41 <Philippa_> yeah, but you're the one complaining about all the boxing and unboxing
10:37:59 <palomer> Tag (Term,Type) deriving unbox
10:38:09 <Philippa_> point. head. whoosh.
10:38:14 <palomer> eh?
10:38:21 <kosmikus> I don't know what you're talking about, but Ralf Laemmel has at least written a paper about generic refactoring using an SYB-like approach.
10:38:28 <Philippa_> not the damn point. Oh, and less flexible than the parameterised approach
10:38:34 <kosmikus> probably not possible with the current GH implementation, though.
10:38:37 <Philippa_> you still need to sprinkle unboxes throughout your code
10:38:53 <franka> TH is a way to do pretty arbitrary transformations on abstract syntax.  It is not for this sort of thing.
10:39:11 <palomer> Philippa_: well, no, functions that deal with terms would deal with terms, functions that deal with TaggedTerms would deal with TaggedTerms, no boxing/unboxing required
10:39:25 <Philippa_> you mean aside from when you need to tag your terms?
10:39:42 <palomer> Philippa_: yeah, but tagging is involved anyways
10:39:44 <Philippa_> or when you need to untag them to pass output from a tagged func into an untagged one?
10:39:47 <palomer> and I already have code for this
10:39:58 <palomer> untagging is also involved
10:40:07 <palomer> actually wait, it isn't
10:40:10 <palomer> yeah, untagging would be derivable
10:40:23 <Philippa_> btw, the parameterised approach has a nice advantage: you don't need to untag, you just ignore it
10:40:29 <palomer> but that's fine, really, since I'll rarely have to untag
10:40:51 <franka> I think that if you had gone ahead and refactored when you started complaining about it you would be done by now. :)
10:41:02 <palomer> I'm thinking about the future!
10:41:18 <ADEpt> anyone tackled xml-based protocols? i'm interested in parsing/printing experiences ...
10:41:47 <Philippa_> for the future, the parameterised approach scales to when you have multiple flavours of tag
10:41:48 <franka> If you think about the future the next time you encounter this problem, you will short-circuit it.
10:44:16 <palomer> yeah, but what if I decide to tag my types?
10:44:23 <palomer> then I have to do the same refactoring again!
10:45:35 <franka> Do you expect to tag your types?
10:45:50 <palomer> I didn't expect to tag my terms!
10:46:09 <franka> Why not?
10:47:11 <franka> I am trying to get you to reflect on the process.
10:47:13 <palomer> why would I have?
10:47:27 <palomer> I wrote my parser so it simply outputs terms
10:47:33 <franka> Because terms have types.
10:47:45 <palomer> franka: but you can annotate terms with textual types
10:47:52 <palomer> that's fine
10:47:54 <palomer> (that I had done)
10:48:01 <franka> What is a "textual type"?
10:48:55 <palomer> a piece of text representing types
10:49:30 <palomer> like "a->a"
10:49:39 <palomer> I have a Qualified constructor for those
10:49:49 <palomer> however, in my first implementation of type inference
10:49:49 <franka> This is a bit out of left field.  Why are you mentioning this?
10:49:59 <palomer> I was doing it with string substitutions and poor error messages
10:50:11 <palomer> franka: you said "because terms have types"
10:50:20 <franka> It is extremely strange to represent types as strings.
10:50:37 <palomer> Terms were only meant to be an AST of the program
10:51:24 <franka> If you have a String attached to each Term, and you really want to, you can encode any old information there.
10:51:29 <franka> Of course, it will be untyped.
10:51:34 <franka> Which is why I would not do it.
10:51:54 <palomer> franka: I had optional type tagging with Qualified
10:52:21 <palomer> oh wait, I could add a constructor taggedWithTypeOccurence
10:52:29 <franka> That represents the expected type, I assume...?
10:53:00 <palomer> 5::Int would parse as Qualified (IntLit 5) (Tyvar "int")
10:53:34 <Philippa_> not Tycon "Int" or something similar?
10:53:51 <palomer> my types aren't parametric (yet)
10:54:19 <palomer> what do you guys think of a tagging constructor?
10:54:21 <Philippa_> yeah, but that doesn't make Int a Tyvar in normal terminology
10:54:27 <franka> OK, you could store types there if you wanted (the string thing is still odd, but...) but it would not be safe, and it would conflate expected types with inferred ones.
10:54:52 <franka> It wouldn't be safe because the datatype does not enforce that every term has a type.
10:54:52 <palomer> Philippa_: I see no difference between int and any other tyvar
10:55:23 <franka> But this isn't what we were talking about.
10:55:27 <palomer> oh, but Qualified doesn't have any effect with unification (except producing extra constraints)
10:55:57 <franka> My point was that to me it seems pretty forseeable that you would have types in your terms.
10:56:10 <franka> With experience, you see things like that.
10:56:15 <palomer> franka: for example?
10:56:23 <franka> If you think about the problem carefully.
10:56:28 <franka> For example what?
10:56:38 <palomer> when you say "types" do you mean "type occurrences" or "type annotations" ?
10:57:01 <Philippa_> it doesn't really matter which, once you realise you'll have extra data you can parameterise on what cheaply anyway
10:57:04 <franka> Type occurrences.
10:57:14 <Philippa_> (but yes, occurrences)
10:57:26 <palomer> well I didn't know that I would have sane error messages
10:57:39 <palomer> Philippa_: but annotations can be handled by a single constructor (since they're optional)
10:57:56 <franka> I would expect that Qualified would cause an error if it conflicted with the inferred type.
10:58:47 <franka> Anyway, concerning refactoring, I don't think it is such a big deal.
11:00:25 <franka> Usually it helps you think about the problem more carefully, and you end up changing more by the time you're done than you expected, and your program ends up even better.
11:00:50 <franka> Because as you're changing it you see more opportunities for abstraction.
11:01:19 <palomer> I could not have imagined that I would be forced to take this into consideration, since this certainly was not an initial goal
11:01:29 <palomer> @hoogle foldl
11:01:30 <lambdabot> Data.List.foldl :: (a -> b -> a) -> a -> [b] -> a
11:01:30 <lambdabot> Prelude.foldl :: (a -> b -> a) -> a -> [b] -> a
11:01:30 <lambdabot> Data.List.foldl' :: (a -> b -> a) -> a -> [b] -> a
11:01:33 <franka> Also, here, by adding a type parameter to Term, you are also opening up a slew of other possibilities.
11:01:58 <franka> With experience, you will see it.
11:02:34 <franka> Frankly, if I were writing your program, I would have seen this, but probably ignored it myself, on purpose.
11:02:59 <franka> And gotten a first, simple version working, then gone back and added the type parameter.
11:03:16 <franka> And then I would do the same again if I added kinds.  (This is why you might want to tag types, BTW.)
11:04:26 <franka> If you want to write a program which can stand up to any future changes whatsoever, you can forget it.
11:04:30 <franka> There are always limitations.
11:05:02 <franka> Refactoring is always necessary to some extent.
11:05:25 <franka> If you understand the problem well, you can avoid it all from the beginning.
11:05:38 <Philippa_> and if you don't, you do your best to make the refactoring easy
11:05:42 <franka> But if you change the problem, then obviously you may have to make a global change to the program.
11:05:45 <Philippa_> = no overcommitting on structure
11:06:02 <vincenz> how do I indentation-sensitive parsing with Parsec?
11:06:11 <Philippa_> vincenz: lex-and-parse
11:06:16 <Philippa_> two-layer, essentially
11:06:30 <vincenz> any examples floating around?
11:07:22 <Philippa_> vincenz: don't have one to hand
11:07:34 <vincenz> alright
11:08:12 * Philippa_ should possibly knock up some examples sometime
11:08:20 <Philippa_> and now is an instance of sometime ;-)
11:08:41 <palomer> why does emacs indent x <- foo \n y <- bar as x <- foo \n \t y <- bar ?
11:10:54 <franka> Isn't there an example of handling the offside rule in the Parsec manual?
11:11:06 <jethr0_> @seen dons
11:11:07 <lambdabot> dons is in #haskell-blah and #haskell. Last spoke 6 hours, 25 minutes and
11:11:07 <lambdabot> 7 seconds ago.
11:12:34 * jethr0_ added a (reasonably fast) pure version to the nbody wiki page: http://haskell.org/hawiki/NbodyEntry
11:13:59 <ADEpt> is there a HXT darcs repo somewhere?
11:14:48 <kevind> is there a Haskell function to make a product of functions? ie forall abcd. (a -> b) -> (c -> d) -> (a,c) -> (b,d)
11:16:18 <jethr0_> kevind: uncurry might help
11:16:32 <palomer> http://www.rafb.net/paste/results/XLkBdj86.html <--this puzzles me
11:16:46 <palomer> @type (,)
11:16:46 <lambdabot> forall b a. a -> b -> (a, b)
11:16:55 <jethr0_> @djinn (a -> b) -> (c -> d) -> (a,c) -> (b,d)
11:16:55 <lambdabot> Cannot parse command
11:16:55 <lambdabot> f :: (a -> b) -> (c -> d) -> (a, c) -> (b, d)
11:16:55 <lambdabot> f a b (c, d) = (a c, b d)
11:17:21 <palomer> @type zip
11:17:21 <lambdabot> forall b a. [a] -> [b] -> [(a, b)]
11:17:54 <palomer> @hoogle (a -> b) -> (c -> d) -> (a,c) -> (b,d)
11:17:55 <lambdabot> Data.Graph.Inductive.Query.Monad.(><) :: (a -> b) -> (c -> d) -> (a, c) ->
11:17:55 <lambdabot> (b, d)
11:18:03 <jethr0_> palomer: you gotta specify "s" over the class, don't you?
11:18:26 <jethr0_> i don't think haskell allows this: getTag :: c s -> (SType s)
11:18:31 <franka> The class says getTag returns SType s but your instance returns the a in Parameter a.
11:18:41 <palomer> jethr0_: it worked with my TaggedParameter
11:18:47 <jethr0_> hmm
11:19:25 <franka> Change it to getTag :: c s -> s
11:19:50 <jethr0_> does "=x" qualify as "SType a"?
11:20:49 * TuringTest look at the N-body code
11:20:59 <franka> BTW, the concept you are trying to define is a comonad.
11:21:30 <xerox> Who are 'they' ?
11:21:46 <franka> palomer
11:21:56 <jethr0_> xerox: they?
11:22:44 <palomer> I am?
11:23:02 <franka> I assumed xerox was asking who "you" is.
11:24:20 <palomer> tagging my type occurrences with terms would be a bad idea, right?
11:24:29 <Philippa_> not necessarily
11:24:41 <Philippa_> there's no reason beyond 'tedium' not to
11:24:47 <palomer> performance
11:25:02 <palomer> it will cause a quadratic increase in space requirements
11:25:08 <Philippa_> er, how?
11:25:16 <Philippa_> all you're storing is a reference back to the same ol' term
11:25:24 <Philippa_> you get one extra field, that's all
11:25:37 <palomer> well, occurence A will be annotated with the whole parse tree, then occurence B will bo annoted with the whole parse tree minus 1 node
11:26:08 <palomer> datatypes store pointers?
11:26:10 <franka> I would not do that, but I am not sure what you mean.
11:26:10 <Philippa_> yes, but you'll have evaluated enough of the whole parse tree to have that anyway
11:26:19 <Philippa_> they sort-of do on an implementation level, yes
11:26:27 <palomer> ahh, then it's ok
11:26:31 <Philippa_> values only get evaluated once however many places refer to them
11:26:37 <xerox> franka: how is it a comonad?
11:26:37 <palomer> I thought they copied the whole thing every time
11:26:56 <franka> The counit operation of a comonad is of type c s -> s.
11:27:10 <Philippa_> franka: just a backlink, as far as I can tell - "this type occurrance was inferred from that term"
11:27:18 <franka> (T,-) is a comonad for any T, and the counit is the projection.
11:27:32 <franka> That is the sort of decoration structure he was looking for.
11:27:37 <xerox> What is '-' there?
11:27:50 <franka> '-' is any type.
11:28:04 <franka> \x.(T,x)
11:28:17 <xerox> Is 'project' just another way to call counit, or does it have some deep meaning?
11:28:42 <xerox> projection, rather
11:29:04 <Philippa_> a projection of foo is "some part of foo", roughly speaking
11:29:05 <franka> By "projection" I mean the operations fst and snd, etc.
11:30:07 <xerox> Where does the tterm come from?
11:30:10 <xerox> term, even
11:31:17 <franka> I imagine it comes from the idea of projecting a 3D figure onto a 2D plane.
11:31:39 <franka> It has other uses in mathematics, though.
11:31:43 <xerox> Thanks for the explanations.
11:35:11 <palomer> @hoogle Maybe -> Bool
11:35:12 <lambdabot> Control.Concurrent.rtsSupportsBoundThreads :: Bool
11:35:12 <lambdabot> Data.Bool.False :: Bool
11:35:12 <lambdabot> Data.Bool.True :: Bool
11:35:24 <palomer> @hoogle (Maybe -> Bool)
11:35:24 <lambdabot> Control.Concurrent.rtsSupportsBoundThreads :: Bool
11:35:24 <lambdabot> Data.Bool.False :: Bool
11:35:24 <lambdabot> Data.Bool.True :: Bool
11:35:31 <palomer> is hoogle on crack?
11:35:35 <franka> Maybe a
11:35:41 <franka> You want the function maybe.
11:35:43 <ndm> @hoogle Maybe a -> Bool
11:35:44 <lambdabot> Data.Maybe.isJust :: Maybe a -> Bool
11:35:44 <lambdabot> Data.Maybe.isNothing :: Maybe a -> Bool
11:35:44 <lambdabot> Control.Concurrent.rtsSupportsBoundThreads :: Bool
11:35:47 <franka> @type maybe
11:35:48 <lambdabot> forall b a. b -> (a -> b) -> Maybe a -> b
11:35:53 <ndm> but yes, hoogle is on crack :)
11:35:55 <xerox> Is there an ascii-art-combinator for counit, like (>>=) is for bind?
11:35:57 <palomer> @hoogle isJust
11:35:59 <lambdabot> Data.Maybe.isJust :: Maybe a -> Bool
11:36:20 <Cale> counit is dual to return
11:36:39 <franka> Yes, it is.
11:36:50 <Cale> =>> or <<= are used for extend
11:36:56 <Cale> er
11:37:05 <Cale> cobind
11:37:11 * palomer goes blind
11:37:13 <franka> Oh, I didn't see you were replying to xerox.
11:37:31 <Philippa_> palomer: stop wanking about!
11:37:49 <xerox> Uh.
11:37:51 <Cale> hehe, IRC ought to have some sort of in-channel threading :)
11:37:58 <xerox> So...
11:38:36 <xerox> What is cobind type?  CoMonad c => c s -> (c s -> s) -> s  ?
11:38:43 <franka> Cale means >>=.
11:38:54 <franka> You could use =>>.
11:39:00 <Cale> >>= is bind
11:39:11 <palomer> @hoogle &&
11:39:12 <lambdabot> Data.Bool.(&&) :: Bool -> Bool -> Bool
11:39:12 <lambdabot> Prelude.(&&) :: Bool -> Bool -> Bool
11:39:12 <lambdabot> Control.Arrow.(&&&) :: Arrow a => a b c -> a b c' -> a b (c, c')
11:39:24 <franka> Oh, I thought you were talking about bind.
11:39:51 <Cale> sorry, I missed a 'co'
11:39:57 <palomer> http://www.rafb.net/paste/results/sF5Pjg73.html <---do you guys see anything wrong with this?
11:39:58 <xerox> ok
11:39:59 <franka> No, I missed it. :)
11:40:00 <Cale> and said 'extend'
11:40:12 <xerox> c s -> (c s -> t) -> t ?
11:40:44 <xerox> c s -> (s -> c t) -> t ?
11:40:46 <franka> d a -> (d a -> b) -> d b
11:40:52 <xerox> ah-ha.
11:40:52 <Cale> palomer: put the  line up the then and else
11:41:00 <integral> f [] xs = xs; f ys _ = ys -- is there some library function that does this?
11:41:02 <Cale> put the 'then' on the next line
11:41:03 <xerox> That would have been my next try.
11:41:08 <Cale> (hit enter too soon)
11:41:08 <xerox> I see.
11:41:43 <Cale> palomer: though I'm not sure about that
11:42:31 <Cale> palomer: (the layout looks mostly good)
11:43:07 <maus> Hello, anyone. I have a question
11:43:16 <palomer> moving the 'then' doesn't change anything
11:43:31 <jethr0_> maus: yes
11:43:33 <maus> Say i have a rose tree with weighted nodes. 
11:43:48 <maus> Weights are increasing on the way from root to leaves.
11:44:03 <maus> I want to enumerate the nodes in order of increasing weights
11:44:16 <xerox> Flatten it, and sort?
11:44:34 <maus> it is a huge tree
11:44:55 <xerox> Don't you have to traverse it all to get the first element of your list?
11:45:01 <maus> i want to use the fact of monotone increasing of weights
11:45:21 <maus> the first element is root
11:45:54 <franka> Is there a relationship between branches?
11:45:57 <xerox> ?
11:46:09 <palomer> Cale: line up?
11:46:17 <xerox> Ah, the list is in descending order.
11:46:20 <xerox> Err, ascending.
11:46:25 <Cale> if ...
11:46:27 <Cale>    then ...
11:46:27 <maus> xerox: yes
11:46:32 <Cale>    else ...
11:48:16 <xerox> Then franka's question is the most pertinent one.
11:48:16 <Cale> otherwise, I don't see any problem there
11:48:16 <palomer> Cale: the then is flush with the if (emacs won't have it any other way)
11:48:17 <maus> which kind of relationship?
11:48:17 <maus> they have common root
11:48:17 <Cale> palomer: turn off smart indenting as it's quite annoying :)
11:48:17 <Cale> I have no idea why that smart indenter does the things it does
11:48:17 <palomer> so you want the then 2 spaces past the if ?
11:48:17 <Cale> the simple indenter is usable though
11:48:22 <franka> So the weights are not related except that they are less than the predecessor's.
11:48:32 <Cale> if (isNothing x) && (isNothing y)
11:48:33 <palomer> oh yes, that works
11:48:34 <maus> franka: exactly
11:48:39 <Cale>    then return Nothing
11:48:47 <Cale>    else return $ Just "arrow error"
11:49:16 <palomer> yeah, that works
11:49:21 <palomer> putting then flush doesn't
11:49:23 <palomer> very strange
11:49:33 <Cale> oh
11:49:34 <Cale> if you do
11:49:38 <Cale> if blah
11:49:39 <Cale> then foo
11:49:42 <Cale> else bar
11:49:55 <Cale> then that puts the then and else at the same level as the if
11:50:05 <Cale> so semicolons will be inserted between them
11:50:06 <franka> Then you just do a breadth-width enumeration.
11:50:11 <palomer> which is fine, no?
11:50:13 <Cale> no
11:50:15 <TuringTest> maus: So you start part way though a heap sort.  An efficient thing to do is pop the root nodes and promote a daughter node (recursively: log n steps) for each of the n node: total is n log n
11:50:16 <franka> Er, breadth-first.
11:50:24 <Cale> they all have to be part of the same expression
11:50:37 <Cale> if-then-else is a single expression
11:51:22 <Cale> what do people think of the MR discussion going on the haskell' list?
11:51:55 <Cale> personally, I see these solutions as way too extreme
11:52:36 <ADEpt> are there any SAX-style XML parsers/processors for Haskell out there?
11:52:37 <franka> Er, yes, breadth-first would be wrong.
11:53:02 <jethr0_> ADEpt: i got to factor two of the fast haskell version
11:53:13 <jethr0_> factor 6 or so of C
11:53:22 <maus> franka: because we should choose the correct branch after each move...
11:54:08 <franka> No, because a grandchild on one branch may be smaller than a child on another.
11:54:21 <ADEpt> jethr0_: so, your are actually profiling on your own? :)
11:54:52 <jethr0_> well, after fixing the space leak i changed sth and afterwards didn't need my fix anymore?!?!
11:55:18 <jethr0_> i'm rather timing than profiling. still no idea how anyone can productively find bottlenecks in haskell
11:56:03 <jethr0_> i only have one little `seq` left in my code and that's only responsible for a in 10% speedup
11:56:10 <jethr0_> haskell is weird when it comes to space leaks
11:56:56 <Cale> jethr0_: the most important thing is to think of computations in terms of demand
11:57:13 <vincenz> why would one use happy vs parsec?
11:57:17 <palomer> Cale: I have a function showType which returns a MonadSupply. my terms are annotated with types, how can I use this showType to create a showTerm?
11:57:26 <jethr0_> sure, i'm all with you there. but once you know you've got a leak, i don't know how to pinpoint it to the line/column/expression
11:57:31 <xerox> vincenz: first one would ask on #haskell, then he would chose Parsec
11:57:48 <vincenz> xerox: ?
11:57:58 <vincenz> xerox: they're both haskell libs, and this iis #haskell
11:58:01 <xerox> vincenz: j/k, in fact Parsec is handier, consisting in Haskell code, instead of annotated something to be translated and so on.
11:58:08 <Cale> jethr0_: well, it's difficult because often it's not really constrained to happening at any one line
11:58:13 <vincenz> so why are people working on happy
11:58:22 <Cale> palomer: that question is kind of general :)
11:58:26 <xerox> vincenz: because it could be useful at times.
11:58:33 <Cale> palomer: you want to show the type alongside the term?
11:58:46 <jethr0_> Cale: hmm. i will continue to look for some kind of algorithm to put constrains on the leak. just adding random strictification doesn't seem all that hot!
11:58:50 <Cale> you'd just call it from the do-block in which you're composing showTerm
11:58:59 <Cale> jethr0_: yeah
11:58:59 <palomer> Cale: yeah
11:59:04 <xerox> yeah!
11:59:20 <palomer> Cale: but showTerm has a little bit of context which needs to be propagated
11:59:52 <Cale> jethr0_: the right way to fix leaks a good deal of the time, is not making things more strict, but composing the algorithm such that it demands less of the input in order to produce the first part of the output
11:59:57 <palomer> oh, that's fine, the context is there
12:00:48 <maus> franka: I can an write imperative version. But what about a functional approach?
12:00:51 <palomer> hrm, I guess I'll use my stt function which has type
12:01:07 <xerox> Imperative is a subset of functional :-)
12:01:07 <palomer> http://www.rafb.net/paste/results/oCwSDz43.html
12:01:08 <Cale> jethr0_: when you really can't do that -- i.e. you're converting some huge structure into a small structure by combining all the parts of the large structure in some way, you really must add strictness.
12:01:12 <jethr0_> Cale: i guess it pretty much comes down to gaining experience with haskell, and _knowing_ what's going wrong
12:01:26 <maus> franka: problem seems to be rather common
12:01:29 <franka> Didn't TuringTest give you an answer, maus?
12:01:50 <Cale> My heuristic table is like this:
12:01:52 <jethr0_> cale: because the heap profiling tools only helped me further to a limited extent.
12:02:03 <Cale> small -> small : lazy
12:02:06 <Cale> small -> large : lazy
12:02:10 <Cale> large -> large : lazy
12:02:16 <Cale> large -> small : strict
12:02:29 <jethr0_> i've seen that on your tmr work-in-progress page, haven't i?
12:02:37 <Cale> possible
12:02:39 * TuringTest hears his name
12:02:39 <Cale> y*
12:03:05 <jethr0_> Cale: but sometimes you don't need lazyness. i.e. when you know you'll need all the input
12:03:05 <Cale> and that last one is qualified with "only when you're eating the whole large structure, not when you're searching it"
12:03:18 <Cale> right, that's the last case there
12:03:39 <Cale> sometimes laziness is right *even if* you know you'll need all the input
12:03:48 <Cale> because it lets you produce some of the output sooner
12:03:53 <eivuokko> Not just sometimes, very often, imo.
12:03:54 <jethr0_> hmm
12:04:02 <Cale> yeah, quite often
12:04:29 <jethr0_> and lazyness let's you write cleaner separation of iteration and mechanism, often
12:04:35 <Cale> You want to look at the first piece of your output and think "what do I need to compute in order to calculate this"
12:04:51 <Cale> and make sure that nothing more is actually being computed
12:05:49 <Cale> that's often a big cause of space leaks
12:06:23 <Cale> and what people end up doing instead is adding strictness annotations to let them think about the problem like a strict language, but I don't think that's quite right
12:06:46 <maus> TuringTest: Do i need a mutable tree for it? Or i misunderstood you?
12:07:06 <Cale> there are cases where you really need strictness, but they're actually fairly rare
12:07:41 <TuringTest> maus: Your new trees would share nodes with the old tree, except for those where you sift up the new smallest element from
12:07:51 <Cale> even then, it's usually better to get the strictness via some higher order function like foldl' than to have to apply it yourself.
12:08:21 <jethr0_> Cale: i just wrote a version of the nbody shootout problem. and in my first version had a _huge_ space leak because objects from former iteration steps weren't freed
12:08:34 <Cale> right
12:08:34 <jethr0_> i don't see how i could've fixed that
12:08:50 <TuringTest> maus: OR you could make a mutable type the basis of the intermediate nodes while you deconstruct the main tree
12:09:07 <jethr0_> Cale: http://paste.lisp.org/display/16119
12:09:40 <jethr0_> Cale: i fixed it first adding a single strictness rule to evaluate all "bodies". and later i didn't even need that, for some weird reason
12:09:49 <maus> TuringTest: Where can i read about it?
12:09:56 <jethr0_> it just can be hard to cope with these things if you don't understand _why_ they occur
12:10:13 <TuringTest> maus: google for "heap sort" for the general idea
12:10:34 <jethr0_> sorry for all the cost centers BTW
12:10:43 <TuringTest> Your nodes have more than 2 children but the concept is the same
12:10:55 <Cale> jethr0_: well, I take it your solution is the $! ?
12:11:06 <maus> TuringTest: thanks for an idea
12:11:10 <Cale> (to the leak)
12:11:21 <Cale> or does that code leak as-is?
12:11:33 <jethr0_> Cale: no that's the version without solution.
12:11:56 <jethr0_> solution was "addDelta body@(Body pos vel _) dvel = body `seq` (body {b_vel = newVel, ...)", i think
12:12:18 <jethr0_> but i don't understand what's going on there...
12:12:22 <Cale> ah, yeah, that might help
12:12:39 <Cale> because the new body is getting defined in terms of the previous one
12:12:43 <Cale> but still not being evaluated
12:13:09 <jethr0_> Cale: *aaahh*. that makes sense
12:13:13 <Cale> the only bod(y/ies) which get evaluated are the last ones which get printed out
12:13:25 <jethr0_> so in effect i was keeping all previous bodies till the very end or sth like that
12:13:27 <Cale> and then that forces demand backwards to all previous steps
12:13:30 <Cale> yep
12:13:48 <Cale> it's only pointers, and little graph structures, but that can still add up
12:13:54 <jethr0_> so, is this a case where strictness makes sense? and how could one have found this out without staring at the code?
12:13:56 <Cale> if you have lots of iterations
12:14:01 <jethr0_> millions
12:14:20 <Cale> well, if I'd written it, it would be easier to find :)
12:14:28 <jethr0_> haha
12:14:39 <jethr0_> no, i mean using heap profiling or sth
12:15:17 <Cale> oh, yeah, you can just use ordinary profiling and see what things are using up all the memory or doing lots of allocations
12:15:41 <Cale> (more important is using lots of memory)
12:16:03 <Cale> did you have some profiling output?
12:16:05 <jethr0_> i just found out that "advance" used up everything. but i never got much more finer grained than that. then stuff was only name "Main.abd 23423"
12:16:27 <Cale> oh, yeah
12:16:44 <Cale> you'd want to add cost centres to all the bindings in advance's where clause at that point
12:16:53 <jethr0_> jethr0.dyndns.org/current/a.out.ps
12:17:03 <jethr0_> i did
12:17:22 <Cale> the graphs are pretty, but less useful than the textual reports
12:17:28 <Cale> (often)
12:18:22 <jethr0_> hmm.
12:18:44 <jethr0_> so, you'd have added cost centers to all functions defined in "advance"'s where clauses, right?
12:18:52 <Cale> yeah
12:19:12 <Cale> that's a good start anyway
12:20:05 <jethr0_> hmm, and than playing around with -hr -hc, ...?
12:20:12 <Cale> I don't seem to write much code that needs heavy profiling, probably because it's usually not that performance-critical.
12:20:32 <Cale> so most of my profiling experience comes from helping other people profile their code :)
12:20:51 <Cale> I usually just look at the .prof
12:21:06 <Cale> and find where the percentages are large
12:22:01 <jethr0_> ok, and then you find the worst function. and the worst subfunction, etc.
12:22:19 <jethr0_> but at some point you have to stare at the code and reason it out, right?
12:22:37 <Cale> well, yeah
12:22:47 <Cale> really, the cost centres don't give the whole story
12:23:09 <Cale> you have to actually look at what's going on at some point
12:24:01 <jethr0_> ok, so i'll have to try a little more, until i start seeing the problematic areas right away. even better would be not writing problematic code in the first place :)
12:24:39 <Cale> so here's an example of turning a large structure into a small one in a kind of abstract way :)
12:24:50 <jethr0_> so code of the style "object {param = value}" will keep the object on the heap until evaluation is demanded, right?
12:25:05 <Cale> yep
12:25:14 <Cale> any definition
12:25:19 <Cale> not just like that
12:26:06 <Cale> If I write c = a + b, then a and b won't get deallocated until c is forced
12:26:15 <jethr0_> sure, but in this case i hadn't thought about it :)
12:26:17 <Cale> (they also might not get allocated until then)
12:27:15 <Cale> however, the parts of  object  which have been replaced might get deallocated
12:27:25 <jethr0_> i actually wrote a raytracer, and was astonished that it could start printing the image before all point were evaluated. that tought me to think more demand oriented :)
12:27:40 <jethr0_> taught
12:27:46 <Cale> yeah
12:27:52 <Cale> a raytracer is a perfect example
12:28:18 <Cale> my scheduler was a good one
12:28:29 <jethr0_> you pretty much only explain how data gets from A to Z. but the actual machinery is only started on demand
12:28:34 <Cale> right
12:29:23 <Cale> so optimising that machinery means looking at the actual data flow, and considering how long various things will be needed.
12:29:57 <Cale> lists alone are really interesting in this regard -- there are lots of ways that they can depend on each other
12:30:21 <Cale> The ideal way for lists to depend on one another is for one to be a 'map' of the other.
12:30:30 <jethr0_> yup
12:31:00 <Cale> but if you can't get that, often it's possible to take small chunks of the first list in order to produce single elements, or small chunks of the second
12:32:11 <Cale> this often happens in the list monad, when a bunch of your options fail, but you eventually find one which lets you produce some output
12:34:58 * ADEpt looks for haskell+xml experience
12:35:40 <Cale> jethr0_: did you read whyfp?
12:36:07 <jethr0_> Cale: i think so
12:37:04 <Cale> I really like the examples of numerical computations in it
12:37:40 <jethr0_> i'll look it up once more
12:38:04 <jethr0_> with haskell papers, i always can go back to them. because i always seem to miss important parts :)
12:38:19 <araujo> Anybody knows what is a good way to implement concurrency in haskell?, any example?
12:38:53 <Cale> araujo: Implement concurrency as in writing your own thread manager and implementing concurrency primitives?
12:39:11 <Cale> araujo: or do you just mean how to use GHC's concurrency stuff?
12:39:24 <tibbe> could anyone find any reasons to choose either (Lam [Id] Expr) or (Lam Id Expr) as abstract syntax for lambdas. The second make partial application super easy, are there some reasons to use the first?
12:40:03 <araujo> Cale, how to use GHC's concurrency
12:40:16 <araujo> Cale, i mean, everything points me to forkIO
12:40:20 <palomer> tibbe: what is your target grammar?
12:40:20 <Cale> tibbe: I probably wouldn't use the first. It might be closer to some concrete syntax for lambdas though (like Haskell's)
12:40:34 <araujo> Cale, nevertheless, i don't seem to get parallel execution of processes with it-
12:40:41 <Cale> araujo: right, forkIO creates threads
12:41:01 <Cale> @type Control.Concurrent.forkIO
12:41:02 <lambdabot> IO () -> IO GHC.Conc.ThreadId
12:41:26 <tibbe> Cale and palomer, I'll bind lambdas to identifiers in function declarations, such as: map f xs = expr   which i translate into (Bind Id Expr)
12:41:39 <Cale> applying forkIO to a computation will cause it to get run in a new lightweight thread
12:41:52 <tibbe> either I get a number of nested lambads or one with a list of vars
12:42:07 <araujo> Cale, It is correct to assume the following:   forkIO (task1) >> forkIO (task2) >> task3 , in which all three tasks are executed in parallel?
12:42:07 <Cale> tibbe: go with the nested one, I think
12:42:37 <Cale> araujo: well, yeah, unless one task is really short
12:42:42 <tibbe> Cale, I was thinking that some of the structure is lost if I later want to pretty print the AST
12:42:51 <Cale> also, you should be careful that your main thread doesn't finish
12:43:03 <Cale> tibbe: oh, that's true
12:43:13 <araujo> Cale, Right, i read about it too, all threads depend upon the main thread.
12:43:25 <tibbe> Cale, it would be nice if I could go source -> ast -> source
12:43:59 <Cale> yeah, but how far do you want to preserve that information?
12:44:07 <palomer> how do you get the inverse of a Map as a [(v,k)] ?
12:44:23 <xerox> map (snd &&& fst) . toList
12:44:36 <tibbe> Cale, dunno, just looking for some input, I saw that in Language.Haskell.Syntax they use the [] form
12:44:38 * xerox wins something?
12:44:49 <palomer> 10 banana bucks
12:45:01 <Cale> tibbe: oh, right, that's because the primary issue there is pretty printing
12:45:02 <xerox> Yeah!
12:45:21 <tibbe> Cale, so it can be compiled later?
12:45:36 <tibbe> Cale, but there's a parser there as well
12:45:54 <Cale> you'd probably do something like  source -> parse tree -> more refined ast -> ... -> code
12:46:29 <Cale> where you might keep references back into the parse tree there so as to be able to pretty print thing
12:46:29 <Cale> s
12:47:02 <tibbe> Cale, also, I was thinking about error messages: if the user writes, add x y = x+ y and I report: there's an error in add = \x \ y x+ y that won't be as nice
12:47:22 <tibbe> hmm, that'd be one way to solve it
12:47:46 <Cale> of course, references are the same as values :)
12:48:02 <tibbe> ?
12:48:47 <Cale> due to sharing, you could just outright copy parts of the source tree into your more refined structure and not worry about the fact that the memory consumption looks like it should be huge
12:48:59 <Cale> since those will really be pointers back into the original tree
12:49:15 * tibbe always forgets to mention that
12:49:18 <tibbe> true
12:49:40 <tibbe> don't mind the half-of-an-emote
12:51:03 <tibbe> it seems like there's no way to distinguish, foo a b = \c -> a + b + c from foo a b c = a + b + c without keeping some of the source
12:51:24 <tibbe> since both are converted into a \a\b\c lambda
13:11:30 <jyp> @quote
13:11:30 <lambdabot> blackdog says: I'm not encouraged by the comment "i don't know haskell,
13:11:30 <lambdabot> but CL is much better", though. it doesn't suggest careful thought and
13:11:30 <lambdabot> objectivity...
13:22:26 <tibbe> Anyone know if there's a hs2(x)html generator that I could use to put code on my website?
13:22:54 <tibbe> Like this: http://www.cs.chalmers.se/Cs/Grundutb/Kurser/progs/exercises/week2/Problem3.html
13:23:39 <palomer> is there a general framework for mixing State and ST?
13:24:00 <Cale> well, you can only do it one way
13:24:11 <palomer> is there a StateST monad?
13:24:18 <Cale> not by default
13:24:31 <Cale> but there is a StateT st (ST s) monad
13:24:52 <palomer> wouldn't you need a ST s (StateT st) monad?
13:25:17 <Cale> you can't mix it the other way
13:25:32 <Cale> though it would be cool to have an ST monad transformer, it doesn't exist
13:26:12 <palomer> is there a good reason for this?
13:26:43 <Cale> I'm not sure.
13:26:54 <Cale> It doesn't appear that there's a great reason for it
13:29:20 <Cale> hmm, odd
13:29:42 <tibbe> anyone willing to critique some code (55 LOC), please?
13:30:06 <Cale> I can't seem to replicate the unnecessary evaluation situations you're supposed to get without the monomorphism restriction, even after turning it off
13:30:18 <Cale> perhaps I'm doing something silly
13:30:37 <Cale> tibbe: paste it somewhere and give us a link :)
13:31:18 <tibbe> Cale, http://www.itstud.chalmers.se/~larssont/Main2.hs
13:31:45 <tibbe> Cale, I'm mostly concerned about the apply function, I'm trying to save then environment to do closures but I'm not sure I'm doing it right.
13:33:10 <kevind> Hey Cale, I figured out what was wrong with my program.  Using the default instance of Ord for a datatype was causing Map.insert to hang
13:33:22 <Cale> kevind: oh!
13:33:47 <Cale> kevind: which type?
13:33:58 <kevind> TSPath
13:34:16 <palomer> @hoogle &&&
13:34:17 <lambdabot> Control.Arrow.(&&&) :: Arrow a => a b c -> a b c' -> a b (c, c')
13:34:24 <Cale> shouldn't the default instance of Ord always be a total ordering?
13:34:38 <kevind> As far as I can tell all the hereditary constituents were elements of Ord, but it didnt work
13:34:49 <kevind> same thing happened before with Eq
13:34:50 <Cale> kevind: very odd
13:35:02 <kevind> I had to define my own functions, the default ones cause stack overflow
13:35:16 <tibbe> Cale, I was also thinking that there might be some variable name changing issues (in beta reductions=
13:35:27 <Cale> perhaps there's an instance of Ord for one of the consituents which doesn't give a total order?
13:35:34 <Cale> tibbe: I'll have a look
13:35:42 <tibbe> Cale, Thanks.
13:36:44 <kevind> the only non-datatype constituent was thread id, and I assume its Ord instance gives a total order
13:39:24 <gzl> has there been any talk on haskell-prime about removing laziness? some guy in #python is claiming that's the case but it sounds absurd.
13:40:09 <kevind> what is the advantage of having everything be lazy?
13:40:11 <eivuokko> Only removing ~ patterns, if that counts.
13:40:24 <eivuokko> (unless I missed something)
13:40:27 <gzl> I'm not sure what ~ patterns are.
13:41:46 <Cale> tibbe: this is looking good to me so far :)
13:41:57 <Cale> btw,
13:42:16 <Cale> show (Fun i e env) = "<function: \\" ++ i ++ " -> " ++ (show e) ++ " | " ++ (show env) ++ ">"
13:42:26 <Cale> is handy :)
13:43:20 <Cale> oh
13:43:35 <Cale> hmmm...
13:44:19 <Cale> no, that looks right :)
13:44:56 <Cale> palomer: have a look :)
13:45:16 <palomer> http://www.rafb.net/paste/results/ozGxwg69.html  <--/me is puzzled
13:45:59 <palomer> Cale: showTerm (Lam s t _) = "(\\"++(showParameter s)++" -> "++ (show t) ++ ")"
13:46:12 <tibbe> Cale, the combining of two environments look okay also?
13:46:35 <tibbe> Cale, I really should write some QuickCheck generators for it
13:46:38 <Cale> palomer: Just y -> do taggedTerm <- tagExistentials {- need a parameter here -}
13:47:04 <palomer> oh, now I can't match IO against ST
13:47:35 <Cale> oh right, you'll have to do that part inside the runST
13:47:57 <Cale> tibbe: it looks correct to me
13:48:08 <Cale> and quite pretty, I might add
13:48:27 <Cale> almost certainly the prettiest way I've seen to implement a lambda evaluator :)
13:48:50 <Cale> (though you should eventually replace the Env type with something like a Map
13:48:52 <palomer> a look at what?
13:49:14 <Cale> palomer: http://www.itstud.chalmers.se/~larssont/Main2.hs
13:49:24 <tibbe> Cale, Yeah, the [()] is just temporary
13:49:46 <tibbe> Cale, and thanks. :)
13:50:17 <palomer> yeah, nice job
13:50:25 <Cale> I'd thought of using Reader for that before, but never actually done it. The result is quite clean.
13:50:29 <palomer> apply is done with substiution?
13:50:51 <palomer> what does local do?
13:50:58 <Cale> palomer: the only sustitution is done in Var
13:51:04 <Cale> (the eval for Var)
13:51:09 <palomer>              Just y -> print $ runST $ do taggedTerm <- tagExistentials y 
13:51:09 <palomer>                                           typedTermToString taggedTerm []
13:51:15 <Cale> local applies a function to the environment locally
13:51:36 <palomer> oh, I see
13:51:37 <palomer> very nice
13:51:41 <tibbe> yeah, that's the part I'm uneasy about
13:51:49 <palomer> however, you'll get capture
13:51:51 <palomer> I think
13:52:05 <tibbe> I'm trying to combine a saved env with the current plus a new binding, can there be overlap between the saved and current env?
13:52:06 <Cale> It seems to work even with messy cases with shadowing vars
13:52:33 <palomer> (\x -> \y -> x) y <--what does it return on this input?
13:53:21 <palomer> http://www.rafb.net/paste/results/sHQZ4654.html  <--/me is still puzzled
13:54:16 <tibbe> palomer, I tell you as soon as I success in matching the brackets in the AST expression....
13:54:26 <tibbe> runReader (eval (App (Lam "x" (Lam "y" (Var "x")))) (Var "y") ) []
13:54:32 <tibbe> anyone see the missing paran?
13:54:42 <Cale> *Main> runReader (eval (App (Lam "x" (Lam "y" (Var "x"))) (Var "y"))) []
13:54:42 <Cale> <function: \y -> x | [("x",*** Exception: Maybe.fromJust: Nothing
13:55:14 <Cale> of course, it doesn't allow variables as values
13:55:29 <tibbe> y is not bound
13:55:30 <tibbe> it strict
13:55:30 <tibbe> it is*
13:56:03 <palomer> oh, righto
13:56:06 <palomer> then this method works
13:56:17 <palomer> probably the nicest solution too
13:56:35 <tibbe> runReader (eval (App (Lam "x" (Lam "y" (Var "x"))) (Var "y")) ) [("y",(Num 2))]
13:56:35 <tibbe> <function: \y -> x | [("x",2),("y",2),("y",2)]>
13:56:55 <tibbe> :) well, I'm past my bed time, thanks for the help, both of you
13:56:59 <palomer> np
13:57:17 <tibbe> good night
13:57:21 <Cale> night
13:57:24 <palomer> hrm
13:57:29 <palomer> mixing monads is hard work
13:57:38 <Cale> it can be
13:58:36 <palomer> Cale: any idea about my problem?
13:58:43 <Cale> you appear to be doing some pretty crazy stuff already -- for me it's sort of backwards looking to say that the mixing monads is the hard part. :)
13:58:52 <palomer> http://www.rafb.net/paste/results/sHQZ4654.html
13:59:00 <Cale> oh
13:59:04 <Cale> can't use $ with runST
13:59:09 <palomer> yeah, this stuff is pretty nuts
13:59:13 <Cale> runST (do ...
13:59:16 <Cale> )
13:59:30 <Cale> that's because runST's type is higher rank
13:59:38 <Cale> so $ doesn't work
13:59:45 <palomer> whoa, it works
13:59:59 <Cale> first time running? :)
14:01:49 <SamB> $ not working for that is a pain :-(
14:02:05 <Cale> it is
14:02:06 <SamB> that is exactly the kind of place where you most want to use $, after all!
14:02:11 <Cale> right
14:02:17 <palomer> I agree
14:02:25 <Cale> there are various situations involving existentials which are similar in that regard
14:03:01 <SamB> yeah. I'm not sure I think using them for this particular purpose is good...
14:03:07 <Cale> I'm not really sure how to fix it apart from turning $ into syntax, which seems cruel and unusual
14:03:28 <SamB> I definately want to keep away from that ;-)
14:03:49 <Cale> there ought to be some kind of rank-polymorphism
14:04:00 <Cale> it's certainly obvious what is meant there
14:04:07 <SamB> hmm
14:04:29 <SamB> yes, quite!
14:05:11 <SamB> $ has but one implementation; expand it and that is what is meant...
14:08:05 <Philippa_> would that require impredicativity?
14:08:21 <xerox> f $ x = f x
14:08:25 <Cale> I frankly don't know what it would require
14:08:40 <roconnor> ($) f x = f x
14:08:42 <xerox> Why doesn't it work with runST ?
14:08:55 <Philippa_> (if so, you'd have a problem with variance and subsumption - GHC and similar implementations need the subsumption rules to be invariant)
14:08:55 <Cale> because the type of runST is screwy :)
14:09:04 <Philippa_> roconnor: now write the type out
14:09:10 <SamB> @type Control.Monad.ST.runST
14:09:10 <Cale> @type Control.Monad.ST.runST
14:09:11 <lambdabot> forall a. (forall s. GHC.ST.ST s a) -> a
14:09:11 <lambdabot> forall a. (forall s. GHC.ST.ST s a) -> a
14:09:23 <xerox> Screwy?
14:09:30 <Cale> it's higher rank
14:09:39 <roconnor> ($) :: (forall a. forall b. (a -> b) -> a -> b)
14:09:42 <Cale> it requires its parameter to be polymorphic
14:09:58 * araujo next to give a try
14:09:59 <roconnor> ah
14:10:03 <Philippa_> right, so the problem's predicativity
14:10:16 <SamB> strange rank system they've got here
14:10:17 <Cale> will boxy types fix this?
14:10:18 <Philippa_> a can't be instantiated to forall s...
14:10:22 <SamB> usually higher ranks come with more priveleges
14:10:24 <Philippa_> they can in some implementations
14:10:26 <Philippa_> they can't in GHC
14:10:32 <roconnor> the problem is that the type parameters to polymorphic functions are alywas implicit
14:10:38 <Philippa_> at least, assuming I've understood the current paper correctly
14:10:43 <Philippa_> that's the variance problem I'm talking about
14:11:09 <Philippa_> roconnor: no. The problem is that you can't instantiate a type variable to a polytype. Implicit or explicit's irrelevant
14:11:41 <SamB> why not?
14:11:41 <Cale> It's such an annoying issue because it's something so small, and it's unclear that there are many larger cases where it would matter so much. I suppose if people start using lots of existential types, it could become a larger problem.
14:11:53 <SamB> @kind (forall a. forall b. (a -> b) -> a -> b)
14:11:53 <Cale> er
14:11:54 <lambdabot> *
14:12:02 <Cale> not existential types, higher rank types
14:12:02 <Philippa_> SamB: because that's how the existing rank-n implementation works
14:12:04 <SamB> @kind forall a. (forall s. GHC.ST.ST s a) -> a
14:12:05 <lambdabot> *
14:12:23 <Philippa_> Cale: yup. JHC's implementation allows the less restrictive variance rules
14:12:32 <Cale> oh, neat
14:12:41 <Cale> How is JHC these days?
14:12:54 <Cale> I really ought to get it and try it
14:12:56 <Philippa_> (that isn't to say its typechecker allows it, just that the implementation of the back end doesn't prohibit it)
14:13:12 <Cale> Does JHC support the FFI and other various extensions?
14:13:16 <Philippa_> dunno :-)
14:13:23 <Cale> oh, okay
14:13:58 <Philippa_> SamB: handling impredicativity properly in the context of a haskell-like type system was until recently an open research question
14:13:58 <Cale> Has anyone given much thought to implementing typeclasses in a different way so as to avoid the need for the MR in the first place?
14:14:02 <palomer> http://www.rafb.net/paste/results/GAtJOT60.html <--more crazy cookiness
14:14:11 <Cale> I recall that JHC does something different there too
14:14:21 <Philippa_> Cale: it might be worth another look over. I've forgotten the original issue
14:14:24 <SamB> robdockins: hmm... these parse trees really look ugly when printed with Show...
14:14:48 <palomer> there should be a showGraphics which creates a jpeg
14:14:52 <SamB> or whatever you call them...
14:14:59 <Cale> Philippa_: it's so stupid -- it seems like a problem which would go away with even the most basic CSE
14:15:03 <palomer> we should really move away from text
14:15:13 <Philippa_> Cale: again, remind me what the actual issue is? :-)
14:15:28 <Philippa_> we shouldn't get stuck with bitmaps though
14:15:44 <Cale> okay
14:16:01 <Cale> so say you have something like (stealing an example)
14:16:06 <Cale> twiceSize x = n + n  where n = size x
14:16:22 <Cale> you'd expect n to only get computed once
14:16:22 <SamB> palomer: what would you prefer?
14:16:37 <Cale> but adding dictionary parameters gives: twiceSize d x  = n d + n d  where  n d = size d x
14:16:41 <palomer> SamB: graphics
14:16:46 <roconnor> Philippa_: I see. ... Impredicative (or parametric type universes) is needed.
14:16:47 <SamB> anyway, I'd just prefer some layout ;-)
14:16:49 <palomer> @hoogle println
14:16:50 <lambdabot> No matches found
14:16:55 <palomer> @hoogle printLn
14:16:56 <lambdabot> No matches found
14:16:57 <palomer> @hoogle printline
14:16:57 <lambdabot> No matches found
14:17:00 <Cale> @hoogle print
14:17:01 <lambdabot> Prelude.print :: Show a => a -> IO ()
14:17:01 <lambdabot> System.IO.print :: Show a => a -> IO ()
14:17:01 <lambdabot> Text.Printf.Print :: Print
14:17:06 <Cale> @hoogle putStrLn
14:17:06 <lambdabot> Prelude.putStrLn :: String -> IO ()
14:17:06 <lambdabot> System.IO.putStrLn :: String -> IO ()
14:17:06 <lambdabot> System.IO.hPutStrLn :: Handle -> String -> IO ()
14:17:19 <palomer> ahh, that's the one
14:17:19 <SamB> palomer: how are you supposed to display data constructors in JPEG?
14:17:31 <Cale> twiceSize d x  = n d + n d  where  n d = size d x
14:17:46 <Cale> and now n d is a function, so it won't get memoed.
14:17:52 <SamB> print = putStrLn . show, iirc
14:17:55 <palomer> SamB: for showGraphics or for prorgamming in general?
14:18:06 <palomer> hmm, so noone has any idea about my paste?
14:18:13 <SamB> palomer: the former
14:18:18 <Philippa_> Cale: I can start to think of transformations that fix that, but I'm not sure if they spec out cleanly
14:18:25 <palomer> SamB: as a tree
14:18:47 <Philippa_> (I'm not thinking of the obvious where n = size d x one because I know why that doesn't work)
14:19:14 <palomer> Cale: it seems as though as runSupplyT returns the unused supply, is this correct?
14:19:26 <Cale> palomer: check that :)
14:19:31 <Philippa_> the short version is to apply the dictionary and then pass the specialised n into the resulting term so you get specialisedN + specialisedN
14:19:45 <Philippa_> palomer: that'd make some sense
14:19:52 <Philippa_> runFoo funcs don't always return just the result
14:20:00 <Cale> palomer: yeah, it does -- use evalSupplyT
14:20:13 <Cale> (I should know, I wrote it :)
14:20:36 <Cale> anyway, I have to get going for a bit
14:20:39 <Cale> I'll be back
14:20:59 <Cale> I'd really like to work on this MR issue, because the suggestions being made on the mailing list are horrific
14:21:42 <Cale> I really think the MR shouldn't exist. This should be something which the compiler is able to optimise silently.
14:23:36 <Philippa_> I think JHC has no problem anyway
14:25:05 <phas> dcoutts?
14:25:24 <phas> Hi, xerox told me to ask you
14:25:48 <phas> i need to make an app in haskell that uses both System.Network and GTK2hs
14:25:59 <musasabi> much new code in JHC lately.
14:49:06 <dcoutts> phas, perhaps you want to use threads. People have wirtten IRC clients with gtk2hs by that method.
14:49:39 <phas> mmh i've to write a really SIMPLE application
14:49:50 <phas> a client and a server
14:49:59 <phas> a client can send a string to a server
14:50:21 <phas> the server write a window with the string as a label and a "ok" button
14:50:34 <phas> you print the "ok" button and the window disappear
14:50:37 <dcoutts> http://haskell.org/gtk2hs/archives/2005/07/24/writing-multi-threaded-guis/
14:50:54 <dcoutts> phas, ok, maybe you don't need threads
14:51:32 <phas> eh eh
14:51:40 <phas> it's a very easy app
14:52:17 <dcoutts> phas, so you were wondering where to start with gtk2hs?
14:52:26 <phas> well
14:52:45 <phas> for now i'v client and server working in textual mode
14:52:47 <palomer> http://www.rafb.net/paste/results/UwASLw92.html <---hmm?
14:52:55 <dcoutts> phas, ok, good
14:53:06 <phas> i'm looking the example program in gtk2hs
14:53:18 <phas> and reading the documentation on the website too
14:53:27 <dcoutts> phas, they come with gtk2hs in the demo directory
14:53:35 <phas> yeah
14:53:40 <dcoutts> http://darcs.haskell.org/gtk2hs/demo/
14:53:47 <dcoutts> start with the hello world one
14:53:48 <phas> i'm reading one of them now
14:54:09 <phas> ok
14:54:28 <dcoutts> and maybe the glade one
14:54:34 <phas> yeah
14:54:35 <dcoutts> you can design your gui using glade
14:54:42 <phas> i was looking at glade one right now
14:55:03 <phas> and i more or less understood how to show the windows
14:55:24 <phas> i was trying to understand how change the text of a label
14:55:32 <phas> i found "set" function
14:55:53 <dcoutts> phas, http://haskell.org/gtk2hs/docs/current/Graphics-UI-Gtk-Display-Label.html
14:56:23 <dcoutts> set myLabelWidget [ labelLabel := "foo" ]
14:56:24 <dcoutts> or
14:56:41 <dcoutts> set myLabelWidget [ labelMarkup := "foo <b>bar</b> baz" ]
14:57:03 <jophar_> hello there
14:57:32 <phas> thanks
14:58:02 <phas> i was tryng to uderstand what was the name of the field
14:58:20 <phas> cause "labelLabel" soudend a little silly eheh
15:00:55 <phas> uhm, seems to don't work
15:01:08 <phas> i used
15:01:10 <phas> 	 label <- xmlGetWidget dialogXml castToButton "label1"
15:01:10 <phas>          
15:01:10 <phas>          set label [ labelLabel := "CLICCATO" ]
15:01:15 <phas> for test
15:01:17 <phas> but i got
15:01:25 <phas> GladeTest.hs:22:41:
15:01:25 <phas>     No instance for (LabelClass Button)
15:01:25 <phas>       arising from use of `labelLabel' at GladeTest.hs:22:41-50
15:01:25 <phas>     Probable fix: add an instance declaration for (LabelClass Button)
15:01:25 <phas>     In the first argument of `(:=)', namely `labelLabel'
15:01:26 <phas>     In the list element: labelLabel := "CLICCATO"
15:01:28 <phas>     In the second argument of `set', namely `[labelLabel := "CLICCATO"]'
15:01:30 <phas> phas@zulu:~/Desktop/gtk2hs$
15:02:17 <dcoutts> phas, oh sorry I though you were talking about an ordinary text label widget, rather than the text on a button.
15:02:37 <dcoutts> http://haskell.org/gtk2hs/docs/current/Graphics-UI-Gtk-Buttons-Button.html
15:02:53 <phas> no no
15:02:58 <dcoutts> in that case you'll need: buttonLabel
15:03:00 <phas> it's a text label
15:03:17 <dcoutts> not it isn't, look
15:03:21 <dcoutts> label <- xmlGetWidget dialogXml castToButton "label1"
15:03:21 <phas> uuuuuuh
15:03:25 <dcoutts> "castToButton"
15:03:29 <phas> castToButton
15:03:31 <phas> d'uh
15:03:34 <phas> i've to use
15:03:36 <dcoutts> :-)
15:03:38 <phas> castToLabel
15:03:39 <dcoutts> yep
15:03:39 <phas> eheh
15:03:41 <jophar_> >:info Eq
15:03:50 <jophar_> >:i Eq
15:04:02 <jophar_> why he doesnt like me? :X
15:04:19 <phas> ehhehehhehehehehehehe
15:04:52 <jophar_> brb
15:05:14 <phas> whoah
15:05:17 <phas> weird
15:05:29 <phas> it work like i want, but i cannot understand
15:05:50 <phas> 	 button <- xmlGetWidget dialogXml castToButton "button1"
15:05:50 <phas> 	 label <- xmlGetWidget dialogXml castToLabel "label1"
15:05:58 <phas> 	 button `onClicked` set label [ labelLabel := "CLICCATO" ]
15:06:11 <phas> it works
15:06:14 <phas> but how
15:06:28 <phas> button is widget, a data
15:06:29 <jyp> @quote
15:06:30 <lambdabot> babel module failed: getRandItem: empty list
15:07:14 <jyp> @dons: this happened after a very long quote by JohnMeacham was shown, truncated (for the record)
15:07:14 <lambdabot> this happened after a very long quote by JohnMeacham was shown, truncated
15:07:14 <lambdabot> (for the record) not available
15:07:34 <dcoutts> phas, confused?
15:07:40 <phas> yeah
15:07:43 <phas> a lot
15:08:01 <dcoutts> which bit?
15:08:17 <phas> i understand that writing
15:08:22 <phas>   button `onClicked` set label [ labelLabel := "CLICCATO" ]
15:08:34 <phas> i say that when the event 'onClicked'
15:08:37 <phas> happens on button
15:08:46 <phas> it does
15:08:52 <phas> set label blah blah
15:08:54 <dcoutts> yep
15:09:06 <phas> but i cannot understand HOW it work
15:09:15 <dcoutts> ah
15:09:38 <dcoutts> it connects a signal handler to the signal
15:10:01 <dcoutts> then gtk's main loop delivers the signal which calls the signal handler
15:10:08 <phas> whoah ok but i cannot understand WHAT is written there
15:10:15 <dcoutts> ok
15:10:23 <dcoutts> I usually write it like this:
15:10:34 <dcoutts> onClicked button $ do
15:10:36 <dcoutts>   ...
15:10:39 <dcoutts>   ...
15:10:54 <phas> yeah right, written like this it has more sense
15:11:16 <phas> but written like that, what's its meaning?
15:11:24 <dcoutts> the same as before
15:11:27 <phas> uuuuuh
15:11:29 <palomer> is there any way for ghc to spit out what it thinks a binding type is?
15:11:45 <dcoutts> "button" is the widget we're interested in
15:11:52 <phas> yeah
15:11:54 <dcoutts> "onClicked" is the event
15:11:55 <phas> and it's a data
15:12:01 <phas> not a function
15:12:09 <phas> how it takes parameters?
15:12:15 <dcoutts> and "do ..." is what we're going to do in response to the event
15:12:22 <dcoutts> what's a data?
15:12:31 <phas> mmh
15:12:37 <dcoutts> onClicked is a function
15:12:50 <phas> uhm, oh, well, who in the hell cares
15:12:57 <dcoutts> which takes the button and the action to perform as paremeters
15:13:00 <phas> i understood how it works
15:13:07 <phas> and it's all for know
15:13:35 <phas> the other question, more pratical one, is, how can i quit only a windows?
15:13:40 <phas> window?
15:13:53 <dcoutts> you mean hide/destroy it?
15:14:22 <phas> yeah
15:14:23 <dcoutts> http://haskell.org/gtk2hs/docs/current/Graphics-UI-Gtk-Abstract-Widget.html#v%3AwidgetDestroy
15:14:44 <wilx> Hmm, this is odd, I tried compiling jhc. There is a step that uses DrIFT to generate stuff. And one generated file seems to end abruptly. And the output is the same everytime I run the command.
15:14:46 <dcoutts> phas, if you have time, I would love to have your input for an introductory tutorial that we're writing.
15:15:09 <phas> well, why not
15:15:15 <phas> but how can I help?
15:15:33 <dcoutts> phas, it's really useful to get people like you who are learning to tell us what are the difficulties in learning.
15:15:45 <phas> ok
15:15:48 <dcoutts> phas, we've got a wiki page where you can add your notes.
15:15:58 <phas> give me the link
15:16:14 <dcoutts> http://haskell.org/haskellwiki/Gtk2Hs/Tutorials/Intro#Basic_Concepts
15:16:32 <dcoutts> phas, araujo has also been adding his notes at the bottom
15:16:36 <dcoutts> of that page
15:17:01 <dcoutts> we want to make sure we're explaining things in the right order
15:17:06 <dcoutts> and not missing stuff out
15:17:07 <phas> ok
15:17:13 <dcoutts> thanks
15:17:28 <phas> but i'm really confusing while i'm study
15:17:39 <phas> so i don't know how my opinion can help
15:17:44 <dcoutts> phas, so keep it in mind and perhaps when you finnish your little prog you could write some notes about how you learned.
15:17:56 <dcoutts> and what order things started to make sense for you
15:17:58 <phas> ok
15:18:04 <dcoutts> that would be really useful to us
15:19:10 <phas> getting back on my little app
15:19:15 <dcoutts> yep
15:19:16 <phas> i have one more problem
15:19:29 <phas> know i understood how to import some widgets with glade
15:19:36 <dcoutts> good
15:19:38 <phas> to modify their attributes
15:19:44 <phas> to show them and to hide
15:20:16 <phas> now the problem is to show a window only when I receive a message 
15:20:28 <dcoutts> ah ok
15:20:43 <dcoutts> so probably you don't want to destroy the window, just to hide it
15:20:50 <phas> uhm
15:20:50 <phas> no
15:20:51 <dcoutts> then you can just show it again later
15:20:58 <phas> because if i get another message
15:21:07 <dcoutts> or you can create a new window from scratch
15:21:09 <phas> when a windows is still showed
15:21:15 <phas> i need to create another window
15:21:30 <dcoutts> ok, you can create a new window
15:21:39 <phas> so I suppouse that any windows will be created from scratch
15:22:00 <dcoutts> do note that if your program is listing to the network then it will not be updateing the GUI
15:22:24 <dcoutts> so it might be better to have no window shown when it is waiting for a message to be recieved
15:22:40 <phas> right
15:23:07 <dcoutts> if you want to listen to the network and have the gui update at the same time then you need to use threads or some other more tricky IO stuff
15:23:24 <phas> uhm
15:23:28 <dcoutts> which you probably do not want to get into now
15:23:46 <phas> because the program wait on a signal, i suppouse
15:25:02 <phas> but probably i'll need to do like that
15:25:26 <phas> because otherwise i will lose some message
15:25:42 <phas> i mean
15:25:57 <phas> i have the server that waits doing nothing-showing nothing
15:25:59 <phas> a message arrives
15:26:17 <dcoutts> yes I see
15:26:18 <phas> the server draw the windows with the message on
15:26:23 <phas> the user click ok
15:26:28 <phas> the windows disappears
15:26:39 <phas> but if in the time that the window is on
15:26:45 <phas> another message is sent
15:26:49 <dcoutts> in that case take a look at the concurrent demo
15:26:49 <phas> the server losts it
15:27:10 <phas> ok, i will take a look
15:27:13 <dcoutts> http://darcs.haskell.org/gtk2hs/demo/concurrent/Progress.hs
15:27:31 <palomer> woot
15:27:55 <dcoutts> phas, and also:
15:27:55 <dcoutts> http://haskell.org/gtk2hs/archives/2005/07/24/writing-multi-threaded-guis/
15:27:55 <phas> using threads seems a solution, but i never used them
15:28:14 <phas> ok, i never used System.Network o gtk2hs before today morning, but..
15:28:17 <dcoutts> it shows how to do it and used an IRC client as an example
15:38:22 <palomer> -:o
15:39:59 <mfgl> Hi, I have a question about Arrays.
15:40:21 <palomer> that sucks
15:40:27 <lightstep> arrays?
15:40:31 <lightstep> or questions?
15:40:53 <palomer> Cale: you around?
15:41:10 <palomer> lightstep: half half
15:41:11 <mfgl> Well, I've just completed a program in Haskell that simulates the Ising model in 2D.
15:41:31 <mfgl> It is based in updating an Array in randomly chosen positions.
15:41:33 <palomer> what's the best gtk2hs tutorial?
15:41:49 <mfgl> But it runs out of memory quite quickly.
15:42:05 <dcoutts> palomer, the hello world example on the gtk2hs website and the gtk2hs demos
15:42:16 <mfgl> I have read that Arrays are best left as read-only data structures.
15:42:21 <mfgl> Is that correct?
15:42:23 <dcoutts> palomer, we're woring on a bigger better tutorial
15:42:52 <dcoutts> palomer, the Gtk+ C tutorial is somewhat helpful for the concepts if not the code
15:43:14 <lightstep> mfgl, look at Data.Array.ST for mutable arrays
15:43:50 <dcoutts> palomer, the gtk2hs api reference is quite good for once you've got to grips with the basics
15:43:55 <mfgl> Thanks, I look that. I've read that finite maps could be an answer.
15:43:56 <kevind> the
15:44:02 <kevind> hrm
15:46:58 <palomer> is it possible to get parsec to get the positions of the productions?
15:47:03 <palomer> the text positions
15:50:29 <eivuokko> Yeah, when you are parsing you can ask for sourcename, line and column.
15:51:57 <palomer> how?
15:52:31 <eivuokko> @hoogle GenParser a b SourcePos
15:52:32 <lambdabot> Text.ParserCombinators.Parsec.Prim.getPosition :: GenParser tok st
15:52:32 <lambdabot> SourcePos
15:52:32 <lambdabot> Text.ParserCombinators.Parsec.Prim.pzero :: GenParser tok st a
15:52:32 <lambdabot> Text.ParserCombinators.Parsec.Prim.getState :: GenParser tok st st
15:53:27 <palomer> @hoogle getPosition
15:53:28 <lambdabot> Text.ParserCombinators.Parsec.Prim.getPosition :: GenParser tok st
15:53:28 <lambdabot> SourcePos
15:53:36 <palomer> @type Text.ParserCombinators.Parsec.Prim.getPosition
15:53:37 <lambdabot> forall st tok.
15:53:37 <lambdabot> Text.ParserCombinators.Parsec.Prim.GenParser tok
15:53:37 <lambdabot>                st
15:53:37 <lambdabot>                Text.ParserCombinators.Parsec.Pos.SourcePos
15:53:57 <boro_> Anyone here know where to get Haskell battleship game code ? :D
15:53:59 <palomer> how do I use this?
15:54:59 <eivuokko> You might call "GenParser st a" as "Parser a", it simply is another parsec-monadic value.  pos <- getPosition
15:59:24 <palomer> nice
16:02:28 * palomer petitions Mr. Haskell for a better way to tag information onto datatype values
16:06:34 <lightstep> records?
16:07:23 <palomer> well, something that factors through
16:07:24 <palomer> bbl
16:08:19 <lightstep> @fptools Data.Typeable
16:08:19 <lambdabot> http://darcs.complete.org/fptools/libraries/base/Data/Typeable.hs
16:09:56 <mfgl> lightstep: Thank you, Data.Array.ST seems to be an efficient answer to the problem. I was using the state monad to store the array in the calculations, but that's clearly inefficient.
16:12:17 <musasabi> Is ghci crashing with "*** Exception: Maybe.fromJust: Nothing
16:12:26 <musasabi> fixed in the snapshots?
16:28:10 <palomer> http://www.rafb.net/paste/results/W7JTPH14.html <--how do I fix this?
16:28:34 <palomer> oh, nevermind
16:30:05 <palomer> hiding constructors can be a good way to implement tagging
16:32:29 <mmc> @index Pt
16:32:30 <lambdabot> bzzt
16:42:30 * SimonRC goes to bed.
16:48:59 <palomer> night SimonRC 
16:52:30 <phas> ddcoutts
16:52:32 <phas> still here?
16:54:42 <palomer> how do you export instances?
16:58:16 <palomer> is getPosition magic?
16:58:33 <eivuokko> Instances are exported and imported always (even with empty lists to export or import)
17:00:36 <palomer> hrm, how do I get a tycon of kind (*->*) to derive show (for a certain parameter)
17:01:04 <palomer> like, data Term a = ...
17:01:10 <palomer> and Show is derivable for certain a
17:01:23 <palomer> so, like, can I say "deriving show when possible" ?
17:02:54 <eivuokko> I am not sure, but maybe data (Show a) => Term a = ..., but I recall there was something quirky about that.
17:03:58 <eivuokko> But it is possible you have to write your own instances :)
17:05:57 <palomer> can you derive instances?
17:06:02 <dons> musasabi, back from death? i hope you're not serious..
17:07:27 <eivuokko> palomer, What you mean?  Deriving-keyword is just a built-in instance definition-generator for Prelude classes.
17:08:09 <mmc> How to test a type declaration in ghci? When I submit "main  :: IO ()" i get  <interactive>:1:0: Not in scope: `main'
17:08:49 <palomer> like (Term Int) deriving Show ?
17:09:09 <dons> :t   ?
17:09:09 <eivuokko> mmc, type annotations or declarations?
17:09:32 <eivuokko> palomer, you have to write instance by hand.
17:09:52 <palomer> ugh! but it's derivable!
17:10:53 <mmc> eivuokko: after that line i would like to submit:  "main =  do c <- getChar\n  putChar c"   (an example from a tutorial)
17:11:48 <eivuokko> mmc, it is better to write that sort of code in a file and :load and :reload it in ghci.
17:12:19 <eivuokko> mmc, you can write it in ghci, but you'd need to use let, it's basically like writing inside do block.
17:12:27 <robdockins> palomer: the automatic deriving instances should do what you want - are you having a specific problem?
17:12:43 <palomer> can I do           instance Show (Show a => Term a) where ?
17:12:59 <robdockins> data Term a = .... deriving Show
17:13:07 <eivuokko> instance (Show a) => Term a where
17:13:21 <phas> someone knows in what library is forkIO ?
17:13:29 <eivuokko> .. => Show (Term a) where
17:13:30 <eivuokko> sorry
17:13:40 <palomer> robdockins: doesn't work
17:13:42 <eivuokko> phas, Control.Concurrent
17:14:05 <robdockins> do you have higher order functions or exestentials in your Term definition?
17:14:08 <eivuokko> phas, or package..hmm, I think base.
17:14:14 <phas> found
17:14:18 <phas> Control.Concurrent
17:14:27 <palomer> I get an error elsewhere:
17:14:30 <eivuokko> @index forkIO
17:14:31 <lambdabot> Control.Concurrent
17:14:31 <palomer> monad4.hs:289:23:
17:14:31 <palomer>     Ambiguous type variable `a' in the constraint:
17:14:31 <palomer>       `Show a' arising from use of `print' at monad4.hs:289:23-27
17:14:31 <palomer>     Probable fix: add a type signature that fixes these type variable(s)
17:14:37 <palomer> woops, sorry about the paste
17:14:55 <palomer> http://www.rafb.net/paste/results/TJOUbZ51.html
17:15:20 <robdockins> palomer: the problem isn't that you don't have the right instances
17:15:58 <robdockins> but rather that it doesn't know what the type is
17:16:18 <robdockins> the classic example of ambiguious types is the function 'show . read'
17:16:28 <robdockins> let f = show . read in f "adsf"
17:17:04 <eivuokko> > let f = show . read in f "adsf"
17:17:05 <lambdabot> Add a type signature
17:17:15 <robdockins> er, thanks
17:17:29 <palomer> lambdabot needs a type signature for anything
17:17:33 <palomer> so how do I add a type signature?
17:18:17 <robdockins> with '::' usually
17:18:31 <palomer> gotcha
17:18:39 <palomer> so derive derives when it can
17:18:50 <robdockins> yup
17:19:03 <palomer> is it possible to derive when it can and let us specify a default behaviour when it can't?
17:19:06 <robdockins> it adds constraints as necessary to the derived instances
17:19:38 <dons> hey robdockins, are you the guy behind lambda, shellac and the new C-- frontend tools?
17:19:49 <robdockins> that's me
17:19:55 <dons> @lambda four
17:19:55 <lambdabot> Unknown command, try @listcommands.
17:19:59 <dons> @lam four
17:20:00 <lambdabot> \f. \x. f (f (f (f x)))
17:20:04 <dons> :) that's your code
17:20:18 <dons> welcome  :)
17:20:30 <robdockins> thanks: glad to be here
17:21:08 <robdockins> palomer: I don't think so -- its all or nothing really
17:21:51 <robdockins> dons: BTW, how did you hook lambda shell into lambdabot?  I don't know how the plugins work
17:22:20 <dons> ah, I wrote a plugin that talks over a pipe to the lambda binary
17:22:21 <palomer> @lam five
17:22:22 <lambdabot> \f. \x. f (f (f (f (f x))))
17:22:28 <palomer> @lam fifteen
17:22:28 <lambdabot> variable 'fifteen' not in scope
17:22:31 <dons> @version
17:22:31 <lambdabot> lambdabot 3p283, GHC 6.5.20050806 (Linux i686)
17:22:31 <lambdabot> darcs get http://www.cse.unsw.edu.au/~dons/code/lambdabot
17:22:56 <dons> you can see the code in Plugins/LShell.hs
17:23:27 <robdockins> so its just a coprocess type setup?
17:23:33 <robdockins> @lam :showall
17:23:34 <lambdabot> Invalid command
17:23:40 <dons> lambdashell :: String -> IO [String]
17:23:40 <dons> lambdashell src = do
17:23:40 <dons>     (out,_,_) <- popen "./lambda" [] $ Just $ 
17:23:41 <dons>                     ":load State/prelude.lam" <$> src <$> ":quit"
17:23:41 <dons>     let o = let s = init . drop 11 . lines $ out 
17:23:42 <robdockins> hummm
17:23:43 <dons>             in if null s then "Terminated" else dropNL . doclean . last $ s
17:23:45 <dons>     return [o]
17:23:48 <dons> that's it, basically
17:24:28 <dons> it rules out things that start with ':'. just in case you can write files or some such through it
17:24:39 <robdockins> ahhh OK
17:25:05 <dons> i'm not sure if yo ucan do IO through lambda that way, but you can in other tools, so I just try to be careful
17:25:26 <robdockins> yeah, you can create a trace dump
17:25:54 <ozone> dons: got to chat to damian conway yesterday!  interesting guy
17:25:59 <ozone> he dissed type theorists in his perl 6 talk :}
17:26:15 <dons> heya ozone. well, what do you expect eh ;)
17:26:35 <robdockins> palomer: the lambda prelude only defines the churn numerals up to 'ten'
17:26:49 <robdockins> *church
17:26:52 <ozone> dons: yeah, he's got his head screwed on right though.  perl6++
17:27:26 <robdockins> @lam plus four nine
17:27:27 <lambdabot> \f. \x. f (f (f (f (f (f (f (f (f (f (f (f (f x))))))))))))
17:28:17 <dons> the prelude lambdabot is using is at: http://www.cse.unsw.edu.au/~dons/code/lambdabot/State/prelude.lam
17:28:37 <dons> maybe there's been more patches to lambda? I should perhaps resync lambdabot and lambda
17:29:16 <robdockins> dons: not yet -- its mostly a demo for shellac and I haven't released 0.2 yet (getting close though)
17:29:41 <dons> ok. you don't just push your patches into the public repo as you do them?
17:30:42 <robdockins> eh, not really.  My web space doesn't have darcs, so I rsync.  I only really bother when I release
17:30:54 <robdockins> mostly because noone else is participating at this point
17:31:33 <phas> uhm i get a strange error, someone could help?
17:32:33 <eivuokko> lisppaste2: help
17:32:33 <lisppaste2> To use the lisppaste bot, visit http://paste.lisp.org/new/haskell and enter your paste.
17:32:49 <phas> i writing a function that displays a window using a separated thread
17:33:01 <phas> and i get an error reading the glade file
17:33:29 <lisppaste2> phas pasted "ThWin" at http://paste.lisp.org/display/16138
17:34:02 <lisppaste2> robdockins pasted "wxHaskell link error" at http://paste.lisp.org/display/16139
17:34:19 <lisppaste2> Phas annotated #16138 with "error" at http://paste.lisp.org/display/16138#1
17:34:39 <robdockins> BTW, I'm trying to compile wxHaskell on OS X and I'm having trouble.  anyone got clues?
17:34:46 * palomer feels helpless without Cale
17:34:52 <palomer> oh cale oh cale, where art thou?
17:35:55 <eivuokko> phas, you should probably not reuse variable name dialogXml so much
17:36:25 <eivuokko> phas, especially the part let x = case x of  is wrong (let can be recursive)
17:36:47 <phas> uhm i copied that part from the Glade Test from gtk2hs site
17:36:56 <eivuokko> Hmmm.
17:37:09 <phas> btw i already tryied to change it but it doesn't work
17:39:36 <phas> uhm a copy-paste after, it works
17:43:06 <robdockins> dons: re lambashell plugin, the lambda shell accepts statements to evaluate and definition files to parse on the command line -- it is a little cleaner than going in through the shell
17:45:45 <dons> musasabi, there's 3 things to do: 1) commit our entry for the new partial-sums test http://www.haskell.org/hawiki/PartialSumsEntry 2) submit the new super-fast nbody code http://www.haskell.org/hawiki/NbodyEntry 3) can you add -fexcess-precision to the mandelbrot entry. i think that missing is why mandelbrot is slower than it should be.
17:46:31 <dons>   robdockins, ah, that would be simpler, yes.
17:49:55 <lisppaste2> Phas pasted "ThWin" at http://paste.lisp.org/display/16140
17:51:41 <lisppaste2> phas annotated #16140 with "crash" at http://paste.lisp.org/display/16140#1
17:51:43 <vincenz> Hello everyone
17:52:05 <phas> someone could put an eye on the code I posed, pls?
17:52:59 <vincenz> Graphics.UI.Gtk does not come with ghc by default?
17:53:45 <phas> uh, i think not
17:53:57 <vincenz> what does then?
17:54:12 <phas> btw all example program on gtk2hs import it
17:54:46 <phas> and how ghc could include Gtk2hs library by default when ghc doesn't include Gtk2hs by default? mmh
17:55:56 <vincenz> how about wxhaskell?
17:57:47 <phas> night at all
18:00:16 <palomer> @hoogle sourcepos
18:00:17 <lambdabot> Text.ParserCombinators.Parsec.Pos.SourcePos :: SourcePos
18:00:17 <lambdabot> Text.ParserCombinators.Parsec.SourcePos :: SourcePos
18:00:39 <palomer> from my understanding, I need to manipulate source positions myself, is this true?
18:02:18 <vincenz> is it normal I can't get wxHaskell to compile?
18:02:20 <palomer> I just can't simply call getPosition whenever I want inside parsec
18:02:26 <vincenz> is there any stdized gui toolkit?/
18:03:10 <vincenz> @help gui
18:03:10 <lambdabot>  @help <command> - ask for help for <command>
18:03:36 <palomer> gtk2hs ?
18:03:37 <vincenz> @where gtkhs
18:03:37 <lambdabot> I know nothing about gtkhs.
18:03:38 <palomer> with glade
18:03:38 <vincenz> @where gtk2hs
18:03:39 <lambdabot> http://haskell.org/gtk2hs/
18:04:11 * vincenz is on ubuntu
18:04:41 <palomer> where can I get some parsec grammars?
18:06:36 <vincenz> configure: error: Package requirements (glib-2.0 >= 2.0.0 gobject-2.0 >= 2.0.0)
18:22:04 <palomer> hrm, now I remember why I decided to build a lexer with parsec
18:26:31 <vincenz> anyone know ohw to make a simple hello world with gtk2hs
18:30:21 <vincenz> how do I compile a gtk2hs program?
18:37:27 <palomer> ghc --make file.hs
18:37:31 <palomer> hello world is on the webpage
18:37:58 <vincenz> ghc -package gtk apparently
18:38:03 <vincenz> @type set
18:38:04 <lambdabot> Not in scope: `set'
18:38:06 <vincenz> @index set
18:38:07 <lambdabot> Graphics.Rendering.OpenGL.GL.StateVar, Graphics.Rendering.OpenGL.GL,
18:38:07 <lambdabot> Graphics.Rendering.OpenGL, Graphics.UI.GLUT
18:48:44 <sproingie> Chris Kuklewicz is today's God.  awesome answer on the haskell wiki on MonadTransformerPuzzle
18:48:46 <sproingie> i finally get it
18:54:33 <vincenz> @hawiki  MonadTransformerPuzzle
18:54:34 <lambdabot> http://www.haskell.org/hawiki/MonadTransformerPuzzle
18:55:51 <sproingie> basically me trying to elucidate non-trivial (at least to a beginner) examples of monad transformers.  which chris did with aplomb
18:56:34 <palomer> is parsec greedy?
18:56:41 <palomer> I'm putting space everywhere
19:02:33 <palomer> oh my, I need explicit left recursiveness to decide start and end pos
19:35:57 <vincenz> hmm
19:36:04 <vincenz> anyone have any nice suggestiions for starting some haskell coding
19:40:27 <musasabi> dons: committed things, except for nbody (have to think how to reset the global GHCFLAGS to avoid the C compiler errors)
19:53:31 <Cale> palomer: what's up?
20:04:05 <Cale> hmm
20:05:54 <Cale> I can't seem to get this lack of sharing to happen with -fno-monomorphism-restriction
20:07:03 <dons> ah, good point musasabi, i'll check that out. i think perhaps if we stick it in an options pragma, we can override the global settings
20:07:27 <vincenz> anyone got a good idea for an intro project for haskell?
20:10:36 <dons> musasabi, so partial-sums, and -fexcess-precision for mandelbrot are done?
20:15:05 <araujo> vincenz, an object database relational program ? :-]
20:15:34 <vincenz> heh..
20:15:42 <vincenz> databases aren't my forte
20:17:21 <araujo> i don't like them either.... but i will need to use that kind of stuff next semester...
20:18:12 <araujo> and a haskell programm for it wouldn't make it so painful 
20:24:55 <vincenz> Anyone have a solution to the typing problem on the HaskellIrcPastePage concerning the mathematical stuff from sdjp
20:32:44 <vincenz> figured it out
20:34:24 <vincenz> @type repeat
20:34:25 <lambdabot> forall a. a -> [a]
20:37:42 <newsham> hi
20:42:09 <vincenz> How do I do a simple monad that basically allows me to update a counter whenever I call a function
20:43:06 <Cale> you also want to be able to read the counter too?
20:43:11 <Cale> (inside the computation)
20:44:05 <newsham> the State monad should be useful for that purpose
20:44:14 <Cale> or even just Writer
20:44:36 <Cale> so long as you don't need to also observe the counter
20:45:13 <vincenz> I want ot observer the counter at the end
20:45:16 <vincenz> so like
20:45:19 <vincenz> do
20:45:22 <vincenz> myComputation
20:45:26 <vincenz> x <- getCounter
20:45:26 <vincenz> print x
20:46:07 <Cale> oh, if you want it in the IO monad, you can just create an IORef and a closure which increments it
20:46:23 <vincenz> State Monad?
20:46:37 <Cale> in the state monad, you'd just do something like
20:46:49 <Cale> inc = do x <- get; put (x+1)
20:47:45 <vincenz> What's the type of a State Monad?
20:47:50 <vincenz> @index get
20:47:50 <lambdabot> Control.Monad.State, Control.Monad.RWS, Graphics.Rendering.OpenGL.GL.
20:47:50 <lambdabot> StateVar, Graphics.Rendering.OpenGL.GL, Graphics.Rendering.OpenGL,
20:47:50 <lambdabot> Graphics.UI.GLUT, Text.ParserCombinators.ReadP, Distribution.Compat.ReadP,
20:47:50 <lambdabot> Text.ParserCombinators.ReadPrec, Text.Read
20:47:57 <newsham> http://lava.net/~newsham/x/machine/eightqueens.lhs.txt  has an example of the state monad
20:48:10 <Cale> A state monad is  State s  for some state type s.
20:48:13 <vincenz> @type {do x <- get; put(x+1)}
20:48:14 <lambdabot> parse error on input `{'
20:48:21 <Cale> So computations in that monad have type  State s a
20:48:21 <vincenz> @type do{ x <- get; put(x+1)}
20:48:22 <lambdabot> Not in scope: `get'
20:48:22 <lambdabot>  
20:48:22 <lambdabot> <interactive>:1:14: Not in scope: `put'
20:48:37 <vincenz> Cale: So in this casae (State Int)
20:48:45 <Cale> yeah, that's your monad
20:48:53 <vincenz> thx
20:48:57 <Cale> and your computation will be something like State Int ()
20:49:01 <vincenz> and how about all the enclosing stuff using that monad?
20:49:10 <Cale> hm?
20:49:22 <Cale> The monad is the type constructor, by the way
20:49:27 <newsham> the monad provides hhelpers for extracting the state and setting a new state
20:49:38 <newsham> so you can use those to write a function to increment the counter contained in the state
20:49:54 <Cale> @type Control.Monad.State.get
20:49:55 <lambdabot> forall s (m :: * -> *). (Control.Monad.State.MonadState s m) => m
20:49:55 <lambdabot> s
20:49:59 <vincenz> Cale: so originally my func is (Double -> Double)
20:50:01 <vincenz> so now it becomes
20:50:06 <newsham> @type Control.monad.State.modify
20:50:07 <vincenz> Double -> State Int Double?
20:50:08 <lambdabot> Couldn't find qualified module.
20:50:08 <lambdabot> Maybe you're using the wrong syntax: Data.List.(\\) instead of (Data.List.
20:50:08 <lambdabot> \\)?
20:50:13 <Cale> vincenz: yep
20:50:22 <newsham> @type Control.Monad.State.modify
20:50:23 <lambdabot> forall (m :: * -> *) s.
20:50:23 <lambdabot> (Control.Monad.State.MonadState s m) =>
20:50:23 <lambdabot> (s -> s) -> m ()
20:51:10 <Cale> there's one problem with it being a full state monad, and that's that the computation itself is allowed to depend on that counter
20:51:25 <Cale> if you want to rule that out, it's pretty easy to create a new monad which can do so
20:51:52 <vincenz> Cale: so now... a funciton that was taking the (Double -> Double) function now takes a (Double -> State Int Double)
20:51:55 <vincenz> how do I do this?
20:52:11 <Cale> well, when do you want the counter to be read back?
20:52:22 <vincenz> let me poste
20:52:36 <vincenz> http://rafb.net/paste/results/QADe7Z70.html
20:52:41 <Cale> applying runState to the computation with an initial value for the counter will project back to a (Double, Integer)
20:52:58 <newsham> incr = modify (+ 1) 
20:53:04 <Cale> ah, whyfp :)
20:53:07 <vincenz> Cale: yeah :)
20:53:16 <vincenz> I want to trace the number of evaluations of the base function being differentiated
20:53:41 <Cale> ah, okay
20:53:49 <vincenz> before I used trace to just print me stuff
20:53:53 <Cale> wait, does this code compile?
20:53:55 <vincenz> but I found it inellgant
20:53:57 <vincenz> Cale: not now
20:53:59 <vincenz> it did before when
20:54:01 <Cale> it looks like there should be a layout problem
20:54:04 <vincenz> myfunc = (\x -> trace ("Evaluating at "++  (show x)) (x * x))
20:54:22 <Cale> the 'then' and 'else' should be spaced in a little further than the 'if'
20:54:28 <vincenz> Cale: oh
20:54:45 <vincenz> fixed
20:54:48 <vincenz> but back to the monad issue
20:55:05 <Cale> genList = iterate
20:55:10 <vincenz> @type iterate
20:55:11 <lambdabot> forall a. (a -> a) -> a -> [a]
20:55:15 <vincenz> cooleis
20:55:20 <Cale> okay
20:55:53 <Cale> hmm
20:56:19 <Cale> you'll need to lift all the uses of myfunc into the monad as well
20:56:23 <vincenz> yeah
20:56:25 <vincenz> how do I do that?
20:56:26 <Cale> they have to be sequenced
20:56:38 <Cale> test f = do
20:56:40 <vincenz> will it keep it's lazyness aspect?
20:56:45 <Cale> yeah
20:56:48 <vincenz> oko
20:56:50 <Cale> it should
20:57:00 <Cale> test f = do
20:57:04 <Cale>    x <- f
20:57:15 <Cale> hmm :)
20:57:42 <newsham> instead of get and put, why not just use modify?
20:57:43 <vincenz> and then reurn
20:57:51 <Cale> ah, the higher order use of f could mean pushing the changes down fairly deeply
20:57:59 <Cale> you can use modify of course
20:58:18 * vincenz did
20:58:37 <newsham> myfunc x = do
20:58:37 <newsham>   x <- get
20:58:39 <newsham>   put (x+1)
20:58:46 <newsham> thats what i'm talking about
20:58:56 <vincenz> I fixed that in ym codde
21:00:00 <Cale> hmm
21:00:07 <Cale> this is a little odd :)
21:01:08 <vincenz> first things first, the take 2
21:01:12 <vincenz> can't I lift that?
21:01:21 <vincenz> test f = liftM (take 2) (super (halveAndImprove simpleDiff 10 f 3))
21:01:24 <vincenz> apparently not
21:01:39 <vincenz> @index liftM
21:01:40 <lambdabot> Control.Monad, Control.Monad.Reader, Control.Monad.Writer, Control.Monad.
21:01:40 <lambdabot> State, Control.Monad.RWS, Control.Monad.Identity, Control.Monad.Cont,
21:01:40 <lambdabot> Control.Monad.Error, Control.Monad.List
21:01:40 <Cale> this will actually get quite involved
21:01:44 <vincenz> @type Control.Monad.liftM
21:01:45 <lambdabot> forall r (m :: * -> *) a1. (Monad m) => (a1 -> r) -> m a1 -> m r
21:01:51 <vincenz> aha
21:01:55 <Cale> liftM is just fmap :)
21:02:14 <vincenz> @pl \x -> (a (b c d x e))
21:02:14 <lambdabot> a . flip (b c d) e
21:02:32 <newsham> the only use of myfunc is down in simpleDiff, no?
21:02:38 <Cale> yeah
21:02:42 <newsham> so simpleDiff should be th eonly thing needing fixin
21:02:44 <vincenz> @pl \x -> (take 2 (super (halveAndImprove simpleDiff 10 f 3)))
21:02:45 <lambdabot> const (take 2 (super (halveAndImprove simpleDiff 10 f 3)))
21:02:49 <Cale> it's simpleDiff which will have to change most
21:02:58 <Cale> the others will have to change as a result
21:03:04 <vincenz> can't I lift the entire computation
21:03:12 <Cale> because calls to simpleDiff will have to be sequenced then
21:03:17 <Cale> since they're stateful
21:03:24 <vincenz> liftM seems to be it
21:03:38 <newsham> oh, mapM of the simplediff result?
21:03:59 <newsham> and of the differentiate result?
21:04:07 <Cale> yep
21:04:12 <Cale> I think so
21:04:27 <Cale> everything needs lifting because it's non-monadic
21:04:37 <vincenz> I can't just lift at the top level in test?
21:05:13 <newsham> vince: test passes f down into lower layers
21:05:21 <vincenz> oh
21:05:22 <newsham> and those layers need to handle the new type of f
21:05:23 <vincenz> so you can't just say
21:05:25 <vincenz> LOTS of code
21:05:32 <vincenz> xxx = liftM lotsofcodetopcall
21:06:06 <Cale> well, because the change you're making affects the computation deeply, it requires a lot of changes
21:06:15 <vincenz> damn
21:06:41 <newsham> but  if you make it once, you may be able to swap in other monads at will in the future ;-)
21:06:45 <Cale> In general, the calls to f could even be noncommutative in their effects, right?
21:06:52 <Cale> like,
21:06:57 <Cale> myfunc x = do
21:06:59 <Cale>    n <- get
21:07:04 <Cale>    put (n+1)
21:07:09 <Cale>    return (n * x * x)
21:07:12 <vincenz> yeah
21:07:15 <vincenz> but not for me
21:07:18 <Cale> right
21:07:52 <newsham> instead of counting with a state monad, what if you just return a list of intermediate results, and zip that with integers and take them until you get the one you want?
21:08:24 <vincenz> i'd prefer this approach
21:08:41 <vincenz> and iif possible to use a commutative state monad :)
21:08:52 <newsham> start mapM'ing your applications, and fix up simpleDiff's type :)
21:09:02 <vincenz> @type mapP
21:09:02 <lambdabot> Not in scope: `mapP'
21:09:04 <vincenz> @type mapM
21:09:05 <Cale> one problem is that Haskell doesn't have any special support for commutative monads
21:09:05 <lambdabot> forall b (m :: * -> *) a. (Monad m) => (a -> m b) -> [a] -> m [b]
21:09:09 <vincenz> ooh
21:09:31 <vincenz> so how do I use mapM
21:10:01 <newsham> mapM myfunc [1,2,3,4]  ?
21:10:07 <vincenz> yeah but in my code
21:11:26 <Cale> vincenz: you'll end up just replacing the maps with mapMs
21:13:15 <vincenz> let's start with simpleDif
21:13:21 <vincenz> simpleDiff :: (Double -> State Int Double) -> Double -> Double -> (State Int Double)
21:13:27 <vincenz> simpleDiff :: (Double -> State Int Double) -> Double -> Double -> (State Int Double)
21:13:31 <vincenz> simpleDiff f x h = (f (x+h) - f x) / h
21:13:35 <vincenz> how do I fix this
21:13:37 <newsham> why dont you name "State Int Double" something easier?
21:13:50 <vincenz> and can I use something more generic than Double
21:13:51 <Cale> simpleDiff f x h = do
21:14:02 <Cale>    a <- f (x + h)
21:14:08 <Cale>    b <- f x
21:14:17 <Cale>    return $ (a - b) / h
21:14:40 <vincenz> ooh nice, what I thought too :)
21:14:51 <vincenz> newsham: how do I rename it?
21:15:00 <vincenz> type MyState a = State Int a
21:15:24 <newsham> type foo = State Int Double ?
21:15:51 <vincenz> ok we fixed simpleDiff
21:16:04 <vincenz> btw, is there something more generic than double?
21:16:08 <newsham> whhats your current code?  rafb url?
21:16:11 <vincenz> like (Fractional a) =>..
21:17:22 <Cale> depending on what you want, Fractional might be enough
21:17:27 <vincenz> http://rafb.net/paste/results/WLNouL32.html
21:17:39 <Cale> @type (**)
21:17:40 <lambdabot> forall a. (Floating a) => a -> a -> a
21:17:45 <Cale> @type (^)
21:17:46 <lambdabot> forall a b. (Integral b, Num a) => a -> b -> a
21:17:48 <Cale> @type (^^)
21:17:49 <lambdabot> forall a b. (Integral b, Fractional a) => a -> b -> a
21:18:14 <vincenz> what's less strict? Fractional or Floating
21:18:25 <Cale> Fractional is more inclusive
21:18:46 <vincenz> ok
21:18:46 <Cale> (in particular, Rational is Fractional)
21:18:48 <vincenz> the next issue
21:18:55 <vincenz> the take 2 bit in test
21:19:10 <vincenz> I can't do
21:19:13 <vincenz> f0 <- f
21:19:15 <vincenz> cause f is not a monad
21:19:21 <vincenz> its (a -> CounterState a)
21:19:39 <vincenz> @type logBase
21:19:40 <lambdabot> forall a. (Floating a) => a -> a -> a
21:19:45 <Cale> actually, you're not applying f there
21:19:53 <Cale> so you shouldn't actually have to run it
21:20:15 <Cale> ah, you do need log
21:21:24 <vincenz> order :: (Floating a, Integral b) => [a] -> b
21:21:24 <vincenz> order (x:b:c:xs) = round (logBase 2 ((x-c) / (b-c) - 1))
21:21:31 <vincenz> for some reason it also requires a to be RealFrac
21:22:16 <vincenz> why is there no round for Floating?/
21:22:39 <vincenz> order :: (Floating a, RealFrac a, Integral b) => [a] -> b
21:22:39 <vincenz> order (x:b:c:xs) = round (logBase 2 ((x-c) / (b-c) - 1))
21:22:42 <vincenz> seems rather redundant
21:23:00 <Cale> RealFrac includes Floating
21:23:19 <vincenz> nope, it complains
21:23:24 <Cale> oh?
21:23:25 <Cale> hmm
21:23:38 * Cale looks at the class chart :)
21:23:39 <dons> musasabi, adding a pragma seems to make things work when -optc-3 is on the cmd line (to solve the nbody issue). i've updated the wiki. 
21:23:46 <Cale> ah, RealFloat
21:25:08 <vincenz> be nice to have a program that "generalizes" your type signatures to the minimum stuff
21:25:17 <vincenz> like Double -> Floating
21:25:19 <vincenz> depending on the usage
21:25:35 <Cale> just remove the type signatures and ask ghci for the types
21:25:55 <Cale> does that not work?
21:26:00 <vincenz> not until it compiles ;)
21:26:18 <Cale> ah
21:26:23 <newsham> coment out the parts thaht arent done yet?
21:27:02 <newsham> whhy not get it workign with Float first and then tweak theh sigs?
21:27:14 <Cale> okay, so what's the problem now?
21:27:16 <vincenz> that worked fine
21:27:19 <vincenz> Cale: still the same
21:27:19 <vincenz> take 2
21:27:27 <vincenz> test :: (a -> CounterState a) -> CounterState [a]
21:27:27 <vincenz> test f = take 2 (super (halveAndImprove simpleDiff 10 f 3))
21:27:37 <vincenz> Couldn't match `CounterState [a]' against `[a1]'
21:27:37 <vincenz>       Expected type: CounterState [a]
21:27:37 <vincenz>       Inferred type: [a1]
21:27:37 <vincenz>     In the application `take 2 (super (halveAndImprove simpleDiff 10 f 3))'
21:27:37 <vincenz>     In the definition of `test':
21:27:37 <Cale> okay, what's the type of super?
21:27:39 <vincenz>         test f = take 2 (super (halveAndImprove simpleDiff 10 f 3))
21:27:43 <vincenz> working on it ;)
21:28:02 <Cale> test f = liftM (take 2) (super (halveAndImprove simpleDiff 10 f 3))
21:28:09 <vincenz> super :: (RealFloat a) => [a] -> [a]
21:28:17 <Cale> not anymore it shouldn't be
21:28:25 <Cale> oh
21:28:26 <Cale> hehe
21:28:28 <Cale> sure
21:28:29 <Cale> okay
21:28:37 <Cale> test f = liftM (take 2 . super) (halveAndImprove simpleDiff 10 f 3)
21:28:40 <sethk> ugh, I've been writing C the last few days and I forgot just how painful it is.
21:29:04 <vincenz> Cale: nope
21:29:05 <newsham> ehh.. C's ok :)
21:29:08 <sethk> anyone every tried using haskell with ECOS?
21:29:10 <vincenz> Cale: it can't be liftMed
21:29:24 <Cale> even that latter case?
21:29:27 <vincenz> nope
21:29:31 <vincenz> let me continue to manually type annotate
21:29:38 <vincenz> working on differentiate
21:29:40 <sethk> newsham, it's been painful because it would be so much quicker and more reliable and faster in haskell, but at the moment that's not an option.
21:29:57 <sethk> newsham, I'm using c where c doesn't belong.
21:30:08 <Cale> vincenz: can I have your current code?
21:30:09 <newsham> sethk; what are you writing?
21:30:14 <vincenz> aha
21:30:19 <vincenz> the issue is in differentiate
21:30:31 <Cale> differentiate h0 f x = mapM ...
21:30:34 <vincenz> even the
21:30:42 <Cale> oh
21:30:54 <sethk> newsham, porting an o/s, mostly.
21:30:54 <vincenz> nm
21:30:58 <vincenz> got it wrong, works now
21:31:08 <newsham> sethk: seems to be the perfect place for C.  which OS?
21:31:11 <vincenz> differentiate :: (Fractional a) => a -> (a -> CounterState a) -> a -> (CounterState [a])
21:31:14 <vincenz> differentiate h0 f x = mapM (simpleDiff f x) (iterate halve h0) where halve x = x / 2
21:31:25 <sethk> newsham, ECOS.  Even c++ would be a big improvement
21:31:39 <newsham> hmm.. I wonder hohw counter state is gonna work when you ask it to map onto an infinite list
21:31:46 <newsham> isnt the counter supposed to be infinite?
21:31:49 <sethk> newsham, but that's not the problem, the problem is that my diagnostic and test software shouldn't be written in c.  I need to bootstrap better languages.
21:31:57 <newsham> ecos is the cygnus embedded system?
21:32:09 <Cale> newsham: hmm...
21:32:15 <sethk> newsham, right.  although I don't think they call themselves cygnus any more.
21:32:26 <newsham> redhat, whatever name du jour
21:32:30 <vincenz> gettiing closer
21:32:36 <Cale> that is a good point
21:32:36 <newsham> sethk: no python?
21:32:48 <sethk> newsham, nothing, yet, it's a new embedded platform.
21:32:56 <vincenz> Cale: type annotated everything
21:32:59 <sethk> newsham, I'll have linux bootstrapped by tomorrow then I'll have everything.
21:33:01 <vincenz> still issues with test
21:33:36 <Cale> vincenz: well, you're going to have to runState somewhere
21:33:57 <Cale> though actually, I'm not sure if this translation is appropriate
21:34:14 <sethk> newsham, I wonder about using haskell and FFI in an environment without a full C library and such.
21:34:26 <Cale> well, try it, and we'll see
21:34:32 <newsham> sethk: way out of my scope of experience :)
21:34:48 <sethk> newsham, first time for everything.  :)
21:34:55 <newsham> *nod*
21:35:12 <sethk> newsham, some folks here pointed me at house a few weeks ago, and I think that house will run on my platform.
21:35:21 <sethk> but I haven't had time to follow through.  Maybe this weekend.
21:35:31 <vincenz> woo
21:35:33 <vincenz> Cale: works now
21:35:43 <vincenz> only one issue: the main
21:36:16 <vincenz> @type runState
21:36:17 <lambdabot> Not in scope: `runState'
21:36:19 <vincenz> @index runState
21:36:19 <lambdabot> Control.Monad.State, Control.Monad.RWS
21:36:24 <vincenz> @type Control.Monad.State.runState
21:36:25 <lambdabot> forall s a. Control.Monad.State.State s a -> s -> (a, s)
21:36:31 <newsham> runState ( mapM myfunc [1,2,3,9,2,3] ) 0
21:36:31 <newsham> ([1.0,4.0,9.0,81.0,4.0,9.0],6)
21:36:48 <newsham> 0 is the start counter, 6 is the end counter
21:37:40 <Cale> however, in your application, there's a problem :)
21:37:45 <vincenz> the main isi my problem
21:37:53 <Cale> you can write
21:38:03 <Cale> main = print $ runState (test myfunc) 0
21:38:13 <vincenz> yeah
21:38:14 <vincenz> beisdes
21:38:15 <Cale> but what will happen is you'll get nontermination
21:38:19 <vincenz> it's runState 0
21:38:27 <Cale> hm?
21:38:34 <vincenz> nm
21:39:04 <vincenz> yeah, nonterminatioin
21:39:14 <Cale> you'll get a result for the first part, but then nontermination in computing the state
21:39:21 <vincenz> hmm
21:39:22 <vincenz> crud?
21:39:28 <vincenz> btw
21:39:31 <Cale> which is because in some sense, f really does get applied infinitely many times :)
21:39:32 <vincenz> how do I get this stuff out
21:40:03 <vincenz> lie
21:40:06 <vincenz> get the list out for printing
21:40:20 <vincenz> s/lie/like
21:40:31 <Cale> evalState ?
21:40:37 <vincenz> well no
21:40:40 <vincenz> I want the counter too
21:40:44 <Cale> runState
21:40:47 <vincenz> evalState (print list, print state)
21:40:48 <newsham> thhink about the "take 2" line.  its taking two values from   (State [Float] Int) 
21:40:58 <newsham> whhere [Float] is an infinite list, and Int is the length of that list
21:41:06 <vincenz> :/
21:41:08 <vincenz> darn
21:41:11 <Cale> let (x,n) = runState ... in do print x; print n
21:41:12 <vincenz> suggestions?
21:41:23 <vincenz> Cale: that assumes that monads are transparent!
21:41:28 <newsham> return  [(Float,Int)]  pairs, and take 2 of them
21:41:36 <Cale> vincenz: hm?
21:41:37 <vincenz> newsham: how do I fix?
21:41:51 <newsham> dont use a state monad.
21:42:03 <vincenz> as long as I dont get the n it works fine
21:42:05 <vincenz> newsham: what then
21:42:19 <vincenz> my spec is really easy
21:42:26 <vincenz> for the evaluation, count hte number of myfunc invokes
21:42:59 <newsham> differentiate' = zip (differentiate h0 f x) [1..]
21:43:00 <vincenz> it's cause of the liftM, right?
21:43:00 <Cale> If you want to know the *real* number, you can use the profiler :)
21:43:13 <vincenz> I thought this was what monads where for!
21:43:22 * vincenz thinks the issue is liftM
21:43:28 <newsham> vinc: i'm still not sure what monad's are for ;-)
21:43:31 <Cale> vincenz: mapM over an infinite list can result in problems
21:43:42 <Cale> hmm
21:43:46 <vincenz> Cale: I thought it would nicely thread through the uses of the myfunc
21:43:47 <vincenz> that was the idea
21:44:13 <newsham> you could write your own mapM+take function?
21:44:40 <Cale> yeah, but that's still got problems in this framework
21:44:53 <vincenz> I think the only culprit is
21:44:54 <vincenz> test f = liftM (take 2 . super) (halveAndImprove simpleDiff 10 f 3)
21:45:12 <Cale> differentiate h0 f x = mapM (simpleDiff f x) (iterate halve h0)
21:45:12 <Cale>  -- this is the real culprit :)
21:45:20 <vincenz> not reall
21:45:22 <newsham> no, the problem is that halveAndImprove returns  (State [...] inf)
21:45:25 <vincenz> they're potential uses
21:45:28 <Cale> iterate halve h0 produces an infinite list
21:45:30 <newsham> also differentiate
21:45:31 <vincenz> newsham: oh
21:45:42 * vincenz hmms
21:45:54 * vincenz hacks some more
21:45:57 <newsham> you're mapM'ing your counter over an infinite list.
21:46:02 <newsham> so you get an infinite count :)
21:46:14 <vincenz> mapM sequences?
21:46:18 <Cale> yep
21:46:23 <newsham> if you could combine the "take" with the "mapM" you might be able to fix your issues
21:46:33 <newsham> but remember that there are two levels of mapM's nested in each other
21:46:43 <Cale> so while the end result still works there's no way to stop the counter from counting
21:47:11 <vincenz> ok
21:47:12 <vincenz> fixed
21:47:14 <vincenz> I removed the mapMs
21:47:22 <vincenz> now just gotta fix the test
21:47:47 <vincenz> @hoogle (Monad m) => [m a] -> m a
21:47:48 <lambdabot> No matches, try a more general search
21:47:51 <vincenz> @hoogle (Monad m) => [m a] -> m [a]
21:47:52 <lambdabot> No matches, try a more general search
21:47:56 <vincenz> hmm
21:48:04 <vincenz> how do I do that
21:48:24 <Cale> @type Control.Monad.sequence
21:48:25 <lambdabot> forall a (m :: * -> *). (Monad m) => [m a] -> m [a]
21:49:03 <Cale> mapM f = sequence . map f
21:49:33 <vincenz> @hoogle (a->b) -> [m a] -> [m b]
21:49:35 <lambdabot> Data.List.map :: (a -> b) -> [a] -> [b]
21:49:35 <lambdabot> Prelude.map :: (a -> b) -> [a] -> [b]
21:49:41 <newsham> take                   :: Int -> [a] -> [a]
21:49:41 <newsham> take n _      | n <= 0 =  []
21:49:41 <newsham> take _ []              =  []
21:49:41 <newsham> take n (x:xs)          =  x : take (n-1) xs
21:50:08 <vincenz> @hoogle (Monad m) => (a->b) -> [m a] -> [m b]
21:50:08 <newsham> mapM             :: Monad m => (a -> m b) -> [a] -> m [b]
21:50:08 <newsham> mapM f as        =  sequence (map f as)
21:50:09 <lambdabot> No matches, try a more general search
21:50:22 <vincenz> test f = sequence (take 2 . (liftM super) $ halveAndImprove simpleDiff 10 f 3)
21:50:24 <vincenz> it won't lift the super
21:50:29 <vincenz> @type Control.Monad.lifitM
21:50:30 <lambdabot> Not in scope: `Control.Monad.lifitM'
21:50:32 <vincenz> @type Control.Monad.lifM
21:50:33 <lambdabot> Not in scope: `Control.Monad.lifM'
21:50:34 <vincenz> @type Control.Monad.liftM
21:50:35 <lambdabot> forall r (m :: * -> *) a1. (Monad m) => (a1 -> r) -> m a1 -> m r
21:52:24 <newsham> takeM f n xs = sequence (take n (map f xs))   ?
21:53:02 <vincenz> yeah
21:53:05 <vincenz> the issue is a lift
21:53:22 <Cale> aha
21:53:29 <Cale> hmm
21:53:32 <vincenz> I need
21:53:39 <vincenz> [a] -> [b] -> [m a] -> [m b]
21:53:47 <vincenz> ([a] -> [b]) -> [m a] -> [m b]
21:53:53 <vincenz> @hoogle (Monad m) => ([a] -> [b]) -> [m a] -> [m b]
21:53:54 <lambdabot> No matches, try a more general search
21:54:11 <vincenz> oh!
21:54:11 <vincenz> duh
21:54:54 <vincenz> crap, I have to change my super and improve
21:54:58 <vincenz> cause there's nothing like the func I'm looking for
21:55:21 <lennart> howdy
21:57:12 <Cale> vincenz: yeah, this sort of change isn't easy if you're not already doing everything monadically
21:57:32 * vincenz has issues with elimError
21:57:40 <lennart> f _ _ = [] has that type
21:57:42 <vincenz> elimError n (x:b:xs) = ((b * nPow - x) / (nPow - 1)) : elimError n (b:xs) where nPow = 2 ** (fromIntegral n)
21:57:52 <Cale> lennart: heh
21:57:53 <vincenz> elimErro (disregaring number types)
21:57:53 <vincenz> :
21:57:59 <vincenz> a -> [b] -> [b]
21:58:01 <vincenz> now I want
21:58:08 <vincenz> a -> [CounterState b] -> [CounterState b]
21:59:09 <vincenz> but I can't use <-
21:59:15 <vincenz> cause the outer type is [] not b
21:59:22 <vincenz> oh!
21:59:28 * vincenz does something
21:59:38 <Cale> well, you're taking in a list of computations, and you want to spit out a list of computations
21:59:43 <vincenz> yeah
22:00:17 <Cale> hmm, this is in elimError
22:00:35 <vincenz> I have an idae
22:00:41 <vincenz> elimError n (x:b:xs) = (f x b) : elimError n (b:xs)
22:00:41 <vincenz>     where f cx cb = do
22:00:41 <vincenz>       x <- cx
22:00:41 <vincenz>       b <- cb
22:00:41 <vincenz>       return ((b * nPow - x) / (nPow - 1))
22:00:43 <vincenz>     where nPow = 2 ** (fromIntegral n)
22:00:46 <vincenz> but it doens't like that syntax
22:00:52 <vincenz> empty do construct
22:01:09 <Cale> you don't want the second where
22:01:18 <vincenz> and the x <- cx had to be more to the right
22:01:21 <Cale> and the x <- cx needs more tabbage
22:01:23 <vincenz> worked :)
22:02:04 <newsham> lots of work for counting computation :)
22:02:14 <vincenz> :D
22:02:47 <vincenz> woo
22:02:51 <vincenz> everything works now except for test
22:05:58 <vincenz> \o
22:06:25 <vincenz> yay
22:06:40 <vincenz> although the number seems to be off
22:07:06 <vincenz> yep, way off
22:09:38 * vincenz mutters as he accidentally loses all his stuff
22:10:01 <Cale> hm?
22:10:02 <vincenz> shoot me please
22:10:10 <Cale> why is it off?
22:10:25 <Cale> what are you getting?
22:10:27 <vincenz> numbers of evaluations are too high
22:10:33 <vincenz> wait let me redo the stuff
22:10:43 <vincenz> (was trying to get originial impl, and now I lost all my changes due to a filemove)
22:14:31 <newsham> s'ok it wasant much code... just a few lines of haskell :)
22:17:02 <vincenz> ok
22:17:10 <vincenz> original impl with trace: 6 evaluations
22:17:21 <vincenz> new impl with monads: value = 12
22:19:51 <vincenz> is this cause the monad reforces certain evals?
22:23:46 <vincenz> @type addpair
22:23:47 <lambdabot> Not in scope: `addpair'
22:24:04 <vincenz> @hoogle (a -> b -> c) -> [(a,b)] -> [c]
22:24:05 <lambdabot> No matches, try a more general search
22:24:12 <vincenz> @hoogle (a -> b -> c) -> (a,b) -> c
22:24:14 <lambdabot> Data.Tuple.uncurry :: (a -> b -> c) -> (a, b) -> c
22:24:14 <lambdabot> Prelude.uncurry :: (a -> b -> c) -> (a, b) -> c
22:28:19 <vincenz> yep
22:28:21 <vincenz> that's the problem
22:28:22 <vincenz> :)
22:28:46 <vincenz> http://rafb.net/paste/results/ASrR6v28.html
22:29:29 <vincenz> how to fix?/
22:40:51 <vincenz> apparently monads reforce evaluation
22:41:36 * vincenz detaches and goes to sleep
22:44:31 <Cale> vincenz: sort of, in this sense
22:56:11 <araujo> @yaw!
22:56:12 <lambdabot> quote module failed: getRandItem: empty list
23:01:47 <Cale> @yow
23:01:47 <lambdabot> quote module failed: getRandItem: empty list
23:01:59 <Cale> hmm
23:02:03 <Cale> @reconnect
23:02:09 <Cale> @yow
23:03:16 <lambdabot> quote module failed: getRandItem: empty list
23:05:02 <araujo> :-P
23:48:58 <mempko> h
23:53:09 <mempko> does anyone here know of an easy way to get HOpenGL to work on Mac os x
23:53:51 <mempko> or suggest a better library for opengl and haskell
23:57:10 <mempko> as hopengl seems as though it has not been worked on in two years
