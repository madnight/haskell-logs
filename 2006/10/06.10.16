00:00:46 <jody> The number thirteen is a very good number to maths debate over. When you break it down into it's component parts, you're left with two things: a 1 and a 3. When it comes to maths debating over the number 13, there are two distinct branches of study that are, for the most part, divided suprisingly by gender. For the most part, you'll find that most females will maths debate over the 1, whilst most males will maths debate over the 3. Females tend to be drawn to th
00:00:47 <lispy> Pseudonym: whatever i'm thinking of seems to be tucked away next to difference equations in my brain
00:01:04 --- mode: ChanServ set +o Pseudonym
00:01:09 --- kick: jody was kicked by Pseudonym (Pseudonym)
00:01:13 --- mode: ChanServ set +o Cale
00:01:29 <Botty> I always thought the whole 1/inf = 0 thing was retarded
00:01:45 <bsdmonkey> yeah
00:02:04 <Cale> bsdmonkey: you shouldn't IRC as root
00:02:10 <bsdmonkey> i know
00:02:11 <lispy> ValarQ: a lot of #haskell trolls come from #math after Cale kicks them there :)
00:02:30 <Pseudonym> Amusingly, the last incarnation of that troll was root, too.
00:02:40 <bsdmonkey> how coincidental...
00:02:44 <ValarQ> lispy: ok, lets blame mr Gibbard then :o)
00:02:45 --- mode: Cale set +b *!*@65.98.24.200
00:02:49 <bsdmonkey> 13 is my favourite number. I am definitely drawn towards 1's and 3's and I have a spare night on hand.
00:05:01 --- mode: Cale set +b %*!*=root@*
00:05:18 <Pseudonym> Did you just ban bsdmonkey?
00:05:25 <Cale> silenced
00:06:53 <Cale> I have a strong suspicion that was the same troll again
00:07:01 * Pseudonym nods
00:07:05 <Pseudonym> Now that I look back, yes.
00:07:11 <ValarQ> it might have been
00:07:30 * lispy is now worried moreon is a troll :)
00:07:56 <Pseudonym> Anyway, what this actually does is computes floor (phi * n + 0.5)
00:08:08 <Pseudonym> Using continued fractions.
00:08:21 <Pseudonym> [1,1..] is the continued fraction representation of phi.
00:08:48 <Pseudonym> > let phi = (1 + sqrt 5) * 0.5 in floor (phi * 1 + 0.5)
00:08:50 <lambdabot>  2
00:08:53 <Pseudonym> > let phi = (1 + sqrt 5) * 0.5 in floor (phi * 2 + 0.5)
00:08:55 <lambdabot>  3
00:08:58 <Pseudonym> > let phi = (1 + sqrt 5) * 0.5 in floor (phi * 3 + 0.5)
00:08:59 <lambdabot>  5
00:09:10 <Pseudonym> That computes fib (n+1) from fib n
00:09:36 <Pseudonym> The "floor" bit is easy, because you just take the first digit.
00:10:08 --- mode: ChanServ set +o vincenz
00:10:35 <lispy> heh
00:10:39 <lispy> that is slick
00:10:47 <vincenz> ooh that's known :)
00:10:54 <vincenz> except that it ain't great for large fib-numbers
00:11:03 <Pseudonym> What do you mean it ain't great?
00:11:05 <vincenz> due to the problems with real-numbers
00:11:13 <Pseudonym> But I use continued fractions. :-)
00:11:15 <vincenz> Pseudonym: limited accuracy for real numers?
00:11:22 <vincenz> Pseudonym: for sqrt 5?
00:11:22 <Pseudonym> All integer arithmetic.
00:11:24 <lispy> vincenz: http://paste.lisp.org/display/28049
00:11:26 <Pseudonym> Sure.
00:11:37 <Pseudonym> phi is [1,1,1,1,1...]
00:11:57 <lispy> Pseudonym: is it very efficient?
00:12:01 <Pseudonym> Nope.
00:12:05 <vincenz> > 1 + 1/2 + 1/4 + 1/8
00:12:06 <lambdabot>  1.875
00:12:10 <vincenz> > sqrt 5
00:12:11 <lambdabot>  2.23606797749979
00:12:22 <Pseudonym> But it doesn't need to be.
00:12:36 <Pseudonym> Because you only need the first element.
00:13:17 <lispy> Pseudonym: i mean is it efficient for computing fibs
00:13:20 <Pseudonym> let h a b c d = if a `div` c == b `div` d then a `div` c else h (a+b) a (c+d) c in 1 : iterate (\n -> h (4*n+1) (2*n+1) 2 2) 1
00:13:31 <Pseudonym> > let h a b c d = if a `div` c == b `div` d then a `div` c else h (a+b) a (c+d) c in 1 : iterate (\n -> h (4*n+1) (2*n+1) 2 2) 1
00:13:32 <lambdabot>  [1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946,17...
00:13:45 <Pseudonym> It's not too bad.
00:14:53 <lispy> faster than O(n) ?
00:15:20 <Pseudonym> I think that h is roughly O(1).
00:15:25 <Pseudonym> On this data.
00:16:29 <Pseudonym> Actually, this suggests an alternative O(log n) algorithm.
00:16:55 <lispy> what is the best complexity for fibs?
00:17:41 <Pseudonym> O(log n) is the best I've been able to do.
00:18:09 <astrolabe> unless you use the formula I s'pose
00:21:56 <Pseudonym> Which formula would that be?
00:22:17 <Botty> the phi one
00:27:34 <astrolabe> > let {phi = (sqrt 5 + 1)/ 2;n=10} in (phi**n-(1-phi)**n)/sqrt 5
00:27:35 <lambdabot>  55.000000000000014
00:30:24 <zarvok> That's an interesting question.  Can we bound the floating point error somehow to show that taking the nearest integer or something will give the right fib, or is this false for large enough values?
00:30:31 <vincenz> hey zarvok
00:30:35 <zarvok> hey vincenz
00:31:14 <astrolabe> It will be false for large enough values
00:31:25 <Pseudonym> astrolabe: That's O(log n).
00:31:38 <Pseudonym> The complexity is hidden in the raise-to-the-power-of operator.
00:31:43 <Pseudonym> @let fib3' a b c d = if a `div` c == b `div` d then a `div` c else fib3' (a+b) a (c+d) c
00:31:43 <Pseudonym> @let fib3 0 = 0
00:31:43 <Pseudonym> @let fib3 1 = 1
00:31:43 <Pseudonym> @let fib3 2 = 1
00:31:43 <Pseudonym> @let fib3 3 = 2
00:31:44 <lambdabot> Defined.
00:31:44 <Pseudonym> @let fib3 k = let { (q,r) = k `divMod` 2; a = fib3 q; b = fib3' (4*a+1) (2*a+1) 2 2 } in if r == 0 then 2*a*b - a*a else a*a + b*b
00:31:45 <lambdabot> Defined.
00:31:45 <lambdabot> Defined.
00:31:46 <lambdabot> Defined.
00:31:47 <lambdabot> Defined.
00:31:48 <lambdabot> Defined.
00:31:57 <Pseudonym> > map L.fib3 [0..10]
00:31:58 <lambdabot>  [0,1,1,2,3,5,8,13,21,34,55]
00:32:01 <Pseudonym> Yay.
00:32:07 <Pseudonym> That's O(log n)
00:32:13 <astrolabe> Pseudonym: raise to the power isn't log n if you use exp is it?
00:32:14 <Pseudonym> It's a shame you need all those base cases, though.
00:32:53 <Pseudonym> astrolabe: Good question.  The obvious way to implement log is O(log n) in the number of significant bits of n.
00:33:16 <Pseudonym> x^y = exp (y * log x)
00:33:21 <Pseudonym> Hmm.
00:33:23 <Pseudonym> I don't know.
00:33:30 <Pseudonym> What's the obvious way to implement exp?
00:33:39 <astrolabe> The series
00:33:42 <lispy> taylor :)
00:33:45 <Pseudonym> Right.
00:33:50 <Pseudonym> There's hidden complexity there.
00:33:52 <lispy> which needs factorial
00:34:06 <astrolabe> But it converges very quickly
00:34:18 <Pseudonym> Even so, it's not going to be O(1).
00:34:40 <lispy> i would say x^y = exp (y * log x) is a bad way to compute it in this context
00:34:45 <astrolabe> It can't be O(1), because even printing the result isn't O(1)
00:34:52 <Pseudonym> I would think so too, lispy.
00:35:09 <astrolabe> why is it bad?
00:35:21 <lispy> we have more information
00:35:46 <lispy> are you talking about using it in the phi function right?
00:35:53 <astrolabe> yes
00:36:03 <vincenz> > L.fib3 1000000
00:36:07 <lambdabot> Terminated
00:36:09 <vincenz> > L.fib3 10000
00:36:11 <lambdabot>  3364476487643178326662161200510754331030214846068006390656476997468008144216...
00:36:14 <vincenz> > L.fib3 100000
00:36:18 <lambdabot> Terminated
00:36:22 <vincenz> > L.fib3 50000
00:36:26 <lambdabot> Terminated
00:36:34 <lispy> heh
00:36:37 <lispy> binary search!
00:36:46 <vincenz> always
00:36:53 <vincenz> > L.fib3 25000
00:36:57 <lambdabot>  2195438355517303012780791914841720922849015222302155773145178112730662303998...
00:37:03 <vincenz> > L.fib3 35000
00:37:06 <lispy> > L.fibs3 75000
00:37:07 <lambdabot> Terminated
00:37:07 <lambdabot>  Not in scope: `L.fibs3'
00:37:13 <vincenz> ah well
00:37:19 <vincenz> somewhere between 25k and 35k
00:37:20 <lispy> oh i misread
00:37:28 <lispy> > L.fibs3 30000
00:37:29 <lambdabot>  Not in scope: `L.fibs3'
00:37:39 <lispy> > L.fib3 30000
00:37:43 <lambdabot> Terminated
00:37:52 <lispy> > L.fib3 27500
00:37:56 <lambdabot>  6465794124466878123000828783403275700597915786878354858442289830282352202432...
00:38:06 <lispy> > L.fib3 29000
00:38:10 <lambdabot> Terminated
00:38:10 <Pseudonym> > L.fib3 50000 `seq` ()
00:38:14 <lambdabot> Terminated
00:38:16 <zarvok> Anyone know offhand how much time lambdabot gives to a request?  Looks like around a second
00:38:18 <Pseudonym> > L.fib3 30000 `seq` ()
00:38:19 <lispy> > L.fib3 28000
00:38:23 <lambdabot> Terminated
00:38:23 <zarvok> or two
00:38:26 <lambdabot>  2015774733273593126239641913404571447387987743234789679740049851893938443966...
00:38:33 <lispy> zarvok: i was thinking 3 seconds for evaluation
00:38:36 <lispy> ?help run
00:38:36 <lambdabot> run <expr>. You have Haskell, 3 seconds and no IO. Go nuts!
00:38:40 <zarvok> heh
00:38:44 <zarvok> there we are
00:39:00 <lispy> > L.fib3 27750
00:39:04 <lambdabot>  1141647249663799910293658279352839435220176541704644403872206592649626893641...
00:39:07 <vincenz> of course it depends on serverload
00:39:11 <lispy> > L.fib3 27950
00:39:14 <vincenz> cause I think it's 3 second clocktime
00:39:15 <lambdabot>  7162423307452323284942947073945811502643107830553813909034901508490878342106...
00:39:17 <vincenz> not usertime
00:39:19 <zarvok> yes
00:39:30 <zarvok> at least, that's what I'd guess as well
00:39:35 <lispy> > L.fib3 27975
00:39:36 <vincenz> > L.fib3 27975
00:39:39 <lambdabot>  1201575296524203416267856462798351211931575055113142268724263513452822425284...
00:39:42 <vincenz> > L.fib3 27985
00:39:43 <lambdabot> Terminated
00:39:45 <lispy> heh
00:39:46 <vincenz> lispy: lol
00:39:47 <lambdabot>  1477839919218346145738347739575801393518588583615456481886597265732738109096...
00:39:50 <vincenz> > L.fib3 27995
00:39:55 <lambdabot>  1817622943108913338916540934031955878906670800341500158493642210499922591945...
00:39:59 <vincenz> > L.fib3 27999
00:40:03 <lambdabot>  1245817298826334142522115966723381986010926061947703811013902755346361518218...
00:40:06 <vincenz> > L.fib3 28000
00:40:09 <lispy> why is it faster for you!
00:40:10 <lambdabot>  2015774733273593126239641913404571447387987743234789679740049851893938443966...
00:40:14 <vincenz> i'm more important
00:40:16 <lispy> not fair!
00:40:18 <zarvok> heh
00:40:34 * lispy goes in the corner to sulk
00:40:38 <astrolabe> > let {phi = (sqrt 5 + 1)/ 2;n=28000} in (phi**n-(1-phi)**n)/sqrt 5
00:40:39 <lambdabot>  Infinity
00:40:44 <astrolabe> heh
00:41:57 <Pseudonym> Anyway, this algorithm does use phi.
00:42:04 <Pseudonym> It just hides it well.
00:42:35 <astrolabe> That doesn't mean it has the same efficiency though.
00:43:08 <Pseudonym> Though mine clearly works and yours doesn't. :-)
00:43:21 <astrolabe> Maybe the answer is infinity :)
00:43:55 <astrolabe> Until you prove it by hand, we won't know.  Can't trust computers.
00:44:22 <Pseudonym> > length (show (L.fib3 28000))
00:44:26 <lambdabot> Terminated
00:44:28 <Pseudonym> > length (show (L.fib3 28000))
00:44:32 <lambdabot>  5852
00:44:46 <Pseudonym> It's not impossible.
00:44:59 <Pseudonym> Writing out a googol in decimal notation is just tedious, not hard.
00:46:13 <vincenz> preferably with set-theoretic constructs
00:47:20 <astrolabe> The proof that it is finite is much shorter than evaluating it.
00:50:10 <astrolabe> I guess the efficiency of the formula is the same (big O), because of calculating sqrt 5 accurately enough.
01:00:31 <Pseudonym> Must away.  Nytol!
01:01:57 <zarvok> > let {phi = (sqrt 5 + 1)/2; fib n = let n' = fromInteger n in floor ((phi**n'-(1-phi)**n')/sqrt 5); dlist = [n | n <- [1..], L.fib3 n /= fib n] } in head dlist
01:01:59 <lambdabot>  72
01:02:09 <zarvok> > L.fib3 72
01:02:11 <lambdabot>  498454011879264
01:03:14 <vincenz> breaks down quite fast
01:03:24 <zarvok> guess so
01:03:43 <zarvok> > let {phi = (sqrt 5 + 1)/2; fib n = let n' = fromInteger n in floor ((phi**n'-(1-phi)**n')/sqrt 5)} in fib 72
01:03:44 <lambdabot>  498454011879265
01:03:50 <zarvok> yep
01:04:33 <profmakx> um
01:40:39 * lispy makes a resolution to never sleep again!
01:41:47 <Patterner> sleep is for wusses
01:41:55 * lispy yawns
01:42:00 <lispy> yeah!
01:42:12 <Captain_Fourier> do it!
01:42:14 * lispy accidentally dozes off for a second
01:42:22 <lispy> do what?
01:42:23 <Syzygy-> > map L.fib3 [1..10]
01:42:25 <lambdabot>  [1,1,2,3,5,8,13,21,34,55]
01:42:41 * lispy sees more fibs and tries to stay a wake :)
01:43:32 <dmead> haha
01:43:37 <dmead> > sleep
01:43:38 <lambdabot>  Not in scope: `sleep'
01:43:43 <dmead> > "sleepy"
01:43:44 <lambdabot>  "sleepy"
01:43:52 <dmead> > "Hi my name is lambdabot"
01:43:53 <lambdabot>  "Hi my name is lambdabot"
01:44:01 <dmead> > "I like cheese"
01:44:02 <lambdabot>  "I like cheese"
01:44:20 <lispy> ?unquote "I like cheese"
01:44:21 <lambdabot> "I like cheese" hasn't said anything memorable
01:44:25 <lispy> lol
01:44:29 <lispy> guess unquote was removed?
01:44:36 <lispy> ?quote dmead
01:44:36 <lambdabot> dmead hasn't said anything memorable
01:45:25 <zarvok> ?localtime zarvok
01:45:26 <lambdabot> Local time for zarvok is Mon Oct 16 04:45:03 2006
01:45:29 <zarvok> I need some sleep soon
01:45:34 <lispy> oy
01:45:34 <zarvok> but now I feel shamed
01:45:38 <lispy> you're later than me
01:45:48 <lispy> yeah, i'm supposed to work tomorrow
01:45:53 <zarvok> I am grading very bad induction proofs.  It takes a long time :(
01:45:58 <lispy> oh, in fact, maybe i'll hack on hdirect again in the morning...
01:46:03 <lispy> heh
01:46:30 <lispy> want to see my induction that set of n elements is size 2^n?
01:46:54 <Igel> > fib = 0 : 1 : [zipWith (+) fib]
01:46:55 <lambdabot>  Parse error
01:47:04 <zarvok> heh, it would be an interesting proof since you dropped the word power :)
01:47:18 <Syzygy-> > let fib = 0 : 1 : [zipWith (+) fib] in take 10 fib
01:47:19 <lambdabot>    Occurs check: cannot construct the infinite type: b = [b] -> [b]
01:47:19 <lambdabot>    E...
01:47:22 <zarvok> at least, I assume that's what you meant
01:47:45 <Syzygy-> > let fib = 0 : 1 : zipWith (+) fib in take 10 fib
01:47:45 <lambdabot>    Expecting a function type, but found `[a]'
01:47:46 <lambdabot>    Expected type: [a]
01:47:46 <lambdabot>   ...
01:48:00 <zarvok> ugh, occurs check, before I was grading I was writing prolog, I just can't escape
01:48:25 <Igel> fib where fib = 0 : 1 : zipWith (+) fib
01:48:25 <Bobstopper> ?localtime lispy
01:48:27 <lambdabot> Local time for lispy is Mon Oct 16 01:48:01 2006
01:48:30 <Igel> > fib where fib = 0 : 1 : zipWith (+) fib
01:48:31 <lambdabot>  Parse error
01:48:42 <Bobstopper> You guys oughta try polyphasic sleeping :P
01:48:47 <Bobstopper> (not really. I've done it. It's crap)
01:48:53 <lispy> n = 0: sum of elemens is sum_{i=0}^{n}(n \choose i} = sum_{i=0}^{n}(n \choose i}(a^(n-i)b^i) assuming a = b = 1.  Well, given this form we can rewrite it to sum = (a + b)^n, but a=b=1 so 2^n.  n > k: repeat argument (gotta love that induction) ;)
01:48:56 <zarvok> what's that?
01:49:21 <Bobstopper> http://en.wikipedia.org/wiki/Polyphasic_sleep
01:49:21 <zarvok> polyphasic sleeping, I mean
01:49:48 <Bobstopper> I did it for a month and contributed the bulk of the criticisms to the wikipedia entry
01:49:49 * lispy <3 binomial theorem
01:50:03 <lispy> zarvok: yeah, i did for get to say power set, but of course you knew what i meaned
01:50:13 <Bobstopper> It's a bit of a fad around some places but it doesn't work like people pretend it does.
01:51:05 <roconnor> hey zarvok
01:51:12 <zarvok> I think it would be inconvenient.  I'm not around a bed often enough
01:51:15 <zarvok> hey roconnor
01:51:20 <lispy> Bobstopper: yeah, it sounds like BS to me :)
01:51:22 <zarvok> 10 to 1 you want to know when we are going to release stuff
01:51:24 <zarvok> I saw your e-mail
01:51:31 <zarvok> :)
01:51:43 <Bobstopper> But if you really need lots of awake time over a period of less than a month it can be useful. But considering it a lifestyle thing is indeed BS
01:51:57 <Syzygy-> @type zipWith
01:51:58 <lambdabot> forall c b a. (a -> b -> c) -> [a] -> [b] -> [c]
01:52:03 <roconnor> zarvok: do you happen to know what the status of the final codex is?
01:52:16 <Syzygy-> Bobstopper: I know quite a number of people who do polyphasic sleep over long intervals...
01:53:02 * lispy &
01:53:02 <zarvok> Our plan is next week, but it's hard to say, it keeps getting pushed back as stuff comes up.  Last week it was a grant proposal, this week who knows
01:53:03 <Igel> let fib = 0 : 1 : (zipWith (+) fib (take 1 fib)) in fib
01:53:08 <Igel> > let fib = 0 : 1 : (zipWith (+) fib (take 1 fib)) in fib
01:53:10 <lambdabot>  [0,1,0]
01:53:22 <roconnor> zarvok: ah okay, but it is still in the works?
01:53:39 <Cale> > let fib = 0 : 1 : (zipWith (+) fib (drop 1 fib)) in fib
01:53:41 <lambdabot>  [0,1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946,...
01:53:45 <zarvok> roconnor: yes, we definitely plan to release soon.  New puzzles, some easter eggs, some bug fixes, and a paper
01:54:05 <zarvok> plus source, of course
01:54:12 <roconnor> zarvok: cool.  Well, let the team know that people are still excited by it. :)
01:54:13 <Igel> Cale: oops, i mixed up take and drop
01:54:28 <Bobstopper> Syzygy-: over how long, how often do they crash and how productive are they *really* during their melatonin peak?
01:54:53 <zarvok> roconnor: yeah, thanks, I will
01:55:04 <Syzygy-> Bobstopper: I would have to poke them about data, but I know one of them has done some sort of polyphasic over a span of at least about a year.
01:55:40 <Bobstopper> I'd be interested to hear their feedback then. I've seen a lot of anecdotal stuff but little hard data.
01:55:40 <Syzygy-> Which is in no way to say everybody could do it or even would benefit from it...
01:56:04 <Bobstopper> I tried it for a month and found I kept sleeping through my alarm and was next to useless at about 04:00 every morning
01:56:30 <Bobstopper> my theory about polyphasic sleepers is they're self-delusional in much the same way as breatharians
01:56:39 <Bobstopper> but I'm willing to be shown differently :)
02:14:42 <Lemmih> Kick ass!
02:14:53 * Lemmih just got his google t-shirt.
02:21:59 <alar> How can I find a way to figure what causes my program to eat all the memory? With GHC
02:22:57 <Cale> alar: profiling
02:23:10 <Cale> http://www.haskell.org/ghc/docs/6.4.2/html/users_guide/profiling.html
02:23:13 <lambdabot> Title: Chapter 5. Profiling, http://tinyurl.com/qtwbd
02:23:27 --- mode: Cale set -oo Cale vincenz
02:23:30 <musasabi> shapr: pong
02:23:36 <Cale> Is it a large program?
02:23:48 <alar> no, it is rather simple
02:23:58 <Cale> I might be able to have a look through it
02:25:30 <alar> handmade parser in list monad
02:25:47 <alar> being applied to LARGE file it consumes all memory
02:28:46 <alar> it seems I've just found what
02:28:58 <alar> there is left fold
02:30:52 <dozer> dang, I have "Cycle in type synonym declarations" again
02:33:12 * mwc whiles petulantly to dcoutts 
02:33:15 <mwc> *whines
02:33:23 <dcoutts> ?
02:33:33 <mwc> still no 0.98.11 :)
02:33:40 <dcoutts> heh
02:33:44 <dcoutts> we're working on it
02:33:46 <mwc> er, 0.9.11
02:34:05 <mwc> So you're saying I woke up at 0530 for nothing... again?
02:34:13 <dcoutts> you can help! :-)
02:34:32 <dcoutts> why did you wake up at 5:30 ?
02:34:36 <dcoutts> freak! ;-)
02:34:54 <zarvok> mwc: some of us are still awake at 5:30!  Much jealousy :)
02:34:59 <Cale> alar: yeah, left folds which are not foldl' tend to build up large expressions
02:35:20 <mwc> @type foldl'
02:35:21 <lambdabot> forall a b. (a -> b -> a) -> a -> [b] -> a
02:35:32 <mwc> oh right, strictness.
02:37:15 <mwc> foldl' f z [] = z; foldl' f z (x:xs) = let y = f z x in y `seq` foldl' f y xs?
02:37:42 <alar> Cale: are 'foldl'-built constructions deforested?
02:39:28 <Cale> hmm... not usually anyway
02:39:41 <Cale> mwc: yeah
02:40:33 <alar> even with prelude foldl?
02:41:11 <alar> that probably means I should manually deforest my program
02:41:40 <mwc> Huh... is Hackage supposed to be broken?
02:41:50 <Cale> You could look and see what RULES pragmas there are in the source
02:42:10 <mwc>  Trac detected an internal error:
02:42:11 <mwc> maximum recursion limit exceeded
02:42:19 <alar> in Prelude.hs?
02:44:37 <Cale> http://darcs.haskell.org/packages/base/GHC/List.lhs -- there don't seem to be any
02:44:41 <lambdabot> http://tinyurl.com/sv6vw
02:45:15 <Cale> Why a left fold?
02:45:28 <Cale> Can you rewrite it as a right fold?
02:48:14 <Cale> Accumulating parameters and lazy evaluation don't mix well
02:48:32 <alar> I'll try rewriting
02:48:45 <Cale> You generally want to design your functions so that they immediately return some dataconstructor whenever that's possible
02:49:54 <alar> that's possible because the program is very simple
03:07:22 <dozer> do type declarations need to be introduced before they are used?
03:08:05 <ozone> dozer: not sure what you mean.  you don'
03:08:12 <ozone> 't need type declarations on functions, in most cases
03:08:35 <dozer> na, I mean "type Foo = [Bar] ; type Bar = String"
03:08:56 <ozone> ah, right.  no, that'll work just fine
03:09:28 <dozer> weird - I'm having to say "type Bar = String ; type Foo = [Bar]"
03:09:41 <dozer> except the type decls are a bit more involved than that
03:10:05 <ozone> hmmm, to be honest, it's been a while since i played with haskell, so maybe i'm wrong
03:10:52 <dozer> np
03:12:41 <Cale> dozer: hm? They have to be somewhere in scope
03:13:10 <Cale> Doesn't matter where they are in your file, but you have to declare types which you're going to use.
03:16:38 <integral> Is there a function that inverts an Ordering?  ie. EQ |-> EQ, LT |-> GT, GT |-> LT.
03:17:09 <Cale> I don't think so, but it's a good idea
03:17:49 <integral> hmm, so no other neat way to get a sort in reverse order?
03:17:54 <dozer> I couldn't find that function last time I looked - perhaps should be defined in the same module as Ordering?
03:18:08 <integral> dozer: is Ordering in anything other than Prelude?
03:18:17 <dozer> don't think so
03:18:20 <Cale> oh, flip compare :)
03:18:44 <integral> doh.
03:18:48 <integral> thank's Cale :-)
03:18:59 <dozer> seems we're still not thinking funcitonally :/
03:19:08 <integral> especially since (invertOrd . compare) doesn't work *sigh*
03:51:20 * SamB wonders why this nofib README identifies itself as belonging to nofib version 2.05...
03:52:37 <wolverian> it has an age crisis?
03:53:36 <roconnor> SamB, how's it going?
03:57:20 <SamB> roconnor: well.
03:58:24 <SamB> I've found some significant differences in the interface files produced by my patched version...
04:02:45 <roconnor> I'm surprised that some tests seem to be much slower.
04:02:59 <roconnor> I'm not too surprised that file sizes are 1% bigger
04:03:19 <SamB> which tests are much slower?
04:03:28 * SamB missed those
04:05:45 <roconnor>           solid           1.0%      0.0%      3.9%
04:06:21 <roconnor>         integer           0.9%      2.1%      1.9%
04:06:33 <roconnor>           power           0.9%      0.0%      1.9%
04:07:38 <roconnor> I'm actually kinda suprised anything is slower.  Must have something to do with allocations and GC.
04:08:52 <SamB> not necessarily
04:11:28 <SamB> a lot of things are inexplicably mising HasNoCafRefs...
04:12:27 <roconnor> Um, what does that mean?
04:13:32 <SamB> I think it is bad.
04:13:40 <roconnor> :/
04:14:00 <roconnor> on the plus side, our geometric mean for speed increase is 0.4% :)
04:14:31 <SamB> hmm.
04:14:46 * SamB doesn't actually understand those percentages well :-(
04:15:07 <roconnor> I assume the negatives are good and positives are bad.
04:21:21 <SamB> I suppose
04:38:43 <SamB> hmm
04:38:52 <SamB> I should be ready for school already...
04:43:50 <brett_> has anyone here had any luck getting 6.6 up and running on freebsd/amd64 ?
04:59:42 <Patterner> it works with linux/amd64...
05:10:34 <Patterner> hmm... where can i get hdbc_1.0.1.tar.gz? quux.org is down...
05:20:29 <ACSpike> good morning
05:22:50 <Psyche^> ACSpike: moin moin
05:23:01 <Lemmih> Patterner: I have a fork of it at http://darcs.haskell.org/~lemmih/ghc6.6/hdbc
05:23:05 <lambdabot> Title: Index of /~lemmih/ghc6.6/hdbc
05:31:03 <matthew__> hey. can someone help my little brain understand the following:
05:31:11 <matthew__> > [1..5] >> "abc"
05:31:12 <lambdabot>  "abcabcabcabcabc"
05:31:52 <matthew__> so, um, that's apply [1..5] into "abc"
05:32:07 <matthew__> but why does the result happen?
05:33:33 <dylan> because of the list monad?
05:34:41 <chessguy> @paste
05:34:42 <lambdabot> http://paste.lisp.org/new/haskell
05:34:53 <chessguy> wow, somebody didn't get his coffee this morning
05:35:04 <chessguy> or am i lagging
05:35:27 <matthew__> dylan: oh yeah, just read that... ;)
05:38:06 <lisppaste2> chessguy pasted "Cleaner way to do this?" at http://paste.lisp.org/display/28058
05:38:54 <ndm> chessguy: length (filter f xs) ?
05:39:04 <chessguy> oh man
05:39:06 <chessguy> duh!
05:39:16 <chessguy> i knew i was missing something simple
05:39:38 <beelsebob> @where hoogle
05:39:38 <lambdabot> http://www.haskell.org/hoogle
05:39:43 <chessguy> thanks
05:51:42 <roconnor> @hoogle union
05:51:43 <lambdabot> List.union :: Eq a => [a] -> [a] -> [a]
05:51:43 <lambdabot> Data.IntMap.union :: IntMap a -> IntMap a -> IntMap a
05:51:43 <lambdabot> Data.IntSet.union :: IntSet -> IntSet -> IntSet
05:51:52 <roconnor> @fptools Data.List
05:51:52 <lambdabot> http://darcs.haskell.org/packages/base/Data/List.hs
05:54:14 <ndm> SamB, did you start doing any work on pretty printing for Yhc.Core?
05:56:34 <xinming> anyone here uses gentoo? *_*
05:59:26 <ndm> dcoutts, xinming is giving you teh gentoo ping
05:59:34 <ndm> @seen Lambdabot
05:59:34 <lambdabot> Yes, I'm here. I'm in #ScannedInAvian, #perl6, #oasis, #darcs, #ghc, #gentoo-haskell, #haskell_ru, #haskell.es, #haskell.se, #haskell.it, #haskell-overflow, #haskell-blah and #haskell
05:59:52 <ndm> xinming: #gentoo-haskell probably has a few gentoo users in it
05:59:59 <Smokey`> xinming: my *nix box uses gentoo :)  though I haven't needed to do anything overly complicated recently.
06:01:08 <xinming> Smokey`: :-P In fact, I just wish to ask when would ghc 6.6 be in portage, as now, I need to compile it myself, It's time cosuming and also a pain....
06:02:04 <Patterner> xinming: <AOL> MEE TO </>
06:02:29 <Patterner> xinming: you want ghc-bin 6.6, right?
06:02:42 <xinming> Yes
06:03:15 <Smokey`> xinming: I get the feeling someone in #gentoo-haskell might be the person making the ebuilds for haskell
06:03:25 <Smokey`> but that's just a bit of a hunch
06:03:45 <sjanssen> xinming: there is an ebuild for GHC 6.6 in a portage overlay
06:03:50 <ndm> i strongly suspect its dcoutts, but agin, just a hunch
06:03:57 <sjanssen> the build worked quite well for me
06:04:04 <xinming> The one offered in ghc home page might not work with glibc 2.4
06:04:47 <xinming> sjanssen: thanks... could you please give me the home url for this? I ever used overlay, and at last, I give up. :-P
06:05:06 <sjanssen> xinming: the build shouldn't take more than a couple hours.  Shouldn't you be used to this sort of waiting with Gentoo? ;)
06:05:08 <Patterner> xinming: Interested in ghc-6.6.tbz2? (x86_64, glibc 2.5)
06:05:33 <xinming> since I just wish use something which are "officially" included...
06:05:48 <xinming> Patterner: I'm using 2006.1 x86. >_<
06:06:14 <Smokey`> sjanssen: lol, suprisingly there's not much waiting if you aren't too worried about compile-time optimizations of everything you emerge :)
06:06:27 <xinming> sjanssen: yes, I do, But with gentoo, I can use distcc.
06:06:53 <sjanssen> xinming: true, true.  Distcc+ghc would be swell
06:08:20 <Patterner> unless you have only one computer...
06:08:57 <sjanssen> xinming: http://www.gentoo.org/proj/en/overlays/userguide.xml -- there's a nice guide to portage overlays
06:08:59 <ndm> just use Yhc, only takes about 10 minutes to install, and have a gentoo ebuild as well
06:09:00 <lambdabot> Title: Gentoo Linux Documentation -- Gentoo Overlays: Users' Guide, http://tinyurl.com/sjzcj
06:11:05 <jmmv> hi
06:11:20 <petekaz> How can I use liftM to just pull the first argument from getArgs and assign it in a do block?  I always end up doing: do args <- getArgs; let a = args !! 0, can I combine that in one line?
06:11:49 <sjanssen> @type liftM head getArgs
06:11:50 <lambdabot> Not in scope: `getArgs'
06:12:21 <int-e> or (arg0:_) <- getArgs
06:12:50 <xinming> Ok,thanks all
06:13:32 <petekaz> thanks.
06:13:33 <sjanssen> int-e's solution has the nice property that GHC will give you a line number when the pattern match fails
06:14:31 <petekaz> in erlang, one can match many items in a list, can I do that in haskell?
06:15:20 <sjanssen> > let f (x:y:z:xs) = x + y + z in f [1..]
06:15:21 <lambdabot>  6
06:15:56 <petekaz> thanks.
06:16:08 * roconnor wonders if that is a lazy pattern match.
06:16:38 <sjanssen> roconnor: nope
06:16:38 <int-e> no. it's evaluated as soon as the value of f is requested.
06:16:59 <int-e> err, of f applied to something.
06:17:08 <petekaz> what does a "lazy pattern match" mean?
06:17:37 <sjanssen> > let f ~(x:xs) = 0 in [] -- see how this doesn't give an error?
06:17:38 <lambdabot>  Add a type signature
06:17:47 <petekaz> x,y,z,and xs get bound as soon as f is evaluated?
06:17:53 <int-e> > let f ~(x:xs) = [x] in length $ f []
06:17:53 <sjanssen> > let f ~(x:xs) = 0 in f [] -- see how this doesn't give an error?
06:17:54 <lambdabot>  1
06:17:55 <lambdabot>  0
06:18:10 <int-e> > let f ~(x:xs) = [x] in f [] :: [Int]
06:18:12 <lambdabot>  Irrefutable pattern failed for pattern (x : xs)
06:18:17 <petekaz> what's ~ do?
06:18:29 <sjanssen> petekaz: makes the following match lazy
06:18:37 <petekaz> oh.
06:19:14 <petekaz> I understand now.
06:19:23 <int-e> it makes the pattern lazy, or 'irrefutable' as the Haskell report calls it. It matches always but when one of the matched variables is used, there will be an error if the pattern doesn't match the corresponding data.
06:19:34 <petekaz> Thanks, I didn't know that pattern matches caould be made lazy, is this a ghc thing only?
06:19:44 <int-e> no, that's Haskell 98
06:20:17 <int-e> basically it works like a let binding. (in the report, let bindings get translated to lazy patterns, but you could also do it the other way)
06:20:20 <ValarQ> btw of irrefutable patterns... why isn't that default when the function type specifies a tuple?
06:20:44 <int-e> then, let f ~(x:xs) = [x]  becomes  f xs' = let (x:xs) = xs' in [x]
06:20:48 <sjanssen> ValarQ: that is a good question
06:20:49 <ValarQ> it shouldn't be to interesting to patternmatch on something else than a tuple then
06:21:08 <hyrax42> hmm
06:21:17 <roconnor> Aren't the pattern matches in a case analysis with one constructor lazy?
06:21:30 <hyrax42> my quest to discover how many nodes are at each level of the game tree was a semi-miserable failure
06:21:31 <sjanssen> roconnor: I don't think so
06:21:36 <roconnor> > case undefined of () -> 7
06:21:37 <lambdabot>  Undefined
06:21:49 <roconnor> > case () of () -> 7
06:21:50 <lambdabot>  7
06:21:53 <roconnor> hmmm
06:22:01 <roconnor> I could have sworn I read that somewhere
06:22:18 <roconnor> It must have been something else
06:22:18 <norpan> that would be very strange if they were
06:22:26 <roconnor> norpan: I thought it was strange
06:22:38 <int-e> ValarQ: because it'd change the behaviour for bottom; also, the additional closures that these patterns generate have a run time cost.
06:22:39 * roconnor goes looking for what he read
06:22:47 <metaperl> does lack of objects affect haskell for large-scale software development?
06:23:16 <zzctb> hello, is there a way to clear the screen in hugs? eg. say i got a program that waits for input then, clears the screen and then prints the input to the screen.
06:23:17 <int-e> ValarQ: and adding a special case for single constructor datatypes seems nasty.
06:23:57 <ValarQ> int-e: you mean that the tuple could be undefined without breaking the typesystem?
06:23:59 <sjanssen> metaperl: probably not
06:24:08 <metaperl> sjanssen: I see
06:24:11 <int-e> ValarQ: sure.
06:24:19 <metaperl> sjanssen: you are which school in the midwest? U Oklahoma?
06:24:20 <sjanssen> but one could argue that Haskell hasn't been used much for "large-scale software development"
06:24:21 <int-e> > undefined :: (Int, Int)
06:24:22 <lambdabot>  Undefined
06:24:34 <sjanssen> metaperl: Nebraska
06:24:35 <ValarQ> int-e: ok, then i get it :)
06:24:37 <metaperl> sjanssen: ICFP is somewhat large-scale I guess
06:25:10 <roconnor> > case undefined of _ -> 7
06:25:10 <xinming> BTW, I've install layman, which overlay should I use?
06:25:11 <lambdabot>  7
06:25:14 <roconnor> ah ha
06:25:16 <roconnor> that was it
06:25:33 <sjanssen> xinming: I think it's just called haskell
06:25:56 <roconnor> > case (undefined::()) of _ -> 7
06:25:58 <lambdabot>  7
06:26:00 <Patterner> what overlay has the yhc ebuild?
06:26:11 <roconnor> > case (undefined::(Int -> Int)) of _ -> 7
06:26:12 <lambdabot>  7
06:26:15 <roconnor> heh
06:27:34 <xinming> sjanssen: No over named this.... >_<
06:27:42 <xinming> layman -L|grep haskell
06:27:43 <xinming> HomePc ~ #
06:27:58 <jmmv> zzctb, I think yi has a module (or uses one) for ncurses interaction; that should do the screen clearing
06:28:51 <sjanssen> xinming: did you remember to run layman --fetch ?
06:31:47 <xinming> sjanssen: yes, I do.
06:32:27 <sjanssen> xinming: don't know what to tell you.  it works over here
06:34:14 <xinming> sjanssen: hmm, I think It's because, It won't list the overlay, But we can check it out, I don't know why,
06:34:27 <xinming> layman -a haskell told me that I didn't have darcs installed
06:34:37 <sjanssen> oh, that'd be why
06:35:04 <sjanssen> it has to use darcs to fetch the overlay
06:41:54 <hyrax42>  /tmp/ghc574.s:11766:Fixup of 39596 too large for field width of 16 bits
06:42:04 <hyrax42> anyone knw what;s up?
06:42:16 <hyrax42> I just tried to enable profiling as outlined in the ghc manual
06:43:22 <Igloo> hyrax42: Is that on powerpc?
06:43:41 <ACSpike> wow, haskell for c programmers is a fabulous tutorial
06:43:44 <hyrax42> yes
06:43:53 <Igloo> hyrax42: Are you using -O?
06:44:03 <hyrax42> I removed it for profiling
06:44:28 <Igloo> If you remove it then you are profiling a different program to the one that you want
06:44:42 <Igloo> If you really do weant to do that then add -fvia-c
06:46:22 <hyrax42> oh I should leave the -O
06:46:27 <Igloo> yup
06:46:35 <hyrax42> what will -fvia-c do
06:47:00 <Igloo> It'll usee GCC rather than the native code generator; it's implied by -O currently
06:47:07 <Igloo> (you're seeing a bug in the NCG for PPC)
06:48:01 <hyrax42> ah ok
06:48:29 <hyrax42> thank god for darcs
06:48:40 <hyrax42> I just did rm *.hs instead of rm *.hi
06:48:56 * hyrax42 shouldn't code within 10 mins of waking up
06:49:19 <Igloo> :-)
06:50:16 * beelsebob rofls at hyrax42 
06:50:27 <beelsebob> it's only funny because of darcs
06:50:34 <xinming> Is www.haskell.org working well for you?
06:51:55 <xinming> I can't access the web, the connection would be reset... >_<
06:52:50 <Igloo> Seems fine here
06:53:11 <xinming> http://www.haskell.org/~gentoo/gentoo-haskell/_darcs/inventory
06:53:13 <lambdabot> http://tinyurl.com/y4daaq
06:53:17 <xinming> Could you access here?
06:53:32 <Igloo> Yes
06:53:53 <xinming> darcs failed:  Failed to download URL http://www.haskell.org/~gentoo/gentoo-haskell/_darcs/inventory
06:53:54 <lambdabot> http://tinyurl.com/y4daaq
06:53:55 <xinming> libcurl error code: 52
06:53:56 <xinming> Ouch...
06:58:46 <roconnor> @seen ndm
06:58:46 <lambdabot> ndm is in #ghc, #haskell-overflow, #haskell-blah and #haskell. I last heard ndm speak 29m 34s ago.
07:00:24 <ndm> @seen roconnor
07:00:24 <lambdabot> roconnor is in #ghc and #haskell. I last heard roconnor speak 1m 38s ago.
07:00:52 <roconnor> ndm: how does yhc -O handle unused parameters?
07:01:39 <ndm> roconnor: disgards them
07:02:10 <roconnor> ndm: and what if there is a chain of function calls with the final function not using it's parameter?
07:02:22 <ndm> roconnor: cleverly digards them
07:02:56 <ndm> roconnor: a parameter is used if its placed in a data structure or has a case examined on it, or passed to a function which uses that parameter
07:03:01 <roconnor> ndm: does that mean specialized version of the intermediate functions are generated with missing paremeters?
07:03:13 <ndm> roconnor: yes
07:03:21 <roconnor> :)
07:03:26 <roconnor> interesting
07:03:48 <ventonegro> anyone knows what's this gtk2hs Mogul module?
07:04:11 <roconnor> I wonder if your code will solve our problems with extracting programs from coq proofs.
07:04:24 <ndm> roconnor: whats the problem with them?
07:04:44 <roconnor> we generate a lot of functions whose parameters were only used for type checking.
07:04:57 <ndm> yeah, mine will deal with them fine
07:05:05 <ndm> can you generate Yhc.Core output from your proof stuff?
07:05:14 <roconnor> there was problems with runing the extracted code under GHC.
07:05:16 <ndm> if you can, i can certainly give you a compiler for it
07:05:24 <ndm> what was the issue?
07:05:44 <ndm> speed? or some more serious issue
07:05:45 <roconnor> I think it was that these unused parameters were sticking around.
07:05:54 <roconnor> speed was the issue.
07:06:09 <ndm> do you output haskell, or GHC Core?
07:06:12 <roconnor> I haven't studied the problem extensively, so I could be mistaken.
07:06:23 <roconnor> coq extracts haskell.
07:06:49 <ndm> any chance you could send me one of your extracted files?
07:06:53 <roconnor> It'd be a bit scary to change it to extract YHC.core, but it probably could be done.
07:07:09 <roconnor> I'd have to do Ocaml programing.
07:07:13 <ndm> if it extracts Haskell, Yhc will convert it to Yhc.Core easily enough
07:07:20 <roconnor> :)
07:07:36 <ndm> if you could just send me a few examples, ndmitchell -AT- gmail.com
07:07:45 <ndm> i'll shove them into my test suite, and keep an eye on them
07:08:02 <roconnor> Well, I'll investigate the problem more first.
07:08:08 <ndm> ok
07:08:12 <roconnor> and then see about getting you some examples.
07:08:17 <ndm> cheers
07:08:28 <ndm> anyway, got to go now, but back in 15 mins
07:11:23 <xinming> hmm
07:11:26 <xinming> http://www.haskell.org/~gentoo/gentoo-haskell
07:11:28 <lambdabot> Title: Index of /~gentoo/gentoo-haskell
07:11:32 <xinming> anyone here can open this url?
07:12:03 <sjanssen> xinming: I can
07:13:45 <xinming> .... I really don't know why I can't access that page...
07:14:03 <xinming> darcs failed:  Failed to download URL http://www.haskell.org/~gentoo/gentoo-haskell/_darcs/inventory
07:14:05 <lambdabot> http://tinyurl.com/y4daaq
07:14:06 <xinming> libcurl error code: 52
07:14:09 <xinming> * Failed to add overlay "haskell".
07:14:11 <xinming> >_<
07:28:09 <vegai> http://common-lisp.net/project/cl-darcs ...
07:28:12 <lambdabot> Title: cl-darcs
07:28:58 <ndm> sounds like a better solution is to get darcs compiling with Yhc, get Yhc bootstrapping, then you have really portable version of darcs
07:29:48 <gour> xinming: just emerge layman and then layman -a haskell
07:30:27 <vegai> ndm: oddly enough, they keep cl-darcs in an svn repository
07:30:38 <ndm> vegai: i did spot that
07:30:38 <vegai> though perhaps it's a common-lisp.net thing
07:30:50 <roconnor> ndm: now I see the problem with the extraction ... they extracted to Ocaml ;)
07:31:05 <atsampson> I guess there might be advantages to having a second implementation of Darcs, though -- if nothing else it's something that not a lot of version control systems can claim...
07:31:07 <ndm> vegai: but its a severe bootstrapping problem if you can't get your reversion system without it
07:31:24 <ndm> roconnor: ah, now that i can do nothing for...
07:31:31 <Igloo> ndm: What arches do you have yhc on that GHC isn't, OOI?
07:31:40 <roconnor> well, there is still something here to be investigated.
07:31:56 <roconnor> I need to get my hand at the code and poke around with it.
07:32:55 <ndm> Igloo: once we have Yhc bootstrapping, then our requirement will be a basic C compiler, so i guess there will be few where a port is > 10 mins
07:34:24 <xinming> gour: but the problem is. I can't get the overlay, The connection would be reset everytime I try to connect
07:34:24 <ndm> roconnor: if it depends on strictness, then Yhc probably won't help much, if on the other hand laziness is acceptable then we can do stuff
07:34:41 <xinming> I don't know if the problem is on my darcs version
07:34:45 <xinming> Now I'm upgrading it.
07:34:53 <gour> xinming: do you have layman emerged?
07:35:13 <roconnor> ndm: how can code depend on strictness?
07:35:19 <xinming> libcurl error code: 52
07:35:22 <xinming> gour: yes I do
07:35:35 <xinming> the error code would be 52, or sometimes 18
07:35:45 <gour> xinming: does layman -L shows haskell overlay?
07:35:54 <xinming> gour: yes
07:35:58 <xinming> for now, It shows,
07:37:02 <gour> what gives: layman -a
07:37:08 <gour> ..haskell ?
07:37:19 <xinming> lisppaste2: url
07:37:19 <lisppaste2> To use the lisppaste bot, visit http://paste.lisp.org/new/haskell and enter your paste.
07:38:05 <lisppaste2> xinming pasted "haskell overlay problem in gentoo" at http://paste.lisp.org/display/28062
07:39:32 <xinming> Now, I'll try it with darcs 1.0.8
07:39:54 <gour> xinming: have you added 'source' line in /etc/make.conf ?
07:40:06 <xinming> gour: yes.
07:40:45 <gour> xinming: is there make.conf in layman's folder?
07:41:02 <xinming> gour: >_< yes
07:41:10 <gour> what is in?
07:41:38 <xinming> In fact, I can't even open http://paste.lisp.org/display/28062
07:41:40 <xinming> oops
07:41:54 <xinming> http://www.haskell.org/~gentoo/gentoo-haskell/_darcs/inventory
07:41:55 <lambdabot> http://tinyurl.com/y4daaq
07:41:57 <xinming> I can't open that url,
07:42:06 <xinming> the connection would be reset...
07:42:22 <xinming> I don't know if it is the problem of master site of haskell.
07:42:34 <gour> i can open those urls
07:43:30 <xinming> that's why I'm confusing..
07:43:59 <xinming> and the error code would sometimes become 18 instead of 52
07:57:24 <glguy> everyone cross your fingers, here goes a remote kernel upgrade :)
07:58:14 <roconnor> crapness
07:58:22 <roconnor> Anomaly: uncaught exception Failure "TODO: Haskell extraction of modules not implemented yet".
07:59:14 <glguy> huzzah, it rebooted :)
07:59:45 <roconnor> glguy: congratz
08:00:47 <glguy> I usually don't breathe during the time between `shutdown -r now` and my ssh client reconnecting
08:27:42 <araujo> morning
08:27:57 <glguy> are you ever not in #haskell?
08:27:59 <glguy> ;)
08:28:36 <araujo> see who talk .....
08:28:38 <araujo> :-P
09:27:41 <dons> ?uptime
09:27:41 <lambdabot> uptime: 3d 18h 34m 10s, longest uptime: 6d 15h 1m 36s
09:27:46 <dons> ?users #haskell
09:27:59 <Igloo> Yo dons
09:28:01 <lambdabot> seen module failed: IRCRaised thread killed
09:28:04 <dons> hey
09:28:06 <dons> ?users #haskell
09:28:28 <lambdabot> seen module failed: IRCRaised thread killed
09:29:09 <dons> grr taking too long. should really hunt that space leak down
09:29:11 <dons> ?users #haskell
09:29:16 <lambdabot> Maximum users seen in #haskell: 256, currently: 231 (90.2%), active: 34 (14.7%)
09:29:40 <Igloo> The old +/-1 problem when people leave/join?
09:30:08 <Igloo> It seems unlikely there would be enough for that, though
09:31:54 <dons> i think the state gets too big somewhere in there
09:32:05 <dons> i should let it run with profiling for a while
09:32:23 <dons> see it also has to track 'activity' now
09:32:28 <dons> which is when the leak appeared ;)
09:32:36 <dons> which is +1 / -1 on every line..
09:32:59 <dons> and if its too lazy, that reult won't be demanded until someone hits ?users..
09:33:20 <profmakx> if my lambdabot runs for 7 days it uses up 512 MB of memory ;)
09:34:48 <Igloo> ?where lambdabot
09:34:49 <lambdabot> http://www.cse.unsw.edu.au/~dons/lambdabot.html
09:35:58 <roconnor> dons, was/is @djinn out of date?
09:36:05 <dons> profmakx: yeah that's the new space issue
09:36:12 <dons> haven't had time to chase it down yet, but its on my list
09:36:26 <dons> roconnor: didn't think so? i can check in a few days
09:36:34 <roconnor> no rush.
09:37:02 <Igloo> dons: I suspect that some $!s in LBState would sort it out
09:37:28 <dons> yeah
09:37:46 * dons -> out and about
10:08:58 <roconnor> Does yhc have unsafeCoerce?
10:09:02 <roconnor> @seen ndm
10:09:02 <lambdabot> ndm is in #ghc, #haskell-overflow, #haskell-blah and #haskell. I don't know when ndm last spoke.
10:26:01 <hyraxfourtwo> ?source GHC.IOBase
10:26:01 <lambdabot> GHC.IOBase not available
10:26:58 <roconnor> Prelude Betaetared> ex
10:26:58 <roconnor> Segmentation fault
10:27:09 <roconnor> Hmmm, maybe the use of unsafeCoerce isn't so safe.
10:27:27 <Maddas> roconnor: Heh, what made you think that?
10:27:29 <Maddas> ;-)
10:27:39 <cm> heya
10:27:39 <roconnor> Maddas: the segmentation fault.
10:27:47 <Philippa_> 'lo cm
10:27:58 <cm> hiho
10:28:00 <Maddas> roconnor: Ah, and I already thought it was the name. :-)
10:28:24 <roconnor> perhaps it is the optimizer.
10:30:10 <roconnor> Prelude Betaetared> ex
10:30:10 <roconnor> Abs Iota Segmentation fault
10:30:18 <roconnor> The unoptimized version get a little farther.
10:40:20 <dcoutts_> @arr
10:40:21 <lambdabot> Aye Aye Cap'n
10:40:50 <hyrax42> ?type (snd *** fst)
10:40:53 <dcoutts_> ventonegro, ignore the gtk2hs Mogule module. It'd deprecated and will go away in the next version.
10:40:55 <lambdabot> forall a b a1 b1. ((a, b), (a1, b1)) -> (b, a1)
10:41:22 <ventonegro> dcoutts, ah, ok
10:41:34 <ventonegro> dcoutts, i was trying to compile the list control demo
10:41:34 <chessguy> i'm trying to write a function collapse :: [a]->[(a,Int)] where Int is the count of the number of times each a appeared in the original list, and each a only appears once in the resulting list, with its count. suggestions?
10:41:53 <dcoutts_> ventonegro, ah, that'll need updating.
10:42:06 <dcoutts_> one more thing to do before the next release
10:42:54 <roconnor> er, how do I use hat?
10:43:32 <ventonegro> dcoutts, and the demo from the darcs repository does not compile because of new modules, so... any release dates? :-)
10:43:42 <chessguy> > [3]:2
10:43:45 <lambdabot>  add an instance declaration for (Num [[a]])
10:43:57 <dcoutts_> ventonegro, you're trying to do a gui using list/tree widgets ?
10:44:04 <ventonegro> dcoutts, yep
10:44:08 <roconnor> ah hat-trans?
10:44:25 <ventonegro> dcoutts, plain boring database browsing
10:44:25 <dcoutts_> ventonegro, cool. Well, there's the basic api and there's a new one too. I think we may even have some demos of the new api.
10:44:34 <dcoutts_> ventonegro, it's not boring!
10:44:39 <dcoutts_> it's a little tricky :-)
10:44:58 <ventonegro> dcoutts, yeah, i know
10:45:03 <dcoutts_> database browsing is one of our tests to see if or api is ok
10:45:07 <dcoutts_> or/our
10:45:29 <roconnor> hat-trans: /usr/lib/haskell-packages/ghc6/lib/hat/IOExts.hx: openFile: does not exist (No such file or directory)
10:45:30 <dcoutts_> the new release will contain both the old and new apis
10:45:43 <dcoutts_> and it's the new one that should be much easer to use
10:45:48 <dcoutts_> you can actually try that out now
10:45:49 <ventonegro> dcoutts, i'm right now reading a tutorial of wxwidgets... would like to do it in Haskell but i'm such a newbie and using C++ i can get it done much faster
10:46:02 <dcoutts_> but there's not much in the way of docs yet for the new api
10:46:21 <roconnor> @hoogle openfile
10:46:22 <dcoutts_> let me see what demos we have...
10:46:22 <lambdabot> IO.openFile :: FilePath -> IOMode -> IO Handle
10:47:10 <dcoutts_> ventonegro, take a look at demo/treeList/SimpleList.hs
10:47:30 <ventonegro> dcoutts, from the darcs version?
10:47:33 <dcoutts_> yes
10:47:36 <dcoutts_> ventonegro, it's possible with the new api to implement custom tree models
10:47:53 <dcoutts_> rather than using the predefined list and tree stores as models
10:48:00 <dcoutts_> that's probably what you'd want to do for a db
10:48:15 <dcoutts_> at least to do it nicely
10:48:19 <hyraxfourtwo> ok so stdout occurs free in putStr
10:48:24 <dcoutts_> especially if you want live updates or stuff like that
10:48:34 <roconnor> hat-trans: ./GHC/Base.hx: openFile: does not exist (No such file or directory)
10:48:36 <hyraxfourtwo> so it should be possible to shadow the binding and use putStr to go somewhere else?
10:48:57 <dcoutts_> ventonegro, otherwise the easy thing is just reading the data out from a query and putting it into a list store, like in that demo
10:49:03 <roconnor> oh, I depend on tha
10:49:06 <roconnor> hmmm
10:49:21 <hyraxfourtwo> let stdout = myhandle in putStr "blah"?
10:49:32 <ventonegro> dcoutts, i see
10:49:59 <dcoutts_> ventonegro, but obviously that doesn't scale very well, it duplicates the data so then you have to keep it in sync. So the more sophisticated thing to do is implement the tree model interface.
10:50:10 <ventonegro> the model seems the way to go, but without docs i'm helpless
10:50:25 <Philippa> hyraxfourtwo: not with lexical scope
10:50:29 <dcoutts_> ventonegro, yeah, for the moment you'd have to just look at the list model for guidance
10:50:40 <hyraxfourtwo> Philippa, oh right
10:50:44 <ventonegro> when using C++ i usually go for qt, don't know much gtk
10:50:47 * hyraxfourtwo was thinking of special variables in common lisp
10:51:02 <dcoutts_> ventonegro, gtk/Graphics/UI/Gtk/TreeList/ListStoreNew.hs.pp
10:51:48 <dcoutts_> ventonegro, start with one that just reads out of the db and puts it into an ordinary list store. Then if you get that working, go for the custom model.
10:52:18 <ventonegro> dcoutts, ok
10:52:21 <dcoutts_> I'd be happy to get your feedback on that, as we're still trying to improve that api
10:52:40 <roconnor> how do I get hat not to trace into GHC.Base?
10:52:47 <ventonegro> i wouldn't count much on it
10:53:02 <ventonegro> this would be my first useful haskell program :-)
10:53:45 <roconnor> ?fptools GHC.Base
10:53:46 <lambdabot> GHC.Base not available
10:54:03 <roconnor> ?fptools Data.Word
10:54:03 <lambdabot> http://darcs.haskell.org/packages/base/Data/Word.hs
10:54:22 * glguy just noticed that he was used as an example of why quickcheck is useful in irc on dons' blog
10:54:58 <roconnor> @hoogle unsafeCoerce
10:54:59 <lambdabot> No matches found
10:55:21 <roconnor> @hoogle unsafeCoerce#
10:55:22 <lambdabot> Hoogle Error: Parse Error: Unexpected character '>'
10:57:15 <roconnor> @docs GHC.Base
10:57:16 <lambdabot> GHC.Base not available
10:59:28 <dcoutts_> ventonegro, oh and I have another example that uses inotify to implement a custom model that represents a live view of a directory.
10:59:30 <dcoutts_> http://dhcp0878.gradacc.ox.ac.uk:8080/~duncan/gtk2hs/demo/treeList/DirTree.hs
10:59:33 <lambdabot> http://tinyurl.com/t8rt3
10:59:35 <dcoutts_> less that 100 lines of code
10:59:45 <dcoutts_> (actually it's 99 lines :-) )
10:59:54 <dcoutts_> that/than
11:00:01 <ventonegro> dcoutts, thanks!
11:00:39 <ventonegro> what's the preferred way to interface with sqlite? hsql?
11:01:19 <dcoutts_> ventonegro, personally I reccomend hdbc
11:02:09 <ventonegro> @where hdbc
11:02:10 <lambdabot> http://quux.org/devel/hdbc
11:02:27 <dcoutts_> emerge hdbc-sqlite
11:02:36 <dcoutts_> gentoo users have it easy :-)
11:02:40 <ventonegro> dcoutts, i use debian
11:03:05 <ValarQ> apt-get install portage # :o)
11:03:18 <dcoutts_> hah hah
11:03:20 <ndm> @seen roconnor
11:03:21 <lambdabot> roconnor is in #ghc and #haskell. I last heard roconnor speak 6m 5s ago.
11:03:44 <ndm> roconnor: yes, we have unsafe coerce
11:03:50 <roconnor> Can I get hat to work with unsafeCoerce?
11:04:10 <ventonegro> ValarQ, no need, it's in apt :-P
11:04:20 <ndm> roconnor: email hat -at- haskell.org...
11:04:33 <ndm> i have no idea
11:05:08 <roconnor> ok
11:05:32 <roconnor> ndm: I got Haskell code extracted from the proof of tait's normalizaton.
11:05:41 <roconnor> but the Haskell program segfaults....
11:05:55 <roconnor> that's not supposed to happen to provably correct code ;)
11:06:01 <ndm> lol :)
11:06:27 <roconnor> I'm expecting the problem is that Haskell extraction doesn't have a lot of support.
11:06:29 <ndm> you can try it in hat, but i don't know if it would work or not
11:06:50 <roconnor> the file is stand alone, except for a dependancy on unsafeCoerce.
11:06:53 <Igloo> I'll bet you're not using a proven correct Haskell implementation
11:07:08 <roconnor> Igloo: yes, GHC must be to blame ;)
11:07:10 <ndm> roconnor: how big?
11:07:33 <roconnor> the haskell file?
11:07:45 <ndm> yep
11:08:02 <roconnor> less than 18K
11:08:04 <Igloo> "unsafeCoerce" and "provably correct" aren't phrases you tend to see together, either
11:08:28 <roconnor> Igloo: it's best to use unsafeCoerce only when you have proved it's use is correct.
11:08:34 <roconnor> its
11:08:51 <Igloo> Well, I can't argue with that  :-)
11:10:15 <Cale> Why is it using unsafeCoerce? You'd think that could be avoided.
11:11:00 <roconnor> Igloo: you were right, Hugs has no trouble!
11:11:27 <roconnor> Cale: I have a complicated type. ... let me find it
11:12:29 <roconnor> @paste
11:12:29 <lambdabot> http://paste.lisp.org/new/haskell
11:14:45 <roconnor> http://www.rafb.net/paste/results/FyJBWe36.html
11:14:52 <roconnor> So Fixpoint means a recursive function.
11:15:03 <roconnor> actually, there is a lot of notation here.
11:15:19 <roconnor> but the point is that it is some complicated recursive function for generating a dependent type.
11:15:30 <roconnor> so, it is hard to find a haskell type for it.
11:17:50 <swiert> Anyone know an easy to use curses binding for Haskell?
11:18:24 <roconnor> So. I have a Haskell program that GHC segfaults on, and Hugs is fine with ...
11:18:50 <dolio> 6.6?
11:19:21 <ndm> roconnor: does Hugs give the right answer?
11:19:47 <ndm> Hugs may just not segfault on a bad unsafeCoerce but just do something silly
11:19:53 <roconnor> ndm: I'm not absolutely certain, but i'm pretty sure it is correct.
11:20:03 <dolio> Does it segfault compiling or running the program?
11:20:07 <ndm> roconnor: i'd give it a whirl with Yhc, get another data point
11:20:16 <roconnor> ndm: but GHC starts outputing the wrong answer, and then segfaults.
11:21:37 <ndm> roconnor: import YHC.Primitive, then use unsafeCoerce
11:21:57 <lisppaste2> roconnor pasted "betaetared.hs" at http://paste.lisp.org/display/28072
11:22:29 <roconnor> ndm: if you want to try it, you will have to fiddle with the ifdefs at the top to get unsafeCoerce
11:22:53 <ndm> roconnor: i don't want to try it - i have no idea what the answer is, but you might want to :)
11:23:18 <ndm> roconnor: its a bigger GHC bug if Hugs and Yhc agree but GHC doesn't
11:25:15 <roconnor> ndm what is an ifdef for YHC?
11:27:59 <roconnor> heh, the yhc graphs doesn't include the time to download and build yhc before you can start computing primes.
11:28:37 <dcoutts> roconnor, hugs would thrash everyone if you included that
11:28:43 <Igloo> yhc graphs?
11:28:58 <roconnor> http://www-users.cs.york.ac.uk/~ndm/yhc/graph-primes.png
11:29:01 <lambdabot> http://tinyurl.com/mcd5j
11:29:06 <dcoutts> Igloo, the yhc page has this graph of how long it takes to compure primes
11:29:13 <dcoutts> including time taken to compile
11:29:44 * Igloo looks at the graph and concludes that GHC has optimised the primes function to an O(1) algorithm
11:29:54 <dcoutts> heh, yeah
11:30:05 <mux> GHC solved the RH by accident
11:30:08 <roconnor> new proof that primality checking is polynomial time.
11:30:09 <mux> :-)
11:30:09 <glguy> if that was the case, GHC would be covered up by the government ;)
11:30:42 * roconnor feels like he should have done darcs get --partial
11:30:48 <Igloo> glguy: The govt just spread rumours about Haskell being an "academic" language, so no-one pays any attention
11:30:55 <mux> so, if I have a thread (forkIO) blocking on a handle for data, it blocks all my threads?
11:31:04 <roconnor> mux: yes :(
11:31:11 <mux> even with -threaded
11:31:13 <mux> apparently
11:31:15 <mux> that kinda sucks
11:31:22 <Igloo> ndm: Can you easily add whichever of ghc -O and ghc you don't have to that graph?
11:31:23 <mux> what's the canonical way to achieve this then?
11:31:48 <mux> some kind of MVar magic?
11:31:49 <roconnor> isn't there some light-weight vs heavy-weight thread things... does that make a differnce?
11:32:07 <wilx> I thought GHC used non blocking descriptors wherever possible, so why should they block?
11:32:08 <Igloo> mux: It shouldn't with -threaded
11:32:10 <mux> it probably does, ie if I had used forkOS, it would probably work
11:32:23 <mux> Igloo: mmm, let me re-check this then
11:32:51 <shapr> musasabi: Do you know if I can call txCheckpointAndExit from inside a case of the main app?
11:33:18 <mux> Igloo: I confirm it's blocking all the threads even with -threaded
11:33:27 <ndm> Igloo: i have a bug open to add ghci, ghc -O and ghc to that graph (i think its GHC on that graph)
11:33:40 * mux notes this is the usual problem with 100% userland threading implementation
11:33:50 <ndm> Igloo: not easily, i lost the builder for it, i might just take it down for now, rather than have it wrong
11:34:03 <mux> those threading libs usually wrap around all the blocking calls and have a huge poll()/select()/whatever loop
11:34:41 <ndm> Igloo: that graph has so little time in the primes (for GHC) that the overhead dwarfs the rest
11:36:04 <roconnor> Compiling Betaetared       ( betaetared.hs )
11:36:04 <roconnor> yhc: Prelude.head: empty list
11:36:17 <mux> heh
11:38:09 <Igloo> roconnor: What gives you a segfault?
11:38:28 <roconnor> evaluating ex, the last thing in the file.
11:38:34 <Igloo> in ghci?
11:38:40 <roconnor> yes
11:38:51 <ndm> roconnor: what was the cpp macro?
11:38:58 <ndm> roconnor: i tried fi nding it in the code, but no luck as yet
11:39:13 <roconnor> ndm, cpp macro?
11:39:29 <ndm> roconnor: for yhc -cpp, which macro flags Yhc?
11:39:30 <Igloo> So it does
11:39:37 <roconnor> oh right, that is imporant
11:40:03 <Igloo> But I'm not particularly tempted to investigate a case with quite so many unsafeCoerce's  :-)
11:40:08 <ndm> roconnor: __YHC__ - just found it
11:40:13 <roconnor> $ yhc/inst/bin/yhc -cpp -98 betaetared.hs
11:40:14 <roconnor> Compiling Betaetared       ( betaetared.hs )
11:40:14 <roconnor> yhc: Prelude.head: empty list
11:40:24 <roconnor> ah okay
11:40:34 <ndm> oh, during compilation it faults?
11:40:42 <roconnor> for now, I just make a copy without the macros specifically for YHC
11:40:45 * ndm smacks Yhc
11:40:49 <roconnor> ... which means I don't need the -cpp flag
11:40:57 <ndm> roconnor: can i have that file, i'll make a bug on it
11:41:10 <roconnor> ndm: techinically I haven't tried it with the latest pull
11:41:19 <roconnor> I'm rebuilding yhc now.
11:41:25 <ndm> roconnor: i doubt it makes a difference
11:41:31 <roconnor> http://paste.lisp.org/display/28072
11:41:46 <roconnor> that is more or less the file (without the include YHC.Primitive)
11:41:49 <mux> so, how should I proceed in order to have threads blocking on data and yet still have other threads running?
11:43:15 <Pegazus> !books
11:43:20 <Pegazus> @books
11:43:21 <lambdabot> Unknown command, try @list
11:43:24 <Pegazus> @list
11:43:25 <lambdabot> http://www.cse.unsw.edu.au/~dons/lambdabot/COMMANDS
11:43:30 <araujo> hiya hira
11:44:19 <ndm> roconnor: Error: C:\Documents\Uni\yhc\inst\bin\Crash.hs(7:1-7:0) Found {-ERROR _-} but exp
11:44:20 <ndm> ected a {-end-of-definition-or-EOF-}
11:44:33 <Pegazus> any recommended books list? for learning "advanced" haskell?
11:44:33 <roconnor> ndm: use -98
11:44:44 <ndm> roconnor: Yhc has -99?
11:44:49 <ndm> roconnor: Yhc has -98?
11:44:53 <roconnor> ndm: yes
11:45:02 <ndm> really?
11:45:08 <roconnor> ndm: either that or rename the __ variable in the source code.
11:45:28 <ndm> roconnor: ok, will do that
11:45:44 <roconnor> Actually, I haven't tried renaming the __ variable. ... maybe I should do that
11:46:24 <ndm> roconnor: i tried it, and works fine with the variable renamed
11:46:27 <roconnor> ah
11:46:30 <roconnor> indeed it does
11:46:36 <Pegazus> no books recommended?
11:46:36 <roconnor> sooooooooooo -98 is broken i think?
11:46:36 <Pegazus> :(
11:47:07 <roconnor> ... is YHC not interactive?
11:47:20 <ndm> nope, thats yhe, and thats probably broken
11:47:30 <roconnor> better add main = print ex
11:47:31 <ndm> and yes -98 is likely broken
11:47:47 <Igloo> yhe?
11:48:18 <roconnor> er main = Prelude.print ex
11:48:28 <Igloo> Pegazus: There is a list on the wiki
11:48:33 <ndm> York Haskell Evaluator
11:48:41 <Igloo> Ah
11:49:02 <ndm> roconnor: i don't have a proper Yhc distribution, just getting it...
11:49:04 <Pegazus> but i want a good list :)
11:49:04 * roconnor tries to figure out how to get yhc to execute this.
11:49:13 <Igloo> http://www.haskell.org/haskellwiki/Books_and_tutorials
11:49:16 <lambdabot> Title: Books and tutorials - HaskellWiki, http://tinyurl.com/y4f3er
11:49:27 <Igloo> If that's not a good list then click on "Edit this page" at the bottom  :-)
11:50:37 <Pegazus> what's the best book of all those?
11:50:51 * mux guesses he'll have to wait for dons to get an answer :-P
11:51:04 <roconnor> ndm: shouldn't yhc output something?
11:51:18 <ndm> roconnor: yhi Main.hbc will run the program
11:51:33 <roconnor> ah yes, captials!
11:51:47 <roconnor> w00t
11:51:53 <ndm> works?
11:51:54 <roconnor> $ yhc/inst/bin/yhi Betaetared.hbc
11:51:54 <roconnor> Var O
11:52:00 <roconnor> same answer as hugs
11:52:20 <roconnor> which appears to be the right answer as far as I can tell.
11:52:35 <roconnor> maybe I should try ghc instead of ghci.
11:54:02 <roconnor> $ ghc --make betaetared.hs
11:54:03 <roconnor> Chasing modules from: betaetared.hs
11:54:03 <roconnor> Compiling Main             ( betaetared.hs, betaetared.o )
11:54:03 <roconnor> Bad eta expand
11:54:10 <roconnor> and then a bunch of GHC core
11:54:14 <roconnor> wtf?
11:54:40 <roconnor> oh, I'm running GHC 6.5 on this machine
11:54:44 <lispy> roconnor: what is the code?
11:54:56 <int-e> funny it should happen in betaetared.hs
11:54:58 <Igloo> 6.6 WFM
11:55:02 <roconnor> lispy: http://paste.lisp.org/display/28072
11:55:49 <roconnor> yes, 6.4.2 is less whiny
11:56:46 <lisppaste2> roconnor annotated #28072 with "GHC compilation result" at http://paste.lisp.org/display/28072#1
11:57:02 <roconnor> both 6.4.2 and 6.6 segfault
11:58:07 <Igloo> If you can make a simpler example that also goes wrong then that would be interesting
11:58:20 <roconnor> Igloo: hmmm...
11:58:38 <roconnor> Igloo: a bit tricky, I didn't write the code.
11:58:42 <roconnor> not even indirectly.
11:58:57 <roconnor> I was hoping to use Hat to trace it.
11:59:16 <dolio> Heh, there's no indication of where the problem is, either. :)
11:59:29 <ndm> hat is for debugging the haskell code, not the compiler - you probably wouldn't have much success
11:59:34 <ndm> just use Yhc instead of GHC :)
11:59:49 <roconnor> ndm: won't hat give me at trace upto the segfault?
12:00:10 <ndm> roconnor: the compilers borked, it could do anything, including work normally
12:00:35 <lisppaste2> roconnor annotated #28072 with "ghci result" at http://paste.lisp.org/display/28072#2
12:00:55 <roconnor> the interesting thing about the ghci, is that it output some data before segfaulting
12:01:02 <roconnor> Prelude Main> ex
12:01:02 <roconnor> Abs Iota Segmentation fault
12:01:13 <roconnor> Abs and Iota are my constructors.
12:01:28 <roconnor> ... you will also notice that this is far from the correct answer of Var O
12:01:48 <roconnor> ndm: interesting point.
12:02:14 * roconnor imagines my email to ghc-users:  unsafeCoerce# is broken...
12:02:38 <int-e> haha. are you sure that what you're doing is correct?
12:02:57 <roconnor> is there some way to set  -O-1
12:03:13 <roconnor> int-e: like I said, I've proved it correct, ... and it works in hugs and yhc.
12:03:15 <int-e> funny: *Betaetared> ex  ->  Var O  (interpreted version, ghci 6.4.2)
12:03:46 <roconnor> int-e: ah yes, the intepreted version in ghci works!
12:03:48 <int-e> using unsafeCoerce# from GHC.Base (it wouldn't find it otherwise)
12:04:51 <roconnor> well, I should go home and go to bed. ... poor GHC.
12:05:02 <roconnor> can't even get unsafeCoerce# right.
12:05:58 * roconnor fears that Coercing things to () leads to optimisations that are actually dangerous.
12:06:30 <roconnor> ndm: BTW, does this answer your question to the mailing list?
12:06:45 <ndm> roconnor: yes, its screwed :)
12:07:16 * roconnor thinks this might count as destroying performance.
12:07:32 <ndm> GHC 6.7 should fix this, with FC
12:07:35 <roconnor> ah
12:07:41 <roconnor> see's Marlow's email
12:07:57 <roconnor> you should be careful not to cast a
12:07:57 <roconnor> function value to a non-function type (except a polymorphic type), because
12:07:58 <roconnor> the two have incompatible representations when it comes to seq and case.
12:08:21 <roconnor> I'm totally doing that everywhere.
12:08:57 <lispy> i don't understand the code at that URL at all
12:09:38 <roconnor> lispy: That code was automatically generated from an implemenation of Tait's proof of the strong normalization of the typed lambda calculus.
12:10:10 <lispy> hah! i almost asked if it was machine generated
12:13:31 <roconnor> heh, it almost looks like a human may have written that.
12:13:48 <roconnor> could use more comments
12:15:26 <roconnor> ndm, BTW, this ought to have examples of unused parameters
12:15:48 <roconnor> for example, I claim that the rs parameter of the function three is never used in computation.
12:15:55 <Pegazus> What was the best tutorial on Monads?
12:16:00 <roconnor> it is just passed around everywhere
12:16:16 <roconnor> ndm, anyhow, I should send you an email later with more details
12:17:55 <lispy> Pegazus: what do you want to learn about them?  how to use IO, what they are in general? examples of monads that come with the standard haskell libs?  how to create your own?
12:18:26 <jmmv> hi
12:18:37 <lispy> jmmv: hello
12:19:11 <glguy> ?google haskell monad
12:19:15 <lambdabot> http://www.nomaware.com/monads/
12:19:15 <lambdabot> Title: Nomaware | Monads
12:19:28 <glguy> Pegazus: that is actually my favorite tutorial on monads
12:19:34 <Pegazus> thx
12:19:43 <glguy> Pegazus: and aparently a lot of people like it because it's first on google's results list
12:19:59 <lispy> Pegazus: that on glguy mentoined is good...but if you just want to learn to use IO i recommend 'tackling the awkward squad'
12:20:15 <glguy> I second that recommendation
12:20:23 <glguy> and recommend reading both ;)
12:20:44 <lispy> yeah
12:21:18 <lispy> i seem to recal someone mentoining "all about monads" as a good one too
12:21:33 <Pegazus> i don't want to learn IO :) i want to learn what Monads are...
12:21:36 <glguy> lispy: I think that's the results from google that I recommended
12:22:01 <lispy> glguy: oh, that's the name of the nomaware one?
12:22:04 <lispy> heh
12:22:08 <lispy> so it's doubly good
12:22:30 * lispy just remembers that one as 'nomaware'
12:24:14 <lispy> Pegazus: cool, that's a good attitude, but i ask because some people just want to get started with IO without worrying so much about monads in general
12:25:29 <lispy> > take 25. map length . sequence . group . fix $ show
12:25:36 <lambdabot> Terminated
12:25:43 <lispy> > take 5 . map length . sequence . group . fix $ show
12:25:47 <lambdabot> Terminated
12:26:05 <lispy> > map length . sequence . take 10 . group . fix $ show
12:26:06 <lambdabot>  [10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,...
12:26:29 <lispy> > map length . sequence . take 5 . group . fix $ show
12:26:30 <lambdabot>  [5,5,5]
12:26:34 <lispy> weird!
12:28:02 <lispy> > map length . sequence . take 7 . group . fix $ show
12:28:03 <lambdabot>  [7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7]
12:28:10 <lispy> glguy: can you explain that?
12:28:20 <lispy> > take 7 . group . fix $ show
12:28:22 <lambdabot>  ["\"","\\","\"","\\\\\\","\"","\\\\\\\\\\\\\\","\""]
12:28:38 <lispy> > group . take 7 . group . fix $ show
12:28:40 <lambdabot>  [["\""],["\\"],["\""],["\\\\\\"],["\""],["\\\\\\\\\\\\\\"],["\""]]
12:28:47 <lispy> > sequence . group . take 7 . group . fix $ show
12:28:49 <lambdabot>  [["\"","\\","\"","\\\\\\","\"","\\\\\\\\\\\\\\","\""]]
12:29:14 <lispy> > join . sequence . group . take 7 . group . fix $ show
12:29:16 <lambdabot>  ["\"","\\","\"","\\\\\\","\"","\\\\\\\\\\\\\\","\""]
12:29:33 <lispy> heh, join . sequence . group == id  in this case
12:29:41 <lispy> ?type join . sequence . group
12:29:42 <lambdabot> forall a. (Eq a) => [a] -> [a]
12:30:28 <Pegazus> lispy: My interest in haskell is pure theoricall...
12:31:31 <lispy> > length . map length . sequence . take 7 . group . fix $ show
12:31:32 <lambdabot>  21
12:31:58 <chessguy> is your interest in spelling theoricall too?
12:32:56 <Pegazus> chessguy: Nope, my interest in spelling is null, as there is no interest at all in there :)!!!
12:33:35 <lispy> > head . map length . sequence . take 17 . group . fix $ show
12:33:36 <lambdabot>  17
12:33:45 <lispy> that is so weird
12:33:48 <glguy> lispy: explain which?
12:34:15 <lispy> ?check (\n -> head . map length . sequence . take n . group . fix $ show == (n::Int))
12:34:16 <lambdabot>  Couldn't match `a -> String' against `Int'
12:34:17 <glguy> i just got back and there is lot of stuff on my screen
12:34:32 <lispy> ?check (\n -> (head . map length . sequence . take n . group . fix $ show) == (n::Int))
12:34:33 <lambdabot>  Falsifiable, after 2 tests: -2
12:34:51 <lispy> ?check n >= 0 ==> (\n -> (head . map length . sequence . take n . group . fix $ show) == (n::Int))
12:34:52 <lambdabot>  Not in scope: `n'
12:35:12 <lispy> ?check (\n -> n>=0 ==> (head . map length . sequence . take n . group . fix $ show) == (n::Int))
12:35:18 <lambdabot> Terminated
12:35:37 <lispy> glguy: why does it produce n when you take n?
12:35:41 <lispy> seems odd
12:36:12 <glguy> fix show returns powers of 2 - 1 interspersed between 1s
12:36:23 <glguy> or the length is, rather
12:36:40 <glguy> let me look at the rest, that's pretty screwy ;)
12:37:03 <glguy> > map length $ group $ fix show
12:37:07 <lambdabot> Terminated
12:37:08 <lispy> glguy: yeah, my current goal is to stumble on a way to get fix show to print fibs :)
12:37:12 <glguy> bah
12:37:24 * lispy leaves for work
12:37:28 <glguy> ^^bah
12:37:30 <glguy> cya
12:37:46 <glguy> lispy: oh, the answer is obvious L:)
12:37:48 <int-e> lispy: sequence produces a list of lists with as many elements as the given list has lists.
12:37:54 <glguy> if you sequence a list of 17 elements
12:38:06 <glguy> each result will have 17 elements
12:38:21 <int-e> I liked my explanation better, it's so confusing :)
12:47:28 <lispy> Ah
12:47:45 <lispy> i was thunking that sequence did the powerset
12:47:53 <lispy> > sequnce [1..3]
12:47:54 <lambdabot>  Not in scope: `sequnce'
12:47:58 <lispy> > sequence [1..3]
12:47:58 <lambdabot>  add an instance declaration for (Show (m [a]))
12:47:59 <glguy> > head . map length . sequence $ repeat [()]
12:48:00 <lambdabot>  Exception: <<loop>>
12:48:11 <glguy> > head . map length . sequence $ replicate 17 [()]
12:48:12 <lispy> ?type sequence
12:48:12 <lambdabot>  17
12:48:14 <lambdabot> forall a (m :: * -> *). (Monad m) => [m a] -> m [a]
12:48:21 <lispy> > sequence [[1..3]]
12:48:22 <lambdabot>  [[1],[2],[3]]
12:48:30 <glguy> > (\n -> head . map length . sequence $ replicate n [()]) 13
12:48:31 <lambdabot>  13
12:48:44 <lispy> mystery solved
12:48:54 <lispy> > join . sequence [[1..3]]
12:48:55 <lambdabot>  Couldn't match `(->) a' against `[]'
12:48:59 <lispy> > join . sequence $ [[1..3]]
12:49:00 <lambdabot>  [1,2,3]
12:49:09 <lispy> > join . sequence . group $ [[1..3]]
12:49:11 <lambdabot>  [[1,2,3]]
12:49:37 <lispy> ?scheck \xs -> (join . sequence . group $ xs) == xs
12:49:38 <lambdabot>  Add a type signature
12:49:44 <lispy> ?scheck \xs -> (join . sequence . group $ xs) == (xs::[Int])
12:49:45 <lambdabot>   Failed test no. 10. Test values follow.: [-1,-1,-1,-1,-1,-1,-1,0]
12:50:04 <lispy> > group [-1,-1,-1,-1,-1,-1,-1,0]
12:50:06 <lambdabot>  [[-1,-1,-1,-1,-1,-1,-1],[0]]
12:50:12 <lispy> > sequence . group [-1,-1,-1,-1,-1,-1,-1,0]
12:50:13 <lambdabot>    Expecting a function type, but found `[[a]]'
12:50:13 <lambdabot>    Expected type: a1 -> ...
12:50:17 <lispy> > sequence . group $ [-1,-1,-1,-1,-1,-1,-1,0]
12:50:19 <lambdabot>  [[-1,0],[-1,0],[-1,0],[-1,0],[-1,0],[-1,0],[-1,0]]
12:50:23 <lispy> > join $ sequence . group $ [-1,-1,-1,-1,-1,-1,-1,0]
12:50:24 <lambdabot>  [-1,0,-1,0,-1,0,-1,0,-1,0,-1,0,-1,0]
12:50:33 <lispy> interesnting
12:50:45 <glguy> really?
12:51:27 <glguy> > join $ replicate 7 [-1,0]
12:51:29 <lambdabot>  [-1,0,-1,0,-1,0,-1,0,-1,0,-1,0,-1,0]
12:51:53 <lispy> well, join . sequence . group == id for quite a few inputs i used
12:51:54 <glguy> > [1..7] >> [-1,0]
12:51:55 <lambdabot>  [-1,0,-1,0,-1,0,-1,0,-1,0,-1,0,-1,0]
12:52:00 <lispy> so i was surprised to see it fail
12:52:20 <lispy> but it's only id for [[1..]] type of lists
13:09:56 <musasabi> shapr: see HAppS.Util.StdMain module.
13:11:41 <phr-newbie> @pf \f xs -> [f x | x <- xs]
13:11:41 <lambdabot> Maybe you meant: bf pl
13:11:46 <phr-newbie> @pl \f xs -> [f x | x <- xs]
13:11:47 <lambdabot> flip flip [] . ((:) .) . (<-) . (| x) . ($ x)
13:11:51 <phr-newbie> haha
13:12:12 <xerox> @do \f xs -> [f x | x <- xs]
13:12:12 <lambdabot> \f xs -> [f x | x <- xs] not available
13:12:16 <xerox> @undo \f xs -> [f x | x <- xs]
13:12:17 <lambdabot> \ f xs -> [f x | x <- xs]
13:12:21 <xerox> Well something like that ;)
13:12:59 <phr-newbie> @pl \f xs -> map f xs
13:13:00 <lambdabot> map
13:13:19 <xerox> @undo do { x <- xs; return (f x) }
13:13:19 <lambdabot> xs >>= \ x -> return (f x)
13:13:25 <xerox> @. pl undo do { x <- xs; return (f x) }
13:13:26 <lambdabot> f `fmap` xs
13:18:09 <dolio> @. pl undo do { x <- m ; x }
13:18:09 <lambdabot> join m
13:18:50 <phr-newbie> @drhaskell flip flip [] . ((:) .) . (<-) . (| x) . ($ x)
13:18:50 <lambdabot> Unknown command, try @list
13:19:02 <phr-newbie> @pl flip flip [] . ((:) .) . (<-) . (| x) . ($ x)
13:19:02 <lambdabot> flip flip [] . ((:) .) . (<-) . (| x) . ($ x)
13:19:07 <xerox> dolio: aka (>>= id)
13:19:13 <glguy> phr-newbie: that's not a real function in case you wondered
13:19:18 <phr-newbie> hmm
13:19:31 <glguy> phr-newbie: lambdabot treated [ and | and <- as raw operators
13:19:37 <phr-newbie> oh i see
13:19:40 <glguy> not as a list comprehension
13:19:45 <phr-newbie> thanks
13:28:11 * SamB wonders how to get decent profiles
13:31:36 <lispy> SamB: -caf-all?
13:31:42 <lispy> SamB: what do you mean by decent
13:32:54 <SamB> lispy: its supposed to have built that way already...
13:34:22 <lispy> SamB: what is wrong?
13:34:32 * lispy wants to help but has too little info
13:34:43 <SamB> hmm.
13:34:50 <SamB> maybe it isn't building right.
13:35:07 <dolio> xerox: Yeah, I knew what it did. I just like playing with pl, making sure it reduces what I think it should reduce.
13:36:43 <lisppaste2> SamB pasted "sample profile" at http://paste.lisp.org/display/28081
13:37:07 <hyraxfourtwo> ?hawiki strictness
13:37:08 <lambdabot> Maybe you meant: gwiki wiki
13:37:13 <hyraxfourtwo> ?wiki strictness
13:37:14 <lambdabot> http://www.haskell.org/haskellwiki/strictness
13:37:31 <hyraxfourtwo> hm
13:37:39 <lispy> SamB: that looks like you don't have -auto-all or -caf-all
13:37:50 <SamB> lispy: yeah
13:37:57 <SamB> it does...
13:38:14 <lispy> SamB: what is your build system? cabal or make files?
13:38:55 <SamB> ack
13:39:04 <SamB> I miscapitalized something in build.mk!
13:39:34 <lispy> ah
13:40:19 * SamB is glad he symlinked those to one file now, so he doesn't have to do the edit-one, cp-to-the-other dance ;-)
13:42:30 <hyraxfourtwo> hmm
13:42:46 * hyraxfourtwo wonders if (id $!) will solve some of his problems
13:42:50 <hyraxfourtwo> but no time to check now
13:43:44 <SamB> hyraxfourtwo: is that somehow different from seq?
13:44:03 <hyraxfourtwo> samB no
13:44:14 <dolio> id $! x = x `seq` id x = x `seq` x. Isn't x `seq` x defined to be evaluated differently than just x?
13:44:15 <lispy> ?type id $!
13:44:16 <lambdabot> parse error (possibly incorrect indentation)
13:44:21 <lispy> ?type id ($!)
13:44:23 <lambdabot> forall a b. (a -> b) -> a -> b
13:44:24 <hyraxfourtwo> just I don't want ot have to put in let x = <big ugly thing> in x `seq` x
13:44:24 <SamB> lispy: its a section
13:44:32 <lispy> ah
13:44:33 <hyraxfourtwo> rather id $! <big ugly thing>
13:44:33 <SamB> @type (id $!)
13:44:34 <lambdabot> forall a. a -> a
13:44:35 <hyraxfourtwo> needs less code
13:44:38 <SamB> hyraxfourtwo: oh
13:44:39 <hyraxfourtwo> less changes
13:44:50 <SamB> that makes sense ;-)
13:44:53 <hyraxfourtwo> or fewer, even
13:45:03 <dolio> Er, x `seq` x to *not* be evaluated differently than just x.
13:45:36 <SamB> true!
13:45:43 <hyraxfourtwo> huh?
13:45:48 <SamB> hyraxfourtwo: that won't do anything
13:45:58 <SamB> id is already strict ;-)
13:46:13 <hyraxfourtwo> hm
13:46:16 <hyraxfourtwo> I have to read more
13:46:18 <hyraxfourtwo> and look at it later
13:46:28 <hyraxfourtwo> haven't messed with adding strictness yet
13:46:36 <hyraxfourtwo> so I dont' know what's what
13:46:37 <Igloo> ndm: x `seq` x might be a good thing for DrHaskell to spot if it doesn't already
13:46:43 <int-e> right, (id $!) is indistinguishable from id.
13:47:15 <hyraxfourtwo> > let f = f in id f
13:47:16 <lambdabot>  Add a type signature
13:47:20 <hyraxfourtwo> > let f = f in id f :: Int
13:47:21 <lambdabot>  Exception: <<loop>>
13:47:38 <hyraxfourtwo> oi see
13:48:34 <int-e> (id $!) is like saying 'oh you want to evaluate this value? hey, let me do this for you.'
13:51:03 <xerox> ?source Prelude
13:51:03 <lambdabot> http://darcs.haskell.org/packages/base/Prelude.hs
13:51:49 <hyraxfourtwo> the two wikis situation is really frustrating
13:52:07 <lispy> hyraxfourtwo: we are working to get rid of the old one
13:52:07 <dolio> Which is the one that's sticking around? haskellwiki?
13:52:19 <hyraxfourtwo> the less brown one
13:52:25 <dolio> Heh.
13:52:44 <hyraxfourtwo> lispy, things are held up by licensing mostly?
13:53:57 <lispy> not sure
13:54:11 <hyraxfourtwo> ok well I'll look at it all later
13:54:11 <lispy> i had very little content on the old wiki, i should see if anyone else moved it for me...
13:54:33 <hyraxfourtwo> anyone have quick pointers to tuts/info on adding strictness
13:54:39 <hyraxfourtwo> so I can open now to look at later
13:56:45 <hyraxfourtwo> ?index rnf
13:56:45 <lambdabot> Control.Parallel.Strategies
14:07:34 <lispy> okay, freaky
14:07:50 <lispy> i just received an email to have my gmail password reset and i didn't request it
14:09:39 <tibbe> "There is no separate module language in Cayenne since the dependent types allow the normal expression language to be used at the module level as well."
14:09:59 <tibbe> I've read similar statements at several different places now, anyone care to explain?
14:18:19 <newsham> lispy: probably phishing
14:18:42 <Cale> "Never contain programs so few bugs, as when no debugging tools are available!" -- Niklaus Wirth
14:19:57 <glguy> Cale: was English Niklaus' second language? :)
14:20:38 <Maddas> AFAIK German was his first.
14:20:45 <lispy> newsham: i thought that, but the email looks genuine
14:20:50 <Cale> perhaps that should have an additional 'do' in it
14:20:51 <glguy> "Whereas Europeans generally pronounce my name the right way ('Ni-klows Wirt'), Americans invariably mangle it into 'Nick-les Worth'. This is to say that Europeans call me by name, but Americans call me by value."
14:21:21 <Maddas> Yeah, he was born in the German-speaking part.
14:22:27 <Cale> I think that sentence is reasonably grammatical, if a little strangely structured for English.
14:24:03 <glguy> I found this on google: In a recent article,5 Niklaus Wirth opined that "never do programs contain so few bugs as when no debugging tools are available."
14:24:12 * Maddas is bothered bboth by the comma and the exclamation mark
14:24:23 <Maddas> Oh, okay, both of them not present in glguy's version.
14:24:35 <glguy> which would not have brought me to complain
14:24:41 <Maddas> Indeed.
14:25:01 * glguy is a proud pedant.
14:25:13 <Cale> I'm looking at the original article :)
14:25:21 <Cale> (in which they are both present)
14:25:42 <Cale> http://www.cs.inf.ethz.ch/~wirth/Articles/GoodIdeas_origFig.pdf
14:25:44 <lambdabot> http://tinyurl.com/yhc5r2
14:25:54 <Maddas> Cale: Heh, okay.
14:26:07 <int-e> page 24 :)
14:26:13 <glguy> Well, considering that he was aparently Swiss-born, that would be OK...
14:26:47 <Cale> The comma only serves to create dramatic suspense.
14:27:44 <Maddas> He doesn't speak very highly of functional languages in 6.1, Functional Programming.
14:28:31 <glguy> But if he was responsible for the abomination that was Pascal....
14:29:04 <Cale> He criticises himself for various misfeatures of Pascal throughout it.
14:29:23 <glguy> ah, then maybe I'll give this article a read
14:29:42 <Cale> But Pascal is certainly nicer than C.
14:30:08 <Maddas> In fact, I'm not very convinced of what he says in the entire chapter 6.
14:30:16 <Cale> yeah
14:30:16 <SamB> practical Pascal or standard Pascal?
14:30:45 <glguy> The complaints about functional programming that he has made (in the part that I have read so far) are generally already addressed in Haskell
14:30:46 * Maddas is a little disappointed by that part of the text :-)
14:31:10 <SamB> they were legitimate beefs, then?
14:31:12 <Cale> glguy: right, I seem to just take his opinions there as being perhaps correct 15 years ago, but a little dated today.
14:31:14 <Maddas> (Not that I have read a lot of Wirth's texts, even though I study at the university he teaches at)
14:31:33 <SamB> oh ack
14:31:41 <Cale> Maddas: you should show him Haskell :)
14:32:01 <Maddas> I also disagree with his characterization of object-oriented programming.
14:32:17 <Maddas> Cale: Oh, I should have said /he teached at/. He retired quite a while ago :-)
14:32:44 <Cale> taught
14:32:48 <Maddas> Argh
14:32:50 <Maddas> Right.
14:32:53 <glguy> Maddas: since you participated in the disection of his quote with me, I have to say: taught
14:33:06 <Maddas> Yes, I'm sorry. I lack a proper excuse ;-)
14:33:22 <monochrom> what is taught?
14:33:25 * glguy is going to have to avoid giving reasons if he is to keep up with Cale ;)
14:33:34 <Cale> haha
14:33:43 <Maddas> Though he's listed as a speaker in the upcoming event celebrating the CS department's 15th anniversary.
14:33:45 <SamB> monochrom: that isn't the point
14:33:54 <SamB> monochrom: the point is that it was Wirth who taught it
14:34:11 <SamB> or, rather, the point is that he taught it, not teached or teaches ;-)
14:34:15 <monochrom> Hmm let me guess the question.  It was "is intuition born or taught?"  And yes the answer is definitely taught not born.
14:34:22 <int-e> Hmm, I don't see why garbage collection is bad, which seems to invalidate the whole section.
14:34:24 <Maddas> (What does "in effigie" mean in the context of a list of speakers for a panel? That the particular speaker is not actually present?)
14:34:43 <SamB> Maddas: it means they got a cardboard cutout instead ;-)
14:34:45 <SamB> or something ;-)
14:35:05 <Maddas> Yeah, but why even list that speaker as a member? I guess just to attract attention :-)
14:35:06 <monochrom> They can use a cardboard cutout?
14:35:14 <Maddas> monochrom: Perhaps a digitally animated one
14:35:26 <Maddas> An animated gif or something like that.
14:35:41 <lisppaste2> SamB pasted "nasty error building with -prof -auto-all -caf-all" at http://paste.lisp.org/display/28082
14:37:35 <lispy> SamB: hmmm...didn't someone else have this problem recently on one of the mail lists?
14:38:16 <Cale> It means that a lock of that speaker's hair is ceremonially placed on a podium, and everyone looks up at it for 15 minutes.
14:38:17 <SamB> lispy: dunno!
14:40:06 <int-e> Ok, did anyone disagree with section 6.2?
14:41:17 <int-e> (Logic programming) I tend to agree but I've only seen the surface of pure prolog ...
14:43:08 <SamB> lispy: any idea how I would *find* this message?
14:45:10 <lispy> SamB: i'll search my gmail
14:46:28 <lispy> SamB: you want haskell-cafe, subject Profiling CAFs (re-post)
14:46:59 <SamB> @google haskell-cafe "Profiling CAFs (re-post)"
14:47:02 <lambdabot> http://news.gmane.org/group/gmane.comp.lang.haskell.cafe/last=/force_load=t
14:47:02 <lambdabot> Title: Gmane -- Gmane Loom: gmane.comp.lang.haskell.cafe
14:47:22 <lispy> http://hackage.haskell.org/trac/ghc/ticket/931
14:47:25 <lambdabot> Title: #931 (-caf-all gives &#34;Error: symbol `Mainmain_CAF_cc_ccs' is already defined ..., http://tinyurl.com/yedxs8
14:58:50 <lispy> is it possible with TH to take an identifier that hasn't been defined and then convert it to a string?
14:59:26 <lispy> ... myIdentifier ... ==> ... someFunction "myIdentifier" ...
15:04:28 <SamB> oh great
15:04:33 <SamB> the compiler is panicking on me...
15:05:02 <petekaz> Are there any gtk2hs users here?  Or is there a separate channel for that?
15:05:23 <int-e> hmm. "DsForeign: why is there an unsafeCoerce here?" is an interesting message.
15:05:32 <SamB> it is
15:05:41 <SamB> @ghc
15:05:42 <lambdabot>  Ambiguous constraint
15:05:49 <dcoutts> petekaz, this channel will do
15:06:16 <lispy> heh, i was going to tell petekaz the only better channel would be /msg dcoutts :)
15:06:51 <dcoutts> hah
15:07:34 <petekaz> I just built gtk2hs, and installed it.  Ran a few demos, but any that use glade give me Could not find module `Graphics.UI.Gtk.Glade'.  Am I doing something stupid?
15:07:58 <dcoutts> petekaz, you probably don't have glade or the glade dev headers installed when you built gtk2hs
15:08:00 <int-e> you don't have libglade installed (or its development headers) but the demo uses it
15:08:16 <SamB> ghc-6.5: panic! (the 'impossible' happened)
15:08:16 <SamB>   (GHC version 6.5 for i386-unknown-linux):
15:08:16 <SamB>         ASSERT failed! file codeGen/ClosureInfo.lhs, line 596
15:08:16 <petekaz> ok, I'll double-check, thanks.
15:08:19 <dcoutts> it's an optional component so gtk2hs doesn't automatically build the libglade bits if they're not available
15:08:28 <petekaz> gotcha.
15:08:28 <SamB> after:
15:08:32 <lispy> SamB: why do you use 6.5?
15:08:34 <SamB> ../../compiler/ghc-inplace -H32m -O -fasm -W -fno-warn-unused-matches -fwarn-unused-imports -fglasgow-exts -cpp -Iinclude -"#include" HsBase.h -funbox-strict-fields -package-name  base-2.0 -O -dcore-lint -W -fno-warn-unused-matches -fwarn-unused-imports  -fgenerics -hisuf p_hi -hcsuf p_hc -osuf p_o -prof -auto-all    -c Data/Dynamic.hs -o Data/Dynamic.p_o  -ohi Data/Dynamic.p_hi
15:08:40 <dcoutts> petekaz, usually it's just a matter of installing libglade-dev or something and rebuilding gtk2hs
15:08:40 <int-e> petekaz: or you've disabled libglade in gtk2hs' configure, but you'd probably know that.
15:08:49 <SamB> lispy: because that was what was in HEAD when I pulled?
15:09:10 <petekaz> libglade-2 or 1
15:09:13 <dcoutts> petekaz, and you don't need to do a full clean rebuild, just './configure && make' again
15:09:18 <dcoutts> petekaz, 2
15:09:36 * lispy wonders how the impossible happens
15:09:53 <SamB> me too!
15:10:02 <petekaz> thanks guys ... rebuilding now.
15:11:18 <petekaz> I'm not a gui person, but I thought I'd try to write a simple app for myself.  I need a telnet/ssh launcher that lets me group hosts in a hierarchical manner.  This should be simple I figure.
15:11:47 <int-e> oh no, what's the status of the tree api, dcoutts?
15:12:08 <dcoutts> int-e, mostly working
15:12:21 <dcoutts> it'll be included along with the old api in the next release
15:12:27 <dcoutts> the old api is still usable
15:12:38 <dcoutts> and the new api is available now in the darcs version
15:12:49 <petekaz> that's what I built, the darcs version.
15:12:50 <SamB>   | updatable || opt_DoTickyProfiling  -- to catch double entry
15:12:51 <SamB>       {- OLD: || opt_SMP
15:12:51 <SamB>          I decided to remove this, because in SMP mode it doesn't matter
15:12:51 <SamB>          if we enter the same thunk multiple times, so the optimisation
15:12:51 <SamB>          of jumping directly to the entry code is still valid.  --SDM
15:12:51 <SamB>         -}
15:12:55 <SamB>   = ASSERT( n_args == 0 ) EnterIt
15:13:24 <petekaz> need to run home .. thanks for the help again.
15:24:03 * SamB wonders why his patch was altered before application, thus making a different patch that conflicted with his...
15:24:35 <SamB> Mon Oct 16 15:00:04 CEST 2006  Samuel Bronson <naesten@gmail.com>
15:24:35 <SamB>   * Don't squish "Inlined fn" into the right margin quite as much in trace output
15:24:46 <SamB> Wed Oct 11 00:19:44 CEST 2006  Samuel Bronson <naesten@gmail.com>
15:24:46 <SamB>   * Don't squish "Inlined fn" into the right margin quite as much in trace output
15:27:18 <Igloo> What are the differences?
15:27:32 <Igloo> Are you sure you didn't send 2 patches with the same name?
15:27:38 <SamB> positive!
15:27:49 <SamB> I did *not* touch that code after recording the patch!
15:28:06 <Igloo> Calm down, I believe you  :-)
15:28:29 <SamB> the replacement indents the code slightly
15:30:31 <Igloo> Oh, it'll have been amend-recorded
15:30:48 <SamB> yes it will!
15:30:51 <Igloo> I was struggling to believe someone had gone to the hassle of explicitly setting you as author
15:31:07 <SamB> someone should chastise the developer responsible!
15:31:22 <SamB> also maybe darcs should object to people amending others' patches!
15:31:32 <Igloo> Do you know if it would have conflicted with another patch in its original state?
15:32:04 <Igloo> Oh, it's also functionally different
15:32:12 <Igloo> Oh, indents the /generated/ code, I see
15:32:16 <SamB> if it would have, it wouldn't have worth using mine ;-)
15:32:26 <SamB> er s/have/have been/
15:34:41 <Igloo> There's actually an interesting psychological question related to this - if someone's patch isn't perfect, how is it best to proceed without making them feel like their contributions aren't wanted?
15:34:42 * araujo looks around
15:35:17 <Igloo> If you ask them to resubmit they may feel like you are making them go to lots of effort and it isn't worthwhile, but equally committing a "fix ..." patch may make them feel their efforts aren't worthwhile
15:35:19 <araujo> Igloo, explaining him why it isn't perfect and if he could send a perfect one version instead?
15:36:03 <SamB> or, you could let them send the imperfect one with their *own* fix patch ;-)
15:36:05 <Igloo> araujo: Do you think that's always the better alternative?
15:36:28 <SamB> but applying a conflicting patch is nearly always a good way to make them feel unappreciated!
15:36:31 <araujo> Igloo, i wouldn't know "always" .. but i think it should work most of the time.
15:36:42 <Igloo> SamB: Yeah, that's what I meant. I think Simon probably just wasn't thinking what the net effect would be
15:36:48 <SamB> yes
15:36:53 <araujo> You are considering his efforts, which is the important issue here.
15:36:56 <SamB> so someone should teach him how to use darcs ;-)
15:37:49 * Igloo will write Simon an e-mail telling him his efforts aren't appreciated  :-)
15:38:53 <Igloo> But yeah, I also think darcs should at least warn you that you are changing someone else's patch, as in the general case you wouldn't necessarily want your name to be accidentally associated with the changes someone else thought were worthwhile...
15:38:56 <SamB> heh
15:40:03 <int-e> I wish amend-record could change patch descriptions.
15:40:40 <lispy> int-e: if what people were saying about descriptions being part of the name and hence part of the hash for the patch then that causes problems :(
15:40:54 <lispy> int-e: but i wolud like that as well
15:41:23 <SamB> lispy: amend-record doesn't give you a compatible patch anyway
15:41:28 <int-e> lispy: I know. It's one of the reasons why I don't really like darcs.
15:41:30 <SamB> and notice how the date changes when you do it?
15:41:39 <araujo> Igloo, just tell Simon that you can handle the whole thing then , and that he shouldn't spend his time in those little details
15:41:41 <araujo> :-)
15:42:39 <lispy> well, if he'd just gone in and fixed the indenting then recorded a new patch all would be well
15:42:46 <SamB> it should also warn that the other party won't like it when your version of their patch conflicts with their version...
15:46:28 <Pegazus> what does expr1 >>= \x -> mean?
15:46:40 <Pegazus> (and by the time what does \x -> mean?)
15:48:25 <dolio> '\x -> e' is a function that takes one parameter, named x, and returns e.
15:48:32 <Pegazus> i know lambda functions
15:48:40 <Pegazus> but what does it means when i have no "e"
15:48:57 <dolio> Well, e is just a stand in for whatever expression you want.
15:49:12 <Pegazus> thx
15:49:24 <dolio> If you actually used e, it would have to be bound somewhere in the environment of the expression.
15:49:30 <Pegazus> yes yes
15:49:39 <dolio> Since haskell doesn't do free variables.
15:49:45 <Pegazus> i was reading the tutorial, and it says x <- expr1, becomes expr1 >>= \x ->
15:49:57 <Pegazus> i just thought that expr1 >>= \x -> was a valid haskell expression
15:49:59 <Pegazus> it's not :p
15:50:25 <dolio> Ah, yeah. If you expand all the lines in a do like that, though, you should (hopefully) end up with something that is a haskell expression.
15:50:38 <Pegazus> yes...
15:55:00 <lispy> ?hoogle (.&.)
15:55:02 <lambdabot> Did you mean: (.&.)
15:55:02 <lambdabot> Prelude.undefined :: a
15:55:02 <lambdabot> Control.Monad.Reader.ask :: MonadReader r m => m r
15:55:08 <lispy> what  is the bitwise and again?
15:55:22 <lispy> ?hoogle DWORD -> DWORD -> DWord
15:55:23 <lambdabot> No matches, try a more general search
15:55:37 <lispy> ?type (.&.)
15:55:39 <lambdabot> forall a. (Bits a) => a -> a -> a
15:55:50 <dolio> > 3 .&. 4
15:55:51 <lambdabot>  Add a type signature
15:55:52 <lispy> ?type .&.
15:55:53 <lambdabot> parse error on input `.&.'
15:55:57 <dolio> > 3 .&. 4 :: Int
15:55:58 <lambdabot>  0
15:56:11 <lispy> ?index (.&.)
15:56:12 <lambdabot> Data.Bits, Foreign
15:56:17 <lispy> ah, data.bits
16:00:11 <lispy> ?hoogle WORD
16:00:12 <lambdabot> System.Win32.Types.WORD :: type WORD
16:00:12 <lambdabot> Data.Word :: module
16:00:12 <lambdabot> Data.Word.Word :: data Word
16:01:46 * SamB thinks GHC's Trac ought to have a "HEAD" version
16:02:51 <Igloo> What would it differ in?
16:03:18 <SamB> you know, in the dropdown box of versions?
16:03:26 <SamB> after 6.6?
16:03:33 <Igloo> Oh, there's a 6.5 isn't there?
16:03:42 <Igloo> HEAD should probably be turned into 6.7
16:03:52 <Pegazus> does anyone know a good page with easy example to understand how to use monads?
16:03:54 <SamB> yes probably!
16:04:15 <SamB> I've been wondering why they haven't done that yet!
16:05:12 <dcoutts> SyntaxNinja!
16:05:19 <SyntaxNinja> y0
16:05:20 <lambdabot> SyntaxNinja: You have 5 new messages. '/msg lambdabot @messages' to read them.
16:05:23 <SyntaxNinja> arjanoosting: !!!
16:05:49 <Igloo> SamB: Probably just post-release exhaustion  :-)  But we also need to work out how we are going to handle library versions, so it probably got lumped in with that
16:05:55 <dcoutts> SyntaxNinja, can you help us persuade your folks to get Trac updated to the lastest version?
16:06:05 <Igloo> Hey Isaac
16:06:14 <dcoutts> SyntaxNinja, there are some things in the latest version that would really help
16:06:21 <arjanoosting> SyntaxNinja: I am DD!!!!!!!
16:06:27 <dcoutts> like an admin tool to delete bugs (think spam)
16:06:27 <SyntaxNinja> arjanoosting: !!!
16:06:27 <SamB> can I add simon marlow to the CC list on this bug just by adding ", simonmar"?
16:06:38 <SyntaxNinja> dcoutts: we're working on it
16:06:39 <Igloo> arjanoosting: Oh, congrats  :-)
16:06:45 <dcoutts> SyntaxNinja, excelent!
16:07:14 <dcoutts> SyntaxNinja, that and the other cool new feature is askimet spam filtering. The Gtk2Hs track has drowned under spam.
16:07:17 <resiak> Did someone here mention an X input method that allows one to use latex-like character, uh, names a few days back?  Did it actualy exist?
16:07:24 <SyntaxNinja> man. I want to turn off lambdabot's ability to record messages for me.
16:07:31 <dcoutts> heh heh
16:07:43 <SyntaxNinja> email people!
16:07:45 <dcoutts> resiak, I recall that, dunno if it really exists, but it should!
16:08:00 <SyntaxNinja> dcoutts: literate haskell + haddock /= good
16:08:09 <dcoutts> SyntaxNinja, huh?
16:08:13 <int-e> resiak: scim with scim-tables, and the latex table that comes with it.
16:08:19 * resiak wants it, rather than trying to figure out if X has a compose sequence for lambda...
16:08:26 <SyntaxNinja> dcoutts: 9 days ago you emailed me about that
16:08:28 <int-e> resiak: I didn't mention it, maybe Cale did?
16:08:31 <resiak> int-e: I think you may have just become my Unicode deity...
16:08:40 <SyntaxNinja> arjanoosting: congrats, man :)
16:09:05 <dcoutts> SyntaxNinja, oh, perhaps I did. :-) Well it's fixed now in the head version. I'm thinking of doing a 1.1.6.1 bug fix release.
16:09:29 <arjanoosting> SyntaxNinja: I was just filling some RC bugs and was waiting for BTS mail when I found the mail from the DAM.
16:09:33 <SyntaxNinja> dcoutts: coo
16:09:35 * arjanoosting is happy now!!
16:09:54 <dcoutts> SyntaxNinja, I might need some help some time in resuresting the Gtk2Hs trac. It's currently giving a python exception. I think it's probabbly due to too much spam.
16:09:56 <SyntaxNinja> arjanoosting: yeah, they emailed me 17 minutes ago, which is why I came here, actually :)
16:10:06 <SyntaxNinja> dcoutts: bugger
16:10:42 <SyntaxNinja> dcoutts: feel free to do a bugfix release.
16:10:46 <dcoutts> SyntaxNinja, I'll have a go with deleteing loads of spammy bugs and see if that cures it. But that needs the latest version for the delete bug admin tool. :-)
16:11:08 <dcoutts> SyntaxNinja, when we've accumulated a reasonable number of few fixes I will.
16:11:25 <dcoutts> but porbably fairly soon
16:11:41 <dcoutts> SyntaxNinja, now might be the right time to talk about branches
16:12:05 <dcoutts> eg branch now for 1.1.6.1 and let xerox shove new cabal-install stuff in for the head branch
16:12:29 <dcoutts> so if I were to branch, I'd just cp to cabal-1.1.6 on the server then ?
16:12:44 <dcoutts> leaving the current branch as head
16:13:19 <SyntaxNinja> dcoutts: we could reorganize the repo to be like cabal/{trunk,branches}
16:13:28 <SyntaxNinja> and cabal/branches/xerox
16:13:37 <dcoutts> we can certainly add a branch for xerox
16:13:44 <SyntaxNinja> or maybe just have cabal and cabal-branches/xerox
16:13:48 <dcoutts> I worry slightly about moving the head branch
16:13:58 <SyntaxNinja> yeah, so maybe the 2nd suggestion is the way to go
16:14:15 <SyntaxNinja> there really already is a branch for xerox, it's "cabal-with-install"
16:14:35 <SyntaxNinja> but it would be good to collect branches together in a logical place
16:14:39 <dcoutts> I'm happy for that stuff to go into the head if he things it's ready
16:14:56 <dibblego> anyone else going to APLAS06 besides dons?
16:15:28 <dcoutts> SyntaxNinja, so I'll add cabal-branches/cabal-1.1.6 and let xerox deal with cabal-branches/cabal-xerox
16:17:26 <dibblego> is it just me or does Paul Graham goes on about the Blub Paradox, but he himself is a Blub programmer - not being able to see beyond lisp?
16:17:55 * dcoutts agrees with dibblego 
16:18:05 <phr-newbie> dibblego, yes
16:18:18 <phr-newbie> i remember someone on c2 wiki saying that too, that lisp is just another blub
16:18:20 <dibblego> ok, I wasn't sure, thanks
16:19:08 <phr-newbie> the way i can tell is that i've done plenty of lisp and picked up python right away because of it, but haskell is confusing the hell out of me :)
16:19:21 <kosmikus> dibblego: when's APLAS?
16:19:31 <lispy> oh, this is interesting
16:19:35 <lispy> ?type (Nothing ==)
16:19:37 <lambdabot> forall a. (Eq (Maybe a)) => Maybe a -> Bool
16:19:38 <lispy> ?type isNothing
16:19:38 <dibblego> well being confused doesn't necessarily make it "higher on the power spectrum"
16:19:39 <lambdabot> forall a. Maybe a -> Bool
16:19:46 <dibblego> kosmikus, November 8-10
16:19:50 <SyntaxNinja> dcoutts: the xerox branch is cabal-with-install, and maybe that should be moved into cabal-branches.
16:19:57 <phr-newbie> ?type logBase
16:19:59 <kosmikus> dibblego: thanks
16:19:59 <lambdabot> forall a. (Floating a) => a -> a -> a
16:20:07 <phr-newbie> @hoogle logBase
16:20:08 <lambdabot> Prelude.logBase :: Floating a => a -> a -> a
16:20:08 <SyntaxNinja> dcoutts: but yeah, it should probably just go into head.
16:20:09 <lispy> looks like you should use isNothing instead of (==Nothing) because then you don't pickup the Eq constraitnt
16:20:14 <dibblego> kosmikus, http://www.cse.unsw.edu.au/~aplas06/index.html
16:20:16 <lambdabot> Title: APLAS'06, http://tinyurl.com/yy56sn
16:20:16 <phr-newbie> @hoogle divRem
16:20:17 <lambdabot> No matches found
16:20:19 <dcoutts> SyntaxNinja, I'll talk to xerox about it.
16:20:30 <phr-newbie> > divRem 5 2
16:20:31 <lambdabot>  Not in scope: `divRem'
16:20:40 <phr-newbie> > divMod 5 2
16:20:41 <lambdabot>  (2,1)
16:20:52 <SyntaxNinja> dcoutts: sweet :)
16:21:24 <SamB> hmm
16:21:26 <kosmikus> dibblego: looks quite interesting, but I'm afraid I lack the time to go
16:21:33 <SamB> should I use Simon Marlows gmail address?
16:21:38 <dcoutts> SyntaxNinja, do you know what the issue with trac is? Is it getting the darcs plugin working with the latest trac version ?
16:21:43 <dibblego> kosmikus, you in Australia?
16:21:47 <SamB> the one called "simonmarhaskell@gmail.com"?
16:21:56 <kosmikus> dibblego: no
16:22:06 <kosmikus> dibblego: but it'd be a good reason to go there :)
16:22:11 <dcoutts> SyntaxNinja, well, I shouldn't pester. :-)  So long as we get an email when it's all done, that'll be great.
16:22:45 <dcoutts> we can owe the sysadmin a beer or two :-)
16:23:43 <resiak> int-e: That's ridiculously cool; thanks.
16:24:14 <dcoutts> resiak, so there is one? where?
16:24:46 <resiak> dcoutts: 00:07            int-e | resiak: scim with scim-tables, and the latex table that comes with it.
16:25:13 <phr-newbie> http://weblog.raganwald.com/2006/10/are-we-blub-programmers.html
16:25:15 <lambdabot> Title: Raganwald: Are we Blub programmers?, http://tinyurl.com/ykelmz
16:25:17 <int-e> resiak: http://paste.lisp.org/display/28086 might be useful
16:25:38 <dcoutts> resiak, int-e, cool
16:25:40 <phr-newbie>   
16:25:40 <phr-newbie> Is it just me or did others also notice that Paul Graham who coined the term is the ultimate Blub programmer ? His belief in Lisp being the ultimate programming language is so strong that he outright rejects alternative paradigms of programming.
16:25:52 <resiak> int-e: Yep, I'm familiar with those; thanks, though!
16:31:49 <mlh> phr-newbie: I'm not a great fan of PG, but I hardly think that's right.  He was quite sceptical of/baffled by lisp before he tried it.
16:39:05 <phr-newbie> mlh, the issue is that PG now considers lisp to be at the top of the pile, and (for example) haskell is just a "weird language"
16:39:13 <dolio> phr-newbie: But Lisp actually is the ultimate programming language, so he can't be a blub programmer. :)
16:39:14 <phr-newbie> i.e. he doesn't realize that lisp is just another blub
16:40:56 <phr-newbie> so tell me something: what makes haskell ever evaluate anything?
16:41:36 <int-e> phr-newbie: the RTS when executing main's IO action.
16:41:44 <int-e> phr-newbie: (RTS = run time system)
16:42:18 <SyntaxNinja> dcoutts: well, I think I need to coax our sysadmin into doing it, but I've been on vacation... he's freaked out by the fact that it's a custom build that I put together and I haven't had a chance to talk to him about it in depth.
16:42:34 <dcoutts> SyntaxNinja, heh, poor chap. :-)
16:42:37 <phr-newbie> hmm how does the RTS make the evaluation happen?  is there some mechanism in the language?
16:43:25 <phr-newbie> and what about things like "seq", how do they work?
16:43:38 <dcoutts> phr-newbie, there's a bunch of papers on it, but you're probably looking for a quick explanation :-)
16:43:46 <phr-newbie> is a quick explanation possible?
16:44:01 <dcoutts> phr-newbie, it's got a lot to do with reducing to weak head normal form
16:44:15 <phr-newbie> i have  d.launchbury's paper that someone here recommended last week, haven't yet read it
16:44:38 <SamB> phr-newbie: well, you try to run:
16:44:40 <dcoutts> each function gets compiled to code that when run produces a result in weak head normal form
16:44:50 <dcoutts> at least that's what GHC does
16:44:58 <phr-newbie> does the language semantics specify that?
16:45:02 <dcoutts> no
16:45:12 <SamB> main = putStrLn (unwords ["Hello,", "World!"]) -- without evaluating anything!
16:45:27 <SamB> phr-newbie: just try it!
16:45:42 <dcoutts> phr-newbie, it specifies stuff about weak head normal form I think (or some equivalent) but doesn't specify an implementation mechanism
16:46:26 <phr-newbie> sam, right, main isn't evaluated til i type "main"
16:46:53 <phr-newbie> dcoutts, ok, each function gets compiled into code that evaluates the function when run, but what makes the function actually get run?
16:47:32 <SamB> phr-newbie: oh, you could try using runhaskell to run it
16:47:42 <phr-newbie> like putStrLn (unwords ... ) makes an IO ()
16:47:46 <phr-newbie> runhaskell?
16:47:50 <SamB> its a script
16:48:02 <dcoutts> phr-newbie, do you mean at a low implementation level or jsut how do you run it ?
16:48:02 <mlh> phr-newbie: oh.  that's silly.  url?
16:48:34 <phr-newbie> dcoutts, i mean at the language definition level
16:48:47 <SamB> phr-newbie: the "main" function will be called by the RTS if you actually compile your program or run it with runhaskell/runhugs/etc.
16:49:05 <dcoutts> phr-newbie, oh, sorry. I was talking about too low level things.
16:49:14 <SamB> or too high!
16:49:55 * SamB thinks phr-newbie needs to hear about Main.main and how to execute a whole program
16:49:56 <dcoutts> phr-newbie, well demaning the value of some expression is what triggers stuff to actually be run.
16:50:26 <phr-newbie> dcoutts, ok, now we're getting somewhere.  what does it mean to demand the value of an expression?  why is the demand itself not deferred?
16:50:53 <phr-newbie> if you put the value into something like putStrLn i guess that has to demand it
16:51:04 <dcoutts> phr-newbie, there must be some initial demand, eg demanding mainm, or you typing "foo 3" in ghci
16:51:10 <dcoutts> mainm/main
16:52:00 <phr-newbie> say I write f = putStrLn ("hi " ++ "there")
16:52:12 <dcoutts> and IO is a bit more tricky
16:52:40 <dcoutts> not only do we get the result in weak head normal form, but the runtime 'perfoms' the IO actions including their side effects on the world
16:52:45 <phr-newbie> putStrLn has type  String -> IO ()
16:53:08 <phr-newbie> thing is i don't have my question fully formed, i don't know enough to really ask it
16:53:14 <dcoutts> so what happens there is that we get putStrLn ("hi " ++ "there") in weak head normal form
16:53:24 <dcoutts> which is a sequence of primitive IO actions
16:53:31 <dcoutts> and then the runtime system performs those
16:53:57 <dcoutts> that's the idealised way of looking at it. In reality the evaluation and performing get interleaved.
16:56:49 <phr-newbie> let me try another example, say   a = 2 + 3  and  b = a + 5   and c = sqrt(b)
16:56:59 <phr-newbie> i can do those three equations and nothing gets evaluated
16:57:28 <phr-newbie> but if instead of sqrt b, i try to print b, then those functions all get evaluated
16:58:18 <phr-newbie> (I'm not sure what function prints a number)
16:58:52 <shapr> @index parseURI
16:58:53 <lambdabot> Network.URI
16:58:53 <phr-newbie> but is it the IO monad that makes the evaluation happen?
16:58:59 <shapr> @docs Network.URI
16:58:59 <lambdabot> http://haskell.org/ghc/docs/latest/html/libraries/network/Network-URI.html
16:59:01 <phr-newbie> or some hook from the print function into the RTS?
16:59:45 <dcoutts> phr-newbie, if in ghci you write a
16:59:55 <dcoutts> then a will indeed be evaluated and the value printed
16:59:56 <shapr> lambdabot is a great IDE
17:00:03 <phr-newbie> shapr lol
17:00:29 <phr-newbie> dcoutts, well, that's some REPL again calling the evaluator through some mysterious means
17:00:30 <shapr> Hiya phr-newbie, who are you?
17:00:43 <shapr> btw, has anyone figured out what's wrong with haskell-mode and how to fix it?
17:00:45 <phr-newbie> shapr, umm, ????  not sure how you mean that
17:00:53 <dcoutts> shapr, aye, for lacking an editor it's pretty good IDE :-)
17:01:14 <phr-newbie> shapr i'm a python/lisp weenie trying to learn haskell :)
17:01:20 <phr-newbie> oops didn't mean to msg that
17:01:29 <shapr> phr-newbie: Hi, I'm Shae Erisson and I've been using Haskell for slightly more than 5 years :-)
17:01:40 <shapr> phr-newbie: Nice to meet you, I hope you enjoy the journey.
17:01:53 <shapr> I also got into Haskell from Python.
17:02:04 <dcoutts> phr-newbie, yeah, I guess it is. And that's the same mysterius thing that calls main when you make a standalone program.
17:02:08 <phr-newbie> shapr, thanks, it's actually been anxiety-provoking
17:02:31 <dcoutts> phr-newbie, the haskell system does have a way of evaluating each expression to WHNF
17:02:43 <phr-newbie> WHNF can still be unevaluated though
17:02:47 <dcoutts> nope
17:03:00 <phr-newbie> according to http://computing-dictionary.thefreedictionary.com/Weak+Head+Normal+Form
17:03:06 <lambdabot> http://tinyurl.com/sonot
17:03:07 <dcoutts> weak head normal form means we can see the first level of structure
17:03:18 <dcoutts> so it's evaluated to the first level
17:03:20 <shapr> phr-newbie: What provokes anxiety?
17:03:56 <phr-newbie> shapr for example the total absence of any complexity guarantees in the language, as far as i can tell.
17:04:09 <phr-newbie> e.g. the scheme specification promises that tail recursion will NOT push stuff on the stack
17:04:30 <phr-newbie> but in haskell as far as i can tell it's implementation dependent
17:05:21 <dcoutts> that's true
17:05:37 <dcoutts> so you need to enquire about the implementation
17:05:48 <dcoutts> and in practice they all do tail recursion perfectly
17:06:08 <phr-newbie> yeah that seems to be true, i'm not too worried about that particular aspect
17:06:38 <dcoutts> the official language spec is fairly abstract, it does not mention space usage at all I think
17:06:51 <dcoutts> or sharing
17:06:58 <phr-newbie> but it's easy to code things that have space leaks or that have much worse time complexity than intended
17:07:16 <Igloo> I think it's mentioned for things like the MR, but it's all very hand-wavy
17:07:21 <Pseudonym> Well it's even easier to write a space leak in C.
17:07:21 <phr-newbie> is the language spec readable?  i haven't looked at it
17:07:55 <dcoutts> I've never read it
17:08:00 <phr-newbie> i get the impression that writing programs with good performance requires being a guru about the implementation
17:08:22 <Igloo> It's been a while since I read it, but I think it's quite readable
17:08:27 <int-e> Well, Haskell has its ugly corners that aren't mentioned in the language brochure.
17:08:56 <dcoutts> phr-newbie, I don't think it's knowing a lot about the implementation, it's more the language and how lazy evaluation works
17:09:01 <ThreeQ> hmm, time complexity isn't particularly an issue, is it?
17:09:20 <ThreeQ> I mean, you're never going to evaluate more than a strict language
17:09:26 <dcoutts> phr-newbie, eg knowing when to use foldl' vs foldr
17:10:04 <int-e> ThreeQ: you run the risk of using more memory and wasting time doing GC or just by causing more cache and tlb misses.
17:11:07 <phr-newbie> there's an example in SoE that i'm trying to find, where an apparent do-nothing change makes a linear algorithm go exponential
17:11:08 <int-e> ThreeQ: oh, and it's easy for a beginner to use awful data structures, like lists for arrays. or mutating immutable arrays.
17:11:23 <ThreeQ> but haskell isn't going to make a O(n) time algorithm into an O(n^2) time algorithm like it does for space sometimes
17:11:31 <ThreeQ> unless you do stuff like that :)
17:11:53 <ThreeQ> you can use awful data structures in any programming language, though
17:12:22 <int-e> ThreeQ: sure. and other languages have different subtle beginner mistakes.
17:12:32 <Igloo> If you turn an O(n) time and space algorithm into an O(n^2) space algorithm then you must also change it into at least an O(n^2) time algorithm
17:12:48 <Igloo> (if you'll allow the notaion abuse)
17:13:22 <phr-newbie> ThreeQ, the problem is that haskell doesn't really let you specify algorithms in the traditional sense, there's just declarations, and you have to concoct declarations that end up running the algorithms you want
17:13:24 <int-e> Igloo: why, we could theoretically allocate stuff on the heap in constant time.
17:13:29 <phr-newbie> and it's very easy to get those wrong
17:14:04 <int-e> Igloo: (I realize it will be hard to do that in Haskell)
17:14:23 <Igloo> OK, assuming you actually use the space
17:14:32 <int-e> I could use it sparsely.
17:14:35 <pejo> phr-newbie, one could argue that it's the traditional algorithms people that have the wrong notation in the beginning. :-)
17:14:36 <lambdabot> pejo: You have 1 new message. '/msg lambdabot @messages' to read it.
17:14:49 <phr-newbie> right, there's this famous way to calculate the fibonacci sequence
17:14:51 <Igloo> "the space" meaning O(n^2) space
17:15:02 <ThreeQ> but you can go from O(n) time O(1) space to O(n) time O(n) space
17:15:13 <phr-newbie>   fib = 1 : 1 : zipWith (+) fib (tail fib)
17:15:17 <int-e> (think hash tables. it's tricky but actually possible to use uninitialized memory for sparse arrays safely. TAoCP has an exercise about that somewhere, I forgot where.)
17:15:32 <ThreeQ> the point wasn't really that the space usage could exceed the order of growth of the algorithm
17:15:32 <emu> > fix (\f -> 1 : 1 : zipWith (+) f (tail f))
17:15:33 <lambdabot>  [1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946,17...
17:15:52 <dcoutts> phr-newbie, after you've coded for a bit, it's not just abstract declerations, you can see pretty easily the operational behaviour (almost) all of the time.
17:15:57 <phr-newbie> now turn that to a zero-arg function
17:16:04 <phr-newbie> fib :: () -> [Integer]
17:16:25 <ThreeQ> fib = const (1 : 1 : zipWith (+) fib (tail fib))
17:16:30 <ThreeQ> er
17:16:31 <dcoutts> heh, easy
17:16:36 <phr-newbie> fib x = 1 : 1 : zipWith (+) (fib ()) (tail (fib ()))
17:16:47 <ThreeQ> yeah
17:16:54 <int-e> ah, exercise 2.2.6.24
17:16:57 <emu> why bother
17:17:00 <dcoutts> phr-newbie, what was the point ?
17:17:05 <emu> it already acts like a zero-arg function in haskell
17:17:18 <phr-newbie> emu, you're saying those two versions should do the same thing?
17:17:23 <phr-newbie> that is in fact true, they calculate the same result
17:17:41 <emu> > let  fib x = 1 : 1 : zipWith (+) (fib ()) (tail (fib ())) in fib ()
17:17:42 <lambdabot>  [1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946,17...
17:17:46 <phr-newbie> but the second one uses exponential space and time
17:18:02 <phr-newbie> according to this book
17:18:18 <dcoutts> becuase you've eliminated sharing
17:18:23 <phr-newbie> > let  fib x = 1 : 1 : zipWith (+) (fib ()) (tail (fib ())) in (fib () !! 50)
17:18:24 <lambdabot>  20365011074
17:18:27 <phr-newbie> hmm
17:18:42 <phr-newbie> maybe ghc is smarter than whatever the book uses
17:18:44 <sjanssen> phr-newbie: yes, assuming that the compiler doesn't lift the zipWith ... CAF out
17:18:46 <emu> sure that the compiler here isn't smart enough to eliminate that?
17:19:05 <emu> yea i'd be more concerned about fundamental issues than things a compiler can deal with
17:19:18 <dcoutts> ghc tends to try not to change the sharing behaviour of code
17:19:22 <phr-newbie> emu ?????
17:19:47 <phr-newbie> what can be more fundamental than whether an algorithm is linear or exponential?
17:19:49 <emu> fib () is always going to have the same value, so why can't it share structure?
17:19:51 <pejo> dcoutts, not change at all, or try to not remove sharing?
17:19:57 <int-e> phr-newbie: http://haskell.org/haskellwiki/Performance/GHC#Common_subexpressions
17:19:59 <lambdabot> Title: Performance/GHC - HaskellWiki, http://tinyurl.com/y86vb7
17:20:01 <dcoutts> pejo, not at all
17:20:02 <emu> phr-newbie: implementation of the compiler can change that apparently :P
17:20:19 <phr-newbie> emu, precisely.  so in order to know the complexity of a program i have to know specifics of the compiler
17:20:20 <int-e> phr-newbie: that should explain why let  fib x = 1 : 1 : zipWith (+) (fib ()) (tail (fib ())) runs in reasonable time on ghc.
17:20:21 <phr-newbie> it's not in the language
17:20:32 <dcoutts> pejo, not introduce it (since that can cause leaks) and not elimiate it (since that can give repeated work)
17:20:35 <ThreeQ> but you know the upper bound
17:20:52 <ThreeQ> the compiler never makes it worse, or at least it shouldn't :)
17:21:19 <phr-newbie> int-e, gaaaaah
17:21:35 <phr-newbie> threeQ, knowing that the upper bound is exponential is useless!
17:21:39 <Maddas> ThreeQ: Every linear function has an exponential upper bound, though :-)
17:21:41 <int-e> phr-newbie: sorry. I was looking for 'opportunistic CSE' and didn't read the context.
17:22:25 <pejo> dcoutts, are there any characterisations on what exactly causes space leaks, and is it possible to mechanically reason about it?
17:22:38 <int-e> phr-newbie: anyway, ghc is very careful with doing CSE. (but actually still not careful enough occasionally)
17:23:11 <dcoutts> pejo, it's not that well formalised, basically it needs more work
17:23:48 <dcoutts> phr-newbie, I think that example is being compiled wrong by the version of ghc that lambdabot is using
17:24:09 <dcoutts> phr-newbie, when I try it, I do get the exponential behaviour that'd you'd expect from no sharing
17:24:38 <phr-newbie> dcoutts, hmm, odd to say that lambdabot's version is the wrong one then :)
17:25:03 <dcoutts> well, I can't repdouce that result with any other ghci or hugs verion I've got
17:25:11 <dcoutts> > let fib x = 1 : 1 : zipWith (+) (fib ()) (tail (fib ())) in (fib () !! 50)
17:25:13 <lambdabot>  20365011074
17:25:20 <dcoutts> dunno
17:25:25 <int-e> > let fib x = 1 : 1 : zipWith (+) (fib ()) (tail (fib 1)) in (fib 2 !! 50)
17:25:25 <lambdabot>  add an instance declaration for (Num ())
17:25:40 <int-e> > let fib x = 1 : 1 : zipWith (+) (fib 3) (tail (fib 1)) in (fib 2 !! 50)
17:25:42 <lambdabot>  20365011074
17:26:07 <int-e> oh wait, it probably does that because x is unused ...
17:27:05 <int-e> dcoutts: I've seen ghc share two calls to [3,5..] in two different constant top level functions. that wasn't pretty.
17:27:10 <phr-newbie> goes exponential in hugs
17:27:32 <dcoutts> int-e, I get different results depending on how I write it
17:27:42 <phr-newbie> goodfib = 1 : 1 : zipWith (+) goodfib (tail goodfib)
17:27:42 <phr-newbie> badfib ()  = 1 : 1 : zipWith (+) (badfib ()) (tail (badfib ()))
17:28:12 <int-e> > let fib x = 1 : 1 : zipWith (+) (fib 3) (tail (fib (x+1))) in (fib 2 !! 50)
17:28:13 <lambdabot>  20365011074
17:28:41 <int-e> > let fib x = x : 1 : zipWith (+) (fib 1) (tail (fib 2)) in (fib 1 !! 50)
17:28:43 <lambdabot>  20365011074
17:29:29 <Igloo> dcoutts++ # fixing bugs!
17:29:31 <dolio> > let fib x = if x < 3 then 1 else fib (x-1) + fib (x-2) in fib 50
17:29:35 <lambdabot> Terminated
17:29:43 <dcoutts> Igloo, it was an easy one :-)
17:29:52 <emu> @pl fix (\f x -> 1 : 1 : zipWith (+) (f ()) (tail (f ())))
17:29:53 <lambdabot> fix (const . (1 :) . (1 :) . ap (zipWith (+)) tail)
17:29:54 <Igloo> Yes, but you actually fixed it  :-)
17:30:02 <emu> > fix (const . (1 :) . (1 :) . ap (zipWith (+)) tail)
17:30:03 <lambdabot>  Couldn't match `[b]' against `b1 -> [b]'
17:30:10 <dcoutts> int-e, for me, it depends if I write it as a top level function and on -O if it shares or not
17:30:35 <dcoutts> Igloo, well, I tell you what, you can fix the next one. :-)
17:30:38 <dolio> > fix ((1:) . scanl (+) 1)
17:30:40 <lambdabot>  [1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946,17...
17:31:04 <dolio> > fix ((1:) . scanl (+) 1) !! 50
17:31:05 <lambdabot>  20365011074
17:31:16 <dcoutts> Igloo, in particular, you can make hsc2hs not need so many ghc header files.
17:31:24 <emu> @type scanl
17:31:26 <lambdabot> forall a b. (a -> b -> a) -> a -> [b] -> [a]
17:31:35 <Igloo> dcoutts: OK, I'll fix the next easy bug, and you can fix the next one that requires spending a day in gdb ghc-6.5  :-)
17:31:51 <dcoutts> heh
17:32:10 <phr-newbie> @hoogle fix
17:32:10 <lambdabot> Control.Monad.Fix.fix :: (a -> a) -> a
17:32:11 <lambdabot> Control.Monad.Fix :: module
17:32:11 <lambdabot> System.IO.fixIO :: (a -> IO a) -> IO a
17:32:11 <ndm> Igloo: ok, i can add x `seq` x easily enough, will do that tomorrow
17:32:24 <Igloo> ndm: id $! is another one along similar lines
17:33:02 <ndm> Igloo: feel free to send patches over :)
17:33:02 <Igloo> dcoutts: If you know of anyone who knows about such things and is interested, I'd love to see Linker.c made redundant, incidentally
17:33:23 <dcoutts> Igloo, by using .so's and the system linker ?
17:33:35 <emu> > fix ((2:) . scanl (+) 1)
17:33:36 <Igloo> ndm: dcoutts does that these days, I just whine on mailing lists
17:33:36 <lambdabot>  [2,1,3,4,7,11,18,29,47,76,123,199,322,521,843,1364,2207,3571,5778,9349,15127...
17:33:45 <emu> > fix ((1:) . scanl (+) 2)
17:33:47 <lambdabot>  [1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946,1771...
17:33:56 <Igloo> dcoutts: Would it not theoretically be possible with .o's and dlopen?
17:34:14 <dcoutts> Igloo, oh, hmm. I really don't know about that.
17:34:21 <Igloo> Hmm, there's no obvious bug for it. I wonder where Simon's notes went
17:34:29 <dcoutts> Igloo, it should be possible to use non-PIC .so's though
17:34:46 <dcoutts> though people typically don't of course
17:35:14 <SamB> libdl doesn't seem to much like .os...
17:35:41 <lisppaste2> int-e pasted "bad sharing in ghc" at http://paste.lisp.org/display/28094
17:35:56 * Igloo will dig out Simon's mail after I've gone through the BTS (in case it is hiding in there after all)
17:36:20 <int-e> dcoutts: maybe you find this interesting (I've only tested 6.4.2 though)
17:37:12 <phr-newbie> i think anybody who knows lisp can write a lisp interpeter pretty easily, which has all the right complexity behavior
17:37:17 <phr-newbie> i don't see that for haskell
17:37:35 <dcoutts> phr-newbie, lisp has to simulate lazyness
17:37:45 <int-e> Haskell isn't meant to be a simple language.
17:37:55 <dcoutts> int-e, there seems to be some naming problem there, primes calls primes0
17:37:57 <phr-newbie> dcoutts, right, laziness is confusing
17:38:05 <int-e> dcoutts: not at all, that's intentional
17:38:10 <dcoutts> int-e, oh
17:38:16 <dcoutts> phr-newbie, doing it an an encoding is more confusing
17:38:21 <shapr> phr-newbie: Actually, it's not hard to implement a lambda calculus interpreter that's close enough to being Haskell to be confusing.
17:38:31 <shapr> phr-newbie: Derek Elkins did that with @lambda in lambdabot
17:38:43 <int-e> dcoutts: I only want to precompute and share the small primes.
17:38:53 <int-e> dcoutts: so that's primes0
17:39:01 <dcoutts> int-e, ah ok
17:39:04 <SamB> shapr: it isn't confusing unless you call it @eval
17:39:32 <shapr> @lambda map (\x -> x + 1) [1,2,3]
17:39:32 <lambdabot> [2, 3, 4]
17:39:33 <dcoutts> phr-newbie, and everyone does use lazyness, they just don't know it. They usually call it doing stuff 'on demand' instead and they have to use heavy encodings like iterators.
17:39:47 <dcoutts> or co-routines
17:40:01 <int-e> or generators (python)
17:40:05 <phr-newbie> i remember one of the claims about algol 60 was that it was sufficiently well-specified that the same program running on any two conforming implementations would reach the same result
17:40:08 <shapr> or they call it "if"
17:40:22 <phr-newbie> as opposed to (for example) C, where f(g(), h()) can evaluate the args of f in either order
17:40:39 <shapr> Conditional operators would be one cheesy way to implement laziness, since both branches are not evaluated.
17:40:54 <dcoutts> phr-newbie, in haskell, if both implementations get a result then it'll be the same.
17:41:06 <phr-newbie> dcoutts, right, but they may not have the same complexity
17:41:17 <dcoutts> phr-newbie, but as you noticed, you can make pathalogical examples where the sharing is crucial
17:41:29 <dcoutts> I've never seen that happen in practics
17:41:33 <int-e> dcoutts: anyway ghc shares a common subexpression here and that's bad.
17:41:41 <dcoutts> int-e, report it
17:41:55 <phr-newbie> int-e, why is it bad if the cse really is common?
17:42:16 <dcoutts> phr-newbie, sometimes it's better to cahce things, sometimes it's better to recalculate
17:42:18 <int-e> phr-newbie: because it comes at a cost in memory consumption.
17:42:41 <phr-newbie> dcoutts, yeah, it's like SQL
17:42:42 <int-e> phr-newbie: the program that should run in less than 5 MB takes 20 now. and it could easily be much worse.
17:42:57 <phr-newbie> int-e, oh i see, it's a space leak
17:45:26 <phr-newbie> so, i want to write high-performance concurrent internet applications.  am i nuts to be messing with haskell with that in mind?
17:45:47 <phr-newbie> is there anything like mnesia (the erlang database) for haskell?
17:47:19 <shapr> There is distributed haskell, goffin, and other interesting libs, but I haven't seen any production quality distributed database stuff.
17:47:29 <shapr> But if you want hiperf internet apps, check out HAppS
17:47:38 <shapr> That's the whole goal of HAppS
17:47:47 <phr-newbie> hmm http://happs.org/HAppS/README.html
17:47:49 <lambdabot> Title: HAppS -- Haskell Application Server (version 0.8.4 )
17:47:52 * shapr is hacking on HAppS right now...
17:48:31 <phr-newbie> it seems to me that a lot of traditional apps use SQL database back ends, in order to punt their concurrency issues to the database, and they screw themselves performance-wise because of that
17:49:07 <phr-newbie> but writing in haskell maybe makes concurrency a lot easier, so one can more easily do without SQL
17:49:29 <shapr> HAppS does not use a SQL database for reasons similar to what you describe.
17:49:51 <phr-newbie> happs looks neat
17:49:53 <emu> rdbms's tend to be much faster at processing data, concurrency issues notwithstanding
17:50:28 <shapr> Correct concurrency is designed into HAppS from the beginning, it has a write ahead log with checkpoints and recovers quickly even if the power is pulled.
17:52:47 <phr-newbie> emu, i think rdbms's kill you because of all the IPC and marshalling/demarshalling overhead
17:53:07 <emu> nope
17:53:33 <emu> if there's anything i've learned in my experience writing apps, it's to do heavy lifting with the database
17:53:37 <emu> *webapps
17:54:22 <phr-newbie> plus they have to maintain all these indices on disk, or at least in practice they try to do that, so committing a transaction always updates the indices
17:55:01 <dcoutts> phr-newbie, no, rdbms kill you because they're psychopathic
17:56:21 <emu> the cost of marshalling is nothing compared to the cost of sorting, selecting, joining, etc
17:56:25 <phr-newbie> well it seems to me that busy web apps are always waiting on the database
17:56:31 <phr-newbie> emu fair enough
17:56:42 <phr-newbie> so the relational model kills you in its own right :)
17:56:50 <shapr> My experience writing webapps is the opposite, I don't see the need for backend databases.
17:57:56 <phr-newbie> web apps are maybe different from data mining apps, in a typical web app, most selects return just a few rows
17:58:11 <phr-newbie> which means they could be done with in-memory table lookups
17:58:30 <phr-newbie> write all updates out to disk by appending to a log
17:58:47 <phr-newbie> crunch the log into something with indexes offline, or just read it back in on restarting the server
17:59:21 <ThreeQ> it seems like most "big" web apps use something like memcached to stick data into memory anyway
17:59:47 <emu> admittedly, if you're dealing with data that's not so easy to squash into the relational model, then things change
18:00:16 <phr-newbie> emu i'm even talking about straightforward apps like blogs
18:00:42 <phr-newbie> i mean, transactional systems from the 1960's ran on computers 1000's of times slower than today's computers, and did just about as many TPS
18:00:47 <emu> ok, sort 5000 comments in order of name
18:01:05 <SamB> name?
18:02:04 <SamB> phr-newbie: WTH is a transaction?
18:02:05 <phr-newbie> sorting 5000 items is not that big a deal
18:02:19 <emu> i assure you, whatever you write, it will be slower than an rdbms
18:02:36 <Pseudonym> I've written the sort code for a database server.  It's a big deal.
18:02:49 <Pseudonym> In some database systems, accessing the sort key costs a huge amount.
18:02:59 <Pseudonym> You have to get pretty clever.
18:03:20 <phr-newbie> emu ???  simply waiting for the two context switches to send the query to the db server, plus the network traffic to get the query out and the answer back, would take far longer than calling an in-memory sort routine
18:03:28 <phr-newbie> for 5000 items
18:03:34 <emu> no, you're wrong on several counts
18:03:37 <phr-newbie> no matter how fast the db does the sort
18:03:49 <emu> i'm speaking from experience
18:03:59 <phr-newbie> emu, then why are these blogs so slow?  they're not doing much
18:04:09 <Pseudonym> When I search my university library's catalogue, it greets me with the following message down the bottom of the screen:
18:04:11 <Pseudonym> Note: If the result set has more than 200 records, it will not be sorted. If it has fewer records, it will be sorted by Date.
18:04:14 <emu> I've made that mistake of doing operations like sorting and filtering in the program
18:04:29 <Pseudonym> Clearly 5000 items is a big deal for this system.
18:04:47 <phr-newbie> samb, transaction = a sequence of lookups and updates that are committed atomically
18:04:49 <emu> the program progressively slows down as the number of items it deals with gets bigger
18:04:55 <emu> and noticeably
18:05:48 <emu> i rewrote the code to just use select with order by, and it was lightning fast
18:06:07 <phr-newbie> wait a sec you were doing select and THEN sorting in the app?
18:06:17 <phr-newbie> so you had the worst of both worlds
18:06:19 <emu> indeed
18:06:47 <syntaxfree> open-ended question: can the type structure available to a Haskell program at a given time be described as a formal ontology?
18:07:51 <SamB> ontology?
18:08:14 <phr-newbie> somebody claimed about OCAML that once he gets his code to compile without error messages, it usually works right
18:08:38 <SamB> this is probably even more true in Haskell...
18:08:41 <syntaxfree> isn't that true about most non-dynamically typed languages?
18:08:46 <emu> somebody hasn't written complicated programs in ocam
18:08:49 <phr-newbie> syntaxfree, definitely not :)
18:08:49 <SamB> does C count?
18:08:56 <SamB> does Java count?
18:09:00 <SamB> does C++ count?
18:09:04 <syntaxfree> C has type casting, I've heard.
18:09:09 <phr-newbie> C and C++ are untyped
18:09:12 <emu> hehe i'd say that "property" applies to languages with an HM-style type system
18:09:19 <Pseudonym> C and C++ are not untyped.
18:09:21 <phr-newbie> java is statically typed and i'd say it's much easier to debug than C
18:09:32 <Pseudonym> Especially C++.
18:09:42 <emu> C++ is statically typed + whatever nonsense they threw into the spec
18:09:45 <syntaxfree> I've heard Java is a straitjacket language that makes it virtually impossible to  mess up.
18:09:58 <Pseudonym> C++'s type system is also really easy to subvert.
18:10:08 <Pseudonym> Just not easy to do by accident.
18:10:10 <phr-newbie> pseudonym that's what I mean, C and C++ are untyped
18:10:14 <Pseudonym> Unlike C's typesystem.
18:10:20 <int-e> syntaxfree: mess up how?
18:10:21 <emu> C++ is stricter than C
18:10:28 <phr-newbie> classic example: int a[10].  what is the type of a[11]?
18:10:28 <Pseudonym> Yes, C++ is much stricted than C.
18:10:32 <SamB> Pseudonym: what about accidentally byteslicing objects?
18:10:32 <emu> C is pretty much like asm in a sense
18:10:34 <phr-newbie> c++ has the same prob
18:10:57 <Pseudonym> SamB: I think that's less common than is customarily believed.
18:10:58 <syntaxfree> can  Haskell data types be described as a Haskell data type?
18:11:06 <Pseudonym> I've never seen a problem with byteslicing in real code.
18:11:11 <emu> syntaxfree: have you taken a look at the Report?
18:11:13 <int-e> syntaxfree: java makes it somewhat hard to cause the jvm dump core.
18:11:16 <phr-newbie> syntaxfree haskell doesn't have 1st class types if that's what you mean
18:11:18 <SamB> phr-newbie: a[11] is *(a+11), which dereferences a pointer of uncertain value
18:11:20 <SamB> that is...
18:11:30 <syntaxfree> not quite.
18:11:32 <SamB> you aren't allowed to have pointers past a+10...
18:11:35 <phr-newbie> right, *(a+11) has no type
18:11:44 <Pseudonym> *(a+11) has a type.
18:11:45 <Pseudonym> It's int.
18:11:49 <SamB> however, the type is quite clear ;-)
18:11:52 <phr-newbie> samB what do you mean, not allowed?  the compiler and runtime both let you do it
18:12:07 <emu> they let you do x / 0 too
18:12:10 <SamB> not allowed as in your brain may be eaten by zombies if you do that
18:12:16 <Pseudonym> Having said that, C++ discourages the use of raw pointers, so this kind of bug is fairly uncommon.
18:12:18 * syntaxfree recalls his gentoo ricer days.
18:12:23 <syntaxfree> -ffast-math
18:12:31 <phr-newbie> fairly uncommon, hee hee hee
18:12:46 <SamB> phr-newbie: in *proper* code
18:12:46 <Pseudonym> It only happens in C++ programs written by C programmers.
18:13:04 <SamB> or those C/C++ programmers you hear so much about
18:13:04 <phr-newbie> all those microsoft c++ apps getting security patches from buffer overflow bugs just about every day
18:13:14 <Pseudonym> Yeah, I've never actually met a C/C++ programmer.
18:13:17 <int-e> I miss a garbage collector that's integrated with the language in C++.
18:13:19 <SamB> who write in a subset of C++ that is subtly different from C ;-)
18:13:23 <emu> libgc!
18:13:25 <Igloo> phr-newbie: If you're arguing that that example makes C not typed, then Haskell with teh FFI isn't either
18:13:26 <emu> lol
18:13:36 <phr-newbie> igloo, yeah, probably true
18:13:36 <SamB> int-e: managed C++?
18:13:52 <Pseudonym> phr-newbie: I can't help Microsoft programmers, unfortunately.
18:13:59 <emu> Pseudonym: is that set-difference?  C / C++ programmers?
18:14:05 <Pseudonym> Oh, it might be.
18:14:08 <syntaxfree> there's a documentary on Kim Jong Il on the telly right now. Such an odd fellow.
18:14:10 <SamB> emu: no it isn't
18:14:12 <phr-newbie> a+11 can point at the address of a float variable
18:14:13 <emu> :P
18:14:21 <emu> hay, operator overloading
18:14:28 <phr-newbie> so if you store some int at *(a+11) then the float variable no longer actually has a float in it
18:14:31 <SamB> I'm referencing the nonexistant C/C++ language ;-)
18:14:48 <phr-newbie> is there also a C % C++ language?
18:14:53 <Pseudonym> I suspect that C/C++ is a dialect of C++/CLI.
18:14:55 <SamB> phr-newbie: or daemons could go up your nose!
18:15:08 <Pseudonym> Or GNU/Linux.
18:15:20 <emu> I was always a fan of the nose-bat theory
18:15:24 <TSC> Out of your nose, surely
18:16:33 <SamB> see http://www.faqs.org/faqs/C-faq/learn/ (question 2)
18:16:34 <lambdabot> Title: [alt.comp.lang.learn.c-c++] - FAQ list
18:16:39 <Pseudonym> The main two things I want from a type system are:
18:16:50 <int-e> SamB: that's interesting but how would I compile a MC++ program? system: Linux. desired target: native x86.
18:16:51 <Pseudonym> 1) The inability to subvert it by accident.
18:17:00 <Pseudonym> 2) The ability to do what I want without subverting it deliberately.
18:17:16 <Pseudonym> Haskell wins on both points.  C++ wins on the first and partly wins on the second.
18:17:36 <Pseudonym> C loses on both points.
18:17:39 <SamB> why doesn't Google Groups have a handy link to the group's FAQ...
18:17:41 <phr-newbie> you've never had a pointer bug in a c++ program?  you've got to be kidding :)
18:17:54 <Pseudonym> phr-newbie: When I was learning C++ I did.
18:17:57 <syntaxfree> What attracts me to Haskell is how close its type system is to algebraic structures.
18:18:08 <Pseudonym> That was ages ago, though.
18:18:26 <SamB> int-e: oh, I have no clue!
18:18:29 <Pseudonym> I rarely use raw pointers when references, smart pointers and iterators do the job better.
18:18:47 <int-e> emu: hmm, do you know any non-conservative gc library for C++?
18:18:53 <emu> yes actually
18:18:57 <SamB> whoa!
18:19:00 <phr-newbie> there's no gc, you've never freed something and then used it again?  or leaked memory?
18:19:02 <SamB> non-conservative?
18:19:04 <emu> however it requires following a specific coding style
18:19:06 <SamB> neato!
18:19:11 <emu> i think it was called Qi
18:19:13 <SamB> emu: I guess!
18:19:16 <int-e> emu: that's expected.
18:19:19 <Pseudonym> phr-newbie: Again, many years ago I did.
18:19:41 <Pseudonym> Since I discovered smart pointers and smart containers, I don't think I've ever done that.
18:20:16 <Pseudonym> Only on very rare occasions have I had pointer-related bugs, and it was in code where I knew it was coming, because I had to do ugly memory hackery.
18:20:25 <Pseudonym> The sort code intthe database server was a good example.
18:20:43 <Pseudonym> Doing it type safe required N more words of memory, where N was the number of records being sorted.
18:20:51 <Pseudonym> And I couldn't afford that.
18:21:10 <Pseudonym> So I did some type subversion and watched it carefully for the inevitable bugs.
18:21:55 <br1> Pseodonym: Could you explain that situation better?
18:22:04 <phr-newbie> this is from alex martelli:
18:22:05 <phr-newbie> At Google, we collectively have rather a lot of experience in these
18:22:05 <phr-newbie> issues, since we use three general-purpose languages: Python, Java, C++.
18:22:05 <phr-newbie> In this mix, the role of C++ is essentially that of allowing the
18:22:05 <phr-newbie> programmer to have complete control on memory allocation issues: the
18:22:05 <phr-newbie> only widespread modern language to do that, since all others, including
18:22:07 <phr-newbie> both Java and Python, have garbage-collection.  In the internal style
18:22:09 <phr-newbie> guide for C++, we forbid the use of so-called ``smart'' pointers which
18:22:13 <phr-newbie> would basically amount to a hacked-up garbage collection system (which
18:22:16 <phr-newbie> can never be as solid and thorough as those built into the virtual
18:22:17 <phr-newbie> machines used in Java or Python -- a GC system that's thread-safe is a
18:22:19 <phr-newbie> nightmare to build and debug based only on those "smart pointers", for
18:22:21 <phr-newbie> example, and if you start locking and mutexing all over the place for
18:22:23 <phr-newbie> that purpose you'll soon see performance plummet...): if you want
18:22:26 <phr-newbie> garbage collection you use a garbage-collected language -- the choice of
18:22:27 <phr-newbie> C++ for a component implies that you need complete control of memory
18:22:29 <phr-newbie> issues for that component, therefore choosing C++ and ``too smart for
18:22:31 <phr-newbie> their own good'' pointers would be mutually contradictory.
18:22:33 <phr-newbie> sorry about the big paste
18:22:48 <emu> lisppaste2: url
18:22:48 <lisppaste2> To use the lisppaste bot, visit http://paste.lisp.org/new/haskell and enter your paste.
18:23:25 <Pseudonym> br1: Kind of, what do you want to know?
18:23:39 <newsham> flawed premise: the only reason to select c++ is to have control over allocation.
18:23:44 <Pseudonym> Look, my answer to that is that he's right in one sense.
18:23:49 <Pseudonym> That C++ isn't the answer to everything.
18:23:54 <Pseudonym> Well duh.
18:24:03 <Pseudonym> But when you need C++, you really need C++.
18:24:18 <br1> What was it that you couldn't do without hackery and what tricks did you use?
18:24:38 <Pseudonym> I think the reason why they disallow smart pointers in C++ is because to do so would encourage use of C++ where Python would be better.
18:24:39 <emu> sigh, i can't find a link to the precise GC library.  it's been a long time.
18:24:44 <newsham> if you pick c++ for some other reason, then GC and/or smart pointers may make sense.
18:24:47 <Pseudonym> Surely it's social engineering.
18:24:58 <newsham> (also, you may want complete control over SOME but not all memory allocations)
18:25:02 <phr-newbie> smart pointers always seemed pretty fragile to me
18:25:04 <int-e> SamB: conservative GC feels dirty :)
18:25:16 <Pseudonym> br1: Oh, the details are unimportant, and trade-secrety.
18:25:21 <br1> :o
18:25:22 <newsham> int-e: conservative GC is dirty.  but sometiems dirty works fine.
18:25:26 <Pseudonym> But... OK, imagine a search engine like Google.
18:25:33 <Pseudonym> Suppose you want to sort your result set.
18:25:47 <emu> there's rtgc, but that's not the one i remember
18:25:59 <Pseudonym> A "result set" in a text database, like Google, is logically a sequence of record numbers.
18:26:16 <Pseudonym> Contrast this with a SQL result, which is a stream of tuples, where the tuples actually contain data.
18:26:47 <Pseudonym> So to sort results in a text database, you need to access sort keys, because they're not right there in the tuples.
18:26:54 <Pseudonym> That requires indirection./
18:27:19 <Pseudonym> And hitting disk is expensive.
18:27:39 <Pseudonym> However, for a system like Google, you don't actually need to sort all the records.
18:27:58 <emu> firefox, for lack of a better word, has... Jammed
18:27:58 <Pseudonym> You actually only need to sort the first few screensful, and enough information to sort the rest later.
18:28:16 <Pseudonym> So you distribute the work over the browse time to decrease latency.
18:28:44 <Pseudonym> Moreover, if you're sorting by multiple keys (say, surname then first name then middle initial), then sometimes you can save work.
18:29:07 <Pseudonym> If the surname determines the order for some range of the records, then you don't need to fetch first name off disk at all,.
18:29:38 <Pseudonym> What I ended up doing was using a specialised sort algorithm which sorts by a single key, but also computes "regions" where the order isnt' fully resolved yet.
18:29:46 <Pseudonym> And only fetch secondary keys for those regions.
18:29:49 <Pseudonym> And so on.
18:30:04 <Pseudonym> Plus a bunch of other stuff.
18:30:14 <Pseudonym> Sorting looks like an easy problem, but I assure you it's not. :-)
18:30:42 <emu> and that's why i prefer to leave it to the database!
18:30:46 <Pseudonym> Anyway, the piece of memory that I had to use was at onne point a sequence of record numbers and at another point a sequence of pointers to structures.
18:30:59 <Pseudonym> 'Cause that's what I needed.
18:31:29 <Pseudonym> The reason why I needed indirection was that the problem was indirect.
18:31:47 <Pseudonym> Result sets might contain data from different databases, perhaps distributed across a server farm.
18:32:12 <Pseudonym> And the most efficient way to access a sort key might be different for different databases.
18:32:18 <Pseudonym> Depending on whether it's local or remote, say.
18:32:49 <Pseudonym> In addition, we had on-disk data structures like indexes to speed up sorting.
18:33:00 <Pseudonym> The presence of absence of these changed the equation further.
18:33:34 <Pseudonym> (Indexes are data structures designed to avoid the need for grepping every record.  "Sortdexes", as we called them, had a similar purpose, only for sorting instead of searching.)
18:33:44 <Pseudonym> Anyway,l
18:33:45 <phr-newbie> in the case of something like a blog, users don't get to enter their own weird comparison functions, they at most get to just choose between a few.  so the app can just keep multiple sorted lists around
18:33:49 <Pseudonym> This is why it's a hard problem.
18:33:56 <Pseudonym> phr-newbie: Sure.
18:34:12 <Pseudonym> Obviously a text database server is for hard problems and big datasets, not for blogs.
18:34:27 <phr-newbie> so we're back to the question of why these damn blogs are so slow
18:34:33 <Pseudonym> :-)
18:34:43 <phr-newbie> :)
18:35:06 <emu> you're assuming the code is well written, phr
18:35:14 <Pseudonym> Well, that's true.
18:35:23 <Pseudonym> Blogs tend not to be well-engineered.
18:35:26 <emu> you're also assuming they're not using some backasswards rdbms like MySQL
18:35:48 <emu> which, sadly, tends not to be the case
18:36:38 <br1> Pseudonym: You have convinced me that it was really tricky to get right.  What I don't see which part of this complexity was due to pointers.
18:36:55 <int-e> emu: thanks anyway :)
18:37:12 <Pseudonym> That's not what I said.
18:37:12 <emu> i swear it was Q something
18:37:19 <Pseudonym> I managed part of the complexity by abusing the type system.
18:37:24 <phr-newbie> i've always heard mysql is ok if you don't select large sets too often and there's not too much concurrent updates
18:37:32 <Pseudonym> And I _knew_ exactly what part of the system would be buggy;
18:37:37 <phr-newbie> i.e. mysql is optimized for typical web apps
18:37:44 <newsham> it amazes me how often people use a database when an ad hoc store would be simpler and easier.
18:37:53 <emu> mysql is ok if all you do is this: "SELECT name, blah FROM stupid_pointless_table"
18:38:08 <Pseudonym> Well, there are some problems for which Berkeley DB isn't quite powerful enough.
18:38:11 * Cale emails Niklaus Wirth about functional programming :)
18:38:34 <Pseudonym> Cale: Mail him a copy of "Lambda, the ultimate GOTO".
18:38:39 <Cale> hehe
18:38:43 <newsham> "databsae administrator", need I say more?
18:38:55 <syntaxfree> where can I download the "Lambda the Ultimate""series?
18:39:04 <hyraxfourtwo> readscheme.org
18:39:36 <Cale> I basically discuss the more recent progress, presenting monads as a way to control the use of state while not making it burdensome for the programmer.
18:39:55 <syntaxfree> oh!
18:40:03 <Cale> and also present the algebraic techniques for optimisation using Data.ByteString as an example
18:40:06 <syntaxfree> have you been exchanging emails for a while?
18:40:10 <Cale> no
18:40:19 <Cale> This is the first one, and I just sent it.
18:40:28 <Cale> It's a bit long, I hope he at least reads it :)
18:40:29 <syntaxfree> I should email professors when I have comments.
18:40:32 <syntaxfree> I'm very shy about it.
18:49:47 <Pseudonym> You should hecke them in lectures.
18:49:49 <Pseudonym> heckel
18:49:52 <Pseudonym> They love that.
18:49:55 <Pseudonym> It shows you're listening.
18:52:44 <dons> hey everyone
18:52:55 <Smokey`> hey dons.
18:52:55 <dibblego> g'day dons
18:52:55 <emu> hi
18:53:12 <jgrimes> hey
18:53:26 <Pseudonym> G'day.
18:55:10 <dons> ?uptime
18:55:11 <lambdabot> uptime: 4d 4h 1m 40s, longest uptime: 6d 15h 1m 36s
18:55:31 <x3m> > foo=1+length[a|a<-[0..200],b<-(map(*2)[0..(100-div(1+a)2)]),c<-(map(*5)[0..(40-div(4+a+b)5)]),d<-(map(*10)[0..(20-div(9+a+b+c)10)]),e<-(map(*20)[0..(10-div(19+a+b+c+d)20)]),f<-(map(*50)[0..(4-div(49+a+b+c+d+e)50)]),g<-(map(*100)[0..(2-div(199+a+b+c+d+e+f)200)]),a+b+c+d+e+f+g==200]
18:55:32 <lambdabot>  Parse error
18:55:39 <dons> hi x3m. interesting....
18:55:40 <x3m> > let foo=1+length[a|a<-[0..200],b<-(map(*2)[0..(100-div(1+a)2)]),c<-(map(*5)[0..(40-div(4+a+b)5)]),d<-(map(*10)[0..(20-div(9+a+b+c)10)]),e<-(map(*20)[0..(10-div(19+a+b+c+d)20)]),f<-(map(*50)[0..(4-div(49+a+b+c+d+e)50)]),g<-(map(*100)[0..(2-div(199+a+b+c+d+e+f)200)]),a+b+c+d+e+f+g==200]
18:55:41 <lambdabot>  Parse error
18:55:44 <x3m> pff
18:55:46 <dons> still hacking away at haskell, i see?
18:55:56 <x3m> not much but a little :)
18:55:57 <dons> you can always run it in a privmsg ;)
18:56:06 <x3m> im short on time :/
18:56:16 <x3m> to much stuff to do
19:00:21 <int-e> x3m: you should reverse the search, start with g <- [0,100..200], f<-[0,50..200-g], ..., let a = 200-g-f-e-d-c-b  ... not sure if that is fast enough but at least it avoids quite a bit of useless work.
19:03:37 <x3m> int-e: no
19:04:52 <int-e> why no?
19:05:47 <x3m> cause its not what i intend to do
19:06:46 <lennart> howdy!
19:07:32 <hyraxfourtwo> > -1/0
19:07:37 <lambdabot>  -Infinity
19:07:46 <int-e> x3m: it'll certainly calculate the same value for foo, only faster.
19:08:01 <hyraxfourtwo> > -1/0 < -3e200
19:08:03 <lambdabot>  True
19:08:39 <hyraxfourtwo> > round $ 1/0
19:08:40 <lambdabot>  1797693134862315907729305190789024733617976978942306572734300811577326758055...
19:08:44 <x3m> int-e: no what i wanna do
19:08:57 <hyraxfourtwo> lambdabot, right
19:09:18 <int-e> > 1+length[a|a<-[0..200],b<-(map(*2)[0..(100-div(1+a)2)]),c<-(map(*5)[0..(40-div(4+a+b)5)]),d<-(map(*10)[0..(20-div(9+a+b+c)10)]),e<-(map(*20)[0..(10-div(19+a+b+c+d)20)]),f<-(map(*50)[0..(4-div(49+a+b+c+d+e)50)]),g<-(map(*100)[0..(2-div(199+a+b+c+d+e+f)200)]),a+b+c+d+e+f+g==200]
19:09:23 <lambdabot> Terminated
19:09:38 <int-e> > 1+length[a|a<-[0,100..200],b<-[0,50..200-a],c<-[0,20..200-a-b],d<-[0,10..200-a-b-c],e<-[0,5..200-a-b-c-d],f<-[0,2..200-a-b-c-d-e]]
19:09:39 <lambdabot>  73682
19:09:41 <phr-newbie> ?type [1,2,3]
19:09:46 <lambdabot> forall a. (Num a) => [a]
19:09:46 <emu> why does it say Infinity for 1/0
19:09:47 <int-e> > let step n l = let l' = zipWith (+) l (replicate n 0 ++ l') in l' in foldr step (1:repeat 0) [1,2,5,10,20,50,100,200] !! 200
19:09:48 <emu> > 1/0
19:09:50 <lambdabot>  73682
19:09:51 <lambdabot>  Infinity
19:10:01 <phr-newbie> ?type []
19:10:03 <lambdabot> forall a. [a]
19:10:28 <lennart> emu: why not?
19:10:37 <emu> cause its not right?
19:10:37 <hyraxfourtwo> ?scheck (< 1/0)
19:10:38 <lambdabot>  Add a type signature
19:10:48 <hyraxfourtwo> ?scheck (< 1/0) :: Double -> Bool
19:10:48 <lambdabot>  add an instance declaration for (Serial Double)
19:10:49 <lambdabot>   In the definition of `p...
19:10:54 <hyraxfourtwo> ?qcheck (< 1/0) :: Double -> Bool
19:10:54 <lambdabot> Maybe you meant: check scheck
19:10:56 <int-e> x3m: so what were you trying to do? the let foo=  was too much (or you should have written let foo=... in foo)
19:10:57 <hyraxfourtwo> ?check (< 1/0) :: Double -> Bool
19:10:58 <lambdabot>  OK, passed 500 tests.
19:11:05 <x3m> int-e: no
19:11:12 <lennart> emu: it's right with certain settings for IEEE arithmetic
19:11:23 <emu> i mean real arithmetic
19:11:39 <hyraxfourtwo> emu, so what should it be?
19:11:42 <lennart> floating point number are *NOT* real numbers
19:11:43 <emu> undefined
19:11:46 <emu> indeed
19:11:53 <hyraxfourtwo> > 1/0 :: Integer
19:11:54 <lambdabot>  add an instance declaration for (Fractional Integer)
19:11:55 <lambdabot>   In the expression:...
19:12:21 <hyraxfourtwo> > NaN
19:12:22 <lambdabot>  Not in scope: data constructor `NaN'
19:12:30 <hyraxfourtwo> > sqrt (-1)
19:12:31 <lambdabot>  NaN
19:12:39 <emu> why does it assume fp arithmetic
19:12:40 <lennart> > 0/0
19:12:41 <lambdabot>  NaN
19:12:44 <hyraxfourtwo> the defaulting
19:12:55 <hyraxfourtwo> you use sqrt
19:12:59 <hyraxfourtwo> ?type sqrt
19:13:00 <lambdabot> forall a. (Floating a) => a -> a
19:13:06 <hyraxfourtwo> the it defaults to Double
19:13:20 <hyraxfourtwo> ?instances Floating
19:13:21 <lambdabot> Double, Float
19:13:24 <lennart> > 1/ (0::Rational)
19:13:25 <SamB> lennart: sure floating point numbers are real numbers
19:13:26 <lambdabot>  Exception: Ratio.%: zero denominator
19:13:28 <emu> really, i think that's a mistake.  fp arithmetic should only be provided when explicitly asked for
19:13:34 <SamB> as long as they aren't complex numbers
19:13:37 <SamB> or something
19:13:39 <hyraxfourtwo> SamB, no they include infinity
19:13:45 <SamB> hyraxfourtwo: well.
19:13:49 <hyraxfourtwo> and NaN
19:13:52 <hyraxfourtwo> both of which are not in real
19:13:57 <SamB> nan isn't a number!
19:14:00 <lennart> samB: floating point numbers are  subset of the rationals with peculiar arithmetic
19:14:03 <hyraxfourtwo> but it's a floating point number
19:14:09 <SamB> > isNaN (sqrt (-1))
19:14:10 <lambdabot>  True
19:14:13 <SamB> lennart: this is true
19:14:18 <hyraxfourtwo> ?type isNaN
19:14:20 <lambdabot> forall a. (RealFloat a) => a -> Bool
19:14:32 <hyraxfourtwo> so isNaN ranges over RealFloat types
19:14:34 <SamB> I remember TAOCP uses wierd (+) and (-) operators
19:14:42 <lennart> samB: the real numbers have various nice properties that fp doesn't
19:14:45 <SamB> which are supposed to be + and - inscribed in circles
19:15:08 <lennart> like + being associative
19:15:10 <hyraxfourtwo> SamB, thatis the notation used in many numerical analysis texts I believe
19:15:25 <SamB> yeah well I haven't got any of those ;-)
19:15:26 <hyraxfourtwo> for the fp versions of the inscribed operation
19:15:29 <int-e> x3m: whatever.
19:15:58 <hyraxfourtwo> emu, it's type inference
19:16:04 <hyraxfourtwo> if you use a function that expects a float type
19:16:17 <lennart> floating point numbers are terrible.  I maintain that before using them people should have an floating point drivers license
19:16:17 <SamB> Haskell, of course, in typical programming language fashion, doesn't worry about whether the arithmatic rules actually make sense ;-)
19:16:17 <hyraxfourtwo> it infers the argument is a float type
19:16:41 <hyraxfourtwo> wasn't there some movement to redefien the numerical classes
19:16:42 <hyraxfourtwo> to have group
19:16:43 <hyraxfourtwo> ring
19:16:45 <hyraxfourtwo> field
19:16:48 <hyraxfourtwo> integral domain?
19:16:56 <SamB> oh, you mean the DoCon or whatever?
19:17:02 * hyraxfourtwo doesn't know
19:17:09 <x3m> int-e: what do you want, the result was what was intended
19:17:12 <hyraxfourtwo> I read about it before I decided to learn haskell
19:17:17 <SamB> emu: what mean you
19:17:21 <dons> ?remember lennart floating point numbers are terrible.  I maintain that before using them people should have an floating point drivers license
19:17:36 <emu> hyraxfourtwo: what type inference
19:17:37 <Pseudonym> > map length $ iterate (>>= (flip (\b->if b==1 then ((1:).(0:)) else (1:)
19:17:38 <lambdabot>  Parse error
19:17:39 <Pseudonym> [])) [0]
19:17:42 <emu> 1 is an integer, 0 is an integer
19:17:45 <hyraxfourtwo> no
19:17:46 <Pseudonym> > map length $ iterate (>>= (flip (\b->if b==1 then ((1:).(0:)) else (1:) []))[0]
19:17:47 <lambdabot>  Parse error
19:17:47 <hyraxfourtwo> ?type 1
19:17:49 <lambdabot> forall t. (Num t) => t
19:17:51 <SamB> emu: those are numbers
19:17:52 <SamB> see:
19:17:56 <SamB> @type 0
19:17:57 <lambdabot> forall t. (Num t) => t
19:17:59 <int-e> x3m: sorry for trying to improve your algorithm and assuming that you won't intentionally produce parse errors.
19:18:03 <emu> it's also a number
19:18:12 <SamB> emu: they can be integers, sure
19:18:31 <hyraxfourtwo> so when you use sqrt
19:18:41 <x3m> int-e: i dont need it changed
19:18:47 <emu> i mean if i asked the computer what 2/4 is i wouldnt expect it to give me 3/6, even though that's "correct"
19:18:59 <lennart> > (1::Double, 1::Int, 1::Rational, 1::Complex Float)
19:19:00 <SamB> emu: of course not!
19:19:00 <lambdabot>  (1.0,1,1%1,1.0 :+ 0.0)
19:19:04 <SamB> you'd expect 1/2!
19:19:08 <SamB> > 2/4
19:19:10 <lambdabot>  0.5
19:19:13 <Pseudonym> > map length $ iterate (>>=(flip(\b->if b==1 then ((1:).(0:)) else (1:)) [
19:19:13 <lambdabot>  Parse error
19:19:13 <Pseudonym> ])) [0]
19:19:16 <emu> yep, 1/2
19:19:19 <Pseudonym> > map length $ iterate (>>=(flip(\b->if b==1 then ((1:).(0:)) else (1:)) [])) [0]
19:19:20 <SamB> unfortunately Rational is after the floating types...
19:19:21 <hyraxfourtwo> > 1 % 2
19:19:23 <lambdabot> Terminated
19:19:24 <lambdabot>  1%2
19:19:27 <hyraxfourtwo> >1 :% 2
19:19:27 <Pseudonym> Huh?
19:19:30 <Pseudonym> Terminated?
19:19:36 <Pseudonym> Dammit.
19:19:52 <emu> You have been Terminated!
19:20:01 <SamB> oooooooh nooooooooooo!
19:20:10 <Cale> > 1 + 1
19:20:11 <lambdabot>  2
19:20:18 <Cale> > 1 :% 2
19:20:19 <lambdabot>  Not in scope: data constructor `:%'
19:20:22 <Cale> > 1 % 2
19:20:24 <lambdabot>  1%2
19:20:35 <hyraxfourtwo> ?type (%)
19:20:37 <lambdabot> forall a. (Integral a) => a -> a -> Ratio a
19:20:38 <lennart> > 1 / (2::Rational)
19:20:40 <lambdabot>  1%2
19:20:48 <hyraxfourtwo> % is a constructor?
19:20:48 <SamB> > 2 / 4 :: Rational
19:20:50 <lambdabot>  1%2
19:20:53 <SamB> hyraxfourtwo: no
19:20:57 <Pseudonym> > map length . take 3 $ iterate (>>=(flip(\b->if b==1 then ((1:).(0:)) else (1:)) [])) [0]
19:20:58 <lambdabot>  [1,1,2]
19:21:00 <SamB> it is a "smart constructor"
19:21:03 <hyraxfourtwo> ah ok
19:21:06 <Pseudonym> > map length . take 5 $ iterate (>>=(flip(\b->if b==1 then ((1:).(0:)) else (1:)) [])) [0]
19:21:07 <lambdabot>  [1,1,2,3,5]
19:21:11 <hyraxfourtwo> puts to reduced terms
19:21:11 <SamB> > 2 % 4
19:21:13 <hyraxfourtwo> automatically
19:21:13 <lambdabot>  1%2
19:21:15 <Pseudonym> > map length . take 10 $ iterate (>>=(flip(\b->if b==1 then ((1:).(0:)) else (1:)) [])) [0]
19:21:16 <hyraxfourtwo> in the real dt
19:21:16 <lambdabot>  [1,1,2,3,5,8,13,21,34,55]
19:21:25 <Pseudonym> > map length $ iterate (>>=(flip(\b->if b==1 then ((1:).(0:)) else (1:)) [])) [0]
19:21:26 <SamB> > 2 % 2
19:21:27 <hyraxfourtwo> (among possibly other things)
19:21:29 <lambdabot> Terminated
19:21:30 <lambdabot>  1%1
19:21:38 <hyraxfourtwo> >2 % 2 :: Integer
19:21:42 <hyraxfourtwo> > 2%2 Integer
19:21:43 <lambdabot>  Not in scope: data constructor `Integer'
19:21:47 <hyraxfourtwo> >252 :: Integer
19:21:51 <hyraxfourtwo> oh fer chrissake
19:21:54 <Pseudonym> Oh, I see.  It times out before computing a full line.
19:21:56 <hyraxfourtwo> > 2%2 :: Integer
19:21:57 <lambdabot>  Couldn't match `Integer' against `Ratio a'
19:22:05 <phr-newbie> @pl \x xs -> f x : xs
19:22:05 <lambdabot> (:) . f
19:22:13 <emu> > fromRational (2 % 2)
19:22:14 <lambdabot>  1.0
19:22:19 <hyraxfourtwo> ?instances Raio
19:22:19 <Cale> http://channel9.msdn.com/Showpost.aspx?postid=231495
19:22:19 <lambdabot> Not a class! Perhaps you need to import the  module that defines it? Try @help instances-importing.
19:22:23 <lambdabot> Title: Programming in the Age of Concurrency: Software Transactional Memory, http://tinyurl.com/ylylaa
19:22:49 <hyraxfourtwo> Cale, cool
19:22:51 <hyraxfourtwo> will have ot watch
19:23:29 <lennart> Pseudonym: are you trying to compute how many fibonacci numbers there are? ;)
19:23:52 <Pseudonym> Of course.
19:25:42 <newsham> i'm computing a list of all irrational fibonacci numbers
19:26:20 <lennart> ah
19:26:42 <emu> how about a list of all prime fibonacci numbers
19:27:23 <lennart> is there some theorem about how many there are?
19:28:18 <Cale> If fib(n) is prime, then n is prime.
19:28:32 <glguy> Is it Hask-al, Haskle, Has-kal, my fiancee keeps saying it different ways and now I'm not so sure
19:28:33 <Cale> But the converse isn't true.
19:29:16 <lennart> Cale: cool, but it doesn't answer my question :)
19:29:39 <Cale> It is not known if there are an infinite number of Fibonacci primes.
19:29:44 <weitzman> @let test = 4
19:29:46 <lambdabot> Defined.
19:30:01 <weitzman> @check (\x -> test == test) :: Int -> Bool
19:30:02 <lambdabot>  add an instance declaration for (Eq (a -> IO ()))     In a lambda abstracti...
19:30:32 <weitzman> @check (\x -> L.test == L.test) :: Int -> Bool
19:30:34 <lambdabot>  OK, passed 500 tests.
19:30:37 <lennart> Cale: thanks, i'll store that away in my fun trivia compartment
19:30:55 <Cale> It's also not known if 6 occurs as the difference of two perfect powers
19:32:25 <lennart> so much unknown!
19:33:06 <weitzman> I'm still waiting for someone to write a proof showing what the optimal algorithm for multiplication is
19:33:11 <weitzman> Seems like we should have that by now
19:34:07 <Cale> http://www.research.att.com/~njas/sequences/A074981
19:34:11 <lambdabot> Title: The On-Line Encyclopedia of Integer Sequences, http://tinyurl.com/rbubg
19:34:59 <Canar> ooh
19:35:05 <Canar> that looks like a job for haskell!
19:35:05 <lennart> weitzman: I thought that was a really tricky one
19:35:08 <Canar> :)
19:35:26 <weitzman> lennart: Everything is tricky if you don't know how to do it
19:35:32 <newsham> optimal algorithm?
19:35:50 <newsham> are we talking multiple-precision arithmetic?
19:36:05 <weitzman> newsham: In terms of algorithm complexity. Just integers, represented in binary
19:36:21 <newsham> and what are the primitives?
19:37:21 <Cale> http://www.archive.org/details/Nicholas1987
19:37:23 <lambdabot> Title: Internet Archive: Details: Nicholas Pippenger: Complexity of Addition
19:38:42 <newsham> if the primitives include 32-bit multiplication and the operands are 32bits then the optimal solution i spretty obvious
19:39:02 <weitzman> newsham: Can find the formulation I saw, but I imagine it's multiplication and bit-shift type stuff
19:39:05 <weitzman> *Can't
19:39:08 <Cale> what if the operands are arbitrarily large?
19:39:19 <weitzman> Ah, addition
19:39:20 <weitzman> Oops
19:39:26 <weitzman> Multiplication makes it easy :)
19:39:33 <newsham> then you can do it in O(N log N) by using a FFT and some addition.
19:39:39 <weitzman> Addition and subtraction, really
19:39:51 <weitzman> And breaking bit sequences into smaller sequences
19:40:09 <Cale> but is that a provably optimal algorithm?
19:40:54 <jgrimes> hm, how would one go about proving that a sorting algorithm sorts using the type system?
19:40:57 <newsham> long multiplication is the "convolution" of the parts of the two operands...
19:41:15 <int-e> http://en.wikipedia.org/wiki/Sch%C3%B6nhage-Strassen_algorithm
19:41:16 <newsham> and you can do convolution in O(n log n) by using an FFT
19:41:19 <lambdabot> http://tinyurl.com/wfhxw
19:41:33 <Cale> apparently the best known bound has bit complexity O(n lg n lg lg n)
19:42:04 <Cale> whereas FFT gives bit complexity O(n (lg n)^(2+e))
19:42:06 <int-e> you need to be a bit more careful in that analysis, because the FFT needs big numbers (although quite a bit smaller than the one you start with)
19:43:50 <newsham> i'm not doing a careful analysis, just stating the answer :)
19:46:03 <int-e> newsham: only that your answer differs from known bounds ...
19:46:23 <newsham> my O() isnt as big as your O()
19:47:23 <int-e> newsham: so either you're extremely clever or your O() means something different.
19:47:35 <dibblego> I hate writing Java after lunch
19:47:53 <newsham> my O is a little lazy
19:48:16 <Cale> You could say that it's O(n!), which you'd be right, but it wouldn't be interesting
19:48:42 <hyraxfourtwo> Cale, how is that to be parsed
19:48:52 <hyraxfourtwo> O(n lg (n lg lg n)?
19:49:00 <SamB_XP_> hyraxfourtwo: you know, "big oh (n factorial)"!
19:49:01 <hyraxfourtwo> )
19:49:04 <Cale> O(n (lg n) (lg lg n))
19:49:07 <int-e> no, O(n(lg n) (lg (lg n)))
19:49:32 <hyraxfourtwo> isn't that worse than n lg n?
19:49:42 <Cale> very slightly
19:49:43 <int-e> yes.
19:49:47 <int-e> that's the point really.
19:50:01 <int-e> newsham is claiming a better bound than the best known one.
19:50:12 <Cale> but it's better than O(n (lg n)^(2+e)), which is what naive FFT-based algorithms get
19:50:28 <hyraxfourtwo> wait I though you could do convolution in n log n with FFT
19:50:31 <hyraxfourtwo> :?
19:50:41 <hyraxfourtwo> oh you're dealing with bits?
19:50:41 <int-e> hyraxfourtwo: in n log n multiplications and additions, yes
19:50:49 <Cale> and better than O(n^(lg 3)) which is what Karatsuba multiplication gives
19:50:58 <hyraxfourtwo> go karatsuba
19:51:12 <int-e> hyraxfourtwo: but these don't need to fit into machine words, so you need higher precision arithmetic again
19:51:49 <hyraxfourtwo> is it strassen matrix multiplication?
19:51:52 * hyraxfourtwo forgets the name
19:51:58 <hyraxfourtwo> that is ~O(n^2.7) or so
19:52:08 <Cale> http://en.wikipedia.org/wiki/Sch%C3%B6nhage-Strassen_algorithm
19:52:13 <lambdabot> http://tinyurl.com/wfhxw
19:52:31 <hyraxfourtwo> oh right it was just linked
19:52:55 <int-e> the 2.7 there is lg(7).
19:53:08 <hyraxfourtwo> int-e, yeah I was about to check
19:53:12 <hyraxfourtwo> > log 7 / log 2
19:53:13 <lambdabot>  2.807354922057604
19:53:32 <int-e> hmm oh, there are improvements ... I forgot.
19:53:48 <Cale> There's O(n^2.376)
19:54:03 <Cale> http://en.wikipedia.org/wiki/Coppersmith%E2%80%93Winograd_algorithm
19:54:05 <lambdabot> http://tinyurl.com/vzt3f
19:54:34 <int-e> see also http://en.wikipedia.org/wiki/Matrix_multiplication
19:54:36 <lambdabot> http://tinyurl.com/qjbup
19:54:49 <hyraxfourtwo> http://en.wikipedia.org/wiki/Strassen_algorithm
19:54:51 <lambdabot> http://tinyurl.com/y82z2y
19:55:38 <Cale> These sorts of algorithms are exactly the sort of thing you get by ignoring constant factors in time :)
19:56:14 <newsham> nobody recommended you use them for anything less than huge numbers :)
19:56:18 <newsham> N^2 works pretty well :)
19:57:51 <Pseudonym> > let { g 0=id;g n=(if(n`mod`2)==0 then(\(a,b)->(a*a+2*a*b,a*a+b*b)) else
19:57:51 <Pseudonym> (\(a,b)->(2*a*a+2*a*b+b*b,a*a+2*a*b))).g(n`div`2) } in map (fst.flip g(0,1)) [0
19:57:52 <lambdabot>  Parse error
19:57:55 <Pseudonym> (\(a,b)->(2*a*a+2*a*b+b*b,a*a+2*a*b))).g(n`div`2) } in map (fst.flip g(0,1)) [0..]
19:57:59 <Pseudonym> Errr...
19:58:15 <Pseudonym> > let { g 0=id;g n=(if(n`mod`2)==0 then(\(a,b)->(a*a+2*a*b,a*a+b*b)) else (\(a,b)->(2*a*a+2*a*b+b*b,a*a+2*a*b))).g(n`div`2) } in map(fst.flip g(0,1)) [0..]
19:58:17 <lambdabot>  [0,1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946,...
19:58:19 <Pseudonym> There we go.
20:04:22 <Cale> http://citeseer.ist.psu.edu/65622.html this is an interesting paper on computing determinants in arbitrary rings (where Gaussian elimination would be impossible in general)
20:08:12 <Pseudonym> > let f n x=if x*x<=n&&n<(x+1)*(x+1) then x*x==n else f n((x+n`div`x)`div`2) in 1:filter(\n->f(5*n*n+4)1||f(5*n*n-4)1) [1..]
20:08:16 <lambdabot> Terminated
20:08:23 <Pseudonym> > let f n x=if x*x<=n&&n<(x+1)*(x+1) then x*x==n else f n((x+n`div`x)`div`2) in take 10 $ 1:filter(\n->f(5*n*n+4)1||f(5*n*n-4)1) [1..]
20:08:25 <lambdabot>  [1,1,2,3,5,8,13,21,34,55]
20:08:28 <Pseudonym> Hmmm.
20:08:42 <Pseudonym> > let f n x=if x*x<=n&&n<(x+1)*(x+1) then x*x==n else f n((x+n`div`x)`div`2) in take 20 $ 1:filter(\n->f(5*n*n+4)1||f(5*n*n-4)1) [1..]
20:08:44 <lambdabot>  [1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765]
20:08:54 <Pseudonym> OK, that one is a bit slow.
20:20:09 <Pseudonym> OK, I think we have a winner.
20:20:11 <Pseudonym> > map (\n -> let s o e i = if i<n then s (e+o) (2*e+o) (i+2) else if i ==
20:20:12 <lambdabot>  Parse error
20:20:23 <int-e> > let (a,b)?(c,d)=(a*c+b*d,b*c+(a+b)*d);g 0=(1,0);g 1=(0,1);g n=let x=g(n`div`2)in x?x?g(n`mod`2)in map(snd.g)[1..10]
20:20:23 <Pseudonym> > map (\n -> let s o e i = if i<n then s (e+o) (2*e+o) (i+2) else if i == n then e else o in s 1 0 0) [0..]
20:20:24 <lambdabot>  [1,1,2,3,5,8,13,21,34,55]
20:20:25 <lambdabot>  [0,1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,1597,2584,4181,6765,10946,...
20:20:43 <Pseudonym> That's NICE.
20:24:01 <dons> we should really write these down...
20:24:12 <dons> if you can get 100 of them, that's a paper! ;)
20:24:26 <hyraxfourtwo> ?type (?)
20:24:27 <lambdabot> Not in scope: `?'
20:24:29 <lisppaste2> dibblego pasted "Is this complete?" at http://paste.lisp.org/display/28105
20:24:30 <Pseudonym> > map (\n -> let s o e i = if i<n then (e+0): (2*e+o): s (e+o) (2*e+o) (i+2) else [if i == n then e else o] in s 1 0 0) [0..]
20:24:31 <lambdabot>  [[0],[0,1,1],[0,1,1],[0,1,1,3,2],[0,1,1,3,3],[0,1,1,3,3,8,5],[0,1,1,3,3,8,8]...
20:24:59 <Pseudonym> > map (\n -> let s o e i = if i<n then e:(e+o): s (e+o) (2*e+o) (i+2) else [if i == n then e else o] in s 1 0 0) [0..]
20:25:01 <lambdabot>  [[0],[0,1,1],[0,1,1],[0,1,1,2,2],[0,1,1,2,3],[0,1,1,2,3,5,5],[0,1,1,2,3,5,8]...
20:25:03 <glguy> hyraxfourtwo, sure
20:25:12 <Pseudonym> > map (\n -> let s o e i = if i<n then e:(e+o): s (e+o) (2*e+o) (i+2) else [] in s 1 0 0) [0..]
20:25:14 <lambdabot>  [[],[0,1],[0,1],[0,1,1,2],[0,1,1,2],[0,1,1,2,3,5],[0,1,1,2,3,5],[0,1,1,2,3,5...
20:25:16 <hyraxfourtwo> glguy, ?
20:25:27 <glguy> dibblego, sure
20:25:32 <hyraxfourtwo> what does ? do?
20:25:34 <hyraxfourtwo> in int-e's one
20:25:37 <dibblego> glguy, just checking, thanks
20:25:43 <int-e> hyraxfourtwo: it's defined in that let binding.
20:25:49 <glguy> hyraxfourtwo, he defined it with let
20:25:50 <Pseudonym> The ? operator in that case is pair multiplication.
20:25:54 <hyraxfourtwo> oh right
20:26:11 <Pseudonym> http://www.inwap.com/pdp10/hbaker/hakmem/recurrence.html
20:26:13 <Pseudonym> See that for details.
20:26:14 <lambdabot> Title: HAKMEM -- RECURRENCE RELATIONS -- DRAFT, NOT YET PROOFED, http://tinyurl.com/y263c8
20:26:29 <Pseudonym> You know, we need a new HAKMEM.
20:26:29 <rahikkala> Pseudonym: How about just using inits?
20:27:09 <hyraxfourtwo> rahikkala, I'm not sure you're getting the purpose... ;)
20:27:17 <int-e> in fact if you map (a,b) to the matrix [a,b;b,(a+b)] you get a homomorphism that maps ? to matrix multiplication
20:27:37 <hyraxfourtwo> iso?
20:27:47 <hyraxfourtwo> oh
20:27:49 <hyraxfourtwo> no of course not
20:28:07 <int-e> well, an isomorphism if you restrict yourself to matrices of that form
20:28:44 <rahikkala> hyraxfourtwo: I have no idea what the purpose is, I just looked at the stuff that Pseudonym has been coming up with and thought "isn't that what inits does" :p
20:29:48 <Pseudonym> Well, yes.
20:30:02 <Pseudonym> But it was the system reporting its progress.
20:46:38 <jgrimes> I was reading something, somewhere (specific, I know) and it said that a sufficiently powerful static type system could check whether or not a sorting algorithm actually sorted the input. Anyone know of any papers/resources I should look at to investigate this?
20:46:52 <skew> some of the epigram stuff
20:49:56 <Pseudonym> As Oleg pointed out, however, a sufficiently powerful static type system is a dynamically typed programming language itself.
20:50:17 <Pseudonym> So the extreme is basically dynamically typed interpretation in the compiler.
20:51:09 <skew> some sorts of static type systems
20:51:09 <jgrimes> but it still proves that at runtime the program will behave correctly, right?
20:51:17 <Pseudonym> "Sufficiently powerful", in this case, means powerful enough to express anything.
20:51:20 <skew> generally, the really powerful static type systems are themeselves statically typed programming languages
20:53:17 <jgrimes> Pseudonym, do you happen to have a link to where Oleg pointed this out?
20:53:22 <jgrimes> it makes sense
20:53:48 <Pseudonym> Not offhand, no.
20:53:54 <Pseudonym> But it's probably on his site.
20:53:59 <jgrimes> ok
20:54:06 <Adamant> if a static type system is a programming language (Turing-complete), doesn't that mean typing is not guaranteed to terminate?
20:54:20 <Pseudonym> Almost certainly.
20:54:29 <Adamant> isn't that a bad thing?
20:54:54 <skew> nah, you just use an incomplete / strongly-normalizing language
20:55:11 <jgrimes> what is the most powerful non-turing complete type system?
20:55:25 <Adamant> right, I know most type systems are not Turing complete
20:55:32 <skew> I'm pretty sure there is no most powerful non-turing complete language
20:55:39 <jgrimes> ok.
20:55:58 <jgrimes> yeah... that would be kind of interesting to judge..
20:56:23 <skew> unless there's some language that lets you define exactly the programs which halt
20:56:41 <skew> actually, I think System F might let you type just the terms of the lambda calculus that halt
20:57:29 <skew> if there is no such language, then you can take a terminating language, find a terminating program it doesn't let you express, and add it as a primitive to get a more powerful but still terminating language
20:57:42 <jgrimes> ah, that makes sense.
20:59:20 <skew> anyway, there are plenty of languages that are turing complete if you just add a fixpoint operator
21:00:02 <skew> and you can use monads to track whether some code possibly doesn't terminate
21:00:08 <skew> and keep those expressions out of types
21:00:31 <jgrimes> hm
21:00:48 <jgrimes> skew, any examples? :)
21:01:08 <hyraxfourtwo> let ar :: Array Int Int = array (0,8) [(x,x*2) | x <- [0..8] in ar!9
21:01:15 <hyraxfourtwo> > let ar :: Array Int Int = array (0,8) [(x,x*2) | x <- [0..8] in ar!9
21:01:15 <lambdabot>  Parse error
21:01:21 <hyraxfourtwo> > let ar :: Array Int Int = array (0,8) [(x,x*2) | x <- [0..8]] in ar!9
21:01:22 <lambdabot>  Parse error
21:01:38 <hyraxfourtwo> > let ar = array (0,8) [(x,x*2) | x <- [0..8]] in ar!9
21:01:40 <lambdabot>  Exception: Ix{Integer}.index: Index (9) out of range ((0,8))
21:01:43 <jgrimes> skew, being able to prove things at compile time about a program just seems incrediby important to me.
21:01:59 <skew> www.e-pig.org
21:04:11 <skew> also http://www.cs.nott.ac.uk/~txa/talks/bctcs06.pdf
21:04:15 <lambdabot> http://tinyurl.com/fx5ap
21:05:10 <jgrimes> skew, all right, thanks. :)
21:08:58 <glguy__> http://www.phatrags.com/menstshirts/community-college-easier-than-regular-college-shirt_29.html This reminds me of a shirt my brother had that just says "College" on it
21:09:02 <lambdabot> Title: Phat Rags - Funny Shirts for Men & Women - Community College (Easier than regula ..., http://tinyurl.com/yar74f
21:15:35 <dons> glguy__: hehe
21:16:56 <glguy__> I was just reading about that scam that was Packard Bell and remembering how much my old Packard Bell computer sucked
21:18:01 <glguy__> but to be honest, I guess I can't think of a decent brand name PC off-hand today either
21:18:54 <dons> there are some nice laptops around though
21:19:20 <dons> i suppose that mips 16 core desktop is in the "nice!" category too
21:19:28 <glguy__> They ditched the US market around 2000 I believe because their reputation was so bad
21:19:40 <dons> heh
21:20:18 <skew> damn, somebody needs to make coq keep source locations on type errors
21:20:30 <skew> "Error: This type is "~ In d ls'" but is expected to be "~ In d ls""
21:20:44 <skew> on a 7 line definition!
21:21:04 <glguy__> skew: Is vs. ls?
21:21:42 <dons> ls' v ls" ?
21:22:04 <dons> (what does that mean, or is it a typo?)
21:22:18 <skew> neither - there's also a bit of pattern matching on GADTs not enriching the local typing environment mixed in
21:23:27 <skew> dons: I had " around the whole thing, and also the message used " around bits of expression
21:23:39 <skew> so it's ~In d ls' vs. ~In d ls
22:04:41 <lucb> Hi everyone
22:05:04 <skew> hi
22:05:15 <jgrimes> hi
22:05:16 <lucb> not much activity
22:05:25 <Pseudonym> There is now you're here.
22:05:27 <Pseudonym> Party time!
22:06:21 <lucb> someone knows of an errata list for Hal Daume Haskell tutorial?
22:07:37 <lucb> specifically about the solution to exercise 4.11 about continuation passing
22:09:26 <skew> hey bringert. I was looking at HaskellDB today.
22:10:48 <bringert> morning
22:11:00 <skew> Mostly, I'm wondering how aggregates work, also if there is any guide to hacking.
22:12:03 <bringert> aggregates cause automatic grouping on all non-aggregate fields
22:12:10 <bringert> there is no guide to hacking
22:12:35 <bringert> but you are welcome to write one :-)
22:12:41 <bringert> and ask me questions
22:12:42 <skew> and then you can project later, if you don't want to actually report all the non-aggregate fields?
22:13:19 <bringert> that should work. can you give me an example of what you want to do?
22:14:00 <skew> no, grouping on the non-aggregate fields should be enough for what I'm actually donig
22:14:52 <skew> but I was asking to help figure out how it composes
22:15:03 <bringert> ah
22:15:38 <bringert> haskelldb needs a serious overhaul
22:15:51 <bringert> for more features and type safety
22:15:53 <skew> I'm trying to rewrite some code that is currently C over MySQL
22:16:17 <bringert> e.g. left joins and typed joins
22:16:37 <bringert> and foreign keys
22:17:08 <skew> I think these things might be nonstandard, but the existing code uses "INSERT INGORE INTO t SELECT ...", which silently drops duplicates, and "DELETE t.* FROM t, t2 WHERE ...", which removes only rows of t that appear in the join
22:17:13 <bringert> probably with ideas from CoddFish, http://wiki.di.uminho.pt/wiki/bin/view/PURe/CoddFish
22:17:28 <lambdabot> Title: PURe Project, http://tinyurl.com/gwqy4
22:17:57 <monstre> I'm trying to learn Haskell, is it okay to ask some basic questions in here?
22:18:08 <dibblego> monstre, sure
22:18:39 <bringert> skew, yes haskelldb ignores duplicates
22:18:48 <lucb> monstre, are you reading Hal Daume tutorial?
22:19:03 <bringert> it would be nice to give the user the option to inlude duplicates
22:19:09 <skew> insertQuery ignores duplicates?
22:19:13 <monstre> The "gentle" introduction, actually
22:19:22 <skew> even if the table has a primary key? Ok
22:19:24 <bringert> skew: don't know actually
22:19:43 <lucb> I did not read it
22:19:51 <skew> what about the delete thing? Both of these are used in little self-contained queries that shuffle some data around, so passing raw SQL for those would not be such a problem
22:20:12 <bringert> ah, I misunderstood
22:20:39 <monstre> Are tail-recursive functions executed in constant space in Haskell?
22:20:56 <monstre> I'm trying to understand how lazy evaluation fits into this picture.
22:21:35 <skew> bringert: I found it convenient to edit DBDirect to generate one module with all the field names
22:22:12 <bringert> skew: I'm not sure about how insertQuery works, and the delete based on a join you would probably have to fake for now, or you could add something like it
22:22:24 <bringert> but, as you say, it sounds like non-standard SQL
22:22:40 <bringert> skew: what if there are duplicate field names with different types?
22:22:54 * bringert goes to get a shower
22:23:01 <skew> In my case I do not have them, and qualifying field names was annoying
22:29:21 <hyraxfourtwo> lucb, I reemmber having trouble with the cps part
22:29:38 <hyraxfourtwo> in the end I decided to ignore it
22:29:47 <lucb> the cfold that he define,
22:29:53 <hyraxfourtwo> hang on
22:29:55 <hyraxfourtwo> ?where htut
22:29:55 <lambdabot> I know nothing about htut.
22:29:59 <hyraxfourtwo> ?where yaht
22:29:59 <lambdabot> http://www.cs.utah.edu/~hal/docs/daume02yaht.pdf
22:30:12 <lucb> it's really the same as a foldr
22:31:29 <hyraxfourtwo> oh yes it is incorrect
22:31:32 <hyraxfourtwo> I remember that now
22:32:04 <lucb> you had the same problem ?
22:32:05 <hyraxfourtwo> or wait
22:32:07 <hyraxfourtwo> hang on
22:32:26 <hyraxfourtwo> it is not as foldr
22:32:33 <lucb> it act as
22:32:44 <lucb> I obtain the same result
22:33:47 <dibblego> you should be able to write a quickcheck to determine it
22:33:49 <hyraxfourtwo> it's meant to act as it
22:33:58 <hyraxfourtwo> but it is different
22:34:04 <hyraxfourtwo> the f in cfold' takes a continuation argument
22:34:10 <hyraxfourtwo> ?type foldr
22:34:12 <lambdabot> forall b a. (a -> b -> b) -> b -> [a] -> b
22:34:39 <lucb> *CPS> :t foldr
22:34:39 <lucb> foldr :: (a -> b -> b) -> b -> [a] -> b
22:34:40 <lucb> *CPS> :t cfold
22:34:40 <lucb> cfold :: (a -> t -> t) -> t -> [a] -> t
22:34:47 <hyraxfourtwo> ?type let cfold f z [] = z
22:34:47 <hyraxfourtwo>  ; cfold f z (x:xs) = f x z (\y -> cfold f y xs) in cfold'
22:34:49 <lambdabot> lexical error
22:34:59 <hyraxfourtwo> ugh
22:35:03 <hyraxfourtwo> yes
22:35:12 <hyraxfourtwo> but cfold is a wrapper around cfold'
22:35:17 <lucb> yeah
22:35:18 <hyraxfourtwo> which does not work the same way as foldr
22:35:31 <lucb> but that's what he meant in the exercise?
22:35:54 <hyraxfourtwo> sorry?
22:35:59 <hyraxfourtwo> oh the exercise
22:36:35 <hyraxfourtwo> well if you think it acts like foldr
22:36:37 <hyraxfourtwo> then it acts like foldr
22:36:38 <hyraxfourtwo> ?type foldr
22:36:40 <lambdabot> forall b a. (a -> b -> b) -> b -> [a] -> b
22:36:41 <hyraxfourtwo> ?type foldl
22:36:43 <lambdabot> forall a b. (a -> b -> a) -> a -> [b] -> a
22:36:53 <lucb> it's really not a foldl for sure
22:37:31 <lucb> from the call
22:37:43 <lucb> cfold (-) 0 [1,2,3]
22:37:54 <lucb> I get the result 2
22:38:34 <lucb> as in foldr and when I "unroll" the continuation (lambda expression) I obtain 1 - (2 - (3 - 0))
22:38:51 <hyraxfourtwo> ?check let cfold' f z [] = z; cfold' f z (x:xs) = f x z (\y -> cfold' f y xs); cfold f z l = cfold (\x t g -> f x (g t)) z l in foldr f z xs == cfold f z xs
22:38:51 <lambdabot>  Illegal character ''\128''
22:39:01 <hyraxfourtwo> bleh
22:39:20 <monstre> Sorry to insist, but can anyone tell me wether tail-recursive functions are executed in constant space in Haskell as they would be in, say, Scheme?
22:39:28 <monstre> Or does lazy evaluation defeat this property?
22:39:28 <hyraxfourtwo> monstre, yes
22:39:42 <monstre> thank you
22:41:08 <monstre> Any particular reason this isn't mandated by the standard?
22:41:42 <monstre> Do all implementations provide this guarantee?
22:45:46 <dibblego> it's just a given
22:48:18 <monstre> thanks dibblego
22:48:31 <monstre> as I said, I'm only just learning the language
22:49:39 <vegai> a haskell implementation that wouldn't do that would be practically useless...
22:54:24 <sjanssen> tail recursive functions aren't necessarily O(1) space
22:54:39 <sjanssen> you have to be careful about strictness in your accumulated value
22:54:48 <audreyt> especially if you alloc some more in each accum thunk...
22:54:56 <audreyt> yup.
22:55:19 <audreyt> sjanssen: how's Stringable doing?
22:57:45 <sjanssen> audreyt: "done", I suppose.  If you're talking about the typeclass specifically
22:58:13 <sjanssen> does say, pugs, need a generic string interface?
22:58:19 <Cale> Perhaps I should illustrate what happens :)
22:58:35 <Cale> monstre: let's evaluate foldl (+) 0 [1,2,3]
22:58:50 <Cale> foldl f z [] = z
22:59:04 <Cale> foldl f z (x:xs) = foldl f (f z x) xs
22:59:07 <audreyt> sjanssen: yes, one that's Rope-ish, preferably a Sequence of ByteString, or one of dcoutt's StrnigBuilder layouts
22:59:09 <Cale> so
22:59:17 <Cale> foldl (+) 0 [1,2,3]
22:59:23 <Cale> = foldl (+) (0+1) [2,3]
22:59:31 <Cale> = foldl (+) ((0+1)+2) [3]
22:59:43 <audreyt> sjanssen: Char8 is insufficient; currently we use Martin's .UTF8 but as you know it's slowish.
22:59:44 <Cale> = foldl (+) (((0+1)+2)+3) []
22:59:50 <Cale> = (((0+1)+2)+3)
22:59:55 <Cale> = ((1+2)+3)
22:59:59 <Cale> = (3+3)
23:00:01 <Cale> = 6
23:00:28 <Cale> monstre: see how the outermost-first lazy evaluation causes that expression to be built up?
23:00:36 <monstre> right
23:00:58 <Cale> So we can actually fix this, by using seq
23:01:01 <sjanssen> audreyt: recently musasabi was hacking on UTF16 for the fps-unstable branch
23:01:11 <sjanssen> I'm not sure how far that's gone
23:01:14 <Cale> foldl' f z [] = z
23:01:40 <Cale> foldl' f z (x:xs) = let u = f z x in u `seq` foldl' f u xs
23:02:36 <Cale> a `seq` b is an expression, which when evaluated, will force the evaluation of a, up to determining its top-level constructor (Weak Head Normal Form), before returning the value of b
23:02:41 <sjanssen> audreyt: also, have you seen Data.StorableVector?
23:02:44 <audreyt> yup
23:02:49 <audreyt> havn't deployed it though
23:03:06 <audreyt> happy to hear the "done" on Stringable
23:03:15 <monstre> Thanks for the explanation Cale :)
23:03:21 <audreyt> when will it be integrated back to -unstable or even fps/ ?
23:03:40 <Cale> So using foldl' instead of foldl will force that evaluation to happen as the foldl runs down the list.
23:03:40 <monstre> So there's no way to mark an argument as strict  la Clean?
23:04:04 <Cale> Well, there's going to be bang patterns, but there's no uniqueness types.
23:04:12 <sjanssen> audreyt: I don't think the Rope stuff will go to the main fps repo
23:04:19 <audreyt> ok
23:04:23 <sjanssen> but I have hopes for StorableVector
23:04:32 <Cale> bang patternss are just a little syntax sugar for seq
23:04:37 <Cale> -s
23:04:54 <monstre> very well then, thanks again for your help
23:05:19 <Cale> I should also warn that there's a good reason to avoid left folds though
23:05:22 <sjanssen> another part of musasabi's hacking was making the stream fusion stuff polymorphic (ie not limited to Word8).  Once that is in the repo, I'm going to port StorableVector to streams fusion
23:05:24 <Cale> (in general)
23:05:34 <Cale> They defeat laziness.
23:05:52 <monstre> I suspected as much
23:06:00 <Cale> In that nothing is ever returned until foldl has completed its work travelling down the list.
23:06:09 <monstre> right
23:06:12 <audreyt> sjanssen: that'd rock. is there a ML or channel for this, or is it all in the darcs?
23:06:31 <Cale> It's actually better in a lazy language to return a constructor immediately, rather than to call yourself immediately with different parameters
23:06:44 <Cale> because returning a constructor actually means that you terminate in one step :)
23:07:01 <monstre> is foldl' already defined anywhere?
23:07:06 <Cale> yeah, in Data.List
23:07:10 <sjanssen> audreyt: just some chatting in #haskell-overflow
23:07:12 <monstre> it doesn't seem to be part of the standard
23:07:17 <Cale> yeah
23:07:59 <Cale> It's documented in the Hierarchical libraries documentation
23:08:12 <Cale> http://www.haskell.org/ghc/docs/latest/html/libraries/index.html
23:08:15 <lambdabot> http://tinyurl.com/eoao7
23:18:36 <monstre> Hmmm, given the existence of foldl', what's the point of foldl then?
23:18:44 <monstre> Am I missing something?
23:19:17 <sjanssen> monstre: there are (very rare) cases where you want the non-strict version
23:19:34 <monstre> such as?
23:19:53 <hyrax42> ?index randomR
23:19:54 <lambdabot> System.Random
23:19:56 <sjanssen> I can't think of any off the top of my head
23:20:39 <hyrax42> what'st eh syntax for re-exporting amodule
23:20:48 <hyrax42> module Module?
23:21:05 <Botty> what does 'strict' in that context mean? the docs are really bad on that topic
23:22:40 <ThreeQ> the arguments are fully evaluated before the function is called
23:22:41 <sjanssen> Botty: strict in this case means that foldl' forces (via seq) the accumulator value after each application of the function
23:23:51 <Botty> ah, huh.  considering that there's no foldr', I guess its something to do with the lazy stuff
23:24:14 <Cale> There's nothing to strictify in foldr
23:24:28 <sjanssen> Botty: it's because foldr' would be forced to use O(n) stack space
23:24:29 <Cale> I suppose you could force the evaluation of the element, but it wouldn't save you anything
23:24:36 <sjanssen> so it wouldn't be an optimization
23:24:51 <Botty> ah, ok
23:26:06 <kzm> Anybody run GHC on IA64 (Itanium)?
23:26:42 <Botty> hmm, with functional programming you tend to recreate data structures alot, as you change little parts, does ghc optimize this to keep the memory region/data and only change what is actually changed?
23:26:50 <Cale> monstre: adding up a list of power series, for instance
23:27:14 <Cale> where you don't want to force the evaluation of the power series, and leave it as something to be lazily evaluated
23:27:25 <Cale> Botty: to some extent
23:27:34 <Cale> Botty: but largely, no
23:27:40 <Cale> but it does share things
23:27:58 <Botty> hmm, well i suppose thats what you pay for niceness
23:28:29 <Cale> You can force it to do so. There are things like monadic mutable arrays.
23:28:54 <Botty> oh, huh
23:29:33 <monstre> Is there any documentation that explores the consequences of lazy evaluation on the space complexity of programs in greater details?
23:29:47 <monstre> I'm still a little confused
23:30:04 <Pseudonym> Not really, no.
23:30:16 <Pseudonym> Memory complexity is a property of the program as a whole.
23:30:31 <Pseudonym> If it helps, lazy evaluation is usually optimal for generational GC.
23:30:42 <lispy> Pseudonym: huh?
23:30:44 <Pseudonym> Since data is usually created only just before it's consumed.
23:31:03 <lispy> Pseudonym: but lazy evaluation can easily lead to unrecoverable thunks and the like eating up tons of space
23:31:23 <Cale> I find a good way to understand things is just to write out the expressions, and do some outermost-first evaluation.
23:31:46 <Cale> If you want a better approximation, use let expressions to remember that variables are shared
23:31:49 <monstre> What is the motivation then for a language that is lazy by default with strictness annotations rather than the other way around?
23:31:50 * lispy has been coding C++ COM stuff for the last several hours and my be grumpy :)
23:32:05 <lispy> monstre: laziness improves composability
23:32:08 <Cale> monstre: The motivation is that you can stick programs together in new ways
23:32:20 <Cale> For example
23:32:27 <Cale> (I always give this example)
23:32:39 <lispy> monstre: it also gets rid of many exceptions to the evaluation rules and pushes it into one weird construct (say seq) for forcing evaluation which can thene be inserted when needed
23:32:49 <Cale> Suppose I have isPrefixOf, like in the Data.List library, and I want to write isSubstringOf
23:32:57 <Cale> I can write
23:33:13 <Cale> isSubstringOf x y = any (isPrefixOf x) (tails y)
23:33:27 <Cale> In a strict language, that is incredibly stupid.
23:33:43 <monstre> what is the time complexity of that function then?
23:33:45 <Cale> Constructing the list of tails will waste lots of time and memory in general.
23:34:06 <Cale> But here, they're only constructed as needed, and even better, the tails are shared.
23:34:20 <glguy__> worst case O(x*y)
23:34:31 <Cale> So this amounts to exactly the same thing as a nested loops implementation with early bailouts in an imperative language.
23:34:35 <lispy> O(|x|*|y|)
23:34:43 <glguy__> :-p
23:34:46 <lispy> (where |.| means size of)
23:35:04 <lispy> glguy__: your complexity had a type error okay :)
23:35:07 <Cale> If the substring occurs near the beginning, then it will stop only after computing that much though
23:35:33 * lispy goes home
23:35:34 <monstre> this is nice and all but I'm not sure it really answers my question...
23:35:44 <lispy> i can't believe i'm at work and it's almost midnight...ugh
23:36:12 <monstre> I'm not skeptical of the value of laziness in general, I'm just not convinced it's the right *default*
23:36:28 <Cale> Well, it doesn't really work unless everything is lazy
23:36:49 <Cale> Because the first strict thing to come along will often mess things up.
23:36:57 <monstre> you can have lazy streams in a strict language, no?
23:37:03 <sjanssen> monstre: this is an open question I suppose.  Just like static v. dynamic typing, white v. wheat, etc.
23:37:23 <Cale> You can, but you don't get quite the level of composability with them.
23:38:13 <Cale> One nice observation to make is this
23:38:58 <Cale> If we have a data structure, either there are lots of subcomponents which could potentially be evaluated separately, or there are relatively few.
23:39:26 <Cale> Functions can be classified based on whether their inputs and outputs are "large" or "small" in this fashion
23:39:59 <glguy__> It never occured to me that I would use the built in zoom and high contrast features to see my laptop w/o my glasses
23:40:04 <Cale> For the case large -> small, where the entire large object is consumed, you want strictness.
23:40:27 <Cale> In all other cases, either strictness/laziness doesn't matter, or laziness wins.
23:41:04 <ibid> hrm. uploading ghc 6.6 to unstable in debian just before general freeze does not seem very smart to me
23:41:25 <ibid> or did the release managers approve this transition?
23:41:45 <Cale> For instance, in the case large -> small, where you are searching through the large object to find something, laziness is better, because you might not need the whole large object.
23:42:14 <Cale> For small -> large, laziness is better because you might never need to construct the entire large object.
23:42:28 <Cale> For small -> small, it doesn't really make a difference.
23:43:31 <Cale> and for large -> large, either it won't make a difference, or laziness will win (if initial parts of the output structure can be built from initial parts of the input)
23:43:46 <monstre> regarding the large->small case, am I right to think that most such functions can be expressed as folds?
23:43:58 <Cale> yes, if viewed the right way
23:44:00 <monstre> assuming you want to conume the entire input
23:44:04 <Cale> right
23:44:09 <monstre> ...consume even
23:44:17 <Cale> so foldl' is really extremely general in some sense :)
23:44:55 <Cale> but even when it's inconvenient, it's usually not so hard after a little profiling to pinpoint places where seq will help, with this mental model.
23:45:22 <Cale> Or you might build some other higher-order function
23:46:51 <monstre> well, I'm slightly less confused than I was an hour ago
23:46:54 <monstre> thanks everyone
23:46:59 <Cale> cool :)
23:47:33 <monstre> back to do some reading now
23:47:39 <monstre> next up: monads
23:47:56 <monstre> *takes a deep breath*
23:48:00 <lispy> monads are fun
23:48:07 <lispy> you'll enjoy that part
23:50:21 <vegai> yeah. And math is fun.
23:50:56 <lispy> comlib is a lot of fun
23:51:06 <ThreeQ> ?where comlib
23:51:07 <lambdabot> I know nothing about comlib.
23:51:21 <Cale> check out my tutorial on monads too :)
23:51:26 <ThreeQ> lispy: comlib?
23:51:27 <lispy> comlib is currently a part of visual haskell, but i'm trying to fix some 'bugs' in it
23:51:30 <Cale> It's called Monads As Containers
23:51:31 <ThreeQ> ah
23:51:44 <monstre> will do :)
23:51:46 <Cale> monstre: http://www.haskell.org/haskellwiki/Monads_as_Containers
23:51:50 <lambdabot> Title: Monads as containers - HaskellWiki, http://tinyurl.com/llgo9
23:52:14 <lispy> i have this example i grabbed from a python forum that uses COM to fire up IE, navigate to google and dump the HTML of the google homepage
23:52:23 <lispy> it shows off a lot of COM without getting too fancy
23:52:38 <lispy> for some reason, it doesn't work the 'right way' with comlib
23:53:05 <lispy> and i spent several hours today coding up a C++ reference implementation so i could see exactly what function calls are needed to just make it work
23:53:27 <lispy> i'm hoping that when i look at the haskell code again i can figure out where it deviates from what it should be doing
23:53:47 <lispy> (note: i was able to get comlib to do it, but i have to do a lot of extra work to fight comlib)
23:54:16 <lispy> in python it takes < 5 minutes to code the example up
23:54:26 <lispy> in C++ it took me probably 5 hours
23:54:38 <lispy> talk about a huge difference in productivity
23:55:48 <lispy> if i can fix the bug i'm seeing with comlib it should be roughly the same productivity as python
23:55:51 <lispy> which is my goal
23:56:44 <astrolabe> I find debugging the most painful thing about haskell at the moment.
23:57:01 <lispy> i find that it depends
23:57:10 <lispy> the C++ debugger sure didn't help me today
23:57:15 <lispy> and i tried using it a lot
23:57:28 <lispy> doing low level stuff i just get stuck no matter what
23:57:47 <lispy> but i find that equational reasoning + haskell is pretty efficient debugging
23:57:58 <astrolabe> C++ debuggers were more useful before all this STL stuff appeared :)
23:58:01 <lispy> astrolabe: what have you been debugging?
23:58:40 <astrolabe> I have some code to find arrangements of objects based on baysian probabilities.
23:58:54 <lispy> oh, so the data is pretty opaque?
23:59:06 <astrolabe> The problem is that it is complicated enough to be counter-intuitive.
23:59:29 <monstre> so I'm reading Cale's 'Monads as containers' tutorial, which seems very nice by the way, and it says that "every monad is a functor"...
23:59:48 <astrolabe> It does things that people are good at, for instance finding an approximate square of objects.
23:59:58 <monstre> so I guess my first question is: why isn't Monad a subclass of Functor?
